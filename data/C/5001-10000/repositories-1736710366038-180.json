{
  "metadata": {
    "timestamp": 1736710366038,
    "page": 180,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "axboe/fio",
      "stars": 5385,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3935546875,
          "content": "*.d\n*.o\n*.so\n*.exe\n/.depend\n/FIO-VERSION-FILE\n/config-host.h\n/config-host.mak\n/config.log\n/cscope.out\n/fio\n/gfio\n/t/axmap\n/t/fio-btrace2fio\n/t/fio-dedupe\n/t/fio-genzipf\n/t/fio-verify-state\n/t/gen-rand\n/t/ieee754\nt/io_uring\n/t/lfsr-test\nt/memlock\nt/read-to-pipe-async\n/t/stest\n/unittests/unittest\ny.tab.*\nlex.yy.c\n*.un~\ndoc/output\n/tags\n/TAGS\n/t/zbd/test-zbd-support.log.*\n/t/fuzz/fuzz_parseini\ntsc-rate\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.384765625,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n   configuration: doc/conf.py\n\n# Optionally build your docs in additional formats such as PDF\nformats:\n   - epub\n   - pdf\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.2421875,
          "content": "cff-version: 1.2.0\npreferred-citation:\n  type: software\n  authors:\n  - family-names: \"Axboe\"\n    given-names: \"Jens\"\n    email: axboe@kernel.dk\n  title: \"Flexible I/O Tester\"\n  year: 2022\n  url: \"https://github.com/axboe/fio\"\nlicence: GNU GPL v2.0\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 17.66796875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Lesser General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n                            NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License along\n    with this program; if not, write to the Free Software Foundation, Inc.,\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.\n"
        },
        {
          "name": "DEDUPE-TODO",
          "type": "blob",
          "size": 0.7890625,
          "content": "- Shifted dedup-able data.\n  Allow for dedup buffer generation to shift contents by random number\n  of sectors (fill the gaps with uncompressible data). Some storage\n  subsystems modernized the deduplication detection algorithms to look\n  for shifted data as well. For example, some databases push a timestamp\n  on the prefix of written blocks, which makes the underlying data\n  dedup-able in different alignment. FIO should be able to simulate such\n  workload.\n\n- Generation of similar data (but not exact).\n  A rising trend in enterprise storage systems.\n  Generation of \"similar\" data means random uncompressible buffers\n  that differ by few(configurable number of) bits from each other.\n  The storage subsystem usually identifies the similar buffers using\n  locality-sensitive hashing or other methods.\n\n"
        },
        {
          "name": "FIO-VERSION-GEN",
          "type": "blob",
          "size": 0.7060546875,
          "content": "#!/bin/sh\n\nGVF=FIO-VERSION-FILE\nDEF_VER=fio-3.38\n\nLF='\n'\n\n# First see if there is a version file (included in release tarballs),\n# then try git-describe, then default.\nif test -f version\nthen\n\tVN=`cat version` || VN=\"$DEF_VER\"\nelif test -d .git -o -f .git &&\n\tVN=`git describe --match \"fio-[0-9]*\" --abbrev=4 HEAD 2>/dev/null` &&\n\tcase \"$VN\" in\n\t*$LF*) (exit 1) ;;\n\tfio-[0-9]*)\n\t\tgit update-index -q --refresh\n\t\ttest -z \"`git diff-index --name-only HEAD --`\" ||\n\t\tVN=\"$VN-dirty\" ;;\n\tesac\nthen\n\tVN=$VN\nelse\n\tVN=\"$DEF_VER\"\nfi\n\nVN=`expr \"$VN\" : v*'\\(.*\\)'`\n\nif test -r $GVF\nthen\n\tVC=`sed -e 's/^FIO_VERSION = //' <$GVF`\nelse\n\tVC=unset\nfi\ntest \"$VN\" = \"$VC\" || {\n\techo >&2 \"FIO_VERSION = $VN\"\n\techo \"FIO_VERSION = $VN\" >$GVF\n}\n"
        },
        {
          "name": "GFIO-TODO",
          "type": "blob",
          "size": 1.8818359375,
          "content": "In no particular order:\n\n- Ability to save job files. Probably in an extended gfio format,\n  so we can include options/settings outside of a fio job file.\n\n- End view improvements:\n\n\t- Cleanup the layout\n\t- Add ability to save the results\n\t- Add ability to load end-results as well\n\t- Add ability to request graphs of whatever graphing options\n\t  the fio job included.\n\t- Add ability to graph completion latencies, percentiles, etc.\n\n- Add ability to edit job options:\n\n\t- We need an options view after sending a job, that allows us to\n\t  visually see what was parsed, make changes, resubmit.\n\n\t- Job options are already converted across the network and\n\t  are available in gfio_client->o for view/edit. We'll need\n\t  a FIO_NET_CMD_UPDATE_OPTIONS command to send them back,\n\t  and backend support for updating an existing set of options.\n\n- Add support for printing end results, graphs, etc.\n\n- Improve the auto-start backend functionality, it's quite buggy.\n\n- Ensure that it works on OSX and Windows. We'll need a bit of porting\n  work there.\n\n- Persistent store of prefences set. This will need a per-OS bit as well,\n  using gfonf on Linux, registry on Windows, ?? on OSX.\n\n- Ensure that local errors go to our log, instead of being displayed on\n  the console.\n\n- Ensure that the whole connect/send/start button logic is sane. Right\n  now it works when you perform the right sequence, but if you connect\n  and disconnect, things can get confused. We'll need to improve how\n  we store and send job files. Right now they are in ge->job_files[]\n  and are always emptied on send. Keep them around?\n\n- Commit rate display is not enabled.\n\n- Group status reporting is not enabled.\n\n- Split gfio.c a bit. Add gfio/ sub directory, and split it into\n  files based on functionality. It's already ~3000 lines long.\n\n- Attempt to ensure that we work with gtk 2.10 and newer. Right\n  now the required version is ~2.18 (not quite known).\n"
        },
        {
          "name": "HOWTO.rst",
          "type": "blob",
          "size": 206.771484375,
          "content": "How fio works\n-------------\n\nThe first step in getting fio to simulate a desired I/O workload, is writing a\njob file describing that specific setup. A job file may contain any number of\nthreads and/or files -- the typical contents of the job file is a *global*\nsection defining shared parameters, and one or more job sections describing the\njobs involved. When run, fio parses this file and sets everything up as\ndescribed. If we break down a job from top to bottom, it contains the following\nbasic parameters:\n\n`I/O type`_\n\n\t\tDefines the I/O pattern issued to the file(s).  We may only be reading\n\t\tsequentially from this file(s), or we may be writing randomly. Or even\n\t\tmixing reads and writes, sequentially or randomly.\n\t\tShould we be doing buffered I/O, or direct/raw I/O?\n\n`Block size`_\n\n\t\tIn how large chunks are we issuing I/O? This may be a single value,\n\t\tor it may describe a range of block sizes.\n\n`I/O size`_\n\n\t\tHow much data are we going to be reading/writing.\n\n`I/O engine`_\n\n\t\tHow do we issue I/O? We could be memory mapping the file, we could be\n\t\tusing regular read/write, we could be using splice, async I/O, or even\n\t\tSG (SCSI generic sg).\n\n`I/O depth`_\n\n\t\tIf the I/O engine is async, how large a queuing depth do we want to\n\t\tmaintain?\n\n\n`Target file/device`_\n\n\t\tHow many files are we spreading the workload over.\n\n`Threads, processes and job synchronization`_\n\n\t\tHow many threads or processes should we spread this workload over.\n\nThe above are the basic parameters defined for a workload, in addition there's a\nmultitude of parameters that modify other aspects of how this job behaves.\n\n\nCommand line options\n--------------------\n\n.. option:: --debug=type\n\n\tEnable verbose tracing `type` of various fio actions.  May be ``all`` for all types\n\tor individual types separated by a comma (e.g. ``--debug=file,mem`` will\n\tenable file and memory debugging).  Currently, additional logging is\n\tavailable for:\n\n\t*process*\n\t\t\tDump info related to processes.\n\t*file*\n\t\t\tDump info related to file actions.\n\t*io*\n\t\t\tDump info related to I/O queuing.\n\t*mem*\n\t\t\tDump info related to memory allocations.\n\t*blktrace*\n\t\t\tDump info related to blktrace setup.\n\t*verify*\n\t\t\tDump info related to I/O verification.\n\t*all*\n\t\t\tEnable all debug options.\n\t*random*\n\t\t\tDump info related to random offset generation.\n\t*parse*\n\t\t\tDump info related to option matching and parsing.\n\t*diskutil*\n\t\t\tDump info related to disk utilization updates.\n\t*job:x*\n\t\t\tDump info only related to job number x.\n\t*mutex*\n\t\t\tDump info only related to mutex up/down ops.\n\t*profile*\n\t\t\tDump info related to profile extensions.\n\t*time*\n\t\t\tDump info related to internal time keeping.\n\t*net*\n\t\t\tDump info related to networking connections.\n\t*rate*\n\t\t\tDump info related to I/O rate switching.\n\t*compress*\n\t\t\tDump info related to log compress/decompress.\n\t*steadystate*\n\t\t\tDump info related to steadystate detection.\n\t*helperthread*\n\t\t\tDump info related to the helper thread.\n\t*zbd*\n\t\t\tDump info related to support for zoned block devices.\n\t*?* or *help*\n\t\t\tShow available debug options.\n\n.. option:: --parse-only\n\n\tParse options only, don't start any I/O.\n\n.. option:: --merge-blktrace-only\n\n\tMerge blktraces only, don't start any I/O.\n\n.. option:: --output=filename\n\n\tWrite output to file `filename`.\n\n.. option:: --output-format=format\n\n\tSet the reporting `format` to `normal`, `terse`, `json`, or `json+`.  Multiple\n\tformats can be selected, separated by a comma.  `terse` is a CSV based\n\tformat.  `json+` is like `json`, except it adds a full dump of the latency\n\tbuckets.\n\n.. option:: --bandwidth-log\n\n\tGenerate aggregate bandwidth logs.\n\n.. option:: --minimal\n\n\tPrint statistics in a terse, semicolon-delimited format.\n\n.. option:: --append-terse\n\n\tPrint statistics in selected mode AND terse, semicolon-delimited format.\n\t**Deprecated**, use :option:`--output-format` instead to select multiple\n\tformats.\n\n.. option:: --terse-version=version\n\n\tSet terse `version` output format (default 3, or 2 or 4 or 5).\n\n.. option:: --version\n\n\tPrint version information and exit.\n\n.. option:: --help\n\n\tPrint a summary of the command line options and exit.\n\n.. option:: --cpuclock-test\n\n\tPerform test and validation of internal CPU clock.\n\n.. option:: --crctest=[test]\n\n\tTest the speed of the built-in checksumming functions. If no argument is\n\tgiven, all of them are tested. Alternatively, a comma separated list can\n\tbe passed, in which case the given ones are tested.\n\n.. option:: --cmdhelp=command\n\n\tPrint help information for `command`. May be ``all`` for all commands.\n\n.. option:: --enghelp=[ioengine[,command]]\n\n\tList all commands defined by `ioengine`, or print help for `command`\n\tdefined by `ioengine`.  If no `ioengine` is given, list all\n\tavailable ioengines.\n\n.. option:: --showcmd\n\n\tConvert given job files to a set of command-line options.\n\n.. option:: --readonly\n\n\tTurn on safety read-only checks, preventing writes and trims.  The\n\t``--readonly`` option is an extra safety guard to prevent users from\n\taccidentally starting a write or trim workload when that is not desired.\n\tFio will only modify the device under test if\n\t`rw=write/randwrite/rw/randrw/trim/randtrim/trimwrite` is given.  This\n\tsafety net can be used as an extra precaution.\n\n.. option:: --eta=when\n\n\tSpecifies when real-time ETA estimate should be printed.  `when` may be\n\t`always`, `never` or `auto`. `auto` is the default, it prints ETA\n\twhen requested if the output is a TTY. `always` disregards the output\n\ttype, and prints ETA when requested. `never` never prints ETA.\n\n.. option:: --eta-interval=time\n\n\tBy default, fio requests client ETA status roughly every second. With\n\tthis option, the interval is configurable. Fio imposes a minimum\n\tallowed time to avoid flooding the console, less than 250 msec is\n\tnot supported.\n\n.. option:: --eta-newline=time\n\n\tForce a new line for every `time` period passed.  When the unit is omitted,\n\tthe value is interpreted in seconds.\n\n.. option:: --status-interval=time\n\n\tForce a full status dump of cumulative (from job start) values at `time`\n\tintervals. This option does *not* provide per-period measurements. So\n\tvalues such as bandwidth are running averages. When the time unit is omitted,\n\t`time` is interpreted in seconds. Note that using this option with\n\t``--output-format=json`` will yield output that technically isn't valid\n\tjson, since the output will be collated sets of valid json. It will need\n\tto be split into valid sets of json after the run.\n\n.. option:: --section=name\n\n\tOnly run specified section `name` in job file.  Multiple sections can be specified.\n\tThe ``--section`` option allows one to combine related jobs into one file.\n\tE.g. one job file could define light, moderate, and heavy sections. Tell\n\tfio to run only the \"heavy\" section by giving ``--section=heavy``\n\tcommand line option.  One can also specify the \"write\" operations in one\n\tsection and \"verify\" operation in another section.  The ``--section`` option\n\tonly applies to job sections.  The reserved *global* section is always\n\tparsed and used.\n\n.. option:: --alloc-size=kb\n\n\tAllocate additional internal smalloc pools of size `kb` in KiB.  The\n\t``--alloc-size`` option increases shared memory set aside for use by fio.\n\tIf running large jobs with randommap enabled, fio can run out of memory.\n\tSmalloc is an internal allocator for shared structures from a fixed size\n\tmemory pool and can grow to 16 pools. The pool size defaults to 16MiB.\n\n\tNOTE: While running :file:`.fio_smalloc.*` backing store files are visible\n\tin :file:`/tmp`.\n\n.. option:: --warnings-fatal\n\n\tAll fio parser warnings are fatal, causing fio to exit with an\n\terror.\n\n.. option:: --max-jobs=nr\n\n\tSet the maximum number of threads/processes to support to `nr`.\n\tNOTE: On Linux, it may be necessary to increase the shared-memory\n\tlimit (:file:`/proc/sys/kernel/shmmax`) if fio runs into errors while\n\tcreating jobs.\n\n.. option:: --server=args\n\n\tStart a backend server, with `args` specifying what to listen to.\n\tSee `Client/Server`_ section.\n\n.. option:: --daemonize=pidfile\n\n\tBackground a fio server, writing the pid to the given `pidfile` file.\n\n.. option:: --client=hostname\n\n\tInstead of running the jobs locally, send and run them on the given `hostname`\n\tor set of `hostname`\\s.  See `Client/Server`_ section.\n\n.. option:: --remote-config=file\n\n\tTell fio server to load this local `file`.\n\n.. option:: --idle-prof=option\n\n\tReport CPU idleness. `option` is one of the following:\n\n\t\t**calibrate**\n\t\t\tRun unit work calibration only and exit.\n\n\t\t**system**\n\t\t\tShow aggregate system idleness and unit work.\n\n\t\t**percpu**\n\t\t\tAs **system** but also show per CPU idleness.\n\n.. option:: --inflate-log=log\n\n\tInflate and output compressed `log`.\n\n.. option:: --trigger-file=file\n\n\tExecute trigger command when `file` exists.\n\n.. option:: --trigger-timeout=time\n\n\tExecute trigger at this `time`.\n\n.. option:: --trigger=command\n\n\tSet this `command` as local trigger.\n\n.. option:: --trigger-remote=command\n\n\tSet this `command` as remote trigger.\n\n.. option:: --aux-path=path\n\n\tUse the directory specified by `path` for generated state files instead\n\tof the current working directory.\n\nAny parameters following the options will be assumed to be job files, unless\nthey match a job file parameter. Multiple job files can be listed and each job\nfile will be regarded as a separate group. Fio will :option:`stonewall`\nexecution between each group.\n\n\nJob file format\n---------------\n\nAs previously described, fio accepts one or more job files describing what it is\nsupposed to do. The job file format is the classic ini file, where the names\nenclosed in [] brackets define the job name. You are free to use any ASCII name\nyou want, except *global* which has special meaning.  Following the job name is\na sequence of zero or more parameters, one per line, that define the behavior of\nthe job. If the first character in a line is a ';' or a '#', the entire line is\ndiscarded as a comment.\n\nA *global* section sets defaults for the jobs described in that file. A job may\noverride a *global* section parameter, and a job file may even have several\n*global* sections if so desired. A job is only affected by a *global* section\nresiding above it.\n\nThe :option:`--cmdhelp` option also lists all options. If used with a `command`\nargument, :option:`--cmdhelp` will detail the given `command`.\n\nSee the `examples/` directory for inspiration on how to write job files.  Note\nthe copyright and license requirements currently apply to `examples/` files.\n\nSo let's look at a really simple job file that defines two processes, each\nrandomly reading from a 128MiB file:\n\n.. code-block:: ini\n\n    ; -- start job file --\n    [global]\n    rw=randread\n    size=128m\n\n    [job1]\n\n    [job2]\n\n    ; -- end job file --\n\nAs you can see, the job file sections themselves are empty as all the described\nparameters are shared. As no :option:`filename` option is given, fio makes up a\n`filename` for each of the jobs as it sees fit. On the command line, this job\nwould look as follows::\n\n$ fio --name=global --rw=randread --size=128m --name=job1 --name=job2\n\n\nLet's look at an example that has a number of processes writing randomly to\nfiles:\n\n.. code-block:: ini\n\n    ; -- start job file --\n    [random-writers]\n    ioengine=libaio\n    iodepth=4\n    rw=randwrite\n    bs=32k\n    direct=0\n    size=64m\n    numjobs=4\n    ; -- end job file --\n\nHere we have no *global* section, as we only have one job defined anyway.  We\nwant to use async I/O here, with a depth of 4 for each file. We also increased\nthe buffer size used to 32KiB and define numjobs to 4 to fork 4 identical\njobs. The result is 4 processes each randomly writing to their own 64MiB\nfile. Instead of using the above job file, you could have given the parameters\non the command line. For this case, you would specify::\n\n$ fio --name=random-writers --ioengine=libaio --iodepth=4 --rw=randwrite --bs=32k --direct=0 --size=64m --numjobs=4\n\nWhen fio is utilized as a basis of any reasonably large test suite, it might be\ndesirable to share a set of standardized settings across multiple job files.\nInstead of copy/pasting such settings, any section may pull in an external\n:file:`filename.fio` file with *include filename* directive, as in the following\nexample::\n\n    ; -- start job file including.fio --\n    [global]\n    filename=/tmp/test\n    filesize=1m\n    include glob-include.fio\n\n    [test]\n    rw=randread\n    bs=4k\n    time_based=1\n    runtime=10\n    include test-include.fio\n    ; -- end job file including.fio --\n\n.. code-block:: ini\n\n    ; -- start job file glob-include.fio --\n    thread=1\n    group_reporting=1\n    ; -- end job file glob-include.fio --\n\n.. code-block:: ini\n\n    ; -- start job file test-include.fio --\n    ioengine=libaio\n    iodepth=4\n    ; -- end job file test-include.fio --\n\nSettings pulled into a section apply to that section only (except *global*\nsection). Include directives may be nested in that any included file may contain\nfurther include directive(s). Include files may not contain [] sections.\n\n\nEnvironment variables\n~~~~~~~~~~~~~~~~~~~~~\n\nFio also supports environment variable expansion in job files. Any sub-string of\nthe form ``${VARNAME}`` as part of an option value (in other words, on the right\nof the '='), will be expanded to the value of the environment variable called\n`VARNAME`.  If no such environment variable is defined, or `VARNAME` is the\nempty string, the empty string will be substituted.\n\nAs an example, let's look at a sample fio invocation and job file::\n\n$ SIZE=64m NUMJOBS=4 fio jobfile.fio\n\n.. code-block:: ini\n\n    ; -- start job file --\n    [random-writers]\n    rw=randwrite\n    size=${SIZE}\n    numjobs=${NUMJOBS}\n    ; -- end job file --\n\nThis will expand to the following equivalent job file at runtime:\n\n.. code-block:: ini\n\n    ; -- start job file --\n    [random-writers]\n    rw=randwrite\n    size=64m\n    numjobs=4\n    ; -- end job file --\n\nFio ships with a few example job files, you can also look there for inspiration.\n\nReserved keywords\n~~~~~~~~~~~~~~~~~\n\nAdditionally, fio has a set of reserved keywords that will be replaced\ninternally with the appropriate value. Those keywords are:\n\n**$pagesize**\n\n\tThe architecture page size of the running system.\n\n**$mb_memory**\n\n\tMegabytes of total memory in the system.\n\n**$ncpus**\n\n\tNumber of online available CPUs.\n\nThese can be used on the command line or in the job file, and will be\nautomatically substituted with the current system values when the job is\nrun. Simple math is also supported on these keywords, so you can perform actions\nlike::\n\n\tsize=8*$mb_memory\n\nand get that properly expanded to 8 times the size of memory in the machine.\n\n\nJob file parameters\n-------------------\n\nThis section describes in details each parameter associated with a job.  Some\nparameters take an option of a given type, such as an integer or a\nstring. Anywhere a numeric value is required, an arithmetic expression may be\nused, provided it is surrounded by parentheses. Supported operators are:\n\n\t- addition (+)\n\t- subtraction (-)\n\t- multiplication (*)\n\t- division (/)\n\t- modulus (%)\n\t- exponentiation (^)\n\nFor time values in expressions, units are microseconds by default. This is\ndifferent than for time values not in expressions (not enclosed in\nparentheses). The following types are used:\n\n\nParameter types\n~~~~~~~~~~~~~~~\n\n**str**\n\tString: A sequence of alphanumeric characters.\n\n**time**\n\tInteger with possible time suffix.  Without a unit value is interpreted as\n\tseconds unless otherwise specified.  Accepts a suffix of 'd' for days, 'h' for\n\thours, 'm' for minutes, 's' for seconds, 'ms' (or 'msec') for milliseconds and\n\t'us' (or 'usec') for microseconds.  For example, use 10m for 10 minutes.\n\n.. _int:\n\n**int**\n\tInteger. A whole number value, which may contain an integer prefix\n\tand an integer suffix:\n\n\t[*integer prefix*] **number** [*integer suffix*]\n\n\tThe optional *integer prefix* specifies the number's base. The default\n\tis decimal. *0x* specifies hexadecimal.\n\n\tThe optional *integer suffix* specifies the number's units, and includes an\n\toptional unit prefix and an optional unit.  For quantities of data, the\n\tdefault unit is bytes. For quantities of time, the default unit is seconds\n\tunless otherwise specified.\n\n\tWith :option:`kb_base`\\=1000, fio follows international standards for unit\n\tprefixes.  To specify power-of-10 decimal values defined in the\n\tInternational System of Units (SI):\n\n\t\t* *K* -- means kilo (K) or 1000\n\t\t* *M* -- means mega (M) or 1000**2\n\t\t* *G* -- means giga (G) or 1000**3\n\t\t* *T* -- means tera (T) or 1000**4\n\t\t* *P* -- means peta (P) or 1000**5\n\n\tTo specify power-of-2 binary values defined in IEC 80000-13:\n\n\t\t* *Ki* -- means kibi (Ki) or 1024\n\t\t* *Mi* -- means mebi (Mi) or 1024**2\n\t\t* *Gi* -- means gibi (Gi) or 1024**3\n\t\t* *Ti* -- means tebi (Ti) or 1024**4\n\t\t* *Pi* -- means pebi (Pi) or 1024**5\n\n\tFor Zone Block Device Mode:\n\t        * *z*  -- means Zone\n\n\tWith :option:`kb_base`\\=1024 (the default), the unit prefixes are opposite\n\tfrom those specified in the SI and IEC 80000-13 standards to provide\n\tcompatibility with old scripts.  For example, 4k means 4096.\n\n\tFor quantities of data, an optional unit of 'B' may be included\n\t(e.g., 'kB' is the same as 'k').\n\n\tThe *integer suffix* is not case sensitive (e.g., m/mi mean mebi/mega,\n\tnot milli). 'b' and 'B' both mean byte, not bit.\n\n\tExamples with :option:`kb_base`\\=1000:\n\n\t\t* *4 KiB*: 4096, 4096b, 4096B, 4ki, 4kib, 4kiB, 4Ki, 4KiB\n\t\t* *1 MiB*: 1048576, 1mi, 1024ki\n\t\t* *1 MB*: 1000000, 1m, 1000k\n\t\t* *1 TiB*: 1099511627776, 1ti, 1024gi, 1048576mi\n\t\t* *1 TB*: 1000000000, 1t, 1000m, 1000000k\n\n\tExamples with :option:`kb_base`\\=1024 (default):\n\n\t\t* *4 KiB*: 4096, 4096b, 4096B, 4k, 4kb, 4kB, 4K, 4KB\n\t\t* *1 MiB*: 1048576, 1m, 1024k\n\t\t* *1 MB*: 1000000, 1mi, 1000ki\n\t\t* *1 TiB*: 1099511627776, 1t, 1024g, 1048576m\n\t\t* *1 TB*: 1000000000, 1ti, 1000mi, 1000000ki\n\n\tTo specify times (units are not case sensitive):\n\n\t\t* *D* -- means days\n\t\t* *H* -- means hours\n\t\t* *M* -- means minutes\n\t\t* *s* -- or sec means seconds (default)\n\t\t* *ms* -- or *msec* means milliseconds\n\t\t* *us* -- or *usec* means microseconds\n\n\tIf the option accepts an upper and lower range, use a colon ':' or\n\tminus '-' to separate such values. See :ref:`irange <irange>`.\n\tIf the lower value specified happens to be larger than the upper value\n\tthe two values are swapped.\n\n.. _bool:\n\n**bool**\n\tBoolean. Usually parsed as an integer, however only defined for\n\ttrue and false (1 and 0).\n\n.. _irange:\n\n**irange**\n\tInteger range with suffix. Allows value range to be given, such as\n\t1024-4096. A colon may also be used as the separator, e.g. 1k:4k. If the\n\toption allows two sets of ranges, they can be specified with a ',' or '/'\n\tdelimiter: 1k-4k/8k-32k. Also see :ref:`int <int>`.\n\n**float_list**\n\tA list of floating point numbers, separated by a ':' character.\n\nWith the above in mind, here follows the complete list of fio job parameters.\n\n\nUnits\n~~~~~\n\n.. option:: kb_base=int\n\n\tSelect the interpretation of unit prefixes in input parameters.\n\n\t\t**1000**\n\t\t\tInputs comply with IEC 80000-13 and the International\n\t\t\tSystem of Units (SI). Use:\n\n\t\t\t\t- power-of-2 values with IEC prefixes (e.g., KiB)\n\t\t\t\t- power-of-10 values with SI prefixes (e.g., kB)\n\n\t\t**1024**\n\t\t\tCompatibility mode (default).  To avoid breaking old scripts:\n\n\t\t\t\t- power-of-2 values with SI prefixes\n\t\t\t\t- power-of-10 values with IEC prefixes\n\n\tSee :option:`bs` for more details on input parameters.\n\n\tOutputs always use correct prefixes.  Most outputs include both\n\tside-by-side, like::\n\n\t\tbw=2383.3kB/s (2327.4KiB/s)\n\n\tIf only one value is reported, then kb_base selects the one to use:\n\n\t\t**1000** -- SI prefixes\n\n\t\t**1024** -- IEC prefixes\n\n.. option:: unit_base=int\n\n\tBase unit for reporting.  Allowed values are:\n\n\t**0**\n\t\tUse auto-detection (default).\n\t**8**\n\t\tByte based.\n\t**1**\n\t\tBit based.\n\n\nJob description\n~~~~~~~~~~~~~~~\n\n.. option:: name=str\n\n\tASCII name of the job. This may be used to override the name printed by fio\n\tfor this job. Otherwise the job name is used. On the command line this\n\tparameter has the special purpose of also signaling the start of a new job.\n\n.. option:: description=str\n\n\tText description of the job. Doesn't do anything except dump this text\n\tdescription when this job is run. It's not parsed.\n\n.. option:: loops=int\n\n\tRun the specified number of iterations of this job. Used to repeat the same\n\tworkload a given number of times. Defaults to 1.\n\n.. option:: numjobs=int\n\n\tCreate the specified number of clones of this job. Each clone of job\n\tis spawned as an independent thread or process. May be used to setup a\n\tlarger number of threads/processes doing the same thing. Each thread is\n\treported separately; to see statistics for all clones as a whole, use\n\t:option:`group_reporting` in conjunction with :option:`new_group`.\n\tSee :option:`--max-jobs`.  Default: 1.\n\n\nTime related parameters\n~~~~~~~~~~~~~~~~~~~~~~~\n\n.. option:: runtime=time\n\n\tLimit runtime. The test will run until it completes the configured I/O\n\tworkload or until it has run for this specified amount of time, whichever\n\toccurs first. It can be quite hard to determine for how long a specified\n\tjob will run, so this parameter is handy to cap the total runtime to a\n\tgiven time.  When the unit is omitted, the value is interpreted in\n\tseconds.\n\n.. option:: time_based\n\n\tIf set, fio will run for the duration of the :option:`runtime` specified\n\teven if the file(s) are completely read or written. It will simply loop over\n\tthe same workload as many times as the :option:`runtime` allows.\n\n.. option:: startdelay=irange(time)\n\n\tDelay the start of job for the specified amount of time.  Can be a single\n\tvalue or a range.  When given as a range, each thread will choose a value\n\trandomly from within the range.  Value is in seconds if a unit is omitted.\n\n.. option:: ramp_time=time\n\n\tIf set, fio will run the specified workload for this amount of time before\n\tlogging any performance numbers. Useful for letting performance settle\n\tbefore logging results, thus minimizing the runtime required for stable\n\tresults. Note that the ``ramp_time`` is considered lead in time for a job,\n\tthus it will increase the total runtime if a special timeout or\n\t:option:`runtime` is specified.  When the unit is omitted, the value is\n\tgiven in seconds.\n\n.. option:: clocksource=str\n\n\tUse the given clocksource as the base of timing. The supported options are:\n\n\t\t**gettimeofday**\n\t\t\t:manpage:`gettimeofday(2)`\n\n\t\t**clock_gettime**\n\t\t\t:manpage:`clock_gettime(2)`\n\n\t\t**cpu**\n\t\t\tInternal CPU clock source\n\n\tcpu is the preferred clocksource if it is reliable, as it is very fast (and\n\tfio is heavy on time calls). Fio will automatically use this clocksource if\n\tit's supported and considered reliable on the system it is running on,\n\tunless another clocksource is specifically set. For x86/x86-64 CPUs, this\n\tmeans supporting TSC Invariant.\n\n.. option:: gtod_reduce=bool\n\n\tEnable all of the :manpage:`gettimeofday(2)` reducing options\n\t(:option:`disable_clat`, :option:`disable_slat`, :option:`disable_bw_measurement`) plus\n\treduce precision of the timeout somewhat to really shrink the\n\t:manpage:`gettimeofday(2)` call count. With this option enabled, we only do\n\tabout 0.4% of the :manpage:`gettimeofday(2)` calls we would have done if all\n\ttime keeping was enabled.\n\n.. option:: gtod_cpu=int\n\n\tSometimes it's cheaper to dedicate a single thread of execution to just\n\tgetting the current time. Fio (and databases, for instance) are very\n\tintensive on :manpage:`gettimeofday(2)` calls. With this option, you can set\n\tone CPU aside for doing nothing but logging current time to a shared memory\n\tlocation. Then the other threads/processes that run I/O workloads need only\n\tcopy that segment, instead of entering the kernel with a\n\t:manpage:`gettimeofday(2)` call. The CPU set aside for doing these time\n\tcalls will be excluded from other uses. Fio will manually clear it from the\n\tCPU mask of other jobs.\n\n.. option:: job_start_clock_id=int\n\n        The clock_id passed to the call to `clock_gettime` used to record\n        job_start in the `json` output format. Default is 0, or CLOCK_REALTIME.\n\n\nTarget file/device\n~~~~~~~~~~~~~~~~~~\n\n.. option:: directory=str\n\n\tPrefix filenames with this directory. Used to place files in a different\n\tlocation than :file:`./`.  You can specify a number of directories by\n\tseparating the names with a ':' character. These directories will be\n\tassigned equally distributed to job clones created by :option:`numjobs` as\n\tlong as they are using generated filenames. If specific `filename(s)` are\n\tset fio will use the first listed directory, and thereby matching the\n\t`filename` semantic (which generates a file for each clone if not\n\tspecified, but lets all clones use the same file if set).\n\n\tSee the :option:`filename` option for information on how to escape \"``:``\"\n\tcharacters within the directory path itself.\n\n\tNote: To control the directory fio will use for internal state files\n\tuse :option:`--aux-path`.\n\n.. option:: filename=str\n\n\tFio normally makes up a `filename` based on the job name, thread number, and\n\tfile number (see :option:`filename_format`). If you want to share files\n\tbetween threads in a job or several\n\tjobs with fixed file paths, specify a `filename` for each of them to override\n\tthe default. If the ioengine is file based, you can specify a number of files\n\tby separating the names with a ':' colon. So if you wanted a job to open\n\t:file:`/dev/sda` and :file:`/dev/sdb` as the two working files, you would use\n\t``filename=/dev/sda:/dev/sdb``. This also means that whenever this option is\n\tspecified, :option:`nrfiles` is ignored. The size of regular files specified\n\tby this option will be :option:`size` divided by number of files unless an\n\texplicit size is specified by :option:`filesize`.\n\n\tEach colon in the wanted path must be escaped with a ``\\``\n\tcharacter.  For instance, if the path is :file:`/dev/dsk/foo@3,0:c` then you\n\twould use ``filename=/dev/dsk/foo@3,0\\:c`` and if the path is\n\t:file:`F:\\\\filename` then you would use ``filename=F\\:\\filename``.\n\n\tOn Windows, disk devices are accessed as :file:`\\\\\\\\.\\\\PhysicalDrive0` for\n\tthe first device, :file:`\\\\\\\\.\\\\PhysicalDrive1` for the second etc.\n\tNote: Windows and FreeBSD (refer to geom(4)) prevent write access to areas\n\tof the disk containing in-use data (e.g. filesystems).\n\n\tFor HTTP and S3 access, specify a valid URL path or S3 key, respectively.\n\tA filename for path-style S3 includes a bucket name (:file:`/bucket/k/e.y`)\n\twhile a virtual-hosted-style S3 filename :file:`/k/e.y` does not because \n\tits bucket name is specified in :option:`http_host`.\n\n\tThe filename \"`-`\" is a reserved name, meaning *stdin* or *stdout*.  Which\n\tof the two depends on the read/write direction set.\n\n.. option:: filename_format=str\n\n\tIf sharing multiple files between jobs, it is usually necessary to have fio\n\tgenerate the exact names that you want. By default, fio will name a file\n\tbased on the default file format specification of\n\t:file:`jobname.jobnumber.filenumber`. With this option, that can be\n\tcustomized. Fio will recognize and replace the following keywords in this\n\tstring:\n\n\t\t**$jobname**\n\t\t\t\tThe name of the worker thread or process.\n\t\t**$clientuid**\n\t\t\t\tIP of the fio process when using client/server mode.\n\t\t**$jobnum**\n\t\t\t\tThe incremental number of the worker thread or process.\n\t\t**$filenum**\n\t\t\t\tThe incremental number of the file for that worker thread or\n\t\t\t\tprocess.\n\n\tTo have dependent jobs share a set of files, this option can be set to have\n\tfio generate filenames that are shared between the two. For instance, if\n\t:file:`testfiles.$filenum` is specified, file number 4 for any job will be\n\tnamed :file:`testfiles.4`. The default of :file:`$jobname.$jobnum.$filenum`\n\twill be used if no other format specifier is given.\n\n\tIf you specify a path then the directories will be created up to the\n\tmain directory for the file.  So for example if you specify\n\t``filename_format=a/b/c/$jobnum`` then the directories a/b/c will be\n\tcreated before the file setup part of the job.  If you specify\n\t:option:`directory` then the path will be relative that directory,\n\totherwise it is treated as the absolute path.\n\n.. option:: unique_filename=bool\n\n\tTo avoid collisions between networked clients, fio defaults to prefixing any\n\tgenerated filenames (with a directory specified) with the source of the\n\tclient connecting. To disable this behavior, set this option to 0.\n\n.. option:: opendir=str\n\n        Recursively open any files below directory `str`. This accepts only a\n        single directory and unlike related options, colons appearing in the\n        path must not be escaped.\n\n.. option:: lockfile=str\n\n\tFio defaults to not locking any files before it does I/O to them. If a file\n\tor file descriptor is shared, fio can serialize I/O to that file to make the\n\tend result consistent. This is usual for emulating real workloads that share\n\tfiles. The lock modes are:\n\n\t\t**none**\n\t\t\tNo locking. The default.\n\t\t**exclusive**\n\t\t\tOnly one thread or process may do I/O at a time, excluding all\n\t\t\tothers.\n\t\t**readwrite**\n\t\t\tRead-write locking on the file. Many readers may\n\t\t\taccess the file at the same time, but writes get exclusive access.\n\n.. option:: nrfiles=int\n\n\tNumber of files to use for this job. Defaults to 1. The size of files\n\twill be :option:`size` divided by this unless explicit size is specified by\n\t:option:`filesize`. Files are created for each thread separately, and each\n\tfile will have a file number within its name by default, as explained in\n\t:option:`filename` section.\n\n\n.. option:: openfiles=int\n\n\tNumber of files to keep open at the same time. Defaults to the same as\n\t:option:`nrfiles`, can be set smaller to limit the number simultaneous\n\topens.\n\n.. option:: file_service_type=str\n\n\tDefines how fio decides which file from a job to service next. The following\n\ttypes are defined:\n\n\t\t**random**\n\t\t\tChoose a file at random.\n\n\t\t**roundrobin**\n\t\t\tRound robin over opened files. This is the default.\n\n\t\t**sequential**\n\t\t\tFinish one file before moving on to the next. Multiple files can\n\t\t\tstill be open depending on :option:`openfiles`.\n\n\t\t**zipf**\n\t\t\tUse a *Zipf* distribution to decide what file to access.\n\n\t\t**pareto**\n\t\t\tUse a *Pareto* distribution to decide what file to access.\n\n\t\t**normal**\n\t\t\tUse a *Gaussian* (normal) distribution to decide what file to\n\t\t\taccess.\n\n\t\t**gauss**\n\t\t\tAlias for normal.\n\n\tFor *random*, *roundrobin*, and *sequential*, a postfix can be appended to\n\ttell fio how many I/Os to issue before switching to a new file. For example,\n\tspecifying ``file_service_type=random:8`` would cause fio to issue\n\t8 I/Os before selecting a new file at random. For the non-uniform\n\tdistributions, a floating point postfix can be given to influence how the\n\tdistribution is skewed. See :option:`random_distribution` for a description\n\tof how that would work.\n\n.. option:: ioscheduler=str\n\n\tAttempt to switch the device hosting the file to the specified I/O scheduler\n\tbefore running.\n\n.. option:: create_serialize=bool\n\n\tIf true, serialize the file creation for the jobs.  This may be handy to\n\tavoid interleaving of data files, which may greatly depend on the filesystem\n\tused and even the number of processors in the system.  Default: true.\n\n.. option:: create_fsync=bool\n\n\t:manpage:`fsync(2)` the data file after creation. This is the default.\n\n.. option:: create_on_open=bool\n\n\tIf true, don't pre-create files but allow the job's open() to create a file\n\twhen it's time to do I/O.  Default: false -- pre-create all necessary files\n\twhen the job starts.\n\n.. option:: create_only=bool\n\n\tIf true, fio will only run the setup phase of the job.  If files need to be\n\tlaid out or updated on disk, only that will be done -- the actual job contents\n\tare not executed.  Default: false.\n\n.. option:: allow_file_create=bool\n\n\tIf true, fio is permitted to create files as part of its workload.  If this\n\toption is false, then fio will error out if\n\tthe files it needs to use don't already exist. Default: true.\n\n.. option:: allow_mounted_write=bool\n\n\tIf this isn't set, fio will abort jobs that are destructive (e.g. that write)\n\tto what appears to be a mounted device or partition. This should help catch\n\tcreating inadvertently destructive tests, not realizing that the test will\n\tdestroy data on the mounted file system. Note that some platforms don't allow\n\twriting against a mounted device regardless of this option. Default: false.\n\n.. option:: pre_read=bool\n\n\tIf this is given, files will be pre-read into memory before starting the\n\tgiven I/O operation. This will also clear the :option:`invalidate` flag,\n\tsince it is pointless to pre-read and then drop the cache. This will only\n\twork for I/O engines that are seek-able, since they allow you to read the\n\tsame data multiple times. Thus it will not work on non-seekable I/O engines\n\t(e.g. network, splice). Default: false.\n\n.. option:: unlink=bool\n\n\tUnlink (delete) the job files when done. Not the default, as repeated runs of that\n\tjob would then waste time recreating the file set again and again. Default:\n\tfalse.\n\n.. option:: unlink_each_loop=bool\n\n\tUnlink (delete) job files after each iteration or loop.  Default: false.\n\n.. option:: zonemode=str\n\n\tAccepted values are:\n\n\t\t**none**\n\t\t\t\tThe :option:`zonerange`, :option:`zonesize`,\n\t\t\t\t:option:`zonecapacity` and :option:`zoneskip`\n\t\t\t\tparameters are ignored.\n\t\t**strided**\n\t\t\t\tI/O happens in a single zone until\n\t\t\t\t:option:`zonesize` bytes have been transferred.\n\t\t\t\tAfter that number of bytes has been\n\t\t\t\ttransferred processing of the next zone\n\t\t\t\tstarts. :option:`zonecapacity` is ignored.\n\t\t**zbd**\n\t\t\t\tZoned block device mode. I/O happens\n\t\t\t\tsequentially in each zone, even if random I/O\n\t\t\t\thas been selected. Random I/O happens across\n\t\t\t\tall zones instead of being restricted to a\n\t\t\t\tsingle zone. The :option:`zoneskip` parameter\n\t\t\t\tis ignored. :option:`zonerange` and\n\t\t\t\t:option:`zonesize` must be identical.\n\t\t\t\tTrim is handled using a zone reset operation.\n\t\t\t\tTrim only considers non-empty sequential write\n\t\t\t\trequired and sequential write preferred zones.\n\n.. option:: zonerange=int\n\n\tSize of a single zone. See also :option:`zonesize` and\n\t:option:`zoneskip`.\n\n.. option:: zonesize=int\n\n\tFor :option:`zonemode` =strided, this is the number of bytes to\n\ttransfer before skipping :option:`zoneskip` bytes. If this parameter\n\tis smaller than :option:`zonerange` then only a fraction of each zone\n\twith :option:`zonerange` bytes will be accessed.  If this parameter is\n\tlarger than :option:`zonerange` then each zone will be accessed\n\tmultiple times before skipping to the next zone.\n\n\tFor :option:`zonemode` =zbd, this is the size of a single zone. The\n\t:option:`zonerange` parameter is ignored in this mode.\n\n\n.. option:: zonecapacity=int\n\n\tFor :option:`zonemode` =zbd, this defines the capacity of a single zone,\n\twhich is the accessible area starting from the zone start address.\n\tThis parameter only applies when using :option:`zonemode` =zbd in\n\tcombination with regular block devices. If not specified it defaults to\n\tthe zone size. If the target device is a zoned block device, the zone\n\tcapacity is obtained from the device information and this option is\n\tignored.\n\n.. option:: zoneskip=int\n\n\tFor :option:`zonemode` =strided, the number of bytes to skip after\n\t:option:`zonesize` bytes of data have been transferred. This parameter\n\tmust be zero for :option:`zonemode` =zbd.\n\n.. option:: read_beyond_wp=bool\n\n\tThis parameter applies to :option:`zonemode` =zbd only.\n\n\tZoned block devices are block devices that consist of multiple zones.\n\tEach zone has a type, e.g. conventional or sequential. A conventional\n\tzone can be written at any offset that is a multiple of the block\n\tsize. Sequential zones must be written sequentially. The position at\n\twhich a write must occur is called the write pointer. A zoned block\n\tdevice can be either drive managed, host managed or host aware. For\n\thost managed devices the host must ensure that writes happen\n\tsequentially. Fio recognizes host managed devices and serializes\n\twrites to sequential zones for these devices.\n\n\tIf a read occurs in a sequential zone beyond the write pointer then\n\tthe zoned block device will complete the read without reading any data\n\tfrom the storage medium. Since such reads lead to unrealistically high\n\tbandwidth and IOPS numbers fio only reads beyond the write pointer if\n\texplicitly told to do so. Default: false.\n\n.. option:: max_open_zones=int\n\n\tWhen a zone of a zoned block device is partially written (i.e. not all\n\tsectors of the zone have been written), the zone is in one of three\n\tconditions: 'implicit open', 'explicit open' or 'closed'. Zoned block\n\tdevices may have a limit called 'max_open_zones' (same name as the\n\tparameter) on the total number of zones that can simultaneously be in\n\tthe 'implicit open' or 'explicit open' conditions. Zoned block devices\n\tmay have another limit called 'max_active_zones', on the total number of\n\tzones that can simultaneously be in the three conditions. The\n\t:option:`max_open_zones` parameter limits the number of zones to which\n\twrite commands are issued by all fio jobs, that is, limits the number of\n\tzones that will be in the conditions. When the device has the\n\tmax_open_zones limit and does not have the max_active_zones limit, the\n\t:option:`max_open_zones` parameter limits the number of zones in the two\n\topen conditions up to the limit. In this case, fio includes zones in the\n\ttwo open conditions to the write target zones at fio start. When the\n\tdevice has both the max_open_zones and the max_active_zones limits, the\n\t:option:`max_open_zones` parameter limits the number of zones in the\n\tthree conditions up to the limit. In this case, fio includes zones in\n\tthe three conditions to the write target zones at fio start.\n\n\tThis parameter is relevant only if the :option:`zonemode` =zbd is used.\n\tThe default value is always equal to the max_open_zones limit of the\n\ttarget zoned block device and a value higher than this limit cannot be\n\tspecified by users unless the option :option:`ignore_zone_limits` is\n\tspecified. When :option:`ignore_zone_limits` is specified or the target\n\tdevice does not have the max_open_zones limit, :option:`max_open_zones`\n\tcan specify 0 to disable any limit on the number of zones that can be\n\tsimultaneously written to by all jobs.\n\n.. option:: job_max_open_zones=int\n\n\tIn the same manner as :option:`max_open_zones`, limit the number of open\n\tzones per fio job, that is, the number of zones that a single job can\n\tsimultaneously write to. A value of zero indicates no limit.\n\tDefault: zero.\n\n.. option:: ignore_zone_limits=bool\n\n\tIf this option is used, fio will ignore the maximum number of open\n\tzones limit of the zoned block device in use, thus allowing the\n\toption :option:`max_open_zones` value to be larger than the device\n\treported limit. Default: false.\n\n.. option:: zone_reset_threshold=float\n\n\tA number between zero and one that indicates the ratio of written bytes\n\tin the zones with write pointers in the IO range to the size of the IO\n\trange. When current ratio is above this ratio, zones are reset\n\tperiodically as :option:`zone_reset_frequency` specifies. If there are\n\tmultiple jobs when using this option, the IO range for all write jobs\n\thas to be the same.\n\n.. option:: zone_reset_frequency=float\n\n\tA number between zero and one that indicates how often a zone reset\n\tshould be issued if the zone reset threshold has been exceeded. A zone\n\treset is submitted after each (1 / zone_reset_frequency) write\n\trequests. This and the previous parameter can be used to simulate\n\tgarbage collection activity.\n\n\nI/O type\n~~~~~~~~\n\n.. option:: direct=bool\n\n\tIf value is true, use non-buffered I/O. This is usually O_DIRECT. Note that\n\tOpenBSD and ZFS on Solaris don't support direct I/O.  On Windows the synchronous\n\tioengines don't support direct I/O.  Default: false.\n\n.. option:: buffered=bool\n\n\tIf value is true, use buffered I/O. This is the opposite of the\n\t:option:`direct` option. Defaults to true.\n\n.. option:: readwrite=str, rw=str\n\n\tType of I/O pattern. Accepted values are:\n\n\t\t**read**\n\t\t\t\tSequential reads.\n\t\t**write**\n\t\t\t\tSequential writes.\n\t\t**trim**\n\t\t\t\tSequential trims (Linux block devices and SCSI\n\t\t\t\tcharacter devices only).\n\t\t**randread**\n\t\t\t\tRandom reads.\n\t\t**randwrite**\n\t\t\t\tRandom writes.\n\t\t**randtrim**\n\t\t\t\tRandom trims (Linux block devices and SCSI\n\t\t\t\tcharacter devices only).\n\t\t**rw,readwrite**\n\t\t\t\tSequential mixed reads and writes.\n\t\t**randrw**\n\t\t\t\tRandom mixed reads and writes.\n\t\t**trimwrite**\n\t\t\t\tSequential trim+write sequences. Blocks will be trimmed first,\n\t\t\t\tthen the same blocks will be written to. So if ``io_size=64K``\n\t\t\t\tis specified, Fio will trim a total of 64K bytes and also\n\t\t\t\twrite 64K bytes on the same trimmed blocks. This behaviour\n\t\t\t\twill be consistent with ``number_ios`` or other Fio options\n\t\t\t\tlimiting the total bytes or number of I/O's.\n\t\t**randtrimwrite**\n\t\t\t\tLike trimwrite, but uses random offsets rather\n\t\t\t\tthan sequential writes.\n\n\tFio defaults to read if the option is not specified.  For the mixed I/O\n\ttypes, the default is to split them 50/50.  For certain types of I/O the\n\tresult may still be skewed a bit, since the speed may be different.\n\n\tIt is possible to specify the number of I/Os to do before getting a new\n\toffset by appending ``:<nr>`` to the end of the string given.  For a\n\trandom read, it would look like ``rw=randread:8`` for passing in an offset\n\tmodifier with a value of 8. If the suffix is used with a sequential I/O\n\tpattern, then the *<nr>* value specified will be **added** to the generated\n\toffset for each I/O turning sequential I/O into sequential I/O with holes.\n\tFor instance, using ``rw=write:4k`` will skip 4k for every write.  Also see\n\tthe :option:`rw_sequencer` option.\n\n.. option:: rw_sequencer=str\n\n\tIf an offset modifier is given by appending a number to the ``rw=<str>``\n\tline, then this option controls how that number modifies the I/O offset\n\tbeing generated. Accepted values are:\n\n\t\t**sequential**\n\t\t\tGenerate sequential offset.\n\t\t**identical**\n\t\t\tGenerate the same offset.\n\n\t``sequential`` is only useful for random I/O, where fio would normally\n\tgenerate a new random offset for every I/O. If you append e.g. 8 to\n\trandread, i.e. ``rw=randread:8`` you would get a new random offset for\n\tevery 8 I/Os. The result would be a sequence of 8 sequential offsets\n\twith a random starting point. However this behavior may change if a\n\tsequential I/O reaches end of the file. As sequential I/O is already\n\tsequential, setting ``sequential`` for that would not result in any\n\tdifference. ``identical`` behaves in a similar fashion, except it sends\n\tthe same offset 8 number of times before generating a new offset.\n\n\tExample #1::\n\n\t\trw=randread:8\n\t\trw_sequencer=sequential\n\t\tbs=4k\n\n\tThe generated sequence of offsets will look like this:\n\t4k, 8k, 12k, 16k, 20k, 24k, 28k, 32k, 92k, 96k, 100k, 104k, 108k,\n\t112k, 116k, 120k, 48k, 52k ...\n\n\tExample #2::\n\n\t\trw=randread:8\n\t\trw_sequencer=identical\n\t\tbs=4k\n\n\tThe generated sequence of offsets will look like this:\n\t4k, 4k, 4k, 4k, 4k, 4k, 4k, 4k, 92k, 92k, 92k, 92k, 92k, 92k, 92k, 92k,\n\t48k, 48k, 48k ...\n\n.. option:: unified_rw_reporting=str\n\n\tFio normally reports statistics on a per data direction basis, meaning that\n\treads, writes, and trims are accounted and reported separately. This option\n\tdetermines whether fio reports the results normally, summed together, or as\n\tboth options.\n\tAccepted values are:\n\n\t\t**none**\n\t\t\tNormal statistics reporting.\n\n\t\t**mixed**\n\t\t\tStatistics are summed per data direction and reported together.\n\n\t\t**both**\n\t\t\tStatistics are reported normally, followed by the mixed statistics.\n\n\t\t**0**\n\t\t\tBackward-compatible alias for **none**.\n\n\t\t**1**\n\t\t\tBackward-compatible alias for **mixed**.\n\n\t\t**2**\n\t\t\tAlias for **both**.\n\n.. option:: randrepeat=bool\n\n        Seed all random number generators in a predictable way so the pattern\n        is repeatable across runs. Default: true.\n\n.. option:: allrandrepeat=bool\n\n\tAlias for :option:`randrepeat`. Default: true.\n\n.. option:: randseed=int\n\n\tSeed the random number generators based on this seed value, to be able to\n\tcontrol what sequence of output is being generated.  If not set, the random\n\tsequence depends on the :option:`randrepeat` setting.\n\n.. option:: fallocate=str\n\n\tWhether pre-allocation is performed when laying down files.\n\tAccepted values are:\n\n\t\t**none**\n\t\t\tDo not pre-allocate space.\n\n\t\t**native**\n\t\t\tUse a platform's native pre-allocation call but fall back to\n\t\t\t**none** behavior if it fails/is not implemented.\n\n\t\t**posix**\n\t\t\tPre-allocate via :manpage:`posix_fallocate(3)`.\n\n\t\t**keep**\n\t\t\tPre-allocate via :manpage:`fallocate(2)` with\n\t\t\tFALLOC_FL_KEEP_SIZE set.\n\n\t\t**truncate**\n\t\t\tExtend file to final size via :manpage:`ftruncate(2)`\n\t\t\tinstead of allocating.\n\n\t\t**0**\n\t\t\tBackward-compatible alias for **none**.\n\n\t\t**1**\n\t\t\tBackward-compatible alias for **posix**.\n\n\tMay not be available on all supported platforms. **keep** is only available\n\ton Linux. If using ZFS on Solaris this cannot be set to **posix**\n\tbecause ZFS doesn't support pre-allocation. Default: **native** if any\n\tpre-allocation methods except **truncate** are available, **none** if not.\n\n\tNote that using **truncate** on Windows will interact surprisingly\n\twith non-sequential write patterns. When writing to a file that has\n\tbeen extended by setting the end-of-file information, Windows will\n\tbackfill the unwritten portion of the file up to that offset with\n\tzeroes before issuing the new write. This means that a single small\n\twrite to the end of an extended file will stall until the entire\n\tfile has been filled with zeroes.\n\n.. option:: fadvise_hint=str\n\n\tUse :manpage:`posix_fadvise(2)` or :manpage:`posix_fadvise(2)` to\n\tadvise the kernel on what I/O patterns are likely to be issued.\n\tAccepted values are:\n\n\t\t**0**\n\t\t\tBackwards-compatible hint for \"no hint\".\n\n\t\t**1**\n\t\t\tBackwards compatible hint for \"advise with fio workload type\". This\n\t\t\tuses **FADV_RANDOM** for a random workload, and **FADV_SEQUENTIAL**\n\t\t\tfor a sequential workload.\n\n\t\t**sequential**\n\t\t\tAdvise using **FADV_SEQUENTIAL**.\n\n\t\t**random**\n\t\t\tAdvise using **FADV_RANDOM**.\n\n\t\t**noreuse**\n\t\t\tAdvise using **FADV_NOREUSE**. This may be a no-op on older Linux\n\t\t\tkernels. Since Linux 6.3, it provides a hint to the LRU algorithm.\n\t\t\tSee the :manpage:`posix_fadvise(2)` man page.\n\n.. option:: write_hint=str\n\n\tUse :manpage:`fcntl(2)` to advise the kernel what life time to expect\n\tfrom a write. Only supported on Linux, as of version 4.13. Accepted\n\tvalues are:\n\n\t\t**none**\n\t\t\tNo particular life time associated with this file.\n\n\t\t**short**\n\t\t\tData written to this file has a short life time.\n\n\t\t**medium**\n\t\t\tData written to this file has a medium life time.\n\n\t\t**long**\n\t\t\tData written to this file has a long life time.\n\n\t\t**extreme**\n\t\t\tData written to this file has a very long life time.\n\n\tThe values are all relative to each other, and no absolute meaning\n\tshould be associated with them.\n\n.. option:: offset=int\n\n\tStart I/O at the provided offset in the file, given as either a fixed size in\n\tbytes, zones or a percentage. If a percentage is given, the generated offset will be\n\taligned to the minimum ``blocksize`` or to the value of ``offset_align`` if\n\tprovided. Data before the given offset will not be touched. This\n\teffectively caps the file size at `real_size - offset`. Can be combined with\n\t:option:`size` to constrain the start and end range of the I/O workload.\n\tA percentage can be specified by a number between 1 and 100 followed by '%',\n\tfor example, ``offset=20%`` to specify 20%. In ZBD mode, value can be set as\n        number of zones using 'z'.\n\n.. option:: offset_align=int\n\n\tIf set to non-zero value, the byte offset generated by a percentage ``offset``\n\tis aligned upwards to this value. Defaults to 0 meaning that a percentage\n\toffset is aligned to the minimum block size.\n\n.. option:: offset_increment=int\n\n\tIf this is provided, then the real offset becomes `offset + offset_increment\n\t* thread_number`, where the thread number is a counter that starts at 0 and\n\tis incremented for each sub-job (i.e. when :option:`numjobs` option is\n\tspecified). This option is useful if there are several jobs which are\n\tintended to operate on a file in parallel disjoint segments, with even\n\tspacing between the starting points. Percentages can be used for this option.\n\tIf a percentage is given, the generated offset will be aligned to the minimum\n\t``blocksize`` or to the value of ``offset_align`` if provided. In ZBD mode, value can\n        also be set as number of zones using 'z'.\n\n.. option:: number_ios=int\n\n\tFio will normally perform I/Os until it has exhausted the size of the region\n\tset by :option:`size`, or if it exhaust the allocated time (or hits an error\n\tcondition). With this setting, the range/size can be set independently of\n\tthe number of I/Os to perform. When fio reaches this number, it will exit\n\tnormally and report status. Note that this does not extend the amount of I/O\n\tthat will be done, it will only stop fio if this condition is met before\n\tother end-of-job criteria.\n\n.. option:: fsync=int\n\n\tIf writing to a file, issue an :manpage:`fsync(2)` (or its equivalent) of\n\tthe dirty data for every number of blocks given. For example, if you give 32\n\tas a parameter, fio will sync the file after every 32 writes issued. If fio is\n\tusing non-buffered I/O, we may not sync the file. The exception is the sg\n\tI/O engine, which synchronizes the disk cache anyway. Defaults to 0, which\n\tmeans fio does not periodically issue and wait for a sync to complete. Also\n\tsee :option:`end_fsync` and :option:`fsync_on_close`.\n\n.. option:: fdatasync=int\n\n\tLike :option:`fsync` but uses :manpage:`fdatasync(2)` to only sync data and\n\tnot metadata blocks. In Windows, DragonFlyBSD or OSX there is no\n\t:manpage:`fdatasync(2)` so this falls back to using :manpage:`fsync(2)`.\n\tDefaults to 0, which means fio does not periodically issue and wait for a\n\tdata-only sync to complete.\n\n.. option:: write_barrier=int\n\n\tMake every `N-th` write a barrier write.\n\n.. option:: sync_file_range=str:int\n\n\tUse :manpage:`sync_file_range(2)` for every `int` number of write\n\toperations. Fio will track range of writes that have happened since the last\n\t:manpage:`sync_file_range(2)` call. `str` can currently be one or more of:\n\n\t\t**wait_before**\n\t\t\tSYNC_FILE_RANGE_WAIT_BEFORE\n\t\t**write**\n\t\t\tSYNC_FILE_RANGE_WRITE\n\t\t**wait_after**\n\t\t\tSYNC_FILE_RANGE_WAIT_AFTER\n\n\tSo if you do ``sync_file_range=wait_before,write:8``, fio would use\n\t``SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE`` for every 8\n\twrites. Also see the :manpage:`sync_file_range(2)` man page.  This option is\n\tLinux specific.\n\n.. option:: overwrite=bool\n\n\tIf true, writes to a file will always overwrite existing data. If the file\n\tdoesn't already exist, it will be created before the write phase begins. If\n\tthe file exists and is large enough for the specified write phase, nothing\n\twill be done. Default: false.\n\n.. option:: end_fsync=bool\n\n\tIf true, :manpage:`fsync(2)` file contents when a write stage has completed.\n\tDefault: false.\n\n.. option:: fsync_on_close=bool\n\n\tIf true, fio will :manpage:`fsync(2)` a dirty file on close.  This differs\n\tfrom :option:`end_fsync` in that it will happen on every file close, not\n\tjust at the end of the job.  Default: false.\n\n.. option:: rwmixread=int\n\n\tPercentage of a mixed workload that should be reads. Default: 50.\n\n.. option:: rwmixwrite=int\n\n\tPercentage of a mixed workload that should be writes. If both\n\t:option:`rwmixread` and :option:`rwmixwrite` is given and the values do not\n\tadd up to 100%, the latter of the two will be used to override the\n\tfirst. This may interfere with a given rate setting, if fio is asked to\n\tlimit reads or writes to a certain rate.  If that is the case, then the\n\tdistribution may be skewed. Default: 50.\n\n.. option:: random_distribution=str:float[:float][,str:float][,str:float]\n\n\tBy default, fio will use a completely uniform random distribution when asked\n\tto perform random I/O. Sometimes it is useful to skew the distribution in\n\tspecific ways, ensuring that some parts of the data is more hot than others.\n\tfio includes the following distribution models:\n\n\t\t**random**\n\t\t\t\tUniform random distribution\n\n\t\t**zipf**\n\t\t\t\tZipf distribution\n\n\t\t**pareto**\n\t\t\t\tPareto distribution\n\n\t\t**normal**\n\t\t\t\tNormal (Gaussian) distribution\n\n\t\t**zoned**\n\t\t\t\tZoned random distribution\n\n\t\t**zoned_abs**\n\t\t\t\tZone absolute random distribution\n\n\tWhen using a **zipf** or **pareto** distribution, an input value is also\n\tneeded to define the access pattern. For **zipf**, this is the `Zipf\n\ttheta`. For **pareto**, it's the `Pareto power`. Fio includes a test\n\tprogram, :command:`fio-genzipf`, that can be used visualize what the given input\n\tvalues will yield in terms of hit rates.  If you wanted to use **zipf** with\n\ta `theta` of 1.2, you would use ``random_distribution=zipf:1.2`` as the\n\toption. If a non-uniform model is used, fio will disable use of the random\n\tmap. For the **normal** distribution, a normal (Gaussian) deviation is\n\tsupplied as a value between 0 and 100.\n\n\tThe second, optional float is allowed for **pareto**, **zipf** and **normal** distributions.\n\tIt allows one to set base of distribution in non-default place, giving more control\n\tover most probable outcome. This value is in range [0-1] which maps linearly to\n\trange of possible random values.\n\tDefaults are: random for **pareto** and **zipf**, and 0.5 for **normal**.\n\tIf you wanted to use **zipf** with a `theta` of 1.2 centered on 1/4 of allowed value range,\n\tyou would use ``random_distribution=zipf:1.2:0.25``.\n\n\tFor a **zoned** distribution, fio supports specifying percentages of I/O\n\taccess that should fall within what range of the file or device. For\n\texample, given a criteria of:\n\n\t\t* 60% of accesses should be to the first 10%\n\t\t* 30% of accesses should be to the next 20%\n\t\t* 8% of accesses should be to the next 30%\n\t\t* 2% of accesses should be to the next 40%\n\n\twe can define that through zoning of the random accesses. For the above\n\texample, the user would do::\n\n\t\trandom_distribution=zoned:60/10:30/20:8/30:2/40\n\n\tA **zoned_abs** distribution works exactly like the **zoned**, except\n\tthat it takes absolute sizes. For example, let's say you wanted to\n\tdefine access according to the following criteria:\n\n\t\t* 60% of accesses should be to the first 20G\n\t\t* 30% of accesses should be to the next 100G\n\t\t* 10% of accesses should be to the next 500G\n\n\twe can define an absolute zoning distribution with:\n\n\t\trandom_distribution=zoned_abs=60/20G:30/100G:10/500g\n\n\tFor both **zoned** and **zoned_abs**, fio supports defining up to\n\t256 separate zones.\n\n\tSimilarly to how :option:`bssplit` works for setting ranges and\n\tpercentages of block sizes. Like :option:`bssplit`, it's possible to\n\tspecify separate zones for reads, writes, and trims. If just one set\n\tis given, it'll apply to all of them. This goes for both **zoned**\n\t**zoned_abs** distributions.\n\n.. option:: percentage_random=int[,int][,int]\n\n\tFor a random workload, set how big a percentage should be random. This\n\tdefaults to 100%, in which case the workload is fully random. It can be set\n\tfrom anywhere from 0 to 100.  Setting it to 0 would make the workload fully\n\tsequential. Any setting in between will result in a random mix of sequential\n\tand random I/O, at the given percentages.  Comma-separated values may be\n\tspecified for reads, writes, and trims as described in :option:`blocksize`.\n\n.. option:: norandommap\n\n\tNormally fio will cover every block of the file when doing random I/O. If\n\tthis option is given, fio will just get a new random offset without looking\n\tat past I/O history. This means that some blocks may not be read or written,\n\tand that some blocks may be read/written more than once. If this option is\n\tused with :option:`verify` and multiple blocksizes (via :option:`bsrange`),\n\tonly intact blocks are verified, i.e., partially-overwritten blocks are\n\tignored.  With an async I/O engine and an I/O depth > 1, it is possible for\n\tthe same block to be overwritten, which can cause verification errors.  Either\n\tdo not use norandommap in this case, or also use the lfsr random generator.\n\n.. option:: softrandommap=bool\n\n\tSee :option:`norandommap`. If fio runs with the random block map enabled and\n\tit fails to allocate the map, if this option is set it will continue without\n\ta random block map. As coverage will not be as complete as with random maps,\n\tthis option is disabled by default.\n\n.. option:: random_generator=str\n\n\tFio supports the following engines for generating I/O offsets for random I/O:\n\n\t\t**tausworthe**\n\t\t\tStrong 2^88 cycle random number generator.\n\t\t**lfsr**\n\t\t\tLinear feedback shift register generator.\n\t\t**tausworthe64**\n\t\t\tStrong 64-bit 2^258 cycle random number generator.\n\n\t**tausworthe** is a strong random number generator, but it requires tracking\n\ton the side if we want to ensure that blocks are only read or written\n\tonce. **lfsr** guarantees that we never generate the same offset twice, and\n\tit's also less computationally expensive. It's not a true random generator,\n\thowever, though for I/O purposes it's typically good enough. **lfsr** only\n\tworks with single block sizes, not with workloads that use multiple block\n\tsizes. If used with such a workload, fio may read or write some blocks\n\tmultiple times. The default value is **tausworthe**, unless the required\n\tspace exceeds 2^32 blocks. If it does, then **tausworthe64** is\n\tselected automatically.\n\n\nBlock size\n~~~~~~~~~~\n\n.. option:: blocksize=int[,int][,int], bs=int[,int][,int]\n\n\tThe block size in bytes used for I/O units. Default: 4096.  A single value\n\tapplies to reads, writes, and trims.  Comma-separated values may be\n\tspecified for reads, writes, and trims.  A value not terminated in a comma\n\tapplies to subsequent types.\n\n\tExamples:\n\n\t\t**bs=256k**\n\t\t\tmeans 256k for reads, writes and trims.\n\n\t\t**bs=8k,32k**\n\t\t\tmeans 8k for reads, 32k for writes and trims.\n\n\t\t**bs=8k,32k,**\n\t\t\tmeans 8k for reads, 32k for writes, and default for trims.\n\n\t\t**bs=,8k**\n\t\t\tmeans default for reads, 8k for writes and trims.\n\n\t\t**bs=,8k,**\n\t\t\tmeans default for reads, 8k for writes, and default for trims.\n\n.. option:: blocksize_range=irange[,irange][,irange], bsrange=irange[,irange][,irange]\n\n\tA range of block sizes in bytes for I/O units.  The issued I/O unit will\n\talways be a multiple of the minimum size, unless\n\t:option:`blocksize_unaligned` is set.\n\n\tComma-separated ranges may be specified for reads, writes, and trims as\n\tdescribed in :option:`blocksize`.\n\n\tExample: ``bsrange=1k-4k,2k-8k`` also the ':' delimiter ``bsrange=1k:4k,2k:8k``.\n\n.. option:: bssplit=str[,str][,str]\n\n\tSometimes you want even finer grained control of the block sizes\n\tissued, not just an even split between them.  This option allows you to\n\tweight various block sizes, so that you are able to define a specific\n\tamount of block sizes issued. The format for this option is::\n\n\t\tbssplit=blocksize/percentage:blocksize/percentage\n\n\tfor as many block sizes as needed. So if you want to define a workload\n\tthat has 50% 64k blocks, 10% 4k blocks, and 40% 32k blocks, you would\n\twrite::\n\n\t\tbssplit=4k/10:64k/50:32k/40\n\n\tOrdering does not matter. If the percentage is left blank, fio will\n\tfill in the remaining values evenly. So a bssplit option like this one::\n\n\t\tbssplit=4k/50:1k/:32k/\n\n\twould have 50% 4k ios, and 25% 1k and 32k ios. The percentages always\n\tadd up to 100, if bssplit is given a range that adds up to more, it\n\twill error out.\n\n\tComma-separated values may be specified for reads, writes, and trims as\n\tdescribed in :option:`blocksize`.\n\n\tIf you want a workload that has 50% 2k reads and 50% 4k reads, while\n\thaving 90% 4k writes and 10% 8k writes, you would specify::\n\n\t\tbssplit=2k/50:4k/50,4k/90:8k/10\n\n\tFio supports defining up to 64 different weights for each data\n\tdirection.\n\n.. option:: blocksize_unaligned, bs_unaligned\n\n\tIf set, fio will issue I/O units with any size within\n\t:option:`blocksize_range`, not just multiples of the minimum size.  This\n\ttypically won't work with direct I/O, as that normally requires sector\n\talignment.\n\n.. option:: bs_is_seq_rand=bool\n\n\tIf this option is set, fio will use the normal read,write blocksize settings\n\tas sequential,random blocksize settings instead. Any random read or write\n\twill use the WRITE blocksize settings, and any sequential read or write will\n\tuse the READ blocksize settings.\n\n.. option:: blockalign=int[,int][,int], ba=int[,int][,int]\n\n\tBoundary to which fio will align random I/O units.  Default:\n\t:option:`blocksize`.  Minimum alignment is typically 512b for using direct\n\tI/O, though it usually depends on the hardware block size. This option is\n\tmutually exclusive with using a random map for files, so it will turn off\n\tthat option.  Comma-separated values may be specified for reads, writes, and\n\ttrims as described in :option:`blocksize`.\n\n\nBuffers and memory\n~~~~~~~~~~~~~~~~~~\n\n.. option:: zero_buffers\n\n\tInitialize buffers with all zeros. Default: fill buffers with random data.\n\n.. option:: refill_buffers\n\n\tIf this option is given, fio will refill the I/O buffers on every\n\tsubmit. Only makes sense if :option:`zero_buffers` isn't specified,\n\tnaturally. Defaults to being unset i.e., the buffer is only filled at\n\tinit time and the data in it is reused when possible but if any of\n\t:option:`verify`, :option:`buffer_compress_percentage` or\n\t:option:`dedupe_percentage` are enabled then `refill_buffers` is also\n\tautomatically enabled.\n\n.. option:: scramble_buffers=bool\n\n\tIf :option:`refill_buffers` is too costly and the target is using data\n\tdeduplication, then setting this option will slightly modify the I/O buffer\n\tcontents to defeat normal de-dupe attempts. This is not enough to defeat\n\tmore clever block compression attempts, but it will stop naive dedupe of\n\tblocks. Default: true.\n\n.. option:: buffer_compress_percentage=int\n\n\tIf this is set, then fio will attempt to provide I/O buffer content\n\t(on WRITEs) that compresses to the specified level. Fio does this by\n\tproviding a mix of random data followed by fixed pattern data. The\n\tfixed pattern is either zeros, or the pattern specified by\n\t:option:`buffer_pattern`. If the `buffer_pattern` option is used, it\n\tmight skew the compression ratio slightly. Setting\n\t`buffer_compress_percentage` to a value other than 100 will also\n\tenable :option:`refill_buffers` in order to reduce the likelihood that\n\tadjacent blocks are so similar that they over compress when seen\n\ttogether. See :option:`buffer_compress_chunk` for how to set a finer or\n\tcoarser granularity for the random/fixed data region. Defaults to unset\n\ti.e., buffer data will not adhere to any compression level.\n\n.. option:: buffer_compress_chunk=int\n\n\tThis setting allows fio to manage how big the random/fixed data region\n\tis when using :option:`buffer_compress_percentage`. When\n\t`buffer_compress_chunk` is set to some non-zero value smaller than the\n\tblock size, fio can repeat the random/fixed region throughout the I/O\n\tbuffer at the specified interval (which particularly useful when\n\tbigger block sizes are used for a job). When set to 0, fio will use a\n\tchunk size that matches the block size resulting in a single\n\trandom/fixed region within the I/O buffer. Defaults to 512. When the\n\tunit is omitted, the value is interpreted in bytes.\n\n.. option:: buffer_pattern=str\n\n\tIf set, fio will fill the I/O buffers with this pattern or with the contents\n\tof a file. If not set, the contents of I/O buffers are defined by the other\n\toptions related to buffer contents. The setting can be any pattern of bytes,\n\tand can be prefixed with 0x for hex values. It may also be a string, where\n\tthe string must then be wrapped with ``\"\"``. Or it may also be a filename,\n\twhere the filename must be wrapped with ``''`` in which case the file is\n\topened and read. Note that not all the file contents will be read if that\n\twould cause the buffers to overflow. So, for example::\n\n\t\tbuffer_pattern='filename'\n\n\tor::\n\n\t\tbuffer_pattern=\"abcd\"\n\n\tor::\n\n\t\tbuffer_pattern=-12\n\n\tor::\n\n\t\tbuffer_pattern=0xdeadface\n\n\tAlso you can combine everything together in any order::\n\n\t\tbuffer_pattern=0xdeadface\"abcd\"-12'filename'\n\n.. option:: dedupe_percentage=int\n\n\tIf set, fio will generate this percentage of identical buffers when\n\twriting. These buffers will be naturally dedupable. The contents of the\n\tbuffers depend on what other buffer compression settings have been set. It's\n\tpossible to have the individual buffers either fully compressible, or not at\n\tall -- this option only controls the distribution of unique buffers. Setting\n\tthis option will also enable :option:`refill_buffers` to prevent every buffer\n\tbeing identical.\n\n.. option:: dedupe_mode=str\n\n\tIf ``dedupe_percentage=<int>`` is given, then this option controls how fio\n\tgenerates the dedupe buffers.\n\n\t\t**repeat**\n\t\t\tGenerate dedupe buffers by repeating previous writes\n\t\t**working_set**\n\t\t\tGenerate dedupe buffers from working set\n\n\t``repeat`` is the default option for fio. Dedupe buffers are generated\n\tby repeating previous unique write.\n\n\t``working_set`` is a more realistic workload.\n\tWith ``working_set``, ``dedupe_working_set_percentage=<int>`` should be provided.\n\tGiven that, fio will use the initial unique write buffers as its working set.\n\tUpon deciding to dedupe, fio will randomly choose a buffer from the working set.\n\tNote that by using ``working_set`` the dedupe percentage will converge\n\tto the desired over time while ``repeat`` maintains the desired percentage\n\tthroughout the job.\n\n.. option:: dedupe_working_set_percentage=int\n\n\tIf ``dedupe_mode=<str>`` is set to ``working_set``, then this controls\n\tthe percentage of size of the file or device used as the buffers\n\tfio will choose to generate the dedupe buffers from\n\n\tNote that size needs to be explicitly provided and only 1 file per\n\tjob is supported\n\n.. option:: dedupe_global=bool\n\n\tThis controls whether the deduplication buffers will be shared amongst\n\tall jobs that have this option set. The buffers are spread evenly between\n\tparticipating jobs.\n\n.. option:: invalidate=bool\n\n\tInvalidate the buffer/page cache parts of the files to be used prior to\n\tstarting I/O if the platform and file type support it.  Defaults to true.\n\tThis will be ignored if :option:`pre_read` is also specified for the\n\tsame job.\n\n.. option:: sync=str\n\n\tWhether, and what type, of synchronous I/O to use for writes.  The allowed\n\tvalues are:\n\n\t\t**none**\n\t\t\tDo not use synchronous IO, the default.\n\n\t\t**0**\n\t\t\tSame as **none**.\n\n\t\t**sync**\n\t\t\tUse synchronous file IO. For the majority of I/O engines,\n\t\t\tthis means using O_SYNC.\n\n\t\t**1**\n\t\t\tSame as **sync**.\n\n\t\t**dsync**\n\t\t\tUse synchronous data IO. For the majority of I/O engines,\n\t\t\tthis means using O_DSYNC.\n\n\n.. option:: iomem=str, mem=str\n\n\tFio can use various types of memory as the I/O unit buffer.  The allowed\n\tvalues are:\n\n\t\t**malloc**\n\t\t\tUse memory from :manpage:`malloc(3)` as the buffers.  Default memory\n\t\t\ttype.\n\n\t\t**shm**\n\t\t\tUse shared memory as the buffers. Allocated through\n\t\t\t:manpage:`shmget(2)`.\n\n\t\t**shmhuge**\n\t\t\tSame as shm, but use huge pages as backing.\n\n\t\t**mmap**\n\t\t\tUse :manpage:`mmap(2)` to allocate buffers. May either be anonymous memory, or can\n\t\t\tbe file backed if a filename is given after the option. The format\n\t\t\tis `mem=mmap:/path/to/file`.\n\n\t\t**mmaphuge**\n\t\t\tUse a memory mapped huge file as the buffer backing. Append filename\n\t\t\tafter mmaphuge, ala `mem=mmaphuge:/hugetlbfs/file`.\n\n\t\t**mmapshared**\n\t\t\tSame as mmap, but use a MMAP_SHARED mapping.\n\n\t\t**cudamalloc**\n\t\t\tUse GPU memory as the buffers for GPUDirect RDMA benchmark.\n\t\t\tThe :option:`ioengine` must be `rdma`.\n\n\tThe area allocated is a function of the maximum allowed bs size for the job,\n\tmultiplied by the I/O depth given. Note that for **shmhuge** and\n\t**mmaphuge** to work, the system must have free huge pages allocated. This\n\tcan normally be checked and set by reading/writing\n\t:file:`/proc/sys/vm/nr_hugepages` on a Linux system. Fio assumes a huge page\n        is 2 or 4MiB in size depending on the platform. So to calculate the\n        number of huge pages you need for a given job file, add up the I/O\n        depth of all jobs (normally one unless :option:`iodepth` is used) and\n        multiply by the maximum bs set. Then divide that number by the huge\n        page size. You can see the size of the huge pages in\n        :file:`/proc/meminfo`. If no huge pages are allocated by having a\n        non-zero number in `nr_hugepages`, using **mmaphuge** or **shmhuge**\n        will fail. Also see :option:`hugepage-size`.\n\n\t**mmaphuge** also needs to have hugetlbfs mounted and the file location\n\tshould point there. So if it's mounted in :file:`/huge`, you would use\n\t`mem=mmaphuge:/huge/somefile`.\n\n.. option:: iomem_align=int, mem_align=int\n\n\tThis indicates the memory alignment of the I/O memory buffers.  Note that\n\tthe given alignment is applied to the first I/O unit buffer, if using\n\t:option:`iodepth` the alignment of the following buffers are given by the\n\t:option:`bs` used. In other words, if using a :option:`bs` that is a\n\tmultiple of the page sized in the system, all buffers will be aligned to\n\tthis value. If using a :option:`bs` that is not page aligned, the alignment\n\tof subsequent I/O memory buffers is the sum of the :option:`iomem_align` and\n\t:option:`bs` used.\n\n.. option:: hugepage-size=int\n\n        Defines the size of a huge page. Must at least be equal to the system\n        setting, see :file:`/proc/meminfo` and\n        :file:`/sys/kernel/mm/hugepages/`. Defaults to 2 or 4MiB depending on\n        the platform.  Should probably always be a multiple of megabytes, so\n        using ``hugepage-size=Xm`` is the preferred way to set this to avoid\n        setting a non-pow-2 bad value.\n\n.. option:: lockmem=int\n\n\tPin the specified amount of memory with :manpage:`mlock(2)`. Can be used to\n\tsimulate a smaller amount of memory.  The amount specified is per worker.\n\n\nI/O size\n~~~~~~~~\n\n.. option:: size=int\n\n\tThe total size of file I/O for each thread of this job. Fio will run until\n\tthis many bytes has been transferred, unless runtime is altered by other means\n\tsuch as (1) :option:`runtime`, (2) :option:`io_size` (3) :option:`number_ios`,\n\t(4) gaps/holes while doing I/O's such as ``rw=read:16K``, or (5) sequential\n\tI/O reaching end of the file which is possible when :option:`percentage_random`\n\tis less than 100.\n\tFio will divide this size between the available files determined by options\n\tsuch as :option:`nrfiles`, :option:`filename`, unless :option:`filesize` is\n\tspecified by the job. If the result of division happens to be 0, the size is\n\tset to the physical size of the given files or devices if they exist.\n\tIf this option is not specified, fio will use the full size of the given\n\tfiles or devices.  If the files do not exist, size must be given. It is also\n\tpossible to give size as a percentage between 1 and 100. If ``size=20%`` is\n\tgiven, fio will use 20% of the full size of the given files or devices.\n\tIn ZBD mode, value can also be set as number of zones using 'z'.\n\tCan be combined with :option:`offset` to constrain the start and end range\n\tthat I/O will be done within.\n\n.. option:: io_size=int, io_limit=int\n\n\tNormally fio operates within the region set by :option:`size`, which means\n\tthat the :option:`size` option sets both the region and size of I/O to be\n\tperformed. Sometimes that is not what you want. With this option, it is\n\tpossible to define just the amount of I/O that fio should do. For instance,\n\tif :option:`size` is set to 20GiB and :option:`io_size` is set to 5GiB, fio\n\twill perform I/O within the first 20GiB but exit when 5GiB have been\n\tdone. The opposite is also possible -- if :option:`size` is set to 20GiB,\n\tand :option:`io_size` is set to 40GiB, then fio will do 40GiB of I/O within\n\tthe 0..20GiB region.\n\n.. option:: filesize=irange(int)\n\n\tIndividual file sizes. May be a range, in which case fio will select sizes for\n\tfiles at random within the given range. If not given, each created file is the\n\tsame size. This option overrides :option:`size` in terms of file size, i.e. if\n\t:option:`filesize` is specified then :option:`size` becomes merely the default\n\tfor :option:`io_size` and has no effect at all if :option:`io_size` is set\n\texplicitly.\n\n.. option:: file_append=bool\n\n\tPerform I/O after the end of the file. Normally fio will operate within the\n\tsize of a file. If this option is set, then fio will append to the file\n\tinstead. This has identical behavior to setting :option:`offset` to the size\n\tof a file.  This option is ignored on non-regular files.\n\n.. option:: fill_device=bool, fill_fs=bool\n\n\tSets size to something really large and waits for ENOSPC (no space left on\n\tdevice) or EDQUOT (disk quota exceeded)\n\tas the terminating condition. Only makes sense with sequential\n\twrite. For a read workload, the mount point will be filled first then I/O\n\tstarted on the result. This option doesn't make sense if operating on a raw\n\tdevice node, since the size of that is already known by the file system.\n\tAdditionally, writing beyond end-of-device will not return ENOSPC there.\n\n\nI/O engine\n~~~~~~~~~~\n\n.. option:: ioengine=str\n\n\tfio supports 2 kinds of performance measurement: I/O and file/directory operation.\n\n\tI/O engines define how the job issues I/O to the file. The following types are defined:\n\n\t\t**sync**\n\t\t\tBasic :manpage:`read(2)` or :manpage:`write(2)`\n\t\t\tI/O. :manpage:`lseek(2)` is used to position the I/O location.\n\t\t\tSee :option:`fsync` and :option:`fdatasync` for syncing write I/Os.\n\n\t\t**psync**\n\t\t\tBasic :manpage:`pread(2)` or :manpage:`pwrite(2)` I/O.  Default on\n\t\t\tall supported operating systems except for Windows.\n\n\t\t**vsync**\n\t\t\tBasic :manpage:`readv(2)` or :manpage:`writev(2)` I/O.  Will emulate\n\t\t\tqueuing by coalescing adjacent I/Os into a single submission.\n\n\t\t**pvsync**\n\t\t\tBasic :manpage:`preadv(2)` or :manpage:`pwritev(2)` I/O.\n\n\t\t**pvsync2**\n\t\t\tBasic :manpage:`preadv2(2)` or :manpage:`pwritev2(2)` I/O.\n\n\t\t**io_uring**\n\t\t\tFast Linux native asynchronous I/O. Supports async IO\n\t\t\tfor both direct and buffered IO.\n\t\t\tThis engine defines engine specific options.\n\n\t\t**io_uring_cmd**\n\t\t\tFast Linux native asynchronous I/O for pass through commands.\n\t\t\tThis engine defines engine specific options.\n\n\t\t**libaio**\n\t\t\tLinux native asynchronous I/O. Note that Linux may only support\n\t\t\tqueued behavior with non-buffered I/O (set ``direct=1`` or\n\t\t\t``buffered=0``).\n\t\t\tThis engine defines engine specific options.\n\n\t\t**posixaio**\n\t\t\tPOSIX asynchronous I/O using :manpage:`aio_read(3)` and\n\t\t\t:manpage:`aio_write(3)`.\n\n\t\t**solarisaio**\n\t\t\tSolaris native asynchronous I/O.\n\n\t\t**windowsaio**\n\t\t\tWindows native asynchronous I/O.  Default on Windows.\n\n\t\t**mmap**\n\t\t\tFile is memory mapped with :manpage:`mmap(2)` and data copied\n\t\t\tto/from using :manpage:`memcpy(3)`.\n\n\t\t**splice**\n\t\t\t:manpage:`splice(2)` is used to transfer the data and\n\t\t\t:manpage:`vmsplice(2)` to transfer data from user space to the\n\t\t\tkernel.\n\n\t\t**sg**\n\t\t\tSCSI generic sg v3 I/O. May either be synchronous using the SG_IO\n\t\t\tioctl, or if the target is an sg character device we use\n\t\t\t:manpage:`read(2)` and :manpage:`write(2)` for asynchronous\n\t\t\tI/O. Requires :option:`filename` option to specify either block or\n\t\t\tcharacter devices. This engine supports trim operations.\n\t\t\tThe sg engine includes engine specific options.\n\n\t\t**libzbc**\n\t\t\tRead, write, trim and ZBC/ZAC operations to a zoned\n\t\t\tblock device using libzbc library. The target can be\n\t\t\teither an SG character device or a block device file.\n\n\t\t**null**\n\t\t\tDoesn't transfer any data, just pretends to.  This is mainly used to\n\t\t\texercise fio itself and for debugging/testing purposes.\n\n\t\t**net**\n\t\t\tTransfer over the network to given ``host:port``.  Depending on the\n\t\t\t:option:`protocol` used, the :option:`hostname`, :option:`port`,\n\t\t\t:option:`listen` and :option:`filename` options are used to specify\n\t\t\twhat sort of connection to make, while the :option:`protocol` option\n\t\t\tdetermines which protocol will be used.  This engine defines engine\n\t\t\tspecific options.\n\n\t\t**netsplice**\n\t\t\tLike **net**, but uses :manpage:`splice(2)` and\n\t\t\t:manpage:`vmsplice(2)` to map data and send/receive.\n\t\t\tThis engine defines engine specific options.\n\n\t\t**cpuio**\n\t\t\tDoesn't transfer any data, but burns CPU cycles according to the\n\t\t\t:option:`cpuload`, :option:`cpuchunks` and :option:`cpumode` options.\n\t\t\tSetting :option:`cpuload`\\=85 will cause that job to do nothing but burn 85%\n\t\t\tof the CPU. In case of SMP machines, use :option:`numjobs`\\=<nr_of_cpu>\n\t\t\tto get desired CPU usage, as the cpuload only loads a\n\t\t\tsingle CPU at the desired rate. A job never finishes unless there is\n\t\t\tat least one non-cpuio job.\n\t\t\tSetting :option:`cpumode`\\=qsort replace the default noop instructions loop\n\t\t\tby a qsort algorithm to consume more energy.\n\n\t\t**rdma**\n\t\t\tThe RDMA I/O engine supports both RDMA memory semantics\n\t\t\t(RDMA_WRITE/RDMA_READ) and channel semantics (Send/Recv) for the\n\t\t\tInfiniBand, RoCE and iWARP protocols. This engine defines engine\n\t\t\tspecific options.\n\n\t\t**falloc**\n\t\t\tI/O engine that does regular fallocate to simulate data transfer as\n\t\t\tfio ioengine.\n\n\t\t\tDDIR_READ\n\t\t\t\tdoes fallocate(,mode = FALLOC_FL_KEEP_SIZE,).\n\n\t\t\tDDIR_WRITE\n\t\t\t\tdoes fallocate(,mode = 0).\n\n\t\t\tDDIR_TRIM\n\t\t\t\tdoes fallocate(,mode = FALLOC_FL_KEEP_SIZE|FALLOC_FL_PUNCH_HOLE).\n\n\t\t**ftruncate**\n\t\t\tI/O engine that sends :manpage:`ftruncate(2)` operations in response\n\t\t\tto write (DDIR_WRITE) events. Each ftruncate issued sets the file's\n\t\t\tsize to the current block offset. :option:`blocksize` is ignored.\n\n\t\t**e4defrag**\n\t\t\tI/O engine that does regular EXT4_IOC_MOVE_EXT ioctls to simulate\n\t\t\tdefragment activity in request to DDIR_WRITE event.\n\n\t\t**rados**\n\t\t\tI/O engine supporting direct access to Ceph Reliable Autonomic\n\t\t\tDistributed Object Store (RADOS) via librados. This ioengine\n\t\t\tdefines engine specific options.\n\n\t\t**rbd**\n\t\t\tI/O engine supporting direct access to Ceph Rados Block Devices\n\t\t\t(RBD) via librbd without the need to use the kernel rbd driver. This\n\t\t\tioengine defines engine specific options.\n\n\t\t**http**\n\t\t\tI/O engine supporting GET/PUT requests over HTTP(S) with libcurl to\n\t\t\ta WebDAV or S3 endpoint.  This ioengine defines engine specific options.\n\n\t\t\tThis engine only supports direct IO of iodepth=1; you need to scale this\n\t\t\tvia numjobs. blocksize defines the size of the objects to be created.\n\n\t\t\tTRIM is translated to object deletion.\n\n\t\t**gfapi**\n\t\t\tUsing GlusterFS libgfapi sync interface to direct access to\n\t\t\tGlusterFS volumes without having to go through FUSE.  This ioengine\n\t\t\tdefines engine specific options.\n\n\t\t**gfapi_async**\n\t\t\tUsing GlusterFS libgfapi async interface to direct access to\n\t\t\tGlusterFS volumes without having to go through FUSE. This ioengine\n\t\t\tdefines engine specific options.\n\n\t\t**libhdfs**\n\t\t\tRead and write through Hadoop (HDFS).  The :option:`filename` option\n\t\t\tis used to specify host,port of the hdfs name-node to connect.  This\n\t\t\tengine interprets offsets a little differently.  In HDFS, files once\n\t\t\tcreated cannot be modified so random writes are not possible. To\n\t\t\timitate this the libhdfs engine expects a bunch of small files to be\n\t\t\tcreated over HDFS and will randomly pick a file from them\n\t\t\tbased on the offset generated by fio backend (see the example\n\t\t\tjob file to create such files, use ``rw=write`` option). Please\n\t\t\tnote, it may be necessary to set environment variables to work\n\t\t\twith HDFS/libhdfs properly.  Each job uses its own connection to\n\t\t\tHDFS.\n\n\t\t**mtd**\n\t\t\tRead, write and erase an MTD character device (e.g.,\n\t\t\t:file:`/dev/mtd0`). Discards are treated as erases. Depending on the\n\t\t\tunderlying device type, the I/O may have to go in a certain pattern,\n\t\t\te.g., on NAND, writing sequentially to erase blocks and discarding\n\t\t\tbefore overwriting. The `trimwrite` mode works well for this\n\t\t\tconstraint.\n\n\t\t**dev-dax**\n\t\t\tRead and write using device DAX to a persistent memory device (e.g.,\n\t\t\t/dev/dax0.0) through the PMDK libpmem library.\n\n\t\t**external**\n\t\t\tPrefix to specify loading an external I/O engine object file. Append\n\t\t\tthe engine filename, e.g. ``ioengine=external:/tmp/foo.o`` to load\n\t\t\tioengine :file:`foo.o` in :file:`/tmp`. The path can be either\n\t\t\tabsolute or relative. See :file:`engines/skeleton_external.c` for\n\t\t\tdetails of writing an external I/O engine.\n\n\t\t**libpmem**\n\t\t\tRead and write using mmap I/O to a file on a filesystem\n\t\t\tmounted with DAX on a persistent memory device through the PMDK\n\t\t\tlibpmem library.\n\n\t\t**ime_psync**\n\t\t\tSynchronous read and write using DDN's Infinite Memory Engine (IME).\n\t\t\tThis engine is very basic and issues calls to IME whenever an IO is\n\t\t\tqueued.\n\n\t\t**ime_psyncv**\n\t\t\tSynchronous read and write using DDN's Infinite Memory Engine (IME).\n\t\t\tThis engine uses iovecs and will try to stack as much IOs as possible\n\t\t\t(if the IOs are \"contiguous\" and the IO depth is not exceeded)\n\t\t\tbefore issuing a call to IME.\n\n\t\t**ime_aio**\n\t\t\tAsynchronous read and write using DDN's Infinite Memory Engine (IME).\n\t\t\tThis engine will try to stack as much IOs as possible by creating\n\t\t\trequests for IME. FIO will then decide when to commit these requests.\n\n\t\t**libiscsi**\n\t\t\tRead and write iscsi lun with libiscsi.\n\n\t\t**nbd**\n\t\t\tRead and write a Network Block Device (NBD).\n\n\t\t**libcufile**\n\t\t\tI/O engine supporting libcufile synchronous access to nvidia-fs and a\n\t\t\tGPUDirect Storage-supported filesystem. This engine performs\n\t\t\tI/O without transferring buffers between user-space and the kernel,\n\t\t\tunless :option:`verify` is set or :option:`cuda_io` is `posix`.\n\t\t\t:option:`iomem` must not be `cudamalloc`. This ioengine defines\n\t\t\tengine specific options.\n\n\t\t**dfs**\n\t\t\tI/O engine supporting asynchronous read and write operations to the\n\t\t\tDAOS File System (DFS) via libdfs.\n\n\t\t**nfs**\n\t\t\tI/O engine supporting asynchronous read and write operations to\n\t\t\tNFS filesystems from userspace via libnfs. This is useful for\n\t\t\tachieving higher concurrency and thus throughput than is possible\n\t\t\tvia kernel NFS.\n\n\t\t**exec**\n\t\t\tExecute 3rd party tools. Could be used to perform monitoring during jobs runtime.\n\n\t\t**xnvme**\n\t\t\tI/O engine using the xNVMe C API, for NVMe devices. The xnvme engine provides\n\t\t\tflexibility to access GNU/Linux Kernel NVMe driver via libaio, IOCTLs, io_uring,\n\t\t\tthe SPDK NVMe driver, or your own custom NVMe driver. The xnvme engine includes\n\t\t\tengine specific options. (See https://xnvme.io).\n\n\t\t**libblkio**\n\t\t\tUse the libblkio library\n\t\t\t(https://gitlab.com/libblkio/libblkio). The specific\n\t\t\t*driver* to use must be set using\n\t\t\t:option:`libblkio_driver`. If\n\t\t\t:option:`mem`/:option:`iomem` is not specified, memory\n\t\t\tallocation is delegated to libblkio (and so is\n\t\t\tguaranteed to work with the selected *driver*). One\n\t\t\tlibblkio instance is used per process, so all jobs\n\t\t\tsetting option :option:`thread` will share a single\n\t\t\tinstance (with one queue per thread) and must specify\n\t\t\tcompatible options. Note that some drivers don't allow\n\t\t\tseveral instances to access the same device or file\n\t\t\tsimultaneously, but allow it for threads.\n\n\tFile/directory operation engines define how the job operates file or directory. The\n\tfollowing types are defined:\n\n\t\t**filecreate**\n\t\t\tSimply create the files and do no I/O to them.  You still need to\n\t\t\tset  `filesize` so that all the accounting still occurs, but no\n\t\t\tactual I/O will be done other than creating the file.\n\t\t\tExample job file: filecreate-ioengine.fio.\n\n\t\t**filestat**\n\t\t\tSimply do stat() and do no I/O to the file. You need to set 'filesize'\n\t\t\tand 'nrfiles', so that files will be created.\n\t\t\tThis engine is to measure file lookup and meta data access.\n\t\t\tExample job file: filestat-ioengine.fio.\n\n\t\t**filedelete**\n\t\t\tSimply delete the files by unlink() and do no I/O to them. You need to set 'filesize'\n\t\t\tand 'nrfiles', so that the files will be created.\n\t\t\tThis engine is to measure file delete.\n\t\t\tExample job file: filedelete-ioengine.fio.\n\n\t\t**dircreate**\n\t\t\tSimply create the directories and do no I/O to them.  You still need to\n\t\t\tset  `filesize` so that all the accounting still occurs, but no\n\t\t\tactual I/O will be done other than creating the directories.\n\t\t\tExample job file: dircreate-ioengine.fio.\n\n\t\t**dirstat**\n\t\t\tSimply do stat() and do no I/O to the directories. You need to set 'filesize'\n\t\t\tand 'nrfiles', so that directories will be created.\n\t\t\tThis engine is to measure directory lookup and meta data access.\n\t\t\tExample job file: dirstat-ioengine.fio.\n\n\t\t**dirdelete**\n\t\t\tSimply delete the directories by rmdir() and do no I/O to them. You need to set 'filesize'\n\t\t\tand 'nrfiles', so that the directories will be created.\n\t\t\tThis engine is to measure directory delete.\n\t\t\tExample job file: dirdelete-ioengine.fio.\n\n\t\tFor file and directory operation engines, there is no I/O throughput, then the\n\t\tstatistics data in report have different meanings. The meaningful output indexes are: 'iops' and 'clat'.\n\t\t'bw' is meaningless. Refer to section: \"Interpreting the output\" for more details.\n\n\nI/O engine specific parameters\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn addition, there are some parameters which are only valid when a specific\n:option:`ioengine` is in use. These are used identically to normal parameters,\nwith the caveat that when used on the command line, they must come after the\n:option:`ioengine` that defines them is selected.\n\n.. option:: cmdprio_percentage=int[,int] : [io_uring] [libaio]\n\n    Set the percentage of I/O that will be issued with the highest priority.\n    Default: 0. A single value applies to reads and writes. Comma-separated\n    values may be specified for reads and writes. For this option to be\n    effective, NCQ priority must be supported and enabled, and the :option:`direct`\n    option must be set. fio must also be run as the root user. Unlike\n    slat/clat/lat stats, which can be tracked and reported independently, per\n    priority stats only track and report a single type of latency. By default,\n    completion latency (clat) will be reported, if :option:`lat_percentiles` is\n    set, total latency (lat) will be reported.\n\n.. option:: cmdprio_class=int[,int] : [io_uring] [libaio]\n\n\tSet the I/O priority class to use for I/Os that must be issued with\n\ta priority when :option:`cmdprio_percentage` or\n\t:option:`cmdprio_bssplit` is set. If not specified when\n\t:option:`cmdprio_percentage` or :option:`cmdprio_bssplit` is set,\n\tthis defaults to the highest priority class. A single value applies\n\tto reads and writes. Comma-separated values may be specified for\n\treads and writes. See :manpage:`ionice(1)`. See also the\n\t:option:`prioclass` option.\n\n.. option:: cmdprio_hint=int[,int] : [io_uring] [libaio]\n\n\tSet the I/O priority hint to use for I/Os that must be issued with\n\ta priority when :option:`cmdprio_percentage` or\n\t:option:`cmdprio_bssplit` is set. If not specified when\n\t:option:`cmdprio_percentage` or :option:`cmdprio_bssplit` is set,\n\tthis defaults to 0 (no hint). A single value applies to reads and\n\twrites. Comma-separated values may be specified for reads and writes.\n\tSee also the :option:`priohint` option.\n\n.. option:: cmdprio=int[,int] : [io_uring] [libaio]\n\n\tSet the I/O priority value to use for I/Os that must be issued with\n\ta priority when :option:`cmdprio_percentage` or\n\t:option:`cmdprio_bssplit` is set. If not specified when\n\t:option:`cmdprio_percentage` or :option:`cmdprio_bssplit` is set,\n\tthis defaults to 0.\n\tLinux limits us to a positive value between 0 and 7, with 0 being the\n\thighest. A single value applies to reads and writes. Comma-separated\n\tvalues may be specified for reads and writes. See :manpage:`ionice(1)`.\n\tRefer to an appropriate manpage for other operating systems since\n\tmeaning of priority may differ. See also the :option:`prio` option.\n\n.. option:: cmdprio_bssplit=str[,str] : [io_uring] [libaio]\n\n\tTo get a finer control over I/O priority, this option allows\n\tspecifying the percentage of IOs that must have a priority set\n\tdepending on the block size of the IO. This option is useful only\n\twhen used together with the :option:`bssplit` option, that is,\n\tmultiple different block sizes are used for reads and writes.\n\n\tThe first accepted format for this option is the same as the format of\n\tthe :option:`bssplit` option:\n\n\t\tcmdprio_bssplit=blocksize/percentage:blocksize/percentage\n\n\tIn this case, each entry will use the priority class, priority hint\n\tand priority level defined by the options :option:`cmdprio_class`,\n        :option:`cmdprio` and :option:`cmdprio_hint` respectively.\n\n\tThe second accepted format for this option is:\n\n\t\tcmdprio_bssplit=blocksize/percentage/class/level:blocksize/percentage/class/level\n\n\tIn this case, the priority class and priority level is defined inside\n\teach entry. In comparison with the first accepted format, the second\n\taccepted format does not restrict all entries to have the same priority\n\tclass and priority level.\n\n\tThe third accepted format for this option is:\n\n\t\tcmdprio_bssplit=blocksize/percentage/class/level/hint:...\n\n\tThis is an extension of the second accepted format that allows one to\n\talso specify a priority hint.\n\n\tFor all formats, only the read and write data directions are supported,\n\tvalues for trim IOs are ignored. This option is mutually exclusive with\n\tthe :option:`cmdprio_percentage` option.\n\n.. option:: fixedbufs : [io_uring] [io_uring_cmd]\n\n\tIf fio is asked to do direct IO, then Linux will map pages for each\n\tIO call, and release them when IO is done. If this option is set, the\n\tpages are pre-mapped before IO is started. This eliminates the need to\n\tmap and release for each IO. This is more efficient, and reduces the\n\tIO latency as well.\n\n.. option:: nonvectored=int : [io_uring] [io_uring_cmd]\n\n\tWith this option, fio will use non-vectored read/write commands, where\n\taddress must contain the address directly. Default is -1.\n\n.. option:: force_async=int : [io_uring] [io_uring_cmd]\n\n\tNormal operation for io_uring is to try and issue an sqe as\n\tnon-blocking first, and if that fails, execute it in an async manner.\n\tWith this option set to N, then every N request fio will ask sqe to\n\tbe issued in an async manner. Default is 0.\n\n.. option:: registerfiles : [io_uring] [io_uring_cmd]\n\n\tWith this option, fio registers the set of files being used with the\n\tkernel. This avoids the overhead of managing file counts in the kernel,\n\tmaking the submission and completion part more lightweight. Required\n\tfor the below :option:`sqthread_poll` option.\n\n.. option:: sqthread_poll : [io_uring] [io_uring_cmd] [xnvme]\n\n\tNormally fio will submit IO by issuing a system call to notify the\n\tkernel of available items in the SQ ring. If this option is set, the\n\tact of submitting IO will be done by a polling thread in the kernel.\n\tThis frees up cycles for fio, at the cost of using more CPU in the\n\tsystem. As submission is just the time it takes to fill in the sqe\n\tentries and any syscall required to wake up the idle kernel thread,\n\tfio will not report submission latencies.\n\n.. option:: sqthread_poll_cpu=int : [io_uring] [io_uring_cmd]\n\n\tWhen :option:`sqthread_poll` is set, this option provides a way to\n\tdefine which CPU should be used for the polling thread.\n\n.. option:: cmd_type=str : [io_uring_cmd]\n\n\tSpecifies the type of uring passthrough command to be used. Supported\n\tvalue is nvme. Default is nvme.\n\n.. option:: hipri\n\n   [io_uring] [io_uring_cmd] [xnvme]\n\n        If this option is set, fio will attempt to use polled IO completions.\n        Normal IO completions generate interrupts to signal the completion of\n        IO, polled completions do not. Hence they are require active reaping\n        by the application. The benefits are more efficient IO for high IOPS\n        scenarios, and lower latencies for low queue depth IO.\n\n   [libblkio]\n\n\tUse poll queues. This is incompatible with\n\t:option:`libblkio_wait_mode=eventfd <libblkio_wait_mode>` and\n\t:option:`libblkio_force_enable_completion_eventfd`.\n\n   [pvsync2]\n\n\tSet RWF_HIPRI on I/O, indicating to the kernel that it's of higher priority\n\tthan normal.\n\n   [sg]\n\n\tIf this option is set, fio will attempt to use polled IO completions.\n\tThis will have a similar effect as (io_uring)hipri. Only SCSI READ and\n\tWRITE commands will have the SGV4_FLAG_HIPRI set (not UNMAP (trim) nor\n\tVERIFY). Older versions of the Linux sg driver that do not support\n\thipri will simply ignore this flag and do normal IO. The Linux SCSI\n\tLow Level Driver (LLD) that \"owns\" the device also needs to support\n\thipri (also known as iopoll and mq_poll). The MegaRAID driver is an\n\texample of a SCSI LLD. Default: clear (0) which does normal\n\t(interrupted based) IO.\n\n.. option:: userspace_reap : [libaio]\n\n\tNormally, with the libaio engine in use, fio will use the\n\t:manpage:`io_getevents(2)` system call to reap newly returned events.  With\n\tthis flag turned on, the AIO ring will be read directly from user-space to\n\treap events. The reaping mode is only enabled when polling for a minimum of\n\t0 events (e.g. when :option:`iodepth_batch_complete` `=0`).\n\n.. option:: hipri_percentage : [pvsync2]\n\n\tWhen hipri is set this determines the probability of a pvsync2 I/O being high\n\tpriority. The default is 100%.\n\n.. option:: nowait=bool : [pvsync2] [libaio] [io_uring] [io_uring_cmd]\n\n\tBy default if a request cannot be executed immediately (e.g. resource starvation,\n\twaiting on locks) it is queued and the initiating process will be blocked until\n\tthe required resource becomes free.\n\n\tThis option sets the RWF_NOWAIT flag (supported from the 4.14 Linux kernel) and\n\tthe call will return instantly with EAGAIN or a partial result rather than waiting.\n\n\tIt is useful to also use ignore_error=EAGAIN when using this option.\n\n\tNote: glibc 2.27, 2.28 have a bug in syscall wrappers preadv2, pwritev2.\n\tThey return EOPNOTSUP instead of EAGAIN.\n\n\tFor cached I/O, using this option usually means a request operates only with\n\tcached data. Currently the RWF_NOWAIT flag does not supported for cached write.\n\n\tFor direct I/O, requests will only succeed if cache invalidation isn't required,\n\tfile blocks are fully allocated and the disk request could be issued immediately.\n\n.. option:: atomic=bool : [pvsync2] [libaio] [io_uring]\n\n\tThis option means that writes are issued with torn-write protection, meaning\n\tthat for a power fail or kernel crash, all or none of the data from the write\n\twill be stored, but never a mix of old and new data. Torn-write protection is\n\talso known as atomic writes.\n\n\tThis option sets the RWF_ATOMIC flag (supported from the 6.11 Linux kernel) on\n\ta per-IO basis.\n\n\tWrites with RWF_ATOMIC set will be rejected by the kernel when the file does\n\tnot support torn-write protection. To learn a file's torn-write limits, issue\n\tstatx with STATX_WRITE_ATOMIC.\n\n.. option:: fdp=bool : [io_uring_cmd] [xnvme]\n\n\tEnable Flexible Data Placement mode for write commands.\n\n.. option:: dataplacement=str : [io_uring_cmd] [xnvme]\n\n        Specifies the data placement directive type to use for write commands.\n        The following types are supported:\n\n                **none**\n                        Do not use a data placement directive. This is the\n                        default.\n\n                **fdp**\n                        Use Flexible Data Placement directives for write\n                        commands. This is equivalent to specifying\n                        :option:`fdp` =1.\n\n               **streams**\n                        Use Streams directives for write commands.\n\n.. option:: plid_select=str, fdp_pli_select=str : [io_uring_cmd] [xnvme]\n\n\tDefines how fio decides which placement ID to use next. The following\n\ttypes are defined:\n\n\t\t**random**\n\t\t\tChoose a placement ID at random (uniform).\n\n\t\t**roundrobin**\n\t\t\tRound robin over available placement IDs. This is the\n\t\t\tdefault.\n\n\t\t**scheme**\n\t\t\tChoose a placement ID (index) based on the scheme file defined by\n\t\t\tthe option :option:`dp_scheme`.\n\n\tThe available placement ID (indices) are defined by the option :option:`fdp_pli`\n\tor :option:`plids` except for the case of **scheme**.\n\n.. option:: plids=str, fdp_pli=str : [io_uring_cmd] [xnvme]\n\n        Select which Placement ID Indices (FDP) or Placement IDs (streams) this\n        job is allowed to use for writes. This option accepts a comma-separated\n        list of values or ranges (e.g., 1,2-4,5,6-8).\n\n        For FDP by default, the job will cycle through all available Placement\n        IDs, so use this option to be selective. The values specified here are\n        array indices for the list of placement IDs returned by the nvme-cli\n        command ``nvme fdp status``. If you want fio to use FDP placement\n        identifiers only at indices 0, 2 and 5, set ``plids=0,2,5``.\n\n        For streams this should be a list of Stream IDs.\n\n.. option:: dp_scheme=str : [io_uring_cmd] [xnvme]\n\n\tDefines which placement ID (index) to be selected based on offset(LBA) range.\n\tThe file should contains one or more scheme entries in the following format:\n\n\t\t0, 10737418240, 0\n\t\t10737418240, 21474836480, 1\n\t\t21474836480, 32212254720, 2\n\t\t...\n\n\tEach line, a scheme entry, contains start offset, end offset, and placement ID\n\t(index) separated by comma(,). If the write offset is within the range of a certain\n\tscheme entry(start offset ≤ offset < end offset), the corresponding placement ID\n\t(index) will be selected. If the write offset belongs to multiple scheme entries,\n\tthe first matched scheme entry will be applied. If the offset is not within any range\n\tof scheme entry, dspec field will be set to 0, default RUH. (Caution: In case of\n\tmultiple devices in a job, all devices of the job will be affected by the scheme. If\n\tthis option is specified, the option :option:`plids` or :option:`fdp_pli` will be\n\tignored.)\n\n.. option:: md_per_io_size=int : [io_uring_cmd] [xnvme]\n\n        Size in bytes for separate metadata buffer per IO. For io_uring_cmd\n        these buffers are allocated using malloc regardless of what is set for\n        :option:`iomem`. Default: 0.\n\n.. option:: pi_act=int : [io_uring_cmd] [xnvme]\n\n\tAction to take when nvme namespace is formatted with protection\n\tinformation. If this is set to 1 and namespace is formatted with\n\tmetadata size equal to protection information size, fio won't use\n\tseparate metadata buffer or extended logical block. If this is set to\n\t1 and namespace is formatted with metadata size greater than protection\n\tinformation size, fio will not generate or verify the protection\n\tinformation portion of metadata for write or read case respectively.\n\tIf this is set to 0, fio generates protection information for\n\twrite case and verifies for read case. Default: 1.\n\n\tFor 16 bit CRC generation fio will use isa-l if available otherwise\n\tit will use the default slower generator.\n\t(see: https://github.com/intel/isa-l)\n\n.. option:: pi_chk=str[,str][,str] : [io_uring_cmd] [xnvme]\n\n\tControls the protection information check. This can take one or more\n\tof these values. Default: none.\n\n\t**GUARD**\n\t\tEnables protection information checking of guard field.\n\t**REFTAG**\n\t\tEnables protection information checking of logical block\n\t\treference tag field.\n\t**APPTAG**\n\t\tEnables protection information checking of application tag field.\n\n.. option:: apptag=int : [io_uring_cmd] [xnvme]\n\n\tSpecifies logical block application tag value, if namespace is\n\tformatted to use end to end protection information. Default: 0x1234.\n\n.. option:: apptag_mask=int : [io_uring_cmd] [xnvme]\n\n\tSpecifies logical block application tag mask value, if namespace is\n\tformatted to use end to end protection information. Default: 0xffff.\n\n.. option:: num_range=int : [io_uring_cmd]\n\n\tFor trim command this will be the number of ranges to trim per I/O\n\trequest. The number of logical blocks per range is determined by the\n\t:option:`bs` option which should be a multiple of logical block size.\n\tThis cannot be used with read or write. Note that setting this\n\toption > 1, :option:`log_offset` will not be able to log all the\n\toffsets. Default: 1.\n\n.. option:: cpuload=int : [cpuio]\n\n\tAttempt to use the specified percentage of CPU cycles. This is a mandatory\n\toption when using cpuio I/O engine.\n\n.. option:: cpuchunks=int : [cpuio]\n\n\tSplit the load into cycles of the given time. In microseconds.\n\n.. option:: cpumode=str : [cpuio]\n\n\tSpecify how to stress the CPU. It can take these two values:\n\n\t**noop**\n\t\tThis is the default where the CPU executes noop instructions.\n\t**qsort**\n\t\tReplace the default noop instructions loop with a qsort algorithm to\n\t\tconsume more energy.\n\n.. option:: exit_on_io_done=bool : [cpuio]\n\n\tDetect when I/O threads are done, then exit.\n\n.. option:: namenode=str : [libhdfs]\n\n\tThe hostname or IP address of a HDFS cluster namenode to contact.\n\n.. option:: port=int\n\n   [libhdfs]\n\n\t\tThe listening port of the HFDS cluster namenode.\n\n   [netsplice], [net]\n\n\t\tThe TCP or UDP port to bind to or connect to. If this is used with\n\t\t:option:`numjobs` to spawn multiple instances of the same job type, then\n\t\tthis will be the starting port number since fio will use a range of\n\t\tports.\n\n   [rdma]\n\n\t\tThe port to use for RDMA-CM communication. This should be the same value\n\t\ton the client and the server side.\n\n.. option:: hostname=str : [netsplice] [net] [rdma]\n\n\tThe hostname or IP address to use for TCP, UDP or RDMA-CM based I/O.  If the job\n\tis a TCP listener or UDP reader, the hostname is not used and must be omitted\n\tunless it is a valid UDP multicast address.\n\n.. option:: interface=str : [netsplice] [net]\n\n\tThe IP address of the network interface used to send or receive UDP\n\tmulticast.\n\n.. option:: ttl=int : [netsplice] [net]\n\n\tTime-to-live value for outgoing UDP multicast packets. Default: 1.\n\n.. option:: nodelay=bool : [netsplice] [net]\n\n\tSet TCP_NODELAY on TCP connections.\n\n.. option:: protocol=str, proto=str : [netsplice] [net]\n\n\tThe network protocol to use. Accepted values are:\n\n\t**tcp**\n\t\tTransmission control protocol.\n\t**tcpv6**\n\t\tTransmission control protocol V6.\n\t**udp**\n\t\tUser datagram protocol.\n\t**udpv6**\n\t\tUser datagram protocol V6.\n\t**unix**\n\t\tUNIX domain socket.\n\t**vsock**\n\t\tVSOCK protocol.\n\n\tWhen the protocol is TCP, UDP or VSOCK, the port must also be given, as well as the\n\thostname if the job is a TCP or VSOCK listener or UDP reader. For unix sockets, the\n\tnormal :option:`filename` option should be used and the port is invalid.\n\tWhen the protocol is VSOCK, the :option:`hostname` is the CID of the remote VM.\n\n.. option:: listen : [netsplice] [net]\n\n\tFor TCP network connections, tell fio to listen for incoming connections\n\trather than initiating an outgoing connection. The :option:`hostname` must\n\tbe omitted if this option is used.\n\n.. option:: pingpong : [netsplice] [net]\n\n\tNormally a network writer will just continue writing data, and a network\n\treader will just consume packages. If ``pingpong=1`` is set, a writer will\n\tsend its normal payload to the reader, then wait for the reader to send the\n\tsame payload back. This allows fio to measure network latencies. The\n\tsubmission and completion latencies then measure local time spent sending or\n\treceiving, and the completion latency measures how long it took for the\n\tother end to receive and send back.  For UDP multicast traffic\n\t``pingpong=1`` should only be set for a single reader when multiple readers\n\tare listening to the same address.\n\n.. option:: window_size : [netsplice] [net]\n\n\tSet the desired socket buffer size for the connection.\n\n.. option:: mss : [netsplice] [net]\n\n\tSet the TCP maximum segment size (TCP_MAXSEG).\n\n.. option:: donorname=str : [e4defrag]\n\n\tFile will be used as a block donor (swap extents between files).\n\n.. option:: inplace=int : [e4defrag]\n\n\tConfigure donor file blocks allocation strategy:\n\n\t**0**\n\t\tDefault. Preallocate donor's file on init.\n\t**1**\n\t\tAllocate space immediately inside defragment event, and free right\n\t\tafter event.\n\n.. option:: clustername=str : [rbd,rados]\n\n\tSpecifies the name of the Ceph cluster.\n\n.. option:: rbdname=str : [rbd]\n\n\tSpecifies the name of the RBD.\n\n.. option:: clientname=str : [rbd,rados]\n\n\tSpecifies the username (without the 'client.' prefix) used to access the\n\tCeph cluster. If the *clustername* is specified, the *clientname* shall be\n\tthe full *type.id* string. If no type. prefix is given, fio will add\n\t'client.' by default.\n\n.. option:: conf=str : [rados]\n\n    Specifies the configuration path of ceph cluster, so conf file does not\n    have to be /etc/ceph/ceph.conf.\n\n.. option:: busy_poll=bool : [rbd,rados]\n\n        Poll store instead of waiting for completion. Usually this provides better\n        throughput at cost of higher(up to 100%) CPU utilization.\n\n.. option:: touch_objects=bool : [rados]\n\n        During initialization, touch (create if do not exist) all objects (files).\n        Touching all objects affects ceph caches and likely impacts test results.\n        Enabled by default.\n\n.. option:: pool=str :\n\n   [rbd,rados]\n\n\tSpecifies the name of the Ceph pool containing RBD or RADOS data.\n\n   [dfs]\n\n\tSpecify the label or UUID of the DAOS pool to connect to.\n\n.. option:: cont=str : [dfs]\n\n\tSpecify the label or UUID of the DAOS container to open.\n\n.. option:: chunk_size=int\n\n   [dfs]\n\n\tSpecify a different chunk size (in bytes) for the dfs file.\n\tUse DAOS container's chunk size by default.\n\n   [libhdfs]\n\n\tThe size of the chunk to use for each file.\n\n.. option:: object_class=str : [dfs]\n\n\tSpecify a different object class for the dfs file.\n\tUse DAOS container's object class by default.\n\n.. option:: skip_bad=bool : [mtd]\n\n\tSkip operations against known bad blocks.\n\n.. option:: hdfsdirectory : [libhdfs]\n\n\tlibhdfs will create chunk in this HDFS directory.\n\n.. option:: verb=str : [rdma]\n\n\tThe RDMA verb to use on this side of the RDMA ioengine connection. Valid\n\tvalues are write, read, send and recv. These correspond to the equivalent\n\tRDMA verbs (e.g. write = rdma_write etc.). Note that this only needs to be\n\tspecified on the client side of the connection. See the examples folder.\n\n.. option:: bindname=str : [rdma]\n\n\tThe name to use to bind the local RDMA-CM connection to a local RDMA device.\n\tThis could be a hostname or an IPv4 or IPv6 address. On the server side this\n\twill be passed into the rdma_bind_addr() function and on the client site it\n\twill be used in the rdma_resolve_add() function. This can be useful when\n\tmultiple paths exist between the client and the server or in certain loopback\n\tconfigurations.\n\n.. option:: stat_type=str : [filestat]\n\n\tSpecify stat system call type to measure lookup/getattr performance.\n\tDefault is **stat** for :manpage:`stat(2)`.\n\n.. option:: readfua=bool : [sg] [io_uring_cmd]\n\n\tWith readfua option set to 1, read operations include\n\tthe force unit access (fua) flag. Default is 0.\n\n.. option:: writefua=bool : [sg] [io_uring_cmd]\n\n\tWith writefua option set to 1, write operations include\n\tthe force unit access (fua) flag. Default is 0.\n\n.. option:: write_mode=str : [io_uring_cmd]\n\n        Specifies the type of write operation.  Defaults to 'write'.\n\n                **write**\n                        Use Write commands for write operations\n\n                **uncor**\n                        Use Write Uncorrectable commands for write operations\n\n                **zeroes**\n                        Use Write Zeroes commands for write operations\n\n                **verify**\n                        Use Verify commands for write operations\n\n.. option:: verify_mode=str : [io_uring_cmd]\n\n        Specifies the type of command to be used in the verification phase.  Defaults to 'read'.\n\n                **read**\n                        Use Read commands for data verification\n                **compare**\n                        Use Compare commands for data verification\n\n.. option:: sg_write_mode=str : [sg]\n\n\tSpecify the type of write commands to issue. This option can take ten values:\n\n\t**write**\n\t\tThis is the default where write opcodes are issued as usual.\n\t**write_and_verify**\n\t\tIssue WRITE AND VERIFY commands. The BYTCHK bit is set to 0. This\n\t\tdirects the device to carry out a medium verification with no data\n\t\tcomparison. The writefua option is ignored with this selection.\n\t**verify**\n\t\tThis option is deprecated. Use write_and_verify instead.\n\t**write_same**\n\t\tIssue WRITE SAME commands. This transfers a single block to the device\n\t\tand writes this same block of data to a contiguous sequence of LBAs\n\t\tbeginning at the specified offset. fio's block size parameter specifies\n\t\tthe amount of data written with each command. However, the amount of data\n\t\tactually transferred to the device is equal to the device's block\n\t\t(sector) size. For a device with 512 byte sectors, blocksize=8k will\n\t\twrite 16 sectors with each command. fio will still generate 8k of data\n\t\tfor each command but only the first 512 bytes will be used and\n\t\ttransferred to the device. The writefua option is ignored with this\n\t\tselection.\n\t**same**\n\t\tThis option is deprecated. Use write_same instead.\n\t**write_same_ndob**\n\t\tIssue WRITE SAME(16) commands as above but with the No Data Output\n\t\tBuffer (NDOB) bit set. No data will be transferred to the device with\n\t\tthis bit set. Data written will be a pre-determined pattern such as\n\t\tall zeroes.\n\t**write_stream**\n\t\tIssue WRITE STREAM(16) commands. Use the **stream_id** option to specify\n\t\tthe stream identifier.\n\t**verify_bytchk_00**\n\t\tIssue VERIFY commands with BYTCHK set to 00. This directs the\n\t\tdevice to carry out a medium verification with no data comparison.\n\t**verify_bytchk_01**\n\t\tIssue VERIFY commands with BYTCHK set to 01. This directs the device to\n\t\tcompare the data on the device with the data transferred to the device.\n\t**verify_bytchk_11**\n\t\tIssue VERIFY commands with BYTCHK set to 11. This transfers a\n\t\tsingle block to the device and compares the contents of this block with the\n\t\tdata on the device beginning at the specified offset. fio's block size\n\t\tparameter specifies the total amount of data compared with this command.\n\t\tHowever, only one block (sector) worth of data is transferred to the device.\n\t\tThis is similar to the WRITE SAME command except that data is compared instead\n\t\tof written.\n\n.. option:: stream_id=int : [sg]\n\n\tSet the stream identifier for WRITE STREAM commands. If this is set to 0 (which is not\n\ta valid stream identifier) fio will open a stream and then close it when done. Default\n\tis 0.\n\n.. option:: http_host=str : [http]\n\n\tHostname to connect to. HTTP port 80 is used automatically when the value of \n\tthe https parameter is *off*, and HTTPS port 443 if it is *on*. A \n\tvirtual-hosted-style S3 hostname starts with a bucket name, while a \n\tpath-style S3 hostname does not. See \n\thttps://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html for \n\tdetailed examples.\n\tDefault is **localhost** (path-style S3 hostname)\n\n.. option:: http_user=str : [http]\n\n\tUsername for HTTP authentication.\n\n.. option:: http_pass=str : [http]\n\n\tPassword for HTTP authentication.\n\n.. option:: https=str : [http]\n\n\tEnable HTTPS instead of http. *on* enables HTTPS; *insecure*\n\twill enable HTTPS, but disable SSL peer verification (use with\n\tcaution!). Default is **off**\n\n.. option:: http_mode=str : [http]\n\n\tWhich HTTP access mode to use: *webdav*, *swift*, or *s3*.\n\tDefault is **webdav**\n\n.. option:: http_s3_region=str : [http]\n\n\tThe S3 region/zone string.\n\tDefault is **us-east-1**\n\n.. option:: http_s3_key=str : [http]\n\n\tThe S3 secret key.\n\n.. option:: http_s3_keyid=str : [http]\n\n\tThe S3 key/access id.\n\n.. option:: http_s3_sse_customer_key=str : [http]\n\n        The encryption customer key in SSE server side.\n\n.. option:: http_s3_sse_customer_algorithm=str : [http]\n\n        The encryption customer algorithm in SSE server side.\n        Default is **AES256**\n\n.. option:: http_s3_storage_class=str : [http]\n\n        Which storage class to access. User-customizable settings.\n        Default is **STANDARD**\n\n.. option:: http_swift_auth_token=str : [http]\n\n\tThe Swift auth token. See the example configuration file on how\n\tto retrieve this.\n\n.. option:: http_verbose=int : [http]\n\n\tEnable verbose requests from libcurl. Useful for debugging. 1\n\tturns on verbose logging from libcurl, 2 additionally enables\n\tHTTP IO tracing. Default is **0**\n\n.. option:: uri=str : [nbd]\n\n\tSpecify the NBD URI of the server to test.  The string\n\tis a standard NBD URI\n\t(see https://github.com/NetworkBlockDevice/nbd/tree/master/doc).\n\tExample URIs: nbd://localhost:10809\n\tnbd+unix:///?socket=/tmp/socket\n\tnbds://tlshost/exportname\n\n.. option:: gpu_dev_ids=str : [libcufile]\n\n\tSpecify the GPU IDs to use with CUDA. This is a colon-separated list of\n\tint. GPUs are assigned to workers roundrobin. Default is 0.\n\n.. option:: cuda_io=str : [libcufile]\n\n\tSpecify the type of I/O to use with CUDA. Default is **cufile**.\n\n\t**cufile**\n\t\tUse libcufile and nvidia-fs. This option performs I/O directly\n\t\tbetween a GPUDirect Storage filesystem and GPU buffers,\n\t\tavoiding use of a bounce buffer. If :option:`verify` is set,\n\t\tcudaMemcpy is used to copy verificaton data between RAM and GPU.\n\t\tVerification data is copied from RAM to GPU before a write\n\t\tand from GPU to RAM after a read. :option:`direct` must be 1.\n\t**posix**\n\t\tUse POSIX to perform I/O with a RAM buffer, and use cudaMemcpy\n\t\tto transfer data between RAM and the GPUs. Data is copied from\n\t\tGPU to RAM before a write and copied from RAM to GPU after a\n\t\tread. :option:`verify` does not affect use of cudaMemcpy.\n\n.. option:: nfs_url=str : [nfs]\n\n\tURL in libnfs format, eg nfs://<server|ipv4|ipv6>/path[?arg=val[&arg=val]*]\n\tRefer to the libnfs README for more details.\n\n.. option:: program=str : [exec]\n\n\tSpecify the program to execute.\n\n.. option:: arguments=str : [exec]\n\n\tSpecify arguments to pass to program.\n\tSome special variables can be expanded to pass fio's job details to the program.\n\n\t**%r**\n\t\tReplaced by the duration of the job in seconds.\n\t**%n**\n\t\tReplaced by the name of the job.\n\n.. option:: grace_time=int : [exec]\n\n\tSpecify the time between the SIGTERM and SIGKILL signals. Default is 1 second.\n\n.. option:: std_redirect=bool : [exec]\n\n\tIf set, stdout and stderr streams are redirected to files named from the job name. Default is true.\n\n.. option:: xnvme_async=str : [xnvme]\n\n\tSelect the xnvme async command interface. This can take these values.\n\n\t**emu**\n\t\tThis is default and use to emulate asynchronous I/O by using a\n\t\tsingle thread to create a queue pair on top of a synchronous\n\t\tI/O interface using the NVMe driver IOCTL.\n\t**thrpool**\n\t\tEmulate an asynchronous I/O interface with a pool of userspace\n\t\tthreads on top of a synchronous I/O interface using the NVMe\n\t\tdriver IOCTL. By default four threads are used.\n\t**io_uring**\n\t\tLinux native asynchronous I/O interface which supports both\n\t\tdirect and buffered I/O.\n\t**io_uring_cmd**\n\t\tFast Linux native asynchronous I/O interface for NVMe pass\n\t\tthrough commands. This only works with NVMe character device\n\t\t(/dev/ngXnY).\n\t**libaio**\n\t\tUse Linux aio for Asynchronous I/O.\n\t**posix**\n\t\tUse the posix asynchronous I/O interface to perform one or\n\t\tmore I/O operations asynchronously.\n\t**vfio**\n\t\tUse the user-space VFIO-based backend, implemented using\n\t\tlibvfn instead of SPDK.\n\t**nil**\n\t\tDo not transfer any data; just pretend to. This is mainly used\n\t\tfor introspective performance evaluation.\n\n.. option:: xnvme_sync=str : [xnvme]\n\n\tSelect the xnvme synchronous command interface. This can take these values.\n\n\t**nvme**\n\t\tThis is default and uses Linux NVMe Driver ioctl() for\n\t\tsynchronous I/O.\n\t**psync**\n\t\tThis supports regular as well as vectored pread() and pwrite()\n\t\tcommands.\n\t**block**\n\t\tThis is the same as psync except that it also supports zone\n\t\tmanagement commands using Linux block layer IOCTLs.\n\n.. option:: xnvme_admin=str : [xnvme]\n\n\tSelect the xnvme admin command interface. This can take these values.\n\n\t**nvme**\n\t\tThis is default and uses linux NVMe Driver ioctl() for admin\n\t\tcommands.\n\t**block**\n\t\tUse Linux Block Layer ioctl() and sysfs for admin commands.\n\n.. option:: xnvme_dev_nsid=int : [xnvme]\n\n\txnvme namespace identifier for userspace NVMe driver, SPDK or vfio.\n\n.. option:: xnvme_dev_subnqn=str : [xnvme]\n\n\tSets the subsystem NQN for fabrics. This is for xNVMe to utilize a\n\tfabrics target with multiple systems.\n\n.. option:: xnvme_mem=str : [xnvme]\n\n\tSelect the xnvme memory backend. This can take these values.\n\n\t**posix**\n\t\tThis is the default posix memory backend for linux NVMe driver.\n\t**hugepage**\n\t\tUse hugepages, instead of existing posix memory backend. The\n\t\tmemory backend uses hugetlbfs. This require users to allocate\n\t\thugepages, mount hugetlbfs and set an environment variable for\n\t\tXNVME_HUGETLB_PATH.\n\t**spdk**\n\t\tUses SPDK's memory allocator.\n\t**vfio**\n\t\tUses libvfn's memory allocator. This also specifies the use\n\t\tof libvfn backend instead of SPDK.\n\n.. option:: xnvme_iovec=int : [xnvme]\n\n\tIf this option is set. xnvme will use vectored read/write commands.\n\n.. option:: libblkio_driver=str : [libblkio]\n\n\tThe libblkio *driver* to use. Different drivers access devices through\n\tdifferent underlying interfaces. Available drivers depend on the\n\tlibblkio version in use and are listed at\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\n\n.. option:: libblkio_path=str : [libblkio]\n\n\tSets the value of the driver-specific \"path\" property before connecting\n\tthe libblkio instance, which identifies the target device or file on\n\twhich to perform I/O. Its exact semantics are driver-dependent and not\n\tall drivers may support it; see\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\n\n.. option:: libblkio_pre_connect_props=str : [libblkio]\n\n\tA colon-separated list of additional libblkio properties to be set after\n\tcreating but before connecting the libblkio instance. Each property must\n\thave the format ``<name>=<value>``. Colons can be escaped as ``\\:``.\n\tThese are set after the engine sets any other properties, so those can\n\tbe overridden. Available properties depend on the libblkio version in use\n\tand are listed at\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#properties\n\n.. option:: libblkio_num_entries=int : [libblkio]\n\n\tSets the value of the driver-specific \"num-entries\" property before\n\tstarting the libblkio instance. Its exact semantics are driver-dependent\n\tand not all drivers may support it; see\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\n\n.. option:: libblkio_queue_size=int : [libblkio]\n\n\tSets the value of the driver-specific \"queue-size\" property before\n\tstarting the libblkio instance. Its exact semantics are driver-dependent\n\tand not all drivers may support it; see\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\n\n.. option:: libblkio_pre_start_props=str : [libblkio]\n\n\tA colon-separated list of additional libblkio properties to be set after\n\tconnecting but before starting the libblkio instance. Each property must\n\thave the format ``<name>=<value>``. Colons can be escaped as ``\\:``.\n\tThese are set after the engine sets any other properties, so those can\n\tbe overridden. Available properties depend on the libblkio version in use\n\tand are listed at\n\thttps://libblkio.gitlab.io/libblkio/blkio.html#properties\n\n.. option:: libblkio_vectored : [libblkio]\n\n\tSubmit vectored read and write requests.\n\n.. option:: libblkio_write_zeroes_on_trim : [libblkio]\n\n\tSubmit trims as \"write zeroes\" requests instead of discard requests.\n\n.. option:: libblkio_wait_mode=str : [libblkio]\n\n\tHow to wait for completions:\n\n\t**block** (default)\n\t\tUse a blocking call to ``blkioq_do_io()``.\n\t**eventfd**\n\t\tUse a blocking call to ``read()`` on the completion eventfd.\n\t**loop**\n\t\tUse a busy loop with a non-blocking call to ``blkioq_do_io()``.\n\n.. option:: libblkio_force_enable_completion_eventfd : [libblkio]\n\n\tEnable the queue's completion eventfd even when unused. This may impact\n\tperformance. The default is to enable it only if\n\t:option:`libblkio_wait_mode=eventfd <libblkio_wait_mode>`.\n\n.. option:: no_completion_thread : [windowsaio]\n\n\tAvoid using a separate thread for completion polling.\n\nI/O depth\n~~~~~~~~~\n\n.. option:: iodepth=int\n\n\tNumber of I/O units to keep in flight against the file.  Note that\n\tincreasing *iodepth* beyond 1 will not affect synchronous ioengines (except\n\tfor small degrees when :option:`verify_async` is in use).  Even async\n\tengines may impose OS restrictions causing the desired depth not to be\n\tachieved.  This may happen on Linux when using libaio and not setting\n\t:option:`direct`\\=1, since buffered I/O is not async on that OS.  Keep an\n\teye on the I/O depth distribution in the fio output to verify that the\n\tachieved depth is as expected. Default: 1.\n\n.. option:: iodepth_batch_submit=int, iodepth_batch=int\n\n\tThis defines how many pieces of I/O to submit at once.  It defaults to 1\n\twhich means that we submit each I/O as soon as it is available, but can be\n\traised to submit bigger batches of I/O at the time. If it is set to 0 the\n\t:option:`iodepth` value will be used.\n\n.. option:: iodepth_batch_complete_min=int, iodepth_batch_complete=int\n\n\tThis defines how many pieces of I/O to retrieve at once. It defaults to 1\n\twhich means that we'll ask for a minimum of 1 I/O in the retrieval process\n\tfrom the kernel. The I/O retrieval will go on until we hit the limit set by\n\t:option:`iodepth_low`. If this variable is set to 0, then fio will always\n\tcheck for completed events before queuing more I/O. This helps reduce I/O\n\tlatency, at the cost of more retrieval system calls.\n\n.. option:: iodepth_batch_complete_max=int\n\n\tThis defines maximum pieces of I/O to retrieve at once. This variable should\n\tbe used along with :option:`iodepth_batch_complete_min`\\=int variable,\n\tspecifying the range of min and max amount of I/O which should be\n\tretrieved. By default it is equal to the :option:`iodepth_batch_complete_min`\n\tvalue.\n\n\tExample #1::\n\n\t\tiodepth_batch_complete_min=1\n\t\tiodepth_batch_complete_max=<iodepth>\n\n\twhich means that we will retrieve at least 1 I/O and up to the whole\n\tsubmitted queue depth. If none of I/O has been completed yet, we will wait.\n\n\tExample #2::\n\n\t\tiodepth_batch_complete_min=0\n\t\tiodepth_batch_complete_max=<iodepth>\n\n\twhich means that we can retrieve up to the whole submitted queue depth, but\n\tif none of I/O has been completed yet, we will NOT wait and immediately exit\n\tthe system call. In this example we simply do polling.\n\n.. option:: iodepth_low=int\n\n\tThe low water mark indicating when to start filling the queue\n\tagain. Defaults to the same as :option:`iodepth`, meaning that fio will\n\tattempt to keep the queue full at all times.  If :option:`iodepth` is set to\n\te.g. 16 and *iodepth_low* is set to 4, then after fio has filled the queue of\n\t16 requests, it will let the depth drain down to 4 before starting to fill\n\tit again.\n\n.. option:: serialize_overlap=bool\n\n\tSerialize in-flight I/Os that might otherwise cause or suffer from data races.\n\tWhen two or more I/Os are submitted simultaneously, there is no guarantee that\n\tthe I/Os will be processed or completed in the submitted order. Further, if\n\ttwo or more of those I/Os are writes, any overlapping region between them can\n\tbecome indeterminate/undefined on certain storage. These issues can cause\n\tverification to fail erratically when at least one of the racing I/Os is\n\tchanging data and the overlapping region has a non-zero size. Setting\n\t``serialize_overlap`` tells fio to avoid provoking this behavior by explicitly\n\tserializing in-flight I/Os that have a non-zero overlap. Note that setting\n\tthis option can reduce both performance and the :option:`iodepth` achieved.\n\n\tThis option only applies to I/Os issued for a single job except when it is\n\tenabled along with :option:`io_submit_mode`\\=offload. In offload mode, fio\n\twill check for overlap among all I/Os submitted by offload jobs with :option:`serialize_overlap`\n\tenabled.\n\n\tDefault: false.\n\n.. option:: io_submit_mode=str\n\n\tThis option controls how fio submits the I/O to the I/O engine. The default\n\tis `inline`, which means that the fio job threads submit and reap I/O\n\tdirectly. If set to `offload`, the job threads will offload I/O submission\n\tto a dedicated pool of I/O threads. This requires some coordination and thus\n\thas a bit of extra overhead, especially for lower queue depth I/O where it\n\tcan increase latencies. The benefit is that fio can manage submission rates\n\tindependently of the device completion rates. This avoids skewed latency\n\treporting if I/O gets backed up on the device side (the coordinated omission\n\tproblem). Note that this option cannot reliably be used with async IO\n\tengines.\n\n\nI/O rate\n~~~~~~~~\n\n.. option:: thinkcycles=int\n\n\tStall the job for the specified number of cycles after an I/O has completed before\n\tissuing the next. May be used to simulate processing being done by an application.\n\tThis is not taken into account for the time to be waited on for  :option:`thinktime`.\n\tMight not have any effect on some platforms, this can be checked by trying a setting\n\ta high enough amount of thinkcycles.\n\n.. option:: thinktime=time\n\n\tStall the job for the specified period of time after an I/O has completed before issuing the\n\tnext. May be used to simulate processing being done by an application.\n\tWhen the unit is omitted, the value is interpreted in microseconds.  See\n\t:option:`thinktime_blocks`, :option:`thinktime_iotime` and :option:`thinktime_spin`.\n\n.. option:: thinktime_spin=time\n\n\tOnly valid if :option:`thinktime` is set - pretend to spend CPU time doing\n\tsomething with the data received, before falling back to sleeping for the\n\trest of the period specified by :option:`thinktime`.  When the unit is\n\tomitted, the value is interpreted in microseconds.\n\n.. option:: thinktime_blocks=int\n\n\tOnly valid if :option:`thinktime` is set - control how many blocks to issue,\n\tbefore waiting :option:`thinktime` usecs. If not set, defaults to 1 which will make\n\tfio wait :option:`thinktime` usecs after every block. This effectively makes any\n\tqueue depth setting redundant, since no more than 1 I/O will be queued\n\tbefore we have to complete it and do our :option:`thinktime`. In other words, this\n\tsetting effectively caps the queue depth if the latter is larger.\n\n.. option:: thinktime_blocks_type=str\n\n\tOnly valid if :option:`thinktime` is set - control how :option:`thinktime_blocks`\n\ttriggers. The default is `complete`, which triggers thinktime when fio completes\n\t:option:`thinktime_blocks` blocks. If this is set to `issue`, then the trigger happens\n\tat the issue side.\n\n.. option:: thinktime_iotime=time\n\n\tOnly valid if :option:`thinktime` is set - control :option:`thinktime`\n\tinterval by time. The :option:`thinktime` stall is repeated after IOs\n\tare executed for :option:`thinktime_iotime`. For example,\n\t``--thinktime_iotime=9s --thinktime=1s`` repeat 10-second cycle with IOs\n\tfor 9 seconds and stall for 1 second. When the unit is omitted,\n\t:option:`thinktime_iotime` is interpreted as a number of seconds. If\n\tthis option is used together with :option:`thinktime_blocks`, the\n\t:option:`thinktime` stall is repeated after :option:`thinktime_iotime`\n\tor after :option:`thinktime_blocks` IOs, whichever happens first.\n\n.. option:: rate=int[,int][,int]\n\n\tCap the bandwidth used by this job. The number is in bytes/sec, the normal\n\tsuffix rules apply.  Comma-separated values may be specified for reads,\n\twrites, and trims as described in :option:`blocksize`.\n\n\tFor example, using `rate=1m,500k` would limit reads to 1MiB/sec and writes to\n\t500KiB/sec.  Capping only reads or writes can be done with `rate=,500k` or\n\t`rate=500k,` where the former will only limit writes (to 500KiB/sec) and the\n\tlatter will only limit reads.\n\n.. option:: rate_min=int[,int][,int]\n\n\tTell fio to do whatever it can to maintain at least this bandwidth. Failing\n\tto meet this requirement will cause the job to exit.  Comma-separated values\n\tmay be specified for reads, writes, and trims as described in\n\t:option:`blocksize`.\n\n.. option:: rate_iops=int[,int][,int]\n\n\tCap the bandwidth to this number of IOPS. Basically the same as\n\t:option:`rate`, just specified independently of bandwidth. If the job is\n\tgiven a block size range instead of a fixed value, the smallest block size\n\tis used as the metric.  Comma-separated values may be specified for reads,\n\twrites, and trims as described in :option:`blocksize`.\n\n.. option:: rate_iops_min=int[,int][,int]\n\n\tIf fio doesn't meet this rate of I/O, it will cause the job to exit.\n\tComma-separated values may be specified for reads, writes, and trims as\n\tdescribed in :option:`blocksize`.\n\n.. option:: rate_process=str\n\n\tThis option controls how fio manages rated I/O submissions. The default is\n\t`linear`, which submits I/O in a linear fashion with fixed delays between\n\tI/Os that gets adjusted based on I/O completion rates. If this is set to\n\t`poisson`, fio will submit I/O based on a more real world random request\n\tflow, known as the Poisson process\n\t(https://en.wikipedia.org/wiki/Poisson_point_process). The lambda will be\n\t10^6 / IOPS for the given workload.\n\n.. option:: rate_ignore_thinktime=bool\n\n\tBy default, fio will attempt to catch up to the specified rate setting,\n\tif any kind of thinktime setting was used. If this option is set, then\n\tfio will ignore the thinktime and continue doing IO at the specified\n\trate, instead of entering a catch-up mode after thinktime is done.\n\n.. option:: rate_cycle=int\n\n        Average bandwidth for :option:`rate_min` and :option:`rate_iops_min`\n        over this number of milliseconds. Defaults to 1000.\n\n\nI/O latency\n~~~~~~~~~~~\n\n.. option:: latency_target=time\n\n\tIf set, fio will attempt to find the max performance point that the given\n\tworkload will run at while maintaining a latency below this target.  When\n\tthe unit is omitted, the value is interpreted in microseconds.  See\n\t:option:`latency_window` and :option:`latency_percentile`.\n\n.. option:: latency_window=time\n\n\tUsed with :option:`latency_target` to specify the sample window that the job\n\tis run at varying queue depths to test the performance.  When the unit is\n\tomitted, the value is interpreted in microseconds.\n\n.. option:: latency_percentile=float\n\n\tThe percentage of I/Os that must fall within the criteria specified by\n\t:option:`latency_target` and :option:`latency_window`. If not set, this\n\tdefaults to 100.0, meaning that all I/Os must be equal or below to the value\n\tset by :option:`latency_target`.\n\n.. option:: latency_run=bool\n\n\tUsed with :option:`latency_target`. If false (default), fio will find\n\tthe highest queue depth that meets :option:`latency_target` and exit. If\n\ttrue, fio will continue running and try to meet :option:`latency_target`\n\tby adjusting queue depth.\n\n.. option:: max_latency=time[,time][,time]\n\n\tIf set, fio will exit the job with an ETIMEDOUT error if it exceeds this\n\tmaximum latency. When the unit is omitted, the value is interpreted in\n\tmicroseconds. Comma-separated values may be specified for reads, writes,\n\tand trims as described in :option:`blocksize`.\n\n\nI/O replay\n~~~~~~~~~~\n\n.. option:: write_iolog=str\n\n\tWrite the issued I/O patterns to the specified file. See\n\t:option:`read_iolog`.  Specify a separate file for each job, otherwise the\n        iologs will be interspersed and the file may be corrupt. This file will\n        be opened in append mode.\n\n.. option:: read_iolog=str\n\n\tOpen an iolog with the specified filename and replay the I/O patterns it\n\tcontains. This can be used to store a workload and replay it sometime\n\tlater. The iolog given may also be a blktrace binary file, which allows fio\n\tto replay a workload captured by :command:`blktrace`. See\n\t:manpage:`blktrace(8)` for how to capture such logging data. For blktrace\n\treplay, the file needs to be turned into a blkparse binary data file first\n\t(``blkparse <device> -o /dev/null -d file_for_fio.bin``).\n\tYou can specify a number of files by separating the names with a ':'\n\tcharacter. See the :option:`filename` option for information on how to\n\tescape ':' characters within the file names. These files will\n\tbe sequentially assigned to job clones created by :option:`numjobs`.\n\t'-' is a reserved name, meaning read from stdin, notably if\n\t:option:`filename` is set to '-' which means stdin as well, then\n\tthis flag can't be set to '-'.\n\n.. option:: read_iolog_chunked=bool\n\n\tDetermines how iolog is read. If false(default) entire :option:`read_iolog`\n\twill be read at once. If selected true, input from iolog will be read\n\tgradually. Useful when iolog is very large, or it is generated.\n\n.. option:: merge_blktrace_file=str\n\n\tWhen specified, rather than replaying the logs passed to :option:`read_iolog`,\n\tthe logs go through a merge phase which aggregates them into a single\n\tblktrace. The resulting file is then passed on as the :option:`read_iolog`\n\tparameter. The intention here is to make the order of events consistent.\n\tThis limits the influence of the scheduler compared to replaying multiple\n\tblktraces via concurrent jobs.\n\n.. option:: merge_blktrace_scalars=float_list\n\n\tThis is a percentage based option that is index paired with the list of\n\tfiles passed to :option:`read_iolog`. When merging is performed, scale\n\tthe time of each event by the corresponding amount. For example,\n\t``--merge_blktrace_scalars=\"50:100\"`` runs the first trace in halftime\n\tand the second trace in realtime. This knob is separately tunable from\n\t:option:`replay_time_scale` which scales the trace during runtime and\n\tdoes not change the output of the merge unlike this option.\n\n.. option:: merge_blktrace_iters=float_list\n\n\tThis is a whole number option that is index paired with the list of files\n\tpassed to :option:`read_iolog`. When merging is performed, run each trace\n\tfor the specified number of iterations. For example,\n\t``--merge_blktrace_iters=\"2:1\"`` runs the first trace for two iterations\n\tand the second trace for one iteration.\n\n.. option:: replay_no_stall=bool\n\n\tWhen replaying I/O with :option:`read_iolog` the default behavior is to\n\tattempt to respect the timestamps within the log and replay them with the\n\tappropriate delay between IOPS. By setting this variable fio will not\n\trespect the timestamps and attempt to replay them as fast as possible while\n\tstill respecting ordering. The result is the same I/O pattern to a given\n\tdevice, but different timings.\n\n.. option:: replay_time_scale=int\n\n\tWhen replaying I/O with :option:`read_iolog`, fio will honor the\n\toriginal timing in the trace. With this option, it's possible to scale\n\tthe time. It's a percentage option, if set to 50 it means run at 50%\n\tthe original IO rate in the trace. If set to 200, run at twice the\n\toriginal IO rate. Defaults to 100.\n\n.. option:: replay_redirect=str\n\n\tWhile replaying I/O patterns using :option:`read_iolog` the default behavior\n\tis to replay the IOPS onto the major/minor device that each IOP was recorded\n\tfrom.  This is sometimes undesirable because on a different machine those\n\tmajor/minor numbers can map to a different device.  Changing hardware on the\n\tsame system can also result in a different major/minor mapping.\n\t``replay_redirect`` causes all I/Os to be replayed onto the single specified\n\tdevice regardless of the device it was recorded\n\tfrom. i.e. :option:`replay_redirect`\\= :file:`/dev/sdc` would cause all I/O\n\tin the blktrace or iolog to be replayed onto :file:`/dev/sdc`.  This means\n\tmultiple devices will be replayed onto a single device, if the trace\n\tcontains multiple devices. If you want multiple devices to be replayed\n\tconcurrently to multiple redirected devices you must blkparse your trace\n\tinto separate traces and replay them with independent fio invocations.\n\tUnfortunately this also breaks the strict time ordering between multiple\n\tdevice accesses.\n\n.. option:: replay_align=int\n\n\tForce alignment of the byte offsets in a trace to this value. The value\n\tmust be a power of 2.\n\n.. option:: replay_scale=int\n\n\tScale byte offsets down by this factor when replaying traces. Should most\n\tlikely use :option:`replay_align` as well.\n\n.. option:: replay_skip=str\n\n\tSometimes it's useful to skip certain IO types in a replay trace.\n\tThis could be, for instance, eliminating the writes in the trace.\n\tOr not replaying the trims/discards, if you are redirecting to\n\ta device that doesn't support them. This option takes a comma\n\tseparated list of read, write, trim, sync.\n\n\nThreads, processes and job synchronization\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. option:: thread\n\n\tFio defaults to creating jobs by using fork, however if this option is\n\tgiven, fio will create jobs by using POSIX Threads' function\n\t:manpage:`pthread_create(3)` to create threads instead.\n\n.. option:: wait_for=str\n\n\tIf set, the current job won't be started until all workers of the specified\n\twaitee job are done.\n\n\t``wait_for`` operates on the job name basis, so there are a few\n\tlimitations. First, the waitee must be defined prior to the waiter job\n\t(meaning no forward references). Second, if a job is being referenced as a\n\twaitee, it must have a unique name (no duplicate waitees).\n\n.. option:: nice=int\n\n\tRun the job with the given nice value. See man :manpage:`nice(2)`.\n\n\tOn Windows, values less than -15 set the process class to \"High\"; -1 through\n\t-15 set \"Above Normal\"; 1 through 15 \"Below Normal\"; and above 15 \"Idle\"\n\tpriority class.\n\n.. option:: prio=int\n\n\tSet the I/O priority value of this job. Linux limits us to a positive value\n\tbetween 0 and 7, with 0 being the highest.  See man\n\t:manpage:`ionice(1)`. Refer to an appropriate manpage for other operating\n\tsystems since meaning of priority may differ. For per-command priority\n\tsetting, see I/O engine specific :option:`cmdprio_percentage` and\n\t:option:`cmdprio` options.\n\n.. option:: prioclass=int\n\n\tSet the I/O priority class. See man :manpage:`ionice(1)`. For per-command\n\tpriority setting, see I/O engine specific :option:`cmdprio_percentage`\n\tand :option:`cmdprio_class` options.\n\n.. option:: priohint=int\n\n\tSet the I/O priority hint. This is only applicable to platforms that\n\tsupport I/O priority classes and to devices with features controlled\n\tthrough priority hints, e.g. block devices supporting command duration\n\tlimits, or CDL. CDL is a way to indicate the desired maximum latency\n\tof I/Os so that the device can optimize its internal command scheduling\n\taccording to the latency limits indicated by the user.\n\n\tFor per-I/O priority hint setting, see the I/O engine specific\n\t:option:`cmdprio_hint` option.\n\n.. option:: cpus_allowed=str\n\n\tControls the same options as :option:`cpumask`, but accepts a textual\n\tspecification of the permitted CPUs instead and CPUs are indexed from 0. So\n\tto use CPUs 0 and 5 you would specify ``cpus_allowed=0,5``. This option also\n\tallows a range of CPUs to be specified -- say you wanted a binding to CPUs\n\t0, 5, and 8 to 15, you would set ``cpus_allowed=0,5,8-15``.\n\n\tOn Windows, when ``cpus_allowed`` is unset only CPUs from fio's current\n\tprocessor group will be used and affinity settings are inherited from the\n\tsystem. An fio build configured to target Windows 7 makes options that set\n\tCPUs processor group aware and values will set both the processor group\n\tand a CPU from within that group. For example, on a system where processor\n\tgroup 0 has 40 CPUs and processor group 1 has 32 CPUs, ``cpus_allowed``\n\tvalues between 0 and 39 will bind CPUs from processor group 0 and\n\t``cpus_allowed`` values between 40 and 71 will bind CPUs from processor\n\tgroup 1. When using ``cpus_allowed_policy=shared`` all CPUs specified by a\n\tsingle ``cpus_allowed`` option must be from the same processor group. For\n\tWindows fio builds not built for Windows 7, CPUs will only be selected from\n\t(and be relative to) whatever processor group fio happens to be running in\n\tand CPUs from other processor groups cannot be used.\n\n.. option:: cpus_allowed_policy=str\n\n\tSet the policy of how fio distributes the CPUs specified by\n\t:option:`cpus_allowed` or :option:`cpumask`. Two policies are supported:\n\n\t\t**shared**\n\t\t\tAll jobs will share the CPU set specified.\n\t\t**split**\n\t\t\tEach job will get a unique CPU from the CPU set.\n\n\t**shared** is the default behavior, if the option isn't specified. If\n\t**split** is specified, then fio will assign one cpu per job. If not\n\tenough CPUs are given for the jobs listed, then fio will roundrobin the CPUs\n\tin the set.\n\n.. option:: cpumask=int\n\n\tSet the CPU affinity of this job. The parameter given is a bit mask of\n\tallowed CPUs the job may run on. So if you want the allowed CPUs to be 1\n\tand 5, you would pass the decimal value of (1 << 1 | 1 << 5), or 34. See man\n\t:manpage:`sched_setaffinity(2)`. This may not work on all supported\n\toperating systems or kernel versions. This option doesn't work well for a\n\thigher CPU count than what you can store in an integer mask, so it can only\n\tcontrol cpus 1-32. For boxes with larger CPU counts, use\n\t:option:`cpus_allowed`.\n\n.. option:: numa_cpu_nodes=str\n\n\tSet this job running on specified NUMA nodes' CPUs. The arguments allow\n\tcomma delimited list of cpu numbers, A-B ranges, or `all`. Note, to enable\n\tNUMA options support, fio must be built on a system with libnuma-dev(el)\n\tinstalled.\n\n.. option:: numa_mem_policy=str\n\n\tSet this job's memory policy and corresponding NUMA nodes. Format of the\n\targuments::\n\n\t\t<mode>[:<nodelist>]\n\n\t``mode`` is one of the following memory policies: ``default``, ``prefer``,\n\t``bind``, ``interleave`` or ``local``. For ``default`` and ``local`` memory\n\tpolicies, no node needs to be specified.  For ``prefer``, only one node is\n\tallowed.  For ``bind`` and ``interleave`` the ``nodelist`` may be as\n\tfollows: a comma delimited list of numbers, A-B ranges, or `all`.\n\n.. option:: cgroup=str\n\n\tAdd job to this control group. If it doesn't exist, it will be created. The\n\tsystem must have a mounted cgroup blkio mount point for this to work. If\n\tyour system doesn't have it mounted, you can do so with::\n\n\t\t# mount -t cgroup -o blkio none /cgroup\n\n.. option:: cgroup_weight=int\n\n\tSet the weight of the cgroup to this value. See the documentation that comes\n\twith the kernel, allowed values are in the range of 100..1000.\n\n.. option:: cgroup_nodelete=bool\n\n\tNormally fio will delete the cgroups it has created after the job\n\tcompletion. To override this behavior and to leave cgroups around after the\n\tjob completion, set ``cgroup_nodelete=1``.  This can be useful if one wants\n\tto inspect various cgroup files after job completion. Default: false.\n\n.. option:: flow_id=int\n\n\tThe ID of the flow. If not specified, it defaults to being a global\n\tflow. See :option:`flow`.\n\n.. option:: flow=int\n\n        Weight in token-based flow control. If this value is used, then fio\n        regulates the activity between two or more jobs sharing the same\n        flow_id. Fio attempts to keep each job activity proportional to other\n        jobs' activities in the same flow_id group, with respect to requested\n        weight per job. That is, if one job has `flow=3', another job has\n        `flow=2' and another with `flow=1`, then there will be a roughly 3:2:1\n        ratio in how much one runs vs the others.\n\n.. option:: flow_sleep=int\n\n\tThe period of time, in microseconds, to wait after the flow counter\n\thas exceeded its proportion before retrying operations.\n\n.. option:: stonewall, wait_for_previous\n\n\tWait for preceding jobs in the job file to exit, before starting this\n\tone. Can be used to insert serialization points in the job file. A stone\n\twall also implies starting a new reporting group, see\n\t:option:`group_reporting`.\n\n.. option:: exitall\n\n\tBy default, fio will continue running all other jobs when one job finishes.\n\tSometimes this is not the desired action.  Setting ``exitall`` will instead\n\tmake fio terminate all jobs in the same group, as soon as one job of that\n\tgroup finishes.\n\n.. option:: exit_what=str\n\n\tBy default, fio will continue running all other jobs when one job finishes.\n\tSometimes this is not the desired action. Setting ``exitall`` will\n\tinstead make fio terminate all jobs in the same group. The option\n        ``exit_what`` allows one to control which jobs get terminated when ``exitall``\n        is enabled. The default is ``group`` and does not change the behaviour of\n        ``exitall``. The setting ``all`` terminates all jobs. The setting ``stonewall``\n        terminates all currently running jobs across all groups and continues execution\n        with the next stonewalled group.\n\n.. option:: exec_prerun=str\n\n\tBefore running this job, issue the command specified through\n\t:manpage:`system(3)`. Output is redirected in a file called\n\t:file:`jobname.prerun.txt`.\n\n.. option:: exec_postrun=str\n\n\tAfter the job completes, issue the command specified though\n\t:manpage:`system(3)`. Output is redirected in a file called\n\t:file:`jobname.postrun.txt`.\n\n.. option:: uid=int\n\n\tInstead of running as the invoking user, set the user ID to this value\n\tbefore the thread/process does any work.\n\n.. option:: gid=int\n\n\tSet group ID, see :option:`uid`.\n\n\nVerification\n~~~~~~~~~~~~\n\n.. option:: verify_only\n\n\tDo not perform specified workload, only verify data still matches previous\n\tinvocation of this workload. This option allows one to check data multiple\n\ttimes at a later date without overwriting it. This option makes sense only\n\tfor workloads that write data, and does not support workloads with the\n\t:option:`time_based` option set.\n\n.. option:: do_verify=bool\n\n\tRun the verify phase after a write phase. Only valid if :option:`verify` is\n\tset. Default: true.\n\n.. option:: verify=str\n\n\tIf writing to a file, fio can verify the file contents after each iteration\n\tof the job. Each verification method also implies verification of special\n\theader, which is written to the beginning of each block. This header also\n\tincludes meta information, like offset of the block, block number, timestamp\n\twhen block was written, etc.  :option:`verify` can be combined with\n\t:option:`verify_pattern` option.  The allowed values are:\n\n\t\t**md5**\n\t\t\tUse an md5 sum of the data area and store it in the header of\n\t\t\teach block.\n\n\t\t**crc64**\n\t\t\tUse an experimental crc64 sum of the data area and store it in the\n\t\t\theader of each block.\n\n\t\t**crc32c**\n\t\t\tUse a crc32c sum of the data area and store it in the header of\n\t\t\teach block. This will automatically use hardware acceleration\n\t\t\t(e.g. SSE4.2 on an x86 or CRC crypto extensions on ARM64) but will\n\t\t\tfall back to software crc32c if none is found. Generally the\n\t\t\tfastest checksum fio supports when hardware accelerated.\n\n\t\t**crc32c-intel**\n\t\t\tSynonym for crc32c.\n\n\t\t**crc32**\n\t\t\tUse a crc32 sum of the data area and store it in the header of each\n\t\t\tblock.\n\n\t\t**crc16**\n\t\t\tUse a crc16 sum of the data area and store it in the header of each\n\t\t\tblock.\n\n\t\t**crc7**\n\t\t\tUse a crc7 sum of the data area and store it in the header of each\n\t\t\tblock.\n\n\t\t**xxhash**\n\t\t\tUse xxhash as the checksum function. Generally the fastest software\n\t\t\tchecksum that fio supports.\n\n\t\t**sha512**\n\t\t\tUse sha512 as the checksum function.\n\n\t\t**sha256**\n\t\t\tUse sha256 as the checksum function.\n\n\t\t**sha1**\n\t\t\tUse optimized sha1 as the checksum function.\n\n\t\t**sha3-224**\n\t\t\tUse optimized sha3-224 as the checksum function.\n\n\t\t**sha3-256**\n\t\t\tUse optimized sha3-256 as the checksum function.\n\n\t\t**sha3-384**\n\t\t\tUse optimized sha3-384 as the checksum function.\n\n\t\t**sha3-512**\n\t\t\tUse optimized sha3-512 as the checksum function.\n\n\t\t**meta**\n\t\t\tThis option is deprecated, since now meta information is included in\n\t\t\tgeneric verification header and meta verification happens by\n\t\t\tdefault. For detailed information see the description of the\n\t\t\t:option:`verify` setting. This option is kept because of\n\t\t\tcompatibility's sake with old configurations. Do not use it.\n\n\t\t**pattern**\n\t\t\tVerify a strict pattern. Normally fio includes a header with some\n\t\t\tbasic information and checksumming, but if this option is set, only\n\t\t\tthe specific pattern set with :option:`verify_pattern` is verified.\n\n\t\t**null**\n\t\t\tOnly pretend to verify. Useful for testing internals with\n\t\t\t:option:`ioengine`\\=null, not for much else.\n\n\tThis option can be used for repeated burn-in tests of a system to make sure\n\tthat the written data is also correctly read back. If the data direction\n\tgiven is a read or random read, fio will assume that it should verify a\n\tpreviously written file. If the data direction includes any form of write,\n\tthe verify will be of the newly written data.\n\n\tTo avoid false verification errors, do not use the norandommap option when\n\tverifying data with async I/O engines and I/O depths > 1.  Or use the\n\tnorandommap and the lfsr random generator together to avoid writing to the\n\tsame offset with multiple outstanding I/Os.\n\n.. option:: verify_offset=int\n\n\tSwap the verification header with data somewhere else in the block before\n\twriting. It is swapped back before verifying.\n\n.. option:: verify_interval=int\n\n\tWrite the verification header at a finer granularity than the\n\t:option:`blocksize`. It will be written for chunks the size of\n\t``verify_interval``. :option:`blocksize` should divide this evenly.\n\n.. option:: verify_pattern=str\n\n\tIf set, fio will fill the I/O buffers with this pattern. Fio defaults to\n\tfilling with totally random bytes, but sometimes it's interesting to fill\n\twith a known pattern for I/O verification purposes. Depending on the width\n\tof the pattern, fio will fill 1/2/3/4 bytes of the buffer at the time (it can\n\tbe either a decimal or a hex number).  The ``verify_pattern`` if larger than\n\ta 32-bit quantity has to be a hex number that starts with either \"0x\" or\n\t\"0X\". Use with :option:`verify`. Also, ``verify_pattern`` supports %o\n\tformat, which means that for each block offset will be written and then\n\tverified back, e.g.::\n\n\t\tverify_pattern=%o\n\n\tOr use combination of everything::\n\n\t\tverify_pattern=0xff%o\"abcd\"-12\n\n.. option:: verify_fatal=bool\n\n\tNormally fio will keep checking the entire contents before quitting on a\n\tblock verification failure. If this option is set, fio will exit the job on\n\tthe first observed failure. Default: false.\n\n.. option:: verify_dump=bool\n\n\tIf set, dump the contents of both the original data block and the data block\n\twe read off disk to files. This allows later analysis to inspect just what\n\tkind of data corruption occurred. Off by default.\n\n.. option:: verify_async=int\n\n\tFio will normally verify I/O inline from the submitting thread. This option\n\ttakes an integer describing how many async offload threads to create for I/O\n\tverification instead, causing fio to offload the duty of verifying I/O\n\tcontents to one or more separate threads. If using this offload option, even\n\tsync I/O engines can benefit from using an :option:`iodepth` setting higher\n\tthan 1, as it allows them to have I/O in flight while verifies are running.\n\tDefaults to 0 async threads, i.e. verification is not asynchronous.\n\n.. option:: verify_async_cpus=str\n\n\tTell fio to set the given CPU affinity on the async I/O verification\n\tthreads. See :option:`cpus_allowed` for the format used.\n\n.. option:: verify_backlog=int\n\n\tFio will normally verify the written contents of a job that utilizes verify\n\tonce that job has completed. In other words, everything is written then\n\teverything is read back and verified. You may want to verify continually\n\tinstead for a variety of reasons. Fio stores the meta data associated with\n\tan I/O block in memory, so for large verify workloads, quite a bit of memory\n\twould be used up holding this meta data. If this option is enabled, fio will\n\twrite only N blocks before verifying these blocks.\n\n.. option:: verify_backlog_batch=int\n\n\tControl how many blocks fio will verify if :option:`verify_backlog` is\n\tset. If not set, will default to the value of :option:`verify_backlog`\n\t(meaning the entire queue is read back and verified).  If\n\t``verify_backlog_batch`` is less than :option:`verify_backlog` then not all\n\tblocks will be verified, if ``verify_backlog_batch`` is larger than\n\t:option:`verify_backlog`, some blocks will be verified more than once.\n\n.. option:: verify_state_save=bool\n\n\tWhen a job exits during the write phase of a verify workload, save its\n\tcurrent state. This allows fio to replay up until that point, if the verify\n\tstate is loaded for the verify read phase. The format of the filename is,\n\troughly::\n\n\t\t<type>-<jobname>-<jobindex>-verify.state.\n\n\t<type> is \"local\" for a local run, \"sock\" for a client/server socket\n\tconnection, and \"ip\" (192.168.0.1, for instance) for a networked\n\tclient/server connection. Defaults to true.\n\n.. option:: verify_state_load=bool\n\n\tIf a verify termination trigger was used, fio stores the current write state\n\tof each thread. This can be used at verification time so that fio knows how\n\tfar it should verify.  Without this information, fio will run a full\n\tverification pass, according to the settings in the job file used.  Default\n\tfalse.\n\n.. option:: experimental_verify=bool\n\n        Enable experimental verification. Standard verify records I/O metadata\n        for later use during the verification phase. Experimental verify\n        instead resets the file after the write phase and then replays I/Os for\n        the verification phase.\n\n.. option:: verify_write_sequence=bool\n\n        Verify the header write sequence number. In a scenario with multiple jobs,\n        verification of the write sequence number may fail. Disabling this option\n        will mean that write sequence number checking is skipped. Doing that can be\n        useful for testing atomic writes, as it means that checksum verification can\n        still be attempted. For when :option:`atomic` is enabled, checksum\n        verification is expected to succeed (while write sequence checking can still\n        fail).\n        Defaults to true.\n\n.. option:: trim_percentage=int\n\n\tNumber of verify blocks to discard/trim.\n\n.. option:: trim_verify_zero=bool\n\n\tVerify that trim/discarded blocks are returned as zeros.\n\n.. option:: trim_backlog=int\n\n\tTrim after this number of blocks are written.\n\n.. option:: trim_backlog_batch=int\n\n\tTrim this number of I/O blocks.\n\nSteady state\n~~~~~~~~~~~~\n\n.. option:: steadystate=str:float, ss=str:float\n\n\tDefine the criterion and limit for assessing steady state performance. The\n\tfirst parameter designates the criterion whereas the second parameter sets\n\tthe threshold. When the criterion falls below the threshold for the\n\tspecified duration, the job will stop. For example, `iops_slope:0.1%` will\n\tdirect fio to terminate the job when the least squares regression slope\n\tfalls below 0.1% of the mean IOPS. If :option:`group_reporting` is enabled\n\tthis will apply to all jobs in the group. Below is the list of available\n\tsteady state assessment criteria. All assessments are carried out using only\n\tdata from the rolling collection window. Threshold limits can be expressed\n\tas a fixed value or as a percentage of the mean in the collection window.\n\n\tWhen using this feature, most jobs should include the :option:`time_based`\n\tand :option:`runtime` options or the :option:`loops` option so that fio does not\n\tstop running after it has covered the full size of the specified file(s) or device(s).\n\n\t\t**iops**\n\t\t\tCollect IOPS data. Stop the job if all individual IOPS measurements\n\t\t\tare within the specified limit of the mean IOPS (e.g., ``iops:2``\n\t\t\tmeans that all individual IOPS values must be within 2 of the mean,\n\t\t\twhereas ``iops:0.2%`` means that all individual IOPS values must be\n\t\t\twithin 0.2% of the mean IOPS to terminate the job).\n\n\t\t**iops_slope**\n\t\t\tCollect IOPS data and calculate the least squares regression\n\t\t\tslope. Stop the job if the slope falls below the specified limit.\n\n\t\t**bw**\n\t\t\tCollect bandwidth data. Stop the job if all individual bandwidth\n\t\t\tmeasurements are within the specified limit of the mean bandwidth.\n\n\t\t**bw_slope**\n\t\t\tCollect bandwidth data and calculate the least squares regression\n\t\t\tslope. Stop the job if the slope falls below the specified limit.\n\n.. option:: steadystate_duration=time, ss_dur=time\n\n        A rolling window of this duration will be used to judge whether steady\n        state has been reached. Data will be collected every\n        :option:`ss_interval`.  The default is 0 which disables steady state\n        detection.  When the unit is omitted, the value is interpreted in\n        seconds.\n\n.. option:: steadystate_ramp_time=time, ss_ramp=time\n\n\tAllow the job to run for the specified duration before beginning data\n\tcollection for checking the steady state job termination criterion. The\n\tdefault is 0.  When the unit is omitted, the value is interpreted in seconds.\n\n.. option:: steadystate_check_interval=time, ss_interval=time\n\n        The values during the rolling window will be collected with a period of\n        this value. If :option:`ss_interval` is 30s and :option:`ss_dur` is\n        300s, 10 measurements will be taken. Default is 1s but that might not\n        converge, especially for slower devices, so set this accordingly. When\n        the unit is omitted, the value is interpreted in seconds.\n\n\nMeasurements and reporting\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. option:: per_job_logs=bool\n\n        If set to true, fio generates bw/clat/iops logs with per job unique\n        filenames. If set to false, jobs with identical names will share a log\n        filename. Note that when this option is set to false log files will be\n        opened in append mode and if log files already exist the previous\n        contents will not be overwritten. Default: true.\n\n.. option:: group_reporting\n\n\tIt may sometimes be interesting to display statistics for groups of jobs as\n\ta whole instead of for each individual job.  This is especially true if\n\t:option:`numjobs` is used; looking at individual thread/process output\n\tquickly becomes unwieldy.  To see the final report per-group instead of\n\tper-job, use :option:`group_reporting`. Jobs in a file will be part of the\n\tsame reporting group, unless if separated by a :option:`stonewall`, or by\n\tusing :option:`new_group`.\n\n\tNOTE: When :option:`group_reporting` is used along with `json` output,\n\tthere are certain per-job properties which can be different between jobs\n\tbut do not have a natural group-level equivalent. Examples include\n\t`kb_base`, `unit_base`, `sig_figs`, `thread_number`, `pid`, and\n\t`job_start`. For these properties, the values for the first job are\n\trecorded for the group.\n\n        Also, options like :option:`percentile_list` and\n        :option:`unified_rw_reporting` should be consistent among the jobs in a\n        reporting group. Having options like these vary across the jobs in a\n        reporting group is an unsupported configuration.\n\n.. option:: new_group\n\n\tStart a new reporting group. See: :option:`group_reporting`.  If not given,\n\tall jobs in a file will be part of the same reporting group, unless\n\tseparated by a :option:`stonewall`.\n\n.. option:: stats=bool\n\n\tBy default, fio collects and shows final output results for all jobs\n\tthat run. If this option is set to 0, then fio will ignore it in\n\tthe final stat output.\n\n.. option:: write_bw_log=str\n\n\tIf given, write a bandwidth log for this job. Can be used to store data of\n\tthe bandwidth of the jobs in their lifetime.\n\n\tIf no str argument is given, the default filename of\n\t:file:`jobname_type.x.log` is used. Even when the argument is given, fio\n\twill still append the type of log. So if one specifies::\n\n\t\twrite_bw_log=foo\n\n\tThe actual log name will be :file:`foo_bw.x.log` where `x` is the index\n\tof the job (`1..N`, where `N` is the number of jobs). If\n\t:option:`per_job_logs` is false, then the filename will not include the\n\t`.x` job index.\n\n\tThe included :command:`fio_generate_plots` script uses :command:`gnuplot` to turn these\n\ttext files into nice graphs. See `Log File Formats`_ for how data is\n\tstructured within the file.\n\n.. option:: write_lat_log=str\n\n\tSame as :option:`write_bw_log`, except this option creates I/O\n\tsubmission (e.g., :file:`name_slat.x.log`), completion (e.g.,\n\t:file:`name_clat.x.log`), and total (e.g., :file:`name_lat.x.log`)\n\tlatency files instead. See :option:`write_bw_log` for details about\n\tthe filename format and `Log File Formats`_ for how data is structured\n\twithin the files.\n\n.. option:: write_hist_log=str\n\n\tSame as :option:`write_bw_log` but writes an I/O completion latency\n\thistogram file (e.g., :file:`name_hist.x.log`) instead. Note that this\n\tfile will be empty unless :option:`log_hist_msec` has also been set.\n\tSee :option:`write_bw_log` for details about the filename format and\n\t`Log File Formats`_ for how data is structured within the file.\n\n.. option:: write_iops_log=str\n\n\tSame as :option:`write_bw_log`, but writes an IOPS file (e.g.\n\t:file:`name_iops.x.log`) instead. Because fio defaults to individual\n\tI/O logging, the value entry in the IOPS log will be 1 unless windowed\n\tlogging (see :option:`log_avg_msec`) has been enabled. See\n\t:option:`write_bw_log` for details about the filename format and `Log\n\tFile Formats`_ for how data is structured within the file.\n\n.. option:: log_entries=int\n\n\tBy default, fio will log an entry in the iops, latency, or bw log for\n\tevery I/O that completes. The initial number of I/O log entries is 1024.\n\tWhen the log entries are all used, new log entries are dynamically\n\tallocated.  This dynamic log entry allocation may negatively impact\n\ttime-related statistics such as I/O tail latencies (e.g. 99.9th percentile\n\tcompletion latency). This option allows specifying a larger initial\n\tnumber of log entries to avoid run-time allocations of new log entries,\n\tresulting in more precise time-related I/O statistics.\n\tAlso see :option:`log_avg_msec`. Defaults to 1024.\n\n.. option:: log_avg_msec=int\n\n        By default, fio will log an entry in the iops, latency, or bw log for\n        every I/O that completes. When writing to the disk log, that can\n        quickly grow to a very large size. Setting this option directs fio to\n        instead record an average over the specified duration for each log\n        entry, reducing the resolution of the log. When the job completes, fio\n        will flush any accumulated latency log data, so the final log interval\n        may not match the value specified by this option and there may even be\n        duplicate timestamps. See :option:`log_window_value` as well. Defaults\n        to 0, logging entries for each I/O. Also see `Log File Formats`_.\n\n.. option:: log_hist_msec=int\n\n\tSame as :option:`log_avg_msec`, but logs entries for completion latency\n\thistograms. Computing latency percentiles from averages of intervals using\n\t:option:`log_avg_msec` is inaccurate. Setting this option makes fio log\n\thistogram entries over the specified period of time, reducing log sizes for\n\thigh IOPS devices while retaining percentile accuracy.  See\n\t:option:`log_hist_coarseness` and :option:`write_hist_log` as well.\n\tDefaults to 0, meaning histogram logging is disabled.\n\n.. option:: log_hist_coarseness=int\n\n\tInteger ranging from 0 to 6, defining the coarseness of the resolution of\n\tthe histogram logs enabled with :option:`log_hist_msec`. For each increment\n\tin coarseness, fio outputs half as many bins. Defaults to 0, for which\n\thistogram logs contain 1216 latency bins. See :option:`write_hist_log`\n\tand `Log File Formats`_.\n\n.. option:: log_window_value=str, log_max_value=str\n\n\tIf :option:`log_avg_msec` is set, fio by default logs the average over that\n\twindow. This option determines whether fio logs the average, maximum or\n\tboth the values over the window. This only affects the latency logging,\n\tas both average and maximum values for iops or bw log will be same.\n\tAccepted values are:\n\n\t\t**avg**\n\t\t\tLog average value over the window. The default.\n\n\t\t**max**\n\t\t\tLog maximum value in the window.\n\n\t\t**both**\n\t\t\tLog both average and maximum value over the window.\n\n\t\t**0**\n\t\t\tBackward-compatible alias for **avg**.\n\n\t\t**1**\n\t\t\tBackward-compatible alias for **max**.\n\n.. option:: log_offset=bool\n\n\tIf this is set, the iolog options will include the byte offset for the I/O\n\tentry as well as the other data values. Defaults to 0 meaning that\n\toffsets are not present in logs. Also see `Log File Formats`_.\n\n.. option:: log_prio=bool\n\n\tIf this is set, the *Command priority* field in `Log File Formats`_\n\tshows the priority value and the IO priority class of the command.\n\tOtherwise, the field shows if the command has the highest RT\n\tpriority class or not. Also see\t`Log File Formats`_.\n\n.. option:: log_issue_time=bool\n\n\tIf this is set, the iolog options will include the command issue time\n\tfor the I/O entry as well as the other data values. Defaults to 0\n\tmeaning that command issue times are not present in logs. Also see\n\t`Log File Formats`_. This option shall be set together with\n\t:option:`write_lat_log` and :option:`log_offset`.\n\n.. option:: log_compression=int\n\n\tIf this is set, fio will compress the I/O logs as it goes, to keep the\n\tmemory footprint lower. When a log reaches the specified size, that chunk is\n\tremoved and compressed in the background. Given that I/O logs are fairly\n\thighly compressible, this yields a nice memory savings for longer runs. The\n\tdownside is that the compression will consume some background CPU cycles, so\n\tit may impact the run. This, however, is also true if the logging ends up\n\tconsuming most of the system memory.  So pick your poison. The I/O logs are\n\tsaved normally at the end of a run, by decompressing the chunks and storing\n\tthem in the specified log file. This feature depends on the availability of\n\tzlib.\n\n.. option:: log_compression_cpus=str\n\n\tDefine the set of CPUs that are allowed to handle online log compression for\n\tthe I/O jobs. This can provide better isolation between performance\n\tsensitive jobs, and background compression work. See\n\t:option:`cpus_allowed` for the format used.\n\n.. option:: log_store_compressed=bool\n\n\tIf set, fio will store the log files in a compressed format. They can be\n\tdecompressed with fio, using the :option:`--inflate-log` command line\n\tparameter. The files will be stored with a :file:`.fz` suffix.\n\n.. option:: log_unix_epoch=bool\n\n\tBackwards compatible alias for log_alternate_epoch.\n\n.. option:: log_alternate_epoch=bool\n\n\tIf set, fio will log timestamps based on the epoch used by the clock specified\n\tin the log_alternate_epoch_clock_id option, to the log files produced by\n\tenabling write_type_log for each log type, instead of the default zero-based\n\ttimestamps.\n\n.. option:: log_alternate_epoch_clock_id=int\n\n    Specifies the clock_id to be used by clock_gettime to obtain the alternate\n    epoch if log_alternate_epoch is true. Otherwise has no effect. Default\n    value is 0, or CLOCK_REALTIME.\n\n.. option:: block_error_percentiles=bool\n\n\tIf set, record errors in trim block-sized units from writes and trims and\n\toutput a histogram of how many trims it took to get to errors, and what kind\n\tof error was encountered.\n\n.. option:: bwavgtime=int\n\n\tAverage the calculated bandwidth over the given time. Value is specified in\n\tmilliseconds. If the job also does bandwidth logging through\n\t:option:`write_bw_log`, then the minimum of this option and\n\t:option:`log_avg_msec` will be used.  Default: 500ms.\n\n.. option:: iopsavgtime=int\n\n\tAverage the calculated IOPS over the given time. Value is specified in\n\tmilliseconds. If the job also does IOPS logging through\n\t:option:`write_iops_log`, then the minimum of this option and\n\t:option:`log_avg_msec` will be used.  Default: 500ms.\n\n.. option:: disk_util=bool\n\n\tGenerate disk utilization statistics, if the platform supports it.\n\tDefault: true.\n\n.. option:: disable_lat=bool\n\n\tDisable measurements of total latency numbers. Useful only for cutting back\n\tthe number of calls to :manpage:`gettimeofday(2)`, as that does impact\n\tperformance at really high IOPS rates.  Note that to really get rid of a\n\tlarge amount of these calls, this option must be used with\n\t:option:`disable_slat` and :option:`disable_bw_measurement` as well.\n\n.. option:: disable_clat=bool\n\n\tDisable measurements of completion latency numbers. See\n\t:option:`disable_lat`.\n\n.. option:: disable_slat=bool\n\n\tDisable measurements of submission latency numbers. See\n\t:option:`disable_lat`.\n\n.. option:: disable_bw_measurement=bool, disable_bw=bool\n\n\tDisable measurements of throughput/bandwidth numbers. See\n\t:option:`disable_lat`.\n\n.. option:: slat_percentiles=bool\n\n\tReport submission latency percentiles. Submission latency is not recorded\n\tfor synchronous ioengines.\n\n.. option:: clat_percentiles=bool\n\n\tReport completion latency percentiles.\n\n.. option:: lat_percentiles=bool\n\n\tReport total latency percentiles. Total latency is the sum of submission\n\tlatency and completion latency.\n\n.. option:: percentile_list=float_list\n\n\tOverwrite the default list of percentiles for latencies and the block error\n\thistogram.  Each number is a floating point number in the range (0,100], and\n\tthe maximum length of the list is 20. Use ``:`` to separate the numbers. For\n\texample, ``--percentile_list=99.5:99.9`` will cause fio to report the\n\tlatency durations below which 99.5% and 99.9% of the observed latencies fell,\n\trespectively.\n\n.. option:: significant_figures=int\n\n\tIf using :option:`--output-format` of `normal`, set the significant\n\tfigures to this\tvalue. Higher values will yield more precise IOPS and\n\tthroughput units, while lower values will round. Requires a minimum\n\tvalue of 1 and a maximum value of 10. Defaults to 4.\n\n\nError handling\n~~~~~~~~~~~~~~\n\n.. option:: exitall_on_error\n\n\tWhen one job finishes in error, terminate the rest. The default is to wait\n\tfor each job to finish.\n\n.. option:: continue_on_error=str\n\n\tNormally fio will exit the job on the first observed failure. If this option\n\tis set, fio will continue the job when there is a 'non-fatal error' (EIO or\n\tEILSEQ) until the runtime is exceeded or the I/O size specified is\n\tcompleted. If this option is used, there are two more stats that are\n\tappended, the total error count and the first error. The error field given\n\tin the stats is the first error that was hit during the run.\n\n\tNote: a write error from the device may go unnoticed by fio when using\n\tbuffered IO, as the write() (or similar) system call merely dirties the\n\tkernel pages, unless :option:`sync` or :option:`direct` is used. Device IO\n\terrors occur when the dirty data is actually written out to disk. If fully\n\tsync writes aren't desirable, :option:`fsync` or :option:`fdatasync` can be\n\tused as well. This is specific to writes, as reads are always synchronous.\n\n\tThe allowed values are:\n\n\t\t**none**\n\t\t\tExit on any I/O or verify errors.\n\n\t\t**read**\n\t\t\tContinue on read errors, exit on all others.\n\n\t\t**write**\n\t\t\tContinue on write errors, exit on all others.\n\n\t\t**io**\n\t\t\tContinue on any I/O error, exit on all others.\n\n\t\t**verify**\n\t\t\tContinue on verify errors, exit on all others.\n\n\t\t**all**\n\t\t\tContinue on all errors.\n\n\t\t**0**\n\t\t\tBackward-compatible alias for 'none'.\n\n\t\t**1**\n\t\t\tBackward-compatible alias for 'all'.\n\n.. option:: ignore_error=str\n\n\tSometimes you want to ignore some errors during test in that case you can\n\tspecify error list for each error type, instead of only being able to\n\tignore the default 'non-fatal error' using :option:`continue_on_error`.\n\t``ignore_error=READ_ERR_LIST,WRITE_ERR_LIST,VERIFY_ERR_LIST`` errors for\n\tgiven error type is separated with ':'. Error may be symbol ('ENOSPC',\n\t'ENOMEM') or integer.  Example::\n\n\t\tignore_error=EAGAIN,ENOSPC:122\n\n\tThis option will ignore EAGAIN from READ, and ENOSPC and 122(EDQUOT) from\n\tWRITE. This option works by overriding :option:`continue_on_error` with\n\tthe list of errors for each error type if any.\n\n.. option:: error_dump=bool\n\n\tIf set dump every error even if it is non fatal, true by default. If\n\tdisabled only fatal error will be dumped.\n\nRunning predefined workloads\n----------------------------\n\nFio includes predefined profiles that mimic the I/O workloads generated by\nother tools.\n\n.. option:: profile=str\n\n\tThe predefined workload to run.  Current profiles are:\n\n\t\t**tiobench**\n\t\t\tThreaded I/O bench (tiotest/tiobench) like workload.\n\n\t\t**act**\n\t\t\tAerospike Certification Tool (ACT) like workload.\n\nTo view a profile's additional options use :option:`--cmdhelp` after specifying\nthe profile.  For example::\n\n\t$ fio --profile=act --cmdhelp\n\nAct profile options\n~~~~~~~~~~~~~~~~~~~\n\n.. option:: device-names=str\n\t:noindex:\n\n\tDevices to use.\n\n.. option:: load=int\n\t:noindex:\n\n\tACT load multiplier.  Default: 1.\n\n.. option:: test-duration=time\n\t:noindex:\n\n\tHow long the entire test takes to run.  When the unit is omitted, the value\n\tis given in seconds.  Default: 24h.\n\n.. option:: threads-per-queue=int\n\t:noindex:\n\n\tNumber of read I/O threads per device.  Default: 8.\n\n.. option:: read-req-num-512-blocks=int\n\t:noindex:\n\n\tNumber of 512B blocks to read at the time.  Default: 3.\n\n.. option:: large-block-op-kbytes=int\n\t:noindex:\n\n\tSize of large block ops in KiB (writes).  Default: 131072.\n\n.. option:: prep\n\t:noindex:\n\n\tSet to run ACT prep phase.\n\nTiobench profile options\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. option:: size=str\n\t:noindex:\n\n\tSize in MiB.\n\n.. option:: block=int\n\t:noindex:\n\n\tBlock size in bytes.  Default: 4096.\n\n.. option:: numruns=int\n\t:noindex:\n\n\tNumber of runs.\n\n.. option:: dir=str\n\t:noindex:\n\n\tTest directory.\n\n.. option:: threads=int\n\t:noindex:\n\n\tNumber of threads.\n\nInterpreting the output\n-----------------------\n\n..\n\tExample output was based on the following:\n\tTZ=UTC fio --iodepth=8 --ioengine=null --size=100M --time_based \\\n\t\t--rate=1256k --bs=14K --name=quick --runtime=1s --name=mixed \\\n\t\t--runtime=2m --rw=rw\n\nFio spits out a lot of output. While running, fio will display the status of the\njobs created. An example of that would be::\n\n    Jobs: 1 (f=1): [_(1),M(1)][24.8%][r=20.5MiB/s,w=23.5MiB/s][r=82,w=94 IOPS][eta 01m:31s]\n\nThe characters inside the first set of square brackets denote the current status of\neach thread.  The first character is the first job defined in the job file, and so\nforth.  The possible values (in typical life cycle order) are:\n\n+------+-----+-----------------------------------------------------------+\n| Idle | Run |                                                           |\n+======+=====+===========================================================+\n| P    |     | Thread setup, but not started.                            |\n+------+-----+-----------------------------------------------------------+\n| C    |     | Thread created.                                           |\n+------+-----+-----------------------------------------------------------+\n| I    |     | Thread initialized, waiting or generating necessary data. |\n+------+-----+-----------------------------------------------------------+\n|      |  p  | Thread running pre-reading file(s).                       |\n+------+-----+-----------------------------------------------------------+\n|      |  /  | Thread is in ramp period.                                 |\n+------+-----+-----------------------------------------------------------+\n|      |  R  | Running, doing sequential reads.                          |\n+------+-----+-----------------------------------------------------------+\n|      |  r  | Running, doing random reads.                              |\n+------+-----+-----------------------------------------------------------+\n|      |  W  | Running, doing sequential writes.                         |\n+------+-----+-----------------------------------------------------------+\n|      |  w  | Running, doing random writes.                             |\n+------+-----+-----------------------------------------------------------+\n|      |  M  | Running, doing mixed sequential reads/writes.             |\n+------+-----+-----------------------------------------------------------+\n|      |  m  | Running, doing mixed random reads/writes.                 |\n+------+-----+-----------------------------------------------------------+\n|      |  D  | Running, doing sequential trims.                          |\n+------+-----+-----------------------------------------------------------+\n|      |  d  | Running, doing random trims.                              |\n+------+-----+-----------------------------------------------------------+\n|      |  F  | Running, currently waiting for :manpage:`fsync(2)`.       |\n+------+-----+-----------------------------------------------------------+\n|      |  V  | Running, doing verification of written data.              |\n+------+-----+-----------------------------------------------------------+\n| f    |     | Thread finishing.                                         |\n+------+-----+-----------------------------------------------------------+\n| E    |     | Thread exited, not reaped by main thread yet.             |\n+------+-----+-----------------------------------------------------------+\n| _    |     | Thread reaped.                                            |\n+------+-----+-----------------------------------------------------------+\n| X    |     | Thread reaped, exited with an error.                      |\n+------+-----+-----------------------------------------------------------+\n| K    |     | Thread reaped, exited due to signal.                      |\n+------+-----+-----------------------------------------------------------+\n\n..\n\tExample output was based on the following:\n\tTZ=UTC fio --iodepth=8 --ioengine=null --size=100M --runtime=58m \\\n\t\t--time_based --rate=2512k --bs=256K --numjobs=10 \\\n\t\t--name=readers --rw=read --name=writers --rw=write\n\nFio will condense the thread string as not to take up more space on the command\nline than needed. For instance, if you have 10 readers and 10 writers running,\nthe output would look like this::\n\n    Jobs: 20 (f=20): [R(10),W(10)][4.0%][r=20.5MiB/s,w=23.5MiB/s][r=82,w=94 IOPS][eta 57m:36s]\n\nNote that the status string is displayed in order, so it's possible to tell which of\nthe jobs are currently doing what.  In the example above this means that jobs 1--10\nare readers and 11--20 are writers.\n\nThe other values are fairly self explanatory -- number of threads currently\nrunning and doing I/O, the number of currently open files (f=), the estimated\ncompletion percentage, the rate of I/O since last check (read speed listed first,\nthen write speed and optionally trim speed) in terms of bandwidth and IOPS,\nand time to completion for the current running group. It's impossible to estimate\nruntime of the following groups (if any).\n\n..\n\tExample output was based on the following:\n\tTZ=UTC fio --iodepth=16 --ioengine=posixaio --filename=/tmp/fiofile \\\n\t\t--direct=1 --size=100M --time_based --runtime=50s --rate_iops=89 \\\n\t\t--bs=7K --name=Client1 --rw=write\n\nWhen fio is done (or interrupted by :kbd:`Ctrl-C`), it will show the data for\neach thread, group of threads, and disks in that order. For each overall thread (or\ngroup) the output looks like::\n\n\tClient1: (groupid=0, jobs=1): err= 0: pid=16109: Sat Jun 24 12:07:54 2017\n\t  write: IOPS=88, BW=623KiB/s (638kB/s)(30.4MiB/50032msec)\n\t    slat (nsec): min=500, max=145500, avg=8318.00, stdev=4781.50\n\t    clat (usec): min=170, max=78367, avg=4019.02, stdev=8293.31\n\t     lat (usec): min=174, max=78375, avg=4027.34, stdev=8291.79\n\t    clat percentiles (usec):\n\t     |  1.00th=[  302],  5.00th=[  326], 10.00th=[  343], 20.00th=[  363],\n\t     | 30.00th=[  392], 40.00th=[  404], 50.00th=[  416], 60.00th=[  445],\n\t     | 70.00th=[  816], 80.00th=[ 6718], 90.00th=[12911], 95.00th=[21627],\n\t     | 99.00th=[43779], 99.50th=[51643], 99.90th=[68682], 99.95th=[72877],\n\t     | 99.99th=[78119]\n\t   bw (  KiB/s): min=  532, max=  686, per=0.10%, avg=622.87, stdev=24.82, samples=  100\n\t   iops        : min=   76, max=   98, avg=88.98, stdev= 3.54, samples=  100\n\t  lat (usec)   : 250=0.04%, 500=64.11%, 750=4.81%, 1000=2.79%\n\t  lat (msec)   : 2=4.16%, 4=1.84%, 10=4.90%, 20=11.33%, 50=5.37%\n\t  lat (msec)   : 100=0.65%\n\t  cpu          : usr=0.27%, sys=0.18%, ctx=12072, majf=0, minf=21\n\t  IO depths    : 1=85.0%, 2=13.1%, 4=1.8%, 8=0.1%, 16=0.0%, 32=0.0%, >=64=0.0%\n\t     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%\n\t     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%\n\t     issued rwt: total=0,4450,0, short=0,0,0, dropped=0,0,0\n\t     latency   : target=0, window=0, percentile=100.00%, depth=8\n\nThe job name (or first job's name when using :option:`group_reporting`) is printed,\nalong with the group id, count of jobs being aggregated, last error id seen (which\nis 0 when there are no errors), pid/tid of that thread and the time the job/group\ncompleted.  Below are the I/O statistics for each data direction performed (showing\nwrites in the example above).  In the order listed, they denote:\n\n**read/write/trim**\n\t\tThe string before the colon shows the I/O direction the statistics\n\t\tare for.  **IOPS** is the average I/Os performed per second.  **BW**\n\t\tis the average bandwidth rate shown as: value in power of 2 format\n\t\t(value in power of 10 format).  The last two values show: (**total\n\t\tI/O performed** in power of 2 format / **runtime** of that thread).\n\n**slat**\n\t\tSubmission latency (**min** being the minimum, **max** being the\n\t\tmaximum, **avg** being the average, **stdev** being the standard\n                deviation).  This is the time from when fio initialized the I/O\n                to submission.  For synchronous ioengines this includes the time\n                up until just before the ioengine's queue function is called.\n                For asynchronous ioengines this includes the time up through the\n                completion of the ioengine's queue function (and commit function\n                if it is defined). For sync I/O this row is not displayed as the\n                slat is negligible.  This value can be in nanoseconds,\n                microseconds or milliseconds --- fio will choose the most\n                appropriate base and print that (in the example above\n                nanoseconds was the best scale).  Note: in :option:`--minimal`\n                mode latencies are always expressed in microseconds.\n\n**clat**\n\t\tCompletion latency. Same names as slat, this denotes the time from\n                submission to completion of the I/O pieces. For sync I/O, this\n                represents the time from when the I/O was submitted to the\n                operating system to when it was completed. For asynchronous\n                ioengines this is the time from when the ioengine's queue (and\n                commit if available) functions were completed to when the I/O's\n                completion was reaped by fio.\n\n\t\tFor file and directory operation engines, **clat** denotes the time\n\t\tto complete one file or directory operation.\n\n\t\t  **filecreate engine**:the time cost to create a new file\n\n\t\t  **filestat engine**:\tthe time cost to look up an existing file\n\n\t\t  **filedelete engine**:the time cost to delete a file\n\n\t\t  **dircreate engine**:\tthe time cost to create a new directory\n\n\t\t  **dirstat engine**:\tthe time cost to look up an existing directory\n\n\t\t  **dirdelete engine**:\tthe time cost to delete a directory\n\n**lat**\n\t\tTotal latency. Same names as slat and clat, this denotes the time from\n\t\twhen fio created the I/O unit to completion of the I/O operation.\n                It is the sum of submission and completion latency.\n\n**bw**\n\t\tBandwidth statistics based on measurements from discrete\n\t\tintervals. Fio continuously monitors bytes transferred and I/O\n\t\toperations completed. By default fio calculates bandwidth in\n\t\teach half-second interval (see :option:`bwavgtime`) and reports\n\t\tdescriptive statistics for the measurements here. Same names as\n\t\tthe xlat stats, but also includes the number of samples taken\n\t\t(**samples**) and an approximate percentage of total aggregate\n\t\tbandwidth this thread received in its group (**per**). This\n\t\tlast value is only really useful if the threads in this group\n\t\tare on the same disk, since they are then competing for disk\n\t\taccess.\n\n\t\tFor file and directory operation engines, **bw** is meaningless.\n\n**iops**\n\t\tIOPS statistics based on measurements from discrete intervals.\n\t\tFor details see the description for bw above. See\n\t\t:option:`iopsavgtime` to control the duration of the intervals.\n\t\tSame values reported here as for bw except for percentage.\n\n\t\tFor file and directory operation engines, **iops** is the most\n\t\tfundamental index to denote the performance.\n\t\tIt means how many files or directories can be operated per second.\n\n\t\t  **filecreate engine**:number of files can be created per second\n\n\t\t  **filestat engine**:\tnumber of files can be looked up per second\n\n\t\t  **filedelete engine**:number of files can be deleted per second\n\n\t\t  **dircreate engine**:\tnumber of directories can be created per second\n\n\t\t  **dirstat engine**:\tnumber of directories can be looked up per second\n\n\t\t  **dirdelete engine**:\tnumber of directories can be deleted per second\n\n**lat (nsec/usec/msec)**\n\t\tThe distribution of I/O completion latencies. This is the time from when\n\t\tI/O leaves fio and when it gets completed. Unlike the separate\n\t\tread/write/trim sections above, the data here and in the remaining\n\t\tsections apply to all I/Os for the reporting group. 250=0.04% means that\n\t\t0.04% of the I/Os completed in under 250us. 500=64.11% means that 64.11%\n\t\tof the I/Os required 250 to 499us for completion.\n\n**cpu**\n\t\tCPU usage. User and system time, along with the number of context\n\t\tswitches this thread went through, usage of system and user time, and\n\t\tfinally the number of major and minor page faults. The CPU utilization\n\t\tnumbers are averages for the jobs in that reporting group, while the\n\t\tcontext and fault counters are summed.\n\n**IO depths**\n\t\tThe distribution of I/O depths over the job lifetime.  The numbers are\n\t\tdivided into powers of 2 and each entry covers depths from that value\n\t\tup to those that are lower than the next entry -- e.g., 16= covers\n\t\tdepths from 16 to 31.  Note that the range covered by a depth\n\t\tdistribution entry can be different to the range covered by the\n\t\tequivalent submit/complete distribution entry.\n\n**IO submit**\n\t\tHow many pieces of I/O were submitting in a single submit call. Each\n\t\tentry denotes that amount and below, until the previous entry -- e.g.,\n\t\t16=100% means that we submitted anywhere between 9 to 16 I/Os per submit\n\t\tcall.  Note that the range covered by a submit distribution entry can\n\t\tbe different to the range covered by the equivalent depth distribution\n\t\tentry.\n\n**IO complete**\n\t\tLike the above submit number, but for completions instead.\n\n**IO issued rwt**\n\t\tThe number of read/write/trim requests issued, and how many of them were\n\t\tshort or dropped.\n\n**IO latency**\n\t\tThese values are for :option:`latency_target` and related options. When\n\t\tthese options are engaged, this section describes the I/O depth required\n\t\tto meet the specified latency target.\n\n..\n\tExample output was based on the following:\n\tTZ=UTC fio --ioengine=null --iodepth=2 --size=100M --numjobs=2 \\\n\t\t--rate_process=poisson --io_limit=32M --name=read --bs=128k \\\n\t\t--rate=11M --name=write --rw=write --bs=2k --rate=700k\n\nAfter each client has been listed, the group statistics are printed. They\nwill look like this::\n\n    Run status group 0 (all jobs):\n       READ: bw=20.9MiB/s (21.9MB/s), 10.4MiB/s-10.8MiB/s (10.9MB/s-11.3MB/s), io=64.0MiB (67.1MB), run=2973-3069msec\n      WRITE: bw=1231KiB/s (1261kB/s), 616KiB/s-621KiB/s (630kB/s-636kB/s), io=64.0MiB (67.1MB), run=52747-53223msec\n\nFor each data direction it prints:\n\n**bw**\n\t\tAggregate bandwidth of threads in this group followed by the\n\t\tminimum and maximum bandwidth of all the threads in this group.\n\t\tValues outside of brackets are power-of-2 format and those\n\t\twithin are the equivalent value in a power-of-10 format.\n**io**\n\t\tAggregate I/O performed of all threads in this group. The\n\t\tformat is the same as bw.\n**run**\n\t\tThe smallest and longest runtimes of the threads in this group.\n\nAnd finally, the disk statistics are printed. This is Linux specific. They will look like this::\n\n  Disk stats (read/write):\n    sda: ios=16398/16511, sectors=32321/65472, merge=30/162, ticks=6853/819634, in_queue=826487, util=100.00%\n\nEach value is printed for both reads and writes, with reads first. The\nnumbers denote:\n\n**ios**\n\t\tNumber of I/Os performed by all groups.\n**sectors**\n\t\tAmount of data transferred in units of 512 bytes for all groups.\n**merge**\n\t\tNumber of merges performed by the I/O scheduler.\n**ticks**\n\t\tNumber of ticks we kept the disk busy.\n**in_queue**\n\t\tTotal time spent in the disk queue.\n**util**\n\t\tThe disk utilization. A value of 100% means we kept the disk\n\t\tbusy constantly, 50% would be a disk idling half of the time.\n\nIt is also possible to get fio to dump the current output while it is running,\nwithout terminating the job. To do that, send fio the **USR1** signal.  You can\nalso get regularly timed dumps by using the :option:`--status-interval`\nparameter, or by creating a file in :file:`/tmp` named\n:file:`fio-dump-status`. If fio sees this file, it will unlink it and dump the\ncurrent output status.\n\n\nTerse output\n------------\n\nFor scripted usage where you typically want to generate tables or graphs of the\nresults, fio can output the results in a semicolon separated format.  The format\nis one long line of values, such as::\n\n    2;card0;0;0;7139336;121836;60004;1;10109;27.932460;116.933948;220;126861;3495.446807;1085.368601;226;126864;3523.635629;1089.012448;24063;99944;50.275485%;59818.274627;5540.657370;7155060;122104;60004;1;8338;29.086342;117.839068;388;128077;5032.488518;1234.785715;391;128085;5061.839412;1236.909129;23436;100928;50.287926%;59964.832030;5644.844189;14.595833%;19.394167%;123706;0;7313;0.1%;0.1%;0.1%;0.1%;0.1%;0.1%;100.0%;0.00%;0.00%;0.00%;0.00%;0.00%;0.00%;0.01%;0.02%;0.05%;0.16%;6.04%;40.40%;52.68%;0.64%;0.01%;0.00%;0.01%;0.00%;0.00%;0.00%;0.00%;0.00%\n    A description of this job goes here.\n\nThe job description (if provided) follows on a second line for terse v2.\nIt appears on the same line for other terse versions.\n\nTo enable terse output, use the :option:`--minimal` or\n:option:`--output-format`\\=terse command line options. The\nfirst value is the version of the terse output format. If the output has to be\nchanged for some reason, this number will be incremented by 1 to signify that\nchange.\n\nSplit up, the format is as follows (comments in brackets denote when a\nfield was introduced or whether it's specific to some terse version):\n\n    ::\n\n        terse version, fio version [v3], jobname, groupid, error\n\n    READ status::\n\n        Total IO (KiB), bandwidth (KiB/sec), IOPS, runtime (msec)\n        Submission latency: min, max, mean, stdev (usec)\n        Completion latency: min, max, mean, stdev (usec)\n        Completion latency percentiles: 20 fields (see below)\n        Total latency: min, max, mean, stdev (usec)\n        Bw (KiB/s): min, max, aggregate percentage of total, mean, stdev, number of samples [v5]\n        IOPS [v5]: min, max, mean, stdev, number of samples\n\n    WRITE status:\n\n    ::\n\n        Total IO (KiB), bandwidth (KiB/sec), IOPS, runtime (msec)\n        Submission latency: min, max, mean, stdev (usec)\n        Completion latency: min, max, mean, stdev (usec)\n        Completion latency percentiles: 20 fields (see below)\n        Total latency: min, max, mean, stdev (usec)\n        Bw (KiB/s): min, max, aggregate percentage of total, mean, stdev, number of samples [v5]\n        IOPS [v5]: min, max, mean, stdev, number of samples\n\n    TRIM status [all but version 3]:\n\n        Fields are similar to READ/WRITE status.\n\n    CPU usage::\n\n        user, system, context switches, major faults, minor faults\n\n    I/O depths::\n\n        <=1, 2, 4, 8, 16, 32, >=64\n\n    I/O latencies microseconds::\n\n        <=2, 4, 10, 20, 50, 100, 250, 500, 750, 1000\n\n    I/O latencies milliseconds::\n\n        <=2, 4, 10, 20, 50, 100, 250, 500, 750, 1000, 2000, >=2000\n\n    Disk utilization [v3]::\n\n        disk name, read ios, write ios, read merges, write merges, read ticks, write ticks,\n        time spent in queue, disk utilization percentage\n\n    Additional Info (dependent on continue_on_error, default off)::\n\n        total # errors, first error code\n\n    Additional Info (dependent on description being set)::\n\n        Text description\n\nCompletion latency percentiles can be a grouping of up to 20 sets, so for the\nterse output fio writes all of them. Each field will look like this::\n\n        1.00%=6112\n\nwhich is the Xth percentile, and the `usec` latency associated with it.\n\nFor `Disk utilization`, all disks used by fio are shown. So for each disk there\nwill be a disk utilization section.\n\nBelow is a single line containing short names for each of the fields in the\nminimal output v3, separated by semicolons::\n\n        terse_version_3;fio_version;jobname;groupid;error;read_kb;read_bandwidth_kb;read_iops;read_runtime_ms;read_slat_min_us;read_slat_max_us;read_slat_mean_us;read_slat_dev_us;read_clat_min_us;read_clat_max_us;read_clat_mean_us;read_clat_dev_us;read_clat_pct01;read_clat_pct02;read_clat_pct03;read_clat_pct04;read_clat_pct05;read_clat_pct06;read_clat_pct07;read_clat_pct08;read_clat_pct09;read_clat_pct10;read_clat_pct11;read_clat_pct12;read_clat_pct13;read_clat_pct14;read_clat_pct15;read_clat_pct16;read_clat_pct17;read_clat_pct18;read_clat_pct19;read_clat_pct20;read_tlat_min_us;read_lat_max_us;read_lat_mean_us;read_lat_dev_us;read_bw_min_kb;read_bw_max_kb;read_bw_agg_pct;read_bw_mean_kb;read_bw_dev_kb;write_kb;write_bandwidth_kb;write_iops;write_runtime_ms;write_slat_min_us;write_slat_max_us;write_slat_mean_us;write_slat_dev_us;write_clat_min_us;write_clat_max_us;write_clat_mean_us;write_clat_dev_us;write_clat_pct01;write_clat_pct02;write_clat_pct03;write_clat_pct04;write_clat_pct05;write_clat_pct06;write_clat_pct07;write_clat_pct08;write_clat_pct09;write_clat_pct10;write_clat_pct11;write_clat_pct12;write_clat_pct13;write_clat_pct14;write_clat_pct15;write_clat_pct16;write_clat_pct17;write_clat_pct18;write_clat_pct19;write_clat_pct20;write_tlat_min_us;write_lat_max_us;write_lat_mean_us;write_lat_dev_us;write_bw_min_kb;write_bw_max_kb;write_bw_agg_pct;write_bw_mean_kb;write_bw_dev_kb;cpu_user;cpu_sys;cpu_csw;cpu_mjf;cpu_minf;iodepth_1;iodepth_2;iodepth_4;iodepth_8;iodepth_16;iodepth_32;iodepth_64;lat_2us;lat_4us;lat_10us;lat_20us;lat_50us;lat_100us;lat_250us;lat_500us;lat_750us;lat_1000us;lat_2ms;lat_4ms;lat_10ms;lat_20ms;lat_50ms;lat_100ms;lat_250ms;lat_500ms;lat_750ms;lat_1000ms;lat_2000ms;lat_over_2000ms;disk_name;disk_read_iops;disk_write_iops;disk_read_merges;disk_write_merges;disk_read_ticks;write_ticks;disk_queue_time;disk_util\n\nIn client/server mode terse output differs from what appears when jobs are run\nlocally. Disk utilization data is omitted from the standard terse output and\nfor v3 and later appears on its own separate line at the end of each terse\nreporting cycle.\n\n\nJSON output\n------------\n\nThe `json` output format is intended to be both human readable and convenient\nfor automated parsing. For the most part its sections mirror those of the\n`normal` output. The `runtime` value is reported in msec and the `bw` value is\nreported in 1024 bytes per second units.\n\n\nJSON+ output\n------------\n\nThe `json+` output format is identical to the `json` output format except that it\nadds a full dump of the completion latency bins. Each `bins` object contains a\nset of (key, value) pairs where keys are latency durations and values count how\nmany I/Os had completion latencies of the corresponding duration. For example,\nconsider:\n\n\t\"bins\" : { \"87552\" : 1, \"89600\" : 1, \"94720\" : 1, \"96768\" : 1, \"97792\" : 1, \"99840\" : 1, \"100864\" : 2, \"103936\" : 6, \"104960\" : 534, \"105984\" : 5995, \"107008\" : 7529, ... }\n\nThis data indicates that one I/O required 87,552ns to complete, two I/Os required\n100,864ns to complete, and 7529 I/Os required 107,008ns to complete.\n\nAlso included with fio is a Python script `fio_jsonplus_clat2csv` that takes\njson+ output and generates CSV-formatted latency data suitable for plotting.\n\nThe latency durations actually represent the midpoints of latency intervals.\nFor details refer to :file:`stat.h`.\n\n\nTrace file format\n-----------------\n\nThere are two trace file format that you can encounter. The older (v1) format is\nunsupported since version 1.20-rc3 (March 2008). It will still be described\nbelow in case that you get an old trace and want to understand it.\n\nIn any case the trace is a simple text file with a single action per line.\n\n\nTrace file format v1\n~~~~~~~~~~~~~~~~~~~~\n\nEach line represents a single I/O action in the following format::\n\n\trw, offset, length\n\nwhere `rw=0/1` for read/write, and the `offset` and `length` entries being in bytes.\n\nThis format is not supported in fio versions >= 1.20-rc3.\n\n\nTrace file format v2\n~~~~~~~~~~~~~~~~~~~~\n\nThe second version of the trace file format was added in fio version 1.17.  It\nallows one to access more than one file per trace and has a bigger set of possible\nfile actions.\n\nThe first line of the trace file has to be::\n\n    fio version 2 iolog\n\nFollowing this can be lines in two different formats, which are described below.\n\nThe file management format::\n\n    filename action\n\nThe `filename` is given as an absolute path. The `action` can be one of these:\n\n**add**\n\t\tAdd the given `filename` to the trace.\n**open**\n\t\tOpen the file with the given `filename`. The `filename` has to have\n\t\tbeen added with the **add** action before.\n**close**\n\t\tClose the file with the given `filename`. The file has to have been\n\t\topened before.\n\n\nThe file I/O action format::\n\n    filename action offset length\n\nThe `filename` is given as an absolute path, and has to have been added and\nopened before it can be used with this format. The `offset` and `length` are\ngiven in bytes. The `action` can be one of these:\n\n**wait**\n\t   Wait for `offset` microseconds. Everything below 100 is discarded.\n\t   The time is relative to the previous `wait` statement. Note that\n\t   action `wait` is not allowed as of version 3, as the same behavior\n\t   can be achieved using timestamps.\n**read**\n\t   Read `length` bytes beginning from `offset`.\n**write**\n\t   Write `length` bytes beginning from `offset`.\n**sync**\n\t   :manpage:`fsync(2)` the file.\n**datasync**\n\t   :manpage:`fdatasync(2)` the file.\n**trim**\n\t   Trim the given file from the given `offset` for `length` bytes.\n\n\nTrace file format v3\n~~~~~~~~~~~~~~~~~~~~\n\nThe third version of the trace file format was added in fio version 3.31. It\nforces each action to have a timestamp associated with it.\n\nThe first line of the trace file has to be::\n\n    fio version 3 iolog\n\nFollowing this can be lines in two different formats, which are described below.\n\nThe file management format::\n\n    timestamp filename action\n\nThe file I/O action format::\n\n    timestamp filename action offset length\n\nThe `timestamp` is relative to the beginning of the run (ie starts at 0). The\n`filename`, `action`, `offset` and `length`  are identical to version 2, except\nthat version 3 does not allow the `wait` action.\n\n\nI/O Replay - Merging Traces\n---------------------------\n\nColocation is a common practice used to get the most out of a machine.\nKnowing which workloads play nicely with each other and which ones don't is\na much harder task. While fio can replay workloads concurrently via multiple\njobs, it leaves some variability up to the scheduler making results harder to\nreproduce. Merging is a way to make the order of events consistent.\n\nMerging is integrated into I/O replay and done when a\n:option:`merge_blktrace_file` is specified. The list of files passed to\n:option:`read_iolog` go through the merge process and output a single file\nstored to the specified file. The output file is passed on as if it were the\nonly file passed to :option:`read_iolog`. An example would look like::\n\n\t$ fio --read_iolog=\"<file1>:<file2>\" --merge_blktrace_file=\"<output_file>\"\n\nCreating only the merged file can be done by passing the command line argument\n:option:`--merge-blktrace-only`.\n\nScaling traces can be done to see the relative impact of any particular trace\nbeing slowed down or sped up. :option:`merge_blktrace_scalars` takes in a colon\nseparated list of percentage scalars. It is index paired with the files passed\nto :option:`read_iolog`.\n\nWith scaling, it may be desirable to match the running time of all traces.\nThis can be done with :option:`merge_blktrace_iters`. It is index paired with\n:option:`read_iolog` just like :option:`merge_blktrace_scalars`.\n\nIn an example, given two traces, A and B, each 60s long. If we want to see\nthe impact of trace A issuing IOs twice as fast and repeat trace A over the\nruntime of trace B, the following can be done::\n\n\t$ fio --read_iolog=\"<trace_a>:\"<trace_b>\" --merge_blktrace_file\"<output_file>\" --merge_blktrace_scalars=\"50:100\" --merge_blktrace_iters=\"2:1\"\n\nThis runs trace A at 2x the speed twice for approximately the same runtime as\na single run of trace B.\n\n\nCPU idleness profiling\n----------------------\n\nIn some cases, we want to understand CPU overhead in a test. For example, we\ntest patches for the specific goodness of whether they reduce CPU usage.\nFio implements a balloon approach to create a thread per CPU that runs at idle\npriority, meaning that it only runs when nobody else needs the cpu.\nBy measuring the amount of work completed by the thread, idleness of each CPU\ncan be derived accordingly.\n\nAn unit work is defined as touching a full page of unsigned characters. Mean and\nstandard deviation of time to complete an unit work is reported in \"unit work\"\nsection. Options can be chosen to report detailed percpu idleness or overall\nsystem idleness by aggregating percpu stats.\n\n\nVerification and triggers\n-------------------------\n\nFio is usually run in one of two ways, when data verification is done. The first\nis a normal write job of some sort with verify enabled. When the write phase has\ncompleted, fio switches to reads and verifies everything it wrote. The second\nmodel is running just the write phase, and then later on running the same job\n(but with reads instead of writes) to repeat the same I/O patterns and verify\nthe contents. Both of these methods depend on the write phase being completed,\nas fio otherwise has no idea how much data was written.\n\nWith verification triggers, fio supports dumping the current write state to\nlocal files. Then a subsequent read verify workload can load this state and know\nexactly where to stop. This is useful for testing cases where power is cut to a\nserver in a managed fashion, for instance.\n\nA verification trigger consists of two things:\n\n1) Storing the write state of each job.\n2) Executing a trigger command.\n\nThe write state is relatively small, on the order of hundreds of bytes to single\nkilobytes. It contains information on the number of completions done, the last X\ncompletions, etc.\n\nA trigger is invoked either through creation ('touch') of a specified file in\nthe system, or through a timeout setting. If fio is run with\n:option:`--trigger-file`\\= :file:`/tmp/trigger-file`, then it will continually\ncheck for the existence of :file:`/tmp/trigger-file`. When it sees this file, it\nwill fire off the trigger (thus saving state, and executing the trigger\ncommand).\n\nFor client/server runs, there's both a local and remote trigger. If fio is\nrunning as a server backend, it will send the job states back to the client for\nsafe storage, then execute the remote trigger, if specified. If a local trigger\nis specified, the server will still send back the write state, but the client\nwill then execute the trigger.\n\nVerification trigger example\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nLet's say we want to run a powercut test on the remote Linux machine 'server'.\nOur write workload is in :file:`write-test.fio`. We want to cut power to 'server' at\nsome point during the run, and we'll run this test from the safety or our local\nmachine, 'localbox'. On the server, we'll start the fio backend normally::\n\n\tserver# fio --server\n\nand on the client, we'll fire off the workload::\n\n\tlocalbox$ fio --client=server --trigger-file=/tmp/my-trigger --trigger-remote=\"bash -c \\\"echo b > /proc/sysrq-triger\\\"\"\n\nWe set :file:`/tmp/my-trigger` as the trigger file, and we tell fio to execute::\n\n\techo b > /proc/sysrq-trigger\n\non the server once it has received the trigger and sent us the write state. This\nwill work, but it's not **really** cutting power to the server, it's merely\nabruptly rebooting it. If we have a remote way of cutting power to the server\nthrough IPMI or similar, we could do that through a local trigger command\ninstead. Let's assume we have a script that does IPMI reboot of a given hostname,\nipmi-reboot. On localbox, we could then have run fio with a local trigger\ninstead::\n\n\tlocalbox$ fio --client=server --trigger-file=/tmp/my-trigger --trigger=\"ipmi-reboot server\"\n\nFor this case, fio would wait for the server to send us the write state, then\nexecute ``ipmi-reboot server`` when that happened.\n\nLoading verify state\n~~~~~~~~~~~~~~~~~~~~\n\nTo load stored write state, a read verification job file must contain the\n:option:`verify_state_load` option. If that is set, fio will load the previously\nstored state. For a local fio run this is done by loading the files directly,\nand on a client/server run, the server backend will ask the client to send the\nfiles over and load them from there.\n\n\nLog File Formats\n----------------\n\nFio supports a variety of log file formats, for logging latencies, bandwidth,\nand IOPS. The logs share a common format, which looks like this:\n\n    *time* (`msec`), *value*, *data direction*, *block size* (`bytes`),\n    *offset* (`bytes`), *command priority*, *issue time* (`nsec`)\n\n*Time* for the log entry is always in milliseconds. The *value* logged depends\non the type of log, it will be one of the following:\n\n    **Latency log**\n\t\tValue is latency in nsecs\n    **Bandwidth log**\n\t\tValue is in KiB/sec\n    **IOPS log**\n\t\tValue is IOPS\n\n*Data direction* is one of the following:\n\n\t**0**\n\t\tI/O is a READ\n\t**1**\n\t\tI/O is a WRITE\n\t**2**\n\t\tI/O is a TRIM\n\nThe entry's *block size* is always in bytes. The *offset* is the position in bytes\nfrom the start of the file for that particular I/O. The logging of the offset can be\ntoggled with :option:`log_offset`.\n\nIf :option:`log_prio` is not set, the entry's *Command priority* is 1 for an IO\nexecuted with the highest RT priority class (:option:`prioclass` =1 or\n:option:`cmdprio_class` =1) and 0 otherwise. This is controlled by the\n:option:`prioclass` option and the ioengine specific\n:option:`cmdprio_percentage`  :option:`cmdprio_class` options. If\n:option:`log_prio` is set, the entry's *Command priority* is the priority set\nfor the IO, as a 16-bits hexadecimal number with the lowest 13 bits indicating\nthe priority value (:option:`prio` and :option:`cmdprio` options) and the\nhighest 3 bits indicating the IO priority class (:option:`prioclass` and\n:option:`cmdprio_class` options).\n\nThe entry's *issue time* is the command issue time in nanoseconds. The logging\nof the issue time can be toggled with :option:`log_issue_time`. This field has\nvalid values in completion latency log file (clat), or submit latency log file\n(slat). The field has value 0 in other logs files.\n\nFio defaults to logging every individual I/O but when windowed logging is set\nthrough :option:`log_avg_msec`, either the average (by default), the maximum\n(:option:`log_window_value` is set to max) *value* seen over the specified period\nof time, or both the average *value* and maximum *value1* (:option:`log_window_value`\nis set to both) is recorded. The log file format when both the values are reported\ntakes this form:\n\n    *time* (`msec`), *value*, *value1*, *data direction*, *block size* (`bytes`),\n    *offset* (`bytes`), *command priority*, *issue time* (`nsec`)\n\n\nEach *data direction* seen within the window period will aggregate its values in a\nseparate row. Further, when using windowed logging the *block size*, *offset*\nand *issue time* entries will always contain 0.\n\n\nClient/Server\n-------------\n\nNormally fio is invoked as a stand-alone application on the machine where the\nI/O workload should be generated. However, the backend and frontend of fio can\nbe run separately i.e., the fio server can generate an I/O workload on the \"Device\nUnder Test\" while being controlled by a client on another machine.\n\nStart the server on the machine which has access to the storage DUT::\n\n\t$ fio --server=args\n\nwhere `args` defines what fio listens to. The arguments are of the form\n``type,hostname`` or ``IP,port``. *type* is either ``ip`` (or ip4) for TCP/IP\nv4, ``ip6`` for TCP/IP v6, or ``sock`` for a local unix domain socket.\n*hostname* is either a hostname or IP address, and *port* is the port to listen\nto (only valid for TCP/IP, not a local socket). Some examples:\n\n1) ``fio --server``\n\n   Start a fio server, listening on all interfaces on the default port (8765).\n\n2) ``fio --server=ip:hostname,4444``\n\n   Start a fio server, listening on IP belonging to hostname and on port 4444.\n\n3) ``fio --server=ip6:::1,4444``\n\n   Start a fio server, listening on IPv6 localhost ::1 and on port 4444.\n\n4) ``fio --server=,4444``\n\n   Start a fio server, listening on all interfaces on port 4444.\n\n5) ``fio --server=1.2.3.4``\n\n   Start a fio server, listening on IP 1.2.3.4 on the default port.\n\n6) ``fio --server=sock:/tmp/fio.sock``\n\n   Start a fio server, listening on the local socket :file:`/tmp/fio.sock`.\n\nOnce a server is running, a \"client\" can connect to the fio server with::\n\n\tfio <local-args> --client=<server> <remote-args> <job file(s)>\n\nwhere `local-args` are arguments for the client where it is running, `server`\nis the connect string, and `remote-args` and `job file(s)` are sent to the\nserver. The `server` string follows the same format as it does on the server\nside, to allow IP/hostname/socket and port strings.\n\nNote that all job options must be defined in job files when running fio as a\nclient. Any job options specified in `remote-args` will be ignored.\n\nFio can connect to multiple servers this way::\n\n    fio --client=<server1> <job file(s)> --client=<server2> <job file(s)>\n\nIf the job file is located on the fio server, then you can tell the server to\nload a local file as well. This is done by using :option:`--remote-config` ::\n\n   fio --client=server --remote-config /path/to/file.fio\n\nThen fio will open this local (to the server) job file instead of being passed\none from the client.\n\nIf you have many servers (example: 100 VMs/containers), you can input a pathname\nof a file containing host IPs/names as the parameter value for the\n:option:`--client` option.  For example, here is an example :file:`host.list`\nfile containing 2 hostnames::\n\n\thost1.your.dns.domain\n\thost2.your.dns.domain\n\nThe fio command would then be::\n\n    fio --client=host.list <job file(s)>\n\nIn this mode, you cannot input server-specific parameters or job files -- all\nservers receive the same job file.\n\nIn order to let ``fio --client`` runs use a shared filesystem from multiple\nhosts, ``fio --client`` now prepends the IP address of the server to the\nfilename.  For example, if fio is using the directory :file:`/mnt/nfs/fio` and is\nwriting filename :file:`fileio.tmp`, with a :option:`--client` `hostfile`\ncontaining two hostnames ``h1`` and ``h2`` with IP addresses 192.168.10.120 and\n192.168.10.121, then fio will create two files::\n\n\t/mnt/nfs/fio/192.168.10.120.fileio.tmp\n\t/mnt/nfs/fio/192.168.10.121.fileio.tmp\n\nThis behavior can be disabled by the :option:`unique_filename` option.\n\nTerse output in client/server mode will differ slightly from what is produced\nwhen fio is run in stand-alone mode. See the terse output section for details.\n\nAlso, if one fio invocation runs workloads on multiple servers, fio will\nprovide at the end an aggregate summary report for all workloads. This\naggregate summary report assumes that options affecting reporting like\n:option:`unified_rw_reporting` and :option:`percentile_list` are identical\nacross all the jobs summarized. Having different values for these options is an\nunsupported configuration.\n"
        },
        {
          "name": "MORAL-LICENSE",
          "type": "blob",
          "size": 0.890625,
          "content": "As specified by the COPYING file, fio is free software published under version\n2 of the GPL license. That covers the copying part of the license. When using\nfio, you are encouraged to uphold the following moral obligations:\n\n- If you publish results that are done using fio, it should be clearly stated\n  that fio was used. The specific version should also be listed.\n\n- If you develop features or bug fixes for fio, they should be sent upstream\n  for inclusion into the main repository. This isn't specific to fio, that\n  is a general rule for any open source project. It's just the Right Thing\n  to do. Plus it means that you don't have to maintain the feature or change\n  internally. In the long run, this is saving you a lot of time.\n\nI would consider the above to fall under \"common courtesy\", but since\npeople tend to have differing opinions of that, it doesn't hurt to spell out\nmy expectations clearly.\n\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 20.0673828125,
          "content": "ifeq ($(SRCDIR),)\nSRCDIR := .\nendif\n\nVPATH := $(SRCDIR)\n\nall: fio\n\nconfig-host.mak: configure\n\t@if [ ! -e \"$@\" ]; then\t\t\t\t\t\\\n\t  echo \"Running configure ...\";\t\t\t\t\\\n\t  ./configure;\t\t\t\t\t\t\\\n\telse\t\t\t\t\t\t\t\\\n\t  echo \"$@ is out-of-date, running configure\";\t\t\\\n\t  sed -n \"/.*Configured with/s/[^:]*: //p\" \"$@\" | sh;\t\\\n\tfi\n\nifneq ($(MAKECMDGOALS),clean)\ninclude config-host.mak\nendif\n\nDEBUGFLAGS = -DFIO_INC_DEBUG\nCPPFLAGS+= -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -DFIO_INTERNAL $(DEBUGFLAGS)\nOPTFLAGS= -g -ffast-math\nFIO_CFLAGS= -std=gnu99 -Wwrite-strings -Wall -Wdeclaration-after-statement $(OPTFLAGS) $(EXTFLAGS) $(BUILD_CFLAGS) -I. -I$(SRCDIR)\nLIBS\t+= -lm $(EXTLIBS)\nPROGS\t= fio\nSCRIPTS = $(addprefix $(SRCDIR)/,tools/fio_generate_plots tools/plot/fio2gnuplot tools/genfio tools/fiologparser.py tools/hist/fiologparser_hist.py tools/hist/fio-histo-log-pctiles.py tools/fio_jsonplus_clat2csv)\n\nifndef CONFIG_FIO_NO_OPT\n  FIO_CFLAGS += -O3\nendif\nifdef CONFIG_BUILD_NATIVE\n  FIO_CFLAGS += -march=native\nendif\n\nifdef CONFIG_PDB\n  LINK_PDBFILE ?= -Wl,-pdb,$(dir $@)/$(basename $(@F)).pdb\n  FIO_CFLAGS += -gcodeview\n  LDFLAGS += -fuse-ld=lld $(LINK_PDBFILE)\nendif\n\n# If clang, do not use builtin stpcpy as it breaks the build\nifeq ($(CC),clang)\n  FIO_CFLAGS += -fno-builtin-stpcpy\nendif\n\nifdef CONFIG_GFIO\n  PROGS += gfio\nendif\n\nSOURCE :=\t$(sort $(patsubst $(SRCDIR)/%,%,$(wildcard $(SRCDIR)/crc/*.c)) \\\n\t\t$(patsubst $(SRCDIR)/%,%,$(wildcard $(SRCDIR)/lib/*.c))) \\\n\t\tgettime.c ioengines.c init.c stat.c log.c time.c filesetup.c \\\n\t\teta.c verify.c memory.c io_u.c parse.c fio_sem.c rwlock.c \\\n\t\tpshared.c options.c \\\n\t\tsmalloc.c filehash.c profile.c debug.c engines/cpu.c \\\n\t\tengines/mmap.c engines/sync.c engines/null.c engines/net.c \\\n\t\tengines/ftruncate.c engines/fileoperations.c \\\n\t\tengines/exec.c \\\n\t\tserver.c client.c iolog.c backend.c libfio.c flow.c cconv.c \\\n\t\tgettime-thread.c helpers.c json.c idletime.c td_error.c \\\n\t\tprofiles/tiobench.c profiles/act.c io_u_queue.c filelock.c \\\n\t\tworkqueue.c rate-submit.c optgroup.c helper_thread.c \\\n\t\tsteadystate.c zone-dist.c zbd.c dedupe.c dataplacement.c\n\nifdef CONFIG_LIBHDFS\n  HDFSFLAGS= -I $(JAVA_HOME)/include -I $(JAVA_HOME)/include/linux -I $(FIO_LIBHDFS_INCLUDE)\n  HDFSLIB= -Wl,-rpath $(JAVA_HOME)/lib/$(FIO_HDFS_CPU)/server -L$(JAVA_HOME)/lib/$(FIO_HDFS_CPU)/server $(FIO_LIBHDFS_LIB)/libhdfs.a -ljvm\n  FIO_CFLAGS += $(HDFSFLAGS)\n  SOURCE += engines/libhdfs.c\nendif\n\nifdef CONFIG_LIBISCSI\n  libiscsi_SRCS = engines/libiscsi.c\n  libiscsi_LIBS = $(LIBISCSI_LIBS)\n  libiscsi_CFLAGS = $(LIBISCSI_CFLAGS)\n  ENGINES += libiscsi\nendif\n\nifdef CONFIG_LIBNBD\n  nbd_SRCS = engines/nbd.c\n  nbd_LIBS = $(LIBNBD_LIBS)\n  nbd_CFLAGS = $(LIBNBD_CFLAGS)\n  ENGINES += nbd\nendif\n\nifdef CONFIG_LIBNFS\n  CFLAGS += $(LIBNFS_CFLAGS)\n  LIBS += $(LIBNFS_LIBS)\n  SOURCE += engines/nfs.c\nendif\n\nifdef CONFIG_64BIT\n  CPPFLAGS += -DBITS_PER_LONG=64\nelse ifdef CONFIG_32BIT\n  CPPFLAGS += -DBITS_PER_LONG=32\nendif\nifdef CONFIG_LIBAIO\n  libaio_SRCS = engines/libaio.c\n  cmdprio_SRCS = engines/cmdprio.c\n  LIBS += -laio\n  libaio_LIBS = -laio\n  ENGINES += libaio\nendif\nifdef CONFIG_RDMA\n  rdma_SRCS = engines/rdma.c\n  rdma_LIBS = -libverbs -lrdmacm\n  ENGINES += rdma\nendif\nifdef CONFIG_POSIXAIO\n  SOURCE += engines/posixaio.c\nendif\nifdef CONFIG_LINUX_FALLOCATE\n  SOURCE += engines/falloc.c\nendif\nifdef CONFIG_LINUX_EXT4_MOVE_EXTENT\n  SOURCE += engines/e4defrag.c\nendif\nifdef CONFIG_LIBCUFILE\n  SOURCE += engines/libcufile.c\nendif\nifdef CONFIG_LINUX_SPLICE\n  SOURCE += engines/splice.c\nendif\nifdef CONFIG_SOLARISAIO\n  SOURCE += engines/solarisaio.c\nendif\nifdef CONFIG_WINDOWSAIO\n  SOURCE += engines/windowsaio.c\nendif\nifdef CONFIG_RADOS\n  rados_SRCS = engines/rados.c\n  rados_LIBS = -lrados\n  ENGINES += rados\nendif\nifdef CONFIG_RBD\n  rbd_SRCS = engines/rbd.c\n  rbd_LIBS = -lrbd -lrados\n  ENGINES += rbd\nendif\nifdef CONFIG_HTTP\n  http_SRCS = engines/http.c\n  http_LIBS = -lcurl -lssl -lcrypto\n  ENGINES += http\nendif\nifdef CONFIG_DFS\n  dfs_SRCS = engines/dfs.c\n  dfs_LIBS = -luuid -ldaos -ldfs\n  ENGINES += dfs\nendif\nSOURCE += oslib/asprintf.c\nifndef CONFIG_STRSEP\n  SOURCE += oslib/strsep.c\nendif\nifndef CONFIG_STRCASESTR\n  SOURCE += oslib/strcasestr.c\nendif\nifndef CONFIG_STRLCAT\n  SOURCE += oslib/strlcat.c\nendif\nifndef CONFIG_HAVE_STRNDUP\n  SOURCE += oslib/strndup.c\nendif\nifndef CONFIG_GETOPT_LONG_ONLY\n  SOURCE += oslib/getopt_long.c\nendif\nifndef CONFIG_INET_ATON\n  SOURCE += oslib/inet_aton.c\nendif\nifndef CONFIG_HAVE_STATX\n  SOURCE += oslib/statx.c\nendif\nifdef CONFIG_GFAPI\n  SOURCE += engines/glusterfs.c\n  SOURCE += engines/glusterfs_sync.c\n  SOURCE += engines/glusterfs_async.c\n  LIBS += -lgfapi -lglusterfs\n  ifdef CONFIG_GF_FADVISE\n    FIO_CFLAGS += \"-DGFAPI_USE_FADVISE\"\n  endif\nendif\nifdef CONFIG_MTD\n  SOURCE += engines/mtd.c\n  SOURCE += oslib/libmtd.c\n  SOURCE += oslib/libmtd_legacy.c\nendif\nifdef CONFIG_LINUX_DEVDAX\n  dev-dax_SRCS = engines/dev-dax.c\n  dev-dax_LIBS = -lpmem\n  ENGINES += dev-dax\nendif\nifdef CONFIG_LIBPMEM\n  libpmem_SRCS = engines/libpmem.c\n  libpmem_LIBS = -lpmem\n  ENGINES += libpmem\nendif\nifdef CONFIG_IME\n  SOURCE += engines/ime.c\nendif\nifdef CONFIG_LIBZBC\n  libzbc_SRCS = engines/libzbc.c\n  libzbc_LIBS = -lzbc\n  ENGINES += libzbc\nendif\nifdef CONFIG_LIBXNVME\n  xnvme_SRCS = engines/xnvme.c\n  xnvme_LIBS = $(LIBXNVME_LIBS)\n  xnvme_CFLAGS = $(LIBXNVME_CFLAGS)\n  ENGINES += xnvme\nendif\nifdef CONFIG_LIBBLKIO\n  libblkio_SRCS = engines/libblkio.c\n  libblkio_LIBS = $(LIBBLKIO_LIBS)\n  libblkio_CFLAGS = $(LIBBLKIO_CFLAGS)\n  ENGINES += libblkio\nendif\nifeq ($(CONFIG_TARGET_OS), Linux)\n  SOURCE += diskutil.c fifo.c blktrace.c cgroup.c trim.c engines/sg.c \\\n\t\toslib/linux-dev-lookup.c engines/io_uring.c engines/nvme.c\n  cmdprio_SRCS = engines/cmdprio.c\nifdef CONFIG_HAS_BLKZONED\n  SOURCE += oslib/linux-blkzoned.c\nendif\n  LIBS += -lpthread -ldl\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), Android)\n  SOURCE += diskutil.c fifo.c blktrace.c cgroup.c trim.c profiles/tiobench.c \\\n\t\toslib/linux-dev-lookup.c engines/io_uring.c engines/nvme.c \\\n\t\tengines/sg.c\n  cmdprio_SRCS = engines/cmdprio.c\nifdef CONFIG_HAS_BLKZONED\n  SOURCE += oslib/linux-blkzoned.c\nendif\n  LIBS += -ldl -llog\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), SunOS)\n  LIBS\t += -lpthread -ldl\n  CPPFLAGS += -D__EXTENSIONS__\nendif\nifeq ($(CONFIG_TARGET_OS), FreeBSD)\n  SOURCE += trim.c\n  LIBS\t += -lpthread -lrt\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), OpenBSD)\n  LIBS\t += -lpthread\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), NetBSD)\n  LIBS\t += -lpthread -lrt\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), DragonFly)\n  SOURCE += trim.c\n  LIBS\t += -lpthread -lrt\n  LDFLAGS += -rdynamic\nendif\nifeq ($(CONFIG_TARGET_OS), AIX)\n  LIBS\t += -lpthread -ldl -lrt\n  CPPFLAGS += -D_LARGE_FILES -D__ppc__\n  LDFLAGS += -L/opt/freeware/lib -Wl,-blibpath:/opt/freeware/lib:/usr/lib:/lib -Wl,-bmaxdata:0x80000000\nendif\nifeq ($(CONFIG_TARGET_OS), HP-UX)\n  LIBS   += -lpthread -ldl -lrt\n  FIO_CFLAGS += -D_LARGEFILE64_SOURCE -D_XOPEN_SOURCE_EXTENDED\nendif\nifeq ($(CONFIG_TARGET_OS), Darwin)\n  LIBS\t += -lpthread -ldl\nendif\nifneq (,$(findstring CYGWIN,$(CONFIG_TARGET_OS)))\n  SOURCE += os/windows/cpu-affinity.c os/windows/posix.c os/windows/dlls.c\n  WINDOWS_OBJS = os/windows/cpu-affinity.o os/windows/posix.o os/windows/dlls.o lib/hweight.o\n  LIBS\t += -lpthread -lpsapi -lws2_32 -lssp\n  FIO_CFLAGS += -DPSAPI_VERSION=1 -Ios/windows/posix/include -Wno-format\nendif\n\nifdef cmdprio_SRCS\n  SOURCE += $(cmdprio_SRCS)\nendif\n\nifdef CONFIG_DYNAMIC_ENGINES\n DYNAMIC_ENGS := $(ENGINES)\ndefine engine_template =\n$(1)_OBJS := $$($(1)_SRCS:.c=.o)\n$$($(1)_OBJS): CFLAGS := -fPIC $$($(1)_CFLAGS) $(CFLAGS)\nengines/fio-$(1).so: $$($(1)_OBJS)\n\t$$(QUIET_LINK)$(CC) $(LDFLAGS) -shared -rdynamic -fPIC -Wl,-soname,fio-$(1).so.1 -o $$@ $$< $$($(1)_LIBS)\nENGS_OBJS += engines/fio-$(1).so\nendef\nelse # !CONFIG_DYNAMIC_ENGINES\ndefine engine_template =\nSOURCE += $$($(1)_SRCS)\nLIBS += $$($(1)_LIBS)\noverride CFLAGS += $$($(1)_CFLAGS)\nendef\nendif\n\nFIO-VERSION-FILE: FORCE\n\t@$(SHELL) $(SRCDIR)/FIO-VERSION-GEN\n-include FIO-VERSION-FILE\n\noverride CFLAGS := -DFIO_VERSION='\"$(FIO_VERSION)\"' $(FIO_CFLAGS) $(CFLAGS)\n\n$(foreach eng,$(ENGINES),$(eval $(call engine_template,$(eng))))\n\nOBJS := $(SOURCE:.c=.o)\n\nFIO_OBJS = $(OBJS) fio.o\n\nGFIO_OBJS = $(OBJS) gfio.o graph.o tickmarks.o ghelpers.o goptions.o gerror.o \\\n\t\t\tgclient.o gcompat.o cairo_text_helpers.o printing.o\n\nifdef CONFIG_ARITHMETIC\nFIO_OBJS += lex.yy.o y.tab.o\nGFIO_OBJS += lex.yy.o y.tab.o\nendif\n\n-include $(OBJS:.o=.d)\n\nT_SMALLOC_OBJS = t/stest.o\nT_SMALLOC_OBJS += gettime.o fio_sem.o pshared.o smalloc.o t/log.o t/debug.o \\\n\t\t  t/arch.o\nT_SMALLOC_PROGS = t/stest\n\nT_IEEE_OBJS = t/ieee754.o\nT_IEEE_OBJS += lib/ieee754.o\nT_IEEE_PROGS = t/ieee754\n\nT_ZIPF_OBS = t/genzipf.o\nT_ZIPF_OBJS += t/log.o lib/ieee754.o lib/rand.o lib/pattern.o lib/zipf.o \\\n\t\tlib/strntol.o lib/gauss.o t/genzipf.o oslib/strcasestr.o \\\n\t\toslib/strndup.o\nT_ZIPF_PROGS = t/fio-genzipf\n\nT_AXMAP_OBJS = t/axmap.o\nT_AXMAP_OBJS += lib/lfsr.o lib/axmap.o\nT_AXMAP_PROGS = t/axmap\n\nT_LFSR_TEST_OBJS = t/lfsr-test.o\nT_LFSR_TEST_OBJS += lib/lfsr.o gettime.o fio_sem.o pshared.o \\\n\t\t    t/log.o t/debug.o t/arch.o\nT_LFSR_TEST_PROGS = t/lfsr-test\n\nT_GEN_RAND_OBJS = t/gen-rand.o\nT_GEN_RAND_OBJS += t/log.o t/debug.o lib/rand.o lib/pattern.o lib/strntol.o \\\n\t\t\toslib/strcasestr.o oslib/strndup.o\nT_GEN_RAND_PROGS = t/gen-rand\n\nifeq ($(CONFIG_TARGET_OS), Linux)\nT_BTRACE_FIO_OBJS = t/btrace2fio.o\nT_BTRACE_FIO_OBJS += fifo.o lib/flist_sort.o t/log.o oslib/linux-dev-lookup.o\nT_BTRACE_FIO_PROGS = t/fio-btrace2fio\nendif\n\nT_DEDUPE_OBJS = t/dedupe.o\nT_DEDUPE_OBJS += lib/rbtree.o t/log.o fio_sem.o pshared.o smalloc.o gettime.o \\\n\t\tcrc/md5.o lib/memalign.o lib/bloom.o t/debug.o crc/xxhash.o \\\n\t\tt/arch.o crc/murmur3.o crc/crc32c.o crc/crc32c-intel.o \\\n\t\tcrc/crc32c-arm64.o crc/fnv.o\nT_DEDUPE_PROGS = t/fio-dedupe\n\nT_VS_OBJS = t/verify-state.o t/log.o crc/crc32c.o crc/crc32c-intel.o crc/crc32c-arm64.o t/debug.o\nT_VS_PROGS = t/fio-verify-state\n\nT_PIPE_ASYNC_OBJS = t/read-to-pipe-async.o\nT_PIPE_ASYNC_PROGS = t/read-to-pipe-async\n\nT_IOU_RING_OBJS = t/io_uring.o lib/rand.o lib/pattern.o lib/strntol.o\nT_IOU_RING_PROGS = t/io_uring\n\nT_MEMLOCK_OBJS = t/memlock.o\nT_MEMLOCK_PROGS = t/memlock\n\nT_TT_OBJS = t/time-test.o\nT_TT_PROGS = t/time-test\n\nifneq (,$(findstring -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION,$(CFLAGS)))\nT_FUZZ_OBJS = t/fuzz/fuzz_parseini.o\nT_FUZZ_OBJS += $(OBJS)\nifdef CONFIG_ARITHMETIC\nT_FUZZ_OBJS += lex.yy.o y.tab.o\nendif\n# For proper fio code teardown CFLAGS needs to include -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION\n# in case there is no fuzz driver defined by environment variable LIB_FUZZING_ENGINE, use a simple one\n# For instance, with compiler clang, address sanitizer and libFuzzer as a fuzzing engine, you should define\n# export CFLAGS=\"-fsanitize=address,fuzzer-no-link -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION\"\n# export LIB_FUZZING_ENGINE=\"-fsanitize=address\"\n# export CC=clang\n# before running configure && make\n# You can adapt this with different compilers, sanitizers, and fuzzing engines\nifndef LIB_FUZZING_ENGINE\nT_FUZZ_OBJS += t/fuzz/onefile.o\nendif\nT_FUZZ_PROGS = t/fuzz/fuzz_parseini\nelse\t# CFLAGS includes -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION\nT_FUZZ_OBJS =\nT_FUZZ_PROGS =\nendif\n\nT_OBJS = $(T_SMALLOC_OBJS)\nT_OBJS += $(T_IEEE_OBJS)\nT_OBJS += $(T_ZIPF_OBJS)\nT_OBJS += $(T_AXMAP_OBJS)\nT_OBJS += $(T_LFSR_TEST_OBJS)\nT_OBJS += $(T_GEN_RAND_OBJS)\nT_OBJS += $(T_BTRACE_FIO_OBJS)\nT_OBJS += $(T_DEDUPE_OBJS)\nT_OBJS += $(T_VS_OBJS)\nT_OBJS += $(T_PIPE_ASYNC_OBJS)\nT_OBJS += $(T_MEMLOCK_OBJS)\nT_OBJS += $(T_TT_OBJS)\nT_OBJS += $(T_IOU_RING_OBJS)\nT_OBJS += $(T_FUZZ_OBJS)\n\nifneq (,$(findstring CYGWIN,$(CONFIG_TARGET_OS)))\n    T_DEDUPE_OBJS += $(WINDOWS_OBJS)\n    T_SMALLOC_OBJS += $(WINDOWS_OBJS)\n    T_LFSR_TEST_OBJS += $(WINDOWS_OBJS)\nendif\n\nT_TEST_PROGS = $(T_SMALLOC_PROGS)\nT_TEST_PROGS += $(T_IEEE_PROGS)\nT_PROGS += $(T_ZIPF_PROGS)\nT_TEST_PROGS += $(T_AXMAP_PROGS)\nT_TEST_PROGS += $(T_LFSR_TEST_PROGS)\nT_TEST_PROGS += $(T_GEN_RAND_PROGS)\nT_PROGS += $(T_BTRACE_FIO_PROGS)\nifdef CONFIG_ZLIB\nT_PROGS += $(T_DEDUPE_PROGS)\nendif\nT_PROGS += $(T_VS_PROGS)\nT_TEST_PROGS += $(T_MEMLOCK_PROGS)\nifdef CONFIG_PREAD\nT_TEST_PROGS += $(T_PIPE_ASYNC_PROGS)\nendif\nifneq (,$(findstring Linux,$(CONFIG_TARGET_OS)))\nT_TEST_PROGS += $(T_IOU_RING_PROGS)\nendif\nT_TEST_PROGS += $(T_FUZZ_PROGS)\n\nPROGS += $(T_PROGS)\n\nifdef CONFIG_HAVE_CUNIT\nUT_OBJS = unittests/unittest.o\nUT_OBJS += unittests/lib/memalign.o\nUT_OBJS += unittests/lib/num2str.o\nUT_OBJS += unittests/lib/strntol.o\nUT_OBJS += unittests/oslib/strlcat.o\nUT_OBJS += unittests/oslib/strndup.o\nUT_OBJS += unittests/oslib/strcasestr.o\nUT_OBJS += unittests/oslib/strsep.o\nUT_TARGET_OBJS = lib/memalign.o\nUT_TARGET_OBJS += lib/num2str.o\nUT_TARGET_OBJS += lib/strntol.o\nUT_TARGET_OBJS += oslib/strlcat.o\nUT_TARGET_OBJS += oslib/strndup.o\nUT_TARGET_OBJS += oslib/strcasestr.o\nUT_TARGET_OBJS += oslib/strsep.o\nUT_PROGS = unittests/unittest\nelse\nUT_OBJS =\nUT_TARGET_OBJS =\nUT_PROGS =\nendif\n\nifneq ($(findstring $(MAKEFLAGS),s),s)\nifndef V\n\tQUIET_CC\t= @echo '   ' CC $@;\n\tQUIET_LINK\t= @echo ' ' LINK $@;\n\tQUIET_DEP\t= @echo '  ' DEP $@;\n\tQUIET_YACC\t= @echo ' ' YACC $@;\n\tQUIET_LEX\t= @echo '  ' LEX $@;\nendif\nendif\n\nifeq ($(CONFIG_TARGET_OS), SunOS)\n\tINSTALL = ginstall\nelse\n\tINSTALL = install\nendif\nprefix = $(INSTALL_PREFIX)\nbindir = $(prefix)/bin\nlibdir = $(prefix)/lib/fio\n\nifeq ($(CONFIG_TARGET_OS), Darwin)\nmandir = /usr/share/man\nsharedir = /usr/share/fio\nelse\nmandir = $(prefix)/man\nsharedir = $(prefix)/share/fio\nendif\n\nall: $(PROGS) $(T_TEST_PROGS) $(UT_PROGS) $(SCRIPTS) $(ENGS_OBJS) FORCE\n\n.PHONY: all install clean test\n.PHONY: FORCE cscope\n\n%.o : %.c\n\t@mkdir -p $(dir $@)\n\t$(QUIET_CC)$(CC) -o $@ $(CFLAGS) $(CPPFLAGS) -c $<\n\t@$(CC) -MM $(CFLAGS) $(CPPFLAGS) $(SRCDIR)/$*.c > $*.d\n\t@mv -f $*.d $*.d.tmp\n\t@sed -e 's|.*:|$*.o:|' < $*.d.tmp > $*.d\n\t@if type -p fmt >/dev/null 2>&1; then\t\t\t\t\\\n\t\tsed -e 's/.*://' -e 's/\\\\$$//' < $*.d.tmp | fmt -w 1 |\t\\\n\t\tsed -e 's/^ *//' -e 's/$$/:/' >> $*.d;\t\t\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\tsed -e 's/.*://' -e 's/\\\\$$//' < $*.d.tmp |\t\t\\\n\t\ttr -cs \"[:graph:]\" \"\\n\" |\t\t\t\t\\\n\t\tsed -e 's/^ *//' -e '/^$$/ d' -e 's/$$/:/' >> $*.d;\t\\\n\tfi\n\t@rm -f $*.d.tmp\n\nifdef CONFIG_ARITHMETIC\nlex.yy.c: exp/expression-parser.l\nifdef CONFIG_LEX_USE_O\n\t$(QUIET_LEX)$(LEX) -o $@ $<\nelse\n\t$(QUIET_LEX)$(LEX) $<\nendif\n\nifneq (,$(findstring -Wimplicit-fallthrough,$(CFLAGS)))\nLEX_YY_CFLAGS := -Wno-implicit-fallthrough\nendif\n\nifdef CONFIG_HAVE_NO_STRINGOP\nYTAB_YY_CFLAGS := -Wno-stringop-truncation\nendif\n\nlex.yy.o: lex.yy.c y.tab.h\n\t$(QUIET_CC)$(CC) -o $@ $(CFLAGS) $(CPPFLAGS) $(LEX_YY_CFLAGS) -c $<\n\ny.tab.o: y.tab.c y.tab.h\n\t$(QUIET_CC)$(CC) -o $@ $(CFLAGS) $(CPPFLAGS) $(YTAB_YY_CFLAGS) -c $<\n\ny.tab.c: exp/expression-parser.y\n\t$(QUIET_YACC)$(YACC) -o $@ -l -d -b y $<\n\ny.tab.h: y.tab.c\n\nlexer.h: lex.yy.c\n\nexp/test-expression-parser.o: exp/test-expression-parser.c\n\t$(QUIET_CC)$(CC) -o $@ $(CFLAGS) $(CPPFLAGS) -c $<\nexp/test-expression-parser: exp/test-expression-parser.o\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) $< y.tab.o lex.yy.o -o $@ $(LIBS)\n\nparse.o: lex.yy.o y.tab.o\nendif\n\ninit.o: init.c FIO-VERSION-FILE\n\ngcompat.o: gcompat.c gcompat.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ngoptions.o: goptions.c goptions.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\nghelpers.o: ghelpers.c ghelpers.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ngerror.o: gerror.c gerror.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ngclient.o: gclient.c gclient.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ngfio.o: gfio.c ghelpers.c\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ngraph.o: graph.c graph.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\ncairo_text_helpers.o: cairo_text_helpers.c cairo_text_helpers.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\nprinting.o: printing.c printing.h\n\t$(QUIET_CC)$(CC) $(CFLAGS) $(GTK_CFLAGS) $(CPPFLAGS) -c $<\n\nt/io_uring.o: os/linux/io_uring.h\nt/io_uring: $(T_IOU_RING_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_IOU_RING_OBJS) $(LIBS)\n\nt/read-to-pipe-async: $(T_PIPE_ASYNC_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_PIPE_ASYNC_OBJS) $(LIBS)\n\nt/memlock: $(T_MEMLOCK_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_MEMLOCK_OBJS) $(LIBS)\n\nt/stest: $(T_SMALLOC_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_SMALLOC_OBJS) $(LIBS)\n\nt/ieee754: $(T_IEEE_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_IEEE_OBJS) $(LIBS)\n\nfio: $(FIO_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(FIO_OBJS) $(LIBS) $(HDFSLIB)\n\nt/fuzz/fuzz_parseini: $(T_FUZZ_OBJS)\nifndef LIB_FUZZING_ENGINE\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_FUZZ_OBJS) $(LIBS) $(HDFSLIB)\nelse\n\t$(QUIET_LINK)$(CXX) $(LDFLAGS) -o $@ $(T_FUZZ_OBJS) $(LIB_FUZZING_ENGINE) $(LIBS) $(HDFSLIB)\nendif\n\ngfio: $(GFIO_OBJS)\n\t$(QUIET_LINK)$(CC) $(filter-out -static, $(LDFLAGS)) -o gfio $(GFIO_OBJS) $(LIBS) $(GFIO_LIBS) $(GTK_LDFLAGS) $(HDFSLIB)\n\nt/fio-genzipf: $(T_ZIPF_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_ZIPF_OBJS) $(LIBS)\n\nt/axmap: $(T_AXMAP_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_AXMAP_OBJS) $(LIBS)\n\nt/lfsr-test: $(T_LFSR_TEST_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_LFSR_TEST_OBJS) $(LIBS)\n\nt/gen-rand: $(T_GEN_RAND_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_GEN_RAND_OBJS) $(LIBS)\n\nifeq ($(CONFIG_TARGET_OS), Linux)\nt/fio-btrace2fio: $(T_BTRACE_FIO_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_BTRACE_FIO_OBJS) $(LIBS)\nendif\n\nifdef CONFIG_ZLIB\nt/fio-dedupe: $(T_DEDUPE_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_DEDUPE_OBJS) $(LIBS)\nendif\n\nt/fio-verify-state: $(T_VS_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_VS_OBJS) $(LIBS)\n\nt/time-test: $(T_TT_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(T_TT_OBJS) $(LIBS)\n\nifdef CONFIG_HAVE_CUNIT\nunittests/unittest: $(UT_OBJS) $(UT_TARGET_OBJS)\n\t$(QUIET_LINK)$(CC) $(LDFLAGS) -o $@ $(UT_OBJS) $(UT_TARGET_OBJS) -lcunit $(LIBS)\nendif\n\nclean: FORCE\n\t@rm -f .depend $(FIO_OBJS) $(GFIO_OBJS) $(OBJS) $(T_OBJS) $(UT_OBJS) $(PROGS) $(T_PROGS) $(T_TEST_PROGS) core.* core gfio unittests/unittest FIO-VERSION-FILE *.[do] lib/*.d oslib/*.[do] crc/*.d engines/*.[do] engines/*.so profiles/*.[do] t/*.[do] t/*/*.[do] unittests/*.[do] unittests/*/*.[do] config-host.mak config-host.h y.tab.[ch] lex.yy.c exp/*.[do] lexer.h\n\t@rm -f t/fio-btrace2fio t/io_uring t/read-to-pipe-async\n\t@rm -rf  doc/output\n\ndistclean: clean FORCE\n\t@rm -f cscope.out fio.pdf fio_generate_plots.pdf fio2gnuplot.pdf fiologparser_hist.pdf\n\ncscope:\n\t@cscope -b -R\n\ntools/plot/fio2gnuplot.1:\n\t@cat tools/plot/fio2gnuplot.manpage | txt2man -t fio2gnuplot >  tools/plot/fio2gnuplot.1\n\ndoc: tools/plot/fio2gnuplot.1\n\t@man -t ./fio.1 | ps2pdf - fio.pdf\n\t@man -t tools/fio_generate_plots.1 | ps2pdf - fio_generate_plots.pdf\n\t@man -t tools/plot/fio2gnuplot.1 | ps2pdf - fio2gnuplot.pdf\n\t@man -t tools/hist/fiologparser_hist.py.1 | ps2pdf - fiologparser_hist.pdf\n\ntest: fio\n\t./fio --minimal --thread --exitall_on_error --runtime=1s --name=nulltest --ioengine=null --rw=randrw --iodepth=2 --norandommap --random_generator=tausworthe64 --size=16T --name=verifyfstest --filename=fiotestfile.tmp --unlink=1 --rw=write --verify=crc32c --verify_state_save=0 --size=16K\n\nfulltest:\n\tsudo modprobe null_blk &&\t\t\t\t \t\\\n\tif [ ! -e /usr/include/libzbc/zbc.h ]; then\t\t\t\\\n\t  git clone https://github.com/westerndigitalcorporation/libzbc && \\\n\t  (cd libzbc &&\t\t\t\t\t\t \t\\\n\t   ./autogen.sh &&\t\t\t\t\t \t\\\n\t   ./configure --prefix=/usr &&\t\t\t\t \t\\\n\t   make -j &&\t\t\t\t\t\t \t\\\n\t   sudo make install)\t\t\t\t\t\t\\\n\tfi &&\t\t\t\t\t \t\t\t\\\n\tsudo t/zbd/run-tests-against-nullb -s 1 &&\t\t \t\\\n\tif [ -e /sys/module/null_blk/parameters/zoned ]; then\t\t\\\n\t\tsudo t/zbd/run-tests-against-nullb -s 2;\t \t\\\n\t\tsudo t/zbd/run-tests-against-nullb -s 4;\t \t\\\n\tfi\n\ninstall: $(PROGS) $(SCRIPTS) $(ENGS_OBJS) tools/plot/fio2gnuplot.1 FORCE\n\t$(INSTALL) -m 755 -d $(DESTDIR)$(bindir)\n\t$(INSTALL) $(PROGS) $(SCRIPTS) $(DESTDIR)$(bindir)\nifdef CONFIG_DYNAMIC_ENGINES\n\t$(INSTALL) -m 755 -d $(DESTDIR)$(libdir)\n\t$(INSTALL) -m 755 $(SRCDIR)/engines/*.so $(DESTDIR)$(libdir)\nendif\n\t$(INSTALL) -m 755 -d $(DESTDIR)$(mandir)/man1\n\t$(INSTALL) -m 644 $(SRCDIR)/fio.1 $(DESTDIR)$(mandir)/man1\n\t$(INSTALL) -m 644 $(SRCDIR)/tools/fio_generate_plots.1 $(DESTDIR)$(mandir)/man1\n\t$(INSTALL) -m 644 $(SRCDIR)/tools/plot/fio2gnuplot.1 $(DESTDIR)$(mandir)/man1\n\t$(INSTALL) -m 644 $(SRCDIR)/tools/hist/fiologparser_hist.py.1 $(DESTDIR)$(mandir)/man1\n\t$(INSTALL) -m 755 -d $(DESTDIR)$(sharedir)\n\t$(INSTALL) -m 644 $(SRCDIR)/tools/plot/*gpm $(DESTDIR)$(sharedir)/\n\n.PHONY: test fulltest\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 10.6953125,
          "content": "Overview and history\n--------------------\n\nFio was originally written to save me the hassle of writing special test case\nprograms when I wanted to test a specific workload, either for performance\nreasons or to find/reproduce a bug. The process of writing such a test app can\nbe tiresome, especially if you have to do it often.  Hence I needed a tool that\nwould be able to simulate a given I/O workload without resorting to writing a\ntailored test case again and again.\n\nA test work load is difficult to define, though. There can be any number of\nprocesses or threads involved, and they can each be using their own way of\ngenerating I/O. You could have someone dirtying large amounts of memory in a\nmemory mapped file, or maybe several threads issuing reads using asynchronous\nI/O. fio needed to be flexible enough to simulate both of these cases, and many\nmore.\n\nFio spawns a number of threads or processes doing a particular type of I/O\naction as specified by the user. fio takes a number of global parameters, each\ninherited by the thread unless otherwise parameters given to them overriding\nthat setting is given.  The typical use of fio is to write a job file matching\nthe I/O load one wants to simulate.\n\n\nSource\n------\n\nFio resides in a git repo, the canonical place is:\n\n\thttps://git.kernel.dk/cgit/fio/\n\nSnapshots are frequently generated and :file:`fio-git-*.tar.gz` include the git\nmeta data as well. Other tarballs are archives of official fio releases.\nSnapshots can download from:\n\n\thttps://brick.kernel.dk/snaps/\n\nThere are also two official mirrors. Both of these are automatically synced with\nthe main repository, when changes are pushed. If the main repo is down for some\nreason, either one of these is safe to use as a backup:\n\n\thttps://git.kernel.org/pub/scm/linux/kernel/git/axboe/fio.git\n\n\thttps://github.com/axboe/fio.git\n\n\nMailing list\n------------\n\nThe fio project mailing list is meant for anything related to fio including\ngeneral discussion, bug reporting, questions, and development. For bug reporting,\nsee REPORTING-BUGS.\n\nAn automated mail detailing recent commits is automatically sent to the list at\nmost daily. The list address is fio@vger.kernel.org, subscribe by sending an\nemail to fio+subscribe@vger.kernel.org or visit\nhttps://subspace.kernel.org/vger.kernel.org.html.\n\nArchives can be found here:\n\n\thttps://www.spinics.net/lists/fio/\n\nor here:\n\n\thttps://lore.kernel.org/fio/\n\nand archives for the old list can be found here:\n\n\thttp://maillist.kernel.dk/fio-devel/\n\n\nAuthor\n------\n\nFio was written by Jens Axboe <axboe@kernel.dk> to enable flexible testing of\nthe Linux I/O subsystem and schedulers. He got tired of writing specific test\napplications to simulate a given workload, and found that the existing I/O\nbenchmark/test tools out there weren't flexible enough to do what he wanted.\n\nJens Axboe <axboe@kernel.dk> 20060905\n\n\nMaintainers\n-----------\n\nFio is maintained by Jens Axboe <axboe@kernel.dk and\nVincent Fu <vincentfu@gmail.com> - however, for reporting bugs please use\nthe fio reflector or the GitHub page rather than email any of them\ndirectly. By using the public resources, others will be able to learn from\nthe responses too. Chances are also good that other members will be able to\nhelp with your inquiry as well.\n\n\nBinary packages\n---------------\n\nDebian:\n\tStarting with Debian \"Squeeze\", fio packages are part of the official\n\tDebian repository. https://packages.debian.org/search?keywords=fio .\n\nUbuntu:\n\tStarting with Ubuntu 10.04 LTS (aka \"Lucid Lynx\"), fio packages are part\n\tof the Ubuntu \"universe\" repository.\n\thttps://packages.ubuntu.com/search?keywords=fio .\n\nRed Hat, Fedora, CentOS & Co:\n\tStarting with Fedora 9/Extra Packages for Enterprise Linux 4, fio\n\tpackages are part of the Fedora/EPEL repositories.\n\thttps://packages.fedoraproject.org/pkgs/fio/ .\n\nMandriva:\n\tMandriva has integrated fio into their package repository, so installing\n\ton that distro should be as easy as typing ``urpmi fio``.\n\nArch Linux:\n        An Arch Linux package is provided under the Community sub-repository:\n        https://www.archlinux.org/packages/?sort=&q=fio\n\nSolaris:\n\tPackages for Solaris are available from OpenCSW. Install their pkgutil\n\ttool (http://www.opencsw.org/get-it/pkgutil/) and then install fio via\n\t``pkgutil -i fio``.\n\nWindows:\n        Beginning with fio 3.31 Windows installers for tagged releases are\n        available on GitHub at https://github.com/axboe/fio/releases. The\n        latest installers for Windows can also be obtained as GitHub Actions\n        artifacts by selecting a build from\n        https://github.com/axboe/fio/actions. These require logging in to a\n        GitHub account.\n\nBSDs:\n\tPackages for BSDs may be available from their binary package repositories.\n\tLook for a package \"fio\" using their binary package managers.\n\n\nBuilding\n--------\n\nJust type::\n\n $ ./configure\n $ make\n $ make install\n\nNote that GNU make is required. On BSDs it's available from devel/gmake within\nports directory; on Solaris it's in the SUNWgmake package.  On platforms where\nGNU make isn't the default, type ``gmake`` instead of ``make``.\n\nConfigure will print the enabled options. Note that on Linux based platforms,\nthe libaio development packages must be installed to use the libaio\nengine. Depending on the distro, it is usually called libaio-devel or libaio-dev.\n\nFor gfio, gtk 2.18 (or newer), associated glib threads, and cairo are required\nto be installed.  gfio isn't built automatically and can be enabled with a\n``--enable-gfio`` option to configure.\n\nTo build fio with a cross-compiler::\n\n $ make clean\n $ make CROSS_COMPILE=/path/to/toolchain/prefix\n\nConfigure will attempt to determine the target platform automatically.\n\nIt's possible to build fio for ESX as well, use the ``--esx`` switch to\nconfigure.\n\n\nWindows\n~~~~~~~\n\nThe minimum versions of Windows for building/running fio are Windows 7/Windows\nServer 2008 R2. On Windows, Cygwin (https://www.cygwin.com/) is required in\norder to build fio. To create an MSI installer package install WiX from\nhttps://wixtoolset.org and run :file:`dobuild.cmd` from the :file:`os/windows`\ndirectory.\n\nHow to compile fio on 64-bit Windows:\n\n 1. Install Cygwin (https://www.cygwin.com/). Install **make** and all\n    packages starting with **mingw64-x86_64**. Ensure\n    **mingw64-x86_64-zlib** are installed if you wish\n    to enable fio's log compression functionality.\n 2. Open the Cygwin Terminal.\n 3. Go to the fio directory (source files).\n 4. Run ``make clean && make -j``.\n\nTo build fio for 32-bit Windows, ensure the -i686 versions of the previously\nmentioned -x86_64 packages are installed and run ``./configure\n--build-32bit-win`` before ``make``.\n\nIt's recommended that once built or installed, fio be run in a Command Prompt or\nother 'native' console such as console2, since there are known to be display and\nsignal issues when running it under a Cygwin shell (see\nhttps://github.com/mintty/mintty/issues/56 and\nhttps://github.com/mintty/mintty/wiki/Tips#inputoutput-interaction-with-alien-programs\nfor details).\n\n\nDocumentation\n~~~~~~~~~~~~~\n\nFio uses Sphinx_ to generate documentation from the reStructuredText_ files.\nTo build HTML formatted documentation run ``make -C doc html`` and direct your\nbrowser to :file:`./doc/output/html/index.html`.  To build manual page run\n``make -C doc man`` and then ``man doc/output/man/fio.1``.  To see what other\noutput formats are supported run ``make -C doc help``.\n\n.. _reStructuredText: https://www.sphinx-doc.org/rest.html\n.. _Sphinx: https://www.sphinx-doc.org\n\n\nPlatforms\n---------\n\nFio works on (at least) Linux, Solaris, AIX, HP-UX, OSX, NetBSD, OpenBSD,\nWindows, FreeBSD, and DragonFly. Some features and/or options may only be\navailable on some of the platforms, typically because those features only apply\nto that platform (like the solarisaio engine, or the splice engine on Linux).\n\nSome features are not available on FreeBSD/Solaris even if they could be\nimplemented, I'd be happy to take patches for that. An example of that is disk\nutility statistics and (I think) huge page support, support for that does exist\nin FreeBSD/Solaris.\n\nFio uses pthread mutexes for signaling and locking and some platforms do not\nsupport process shared pthread mutexes. As a result, on such platforms only\nthreads are supported. This could be fixed with sysv ipc locking or other\nlocking alternatives.\n\nOther \\*BSD platforms are untested, but fio should work there almost out of the\nbox. Since I don't do test runs or even compiles on those platforms, your\nmileage may vary. Sending me patches for other platforms is greatly\nappreciated. There's a lot of value in having the same test/benchmark tool\navailable on all platforms.\n\nNote that POSIX aio is not enabled by default on AIX. Messages like these::\n\n    Symbol resolution failed for /usr/lib/libc.a(posix_aio.o) because:\n        Symbol _posix_kaio_rdwr (number 2) is not exported from dependent module /unix.\n\nindicate one needs to enable POSIX aio. Run the following commands as root::\n\n    # lsdev -C -l posix_aio0\n        posix_aio0 Defined  Posix Asynchronous I/O\n    # cfgmgr -l posix_aio0\n    # lsdev -C -l posix_aio0\n        posix_aio0 Available  Posix Asynchronous I/O\n\nPOSIX aio should work now. To make the change permanent::\n\n    # chdev -l posix_aio0 -P -a autoconfig='available'\n        posix_aio0 changed\n\n\nRunning fio\n-----------\n\nRunning fio is normally the easiest part - you just give it the job file\n(or job files) as parameters::\n\n\t$ fio [options] [jobfile] ...\n\nand it will start doing what the *jobfile* tells it to do. You can give more\nthan one job file on the command line, fio will serialize the running of those\nfiles. Internally that is the same as using the :option:`stonewall` parameter\ndescribed in the parameter section.\n\nIf the job file contains only one job, you may as well just give the parameters\non the command line. The command line parameters are identical to the job\nparameters, with a few extra that control global parameters.  For example, for\nthe job file parameter :option:`iodepth=2 <iodepth>`, the mirror command line\noption would be :option:`--iodepth 2 <iodepth>` or :option:`--iodepth=2\n<iodepth>`. You can also use the command line for giving more than one job\nentry. For each :option:`--name <name>` option that fio sees, it will start a\nnew job with that name.  Command line entries following a\n:option:`--name <name>` entry will apply to that job, until there are no more\nentries or a new :option:`--name <name>` entry is seen. This is similar to the\njob file options, where each option applies to the current job until a new []\njob entry is seen.\n\nfio does not need to run as root, except if the files or devices specified in\nthe job section requires that. Some other options may also be restricted, such\nas memory locking, I/O scheduler switching, and decreasing the nice value.\n\nIf *jobfile* is specified as ``-``, the job file will be read from standard\ninput.\n"
        },
        {
          "name": "REPORTING-BUGS",
          "type": "blob",
          "size": 1.599609375,
          "content": "Reporting a bug\n---------------\n\n...via the mailing list\n=======================\n\nIf you notice anything that seems like a fio bug or want to ask fio related\nquestions, please send a plain-text only email to the list\n(fio@vger.kernel.org, see README) about it. If you are not running the newest\nrelease of fio please upgrade first.\n\nWhen reporting a bug, you'll need to include:\n\n1) A description of what you think the bug is\n2) Environment (e.g. Linux distro version, kernel version). This is mostly\n   needed if it's a build bug.\n3) The output from fio --version .\n4) How to reproduce. Please include a full list of the parameters\n   passed to fio and the job file used (if any).\n\nA bug report can't have too much information. Any time information that\nis left out and has to be asked for will add to the turn-around time\nof getting to the bottom of the issue, and an eventual fix.\n\nThat's it!\n\n...via GitHub issues\n====================\n\nPlease create an issue in the GitHub issue tracker\n(https://github.com/axboe/fio/issues ) but observe the following:\n\na) If you are asking a question on how to do something (\"How do I/Why is?\")\n   please send it to the mailing list and not GitHub issues. The fio project\n   uses GitHub issues for reproducible bugs/enhancement requests.\nb) Please reproduce your bug using the latest fio listed on\n   https://github.com/axboe/fio/releases (see the Source and Building sections\n   of the README for how to build fio from source).\nc) Include all of the information requested in the mailing list section above\n   (description, environment, version, reproduction steps and all job parameters).\n\nThanks!\n"
        },
        {
          "name": "SERVER-TODO",
          "type": "blob",
          "size": 0.126953125,
          "content": "- Collate ETA output from multiple connections into 1\n- If group_reporting is set, collate final output from multiple connections\n"
        },
        {
          "name": "STEADYSTATE-TODO",
          "type": "blob",
          "size": 0.869140625,
          "content": "Known issues/TODO (for steady-state)\n\n- Replace the test script with a better one\n  - Add test cases for the new check_interval option\n  - Parse debug=steadystate output to check calculations\n\n- Instead of calculating `intervals` every time, calculate it once and stash it\n  somewhere\n\n- Add the time unit to the ss_dur and check_interval variable names to reduce\n  possible confusion\n\n- Better documentation for output\n\n- Report read, write, trim IOPS/BW separately\n\n- Semantics for the ring buffer ss->head are confusing. ss->head points\n  to the beginning of the buffer up through the point where the buffer\n  is filled for the first time. afterwards, when a new element is added,\n  ss->head is advanced to point to the second element in the buffer. if\n  steady state is attained upon adding a new element, ss->head is not\n  advanced so it actually does point to the head of the buffer.\n"
        },
        {
          "name": "arch",
          "type": "tree",
          "content": null
        },
        {
          "name": "backend.c",
          "type": "blob",
          "size": 59.32421875,
          "content": "/*\n * fio - the flexible io tester\n *\n * Copyright (C) 2005 Jens Axboe <axboe@suse.de>\n * Copyright (C) 2006-2012 Jens Axboe <axboe@kernel.dk>\n *\n * The license below covers all files distributed with fio unless otherwise\n * noted in the file itself.\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License version 2 as\n *  published by the Free Software Foundation.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; if not, write to the Free Software\n *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n#include <unistd.h>\n#include <string.h>\n#include <signal.h>\n#include <assert.h>\n#include <inttypes.h>\n#include <sys/stat.h>\n#include <sys/wait.h>\n#include <math.h>\n#include <pthread.h>\n\n#include \"fio.h\"\n#include \"smalloc.h\"\n#include \"verify.h\"\n#include \"diskutil.h\"\n#include \"cgroup.h\"\n#include \"profile.h\"\n#include \"lib/rand.h\"\n#include \"lib/memalign.h\"\n#include \"server.h\"\n#include \"lib/getrusage.h\"\n#include \"idletime.h\"\n#include \"err.h\"\n#include \"workqueue.h\"\n#include \"lib/mountcheck.h\"\n#include \"rate-submit.h\"\n#include \"helper_thread.h\"\n#include \"pshared.h\"\n#include \"zone-dist.h\"\n#include \"fio_time.h\"\n\nstatic struct fio_sem *startup_sem;\nstatic struct flist_head *cgroup_list;\nstatic struct cgroup_mnt *cgroup_mnt;\nstatic int exit_value;\nstatic volatile bool fio_abort;\nstatic unsigned int nr_process = 0;\nstatic unsigned int nr_thread = 0;\n\nstruct io_log *agg_io_log[DDIR_RWDIR_CNT];\n\nint groupid = 0;\nunsigned int thread_number = 0;\nunsigned int nr_segments = 0;\nunsigned int cur_segment = 0;\nunsigned int stat_number = 0;\nint temp_stall_ts;\nunsigned long done_secs = 0;\n#ifdef PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP\npthread_mutex_t overlap_check = PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP;\n#else\npthread_mutex_t overlap_check = PTHREAD_MUTEX_INITIALIZER;\n#endif\n\n#define JOB_START_TIMEOUT\t(5 * 1000)\n\nstatic void sig_int(int sig)\n{\n\tif (nr_segments) {\n\t\tif (is_backend)\n\t\t\tfio_server_got_signal(sig);\n\t\telse {\n\t\t\tlog_info(\"\\nfio: terminating on signal %d\\n\", sig);\n\t\t\tlog_info_flush();\n\t\t\texit_value = 128;\n\t\t}\n\n\t\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n\t}\n}\n\n#ifdef WIN32\nstatic void sig_break(int sig)\n{\n\tsig_int(sig);\n\n\t/**\n\t * Windows terminates all job processes on SIGBREAK after the handler\n\t * returns, so give them time to wrap-up and give stats\n\t */\n\tfor_each_td(td) {\n\t\twhile (td->runstate < TD_EXITED)\n\t\t\tsleep(1);\n\t} end_for_each();\n}\n#endif\n\nvoid sig_show_status(int sig)\n{\n\tshow_running_run_stats();\n}\n\nstatic void set_sig_handlers(void)\n{\n\tstruct sigaction act;\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_int;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGINT, &act, NULL);\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_int;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGTERM, &act, NULL);\n\n/* Windows uses SIGBREAK as a quit signal from other applications */\n#ifdef WIN32\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_break;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGBREAK, &act, NULL);\n#endif\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_show_status;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGUSR1, &act, NULL);\n\n\tif (is_backend) {\n\t\tmemset(&act, 0, sizeof(act));\n\t\tact.sa_handler = sig_int;\n\t\tact.sa_flags = SA_RESTART;\n\t\tsigaction(SIGPIPE, &act, NULL);\n\t}\n}\n\n/*\n * Check if we are above the minimum rate given.\n */\nstatic bool __check_min_rate(struct thread_data *td, struct timespec *now,\n\t\t\t     enum fio_ddir ddir)\n{\n\tunsigned long long current_rate_check_bytes = td->this_io_bytes[ddir];\n\tunsigned long current_rate_check_blocks = td->this_io_blocks[ddir];\n\tunsigned long long option_rate_bytes_min = td->o.ratemin[ddir];\n\tunsigned int option_rate_iops_min = td->o.rate_iops_min[ddir];\n\n\tassert(ddir_rw(ddir));\n\n\tif (!td->o.ratemin[ddir] && !td->o.rate_iops_min[ddir])\n\t\treturn false;\n\n\t/*\n\t * allow a 2 second settle period in the beginning\n\t */\n\tif (mtime_since(&td->start, now) < 2000)\n\t\treturn false;\n\n\t/*\n\t * if last_rate_check_blocks or last_rate_check_bytes is set,\n\t * we can compute a rate per ratecycle\n\t */\n\tif (td->last_rate_check_bytes[ddir] || td->last_rate_check_blocks[ddir]) {\n\t\tunsigned long spent = mtime_since(&td->last_rate_check_time[ddir], now);\n\t\tif (spent < td->o.ratecycle || spent==0)\n\t\t\treturn false;\n\n\t\tif (td->o.ratemin[ddir]) {\n\t\t\t/*\n\t\t\t * check bandwidth specified rate\n\t\t\t */\n\t\t\tunsigned long long current_rate_bytes =\n\t\t\t\t((current_rate_check_bytes - td->last_rate_check_bytes[ddir]) * 1000) / spent;\n\t\t\tif (current_rate_bytes < option_rate_bytes_min) {\n\t\t\t\tlog_err(\"%s: rate_min=%lluB/s not met, got %lluB/s\\n\",\n\t\t\t\t\ttd->o.name, option_rate_bytes_min, current_rate_bytes);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * checks iops specified rate\n\t\t\t */\n\t\t\tunsigned long long current_rate_iops =\n\t\t\t\t((current_rate_check_blocks - td->last_rate_check_blocks[ddir]) * 1000) / spent;\n\n\t\t\tif (current_rate_iops < option_rate_iops_min) {\n\t\t\t\tlog_err(\"%s: rate_iops_min=%u not met, got %llu IOPS\\n\",\n\t\t\t\t\ttd->o.name, option_rate_iops_min, current_rate_iops);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\n\ttd->last_rate_check_bytes[ddir] = current_rate_check_bytes;\n\ttd->last_rate_check_blocks[ddir] = current_rate_check_blocks;\n\tmemcpy(&td->last_rate_check_time[ddir], now, sizeof(*now));\n\treturn false;\n}\n\nstatic bool check_min_rate(struct thread_data *td, struct timespec *now)\n{\n\tbool ret = false;\n\n\tfor_each_rw_ddir(ddir) {\n\t\tif (td->bytes_done[ddir])\n\t\t\tret |= __check_min_rate(td, now, ddir);\n\t}\n\n\treturn ret;\n}\n\n/*\n * When job exits, we can cancel the in-flight IO if we are using async\n * io. Attempt to do so.\n */\nstatic void cleanup_pending_aio(struct thread_data *td)\n{\n\tint r;\n\n\t/*\n\t * get immediately available events, if any\n\t */\n\tr = io_u_queued_complete(td, 0);\n\n\t/*\n\t * now cancel remaining active events\n\t */\n\tif (td->io_ops->cancel) {\n\t\tstruct io_u *io_u;\n\t\tint i;\n\n\t\tio_u_qiter(&td->io_u_all, io_u, i) {\n\t\t\tif (io_u->flags & IO_U_F_FLIGHT) {\n\t\t\t\tr = td->io_ops->cancel(td, io_u);\n\t\t\t\tif (!r)\n\t\t\t\t\tput_io_u(td, io_u);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (td->cur_depth)\n\t\tr = io_u_queued_complete(td, td->cur_depth);\n}\n\n/*\n * Helper to handle the final sync of a file. Works just like the normal\n * io path, just does everything sync.\n */\nstatic bool fio_io_sync(struct thread_data *td, struct fio_file *f)\n{\n\tstruct io_u *io_u = __get_io_u(td);\n\tenum fio_q_status ret;\n\n\tif (!io_u)\n\t\treturn true;\n\n\tio_u->ddir = DDIR_SYNC;\n\tio_u->file = f;\n\tio_u_set(td, io_u, IO_U_F_NO_FILE_PUT);\n\n\tif (td_io_prep(td, io_u)) {\n\t\tput_io_u(td, io_u);\n\t\treturn true;\n\t}\n\nrequeue:\n\tret = td_io_queue(td, io_u);\n\tswitch (ret) {\n\tcase FIO_Q_QUEUED:\n\t\ttd_io_commit(td);\n\t\tif (io_u_queued_complete(td, 1) < 0)\n\t\t\treturn true;\n\t\tbreak;\n\tcase FIO_Q_COMPLETED:\n\t\tif (io_u->error) {\n\t\t\ttd_verror(td, io_u->error, \"td_io_queue\");\n\t\t\treturn true;\n\t\t}\n\n\t\tif (io_u_sync_complete(td, io_u) < 0)\n\t\t\treturn true;\n\t\tbreak;\n\tcase FIO_Q_BUSY:\n\t\ttd_io_commit(td);\n\t\tgoto requeue;\n\t}\n\n\treturn false;\n}\n\nstatic int fio_file_fsync(struct thread_data *td, struct fio_file *f)\n{\n\tint ret, ret2;\n\n\tif (fio_file_open(f))\n\t\treturn fio_io_sync(td, f);\n\n\tif (td_io_open_file(td, f))\n\t\treturn 1;\n\n\tret = fio_io_sync(td, f);\n\tret2 = 0;\n\tif (fio_file_open(f))\n\t\tret2 = td_io_close_file(td, f);\n\treturn (ret || ret2);\n}\n\nstatic inline void __update_ts_cache(struct thread_data *td)\n{\n\tfio_gettime(&td->ts_cache, NULL);\n}\n\nstatic inline void update_ts_cache(struct thread_data *td)\n{\n\tif ((++td->ts_cache_nr & td->ts_cache_mask) == td->ts_cache_mask)\n\t\t__update_ts_cache(td);\n}\n\nstatic inline bool runtime_exceeded(struct thread_data *td, struct timespec *t)\n{\n\tif (in_ramp_time(td))\n\t\treturn false;\n\tif (!td->o.timeout)\n\t\treturn false;\n\tif (utime_since(&td->epoch, t) >= td->o.timeout)\n\t\treturn true;\n\n\treturn false;\n}\n\n/*\n * We need to update the runtime consistently in ms, but keep a running\n * tally of the current elapsed time in microseconds for sub millisecond\n * updates.\n */\nstatic inline void update_runtime(struct thread_data *td,\n\t\t\t\t  unsigned long long *elapsed_us,\n\t\t\t\t  const enum fio_ddir ddir)\n{\n\tif (ddir == DDIR_WRITE && td_write(td) && td->o.verify_only)\n\t\treturn;\n\n\ttd->ts.runtime[ddir] -= (elapsed_us[ddir] + 999) / 1000;\n\telapsed_us[ddir] += utime_since_now(&td->start);\n\ttd->ts.runtime[ddir] += (elapsed_us[ddir] + 999) / 1000;\n}\n\nstatic bool break_on_this_error(struct thread_data *td, enum fio_ddir ddir,\n\t\t\t\tint *retptr)\n{\n\tint ret = *retptr;\n\n\tif (ret < 0 || td->error) {\n\t\tint err = td->error;\n\t\tenum error_type_bit eb;\n\n\t\tif (ret < 0)\n\t\t\terr = -ret;\n\n\t\teb = td_error_type(ddir, err);\n\t\tif (!(td->o.continue_on_error & (1 << eb)))\n\t\t\treturn true;\n\n\t\tif (td_non_fatal_error(td, eb, err)) {\n\t\t        /*\n\t\t         * Continue with the I/Os in case of\n\t\t\t * a non fatal error.\n\t\t\t */\n\t\t\tupdate_error_count(td, err);\n\t\t\ttd_clear_error(td);\n\t\t\t*retptr = 0;\n\t\t\treturn false;\n\t\t} else if (td->o.fill_device && (err == ENOSPC || err == EDQUOT)) {\n\t\t\t/*\n\t\t\t * We expect to hit this error if\n\t\t\t * fill_device option is set.\n\t\t\t */\n\t\t\ttd_clear_error(td);\n\t\t\tfio_mark_td_terminate(td);\n\t\t\treturn true;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Stop the I/O in case of a fatal\n\t\t\t * error.\n\t\t\t */\n\t\t\tupdate_error_count(td, err);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic void check_update_rusage(struct thread_data *td)\n{\n\tif (td->update_rusage) {\n\t\ttd->update_rusage = 0;\n\t\tupdate_rusage_stat(td);\n\t\tfio_sem_up(td->rusage_sem);\n\t}\n}\n\nstatic int wait_for_completions(struct thread_data *td, struct timespec *time)\n{\n\tconst int full = queue_full(td);\n\tint min_evts = 0;\n\tint ret;\n\n\tif (td->flags & TD_F_REGROW_LOGS)\n\t\treturn io_u_quiesce(td);\n\n\t/*\n\t * if the queue is full, we MUST reap at least 1 event\n\t */\n\tmin_evts = min(td->o.iodepth_batch_complete_min, td->cur_depth);\n\tif ((full && !min_evts) || !td->o.iodepth_batch_complete_min)\n\t\tmin_evts = 1;\n\n\tif (time && should_check_rate(td))\n\t\tfio_gettime(time, NULL);\n\n\tdo {\n\t\tret = io_u_queued_complete(td, min_evts);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t} while (full && (td->cur_depth > td->o.iodepth_low));\n\n\treturn ret;\n}\n\nint io_queue_event(struct thread_data *td, struct io_u *io_u, int *ret,\n\t\t   enum fio_ddir ddir, uint64_t *bytes_issued, int from_verify,\n\t\t   struct timespec *comp_time)\n{\n\tswitch (*ret) {\n\tcase FIO_Q_COMPLETED:\n\t\tif (io_u->error) {\n\t\t\t*ret = -io_u->error;\n\t\t\tclear_io_u(td, io_u);\n\t\t} else if (io_u->resid) {\n\t\t\tlong long bytes = io_u->xfer_buflen - io_u->resid;\n\t\t\tstruct fio_file *f = io_u->file;\n\n\t\t\tif (bytes_issued)\n\t\t\t\t*bytes_issued += bytes;\n\n\t\t\tif (!from_verify)\n\t\t\t\ttrim_io_piece(io_u);\n\n\t\t\t/*\n\t\t\t * zero read, fail\n\t\t\t */\n\t\t\tif (!bytes) {\n\t\t\t\tif (!from_verify)\n\t\t\t\t\tunlog_io_piece(td, io_u);\n\t\t\t\ttd_verror(td, EIO, \"full resid\");\n\t\t\t\tclear_io_u(td, io_u);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tio_u->xfer_buflen = io_u->resid;\n\t\t\tio_u->xfer_buf += bytes;\n\t\t\tio_u->offset += bytes;\n\n\t\t\tif (ddir_rw(io_u->ddir))\n\t\t\t\ttd->ts.short_io_u[io_u->ddir]++;\n\n\t\t\tif (io_u->offset == f->real_file_size)\n\t\t\t\tgoto sync_done;\n\n\t\t\trequeue_io_u(td, &io_u);\n\t\t} else {\nsync_done:\n\t\t\tif (comp_time && should_check_rate(td))\n\t\t\t\tfio_gettime(comp_time, NULL);\n\n\t\t\t*ret = io_u_sync_complete(td, io_u);\n\t\t\tif (*ret < 0)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (td->flags & TD_F_REGROW_LOGS)\n\t\t\tregrow_logs(td);\n\n\t\t/*\n\t\t * when doing I/O (not when verifying),\n\t\t * check for any errors that are to be ignored\n\t\t */\n\t\tif (!from_verify)\n\t\t\tbreak;\n\n\t\treturn 0;\n\tcase FIO_Q_QUEUED:\n\t\t/*\n\t\t * if the engine doesn't have a commit hook,\n\t\t * the io_u is really queued. if it does have such\n\t\t * a hook, it has to call io_u_queued() itself.\n\t\t */\n\t\tif (td->io_ops->commit == NULL)\n\t\t\tio_u_queued(td, io_u);\n\t\tif (bytes_issued)\n\t\t\t*bytes_issued += io_u->xfer_buflen;\n\t\tbreak;\n\tcase FIO_Q_BUSY:\n\t\tif (!from_verify)\n\t\t\tunlog_io_piece(td, io_u);\n\t\trequeue_io_u(td, &io_u);\n\t\ttd_io_commit(td);\n\t\tbreak;\n\tdefault:\n\t\tassert(*ret < 0);\n\t\ttd_verror(td, -(*ret), \"td_io_queue\");\n\t\tbreak;\n\t}\n\n\tif (break_on_this_error(td, ddir, ret))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic inline bool io_in_polling(struct thread_data *td)\n{\n\treturn !td->o.iodepth_batch_complete_min &&\n\t\t   !td->o.iodepth_batch_complete_max;\n}\n/*\n * Unlinks files from thread data fio_file structure\n */\nstatic int unlink_all_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\tint ret = 0;\n\n\tfor_each_file(td, f, i) {\n\t\tif (f->filetype != FIO_TYPE_FILE)\n\t\t\tcontinue;\n\t\tret = td_io_unlink_file(td, f);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tif (ret)\n\t\ttd_verror(td, ret, \"unlink_all_files\");\n\n\treturn ret;\n}\n\n/*\n * Check if io_u will overlap an in-flight IO in the queue\n */\nbool in_flight_overlap(struct io_u_queue *q, struct io_u *io_u)\n{\n\tbool overlap;\n\tstruct io_u *check_io_u;\n\tunsigned long long x1, x2, y1, y2;\n\tint i;\n\n\tx1 = io_u->offset;\n\tx2 = io_u->offset + io_u->buflen;\n\toverlap = false;\n\tio_u_qiter(q, check_io_u, i) {\n\t\tif (check_io_u->flags & IO_U_F_FLIGHT) {\n\t\t\ty1 = check_io_u->offset;\n\t\t\ty2 = check_io_u->offset + check_io_u->buflen;\n\n\t\t\tif (x1 < y2 && y1 < x2) {\n\t\t\t\toverlap = true;\n\t\t\t\tdprint(FD_IO, \"in-flight overlap: %llu/%llu, %llu/%llu\\n\",\n\t\t\t\t\t\tx1, io_u->buflen,\n\t\t\t\t\t\ty1, check_io_u->buflen);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn overlap;\n}\n\nstatic enum fio_q_status io_u_submit(struct thread_data *td, struct io_u *io_u)\n{\n\t/*\n\t * Check for overlap if the user asked us to, and we have\n\t * at least one IO in flight besides this one.\n\t */\n\tif (td->o.serialize_overlap && td->cur_depth > 1 &&\n\t    in_flight_overlap(&td->io_u_all, io_u))\n\t\treturn FIO_Q_BUSY;\n\n\treturn td_io_queue(td, io_u);\n}\n\n/*\n * The main verify engine. Runs over the writes we previously submitted,\n * reads the blocks back in, and checks the crc/md5 of the data.\n */\nstatic void do_verify(struct thread_data *td, uint64_t verify_bytes)\n{\n\tstruct fio_file *f;\n\tstruct io_u *io_u;\n\tint ret, min_events;\n\tunsigned int i;\n\n\tdprint(FD_VERIFY, \"starting loop\\n\");\n\n\t/*\n\t * sync io first and invalidate cache, to make sure we really\n\t * read from disk.\n\t */\n\tfor_each_file(td, f, i) {\n\t\tif (!fio_file_open(f))\n\t\t\tcontinue;\n\t\tif (fio_io_sync(td, f))\n\t\t\tbreak;\n\t\tif (file_invalidate_cache(td, f))\n\t\t\tbreak;\n\t}\n\n\tcheck_update_rusage(td);\n\n\tif (td->error)\n\t\treturn;\n\n\ttd_set_runstate(td, TD_VERIFYING);\n\n\tio_u = NULL;\n\twhile (!td->terminate) {\n\t\tenum fio_ddir ddir;\n\t\tint full;\n\n\t\tupdate_ts_cache(td);\n\t\tcheck_update_rusage(td);\n\n\t\tif (runtime_exceeded(td, &td->ts_cache)) {\n\t\t\t__update_ts_cache(td);\n\t\t\tif (runtime_exceeded(td, &td->ts_cache)) {\n\t\t\t\tfio_mark_td_terminate(td);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (flow_threshold_exceeded(td))\n\t\t\tcontinue;\n\n\t\tif (!td->o.experimental_verify) {\n\t\t\tio_u = __get_io_u(td);\n\t\t\tif (!io_u)\n\t\t\t\tbreak;\n\n\t\t\tif (get_next_verify(td, io_u)) {\n\t\t\t\tput_io_u(td, io_u);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (td_io_prep(td, io_u)) {\n\t\t\t\tput_io_u(td, io_u);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (td->bytes_verified + td->o.rw_min_bs > verify_bytes)\n\t\t\t\tbreak;\n\n\t\t\twhile ((io_u = get_io_u(td)) != NULL) {\n\t\t\t\tif (IS_ERR_OR_NULL(io_u)) {\n\t\t\t\t\tio_u = NULL;\n\t\t\t\t\tret = FIO_Q_BUSY;\n\t\t\t\t\tgoto reap;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * We are only interested in the places where\n\t\t\t\t * we wrote or trimmed IOs. Turn those into\n\t\t\t\t * reads for verification purposes.\n\t\t\t\t */\n\t\t\t\tif (io_u->ddir == DDIR_READ) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Pretend we issued it for rwmix\n\t\t\t\t\t * accounting\n\t\t\t\t\t */\n\t\t\t\t\ttd->io_issues[DDIR_READ]++;\n\t\t\t\t\tput_io_u(td, io_u);\n\t\t\t\t\tcontinue;\n\t\t\t\t} else if (io_u->ddir == DDIR_TRIM) {\n\t\t\t\t\tio_u->ddir = DDIR_READ;\n\t\t\t\t\tio_u_set(td, io_u, IO_U_F_TRIMMED);\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (io_u->ddir == DDIR_WRITE) {\n\t\t\t\t\tio_u->ddir = DDIR_READ;\n\t\t\t\t\tio_u->numberio = td->verify_read_issues;\n\t\t\t\t\ttd->verify_read_issues++;\n\t\t\t\t\tpopulate_verify_io_u(td, io_u);\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tput_io_u(td, io_u);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!io_u)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (verify_state_should_stop(td, io_u)) {\n\t\t\tput_io_u(td, io_u);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (td->o.verify_async)\n\t\t\tio_u->end_io = verify_io_u_async;\n\t\telse\n\t\t\tio_u->end_io = verify_io_u;\n\n\t\tddir = io_u->ddir;\n\t\tif (!td->o.disable_slat)\n\t\t\tfio_gettime(&io_u->start_time, NULL);\n\n\t\tret = io_u_submit(td, io_u);\n\n\t\tif (io_queue_event(td, io_u, &ret, ddir, NULL, 1, NULL))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * if we can queue more, do so. but check if there are\n\t\t * completed io_u's first. Note that we can get BUSY even\n\t\t * without IO queued, if the system is resource starved.\n\t\t */\nreap:\n\t\tfull = queue_full(td) || (ret == FIO_Q_BUSY && td->cur_depth);\n\t\tif (full || io_in_polling(td))\n\t\t\tret = wait_for_completions(td, NULL);\n\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t}\n\n\tcheck_update_rusage(td);\n\n\tif (!td->error) {\n\t\tmin_events = td->cur_depth;\n\n\t\tif (min_events)\n\t\t\tret = io_u_queued_complete(td, min_events);\n\t} else\n\t\tcleanup_pending_aio(td);\n\n\ttd_set_runstate(td, TD_RUNNING);\n\n\tdprint(FD_VERIFY, \"exiting loop\\n\");\n}\n\nstatic bool exceeds_number_ios(struct thread_data *td)\n{\n\tunsigned long long number_ios;\n\n\tif (!td->o.number_ios)\n\t\treturn false;\n\n\tnumber_ios = ddir_rw_sum(td->io_blocks);\n\tnumber_ios += td->io_u_queued + td->io_u_in_flight;\n\n\treturn number_ios >= (td->o.number_ios * td->loops);\n}\n\nstatic bool io_bytes_exceeded(struct thread_data *td, uint64_t *this_bytes)\n{\n\tunsigned long long bytes, limit;\n\n\tif (td_rw(td))\n\t\tbytes = this_bytes[DDIR_READ] + this_bytes[DDIR_WRITE];\n\telse if (td_write(td))\n\t\tbytes = this_bytes[DDIR_WRITE];\n\telse if (td_read(td))\n\t\tbytes = this_bytes[DDIR_READ];\n\telse\n\t\tbytes = this_bytes[DDIR_TRIM];\n\n\tif (td->o.io_size)\n\t\tlimit = td->o.io_size;\n\telse\n\t\tlimit = td->o.size;\n\n\tlimit *= td->loops;\n\treturn bytes >= limit || exceeds_number_ios(td);\n}\n\nstatic bool io_issue_bytes_exceeded(struct thread_data *td)\n{\n\treturn io_bytes_exceeded(td, td->io_issue_bytes);\n}\n\nstatic bool io_complete_bytes_exceeded(struct thread_data *td)\n{\n\treturn io_bytes_exceeded(td, td->this_io_bytes);\n}\n\n/*\n * used to calculate the next io time for rate control\n *\n */\nstatic long long usec_for_io(struct thread_data *td, enum fio_ddir ddir)\n{\n\tuint64_t bps = td->rate_bps[ddir];\n\n\tassert(!(td->flags & TD_F_CHILD));\n\n\tif (td->o.rate_process == RATE_PROCESS_POISSON) {\n\t\tuint64_t val, iops;\n\n\t\tiops = bps / td->o.min_bs[ddir];\n\t\tval = (int64_t) (1000000 / iops) *\n\t\t\t\t-logf(__rand_0_1(&td->poisson_state[ddir]));\n\t\tif (val) {\n\t\t\tdprint(FD_RATE, \"poisson rate iops=%llu, ddir=%d\\n\",\n\t\t\t\t\t(unsigned long long) 1000000 / val,\n\t\t\t\t\tddir);\n\t\t}\n\t\ttd->last_usec[ddir] += val;\n\t\treturn td->last_usec[ddir];\n\t} else if (bps) {\n\t\tuint64_t bytes = td->rate_io_issue_bytes[ddir];\n\t\tuint64_t secs = bytes / bps;\n\t\tuint64_t remainder = bytes % bps;\n\n\t\treturn remainder * 1000000 / bps + secs * 1000000;\n\t}\n\n\treturn 0;\n}\n\nstatic void init_thinktime(struct thread_data *td)\n{\n\tif (td->o.thinktime_blocks_type == THINKTIME_BLOCKS_TYPE_COMPLETE)\n\t\ttd->thinktime_blocks_counter = td->io_blocks;\n\telse\n\t\ttd->thinktime_blocks_counter = td->io_issues;\n\ttd->last_thinktime = td->epoch;\n\ttd->last_thinktime_blocks = 0;\n}\n\nstatic void handle_thinktime(struct thread_data *td, enum fio_ddir ddir,\n\t\t\t     struct timespec *time)\n{\n\tunsigned long long b;\n\tunsigned long long runtime_left;\n\tuint64_t total;\n\tint left;\n\tstruct timespec now;\n\tbool stall = false;\n\n\tif (td->o.thinktime_iotime) {\n\t\tfio_gettime(&now, NULL);\n\t\tif (utime_since(&td->last_thinktime, &now)\n\t\t    >= td->o.thinktime_iotime) {\n\t\t\tstall = true;\n\t\t} else if (!fio_option_is_set(&td->o, thinktime_blocks)) {\n\t\t\t/*\n\t\t\t * When thinktime_iotime is set and thinktime_blocks is\n\t\t\t * not set, skip the thinktime_blocks check, since\n\t\t\t * thinktime_blocks default value 1 does not work\n\t\t\t * together with thinktime_iotime.\n\t\t\t */\n\t\t\treturn;\n\t\t}\n\n\t}\n\n\tb = ddir_rw_sum(td->thinktime_blocks_counter);\n\tif (b >= td->last_thinktime_blocks + td->o.thinktime_blocks)\n\t\tstall = true;\n\n\tif (!stall)\n\t\treturn;\n\n\tio_u_quiesce(td);\n\n\tleft = td->o.thinktime_spin;\n\tif (td->o.timeout) {\n\t\truntime_left = td->o.timeout - utime_since_now(&td->epoch);\n\t\tif (runtime_left < (unsigned long long)left)\n\t\t\tleft = runtime_left;\n\t}\n\n\ttotal = 0;\n\tif (left)\n\t\ttotal = usec_spin(left);\n\n\t/*\n\t * usec_spin() might run for slightly longer than intended in a VM\n\t * where the vCPU could get descheduled or the hypervisor could steal\n\t * CPU time. Ensure \"left\" doesn't become negative.\n\t */\n\tif (total < td->o.thinktime)\n\t\tleft = td->o.thinktime - total;\n\telse\n\t\tleft = 0;\n\n\tif (td->o.timeout) {\n\t\truntime_left = td->o.timeout - utime_since_now(&td->epoch);\n\t\tif (runtime_left < (unsigned long long)left)\n\t\t\tleft = runtime_left;\n\t}\n\n\tif (left)\n\t\ttotal += usec_sleep(td, left);\n\n\t/*\n\t * If we're ignoring thinktime for the rate, add the number of bytes\n\t * we would have done while sleeping, minus one block to ensure we\n\t * start issuing immediately after the sleep.\n\t */\n\tif (total && td->rate_bps[ddir] && td->o.rate_ign_think) {\n\t\tuint64_t missed = (td->rate_bps[ddir] * total) / 1000000ULL;\n\t\tuint64_t bs = td->o.min_bs[ddir];\n\t\tuint64_t usperop = bs * 1000000ULL / td->rate_bps[ddir];\n\t\tuint64_t over;\n\n\t\tif (usperop <= total)\n\t\t\tover = bs;\n\t\telse\n\t\t\tover = (usperop - total) / usperop * -bs;\n\n\t\ttd->rate_io_issue_bytes[ddir] += (missed - over);\n\t\t/* adjust for rate_process=poisson */\n\t\ttd->last_usec[ddir] += total;\n\t}\n\n\tif (time && should_check_rate(td))\n\t\tfio_gettime(time, NULL);\n\n\ttd->last_thinktime_blocks = b;\n\tif (td->o.thinktime_iotime) {\n\t\tfio_gettime(&now, NULL);\n\t\ttd->last_thinktime = now;\n\t}\n}\n\n/*\n * Main IO worker function. It retrieves io_u's to process and queues\n * and reaps them, checking for rate and errors along the way.\n *\n * Returns number of bytes written and trimmed.\n */\nstatic void do_io(struct thread_data *td, uint64_t *bytes_done)\n{\n\tunsigned int i;\n\tint ret = 0;\n\tuint64_t total_bytes, bytes_issued = 0;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\tbytes_done[i] = td->bytes_done[i];\n\n\tif (in_ramp_time(td))\n\t\ttd_set_runstate(td, TD_RAMP);\n\telse\n\t\ttd_set_runstate(td, TD_RUNNING);\n\n\tlat_target_init(td);\n\n\ttotal_bytes = td->o.size;\n\t/*\n\t* Allow random overwrite workloads to write up to io_size\n\t* before starting verification phase as 'size' doesn't apply.\n\t*/\n\tif (td_write(td) && td_random(td) && td->o.norandommap)\n\t\ttotal_bytes = max(total_bytes, (uint64_t) td->o.io_size);\n\n\t/* Don't break too early if io_size > size */\n\tif (td_rw(td) && !td_random(td))\n\t\ttotal_bytes = max(total_bytes, (uint64_t)td->o.io_size);\n\n\t/*\n\t * If verify_backlog is enabled, we'll run the verify in this\n\t * handler as well. For that case, we may need up to twice the\n\t * amount of bytes.\n\t */\n\tif (td->o.verify != VERIFY_NONE &&\n\t   (td_write(td) && td->o.verify_backlog))\n\t\ttotal_bytes += td->o.size;\n\n\t/* In trimwrite mode, each byte is trimmed and then written, so\n\t * allow total_bytes or number of ios to be twice as big */\n\tif (td_trimwrite(td)) {\n\t\ttotal_bytes += td->total_io_size;\n\t\ttd->o.number_ios *= 2;\n\t}\n\n\twhile ((td->o.read_iolog_file && !flist_empty(&td->io_log_list)) ||\n\t\t(!flist_empty(&td->trim_list)) || !io_issue_bytes_exceeded(td) ||\n\t\ttd->o.time_based) {\n\t\tstruct timespec comp_time;\n\t\tstruct io_u *io_u;\n\t\tint full;\n\t\tenum fio_ddir ddir;\n\n\t\tcheck_update_rusage(td);\n\n\t\tif (td->terminate || td->done)\n\t\t\tbreak;\n\n\t\tupdate_ts_cache(td);\n\n\t\tif (runtime_exceeded(td, &td->ts_cache)) {\n\t\t\t__update_ts_cache(td);\n\t\t\tif (runtime_exceeded(td, &td->ts_cache)) {\n\t\t\t\tfio_mark_td_terminate(td);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (flow_threshold_exceeded(td))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Break if we exceeded the bytes. The exception is time\n\t\t * based runs, but we still need to break out of the loop\n\t\t * for those to run verification, if enabled.\n\t\t * Jobs read from iolog do not use this stop condition.\n\t\t */\n\t\tif (bytes_issued >= total_bytes &&\n\t\t    !td->o.read_iolog_file &&\n\t\t    (!td->o.time_based ||\n\t\t     (td->o.time_based && td->o.verify != VERIFY_NONE)))\n\t\t\tbreak;\n\n\t\tio_u = get_io_u(td);\n\t\tif (IS_ERR_OR_NULL(io_u)) {\n\t\t\tint err = PTR_ERR(io_u);\n\n\t\t\tio_u = NULL;\n\t\t\tddir = DDIR_INVAL;\n\t\t\tif (err == -EBUSY) {\n\t\t\t\tret = FIO_Q_BUSY;\n\t\t\t\tgoto reap;\n\t\t\t}\n\t\t\tif (td->o.latency_target)\n\t\t\t\tgoto reap;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (io_u->ddir == DDIR_WRITE && td->flags & TD_F_DO_VERIFY) {\n\t\t\tif (!(io_u->flags & IO_U_F_PATTERN_DONE)) {\n\t\t\t\tio_u_set(td, io_u, IO_U_F_PATTERN_DONE);\n\t\t\t\tio_u->numberio = td->io_issues[io_u->ddir];\n\t\t\t\tpopulate_verify_io_u(td, io_u);\n\t\t\t}\n\t\t}\n\n\t\tddir = io_u->ddir;\n\n\t\t/*\n\t\t * Add verification end_io handler if:\n\t\t *\t- Asked to verify (!td_rw(td))\n\t\t *\t- Or the io_u is from our verify list (mixed write/ver)\n\t\t */\n\t\tif (td->o.verify != VERIFY_NONE && io_u->ddir == DDIR_READ &&\n\t\t    ((io_u->flags & IO_U_F_VER_LIST) || !td_rw(td))) {\n\n\t\t\tif (verify_state_should_stop(td, io_u)) {\n\t\t\t\tput_io_u(td, io_u);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (td->o.verify_async)\n\t\t\t\tio_u->end_io = verify_io_u_async;\n\t\t\telse\n\t\t\t\tio_u->end_io = verify_io_u;\n\t\t\ttd_set_runstate(td, TD_VERIFYING);\n\t\t} else if (in_ramp_time(td))\n\t\t\ttd_set_runstate(td, TD_RAMP);\n\t\telse\n\t\t\ttd_set_runstate(td, TD_RUNNING);\n\n\t\t/*\n\t\t * Always log IO before it's issued, so we know the specific\n\t\t * order of it. The logged unit will track when the IO has\n\t\t * completed.\n\t\t */\n\t\tif (td_write(td) && io_u->ddir == DDIR_WRITE &&\n\t\t    td->o.do_verify &&\n\t\t    td->o.verify != VERIFY_NONE &&\n\t\t    !td->o.experimental_verify)\n\t\t\tlog_io_piece(td, io_u);\n\n\t\tif (td->o.io_submit_mode == IO_MODE_OFFLOAD) {\n\t\t\tconst unsigned long long blen = io_u->xfer_buflen;\n\t\t\tconst enum fio_ddir __ddir = acct_ddir(io_u);\n\n\t\t\tif (td->error)\n\t\t\t\tbreak;\n\n\t\t\tworkqueue_enqueue(&td->io_wq, &io_u->work);\n\t\t\tret = FIO_Q_QUEUED;\n\n\t\t\tif (ddir_rw(__ddir)) {\n\t\t\t\ttd->io_issues[__ddir]++;\n\t\t\t\ttd->io_issue_bytes[__ddir] += blen;\n\t\t\t\ttd->rate_io_issue_bytes[__ddir] += blen;\n\t\t\t}\n\n\t\t\tif (should_check_rate(td)) {\n\t\t\t\ttd->rate_next_io_time[__ddir] = usec_for_io(td, __ddir);\n\t\t\t\tfio_gettime(&comp_time, NULL);\n\t\t\t}\n\n\t\t} else {\n\t\t\tret = io_u_submit(td, io_u);\n\n\t\t\tif (should_check_rate(td))\n\t\t\t\ttd->rate_next_io_time[ddir] = usec_for_io(td, ddir);\n\n\t\t\tif (io_queue_event(td, io_u, &ret, ddir, &bytes_issued, 0, &comp_time))\n\t\t\t\tbreak;\n\n\t\t\t/*\n\t\t\t * See if we need to complete some commands. Note that\n\t\t\t * we can get BUSY even without IO queued, if the\n\t\t\t * system is resource starved.\n\t\t\t */\nreap:\n\t\t\tfull = queue_full(td) ||\n\t\t\t\t(ret == FIO_Q_BUSY && td->cur_depth);\n\t\t\tif (full || io_in_polling(td))\n\t\t\t\tret = wait_for_completions(td, &comp_time);\n\t\t}\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\tif (ddir_rw(ddir) && td->o.thinkcycles)\n\t\t\tcycles_spin(td->o.thinkcycles);\n\n\t\tif (ddir_rw(ddir) && td->o.thinktime)\n\t\t\thandle_thinktime(td, ddir, &comp_time);\n\n\t\tif (!ddir_rw_sum(td->bytes_done) &&\n\t\t    !td_ioengine_flagged(td, FIO_NOIO))\n\t\t\tcontinue;\n\n\t\tif (!in_ramp_time(td) && should_check_rate(td)) {\n\t\t\tif (check_min_rate(td, &comp_time)) {\n\t\t\t\tif (exitall_on_terminate || td->o.exitall_error)\n\t\t\t\t\tfio_terminate_threads(td->groupid, td->o.exit_what);\n\t\t\t\ttd_verror(td, EIO, \"check_min_rate\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!in_ramp_time(td) && td->o.latency_target)\n\t\t\tlat_target_check(td);\n\t}\n\n\tcheck_update_rusage(td);\n\n\tif (td->trim_entries)\n\t\tlog_err(\"fio: %lu trim entries leaked?\\n\", td->trim_entries);\n\n\tif (td->o.fill_device && (td->error == ENOSPC || td->error == EDQUOT)) {\n\t\ttd->error = 0;\n\t\tfio_mark_td_terminate(td);\n\t}\n\tif (!td->error) {\n\t\tstruct fio_file *f;\n\n\t\tif (td->o.io_submit_mode == IO_MODE_OFFLOAD) {\n\t\t\tworkqueue_flush(&td->io_wq);\n\t\t\ti = 0;\n\t\t} else\n\t\t\ti = td->cur_depth;\n\n\t\tif (i) {\n\t\t\tret = io_u_queued_complete(td, i);\n\t\t\tif (td->o.fill_device &&\n\t\t\t    (td->error == ENOSPC || td->error == EDQUOT))\n\t\t\t\ttd->error = 0;\n\t\t}\n\n\t\tif (should_fsync(td) && (td->o.end_fsync || td->o.fsync_on_close)) {\n\t\t\ttd_set_runstate(td, TD_FSYNCING);\n\n\t\t\tfor_each_file(td, f, i) {\n\t\t\t\tif (!fio_file_fsync(td, f))\n\t\t\t\t\tcontinue;\n\n\t\t\t\tlog_err(\"fio: end_fsync failed for file %s\\n\",\n\t\t\t\t\t\t\t\tf->file_name);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (td->o.io_submit_mode == IO_MODE_OFFLOAD)\n\t\t\tworkqueue_flush(&td->io_wq);\n\t\tcleanup_pending_aio(td);\n\t}\n\n\t/*\n\t * stop job if we failed doing any IO\n\t */\n\tif (!ddir_rw_sum(td->this_io_bytes))\n\t\ttd->done = 1;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\tbytes_done[i] = td->bytes_done[i] - bytes_done[i];\n}\n\nstatic void free_file_completion_logging(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i) {\n\t\tif (!f->last_write_comp)\n\t\t\tbreak;\n\t\tsfree(f->last_write_comp);\n\t}\n}\n\nstatic int init_file_completion_logging(struct thread_data *td,\n\t\t\t\t\tunsigned int depth)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tif (td->o.verify == VERIFY_NONE || !td->o.verify_state_save)\n\t\treturn 0;\n\n\tfor_each_file(td, f, i) {\n\t\tf->last_write_comp = scalloc(depth, sizeof(uint64_t));\n\t\tif (!f->last_write_comp)\n\t\t\tgoto cleanup;\n\t}\n\n\treturn 0;\n\ncleanup:\n\tfree_file_completion_logging(td);\n\tlog_err(\"fio: failed to alloc write comp data\\n\");\n\treturn 1;\n}\n\nstatic void cleanup_io_u(struct thread_data *td)\n{\n\tstruct io_u *io_u;\n\n\twhile ((io_u = io_u_qpop(&td->io_u_freelist)) != NULL) {\n\n\t\tif (td->io_ops->io_u_free)\n\t\t\ttd->io_ops->io_u_free(td, io_u);\n\n\t\tfio_memfree(io_u, sizeof(*io_u), td_offload_overlap(td));\n\t}\n\n\tfree_io_mem(td);\n\n\tio_u_rexit(&td->io_u_requeues);\n\tio_u_qexit(&td->io_u_freelist, false);\n\tio_u_qexit(&td->io_u_all, td_offload_overlap(td));\n\n\tfree_file_completion_logging(td);\n}\n\nstatic int init_io_u(struct thread_data *td)\n{\n\tstruct io_u *io_u;\n\tint cl_align, i, max_units;\n\tint err;\n\n\tmax_units = td->o.iodepth;\n\n\terr = 0;\n\terr += !io_u_rinit(&td->io_u_requeues, td->o.iodepth);\n\terr += !io_u_qinit(&td->io_u_freelist, td->o.iodepth, false);\n\terr += !io_u_qinit(&td->io_u_all, td->o.iodepth, td_offload_overlap(td));\n\n\tif (err) {\n\t\tlog_err(\"fio: failed setting up IO queues\\n\");\n\t\treturn 1;\n\t}\n\n\tcl_align = os_cache_line_size();\n\n\tfor (i = 0; i < max_units; i++) {\n\t\tvoid *ptr;\n\n\t\tif (td->terminate)\n\t\t\treturn 1;\n\n\t\tptr = fio_memalign(cl_align, sizeof(*io_u), td_offload_overlap(td));\n\t\tif (!ptr) {\n\t\t\tlog_err(\"fio: unable to allocate aligned memory\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\tio_u = ptr;\n\t\tmemset(io_u, 0, sizeof(*io_u));\n\t\tINIT_FLIST_HEAD(&io_u->verify_list);\n\t\tdprint(FD_MEM, \"io_u alloc %p, index %u\\n\", io_u, i);\n\n\t\tio_u->index = i;\n\t\tio_u->flags = IO_U_F_FREE;\n\t\tio_u_qpush(&td->io_u_freelist, io_u);\n\n\t\t/*\n\t\t * io_u never leaves this stack, used for iteration of all\n\t\t * io_u buffers.\n\t\t */\n\t\tio_u_qpush(&td->io_u_all, io_u);\n\n\t\tif (td->io_ops->io_u_init) {\n\t\t\tint ret = td->io_ops->io_u_init(td, io_u);\n\n\t\t\tif (ret) {\n\t\t\t\tlog_err(\"fio: failed to init engine data: %d\\n\", ret);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (init_io_u_buffers(td))\n\t\treturn 1;\n\n\tif (init_file_completion_logging(td, max_units))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nint init_io_u_buffers(struct thread_data *td)\n{\n\tstruct io_u *io_u;\n\tunsigned long long max_bs, min_write, trim_bs = 0;\n\tint i, max_units;\n\tint data_xfer = 1;\n\tchar *p;\n\n\tmax_units = td->o.iodepth;\n\tmax_bs = td_max_bs(td);\n\tmin_write = td->o.min_bs[DDIR_WRITE];\n\ttd->orig_buffer_size = (unsigned long long) max_bs\n\t\t\t\t\t* (unsigned long long) max_units;\n\n\tif (td_trim(td) && td->o.num_range > 1) {\n\t\ttrim_bs = td->o.num_range * sizeof(struct trim_range);\n\t\ttd->orig_buffer_size = trim_bs\n\t\t\t\t\t* (unsigned long long) max_units;\n\t}\n\n\t/*\n\t * For reads, writes, and multi-range trim operations we need a\n\t * data buffer\n\t */\n\tif (td_ioengine_flagged(td, FIO_NOIO) ||\n\t    !(td_read(td) || td_write(td) || (td_trim(td) && td->o.num_range > 1)))\n\t\tdata_xfer = 0;\n\n\t/*\n\t * if we may later need to do address alignment, then add any\n\t * possible adjustment here so that we don't cause a buffer\n\t * overflow later. this adjustment may be too much if we get\n\t * lucky and the allocator gives us an aligned address.\n\t */\n\tif (td->o.odirect || td->o.mem_align ||\n\t    td_ioengine_flagged(td, FIO_RAWIO))\n\t\ttd->orig_buffer_size += page_mask + td->o.mem_align;\n\n\tif (td->o.mem_type == MEM_SHMHUGE || td->o.mem_type == MEM_MMAPHUGE) {\n\t\tunsigned long long bs;\n\n\t\tbs = td->orig_buffer_size + td->o.hugepage_size - 1;\n\t\ttd->orig_buffer_size = bs & ~(td->o.hugepage_size - 1);\n\t}\n\n\tif (td->orig_buffer_size != (size_t) td->orig_buffer_size) {\n\t\tlog_err(\"fio: IO memory too large. Reduce max_bs or iodepth\\n\");\n\t\treturn 1;\n\t}\n\n\tif (data_xfer && allocate_io_mem(td))\n\t\treturn 1;\n\n\tif (td->o.odirect || td->o.mem_align ||\n\t    td_ioengine_flagged(td, FIO_RAWIO))\n\t\tp = PTR_ALIGN(td->orig_buffer, page_mask) + td->o.mem_align;\n\telse\n\t\tp = td->orig_buffer;\n\n\tfor (i = 0; i < max_units; i++) {\n\t\tio_u = td->io_u_all.io_us[i];\n\t\tdprint(FD_MEM, \"io_u alloc %p, index %u\\n\", io_u, i);\n\n\t\tif (data_xfer) {\n\t\t\tio_u->buf = p;\n\t\t\tdprint(FD_MEM, \"io_u %p, mem %p\\n\", io_u, io_u->buf);\n\n\t\t\tif (td_write(td))\n\t\t\t\tio_u_fill_buffer(td, io_u, min_write, max_bs);\n\t\t\tif (td_write(td) && td->o.verify_pattern_bytes) {\n\t\t\t\t/*\n\t\t\t\t * Fill the buffer with the pattern if we are\n\t\t\t\t * going to be doing writes.\n\t\t\t\t */\n\t\t\t\tfill_verify_pattern(td, io_u->buf, max_bs, io_u, 0, 0);\n\t\t\t}\n\t\t}\n\t\tif (td_trim(td) && td->o.num_range > 1)\n\t\t\tp += trim_bs;\n\t\telse\n\t\t\tp += max_bs;\n\t}\n\n\treturn 0;\n}\n\n#ifdef FIO_HAVE_IOSCHED_SWITCH\n/*\n * These functions are Linux specific.\n * FIO_HAVE_IOSCHED_SWITCH enabled currently means it's Linux.\n */\nstatic int set_ioscheduler(struct thread_data *td, struct fio_file *file)\n{\n\tchar tmp[256], tmp2[128], *p;\n\tFILE *f;\n\tint ret;\n\n\tassert(file->du && file->du->sysfs_root);\n\tsprintf(tmp, \"%s/queue/scheduler\", file->du->sysfs_root);\n\n\tf = fopen(tmp, \"r+\");\n\tif (!f) {\n\t\tif (errno == ENOENT) {\n\t\t\tlog_err(\"fio: os or kernel doesn't support IO scheduler\"\n\t\t\t\t\" switching\\n\");\n\t\t\treturn 0;\n\t\t}\n\t\ttd_verror(td, errno, \"fopen iosched\");\n\t\treturn 1;\n\t}\n\n\t/*\n\t * Set io scheduler.\n\t */\n\tret = fwrite(td->o.ioscheduler, strlen(td->o.ioscheduler), 1, f);\n\tif (ferror(f) || ret != 1) {\n\t\ttd_verror(td, errno, \"fwrite\");\n\t\tfclose(f);\n\t\treturn 1;\n\t}\n\n\trewind(f);\n\n\t/*\n\t * Read back and check that the selected scheduler is now the default.\n\t */\n\tret = fread(tmp, 1, sizeof(tmp) - 1, f);\n\tif (ferror(f) || ret < 0) {\n\t\ttd_verror(td, errno, \"fread\");\n\t\tfclose(f);\n\t\treturn 1;\n\t}\n\ttmp[ret] = '\\0';\n\t/*\n\t * either a list of io schedulers or \"none\\n\" is expected. Strip the\n\t * trailing newline.\n\t */\n\tp = tmp;\n\tstrsep(&p, \"\\n\");\n\n\t/*\n\t * Write to \"none\" entry doesn't fail, so check the result here.\n\t */\n\tif (!strcmp(tmp, \"none\")) {\n\t\tlog_err(\"fio: io scheduler is not tunable\\n\");\n\t\tfclose(f);\n\t\treturn 0;\n\t}\n\n\tsprintf(tmp2, \"[%s]\", td->o.ioscheduler);\n\tif (!strstr(tmp, tmp2)) {\n\t\tlog_err(\"fio: unable to set io scheduler to %s\\n\", td->o.ioscheduler);\n\t\ttd_verror(td, EINVAL, \"iosched_switch\");\n\t\tfclose(f);\n\t\treturn 1;\n\t}\n\n\tfclose(f);\n\treturn 0;\n}\n\nstatic int switch_ioscheduler(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\tint ret = 0;\n\n\tif (td_ioengine_flagged(td, FIO_DISKLESSIO))\n\t\treturn 0;\n\n\tassert(td->files && td->files[0]);\n\n\tfor_each_file(td, f, i) {\n\n\t\t/* Only consider regular files and block device files */\n\t\tswitch (f->filetype) {\n\t\tcase FIO_TYPE_FILE:\n\t\tcase FIO_TYPE_BLOCK:\n\t\t\t/*\n\t\t\t * Make sure that the device hosting the file could\n\t\t\t * be determined.\n\t\t\t */\n\t\t\tif (!f->du)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\tcase FIO_TYPE_CHAR:\n\t\tcase FIO_TYPE_PIPE:\n\t\tdefault:\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = set_ioscheduler(td, f);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n#else\n\nstatic int switch_ioscheduler(struct thread_data *td)\n{\n\treturn 0;\n}\n\n#endif /* FIO_HAVE_IOSCHED_SWITCH */\n\nstatic bool keep_running(struct thread_data *td)\n{\n\tunsigned long long limit;\n\n\tif (td->done)\n\t\treturn false;\n\tif (td->terminate)\n\t\treturn false;\n\tif (td->o.time_based)\n\t\treturn true;\n\tif (td->o.loops) {\n\t\ttd->o.loops--;\n\t\treturn true;\n\t}\n\tif (exceeds_number_ios(td))\n\t\treturn false;\n\n\tif (td->o.io_size)\n\t\tlimit = td->o.io_size;\n\telse\n\t\tlimit = td->o.size;\n\n\tif (limit != -1ULL && ddir_rw_sum(td->io_bytes) < limit) {\n\t\tuint64_t diff;\n\n\t\t/*\n\t\t * If the difference is less than the maximum IO size, we\n\t\t * are done.\n\t\t */\n\t\tdiff = limit - ddir_rw_sum(td->io_bytes);\n\t\tif (diff < td_max_bs(td))\n\t\t\treturn false;\n\n\t\tif (fio_files_done(td) && !td->o.io_size)\n\t\t\treturn false;\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int exec_string(struct thread_options *o, const char *string,\n\t\t       const char *mode)\n{\n\tint ret;\n\tchar *str;\n\n\tif (asprintf(&str, \"%s > %s.%s.txt 2>&1\", string, o->name, mode) < 0)\n\t\treturn -1;\n\n\tlog_info(\"%s : Saving output of %s in %s.%s.txt\\n\", o->name, mode,\n\t\t o->name, mode);\n\tret = system(str);\n\tif (ret == -1)\n\t\tlog_err(\"fio: exec of cmd <%s> failed\\n\", str);\n\n\tfree(str);\n\treturn ret;\n}\n\n/*\n * Dry run to compute correct state of numberio for verification.\n */\nstatic uint64_t do_dry_run(struct thread_data *td)\n{\n\ttd_set_runstate(td, TD_RUNNING);\n\n\twhile ((td->o.read_iolog_file && !flist_empty(&td->io_log_list)) ||\n\t\t(!flist_empty(&td->trim_list)) || !io_complete_bytes_exceeded(td)) {\n\t\tstruct io_u *io_u;\n\t\tint ret;\n\n\t\tif (td->terminate || td->done)\n\t\t\tbreak;\n\n\t\tio_u = get_io_u(td);\n\t\tif (IS_ERR_OR_NULL(io_u))\n\t\t\tbreak;\n\n\t\tio_u_set(td, io_u, IO_U_F_FLIGHT);\n\t\tio_u->error = 0;\n\t\tio_u->resid = 0;\n\t\tif (ddir_rw(acct_ddir(io_u)))\n\t\t\ttd->io_issues[acct_ddir(io_u)]++;\n\t\tif (ddir_rw(io_u->ddir)) {\n\t\t\tio_u_mark_depth(td, 1);\n\t\t\ttd->ts.total_io_u[io_u->ddir]++;\n\t\t}\n\n\t\tif (td_write(td) && io_u->ddir == DDIR_WRITE &&\n\t\t    td->o.do_verify &&\n\t\t    td->o.verify != VERIFY_NONE &&\n\t\t    !td->o.experimental_verify)\n\t\t\tlog_io_piece(td, io_u);\n\n\t\tret = io_u_sync_complete(td, io_u);\n\t\t(void) ret;\n\t}\n\n\treturn td->bytes_done[DDIR_WRITE] + td->bytes_done[DDIR_TRIM];\n}\n\nstruct fork_data {\n\tstruct thread_data *td;\n\tstruct sk_out *sk_out;\n};\n\n/*\n * Entry point for the thread based jobs. The process based jobs end up\n * here as well, after a little setup.\n */\nstatic void *thread_main(void *data)\n{\n\tstruct fork_data *fd = data;\n\tunsigned long long elapsed_us[DDIR_RWDIR_CNT] = { 0, };\n\tstruct thread_data *td = fd->td;\n\tstruct thread_options *o = &td->o;\n\tstruct sk_out *sk_out = fd->sk_out;\n\tuint64_t bytes_done[DDIR_RWDIR_CNT];\n\tint deadlock_loop_cnt;\n\tbool clear_state;\n\tint ret;\n\n\tsk_out_assign(sk_out);\n\tfree(fd);\n\n\tif (!o->use_thread) {\n\t\tsetsid();\n\t\ttd->pid = getpid();\n\t} else\n\t\ttd->pid = gettid();\n\n\tfio_local_clock_init();\n\n\tdprint(FD_PROCESS, \"jobs pid=%d started\\n\", (int) td->pid);\n\n\tif (is_backend)\n\t\tfio_server_send_start(td);\n\n\tINIT_FLIST_HEAD(&td->io_log_list);\n\tINIT_FLIST_HEAD(&td->io_hist_list);\n\tINIT_FLIST_HEAD(&td->verify_list);\n\tINIT_FLIST_HEAD(&td->trim_list);\n\ttd->io_hist_tree = RB_ROOT;\n\n\tret = mutex_cond_init_pshared(&td->io_u_lock, &td->free_cond);\n\tif (ret) {\n\t\ttd_verror(td, ret, \"mutex_cond_init_pshared\");\n\t\tgoto err;\n\t}\n\tret = cond_init_pshared(&td->verify_cond);\n\tif (ret) {\n\t\ttd_verror(td, ret, \"mutex_cond_pshared\");\n\t\tgoto err;\n\t}\n\n\ttd_set_runstate(td, TD_INITIALIZED);\n\tdprint(FD_MUTEX, \"up startup_sem\\n\");\n\tfio_sem_up(startup_sem);\n\tdprint(FD_MUTEX, \"wait on td->sem\\n\");\n\tfio_sem_down(td->sem);\n\tdprint(FD_MUTEX, \"done waiting on td->sem\\n\");\n\n\t/*\n\t * A new gid requires privilege, so we need to do this before setting\n\t * the uid.\n\t */\n\tif (o->gid != -1U && setgid(o->gid)) {\n\t\ttd_verror(td, errno, \"setgid\");\n\t\tgoto err;\n\t}\n\tif (o->uid != -1U && setuid(o->uid)) {\n\t\ttd_verror(td, errno, \"setuid\");\n\t\tgoto err;\n\t}\n\n\ttd_zone_gen_index(td);\n\n\t/*\n\t * Do this early, we don't want the compress threads to be limited\n\t * to the same CPUs as the IO workers. So do this before we set\n\t * any potential CPU affinity\n\t */\n\tif (iolog_compress_init(td, sk_out))\n\t\tgoto err;\n\n\t/*\n\t * If we have a gettimeofday() thread, make sure we exclude that\n\t * thread from this job\n\t */\n\tif (o->gtod_cpu)\n\t\tfio_cpu_clear(&o->cpumask, o->gtod_cpu);\n\n\t/*\n\t * Set affinity first, in case it has an impact on the memory\n\t * allocations.\n\t */\n\tif (fio_option_is_set(o, cpumask)) {\n\t\tif (o->cpus_allowed_policy == FIO_CPUS_SPLIT) {\n\t\t\tret = fio_cpus_split(&o->cpumask, td->thread_number - 1);\n\t\t\tif (!ret) {\n\t\t\t\tlog_err(\"fio: no CPUs set\\n\");\n\t\t\t\tlog_err(\"fio: Try increasing number of available CPUs\\n\");\n\t\t\t\ttd_verror(td, EINVAL, \"cpus_split\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\t\tret = fio_setaffinity(td->pid, o->cpumask);\n\t\tif (ret == -1) {\n\t\t\ttd_verror(td, errno, \"cpu_set_affinity\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n#ifdef CONFIG_LIBNUMA\n\t/* numa node setup */\n\tif (fio_option_is_set(o, numa_cpunodes) ||\n\t    fio_option_is_set(o, numa_memnodes)) {\n\t\tstruct bitmask *mask;\n\n\t\tif (numa_available() < 0) {\n\t\t\ttd_verror(td, errno, \"Does not support NUMA API\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (fio_option_is_set(o, numa_cpunodes)) {\n\t\t\tmask = numa_parse_nodestring(o->numa_cpunodes);\n\t\t\tret = numa_run_on_node_mask(mask);\n\t\t\tnuma_free_nodemask(mask);\n\t\t\tif (ret == -1) {\n\t\t\t\ttd_verror(td, errno, \\\n\t\t\t\t\t\"numa_run_on_node_mask failed\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\tif (fio_option_is_set(o, numa_memnodes)) {\n\t\t\tmask = NULL;\n\t\t\tif (o->numa_memnodes)\n\t\t\t\tmask = numa_parse_nodestring(o->numa_memnodes);\n\n\t\t\tswitch (o->numa_mem_mode) {\n\t\t\tcase MPOL_INTERLEAVE:\n\t\t\t\tnuma_set_interleave_mask(mask);\n\t\t\t\tbreak;\n\t\t\tcase MPOL_BIND:\n\t\t\t\tnuma_set_membind(mask);\n\t\t\t\tbreak;\n\t\t\tcase MPOL_LOCAL:\n\t\t\t\tnuma_set_localalloc();\n\t\t\t\tbreak;\n\t\t\tcase MPOL_PREFERRED:\n\t\t\t\tnuma_set_preferred(o->numa_mem_prefer_node);\n\t\t\t\tbreak;\n\t\t\tcase MPOL_DEFAULT:\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (mask)\n\t\t\t\tnuma_free_nodemask(mask);\n\n\t\t}\n\t}\n#endif\n\n\tif (fio_pin_memory(td))\n\t\tgoto err;\n\n\t/*\n\t * May alter parameters that init_io_u() will use, so we need to\n\t * do this first.\n\t */\n\tif (!init_iolog(td))\n\t\tgoto err;\n\n\t/* ioprio_set() has to be done before td_io_init() */\n\tif (fio_option_is_set(o, ioprio) ||\n\t    fio_option_is_set(o, ioprio_class) ||\n\t    fio_option_is_set(o, ioprio_hint)) {\n\t\tret = ioprio_set(IOPRIO_WHO_PROCESS, 0, o->ioprio_class,\n\t\t\t\t o->ioprio, o->ioprio_hint);\n\t\tif (ret == -1) {\n\t\t\ttd_verror(td, errno, \"ioprio_set\");\n\t\t\tgoto err;\n\t\t}\n\t\ttd->ioprio = ioprio_value(o->ioprio_class, o->ioprio,\n\t\t\t\t\t  o->ioprio_hint);\n\t\ttd->ts.ioprio = td->ioprio;\n\t}\n\n\tif (td_io_init(td))\n\t\tgoto err;\n\n\tif (td_ioengine_flagged(td, FIO_SYNCIO) && td->o.iodepth > 1 && td->o.io_submit_mode != IO_MODE_OFFLOAD) {\n\t\tlog_info(\"note: both iodepth >= 1 and synchronous I/O engine \"\n\t\t\t \"are selected, queue depth will be capped at 1\\n\");\n\t}\n\n\tif (init_io_u(td))\n\t\tgoto err;\n\n\tif (td->io_ops->post_init && td->io_ops->post_init(td))\n\t\tgoto err;\n\n\tif (o->verify_async && verify_async_init(td))\n\t\tgoto err;\n\n\tif (o->cgroup && cgroup_setup(td, cgroup_list, &cgroup_mnt))\n\t\tgoto err;\n\n\terrno = 0;\n\tif (nice(o->nice) == -1 && errno != 0) {\n\t\ttd_verror(td, errno, \"nice\");\n\t\tgoto err;\n\t}\n\n\tif (o->ioscheduler && switch_ioscheduler(td))\n\t\tgoto err;\n\n\tif (!o->create_serialize && setup_files(td))\n\t\tgoto err;\n\n\tif (!init_random_map(td))\n\t\tgoto err;\n\n\tif (o->exec_prerun && exec_string(o, o->exec_prerun, \"prerun\"))\n\t\tgoto err;\n\n\tif (o->pre_read && !pre_read_files(td))\n\t\tgoto err;\n\n\tfio_verify_init(td);\n\n\tif (rate_submit_init(td, sk_out))\n\t\tgoto err;\n\n\tset_epoch_time(td, o->log_alternate_epoch_clock_id, o->job_start_clock_id);\n\tfio_getrusage(&td->ru_start);\n\tmemcpy(&td->bw_sample_time, &td->epoch, sizeof(td->epoch));\n\tmemcpy(&td->iops_sample_time, &td->epoch, sizeof(td->epoch));\n\tmemcpy(&td->ss.prev_time, &td->epoch, sizeof(td->epoch));\n\n\tinit_thinktime(td);\n\n\tif (o->ratemin[DDIR_READ] || o->ratemin[DDIR_WRITE] ||\n\t\t\to->ratemin[DDIR_TRIM]) {\n\t        memcpy(&td->last_rate_check_time[DDIR_READ], &td->bw_sample_time,\n\t\t\t\t\tsizeof(td->bw_sample_time));\n\t        memcpy(&td->last_rate_check_time[DDIR_WRITE], &td->bw_sample_time,\n\t\t\t\t\tsizeof(td->bw_sample_time));\n\t        memcpy(&td->last_rate_check_time[DDIR_TRIM], &td->bw_sample_time,\n\t\t\t\t\tsizeof(td->bw_sample_time));\n\t}\n\n\tmemset(bytes_done, 0, sizeof(bytes_done));\n\tclear_state = false;\n\n\twhile (keep_running(td)) {\n\t\tuint64_t verify_bytes;\n\n\t\tfio_gettime(&td->start, NULL);\n\t\tmemcpy(&td->ts_cache, &td->start, sizeof(td->start));\n\n\t\tif (clear_state) {\n\t\t\tclear_io_state(td, 0);\n\n\t\t\tif (o->unlink_each_loop && unlink_all_files(td))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tprune_io_piece_log(td);\n\n\t\tif (td->o.verify_only && td_write(td))\n\t\t\tverify_bytes = do_dry_run(td);\n\t\telse {\n\t\t\tif (!td->o.rand_repeatable)\n\t\t\t\t/* save verify rand state to replay hdr seeds later at verify */\n\t\t\t\tfrand_copy(&td->verify_state_last_do_io, &td->verify_state);\n\t\t\tdo_io(td, bytes_done);\n\t\t\tif (!td->o.rand_repeatable)\n\t\t\t\tfrand_copy(&td->verify_state, &td->verify_state_last_do_io);\n\t\t\tif (!ddir_rw_sum(bytes_done)) {\n\t\t\t\tfio_mark_td_terminate(td);\n\t\t\t\tverify_bytes = 0;\n\t\t\t} else {\n\t\t\t\tverify_bytes = bytes_done[DDIR_WRITE] +\n\t\t\t\t\t\tbytes_done[DDIR_TRIM];\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * If we took too long to shut down, the main thread could\n\t\t * already consider us reaped/exited. If that happens, break\n\t\t * out and clean up.\n\t\t */\n\t\tif (td->runstate >= TD_EXITED)\n\t\t\tbreak;\n\n\t\tclear_state = true;\n\n\t\t/*\n\t\t * Make sure we've successfully updated the rusage stats\n\t\t * before waiting on the stat mutex. Otherwise we could have\n\t\t * the stat thread holding stat mutex and waiting for\n\t\t * the rusage_sem, which would never get upped because\n\t\t * this thread is waiting for the stat mutex.\n\t\t */\n\t\tdeadlock_loop_cnt = 0;\n\t\tdo {\n\t\t\tcheck_update_rusage(td);\n\t\t\tif (!fio_sem_down_trylock(stat_sem))\n\t\t\t\tbreak;\n\t\t\tusleep(1000);\n\t\t\tif (deadlock_loop_cnt++ > 5000) {\n\t\t\t\tlog_err(\"fio seems to be stuck grabbing stat_sem, forcibly exiting\\n\");\n\t\t\t\ttd->error = EDEADLK;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t} while (1);\n\n\t\tif (td->io_bytes[DDIR_READ] && (td_read(td) ||\n\t\t\t((td->flags & TD_F_VER_BACKLOG) && td_write(td))))\n\t\t\tupdate_runtime(td, elapsed_us, DDIR_READ);\n\t\tif (td_write(td) && td->io_bytes[DDIR_WRITE])\n\t\t\tupdate_runtime(td, elapsed_us, DDIR_WRITE);\n\t\tif (td_trim(td) && td->io_bytes[DDIR_TRIM])\n\t\t\tupdate_runtime(td, elapsed_us, DDIR_TRIM);\n\t\tfio_gettime(&td->start, NULL);\n\t\tfio_sem_up(stat_sem);\n\n\t\tif (td->error || td->terminate)\n\t\t\tbreak;\n\n\t\tif (!o->do_verify ||\n\t\t    o->verify == VERIFY_NONE ||\n\t\t    td_ioengine_flagged(td, FIO_UNIDIR))\n\t\t\tcontinue;\n\n\t\tclear_io_state(td, 0);\n\n\t\tfio_gettime(&td->start, NULL);\n\n\t\tdo_verify(td, verify_bytes);\n\n\t\t/*\n\t\t * See comment further up for why this is done here.\n\t\t */\n\t\tcheck_update_rusage(td);\n\n\t\tfio_sem_down(stat_sem);\n\t\tupdate_runtime(td, elapsed_us, DDIR_READ);\n\t\tfio_gettime(&td->start, NULL);\n\t\tfio_sem_up(stat_sem);\n\n\t\tif (td->error || td->terminate)\n\t\t\tbreak;\n\t}\n\n\t/*\n\t * Acquire this lock if we were doing overlap checking in\n\t * offload mode so that we don't clean up this job while\n\t * another thread is checking its io_u's for overlap\n\t */\n\tif (td_offload_overlap(td)) {\n\t\tint res;\n\n\t\tres = pthread_mutex_lock(&overlap_check);\n\t\tif (res) {\n\t\t\ttd->error = errno;\n\t\t\tgoto err;\n\t\t}\n\t}\n\ttd_set_runstate(td, TD_FINISHING);\n\tif (td_offload_overlap(td)) {\n\t\tint res;\n\n\t\tres = pthread_mutex_unlock(&overlap_check);\n\t\tif (res) {\n\t\t\ttd->error = errno;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tupdate_rusage_stat(td);\n\ttd->ts.total_run_time = mtime_since_now(&td->epoch);\n\tfor_each_rw_ddir(ddir) {\n\t\ttd->ts.io_bytes[ddir] = td->io_bytes[ddir];\n\t}\n\n\tif (td->o.verify_state_save && !(td->flags & TD_F_VSTATE_SAVED) &&\n\t    (td->o.verify != VERIFY_NONE && td_write(td)))\n\t\tverify_save_state(td->thread_number);\n\n\tfio_unpin_memory(td);\n\n\ttd_writeout_logs(td, true);\n\n\tiolog_compress_exit(td);\n\trate_submit_exit(td);\n\n\tif (o->exec_postrun)\n\t\texec_string(o, o->exec_postrun, \"postrun\");\n\n\tif (exitall_on_terminate || (o->exitall_error && td->error))\n\t\tfio_terminate_threads(td->groupid, td->o.exit_what);\n\nerr:\n\tif (td->error)\n\t\tlog_info(\"fio: pid=%d, err=%d/%s\\n\", (int) td->pid, td->error,\n\t\t\t\t\t\t\ttd->verror);\n\n\tif (o->verify_async)\n\t\tverify_async_exit(td);\n\n\tclose_and_free_files(td);\n\tcleanup_io_u(td);\n\tclose_ioengine(td);\n\tcgroup_shutdown(td, cgroup_mnt);\n\tverify_free_state(td);\n\ttd_zone_free_index(td);\n\n\tif (fio_option_is_set(o, cpumask)) {\n\t\tret = fio_cpuset_exit(&o->cpumask);\n\t\tif (ret)\n\t\t\ttd_verror(td, ret, \"fio_cpuset_exit\");\n\t}\n\n\t/*\n\t * do this very late, it will log file closing as well\n\t */\n\tif (o->write_iolog_file)\n\t\twrite_iolog_close(td);\n\tif (td->io_log_rfile)\n\t\tfclose(td->io_log_rfile);\n\n\ttd_set_runstate(td, TD_EXITED);\n\n\t/*\n\t * Do this last after setting our runstate to exited, so we\n\t * know that the stat thread is signaled.\n\t */\n\tcheck_update_rusage(td);\n\n\tsk_out_drop();\n\treturn (void *) (uintptr_t) td->error;\n}\n\n/*\n * Run over the job map and reap the threads that have exited, if any.\n */\nstatic void reap_threads(unsigned int *nr_running, uint64_t *t_rate,\n\t\t\t uint64_t *m_rate)\n{\n\tunsigned int cputhreads, realthreads, pending;\n\tint ret;\n\n\t/*\n\t * reap exited threads (TD_EXITED -> TD_REAPED)\n\t */\n\trealthreads = pending = cputhreads = 0;\n\tfor_each_td(td) {\n\t\tint flags = 0, status;\n\n\t\tif (!strcmp(td->o.ioengine, \"cpuio\"))\n\t\t\tcputhreads++;\n\t\telse\n\t\t\trealthreads++;\n\n\t\tif (!td->pid) {\n\t\t\tpending++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (td->runstate == TD_REAPED)\n\t\t\tcontinue;\n\t\tif (td->o.use_thread) {\n\t\t\tif (td->runstate == TD_EXITED) {\n\t\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\t\tgoto reaped;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tflags = WNOHANG;\n\t\tif (td->runstate == TD_EXITED)\n\t\t\tflags = 0;\n\n\t\t/*\n\t\t * check if someone quit or got killed in an unusual way\n\t\t */\n\t\tret = waitpid(td->pid, &status, flags);\n\t\tif (ret < 0) {\n\t\t\tif (errno == ECHILD) {\n\t\t\t\tlog_err(\"fio: pid=%d disappeared %d\\n\",\n\t\t\t\t\t\t(int) td->pid, td->runstate);\n\t\t\t\ttd->sig = ECHILD;\n\t\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\t\tgoto reaped;\n\t\t\t}\n\t\t\tperror(\"waitpid\");\n\t\t} else if (ret == td->pid) {\n\t\t\tif (WIFSIGNALED(status)) {\n\t\t\t\tint sig = WTERMSIG(status);\n\n\t\t\t\tif (sig != SIGTERM && sig != SIGUSR2)\n\t\t\t\t\tlog_err(\"fio: pid=%d, got signal=%d\\n\",\n\t\t\t\t\t\t\t(int) td->pid, sig);\n\t\t\t\ttd->sig = sig;\n\t\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\t\tgoto reaped;\n\t\t\t}\n\t\t\tif (WIFEXITED(status)) {\n\t\t\t\tif (WEXITSTATUS(status) && !td->error)\n\t\t\t\t\ttd->error = WEXITSTATUS(status);\n\n\t\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\t\tgoto reaped;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * If the job is stuck, do a forceful timeout of it and\n\t\t * move on.\n\t\t */\n\t\tif (td->terminate &&\n\t\t    td->runstate < TD_FSYNCING &&\n\t\t    time_since_now(&td->terminate_time) >= FIO_REAP_TIMEOUT) {\n\t\t\tlog_err(\"fio: job '%s' (state=%d) hasn't exited in \"\n\t\t\t\t\"%lu seconds, it appears to be stuck. Doing \"\n\t\t\t\t\"forceful exit of this job.\\n\",\n\t\t\t\ttd->o.name, td->runstate,\n\t\t\t\t(unsigned long) time_since_now(&td->terminate_time));\n\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\tgoto reaped;\n\t\t}\n\n\t\t/*\n\t\t * thread is not dead, continue\n\t\t */\n\t\tpending++;\n\t\tcontinue;\nreaped:\n\t\t(*nr_running)--;\n\t\t(*m_rate) -= ddir_rw_sum(td->o.ratemin);\n\t\t(*t_rate) -= ddir_rw_sum(td->o.rate);\n\t\tif (!td->pid)\n\t\t\tpending--;\n\n\t\tif (td->error)\n\t\t\texit_value++;\n\n\t\tdone_secs += mtime_since_now(&td->epoch) / 1000;\n\t\tprofile_td_exit(td);\n\t\tflow_exit_job(td);\n\t} end_for_each();\n\n\tif (*nr_running == cputhreads && !pending && realthreads)\n\t\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n}\n\nstatic bool __check_trigger_file(void)\n{\n\tstruct stat sb;\n\n\tif (!trigger_file)\n\t\treturn false;\n\n\tif (stat(trigger_file, &sb))\n\t\treturn false;\n\n\tif (unlink(trigger_file) < 0)\n\t\tlog_err(\"fio: failed to unlink %s: %s\\n\", trigger_file,\n\t\t\t\t\t\t\tstrerror(errno));\n\n\treturn true;\n}\n\nstatic bool trigger_timedout(void)\n{\n\tif (trigger_timeout)\n\t\tif (time_since_genesis() >= trigger_timeout) {\n\t\t\ttrigger_timeout = 0;\n\t\t\treturn true;\n\t\t}\n\n\treturn false;\n}\n\nvoid exec_trigger(const char *cmd)\n{\n\tint ret;\n\n\tif (!cmd || cmd[0] == '\\0')\n\t\treturn;\n\n\tret = system(cmd);\n\tif (ret == -1)\n\t\tlog_err(\"fio: failed executing %s trigger\\n\", cmd);\n}\n\nvoid check_trigger_file(void)\n{\n\tif (__check_trigger_file() || trigger_timedout()) {\n\t\tif (nr_clients)\n\t\t\tfio_clients_send_trigger(trigger_remote_cmd);\n\t\telse {\n\t\t\tverify_save_state(IO_LIST_ALL);\n\t\t\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n\t\t\texec_trigger(trigger_cmd);\n\t\t}\n\t}\n}\n\nstatic int fio_verify_load_state(struct thread_data *td)\n{\n\tint ret;\n\n\tif (!td->o.verify_state)\n\t\treturn 0;\n\n\tif (is_backend) {\n\t\tvoid *data;\n\n\t\tret = fio_server_get_verify_state(td->o.name,\n\t\t\t\t\ttd->thread_number - 1, &data);\n\t\tif (!ret)\n\t\t\tverify_assign_state(td, data);\n\t} else {\n\t\tchar prefix[PATH_MAX];\n\n\t\tif (aux_path)\n\t\t\tsprintf(prefix, \"%s%clocal\", aux_path,\n\t\t\t\t\tFIO_OS_PATH_SEPARATOR);\n\t\telse\n\t\t\tstrcpy(prefix, \"local\");\n\t\tret = verify_load_state(td, prefix);\n\t}\n\n\treturn ret;\n}\n\nstatic void do_usleep(unsigned int usecs)\n{\n\tcheck_for_running_stats();\n\tcheck_trigger_file();\n\tusleep(usecs);\n}\n\nstatic bool check_mount_writes(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tif (!td_write(td) || td->o.allow_mounted_write)\n\t\treturn false;\n\n\t/*\n\t * If FIO_HAVE_CHARDEV_SIZE is defined, it's likely that chrdevs\n\t * are mkfs'd and mounted.\n\t */\n\tfor_each_file(td, f, i) {\n#ifdef FIO_HAVE_CHARDEV_SIZE\n\t\tif (f->filetype != FIO_TYPE_BLOCK && f->filetype != FIO_TYPE_CHAR)\n#else\n\t\tif (f->filetype != FIO_TYPE_BLOCK)\n#endif\n\t\t\tcontinue;\n\t\tif (device_is_mounted(f->file_name))\n\t\t\tgoto mounted;\n\t}\n\n\treturn false;\nmounted:\n\tlog_err(\"fio: %s appears mounted, and 'allow_mounted_write' isn't set. Aborting.\\n\", f->file_name);\n\treturn true;\n}\n\nstatic bool waitee_running(struct thread_data *me)\n{\n\tconst char *waitee = me->o.wait_for;\n\tconst char *self = me->o.name;\n\n\tif (!waitee)\n\t\treturn false;\n\n\tfor_each_td(td) {\n\t\tif (!strcmp(td->o.name, self) || strcmp(td->o.name, waitee))\n\t\t\tcontinue;\n\n\t\tif (td->runstate < TD_EXITED) {\n\t\t\tdprint(FD_PROCESS, \"%s fenced by %s(%s)\\n\",\n\t\t\t\t\tself, td->o.name,\n\t\t\t\t\trunstate_to_name(td->runstate));\n\t\t\treturn true;\n\t\t}\n\t} end_for_each();\n\n\tdprint(FD_PROCESS, \"%s: %s completed, can run\\n\", self, waitee);\n\treturn false;\n}\n\n/*\n * Main function for kicking off and reaping jobs, as needed.\n */\nstatic void run_threads(struct sk_out *sk_out)\n{\n\tstruct thread_data *td;\n\tunsigned int i, todo, nr_running, nr_started;\n\tuint64_t m_rate, t_rate;\n\tuint64_t spent;\n\n\tif (fio_gtod_offload && fio_start_gtod_thread())\n\t\treturn;\n\n\tfio_idle_prof_init();\n\n\tset_sig_handlers();\n\n\tnr_thread = nr_process = 0;\n\tfor_each_td(td) {\n\t\tif (check_mount_writes(td))\n\t\t\treturn;\n\t\tif (td->o.use_thread)\n\t\t\tnr_thread++;\n\t\telse\n\t\t\tnr_process++;\n\t} end_for_each();\n\n\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\tstruct buf_output out;\n\n\t\tbuf_output_init(&out);\n\t\t__log_buf(&out, \"Starting \");\n\t\tif (nr_thread)\n\t\t\t__log_buf(&out, \"%d thread%s\", nr_thread,\n\t\t\t\t\t\tnr_thread > 1 ? \"s\" : \"\");\n\t\tif (nr_process) {\n\t\t\tif (nr_thread)\n\t\t\t\t__log_buf(&out, \" and \");\n\t\t\t__log_buf(&out, \"%d process%s\", nr_process,\n\t\t\t\t\t\tnr_process > 1 ? \"es\" : \"\");\n\t\t}\n\t\t__log_buf(&out, \"\\n\");\n\t\tlog_info_buf(out.buf, out.buflen);\n\t\tbuf_output_free(&out);\n\t}\n\n\ttodo = thread_number;\n\tnr_running = 0;\n\tnr_started = 0;\n\tm_rate = t_rate = 0;\n\n\tfor_each_td(td) {\n\t\tprint_status_init(td->thread_number - 1);\n\n\t\tif (!td->o.create_serialize)\n\t\t\tcontinue;\n\n\t\tif (fio_verify_load_state(td))\n\t\t\tgoto reap;\n\n\t\t/*\n\t\t * do file setup here so it happens sequentially,\n\t\t * we don't want X number of threads getting their\n\t\t * client data interspersed on disk\n\t\t */\n\t\tif (setup_files(td)) {\nreap:\n\t\t\texit_value++;\n\t\t\tif (td->error)\n\t\t\t\tlog_err(\"fio: pid=%d, err=%d/%s\\n\",\n\t\t\t\t\t(int) td->pid, td->error, td->verror);\n\t\t\ttd_set_runstate(td, TD_REAPED);\n\t\t\ttodo--;\n\t\t} else {\n\t\t\tstruct fio_file *f;\n\t\t\tunsigned int j;\n\n\t\t\t/*\n\t\t\t * for sharing to work, each job must always open\n\t\t\t * its own files. so close them, if we opened them\n\t\t\t * for creation\n\t\t\t */\n\t\t\tfor_each_file(td, f, j) {\n\t\t\t\tif (fio_file_open(f))\n\t\t\t\t\ttd_io_close_file(td, f);\n\t\t\t}\n\t\t}\n\t} end_for_each();\n\n\t/* start idle threads before io threads start to run */\n\tfio_idle_prof_start();\n\n\tset_genesis_time();\n\n\twhile (todo) {\n\t\tstruct thread_data *map[REAL_MAX_JOBS];\n\t\tstruct timespec this_start;\n\t\tint this_jobs = 0, left;\n\t\tstruct fork_data *fd;\n\n\t\t/*\n\t\t * create threads (TD_NOT_CREATED -> TD_CREATED)\n\t\t */\n\t\tfor_each_td(td) {\n\t\t\tif (td->runstate != TD_NOT_CREATED)\n\t\t\t\tcontinue;\n\n\t\t\t/*\n\t\t\t * never got a chance to start, killed by other\n\t\t\t * thread for some reason\n\t\t\t */\n\t\t\tif (td->terminate) {\n\t\t\t\ttodo--;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (td->o.start_delay) {\n\t\t\t\tspent = utime_since_genesis();\n\n\t\t\t\tif (td->o.start_delay > spent)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (td->o.stonewall && (nr_started || nr_running)) {\n\t\t\t\tdprint(FD_PROCESS, \"%s: stonewall wait\\n\",\n\t\t\t\t\t\t\ttd->o.name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (waitee_running(td)) {\n\t\t\t\tdprint(FD_PROCESS, \"%s: waiting for %s\\n\",\n\t\t\t\t\t\ttd->o.name, td->o.wait_for);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tinit_disk_util(td);\n\n\t\t\ttd->rusage_sem = fio_sem_init(FIO_SEM_LOCKED);\n\t\t\ttd->update_rusage = 0;\n\n\t\t\t/*\n\t\t\t * Set state to created. Thread will transition\n\t\t\t * to TD_INITIALIZED when it's done setting up.\n\t\t\t */\n\t\t\ttd_set_runstate(td, TD_CREATED);\n\t\t\tmap[this_jobs++] = td;\n\t\t\tnr_started++;\n\n\t\t\tfd = calloc(1, sizeof(*fd));\n\t\t\tfd->td = td;\n\t\t\tfd->sk_out = sk_out;\n\n\t\t\tif (td->o.use_thread) {\n\t\t\t\tint ret;\n\n\t\t\t\tdprint(FD_PROCESS, \"will pthread_create\\n\");\n\t\t\t\tret = pthread_create(&td->thread, NULL,\n\t\t\t\t\t\t\tthread_main, fd);\n\t\t\t\tif (ret) {\n\t\t\t\t\tlog_err(\"pthread_create: %s\\n\",\n\t\t\t\t\t\t\tstrerror(ret));\n\t\t\t\t\tfree(fd);\n\t\t\t\t\tnr_started--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tfd = NULL;\n\t\t\t\tret = pthread_detach(td->thread);\n\t\t\t\tif (ret)\n\t\t\t\t\tlog_err(\"pthread_detach: %s\",\n\t\t\t\t\t\t\tstrerror(ret));\n\t\t\t} else {\n\t\t\t\tpid_t pid;\n\t\t\t\tvoid *eo;\n\t\t\t\tdprint(FD_PROCESS, \"will fork\\n\");\n\t\t\t\teo = td->eo;\n\t\t\t\tread_barrier();\n\t\t\t\tpid = fork();\n\t\t\t\tif (!pid) {\n\t\t\t\t\tint ret;\n\n\t\t\t\t\tret = (int)(uintptr_t)thread_main(fd);\n\t\t\t\t\t_exit(ret);\n\t\t\t\t} else if (__td_index == fio_debug_jobno)\n\t\t\t\t\t*fio_debug_jobp = pid;\n\t\t\t\tfree(eo);\n\t\t\t\tfree(fd);\n\t\t\t\tfd = NULL;\n\t\t\t}\n\t\t\tdprint(FD_MUTEX, \"wait on startup_sem\\n\");\n\t\t\tif (fio_sem_down_timeout(startup_sem, 10000)) {\n\t\t\t\tlog_err(\"fio: job startup hung? exiting.\\n\");\n\t\t\t\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n\t\t\t\tfio_abort = true;\n\t\t\t\tnr_started--;\n\t\t\t\tfree(fd);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdprint(FD_MUTEX, \"done waiting on startup_sem\\n\");\n\t\t} end_for_each();\n\n\t\t/*\n\t\t * Wait for the started threads to transition to\n\t\t * TD_INITIALIZED.\n\t\t */\n\t\tfio_gettime(&this_start, NULL);\n\t\tleft = this_jobs;\n\t\twhile (left && !fio_abort) {\n\t\t\tif (mtime_since_now(&this_start) > JOB_START_TIMEOUT)\n\t\t\t\tbreak;\n\n\t\t\tdo_usleep(100000);\n\n\t\t\tfor (i = 0; i < this_jobs; i++) {\n\t\t\t\ttd = map[i];\n\t\t\t\tif (!td)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (td->runstate == TD_INITIALIZED) {\n\t\t\t\t\tmap[i] = NULL;\n\t\t\t\t\tleft--;\n\t\t\t\t} else if (td->runstate >= TD_EXITED) {\n\t\t\t\t\tmap[i] = NULL;\n\t\t\t\t\tleft--;\n\t\t\t\t\ttodo--;\n\t\t\t\t\tnr_running++; /* work-around... */\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (left) {\n\t\t\tlog_err(\"fio: %d job%s failed to start\\n\", left,\n\t\t\t\t\tleft > 1 ? \"s\" : \"\");\n\t\t\tfor (i = 0; i < this_jobs; i++) {\n\t\t\t\ttd = map[i];\n\t\t\t\tif (!td)\n\t\t\t\t\tcontinue;\n\t\t\t\tkill(td->pid, SIGTERM);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * start created threads (TD_INITIALIZED -> TD_RUNNING).\n\t\t */\n\t\tfor_each_td(td) {\n\t\t\tif (td->runstate != TD_INITIALIZED)\n\t\t\t\tcontinue;\n\n\t\t\tif (in_ramp_time(td))\n\t\t\t\ttd_set_runstate(td, TD_RAMP);\n\t\t\telse\n\t\t\t\ttd_set_runstate(td, TD_RUNNING);\n\t\t\tnr_running++;\n\t\t\tnr_started--;\n\t\t\tm_rate += ddir_rw_sum(td->o.ratemin);\n\t\t\tt_rate += ddir_rw_sum(td->o.rate);\n\t\t\ttodo--;\n\t\t\tfio_sem_up(td->sem);\n\t\t} end_for_each();\n\n\t\treap_threads(&nr_running, &t_rate, &m_rate);\n\n\t\tif (todo)\n\t\t\tdo_usleep(100000);\n\t}\n\n\twhile (nr_running) {\n\t\treap_threads(&nr_running, &t_rate, &m_rate);\n\t\tdo_usleep(10000);\n\t}\n\n\tfio_idle_prof_stop();\n\n\tupdate_io_ticks();\n}\n\nstatic void free_disk_util(void)\n{\n\tdisk_util_prune_entries();\n\thelper_thread_destroy();\n}\n\nint fio_backend(struct sk_out *sk_out)\n{\n\tint i;\n\tif (exec_profile) {\n\t\tif (load_profile(exec_profile))\n\t\t\treturn 1;\n\t\tfree(exec_profile);\n\t\texec_profile = NULL;\n\t}\n\tif (!thread_number)\n\t\treturn 0;\n\n\tif (write_bw_log) {\n\t\tstruct log_params p = {\n\t\t\t.log_type = IO_LOG_TYPE_BW,\n\t\t};\n\n\t\tsetup_log(&agg_io_log[DDIR_READ], &p, \"agg-read_bw.log\");\n\t\tsetup_log(&agg_io_log[DDIR_WRITE], &p, \"agg-write_bw.log\");\n\t\tsetup_log(&agg_io_log[DDIR_TRIM], &p, \"agg-trim_bw.log\");\n\t}\n\n\tif (init_global_dedupe_working_set_seeds()) {\n\t\tlog_err(\"fio: failed to initialize global dedupe working set\\n\");\n\t\treturn 1;\n\t}\n\n\tstartup_sem = fio_sem_init(FIO_SEM_LOCKED);\n\tif (!sk_out)\n\t\tis_local_backend = true;\n\tif (startup_sem == NULL)\n\t\treturn 1;\n\n\tset_genesis_time();\n\tstat_init();\n\tif (helper_thread_create(startup_sem, sk_out))\n\t\tlog_err(\"fio: failed to create helper thread\\n\");\n\n\tcgroup_list = smalloc(sizeof(*cgroup_list));\n\tif (cgroup_list)\n\t\tINIT_FLIST_HEAD(cgroup_list);\n\n\trun_threads(sk_out);\n\n\thelper_thread_exit();\n\n\tif (!fio_abort) {\n\t\t__show_run_stats();\n\t\tif (write_bw_log) {\n\t\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\t\tstruct io_log *log = agg_io_log[i];\n\n\t\t\t\tflush_log(log, false);\n\t\t\t\tfree_log(log);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor_each_td(td) {\n\t\tstruct thread_stat *ts = &td->ts;\n\n\t\tfree_clat_prio_stats(ts);\n\t\tsteadystate_free(td);\n\t\tfio_options_free(td);\n\t\tfio_dump_options_free(td);\n\t\tif (td->rusage_sem) {\n\t\t\tfio_sem_remove(td->rusage_sem);\n\t\t\ttd->rusage_sem = NULL;\n\t\t}\n\t\tfio_sem_remove(td->sem);\n\t\ttd->sem = NULL;\n\t} end_for_each();\n\n\tfree_disk_util();\n\tif (cgroup_list) {\n\t\tcgroup_kill(cgroup_list);\n\t\tsfree(cgroup_list);\n\t}\n\n\tfio_sem_remove(startup_sem);\n\tstat_exit();\n\treturn exit_value;\n}\n"
        },
        {
          "name": "blktrace.c",
          "type": "blob",
          "size": 17.953125,
          "content": "/*\n * blktrace support code for fio\n */\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <errno.h>\n#include <sys/sysmacros.h>\n\n#include \"flist.h\"\n#include \"fio.h\"\n#include \"iolog.h\"\n#include \"blktrace.h\"\n#include \"blktrace_api.h\"\n#include \"oslib/linux-dev-lookup.h\"\n\nstruct file_cache {\n\tunsigned int maj;\n\tunsigned int min;\n\tunsigned int fileno;\n};\n\n/*\n * Just discard the pdu by seeking past it.\n */\nstatic int discard_pdu(FILE* f, struct blk_io_trace *t)\n{\n\tif (t->pdu_len == 0)\n\t\treturn 0;\n\n\tdprint(FD_BLKTRACE, \"discard pdu len %u\\n\", t->pdu_len);\n\tif (fseek(f, t->pdu_len, SEEK_CUR) < 0)\n\t\treturn -errno;\n\n\treturn t->pdu_len;\n}\n\n/*\n * Check if this is a blktrace binary data file. We read a single trace\n * into memory and check for the magic signature.\n */\nbool is_blktrace(const char *filename, int *need_swap)\n{\n\tstruct blk_io_trace t;\n\tint fd, ret;\n\n\tfd = open(filename, O_RDONLY);\n\tif (fd < 0)\n\t\treturn false;\n\n\tret = read(fd, &t, sizeof(t));\n\tclose(fd);\n\n\tif (ret < 0) {\n\t\tperror(\"read blktrace\");\n\t\treturn false;\n\t} else if (ret != sizeof(t)) {\n\t\tlog_err(\"fio: short read on blktrace file\\n\");\n\t\treturn false;\n\t}\n\n\tif ((t.magic & 0xffffff00) == BLK_IO_TRACE_MAGIC) {\n\t\t*need_swap = 0;\n\t\treturn true;\n\t}\n\n\t/*\n\t * Maybe it needs to be endian swapped...\n\t */\n\tt.magic = fio_swap32(t.magic);\n\tif ((t.magic & 0xffffff00) == BLK_IO_TRACE_MAGIC) {\n\t\t*need_swap = 1;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n#define FMINORBITS\t20\n#define FMINORMASK\t((1U << FMINORBITS) - 1)\n#define FMAJOR(dev)\t((unsigned int) ((dev) >> FMINORBITS))\n#define FMINOR(dev)\t((unsigned int) ((dev) & FMINORMASK))\n\nstatic void trace_add_open_close_event(struct thread_data *td, int fileno, enum file_log_act action)\n{\n\tstruct io_piece *ipo;\n\n\tipo = calloc(1, sizeof(*ipo));\n\tinit_ipo(ipo);\n\n\tipo->ddir = DDIR_INVAL;\n\tipo->fileno = fileno;\n\tipo->file_action = action;\n\tflist_add_tail(&ipo->list, &td->io_log_list);\n}\n\nstatic int trace_add_file(struct thread_data *td, __u32 device,\n\t\t\t  struct file_cache *cache)\n{\n\tunsigned int maj = FMAJOR(device);\n\tunsigned int min = FMINOR(device);\n\tstruct fio_file *f;\n\tchar dev[256];\n\tunsigned int i;\n\n\tif (cache->maj == maj && cache->min == min)\n\t\treturn cache->fileno;\n\n\tcache->maj = maj;\n\tcache->min = min;\n\n\t/*\n\t * check for this file in our list\n\t */\n\tfor_each_file(td, f, i)\n\t\tif (f->major == maj && f->minor == min) {\n\t\t\tcache->fileno = f->fileno;\n\t\t\treturn cache->fileno;\n\t\t}\n\n\tstrcpy(dev, \"/dev\");\n\tif (blktrace_lookup_device(td->o.replay_redirect, dev, maj, min)) {\n\t\tint fileno;\n\n\t\tif (td->o.replay_redirect)\n\t\t\tdprint(FD_BLKTRACE, \"device lookup: %d/%d\\n overridden\"\n\t\t\t\t\t\" with: %s\\n\", maj, min,\n\t\t\t\t\ttd->o.replay_redirect);\n\t\telse\n\t\t\tdprint(FD_BLKTRACE, \"device lookup: %d/%d\\n\", maj, min);\n\n\t\tdprint(FD_BLKTRACE, \"add devices %s\\n\", dev);\n\t\tfileno = add_file_exclusive(td, dev);\n\t\ttd->o.open_files++;\n\t\ttd->files[fileno]->major = maj;\n\t\ttd->files[fileno]->minor = min;\n\t\ttrace_add_open_close_event(td, fileno, FIO_LOG_OPEN_FILE);\n\t\tcache->fileno = fileno;\n\t}\n\n\treturn cache->fileno;\n}\n\nstatic void t_bytes_align(struct thread_options *o, struct blk_io_trace *t)\n{\n\tif (!o->replay_align)\n\t\treturn;\n\n\tt->bytes = (t->bytes + o->replay_align - 1) & ~(o->replay_align - 1);\n}\n\n/*\n * Store blk_io_trace data in an ipo for later retrieval.\n */\nstatic void store_ipo(struct thread_data *td, unsigned long long offset,\n\t\t      unsigned int bytes, int rw, unsigned long long ttime,\n\t\t      int fileno)\n{\n\tstruct io_piece *ipo;\n\n\tipo = calloc(1, sizeof(*ipo));\n\tinit_ipo(ipo);\n\n\tipo->offset = offset * 512;\n\tif (td->o.replay_scale)\n\t\tipo->offset = ipo->offset / td->o.replay_scale;\n\tipo_bytes_align(td->o.replay_align, ipo);\n\tipo->len = bytes;\n\tipo->delay = ttime / 1000;\n\tif (rw)\n\t\tipo->ddir = DDIR_WRITE;\n\telse\n\t\tipo->ddir = DDIR_READ;\n\tipo->fileno = fileno;\n\n\tdprint(FD_BLKTRACE, \"store ddir=%d, off=%llu, len=%lu, delay=%lu\\n\",\n\t\t\t\t\t\t\tipo->ddir, ipo->offset,\n\t\t\t\t\t\t\tipo->len, ipo->delay);\n\tqueue_io_piece(td, ipo);\n}\n\nstatic bool handle_trace_notify(struct blk_io_trace *t)\n{\n\tswitch (t->action) {\n\tcase BLK_TN_PROCESS:\n\t\tdprint(FD_BLKTRACE, \"got process notify: %x, %d\\n\",\n\t\t\t\tt->action, t->pid);\n\t\tbreak;\n\tcase BLK_TN_TIMESTAMP:\n\t\tdprint(FD_BLKTRACE, \"got timestamp notify: %x, %d\\n\",\n\t\t\t\tt->action, t->pid);\n\t\tbreak;\n\tcase BLK_TN_MESSAGE:\n\t\tbreak;\n\tdefault:\n\t\tdprint(FD_BLKTRACE, \"unknown trace act %x\\n\", t->action);\n\t\tbreak;\n\t}\n\treturn false;\n}\n\nstatic bool handle_trace_discard(struct thread_data *td,\n\t\t\t\t struct blk_io_trace *t,\n\t\t\t\t unsigned long long ttime,\n\t\t\t\t unsigned long *ios, unsigned long long *bs,\n\t\t\t\t struct file_cache *cache)\n{\n\tstruct io_piece *ipo;\n\tint fileno;\n\n\tif (td->o.replay_skip & (1u << DDIR_TRIM))\n\t\treturn false;\n\n\tipo = calloc(1, sizeof(*ipo));\n\tinit_ipo(ipo);\n\tfileno = trace_add_file(td, t->device, cache);\n\n\tios[DDIR_TRIM]++;\n\tif (t->bytes > bs[DDIR_TRIM])\n\t\tbs[DDIR_TRIM] = t->bytes;\n\n\ttd->o.size += t->bytes;\n\n\tINIT_FLIST_HEAD(&ipo->list);\n\n\tipo->offset = t->sector * 512;\n\tif (td->o.replay_scale)\n\t\tipo->offset = ipo->offset / td->o.replay_scale;\n\tipo_bytes_align(td->o.replay_align, ipo);\n\tipo->len = t->bytes;\n\tipo->delay = ttime / 1000;\n\tipo->ddir = DDIR_TRIM;\n\tipo->fileno = fileno;\n\n\tdprint(FD_BLKTRACE, \"store discard, off=%llu, len=%lu, delay=%lu\\n\",\n\t\t\t\t\t\t\tipo->offset, ipo->len,\n\t\t\t\t\t\t\tipo->delay);\n\tqueue_io_piece(td, ipo);\n\treturn true;\n}\n\nstatic void dump_trace(struct blk_io_trace *t)\n{\n\tlog_err(\"blktrace: ignoring zero byte trace: action=%x\\n\", t->action);\n}\n\nstatic bool handle_trace_fs(struct thread_data *td, struct blk_io_trace *t,\n\t\t\t    unsigned long long ttime, unsigned long *ios,\n\t\t\t    unsigned long long *bs, struct file_cache *cache)\n{\n\tint rw;\n\tint fileno;\n\n\tfileno = trace_add_file(td, t->device, cache);\n\n\trw = (t->action & BLK_TC_ACT(BLK_TC_WRITE)) != 0;\n\n\tif (rw) {\n\t\tif (td->o.replay_skip & (1u << DDIR_WRITE))\n\t\t\treturn false;\n\t} else {\n\t\tif (td->o.replay_skip & (1u << DDIR_READ))\n\t\t\treturn false;\n\t}\n\n\tif (!t->bytes) {\n\t\tif (!fio_did_warn(FIO_WARN_BTRACE_ZERO))\n\t\t\tdump_trace(t);\n\t\treturn false;\n\t}\n\n\tif (t->bytes > bs[rw])\n\t\tbs[rw] = t->bytes;\n\n\tios[rw]++;\n\ttd->o.size += t->bytes;\n\tstore_ipo(td, t->sector, t->bytes, rw, ttime, fileno);\n\treturn true;\n}\n\nstatic bool handle_trace_flush(struct thread_data *td, struct blk_io_trace *t,\n\t\t\t       unsigned long long ttime, unsigned long *ios,\n\t\t\t       struct file_cache *cache)\n{\n\tstruct io_piece *ipo;\n\tint fileno;\n\n\tif (td->o.replay_skip & (1u << DDIR_SYNC))\n\t\treturn false;\n\n\tipo = calloc(1, sizeof(*ipo));\n\tinit_ipo(ipo);\n\tfileno = trace_add_file(td, t->device, cache);\n\n\tipo->delay = ttime / 1000;\n\tipo->ddir = DDIR_SYNC;\n\tipo->fileno = fileno;\n\n\tios[DDIR_SYNC]++;\n\tdprint(FD_BLKTRACE, \"store flush delay=%lu\\n\", ipo->delay);\n\n\tif (!(td->flags & TD_F_SYNCS))\n\t\ttd->flags |= TD_F_SYNCS;\n\n\tqueue_io_piece(td, ipo);\n\treturn true;\n}\n\n/*\n * We only care for queue traces, most of the others are side effects\n * due to internal workings of the block layer.\n */\nstatic bool queue_trace(struct thread_data *td, struct blk_io_trace *t,\n\t\t\t unsigned long *ios, unsigned long long *bs,\n\t\t\t struct file_cache *cache)\n{\n\tunsigned long long *last_ttime = &td->io_log_last_ttime;\n\tunsigned long long delay = 0;\n\n\tif ((t->action & 0xffff) != __BLK_TA_QUEUE)\n\t\treturn false;\n\n\tif (!(t->action & BLK_TC_ACT(BLK_TC_NOTIFY))) {\n\t\tdelay = delay_since_ttime(td, t->time);\n\t\t*last_ttime = t->time;\n\t}\n\n\tt_bytes_align(&td->o, t);\n\n\tif (t->action & BLK_TC_ACT(BLK_TC_NOTIFY))\n\t\treturn handle_trace_notify(t);\n\telse if (t->action & BLK_TC_ACT(BLK_TC_DISCARD))\n\t\treturn handle_trace_discard(td, t, delay, ios, bs, cache);\n\telse if (t->action & BLK_TC_ACT(BLK_TC_FLUSH))\n\t\treturn handle_trace_flush(td, t, delay, ios, cache);\n\telse\n\t\treturn handle_trace_fs(td, t, delay, ios, bs, cache);\n}\n\nstatic void byteswap_trace(struct blk_io_trace *t)\n{\n\tt->magic = fio_swap32(t->magic);\n\tt->sequence = fio_swap32(t->sequence);\n\tt->time = fio_swap64(t->time);\n\tt->sector = fio_swap64(t->sector);\n\tt->bytes = fio_swap32(t->bytes);\n\tt->action = fio_swap32(t->action);\n\tt->pid = fio_swap32(t->pid);\n\tt->device = fio_swap32(t->device);\n\tt->cpu = fio_swap32(t->cpu);\n\tt->error = fio_swap16(t->error);\n\tt->pdu_len = fio_swap16(t->pdu_len);\n}\n\nstatic bool t_is_write(struct blk_io_trace *t)\n{\n\treturn (t->action & BLK_TC_ACT(BLK_TC_WRITE | BLK_TC_DISCARD)) != 0;\n}\n\nstatic enum fio_ddir t_get_ddir(struct blk_io_trace *t)\n{\n\tif (t->action & BLK_TC_ACT(BLK_TC_READ))\n\t\treturn DDIR_READ;\n\telse if (t->action & BLK_TC_ACT(BLK_TC_WRITE))\n\t\treturn DDIR_WRITE;\n\telse if (t->action & BLK_TC_ACT(BLK_TC_DISCARD))\n\t\treturn DDIR_TRIM;\n\n\treturn DDIR_INVAL;\n}\n\nstatic void depth_inc(struct blk_io_trace *t, int *depth)\n{\n\tenum fio_ddir ddir;\n\n\tddir = t_get_ddir(t);\n\tif (ddir != DDIR_INVAL)\n\t\tdepth[ddir]++;\n}\n\nstatic void depth_dec(struct blk_io_trace *t, int *depth)\n{\n\tenum fio_ddir ddir;\n\n\tddir = t_get_ddir(t);\n\tif (ddir != DDIR_INVAL)\n\t\tdepth[ddir]--;\n}\n\nstatic void depth_end(struct blk_io_trace *t, int *this_depth, int *depth)\n{\n\tenum fio_ddir ddir = DDIR_INVAL;\n\n\tddir = t_get_ddir(t);\n\tif (ddir != DDIR_INVAL) {\n\t\tdepth[ddir] = max(depth[ddir], this_depth[ddir]);\n\t\tthis_depth[ddir] = 0;\n\t}\n}\n\n/*\n * Load a blktrace file by reading all the blk_io_trace entries, and storing\n * them as io_pieces like the fio text version would do.\n */\nbool init_blktrace_read(struct thread_data *td, const char *filename, int need_swap)\n{\n\tint old_state;\n\n\ttd->io_log_rfile = fopen(filename, \"rb\");\n\tif (!td->io_log_rfile) {\n\t\ttd_verror(td, errno, \"open blktrace file\");\n\t\tgoto err;\n\t}\n\ttd->io_log_blktrace_swap = need_swap;\n\ttd->io_log_last_ttime = 0;\n\ttd->o.size = 0;\n\n\tfree_release_files(td);\n\n\told_state = td_bump_runstate(td, TD_SETTING_UP);\n\n\tif (!read_blktrace(td)) {\n\t\tgoto err;\n\t}\n\n\ttd_restore_runstate(td, old_state);\n\n\tif (!td->files_index) {\n\t\tlog_err(\"fio: did not find replay device(s)\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n\nerr:\n\tif (td->io_log_rfile) {\n\t\tfclose(td->io_log_rfile);\n\t\ttd->io_log_rfile = NULL;\n\t}\n\treturn false;\n}\n\nbool read_blktrace(struct thread_data* td)\n{\n\tstruct blk_io_trace t;\n\tstruct file_cache cache = {\n\t\t.maj = ~0U,\n\t\t.min = ~0U,\n\t};\n\tunsigned long ios[DDIR_RWDIR_SYNC_CNT] = { };\n\tunsigned long long rw_bs[DDIR_RWDIR_CNT] = { };\n\tunsigned long skipped_writes;\n\tFILE *f = td->io_log_rfile;\n\tint i, max_depth;\n\tstruct fio_file *fiof;\n\tint this_depth[DDIR_RWDIR_CNT] = { };\n\tint depth[DDIR_RWDIR_CNT] = { };\n\tint64_t items_to_fetch = 0;\n\n\tif (td->o.read_iolog_chunked) {\n\t\titems_to_fetch = iolog_items_to_fetch(td);\n\t\tif (!items_to_fetch)\n\t\t\treturn true;\n\t}\n\n\tskipped_writes = 0;\n\tdo {\n\t\tint ret = fread(&t, 1, sizeof(t), f);\n\n\t\tif (ferror(f)) {\n\t\t\ttd_verror(td, errno, \"read blktrace file\");\n\t\t\tgoto err;\n\t\t} else if (feof(f)) {\n\t\t\tbreak;\n\t\t} else if (ret < (int) sizeof(t)) {\n\t\t\tlog_err(\"fio: iolog short read\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (td->io_log_blktrace_swap)\n\t\t\tbyteswap_trace(&t);\n\n\t\tif ((t.magic & 0xffffff00) != BLK_IO_TRACE_MAGIC) {\n\t\t\tlog_err(\"fio: bad magic in blktrace data: %x\\n\",\n\t\t\t\t\t\t\t\tt.magic);\n\t\t\tgoto err;\n\t\t}\n\t\tif ((t.magic & 0xff) != BLK_IO_TRACE_VERSION) {\n\t\t\tlog_err(\"fio: bad blktrace version %d\\n\",\n\t\t\t\t\t\t\t\tt.magic & 0xff);\n\t\t\tgoto err;\n\t\t}\n\t\tret = discard_pdu(f, &t);\n\t\tif (ret < 0) {\n\t\t\ttd_verror(td, -ret, \"blktrace lseek\");\n\t\t\tgoto err;\n\t\t}\n\t\tif ((t.action & BLK_TC_ACT(BLK_TC_NOTIFY)) == 0) {\n\t\t\tif ((t.action & 0xffff) == __BLK_TA_QUEUE)\n\t\t\t\tdepth_inc(&t, this_depth);\n\t\t\telse if (((t.action & 0xffff) == __BLK_TA_BACKMERGE) ||\n\t\t\t\t((t.action & 0xffff) == __BLK_TA_FRONTMERGE))\n\t\t\t\tdepth_dec(&t, this_depth);\n\t\t\telse if ((t.action & 0xffff) == __BLK_TA_COMPLETE)\n\t\t\t\tdepth_end(&t, this_depth, depth);\n\n\t\t\tif (t_is_write(&t) && read_only) {\n\t\t\t\tskipped_writes++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (!queue_trace(td, &t, ios, rw_bs, &cache))\n\t\t\tcontinue;\n\n\t\tif (td->o.read_iolog_chunked) {\n\t\t\ttd->io_log_current++;\n\t\t\titems_to_fetch--;\n\t\t\tif (items_to_fetch == 0)\n\t\t\t\tbreak;\n\t\t}\n\t} while (1);\n\n\tif (td->o.read_iolog_chunked) {\n\t\ttd->io_log_highmark = td->io_log_current;\n\t\ttd->io_log_checkmark = (td->io_log_highmark + 1) / 2;\n\t\tfio_gettime(&td->io_log_highmark_time, NULL);\n\t}\n\n\tif (skipped_writes)\n\t\tlog_err(\"fio: %s skips replay of %lu writes due to read-only\\n\",\n\t\t\t\t\t\ttd->o.name, skipped_writes);\n\n\tif (td->o.read_iolog_chunked) {\n\t\tif (td->io_log_current == 0) {\n\t\t\treturn false;\n\t\t}\n\t\ttd->o.td_ddir = TD_DDIR_RW;\n\t\tif ((rw_bs[DDIR_READ] > td->o.max_bs[DDIR_READ] ||\n\t\t     rw_bs[DDIR_WRITE] > td->o.max_bs[DDIR_WRITE] ||\n\t\t     rw_bs[DDIR_TRIM] > td->o.max_bs[DDIR_TRIM]) &&\n\t\t    td->orig_buffer)\n\t\t{\n\t\t\ttd->o.max_bs[DDIR_READ] = max(td->o.max_bs[DDIR_READ], rw_bs[DDIR_READ]);\n\t\t\ttd->o.max_bs[DDIR_WRITE] = max(td->o.max_bs[DDIR_WRITE], rw_bs[DDIR_WRITE]);\n\t\t\ttd->o.max_bs[DDIR_TRIM] = max(td->o.max_bs[DDIR_TRIM], rw_bs[DDIR_TRIM]);\n\t\t\tio_u_quiesce(td);\n\t\t\tfree_io_mem(td);\n\t\t\tif (init_io_u_buffers(td))\n\t\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\n\tfor_each_file(td, fiof, i)\n\t\ttrace_add_open_close_event(td, fiof->fileno, FIO_LOG_CLOSE_FILE);\n\n\tfclose(td->io_log_rfile);\n\ttd->io_log_rfile = NULL;\n\n\t/*\n\t * For stacked devices, we don't always get a COMPLETE event so\n\t * the depth grows to insane values. Limit it to something sane(r).\n\t */\n\tmax_depth = 0;\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (depth[i] > 1024)\n\t\t\tdepth[i] = 1024;\n\t\telse if (!depth[i] && ios[i])\n\t\t\tdepth[i] = 1;\n\t\tmax_depth = max(depth[i], max_depth);\n\t}\n\n\tif (!ios[DDIR_READ] && !ios[DDIR_WRITE] && !ios[DDIR_TRIM] &&\n\t    !ios[DDIR_SYNC]) {\n\t\tlog_err(\"fio: found no ios in blktrace data\\n\");\n\t\treturn false;\n\t}\n\n\ttd->o.td_ddir = 0;\n\tif (ios[DDIR_READ]) {\n\t\ttd->o.td_ddir |= TD_DDIR_READ;\n\t\ttd->o.max_bs[DDIR_READ] = rw_bs[DDIR_READ];\n\t}\n\tif (ios[DDIR_WRITE]) {\n\t\ttd->o.td_ddir |= TD_DDIR_WRITE;\n\t\ttd->o.max_bs[DDIR_WRITE] = rw_bs[DDIR_WRITE];\n\t}\n\tif (ios[DDIR_TRIM]) {\n\t\ttd->o.td_ddir |= TD_DDIR_TRIM;\n\t\ttd->o.max_bs[DDIR_TRIM] = rw_bs[DDIR_TRIM];\n\t}\n\n\t/*\n\t * If depth wasn't manually set, use probed depth\n\t */\n\tif (!fio_option_is_set(&td->o, iodepth))\n\t\ttd->o.iodepth = td->o.iodepth_low = max_depth;\n\n\treturn true;\nerr:\n\tfclose(f);\n\treturn false;\n}\n\nstatic int init_merge_param_list(fio_fp64_t *vals, struct blktrace_cursor *bcs,\n\t\t\t\t int nr_logs, int def, size_t off)\n{\n\tint i = 0, len = 0;\n\n\twhile (len < FIO_IO_U_LIST_MAX_LEN && vals[len].u.f != 0.0)\n\t\tlen++;\n\n\tif (len && len != nr_logs)\n\t\treturn len;\n\n\tfor (i = 0; i < nr_logs; i++) {\n\t\tint *val = (int *)((char *)&bcs[i] + off);\n\t\t*val = def;\n\t\tif (len)\n\t\t\t*val = (int)vals[i].u.f;\n\t}\n\n\treturn 0;\n\n}\n\nstatic int find_earliest_io(struct blktrace_cursor *bcs, int nr_logs)\n{\n\t__u64 time = ~(__u64)0;\n\tint idx = 0, i;\n\n\tfor (i = 0; i < nr_logs; i++) {\n\t\tif (bcs[i].t.time < time) {\n\t\t\ttime = bcs[i].t.time;\n\t\t\tidx = i;\n\t\t}\n\t}\n\n\treturn idx;\n}\n\nstatic void merge_finish_file(struct blktrace_cursor *bcs, int i, int *nr_logs)\n{\n\tbcs[i].iter++;\n\tif (bcs[i].iter < bcs[i].nr_iter) {\n\t\tfseek(bcs[i].f, 0, SEEK_SET);\n\t\treturn;\n\t}\n\n\t*nr_logs -= 1;\n\n\t/* close file */\n\tfclose(bcs[i].f);\n\n\t/* keep active files contiguous */\n\tmemmove(&bcs[i], &bcs[*nr_logs], sizeof(bcs[i]));\n}\n\nstatic int read_trace(struct thread_data *td, struct blktrace_cursor *bc)\n{\n\tint ret = 0;\n\tstruct blk_io_trace *t = &bc->t;\n\nread_skip:\n\t/* read an io trace */\n\tret = fread(&t, 1, sizeof(t), bc->f);\n\tif (ferror(bc->f)) {\n\t\ttd_verror(td, errno, \"read blktrace file\");\n\t\treturn ret;\n\t} else if (feof(bc->f)) {\n\t\tif (!bc->length)\n\t\t\tbc->length = bc->t.time;\n\t\treturn ret;\n\t} else if (ret < (int) sizeof(*t)) {\n\t\tlog_err(\"fio: iolog short read\\n\");\n\t\treturn -1;\n\t}\n\n\tif (bc->swap)\n\t\tbyteswap_trace(t);\n\n\t/* skip over actions that fio does not care about */\n\tif ((t->action & 0xffff) != __BLK_TA_QUEUE ||\n\t    t_get_ddir(t) == DDIR_INVAL) {\n\t\tret = discard_pdu(bc->f, t);\n\t\tif (ret < 0) {\n\t\t\ttd_verror(td, -ret, \"blktrace lseek\");\n\t\t\treturn ret;\n\t\t}\n\t\tgoto read_skip;\n\t}\n\n\tt->time = (t->time + bc->iter * bc->length) * bc->scalar / 100;\n\n\treturn ret;\n}\n\nstatic int write_trace(FILE *fp, struct blk_io_trace *t)\n{\n\t/* pdu is not used so just write out only the io trace */\n\tt->pdu_len = 0;\n\treturn fwrite((void *)t, sizeof(*t), 1, fp);\n}\n\nint merge_blktrace_iologs(struct thread_data *td)\n{\n\tint nr_logs = get_max_str_idx(td->o.read_iolog_file);\n\tstruct blktrace_cursor *bcs = malloc(sizeof(struct blktrace_cursor) *\n\t\t\t\t\t     nr_logs);\n\tstruct blktrace_cursor *bc;\n\tFILE *merge_fp;\n\tchar *str, *ptr, *name, *merge_buf;\n\tint i, ret;\n\n\tret = init_merge_param_list(td->o.merge_blktrace_scalars, bcs, nr_logs,\n\t\t\t\t    100, offsetof(struct blktrace_cursor,\n\t\t\t\t\t\t  scalar));\n\tif (ret) {\n\t\tlog_err(\"fio: merge_blktrace_scalars(%d) != nr_logs(%d)\\n\",\n\t\t\tret, nr_logs);\n\t\tgoto err_param;\n\t}\n\n\tret = init_merge_param_list(td->o.merge_blktrace_iters, bcs, nr_logs,\n\t\t\t\t    1, offsetof(struct blktrace_cursor,\n\t\t\t\t\t\tnr_iter));\n\tif (ret) {\n\t\tlog_err(\"fio: merge_blktrace_iters(%d) != nr_logs(%d)\\n\",\n\t\t\tret, nr_logs);\n\t\tgoto err_param;\n\t}\n\n\t/* setup output file */\n\tmerge_fp = fopen(td->o.merge_blktrace_file, \"w\");\n\tmerge_buf = malloc(128 * 1024);\n\tif (!merge_buf)\n\t\tgoto err_out_file;\n\tret = setvbuf(merge_fp, merge_buf, _IOFBF, 128 * 1024);\n\tif (ret)\n\t\tgoto err_merge_buf;\n\n\t/* setup input files */\n\tstr = ptr = strdup(td->o.read_iolog_file);\n\tnr_logs = 0;\n\tfor (i = 0; (name = get_next_str(&ptr)) != NULL; i++) {\n\t\tbcs[i].f = fopen(name, \"rb\");\n\t\tif (!bcs[i].f) {\n\t\t\tlog_err(\"fio: could not open file: %s\\n\", name);\n\t\t\tret = -errno;\n\t\t\tfree(str);\n\t\t\tgoto err_file;\n\t\t}\n\t\tnr_logs++;\n\n\t\tif (!is_blktrace(name, &bcs[i].swap)) {\n\t\t\tlog_err(\"fio: file is not a blktrace: %s\\n\", name);\n\t\t\tfree(str);\n\t\t\tgoto err_file;\n\t\t}\n\n\t\tret = read_trace(td, &bcs[i]);\n\t\tif (ret < 0) {\n\t\t\tfree(str);\n\t\t\tgoto err_file;\n\t\t} else if (!ret) {\n\t\t\tmerge_finish_file(bcs, i, &nr_logs);\n\t\t\ti--;\n\t\t}\n\t}\n\tfree(str);\n\n\t/* merge files */\n\twhile (nr_logs) {\n\t\ti = find_earliest_io(bcs, nr_logs);\n\t\tbc = &bcs[i];\n\t\t/* skip over the pdu */\n\t\tret = discard_pdu(bc->f, &bc->t);\n\t\tif (ret < 0) {\n\t\t\ttd_verror(td, -ret, \"blktrace lseek\");\n\t\t\tgoto err_file;\n\t\t}\n\n\t\tret = write_trace(merge_fp, &bc->t);\n\t\tret = read_trace(td, bc);\n\t\tif (ret < 0)\n\t\t\tgoto err_file;\n\t\telse if (!ret)\n\t\t\tmerge_finish_file(bcs, i, &nr_logs);\n\t}\n\n\t/* set iolog file to read from the newly merged file */\n\ttd->o.read_iolog_file = td->o.merge_blktrace_file;\n\tret = 0;\n\nerr_file:\n\t/* cleanup */\n\tfor (i = 0; i < nr_logs; i++) {\n\t\tfclose(bcs[i].f);\n\t}\nerr_merge_buf:\n\tfree(merge_buf);\nerr_out_file:\n\tfflush(merge_fp);\n\tfclose(merge_fp);\nerr_param:\n\tfree(bcs);\n\n\treturn ret;\n}\n"
        },
        {
          "name": "blktrace.h",
          "type": "blob",
          "size": 1.0341796875,
          "content": "#ifndef FIO_BLKTRACE_H\n#define FIO_BLKTRACE_H\n\n\n#ifdef FIO_HAVE_BLKTRACE\n\n#include <asm/types.h>\n\n#include \"blktrace_api.h\"\n\nstruct blktrace_cursor {\n\tstruct fifo\t\t*fifo;\t// fifo queue for reading\n\tFILE\t\t\t*f;\t// blktrace file\n\t__u64\t\t\tlength; // length of trace\n\tstruct blk_io_trace\tt;\t// current io trace\n\tint\t\t\tswap;\t// bitwise reverse required\n\tint\t\t\tscalar;\t// scale percentage\n\tint\t\t\titer;\t// current iteration\n\tint\t\t\tnr_iter; // number of iterations to run\n};\n\nbool is_blktrace(const char *, int *);\nbool init_blktrace_read(struct thread_data *, const char *, int);\nbool read_blktrace(struct thread_data* td);\n\nint merge_blktrace_iologs(struct thread_data *td);\n\n#else\n\nstatic inline bool is_blktrace(const char *fname, int *need_swap)\n{\n\treturn false;\n}\n\nstatic inline bool init_blktrace_read(struct thread_data *td, const char *fname,\n\t\t\t\t int need_swap)\n{\n\treturn false;\n}\n\nstatic inline bool read_blktrace(struct thread_data* td)\n{\n\treturn false;\n}\n\n\nstatic inline int merge_blktrace_iologs(struct thread_data *td)\n{\n\treturn false;\n}\n\n#endif\n#endif\n"
        },
        {
          "name": "blktrace_api.h",
          "type": "blob",
          "size": 4.103515625,
          "content": "#ifndef BLKTRACEAPI_H\n#define BLKTRACEAPI_H\n\n#include <asm/types.h>\n\n/*\n * Trace categories\n */\nenum {\n\tBLK_TC_READ\t= 1 << 0,\t/* reads */\n\tBLK_TC_WRITE\t= 1 << 1,\t/* writes */\n\tBLK_TC_FLUSH\t= 1 << 2,\t/* flush */\n\tBLK_TC_SYNC\t= 1 << 3,\t/* sync */\n\tBLK_TC_QUEUE\t= 1 << 4,\t/* queueing/merging */\n\tBLK_TC_REQUEUE\t= 1 << 5,\t/* requeueing */\n\tBLK_TC_ISSUE\t= 1 << 6,\t/* issue */\n\tBLK_TC_COMPLETE\t= 1 << 7,\t/* completions */\n\tBLK_TC_FS\t= 1 << 8,\t/* fs requests */\n\tBLK_TC_PC\t= 1 << 9,\t/* pc requests */\n\tBLK_TC_NOTIFY\t= 1 << 10,\t/* special message */\n\tBLK_TC_AHEAD\t= 1 << 11,\t/* readahead */\n\tBLK_TC_META\t= 1 << 12,\t/* metadata */\n\tBLK_TC_DISCARD\t= 1 << 13,\t/* discard requests */\n\tBLK_TC_DRV_DATA\t= 1 << 14,\t/* binary per-driver data */\n\n\tBLK_TC_END\t= 1 << 15,\t/* only 16-bits, reminder */\n};\n\n#define BLK_TC_SHIFT\t\t(16)\n#define BLK_TC_ACT(act)\t\t((act) << BLK_TC_SHIFT)\n\n/*\n * Basic trace actions\n */\nenum {\n\t__BLK_TA_QUEUE = 1,\t\t/* queued */\n\t__BLK_TA_BACKMERGE,\t\t/* back merged to existing rq */\n\t__BLK_TA_FRONTMERGE,\t\t/* front merge to existing rq */\n\t__BLK_TA_GETRQ,\t\t\t/* allocated new request */\n\t__BLK_TA_SLEEPRQ,\t\t/* sleeping on rq allocation */\n\t__BLK_TA_REQUEUE,\t\t/* request requeued */\n\t__BLK_TA_ISSUE,\t\t\t/* sent to driver */\n\t__BLK_TA_COMPLETE,\t\t/* completed by driver */\n\t__BLK_TA_PLUG,\t\t\t/* queue was plugged */\n\t__BLK_TA_UNPLUG_IO,\t\t/* queue was unplugged by io */\n\t__BLK_TA_UNPLUG_TIMER,\t\t/* queue was unplugged by timer */\n\t__BLK_TA_INSERT,\t\t/* insert request */\n\t__BLK_TA_SPLIT,\t\t\t/* bio was split */\n\t__BLK_TA_BOUNCE,\t\t/* bio was bounced */\n\t__BLK_TA_REMAP,\t\t\t/* bio was remapped */\n\t__BLK_TA_ABORT,\t\t\t/* request aborted */\n\t__BLK_TA_DRV_DATA,\t\t/* driver-specific binary data */\n};\n\n/*\n * Notify events.\n */\nenum blktrace_notify {\n\t__BLK_TN_PROCESS = 0,\t\t/* establish pid/name mapping */\n\t__BLK_TN_TIMESTAMP,\t\t/* include system clock */\n\t__BLK_TN_MESSAGE,\t\t/* Character string message */\n};\n\n/*\n * Trace actions in full. Additionally, read or write is masked\n */\n#define BLK_TA_QUEUE\t\t(__BLK_TA_QUEUE | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_BACKMERGE\t(__BLK_TA_BACKMERGE | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_FRONTMERGE\t(__BLK_TA_FRONTMERGE | BLK_TC_ACT(BLK_TC_QUEUE))\n#define\tBLK_TA_GETRQ\t\t(__BLK_TA_GETRQ | BLK_TC_ACT(BLK_TC_QUEUE))\n#define\tBLK_TA_SLEEPRQ\t\t(__BLK_TA_SLEEPRQ | BLK_TC_ACT(BLK_TC_QUEUE))\n#define\tBLK_TA_REQUEUE\t\t(__BLK_TA_REQUEUE | BLK_TC_ACT(BLK_TC_REQUEUE))\n#define BLK_TA_ISSUE\t\t(__BLK_TA_ISSUE | BLK_TC_ACT(BLK_TC_ISSUE))\n#define BLK_TA_COMPLETE\t\t(__BLK_TA_COMPLETE| BLK_TC_ACT(BLK_TC_COMPLETE))\n#define BLK_TA_PLUG\t\t(__BLK_TA_PLUG | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_UNPLUG_IO\t(__BLK_TA_UNPLUG_IO | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_UNPLUG_TIMER\t(__BLK_TA_UNPLUG_TIMER | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_INSERT\t\t(__BLK_TA_INSERT | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_SPLIT\t\t(__BLK_TA_SPLIT)\n#define BLK_TA_BOUNCE\t\t(__BLK_TA_BOUNCE)\n#define BLK_TA_REMAP\t\t(__BLK_TA_REMAP | BLK_TC_ACT(BLK_TC_QUEUE))\n#define BLK_TA_DRV_DATA (__BLK_TA_DRV_DATA | BLK_TC_ACT(BLK_TC_DRV_DATA))\n\n#define BLK_TN_PROCESS\t\t(__BLK_TN_PROCESS | BLK_TC_ACT(BLK_TC_NOTIFY))\n#define BLK_TN_TIMESTAMP\t(__BLK_TN_TIMESTAMP | BLK_TC_ACT(BLK_TC_NOTIFY))\n#define BLK_TN_MESSAGE          (__BLK_TN_MESSAGE | BLK_TC_ACT(BLK_TC_NOTIFY))\n\n#define BLK_IO_TRACE_MAGIC\t0x65617400\n#define BLK_IO_TRACE_VERSION\t0x07\n\n/*\n * The trace itself\n */\nstruct blk_io_trace {\n\t__u32 magic;\t\t/* MAGIC << 8 | version */\n\t__u32 sequence;\t\t/* event number */\n\t__u64 time;\t\t/* in nanoseconds */\n\t__u64 sector;\t\t/* disk offset */\n\t__u32 bytes;\t\t/* transfer length */\n\t__u32 action;\t\t/* what happened */\n\t__u32 pid;\t\t/* who did it */\n\t__u32 device;\t\t/* device identifier (dev_t) */\n\t__u32 cpu;\t\t/* on what cpu did it happen */\n\t__u16 error;\t\t/* completion error */\n\t__u16 pdu_len;\t\t/* length of data after this trace */\n};\n\n/*\n * The remap event\n */\nstruct blk_io_trace_remap {\n\t__u32 device;\n\t__u32 device_from;\n\t__u64 sector;\n};\n\n/*\n * User setup structure passed with BLKSTARTTRACE\n */\nstruct blk_user_trace_setup {\n\tchar name[32];\t\t\t/* output */\n\t__u16 act_mask;\t\t\t/* input */\n\t__u32 buf_size;\t\t\t/* input */\n\t__u32 buf_nr;\t\t\t/* input */\n\t__u64 start_lba;\n\t__u64 end_lba;\n\t__u32 pid;\n};\n\n#endif\n"
        },
        {
          "name": "cairo_text_helpers.c",
          "type": "blob",
          "size": 2.14453125,
          "content": "#include \"cairo_text_helpers.h\"\n\n#include <cairo.h>\n#include <gtk/gtk.h>\n#include <math.h>\n\nstatic void draw_aligned_text(cairo_t *cr, const char *font, double x, double y,\n\t\t\t       double fontsize, const char *text, int alignment)\n{\n#define CENTERED 0\n#define LEFT_JUSTIFIED 1\n#define RIGHT_JUSTIFIED 2\n\n\tdouble factor, direction;\n\tcairo_text_extents_t extents;\n\n\tswitch (alignment) {\n\t\tcase CENTERED:\n\t\t\tdirection = -1.0;\n\t\t\tfactor = 0.5;\n\t\t\tbreak;\n\t\tcase RIGHT_JUSTIFIED:\n\t\t\tdirection = -1.0;\n\t\t\tfactor = 1.0;\n\t\t\tbreak;\n\t\tcase LEFT_JUSTIFIED:\n\t\tdefault:\n\t\t\tdirection = 1.0;\n\t\t\tfactor = 0.0;\n\t\t\tbreak;\n\t}\n\tcairo_select_font_face(cr, font, CAIRO_FONT_SLANT_NORMAL, CAIRO_FONT_WEIGHT_NORMAL);\n\n\tcairo_set_font_size(cr, fontsize);\n\tcairo_text_extents(cr, text, &extents);\n\tx = x + direction * (factor * extents.width  + extents.x_bearing);\n\ty = y - (extents.height / 2 + extents.y_bearing);\n\n\tcairo_move_to(cr, x, y);\n\tcairo_show_text(cr, text);\n}\n\nvoid draw_centered_text(cairo_t *cr, const char *font, double x, double y,\n\t\t\t       double fontsize, const char *text)\n{\n\tdraw_aligned_text(cr, font, x, y, fontsize, text, CENTERED);\n}\n\nvoid draw_right_justified_text(cairo_t *cr, const char *font,\n\t\t\t\tdouble x, double y,\n\t\t\t\tdouble fontsize, const char *text)\n{\n\tdraw_aligned_text(cr, font, x, y, fontsize, text, RIGHT_JUSTIFIED);\n}\n\nvoid draw_left_justified_text(cairo_t *cr, const char *font,\n\t\t\t\tdouble x, double y,\n\t\t\t\tdouble fontsize, const char *text)\n{\n\tdraw_aligned_text(cr, font, x, y, fontsize, text, LEFT_JUSTIFIED);\n}\n\nvoid draw_vertical_centered_text(cairo_t *cr, const char *font, double x,\n\t\t\t\t\tdouble y, double fontsize,\n\t\t\t\t\tconst char *text)\n{\n\tdouble sx, sy;\n\tcairo_text_extents_t extents;\n\n\tcairo_select_font_face(cr, font, CAIRO_FONT_SLANT_NORMAL, CAIRO_FONT_WEIGHT_NORMAL);\n\n\tcairo_set_font_size(cr, fontsize);\n\tcairo_text_extents(cr, text, &extents);\n\tsx = x;\n\tsy = y;\n\ty = y + (extents.width / 2.0 + extents.x_bearing);\n\tx = x - (extents.height / 2.0 + extents.y_bearing);\n\n\tcairo_move_to(cr, x, y);\n\tcairo_save(cr);\n\tcairo_translate(cr, -sx, -sy);\n\tcairo_rotate(cr, -90.0 * M_PI / 180.0);\n\tcairo_translate(cr, sx, sy);\n\tcairo_show_text(cr, text);\n\tcairo_restore(cr);\n}\n\n"
        },
        {
          "name": "cairo_text_helpers.h",
          "type": "blob",
          "size": 0.5771484375,
          "content": "#ifndef CAIRO_TEXT_HELPERS_H\n#define CAIRO_TEXT_HELPERS_H\n\n#include <cairo.h>\n\nvoid draw_centered_text(cairo_t *cr, const char *font, double x, double y,\n\t\t\t       double fontsize, const char *text);\n\nvoid draw_right_justified_text(cairo_t *cr, const char *font,\n\t\t\t\tdouble x, double y,\n\t\t\t\tdouble fontsize, const char *text);\n\nvoid draw_left_justified_text(cairo_t *cr, const char *font,\n\t\t\t\tdouble x, double y,\n\t\t\t\tdouble fontsize, const char *text);\n\nvoid draw_vertical_centered_text(cairo_t *cr, const char *font, double x,\n\t\t\t\t\tdouble y, double fontsize,\n\t\t\t\t\tconst char *text);\n#endif\n"
        },
        {
          "name": "cconv.c",
          "type": "blob",
          "size": 29.9814453125,
          "content": "#include <string.h>\n\n#include \"log.h\"\n#include \"thread_options.h\"\n\nstatic void string_to_cpu(char **dst, const uint8_t *src)\n{\n\tconst char *__src = (const char *) src;\n\n\tif (strlen(__src))\n\t\t*dst = strdup(__src);\n}\n\nstatic void __string_to_net(uint8_t *dst, const char *src, size_t dst_size)\n{\n\tif (src)\n\t\tsnprintf((char *) dst, dst_size, \"%s\", src);\n\telse\n\t\tdst[0] = '\\0';\n}\n\n#define string_to_net(dst, src)\t__string_to_net((dst), (src), sizeof(dst))\n\nstatic void free_thread_options_to_cpu(struct thread_options *o)\n{\n\tint i;\n\n\tfree(o->description);\n\tfree(o->name);\n\tfree(o->wait_for);\n\tfree(o->directory);\n\tfree(o->filename);\n\tfree(o->filename_format);\n\tfree(o->opendir);\n\tfree(o->ioengine);\n\tfree(o->mmapfile);\n\tfree(o->read_iolog_file);\n\tfree(o->write_iolog_file);\n\tfree(o->merge_blktrace_file);\n\tfree(o->bw_log_file);\n\tfree(o->lat_log_file);\n\tfree(o->iops_log_file);\n\tfree(o->hist_log_file);\n\tfree(o->replay_redirect);\n\tfree(o->exec_prerun);\n\tfree(o->exec_postrun);\n\tfree(o->ioscheduler);\n\tfree(o->profile);\n\tfree(o->cgroup);\n\n\tfree(o->verify_pattern);\n\tfree(o->buffer_pattern);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tfree(o->bssplit[i]);\n\t\tfree(o->zone_split[i]);\n\t}\n}\n\nsize_t thread_options_pack_size(struct thread_options *o)\n{\n\treturn sizeof(struct thread_options_pack) + o->verify_pattern_bytes +\n\t\to->buffer_pattern_bytes;\n}\n\nint convert_thread_options_to_cpu(struct thread_options *o,\n\t\t\t\t  struct thread_options_pack *top,\n\t\t\t\t  size_t top_sz)\n{\n\tint i, j;\n\n\tfor (i = 0; i < NR_OPTS_SZ; i++)\n\t\to->set_options[i] = le64_to_cpu(top->set_options[i]);\n\n\tstring_to_cpu(&o->description, top->description);\n\tstring_to_cpu(&o->name, top->name);\n\tstring_to_cpu(&o->wait_for, top->wait_for);\n\tstring_to_cpu(&o->directory, top->directory);\n\tstring_to_cpu(&o->filename, top->filename);\n\tstring_to_cpu(&o->filename_format, top->filename_format);\n\tstring_to_cpu(&o->opendir, top->opendir);\n\tstring_to_cpu(&o->ioengine, top->ioengine);\n\tstring_to_cpu(&o->mmapfile, top->mmapfile);\n\tstring_to_cpu(&o->read_iolog_file, top->read_iolog_file);\n\tstring_to_cpu(&o->write_iolog_file, top->write_iolog_file);\n\tstring_to_cpu(&o->merge_blktrace_file, top->merge_blktrace_file);\n\tstring_to_cpu(&o->bw_log_file, top->bw_log_file);\n\tstring_to_cpu(&o->lat_log_file, top->lat_log_file);\n\tstring_to_cpu(&o->iops_log_file, top->iops_log_file);\n\tstring_to_cpu(&o->hist_log_file, top->hist_log_file);\n\tstring_to_cpu(&o->replay_redirect, top->replay_redirect);\n\tstring_to_cpu(&o->exec_prerun, top->exec_prerun);\n\tstring_to_cpu(&o->exec_postrun, top->exec_postrun);\n\tstring_to_cpu(&o->ioscheduler, top->ioscheduler);\n\tstring_to_cpu(&o->profile, top->profile);\n\tstring_to_cpu(&o->cgroup, top->cgroup);\n\tstring_to_cpu(&o->dp_scheme_file, top->dp_scheme_file);\n\n\to->allow_create = le32_to_cpu(top->allow_create);\n\to->allow_mounted_write = le32_to_cpu(top->allow_mounted_write);\n\to->td_ddir = le32_to_cpu(top->td_ddir);\n\to->rw_seq = le32_to_cpu(top->rw_seq);\n\to->kb_base = le32_to_cpu(top->kb_base);\n\to->unit_base = le32_to_cpu(top->unit_base);\n\to->ddir_seq_nr = le32_to_cpu(top->ddir_seq_nr);\n\to->ddir_seq_add = le64_to_cpu(top->ddir_seq_add);\n\to->iodepth = le32_to_cpu(top->iodepth);\n\to->iodepth_low = le32_to_cpu(top->iodepth_low);\n\to->iodepth_batch = le32_to_cpu(top->iodepth_batch);\n\to->iodepth_batch_complete_min = le32_to_cpu(top->iodepth_batch_complete_min);\n\to->iodepth_batch_complete_max = le32_to_cpu(top->iodepth_batch_complete_max);\n\to->serialize_overlap = le32_to_cpu(top->serialize_overlap);\n\to->size = le64_to_cpu(top->size);\n\to->io_size = le64_to_cpu(top->io_size);\n\to->num_range = le32_to_cpu(top->num_range);\n\to->size_percent = le32_to_cpu(top->size_percent);\n\to->io_size_percent = le32_to_cpu(top->io_size_percent);\n\to->fill_device = le32_to_cpu(top->fill_device);\n\to->file_append = le32_to_cpu(top->file_append);\n\to->file_size_low = le64_to_cpu(top->file_size_low);\n\to->file_size_high = le64_to_cpu(top->file_size_high);\n\to->start_offset = le64_to_cpu(top->start_offset);\n\to->start_offset_align = le64_to_cpu(top->start_offset_align);\n\to->start_offset_percent = le32_to_cpu(top->start_offset_percent);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\to->bs[i] = le64_to_cpu(top->bs[i]);\n\t\to->ba[i] = le64_to_cpu(top->ba[i]);\n\t\to->min_bs[i] = le64_to_cpu(top->min_bs[i]);\n\t\to->max_bs[i] = le64_to_cpu(top->max_bs[i]);\n\t\to->bssplit_nr[i] = le32_to_cpu(top->bssplit_nr[i]);\n\n\t\tif (o->bssplit_nr[i]) {\n\t\t\to->bssplit[i] = malloc(o->bssplit_nr[i] * sizeof(struct bssplit));\n\t\t\tfor (j = 0; j < o->bssplit_nr[i]; j++) {\n\t\t\t\to->bssplit[i][j].bs = le64_to_cpu(top->bssplit[i][j].bs);\n\t\t\t\to->bssplit[i][j].perc = le32_to_cpu(top->bssplit[i][j].perc);\n\t\t\t}\n\t\t}\n\n\t\to->zone_split_nr[i] = le32_to_cpu(top->zone_split_nr[i]);\n\n\t\tif (o->zone_split_nr[i]) {\n\t\t\to->zone_split[i] = malloc(o->zone_split_nr[i] * sizeof(struct zone_split));\n\t\t\tfor (j = 0; j < o->zone_split_nr[i]; j++) {\n\t\t\t\to->zone_split[i][j].access_perc = top->zone_split[i][j].access_perc;\n\t\t\t\to->zone_split[i][j].size_perc = top->zone_split[i][j].size_perc;\n\t\t\t}\n\t\t}\n\n\t\to->rwmix[i] = le32_to_cpu(top->rwmix[i]);\n\t\to->rate[i] = le64_to_cpu(top->rate[i]);\n\t\to->ratemin[i] = le64_to_cpu(top->ratemin[i]);\n\t\to->rate_iops[i] = le32_to_cpu(top->rate_iops[i]);\n\t\to->rate_iops_min[i] = le32_to_cpu(top->rate_iops_min[i]);\n\n\t\to->perc_rand[i] = le32_to_cpu(top->perc_rand[i]);\n\n\t\to->max_latency[i] = le64_to_cpu(top->max_latency[i]);\n\t}\n\n\to->ratecycle = le32_to_cpu(top->ratecycle);\n\to->io_submit_mode = le32_to_cpu(top->io_submit_mode);\n\to->unique_filename = le32_to_cpu(top->unique_filename);\n\to->nr_files = le32_to_cpu(top->nr_files);\n\to->open_files = le32_to_cpu(top->open_files);\n\to->file_lock_mode = le32_to_cpu(top->file_lock_mode);\n\to->odirect = le32_to_cpu(top->odirect);\n\to->oatomic = le32_to_cpu(top->oatomic);\n\to->invalidate_cache = le32_to_cpu(top->invalidate_cache);\n\to->create_serialize = le32_to_cpu(top->create_serialize);\n\to->create_fsync = le32_to_cpu(top->create_fsync);\n\to->create_on_open = le32_to_cpu(top->create_on_open);\n\to->create_only = le32_to_cpu(top->create_only);\n\to->end_fsync = le32_to_cpu(top->end_fsync);\n\to->pre_read = le32_to_cpu(top->pre_read);\n\to->sync_io = le32_to_cpu(top->sync_io);\n\to->write_hint = le32_to_cpu(top->write_hint);\n\to->verify = le32_to_cpu(top->verify);\n\to->do_verify = le32_to_cpu(top->do_verify);\n\to->experimental_verify = le32_to_cpu(top->experimental_verify);\n\to->verify_state = le32_to_cpu(top->verify_state);\n\to->verify_interval = le32_to_cpu(top->verify_interval);\n\to->verify_offset = le32_to_cpu(top->verify_offset);\n\n\to->verify_pattern_bytes = le32_to_cpu(top->verify_pattern_bytes);\n\to->buffer_pattern_bytes = le32_to_cpu(top->buffer_pattern_bytes);\n\tif (o->verify_pattern_bytes >= MAX_PATTERN_SIZE ||\n\t    o->buffer_pattern_bytes >= MAX_PATTERN_SIZE ||\n\t    thread_options_pack_size(o) > top_sz)\n\t\treturn -EINVAL;\n\n\to->verify_pattern = realloc(o->verify_pattern,\n\t\t\t\t    o->verify_pattern_bytes);\n\to->buffer_pattern = realloc(o->buffer_pattern,\n\t\t\t\t    o->buffer_pattern_bytes);\n\tmemcpy(o->verify_pattern, top->patterns, o->verify_pattern_bytes);\n\tmemcpy(o->buffer_pattern, &top->patterns[o->verify_pattern_bytes],\n\t       o->buffer_pattern_bytes);\n\n\to->verify_fatal = le32_to_cpu(top->verify_fatal);\n\to->verify_dump = le32_to_cpu(top->verify_dump);\n\to->verify_async = le32_to_cpu(top->verify_async);\n\to->verify_batch = le32_to_cpu(top->verify_batch);\n\to->use_thread = le32_to_cpu(top->use_thread);\n\to->unlink = le32_to_cpu(top->unlink);\n\to->unlink_each_loop = le32_to_cpu(top->unlink_each_loop);\n\to->do_disk_util = le32_to_cpu(top->do_disk_util);\n\to->override_sync = le32_to_cpu(top->override_sync);\n\to->rand_repeatable = le32_to_cpu(top->rand_repeatable);\n\to->rand_seed = le64_to_cpu(top->rand_seed);\n\to->log_entries = le32_to_cpu(top->log_entries);\n\to->log_avg_msec = le32_to_cpu(top->log_avg_msec);\n\to->log_hist_msec = le32_to_cpu(top->log_hist_msec);\n\to->log_hist_coarseness = le32_to_cpu(top->log_hist_coarseness);\n\to->log_max = le32_to_cpu(top->log_max);\n\to->log_offset = le32_to_cpu(top->log_offset);\n\to->log_prio = le32_to_cpu(top->log_prio);\n\to->log_issue_time = le32_to_cpu(top->log_issue_time);\n\to->log_gz = le32_to_cpu(top->log_gz);\n\to->log_gz_store = le32_to_cpu(top->log_gz_store);\n\to->log_alternate_epoch = le32_to_cpu(top->log_alternate_epoch);\n\to->log_alternate_epoch_clock_id = le32_to_cpu(top->log_alternate_epoch_clock_id);\n\to->job_start_clock_id = le32_to_cpu(top->job_start_clock_id);\n\to->norandommap = le32_to_cpu(top->norandommap);\n\to->softrandommap = le32_to_cpu(top->softrandommap);\n\to->bs_unaligned = le32_to_cpu(top->bs_unaligned);\n\to->fsync_on_close = le32_to_cpu(top->fsync_on_close);\n\to->bs_is_seq_rand = le32_to_cpu(top->bs_is_seq_rand);\n\to->random_distribution = le32_to_cpu(top->random_distribution);\n\to->exitall_error = le32_to_cpu(top->exitall_error);\n\to->zipf_theta.u.f = fio_uint64_to_double(le64_to_cpu(top->zipf_theta.u.i));\n\to->pareto_h.u.f = fio_uint64_to_double(le64_to_cpu(top->pareto_h.u.i));\n\to->gauss_dev.u.f = fio_uint64_to_double(le64_to_cpu(top->gauss_dev.u.i));\n\to->random_center.u.f = fio_uint64_to_double(le64_to_cpu(top->random_center.u.i));\n\to->random_generator = le32_to_cpu(top->random_generator);\n\to->hugepage_size = le32_to_cpu(top->hugepage_size);\n\to->rw_min_bs = le64_to_cpu(top->rw_min_bs);\n\to->thinkcycles = le32_to_cpu(top->thinkcycles);\n\to->thinktime = le32_to_cpu(top->thinktime);\n\to->thinktime_spin = le32_to_cpu(top->thinktime_spin);\n\to->thinktime_blocks = le32_to_cpu(top->thinktime_blocks);\n\to->thinktime_blocks_type = le32_to_cpu(top->thinktime_blocks_type);\n\to->thinktime_iotime = le32_to_cpu(top->thinktime_iotime);\n\to->fsync_blocks = le32_to_cpu(top->fsync_blocks);\n\to->fdatasync_blocks = le32_to_cpu(top->fdatasync_blocks);\n\to->barrier_blocks = le32_to_cpu(top->barrier_blocks);\n\n\to->verify_backlog = le64_to_cpu(top->verify_backlog);\n\to->start_delay = le64_to_cpu(top->start_delay);\n\to->start_delay_high = le64_to_cpu(top->start_delay_high);\n\to->timeout = le64_to_cpu(top->timeout);\n\to->ramp_time = le64_to_cpu(top->ramp_time);\n\to->ss_dur = le64_to_cpu(top->ss_dur);\n\to->ss_ramp_time = le64_to_cpu(top->ss_ramp_time);\n\to->ss_state = le32_to_cpu(top->ss_state);\n\to->ss_limit.u.f = fio_uint64_to_double(le64_to_cpu(top->ss_limit.u.i));\n\to->ss_check_interval = le64_to_cpu(top->ss_check_interval);\n\to->zone_range = le64_to_cpu(top->zone_range);\n\to->zone_size = le64_to_cpu(top->zone_size);\n\to->zone_capacity = le64_to_cpu(top->zone_capacity);\n\to->zone_skip = le64_to_cpu(top->zone_skip);\n\to->zone_mode = le32_to_cpu(top->zone_mode);\n\to->max_open_zones = __le32_to_cpu(top->max_open_zones);\n\to->ignore_zone_limits = le32_to_cpu(top->ignore_zone_limits);\n\to->lockmem = le64_to_cpu(top->lockmem);\n\to->offset_increment_percent = le32_to_cpu(top->offset_increment_percent);\n\to->offset_increment = le64_to_cpu(top->offset_increment);\n\to->number_ios = le64_to_cpu(top->number_ios);\n\n\to->overwrite = le32_to_cpu(top->overwrite);\n\to->bw_avg_time = le32_to_cpu(top->bw_avg_time);\n\to->iops_avg_time = le32_to_cpu(top->iops_avg_time);\n\to->loops = le32_to_cpu(top->loops);\n\to->mem_type = le32_to_cpu(top->mem_type);\n\to->mem_align = le32_to_cpu(top->mem_align);\n\to->exit_what = le32_to_cpu(top->exit_what);\n\to->stonewall = le32_to_cpu(top->stonewall);\n\to->new_group = le32_to_cpu(top->new_group);\n\to->numjobs = le32_to_cpu(top->numjobs);\n\to->cpus_allowed_policy = le32_to_cpu(top->cpus_allowed_policy);\n\to->gpu_dev_id = le32_to_cpu(top->gpu_dev_id);\n\to->iolog = le32_to_cpu(top->iolog);\n\to->rwmixcycle = le32_to_cpu(top->rwmixcycle);\n\to->nice = le32_to_cpu(top->nice);\n\to->ioprio = le32_to_cpu(top->ioprio);\n\to->ioprio_class = le32_to_cpu(top->ioprio_class);\n\to->ioprio_hint = le32_to_cpu(top->ioprio_hint);\n\to->file_service_type = le32_to_cpu(top->file_service_type);\n\to->group_reporting = le32_to_cpu(top->group_reporting);\n\to->stats = le32_to_cpu(top->stats);\n\to->fadvise_hint = le32_to_cpu(top->fadvise_hint);\n\to->fallocate_mode = le32_to_cpu(top->fallocate_mode);\n\to->zero_buffers = le32_to_cpu(top->zero_buffers);\n\to->refill_buffers = le32_to_cpu(top->refill_buffers);\n\to->scramble_buffers = le32_to_cpu(top->scramble_buffers);\n\to->time_based = le32_to_cpu(top->time_based);\n\to->disable_lat = le32_to_cpu(top->disable_lat);\n\to->disable_clat = le32_to_cpu(top->disable_clat);\n\to->disable_slat = le32_to_cpu(top->disable_slat);\n\to->disable_bw = le32_to_cpu(top->disable_bw);\n\to->unified_rw_rep = le32_to_cpu(top->unified_rw_rep);\n\to->gtod_reduce = le32_to_cpu(top->gtod_reduce);\n\to->gtod_cpu = le32_to_cpu(top->gtod_cpu);\n\to->clocksource = le32_to_cpu(top->clocksource);\n\to->no_stall = le32_to_cpu(top->no_stall);\n\to->trim_percentage = le32_to_cpu(top->trim_percentage);\n\to->trim_batch = le32_to_cpu(top->trim_batch);\n\to->trim_zero = le32_to_cpu(top->trim_zero);\n\to->clat_percentiles = le32_to_cpu(top->clat_percentiles);\n\to->lat_percentiles = le32_to_cpu(top->lat_percentiles);\n\to->slat_percentiles = le32_to_cpu(top->slat_percentiles);\n\to->percentile_precision = le32_to_cpu(top->percentile_precision);\n\to->sig_figs = le32_to_cpu(top->sig_figs);\n\to->continue_on_error = le32_to_cpu(top->continue_on_error);\n\to->cgroup_weight = le32_to_cpu(top->cgroup_weight);\n\to->cgroup_nodelete = le32_to_cpu(top->cgroup_nodelete);\n\to->uid = le32_to_cpu(top->uid);\n\to->gid = le32_to_cpu(top->gid);\n\to->flow_id = __le32_to_cpu(top->flow_id);\n\to->flow = le32_to_cpu(top->flow);\n\to->flow_sleep = le32_to_cpu(top->flow_sleep);\n\to->sync_file_range = le32_to_cpu(top->sync_file_range);\n\to->latency_target = le64_to_cpu(top->latency_target);\n\to->latency_window = le64_to_cpu(top->latency_window);\n\to->latency_percentile.u.f = fio_uint64_to_double(le64_to_cpu(top->latency_percentile.u.i));\n\to->latency_run = le32_to_cpu(top->latency_run);\n\to->compress_percentage = le32_to_cpu(top->compress_percentage);\n\to->compress_chunk = le32_to_cpu(top->compress_chunk);\n\to->dedupe_percentage = le32_to_cpu(top->dedupe_percentage);\n\to->dedupe_mode = le32_to_cpu(top->dedupe_mode);\n\to->dedupe_working_set_percentage = le32_to_cpu(top->dedupe_working_set_percentage);\n\to->dedupe_global = le32_to_cpu(top->dedupe_global);\n\to->block_error_hist = le32_to_cpu(top->block_error_hist);\n\to->replay_align = le32_to_cpu(top->replay_align);\n\to->replay_scale = le32_to_cpu(top->replay_scale);\n\to->replay_time_scale = le32_to_cpu(top->replay_time_scale);\n\to->replay_skip = le32_to_cpu(top->replay_skip);\n\to->per_job_logs = le32_to_cpu(top->per_job_logs);\n\to->write_bw_log = le32_to_cpu(top->write_bw_log);\n\to->write_lat_log = le32_to_cpu(top->write_lat_log);\n\to->write_iops_log = le32_to_cpu(top->write_iops_log);\n\to->write_hist_log = le32_to_cpu(top->write_hist_log);\n\n\to->trim_backlog = le64_to_cpu(top->trim_backlog);\n\to->rate_process = le32_to_cpu(top->rate_process);\n\to->rate_ign_think = le32_to_cpu(top->rate_ign_think);\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\to->percentile_list[i].u.f = fio_uint64_to_double(le64_to_cpu(top->percentile_list[i].u.i));\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\to->merge_blktrace_scalars[i].u.f = fio_uint64_to_double(le64_to_cpu(top->merge_blktrace_scalars[i].u.i));\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\to->merge_blktrace_iters[i].u.f = fio_uint64_to_double(le64_to_cpu(top->merge_blktrace_iters[i].u.i));\n\n\to->fdp = le32_to_cpu(top->fdp);\n\to->dp_type = le32_to_cpu(top->dp_type);\n\to->dp_id_select = le32_to_cpu(top->dp_id_select);\n\to->dp_nr_ids = le32_to_cpu(top->dp_nr_ids);\n\tfor (i = 0; i < o->dp_nr_ids; i++)\n\t\to->dp_ids[i] = le16_to_cpu(top->dp_ids[i]);\n#if 0\n\tuint8_t cpumask[FIO_TOP_STR_MAX];\n\tuint8_t verify_cpumask[FIO_TOP_STR_MAX];\n\tuint8_t log_gz_cpumask[FIO_TOP_STR_MAX];\n#endif\n\n\treturn 0;\n}\n\nvoid convert_thread_options_to_net(struct thread_options_pack *top,\n\t\t\t\t   struct thread_options *o)\n{\n\tint i, j;\n\n\tfor (i = 0; i < NR_OPTS_SZ; i++)\n\t\ttop->set_options[i] = cpu_to_le64(o->set_options[i]);\n\n\tstring_to_net(top->description, o->description);\n\tstring_to_net(top->name, o->name);\n\tstring_to_net(top->wait_for, o->wait_for);\n\tstring_to_net(top->directory, o->directory);\n\tstring_to_net(top->filename, o->filename);\n\tstring_to_net(top->filename_format, o->filename_format);\n\tstring_to_net(top->opendir, o->opendir);\n\tstring_to_net(top->ioengine, o->ioengine);\n\tstring_to_net(top->mmapfile, o->mmapfile);\n\tstring_to_net(top->read_iolog_file, o->read_iolog_file);\n\tstring_to_net(top->write_iolog_file, o->write_iolog_file);\n\tstring_to_net(top->merge_blktrace_file, o->merge_blktrace_file);\n\tstring_to_net(top->bw_log_file, o->bw_log_file);\n\tstring_to_net(top->lat_log_file, o->lat_log_file);\n\tstring_to_net(top->iops_log_file, o->iops_log_file);\n\tstring_to_net(top->hist_log_file, o->hist_log_file);\n\tstring_to_net(top->replay_redirect, o->replay_redirect);\n\tstring_to_net(top->exec_prerun, o->exec_prerun);\n\tstring_to_net(top->exec_postrun, o->exec_postrun);\n\tstring_to_net(top->ioscheduler, o->ioscheduler);\n\tstring_to_net(top->profile, o->profile);\n\tstring_to_net(top->cgroup, o->cgroup);\n\tstring_to_net(top->dp_scheme_file, o->dp_scheme_file);\n\n\ttop->allow_create = cpu_to_le32(o->allow_create);\n\ttop->allow_mounted_write = cpu_to_le32(o->allow_mounted_write);\n\ttop->td_ddir = cpu_to_le32(o->td_ddir);\n\ttop->rw_seq = cpu_to_le32(o->rw_seq);\n\ttop->kb_base = cpu_to_le32(o->kb_base);\n\ttop->unit_base = cpu_to_le32(o->unit_base);\n\ttop->ddir_seq_nr = cpu_to_le32(o->ddir_seq_nr);\n\ttop->iodepth = cpu_to_le32(o->iodepth);\n\ttop->iodepth_low = cpu_to_le32(o->iodepth_low);\n\ttop->iodepth_batch = cpu_to_le32(o->iodepth_batch);\n\ttop->iodepth_batch_complete_min = cpu_to_le32(o->iodepth_batch_complete_min);\n\ttop->iodepth_batch_complete_max = cpu_to_le32(o->iodepth_batch_complete_max);\n\ttop->serialize_overlap = cpu_to_le32(o->serialize_overlap);\n\ttop->size_percent = cpu_to_le32(o->size_percent);\n\ttop->io_size_percent = cpu_to_le32(o->io_size_percent);\n\ttop->fill_device = cpu_to_le32(o->fill_device);\n\ttop->file_append = cpu_to_le32(o->file_append);\n\ttop->ratecycle = cpu_to_le32(o->ratecycle);\n\ttop->io_submit_mode = cpu_to_le32(o->io_submit_mode);\n\ttop->nr_files = cpu_to_le32(o->nr_files);\n\ttop->unique_filename = cpu_to_le32(o->unique_filename);\n\ttop->open_files = cpu_to_le32(o->open_files);\n\ttop->file_lock_mode = cpu_to_le32(o->file_lock_mode);\n\ttop->odirect = cpu_to_le32(o->odirect);\n\ttop->oatomic = cpu_to_le32(o->oatomic);\n\ttop->invalidate_cache = cpu_to_le32(o->invalidate_cache);\n\ttop->create_serialize = cpu_to_le32(o->create_serialize);\n\ttop->create_fsync = cpu_to_le32(o->create_fsync);\n\ttop->create_on_open = cpu_to_le32(o->create_on_open);\n\ttop->create_only = cpu_to_le32(o->create_only);\n\ttop->end_fsync = cpu_to_le32(o->end_fsync);\n\ttop->pre_read = cpu_to_le32(o->pre_read);\n\ttop->sync_io = cpu_to_le32(o->sync_io);\n\ttop->write_hint = cpu_to_le32(o->write_hint);\n\ttop->verify = cpu_to_le32(o->verify);\n\ttop->do_verify = cpu_to_le32(o->do_verify);\n\ttop->experimental_verify = cpu_to_le32(o->experimental_verify);\n\ttop->verify_state = cpu_to_le32(o->verify_state);\n\ttop->verify_interval = cpu_to_le32(o->verify_interval);\n\ttop->verify_offset = cpu_to_le32(o->verify_offset);\n\ttop->verify_pattern_bytes = cpu_to_le32(o->verify_pattern_bytes);\n\ttop->verify_fatal = cpu_to_le32(o->verify_fatal);\n\ttop->verify_dump = cpu_to_le32(o->verify_dump);\n\ttop->verify_async = cpu_to_le32(o->verify_async);\n\ttop->verify_batch = cpu_to_le32(o->verify_batch);\n\ttop->use_thread = cpu_to_le32(o->use_thread);\n\ttop->unlink = cpu_to_le32(o->unlink);\n\ttop->unlink_each_loop = cpu_to_le32(o->unlink_each_loop);\n\ttop->do_disk_util = cpu_to_le32(o->do_disk_util);\n\ttop->override_sync = cpu_to_le32(o->override_sync);\n\ttop->rand_repeatable = cpu_to_le32(o->rand_repeatable);\n\ttop->rand_seed = __cpu_to_le64(o->rand_seed);\n\ttop->log_entries = cpu_to_le32(o->log_entries);\n\ttop->log_avg_msec = cpu_to_le32(o->log_avg_msec);\n\ttop->log_max = cpu_to_le32(o->log_max);\n\ttop->log_offset = cpu_to_le32(o->log_offset);\n\ttop->log_prio = cpu_to_le32(o->log_prio);\n\ttop->log_issue_time = cpu_to_le32(o->log_issue_time);\n\ttop->log_gz = cpu_to_le32(o->log_gz);\n\ttop->log_gz_store = cpu_to_le32(o->log_gz_store);\n\ttop->log_alternate_epoch = cpu_to_le32(o->log_alternate_epoch);\n\ttop->log_alternate_epoch_clock_id = cpu_to_le32(o->log_alternate_epoch_clock_id);\n\ttop->job_start_clock_id = cpu_to_le32(o->job_start_clock_id);\n\ttop->norandommap = cpu_to_le32(o->norandommap);\n\ttop->softrandommap = cpu_to_le32(o->softrandommap);\n\ttop->bs_unaligned = cpu_to_le32(o->bs_unaligned);\n\ttop->fsync_on_close = cpu_to_le32(o->fsync_on_close);\n\ttop->bs_is_seq_rand = cpu_to_le32(o->bs_is_seq_rand);\n\ttop->random_distribution = cpu_to_le32(o->random_distribution);\n\ttop->exitall_error = cpu_to_le32(o->exitall_error);\n\ttop->zipf_theta.u.i = __cpu_to_le64(fio_double_to_uint64(o->zipf_theta.u.f));\n\ttop->pareto_h.u.i = __cpu_to_le64(fio_double_to_uint64(o->pareto_h.u.f));\n\ttop->gauss_dev.u.i = __cpu_to_le64(fio_double_to_uint64(o->gauss_dev.u.f));\n\ttop->random_center.u.i = __cpu_to_le64(fio_double_to_uint64(o->random_center.u.f));\n\ttop->random_generator = cpu_to_le32(o->random_generator);\n\ttop->hugepage_size = cpu_to_le32(o->hugepage_size);\n\ttop->rw_min_bs = __cpu_to_le64(o->rw_min_bs);\n\ttop->thinkcycles = cpu_to_le32(o->thinkcycles);\n\ttop->thinktime = cpu_to_le32(o->thinktime);\n\ttop->thinktime_spin = cpu_to_le32(o->thinktime_spin);\n\ttop->thinktime_blocks = cpu_to_le32(o->thinktime_blocks);\n\ttop->thinktime_blocks_type = __cpu_to_le32(o->thinktime_blocks_type);\n\ttop->thinktime_iotime = __cpu_to_le32(o->thinktime_iotime);\n\ttop->fsync_blocks = cpu_to_le32(o->fsync_blocks);\n\ttop->fdatasync_blocks = cpu_to_le32(o->fdatasync_blocks);\n\ttop->barrier_blocks = cpu_to_le32(o->barrier_blocks);\n\ttop->overwrite = cpu_to_le32(o->overwrite);\n\ttop->bw_avg_time = cpu_to_le32(o->bw_avg_time);\n\ttop->iops_avg_time = cpu_to_le32(o->iops_avg_time);\n\ttop->loops = cpu_to_le32(o->loops);\n\ttop->mem_type = cpu_to_le32(o->mem_type);\n\ttop->mem_align = cpu_to_le32(o->mem_align);\n\ttop->exit_what = cpu_to_le32(o->exit_what);\n\ttop->stonewall = cpu_to_le32(o->stonewall);\n\ttop->new_group = cpu_to_le32(o->new_group);\n\ttop->numjobs = cpu_to_le32(o->numjobs);\n\ttop->cpus_allowed_policy = cpu_to_le32(o->cpus_allowed_policy);\n\ttop->gpu_dev_id = cpu_to_le32(o->gpu_dev_id);\n\ttop->iolog = cpu_to_le32(o->iolog);\n\ttop->rwmixcycle = cpu_to_le32(o->rwmixcycle);\n\ttop->nice = cpu_to_le32(o->nice);\n\ttop->ioprio = cpu_to_le32(o->ioprio);\n\ttop->ioprio_class = cpu_to_le32(o->ioprio_class);\n\ttop->ioprio_hint = cpu_to_le32(o->ioprio_hint);\n\ttop->file_service_type = cpu_to_le32(o->file_service_type);\n\ttop->group_reporting = cpu_to_le32(o->group_reporting);\n\ttop->stats = cpu_to_le32(o->stats);\n\ttop->fadvise_hint = cpu_to_le32(o->fadvise_hint);\n\ttop->fallocate_mode = cpu_to_le32(o->fallocate_mode);\n\ttop->zero_buffers = cpu_to_le32(o->zero_buffers);\n\ttop->refill_buffers = cpu_to_le32(o->refill_buffers);\n\ttop->scramble_buffers = cpu_to_le32(o->scramble_buffers);\n\ttop->buffer_pattern_bytes = cpu_to_le32(o->buffer_pattern_bytes);\n\ttop->time_based = cpu_to_le32(o->time_based);\n\ttop->disable_lat = cpu_to_le32(o->disable_lat);\n\ttop->disable_clat = cpu_to_le32(o->disable_clat);\n\ttop->disable_slat = cpu_to_le32(o->disable_slat);\n\ttop->disable_bw = cpu_to_le32(o->disable_bw);\n\ttop->unified_rw_rep = cpu_to_le32(o->unified_rw_rep);\n\ttop->gtod_reduce = cpu_to_le32(o->gtod_reduce);\n\ttop->gtod_cpu = cpu_to_le32(o->gtod_cpu);\n\ttop->clocksource = cpu_to_le32(o->clocksource);\n\ttop->no_stall = cpu_to_le32(o->no_stall);\n\ttop->trim_percentage = cpu_to_le32(o->trim_percentage);\n\ttop->trim_batch = cpu_to_le32(o->trim_batch);\n\ttop->trim_zero = cpu_to_le32(o->trim_zero);\n\ttop->clat_percentiles = cpu_to_le32(o->clat_percentiles);\n\ttop->lat_percentiles = cpu_to_le32(o->lat_percentiles);\n\ttop->slat_percentiles = cpu_to_le32(o->slat_percentiles);\n\ttop->percentile_precision = cpu_to_le32(o->percentile_precision);\n\ttop->sig_figs = cpu_to_le32(o->sig_figs);\n\ttop->continue_on_error = cpu_to_le32(o->continue_on_error);\n\ttop->cgroup_weight = cpu_to_le32(o->cgroup_weight);\n\ttop->cgroup_nodelete = cpu_to_le32(o->cgroup_nodelete);\n\ttop->uid = cpu_to_le32(o->uid);\n\ttop->gid = cpu_to_le32(o->gid);\n\ttop->flow_id = __cpu_to_le32(o->flow_id);\n\ttop->flow = cpu_to_le32(o->flow);\n\ttop->flow_sleep = cpu_to_le32(o->flow_sleep);\n\ttop->sync_file_range = cpu_to_le32(o->sync_file_range);\n\ttop->latency_target = __cpu_to_le64(o->latency_target);\n\ttop->latency_window = __cpu_to_le64(o->latency_window);\n\ttop->latency_percentile.u.i = __cpu_to_le64(fio_double_to_uint64(o->latency_percentile.u.f));\n\ttop->latency_run = __cpu_to_le32(o->latency_run);\n\ttop->compress_percentage = cpu_to_le32(o->compress_percentage);\n\ttop->compress_chunk = cpu_to_le32(o->compress_chunk);\n\ttop->dedupe_percentage = cpu_to_le32(o->dedupe_percentage);\n\ttop->dedupe_mode = cpu_to_le32(o->dedupe_mode);\n\ttop->dedupe_working_set_percentage = cpu_to_le32(o->dedupe_working_set_percentage);\n\ttop->dedupe_global = cpu_to_le32(o->dedupe_global);\n\ttop->block_error_hist = cpu_to_le32(o->block_error_hist);\n\ttop->replay_align = cpu_to_le32(o->replay_align);\n\ttop->replay_scale = cpu_to_le32(o->replay_scale);\n\ttop->replay_time_scale = cpu_to_le32(o->replay_time_scale);\n\ttop->replay_skip = cpu_to_le32(o->replay_skip);\n\ttop->per_job_logs = cpu_to_le32(o->per_job_logs);\n\ttop->write_bw_log = cpu_to_le32(o->write_bw_log);\n\ttop->write_lat_log = cpu_to_le32(o->write_lat_log);\n\ttop->write_iops_log = cpu_to_le32(o->write_iops_log);\n\ttop->write_hist_log = cpu_to_le32(o->write_hist_log);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\ttop->bs[i] = __cpu_to_le64(o->bs[i]);\n\t\ttop->ba[i] = __cpu_to_le64(o->ba[i]);\n\t\ttop->min_bs[i] = __cpu_to_le64(o->min_bs[i]);\n\t\ttop->max_bs[i] = __cpu_to_le64(o->max_bs[i]);\n\t\ttop->bssplit_nr[i] = cpu_to_le32(o->bssplit_nr[i]);\n\n\t\tif (o->bssplit_nr[i]) {\n\t\t\tunsigned int bssplit_nr = o->bssplit_nr[i];\n\n\t\t\tif (bssplit_nr > BSSPLIT_MAX) {\n\t\t\t\tlog_err(\"fio: BSSPLIT_MAX is too small\\n\");\n\t\t\t\tbssplit_nr = BSSPLIT_MAX;\n\t\t\t}\n\t\t\tfor (j = 0; j < bssplit_nr; j++) {\n\t\t\t\ttop->bssplit[i][j].bs = cpu_to_le64(o->bssplit[i][j].bs);\n\t\t\t\ttop->bssplit[i][j].perc = cpu_to_le32(o->bssplit[i][j].perc);\n\t\t\t}\n\t\t}\n\n\t\ttop->zone_split_nr[i] = cpu_to_le32(o->zone_split_nr[i]);\n\n\t\tif (o->zone_split_nr[i]) {\n\t\t\tunsigned int zone_split_nr = o->zone_split_nr[i];\n\n\t\t\tif (zone_split_nr > ZONESPLIT_MAX) {\n\t\t\t\tlog_err(\"fio: ZONESPLIT_MAX is too small\\n\");\n\t\t\t\tzone_split_nr = ZONESPLIT_MAX;\n\t\t\t}\n\t\t\tfor (j = 0; j < zone_split_nr; j++) {\n\t\t\t\ttop->zone_split[i][j].access_perc = o->zone_split[i][j].access_perc;\n\t\t\t\ttop->zone_split[i][j].size_perc = o->zone_split[i][j].size_perc;\n\t\t\t}\n\t\t}\n\n\t\ttop->rwmix[i] = cpu_to_le32(o->rwmix[i]);\n\t\ttop->rate[i] = cpu_to_le64(o->rate[i]);\n\t\ttop->ratemin[i] = cpu_to_le64(o->ratemin[i]);\n\t\ttop->rate_iops[i] = cpu_to_le32(o->rate_iops[i]);\n\t\ttop->rate_iops_min[i] = cpu_to_le32(o->rate_iops_min[i]);\n\n\t\ttop->perc_rand[i] = cpu_to_le32(o->perc_rand[i]);\n\n\t\ttop->max_latency[i] = __cpu_to_le64(o->max_latency[i]);\n\t}\n\n\tmemcpy(top->patterns, o->verify_pattern, o->verify_pattern_bytes);\n\tmemcpy(&top->patterns[o->verify_pattern_bytes], o->buffer_pattern,\n\t       o->buffer_pattern_bytes);\n\n\ttop->size = __cpu_to_le64(o->size);\n\ttop->io_size = __cpu_to_le64(o->io_size);\n\ttop->num_range = __cpu_to_le32(o->num_range);\n\ttop->verify_backlog = __cpu_to_le64(o->verify_backlog);\n\ttop->start_delay = __cpu_to_le64(o->start_delay);\n\ttop->start_delay_high = __cpu_to_le64(o->start_delay_high);\n\ttop->timeout = __cpu_to_le64(o->timeout);\n\ttop->ramp_time = __cpu_to_le64(o->ramp_time);\n\ttop->ss_dur = __cpu_to_le64(top->ss_dur);\n\ttop->ss_ramp_time = __cpu_to_le64(top->ss_ramp_time);\n\ttop->ss_state = cpu_to_le32(top->ss_state);\n\ttop->ss_limit.u.i = __cpu_to_le64(fio_double_to_uint64(o->ss_limit.u.f));\n\ttop->ss_check_interval = __cpu_to_le64(top->ss_check_interval);\n\ttop->zone_range = __cpu_to_le64(o->zone_range);\n\ttop->zone_size = __cpu_to_le64(o->zone_size);\n\ttop->zone_capacity = __cpu_to_le64(o->zone_capacity);\n\ttop->zone_skip = __cpu_to_le64(o->zone_skip);\n\ttop->zone_mode = __cpu_to_le32(o->zone_mode);\n\ttop->max_open_zones = __cpu_to_le32(o->max_open_zones);\n\ttop->ignore_zone_limits = cpu_to_le32(o->ignore_zone_limits);\n\ttop->lockmem = __cpu_to_le64(o->lockmem);\n\ttop->ddir_seq_add = __cpu_to_le64(o->ddir_seq_add);\n\ttop->file_size_low = __cpu_to_le64(o->file_size_low);\n\ttop->file_size_high = __cpu_to_le64(o->file_size_high);\n\ttop->start_offset = __cpu_to_le64(o->start_offset);\n\ttop->start_offset_align = __cpu_to_le64(o->start_offset_align);\n\ttop->start_offset_percent = __cpu_to_le32(o->start_offset_percent);\n\ttop->trim_backlog = __cpu_to_le64(o->trim_backlog);\n\ttop->offset_increment_percent = __cpu_to_le32(o->offset_increment_percent);\n\ttop->offset_increment = __cpu_to_le64(o->offset_increment);\n\ttop->number_ios = __cpu_to_le64(o->number_ios);\n\ttop->rate_process = cpu_to_le32(o->rate_process);\n\ttop->rate_ign_think = cpu_to_le32(o->rate_ign_think);\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\ttop->percentile_list[i].u.i = __cpu_to_le64(fio_double_to_uint64(o->percentile_list[i].u.f));\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\ttop->merge_blktrace_scalars[i].u.i = __cpu_to_le64(fio_double_to_uint64(o->merge_blktrace_scalars[i].u.f));\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\ttop->merge_blktrace_iters[i].u.i = __cpu_to_le64(fio_double_to_uint64(o->merge_blktrace_iters[i].u.f));\n\n\ttop->fdp = cpu_to_le32(o->fdp);\n\ttop->dp_type = cpu_to_le32(o->dp_type);\n\ttop->dp_id_select = cpu_to_le32(o->dp_id_select);\n\ttop->dp_nr_ids = cpu_to_le32(o->dp_nr_ids);\n\tfor (i = 0; i < o->dp_nr_ids; i++)\n\t\ttop->dp_ids[i] = cpu_to_le16(o->dp_ids[i]);\n#if 0\n\tuint8_t cpumask[FIO_TOP_STR_MAX];\n\tuint8_t verify_cpumask[FIO_TOP_STR_MAX];\n\tuint8_t log_gz_cpumask[FIO_TOP_STR_MAX];\n#endif\n}\n\n/*\n * Basic conversion test. We'd really need to fill in more of the options\n * to have a thorough test. Even better, we should auto-generate the\n * converter functions...\n */\nint fio_test_cconv(struct thread_options *__o)\n{\n\tstruct thread_options o1 = *__o, o2;\n\tstruct thread_options_pack *top1, *top2;\n\tsize_t top_sz;\n\tint ret;\n\n\to1.verify_pattern_bytes = 61;\n\to1.verify_pattern = malloc(o1.verify_pattern_bytes);\n\tmemset(o1.verify_pattern, 'V', o1.verify_pattern_bytes);\n\to1.buffer_pattern_bytes = 15;\n\to1.buffer_pattern = malloc(o1.buffer_pattern_bytes);\n\tmemset(o1.buffer_pattern, 'B', o1.buffer_pattern_bytes);\n\n\ttop_sz = thread_options_pack_size(&o1);\n\ttop1 = calloc(1, top_sz);\n\ttop2 = calloc(1, top_sz);\n\n\tconvert_thread_options_to_net(top1, &o1);\n\tmemset(&o2, 0, sizeof(o2));\n\tret = convert_thread_options_to_cpu(&o2, top1, top_sz);\n\tif (ret)\n\t\tgoto out;\n\n\tconvert_thread_options_to_net(top2, &o2);\n\tret = memcmp(top1, top2, top_sz);\n\nout:\n\tfree_thread_options_to_cpu(&o2);\n\tfree(top2);\n\tfree(top1);\n\tfree(o1.buffer_pattern);\n\tfree(o1.verify_pattern);\n\treturn ret;\n}\n"
        },
        {
          "name": "cgroup.c",
          "type": "blob",
          "size": 4.4052734375,
          "content": "/*\n * Code related to setting up a blkio cgroup\n */\n#include <stdio.h>\n#include <stdlib.h>\n#include <mntent.h>\n#include <sys/stat.h>\n#include \"fio.h\"\n#include \"flist.h\"\n#include \"cgroup.h\"\n#include \"smalloc.h\"\n\nstatic struct fio_sem *lock;\n\nstruct cgroup_member {\n\tstruct flist_head list;\n\tchar *root;\n\tunsigned int cgroup_nodelete;\n};\n\nstatic struct cgroup_mnt *find_cgroup_mnt(struct thread_data *td)\n{\n\tstruct cgroup_mnt *cgroup_mnt = NULL;\n\tstruct mntent *mnt, dummy;\n\tchar buf[256] = {0};\n\tFILE *f;\n\tbool cgroup2 = false;\n\n\tf = setmntent(\"/proc/mounts\", \"r\");\n\tif (!f) {\n\t\ttd_verror(td, errno, \"setmntent /proc/mounts\");\n\t\treturn NULL;\n\t}\n\n\twhile ((mnt = getmntent_r(f, &dummy, buf, sizeof(buf))) != NULL) {\n\t\tif (!strcmp(mnt->mnt_type, \"cgroup\") &&\n\t\t    strstr(mnt->mnt_opts, \"blkio\"))\n\t\t\tbreak;\n\t\tif (!strcmp(mnt->mnt_type, \"cgroup2\")) {\n\t\t\tcgroup2 = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (mnt) {\n\t\tcgroup_mnt = smalloc(sizeof(*cgroup_mnt));\n\t\tif (cgroup_mnt) {\n\t\t\tcgroup_mnt->path = smalloc_strdup(mnt->mnt_dir);\n\t\t\tif (!cgroup_mnt->path) {\n\t\t\t\tsfree(cgroup_mnt);\n\t\t\t\tlog_err(\"fio: could not allocate memory\\n\");\n\t\t\t} else {\n\t\t\t\tcgroup_mnt->cgroup2 = cgroup2;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlog_err(\"fio: cgroup blkio does not appear to be mounted\\n\");\n\t}\n\n\tendmntent(f);\n\treturn cgroup_mnt;\n}\n\nstatic void add_cgroup(struct thread_data *td, const char *name,\n\t\t\tstruct flist_head *clist)\n{\n\tstruct cgroup_member *cm;\n\n\tif (!lock)\n\t\treturn;\n\n\tcm = smalloc(sizeof(*cm));\n\tif (!cm) {\nerr:\n\t\tlog_err(\"fio: failed to allocate cgroup member\\n\");\n\t\treturn;\n\t}\n\n\tINIT_FLIST_HEAD(&cm->list);\n\tcm->root = smalloc_strdup(name);\n\tif (!cm->root) {\n\t\tsfree(cm);\n\t\tgoto err;\n\t}\n\tif (td->o.cgroup_nodelete)\n\t\tcm->cgroup_nodelete = 1;\n\tfio_sem_down(lock);\n\tflist_add_tail(&cm->list, clist);\n\tfio_sem_up(lock);\n}\n\nvoid cgroup_kill(struct flist_head *clist)\n{\n\tstruct flist_head *n, *tmp;\n\tstruct cgroup_member *cm;\n\n\tif (!lock)\n\t\treturn;\n\n\tfio_sem_down(lock);\n\n\tflist_for_each_safe(n, tmp, clist) {\n\t\tcm = flist_entry(n, struct cgroup_member, list);\n\t\tif (!cm->cgroup_nodelete)\n\t\t\trmdir(cm->root);\n\t\tflist_del(&cm->list);\n\t\tsfree(cm->root);\n\t\tsfree(cm);\n\t}\n\n\tfio_sem_up(lock);\n}\n\nstatic char *get_cgroup_root(struct thread_data *td, struct cgroup_mnt *mnt)\n{\n\tchar *str = malloc(64);\n\n\tif (td->o.cgroup)\n\t\tsprintf(str, \"%s/%s\", mnt->path, td->o.cgroup);\n\telse\n\t\tsprintf(str, \"%s/%s\", mnt->path, td->o.name);\n\n\treturn str;\n}\n\nstatic int write_int_to_file(struct thread_data *td, const char *path,\n\t\t\t     const char *filename, unsigned int val,\n\t\t\t     const char *onerr)\n{\n\tchar tmp[256];\n\tFILE *f;\n\n\tsprintf(tmp, \"%s/%s\", path, filename);\n\tf = fopen(tmp, \"w\");\n\tif (!f) {\n\t\ttd_verror(td, errno, onerr);\n\t\treturn 1;\n\t}\n\n\tfprintf(f, \"%u\", val);\n\tfclose(f);\n\treturn 0;\n\n}\n\nstatic int cgroup_write_pid(struct thread_data *td, char *path, bool cgroup2)\n{\n\tunsigned int val = td->pid;\n\n\tif (cgroup2)\n\t\treturn write_int_to_file(td, path, \"cgroup.procs\",\n\t\t\t\t\t val, \"cgroup write pid\");\n\treturn write_int_to_file(td, path, \"tasks\", val, \"cgroup write pid\");\n}\n\n/*\n * Move pid to root class\n */\nstatic int cgroup_del_pid(struct thread_data *td, struct cgroup_mnt *mnt)\n{\n\treturn cgroup_write_pid(td, mnt->path, mnt->cgroup2);\n}\n\nint cgroup_setup(struct thread_data *td, struct flist_head *clist, struct cgroup_mnt **mnt)\n{\n\tchar *root;\n\n\tif (!clist)\n\t\treturn 1;\n\n\tif (!*mnt) {\n\t\t*mnt = find_cgroup_mnt(td);\n\t\tif (!*mnt)\n\t\t\treturn 1;\n\t}\n\n\t/*\n\t * Create container, if it doesn't exist\n\t */\n\troot = get_cgroup_root(td, *mnt);\n\tif (mkdir(root, 0755) < 0) {\n\t\tint __e = errno;\n\n\t\tif (__e != EEXIST) {\n\t\t\ttd_verror(td, __e, \"cgroup mkdir\");\n\t\t\tlog_err(\"fio: path %s\\n\", root);\n\t\t\tgoto err;\n\t\t}\n\t} else\n\t\tadd_cgroup(td, root, clist);\n\n\tif (td->o.cgroup_weight) {\n\t\tif ((*mnt)->cgroup2) {\n\t\t\tlog_err(\"fio: cgroup weit doesn't work with cgroup2\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tif (write_int_to_file(td, root, \"blkio.weight\",\n\t\t\t\t\ttd->o.cgroup_weight,\n\t\t\t\t\t\"cgroup open weight\"))\n\t\t\tgoto err;\n\t}\n\n\tif (!cgroup_write_pid(td, root, (*mnt)->cgroup2)) {\n\t\tfree(root);\n\t\treturn 0;\n\t}\n\nerr:\n\tfree(root);\n\treturn 1;\n}\n\nvoid cgroup_shutdown(struct thread_data *td, struct cgroup_mnt *mnt)\n{\n\tif (mnt == NULL)\n\t\treturn;\n\tif (!td->o.cgroup_weight && !td->o.cgroup)\n\t\tgoto out;\n\n\tcgroup_del_pid(td, mnt);\nout:\n\tif (mnt->path)\n\t\tsfree(mnt->path);\n\tsfree(mnt);\n}\n\nstatic void fio_init cgroup_init(void)\n{\n\tlock = fio_sem_init(FIO_SEM_UNLOCKED);\n\tif (!lock)\n\t\tlog_err(\"fio: failed to allocate cgroup lock\\n\");\n}\n\nstatic void fio_exit cgroup_exit(void)\n{\n\tfio_sem_remove(lock);\n}\n"
        },
        {
          "name": "cgroup.h",
          "type": "blob",
          "size": 0.658203125,
          "content": "#ifndef FIO_CGROUP_H\n#define FIO_CGROUP_H\n\n#ifdef FIO_HAVE_CGROUPS\n\nstruct cgroup_mnt {\n\tchar *path;\n\tbool cgroup2;\n};\n\nint cgroup_setup(struct thread_data *, struct flist_head *, struct cgroup_mnt **);\nvoid cgroup_shutdown(struct thread_data *, struct cgroup_mnt *);\n\nvoid cgroup_kill(struct flist_head *list);\n\n#else\n\nstruct cgroup_mnt;\n\nstatic inline int cgroup_setup(struct thread_data *td, struct flist_head *list,\n\t\t\t       struct cgroup_mnt **mnt)\n{\n\ttd_verror(td, EINVAL, \"cgroup_setup\");\n\treturn 1;\n}\n\nstatic inline void cgroup_shutdown(struct thread_data *td, struct cgroup_mnt *mnt)\n{\n}\n\nstatic inline void cgroup_kill(struct flist_head *list)\n{\n}\n\n#endif\n#endif\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "client.c",
          "type": "blob",
          "size": 52.818359375,
          "content": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <poll.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <sys/socket.h>\n#include <sys/un.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <netdb.h>\n#include <signal.h>\n#ifdef CONFIG_ZLIB\n#include <zlib.h>\n#endif\n\n#include \"fio.h\"\n#include \"client.h\"\n#include \"server.h\"\n#include \"flist.h\"\n#include \"hash.h\"\n#include \"verify-state.h\"\n\nstatic void handle_du(struct fio_client *client, struct fio_net_cmd *cmd);\nstatic void handle_ts(struct fio_client *client, struct fio_net_cmd *cmd);\nstatic void handle_gs(struct fio_client *client, struct fio_net_cmd *cmd);\nstatic void handle_probe(struct fio_client *client, struct fio_net_cmd *cmd);\nstatic void handle_text(struct fio_client *client, struct fio_net_cmd *cmd);\nstatic void handle_stop(struct fio_client *client);\nstatic void handle_start(struct fio_client *client, struct fio_net_cmd *cmd);\n\nstatic void convert_text(struct fio_net_cmd *cmd);\nstatic void client_display_thread_status(struct jobs_eta *je);\n\nstruct client_ops const fio_client_ops = {\n\t.text\t\t= handle_text,\n\t.disk_util\t= handle_du,\n\t.thread_status\t= handle_ts,\n\t.group_stats\t= handle_gs,\n\t.stop\t\t= handle_stop,\n\t.start\t\t= handle_start,\n\t.eta\t\t= client_display_thread_status,\n\t.probe\t\t= handle_probe,\n\t.eta_msec\t= FIO_CLIENT_DEF_ETA_MSEC,\n\t.client_type\t= FIO_CLIENT_TYPE_CLI,\n};\n\nstatic struct timespec eta_ts;\n\nstatic FLIST_HEAD(client_list);\nstatic FLIST_HEAD(eta_list);\n\nstatic FLIST_HEAD(arg_list);\n\nstruct thread_stat client_ts;\nstruct group_run_stats client_gs;\nint sum_stat_clients;\n\nstatic int sum_stat_nr;\nstatic struct buf_output allclients;\nstatic struct json_object *root = NULL;\nstatic struct json_object *job_opt_object = NULL;\nstatic struct json_array *clients_array = NULL;\nstatic struct json_array *du_array = NULL;\n\nstatic int error_clients;\n\n#define FIO_CLIENT_HASH_BITS\t7\n#define FIO_CLIENT_HASH_SZ\t(1 << FIO_CLIENT_HASH_BITS)\n#define FIO_CLIENT_HASH_MASK\t(FIO_CLIENT_HASH_SZ - 1)\nstatic struct flist_head client_hash[FIO_CLIENT_HASH_SZ];\n\nstatic struct cmd_iolog_pdu *convert_iolog(struct fio_net_cmd *, bool *);\n\nstatic void fio_client_add_hash(struct fio_client *client)\n{\n\tint bucket = hash_long(client->fd, FIO_CLIENT_HASH_BITS);\n\n\tbucket &= FIO_CLIENT_HASH_MASK;\n\tflist_add(&client->hash_list, &client_hash[bucket]);\n}\n\nstatic void fio_client_remove_hash(struct fio_client *client)\n{\n\tif (!flist_empty(&client->hash_list))\n\t\tflist_del_init(&client->hash_list);\n}\n\nstatic void fio_init fio_client_hash_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < FIO_CLIENT_HASH_SZ; i++)\n\t\tINIT_FLIST_HEAD(&client_hash[i]);\n}\n\nstatic int read_data(int fd, void *data, size_t size)\n{\n\tssize_t ret;\n\n\twhile (size) {\n\t\tret = read(fd, data, size);\n\t\tif (ret < 0) {\n\t\t\tif (errno == EAGAIN || errno == EINTR)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t} else if (!ret)\n\t\t\tbreak;\n\t\telse {\n\t\t\tdata += ret;\n\t\t\tsize -= ret;\n\t\t}\n\t}\n\n\tif (size)\n\t\treturn EAGAIN;\n\n\treturn 0;\n}\n\nstatic int read_ini_data(int fd, void *data, size_t size)\n{\n\tchar *p = data;\n\tint ret = 0;\n\tFILE *fp;\n\tint dupfd;\n\n\tdupfd = dup(fd);\n\tif (dupfd < 0)\n\t\treturn errno;\n\n\tfp = fdopen(dupfd, \"r\");\n\tif (!fp) {\n\t\tret = errno;\n\t\tclose(dupfd);\n\t\tgoto out;\n\t}\n\n\twhile (1) {\n\t\tssize_t len;\n\t\tchar buf[OPT_LEN_MAX+1], *sub;\n\n\t\tif (!fgets(buf, sizeof(buf), fp)) {\n\t\t\tif (ferror(fp)) {\n\t\t\t\tif (errno == EAGAIN || errno == EINTR)\n\t\t\t\t\tcontinue;\n\t\t\t\tret = errno;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tsub = fio_option_dup_subs(buf);\n\t\tlen = strlen(sub);\n\t\tif (len + 1 > size) {\n\t\t\tlog_err(\"fio: no space left to read data\\n\");\n\t\t\tfree(sub);\n\t\t\tret = ENOSPC;\n\t\t\tbreak;\n\t\t}\n\n\t\tmemcpy(p, sub, len);\n\t\tfree(sub);\n\t\tp += len;\n\t\t*p = '\\0';\n\t\tsize -= len;\n\t}\n\n\tfclose(fp);\nout:\n\treturn ret;\n}\n\nstatic void fio_client_json_init(void)\n{\n\tchar time_buf[32];\n\ttime_t time_p;\n\n\tif (!(output_format & FIO_OUTPUT_JSON))\n\t\treturn;\n\n\ttime(&time_p);\n\tos_ctime_r((const time_t *) &time_p, time_buf, sizeof(time_buf));\n\ttime_buf[strlen(time_buf) - 1] = '\\0';\n\n\troot = json_create_object();\n\tjson_object_add_value_string(root, \"fio version\", fio_version_string);\n\tjson_object_add_value_int(root, \"timestamp\", time_p);\n\tjson_object_add_value_string(root, \"time\", time_buf);\n\n\tjob_opt_object = json_create_object();\n\tjson_object_add_value_object(root, \"global options\", job_opt_object);\n\tclients_array = json_create_array();\n\tjson_object_add_value_array(root, \"client_stats\", clients_array);\n\tdu_array = json_create_array();\n\tjson_object_add_value_array(root, \"disk_util\", du_array);\n}\n\nstatic void fio_client_json_fini(void)\n{\n\tstruct buf_output out;\n\n\tif (!root)\n\t\treturn;\n\n\tbuf_output_init(&out);\n\n\t__log_buf(&out, \"\\n\");\n\tjson_print_object(root, &out);\n\t__log_buf(&out, \"\\n\");\n\tlog_info_buf(out.buf, out.buflen);\n\n\tbuf_output_free(&out);\n\n\tjson_free_object(root);\n\troot = NULL;\n\tjob_opt_object = NULL;\n\tclients_array = NULL;\n\tdu_array = NULL;\n}\n\nstatic struct fio_client *find_client_by_fd(int fd)\n{\n\tint bucket = hash_long(fd, FIO_CLIENT_HASH_BITS) & FIO_CLIENT_HASH_MASK;\n\tstruct fio_client *client;\n\tstruct flist_head *entry;\n\n\tflist_for_each(entry, &client_hash[bucket]) {\n\t\tclient = flist_entry(entry, struct fio_client, hash_list);\n\n\t\tif (client->fd == fd) {\n\t\t\tclient->refs++;\n\t\t\treturn client;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nvoid fio_put_client(struct fio_client *client)\n{\n\tif (--client->refs)\n\t\treturn;\n\n\tlog_info_buf(client->buf.buf, client->buf.buflen);\n\tbuf_output_free(&client->buf);\n\n\tfree(client->hostname);\n\tif (client->argv)\n\t\tfree(client->argv);\n\tif (client->name)\n\t\tfree(client->name);\n\twhile (client->nr_files) {\n\t\tstruct client_file *cf = &client->files[--client->nr_files];\n\n\t\tfree(cf->file);\n\t}\n\tif (client->files)\n\t\tfree(client->files);\n\tif (client->opt_lists)\n\t\tfree(client->opt_lists);\n\n\tif (!client->did_stat)\n\t\tsum_stat_clients--;\n\n\tif (client->error)\n\t\terror_clients++;\n\n\tfree(client);\n}\n\nstatic int fio_client_dec_jobs_eta(struct client_eta *eta, client_eta_op eta_fn)\n{\n\tif (!--eta->pending) {\n\t\teta_fn(&eta->eta);\n\t\tfree(eta);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void fio_drain_client_text(struct fio_client *client)\n{\n\tdo {\n\t\tstruct fio_net_cmd *cmd = NULL;\n\n\t\tif (fio_server_poll_fd(client->fd, POLLIN, 0))\n\t\t\tcmd = fio_net_recv_cmd(client->fd, false);\n\t\tif (!cmd)\n\t\t\tbreak;\n\n\t\tif (cmd->opcode == FIO_NET_CMD_TEXT) {\n\t\t\tconvert_text(cmd);\n\t\t\tclient->ops->text(client, cmd);\n\t\t}\n\n\t\tfree(cmd);\n\t} while (1);\n}\n\nstatic void remove_client(struct fio_client *client)\n{\n\tassert(client->refs);\n\n\tdprint(FD_NET, \"client: removed <%s>\\n\", client->hostname);\n\n\tfio_drain_client_text(client);\n\n\tif (!flist_empty(&client->list))\n\t\tflist_del_init(&client->list);\n\n\tfio_client_remove_hash(client);\n\n\tif (!flist_empty(&client->eta_list)) {\n\t\tflist_del_init(&client->eta_list);\n\t\tfio_client_dec_jobs_eta(client->eta_in_flight, client->ops->eta);\n\t}\n\n\tclose(client->fd);\n\tclient->fd = -1;\n\n\tif (client->ops->removed)\n\t\tclient->ops->removed(client);\n\n\tnr_clients--;\n\tfio_put_client(client);\n}\n\nstruct fio_client *fio_get_client(struct fio_client *client)\n{\n\tclient->refs++;\n\treturn client;\n}\n\nstatic void __fio_client_add_cmd_option(struct fio_client *client,\n\t\t\t\t\tconst char *opt)\n{\n\tint index;\n\n\tindex = client->argc++;\n\tclient->argv = realloc(client->argv, sizeof(char *) * client->argc);\n\tclient->argv[index] = strdup(opt);\n\tdprint(FD_NET, \"client: add cmd %d: %s\\n\", index, opt);\n}\n\nvoid fio_client_add_cmd_option(void *cookie, const char *opt)\n{\n\tstruct fio_client *client = cookie;\n\tstruct flist_head *entry;\n\n\tif (!client || !opt)\n\t\treturn;\n\n\t__fio_client_add_cmd_option(client, opt);\n\n\t/*\n\t * Duplicate arguments to shared client group\n\t */\n\tflist_for_each(entry, &arg_list) {\n\t\tclient = flist_entry(entry, struct fio_client, arg_list);\n\n\t\t__fio_client_add_cmd_option(client, opt);\n\t}\n}\n\nstatic struct fio_client *get_new_client(void)\n{\n\tstruct fio_client *client;\n\n\tclient = calloc(1, sizeof(*client));\n\n\tINIT_FLIST_HEAD(&client->list);\n\tINIT_FLIST_HEAD(&client->hash_list);\n\tINIT_FLIST_HEAD(&client->arg_list);\n\tINIT_FLIST_HEAD(&client->eta_list);\n\tINIT_FLIST_HEAD(&client->cmd_list);\n\n\tbuf_output_init(&client->buf);\n\n\treturn client;\n}\n\nstruct fio_client *fio_client_add_explicit(struct client_ops *ops,\n\t\t\t\t\t   const char *hostname, int type,\n\t\t\t\t\t   int port)\n{\n\tstruct fio_client *client;\n\n\tclient = get_new_client();\n\n\tif (type == Fio_client_socket)\n\t\tclient->is_sock = true;\n\telse {\n\t\tint ipv6;\n\n\t\tipv6 = type == Fio_client_ipv6;\n\t\tif (fio_server_parse_host(hostname, ipv6,\n\t\t\t\t\t\t&client->addr.sin_addr,\n\t\t\t\t\t\t&client->addr6.sin6_addr))\n\t\t\tgoto err;\n\n\t\tclient->port = port;\n\t}\n\n\tclient->fd = -1;\n\tclient->ops = ops;\n\tclient->refs = 1;\n\tclient->type = ops->client_type;\n\tclient->hostname = strdup(hostname);\n\n\t__fio_client_add_cmd_option(client, \"fio\");\n\n\tflist_add(&client->list, &client_list);\n\tnr_clients++;\n\tdprint(FD_NET, \"client: added <%s>\\n\", client->hostname);\n\treturn client;\nerr:\n\tfree(client);\n\treturn NULL;\n}\n\nint fio_client_add_ini_file(void *cookie, const char *ini_file, bool remote)\n{\n\tstruct fio_client *client = cookie;\n\tstruct client_file *cf;\n\tsize_t new_size;\n\tvoid *new_files;\n\n\tif (!client)\n\t\treturn 1;\n\n\tdprint(FD_NET, \"client <%s>: add ini %s\\n\", client->hostname, ini_file);\n\n\tnew_size = (client->nr_files + 1) * sizeof(struct client_file);\n\tnew_files = realloc(client->files, new_size);\n\tif (!new_files)\n\t\treturn 1;\n\n\tclient->files = new_files;\n\tcf = &client->files[client->nr_files];\n\tcf->file = strdup(ini_file);\n\tcf->remote = remote;\n\tclient->nr_files++;\n\treturn 0;\n}\n\nint fio_client_add(struct client_ops const *ops, const char *hostname, void **cookie)\n{\n\tstruct fio_client *existing = *cookie;\n\tstruct fio_client *client;\n\n\tif (existing) {\n\t\t/*\n\t\t * We always add our \"exec\" name as the option, hence 1\n\t\t * means empty.\n\t\t */\n\t\tif (existing->argc == 1)\n\t\t\tflist_add_tail(&existing->arg_list, &arg_list);\n\t\telse {\n\t\t\twhile (!flist_empty(&arg_list))\n\t\t\t\tflist_del_init(arg_list.next);\n\t\t}\n\t}\n\n\tclient = get_new_client();\n\n\tif (fio_server_parse_string(hostname, &client->hostname,\n\t\t\t\t\t&client->is_sock, &client->port,\n\t\t\t\t\t&client->addr.sin_addr,\n\t\t\t\t\t&client->addr6.sin6_addr,\n\t\t\t\t\t&client->ipv6)) {\n\t\tfio_put_client(client);\n\t\treturn -1;\n\t}\n\n\tclient->fd = -1;\n\tclient->ops = ops;\n\tclient->refs = 1;\n\tclient->type = ops->client_type;\n\n\t__fio_client_add_cmd_option(client, \"fio\");\n\n\tflist_add(&client->list, &client_list);\n\tnr_clients++;\n\tdprint(FD_NET, \"client: added <%s>\\n\", client->hostname);\n\t*cookie = client;\n\treturn 0;\n}\n\nstatic const char *server_name(struct fio_client *client, char *buf,\n\t\t\t       size_t bufsize)\n{\n\tconst char *from;\n\n\tif (client->ipv6)\n\t\tfrom = inet_ntop(AF_INET6, (struct sockaddr *) &client->addr6.sin6_addr, buf, bufsize);\n\telse if (client->is_sock)\n\t\tfrom = \"sock\";\n\telse\n\t\tfrom = inet_ntop(AF_INET, (struct sockaddr *) &client->addr.sin_addr, buf, bufsize);\n\n\treturn from;\n}\n\nstatic void probe_client(struct fio_client *client)\n{\n\tstruct cmd_client_probe_pdu pdu;\n\tconst char *sname;\n\tuint64_t tag;\n\tchar buf[64];\n\n\tdprint(FD_NET, \"client: send probe\\n\");\n\n#ifdef CONFIG_ZLIB\n\tpdu.flags = __le64_to_cpu(FIO_PROBE_FLAG_ZLIB);\n#else\n\tpdu.flags = 0;\n#endif\n\n\tsname = server_name(client, buf, sizeof(buf));\n\tmemset(pdu.server, 0, sizeof(pdu.server));\n\tsnprintf((char *) pdu.server, sizeof(pdu.server), \"%s\", sname);\n\n\tfio_net_send_cmd(client->fd, FIO_NET_CMD_PROBE, &pdu, sizeof(pdu), &tag, &client->cmd_list);\n}\n\nstatic int fio_client_connect_ip(struct fio_client *client)\n{\n\tstruct sockaddr *addr;\n\tsocklen_t socklen;\n\tint fd, domain;\n\n\tif (client->ipv6) {\n\t\tclient->addr6.sin6_family = AF_INET6;\n\t\tclient->addr6.sin6_port = htons(client->port);\n\t\tdomain = AF_INET6;\n\t\taddr = (struct sockaddr *) &client->addr6;\n\t\tsocklen = sizeof(client->addr6);\n\t} else {\n\t\tclient->addr.sin_family = AF_INET;\n\t\tclient->addr.sin_port = htons(client->port);\n\t\tdomain = AF_INET;\n\t\taddr = (struct sockaddr *) &client->addr;\n\t\tsocklen = sizeof(client->addr);\n\t}\n\n\tfd = socket(domain, SOCK_STREAM, 0);\n\tif (fd < 0) {\n\t\tint ret = -errno;\n\n\t\tlog_err(\"fio: socket: %s\\n\", strerror(errno));\n\t\treturn ret;\n\t}\n\n\tif (connect(fd, addr, socklen) < 0) {\n\t\tint ret = -errno;\n\n\t\tlog_err(\"fio: connect: %s\\n\", strerror(errno));\n\t\tlog_err(\"fio: failed to connect to %s:%u\\n\", client->hostname,\n\t\t\t\t\t\t\t\tclient->port);\n\t\tclose(fd);\n\t\treturn ret;\n\t}\n\n\treturn fd;\n}\n\nstatic int fio_client_connect_sock(struct fio_client *client)\n{\n\tstruct sockaddr_un *addr = &client->addr_un;\n\tsocklen_t len;\n\tint fd;\n\n\tmemset(addr, 0, sizeof(*addr));\n\taddr->sun_family = AF_UNIX;\n\tsnprintf(addr->sun_path, sizeof(addr->sun_path), \"%s\",\n\t\t client->hostname);\n\n\tfd = socket(AF_UNIX, SOCK_STREAM, 0);\n\tif (fd < 0) {\n\t\tint ret = -errno;\n\n\t\tlog_err(\"fio: socket: %s\\n\", strerror(errno));\n\t\treturn ret;\n\t}\n\n\tlen = sizeof(addr->sun_family) + strlen(addr->sun_path) + 1;\n\tif (connect(fd, (struct sockaddr *) addr, len) < 0) {\n\t\tint ret = -errno;\n\n\t\tlog_err(\"fio: connect; %s\\n\", strerror(errno));\n\t\tclose(fd);\n\t\treturn ret;\n\t}\n\n\treturn fd;\n}\n\nint fio_client_connect(struct fio_client *client)\n{\n\tint fd;\n\n\tdprint(FD_NET, \"client: connect to host %s\\n\", client->hostname);\n\n\tif (client->is_sock)\n\t\tfd = fio_client_connect_sock(client);\n\telse\n\t\tfd = fio_client_connect_ip(client);\n\n\tdprint(FD_NET, \"client: %s connected %d\\n\", client->hostname, fd);\n\n\tif (fd < 0)\n\t\treturn fd;\n\n\tclient->fd = fd;\n\tfio_client_add_hash(client);\n\tclient->state = Client_connected;\n\n\tprobe_client(client);\n\treturn 0;\n}\n\nint fio_client_terminate(struct fio_client *client)\n{\n\treturn fio_net_send_quit(client->fd);\n}\n\nstatic void fio_clients_terminate(void)\n{\n\tstruct flist_head *entry;\n\tstruct fio_client *client;\n\n\tdprint(FD_NET, \"client: terminate clients\\n\");\n\n\tflist_for_each(entry, &client_list) {\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\t\tfio_client_terminate(client);\n\t}\n}\n\nstatic void sig_int(int sig)\n{\n\tdprint(FD_NET, \"client: got signal %d\\n\", sig);\n\tfio_clients_terminate();\n}\n\nstatic void client_signal_handler(void)\n{\n\tstruct sigaction act;\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_int;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGINT, &act, NULL);\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_int;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGTERM, &act, NULL);\n\n/* Windows uses SIGBREAK as a quit signal from other applications */\n#ifdef WIN32\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_int;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGBREAK, &act, NULL);\n#endif\n\n\tmemset(&act, 0, sizeof(act));\n\tact.sa_handler = sig_show_status;\n\tact.sa_flags = SA_RESTART;\n\tsigaction(SIGUSR1, &act, NULL);\n}\n\nstatic int send_client_cmd_line(struct fio_client *client)\n{\n\tstruct cmd_single_line_pdu *cslp;\n\tstruct cmd_line_pdu *clp;\n\tunsigned long offset;\n\tunsigned int *lens;\n\tvoid *pdu;\n\tsize_t mem;\n\tint i, ret;\n\n\tdprint(FD_NET, \"client: send cmdline %d\\n\", client->argc);\n\n\tlens = malloc(client->argc * sizeof(unsigned int));\n\n\t/*\n\t * Find out how much mem we need\n\t */\n\tfor (i = 0, mem = 0; i < client->argc; i++) {\n\t\tlens[i] = strlen(client->argv[i]) + 1;\n\t\tmem += lens[i];\n\t}\n\n\t/*\n\t * We need one cmd_line_pdu, and argc number of cmd_single_line_pdu\n\t */\n\tmem += sizeof(*clp) + (client->argc * sizeof(*cslp));\n\n\tpdu = malloc(mem);\n\tclp = pdu;\n\toffset = sizeof(*clp);\n\n\tfor (i = 0; i < client->argc; i++) {\n\t\tuint16_t arg_len = lens[i];\n\n\t\tcslp = pdu + offset;\n\t\tstrcpy((char *) cslp->text, client->argv[i]);\n\t\tcslp->len = cpu_to_le16(arg_len);\n\t\toffset += sizeof(*cslp) + arg_len;\n\t}\n\n\tfree(lens);\n\tclp->lines = cpu_to_le16(client->argc);\n\tclp->client_type = __cpu_to_le16(client->type);\n\tret = fio_net_send_cmd(client->fd, FIO_NET_CMD_JOBLINE, pdu, mem, NULL, NULL);\n\tfree(pdu);\n\treturn ret;\n}\n\nint fio_clients_connect(void)\n{\n\tstruct fio_client *client;\n\tstruct flist_head *entry, *tmp;\n\tint ret;\n\n#ifdef WIN32\n\tWSADATA wsd;\n\tWSAStartup(MAKEWORD(2, 2), &wsd);\n#endif\n\n\tdprint(FD_NET, \"client: connect all\\n\");\n\n\tclient_signal_handler();\n\n\tflist_for_each_safe(entry, tmp, &client_list) {\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tret = fio_client_connect(client);\n\t\tif (ret) {\n\t\t\tremove_client(client);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (client->argc > 1)\n\t\t\tsend_client_cmd_line(client);\n\t}\n\n\treturn !nr_clients;\n}\n\nint fio_start_client(struct fio_client *client)\n{\n\tdprint(FD_NET, \"client: start %s\\n\", client->hostname);\n\treturn fio_net_send_simple_cmd(client->fd, FIO_NET_CMD_RUN, 0, NULL);\n}\n\nint fio_start_all_clients(void)\n{\n\tstruct fio_client *client;\n\tstruct flist_head *entry, *tmp;\n\tint ret;\n\n\tdprint(FD_NET, \"client: start all\\n\");\n\n\tfio_client_json_init();\n\n\tflist_for_each_safe(entry, tmp, &client_list) {\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tret = fio_start_client(client);\n\t\tif (ret) {\n\t\t\tremove_client(client);\n\t\t\tcontinue;\n\t\t}\n\t}\n\n\treturn flist_empty(&client_list);\n}\n\nstatic int __fio_client_send_remote_ini(struct fio_client *client,\n\t\t\t\t\tconst char *filename)\n{\n\tstruct cmd_load_file_pdu *pdu;\n\tsize_t p_size;\n\tint ret;\n\n\tdprint(FD_NET, \"send remote ini %s to %s\\n\", filename, client->hostname);\n\n\tp_size = sizeof(*pdu) + strlen(filename) + 1;\n\tpdu = calloc(1, p_size);\n\tpdu->name_len = strlen(filename);\n\tstrcpy((char *) pdu->file, filename);\n\tpdu->client_type = cpu_to_le16((uint16_t) client->type);\n\n\tclient->sent_job = true;\n\tret = fio_net_send_cmd(client->fd, FIO_NET_CMD_LOAD_FILE, pdu, p_size,NULL, NULL);\n\tfree(pdu);\n\treturn ret;\n}\n\n/*\n * Send file contents to server backend. We could use sendfile(), but to remain\n * more portable lets just read/write the darn thing.\n */\nstatic int __fio_client_send_local_ini(struct fio_client *client,\n\t\t\t\t       const char *filename)\n{\n\tstruct cmd_job_pdu *pdu;\n\tsize_t p_size;\n\tstruct stat sb;\n\tchar *p;\n\tvoid *buf;\n\toff_t len;\n\tint fd, ret;\n\n\tdprint(FD_NET, \"send ini %s to %s\\n\", filename, client->hostname);\n\n\tfd = open(filename, O_RDONLY);\n\tif (fd < 0) {\n\t\tret = -errno;\n\t\tlog_err(\"fio: job file <%s> open: %s\\n\", filename, strerror(errno));\n\t\treturn ret;\n\t}\n\n\tif (fstat(fd, &sb) < 0) {\n\t\tret = -errno;\n\t\tlog_err(\"fio: job file stat: %s\\n\", strerror(errno));\n\t\tclose(fd);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * Add extra space for variable expansion, but doesn't guarantee.\n\t */\n\tsb.st_size += OPT_LEN_MAX;\n\tp_size = sb.st_size + sizeof(*pdu);\n\tpdu = malloc(p_size);\n\tbuf = pdu->buf;\n\n\tlen = sb.st_size;\n\tp = buf;\n\tif (read_ini_data(fd, p, len)) {\n\t\tlog_err(\"fio: failed reading job file %s\\n\", filename);\n\t\tclose(fd);\n\t\tfree(pdu);\n\t\treturn 1;\n\t}\n\n\tpdu->buf_len = __cpu_to_le32(sb.st_size);\n\tpdu->client_type = cpu_to_le32(client->type);\n\n\tclient->sent_job = true;\n\tret = fio_net_send_cmd(client->fd, FIO_NET_CMD_JOB, pdu, p_size, NULL, NULL);\n\tfree(pdu);\n\tclose(fd);\n\treturn ret;\n}\n\nint fio_client_send_ini(struct fio_client *client, const char *filename,\n\t\t\tbool remote)\n{\n\tint ret;\n\n\tif (!remote)\n\t\tret = __fio_client_send_local_ini(client, filename);\n\telse\n\t\tret = __fio_client_send_remote_ini(client, filename);\n\n\tif (!ret)\n\t\tclient->sent_job = true;\n\n\treturn ret;\n}\n\nstatic int fio_client_send_cf(struct fio_client *client,\n\t\t\t      struct client_file *cf)\n{\n\treturn fio_client_send_ini(client, cf->file, cf->remote);\n}\n\nint fio_clients_send_ini(const char *filename)\n{\n\tstruct fio_client *client;\n\tstruct flist_head *entry, *tmp;\n\n\tflist_for_each_safe(entry, tmp, &client_list) {\n\t\tbool failed = false;\n\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tif (client->nr_files) {\n\t\t\tint i;\n\n\t\t\tfor (i = 0; i < client->nr_files; i++) {\n\t\t\t\tstruct client_file *cf;\n\n\t\t\t\tcf = &client->files[i];\n\n\t\t\t\tif (fio_client_send_cf(client, cf)) {\n\t\t\t\t\tfailed = true;\n\t\t\t\t\tremove_client(client);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (client->sent_job || failed)\n\t\t\tcontinue;\n\t\tif (!filename || fio_client_send_ini(client, filename, 0))\n\t\t\tremove_client(client);\n\t}\n\n\treturn !nr_clients;\n}\n\nint fio_client_update_options(struct fio_client *client,\n\t\t\t      struct thread_options *o, uint64_t *tag)\n{\n\tsize_t cmd_sz = offsetof(struct cmd_add_job_pdu, top) +\n\t\tthread_options_pack_size(o);\n\tstruct cmd_add_job_pdu *pdu;\n\tint ret;\n\n\tpdu = malloc(cmd_sz);\n\tpdu->thread_number = cpu_to_le32(client->thread_number);\n\tpdu->groupid = cpu_to_le32(client->groupid);\n\tconvert_thread_options_to_net(&pdu->top, o);\n\n\tret = fio_net_send_cmd(client->fd, FIO_NET_CMD_UPDATE_JOB, pdu,\n\t\t\t       cmd_sz, tag, &client->cmd_list);\n\tfree(pdu);\n\treturn ret;\n}\n\nstatic void convert_io_stat(struct io_stat *dst, struct io_stat *src)\n{\n\tdst->max_val\t= le64_to_cpu(src->max_val);\n\tdst->min_val\t= le64_to_cpu(src->min_val);\n\tdst->samples\t= le64_to_cpu(src->samples);\n\n\t/*\n\t * Floats arrive as IEEE 754 encoded uint64_t, convert back to double\n\t */\n\tdst->mean.u.f\t= fio_uint64_to_double(le64_to_cpu(dst->mean.u.i));\n\tdst->S.u.f\t= fio_uint64_to_double(le64_to_cpu(dst->S.u.i));\n}\n\nstatic void convert_ts(struct thread_stat *dst, struct thread_stat *src)\n{\n\tint i, j, k;\n\n\tdst->error\t\t= le32_to_cpu(src->error);\n\tdst->thread_number\t= le32_to_cpu(src->thread_number);\n\tdst->groupid\t\t= le32_to_cpu(src->groupid);\n\tdst->job_start\t\t= le64_to_cpu(src->job_start);\n\tdst->pid\t\t= le32_to_cpu(src->pid);\n\tdst->members\t\t= le32_to_cpu(src->members);\n\tdst->unified_rw_rep\t= le32_to_cpu(src->unified_rw_rep);\n\tdst->ioprio\t\t= le32_to_cpu(src->ioprio);\n\tdst->disable_prio_stat\t= le32_to_cpu(src->disable_prio_stat);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tconvert_io_stat(&dst->clat_stat[i], &src->clat_stat[i]);\n\t\tconvert_io_stat(&dst->slat_stat[i], &src->slat_stat[i]);\n\t\tconvert_io_stat(&dst->lat_stat[i], &src->lat_stat[i]);\n\t\tconvert_io_stat(&dst->bw_stat[i], &src->bw_stat[i]);\n\t\tconvert_io_stat(&dst->iops_stat[i], &src->iops_stat[i]);\n\t}\n\tconvert_io_stat(&dst->sync_stat, &src->sync_stat);\n\n\tdst->usr_time\t\t= le64_to_cpu(src->usr_time);\n\tdst->sys_time\t\t= le64_to_cpu(src->sys_time);\n\tdst->ctx\t\t= le64_to_cpu(src->ctx);\n\tdst->minf\t\t= le64_to_cpu(src->minf);\n\tdst->majf\t\t= le64_to_cpu(src->majf);\n\tdst->clat_percentiles\t= le32_to_cpu(src->clat_percentiles);\n\tdst->lat_percentiles\t= le32_to_cpu(src->lat_percentiles);\n\tdst->slat_percentiles\t= le32_to_cpu(src->slat_percentiles);\n\tdst->percentile_precision = le64_to_cpu(src->percentile_precision);\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++) {\n\t\tfio_fp64_t *fps = &src->percentile_list[i];\n\t\tfio_fp64_t *fpd = &dst->percentile_list[i];\n\n\t\tfpd->u.f = fio_uint64_to_double(le64_to_cpu(fps->u.i));\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_MAP_NR; i++) {\n\t\tdst->io_u_map[i]\t= le64_to_cpu(src->io_u_map[i]);\n\t\tdst->io_u_submit[i]\t= le64_to_cpu(src->io_u_submit[i]);\n\t\tdst->io_u_complete[i]\t= le64_to_cpu(src->io_u_complete[i]);\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_LAT_N_NR; i++)\n\t\tdst->io_u_lat_n[i]\t= le64_to_cpu(src->io_u_lat_n[i]);\n\tfor (i = 0; i < FIO_IO_U_LAT_U_NR; i++)\n\t\tdst->io_u_lat_u[i]\t= le64_to_cpu(src->io_u_lat_u[i]);\n\tfor (i = 0; i < FIO_IO_U_LAT_M_NR; i++)\n\t\tdst->io_u_lat_m[i]\t= le64_to_cpu(src->io_u_lat_m[i]);\n\n\tfor (i = 0; i < FIO_LAT_CNT; i++)\n\t\tfor (j = 0; j < DDIR_RWDIR_CNT; j++)\n\t\t\tfor (k = 0; k < FIO_IO_U_PLAT_NR; k++)\n\t\t\t\tdst->io_u_plat[i][j][k] = le64_to_cpu(src->io_u_plat[i][j][k]);\n\n\tfor (j = 0; j < FIO_IO_U_PLAT_NR; j++)\n\t\tdst->io_u_sync_plat[j] = le64_to_cpu(src->io_u_sync_plat[j]);\n\n\tfor (i = 0; i < DDIR_RWDIR_SYNC_CNT; i++)\n\t\tdst->total_io_u[i]\t= le64_to_cpu(src->total_io_u[i]);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->short_io_u[i]\t= le64_to_cpu(src->short_io_u[i]);\n\t\tdst->drop_io_u[i]\t= le64_to_cpu(src->drop_io_u[i]);\n\t}\n\n\tdst->total_submit\t= le64_to_cpu(src->total_submit);\n\tdst->total_complete\t= le64_to_cpu(src->total_complete);\n\tdst->nr_zone_resets\t= le64_to_cpu(src->nr_zone_resets);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->io_bytes[i]\t= le64_to_cpu(src->io_bytes[i]);\n\t\tdst->runtime[i]\t\t= le64_to_cpu(src->runtime[i]);\n\t}\n\n\tdst->total_run_time\t= le64_to_cpu(src->total_run_time);\n\tdst->continue_on_error\t= le16_to_cpu(src->continue_on_error);\n\tdst->total_err_count\t= le64_to_cpu(src->total_err_count);\n\tdst->first_error\t= le32_to_cpu(src->first_error);\n\tdst->kb_base\t\t= le32_to_cpu(src->kb_base);\n\tdst->unit_base\t\t= le32_to_cpu(src->unit_base);\n\n\tdst->sig_figs\t\t= le32_to_cpu(src->sig_figs);\n\n\tdst->latency_depth\t= le32_to_cpu(src->latency_depth);\n\tdst->latency_target\t= le64_to_cpu(src->latency_target);\n\tdst->latency_window\t= le64_to_cpu(src->latency_window);\n\tdst->latency_percentile.u.f = fio_uint64_to_double(le64_to_cpu(src->latency_percentile.u.i));\n\n\tdst->nr_block_infos\t= le64_to_cpu(src->nr_block_infos);\n\tfor (i = 0; i < dst->nr_block_infos; i++)\n\t\tdst->block_infos[i] = le32_to_cpu(src->block_infos[i]);\n\n\tdst->ss_dur\t\t= le64_to_cpu(src->ss_dur);\n\tdst->ss_state\t\t= le32_to_cpu(src->ss_state);\n\tdst->ss_head\t\t= le32_to_cpu(src->ss_head);\n\tdst->ss_limit.u.f \t= fio_uint64_to_double(le64_to_cpu(src->ss_limit.u.i));\n\tdst->ss_slope.u.f \t= fio_uint64_to_double(le64_to_cpu(src->ss_slope.u.i));\n\tdst->ss_deviation.u.f \t= fio_uint64_to_double(le64_to_cpu(src->ss_deviation.u.i));\n\tdst->ss_criterion.u.f \t= fio_uint64_to_double(le64_to_cpu(src->ss_criterion.u.i));\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->nr_clat_prio[i] = le32_to_cpu(src->nr_clat_prio[i]);\n\t\tfor (j = 0; j < dst->nr_clat_prio[i]; j++) {\n\t\t\tfor (k = 0; k < FIO_IO_U_PLAT_NR; k++)\n\t\t\t\tdst->clat_prio[i][j].io_u_plat[k] =\n\t\t\t\t\tle64_to_cpu(src->clat_prio[i][j].io_u_plat[k]);\n\t\t\tconvert_io_stat(&dst->clat_prio[i][j].clat_stat,\n\t\t\t\t\t&src->clat_prio[i][j].clat_stat);\n\t\t\tdst->clat_prio[i][j].ioprio =\n\t\t\t\tle32_to_cpu(dst->clat_prio[i][j].ioprio);\n\t\t}\n\t}\n\n\tif (dst->ss_state & FIO_SS_DATA) {\n\t\tfor (i = 0; i < dst->ss_dur; i++ ) {\n\t\t\tdst->ss_iops_data[i] = le64_to_cpu(src->ss_iops_data[i]);\n\t\t\tdst->ss_bw_data[i] = le64_to_cpu(src->ss_bw_data[i]);\n\t\t}\n\t}\n\n\tdst->cachehit\t\t= le64_to_cpu(src->cachehit);\n\tdst->cachemiss\t\t= le64_to_cpu(src->cachemiss);\n}\n\nstatic void convert_gs(struct group_run_stats *dst, struct group_run_stats *src)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->max_run[i]\t\t= le64_to_cpu(src->max_run[i]);\n\t\tdst->min_run[i]\t\t= le64_to_cpu(src->min_run[i]);\n\t\tdst->max_bw[i]\t\t= le64_to_cpu(src->max_bw[i]);\n\t\tdst->min_bw[i]\t\t= le64_to_cpu(src->min_bw[i]);\n\t\tdst->iobytes[i]\t\t= le64_to_cpu(src->iobytes[i]);\n\t\tdst->agg[i]\t\t= le64_to_cpu(src->agg[i]);\n\t}\n\n\tdst->kb_base\t= le32_to_cpu(src->kb_base);\n\tdst->unit_base\t= le32_to_cpu(src->unit_base);\n\tdst->sig_figs\t= le32_to_cpu(src->sig_figs);\n\tdst->groupid\t= le32_to_cpu(src->groupid);\n\tdst->unified_rw_rep\t= le32_to_cpu(src->unified_rw_rep);\n}\n\nstatic void json_object_add_client_info(struct json_object *obj,\n\t\t\t\t\tstruct fio_client *client)\n{\n\tconst char *hostname = client->hostname ? client->hostname : \"\";\n\n\tjson_object_add_value_string(obj, \"hostname\", hostname);\n\tjson_object_add_value_int(obj, \"port\", client->port);\n}\n\nstatic void handle_ts(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_ts_pdu *p = (struct cmd_ts_pdu *) cmd->payload;\n\tstruct flist_head *opt_list = NULL;\n\tstruct json_object *tsobj;\n\n\tif (client->opt_lists && p->ts.thread_number <= client->jobs)\n\t\topt_list = &client->opt_lists[p->ts.thread_number - 1];\n\n\ttsobj = show_thread_status(&p->ts, &p->rs, opt_list, &client->buf);\n\tclient->did_stat = true;\n\tif (tsobj) {\n\t\tjson_object_add_client_info(tsobj, client);\n\t\tjson_array_add_value_object(clients_array, tsobj);\n\t}\n\n\tif (sum_stat_clients <= 1)\n\t\treturn;\n\n\tsum_thread_stats(&client_ts, &p->ts);\n\tsum_group_stats(&client_gs, &p->rs);\n\n\tif (!client_ts.members) {\n\t\t/* Arbitrarily use the percentile toggles and percentile list\n\t\t * from the first thread_stat that comes our way */\n\t\tclient_ts.slat_percentiles = p->ts.slat_percentiles;\n\t\tclient_ts.clat_percentiles = p->ts.clat_percentiles;\n\t\tclient_ts.lat_percentiles = p->ts.lat_percentiles;\n\n\t\tfor (int i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++)\n\t\t\tclient_ts.percentile_list[i] = p->ts.percentile_list[i];\n\t}\n\tclient_ts.members++;\n\tclient_ts.thread_number = p->ts.thread_number;\n\tclient_ts.groupid = p->ts.groupid;\n\tclient_ts.unified_rw_rep = p->ts.unified_rw_rep;\n\tclient_ts.sig_figs = p->ts.sig_figs;\n\n\tif (++sum_stat_nr == sum_stat_clients) {\n\t\tstrcpy(client_ts.name, \"All clients\");\n\t\ttsobj = show_thread_status(&client_ts, &client_gs, NULL, &allclients);\n\t\tif (tsobj) {\n\t\t\tjson_object_add_client_info(tsobj, client);\n\t\t\tjson_array_add_value_object(clients_array, tsobj);\n\t\t}\n\t}\n}\n\nstatic void handle_gs(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct group_run_stats *gs = (struct group_run_stats *) cmd->payload;\n\n\tif (output_format & FIO_OUTPUT_NORMAL)\n\t\tshow_group_stats(gs, &client->buf);\n}\n\nstatic void handle_job_opt(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_job_option *pdu = (struct cmd_job_option *) cmd->payload;\n\n\tpdu->global = le16_to_cpu(pdu->global);\n\tpdu->truncated = le16_to_cpu(pdu->truncated);\n\tpdu->groupid = le32_to_cpu(pdu->groupid);\n\n\tif (pdu->global) {\n\t\tif (!job_opt_object)\n\t\t\treturn;\n\n\t\tjson_object_add_value_string(job_opt_object,\n\t\t\t\t\t     (const char *)pdu->name,\n\t\t\t\t\t     (const char *)pdu->value);\n\t} else if (client->opt_lists) {\n\t\tstruct flist_head *opt_list = &client->opt_lists[pdu->groupid];\n\t\tstruct print_option *p;\n\n\t\tp = malloc(sizeof(*p));\n\t\tp->name = strdup((const char *)pdu->name);\n\t\tp->value = pdu->value[0] ? strdup((const char *)pdu->value) :\n\t\t\tNULL;\n\t\tflist_add_tail(&p->list, opt_list);\n\t}\n}\n\nstatic void handle_text(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_text_pdu *pdu = (struct cmd_text_pdu *) cmd->payload;\n\tconst char *buf = (const char *) pdu->buf;\n\tconst char *name;\n\tint fio_unused ret;\n\tstruct buf_output out;\n\n\tbuf_output_init(&out);\n\n\tname = client->name ? client->name : client->hostname;\n\n\tif (!client->skip_newline && !(output_format & FIO_OUTPUT_TERSE))\n\t\t__log_buf(&out, \"<%s> \", name);\n\t__log_buf(&out, \"%s\", buf);\n\tlog_info_buf(out.buf, out.buflen);\n\tbuf_output_free(&out);\n\tclient->skip_newline = strchr(buf, '\\n') == NULL;\n}\n\nstatic void convert_agg(struct disk_util_agg *agg)\n{\n\tint i;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tagg->ios[i]\t= le64_to_cpu(agg->ios[i]);\n\t\tagg->merges[i]\t= le64_to_cpu(agg->merges[i]);\n\t\tagg->sectors[i]\t= le64_to_cpu(agg->sectors[i]);\n\t\tagg->ticks[i]\t= le64_to_cpu(agg->ticks[i]);\n\t}\n\n\tagg->io_ticks\t\t= le64_to_cpu(agg->io_ticks);\n\tagg->time_in_queue\t= le64_to_cpu(agg->time_in_queue);\n\tagg->slavecount\t\t= le32_to_cpu(agg->slavecount);\n\tagg->max_util.u.f\t= fio_uint64_to_double(le64_to_cpu(agg->max_util.u.i));\n}\n\nstatic void convert_dus(struct disk_util_stat *dus)\n{\n\tint i;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tdus->s.ios[i]\t\t= le64_to_cpu(dus->s.ios[i]);\n\t\tdus->s.merges[i]\t= le64_to_cpu(dus->s.merges[i]);\n\t\tdus->s.sectors[i]\t= le64_to_cpu(dus->s.sectors[i]);\n\t\tdus->s.ticks[i]\t\t= le64_to_cpu(dus->s.ticks[i]);\n\t}\n\n\tdus->s.io_ticks\t\t= le64_to_cpu(dus->s.io_ticks);\n\tdus->s.time_in_queue\t= le64_to_cpu(dus->s.time_in_queue);\n\tdus->s.msec\t\t= le64_to_cpu(dus->s.msec);\n}\n\nstatic void handle_du(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_du_pdu *du = (struct cmd_du_pdu *) cmd->payload;\n\n\tif (!client->disk_stats_shown)\n\t\tclient->disk_stats_shown = true;\n\n\tif (output_format & FIO_OUTPUT_JSON) {\n\t\tstruct json_object *duobj;\n\n\t\tjson_array_add_disk_util(&du->dus, &du->agg, du_array);\n\t\tduobj = json_array_last_value_object(du_array);\n\t\tjson_object_add_client_info(duobj, client);\n\t}\n\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\t__log_buf(&client->buf, \"\\nDisk stats (read/write):\\n\");\n\t\tprint_disk_util(&du->dus, &du->agg, 0, &client->buf);\n\t}\n\tif (output_format & FIO_OUTPUT_TERSE && terse_version >= 3) {\n\t\tprint_disk_util(&du->dus, &du->agg, 1, &client->buf);\n\t\t__log_buf(&client->buf, \"\\n\");\n\t}\n}\n\nstatic void convert_jobs_eta(struct jobs_eta *je)\n{\n\tint i;\n\n\tje->nr_running\t\t= le32_to_cpu(je->nr_running);\n\tje->nr_ramp\t\t= le32_to_cpu(je->nr_ramp);\n\tje->nr_pending\t\t= le32_to_cpu(je->nr_pending);\n\tje->nr_setting_up\t= le32_to_cpu(je->nr_setting_up);\n\tje->files_open\t\t= le32_to_cpu(je->files_open);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tje->m_rate[i]\t= le64_to_cpu(je->m_rate[i]);\n\t\tje->t_rate[i]\t= le64_to_cpu(je->t_rate[i]);\n\t\tje->m_iops[i]\t= le32_to_cpu(je->m_iops[i]);\n\t\tje->t_iops[i]\t= le32_to_cpu(je->t_iops[i]);\n\t\tje->rate[i]\t= le64_to_cpu(je->rate[i]);\n\t\tje->iops[i]\t= le32_to_cpu(je->iops[i]);\n\t}\n\n\tje->elapsed_sec\t\t= le64_to_cpu(je->elapsed_sec);\n\tje->eta_sec\t\t= le64_to_cpu(je->eta_sec);\n\tje->nr_threads\t\t= le32_to_cpu(je->nr_threads);\n\tje->is_pow2\t\t= le32_to_cpu(je->is_pow2);\n\tje->unit_base\t\t= le32_to_cpu(je->unit_base);\n\tje->sig_figs\t\t= le32_to_cpu(je->sig_figs);\n}\n\nvoid fio_client_sum_jobs_eta(struct jobs_eta *dst, struct jobs_eta *je)\n{\n\tint i;\n\n\tdst->nr_running\t\t+= je->nr_running;\n\tdst->nr_ramp\t\t+= je->nr_ramp;\n\tdst->nr_pending\t\t+= je->nr_pending;\n\tdst->nr_setting_up\t+= je->nr_setting_up;\n\tdst->files_open\t\t+= je->files_open;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->m_rate[i]\t+= je->m_rate[i];\n\t\tdst->t_rate[i]\t+= je->t_rate[i];\n\t\tdst->m_iops[i]\t+= je->m_iops[i];\n\t\tdst->t_iops[i]\t+= je->t_iops[i];\n\t\tdst->rate[i]\t+= je->rate[i];\n\t\tdst->iops[i]\t+= je->iops[i];\n\t}\n\n\tdst->elapsed_sec\t+= je->elapsed_sec;\n\n\tif (je->eta_sec > dst->eta_sec)\n\t\tdst->eta_sec = je->eta_sec;\n\n\tdst->nr_threads\t\t+= je->nr_threads;\n\n\t/*\n\t * This wont be correct for multiple strings, but at least it\n\t * works for the basic cases.\n\t */\n\tstrcpy((char *) dst->run_str, (char *) je->run_str);\n}\n\nstatic bool remove_reply_cmd(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct fio_net_cmd_reply *reply = NULL;\n\tstruct flist_head *entry;\n\n\tflist_for_each(entry, &client->cmd_list) {\n\t\treply = flist_entry(entry, struct fio_net_cmd_reply, list);\n\n\t\tif (cmd->tag == (uintptr_t) reply)\n\t\t\tbreak;\n\n\t\treply = NULL;\n\t}\n\n\tif (!reply) {\n\t\tlog_err(\"fio: client: unable to find matching tag (%llx)\\n\", (unsigned long long) cmd->tag);\n\t\treturn false;\n\t}\n\n\tflist_del(&reply->list);\n\tcmd->tag = reply->saved_tag;\n\tfree(reply);\n\treturn true;\n}\n\nint fio_client_wait_for_reply(struct fio_client *client, uint64_t tag)\n{\n\tdo {\n\t\tstruct fio_net_cmd_reply *reply = NULL;\n\t\tstruct flist_head *entry;\n\n\t\tflist_for_each(entry, &client->cmd_list) {\n\t\t\treply = flist_entry(entry, struct fio_net_cmd_reply, list);\n\n\t\t\tif (tag == (uintptr_t) reply)\n\t\t\t\tbreak;\n\n\t\t\treply = NULL;\n\t\t}\n\n\t\tif (!reply)\n\t\t\tbreak;\n\n\t\tusleep(1000);\n\t} while (1);\n\n\treturn 0;\n}\n\nstatic void handle_eta(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct jobs_eta *je = (struct jobs_eta *) cmd->payload;\n\tstruct client_eta *eta = (struct client_eta *) (uintptr_t) cmd->tag;\n\n\tdprint(FD_NET, \"client: got eta tag %p, %d\\n\", eta, eta->pending);\n\n\tassert(client->eta_in_flight == eta);\n\n\tclient->eta_in_flight = NULL;\n\tflist_del_init(&client->eta_list);\n\tclient->eta_timeouts = 0;\n\n\tif (client->ops->jobs_eta)\n\t\tclient->ops->jobs_eta(client, je);\n\n\tfio_client_sum_jobs_eta(&eta->eta, je);\n\tfio_client_dec_jobs_eta(eta, client->ops->eta);\n}\n\nstatic void client_flush_hist_samples(FILE *f, int hist_coarseness, void *samples,\n\t\t\t\t      uint64_t sample_size)\n{\n\tstruct io_sample *s, *s_tmp;\n\tbool log_offset, log_issue_time;\n\tuint64_t i, j, nr_samples;\n\tstruct io_u_plat_entry *entry;\n\tuint64_t *io_u_plat;\n\n\tint stride = 1 << hist_coarseness;\n\n\tif (!sample_size)\n\t\treturn;\n\n\ts = __get_sample(samples, 0, 0, 0);\n\tlog_offset = (s->__ddir & LOG_OFFSET_SAMPLE_BIT) != 0;\n\tlog_issue_time = (s->__ddir & LOG_ISSUE_TIME_SAMPLE_BIT) != 0;\n\n\tnr_samples = sample_size / __log_entry_sz(log_offset, log_issue_time);\n\n\tfor (i = 0; i < nr_samples; i++) {\n\n\t\ts_tmp = __get_sample(samples, log_offset, log_issue_time, i);\n\t\ts = (struct io_sample *)((char *)s_tmp +\n\t\t\t\t\t i * sizeof(struct io_u_plat_entry));\n\n\t\tentry = s->data.plat_entry;\n\t\tio_u_plat = entry->io_u_plat;\n\n\t\tfprintf(f, \"%lu, %u, %llu, \", (unsigned long) s->time,\n\t\t\t\t\t\tio_sample_ddir(s), (unsigned long long) s->bs);\n\t\tfor (j = 0; j < FIO_IO_U_PLAT_NR - stride; j += stride) {\n\t\t\tfprintf(f, \"%llu, \", (unsigned long long)hist_sum(j, stride, io_u_plat, NULL));\n\t\t}\n\t\tfprintf(f, \"%llu\\n\", (unsigned long long)\n\t\t\thist_sum(FIO_IO_U_PLAT_NR - stride, stride, io_u_plat, NULL));\n\n\t}\n}\n\nstatic int fio_client_handle_iolog(struct fio_client *client,\n\t\t\t\t   struct fio_net_cmd *cmd)\n{\n\tstruct cmd_iolog_pdu *pdu = NULL;\n\tbool store_direct;\n\tchar *log_pathname = NULL;\n\tint ret = 0;\n\n\tpdu = convert_iolog(cmd, &store_direct);\n\tif (!pdu) {\n\t\tlog_err(\"fio: failed converting IO log\\n\");\n\t\tret = 1;\n\t\tgoto out;\n\t}\n\n        /* allocate buffer big enough for next sprintf() call */\n\tlog_pathname = malloc(10 + strlen((char *)pdu->name) +\n\t\t\tstrlen(client->hostname));\n\tif (!log_pathname) {\n\t\tlog_err(\"fio: memory allocation of unique pathname failed\\n\");\n\t\tret = -1;\n\t\tgoto out;\n\t}\n\t/* generate a unique pathname for the log file using hostname */\n\tsprintf(log_pathname, \"%s.%s\", pdu->name, client->hostname);\n\n\tif (store_direct) {\n\t\tssize_t wrote;\n\t\tsize_t sz;\n\t\tint fd, flags;\n\n\t\tif (pdu->per_job_logs)\n\t\t\tflags = O_WRONLY | O_CREAT | O_TRUNC;\n\t\telse\n\t\t\tflags = O_WRONLY | O_CREAT | O_APPEND;\n\t\tfd = open((const char *) log_pathname, flags, 0644);\n\t\tif (fd < 0) {\n\t\t\tlog_err(\"fio: open log %s: %s\\n\",\n\t\t\t\tlog_pathname, strerror(errno));\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsz = cmd->pdu_len - sizeof(*pdu);\n\t\twrote = write(fd, pdu->samples, sz);\n\t\tclose(fd);\n\n\t\tif (wrote != sz) {\n\t\t\tlog_err(\"fio: short write on compressed log\\n\");\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = 0;\n\t} else {\n\t\tFILE *f;\n\t\tconst char *mode;\n\n\t\tif (pdu->per_job_logs)\n\t\t\tmode = \"w\";\n\t\telse\n\t\t\tmode = \"a\";\n\t\tf = fopen((const char *) log_pathname, mode);\n\t\tif (!f) {\n\t\t\tlog_err(\"fio: fopen log %s : %s\\n\",\n\t\t\t\tlog_pathname, strerror(errno));\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (pdu->log_type == IO_LOG_TYPE_HIST) {\n\t\t\tclient_flush_hist_samples(f, pdu->log_hist_coarseness, pdu->samples,\n\t\t\t\t\t   pdu->nr_samples * sizeof(struct io_sample));\n\t\t} else {\n\t\t\tflush_samples(f, pdu->samples,\n\t\t\t\t\tpdu->nr_samples * sizeof(struct io_sample));\n\t\t}\n\t\tfclose(f);\n\t\tret = 0;\n\t}\n\nout:\n\tif (pdu && pdu != (void *) cmd->payload)\n\t\tfree(pdu);\n\n\tif (log_pathname)\n\t\tfree(log_pathname);\n\n\treturn ret;\n}\n\nstatic void handle_probe(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_probe_reply_pdu *probe = (struct cmd_probe_reply_pdu *) cmd->payload;\n\tconst char *os, *arch;\n\tchar bit[16];\n\n\tos = fio_get_os_string(probe->os);\n\tif (!os)\n\t\tos = \"unknown\";\n\n\tarch = fio_get_arch_string(probe->arch);\n\tif (!arch)\n\t\tos = \"unknown\";\n\n\tsprintf(bit, \"%d-bit\", probe->bpp * 8);\n\tprobe->flags = le64_to_cpu(probe->flags);\n\n\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\tlog_info(\"hostname=%s, be=%u, %s, os=%s, arch=%s, fio=%s, flags=%lx\\n\",\n\t\t\tprobe->hostname, probe->bigendian, bit, os, arch,\n\t\t\tprobe->fio_version, (unsigned long) probe->flags);\n\t}\n\n\tif (!client->name)\n\t\tclient->name = strdup((char *) probe->hostname);\n}\n\nstatic void handle_start(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_start_pdu *pdu = (struct cmd_start_pdu *) cmd->payload;\n\n\tclient->state = Client_started;\n\tclient->jobs = le32_to_cpu(pdu->jobs);\n\tclient->nr_stat = le32_to_cpu(pdu->stat_outputs);\n\n\tif (client->jobs) {\n\t\tint i;\n\n\t\tif (client->opt_lists)\n\t\t\tfree(client->opt_lists);\n\n\t\tclient->opt_lists = malloc(client->jobs * sizeof(struct flist_head));\n\t\tfor (i = 0; i < client->jobs; i++)\n\t\t\tINIT_FLIST_HEAD(&client->opt_lists[i]);\n\t}\n\n\tsum_stat_clients += client->nr_stat;\n}\n\nstatic void handle_stop(struct fio_client *client)\n{\n\tif (client->error)\n\t\tlog_info(\"client <%s>: exited with error %d\\n\", client->hostname, client->error);\n}\n\nstatic void convert_stop(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_end_pdu *pdu = (struct cmd_end_pdu *) cmd->payload;\n\n\tpdu->error = le32_to_cpu(pdu->error);\n}\n\nstatic void convert_text(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_text_pdu *pdu = (struct cmd_text_pdu *) cmd->payload;\n\n\tpdu->level\t= le32_to_cpu(pdu->level);\n\tpdu->buf_len\t= le32_to_cpu(pdu->buf_len);\n\tpdu->log_sec\t= le64_to_cpu(pdu->log_sec);\n\tpdu->log_usec\t= le64_to_cpu(pdu->log_usec);\n}\n\nstatic struct cmd_iolog_pdu *convert_iolog_gz(struct fio_net_cmd *cmd,\n\t\t\t\t\t      struct cmd_iolog_pdu *pdu)\n{\n#ifdef CONFIG_ZLIB\n\tstruct cmd_iolog_pdu *ret;\n\tz_stream stream;\n\tuint64_t nr_samples;\n\tsize_t total;\n\tchar *p;\n\tsize_t log_entry_size;\n\n\tstream.zalloc = Z_NULL;\n\tstream.zfree = Z_NULL;\n\tstream.opaque = Z_NULL;\n\tstream.avail_in = 0;\n\tstream.next_in = Z_NULL;\n\n\tif (inflateInit(&stream) != Z_OK)\n\t\treturn NULL;\n\n\t/*\n\t * Get header first, it's not compressed\n\t */\n\tnr_samples = le64_to_cpu(pdu->nr_samples);\n\n\tlog_entry_size = __log_entry_sz(le32_to_cpu(pdu->log_offset),\n\t\t\t\t\tle32_to_cpu(pdu->log_issue_time));\n\tif (pdu->log_type == IO_LOG_TYPE_HIST)\n\t\ttotal = nr_samples * (log_entry_size +\n\t\t\t\t      sizeof(struct io_u_plat_entry));\n\telse\n\t\ttotal = nr_samples * log_entry_size;\n\tret = malloc(total + sizeof(*pdu));\n\tret->nr_samples = nr_samples;\n\n\tmemcpy(ret, pdu, sizeof(*pdu));\n\n\tp = (char *) ret + sizeof(*pdu);\n\n\tstream.avail_in = cmd->pdu_len - sizeof(*pdu);\n\tstream.next_in = (void *)((char *) pdu + sizeof(*pdu));\n\twhile (stream.avail_in) {\n\t\tunsigned int this_chunk = 65536;\n\t\tunsigned int this_len;\n\t\tint err;\n\n\t\tif (this_chunk > total)\n\t\t\tthis_chunk = total;\n\n\t\tstream.avail_out = this_chunk;\n\t\tstream.next_out = (void *)p;\n\t\terr = inflate(&stream, Z_NO_FLUSH);\n\t\t/* may be Z_OK, or Z_STREAM_END */\n\t\tif (err < 0) {\n\t\t\t/*\n\t\t\t * Z_STREAM_ERROR and Z_BUF_ERROR can safely be\n\t\t\t * ignored */\n\t\t\tif (err == Z_STREAM_ERROR || err == Z_BUF_ERROR)\n\t\t\t\tbreak;\n\t\t\tlog_err(\"fio: inflate error %d\\n\", err);\n\t\t\tfree(ret);\n\t\t\tret = NULL;\n\t\t\tgoto err;\n\t\t}\n\n\t\tthis_len = this_chunk - stream.avail_out;\n\t\tp += this_len;\n\t\ttotal -= this_len;\n\t}\n\nerr:\n\tinflateEnd(&stream);\n\treturn ret;\n#else\n\treturn NULL;\n#endif\n}\n\n/*\n * This has been compressed on the server side, since it can be big.\n * Uncompress here.\n */\nstatic struct cmd_iolog_pdu *convert_iolog(struct fio_net_cmd *cmd,\n\t\t\t\t\t   bool *store_direct)\n{\n\tstruct cmd_iolog_pdu *pdu = (struct cmd_iolog_pdu *) cmd->payload;\n\tstruct cmd_iolog_pdu *ret;\n\tuint64_t i;\n\tint compressed;\n\tvoid *samples;\n\n\t*store_direct = false;\n\n\t/*\n\t * Convert if compressed and we support it. If it's not\n\t * compressed, we need not do anything.\n\t */\n\tcompressed = le32_to_cpu(pdu->compressed);\n\tif (compressed == XMIT_COMPRESSED) {\n#ifndef CONFIG_ZLIB\n\t\tlog_err(\"fio: server sent compressed data by mistake\\n\");\n\t\treturn NULL;\n#endif\n\t\tret = convert_iolog_gz(cmd, pdu);\n\t\tif (!ret) {\n\t\t\tlog_err(\"fio: failed decompressing log\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t} else if (compressed == STORE_COMPRESSED) {\n\t\t*store_direct = true;\n\t\tret = pdu;\n\t} else\n\t\tret = pdu;\n\n\tret->nr_samples\t\t= le64_to_cpu(ret->nr_samples);\n\tret->thread_number\t= le32_to_cpu(ret->thread_number);\n\tret->log_type\t\t= le32_to_cpu(ret->log_type);\n\tret->compressed\t\t= le32_to_cpu(ret->compressed);\n\tret->log_offset\t\t= le32_to_cpu(ret->log_offset);\n\tret->log_prio\t\t= le32_to_cpu(ret->log_prio);\n\tret->log_issue_time\t= le32_to_cpu(ret->log_issue_time);\n\tret->log_hist_coarseness = le32_to_cpu(ret->log_hist_coarseness);\n\tret->per_job_logs\t= le32_to_cpu(ret->per_job_logs);\n\n\tif (*store_direct)\n\t\treturn ret;\n\n\tsamples = &ret->samples[0];\n\tfor (i = 0; i < ret->nr_samples; i++) {\n\t\tstruct io_sample *s;\n\n\t\ts = __get_sample(samples, ret->log_offset, ret->log_issue_time, i);\n\t\tif (ret->log_type == IO_LOG_TYPE_HIST)\n\t\t\ts = (struct io_sample *)((char *)s + sizeof(struct io_u_plat_entry) * i);\n\n\t\ts->time\t\t= le64_to_cpu(s->time);\n\t\tif (ret->log_type != IO_LOG_TYPE_HIST) {\n\t\t\ts->data.val.val0\t= le64_to_cpu(s->data.val.val0);\n\t\t\ts->data.val.val1\t= le64_to_cpu(s->data.val.val1);\n\t\t}\n\t\ts->__ddir\t= __le32_to_cpu(s->__ddir);\n\t\ts->bs\t\t= le64_to_cpu(s->bs);\n\t\ts->priority\t= le16_to_cpu(s->priority);\n\n\t\tif (ret->log_offset)\n\t\t\ts->aux[IOS_AUX_OFFSET_INDEX] =\n\t\t\t\tle64_to_cpu(s->aux[IOS_AUX_OFFSET_INDEX]);\n\n\t\tif (ret->log_issue_time)\n\t\t\ts->aux[IOS_AUX_ISSUE_TIME_INDEX] =\n\t\t\t\tle64_to_cpu(s->aux[IOS_AUX_ISSUE_TIME_INDEX]);\n\n\t\tif (ret->log_type == IO_LOG_TYPE_HIST) {\n\t\t\ts->data.plat_entry = (struct io_u_plat_entry *)(((char *)s) + sizeof(*s));\n\t\t\ts->data.plat_entry->list.next = NULL;\n\t\t\ts->data.plat_entry->list.prev = NULL;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic void sendfile_reply(int fd, struct cmd_sendfile_reply *rep,\n\t\t\t   size_t size, uint64_t tag)\n{\n\trep->error = cpu_to_le32(rep->error);\n\tfio_net_send_cmd(fd, FIO_NET_CMD_SENDFILE, rep, size, &tag, NULL);\n}\n\nstatic int fio_send_file(struct fio_client *client, struct cmd_sendfile *pdu,\n\t\t\t uint64_t tag)\n{\n\tstruct cmd_sendfile_reply *rep;\n\tstruct stat sb;\n\tsize_t size;\n\tint fd;\n\n\tsize = sizeof(*rep);\n\trep = malloc(size);\n\n\tif (stat((char *)pdu->path, &sb) < 0) {\nfail:\n\t\trep->error = errno;\n\t\tsendfile_reply(client->fd, rep, size, tag);\n\t\tfree(rep);\n\t\treturn 1;\n\t}\n\n\tsize += sb.st_size;\n\trep = realloc(rep, size);\n\trep->size = cpu_to_le32((uint32_t) sb.st_size);\n\n\tfd = open((char *)pdu->path, O_RDONLY);\n\tif (fd == -1 )\n\t\tgoto fail;\n\n\trep->error = read_data(fd, &rep->data, sb.st_size);\n\tsendfile_reply(client->fd, rep, size, tag);\n\tfree(rep);\n\tclose(fd);\n\treturn 0;\n}\n\nint fio_handle_client(struct fio_client *client)\n{\n\tstruct client_ops const *ops = client->ops;\n\tstruct fio_net_cmd *cmd;\n\n\tdprint(FD_NET, \"client: handle %s\\n\", client->hostname);\n\n\tcmd = fio_net_recv_cmd(client->fd, true);\n\tif (!cmd)\n\t\treturn 0;\n\n\tdprint(FD_NET, \"client: got cmd op %s from %s (pdu=%u)\\n\",\n\t\tfio_server_op(cmd->opcode), client->hostname, cmd->pdu_len);\n\n\tclient->last_cmd = cmd->opcode;\n\n\tswitch (cmd->opcode) {\n\tcase FIO_NET_CMD_QUIT:\n\t\tif (ops->quit)\n\t\t\tops->quit(client, cmd);\n\t\tremove_client(client);\n\t\tbreak;\n\tcase FIO_NET_CMD_TEXT:\n\t\tconvert_text(cmd);\n\t\tops->text(client, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_DU: {\n\t\tstruct cmd_du_pdu *du = (struct cmd_du_pdu *) cmd->payload;\n\n\t\tconvert_dus(&du->dus);\n\t\tconvert_agg(&du->agg);\n\n\t\tops->disk_util(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_TS: {\n\t\tstruct cmd_ts_pdu *p = (struct cmd_ts_pdu *) cmd->payload;\n\t\tuint64_t offset;\n\t\tint i;\n\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tif (le32_to_cpu(p->ts.nr_clat_prio[i])) {\n\t\t\t\toffset = le64_to_cpu(p->ts.clat_prio_offset[i]);\n\t\t\t\tp->ts.clat_prio[i] =\n\t\t\t\t\t(struct clat_prio_stat *)((char *)p + offset);\n\t\t\t}\n\t\t}\n\n\t\tdprint(FD_NET, \"client: ts->ss_state = %u\\n\", (unsigned int) le32_to_cpu(p->ts.ss_state));\n\t\tif (le32_to_cpu(p->ts.ss_state) & FIO_SS_DATA) {\n\t\t\tdprint(FD_NET, \"client: received steadystate ring buffers\\n\");\n\n\t\t\toffset = le64_to_cpu(p->ts.ss_iops_data_offset);\n\t\t\tp->ts.ss_iops_data = (uint64_t *)((char *)p + offset);\n\n\t\t\toffset = le64_to_cpu(p->ts.ss_bw_data_offset);\n\t\t\tp->ts.ss_bw_data = (uint64_t *)((char *)p + offset);\n\t\t}\n\n\t\tconvert_ts(&p->ts, &p->ts);\n\t\tconvert_gs(&p->rs, &p->rs);\n\n\t\tops->thread_status(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_GS: {\n\t\tstruct group_run_stats *gs = (struct group_run_stats *) cmd->payload;\n\n\t\tconvert_gs(gs, gs);\n\n\t\tops->group_stats(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_ETA: {\n\t\tstruct jobs_eta *je = (struct jobs_eta *) cmd->payload;\n\n\t\tif (!remove_reply_cmd(client, cmd))\n\t\t\tbreak;\n\t\tconvert_jobs_eta(je);\n\t\thandle_eta(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_PROBE:\n\t\tremove_reply_cmd(client, cmd);\n\t\tops->probe(client, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_SERVER_START:\n\t\tclient->state = Client_running;\n\t\tif (ops->job_start)\n\t\t\tops->job_start(client, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_START: {\n\t\tstruct cmd_start_pdu *pdu = (struct cmd_start_pdu *) cmd->payload;\n\n\t\tpdu->jobs = le32_to_cpu(pdu->jobs);\n\t\tops->start(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_STOP: {\n\t\tstruct cmd_end_pdu *pdu = (struct cmd_end_pdu *) cmd->payload;\n\n\t\tconvert_stop(cmd);\n\t\tclient->state = Client_stopped;\n\t\tclient->error = le32_to_cpu(pdu->error);\n\t\tclient->signal = le32_to_cpu(pdu->signal);\n\t\tops->stop(client);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_ADD_JOB: {\n\t\tstruct cmd_add_job_pdu *pdu = (struct cmd_add_job_pdu *) cmd->payload;\n\n\t\tclient->thread_number = le32_to_cpu(pdu->thread_number);\n\t\tclient->groupid = le32_to_cpu(pdu->groupid);\n\n\t\tif (ops->add_job)\n\t\t\tops->add_job(client, cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_IOLOG:\n\t\tfio_client_handle_iolog(client, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_UPDATE_JOB:\n\t\tops->update_job(client, cmd);\n\t\tremove_reply_cmd(client, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_VTRIGGER: {\n\t\tstruct all_io_list *pdu = (struct all_io_list *) cmd->payload;\n\t\tchar buf[128];\n\t\tint off = 0;\n\n\t\tif (aux_path) {\n\t\t\tstrcpy(buf, aux_path);\n\t\t\toff = strlen(buf);\n\t\t}\n\n\t\t__verify_save_state(pdu, server_name(client, &buf[off], sizeof(buf) - off));\n\t\texec_trigger(trigger_cmd);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_SENDFILE: {\n\t\tstruct cmd_sendfile *pdu = (struct cmd_sendfile *) cmd->payload;\n\t\tfio_send_file(client, pdu, cmd->tag);\n\t\tbreak;\n\t\t}\n\tcase FIO_NET_CMD_JOB_OPT: {\n\t\thandle_job_opt(client, cmd);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tlog_err(\"fio: unknown client op: %s\\n\", fio_server_op(cmd->opcode));\n\t\tbreak;\n\t}\n\n\tfree(cmd);\n\treturn 1;\n}\n\nint fio_clients_send_trigger(const char *cmd)\n{\n\tstruct flist_head *entry;\n\tstruct fio_client *client;\n\tsize_t slen;\n\n\tdprint(FD_NET, \"client: send vtrigger: %s\\n\", cmd);\n\n\tif (!cmd)\n\t\tslen = 0;\n\telse\n\t\tslen = strlen(cmd);\n\n\tflist_for_each(entry, &client_list) {\n\t\tstruct cmd_vtrigger_pdu *pdu;\n\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tpdu = malloc(sizeof(*pdu) + slen);\n\t\tpdu->len = cpu_to_le16((uint16_t) slen);\n\t\tif (slen)\n\t\t\tmemcpy(pdu->cmd, cmd, slen);\n\t\tfio_net_send_cmd(client->fd, FIO_NET_CMD_VTRIGGER, pdu,\n\t\t\t\t\tsizeof(*pdu) + slen, NULL, NULL);\n\t\tfree(pdu);\n\t}\n\n\treturn 0;\n}\n\nstatic void request_client_etas(struct client_ops const *ops)\n{\n\tstruct fio_client *client;\n\tstruct flist_head *entry;\n\tstruct client_eta *eta;\n\tint skipped = 0;\n\n\tif (eta_print == FIO_ETA_NEVER)\n\t\treturn;\n\n\tdprint(FD_NET, \"client: request eta (%d)\\n\", nr_clients);\n\n\teta = calloc(1, sizeof(*eta) + __THREAD_RUNSTR_SZ(REAL_MAX_JOBS));\n\teta->pending = nr_clients;\n\n\tflist_for_each(entry, &client_list) {\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tif (!flist_empty(&client->eta_list)) {\n\t\t\tskipped++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (client->state != Client_running)\n\t\t\tcontinue;\n\n\t\tassert(!client->eta_in_flight);\n\t\tflist_add_tail(&client->eta_list, &eta_list);\n\t\tclient->eta_in_flight = eta;\n\t\tfio_net_send_simple_cmd(client->fd, FIO_NET_CMD_SEND_ETA,\n\t\t\t\t\t(uintptr_t) eta, &client->cmd_list);\n\t}\n\n\twhile (skipped--) {\n\t\tif (!fio_client_dec_jobs_eta(eta, ops->eta))\n\t\t\tbreak;\n\t}\n\n\tdprint(FD_NET, \"client: requested eta tag %p\\n\", eta);\n}\n\n/*\n * A single SEND_ETA timeout isn't fatal. Attempt to recover.\n */\nstatic int handle_cmd_timeout(struct fio_client *client,\n\t\t\t      struct fio_net_cmd_reply *reply)\n{\n\tuint16_t reply_opcode = reply->opcode;\n\n\tflist_del(&reply->list);\n\tfree(reply);\n\n\tif (reply_opcode != FIO_NET_CMD_SEND_ETA)\n\t\treturn 1;\n\n\tlog_info(\"client <%s>: timeout on SEND_ETA\\n\", client->hostname);\n\n\tflist_del_init(&client->eta_list);\n\tif (client->eta_in_flight) {\n\t\tfio_client_dec_jobs_eta(client->eta_in_flight, client->ops->eta);\n\t\tclient->eta_in_flight = NULL;\n\t}\n\n\t/*\n\t * If we fail 5 in a row, give up...\n\t */\n\tif (client->eta_timeouts++ > 5)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int client_check_cmd_timeout(struct fio_client *client,\n\t\t\t\t    struct timespec *now)\n{\n\tstruct fio_net_cmd_reply *reply;\n\tstruct flist_head *entry, *tmp;\n\tint ret = 0;\n\n\tflist_for_each_safe(entry, tmp, &client->cmd_list) {\n\t\tunsigned int op;\n\n\t\treply = flist_entry(entry, struct fio_net_cmd_reply, list);\n\n\t\tif (mtime_since(&reply->ts, now) < FIO_NET_CLIENT_TIMEOUT)\n\t\t\tcontinue;\n\n\t\top = reply->opcode;\n\t\tif (!handle_cmd_timeout(client, reply))\n\t\t\tcontinue;\n\n\t\tlog_err(\"fio: client %s, timeout on cmd %s\\n\", client->hostname,\n\t\t\t\t\t\tfio_server_op(op));\n\t\tret = 1;\n\t}\n\n\treturn flist_empty(&client->cmd_list) && ret;\n}\n\nstatic int fio_check_clients_timed_out(void)\n{\n\tstruct fio_client *client;\n\tstruct flist_head *entry, *tmp;\n\tstruct timespec ts;\n\tint ret = 0;\n\n\tfio_gettime(&ts, NULL);\n\n\tflist_for_each_safe(entry, tmp, &client_list) {\n\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\tif (flist_empty(&client->cmd_list))\n\t\t\tcontinue;\n\n\t\tif (!client_check_cmd_timeout(client, &ts))\n\t\t\tcontinue;\n\n\t\tif (client->ops->timed_out)\n\t\t\tclient->ops->timed_out(client);\n\t\telse\n\t\t\tlog_err(\"fio: client %s timed out\\n\", client->hostname);\n\n\t\tif (client->last_cmd != FIO_NET_CMD_VTRIGGER)\n\t\t\tclient->error = ETIMEDOUT;\n\t\telse\n\t\t\tlog_info(\"fio: ignoring timeout due to vtrigger\\n\");\n\t\tremove_client(client);\n\t\tret = 1;\n\t}\n\n\treturn ret;\n}\n\nint fio_handle_clients(struct client_ops const *ops)\n{\n\tstruct pollfd *pfds;\n\tint i, ret = 0, retval = 0;\n\n\tfio_gettime(&eta_ts, NULL);\n\n\tpfds = malloc(nr_clients * sizeof(struct pollfd));\n\n\tinit_thread_stat(&client_ts);\n\tinit_group_run_stat(&client_gs);\n\n\twhile (!exit_backend && nr_clients) {\n\t\tstruct flist_head *entry, *tmp;\n\t\tstruct fio_client *client;\n\n\t\ti = 0;\n\t\tflist_for_each_safe(entry, tmp, &client_list) {\n\t\t\tclient = flist_entry(entry, struct fio_client, list);\n\n\t\t\tif (!client->sent_job && !client->ops->stay_connected &&\n\t\t\t    flist_empty(&client->cmd_list)) {\n\t\t\t\tremove_client(client);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tpfds[i].fd = client->fd;\n\t\t\tpfds[i].events = POLLIN;\n\t\t\ti++;\n\t\t}\n\n\t\tif (!nr_clients)\n\t\t\tbreak;\n\n\t\tassert(i == nr_clients);\n\n\t\tdo {\n\t\t\tstruct timespec ts;\n\t\t\tint timeout;\n\n\t\t\tfio_gettime(&ts, NULL);\n\t\t\tif (eta_time_within_slack(mtime_since(&eta_ts, &ts))) {\n\t\t\t\trequest_client_etas(ops);\n\t\t\t\tmemcpy(&eta_ts, &ts, sizeof(ts));\n\n\t\t\t\tif (fio_check_clients_timed_out())\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tcheck_trigger_file();\n\n\t\t\ttimeout = min(100u, ops->eta_msec);\n\n\t\t\tret = poll(pfds, nr_clients, timeout);\n\t\t\tif (ret < 0) {\n\t\t\t\tif (errno == EINTR)\n\t\t\t\t\tcontinue;\n\t\t\t\tlog_err(\"fio: poll clients: %s\\n\", strerror(errno));\n\t\t\t\tbreak;\n\t\t\t} else if (!ret)\n\t\t\t\tcontinue;\n\t\t} while (ret <= 0);\n\n\t\tfor (i = 0; i < nr_clients; i++) {\n\t\t\tif (!(pfds[i].revents & POLLIN))\n\t\t\t\tcontinue;\n\n\t\t\tclient = find_client_by_fd(pfds[i].fd);\n\t\t\tif (!client) {\n\t\t\t\tlog_err(\"fio: unknown client fd %ld\\n\", (long) pfds[i].fd);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!fio_handle_client(client)) {\n\t\t\t\tlog_info(\"client: host=%s disconnected\\n\",\n\t\t\t\t\t\tclient->hostname);\n\t\t\t\tremove_client(client);\n\t\t\t\tretval = 1;\n\t\t\t} else if (client->error)\n\t\t\t\tretval = 1;\n\t\t\tfio_put_client(client);\n\t\t}\n\t}\n\n\tlog_info_buf(allclients.buf, allclients.buflen);\n\tbuf_output_free(&allclients);\n\n\tfio_client_json_fini();\n\n\tfree_clat_prio_stats(&client_ts);\n\tfree(pfds);\n\treturn retval || error_clients;\n}\n\nstatic void client_display_thread_status(struct jobs_eta *je)\n{\n\tif (!(output_format & FIO_OUTPUT_JSON))\n\t\tdisplay_thread_status(je);\n}\n"
        },
        {
          "name": "client.h",
          "type": "blob",
          "size": 3.5234375,
          "content": "#ifndef CLIENT_H\n#define CLIENT_H\n\n#include <sys/un.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n\n#include \"lib/types.h\"\n#include \"stat.h\"\n\nstruct fio_net_cmd;\n\nenum {\n\tClient_created\t\t= 0,\n\tClient_connected\t= 1,\n\tClient_started\t\t= 2,\n\tClient_running\t\t= 3,\n\tClient_stopped\t\t= 4,\n\tClient_exited\t\t= 5,\n};\n\nstruct client_file {\n\tchar *file;\n\tbool remote;\n};\n\nstruct fio_client {\n\tstruct flist_head list;\n\tstruct flist_head hash_list;\n\tstruct flist_head arg_list;\n\tunion {\n\t\tstruct sockaddr_in addr;\n\t\tstruct sockaddr_in6 addr6;\n\t\tstruct sockaddr_un addr_un;\n\t};\n\tchar *hostname;\n\tint port;\n\tint fd;\n\tunsigned int refs;\n\tunsigned int last_cmd;\n\n\tchar *name;\n\n\tstruct flist_head *opt_lists;\n\n\tint state;\n\n\tbool skip_newline;\n\tbool is_sock;\n\tbool disk_stats_shown;\n\tunsigned int jobs;\n\tunsigned int nr_stat;\n\tint error;\n\tint signal;\n\tint ipv6;\n\tbool sent_job;\n\tbool did_stat;\n\tuint32_t type;\n\n\tuint32_t thread_number;\n\tuint32_t groupid;\n\n\tstruct flist_head eta_list;\n\tstruct client_eta *eta_in_flight;\n\tunsigned int eta_timeouts;\n\n\tstruct flist_head cmd_list;\n\n\tuint16_t argc;\n\tchar **argv;\n\n\tstruct client_ops const *ops;\n\tvoid *client_data;\n\n\tstruct client_file *files;\n\tunsigned int nr_files;\n\n\tstruct buf_output buf;\n};\n\ntypedef void (client_cmd_op)(struct fio_client *, struct fio_net_cmd *);\ntypedef void (client_op)(struct fio_client *);\ntypedef void (client_eta_op)(struct jobs_eta *je);\ntypedef void (client_timed_out_op)(struct fio_client *);\ntypedef void (client_jobs_eta_op)(struct fio_client *client, struct jobs_eta *je);\n\nextern struct client_ops const fio_client_ops;\n\nstruct client_ops {\n\tclient_cmd_op\t\t*text;\n\tclient_cmd_op\t\t*disk_util;\n\tclient_cmd_op\t\t*thread_status;\n\tclient_cmd_op\t\t*group_stats;\n\tclient_jobs_eta_op\t*jobs_eta;\n\tclient_eta_op\t\t*eta;\n\tclient_cmd_op\t\t*probe;\n\tclient_cmd_op\t\t*quit;\n\tclient_cmd_op\t\t*add_job;\n\tclient_cmd_op\t\t*update_job;\n\tclient_timed_out_op\t*timed_out;\n\tclient_op\t\t*stop;\n\tclient_cmd_op\t\t*start;\n\tclient_cmd_op\t\t*job_start;\n\tclient_timed_out_op\t*removed;\n\n\tunsigned int eta_msec;\n\tint stay_connected;\n\tuint32_t client_type;\n};\n\nstruct client_eta {\n\tunsigned int pending;\n\tstruct jobs_eta eta;\n};\n\nextern int fio_handle_client(struct fio_client *);\nextern void fio_client_sum_jobs_eta(struct jobs_eta *dst, struct jobs_eta *je);\n\nenum {\n\tFio_client_ipv4 = 1,\n\tFio_client_ipv6,\n\tFio_client_socket,\n};\n\nextern int fio_client_connect(struct fio_client *);\nextern int fio_clients_connect(void);\nextern int fio_start_client(struct fio_client *);\nextern int fio_start_all_clients(void);\nextern int fio_clients_send_ini(const char *);\nextern int fio_client_send_ini(struct fio_client *, const char *, bool);\nextern int fio_handle_clients(struct client_ops const*);\nextern int fio_client_add(struct client_ops const*, const char *, void **);\nextern struct fio_client *fio_client_add_explicit(struct client_ops *, const char *, int, int);\nextern void fio_client_add_cmd_option(void *, const char *);\nextern int fio_client_add_ini_file(void *, const char *, bool);\nextern int fio_client_terminate(struct fio_client *);\nextern struct fio_client *fio_get_client(struct fio_client *);\nextern void fio_put_client(struct fio_client *);\nextern int fio_client_update_options(struct fio_client *, struct thread_options *, uint64_t *);\nextern int fio_client_wait_for_reply(struct fio_client *, uint64_t);\nextern int fio_clients_send_trigger(const char *);\n\n#define FIO_CLIENT_DEF_ETA_MSEC\t\t900\n\nenum {\n\tFIO_CLIENT_TYPE_CLI\t\t= 1,\n\tFIO_CLIENT_TYPE_GUI\t\t= 2,\n};\n\nextern int sum_stat_clients;\nextern struct thread_stat client_ts;\nextern struct group_run_stats client_gs;\n\n#endif\n\n"
        },
        {
          "name": "compiler",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure",
          "type": "blob",
          "size": 76.9951171875,
          "content": "#!/bin/sh\n#\n# Fio configure script. Heavily influenced by the manual qemu configure\n# script. Sad this is easier than autoconf and enemies.\n#\n\n# set temporary file name\nif test ! -z \"$TMPDIR\" ; then\n    TMPDIR1=\"${TMPDIR}\"\nelif test ! -z \"$TEMPDIR\" ; then\n    TMPDIR1=\"${TEMPDIR}\"\nelse\n    TMPDIR1=\"/tmp\"\nfi\n\nTMPC=\"${TMPDIR1}/fio-conf-${RANDOM}-$$-${RANDOM}.c\"\nTMPC2=\"${TMPDIR1}/fio-conf-${RANDOM}-$$-${RANDOM}-2.c\"\nTMPO=\"${TMPDIR1}/fio-conf-${RANDOM}-$$-${RANDOM}.o\"\nTMPE=\"${TMPDIR1}/fio-conf-${RANDOM}-$$-${RANDOM}.exe\"\n\n# NB: do not call \"exit\" in the trap handler; this is buggy with some shells;\n# see <1285349658-3122-1-git-send-email-loic.minier@linaro.org>\ntrap \"rm -f $TMPC $TMPC2 $TMPO $TMPE\" EXIT INT QUIT TERM\n\nrm -rf config.log\n\nconfig_host_mak=\"config-host.mak\"\nconfig_host_h=\"config-host.h\"\n\nrm -rf $config_host_mak\nrm -rf $config_host_h\n\nfatal() {\n  echo $@\n  echo \"Configure failed, check config.log and/or the above output\"\n  rm -rf $config_host_mak\n  rm -rf $config_host_h\n  exit 1\n}\n\n# Print result for each configuration test\nprint_config() {\n  printf \"%-30s%s\\n\" \"$1\" \"$2\"\n}\n\n# Default CFLAGS\nCFLAGS=\"-D_GNU_SOURCE -include config-host.h $CFLAGS\"\nCONFIGURE_CFLAGS=\"-Werror-implicit-function-declaration\"\nBUILD_CFLAGS=\"\"\n\n# Print a helpful header at the top of config.log\necho \"# FIO configure log $(date)\" >> config.log\nprintf \"# Configured with:\" >> config.log\nprintf \" '%s'\" \"$0\" \"$@\" >> config.log\necho >> config.log\necho \"#\" >> config.log\n\n# Print configure header at the top of $config_host_h\necho \"/*\" > $config_host_h\necho \" * Automatically generated by configure - do not modify\" >> $config_host_h\nprintf \" * Configured with:\" >> $config_host_h\nprintf \" * '%s'\" \"$0\" \"$@\" >> $config_host_h\necho \"\" >> $config_host_h\necho \" */\" >> $config_host_h\n\ndo_cc() {\n    # Run the compiler, capturing its output to the log.\n    echo $cc \"$@\" >> config.log\n    $cc \"$@\" >> config.log 2>&1 || return $?\n    # Test passed. If this is an --enable-werror build, rerun\n    # the test with -Werror and bail out if it fails. This\n    # makes warning-generating-errors in configure test code\n    # obvious to developers.\n    if test \"$werror\" != \"yes\"; then\n        return 0\n    fi\n    # Don't bother rerunning the compile if we were already using -Werror\n    case \"$*\" in\n        *-Werror*)\n           return 0\n        ;;\n    esac\n    echo $cc -Werror \"$@\" >> config.log\n    $cc -Werror \"$@\" >> config.log 2>&1 && return $?\n    echo \"ERROR: configure test passed without -Werror but failed with -Werror.\"\n    echo \"This is probably a bug in the configure script. The failing command\"\n    echo \"will be at the bottom of config.log.\"\n    fatal \"You can run configure with --disable-werror to bypass this check.\"\n}\n\ncompile_object() {\n  do_cc $CFLAGS $CONFIGURE_CFLAGS -c -o $TMPO $TMPC\n}\n\ncompile_prog() {\n  local_cflags=\"$1\"\n  local_ldflags=\"$2 $LIBS\"\n  echo \"Compiling test case $3\" >> config.log\n  do_cc $CFLAGS $CONFIGURE_CFLAGS $local_cflags -o $TMPE $TMPC $LDFLAGS $local_ldflags\n}\n\nfeature_not_found() {\n  feature=$1\n  packages=$2\n\n  echo \"ERROR\"\n  echo \"ERROR: User requested feature $feature\"\n  if test ! -z \"$packages\" ; then\n    echo \"ERROR: That feature needs $packages installed\"\n  fi\n  echo \"ERROR: configure was not able to find it\"\n  fatal \"ERROR\"\n}\n\nhas() {\n  type \"$1\" >/dev/null 2>&1\n}\n\nnum() {\n  echo \"$1\" | grep -E -q \"^[0-9]+$\"\n}\n\ncheck_define() {\n  cat > $TMPC <<EOF\n#if !defined($1)\n#error $1 not defined\n#endif\nint main(void)\n{\n  return 0;\n}\nEOF\n  compile_object\n}\n\ncheck_val() {\n    cat > $TMPC <<EOF\n#if $1 == $2\nint main(void)\n{\n  return 0;\n}\n#else\n#error $1 is not equal $2\n#endif\nEOF\n  compile_object\n}\n\noutput_sym() {\n  echo \"$1=y\" >> $config_host_mak\n  echo \"#define $1\" >> $config_host_h\n}\n\ncheck_min_lib_version() {\n  _feature=$3\n\n  if pkg-config --atleast-version=\"$2\" \"$1\" > /dev/null 2>&1; then\n    return 0\n  fi\n  : \"${_feature:=${1}}\"\n  if pkg-config --version > /dev/null 2>&1; then\n    if test \"$(eval echo \\\"\\$$_feature\\\")\" = \"yes\" ; then\n      feature_not_found \"$_feature\" \"$1 >= $2\"\n    fi\n  else\n    print_config \"$1\" \"missing pkg-config, can't check $_feature version\"\n  fi\n  return 1\n}\n\ntargetos=\"\"\ncpu=\"\"\n\n# default options\nshow_help=\"no\"\nexit_val=0\ngfio_check=\"no\"\nlibhdfs=\"no\"\ndevdax=\"no\"\npmem=\"no\"\ncuda=\"no\"\nlibcufile=\"no\"\ndisable_lex=\"\"\ndisable_pmem=\"no\"\ndisable_native=\"no\"\nmarch_set=\"no\"\nlibiscsi=\"no\"\nlibnbd=\"no\"\nlibnfs=\"\"\nxnvme=\"\"\nisal=\"\"\nlibblkio=\"\"\nlibzbc=\"\"\ndfs=\"\"\nseed_buckets=\"\"\ndynamic_engines=\"no\"\nprefix=/usr/local\n\n# parse options\nfor opt do\n  optarg=`expr \"x$opt\" : 'x[^=]*=\\(.*\\)'`\n  case \"$opt\" in\n  --prefix=*) prefix=\"$optarg\"\n  ;;\n  --cpu=*) cpu=\"$optarg\"\n  ;;\n  #  esx is cross compiled and cannot be detect through simple uname calls\n  --esx)\n  esx=\"yes\"\n  ;;\n  --cc=*) CC=\"$optarg\"\n  ;;\n  --extra-cflags=*) CFLAGS=\"$CFLAGS $optarg\"\n  ;;\n  --build-32bit-win) build_32bit_win=\"yes\"\n  ;;\n  --target-win-ver=*) target_win_ver=\"$optarg\"\n  ;;\n  --enable-pdb) pdb=\"yes\"\n  ;;\n  --build-static) build_static=\"yes\"\n  ;;\n  --enable-gfio) gfio_check=\"yes\"\n  ;;\n  --disable-numa) disable_numa=\"yes\"\n  ;;\n  --disable-rdma) disable_rdma=\"yes\"\n  ;;\n  --disable-rados) disable_rados=\"yes\"\n  ;;\n  --disable-rbd) disable_rbd=\"yes\"\n  ;;\n  --disable-http) disable_http=\"yes\"\n  ;;\n  --disable-gfapi) disable_gfapi=\"yes\"\n  ;;\n  --enable-libhdfs) libhdfs=\"yes\"\n  ;;\n  --disable-lex) disable_lex=\"yes\"\n  ;;\n  --enable-lex) disable_lex=\"no\"\n  ;;\n  --disable-shm) no_shm=\"yes\"\n  ;;\n  --disable-optimizations) disable_opt=\"yes\"\n  ;;\n  --disable-pmem) disable_pmem=\"yes\"\n  ;;\n  --enable-cuda) cuda=\"yes\"\n  ;;\n  --enable-libcufile) libcufile=\"yes\"\n  ;;\n  --disable-native) disable_native=\"yes\"\n  ;;\n  --with-ime=*) ime_path=\"$optarg\"\n  ;;\n  --enable-libiscsi) libiscsi=\"yes\"\n  ;;\n  --enable-libnbd) libnbd=\"yes\"\n  ;;\n  --disable-libzbc) libzbc=\"no\"\n  ;;\n  --disable-xnvme) xnvme=\"no\"\n  ;;\n  --disable-isal) isal=\"no\"\n  ;;\n  --disable-libblkio) libblkio=\"no\"\n  ;;\n  --disable-tcmalloc) disable_tcmalloc=\"yes\"\n  ;;\n  --disable-libnfs) libnfs=\"no\"\n  ;;\n  --enable-libnfs) libnfs=\"yes\"\n  ;;\n  --dynamic-libengines) dynamic_engines=\"yes\"\n  ;;\n  --disable-dfs) dfs=\"no\"\n  ;;\n  --enable-asan) asan=\"yes\"\n  ;;\n  --seed-buckets=*) seed_buckets=\"$optarg\"\n  ;;\n  --disable-tls) tls_check=\"no\"\n  ;;\n  --help)\n    show_help=\"yes\"\n    ;;\n  *)\n  echo \"Bad option $opt\"\n  show_help=\"yes\"\n  exit_val=1\n  esac\ndone\n\nif test \"$show_help\" = \"yes\" ; then\n  echo \"--prefix=               Use this directory as installation prefix\"\n  echo \"--cpu=                  Specify target CPU if auto-detect fails\"\n  echo \"--cc=                   Specify compiler to use\"\n  echo \"--extra-cflags=         Specify extra CFLAGS to pass to compiler\"\n  echo \"--build-32bit-win       Enable 32-bit build on Windows\"\n  echo \"--target-win-ver=       Minimum version of Windows to target (only accepts 7)\"\n  echo \"--enable-pdb            Enable Windows PDB symbols generation (needs clang/lld)\"\n  echo \"--build-static          Build a static fio\"\n  echo \"--esx                   Configure build options for esx\"\n  echo \"--enable-gfio           Enable building of gtk gfio\"\n  echo \"--disable-numa          Disable libnuma even if found\"\n  echo \"--disable-rdma          Disable RDMA support even if found\"\n  echo \"--disable-rados         Disable Rados support even if found\"\n  echo \"--disable-rbd           Disable Rados Block Device even if found\"\n  echo \"--disable-http          Disable HTTP support even if found\"\n  echo \"--disable-gfapi         Disable gfapi\"\n  echo \"--enable-libhdfs        Enable hdfs support\"\n  echo \"--enable-libnfs         Enable nfs support\"\n  echo \"--disable-libnfs        Disable nfs support\"\n  echo \"--disable-lex           Disable use of lex/yacc for math\"\n  echo \"--disable-pmem          Disable pmem based engines even if found\"\n  echo \"--enable-lex            Enable use of lex/yacc for math\"\n  echo \"--disable-shm           Disable SHM support\"\n  echo \"--disable-optimizations Don't enable compiler optimizations\"\n  echo \"--enable-cuda           Enable GPUDirect RDMA support\"\n  echo \"--enable-libcufile      Enable GPUDirect Storage cuFile support\"\n  echo \"--disable-native        Don't build for native host\"\n  echo \"--with-ime=             Install path for DDN's Infinite Memory Engine\"\n  echo \"--enable-libiscsi       Enable iscsi support\"\n  echo \"--enable-libnbd         Enable libnbd (NBD engine) support\"\n  echo \"--disable-xnvme         Disable xnvme support even if found\"\n  echo \"--disable-isal          Disable isal support even if found\"\n  echo \"--disable-libblkio      Disable libblkio support even if found\"\n  echo \"--disable-libzbc        Disable libzbc even if found\"\n  echo \"--disable-tcmalloc      Disable tcmalloc support\"\n  echo \"--dynamic-libengines    Lib-based ioengines as dynamic libraries\"\n  echo \"--disable-dfs           Disable DAOS File System support even if found\"\n  echo \"--enable-asan           Enable address sanitizer\"\n  echo \"--seed-buckets=         Number of seed buckets for the refill-buffer\"\n  echo \"--disable-tls\t\tDisable __thread local storage\"\n  exit $exit_val\nfi\n\ncross_prefix=${cross_prefix-${CROSS_COMPILE}}\n# Preferred compiler (can be overridden later after we know the platform):\n#  ${CC} (if set)\n#  ${cross_prefix}gcc (if cross-prefix specified)\n#  gcc if available\n#  clang if available\nif test -z \"${CC}${cross_prefix}\"; then\n  if has gcc; then\n    cc=gcc\n  elif has clang; then\n    cc=clang\n  fi\nelse\n  cc=\"${CC-${cross_prefix}gcc}\"\nfi\n\nif check_define __ANDROID__ ; then\n  targetos=\"Android\"\nelif check_define __linux__ ; then\n  targetos=\"Linux\"\nelif check_define __OpenBSD__ ; then\n  targetos='OpenBSD'\nelif check_define __NetBSD__ ; then\n  targetos='NetBSD'\nelif check_define __sun__ ; then\n  targetos='SunOS'\n  CFLAGS=\"$CFLAGS -D_REENTRANT\"\nelif check_define _WIN32 ; then\n  targetos='CYGWIN'\nelif check_define __QNX__ ; then\n  targetos='QNX'\nelse\n  targetos=`uname -s`\nfi\n\necho \"# Automatically generated by configure - do not modify\" > $config_host_mak\nprintf \"# Configured with:\" >> $config_host_mak\nprintf \" '%s'\" \"$0\" \"$@\" >> $config_host_mak\necho >> $config_host_mak\necho \"CONFIG_TARGET_OS=$targetos\" >> $config_host_mak\n\nif test \"$no_shm\" = \"yes\" ; then\n  output_sym \"CONFIG_NO_SHM\"\nfi\n\nif test \"$disable_opt\" = \"yes\" ; then\n  output_sym \"CONFIG_FIO_NO_OPT\"\nfi\n\n# Some host OSes need non-standard checks for which CPU to use.\n# Note that these checks are broken for cross-compilation: if you're\n# cross-compiling to one of these OSes then you'll need to specify\n# the correct CPU with the --cpu option.\ncase $targetos in\nAIX|OpenBSD|NetBSD)\n  # Unless explicitly enabled, turn off lex.\n  # OpenBSD will hit syntax error when enabled.\n  if test -z \"$disable_lex\" ; then\n    disable_lex=\"yes\"\n  else\n    force_no_lex_o=\"yes\"\n  fi\n  ;;\nFreeBSD)\n  CFLAGS=\"$CFLAGS -I/usr/local/include\"\n  LDFLAGS=\"$LDFLAGS -L/usr/local/lib\"\n  ;;\nDarwin)\n  # on Leopard most of the system is 32-bit, so we have to ask the kernel if\n  # we can run 64-bit userspace code.\n  # If the user didn't specify a CPU explicitly and the kernel says this is\n  # 64 bit hw, then assume x86_64. Otherwise fall through to the usual\n  # detection code.\n  if test -z \"$cpu\" && test \"$(sysctl -n hw.optional.x86_64)\" = \"1\"; then\n    cpu=\"x86_64\"\n  fi\n  # Avoid configure feature detection of features provided by weak symbols\ncat > $TMPC <<EOF\nint main(void)\n{\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"-Werror=partial-availability\" \"error on weak symbols\"; then\n    CONFIGURE_CFLAGS=\"$CONFIGURE_CFLAGS -Werror=partial-availability\"\n  fi\n  ;;\nSunOS)\n  # `uname -m` returns i86pc even on an x86_64 box, so default based on isainfo\n  if test -z \"$cpu\" && test \"$(isainfo -k)\" = \"amd64\"; then\n    cpu=\"x86_64\"\n  fi\n  LIBS=\"-lnsl -lsocket\"\n  ;;\nCYGWIN*)\n  # We still force some options, so keep this message here.\n  echo \"Forcing some known good options on Windows\"\n  if test -z \"${CC}${cross_prefix}\"; then\n    if test ! -z \"$build_32bit_win\" && test \"$build_32bit_win\" = \"yes\"; then\n      cc=\"i686-w64-mingw32-gcc\"\n    else\n      cc=\"x86_64-w64-mingw32-gcc\"\n    fi\n  fi\n\n  target_win_ver=$(echo \"$target_win_ver\" | tr '[:lower:]' '[:upper:]')\n  if test -z \"$target_win_ver\"; then\n    # Default Windows API target\n    target_win_ver=\"7\"\n  fi\n  if test \"$target_win_ver\" = \"7\"; then\n    output_sym \"CONFIG_WINDOWS_7\"\n    CFLAGS=\"$CFLAGS -D_WIN32_WINNT=0x0601\"\n  else\n    fatal \"Unknown target Windows version\"\n  fi\n\n  # We need this to be output_sym'd here because this is Windows specific.\n  # The regular configure path never sets this config.\n  output_sym \"CONFIG_WINDOWSAIO\"\n  # We now take the regular configuration path without having exit 0 here.\n  # Flags below are still necessary mostly for MinGW.\n  build_static=\"yes\"\n  rusage_thread=\"yes\"\n  fdatasync=\"yes\"\n  clock_gettime=\"yes\" # clock_monotonic probe has dependency on this\n  clock_monotonic=\"yes\"\n  sched_idle=\"yes\"\n  pthread_condattr_setclock=\"no\"\n  pthread_affinity=\"no\"\n  ;;\nQNX)\n  LIBS=\"-lsocket\"\n  ;;\nesac\n\n# Now we know the target platform we can have another guess at the preferred\n# compiler when it wasn't explictly set\nif test -z \"${CC}${cross_prefix}\"; then\n  if test \"$targetos\" = \"FreeBSD\" || test \"$targetos\" = \"Darwin\"; then\n    if has clang; then\n      cc=clang\n    fi\n  fi\nfi\nif test -z \"$cc\"; then\n    echo \"configure: failed to find compiler\"\n    exit 1\nfi\n\nif test ! -z \"$cpu\" ; then\n  # command line argument\n  :\nelif check_define __i386__ ; then\n  cpu=\"i386\"\nelif check_define __x86_64__ ; then\n  cpu=\"x86_64\"\nelif check_define __sparc__ ; then\n  if check_define __arch64__ ; then\n    cpu=\"sparc64\"\n  else\n    cpu=\"sparc\"\n  fi\nelif check_define _ARCH_PPC ; then\n  if check_define _ARCH_PPC64 ; then\n    cpu=\"ppc64\"\n  else\n    cpu=\"ppc\"\n  fi\nelif check_define __mips__ ; then\n  cpu=\"mips\"\nelif check_define __ia64__ ; then\n  cpu=\"ia64\"\nelif check_define __s390__ ; then\n  if check_define __s390x__ ; then\n    cpu=\"s390x\"\n  else\n    cpu=\"s390\"\n  fi\nelif check_define __arm__ ; then\n  cpu=\"arm\"\nelif check_define __aarch64__ ; then\n  cpu=\"aarch64\"\nelif check_define __hppa__ ; then\n  cpu=\"hppa\"\nelif check_define __loongarch64 ; then\n  cpu=\"loongarch64\"\nelif check_define __riscv ; then\n  if check_val __riscv_xlen 32 ; then\n    cpu=\"riscv32\"\n  elif check_val __riscv_xlen 64 ; then\n    cpu=\"riscv64\"\n  elif check_val __riscv_xlen 128 ; then\n    cpu=\"riscv128\"\n  fi\nelse\n  cpu=`uname -m`\nfi\n\n# Normalise host CPU name and set ARCH.\ncase \"$cpu\" in\n  ia64|ppc|ppc64|s390|s390x|sparc64|loongarch64|riscv64)\n    cpu=\"$cpu\"\n  ;;\n  i386|i486|i586|i686|i86pc|BePC)\n    cpu=\"x86\"\n  ;;\n  x86_64|amd64)\n    cpu=\"x86_64\"\n  ;;\n  armv*b|armv*l|arm)\n    cpu=\"arm\"\n  ;;\n  aarch64)\n    cpu=\"arm64\"\n  ;;\n  hppa|parisc|parisc64)\n    cpu=\"hppa\"\n  ;;\n  mips*)\n    cpu=\"mips\"\n  ;;\n  sparc|sun4[cdmuv])\n    cpu=\"sparc\"\n  ;;\n  *)\n  echo \"Unknown CPU\"\n  ;;\nesac\n\n##########################################\n# check cross compile\n\nif test \"$cross_compile\" != \"yes\" ; then\n  cross_compile=\"no\"\nfi\ncat > $TMPC <<EOF\nint main(void)\n{\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"cross\"; then\n  $TMPE 2>/dev/null || cross_compile=\"yes\"\nelse\n  fatal \"compile test failed\"\nfi\n\n##########################################\n# check endianness\nif test \"$bigendian\" != \"yes\" ; then\n  bigendian=\"no\"\nfi\nif test \"$cross_compile\" = \"no\" ; then\n  cat > $TMPC <<EOF\n#include <inttypes.h>\nint main(void)\n{\n  volatile uint32_t i=0x01234567;\n  return (*((uint8_t*)(&i))) == 0x67;\n}\nEOF\n  if compile_prog \"\" \"\" \"endian\"; then\n    $TMPE && bigendian=\"yes\"\n  fi\nelse\n  # If we're cross compiling, try our best to work it out and rely on the\n  # run-time check to fail if we get it wrong.\n  cat > $TMPC <<EOF\n#include <endian.h>\nint main(void)\n{\n#if __BYTE_ORDER != __BIG_ENDIAN\n# error \"Unknown endianness\"\n#endif\n}\nEOF\n  compile_prog \"\" \"\" \"endian\" && bigendian=\"yes\"\n  check_define \"__ARMEB__\" && bigendian=\"yes\"\n  check_define \"__MIPSEB__\" && bigendian=\"yes\"\nfi\n\n\nprint_config \"Operating system\" \"$targetos\"\nprint_config \"CPU\" \"$cpu\"\nprint_config \"Big endian\" \"$bigendian\"\nif test ! -z \"$target_win_ver\"; then\n  print_config \"Target Windows version\" \"$target_win_ver\"\nfi\nprint_config \"Compiler\" \"$cc\"\nprint_config \"Cross compile\" \"$cross_compile\"\necho\n\n##########################################\n# See if we need to build a static build\nif test \"$build_static\" = \"yes\" ; then\n  CFLAGS=\"$CFLAGS -ffunction-sections -fdata-sections\"\n  LDFLAGS=\"$LDFLAGS -static -Wl,--gc-sections\"\nelse\n  build_static=\"no\"\nfi\nprint_config \"Static build\" \"$build_static\"\n\n##########################################\n# check for C11 atomics support\ncat > $TMPC <<EOF\n#include <stdatomic.h>\nint main(void)\n{\n  _Atomic unsigned v;\n  atomic_load(&v);\n  return 0;\n}\nEOF\nif ! compile_prog \"\" \"\" \"C11 atomics\"; then\n  echo\n  echo \"Your compiler doesn't support C11 atomics. gcc 4.9/clang 3.6 are the\"\n  echo \"minimum versions with it - perhaps your compiler is too old?\"\n  fatal \"C11 atomics support not found\"\nfi\n\n\n##########################################\n# check for wordsize\nwordsize=\"0\"\ncat > $TMPC <<EOF\n#include <limits.h>\n#define BUILD_BUG_ON(condition) ((void)sizeof(char[1 - 2*!!(condition)]))\nint main(void)\n{\n  BUILD_BUG_ON(sizeof(long)*CHAR_BIT != WORDSIZE);\n  return 0;\n}\nEOF\nif compile_prog \"-DWORDSIZE=32\" \"\" \"wordsize\"; then\n  wordsize=\"32\"\nelif compile_prog \"-DWORDSIZE=64\" \"\" \"wordsize\"; then\n  wordsize=\"64\"\nelse\n  fatal \"Unknown wordsize\"\nfi\nprint_config \"Wordsize\" \"$wordsize\"\n\n##########################################\n# zlib probe\nif test \"$zlib\" != \"yes\" ; then\n  zlib=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <zlib.h>\nint main(void)\n{\n  z_stream stream;\n  if (inflateInit(&stream) != Z_OK)\n    return 1;\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-lz\" \"zlib\" ; then\n  zlib=yes\n  LIBS=\"-lz $LIBS\"\nfi\nprint_config \"zlib\" \"$zlib\"\n\n##########################################\n# fcntl(F_FULLFSYNC) support\nif test \"$fcntl_sync\" != \"yes\" ; then\n  fcntl_sync=\"no\"\nfi\ncat > $TMPC << EOF\n#include <unistd.h>\n#include <fcntl.h>\n\nint main(int argc, char **argv)\n{\n  return fcntl(0, F_FULLFSYNC);\n}\nEOF\nif compile_prog \"\" \"\" \"fcntl(F_FULLFSYNC)\" ; then\n    fcntl_sync=\"yes\"\nfi\nprint_config \"fcntl(F_FULLFSYNC)\" \"$fcntl_sync\"\n\n##########################################\n# linux-aio probe\nif test \"$libaio\" != \"yes\" ; then\n  libaio=\"no\"\nfi\nif test \"$esx\" != \"yes\" ; then\n  cat > $TMPC <<EOF\n#include <libaio.h>\n#include <stddef.h>\nint main(void)\n{\n  io_setup(0, NULL);\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"-laio\" \"libaio\" ; then\n    libaio=yes\n  else\n    if test \"$libaio\" = \"yes\" ; then\n      feature_not_found \"linux AIO\" \"libaio-dev or libaio-devel\"\n    fi\n    libaio=no\n  fi\n\n  cat > $TMPC <<EOF\n#include <libaio.h>\n#include <stddef.h>\nint main(void)\n{\n  io_prep_preadv2(NULL, 0, NULL, 0, 0, 0);\n  io_prep_pwritev2(NULL, 0, NULL, 0, 0, 0);\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"\" \"libaio rw flags\" ; then\n    libaio_rw_flags=yes\n  else\n    libaio_rw_flags=no\n  fi\nfi\nprint_config \"Linux AIO support\" \"$libaio\"\nprint_config \"Linux AIO support rw flags\" \"$libaio_rw_flags\"\n\n##########################################\n# posix aio probe\nif test \"$posix_aio\" != \"yes\" ; then\n  posix_aio=\"no\"\nfi\nif test \"$posix_aio_lrt\" != \"yes\" ; then\n  posix_aio_lrt=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <aio.h>\nint main(void)\n{\n  struct aiocb cb;\n  aio_read(&cb);\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"posixaio\" ; then\n  posix_aio=\"yes\"\nelif compile_prog \"\" \"-lrt\" \"posixaio -lrt\"; then\n  posix_aio=\"yes\"\n  posix_aio_lrt=\"yes\"\n  LIBS=\"-lrt $LIBS\"\nfi\nprint_config \"POSIX AIO support\" \"$posix_aio\"\nprint_config \"POSIX AIO support needs -lrt\" \"$posix_aio_lrt\"\n\n##########################################\n# posix aio fsync probe\nif test \"$posix_aio_fsync\" != \"yes\" ; then\n  posix_aio_fsync=\"no\"\nfi\nif test \"$posix_aio\" = \"yes\" ; then\n  cat > $TMPC <<EOF\n#include <fcntl.h>\n#include <aio.h>\nint main(void)\n{\n  struct aiocb cb;\n  return aio_fsync(O_SYNC, &cb);\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"$LIBS\" \"posix_aio_fsync\" ; then\n    posix_aio_fsync=yes\n  fi\nfi\nprint_config \"POSIX AIO fsync\" \"$posix_aio_fsync\"\n\n##########################################\n# POSIX pshared attribute probe\nif test \"$posix_pshared\" != \"yes\" ; then\n  posix_pshared=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <unistd.h>\nint main(void)\n{\n#if defined(_POSIX_THREAD_PROCESS_SHARED) && ((_POSIX_THREAD_PROCESS_SHARED + 0) > 0)\n# if defined(__CYGWIN__)\n#  error \"_POSIX_THREAD_PROCESS_SHARED is buggy on Cygwin\"\n# elif defined(__APPLE__)\n#  include <AvailabilityMacros.h>\n#  include <TargetConditionals.h>\n#  if TARGET_OS_MAC && MAC_OS_X_VERSION_MIN_REQUIRED < 1070\n#   error \"_POSIX_THREAD_PROCESS_SHARED is buggy/unsupported prior to OSX 10.7\"\n#  endif\n# endif\n#else\n# error \"_POSIX_THREAD_PROCESS_SHARED is unsupported\"\n#endif\n  return 0;\n}\nEOF\nif compile_prog \"\" \"$LIBS\" \"posix_pshared\" ; then\n  posix_pshared=yes\nfi\nprint_config \"POSIX pshared support\" \"$posix_pshared\"\n\n##########################################\n# POSIX pthread_condattr_setclock() probe\nif test \"$pthread_condattr_setclock\" != \"no\" ; then\n  cat > $TMPC <<EOF\n#include <pthread.h>\nint main(void)\n{\n  pthread_condattr_t condattr;\n  pthread_condattr_setclock(&condattr, CLOCK_MONOTONIC);\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"$LIBS\" \"pthread_condattr_setclock\" ; then\n    pthread_condattr_setclock=yes\n  elif compile_prog \"\" \"$LIBS -lpthread\" \"pthread_condattr_setclock\" ; then\n    pthread_condattr_setclock=yes\n    LIBS=\"$LIBS -lpthread\"\n  fi\nfi\nprint_config \"pthread_condattr_setclock()\" \"$pthread_condattr_setclock\"\n\n##########################################\n# pthread_sigmask() probe\nif test \"$pthread_sigmask\" != \"yes\" ; then\n  pthread_sigmask=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <stddef.h> /* NULL */\n#include <signal.h> /* pthread_sigmask() */\nint main(void)\n{\n  sigset_t sigmask;\n  return pthread_sigmask(0, NULL, &sigmask);\n}\nEOF\nif compile_prog \"\" \"$LIBS\" \"pthread_sigmask\" ; then\n  pthread_sigmask=yes\nelif compile_prog \"\" \"$LIBS -lpthread\" \"pthread_sigmask\" ; then\n  pthread_sigmask=yes\n  LIBS=\"$LIBS -lpthread\"\nfi\nprint_config \"pthread_sigmask()\" \"$pthread_sigmask\"\n\n##########################################\n# pthread_getaffinity_np() probe\nif test \"$pthread_getaffinity\" != \"yes\" ; then\n  pthread_getaffinity=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <stddef.h> /* NULL */\n#include <signal.h> /* pthread_sigmask() */\n#include <pthread.h>\nint main(void)\n{\n  cpu_set_t set;\n  return pthread_getaffinity_np(pthread_self(), sizeof(set), &set);\n}\nEOF\nif compile_prog \"\" \"$LIBS\" \"pthread_getaffinity\" ; then\n  pthread_getaffinity=\"yes\"\nelif compile_prog \"\" \"$LIBS -lpthread\" \"pthread_getaffinity\" ; then\n  pthread_getaffinity=\"yes\"\n  LIBS=\"$LIBS -lpthread\"\nfi\nprint_config \"pthread_getaffinity_np()\" \"$pthread_getaffinity\"\n\n##########################################\n# solaris aio probe\nif test \"$solaris_aio\" != \"yes\" ; then\n  solaris_aio=\"no\"\nfi\ncat > $TMPC <<EOF\n#include <sys/types.h>\n#include <sys/asynch.h>\n#include <unistd.h>\nint main(void)\n{\n  aio_result_t res;\n  return aioread(0, NULL, 0, 0, SEEK_SET, &res);\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-laio\" \"solarisaio\" ; then\n  solaris_aio=yes\n  LIBS=\"-laio $LIBS\"\nfi\nprint_config \"Solaris AIO support\" \"$solaris_aio\"\n\n##########################################\n# __sync_fetch_and_add test\nif test \"$sfaa\" != \"yes\" ; then\n  sfaa=\"no\"\nfi\ncat > $TMPC << EOF\n#include <inttypes.h>\nstatic int sfaa(uint64_t *ptr)\n{\n  return __sync_fetch_and_add(ptr, 0);\n}\n\nint main(int argc, char **argv)\n{\n  uint64_t val = 42;\n  sfaa(&val);\n  return val;\n}\nEOF\nif compile_prog \"\" \"\" \"__sync_fetch_and_add()\" ; then\n    sfaa=\"yes\"\nfi\nprint_config \"__sync_fetch_and_add\" \"$sfaa\"\n\n##########################################\n# __sync_synchronize() test\nif test \"$sync_sync\" != \"yes\" ; then\n  sync_sync=\"no\"\nfi\ncat > $TMPC << EOF\n#include <inttypes.h>\n\nint main(int argc, char **argv)\n{\n  __sync_synchronize();\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"__sync_synchronize()\" ; then\n    sync_sync=\"yes\"\nfi\nprint_config \"__sync_synchronize\" \"$sync_sync\"\n\n##########################################\n# __sync_val_compare_and_swap() test\nif test \"$cmp_swap\" != \"yes\" ; then\n  cmp_swap=\"no\"\nfi\ncat > $TMPC << EOF\n#include <inttypes.h>\n\nint main(int argc, char **argv)\n{\n  int x = 0;\n  return __sync_val_compare_and_swap(&x, 1, 2);\n}\nEOF\nif compile_prog \"\" \"\" \"__sync_val_compare_and_swap()\" ; then\n    cmp_swap=\"yes\"\nfi\nprint_config \"__sync_val_compare_and_swap\" \"$cmp_swap\"\n\n##########################################\n# libverbs probe\nif test \"$libverbs\" != \"yes\" ; then\n  libverbs=\"no\"\nfi\ncat > $TMPC << EOF\n#include <infiniband/verbs.h>\nint main(int argc, char **argv)\n{\n  struct ibv_pd *pd = ibv_alloc_pd(NULL);\n  return pd != NULL;\n}\nEOF\nif test \"$disable_rdma\" != \"yes\" && compile_prog \"\" \"-libverbs -lnl-3 -lnl-route-3\" \"libverbs\" ; then\n    libverbs=\"yes\"\n    LIBS=\"-libverbs -lnl-3 -lnl-route-3 $LIBS\"\nfi\nprint_config \"libverbs\" \"$libverbs\"\n\n##########################################\n# rdmacm probe\nif test \"$rdmacm\" != \"yes\" ; then\n  rdmacm=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <rdma/rdma_cma.h>\nint main(int argc, char **argv)\n{\n  rdma_destroy_qp(NULL);\n  return 0;\n}\nEOF\nif test \"$disable_rdma\" != \"yes\" && compile_prog \"\" \"-lrdmacm -lnl-3 -lnl-route-3\" \"rdma\"; then\n    rdmacm=\"yes\"\n    LIBS=\"-libverbs -lnl-3 -lnl-route-3 $LIBS\"\nfi\nprint_config \"rdmacm\" \"$rdmacm\"\n\n##########################################\n# asprintf() and vasprintf() probes\nif test \"$have_asprintf\" != \"yes\" ; then\n  have_asprintf=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n\nint main(int argc, char **argv)\n{\n  char *buf;\n  return asprintf(&buf, \"%s\", \"str\") == 0;\n}\nEOF\nif compile_prog \"\" \"\" \"have_asprintf\"; then\n    have_asprintf=\"yes\"\nfi\nprint_config \"asprintf()\" \"$have_asprintf\"\n\nif test \"$have_vasprintf\" != \"yes\" ; then\n  have_vasprintf=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <stdarg.h>\n\nint main(int argc, char **argv)\n{\n  va_list ap;\n  char *buf;\n  return vasprintf(&buf, \"%s\", ap) == 0;\n}\nEOF\nif compile_prog \"\" \"\" \"have_vasprintf\"; then\n    have_vasprintf=\"yes\"\nfi\nprint_config \"vasprintf()\" \"$have_vasprintf\"\n\n##########################################\n# Linux fallocate probe\nif test \"$linux_fallocate\" != \"yes\" ; then\n  linux_fallocate=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <fcntl.h>\n#include <linux/falloc.h>\nint main(int argc, char **argv)\n{\n  int r = fallocate(0, FALLOC_FL_KEEP_SIZE, 0, 1024);\n  return r;\n}\nEOF\nif compile_prog \"\" \"\" \"linux_fallocate\"; then\n    linux_fallocate=\"yes\"\nfi\nprint_config \"Linux fallocate\" \"$linux_fallocate\"\n\n##########################################\n# POSIX fadvise probe\nif test \"$posix_fadvise\" != \"yes\" ; then\n  posix_fadvise=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <fcntl.h>\nint main(int argc, char **argv)\n{\n  int r = posix_fadvise(0, 0, 0, POSIX_FADV_NORMAL);\n  return r;\n}\nEOF\nif compile_prog \"\" \"\" \"posix_fadvise\"; then\n    posix_fadvise=\"yes\"\nfi\nprint_config \"POSIX fadvise\" \"$posix_fadvise\"\n\n##########################################\n# POSIX fallocate probe\nif test \"$posix_fallocate\" != \"yes\" ; then\n  posix_fallocate=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <fcntl.h>\nint main(int argc, char **argv)\n{\n  int r = posix_fallocate(0, 0, 1024);\n  return r;\n}\nEOF\nif compile_prog \"\" \"\" \"posix_fallocate\"; then\n    posix_fallocate=\"yes\"\nfi\nprint_config \"POSIX fallocate\" \"$posix_fallocate\"\n\n##########################################\n# sched_set/getaffinity 2 or 3 argument test\nif test \"$linux_2arg_affinity\" != \"yes\" ; then\n  linux_2arg_affinity=\"no\"\nfi\nif test \"$linux_3arg_affinity\" != \"yes\" ; then\n  linux_3arg_affinity=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sched.h>\nint main(int argc, char **argv)\n{\n  cpu_set_t mask = { };\n\n  return sched_setaffinity(0, sizeof(mask), &mask);\n}\nEOF\nif compile_prog \"\" \"\" \"sched_setaffinity(,,)\"; then\n  linux_3arg_affinity=\"yes\"\nelse\n  cat > $TMPC << EOF\n#include <sched.h>\nint main(int argc, char **argv)\n{\n  cpu_set_t mask = { };\n\n  return sched_setaffinity(0, &mask);\n}\nEOF\n  if compile_prog \"\" \"\" \"sched_setaffinity(,)\"; then\n    linux_2arg_affinity=\"yes\"\n  fi\nfi\nprint_config \"sched_setaffinity(3 arg)\" \"$linux_3arg_affinity\"\nprint_config \"sched_setaffinity(2 arg)\" \"$linux_2arg_affinity\"\n\n##########################################\n# clock_gettime probe\nif test \"$clock_gettime\" != \"yes\" ; then\n  clock_gettime=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <time.h>\nint main(int argc, char **argv)\n{\n  struct timespec ts;\n\n  return clock_gettime(0, &ts);\n}\nEOF\nif compile_prog \"\" \"\" \"clock_gettime\"; then\n    clock_gettime=\"yes\"\nelif compile_prog \"\" \"-lrt\" \"clock_gettime\"; then\n    clock_gettime=\"yes\"\n    LIBS=\"-lrt $LIBS\"\nfi\nprint_config \"clock_gettime\" \"$clock_gettime\"\n\n##########################################\n# CLOCK_MONOTONIC probe\nif test \"$clock_monotonic\" != \"yes\" ; then\n  clock_monotonic=\"no\"\nfi\nif test \"$clock_gettime\" = \"yes\" ; then\n  cat > $TMPC << EOF\n#include <stdio.h>\n#include <time.h>\nint main(int argc, char **argv)\n{\n  struct timespec ts;\n\n  return clock_gettime(CLOCK_MONOTONIC, &ts);\n}\nEOF\n  if compile_prog \"\" \"$LIBS\" \"clock monotonic\"; then\n      clock_monotonic=\"yes\"\n  fi\nfi\nprint_config \"CLOCK_MONOTONIC\" \"$clock_monotonic\"\n\n##########################################\n# clockid_t probe\nif test \"$clockid_t\" != \"yes\" ; then\n  clockid_t=\"no\"\nfi\ncat > $TMPC << EOF\n#include <time.h>\n#include <string.h>\nint main(int argc, char **argv)\n{\n  volatile clockid_t cid;\n  memset((void*)&cid, 0, sizeof(cid));\n  return 0;\n}\nEOF\nif compile_prog \"\" \"$LIBS\" \"clockid_t\"; then\n  clockid_t=\"yes\"\nfi\nprint_config \"clockid_t\" \"$clockid_t\"\n\n##########################################\n# gettimeofday() probe\nif test \"$gettimeofday\" != \"yes\" ; then\n  gettimeofday=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sys/time.h>\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n  struct timeval tv;\n  return gettimeofday(&tv, NULL);\n}\nEOF\nif compile_prog \"\" \"\" \"gettimeofday\"; then\n    gettimeofday=\"yes\"\nfi\nprint_config \"gettimeofday\" \"$gettimeofday\"\n\n##########################################\n# fdatasync() probe\nif test \"$fdatasync\" != \"yes\" ; then\n  fdatasync=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <unistd.h>\nint main(int argc, char **argv)\n{\n  return fdatasync(0);\n}\nEOF\nif compile_prog \"\" \"\" \"fdatasync\"; then\n  fdatasync=\"yes\"\nfi\nprint_config \"fdatasync\" \"$fdatasync\"\n\n##########################################\n# pipe() probe\nif test \"$pipe\" != \"yes\" ; then\n  pipe=\"no\"\nfi\ncat > $TMPC << EOF\n#include <unistd.h>\nint main(int argc, char **argv)\n{\n  int fd[2];\n  return pipe(fd);\n}\nEOF\nif compile_prog \"\" \"\" \"pipe\"; then\n  pipe=\"yes\"\nfi\nprint_config \"pipe()\" \"$pipe\"\n\n##########################################\n# pipe2() probe\nif test \"$pipe2\" != \"yes\" ; then\n  pipe2=\"no\"\nfi\ncat > $TMPC << EOF\n#include <unistd.h>\nint main(int argc, char **argv)\n{\n  int fd[2];\n  return pipe2(fd, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"pipe2\"; then\n  pipe2=\"yes\"\nfi\nprint_config \"pipe2()\" \"$pipe2\"\n\n##########################################\n# pread() probe\nif test \"$pread\" != \"yes\" ; then\n  pread=\"no\"\nfi\ncat > $TMPC << EOF\n#include <unistd.h>\nint main(int argc, char **argv)\n{\n  return pread(0, NULL, 0, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"pread\"; then\n  pread=\"yes\"\nfi\nprint_config \"pread()\" \"$pread\"\n\n##########################################\n# sync_file_range() probe\nif test \"$sync_file_range\" != \"yes\" ; then\n  sync_file_range=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <linux/fs.h>\nint main(int argc, char **argv)\n{\n  unsigned int flags = SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE |\n\t\t\tSYNC_FILE_RANGE_WAIT_AFTER;\n  return sync_file_range(0, 0, 0, flags);\n}\nEOF\nif compile_prog \"\" \"\" \"sync_file_range\"; then\n  sync_file_range=\"yes\"\nfi\nprint_config \"sync_file_range\" \"$sync_file_range\"\n\n##########################################\n# ASharedMemory_create() probe\nif test \"$ASharedMemory_create\" != \"yes\" ; then\n  ASharedMemory_create=\"no\"\nfi\ncat > $TMPC << EOF\n#include <android/sharedmem.h>\nint main(int argc, char **argv)\n{\n  return ASharedMemory_create(\"\", 0);\n}\nEOF\nif compile_prog \"\" \"\" \"ASharedMemory_create\"; then\n  ASharedMemory_create=\"yes\"\nfi\nprint_config \"ASharedMemory_create\" \"$ASharedMemory_create\"\n\n##########################################\n# ext4 move extent probe\nif test \"$ext4_me\" != \"yes\" ; then\n  ext4_me=\"no\"\nfi\ncat > $TMPC << EOF\n#include <fcntl.h>\n#include <sys/ioctl.h>\nint main(int argc, char **argv)\n{\n  struct move_extent me;\n  return ioctl(0, EXT4_IOC_MOVE_EXT, &me);\n}\nEOF\nif compile_prog \"\" \"\" \"ext4 move extent\" ; then\n  ext4_me=\"yes\"\nelif test $targetos = \"Linux\" ; then\n  # On Linux, just default to it on and let it error at runtime if we really\n  # don't have it. None of my updated systems have it defined, but it does\n  # work. Takes a while to bubble back.\n  ext4_me=\"yes\"\nfi\nprint_config \"EXT4 move extent\" \"$ext4_me\"\n\n##########################################\n# splice probe\nif test \"$linux_splice\" != \"yes\" ; then\n  linux_splice=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <fcntl.h>\nint main(int argc, char **argv)\n{\n  return splice(0, NULL, 0, NULL, 0, SPLICE_F_NONBLOCK);\n}\nEOF\nif compile_prog \"\" \"\" \"linux splice\"; then\n  linux_splice=\"yes\"\nfi\nprint_config \"Linux splice(2)\" \"$linux_splice\"\n\n##########################################\n# libnuma probe\nif test \"$libnuma\" != \"yes\" ; then\n  libnuma=\"no\"\nfi\ncat > $TMPC << EOF\n#include <numa.h>\nint main(int argc, char **argv)\n{\n  return numa_available();\n}\nEOF\nif test \"$disable_numa\" != \"yes\"  && compile_prog \"\" \"-lnuma\" \"libnuma\"; then\n  libnuma=\"yes\"\n  LIBS=\"-lnuma $LIBS\"\nfi\nprint_config \"libnuma\" \"$libnuma\"\n\n##########################################\n# libnuma 2.x version API, initialize with \"no\" only if $libnuma is set to \"yes\"\nif test \"$libnuma\" = \"yes\" ; then\nlibnuma_v2=\"no\"\ncat > $TMPC << EOF\n#include <numa.h>\nint main(int argc, char **argv)\n{\n  struct bitmask *mask = numa_parse_nodestring(NULL);\n  return mask->size == 0;\n}\nEOF\nif compile_prog \"\" \"\" \"libnuma api\"; then\n  libnuma_v2=\"yes\"\nfi\nprint_config \"libnuma v2\" \"$libnuma_v2\"\nfi\n\n##########################################\n# strsep() probe\nif test \"$strsep\" != \"yes\" ; then\n  strsep=\"no\"\nfi\ncat > $TMPC << EOF\n#include <string.h>\nint main(int argc, char **argv)\n{\n  static char *string = \"This is a string\";\n  strsep(&string, \"needle\");\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"strsep\"; then\n  strsep=\"yes\"\nfi\nprint_config \"strsep\" \"$strsep\"\n\n##########################################\n# strcasestr() probe\nif test \"$strcasestr\" != \"yes\" ; then\n  strcasestr=\"no\"\nfi\ncat > $TMPC << EOF\n#include <string.h>\nint main(int argc, char **argv)\n{\n  return strcasestr(argv[0], argv[1]) != NULL;\n}\nEOF\nif compile_prog \"\" \"\" \"strcasestr\"; then\n  strcasestr=\"yes\"\nfi\nprint_config \"strcasestr\" \"$strcasestr\"\n\n##########################################\n# strlcat() probe\nif test \"$strlcat\" != \"yes\" ; then\n  strlcat=\"no\"\nfi\ncat > $TMPC << EOF\n#include <string.h>\nint main(int argc, char **argv)\n{\n  static char dst[64];\n  static char *string = \"This is a string\";\n  memset(dst, 0, sizeof(dst));\n  strlcat(dst, string, sizeof(dst));\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"strlcat\"; then\n  strlcat=\"yes\"\nfi\nprint_config \"strlcat\" \"$strlcat\"\n\n##########################################\n# getopt_long_only() probe\nif test \"$getopt_long_only\" != \"yes\" ; then\n  getopt_long_only=\"no\"\nfi\ncat > $TMPC << EOF\n#include <unistd.h>\n#include <stdio.h>\n#include <getopt.h>\nint main(int argc, char **argv)\n{\n  int c = getopt_long_only(argc, argv, \"\", NULL, NULL);\n  return c;\n}\nEOF\nif compile_prog \"\" \"\" \"getopt_long_only\"; then\n  getopt_long_only=\"yes\"\nfi\nprint_config \"getopt_long_only()\" \"$getopt_long_only\"\n\n##########################################\n# inet_aton() probe\nif test \"$inet_aton\" != \"yes\" ; then\n  inet_aton=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#else\n#include <sys/socket.h>\n#include <arpa/inet.h>\n#endif\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n  struct in_addr in;\n  return inet_aton(NULL, &in);\n}\nEOF\nif compile_prog \"\" \"\" \"inet_aton\"; then\n  inet_aton=\"yes\"\nfi\nprint_config \"inet_aton\" \"$inet_aton\"\n\n##########################################\n# socklen_t probe\nif test \"$socklen_t\" != \"yes\" ; then\n  socklen_t=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#else\n#include <sys/socket.h>\n#endif\nint main(int argc, char **argv)\n{\n  socklen_t len = 0;\n  return len;\n}\nEOF\nif compile_prog \"\" \"\" \"socklen_t\"; then\n  socklen_t=\"yes\"\nfi\nprint_config \"socklen_t\" \"$socklen_t\"\n\n##########################################\n# Whether or not __thread is supported for TLS\nif test \"$tls_thread\" != \"yes\" ; then\n  tls_thread=\"no\"\nfi\nif test \"$tls_check\" != \"no\"; then\n  cat > $TMPC << EOF\n#include <stdio.h>\nstatic __thread int ret;\nint main(int argc, char **argv)\n{\n  return ret;\n}\nEOF\nif compile_prog \"\" \"\" \"__thread\"; then\n  tls_thread=\"yes\"\nfi\nfi\nprint_config \"__thread\" \"$tls_thread\"\n\n##########################################\n# Check if we have required gtk/glib support for gfio\nif test \"$gfio\" != \"yes\" ; then\n  gfio=\"no\"\nfi\nif test \"$gfio_check\" = \"yes\" ; then\n  cat > $TMPC << EOF\n#include <glib.h>\n#include <cairo.h>\n#include <gtk/gtk.h>\nint main(void)\n{\n  gdk_threads_enter();\n  gdk_threads_leave();\n\n  return GTK_CHECK_VERSION(2, 18, 0) ? 0 : 1; /* 0 on success */\n}\nEOF\nGTK_CFLAGS=$(pkg-config --cflags gtk+-2.0 gthread-2.0)\nORG_LDFLAGS=$LDFLAGS\nLDFLAGS=$(echo $LDFLAGS | sed s/\"-static\"//g)\nif test \"$?\" != \"0\" ; then\n  echo \"configure: gtk and gthread not found\"\n  exit 1\nfi\nGTK_LIBS=$(pkg-config --libs gtk+-2.0 gthread-2.0)\nif test \"$?\" != \"0\" ; then\n  echo \"configure: gtk and gthread not found\"\n  exit 1\nfi\ngfio=\"yes\"\nif check_min_lib_version gtk+-2.0 2.18.0 \"gfio\"; then\n  if compile_prog \"$GTK_CFLAGS\" \"$GTK_LIBS\" \"gfio\" ; then\n    GFIO_LIBS=\"$LIBS $GTK_LIBS\"\n    CFLAGS=\"$CFLAGS $GTK_CFLAGS\"\n  else\n    echo \"Please install gtk and gdk libraries\"\n    gfio=\"no\"\n  fi\nelse\n  gfio=\"no\"\nfi\nLDFLAGS=$ORG_LDFLAGS\nfi\n\nif test \"$gfio_check\" = \"yes\" ; then\n  print_config \"gtk 2.18 or higher\" \"$gfio\"\nfi\n\n##########################################\n# Check whether we have getrusage(RUSAGE_THREAD)\nif test \"$rusage_thread\" != \"yes\" ; then\n  rusage_thread=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sys/time.h>\n#include <sys/resource.h>\nint main(int argc, char **argv)\n{\n  struct rusage ru;\n  getrusage(RUSAGE_THREAD, &ru);\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"RUSAGE_THREAD\"; then\n  rusage_thread=\"yes\"\nfi\nprint_config \"RUSAGE_THREAD\" \"$rusage_thread\"\n\n##########################################\n# Check whether we have SCHED_IDLE\nif test \"$sched_idle\" != \"yes\" ; then\n  sched_idle=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sched.h>\nint main(int argc, char **argv)\n{\n  struct sched_param p = { };\n\n  return sched_setscheduler(0, SCHED_IDLE, &p);\n}\nEOF\nif compile_prog \"\" \"\" \"SCHED_IDLE\"; then\n  sched_idle=\"yes\"\nfi\nprint_config \"SCHED_IDLE\" \"$sched_idle\"\n\n##########################################\n# Check whether we have TCP_NODELAY\nif test \"$tcp_nodelay\" != \"yes\" ; then\n  tcp_nodelay=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#else\n#include <stdio.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/tcp.h>\n#endif\nint main(int argc, char **argv)\n{\n  return getsockopt(0, 0, TCP_NODELAY, NULL, NULL);\n}\nEOF\nif compile_prog \"\" \"\" \"TCP_NODELAY\"; then\n  tcp_nodelay=\"yes\"\nelif compile_prog \"\" \"-lws2_32\" \"TCP_NODELAY\"; then\n  tcp_nodelay=\"yes\"\n  LIBS=\"$LIBS -lws2_32\"\nfi\nprint_config \"TCP_NODELAY\" \"$tcp_nodelay\"\n\n##########################################\n# Check whether we have vsock\nif test \"$vsock\" != \"yes\" ; then\n  vsock=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <linux/vm_sockets.h>\nint main(int argc, char **argv)\n{\n  return socket(AF_VSOCK, SOCK_STREAM, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"vsock\"; then\n  vsock=\"yes\"\nfi\nprint_config \"vsock\" \"$vsock\"\n\n##########################################\n# Check whether we have SO_SNDBUF\nif test \"$window_size\" != \"yes\" ; then\n  window_size=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#else\n#include <stdio.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/tcp.h>\n#endif\nint main(int argc, char **argv)\n{\n  setsockopt(0, SOL_SOCKET, SO_SNDBUF, NULL, 0);\n  setsockopt(0, SOL_SOCKET, SO_RCVBUF, NULL, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"SO_SNDBUF\"; then\n  window_size=\"yes\"\nelif compile_prog \"\" \"-lws2_32\" \"SO_SNDBUF\"; then\n  window_size=\"yes\"\n  LIBS=\"$LIBS -lws2_32\"\nfi\nprint_config \"Net engine window_size\" \"$window_size\"\n\n##########################################\n# Check whether we have TCP_MAXSEG\nif test \"$mss\" != \"yes\" ; then\n  mss=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#else\n#include <stdio.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/tcp.h>\n#include <arpa/inet.h>\n#include <netinet/in.h>\n#endif\nint main(int argc, char **argv)\n{\n  return setsockopt(0, IPPROTO_TCP, TCP_MAXSEG, NULL, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"TCP_MAXSEG\"; then\n  mss=\"yes\"\nelif compile_prog \"\" \"-lws2_32\" \"TCP_MAXSEG\"; then\n  mss=\"yes\"\n  LIBS=\"$LIBS -lws2_32\"\nfi\nprint_config \"TCP_MAXSEG\" \"$mss\"\n\n##########################################\n# Check whether we have RLIMIT_MEMLOCK\nif test \"$rlimit_memlock\" != \"yes\" ; then\n  rlimit_memlock=\"no\"\nfi\ncat > $TMPC << EOF\n#include <sys/time.h>\n#include <sys/resource.h>\nint main(int argc, char **argv)\n{\n  struct rlimit rl;\n  return getrlimit(RLIMIT_MEMLOCK, &rl);\n}\nEOF\nif compile_prog \"\" \"\" \"RLIMIT_MEMLOCK\"; then\n  rlimit_memlock=\"yes\"\nfi\nprint_config \"RLIMIT_MEMLOCK\" \"$rlimit_memlock\"\n\n##########################################\n# Check whether we have pwritev/preadv\nif test \"$pwritev\" != \"yes\" ; then\n  pwritev=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <sys/uio.h>\nint main(int argc, char **argv)\n{\n  struct iovec iov[1] = { };\n\n  return pwritev(0, iov, 1, 0) + preadv(0, iov, 1, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"pwritev\"; then\n  pwritev=\"yes\"\nfi\nprint_config \"pwritev/preadv\" \"$pwritev\"\n\n##########################################\n# Check whether we have pwritev2/preadv2\nif test \"$pwritev2\" != \"yes\" ; then\n  pwritev2=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <sys/uio.h>\nint main(int argc, char **argv)\n{\n  struct iovec iov[1] = { };\n\n  return pwritev2(0, iov, 1, 0, 0) + preadv2(0, iov, 1, 0, 0);\n}\nEOF\nif compile_prog \"\" \"\" \"pwritev2\"; then\n  pwritev2=\"yes\"\nfi\nprint_config \"pwritev2/preadv2\" \"$pwritev2\"\n\n##########################################\n# Check whether we have the required functions for ipv6\nif test \"$ipv6\" != \"yes\" ; then\n  ipv6=\"no\"\nfi\ncat > $TMPC << EOF\n#ifdef _WIN32\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#else\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <netdb.h>\n#endif\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n  struct addrinfo hints = { };\n  struct in6_addr addr = in6addr_any;\n  int ret;\n\n  ret = getaddrinfo(NULL, NULL, &hints, NULL);\n  freeaddrinfo(NULL);\n  printf(\"%s %d\\n\", gai_strerror(ret), addr.s6_addr[0]);\n\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"ipv6\"; then\n  ipv6=\"yes\"\nfi\nprint_config \"IPv6 helpers\" \"$ipv6\"\n\n##########################################\n# check for http\nif test \"$http\" != \"yes\" ; then\n  http=\"no\"\nfi\n# check for openssl >= 1.1.0, which uses an opaque HMAC_CTX pointer\ncat > $TMPC << EOF\n#include <curl/curl.h>\n#include <openssl/hmac.h>\n\nint main(int argc, char **argv)\n{\n  CURL *curl;\n  HMAC_CTX *ctx;\n\n  curl = curl_easy_init();\n  curl_easy_cleanup(curl);\n\n  ctx = HMAC_CTX_new();\n  HMAC_CTX_reset(ctx);\n  HMAC_CTX_free(ctx);\n  return 0;\n}\nEOF\n# openssl < 1.1.0 uses the HMAC_CTX type directly\ncat > $TMPC2 << EOF\n#include <curl/curl.h>\n#include <openssl/hmac.h>\n\nint main(int argc, char **argv)\n{\n  CURL *curl;\n  HMAC_CTX ctx;\n\n  curl = curl_easy_init();\n  curl_easy_cleanup(curl);\n\n  HMAC_CTX_init(&ctx);\n  HMAC_CTX_cleanup(&ctx);\n  return 0;\n}\nEOF\nif test \"$disable_http\" != \"yes\"; then\n  HTTP_LIBS=\"-lcurl -lssl -lcrypto\"\n  if compile_prog \"\" \"$HTTP_LIBS\" \"curl-new-ssl\"; then\n    output_sym \"CONFIG_HAVE_OPAQUE_HMAC_CTX\"\n    http=\"yes\"\n  elif mv $TMPC2 $TMPC && compile_prog \"\" \"$HTTP_LIBS\" \"curl-old-ssl\"; then\n    http=\"yes\"\n  fi\nfi\nprint_config \"http engine\" \"$http\"\n\n##########################################\n# check for rados\nif test \"$rados\" != \"yes\" ; then\n  rados=\"no\"\nfi\ncat > $TMPC << EOF\n#include <rados/librados.h>\n\nint main(int argc, char **argv)\n{\n  rados_t cluster;\n  rados_ioctx_t io_ctx;\n  const char cluster_name[] = \"ceph\";\n  const char user_name[] = \"client.admin\";\n  const char pool[] = \"rados\";\n\n  /* The rados_create2 signature required was only introduced in ceph 0.65 */\n  rados_create2(&cluster, cluster_name, user_name, 0);\n  rados_ioctx_create(cluster, pool, &io_ctx);\n\n  return 0;\n}\nEOF\nif test \"$disable_rados\" != \"yes\"  && compile_prog \"\" \"-lrados\" \"rados\"; then\n  rados=\"yes\"\nfi\nprint_config \"Rados engine\" \"$rados\"\n\n##########################################\n# check for rbd\nif test \"$rbd\" != \"yes\" ; then\n  rbd=\"no\"\nfi\ncat > $TMPC << EOF\n#include <rbd/librbd.h>\n\nint main(int argc, char **argv)\n{\n  rados_t cluster;\n  rados_ioctx_t io_ctx;\n  const char cluster_name[] = \"ceph\";\n  const char user_name[] = \"client.admin\";\n  const char pool[] = \"rbd\";\n  int major, minor, extra;\n\n  rbd_version(&major, &minor, &extra);\n  /* The rados_create2 signature required was only introduced in ceph 0.65 */\n  rados_create2(&cluster, cluster_name, user_name, 0);\n  rados_ioctx_create(cluster, pool, &io_ctx);\n\n  return 0;\n}\nEOF\nif test \"$disable_rbd\" != \"yes\"  && compile_prog \"\" \"-lrbd -lrados\" \"rbd\"; then\n  rbd=\"yes\"\nfi\nprint_config \"Rados Block Device engine\" \"$rbd\"\n\n##########################################\n# check for rbd_poll\nif test \"$rbd_poll\" != \"yes\" ; then\n  rbd_poll=\"no\"\nfi\nif test \"$rbd\" = \"yes\"; then\ncat > $TMPC << EOF\n#include <rbd/librbd.h>\n#include <sys/eventfd.h>\n\nint main(int argc, char **argv)\n{\n  rbd_image_t image;\n  rbd_completion_t comp;\n\n  int fd = eventfd(0, EFD_NONBLOCK);\n  rbd_set_image_notification(image, fd, EVENT_TYPE_EVENTFD);\n  rbd_poll_io_events(image, comp, 1);\n\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-lrbd -lrados\" \"rbd\"; then\n  rbd_poll=\"yes\"\nfi\nprint_config \"rbd_poll\" \"$rbd_poll\"\nfi\n\n##########################################\n# check for rbd_invalidate_cache()\nif test \"$rbd_inval\" != \"yes\" ; then\n  rbd_inval=\"no\"\nfi\nif test \"$rbd\" = \"yes\"; then\ncat > $TMPC << EOF\n#include <rbd/librbd.h>\n\nint main(int argc, char **argv)\n{\n  rbd_image_t image;\n\n  return rbd_invalidate_cache(image);\n}\nEOF\nif compile_prog \"\" \"-lrbd -lrados\" \"rbd\"; then\n  rbd_inval=\"yes\"\nfi\nprint_config \"rbd_invalidate_cache\" \"$rbd_inval\"\nfi\n\n##########################################\n# Check whether we have setvbuf\nif test \"$setvbuf\" != \"yes\" ; then\n  setvbuf=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n  FILE *f = NULL;\n  char buf[80];\n  setvbuf(f, buf, _IOFBF, sizeof(buf));\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"setvbuf\"; then\n  setvbuf=\"yes\"\nfi\nprint_config \"setvbuf\" \"$setvbuf\"\n\n##########################################\n# check for gfapi\nif test \"$gfapi\" != \"yes\" ; then\n  gfapi=\"no\"\nfi\ncat > $TMPC << EOF\n#include <glusterfs/api/glfs.h>\n\nint main(int argc, char **argv)\n{\n  glfs_t *g = glfs_new(\"foo\");\n\n  return 0;\n}\nEOF\nif test \"$disable_gfapi\" != \"yes\"  && compile_prog \"\" \"-lgfapi -lglusterfs\" \"gfapi\"; then\n  gfapi=\"yes\"\nfi\nprint_config \"Gluster API engine\" \"$gfapi\"\n\n##########################################\n# check for gfapi fadvise support, initialize with \"no\" only if $gfapi is set to \"yes\"\nif test \"$gfapi\" = \"yes\" ; then\ngf_fadvise=\"no\"\ncat > $TMPC << EOF\n#include <glusterfs/api/glfs.h>\n\nint main(int argc, char **argv)\n{\n  struct glfs_fd *fd;\n  int ret = glfs_fadvise(fd, 0, 0, 1);\n\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-lgfapi -lglusterfs\" \"gfapi\"; then\n  gf_fadvise=\"yes\"\nfi\nprint_config \"Gluster API use fadvise\" \"$gf_fadvise\"\nfi\n\n##########################################\n# check for newer gfapi\nif test \"$gfapi\" = \"yes\" ; then\ngf_new=\"no\"\ncat > $TMPC << EOF\n#include <glusterfs/api/glfs.h>\n\nint main(int argc, char **argv)\n{\n  return glfs_fsync(NULL, NULL, NULL) && glfs_ftruncate(NULL, 0, NULL, NULL);\n}\nEOF\nif compile_prog \"\" \"-lgfapi -lglusterfs\" \"gf new api\"; then\n  gf_new=\"yes\"\nfi\nprint_config \"Gluster new API\" \"$gf_new\"\nfi\n\n##########################################\n# check for gfapi trim support\nif test \"$gf_trim\" != \"yes\" ; then\n  gf_trim=\"no\"\nfi\nif test \"$gfapi\" = \"yes\" ; then\ncat > $TMPC << EOF\n#include <glusterfs/api/glfs.h>\n\nint main(int argc, char **argv)\n{\n  return glfs_discard_async(NULL, 0, 0);\n}\nEOF\nif compile_prog \"\" \"-lgfapi -lglusterfs\" \"gf trim\"; then\n  gf_trim=\"yes\"\nfi\nprint_config \"Gluster API trim support\" \"$gf_trim\"\nfi\n\n##########################################\n# Check if we support stckf on s390\nif test \"$s390_z196_facilities\" != \"yes\" ; then\n  s390_z196_facilities=\"no\"\nfi\ncat > $TMPC << EOF\n#define STFLE_BITS_Z196 45 /* various z196 facilities ... */\nint main(int argc, char **argv)\n{\n    /* We want just 1 double word to be returned.  */\n    register unsigned long reg0 asm(\"0\") = 0;\n    unsigned long stfle_bits;\n    asm volatile(\".machine push\"        \"\\n\\t\"\n                 \".machine \\\"z9-109\\\"\"  \"\\n\\t\"\n                 \"stfle %0\"             \"\\n\\t\"\n                 \".machine pop\"         \"\\n\"\n                 : \"=QS\" (stfle_bits), \"+d\" (reg0)\n                 : : \"cc\");\n\n    if ((stfle_bits & (1UL << (63 - STFLE_BITS_Z196))) != 0)\n      return 0;\n    else\n      return -1;\n}\nEOF\nif compile_prog \"\" \"\" \"s390_z196_facilities\"; then\n  $TMPE\n  if [ $? -eq 0 ]; then\n  \ts390_z196_facilities=\"yes\"\n  fi\nfi\nprint_config \"s390_z196_facilities\" \"$s390_z196_facilities\"\n\n##########################################\n# Check if we have required environment variables configured for libhdfs\nif test \"$libhdfs\" = \"yes\" ; then\n  hdfs_conf_error=0\n  if test \"$JAVA_HOME\" = \"\" ; then\n    echo \"configure: JAVA_HOME should be defined to jdk/jvm path\"\n    hdfs_conf_error=1\n  fi\n  if test \"$FIO_LIBHDFS_INCLUDE\" = \"\" ; then\n    echo \"configure: FIO_LIBHDFS_INCLUDE should be defined to libhdfs include path\"\n    hdfs_conf_error=1\n  fi\n  if test \"$FIO_LIBHDFS_LIB\" = \"\" ; then\n    echo \"configure: FIO_LIBHDFS_LIB should be defined to libhdfs library path\"\n    hdfs_conf_error=1\n  fi\n  if test \"$hdfs_conf_error\" = \"1\" ; then\n    feature_not_found \"libhdfs\" \"\"\n  fi\n  FIO_HDFS_CPU=$cpu\n  if test \"$FIO_HDFS_CPU\" = \"x86_64\" ; then\n    FIO_HDFS_CPU=\"amd64\"\n  fi\nfi\nprint_config \"HDFS engine\" \"$libhdfs\"\n\n##########################################\n# Check whether we have MTD\nif test \"$mtd\" != \"yes\" ; then\n  mtd=\"no\"\nfi\ncat > $TMPC << EOF\n#include <string.h>\n#include <mtd/mtd-user.h>\n#include <sys/ioctl.h>\nint main(int argc, char **argv)\n{\n  struct mtd_write_req ops;\n  struct mtd_info_user info;\n  memset(&ops, 0, sizeof(ops));\n  info.type = MTD_MLCNANDFLASH;\n  return ioctl(0, MEMGETINFO, &info);\n}\nEOF\nif compile_prog \"\" \"\" \"mtd\"; then\n  mtd=\"yes\"\nfi\nprint_config \"MTD\" \"$mtd\"\n\n##########################################\n# Check whether we have libpmem\nif test \"$libpmem\" != \"yes\" ; then\n  libpmem=\"no\"\nfi\ncat > $TMPC << EOF\n#include <libpmem.h>\n#include <stdlib.h>\nint main(int argc, char **argv)\n{\n  return pmem_is_pmem(NULL, 0);\n}\nEOF\nif compile_prog \"\" \"-lpmem\" \"libpmem\"; then\n  libpmem=\"yes\"\nfi\nprint_config \"libpmem\" \"$libpmem\"\n\n##########################################\n# Check whether libpmem's version >= 1.5\nif test \"$libpmem1_5\" != \"yes\" ; then\n  libpmem1_5=\"no\"\nfi\nif test \"$libpmem\" = \"yes\"; then\n  cat > $TMPC << EOF\n#include <libpmem.h>\n#include <stdlib.h>\nint main(int argc, char **argv)\n{\n  pmem_memcpy(NULL, NULL, 0, 0);\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"-lpmem\" \"libpmem1_5\"; then\n    libpmem1_5=\"yes\"\n  fi\nfi\nprint_config \"libpmem1_5\" \"$libpmem1_5\"\n\n##########################################\n# Check whether we have libpmem2\nif test \"$libpmem2\" != \"yes\" ; then\n  libpmem2=\"no\"\nfi\ncat > $TMPC << EOF\n#include <libpmem2.h>\nint main(int argc, char **argv)\n{\n  struct pmem2_config *cfg;\n  pmem2_config_new(&cfg);\n  pmem2_config_delete(&cfg);\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-lpmem2\" \"libpmem2\"; then\n  libpmem2=\"yes\"\nfi\nprint_config \"libpmem2\" \"$libpmem2\"\n\n# Choose libpmem-based ioengines\nif test \"$libpmem\" = \"yes\" && test \"$disable_pmem\" = \"no\"; then\n  devdax=\"yes\"\n  if test \"$libpmem1_5\" = \"yes\"; then\n    pmem=\"yes\"\n  fi\nfi\n\n##########################################\n# Report whether dev-dax engine is enabled\nprint_config \"PMDK dev-dax engine\" \"$devdax\"\n\n##########################################\n# Report whether libpmem engine is enabled\nprint_config \"PMDK libpmem engine\" \"$pmem\"\n\n##########################################\n# Check whether we support DDN's IME\nif test \"$libime\" != \"yes\" ; then\n  libime=\"no\"\nfi\ncat > $TMPC << EOF\n#include <ime_native.h>\nint main(int argc, char **argv)\n{\n  int rc;\n  ime_native_init();\n  rc = ime_native_finalize();\n  return 0;\n}\nEOF\nif compile_prog \"-I${ime_path}/include\" \"-L${ime_path}/lib -lim_client\" \"libime\"; then\n  libime=\"yes\"\n  CFLAGS=\"-I${ime_path}/include $CFLAGS\"\n  LDFLAGS=\"-Wl,-rpath ${ime_path}/lib -L${ime_path}/lib $LDFLAGS\"\n  LIBS=\"-lim_client $LIBS\"\nfi\nprint_config \"DDN's Infinite Memory Engine\" \"$libime\"\n\n##########################################\n# Check if we have libiscsi\nif test \"$libiscsi\" != \"no\" ; then\n  if check_min_lib_version libiscsi 1.9.0; then\n    libiscsi=\"yes\"\n    libiscsi_cflags=$(pkg-config --cflags libiscsi)\n    libiscsi_libs=$(pkg-config --libs libiscsi)\n  else\n    libiscsi=\"no\"\n  fi\nfi\nprint_config \"iscsi engine\" \"$libiscsi\"\n\n##########################################\n# Check if we have libnbd (for NBD support)\nif test \"$libnbd\" != \"no\" ; then\n  if check_min_lib_version libnbd 0.9.8; then\n    libnbd=\"yes\"\n    libnbd_cflags=$(pkg-config --cflags libnbd)\n    libnbd_libs=$(pkg-config --libs libnbd)\n  else\n    libnbd=\"no\"\n  fi\nfi\nprint_config \"NBD engine\" \"$libnbd\"\n\n##########################################\n# check for dfs (DAOS File System)\nif test \"$dfs\" != \"no\" ; then\n  cat > $TMPC << EOF\n#include <fcntl.h>\n#include <daos.h>\n#include <daos_fs.h>\n\nint main(int argc, char **argv)\n{\n  daos_handle_t\tpoh;\n  daos_handle_t\tcoh;\n  dfs_t\t\t*dfs;\n\n  (void) dfs_mount(poh, coh, O_RDWR, &dfs);\n\n  return 0;\n}\nEOF\n  if compile_prog \"\" \"-luuid -ldfs -ldaos\" \"dfs\"; then\n    dfs=\"yes\"\n  else\n    dfs=\"no\"\n  fi\nfi\nprint_config \"DAOS File System (dfs) Engine\" \"$dfs\"\n\n##########################################\n# Check if we have libnfs (for userspace nfs support).\nif test \"$libnfs\" != \"no\" ; then\n  if $(pkg-config libnfs > /dev/null 2>&1); then\n    libnfs=\"yes\"\n    libnfs_cflags=$(pkg-config --cflags libnfs)\n    libnfs_libs=$(pkg-config --libs libnfs)\n  else\n    if test \"$libnfs\" = \"yes\" ; then\n      feature_not_found \"libnfs\" \"libnfs\"\n    fi\n    libnfs=\"no\"\n  fi\nfi\nprint_config \"NFS engine\" \"$libnfs\"\n\n##########################################\n# Check if we have lex/yacc available\nyacc=\"no\"\nyacc_is_bison=\"no\"\nlex=\"no\"\narith=\"no\"\nif test \"$disable_lex\" = \"no\" || test -z \"$disable_lex\" ; then\nif test \"$targetos\" != \"SunOS\" ; then\nif has lex; then\n  lex=\"yes\"\nfi\nif has bison; then\n  yacc=\"yes\"\n  yacc_is_bison=\"yes\"\nelif has yacc; then\n  yacc=\"yes\"\nfi\nif test \"$yacc\" = \"yes\" && test \"$lex\" = \"yes\" ; then\n  arith=\"yes\"\nfi\n\nif test \"$arith\" = \"yes\" ; then\ncat > $TMPC << EOF\nextern int yywrap(void);\n\nint main(int argc, char **argv)\n{\n  yywrap();\n  return 0;\n}\nEOF\nif compile_prog \"\" \"-lfl\" \"flex\"; then\n  LIBS=\"-lfl $LIBS\"\nelif compile_prog \"\" \"-ll\" \"lex\"; then\n  LIBS=\"-ll $LIBS\"\nelse\n  arith=\"no\"\nfi\nfi\nfi\nfi\n\n# Check if lex fails using -o\nif test \"$arith\" = \"yes\" ; then\nif test \"$force_no_lex_o\" = \"yes\" ; then\n  lex_use_o=\"no\"\nelse\nif lex -o lex.yy.c exp/expression-parser.l 2> /dev/null; then\n  lex_use_o=\"yes\"\nelse\n  lex_use_o=\"no\"\nfi\nfi\nfi\n\nprint_config \"lex/yacc for arithmetic\" \"$arith\"\n\n##########################################\n# Check whether we have setmntent/getmntent\nif test \"$getmntent\" != \"yes\" ; then\n  getmntent=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <mntent.h>\nint main(int argc, char **argv)\n{\n  FILE *mtab = setmntent(NULL, \"r\");\n  struct mntent *mnt = getmntent(mtab);\n  endmntent(mtab);\n  return mnt != NULL;\n}\nEOF\nif compile_prog \"\" \"\" \"getmntent\"; then\n  getmntent=\"yes\"\nfi\nprint_config \"getmntent\" \"$getmntent\"\n\n##########################################\n# Check whether we have getmntinfo\n# These are originally added for BSDs, but may also work\n# on other operating systems with getmntinfo(3).\n\n# getmntinfo(3) for FreeBSD/DragonFlyBSD/OpenBSD.\n# Note that NetBSD needs -Werror to catch warning as error.\nif test \"$getmntinfo\" != \"yes\" ; then\n  getmntinfo=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <sys/param.h>\n#include <sys/mount.h>\nint main(int argc, char **argv)\n{\n  struct statfs *st;\n  return getmntinfo(&st, MNT_NOWAIT);\n}\nEOF\nif compile_prog \"-Werror\" \"\" \"getmntinfo\"; then\n  getmntinfo=\"yes\"\nfi\nprint_config \"getmntinfo\" \"$getmntinfo\"\n\n# getmntinfo(3) for NetBSD.\nif test \"$getmntinfo_statvfs\" != \"yes\" ; then\n  getmntinfo_statvfs=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdio.h>\n#include <sys/statvfs.h>\nint main(int argc, char **argv)\n{\n  struct statvfs *st;\n  return getmntinfo(&st, MNT_NOWAIT);\n}\nEOF\n# Skip the test if the one with statfs arg is detected.\nif test \"$getmntinfo\" != \"yes\" && compile_prog \"-Werror\" \"\" \"getmntinfo_statvfs\"; then\n  getmntinfo_statvfs=\"yes\"\n  print_config \"getmntinfo_statvfs\" \"$getmntinfo_statvfs\"\nfi\n\n##########################################\n# Check whether we have _Static_assert\nif test \"$static_assert\" != \"yes\" ; then\n  static_assert=\"no\"\nfi\ncat > $TMPC << EOF\n#include <assert.h>\n#include <stdlib.h>\n#include <stddef.h>\n\nstruct foo {\n  int a, b;\n};\n\nint main(int argc, char **argv)\n{\n  _Static_assert(offsetof(struct foo, a) == 0 , \"Check\");\n  return 0 ;\n}\nEOF\nif compile_prog \"\" \"\" \"static_assert\"; then\n    static_assert=\"yes\"\nfi\nprint_config \"Static Assert\" \"$static_assert\"\n\n##########################################\n# Check whether we have bool / stdbool.h\nif test \"$have_bool\" != \"yes\" ; then\n  have_bool=\"no\"\nfi\ncat > $TMPC << EOF\n#include <stdbool.h>\nint main(int argc, char **argv)\n{\n  bool var = true;\n  return var != false;\n}\nEOF\nif compile_prog \"\" \"\" \"bool\"; then\n  have_bool=\"yes\"\nfi\nprint_config \"bool\" \"$have_bool\"\n\n##########################################\n# Check whether we have strndup()\nstrndup=\"no\"\ncat > $TMPC << EOF\n#include <string.h>\n#include <stdlib.h>\nint main(int argc, char **argv)\n{\n  char *res = strndup(\"test string\", 8);\n\n  free(res);\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"strndup\"; then\n  strndup=\"yes\"\nfi\nprint_config \"strndup\" \"$strndup\"\n\n##########################################\n# <valgrind/drd.h> probe\n# Note: presence of <valgrind/drd.h> implies that <valgrind/valgrind.h> is\n# also available but not the other way around.\nif test \"$valgrind_dev\" != \"yes\" ; then\n  valgrind_dev=\"no\"\nfi\ncat > $TMPC << EOF\n#include <valgrind/drd.h>\nint main(int argc, char **argv)\n{\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"valgrind_dev\"; then\n  valgrind_dev=\"yes\"\nfi\nprint_config \"Valgrind headers\" \"$valgrind_dev\"\n\nif test \"$targetos\" = \"Linux\" || test \"$targetos\" = \"Android\"; then\n##########################################\n# <linux/blkzoned.h> probe\nif test \"$linux_blkzoned\" != \"yes\" ; then\n  linux_blkzoned=\"no\"\nfi\ncat > $TMPC << EOF\n#include <linux/blkzoned.h>\nint main(int argc, char **argv)\n{\n  return 0;\n}\nEOF\nif compile_prog \"\" \"\" \"linux_blkzoned\"; then\n  linux_blkzoned=\"yes\"\nfi\nprint_config \"Zoned block device support\" \"$linux_blkzoned\"\n\n##########################################\n# Check BLK_ZONE_REP_CAPACITY\ncat > $TMPC << EOF\n#include <linux/blkzoned.h>\nint main(void)\n{\n  return BLK_ZONE_REP_CAPACITY;\n}\nEOF\nif compile_prog \"\" \"\" \"blkzoned report capacity\"; then\n  output_sym \"CONFIG_HAVE_REP_CAPACITY\"\n  rep_capacity=\"yes\"\nelse\n  rep_capacity=\"no\"\nfi\nprint_config \"Zoned block device capacity\" \"$rep_capacity\"\nfi\n\n##########################################\n# libzbc probe\ncat > $TMPC << EOF\n#include <libzbc/zbc.h>\nint main(int argc, char **argv)\n{\n  struct zbc_device *dev = NULL;\n\n  return zbc_open(\"foo=bar\", O_RDONLY, &dev);\n}\nEOF\nif test \"$libzbc\" != \"no\" ; then\n  if [ -e /usr/include/libzbc/libzbc ]; then\n    # SUSE Linux.\n    CFLAGS=\"$CFLAGS -I/usr/include/libzbc\"\n  fi\n  if compile_prog \"\" \"-lzbc\" \"libzbc\"; then\n    libzbc=\"yes\"\n    if ! check_min_lib_version libzbc 5; then\n      libzbc=\"no\"\n    fi\n  else\n    if test \"$libzbc\" = \"yes\" ; then\n      feature_not_found \"libzbc\" \"libzbc or libzbc/zbc.h\"\n    fi\n    libzbc=\"no\"\n  fi\nfi\nprint_config \"libzbc engine\" \"$libzbc\"\n\nif test \"$targetos\" = \"Linux\" || test \"$targetos\" = \"Android\"; then\n##########################################\n# Check NVME_URING_CMD support\ncat > $TMPC << EOF\n#include <linux/nvme_ioctl.h>\nint main(void)\n{\n  return sizeof(struct nvme_uring_cmd);\n}\nEOF\nif compile_prog \"\" \"\" \"nvme uring cmd\"; then\n  output_sym \"CONFIG_NVME_URING_CMD\"\n  nvme_uring_cmd=\"yes\"\nelse\n  nvme_uring_cmd=\"no\"\nfi\nprint_config \"NVMe uring command support\" \"$nvme_uring_cmd\"\nfi\n\n##########################################\n# Check if we have xnvme\nif test \"$xnvme\" != \"no\" ; then\n  if check_min_lib_version xnvme 0.7.4; then\n    xnvme=\"yes\"\n    xnvme_cflags=$(pkg-config --cflags xnvme)\n    xnvme_libs=$(pkg-config --libs xnvme)\n  else\n    xnvme=\"no\"\n  fi\nfi\nprint_config \"xnvme engine\" \"$xnvme\"\n\nif test \"$targetos\" = \"Linux\" ; then\n##########################################\n# Check ISA-L support\ncat > $TMPC << EOF\n#include <isa-l/crc.h>\n#include <stddef.h>\nint main(void)\n{\n  return crc16_t10dif(0, NULL, 4096);\n}\nEOF\nif test \"$isal\" != \"no\" ; then\n  if compile_prog \"\" \"-lisal\" \"ISAL\"; then\n    isal=\"yes\"\n    LIBS=\"-lisal $LIBS\"\n  else\n    isal=\"no\"\n  fi\nfi\nprint_config \"isal\" \"$isal\"\nfi\n\n##########################################\n# Check if we have libblkio\nif test \"$libblkio\" != \"no\" ; then\n  if check_min_lib_version blkio 1.0.0; then\n    libblkio=\"yes\"\n    libblkio_cflags=$(pkg-config --cflags blkio)\n    libblkio_libs=$(pkg-config --libs blkio)\n  else\n    if test \"$libblkio\" = \"yes\" ; then\n      feature_not_found \"libblkio\" \"libblkio-dev or libblkio-devel\"\n    fi\n    libblkio=\"no\"\n  fi\nfi\nprint_config \"libblkio engine\" \"$libblkio\"\n\n##########################################\n# check march=armv8-a+crc+crypto\nmarch_armv8_a_crc_crypto=\"no\"\nif test \"$cpu\" = \"arm64\" ; then\n  cat > $TMPC <<EOF\n#if __linux__\n#include <arm_acle.h>\n#include <arm_neon.h>\n#include <sys/auxv.h>\n#endif\n\nint main(void)\n{\n  /* Can we also do a runtime probe? */\n#if __linux__\n  return getauxval(AT_HWCAP);\n#elif defined(__APPLE__)\n  return 0;\n#else\n# error \"Don't know how to do runtime probe for ARM CRC32c\"\n#endif\n}\nEOF\n  if compile_prog \"-march=armv8-a+crc+crypto\" \"\" \"ARM CRC32c\"; then\n    march_armv8_a_crc_crypto=\"yes\"\n    CFLAGS=\"$CFLAGS -march=armv8-a+crc+crypto\"\n    march_set=\"yes\"\n  fi\nfi\nprint_config \"march_armv8_a_crc_crypto\" \"$march_armv8_a_crc_crypto\"\n\n##########################################\n# cuda probe\nif test \"$cuda\" != \"no\" ; then\ncat > $TMPC << EOF\n#include <cuda.h>\nint main(int argc, char **argv)\n{\n  return cuInit(0);\n}\nEOF\n  if compile_prog \"\" \"-lcuda\" \"cuda\"; then\n    cuda=\"yes\"\n    LIBS=\"-lcuda $LIBS\"\n  else\n    if test \"$cuda\" = \"yes\" ; then\n      feature_not_found \"cuda\" \"\"\n    fi\n    cuda=\"no\"\n  fi\nfi\nprint_config \"cuda\" \"$cuda\"\n\n##########################################\n# libcufile probe\nif test \"$libcufile\" != \"no\" ; then\ncat > $TMPC << EOF\n#include <cufile.h>\n\nint main(int argc, char* argv[]) {\n   cuFileDriverOpen();\n   return 0;\n}\nEOF\n  if compile_prog \"\" \"-lcuda -lcudart -lcufile -ldl\" \"libcufile\"; then\n    libcufile=\"yes\"\n    LIBS=\"-lcuda -lcudart -lcufile -ldl $LIBS\"\n  else\n    if test \"$libcufile\" = \"yes\" ; then\n      feature_not_found \"libcufile\" \"\"\n    fi\n    libcufile=\"no\"\n  fi\nfi\nprint_config \"libcufile\" \"$libcufile\"\n\n##########################################\n# check for cc -march=native\nbuild_native=\"no\"\ncat > $TMPC << EOF\nint main(int argc, char **argv)\n{\n  return 0;\n}\nEOF\nif test \"$disable_native\" = \"no\" && test \"$disable_opt\" != \"yes\" && \\\n   compile_prog \"-march=native\" \"\" \"march=native\"; then\n  build_native=\"yes\"\nfi\nprint_config \"Build march=native\" \"$build_native\"\n\n##########################################\n# check for -lcunit\nif test \"$cunit\" != \"yes\" ; then\n  cunit=\"no\"\nfi\ncat > $TMPC << EOF\n#include <CUnit/CUnit.h>\n#include <CUnit/Basic.h>\nint main(void)\n{\n  if (CU_initialize_registry() != CUE_SUCCESS)\n    return CU_get_error();\n  CU_basic_set_mode(CU_BRM_VERBOSE);\n  CU_basic_run_tests();\n  CU_cleanup_registry();\n  return CU_get_error();\n}\nEOF\nif compile_prog \"\" \"-lcunit\" \"CUnit\"; then\n  cunit=\"yes\"\nfi\nprint_config \"CUnit\" \"$cunit\"\n\n##########################################\n# check for __kernel_rwf_t\n__kernel_rwf_t=\"no\"\ncat > $TMPC << EOF\n#include <linux/fs.h>\nint main(int argc, char **argv)\n{\n  __kernel_rwf_t x;\n  x = 0;\n  return x;\n}\nEOF\nif compile_prog \"\" \"\" \"__kernel_rwf_t\"; then\n  __kernel_rwf_t=\"yes\"\nfi\nprint_config \"__kernel_rwf_t\" \"$__kernel_rwf_t\"\n\n##########################################\n# check if gcc has -Wimplicit-fallthrough=2\nfallthrough=\"no\"\ncat > $TMPC << EOF\nint main(int argc, char **argv)\n{\n  return 0;\n}\nEOF\nif compile_prog \"-Wimplicit-fallthrough=2\" \"\" \"-Wimplicit-fallthrough=2\"; then\n  fallthrough=\"yes\"\nfi\nprint_config \"-Wimplicit-fallthrough=2\" \"$fallthrough\"\n\n##########################################\n# check if the compiler has -Wno-stringop-concatenation\nno_stringop=\"no\"\ncat > $TMPC << EOF\n#include <stdio.h>\n\nint main(int argc, char **argv)\n{\n\treturn printf(\"%s\\n\", argv[0]);\n}\nEOF\nif compile_prog \"-Wno-stringop-truncation -Werror\" \"\" \"no_stringop\"; then\n  no_stringop=\"yes\"\nfi\nprint_config \"-Wno-stringop-truncation\" \"$no_stringop\"\n\n##########################################\n# check for MADV_HUGEPAGE support\nif test \"$thp\" != \"yes\" ; then\n  thp=\"no\"\nfi\nif test \"$esx\" != \"yes\" ; then\n  cat > $TMPC <<EOF\n#include <sys/mman.h>\nint main(void)\n{\n  return madvise(0, 0x1000, MADV_HUGEPAGE);\n}\nEOF\n  if compile_prog \"\" \"\" \"thp\" ; then\n    thp=yes\n  else\n    if test \"$thp\" = \"yes\" ; then\n      feature_not_found \"Transparent Huge Page\" \"\"\n    fi\n    thp=no\n  fi\nfi\nprint_config \"MADV_HUGEPAGE\" \"$thp\"\n\n##########################################\n# check for gettid()\ngettid=\"no\"\ncat > $TMPC << EOF\n#include <unistd.h>\nint main(int argc, char **argv)\n{\n  return gettid();\n}\nEOF\nif compile_prog \"\" \"\" \"gettid\"; then\n  gettid=\"yes\"\nfi\nprint_config \"gettid\" \"$gettid\"\n\n##########################################\n# check for statx(2) support by libc\nstatx=\"no\"\ncat > $TMPC << EOF\n#include <unistd.h>\n#include <sys/stat.h>\n\nint main(int argc, char **argv)\n{\n\tstruct statx st;\n\treturn statx(-1, *argv, 0, 0, &st);\n}\nEOF\nif compile_prog \"\" \"\" \"statx\"; then\n  statx=\"yes\"\nfi\nprint_config \"statx(2)/libc\" \"$statx\"\n\n##########################################\n# check for statx(2) support by kernel\nstatx_syscall=\"no\"\ncat > $TMPC << EOF\n#include <unistd.h>\n#include <linux/stat.h>\n#include <sys/stat.h>\n#include <sys/syscall.h>\n\nstatic int _statx(int dfd, const char *pathname, int flags, unsigned int mask,\n\t\t  struct statx *buffer)\n{\n\treturn syscall(__NR_statx, dfd, pathname, flags, mask, buffer);\n}\n\nint main(int argc, char **argv)\n{\n\tstruct statx st;\n\treturn _statx(-1, *argv, 0, 0, &st);\n}\nEOF\nif compile_prog \"\" \"\" \"statx_syscall\"; then\n  statx_syscall=\"yes\"\nfi\nprint_config \"statx(2)/syscall\" \"$statx_syscall\"\n\n##########################################\n# check for Windows PDB generation support\nif test \"pdb\" != \"no\" ; then\n  cat > $TMPC <<EOF\nint main(void)\n{\n  return 0;\n}\nEOF\n  if compile_prog \"-g -gcodeview\" \"-fuse-ld=lld -Wl,-pdb,$TMPO\" \"pdb\"; then\n    pdb=yes\n  else\n    if test \"$pdb\" = \"yes\"; then\n      feature_not_found \"PDB\" \"clang and lld\"\n    fi\n    pdb=no\n  fi\nelse\n  pdb=no\nfi\nprint_config \"Windows PDB generation\" \"$pdb\"\n\n##########################################\n# check for timerfd support\ntimerfd_create=\"no\"\nif test \"$esx\" != \"yes\" ; then\ncat > $TMPC << EOF\n#include <sys/time.h>\n#include <sys/timerfd.h>\n\nint main(int argc, char **argv)\n{\n\treturn timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK);\n}\nEOF\n  if compile_prog \"\" \"\" \"timerfd_create\"; then\n    timerfd_create=\"yes\"\n  fi\nfi\nprint_config \"timerfd_create\" \"$timerfd_create\"\n\n#############################################################################\n\nif test \"$wordsize\" = \"64\" ; then\n  output_sym \"CONFIG_64BIT\"\nelif test \"$wordsize\" = \"32\" ; then\n  output_sym \"CONFIG_32BIT\"\nelse\n  fatal \"Unknown wordsize!\"\nfi\nif test \"$bigendian\" = \"yes\" ; then\n  output_sym \"CONFIG_BIG_ENDIAN\"\nelse\n  output_sym \"CONFIG_LITTLE_ENDIAN\"\nfi\nif test \"$zlib\" = \"yes\" ; then\n  output_sym \"CONFIG_ZLIB\"\nfi\nif test \"$libaio\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBAIO\"\n  if test \"$libaio_rw_flags\" = \"yes\" ; then\n    output_sym \"CONFIG_LIBAIO_RW_FLAGS\"\n  fi\nfi\nif test \"$posix_aio\" = \"yes\" ; then\n  output_sym \"CONFIG_POSIXAIO\"\nfi\nif test \"$posix_aio_fsync\" = \"yes\" ; then\n  output_sym \"CONFIG_POSIXAIO_FSYNC\"\nfi\nif test \"$posix_pshared\" = \"yes\" ; then\n  output_sym \"CONFIG_PSHARED\"\nfi\nif test \"$pthread_condattr_setclock\" = \"yes\" ; then\n  output_sym \"CONFIG_PTHREAD_CONDATTR_SETCLOCK\"\nfi\nif test \"$pthread_sigmask\" = \"yes\" ; then\n  output_sym \"CONFIG_PTHREAD_SIGMASK\"\nfi\nif test \"$pthread_getaffinity\" = \"yes\" ; then\n  output_sym \"CONFIG_PTHREAD_GETAFFINITY\"\nfi\nif test \"$have_asprintf\" = \"yes\" ; then\n    output_sym \"CONFIG_HAVE_ASPRINTF\"\nfi\nif test \"$have_vasprintf\" = \"yes\" ; then\n    output_sym \"CONFIG_HAVE_VASPRINTF\"\nfi\nif test \"$linux_fallocate\" = \"yes\" ; then\n  output_sym \"CONFIG_LINUX_FALLOCATE\"\nfi\nif test \"$posix_fallocate\" = \"yes\" ; then\n  output_sym \"CONFIG_POSIX_FALLOCATE\"\nfi\nif test \"$fdatasync\" = \"yes\" ; then\n  output_sym \"CONFIG_FDATASYNC\"\nfi\nif test \"$pipe\" = \"yes\" ; then\n  output_sym \"CONFIG_PIPE\"\nfi\nif test \"$pipe2\" = \"yes\" ; then\n  output_sym \"CONFIG_PIPE2\"\nfi\nif test \"$pread\" = \"yes\" ; then\n  output_sym \"CONFIG_PREAD\"\nfi\nif test \"$sync_file_range\" = \"yes\" ; then\n  output_sym \"CONFIG_SYNC_FILE_RANGE\"\nfi\nif test \"$ASharedMemory_create\" = \"yes\" ; then\n  output_sym \"CONFIG_ASHAREDMEMORY_CREATE\"\nfi\nif test \"$sfaa\" = \"yes\" ; then\n  output_sym \"CONFIG_SFAA\"\nfi\nif test \"$sync_sync\" = \"yes\" ; then\n  output_sym \"CONFIG_SYNC_SYNC\"\nfi\nif test \"$cmp_swap\" = \"yes\" ; then\n  output_sym \"CONFIG_CMP_SWAP\"\nfi\nif test \"$libverbs\" = \"yes\" -a \"$rdmacm\" = \"yes\" ; then\n  output_sym \"CONFIG_RDMA\"\nfi\nif test \"$clock_gettime\" = \"yes\" ; then\n  output_sym \"CONFIG_CLOCK_GETTIME\"\nfi\nif test \"$clock_monotonic\" = \"yes\" ; then\n  output_sym \"CONFIG_CLOCK_MONOTONIC\"\nfi\nif test \"$clockid_t\" = \"yes\"; then\n  output_sym \"CONFIG_CLOCKID_T\"\nfi\nif test \"$gettimeofday\" = \"yes\" ; then\n  output_sym \"CONFIG_GETTIMEOFDAY\"\nfi\nif test \"$posix_fadvise\" = \"yes\" ; then\n  output_sym \"CONFIG_POSIX_FADVISE\"\nfi\nif test \"$linux_3arg_affinity\" = \"yes\" ; then\n  output_sym \"CONFIG_3ARG_AFFINITY\"\nelif test \"$linux_2arg_affinity\" = \"yes\" ; then\n  output_sym \"CONFIG_2ARG_AFFINITY\"\nfi\nif test \"$strsep\" = \"yes\" ; then\n  output_sym \"CONFIG_STRSEP\"\nfi\nif test \"$strcasestr\" = \"yes\" ; then\n  output_sym \"CONFIG_STRCASESTR\"\nfi\nif test \"$strlcat\" = \"yes\" ; then\n  output_sym \"CONFIG_STRLCAT\"\nfi\nif test \"$getopt_long_only\" = \"yes\" ; then\n  output_sym \"CONFIG_GETOPT_LONG_ONLY\"\nfi\nif test \"$inet_aton\" = \"yes\" ; then\n  output_sym \"CONFIG_INET_ATON\"\nfi\nif test \"$socklen_t\" = \"yes\" ; then\n  output_sym \"CONFIG_SOCKLEN_T\"\nfi\nif test \"$ext4_me\" = \"yes\" ; then\n  output_sym \"CONFIG_LINUX_EXT4_MOVE_EXTENT\"\nfi\nif test \"$linux_splice\" = \"yes\" ; then\n  output_sym \"CONFIG_LINUX_SPLICE\"\nfi\nif test \"$libnuma_v2\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBNUMA\"\nfi\nif test \"$solaris_aio\" = \"yes\" ; then\n  output_sym \"CONFIG_SOLARISAIO\"\nfi\nif test \"$tls_thread\" = \"yes\" ; then\n  output_sym \"CONFIG_TLS_THREAD\"\nfi\nif test \"$rusage_thread\" = \"yes\" ; then\n  output_sym \"CONFIG_RUSAGE_THREAD\"\nfi\nif test \"$gfio\" = \"yes\" ; then\n  output_sym \"CONFIG_GFIO\"\nfi\nif test \"$esx\" = \"yes\" ; then\n  output_sym \"CONFIG_ESX\"\n  output_sym \"CONFIG_NO_SHM\"\nfi\nif test \"$sched_idle\" = \"yes\" ; then\n  output_sym \"CONFIG_SCHED_IDLE\"\nfi\nif test \"$tcp_nodelay\" = \"yes\" ; then\n  output_sym \"CONFIG_TCP_NODELAY\"\nfi\nif test \"$window_size\" = \"yes\" ; then\n  output_sym \"CONFIG_NET_WINDOWSIZE\"\nfi\nif test \"$mss\" = \"yes\" ; then\n  output_sym \"CONFIG_NET_MSS\"\nfi\nif test \"$rlimit_memlock\" = \"yes\" ; then\n  output_sym \"CONFIG_RLIMIT_MEMLOCK\"\nfi\nif test \"$pwritev\" = \"yes\" ; then\n  output_sym \"CONFIG_PWRITEV\"\nfi\nif test \"$pwritev2\" = \"yes\" ; then\n  output_sym \"CONFIG_PWRITEV2\"\nfi\nif test \"$ipv6\" = \"yes\" ; then\n  output_sym \"CONFIG_IPV6\"\nfi\nif test \"$vsock\" = \"yes\"; then\n  output_sym \"CONFIG_VSOCK\"\nfi\nif test \"$http\" = \"yes\" ; then\n  output_sym \"CONFIG_HTTP\"\nfi\nif test \"$rados\" = \"yes\" ; then\n  output_sym \"CONFIG_RADOS\"\nfi\nif test \"$rbd\" = \"yes\" ; then\n  output_sym \"CONFIG_RBD\"\nfi\nif test \"$rbd_poll\" = \"yes\" ; then\n  output_sym \"CONFIG_RBD_POLL\"\nfi\nif test \"$rbd_inval\" = \"yes\" ; then\n  output_sym \"CONFIG_RBD_INVAL\"\nfi\nif test \"$setvbuf\" = \"yes\" ; then\n  output_sym \"CONFIG_SETVBUF\"\nfi\nif test \"$s390_z196_facilities\" = \"yes\" ; then\n  output_sym \"CONFIG_S390_Z196_FACILITIES\"\n  CFLAGS=\"$CFLAGS -march=z9-109\"\n  march_set=\"yes\"\nfi\nif test \"$gfapi\" = \"yes\" ; then\n  output_sym \"CONFIG_GFAPI\"\nfi\nif test \"$gf_fadvise\" = \"yes\" ; then\n  output_sym \"CONFIG_GF_FADVISE\"\nfi\nif test \"$gf_trim\" = \"yes\" ; then\n  output_sym \"CONFIG_GF_TRIM\"\nfi\nif test \"$gf_new\" = \"yes\" ; then\n  output_sym \"CONFIG_GF_NEW_API\"\nfi\nif test \"$libhdfs\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBHDFS\"\n  echo \"FIO_HDFS_CPU=$FIO_HDFS_CPU\" >> $config_host_mak\n  echo \"JAVA_HOME=$JAVA_HOME\" >> $config_host_mak\n  echo \"FIO_LIBHDFS_INCLUDE=$FIO_LIBHDFS_INCLUDE\" >> $config_host_mak\n  echo \"FIO_LIBHDFS_LIB=$FIO_LIBHDFS_LIB\" >> $config_host_mak\nfi\nif test \"$mtd\" = \"yes\" ; then\n  output_sym \"CONFIG_MTD\"\nfi\nif test \"$devdax\" = \"yes\" ; then\n  output_sym \"CONFIG_LINUX_DEVDAX\"\nfi\nif test \"$pmem\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBPMEM\"\nfi\nif test \"$libpmem2\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBPMEM2_INSTALLED\"\nfi\nif test \"$libime\" = \"yes\" ; then\n  output_sym \"CONFIG_IME\"\nfi\nif test \"$arith\" = \"yes\" ; then\n  output_sym \"CONFIG_ARITHMETIC\"\n  if test \"$yacc_is_bison\" = \"yes\" ; then\n    echo \"YACC=bison -y\" >> $config_host_mak\n  else\n    echo \"YACC=yacc\" >> $config_host_mak\n  fi\n  if test \"$lex_use_o\" = \"yes\" ; then\n    echo \"CONFIG_LEX_USE_O=y\" >> $config_host_mak\n  fi\nfi\nif test \"$getmntent\" = \"yes\" ; then\n  output_sym \"CONFIG_GETMNTENT\"\nfi\nif test \"$getmntinfo\" = \"yes\" ; then\n  output_sym \"CONFIG_GETMNTINFO\"\nfi\nif test \"$getmntinfo_statvfs\" = \"yes\" ; then\n  output_sym \"CONFIG_GETMNTINFO_STATVFS\"\nfi\nif test \"$static_assert\" = \"yes\" ; then\n  output_sym \"CONFIG_STATIC_ASSERT\"\nfi\nif test \"$have_bool\" = \"yes\" ; then\n  output_sym \"CONFIG_HAVE_BOOL\"\nfi\nif test \"$strndup\" = \"yes\" ; then\n  output_sym \"CONFIG_HAVE_STRNDUP\"\nfi\nif test \"$disable_opt\" = \"yes\" ; then\n  output_sym \"CONFIG_DISABLE_OPTIMIZATIONS\"\nfi\nif test \"$valgrind_dev\" = \"yes\"; then\n  output_sym \"CONFIG_VALGRIND_DEV\"\nfi\nif test \"$linux_blkzoned\" = \"yes\" ; then\n  output_sym \"CONFIG_HAS_BLKZONED\"\nfi\nif test \"$libzbc\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBZBC\"\nfi\nif test \"$zlib\" = \"no\" ; then\n  echo \"Consider installing zlib1g-dev (zlib-devel) as some fio features depend on it.\"\n  if test \"$build_static\" = \"yes\"; then\n    echo \"Note that some distros have separate packages for static libraries.\"\n  fi\nfi\nif test \"$march_armv8_a_crc_crypto\" = \"yes\" ; then\n  output_sym \"ARCH_HAVE_CRC_CRYPTO\"\nfi\nif test \"$cuda\" = \"yes\" ; then\n  output_sym \"CONFIG_CUDA\"\nfi\nif test \"$libcufile\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBCUFILE\"\nfi\nif test \"$dfs\" = \"yes\" ; then\n  output_sym \"CONFIG_DFS\"\nfi\nif test \"$march_set\" = \"no\" && test \"$build_native\" = \"yes\" ; then\n  output_sym \"CONFIG_BUILD_NATIVE\"\nfi\nif test \"$cunit\" = \"yes\" ; then\n  output_sym \"CONFIG_HAVE_CUNIT\"\nfi\nif test \"$__kernel_rwf_t\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_KERNEL_RWF_T\"\nfi\nif test \"$gettid\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_GETTID\"\nfi\nif test \"$statx\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_STATX\"\nfi\nif test \"$statx_syscall\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_STATX_SYSCALL\"\nfi\nif test \"$timerfd_create\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_TIMERFD_CREATE\"\nfi\nif test \"$fallthrough\" = \"yes\"; then\n  CFLAGS=\"$CFLAGS -Wimplicit-fallthrough\"\nfi\nif test \"$no_stringop\" = \"yes\"; then\n  output_sym \"CONFIG_HAVE_NO_STRINGOP\"\nfi\nif test \"$thp\" = \"yes\" ; then\n  output_sym \"CONFIG_HAVE_THP\"\nfi\nif test \"$libiscsi\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBISCSI\"\n  echo \"CONFIG_LIBISCSI=m\" >> $config_host_mak\n  echo \"LIBISCSI_CFLAGS=$libiscsi_cflags\" >> $config_host_mak\n  echo \"LIBISCSI_LIBS=$libiscsi_libs\" >> $config_host_mak\nfi\nif test \"$libnbd\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBNBD\"\n  echo \"CONFIG_LIBNBD=m\" >> $config_host_mak\n  echo \"LIBNBD_CFLAGS=$libnbd_cflags\" >> $config_host_mak\n  echo \"LIBNBD_LIBS=$libnbd_libs\" >> $config_host_mak\nfi\nif test \"$libnfs\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBNFS\"\n  echo \"LIBNFS_CFLAGS=$libnfs_cflags\" >> $config_host_mak\n  echo \"LIBNFS_LIBS=$libnfs_libs\" >> $config_host_mak\nfi\nif test \"$xnvme\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBXNVME\"\n  echo \"LIBXNVME_CFLAGS=$xnvme_cflags\" >> $config_host_mak\n  echo \"LIBXNVME_LIBS=$xnvme_libs\" >> $config_host_mak\nfi\nif test \"$isal\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBISAL\"\nfi\nif test \"$libblkio\" = \"yes\" ; then\n  output_sym \"CONFIG_LIBBLKIO\"\n  echo \"LIBBLKIO_CFLAGS=$libblkio_cflags\" >> $config_host_mak\n  echo \"LIBBLKIO_LIBS=$libblkio_libs\" >> $config_host_mak\nfi\nif test \"$dynamic_engines\" = \"yes\" ; then\n  output_sym \"CONFIG_DYNAMIC_ENGINES\"\nfi\nif test \"$pdb\" = yes; then\n  output_sym \"CONFIG_PDB\"\nfi\nif test \"$fcntl_sync\" = \"yes\" ; then\n  output_sym \"CONFIG_FCNTL_SYNC\"\nfi\nif test \"$asan\" = \"yes\"; then\n  CFLAGS=\"$CFLAGS -fsanitize=address\"\n  LDFLAGS=\"$LDFLAGS -fsanitize=address\"\nfi\nprint_config \"Lib-based ioengines dynamic\" \"$dynamic_engines\"\ncat > $TMPC << EOF\nint main(int argc, char **argv)\n{\n  return 0;\n}\nEOF\nif test \"$disable_tcmalloc\" != \"yes\"; then\n  if compile_prog \"\" \"-ltcmalloc\" \"tcmalloc\"; then\n    tcmalloc=\"yes\"\n    LIBS=\"-ltcmalloc $LIBS\"\n  elif compile_prog \"\" \"-l:libtcmalloc_minimal.so.4\" \"tcmalloc_minimal4\"; then\n    tcmalloc=\"yes\"\n    LIBS=\"-l:libtcmalloc_minimal.so.4 $LIBS\"\n  else\n    tcmalloc=\"no\"\n  fi\nfi\nprint_config \"TCMalloc support\" \"$tcmalloc\"\nif ! num \"$seed_buckets\"; then\n  seed_buckets=4\nelif test \"$seed_buckets\" -lt 2; then\n  seed_buckets=2\nelif test \"$seed_buckets\" -gt 16; then\n  seed_buckets=16\nfi\necho \"#define CONFIG_SEED_BUCKETS $seed_buckets\" >> $config_host_h\nprint_config \"seed_buckets\" \"$seed_buckets\"\n\necho \"LIBS+=$LIBS\" >> $config_host_mak\necho \"GFIO_LIBS+=$GFIO_LIBS\" >> $config_host_mak\necho \"CFLAGS+=$CFLAGS\" >> $config_host_mak\necho \"LDFLAGS+=$LDFLAGS\" >> $config_host_mak\necho \"CC=$cc\" >> $config_host_mak\necho \"BUILD_CFLAGS=$BUILD_CFLAGS $CFLAGS\" >> $config_host_mak\necho \"INSTALL_PREFIX=$prefix\" >> $config_host_mak\n\nif [ `dirname $0` != \".\" -a ! -e Makefile ]; then\n    cat > Makefile <<EOF\nSRCDIR:=`dirname $0`\ninclude \\$(SRCDIR)/Makefile\nEOF\nfi\n"
        },
        {
          "name": "crc",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataplacement.c",
          "type": "blob",
          "size": 5.818359375,
          "content": "/*\n * Note: This is similar to a very basic setup\n * of ZBD devices\n *\n * Specify fdp=1 (With char devices /dev/ng0n1)\n */\n\n#include <errno.h>\n#include <string.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include \"fio.h\"\n#include \"file.h\"\n\n#include \"pshared.h\"\n#include \"dataplacement.h\"\n\nstatic int fdp_ruh_info(struct thread_data *td, struct fio_file *f,\n\t\t\tstruct fio_ruhs_info *ruhs)\n{\n\tint ret = -EINVAL;\n\n\tif (!td->io_ops) {\n\t\tlog_err(\"fio: no ops set in fdp init?!\\n\");\n\t\treturn ret;\n\t}\n\n\tif (td->io_ops->fdp_fetch_ruhs) {\n\t\tret = td->io_ops->fdp_fetch_ruhs(td, f, ruhs);\n\t\tif (ret < 0) {\n\t\t\ttd_verror(td, errno, \"fdp fetch ruhs failed\");\n\t\t\tlog_err(\"%s: fdp fetch ruhs failed (%d)\\n\",\n\t\t\t\tf->file_name, errno);\n\t\t}\n\t} else {\n\t\tlog_err(\"%s: engine (%s) lacks fetch ruhs\\n\",\n\t\t\tf->file_name, td->io_ops->name);\n\t}\n\n\treturn ret;\n}\n\nstatic int init_ruh_info(struct thread_data *td, struct fio_file *f)\n{\n\tstruct fio_ruhs_info *ruhs, *tmp;\n\tuint32_t nr_ruhs;\n\tint i, ret;\n\n\t/* set up the data structure used for FDP to work with the supplied stream IDs */\n\tif (td->o.dp_type == FIO_DP_STREAMS) {\n\t\tif (!td->o.dp_nr_ids) {\n\t\t\tlog_err(\"fio: stream IDs must be provided for dataplacement=streams\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\truhs = scalloc(1, sizeof(*ruhs) + td->o.dp_nr_ids * sizeof(*ruhs->plis));\n\t\tif (!ruhs)\n\t\t\treturn -ENOMEM;\n\n\t\truhs->nr_ruhs = td->o.dp_nr_ids;\n\t\tfor (int i = 0; i < ruhs->nr_ruhs; i++)\n\t\t\truhs->plis[i] = td->o.dp_ids[i];\n\n\t\tf->ruhs_info = ruhs;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Since we don't know the actual number of ruhs. Only fetch the header.\n\t * We will reallocate this buffer and then fetch all the ruhs again.\n\t */\n\truhs = calloc(1, sizeof(*ruhs));\n\tret = fdp_ruh_info(td, f, ruhs);\n\tif (ret) {\n\t\tlog_err(\"fio: ruh info failed for %s (%d)\\n\",\n\t\t\tf->file_name, -ret);\n\t\tgoto out;\n\t}\n\n\tnr_ruhs = ruhs->nr_ruhs;\n\truhs = realloc(ruhs, sizeof(*ruhs) + nr_ruhs * sizeof(*ruhs->plis));\n\tif (!ruhs) {\n\t\tlog_err(\"fio: ruhs buffer realloc failed for %s\\n\",\n\t\t\tf->file_name);\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\truhs->nr_ruhs = nr_ruhs;\n\tret = fdp_ruh_info(td, f, ruhs);\n\tif (ret) {\n\t\tlog_err(\"fio: ruh info failed for %s (%d)\\n\",\n\t\t\tf->file_name, -ret);\n\t\tgoto out;\n\t}\n\n\tif (td->o.dp_nr_ids == 0) {\n\t\tif (ruhs->nr_ruhs > FIO_MAX_DP_IDS)\n\t\t\truhs->nr_ruhs = FIO_MAX_DP_IDS;\n\t} else {\n\t\tfor (i = 0; i < td->o.dp_nr_ids; i++) {\n\t\t\tif (td->o.dp_ids[i] >= ruhs->nr_ruhs) {\n\t\t\t\tlog_err(\"fio: for %s PID index %d must be smaller than %d\\n\",\n\t\t\t\t\tf->file_name, td->o.dp_ids[i],\n\t\t\t\t\truhs->nr_ruhs);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\truhs->nr_ruhs = td->o.dp_nr_ids;\n\t}\n\n\ttmp = scalloc(1, sizeof(*tmp) + ruhs->nr_ruhs * sizeof(*tmp->plis));\n\tif (!tmp) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (td->o.dp_nr_ids == 0) {\n\t\tfor (i = 0; i < ruhs->nr_ruhs; i++)\n\t\t\ttmp->plis[i] = ruhs->plis[i];\n\n\t\ttmp->nr_ruhs = ruhs->nr_ruhs;\n\t\tf->ruhs_info = tmp;\n\t\tfree(ruhs);\n\n\t\treturn 0;\n\t}\n\n\ttmp->nr_ruhs = td->o.dp_nr_ids;\n\tfor (i = 0; i < td->o.dp_nr_ids; i++)\n\t\ttmp->plis[i] = ruhs->plis[td->o.dp_ids[i]];\n\tf->ruhs_info = tmp;\nout:\n\tfree(ruhs);\n\treturn ret;\n}\n\nstatic int init_ruh_scheme(struct thread_data *td, struct fio_file *f)\n{\n\tstruct fio_ruhs_scheme *ruh_scheme;\n\tFILE *scheme_fp;\n\tunsigned long long start, end;\n\tuint16_t pli;\n\tint ret = 0;\n\n\tif (td->o.dp_id_select != FIO_DP_SCHEME)\n\t\treturn 0;\n\n\t/* Get the scheme from the file */\n\tscheme_fp = fopen(td->o.dp_scheme_file, \"r\");\n\n\tif (!scheme_fp) {\n\t\tlog_err(\"fio: ruh scheme failed to open scheme file %s\\n\",\n\t\t\ttd->o.dp_scheme_file);\n\t\tret = -errno;\n\t\tgoto out;\n\t}\n\n\truh_scheme = scalloc(1, sizeof(*ruh_scheme));\n\tif (!ruh_scheme) {\n\t\tret = -ENOMEM;\n\t\tgoto out_with_close_fp;\n\t}\n\n\tfor (int i = 0;\n\t\ti < DP_MAX_SCHEME_ENTRIES && fscanf(scheme_fp, \"%llu,%llu,%hu\\n\", &start, &end, &pli) == 3;\n\t\ti++) {\n\n\t\truh_scheme->scheme_entries[i].start_offset = start;\n\t\truh_scheme->scheme_entries[i].end_offset = end;\n\t\truh_scheme->scheme_entries[i].pli = pli;\n\t\truh_scheme->nr_schemes++;\n\t}\n\n\tif (fscanf(scheme_fp, \"%llu,%llu,%hu\\n\", &start, &end, &pli) == 3)\n\t\tlog_info(\"fio: too many scheme entries in %s. Only the first %d scheme entries are applied\\n\",\n\t\t\t td->o.dp_scheme_file,\n\t\t\t DP_MAX_SCHEME_ENTRIES);\n\n\tf->ruhs_scheme = ruh_scheme;\n\nout_with_close_fp:\n\tfclose(scheme_fp);\nout:\n\treturn ret;\n}\n\nint dp_init(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tint i, ret = 0;\n\n\tfor_each_file(td, f, i) {\n\t\tret = init_ruh_info(td, f);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tret = init_ruh_scheme(td, f);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\nvoid fdp_free_ruhs_info(struct fio_file *f)\n{\n\tif (!f->ruhs_info)\n\t\treturn;\n\tsfree(f->ruhs_info);\n\tf->ruhs_info = NULL;\n\n\tif (!f->ruhs_scheme)\n\t\treturn;\n\tsfree(f->ruhs_scheme);\n\tf->ruhs_scheme = NULL;\n}\n\nvoid dp_fill_dspec_data(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f = io_u->file;\n\tstruct fio_ruhs_info *ruhs = f->ruhs_info;\n\tint dspec;\n\n\tif (!ruhs || io_u->ddir != DDIR_WRITE) {\n\t\tio_u->dtype = 0;\n\t\tio_u->dspec = 0;\n\t\treturn;\n\t}\n\n\tif (td->o.dp_id_select == FIO_DP_RR) {\n\t\tif (ruhs->pli_loc >= ruhs->nr_ruhs)\n\t\t\truhs->pli_loc = 0;\n\n\t\tdspec = ruhs->plis[ruhs->pli_loc++];\n\t} else if (td->o.dp_id_select == FIO_DP_SCHEME) {\n\t\tstruct fio_ruhs_scheme *ruhs_scheme = f->ruhs_scheme;\n\t\tunsigned long long offset = io_u->offset;\n\t\tint i;\n\n\t\tfor (i = 0; i < ruhs_scheme->nr_schemes; i++) {\n\t\t\tif (offset >= ruhs_scheme->scheme_entries[i].start_offset &&\n\t\t\t    offset < ruhs_scheme->scheme_entries[i].end_offset) {\n\t\t\t\tdspec = ruhs_scheme->scheme_entries[i].pli;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * If the write offset is not affected by any scheme entry,\n\t\t * 0(default RUH) will be assigned to dspec\n\t\t */\n\t\tif (i == ruhs_scheme->nr_schemes)\n\t\t\tdspec = 0;\n\t} else {\n\t\truhs->pli_loc = rand_between(&td->fdp_state, 0, ruhs->nr_ruhs - 1);\n\t\tdspec = ruhs->plis[ruhs->pli_loc];\n\t}\n\n\tio_u->dtype = td->o.dp_type == FIO_DP_FDP ? FDP_DIR_DTYPE : STREAMS_DIR_DTYPE;\n\tio_u->dspec = dspec;\n\tdprint(FD_IO, \"dtype set to 0x%x, dspec set to 0x%x\\n\", io_u->dtype, io_u->dspec);\n}\n"
        },
        {
          "name": "dataplacement.h",
          "type": "blob",
          "size": 0.9296875,
          "content": "#ifndef FIO_DATAPLACEMENT_H\n#define FIO_DATAPLACEMENT_H\n\n#include \"io_u.h\"\n\n#define STREAMS_DIR_DTYPE\t1\n#define FDP_DIR_DTYPE\t\t2\n#define FIO_MAX_DP_IDS \t\t128\n#define DP_MAX_SCHEME_ENTRIES\t32\n\n/*\n * How fio chooses what placement identifier to use next. Choice of\n * uniformly random, or roundrobin.\n */\nenum {\n\tFIO_DP_RANDOM\t= 0x1,\n\tFIO_DP_RR\t= 0x2,\n\tFIO_DP_SCHEME\t= 0x3,\n};\n\nenum {\n\tFIO_DP_NONE\t= 0x0,\n\tFIO_DP_FDP\t= 0x1,\n\tFIO_DP_STREAMS\t= 0x2,\n};\n\nstruct fio_ruhs_info {\n\tuint32_t nr_ruhs;\n\tuint32_t pli_loc;\n\tuint16_t plis[];\n};\n\nstruct fio_ruhs_scheme_entry {\n\tunsigned long long start_offset;\n\tunsigned long long end_offset;\n\tuint16_t pli;\n};\n\nstruct fio_ruhs_scheme {\n\tuint16_t nr_schemes;\n\tstruct fio_ruhs_scheme_entry scheme_entries[DP_MAX_SCHEME_ENTRIES];\n};\n\nint dp_init(struct thread_data *td);\nvoid fdp_free_ruhs_info(struct fio_file *f);\nvoid dp_fill_dspec_data(struct thread_data *td, struct io_u *io_u);\n\n#endif /* FIO_DATAPLACEMENT_H */\n"
        },
        {
          "name": "debug.c",
          "type": "blob",
          "size": 0.2666015625,
          "content": "#include <assert.h>\n#include <stdarg.h>\n\n#include \"debug.h\"\n#include \"log.h\"\n\n#ifdef FIO_INC_DEBUG\nvoid __dprint(int type, const char *str, ...)\n{\n\tva_list args;\n\n\tassert(type < FD_DEBUG_MAX);\n\n\tva_start(args, str);\n\tlog_prevalist(type, str, args);\n\tva_end(args);\n}\n#endif\n"
        },
        {
          "name": "debug.h",
          "type": "blob",
          "size": 1.2001953125,
          "content": "#ifndef FIO_DEBUG_H\n#define FIO_DEBUG_H\n\n#include \"lib/types.h\"\n\nenum {\n\tFD_PROCESS\t= 0,\n\tFD_FILE,\n\tFD_IO,\n\tFD_MEM,\n\tFD_BLKTRACE,\n\tFD_VERIFY,\n\tFD_RANDOM,\n\tFD_PARSE,\n\tFD_DISKUTIL,\n\tFD_JOB,\n\tFD_MUTEX,\n\tFD_PROFILE,\n\tFD_TIME,\n\tFD_NET,\n\tFD_RATE,\n\tFD_COMPRESS,\n\tFD_STEADYSTATE,\n\tFD_HELPERTHREAD,\n\tFD_ZBD,\n\tFD_DEBUG_MAX,\n};\n\nextern unsigned int fio_debug_jobno, *fio_debug_jobp, *fio_warned;\n\nstatic inline bool fio_did_warn(unsigned int mask)\n{\n\tif (*fio_warned & mask)\n\t\treturn true;\n\n\t*fio_warned |= mask;\n\treturn false;\n}\n\nenum {\n\tFIO_WARN_ROOT_FLUSH\t= 1,\n\tFIO_WARN_VERIFY_BUF\t= 2,\n\tFIO_WARN_ZONED_BUG\t= 4,\n\tFIO_WARN_IOLOG_DROP\t= 8,\n\tFIO_WARN_FADVISE\t= 16,\n\tFIO_WARN_BTRACE_ZERO\t= 32,\n};\n\n#ifdef FIO_INC_DEBUG\nstruct debug_level {\n\tconst char *name;\n\tconst char *help;\n\tunsigned long shift;\n\tunsigned int jobno;\n};\nextern const struct debug_level debug_levels[];\n\nextern unsigned long fio_debug;\n\nvoid __dprint(int type, const char *str, ...) __attribute__((format (printf, 2, 3)));\n\n#define dprint(type, str, args...)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\tif (((1 << type) & fio_debug) == 0)\t\\\n\t\t\tbreak;\t\t\t\t\\\n\t\t__dprint((type), (str), ##args);\t\\\n\t} while (0)\t\t\t\t\t\\\n\n#else\n\nstatic inline void dprint(int type, const char *str, ...)\n{\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "dedupe.c",
          "type": "blob",
          "size": 2.2685546875,
          "content": "#include \"fio.h\"\n\n/**\n * initializes the global dedup workset.\n * this needs to be called after all jobs' seeds\n * have been initialized\n */\nint init_global_dedupe_working_set_seeds(void)\n{\n\tfor_each_td(td) {\n\t\tif (!td->o.dedupe_global)\n\t\t\tcontinue;\n\n\t\tif (init_dedupe_working_set_seeds(td, 1))\n\t\t\treturn 1;\n\t} end_for_each();\n\n\treturn 0;\n}\n\nint init_dedupe_working_set_seeds(struct thread_data *td, bool global_dedup)\n{\n\tint tindex;\n\tstruct thread_data *td_seed;\n\tunsigned long long i, j, num_seed_advancements, pages_per_seed;\n\tstruct frand_state dedupe_working_set_state = {0};\n\n\tif (!td->o.dedupe_percentage || !(td->o.dedupe_mode == DEDUPE_MODE_WORKING_SET))\n\t\treturn 0;\n\n\ttindex = td->thread_number - 1;\n\tnum_seed_advancements = td->o.min_bs[DDIR_WRITE] /\n\t\tmin_not_zero(td->o.min_bs[DDIR_WRITE], (unsigned long long) td->o.compress_chunk);\n\t/*\n\t * The dedupe working set keeps seeds of unique data (generated by buf_state).\n\t * Dedupe-ed pages will be generated using those seeds.\n\t */\n\ttd->num_unique_pages = (td->o.size * (unsigned long long)td->o.dedupe_working_set_percentage / 100) / td->o.min_bs[DDIR_WRITE];\n\ttd->dedupe_working_set_states = malloc(sizeof(struct frand_state) * td->num_unique_pages);\n\tif (!td->dedupe_working_set_states) {\n\t\tlog_err(\"fio: could not allocate dedupe working set\\n\");\n\t\treturn 1;\n\t}\n\n\tfrand_copy(&dedupe_working_set_state, &td->buf_state);\n\tfrand_copy(&td->dedupe_working_set_states[0], &dedupe_working_set_state);\n\tpages_per_seed = max(td->num_unique_pages / thread_number, 1ull);\n\tfor (i = 1; i < td->num_unique_pages; i++) {\n\t\t/*\n\t\t * When compression is used the seed is advanced multiple times to\n\t\t * generate the buffer. We want to regenerate the same buffer when\n\t\t * deduping against this page\n\t\t */\n\t\tfor (j = 0; j < num_seed_advancements; j++)\n\t\t\t__get_next_seed(&dedupe_working_set_state);\n\n\t\t/*\n\t\t * When global dedup is used, we rotate the seeds to allow\n\t\t * generating same buffers across different jobs. Deduplication buffers\n\t\t * are spread evenly across jobs participating in global dedupe\n\t\t */\n\t\tif (global_dedup && i % pages_per_seed == 0) {\n\t\t\ttd_seed = tnumber_to_td(++tindex % thread_number);\n\t\t\tfrand_copy(&dedupe_working_set_state, &td_seed->buf_state);\n\t\t}\n\n\t\tfrand_copy(&td->dedupe_working_set_states[i], &dedupe_working_set_state);\n\t}\n\n\treturn 0;\n}\n"
        },
        {
          "name": "dedupe.h",
          "type": "blob",
          "size": 0.166015625,
          "content": "#ifndef DEDUPE_H\n#define DEDUPE_H\n\nint init_dedupe_working_set_seeds(struct thread_data *td, bool global_dedupe);\nint init_global_dedupe_working_set_seeds(void);\n\n#endif\n"
        },
        {
          "name": "diskutil.c",
          "type": "blob",
          "size": 11.86328125,
          "content": "#include <inttypes.h>\n#include <stdio.h>\n#include <string.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <sys/sysmacros.h>\n#include <dirent.h>\n#include <libgen.h>\n#ifdef CONFIG_VALGRIND_DEV\n#include <valgrind/drd.h>\n#else\n#define DRD_IGNORE_VAR(x) do { } while (0)\n#endif\n\n#include \"fio.h\"\n#include \"smalloc.h\"\n#include \"diskutil.h\"\n#include \"helper_thread.h\"\n\nstatic int last_majdev, last_mindev;\nstatic struct disk_util *last_du;\n\nstatic struct fio_sem *disk_util_sem;\n\nstatic struct disk_util *__init_per_file_disk_util(struct thread_data *td,\n\t\tint majdev, int mindev, char *path);\n\nstatic void disk_util_free(struct disk_util *du)\n{\n\tif (du == last_du)\n\t\tlast_du = NULL;\n\n\twhile (!flist_empty(&du->slaves)) {\n\t\tstruct disk_util *slave;\n\n\t\tslave = flist_first_entry(&du->slaves, struct disk_util, slavelist);\n\t\tflist_del(&slave->slavelist);\n\t\tslave->users--;\n\t}\n\n\tfio_sem_remove(du->lock);\n\tfree(du->sysfs_root);\n\tsfree(du);\n}\n\nstatic int get_io_ticks(struct disk_util *du, struct disk_util_stat *dus)\n{\n\tchar line[256];\n\tFILE *f;\n\tchar *p;\n\tint ret;\n\n\tdprint(FD_DISKUTIL, \"open stat file: %s\\n\", du->path);\n\n\tf = fopen(du->path, \"r\");\n\tif (!f)\n\t\treturn 1;\n\n\tp = fgets(line, sizeof(line), f);\n\tif (!p) {\n\t\tfclose(f);\n\t\treturn 1;\n\t}\n\n\tdprint(FD_DISKUTIL, \"%s: %s\", du->path, p);\n\n\tret = sscanf(p, \"%\"SCNu64\" %\"SCNu64\" %\"SCNu64\" %\"SCNu64\" \"\n\t\t     \"%\"SCNu64\" %\"SCNu64\" %\"SCNu64\" %\"SCNu64\" \"\n\t\t     \"%*u %\"SCNu64\" %\"SCNu64\"\\n\",\n\t\t     &dus->s.ios[0], &dus->s.merges[0], &dus->s.sectors[0],\n\t\t     &dus->s.ticks[0],\n\t\t     &dus->s.ios[1], &dus->s.merges[1], &dus->s.sectors[1],\n\t\t     &dus->s.ticks[1],\n\t\t     &dus->s.io_ticks, &dus->s.time_in_queue);\n\tfclose(f);\n\tdprint(FD_DISKUTIL, \"%s: stat read ok? %d\\n\", du->path, ret == 10);\n\treturn ret != 10;\n}\n\nstatic uint64_t safe_32bit_diff(uint64_t nval, uint64_t oval)\n{\n\t/* Linux kernel prints some of the stat fields as 32-bit integers. It is\n\t * possible that the value overflows, but since fio uses unsigned 64-bit\n\t * arithmetic in update_io_tick_disk(), it instead results in a huge\n\t * bogus value being added to the respective accumulating field. Just\n\t * in case Linux starts reporting these metrics as 64-bit values in the\n\t * future, check that overflow actually happens around the 32-bit\n\t * unsigned boundary; assume overflow only happens once between\n\t * successive polls.\n\t */\n\tif (oval <= nval || oval >= (1ull << 32))\n\t\treturn nval - oval;\n\telse\n\t\treturn (1ull << 32) + nval - oval;\n}\n\nstatic void update_io_tick_disk(struct disk_util *du)\n{\n\tstruct disk_util_stat __dus, *dus, *ldus;\n\tstruct timespec t;\n\n\tif (!du->users)\n\t\treturn;\n\tif (get_io_ticks(du, &__dus))\n\t\treturn;\n\n\tdus = &du->dus;\n\tldus = &du->last_dus;\n\n\tdus->s.sectors[0] += (__dus.s.sectors[0] - ldus->s.sectors[0]);\n\tdus->s.sectors[1] += (__dus.s.sectors[1] - ldus->s.sectors[1]);\n\tdus->s.ios[0] += (__dus.s.ios[0] - ldus->s.ios[0]);\n\tdus->s.ios[1] += (__dus.s.ios[1] - ldus->s.ios[1]);\n\tdus->s.merges[0] += (__dus.s.merges[0] - ldus->s.merges[0]);\n\tdus->s.merges[1] += (__dus.s.merges[1] - ldus->s.merges[1]);\n\tdus->s.ticks[0] += safe_32bit_diff(__dus.s.ticks[0], ldus->s.ticks[0]);\n\tdus->s.ticks[1] += safe_32bit_diff(__dus.s.ticks[1], ldus->s.ticks[1]);\n\tdus->s.io_ticks += safe_32bit_diff(__dus.s.io_ticks, ldus->s.io_ticks);\n\tdus->s.time_in_queue +=\n\t\t\tsafe_32bit_diff(__dus.s.time_in_queue, ldus->s.time_in_queue);\n\n\tfio_gettime(&t, NULL);\n\tdus->s.msec += mtime_since(&du->time, &t);\n\tdu->time = t;\n\tldus->s = __dus.s;\n}\n\nint update_io_ticks(void)\n{\n\tstruct flist_head *entry;\n\tstruct disk_util *du;\n\tint ret = 0;\n\n\tdprint(FD_DISKUTIL, \"update io ticks\\n\");\n\n\tfio_sem_down(disk_util_sem);\n\n\tif (!helper_should_exit()) {\n\t\tflist_for_each(entry, &disk_list) {\n\t\t\tdu = flist_entry(entry, struct disk_util, list);\n\t\t\tupdate_io_tick_disk(du);\n\t\t}\n\t} else\n\t\tret = 1;\n\n\tfio_sem_up(disk_util_sem);\n\treturn ret;\n}\n\nstatic struct disk_util *disk_util_exists(int major, int minor)\n{\n\tstruct flist_head *entry;\n\tstruct disk_util *du;\n\n\tfio_sem_down(disk_util_sem);\n\n\tflist_for_each(entry, &disk_list) {\n\t\tdu = flist_entry(entry, struct disk_util, list);\n\n\t\tif (major == du->major && minor == du->minor) {\n\t\t\tfio_sem_up(disk_util_sem);\n\t\t\treturn du;\n\t\t}\n\t}\n\n\tfio_sem_up(disk_util_sem);\n\treturn NULL;\n}\n\nstatic int get_device_numbers(char *file_name, int *maj, int *min)\n{\n\tstruct stat st;\n\tint majdev, mindev;\n\tchar tempname[PATH_MAX], *p;\n\n\tif (!lstat(file_name, &st)) {\n\t\tif (S_ISBLK(st.st_mode)) {\n\t\t\tmajdev = major(st.st_rdev);\n\t\t\tmindev = minor(st.st_rdev);\n\t\t} else if (S_ISCHR(st.st_mode) ||\n\t\t\t   S_ISFIFO(st.st_mode)) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\tmajdev = major(st.st_dev);\n\t\t\tmindev = minor(st.st_dev);\n\t\t}\n\t} else {\n\t\t/*\n\t\t * must be a file, open \".\" in that path\n\t\t */\n\t\tsnprintf(tempname, FIO_ARRAY_SIZE(tempname), \"%s\", file_name);\n\t\tp = dirname(tempname);\n\t\tif (stat(p, &st)) {\n\t\t\tperror(\"disk util stat\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tmajdev = major(st.st_dev);\n\t\tmindev = minor(st.st_dev);\n\t}\n\n\t*min = mindev;\n\t*maj = majdev;\n\n\treturn 0;\n}\n\nstatic int read_block_dev_entry(char *path, int *maj, int *min)\n{\n\tchar line[256], *p;\n\tFILE *f;\n\n\tf = fopen(path, \"r\");\n\tif (!f) {\n\t\tperror(\"open path\");\n\t\treturn 1;\n\t}\n\n\tp = fgets(line, sizeof(line), f);\n\tfclose(f);\n\n\tif (!p)\n\t\treturn 1;\n\n\tif (sscanf(p, \"%u:%u\", maj, min) != 2)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic void find_add_disk_slaves(struct thread_data *td, char *path,\n\t\t\t\t struct disk_util *masterdu)\n{\n\tDIR *dirhandle = NULL;\n\tstruct dirent *dirent = NULL;\n\tchar slavesdir[PATH_MAX], temppath[PATH_MAX], slavepath[PATH_MAX];\n\tstruct disk_util *slavedu = NULL;\n\tint majdev, mindev;\n\tssize_t linklen;\n\n\tsprintf(slavesdir, \"%s/%s\", path, \"slaves\");\n\tdirhandle = opendir(slavesdir);\n\tif (!dirhandle)\n\t\treturn;\n\n\twhile ((dirent = readdir(dirhandle)) != NULL) {\n\t\tif (!strcmp(dirent->d_name, \".\") ||\n\t\t    !strcmp(dirent->d_name, \"..\"))\n\t\t\tcontinue;\n\n\t\tnowarn_snprintf(temppath, sizeof(temppath), \"%s/%s\", slavesdir,\n\t\t\t\tdirent->d_name);\n\t\t/* Can we always assume that the slaves device entries\n\t\t * are links to the real directories for the slave\n\t\t * devices?\n\t\t */\n\t\tlinklen = readlink(temppath, slavepath, PATH_MAX - 1);\n\t\tif (linklen < 0) {\n\t\t\tperror(\"readlink() for slave device.\");\n\t\t\tclosedir(dirhandle);\n\t\t\treturn;\n\t\t}\n\t\tslavepath[linklen] = '\\0';\n\n\t\tnowarn_snprintf(temppath, sizeof(temppath), \"%s/%s/dev\",\n\t\t\t\tslavesdir, slavepath);\n\t\tif (access(temppath, F_OK) != 0)\n\t\t\tnowarn_snprintf(temppath, sizeof(temppath),\n\t\t\t\t\t\"%s/%s/device/dev\", slavesdir,\n\t\t\t\t\tslavepath);\n\t\tif (read_block_dev_entry(temppath, &majdev, &mindev)) {\n\t\t\tperror(\"Error getting slave device numbers\");\n\t\t\tclosedir(dirhandle);\n\t\t\treturn;\n\t\t}\n\n\t\t/*\n\t\t * See if this maj,min already exists\n\t\t */\n\t\tslavedu = disk_util_exists(majdev, mindev);\n\t\tif (slavedu)\n\t\t\tcontinue;\n\n\t\tnowarn_snprintf(temppath, sizeof(temppath), \"%s/%s\", slavesdir,\n\t\t\t\tslavepath);\n\t\t__init_per_file_disk_util(td, majdev, mindev, temppath);\n\t\tslavedu = disk_util_exists(majdev, mindev);\n\n\t\t/* Should probably use an assert here. slavedu should\n\t\t * always be present at this point. */\n\t\tif (slavedu) {\n\t\t\tslavedu->users++;\n\t\t\tflist_add_tail(&slavedu->slavelist, &masterdu->slaves);\n\t\t}\n\t}\n\n\tclosedir(dirhandle);\n}\n\nstatic struct disk_util *disk_util_add(struct thread_data *td, int majdev,\n\t\t\t\t       int mindev, char *path)\n{\n\tstruct disk_util *du, *__du;\n\tstruct flist_head *entry;\n\tint l;\n\n\tdprint(FD_DISKUTIL, \"add maj/min %d/%d: %s\\n\", majdev, mindev, path);\n\n\tdu = smalloc(sizeof(*du));\n\tif (!du)\n\t\treturn NULL;\n\n\tDRD_IGNORE_VAR(du->users);\n\tmemset(du, 0, sizeof(*du));\n\tINIT_FLIST_HEAD(&du->list);\n\tl = snprintf(du->path, sizeof(du->path), \"%s/stat\", path);\n\tif (l < 0 || l >= sizeof(du->path)) {\n\t\tlog_err(\"constructed path \\\"%.100s[...]/stat\\\" larger than buffer (%zu bytes)\\n\",\n\t\t\tpath, sizeof(du->path) - 1);\n\t\tsfree(du);\n\t\treturn NULL;\n\t}\n\tsnprintf((char *) du->dus.name, FIO_ARRAY_SIZE(du->dus.name), \"%s\",\n\t\t basename(path));\n\tdu->sysfs_root = strdup(path);\n\tdu->major = majdev;\n\tdu->minor = mindev;\n\tINIT_FLIST_HEAD(&du->slavelist);\n\tINIT_FLIST_HEAD(&du->slaves);\n\tdu->lock = fio_sem_init(FIO_SEM_UNLOCKED);\n\tdu->users = 0;\n\n\tfio_sem_down(disk_util_sem);\n\n\tflist_for_each(entry, &disk_list) {\n\t\t__du = flist_entry(entry, struct disk_util, list);\n\n\t\tdprint(FD_DISKUTIL, \"found %s in list\\n\", __du->dus.name);\n\n\t\tif (!strcmp((char *) du->dus.name, (char *) __du->dus.name)) {\n\t\t\tdisk_util_free(du);\n\t\t\tfio_sem_up(disk_util_sem);\n\t\t\treturn __du;\n\t\t}\n\t}\n\n\tdprint(FD_DISKUTIL, \"add %s to list\\n\", du->dus.name);\n\n\tfio_gettime(&du->time, NULL);\n\tget_io_ticks(du, &du->last_dus);\n\n\tflist_add_tail(&du->list, &disk_list);\n\tfio_sem_up(disk_util_sem);\n\n\tfind_add_disk_slaves(td, path, du);\n\treturn du;\n}\n\nstatic int check_dev_match(int majdev, int mindev, char *path)\n{\n\tint major, minor;\n\n\tif (read_block_dev_entry(path, &major, &minor))\n\t\treturn 1;\n\n\tif (majdev == major && mindev == minor)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int find_block_dir(int majdev, int mindev, char *path, int link_ok)\n{\n\tstruct dirent *dir;\n\tstruct stat st;\n\tint found = 0;\n\tDIR *D;\n\n\tD = opendir(path);\n\tif (!D)\n\t\treturn 0;\n\n\twhile ((dir = readdir(D)) != NULL) {\n\t\tchar full_path[257];\n\n\t\tif (!strcmp(dir->d_name, \".\") || !strcmp(dir->d_name, \"..\"))\n\t\t\tcontinue;\n\n\t\tsprintf(full_path, \"%s/%s\", path, dir->d_name);\n\n\t\tif (!strcmp(dir->d_name, \"dev\")) {\n\t\t\tif (!check_dev_match(majdev, mindev, full_path)) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (link_ok) {\n\t\t\tif (stat(full_path, &st) == -1) {\n\t\t\t\tperror(\"stat\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (lstat(full_path, &st) == -1) {\n\t\t\t\tperror(\"stat\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!S_ISDIR(st.st_mode) || S_ISLNK(st.st_mode))\n\t\t\tcontinue;\n\n\t\tfound = find_block_dir(majdev, mindev, full_path, 0);\n\t\tif (found) {\n\t\t\tstrcpy(path, full_path);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tclosedir(D);\n\treturn found;\n}\n\nstatic struct disk_util *__init_per_file_disk_util(struct thread_data *td,\n\t\t\t\t\t\t   int majdev, int mindev,\n\t\t\t\t\t\t   char *path)\n{\n\tstruct stat st;\n\tchar tmp[PATH_MAX];\n\tchar *p;\n\n\t/*\n\t * If there's a ../queue/ directory there, we are inside a partition.\n\t * Check if that is the case and jump back. For loop/md/dm etc we\n\t * are already in the right spot.\n\t */\n\tsprintf(tmp, \"%s/../queue\", path);\n\tif (!stat(tmp, &st)) {\n\t\tp = dirname(path);\n\t\tsprintf(tmp, \"%s/queue\", p);\n\t\tif (stat(tmp, &st)) {\n\t\t\tlog_err(\"unknown sysfs layout\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\tsnprintf(tmp, FIO_ARRAY_SIZE(tmp), \"%s\", p);\n\t\tsprintf(path, \"%s\", tmp);\n\t}\n\n\treturn disk_util_add(td, majdev, mindev, path);\n}\n\nstatic struct disk_util *init_per_file_disk_util(struct thread_data *td,\n\t\t\t\t\t\t char *filename)\n{\n\n\tchar foo[PATH_MAX];\n\tstruct disk_util *du;\n\tint mindev, majdev;\n\n\tif (get_device_numbers(filename, &majdev, &mindev))\n\t\treturn NULL;\n\n\tdprint(FD_DISKUTIL, \"%s belongs to maj/min %d/%d\\n\", filename, majdev,\n\t\t\tmindev);\n\n\tdu = disk_util_exists(majdev, mindev);\n\tif (du)\n\t\treturn du;\n\n\t/*\n\t * for an fs without a device, we will repeatedly stat through\n\t * sysfs which can take oodles of time for thousands of files. so\n\t * cache the last lookup and compare with that before going through\n\t * everything again.\n\t */\n\tif (mindev == last_mindev && majdev == last_majdev)\n\t\treturn last_du;\n\n\tlast_mindev = mindev;\n\tlast_majdev = majdev;\n\n\tsprintf(foo, \"/sys/block\");\n\tif (!find_block_dir(majdev, mindev, foo, 1))\n\t\treturn NULL;\n\n\treturn __init_per_file_disk_util(td, majdev, mindev, foo);\n}\n\nstatic struct disk_util *__init_disk_util(struct thread_data *td,\n\t\t\t\t\t  struct fio_file *f)\n{\n\treturn init_per_file_disk_util(td, f->file_name);\n}\n\nvoid init_disk_util(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tif (!td->o.do_disk_util ||\n\t    td_ioengine_flagged(td, FIO_DISKLESSIO | FIO_NODISKUTIL))\n\t\treturn;\n\n\tfor_each_file(td, f, i)\n\t\tf->du = __init_disk_util(td, f);\n}\n\nvoid disk_util_prune_entries(void)\n{\n\tfio_sem_down(disk_util_sem);\n\n\twhile (!flist_empty(&disk_list)) {\n\t\tstruct disk_util *du;\n\n\t\tdu = flist_first_entry(&disk_list, struct disk_util, list);\n\t\tflist_del(&du->list);\n\t\tdisk_util_free(du);\n\t}\n\n\tlast_majdev = last_mindev = -1;\n\tfio_sem_up(disk_util_sem);\n\tfio_sem_remove(disk_util_sem);\n}\n\nvoid setup_disk_util(void)\n{\n\tdisk_util_sem = fio_sem_init(FIO_SEM_UNLOCKED);\n}\n"
        },
        {
          "name": "diskutil.h",
          "type": "blob",
          "size": 2.9404296875,
          "content": "#ifndef FIO_DISKUTIL_H\n#define FIO_DISKUTIL_H\n#define FIO_DU_NAME_SZ\t\t64\n\n#include <stdint.h>\n#include <limits.h>\n\n#include \"helper_thread.h\"\n#include \"fio_sem.h\"\n#include \"flist.h\"\n#include \"lib/ieee754.h\"\n\n/**\n * @ios: Number of I/O operations that have been completed successfully.\n * @merges: Number of I/O operations that have been merged.\n * @sectors: I/O size in 512-byte units.\n * @ticks: Time spent on I/O in milliseconds.\n * @io_ticks: CPU time spent on I/O in milliseconds.\n * @time_in_queue: Weighted time spent doing I/O in milliseconds.\n *\n * For the array members, index 0 refers to reads and index 1 refers to writes.\n */\nstruct disk_util_stats {\n\tuint64_t ios[2];\n\tuint64_t merges[2];\n\tuint64_t sectors[2];\n\tuint64_t ticks[2];\n\tuint64_t io_ticks;\n\tuint64_t time_in_queue;\n\tuint64_t msec;\n};\n\n/*\n * Disk utilization as read from /sys/block/<dev>/stat\n */\nstruct disk_util_stat {\n\tuint8_t name[FIO_DU_NAME_SZ];\n\tstruct disk_util_stats s;\n};\n\nstruct disk_util_agg {\n\tuint64_t ios[2];\n\tuint64_t merges[2];\n\tuint64_t sectors[2];\n\tuint64_t ticks[2];\n\tuint64_t io_ticks;\n\tuint64_t time_in_queue;\n\tuint32_t slavecount;\n\tuint32_t pad;\n\tfio_fp64_t max_util;\n};\n\n/*\n * Per-device disk util management\n */\nstruct disk_util {\n\tstruct flist_head list;\n\t/* If this disk is a slave, hook it into the master's\n\t * list using this head.\n\t */\n\tstruct flist_head slavelist;\n\n\tchar *sysfs_root;\n\tchar path[PATH_MAX];\n\tint major, minor;\n\n\tstruct disk_util_stat dus;\n\tstruct disk_util_stat last_dus;\n\n\tstruct disk_util_agg agg;\n\n\t/* For software raids, this entry maintains pointers to the\n\t * entries for the slave devices. The disk_util entries for\n\t * the slaves devices should primarily be maintained through\n\t * the disk_list list, i.e. for memory allocation and\n\t * de-allocation, etc. Whereas this list should be used only\n\t * for aggregating a software RAID's disk util figures.\n\t */\n\tstruct flist_head slaves;\n\n\tstruct timespec time;\n\n\tstruct fio_sem *lock;\n\tunsigned long users;\n};\n\nstatic inline void disk_util_mod(struct disk_util *du, int val)\n{\n\tif (du) {\n\t\tstruct flist_head *n;\n\n\t\tfio_sem_down(du->lock);\n\t\tdu->users += val;\n\n\t\tflist_for_each(n, &du->slavelist) {\n\t\t\tstruct disk_util *slave;\n\n\t\t\tslave = flist_entry(n, struct disk_util, slavelist);\n\t\t\tslave->users += val;\n\t\t}\n\t\tfio_sem_up(du->lock);\n\t}\n}\nstatic inline void disk_util_inc(struct disk_util *du)\n{\n\tdisk_util_mod(du, 1);\n}\n\nstatic inline void disk_util_dec(struct disk_util *du)\n{\n\tdisk_util_mod(du, -1);\n}\n\n#define DISK_UTIL_MSEC\t(250)\n\nextern struct flist_head disk_list;\n\n/*\n * disk util stuff\n */\n#ifdef FIO_HAVE_DISK_UTIL\nextern void init_disk_util(struct thread_data *);\nextern int update_io_ticks(void);\nextern void setup_disk_util(void);\nextern void disk_util_prune_entries(void);\n#else\n/* keep this as a function to avoid a warning in handle_du() */\n#define disk_util_prune_entries()\n#define init_disk_util(td)\n#define setup_disk_util()\n\nstatic inline int update_io_ticks(void)\n{\n\treturn helper_should_exit();\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "engines",
          "type": "tree",
          "content": null
        },
        {
          "name": "err.h",
          "type": "blob",
          "size": 0.83984375,
          "content": "#ifndef FIO_ERR_H\n#define FIO_ERR_H\n\n/*\n * Kernel pointers have redundant information, so we can use a\n * scheme where we can return either an error code or a dentry\n * pointer with the same return value.\n *\n * This should be a per-architecture thing, to allow different\n * error and pointer decisions.\n */\n#define MAX_ERRNO\t4095\n\n#define IS_ERR_VALUE(x) ((x) >= (uintptr_t)-MAX_ERRNO)\n\nstatic inline void *ERR_PTR(uintptr_t error)\n{\n\treturn (void *) error;\n}\n\nstatic inline uintptr_t PTR_ERR(const void *ptr)\n{\n\treturn (uintptr_t) ptr;\n}\n\nstatic inline uintptr_t IS_ERR(const void *ptr)\n{\n\treturn IS_ERR_VALUE((uintptr_t)ptr);\n}\n\nstatic inline uintptr_t IS_ERR_OR_NULL(const void *ptr)\n{\n\treturn !ptr || IS_ERR_VALUE((uintptr_t)ptr);\n}\n\nstatic inline int PTR_ERR_OR_ZERO(const void *ptr)\n{\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\telse\n\t\treturn 0;\n}\n\n#endif\n"
        },
        {
          "name": "eta.c",
          "type": "blob",
          "size": 17.04296875,
          "content": "/*\n * Status and ETA code\n */\n#include <unistd.h>\n#include <string.h>\n#include <stdlib.h>\n#ifdef CONFIG_VALGRIND_DEV\n#include <valgrind/drd.h>\n#else\n#define DRD_IGNORE_VAR(x) do { } while (0)\n#endif\n\n#include \"fio.h\"\n#include \"lib/pow2.h\"\n\nstatic char __run_str[REAL_MAX_JOBS + 1];\nstatic char run_str[__THREAD_RUNSTR_SZ(REAL_MAX_JOBS) + 1];\n\nstatic void update_condensed_str(char *rstr, char *run_str_condensed)\n{\n\tif (*rstr) {\n\t\twhile (*rstr) {\n\t\t\tint nr = 1;\n\n\t\t\t*run_str_condensed++ = *rstr++;\n\t\t\twhile (*(rstr - 1) == *rstr) {\n\t\t\t\trstr++;\n\t\t\t\tnr++;\n\t\t\t}\n\t\t\trun_str_condensed += sprintf(run_str_condensed, \"(%u),\", nr);\n\t\t}\n\t\trun_str_condensed--;\n\t}\n\t*run_str_condensed = '\\0';\n}\n\n/*\n * Sets the status of the 'td' in the printed status map.\n */\nstatic void check_str_update(struct thread_data *td)\n{\n\tchar c = __run_str[td->thread_number - 1];\n\n\tswitch (td->runstate) {\n\tcase TD_REAPED:\n\t\tif (td->error)\n\t\t\tc = 'X';\n\t\telse if (td->sig)\n\t\t\tc = 'K';\n\t\telse\n\t\t\tc = '_';\n\t\tbreak;\n\tcase TD_EXITED:\n\t\tc = 'E';\n\t\tbreak;\n\tcase TD_RAMP:\n\t\tc = '/';\n\t\tbreak;\n\tcase TD_RUNNING:\n\t\tif (td_rw(td)) {\n\t\t\tif (td_random(td)) {\n\t\t\t\tif (td->o.rwmix[DDIR_READ] == 100)\n\t\t\t\t\tc = 'r';\n\t\t\t\telse if (td->o.rwmix[DDIR_WRITE] == 100)\n\t\t\t\t\tc = 'w';\n\t\t\t\telse\n\t\t\t\t\tc = 'm';\n\t\t\t} else {\n\t\t\t\tif (td->o.rwmix[DDIR_READ] == 100)\n\t\t\t\t\tc = 'R';\n\t\t\t\telse if (td->o.rwmix[DDIR_WRITE] == 100)\n\t\t\t\t\tc = 'W';\n\t\t\t\telse\n\t\t\t\t\tc = 'M';\n\t\t\t}\n\t\t} else if (td_read(td)) {\n\t\t\tif (td_random(td))\n\t\t\t\tc = 'r';\n\t\t\telse\n\t\t\t\tc = 'R';\n\t\t} else if (td_write(td)) {\n\t\t\tif (td_random(td))\n\t\t\t\tc = 'w';\n\t\t\telse\n\t\t\t\tc = 'W';\n\t\t} else {\n\t\t\tif (td_random(td))\n\t\t\t\tc = 'd';\n\t\t\telse\n\t\t\t\tc = 'D';\n\t\t}\n\t\tbreak;\n\tcase TD_PRE_READING:\n\t\tc = 'p';\n\t\tbreak;\n\tcase TD_VERIFYING:\n\t\tc = 'V';\n\t\tbreak;\n\tcase TD_FSYNCING:\n\t\tc = 'F';\n\t\tbreak;\n\tcase TD_FINISHING:\n\t\tc = 'f';\n\t\tbreak;\n\tcase TD_CREATED:\n\t\tc = 'C';\n\t\tbreak;\n\tcase TD_INITIALIZED:\n\tcase TD_SETTING_UP:\n\t\tc = 'I';\n\t\tbreak;\n\tcase TD_NOT_CREATED:\n\t\tc = 'P';\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"state %d\\n\", td->runstate);\n\t}\n\n\t__run_str[td->thread_number - 1] = c;\n\tupdate_condensed_str(__run_str, run_str);\n}\n\n/*\n * Convert seconds to a printable string.\n */\nvoid eta_to_str(char *str, unsigned long eta_sec)\n{\n\tunsigned int d, h, m, s;\n\tint disp_hour = 0;\n\n\tif (eta_sec == -1) {\n\t\tsprintf(str, \"--\");\n\t\treturn;\n\t}\n\n\ts = eta_sec % 60;\n\teta_sec /= 60;\n\tm = eta_sec % 60;\n\teta_sec /= 60;\n\th = eta_sec % 24;\n\teta_sec /= 24;\n\td = eta_sec;\n\n\tif (d) {\n\t\tdisp_hour = 1;\n\t\tstr += sprintf(str, \"%02ud:\", d);\n\t}\n\n\tif (h || disp_hour)\n\t\tstr += sprintf(str, \"%02uh:\", h);\n\n\tstr += sprintf(str, \"%02um:\", m);\n\tsprintf(str, \"%02us\", s);\n}\n\n/*\n * Best effort calculation of the estimated pending runtime of a job.\n */\nstatic unsigned long thread_eta(struct thread_data *td)\n{\n\tunsigned long long bytes_total, bytes_done;\n\tunsigned long eta_sec = 0;\n\tunsigned long elapsed;\n\tuint64_t timeout;\n\n\telapsed = (mtime_since_now(&td->epoch) + 999) / 1000;\n\ttimeout = td->o.timeout / 1000000UL;\n\n\tbytes_total = td->total_io_size;\n\n\tif (td->flags & TD_F_NO_PROGRESS)\n\t\treturn -1;\n\n\tif (td->o.fill_device && td->o.size  == -1ULL) {\n\t\tif (!td->fill_device_size || td->fill_device_size == -1ULL)\n\t\t\treturn 0;\n\n\t\tbytes_total = td->fill_device_size;\n\t}\n\n\t/*\n\t * If io_size is set, bytes_total is an exact value that does not need\n\t * adjustment.\n\t */\n\tif (td->o.zone_size && td->o.zone_skip && bytes_total &&\n\t    !fio_option_is_set(&td->o, io_size)) {\n\t\tunsigned int nr_zones;\n\t\tuint64_t zone_bytes;\n\n\t\t/*\n\t\t * Calculate the upper bound of the number of zones that will\n\t\t * be processed, including skipped bytes between zones. If this\n\t\t * is larger than total_io_size (e.g. when --io_size or --size\n\t\t * specify a small value), use the lower bound to avoid\n\t\t * adjustments to a negative value that would result in a very\n\t\t * large bytes_total and an incorrect eta.\n\t\t */\n\t\tzone_bytes = td->o.zone_size + td->o.zone_skip;\n\t\tnr_zones = (bytes_total + zone_bytes - 1) / zone_bytes;\n\t\tif (bytes_total < nr_zones * td->o.zone_skip)\n\t\t\tnr_zones = bytes_total / zone_bytes;\n\t\tbytes_total -= nr_zones * td->o.zone_skip;\n\t}\n\n\t/*\n\t * if writing and verifying afterwards, bytes_total will be twice the\n\t * size. In a mixed workload, verify phase will be the size of the\n\t * first stage writes.\n\t */\n\tif (td->o.do_verify && td->o.verify && td_write(td)) {\n\t\tif (td_rw(td)) {\n\t\t\tunsigned int perc = 50;\n\n\t\t\tif (td->o.rwmix[DDIR_WRITE])\n\t\t\t\tperc = td->o.rwmix[DDIR_WRITE];\n\n\t\t\tbytes_total += (bytes_total * perc) / 100;\n\t\t} else {\n\t\t\tbytes_total <<= 1;\n\t\t}\n\t}\n\n\tif (td->runstate == TD_RUNNING || td->runstate == TD_VERIFYING) {\n\t\tdouble perc, perc_t;\n\n\t\tbytes_done = ddir_rw_sum(td->io_bytes);\n\n\t\tif (bytes_total) {\n\t\t\tperc = (double) bytes_done / (double) bytes_total;\n\t\t\tif (perc > 1.0)\n\t\t\t\tperc = 1.0;\n\t\t} else {\n\t\t\tperc = 0.0;\n\t\t}\n\n\t\tif (td->o.time_based) {\n\t\t\tif (timeout) {\n\t\t\t\tperc_t = (double) elapsed / (double) timeout;\n\t\t\t\tif (perc_t < perc)\n\t\t\t\t\tperc = perc_t;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * Will never hit, we can't have time_based\n\t\t\t\t * without a timeout set.\n\t\t\t\t */\n\t\t\t\tperc = 0.0;\n\t\t\t}\n\t\t}\n\n\t\tif (perc == 0.0) {\n\t\t\teta_sec = timeout;\n\t\t} else {\n\t\t\teta_sec = (unsigned long) (elapsed * (1.0 / perc)) - elapsed;\n\t\t}\n\n\t\tif (td->o.timeout &&\n\t\t    eta_sec > (timeout + done_secs - elapsed))\n\t\t\teta_sec = timeout + done_secs - elapsed;\n\t} else if (td->runstate == TD_NOT_CREATED || td->runstate == TD_CREATED\n\t\t\t|| td->runstate == TD_INITIALIZED\n\t\t\t|| td->runstate == TD_SETTING_UP\n\t\t\t|| td->runstate == TD_RAMP\n\t\t\t|| td->runstate == TD_PRE_READING) {\n\t\tint64_t t_eta = 0, r_eta = 0;\n\t\tunsigned long long rate_bytes;\n\n\t\t/*\n\t\t * We can only guess - assume it'll run the full timeout\n\t\t * if given, otherwise assume it'll run at the specified rate.\n\t\t */\n\t\tif (td->o.timeout) {\n\t\t\tuint64_t __timeout = td->o.timeout;\n\t\t\tuint64_t start_delay = td->o.start_delay;\n\t\t\tuint64_t ramp_time = td->o.ramp_time;\n\n\t\t\tt_eta = __timeout + start_delay;\n\t\t\tif (!td->ramp_time_over) {\n\t\t\t\tt_eta += ramp_time;\n\t\t\t}\n\t\t\tt_eta /= 1000000ULL;\n\n\t\t\tif ((td->runstate == TD_RAMP) && in_ramp_time(td)) {\n\t\t\t\tunsigned long ramp_left;\n\n\t\t\t\tramp_left = mtime_since_now(&td->epoch);\n\t\t\t\tramp_left = (ramp_left + 999) / 1000;\n\t\t\t\tif (ramp_left <= t_eta)\n\t\t\t\t\tt_eta -= ramp_left;\n\t\t\t}\n\t\t}\n\t\trate_bytes = 0;\n\t\tif (td_read(td))\n\t\t\trate_bytes  = td->o.rate[DDIR_READ];\n\t\tif (td_write(td))\n\t\t\trate_bytes += td->o.rate[DDIR_WRITE];\n\t\tif (td_trim(td))\n\t\t\trate_bytes += td->o.rate[DDIR_TRIM];\n\n\t\tif (rate_bytes) {\n\t\t\tr_eta = bytes_total / rate_bytes;\n\t\t\tr_eta += (td->o.start_delay / 1000000ULL);\n\t\t}\n\n\t\tif (r_eta && t_eta)\n\t\t\teta_sec = min(r_eta, t_eta);\n\t\telse if (r_eta)\n\t\t\teta_sec = r_eta;\n\t\telse if (t_eta)\n\t\t\teta_sec = t_eta;\n\t\telse\n\t\t\teta_sec = 0;\n\t} else {\n\t\t/*\n\t\t * thread is already done or waiting for fsync\n\t\t */\n\t\teta_sec = 0;\n\t}\n\n\treturn eta_sec;\n}\n\nstatic void calc_rate(int unified_rw_rep, unsigned long mtime,\n\t\t      unsigned long long *io_bytes,\n\t\t      unsigned long long *prev_io_bytes, uint64_t *rate)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tunsigned long long diff, this_rate;\n\n\t\tdiff = io_bytes[i] - prev_io_bytes[i];\n\t\tif (mtime)\n\t\t\tthis_rate = ((1000 * diff) / mtime) / 1024; /* KiB/s */\n\t\telse\n\t\t\tthis_rate = 0;\n\n\t\tif (unified_rw_rep == UNIFIED_MIXED) {\n\t\t\trate[i] = 0;\n\t\t\trate[0] += this_rate;\n\t\t} else\n\t\t\trate[i] = this_rate;\n\n\t\tprev_io_bytes[i] = io_bytes[i];\n\t}\n}\n\nstatic void calc_iops(int unified_rw_rep, unsigned long mtime,\n\t\t      unsigned long long *io_iops,\n\t\t      unsigned long long *prev_io_iops, unsigned int *iops)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tunsigned long long diff, this_iops;\n\n\t\tdiff = io_iops[i] - prev_io_iops[i];\n\t\tif (mtime)\n\t\t\tthis_iops = (diff * 1000) / mtime;\n\t\telse\n\t\t\tthis_iops = 0;\n\n\t\tif (unified_rw_rep == UNIFIED_MIXED) {\n\t\t\tiops[i] = 0;\n\t\t\tiops[0] += this_iops;\n\t\t} else\n\t\t\tiops[i] = this_iops;\n\n\t\tprev_io_iops[i] = io_iops[i];\n\t}\n}\n\n/*\n * Allow a little slack - if we're within 95% of the time, allow ETA.\n */\nbool eta_time_within_slack(unsigned int time)\n{\n\treturn time > ((eta_interval_msec * 95) / 100);\n}\n\n/*\n * These are the conditions under which we might be able to skip the eta\n * calculation.\n */\nstatic bool skip_eta()\n{\n\tif (!(output_format & FIO_OUTPUT_NORMAL) && f_out == stdout)\n\t\treturn true;\n\tif (temp_stall_ts || eta_print == FIO_ETA_NEVER)\n\t\treturn true;\n\tif (!isatty(STDOUT_FILENO) && eta_print != FIO_ETA_ALWAYS)\n\t\treturn true;\n\n\treturn false;\n}\n\n/*\n * Print status of the jobs we know about. This includes rate estimates,\n * ETA, thread state, etc.\n */\nstatic bool calc_thread_status(struct jobs_eta *je, int force)\n{\n\tint unified_rw_rep;\n\tbool any_td_in_ramp;\n\tuint64_t rate_time, disp_time, bw_avg_time, *eta_secs;\n\tunsigned long long io_bytes[DDIR_RWDIR_CNT] = {};\n\tunsigned long long io_iops[DDIR_RWDIR_CNT] = {};\n\tstruct timespec now;\n\n\tstatic unsigned long long rate_io_bytes[DDIR_RWDIR_CNT];\n\tstatic unsigned long long disp_io_bytes[DDIR_RWDIR_CNT];\n\tstatic unsigned long long disp_io_iops[DDIR_RWDIR_CNT];\n\tstatic struct timespec rate_prev_time, disp_prev_time;\n\n\tbool ret = true;\n\n\tif (!force && skip_eta()) {\n\t\tif (write_bw_log)\n\t\t\tret = false;\n\t\telse\n\t\t\treturn false;\n\t}\n\n\tif (!ddir_rw_sum(rate_io_bytes))\n\t\tfill_start_time(&rate_prev_time);\n\tif (!ddir_rw_sum(disp_io_bytes))\n\t\tfill_start_time(&disp_prev_time);\n\n\teta_secs = calloc(thread_number, sizeof(uint64_t));\n\n\tje->elapsed_sec = (mtime_since_genesis() + 999) / 1000;\n\n\tbw_avg_time = ULONG_MAX;\n\tunified_rw_rep = 0;\n\tfor_each_td(td) {\n\t\tunified_rw_rep += td->o.unified_rw_rep;\n\t\tif (is_power_of_2(td->o.kb_base))\n\t\t\tje->is_pow2 = 1;\n\t\tje->unit_base = td->o.unit_base;\n\t\tje->sig_figs = td->o.sig_figs;\n\t\tif (td->o.bw_avg_time < bw_avg_time)\n\t\t\tbw_avg_time = td->o.bw_avg_time;\n\t\tif (td->runstate == TD_RUNNING || td->runstate == TD_VERIFYING\n\t\t    || td->runstate == TD_FSYNCING\n\t\t    || td->runstate == TD_PRE_READING\n\t\t    || td->runstate == TD_FINISHING) {\n\t\t\tje->nr_running++;\n\t\t\tif (td_read(td)) {\n\t\t\t\tje->t_rate[0] += td->o.rate[DDIR_READ];\n\t\t\t\tje->t_iops[0] += td->o.rate_iops[DDIR_READ];\n\t\t\t\tje->m_rate[0] += td->o.ratemin[DDIR_READ];\n\t\t\t\tje->m_iops[0] += td->o.rate_iops_min[DDIR_READ];\n\t\t\t}\n\t\t\tif (td_write(td)) {\n\t\t\t\tje->t_rate[1] += td->o.rate[DDIR_WRITE];\n\t\t\t\tje->t_iops[1] += td->o.rate_iops[DDIR_WRITE];\n\t\t\t\tje->m_rate[1] += td->o.ratemin[DDIR_WRITE];\n\t\t\t\tje->m_iops[1] += td->o.rate_iops_min[DDIR_WRITE];\n\t\t\t}\n\t\t\tif (td_trim(td)) {\n\t\t\t\tje->t_rate[2] += td->o.rate[DDIR_TRIM];\n\t\t\t\tje->t_iops[2] += td->o.rate_iops[DDIR_TRIM];\n\t\t\t\tje->m_rate[2] += td->o.ratemin[DDIR_TRIM];\n\t\t\t\tje->m_iops[2] += td->o.rate_iops_min[DDIR_TRIM];\n\t\t\t}\n\n\t\t\tje->files_open += td->nr_open_files;\n\t\t} else if (td->runstate == TD_RAMP) {\n\t\t\tje->nr_running++;\n\t\t\tje->nr_ramp++;\n\t\t} else if (td->runstate == TD_SETTING_UP)\n\t\t\tje->nr_setting_up++;\n\t\telse if (td->runstate < TD_RUNNING)\n\t\t\tje->nr_pending++;\n\n\t\tif (je->elapsed_sec >= 3)\n\t\t\teta_secs[__td_index] = thread_eta(td);\n\t\telse\n\t\t\teta_secs[__td_index] = INT_MAX;\n\n\t\tcheck_str_update(td);\n\n\t\tif (td->runstate > TD_SETTING_UP) {\n\t\t\tint ddir;\n\n\t\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\t\tif (unified_rw_rep) {\n\t\t\t\t\tio_bytes[0] += td->io_bytes[ddir];\n\t\t\t\t\tio_iops[0] += td->io_blocks[ddir];\n\t\t\t\t} else {\n\t\t\t\t\tio_bytes[ddir] += td->io_bytes[ddir];\n\t\t\t\t\tio_iops[ddir] += td->io_blocks[ddir];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} end_for_each();\n\n\tif (exitall_on_terminate) {\n\t\tje->eta_sec = INT_MAX;\n\t\tfor_each_td_index() {\n\t\t\tif (eta_secs[__td_index] < je->eta_sec)\n\t\t\t\tje->eta_sec = eta_secs[__td_index];\n\t\t} end_for_each();\n\t} else {\n\t\tunsigned long eta_stone = 0;\n\n\t\tje->eta_sec = 0;\n\t\tfor_each_td(td) {\n\t\t\tif ((td->runstate == TD_NOT_CREATED) && td->o.stonewall)\n\t\t\t\teta_stone += eta_secs[__td_index];\n\t\t\telse {\n\t\t\t\tif (eta_secs[__td_index] > je->eta_sec)\n\t\t\t\t\tje->eta_sec = eta_secs[__td_index];\n\t\t\t}\n\t\t} end_for_each();\n\t\tje->eta_sec += eta_stone;\n\t}\n\n\tfree(eta_secs);\n\n\tfio_gettime(&now, NULL);\n\trate_time = mtime_since(&rate_prev_time, &now);\n\n\tany_td_in_ramp = false;\n\tfor_each_td(td) {\n\t\tany_td_in_ramp |= in_ramp_time(td);\n\t} end_for_each();\n\tif (write_bw_log && rate_time > bw_avg_time && !any_td_in_ramp) {\n\t\tcalc_rate(unified_rw_rep, rate_time, io_bytes, rate_io_bytes,\n\t\t\t\tje->rate);\n\t\tmemcpy(&rate_prev_time, &now, sizeof(now));\n\t\tregrow_agg_logs();\n\t\tfor_each_rw_ddir(ddir) {\n\t\t\tadd_agg_sample(sample_val(je->rate[ddir]), ddir, 0);\n\t\t}\n\t}\n\n\tdisp_time = mtime_since(&disp_prev_time, &now);\n\n\tif (!force && !eta_time_within_slack(disp_time))\n\t\treturn false;\n\n\tcalc_rate(unified_rw_rep, disp_time, io_bytes, disp_io_bytes, je->rate);\n\tcalc_iops(unified_rw_rep, disp_time, io_iops, disp_io_iops, je->iops);\n\n\tmemcpy(&disp_prev_time, &now, sizeof(now));\n\n\tif (!force && !je->nr_running && !je->nr_pending)\n\t\treturn false;\n\n\tje->nr_threads = thread_number;\n\tupdate_condensed_str(__run_str, run_str);\n\tmemcpy(je->run_str, run_str, strlen(run_str));\n\treturn ret;\n}\n\nstatic int gen_eta_str(struct jobs_eta *je, char *p, size_t left,\n\t\t       char **rate_str, char **iops_str)\n{\n\tstatic const char c[DDIR_RWDIR_CNT] = {'r', 'w', 't'};\n\tbool has[DDIR_RWDIR_CNT];\n\tbool has_any = false;\n\tconst char *sep;\n\tint l = 0;\n\n\tfor_each_rw_ddir(ddir) {\n\t\thas[ddir] = (je->rate[ddir] || je->iops[ddir]);\n\t\thas_any |= has[ddir];\n\t}\n\tif (!has_any)\n\t\treturn 0;\n\n\tl += snprintf(p + l, left - l, \"[\");\n\tsep = \"\";\n\tfor_each_rw_ddir(ddir) {\n\t\tif (has[ddir]) {\n\t\t\tl += snprintf(p + l, left - l, \"%s%c=%s\",\n\t\t\t\t\tsep, c[ddir], rate_str[ddir]);\n\t\t\tsep = \",\";\n\t\t}\n\t}\n\tl += snprintf(p + l, left - l, \"][\");\n\tsep = \"\";\n\tfor_each_rw_ddir(ddir) {\n\t\tif (has[ddir]) {\n\t\t\tl += snprintf(p + l, left - l, \"%s%c=%s\",\n\t\t\t\t\tsep, c[ddir], iops_str[ddir]);\n\t\t\tsep = \",\";\n\t\t}\n\t}\n\tl += snprintf(p + l, left - l, \" IOPS]\");\n\n\treturn l;\n}\n\nvoid display_thread_status(struct jobs_eta *je)\n{\n\tstatic struct timespec disp_eta_new_line;\n\tstatic int eta_new_line_init, eta_new_line_pending;\n\tstatic int linelen_last;\n\tstatic int eta_good;\n\tchar output[__THREAD_RUNSTR_SZ(REAL_MAX_JOBS) + 512], *p = output;\n\tchar eta_str[128];\n\tdouble perc = 0.0;\n\n\tif (je->eta_sec != INT_MAX && je->elapsed_sec) {\n\t\tperc = (double) je->elapsed_sec / (double) (je->elapsed_sec + je->eta_sec);\n\t\teta_to_str(eta_str, je->eta_sec);\n\t}\n\n\tif (eta_new_line_pending) {\n\t\teta_new_line_pending = 0;\n\t\tlinelen_last = 0;\n\t\tp += sprintf(p, \"\\n\");\n\t}\n\n\tp += sprintf(p, \"Jobs: %d (f=%d)\", je->nr_running, je->files_open);\n\n\t/* rate limits, if any */\n\tif (je->m_rate[0] || je->m_rate[1] || je->m_rate[2] ||\n\t    je->t_rate[0] || je->t_rate[1] || je->t_rate[2]) {\n\t\tchar *tr, *mr;\n\n\t\tmr = num2str(je->m_rate[0] + je->m_rate[1] + je->m_rate[2],\n\t\t\t\tje->sig_figs, 1, je->is_pow2, N2S_BYTEPERSEC);\n\t\ttr = num2str(je->t_rate[0] + je->t_rate[1] + je->t_rate[2],\n\t\t\t\tje->sig_figs, 1, je->is_pow2, N2S_BYTEPERSEC);\n\n\t\tp += sprintf(p, \", %s-%s\", mr, tr);\n\t\tfree(tr);\n\t\tfree(mr);\n\t} else if (je->m_iops[0] || je->m_iops[1] || je->m_iops[2] ||\n\t\t   je->t_iops[0] || je->t_iops[1] || je->t_iops[2]) {\n\t\tp += sprintf(p, \", %d-%d IOPS\",\n\t\t\t\t\tje->m_iops[0] + je->m_iops[1] + je->m_iops[2],\n\t\t\t\t\tje->t_iops[0] + je->t_iops[1] + je->t_iops[2]);\n\t}\n\n\t/* current run string, % done, bandwidth, iops, eta */\n\tif (je->eta_sec != INT_MAX && je->nr_running) {\n\t\tchar perc_str[32];\n\t\tchar *iops_str[DDIR_RWDIR_CNT];\n\t\tchar *rate_str[DDIR_RWDIR_CNT];\n\t\tsize_t left;\n\t\tint l;\n\t\tint ddir;\n\t\tint linelen;\n\n\t\tif ((!je->eta_sec && !eta_good) || je->nr_ramp == je->nr_running ||\n\t\t    je->eta_sec == -1)\n\t\t\tstrcpy(perc_str, \"-.-%\");\n\t\telse {\n\t\t\tdouble mult = 100.0;\n\n\t\t\tif (je->nr_setting_up && je->nr_running)\n\t\t\t\tmult *= (1.0 - (double) je->nr_setting_up / (double) je->nr_running);\n\n\t\t\teta_good = 1;\n\t\t\tperc *= mult;\n\t\t\tsprintf(perc_str, \"%3.1f%%\", perc);\n\t\t}\n\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\trate_str[ddir] = num2str(je->rate[ddir], 4,\n\t\t\t\t\t\t1024, je->is_pow2, je->unit_base);\n\t\t\tiops_str[ddir] = num2str(je->iops[ddir], 4, 1, 0, N2S_NONE);\n\t\t}\n\n\t\tleft = sizeof(output) - (p - output) - 1;\n\t\tl = snprintf(p, left, \": [%s][%s]\", je->run_str, perc_str);\n\t\tl += gen_eta_str(je, p + l, left - l, rate_str, iops_str);\n\t\tl += snprintf(p + l, left - l, \"[eta %s]\", eta_str);\n\n\t\t/* If truncation occurred adjust l so p is on the null */\n\t\tif (l >= left)\n\t\t\tl = left - 1;\n\t\tp += l;\n\t\tlinelen = p - output;\n\t\tif (l >= 0 && linelen < linelen_last)\n\t\t\tp += sprintf(p, \"%*s\", linelen_last - linelen, \"\");\n\t\tlinelen_last = linelen;\n\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\tfree(rate_str[ddir]);\n\t\t\tfree(iops_str[ddir]);\n\t\t}\n\t}\n\tsprintf(p, \"\\r\");\n\n\tprintf(\"%s\", output);\n\n\tif (!eta_new_line_init) {\n\t\tfio_gettime(&disp_eta_new_line, NULL);\n\t\teta_new_line_init = 1;\n\t} else if (eta_new_line && mtime_since_now(&disp_eta_new_line) > eta_new_line) {\n\t\tfio_gettime(&disp_eta_new_line, NULL);\n\t\teta_new_line_pending = 1;\n\t}\n\n\tfflush(stdout);\n}\n\nstruct jobs_eta *get_jobs_eta(bool force, size_t *size)\n{\n\tstruct jobs_eta *je;\n\n\tif (!thread_number)\n\t\treturn NULL;\n\n\t*size = sizeof(*je) + THREAD_RUNSTR_SZ + 8;\n\tje = calloc(1, *size);\n\tif (!je)\n\t\treturn NULL;\n\n\tif (!calc_thread_status(je, force)) {\n\t\tfree(je);\n\t\treturn NULL;\n\t}\n\n\t*size = sizeof(*je) + strlen((char *) je->run_str) + 1;\n\treturn je;\n}\n\nvoid print_thread_status(void)\n{\n\tstruct jobs_eta *je;\n\tsize_t size;\n\n\tje = get_jobs_eta(false, &size);\n\tif (je) {\n\t\tdisplay_thread_status(je);\n\t\tfree(je);\n\t}\n}\n\nvoid print_status_init(int thr_number)\n{\n\tstruct jobs_eta_packed jep;\n\n\tcompiletime_assert(sizeof(struct jobs_eta) == sizeof(jep), \"jobs_eta\");\n\n\tDRD_IGNORE_VAR(__run_str);\n\t__run_str[thr_number] = 'P';\n\tupdate_condensed_str(__run_str, run_str);\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "exp",
          "type": "tree",
          "content": null
        },
        {
          "name": "fifo.c",
          "type": "blob",
          "size": 2.294921875,
          "content": "/*\n * A simple kernel FIFO implementation.\n *\n * Copyright (C) 2004 Stelian Pop <stelian@popies.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"fifo.h\"\n#include \"minmax.h\"\n\nstruct fifo *fifo_alloc(unsigned int size)\n{\n\tstruct fifo *fifo;\n\n\tfifo = malloc(sizeof(struct fifo));\n\tif (!fifo)\n\t\treturn NULL;\n\n\tfifo->buffer = malloc(size);\n\tfifo->size = size;\n\tfifo->in = fifo->out = 0;\n\n\treturn fifo;\n}\n\nvoid fifo_free(struct fifo *fifo)\n{\n\tfree(fifo->buffer);\n\tfree(fifo);\n}\n\nunsigned int fifo_put(struct fifo *fifo, void *buffer, unsigned int len)\n{\n\tunsigned int l;\n\n\tlen = min(len, fifo_room(fifo));\n\n\t/* first put the data starting from fifo->in to buffer end */\n\tl = min(len, fifo->size - (fifo->in & (fifo->size - 1)));\n\tmemcpy(fifo->buffer + (fifo->in & (fifo->size - 1)), buffer, l);\n\n\t/* then put the rest (if any) at the beginning of the buffer */\n\tmemcpy(fifo->buffer, buffer + l, len - l);\n\n\t/*\n\t * Ensure that we add the bytes to the fifo -before-\n\t * we update the fifo->in index.\n\t */\n\n\tfifo->in += len;\n\n\treturn len;\n}\n\nunsigned int fifo_get(struct fifo *fifo, void *buf, unsigned int len)\n{\n\tlen = min(len, fifo->in - fifo->out);\n\n\tif (buf) {\n\t\tunsigned int l;\n\n\t\t/*\n\t\t * first get the data from fifo->out until the end of the buffer\n\t\t */\n\t\tl = min(len, fifo->size - (fifo->out & (fifo->size - 1)));\n\t\tmemcpy(buf, fifo->buffer + (fifo->out & (fifo->size - 1)), l);\n\n\t\t/*\n\t\t * then get the rest (if any) from the beginning of the buffer\n\t\t */\n\t\tmemcpy(buf + l, fifo->buffer, len - l);\n\t}\n\n\tfifo->out += len;\n\n\tif (fifo->in == fifo->out)\n\t\tfifo->in = fifo->out = 0;\n\n\treturn len;\n}\n"
        },
        {
          "name": "fifo.h",
          "type": "blob",
          "size": 1.478515625,
          "content": "#ifndef FIO_FIFO_H\n#define FIO_FIFO_H\n/*\n * A simple FIFO implementation.\n *\n * Copyright (C) 2004 Stelian Pop <stelian@popies.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n\nstruct fifo {\n\tunsigned char *buffer;\t/* the buffer holding the data */\n\tunsigned int size;\t/* the size of the allocated buffer */\n\tunsigned int in;\t/* data is added at offset (in % size) */\n\tunsigned int out;\t/* data is extracted from off. (out % size) */\n};\n\nstruct fifo *fifo_alloc(unsigned int);\nunsigned int fifo_put(struct fifo *, void *, unsigned int);\nunsigned int fifo_get(struct fifo *, void *, unsigned int);\nvoid fifo_free(struct fifo *);\n\nstatic inline unsigned int fifo_len(struct fifo *fifo)\n{\n\treturn fifo->in - fifo->out;\n}\n\nstatic inline unsigned int fifo_room(struct fifo *fifo)\n{\n\treturn fifo->size - fifo->in + fifo->out;\n}\n\n#endif\n"
        },
        {
          "name": "file.h",
          "type": "blob",
          "size": 6.6044921875,
          "content": "#ifndef FIO_FILE_H\n#define FIO_FILE_H\n\n#include <string.h>\n#include \"compiler/compiler.h\"\n#include \"io_ddir.h\"\n#include \"flist.h\"\n#include \"lib/zipf.h\"\n#include \"lib/axmap.h\"\n#include \"lib/lfsr.h\"\n#include \"lib/gauss.h\"\n\n/* Forward declarations */\nstruct zoned_block_device_info;\nstruct fdp_ruh_info;\n\n/*\n * The type of object we are working on\n */\nenum fio_filetype {\n\tFIO_TYPE_FILE = 1,\t\t/* plain file */\n\tFIO_TYPE_BLOCK,\t\t\t/* block device */\n\tFIO_TYPE_CHAR,\t\t\t/* character device */\n\tFIO_TYPE_PIPE,\t\t\t/* pipe */\n};\n\nenum fio_file_flags {\n\tFIO_FILE_open\t\t= 1 << 0,\t/* file is open */\n\tFIO_FILE_closing\t= 1 << 1,\t/* file being closed */\n\tFIO_FILE_extend\t\t= 1 << 2,\t/* needs extend */\n\tFIO_FILE_done\t\t= 1 << 3,\t/* io completed to this file */\n\tFIO_FILE_size_known\t= 1 << 4,\t/* size has been set */\n\tFIO_FILE_hashed\t\t= 1 << 5,\t/* file is on hash */\n\tFIO_FILE_partial_mmap\t= 1 << 6,\t/* can't do full mmap */\n\tFIO_FILE_axmap\t\t= 1 << 7,\t/* uses axmap */\n\tFIO_FILE_lfsr\t\t= 1 << 8,\t/* lfsr is used */\n\tFIO_FILE_smalloc\t= 1 << 9,\t/* smalloc file/file_name */\n};\n\nenum file_lock_mode {\n\tFILE_LOCK_NONE,\n\tFILE_LOCK_EXCLUSIVE,\n\tFILE_LOCK_READWRITE,\n};\n\n/*\n * How fio chooses what file to service next. Choice of uniformly random, or\n * some skewed random variants, or just sequentially go through them or\n * roundrobing.\n */\nenum {\n\tFIO_FSERVICE_RANDOM\t\t= 1,\n\tFIO_FSERVICE_RR\t\t\t= 2,\n\tFIO_FSERVICE_SEQ\t\t= 3,\n\t__FIO_FSERVICE_NONUNIFORM\t= 0x100,\n\tFIO_FSERVICE_ZIPF\t\t= __FIO_FSERVICE_NONUNIFORM | 4,\n\tFIO_FSERVICE_PARETO\t\t= __FIO_FSERVICE_NONUNIFORM | 5,\n\tFIO_FSERVICE_GAUSS\t\t= __FIO_FSERVICE_NONUNIFORM | 6,\n\n\tFIO_FSERVICE_SHIFT\t\t= 10,\n};\n\n/*\n * No pre-allocation when laying down files, or call posix_fallocate(), or\n * call fallocate() with FALLOC_FL_KEEP_SIZE set.\n */\nenum fio_fallocate_mode {\n\tFIO_FALLOCATE_NONE\t= 1,\n\tFIO_FALLOCATE_POSIX\t= 2,\n\tFIO_FALLOCATE_KEEP_SIZE\t= 3,\n\tFIO_FALLOCATE_NATIVE\t= 4,\n\tFIO_FALLOCATE_TRUNCATE\t= 5,\n};\n\n/*\n * Each thread_data structure has a number of files associated with it,\n * this structure holds state information for a single file.\n */\nstruct fio_file {\n\tstruct flist_head hash_list;\n\tenum fio_filetype filetype;\n\n\tint fd;\n\tint shadow_fd;\n#ifdef WIN32\n\tHANDLE hFile;\n\tHANDLE ioCP;\n#endif\n\n\t/*\n\t * filename and possible memory mapping\n\t */\n\tunsigned int major, minor;\n\tint fileno;\n\tchar *file_name;\n\n\t/*\n\t * size of the file, offset into file, and io size from that offset\n\t * (be aware io_size is different from thread_options::io_size)\n\t */\n\tuint64_t real_file_size;\n\tuint64_t file_offset;\n\tuint64_t io_size;\n\n\tstruct fio_ruhs_info *ruhs_info;\n\tstruct fio_ruhs_scheme *ruhs_scheme;\n\n\t/*\n\t * Zoned block device information. See also zonemode=zbd.\n\t */\n\tstruct zoned_block_device_info *zbd_info;\n\t/* zonemode=zbd working area */\n\tuint32_t min_zone;\t/* inclusive */\n\tuint32_t max_zone;\t/* exclusive */\n\n\t/*\n\t * Track last end and last start of IO for a given data direction\n\t */\n\tuint64_t last_pos[DDIR_RWDIR_CNT];\n\tuint64_t last_start[DDIR_RWDIR_CNT];\n\n\tuint64_t first_write;\n\tuint64_t last_write;\n\n\t/*\n\t * Tracks the last iodepth number of completed writes, if data\n\t * verification is enabled\n\t */\n\tuint64_t *last_write_comp;\n\tunsigned int last_write_idx;\n\n\t/*\n\t * For use by the io engine to store offset\n\t */\n\tuint64_t engine_pos;\n\n\t/*\n\t * For use by the io engine for private data storage\n\t */\n\tvoid *engine_data;\n\n\t/*\n\t * if io is protected by a semaphore, this is set\n\t */\n\tunion {\n\t\tstruct fio_sem *lock;\n\t\tstruct fio_rwlock *rwlock;\n\t};\n\n\t/*\n\t * block map or LFSR for random io\n\t */\n\tunion {\n\t\tstruct axmap *io_axmap;\n\t\tstruct fio_lfsr lfsr;\n\t};\n\n\t/*\n\t * Used for zipf random distribution\n\t */\n\tunion {\n\t\tstruct zipf_state zipf;\n\t\tstruct gauss_state gauss;\n\t};\n\n\tint references;\n\tenum fio_file_flags flags;\n\n\tstruct disk_util *du;\n};\n\n#define FILE_ENG_DATA(f)\t\t((f)->engine_data)\n#define FILE_SET_ENG_DATA(f, data)\t((f)->engine_data = (data))\n\n#define FILE_FLAG_FNS(name)\t\t\t\t\t\t\\\nstatic inline void fio_file_set_##name(struct fio_file *f)\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\t(f)->flags = (enum fio_file_flags) ((f)->flags | FIO_FILE_##name);\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic inline void fio_file_clear_##name(struct fio_file *f)\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\t(f)->flags = (enum fio_file_flags) ((f)->flags & ~FIO_FILE_##name);\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic inline int fio_file_##name(struct fio_file *f)\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn ((f)->flags & FIO_FILE_##name) != 0;\t\t\t\\\n}\n\nFILE_FLAG_FNS(open);\nFILE_FLAG_FNS(closing);\nFILE_FLAG_FNS(extend);\nFILE_FLAG_FNS(done);\nFILE_FLAG_FNS(size_known);\nFILE_FLAG_FNS(hashed);\nFILE_FLAG_FNS(partial_mmap);\nFILE_FLAG_FNS(axmap);\nFILE_FLAG_FNS(lfsr);\nFILE_FLAG_FNS(smalloc);\n#undef FILE_FLAG_FNS\n\n/*\n * File setup/shutdown\n */\nstruct thread_data;\nextern void close_files(struct thread_data *);\nextern void close_and_free_files(struct thread_data *);\nextern uint64_t get_start_offset(struct thread_data *, struct fio_file *);\nextern int __must_check setup_files(struct thread_data *);\nextern int __must_check file_invalidate_cache(struct thread_data *, struct fio_file *);\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nextern int __must_check generic_open_file(struct thread_data *, struct fio_file *);\nextern int __must_check generic_close_file(struct thread_data *, struct fio_file *);\nextern int __must_check generic_get_file_size(struct thread_data *, struct fio_file *);\nextern int __must_check generic_prepopulate_file(struct thread_data *, struct fio_file *);\n#ifdef __cplusplus\n}\n#endif\nextern int __must_check file_lookup_open(struct fio_file *f, int flags);\nextern bool __must_check pre_read_files(struct thread_data *);\nextern unsigned long long get_rand_file_size(struct thread_data *td);\nextern int add_file(struct thread_data *, const char *, int, int);\nextern int add_file_exclusive(struct thread_data *, const char *);\nextern void get_file(struct fio_file *);\nextern int __must_check put_file(struct thread_data *, struct fio_file *);\nextern void put_file_log(struct thread_data *, struct fio_file *);\nextern void lock_file(struct thread_data *, struct fio_file *, enum fio_ddir);\nextern void unlock_file(struct thread_data *, struct fio_file *);\nextern void unlock_file_all(struct thread_data *, struct fio_file *);\nextern int add_dir_files(struct thread_data *, const char *);\nextern bool init_random_map(struct thread_data *);\nextern void dup_files(struct thread_data *, struct thread_data *);\nextern int get_fileno(struct thread_data *, const char *);\nextern void free_release_files(struct thread_data *);\nextern void filesetup_mem_free(void);\nextern void fio_file_reset(struct thread_data *, struct fio_file *);\nextern bool fio_files_done(struct thread_data *);\nextern bool exists_and_not_regfile(const char *);\nextern int fio_set_directio(struct thread_data *, struct fio_file *);\nextern void fio_file_free(struct fio_file *);\n\n#endif\n"
        },
        {
          "name": "filehash.c",
          "type": "blob",
          "size": 2.5107421875,
          "content": "#include <stdlib.h>\n#include <assert.h>\n\n#include \"fio.h\"\n#include \"flist.h\"\n#include \"hash.h\"\n#include \"filehash.h\"\n#include \"smalloc.h\"\n#include \"lib/bloom.h\"\n\n#define HASH_BUCKETS\t512\n#define HASH_MASK\t(HASH_BUCKETS - 1)\n\n#define BLOOM_SIZE\t16*1024*1024\n\nstatic unsigned int file_hash_size = HASH_BUCKETS * sizeof(struct flist_head);\n\nstatic struct flist_head *file_hash;\nstatic struct fio_sem *hash_lock;\nstatic struct bloom *file_bloom;\n\nstatic unsigned short hash(const char *name)\n{\n\treturn jhash(name, strlen(name), 0) & HASH_MASK;\n}\n\nvoid fio_file_hash_lock(void)\n{\n\tif (hash_lock)\n\t\tfio_sem_down(hash_lock);\n}\n\nvoid fio_file_hash_unlock(void)\n{\n\tif (hash_lock)\n\t\tfio_sem_up(hash_lock);\n}\n\nvoid remove_file_hash(struct fio_file *f)\n{\n\tfio_sem_down(hash_lock);\n\n\tif (fio_file_hashed(f)) {\n\t\tassert(!flist_empty(&f->hash_list));\n\t\tflist_del_init(&f->hash_list);\n\t\tfio_file_clear_hashed(f);\n\t}\n\n\tfio_sem_up(hash_lock);\n}\n\nstatic struct fio_file *__lookup_file_hash(const char *name)\n{\n\tstruct flist_head *bucket = &file_hash[hash(name)];\n\tstruct flist_head *n;\n\n\tflist_for_each(n, bucket) {\n\t\tstruct fio_file *f = flist_entry(n, struct fio_file, hash_list);\n\n\t\tif (!f->file_name)\n\t\t\tcontinue;\n\n\t\tif (!strcmp(f->file_name, name))\n\t\t\treturn f;\n\t}\n\n\treturn NULL;\n}\n\nstruct fio_file *lookup_file_hash(const char *name)\n{\n\tstruct fio_file *f;\n\n\tfio_sem_down(hash_lock);\n\tf = __lookup_file_hash(name);\n\tfio_sem_up(hash_lock);\n\treturn f;\n}\n\nstruct fio_file *add_file_hash(struct fio_file *f)\n{\n\tstruct fio_file *alias;\n\n\tif (fio_file_hashed(f))\n\t\treturn NULL;\n\n\tINIT_FLIST_HEAD(&f->hash_list);\n\n\tfio_sem_down(hash_lock);\n\n\talias = __lookup_file_hash(f->file_name);\n\tif (!alias) {\n\t\tfio_file_set_hashed(f);\n\t\tflist_add_tail(&f->hash_list, &file_hash[hash(f->file_name)]);\n\t}\n\n\tfio_sem_up(hash_lock);\n\treturn alias;\n}\n\nbool file_bloom_exists(const char *fname, bool set)\n{\n\treturn bloom_string(file_bloom, fname, strlen(fname), set);\n}\n\nvoid file_hash_exit(void)\n{\n\tunsigned int i, has_entries = 0;\n\n\tfio_sem_down(hash_lock);\n\tfor (i = 0; i < HASH_BUCKETS; i++)\n\t\thas_entries += !flist_empty(&file_hash[i]);\n\tfio_sem_up(hash_lock);\n\n\tif (has_entries)\n\t\tlog_err(\"fio: file hash not empty on exit\\n\");\n\n\tsfree(file_hash);\n\tfile_hash = NULL;\n\tfio_sem_remove(hash_lock);\n\thash_lock = NULL;\n\tbloom_free(file_bloom);\n\tfile_bloom = NULL;\n}\n\nvoid file_hash_init(void)\n{\n\tunsigned int i;\n\n\tfile_hash = smalloc(file_hash_size);\n\n\tfor (i = 0; i < HASH_BUCKETS; i++)\n\t\tINIT_FLIST_HEAD(&file_hash[i]);\n\n\thash_lock = fio_sem_init(FIO_SEM_UNLOCKED);\n\tfile_bloom = bloom_new(BLOOM_SIZE);\n}\n"
        },
        {
          "name": "filehash.h",
          "type": "blob",
          "size": 0.4306640625,
          "content": "#ifndef FIO_FILE_HASH_H\n#define FIO_FILE_HASH_H\n\n#include \"lib/types.h\"\n\nextern void file_hash_init(void);\nextern void file_hash_exit(void);\nextern struct fio_file *lookup_file_hash(const char *);\nextern struct fio_file *add_file_hash(struct fio_file *);\nextern void remove_file_hash(struct fio_file *);\nextern void fio_file_hash_lock(void);\nextern void fio_file_hash_unlock(void);\nextern bool file_bloom_exists(const char *, bool);\n\n#endif\n"
        },
        {
          "name": "filelock.c",
          "type": "blob",
          "size": 4.177734375,
          "content": "/*\n * Really simple exclusive file locking based on filename.\n * No hash indexing, just a list, so only works well for < 100 files or\n * so. But that's more than what fio needs, so should be fine.\n */\n#include <inttypes.h>\n#include <string.h>\n#include <unistd.h>\n#include <assert.h>\n\n#include \"flist.h\"\n#include \"filelock.h\"\n#include \"smalloc.h\"\n#include \"fio_sem.h\"\n#include \"hash.h\"\n#include \"log.h\"\n\nstruct fio_filelock {\n\tuint32_t hash;\n\tstruct fio_sem lock;\n\tstruct flist_head list;\n\tunsigned int references;\n};\n\n#define MAX_FILELOCKS\t1024\n\t\nstatic struct filelock_data {\n\tstruct flist_head list;\n\tstruct fio_sem lock;\n\n\tstruct flist_head free_list;\n\tstruct fio_filelock ffs[MAX_FILELOCKS];\n} *fld;\n\nstatic void put_filelock(struct fio_filelock *ff)\n{\n\tflist_add(&ff->list, &fld->free_list);\n}\n\nstatic struct fio_filelock *__get_filelock(void)\n{\n\tstruct fio_filelock *ff;\n\n\tif (flist_empty(&fld->free_list))\n\t\treturn NULL;\n\n\tff = flist_first_entry(&fld->free_list, struct fio_filelock, list);\n\tflist_del_init(&ff->list);\n\treturn ff;\n}\n\nstatic struct fio_filelock *get_filelock(int trylock, int *retry)\n{\n\tstruct fio_filelock *ff;\n\n\tdo {\n\t\tff = __get_filelock();\n\t\tif (ff || trylock)\n\t\t\tbreak;\n\n\t\tfio_sem_up(&fld->lock);\n\t\tusleep(1000);\n\t\tfio_sem_down(&fld->lock);\n\t\t*retry = 1;\n\t} while (1);\n\n\treturn ff;\n}\n\nint fio_filelock_init(void)\n{\n\tint i;\n\n\tfld = smalloc(sizeof(*fld));\n\tif (!fld)\n\t\treturn 1;\n\n\tINIT_FLIST_HEAD(&fld->list);\n\tINIT_FLIST_HEAD(&fld->free_list);\n\n\tif (__fio_sem_init(&fld->lock, FIO_SEM_UNLOCKED))\n\t\tgoto err;\n\n\tfor (i = 0; i < MAX_FILELOCKS; i++) {\n\t\tstruct fio_filelock *ff = &fld->ffs[i];\n\n\t\tif (__fio_sem_init(&ff->lock, FIO_SEM_UNLOCKED))\n\t\t\tgoto err;\n\t\tflist_add_tail(&ff->list, &fld->free_list);\n\t}\n\n\treturn 0;\nerr:\n\tfio_filelock_exit();\n\treturn 1;\n}\n\nvoid fio_filelock_exit(void)\n{\n\tif (!fld)\n\t\treturn;\n\n\tassert(flist_empty(&fld->list));\n\t__fio_sem_remove(&fld->lock);\n\n\twhile (!flist_empty(&fld->free_list)) {\n\t\tstruct fio_filelock *ff;\n\n\t\tff = flist_first_entry(&fld->free_list, struct fio_filelock, list);\n\n\t\tflist_del_init(&ff->list);\n\t\t__fio_sem_remove(&ff->lock);\n\t}\n\n\tsfree(fld);\n\tfld = NULL;\n}\n\nstatic struct fio_filelock *fio_hash_find(uint32_t hash)\n{\n\tstruct flist_head *entry;\n\tstruct fio_filelock *ff;\n\n\tflist_for_each(entry, &fld->list) {\n\t\tff = flist_entry(entry, struct fio_filelock, list);\n\t\tif (ff->hash == hash)\n\t\t\treturn ff;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct fio_filelock *fio_hash_get(uint32_t hash, int trylock)\n{\n\tstruct fio_filelock *ff;\n\n\tff = fio_hash_find(hash);\n\tif (!ff) {\n\t\tint retry = 0;\n\n\t\tff = get_filelock(trylock, &retry);\n\t\tif (!ff)\n\t\t\treturn NULL;\n\n\t\t/*\n\t\t * If we dropped the main lock, re-lookup the hash in case\n\t\t * someone else added it meanwhile. If it's now there,\n\t\t * just return that.\n\t\t */\n\t\tif (retry) {\n\t\t\tstruct fio_filelock *__ff;\n\n\t\t\t__ff = fio_hash_find(hash);\n\t\t\tif (__ff) {\n\t\t\t\tput_filelock(ff);\n\t\t\t\treturn __ff;\n\t\t\t}\n\t\t}\n\n\t\tff->hash = hash;\n\t\tff->references = 0;\n\t\tflist_add(&ff->list, &fld->list);\n\t}\n\n\treturn ff;\n}\n\nstatic bool __fio_lock_file(const char *fname, int trylock)\n{\n\tstruct fio_filelock *ff;\n\tuint32_t hash;\n\n\thash = jhash(fname, strlen(fname), 0);\n\n\tfio_sem_down(&fld->lock);\n\tff = fio_hash_get(hash, trylock);\n\tif (ff)\n\t\tff->references++;\n\tfio_sem_up(&fld->lock);\n\n\tif (!ff) {\n\t\tassert(trylock);\n\t\treturn true;\n\t}\n\n\tif (!trylock) {\n\t\tfio_sem_down(&ff->lock);\n\t\treturn false;\n\t}\n\n\tif (!fio_sem_down_trylock(&ff->lock))\n\t\treturn false;\n\n\tfio_sem_down(&fld->lock);\n\n\t/*\n\t * If we raced and the only reference to the lock is us, we can\n\t * grab it\n\t */\n\tif (ff->references != 1) {\n\t\tff->references--;\n\t\tff = NULL;\n\t}\n\n\tfio_sem_up(&fld->lock);\n\n\tif (ff) {\n\t\tfio_sem_down(&ff->lock);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nbool fio_trylock_file(const char *fname)\n{\n\treturn __fio_lock_file(fname, 1);\n}\n\nvoid fio_lock_file(const char *fname)\n{\n\t__fio_lock_file(fname, 0);\n}\n\nvoid fio_unlock_file(const char *fname)\n{\n\tstruct fio_filelock *ff;\n\tuint32_t hash;\n\n\thash = jhash(fname, strlen(fname), 0);\n\n\tfio_sem_down(&fld->lock);\n\n\tff = fio_hash_find(hash);\n\tif (ff) {\n\t\tint refs = --ff->references;\n\t\tfio_sem_up(&ff->lock);\n\t\tif (!refs) {\n\t\t\tflist_del_init(&ff->list);\n\t\t\tput_filelock(ff);\n\t\t}\n\t} else\n\t\tlog_err(\"fio: file not found for unlocking\\n\");\n\n\tfio_sem_up(&fld->lock);\n}\n"
        },
        {
          "name": "filelock.h",
          "type": "blob",
          "size": 0.2763671875,
          "content": "#ifndef FIO_LOCK_FILE_H\n#define FIO_LOCK_FILE_H\n\n#include \"lib/types.h\"\n\nextern void fio_lock_file(const char *);\nextern bool fio_trylock_file(const char *);\nextern void fio_unlock_file(const char *);\n\nextern int fio_filelock_init(void);\nextern void fio_filelock_exit(void);\n\n#endif\n"
        },
        {
          "name": "filesetup.c",
          "type": "blob",
          "size": 45.787109375,
          "content": "#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n#include <assert.h>\n#include <dirent.h>\n#include <libgen.h>\n#include <sys/stat.h>\n\n#include \"fio.h\"\n#include \"smalloc.h\"\n#include \"filehash.h\"\n#include \"options.h\"\n#include \"os/os.h\"\n#include \"hash.h\"\n#include \"lib/axmap.h\"\n#include \"rwlock.h\"\n#include \"zbd.h\"\n\n#ifdef CONFIG_LINUX_FALLOCATE\n#include <linux/falloc.h>\n#endif\n\nstatic FLIST_HEAD(filename_list);\n\n/*\n * List entry for filename_list\n */\nstruct file_name {\n\tstruct flist_head list;\n\tchar *filename;\n};\n\nstatic inline void clear_error(struct thread_data *td)\n{\n\ttd->error = 0;\n\ttd->verror[0] = '\\0';\n}\n\nstatic int native_fallocate(struct thread_data *td, struct fio_file *f)\n{\n\tbool success;\n\n\tsuccess = fio_fallocate(f, 0, f->real_file_size);\n\tdprint(FD_FILE, \"native fallocate of file %s size %llu was \"\n\t\t\t\"%ssuccessful\\n\", f->file_name,\n\t\t\t(unsigned long long) f->real_file_size,\n\t\t\t!success ? \"un\": \"\");\n\n\tif (success)\n\t\treturn false;\n\n\tif (errno == ENOSYS)\n\t\tdprint(FD_FILE, \"native fallocate is not implemented\\n\");\n\n\treturn true;\n}\n\nstatic void fallocate_file(struct thread_data *td, struct fio_file *f)\n{\n\tif (td->o.fill_device)\n\t\treturn;\n\n\tswitch (td->o.fallocate_mode) {\n\tcase FIO_FALLOCATE_NATIVE:\n\t\tnative_fallocate(td, f);\n\t\tbreak;\n\tcase FIO_FALLOCATE_NONE:\n\t\tbreak;\n#ifdef CONFIG_POSIX_FALLOCATE\n\tcase FIO_FALLOCATE_POSIX: {\n\t\tint r;\n\n\t\tdprint(FD_FILE, \"posix_fallocate file %s size %llu\\n\",\n\t\t\t\t f->file_name,\n\t\t\t\t (unsigned long long) f->real_file_size);\n\n\t\tr = posix_fallocate(f->fd, 0, f->real_file_size);\n\t\tif (r > 0)\n\t\t\tlog_err(\"fio: posix_fallocate fails: %s\\n\", strerror(r));\n\t\tbreak;\n\t\t}\n#endif /* CONFIG_POSIX_FALLOCATE */\n#ifdef CONFIG_LINUX_FALLOCATE\n\tcase FIO_FALLOCATE_KEEP_SIZE: {\n\t\tint r;\n\n\t\tdprint(FD_FILE, \"fallocate(FALLOC_FL_KEEP_SIZE) \"\n\t\t\t\t\"file %s size %llu\\n\", f->file_name,\n\t\t\t\t(unsigned long long) f->real_file_size);\n\n\t\tr = fallocate(f->fd, FALLOC_FL_KEEP_SIZE, 0, f->real_file_size);\n\t\tif (r != 0)\n\t\t\ttd_verror(td, errno, \"fallocate\");\n\n\t\tbreak;\n\t\t}\n#endif /* CONFIG_LINUX_FALLOCATE */\n\tcase FIO_FALLOCATE_TRUNCATE: {\n\t\tint r;\n\n\t\tdprint(FD_FILE, \"ftruncate file %s size %llu\\n\",\n\t\t\t\tf->file_name,\n\t\t\t\t(unsigned long long) f->real_file_size);\n\t\tr = ftruncate(f->fd, f->real_file_size);\n\t\tif (r != 0)\n\t\t\ttd_verror(td, errno, \"ftruncate\");\n\n\t\tbreak;\n\t}\n\tdefault:\n\t\tlog_err(\"fio: unknown fallocate mode: %d\\n\", td->o.fallocate_mode);\n\t\tassert(0);\n\t}\n}\n\n/*\n * Leaves f->fd open on success, caller must close\n */\nstatic int extend_file(struct thread_data *td, struct fio_file *f)\n{\n\tint new_layout = 0, unlink_file = 0, flags;\n\tunsigned long long left;\n\tunsigned long long bs;\n\tchar *b = NULL;\n\n\tif (read_only) {\n\t\tlog_err(\"fio: refusing extend of file due to read-only\\n\");\n\t\treturn 0;\n\t}\n\n\t/*\n\t * check if we need to lay the file out complete again. fio\n\t * does that for operations involving reads, or for writes\n\t * where overwrite is set\n\t */\n\tif (td_read(td) ||\n\t   (td_write(td) && td->o.overwrite && !td->o.file_append) ||\n\t    (td_write(td) && td_ioengine_flagged(td, FIO_NOEXTEND)))\n\t\tnew_layout = 1;\n\tif (td_write(td) && !td->o.overwrite && !td->o.file_append)\n\t\tunlink_file = 1;\n\n\tif (unlink_file || new_layout) {\n\t\tint ret;\n\n\t\tdprint(FD_FILE, \"layout unlink %s\\n\", f->file_name);\n\n\t\tret = td_io_unlink_file(td, f);\n\t\tif (ret != 0 && ret != ENOENT) {\n\t\t\ttd_verror(td, errno, \"unlink\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tflags = O_WRONLY;\n\tif (td->o.allow_create)\n\t\tflags |= O_CREAT;\n\tif (new_layout)\n\t\tflags |= O_TRUNC;\n\n#ifdef WIN32\n\tflags |= _O_BINARY;\n#endif\n\n\tdprint(FD_FILE, \"open file %s, flags %x\\n\", f->file_name, flags);\n\tf->fd = open(f->file_name, flags, 0644);\n\tif (f->fd < 0) {\n\t\tint err = errno;\n\n\t\tif (err == ENOENT && !td->o.allow_create)\n\t\t\tlog_err(\"fio: file creation disallowed by \"\n\t\t\t\t\t\"allow_file_create=0\\n\");\n\t\telse\n\t\t\ttd_verror(td, err, \"open\");\n\t\treturn 1;\n\t}\n\n\tfallocate_file(td, f);\n\n\t/*\n\t * If our jobs don't require regular files initially, we're done.\n\t */\n\tif (!new_layout)\n\t\tgoto done;\n\n\t/*\n\t * The size will be -1ULL when fill_device is used, so don't truncate\n\t * or fallocate this file, just write it\n\t */\n\tif (!td->o.fill_device) {\n\t\tdprint(FD_FILE, \"truncate file %s, size %llu\\n\", f->file_name,\n\t\t\t\t\t(unsigned long long) f->real_file_size);\n\t\tif (ftruncate(f->fd, f->real_file_size) == -1) {\n\t\t\tif (errno != EFBIG) {\n\t\t\t\ttd_verror(td, errno, \"ftruncate\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\t}\n\n\tleft = f->real_file_size;\n\tbs = td->o.max_bs[DDIR_WRITE];\n\tif (bs > left)\n\t\tbs = left;\n\n\tb = malloc(bs);\n\tif (!b) {\n\t\ttd_verror(td, errno, \"malloc\");\n\t\tgoto err;\n\t}\n\n\twhile (left && !td->terminate) {\n\t\tssize_t r;\n\n\t\tif (bs > left)\n\t\t\tbs = left;\n\n\t\tfill_io_buffer(td, b, bs, bs);\n\n\t\tr = write(f->fd, b, bs);\n\n\t\tif (r > 0) {\n\t\t\tleft -= r;\n\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (r < 0) {\n\t\t\t\tint __e = errno;\n\n\t\t\t\tif (__e == ENOSPC || __e == EDQUOT) {\n\t\t\t\t\tconst char *__e_name;\n\t\t\t\t\tif (td->o.fill_device)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tif (__e == ENOSPC)\n\t\t\t\t\t\t__e_name = \"ENOSPC\";\n\t\t\t\t\telse\n\t\t\t\t\t\t__e_name = \"EDQUOT\";\n\t\t\t\t\tlog_info(\"fio: %s on laying out \"\n\t\t\t\t\t\t \"file, stopping\\n\", __e_name);\n\t\t\t\t}\n\t\t\t\ttd_verror(td, errno, \"write\");\n\t\t\t} else\n\t\t\t\ttd_verror(td, EIO, \"write\");\n\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (td->terminate) {\n\t\tdprint(FD_FILE, \"terminate unlink %s\\n\", f->file_name);\n\t\ttd_io_unlink_file(td, f);\n\t} else if (td->o.create_fsync) {\n\t\tif (fsync(f->fd) < 0) {\n\t\t\ttd_verror(td, errno, \"fsync\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\tif (td->o.fill_device && !td_write(td)) {\n\t\tfio_file_clear_size_known(f);\n\t\tif (td_io_get_file_size(td, f))\n\t\t\tgoto err;\n\t\tif (f->io_size > f->real_file_size)\n\t\t\tf->io_size = f->real_file_size;\n\t}\n\n\tfree(b);\ndone:\n\treturn 0;\nerr:\n\tclose(f->fd);\n\tf->fd = -1;\n\tif (b)\n\t\tfree(b);\n\treturn 1;\n}\n\nstatic bool pre_read_file(struct thread_data *td, struct fio_file *f)\n{\n\tint r, did_open = 0, old_runstate;\n\tunsigned long long left;\n\tunsigned long long bs;\n\tbool ret = true;\n\tchar *b;\n\n\tif (td_ioengine_flagged(td, FIO_PIPEIO) ||\n\t    td_ioengine_flagged(td, FIO_NOIO))\n\t\treturn true;\n\n\tif (f->filetype == FIO_TYPE_CHAR)\n\t\treturn true;\n\n\tif (!fio_file_open(f)) {\n\t\tif (td->io_ops->open_file(td, f)) {\n\t\t\tlog_err(\"fio: cannot pre-read, failed to open file\\n\");\n\t\t\treturn false;\n\t\t}\n\t\tdid_open = 1;\n\t}\n\n\told_runstate = td_bump_runstate(td, TD_PRE_READING);\n\n\tleft = f->io_size;\n\tbs = td->o.max_bs[DDIR_READ];\n\tif (bs > left)\n\t\tbs = left;\n\n\tb = calloc(1, bs);\n\tif (!b) {\n\t\ttd_verror(td, errno, \"malloc\");\n\t\tret = false;\n\t\tgoto error;\n\t}\n\n\tif (lseek(f->fd, f->file_offset, SEEK_SET) < 0) {\n\t\ttd_verror(td, errno, \"lseek\");\n\t\tlog_err(\"fio: failed to lseek pre-read file\\n\");\n\t\tret = false;\n\t\tgoto error;\n\t}\n\n\twhile (left && !td->terminate) {\n\t\tif (bs > left)\n\t\t\tbs = left;\n\n\t\tr = read(f->fd, b, bs);\n\n\t\tif (r == (int) bs) {\n\t\t\tleft -= bs;\n\t\t\tcontinue;\n\t\t} else {\n\t\t\ttd_verror(td, EIO, \"pre_read\");\n\t\t\tbreak;\n\t\t}\n\t}\n\nerror:\n\ttd_restore_runstate(td, old_runstate);\n\n\tif (did_open)\n\t\ttd->io_ops->close_file(td, f);\n\n\tfree(b);\n\treturn ret;\n}\n\n/*\n * Generic function to prepopulate regular file with data.\n * Useful if you want to make sure I/O engine has data to read.\n * Leaves f->fd open on success, caller must close.\n */\nint generic_prepopulate_file(struct thread_data *td, struct fio_file *f)\n{\n\tint flags;\n\tunsigned long long left, bs;\n\tchar *b = NULL;\n\n\t/* generic function for regular files only */\n\tassert(f->filetype == FIO_TYPE_FILE);\n\n\tif (read_only) {\n\t\tlog_err(\"fio: refusing to write a file due to read-only\\n\");\n\t\treturn 0;\n\t}\n\n\tflags = O_WRONLY;\n\tif (td->o.allow_create)\n\t\tflags |= O_CREAT;\n\n#ifdef WIN32\n\tflags |= _O_BINARY;\n#endif\n\n\tdprint(FD_FILE, \"open file %s, flags %x\\n\", f->file_name, flags);\n\tf->fd = open(f->file_name, flags, 0644);\n\tif (f->fd < 0) {\n\t\tint err = errno;\n\n\t\tif (err == ENOENT && !td->o.allow_create)\n\t\t\tlog_err(\"fio: file creation disallowed by \"\n\t\t\t\t\t\"allow_file_create=0\\n\");\n\t\telse\n\t\t\ttd_verror(td, err, \"open\");\n\t\treturn 1;\n\t}\n\n\tleft = f->real_file_size;\n\tbs = td->o.max_bs[DDIR_WRITE];\n\tif (bs > left)\n\t\tbs = left;\n\n\tb = malloc(bs);\n\tif (!b) {\n\t\ttd_verror(td, errno, \"malloc\");\n\t\tgoto err;\n\t}\n\n\twhile (left && !td->terminate) {\n\t\tssize_t r;\n\n\t\tif (bs > left)\n\t\t\tbs = left;\n\n\t\tfill_io_buffer(td, b, bs, bs);\n\n\t\tr = write(f->fd, b, bs);\n\n\t\tif (r > 0) {\n\t\t\tleft -= r;\n\t\t} else {\n\t\t\ttd_verror(td, errno, \"write\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (td->terminate) {\n\t\tdprint(FD_FILE, \"terminate unlink %s\\n\", f->file_name);\n\t\ttd_io_unlink_file(td, f);\n\t} else if (td->o.create_fsync) {\n\t\tif (fsync(f->fd) < 0) {\n\t\t\ttd_verror(td, errno, \"fsync\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tfree(b);\n\treturn 0;\nerr:\n\tclose(f->fd);\n\tf->fd = -1;\n\tif (b)\n\t\tfree(b);\n\treturn 1;\n}\n\nunsigned long long get_rand_file_size(struct thread_data *td)\n{\n\tunsigned long long ret, sized;\n\tuint64_t frand_max;\n\tuint64_t r;\n\n\tfrand_max = rand_max(&td->file_size_state);\n\tr = __rand(&td->file_size_state);\n\tsized = td->o.file_size_high - td->o.file_size_low;\n\tret = (unsigned long long) ((double) sized * (r / (frand_max + 1.0)));\n\tret += td->o.file_size_low;\n\tret -= (ret % td->o.rw_min_bs);\n\treturn ret;\n}\n\nstatic int file_size(struct thread_data *td, struct fio_file *f)\n{\n\tstruct stat st;\n\n\tif (stat(f->file_name, &st) == -1) {\n\t\ttd_verror(td, errno, \"fstat\");\n\t\treturn 1;\n\t}\n\n\tf->real_file_size = st.st_size;\n\treturn 0;\n}\n\nstatic int bdev_size(struct thread_data *td, struct fio_file *f)\n{\n\tunsigned long long bytes = 0;\n\tint r;\n\n\tif (td->io_ops->open_file(td, f)) {\n\t\tlog_err(\"fio: failed opening blockdev %s for size check\\n\",\n\t\t\tf->file_name);\n\t\treturn 1;\n\t}\n\n\tr = blockdev_size(f, &bytes);\n\tif (r) {\n\t\ttd_verror(td, r, \"blockdev_size\");\n\t\tgoto err;\n\t}\n\n\tif (!bytes) {\n\t\tlog_err(\"%s: zero sized block device?\\n\", f->file_name);\n\t\tgoto err;\n\t}\n\n\tf->real_file_size = bytes;\n\ttd->io_ops->close_file(td, f);\n\treturn 0;\nerr:\n\ttd->io_ops->close_file(td, f);\n\treturn 1;\n}\n\nstatic int char_size(struct thread_data *td, struct fio_file *f)\n{\n#ifdef FIO_HAVE_CHARDEV_SIZE\n\tunsigned long long bytes = 0;\n\tint r;\n\n\tif (td->io_ops->open_file(td, f)) {\n\t\tlog_err(\"fio: failed opening chardev %s for size check\\n\",\n\t\t\tf->file_name);\n\t\treturn 1;\n\t}\n\n\tr = chardev_size(f, &bytes);\n\tif (r) {\n\t\ttd_verror(td, r, \"chardev_size\");\n\t\tgoto err;\n\t}\n\n\tif (!bytes) {\n\t\tlog_err(\"%s: zero sized char device?\\n\", f->file_name);\n\t\tgoto err;\n\t}\n\n\tf->real_file_size = bytes;\n\ttd->io_ops->close_file(td, f);\n\treturn 0;\nerr:\n\ttd->io_ops->close_file(td, f);\n\treturn 1;\n#else\n\tf->real_file_size = -1ULL;\n\treturn 0;\n#endif\n}\n\nstatic int get_file_size(struct thread_data *td, struct fio_file *f)\n{\n\tint ret = 0;\n\n\tif (fio_file_size_known(f))\n\t\treturn 0;\n\n\tif (f->filetype == FIO_TYPE_FILE)\n\t\tret = file_size(td, f);\n\telse if (f->filetype == FIO_TYPE_BLOCK)\n\t\tret = bdev_size(td, f);\n\telse if (f->filetype == FIO_TYPE_CHAR)\n\t\tret = char_size(td, f);\n\telse {\n\t\tf->real_file_size = -1;\n\t\tlog_info(\"%s: failed to get file size of %s\\n\", td->o.name,\n\t\t\t\t\tf->file_name);\n\t\treturn 1; /* avoid offset extends end error message */\n\t}\n\n\t/*\n\t * Leave ->real_file_size with 0 since it could be expectation\n\t * of initial setup for regular files.\n\t */\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * ->file_offset normally hasn't been initialized yet, so this\n\t * is basically always false unless ->real_file_size is -1, but\n\t * if ->real_file_size is -1 this message doesn't make sense.\n\t * As a result, this message is basically useless.\n\t */\n\tif (f->file_offset > f->real_file_size) {\n\t\tlog_err(\"%s: offset extends end (%llu > %llu)\\n\", td->o.name,\n\t\t\t\t\t(unsigned long long) f->file_offset,\n\t\t\t\t\t(unsigned long long) f->real_file_size);\n\t\treturn 1;\n\t}\n\n\tfio_file_set_size_known(f);\n\treturn 0;\n}\n\nstatic int __file_invalidate_cache(struct thread_data *td, struct fio_file *f,\n\t\t\t\t   unsigned long long off,\n\t\t\t\t   unsigned long long len)\n{\n\tint errval = 0, ret = 0;\n\n#ifdef CONFIG_ESX\n\treturn 0;\n#endif\n\n\tif (len == -1ULL)\n\t\tlen = f->io_size;\n\tif (off == -1ULL)\n\t\toff = f->file_offset;\n\n\tif (len == -1ULL || off == -1ULL)\n\t\treturn 0;\n\n\tif (td->io_ops->invalidate) {\n\t\tdprint(FD_IO, \"invalidate %s cache %s\\n\", td->io_ops->name,\n\t\t\tf->file_name);\n\t\tret = td->io_ops->invalidate(td, f);\n\t\tif (ret < 0)\n\t\t\terrval = -ret;\n\t} else if (td_ioengine_flagged(td, FIO_DISKLESSIO)) {\n\t\tdprint(FD_IO, \"invalidate not supported by ioengine %s\\n\",\n\t\t       td->io_ops->name);\n\t} else if (f->filetype == FIO_TYPE_FILE) {\n\t\tdprint(FD_IO, \"declare unneeded cache %s: %llu/%llu\\n\",\n\t\t\tf->file_name, off, len);\n\t\tret = posix_fadvise(f->fd, off, len, POSIX_FADV_DONTNEED);\n\t\tif (ret)\n\t\t\terrval = ret;\n\t} else if (f->filetype == FIO_TYPE_BLOCK) {\n\t\tint retry_count = 0;\n\n\t\tdprint(FD_IO, \"drop page cache %s\\n\", f->file_name);\n\t\tret = blockdev_invalidate_cache(f);\n\t\twhile (ret < 0 && errno == EAGAIN && retry_count++ < 25) {\n\t\t\t/*\n\t\t\t * Linux multipath devices reject ioctl while\n\t\t\t * the maps are being updated. That window can\n\t\t\t * last tens of milliseconds; we'll try up to\n\t\t\t * a quarter of a second.\n\t\t\t */\n\t\t\tusleep(10000);\n\t\t\tret = blockdev_invalidate_cache(f);\n\t\t}\n\t\tif (ret < 0 && errno == EACCES && geteuid()) {\n\t\t\tif (!fio_did_warn(FIO_WARN_ROOT_FLUSH)) {\n\t\t\t\tlog_err(\"fio: only root may flush block \"\n\t\t\t\t\t\"devices. Cache flush bypassed!\\n\");\n\t\t\t}\n\t\t}\n\t\tif (ret < 0)\n\t\t\terrval = errno;\n\t} else if (f->filetype == FIO_TYPE_CHAR ||\n\t\t   f->filetype == FIO_TYPE_PIPE) {\n\t\tdprint(FD_IO, \"invalidate not supported %s\\n\", f->file_name);\n\t}\n\n\t/*\n\t * Cache flushing isn't a fatal condition, and we know it will\n\t * happen on some platforms where we don't have the proper\n\t * function to flush eg block device caches. So just warn and\n\t * continue on our way.\n\t */\n\tif (errval)\n\t\tlog_info(\"fio: cache invalidation of %s failed: %s\\n\",\n\t\t\t f->file_name, strerror(errval));\n\n\treturn 0;\n\n}\n\nint file_invalidate_cache(struct thread_data *td, struct fio_file *f)\n{\n\tif (!fio_file_open(f))\n\t\treturn 0;\n\n\treturn __file_invalidate_cache(td, f, -1ULL, -1ULL);\n}\n\nint generic_close_file(struct thread_data fio_unused *td, struct fio_file *f)\n{\n\tint ret = 0;\n\n\tdprint(FD_FILE, \"fd close %s\\n\", f->file_name);\n\n\tremove_file_hash(f);\n\n\tif (close(f->fd) < 0)\n\t\tret = errno;\n\n\tf->fd = -1;\n\n\tif (f->shadow_fd != -1) {\n\t\tclose(f->shadow_fd);\n\t\tf->shadow_fd = -1;\n\t}\n\n\tf->engine_pos = 0;\n\treturn ret;\n}\n\nint file_lookup_open(struct fio_file *f, int flags)\n{\n\tstruct fio_file *__f;\n\tint from_hash;\n\n\t__f = lookup_file_hash(f->file_name);\n\tif (__f) {\n\t\tdprint(FD_FILE, \"found file in hash %s\\n\", f->file_name);\n\t\tf->lock = __f->lock;\n\t\tfrom_hash = 1;\n\t} else {\n\t\tdprint(FD_FILE, \"file not found in hash %s\\n\", f->file_name);\n\t\tfrom_hash = 0;\n\t}\n\n#ifdef WIN32\n\tflags |= _O_BINARY;\n#endif\n\n\tf->fd = open(f->file_name, flags, 0600);\n\treturn from_hash;\n}\n\nstatic int file_close_shadow_fds(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tint num_closed = 0;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i) {\n\t\tif (f->shadow_fd == -1)\n\t\t\tcontinue;\n\n\t\tclose(f->shadow_fd);\n\t\tf->shadow_fd = -1;\n\t\tnum_closed++;\n\t}\n\n\treturn num_closed;\n}\n\nint generic_open_file(struct thread_data *td, struct fio_file *f)\n{\n\tint is_std = 0;\n\tint flags = 0;\n\tint from_hash = 0;\n\n\tdprint(FD_FILE, \"fd open %s\\n\", f->file_name);\n\n\tif (!strcmp(f->file_name, \"-\")) {\n\t\tif (td_rw(td)) {\n\t\t\tlog_err(\"fio: can't read/write to stdin/out\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tis_std = 1;\n\n\t\t/*\n\t\t * move output logging to stderr, if we are writing to stdout\n\t\t */\n\t\tif (td_write(td))\n\t\t\tf_out = stderr;\n\t}\n\n\tif (td->o.odirect)\n\t\tflags |= OS_O_DIRECT;\n\tflags |= td->o.sync_io;\n\tif (td->o.create_on_open && td->o.allow_create)\n\t\tflags |= O_CREAT;\n\tif (f->filetype != FIO_TYPE_FILE)\n\t\tflags |= FIO_O_NOATIME;\n\nopen_again:\n\tif (td_write(td)) {\n\t\tif (!read_only)\n\t\t\tflags |= O_RDWR;\n\n\t\tif (td->o.verify_only) {\n\t\t\tflags &= ~O_RDWR;\n\t\t\tflags |= O_RDONLY;\n\t\t}\n\n\t\tif (f->filetype == FIO_TYPE_FILE && td->o.allow_create)\n\t\t\tflags |= O_CREAT;\n\n\t\tif (is_std)\n\t\t\tf->fd = dup(STDOUT_FILENO);\n\t\telse\n\t\t\tfrom_hash = file_lookup_open(f, flags);\n\t} else if (td_read(td)) {\n\t\tif (td_ioengine_flagged(td, FIO_RO_NEEDS_RW_OPEN) && !read_only)\n\t\t\tflags |= O_RDWR;\n\t\telse\n\t\t\tflags |= O_RDONLY;\n\n\t\tif (is_std)\n\t\t\tf->fd = dup(STDIN_FILENO);\n\t\telse\n\t\t\tfrom_hash = file_lookup_open(f, flags);\n\t} else if (td_trim(td)) {\n\t\tassert(!td_rw(td)); /* should have matched above */\n\t\tif (!read_only)\n\t\t\tflags |= O_RDWR;\n\t\tfrom_hash = file_lookup_open(f, flags);\n\t}\n\n\tif (f->fd == -1) {\n\t\tchar buf[FIO_VERROR_SIZE];\n\t\tint __e = errno;\n\n\t\tif (__e == EPERM && (flags & FIO_O_NOATIME)) {\n\t\t\tflags &= ~FIO_O_NOATIME;\n\t\t\tgoto open_again;\n\t\t}\n\t\tif (__e == EMFILE && file_close_shadow_fds(td))\n\t\t\tgoto open_again;\n\n\t\tsnprintf(buf, sizeof(buf), \"open(%s)\", f->file_name);\n\n\t\tif (__e == EINVAL && (flags & OS_O_DIRECT)) {\n\t\t\tlog_err(\"fio: looks like your file system does not \" \\\n\t\t\t\t\"support direct=1/buffered=0\\n\");\n\t\t}\n\n\t\ttd_verror(td, __e, buf);\n\t\treturn 1;\n\t}\n\n\tif (!from_hash && f->fd != -1) {\n\t\tif (add_file_hash(f)) {\n\t\t\tint fio_unused ret;\n\n\t\t\t/*\n\t\t\t * Stash away descriptor for later close. This is to\n\t\t\t * work-around a \"feature\" on Linux, where a close of\n\t\t\t * an fd that has been opened for write will trigger\n\t\t\t * udev to call blkid to check partitions, fs id, etc.\n\t\t\t * That pollutes the device cache, which can slow down\n\t\t\t * unbuffered accesses.\n\t\t\t */\n\t\t\tif (f->shadow_fd == -1)\n\t\t\t\tf->shadow_fd = f->fd;\n\t\t\telse {\n\t\t\t\t/*\n\t\t\t \t * OK to ignore, we haven't done anything\n\t\t\t\t * with it\n\t\t\t\t */\n\t\t\t\tret = generic_close_file(td, f);\n\t\t\t}\n\t\t\tgoto open_again;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * This function i.e. get_file_size() is the default .get_file_size\n * implementation of majority of I/O engines.\n */\nint generic_get_file_size(struct thread_data *td, struct fio_file *f)\n{\n\treturn get_file_size(td, f);\n}\n\n/*\n * open/close all files, so that ->real_file_size gets set\n */\nstatic int get_file_sizes(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\tint err = 0;\n\n\tfor_each_file(td, f, i) {\n\t\tdprint(FD_FILE, \"get file size for %p/%d/%s\\n\", f, i,\n\t\t\t\t\t\t\t\tf->file_name);\n\n\t\tif (td_io_get_file_size(td, f)) {\n\t\t\tif (td->error != ENOENT) {\n\t\t\t\tlog_err(\"%s\\n\", td->verror);\n\t\t\t\terr = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tclear_error(td);\n\t\t}\n\n\t\t/*\n\t\t * There are corner cases where we end up with -1 for\n\t\t * ->real_file_size due to unsupported file type, etc.\n\t\t * We then just set to size option value divided by number\n\t\t * of files, similar to the way file ->io_size is set.\n\t\t * stat(2) failure doesn't set ->real_file_size to -1.\n\t\t */\n\t\tif (f->real_file_size == -1ULL && td->o.size)\n\t\t\tf->real_file_size = td->o.size / td->o.nr_files;\n\t}\n\n\treturn err;\n}\n\nstruct fio_mount {\n\tstruct flist_head list;\n\tconst char *base;\n\tchar __base[256];\n\tunsigned int key;\n};\n\n/*\n * Get free number of bytes for each file on each unique mount.\n */\nstatic unsigned long long get_fs_free_counts(struct thread_data *td)\n{\n\tstruct flist_head *n, *tmp;\n\tunsigned long long ret = 0;\n\tstruct fio_mount *fm;\n\tFLIST_HEAD(list);\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i) {\n\t\tstruct stat sb;\n\t\tchar buf[256];\n\n\t\tif (f->filetype == FIO_TYPE_BLOCK || f->filetype == FIO_TYPE_CHAR) {\n\t\t\tif (f->real_file_size != -1ULL)\n\t\t\t\tret += f->real_file_size;\n\t\t\tcontinue;\n\t\t} else if (f->filetype != FIO_TYPE_FILE)\n\t\t\tcontinue;\n\n\t\tsnprintf(buf, FIO_ARRAY_SIZE(buf), \"%s\", f->file_name);\n\n\t\tif (stat(buf, &sb) < 0) {\n\t\t\tif (errno != ENOENT)\n\t\t\t\tbreak;\n\t\t\tstrcpy(buf, \".\");\n\t\t\tif (stat(buf, &sb) < 0)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tfm = NULL;\n\t\tflist_for_each(n, &list) {\n\t\t\tfm = flist_entry(n, struct fio_mount, list);\n\t\t\tif (fm->key == sb.st_dev)\n\t\t\t\tbreak;\n\n\t\t\tfm = NULL;\n\t\t}\n\n\t\tif (fm)\n\t\t\tcontinue;\n\n\t\tfm = calloc(1, sizeof(*fm));\n\t\tsnprintf(fm->__base, FIO_ARRAY_SIZE(fm->__base), \"%s\", buf);\n\t\tfm->base = basename(fm->__base);\n\t\tfm->key = sb.st_dev;\n\t\tflist_add(&fm->list, &list);\n\t}\n\n\tflist_for_each_safe(n, tmp, &list) {\n\t\tunsigned long long sz;\n\n\t\tfm = flist_entry(n, struct fio_mount, list);\n\t\tflist_del(&fm->list);\n\n\t\tsz = get_fs_free_size(fm->base);\n\t\tif (sz && sz != -1ULL)\n\t\t\tret += sz;\n\n\t\tfree(fm);\n\t}\n\n\treturn ret;\n}\n\nuint64_t get_start_offset(struct thread_data *td, struct fio_file *f)\n{\n\tbool align = false;\n\tstruct thread_options *o = &td->o;\n\tunsigned long long align_bs;\n\tunsigned long long offset;\n\tunsigned long long increment;\n\n\tif (o->file_append && f->filetype == FIO_TYPE_FILE)\n\t\treturn f->real_file_size;\n\n\tif (o->offset_increment_percent) {\n\t\tassert(!o->offset_increment);\n\t\tincrement = o->offset_increment_percent * f->real_file_size / 100;\n\t\talign = true;\n\t} else\n\t\tincrement = o->offset_increment;\n\n\tif (o->start_offset_percent > 0) {\n\t\t/* calculate the raw offset */\n\t\toffset = (f->real_file_size * o->start_offset_percent / 100) +\n\t\t\t(td->subjob_number * increment);\n\n\t\talign = true;\n\t} else {\n\t\t/* start_offset_percent not set */\n\t\toffset = o->start_offset +\n\t\t\t\ttd->subjob_number * increment;\n\t}\n\n\tif (align) {\n\t\t/*\n\t\t * if offset_align is provided, use it\n\t\t */\n\t\tif (fio_option_is_set(o, start_offset_align)) {\n\t\t\talign_bs = o->start_offset_align;\n\t\t} else {\n\t\t\t/* else take the minimum block size */\n\t\t\talign_bs = td_min_bs(td);\n\t\t}\n\n\t\t/*\n\t\t * block align the offset at the next available boundary at\n\t\t * ceiling(offset / align_bs) * align_bs\n\t\t */\n\t\toffset = (offset / align_bs + (offset % align_bs != 0)) * align_bs;\n\t}\n\n\treturn offset;\n}\n\n/*\n * Find longest path component that exists and return its length\n */\nint longest_existing_path(char *path) {\n\tchar buf[PATH_MAX];\n\tbool done;\n\tchar *buf_pos;\n\tint offset;\n#ifdef WIN32\n\tDWORD dwAttr;\n#else\n\tstruct stat sb;\n#endif\n\n\tsprintf(buf, \"%s\", path);\n\tdone = false;\n\twhile (!done) {\n\t\tbuf_pos = strrchr(buf, FIO_OS_PATH_SEPARATOR);\n\t\tif (!buf_pos) {\n\t\t\toffset = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t*(buf_pos + 1) = '\\0';\n\n#ifdef WIN32\n\t\tdwAttr = GetFileAttributesA(buf);\n\t\tif (dwAttr != INVALID_FILE_ATTRIBUTES) {\n\t\t\tdone = true;\n\t\t}\n#else\n\t\tif (stat(buf, &sb) == 0)\n\t\t\tdone = true;\n#endif\n\t\tif (done)\n\t\t\toffset = buf_pos - buf;\n\t\telse\n\t\t\t*buf_pos = '\\0';\n\t}\n\n\treturn offset;\n}\n\nstatic bool create_work_dirs(struct thread_data *td, const char *fname)\n{\n\tchar path[PATH_MAX];\n\tchar *start, *end;\n\tint offset;\n\n\tsnprintf(path, PATH_MAX, \"%s\", fname);\n\tstart = path;\n\n\toffset = longest_existing_path(path);\n\tend = start + offset;\n\twhile ((end = strchr(end, FIO_OS_PATH_SEPARATOR)) != NULL) {\n\t\tif (end == start) {\n\t\t\tend++;\n\t\t\tcontinue;\n\t\t}\n\t\t*end = '\\0';\n\t\terrno = 0;\n\t\tif (fio_mkdir(path, 0700) && errno != EEXIST) {\n\t\t\tlog_err(\"fio: failed to create dir (%s): %s\\n\",\n\t\t\t\tstart, strerror(errno));\n\t\t\treturn false;\n\t\t}\n\t\t*end = FIO_OS_PATH_SEPARATOR;\n\t\tend++;\n\t}\n\ttd->flags |= TD_F_DIRS_CREATED;\n\treturn true;\n}\n\n/*\n * Open the files and setup files sizes, creating files if necessary.\n */\nint setup_files(struct thread_data *td)\n{\n\tunsigned long long total_size, extend_size;\n\tstruct thread_options *o = &td->o;\n\tstruct fio_file *f;\n\tunsigned int i, nr_fs_extra = 0;\n\tint err = 0, need_extend;\n\tint old_state;\n\tconst unsigned long long bs = td_min_bs(td);\n\tuint64_t fs = 0;\n\n\tdprint(FD_FILE, \"setup files\\n\");\n\n\told_state = td_bump_runstate(td, TD_SETTING_UP);\n\n\tfor_each_file(td, f, i) {\n\t\tif (!td_ioengine_flagged(td, FIO_DISKLESSIO) &&\n\t\t    strchr(f->file_name, FIO_OS_PATH_SEPARATOR) &&\n\t\t    !(td->flags & TD_F_DIRS_CREATED) &&\n\t\t    !create_work_dirs(td, f->file_name))\n\t\t\tgoto err_out;\n\t}\n\n\t/*\n\t * Find out physical size of files or devices for this thread,\n\t * before we determine I/O size and range of our targets.\n\t * If ioengine defines a setup() method, it's responsible for\n\t * opening the files and setting f->real_file_size to indicate\n\t * the valid range for that file.\n\t */\n\tif (td->io_ops->setup)\n\t\terr = td->io_ops->setup(td);\n\telse\n\t\terr = get_file_sizes(td);\n\n\tif (err)\n\t\tgoto err_out;\n\n\tif (td->o.zone_mode == ZONE_MODE_ZBD) {\n\t\terr = zbd_init_files(td);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\tzbd_recalc_options_with_zone_granularity(td);\n\n\tif (o->read_iolog_file)\n\t\tgoto done;\n\n\t/*\n\t * check sizes. if the files/devices do not exist and the size\n\t * isn't passed to fio, abort.\n\t */\n\ttotal_size = 0;\n\tfor_each_file(td, f, i) {\n\t\tf->fileno = i;\n\t\tif (f->real_file_size == -1ULL)\n\t\t\ttotal_size = -1ULL;\n\t\telse\n\t\t\ttotal_size += f->real_file_size;\n\t}\n\n\tif (o->fill_device)\n\t\ttd->fill_device_size = get_fs_free_counts(td);\n\n\t/*\n\t * device/file sizes are zero and no size given, punt\n\t */\n\tif ((!total_size || total_size == -1ULL) && !o->size &&\n\t    !td_ioengine_flagged(td, FIO_NOIO) && !o->fill_device &&\n\t    !(o->nr_files && (o->file_size_low || o->file_size_high))) {\n\t\tlog_err(\"%s: you need to specify size=\\n\", o->name);\n\t\ttd_verror(td, EINVAL, \"total_file_size\");\n\t\tgoto err_out;\n\t}\n\n\t/*\n\t * Calculate per-file size and potential extra size for the\n\t * first files, if needed (i.e. if we don't have a fixed size).\n\t */\n\tif (!o->file_size_low && o->nr_files) {\n\t\tuint64_t all_fs;\n\n\t\tfs = o->size / o->nr_files;\n\t\tall_fs = fs * o->nr_files;\n\n\t\tif (all_fs < o->size)\n\t\t\tnr_fs_extra = (o->size - all_fs) / bs;\n\t}\n\n\t/*\n\t * now file sizes are known, so we can set ->io_size. if size= is\n\t * not given, ->io_size is just equal to ->real_file_size. if size\n\t * is given, ->io_size is size / nr_files.\n\t */\n\textend_size = total_size = 0;\n\tneed_extend = 0;\n\tfor_each_file(td, f, i) {\n\t\tf->file_offset = get_start_offset(td, f);\n\n\t\t/*\n\t\t * Update ->io_size depending on options specified.\n\t\t * ->file_size_low being 0 means filesize option isn't set.\n\t\t * Non zero ->file_size_low equals ->file_size_high means\n\t\t * filesize option is set in a fixed size format.\n\t\t * Non zero ->file_size_low not equals ->file_size_high means\n\t\t * filesize option is set in a range format.\n\t\t */\n\t\tif (!o->file_size_low) {\n\t\t\t/*\n\t\t\t * no file size or range given, file size is equal to\n\t\t\t * total size divided by number of files. If the size\n\t\t\t * doesn't divide nicely with the min blocksize,\n\t\t\t * make the first files bigger.\n\t\t\t */\n\t\t\tf->io_size = fs;\n\t\t\tif (nr_fs_extra) {\n\t\t\t\tnr_fs_extra--;\n\t\t\t\tf->io_size += bs;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * We normally don't come here for regular files, but\n\t\t\t * if the result is 0 for a regular file, set it to the\n\t\t\t * real file size. This could be size of the existing\n\t\t\t * one if it already exists, but otherwise will be set\n\t\t\t * to 0. A new file won't be created because\n\t\t\t * ->io_size + ->file_offset equals ->real_file_size.\n\t\t\t */\n\t\t\tif (!f->io_size) {\n\t\t\t\tif (f->file_offset > f->real_file_size)\n\t\t\t\t\tgoto err_offset;\n\t\t\t\tf->io_size = f->real_file_size - f->file_offset;\n\t\t\t\tif (!f->io_size)\n\t\t\t\t\tlog_info(\"fio: file %s may be ignored\\n\",\n\t\t\t\t\t\tf->file_name);\n\t\t\t}\n\t\t} else if (f->real_file_size < o->file_size_low ||\n\t\t\t   f->real_file_size > o->file_size_high) {\n\t\t\tif (f->file_offset > o->file_size_low)\n\t\t\t\tgoto err_offset;\n\t\t\t/*\n\t\t\t * file size given. if it's fixed, use that. if it's a\n\t\t\t * range, generate a random size in-between.\n\t\t\t */\n\t\t\tif (o->file_size_low == o->file_size_high)\n\t\t\t\tf->io_size = o->file_size_low - f->file_offset;\n\t\t\telse {\n\t\t\t\tf->io_size = get_rand_file_size(td)\n\t\t\t\t\t\t- f->file_offset;\n\t\t\t}\n\t\t} else\n\t\t\tf->io_size = f->real_file_size - f->file_offset;\n\n\t\tif (f->io_size == -1ULL)\n\t\t\ttotal_size = -1ULL;\n\t\telse {\n\t\t\tuint64_t io_size;\n\n                        if (o->size_percent && o->size_percent != 100) {\n\t\t\t\tuint64_t file_size;\n\n\t\t\t\tfile_size = f->io_size + f->file_offset;\n\t\t\t\tf->io_size = (file_size *\n\t\t\t\t\t      o->size_percent) / 100;\n\t\t\t\tif (f->io_size > (file_size - f->file_offset))\n\t\t\t\t\tf->io_size = file_size - f->file_offset;\n\n\t\t\t\tf->io_size -= (f->io_size % td_min_bs(td));\n\t\t\t}\n\n\t\t\tio_size = f->io_size;\n\t\t\tif (o->io_size_percent && o->io_size_percent != 100) {\n\t\t\t\tio_size *= o->io_size_percent;\n\t\t\t\tio_size /= 100;\n\t\t\t}\n\n\t\t\ttotal_size += io_size;\n\t\t}\n\n\t\tif (f->filetype == FIO_TYPE_FILE &&\n\t\t    (f->io_size + f->file_offset) > f->real_file_size) {\n\t\t\tif (!td_ioengine_flagged(td, FIO_DISKLESSIO) &&\n\t\t\t    !o->create_on_open) {\n\t\t\t\tneed_extend++;\n\t\t\t\textend_size += (f->io_size + f->file_offset);\n\t\t\t\tfio_file_set_extend(f);\n\t\t\t} else if (!td_ioengine_flagged(td, FIO_DISKLESSIO) ||\n\t\t\t\t   (td_ioengine_flagged(td, FIO_DISKLESSIO) &&\n\t\t\t\t    td_ioengine_flagged(td, FIO_FAKEIO)))\n\t\t\t\tf->real_file_size = f->io_size + f->file_offset;\n\t\t}\n\t}\n\n\tif (td->o.block_error_hist) {\n\t\tint len;\n\n\t\tassert(td->o.nr_files == 1);\t/* checked in fixup_options */\n\t\tf = td->files[0];\n\t\tlen = f->io_size / td->o.bs[DDIR_TRIM];\n\t\tif (len > MAX_NR_BLOCK_INFOS || len <= 0) {\n\t\t\tlog_err(\"fio: cannot calculate block histogram with \"\n\t\t\t\t\"%d trim blocks, maximum %d\\n\",\n\t\t\t\tlen, MAX_NR_BLOCK_INFOS);\n\t\t\ttd_verror(td, EINVAL, \"block_error_hist\");\n\t\t\tgoto err_out;\n\t\t}\n\n\t\ttd->ts.nr_block_infos = len;\n\t\tfor (i = 0; i < len; i++)\n\t\t\ttd->ts.block_infos[i] =\n\t\t\t\tBLOCK_INFO(0, BLOCK_STATE_UNINIT);\n\t} else\n\t\ttd->ts.nr_block_infos = 0;\n\n\tif (!o->size || (total_size && o->size > total_size))\n\t\to->size = total_size;\n\n\tif (o->size < td_min_bs(td)) {\n\t\tlog_err(\"fio: blocksize is larger than data set range\\n\");\n\t\tgoto err_out;\n\t}\n\n\t/*\n\t * See if we need to extend some files, typically needed when our\n\t * target regular files don't exist yet, but our jobs require them\n\t * initially due to read I/Os.\n\t */\n\tif (need_extend) {\n\t\ttemp_stall_ts = 1;\n\t\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\t\tlog_info(\"%s: Laying out IO file%s (%u file%s / %s%lluMiB)\\n\",\n\t\t\t\t o->name,\n\t\t\t\t need_extend > 1 ? \"s\" : \"\",\n\t\t\t\t need_extend,\n\t\t\t\t need_extend > 1 ? \"s\" : \"\",\n\t\t\t\t need_extend > 1 ? \"total \" : \"\",\n\t\t\t\t extend_size >> 20);\n\t\t}\n\n\t\tfor_each_file(td, f, i) {\n\t\t\tunsigned long long old_len = -1ULL, extend_len = -1ULL;\n\n\t\t\tif (!fio_file_extend(f))\n\t\t\t\tcontinue;\n\n\t\t\tassert(f->filetype == FIO_TYPE_FILE);\n\t\t\tfio_file_clear_extend(f);\n\t\t\tif (!o->fill_device) {\n\t\t\t\told_len = f->real_file_size;\n\t\t\t\textend_len = f->io_size + f->file_offset -\n\t\t\t\t\t\told_len;\n\t\t\t}\n\t\t\tf->real_file_size = (f->io_size + f->file_offset);\n\t\t\terr = extend_file(td, f);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\terr = __file_invalidate_cache(td, f, old_len,\n\t\t\t\t\t\t\t\textend_len);\n\n\t\t\t/*\n\t\t\t * Shut up static checker\n\t\t\t */\n\t\t\tif (f->fd != -1)\n\t\t\t\tclose(f->fd);\n\n\t\t\tf->fd = -1;\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t\ttemp_stall_ts = 0;\n\t}\n\n\tif (err)\n\t\tgoto err_out;\n\n\t/*\n\t * Prepopulate files with data. It might be expected to read some\n\t * \"real\" data instead of zero'ed files (if no writes to file occurred\n\t * prior to a read job). Engine has to provide a way to do that.\n\t */\n\tif (td->io_ops->prepopulate_file) {\n\t\ttemp_stall_ts = 1;\n\n\t\tfor_each_file(td, f, i) {\n\t\t\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\t\t\tlog_info(\"%s: Prepopulating IO file (%s)\\n\",\n\t\t\t\t\t\t\to->name, f->file_name);\n\t\t\t}\n\n\t\t\terr = td->io_ops->prepopulate_file(td, f);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\terr = __file_invalidate_cache(td, f, f->file_offset,\n\t\t\t\t\t\t\t\tf->io_size);\n\n\t\t\t/*\n\t\t\t * Shut up static checker\n\t\t\t */\n\t\t\tif (f->fd != -1)\n\t\t\t\tclose(f->fd);\n\n\t\t\tf->fd = -1;\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t\ttemp_stall_ts = 0;\n\t}\n\n\tif (err)\n\t\tgoto err_out;\n\n\t/*\n\t * iolog already set the total io size, if we read back\n\t * stored entries.\n\t */\n\tif (!o->read_iolog_file) {\n\t\tif (o->io_size)\n\t\t\ttd->total_io_size = o->io_size * o->loops;\n\t\telse\n\t\t\ttd->total_io_size = o->size * o->loops;\n\t}\n\ndone:\n\tif (td->o.zone_mode == ZONE_MODE_ZBD) {\n\t\terr = zbd_setup_files(td);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\n\tif (o->create_only)\n\t\ttd->done = 1;\n\n\ttd_restore_runstate(td, old_state);\n\n\tif (td->o.dp_type != FIO_DP_NONE) {\n\t\terr = dp_init(td);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\n\treturn 0;\n\nerr_offset:\n\tlog_err(\"%s: you need to specify valid offset=\\n\", o->name);\nerr_out:\n\ttd_restore_runstate(td, old_state);\n\treturn 1;\n}\n\nbool pre_read_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tdprint(FD_FILE, \"pre_read files\\n\");\n\n\tfor_each_file(td, f, i) {\n\t\tif (!pre_read_file(td, f))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void __init_rand_distribution(struct thread_data *td, struct fio_file *f)\n{\n\tunsigned int range_size, seed;\n\tuint64_t nranges;\n\tuint64_t fsize;\n\n\trange_size = min(td->o.min_bs[DDIR_READ], td->o.min_bs[DDIR_WRITE]);\n\tfsize = min(f->real_file_size, f->io_size);\n\n\tnranges = (fsize + range_size - 1ULL) / range_size;\n\n\tseed = jhash(f->file_name, strlen(f->file_name), 0) * td->thread_number *\n\t\ttd->rand_seeds[FIO_RAND_BLOCK_OFF];\n\n\tif (td->o.random_distribution == FIO_RAND_DIST_ZIPF)\n\t\tzipf_init(&f->zipf, nranges, td->o.zipf_theta.u.f, td->o.random_center.u.f, seed);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_PARETO)\n\t\tpareto_init(&f->zipf, nranges, td->o.pareto_h.u.f, td->o.random_center.u.f, seed);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_GAUSS)\n\t\tgauss_init(&f->gauss, nranges, td->o.gauss_dev.u.f, td->o.random_center.u.f, seed);\n}\n\nstatic bool init_rand_distribution(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\tint state;\n\n\tif (td->o.random_distribution == FIO_RAND_DIST_RANDOM ||\n\t    td->o.random_distribution == FIO_RAND_DIST_ZONED ||\n\t    td->o.random_distribution == FIO_RAND_DIST_ZONED_ABS)\n\t\treturn false;\n\n\tstate = td_bump_runstate(td, TD_SETTING_UP);\n\n\tfor_each_file(td, f, i)\n\t\t__init_rand_distribution(td, f);\n\n\ttd_restore_runstate(td, state);\n\treturn true;\n}\n\n/*\n * Check if the number of blocks exceeds the randomness capability of\n * the selected generator. Tausworthe is 32-bit, the others are fully\n * 64-bit capable.\n */\nstatic int check_rand_gen_limits(struct thread_data *td, struct fio_file *f,\n\t\t\t\t uint64_t blocks)\n{\n\tif (blocks <= FRAND32_MAX)\n\t\treturn 0;\n\tif (td->o.random_generator != FIO_RAND_GEN_TAUSWORTHE)\n\t\treturn 0;\n\n\t/*\n\t * If the user hasn't specified a random generator, switch\n\t * to tausworthe64 with informational warning. If the user did\n\t * specify one, just warn.\n\t */\n\tlog_info(\"fio: file %s exceeds 32-bit tausworthe random generator.\\n\",\n\t\t\tf->file_name);\n\n\tif (!fio_option_is_set(&td->o, random_generator)) {\n\t\tlog_info(\"fio: Switching to tausworthe64. Use the \"\n\t\t\t \"random_generator= option to get rid of this \"\n\t\t\t \"warning.\\n\");\n\t\ttd->o.random_generator = FIO_RAND_GEN_TAUSWORTHE64;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Just make this information to avoid breaking scripts.\n\t */\n\tlog_info(\"fio: Use the random_generator= option to switch to lfsr or \"\n\t\t\t \"tausworthe64.\\n\");\n\treturn 0;\n}\n\nbool init_random_map(struct thread_data *td)\n{\n\tunsigned long long blocks;\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tif (init_rand_distribution(td))\n\t\treturn true;\n\tif (!td_random(td))\n\t\treturn true;\n\n\tfor_each_file(td, f, i) {\n\t\tuint64_t fsize = min(f->real_file_size, f->io_size);\n\n\t\tif (td->o.zone_mode == ZONE_MODE_STRIDED)\n\t\t\tfsize = td->o.zone_range;\n\n\t\tblocks = fsize / (unsigned long long) td->o.rw_min_bs;\n\n\t\tif (check_rand_gen_limits(td, f, blocks))\n\t\t\treturn false;\n\n\t\tif (td->o.random_generator == FIO_RAND_GEN_LFSR) {\n\t\t\tuint64_t seed;\n\n\t\t\tseed = td->rand_seeds[FIO_RAND_BLOCK_OFF];\n\n\t\t\tif (!lfsr_init(&f->lfsr, blocks, seed, 0)) {\n\t\t\t\tfio_file_set_lfsr(f);\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tlog_err(\"fio: failed initializing LFSR\\n\");\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} else if (!td->o.norandommap) {\n\t\t\tf->io_axmap = axmap_new(blocks);\n\t\t\tif (f->io_axmap) {\n\t\t\t\tfio_file_set_axmap(f);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else if (td->o.norandommap)\n\t\t\tcontinue;\n\n\t\tif (!td->o.softrandommap) {\n\t\t\tlog_err(\"fio: failed allocating random map. If running\"\n\t\t\t\t\" a large number of jobs, try the 'norandommap'\"\n\t\t\t\t\" option or set 'softrandommap'. Or give\"\n\t\t\t\t\" a larger --alloc-size to fio.\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tlog_info(\"fio: file %s failed allocating random map. Running \"\n\t\t\t \"job without.\\n\", f->file_name);\n\t}\n\n\treturn true;\n}\n\nvoid close_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i) {\n\t\tif (fio_file_open(f))\n\t\t\ttd_io_close_file(td, f);\n\t}\n}\n\nvoid fio_file_free(struct fio_file *f)\n{\n\tif (fio_file_axmap(f))\n\t\taxmap_free(f->io_axmap);\n\tif (f->ruhs_info)\n\t\tsfree(f->ruhs_info);\n\tif (!fio_file_smalloc(f)) {\n\t\tfree(f->file_name);\n\t\tfree(f);\n\t} else {\n\t\tsfree(f->file_name);\n\t\tsfree(f);\n\t}\n}\n\nvoid close_and_free_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tdprint(FD_FILE, \"close files\\n\");\n\n\tfor_each_file(td, f, i) {\n\t\tif (td->o.unlink && f->filetype == FIO_TYPE_FILE) {\n\t\t\tdprint(FD_FILE, \"free unlink %s\\n\", f->file_name);\n\t\t\ttd_io_unlink_file(td, f);\n\t\t}\n\n\t\tif (fio_file_open(f))\n\t\t\ttd_io_close_file(td, f);\n\n\t\tremove_file_hash(f);\n\n\t\tif (td->o.unlink && f->filetype == FIO_TYPE_FILE) {\n\t\t\tdprint(FD_FILE, \"free unlink %s\\n\", f->file_name);\n\t\t\ttd_io_unlink_file(td, f);\n\t\t}\n\n\t\tzbd_close_file(f);\n\t\tfdp_free_ruhs_info(f);\n\t\tfio_file_free(f);\n\t}\n\n\ttd->o.filename = NULL;\n\tfree(td->files);\n\tfree(td->file_locks);\n\ttd->files_index = 0;\n\ttd->files = NULL;\n\ttd->file_locks = NULL;\n\ttd->o.file_lock_mode = FILE_LOCK_NONE;\n\ttd->o.nr_files = 0;\n}\n\nstatic void get_file_type(struct fio_file *f)\n{\n\tstruct stat sb;\n\n\tif (!strcmp(f->file_name, \"-\"))\n\t\tf->filetype = FIO_TYPE_PIPE;\n\telse\n\t\tf->filetype = FIO_TYPE_FILE;\n\n#ifdef WIN32\n\t/* \\\\.\\ is the device namespace in Windows, where every file is\n\t * a block device */\n\tif (strncmp(f->file_name, \"\\\\\\\\.\\\\\", 4) == 0)\n\t\tf->filetype = FIO_TYPE_BLOCK;\n#endif\n\n\tif (!stat(f->file_name, &sb)) {\n\t\tif (S_ISBLK(sb.st_mode))\n\t\t\tf->filetype = FIO_TYPE_BLOCK;\n\t\telse if (S_ISCHR(sb.st_mode))\n\t\t\tf->filetype = FIO_TYPE_CHAR;\n\t\telse if (S_ISFIFO(sb.st_mode))\n\t\t\tf->filetype = FIO_TYPE_PIPE;\n\t}\n}\n\nstatic bool __is_already_allocated(const char *fname, bool set)\n{\n\tstruct flist_head *entry;\n\tbool ret;\n\n\tret = file_bloom_exists(fname, set);\n\tif (!ret)\n\t\treturn ret;\n\n\tflist_for_each(entry, &filename_list) {\n\t\tstruct file_name *fn;\n\n\t\tfn = flist_entry(entry, struct file_name, list);\n\n\t\tif (!strcmp(fn->filename, fname))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool is_already_allocated(const char *fname)\n{\n\tbool ret;\n\n\tfio_file_hash_lock();\n\tret = __is_already_allocated(fname, false);\n\tfio_file_hash_unlock();\n\n\treturn ret;\n}\n\nstatic void set_already_allocated(const char *fname)\n{\n\tstruct file_name *fn;\n\n\tfn = malloc(sizeof(struct file_name));\n\tfn->filename = strdup(fname);\n\n\tfio_file_hash_lock();\n\tif (!__is_already_allocated(fname, true)) {\n\t\tflist_add_tail(&fn->list, &filename_list);\n\t\tfn = NULL;\n\t}\n\tfio_file_hash_unlock();\n\n\tif (fn) {\n\t\tfree(fn->filename);\n\t\tfree(fn);\n\t}\n}\n\nstatic void free_already_allocated(void)\n{\n\tstruct flist_head *entry, *tmp;\n\tstruct file_name *fn;\n\n\tif (flist_empty(&filename_list))\n\t\treturn;\n\n\tfio_file_hash_lock();\n\tflist_for_each_safe(entry, tmp, &filename_list) {\n\t\tfn = flist_entry(entry, struct file_name, list);\n\t\tfree(fn->filename);\n\t\tflist_del(&fn->list);\n\t\tfree(fn);\n\t}\n\n\tfio_file_hash_unlock();\n}\n\nstatic struct fio_file *alloc_new_file(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\n\tif (td_ioengine_flagged(td, FIO_NOFILEHASH))\n\t\tf = calloc(1, sizeof(*f));\n\telse\n\t\tf = scalloc(1, sizeof(*f));\n\tif (!f) {\n\t\tassert(0);\n\t\treturn NULL;\n\t}\n\n\tf->fd = -1;\n\tf->shadow_fd = -1;\n\tfio_file_reset(td, f);\n\tif (!td_ioengine_flagged(td, FIO_NOFILEHASH))\n\t\tfio_file_set_smalloc(f);\n\treturn f;\n}\n\nbool exists_and_not_regfile(const char *filename)\n{\n\tstruct stat sb;\n\n\tif (lstat(filename, &sb) == -1)\n\t\treturn false;\n\n#ifndef WIN32 /* NOT Windows */\n\tif (S_ISREG(sb.st_mode))\n\t\treturn false;\n#else\n\t/* \\\\.\\ is the device namespace in Windows, where every file\n\t * is a device node */\n\tif (S_ISREG(sb.st_mode) && strncmp(filename, \"\\\\\\\\.\\\\\", 4) != 0)\n\t\treturn false;\n#endif\n\n\treturn true;\n}\n\nint add_file(struct thread_data *td, const char *fname, int numjob, int inc)\n{\n\tint cur_files = td->files_index;\n\tchar file_name[PATH_MAX];\n\tstruct fio_file *f;\n\tint len = 0;\n\n\tdprint(FD_FILE, \"add file %s\\n\", fname);\n\n\tif (td->o.directory)\n\t\tlen = set_name_idx(file_name, PATH_MAX, td->o.directory, numjob,\n\t\t\t\t\ttd->o.unique_filename);\n\n\tsprintf(file_name + len, \"%s\", fname);\n\n\t/* clean cloned siblings using existing files */\n\tif (numjob && is_already_allocated(file_name) &&\n\t    !exists_and_not_regfile(fname))\n\t\treturn 0;\n\n\tf = alloc_new_file(td);\n\n\tif (td->files_size <= td->files_index) {\n\t\tunsigned int new_size = td->o.nr_files + 1;\n\n\t\tdprint(FD_FILE, \"resize file array to %d files\\n\", new_size);\n\n\t\ttd->files = realloc(td->files, new_size * sizeof(f));\n\t\tif (td->files == NULL) {\n\t\t\tlog_err(\"fio: realloc OOM\\n\");\n\t\t\tassert(0);\n\t\t}\n\t\tif (td->o.file_lock_mode != FILE_LOCK_NONE) {\n\t\t\ttd->file_locks = realloc(td->file_locks, new_size);\n\t\t\tif (!td->file_locks) {\n\t\t\t\tlog_err(\"fio: realloc OOM\\n\");\n\t\t\t\tassert(0);\n\t\t\t}\n\t\t\ttd->file_locks[cur_files] = FILE_LOCK_NONE;\n\t\t}\n\t\ttd->files_size = new_size;\n\t}\n\ttd->files[cur_files] = f;\n\tf->fileno = cur_files;\n\n\t/*\n\t * init function, io engine may not be loaded yet\n\t */\n\tif (td->io_ops && td_ioengine_flagged(td, FIO_DISKLESSIO))\n\t\tf->real_file_size = -1ULL;\n\n\tif (td_ioengine_flagged(td, FIO_NOFILEHASH))\n\t\tf->file_name = strdup(file_name);\n\telse\n\t\tf->file_name = smalloc_strdup(file_name);\n\n\t/* can't handle smalloc failure from here */\n\tassert(f->file_name);\n\n\tget_file_type(f);\n\n\tswitch (td->o.file_lock_mode) {\n\tcase FILE_LOCK_NONE:\n\t\tbreak;\n\tcase FILE_LOCK_READWRITE:\n\t\tf->rwlock = fio_rwlock_init();\n\t\tbreak;\n\tcase FILE_LOCK_EXCLUSIVE:\n\t\tf->lock = fio_sem_init(FIO_SEM_UNLOCKED);\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: unknown lock mode: %d\\n\", td->o.file_lock_mode);\n\t\tassert(0);\n\t}\n\n\ttd->files_index++;\n\n\tif (td->o.numjobs > 1)\n\t\tset_already_allocated(file_name);\n\n\tif (inc)\n\t\ttd->o.nr_files++;\n\n\tdprint(FD_FILE, \"file %p \\\"%s\\\" added at %d\\n\", f, f->file_name,\n\t\t\t\t\t\t\tcur_files);\n\n\treturn cur_files;\n}\n\nint add_file_exclusive(struct thread_data *td, const char *fname)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i) {\n\t\tif (!strcmp(f->file_name, fname))\n\t\t\treturn i;\n\t}\n\n\treturn add_file(td, fname, 0, 1);\n}\n\nvoid get_file(struct fio_file *f)\n{\n\tdprint(FD_FILE, \"get file %s, ref=%d\\n\", f->file_name, f->references);\n\tassert(fio_file_open(f));\n\tf->references++;\n}\n\nint put_file(struct thread_data *td, struct fio_file *f)\n{\n\tint f_ret = 0, ret = 0;\n\n\tdprint(FD_FILE, \"put file %s, ref=%d\\n\", f->file_name, f->references);\n\n\tif (!fio_file_open(f)) {\n\t\tassert(f->fd == -1);\n\t\treturn 0;\n\t}\n\n\tassert(f->references);\n\tif (--f->references)\n\t\treturn 0;\n\n\tdisk_util_dec(f->du);\n\n\tif (td->o.file_lock_mode != FILE_LOCK_NONE)\n\t\tunlock_file_all(td, f);\n\n\tif (should_fsync(td) && td->o.fsync_on_close) {\n\t\tf_ret = fsync(f->fd);\n\t\tif (f_ret < 0)\n\t\t\tf_ret = errno;\n\t}\n\n\tif (td->io_ops->close_file)\n\t\tret = td->io_ops->close_file(td, f);\n\n\tif (!ret)\n\t\tret = f_ret;\n\n\ttd->nr_open_files--;\n\tfio_file_clear_closing(f);\n\tfio_file_clear_open(f);\n\tassert(f->fd == -1);\n\treturn ret;\n}\n\nvoid lock_file(struct thread_data *td, struct fio_file *f, enum fio_ddir ddir)\n{\n\tif (!f->lock || td->o.file_lock_mode == FILE_LOCK_NONE)\n\t\treturn;\n\n\tif (td->o.file_lock_mode == FILE_LOCK_READWRITE) {\n\t\tif (ddir == DDIR_READ)\n\t\t\tfio_rwlock_read(f->rwlock);\n\t\telse\n\t\t\tfio_rwlock_write(f->rwlock);\n\t} else if (td->o.file_lock_mode == FILE_LOCK_EXCLUSIVE)\n\t\tfio_sem_down(f->lock);\n\n\ttd->file_locks[f->fileno] = td->o.file_lock_mode;\n}\n\nvoid unlock_file(struct thread_data *td, struct fio_file *f)\n{\n\tif (!f->lock || td->o.file_lock_mode == FILE_LOCK_NONE)\n\t\treturn;\n\n\tif (td->o.file_lock_mode == FILE_LOCK_READWRITE)\n\t\tfio_rwlock_unlock(f->rwlock);\n\telse if (td->o.file_lock_mode == FILE_LOCK_EXCLUSIVE)\n\t\tfio_sem_up(f->lock);\n\n\ttd->file_locks[f->fileno] = FILE_LOCK_NONE;\n}\n\nvoid unlock_file_all(struct thread_data *td, struct fio_file *f)\n{\n\tif (td->o.file_lock_mode == FILE_LOCK_NONE || !td->file_locks)\n\t\treturn;\n\tif (td->file_locks[f->fileno] != FILE_LOCK_NONE)\n\t\tunlock_file(td, f);\n}\n\nstatic bool recurse_dir(struct thread_data *td, const char *dirname)\n{\n\tstruct dirent *dir;\n\tbool ret = false;\n\tDIR *D;\n\n\tD = opendir(dirname);\n\tif (!D) {\n\t\tchar buf[FIO_VERROR_SIZE];\n\n\t\tsnprintf(buf, FIO_VERROR_SIZE, \"opendir(%s)\", dirname);\n\t\ttd_verror(td, errno, buf);\n\t\treturn true;\n\t}\n\n\twhile ((dir = readdir(D)) != NULL) {\n\t\tchar full_path[PATH_MAX];\n\t\tstruct stat sb;\n\n\t\tif (!strcmp(dir->d_name, \".\") || !strcmp(dir->d_name, \"..\"))\n\t\t\tcontinue;\n\n\t\tsprintf(full_path, \"%s%c%s\", dirname, FIO_OS_PATH_SEPARATOR, dir->d_name);\n\n\t\tif (lstat(full_path, &sb) == -1) {\n\t\t\tif (errno != ENOENT) {\n\t\t\t\ttd_verror(td, errno, \"stat\");\n\t\t\t\tret = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (S_ISREG(sb.st_mode)) {\n\t\t\tadd_file(td, full_path, 0, 1);\n\t\t\tcontinue;\n\t\t}\n\t\tif (!S_ISDIR(sb.st_mode))\n\t\t\tcontinue;\n\n\t\tret = recurse_dir(td, full_path);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tclosedir(D);\n\treturn ret;\n}\n\nint add_dir_files(struct thread_data *td, const char *path)\n{\n\tint ret = recurse_dir(td, path);\n\n\tif (!ret)\n\t\tlog_info(\"fio: opendir added %d files\\n\", td->o.nr_files);\n\n\treturn ret;\n}\n\nvoid dup_files(struct thread_data *td, struct thread_data *org)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tdprint(FD_FILE, \"dup files: %d\\n\", org->files_index);\n\n\tif (!org->files)\n\t\treturn;\n\n\ttd->files = calloc(org->files_index, sizeof(f));\n\n\tif (td->o.file_lock_mode != FILE_LOCK_NONE)\n\t\ttd->file_locks = malloc(org->files_index);\n\n\tassert(org->files_index >= org->o.nr_files);\n\tfor_each_file(org, f, i) {\n\t\tstruct fio_file *__f;\n\n\t\t__f = alloc_new_file(td);\n\n\t\tif (f->file_name) {\n\t\t\tif (td_ioengine_flagged(td, FIO_NOFILEHASH))\n\t\t\t\t__f->file_name = strdup(f->file_name);\n\t\t\telse\n\t\t\t\t__f->file_name = smalloc_strdup(f->file_name);\n\n\t\t\t/* can't handle smalloc failure from here */\n\t\t\tassert(__f->file_name);\n\t\t\t__f->filetype = f->filetype;\n\t\t}\n\n\t\tif (td->o.file_lock_mode == FILE_LOCK_EXCLUSIVE)\n\t\t\t__f->lock = f->lock;\n\t\telse if (td->o.file_lock_mode == FILE_LOCK_READWRITE)\n\t\t\t__f->rwlock = f->rwlock;\n\n\t\ttd->files[i] = __f;\n\t}\n}\n\n/*\n * Returns the index that matches the filename, or -1 if not there\n */\nint get_fileno(struct thread_data *td, const char *fname)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i)\n\t\tif (!strcmp(f->file_name, fname))\n\t\t\treturn i;\n\n\treturn -1;\n}\n\n/*\n * For log usage, where we add/open/close files automatically\n */\nvoid free_release_files(struct thread_data *td)\n{\n\tclose_files(td);\n\ttd->o.nr_files = 0;\n\ttd->o.open_files = 0;\n\ttd->files_index = 0;\n}\n\nvoid fio_file_reset(struct thread_data *td, struct fio_file *f)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tf->last_pos[i] = f->file_offset;\n\t\tf->last_start[i] = -1ULL;\n\t}\n\n\tif (fio_file_axmap(f))\n\t\taxmap_reset(f->io_axmap);\n\telse if (fio_file_lfsr(f))\n\t\tlfsr_reset(&f->lfsr, td->rand_seeds[FIO_RAND_BLOCK_OFF]);\n\n\tzbd_file_reset(td, f);\n}\n\nbool fio_files_done(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\tfor_each_file(td, f, i)\n\t\tif (!fio_file_done(f))\n\t\t\treturn false;\n\n\treturn true;\n}\n\n/* free memory used in initialization phase only */\nvoid filesetup_mem_free(void)\n{\n\tfree_already_allocated();\n}\n\n/*\n * This function is for platforms which support direct I/O but not O_DIRECT.\n */\nint fio_set_directio(struct thread_data *td, struct fio_file *f)\n{\n#ifdef FIO_OS_DIRECTIO\n\tint ret = fio_set_odirect(f);\n\n\tif (ret) {\n\t\ttd_verror(td, ret, \"fio_set_directio\");\n#if defined(__sun__)\n\t\tif (ret == ENOTTY) { /* ENOTTY suggests RAW device or ZFS */\n\t\t\tlog_err(\"fio: doing directIO to RAW devices or ZFS not supported\\n\");\n\t\t} else {\n\t\t\tlog_err(\"fio: the file system does not seem to support direct IO\\n\");\n\t\t}\n#else\n\t\tlog_err(\"fio: the file system does not seem to support direct IO\\n\");\n#endif\n\t\treturn -1;\n\t}\n\n\treturn 0;\n#else\n\tlog_err(\"fio: direct IO is not supported on this host operating system\\n\");\n\treturn -1;\n#endif\n}\n"
        },
        {
          "name": "fio.1",
          "type": "blob",
          "size": 193.71484375,
          "content": ".TH fio 1 \"August 2017\" \"User Manual\"\n.SH NAME\nfio \\- flexible I/O tester\n.SH SYNOPSIS\n.B fio\n[\\fIoptions\\fR] [\\fIjobfile\\fR]...\n.SH DESCRIPTION\n.B fio\nis a tool that will spawn a number of threads or processes doing a\nparticular type of I/O action as specified by the user.\nThe typical use of fio is to write a job file matching the I/O load\none wants to simulate.\n.SH OPTIONS\n.TP\n.BI \\-\\-debug \\fR=\\fPtype\nEnable verbose tracing \\fItype\\fR of various fio actions. May be `all' for all \\fItype\\fRs\nor individual types separated by a comma (e.g. `\\-\\-debug=file,mem' will enable\nfile and memory debugging). `help' will list all available tracing options.\n.TP\n.BI \\-\\-parse\\-only\nParse options only, don't start any I/O.\n.TP\n.BI \\-\\-merge\\-blktrace\\-only\nMerge blktraces only, don't start any I/O.\n.TP\n.BI \\-\\-output \\fR=\\fPfilename\nWrite output to \\fIfilename\\fR.\n.TP\n.BI \\-\\-output\\-format \\fR=\\fPformat\nSet the reporting \\fIformat\\fR to `normal', `terse', `json', or\n`json+'. Multiple formats can be selected, separate by a comma. `terse'\nis a CSV based format. `json+' is like `json', except it adds a full\ndump of the latency buckets.\n.TP\n.BI \\-\\-bandwidth\\-log\nGenerate aggregate bandwidth logs.\n.TP\n.BI \\-\\-minimal\nPrint statistics in a terse, semicolon\\-delimited format.\n.TP\n.BI \\-\\-append\\-terse\nPrint statistics in selected mode AND terse, semicolon\\-delimited format.\n\\fBDeprecated\\fR, use \\fB\\-\\-output\\-format\\fR instead to select multiple formats.\n.TP\n.BI \\-\\-terse\\-version \\fR=\\fPversion\nSet terse \\fIversion\\fR output format (default `3', or `2', `4', `5').\n.TP\n.BI \\-\\-version\nPrint version information and exit.\n.TP\n.BI \\-\\-help\nPrint a summary of the command line options and exit.\n.TP\n.BI \\-\\-cpuclock\\-test\nPerform test and validation of internal CPU clock.\n.TP\n.BI \\-\\-crctest \\fR=\\fP[test]\nTest the speed of the built\\-in checksumming functions. If no argument is given,\nall of them are tested. Alternatively, a comma separated list can be passed, in which\ncase the given ones are tested.\n.TP\n.BI \\-\\-cmdhelp \\fR=\\fPcommand\nPrint help information for \\fIcommand\\fR. May be `all' for all commands.\n.TP\n.BI \\-\\-enghelp \\fR=\\fP[ioengine[,command]]\nList all commands defined by \\fIioengine\\fR, or print help for \\fIcommand\\fR\ndefined by \\fIioengine\\fR. If no \\fIioengine\\fR is given, list all\navailable ioengines.\n.TP\n.BI \\-\\-showcmd\nConvert given \\fIjobfile\\fRs to a set of command\\-line options.\n.TP\n.BI \\-\\-readonly\nTurn on safety read\\-only checks, preventing writes and trims. The \\fB\\-\\-readonly\\fR\noption is an extra safety guard to prevent users from accidentally starting\na write or trim workload when that is not desired. Fio will only modify the\ndevice under test if `rw=write/randwrite/rw/randrw/trim/randtrim/trimwrite'\nis given. This safety net can be used as an extra precaution.\n.TP\n.BI \\-\\-eta \\fR=\\fPwhen\nSpecifies when real\\-time ETA estimate should be printed. \\fIwhen\\fR may\nbe `always', `never' or `auto'. `auto' is the default, it prints ETA when\nrequested if the output is a TTY. `always' disregards the output type, and\nprints ETA when requested. `never' never prints ETA.\n.TP\n.BI \\-\\-eta\\-interval \\fR=\\fPtime\nBy default, fio requests client ETA status roughly every second. With this\noption, the interval is configurable. Fio imposes a minimum allowed time to\navoid flooding the console, less than 250 msec is not supported.\n.TP\n.BI \\-\\-eta\\-newline \\fR=\\fPtime\nForce a new line for every \\fItime\\fR period passed. When the unit is omitted,\nthe value is interpreted in seconds.\n.TP\n.BI \\-\\-status\\-interval \\fR=\\fPtime\nForce a full status dump of cumulative (from job start) values at \\fItime\\fR\nintervals. This option does *not* provide per-period measurements. So\nvalues such as bandwidth are running averages. When the time unit is omitted,\n\\fItime\\fR is interpreted in seconds. Note that using this option with\n`\\-\\-output-format=json' will yield output that technically isn't valid json,\nsince the output will be collated sets of valid json. It will need to be split\ninto valid sets of json after the run.\n.TP\n.BI \\-\\-section \\fR=\\fPname\nOnly run specified section \\fIname\\fR in job file. Multiple sections can be specified.\nThe \\fB\\-\\-section\\fR option allows one to combine related jobs into one file.\nE.g. one job file could define light, moderate, and heavy sections. Tell\nfio to run only the \"heavy\" section by giving `\\-\\-section=heavy'\ncommand line option. One can also specify the \"write\" operations in one\nsection and \"verify\" operation in another section. The \\fB\\-\\-section\\fR option\nonly applies to job sections. The reserved *global* section is always\nparsed and used.\n.TP\n.BI \\-\\-alloc\\-size \\fR=\\fPkb\nAllocate additional internal smalloc pools of size \\fIkb\\fR in KiB. The\n\\fB\\-\\-alloc\\-size\\fR option increases shared memory set aside for use by fio.\nIf running large jobs with randommap enabled, fio can run out of memory.\nSmalloc is an internal allocator for shared structures from a fixed size\nmemory pool and can grow to 16 pools. The pool size defaults to 16MiB.\nNOTE: While running `.fio_smalloc.*' backing store files are visible\nin `/tmp'.\n.TP\n.BI \\-\\-warnings\\-fatal\nAll fio parser warnings are fatal, causing fio to exit with an error.\n.TP\n.BI \\-\\-max\\-jobs \\fR=\\fPnr\nSet the maximum number of threads/processes to support to \\fInr\\fR.\nNOTE: On Linux, it may be necessary to increase the shared-memory limit\n(`/proc/sys/kernel/shmmax') if fio runs into errors while creating jobs.\n.TP\n.BI \\-\\-server \\fR=\\fPargs\nStart a backend server, with \\fIargs\\fR specifying what to listen to.\nSee \\fBCLIENT/SERVER\\fR section.\n.TP\n.BI \\-\\-daemonize \\fR=\\fPpidfile\nBackground a fio server, writing the pid to the given \\fIpidfile\\fR file.\n.TP\n.BI \\-\\-client \\fR=\\fPhostname\nInstead of running the jobs locally, send and run them on the given \\fIhostname\\fR\nor set of \\fIhostname\\fRs. See \\fBCLIENT/SERVER\\fR section.\n.TP\n.BI \\-\\-remote\\-config \\fR=\\fPfile\nTell fio server to load this local \\fIfile\\fR.\n.TP\n.BI \\-\\-idle\\-prof \\fR=\\fPoption\nReport CPU idleness. \\fIoption\\fR is one of the following:\n.RS\n.RS\n.TP\n.B calibrate\nRun unit work calibration only and exit.\n.TP\n.B system\nShow aggregate system idleness and unit work.\n.TP\n.B percpu\nAs \\fBsystem\\fR but also show per CPU idleness.\n.RE\n.RE\n.TP\n.BI \\-\\-inflate\\-log \\fR=\\fPlog\nInflate and output compressed \\fIlog\\fR.\n.TP\n.BI \\-\\-trigger\\-file \\fR=\\fPfile\nExecute trigger command when \\fIfile\\fR exists.\n.TP\n.BI \\-\\-trigger\\-timeout \\fR=\\fPtime\nExecute trigger at this \\fItime\\fR.\n.TP\n.BI \\-\\-trigger \\fR=\\fPcommand\nSet this \\fIcommand\\fR as local trigger.\n.TP\n.BI \\-\\-trigger\\-remote \\fR=\\fPcommand\nSet this \\fIcommand\\fR as remote trigger.\n.TP\n.BI \\-\\-aux\\-path \\fR=\\fPpath\nUse the directory specified by \\fIpath\\fP for generated state files instead\nof the current working directory.\n.SH \"JOB FILE FORMAT\"\nAny parameters following the options will be assumed to be job files, unless\nthey match a job file parameter. Multiple job files can be listed and each job\nfile will be regarded as a separate group. Fio will \\fBstonewall\\fR execution\nbetween each group.\n\nFio accepts one or more job files describing what it is\nsupposed to do. The job file format is the classic ini file, where the names\nenclosed in [] brackets define the job name. You are free to use any ASCII name\nyou want, except *global* which has special meaning. Following the job name is\na sequence of zero or more parameters, one per line, that define the behavior of\nthe job. If the first character in a line is a ';' or a '#', the entire line is\ndiscarded as a comment.\n\nA *global* section sets defaults for the jobs described in that file. A job may\noverride a *global* section parameter, and a job file may even have several\n*global* sections if so desired. A job is only affected by a *global* section\nresiding above it.\n\nThe \\fB\\-\\-cmdhelp\\fR option also lists all options. If used with an \\fIcommand\\fR\nargument, \\fB\\-\\-cmdhelp\\fR will detail the given \\fIcommand\\fR.\n\nSee the `examples/' directory for inspiration on how to write job files. Note\nthe copyright and license requirements currently apply to\n`examples/' files.\n\nNote that the maximum length of a line in the job file is 8192 bytes.\n.SH \"JOB FILE PARAMETERS\"\nSome parameters take an option of a given type, such as an integer or a\nstring. Anywhere a numeric value is required, an arithmetic expression may be\nused, provided it is surrounded by parentheses. Supported operators are:\n.RS\n.P\n.B addition (+)\n.P\n.B subtraction (\\-)\n.P\n.B multiplication (*)\n.P\n.B division (/)\n.P\n.B modulus (%)\n.P\n.B exponentiation (^)\n.RE\n.P\nFor time values in expressions, units are microseconds by default. This is\ndifferent than for time values not in expressions (not enclosed in\nparentheses).\n.SH \"PARAMETER TYPES\"\nThe following parameter types are used.\n.TP\n.I str\nString. A sequence of alphanumeric characters.\n.TP\n.I time\nInteger with possible time suffix. Without a unit value is interpreted as\nseconds unless otherwise specified. Accepts a suffix of 'd' for days, 'h' for\nhours, 'm' for minutes, 's' for seconds, 'ms' (or 'msec') for milliseconds and 'us'\n(or 'usec') for microseconds. For example, use 10m for 10 minutes.\n.TP\n.I int\nInteger. A whole number value, which may contain an integer prefix\nand an integer suffix.\n.RS\n.RS\n.P\n[*integer prefix*] **number** [*integer suffix*]\n.RE\n.P\nThe optional *integer prefix* specifies the number's base. The default\nis decimal. *0x* specifies hexadecimal.\n.P\nThe optional *integer suffix* specifies the number's units, and includes an\noptional unit prefix and an optional unit. For quantities of data, the\ndefault unit is bytes. For quantities of time, the default unit is seconds\nunless otherwise specified.\n.P\nWith `kb_base=1000', fio follows international standards for unit\nprefixes. To specify power-of-10 decimal values defined in the\nInternational System of Units (SI):\n.RS\n.P\n.PD 0\nK means kilo (K) or 1000\n.P\nM means mega (M) or 1000**2\n.P\nG means giga (G) or 1000**3\n.P\nT means tera (T) or 1000**4\n.P\nP means peta (P) or 1000**5\n.PD\n.RE\n.P\nTo specify power-of-2 binary values defined in IEC 80000-13:\n.RS\n.P\n.PD 0\nKi means kibi (Ki) or 1024\n.P\nMi means mebi (Mi) or 1024**2\n.P\nGi means gibi (Gi) or 1024**3\n.P\nTi means tebi (Ti) or 1024**4\n.P\nPi means pebi (Pi) or 1024**5\n.PD\n.RE\n.P\nFor Zone Block Device Mode:\n.RS\n.P\n.PD 0\nz means Zone\n.P\n.PD\n.RE\n.P\nWith `kb_base=1024' (the default), the unit prefixes are opposite\nfrom those specified in the SI and IEC 80000-13 standards to provide\ncompatibility with old scripts. For example, 4k means 4096.\n.P\nFor quantities of data, an optional unit of 'B' may be included\n(e.g., 'kB' is the same as 'k').\n.P\nThe *integer suffix* is not case sensitive (e.g., m/mi mean mebi/mega,\nnot milli). 'b' and 'B' both mean byte, not bit.\n.P\nExamples with `kb_base=1000':\n.RS\n.P\n.PD 0\n4 KiB: 4096, 4096b, 4096B, 4k, 4kb, 4kB, 4K, 4KB\n.P\n1 MiB: 1048576, 1m, 1024k\n.P\n1 MB: 1000000, 1mi, 1000ki\n.P\n1 TiB: 1073741824, 1t, 1024m, 1048576k\n.P\n1 TB: 1000000000, 1ti, 1000mi, 1000000ki\n.PD\n.RE\n.P\nExamples with `kb_base=1024' (default):\n.RS\n.P\n.PD 0\n4 KiB: 4096, 4096b, 4096B, 4k, 4kb, 4kB, 4K, 4KB\n.P\n1 MiB: 1048576, 1m, 1024k\n.P\n1 MB: 1000000, 1mi, 1000ki\n.P\n1 TiB: 1073741824, 1t, 1024m, 1048576k\n.P\n1 TB: 1000000000, 1ti, 1000mi, 1000000ki\n.PD\n.RE\n.P\nTo specify times (units are not case sensitive):\n.RS\n.P\n.PD 0\nD means days\n.P\nH means hours\n.P\nM mean minutes\n.P\ns or sec means seconds (default)\n.P\nms or msec means milliseconds\n.P\nus or usec means microseconds\n.PD\n.RE\n.P\n`z' suffix specifies that the value is measured in zones.\nValue is recalculated once block device's zone size becomes known.\n.P\nIf the option accepts an upper and lower range, use a colon ':' or\nminus '\\-' to separate such values. See \\fIirange\\fR parameter type.\nIf the lower value specified happens to be larger than the upper value\nthe two values are swapped.\n.RE\n.TP\n.I bool\nBoolean. Usually parsed as an integer, however only defined for\ntrue and false (1 and 0).\n.TP\n.I irange\nInteger range with suffix. Allows value range to be given, such as\n1024\\-4096. A colon may also be used as the separator, e.g. 1k:4k. If the\noption allows two sets of ranges, they can be specified with a ',' or '/'\ndelimiter: 1k\\-4k/8k\\-32k. Also see \\fIint\\fR parameter type.\n.TP\n.I float_list\nA list of floating point numbers, separated by a ':' character.\n.SH \"JOB PARAMETERS\"\nWith the above in mind, here follows the complete list of fio job parameters.\n.SS \"Units\"\n.TP\n.BI kb_base \\fR=\\fPint\nSelect the interpretation of unit prefixes in input parameters.\n.RS\n.RS\n.TP\n.B 1000\nInputs comply with IEC 80000-13 and the International\nSystem of Units (SI). Use:\n.RS\n.P\n.PD 0\n\\- power-of-2 values with IEC prefixes (e.g., KiB)\n.P\n\\- power-of-10 values with SI prefixes (e.g., kB)\n.PD\n.RE\n.TP\n.B 1024\nCompatibility mode (default). To avoid breaking old scripts:\n.P\n.RS\n.PD 0\n\\- power-of-2 values with SI prefixes\n.P\n\\- power-of-10 values with IEC prefixes\n.PD\n.RE\n.RE\n.P\nSee \\fBbs\\fR for more details on input parameters.\n.P\nOutputs always use correct prefixes. Most outputs include both\nside-by-side, like:\n.P\n.RS\nbw=2383.3kB/s (2327.4KiB/s)\n.RE\n.P\nIf only one value is reported, then kb_base selects the one to use:\n.P\n.RS\n.PD 0\n1000 \\-\\- SI prefixes\n.P\n1024 \\-\\- IEC prefixes\n.PD\n.RE\n.RE\n.TP\n.BI unit_base \\fR=\\fPint\nBase unit for reporting. Allowed values are:\n.RS\n.RS\n.TP\n.B 0\nUse auto-detection (default).\n.TP\n.B 8\nByte based.\n.TP\n.B 1\nBit based.\n.RE\n.RE\n.SS \"Job description\"\n.TP\n.BI name \\fR=\\fPstr\nASCII name of the job. This may be used to override the name printed by fio\nfor this job. Otherwise the job name is used. On the command line this\nparameter has the special purpose of also signaling the start of a new job.\n.TP\n.BI description \\fR=\\fPstr\nText description of the job. Doesn't do anything except dump this text\ndescription when this job is run. It's not parsed.\n.TP\n.BI loops \\fR=\\fPint\nRun the specified number of iterations of this job. Used to repeat the same\nworkload a given number of times. Defaults to 1.\n.TP\n.BI numjobs \\fR=\\fPint\nCreate the specified number of clones of this job. Each clone of job\nis spawned as an independent thread or process. May be used to setup a\nlarger number of threads/processes doing the same thing. Each thread is\nreported separately; to see statistics for all clones as a whole, use\n\\fBgroup_reporting\\fR in conjunction with \\fBnew_group\\fR.\nSee \\fB\\-\\-max\\-jobs\\fR. Default: 1.\n.SS \"Time related parameters\"\n.TP\n.BI runtime \\fR=\\fPtime\nLimit runtime. The test will run until it completes the configured I/O\nworkload or until it has run for this specified amount of time, whichever\noccurs first. It can be quite hard to determine for how long a specified\njob will run, so this parameter is handy to cap the total runtime to a\ngiven time.  When the unit is omitted, the value is interpreted in\nseconds.\n.TP\n.BI time_based\nIf set, fio will run for the duration of the \\fBruntime\\fR specified\neven if the file(s) are completely read or written. It will simply loop over\nthe same workload as many times as the \\fBruntime\\fR allows.\n.TP\n.BI startdelay \\fR=\\fPirange(int)\nDelay the start of job for the specified amount of time. Can be a single\nvalue or a range. When given as a range, each thread will choose a value\nrandomly from within the range. Value is in seconds if a unit is omitted.\n.TP\n.BI ramp_time \\fR=\\fPtime\nIf set, fio will run the specified workload for this amount of time before\nlogging any performance numbers. Useful for letting performance settle\nbefore logging results, thus minimizing the runtime required for stable\nresults. Note that the \\fBramp_time\\fR is considered lead in time for a job,\nthus it will increase the total runtime if a special timeout or\n\\fBruntime\\fR is specified. When the unit is omitted, the value is\ngiven in seconds.\n.TP\n.BI clocksource \\fR=\\fPstr\nUse the given clocksource as the base of timing. The supported options are:\n.RS\n.RS\n.TP\n.B gettimeofday\n\\fBgettimeofday\\fR\\|(2)\n.TP\n.B clock_gettime\n\\fBclock_gettime\\fR\\|(2)\n.TP\n.B cpu\nInternal CPU clock source\n.RE\n.P\n\\fBcpu\\fR is the preferred clocksource if it is reliable, as it is very fast (and\nfio is heavy on time calls). Fio will automatically use this clocksource if\nit's supported and considered reliable on the system it is running on,\nunless another clocksource is specifically set. For x86/x86\\-64 CPUs, this\nmeans supporting TSC Invariant.\n.RE\n.TP\n.BI gtod_reduce \\fR=\\fPbool\nEnable all of the \\fBgettimeofday\\fR\\|(2) reducing options\n(\\fBdisable_clat\\fR, \\fBdisable_slat\\fR, \\fBdisable_bw_measurement\\fR) plus\nreduce precision of the timeout somewhat to really shrink the\n\\fBgettimeofday\\fR\\|(2) call count. With this option enabled, we only do\nabout 0.4% of the \\fBgettimeofday\\fR\\|(2) calls we would have done if all\ntime keeping was enabled.\n.TP\n.BI gtod_cpu \\fR=\\fPint\nSometimes it's cheaper to dedicate a single thread of execution to just\ngetting the current time. Fio (and databases, for instance) are very\nintensive on \\fBgettimeofday\\fR\\|(2) calls. With this option, you can set\none CPU aside for doing nothing but logging current time to a shared memory\nlocation. Then the other threads/processes that run I/O workloads need only\ncopy that segment, instead of entering the kernel with a\n\\fBgettimeofday\\fR\\|(2) call. The CPU set aside for doing these time\ncalls will be excluded from other uses. Fio will manually clear it from the\nCPU mask of other jobs.\n.TP\n.BI job_start_clock_id \\fR=\\fPint\nThe clock_id passed to the call to \\fBclock_gettime\\fR used to record job_start\nin the \\fBjson\\fR output format. Default is 0, or CLOCK_REALTIME.\n.SS \"Target file/device\"\n.TP\n.BI directory \\fR=\\fPstr\nPrefix \\fBfilename\\fRs with this directory. Used to place files in a different\nlocation than `./'. You can specify a number of directories by\nseparating the names with a ':' character. These directories will be\nassigned equally distributed to job clones created by \\fBnumjobs\\fR as\nlong as they are using generated filenames. If specific \\fBfilename\\fR(s) are\nset fio will use the first listed directory, and thereby matching the\n\\fBfilename\\fR semantic (which generates a file for each clone if not\nspecified, but lets all clones use the same file if set).\n.RS\n.P\nSee the \\fBfilename\\fR option for information on how to escape ':'\ncharacters within the directory path itself.\n.P\nNote: To control the directory fio will use for internal state files\nuse \\fB\\-\\-aux\\-path\\fR.\n.RE\n.TP\n.BI filename \\fR=\\fPstr\nFio normally makes up a \\fBfilename\\fR based on the job name, thread number, and\nfile number (see \\fBfilename_format\\fR). If you want to share files\nbetween threads in a job or several\njobs with fixed file paths, specify a \\fBfilename\\fR for each of them to override\nthe default. If the ioengine is file based, you can specify a number of files\nby separating the names with a ':' colon. So if you wanted a job to open\n`/dev/sda' and `/dev/sdb' as the two working files, you would use\n`filename=/dev/sda:/dev/sdb'. This also means that whenever this option is\nspecified, \\fBnrfiles\\fR is ignored. The size of regular files specified\nby this option will be \\fBsize\\fR divided by number of files unless an\nexplicit size is specified by \\fBfilesize\\fR.\n.RS\n.P\nEach colon in the wanted path must be escaped with a '\\e'\ncharacter. For instance, if the path is `/dev/dsk/foo@3,0:c' then you\nwould use `filename=/dev/dsk/foo@3,0\\\\:c' and if the path is\n`F:\\\\filename' then you would use `filename=F\\\\:\\\\filename'.\n.P\nOn Windows, disk devices are accessed as `\\\\\\\\.\\\\PhysicalDrive0' for\nthe first device, `\\\\\\\\.\\\\PhysicalDrive1' for the second etc.\nNote: Windows and FreeBSD prevent write access to areas\nof the disk containing in-use data (e.g. filesystems).\n.P\nFor HTTP and S3 access, specify a valid URL path or S3 key, respectively. \nA filename for path-style S3 includes a bucket name (`/bucket/k/e.y') \nwhile a virtual-hosted-style S3 filename (`/k/e.y') does not because its \nbucket name is specified in \\fBhttp_host\\fR.\n.P\nThe filename `\\-' is a reserved name, meaning *stdin* or *stdout*. Which\nof the two depends on the read/write direction set.\n.RE\n.TP\n.BI filename_format \\fR=\\fPstr\nIf sharing multiple files between jobs, it is usually necessary to have fio\ngenerate the exact names that you want. By default, fio will name a file\nbased on the default file format specification of\n`jobname.jobnumber.filenumber'. With this option, that can be\ncustomized. Fio will recognize and replace the following keywords in this\nstring:\n.RS\n.RS\n.TP\n.B $jobname\nThe name of the worker thread or process.\n.TP\n.B $clientuid\nIP of the fio process when using client/server mode.\n.TP\n.B $jobnum\nThe incremental number of the worker thread or process.\n.TP\n.B $filenum\nThe incremental number of the file for that worker thread or process.\n.RE\n.P\nTo have dependent jobs share a set of files, this option can be set to have\nfio generate filenames that are shared between the two. For instance, if\n`testfiles.$filenum' is specified, file number 4 for any job will be\nnamed `testfiles.4'. The default of `$jobname.$jobnum.$filenum'\nwill be used if no other format specifier is given.\n.P\nIf you specify a path then the directories will be created up to the main\ndirectory for the file.  So for example if you specify `a/b/c/$jobnum` then the\ndirectories a/b/c will be created before the file setup part of the job.  If you\nspecify \\fBdirectory\\fR then the path will be relative that directory, otherwise\nit is treated as the absolute path.\n.RE\n.TP\n.BI unique_filename \\fR=\\fPbool\nTo avoid collisions between networked clients, fio defaults to prefixing any\ngenerated filenames (with a directory specified) with the source of the\nclient connecting. To disable this behavior, set this option to 0.\n.TP\n.BI opendir \\fR=\\fPstr\nRecursively open any files below directory \\fIstr\\fR. This accepts only a\nsingle directory and unlike related options, colons appearing in the path must\nnot be escaped.\n.TP\n.BI lockfile \\fR=\\fPstr\nFio defaults to not locking any files before it does I/O to them. If a file\nor file descriptor is shared, fio can serialize I/O to that file to make the\nend result consistent. This is usual for emulating real workloads that share\nfiles. The lock modes are:\n.RS\n.RS\n.TP\n.B none\nNo locking. The default.\n.TP\n.B exclusive\nOnly one thread or process may do I/O at a time, excluding all others.\n.TP\n.B readwrite\nRead\\-write locking on the file. Many readers may\naccess the file at the same time, but writes get exclusive access.\n.RE\n.RE\n.TP\n.BI nrfiles \\fR=\\fPint\nNumber of files to use for this job. Defaults to 1. The size of files\nwill be \\fBsize\\fR divided by this unless explicit size is specified by\n\\fBfilesize\\fR. Files are created for each thread separately, and each\nfile will have a file number within its name by default, as explained in\n\\fBfilename\\fR section.\n.TP\n.BI openfiles \\fR=\\fPint\nNumber of files to keep open at the same time. Defaults to the same as\n\\fBnrfiles\\fR, can be set smaller to limit the number simultaneous\nopens.\n.TP\n.BI file_service_type \\fR=\\fPstr\nDefines how fio decides which file from a job to service next. The following\ntypes are defined:\n.RS\n.RS\n.TP\n.B random\nChoose a file at random.\n.TP\n.B roundrobin\nRound robin over opened files. This is the default.\n.TP\n.B sequential\nFinish one file before moving on to the next. Multiple files can\nstill be open depending on \\fBopenfiles\\fR.\n.TP\n.B zipf\nUse a Zipf distribution to decide what file to access.\n.TP\n.B pareto\nUse a Pareto distribution to decide what file to access.\n.TP\n.B normal\nUse a Gaussian (normal) distribution to decide what file to access.\n.TP\n.B gauss\nAlias for normal.\n.RE\n.P\nFor \\fBrandom\\fR, \\fBroundrobin\\fR, and \\fBsequential\\fR, a postfix can be appended to\ntell fio how many I/Os to issue before switching to a new file. For example,\nspecifying `file_service_type=random:8' would cause fio to issue\n8 I/Os before selecting a new file at random. For the non-uniform\ndistributions, a floating point postfix can be given to influence how the\ndistribution is skewed. See \\fBrandom_distribution\\fR for a description\nof how that would work.\n.RE\n.TP\n.BI ioscheduler \\fR=\\fPstr\nAttempt to switch the device hosting the file to the specified I/O scheduler\nbefore running. If the file is a pipe, a character device file or if device\nhosting the file could not be determined, this option is ignored.\n.TP\n.BI create_serialize \\fR=\\fPbool\nIf true, serialize the file creation for the jobs. This may be handy to\navoid interleaving of data files, which may greatly depend on the filesystem\nused and even the number of processors in the system. Default: true.\n.TP\n.BI create_fsync \\fR=\\fPbool\n\\fBfsync\\fR\\|(2) the data file after creation. This is the default.\n.TP\n.BI create_on_open \\fR=\\fPbool\nIf true, don't pre-create files but allow the job's open() to create a file\nwhen it's time to do I/O. Default: false \\-\\- pre-create all necessary files\nwhen the job starts.\n.TP\n.BI create_only \\fR=\\fPbool\nIf true, fio will only run the setup phase of the job. If files need to be\nlaid out or updated on disk, only that will be done \\-\\- the actual job contents\nare not executed. Default: false.\n.TP\n.BI allow_file_create \\fR=\\fPbool\nIf true, fio is permitted to create files as part of its workload. If this\noption is false, then fio will error out if\nthe files it needs to use don't already exist. Default: true.\n.TP\n.BI allow_mounted_write \\fR=\\fPbool\nIf this isn't set, fio will abort jobs that are destructive (e.g. that write)\nto what appears to be a mounted device or partition. This should help catch\ncreating inadvertently destructive tests, not realizing that the test will\ndestroy data on the mounted file system. Note that some platforms don't allow\nwriting against a mounted device regardless of this option. Default: false.\n.TP\n.BI pre_read \\fR=\\fPbool\nIf this is given, files will be pre-read into memory before starting the\ngiven I/O operation. This will also clear the \\fBinvalidate\\fR flag,\nsince it is pointless to pre-read and then drop the cache. This will only\nwork for I/O engines that are seek-able, since they allow you to read the\nsame data multiple times. Thus it will not work on non-seekable I/O engines\n(e.g. network, splice). Default: false.\n.TP\n.BI unlink \\fR=\\fPbool\nUnlink (delete) the job files when done. Not the default, as repeated runs of that\njob would then waste time recreating the file set again and again. Default:\nfalse.\n.TP\n.BI unlink_each_loop \\fR=\\fPbool\nUnlink (delete) job files after each iteration or loop. Default: false.\n.TP\n.BI zonemode \\fR=\\fPstr\nAccepted values are:\n.RS\n.RS\n.TP\n.B none\nThe \\fBzonerange\\fR, \\fBzonesize\\fR \\fBzonecapacity\\fR and \\fBzoneskip\\fR\nparameters are ignored.\n.TP\n.B strided\nI/O happens in a single zone until \\fBzonesize\\fR bytes have been transferred.\nAfter that number of bytes has been transferred processing of the next zone\nstarts. The \\fBzonecapacity\\fR parameter is ignored.\n.TP\n.B zbd\nZoned block device mode. I/O happens sequentially in each zone, even if random\nI/O has been selected. Random I/O happens across all zones instead of being\nrestricted to a single zone.\nTrim is handled using a zone reset operation. Trim only considers non-empty\nsequential write required and sequential write preferred zones.\n.RE\n.RE\n.TP\n.BI zonerange \\fR=\\fPint\nFor \\fBzonemode\\fR=strided, this is the size of a single zone. See also\n\\fBzonesize\\fR and \\fBzoneskip\\fR.\n\nFor \\fBzonemode\\fR=zbd, this parameter is ignored.\n.TP\n.BI zonesize \\fR=\\fPint\nFor \\fBzonemode\\fR=strided, this is the number of bytes to transfer before\nskipping \\fBzoneskip\\fR bytes. If this parameter is smaller than\n\\fBzonerange\\fR then only a fraction of each zone with \\fBzonerange\\fR bytes\nwill be accessed.  If this parameter is larger than \\fBzonerange\\fR then each\nzone will be accessed multiple times before skipping to the next zone.\n\nFor \\fBzonemode\\fR=zbd, this is the size of a single zone. The\n\\fBzonerange\\fR parameter is ignored in this mode. For a job accessing a\nzoned block device, the specified \\fBzonesize\\fR must be 0 or equal to the\ndevice zone size. For a regular block device or file, the specified\n\\fBzonesize\\fR must be at least 512B.\n.TP\n.BI zonecapacity \\fR=\\fPint\nFor \\fBzonemode\\fR=zbd, this defines the capacity of a single zone, which is\nthe accessible area starting from the zone start address. This parameter only\napplies when using \\fBzonemode\\fR=zbd in combination with regular block devices.\nIf not specified it defaults to the zone size. If the target device is a zoned\nblock device, the zone capacity is obtained from the device information and this\noption is ignored.\n.TP\n.BI zoneskip \\fR=\\fPint[z]\nFor \\fBzonemode\\fR=strided, the number of bytes to skip after \\fBzonesize\\fR\nbytes of data have been transferred.\n\nFor \\fBzonemode\\fR=zbd, the \\fBzonesize\\fR aligned number of bytes to skip\nonce a zone is fully written (write workloads) or all written data in the\nzone have been read (read workloads). This parameter is valid only for\nsequential workloads and ignored for random workloads. For read workloads,\nsee also \\fBread_beyond_wp\\fR.\n\n.TP\n.BI read_beyond_wp \\fR=\\fPbool\nThis parameter applies to \\fBzonemode=zbd\\fR only.\n\nZoned block devices are block devices that consist of multiple zones. Each\nzone has a type, e.g. conventional or sequential. A conventional zone can be\nwritten at any offset that is a multiple of the block size. Sequential zones\nmust be written sequentially. The position at which a write must occur is\ncalled the write pointer. A zoned block device can be either host managed or\nhost aware. For host managed devices the host must ensure that writes happen\nsequentially. Fio recognizes host managed devices and serializes writes to\nsequential zones for these devices.\n\nIf a read occurs in a sequential zone beyond the write pointer then the zoned\nblock device will complete the read without reading any data from the storage\nmedium. Since such reads lead to unrealistically high bandwidth and IOPS\nnumbers fio only reads beyond the write pointer if explicitly told to do\nso. Default: false.\n.TP\n.BI max_open_zones \\fR=\\fPint\nWhen a zone of a zoned block device is partially written (i.e. not all sectors\nof the zone have been written), the zone is in one of three\nconditions: 'implicit open', 'explicit open' or 'closed'. Zoned block devices\nmay have a limit called 'max_open_zones' (same name as the parameter) on the\ntotal number of zones that can simultaneously be in the 'implicit open'\nor 'explicit open' conditions. Zoned block devices may have another limit\ncalled 'max_active_zones', on the total number of zones that can simultaneously\nbe in the three conditions. The \\fBmax_open_zones\\fR parameter limits\nthe number of zones to which write commands are issued by all fio jobs, that is,\nlimits the number of zones that will be in the conditions. When the device has\nthe max_open_zones limit and does not have the max_active_zones limit, the\n\\fBmax_open_zones\\fR parameter limits the number of zones in the two open\nconditions up to the limit. In this case, fio includes zones in the two open\nconditions to the write target zones at fio start. When the device has both the\nmax_open_zones and the max_active_zones limits, the \\fBmax_open_zones\\fR\nparameter limits the number of zones in the three conditions up to the limit.\nIn this case, fio includes zones in the three conditions to the write target\nzones at fio start.\n\nThis parameter is relevant only if the \\fBzonemode=zbd\\fR is used. The default\nvalue is always equal to the max_open_zones limit of the target zoned block\ndevice and a value higher than this limit cannot be specified by users unless\nthe option \\fBignore_zone_limits\\fR is specified. When \\fBignore_zone_limits\\fR\nis specified or the target device does not have the max_open_zones limit,\n\\fBmax_open_zones\\fR can specify 0 to disable any limit on the number of zones\nthat can be simultaneously written to by all jobs.\n.TP\n.BI job_max_open_zones \\fR=\\fPint\nIn the same manner as \\fBmax_open_zones\\fR, limit the number of open zones per\nfio job, that is, the number of zones that a single job can simultaneously write\nto. A value of zero indicates no limit. Default: zero.\n.TP\n.BI ignore_zone_limits \\fR=\\fPbool\nIf this option is used, fio will ignore the maximum number of open zones limit\nof the zoned block device in use, thus allowing the option \\fBmax_open_zones\\fR\nvalue to be larger than the device reported limit. Default: false.\n.TP\n.BI zone_reset_threshold \\fR=\\fPfloat\nA number between zero and one that indicates the ratio of written bytes in the\nzones with write pointers in the IO range to the size of the IO range. When\ncurrent ratio is above this ratio, zones are reset periodically as\n\\fBzone_reset_frequency\\fR specifies. If there are multiple jobs when using this\noption, the IO range for all write jobs has to be the same.\n.TP\n.BI zone_reset_frequency \\fR=\\fPfloat\nA number between zero and one that indicates how often a zone reset should be\nissued if the zone reset threshold has been exceeded. A zone reset is\nsubmitted after each (1 / zone_reset_frequency) write requests. This and the\nprevious parameter can be used to simulate garbage collection activity.\n\n.SS \"I/O type\"\n.TP\n.BI direct \\fR=\\fPbool\nIf value is true, use non-buffered I/O. This is usually O_DIRECT. Note that\nOpenBSD and ZFS on Solaris don't support direct I/O. On Windows the synchronous\nioengines don't support direct I/O. Default: false.\n.TP\n.BI buffered \\fR=\\fPbool\nIf value is true, use buffered I/O. This is the opposite of the\n\\fBdirect\\fR option. Defaults to true.\n.TP\n.BI readwrite \\fR=\\fPstr \"\\fR,\\fP rw\" \\fR=\\fPstr\nType of I/O pattern. Accepted values are:\n.RS\n.RS\n.TP\n.B read\nSequential reads.\n.TP\n.B write\nSequential writes.\n.TP\n.B trim\nSequential trims (Linux block devices and SCSI character devices only).\n.TP\n.B randread\nRandom reads.\n.TP\n.B randwrite\nRandom writes.\n.TP\n.B randtrim\nRandom trims (Linux block devices and SCSI character devices only).\n.TP\n.B rw,readwrite\nSequential mixed reads and writes.\n.TP\n.B randrw\nRandom mixed reads and writes.\n.TP\n.B trimwrite\nSequential trim+write sequences. Blocks will be trimmed first,\nthen the same blocks will be written to. So if `io_size=64K' is specified,\nFio will trim a total of 64K bytes and also write 64K bytes on the same\ntrimmed blocks. This behaviour will be consistent with `number_ios' or\nother Fio options limiting the total bytes or number of I/O's.\n.TP\n.B randtrimwrite\nLike\n.B trimwrite ,\nbut uses random offsets rather than sequential writes.\n.RE\n.P\nFio defaults to read if the option is not specified. For the mixed I/O\ntypes, the default is to split them 50/50. For certain types of I/O the\nresult may still be skewed a bit, since the speed may be different.\n.P\nIt is possible to specify the number of I/Os to do before getting a new\noffset by appending `:<nr>' to the end of the string given. For a\nrandom read, it would look like `rw=randread:8' for passing in an offset\nmodifier with a value of 8. If the suffix is used with a sequential I/O\npattern, then the `<nr>' value specified will be added to the generated\noffset for each I/O turning sequential I/O into sequential I/O with holes.\nFor instance, using `rw=write:4k' will skip 4k for every write. Also see\nthe \\fBrw_sequencer\\fR option.\n.RE\n.TP\n.BI rw_sequencer \\fR=\\fPstr\nIf an offset modifier is given by appending a number to the `rw=\\fIstr\\fR'\nline, then this option controls how that number modifies the I/O offset\nbeing generated. Accepted values are:\n.RS\n.RS\n.TP\n.B sequential\nGenerate sequential offset.\n.TP\n.B identical\nGenerate the same offset.\n.RE\n.P\n\\fBsequential\\fR is only useful for random I/O, where fio would normally\ngenerate a new random offset for every I/O. If you append e.g. 8 to randread,\ni.e. `rw=randread:8' you would get a new random offset for every 8 I/Os. The\nresult would be a sequence of 8 sequential offsets with a random starting\npoint.  However this behavior may change if a sequential I/O reaches end of the\nfile. As sequential I/O is already sequential, setting \\fBsequential\\fR for\nthat would not result in any difference. \\fBidentical\\fR behaves in a similar\nfashion, except it sends the same offset 8 number of times before generating a\nnew offset.\n.P\n.P\nExample #1:\n.RS\n.P\n.PD 0\nrw=randread:8\n.P\nrw_sequencer=sequential\n.P\nbs=4k\n.PD\n.RE\n.P\nThe generated sequence of offsets will look like this:\n4k, 8k, 12k, 16k, 20k, 24k, 28k, 32k, 92k, 96k, 100k, 104k, 108k, 112k, 116k,\n120k, 48k, 52k ...\n.P\n.P\nExample #2:\n.RS\n.P\n.PD 0\nrw=randread:8\n.P\nrw_sequencer=identical\n.P\nbs=4k\n.PD\n.RE\n.P\nThe generated sequence of offsets will look like this:\n4k, 4k, 4k, 4k, 4k, 4k, 4k, 4k, 92k, 92k, 92k, 92k, 92k, 92k, 92k, 92k, 48k,\n48k, 48k ...\n.RE\n.TP\n.BI unified_rw_reporting \\fR=\\fPstr\nFio normally reports statistics on a per data direction basis, meaning that\nreads, writes, and trims are accounted and reported separately. This option\ndetermines whether fio reports the results normally, summed together, or as\nboth options.\nAccepted values are:\n.RS\n.TP\n.B none\nNormal statistics reporting.\n.TP\n.B mixed\nStatistics are summed per data direction and reported together.\n.TP\n.B both\nStatistics are reported normally, followed by the mixed statistics.\n.TP\n.B 0\nBackward-compatible alias for \\fBnone\\fR.\n.TP\n.B 1\nBackward-compatible alias for \\fBmixed\\fR.\n.TP\n.B 2\nAlias for \\fBboth\\fR.\n.RE\n.TP\n.BI randrepeat \\fR=\\fPbool\nSeed all random number generators in a predictable way so the pattern is\nrepeatable across runs. Default: true.\n.TP\n.BI allrandrepeat \\fR=\\fPbool\nAlias for \\fBrandrepeat\\fR. Default: true.\n.TP\n.BI randseed \\fR=\\fPint\nSeed the random number generators based on this seed value, to be able to\ncontrol what sequence of output is being generated. If not set, the random\nsequence depends on the \\fBrandrepeat\\fR setting.\n.TP\n.BI fallocate \\fR=\\fPstr\nWhether pre-allocation is performed when laying down files.\nAccepted values are:\n.RS\n.RS\n.TP\n.B none\nDo not pre-allocate space.\n.TP\n.B native\nUse a platform's native pre-allocation call but fall back to\n\\fBnone\\fR behavior if it fails/is not implemented.\n.TP\n.B posix\nPre-allocate via \\fBposix_fallocate\\fR\\|(3).\n.TP\n.B keep\nPre-allocate via \\fBfallocate\\fR\\|(2) with\nFALLOC_FL_KEEP_SIZE set.\n.TP\n.B truncate\nExtend file to final size using \\fBftruncate\\fR|(2)\ninstead of allocating.\n.TP\n.B 0\nBackward-compatible alias for \\fBnone\\fR.\n.TP\n.B 1\nBackward-compatible alias for \\fBposix\\fR.\n.RE\n.P\nMay not be available on all supported platforms. \\fBkeep\\fR is only available\non Linux. If using ZFS on Solaris this cannot be set to \\fBposix\\fR\nbecause ZFS doesn't support pre-allocation. Default: \\fBnative\\fR if any\npre-allocation methods except \\fBtruncate\\fR are available, \\fBnone\\fR if not.\n.P\nNote that using \\fBtruncate\\fR on Windows will interact surprisingly\nwith non-sequential write patterns. When writing to a file that has\nbeen extended by setting the end-of-file information, Windows will\nbackfill the unwritten portion of the file up to that offset with\nzeroes before issuing the new write. This means that a single small\nwrite to the end of an extended file will stall until the entire\nfile has been filled with zeroes.\n.RE\n.TP\n.BI fadvise_hint \\fR=\\fPstr\nUse \\fBposix_fadvise\\fR\\|(2) or \\fBposix_madvise\\fR\\|(2) to advise the kernel\nwhat I/O patterns are likely to be issued. Accepted values are:\n.RS\n.RS\n.TP\n.B 0\nBackwards compatible hint for \"no hint\".\n.TP\n.B 1\nBackwards compatible hint for \"advise with fio workload type\". This\nuses FADV_RANDOM for a random workload, and FADV_SEQUENTIAL\nfor a sequential workload.\n.TP\n.B sequential\nAdvise using FADV_SEQUENTIAL.\n.TP\n.B random\nAdvise using FADV_RANDOM.\n.TP\n.B noreuse\nAdvise using FADV_NOREUSE. This may be a no-op on older Linux\nkernels. Since Linux 6.3, it provides a hint to the LRU algorithm.\nSee the \\fBposix_fadvise\\fR\\|(2) man page.\n.RE\n.RE\n.TP\n.BI write_hint \\fR=\\fPstr\nUse \\fBfcntl\\fR\\|(2) to advise the kernel what life time to expect\nfrom a write. Only supported on Linux, as of version 4.13. Accepted\nvalues are:\n.RS\n.RS\n.TP\n.B none\nNo particular life time associated with this file.\n.TP\n.B short\nData written to this file has a short life time.\n.TP\n.B medium\nData written to this file has a medium life time.\n.TP\n.B long\nData written to this file has a long life time.\n.TP\n.B extreme\nData written to this file has a very long life time.\n.RE\n.P\nThe values are all relative to each other, and no absolute meaning\nshould be associated with them.\n.RE\n.TP\n.BI offset \\fR=\\fPint[%|z]\nStart I/O at the provided offset in the file, given as either a fixed size in\nbytes, zones or a percentage. If a percentage is given, the generated offset will be\naligned to the minimum \\fBblocksize\\fR or to the value of \\fBoffset_align\\fR if\nprovided. Data before the given offset will not be touched. This\neffectively caps the file size at `real_size \\- offset'. Can be combined with\n\\fBsize\\fR to constrain the start and end range of the I/O workload.\nA percentage can be specified by a number between 1 and 100 followed by '%',\nfor example, `offset=20%' to specify 20%. In ZBD mode, value can be set as\nnumber of zones using 'z'.\n.TP\n.BI offset_align \\fR=\\fPint\nIf set to non-zero value, the byte offset generated by a percentage \\fBoffset\\fR\nis aligned upwards to this value. Defaults to 0 meaning that a percentage\noffset is aligned to the minimum block size.\n.TP\n.BI offset_increment \\fR=\\fPint[%|z]\nIf this is provided, then the real offset becomes `\\fBoffset\\fR + \\fBoffset_increment\\fR\n* thread_number', where the thread number is a counter that starts at 0 and\nis incremented for each sub-job (i.e. when \\fBnumjobs\\fR option is\nspecified). This option is useful if there are several jobs which are\nintended to operate on a file in parallel disjoint segments, with even\nspacing between the starting points. Percentages can be used for this option.\nIf a percentage is given, the generated offset will be aligned to the minimum\n\\fBblocksize\\fR or to the value of \\fBoffset_align\\fR if provided.In ZBD mode, value\ncan be set as number of zones using 'z'.\n.TP\n.BI number_ios \\fR=\\fPint\nFio will normally perform I/Os until it has exhausted the size of the region\nset by \\fBsize\\fR, or if it exhaust the allocated time (or hits an error\ncondition). With this setting, the range/size can be set independently of\nthe number of I/Os to perform. When fio reaches this number, it will exit\nnormally and report status. Note that this does not extend the amount of I/O\nthat will be done, it will only stop fio if this condition is met before\nother end-of-job criteria.\n.TP\n.BI fsync \\fR=\\fPint\nIf writing to a file, issue an \\fBfsync\\fR\\|(2) (or its equivalent) of\nthe dirty data for every number of blocks given. For example, if you give 32\nas a parameter, fio will sync the file after every 32 writes issued. If fio is\nusing non-buffered I/O, we may not sync the file. The exception is the sg\nI/O engine, which synchronizes the disk cache anyway. Defaults to 0, which\nmeans fio does not periodically issue and wait for a sync to complete. Also\nsee \\fBend_fsync\\fR and \\fBfsync_on_close\\fR.\n.TP\n.BI fdatasync \\fR=\\fPint\nLike \\fBfsync\\fR but uses \\fBfdatasync\\fR\\|(2) to only sync data and\nnot metadata blocks. In Windows, DragonFlyBSD or OSX there is no\n\\fBfdatasync\\fR\\|(2) so this falls back to using \\fBfsync\\fR\\|(2).\nDefaults to 0, which means fio does not periodically issue and wait for a\ndata-only sync to complete.\n.TP\n.BI write_barrier \\fR=\\fPint\nMake every N\\-th write a barrier write.\n.TP\n.BI sync_file_range \\fR=\\fPstr:int\nUse \\fBsync_file_range\\fR\\|(2) for every \\fIint\\fR number of write\noperations. Fio will track range of writes that have happened since the last\n\\fBsync_file_range\\fR\\|(2) call. \\fIstr\\fR can currently be one or more of:\n.RS\n.RS\n.TP\n.B wait_before\nSYNC_FILE_RANGE_WAIT_BEFORE\n.TP\n.B write\nSYNC_FILE_RANGE_WRITE\n.TP\n.B wait_after\nSYNC_FILE_RANGE_WRITE_AFTER\n.RE\n.P\nSo if you do `sync_file_range=wait_before,write:8', fio would use\n`SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE' for every 8\nwrites. Also see the \\fBsync_file_range\\fR\\|(2) man page. This option is\nLinux specific.\n.RE\n.TP\n.BI overwrite \\fR=\\fPbool\nIf true, writes to a file will always overwrite existing data. If the file\ndoesn't already exist, it will be created before the write phase begins. If\nthe file exists and is large enough for the specified write phase, nothing\nwill be done. Default: false.\n.TP\n.BI end_fsync \\fR=\\fPbool\nIf true, \\fBfsync\\fR\\|(2) file contents when a write stage has completed.\nDefault: false.\n.TP\n.BI fsync_on_close \\fR=\\fPbool\nIf true, fio will \\fBfsync\\fR\\|(2) a dirty file on close. This differs\nfrom \\fBend_fsync\\fR in that it will happen on every file close, not\njust at the end of the job. Default: false.\n.TP\n.BI rwmixread \\fR=\\fPint\nPercentage of a mixed workload that should be reads. Default: 50.\n.TP\n.BI rwmixwrite \\fR=\\fPint\nPercentage of a mixed workload that should be writes. If both\n\\fBrwmixread\\fR and \\fBrwmixwrite\\fR is given and the values do not\nadd up to 100%, the latter of the two will be used to override the\nfirst. This may interfere with a given rate setting, if fio is asked to\nlimit reads or writes to a certain rate. If that is the case, then the\ndistribution may be skewed. Default: 50.\n.TP\n.BI random_distribution \\fR=\\fPstr:float[:float][,str:float][,str:float]\nBy default, fio will use a completely uniform random distribution when asked\nto perform random I/O. Sometimes it is useful to skew the distribution in\nspecific ways, ensuring that some parts of the data is more hot than others.\nfio includes the following distribution models:\n.RS\n.RS\n.TP\n.B random\nUniform random distribution\n.TP\n.B zipf\nZipf distribution\n.TP\n.B pareto\nPareto distribution\n.TP\n.B normal\nNormal (Gaussian) distribution\n.TP\n.B zoned\nZoned random distribution\n.B zoned_abs\nZoned absolute random distribution\n.RE\n.P\nWhen using a \\fBzipf\\fR or \\fBpareto\\fR distribution, an input value is also\nneeded to define the access pattern. For \\fBzipf\\fR, this is the `Zipf theta'.\nFor \\fBpareto\\fR, it's the `Pareto power'. Fio includes a test\nprogram, \\fBfio\\-genzipf\\fR, that can be used visualize what the given input\nvalues will yield in terms of hit rates. If you wanted to use \\fBzipf\\fR with\na `theta' of 1.2, you would use `random_distribution=zipf:1.2' as the\noption. If a non\\-uniform model is used, fio will disable use of the random\nmap. For the \\fBnormal\\fR distribution, a normal (Gaussian) deviation is\nsupplied as a value between 0 and 100.\n.P\nThe second, optional float is allowed for \\fBpareto\\fR, \\fBzipf\\fR and \\fBnormal\\fR\ndistributions. It allows one to set base of distribution in non-default place, giving\nmore control over most probable outcome. This value is in range [0-1] which maps linearly to\nrange of possible random values.\nDefaults are: random for \\fBpareto\\fR and \\fBzipf\\fR, and 0.5 for \\fBnormal\\fR.\nIf you wanted to use \\fBzipf\\fR with a `theta` of 1.2 centered on 1/4 of allowed value range,\nyou would use `random_distribution=zipf:1.2:0.25`.\n.P\nFor a \\fBzoned\\fR distribution, fio supports specifying percentages of I/O\naccess that should fall within what range of the file or device. For\nexample, given a criteria of:\n.RS\n.P\n.PD 0\n60% of accesses should be to the first 10%\n.P\n30% of accesses should be to the next 20%\n.P\n8% of accesses should be to the next 30%\n.P\n2% of accesses should be to the next 40%\n.PD\n.RE\n.P\nwe can define that through zoning of the random accesses. For the above\nexample, the user would do:\n.RS\n.P\nrandom_distribution=zoned:60/10:30/20:8/30:2/40\n.RE\n.P\nA \\fBzoned_abs\\fR distribution works exactly like the\\fBzoned\\fR, except that\nit takes absolute sizes. For example, let's say you wanted to define access\naccording to the following criteria:\n.RS\n.P\n.PD 0\n60% of accesses should be to the first 20G\n.P\n30% of accesses should be to the next 100G\n.P\n10% of accesses should be to the next 500G\n.PD\n.RE\n.P\nwe can define an absolute zoning distribution with:\n.RS\n.P\nrandom_distribution=zoned:60/10:30/20:8/30:2/40\n.RE\n.P\nFor both \\fBzoned\\fR and \\fBzoned_abs\\fR, fio supports defining up to 256\nseparate zones.\n.P\nSimilarly to how \\fBbssplit\\fR works for setting ranges and percentages\nof block sizes. Like \\fBbssplit\\fR, it's possible to specify separate\nzones for reads, writes, and trims. If just one set is given, it'll apply to\nall of them.\n.RE\n.TP\n.BI percentage_random \\fR=\\fPint[,int][,int]\nFor a random workload, set how big a percentage should be random. This\ndefaults to 100%, in which case the workload is fully random. It can be set\nfrom anywhere from 0 to 100. Setting it to 0 would make the workload fully\nsequential. Any setting in between will result in a random mix of sequential\nand random I/O, at the given percentages. Comma-separated values may be\nspecified for reads, writes, and trims as described in \\fBblocksize\\fR.\n.TP\n.BI norandommap\nNormally fio will cover every block of the file when doing random I/O. If\nthis option is given, fio will just get a new random offset without looking\nat past I/O history. This means that some blocks may not be read or written,\nand that some blocks may be read/written more than once. If this option is\nused with \\fBverify\\fR and multiple blocksizes (via \\fBbsrange\\fR),\nonly intact blocks are verified, i.e., partially-overwritten blocks are\nignored.  With an async I/O engine and an I/O depth > 1, it is possible for\nthe same block to be overwritten, which can cause verification errors.  Either\ndo not use norandommap in this case, or also use the lfsr random generator.\n.TP\n.BI softrandommap \\fR=\\fPbool\nSee \\fBnorandommap\\fR. If fio runs with the random block map enabled and\nit fails to allocate the map, if this option is set it will continue without\na random block map. As coverage will not be as complete as with random maps,\nthis option is disabled by default.\n.TP\n.BI random_generator \\fR=\\fPstr\nFio supports the following engines for generating I/O offsets for random I/O:\n.RS\n.RS\n.TP\n.B tausworthe\nStrong 2^88 cycle random number generator.\n.TP\n.B lfsr\nLinear feedback shift register generator.\n.TP\n.B tausworthe64\nStrong 64\\-bit 2^258 cycle random number generator.\n.RE\n.P\n\\fBtausworthe\\fR is a strong random number generator, but it requires tracking\non the side if we want to ensure that blocks are only read or written\nonce. \\fBlfsr\\fR guarantees that we never generate the same offset twice, and\nit's also less computationally expensive. It's not a true random generator,\nhowever, though for I/O purposes it's typically good enough. \\fBlfsr\\fR only\nworks with single block sizes, not with workloads that use multiple block\nsizes. If used with such a workload, fio may read or write some blocks\nmultiple times. The default value is \\fBtausworthe\\fR, unless the required\nspace exceeds 2^32 blocks. If it does, then \\fBtausworthe64\\fR is\nselected automatically.\n.RE\n.SS \"Block size\"\n.TP\n.BI blocksize \\fR=\\fPint[,int][,int] \"\\fR,\\fB bs\" \\fR=\\fPint[,int][,int]\nThe block size in bytes used for I/O units. Default: 4096. A single value\napplies to reads, writes, and trims. Comma-separated values may be\nspecified for reads, writes, and trims. A value not terminated in a comma\napplies to subsequent types. Examples:\n.RS\n.RS\n.P\n.PD 0\nbs=256k        means 256k for reads, writes and trims.\n.P\nbs=8k,32k      means 8k for reads, 32k for writes and trims.\n.P\nbs=8k,32k,     means 8k for reads, 32k for writes, and default for trims.\n.P\nbs=,8k         means default for reads, 8k for writes and trims.\n.P\nbs=,8k,        means default for reads, 8k for writes, and default for trims.\n.PD\n.RE\n.RE\n.TP\n.BI blocksize_range \\fR=\\fPirange[,irange][,irange] \"\\fR,\\fB bsrange\" \\fR=\\fPirange[,irange][,irange]\nA range of block sizes in bytes for I/O units. The issued I/O unit will\nalways be a multiple of the minimum size, unless\n\\fBblocksize_unaligned\\fR is set.\nComma-separated ranges may be specified for reads, writes, and trims as\ndescribed in \\fBblocksize\\fR. Example:\n.RS\n.RS\n.P\nbsrange=1k\\-4k,2k\\-8k or bsrange=1k:4k,2k:8k\n.RE\n.RE\n.TP\n.BI bssplit \\fR=\\fPstr[,str][,str]\nSometimes you want even finer grained control of the block sizes issued, not\njust an even split between them. This option allows you to weight various\nblock sizes, so that you are able to define a specific amount of block sizes\nissued. The format for this option is:\n.RS\n.RS\n.P\nbssplit=blocksize/percentage:blocksize/percentage\n.RE\n.P\nfor as many block sizes as needed. So if you want to define a workload that\nhas 50% 64k blocks, 10% 4k blocks, and 40% 32k blocks, you would write:\n.RS\n.P\nbssplit=4k/10:64k/50:32k/40\n.RE\n.P\nOrdering does not matter. If the percentage is left blank, fio will fill in\nthe remaining values evenly. So a bssplit option like this one:\n.RS\n.P\nbssplit=4k/50:1k/:32k/\n.RE\n.P\nwould have 50% 4k ios, and 25% 1k and 32k ios. The percentages always add up\nto 100, if bssplit is given a range that adds up to more, it will error out.\n.P\nComma-separated values may be specified for reads, writes, and trims as\ndescribed in \\fBblocksize\\fR.\n.P\nIf you want a workload that has 50% 2k reads and 50% 4k reads, while having\n90% 4k writes and 10% 8k writes, you would specify:\n.RS\n.P\nbssplit=2k/50:4k/50,4k/90:8k/10\n.RE\n.P\nFio supports defining up to 64 different weights for each data direction.\n.RE\n.TP\n.BI blocksize_unaligned \"\\fR,\\fB bs_unaligned\"\nIf set, fio will issue I/O units with any size within\n\\fBblocksize_range\\fR, not just multiples of the minimum size. This\ntypically won't work with direct I/O, as that normally requires sector\nalignment.\n.TP\n.BI bs_is_seq_rand \\fR=\\fPbool\nIf this option is set, fio will use the normal read,write blocksize settings\nas sequential,random blocksize settings instead. Any random read or write\nwill use the WRITE blocksize settings, and any sequential read or write will\nuse the READ blocksize settings.\n.TP\n.BI blockalign \\fR=\\fPint[,int][,int] \"\\fR,\\fB ba\" \\fR=\\fPint[,int][,int]\nBoundary to which fio will align random I/O units. Default:\n\\fBblocksize\\fR. Minimum alignment is typically 512b for using direct\nI/O, though it usually depends on the hardware block size. This option is\nmutually exclusive with using a random map for files, so it will turn off\nthat option. Comma-separated values may be specified for reads, writes, and\ntrims as described in \\fBblocksize\\fR.\n.SS \"Buffers and memory\"\n.TP\n.BI zero_buffers\nInitialize buffers with all zeros. Default: fill buffers with random data.\n.TP\n.BI refill_buffers\nIf this option is given, fio will refill the I/O buffers on every\nsubmit. The default is to only fill it at init time and reuse that\ndata. Only makes sense if zero_buffers isn't specified, naturally. If data\nverification is enabled, \\fBrefill_buffers\\fR is also automatically enabled.\n.TP\n.BI scramble_buffers \\fR=\\fPbool\nIf \\fBrefill_buffers\\fR is too costly and the target is using data\ndeduplication, then setting this option will slightly modify the I/O buffer\ncontents to defeat normal de-dupe attempts. This is not enough to defeat\nmore clever block compression attempts, but it will stop naive dedupe of\nblocks. Default: true.\n.TP\n.BI buffer_compress_percentage \\fR=\\fPint\nIf this is set, then fio will attempt to provide I/O buffer content\n(on WRITEs) that compresses to the specified level. Fio does this by\nproviding a mix of random data followed by fixed pattern data. The\nfixed pattern is either zeros, or the pattern specified by\n\\fBbuffer_pattern\\fR. If the \\fBbuffer_pattern\\fR option is used, it\nmight skew the compression ratio slightly. Setting\n\\fBbuffer_compress_percentage\\fR to a value other than 100 will also\nenable \\fBrefill_buffers\\fR in order to reduce the likelihood that\nadjacent blocks are so similar that they over compress when seen\ntogether. See \\fBbuffer_compress_chunk\\fR for how to set a finer or\ncoarser granularity of the random/fixed data regions. Defaults to unset\ni.e., buffer data will not adhere to any compression level.\n.TP\n.BI buffer_compress_chunk \\fR=\\fPint\nThis setting allows fio to manage how big the random/fixed data region\nis when using \\fBbuffer_compress_percentage\\fR. When\n\\fBbuffer_compress_chunk\\fR is set to some non-zero value smaller than the\nblock size, fio can repeat the random/fixed region throughout the I/O\nbuffer at the specified interval (which particularly useful when\nbigger block sizes are used for a job). When set to 0, fio will use a\nchunk size that matches the block size resulting in a single\nrandom/fixed region within the I/O buffer. Defaults to 512. When the\nunit is omitted, the value is interpreted in bytes.\n.TP\n.BI buffer_pattern \\fR=\\fPstr\nIf set, fio will fill the I/O buffers with this pattern or with the contents\nof a file. If not set, the contents of I/O buffers are defined by the other\noptions related to buffer contents. The setting can be any pattern of bytes,\nand can be prefixed with 0x for hex values. It may also be a string, where\nthe string must then be wrapped with \"\". Or it may also be a filename,\nwhere the filename must be wrapped with '' in which case the file is\nopened and read. Note that not all the file contents will be read if that\nwould cause the buffers to overflow. So, for example:\n.RS\n.RS\n.P\n.PD 0\nbuffer_pattern='filename'\n.P\nor:\n.P\nbuffer_pattern=\"abcd\"\n.P\nor:\n.P\nbuffer_pattern=\\-12\n.P\nor:\n.P\nbuffer_pattern=0xdeadface\n.PD\n.RE\n.P\nAlso you can combine everything together in any order:\n.RS\n.P\nbuffer_pattern=0xdeadface\"abcd\"\\-12'filename'\n.RE\n.RE\n.TP\n.BI dedupe_percentage \\fR=\\fPint\nIf set, fio will generate this percentage of identical buffers when\nwriting. These buffers will be naturally dedupable. The contents of the\nbuffers depend on what other buffer compression settings have been set. It's\npossible to have the individual buffers either fully compressible, or not at\nall \\-\\- this option only controls the distribution of unique buffers. Setting\nthis option will also enable \\fBrefill_buffers\\fR to prevent every buffer\nbeing identical.\n.TP\n.BI dedupe_mode \\fR=\\fPstr\nIf \\fBdedupe_percentage\\fR is given, then this option controls how fio\ngenerates the dedupe buffers.\n.RS\n.RS\n.TP\n.B repeat\n.P\n.RS\nGenerate dedupe buffers by repeating previous writes\n.RE\n.TP\n.B working_set\n.P\n.RS\nGenerate dedupe buffers from working set\n.RE\n.RE\n.P\n\\fBrepeat\\fR is the default option for fio. Dedupe buffers are generated\nby repeating previous unique write.\n\n\\fBworking_set\\fR is a more realistic workload.\nWith \\fBworking_set\\fR, \\fBdedupe_working_set_percentage\\fR should be provided.\nGiven that, fio will use the initial unique write buffers as its working set.\nUpon deciding to dedupe, fio will randomly choose a buffer from the working set.\nNote that by using \\fBworking_set\\fR the dedupe percentage will converge\nto the desired over time while \\fBrepeat\\fR maintains the desired percentage\nthroughout the job.\n.RE\n.RE\n.TP\n.BI dedupe_working_set_percentage \\fR=\\fPint\nIf \\fBdedupe_mode\\fR is set to \\fBworking_set\\fR, then this controls\nthe percentage of size of the file or device used as the buffers\nfio will choose to generate the dedupe buffers from\n.P\n.RS\nNote that \\fBsize\\fR needs to be explicitly provided and only 1 file\nper job is supported\n.RE\n.TP\n.BI dedupe_global \\fR=\\fPbool\nThis controls whether the deduplication buffers will be shared amongst\nall jobs that have this option set. The buffers are spread evenly between\nparticipating jobs.\n.P\n.RS\nNote that \\fBdedupe_mode\\fR must be set to \\fBworking_set\\fR for this to work.\nCan be used in combination with compression\n.TP\n.BI invalidate \\fR=\\fPbool\nInvalidate the buffer/page cache parts of the files to be used prior to\nstarting I/O if the platform and file type support it. Defaults to true.\nThis will be ignored if \\fBpre_read\\fR is also specified for the\nsame job.\n.TP\n.BI sync \\fR=\\fPstr\nWhether, and what type, of synchronous I/O to use for writes.  The allowed\nvalues are:\n.RS\n.RS\n.TP\n.B none\nDo not use synchronous IO, the default.\n.TP\n.B 0\nSame as \\fBnone\\fR.\n.TP\n.B sync\nUse synchronous file IO. For the majority of I/O engines,\nthis means using O_SYNC.\n.TP\n.B 1\nSame as \\fBsync\\fR.\n.TP\n.B dsync\nUse synchronous data IO. For the majority of I/O engines,\nthis means using O_DSYNC.\n.PD\n.RE\n.RE\n.TP\n.BI iomem \\fR=\\fPstr \"\\fR,\\fP mem\" \\fR=\\fPstr\nFio can use various types of memory as the I/O unit buffer. The allowed\nvalues are:\n.RS\n.RS\n.TP\n.B malloc\nUse memory from \\fBmalloc\\fR\\|(3) as the buffers. Default memory type.\n.TP\n.B shm\nUse shared memory as the buffers. Allocated through \\fBshmget\\fR\\|(2).\n.TP\n.B shmhuge\nSame as \\fBshm\\fR, but use huge pages as backing.\n.TP\n.B mmap\nUse \\fBmmap\\fR\\|(2) to allocate buffers. May either be anonymous memory, or can\nbe file backed if a filename is given after the option. The format\nis `mem=mmap:/path/to/file'.\n.TP\n.B mmaphuge\nUse a memory mapped huge file as the buffer backing. Append filename\nafter mmaphuge, ala `mem=mmaphuge:/hugetlbfs/file'.\n.TP\n.B mmapshared\nSame as \\fBmmap\\fR, but use a MMAP_SHARED mapping.\n.TP\n.B cudamalloc\nUse GPU memory as the buffers for GPUDirect RDMA benchmark.\nThe \\fBioengine\\fR must be \\fBrdma\\fR.\n.RE\n.P\nThe area allocated is a function of the maximum allowed bs size for the job,\nmultiplied by the I/O depth given. Note that for \\fBshmhuge\\fR and\n\\fBmmaphuge\\fR to work, the system must have free huge pages allocated. This\ncan normally be checked and set by reading/writing\n`/proc/sys/vm/nr_hugepages' on a Linux system. Fio assumes a huge page\nis 2 or 4MiB in size depending on the platform. So to calculate the number of\nhuge pages you need for a given job file, add up the I/O depth of all jobs\n(normally one unless \\fBiodepth\\fR is used) and multiply by the maximum bs set.\nThen divide that number by the huge page size. You can see the size of the huge\npages in `/proc/meminfo'. If no huge pages are allocated by having a non-zero\nnumber in `nr_hugepages', using \\fBmmaphuge\\fR or \\fBshmhuge\\fR will fail. Also\nsee \\fBhugepage\\-size\\fR.\n.P\n\\fBmmaphuge\\fR also needs to have hugetlbfs mounted and the file location\nshould point there. So if it's mounted in `/huge', you would use\n`mem=mmaphuge:/huge/somefile'.\n.RE\n.TP\n.BI iomem_align \\fR=\\fPint \"\\fR,\\fP mem_align\" \\fR=\\fPint\nThis indicates the memory alignment of the I/O memory buffers. Note that\nthe given alignment is applied to the first I/O unit buffer, if using\n\\fBiodepth\\fR the alignment of the following buffers are given by the\n\\fBbs\\fR used. In other words, if using a \\fBbs\\fR that is a\nmultiple of the page sized in the system, all buffers will be aligned to\nthis value. If using a \\fBbs\\fR that is not page aligned, the alignment\nof subsequent I/O memory buffers is the sum of the \\fBiomem_align\\fR and\n\\fBbs\\fR used.\n.TP\n.BI hugepage\\-size \\fR=\\fPint\nDefines the size of a huge page. Must at least be equal to the system setting,\nsee `/proc/meminfo' and `/sys/kernel/mm/hugepages/'. Defaults to 2 or 4MiB\ndepending on the platform. Should probably always be a multiple of megabytes,\nso using `hugepage\\-size=Xm' is the preferred way to set this to avoid setting\na non-pow-2 bad value.\n.TP\n.BI lockmem \\fR=\\fPint\nPin the specified amount of memory with \\fBmlock\\fR\\|(2). Can be used to\nsimulate a smaller amount of memory. The amount specified is per worker.\n.SS \"I/O size\"\n.TP\n.BI size \\fR=\\fPint[%|z]\nThe total size of file I/O for each thread of this job. Fio will run until\nthis many bytes has been transferred, unless runtime is altered by other means\nsuch as (1) \\fBruntime\\fR, (2) \\fBio_size\\fR, (3) \\fBnumber_ios\\fR, (4)\ngaps/holes while doing I/O's such as `rw=read:16K', or (5) sequential I/O\nreaching end of the file which is possible when \\fBpercentage_random\\fR is\nless than 100.\nFio will divide this size between the available files determined by options\nsuch as \\fBnrfiles\\fR, \\fBfilename\\fR, unless \\fBfilesize\\fR is\nspecified by the job. If the result of division happens to be 0, the size is\nset to the physical size of the given files or devices if they exist.\nIf this option is not specified, fio will use the full size of the given\nfiles or devices. If the files do not exist, size must be given. It is also\npossible to give size as a percentage between 1 and 100. If `size=20%' is\ngiven, fio will use 20% of the full size of the given files or devices. In ZBD mode,\nsize can be given in units of number of zones using 'z'. Can be combined with \\fBoffset\\fR to\nconstrain the start and end range that I/O will be done within.\n.TP\n.BI io_size \\fR=\\fPint[%|z] \"\\fR,\\fB io_limit\" \\fR=\\fPint[%|z]\nNormally fio operates within the region set by \\fBsize\\fR, which means\nthat the \\fBsize\\fR option sets both the region and size of I/O to be\nperformed. Sometimes that is not what you want. With this option, it is\npossible to define just the amount of I/O that fio should do. For instance,\nif \\fBsize\\fR is set to 20GiB and \\fBio_size\\fR is set to 5GiB, fio\nwill perform I/O within the first 20GiB but exit when 5GiB have been\ndone. The opposite is also possible \\-\\- if \\fBsize\\fR is set to 20GiB,\nand \\fBio_size\\fR is set to 40GiB, then fio will do 40GiB of I/O within\nthe 0..20GiB region. Value can be set as percentage: \\fBio_size\\fR=N%.\nIn this case \\fBio_size\\fR multiplies \\fBsize\\fR= value. In ZBD mode, value can\nalso be set as number of zones using 'z'.\n.TP\n.BI filesize \\fR=\\fPirange(int)\nIndividual file sizes. May be a range, in which case fio will select sizes\nfor files at random within the given range. If not given, each created file\nis the same size. This option overrides \\fBsize\\fR in terms of file size,\ni.e. \\fBsize\\fR becomes merely the default for \\fBio_size\\fR (and\nhas no effect it all if \\fBio_size\\fR is set explicitly).\n.TP\n.BI file_append \\fR=\\fPbool\nPerform I/O after the end of the file. Normally fio will operate within the\nsize of a file. If this option is set, then fio will append to the file\ninstead. This has identical behavior to setting \\fBoffset\\fR to the size\nof a file. This option is ignored on non-regular files.\n.TP\n.BI fill_device \\fR=\\fPbool \"\\fR,\\fB fill_fs\" \\fR=\\fPbool\nSets size to something really large and waits for ENOSPC (no space left on\ndevice) or EDQUOT (disk quota exceeded)\nas the terminating condition. Only makes sense with sequential\nwrite. For a read workload, the mount point will be filled first then I/O\nstarted on the result.\n.SS \"I/O engine\"\n.TP\n.BI ioengine \\fR=\\fPstr\nfio supports 2 kinds of performance measurement: I/O and file/directory operation.\n\nI/O engines define how the job issues I/O to the file. The following types are defined:\n.RS\n.TP\n.B sync\nBasic \\fBread\\fR\\|(2) or \\fBwrite\\fR\\|(2)\nI/O. \\fBlseek\\fR\\|(2) is used to position the I/O location.\nSee \\fBfsync\\fR and \\fBfdatasync\\fR for syncing write I/Os.\n.TP\n.B psync\nBasic \\fBpread\\fR\\|(2) or \\fBpwrite\\fR\\|(2) I/O. Default on\nall supported operating systems except for Windows.\n.TP\n.B vsync\nBasic \\fBreadv\\fR\\|(2) or \\fBwritev\\fR\\|(2) I/O. Will emulate\nqueuing by coalescing adjacent I/Os into a single submission.\n.TP\n.B pvsync\nBasic \\fBpreadv\\fR\\|(2) or \\fBpwritev\\fR\\|(2) I/O.\n.TP\n.B pvsync2\nBasic \\fBpreadv2\\fR\\|(2) or \\fBpwritev2\\fR\\|(2) I/O.\n.TP\n.B io_uring\nFast Linux native asynchronous I/O. Supports async IO\nfor both direct and buffered IO.\nThis engine defines engine specific options.\n.TP\n.B io_uring_cmd\nFast Linux native asynchronous I/O for passthrough commands.\nThis engine defines engine specific options.\n.TP\n.B libaio\nLinux native asynchronous I/O. Note that Linux may only support\nqueued behavior with non-buffered I/O (set `direct=1' or\n`buffered=0').\nThis engine defines engine specific options.\n.TP\n.B posixaio\nPOSIX asynchronous I/O using \\fBaio_read\\fR\\|(3) and\n\\fBaio_write\\fR\\|(3).\n.TP\n.B solarisaio\nSolaris native asynchronous I/O.\n.TP\n.B windowsaio\nWindows native asynchronous I/O. Default on Windows.\n.TP\n.B mmap\nFile is memory mapped with \\fBmmap\\fR\\|(2) and data copied\nto/from using \\fBmemcpy\\fR\\|(3).\n.TP\n.B splice\n\\fBsplice\\fR\\|(2) is used to transfer the data and\n\\fBvmsplice\\fR\\|(2) to transfer data from user space to the\nkernel.\n.TP\n.B sg\nSCSI generic sg v3 I/O. May either be synchronous using the SG_IO\nioctl, or if the target is an sg character device we use\n\\fBread\\fR\\|(2) and \\fBwrite\\fR\\|(2) for asynchronous\nI/O. Requires \\fBfilename\\fR option to specify either block or\ncharacter devices. This engine supports trim operations. The\nsg engine includes engine specific options.\n.TP\n.B libzbc\nRead, write, trim and ZBC/ZAC operations to a zoned block device using\n\\fBlibzbc\\fR library. The target can be either an SG character device or\na block device file.\n.TP\n.B null\nDoesn't transfer any data, just pretends to. This is mainly used to\nexercise fio itself and for debugging/testing purposes.\n.TP\n.B net\nTransfer over the network to given `host:port'. Depending on the\n\\fBprotocol\\fR used, the \\fBhostname\\fR, \\fBport\\fR,\n\\fBlisten\\fR and \\fBfilename\\fR options are used to specify\nwhat sort of connection to make, while the \\fBprotocol\\fR option\ndetermines which protocol will be used. This engine defines engine\nspecific options.\n.TP\n.B netsplice\nLike \\fBnet\\fR, but uses \\fBsplice\\fR\\|(2) and\n\\fBvmsplice\\fR\\|(2) to map data and send/receive.\nThis engine defines engine specific options.\n.TP\n.B cpuio\nDoesn't transfer any data, but burns CPU cycles according to the\n\\fBcpuload\\fR, \\fBcpuchunks\\fR and \\fBcpumode\\fR options.\nA job never finishes unless there is at least one non-cpuio job.\n.RS\n.P\n.PD 0\n\\fBcpuload\\fR\\=85 will cause that job to do nothing but burn 85% of the CPU.\nIn case of SMP machines, use \\fBnumjobs=<nr_of_cpu>\\fR\\ to get desired CPU usage,\nas the cpuload only loads a single CPU at the desired rate.\n\n.P\n\\fBcpumode\\fR\\=qsort replace the default noop instructions loop\nby a qsort algorithm to consume more energy.\n\n.P\n.RE\n.TP\n.B rdma\nThe RDMA I/O engine supports both RDMA memory semantics\n(RDMA_WRITE/RDMA_READ) and channel semantics (Send/Recv) for the\nInfiniBand, RoCE and iWARP protocols. This engine defines engine\nspecific options.\n.TP\n.B falloc\nI/O engine that does regular fallocate to simulate data transfer as\nfio ioengine.\n.RS\n.P\n.PD 0\nDDIR_READ      does fallocate(,mode = FALLOC_FL_KEEP_SIZE,).\n.P\nDIR_WRITE      does fallocate(,mode = 0).\n.P\nDDIR_TRIM      does fallocate(,mode = FALLOC_FL_KEEP_SIZE|FALLOC_FL_PUNCH_HOLE).\n.PD\n.RE\n.TP\n.B ftruncate\nI/O engine that sends \\fBftruncate\\fR\\|(2) operations in response\nto write (DDIR_WRITE) events. Each ftruncate issued sets the file's\nsize to the current block offset. \\fBblocksize\\fR is ignored.\n.TP\n.B e4defrag\nI/O engine that does regular EXT4_IOC_MOVE_EXT ioctls to simulate\ndefragment activity in request to DDIR_WRITE event.\n.TP\n.B rados\nI/O engine supporting direct access to Ceph Reliable Autonomic Distributed\nObject Store (RADOS) via librados. This ioengine defines engine specific\noptions.\n.TP\n.B rbd\nI/O engine supporting direct access to Ceph Rados Block Devices\n(RBD) via librbd without the need to use the kernel rbd driver. This\nioengine defines engine specific options.\n.TP\n.B http\nI/O engine supporting GET/PUT requests over HTTP(S) with libcurl to\na WebDAV or S3 endpoint.  This ioengine defines engine specific options.\n\nThis engine only supports direct IO of iodepth=1; you need to scale this\nvia numjobs. blocksize defines the size of the objects to be created.\n\nTRIM is translated to object deletion.\n.TP\n.B gfapi\nUsing GlusterFS libgfapi sync interface to direct access to\nGlusterFS volumes without having to go through FUSE. This ioengine\ndefines engine specific options.\n.TP\n.B gfapi_async\nUsing GlusterFS libgfapi async interface to direct access to\nGlusterFS volumes without having to go through FUSE. This ioengine\ndefines engine specific options.\n.TP\n.B libhdfs\nRead and write through Hadoop (HDFS). The \\fBfilename\\fR option\nis used to specify host,port of the hdfs name\\-node to connect. This\nengine interprets offsets a little differently. In HDFS, files once\ncreated cannot be modified so random writes are not possible. To\nimitate this the libhdfs engine expects a bunch of small files to be\ncreated over HDFS and will randomly pick a file from them\nbased on the offset generated by fio backend (see the example\njob file to create such files, use `rw=write' option). Please\nnote, it may be necessary to set environment variables to work\nwith HDFS/libhdfs properly. Each job uses its own connection to\nHDFS.\n.TP\n.B mtd\nRead, write and erase an MTD character device (e.g.,\n`/dev/mtd0'). Discards are treated as erases. Depending on the\nunderlying device type, the I/O may have to go in a certain pattern,\ne.g., on NAND, writing sequentially to erase blocks and discarding\nbefore overwriting. The \\fBtrimwrite\\fR mode works well for this\nconstraint.\n.TP\n.B dev\\-dax\nRead and write using device DAX to a persistent memory device (e.g.,\n/dev/dax0.0) through the PMDK libpmem library.\n.TP\n.B external\nPrefix to specify loading an external I/O engine object file. Append\nthe engine filename, e.g. `ioengine=external:/tmp/foo.o' to load\nioengine `foo.o' in `/tmp'. The path can be either\nabsolute or relative. See `engines/skeleton_external.c' in the fio source for\ndetails of writing an external I/O engine.\n.TP\n.B libpmem\nRead and write using mmap I/O to a file on a filesystem\nmounted with DAX on a persistent memory device through the PMDK\nlibpmem library.\n.TP\n.B ime_psync\nSynchronous read and write using DDN's Infinite Memory Engine (IME). This\nengine is very basic and issues calls to IME whenever an IO is queued.\n.TP\n.B ime_psyncv\nSynchronous read and write using DDN's Infinite Memory Engine (IME). This\nengine uses iovecs and will try to stack as much IOs as possible (if the IOs\nare \"contiguous\" and the IO depth is not exceeded) before issuing a call to IME.\n.TP\n.B ime_aio\nAsynchronous read and write using DDN's Infinite Memory Engine (IME). This\nengine will try to stack as much IOs as possible by creating requests for IME.\nFIO will then decide when to commit these requests.\n.TP\n.B libiscsi\nRead and write iscsi lun with libiscsi.\n.TP\n.B nbd\nSynchronous read and write a Network Block Device (NBD).\n.TP\n.B libcufile\nI/O engine supporting libcufile synchronous access to nvidia-fs and a\nGPUDirect Storage-supported filesystem. This engine performs\nI/O without transferring buffers between user-space and the kernel,\nunless \\fBverify\\fR is set or \\fBcuda_io\\fR is \\fBposix\\fR. \\fBiomem\\fR must\nnot be \\fBcudamalloc\\fR. This ioengine defines engine specific options.\n.TP\n.B dfs\nI/O engine supporting asynchronous read and write operations to the DAOS File\nSystem (DFS) via libdfs.\n.TP\n.B nfs\nI/O engine supporting asynchronous read and write operations to\nNFS filesystems from userspace via libnfs. This is useful for\nachieving higher concurrency and thus throughput than is possible\nvia kernel NFS.\n.TP\n.B exec\nExecute 3rd party tools. Could be used to perform monitoring during jobs runtime.\n.TP\n.B xnvme\nI/O engine using the xNVMe C API, for NVMe devices. The xnvme engine provides\nflexibility to access GNU/Linux Kernel NVMe driver via libaio, IOCTLs, io_uring,\nthe SPDK NVMe driver, or your own custom NVMe driver. The xnvme engine includes\nengine specific options. (See \\fIhttps://xnvme.io/\\fR).\n.TP\n.B libblkio\nUse the libblkio library (\\fIhttps://gitlab.com/libblkio/libblkio\\fR). The\nspecific driver to use must be set using \\fBlibblkio_driver\\fR. If\n\\fBmem\\fR/\\fBiomem\\fR is not specified, memory allocation is delegated to\nlibblkio (and so is guaranteed to work with the selected driver). One libblkio\ninstance is used per process, so all jobs setting option \\fBthread\\fR will share\na single instance (with one queue per thread) and must specify compatible\noptions. Note that some drivers don't allow several instances to access the same\ndevice or file simultaneously, but allow it for threads.\n.TP\n.RE\n.P\nFile/directory operation engines define how the job operates file or directory.\nThe following types are defined:\n.RS\n.TP\n.B filecreate\nSimply create the files and do no I/O to them.  You still need to\nset  \\fBfilesize\\fP so that all the accounting still occurs, but no\nactual I/O will be done other than creating the file.\nExample job file: filecreate-ioengine.fio.\n.TP\n.B filestat\nSimply do stat() and do no I/O to the file. You need to set \\fBfilesize\\fP\nand \\fBnrfiles\\fP, so that files will be created.\nThis engine is to measure file lookup and meta data access.\nExample job file: filestat-ioengine.fio.\n.TP\n.B filedelete\nSimply delete the files by unlink() and do no I/O to them. You need to set \\fBfilesize\\fP\nand \\fBnrfiles\\fP, so that the files will be created.\nThis engine is to measure file delete.\nExample job file: filedelete-ioengine.fio.\n.TP\n.B dircreate\nSimply create the directories and do no I/O to them.  You still need to\nset  \\fBfilesize\\fP so that all the accounting still occurs, but no\nactual I/O will be done other than creating the directories.\nExample job file: dircreate-ioengine.fio.\n.TP\n.B dirstat\nSimply do stat() and do no I/O to the directories. You need to set \\fBfilesize\\fP\nand \\fBnrfiles\\fP, so that directories will be created.\nThis engine is to measure directory lookup and meta data access.\nExample job file: dirstat-ioengine.fio.\n.TP\n.B dirdelete\nSimply delete the directories by rmdir() and do no I/O to them. You need to set \\fBfilesize\\fP\nand \\fBnrfiles\\fP, so that the directories will be created.\nThis engine is to measure directory delete.\n.TP\n.RE\n.P\nFor file and directory operation engines, there is no I/O throughput, then the statistics \\\ndata in report have different meanings. The meaningful output indexes are: \\fBiops\\fP and \\fBclat\\fP. \\\n\\fBbw\\fP is meaningless. Refer to section: \"Interpreting the output\" for more details.\n.RE\n.P\n.SS \"I/O engine specific parameters\"\nIn addition, there are some parameters which are only valid when a specific\n\\fBioengine\\fR is in use. These are used identically to normal parameters,\nwith the caveat that when used on the command line, they must come after the\n\\fBioengine\\fR that defines them is selected.\n.TP\n.BI (io_uring,libaio)cmdprio_percentage \\fR=\\fPint[,int]\nSet the percentage of I/O that will be issued with the highest priority.\nDefault: 0. A single value applies to reads and writes. Comma-separated\nvalues may be specified for reads and writes. For this option to be effective,\nNCQ priority must be supported and enabled, and `direct=1' option must be\nused. fio must also be run as the root user. Unlike slat/clat/lat stats, which\ncan be tracked and reported independently, per priority stats only track and\nreport a single type of latency. By default, completion latency (clat) will be\nreported, if \\fBlat_percentiles\\fR is set, total latency (lat) will be reported.\n.TP\n.BI (io_uring,libaio)cmdprio_class \\fR=\\fPint[,int]\nSet the I/O priority class to use for I/Os that must be issued with a\npriority when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR is set.\nIf not specified when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR\nis set, this defaults to the highest priority class. A single value applies\nto reads and writes. Comma-separated values may be specified for reads and\nwrites. See man \\fBionice\\fR\\|(1). See also the \\fBprioclass\\fR option.\n.TP\n.BI (io_uring,libaio)cmdprio_hint \\fR=\\fPint[,int]\nSet the I/O priority hint to use for I/Os that must be issued with a\npriority when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR is set.\nIf not specified when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR\nis set, this defaults to 0 (no hint). A single value applies to reads and\nwrites. Comma-separated values may be specified for reads and writes.\nSee also the \\fBpriohint\\fR option.\n.TP\n.BI (io_uring,libaio)cmdprio \\fR=\\fPint[,int]\nSet the I/O priority value to use for I/Os that must be issued with a\npriority when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR is set.\nIf not specified when \\fBcmdprio_percentage\\fR or \\fBcmdprio_bssplit\\fR\nis set, this defaults to 0. Linux limits us to a positive value between\n0 and 7, with 0 being the highest. A single value applies to reads and writes.\nComma-separated values may be specified for reads and writes. See man\n\\fBionice\\fR\\|(1). Refer to an appropriate manpage for other operating systems\nsince the meaning of priority may differ. See also the \\fBprio\\fR option.\n.TP\n.BI (io_uring,libaio)cmdprio_bssplit \\fR=\\fPstr[,str]\nTo get a finer control over I/O priority, this option allows specifying\nthe percentage of IOs that must have a priority set depending on the block\nsize of the IO. This option is useful only when used together with the option\n\\fBbssplit\\fR, that is, multiple different block sizes are used for reads and\nwrites.\n.RS\n.P\nThe first accepted format for this option is the same as the format of the\n\\fBbssplit\\fR option:\n.RS\n.P\ncmdprio_bssplit=blocksize/percentage:blocksize/percentage\n.RE\n.P\nIn this case, each entry will use the priority class, priority hint and\npriority level defined by the options \\fBcmdprio_class\\fR, \\fBcmdprio\\fR\nand \\fBcmdprio_hint\\fR respectively.\n.P\nThe second accepted format for this option is:\n.RS\n.P\ncmdprio_bssplit=blocksize/percentage/class/level:blocksize/percentage/class/level\n.RE\n.P\nIn this case, the priority class and priority level is defined inside each\nentry. In comparison with the first accepted format, the second accepted format\ndoes not restrict all entries to have the same priority class and priority\nlevel.\n.P\nThe third accepted format for this option is:\n.RS\n.P\ncmdprio_bssplit=blocksize/percentage/class/level/hint:...\n.RE\n.P\nThis is an extension of the second accepted format that allows one to also\nspecify a priority hint.\n.P\nFor all formats, only the read and write data directions are supported, values\nfor trim IOs are ignored. This option is mutually exclusive with the\n\\fBcmdprio_percentage\\fR option.\n.RE\n.TP\n.BI (io_uring,io_uring_cmd)fixedbufs\nIf fio is asked to do direct IO, then Linux will map pages for each IO call, and\nrelease them when IO is done. If this option is set, the pages are pre-mapped\nbefore IO is started. This eliminates the need to map and release for each IO.\nThis is more efficient, and reduces the IO latency as well.\n.TP\n.BI (io_uring,io_uring_cmd)nonvectored \\fR=\\fPint\nWith this option, fio will use non-vectored read/write commands, where address\nmust contain the address directly. Default is -1.\n.TP\n.BI (io_uring,io_uring_cmd)force_async\nNormal operation for io_uring is to try and issue an sqe as non-blocking first,\nand if that fails, execute it in an async manner. With this option set to N,\nthen every N request fio will ask sqe to be issued in an async manner. Default\nis 0.\n.TP\n.BI (io_uring,io_uring_cmd,xnvme)hipri\nIf this option is set, fio will attempt to use polled IO completions. Normal IO\ncompletions generate interrupts to signal the completion of IO, polled\ncompletions do not. Hence they are require active reaping by the application.\nThe benefits are more efficient IO for high IOPS scenarios, and lower latencies\nfor low queue depth IO.\n.TP\n.BI (io_uring,io_uring_cmd)registerfiles\nWith this option, fio registers the set of files being used with the kernel.\nThis avoids the overhead of managing file counts in the kernel, making the\nsubmission and completion part more lightweight. Required for the below\nsqthread_poll option.\n.TP\n.BI (io_uring,io_uring_cmd,xnvme)sqthread_poll\nNormally fio will submit IO by issuing a system call to notify the kernel of\navailable items in the SQ ring. If this option is set, the act of submitting IO\nwill be done by a polling thread in the kernel. This frees up cycles for fio, at\nthe cost of using more CPU in the system. As submission is just the time it\ntakes to fill in the sqe entries and any syscall required to wake up the idle\nkernel thread, fio will not report submission latencies.\n.TP\n.BI (io_uring,io_uring_cmd)sqthread_poll_cpu \\fR=\\fPint\nWhen `sqthread_poll` is set, this option provides a way to define which CPU\nshould be used for the polling thread.\n.TP\n.BI (io_uring_cmd)cmd_type \\fR=\\fPstr\nSpecifies the type of uring passthrough command to be used. Supported\nvalue is nvme. Default is nvme.\n.TP\n.BI (libaio)userspace_reap\nNormally, with the libaio engine in use, fio will use the\n\\fBio_getevents\\fR\\|(3) system call to reap newly returned events. With\nthis flag turned on, the AIO ring will be read directly from user-space to\nreap events. The reaping mode is only enabled when polling for a minimum of\n0 events (e.g. when `iodepth_batch_complete=0').\n.TP\n.BI (pvsync2)hipri\nSet RWF_HIPRI on I/O, indicating to the kernel that it's of higher priority\nthan normal.\n.TP\n.BI (pvsync2)hipri_percentage\nWhen hipri is set this determines the probability of a pvsync2 I/O being high\npriority. The default is 100%.\n.TP\n.BI (pvsync2,libaio,io_uring,io_uring_cmd)nowait \\fR=\\fPbool\nBy default if a request cannot be executed immediately (e.g. resource starvation,\nwaiting on locks) it is queued and the initiating process will be blocked until\nthe required resource becomes free.\nThis option sets the RWF_NOWAIT flag (supported from the 4.14 Linux kernel) and\nthe call will return instantly with EAGAIN or a partial result rather than waiting.\n\nIt is useful to also use \\fBignore_error\\fR=EAGAIN when using this option.\nNote: glibc 2.27, 2.28 have a bug in syscall wrappers preadv2, pwritev2.\nThey return EOPNOTSUP instead of EAGAIN.\n\nFor cached I/O, using this option usually means a request operates only with\ncached data. Currently the RWF_NOWAIT flag does not supported for cached write.\nFor direct I/O, requests will only succeed if cache invalidation isn't required,\nfile blocks are fully allocated and the disk request could be issued immediately.\n.TP\n.BI (pvsync2,libaio,io_uring)atomic \\fR=\\fPbool\nThis option means that writes are issued with torn-write protection, meaning\nthat for a power fail or kernel crash, all or none of the data from the write\nwill be stored, but never a mix of old and new data. Torn-write protection is\nalso known as atomic writes.\n\nThis option sets the RWF_ATOMIC flag (supported from the 6.11 Linux kernel) on\na per-IO basis.\n\nWrites with RWF_ATOMIC set will be rejected by the kernel when the file does\nnot support torn-write protection. To learn a file's torn-write limits, issue\nstatx with STATX_WRITE_ATOMIC.\n.TP\n.BI (io_uring_cmd,xnvme)fdp \\fR=\\fPbool\nEnable Flexible Data Placement mode for write commands.\n.TP\n.BI (io_uring_cmd,xnvme)dataplacement \\fR=\\fPstr\nSpecifies the data placement directive type to use for write commands. The\nfollowing types are supported:\n.RS\n.RS\n.TP\n.B none\nDo not use a data placement directive. This is the default.\n.TP\n.B fdp\nUse Flexible Data placement directives for write commands. This is equivalent\nto specifying \\fBfdp\\fR=1.\n.TP\n.B streams\nUse Streams directives for write commands.\n.TP\n.RE\n.RE\n.TP\n.BI (io_uring_cmd,xnvme)plid_select=str, fdp_pli_select \\fR=\\fPstr\nDefines how fio decides which placement ID to use next. The following types\nare defined:\n.RS\n.RS\n.TP\n.B random\nChoose a placement ID at random (uniform).\n.TP\n.B roundrobin\nRound robin over available placement IDs. This is the default.\n.TP\n.B scheme\nChoose a placement ID (index) based on the scheme file defined by\nthe option \\fBdp_scheme\\fP.\n.RE\n.P\nThe available placement ID (indices) are defined by \\fBplids\\fR or\n\\fBfdp_pli\\fR option except for the case of \\fBscheme\\fP.\n.RE\n.TP\n.BI (io_uring_cmd,xnvme)plids=str, fdp_pli \\fR=\\fPstr\nSelect which Placement ID Indices (FDP) or Placement IDs (streams) this job is\nallowed to use for writes. This option accepts a comma-separated list of values\nor ranges (e.g., 1,2-4,5,6-8).\n\nFor FDP by default, the job will cycle through all available Placement IDs, so\nuse this option to be selective. The values specified here are array indices\nfor the list of placement IDs returned by the nvme-cli command `nvme fdp\nstatus'. If you want fio to use FDP placement identifiers only at indices 0, 2\nand 5, set `plids=0,2,5'.\n\nFor streams this should be a list of Stream IDs.\n.TP\n.BI (io_uring_cmd,xnvme)\\fR\\fBdp_scheme\\fP=str\nDefines which placement ID (index) to be selected based on offset(LBA) range.\nThe file should contains one or more scheme entries in the following format:\n.sp\n.RS\n.RS\n0, 10737418240, 0\n.br\n10737418240, 21474836480, 1\n.br\n21474836480, 32212254720, 2\n.br\n\\&...\n.RE\n.sp\nEach line, a scheme entry, contains start offset, end offset, and placement ID\n(index) separated by comma(,). If the write offset is within the range of a certain\nscheme entry(start offset ≤ offset < end offset), the corresponding placement ID\n(index) will be selected. If the write offset belongs to multiple scheme entries,\nthe first matched scheme entry will be applied. If the offset is not within any range\nof scheme entry, dspec field will be set to 0, default RUH. (Caution: In case of\nmultiple devices in a job, all devices of the job will be affected by the scheme. If\nthis option is specified, the option \\fBplids\\fP or \\fBfdp_pli\\fP will be ignored.)\n.RE\n.TP\n.BI (io_uring_cmd,xnvme)md_per_io_size \\fR=\\fPint\nSize in bytes for separate metadata buffer per IO. For io_uring_cmd these\nbuffers are allocated using malloc regardless of what is set for \\fBiomem\\fR.\nDefault: 0.\n.TP\n.BI (io_uring_cmd,xnvme)pi_act \\fR=\\fPint\nAction to take when nvme namespace is formatted with protection information.\nIf this is set to 1 and namespace is formatted with metadata size equal to\nprotection information size, fio won't use separate metadata buffer or extended\nlogical block. If this is set to 1 and namespace is formatted with metadata\nsize greater than protection information size, fio will not generate or verify\nthe protection information portion of metadata for write or read case\nrespectively. If this is set to 0, fio generates protection information for\nwrite case and verifies for read case. Default: 1.\n\nFor 16 bit CRC generation fio will use isa-l if available otherwise it will\nuse the default slower generator.\n(see: https://github.com/intel/isa-l)\n.TP\n.BI (io_uring_cmd,xnvme)pi_chk \\fR=\\fPstr[,str][,str]\nControls the protection information check. This can take one or more of these\nvalues. Default: none.\n.RS\n.RS\n.TP\n.B GUARD\nEnables protection information checking of guard field.\n.TP\n.B REFTAG\nEnables protection information checking of logical block reference tag field.\n.TP\n.B APPTAG\nEnables protection information checking of application tag field.\n.RE\n.RE\n.TP\n.BI (io_uring_cmd,xnvme)apptag \\fR=\\fPint\nSpecifies logical block application tag value, if namespace is formatted to use\nend to end protection information. Default: 0x1234.\n.TP\n.BI (io_uring_cmd,xnvme)apptag_mask \\fR=\\fPint\nSpecifies logical block application tag mask value, if namespace is formatted\nto use end to end protection information. Default: 0xffff.\n.TP\n.BI (io_uring_cmd)num_range \\fR=\\fPint\nFor trim command this will be the number of ranges to trim per I/O request.\nThe number of logical blocks per range is determined by the \\fBbs\\fR option\nwhich should be a multiple of logical block size. This cannot be used with\nread or write. Note that setting this option > 1, \\fBlog_offset\\fR will not be\nable to log all the offsets. Default: 1.\n.TP\n.BI (cpuio)cpuload \\fR=\\fPint\nAttempt to use the specified percentage of CPU cycles. This is a mandatory\noption when using cpuio I/O engine.\n.TP\n.BI (cpuio)cpuchunks \\fR=\\fPint\nSplit the load into cycles of the given time. In microseconds.\n.TP\n.BI (cpuio)cpumode \\fR=\\fPstr\nSpecify how to stress the CPU. It can take these two values:\n.RS\n.RS\n.TP\n.B noop\nThis is the default and directs the CPU to execute noop instructions.\n.TP\n.B qsort\nReplace the default noop instructions with a qsort algorithm to consume more energy.\n.RE\n.RE\n.TP\n.BI (cpuio)exit_on_io_done \\fR=\\fPbool\nDetect when I/O threads are done, then exit.\n.TP\n.BI (libhdfs)namenode \\fR=\\fPstr\nThe hostname or IP address of a HDFS cluster namenode to contact.\n.TP\n.BI (libhdfs)port \\fR=\\fPint\nThe listening port of the HFDS cluster namenode.\n.TP\n.BI (netsplice,net)port \\fR=\\fPint\nThe TCP or UDP port to bind to or connect to. If this is used with\n\\fBnumjobs\\fR to spawn multiple instances of the same job type, then\nthis will be the starting port number since fio will use a range of\nports.\n.TP\n.BI (rdma)port \\fR=\\fPint\nThe port to use for RDMA-CM communication. This should be the same\nvalue on the client and the server side.\n.TP\n.BI (netsplice,net,rdma)hostname \\fR=\\fPstr\nThe hostname or IP address to use for TCP, UDP or RDMA-CM based I/O.\nIf the job is a TCP listener or UDP reader, the hostname is not used\nand must be omitted unless it is a valid UDP multicast address.\n.TP\n.BI (netsplice,net)interface \\fR=\\fPstr\nThe IP address of the network interface used to send or receive UDP\nmulticast.\n.TP\n.BI (netsplice,net)ttl \\fR=\\fPint\nTime\\-to\\-live value for outgoing UDP multicast packets. Default: 1.\n.TP\n.BI (netsplice,net)nodelay \\fR=\\fPbool\nSet TCP_NODELAY on TCP connections.\n.TP\n.BI (netsplice,net)protocol \\fR=\\fPstr \"\\fR,\\fP proto\" \\fR=\\fPstr\nThe network protocol to use. Accepted values are:\n.RS\n.RS\n.TP\n.B tcp\nTransmission control protocol.\n.TP\n.B tcpv6\nTransmission control protocol V6.\n.TP\n.B udp\nUser datagram protocol.\n.TP\n.B udpv6\nUser datagram protocol V6.\n.TP\n.B unix\nUNIX domain socket.\n.TP\n.B vsock\nVSOCK protocol.\n.RE\n.P\nWhen the protocol is TCP, UDP or VSOCK, the port must also be given, as well as the\nhostname if the job is a TCP or VSOCK listener or UDP reader. For unix sockets, the\nnormal \\fBfilename\\fR option should be used and the port is invalid.\nWhen the protocol is VSOCK, the \\fBhostname\\fR is the CID of the remote VM.\n\n.RE\n.TP\n.BI (netsplice,net)listen\nFor TCP network connections, tell fio to listen for incoming connections\nrather than initiating an outgoing connection. The \\fBhostname\\fR must\nbe omitted if this option is used.\n.TP\n.BI (netsplice,net)pingpong\nNormally a network writer will just continue writing data, and a network\nreader will just consume packages. If `pingpong=1' is set, a writer will\nsend its normal payload to the reader, then wait for the reader to send the\nsame payload back. This allows fio to measure network latencies. The\nsubmission and completion latencies then measure local time spent sending or\nreceiving, and the completion latency measures how long it took for the\nother end to receive and send back. For UDP multicast traffic\n`pingpong=1' should only be set for a single reader when multiple readers\nare listening to the same address.\n.TP\n.BI (netsplice,net)window_size \\fR=\\fPint\nSet the desired socket buffer size for the connection.\n.TP\n.BI (netsplice,net)mss \\fR=\\fPint\nSet the TCP maximum segment size (TCP_MAXSEG).\n.TP\n.BI (e4defrag)donorname \\fR=\\fPstr\nFile will be used as a block donor (swap extents between files).\n.TP\n.BI (e4defrag)inplace \\fR=\\fPint\nConfigure donor file blocks allocation strategy:\n.RS\n.RS\n.TP\n.B 0\nDefault. Preallocate donor's file on init.\n.TP\n.B 1\nAllocate space immediately inside defragment event, and free right\nafter event.\n.RE\n.RE\n.TP\n.BI (rbd,rados)clustername \\fR=\\fPstr\nSpecifies the name of the Ceph cluster.\n.TP\n.BI (rbd)rbdname \\fR=\\fPstr\nSpecifies the name of the RBD.\n.TP\n.BI (rbd,rados)pool \\fR=\\fPstr\nSpecifies the name of the Ceph pool containing RBD or RADOS data.\n.TP\n.BI (rbd,rados)clientname \\fR=\\fPstr\nSpecifies the username (without the 'client.' prefix) used to access the\nCeph cluster. If the \\fBclustername\\fR is specified, the \\fBclientname\\fR shall be\nthe full *type.id* string. If no type. prefix is given, fio will add 'client.'\nby default.\n.TP\n.BI (rados)conf \\fR=\\fPstr\nSpecifies the configuration path of ceph cluster, so conf file does not\nhave to be /etc/ceph/ceph.conf.\n.TP\n.BI (rbd,rados)busy_poll \\fR=\\fPbool\nPoll store instead of waiting for completion. Usually this provides better\nthroughput at cost of higher(up to 100%) CPU utilization.\n.TP\n.BI (rados)touch_objects \\fR=\\fPbool\nDuring initialization, touch (create if do not exist) all objects (files).\nTouching all objects affects ceph caches and likely impacts test results.\nEnabled by default.\n.TP\n.BI (http)http_host \\fR=\\fPstr\nHostname to connect to.  HTTP port 80 is used automatically when the value \nof the \\fBhttps\\fP parameter is \\fRoff\\fP, and HTTPS port 443 if it is \\Ron\\fP.  \nA virtual-hosted-style S3 hostname starts with a bucket name, while a \npath-style S3 hostname does not.  Default is \\fBlocalhost\\fR.\n.TP\n.BI (http)http_user \\fR=\\fPstr\nUsername for HTTP authentication.\n.TP\n.BI (http)http_pass \\fR=\\fPstr\nPassword for HTTP authentication.\n.TP\n.BI (http)https \\fR=\\fPstr\nWhether to use HTTPS instead of plain HTTP. \\fRon\\fP enables HTTPS;\n\\fRinsecure\\fP will enable HTTPS, but disable SSL peer verification (use\nwith caution!).  Default is \\fBoff\\fR.\n.TP\n.BI (http)http_mode \\fR=\\fPstr\nWhich HTTP access mode to use: webdav, swift, or s3. Default is\n\\fBwebdav\\fR.\n.TP\n.BI (http)http_s3_region \\fR=\\fPstr\nThe S3 region/zone to include in the request. Default is \\fBus-east-1\\fR.\n.TP\n.BI (http)http_s3_key \\fR=\\fPstr\nThe S3 secret key.\n.TP\n.BI (http)http_s3_keyid \\fR=\\fPstr\nThe S3 key/access id.\n.TP\n.BI (http)http_s3_sse_customer_key \\fR=\\fPstr\nThe encryption customer key in SSE server side.\n.TP\n.BI (http)http_s3_sse_customer_algorithm \\fR=\\fPstr\nThe encryption customer algorithm in SSE server side. Default is \\fBAES256\\fR\n.TP\n.BI (http)http_s3_storage_class \\fR=\\fPstr\nWhich storage class to access. User-customizable settings. Default is \\fBSTANDARD\\fR\n.TP\n.BI (http)http_swift_auth_token \\fR=\\fPstr\nThe Swift auth token. See the example configuration file on how to\nretrieve this.\n.TP\n.BI (http)http_verbose \\fR=\\fPint\nEnable verbose requests from libcurl. Useful for debugging. 1 turns on\nverbose logging from libcurl, 2 additionally enables HTTP IO tracing.\nDefault is \\fB0\\fR\n.TP\n.BI (mtd)skip_bad \\fR=\\fPbool\nSkip operations against known bad blocks.\n.TP\n.BI (libhdfs)hdfsdirectory\nlibhdfs will create chunk in this HDFS directory.\n.TP\n.BI (libhdfs)chunk_size\nThe size of the chunk to use for each file.\n.TP\n.BI (rdma)verb \\fR=\\fPstr\nThe RDMA verb to use on this side of the RDMA ioengine\nconnection. Valid values are write, read, send and recv. These\ncorrespond to the equivalent RDMA verbs (e.g. write = rdma_write\netc.). Note that this only needs to be specified on the client side of\nthe connection. See the examples folder.\n.TP\n.BI (rdma)bindname \\fR=\\fPstr\nThe name to use to bind the local RDMA-CM connection to a local RDMA\ndevice. This could be a hostname or an IPv4 or IPv6 address. On the\nserver side this will be passed into the rdma_bind_addr() function and\non the client site it will be used in the rdma_resolve_add()\nfunction. This can be useful when multiple paths exist between the\nclient and the server or in certain loopback configurations.\n.TP\n.BI (filestat)stat_type \\fR=\\fPstr\nSpecify stat system call type to measure lookup/getattr performance.\nDefault is \\fBstat\\fR for \\fBstat\\fR\\|(2).\n.TP\n.BI (sg)hipri\nIf this option is set, fio will attempt to use polled IO completions. This\nwill have a similar effect as (io_uring)hipri. Only SCSI READ and WRITE\ncommands will have the SGV4_FLAG_HIPRI set (not UNMAP (trim) nor VERIFY).\nOlder versions of the Linux sg driver that do not support hipri will simply\nignore this flag and do normal IO. The Linux SCSI Low Level Driver (LLD)\nthat \"owns\" the device also needs to support hipri (also known as iopoll\nand mq_poll). The MegaRAID driver is an example of a SCSI LLD.\nDefault: clear (0) which does normal (interrupted based) IO.\n.TP\n.BI (sg, io_uring_cmd)readfua \\fR=\\fPbool\nWith readfua option set to 1, read operations include the force\nunit access (fua) flag. Default: 0.\n.TP\n.BI (sg, io_uring_cmd)writefua \\fR=\\fPbool\nWith writefua option set to 1, write operations include the force\nunit access (fua) flag. Default: 0.\n.TP\n.BI (io_uring_cmd)write_mode \\fR=\\fPstr\nSpecifies the type of write operation.  Defaults to 'write'.\n.RS\n.RS\n.TP\n.B write\nUse Write commands for write operations\n.TP\n.B uncor\nUse Write Uncorrectable commands for write operations\n.TP\n.B zeroes\nUse Write Zeroes commands for write operations\n.TP\n.B verify\nUse Verify commands for write operations\n.TP\n.RE\n.RE\n.TP\n.BI (io_uring_cmd)verify_mode \\fR=\\fPstr\nSpecifies the type of command to be used in the verification phase. Defaults to 'read'.\n.RS\n.RS\n.TP\n.B read\nUse Read commands for data verification\n.TP\n.B compare\nUse Compare commands for data verification\n.TP\n.RE\n.RE\n.TP\n.BI (sg)sg_write_mode \\fR=\\fPstr\nSpecify the type of write commands to issue. This option can take multiple\nvalues:\n.RS\n.RS\n.TP\n.B write (default)\nWrite opcodes are issued as usual\n.TP\n.B write_and_verify\nIssue WRITE AND VERIFY commands. The BYTCHK bit is set to 00b. This directs the\ndevice to carry out a medium verification with no data comparison for the data\nthat was written. The writefua option is ignored with this selection.\n.TP\n.B verify\nThis option is deprecated. Use write_and_verify instead.\n.TP\n.B write_same\nIssue WRITE SAME commands. This transfers a single block to the device\nand writes this same block of data to a contiguous sequence of LBAs\nbeginning at the specified offset. fio's block size parameter\nspecifies the amount of data written with each command. However, the\namount of data actually transferred to the device is equal to the\ndevice's block (sector) size. For a device with 512 byte sectors,\nblocksize=8k will write 16 sectors with each command. fio will still\ngenerate 8k of data for each command butonly the first 512 bytes will\nbe used and transferred to the device. The writefua option is ignored\nwith this selection.\n.TP\n.B same\nThis option is deprecated. Use write_same instead.\n.TP\n.B write_same_ndob\nIssue WRITE SAME(16) commands as above but with the No Data Output\nBuffer (NDOB) bit set. No data will be transferred to the device with\nthis bit set. Data written will be a pre-determined pattern such as\nall zeroes.\n.TP\n.B write_stream\nIssue WRITE STREAM(16) commands. Use the stream_id option to specify\nthe stream identifier.\n.TP\n.B verify_bytchk_00\nIssue VERIFY commands with BYTCHK set to 00. This directs the device to carry\nout a medium verification with no data comparison.\n.TP\n.B verify_bytchk_01\nIssue VERIFY commands with BYTCHK set to 01. This directs the device to\ncompare the data on the device with the data transferred to the device.\n.TP\n.B verify_bytchk_11\nIssue VERIFY commands with BYTCHK set to 11. This transfers a single block to\nthe device and compares the contents of this block with the data on the device\nbeginning at the specified offset. fio's block size parameter specifies the\ntotal amount of data compared with this command. However, only one block\n(sector) worth of data is transferred to the device. This is similar to the\nWRITE SAME command except that data is compared instead of written.\n.RE\n.RE\n.TP\n.BI (sg)stream_id \\fR=\\fPint\nSet the stream identifier for WRITE STREAM commands. If this is set to 0 (which is not\na valid stream identifier) fio will open a stream and then close it when done. Default\nis 0.\n.TP\n.BI (nbd)uri \\fR=\\fPstr\nSpecify the NBD URI of the server to test.\nThe string is a standard NBD URI (see\n\\fIhttps://github.com/NetworkBlockDevice/nbd/tree/master/doc\\fR).\nExample URIs:\n.RS\n.RS\n.TP\n\\fInbd://localhost:10809\\fR\n.TP\n\\fInbd+unix:///?socket=/tmp/socket\\fR\n.TP\n\\fInbds://tlshost/exportname\\fR\n.RE\n.RE\n.TP\n.BI (libcufile)gpu_dev_ids\\fR=\\fPstr\nSpecify the GPU IDs to use with CUDA. This is a colon-separated list of int.\nGPUs are assigned to workers roundrobin. Default is 0.\n.TP\n.BI (libcufile)cuda_io\\fR=\\fPstr\nSpecify the type of I/O to use with CUDA. This option\ntakes the following values:\n.RS\n.RS\n.TP\n.B cufile (default)\nUse libcufile and nvidia-fs. This option performs I/O directly\nbetween a GPUDirect Storage filesystem and GPU buffers,\navoiding use of a bounce buffer. If \\fBverify\\fR is set,\ncudaMemcpy is used to copy verification data between RAM and GPU(s).\nVerification data is copied from RAM to GPU before a write\nand from GPU to RAM after a read.\n\\fBdirect\\fR must be 1.\n.TP\n.BI posix\nUse POSIX to perform I/O with a RAM buffer, and use\ncudaMemcpy to transfer data between RAM and the GPU(s).\nData is copied from GPU to RAM before a write and copied\nfrom RAM to GPU after a read. \\fBverify\\fR does not affect\nthe use of cudaMemcpy.\n.RE\n.RE\n.TP\n.BI (dfs)pool\nSpecify the label or UUID of the DAOS pool to connect to.\n.TP\n.BI (dfs)cont\nSpecify the label or UUID of the DAOS container to open.\n.TP\n.BI (dfs)chunk_size\nSpecify a different chunk size (in bytes) for the dfs file.\nUse DAOS container's chunk size by default.\n.TP\n.BI (dfs)object_class\nSpecify a different object class for the dfs file.\nUse DAOS container's object class by default.\n.TP\n.BI (nfs)nfs_url\nURL in libnfs format, eg nfs://<server|ipv4|ipv6>/path[?arg=val[&arg=val]*]\nRefer to the libnfs README for more details.\n.TP\n.BI (exec)program\\fR=\\fPstr\nSpecify the program to execute.\nNote the program will receive a SIGTERM when the job is reaching the time limit.\nA SIGKILL is sent once the job is over. The delay between the two signals is defined by \\fBgrace_time\\fR option.\n.TP\n.BI (exec)arguments\\fR=\\fPstr\nSpecify arguments to pass to program.\nSome special variables can be expanded to pass fio's job details to the program :\n.RS\n.RS\n.TP\n.B %r\nreplaced by the duration of the job in seconds\n.TP\n.BI %n\nreplaced by the name of the job\n.RE\n.RE\n.TP\n.BI (exec)grace_time\\fR=\\fPint\nDefines the time between the SIGTERM and SIGKILL signals. Default is 1 second.\n.TP\n.BI (exec)std_redirect\\fR=\\fPbool\nIf set, stdout and stderr streams are redirected to files named from the job name. Default is true.\n.TP\n.BI (xnvme)xnvme_async\\fR=\\fPstr\nSelect the xnvme async command interface. This can take these values.\n.RS\n.RS\n.TP\n.B emu\nThis is default and use to emulate asynchronous I/O by using a single thread to\ncreate a queue pair on top of a synchronous I/O interface using the NVMe driver\nIOCTL.\n.TP\n.BI thrpool\nEmulate an asynchronous I/O interface with a pool of userspace threads on top\nof a synchronous I/O interface using the NVMe driver IOCTL. By default four\nthreads are used.\n.TP\n.BI io_uring\nLinux native asynchronous I/O interface which supports both direct and buffered\nI/O.\n.TP\n.BI libaio\nUse Linux aio for Asynchronous I/O\n.TP\n.BI posix\nUse the posix asynchronous I/O interface to perform one or more I/O operations\nasynchronously.\n.TP\n.BI vfio\nUse the user-space VFIO-based backend, implemented using libvfn instead of\nSPDK.\n.TP\n.BI nil\nDo not transfer any data; just pretend to. This is mainly used for\nintrospective performance evaluation.\n.RE\n.RE\n.TP\n.BI (xnvme)xnvme_sync\\fR=\\fPstr\nSelect the xnvme synchronous command interface. This can take these values.\n.RS\n.RS\n.TP\n.B nvme\nThis is default and uses Linux NVMe Driver ioctl() for synchronous I/O.\n.TP\n.BI psync\nThis supports regular as well as vectored pread() and pwrite() commands.\n.TP\n.BI block\nThis is the same as psync except that it also supports zone management\ncommands using Linux block layer IOCTLs.\n.RE\n.RE\n.TP\n.BI (xnvme)xnvme_admin\\fR=\\fPstr\nSelect the xnvme admin command interface. This can take these values.\n.RS\n.RS\n.TP\n.B nvme\nThis is default and uses Linux NVMe Driver ioctl() for admin commands.\n.TP\n.BI block\nUse Linux Block Layer ioctl() and sysfs for admin commands.\n.RE\n.RE\n.TP\n.BI (xnvme)xnvme_dev_nsid\\fR=\\fPint\nxnvme namespace identifier for userspace NVMe driver SPDK or vfio.\n.TP\n.BI (xnvme)xnvme_dev_subnqn\\fR=\\fPstr\nSets the subsystem NQN for fabrics. This is for xNVMe to utilize a fabrics\ntarget with multiple systems.\n.TP\n.BI (xnvme)xnvme_mem\\fR=\\fPstr\nSelect the xnvme memory backend. This can take these values.\n.RS\n.RS\n.TP\n.B posix\nThis is the default posix memory backend for linux NVMe driver.\n.TP\n.BI hugepage\nUse hugepages, instead of existing posix memory backend. The memory backend\nuses hugetlbfs. This require users to allocate hugepages, mount hugetlbfs and\nset an environment variable for XNVME_HUGETLB_PATH.\n.TP\n.BI spdk\nUses SPDK's memory allocator.\n.TP\n.BI vfio\nUses libvfn's memory allocator. This also specifies the use of libvfn backend\ninstead of SPDK.\n.RE\n.RE\n.TP\n.BI (xnvme)xnvme_iovec\nIf this option is set, xnvme will use vectored read/write commands.\n.TP\n.BI (libblkio)libblkio_driver \\fR=\\fPstr\nThe libblkio driver to use. Different drivers access devices through different\nunderlying interfaces. Available drivers depend on the libblkio version in use\nand are listed at \\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\\fR\n.TP\n.BI (libblkio)libblkio_path \\fR=\\fPstr\nSets the value of the driver-specific \"path\" property before connecting the\nlibblkio instance, which identifies the target device or file on which to\nperform I/O. Its exact semantics are driver-dependent and not all drivers may\nsupport it; see \\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\\fR\n.TP\n.BI (libblkio)libblkio_pre_connect_props \\fR=\\fPstr\nA colon-separated list of additional libblkio properties to be set after\ncreating but before connecting the libblkio instance. Each property must have\nthe format \\fB<name>=<value>\\fR. Colons can be escaped as \\fB\\\\:\\fR. These are\nset after the engine sets any other properties, so those can be overridden.\nAvailable properties depend on the libblkio version in use and are listed at\n\\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#properties\\fR\n.TP\n.BI (libblkio)libblkio_num_entries \\fR=\\fPint\nSets the value of the driver-specific \"num-entries\" property before starting the\nlibblkio instance. Its exact semantics are driver-dependent and not all drivers\nmay support it; see \\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\\fR\n.TP\n.BI (libblkio)libblkio_queue_size \\fR=\\fPint\nSets the value of the driver-specific \"queue-size\" property before starting the\nlibblkio instance. Its exact semantics are driver-dependent and not all drivers\nmay support it; see \\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#drivers\\fR\n.TP\n.BI (libblkio)libblkio_pre_start_props \\fR=\\fPstr\nA colon-separated list of additional libblkio properties to be set after\nconnecting but before starting the libblkio instance. Each property must have\nthe format \\fB<name>=<value>\\fR. Colons can be escaped as \\fB\\\\:\\fR. These are\nset after the engine sets any other properties, so those can be overridden.\nAvailable properties depend on the libblkio version in use and are listed at\n\\fIhttps://libblkio.gitlab.io/libblkio/blkio.html#properties\\fR\n.TP\n.BI (libblkio)hipri\nUse poll queues. This is incompatible with \\fBlibblkio_wait_mode=eventfd\\fR and\n\\fBlibblkio_force_enable_completion_eventfd\\fR.\n.TP\n.BI (libblkio)libblkio_vectored\nSubmit vectored read and write requests.\n.TP\n.BI (libblkio)libblkio_write_zeroes_on_trim\nSubmit trims as \"write zeroes\" requests instead of discard requests.\n.TP\n.BI (libblkio)libblkio_wait_mode \\fR=\\fPstr\nHow to wait for completions:\n.RS\n.RS\n.TP\n.B block \\fR(default)\nUse a blocking call to \\fBblkioq_do_io()\\fR.\n.TP\n.B eventfd\nUse a blocking call to \\fBread()\\fR on the completion eventfd.\n.TP\n.B loop\nUse a busy loop with a non-blocking call to \\fBblkioq_do_io()\\fR.\n.RE\n.RE\n.TP\n.BI (libblkio)libblkio_force_enable_completion_eventfd\nEnable the queue's completion eventfd even when unused. This may impact\nperformance. The default is to enable it only if\n\\fBlibblkio_wait_mode=eventfd\\fR.\n.TP\n.BI (windowsaio)no_completion_thread\nAvoid using a separate thread for completion polling.\n.SS \"I/O depth\"\n.TP\n.BI iodepth \\fR=\\fPint\nNumber of I/O units to keep in flight against the file. Note that\nincreasing \\fBiodepth\\fR beyond 1 will not affect synchronous ioengines (except\nfor small degrees when \\fBverify_async\\fR is in use). Even async\nengines may impose OS restrictions causing the desired depth not to be\nachieved. This may happen on Linux when using libaio and not setting\n`direct=1', since buffered I/O is not async on that OS. Keep an\neye on the I/O depth distribution in the fio output to verify that the\nachieved depth is as expected. Default: 1.\n.TP\n.BI iodepth_batch_submit \\fR=\\fPint \"\\fR,\\fP iodepth_batch\" \\fR=\\fPint\nThis defines how many pieces of I/O to submit at once. It defaults to 1\nwhich means that we submit each I/O as soon as it is available, but can be\nraised to submit bigger batches of I/O at the time. If it is set to 0 the\n\\fBiodepth\\fR value will be used.\n.TP\n.BI iodepth_batch_complete_min \\fR=\\fPint \"\\fR,\\fP iodepth_batch_complete\" \\fR=\\fPint\nThis defines how many pieces of I/O to retrieve at once. It defaults to 1\nwhich means that we'll ask for a minimum of 1 I/O in the retrieval process\nfrom the kernel. The I/O retrieval will go on until we hit the limit set by\n\\fBiodepth_low\\fR. If this variable is set to 0, then fio will always\ncheck for completed events before queuing more I/O. This helps reduce I/O\nlatency, at the cost of more retrieval system calls.\n.TP\n.BI iodepth_batch_complete_max \\fR=\\fPint\nThis defines maximum pieces of I/O to retrieve at once. This variable should\nbe used along with \\fBiodepth_batch_complete_min\\fR=\\fIint\\fR variable,\nspecifying the range of min and max amount of I/O which should be\nretrieved. By default it is equal to \\fBiodepth_batch_complete_min\\fR\nvalue. Example #1:\n.RS\n.RS\n.P\n.PD 0\niodepth_batch_complete_min=1\n.P\niodepth_batch_complete_max=<iodepth>\n.PD\n.RE\n.P\nwhich means that we will retrieve at least 1 I/O and up to the whole\nsubmitted queue depth. If none of I/O has been completed yet, we will wait.\nExample #2:\n.RS\n.P\n.PD 0\niodepth_batch_complete_min=0\n.P\niodepth_batch_complete_max=<iodepth>\n.PD\n.RE\n.P\nwhich means that we can retrieve up to the whole submitted queue depth, but\nif none of I/O has been completed yet, we will NOT wait and immediately exit\nthe system call. In this example we simply do polling.\n.RE\n.TP\n.BI iodepth_low \\fR=\\fPint\nThe low water mark indicating when to start filling the queue\nagain. Defaults to the same as \\fBiodepth\\fR, meaning that fio will\nattempt to keep the queue full at all times. If \\fBiodepth\\fR is set to\ne.g. 16 and \\fBiodepth_low\\fR is set to 4, then after fio has filled the queue of\n16 requests, it will let the depth drain down to 4 before starting to fill\nit again.\n.TP\n.BI serialize_overlap \\fR=\\fPbool\nSerialize in-flight I/Os that might otherwise cause or suffer from data races.\nWhen two or more I/Os are submitted simultaneously, there is no guarantee that\nthe I/Os will be processed or completed in the submitted order. Further, if\ntwo or more of those I/Os are writes, any overlapping region between them can\nbecome indeterminate/undefined on certain storage. These issues can cause\nverification to fail erratically when at least one of the racing I/Os is\nchanging data and the overlapping region has a non-zero size. Setting\n\\fBserialize_overlap\\fR tells fio to avoid provoking this behavior by explicitly\nserializing in-flight I/Os that have a non-zero overlap. Note that setting\nthis option can reduce both performance and the \\fBiodepth\\fR achieved.\n.RS\n.P\nThis option only applies to I/Os issued for a single job except when it is\nenabled along with \\fBio_submit_mode\\fR=offload. In offload mode, fio\nwill check for overlap among all I/Os submitted by offload jobs with \\fBserialize_overlap\\fR\nenabled.\n.P\nDefault: false.\n.RE\n.TP\n.BI io_submit_mode \\fR=\\fPstr\nThis option controls how fio submits the I/O to the I/O engine. The default\nis `inline', which means that the fio job threads submit and reap I/O\ndirectly. If set to `offload', the job threads will offload I/O submission\nto a dedicated pool of I/O threads. This requires some coordination and thus\nhas a bit of extra overhead, especially for lower queue depth I/O where it\ncan increase latencies. The benefit is that fio can manage submission rates\nindependently of the device completion rates. This avoids skewed latency\nreporting if I/O gets backed up on the device side (the coordinated omission\nproblem). Note that this option cannot reliably be used with async IO engines.\n.SS \"I/O rate\"\n.TP\n.BI thinkcycles \\fR=\\fPint\nStall the job for the specified number of cycles after an I/O has completed before\nissuing the next. May be used to simulate processing being done by an application.\nThis is not taken into account for the time to be waited on for \\fBthinktime\\fR.\nMight not have any effect on some platforms, this can be checked by trying a setting\na high enough amount of thinkcycles.\n.TP\n.BI thinktime \\fR=\\fPtime\nStall the job for the specified period of time after an I/O has completed before issuing the\nnext. May be used to simulate processing being done by an application.\nWhen the unit is omitted, the value is interpreted in microseconds. See\n\\fBthinktime_blocks\\fR, \\fBthinktime_iotime\\fR and \\fBthinktime_spin\\fR.\n.TP\n.BI thinktime_spin \\fR=\\fPtime\nOnly valid if \\fBthinktime\\fR is set - pretend to spend CPU time doing\nsomething with the data received, before falling back to sleeping for the\nrest of the period specified by \\fBthinktime\\fR. When the unit is\nomitted, the value is interpreted in microseconds.\n.TP\n.BI thinktime_blocks \\fR=\\fPint\nOnly valid if \\fBthinktime\\fR is set - control how many blocks to issue,\nbefore waiting \\fBthinktime\\fR usecs. If not set, defaults to 1 which will make\nfio wait \\fBthinktime\\fR usecs after every block. This effectively makes any\nqueue depth setting redundant, since no more than 1 I/O will be queued\nbefore we have to complete it and do our \\fBthinktime\\fR. In other words, this\nsetting effectively caps the queue depth if the latter is larger.\n.TP\n.BI thinktime_blocks_type \\fR=\\fPstr\nOnly valid if \\fBthinktime\\fR is set - control how \\fBthinktime_blocks\\fR triggers.\nThe default is `complete', which triggers \\fBthinktime\\fR when fio completes\n\\fBthinktime_blocks\\fR blocks. If this is set to `issue', then the trigger happens\nat the issue side.\n.TP\n.BI thinktime_iotime \\fR=\\fPtime\nOnly valid if \\fBthinktime\\fR is set - control \\fBthinktime\\fR interval by time.\nThe \\fBthinktime\\fR stall is repeated after IOs are executed for\n\\fBthinktime_iotime\\fR. For example, `\\-\\-thinktime_iotime=9s \\-\\-thinktime=1s'\nrepeat 10-second cycle with IOs for 9 seconds and stall for 1 second. When the\nunit is omitted, \\fBthinktime_iotime\\fR is interpreted as a number of seconds.\nIf this option is used together with \\fBthinktime_blocks\\fR, the \\fBthinktime\\fR\nstall is repeated after \\fBthinktime_iotime\\fR or after \\fBthinktime_blocks\\fR\nIOs, whichever happens first.\n\n.TP\n.BI rate \\fR=\\fPint[,int][,int]\nCap the bandwidth used by this job. The number is in bytes/sec, the normal\nsuffix rules apply. Comma-separated values may be specified for reads,\nwrites, and trims as described in \\fBblocksize\\fR.\n.RS\n.P\nFor example, using `rate=1m,500k' would limit reads to 1MiB/sec and writes to\n500KiB/sec. Capping only reads or writes can be done with `rate=,500k' or\n`rate=500k,' where the former will only limit writes (to 500KiB/sec) and the\nlatter will only limit reads.\n.RE\n.TP\n.BI rate_min \\fR=\\fPint[,int][,int]\nTell fio to do whatever it can to maintain at least this bandwidth. Failing\nto meet this requirement will cause the job to exit. Comma-separated values\nmay be specified for reads, writes, and trims as described in\n\\fBblocksize\\fR.\n.TP\n.BI rate_iops \\fR=\\fPint[,int][,int]\nCap the bandwidth to this number of IOPS. Basically the same as\n\\fBrate\\fR, just specified independently of bandwidth. If the job is\ngiven a block size range instead of a fixed value, the smallest block size\nis used as the metric. Comma-separated values may be specified for reads,\nwrites, and trims as described in \\fBblocksize\\fR.\n.TP\n.BI rate_iops_min \\fR=\\fPint[,int][,int]\nIf fio doesn't meet this rate of I/O, it will cause the job to exit.\nComma-separated values may be specified for reads, writes, and trims as\ndescribed in \\fBblocksize\\fR.\n.TP\n.BI rate_process \\fR=\\fPstr\nThis option controls how fio manages rated I/O submissions. The default is\n`linear', which submits I/O in a linear fashion with fixed delays between\nI/Os that gets adjusted based on I/O completion rates. If this is set to\n`poisson', fio will submit I/O based on a more real world random request\nflow, known as the Poisson process\n(\\fIhttps://en.wikipedia.org/wiki/Poisson_point_process\\fR). The lambda will be\n10^6 / IOPS for the given workload.\n.TP\n.BI rate_ignore_thinktime \\fR=\\fPbool\nBy default, fio will attempt to catch up to the specified rate setting, if any\nkind of thinktime setting was used. If this option is set, then fio will\nignore the thinktime and continue doing IO at the specified rate, instead of\nentering a catch-up mode after thinktime is done.\n.TP\n.BI rate_cycle \\fR=\\fPint\nAverage bandwidth for \\fBrate_min\\fR and \\fBrate_iops_min\\fR over this number\nof milliseconds. Defaults to 1000.\n.SS \"I/O latency\"\n.TP\n.BI latency_target \\fR=\\fPtime\nIf set, fio will attempt to find the max performance point that the given\nworkload will run at while maintaining a latency below this target. When\nthe unit is omitted, the value is interpreted in microseconds. See\n\\fBlatency_window\\fR and \\fBlatency_percentile\\fR.\n.TP\n.BI latency_window \\fR=\\fPtime\nUsed with \\fBlatency_target\\fR to specify the sample window that the job\nis run at varying queue depths to test the performance. When the unit is\nomitted, the value is interpreted in microseconds.\n.TP\n.BI latency_percentile \\fR=\\fPfloat\nThe percentage of I/Os that must fall within the criteria specified by\n\\fBlatency_target\\fR and \\fBlatency_window\\fR. If not set, this\ndefaults to 100.0, meaning that all I/Os must be equal or below to the value\nset by \\fBlatency_target\\fR.\n.TP\n.BI latency_run \\fR=\\fPbool\nUsed with \\fBlatency_target\\fR. If false (default), fio will find the highest\nqueue depth that meets \\fBlatency_target\\fR and exit. If true, fio will continue\nrunning and try to meet \\fBlatency_target\\fR by adjusting queue depth.\n.TP\n.BI max_latency \\fR=\\fPtime[,time][,time]\nIf set, fio will exit the job with an ETIMEDOUT error if it exceeds this\nmaximum latency. When the unit is omitted, the value is interpreted in\nmicroseconds. Comma-separated values may be specified for reads, writes,\nand trims as described in \\fBblocksize\\fR.\n.SS \"I/O replay\"\n.TP\n.BI write_iolog \\fR=\\fPstr\nWrite the issued I/O patterns to the specified file. See\n\\fBread_iolog\\fR. Specify a separate file for each job, otherwise the\niologs will be interspersed and the file may be corrupt. This file will be\nopened in append mode.\n.TP\n.BI read_iolog \\fR=\\fPstr\nOpen an iolog with the specified filename and replay the I/O patterns it\ncontains. This can be used to store a workload and replay it sometime\nlater. The iolog given may also be a blktrace binary file, which allows fio\nto replay a workload captured by blktrace. See\n\\fBblktrace\\fR\\|(8) for how to capture such logging data. For blktrace\nreplay, the file needs to be turned into a blkparse binary data file first\n(`blkparse <device> \\-o /dev/null \\-d file_for_fio.bin').\nYou can specify a number of files by separating the names with a ':' character.\nSee the \\fBfilename\\fR option for information on how to escape ':'\ncharacters within the file names. These files will be sequentially assigned to\njob clones created by \\fBnumjobs\\fR. '-' is a reserved name, meaning read from\nstdin, notably if \\fBfilename\\fR is set to '-' which means stdin as well,\nthen this flag can't be set to '-'.\n.TP\n.BI read_iolog_chunked \\fR=\\fPbool\nDetermines how iolog is read. If false (default) entire \\fBread_iolog\\fR will\nbe read at once. If selected true, input from iolog will be read gradually.\nUseful when iolog is very large, or it is generated.\n.TP\n.BI merge_blktrace_file \\fR=\\fPstr\nWhen specified, rather than replaying the logs passed to \\fBread_iolog\\fR,\nthe logs go through a merge phase which aggregates them into a single blktrace.\nThe resulting file is then passed on as the \\fBread_iolog\\fR parameter. The\nintention here is to make the order of events consistent. This limits the\ninfluence of the scheduler compared to replaying multiple blktraces via\nconcurrent jobs.\n.TP\n.BI merge_blktrace_scalars \\fR=\\fPfloat_list\nThis is a percentage based option that is index paired with the list of files\npassed to \\fBread_iolog\\fR. When merging is performed, scale the time of each\nevent by the corresponding amount. For example,\n`\\-\\-merge_blktrace_scalars=\"50:100\"' runs the first trace in halftime and the\nsecond trace in realtime. This knob is separately tunable from\n\\fBreplay_time_scale\\fR which scales the trace during runtime and will not\nchange the output of the merge unlike this option.\n.TP\n.BI merge_blktrace_iters \\fR=\\fPfloat_list\nThis is a whole number option that is index paired with the list of files\npassed to \\fBread_iolog\\fR. When merging is performed, run each trace for\nthe specified number of iterations. For example,\n`\\-\\-merge_blktrace_iters=\"2:1\"' runs the first trace for two iterations\nand the second trace for one iteration.\n.TP\n.BI replay_no_stall \\fR=\\fPbool\nWhen replaying I/O with \\fBread_iolog\\fR the default behavior is to\nattempt to respect the timestamps within the log and replay them with the\nappropriate delay between IOPS. By setting this variable fio will not\nrespect the timestamps and attempt to replay them as fast as possible while\nstill respecting ordering. The result is the same I/O pattern to a given\ndevice, but different timings.\n.TP\n.BI replay_time_scale \\fR=\\fPint\nWhen replaying I/O with \\fBread_iolog\\fR, fio will honor the original timing\nin the trace. With this option, it's possible to scale the time. It's a\npercentage option, if set to 50 it means run at 50% the original IO rate in\nthe trace. If set to 200, run at twice the original IO rate. Defaults to 100.\n.TP\n.BI replay_redirect \\fR=\\fPstr\nWhile replaying I/O patterns using \\fBread_iolog\\fR the default behavior\nis to replay the IOPS onto the major/minor device that each IOP was recorded\nfrom. This is sometimes undesirable because on a different machine those\nmajor/minor numbers can map to a different device. Changing hardware on the\nsame system can also result in a different major/minor mapping.\n\\fBreplay_redirect\\fR causes all I/Os to be replayed onto the single specified\ndevice regardless of the device it was recorded\nfrom. i.e. `replay_redirect=/dev/sdc' would cause all I/O\nin the blktrace or iolog to be replayed onto `/dev/sdc'. This means\nmultiple devices will be replayed onto a single device, if the trace\ncontains multiple devices. If you want multiple devices to be replayed\nconcurrently to multiple redirected devices you must blkparse your trace\ninto separate traces and replay them with independent fio invocations.\nUnfortunately this also breaks the strict time ordering between multiple\ndevice accesses.\n.TP\n.BI replay_align \\fR=\\fPint\nForce alignment of the byte offsets in a trace to this value. The value\nmust be a power of 2.\n.TP\n.BI replay_scale \\fR=\\fPint\nScale bye offsets down by this factor when replaying traces. Should most\nlikely use \\fBreplay_align\\fR as well.\n.SS \"Threads, processes and job synchronization\"\n.TP\n.BI replay_skip \\fR=\\fPstr\nSometimes it's useful to skip certain IO types in a replay trace. This could\nbe, for instance, eliminating the writes in the trace. Or not replaying the\ntrims/discards, if you are redirecting to a device that doesn't support them.\nThis option takes a comma separated list of read, write, trim, sync.\n.TP\n.BI thread\nFio defaults to creating jobs by using fork, however if this option is\ngiven, fio will create jobs by using POSIX Threads' function\n\\fBpthread_create\\fR\\|(3) to create threads instead.\n.TP\n.BI wait_for \\fR=\\fPstr\nIf set, the current job won't be started until all workers of the specified\nwaitee job are done.\n.\\\" ignore blank line here from HOWTO as it looks normal without it\n\\fBwait_for\\fR operates on the job name basis, so there are a few\nlimitations. First, the waitee must be defined prior to the waiter job\n(meaning no forward references). Second, if a job is being referenced as a\nwaitee, it must have a unique name (no duplicate waitees).\n.TP\n.BI nice \\fR=\\fPint\nRun the job with the given nice value. See man \\fBnice\\fR\\|(2).\n.\\\" ignore blank line here from HOWTO as it looks normal without it\nOn Windows, values less than \\-15 set the process class to \"High\"; \\-1 through\n\\-15 set \"Above Normal\"; 1 through 15 \"Below Normal\"; and above 15 \"Idle\"\npriority class.\n.TP\n.BI prio \\fR=\\fPint\nSet the I/O priority value of this job. Linux limits us to a positive value\nbetween 0 and 7, with 0 being the highest. See man\n\\fBionice\\fR\\|(1). Refer to an appropriate manpage for other operating\nsystems since meaning of priority may differ. For per-command priority\nsetting, see the I/O engine specific `cmdprio_percentage` and\n`cmdprio` options.\n.TP\n.BI prioclass \\fR=\\fPint\nSet the I/O priority class. See man \\fBionice\\fR\\|(1). For per-command\npriority setting, see the I/O engine specific `cmdprio_percentage` and\n`cmdprio_class` options.\n.TP\n.BI priohint \\fR=\\fPint\nSet the I/O priority hint. This is only applicable to platforms that support\nI/O priority classes and to devices with features controlled through priority\nhints, e.g. block devices supporting command duration limits, or CDL. CDL is a\nway to indicate the desired maximum latency of I/Os so that the device can\noptimize its internal command scheduling according to the latency limits\nindicated by the user. For per-I/O priority hint setting, see the I/O engine\nspecific \\fBcmdprio_hint\\fB option.\n.TP\n.BI cpus_allowed \\fR=\\fPstr\nControls the same options as \\fBcpumask\\fR, but accepts a textual\nspecification of the permitted CPUs instead and CPUs are indexed from 0. So\nto use CPUs 0 and 5 you would specify `cpus_allowed=0,5'. This option also\nallows a range of CPUs to be specified \\-\\- say you wanted a binding to CPUs\n0, 5, and 8 to 15, you would set `cpus_allowed=0,5,8\\-15'.\n.RS\n.P\nOn Windows, when `cpus_allowed' is unset only CPUs from fio's current\nprocessor group will be used and affinity settings are inherited from the\nsystem. An fio build configured to target Windows 7 makes options that set\nCPUs processor group aware and values will set both the processor group\nand a CPU from within that group. For example, on a system where processor\ngroup 0 has 40 CPUs and processor group 1 has 32 CPUs, `cpus_allowed'\nvalues between 0 and 39 will bind CPUs from processor group 0 and\n`cpus_allowed' values between 40 and 71 will bind CPUs from processor\ngroup 1. When using `cpus_allowed_policy=shared' all CPUs specified by a\nsingle `cpus_allowed' option must be from the same processor group. For\nWindows fio builds not built for Windows 7, CPUs will only be selected from\n(and be relative to) whatever processor group fio happens to be running in\nand CPUs from other processor groups cannot be used.\n.RE\n.TP\n.BI cpus_allowed_policy \\fR=\\fPstr\nSet the policy of how fio distributes the CPUs specified by\n\\fBcpus_allowed\\fR or \\fBcpumask\\fR. Two policies are supported:\n.RS\n.RS\n.TP\n.B shared\nAll jobs will share the CPU set specified.\n.TP\n.B split\nEach job will get a unique CPU from the CPU set.\n.RE\n.P\n\\fBshared\\fR is the default behavior, if the option isn't specified. If\n\\fBsplit\\fR is specified, then fio will assign one cpu per job. If not\nenough CPUs are given for the jobs listed, then fio will roundrobin the CPUs\nin the set.\n.RE\n.TP\n.BI cpumask \\fR=\\fPint\nSet the CPU affinity of this job. The parameter given is a bit mask of\nallowed CPUs the job may run on. So if you want the allowed CPUs to be 1\nand 5, you would pass the decimal value of (1 << 1 | 1 << 5), or 34. See man\n\\fBsched_setaffinity\\fR\\|(2). This may not work on all supported\noperating systems or kernel versions. This option doesn't work well for a\nhigher CPU count than what you can store in an integer mask, so it can only\ncontrol cpus 1\\-32. For boxes with larger CPU counts, use\n\\fBcpus_allowed\\fR.\n.TP\n.BI numa_cpu_nodes \\fR=\\fPstr\nSet this job running on specified NUMA nodes' CPUs. The arguments allow\ncomma delimited list of cpu numbers, A\\-B ranges, or `all'. Note, to enable\nNUMA options support, fio must be built on a system with libnuma\\-dev(el)\ninstalled.\n.TP\n.BI numa_mem_policy \\fR=\\fPstr\nSet this job's memory policy and corresponding NUMA nodes. Format of the\narguments:\n.RS\n.RS\n.P\n<mode>[:<nodelist>]\n.RE\n.P\n`mode' is one of the following memory policies: `default', `prefer',\n`bind', `interleave' or `local'. For `default' and `local' memory\npolicies, no node needs to be specified. For `prefer', only one node is\nallowed. For `bind' and `interleave' the `nodelist' may be as\nfollows: a comma delimited list of numbers, A\\-B ranges, or `all'.\n.RE\n.TP\n.BI cgroup \\fR=\\fPstr\nAdd job to this control group. If it doesn't exist, it will be created. The\nsystem must have a mounted cgroup blkio mount point for this to work. If\nyour system doesn't have it mounted, you can do so with:\n.RS\n.RS\n.P\n# mount \\-t cgroup \\-o blkio none /cgroup\n.RE\n.RE\n.TP\n.BI cgroup_weight \\fR=\\fPint\nSet the weight of the cgroup to this value. See the documentation that comes\nwith the kernel, allowed values are in the range of 100..1000.\n.TP\n.BI cgroup_nodelete \\fR=\\fPbool\nNormally fio will delete the cgroups it has created after the job\ncompletion. To override this behavior and to leave cgroups around after the\njob completion, set `cgroup_nodelete=1'. This can be useful if one wants\nto inspect various cgroup files after job completion. Default: false.\n.TP\n.BI flow_id \\fR=\\fPint\nThe ID of the flow. If not specified, it defaults to being a global\nflow. See \\fBflow\\fR.\n.TP\n.BI flow \\fR=\\fPint\nWeight in token-based flow control. If this value is used,\nthen fio regulates the activity between two or more jobs\nsharing the same flow_id.\nFio attempts to keep each job activity proportional to other jobs' activities\nin the same flow_id group, with respect to requested weight per job.\nThat is, if one job has `flow=3', another job has `flow=2'\nand another with `flow=1`, then there will be a roughly 3:2:1 ratio\nin how much one runs vs the others.\n.TP\n.BI flow_sleep \\fR=\\fPint\nThe period of time, in microseconds, to wait after the flow counter\nhas exceeded its proportion before retrying operations.\n.TP\n.BI stonewall \"\\fR,\\fB wait_for_previous\"\nWait for preceding jobs in the job file to exit, before starting this\none. Can be used to insert serialization points in the job file. A stone\nwall also implies starting a new reporting group, see\n\\fBgroup_reporting\\fR. Optionally you can use `stonewall=0` to disable or\n`stonewall=1` to enable it.\n.TP\n.BI exitall\nBy default, fio will continue running all other jobs when one job finishes.\nSometimes this is not the desired action. Setting \\fBexitall\\fR will instead\nmake fio terminate all jobs in the same group, as soon as one job of that\ngroup finishes.\n.TP\n.BI exit_what \\fR=\\fPstr\nBy default, fio will continue running all other jobs when one job finishes.\nSometimes this is not the desired action. Setting \\fBexitall\\fR will instead\nmake fio terminate all jobs in the same group. The option \\fBexit_what\\fR\nallows you to control which jobs get terminated when \\fBexitall\\fR is enabled.\nThe default value is \\fBgroup\\fR.\nThe allowed values are:\n.RS\n.RS\n.TP\n.B all\nterminates all jobs.\n.TP\n.B group\nis the default and does not change the behaviour of \\fBexitall\\fR.\n.TP\n.B stonewall\nterminates all currently running jobs across all groups and continues\nexecution with the next stonewalled group.\n.RE\n.RE\n.TP\n.BI exec_prerun \\fR=\\fPstr\nBefore running this job, issue the command specified through\n\\fBsystem\\fR\\|(3). Output is redirected in a file called `jobname.prerun.txt'.\n.TP\n.BI exec_postrun \\fR=\\fPstr\nAfter the job completes, issue the command specified though\n\\fBsystem\\fR\\|(3). Output is redirected in a file called `jobname.postrun.txt'.\n.TP\n.BI uid \\fR=\\fPint\nInstead of running as the invoking user, set the user ID to this value\nbefore the thread/process does any work.\n.TP\n.BI gid \\fR=\\fPint\nSet group ID, see \\fBuid\\fR.\n.SS \"Verification\"\n.TP\n.BI verify_only\nDo not perform specified workload, only verify data still matches previous\ninvocation of this workload. This option allows one to check data multiple\ntimes at a later date without overwriting it. This option makes sense only\nfor workloads that write data, and does not support workloads with the\n\\fBtime_based\\fR option set.\n.TP\n.BI do_verify \\fR=\\fPbool\nRun the verify phase after a write phase. Only valid if \\fBverify\\fR is\nset. Default: true.\n.TP\n.BI verify \\fR=\\fPstr\nIf writing to a file, fio can verify the file contents after each iteration\nof the job. Each verification method also implies verification of special\nheader, which is written to the beginning of each block. This header also\nincludes meta information, like offset of the block, block number, timestamp\nwhen block was written, etc. \\fBverify\\fR can be combined with\n\\fBverify_pattern\\fR option. The allowed values are:\n.RS\n.RS\n.TP\n.B md5\nUse an md5 sum of the data area and store it in the header of\neach block.\n.TP\n.B crc64\nUse an experimental crc64 sum of the data area and store it in the\nheader of each block.\n.TP\n.B crc32c\nUse a crc32c sum of the data area and store it in the header of\neach block. This will automatically use hardware acceleration\n(e.g. SSE4.2 on an x86 or CRC crypto extensions on ARM64) but will\nfall back to software crc32c if none is found. Generally the\nfastest checksum fio supports when hardware accelerated.\n.TP\n.B crc32c\\-intel\nSynonym for crc32c.\n.TP\n.B crc32\nUse a crc32 sum of the data area and store it in the header of each\nblock.\n.TP\n.B crc16\nUse a crc16 sum of the data area and store it in the header of each\nblock.\n.TP\n.B crc7\nUse a crc7 sum of the data area and store it in the header of each\nblock.\n.TP\n.B xxhash\nUse xxhash as the checksum function. Generally the fastest software\nchecksum that fio supports.\n.TP\n.B sha512\nUse sha512 as the checksum function.\n.TP\n.B sha256\nUse sha256 as the checksum function.\n.TP\n.B sha1\nUse optimized sha1 as the checksum function.\n.TP\n.B sha3\\-224\nUse optimized sha3\\-224 as the checksum function.\n.TP\n.B sha3\\-256\nUse optimized sha3\\-256 as the checksum function.\n.TP\n.B sha3\\-384\nUse optimized sha3\\-384 as the checksum function.\n.TP\n.B sha3\\-512\nUse optimized sha3\\-512 as the checksum function.\n.TP\n.B meta\nThis option is deprecated, since now meta information is included in\ngeneric verification header and meta verification happens by\ndefault. For detailed information see the description of the\n\\fBverify\\fR setting. This option is kept because of\ncompatibility's sake with old configurations. Do not use it.\n.TP\n.B pattern\nVerify a strict pattern. Normally fio includes a header with some\nbasic information and checksumming, but if this option is set, only\nthe specific pattern set with \\fBverify_pattern\\fR is verified.\n.TP\n.B null\nOnly pretend to verify. Useful for testing internals with\n`ioengine=null', not for much else.\n.RE\n.P\nThis option can be used for repeated burn\\-in tests of a system to make sure\nthat the written data is also correctly read back. If the data direction\ngiven is a read or random read, fio will assume that it should verify a\npreviously written file. If the data direction includes any form of write,\nthe verify will be of the newly written data.\n.P\nTo avoid false verification errors, do not use the norandommap option when\nverifying data with async I/O engines and I/O depths > 1.  Or use the\nnorandommap and the lfsr random generator together to avoid writing to the\nsame offset with multiple outstanding I/Os.\n.RE\n.TP\n.BI verify_offset \\fR=\\fPint\nSwap the verification header with data somewhere else in the block before\nwriting. It is swapped back before verifying.\n.TP\n.BI verify_interval \\fR=\\fPint\nWrite the verification header at a finer granularity than the\n\\fBblocksize\\fR. It will be written for chunks the size of\n\\fBverify_interval\\fR. \\fBblocksize\\fR should divide this evenly.\n.TP\n.BI verify_pattern \\fR=\\fPstr\nIf set, fio will fill the I/O buffers with this pattern. Fio defaults to\nfilling with totally random bytes, but sometimes it's interesting to fill\nwith a known pattern for I/O verification purposes. Depending on the width\nof the pattern, fio will fill 1/2/3/4 bytes of the buffer at the time (it can\nbe either a decimal or a hex number). The \\fBverify_pattern\\fR if larger than\na 32\\-bit quantity has to be a hex number that starts with either \"0x\" or\n\"0X\". Use with \\fBverify\\fR. Also, \\fBverify_pattern\\fR supports %o\nformat, which means that for each block offset will be written and then\nverified back, e.g.:\n.RS\n.RS\n.P\nverify_pattern=%o\n.RE\n.P\nOr use combination of everything:\n.RS\n.P\nverify_pattern=0xff%o\"abcd\"\\-12\n.RE\n.RE\n.TP\n.BI verify_fatal \\fR=\\fPbool\nNormally fio will keep checking the entire contents before quitting on a\nblock verification failure. If this option is set, fio will exit the job on\nthe first observed failure. Default: false.\n.TP\n.BI verify_dump \\fR=\\fPbool\nIf set, dump the contents of both the original data block and the data block\nwe read off disk to files. This allows later analysis to inspect just what\nkind of data corruption occurred. Off by default.\n.TP\n.BI verify_async \\fR=\\fPint\nFio will normally verify I/O inline from the submitting thread. This option\ntakes an integer describing how many async offload threads to create for I/O\nverification instead, causing fio to offload the duty of verifying I/O\ncontents to one or more separate threads. If using this offload option, even\nsync I/O engines can benefit from using an \\fBiodepth\\fR setting higher\nthan 1, as it allows them to have I/O in flight while verifies are running.\nDefaults to 0 async threads, i.e. verification is not asynchronous.\n.TP\n.BI verify_async_cpus \\fR=\\fPstr\nTell fio to set the given CPU affinity on the async I/O verification\nthreads. See \\fBcpus_allowed\\fR for the format used.\n.TP\n.BI verify_backlog \\fR=\\fPint\nFio will normally verify the written contents of a job that utilizes verify\nonce that job has completed. In other words, everything is written then\neverything is read back and verified. You may want to verify continually\ninstead for a variety of reasons. Fio stores the meta data associated with\nan I/O block in memory, so for large verify workloads, quite a bit of memory\nwould be used up holding this meta data. If this option is enabled, fio will\nwrite only N blocks before verifying these blocks.\n.TP\n.BI verify_backlog_batch \\fR=\\fPint\nControl how many blocks fio will verify if \\fBverify_backlog\\fR is\nset. If not set, will default to the value of \\fBverify_backlog\\fR\n(meaning the entire queue is read back and verified). If\n\\fBverify_backlog_batch\\fR is less than \\fBverify_backlog\\fR then not all\nblocks will be verified, if \\fBverify_backlog_batch\\fR is larger than\n\\fBverify_backlog\\fR, some blocks will be verified more than once.\n.TP\n.BI verify_state_save \\fR=\\fPbool\nWhen a job exits during the write phase of a verify workload, save its\ncurrent state. This allows fio to replay up until that point, if the verify\nstate is loaded for the verify read phase. The format of the filename is,\nroughly:\n.RS\n.RS\n.P\n<type>\\-<jobname>\\-<jobindex>\\-verify.state.\n.RE\n.P\n<type> is \"local\" for a local run, \"sock\" for a client/server socket\nconnection, and \"ip\" (192.168.0.1, for instance) for a networked\nclient/server connection. Defaults to true.\n.RE\n.TP\n.BI verify_state_load \\fR=\\fPbool\nIf a verify termination trigger was used, fio stores the current write state\nof each thread. This can be used at verification time so that fio knows how\nfar it should verify. Without this information, fio will run a full\nverification pass, according to the settings in the job file used. Default\nfalse.\n.TP\n.BI experimental_verify \\fR=\\fPbool\nEnable experimental verification. Standard verify records I/O metadata for\nlater use during the verification phase. Experimental verify instead resets the\nfile after the write phase and then replays I/Os for the verification phase.\n.TP\n.BI verify_write_sequence \\fR=\\fPbool\nVerify the header write sequence number. In a scenario with multiple jobs,\nverification of the write sequence number may fail. Disabling this option\nwill mean that write sequence number checking is skipped. Doing that can be\nuseful for testing atomic writes, as it means that checksum verification can\nstill be attempted. For when \\fBatomic\\fR is enabled, checksum verification\nis expected to succeed (while write sequence checking can still fail).\n.TP\n.BI trim_percentage \\fR=\\fPint\nNumber of verify blocks to discard/trim.\n.TP\n.BI trim_verify_zero \\fR=\\fPbool\nVerify that trim/discarded blocks are returned as zeros.\n.TP\n.BI trim_backlog \\fR=\\fPint\nVerify that trim/discarded blocks are returned as zeros.\n.TP\n.BI trim_backlog_batch \\fR=\\fPint\nTrim this number of I/O blocks.\n.SS \"Steady state\"\n.TP\n.BI steadystate \\fR=\\fPstr:float \"\\fR,\\fP ss\" \\fR=\\fPstr:float\nDefine the criterion and limit for assessing steady state performance. The\nfirst parameter designates the criterion whereas the second parameter sets\nthe threshold. When the criterion falls below the threshold for the\nspecified duration, the job will stop. For example, `iops_slope:0.1%' will\ndirect fio to terminate the job when the least squares regression slope\nfalls below 0.1% of the mean IOPS. If \\fBgroup_reporting\\fR is enabled\nthis will apply to all jobs in the group. Below is the list of available\nsteady state assessment criteria. All assessments are carried out using only\ndata from the rolling collection window. Threshold limits can be expressed\nas a fixed value or as a percentage of the mean in the collection window.\n.RS\n.P\nWhen using this feature, most jobs should include the \\fBtime_based\\fR\nand \\fBruntime\\fR options or the \\fBloops\\fR option so that fio does not\nstop running after it has covered the full size of the specified file(s)\nor device(s).\n.RS\n.RS\n.TP\n.B iops\nCollect IOPS data. Stop the job if all individual IOPS measurements\nare within the specified limit of the mean IOPS (e.g., `iops:2'\nmeans that all individual IOPS values must be within 2 of the mean,\nwhereas `iops:0.2%' means that all individual IOPS values must be\nwithin 0.2% of the mean IOPS to terminate the job).\n.TP\n.B iops_slope\nCollect IOPS data and calculate the least squares regression\nslope. Stop the job if the slope falls below the specified limit.\n.TP\n.B bw\nCollect bandwidth data. Stop the job if all individual bandwidth\nmeasurements are within the specified limit of the mean bandwidth.\n.TP\n.B bw_slope\nCollect bandwidth data and calculate the least squares regression\nslope. Stop the job if the slope falls below the specified limit.\n.RE\n.RE\n.TP\n.BI steadystate_duration \\fR=\\fPtime \"\\fR,\\fP ss_dur\" \\fR=\\fPtime\nA rolling window of this duration will be used to judge whether steady state\nhas been reached. Data will be collected every \\fBss_interval\\fR. The default\nis 0 which disables steady state detection. When the unit is omitted, the value\nis interpreted in seconds.\n.TP\n.BI steadystate_ramp_time \\fR=\\fPtime \"\\fR,\\fP ss_ramp\" \\fR=\\fPtime\nAllow the job to run for the specified duration before beginning data\ncollection for checking the steady state job termination criterion. The\ndefault is 0. When the unit is omitted, the value is interpreted in seconds.\n.TP\n.BI steadystate_check_interval \\fR=\\fPtime \"\\fR,\\fP ss_interval\" \\fR=\\fPtime\nThe values suring the rolling window will be collected with a period of this\nvalue. If \\fBss_interval\\fR is 30s and \\fBss_dur\\fR is 300s, 10 measurements\nwill be taken. Default is 1s but that might not converge, especially for slower\ndevices, so set this accordingly. When the unit is omitted, the value is\ninterpreted in seconds.\n.SS \"Measurements and reporting\"\n.TP\n.BI per_job_logs \\fR=\\fPbool\nIf set to true, fio generates bw/clat/iops logs with per job unique filenames.\nIf set to false, jobs with identical names will share a log filename. Note that\nwhen this option is set to false log files will be opened in append mode and if\nlog files already exist the previous contents will not be overwritten. Default:\ntrue.\n.TP\n.BI group_reporting\nIt may sometimes be interesting to display statistics for groups of jobs as\na whole instead of for each individual job. This is especially true if\n\\fBnumjobs\\fR is used; looking at individual thread/process output\nquickly becomes unwieldy. To see the final report per-group instead of\nper-job, use \\fBgroup_reporting\\fR. Jobs in a file will be part of the\nsame reporting group, unless if separated by a \\fBstonewall\\fR, or by\nusing \\fBnew_group\\fR.\n.RS\n.P\nNOTE: When \\fBgroup_reporting\\fR is used along with \\fBjson\\fR output, there\nare certain per-job properties which can be different between jobs but do not\nhave a natural group-level equivalent. Examples include \\fBkb_base\\fR,\n\\fBunit_base\\fR, \\fBsig_figs\\fR, \\fBthread_number\\fR, \\fBpid\\fR, and\n\\fBjob_start\\fR. For these properties, the values for the first job are\nrecorded for the group.\n.P\nAlso, options like \\fBpercentile_list\\fR and \\fBunified_rw_reporting\\fR should\nbe consistent among the jobs in a reporting group. Having options like these\nvary across the jobs in a reporting group is an unsupported configuration.\n.RE\n.TP\n.BI new_group\nStart a new reporting group. See: \\fBgroup_reporting\\fR. If not given,\nall jobs in a file will be part of the same reporting group, unless\nseparated by a \\fBstonewall\\fR.\n.TP\n.BI stats \\fR=\\fPbool\nBy default, fio collects and shows final output results for all jobs\nthat run. If this option is set to 0, then fio will ignore it in\nthe final stat output.\n.TP\n.BI write_bw_log \\fR=\\fPstr\nIf given, write a bandwidth log for this job. Can be used to store data of\nthe bandwidth of the jobs in their lifetime.\n.RS\n.P\nIf no str argument is given, the default filename of\n`jobname_type.x.log' is used. Even when the argument is given, fio\nwill still append the type of log. So if one specifies:\n.RS\n.P\nwrite_bw_log=foo\n.RE\n.P\nThe actual log name will be `foo_bw.x.log' where `x' is the index\nof the job (1..N, where N is the number of jobs). If\n\\fBper_job_logs\\fR is false, then the filename will not include the\n`.x` job index.\n.P\nThe included \\fBfio_generate_plots\\fR script uses gnuplot to turn these\ntext files into nice graphs. See the \\fBLOG FILE FORMATS\\fR section for how data is\nstructured within the file.\n.RE\n.TP\n.BI write_lat_log \\fR=\\fPstr\nSame as \\fBwrite_bw_log\\fR, except this option creates I/O\nsubmission (e.g., `name_slat.x.log'), completion (e.g.,\n`name_clat.x.log'), and total (e.g., `name_lat.x.log') latency\nfiles instead. See \\fBwrite_bw_log\\fR for details about the\nfilename format and the \\fBLOG FILE FORMATS\\fR section for how data is structured\nwithin the files.\n.TP\n.BI write_hist_log \\fR=\\fPstr\nSame as \\fBwrite_bw_log\\fR but writes an I/O completion latency\nhistogram file (e.g., `name_hist.x.log') instead. Note that this\nfile will be empty unless \\fBlog_hist_msec\\fR has also been set.\nSee \\fBwrite_bw_log\\fR for details about the filename format and\nthe \\fBLOG FILE FORMATS\\fR section for how data is structured\nwithin the file.\n.TP\n.BI write_iops_log \\fR=\\fPstr\nSame as \\fBwrite_bw_log\\fR, but writes an IOPS file (e.g.\n`name_iops.x.log`) instead. Because fio defaults to individual\nI/O logging, the value entry in the IOPS log will be 1 unless windowed\nlogging (see \\fBlog_avg_msec\\fR) has been enabled. See\n\\fBwrite_bw_log\\fR for details about the filename format and \\fBLOG\nFILE FORMATS\\fR for how data is structured within the file.\n.TP\n.BI log_entries \\fR=\\fPint\nBy default, fio will log an entry in the iops, latency, or bw log for\nevery I/O that completes. The initial number of I/O log entries is 1024.\nWhen the log entries are all used, new log entries are dynamically\nallocated.  This dynamic log entry allocation may negatively impact\ntime-related statistics such as I/O tail latencies (e.g. 99.9th percentile\ncompletion latency). This option allows specifying a larger initial\nnumber of log entries to avoid run-time allocation of new log entries,\nresulting in more precise time-related I/O statistics.\nAlso see \\fBlog_avg_msec\\fR as well. Defaults to 1024.\n.TP\n.BI log_avg_msec \\fR=\\fPint\nBy default, fio will log an entry in the iops, latency, or bw log for every I/O\nthat completes. When writing to the disk log, that can quickly grow to a very\nlarge size. Setting this option directs fio to instead record an average over\nthe specified duration for each log entry, reducing the resolution of the log.\nWhen the job completes, fio will flush any accumulated latency log data, so the\nfinal log interval may not match the value specified by this option and there\nmay even be duplicate timestamps. See \\fBlog_window_value\\fR as well. Defaults\nto 0, logging entries for each I/O. Also see \\fBLOG FILE FORMATS\\fR section.\n.TP\n.BI log_hist_msec \\fR=\\fPint\nSame as \\fBlog_avg_msec\\fR, but logs entries for completion latency\nhistograms. Computing latency percentiles from averages of intervals using\n\\fBlog_avg_msec\\fR is inaccurate. Setting this option makes fio log\nhistogram entries over the specified period of time, reducing log sizes for\nhigh IOPS devices while retaining percentile accuracy. See\n\\fBlog_hist_coarseness\\fR and \\fBwrite_hist_log\\fR as well.\nDefaults to 0, meaning histogram logging is disabled.\n.TP\n.BI log_hist_coarseness \\fR=\\fPint\nInteger ranging from 0 to 6, defining the coarseness of the resolution of\nthe histogram logs enabled with \\fBlog_hist_msec\\fR. For each increment\nin coarseness, fio outputs half as many bins. Defaults to 0, for which\nhistogram logs contain 1216 latency bins. See \\fBLOG FILE FORMATS\\fR section.\n.TP\n.BI log_window_value \\fR=\\fPstr \"\\fR,\\fP log_max_value\" \\fR=\\fPstr\nIf \\fBlog_avg_msec\\fR is set, fio by default logs the average over that window.\nThis option determines whether fio logs the average, maximum or both the\nvalues over the window. This only affects the latency logging, as both average\nand maximum values for iops or bw log will be same. Accepted values are:\n.RS\n.TP\n.B avg\nLog average value over the window. The default.\n.TP\n.B max\nLog maximum value in the window.\n.TP\n.B both\nLog both average and maximum value over the window.\n.TP\n.B 0\nBackward-compatible alias for \\fBavg\\fR.\n.TP\n.B 1\nBackward-compatible alias for \\fBmax\\fR.\n.RE\n.TP\n.BI log_offset \\fR=\\fPbool\nIf this is set, the iolog options will include the byte offset for the I/O\nentry as well as the other data values. Defaults to 0 meaning that\noffsets are not present in logs. Also see \\fBLOG FILE FORMATS\\fR section.\n.TP\n.BI log_prio \\fR=\\fPbool\nIf this is set, the `Command priority` field in \\fBLOG FILE FORMATS\\fR\nshows the priority value and the IO priority class of the command.\nOtherwise, the field shows if the command has the highest RT priority\nclass or not. Also see \\fBLOG FILE FORMATS\\fR section.\n.TP\n.BI log_issue_time \\fR=\\fPbool\nIf this is set, the iolog options will include the command issue time for the\nI/O entry as well as the other data values. Defaults to 0 meaning that command\nissue times are not present in logs. Also see \\fBLOG FILE FORMATS\\fR section.\nThis option shall be set together with \\fBwrite_lat_log\\fR and \\fBlog_offset\\fR.\n.TP\n.BI log_compression \\fR=\\fPint\nIf this is set, fio will compress the I/O logs as it goes, to keep the\nmemory footprint lower. When a log reaches the specified size, that chunk is\nremoved and compressed in the background. Given that I/O logs are fairly\nhighly compressible, this yields a nice memory savings for longer runs. The\ndownside is that the compression will consume some background CPU cycles, so\nit may impact the run. This, however, is also true if the logging ends up\nconsuming most of the system memory. So pick your poison. The I/O logs are\nsaved normally at the end of a run, by decompressing the chunks and storing\nthem in the specified log file. This feature depends on the availability of\nzlib.\n.TP\n.BI log_compression_cpus \\fR=\\fPstr\nDefine the set of CPUs that are allowed to handle online log compression for\nthe I/O jobs. This can provide better isolation between performance\nsensitive jobs, and background compression work. See \\fBcpus_allowed\\fR for\nthe format used.\n.TP\n.BI log_store_compressed \\fR=\\fPbool\nIf set, fio will store the log files in a compressed format. They can be\ndecompressed with fio, using the \\fB\\-\\-inflate\\-log\\fR command line\nparameter. The files will be stored with a `.fz' suffix.\n.TP\n.BI log_unix_epoch \\fR=\\fPbool\nBackward-compatible alias for \\fBlog_alternate_epoch\\fR.\n.TP\n.BI log_alternate_epoch \\fR=\\fPbool\nIf set, fio will log timestamps based on the epoch used by the clock specified\nin the \\fBlog_alternate_epoch_clock_id\\fR option, to the log files produced by\nenabling write_type_log for each log type, instead of the default zero-based\ntimestamps.\n.TP\n.BI log_alternate_epoch_clock_id \\fR=\\fPint\nSpecifies the clock_id to be used by clock_gettime to obtain the alternate\nepoch if \\fBlog_alternate_epoch\\fR is true. Otherwise has no effect. Default\nvalue is 0, or CLOCK_REALTIME.\n.TP\n.BI block_error_percentiles \\fR=\\fPbool\nIf set, record errors in trim block-sized units from writes and trims and\noutput a histogram of how many trims it took to get to errors, and what kind\nof error was encountered.\n.TP\n.BI bwavgtime \\fR=\\fPint\nAverage the calculated bandwidth over the given time. Value is specified in\nmilliseconds. If the job also does bandwidth logging through\n\\fBwrite_bw_log\\fR, then the minimum of this option and\n\\fBlog_avg_msec\\fR will be used. Default: 500ms.\n.TP\n.BI iopsavgtime \\fR=\\fPint\nAverage the calculated IOPS over the given time. Value is specified in\nmilliseconds. If the job also does IOPS logging through\n\\fBwrite_iops_log\\fR, then the minimum of this option and\n\\fBlog_avg_msec\\fR will be used. Default: 500ms.\n.TP\n.BI disk_util \\fR=\\fPbool\nGenerate disk utilization statistics, if the platform supports it.\nDefault: true.\n.TP\n.BI disable_lat \\fR=\\fPbool\nDisable measurements of total latency numbers. Useful only for cutting back\nthe number of calls to \\fBgettimeofday\\fR\\|(2), as that does impact\nperformance at really high IOPS rates. Note that to really get rid of a\nlarge amount of these calls, this option must be used with\n\\fBdisable_slat\\fR and \\fBdisable_bw_measurement\\fR as well.\n.TP\n.BI disable_clat \\fR=\\fPbool\nDisable measurements of completion latency numbers. See\n\\fBdisable_lat\\fR.\n.TP\n.BI disable_slat \\fR=\\fPbool\nDisable measurements of submission latency numbers. See\n\\fBdisable_lat\\fR.\n.TP\n.BI disable_bw_measurement \\fR=\\fPbool \"\\fR,\\fP disable_bw\" \\fR=\\fPbool\nDisable measurements of throughput/bandwidth numbers. See\n\\fBdisable_lat\\fR.\n.TP\n.BI slat_percentiles \\fR=\\fPbool\nReport submission latency percentiles. Submission latency is not recorded\nfor synchronous ioengines.\n.TP\n.BI clat_percentiles \\fR=\\fPbool\nReport completion latency percentiles.\n.TP\n.BI lat_percentiles \\fR=\\fPbool\nReport total latency percentiles. Total latency is the sum of submission\nlatency and completion latency.\n.TP\n.BI percentile_list \\fR=\\fPfloat_list\nOverwrite the default list of percentiles for latencies and the\nblock error histogram. Each number is a floating point number in the range\n(0,100], and the maximum length of the list is 20. Use ':' to separate the\nnumbers. For example, `\\-\\-percentile_list=99.5:99.9' will cause fio to\nreport the latency durations below which 99.5% and 99.9% of the observed\nlatencies fell, respectively.\n.TP\n.BI significant_figures \\fR=\\fPint\nIf using \\fB\\-\\-output\\-format\\fR of `normal', set the significant figures\nto this value. Higher values will yield more precise IOPS and throughput\nunits, while lower values will round. Requires a minimum value of 1 and a\nmaximum value of 10. Defaults to 4.\n.SS \"Error handling\"\n.TP\n.BI exitall_on_error\nWhen one job finishes in error, terminate the rest. The default is to wait\nfor each job to finish.\n.TP\n.BI continue_on_error \\fR=\\fPstr\nNormally fio will exit the job on the first observed failure. If this option\nis set, fio will continue the job when there is a 'non-fatal error' (EIO or\nEILSEQ) until the runtime is exceeded or the I/O size specified is\ncompleted. If this option is used, there are two more stats that are\nappended, the total error count and the first error. The error field given\nin the stats is the first error that was hit during the run.\n.RS\n.P\nNote: a write error from the device may go unnoticed by fio when using buffered\nIO, as the write() (or similar) system call merely dirties the kernel pages,\nunless `sync' or `direct' is used. Device IO errors occur when the dirty data is\nactually written out to disk. If fully sync writes aren't desirable, `fsync' or\n`fdatasync' can be used as well. This is specific to writes, as reads are always\nsynchronous.\n.RS\n.P\nThe allowed values are:\n.RS\n.RS\n.TP\n.B none\nExit on any I/O or verify errors.\n.TP\n.B read\nContinue on read errors, exit on all others.\n.TP\n.B write\nContinue on write errors, exit on all others.\n.TP\n.B io\nContinue on any I/O error, exit on all others.\n.TP\n.B verify\nContinue on verify errors, exit on all others.\n.TP\n.B all\nContinue on all errors.\n.TP\n.B 0\nBackward-compatible alias for 'none'.\n.TP\n.B 1\nBackward-compatible alias for 'all'.\n.RE\n.RE\n.TP\n.BI ignore_error \\fR=\\fPstr\nSometimes you want to ignore some errors during test in that case you can\nspecify error list for each error type, instead of only being able to\nignore the default 'non-fatal error' using \\fBcontinue_on_error\\fR.\n`ignore_error=READ_ERR_LIST,WRITE_ERR_LIST,VERIFY_ERR_LIST' errors for\ngiven error type is separated with ':'. Error may be symbol ('ENOSPC', 'ENOMEM')\nor integer. Example:\n.RS\n.RS\n.P\nignore_error=EAGAIN,ENOSPC:122\n.RE\n.P\nThis option will ignore EAGAIN from READ, and ENOSPC and 122(EDQUOT) from\nWRITE. This option works by overriding \\fBcontinue_on_error\\fR with\nthe list of errors for each error type if any.\n.RE\n.TP\n.BI error_dump \\fR=\\fPbool\nIf set dump every error even if it is non fatal, true by default. If\ndisabled only fatal error will be dumped.\n.SS \"Running predefined workloads\"\nFio includes predefined profiles that mimic the I/O workloads generated by\nother tools.\n.TP\n.BI profile \\fR=\\fPstr\nThe predefined workload to run. Current profiles are:\n.RS\n.RS\n.TP\n.B tiobench\nThreaded I/O bench (tiotest/tiobench) like workload.\n.TP\n.B act\nAerospike Certification Tool (ACT) like workload.\n.RE\n.RE\n.P\nTo view a profile's additional options use \\fB\\-\\-cmdhelp\\fR after specifying\nthe profile. For example:\n.RS\n.TP\n$ fio \\-\\-profile=act \\-\\-cmdhelp\n.RE\n.SS \"Act profile options\"\n.TP\n.BI device\\-names \\fR=\\fPstr\nDevices to use.\n.TP\n.BI load \\fR=\\fPint\nACT load multiplier. Default: 1.\n.TP\n.BI test\\-duration\\fR=\\fPtime\nHow long the entire test takes to run. When the unit is omitted, the value\nis given in seconds. Default: 24h.\n.TP\n.BI threads\\-per\\-queue\\fR=\\fPint\nNumber of read I/O threads per device. Default: 8.\n.TP\n.BI read\\-req\\-num\\-512\\-blocks\\fR=\\fPint\nNumber of 512B blocks to read at the time. Default: 3.\n.TP\n.BI large\\-block\\-op\\-kbytes\\fR=\\fPint\nSize of large block ops in KiB (writes). Default: 131072.\n.TP\n.BI prep\nSet to run ACT prep phase.\n.SS \"Tiobench profile options\"\n.TP\n.BI size\\fR=\\fPstr\nSize in MiB.\n.TP\n.BI block\\fR=\\fPint\nBlock size in bytes. Default: 4096.\n.TP\n.BI numruns\\fR=\\fPint\nNumber of runs.\n.TP\n.BI dir\\fR=\\fPstr\nTest directory.\n.TP\n.BI threads\\fR=\\fPint\nNumber of threads.\n.SH OUTPUT\nFio spits out a lot of output. While running, fio will display the status of the\njobs created. An example of that would be:\n.P\n.nf\n\t\tJobs: 1 (f=1): [_(1),M(1)][24.8%][r=20.5MiB/s,w=23.5MiB/s][r=82,w=94 IOPS][eta 01m:31s]\n.fi\n.P\nThe characters inside the first set of square brackets denote the current status of\neach thread. The first character is the first job defined in the job file, and so\nforth. The possible values (in typical life cycle order) are:\n.RS\n.TP\n.PD 0\n.B P\nThread setup, but not started.\n.TP\n.B C\nThread created.\n.TP\n.B I\nThread initialized, waiting or generating necessary data.\n.TP\n.B p\nThread running pre-reading file(s).\n.TP\n.B /\nThread is in ramp period.\n.TP\n.B R\nRunning, doing sequential reads.\n.TP\n.B r\nRunning, doing random reads.\n.TP\n.B W\nRunning, doing sequential writes.\n.TP\n.B w\nRunning, doing random writes.\n.TP\n.B M\nRunning, doing mixed sequential reads/writes.\n.TP\n.B m\nRunning, doing mixed random reads/writes.\n.TP\n.B D\nRunning, doing sequential trims.\n.TP\n.B d\nRunning, doing random trims.\n.TP\n.B F\nRunning, currently waiting for \\fBfsync\\fR\\|(2).\n.TP\n.B V\nRunning, doing verification of written data.\n.TP\n.B f\nThread finishing.\n.TP\n.B E\nThread exited, not reaped by main thread yet.\n.TP\n.B \\-\nThread reaped.\n.TP\n.B X\nThread reaped, exited with an error.\n.TP\n.B K\nThread reaped, exited due to signal.\n.PD\n.RE\n.P\nFio will condense the thread string as not to take up more space on the command\nline than needed. For instance, if you have 10 readers and 10 writers running,\nthe output would look like this:\n.P\n.nf\n\t\tJobs: 20 (f=20): [R(10),W(10)][4.0%][r=20.5MiB/s,w=23.5MiB/s][r=82,w=94 IOPS][eta 57m:36s]\n.fi\n.P\nNote that the status string is displayed in order, so it's possible to tell which of\nthe jobs are currently doing what. In the example above this means that jobs 1\\-\\-10\nare readers and 11\\-\\-20 are writers.\n.P\nThe other values are fairly self explanatory \\-\\- number of threads currently\nrunning and doing I/O, the number of currently open files (f=), the estimated\ncompletion percentage, the rate of I/O since last check (read speed listed first,\nthen write speed and optionally trim speed) in terms of bandwidth and IOPS,\nand time to completion for the current running group. It's impossible to estimate\nruntime of the following groups (if any).\n.P\nWhen fio is done (or interrupted by Ctrl\\-C), it will show the data for\neach thread, group of threads, and disks in that order. For each overall thread (or\ngroup) the output looks like:\n.P\n.nf\n\t\tClient1: (groupid=0, jobs=1): err= 0: pid=16109: Sat Jun 24 12:07:54 2017\n\t\t  write: IOPS=88, BW=623KiB/s (638kB/s)(30.4MiB/50032msec)\n\t\t    slat (nsec): min=500, max=145500, avg=8318.00, stdev=4781.50\n\t\t    clat (usec): min=170, max=78367, avg=4019.02, stdev=8293.31\n\t\t     lat (usec): min=174, max=78375, avg=4027.34, stdev=8291.79\n\t\t    clat percentiles (usec):\n\t\t     |  1.00th=[  302],  5.00th=[  326], 10.00th=[  343], 20.00th=[  363],\n\t\t     | 30.00th=[  392], 40.00th=[  404], 50.00th=[  416], 60.00th=[  445],\n\t\t     | 70.00th=[  816], 80.00th=[ 6718], 90.00th=[12911], 95.00th=[21627],\n\t\t     | 99.00th=[43779], 99.50th=[51643], 99.90th=[68682], 99.95th=[72877],\n\t\t     | 99.99th=[78119]\n\t\t   bw (  KiB/s): min=  532, max=  686, per=0.10%, avg=622.87, stdev=24.82, samples=  100\n\t\t   iops        : min=   76, max=   98, avg=88.98, stdev= 3.54, samples=  100\n\t\t  lat (usec)   : 250=0.04%, 500=64.11%, 750=4.81%, 1000=2.79%\n\t\t  lat (msec)   : 2=4.16%, 4=1.84%, 10=4.90%, 20=11.33%, 50=5.37%\n\t\t  lat (msec)   : 100=0.65%\n\t\t  cpu          : usr=0.27%, sys=0.18%, ctx=12072, majf=0, minf=21\n\t\t  IO depths    : 1=85.0%, 2=13.1%, 4=1.8%, 8=0.1%, 16=0.0%, 32=0.0%, >=64=0.0%\n\t\t     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%\n\t\t     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%\n\t\t     issued rwt: total=0,4450,0, short=0,0,0, dropped=0,0,0\n\t\t     latency   : target=0, window=0, percentile=100.00%, depth=8\n.fi\n.P\nThe job name (or first job's name when using \\fBgroup_reporting\\fR) is printed,\nalong with the group id, count of jobs being aggregated, last error id seen (which\nis 0 when there are no errors), pid/tid of that thread and the time the job/group\ncompleted. Below are the I/O statistics for each data direction performed (showing\nwrites in the example above). In the order listed, they denote:\n.RS\n.TP\n.B read/write/trim\nThe string before the colon shows the I/O direction the statistics\nare for. \\fIIOPS\\fR is the average I/Os performed per second. \\fIBW\\fR\nis the average bandwidth rate shown as: value in power of 2 format\n(value in power of 10 format). The last two values show: (total\nI/O performed in power of 2 format / \\fIruntime\\fR of that thread).\n.TP\n.B slat\nSubmission latency (\\fImin\\fR being the minimum, \\fImax\\fR being the\nmaximum, \\fIavg\\fR being the average, \\fIstdev\\fR being the standard\ndeviation). This is the time it took to submit the I/O. For\nsync I/O this row is not displayed as the slat is really the\ncompletion latency (since queue/complete is one operation there).\nThis value can be in nanoseconds, microseconds or milliseconds \\-\\-\\-\nfio will choose the most appropriate base and print that (in the\nexample above nanoseconds was the best scale). Note: in \\fB\\-\\-minimal\\fR mode\nlatencies are always expressed in microseconds.\n.TP\n.B clat\nCompletion latency. Same names as slat, this denotes the time from\nsubmission to completion of the I/O pieces. For sync I/O, clat will\nusually be equal (or very close) to 0, as the time from submit to\ncomplete is basically just CPU time (I/O has already been done, see slat\nexplanation).\n\nFor file and directory operation engines, \\fBclat\\fP denotes the time\nto complete one file or directory operation.\n.RS\n.TP\n\\fBfilecreate engine\\fP:\\tthe time cost to create a new file\n.TP\n\\fBfilestat engine\\fP:\\tthe time cost to look up an existing file\n.TP\n\\fBfiledelete engine\\fP:\\tthe time cost to delete a file\n.TP\n\\fBdircreate engine\\fP:\\tthe time cost to create a new directory\n.TP\n\\fBdirstat engine\\fP:\\tthe time cost to look up an existing directory\n.TP\n\\fBdirdelete engine\\fP:\\tthe time cost to delete a directory\n.TP\n.RE\n.TP\n.B lat\nTotal latency. Same names as slat and clat, this denotes the time from\nwhen fio created the I/O unit to completion of the I/O operation.\n.TP\n.B bw\nBandwidth statistics based on measurements from discrete intervals. Fio\ncontinuosly monitors bytes transferred and I/O operations completed. By default\nfio calculates bandwidth in each half-second interval (see \\fBbwavgtime\\fR)\nand reports descriptive statistics for the measurements here. Same names as the\nxlat stats, but also includes the number of samples taken (\\fIsamples\\fR) and an\napproximate percentage of total aggregate bandwidth this thread received in its\ngroup (\\fIper\\fR). This last value is only really useful if the threads in this\ngroup are on the same disk, since they are then competing for disk access.\n\nFor file and directory operation engines, \\fBbw\\fR is meaningless.\n.TP\n.B iops\nIOPS statistics based on measurements from discrete intervals.\nFor details see the description for \\fBbw\\fR above. See\n\\fBiopsavgtime\\fR to control the duration of the intervals.\nSame values reported here as for \\fBbw\\fR except for percentage.\n\nFor file and directory operation engines, \\fBiops\\fP is the most\nfundamental index to denote the performance.\nIt means how many files or directories can be operated per second.\n.RS\n.TP\n\\fBfilecreate engine\\fP:\\tnumber of files can be created per second\n.TP\n\\fBfilestat engine\\fP:\\tnumber of files can be looked up per second\n.TP\n\\fBfiledelete engine\\fP:\\tnumber of files can be deleted per second\n.TP\n\\fBdircreate engine\\fP:\\tnumber of directories can be created per second\n.TP\n\\fBdirstat engine\\fP:\\tnumber of directories can be looked up per second\n.TP\n\\fBdirdelete engine\\fP:\\tnumber of directories can be deleted per second\n.TP\n.RE\n.TP\n.B lat (nsec/usec/msec)\nThe distribution of I/O completion latencies. This is the time from when\nI/O leaves fio and when it gets completed. Unlike the separate\nread/write/trim sections above, the data here and in the remaining\nsections apply to all I/Os for the reporting group. 250=0.04% means that\n0.04% of the I/Os completed in under 250us. 500=64.11% means that 64.11%\nof the I/Os required 250 to 499us for completion.\n.TP\n.B cpu\nCPU usage. User and system time, along with the number of context\nswitches this thread went through, usage of system and user time, and\nfinally the number of major and minor page faults. The CPU utilization\nnumbers are averages for the jobs in that reporting group, while the\ncontext and fault counters are summed.\n.TP\n.B IO depths\nThe distribution of I/O depths over the job lifetime. The numbers are\ndivided into powers of 2 and each entry covers depths from that value\nup to those that are lower than the next entry \\-\\- e.g., 16= covers\ndepths from 16 to 31. Note that the range covered by a depth\ndistribution entry can be different to the range covered by the\nequivalent \\fBsubmit\\fR/\\fBcomplete\\fR distribution entry.\n.TP\n.B IO submit\nHow many pieces of I/O were submitting in a single submit call. Each\nentry denotes that amount and below, until the previous entry \\-\\- e.g.,\n16=100% means that we submitted anywhere between 9 to 16 I/Os per submit\ncall. Note that the range covered by a \\fBsubmit\\fR distribution entry can\nbe different to the range covered by the equivalent depth distribution\nentry.\n.TP\n.B IO complete\nLike the above \\fBsubmit\\fR number, but for completions instead.\n.TP\n.B IO issued rwt\nThe number of \\fBread/write/trim\\fR requests issued, and how many of them were\nshort or dropped.\n.TP\n.B IO latency\nThese values are for \\fBlatency_target\\fR and related options. When\nthese options are engaged, this section describes the I/O depth required\nto meet the specified latency target.\n.RE\n.P\nAfter each client has been listed, the group statistics are printed. They\nwill look like this:\n.P\n.nf\n\t\tRun status group 0 (all jobs):\n\t\t   READ: bw=20.9MiB/s (21.9MB/s), 10.4MiB/s\\-10.8MiB/s (10.9MB/s\\-11.3MB/s), io=64.0MiB (67.1MB), run=2973\\-3069msec\n\t\t  WRITE: bw=1231KiB/s (1261kB/s), 616KiB/s\\-621KiB/s (630kB/s\\-636kB/s), io=64.0MiB (67.1MB), run=52747\\-53223msec\n.fi\n.P\nFor each data direction it prints:\n.RS\n.TP\n.B bw\nAggregate bandwidth of threads in this group followed by the\nminimum and maximum bandwidth of all the threads in this group.\nValues outside of brackets are power-of-2 format and those\nwithin are the equivalent value in a power-of-10 format.\n.TP\n.B io\nAggregate I/O performed of all threads in this group. The\nformat is the same as \\fBbw\\fR.\n.TP\n.B run\nThe smallest and longest runtimes of the threads in this group.\n.RE\n.P\nAnd finally, the disk statistics are printed. This is Linux specific.\nThey will look like this:\n.P\n.nf\n\t\t  Disk stats (read/write):\n\t\t    sda: ios=16398/16511, sectors=32321/65472, merge=30/162, ticks=6853/819634, in_queue=826487, util=100.00%\n.fi\n.P\nEach value is printed for both reads and writes, with reads first. The\nnumbers denote:\n.RS\n.TP\n.B ios\nNumber of I/Os performed by all groups.\n.TP\n.B merge\nNumber of merges performed by the I/O scheduler.\n.TP\n.B ticks\nNumber of ticks we kept the disk busy.\n.TP\n.B in_queue\nTotal time spent in the disk queue.\n.TP\n.B util\nThe disk utilization. A value of 100% means we kept the disk\nbusy constantly, 50% would be a disk idling half of the time.\n.RE\n.P\nIt is also possible to get fio to dump the current output while it is running,\nwithout terminating the job. To do that, send fio the USR1 signal. You can\nalso get regularly timed dumps by using the \\fB\\-\\-status\\-interval\\fR\nparameter, or by creating a file in `/tmp' named\n`fio\\-dump\\-status'. If fio sees this file, it will unlink it and dump the\ncurrent output status.\n.SH TERSE OUTPUT\nFor scripted usage where you typically want to generate tables or graphs of the\nresults, fio can output the results in a semicolon separated format. The format\nis one long line of values, such as:\n.P\n.nf\n\t\t2;card0;0;0;7139336;121836;60004;1;10109;27.932460;116.933948;220;126861;3495.446807;1085.368601;226;126864;3523.635629;1089.012448;24063;99944;50.275485%;59818.274627;5540.657370;7155060;122104;60004;1;8338;29.086342;117.839068;388;128077;5032.488518;1234.785715;391;128085;5061.839412;1236.909129;23436;100928;50.287926%;59964.832030;5644.844189;14.595833%;19.394167%;123706;0;7313;0.1%;0.1%;0.1%;0.1%;0.1%;0.1%;100.0%;0.00%;0.00%;0.00%;0.00%;0.00%;0.00%;0.01%;0.02%;0.05%;0.16%;6.04%;40.40%;52.68%;0.64%;0.01%;0.00%;0.01%;0.00%;0.00%;0.00%;0.00%;0.00%\n\t\tA description of this job goes here.\n.fi\n.P\nThe job description (if provided) follows on a second line for terse v2.\nIt appears on the same line for other terse versions.\n.P\nTo enable terse output, use the \\fB\\-\\-minimal\\fR or\n`\\-\\-output\\-format=terse' command line options. The\nfirst value is the version of the terse output format. If the output has to be\nchanged for some reason, this number will be incremented by 1 to signify that\nchange.\n.P\nSplit up, the format is as follows (comments in brackets denote when a\nfield was introduced or whether it's specific to some terse version):\n.P\n.nf\n\t\t\tterse version, fio version [v3], jobname, groupid, error\n.fi\n.RS\n.P\n.B\nREAD status:\n.RE\n.P\n.nf\n\t\t\tTotal IO (KiB), bandwidth (KiB/sec), IOPS, runtime (msec)\n\t\t\tSubmission latency: min, max, mean, stdev (usec)\n\t\t\tCompletion latency: min, max, mean, stdev (usec)\n\t\t\tCompletion latency percentiles: 20 fields (see below)\n\t\t\tTotal latency: min, max, mean, stdev (usec)\n\t\t\tBw (KiB/s): min, max, aggregate percentage of total, mean, stdev, number of samples [v5]\n\t\t\tIOPS [v5]: min, max, mean, stdev, number of samples\n.fi\n.RS\n.P\n.B\nWRITE status:\n.RE\n.P\n.nf\n\t\t\tTotal IO (KiB), bandwidth (KiB/sec), IOPS, runtime (msec)\n\t\t\tSubmission latency: min, max, mean, stdev (usec)\n\t\t\tCompletion latency: min, max, mean, stdev (usec)\n\t\t\tCompletion latency percentiles: 20 fields (see below)\n\t\t\tTotal latency: min, max, mean, stdev (usec)\n\t\t\tBw (KiB/s): min, max, aggregate percentage of total, mean, stdev, number of samples [v5]\n\t\t\tIOPS [v5]: min, max, mean, stdev, number of samples\n.fi\n.RS\n.P\n.B\nTRIM status [all but version 3]:\n.RE\n.P\n.nf\n\t\t\tFields are similar to \\fBREAD/WRITE\\fR status.\n.fi\n.RS\n.P\n.B\nCPU usage:\n.RE\n.P\n.nf\n\t\t\tuser, system, context switches, major faults, minor faults\n.fi\n.RS\n.P\n.B\nI/O depths:\n.RE\n.P\n.nf\n\t\t\t<=1, 2, 4, 8, 16, 32, >=64\n.fi\n.RS\n.P\n.B\nI/O latencies microseconds:\n.RE\n.P\n.nf\n\t\t\t<=2, 4, 10, 20, 50, 100, 250, 500, 750, 1000\n.fi\n.RS\n.P\n.B\nI/O latencies milliseconds:\n.RE\n.P\n.nf\n\t\t\t<=2, 4, 10, 20, 50, 100, 250, 500, 750, 1000, 2000, >=2000\n.fi\n.RS\n.P\n.B\nDisk utilization [v3]:\n.RE\n.P\n.nf\n\t\t\tdisk name, read ios, write ios, read merges, write merges, read ticks, write ticks, time spent in queue, disk utilization percentage\n.fi\n.RS\n.P\n.B\nAdditional Info (dependent on continue_on_error, default off):\n.RE\n.P\n.nf\n\t\t\ttotal # errors, first error code\n.fi\n.RS\n.P\n.B\nAdditional Info (dependent on description being set):\n.RE\n.P\n.nf\n\t\t\tText description\n.fi\n.P\nCompletion latency percentiles can be a grouping of up to 20 sets, so for the\nterse output fio writes all of them. Each field will look like this:\n.P\n.nf\n\t\t1.00%=6112\n.fi\n.P\nwhich is the Xth percentile, and the `usec' latency associated with it.\n.P\nFor \\fBDisk utilization\\fR, all disks used by fio are shown. So for each disk there\nwill be a disk utilization section.\n.P\nBelow is a single line containing short names for each of the fields in the\nminimal output v3, separated by semicolons:\n.P\n.nf\n\t\tterse_version_3;fio_version;jobname;groupid;error;read_kb;read_bandwidth_kb;read_iops;read_runtime_ms;read_slat_min_us;read_slat_max_us;read_slat_mean_us;read_slat_dev_us;read_clat_min_us;read_clat_max_us;read_clat_mean_us;read_clat_dev_us;read_clat_pct01;read_clat_pct02;read_clat_pct03;read_clat_pct04;read_clat_pct05;read_clat_pct06;read_clat_pct07;read_clat_pct08;read_clat_pct09;read_clat_pct10;read_clat_pct11;read_clat_pct12;read_clat_pct13;read_clat_pct14;read_clat_pct15;read_clat_pct16;read_clat_pct17;read_clat_pct18;read_clat_pct19;read_clat_pct20;read_tlat_min_us;read_lat_max_us;read_lat_mean_us;read_lat_dev_us;read_bw_min_kb;read_bw_max_kb;read_bw_agg_pct;read_bw_mean_kb;read_bw_dev_kb;write_kb;write_bandwidth_kb;write_iops;write_runtime_ms;write_slat_min_us;write_slat_max_us;write_slat_mean_us;write_slat_dev_us;write_clat_min_us;write_clat_max_us;write_clat_mean_us;write_clat_dev_us;write_clat_pct01;write_clat_pct02;write_clat_pct03;write_clat_pct04;write_clat_pct05;write_clat_pct06;write_clat_pct07;write_clat_pct08;write_clat_pct09;write_clat_pct10;write_clat_pct11;write_clat_pct12;write_clat_pct13;write_clat_pct14;write_clat_pct15;write_clat_pct16;write_clat_pct17;write_clat_pct18;write_clat_pct19;write_clat_pct20;write_tlat_min_us;write_lat_max_us;write_lat_mean_us;write_lat_dev_us;write_bw_min_kb;write_bw_max_kb;write_bw_agg_pct;write_bw_mean_kb;write_bw_dev_kb;cpu_user;cpu_sys;cpu_csw;cpu_mjf;cpu_minf;iodepth_1;iodepth_2;iodepth_4;iodepth_8;iodepth_16;iodepth_32;iodepth_64;lat_2us;lat_4us;lat_10us;lat_20us;lat_50us;lat_100us;lat_250us;lat_500us;lat_750us;lat_1000us;lat_2ms;lat_4ms;lat_10ms;lat_20ms;lat_50ms;lat_100ms;lat_250ms;lat_500ms;lat_750ms;lat_1000ms;lat_2000ms;lat_over_2000ms;disk_name;disk_read_iops;disk_write_iops;disk_read_merges;disk_write_merges;disk_read_ticks;write_ticks;disk_queue_time;disk_util\n.fi\n.P\nIn client/server mode terse output differs from what appears when jobs are run\nlocally. Disk utilization data is omitted from the standard terse output and\nfor v3 and later appears on its own separate line at the end of each terse\nreporting cycle.\n.SH JSON OUTPUT\nThe \\fBjson\\fR output format is intended to be both human readable and convenient\nfor automated parsing. For the most part its sections mirror those of the\n\\fBnormal\\fR output. The \\fBruntime\\fR value is reported in msec and the \\fBbw\\fR value is\nreported in 1024 bytes per second units.\n.fi\n.SH JSON+ OUTPUT\nThe \\fBjson+\\fR output format is identical to the \\fBjson\\fR output format except that it\nadds a full dump of the completion latency bins. Each \\fBbins\\fR object contains a\nset of (key, value) pairs where keys are latency durations and values count how\nmany I/Os had completion latencies of the corresponding duration. For example,\nconsider:\n.RS\n.P\n\"bins\" : { \"87552\" : 1, \"89600\" : 1, \"94720\" : 1, \"96768\" : 1, \"97792\" : 1, \"99840\" : 1, \"100864\" : 2, \"103936\" : 6, \"104960\" : 534, \"105984\" : 5995, \"107008\" : 7529, ... }\n.RE\n.P\nThis data indicates that one I/O required 87,552ns to complete, two I/Os required\n100,864ns to complete, and 7529 I/Os required 107,008ns to complete.\n.P\nAlso included with fio is a Python script \\fBfio_jsonplus_clat2csv\\fR that takes\njson+ output and generates CSV-formatted latency data suitable for plotting.\n.P\nThe latency durations actually represent the midpoints of latency intervals.\nFor details refer to `stat.h' in the fio source.\n.SH TRACE FILE FORMAT\nThere are two trace file format that you can encounter. The older (v1) format is\nunsupported since version 1.20\\-rc3 (March 2008). It will still be described\nbelow in case that you get an old trace and want to understand it.\n.P\nIn any case the trace is a simple text file with a single action per line.\n.TP\n.B Trace file format v1\nEach line represents a single I/O action in the following format:\n.RS\n.RS\n.P\nrw, offset, length\n.RE\n.P\nwhere `rw=0/1' for read/write, and the `offset' and `length' entries being in bytes.\n.P\nThis format is not supported in fio versions >= 1.20\\-rc3.\n.RE\n.TP\n.B Trace file format v2\nThe second version of the trace file format was added in fio version 1.17. It\nallows one to access more than one file per trace and has a bigger set of possible\nfile actions.\n.RS\n.P\nThe first line of the trace file has to be:\n.RS\n.P\n\"fio version 2 iolog\"\n.RE\n.P\nFollowing this can be lines in two different formats, which are described below.\n.P\n.B\nThe file management format:\n.RS\nfilename action\n.P\nThe `filename' is given as an absolute path. The `action' can be one of these:\n.RS\n.TP\n.B add\nAdd the given `filename' to the trace.\n.TP\n.B open\nOpen the file with the given `filename'. The `filename' has to have\nbeen added with the \\fBadd\\fR action before.\n.TP\n.B close\nClose the file with the given `filename'. The file has to have been\n\\fBopen\\fRed before.\n.RE\n.RE\n.P\n.B\nThe file I/O action format:\n.RS\nfilename action offset length\n.P\nThe `filename' is given as an absolute path, and has to have been \\fBadd\\fRed and\n\\fBopen\\fRed before it can be used with this format. The `offset' and `length' are\ngiven in bytes. The `action' can be one of these:\n.RS\n.TP\n.B wait\nWait for `offset' microseconds. Everything below 100 is discarded.\nThe time is relative to the previous `wait' statement. Note that action `wait`\nis not allowed as of version 3, as the same behavior can be achieved using\ntimestamps.\n.TP\n.B read\nRead `length' bytes beginning from `offset'.\n.TP\n.B write\nWrite `length' bytes beginning from `offset'.\n.TP\n.B sync\n\\fBfsync\\fR\\|(2) the file.\n.TP\n.B datasync\n\\fBfdatasync\\fR\\|(2) the file.\n.TP\n.B trim\nTrim the given file from the given `offset' for `length' bytes.\n.RE\n.RE\n.RE\n.TP\n.B Trace file format v3\nThe third version of the trace file format was added in fio version 3.31. It\nforces each action to have a timestamp associated with it.\n.RS\n.P\nThe first line of the trace file has to be:\n.RS\n.P\n\"fio version 3 iolog\"\n.RE\n.P\nFollowing this can be lines in two different formats, which are described below.\n.P\n.B\nThe file management format:\n.RS\ntimestamp filename action\n.P\n.RE\n.B\nThe file I/O action format:\n.RS\ntimestamp filename action offset length\n.P\nThe `timestamp` is relative to the beginning of the run (ie starts at 0). The\n`filename`, `action`, `offset` and `length`  are identical to version 2, except\nthat version 3 does not allow the `wait` action.\n.RE\n.RE\n.SH I/O REPLAY \\- MERGING TRACES\nColocation is a common practice used to get the most out of a machine.\nKnowing which workloads play nicely with each other and which ones don't is\na much harder task. While fio can replay workloads concurrently via multiple\njobs, it leaves some variability up to the scheduler making results harder to\nreproduce. Merging is a way to make the order of events consistent.\n.P\nMerging is integrated into I/O replay and done when a \\fBmerge_blktrace_file\\fR\nis specified. The list of files passed to \\fBread_iolog\\fR go through the merge\nprocess and output a single file stored to the specified file. The output file is\npassed on as if it were the only file passed to \\fBread_iolog\\fR. An example would\nlook like:\n.RS\n.P\n$ fio \\-\\-read_iolog=\"<file1>:<file2>\" \\-\\-merge_blktrace_file=\"<output_file>\"\n.RE\n.P\nCreating only the merged file can be done by passing the command line argument\n\\fBmerge-blktrace-only\\fR.\n.P\nScaling traces can be done to see the relative impact of any particular trace\nbeing slowed down or sped up. \\fBmerge_blktrace_scalars\\fR takes in a colon\nseparated list of percentage scalars. It is index paired with the files passed\nto \\fBread_iolog\\fR.\n.P\nWith scaling, it may be desirable to match the running time of all traces.\nThis can be done with \\fBmerge_blktrace_iters\\fR. It is index paired with\n\\fBread_iolog\\fR just like \\fBmerge_blktrace_scalars\\fR.\n.P\nIn an example, given two traces, A and B, each 60s long. If we want to see\nthe impact of trace A issuing IOs twice as fast and repeat trace A over the\nruntime of trace B, the following can be done:\n.RS\n.P\n$ fio \\-\\-read_iolog=\"<trace_a>:\"<trace_b>\" \\-\\-merge_blktrace_file\"<output_file>\" \\-\\-merge_blktrace_scalars=\"50:100\" \\-\\-merge_blktrace_iters=\"2:1\"\n.RE\n.P\nThis runs trace A at 2x the speed twice for approximately the same runtime as\na single run of trace B.\n.SH CPU IDLENESS PROFILING\nIn some cases, we want to understand CPU overhead in a test. For example, we\ntest patches for the specific goodness of whether they reduce CPU usage.\nFio implements a balloon approach to create a thread per CPU that runs at idle\npriority, meaning that it only runs when nobody else needs the cpu.\nBy measuring the amount of work completed by the thread, idleness of each CPU\ncan be derived accordingly.\n.P\nAn unit work is defined as touching a full page of unsigned characters. Mean and\nstandard deviation of time to complete an unit work is reported in \"unit work\"\nsection. Options can be chosen to report detailed percpu idleness or overall\nsystem idleness by aggregating percpu stats.\n.SH VERIFICATION AND TRIGGERS\nFio is usually run in one of two ways, when data verification is done. The first\nis a normal write job of some sort with verify enabled. When the write phase has\ncompleted, fio switches to reads and verifies everything it wrote. The second\nmodel is running just the write phase, and then later on running the same job\n(but with reads instead of writes) to repeat the same I/O patterns and verify\nthe contents. Both of these methods depend on the write phase being completed,\nas fio otherwise has no idea how much data was written.\n.P\nWith verification triggers, fio supports dumping the current write state to\nlocal files. Then a subsequent read verify workload can load this state and know\nexactly where to stop. This is useful for testing cases where power is cut to a\nserver in a managed fashion, for instance.\n.P\nA verification trigger consists of two things:\n.RS\n.P\n1) Storing the write state of each job.\n.P\n2) Executing a trigger command.\n.RE\n.P\nThe write state is relatively small, on the order of hundreds of bytes to single\nkilobytes. It contains information on the number of completions done, the last X\ncompletions, etc.\n.P\nA trigger is invoked either through creation ('touch') of a specified file in\nthe system, or through a timeout setting. If fio is run with\n`\\-\\-trigger\\-file=/tmp/trigger\\-file', then it will continually\ncheck for the existence of `/tmp/trigger\\-file'. When it sees this file, it\nwill fire off the trigger (thus saving state, and executing the trigger\ncommand).\n.P\nFor client/server runs, there's both a local and remote trigger. If fio is\nrunning as a server backend, it will send the job states back to the client for\nsafe storage, then execute the remote trigger, if specified. If a local trigger\nis specified, the server will still send back the write state, but the client\nwill then execute the trigger.\n.RE\n.P\n.B Verification trigger example\n.RS\nLet's say we want to run a powercut test on the remote Linux machine 'server'.\nOur write workload is in `write\\-test.fio'. We want to cut power to 'server' at\nsome point during the run, and we'll run this test from the safety or our local\nmachine, 'localbox'. On the server, we'll start the fio backend normally:\n.RS\n.P\nserver# fio \\-\\-server\n.RE\n.P\nand on the client, we'll fire off the workload:\n.RS\n.P\nlocalbox$ fio \\-\\-client=server \\-\\-trigger\\-file=/tmp/my\\-trigger \\-\\-trigger\\-remote=\"bash \\-c \"echo b > /proc/sysrq\\-triger\"\"\n.RE\n.P\nWe set `/tmp/my\\-trigger' as the trigger file, and we tell fio to execute:\n.RS\n.P\necho b > /proc/sysrq\\-trigger\n.RE\n.P\non the server once it has received the trigger and sent us the write state. This\nwill work, but it's not really cutting power to the server, it's merely\nabruptly rebooting it. If we have a remote way of cutting power to the server\nthrough IPMI or similar, we could do that through a local trigger command\ninstead. Let's assume we have a script that does IPMI reboot of a given hostname,\nipmi\\-reboot. On localbox, we could then have run fio with a local trigger\ninstead:\n.RS\n.P\nlocalbox$ fio \\-\\-client=server \\-\\-trigger\\-file=/tmp/my\\-trigger \\-\\-trigger=\"ipmi\\-reboot server\"\n.RE\n.P\nFor this case, fio would wait for the server to send us the write state, then\nexecute `ipmi\\-reboot server' when that happened.\n.RE\n.P\n.B Loading verify state\n.RS\nTo load stored write state, a read verification job file must contain the\n\\fBverify_state_load\\fR option. If that is set, fio will load the previously\nstored state. For a local fio run this is done by loading the files directly,\nand on a client/server run, the server backend will ask the client to send the\nfiles over and load them from there.\n.RE\n.SH LOG FILE FORMATS\nFio supports a variety of log file formats, for logging latencies, bandwidth,\nand IOPS. The logs share a common format, which looks like this:\n.RS\n.P\ntime (msec), value, data direction, block size (bytes), offset (bytes),\ncommand priority, issue time (nsec)\n.RE\n.P\n`Time' for the log entry is always in milliseconds. The `value' logged depends\non the type of log, it will be one of the following:\n.RS\n.TP\n.B Latency log\nValue is latency in nsecs\n.TP\n.B Bandwidth log\nValue is in KiB/sec\n.TP\n.B IOPS log\nValue is IOPS\n.RE\n.P\n`Data direction' is one of the following:\n.RS\n.TP\n.B 0\nI/O is a READ\n.TP\n.B 1\nI/O is a WRITE\n.TP\n.B 2\nI/O is a TRIM\n.RE\n.P\nThe entry's `block size' is always in bytes. The `offset' is the position in bytes\nfrom the start of the file for that particular I/O. The logging of the offset can be\ntoggled with \\fBlog_offset\\fR.\n.P\nIf \\fBlog_prio\\fR is not set, the entry's `Command priority` is 1 for an IO executed\nwith the highest RT priority class (\\fBprioclass\\fR=1 or \\fBcmdprio_class\\fR=1) and 0\notherwise. This is controlled by the \\fBprioclass\\fR option and the ioengine specific\n\\fBcmdprio_percentage\\fR \\fBcmdprio_class\\fR options. If \\fBlog_prio\\fR is set, the\nentry's `Command priority` is the priority set for the IO, as a 16-bits hexadecimal\nnumber with the lowest 13 bits indicating the priority value (\\fBprio\\fR and\n\\fBcmdprio\\fR options) and the highest 3 bits indicating the IO priority class\n(\\fBprioclass\\fR and \\fBcmdprio_class\\fR options).\n.P\nThe entry's `issue time` is the command issue time in nanoseconds. The logging\nof the issue time can be toggled with \\fBlog_issue_time\\fR. This field has valid\nvalues in completion latency log file (clat), or submit latency log file (slat).\nThe field has value 0 in other log files.\n.P\nFio defaults to logging every individual I/O but when windowed logging is set\nthrough \\fBlog_avg_msec\\fR, either the average (by default), the maximum\n(\\fBlog_window_value\\fR is set to max) `value' seen over the specified period of\ntime, or both the average `value' and maximum `value1' (\\fBlog_window_value\\fR is\nset to both) is recorded. The log file format when both the values are reported\ntakes this form:\n.RS\n.P\ntime (msec), value, value1, data direction, block size (bytes), offset (bytes),\ncommand priority, issue time (nsec)\n.RE\n.P\nEach `data direction' seen within the window period will aggregate its values\nin a separate row. Further, when using windowed logging the `block size',\n`offset' and `issue time` entries will always contain 0.\n.SH CLIENT / SERVER\nNormally fio is invoked as a stand-alone application on the machine where the\nI/O workload should be generated. However, the backend and frontend of fio can\nbe run separately i.e., the fio server can generate an I/O workload on the \"Device\nUnder Test\" while being controlled by a client on another machine.\n.P\nStart the server on the machine which has access to the storage DUT:\n.RS\n.P\n$ fio \\-\\-server=args\n.RE\n.P\nwhere `args' defines what fio listens to. The arguments are of the form\n`type,hostname' or `IP,port'. `type' is either `ip' (or ip4) for TCP/IP\nv4, `ip6' for TCP/IP v6, or `sock' for a local unix domain socket.\n`hostname' is either a hostname or IP address, and `port' is the port to listen\nto (only valid for TCP/IP, not a local socket). Some examples:\n.RS\n.TP\n1) \\fBfio \\-\\-server\\fR\nStart a fio server, listening on all interfaces on the default port (8765).\n.TP\n2) \\fBfio \\-\\-server=ip:hostname,4444\\fR\nStart a fio server, listening on IP belonging to hostname and on port 4444.\n.TP\n3) \\fBfio \\-\\-server=ip6:::1,4444\\fR\nStart a fio server, listening on IPv6 localhost ::1 and on port 4444.\n.TP\n4) \\fBfio \\-\\-server=,4444\\fR\nStart a fio server, listening on all interfaces on port 4444.\n.TP\n5) \\fBfio \\-\\-server=1.2.3.4\\fR\nStart a fio server, listening on IP 1.2.3.4 on the default port.\n.TP\n6) \\fBfio \\-\\-server=sock:/tmp/fio.sock\\fR\nStart a fio server, listening on the local socket `/tmp/fio.sock'.\n.RE\n.P\nOnce a server is running, a \"client\" can connect to the fio server with:\n.RS\n.P\n$ fio <local\\-args> \\-\\-client=<server> <remote\\-args> <job file(s)>\n.RE\n.P\nwhere `local\\-args' are arguments for the client where it is running, `server'\nis the connect string, and `remote\\-args' and `job file(s)' are sent to the\nserver. The `server' string follows the same format as it does on the server\nside, to allow IP/hostname/socket and port strings.\n.P\nNote that all job options must be defined in job files when running fio as a\nclient. Any job options specified in `remote\\-args' will be ignored.\n.P\nFio can connect to multiple servers this way:\n.RS\n.P\n$ fio \\-\\-client=<server1> <job file(s)> \\-\\-client=<server2> <job file(s)>\n.RE\n.P\nIf the job file is located on the fio server, then you can tell the server to\nload a local file as well. This is done by using \\fB\\-\\-remote\\-config\\fR:\n.RS\n.P\n$ fio \\-\\-client=server \\-\\-remote\\-config /path/to/file.fio\n.RE\n.P\nThen fio will open this local (to the server) job file instead of being passed\none from the client.\n.P\nIf you have many servers (example: 100 VMs/containers), you can input a pathname\nof a file containing host IPs/names as the parameter value for the\n\\fB\\-\\-client\\fR option. For example, here is an example `host.list'\nfile containing 2 hostnames:\n.RS\n.P\n.PD 0\nhost1.your.dns.domain\n.P\nhost2.your.dns.domain\n.PD\n.RE\n.P\nThe fio command would then be:\n.RS\n.P\n$ fio \\-\\-client=host.list <job file(s)>\n.RE\n.P\nIn this mode, you cannot input server-specific parameters or job files \\-\\- all\nservers receive the same job file.\n.P\nIn order to let `fio \\-\\-client' runs use a shared filesystem from multiple\nhosts, `fio \\-\\-client' now prepends the IP address of the server to the\nfilename. For example, if fio is using the directory `/mnt/nfs/fio' and is\nwriting filename `fileio.tmp', with a \\fB\\-\\-client\\fR `hostfile'\ncontaining two hostnames `h1' and `h2' with IP addresses 192.168.10.120 and\n192.168.10.121, then fio will create two files:\n.RS\n.P\n.PD 0\n/mnt/nfs/fio/192.168.10.120.fileio.tmp\n.P\n/mnt/nfs/fio/192.168.10.121.fileio.tmp\n.PD\n.RE\n.P\nThis behavior can be disabled by the \\fBunique_filename\\fR option.\n.P\nTerse output in client/server mode will differ slightly from what is produced\nwhen fio is run in stand-alone mode. See the terse output section for details.\n.P\nAlso, if one fio invocation runs workloads on multiple servers, fio will\nprovide at the end an aggregate summary report for all workloads. This\naggregate summary report assumes that options affecting reporting like\n\\fBunified_rw_reporting\\fR and \\fBpercentile_list\\fR are identical across all\nthe jobs summarized. Having different values for these options is an\nunsupported configuration.\n.SH AUTHORS\n.B fio\nwas written by Jens Axboe <axboe@kernel.dk>.\n.br\nThis man page was written by Aaron Carroll <aaronc@cse.unsw.edu.au> based\non documentation by Jens Axboe.\n.br\nThis man page was rewritten by Tomohiro Kusumi <tkusumi@tuxera.com> based\non documentation by Jens Axboe.\n.SH \"REPORTING BUGS\"\nReport bugs to the \\fBfio\\fR mailing list <fio@vger.kernel.org>.\n.br\nSee \\fBREPORTING\\-BUGS\\fR.\n.P\n\\fBREPORTING\\-BUGS\\fR: \\fIhttp://git.kernel.dk/cgit/fio/plain/REPORTING\\-BUGS\\fR\n.SH \"SEE ALSO\"\nFor further documentation see \\fBHOWTO\\fR and \\fBREADME\\fR.\n.br\nSample jobfiles are available in the `examples/' directory.\n.br\nThese are typically located under `/usr/share/doc/fio'.\n.P\n\\fBHOWTO\\fR: \\fIhttp://git.kernel.dk/cgit/fio/plain/HOWTO\\fR\n.br\n\\fBREADME\\fR: \\fIhttp://git.kernel.dk/cgit/fio/plain/README\\fR\n"
        },
        {
          "name": "fio.c",
          "type": "blob",
          "size": 1.619140625,
          "content": "/*\n * fio - the flexible io tester\n *\n * Copyright (C) 2005 Jens Axboe <axboe@suse.de>\n * Copyright (C) 2006-2012 Jens Axboe <axboe@kernel.dk>\n *\n * The license below covers all files distributed with fio unless otherwise\n * noted in the file itself.\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License version 2 as\n *  published by the Free Software Foundation.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; if not, write to the Free Software\n *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n#include \"fio.h\"\n\nint main(int argc, char *argv[], char *envp[])\n{\n\tint ret = 1;\n\n\tif (initialize_fio(envp))\n\t\treturn 1;\n\n#if !defined(CONFIG_GETTIMEOFDAY) && !defined(CONFIG_CLOCK_GETTIME)\n#error \"No available clock source!\"\n#endif\n\n\tif (fio_server_create_sk_key())\n\t\tgoto done;\n\n\tif (parse_options(argc, argv))\n\t\tgoto done_key;\n\n\t/*\n\t * line buffer stdout to avoid output lines from multiple\n\t * threads getting mixed\n\t */\n\tsetvbuf(stdout, NULL, _IOLBF, 0);\n\n\tfio_time_init();\n\n\tif (nr_clients) {\n\t\tset_genesis_time();\n\n\t\tif (fio_start_all_clients())\n\t\t\tgoto done_key;\n\t\tret = fio_handle_clients(&fio_client_ops);\n\t} else\n\t\tret = fio_backend(NULL);\n\ndone_key:\n\tfio_server_destroy_sk_key();\ndone:\n\tdeinitialize_fio();\n\treturn ret;\n}\n"
        },
        {
          "name": "fio.h",
          "type": "blob",
          "size": 21.8466796875,
          "content": "#ifndef FIO_H\n#define FIO_H\n\n#include <sched.h>\n#include <limits.h>\n#include <pthread.h>\n#include <sys/time.h>\n#include <sys/resource.h>\n#include <errno.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <inttypes.h>\n#include <assert.h>\n\n#include \"compiler/compiler.h\"\n#include \"thread_options.h\"\n#include \"flist.h\"\n#include \"fifo.h\"\n#include \"arch/arch.h\"\n#include \"os/os.h\"\n#include \"log.h\"\n#include \"debug.h\"\n#include \"file.h\"\n#include \"io_ddir.h\"\n#include \"ioengines.h\"\n#include \"iolog.h\"\n#include \"helpers.h\"\n#include \"minmax.h\"\n#include \"options.h\"\n#include \"profile.h\"\n#include \"fio_time.h\"\n#include \"gettime.h\"\n#include \"oslib/getopt.h\"\n#include \"lib/rand.h\"\n#include \"lib/rbtree.h\"\n#include \"lib/num2str.h\"\n#include \"lib/memalign.h\"\n#include \"smalloc.h\"\n#include \"client.h\"\n#include \"server.h\"\n#include \"stat.h\"\n#include \"flow.h\"\n#include \"io_u.h\"\n#include \"io_u_queue.h\"\n#include \"workqueue.h\"\n#include \"steadystate.h\"\n#include \"lib/nowarn_snprintf.h\"\n#include \"dedupe.h\"\n\n#ifdef CONFIG_SOLARISAIO\n#include <sys/asynch.h>\n#endif\n\n#ifdef CONFIG_LIBNUMA\n#include <linux/mempolicy.h>\n#include <numa.h>\n\n/*\n * \"local\" is pseudo-policy\n */\n#ifndef MPOL_LOCAL\n#define MPOL_LOCAL 4\n#endif\n#endif\n\n#ifdef CONFIG_CUDA\n#include <cuda.h>\n#endif\n\nstruct fio_sem;\n\n#define MAX_TRIM_RANGE\t256\n\n/*\n * Range for trim command\n */\nstruct trim_range {\n\tunsigned long long start;\n\tunsigned long long len;\n};\n\n/*\n * offset generator types\n */\nenum {\n\tRW_SEQ_SEQ\t= 0,\n\tRW_SEQ_IDENT,\n};\n\nenum {\n\t__TD_F_VER_BACKLOG\t= 0,\n\t__TD_F_TRIM_BACKLOG,\n\t__TD_F_READ_IOLOG,\n\t__TD_F_REFILL_BUFFERS,\n\t__TD_F_SCRAMBLE_BUFFERS,\n\t__TD_F_DO_VERIFY,\n\t__TD_F_PROFILE_OPS,\n\t__TD_F_COMPRESS,\n\t__TD_F_COMPRESS_LOG,\n\t__TD_F_VSTATE_SAVED,\n\t__TD_F_NEED_LOCK,\n\t__TD_F_CHILD,\n\t__TD_F_NO_PROGRESS,\n\t__TD_F_REGROW_LOGS,\n\t__TD_F_MMAP_KEEP,\n\t__TD_F_DIRS_CREATED,\n\t__TD_F_CHECK_RATE,\n\t__TD_F_SYNCS,\n\t__TD_F_LAST,\t\t/* not a real bit, keep last */\n};\n\nenum {\n\tTD_F_VER_BACKLOG\t= 1U << __TD_F_VER_BACKLOG,\n\tTD_F_TRIM_BACKLOG\t= 1U << __TD_F_TRIM_BACKLOG,\n\tTD_F_READ_IOLOG\t\t= 1U << __TD_F_READ_IOLOG,\n\tTD_F_REFILL_BUFFERS\t= 1U << __TD_F_REFILL_BUFFERS,\n\tTD_F_SCRAMBLE_BUFFERS\t= 1U << __TD_F_SCRAMBLE_BUFFERS,\n\tTD_F_DO_VERIFY\t\t= 1U << __TD_F_DO_VERIFY,\n\tTD_F_PROFILE_OPS\t= 1U << __TD_F_PROFILE_OPS,\n\tTD_F_COMPRESS\t\t= 1U << __TD_F_COMPRESS,\n\tTD_F_COMPRESS_LOG\t= 1U << __TD_F_COMPRESS_LOG,\n\tTD_F_VSTATE_SAVED\t= 1U << __TD_F_VSTATE_SAVED,\n\tTD_F_NEED_LOCK\t\t= 1U << __TD_F_NEED_LOCK,\n\tTD_F_CHILD\t\t= 1U << __TD_F_CHILD,\n\tTD_F_NO_PROGRESS        = 1U << __TD_F_NO_PROGRESS,\n\tTD_F_REGROW_LOGS\t= 1U << __TD_F_REGROW_LOGS,\n\tTD_F_MMAP_KEEP\t\t= 1U << __TD_F_MMAP_KEEP,\n\tTD_F_DIRS_CREATED\t= 1U << __TD_F_DIRS_CREATED,\n\tTD_F_CHECK_RATE\t\t= 1U << __TD_F_CHECK_RATE,\n\tTD_F_SYNCS\t\t= 1U << __TD_F_SYNCS,\n};\n\nenum {\n\tFIO_RAND_BS_OFF\t\t= 0,\n\tFIO_RAND_BS1_OFF,\n\tFIO_RAND_BS2_OFF,\n\tFIO_RAND_VER_OFF,\n\tFIO_RAND_MIX_OFF,\n\tFIO_RAND_FILE_OFF,\n\tFIO_RAND_BLOCK_OFF,\n\tFIO_RAND_FILE_SIZE_OFF,\n\tFIO_RAND_TRIM_OFF,\n\tFIO_RAND_BUF_OFF,\n\tFIO_RAND_SEQ_RAND_READ_OFF,\n\tFIO_RAND_SEQ_RAND_WRITE_OFF,\n\tFIO_RAND_SEQ_RAND_TRIM_OFF,\n\tFIO_RAND_START_DELAY,\n\tFIO_DEDUPE_OFF,\n\tFIO_RAND_POISSON_OFF,\n\tFIO_RAND_ZONE_OFF,\n\tFIO_RAND_POISSON2_OFF,\n\tFIO_RAND_POISSON3_OFF,\n\tFIO_RAND_PRIO_CMDS,\n\tFIO_RAND_DEDUPE_WORKING_SET_IX,\n\tFIO_RAND_FDP_OFF,\n\tFIO_RAND_NR_OFFS,\n};\n\nenum {\n\tIO_MODE_INLINE = 0,\n\tIO_MODE_OFFLOAD = 1,\n\n\tRATE_PROCESS_LINEAR = 0,\n\tRATE_PROCESS_POISSON = 1,\n\n\tTHINKTIME_BLOCKS_TYPE_COMPLETE = 0,\n\tTHINKTIME_BLOCKS_TYPE_ISSUE = 1,\n};\n\nenum {\n\tF_ADV_NONE = 0,\n\tF_ADV_TYPE,\n\tF_ADV_RANDOM,\n\tF_ADV_SEQUENTIAL,\n\tF_ADV_NOREUSE,\n};\n\n/*\n * Per-thread/process specific data. Only used for the network client\n * for now.\n */\nvoid sk_out_assign(struct sk_out *);\nvoid sk_out_drop(void);\n\nstruct zone_split_index {\n\tuint8_t size_perc;\n\tuint8_t size_perc_prev;\n\tuint64_t size;\n\tuint64_t size_prev;\n};\n\n/*\n * This describes a single thread/process executing a fio job.\n */\nstruct thread_data {\n\tstruct flist_head opt_list;\n\tunsigned long long flags;\n\tstruct thread_options o;\n\tvoid *eo;\n\tpthread_t thread;\n\tunsigned int thread_number;\n\tunsigned int subjob_number;\n\tunsigned int groupid;\n\tstruct thread_stat ts __attribute__ ((aligned(8)));\n\n\tint client_type;\n\n\tstruct io_log *slat_log;\n\tstruct io_log *clat_log;\n\tstruct io_log *clat_hist_log;\n\tstruct io_log *lat_log;\n\tstruct io_log *bw_log;\n\tstruct io_log *iops_log;\n\n\tstruct workqueue log_compress_wq;\n\n\tstruct thread_data *parent;\n\n\tuint64_t stat_io_bytes[DDIR_RWDIR_CNT];\n\tstruct timespec bw_sample_time;\n\n\tuint64_t stat_io_blocks[DDIR_RWDIR_CNT];\n\tstruct timespec iops_sample_time;\n\n\tvolatile int update_rusage;\n\tstruct fio_sem *rusage_sem;\n\tstruct rusage ru_start;\n\tstruct rusage ru_end;\n\n\tstruct fio_file **files;\n\tunsigned char *file_locks;\n\tunsigned int files_size;\n\tunsigned int files_index;\n\tunsigned int nr_open_files;\n\tunsigned int nr_done_files;\n\tunion {\n\t\tunsigned int next_file;\n\t\tstruct frand_state next_file_state;\n\t};\n\tunion {\n\t\tstruct zipf_state next_file_zipf;\n\t\tstruct gauss_state next_file_gauss;\n\t};\n\tunion {\n\t\tdouble zipf_theta;\n\t\tdouble pareto_h;\n\t\tdouble gauss_dev;\n\t};\n\tdouble random_center;\n\tint error;\n\tint sig;\n\tint done;\n\tint stop_io;\n\tpid_t pid;\n\tchar *orig_buffer;\n\tsize_t orig_buffer_size;\n\tvolatile int runstate;\n\tvolatile bool terminate;\n\n\tenum fio_ddir last_ddir_completed;\n\tenum fio_ddir last_ddir_issued;\n\n\tint mmapfd;\n\n\tvoid *iolog_buf;\n\tFILE *iolog_f;\n\n\tuint64_t rand_seeds[FIO_RAND_NR_OFFS];\n\n\tstruct frand_state bsrange_state[DDIR_RWDIR_CNT];\n\tstruct frand_state verify_state;\n\tstruct frand_state verify_state_last_do_io;\n\tstruct frand_state trim_state;\n\tstruct frand_state delay_state;\n\tstruct frand_state fdp_state;\n\n\tstruct frand_state buf_state;\n\tstruct frand_state buf_state_prev;\n\tstruct frand_state buf_state_ret;\n\tstruct frand_state dedupe_state;\n\tstruct frand_state zone_state;\n\tstruct frand_state prio_state;\n\tstruct frand_state dedupe_working_set_index_state;\n\tstruct frand_state *dedupe_working_set_states;\n\n\tunsigned long long num_unique_pages;\n\n\tstruct zone_split_index **zone_state_index;\n\tunsigned int num_write_zones;\n\n\tunsigned int verify_batch;\n\tunsigned int trim_batch;\n\n\tstruct thread_io_list *vstate;\n\n\tint shm_id;\n\n\t/*\n\t * Job default IO priority set with prioclass and prio options.\n\t */\n\tunsigned int ioprio;\n\n\t/*\n\t * IO engine hooks, contains everything needed to submit an io_u\n\t * to any of the available IO engines.\n\t */\n\tstruct ioengine_ops *io_ops;\n\tint io_ops_init;\n\n\t/*\n\t * IO engine private data and dlhandle.\n\t */\n\tvoid *io_ops_data;\n\n\t/*\n\t * Queue depth of io_u's that fio MIGHT do\n\t */\n\tunsigned int cur_depth;\n\n\t/*\n\t * io_u's about to be committed\n\t */\n\tunsigned int io_u_queued;\n\n\t/*\n\t * io_u's submitted but not completed yet\n\t */\n\tunsigned int io_u_in_flight;\n\n\t/*\n\t * List of free and busy io_u's\n\t */\n\tstruct io_u_ring io_u_requeues;\n\tstruct io_u_queue io_u_freelist;\n\tstruct io_u_queue io_u_all;\n\tpthread_mutex_t io_u_lock;\n\tpthread_cond_t free_cond;\n\n\t/*\n\t * async verify offload\n\t */\n\tstruct flist_head verify_list;\n\tpthread_t *verify_threads;\n\tunsigned int nr_verify_threads;\n\tpthread_cond_t verify_cond;\n\tint verify_thread_exit;\n\n\t/*\n\t * Rate state\n\t */\n\tuint64_t rate_bps[DDIR_RWDIR_CNT];\n\tuint64_t rate_next_io_time[DDIR_RWDIR_CNT];\n\tunsigned long long last_rate_check_bytes[DDIR_RWDIR_CNT];\n\tunsigned long last_rate_check_blocks[DDIR_RWDIR_CNT];\n\tunsigned long long rate_io_issue_bytes[DDIR_RWDIR_CNT];\n\tstruct timespec last_rate_check_time[DDIR_RWDIR_CNT];\n\tint64_t last_usec[DDIR_RWDIR_CNT];\n\tstruct frand_state poisson_state[DDIR_RWDIR_CNT];\n\n\t/*\n\t * Enforced rate submission/completion workqueue\n\t */\n\tstruct workqueue io_wq;\n\n\tuint64_t total_io_size;\n\tuint64_t fill_device_size;\n\n\t/*\n\t * Issue side\n\t */\n\tuint64_t io_issues[DDIR_RWDIR_CNT];\n\tuint64_t verify_read_issues;\n\tuint64_t io_issue_bytes[DDIR_RWDIR_CNT];\n\tuint64_t loops;\n\n\t/*\n\t * Completions\n\t */\n\tuint64_t io_blocks[DDIR_RWDIR_CNT];\n\tuint64_t this_io_blocks[DDIR_RWDIR_CNT];\n\tuint64_t io_bytes[DDIR_RWDIR_CNT];\n\tuint64_t this_io_bytes[DDIR_RWDIR_CNT];\n\tuint64_t io_skip_bytes;\n\tuint64_t zone_bytes;\n\tstruct fio_sem *sem;\n\tuint64_t bytes_done[DDIR_RWDIR_CNT];\n\tuint64_t bytes_verified;\n\n\tuint64_t *thinktime_blocks_counter;\n\tstruct timespec last_thinktime;\n\tint64_t last_thinktime_blocks;\n\n\t/*\n\t * State for random io, a bitmap of blocks done vs not done\n\t */\n\tstruct frand_state random_state;\n\n\tstruct timespec start;\t/* start of this loop */\n\tstruct timespec epoch;\t/* time job was started */\n\tunsigned long long alternate_epoch; /* Time job was started, as clock_gettime(log_alternate_epoch_clock_id) */\n\tunsigned long long job_start; /* Time job was started, as clock_gettime(job_start_clock_id) */\n\tstruct timespec last_issue;\n\tlong time_offset;\n\tstruct timespec ts_cache;\n\tstruct timespec terminate_time;\n\tunsigned int ts_cache_nr;\n\tunsigned int ts_cache_mask;\n\tbool ramp_time_over;\n\n\t/*\n\t * Time since last latency_window was started\n\t */\n\tstruct timespec latency_ts;\n\tunsigned int latency_qd;\n\tunsigned int latency_qd_high;\n\tunsigned int latency_qd_low;\n\tunsigned int latency_failed;\n\tunsigned int latency_stable_count;\n\tuint64_t latency_ios;\n\tint latency_end_run;\n\n\t/*\n\t * read/write mixed workload state\n\t */\n\tstruct frand_state rwmix_state;\n\tunsigned long rwmix_issues;\n\tenum fio_ddir rwmix_ddir;\n\tunsigned int ddir_seq_nr;\n\n\t/*\n\t * rand/seq mixed workload state\n\t */\n\tstruct frand_state seq_rand_state[DDIR_RWDIR_CNT];\n\n\t/*\n\t * IO history logs for verification. We use a tree for sorting,\n\t * if we are overwriting. Otherwise just use a fifo.\n\t */\n\tstruct rb_root io_hist_tree;\n\tstruct flist_head io_hist_list;\n\tunsigned long io_hist_len;\n\n\t/*\n\t * For IO replaying\n\t */\n\tstruct flist_head io_log_list;\n\tFILE *io_log_rfile;\n\tunsigned int io_log_blktrace;\n\tunsigned int io_log_blktrace_swap;\n\tunsigned long long io_log_last_ttime;\n\tstruct timespec io_log_start_time;\n\tunsigned int io_log_current;\n\tunsigned int io_log_checkmark;\n\tunsigned int io_log_highmark;\n\tunsigned int io_log_version;\n\tstruct timespec io_log_highmark_time;\n\n\t/*\n\t * For tracking/handling discards\n\t */\n\tstruct flist_head trim_list;\n\tunsigned long trim_entries;\n\n\t/*\n\t * for fileservice, how often to switch to a new file\n\t */\n\tunsigned int file_service_nr;\n\tunsigned int file_service_left;\n\tstruct fio_file *file_service_file;\n\n\tunsigned int sync_file_range_nr;\n\n\t/*\n\t * For generating file sizes\n\t */\n\tstruct frand_state file_size_state;\n\n\t/*\n\t * Error counts\n\t */\n\tunsigned int total_err_count;\n\tint first_error;\n\n\tstruct fio_flow *flow;\n\tunsigned long long flow_counter;\n\n\t/*\n\t * Can be overloaded by profiles\n\t */\n\tstruct prof_io_ops prof_io_ops;\n\tvoid *prof_data;\n\n\tvoid *pinned_mem;\n\n\tstruct steadystate_data ss;\n\n\tchar verror[FIO_VERROR_SIZE];\n\n#ifdef CONFIG_CUDA\n\t/*\n\t * for GPU memory management\n\t */\n\tint gpu_dev_cnt;\n\tint gpu_dev_id;\n\tCUdevice  cu_dev;\n\tCUcontext cu_ctx;\n\tCUdeviceptr dev_mem_ptr;\n#endif\n\n};\n\nstruct thread_segment {\n\tstruct thread_data *threads;\n\tint shm_id;\n\tint nr_threads;\n};\n\n/*\n * when should interactive ETA output be generated\n */\nenum {\n\tFIO_ETA_AUTO,\n\tFIO_ETA_ALWAYS,\n\tFIO_ETA_NEVER,\n};\n\n#define __td_verror(td, err, msg, func)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tunsigned int ____e = (err);\t\t\t\t\\\n\t\tif ((td)->error)\t\t\t\t\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\t(td)->error = ____e;\t\t\t\t\t\\\n\t\tif (!(td)->first_error)\t\t\t\t\t\\\n\t\t\tnowarn_snprintf(td->verror, sizeof(td->verror),\t\\\n\t\t\t\t\t\"file:%s:%d, func=%s, error=%s\", \\\n\t\t\t\t\t__FILE__, __LINE__, (func), (msg)); \\\n\t} while (0)\n\n\n#define td_clear_error(td)\t\tdo {\t\t\\\n\t(td)->error = 0;\t\t\t\t\\\n\tif ((td)->parent)\t\t\t\t\\\n\t\t(td)->parent->error = 0;\t\t\\\n} while (0)\n\n#define td_verror(td, err, func)\tdo {\t\t\t\\\n\t__td_verror((td), (err), strerror((err)), (func));\t\\\n\tif ((td)->parent)\t\t\t\t\t\\\n\t\t__td_verror((td)->parent, (err), strerror((err)), (func)); \\\n} while (0)\n\n#define td_vmsg(td, err, msg, func)\tdo {\t\t\t\\\n\t__td_verror((td), (err), (msg), (func));\t\t\\\n\tif ((td)->parent)\t\t\t\t\t\\\n\t\t__td_verror((td)->parent, (err), (msg), (func));\t\\\n} while (0)\n\n#define __fio_stringify_1(x)\t#x\n#define __fio_stringify(x)\t__fio_stringify_1(x)\n\n#define REAL_MAX_JOBS\t\t4096\n#define JOBS_PER_SEG\t\t8\n#define REAL_MAX_SEG\t\t(REAL_MAX_JOBS / JOBS_PER_SEG)\n\nextern bool exitall_on_terminate;\nextern unsigned int thread_number;\nextern unsigned int stat_number;\nextern unsigned int nr_segments;\nextern unsigned int cur_segment;\nextern int groupid;\nextern int output_format;\nextern int append_terse_output;\nextern int temp_stall_ts;\nextern uintptr_t page_mask, page_size;\nextern bool read_only;\nextern int eta_print;\nextern int eta_new_line;\nextern unsigned int eta_interval_msec;\nextern unsigned long done_secs;\nextern int fio_gtod_offload;\nextern int fio_gtod_cpu;\nextern enum fio_cs fio_clock_source;\nextern int fio_clock_source_set;\nextern int warnings_fatal;\nextern int terse_version;\nextern bool is_backend;\nextern bool is_local_backend;\nextern int nr_clients;\nextern bool log_syslog;\nextern int status_interval;\nextern const char fio_version_string[];\nextern char *trigger_file;\nextern char *trigger_cmd;\nextern char *trigger_remote_cmd;\nextern long long trigger_timeout;\nextern char *aux_path;\n\nextern struct thread_segment segments[REAL_MAX_SEG];\n\nstatic inline struct thread_data *tnumber_to_td(unsigned int tnumber)\n{\n\tstruct thread_segment *seg;\n\n\tseg = &segments[tnumber / JOBS_PER_SEG];\n\treturn &seg->threads[tnumber & (JOBS_PER_SEG - 1)];\n}\n\nstatic inline bool is_running_backend(void)\n{\n\treturn is_backend || is_local_backend;\n}\n\nextern bool eta_time_within_slack(unsigned int time);\n\nstatic inline void fio_ro_check(const struct thread_data *td, struct io_u *io_u)\n{\n\tassert(!(io_u->ddir == DDIR_WRITE && !td_write(td)) &&\n\t       !(io_u->ddir == DDIR_TRIM && !td_trim(td)));\n}\n\nstatic inline bool multi_range_trim(struct thread_data *td, struct io_u *io_u)\n{\n\tif (io_u->ddir == DDIR_TRIM && td->o.num_range > 1)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool should_fsync(struct thread_data *td)\n{\n\tif (ddir_sync(td->last_ddir_issued))\n\t\treturn false;\n\tif (td_write(td) || td->o.override_sync)\n\t\treturn true;\n\n\treturn false;\n}\n\n/*\n * Init/option functions\n */\nextern int __must_check fio_init_options(void);\nextern int __must_check parse_options(int, char **);\nextern int parse_jobs_ini(char *, int, int, int);\nextern int parse_cmd_line(int, char **, int);\nextern int fio_backend(struct sk_out *);\nextern void reset_fio_state(void);\nextern void clear_io_state(struct thread_data *, int);\nextern int fio_options_parse(struct thread_data *, char **, int);\nextern void fio_keywords_init(void);\nextern void fio_keywords_exit(void);\nextern int fio_cmd_option_parse(struct thread_data *, const char *, char *);\nextern int fio_cmd_ioengine_option_parse(struct thread_data *, const char *, char *);\nextern void fio_fill_default_options(struct thread_data *);\nextern int fio_show_option_help(const char *);\nextern void fio_options_set_ioengine_opts(struct option *long_options, struct thread_data *td);\nextern void fio_options_dup_and_init(struct option *);\nextern char *fio_option_dup_subs(const char *);\nextern void fio_options_mem_dupe(struct thread_data *);\nextern void td_fill_rand_seeds(struct thread_data *);\nextern void add_job_opts(const char **, int);\nextern int ioengine_load(struct thread_data *);\nextern bool parse_dryrun(void);\nextern int fio_running_or_pending_io_threads(void);\nextern int fio_set_fd_nonblocking(int, const char *);\nextern void sig_show_status(int sig);\nextern struct thread_data *get_global_options(void);\n\nextern uintptr_t page_mask;\nextern uintptr_t page_size;\nextern int initialize_fio(char *envp[]);\nextern void deinitialize_fio(void);\n\n#define FIO_GETOPT_JOB\t\t0x89000000\n#define FIO_GETOPT_IOENGINE\t0x98000000\n#define FIO_NR_OPTIONS\t\t(FIO_MAX_OPTS + 128)\n\n/*\n * ETA/status stuff\n */\nextern void print_thread_status(void);\nextern void print_status_init(int);\nextern char *fio_uint_to_kmg(unsigned int val);\n\n/*\n * Thread life cycle. Once a thread has a runstate beyond TD_INITIALIZED, it\n * will never back again. It may cycle between running/verififying/fsyncing.\n * Once the thread reaches TD_EXITED, it is just waiting for the core to\n * reap it.\n */\nenum {\n\tTD_NOT_CREATED = 0,\n\tTD_CREATED,\n\tTD_INITIALIZED,\n\tTD_RAMP,\n\tTD_SETTING_UP,\n\tTD_RUNNING,\n\tTD_PRE_READING,\n\tTD_VERIFYING,\n\tTD_FSYNCING,\n\tTD_FINISHING,\n\tTD_EXITED,\n\tTD_REAPED,\n\tTD_LAST,\n\tTD_NR,\n};\n\n#define TD_ENG_FLAG_SHIFT\t(__TD_F_LAST)\n#define TD_ENG_FLAG_MASK\t((1ULL << (__TD_F_LAST)) - 1)\n\nstatic inline void td_set_ioengine_flags(struct thread_data *td)\n{\n\ttd->flags = (~(TD_ENG_FLAG_MASK << TD_ENG_FLAG_SHIFT) & td->flags) |\n\t\t    ((unsigned long long)td->io_ops->flags << TD_ENG_FLAG_SHIFT);\n}\n\nstatic inline bool td_ioengine_flagged(struct thread_data *td,\n\t\t\t\t       enum fio_ioengine_flags flags)\n{\n\treturn ((td->flags >> TD_ENG_FLAG_SHIFT) & flags) != 0;\n}\n\nextern void td_set_runstate(struct thread_data *, int);\nextern int td_bump_runstate(struct thread_data *, int);\nextern void td_restore_runstate(struct thread_data *, int);\nextern const char *runstate_to_name(int runstate);\n\n/*\n * Allow 60 seconds for a job to quit on its own, otherwise reap with\n * a vengeance.\n */\n#define FIO_REAP_TIMEOUT\t300\n\nenum {\n\tTERMINATE_NONE = 0,\n\tTERMINATE_GROUP = 1,\n\tTERMINATE_STONEWALL = 2,\n\tTERMINATE_ALL = -1,\n};\n\nextern void fio_terminate_threads(unsigned int, unsigned int);\nextern void fio_mark_td_terminate(struct thread_data *);\n\n/*\n * Memory helpers\n */\nextern int __must_check fio_pin_memory(struct thread_data *);\nextern void fio_unpin_memory(struct thread_data *);\nextern int __must_check allocate_io_mem(struct thread_data *);\nextern void free_io_mem(struct thread_data *);\nextern void free_threads_shm(void);\n\n#ifdef FIO_INTERNAL\n#define PTR_ALIGN(ptr, mask)\t\\\n\t(char *) (((uintptr_t) (ptr) + (mask)) & ~(mask))\n#endif\n\n/*\n * Reset stats after ramp time completes\n */\nextern void reset_all_stats(struct thread_data *);\n\nextern int io_queue_event(struct thread_data *td, struct io_u *io_u, int *ret,\n\t\t   enum fio_ddir ddir, uint64_t *bytes_issued, int from_verify,\n\t\t   struct timespec *comp_time);\n\n/*\n * Latency target helpers\n */\nextern void lat_target_check(struct thread_data *);\nextern void lat_target_init(struct thread_data *);\nextern void lat_target_reset(struct thread_data *);\n\n/*\n * Iterates all threads/processes within all the defined jobs\n * Usage:\n *\t\tfor_each_td(var_name_for_td) {\n *\t\t\t<< bodoy of your loop >>\n *\t\t\t Note: internally-scoped loop index availble as __td_index\n *\t\t} end_for_each_td()\n */\n#define for_each_td(td)\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\tint __td_index;\t\t\t\t\\\n\tstruct thread_data *(td);\t\\\n\tfor (__td_index = 0, (td) = &segments[0].threads[0];\\\n\t\t__td_index < (int) thread_number; __td_index++, (td) = tnumber_to_td(__td_index))\n#define for_each_td_index()\t    \\\n{\t\t\t\t\t\t\t\t\\\n\tint __td_index;\t\t\t\t\\\n\tfor (__td_index = 0; __td_index < (int) thread_number; __td_index++)\n#define\tend_for_each()\t}\n\n#define for_each_file(td, f, i)\t\\\n\tif ((td)->files_index)\t\t\t\t\t\t\\\n\t\tfor ((i) = 0, (f) = (td)->files[0];\t\t\t\\\n\t    \t (i) < (td)->o.nr_files && ((f) = (td)->files[i]) != NULL; \\\n\t\t (i)++)\n\nstatic inline bool fio_fill_issue_time(struct thread_data *td)\n{\n\tif (td->o.read_iolog_file ||\n\t    !td->o.disable_clat || !td->o.disable_slat || !td->o.disable_bw)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool option_check_rate(struct thread_data *td, enum fio_ddir ddir)\n{\n\tstruct thread_options *o = &td->o;\n\n\t/*\n\t * If some rate setting was given, we need to check it\n\t */\n\tif (o->rate[ddir] || o->ratemin[ddir] || o->rate_iops[ddir] ||\n\t    o->rate_iops_min[ddir])\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool should_check_rate(struct thread_data *td)\n{\n\treturn (td->flags & TD_F_CHECK_RATE) != 0;\n}\n\nstatic inline unsigned long long td_max_bs(struct thread_data *td)\n{\n\tunsigned long long max_bs;\n\n\tmax_bs = max(td->o.max_bs[DDIR_READ], td->o.max_bs[DDIR_WRITE]);\n\treturn max(td->o.max_bs[DDIR_TRIM], max_bs);\n}\n\nstatic inline unsigned long long td_min_bs(struct thread_data *td)\n{\n\tunsigned long long min_bs;\n\n\tmin_bs = min(td->o.min_bs[DDIR_READ], td->o.min_bs[DDIR_WRITE]);\n\treturn min(td->o.min_bs[DDIR_TRIM], min_bs);\n}\n\nstatic inline bool td_async_processing(struct thread_data *td)\n{\n\treturn (td->flags & TD_F_NEED_LOCK) != 0;\n}\n\nstatic inline bool td_offload_overlap(struct thread_data *td)\n{\n\treturn td->o.serialize_overlap && td->o.io_submit_mode == IO_MODE_OFFLOAD;\n}\n\n/*\n * We currently only need to do locking if we have verifier threads\n * accessing our internal structures too\n */\nstatic inline void __td_io_u_lock(struct thread_data *td)\n{\n\tpthread_mutex_lock(&td->io_u_lock);\n}\n\nstatic inline void __td_io_u_unlock(struct thread_data *td)\n{\n\tpthread_mutex_unlock(&td->io_u_lock);\n}\n\nstatic inline void td_io_u_free_notify(struct thread_data *td)\n{\n\tif (td_async_processing(td))\n\t\tpthread_cond_signal(&td->free_cond);\n}\n\nstatic inline void td_flags_clear(struct thread_data *td, unsigned int *flags,\n\t\t\t\t  unsigned int value)\n{\n\tif (!td_async_processing(td))\n\t\t*flags &= ~value;\n\telse\n\t\t__sync_fetch_and_and(flags, ~value);\n}\n\nstatic inline void td_flags_set(struct thread_data *td, unsigned int *flags,\n\t\t\t\tunsigned int value)\n{\n\tif (!td_async_processing(td))\n\t\t*flags |= value;\n\telse\n\t\t__sync_fetch_and_or(flags, value);\n}\n\nextern const char *fio_get_arch_string(int);\nextern const char *fio_get_os_string(int);\n\nenum {\n\t__FIO_OUTPUT_TERSE\t= 0,\n\t__FIO_OUTPUT_JSON\t= 1,\n\t__FIO_OUTPUT_NORMAL\t= 2,\n        __FIO_OUTPUT_JSON_PLUS  = 3,\n\tFIO_OUTPUT_NR\t\t= 4,\n\n\tFIO_OUTPUT_TERSE\t= 1U << __FIO_OUTPUT_TERSE,\n\tFIO_OUTPUT_JSON\t\t= 1U << __FIO_OUTPUT_JSON,\n\tFIO_OUTPUT_NORMAL\t= 1U << __FIO_OUTPUT_NORMAL,\n\tFIO_OUTPUT_JSON_PLUS    = 1U << __FIO_OUTPUT_JSON_PLUS,\n};\n\nenum {\n\tFIO_RAND_DIST_RANDOM\t= 0,\n\tFIO_RAND_DIST_ZIPF,\n\tFIO_RAND_DIST_PARETO,\n\tFIO_RAND_DIST_GAUSS,\n\tFIO_RAND_DIST_ZONED,\n\tFIO_RAND_DIST_ZONED_ABS,\n};\n\n#define FIO_DEF_ZIPF\t\t1.1\n#define FIO_DEF_PARETO\t\t0.2\n\nenum {\n\tFIO_RAND_GEN_TAUSWORTHE = 0,\n\tFIO_RAND_GEN_LFSR,\n\tFIO_RAND_GEN_TAUSWORTHE64,\n};\n\nenum {\n\tFIO_CPUS_SHARED\t\t= 0,\n\tFIO_CPUS_SPLIT,\n};\n\nextern void exec_trigger(const char *);\nextern void check_trigger_file(void);\n\nextern bool in_flight_overlap(struct io_u_queue *q, struct io_u *io_u);\nextern pthread_mutex_t overlap_check;\n\nstatic inline void *fio_memalign(size_t alignment, size_t size, bool shared)\n{\n\treturn __fio_memalign(alignment, size, shared ? smalloc : malloc);\n}\n\nstatic inline void fio_memfree(void *ptr, size_t size, bool shared)\n{\n\treturn __fio_memfree(ptr, size, shared ? sfree : free);\n}\n\n#endif\n"
        },
        {
          "name": "fio_sem.c",
          "type": "blob",
          "size": 3.3662109375,
          "content": "#include <stdio.h>\n#include <string.h>\n#include <sys/mman.h>\n#include <assert.h>\n#ifdef CONFIG_VALGRIND_DEV\n#include <valgrind/valgrind.h>\n#else\n#define RUNNING_ON_VALGRIND 0\n#endif\n\n#include \"fio_sem.h\"\n#include \"pshared.h\"\n#include \"os/os.h\"\n#include \"fio_time.h\"\n#include \"gettime.h\"\n\nvoid __fio_sem_remove(struct fio_sem *sem)\n{\n\tassert(sem->magic == FIO_SEM_MAGIC);\n\tpthread_mutex_destroy(&sem->lock);\n\tpthread_cond_destroy(&sem->cond);\n\n\t/*\n\t * When not running on Valgrind, ensure any subsequent attempt to grab\n\t * this semaphore will fail with an assert, instead of just silently\n\t * hanging. When running on Valgrind, let Valgrind detect\n\t * use-after-free.\n         */\n\tif (!RUNNING_ON_VALGRIND)\n\t\tmemset(sem, 0, sizeof(*sem));\n}\n\nvoid fio_sem_remove(struct fio_sem *sem)\n{\n\t__fio_sem_remove(sem);\n\tmunmap((void *) sem, sizeof(*sem));\n}\n\nint __fio_sem_init(struct fio_sem *sem, int value)\n{\n\tint ret;\n\n\tsem->value = value;\n\t/* Initialize .waiters explicitly for Valgrind. */\n\tsem->waiters = 0;\n\tsem->magic = FIO_SEM_MAGIC;\n\n\tret = mutex_cond_init_pshared(&sem->lock, &sem->cond);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstruct fio_sem *fio_sem_init(int value)\n{\n\tstruct fio_sem *sem = NULL;\n\n\tsem = (void *) mmap(NULL, sizeof(struct fio_sem),\n\t\t\t\tPROT_READ | PROT_WRITE,\n\t\t\t\tOS_MAP_ANON | MAP_SHARED, -1, 0);\n\tif (sem == MAP_FAILED) {\n\t\tperror(\"mmap semaphore\");\n\t\treturn NULL;\n\t}\n\n\tif (!__fio_sem_init(sem, value))\n\t\treturn sem;\n\n\tfio_sem_remove(sem);\n\treturn NULL;\n}\n\nstatic bool sem_timed_out(struct timespec *t, unsigned int msecs)\n{\n\tstruct timeval tv;\n\tstruct timespec now;\n\n\tgettimeofday(&tv, NULL);\n\tnow.tv_sec = tv.tv_sec;\n\tnow.tv_nsec = tv.tv_usec * 1000;\n\n\treturn mtime_since(t, &now) >= msecs;\n}\n\nint fio_sem_down_timeout(struct fio_sem *sem, unsigned int msecs)\n{\n\tstruct timespec base;\n\tstruct timespec t;\n\tint ret = 0;\n\n\tassert(sem->magic == FIO_SEM_MAGIC);\n\n#ifdef CONFIG_PTHREAD_CONDATTR_SETCLOCK\n\tclock_gettime(CLOCK_MONOTONIC, &t);\n#else\n\tclock_gettime(CLOCK_REALTIME, &t);\n#endif\n\n\tbase = t;\n\n\tt.tv_sec += msecs / 1000;\n\tt.tv_nsec += ((msecs * 1000000ULL) % 1000000000);\n\tif (t.tv_nsec >= 1000000000) {\n\t\tt.tv_nsec -= 1000000000;\n\t\tt.tv_sec++;\n\t}\n\n\tpthread_mutex_lock(&sem->lock);\n\n\tsem->waiters++;\n\twhile (!sem->value && !ret) {\n\t\t/*\n\t\t * Some platforms (FreeBSD 9?) seems to return timed out\n\t\t * way too early, double check.\n\t\t */\n\t\tret = pthread_cond_timedwait(&sem->cond, &sem->lock, &t);\n\t\tif (ret == ETIMEDOUT && !sem_timed_out(&base, msecs))\n\t\t\tret = 0;\n\t}\n\tsem->waiters--;\n\n\tif (!ret) {\n\t\tsem->value--;\n\t\tpthread_mutex_unlock(&sem->lock);\n\t\treturn 0;\n\t}\n\n\tpthread_mutex_unlock(&sem->lock);\n\treturn ret;\n}\n\nbool fio_sem_down_trylock(struct fio_sem *sem)\n{\n\tbool ret = true;\n\n\tassert(sem->magic == FIO_SEM_MAGIC);\n\n\tpthread_mutex_lock(&sem->lock);\n\tif (sem->value) {\n\t\tsem->value--;\n\t\tret = false;\n\t}\n\tpthread_mutex_unlock(&sem->lock);\n\n\treturn ret;\n}\n\nvoid fio_sem_down(struct fio_sem *sem)\n{\n\tassert(sem->magic == FIO_SEM_MAGIC);\n\n\tpthread_mutex_lock(&sem->lock);\n\n\twhile (!sem->value) {\n\t\tsem->waiters++;\n\t\tpthread_cond_wait(&sem->cond, &sem->lock);\n\t\tsem->waiters--;\n\t}\n\n\tsem->value--;\n\tpthread_mutex_unlock(&sem->lock);\n}\n\nvoid fio_sem_up(struct fio_sem *sem)\n{\n\tint do_wake = 0;\n\n\tassert(sem->magic == FIO_SEM_MAGIC);\n\n\tpthread_mutex_lock(&sem->lock);\n\tif (!sem->value && sem->waiters)\n\t\tdo_wake = 1;\n\tsem->value++;\n\n\tif (do_wake)\n\t\tpthread_cond_signal(&sem->cond);\n\n\tpthread_mutex_unlock(&sem->lock);\n}\n"
        },
        {
          "name": "fio_sem.h",
          "type": "blob",
          "size": 0.658203125,
          "content": "#ifndef FIO_SEM_H\n#define FIO_SEM_H\n\n#include <pthread.h>\n#include \"lib/types.h\"\n\n#define FIO_SEM_MAGIC\t\t0x4d555445U\n\nstruct fio_sem {\n\tpthread_mutex_t lock;\n\tpthread_cond_t cond;\n\tint value;\n\tint waiters;\n\tint magic;\n};\n\nenum {\n\tFIO_SEM_LOCKED\t= 0,\n\tFIO_SEM_UNLOCKED\t= 1,\n};\n\nextern int __fio_sem_init(struct fio_sem *, int);\nextern struct fio_sem *fio_sem_init(int);\nextern void __fio_sem_remove(struct fio_sem *);\nextern void fio_sem_remove(struct fio_sem *);\nextern void fio_sem_up(struct fio_sem *);\nextern void fio_sem_down(struct fio_sem *);\nextern bool fio_sem_down_trylock(struct fio_sem *);\nextern int fio_sem_down_timeout(struct fio_sem *, unsigned int);\n\n#endif\n"
        },
        {
          "name": "fio_time.h",
          "type": "blob",
          "size": 1.4423828125,
          "content": "#ifndef FIO_TIME_H\n#define FIO_TIME_H\n\n#include <stdint.h>\n/* IWYU pragma: begin_exports */\n#include <time.h>\n#include <sys/time.h>\n/* IWYU pragma: end_exports */\n#include \"lib/types.h\"\n\nstruct thread_data;\nextern uint64_t ntime_since(const struct timespec *, const struct timespec *);\nextern uint64_t ntime_since_now(const struct timespec *);\nextern uint64_t utime_since(const struct timespec *, const struct timespec *);\nextern uint64_t utime_since_now(const struct timespec *);\nextern int64_t rel_time_since(const struct timespec *,\n\t\t\t      const struct timespec *);\nextern uint64_t mtime_since(const struct timespec *, const struct timespec *);\nextern uint64_t mtime_since_now(const struct timespec *);\nextern uint64_t mtime_since_tv(const struct timeval *, const struct timeval *);\nextern uint64_t time_since_now(const struct timespec *);\nextern uint64_t time_since_genesis(void);\nextern uint64_t mtime_since_genesis(void);\nextern uint64_t utime_since_genesis(void);\nextern void cycles_spin(unsigned int);\nextern uint64_t usec_spin(unsigned int);\nextern uint64_t usec_sleep(struct thread_data *, unsigned long);\nextern void fill_start_time(struct timespec *);\nextern void set_genesis_time(void);\nextern bool ramp_time_over(struct thread_data *);\nextern bool in_ramp_time(struct thread_data *);\nextern void fio_time_init(void);\nextern void timespec_add_msec(struct timespec *, unsigned int);\nextern void set_epoch_time(struct thread_data *, clockid_t, clockid_t);\n\n#endif\n"
        },
        {
          "name": "flist.h",
          "type": "blob",
          "size": 4.98046875,
          "content": "#ifndef _LINUX_FLIST_H\n#define _LINUX_FLIST_H\n\n#include <stdlib.h>\n#include <stddef.h>\n\n#define container_of(ptr, type, member)  ({\t\t\t\\\n\tconst __typeof__( ((type *)0)->member ) *__mptr = (ptr);\t\\\n\t(type *)( (char *)__mptr - offsetof(type,member) );})\n\n/*\n * Simple doubly linked list implementation.\n *\n * Some of the internal functions (\"__xxx\") are useful when\n * manipulating whole lists rather than single entries, as\n * sometimes we already know the next/prev entries and we can\n * generate better code by using them directly rather than\n * using the generic single-entry routines.\n */\n\nstruct flist_head {\n\tstruct flist_head *next, *prev;\n};\n\n#define FLIST_HEAD_INIT(name) { &(name), &(name) }\n\n#define FLIST_HEAD(name) \\\n\tstruct flist_head name = FLIST_HEAD_INIT(name)\n\n#define INIT_FLIST_HEAD(ptr) do { \\\n\t(ptr)->next = (ptr); (ptr)->prev = (ptr); \\\n} while (0)\n\n/*\n * Insert a new entry between two known consecutive entries.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __flist_add(struct flist_head *new_entry,\n\t\t\t       struct flist_head *prev,\n\t\t\t       struct flist_head *next)\n{\n\tnext->prev = new_entry;\n\tnew_entry->next = next;\n\tnew_entry->prev = prev;\n\tprev->next = new_entry;\n}\n\n/**\n * flist_add - add a new entry\n * @new_entry: new entry to be added\n * @head: list head to add it after\n *\n * Insert a new entry after the specified head.\n * This is good for implementing stacks.\n */\nstatic inline void flist_add(struct flist_head *new_entry,\n                             struct flist_head *head)\n{\n\t__flist_add(new_entry, head, head->next);\n}\n\nstatic inline void flist_add_tail(struct flist_head *new_entry,\n\t\t\t\t  struct flist_head *head)\n{\n\t__flist_add(new_entry, head->prev, head);\n}\n\n/*\n * Delete a list entry by making the prev/next entries\n * point to each other.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __flist_del(struct flist_head *prev,\n\t\t\t       struct flist_head * next)\n{\n\tnext->prev = prev;\n\tprev->next = next;\n}\n\n/**\n * flist_del - deletes entry from list.\n * @entry: the element to delete from the list.\n * Note: flist_empty on entry does not return true after this, the entry is\n * in an undefined state.\n */\nstatic inline void flist_del(struct flist_head *entry)\n{\n\t__flist_del(entry->prev, entry->next);\n\tentry->next = NULL;\n\tentry->prev = NULL;\n}\n\n/**\n * flist_del_init - deletes entry from list and reinitialize it.\n * @entry: the element to delete from the list.\n */\nstatic inline void flist_del_init(struct flist_head *entry)\n{\n\t__flist_del(entry->prev, entry->next);\n\tINIT_FLIST_HEAD(entry);\n}\n\n/**\n * flist_empty - tests whether a list is empty\n * @head: the list to test.\n */\nstatic inline int flist_empty(const struct flist_head *head)\n{\n\treturn head->next == head;\n}\n\nstatic inline void __flist_splice(const struct flist_head *list,\n\t\t\t\t  struct flist_head *prev,\n\t\t\t\t  struct flist_head *next)\n{\n\tstruct flist_head *first = list->next;\n\tstruct flist_head *last = list->prev;\n\n\tfirst->prev = prev;\n\tprev->next = first;\n\n\tlast->next = next;\n\tnext->prev = last;\n}\n\nstatic inline void flist_splice(const struct flist_head *list,\n\t\t\t\tstruct flist_head *head)\n{\n\tif (!flist_empty(list))\n\t\t__flist_splice(list, head, head->next);\n}\n\nstatic inline void flist_splice_tail(struct flist_head *list,\n\t\t\t\t     struct flist_head *head)\n{\n\tif (!flist_empty(list))\n\t\t__flist_splice(list, head->prev, head);\n}\n\nstatic inline void flist_splice_tail_init(struct flist_head *list,\n\t\t\t\t\t  struct flist_head *head)\n{\n\tif (!flist_empty(list)) {\n\t\t__flist_splice(list, head->prev, head);\n\t\tINIT_FLIST_HEAD(list);\n\t}\n}\n\nstatic inline void flist_splice_init(struct flist_head *list,\n\t\t\t\t    struct flist_head *head)\n{\n\tif (!flist_empty(list)) {\n\t\t__flist_splice(list, head, head->next);\n\t\tINIT_FLIST_HEAD(list);\n\t}\n}\n\n/**\n * flist_entry - get the struct for this entry\n * @ptr:\tthe &struct flist_head pointer.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the flist_struct within the struct.\n */\n#define flist_entry(ptr, type, member) \\\n\tcontainer_of(ptr, type, member)\n\n#define flist_first_entry(ptr, type, member) \\\n\tflist_entry((ptr)->next, type, member)\n\n#define flist_last_entry(ptr, type, member) \\\n\tflist_entry((ptr)->prev, type, member)\n\n/**\n * flist_for_each\t-\titerate over a list\n * @pos:\tthe &struct flist_head to use as a loop counter.\n * @head:\tthe head for your list.\n */\n#define flist_for_each(pos, head) \\\n\tfor (pos = (head)->next; pos != (head); pos = pos->next)\n\n/**\n * flist_for_each_safe\t-\titerate over a list safe against removal of list entry\n * @pos:\tthe &struct flist_head to use as a loop counter.\n * @n:\t\tanother &struct flist_head to use as temporary storage\n * @head:\tthe head for your list.\n */\n#define flist_for_each_safe(pos, n, head) \\\n\tfor (pos = (head)->next, n = pos->next; pos != (head); \\\n\t\tpos = n, n = pos->next)\n\nextern void flist_sort(void *priv, struct flist_head *head,\n\tint (*cmp)(void *priv, struct flist_head *a, struct flist_head *b));\n\n#endif\n"
        },
        {
          "name": "flow.c",
          "type": "blob",
          "size": 2.9892578125,
          "content": "#include \"fio.h\"\n#include \"fio_sem.h\"\n#include \"smalloc.h\"\n#include \"flist.h\"\n\nstruct fio_flow {\n\tunsigned int refs;\n\tunsigned int id;\n\tstruct flist_head list;\n\tunsigned long flow_counter;\n\tunsigned int total_weight;\n};\n\nstatic struct flist_head *flow_list;\nstatic struct fio_sem *flow_lock;\n\nint flow_threshold_exceeded(struct thread_data *td)\n{\n\tstruct fio_flow *flow = td->flow;\n\tdouble flow_counter_ratio, flow_weight_ratio;\n\n\tif (!flow)\n\t\treturn 0;\n\n\tflow_counter_ratio = (double)td->flow_counter /\n\t\tatomic_load_relaxed(&flow->flow_counter);\n\tflow_weight_ratio = (double)td->o.flow /\n\t\tatomic_load_relaxed(&flow->total_weight);\n\n\t/*\n\t * each thread/process executing a fio job will stall based on the\n\t * expected  user ratio for a given flow_id group. the idea is to keep\n\t * 2 counters, flow and job-specific counter to test if the\n\t * ratio between them is proportional to other jobs in the same flow_id\n\t */\n\tif (flow_counter_ratio > flow_weight_ratio) {\n\t\tif (td->o.flow_sleep) {\n\t\t\tio_u_quiesce(td);\n\t\t\tusleep(td->o.flow_sleep);\n\t\t} else if (td->o.zone_mode == ZONE_MODE_ZBD) {\n\t\t\tio_u_quiesce(td);\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\t/*\n\t * increment flow(shared counter, therefore atomically)\n\t * and job-specific counter\n\t */\n\tatomic_add(&flow->flow_counter, 1);\n\t++td->flow_counter;\n\n\treturn 0;\n}\n\nstatic struct fio_flow *flow_get(unsigned int id)\n{\n\tstruct fio_flow *flow = NULL;\n\tstruct flist_head *n;\n\n\tif (!flow_lock)\n\t\treturn NULL;\n\n\tfio_sem_down(flow_lock);\n\n\tflist_for_each(n, flow_list) {\n\t\tflow = flist_entry(n, struct fio_flow, list);\n\t\tif (flow->id == id)\n\t\t\tbreak;\n\n\t\tflow = NULL;\n\t}\n\n\tif (!flow) {\n\t\tflow = smalloc(sizeof(*flow));\n\t\tif (!flow) {\n\t\t\tfio_sem_up(flow_lock);\n\t\t\treturn NULL;\n\t\t}\n\t\tflow->refs = 0;\n\t\tINIT_FLIST_HEAD(&flow->list);\n\t\tflow->id = id;\n\t\tflow->flow_counter = 1;\n\t\tflow->total_weight = 0;\n\n\t\tflist_add_tail(&flow->list, flow_list);\n\t}\n\n\tflow->refs++;\n\tfio_sem_up(flow_lock);\n\treturn flow;\n}\n\nstatic void flow_put(struct fio_flow *flow, unsigned long flow_counter,\n\t\t\t\t        unsigned int weight)\n{\n\tif (!flow_lock)\n\t\treturn;\n\n\tfio_sem_down(flow_lock);\n\n\tatomic_sub(&flow->flow_counter, flow_counter);\n\tatomic_sub(&flow->total_weight, weight);\n\n\tif (!--flow->refs) {\n\t\tassert(flow->flow_counter == 1);\n\t\tflist_del(&flow->list);\n\t\tsfree(flow);\n\t}\n\n\tfio_sem_up(flow_lock);\n}\n\nvoid flow_init_job(struct thread_data *td)\n{\n\tif (td->o.flow) {\n\t\ttd->flow = flow_get(td->o.flow_id);\n\t\ttd->flow_counter = 0;\n\t\tatomic_add(&td->flow->total_weight, td->o.flow);\n\t}\n}\n\nvoid flow_exit_job(struct thread_data *td)\n{\n\tif (td->flow) {\n\t\tflow_put(td->flow, td->flow_counter, td->o.flow);\n\t\ttd->flow = NULL;\n\t}\n}\n\nvoid flow_init(void)\n{\n\tflow_list = smalloc(sizeof(*flow_list));\n\tif (!flow_list) {\n\t\tlog_err(\"fio: smalloc pool exhausted\\n\");\n\t\treturn;\n\t}\n\n\tflow_lock = fio_sem_init(FIO_SEM_UNLOCKED);\n\tif (!flow_lock) {\n\t\tlog_err(\"fio: failed to allocate flow lock\\n\");\n\t\tsfree(flow_list);\n\t\treturn;\n\t}\n\n\tINIT_FLIST_HEAD(flow_list);\n}\n\nvoid flow_exit(void)\n{\n\tif (flow_lock)\n\t\tfio_sem_remove(flow_lock);\n\tif (flow_list)\n\t\tsfree(flow_list);\n}\n"
        },
        {
          "name": "flow.h",
          "type": "blob",
          "size": 0.2568359375,
          "content": "#ifndef FIO_FLOW_H\n#define FIO_FLOW_H\n\n#define FLOW_MAX_WEIGHT 1000\n\nint flow_threshold_exceeded(struct thread_data *td);\nvoid flow_init_job(struct thread_data *td);\nvoid flow_exit_job(struct thread_data *td);\n\nvoid flow_exit(void);\nvoid flow_init(void);\n\n#endif\n"
        },
        {
          "name": "gclient.c",
          "type": "blob",
          "size": 41.52734375,
          "content": "#include <stdlib.h>\n#include <string.h>\n\n#include <glib.h>\n#include <cairo.h>\n#include <gtk/gtk.h>\n\n#include \"fio.h\"\n#include \"gfio.h\"\n#include \"ghelpers.h\"\n#include \"goptions.h\"\n#include \"gerror.h\"\n#include \"graph.h\"\n#include \"gclient.h\"\n#include \"printing.h\"\n#include \"lib/pow2.h\"\n\nstatic void gfio_display_ts(struct fio_client *client, struct thread_stat *ts,\n\t\t\t    struct group_run_stats *rs);\n\nstatic gboolean results_window_delete(GtkWidget *w, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tgtk_widget_destroy(w);\n\tge->results_window = NULL;\n\tge->results_notebook = NULL;\n\treturn TRUE;\n}\n\nstatic void results_close(GtkWidget *w, gpointer *data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tgtk_widget_destroy(ge->results_window);\n}\n\nstatic void results_print(GtkWidget *w, gpointer *data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tgfio_print_results(ge);\n}\n\nstatic GtkActionEntry results_menu_items[] = {\n\t{ \"FileMenuAction\", GTK_STOCK_FILE, \"File\", NULL, NULL, NULL},\n\t{ \"GraphMenuAction\", GTK_STOCK_FILE, \"Graph\", NULL, NULL, NULL},\n\t{ \"PrintFile\", GTK_STOCK_PRINT, \"Print\", \"<Control>P\", NULL, G_CALLBACK(results_print) },\n\t{ \"CloseFile\", GTK_STOCK_CLOSE, \"Close\", \"<Control>W\", NULL, G_CALLBACK(results_close) },\n};\nstatic gint results_nmenu_items = FIO_ARRAY_SIZE(results_menu_items);\n\nstatic const gchar *results_ui_string = \" \\\n\t<ui> \\\n\t\t<menubar name=\\\"MainMenu\\\"> \\\n\t\t\t<menu name=\\\"FileMenu\\\" action=\\\"FileMenuAction\\\"> \\\n\t\t\t\t<menuitem name=\\\"Print\\\" action=\\\"PrintFile\\\" /> \\\n\t\t\t\t<menuitem name=\\\"Close\\\" action=\\\"CloseFile\\\" /> \\\n\t\t\t</menu> \\\n\t\t\t<menu name=\\\"GraphMenu\\\" action=\\\"GraphMenuAction\\\"> \\\n\t\t\t</menu>\\\n\t\t</menubar> \\\n\t</ui> \\\n\";\n\nstatic GtkWidget *get_results_menubar(GtkWidget *window, struct gui_entry *ge)\n{\n\tGtkActionGroup *action_group;\n\tGtkWidget *widget;\n\tGError *error = 0;\n\n\tge->results_uimanager = gtk_ui_manager_new();\n\n\taction_group = gtk_action_group_new(\"ResultsMenu\");\n\tgtk_action_group_add_actions(action_group, results_menu_items, results_nmenu_items, ge);\n\n\tgtk_ui_manager_insert_action_group(ge->results_uimanager, action_group, 0);\n\tgtk_ui_manager_add_ui_from_string(GTK_UI_MANAGER(ge->results_uimanager), results_ui_string, -1, &error);\n\n\tgtk_window_add_accel_group(GTK_WINDOW(window), gtk_ui_manager_get_accel_group(ge->results_uimanager));\n\n\twidget = gtk_ui_manager_get_widget(ge->results_uimanager, \"/MainMenu\");\n\treturn widget;\n}\n\nstatic GtkWidget *get_results_window(struct gui_entry *ge)\n{\n\tGtkWidget *win, *notebook, *vbox;\n\n\tif (ge->results_window)\n\t\treturn ge->results_notebook;\n\n\twin = gtk_window_new(GTK_WINDOW_TOPLEVEL);\n\tgtk_window_set_title(GTK_WINDOW(win), \"Results\");\n\tgtk_window_set_default_size(GTK_WINDOW(win), 1024, 768);\n\tg_signal_connect(win, \"delete-event\", G_CALLBACK(results_window_delete), ge);\n\tg_signal_connect(win, \"destroy\", G_CALLBACK(results_window_delete), ge);\n\n\tvbox = gtk_vbox_new(FALSE, 0);\n\tgtk_container_add(GTK_CONTAINER(win), vbox);\n\n\tge->results_menu = get_results_menubar(win, ge);\n\tgtk_box_pack_start(GTK_BOX(vbox), ge->results_menu, FALSE, FALSE, 0);\n\n\tnotebook = gtk_notebook_new();\n\tgtk_notebook_set_scrollable(GTK_NOTEBOOK(notebook), 1);\n\tgtk_notebook_popup_enable(GTK_NOTEBOOK(notebook));\n\tgtk_container_add(GTK_CONTAINER(vbox), notebook);\n\n\tge->results_window = win;\n\tge->results_notebook = notebook;\n\treturn ge->results_notebook;\n}\n\nstatic void gfio_text_op(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_text_pdu *p = (struct cmd_text_pdu *) cmd->payload;\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\tstruct gui *ui = ge->ui;\n\tGtkTreeIter iter;\n\tstruct tm *tm;\n\ttime_t sec;\n\tchar tmp[64], timebuf[96];\n\n\tsec = p->log_sec;\n\ttm = localtime(&sec);\n\tstrftime(tmp, sizeof(tmp), \"%Y-%m-%d %H:%M:%S\", tm);\n\tsprintf(timebuf, \"%s.%03ld\", tmp, (long) p->log_usec / 1000);\n\n\tgdk_threads_enter();\n\n\tgtk_list_store_append(ui->log_model, &iter);\n\tgtk_list_store_set(ui->log_model, &iter, 0, timebuf, -1);\n\tgtk_list_store_set(ui->log_model, &iter, 1, client->hostname, -1);\n\tgtk_list_store_set(ui->log_model, &iter, 2, log_get_level(p->level), -1);\n\tgtk_list_store_set(ui->log_model, &iter, 3, p->buf, -1);\n\n\tif (p->level == FIO_LOG_ERR)\n\t\tgfio_view_log(ui);\n\n\tgdk_threads_leave();\n}\n\nstatic void disk_util_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tge->disk_util_vbox = NULL;\n\tgtk_widget_destroy(w);\n}\n\nstatic GtkWidget *gfio_disk_util_get_vbox(struct gui_entry *ge)\n{\n\tGtkWidget *vbox, *box, *scroll, *res_notebook;\n\n\tif (ge->disk_util_vbox)\n\t\treturn ge->disk_util_vbox;\n\n\tscroll = get_scrolled_window(5);\n\tvbox = gtk_vbox_new(FALSE, 3);\n\tbox = gtk_hbox_new(FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(vbox), box, FALSE, FALSE, 5);\n\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scroll), vbox);\n\tres_notebook = get_results_window(ge);\n\n\tgtk_notebook_append_page(GTK_NOTEBOOK(res_notebook), scroll, gtk_label_new(\"Disk utilization\"));\n\tge->disk_util_vbox = box;\n\tg_signal_connect(vbox, \"destroy\", G_CALLBACK(disk_util_destroy), ge);\n\n\treturn ge->disk_util_vbox;\n}\n\nstatic int __gfio_disk_util_show(GtkWidget *res_notebook,\n\t\t\t\t struct gfio_client *gc, struct cmd_du_pdu *p)\n{\n\tGtkWidget *box, *frame, *entry, *vbox, *util_vbox;\n\tstruct gui_entry *ge = gc->ge;\n\tdouble util;\n\tchar tmp[16];\n\n\tutil_vbox = gfio_disk_util_get_vbox(ge);\n\n\tvbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(util_vbox), vbox);\n\n\tframe = gtk_frame_new((char *) p->dus.name);\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 2);\n\n\tbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\tframe = gtk_frame_new(\"Read\");\n\tgtk_box_pack_start(GTK_BOX(box), frame, FALSE, FALSE, 2);\n\tvbox = gtk_hbox_new(TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\tentry = new_info_entry_in_frame(vbox, \"IOs\");\n\tentry_set_int_value(entry, p->dus.s.ios[0]);\n\tentry = new_info_entry_in_frame(vbox, \"Merges\");\n\tentry_set_int_value(entry, p->dus.s.merges[0]);\n\tentry = new_info_entry_in_frame(vbox, \"Sectors\");\n\tentry_set_int_value(entry, p->dus.s.sectors[0]);\n\tentry = new_info_entry_in_frame(vbox, \"Ticks\");\n\tentry_set_int_value(entry, p->dus.s.ticks[0]);\n\n\tframe = gtk_frame_new(\"Write\");\n\tgtk_box_pack_start(GTK_BOX(box), frame, FALSE, FALSE, 2);\n\tvbox = gtk_hbox_new(TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\tentry = new_info_entry_in_frame(vbox, \"IOs\");\n\tentry_set_int_value(entry, p->dus.s.ios[1]);\n\tentry = new_info_entry_in_frame(vbox, \"Merges\");\n\tentry_set_int_value(entry, p->dus.s.merges[1]);\n\tentry = new_info_entry_in_frame(vbox, \"Sectors\");\n\tentry_set_int_value(entry, p->dus.s.sectors[1]);\n\tentry = new_info_entry_in_frame(vbox, \"Ticks\");\n\tentry_set_int_value(entry, p->dus.s.ticks[1]);\n\n\tframe = gtk_frame_new(\"Shared\");\n\tgtk_box_pack_start(GTK_BOX(box), frame, FALSE, FALSE, 2);\n\tvbox = gtk_hbox_new(TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\tentry = new_info_entry_in_frame(vbox, \"IO ticks\");\n\tentry_set_int_value(entry, p->dus.s.io_ticks);\n\tentry = new_info_entry_in_frame(vbox, \"Time in queue\");\n\tentry_set_int_value(entry, p->dus.s.time_in_queue);\n\n\tutil = 0.0;\n\tif (p->dus.s.msec)\n\t\tutil = (double) 100 * p->dus.s.io_ticks / (double) p->dus.s.msec;\n\tif (util > 100.0)\n\t\tutil = 100.0;\n\n\tsprintf(tmp, \"%3.2f%%\", util);\n\tentry = new_info_entry_in_frame(vbox, \"Disk utilization\");\n\tgtk_entry_set_text(GTK_ENTRY(entry), tmp);\n\n\tgtk_widget_show_all(ge->results_window);\n\treturn 0;\n}\n\nstatic int gfio_disk_util_show(struct gfio_client *gc)\n{\n\tstruct gui_entry *ge = gc->ge;\n\tGtkWidget *res_notebook;\n\tint i;\n\n\tif (!gc->nr_du)\n\t\treturn 1;\n\n\tres_notebook = get_results_window(ge);\n\n\tfor (i = 0; i < gc->nr_du; i++) {\n\t\tstruct cmd_du_pdu *p = &gc->du[i];\n\n\t\t__gfio_disk_util_show(res_notebook, gc, p);\n\t}\n\n\tgtk_widget_show_all(ge->results_window);\n\treturn 0;\n}\n\nstatic void gfio_disk_util_op(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_du_pdu *p = (struct cmd_du_pdu *) cmd->payload;\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\tunsigned int nr = gc->nr_du;\n\n\tgc->du = realloc(gc->du, (nr + 1) * sizeof(struct cmd_du_pdu));\n\tmemcpy(&gc->du[nr], p, sizeof(*p));\n\tgc->nr_du++;\n\n\tgdk_threads_enter();\n\tif (ge->results_window)\n\t\t__gfio_disk_util_show(ge->results_notebook, gc, p);\n\telse\n\t\tgfio_disk_util_show(gc);\n\tgdk_threads_leave();\n}\n\nstatic int sum_stat_nr;\n\nstatic void gfio_thread_status_op(struct fio_client *client,\n\t\t\t\t  struct fio_net_cmd *cmd)\n{\n\tstruct cmd_ts_pdu *p = (struct cmd_ts_pdu *) cmd->payload;\n\n\tgfio_display_ts(client, &p->ts, &p->rs);\n\n\tif (sum_stat_clients == 1)\n\t\treturn;\n\n\tsum_thread_stats(&client_ts, &p->ts);\n\tsum_group_stats(&client_gs, &p->rs);\n\n\tclient_ts.members++;\n\tclient_ts.thread_number = p->ts.thread_number;\n\tclient_ts.groupid = p->ts.groupid;\n\tclient_ts.sig_figs = p->ts.sig_figs;\n\n\tif (++sum_stat_nr == sum_stat_clients) {\n\t\tstrcpy(client_ts.name, \"All clients\");\n\t\tgfio_display_ts(client, &client_ts, &client_gs);\n\t}\n}\n\nstatic void gfio_group_stats_op(struct fio_client *client,\n\t\t\t\tstruct fio_net_cmd *cmd)\n{\n\t/* We're ignoring group stats for now */\n}\n\nstatic void gfio_update_thread_status(struct gui_entry *ge,\n\t\t\t\t      char *status_message, double perc)\n{\n\tstatic char message[100];\n\tconst char *m = message;\n\n\tsnprintf(message, sizeof(message), \"%s\", status_message);\n\tgtk_progress_bar_set_text(GTK_PROGRESS_BAR(ge->thread_status_pb), m);\n\tgtk_progress_bar_set_fraction(GTK_PROGRESS_BAR(ge->thread_status_pb), perc / 100.0);\n\tgtk_widget_queue_draw(ge->ui->window);\n}\n\nstatic void gfio_update_thread_status_all(struct gui *ui, char *status_message,\n\t\t\t\t\t  double perc)\n{\n\tstatic char message[100];\n\tconst char *m = message;\n\n\tsnprintf(message, sizeof(message), \"%s\", status_message);\n\tgtk_progress_bar_set_text(GTK_PROGRESS_BAR(ui->thread_status_pb), m);\n\tgtk_progress_bar_set_fraction(GTK_PROGRESS_BAR(ui->thread_status_pb), perc / 100.0);\n\tgtk_widget_queue_draw(ui->window);\n}\n\n/*\n * Client specific ETA\n */\nstatic void gfio_update_client_eta(struct fio_client *client, struct jobs_eta *je)\n{\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\tstatic int eta_good;\n\tchar eta_str[128];\n\tchar output[256];\n\tchar tmp[32];\n\tdouble perc = 0.0;\n\tint i2p = 0;\n\n\tgdk_threads_enter();\n\n\teta_str[0] = '\\0';\n\toutput[0] = '\\0';\n\n\tif (je->eta_sec != INT_MAX && je->elapsed_sec) {\n\t\tperc = (double) je->elapsed_sec / (double) (je->elapsed_sec + je->eta_sec);\n\t\teta_to_str(eta_str, je->eta_sec);\n\t}\n\n\tsprintf(tmp, \"%u\", je->nr_running);\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.jobs), tmp);\n\tsprintf(tmp, \"%u\", je->files_open);\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.files), tmp);\n\n\tif (je->eta_sec != INT_MAX && je->nr_running) {\n\t\tchar *iops_str[DDIR_RWDIR_CNT];\n\t\tchar *rate_str[DDIR_RWDIR_CNT];\n\t\tchar *rate_alt[DDIR_RWDIR_CNT];\n\t\tchar tmp[128];\n\t\tint i;\n\n\t\tif ((!je->eta_sec && !eta_good) || je->nr_ramp == je->nr_running)\n\t\t\tstrcpy(output, \"-.-% done\");\n\t\telse {\n\t\t\teta_good = 1;\n\t\t\tperc *= 100.0;\n\t\t\tsprintf(output, \"%3.1f%% done\", perc);\n\t\t}\n\n\t\tiops_str[0] = num2str(je->iops[0], je->sig_figs, 1, 0, N2S_PERSEC);\n\t\tiops_str[1] = num2str(je->iops[1], je->sig_figs, 1, 0, N2S_PERSEC);\n\t\tiops_str[2] = num2str(je->iops[2], je->sig_figs, 1, 0, N2S_PERSEC);\n\n\t\trate_str[0] = num2str(je->rate[0], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[0] = num2str(je->rate[0], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[0], rate_alt[0]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.read_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.read_iops), iops_str[0]);\n\n\t\trate_str[1] = num2str(je->rate[1], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[1] = num2str(je->rate[1], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[1], rate_alt[1]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.write_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.write_iops), iops_str[1]);\n\n\t\trate_str[2] = num2str(je->rate[2], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[2] = num2str(je->rate[2], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[2], rate_alt[2]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.trim_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ge->eta.trim_iops), iops_str[2]);\n\n\t\tgraph_add_xy_data(ge->graphs.iops_graph, ge->graphs.read_iops, je->elapsed_sec, je->iops[0], iops_str[0]);\n\t\tgraph_add_xy_data(ge->graphs.iops_graph, ge->graphs.write_iops, je->elapsed_sec, je->iops[1], iops_str[1]);\n\t\tgraph_add_xy_data(ge->graphs.iops_graph, ge->graphs.trim_iops, je->elapsed_sec, je->iops[2], iops_str[2]);\n\t\tgraph_add_xy_data(ge->graphs.bandwidth_graph, ge->graphs.read_bw, je->elapsed_sec, je->rate[0], rate_str[0]);\n\t\tgraph_add_xy_data(ge->graphs.bandwidth_graph, ge->graphs.write_bw, je->elapsed_sec, je->rate[1], rate_str[1]);\n\t\tgraph_add_xy_data(ge->graphs.bandwidth_graph, ge->graphs.trim_bw, je->elapsed_sec, je->rate[2], rate_str[2]);\n\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tfree(rate_str[i]);\n\t\t\tfree(rate_alt[i]);\n\t\t\tfree(iops_str[i]);\n\t\t}\n\t}\n\n\tif (eta_str[0]) {\n\t\tchar *dst = output + strlen(output);\n\n\t\tsprintf(dst, \" - %s\", eta_str);\n\t}\n\n\tgfio_update_thread_status(ge, output, perc);\n\tgdk_threads_leave();\n}\n\n/*\n * Update ETA in main window for all clients\n */\nstatic void gfio_update_all_eta(struct jobs_eta *je)\n{\n\tstruct gui *ui = &main_ui;\n\tstatic int eta_good;\n\tchar eta_str[128];\n\tchar output[256];\n\tdouble perc = 0.0;\n\tint i, i2p = 0;\n\n\tgdk_threads_enter();\n\n\teta_str[0] = '\\0';\n\toutput[0] = '\\0';\n\n\tif (je->eta_sec != INT_MAX && je->elapsed_sec) {\n\t\tperc = (double) je->elapsed_sec / (double) (je->elapsed_sec + je->eta_sec);\n\t\teta_to_str(eta_str, je->eta_sec);\n\t}\n\n\tentry_set_int_value(ui->eta.jobs, je->nr_running);\n\n\tif (je->eta_sec != INT_MAX && je->nr_running) {\n\t\tchar *iops_str[DDIR_RWDIR_CNT];\n\t\tchar *rate_str[DDIR_RWDIR_CNT];\n\t\tchar *rate_alt[DDIR_RWDIR_CNT];\n\t\tchar tmp[128];\n\n\t\tif ((!je->eta_sec && !eta_good) || je->nr_ramp == je->nr_running)\n\t\t\tstrcpy(output, \"-.-% done\");\n\t\telse {\n\t\t\teta_good = 1;\n\t\t\tperc *= 100.0;\n\t\t\tsprintf(output, \"%3.1f%% done\", perc);\n\t\t}\n\n\t\tiops_str[0] = num2str(je->iops[0], je->sig_figs, 1, 0, N2S_PERSEC);\n\t\tiops_str[1] = num2str(je->iops[1], je->sig_figs, 1, 0, N2S_PERSEC);\n\t\tiops_str[2] = num2str(je->iops[2], je->sig_figs, 1, 0, N2S_PERSEC);\n\n\t\trate_str[0] = num2str(je->rate[0], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[0] = num2str(je->rate[0], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[0], rate_alt[0]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.read_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.read_iops), iops_str[0]);\n\n\t\trate_str[1] = num2str(je->rate[1], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[1] = num2str(je->rate[1], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[1], rate_alt[1]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.write_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.write_iops), iops_str[1]);\n\n\t\trate_str[2] = num2str(je->rate[2], je->sig_figs, 10, i2p, N2S_BYTEPERSEC);\n\t\trate_alt[2] = num2str(je->rate[2], je->sig_figs, 10, !i2p, N2S_BYTEPERSEC);\n\t\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", rate_str[2], rate_alt[2]);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.trim_bw), tmp);\n\t\tgtk_entry_set_text(GTK_ENTRY(ui->eta.trim_iops), iops_str[2]);\n\n\t\tgraph_add_xy_data(ui->graphs.iops_graph, ui->graphs.read_iops, je->elapsed_sec, je->iops[0], iops_str[0]);\n\t\tgraph_add_xy_data(ui->graphs.iops_graph, ui->graphs.write_iops, je->elapsed_sec, je->iops[1], iops_str[1]);\n\t\tgraph_add_xy_data(ui->graphs.iops_graph, ui->graphs.trim_iops, je->elapsed_sec, je->iops[2], iops_str[2]);\n\t\tgraph_add_xy_data(ui->graphs.bandwidth_graph, ui->graphs.read_bw, je->elapsed_sec, je->rate[0], rate_str[0]);\n\t\tgraph_add_xy_data(ui->graphs.bandwidth_graph, ui->graphs.write_bw, je->elapsed_sec, je->rate[1], rate_str[1]);\n\t\tgraph_add_xy_data(ui->graphs.bandwidth_graph, ui->graphs.trim_bw, je->elapsed_sec, je->rate[2], rate_str[2]);\n\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tfree(rate_str[i]);\n\t\t\tfree(rate_alt[i]);\n\t\t\tfree(iops_str[i]);\n\t\t}\n\t}\n\n\tif (eta_str[0]) {\n\t\tchar *dst = output + strlen(output);\n\n\t\tsprintf(dst, \" - %s\", eta_str);\n\t}\n\n\tgfio_update_thread_status_all(ui, output, perc);\n\tgdk_threads_leave();\n}\n\nstatic void gfio_probe_op(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_probe_reply_pdu *probe = (struct cmd_probe_reply_pdu *) cmd->payload;\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\tconst char *os, *arch;\n\n\tos = fio_get_os_string(probe->os);\n\tif (!os)\n\t\tos = \"unknown\";\n\n\tarch = fio_get_arch_string(probe->arch);\n\tif (!arch)\n\t\tos = \"unknown\";\n\n\tif (!client->name)\n\t\tclient->name = strdup((char *) probe->hostname);\n\n\tgc->client_cpus = le32_to_cpu(probe->cpus);\n\tgc->client_flags = le64_to_cpu(probe->flags);\n\n\tgdk_threads_enter();\n\n\tgtk_label_set_text(GTK_LABEL(ge->probe.hostname), (char *) probe->hostname);\n\tgtk_label_set_text(GTK_LABEL(ge->probe.os), os);\n\tgtk_label_set_text(GTK_LABEL(ge->probe.arch), arch);\n\tgtk_label_set_text(GTK_LABEL(ge->probe.fio_ver), (char *) probe->fio_version);\n\n\tgfio_set_state(ge, GE_STATE_CONNECTED);\n\n\tgdk_threads_leave();\n}\n\nstatic void gfio_quit_op(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct gfio_client *gc = client->client_data;\n\n\tgdk_threads_enter();\n\tgfio_set_state(gc->ge, GE_STATE_NEW);\n\tgdk_threads_leave();\n}\n\nstatic struct thread_options *gfio_client_add_job(struct gfio_client *gc,\n\t\t\tstruct thread_options_pack *top, size_t top_sz)\n{\n\tstruct gfio_client_options *gco;\n\n\tgco = calloc(1, sizeof(*gco));\n\tif (convert_thread_options_to_cpu(&gco->o, top, top_sz)) {\n\t\tdprint(FD_NET, \"client: failed parsing add_job command\\n\");\n\t\treturn NULL;\n\t}\n\tINIT_FLIST_HEAD(&gco->list);\n\tflist_add_tail(&gco->list, &gc->o_list);\n\tgc->o_list_nr = 1;\n\treturn &gco->o;\n}\n\nstatic void gfio_add_job_op(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct cmd_add_job_pdu *p = (struct cmd_add_job_pdu *) cmd->payload;\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\tstruct thread_options *o;\n\tchar *c1, *c2, *c3, *c4;\n\tchar tmp[80];\n\tint i2p;\n\n\tp->thread_number = le32_to_cpu(p->thread_number);\n\tp->groupid = le32_to_cpu(p->groupid);\n\to = gfio_client_add_job(gc, &p->top,\n\t\t\tcmd->pdu_len - offsetof(struct cmd_add_job_pdu, top));\n\tif (o == NULL)\n\t\treturn;\n\n\tgdk_threads_enter();\n\n\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(ge->eta.names), (gchar *) o->name);\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(ge->eta.names), 0);\n\n\tsprintf(tmp, \"%s %s\", o->odirect ? \"direct\" : \"buffered\", ddir_str(o->td_ddir));\n\tmultitext_add_entry(&ge->eta.iotype, tmp);\n\n\ti2p = is_power_of_2(o->kb_base);\n\tc1 = num2str(o->min_bs[DDIR_READ], o->sig_figs, 1, i2p, N2S_BYTE);\n\tc2 = num2str(o->max_bs[DDIR_READ], o->sig_figs, 1, i2p, N2S_BYTE);\n\tc3 = num2str(o->min_bs[DDIR_WRITE], o->sig_figs, 1, i2p, N2S_BYTE);\n\tc4 = num2str(o->max_bs[DDIR_WRITE], o->sig_figs, 1, i2p, N2S_BYTE);\n\n\tsprintf(tmp, \"%s-%s,%s-%s\", c1, c2, c3, c4);\n\tfree(c1);\n\tfree(c2);\n\tfree(c3);\n\tfree(c4);\n\tmultitext_add_entry(&ge->eta.bs, tmp);\n\n\tmultitext_add_entry(&ge->eta.ioengine, (const char *) o->ioengine);\n\n\tsprintf(tmp, \"%u\", o->iodepth);\n\tmultitext_add_entry(&ge->eta.iodepth, tmp);\n\n\tmultitext_set_entry(&ge->eta.iotype, 0);\n\tmultitext_set_entry(&ge->eta.bs, 0);\n\tmultitext_set_entry(&ge->eta.ioengine, 0);\n\tmultitext_set_entry(&ge->eta.iodepth, 0);\n\n\tgfio_set_state(ge, GE_STATE_JOB_SENT);\n\n\tgdk_threads_leave();\n}\n\nstatic void gfio_update_job_op(struct fio_client *client,\n\t\t\t       struct fio_net_cmd *cmd)\n{\n\tuint32_t *pdu_error = (uint32_t *) cmd->payload;\n\tstruct gfio_client *gc = client->client_data;\n\n\tgc->update_job_status = le32_to_cpu(*pdu_error);\n\tgc->update_job_done = 1;\n}\n\nstatic void gfio_client_timed_out(struct fio_client *client)\n{\n\tstruct gfio_client *gc = client->client_data;\n\tchar buf[256];\n\n\tgdk_threads_enter();\n\n\tgfio_set_state(gc->ge, GE_STATE_NEW);\n\tclear_ge_ui_info(gc->ge);\n\n\tsprintf(buf, \"Client %s: timeout talking to server.\\n\", client->hostname);\n\tgfio_report_info(gc->ge->ui, \"Network timeout\", buf);\n\n\tgdk_threads_leave();\n}\n\nstatic void gfio_client_stop(struct fio_client *client)\n{\n\tstruct gfio_client *gc = client->client_data;\n\n\tgdk_threads_enter();\n\n\tgfio_set_state(gc->ge, GE_STATE_JOB_DONE);\n\n\tif (gc->err_entry)\n\t\tentry_set_int_value(gc->err_entry, client->error);\n\n\tgdk_threads_leave();\n}\n\nstatic void gfio_client_start(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct gfio_client *gc = client->client_data;\n\n\tgdk_threads_enter();\n\tgfio_set_state(gc->ge, GE_STATE_JOB_STARTED);\n\tgdk_threads_leave();\n}\n\nstatic void gfio_client_job_start(struct fio_client *client, struct fio_net_cmd *cmd)\n{\n\tstruct gfio_client *gc = client->client_data;\n\n\tgdk_threads_enter();\n\tgfio_set_state(gc->ge, GE_STATE_JOB_RUNNING);\n\tgdk_threads_leave();\n}\n\nstatic void gfio_add_total_depths_tree(GtkListStore *model,\n\t\t\t\t       struct thread_stat *ts, unsigned int len)\n{\n\tdouble io_u_dist[FIO_IO_U_MAP_NR];\n\tGtkTreeIter iter;\n\t/* Bits 1-6, and 8 */\n\tconst int add_mask = 0x17e;\n\tint i, j;\n\n\tstat_calc_dist(ts->io_u_map, ddir_rw_sum(ts->total_io_u), io_u_dist);\n\n\tgtk_list_store_append(model, &iter);\n\n\tgtk_list_store_set(model, &iter, 0, \"Total\", -1);\n\n\tfor (i = 1, j = 0; i < len; i++) {\n\t\tchar fbuf[32];\n\n\t\tif (!(add_mask & (1UL << (i - 1))))\n\t\t\tsprintf(fbuf, \"0.0%%\");\n\t\telse {\n\t\t\tsprintf(fbuf, \"%3.1f%%\", io_u_dist[j]);\n\t\t\tj++;\n\t\t}\n\n\t\tgtk_list_store_set(model, &iter, i, fbuf, -1);\n\t}\n\n}\n\nstatic void gfio_add_end_results(struct gfio_client *gc, struct thread_stat *ts,\n\t\t\t\t struct group_run_stats *rs)\n{\n\tunsigned int nr = gc->nr_results;\n\n\tgc->results = realloc(gc->results, (nr + 1) * sizeof(struct end_results));\n\tmemcpy(&gc->results[nr].ts, ts, sizeof(*ts));\n\tmemcpy(&gc->results[nr].gs, rs, sizeof(*rs));\n\tgc->nr_results++;\n}\n\nstatic void gfio_add_sc_depths_tree(GtkListStore *model,\n\t\t\t\t    struct thread_stat *ts, unsigned int len,\n\t\t\t\t    int submit)\n{\n\tdouble io_u_dist[FIO_IO_U_MAP_NR];\n\tGtkTreeIter iter;\n\t/* Bits 0, and 3-8 */\n\tconst int add_mask = 0x1f9;\n\tint i, j;\n\n\tif (submit)\n\t\tstat_calc_dist(ts->io_u_submit, ts->total_submit, io_u_dist);\n\telse\n\t\tstat_calc_dist(ts->io_u_complete, ts->total_complete, io_u_dist);\n\n\tgtk_list_store_append(model, &iter);\n\n\tgtk_list_store_set(model, &iter, 0, submit ? \"Submit\" : \"Complete\", -1);\n\n\tfor (i = 1, j = 0; i < len; i++) {\n\t\tchar fbuf[32];\n\n\t\tif (!(add_mask & (1UL << (i - 1))))\n\t\t\tsprintf(fbuf, \"0.0%%\");\n\t\telse {\n\t\t\tsprintf(fbuf, \"%3.1f%%\", io_u_dist[j]);\n\t\t\tj++;\n\t\t}\n\n\t\tgtk_list_store_set(model, &iter, i, fbuf, -1);\n\t}\n\n}\n\nstatic void gfio_show_io_depths(GtkWidget *vbox, struct thread_stat *ts)\n{\n\tGtkWidget *frame, *box, *tree_view = NULL;\n\tGtkTreeSelection *selection;\n\tGtkListStore *model;\n\tint i;\n\tconst char *labels[] = { \"Depth\", \"0\", \"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \">= 64\" };\n\tconst int nr_labels = FIO_ARRAY_SIZE(labels);\n\tGType types[nr_labels];\n\n\tframe = gtk_frame_new(\"IO depths\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\tbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\tfor (i = 0; i < nr_labels; i++)\n\t\ttypes[i] = G_TYPE_STRING;\n\n\tmodel = gtk_list_store_newv(nr_labels, types);\n\n\ttree_view = gtk_tree_view_new_with_model(GTK_TREE_MODEL(model));\n\tgtk_widget_set_can_focus(tree_view, FALSE);\n\n\tg_object_set(G_OBJECT(tree_view), \"headers-visible\", TRUE,\n\t\t\"enable-grid-lines\", GTK_TREE_VIEW_GRID_LINES_BOTH, NULL);\n\n\tselection = gtk_tree_view_get_selection(GTK_TREE_VIEW(tree_view));\n\tgtk_tree_selection_set_mode(GTK_TREE_SELECTION(selection), GTK_SELECTION_BROWSE);\n\n\tfor (i = 0; i < nr_labels; i++)\n\t\ttree_view_column(tree_view, i, labels[i], ALIGN_RIGHT | UNSORTABLE);\n\n\tgfio_add_total_depths_tree(model, ts, nr_labels);\n\tgfio_add_sc_depths_tree(model, ts, nr_labels, 1);\n\tgfio_add_sc_depths_tree(model, ts, nr_labels, 0);\n\n\tgtk_box_pack_start(GTK_BOX(box), tree_view, TRUE, TRUE, 3);\n}\n\nstatic void gfio_show_cpu_usage(GtkWidget *vbox, struct thread_stat *ts)\n{\n\tGtkWidget *box, *frame, *entry;\n\tdouble usr_cpu, sys_cpu;\n\tunsigned long runtime;\n\tchar tmp[32];\n\n\truntime = ts->total_run_time;\n\tif (runtime) {\n\t\tdouble runt = (double) runtime;\n\n\t\tusr_cpu = (double) ts->usr_time * 100 / runt;\n\t\tsys_cpu = (double) ts->sys_time * 100 / runt;\n\t} else {\n\t\tusr_cpu = 0;\n\t\tsys_cpu = 0;\n\t}\n\n\tframe = gtk_frame_new(\"OS resources\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\tbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\tentry = new_info_entry_in_frame(box, \"User CPU\");\n\tsprintf(tmp, \"%3.2f%%\", usr_cpu);\n\tgtk_entry_set_text(GTK_ENTRY(entry), tmp);\n\tentry = new_info_entry_in_frame(box, \"System CPU\");\n\tsprintf(tmp, \"%3.2f%%\", sys_cpu);\n\tgtk_entry_set_text(GTK_ENTRY(entry), tmp);\n\tentry = new_info_entry_in_frame(box, \"Context switches\");\n\tentry_set_int_value(entry, ts->ctx);\n\tentry = new_info_entry_in_frame(box, \"Major faults\");\n\tentry_set_int_value(entry, ts->majf);\n\tentry = new_info_entry_in_frame(box, \"Minor faults\");\n\tentry_set_int_value(entry, ts->minf);\n}\n\nstatic GtkWidget *gfio_output_lat_buckets(double *lat, const char **labels,\n\t\t\t\t\t  int num)\n{\n\tGtkWidget *tree_view;\n\tGtkTreeSelection *selection;\n\tGtkListStore *model;\n\tGtkTreeIter iter;\n\tGType *types;\n\tint i;\n\n\ttypes = malloc(num * sizeof(GType));\n\n\tfor (i = 0; i < num; i++)\n\t\ttypes[i] = G_TYPE_STRING;\n\n\tmodel = gtk_list_store_newv(num, types);\n\tfree(types);\n\ttypes = NULL;\n\n\ttree_view = gtk_tree_view_new_with_model(GTK_TREE_MODEL(model));\n\tgtk_widget_set_can_focus(tree_view, FALSE);\n\n\tg_object_set(G_OBJECT(tree_view), \"headers-visible\", TRUE,\n\t\t\"enable-grid-lines\", GTK_TREE_VIEW_GRID_LINES_BOTH, NULL);\n\n\tselection = gtk_tree_view_get_selection(GTK_TREE_VIEW(tree_view));\n\tgtk_tree_selection_set_mode(GTK_TREE_SELECTION(selection), GTK_SELECTION_BROWSE);\n\n\tfor (i = 0; i < num; i++)\n\t\ttree_view_column(tree_view, i, labels[i], ALIGN_RIGHT | UNSORTABLE);\n\n\tgtk_list_store_append(model, &iter);\n\n\tfor (i = 0; i < num; i++) {\n\t\tchar fbuf[32];\n\n\t\tif (lat[i] <= 0.0)\n\t\t\tsprintf(fbuf, \"0.00\");\n\t\telse\n\t\t\tsprintf(fbuf, \"%3.2f%%\", lat[i]);\n\n\t\tgtk_list_store_set(model, &iter, i, fbuf, -1);\n\t}\n\n\treturn tree_view;\n}\n\nstatic struct graph *setup_lat_bucket_graph(const char *title, double *lat,\n\t\t\t\t\t    const char **labels,\n\t\t\t\t\t    unsigned int len,\n\t\t\t\t\t    double xdim, double ydim)\n{\n\tstruct graph *g;\n\tint i;\n\n\tg = graph_new(xdim, ydim, gfio_graph_font);\n\tgraph_title(g, title);\n\tgraph_x_title(g, \"Buckets\");\n\tgraph_y_title(g, \"Percent\");\n\n\tfor (i = 0; i < len; i++) {\n\t\tgraph_label_t l;\n\n\t\tl = graph_add_label(g, labels[i]);\n\t\tgraph_add_data(g, l, lat[i]);\n\t}\n\n\treturn g;\n}\n\nstatic int on_expose_lat_drawing_area(GtkWidget *w, GdkEvent *event, gpointer p)\n{\n\tstruct graph *g = p;\n\tcairo_t *cr;\n\n\tcr = gdk_cairo_create(gtk_widget_get_window(w));\n#if 0\n\tif (graph_has_tooltips(g)) {\n\t\tg_object_set(w, \"has-tooltip\", TRUE, NULL);\n\t\tg_signal_connect(w, \"query-tooltip\", G_CALLBACK(clat_graph_tooltip), g);\n\t}\n#endif\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tbar_graph_draw(g, cr);\n\tcairo_destroy(cr);\n\n\treturn FALSE;\n}\n\nstatic gint on_config_lat_drawing_area(GtkWidget *w, GdkEventConfigure *event,\n\t\t\t\t       gpointer data)\n{\n\tguint width = gtk_widget_get_allocated_width(w);\n\tguint height = gtk_widget_get_allocated_height(w);\n\tstruct graph *g = data;\n\n\tgraph_set_size(g, width, height);\n\tgraph_set_size(g, width, height);\n\tgraph_set_position(g, 0, 0);\n\treturn TRUE;\n}\n\nstatic void gfio_show_latency_buckets(struct gfio_client *gc, GtkWidget *vbox,\n\t\t\t\t      struct thread_stat *ts)\n{\n\tdouble io_u_lat[FIO_IO_U_LAT_N_NR + FIO_IO_U_LAT_U_NR + FIO_IO_U_LAT_M_NR];\n\tconst char *ranges[] = { \"2ns\", \"4ns\", \"10ns\", \"20ns\", \"50ns\", \"100ns\",\n\t\t\t\t \"250ns\", \"500ns\", \"750ns\", \"1000ns\", \"2us\",\n\t\t\t\t \"4us\", \"10us\", \"20us\", \"50us\", \"100us\",\n\t\t\t\t \"250us\", \"500us\", \"750us\", \"1ms\", \"2ms\",\n\t\t\t\t \"4ms\", \"10ms\", \"20ms\", \"50ms\", \"100ms\",\n\t\t\t\t \"250ms\", \"500ms\", \"750ms\", \"1s\", \"2s\", \">= 2s\" };\n\tint start, end, i;\n\tconst int total = FIO_IO_U_LAT_U_NR + FIO_IO_U_LAT_M_NR;\n\tGtkWidget *frame, *tree_view, *hbox, *completion_vbox, *drawing_area;\n\tstruct gui_entry *ge = gc->ge;\n\n\tstat_calc_lat_n(ts, io_u_lat);\n\tstat_calc_lat_u(ts, &io_u_lat[FIO_IO_U_LAT_N_NR]);\n\tstat_calc_lat_m(ts, &io_u_lat[FIO_IO_U_LAT_N_NR + FIO_IO_U_LAT_U_NR]);\n\n\t/*\n\t * Found out which first bucket has entries, and which last bucket\n\t */\n\tstart = end = -1U;\n\tfor (i = 0; i < total; i++) {\n\t\tif (io_u_lat[i] == 0.00)\n\t\t\tcontinue;\n\n\t\tif (start == -1U)\n\t\t\tstart = i;\n\t\tend = i;\n\t}\n\n\t/*\n\t * No entries...\n\t */\n\tif (start == -1U)\n\t\treturn;\n\n\ttree_view = gfio_output_lat_buckets(&io_u_lat[start], &ranges[start], end - start + 1);\n\tge->lat_bucket_graph = setup_lat_bucket_graph(\"Latency buckets\", &io_u_lat[start], &ranges[start], end - start + 1, 700.0, 300.0);\n\n\tframe = gtk_frame_new(\"Latency buckets\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\tcompletion_vbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), completion_vbox);\n\thbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(completion_vbox), hbox);\n\n\tdrawing_area = gtk_drawing_area_new();\n\tgtk_widget_set_size_request(GTK_WIDGET(drawing_area), 700, 300);\n\tgtk_widget_modify_bg(drawing_area, GTK_STATE_NORMAL, &gfio_color_white);\n\tgtk_container_add(GTK_CONTAINER(completion_vbox), drawing_area);\n\tg_signal_connect(G_OBJECT(drawing_area), GFIO_DRAW_EVENT, G_CALLBACK(on_expose_lat_drawing_area), ge->lat_bucket_graph);\n\tg_signal_connect(G_OBJECT(drawing_area), \"configure_event\", G_CALLBACK(on_config_lat_drawing_area), ge->lat_bucket_graph);\n\n\tgtk_box_pack_start(GTK_BOX(hbox), tree_view, TRUE, TRUE, 3);\n}\n\nstatic void gfio_show_lat(GtkWidget *vbox, const char *name, unsigned long long min,\n\t\t\t  unsigned long long max, double mean, double dev)\n{\n\tconst char *base = \"(nsec)\";\n\tGtkWidget *hbox, *label, *frame;\n\tchar *minp, *maxp;\n\tchar tmp[64];\n\n\tif (nsec_to_msec(&min, &max, &mean, &dev))\n\t\tbase = \"(msec)\";\n\telse if (nsec_to_usec(&min, &max, &mean, &dev))\n\t\tbase = \"(usec)\";\n\n\tminp = num2str(min, 6, 1, 0, N2S_NONE);\n\tmaxp = num2str(max, 6, 1, 0, N2S_NONE);\n\n\tsprintf(tmp, \"%s %s\", name, base);\n\tframe = gtk_frame_new(tmp);\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\thbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), hbox);\n\n\tlabel = new_info_label_in_frame(hbox, \"Minimum\");\n\tgtk_label_set_text(GTK_LABEL(label), minp);\n\tlabel = new_info_label_in_frame(hbox, \"Maximum\");\n\tgtk_label_set_text(GTK_LABEL(label), maxp);\n\tlabel = new_info_label_in_frame(hbox, \"Average\");\n\tsprintf(tmp, \"%5.02f\", mean);\n\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\tlabel = new_info_label_in_frame(hbox, \"Standard deviation\");\n\tsprintf(tmp, \"%5.02f\", dev);\n\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\n\tfree(minp);\n\tfree(maxp);\n}\n\nstatic GtkWidget *gfio_output_clat_percentiles(unsigned long long *ovals,\n\t\t\t\t\t       fio_fp64_t *plist,\n\t\t\t\t\t       unsigned int len,\n\t\t\t\t\t       const char *base,\n\t\t\t\t\t       unsigned int scale)\n{\n\tGType types[FIO_IO_U_LIST_MAX_LEN];\n\tGtkWidget *tree_view;\n\tGtkTreeSelection *selection;\n\tGtkListStore *model;\n\tGtkTreeIter iter;\n\tint i, j;\n\n\tfor (i = 0; i < len; i++)\n\t\ttypes[i] = G_TYPE_ULONG;\n\n\tmodel = gtk_list_store_newv(len, types);\n\n\ttree_view = gtk_tree_view_new_with_model(GTK_TREE_MODEL(model));\n\tgtk_widget_set_can_focus(tree_view, FALSE);\n\n\tg_object_set(G_OBJECT(tree_view), \"headers-visible\", TRUE,\n\t\t\"enable-grid-lines\", GTK_TREE_VIEW_GRID_LINES_BOTH, NULL);\n\n\tselection = gtk_tree_view_get_selection(GTK_TREE_VIEW(tree_view));\n\tgtk_tree_selection_set_mode(GTK_TREE_SELECTION(selection), GTK_SELECTION_BROWSE);\n\n\tfor (i = 0; i < len; i++) {\n\t\tchar fbuf[8];\n\n\t\tsprintf(fbuf, \"%2.2f%%\", plist[i].u.f);\n\t\ttree_view_column(tree_view, i, fbuf, ALIGN_RIGHT | UNSORTABLE);\n\t}\n\n\tgtk_list_store_append(model, &iter);\n\n\tfor (i = 0; i < len; i++) {\n\t\tfor (j = 0; j < scale; j++)\n\t\t\tovals[i] = (ovals[i] + 999) / 1000;\n\t\tgtk_list_store_set(model, &iter, i, (unsigned long) ovals[i], -1);\n\t}\n\n\treturn tree_view;\n}\n\nstatic struct graph *setup_clat_graph(char *title, unsigned long long *ovals,\n\t\t\t\t      fio_fp64_t *plist,\n\t\t\t\t      unsigned int len,\n\t\t\t\t      double xdim, double ydim)\n{\n\tstruct graph *g;\n\tint i;\n\n\tg = graph_new(xdim, ydim, gfio_graph_font);\n\tgraph_title(g, title);\n\tgraph_x_title(g, \"Percentile\");\n\tgraph_y_title(g, \"Time\");\n\n\tfor (i = 0; i < len; i++) {\n\t\tgraph_label_t l;\n\t\tchar fbuf[8];\n\n\t\tsprintf(fbuf, \"%2.2f%%\", plist[i].u.f);\n\t\tl = graph_add_label(g, fbuf);\n\t\tgraph_add_data(g, l, (double) ovals[i]);\n\t}\n\n\treturn g;\n}\n\nstatic void gfio_show_clat_percentiles(struct gfio_client *gc,\n\t\t\t\t       GtkWidget *vbox, struct thread_stat *ts,\n\t\t\t\t       int ddir, uint64_t *io_u_plat,\n\t\t\t\t       unsigned long long nr, const char *type)\n{\n\tfio_fp64_t *plist = ts->percentile_list;\n\tunsigned int len, scale_down;\n\tunsigned long long *ovals, minv, maxv;\n\tconst char *base;\n\tGtkWidget *tree_view, *frame, *hbox, *drawing_area, *completion_vbox;\n\tstruct gui_entry *ge = gc->ge;\n\tchar tmp[64];\n\n\tlen = calc_clat_percentiles(io_u_plat, nr, plist, &ovals, &maxv, &minv);\n\tif (!len)\n\t\tgoto out;\n\n\t/*\n\t * We default to nsecs, but if the value range is such that we\n\t * should scale down to usecs or msecs, do that.\n\t */\n        if (minv > 2000000 && maxv > 99999999ULL) {\n                scale_down = 2;\n\t\tbase = \"msec\";\n        } else if (minv > 2000 && maxv > 99999) {\n                scale_down = 1;\n\t\tbase = \"usec\";\n        } else {\n                scale_down = 0;\n\t\tbase = \"nsec\";\n        }\n\n\tsprintf(tmp, \"%s latency percentiles (%s)\", type, base);\n\n\ttree_view = gfio_output_clat_percentiles(ovals, plist, len, base, scale_down);\n\tge->clat_graph = setup_clat_graph(tmp, ovals, plist, len, 700.0, 300.0);\n\n\tframe = gtk_frame_new(tmp);\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\tcompletion_vbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), completion_vbox);\n\thbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(completion_vbox), hbox);\n\tdrawing_area = gtk_drawing_area_new();\n\tgtk_widget_set_size_request(GTK_WIDGET(drawing_area), 700, 300);\n\tgtk_widget_modify_bg(drawing_area, GTK_STATE_NORMAL, &gfio_color_white);\n\tgtk_container_add(GTK_CONTAINER(completion_vbox), drawing_area);\n\tg_signal_connect(G_OBJECT(drawing_area), GFIO_DRAW_EVENT, G_CALLBACK(on_expose_lat_drawing_area), ge->clat_graph);\n\tg_signal_connect(G_OBJECT(drawing_area), \"configure_event\", G_CALLBACK(on_config_lat_drawing_area), ge->clat_graph);\n\n\tgtk_box_pack_start(GTK_BOX(hbox), tree_view, TRUE, TRUE, 3);\nout:\n\tif (ovals)\n\t\tfree(ovals);\n}\n\n#define GFIO_CLAT\t1\n#define GFIO_SLAT\t2\n#define GFIO_LAT\t4\n\nstatic void gfio_show_ddir_status(struct gfio_client *gc, GtkWidget *mbox,\n\t\t\t\t  struct group_run_stats *rs,\n\t\t\t\t  struct thread_stat *ts, int ddir)\n{\n\tconst char *ddir_label[3] = { \"Read\", \"Write\", \"Trim\" };\n\tGtkWidget *frame, *label, *box, *vbox, *main_vbox;\n\tunsigned long long min[3], max[3];\n\tunsigned long runt;\n\tunsigned long long bw, iops;\n\tunsigned int flags = 0;\n\tdouble mean[3], dev[3];\n\tchar *io_p, *io_palt, *bw_p, *bw_palt, *iops_p;\n\tchar tmp[128];\n\tint i2p;\n\n\tif (!ts->runtime[ddir])\n\t\treturn;\n\n\ti2p = is_power_of_2(rs->kb_base);\n\trunt = ts->runtime[ddir];\n\n\tbw = (1000 * ts->io_bytes[ddir]) / runt;\n\n\tiops = (1000 * (uint64_t)ts->total_io_u[ddir]) / runt;\n\tiops_p = num2str(iops, ts->sig_figs, 1, 0, N2S_PERSEC);\n\n\tbox = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(mbox), box, TRUE, FALSE, 3);\n\n\tframe = gtk_frame_new(ddir_label[ddir]);\n\tgtk_box_pack_start(GTK_BOX(box), frame, TRUE, TRUE, 5);\n\n\tmain_vbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), main_vbox);\n\n\tbox = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), box, TRUE, FALSE, 3);\n\n\tlabel = new_info_label_in_frame(box, \"IO\");\n\tio_p = num2str(ts->io_bytes[ddir], ts->sig_figs, 1, i2p, N2S_BYTE);\n\tio_palt = num2str(ts->io_bytes[ddir], ts->sig_figs, 1, !i2p, N2S_BYTE);\n\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", io_p, io_palt);\n\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\n\tlabel = new_info_label_in_frame(box, \"Bandwidth\");\n\tbw_p = num2str(bw, ts->sig_figs, 1, i2p, ts->unit_base);\n\tbw_palt = num2str(bw, ts->sig_figs, 1, !i2p, ts->unit_base);\n\tsnprintf(tmp, sizeof(tmp), \"%s (%s)\", bw_p, bw_palt);\n\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\n\tlabel = new_info_label_in_frame(box, \"IOPS\");\n\tgtk_label_set_text(GTK_LABEL(label), iops_p);\n\tlabel = new_info_label_in_frame(box, \"Runtime (msec)\");\n\tlabel_set_int_value(label, ts->runtime[ddir]);\n\n\tif (calc_lat(&ts->bw_stat[ddir], &min[0], &max[0], &mean[0], &dev[0])) {\n\t\tdouble p_of_agg = 100.0;\n\t\tconst char *bw_str = \"KiB/s\";\n\t\tchar tmp[32];\n\n\t\tif (rs->agg[ddir]) {\n\t\t\tp_of_agg = mean[0] * 100 / (double) rs->agg[ddir];\n\t\t\tif (p_of_agg > 100.0)\n\t\t\t\tp_of_agg = 100.0;\n\t\t}\n\n\t\tif (mean[0] > 1073741824.9) {\n\t\t\tmin[0] /= 1048576.0;\n\t\t\tmax[0] /= 1048576.0;\n\t\t\tmean[0] /= 1048576.0;\n\t\t\tdev[0] /= 1048576.0;\n\t\t\tbw_str = \"GiB/s\";\n\t\t}\n\n\t\tif (mean[0] > 1047575.9) {\n\t\t\tmin[0] /= 1024.0;\n\t\t\tmax[0] /= 1024.0;\n\t\t\tmean[0] /= 1024.0;\n\t\t\tdev[0] /= 1024.0;\n\t\t\tbw_str = \"MiB/s\";\n\t\t}\n\t\tsprintf(tmp, \"Bandwidth (%s)\", bw_str);\n\t\tframe = gtk_frame_new(tmp);\n\t\tgtk_box_pack_start(GTK_BOX(main_vbox), frame, FALSE, FALSE, 5);\n\n\t\tbox = gtk_hbox_new(FALSE, 3);\n\t\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\t\tlabel = new_info_label_in_frame(box, \"Minimum\");\n\t\tlabel_set_int_value(label, min[0]);\n\t\tlabel = new_info_label_in_frame(box, \"Maximum\");\n\t\tlabel_set_int_value(label, max[0]);\n\t\tlabel = new_info_label_in_frame(box, \"Percentage of jobs\");\n\t\tsprintf(tmp, \"%3.2f%%\", p_of_agg);\n\t\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\t\tlabel = new_info_label_in_frame(box, \"Average\");\n\t\tsprintf(tmp, \"%5.02f\", mean[0]);\n\t\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\t\tlabel = new_info_label_in_frame(box, \"Standard deviation\");\n\t\tsprintf(tmp, \"%5.02f\", dev[0]);\n\t\tgtk_label_set_text(GTK_LABEL(label), tmp);\n\t}\n\n\tif (calc_lat(&ts->slat_stat[ddir], &min[0], &max[0], &mean[0], &dev[0]))\n\t\tflags |= GFIO_SLAT;\n\tif (calc_lat(&ts->clat_stat[ddir], &min[1], &max[1], &mean[1], &dev[1]))\n\t\tflags |= GFIO_CLAT;\n\tif (calc_lat(&ts->lat_stat[ddir], &min[2], &max[2], &mean[2], &dev[2]))\n\t\tflags |= GFIO_LAT;\n\n\tif (flags) {\n\t\tframe = gtk_frame_new(\"Latency\");\n\t\tgtk_box_pack_start(GTK_BOX(main_vbox), frame, FALSE, FALSE, 5);\n\n\t\tvbox = gtk_vbox_new(FALSE, 3);\n\t\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\n\t\tif (flags & GFIO_SLAT)\n\t\t\tgfio_show_lat(vbox, \"Submission latency\", min[0], max[0], mean[0], dev[0]);\n\t\tif (flags & GFIO_CLAT)\n\t\t\tgfio_show_lat(vbox, \"Completion latency\", min[1], max[1], mean[1], dev[1]);\n\t\tif (flags & GFIO_LAT)\n\t\t\tgfio_show_lat(vbox, \"Total latency\", min[2], max[2], mean[2], dev[2]);\n\t}\n\n\tif (ts->slat_percentiles && flags & GFIO_SLAT)\n\t\tgfio_show_clat_percentiles(gc, main_vbox, ts, ddir,\n\t\t\t\tts->io_u_plat[FIO_SLAT][ddir],\n\t\t\t\tts->slat_stat[ddir].samples,\n\t\t\t\t\"Submission\");\n\tif (ts->clat_percentiles && flags & GFIO_CLAT)\n\t\tgfio_show_clat_percentiles(gc, main_vbox, ts, ddir,\n\t\t\t\tts->io_u_plat[FIO_CLAT][ddir],\n\t\t\t\tts->clat_stat[ddir].samples,\n\t\t\t\t\"Completion\");\n\tif (ts->lat_percentiles && flags & GFIO_LAT)\n\t\tgfio_show_clat_percentiles(gc, main_vbox, ts, ddir,\n\t\t\t\tts->io_u_plat[FIO_LAT][ddir],\n\t\t\t\tts->lat_stat[ddir].samples,\n\t\t\t\t\"Total\");\n\n\tfree(io_p);\n\tfree(bw_p);\n\tfree(io_palt);\n\tfree(bw_palt);\n\tfree(iops_p);\n}\n\nstatic void __gfio_display_end_results(GtkWidget *win, struct gfio_client *gc,\n\t\t\t\t       struct thread_stat *ts,\n\t\t\t\t       struct group_run_stats *rs)\n{\n\tGtkWidget *box, *vbox, *entry, *scroll;\n\tint i;\n\n\tscroll = gtk_scrolled_window_new(NULL, NULL);\n\tgtk_container_set_border_width(GTK_CONTAINER(scroll), 5);\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scroll), GTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\n\tvbox = gtk_vbox_new(FALSE, 3);\n\n\tbox = gtk_hbox_new(FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(vbox), box, TRUE, FALSE, 5);\n\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scroll), vbox);\n\n\tgtk_notebook_append_page(GTK_NOTEBOOK(win), scroll, gtk_label_new(ts->name));\n\n\tentry = new_info_entry_in_frame(box, \"Name\");\n\tgtk_entry_set_text(GTK_ENTRY(entry), ts->name);\n\tif (strlen(ts->description)) {\n\t\tentry = new_info_entry_in_frame(box, \"Description\");\n\t\tgtk_entry_set_text(GTK_ENTRY(entry), ts->description);\n\t}\n\tentry = new_info_entry_in_frame(box, \"Group ID\");\n\tentry_set_int_value(entry, ts->groupid);\n\tentry = new_info_entry_in_frame(box, \"Jobs\");\n\tentry_set_int_value(entry, ts->members);\n\tgc->err_entry = entry = new_info_entry_in_frame(box, \"Error\");\n\tentry_set_int_value(entry, ts->error);\n\tentry = new_info_entry_in_frame(box, \"PID\");\n\tentry_set_int_value(entry, ts->pid);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (ts->io_bytes[i])\n\t\t\tgfio_show_ddir_status(gc, vbox, rs, ts, i);\n\t}\n\n\tgfio_show_latency_buckets(gc, vbox, ts);\n\tgfio_show_cpu_usage(vbox, ts);\n\tgfio_show_io_depths(vbox, ts);\n}\n\nvoid gfio_display_end_results(struct gfio_client *gc)\n{\n\tstruct gui_entry *ge = gc->ge;\n\tGtkWidget *res_notebook;\n\tint i;\n\n\tres_notebook = get_results_window(ge);\n\n\tfor (i = 0; i < gc->nr_results; i++) {\n\t\tstruct end_results *e = &gc->results[i];\n\n\t\t__gfio_display_end_results(res_notebook, gc, &e->ts, &e->gs);\n\t}\n\n\tif (gfio_disk_util_show(gc))\n\t\tgtk_widget_show_all(ge->results_window);\n}\n\nstatic void gfio_display_ts(struct fio_client *client, struct thread_stat *ts,\n\t\t\t    struct group_run_stats *rs)\n{\n\tstruct gfio_client *gc = client->client_data;\n\tstruct gui_entry *ge = gc->ge;\n\n\tgfio_add_end_results(gc, ts, rs);\n\n\tgdk_threads_enter();\n\tif (ge->results_window)\n\t\t__gfio_display_end_results(ge->results_notebook, gc, ts, rs);\n\telse\n\t\tgfio_display_end_results(gc);\n\tgdk_threads_leave();\n}\n\nstatic void gfio_client_removed(struct fio_client *client)\n{\n\tstruct gfio_client *gc = client->client_data;\n\n\tassert(gc->client == client);\n\tfio_put_client(gc->client);\n\tgc->client = NULL;\n}\n\nstruct client_ops gfio_client_ops = {\n\t.text\t\t\t= gfio_text_op,\n\t.disk_util\t\t= gfio_disk_util_op,\n\t.thread_status\t\t= gfio_thread_status_op,\n\t.group_stats\t\t= gfio_group_stats_op,\n\t.jobs_eta\t\t= gfio_update_client_eta,\n\t.eta\t\t\t= gfio_update_all_eta,\n\t.probe\t\t\t= gfio_probe_op,\n\t.quit\t\t\t= gfio_quit_op,\n\t.add_job\t\t= gfio_add_job_op,\n\t.update_job\t\t= gfio_update_job_op,\n\t.timed_out\t\t= gfio_client_timed_out,\n\t.stop\t\t\t= gfio_client_stop,\n\t.start\t\t\t= gfio_client_start,\n\t.job_start\t\t= gfio_client_job_start,\n\t.removed\t\t= gfio_client_removed,\n\t.eta_msec\t\t= FIO_CLIENT_DEF_ETA_MSEC,\n\t.stay_connected\t\t= 1,\n\t.client_type\t\t= FIO_CLIENT_TYPE_GUI,\n};\n"
        },
        {
          "name": "gclient.h",
          "type": "blob",
          "size": 0.3759765625,
          "content": "#ifndef GFIO_CLIENT_H\n#define GFIO_CLIENT_H\n\nextern struct client_ops gfio_client_ops;\n\nextern void gfio_display_end_results(struct gfio_client *);\n\n#define GFIO_READ_R\t0.13\n#define GFIO_READ_G\t0.54\n#define GFIO_READ_B\t0.13\n#define GFIO_WRITE_R\t1.00\n#define GFIO_WRITE_G\t0.00\n#define GFIO_WRITE_B\t0.00\n#define GFIO_TRIM_R\t0.24\n#define GFIO_TRIM_G\t0.18\n#define GFIO_TRIM_B\t0.52\n\n#endif\n"
        },
        {
          "name": "gcompat.c",
          "type": "blob",
          "size": 1.244140625,
          "content": "#include <gtk/gtk.h>\n\n#include \"gcompat.h\"\n\n#if GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 24\n\nGtkWidget *gtk_combo_box_text_new(void)\n{\n\treturn gtk_combo_box_new();\n}\n\nvoid gtk_combo_box_text_append_text(GtkComboBoxText *combo_box,\n\t\t\t\t    const gchar *text)\n{\n\tgtk_combo_box_append_text(GTK_COMBO_BOX(combo_box), text);\n}\n\nvoid gtk_combo_box_text_insert_text(GtkComboBoxText *combo_box, gint position,\n\t\t\t\t    const gchar *text)\n{\n\tgtk_combo_box_insert_text(GTK_COMBO_BOX(combo_box), position, text);\n}\n\nvoid gtk_combo_box_text_prepend_text(GtkComboBoxText *combo_box,\n\t\t\t\t     const gchar *text)\n{\n\tgtk_combo_box_prepend_text(GTK_COMBO_BOX(combo_box), text);\n}\n\ngchar *gtk_combo_box_text_get_active_text(GtkComboBoxText *combo_box)\n{\n\treturn gtk_combo_box_get_active_text(GTK_COMBO_BOX(combo_box));\n}\n\n#endif\n\n#if GTK_MAJOR_VERSION < 3\n\nguint gtk_widget_get_allocated_width(GtkWidget *w)\n{\n\treturn w->allocation.width;\n}\n\nguint gtk_widget_get_allocated_height(GtkWidget *w)\n{\n\treturn w->allocation.height;\n}\n\n#endif\n\n#if GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 18\nvoid gtk_widget_set_can_focus(GtkWidget *widget, gboolean can_focus)\n{\n\tif (can_focus)\n\t\tGTK_WIDGET_SET_FLAGS(widget, GTK_CAN_FOCUS);\n\telse\n\t\tGTK_WIDGET_UNSET_FLAGS(widget, GTK_CAN_FOCUS);\n}\n#endif\n"
        },
        {
          "name": "gcompat.h",
          "type": "blob",
          "size": 1.4189453125,
          "content": "#ifndef GFIO_GTK_COMPAT\n#define GFIO_GTK_COMPAT\n\n#include <gtk/gtk.h>\n\n#if GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 24\nstruct GtkComboBoxText;\ntypedef GtkComboBox GtkComboBoxText;\nGtkWidget *gtk_combo_box_text_new(void);\nGtkWidget *gtk_combo_box_text_new_with_entry(void);\nvoid gtk_combo_box_text_append_text(GtkComboBoxText *combo_box, const gchar *text);\nvoid gtk_combo_box_text_insert_text(GtkComboBoxText *combo_box, gint position, const gchar *text);\nvoid gtk_combo_box_text_prepend_text(GtkComboBoxText *combo_box, const gchar *text);\nvoid gtk_combo_box_text_remove(GtkComboBoxText *combo_box, gint position);\ngchar *gtk_combo_box_text_get_active_text(GtkComboBoxText *combo_box);\n\n#define GTK_COMBO_BOX_TEXT\tGTK_COMBO_BOX\n#endif /* GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 24 */\n\n#if GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 14\nstatic inline GtkWidget *gtk_dialog_get_content_area(GtkDialog *dialog)\n{\n\treturn dialog->vbox;\n}\nstatic inline GdkWindow *gtk_widget_get_window(GtkWidget *w)\n{\n\treturn w->window;\n}\n#endif\n\n#if GTK_MAJOR_VERSION < 3\nguint gtk_widget_get_allocated_width(GtkWidget *w);\nguint gtk_widget_get_allocated_height(GtkWidget *w);\n#endif\n\n#if GTK_MAJOR_VERSION == 3\n#define GFIO_DRAW_EVENT\t\t\"draw\"\n#elif GTK_MAJOR_VERSION == 2\n#define GFIO_DRAW_EVENT\t\t\"expose_event\"\n#endif\n\n#if GTK_MAJOR_VERSION <= 2 && GTK_MINOR_VERSION < 18\nvoid gtk_widget_set_can_focus(GtkWidget *widget, gboolean can_focus);\n#endif\n\n#endif\n"
        },
        {
          "name": "gerror.c",
          "type": "blob",
          "size": 2.083984375,
          "content": "#include <locale.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdarg.h>\n\n#include <gtk/gtk.h>\n\n#include \"gfio.h\"\n#include \"gerror.h\"\n\nstatic void on_info_bar_response(GtkWidget *widget, gint response,\n\t\t\t\t gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\n\tif (response == GTK_RESPONSE_OK) {\n\t\tgtk_widget_destroy(widget);\n\t\tui->error_info_bar = NULL;\n\t}\n}\n\nstatic void report_error(struct gui_entry *ge, GError *error)\n{\n\tstruct gui *ui = ge->ui;\n\n\tif (ui->error_info_bar == NULL) {\n\t\tGtkWidget *container;\n\n\t\tui->error_info_bar = gtk_info_bar_new_with_buttons(GTK_STOCK_OK,\n\t\t\t\t\t\tGTK_RESPONSE_OK, NULL);\n\t\tg_signal_connect(ui->error_info_bar, \"response\", G_CALLBACK(on_info_bar_response), ui);\n\t\tgtk_info_bar_set_message_type(GTK_INFO_BAR(ui->error_info_bar),\n\t\t\t\t\t\tGTK_MESSAGE_ERROR);\n\n\t\tui->error_label = gtk_label_new(error->message);\n\t\tcontainer = gtk_info_bar_get_content_area(GTK_INFO_BAR(ui->error_info_bar));\n\t\tgtk_container_add(GTK_CONTAINER(container), ui->error_label);\n\n\t\tgtk_box_pack_start(GTK_BOX(ui->vbox), ui->error_info_bar, FALSE, FALSE, 0);\n\t\tgtk_widget_show_all(ui->vbox);\n\t} else {\n\t\tchar buffer[256];\n\t\tsnprintf(buffer, sizeof(buffer), \"Failed to open file.\");\n\t\tgtk_label_set_text(GTK_LABEL(ui->error_label), buffer);\n\t}\n}\n\nvoid gfio_report_error(struct gui_entry *ge, const char *format, ...)\n{\n\tva_list args;\n\tGError *error;\n\n\tva_start(args, format);\n\terror = g_error_new_valist(g_quark_from_string(\"fio\"), 1, format, args);\n\tva_end(args);\n\n\treport_error(ge, error);\n\tg_error_free(error);\n}\n\nvoid gfio_report_info(struct gui *ui, const char *title, const char *message)\n{\n\tGtkWidget *dialog, *content, *label;\n\n\tdialog = gtk_dialog_new_with_buttons(title, GTK_WINDOW(ui->window),\n\t\t\tGTK_DIALOG_MODAL | GTK_DIALOG_DESTROY_WITH_PARENT,\n\t\t\tGTK_STOCK_OK, GTK_RESPONSE_OK, NULL);\n\n\tcontent = gtk_dialog_get_content_area(GTK_DIALOG(dialog));\n\tlabel = gtk_label_new(message);\n\tgtk_container_add(GTK_CONTAINER(content), label);\n\tgtk_widget_show_all(dialog);\n\tgtk_dialog_set_default_response(GTK_DIALOG(dialog), GTK_RESPONSE_ACCEPT);\n\tgtk_dialog_run(GTK_DIALOG(dialog));\n\tgtk_widget_destroy(dialog);\n}\n"
        },
        {
          "name": "gerror.h",
          "type": "blob",
          "size": 0.2099609375,
          "content": "#ifndef GFIO_ERROR_H\n#define GFIO_ERROR_H\n\nextern void gfio_report_error(struct gui_entry *ge, const char *format, ...);\nextern void gfio_report_info(struct gui *ui, const char *title, const char *message);\n\n#endif\n"
        },
        {
          "name": "gettime-thread.c",
          "type": "blob",
          "size": 1.9921875,
          "content": "#include <sys/time.h>\n#include <time.h>\n\n#include \"fio.h\"\n#include \"lib/seqlock.h\"\n#include \"smalloc.h\"\n\nstruct fio_ts *fio_ts;\nint fio_gtod_offload = 0;\nstatic pthread_t gtod_thread;\nstatic os_cpu_mask_t fio_gtod_cpumask;\n\nvoid fio_gtod_init(void)\n{\n\tif (fio_ts)\n\t\treturn;\n\n\tfio_ts = smalloc(sizeof(*fio_ts));\n}\n\nstatic void fio_gtod_update(void)\n{\n\tstruct timeval __tv;\n\n\tif (!fio_ts)\n\t\treturn;\n\n\tgettimeofday(&__tv, NULL);\n\n\twrite_seqlock_begin(&fio_ts->seqlock);\n\tfio_ts->ts.tv_sec = __tv.tv_sec;\n\tfio_ts->ts.tv_nsec = __tv.tv_usec * 1000;\n\twrite_seqlock_end(&fio_ts->seqlock);\n}\n\nstruct gtod_cpu_data {\n\tstruct fio_sem *sem;\n\tunsigned int cpu;\n};\n\nstatic void *gtod_thread_main(void *data)\n{\n\tstruct fio_sem *sem = data;\n\tint ret;\n\n\tret = fio_setaffinity(gettid(), fio_gtod_cpumask);\n\n\tfio_sem_up(sem);\n\n\tif (ret == -1) {\n\t\tlog_err(\"gtod: setaffinity failed\\n\");\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * As long as we have jobs around, update the clock. It would be nice\n\t * to have some way of NOT hammering that CPU with gettimeofday(),\n\t * but I'm not sure what to use outside of a simple CPU nop to relax\n\t * it - we don't want to lose precision.\n\t */\n\twhile (nr_segments) {\n\t\tfio_gtod_update();\n\t\tnop;\n\t}\n\n\treturn NULL;\n}\n\nint fio_start_gtod_thread(void)\n{\n\tstruct fio_sem *sem;\n\tpthread_attr_t attr;\n\tint ret;\n\n\tsem = fio_sem_init(FIO_SEM_LOCKED);\n\tif (!sem)\n\t\treturn 1;\n\n\tpthread_attr_init(&attr);\n\tpthread_attr_setstacksize(&attr, 2 * PTHREAD_STACK_MIN);\n\tret = pthread_create(&gtod_thread, &attr, gtod_thread_main, sem);\n\tpthread_attr_destroy(&attr);\n\tif (ret) {\n\t\tlog_err(\"Can't create gtod thread: %s\\n\", strerror(ret));\n\t\tgoto err;\n\t}\n\n\tret = pthread_detach(gtod_thread);\n\tif (ret) {\n\t\tlog_err(\"Can't detach gtod thread: %s\\n\", strerror(ret));\n\t\tgoto err;\n\t}\n\n\tdprint(FD_MUTEX, \"wait on startup_sem\\n\");\n\tfio_sem_down(sem);\n\tdprint(FD_MUTEX, \"done waiting on startup_sem\\n\");\nerr:\n\tfio_sem_remove(sem);\n\treturn ret;\n}\n\nvoid fio_gtod_set_cpu(unsigned int cpu)\n{\n#ifdef FIO_HAVE_CPU_AFFINITY\n\tfio_cpu_set(&fio_gtod_cpumask, cpu);\n#endif\n}\n"
        },
        {
          "name": "gettime.c",
          "type": "blob",
          "size": 17.0146484375,
          "content": "/*\n * Clock functions\n */\n\n#include <math.h>\n\n#include \"fio.h\"\n#include \"os/os.h\"\n\n#if defined(ARCH_HAVE_CPU_CLOCK)\n#ifndef ARCH_CPU_CLOCK_CYCLES_PER_USEC\nstatic unsigned long long cycles_per_msec;\nstatic unsigned long long cycles_start;\nstatic unsigned long long clock_mult;\nstatic unsigned long long max_cycles_mask;\nstatic unsigned long long nsecs_for_max_cycles;\nstatic unsigned int clock_shift;\nstatic unsigned int max_cycles_shift;\n#define MAX_CLOCK_SEC 60*60\n#endif\n#ifdef ARCH_CPU_CLOCK_WRAPS\nstatic unsigned int cycles_wrap;\n#endif\n#endif\nbool tsc_reliable = false;\n\nstruct tv_valid {\n\tint warned;\n};\n#ifdef ARCH_HAVE_CPU_CLOCK\n#ifdef CONFIG_TLS_THREAD\nstatic __thread struct tv_valid static_tv_valid;\n#else\nstatic pthread_key_t tv_tls_key;\n#endif\n#endif\n\nenum fio_cs fio_clock_source = FIO_PREFERRED_CLOCK_SOURCE;\nint fio_clock_source_set = 0;\nstatic enum fio_cs fio_clock_source_inited = CS_INVAL;\n\n#ifdef FIO_DEBUG_TIME\n\n#define HASH_BITS\t8\n#define HASH_SIZE\t(1 << HASH_BITS)\n\nstatic struct flist_head hash[HASH_SIZE];\nstatic int gtod_inited;\n\nstruct gtod_log {\n\tstruct flist_head list;\n\tvoid *caller;\n\tunsigned long calls;\n};\n\nstatic struct gtod_log *find_hash(void *caller)\n{\n\tunsigned long h = hash_ptr(caller, HASH_BITS);\n\tstruct flist_head *entry;\n\n\tflist_for_each(entry, &hash[h]) {\n\t\tstruct gtod_log *log = flist_entry(entry, struct gtod_log,\n\t\t\t\t\t\t\t\t\tlist);\n\n\t\tif (log->caller == caller)\n\t\t\treturn log;\n\t}\n\n\treturn NULL;\n}\n\nstatic void inc_caller(void *caller)\n{\n\tstruct gtod_log *log = find_hash(caller);\n\n\tif (!log) {\n\t\tunsigned long h;\n\n\t\tlog = malloc(sizeof(*log));\n\t\tINIT_FLIST_HEAD(&log->list);\n\t\tlog->caller = caller;\n\t\tlog->calls = 0;\n\n\t\th = hash_ptr(caller, HASH_BITS);\n\t\tflist_add_tail(&log->list, &hash[h]);\n\t}\n\n\tlog->calls++;\n}\n\nstatic void gtod_log_caller(void *caller)\n{\n\tif (gtod_inited)\n\t\tinc_caller(caller);\n}\n\nstatic void fio_exit fio_dump_gtod(void)\n{\n\tunsigned long total_calls = 0;\n\tint i;\n\n\tfor (i = 0; i < HASH_SIZE; i++) {\n\t\tstruct flist_head *entry;\n\t\tstruct gtod_log *log;\n\n\t\tflist_for_each(entry, &hash[i]) {\n\t\t\tlog = flist_entry(entry, struct gtod_log, list);\n\n\t\t\tprintf(\"function %p, calls %lu\\n\", log->caller,\n\t\t\t\t\t\t\t\tlog->calls);\n\t\t\ttotal_calls += log->calls;\n\t\t}\n\t}\n\n\tprintf(\"Total %lu gettimeofday\\n\", total_calls);\n}\n\nstatic void fio_init gtod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < HASH_SIZE; i++)\n\t\tINIT_FLIST_HEAD(&hash[i]);\n\n\tgtod_inited = 1;\n}\n\n#endif /* FIO_DEBUG_TIME */\n\n/*\n * Queries the value of the monotonic clock if a monotonic clock is available\n * or the wall clock time if no monotonic clock is available. Returns 0 if\n * querying the clock succeeded or -1 if querying the clock failed.\n */\nint fio_get_mono_time(struct timespec *ts)\n{\n\tint ret;\n\n#ifdef CONFIG_CLOCK_GETTIME\n#if defined(CONFIG_CLOCK_MONOTONIC)\n\tret = clock_gettime(CLOCK_MONOTONIC, ts);\n#else\n\tret = clock_gettime(CLOCK_REALTIME, ts);\n#endif\n#else\n\tstruct timeval tv;\n\n\tret = gettimeofday(&tv, NULL);\n\tif (ret == 0) {\n\t\tts->tv_sec = tv.tv_sec;\n\t\tts->tv_nsec = tv.tv_usec * 1000;\n\t}\n#endif\n\tassert(ret <= 0);\n\treturn ret;\n}\n\nstatic void __fio_gettime(struct timespec *tp)\n{\n\tswitch (fio_clock_source) {\n#ifdef CONFIG_GETTIMEOFDAY\n\tcase CS_GTOD: {\n\t\tstruct timeval tv;\n\t\tgettimeofday(&tv, NULL);\n\n\t\ttp->tv_sec = tv.tv_sec;\n\t\ttp->tv_nsec = tv.tv_usec * 1000;\n\t\tbreak;\n\t\t}\n#endif\n#ifdef CONFIG_CLOCK_GETTIME\n\tcase CS_CGETTIME: {\n\t\tif (fio_get_mono_time(tp) < 0) {\n\t\t\tlog_err(\"fio: fio_get_mono_time() fails\\n\");\n\t\t\tassert(0);\n\t\t}\n\t\tbreak;\n\t\t}\n#endif\n#ifdef ARCH_HAVE_CPU_CLOCK\n\tcase CS_CPUCLOCK: {\n\t\tuint64_t nsecs, t, multiples;\n\t\tstruct tv_valid *tv;\n\n#ifdef CONFIG_TLS_THREAD\n\t\ttv = &static_tv_valid;\n#else\n\t\ttv = pthread_getspecific(tv_tls_key);\n#endif\n\n\t\tt = get_cpu_clock();\n#ifdef ARCH_CPU_CLOCK_WRAPS\n\t\tif (t < cycles_start && !cycles_wrap)\n\t\t\tcycles_wrap = 1;\n\t\telse if (cycles_wrap && t >= cycles_start && !tv->warned) {\n\t\t\tlog_err(\"fio: double CPU clock wrap\\n\");\n\t\t\ttv->warned = 1;\n\t\t}\n#endif\n#ifdef ARCH_CPU_CLOCK_CYCLES_PER_USEC\n\t\tnsecs = t / ARCH_CPU_CLOCK_CYCLES_PER_USEC * 1000;\n#else\n\t\tt -= cycles_start;\n\t\tmultiples = t >> max_cycles_shift;\n\t\tnsecs = multiples * nsecs_for_max_cycles;\n\t\tnsecs += ((t & max_cycles_mask) * clock_mult) >> clock_shift;\n#endif\n\t\ttp->tv_sec = nsecs / 1000000000ULL;\n\t\ttp->tv_nsec = nsecs % 1000000000ULL;\n\t\tbreak;\n\t\t}\n#endif\n\tdefault:\n\t\tlog_err(\"fio: invalid clock source %d\\n\", fio_clock_source);\n\t\tbreak;\n\t}\n}\n\n#ifdef FIO_DEBUG_TIME\nvoid fio_gettime(struct timespec *tp, void *caller)\n#else\nvoid fio_gettime(struct timespec *tp, void fio_unused *caller)\n#endif\n{\n#ifdef FIO_DEBUG_TIME\n\tif (!caller)\n\t\tcaller = __builtin_return_address(0);\n\n\tgtod_log_caller(caller);\n#endif\n\tif (fio_unlikely(fio_gettime_offload(tp)))\n\t\treturn;\n\n\t__fio_gettime(tp);\n}\n\n#if defined(ARCH_HAVE_CPU_CLOCK) && !defined(ARCH_CPU_CLOCK_CYCLES_PER_USEC)\nstatic unsigned long get_cycles_per_msec(void)\n{\n\tstruct timespec s, e;\n\tuint64_t c_s, c_e;\n\tuint64_t elapsed;\n\n\tfio_get_mono_time(&s);\n\n\tc_s = get_cpu_clock();\n\tdo {\n\t\tfio_get_mono_time(&e);\n\t\tc_e = get_cpu_clock();\n\n\t\telapsed = ntime_since(&s, &e);\n\t\tif (elapsed >= 1280000)\n\t\t\tbreak;\n\t} while (1);\n\n\treturn (c_e - c_s) * 1000000 / elapsed;\n}\n\n#define NR_TIME_ITERS\t50\n\nstatic int calibrate_cpu_clock(void)\n{\n\tdouble delta, mean, S;\n\tuint64_t minc, maxc, avg, cycles[NR_TIME_ITERS];\n\tint i, samples, sft = 0;\n\tunsigned long long tmp, max_ticks, max_mult;\n\n\tcycles[0] = get_cycles_per_msec();\n\tS = delta = mean = 0.0;\n\tfor (i = 0; i < NR_TIME_ITERS; i++) {\n\t\tcycles[i] = get_cycles_per_msec();\n\t\tdelta = cycles[i] - mean;\n\t\tif (delta) {\n\t\t\tmean += delta / (i + 1.0);\n\t\t\tS += delta * (cycles[i] - mean);\n\t\t}\n\t}\n\n\t/*\n\t * The most common platform clock breakage is returning zero\n\t * indefinitely. Check for that and return failure.\n\t */\n\tif (!cycles[0] && !cycles[NR_TIME_ITERS - 1])\n\t\treturn 1;\n\n\tS = sqrt(S / (NR_TIME_ITERS - 1.0));\n\n\tminc = -1ULL;\n\tmaxc = samples = avg = 0;\n\tfor (i = 0; i < NR_TIME_ITERS; i++) {\n\t\tdouble this = cycles[i];\n\n\t\tminc = min(cycles[i], minc);\n\t\tmaxc = max(cycles[i], maxc);\n\n\t\tif ((fmax(this, mean) - fmin(this, mean)) > S)\n\t\t\tcontinue;\n\t\tsamples++;\n\t\tavg += this;\n\t}\n\n\tS /= (double) NR_TIME_ITERS;\n\n\tfor (i = 0; i < NR_TIME_ITERS; i++)\n\t\tdprint(FD_TIME, \"cycles[%d]=%llu\\n\", i, (unsigned long long) cycles[i]);\n\n\tavg /= samples;\n\tcycles_per_msec = avg;\n\tdprint(FD_TIME, \"min=%llu, max=%llu, mean=%f, S=%f, N=%d\\n\",\n\t\t\t(unsigned long long) minc,\n\t\t\t(unsigned long long) maxc, mean, S, NR_TIME_ITERS);\n\tdprint(FD_TIME, \"trimmed mean=%llu, N=%d\\n\", (unsigned long long) avg, samples);\n\n\tmax_ticks = MAX_CLOCK_SEC * cycles_per_msec * 1000ULL;\n\tmax_mult = ULLONG_MAX / max_ticks;\n\tdprint(FD_TIME, \"max_ticks=%llu, __builtin_clzll=%d, \"\n\t\t\t\"max_mult=%llu\\n\", max_ticks,\n\t\t\t__builtin_clzll(max_ticks), max_mult);\n\n        /*\n         * Find the largest shift count that will produce\n         * a multiplier that does not exceed max_mult\n         */\n        tmp = max_mult * cycles_per_msec / 1000000;\n        while (tmp > 1) {\n                tmp >>= 1;\n                sft++;\n                dprint(FD_TIME, \"tmp=%llu, sft=%u\\n\", tmp, sft);\n        }\n\n\tclock_shift = sft;\n\tclock_mult = (1ULL << sft) * 1000000 / cycles_per_msec;\n\tdprint(FD_TIME, \"clock_shift=%u, clock_mult=%llu\\n\", clock_shift,\n\t\t\t\t\t\t\tclock_mult);\n\n\t/*\n\t * Find the greatest power of 2 clock ticks that is less than the\n\t * ticks in MAX_CLOCK_SEC\n\t */\n\tmax_cycles_shift = max_cycles_mask = 0;\n\ttmp = MAX_CLOCK_SEC * 1000ULL * cycles_per_msec;\n\tdprint(FD_TIME, \"tmp=%llu, max_cycles_shift=%u\\n\", tmp,\n\t\t\t\t\t\t\tmax_cycles_shift);\n\twhile (tmp > 1) {\n\t\ttmp >>= 1;\n\t\tmax_cycles_shift++;\n\t\tdprint(FD_TIME, \"tmp=%llu, max_cycles_shift=%u\\n\", tmp, max_cycles_shift);\n\t}\n\t/*\n\t * if use use (1ULL << max_cycles_shift) * 1000 / cycles_per_msec\n\t * here we will have a discontinuity every\n\t * (1ULL << max_cycles_shift) cycles\n\t */\n\tnsecs_for_max_cycles = ((1ULL << max_cycles_shift) * clock_mult)\n\t\t\t\t\t>> clock_shift;\n\n\t/* Use a bitmask to calculate ticks % (1ULL << max_cycles_shift) */\n\tfor (tmp = 0; tmp < max_cycles_shift; tmp++)\n\t\tmax_cycles_mask |= 1ULL << tmp;\n\n\tdprint(FD_TIME, \"max_cycles_shift=%u, 2^max_cycles_shift=%llu, \"\n\t\t\t\"nsecs_for_max_cycles=%llu, \"\n\t\t\t\"max_cycles_mask=%016llx\\n\",\n\t\t\tmax_cycles_shift, (1ULL << max_cycles_shift),\n\t\t\tnsecs_for_max_cycles, max_cycles_mask);\n\n\tcycles_start = get_cpu_clock();\n\tdprint(FD_TIME, \"cycles_start=%llu\\n\", cycles_start);\n\treturn 0;\n}\n#else\nstatic int calibrate_cpu_clock(void)\n{\n#ifdef ARCH_CPU_CLOCK_CYCLES_PER_USEC\n\treturn 0;\n#else\n\treturn 1;\n#endif\n}\n#endif // ARCH_HAVE_CPU_CLOCK\n\n#if defined(ARCH_HAVE_CPU_CLOCK) && !defined(CONFIG_TLS_THREAD)\nvoid fio_local_clock_init(void)\n{\n\tstruct tv_valid *t;\n\n\tt = calloc(1, sizeof(*t));\n\tif (pthread_setspecific(tv_tls_key, t)) {\n\t\tlog_err(\"fio: can't set TLS key\\n\");\n\t\tassert(0);\n\t}\n}\n\nstatic void kill_tv_tls_key(void *data)\n{\n\tfree(data);\n}\n#else\nvoid fio_local_clock_init(void)\n{\n}\n#endif\n\nvoid fio_clock_init(void)\n{\n\tif (fio_clock_source == fio_clock_source_inited)\n\t\treturn;\n\n#if defined(ARCH_HAVE_CPU_CLOCK) && !defined(CONFIG_TLS_THREAD)\n\tif (pthread_key_create(&tv_tls_key, kill_tv_tls_key))\n\t\tlog_err(\"fio: can't create TLS key\\n\");\n#endif\n\n\tfio_clock_source_inited = fio_clock_source;\n\n\tif (calibrate_cpu_clock())\n\t\ttsc_reliable = false;\n\n\t/*\n\t * If the arch sets tsc_reliable != 0, then it must be good enough\n\t * to use as THE clock source. For x86 CPUs, this means the TSC\n\t * runs at a constant rate and is synced across CPU cores.\n\t */\n\tif (tsc_reliable) {\n\t\tif (!fio_clock_source_set && !fio_monotonic_clocktest(0))\n\t\t\tfio_clock_source = CS_CPUCLOCK;\n\t} else if (fio_clock_source == CS_CPUCLOCK)\n\t\tlog_info(\"fio: clocksource=cpu may not be reliable\\n\");\n\tdprint(FD_TIME, \"gettime: clocksource=%d\\n\", (int) fio_clock_source);\n}\n\nuint64_t ntime_since(const struct timespec *s, const struct timespec *e)\n{\n\tint64_t sec, nsec;\n\n\tsec = e->tv_sec - s->tv_sec;\n\tnsec = e->tv_nsec - s->tv_nsec;\n\tif (sec > 0 && nsec < 0) {\n\t\tsec--;\n\t\tnsec += 1000000000LL;\n\t}\n\n       /*\n\t* time warp bug on some kernels?\n\t*/\n\tif (sec < 0 || (sec == 0 && nsec < 0))\n\t\treturn 0;\n\n\treturn nsec + (sec * 1000000000LL);\n}\n\nuint64_t ntime_since_now(const struct timespec *s)\n{\n\tstruct timespec now;\n\n\tfio_gettime(&now, NULL);\n\treturn ntime_since(s, &now);\n}\n\nuint64_t utime_since(const struct timespec *s, const struct timespec *e)\n{\n\tint64_t sec, usec;\n\n\tsec = e->tv_sec - s->tv_sec;\n\tusec = (e->tv_nsec - s->tv_nsec) / 1000;\n\tif (sec > 0 && usec < 0) {\n\t\tsec--;\n\t\tusec += 1000000;\n\t}\n\n\t/*\n\t * time warp bug on some kernels?\n\t */\n\tif (sec < 0 || (sec == 0 && usec < 0))\n\t\treturn 0;\n\n\treturn usec + (sec * 1000000);\n}\n\nuint64_t utime_since_now(const struct timespec *s)\n{\n\tstruct timespec t;\n#ifdef FIO_DEBUG_TIME\n\tvoid *p = __builtin_return_address(0);\n\n\tfio_gettime(&t, p);\n#else\n\tfio_gettime(&t, NULL);\n#endif\n\n\treturn utime_since(s, &t);\n}\n\nuint64_t mtime_since_tv(const struct timeval *s, const struct timeval *e)\n{\n\tint64_t sec, usec;\n\n\tsec = e->tv_sec - s->tv_sec;\n\tusec = (e->tv_usec - s->tv_usec);\n\tif (sec > 0 && usec < 0) {\n\t\tsec--;\n\t\tusec += 1000000;\n\t}\n\n\tif (sec < 0 || (sec == 0 && usec < 0))\n\t\treturn 0;\n\n\tsec *= 1000;\n\tusec /= 1000;\n\treturn sec + usec;\n}\n\nuint64_t mtime_since_now(const struct timespec *s)\n{\n\tstruct timespec t;\n#ifdef FIO_DEBUG_TIME\n\tvoid *p = __builtin_return_address(0);\n\n\tfio_gettime(&t, p);\n#else\n\tfio_gettime(&t, NULL);\n#endif\n\n\treturn mtime_since(s, &t);\n}\n\n/*\n * Returns *e - *s in milliseconds as a signed integer. Note: rounding is\n * asymmetric. If the difference yields +1 ns then 0 is returned. If the\n * difference yields -1 ns then -1 is returned.\n */\nint64_t rel_time_since(const struct timespec *s, const struct timespec *e)\n{\n\tint64_t sec, nsec;\n\n\tsec = e->tv_sec - s->tv_sec;\n\tnsec = e->tv_nsec - s->tv_nsec;\n\tif (nsec < 0) {\n\t\tsec--;\n\t\tnsec += 1000ULL * 1000 * 1000;\n\t}\n\tassert(0 <= nsec && nsec < 1000ULL * 1000 * 1000);\n\n\treturn sec * 1000 + nsec / (1000 * 1000);\n}\n\n/*\n * Returns *e - *s in milliseconds as an unsigned integer. Returns 0 if\n * *e < *s.\n */\nuint64_t mtime_since(const struct timespec *s, const struct timespec *e)\n{\n\treturn max(rel_time_since(s, e), (int64_t)0);\n}\n\nuint64_t time_since_now(const struct timespec *s)\n{\n\treturn mtime_since_now(s) / 1000;\n}\n\n#if defined(FIO_HAVE_CPU_AFFINITY) && defined(ARCH_HAVE_CPU_CLOCK)  && \\\n    defined(CONFIG_SYNC_SYNC) && defined(CONFIG_CMP_SWAP)\n\n#define CLOCK_ENTRIES_DEBUG\t100000\n#define CLOCK_ENTRIES_TEST\t1000\n\nstruct clock_entry {\n\tuint32_t seq;\n\tuint32_t cpu;\n\tuint64_t tsc;\n};\n\nstruct clock_thread {\n\tpthread_t thread;\n\tint cpu;\n\tint debug;\n\tstruct fio_sem lock;\n\tunsigned long nr_entries;\n\tuint32_t *seq;\n\tstruct clock_entry *entries;\n};\n\nstatic inline uint32_t atomic32_compare_and_swap(uint32_t *ptr, uint32_t old,\n\t\t\t\t\t\t uint32_t new)\n{\n\treturn __sync_val_compare_and_swap(ptr, old, new);\n}\n\nstatic void *clock_thread_fn(void *data)\n{\n\tstruct clock_thread *t = data;\n\tstruct clock_entry *c;\n\tos_cpu_mask_t cpu_mask;\n\tunsigned long long first;\n\tint i;\n\n\tif (fio_cpuset_init(&cpu_mask)) {\n\t\tint __err = errno;\n\n\t\tlog_err(\"clock cpuset init failed: %s\\n\", strerror(__err));\n\t\tgoto err_out;\n\t}\n\n\tfio_cpu_set(&cpu_mask, t->cpu);\n\n\tif (fio_setaffinity(gettid(), cpu_mask) == -1) {\n\t\tint __err = errno;\n\n\t\tlog_err(\"clock setaffinity failed: %s\\n\", strerror(__err));\n\t\tgoto err;\n\t}\n\n\tfio_sem_down(&t->lock);\n\n\tfirst = get_cpu_clock();\n\tc = &t->entries[0];\n\tfor (i = 0; i < t->nr_entries; i++, c++) {\n\t\tuint32_t seq;\n\t\tuint64_t tsc;\n\n\t\tc->cpu = t->cpu;\n\t\tdo {\n\t\t\tseq = *t->seq;\n\t\t\tif (seq == UINT_MAX)\n\t\t\t\tbreak;\n\t\t\ttsc_barrier();\n\t\t\ttsc = get_cpu_clock();\n\t\t} while (seq != atomic32_compare_and_swap(t->seq, seq, seq + 1));\n\n\t\tif (seq == UINT_MAX)\n\t\t\tbreak;\n\n\t\tc->seq = seq;\n\t\tc->tsc = tsc;\n\t}\n\n\tif (t->debug) {\n\t\tunsigned long long clocks;\n\n\t\tclocks = t->entries[i - 1].tsc - t->entries[0].tsc;\n\t\tlog_info(\"cs: cpu%3d: %llu clocks seen, first %llu\\n\", t->cpu,\n\t\t\t\t\t\t\tclocks, first);\n\t}\n\n\t/*\n\t * The most common platform clock breakage is returning zero\n\t * indefinitely. Check for that and return failure.\n\t */\n\tif (i > 1 && !t->entries[i - 1].tsc && !t->entries[0].tsc)\n\t\tgoto err;\n\n\tfio_cpuset_exit(&cpu_mask);\n\treturn NULL;\nerr:\n\tfio_cpuset_exit(&cpu_mask);\nerr_out:\n\treturn (void *) 1;\n}\n\nstatic int clock_cmp(const void *p1, const void *p2)\n{\n\tconst struct clock_entry *c1 = p1;\n\tconst struct clock_entry *c2 = p2;\n\n\tif (c1->seq == c2->seq)\n\t\tlog_err(\"cs: bug in atomic sequence!\\n\");\n\n\treturn c1->seq - c2->seq;\n}\n\nint fio_monotonic_clocktest(int debug)\n{\n\tstruct clock_thread *cthreads;\n\tunsigned int seen_cpus, nr_cpus = cpus_configured();\n\tstruct clock_entry *entries;\n\tunsigned long nr_entries, tentries, failed = 0;\n\tstruct clock_entry *prev, *this;\n\tuint32_t seq = 0;\n\tunsigned int i;\n\tos_cpu_mask_t mask;\n\n#ifdef FIO_HAVE_GET_THREAD_AFFINITY\n\tfio_get_thread_affinity(mask);\n#else\n\tmemset(&mask, 0, sizeof(mask));\n\tfor (i = 0; i < nr_cpus; i++)\n\t\tfio_cpu_set(&mask, i);\n#endif\n\n\tif (debug) {\n\t\tlog_info(\"cs: reliable_tsc: %s\\n\", tsc_reliable ? \"yes\" : \"no\");\n\n#ifdef FIO_INC_DEBUG\n\t\tfio_debug |= 1U << FD_TIME;\n#endif\n\t\tnr_entries = CLOCK_ENTRIES_DEBUG;\n\t} else\n\t\tnr_entries = CLOCK_ENTRIES_TEST;\n\n\tcalibrate_cpu_clock();\n\n\tif (debug) {\n#ifdef FIO_INC_DEBUG\n\t\tfio_debug &= ~(1U << FD_TIME);\n#endif\n\t}\n\n\tcthreads = malloc(nr_cpus * sizeof(struct clock_thread));\n\ttentries = nr_entries * nr_cpus;\n\tentries = malloc(tentries * sizeof(struct clock_entry));\n\n\tif (debug)\n\t\tlog_info(\"cs: Testing %u CPUs\\n\", nr_cpus);\n\n\tseen_cpus = 0;\n\tfor (i = 0; i < nr_cpus; i++) {\n\t\tstruct clock_thread *t = &cthreads[i];\n\n\t\tif (!fio_cpu_isset(&mask, i))\n\t\t\tcontinue;\n\t\tt->cpu = i;\n\t\tt->debug = debug;\n\t\tt->seq = &seq;\n\t\tt->nr_entries = nr_entries;\n\t\tt->entries = &entries[seen_cpus * nr_entries];\n\t\t__fio_sem_init(&t->lock, FIO_SEM_LOCKED);\n\t\tif (pthread_create(&t->thread, NULL, clock_thread_fn, t)) {\n\t\t\tfailed++;\n\t\t\tnr_cpus = i;\n\t\t\tbreak;\n\t\t}\n\t\tseen_cpus++;\n\t}\n\n\tfor (i = 0; i < nr_cpus; i++) {\n\t\tstruct clock_thread *t = &cthreads[i];\n\n\t\tif (!fio_cpu_isset(&mask, i))\n\t\t\tcontinue;\n\t\tfio_sem_up(&t->lock);\n\t}\n\n\tfor (i = 0; i < nr_cpus; i++) {\n\t\tstruct clock_thread *t = &cthreads[i];\n\t\tvoid *ret;\n\n\t\tif (!fio_cpu_isset(&mask, i))\n\t\t\tcontinue;\n\t\tpthread_join(t->thread, &ret);\n\t\tif (ret)\n\t\t\tfailed++;\n\t\t__fio_sem_remove(&t->lock);\n\t}\n\tfree(cthreads);\n\n\tif (failed) {\n\t\tif (debug)\n\t\t\tlog_err(\"Clocksource test: %lu threads failed\\n\", failed);\n\t\tgoto err;\n\t}\n\n\ttentries = nr_entries * seen_cpus;\n\tqsort(entries, tentries, sizeof(struct clock_entry), clock_cmp);\n\n\t/* silence silly gcc */\n\tprev = NULL;\n\tfor (failed = i = 0; i < tentries; i++) {\n\t\tthis = &entries[i];\n\n\t\tif (!i) {\n\t\t\tprev = this;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prev->tsc > this->tsc) {\n\t\t\tuint64_t diff = prev->tsc - this->tsc;\n\n\t\t\tif (!debug) {\n\t\t\t\tfailed++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tlog_info(\"cs: CPU clock mismatch (diff=%llu):\\n\",\n\t\t\t\t\t\t(unsigned long long) diff);\n\t\t\tlog_info(\"\\t CPU%3u: TSC=%llu, SEQ=%u\\n\", prev->cpu, (unsigned long long) prev->tsc, prev->seq);\n\t\t\tlog_info(\"\\t CPU%3u: TSC=%llu, SEQ=%u\\n\", this->cpu, (unsigned long long) this->tsc, this->seq);\n\t\t\tfailed++;\n\t\t}\n\n\t\tprev = this;\n\t}\n\n\tif (debug) {\n\t\tif (failed)\n\t\t\tlog_info(\"cs: Failed: %lu\\n\", failed);\n\t\telse\n\t\t\tlog_info(\"cs: Pass!\\n\");\n\t}\nerr:\n\tfree(entries);\n\treturn !!failed;\n}\n\n#else /* defined(FIO_HAVE_CPU_AFFINITY) && defined(ARCH_HAVE_CPU_CLOCK) */\n\nint fio_monotonic_clocktest(int debug)\n{\n\tif (debug)\n\t\tlog_info(\"cs: current platform does not support CPU clocks\\n\");\n\treturn 1;\n}\n\n#endif\n"
        },
        {
          "name": "gettime.h",
          "type": "blob",
          "size": 0.8740234375,
          "content": "#ifndef FIO_GETTIME_H\n#define FIO_GETTIME_H\n\n#include <sys/time.h>\n\n#include \"arch/arch.h\"\n#include \"lib/seqlock.h\"\n\n/*\n * Clock sources\n */\nenum fio_cs {\n\tCS_GTOD\t\t= 1,\n\tCS_CGETTIME,\n\tCS_CPUCLOCK,\n\tCS_INVAL,\n};\n\nextern int fio_get_mono_time(struct timespec *);\nextern void fio_gettime(struct timespec *, void *);\nextern void fio_gtod_init(void);\nextern void fio_clock_init(void);\nextern int fio_start_gtod_thread(void);\nextern int fio_monotonic_clocktest(int debug);\nextern void fio_local_clock_init(void);\n\nextern struct fio_ts {\n\tstruct seqlock seqlock;\n\tstruct timespec ts;\n} *fio_ts;\n\nstatic inline int fio_gettime_offload(struct timespec *ts)\n{\n\tunsigned int seq;\n\n\tif (!fio_ts)\n\t\treturn 0;\n\n\tdo {\n\t\tseq = read_seqlock_begin(&fio_ts->seqlock);\n\t\t*ts = fio_ts->ts;\n\t} while (read_seqlock_retry(&fio_ts->seqlock, seq));\n\n\treturn 1;\n}\n\nextern void fio_gtod_set_cpu(unsigned int cpu);\n\n#endif\n"
        },
        {
          "name": "gfio.c",
          "type": "blob",
          "size": 51.46875,
          "content": "/*\n * gfio - gui front end for fio - the flexible io tester\n *\n * Copyright (C) 2012 Stephen M. Cameron <stephenmcameron@gmail.com>\n * Copyright (C) 2012 Jens Axboe <axboe@kernel.dk>\n *\n * The license below covers all files distributed with fio unless otherwise\n * noted in the file itself.\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License version 2 as\n *  published by the Free Software Foundation.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; if not, write to the Free Software\n *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n#include <locale.h>\n#include <stdlib.h>\n#include <string.h>\n#include <libgen.h>\n\n#include <glib.h>\n#include <cairo.h>\n#include <gtk/gtk.h>\n\n#include \"fio.h\"\n#include \"gfio.h\"\n#include \"ghelpers.h\"\n#include \"goptions.h\"\n#include \"gerror.h\"\n#include \"gclient.h\"\n#include \"graph.h\"\n\nstruct gui main_ui;\n\nstatic bool gfio_server_running;\nstatic unsigned int gfio_graph_limit = 100;\n\nGdkColor gfio_color_white;\nGdkColor gfio_color_lightyellow;\nconst char *gfio_graph_font = GRAPH_DEFAULT_FONT;\n\ntypedef void (*clickfunction)(GtkWidget *widget, gpointer data);\n\nstatic void connect_clicked(GtkWidget *widget, gpointer data);\nstatic void start_job_clicked(GtkWidget *widget, gpointer data);\nstatic void send_clicked(GtkWidget *widget, gpointer data);\n\nstatic struct button_spec {\n\tconst char *buttontext;\n\tclickfunction f;\n\tconst char *tooltiptext[2];\n\tconst int start_sensitive;\n} buttonspeclist[] = {\n\t{\n\t  .buttontext\t\t= \"Connect\",\n\t  .f\t\t\t= connect_clicked,\n\t  .tooltiptext\t\t= { \"Disconnect from host\", \"Connect to host\" },\n\t  .start_sensitive\t= 1,\n\t},\n\t{\n\t  .buttontext\t\t= \"Send\",\n\t  .f\t\t\t= send_clicked,\n\t  .tooltiptext\t\t= { \"Send job description to host\", NULL },\n\t  .start_sensitive\t= 0,\n\t},\n\t{\n\t  .buttontext\t\t= \"Start Job\",\n\t  .f\t\t\t= start_job_clicked,\n\t  .tooltiptext\t\t= { \"Start the current job on the server\", NULL },\n\t  .start_sensitive\t= 0,\n\t},\n};\n\nstatic void setup_iops_graph(struct gfio_graphs *gg)\n{\n\tstruct graph *g;\n\n\tg = graph_new(DRAWING_AREA_XDIM / 2.0, DRAWING_AREA_YDIM, gfio_graph_font);\n\tgraph_title(g, \"IOPS (IOs/sec)\");\n\tgraph_x_title(g, \"Time (secs)\");\n\tgg->read_iops = graph_add_label(g, \"Read IOPS\");\n\tgg->write_iops = graph_add_label(g, \"Write IOPS\");\n\tgg->trim_iops = graph_add_label(g, \"Trim IOPS\");\n\tgraph_set_color(g, gg->read_iops, GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tgraph_set_color(g, gg->write_iops, GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tgraph_set_color(g, gg->trim_iops, GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\tline_graph_set_data_count_limit(g, gfio_graph_limit);\n\tgraph_add_extra_space(g, 0.0, 0.0, 0.0, 0.0);\n\tgraph_set_graph_all_zeroes(g, 0);\n\tgg->iops_graph = g;\n}\n\nstatic void setup_bandwidth_graph(struct gfio_graphs *gg)\n{\n\tstruct graph *g;\n\n\tg = graph_new(DRAWING_AREA_XDIM / 2.0, DRAWING_AREA_YDIM, gfio_graph_font);\n\tgraph_title(g, \"Bandwidth (bytes/sec)\");\n\tgraph_x_title(g, \"Time (secs)\");\n\tgg->read_bw = graph_add_label(g, \"Read Bandwidth\");\n\tgg->write_bw = graph_add_label(g, \"Write Bandwidth\");\n\tgg->trim_bw = graph_add_label(g, \"Trim Bandwidth\");\n\tgraph_set_color(g, gg->read_bw, GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tgraph_set_color(g, gg->write_bw, GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tgraph_set_color(g, gg->trim_bw, GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\tgraph_set_base_offset(g, 1);\n\tline_graph_set_data_count_limit(g, 100);\n\tgraph_add_extra_space(g, 0.0, 0.0, 0.0, 0.0);\n\tgraph_set_graph_all_zeroes(g, 0);\n\tgg->bandwidth_graph = g;\n}\n\nstatic void setup_graphs(struct gfio_graphs *g)\n{\n\tsetup_iops_graph(g);\n\tsetup_bandwidth_graph(g);\n}\n\nvoid clear_ge_ui_info(struct gui_entry *ge)\n{\n\tgtk_label_set_text(GTK_LABEL(ge->probe.hostname), \"\");\n\tgtk_label_set_text(GTK_LABEL(ge->probe.os), \"\");\n\tgtk_label_set_text(GTK_LABEL(ge->probe.arch), \"\");\n\tgtk_label_set_text(GTK_LABEL(ge->probe.fio_ver), \"\");\n#if 0\n\t/* should we empty it... */\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.name), \"\");\n#endif\n\tmultitext_update_entry(&ge->eta.iotype, 0, \"\");\n\tmultitext_update_entry(&ge->eta.bs, 0, \"\");\n\tmultitext_update_entry(&ge->eta.ioengine, 0, \"\");\n\tmultitext_update_entry(&ge->eta.iodepth, 0, \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.jobs), \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.files), \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.read_bw), \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.read_iops), \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.write_bw), \"\");\n\tgtk_entry_set_text(GTK_ENTRY(ge->eta.write_iops), \"\");\n}\n\nstatic void set_menu_entry_text(struct gui *ui, const char *path,\n\t\t\t\tconst char *text)\n{\n\tGtkWidget *w;\n\n\tw = gtk_ui_manager_get_widget(ui->uimanager, path);\n\tif (w)\n\t\tgtk_menu_item_set_label(GTK_MENU_ITEM(w), text);\n\telse\n\t\tfprintf(stderr, \"gfio: can't find path %s\\n\", path);\n}\n\n\nstatic void set_menu_entry_visible(struct gui *ui, const char *path, int show)\n{\n\tGtkWidget *w;\n\n\tw = gtk_ui_manager_get_widget(ui->uimanager, path);\n\tif (w)\n\t\tgtk_widget_set_sensitive(w, show);\n\telse\n\t\tfprintf(stderr, \"gfio: can't find path %s\\n\", path);\n}\n\nstatic void set_job_menu_visible(struct gui *ui, int visible)\n{\n\tset_menu_entry_visible(ui, \"/MainMenu/JobMenu\", visible);\n}\n\nstatic void set_view_results_visible(struct gui *ui, int visible)\n{\n\tset_menu_entry_visible(ui, \"/MainMenu/ViewMenu/Results\", visible);\n}\n\nstatic const char *get_button_tooltip(struct button_spec *s, int sensitive)\n{\n\tif (s->tooltiptext[sensitive])\n\t\treturn s->tooltiptext[sensitive];\n\n\treturn s->tooltiptext[0];\n}\n\nstatic GtkWidget *add_button(GtkWidget *buttonbox,\n\t\t\t     struct button_spec *buttonspec, gpointer data)\n{\n\tGtkWidget *button = gtk_button_new_with_label(buttonspec->buttontext);\n\tgboolean sens = buttonspec->start_sensitive;\n\n\tg_signal_connect(button, \"clicked\", G_CALLBACK(buttonspec->f), data);\n\tgtk_box_pack_start(GTK_BOX(buttonbox), button, FALSE, FALSE, 3);\n\n\tsens = buttonspec->start_sensitive;\n\tgtk_widget_set_tooltip_text(button, get_button_tooltip(buttonspec, sens));\n\tgtk_widget_set_sensitive(button, sens);\n\n\treturn button;\n}\n\nstatic void add_buttons(struct gui_entry *ge, struct button_spec *buttonlist,\n\t\t\tint nbuttons)\n{\n\tint i;\n\n\tfor (i = 0; i < nbuttons; i++)\n\t\tge->button[i] = add_button(ge->buttonbox, &buttonlist[i], ge);\n}\n\n/*\n * Update sensitivity of job buttons and job menu items, based on the\n * state of the client.\n */\nstatic void update_button_states(struct gui *ui, struct gui_entry *ge)\n{\n\tunsigned int connect_state, send_state, start_state, edit_state;\n\tconst char *connect_str = NULL;\n\n\tswitch (ge->state) {\n\tdefault:\n\t\tgfio_report_error(ge, \"Bad client state: %u\\n\", ge->state);\n\t\t/* fall-through */\n\tcase GE_STATE_NEW:\n\t\tconnect_state = 1;\n\t\tedit_state = 1;\n\t\tconnect_str = \"Connect\";\n\t\tsend_state = 0;\n\t\tstart_state = 0;\n\t\tbreak;\n\tcase GE_STATE_CONNECTED:\n\t\tconnect_state = 1;\n\t\tedit_state = 1;\n\t\tconnect_str = \"Disconnect\";\n\t\tsend_state = 1;\n\t\tstart_state = 0;\n\t\tbreak;\n\tcase GE_STATE_JOB_SENT:\n\t\tconnect_state = 1;\n\t\tedit_state = 1;\n\t\tconnect_str = \"Disconnect\";\n\t\tsend_state = 0;\n\t\tstart_state = 1;\n\t\tbreak;\n\tcase GE_STATE_JOB_STARTED:\n\t\tconnect_state = 1;\n\t\tedit_state = 1;\n\t\tconnect_str = \"Disconnect\";\n\t\tsend_state = 0;\n\t\tstart_state = 1;\n\t\tbreak;\n\tcase GE_STATE_JOB_RUNNING:\n\t\tconnect_state = 1;\n\t\tedit_state = 0;\n\t\tconnect_str = \"Disconnect\";\n\t\tsend_state = 0;\n\t\tstart_state = 0;\n\t\tbreak;\n\tcase GE_STATE_JOB_DONE:\n\t\tconnect_state = 1;\n\t\tedit_state = 0;\n\t\tconnect_str = \"Connect\";\n\t\tsend_state = 0;\n\t\tstart_state = 0;\n\t\tbreak;\n\t}\n\n\tgtk_widget_set_sensitive(ge->button[GFIO_BUTTON_CONNECT], connect_state);\n\tgtk_widget_set_sensitive(ge->button[GFIO_BUTTON_SEND], send_state);\n\tgtk_widget_set_sensitive(ge->button[GFIO_BUTTON_START], start_state);\n\tgtk_button_set_label(GTK_BUTTON(ge->button[GFIO_BUTTON_CONNECT]), connect_str);\n\tgtk_widget_set_tooltip_text(ge->button[GFIO_BUTTON_CONNECT], get_button_tooltip(&buttonspeclist[GFIO_BUTTON_CONNECT], connect_state));\n\n\tset_menu_entry_visible(ui, \"/MainMenu/JobMenu/Connect\", connect_state);\n\tset_menu_entry_text(ui, \"/MainMenu/JobMenu/Connect\", connect_str);\n\n\tset_menu_entry_visible(ui, \"/MainMenu/JobMenu/Edit job\", edit_state);\n\tset_menu_entry_visible(ui, \"/MainMenu/JobMenu/Send job\", send_state);\n\tset_menu_entry_visible(ui, \"/MainMenu/JobMenu/Start job\", start_state);\n\n\tif (ge->client && ge->client->nr_results)\n\t\tset_view_results_visible(ui, 1);\n\telse\n\t\tset_view_results_visible(ui, 0);\n}\n\nvoid gfio_set_state(struct gui_entry *ge, unsigned int state)\n{\n\tge->state = state;\n\tupdate_button_states(ge->ui, ge);\n}\n\nstatic void gfio_ui_setup_log(struct gui *ui)\n{\n\tGtkTreeSelection *selection;\n\tGtkListStore *model;\n\tGtkWidget *tree_view;\n\n\tmodel = gtk_list_store_new(4, G_TYPE_STRING, G_TYPE_STRING, G_TYPE_STRING, G_TYPE_STRING);\n\n\ttree_view = gtk_tree_view_new_with_model(GTK_TREE_MODEL(model));\n\tgtk_widget_set_can_focus(tree_view, FALSE);\n\n\tselection = gtk_tree_view_get_selection(GTK_TREE_VIEW(tree_view));\n\tgtk_tree_selection_set_mode(GTK_TREE_SELECTION(selection), GTK_SELECTION_BROWSE);\n\tg_object_set(G_OBJECT(tree_view), \"headers-visible\", TRUE,\n\t\t\"enable-grid-lines\", GTK_TREE_VIEW_GRID_LINES_BOTH, NULL);\n\n\ttree_view_column(tree_view, 0, \"Time\", ALIGN_RIGHT | UNSORTABLE);\n\ttree_view_column(tree_view, 1, \"Host\", ALIGN_RIGHT | UNSORTABLE);\n\ttree_view_column(tree_view, 2, \"Level\", ALIGN_RIGHT | UNSORTABLE);\n\ttree_view_column(tree_view, 3, \"Text\", ALIGN_LEFT | UNSORTABLE);\n\n\tui->log_model = model;\n\tui->log_tree = tree_view;\n}\n\nstatic gint on_config_drawing_area(GtkWidget *w, GdkEventConfigure *event,\n\t\t\t\t   gpointer data)\n{\n\tguint width = gtk_widget_get_allocated_width(w);\n\tguint height = gtk_widget_get_allocated_height(w);\n\tstruct gfio_graphs *g = data;\n\n\tgraph_set_size(g->iops_graph, width / 2.0, height);\n\tgraph_set_position(g->iops_graph, width / 2.0, 0.0);\n\tgraph_set_size(g->bandwidth_graph, width / 2.0, height);\n\tgraph_set_position(g->bandwidth_graph, 0, 0);\n\treturn TRUE;\n}\n\nstatic void draw_graph(struct graph *g, cairo_t *cr)\n{\n\tline_graph_draw(g, cr);\n\tcairo_stroke(cr);\n}\n\nstatic gboolean graph_tooltip(GtkWidget *w, gint x, gint y,\n\t\t\t      gboolean keyboard_mode, GtkTooltip *tooltip,\n\t\t\t      gpointer data)\n{\n\tstruct gfio_graphs *g = data;\n\tconst char *text = NULL;\n\n\tif (graph_contains_xy(g->iops_graph, x, y))\n\t\ttext = graph_find_tooltip(g->iops_graph, x, y);\n\telse if (graph_contains_xy(g->bandwidth_graph, x, y))\n\t\ttext = graph_find_tooltip(g->bandwidth_graph, x, y);\n\n\tif (text) {\n\t\tgtk_tooltip_set_text(tooltip, text);\n\t\treturn TRUE;\n\t}\n\n\treturn FALSE;\n}\n\nstatic int on_expose_drawing_area(GtkWidget *w, GdkEvent *event, gpointer p)\n{\n\tstruct gfio_graphs *g = p;\n\tcairo_t *cr;\n\n\tcr = gdk_cairo_create(gtk_widget_get_window(w));\n\n\tif (graph_has_tooltips(g->iops_graph) ||\n\t    graph_has_tooltips(g->bandwidth_graph)) {\n\t\tg_object_set(w, \"has-tooltip\", TRUE, NULL);\n\t\tg_signal_connect(w, \"query-tooltip\", G_CALLBACK(graph_tooltip), g);\n\t}\n\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tdraw_graph(g->iops_graph, cr);\n\tdraw_graph(g->bandwidth_graph, cr);\n\tcairo_destroy(cr);\n\n\treturn FALSE;\n}\n\n/*\n * FIXME: need more handling here\n */\nstatic void ge_destroy(struct gui_entry *ge)\n{\n\tstruct gfio_client *gc = ge->client;\n\n\tif (gc) {\n\t\tif (gc->client) {\n\t\t\tif (ge->state >= GE_STATE_CONNECTED)\n\t\t\t\tfio_client_terminate(gc->client);\n\n\t\t\tfio_put_client(gc->client);\n\t\t}\n\t\tfree(gc);\n\t}\n\n\tg_hash_table_remove(ge->ui->ge_hash, &ge->page_num);\n\n\tfree(ge->job_file);\n\tfree(ge->host);\n\tfree(ge);\n}\n\nstatic void ge_widget_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tge_destroy(ge);\n}\n\nstatic void gfio_quit(struct gui *ui)\n{\n\tgtk_main_quit();\n}\n\nstatic void quit_clicked(__attribute__((unused)) GtkWidget *widget,\n\t\t\t gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\n\tgfio_quit(ui);\n}\n\nstatic void *job_thread(void *arg)\n{\n\tstruct gui *ui = arg;\n\n\tui->handler_running = 1;\n\tfio_handle_clients(&gfio_client_ops);\n\tui->handler_running = 0;\n\treturn NULL;\n}\n\nstatic int send_job_file(struct gui_entry *ge)\n{\n\tstruct gfio_client *gc = ge->client;\n\tint ret = 0;\n\n\t/*\n\t * Prune old options, we are expecting the return options\n\t * when the job file is parsed remotely and returned to us.\n\t */\n\twhile (!flist_empty(&gc->o_list)) {\n\t\tstruct gfio_client_options *gco;\n\n\t\tgco = flist_first_entry(&gc->o_list, struct gfio_client_options, list);\n\t\tflist_del(&gco->list);\n\t\tfree(gco);\n\t}\n\n\tret = fio_client_send_ini(gc->client, ge->job_file, false);\n\tif (!ret)\n\t\treturn 0;\n\n\tgfio_report_error(ge, \"Failed to send file %s: %s\\n\", ge->job_file, strerror(-ret));\n\treturn 1;\n}\n\nstatic void *server_thread(void *arg)\n{\n\tfio_server_create_sk_key();\n\tis_backend = true;\n\tgfio_server_running = true;\n\tfio_start_server(NULL);\n\tgfio_server_running = false;\n\tfio_server_destroy_sk_key();\n\treturn NULL;\n}\n\nstatic void gfio_start_server(struct gui *ui)\n{\n\tif (!gfio_server_running) {\n\t\tgfio_server_running = true;\n\t\tpthread_create(&ui->server_t, NULL, server_thread, NULL);\n\t\tpthread_detach(ui->server_t);\n\t}\n}\n\nstatic void start_job_clicked(__attribute__((unused)) GtkWidget *widget,\n\t\t\t      gpointer data)\n{\n\tstruct gui_entry *ge = data;\n\tstruct gfio_client *gc = ge->client;\n\n\tif (gc)\n\t\tfio_start_client(gc->client);\n}\n\nstatic void file_open(GtkWidget *w, gpointer data);\n\nstruct connection_widgets\n{\n\tGtkWidget *hentry;\n\tGtkWidget *combo;\n\tGtkWidget *button;\n};\n\nstatic void hostname_cb(GtkEntry *entry, gpointer data)\n{\n\tstruct connection_widgets *cw = data;\n\tint uses_net = 0, is_localhost = 0;\n\tconst gchar *text;\n\tgchar *ctext;\n\n\t/*\n\t * Check whether to display the 'auto start backend' box\n\t * or not. Show it if we are a localhost and using network,\n\t * or using a socket.\n\t */\n\tctext = gtk_combo_box_text_get_active_text(GTK_COMBO_BOX_TEXT(cw->combo));\n\tif (!ctext || !strncmp(ctext, \"IPv4\", 4) || !strncmp(ctext, \"IPv6\", 4))\n\t\tuses_net = 1;\n\tg_free(ctext);\n\n\tif (uses_net) {\n\t\ttext = gtk_entry_get_text(GTK_ENTRY(cw->hentry));\n\t\tif (!strcmp(text, \"127.0.0.1\") || !strcmp(text, \"localhost\") ||\n\t\t    !strcmp(text, \"::1\") || !strcmp(text, \"ip6-localhost\") ||\n\t\t    !strcmp(text, \"ip6-loopback\"))\n\t\t\tis_localhost = 1;\n\t}\n\n\tif (!uses_net || is_localhost) {\n\t\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(cw->button), 1);\n\t\tgtk_widget_set_sensitive(cw->button, 1);\n\t} else {\n\t\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(cw->button), 0);\n\t\tgtk_widget_set_sensitive(cw->button, 0);\n\t}\n}\n\nstatic int get_connection_details(struct gui_entry *ge)\n{\n\tGtkWidget *dialog, *box, *vbox, *hbox, *frame, *pentry;\n\tstruct connection_widgets cw;\n\tstruct gui *ui = ge->ui;\n\tchar *typeentry;\n\n\tif (ge->host)\n\t\treturn 0;\n\n\tdialog = gtk_dialog_new_with_buttons(\"Connection details\",\n\t\t\tGTK_WINDOW(ui->window),\n\t\t\tGTK_DIALOG_DESTROY_WITH_PARENT,\n\t\t\tGTK_STOCK_OK, GTK_RESPONSE_ACCEPT,\n\t\t\tGTK_STOCK_CANCEL, GTK_RESPONSE_REJECT, NULL);\n\n\tframe = gtk_frame_new(\"Hostname / socket name\");\n\tvbox = gtk_dialog_get_content_area(GTK_DIALOG(dialog));\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\n\tbox = gtk_vbox_new(FALSE, 6);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\thbox = gtk_hbox_new(TRUE, 10);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, FALSE, FALSE, 0);\n\tcw.hentry = gtk_entry_new();\n\tgtk_entry_set_text(GTK_ENTRY(cw.hentry), \"localhost\");\n\tgtk_box_pack_start(GTK_BOX(hbox), cw.hentry, TRUE, TRUE, 0);\n\n\tframe = gtk_frame_new(\"Port\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\tbox = gtk_vbox_new(FALSE, 10);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\thbox = gtk_hbox_new(TRUE, 4);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, FALSE, FALSE, 0);\n\tpentry = create_spinbutton(hbox, 1, 65535, FIO_NET_PORT);\n\n\tframe = gtk_frame_new(\"Type\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\tbox = gtk_vbox_new(FALSE, 10);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\thbox = gtk_hbox_new(TRUE, 4);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, FALSE, FALSE, 0);\n\n\tcw.combo = gtk_combo_box_text_new();\n\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(cw.combo), \"IPv4\");\n\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(cw.combo), \"IPv6\");\n\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(cw.combo), \"local socket\");\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(cw.combo), 0);\n\n\tgtk_container_add(GTK_CONTAINER(hbox), cw.combo);\n\n\tframe = gtk_frame_new(\"Options\");\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\tbox = gtk_vbox_new(FALSE, 10);\n\tgtk_container_add(GTK_CONTAINER(frame), box);\n\n\thbox = gtk_hbox_new(TRUE, 4);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, FALSE, FALSE, 0);\n\n\tcw.button = gtk_check_button_new_with_label(\"Auto-spawn fio backend\");\n\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(cw.button), 1);\n\tgtk_widget_set_tooltip_text(cw.button, \"When running fio locally, it is necessary to have the backend running on the same system. If this is checked, gfio will start the backend automatically for you if it isn't already running.\");\n\tgtk_box_pack_start(GTK_BOX(hbox), cw.button, FALSE, FALSE, 6);\n\n\t/*\n\t * Connect edit signal, so we can show/not-show the auto start button\n\t */\n\tg_signal_connect(G_OBJECT(cw.hentry), \"changed\", G_CALLBACK(hostname_cb), &cw);\n\tg_signal_connect(G_OBJECT(cw.combo), \"changed\", G_CALLBACK(hostname_cb), &cw);\n\n\tgtk_widget_show_all(dialog);\n\n\tif (gtk_dialog_run(GTK_DIALOG(dialog)) != GTK_RESPONSE_ACCEPT) {\n\t\tgtk_widget_destroy(dialog);\n\t\treturn 1;\n\t}\n\n\tge->host = strdup(gtk_entry_get_text(GTK_ENTRY(cw.hentry)));\n\tge->port = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(pentry));\n\n\ttypeentry = gtk_combo_box_text_get_active_text(GTK_COMBO_BOX_TEXT(cw.combo));\n\tif (!typeentry || !strncmp(typeentry, \"IPv4\", 4))\n\t\tge->type = Fio_client_ipv4;\n\telse if (!strncmp(typeentry, \"IPv6\", 4))\n\t\tge->type = Fio_client_ipv6;\n\telse\n\t\tge->type = Fio_client_socket;\n\tg_free(typeentry);\n\n\tge->server_start = gtk_toggle_button_get_active(GTK_TOGGLE_BUTTON(cw.button));\n\n\tgtk_widget_destroy(dialog);\n\treturn 0;\n}\n\nstatic void gfio_set_client(struct gfio_client *gc, struct fio_client *client)\n{\n\tgc->client = fio_get_client(client);\n\tclient->client_data = gc;\n}\n\nstatic void gfio_client_added(struct gui_entry *ge, struct fio_client *client)\n{\n\tstruct gfio_client_options *gco;\n\tstruct gfio_client *gc;\n\n\tgc = calloc(1, sizeof(*gc));\n\tINIT_FLIST_HEAD(&gc->o_list);\n\tgc->ge = ge;\n\tge->client = gc;\n\tgfio_set_client(gc, client);\n\n\t/*\n\t * Just add a default set of options, need to consider how best\n\t * to handle this\n\t */\n\tgco = calloc(1, sizeof(*gco));\n\tINIT_FLIST_HEAD(&gco->list);\n\toptions_default_fill(&gco->o);\n\tflist_add_tail(&gco->list, &gc->o_list);\n\tgc->o_list_nr++;\n}\n\nstatic void gfio_clear_graph_data(struct gfio_graphs *g)\n{\n\tgraph_clear_values(g->iops_graph);\n\tgraph_clear_values(g->bandwidth_graph);\n}\n\nstatic void connect_clicked(GtkWidget *widget, gpointer data)\n{\n\tstruct gui_entry *ge = data;\n\tstruct gfio_client *gc = ge->client;\n\n\tif (ge->state == GE_STATE_NEW) {\n\t\tint ret;\n\n\t\tif (!ge->job_file)\n\t\t\tfile_open(widget, ge->ui);\n\t\tif (!ge->job_file)\n\t\t\treturn;\n\n\t\tgc = ge->client;\n\n\t\tif (!gc->client) {\n\t\t\tstruct fio_client *client;\n\n\t\t\tif (get_connection_details(ge)) {\n\t\t\t\tgfio_report_error(ge, \"Failed to get connection details\\n\");\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tclient = fio_client_add_explicit(&gfio_client_ops, ge->host, ge->type, ge->port);\n\t\t\tif (!client) {\n\t\t\t\tgfio_report_error(ge, \"Failed to add client %s\\n\", ge->host);\n\t\t\t\tfree(ge->host);\n\t\t\t\tge->host = NULL;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tgfio_set_client(gc, client);\n\t\t}\n\n\t\tgtk_progress_bar_set_text(GTK_PROGRESS_BAR(ge->thread_status_pb), \"No jobs running\");\n\t\tgtk_progress_bar_set_fraction(GTK_PROGRESS_BAR(ge->thread_status_pb), 0.0);\n\t\tret = fio_client_connect(gc->client);\n\t\tif (!ret) {\n\t\t\tif (!ge->ui->handler_running)\n\t\t\t\tpthread_create(&ge->ui->t, NULL, job_thread, ge->ui);\n\t\t\tgfio_set_state(ge, GE_STATE_CONNECTED);\n\t\t\tgfio_clear_graph_data(&ge->graphs);\n\t\t} else {\n\t\t\tgfio_report_error(ge, \"Failed to connect to %s: %s\\n\", ge->client->client->hostname, strerror(-ret));\n\t\t}\n\t} else {\n\t\tfio_client_terminate(gc->client);\n\t\tgfio_set_state(ge, GE_STATE_NEW);\n\t\tclear_ge_ui_info(ge);\n\t}\n}\n\nstatic void send_clicked(GtkWidget *widget, gpointer data)\n{\n\tstruct gui_entry *ge = data;\n\n\tif (send_job_file(ge))\n\t\tgtk_widget_set_sensitive(ge->button[GFIO_BUTTON_START], 1);\n}\n\nstatic GtkWidget *new_client_page(struct gui_entry *ge);\n\nstatic struct gui_entry *alloc_new_gui_entry(struct gui *ui)\n{\n\tstruct gui_entry *ge;\n\n\tge = calloc(1, sizeof(*ge));\n\tge->state = GE_STATE_NEW;\n\tge->ui = ui;\n\treturn ge;\n}\n\nstatic struct gui_entry *get_new_ge_with_tab(struct gui *ui, const char *name)\n{\n\tstruct gui_entry *ge;\n\n\tge = alloc_new_gui_entry(ui);\n\n\tge->vbox = new_client_page(ge);\n\tg_signal_connect(ge->vbox, \"destroy\", G_CALLBACK(ge_widget_destroy), ge);\n\n\tge->page_label = gtk_label_new(name);\n\tge->page_num = gtk_notebook_append_page(GTK_NOTEBOOK(ui->notebook), ge->vbox, ge->page_label);\n\n\tg_hash_table_insert(ui->ge_hash, &ge->page_num, ge);\n\n\tgtk_widget_show_all(ui->window);\n\treturn ge;\n}\n\nstatic void file_new(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tge = get_new_ge_with_tab(ui, \"Untitled\");\n\tgtk_notebook_set_current_page(GTK_NOTEBOOK(ui->notebook), ge->page_num);\n}\n\n/*\n * Return the 'ge' corresponding to the tab. If the active tab is the\n * main tab, open a new tab.\n */\nstatic struct gui_entry *get_ge_from_page(struct gui *ui, gint cur_page,\n\t\t\t\t\t  int *created)\n{\n\tif (!cur_page) {\n\t\tif (created)\n\t\t\t*created = 1;\n\t\treturn get_new_ge_with_tab(ui, \"Untitled\");\n\t}\n\n\tif (created)\n\t\t*created = 0;\n\n\treturn g_hash_table_lookup(ui->ge_hash, &cur_page);\n}\n\nstatic struct gui_entry *get_ge_from_cur_tab(struct gui *ui)\n{\n\tgint cur_page;\n\n\t/*\n\t * Main tab is tab 0, so any current page other than 0 holds\n\t * a ge entry.\n\t */\n\tcur_page = gtk_notebook_get_current_page(GTK_NOTEBOOK(ui->notebook));\n\tif (cur_page)\n\t\treturn get_ge_from_page(ui, cur_page, NULL);\n\n\treturn NULL;\n}\n\nstatic void file_close(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\t/*\n\t * Can't close the main tab\n\t */\n\tge = get_ge_from_cur_tab(ui);\n\tif (ge) {\n\t\tgtk_widget_destroy(ge->vbox);\n\t\treturn;\n\t}\n\n\tif (g_hash_table_size(ui->ge_hash)) {\n\t\tgfio_report_info(ui, \"Error\", \"The main page view cannot be closed\\n\");\n\t\treturn;\n\t}\n\n\tgfio_quit(ui);\n}\n\nstatic void file_add_recent(struct gui *ui, const gchar *uri)\n{\n\tGtkRecentData grd;\n\n\tmemset(&grd, 0, sizeof(grd));\n\tgrd.display_name = strdup(\"gfio\");\n\tgrd.description = strdup(\"Fio job file\");\n\tgrd.mime_type = strdup(GFIO_MIME);\n\tgrd.app_name = strdup(g_get_application_name());\n\tgrd.app_exec = strdup(\"gfio %f/%u\");\n\n\tgtk_recent_manager_add_full(ui->recentmanager, uri, &grd);\n}\n\nstatic gchar *get_filename_from_uri(const gchar *uri)\n{\n\tif (strncmp(uri, \"file://\", 7))\n\t\treturn strdup(uri);\n\n\treturn strdup(uri + 7);\n}\n\nstatic int do_file_open(struct gui_entry *ge, const gchar *uri)\n{\n\tstruct fio_client *client;\n\n\tassert(!ge->job_file);\n\n\tge->job_file = get_filename_from_uri(uri);\n\n\tclient = fio_client_add_explicit(&gfio_client_ops, ge->host, ge->type, ge->port);\n\tif (client) {\n\t\tchar *label = strdup(uri);\n\n\t\tbasename(label);\n\t\tgtk_label_set_text(GTK_LABEL(ge->page_label), basename(label));\n\t\tfree(label);\n\n\t\tgfio_client_added(ge, client);\n\t\tfile_add_recent(ge->ui, uri);\n\t\treturn 0;\n\t}\n\n\tgfio_report_error(ge, \"Failed to add client %s\\n\", ge->host);\n\tfree(ge->host);\n\tge->host = NULL;\n\tfree(ge->job_file);\n\tge->job_file = NULL;\n\treturn 1;\n}\n\nstatic int do_file_open_with_tab(struct gui *ui, const gchar *uri)\n{\n\tstruct gui_entry *ge;\n\tgint cur_page;\n\tint ret, ge_is_new = 0;\n\n\t/*\n\t * Creates new tab if current tab is the main window, or the\n\t * current tab already has a client.\n\t */\n\tcur_page = gtk_notebook_get_current_page(GTK_NOTEBOOK(ui->notebook));\n\tge = get_ge_from_page(ui, cur_page, &ge_is_new);\n\tif (ge->client) {\n\t\tge = get_new_ge_with_tab(ui, \"Untitled\");\n\t\tge_is_new = 1;\n\t}\n\n\tgtk_notebook_set_current_page(GTK_NOTEBOOK(ui->notebook), ge->page_num);\n\n\tif (get_connection_details(ge)) {\n\t\tif (ge_is_new)\n\t\t\tgtk_widget_destroy(ge->vbox);\n\n\t\treturn 1;\n\t}\n\n\tret = do_file_open(ge, uri);\n\n\tif (!ret) {\n\t\tif (ge->server_start)\n\t\t\tgfio_start_server(ui);\n\t} else {\n\t\tif (ge_is_new)\n\t\t\tgtk_widget_destroy(ge->vbox);\n\t}\n\n\treturn ret;\n}\n\nstatic void recent_open(GtkAction *action, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tGtkRecentInfo *info;\n\tconst gchar *uri;\n\n\tinfo = g_object_get_data(G_OBJECT(action), \"gtk-recent-info\");\n\turi = gtk_recent_info_get_uri(info);\n\n\tdo_file_open_with_tab(ui, uri);\n}\n\nstatic void file_open(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = data;\n\tGtkWidget *dialog;\n\tGtkFileFilter *filter;\n\tgchar *filename;\n\n\tdialog = gtk_file_chooser_dialog_new(\"Open File\",\n\t\tGTK_WINDOW(ui->window),\n\t\tGTK_FILE_CHOOSER_ACTION_OPEN,\n\t\tGTK_STOCK_CANCEL, GTK_RESPONSE_CANCEL,\n\t\tGTK_STOCK_OPEN, GTK_RESPONSE_ACCEPT,\n\t\tNULL);\n\tgtk_file_chooser_set_select_multiple(GTK_FILE_CHOOSER(dialog), FALSE);\n\n\tfilter = gtk_file_filter_new();\n\tgtk_file_filter_add_pattern(filter, \"*.fio\");\n\tgtk_file_filter_add_pattern(filter, \"*.job\");\n\tgtk_file_filter_add_pattern(filter, \"*.ini\");\n\tgtk_file_filter_add_mime_type(filter, GFIO_MIME);\n\tgtk_file_filter_set_name(filter, \"Fio job file\");\n\tgtk_file_chooser_set_filter(GTK_FILE_CHOOSER(dialog), filter);\n\n\tif (gtk_dialog_run(GTK_DIALOG(dialog)) != GTK_RESPONSE_ACCEPT) {\n\t\tgtk_widget_destroy(dialog);\n\t\treturn;\n\t}\n\n\tfilename = gtk_file_chooser_get_filename(GTK_FILE_CHOOSER(dialog));\n\n\tgtk_widget_destroy(dialog);\n\n\tdo_file_open_with_tab(ui, filename);\n\tg_free(filename);\n}\n\nstatic void file_save(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = data;\n\tGtkWidget *dialog;\n\n\tdialog = gtk_file_chooser_dialog_new(\"Save File\",\n\t\tGTK_WINDOW(ui->window),\n\t\tGTK_FILE_CHOOSER_ACTION_SAVE,\n\t\tGTK_STOCK_CANCEL, GTK_RESPONSE_CANCEL,\n\t\tGTK_STOCK_SAVE, GTK_RESPONSE_ACCEPT,\n\t\tNULL);\n\n\tgtk_file_chooser_set_do_overwrite_confirmation(GTK_FILE_CHOOSER(dialog), TRUE);\n\tgtk_file_chooser_set_current_name(GTK_FILE_CHOOSER(dialog), \"Untitled document\");\n\n\tif (gtk_dialog_run(GTK_DIALOG(dialog)) == GTK_RESPONSE_ACCEPT) {\n\t\tchar *filename;\n\n\t\tfilename = gtk_file_chooser_get_filename(GTK_FILE_CHOOSER(dialog));\n\t\t// save_job_file(filename);\n\t\tg_free(filename);\n\t}\n\tgtk_widget_destroy(dialog);\n}\n\nstatic void view_log_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\n\tg_object_ref(G_OBJECT(ui->log_tree));\n\tgtk_container_remove(GTK_CONTAINER(w), ui->log_tree);\n\tgtk_widget_destroy(w);\n\tui->log_view = NULL;\n}\n\nvoid gfio_view_log(struct gui *ui)\n{\n\tGtkWidget *win, *scroll, *vbox, *box;\n\n\tif (ui->log_view)\n\t\treturn;\n\n\tui->log_view = win = gtk_window_new(GTK_WINDOW_TOPLEVEL);\n\tgtk_window_set_title(GTK_WINDOW(win), \"Log\");\n\tgtk_window_set_default_size(GTK_WINDOW(win), 700, 500);\n\n\tscroll = gtk_scrolled_window_new(NULL, NULL);\n\n\tgtk_container_set_border_width(GTK_CONTAINER(scroll), 5);\n\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scroll), GTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\n\tbox = gtk_hbox_new(TRUE, 0);\n\tgtk_box_pack_start(GTK_BOX(box), ui->log_tree, TRUE, TRUE, 0);\n\tg_signal_connect(box, \"destroy\", G_CALLBACK(view_log_destroy), ui);\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scroll), box);\n\n\tvbox = gtk_vbox_new(TRUE, 5);\n\tgtk_box_pack_start(GTK_BOX(vbox), scroll, TRUE, TRUE, 0);\n\n\tgtk_container_add(GTK_CONTAINER(win), vbox);\n\tgtk_widget_show_all(win);\n}\n\nstatic void view_log(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\n\tgfio_view_log(ui);\n}\n\nstatic void connect_job_entry(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tge = get_ge_from_cur_tab(ui);\n\tif (ge)\n\t\tconnect_clicked(w, ge);\n}\n\nstatic void send_job_entry(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tge = get_ge_from_cur_tab(ui);\n\tif (ge)\n\t\tsend_clicked(w, ge);\n}\n\nstatic void edit_job_entry(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tge = get_ge_from_cur_tab(ui);\n\tif (ge && ge->client)\n\t\tgopt_get_options_window(ui->window, ge->client);\n}\n\nstatic void start_job_entry(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tge = get_ge_from_cur_tab(ui);\n\tif (ge)\n\t\tstart_job_clicked(w, ge);\n}\n\nstatic void view_results(GtkWidget *w, gpointer data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gfio_client *gc;\n\tstruct gui_entry *ge;\n\n\tge = get_ge_from_cur_tab(ui);\n\tif (!ge)\n\t\treturn;\n\n\tif (ge->results_window)\n\t\treturn;\n\n\tgc = ge->client;\n\tif (gc && gc->nr_results)\n\t\tgfio_display_end_results(gc);\n}\n\nstatic void __update_graph_settings(struct gfio_graphs *g)\n{\n\tline_graph_set_data_count_limit(g->iops_graph, gfio_graph_limit);\n\tgraph_set_font(g->iops_graph, gfio_graph_font);\n\tline_graph_set_data_count_limit(g->bandwidth_graph, gfio_graph_limit);\n\tgraph_set_font(g->bandwidth_graph, gfio_graph_font);\n}\n\nstatic void ge_update_settings_fn(gpointer key, gpointer value, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) value;\n\tGdkEvent *ev;\n\n\t__update_graph_settings(&ge->graphs);\n\n\tev = gdk_event_new(GDK_EXPOSE);\n\tg_signal_emit_by_name(G_OBJECT(ge->graphs.drawing_area), GFIO_DRAW_EVENT, GTK_WIDGET(ge->graphs.drawing_area), ev, &ge->graphs);\n\tgdk_event_free(ev);\n}\n\nstatic void update_graph_limits(void)\n{\n\tstruct gui *ui = &main_ui;\n\tGdkEvent *ev;\n\n\t__update_graph_settings(&ui->graphs);\n\n\tev = gdk_event_new(GDK_EXPOSE);\n\tg_signal_emit_by_name(G_OBJECT(ui->graphs.drawing_area), GFIO_DRAW_EVENT, GTK_WIDGET(ui->graphs.drawing_area), ev, &ui->graphs);\n\tgdk_event_free(ev);\n\n\tg_hash_table_foreach(ui->ge_hash, ge_update_settings_fn, NULL);\n}\n\nstatic void preferences(GtkWidget *w, gpointer data)\n{\n\tGtkWidget *dialog, *frame, *box, **buttons, *vbox, *font;\n\tGtkWidget *hbox, *spin, *entry, *spin_int;\n\tstruct gui *ui = (struct gui *) data;\n\tint i;\n\n\tdialog = gtk_dialog_new_with_buttons(\"Preferences\",\n\t\tGTK_WINDOW(ui->window),\n\t\tGTK_DIALOG_DESTROY_WITH_PARENT,\n\t\tGTK_STOCK_OK, GTK_RESPONSE_ACCEPT,\n\t\tGTK_STOCK_CANCEL, GTK_RESPONSE_REJECT,\n\t\tNULL);\n\n\tframe = gtk_frame_new(\"Graphing\");\n\tvbox = gtk_dialog_get_content_area(GTK_DIALOG(dialog));\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\tvbox = gtk_vbox_new(FALSE, 6);\n\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\n\thbox = gtk_hbox_new(FALSE, 5);\n\tgtk_box_pack_start(GTK_BOX(vbox), hbox, FALSE, FALSE, 5);\n\tentry = gtk_label_new(\"Font face to use for graph labels\");\n\tgtk_box_pack_start(GTK_BOX(hbox), entry, TRUE, TRUE, 5);\n\n\tfont = gtk_font_button_new_with_font(gfio_graph_font);\n\tgtk_box_pack_start(GTK_BOX(hbox), font, FALSE, FALSE, 5);\n\n\tbox = gtk_vbox_new(FALSE, 6);\n\tgtk_box_pack_start(GTK_BOX(vbox), box, FALSE, FALSE, 5);\n\n\thbox = gtk_hbox_new(FALSE, 5);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, TRUE, TRUE, 5);\n\tentry = gtk_label_new(\"Maximum number of data points in graph (seconds)\");\n\tgtk_box_pack_start(GTK_BOX(hbox), entry, FALSE, FALSE, 5);\n\n\tspin = create_spinbutton(hbox, 10, 1000000, gfio_graph_limit);\n\n\tbox = gtk_vbox_new(FALSE, 6);\n\tgtk_box_pack_start(GTK_BOX(vbox), box, FALSE, FALSE, 5);\n\n\thbox = gtk_hbox_new(FALSE, 5);\n\tgtk_box_pack_start(GTK_BOX(box), hbox, TRUE, TRUE, 5);\n\tentry = gtk_label_new(\"Client ETA request interval (msec)\");\n\tgtk_box_pack_start(GTK_BOX(hbox), entry, FALSE, FALSE, 5);\n\n\tspin_int = create_spinbutton(hbox, 100, 100000, gfio_client_ops.eta_msec);\n\tframe = gtk_frame_new(\"Debug logging\");\n\tvbox = gtk_dialog_get_content_area(GTK_DIALOG(dialog));\n\tgtk_box_pack_start(GTK_BOX(vbox), frame, FALSE, FALSE, 5);\n\tvbox = gtk_vbox_new(FALSE, 6);\n\tgtk_container_add(GTK_CONTAINER(frame), vbox);\n\n\tbox = gtk_hbox_new(FALSE, 6);\n\tgtk_container_add(GTK_CONTAINER(vbox), box);\n\n\tbuttons = malloc(sizeof(GtkWidget *) * FD_DEBUG_MAX);\n\n\tfor (i = 0; i < FD_DEBUG_MAX; i++) {\n\t\tif (i == 7) {\n\t\t\tbox = gtk_hbox_new(FALSE, 6);\n\t\t\tgtk_container_add(GTK_CONTAINER(vbox), box);\n\t\t}\n\n\n\t\tbuttons[i] = gtk_check_button_new_with_label(debug_levels[i].name);\n\t\tgtk_widget_set_tooltip_text(buttons[i], debug_levels[i].help);\n\t\tgtk_box_pack_start(GTK_BOX(box), buttons[i], FALSE, FALSE, 6);\n\t}\n\n\tgtk_widget_show_all(dialog);\n\n\tif (gtk_dialog_run(GTK_DIALOG(dialog)) != GTK_RESPONSE_ACCEPT) {\n\t\tgtk_widget_destroy(dialog);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < FD_DEBUG_MAX; i++) {\n\t\tint set;\n\n\t\tset = gtk_toggle_button_get_active(GTK_TOGGLE_BUTTON(buttons[i]));\n\t\tif (set)\n\t\t\tfio_debug |= (1UL << i);\n\t}\n\n\tgfio_graph_font = strdup(gtk_font_button_get_font_name(GTK_FONT_BUTTON(font)));\n\tgfio_graph_limit = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(spin));\n\tupdate_graph_limits();\n\tgfio_client_ops.eta_msec = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(spin_int));\n\n\tgtk_widget_destroy(dialog);\n}\n\nstatic void about_dialog(GtkWidget *w, gpointer data)\n{\n\tconst char *authors[] = {\n\t\t\"Jens Axboe <axboe@kernel.dk>\",\n\t\t\"Stephen Cameron <stephenmcameron@gmail.com>\",\n\t\tNULL\n\t};\n\tconst char *license[] = {\n\t\t\"Fio is free software; you can redistribute it and/or modify \"\n\t\t\"it under the terms of the GNU General Public License as published by \"\n\t\t\"the Free Software Foundation; either version 2 of the License, or \"\n\t\t\"(at your option) any later version.\\n\",\n\t\t\"Fio is distributed in the hope that it will be useful, \"\n\t\t\"but WITHOUT ANY WARRANTY; without even the implied warranty of \"\n\t\t\"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the \"\n\t\t\"GNU General Public License for more details.\\n\",\n\t\t\"You should have received a copy of the GNU General Public License \"\n\t\t\"along with Fio; if not, write to the Free Software Foundation, Inc., \"\n\t\t\"51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA\\n\"\n\t};\n\tchar *license_trans;\n\n\tlicense_trans = g_strconcat(license[0], \"\\n\", license[1], \"\\n\",\n\t\t\t\t     license[2], \"\\n\", NULL);\n\n\tgtk_show_about_dialog(NULL,\n\t\t\"program-name\", \"gfio\",\n\t\t\"comments\", \"Gtk2 UI for fio\",\n\t\t\"license\", license_trans,\n\t\t\"website\", \"http://git.kernel.dk/cgit/fio/\",\n\t\t\"authors\", authors,\n\t\t\"version\", fio_version_string,\n\t\t\"copyright\", \"© 2012-2017 Jens Axboe <axboe@kernel.dk>\",\n\t\t\"logo-icon-name\", \"fio\",\n\t\t/* Must be last: */\n\t\t\"wrap-license\", TRUE,\n\t\tNULL);\n\n\tg_free(license_trans);\n}\n\nstatic GtkActionEntry menu_items[] = {\n\t{ \"FileMenuAction\", GTK_STOCK_FILE, \"File\", NULL, NULL, NULL},\n\t{ \"ViewMenuAction\", GTK_STOCK_FILE, \"View\", NULL, NULL, NULL},\n\t{ \"JobMenuAction\", GTK_STOCK_FILE, \"Job\", NULL, NULL, NULL},\n\t{ \"HelpMenuAction\", GTK_STOCK_HELP, \"Help\", NULL, NULL, NULL},\n\t{ \"NewFile\", GTK_STOCK_NEW, \"New\", \"<Control>N\", NULL, G_CALLBACK(file_new) },\n\t{ \"CloseFile\", GTK_STOCK_CLOSE, \"Close\", \"<Control>W\", NULL, G_CALLBACK(file_close) },\n\t{ \"OpenFile\", GTK_STOCK_OPEN, NULL,   \"<Control>O\", NULL, G_CALLBACK(file_open) },\n\t{ \"SaveFile\", GTK_STOCK_SAVE, NULL,   \"<Control>S\", NULL, G_CALLBACK(file_save) },\n\t{ \"Preferences\", GTK_STOCK_PREFERENCES, NULL, \"<Control>p\", NULL, G_CALLBACK(preferences) },\n\t{ \"ViewLog\", NULL, \"Log\", \"<Control>l\", NULL, G_CALLBACK(view_log) },\n\t{ \"ViewResults\", NULL, \"Results\", \"<Control>R\", NULL, G_CALLBACK(view_results) },\n\t{ \"ConnectJob\", NULL, \"Connect\", \"<Control>D\", NULL, G_CALLBACK(connect_job_entry) },\n\t{ \"EditJob\", NULL, \"Edit job\", \"<Control>E\", NULL, G_CALLBACK(edit_job_entry) },\n\t{ \"SendJob\", NULL, \"Send job\", \"<Control>X\", NULL, G_CALLBACK(send_job_entry) },\n\t{ \"StartJob\", NULL, \"Start job\", \"<Control>L\", NULL, G_CALLBACK(start_job_entry) },\n\t{ \"Quit\", GTK_STOCK_QUIT, NULL,   \"<Control>Q\", NULL, G_CALLBACK(quit_clicked) },\n\t{ \"About\", GTK_STOCK_ABOUT, NULL,  NULL, NULL, G_CALLBACK(about_dialog) },\n};\nstatic gint nmenu_items = FIO_ARRAY_SIZE(menu_items);\n\nstatic const gchar *ui_string = \" \\\n\t<ui> \\\n\t\t<menubar name=\\\"MainMenu\\\"> \\\n\t\t\t<menu name=\\\"FileMenu\\\" action=\\\"FileMenuAction\\\"> \\\n\t\t\t\t<menuitem name=\\\"New\\\" action=\\\"NewFile\\\" /> \\\n\t\t\t\t<menuitem name=\\\"Open\\\" action=\\\"OpenFile\\\" /> \\\n\t\t\t\t<menuitem name=\\\"Close\\\" action=\\\"CloseFile\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator1\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Save\\\" action=\\\"SaveFile\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator2\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Preferences\\\" action=\\\"Preferences\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator3\\\"/> \\\n\t\t\t\t<placeholder name=\\\"FileRecentFiles\\\"/> \\\n\t\t\t\t<separator name=\\\"Separator4\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Quit\\\" action=\\\"Quit\\\" /> \\\n\t\t\t</menu> \\\n\t\t\t<menu name=\\\"JobMenu\\\" action=\\\"JobMenuAction\\\"> \\\n\t\t\t\t<menuitem name=\\\"Connect\\\" action=\\\"ConnectJob\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator5\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Edit job\\\" action=\\\"EditJob\\\" /> \\\n\t\t\t\t<menuitem name=\\\"Send job\\\" action=\\\"SendJob\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator6\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Start job\\\" action=\\\"StartJob\\\" /> \\\n\t\t\t</menu>\\\n\t\t\t<menu name=\\\"ViewMenu\\\" action=\\\"ViewMenuAction\\\"> \\\n\t\t\t\t<menuitem name=\\\"Results\\\" action=\\\"ViewResults\\\" /> \\\n\t\t\t\t<separator name=\\\"Separator7\\\"/> \\\n\t\t\t\t<menuitem name=\\\"Log\\\" action=\\\"ViewLog\\\" /> \\\n\t\t\t</menu>\\\n\t\t\t<menu name=\\\"Help\\\" action=\\\"HelpMenuAction\\\"> \\\n\t\t\t\t<menuitem name=\\\"About\\\" action=\\\"About\\\" /> \\\n\t\t\t</menu> \\\n\t\t</menubar> \\\n\t</ui> \\\n\";\n\nstatic GtkWidget *get_menubar_menu(GtkWidget *window, GtkUIManager *ui_manager,\n\t\t\t\t   struct gui *ui)\n{\n\tGtkActionGroup *action_group;\n\tGError *error = 0;\n\n\taction_group = gtk_action_group_new(\"Menu\");\n\tgtk_action_group_add_actions(action_group, menu_items, nmenu_items, ui);\n\n\tgtk_ui_manager_insert_action_group(ui_manager, action_group, 0);\n\tgtk_ui_manager_add_ui_from_string(GTK_UI_MANAGER(ui_manager), ui_string, -1, &error);\n\n\tgtk_window_add_accel_group(GTK_WINDOW(window), gtk_ui_manager_get_accel_group(ui_manager));\n\n\treturn gtk_ui_manager_get_widget(ui_manager, \"/MainMenu\");\n}\n\nvoid gfio_ui_setup(GtkSettings *settings, GtkWidget *menubar,\n\t\t   GtkWidget *vbox, GtkUIManager *ui_manager)\n{\n\tgtk_box_pack_start(GTK_BOX(vbox), menubar, FALSE, FALSE, 0);\n}\n\nstatic void combo_entry_changed(GtkComboBox *box, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\tgint index;\n\n\tindex = gtk_combo_box_get_active(box);\n\n\tmultitext_set_entry(&ge->eta.iotype, index);\n\tmultitext_set_entry(&ge->eta.bs, index);\n\tmultitext_set_entry(&ge->eta.ioengine, index);\n\tmultitext_set_entry(&ge->eta.iodepth, index);\n}\n\nstatic void combo_entry_destroy(GtkWidget *widget, gpointer data)\n{\n\tstruct gui_entry *ge = (struct gui_entry *) data;\n\n\tmultitext_free(&ge->eta.iotype);\n\tmultitext_free(&ge->eta.bs);\n\tmultitext_free(&ge->eta.ioengine);\n\tmultitext_free(&ge->eta.iodepth);\n}\n\nstatic GtkWidget *new_client_page(struct gui_entry *ge)\n{\n\tGtkWidget *main_vbox, *probe, *probe_frame, *probe_box;\n\tGtkWidget *scrolled_window, *bottom_align, *top_align, *top_vbox;\n\n\tmain_vbox = gtk_vbox_new(FALSE, 3);\n\n\ttop_align = gtk_alignment_new(0, 0, 1, 0);\n\ttop_vbox = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(top_align), top_vbox);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), top_align, FALSE, FALSE, 0);\n\n\tprobe = gtk_frame_new(\"Job\");\n\tgtk_box_pack_start(GTK_BOX(main_vbox), probe, FALSE, FALSE, 3);\n\tprobe_frame = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(probe), probe_frame);\n\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, FALSE, FALSE, 3);\n\tge->probe.hostname = new_info_label_in_frame(probe_box, \"Host\");\n\tge->probe.os = new_info_label_in_frame(probe_box, \"OS\");\n\tge->probe.arch = new_info_label_in_frame(probe_box, \"Architecture\");\n\tge->probe.fio_ver = new_info_label_in_frame(probe_box, \"Fio version\");\n\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, FALSE, FALSE, 3);\n\n\tge->eta.names = new_combo_entry_in_frame(probe_box, \"Jobs\");\n\tg_signal_connect(ge->eta.names, \"changed\", G_CALLBACK(combo_entry_changed), ge);\n\tg_signal_connect(ge->eta.names, \"destroy\", G_CALLBACK(combo_entry_destroy), ge);\n\tge->eta.iotype.entry = new_info_entry_in_frame(probe_box, \"IO\");\n\tge->eta.bs.entry = new_info_entry_in_frame(probe_box, \"Blocksize (Read/Write/Trim)\");\n\tge->eta.ioengine.entry = new_info_entry_in_frame(probe_box, \"IO Engine\");\n\tge->eta.iodepth.entry = new_info_entry_in_frame(probe_box, \"IO Depth\");\n\tge->eta.jobs = new_info_entry_in_frame(probe_box, \"Jobs\");\n\tge->eta.files = new_info_entry_in_frame(probe_box, \"Open files\");\n\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, FALSE, FALSE, 3);\n\tge->eta.read_bw = new_info_entry_in_frame_rgb(probe_box, \"Read BW\", GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tge->eta.read_iops = new_info_entry_in_frame_rgb(probe_box, \"Read IOPS\", GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tge->eta.write_bw = new_info_entry_in_frame_rgb(probe_box, \"Write BW\", GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tge->eta.write_iops = new_info_entry_in_frame_rgb(probe_box, \"Write IOPS\", GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tge->eta.trim_bw = new_info_entry_in_frame_rgb(probe_box, \"Trim BW\", GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\tge->eta.trim_iops = new_info_entry_in_frame_rgb(probe_box, \"Trim IOPS\", GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\n\t/*\n\t * Only add this if we have a commit rate\n\t */\n#if 0\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, TRUE, FALSE, 3);\n\n\tge->eta.cr_bw = new_info_label_in_frame(probe_box, \"Commit BW\");\n\tge->eta.cr_iops = new_info_label_in_frame(probe_box, \"Commit IOPS\");\n\n\tge->eta.cw_bw = new_info_label_in_frame(probe_box, \"Commit BW\");\n\tge->eta.cw_iops = new_info_label_in_frame(probe_box, \"Commit IOPS\");\n#endif\n\n\t/*\n\t * Set up a drawing area and IOPS and bandwidth graphs\n\t */\n\tge->graphs.drawing_area = gtk_drawing_area_new();\n\tgtk_widget_set_size_request(GTK_WIDGET(ge->graphs.drawing_area),\n\t\tDRAWING_AREA_XDIM, DRAWING_AREA_YDIM);\n\tgtk_widget_modify_bg(ge->graphs.drawing_area, GTK_STATE_NORMAL, &gfio_color_lightyellow);\n\tg_signal_connect(G_OBJECT(ge->graphs.drawing_area), GFIO_DRAW_EVENT,\n\t\t\t\tG_CALLBACK(on_expose_drawing_area), &ge->graphs);\n\tg_signal_connect(G_OBJECT(ge->graphs.drawing_area), \"configure_event\",\n\t\t\t\tG_CALLBACK(on_config_drawing_area), &ge->graphs);\n\tscrolled_window = gtk_scrolled_window_new(NULL, NULL);\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scrolled_window),\n\t\t\t\t\tGTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scrolled_window),\n\t\t\t\t\tge->graphs.drawing_area);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), scrolled_window, TRUE, TRUE, 0);\n\n\tsetup_graphs(&ge->graphs);\n\n\t/*\n\t * Set up alignments for widgets at the bottom of ui,\n\t * align bottom left, expand horizontally but not vertically\n\t */\n\tbottom_align = gtk_alignment_new(0, 1, 1, 0);\n\tge->buttonbox = gtk_hbox_new(FALSE, 0);\n\tgtk_container_add(GTK_CONTAINER(bottom_align), ge->buttonbox);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), bottom_align, FALSE, FALSE, 0);\n\n\tadd_buttons(ge, buttonspeclist, FIO_ARRAY_SIZE(buttonspeclist));\n\n\t/*\n\t * Set up thread status progress bar\n\t */\n\tge->thread_status_pb = gtk_progress_bar_new();\n\tgtk_progress_bar_set_fraction(GTK_PROGRESS_BAR(ge->thread_status_pb), 0.0);\n\tgtk_progress_bar_set_text(GTK_PROGRESS_BAR(ge->thread_status_pb), \"No connections\");\n\tgtk_container_add(GTK_CONTAINER(ge->buttonbox), ge->thread_status_pb);\n\n\n\treturn main_vbox;\n}\n\nstatic GtkWidget *new_main_page(struct gui *ui)\n{\n\tGtkWidget *main_vbox, *probe, *probe_frame, *probe_box;\n\tGtkWidget *scrolled_window, *bottom_align, *top_align, *top_vbox;\n\n\tmain_vbox = gtk_vbox_new(FALSE, 3);\n\n\t/*\n\t * Set up alignments for widgets at the top of ui,\n\t * align top left, expand horizontally but not vertically\n\t */\n\ttop_align = gtk_alignment_new(0, 0, 1, 0);\n\ttop_vbox = gtk_vbox_new(FALSE, 0);\n\tgtk_container_add(GTK_CONTAINER(top_align), top_vbox);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), top_align, FALSE, FALSE, 0);\n\n\tprobe = gtk_frame_new(\"Run statistics\");\n\tgtk_box_pack_start(GTK_BOX(main_vbox), probe, FALSE, FALSE, 3);\n\tprobe_frame = gtk_vbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(probe), probe_frame);\n\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, FALSE, FALSE, 3);\n\tui->eta.jobs = new_info_entry_in_frame(probe_box, \"Running\");\n\tui->eta.read_bw = new_info_entry_in_frame_rgb(probe_box, \"Read BW\", GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tui->eta.read_iops = new_info_entry_in_frame_rgb(probe_box, \"IOPS\", GFIO_READ_R, GFIO_READ_G, GFIO_READ_B);\n\tui->eta.write_bw = new_info_entry_in_frame_rgb(probe_box, \"Write BW\", GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tui->eta.write_iops = new_info_entry_in_frame_rgb(probe_box, \"IOPS\", GFIO_WRITE_R, GFIO_WRITE_G, GFIO_WRITE_B);\n\tui->eta.trim_bw = new_info_entry_in_frame_rgb(probe_box, \"Trim BW\", GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\tui->eta.trim_iops = new_info_entry_in_frame_rgb(probe_box, \"IOPS\", GFIO_TRIM_R, GFIO_TRIM_G, GFIO_TRIM_B);\n\n\t/*\n\t * Only add this if we have a commit rate\n\t */\n#if 0\n\tprobe_box = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(probe_frame), probe_box, TRUE, FALSE, 3);\n\n\tui->eta.cr_bw = new_info_label_in_frame(probe_box, \"Commit BW\");\n\tui->eta.cr_iops = new_info_label_in_frame(probe_box, \"Commit IOPS\");\n\n\tui->eta.cw_bw = new_info_label_in_frame(probe_box, \"Commit BW\");\n\tui->eta.cw_iops = new_info_label_in_frame(probe_box, \"Commit IOPS\");\n#endif\n\n\t/*\n\t * Set up a drawing area and IOPS and bandwidth graphs\n\t */\n\tui->graphs.drawing_area = gtk_drawing_area_new();\n\tgtk_widget_set_size_request(GTK_WIDGET(ui->graphs.drawing_area),\n\t\tDRAWING_AREA_XDIM, DRAWING_AREA_YDIM);\n\tgtk_widget_modify_bg(ui->graphs.drawing_area, GTK_STATE_NORMAL, &gfio_color_lightyellow);\n\tg_signal_connect(G_OBJECT(ui->graphs.drawing_area), GFIO_DRAW_EVENT,\n\t\t\tG_CALLBACK(on_expose_drawing_area), &ui->graphs);\n\tg_signal_connect(G_OBJECT(ui->graphs.drawing_area), \"configure_event\",\n\t\t\tG_CALLBACK(on_config_drawing_area), &ui->graphs);\n\tscrolled_window = gtk_scrolled_window_new(NULL, NULL);\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scrolled_window),\n\t\t\t\t\tGTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scrolled_window),\n\t\t\t\t\tui->graphs.drawing_area);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), scrolled_window,\n\t\t\tTRUE, TRUE, 0);\n\n\tsetup_graphs(&ui->graphs);\n\n\t/*\n\t * Set up alignments for widgets at the bottom of ui,\n\t * align bottom left, expand horizontally but not vertically\n\t */\n\tbottom_align = gtk_alignment_new(0, 1, 1, 0);\n\tui->buttonbox = gtk_hbox_new(FALSE, 0);\n\tgtk_container_add(GTK_CONTAINER(bottom_align), ui->buttonbox);\n\tgtk_box_pack_start(GTK_BOX(main_vbox), bottom_align, FALSE, FALSE, 0);\n\n\t/*\n\t * Set up thread status progress bar\n\t */\n\tui->thread_status_pb = gtk_progress_bar_new();\n\tgtk_progress_bar_set_fraction(GTK_PROGRESS_BAR(ui->thread_status_pb), 0.0);\n\tgtk_progress_bar_set_text(GTK_PROGRESS_BAR(ui->thread_status_pb), \"No connections\");\n\tgtk_container_add(GTK_CONTAINER(ui->buttonbox), ui->thread_status_pb);\n\n\treturn main_vbox;\n}\n\nstatic gboolean notebook_switch_page(GtkNotebook *notebook, GtkWidget *widget,\n\t\t\t\t     guint page, gpointer data)\n\n{\n\tstruct gui *ui = (struct gui *) data;\n\tstruct gui_entry *ge;\n\n\tif (!page) {\n\t\tset_job_menu_visible(ui, 0);\n\t\tset_view_results_visible(ui, 0);\n\t\treturn TRUE;\n\t}\n\n\tset_job_menu_visible(ui, 1);\n\tge = get_ge_from_page(ui, page, NULL);\n\tif (ge)\n\t\tupdate_button_states(ui, ge);\n\n\treturn TRUE;\n}\n\nstatic gint compare_recent_items(GtkRecentInfo *a, GtkRecentInfo *b)\n{\n\ttime_t time_a = gtk_recent_info_get_visited(a);\n\ttime_t time_b = gtk_recent_info_get_visited(b);\n\n\treturn time_b - time_a;\n}\n\nstatic void add_recent_file_items(struct gui *ui)\n{\n\tconst gchar *gfio = g_get_application_name();\n\tGList *items, *item;\n\tint i = 0;\n\n\tif (ui->recent_ui_id) {\n\t\tgtk_ui_manager_remove_ui(ui->uimanager, ui->recent_ui_id);\n\t\tgtk_ui_manager_ensure_update(ui->uimanager);\n\t}\n\tui->recent_ui_id = gtk_ui_manager_new_merge_id(ui->uimanager);\n\n\tif (ui->actiongroup) {\n\t\tgtk_ui_manager_remove_action_group(ui->uimanager, ui->actiongroup);\n\t\tg_object_unref(ui->actiongroup);\n\t}\n\tui->actiongroup = gtk_action_group_new(\"RecentFileActions\");\n\n\tgtk_ui_manager_insert_action_group(ui->uimanager, ui->actiongroup, -1);\n\n\titems = gtk_recent_manager_get_items(ui->recentmanager);\n\titems = g_list_sort(items, (GCompareFunc) compare_recent_items);\n\n\tfor (item = items; item && item->data; item = g_list_next(item)) {\n\t\tGtkRecentInfo *info = (GtkRecentInfo *) item->data;\n\t\tgchar *action_name;\n\t\tconst gchar *label;\n\t\tGtkAction *action;\n\n\t\tif (!gtk_recent_info_has_application(info, gfio))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We only support local files for now\n\t\t */\n\t\tif (!gtk_recent_info_is_local(info) || !gtk_recent_info_exists(info))\n\t\t\tcontinue;\n\n\t\taction_name = g_strdup_printf(\"RecentFile%u\", i++);\n\t\tlabel = gtk_recent_info_get_display_name(info);\n\n\t\taction = g_object_new(GTK_TYPE_ACTION,\n\t\t\t\t\t\"name\", action_name,\n\t\t\t\t\t\"label\", label, NULL);\n\n\t\tg_object_set_data_full(G_OBJECT(action), \"gtk-recent-info\",\n\t\t\t\t\tgtk_recent_info_ref(info),\n\t\t\t\t\t(GDestroyNotify) gtk_recent_info_unref);\n\n\n\t\tg_signal_connect(action, \"activate\", G_CALLBACK(recent_open), ui);\n\n\t\tgtk_action_group_add_action(ui->actiongroup, action);\n\t\tg_object_unref(action);\n\n\t\tgtk_ui_manager_add_ui(ui->uimanager, ui->recent_ui_id,\n\t\t\t\t\t\"/MainMenu/FileMenu/FileRecentFiles\",\n\t\t\t\t\tlabel, action_name,\n\t\t\t\t\tGTK_UI_MANAGER_MENUITEM, FALSE);\n\n\t\tg_free(action_name);\n\n\t\tif (i == 8)\n\t\t\tbreak;\n\t}\n\n\tg_list_foreach(items, (GFunc) gtk_recent_info_unref, NULL);\n\tg_list_free(items);\n}\n\nstatic void drag_and_drop_received(GtkWidget *widget, GdkDragContext *ctx,\n\t\t\t\t   gint x, gint y, GtkSelectionData *seldata,\n\t\t\t\t   guint info, guint time, gpointer *data)\n{\n\tstruct gui *ui = (struct gui *) data;\n\tgchar **uris;\n\tGtkWidget *source;\n\n\tsource = gtk_drag_get_source_widget(ctx);\n\tif (source && widget == gtk_widget_get_toplevel(source)) {\n\t\tgtk_drag_finish(ctx, FALSE, FALSE, time);\n\t\treturn;\n\t}\n\n\turis = gtk_selection_data_get_uris(seldata);\n\tif (!uris) {\n\t\tgtk_drag_finish(ctx, FALSE, FALSE, time);\n\t\treturn;\n\t}\n\n\tif (uris[0])\n\t\tdo_file_open_with_tab(ui, uris[0]);\n\n\tgtk_drag_finish(ctx, TRUE, FALSE, time);\n\tg_strfreev(uris);\n}\n\nstatic void init_ui(int *argc, char **argv[], struct gui *ui)\n{\n\tGtkSettings *settings;\n\tGtkWidget *vbox;\n\n\t/* Magical g*thread incantation, you just need this thread stuff.\n\t * Without it, the update that happens in gfio_update_thread_status\n\t * doesn't really happen in a timely fashion, you need expose events\n\t */\n#if !GLIB_CHECK_VERSION(2, 31, 0)\n\tif (!g_thread_supported())\n\t\tg_thread_init(NULL);\n#endif\n\n\tgdk_threads_init();\n\n\tgtk_init(argc, argv);\n\tsettings = gtk_settings_get_default();\n\tgtk_settings_set_long_property(settings, \"gtk_tooltip_timeout\", 10, \"gfio setting\");\n#if !GLIB_CHECK_VERSION(2, 36, 0)\n\tg_type_init();\n#endif\n\tgdk_color_parse(\"#fffff4\", &gfio_color_lightyellow);\n\tgdk_color_parse(\"white\", &gfio_color_white);\n\n\tui->window = gtk_window_new(GTK_WINDOW_TOPLEVEL);\n\tgtk_window_set_title(GTK_WINDOW(ui->window), \"fio\");\n\tgtk_window_set_default_size(GTK_WINDOW(ui->window), 1024, 768);\n\n\tg_signal_connect(ui->window, \"delete-event\", G_CALLBACK(quit_clicked), ui);\n\tg_signal_connect(ui->window, \"destroy\", G_CALLBACK(quit_clicked), ui);\n\n\tui->vbox = gtk_vbox_new(FALSE, 0);\n\tgtk_container_add(GTK_CONTAINER(ui->window), ui->vbox);\n\n\tui->uimanager = gtk_ui_manager_new();\n\tui->menu = get_menubar_menu(ui->window, ui->uimanager, ui);\n\tgfio_ui_setup(settings, ui->menu, ui->vbox, ui->uimanager);\n\n\tui->recentmanager = gtk_recent_manager_get_default();\n\tadd_recent_file_items(ui);\n\n\tui->notebook = gtk_notebook_new();\n\tg_signal_connect(ui->notebook, \"switch-page\", G_CALLBACK(notebook_switch_page), ui);\n\tgtk_notebook_set_scrollable(GTK_NOTEBOOK(ui->notebook), 1);\n\tgtk_notebook_popup_enable(GTK_NOTEBOOK(ui->notebook));\n\tgtk_container_add(GTK_CONTAINER(ui->vbox), ui->notebook);\n\n\tvbox = new_main_page(ui);\n\tgtk_drag_dest_set(GTK_WIDGET(ui->window), GTK_DEST_DEFAULT_ALL, NULL, 1, GDK_ACTION_COPY);\n\tgtk_drag_dest_add_uri_targets(GTK_WIDGET(ui->window));\n\tg_signal_connect(ui->window, \"drag-data-received\", G_CALLBACK(drag_and_drop_received), ui);\n\n\tgtk_notebook_append_page(GTK_NOTEBOOK(ui->notebook), vbox, gtk_label_new(\"Main\"));\n\n\tgfio_ui_setup_log(ui);\n\n\tgtk_widget_show_all(ui->window);\n}\n\nint main(int argc, char *argv[], char *envp[])\n{\n\tif (initialize_fio(envp))\n\t\treturn 1;\n\tif (fio_init_options())\n\t\treturn 1;\n\n\tgopt_init();\n\n\tmemset(&main_ui, 0, sizeof(main_ui));\n\tmain_ui.ge_hash = g_hash_table_new(g_int_hash, g_int_equal);\n\n\tinit_ui(&argc, &argv, &main_ui);\n\n\tgdk_threads_enter();\n\tgtk_main();\n\tgdk_threads_leave();\n\n\tg_hash_table_destroy(main_ui.ge_hash);\n\n\tgopt_exit();\n\treturn 0;\n}\n"
        },
        {
          "name": "gfio.h",
          "type": "blob",
          "size": 3.4072265625,
          "content": "#ifndef GFIO_H\n#define GFIO_H\n\n#include <gtk/gtk.h>\n\n#include \"gcompat.h\"\n#include \"stat.h\"\n#include \"thread_options.h\"\n#include \"ghelpers.h\"\n#include \"graph.h\"\n\nstruct probe_widget {\n\tGtkWidget *hostname;\n\tGtkWidget *os;\n\tGtkWidget *arch;\n\tGtkWidget *fio_ver;\n};\n\nstruct eta_widget {\n\tGtkWidget *names;\n\tstruct multitext_widget iotype;\n\tstruct multitext_widget bs;\n\tstruct multitext_widget ioengine;\n\tstruct multitext_widget iodepth;\n\tGtkWidget *jobs;\n\tGtkWidget *files;\n\tGtkWidget *read_bw;\n\tGtkWidget *read_iops;\n\tGtkWidget *cr_bw;\n\tGtkWidget *cr_iops;\n\tGtkWidget *write_bw;\n\tGtkWidget *write_iops;\n\tGtkWidget *cw_bw;\n\tGtkWidget *cw_iops;\n\tGtkWidget *trim_bw;\n\tGtkWidget *trim_iops;\n};\n\nstruct gfio_graphs {\n#define DRAWING_AREA_XDIM 1000\n#define DRAWING_AREA_YDIM 400\n\tGtkWidget *drawing_area;\n\tstruct graph *iops_graph;\n\tgraph_label_t read_iops;\n\tgraph_label_t write_iops;\n\tgraph_label_t trim_iops;\n\tstruct graph *bandwidth_graph;\n\tgraph_label_t read_bw;\n\tgraph_label_t write_bw;\n\tgraph_label_t trim_bw;\n};\n\n/*\n * Main window widgets and data\n */\nstruct gui {\n\tGtkUIManager *uimanager;\n\tGtkRecentManager *recentmanager;\n\tGtkActionGroup *actiongroup;\n\tguint recent_ui_id;\n\tGtkWidget *menu;\n\tGtkWidget *window;\n\tGtkWidget *vbox;\n\tGtkWidget *thread_status_pb;\n\tGtkWidget *buttonbox;\n\tGtkWidget *notebook;\n\tGtkWidget *error_info_bar;\n\tGtkWidget *error_label;\n\tGtkListStore *log_model;\n\tGtkWidget *log_tree;\n\tGtkWidget *log_view;\n\tstruct gfio_graphs graphs;\n\tstruct probe_widget probe;\n\tstruct eta_widget eta;\n\tpthread_t server_t;\n\n\tpthread_t t;\n\tint handler_running;\n\n\tGHashTable *ge_hash;\n};\n\nextern struct gui main_ui;\n\nenum {\n\tGE_STATE_NEW = 1,\n\tGE_STATE_CONNECTED,\n\tGE_STATE_JOB_SENT,\n\tGE_STATE_JOB_STARTED,\n\tGE_STATE_JOB_RUNNING,\n\tGE_STATE_JOB_DONE,\n};\n\nenum {\n\tGFIO_BUTTON_CONNECT = 0,\n\tGFIO_BUTTON_SEND,\n\tGFIO_BUTTON_START,\n\tGFIO_BUTTON_NR,\n};\n\n/*\n * Notebook entry\n */\nstruct gui_entry {\n\tstruct gui *ui;\n\n\tGtkWidget *vbox;\n\tGtkWidget *job_notebook;\n\tGtkWidget *thread_status_pb;\n\tGtkWidget *buttonbox;\n\tGtkWidget *button[GFIO_BUTTON_NR];\n\tGtkWidget *notebook;\n\tGtkWidget *error_info_bar;\n\tGtkWidget *error_label;\n\tGtkWidget *results_window;\n\tGtkWidget *results_notebook;\n\tGtkUIManager *results_uimanager;\n\tGtkWidget *results_menu;\n\tGtkWidget *disk_util_vbox;\n\tGtkListStore *log_model;\n\tGtkWidget *log_tree;\n\tGtkWidget *log_view;\n\tstruct gfio_graphs graphs;\n\tstruct probe_widget probe;\n\tstruct eta_widget eta;\n\tGtkWidget *page_label;\n\tgint page_num;\n\tunsigned int state;\n\n\tstruct graph *clat_graph;\n\tstruct graph *lat_bucket_graph;\n\n\tstruct gfio_client *client;\n\tchar *job_file;\n\tchar *host;\n\tint port;\n\tint type;\n\tint server_start;\n};\n\nstruct end_results {\n\tstruct group_run_stats gs;\n\tstruct thread_stat ts;\n};\n\nstruct gfio_client_options {\n\tstruct flist_head list;\n\tstruct thread_options o;\n};\n\nstruct gfio_client {\n\tstruct gui_entry *ge;\n\tstruct fio_client *client;\n\tGtkWidget *err_entry;\n\tuint32_t client_cpus;\n\tuint64_t client_flags;\n\n\tstruct flist_head o_list;\n\tunsigned int o_list_nr;\n\n\tstruct end_results *results;\n\tunsigned int nr_results;\n\n\tuint32_t update_job_status;\n\tvolatile uint32_t update_job_done;\n\n\tstruct cmd_du_pdu *du;\n\tunsigned int nr_du;\n};\n\n#define GFIO_MIME\t\"text/fio\"\n\nextern void gfio_view_log(struct gui *ui);\nextern void gfio_set_state(struct gui_entry *ge, unsigned int state);\nextern void clear_ge_ui_info(struct gui_entry *ge);\n\nextern const char *gfio_graph_font;\nextern GdkColor gfio_color_white;\nextern GdkColor gfio_color_lightyellow;\n\n#endif\n"
        },
        {
          "name": "ghelpers.c",
          "type": "blob",
          "size": 4.849609375,
          "content": "#include <stdlib.h>\n#include <string.h>\n#include <gtk/gtk.h>\n\n#include \"gcompat.h\"\n#include \"ghelpers.h\"\n\nGtkWidget *new_combo_entry_in_frame(GtkWidget *box, const char *label)\n{\n\tGtkWidget *entry, *frame;\n\n\tframe = gtk_frame_new(label);\n\tentry = gtk_combo_box_text_new();\n\tgtk_box_pack_start(GTK_BOX(box), frame, TRUE, TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), entry);\n\n\treturn entry;\n}\n\nGtkWidget *new_info_entry_in_frame(GtkWidget *box, const char *label)\n{\n\tGtkWidget *entry, *frame;\n\n\tframe = gtk_frame_new(label);\n\tentry = gtk_entry_new();\n\tgtk_editable_set_editable(GTK_EDITABLE(entry), 0);\n\tgtk_box_pack_start(GTK_BOX(box), frame, TRUE, TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), entry);\n\n\treturn entry;\n}\n\nstatic void fill_color_from_rgb(GdkColor *c, gfloat r, gfloat g, gfloat b)\n{\n\tgint R, G, B;\n\tgchar tmp[8];\n\n\tmemset(c, 0, sizeof(*c));\n\tR = r * 255;\n\tG = g * 255;\n\tB = b * 255;\n\tsnprintf(tmp, sizeof(tmp), \"#%02x%02x%02x\", R, G, B);\n\tgdk_color_parse(tmp, c);\n}\n\nGtkWidget *new_info_entry_in_frame_rgb(GtkWidget *box, const char *label,\n\t\t\t\t\tgfloat r, gfloat g, gfloat b)\n{\n\tGtkWidget *entry;\n\tGdkColor c;\n\n\tentry = new_info_entry_in_frame(box, label);\n\tfill_color_from_rgb(&c, r, g, b);\n\tgtk_widget_modify_text(entry, GTK_STATE_NORMAL, &c);\n\treturn entry;\n}\n\nGtkWidget *new_info_label_in_frame(GtkWidget *box, const char *label)\n{\n\tGtkWidget *label_widget;\n\tGtkWidget *frame;\n\n\tframe = gtk_frame_new(label);\n\tlabel_widget = gtk_label_new(NULL);\n\tgtk_box_pack_start(GTK_BOX(box), frame, TRUE, TRUE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), label_widget);\n\n\treturn label_widget;\n}\n\nGtkWidget *create_spinbutton(GtkWidget *hbox, double min, double max, double defval)\n{\n\tGtkWidget *button, *box;\n\n\tbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(hbox), box);\n\n\tbutton = gtk_spin_button_new_with_range(min, max, 1.0);\n\tgtk_box_pack_start(GTK_BOX(box), button, TRUE, TRUE, 0);\n\n\tgtk_spin_button_set_update_policy(GTK_SPIN_BUTTON(button), GTK_UPDATE_IF_VALID);\n\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(button), defval);\n\n\treturn button;\n}\n\nvoid label_set_int_value(GtkWidget *entry, unsigned int val)\n{\n\tchar tmp[80];\n\n\tsprintf(tmp, \"%u\", val);\n\tgtk_label_set_text(GTK_LABEL(entry), tmp);\n}\n\nvoid entry_set_int_value(GtkWidget *entry, unsigned int val)\n{\n\tchar tmp[80];\n\n\tsprintf(tmp, \"%u\", val);\n\tgtk_entry_set_text(GTK_ENTRY(entry), tmp);\n}\n\nGtkTreeViewColumn *tree_view_column(GtkWidget *tree_view, int index, const char *title, unsigned int flags)\n{\n\tGtkCellRenderer *renderer;\n\tGtkTreeViewColumn *col;\n\tdouble xalign = 0.0; /* left as default */\n\tPangoAlignment align;\n\tgboolean visible;\n\n\talign = (flags & ALIGN_LEFT) ? PANGO_ALIGN_LEFT :\n\t\t(flags & ALIGN_RIGHT) ? PANGO_ALIGN_RIGHT :\n\t\tPANGO_ALIGN_CENTER;\n\tvisible = !(flags & INVISIBLE);\n\n\trenderer = gtk_cell_renderer_text_new();\n\tcol = gtk_tree_view_column_new();\n\n\tgtk_tree_view_column_set_title(col, title);\n\tif (!(flags & UNSORTABLE))\n\t\tgtk_tree_view_column_set_sort_column_id(col, index);\n\tgtk_tree_view_column_set_resizable(col, TRUE);\n\tgtk_tree_view_column_pack_start(col, renderer, TRUE);\n\tgtk_tree_view_column_set_expand(col, TRUE);\n\tgtk_tree_view_column_add_attribute(col, renderer, \"text\", index);\n\tg_object_set(G_OBJECT(renderer), \"alignment\", align, NULL);\n\tswitch (align) {\n\tcase PANGO_ALIGN_LEFT:\n\t\txalign = 0.0;\n\t\tbreak;\n\tcase PANGO_ALIGN_CENTER:\n\t\txalign = 0.5;\n\t\tbreak;\n\tcase PANGO_ALIGN_RIGHT:\n\t\txalign = 1.0;\n\t\tbreak;\n\t}\n\tgtk_cell_renderer_set_alignment(GTK_CELL_RENDERER(renderer), xalign, 0.5);\n\tgtk_tree_view_column_set_visible(col, visible);\n\tgtk_tree_view_append_column(GTK_TREE_VIEW(tree_view), col);\n\treturn col;\n}\n\nvoid multitext_add_entry(struct multitext_widget *mt, const char *text)\n{\n\tmt->text = realloc(mt->text, (mt->max_text + 1) * sizeof(char *));\n\tmt->text[mt->max_text] = strdup(text);\n\tmt->max_text++;\n}\n\nvoid multitext_set_entry(struct multitext_widget *mt, unsigned int index)\n{\n\tif (index >= mt->max_text)\n\t\treturn;\n\tif (!mt->text || !mt->text[index])\n\t\treturn;\n\n\tmt->cur_text = index;\n\tgtk_entry_set_text(GTK_ENTRY(mt->entry), mt->text[index]);\n}\n\nvoid multitext_update_entry(struct multitext_widget *mt, unsigned int index,\n\t\t\t    const char *text)\n{\n\tif (!mt->text)\n\t\treturn;\n\n\tif (mt->text[index])\n\t\tfree(mt->text[index]);\n\n\tmt->text[index] = strdup(text);\n\tif (mt->cur_text == index)\n\t\tgtk_entry_set_text(GTK_ENTRY(mt->entry), mt->text[index]);\n}\n\nvoid multitext_free(struct multitext_widget *mt)\n{\n\tint i;\n\n\tgtk_entry_set_text(GTK_ENTRY(mt->entry), \"\");\n\n\tfor (i = 0; i < mt->max_text; i++) {\n\t\tif (mt->text[i])\n\t\t\tfree(mt->text[i]);\n\t}\n\n\tfree(mt->text);\n\tmt->cur_text = -1;\n\tmt->max_text = 0;\n}\n\nGtkWidget *get_scrolled_window(gint border_width)\n{\n\tGtkWidget *scroll;\n\n\tscroll = gtk_scrolled_window_new(NULL, NULL);\n\tgtk_container_set_border_width(GTK_CONTAINER(scroll), border_width);\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scroll), GTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\n\treturn scroll;\n}\n"
        },
        {
          "name": "ghelpers.h",
          "type": "blob",
          "size": 1.2197265625,
          "content": "#ifndef GFIO_HELPERS_H\n#define GFIO_HELPERS_H\n\nGtkWidget *new_combo_entry_in_frame(GtkWidget *box, const char *label);\nGtkWidget *new_info_entry_in_frame(GtkWidget *box, const char *label);\nGtkWidget *new_info_label_in_frame(GtkWidget *box, const char *label);\nGtkWidget *new_info_entry_in_frame_rgb(GtkWidget *box, const char *label,\n\t\t\t\t\tgfloat r, gfloat g, gfloat b);\nGtkWidget *create_spinbutton(GtkWidget *hbox, double min, double max, double defval);\nvoid label_set_int_value(GtkWidget *entry, unsigned int val);\nvoid entry_set_int_value(GtkWidget *entry, unsigned int val);\n\nGtkWidget *get_scrolled_window(gint border_width);\n\nstruct multitext_widget {\n\tGtkWidget *entry;\n\tchar **text;\n\tunsigned int cur_text;\n\tunsigned int max_text;\n};\n\nvoid multitext_add_entry(struct multitext_widget *mt, const char *text);\nvoid multitext_set_entry(struct multitext_widget *mt, unsigned int index);\nvoid multitext_update_entry(struct multitext_widget *mt, unsigned int index,\n\t\t\t    const char *text);\nvoid multitext_free(struct multitext_widget *mt);\n\n#define ALIGN_LEFT 1\n#define ALIGN_RIGHT 2\n#define INVISIBLE 4\n#define UNSORTABLE 8\n\nGtkTreeViewColumn *tree_view_column(GtkWidget *tree_view, int index, const char *title, unsigned int flags);\n\n#endif\n"
        },
        {
          "name": "goptions.c",
          "type": "blob",
          "size": 37.7802734375,
          "content": "#include <locale.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <glib.h>\n#include <cairo.h>\n#include <gtk/gtk.h>\n\n#include \"fio.h\"\n#include \"gfio.h\"\n#include \"ghelpers.h\"\n#include \"gerror.h\"\n#include \"parse.h\"\n#include \"optgroup.h\"\n\nstruct gopt {\n\tGtkWidget *box;\n\tunsigned int opt_index;\n\tunsigned int opt_type;\n\tgulong sig_handler;\n\tstruct gopt_job_view *gjv;\n\tstruct flist_head changed_list;\n};\n\nstruct gopt_combo {\n\tstruct gopt gopt;\n\tGtkWidget *combo;\n};\n\nstruct gopt_int {\n\tstruct gopt gopt;\n\tunsigned long long lastval;\n\tGtkWidget *spin;\n};\n\nstruct gopt_bool {\n\tstruct gopt gopt;\n\tGtkWidget *check;\n};\n\nstruct gopt_str {\n\tstruct gopt gopt;\n\tGtkWidget *entry;\n};\n\nstruct gopt_str_val {\n\tstruct gopt gopt;\n\tGtkWidget *spin;\n\tGtkWidget *combo;\n\tunsigned int maxindex;\n};\n\n#define GOPT_RANGE_SPIN\t4\n\nstruct gopt_range {\n\tstruct gopt gopt;\n\tGtkWidget *spins[GOPT_RANGE_SPIN];\n};\n\nstruct gopt_str_multi {\n\tstruct gopt gopt;\n\tGtkWidget *checks[PARSE_MAX_VP];\n};\n\nenum {\n\tGOPT_COMBO_INT = 1,\n\tGOPT_COMBO_STR,\n\tGOPT_INT,\n\tGOPT_BOOL,\n\tGOPT_STR,\n\tGOPT_STR_VAL,\n\tGOPT_RANGE,\n\tGOPT_STR_MULTI,\n};\n\nstruct gopt_frame_widget {\n\tGtkWidget *vbox[2];\n\tunsigned int nr;\n};\n\nstruct gopt_job_view {\n\tstruct gopt_frame_widget g_widgets[__FIO_OPT_G_NR];\n\tGtkWidget *vboxes[__FIO_OPT_C_NR];\n\tstruct gopt *gopts[FIO_MAX_OPTS];\n\tGtkWidget *dialog;\n\tGtkWidget *job_combo;\n\tstruct gfio_client *client;\n\tstruct flist_head changed_list;\n\tstruct thread_options *o;\n\tint in_job_switch;\n};\n\nstatic GNode *gopt_dep_tree;\n\nstatic GtkWidget *gopt_get_group_frame(struct gopt_job_view *gjv,\n\t\t\t\t       GtkWidget *box, uint64_t groupmask)\n{\n\tuint64_t mask, group;\n\tconst struct opt_group *og;\n\tGtkWidget *frame, *hbox;\n\tstruct gopt_frame_widget *gfw;\n\n\tif (!groupmask)\n\t\treturn 0;\n\n\tmask = groupmask;\n\tog = opt_group_cat_from_mask(&mask);\n\tif (!og)\n\t\treturn NULL;\n\n\tgroup = ffz64(~groupmask);\n\tgfw = &gjv->g_widgets[group];\n\tif (!gfw->vbox[0]) {\n\t\tframe = gtk_frame_new(og->name);\n\t\tgtk_box_pack_start(GTK_BOX(box), frame, FALSE, FALSE, 3);\n\t\thbox = gtk_hbox_new(FALSE, 0);\n\t\tgtk_container_add(GTK_CONTAINER(frame), hbox);\n\t\tgfw->vbox[0] = gtk_vbox_new(TRUE, 5);\n\t\tgfw->vbox[1] = gtk_vbox_new(TRUE, 5);\n\t\tgtk_box_pack_start(GTK_BOX(hbox), gfw->vbox[0], TRUE, TRUE, 5);\n\t\tgtk_box_pack_start(GTK_BOX(hbox), gfw->vbox[1], TRUE, TRUE, 5);\n\t}\n\n\thbox = gtk_hbox_new(FALSE, 3);\n\tgtk_box_pack_start(GTK_BOX(gfw->vbox[gfw->nr++ & 1]), hbox, FALSE, FALSE, 5);\n\treturn hbox;\n}\n\n/*\n * Mark children as invisible, if needed.\n */\nstatic void gopt_set_children_visible(struct gopt_job_view *gjv,\n\t\t\t\t      struct fio_option *parent,\n\t\t\t\t      gboolean visible)\n{\n\tGNode *child, *node;\n\n\tif (parent->hide_on_set)\n\t\tvisible = !visible;\n\n\tnode = g_node_find(gopt_dep_tree, G_IN_ORDER, G_TRAVERSE_ALL, parent);\n\tchild = g_node_first_child(node);\n\twhile (child) {\n\t\tstruct fio_option *o = child->data;\n\t\tstruct gopt *g = o->gui_data;\n\t\tGtkWidget *widget = g->box;\n\n\t\t/*\n\t\t * Recurse into child, if it also has children\n\t\t */\n\t\tif (g_node_n_children(child))\n\t\t\tgopt_set_children_visible(gjv, o, visible);\n\n\t\tgtk_widget_set_sensitive(widget, visible);\n\t\tchild = g_node_next_sibling(child);\n\t}\n}\n\nstatic void gopt_mark_index(struct gopt_job_view *gjv, struct gopt *gopt,\n\t\t\t    unsigned int idx, int type)\n{\n\tINIT_FLIST_HEAD(&gopt->changed_list);\n\n\tassert(!gjv->gopts[idx]);\n\tgopt->opt_index = idx;\n\tgopt->opt_type = type;\n\tgopt->gjv = gjv;\n\tgjv->gopts[idx] = gopt;\n}\n\nstatic void gopt_dialog_update_apply_button(struct gopt_job_view *gjv)\n{\n\tGtkDialog *dialog = GTK_DIALOG(gjv->dialog);\n\tgboolean set;\n\n\tset = !flist_empty(&gjv->changed_list);\n\tgtk_dialog_set_response_sensitive(dialog, GTK_RESPONSE_APPLY, set);\n\n\tif (set) {\n\t\tgtk_widget_set_sensitive(gjv->job_combo, 0);\n\t\tgtk_widget_set_tooltip_text(gjv->job_combo, \"Apply option changes before switching to a new job\");\n\t} else {\n\t\tgtk_widget_set_sensitive(gjv->job_combo, 1);\n\t\tgtk_widget_set_tooltip_text(gjv->job_combo, \"Change current job\");\n\t}\n}\n\nstatic void gopt_changed(struct gopt *gopt)\n{\n\tstruct gopt_job_view *gjv = gopt->gjv;\n\n\tif (gjv->in_job_switch)\n\t\treturn;\n\n\t/*\n\t * Add to changed list. This also prevents the option from being\n\t * freed when the widget is destroyed.\n\t */\n\tif (flist_empty(&gopt->changed_list)) {\n\t\tflist_add_tail(&gopt->changed_list, &gjv->changed_list);\n\t\tgopt_dialog_update_apply_button(gjv);\n\t}\n}\n\nstatic void gopt_str_changed(GtkEntry *entry, gpointer data)\n{\n\tstruct gopt_str *s = (struct gopt_str *) data;\n\tstruct fio_option *o = &fio_options[s->gopt.opt_index];\n\tconst gchar *text;\n\tint set;\n\n\tgopt_changed(&s->gopt);\n\n\ttext = gtk_entry_get_text(GTK_ENTRY(s->entry));\n\tset = strcmp(text, \"\") != 0;\n\n\tgopt_set_children_visible(s->gopt.gjv, o, set);\n}\n\nstatic void gopt_str_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_str *s = (struct gopt_str *) data;\n\n\tfree(s);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_str_store_set_val(struct gopt_str *s, const char *text)\n{\n\tif (text)\n\t\tgtk_entry_set_text(GTK_ENTRY(s->entry), text);\n}\n\nstatic struct gopt *gopt_new_str_store(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o, const char *text,\n\t\t\t\t       unsigned int idx)\n{\n\tstruct gopt_str *s;\n\tGtkWidget *label;\n\n\ts = calloc(1, sizeof(*s));\n\n\ts->gopt.box = gtk_hbox_new(FALSE, 3);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\n\ts->entry = gtk_entry_new();\n\tgopt_mark_index(gjv, &s->gopt, idx, GOPT_STR);\n\tgtk_editable_set_editable(GTK_EDITABLE(s->entry), 1);\n\n\tif (text)\n\t\tgopt_str_store_set_val(s, text);\n\telse if (o->def)\n\t\tgopt_str_store_set_val(s, o->def);\n\n\ts->gopt.sig_handler = g_signal_connect(G_OBJECT(s->entry), \"changed\", G_CALLBACK(gopt_str_changed), s);\n\tg_signal_connect(G_OBJECT(s->entry), \"destroy\", G_CALLBACK(gopt_str_destroy), s);\n\n\tgtk_box_pack_start(GTK_BOX(s->gopt.box), s->entry, FALSE, FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(s->gopt.box), label, FALSE, FALSE, 0);\n\treturn &s->gopt;\n}\n\nstatic void gopt_combo_changed(GtkComboBox *box, gpointer data)\n{\n\tstruct gopt_combo *c = (struct gopt_combo *) data;\n\tstruct fio_option *o = &fio_options[c->gopt.opt_index];\n\tunsigned int index;\n\n\tgopt_changed(&c->gopt);\n\n\tindex = gtk_combo_box_get_active(GTK_COMBO_BOX(c->combo));\n\n\tgopt_set_children_visible(c->gopt.gjv, o, index);\n}\n\nstatic void gopt_combo_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_combo *c = (struct gopt_combo *) data;\n\n\tfree(c);\n\tgtk_widget_destroy(w);\n}\n\nstatic struct gopt_combo *__gopt_new_combo(struct gopt_job_view *gjv,\n\t\t\t\t\t   struct fio_option *o,\n\t\t\t\t\t   unsigned int idx, int type)\n{\n\tstruct gopt_combo *c;\n\tGtkWidget *label;\n\n\tc = calloc(1, sizeof(*c));\n\n\tc->gopt.box = gtk_hbox_new(FALSE, 3);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\n\tc->combo = gtk_combo_box_text_new();\n\tgopt_mark_index(gjv, &c->gopt, idx, type);\n\tg_signal_connect(G_OBJECT(c->combo), \"destroy\", G_CALLBACK(gopt_combo_destroy), c);\n\n\tgtk_box_pack_start(GTK_BOX(c->gopt.box), c->combo, FALSE, FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(c->gopt.box), label, FALSE, FALSE, 0);\n\n\treturn c;\n}\n\nstatic void gopt_combo_str_set_val(struct gopt_combo *c, const char *text)\n{\n\tstruct fio_option *o = &fio_options[c->gopt.opt_index];\n\tstruct value_pair *vp;\n\tint i;\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tif (!strcmp(vp->ival, text)) {\n\t\t\tgtk_combo_box_set_active(GTK_COMBO_BOX(c->combo), i);\n\t\t\tbreak;\n\t\t}\n\t\tvp++;\n\t\ti++;\n\t}\n}\n\nstatic struct gopt *gopt_new_combo_str(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o, const char *text,\n\t\t\t\t       unsigned int idx)\n{\n\tstruct gopt_combo *c;\n\tstruct value_pair *vp;\n\tint i, active = 0;\n\n\tc = __gopt_new_combo(gjv, o, idx, GOPT_COMBO_STR);\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(c->combo), vp->ival);\n\t\tif (o->def && !strcmp(vp->ival, o->def))\n\t\t\tactive = i;\n\t\tvp++;\n\t\ti++;\n\t}\n\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(c->combo), active);\n\tif (text)\n\t\tgopt_combo_str_set_val(c, text);\n\tc->gopt.sig_handler = g_signal_connect(G_OBJECT(c->combo), \"changed\", G_CALLBACK(gopt_combo_changed), c);\n\treturn &c->gopt;\n}\n\nstatic void gopt_combo_int_set_val(struct gopt_combo *c, unsigned int ip)\n{\n\tstruct fio_option *o = &fio_options[c->gopt.opt_index];\n\tstruct value_pair *vp;\n\tint i;\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tif (vp->oval == ip) {\n\t\t\tgtk_combo_box_set_active(GTK_COMBO_BOX(c->combo), i);\n\t\t\tbreak;\n\t\t}\n\t\tvp++;\n\t\ti++;\n\t}\n}\n\nstatic struct gopt *gopt_new_combo_int(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o, unsigned int *ip,\n\t\t\t\t       unsigned int idx)\n{\n\tstruct gopt_combo *c;\n\tstruct value_pair *vp;\n\tint i, active = 0;\n\n\tc = __gopt_new_combo(gjv, o, idx, GOPT_COMBO_INT);\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(c->combo), vp->ival);\n\t\tif (ip && vp->oval == *ip)\n\t\t\tactive = i;\n\t\tvp++;\n\t\ti++;\n\t}\n\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(c->combo), active);\n\tif (ip)\n\t\tgopt_combo_int_set_val(c, *ip);\n\tc->gopt.sig_handler = g_signal_connect(G_OBJECT(c->combo), \"changed\", G_CALLBACK(gopt_combo_changed), c);\n\treturn &c->gopt;\n}\n\nstatic void gopt_str_multi_toggled(GtkToggleButton *button, gpointer data)\n{\n\tstruct gopt_str_multi *m = (struct gopt_str_multi *) data;\n\n\tgopt_changed(&m->gopt);\n}\n\nstatic void gopt_str_multi_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_str_multi *m = (struct gopt_str_multi *) data;\n\n\tfree(m);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_str_multi_set_val(struct gopt_str_multi *m, int val)\n{\n}\n\nstatic struct gopt *gopt_new_str_multi(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o, unsigned int idx)\n{\n\tstruct gopt_str_multi *m;\n\tstruct value_pair *vp;\n\tGtkWidget *frame, *hbox;\n\tint i;\n\n\tm = calloc(1, sizeof(*m));\n\tm->gopt.box = gtk_hbox_new(FALSE, 3);\n\tgopt_mark_index(gjv, &m->gopt, idx, GOPT_STR_MULTI);\n\n\tif (!o->lname)\n\t\tframe = gtk_frame_new(o->name);\n\telse\n\t\tframe = gtk_frame_new(o->lname);\n\tgtk_box_pack_start(GTK_BOX(m->gopt.box), frame, FALSE, FALSE, 3);\n\n\thbox = gtk_hbox_new(FALSE, 3);\n\tgtk_container_add(GTK_CONTAINER(frame), hbox);\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tm->checks[i] = gtk_check_button_new_with_label(vp->ival);\n\t\tgtk_widget_set_tooltip_text(m->checks[i], vp->help);\n\t\tgtk_box_pack_start(GTK_BOX(hbox), m->checks[i], FALSE, FALSE, 3);\n\t\tg_signal_connect(G_OBJECT(m->checks[i]), \"toggled\", G_CALLBACK(gopt_str_multi_toggled), m);\n\t\tvp++;\n\t\ti++;\n\t}\n\n\tgopt_str_multi_set_val(m, 0);\n\tg_signal_connect(G_OBJECT(m->gopt.box), \"destroy\", G_CALLBACK(gopt_str_multi_destroy), m);\n\treturn &m->gopt;\n}\n\nstatic void gopt_int_changed(GtkSpinButton *spin, gpointer data)\n{\n\tstruct gopt_int *i = (struct gopt_int *) data;\n\tstruct fio_option *o = &fio_options[i->gopt.opt_index];\n\tGtkAdjustment *adj;\n\tint value, delta;\n\n\tgopt_changed(&i->gopt);\n\n\tadj = gtk_spin_button_get_adjustment(spin);\n\tvalue = gtk_adjustment_get_value(adj);\n\tdelta = value - i->lastval;\n\ti->lastval = value;\n\n\tif (o->inv_opt) {\n\t\tstruct gopt *b_inv = o->inv_opt->gui_data;\n\t\tstruct gopt_int *i_inv = container_of(b_inv, struct gopt_int, gopt);\n\t\tint cur_val;\n\n\t\tassert(o->type == o->inv_opt->type);\n\n\t\tcur_val = gtk_spin_button_get_value(GTK_SPIN_BUTTON(i_inv->spin));\n\t\tcur_val -= delta;\n\t\tg_signal_handler_block(G_OBJECT(i_inv->spin), i_inv->gopt.sig_handler);\n\t\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(i_inv->spin), cur_val);\n\t\tg_signal_handler_unblock(G_OBJECT(i_inv->spin), i_inv->gopt.sig_handler);\n\t}\n}\n\nstatic void gopt_int_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_int *i = (struct gopt_int *) data;\n\n\tfree(i);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_int_set_val(struct gopt_int *i, unsigned long long p)\n{\n\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(i->spin), p);\n\ti->lastval = p;\n}\n\nstatic struct gopt_int *__gopt_new_int(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o,\n\t\t\t\t       unsigned long long *p, unsigned int idx)\n{\n\tunsigned long long defval;\n\tstruct gopt_int *i;\n\tguint maxval, interval;\n\tGtkWidget *label;\n\n\ti = calloc(1, sizeof(*i));\n\ti->gopt.box = gtk_hbox_new(FALSE, 3);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\n\tmaxval = o->maxval;\n\tif (!maxval)\n\t\tmaxval = UINT_MAX;\n\n\tdefval = 0;\n\tif (p)\n\t\tdefval = *p;\n\telse if (o->def) {\n\t\tlong long val;\n\n\t\tcheck_str_bytes(o->def, &val, o);\n\t\tdefval = val;\n\t}\n\n\tinterval = 1.0;\n\tif (o->interval)\n\t\tinterval = o->interval;\n\n\ti->spin = gtk_spin_button_new_with_range(o->minval, maxval, interval);\n\tgopt_mark_index(gjv, &i->gopt, idx, GOPT_INT);\n\tgtk_spin_button_set_update_policy(GTK_SPIN_BUTTON(i->spin), GTK_UPDATE_IF_VALID);\n\tif (p)\n\t\tgopt_int_set_val(i, *p);\n\telse\n\t\tgopt_int_set_val(i, defval);\n\ti->gopt.sig_handler = g_signal_connect(G_OBJECT(i->spin), \"value-changed\", G_CALLBACK(gopt_int_changed), i);\n\tg_signal_connect(G_OBJECT(i->spin), \"destroy\", G_CALLBACK(gopt_int_destroy), i);\n\n\tgtk_box_pack_start(GTK_BOX(i->gopt.box), i->spin, FALSE, FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(i->gopt.box), label, FALSE, FALSE, 0);\n\n\treturn i;\n}\n\nstatic struct gopt *gopt_new_int(struct gopt_job_view *gjv,\n\t\t\t\t struct fio_option *o, unsigned int *ip,\n\t\t\t\t unsigned int idx)\n{\n\tunsigned long long ullp;\n\tstruct gopt_int *i;\n\n\tif (ip) {\n\t\tullp = *ip;\n\t\ti = __gopt_new_int(gjv, o, &ullp, idx);\n\t} else\n\t\ti = __gopt_new_int(gjv, o, NULL, idx);\n\n\treturn &i->gopt;\n}\n\nstatic struct gopt *gopt_new_ullong(struct gopt_job_view *gjv,\n\t\t\t\t    struct fio_option *o, unsigned long long *p,\n\t\t\t\t    unsigned int idx)\n{\n\tstruct gopt_int *i;\n\n\ti = __gopt_new_int(gjv, o, p, idx);\n\treturn &i->gopt;\n}\n\nstatic void gopt_bool_toggled(GtkToggleButton *button, gpointer data)\n{\n\tstruct gopt_bool *b = (struct gopt_bool *) data;\n\tstruct fio_option *o = &fio_options[b->gopt.opt_index];\n\tgboolean set;\n\n\tgopt_changed(&b->gopt);\n\n\tset = gtk_toggle_button_get_active(GTK_TOGGLE_BUTTON(b->check));\n\n\tif (o->inv_opt) {\n\t\tstruct gopt *g_inv = o->inv_opt->gui_data;\n\t\tstruct gopt_bool *b_inv = container_of(g_inv, struct gopt_bool, gopt);\n\n\t\tassert(o->type == o->inv_opt->type);\n\n\t\tg_signal_handler_block(G_OBJECT(b_inv->check), b_inv->gopt.sig_handler);\n\t\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(b_inv->check), !set);\n\t\tg_signal_handler_unblock(G_OBJECT(b_inv->check), b_inv->gopt.sig_handler);\n\t}\n\n\tgopt_set_children_visible(b->gopt.gjv, o, set);\n}\n\nstatic void gopt_bool_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_bool *b = (struct gopt_bool *) data;\n\n\tfree(b);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_bool_set_val(struct gopt_bool *b, unsigned int val)\n{\n\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(b->check), val);\n}\n\nstatic struct gopt *gopt_new_bool(struct gopt_job_view *gjv,\n\t\t\t\t  struct fio_option *o, unsigned int *val,\n\t\t\t\t  unsigned int idx)\n{\n\tstruct gopt_bool *b;\n\tGtkWidget *label;\n\tint defstate = 0;\n\n\tb = calloc(1, sizeof(*b));\n\tb->gopt.box = gtk_hbox_new(FALSE, 3);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\n\tb->check = gtk_check_button_new();\n\tgopt_mark_index(gjv, &b->gopt, idx, GOPT_BOOL);\n\tif (o->def && !strcmp(o->def, \"1\"))\n\t\tdefstate = 1;\n\n\tif (o->neg)\n\t\tdefstate = !defstate;\n\n\tif (val)\n\t\tgopt_bool_set_val(b, *val);\n\telse\n\t\tgtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(b->check), defstate);\n\tb->gopt.sig_handler = g_signal_connect(G_OBJECT(b->check), \"toggled\", G_CALLBACK(gopt_bool_toggled), b);\n\tg_signal_connect(G_OBJECT(b->check), \"destroy\", G_CALLBACK(gopt_bool_destroy), b);\n\n\tgtk_box_pack_start(GTK_BOX(b->gopt.box), b->check, FALSE, FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(b->gopt.box), label, FALSE, FALSE, 0);\n\treturn &b->gopt;\n}\n\n/*\n * These are paired 0/1 and 2/3. 0/2 are min values, 1/3 are max values.\n * If the max is made smaller than min, adjust min down.\n * If the min is made larger than max, adjust the max.\n */\nstatic void range_value_changed(GtkSpinButton *spin, gpointer data)\n{\n\tstruct gopt_range *r = (struct gopt_range *) data;\n\tint changed = -1, i;\n\tgint val, mval;\n\n\tgopt_changed(&r->gopt);\n\n\tfor (i = 0; i < GOPT_RANGE_SPIN; i++) {\n\t\tif (GTK_SPIN_BUTTON(r->spins[i]) == spin) {\n\t\t\tchanged = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tassert(changed != -1);\n\n\t/*\n\t * Min changed\n\t */\n\tif (changed == 0 || changed == 2) {\n\t\tGtkWidget *mspin = r->spins[changed + 1];\n\n\t\tval = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(r->spins[changed]));\n\t\tmval = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(mspin));\n\t\tif (val > mval)\n\t\t\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(mspin), val);\n\t} else {\n\t\tGtkWidget *mspin = r->spins[changed - 1];\n\n\t\tval = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(r->spins[changed]));\n\t\tmval = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(mspin));\n\t\tif (val < mval)\n\t\t\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(mspin), val);\n\t}\n}\n\nstatic void gopt_range_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_range *r = (struct gopt_range *) data;\n\n\tfree(r);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_int_range_set_val(struct gopt_range *r, unsigned int *vals)\n{\n\tint i;\n\n\tfor (i = 0; i < GOPT_RANGE_SPIN; i++)\n\t\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(r->spins[i]), vals[i]);\n}\n\nstatic struct gopt *gopt_new_int_range(struct gopt_job_view *gjv,\n\t\t\t\t       struct fio_option *o, unsigned int **ip,\n\t\t\t\t       unsigned int idx)\n{\n\tstruct gopt_range *r;\n\tGtkWidget *label;\n\tguint interval;\n\tunsigned int defvals[GOPT_RANGE_SPIN];\n\tgint maxval;\n\tint i;\n\n\tr = calloc(1, sizeof(*r));\n\tr->gopt.box = gtk_hbox_new(FALSE, 3);\n\tgopt_mark_index(gjv, &r->gopt, idx, GOPT_RANGE);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\n\tmaxval = o->maxval;\n\tif (!maxval)\n\t\tmaxval = INT_MAX;\n\n\tmemset(defvals, 0, sizeof(defvals));\n\tif (o->def) {\n\t\tlong long val;\n\n\t\tcheck_str_bytes(o->def, &val, o);\n\t\tfor (i = 0; i < GOPT_RANGE_SPIN; i++)\n\t\t\tdefvals[i] = val;\n\t}\n\n\tinterval = 1.0;\n\tif (o->interval)\n\t\tinterval = o->interval;\n\n\tfor (i = 0; i < GOPT_RANGE_SPIN; i++) {\n\t\tr->spins[i] = gtk_spin_button_new_with_range(o->minval, maxval, interval);\n\t\tgtk_spin_button_set_update_policy(GTK_SPIN_BUTTON(r->spins[i]), GTK_UPDATE_IF_VALID);\n\t\tgtk_box_pack_start(GTK_BOX(r->gopt.box), r->spins[i], FALSE, FALSE, 0);\n\t}\n\n\tif (ip)\n\t\tgopt_int_range_set_val(r, *ip);\n\telse\n\t\tgopt_int_range_set_val(r, defvals);\n\n\tfor (i = 0; i < GOPT_RANGE_SPIN; i++)\n\t\tg_signal_connect(G_OBJECT(r->spins[i]), \"value-changed\", G_CALLBACK(range_value_changed), r);\n\n\tgtk_box_pack_start(GTK_BOX(r->gopt.box), label, FALSE, FALSE, 0);\n\tg_signal_connect(G_OBJECT(r->gopt.box), \"destroy\", G_CALLBACK(gopt_range_destroy), r);\n\treturn &r->gopt;\n}\n\nstatic void gopt_str_val_destroy(GtkWidget *w, gpointer data)\n{\n\tstruct gopt_str_val *g = (struct gopt_str_val *) data;\n\n\tfree(g);\n\tgtk_widget_destroy(w);\n}\n\nstatic void gopt_str_val_spin_wrapped(GtkSpinButton *spin, gpointer data)\n{\n\tstruct gopt_str_val *g = (struct gopt_str_val *) data;\n\tunsigned int val;\n\tGtkAdjustment *adj;\n\tgint index;\n\n\tadj = gtk_spin_button_get_adjustment(spin);\n\tval = gtk_adjustment_get_value(adj);\n\n\t/*\n\t * Can't rely on exact value, as fast changes increment >= 1\n\t */\n\tif (!val) {\n\t\tindex = gtk_combo_box_get_active(GTK_COMBO_BOX(g->combo));\n\t\tif (index + 1 <= g->maxindex) {\n\t\t\tval = 1;\n\t\t\tgtk_combo_box_set_active(GTK_COMBO_BOX(g->combo), ++index);\n\t\t} else\n\t\t\tval = 1023;\n\t\tgtk_spin_button_set_value(spin, val);\n\t} else {\n\t\tindex = gtk_combo_box_get_active(GTK_COMBO_BOX(g->combo));\n\t\tif (index) {\n\t\t\tgtk_combo_box_set_active(GTK_COMBO_BOX(g->combo), --index);\n\t\t\tgtk_spin_button_set_value(spin, 1023);\n\t\t} else\n\t\t\tgtk_spin_button_set_value(spin, 0);\n\t}\n}\n\nstatic void gopt_str_val_changed(GtkSpinButton *spin, gpointer data)\n{\n\tstruct gopt_str_val *g = (struct gopt_str_val *) data;\n\n\tgopt_changed(&g->gopt);\n}\n\nstatic void gopt_str_val_set_val(struct gopt_str_val *g, unsigned long long val)\n{\n\tint i = 0;\n\n\tdo {\n\t\tif (!val || (val % 1024))\n\t\t\tbreak;\n\n\t\ti++;\n\t\tval /= 1024;\n\t} while (1);\n\n\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(g->spin), val);\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(g->combo), i);\n}\n\nstatic struct gopt *gopt_new_str_val(struct gopt_job_view *gjv,\n\t\t\t\t     struct fio_option *o,\n\t\t\t\t     unsigned long long *p, unsigned int idx)\n{\n\tstruct gopt_str_val *g;\n\tconst gchar *postfix[] = { \"B\", \"KiB\", \"MiB\", \"GiB\", \"TiB\", \"PiB\", \"EiB\" };\n\tGtkWidget *label;\n\tint i;\n\n\tg = calloc(1, sizeof(*g));\n\tg->gopt.box = gtk_hbox_new(FALSE, 3);\n\tif (!o->lname)\n\t\tlabel = gtk_label_new(o->name);\n\telse\n\t\tlabel = gtk_label_new(o->lname);\n\tgopt_mark_index(gjv, &g->gopt, idx, GOPT_STR_VAL);\n\n\tg->spin = gtk_spin_button_new_with_range(0.0, 1023.0, 1.0);\n\tgtk_spin_button_set_update_policy(GTK_SPIN_BUTTON(g->spin), GTK_UPDATE_IF_VALID);\n\tgtk_spin_button_set_value(GTK_SPIN_BUTTON(g->spin), 0);\n\tgtk_spin_button_set_wrap(GTK_SPIN_BUTTON(g->spin), 1);\n\tgtk_box_pack_start(GTK_BOX(g->gopt.box), g->spin, FALSE, FALSE, 0);\n\tg_signal_connect(G_OBJECT(g->spin), \"wrapped\", G_CALLBACK(gopt_str_val_spin_wrapped), g);\n\tg_signal_connect(G_OBJECT(g->spin), \"changed\", G_CALLBACK(gopt_str_val_changed), g);\n\n\tg->combo = gtk_combo_box_text_new();\n\ti = 0;\n\twhile (strlen(postfix[i])) {\n\t\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(g->combo), postfix[i]);\n\t\ti++;\n\t}\n\tg->maxindex = i - 1;\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(g->combo), 0);\n\tgtk_box_pack_start(GTK_BOX(g->gopt.box), g->combo, FALSE, FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(g->gopt.box), label, FALSE, FALSE, 3);\n\n\tif (p)\n\t\tgopt_str_val_set_val(g, *p);\n\n\tg_signal_connect(G_OBJECT(g->combo), \"changed\", G_CALLBACK(gopt_str_val_changed), g);\n\n\tg_signal_connect(G_OBJECT(g->gopt.box), \"destroy\", G_CALLBACK(gopt_str_val_destroy), g);\n\treturn &g->gopt;\n}\n\nstatic void gopt_set_option(struct gopt_job_view *gjv, struct fio_option *o,\n\t\t\t    struct gopt *gopt, struct thread_options *to)\n{\n\tswitch (o->type) {\n\tcase FIO_OPT_STR_VAL: {\n\t\tunsigned long long *ullp = NULL;\n\t\tstruct gopt_str_val *g;\n\n\t\tif (o->off1)\n\t\t\tullp = td_var(to, o, o->off1);\n\n\t\tg = container_of(gopt, struct gopt_str_val, gopt);\n\t\tif (ullp)\n\t\t\tgopt_str_val_set_val(g, *ullp);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_VAL_TIME: {\n\t\tunsigned long long *ullp = NULL;\n\t\tstruct gopt_int *i;\n\n\t\tif (o->off1)\n\t\t\tullp = td_var(to, o, o->off1);\n\n\t\ti = container_of(gopt, struct gopt_int, gopt);\n\t\tif (ullp)\n\t\t\tgopt_int_set_val(i, *ullp);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_INT:\n\t\tif (o->posval[0].ival) {\n\t\t\tunsigned int *ip = NULL;\n\t\t\tstruct gopt_combo *c;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\tc = container_of(gopt, struct gopt_combo, gopt);\n\t\t\tif (ip)\n\t\t\t\tgopt_combo_int_set_val(c, *ip);\n\t\t} else {\n\t\t\tunsigned int *ip = NULL;\n\t\t\tstruct gopt_int *i;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\ti = container_of(gopt, struct gopt_int, gopt);\n\t\t\tif (ip)\n\t\t\t\tgopt_int_set_val(i, *ip);\n\t\t}\n\t\tbreak;\n\tcase FIO_OPT_STR_SET:\n\tcase FIO_OPT_BOOL: {\n\t\tunsigned int *ip = NULL;\n\t\tstruct gopt_bool *b;\n\n\t\tif (o->off1)\n\t\t\tip = td_var(to, o, o->off1);\n\n\t\tb = container_of(gopt, struct gopt_bool, gopt);\n\t\tif (ip)\n\t\t\tgopt_bool_set_val(b, *ip);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR: {\n\t\tif (o->posval[0].ival) {\n\t\t\tunsigned int *ip = NULL;\n\t\t\tstruct gopt_combo *c;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\tc = container_of(gopt, struct gopt_combo, gopt);\n\t\t\tif (ip)\n\t\t\t\tgopt_combo_int_set_val(c, *ip);\n\t\t} else {\n\t\t\tstruct gopt_str *s;\n\t\t\tchar *text = NULL;\n\n\t\t\tif (o->off1) {\n\t\t\t\tchar **p = td_var(to, o, o->off1);\n\n\t\t\t\ttext = *p;\n\t\t\t}\n\n\t\t\ts = container_of(gopt, struct gopt_str, gopt);\n\t\t\tgopt_str_store_set_val(s, text);\n\t\t}\n\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_STORE: {\n\t\tstruct gopt_combo *c;\n\t\tchar *text = NULL;\n\n\t\tif (o->off1) {\n\t\t\tchar **p = td_var(to, o, o->off1);\n\t\t\ttext = *p;\n\t\t}\n\n\t\tif (!o->posval[0].ival) {\n\t\t\tstruct gopt_str *s;\n\n\t\t\ts = container_of(gopt, struct gopt_str, gopt);\n\t\t\tgopt_str_store_set_val(s, text);\n\t\t\tbreak;\n\t\t}\n\n\t\tc = container_of(gopt, struct gopt_combo, gopt);\n\t\tif (text)\n\t\t\tgopt_combo_str_set_val(c, text);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_MULTI:\n\t\t/* HANDLE ME */\n\t\tbreak;\n\tcase FIO_OPT_RANGE: {\n\t\tstruct gopt_range *r;\n\t\tunsigned int *ip[4] = { td_var(to, o, o->off1),\n\t\t\t\t\ttd_var(to, o, o->off2),\n\t\t\t\t\ttd_var(to, o, o->off3),\n\t\t\t\t\ttd_var(to, o, o->off4) };\n\n\t\tr = container_of(gopt, struct gopt_range, gopt);\n\t\tgopt_int_range_set_val(r, *ip);\n\t\tbreak;\n\t\t}\n\t/* still need to handle this one */\n\tcase FIO_OPT_FLOAT_LIST:\n\t\tbreak;\n\tcase FIO_OPT_DEPRECATED:\n\t\tbreak;\n\tdefault:\n\t\tprintf(\"ignore type %u\\n\", o->type);\n\t\tbreak;\n\t}\n}\n\nstatic void gopt_add_option(struct gopt_job_view *gjv, GtkWidget *hbox,\n\t\t\t    struct fio_option *o, unsigned int opt_index,\n\t\t\t    struct thread_options *to)\n{\n\tstruct gopt *go = NULL;\n\n\tswitch (o->type) {\n\tcase FIO_OPT_STR_VAL: {\n\t\tunsigned long long *ullp = NULL;\n\n\t\tif (o->off1)\n\t\t\tullp = td_var(to, o, o->off1);\n\n\t\tgo = gopt_new_str_val(gjv, o, ullp, opt_index);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_VAL_TIME: {\n\t\tunsigned long long *ullp = NULL;\n\n\t\tif (o->off1)\n\t\t\tullp = td_var(to, o, o->off1);\n\n\t\tgo = gopt_new_ullong(gjv, o, ullp, opt_index);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_INT:\n\t\tif (o->posval[0].ival) {\n\t\t\tunsigned int *ip = NULL;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\tgo = gopt_new_combo_int(gjv, o, ip, opt_index);\n\t\t} else {\n\t\t\tunsigned int *ip = NULL;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\tgo = gopt_new_int(gjv, o, ip, opt_index);\n\t\t}\n\t\tbreak;\n\tcase FIO_OPT_STR_SET:\n\tcase FIO_OPT_BOOL: {\n\t\tunsigned int *ip = NULL;\n\n\t\tif (o->off1)\n\t\t\tip = td_var(to, o, o->off1);\n\n\t\tgo = gopt_new_bool(gjv, o, ip, opt_index);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR: {\n\t\tif (o->posval[0].ival) {\n\t\t\tunsigned int *ip = NULL;\n\n\t\t\tif (o->off1)\n\t\t\t\tip = td_var(to, o, o->off1);\n\n\t\t\tgo = gopt_new_combo_int(gjv, o, ip, opt_index);\n\t\t} else {\n\t\t\t/* TODO: usually ->cb, or unsigned int pointer */\n\t\t\tgo = gopt_new_str_store(gjv, o, NULL, opt_index);\n\t\t}\n\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_STORE: {\n\t\tchar *text = NULL;\n\n\t\tif (o->off1) {\n\t\t\tchar **p = td_var(to, o, o->off1);\n\t\t\ttext = *p;\n\t\t}\n\n\t\tif (!o->posval[0].ival) {\n\t\t\tgo = gopt_new_str_store(gjv, o, text, opt_index);\n\t\t\tbreak;\n\t\t}\n\n\t\tgo = gopt_new_combo_str(gjv, o, text, opt_index);\n\t\tbreak;\n\t\t}\n\tcase FIO_OPT_STR_MULTI:\n\t\tgo = gopt_new_str_multi(gjv, o, opt_index);\n\t\tbreak;\n\tcase FIO_OPT_RANGE: {\n\t\tunsigned int *ip[4] = { td_var(to, o, o->off1),\n\t\t\t\t\ttd_var(to, o, o->off2),\n\t\t\t\t\ttd_var(to, o, o->off3),\n\t\t\t\t\ttd_var(to, o, o->off4) };\n\n\t\tgo = gopt_new_int_range(gjv, o, ip, opt_index);\n\t\tbreak;\n\t\t}\n\t/* still need to handle this one */\n\tcase FIO_OPT_FLOAT_LIST:\n\t\tbreak;\n\tcase FIO_OPT_DEPRECATED:\n\t\tbreak;\n\tdefault:\n\t\tprintf(\"ignore type %u\\n\", o->type);\n\t\tbreak;\n\t}\n\n\tif (go) {\n\t\tGtkWidget *dest;\n\n\t\tif (o->help)\n\t\t\tgtk_widget_set_tooltip_text(go->box, o->help);\n\n\t\to->gui_data = go;\n\n\t\tdest = gopt_get_group_frame(gjv, hbox, o->group);\n\t\tif (!dest)\n\t\t\tgtk_box_pack_start(GTK_BOX(hbox), go->box, FALSE, FALSE, 5);\n\t\telse\n\t\t\tgtk_box_pack_start(GTK_BOX(dest), go->box, FALSE, FALSE, 5);\n\t}\n}\n\nstatic void gopt_add_options(struct gopt_job_view *gjv,\n\t\t\t     struct thread_options *to)\n{\n\tGtkWidget *hbox = NULL;\n\tint i;\n\n\t/*\n\t * First add all options\n\t */\n\tfor (i = 0; fio_options[i].name; i++) {\n\t\tstruct fio_option *o = &fio_options[i];\n\t\tuint64_t mask = o->category;\n\t\tconst struct opt_group *og;\n\n\t\twhile ((og = opt_group_from_mask(&mask)) != NULL) {\n\t\t\tGtkWidget *vbox = gjv->vboxes[ffz64(~og->mask)];\n\n\t\t\thbox = gtk_hbox_new(FALSE, 3);\n\t\t\tgtk_box_pack_start(GTK_BOX(vbox), hbox, FALSE, FALSE, 5);\n\t\t\tgopt_add_option(gjv, hbox, o, i, to);\n\t\t}\n\t}\n}\n\nstatic void gopt_set_options(struct gopt_job_view *gjv,\n\t\t\t     struct thread_options *to)\n{\n\tint i;\n\n\tfor (i = 0; fio_options[i].name; i++) {\n\t\tstruct fio_option *o = &fio_options[i];\n\t\tstruct gopt *gopt = gjv->gopts[i];\n\n\t\tgopt_set_option(gjv, o, gopt, to);\n\t}\n}\n\nstatic GtkWidget *gopt_add_tab(GtkWidget *notebook, const char *name)\n{\n\tGtkWidget *box, *vbox, *scroll;\n\n\tscroll = gtk_scrolled_window_new(NULL, NULL);\n\tgtk_container_set_border_width(GTK_CONTAINER(scroll), 5);\n\tgtk_scrolled_window_set_policy(GTK_SCROLLED_WINDOW(scroll), GTK_POLICY_AUTOMATIC, GTK_POLICY_AUTOMATIC);\n\n\tvbox = gtk_vbox_new(FALSE, 3);\n\tbox = gtk_hbox_new(FALSE, 0);\n\tgtk_box_pack_start(GTK_BOX(vbox), box, FALSE, FALSE, 5);\n\tgtk_scrolled_window_add_with_viewport(GTK_SCROLLED_WINDOW(scroll), vbox);\n\tgtk_notebook_append_page(GTK_NOTEBOOK(notebook), scroll, gtk_label_new(name));\n\treturn vbox;\n}\n\nstatic GtkWidget *gopt_add_group_tab(GtkWidget *notebook,\n\t\t\t\t     const struct opt_group *og)\n{\n\treturn gopt_add_tab(notebook, og->name);\n}\n\nstatic void gopt_add_group_tabs(GtkWidget *notebook, struct gopt_job_view *gjv)\n{\n\tconst struct opt_group *og;\n\tunsigned int i;\n\n\ti = 0;\n\tdo {\n\t\tuint64_t mask = (1ULL << i);\n\n\t\tog = opt_group_from_mask(&mask);\n\t\tif (!og)\n\t\t\tbreak;\n\t\tgjv->vboxes[i] = gopt_add_group_tab(notebook, og);\n\t\ti++;\n\t} while (1);\n}\n\nstatic void gopt_handle_str_multi_changed(struct gopt_job_view *gjv,\n\t\t\t\t\t  struct gopt_str_multi *m,\n\t\t\t\t\t  struct fio_option *o)\n{\n\tunsigned int *ip = td_var(gjv->o, o, o->off1);\n\tstruct value_pair *vp;\n\tgboolean set;\n\tguint val = 0;\n\tint i;\n\n\ti = 0;\n\tvp = &o->posval[0];\n\twhile (vp->ival) {\n\t\tif (!m->checks[i])\n\t\t\tbreak;\n\t\tset = gtk_toggle_button_get_active(GTK_TOGGLE_BUTTON(m->checks[i]));\n\t\tif (set) {\n\t\t\tif (vp->orval)\n\t\t\t\tval |= vp->oval;\n\t\t\telse\n\t\t\t\tval = vp->oval;\n\t\t}\n\t\ti++;\n\t\tvp++;\n\t}\n\n\tif (o->off1)\n\t\t*ip = val;\n}\n\nstatic void gopt_handle_range_changed(struct gopt_job_view *gjv,\n\t\t\t\t      struct gopt_range *r,\n\t\t\t\t      struct fio_option *o)\n{\n\tunsigned int *ip[4] = { td_var(gjv->o, o, o->off1),\n\t\t\t\ttd_var(gjv->o, o, o->off2),\n\t\t\t\ttd_var(gjv->o, o, o->off3),\n\t\t\t\ttd_var(gjv->o, o, o->off4) };\n\tgint val;\n\tint i;\n\n\tfor (i = 0; i < GOPT_RANGE_SPIN; i++) {\n\t\tval = gtk_spin_button_get_value_as_int(GTK_SPIN_BUTTON(r->spins[i]));\n\t\t*ip[i] = val;\n\t}\n}\n\nstatic void gopt_handle_str_val_changed(struct gopt_job_view *gjv,\n\t\t\t\t\tstruct gopt_str_val *s,\n\t\t\t\t\tstruct fio_option *o)\n{\n\tunsigned long long *ullp = td_var(gjv->o, o, o->off1);\n\tGtkAdjustment *adj;\n\tgint index;\n\n\tif (!ullp)\n\t\treturn;\n\n\t/*\n\t * Numerical value\n\t */\n\tadj = gtk_spin_button_get_adjustment(GTK_SPIN_BUTTON(s->spin));\n\t*ullp = gtk_adjustment_get_value(adj);\n\n\t/*\n\t * Multiplier\n\t */\n\tindex = gtk_combo_box_get_active(GTK_COMBO_BOX(s->combo));\n\twhile (index--)\n\t\t*ullp *= 1024ULL;\n}\n\nstatic void gopt_handle_str_changed(struct gopt_job_view *gjv,\n\t\t\t\t    struct gopt_str *s, struct fio_option *o)\n{\n\tchar **p = td_var(gjv->o, o, o->off1);\n\n\tif (*p)\n\t\tfree(*p);\n\n\t*p = strdup(gtk_entry_get_text(GTK_ENTRY(s->entry)));\n}\n\nstatic void gopt_handle_bool_changed(struct gopt_job_view *gjv,\n\t\t\t\t     struct gopt_bool *b, struct fio_option *o)\n{\n\tunsigned int *ip = td_var(gjv->o, o, o->off1);\n\tgboolean set;\n\n\tset = gtk_toggle_button_get_active(GTK_TOGGLE_BUTTON(b->check));\n\t*ip = set;\n}\n\nstatic void gopt_handle_int_changed(struct gopt_job_view *gjv,\n\t\t\t\t    struct gopt_int *i, struct fio_option *o)\n{\n\tunsigned int *ip = td_var(gjv->o, o, o->off1);\n\tGtkAdjustment *adj;\n\tguint val;\n\n\tadj = gtk_spin_button_get_adjustment(GTK_SPIN_BUTTON(i->spin));\n\tval = gtk_adjustment_get_value(adj);\n\t*ip = val;\n}\n\nstatic void gopt_handle_combo_str_changed(struct gopt_job_view *gjv,\n\t\t\t\t\t  struct gopt_combo *c,\n\t\t\t\t\t  struct fio_option *o)\n{\n\tchar **p = td_var(gjv->o, o, o->off1);\n\n\tif (*p)\n\t\tfree(*p);\n\n\t*p = strdup(gtk_combo_box_text_get_active_text(GTK_COMBO_BOX_TEXT(c->combo)));\n}\n\nstatic void gopt_handle_combo_int_changed(struct gopt_job_view *gjv,\n\t\t\t\t\t  struct gopt_combo *c,\n\t\t\t\t\t  struct fio_option *o)\n{\n\tunsigned int *ip = td_var(gjv->o, o, o->off1);\n\tgint index;\n\n\tindex = gtk_combo_box_get_active(GTK_COMBO_BOX(c->combo));\n\t*ip = o->posval[index].oval;\n}\n\nstatic void gopt_handle_changed(struct gopt *gopt)\n{\n\tstruct fio_option *o = &fio_options[gopt->opt_index];\n\tstruct gopt_job_view *gjv = gopt->gjv;\n\n\tswitch (gopt->opt_type) {\n\tcase GOPT_COMBO_INT: {\n\t\tstruct gopt_combo *c;\n\n\t\tc = container_of(gopt, struct gopt_combo, gopt);\n\t\tgopt_handle_combo_int_changed(gjv, c, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_COMBO_STR: {\n\t\tstruct gopt_combo *c;\n\n\t\tc = container_of(gopt, struct gopt_combo, gopt);\n\t\tgopt_handle_combo_str_changed(gjv, c, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_INT: {\n\t\tstruct gopt_int *i;\n\n\t\ti = container_of(gopt, struct gopt_int, gopt);\n\t\tgopt_handle_int_changed(gjv, i, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_BOOL: {\n\t\tstruct gopt_bool *b;\n\n\t\tb = container_of(gopt, struct gopt_bool, gopt);\n\t\tgopt_handle_bool_changed(gjv, b, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_STR: {\n\t\tstruct gopt_str *s;\n\n\t\ts = container_of(gopt, struct gopt_str, gopt);\n\t\tgopt_handle_str_changed(gjv, s, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_STR_VAL: {\n\t\tstruct gopt_str_val *s;\n\n\t\ts = container_of(gopt, struct gopt_str_val, gopt);\n\t\tgopt_handle_str_val_changed(gjv, s, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_RANGE: {\n\t\tstruct gopt_range *r;\n\n\t\tr = container_of(gopt, struct gopt_range, gopt);\n\t\tgopt_handle_range_changed(gjv, r, o);\n\t\tbreak;\n\t\t}\n\tcase GOPT_STR_MULTI: {\n\t\tstruct gopt_str_multi *m;\n\n\t\tm = container_of(gopt, struct gopt_str_multi, gopt);\n\t\tgopt_handle_str_multi_changed(gjv, m, o);\n\t\tbreak;\n\t\t}\n\tdefault:\n\t\tlog_err(\"gfio: bad option type: %d\\n\", gopt->opt_type);\n\t\tbreak;\n\t}\n}\n\nstatic void gopt_report_update_status(struct gopt_job_view *gjv)\n{\n\tstruct gfio_client *gc = gjv->client;\n\tchar tmp[80];\n\n\tsprintf(tmp, \"\\nCompleted with error: %d\\n\", gc->update_job_status);\n\tgfio_report_info(gc->ge->ui, \"Update job\", tmp);\n}\n\nstatic int gopt_handle_changed_options(struct gopt_job_view *gjv)\n{\n\tstruct gfio_client *gc = gjv->client;\n\tstruct flist_head *entry;\n\tuint64_t waitid = 0;\n\tstruct gopt *gopt;\n\tint ret;\n\n\tflist_for_each(entry, &gjv->changed_list) {\n\t\tgopt = flist_entry(entry, struct gopt, changed_list);\n\t\tgopt_handle_changed(gopt);\n\t}\n\n\tgc->update_job_status = 0;\n\tgc->update_job_done = 0;\n\n\tret = fio_client_update_options(gc->client, gjv->o, &waitid);\n\tif (ret)\n\t\tgoto done;\n\n\tret = fio_client_wait_for_reply(gc->client, waitid);\n\tif (ret)\n\t\tgoto done;\n\n\tassert(gc->update_job_done);\n\tif (gc->update_job_status)\n\t\tgoto done;\n\n\twhile (!flist_empty(&gjv->changed_list)) {\n\t\tgopt = flist_first_entry(&gjv->changed_list, struct gopt, changed_list);\n\t\tflist_del_init(&gopt->changed_list);\n\t}\n\ndone:\n\tgopt_dialog_update_apply_button(gjv);\n\treturn ret;\n}\n\nstatic gint gopt_dialog_cancel(gint response)\n{\n\tswitch (response) {\n\tcase GTK_RESPONSE_NONE:\n\tcase GTK_RESPONSE_REJECT:\n\tcase GTK_RESPONSE_DELETE_EVENT:\n\tcase GTK_RESPONSE_CANCEL:\n\tcase GTK_RESPONSE_NO:\n\t\treturn 1;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic gint gopt_dialog_done(gint response)\n{\n\tswitch (response) {\n\tcase GTK_RESPONSE_ACCEPT:\n\tcase GTK_RESPONSE_OK:\n\tcase GTK_RESPONSE_YES:\n\t\treturn 1;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic void gopt_handle_option_dialog(struct gopt_job_view *gjv)\n{\n\tgint response;\n\n\tdo {\n\t\tresponse = gtk_dialog_run(GTK_DIALOG(gjv->dialog));\n\n\t\tif (gopt_dialog_cancel(response) ||\n\t\t    gopt_dialog_done(response))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Apply\n\t\t */\n\t\tgopt_handle_changed_options(gjv);\n\t\tgopt_report_update_status(gjv);\n\t} while (1);\n\n\tif (gopt_dialog_cancel(response))\n\t\treturn;\n\n\tgopt_handle_changed_options(gjv);\n}\n\nstatic void gopt_job_changed(GtkComboBox *box, gpointer data)\n{\n\tstruct gopt_job_view *gjv = (struct gopt_job_view *) data;\n\tstruct gfio_client_options *gco = NULL;\n\tstruct gfio_client *gc = gjv->client;\n\tstruct flist_head *entry;\n\tgchar *job;\n\n\t/*\n\t * The switch act should be sensitized appropriately, so that we\n\t * never get here with modified options.\n\t */\n\tif (!flist_empty(&gjv->changed_list)) {\n\t\tgfio_report_info(gc->ge->ui, \"Internal Error\", \"Modified options on job switch.\\nThat should not be possible!\\n\");\n\t\treturn;\n\t}\n\n\tjob = gtk_combo_box_text_get_active_text(GTK_COMBO_BOX_TEXT(gjv->job_combo));\n\tflist_for_each(entry, &gc->o_list) {\n\t\tconst char *name;\n\n\t\tgco = flist_entry(entry, struct gfio_client_options, list);\n\t\tname = gco->o.name;\n\t\tif (!name || !strlen(name))\n\t\t\tname = \"Default job\";\n\n\t\tif (!strcmp(name, job))\n\t\t\tbreak;\n\n\t\tgco = NULL;\n\t}\n\n\tif (!gco) {\n\t\tgfio_report_info(gc->ge->ui, \"Internal Error\", \"Could not find job description.\\nThat should not be possible!\\n\");\n\t\treturn;\n\t}\n\n\tgjv->in_job_switch = 1;\n\tgopt_set_options(gjv, &gco->o);\n\tgjv->in_job_switch = 0;\n}\n\nvoid gopt_get_options_window(GtkWidget *window, struct gfio_client *gc)\n{\n\tGtkWidget *dialog, *notebook, *vbox, *topvbox, *combo;\n\tstruct gfio_client_options *gco;\n\tstruct flist_head *entry;\n\tstruct gopt_job_view *gjv;\n\n\tdialog = gtk_dialog_new_with_buttons(\"Fio options\",\n\t\t\tGTK_WINDOW(window), GTK_DIALOG_DESTROY_WITH_PARENT,\n\t\t\tGTK_STOCK_OK, GTK_RESPONSE_ACCEPT,\n\t\t\tGTK_STOCK_APPLY, GTK_RESPONSE_APPLY,\n\t\t\tGTK_STOCK_CANCEL, GTK_RESPONSE_REJECT, NULL);\n\n\tcombo = gtk_combo_box_text_new();\n\tflist_for_each(entry, &gc->o_list) {\n\t\tstruct thread_options *o;\n\t\tconst char *name;\n\n\t\tgco = flist_entry(entry, struct gfio_client_options, list);\n\t\to = &gco->o;\n\t\tname = o->name;\n\t\tif (!name || !strlen(name))\n\t\t\tname = \"Default job\";\n\n\t\tgtk_combo_box_text_append_text(GTK_COMBO_BOX_TEXT(combo), name);\n\t}\n\tgtk_combo_box_set_active(GTK_COMBO_BOX(combo), 0);\n\n\tgtk_widget_set_size_request(GTK_WIDGET(dialog), 1024, 768);\n\n\ttopvbox = gtk_dialog_get_content_area(GTK_DIALOG(dialog));\n\tgtk_box_pack_start(GTK_BOX(topvbox), combo, FALSE, FALSE, 5);\n\n\tvbox = gtk_vbox_new(TRUE, 5);\n\tgtk_box_pack_start(GTK_BOX(topvbox), vbox, TRUE, TRUE, 5);\n\n\tnotebook = gtk_notebook_new();\n\tgtk_notebook_set_scrollable(GTK_NOTEBOOK(notebook), 1);\n\tgtk_notebook_popup_enable(GTK_NOTEBOOK(notebook));\n\tgtk_box_pack_start(GTK_BOX(vbox), notebook, TRUE, TRUE, 5);\n\n\tgjv = calloc(1, sizeof(*gjv));\n\tINIT_FLIST_HEAD(&gjv->changed_list);\n\tgco = flist_first_entry(&gc->o_list, struct gfio_client_options, list);\n\tgjv->o = &gco->o;\n\tgjv->dialog = dialog;\n\tgjv->client = gc;\n\tgjv->job_combo = combo;\n\tgopt_add_group_tabs(notebook, gjv);\n\tgopt_add_options(gjv, &gco->o);\n\tgopt_dialog_update_apply_button(gjv);\n\n\tg_signal_connect(G_OBJECT(combo), \"changed\", G_CALLBACK(gopt_job_changed), gjv);\n\n\tgtk_widget_show_all(dialog);\n\n\tgopt_handle_option_dialog(gjv);\n\n\tgtk_widget_destroy(dialog);\n\tfree(gjv);\n}\n\n/*\n * Build n-ary option dependency tree\n */\nvoid gopt_init(void)\n{\n\tint i;\n\n\tgopt_dep_tree = g_node_new(NULL);\n\n\tfor (i = 0; fio_options[i].name; i++) {\n\t\tstruct fio_option *o = &fio_options[i];\n\t\tGNode *node, *nparent;\n\n\t\t/*\n\t\t * Insert node with either the root parent, or an\n\t\t * option parent.\n\t\t */\n\t\tnode = g_node_new(o);\n\t\tnparent = gopt_dep_tree;\n\t\tif (o->parent) {\n\t\t\tstruct fio_option *parent;\n\n\t\t\tparent = fio_option_find(o->parent);\n\t\t\tnparent = g_node_find(gopt_dep_tree, G_IN_ORDER, G_TRAVERSE_ALL, parent);\n\t\t\tif (!nparent) {\n\t\t\t\tlog_err(\"fio: did not find parent %s for opt %s\\n\", o->name, o->parent);\n\t\t\t\tnparent = gopt_dep_tree;\n\t\t\t}\n\t\t}\n\n\t\tg_node_insert(nparent, -1, node);\n\t}\n}\n\nvoid gopt_exit(void)\n{\n\tg_node_destroy(gopt_dep_tree);\n\tgopt_dep_tree = NULL;\n}\n"
        },
        {
          "name": "goptions.h",
          "type": "blob",
          "size": 0.189453125,
          "content": "#ifndef GFIO_OPTIONS_H\n#define GFIO_OPTIONS_H\n\n#include <gtk/gtk.h>\n\nvoid gopt_get_options_window(GtkWidget *window, struct gfio_client *gc);\nvoid gopt_init(void);\nvoid gopt_exit(void);\n\n#endif\n"
        },
        {
          "name": "graph.c",
          "type": "blob",
          "size": 23.2373046875,
          "content": "/*\n * gfio - gui front end for fio - the flexible io tester\n *\n * Copyright (C) 2012 Stephen M. Cameron <stephenmcameron@gmail.com>\n *\n * The license below covers all files distributed with fio unless otherwise\n * noted in the file itself.\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License version 2 as\n *  published by the Free Software Foundation.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; if not, write to the Free Software\n *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n#include <string.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <stdlib.h>\n\n#include <cairo.h>\n#include <gtk/gtk.h>\n\n#include \"tickmarks.h\"\n#include \"graph.h\"\n#include \"flist.h\"\n#include \"lib/prio_tree.h\"\n#include \"cairo_text_helpers.h\"\n\n/*\n * Allowable difference to show tooltip\n */\n#define TOOLTIP_DELTA\t0.08\n\nstruct xyvalue {\n\tdouble x, y;\n};\n\nenum {\n\tGV_F_ON_PRIO\t= 1,\n\tGV_F_PRIO_SKIP\t= 2,\n};\n\nstruct graph_value {\n\tstruct flist_head list;\n\tstruct prio_tree_node node;\n\tstruct flist_head alias;\n\tunsigned int flags;\n\tchar *tooltip;\n\tvoid *value;\n};\n\nstruct graph_label {\n\tstruct flist_head list;\n\tchar *label;\n\tstruct flist_head value_list;\n\tstruct prio_tree_root prio_tree;\n\tdouble r, g, b;\n\tint hide;\n\tint value_count;\n\tstruct graph *parent;\n};\n\nstruct tick_value {\n\tunsigned int offset;\n\tdouble value;\n};\n\nstruct graph {\n\tchar *title;\n\tchar *xtitle;\n\tchar *ytitle;\n\tunsigned int xdim, ydim;\n\tdouble xoffset, yoffset;\n\tstruct flist_head label_list;\n\tint per_label_limit;\n\tconst char *font;\n\tgraph_axis_unit_change_callback x_axis_unit_change_callback;\n\tgraph_axis_unit_change_callback y_axis_unit_change_callback;\n\tunsigned int base_offset;\n\tunsigned int dont_graph_all_zeroes;\n\tdouble left_extra;\n\tdouble right_extra;\n\tdouble top_extra;\n\tdouble bottom_extra;\n\n\tdouble xtick_zero;\n\tdouble xtick_delta;\n\tdouble xtick_zero_val;\n\tdouble xtick_one_val;\n\tdouble ytick_zero;\n\tdouble ytick_delta;\n\tdouble ytick_zero_val;\n\tdouble ytick_one_val;\n};\n\nvoid graph_set_size(struct graph *g, unsigned int xdim, unsigned int ydim)\n{\n\tg->xdim = xdim;\n\tg->ydim = ydim;\n}\n\nvoid graph_set_position(struct graph *g, double xoffset, double yoffset)\n{\n\tg->xoffset = xoffset;\n\tg->yoffset = yoffset;\n}\n\nstruct graph *graph_new(unsigned int xdim, unsigned int ydim, const char *font)\n{\n\tstruct graph *g;\n\n\tg = calloc(1, sizeof(*g));\n\tINIT_FLIST_HEAD(&g->label_list);\n\tgraph_set_size(g, xdim, ydim);\n\tg->per_label_limit = -1;\n\tg->font = font;\n\tif (!g->font)\n\t\tg->font = GRAPH_DEFAULT_FONT;\n\treturn g;\n}\n\nvoid graph_set_font(struct graph *g, const char *font)\n{\n\tg->font = font;\n}\n\nvoid graph_x_axis_unit_change_notify(struct graph *g, graph_axis_unit_change_callback f)\n{\n\tg->x_axis_unit_change_callback = f;\n}\n\nvoid graph_y_axis_unit_change_notify(struct graph *g, graph_axis_unit_change_callback f)\n{\n\tg->y_axis_unit_change_callback = f;\n}\n\nstatic int count_labels(struct graph *g)\n{\n\tstruct flist_head *entry;\n\tint count = 0;\n\n\tflist_for_each(entry, &g->label_list)\n\t\tcount++;\n\n\treturn count;\n}\n\nstatic int count_values(struct graph_label *l)\n{\n\tstruct flist_head *entry;\n\tint count = 0;\n\n\tflist_for_each(entry, &l->value_list)\n\t\tcount++;\n\n\treturn count;\n}\n\ntypedef double (*double_comparator)(double a, double b);\n\nstatic double mindouble(double a, double b)\n{\n\treturn a < b ? a : b;\n}\n\nstatic double maxdouble(double a, double b)\n{\n\treturn a < b ? b : a;\n}\n\nstatic double find_double_values(struct graph_label *l, double_comparator cmp)\n{\n\tstruct flist_head *entry;\n\tdouble answer = 0.0, tmp;\n\tint first = 1;\n\n\tif (flist_empty(&l->value_list))\n\t\treturn 0.0;\n\n\tflist_for_each(entry, &l->value_list) {\n\t\tstruct graph_value *i;\n\n\t\ti = flist_entry(entry, struct graph_value, list);\n\t\ttmp = *(double *) i->value;\n\t\tif (first) {\n\t\t\tanswer = tmp;\n\t\t\tfirst = 0;\n\t\t} else {\n\t\t\tanswer = cmp(answer, tmp);\n\t\t}\n\t}\n\treturn answer;\n}\n\nstatic double find_double_data(struct graph *g, double_comparator cmp)\n{\n\tstruct flist_head *entry;\n\tstruct graph_label *i;\n\tint first = 1;\n\tdouble answer, tmp;\n\n\tif (flist_empty(&g->label_list))\n\t\treturn 0.0;\n\n\tflist_for_each(entry, &g->label_list) {\n\t\ti = flist_entry(entry, struct graph_label, list);\n\t\ttmp = find_double_values(i, cmp);\n\t\tif (first) {\n\t\t\tanswer = tmp;\n\t\t\tfirst = 0;\n\t\t} else {\n\t\t\tanswer = cmp(tmp, answer);\n\t\t}\n\t}\n\treturn answer;\n}\n\nstatic double find_min_data(struct graph *g)\n{\n\treturn find_double_data(g, mindouble);\n}\n\nstatic double find_max_data(struct graph *g)\n{\n\treturn find_double_data(g, maxdouble);\n}\n\nstatic void draw_bars(struct graph *bg, cairo_t *cr, struct graph_label *lb,\n\t\t\tdouble label_offset, double bar_width,\n\t\t\tdouble mindata, double maxdata)\n{\n\tstruct flist_head *entry;\n\tdouble x1, y1, x2, y2;\n\tint bar_num = 0;\n\tdouble domain, range, v;\n\n\tdomain = (maxdata - mindata);\n\trange = (double) bg->ydim * 0.80; /* FIXME */\n\tcairo_stroke(cr);\n\tflist_for_each(entry, &lb->value_list) {\n\t\tstruct graph_value *i;\n\n\t\ti = flist_entry(entry, struct graph_value, list);\n\n\t\tx1 = label_offset + (double) bar_num * bar_width + (bar_width * 0.05);\n\t\tx2 = x1 + bar_width * 0.90;\n\t\ty2 = bg->ydim * 0.90;\n\t\tv = *(double *) i->value;\n\t\ty1 = y2 - (((v - mindata) / domain) * range);\n\t\tcairo_move_to(cr, x1, y1);\n\t\tcairo_line_to(cr, x1, y2);\n\t\tcairo_line_to(cr, x2, y2);\n\t\tcairo_line_to(cr, x2, y1);\n\t\tcairo_close_path(cr);\n\t\tcairo_fill(cr);\n\t\tcairo_stroke(cr);\n\t\tbar_num++;\n\t}\n}\n\nstatic void graph_draw_common(struct graph *g, cairo_t *cr, double *x1,\n\t\t\t      double *y1, double *x2, double *y2)\n{\n\tconst double shade_col[3][3] = { { 0.55, 0.54, 0.54 },\n\t\t\t\t\t { 0.80, 0.78, 0.78 },\n\t\t\t\t\t { 0.93, 0.91, 0.91 } };\n\tint i;\n\n\t*x1 = 0.10 * g->xdim;\n\t*x2 = 0.95 * g->xdim;\n\t*y1 = 0.10 * g->ydim;\n\t*y2 = 0.90 * g->ydim;\n\n\t/*\n\t * Add shade\n\t */\n\tcairo_set_line_width(cr, 1.0);\n\tfor (i = 0; i < 3; i++) {\n\t\tfloat offset = i + 1.0;\n\n\t\tcairo_set_source_rgb(cr, shade_col[i][0], shade_col[i][1], shade_col[i][2]);\n\t\tcairo_move_to(cr, offset + *x1, *y1 - offset);\n\t\tcairo_line_to(cr, *x2 + offset, *y1 - offset);\n\t\tcairo_line_to(cr, *x2 + offset, *y2 - offset);\n\t\tcairo_stroke(cr);\n\t}\n\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tcairo_set_line_width(cr, 1.2);\n\n\tcairo_move_to(cr, *x1, *y1);\n\tcairo_line_to(cr, *x1, *y2);\n\tcairo_line_to(cr, *x2, *y2);\n\tcairo_line_to(cr, *x2, *y1);\n\tcairo_line_to(cr, *x1, *y1);\n\tcairo_stroke(cr);\n\n\tdraw_centered_text(cr, g->font, g->xdim / 2, g->ydim / 20, 20.0, g->title);\n\tdraw_centered_text(cr, g->font, g->xdim / 2, g->ydim * 0.97, 14.0, g->xtitle);\n\tdraw_vertical_centered_text(cr, g->font, g->xdim * 0.02, g->ydim / 2, 14.0, g->ytitle);\n\tcairo_stroke(cr);\n}\n\nstatic void graph_draw_x_ticks(struct graph *g, cairo_t *cr,\n\tdouble x1, double y1, double x2, double y2,\n\tdouble minx, double maxx, int nticks, int add_tm_text)\n{\n\tstruct tickmark *tm;\n\tdouble tx;\n\tint i, power_of_ten;\n\tstatic double dash[] = { 1.0, 2.0 };\n\n\tnticks = calc_tickmarks(minx, maxx, nticks, &tm, &power_of_ten,\n\t\tg->x_axis_unit_change_callback == NULL, g->base_offset);\n\tif (g->x_axis_unit_change_callback)\n\t\tg->x_axis_unit_change_callback(g, power_of_ten);\n\n\tfor (i = 0; i < nticks; i++) {\n\t\ttx = (((tm[i].value) - minx) / (maxx - minx)) * (x2 - x1) + x1;\n\n\t\t/*\n\t\t * Update tick delta\n\t\t */\n\t\tif (!i) {\n\t\t\tg->xtick_zero = tx;\n\t\t\tg->xtick_zero_val = tm[0].value;\n\t\t} else if (i == 1) {\n\t\t\tg->xtick_delta = (tm[1].value - tm[0].value) / (tx - g->xtick_zero);\n\t\t\tg->xtick_one_val = tm[1].value;\n\t\t}\n\n\t\t/* really tx < yx || tx > x2, but protect against rounding */\n\t\tif (x1 - tx > 0.01 || tx - x2 > 0.01)\n\t\t\tcontinue;\n\n\t\t/* Draw tick mark */\n\t\tcairo_set_line_width(cr, 1.0);\n\t\tcairo_move_to(cr, tx, y2);\n\t\tcairo_line_to(cr, tx, y2 + (y2 - y1) * 0.03);\n\t\tcairo_stroke(cr);\n\n\t\t/* draw grid lines */\n\t\tcairo_save(cr);\n\t\tcairo_set_dash(cr, dash, 2, 0.66);\n\t\tcairo_set_line_width(cr, 0.33);\n\t\tcairo_move_to(cr, tx, y1);\n\t\tcairo_line_to(cr, tx, y2);\n\t\tcairo_stroke(cr);\n\t\tcairo_restore(cr);\n\n\t\tif (!add_tm_text)\n\t\t\tcontinue;\n\n\t\t/* draw tickmark label */\n\t\tdraw_centered_text(cr, g->font, tx, y2 * 1.04, 12.0, tm[i].string);\n\t\tcairo_stroke(cr);\n\t}\n}\n\nstatic double graph_draw_y_ticks(struct graph *g, cairo_t *cr,\n\tdouble x1, double y1, double x2, double y2,\n\tdouble miny, double maxy, int nticks, int add_tm_text)\n{\n\tstruct tickmark *tm;\n\tdouble ty;\n\tint i, power_of_ten;\n\tstatic double dash[] = { 1.0, 2.0 };\n\n\tnticks = calc_tickmarks(miny, maxy, nticks, &tm, &power_of_ten,\n\t\tg->y_axis_unit_change_callback == NULL, g->base_offset);\n\tif (g->y_axis_unit_change_callback)\n\t\tg->y_axis_unit_change_callback(g, power_of_ten);\n\n\t/*\n\t * Use highest tickmark as top of graph, not highest value. Otherwise\n\t * it's impossible to see what the max value is, if the graph is\n\t * fairly flat.\n\t */\n\tmaxy = tm[nticks - 1].value;\n\n\tfor (i = 0; i < nticks; i++) {\n\t\tty = y2 - (((tm[i].value) - miny) / (maxy - miny)) * (y2 - y1);\n\n\t\t/*\n\t\t * Update tick delta\n\t\t */\n\t\tif (!i) {\n\t\t\tg->ytick_zero = ty;\n\t\t\tg->ytick_zero_val = tm[0].value;\n\t\t} else if (i == 1) {\n\t\t\tg->ytick_delta = (tm[1].value - tm[0].value) / (ty - g->ytick_zero);\n\t\t\tg->ytick_one_val = tm[1].value;\n\t\t}\n\n\t\t/* really ty < y1 || ty > y2, but protect against rounding */\n\t\tif (y1 - ty > 0.01 || ty - y2 > 0.01)\n\t\t\tcontinue;\n\n\t\t/* draw tick mark */\n\t\tcairo_move_to(cr, x1, ty);\n\t\tcairo_line_to(cr, x1 - (x2 - x1) * 0.02, ty);\n\t\tcairo_stroke(cr);\n\n\t\t/* draw grid lines */\n\t\tcairo_save(cr);\n\t\tcairo_set_dash(cr, dash, 2, 0.66);\n\t\tcairo_set_line_width(cr, 0.33);\n\t\tcairo_move_to(cr, x1, ty);\n\t\tcairo_line_to(cr, x2, ty);\n\t\tcairo_stroke(cr);\n\t\tcairo_restore(cr);\n\n\t\tif (!add_tm_text)\n\t\t\tcontinue;\n\n\t\t/* draw tickmark label */\n\t\tdraw_right_justified_text(cr, g->font, x1 - (x2 - x1) * 0.025, ty, 12.0, tm[i].string);\n\t\tcairo_stroke(cr);\n\t}\n\n\t/*\n\t * Return new max to use\n\t */\n\treturn maxy;\n}\n\nvoid bar_graph_draw(struct graph *bg, cairo_t *cr)\n{\n\tdouble x1, y1, x2, y2;\n\tdouble space_per_label, bar_width;\n\tdouble label_offset, mindata, maxdata;\n\tint i, nlabels;\n\tstruct graph_label *lb;\n\tstruct flist_head *entry;\n\n\tcairo_save(cr);\n\tcairo_translate(cr, bg->xoffset, bg->yoffset);\n\tgraph_draw_common(bg, cr, &x1, &y1, &x2, &y2);\n\n\tnlabels = count_labels(bg);\n\tspace_per_label = (x2 - x1) / (double) nlabels;\n\n\t/*\n\t * Start bars at 0 unless we have negative values, otherwise we\n\t * present a skewed picture comparing label X and X+1.\n\t */\n\tmindata = find_min_data(bg);\n\tif (mindata > 0)\n\t\tmindata = 0;\n\n\tmaxdata = find_max_data(bg);\n\n\tif (fabs(maxdata - mindata) < 1e-20) {\n\t\tdraw_centered_text(cr, bg->font,\n\t\t\tx1 + (x2 - x1) / 2.0,\n\t\t\ty1 + (y2 - y1) / 2.0, 20.0, \"No good data\");\n\t\treturn;\n\t}\n\n\tmaxdata = graph_draw_y_ticks(bg, cr, x1, y1, x2, y2, mindata, maxdata, 10, 1);\n\ti = 0;\n\tflist_for_each(entry, &bg->label_list) {\n\t\tint nvalues;\n\n\t\tlb = flist_entry(entry, struct graph_label, list);\n\t\tnvalues = count_values(lb);\n\t\tbar_width = (space_per_label - space_per_label * 0.2) / (double) nvalues;\n\t\tlabel_offset = bg->xdim * 0.1 + space_per_label * (double) i + space_per_label * 0.1;\n\t\tdraw_bars(bg, cr, lb, label_offset, bar_width, mindata, maxdata);\n\t\t// draw_centered_text(cr, label_offset + (bar_width / 2.0 + bar_width * 0.1), bg->ydim * 0.93,\n\t\tdraw_centered_text(cr, bg->font, x1 + space_per_label * (i + 0.5), bg->ydim * 0.93,\n\t\t\t12.0, lb->label);\n\t\ti++;\n\t}\n\tcairo_stroke(cr);\n\tcairo_restore(cr);\n}\n\ntypedef double (*xy_value_extractor)(struct graph_value *v);\n\nstatic double getx(struct graph_value *v)\n{\n\tstruct xyvalue *xy = v->value;\n\treturn xy->x;\n}\n\nstatic double gety(struct graph_value *v)\n{\n\tstruct xyvalue *xy = v->value;\n\treturn xy->y;\n}\n\nstatic double find_xy_value(struct graph *g, xy_value_extractor getvalue, double_comparator cmp)\n{\n\tdouble tmp, answer = 0.0;\n\tstruct graph_label *i;\n\tstruct graph_value *j;\n\tstruct flist_head *jentry, *entry;\n\tint first = 1;\n\n\tflist_for_each(entry, &g->label_list) {\n\t\ti = flist_entry(entry, struct graph_label, list);\n\n\t\tflist_for_each(jentry, &i->value_list) {\n\t\t\tj = flist_entry(jentry, struct graph_value, list);\n\t\t\ttmp = getvalue(j);\n\t\t\tif (first) {\n\t\t\t\tfirst = 0;\n\t\t\t\tanswer = tmp;\n\t\t\t}\n\t\t\tanswer = cmp(tmp, answer);\n\t\t}\n\t}\n\n\treturn answer;\n}\n\nvoid line_graph_draw(struct graph *g, cairo_t *cr)\n{\n\tdouble x1, y1, x2, y2;\n\tdouble minx, miny, maxx, maxy, gminx, gminy, gmaxx, gmaxy;\n\tdouble tx, ty, top_extra, bottom_extra, left_extra, right_extra;\n\tstruct graph_label *i;\n\tstruct graph_value *j;\n\tint good_data = 1, first = 1;\n\tstruct flist_head *entry, *lentry;\n\n\tcairo_save(cr);\n\tcairo_translate(cr, g->xoffset, g->yoffset);\n\tgraph_draw_common(g, cr, &x1, &y1, &x2, &y2);\n\n\tminx = find_xy_value(g, getx, mindouble);\n\tmaxx = find_xy_value(g, getx, maxdouble);\n\tminy = find_xy_value(g, gety, mindouble);\n\n\t/*\n\t * Start graphs at zero, unless we have a value below. Otherwise\n\t * it's hard to visually compare the read and write graph, since\n\t * the lowest valued one will be the floor of the graph view.\n\t */\n\tif (miny > 0)\n\t\tminy = 0;\n\n\tmaxy = find_xy_value(g, gety, maxdouble);\n\n\tif (fabs(maxx - minx) < 1e-20 || fabs(maxy - miny) < 1e-20) {\n\t\tgood_data = 0;\n\t\tminx = 0.0;\n\t\tminy = 0.0;\n\t\tmaxx = 10.0;\n\t\tmaxy = 100.0;\n\t}\n\n\ttop_extra = 0.0;\n\tbottom_extra = 0.0;\n\tleft_extra = 0.0;\n\tright_extra = 0.0;\n\n\tif (g->top_extra > 0.001)\n\t\ttop_extra = fabs(maxy - miny) * g->top_extra;\n\tif (g->bottom_extra > 0.001)\n\t\tbottom_extra = fabs(maxy - miny) * g->bottom_extra;\n\tif (g->left_extra > 0.001)\n\t\tleft_extra = fabs(maxx - minx) * g->left_extra;\n\tif (g->right_extra > 0.001)\n\t\tright_extra = fabs(maxx - minx) * g->right_extra;\n\n\tgminx = minx - left_extra;\n\tgmaxx = maxx + right_extra;\n\tgminy = miny - bottom_extra;\n\tgmaxy = maxy + top_extra;\n\n\tgraph_draw_x_ticks(g, cr, x1, y1, x2, y2, gminx, gmaxx, 10, good_data);\n\tgmaxy = graph_draw_y_ticks(g, cr, x1, y1, x2, y2, gminy, gmaxy, 10, good_data);\n\n\tif (!good_data)\n\t\tgoto skip_data;\n\n\tcairo_set_line_width(cr, 1.5);\n\tcairo_set_line_join(cr, CAIRO_LINE_JOIN_ROUND);\n\n\tflist_for_each(lentry, &g->label_list) {\n\t\ti = flist_entry(lentry, struct graph_label, list);\n\t\tfirst = 1;\n\t\tif (i->hide || i->r < 0) /* invisible data */\n\t\t\tcontinue;\n\n\t\tcairo_set_source_rgb(cr, i->r, i->g, i->b);\n\t\tflist_for_each(entry, &i->value_list) {\n\t\t\tj = flist_entry(entry, struct graph_value, list);\n\t\t\ttx = ((getx(j) - gminx) / (gmaxx - gminx)) * (x2 - x1) + x1;\n\t\t\tty = y2 - ((gety(j) - gminy) / (gmaxy - gminy)) * (y2 - y1);\n\t\t\tif (first) {\n\t\t\t\tcairo_move_to(cr, tx, ty);\n\t\t\t\tfirst = 0;\n\t\t\t} else\n\t\t\t\tcairo_line_to(cr, tx, ty);\n\t\t}\n\t\tcairo_stroke(cr);\n\t}\n\nskip_data:\n\tcairo_restore(cr);\n}\n\nstatic void setstring(char **str, const char *value)\n{\n\tfree(*str);\n\t*str = strdup(value);\n}\n\nvoid graph_title(struct graph *bg, const char *title)\n{\n\tsetstring(&bg->title, title);\n}\n\nvoid graph_x_title(struct graph *bg, const char *title)\n{\n\tsetstring(&bg->xtitle, title);\n}\n\nvoid graph_y_title(struct graph *bg, const char *title)\n{\n\tsetstring(&bg->ytitle, title);\n}\n\nstatic struct graph_label *graph_find_label(struct graph *bg,\n\t\t\t\tconst char *label)\n{\n\tstruct flist_head *entry;\n\tstruct graph_label *i;\n\n\tflist_for_each(entry, &bg->label_list) {\n\t\ti = flist_entry(entry, struct graph_label, list);\n\n\t\tif (strcmp(label, i->label) == 0)\n\t\t\treturn i;\n\t}\n\n\treturn NULL;\n}\n\ngraph_label_t graph_add_label(struct graph *bg, const char *label)\n{\n\tstruct graph_label *i;\n\n\ti = graph_find_label(bg, label);\n\tif (i)\n\t\treturn i; /* already present. */\n\ti = calloc(1, sizeof(*i));\n\tINIT_FLIST_HEAD(&i->value_list);\n\ti->parent = bg;\n\tsetstring(&i->label, label);\n\tflist_add_tail(&i->list, &bg->label_list);\n\tINIT_PRIO_TREE_ROOT(&i->prio_tree);\n\treturn i;\n}\n\nstatic void __graph_value_drop(struct graph_label *l, struct graph_value *v)\n{\n\tflist_del_init(&v->list);\n\tif (v->tooltip)\n\t\tfree(v->tooltip);\n\tfree(v->value);\n\tfree(v);\n\tl->value_count--;\n}\n\nstatic void graph_value_drop(struct graph_label *l, struct graph_value *v)\n{\n\tif (v->flags & GV_F_PRIO_SKIP) {\n\t\t__graph_value_drop(l, v);\n\t\treturn;\n\t}\n\n\t/*\n\t * Find head, the guy that's on the prio tree\n\t */\n\twhile (!(v->flags & GV_F_ON_PRIO)) {\n\t\tassert(!flist_empty(&v->alias));\n\t\tv = flist_first_entry(&v->alias, struct graph_value, alias);\n\t}\n\n\tprio_tree_remove(&l->prio_tree, &v->node);\n\n\t/*\n\t * Free aliases\n\t */\n\twhile (!flist_empty(&v->alias)) {\n\t\tstruct graph_value *a;\n\n\t\ta = flist_first_entry(&v->alias, struct graph_value, alias);\n\t\tflist_del_init(&a->alias);\n\n\t\t__graph_value_drop(l, a);\n\t}\n\n\t__graph_value_drop(l, v);\n}\n\nstatic void graph_label_add_value(struct graph_label *i, void *value,\n\t\t\t\t  const char *tooltip)\n{\n\tstruct graph *g = i->parent;\n\tstruct graph_value *x;\n\n\tx = calloc(1, sizeof(*x));\n\tINIT_FLIST_HEAD(&x->alias);\n\tINIT_FLIST_HEAD(&x->list);\n\tflist_add_tail(&x->list, &i->value_list);\n\ti->value_count++;\n\tx->value = value;\n\n\tif (tooltip) {\n\t\tdouble xval = getx(x);\n\t\tdouble minx = xval - (g->xtick_one_val * TOOLTIP_DELTA);\n\t\tdouble maxx = xval + (g->xtick_one_val * TOOLTIP_DELTA);\n\t\tstruct prio_tree_node *ret;\n\n\t\t/*\n\t\t * use msec to avoid dropping too much precision when\n\t\t * storing as an integer.\n\t\t */\n\t\tminx = minx * 1000.0;\n\t\tmaxx = maxx * 1000.0;\n\n\t\tINIT_PRIO_TREE_NODE(&x->node);\n\t\tx->node.start = minx;\n\t\tx->node.last = maxx;\n\t\tx->tooltip = strdup(tooltip);\n\t\tif (x->node.last == x->node.start) {\n\t\t\tx->node.last += fabs(g->xtick_delta);\n\t\t\tif (x->node.last == x->node.start)\n\t\t\t\tx->node.last++;\n\t\t}\n\n\t\t/*\n\t\t * If ret != &x->node, we have an alias. Since the values\n\t\t * should be identical, we can drop it\n\t\t */\n\t\tret = prio_tree_insert(&i->prio_tree, &x->node);\n\t\tif (ret != &x->node) {\n\t\t\tstruct graph_value *alias;\n\n\t\t\talias = container_of(ret, struct graph_value, node);\n\t\t\tflist_add_tail(&x->alias, &alias->alias);\n\t\t} else\n\t\t\tx->flags = GV_F_ON_PRIO;\n\t} else\n\t\tx->flags = GV_F_PRIO_SKIP;\n\n\tif (g->per_label_limit != -1 &&\n\t\ti->value_count > g->per_label_limit) {\n\t\tint to_drop = 1;\n\n\t\t/*\n\t\t * If the limit was dynamically reduced, making us more\n\t\t * than 1 entry ahead after adding this one, drop two\n\t\t * entries. This will make us (eventually) reach the\n\t\t * specified limit.\n\t\t */\n\t\tif (i->value_count - g->per_label_limit >= 2)\n\t\t\tto_drop = 2;\n\n\t\twhile (to_drop-- && !flist_empty(&i->value_list)) {\n\t\t\tx = flist_first_entry(&i->value_list, struct graph_value, list);\n\t\t\tgraph_value_drop(i, x);\n\n\t\t\t/*\n\t\t\t * If we have aliases, we could drop > 1 above.\n\t\t\t */\n\t\t\tif (i->value_count <= g->per_label_limit)\n\t\t\t\tbreak;\n\t\t}\n\t}\n}\n\nint graph_add_data(struct graph *bg, graph_label_t label, const double value)\n{\n\tstruct graph_label *i = label;\n\tdouble *d;\n\n\td = malloc(sizeof(*d));\n\t*d = value;\n\n\tgraph_label_add_value(i, d, NULL);\n\treturn 0;\n}\n\nstatic int graph_nonzero_y(struct graph_label *l)\n{\n\tstruct flist_head *entry;\n\n\tflist_for_each(entry, &l->value_list) {\n\t\tstruct graph_value *v;\n\n\t\tv = flist_entry(entry, struct graph_value, list);\n\t\tif (gety(v) != 0.0)\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nint graph_add_xy_data(struct graph *bg, graph_label_t label,\n\t\t      const double x, const double y, const char *tooltip)\n{\n\tstruct graph_label *i = label;\n\tstruct xyvalue *xy;\n\n\tif (bg->dont_graph_all_zeroes && y == 0.0 && !graph_nonzero_y(i))\n\t\ti->hide = 1;\n\telse\n\t\ti->hide = 0;\n\n\txy = malloc(sizeof(*xy));\n\txy->x = x;\n\txy->y = y;\n\n\tgraph_label_add_value(i, xy, tooltip);\n\treturn 0;\n}\n\nstatic void graph_free_values(struct graph_label *l)\n{\n\tstruct graph_value *i;\n\n\twhile (!flist_empty(&l->value_list)) {\n\t\ti = flist_first_entry(&l->value_list, struct graph_value, list);\n\t\tgraph_value_drop(l, i);\n\t}\n}\n\nstatic void graph_free_labels(struct graph *g)\n{\n\tstruct graph_label *i;\n\n\twhile (!flist_empty(&g->label_list)) {\n\t\ti = flist_first_entry(&g->label_list, struct graph_label, list);\n\t\tflist_del(&i->list);\n\t\tgraph_free_values(i);\n\t\tfree(i);\n\t}\n}\n\nvoid graph_clear_values(struct graph *g)\n{\n\tstruct flist_head *node;\n\tstruct graph_label *i;\n\n\tflist_for_each(node, &g->label_list) {\n\t\ti = flist_entry(node, struct graph_label, list);\n\t\tgraph_free_values(i);\n\t}\n}\n\nvoid graph_set_color(struct graph *gr, graph_label_t label, double red,\n\t\t     double green, double blue)\n{\n\tstruct graph_label *i = label;\n\tdouble r, g, b;\n\n\tif (red < 0.0) { /* invisible color */\n\t\tr = -1.0;\n\t\tg = -1.0;\n\t\tb = -1.0;\n\t} else {\n\t\tr = fabs(red);\n\t\tg = fabs(green);\n\t\tb = fabs(blue);\n\n\t\tif (r > 1.0)\n\t\t\tr = 1.0;\n\t\tif (g > 1.0)\n\t\t\tg = 1.0;\n\t\tif (b > 1.0)\n\t\t\tb = 1.0;\n\t}\n\n\ti->r = r;\n\ti->g = g;\n\ti->b = b;\n}\n\nvoid graph_free(struct graph *bg)\n{\n\tfree(bg->title);\n\tfree(bg->xtitle);\n\tfree(bg->ytitle);\n\tgraph_free_labels(bg);\n}\n\n/* For each line in the line graph, up to per_label_limit segments may\n * be added.  After that, adding more data to the end of the line\n * causes data to drop off of the front of the line.\n */\nvoid line_graph_set_data_count_limit(struct graph *g, int per_label_limit)\n{\n\tg->per_label_limit = per_label_limit;\n}\n\nvoid graph_add_extra_space(struct graph *g, double left_percent,\n\t\t\t   double right_percent, double top_percent,\n\t\t\t   double bottom_percent)\n{\n\tg->left_extra = left_percent;\n\tg->right_extra = right_percent;\n\tg->top_extra = top_percent;\n\tg->bottom_extra = bottom_percent;\n}\n\n/*\n * Normally values are logged in a base unit of 0, but for other purposes\n * it makes more sense to log in higher unit. For instance for bandwidth\n * purposes, you may want to log in KB/sec (or MB/sec) rather than bytes/sec.\n */\nvoid graph_set_base_offset(struct graph *g, unsigned int base_offset)\n{\n\tg->base_offset = base_offset;\n}\n\nint graph_has_tooltips(struct graph *g)\n{\n\tstruct flist_head *entry;\n\tstruct graph_label *i;\n\n\tflist_for_each(entry, &g->label_list) {\n\t\ti = flist_entry(entry, struct graph_label, list);\n\n\t\tif (!prio_tree_empty(&i->prio_tree))\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nint graph_contains_xy(struct graph *g, int x, int y)\n{\n\tint first_x = g->xoffset;\n\tint last_x = g->xoffset + g->xdim;\n\tint first_y = g->yoffset;\n\tint last_y = g->yoffset + g->ydim;\n\n\treturn (x >= first_x && x <= last_x) && (y >= first_y && y <= last_y);\n}\n\nconst char *graph_find_tooltip(struct graph *g, int ix, int iy)\n{\n\tdouble x = ix, y = iy;\n\tstruct prio_tree_iter iter;\n\tstruct prio_tree_node *n;\n\tstruct graph_value *best = NULL;\n\tstruct flist_head *entry;\n\tdouble best_delta;\n\tdouble maxy, miny;\n\n\tx -= g->xoffset;\n\ty -= g->yoffset;\n\n\tx = g->xtick_zero_val + ((x - g->xtick_zero) * g->xtick_delta);\n\ty = g->ytick_zero_val + ((y - g->ytick_zero) * g->ytick_delta);\n\n\tx = x * 1000.0;\n\tmaxy = y + (g->ytick_one_val * TOOLTIP_DELTA);\n\tminy = y - (g->ytick_one_val * TOOLTIP_DELTA);\n\tbest_delta = UINT_MAX;\n\tflist_for_each(entry, &g->label_list) {\n\t\tstruct graph_label *i;\n\n\t\ti = flist_entry(entry, struct graph_label, list);\n\t\tif (i->hide)\n\t\t\tcontinue;\n\n\t\tINIT_PRIO_TREE_ITER(&iter);\n\t\tprio_tree_iter_init(&iter, &i->prio_tree, x, x);\n\n\t\tn = prio_tree_next(&iter);\n\t\tif (!n)\n\t\t\tcontinue;\n\n\t\tdo {\n\t\t\tstruct graph_value *v, *rootv;\n\t\t\tdouble yval, ydiff;\n\n\t\t\tv = container_of(n, struct graph_value, node);\n\t\t\trootv = v;\n\t\t\tdo {\n\t\t\t\tyval = gety(v);\n\t\t\t\tydiff = fabs(yval - y);\n\n\t\t\t\t/*\n\t\t\t\t * zero delta, or within or match criteria, break\n\t\t\t\t */\n\t\t\t\tif (ydiff < best_delta) {\n\t\t\t\t\tbest_delta = ydiff;\n\t\t\t\t\tif (!best_delta ||\n\t\t\t\t\t    (yval >= miny && yval <= maxy)) {\n\t\t\t\t\t\tbest = v;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!flist_empty(&v->alias))\n\t\t\t\t\tv = flist_first_entry(&v->alias, struct graph_value, alias);\n\t\t\t} while (v != rootv);\n\t\t} while ((n = prio_tree_next(&iter)) != NULL);\n\n\t\t/*\n\t\t * If we got matches in one label, don't check others.\n\t\t */\n\t\tif (best)\n\t\t\tbreak;\n\t}\n\n\tif (best)\n\t\treturn best->tooltip;\n\n\treturn NULL;\n}\n\nvoid graph_set_graph_all_zeroes(struct graph *g, unsigned int set)\n{\n\tg->dont_graph_all_zeroes = !set;\n}\n"
        },
        {
          "name": "graph.h",
          "type": "blob",
          "size": 4.4580078125,
          "content": "#ifndef GRAPH_H\n#define GRAPH_H\n\nstruct graph;\nstruct graph_label;\n\ntypedef struct graph_label * graph_label_t;\n\n#define GRAPH_DEFAULT_FONT\t\"Sans 12\"\n\nstruct graph *graph_new(unsigned int xdim, unsigned int ydim, const char *font);\n/* graph_new() Returns a new graph structure of the given dimensions and font */\nvoid graph_set_size(struct graph *g, unsigned int xdim, unsigned int ydim);\n/* graph_set_size() Changes the size of a graph to the given dimensions. */ \nvoid graph_set_position(struct graph *g, double xoffset, double yoffset);\n/* graph_set_position() sets the x- and y-offset to translate the graph */\nvoid bar_graph_draw(struct graph *g, cairo_t *cr);\n/* bar_graph_draw() draws the given graph as a bar graph */\nvoid line_graph_draw(struct graph *g, cairo_t *cr);\n/* line_graph_draw draws the given graph as a line graph */\nvoid line_graph_set_data_count_limit(struct graph *g, int per_label_limit);\n/* line_graph_set_data_count_limit() limits the amount of data which can\n * be added to a line graph.  Once the limit is reached, the oldest data \n * is discarded as new data is added\n */\nvoid graph_set_font(struct graph *g, const char *font);\nvoid graph_title(struct graph *g, const char *title);\n/* graph_title() sets the main title of the graph to the given string */\nvoid graph_x_title(struct graph *g, const char *title);\n/* graph_x_title() sets the title of the x axis to the given string */\nvoid graph_y_title(struct graph *g, const char *title);\n/* graph_y_title() sets the title of the y axis to the given string */\ngraph_label_t graph_add_label(struct graph *g, const char *label);\n/* graph_add_label() adds a new \"stream\" of data to be graphed.\n * For line charts, each label is a separate line on the graph.\n * For bar charts, each label is a grouping of columns on the x-axis\n * For example:\n *\n *  |  *                          | **\n *  |   *      xxxxxxxx           | **\n *  |    ***  x                   | **              **\n *  |       *x       ****         | **      **      **\n *  |    xxxx*  *****             | ** xx   ** xx   **\n *  |   x     **                  | ** xx   ** xx   ** xx\n *  |  x                          | ** xx   ** xx   ** xx\n *  -----------------------       -------------------------\n *                                    A       B       C\n *\n * For a line graph, the 'x's     For a bar graph, \n * would be on one \"label\", and   'A', 'B', and 'C'\n * the '*'s would be on another   are the labels.\n * label.\n */\n\nint graph_add_data(struct graph *g, graph_label_t label, const double value);\n/* graph_add_data() is used to add data to the labels of a bar graph */\nint graph_add_xy_data(struct graph *g, graph_label_t label,\n\t\tconst double x, const double y, const char *tooltip);\n/* graph_add_xy_data is used to add data to the labels of a line graph */\n\nvoid graph_set_color(struct graph *g, graph_label_t label,\n\t\tdouble red, double green, double blue);\n#define INVISIBLE_COLOR (-1.0)\n/* graph_set_color is used to set the color used to plot the data in\n * a line graph.  INVISIBLE_COLOR can be used to plot the data invisibly.\n * Invisible data will have the same effect on the scaling of the axes\n * as visible data.\n */\n\nvoid graph_free(struct graph *bg);\n/* free a graph allocated by graph_new() */\n\ntypedef void (*graph_axis_unit_change_callback)(struct graph *g, int power_of_ten);\nvoid graph_x_axis_unit_change_notify(struct graph *g, graph_axis_unit_change_callback f);\nvoid graph_y_axis_unit_change_notify(struct graph *g, graph_axis_unit_change_callback f);\n/* The labels used on the x and y axes may be shortened.  You can register for callbacks\n * so that you can know how the labels are shorted, typically used to adjust the axis\n * titles to display the proper units.  The power_of_ten parameter indicates what power\n * of ten the labels have been divided by (9, 6, 3, or 0, corresponding to billions,\n * millions, thousands and ones. \n */ \n\nvoid graph_add_extra_space(struct graph *g, double left_percent, double right_percent,\n\t\t\t\tdouble top_percent, double bottom_percent);\n/* graph_add_extra_space() adds extra space to edges of the the graph\n * so that the data doesn't go to the very edges.\n */\n\nextern int graph_has_tooltips(struct graph *g);\nextern const char *graph_find_tooltip(struct graph *g, int x, int y);\nextern int graph_contains_xy(struct graph *p, int x, int y);\n\nextern void graph_set_base_offset(struct graph *g, unsigned int base_offset);\nextern void graph_set_graph_all_zeroes(struct graph *g, unsigned int set);\n\nextern void graph_clear_values(struct graph *g);\n\n#endif\n\n"
        },
        {
          "name": "hash.h",
          "type": "blob",
          "size": 3.322265625,
          "content": "#ifndef _LINUX_HASH_H\n#define _LINUX_HASH_H\n\n#include <inttypes.h>\n#include \"arch/arch.h\"\n#include \"compiler/compiler.h\"\n\n/* Fast hashing routine for a long.\n   (C) 2002 William Lee Irwin III, IBM */\n\n/*\n * Although a random odd number will do, it turns out that the golden\n * ratio phi = (sqrt(5)-1)/2, or its negative, has particularly nice\n * properties.\n *\n * These are the negative, (1 - phi) = (phi^2) = (3 - sqrt(5))/2.\n * (See Knuth vol 3, section 6.4, exercise 9.)\n */\n#define GOLDEN_RATIO_32 0x61C88647\n#define GOLDEN_RATIO_64 0x61C8864680B583EBull\n\nstatic inline unsigned long __hash_long(uint64_t val)\n{\n\tuint64_t hash = val;\n\n#if BITS_PER_LONG == 64\n\thash *= GOLDEN_RATIO_64;\n#else\n\t/*  Sigh, gcc can't optimise this alone like it does for 32 bits. */\n\tuint64_t n = hash;\n\tn <<= 18;\n\thash -= n;\n\tn <<= 33;\n\thash -= n;\n\tn <<= 3;\n\thash += n;\n\tn <<= 3;\n\thash -= n;\n\tn <<= 4;\n\thash += n;\n\tn <<= 2;\n\thash += n;\n#endif\n\n\treturn hash;\n}\n\nstatic inline unsigned long hash_long(unsigned long val, unsigned int bits)\n{\n\t/* High bits are more random, so use them. */\n\treturn __hash_long(val) >> (BITS_PER_LONG - bits);\n}\n\nstatic inline uint64_t __hash_u64(uint64_t val)\n{\n\treturn val * GOLDEN_RATIO_64;\n}\n\t\nstatic inline unsigned long hash_ptr(void *ptr, unsigned int bits)\n{\n\treturn hash_long((uintptr_t)ptr, bits);\n}\n\n/*\n * Bob Jenkins jhash\n */\n\n#define JHASH_INITVAL\tGOLDEN_RATIO_32\n\nstatic inline uint32_t rol32(uint32_t word, uint32_t shift)\n{\n\treturn (word << shift) | (word >> (32 - shift));\n}\n\n/* __jhash_mix -- mix 3 32-bit values reversibly. */\n#define __jhash_mix(a, b, c)\t\t\t\\\n{\t\t\t\t\t\t\\\n\ta -= c;  a ^= rol32(c, 4);  c += b;\t\\\n\tb -= a;  b ^= rol32(a, 6);  a += c;\t\\\n\tc -= b;  c ^= rol32(b, 8);  b += a;\t\\\n\ta -= c;  a ^= rol32(c, 16); c += b;\t\\\n\tb -= a;  b ^= rol32(a, 19); a += c;\t\\\n\tc -= b;  c ^= rol32(b, 4);  b += a;\t\\\n}\n\n/* __jhash_final - final mixing of 3 32-bit values (a,b,c) into c */\n#define __jhash_final(a, b, c)\t\t\t\\\n{\t\t\t\t\t\t\\\n\tc ^= b; c -= rol32(b, 14);\t\t\\\n\ta ^= c; a -= rol32(c, 11);\t\t\\\n\tb ^= a; b -= rol32(a, 25);\t\t\\\n\tc ^= b; c -= rol32(b, 16);\t\t\\\n\ta ^= c; a -= rol32(c, 4);\t\t\\\n\tb ^= a; b -= rol32(a, 14);\t\t\\\n\tc ^= b; c -= rol32(b, 24);\t\t\\\n}\n\nstatic inline uint32_t jhash(const void *key, uint32_t length, uint32_t initval)\n{\n\tconst uint8_t *k = key;\n\tuint32_t a, b, c;\n\n\t/* Set up the internal state */\n\ta = b = c = JHASH_INITVAL + length + initval;\n\n\t/* All but the last block: affect some 32 bits of (a,b,c) */\n\twhile (length > 12) {\n\t\ta += *k;\n\t\tb += *(k + 4);\n\t\tc += *(k + 8);\n\t\t__jhash_mix(a, b, c);\n\t\tlength -= 12;\n\t\tk += 12;\n\t}\n\n\t/* Last block: affect all 32 bits of (c) */\n\t/* All the case statements fall through */\n\tswitch (length) {\n\tcase 12: c += (uint32_t) k[11] << 24;\tfio_fallthrough;\n\tcase 11: c += (uint32_t) k[10] << 16;\tfio_fallthrough;\n\tcase 10: c += (uint32_t) k[9] << 8;\tfio_fallthrough;\n\tcase 9:  c += k[8];\t\t\tfio_fallthrough;\n\tcase 8:  b += (uint32_t) k[7] << 24;\tfio_fallthrough;\n\tcase 7:  b += (uint32_t) k[6] << 16;\tfio_fallthrough;\n\tcase 6:  b += (uint32_t) k[5] << 8;\tfio_fallthrough;\n\tcase 5:  b += k[4];\t\t\tfio_fallthrough;\n\tcase 4:  a += (uint32_t) k[3] << 24;\tfio_fallthrough;\n\tcase 3:  a += (uint32_t) k[2] << 16;\tfio_fallthrough;\n\tcase 2:  a += (uint32_t) k[1] << 8;\tfio_fallthrough;\n\tcase 1:  a += k[0];\n\t\t __jhash_final(a, b, c);\n\t\t fio_fallthrough;\n\tcase 0: /* Nothing left to add */\n\t\tbreak;\n\t}\n\n\treturn c;\n}\n\n#endif /* _LINUX_HASH_H */\n"
        },
        {
          "name": "helper_thread.c",
          "type": "blob",
          "size": 9.494140625,
          "content": "#include <errno.h>\n#include <signal.h>\n#include <stdio.h>\n#include <string.h>\n#include <unistd.h>\n#ifdef CONFIG_HAVE_TIMERFD_CREATE\n#include <sys/timerfd.h>\n#endif\n#ifdef CONFIG_VALGRIND_DEV\n#include <valgrind/drd.h>\n#else\n#define DRD_IGNORE_VAR(x) do { } while (0)\n#endif\n\n#ifdef WIN32\n#include \"os/os-windows.h\"\n#endif\n\n#include \"fio.h\"\n#include \"smalloc.h\"\n#include \"helper_thread.h\"\n#include \"steadystate.h\"\n#include \"pshared.h\"\n\nstatic int sleep_accuracy_ms;\nstatic int timerfd = -1;\n\nenum action {\n\tA_EXIT\t\t= 1,\n\tA_RESET\t\t= 2,\n\tA_DO_STAT\t= 3,\n};\n\nstatic struct helper_data {\n\tvolatile int exit;\n\tint pipe[2]; /* 0: read end; 1: write end. */\n\tstruct sk_out *sk_out;\n\tpthread_t thread;\n\tstruct fio_sem *startup_sem;\n} *helper_data;\n\nstruct interval_timer {\n\tconst char\t*name;\n\tstruct timespec\texpires;\n\tuint32_t\tinterval_ms;\n\tint\t\t(*func)(void);\n};\n\nvoid helper_thread_destroy(void)\n{\n\tif (!helper_data)\n\t\treturn;\n\n\tclose(helper_data->pipe[0]);\n\tclose(helper_data->pipe[1]);\n\tsfree(helper_data);\n}\n\n#ifdef _WIN32\nstatic void sock_init(void)\n{\n\tWSADATA wsaData;\n\tint res;\n\n\t/* It is allowed to call WSAStartup() more than once. */\n\tres = WSAStartup(MAKEWORD(2, 2), &wsaData);\n\tassert(res == 0);\n}\n\nstatic int make_nonblocking(int fd)\n{\n\tunsigned long arg = 1;\n\n\treturn ioctlsocket(fd, FIONBIO, &arg);\n}\n\nstatic int write_to_pipe(int fd, const void *buf, size_t len)\n{\n\treturn send(fd, buf, len, 0);\n}\n\nstatic int read_from_pipe(int fd, void *buf, size_t len)\n{\n\treturn recv(fd, buf, len, 0);\n}\n#else\nstatic void sock_init(void)\n{\n}\n\nstatic int make_nonblocking(int fd)\n{\n\treturn fcntl(fd, F_SETFL, O_NONBLOCK);\n}\n\nstatic int write_to_pipe(int fd, const void *buf, size_t len)\n{\n\treturn write(fd, buf, len);\n}\n\nstatic int read_from_pipe(int fd, void *buf, size_t len)\n{\n\treturn read(fd, buf, len);\n}\n#endif\n\nstatic void block_signals(void)\n{\n#ifdef CONFIG_PTHREAD_SIGMASK\n\tsigset_t sigmask;\n\n\tint ret;\n\n\tret = pthread_sigmask(SIG_UNBLOCK, NULL, &sigmask);\n\tassert(ret == 0);\n\tret = pthread_sigmask(SIG_BLOCK, &sigmask, NULL);\n#endif\n}\n\nstatic void submit_action(enum action a)\n{\n\tconst char data = a;\n\tint ret;\n\n\tif (!helper_data)\n\t\treturn;\n\n\tret = write_to_pipe(helper_data->pipe[1], &data, sizeof(data));\n\tif (ret != 1) {\n\t\tlog_err(\"failed to write action into pipe, err %i:%s\", errno, strerror(errno));\n\t\tassert(0);\n\t}\n}\n\nvoid helper_reset(void)\n{\n\tsubmit_action(A_RESET);\n}\n\n/*\n * May be invoked in signal handler context and hence must only call functions\n * that are async-signal-safe. See also\n * https://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html#tag_15_04_03.\n */\nvoid helper_do_stat(void)\n{\n\tsubmit_action(A_DO_STAT);\n}\n\nbool helper_should_exit(void)\n{\n\tif (!helper_data)\n\t\treturn true;\n\n\treturn helper_data->exit;\n}\n\nvoid helper_thread_exit(void)\n{\n\tif (!helper_data)\n\t\treturn;\n\n\thelper_data->exit = 1;\n\tpthread_join(helper_data->thread, NULL);\n}\n\n/* Resets timers and returns the time in milliseconds until the next event. */\nstatic int reset_timers(struct interval_timer timer[], int num_timers,\n\t\t\tstruct timespec *now)\n{\n\tuint32_t msec_to_next_event = INT_MAX;\n\tint i;\n\n\tfor (i = 0; i < num_timers; ++i) {\n\t\ttimer[i].expires = *now;\n\t\ttimespec_add_msec(&timer[i].expires, timer[i].interval_ms);\n\t\tmsec_to_next_event = min_not_zero(msec_to_next_event,\n\t\t\t\t\t\t  timer[i].interval_ms);\n\t}\n\n\treturn msec_to_next_event;\n}\n\n/*\n * Waits for an action from fd during at least timeout_ms. `fd` must be in\n * non-blocking mode.\n */\nstatic uint8_t wait_for_action(int fd, unsigned int timeout_ms)\n{\n\tstruct timeval timeout = {\n\t\t.tv_sec  = timeout_ms / 1000,\n\t\t.tv_usec = (timeout_ms % 1000) * 1000,\n\t};\n\tfd_set rfds, efds;\n\tuint8_t action = 0;\n\tuint64_t exp;\n\tint res;\n\n\tres = read_from_pipe(fd, &action, sizeof(action));\n\tif (res > 0 || timeout_ms == 0)\n\t\treturn action;\n\tFD_ZERO(&rfds);\n\tFD_SET(fd, &rfds);\n\tFD_ZERO(&efds);\n\tFD_SET(fd, &efds);\n#ifdef CONFIG_HAVE_TIMERFD_CREATE\n\t{\n\t\t/*\n\t\t * If the timer frequency is 100 Hz, select() will round up\n\t\t * `timeout` to the next multiple of 1 / 100 Hz = 10 ms. Hence\n\t\t * use a high-resolution timer if possible to increase\n\t\t * select() timeout accuracy.\n\t\t */\n\t\tstruct itimerspec delta = {};\n\n\t\tdelta.it_value.tv_sec = timeout.tv_sec;\n\t\tdelta.it_value.tv_nsec = timeout.tv_usec * 1000;\n\t\tres = timerfd_settime(timerfd, 0, &delta, NULL);\n\t\tassert(res == 0);\n\t\tFD_SET(timerfd, &rfds);\n\t}\n#endif\n\tres = select(max(fd, timerfd) + 1, &rfds, NULL, &efds,\n\t\t     timerfd >= 0 ? NULL : &timeout);\n\tif (res < 0) {\n\t\tlog_err(\"fio: select() call in helper thread failed: %s\",\n\t\t\tstrerror(errno));\n\t\treturn A_EXIT;\n\t}\n\tif (FD_ISSET(fd, &rfds))\n\t\tread_from_pipe(fd, &action, sizeof(action));\n\tif (timerfd >= 0 && FD_ISSET(timerfd, &rfds)) {\n\t\tres = read(timerfd, &exp, sizeof(exp));\n\t\tassert(res == sizeof(exp));\n\t}\n\treturn action;\n}\n\n/*\n * Verify whether or not timer @it has expired. If timer @it has expired, call\n * @it->func(). @now is the current time. @msec_to_next_event is an\n * input/output parameter that represents the time until the next event.\n */\nstatic int eval_timer(struct interval_timer *it, const struct timespec *now,\n\t\t      unsigned int *msec_to_next_event)\n{\n\tint64_t delta_ms;\n\tbool expired;\n\n\t/* interval == 0 means that the timer is disabled. */\n\tif (it->interval_ms == 0)\n\t\treturn 0;\n\n\tdelta_ms = rel_time_since(now, &it->expires);\n\texpired = delta_ms <= sleep_accuracy_ms;\n\tif (expired) {\n\t\ttimespec_add_msec(&it->expires, it->interval_ms);\n\t\tdelta_ms = rel_time_since(now, &it->expires);\n\t\tif (delta_ms < it->interval_ms - sleep_accuracy_ms ||\n\t\t    delta_ms > it->interval_ms + sleep_accuracy_ms) {\n\t\t\tdprint(FD_HELPERTHREAD,\n\t\t\t       \"%s: delta = %\" PRIi64 \" <> %u. Clock jump?\\n\",\n\t\t\t       it->name, delta_ms, it->interval_ms);\n\t\t\tdelta_ms = it->interval_ms;\n\t\t\tit->expires = *now;\n\t\t\ttimespec_add_msec(&it->expires, it->interval_ms);\n\t\t}\n\t}\n\t*msec_to_next_event = min((unsigned int)delta_ms, *msec_to_next_event);\n\treturn expired ? it->func() : 0;\n}\n\nstatic void *helper_thread_main(void *data)\n{\n\tstruct helper_data *hd = data;\n\tunsigned int msec_to_next_event, next_log;\n\tstruct interval_timer timer[] = {\n\t\t{\n\t\t\t.name = \"disk_util\",\n\t\t\t.interval_ms = DISK_UTIL_MSEC,\n\t\t\t.func = update_io_ticks,\n\t\t},\n\t\t{\n\t\t\t.name = \"status_interval\",\n\t\t\t.interval_ms = status_interval,\n\t\t\t.func = __show_running_run_stats,\n\t\t},\n\t\t{\n\t\t\t.name = \"steadystate\",\n\t\t\t.interval_ms = steadystate_enabled ? ss_check_interval :\n\t\t\t\t0,\n\t\t\t.func = steadystate_check,\n\t\t}\n\t};\n\tstruct timespec ts;\n\tlong clk_tck;\n\tint ret = 0;\n\n\tos_clk_tck(&clk_tck);\n\n\tdprint(FD_HELPERTHREAD, \"clk_tck = %ld\\n\", clk_tck);\n\tassert(clk_tck > 0);\n\tsleep_accuracy_ms = (1000 + clk_tck - 1) / clk_tck;\n\n#ifdef CONFIG_HAVE_TIMERFD_CREATE\n\ttimerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK);\n\tassert(timerfd >= 0);\n\tsleep_accuracy_ms = 1;\n#endif\n\n\tsk_out_assign(hd->sk_out);\n\n\t/* Let another thread handle signals. */\n\tblock_signals();\n\n\tfio_get_mono_time(&ts);\n\tmsec_to_next_event = reset_timers(timer, FIO_ARRAY_SIZE(timer), &ts);\n\n\tfio_sem_up(hd->startup_sem);\n\n\twhile (!ret && !hd->exit) {\n\t\tuint8_t action;\n\t\tint i;\n\n\t\taction = wait_for_action(hd->pipe[0], msec_to_next_event);\n\t\tif (action == A_EXIT)\n\t\t\tbreak;\n\n\t\tfio_get_mono_time(&ts);\n\n\t\tmsec_to_next_event = INT_MAX;\n\n\t\tif (action == A_RESET)\n\t\t\tmsec_to_next_event = reset_timers(timer,\n\t\t\t\t\t\tFIO_ARRAY_SIZE(timer), &ts);\n\n\t\tfor (i = 0; i < FIO_ARRAY_SIZE(timer); ++i)\n\t\t\tret = eval_timer(&timer[i], &ts, &msec_to_next_event);\n\n\t\tif (action == A_DO_STAT)\n\t\t\t__show_running_run_stats();\n\n\t\tnext_log = calc_log_samples();\n\t\tif (!next_log)\n\t\t\tnext_log = DISK_UTIL_MSEC;\n\n\t\tmsec_to_next_event = min(next_log, msec_to_next_event);\n\t\tdprint(FD_HELPERTHREAD,\n\t\t       \"next_log: %u, msec_to_next_event: %u\\n\",\n\t\t       next_log, msec_to_next_event);\n\n\t\tif (!is_backend)\n\t\t\tprint_thread_status();\n\t}\n\n\tif (timerfd >= 0) {\n\t\tclose(timerfd);\n\t\ttimerfd = -1;\n\t}\n\n\tfio_writeout_logs(false);\n\n\tsk_out_drop();\n\treturn NULL;\n}\n\n/*\n * Connect two sockets to each other to emulate the pipe() system call on Windows.\n */\nint pipe_over_loopback(int fd[2])\n{\n\tstruct sockaddr_in addr = { .sin_family = AF_INET };\n\tsocklen_t len = sizeof(addr);\n\tint res;\n\n\taddr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);\n\n\tsock_init();\n\n\tfd[0] = socket(AF_INET, SOCK_STREAM, 0);\n\tif (fd[0] < 0)\n\t\tgoto err;\n\tfd[1] = socket(AF_INET, SOCK_STREAM, 0);\n\tif (fd[1] < 0)\n\t\tgoto close_fd_0;\n\tres = bind(fd[0], (struct sockaddr *)&addr, len);\n\tif (res < 0)\n\t\tgoto close_fd_1;\n\tres = getsockname(fd[0], (struct sockaddr *)&addr, &len);\n\tif (res < 0)\n\t\tgoto close_fd_1;\n\tres = listen(fd[0], 1);\n\tif (res < 0)\n\t\tgoto close_fd_1;\n\tres = connect(fd[1], (struct sockaddr *)&addr, len);\n\tif (res < 0)\n\t\tgoto close_fd_1;\n\tres = accept(fd[0], NULL, NULL);\n\tif (res < 0)\n\t\tgoto close_fd_1;\n\tclose(fd[0]);\n\tfd[0] = res;\n\treturn 0;\n\nclose_fd_1:\n\tclose(fd[1]);\n\nclose_fd_0:\n\tclose(fd[0]);\n\nerr:\n\treturn -1;\n}\n\nint helper_thread_create(struct fio_sem *startup_sem, struct sk_out *sk_out)\n{\n\tstruct helper_data *hd;\n\tint ret;\n\n\thd = scalloc(1, sizeof(*hd));\n\tif (!hd)\n\t\treturn 1;\n\n\tsetup_disk_util();\n\tsteadystate_setup();\n\n\thd->sk_out = sk_out;\n\n#if defined(CONFIG_PIPE2)\n\tret = pipe2(hd->pipe, O_CLOEXEC);\n#elif defined(CONFIG_PIPE)\n\tret = pipe(hd->pipe);\n#else\n\tret = pipe_over_loopback(hd->pipe);\n#endif\n\tif (ret)\n\t\treturn 1;\n\n\tret = make_nonblocking(hd->pipe[0]);\n\tassert(ret >= 0);\n\n\thd->startup_sem = startup_sem;\n\n\tDRD_IGNORE_VAR(helper_data);\n\n\tret = pthread_create(&hd->thread, NULL, helper_thread_main, hd);\n\tif (ret) {\n\t\tlog_err(\"Can't create helper thread: %s\\n\", strerror(ret));\n\t\treturn 1;\n\t}\n\n\thelper_data = hd;\n\n\tdprint(FD_MUTEX, \"wait on startup_sem\\n\");\n\tfio_sem_down(startup_sem);\n\tdprint(FD_MUTEX, \"done waiting on startup_sem\\n\");\n\treturn 0;\n}\n"
        },
        {
          "name": "helper_thread.h",
          "type": "blob",
          "size": 0.361328125,
          "content": "#ifndef FIO_HELPER_THREAD_H\n#define FIO_HELPER_THREAD_H\n\n#include <stdbool.h>\n\nstruct fio_sem;\nstruct sk_out;\n\nextern void helper_reset(void);\nextern void helper_do_stat(void);\nextern bool helper_should_exit(void);\nextern void helper_thread_destroy(void);\nextern void helper_thread_exit(void);\nextern int helper_thread_create(struct fio_sem *, struct sk_out *);\n\n#endif\n"
        },
        {
          "name": "helpers.c",
          "type": "blob",
          "size": 0.5390625,
          "content": "#include <errno.h>\n\n#include \"helpers.h\"\n\n#ifndef CONFIG_LINUX_FALLOCATE\nint fallocate(int fd, int mode, off_t offset, off_t len)\n{\n\terrno = ENOSYS;\n\treturn -1;\n}\n#endif\n\n#ifndef CONFIG_POSIX_FALLOCATE\nint posix_fallocate(int fd, off_t offset, off_t len)\n{\n\treturn 0;\n}\n#endif\n\n#ifndef CONFIG_SYNC_FILE_RANGE\nint sync_file_range(int fd, uint64_t offset, uint64_t nbytes,\n\t\t    unsigned int flags)\n{\n\terrno = ENOSYS;\n\treturn -1;\n}\n#endif\n\n#ifndef CONFIG_POSIX_FADVISE\nint posix_fadvise(int fd, off_t offset, off_t len, int advice)\n{\n\treturn 0;\n}\n#endif\n"
        },
        {
          "name": "helpers.h",
          "type": "blob",
          "size": 0.4375,
          "content": "#ifndef FIO_HELPERS_H\n#define FIO_HELPERS_H\n\n#include <sys/types.h>\n\n#include \"os/os.h\"\n\nextern int fallocate(int fd, int mode, off_t offset, off_t len);\nextern int posix_fallocate(int fd, off_t offset, off_t len);\n#ifndef CONFIG_SYNC_FILE_RANGE\nextern int sync_file_range(int fd, uint64_t offset, uint64_t nbytes,\n\t\t\t\t\tunsigned int flags);\n#endif\nextern int posix_fadvise(int fd, off_t offset, off_t len, int advice);\n\n#endif /* FIO_HELPERS_H_ */\n"
        },
        {
          "name": "idletime.c",
          "type": "blob",
          "size": 11.60546875,
          "content": "#include <math.h>\n#include \"fio.h\"\n#include \"json.h\"\n#include \"idletime.h\"\n\nstatic volatile struct idle_prof_common ipc;\n\n/*\n * Get time to complete an unit work on a particular cpu.\n * The minimum number in CALIBRATE_RUNS runs is returned.\n */\nstatic double calibrate_unit(unsigned char *data)\n{\n\tunsigned long t, i, j, k;\n\tstruct timespec tps;\n\tdouble tunit = 0.0;\n\n\tfor (i = 0; i < CALIBRATE_RUNS; i++) {\n\n\t\tfio_gettime(&tps, NULL);\n\t\t/* scale for less variance */\n\t\tfor (j = 0; j < CALIBRATE_SCALE; j++) {\n\t\t\t/* unit of work */\n\t\t\tfor (k=0; k < page_size; k++) {\n\t\t\t\tdata[(k + j) % page_size] = k % 256;\n\t\t\t\t/*\n\t\t\t\t * we won't see STOP here. this is to match\n\t\t\t\t * the same statement in the profiling loop.\n\t\t\t\t */\n\t\t\t\tif (ipc.status == IDLE_PROF_STATUS_PROF_STOP)\n\t\t\t\t\treturn 0.0;\n\t\t\t}\n\t\t}\n\n\t\tt = utime_since_now(&tps);\n\t\tif (!t)\n\t\t\tcontinue;\n\n\t\t/* get the minimum time to complete CALIBRATE_SCALE units */\n\t\tif ((i == 0) || ((double)t < tunit))\n\t\t\ttunit = (double)t;\n\t}\n\n\treturn tunit / CALIBRATE_SCALE;\n}\n\nstatic void free_cpu_affinity(struct idle_prof_thread *ipt)\n{\n#if defined(FIO_HAVE_CPU_AFFINITY)\n\tfio_cpuset_exit(&ipt->cpu_mask);\n#endif\n}\n\nstatic int set_cpu_affinity(struct idle_prof_thread *ipt)\n{\n#if defined(FIO_HAVE_CPU_AFFINITY)\n\tif (fio_cpuset_init(&ipt->cpu_mask)) {\n\t\tlog_err(\"fio: cpuset init failed\\n\");\n\t\treturn -1;\n\t}\n\n\tfio_cpu_set(&ipt->cpu_mask, ipt->cpu);\n\n\tif (fio_setaffinity(gettid(), ipt->cpu_mask)) {\n\t\tlog_err(\"fio: fio_setaffinity failed\\n\");\n\t\tfio_cpuset_exit(&ipt->cpu_mask);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n#else\n\tlog_err(\"fio: fio_setaffinity not supported\\n\");\n\treturn -1;\n#endif\n}\n\nstatic void *idle_prof_thread_fn(void *data)\n{\n\tint retval;\n\tunsigned long j, k;\n\tstruct idle_prof_thread *ipt = data;\n\n\t/* wait for all threads are spawned */\n\tpthread_mutex_lock(&ipt->init_lock);\n\n\t/* exit if any other thread failed to start */\n\tif (ipc.status == IDLE_PROF_STATUS_ABORT) {\n\t\tpthread_mutex_unlock(&ipt->init_lock);\n\t\treturn NULL;\n\t}\n\n\tretval = set_cpu_affinity(ipt);\n\tif (retval == -1) {\n\t\tipt->state = TD_EXITED;\n\t\tpthread_mutex_unlock(&ipt->init_lock);\n\t\treturn NULL;\n        }\n\n\tipt->cali_time = calibrate_unit(ipt->data);\n\n\t/* delay to set IDLE class till now for better calibration accuracy */\n#if defined(CONFIG_SCHED_IDLE)\n\tif ((retval = fio_set_sched_idle()))\n\t\tlog_err(\"fio: fio_set_sched_idle failed\\n\");\n#else\n\tretval = -1;\n\tlog_err(\"fio: fio_set_sched_idle not supported\\n\");\n#endif\n\tif (retval == -1) {\n\t\tipt->state = TD_EXITED;\n\t\tpthread_mutex_unlock(&ipt->init_lock);\n\t\tgoto do_exit;\n\t}\n\n\tipt->state = TD_INITIALIZED;\n\n\t/* signal the main thread that calibration is done */\n\tpthread_cond_signal(&ipt->cond);\n\tpthread_mutex_unlock(&ipt->init_lock);\n\n\t/* wait for other calibration to finish */\n\tpthread_mutex_lock(&ipt->start_lock);\n\n\t/* exit if other threads failed to initialize */\n\tif (ipc.status == IDLE_PROF_STATUS_ABORT) {\n\t\tpthread_mutex_unlock(&ipt->start_lock);\n\t\tgoto do_exit;\n\t}\n\n\t/* exit if we are doing calibration only */\n\tif (ipc.status == IDLE_PROF_STATUS_CALI_STOP) {\n\t\tpthread_mutex_unlock(&ipt->start_lock);\n\t\tgoto do_exit;\n\t}\n\n\tfio_gettime(&ipt->tps, NULL);\n\tipt->state = TD_RUNNING;\n\n\tj = 0;\n\twhile (1) {\n\t\tfor (k = 0; k < page_size; k++) {\n\t\t\tipt->data[(k + j) % page_size] = k % 256;\n\t\t\tif (ipc.status == IDLE_PROF_STATUS_PROF_STOP) {\n\t\t\t\tfio_gettime(&ipt->tpe, NULL);\n\t\t\t\tgoto idle_prof_done;\n\t\t\t}\n\t\t}\n\t\tj++;\n\t}\n\nidle_prof_done:\n\n\tipt->loops = j + (double) k / page_size;\n\tipt->state = TD_EXITED;\n\tpthread_mutex_unlock(&ipt->start_lock);\n\ndo_exit:\n\tfree_cpu_affinity(ipt);\n\treturn NULL;\n}\n\n/* calculate mean and standard deviation to complete an unit of work */\nstatic void calibration_stats(void)\n{\n\tint i;\n\tdouble sum = 0.0, var = 0.0;\n\tstruct idle_prof_thread *ipt;\n\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tsum += ipt->cali_time;\n\t}\n\n\tipc.cali_mean = sum/ipc.nr_cpus;\n\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tvar += pow(ipt->cali_time-ipc.cali_mean, 2);\n\t}\n\n\tipc.cali_stddev = sqrt(var/(ipc.nr_cpus-1));\n}\n\nvoid fio_idle_prof_init(void)\n{\n\tint i, ret;\n\tstruct timespec ts;\n\tpthread_attr_t tattr;\n\tpthread_condattr_t cattr;\n\tstruct idle_prof_thread *ipt;\n\n\tipc.nr_cpus = cpus_configured();\n\tipc.status = IDLE_PROF_STATUS_OK;\n\n\tif (ipc.opt == IDLE_PROF_OPT_NONE)\n\t\treturn;\n\n\tret = pthread_condattr_init(&cattr);\n\tassert(ret == 0);\n#ifdef CONFIG_PTHREAD_CONDATTR_SETCLOCK\n\tret = pthread_condattr_setclock(&cattr, CLOCK_MONOTONIC);\n\tassert(ret == 0);\n#endif\n\n\tif ((ret = pthread_attr_init(&tattr))) {\n\t\tlog_err(\"fio: pthread_attr_init %s\\n\", strerror(ret));\n\t\treturn;\n\t}\n\tif ((ret = pthread_attr_setscope(&tattr, PTHREAD_SCOPE_SYSTEM))) {\n\t\tlog_err(\"fio: pthread_attr_setscope %s\\n\", strerror(ret));\n\t\treturn;\n\t}\n\n\tipc.ipts = malloc(ipc.nr_cpus * sizeof(struct idle_prof_thread));\n\tif (!ipc.ipts) {\n\t\tlog_err(\"fio: malloc failed\\n\");\n\t\treturn;\n\t}\n\n\tipc.buf = malloc(ipc.nr_cpus * page_size);\n\tif (!ipc.buf) {\n\t\tlog_err(\"fio: malloc failed\\n\");\n\t\tfree(ipc.ipts);\n\t\treturn;\n\t}\n\n\t/*\n\t * profiling aborts on any single thread failure since the\n\t * result won't be accurate if any cpu is not used.\n\t */\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\n\t\tipt->cpu = i;\t\n\t\tipt->state = TD_NOT_CREATED;\n\t\tipt->data = (unsigned char *)(ipc.buf + page_size * i);\n\n\t\tif ((ret = pthread_mutex_init(&ipt->init_lock, NULL))) {\n\t\t\tipc.status = IDLE_PROF_STATUS_ABORT;\n\t\t\tlog_err(\"fio: pthread_mutex_init %s\\n\", strerror(ret));\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((ret = pthread_mutex_init(&ipt->start_lock, NULL))) {\n\t\t\tipc.status = IDLE_PROF_STATUS_ABORT;\n\t\t\tlog_err(\"fio: pthread_mutex_init %s\\n\", strerror(ret));\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((ret = pthread_cond_init(&ipt->cond, &cattr))) {\n\t\t\tipc.status = IDLE_PROF_STATUS_ABORT;\n\t\t\tlog_err(\"fio: pthread_cond_init %s\\n\", strerror(ret));\n\t\t\tbreak;\n\t\t}\n\n\t\t/* make sure all threads are spawned before they start */\n\t\tpthread_mutex_lock(&ipt->init_lock);\n\n\t\t/* make sure all threads finish init before profiling starts */\n\t\tpthread_mutex_lock(&ipt->start_lock);\n\n\t\tif ((ret = pthread_create(&ipt->thread, &tattr, idle_prof_thread_fn, ipt))) {\n\t\t\tipc.status = IDLE_PROF_STATUS_ABORT;\n\t\t\tlog_err(\"fio: pthread_create %s\\n\", strerror(ret));\n\t\t\tbreak;\n\t\t} else\n\t\t\tipt->state = TD_CREATED;\n\n\t\tif ((ret = pthread_detach(ipt->thread))) {\n\t\t\t/* log error and let the thread spin */\n\t\t\tlog_err(\"fio: pthread_detach %s\\n\", strerror(ret));\n\t\t}\n\t}\n\n\t/*\n\t * let good threads continue so that they can exit\n\t * if errors on other threads occurred previously.\n\t */\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tpthread_mutex_unlock(&ipt->init_lock);\n\t}\n\t\n\tif (ipc.status == IDLE_PROF_STATUS_ABORT)\n\t\treturn;\n\t\n\t/* wait for calibration to finish */\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tpthread_mutex_lock(&ipt->init_lock);\n\t\twhile ((ipt->state != TD_EXITED) &&\n\t\t       (ipt->state!=TD_INITIALIZED)) {\n#ifdef CONFIG_PTHREAD_CONDATTR_SETCLOCK\n\t\t\tclock_gettime(CLOCK_MONOTONIC, &ts);\n#else\n\t\t\tclock_gettime(CLOCK_REALTIME, &ts);\n#endif\n\t\t\tts.tv_sec += 1;\n\t\t\tpthread_cond_timedwait(&ipt->cond, &ipt->init_lock, &ts);\n\t\t}\n\t\tpthread_mutex_unlock(&ipt->init_lock);\n\t\n\t\t/*\n\t\t * any thread failed to initialize would abort other threads\n\t\t * later after fio_idle_prof_start. \n\t\t */\t\n\t\tif (ipt->state == TD_EXITED)\n\t\t\tipc.status = IDLE_PROF_STATUS_ABORT;\n\t}\n\n\tif (ipc.status != IDLE_PROF_STATUS_ABORT)\n\t\tcalibration_stats();\n\telse\n\t\tipc.cali_mean = ipc.cali_stddev = 0.0;\n\n\tif (ipc.opt == IDLE_PROF_OPT_CALI)\n\t\tipc.status = IDLE_PROF_STATUS_CALI_STOP;\n}\n\nvoid fio_idle_prof_start(void)\n{\n\tint i;\n\tstruct idle_prof_thread *ipt;\n\n\tif (ipc.opt == IDLE_PROF_OPT_NONE)\n\t\treturn;\n\n\t/* unlock regardless abort is set or not */\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tpthread_mutex_unlock(&ipt->start_lock);\n\t}\n}\n\nvoid fio_idle_prof_stop(void)\n{\n\tint i;\n\tuint64_t runt;\n\tstruct timespec ts;\n\tstruct idle_prof_thread *ipt;\n\n\tif (ipc.opt == IDLE_PROF_OPT_NONE)\n\t\treturn;\n\n\tif (ipc.opt == IDLE_PROF_OPT_CALI)\n\t\treturn;\n\n\tipc.status = IDLE_PROF_STATUS_PROF_STOP;\n\n\t/* wait for all threads to exit from profiling */\n\tfor (i = 0; i < ipc.nr_cpus; i++) {\n\t\tipt = &ipc.ipts[i];\n\t\tpthread_mutex_lock(&ipt->start_lock);\n\t\twhile ((ipt->state != TD_EXITED) &&\n\t\t       (ipt->state!=TD_NOT_CREATED)) {\n\t\t\tfio_gettime(&ts, NULL);\n\t\t\tts.tv_sec += 1;\n\t\t\t/* timed wait in case a signal is not received */\n\t\t\tpthread_cond_timedwait(&ipt->cond, &ipt->start_lock, &ts);\n\t\t}\n\t\tpthread_mutex_unlock(&ipt->start_lock);\n\n\t\t/* calculate idleness */\n\t\tif (ipc.cali_mean != 0.0) {\n\t\t\trunt = utime_since(&ipt->tps, &ipt->tpe);\n\t\t\tif (runt)\n\t\t\t\tipt->idleness = ipt->loops * ipc.cali_mean / runt;\n\t\t\telse\n\t\t\t\tipt->idleness = 0.0;\n\t\t} else\n\t\t\tipt->idleness = 0.0;\n\t}\n\n\t/*\n\t * memory allocations are freed via explicit fio_idle_prof_cleanup\n\t * after profiling stats are collected by apps.  \n\t */\n}\n\n/*\n * return system idle percentage when cpu is -1;\n * return one cpu idle percentage otherwise.\n */\nstatic double fio_idle_prof_cpu_stat(int cpu)\n{\n\tint i, nr_cpus = ipc.nr_cpus;\n\tstruct idle_prof_thread *ipt;\n\tdouble p = 0.0;\n\n\tif (ipc.opt == IDLE_PROF_OPT_NONE)\n\t\treturn 0.0;\n\n\tif ((cpu >= nr_cpus) || (cpu < -1)) {\n\t\tlog_err(\"fio: idle profiling invalid cpu index\\n\");\n\t\treturn 0.0;\n\t}\n\n\tif (cpu == -1) {\n\t\tfor (i = 0; i < nr_cpus; i++) {\n\t\t\tipt = &ipc.ipts[i];\n\t\t\tp += ipt->idleness;\n\t\t}\n\t\tp /= nr_cpus;\n\t} else {\n\t\tipt = &ipc.ipts[cpu];\n\t\tp = ipt->idleness;\n\t}\n\n\treturn p * 100.0;\n}\n\nvoid fio_idle_prof_cleanup(void)\n{\n\tif (ipc.ipts) {\n\t\tfree(ipc.ipts);\n\t\tipc.ipts = NULL;\n\t}\n\n\tif (ipc.buf) {\n\t\tfree(ipc.buf);\n\t\tipc.buf = NULL;\n\t}\n}\n\nint fio_idle_prof_parse_opt(const char *args)\n{\n\tipc.opt = IDLE_PROF_OPT_NONE; /* default */\n\n\tif (!args) {\n\t\tlog_err(\"fio: empty idle-prof option string\\n\");\n\t\treturn -1;\n\t}\t\n\n#if defined(FIO_HAVE_CPU_AFFINITY) && defined(CONFIG_SCHED_IDLE)\n\tif (strcmp(\"calibrate\", args) == 0) {\n\t\tipc.opt = IDLE_PROF_OPT_CALI;\n\t\tfio_idle_prof_init();\n\t\tfio_idle_prof_start();\n\t\tfio_idle_prof_stop();\n\t\tshow_idle_prof_stats(FIO_OUTPUT_NORMAL, NULL, NULL);\n\t\treturn 1;\n\t} else if (strcmp(\"system\", args) == 0) {\n\t\tipc.opt = IDLE_PROF_OPT_SYSTEM;\n\t\treturn 0;\n\t} else if (strcmp(\"percpu\", args) == 0) {\n\t\tipc.opt = IDLE_PROF_OPT_PERCPU;\n\t\treturn 0;\n\t} else {\n\t\tlog_err(\"fio: incorrect idle-prof option: %s\\n\", args);\n\t\treturn -1;\n\t}\t\n#else\n\tlog_err(\"fio: idle-prof not supported on this platform\\n\");\n\treturn -1;\n#endif\n}\n\nvoid show_idle_prof_stats(int output, struct json_object *parent,\n\t\t\t  struct buf_output *out)\n{\n\tint i, nr_cpus = ipc.nr_cpus;\n\tstruct json_object *tmp;\n\tchar s[MAX_CPU_STR_LEN];\n\n\tif (output == FIO_OUTPUT_NORMAL) {\n\t\tif (ipc.opt > IDLE_PROF_OPT_CALI)\n\t\t\tlog_buf(out, \"\\nCPU idleness:\\n\");\n\t\telse if (ipc.opt == IDLE_PROF_OPT_CALI)\n\t\t\tlog_buf(out, \"CPU idleness:\\n\");\n\n\t\tif (ipc.opt >= IDLE_PROF_OPT_SYSTEM)\n\t\t\tlog_buf(out, \"  system: %3.2f%%\\n\", fio_idle_prof_cpu_stat(-1));\n\n\t\tif (ipc.opt == IDLE_PROF_OPT_PERCPU) {\n\t\t\tlog_buf(out, \"  percpu: %3.2f%%\", fio_idle_prof_cpu_stat(0));\n\t\t\tfor (i = 1; i < nr_cpus; i++)\n\t\t\t\tlog_buf(out, \", %3.2f%%\", fio_idle_prof_cpu_stat(i));\n\t\t\tlog_buf(out, \"\\n\");\n\t\t}\n\n\t\tif (ipc.opt >= IDLE_PROF_OPT_CALI) {\n\t\t\tlog_buf(out, \"  unit work: mean=%3.2fus,\", ipc.cali_mean);\n\t\t\tlog_buf(out, \" stddev=%3.2f\\n\", ipc.cali_stddev);\n\t\t}\n\n\t\treturn;\n\t}\n\n\tif ((ipc.opt != IDLE_PROF_OPT_NONE) && (output & FIO_OUTPUT_JSON)) {\n\t\tif (!parent)\n\t\t\treturn;\n\n\t\ttmp = json_create_object();\n\t\tif (!tmp)\n\t\t\treturn;\n\n\t\tjson_object_add_value_object(parent, \"cpu_idleness\", tmp);\n\t\tjson_object_add_value_float(tmp, \"system\", fio_idle_prof_cpu_stat(-1));\n\n\t\tif (ipc.opt == IDLE_PROF_OPT_PERCPU) {\n\t\t\tfor (i = 0; i < nr_cpus; i++) {\n\t\t\t\tsnprintf(s, MAX_CPU_STR_LEN, \"cpu-%d\", i);\n\t\t\t\tjson_object_add_value_float(tmp, s, fio_idle_prof_cpu_stat(i));\n\t\t\t}\n\t\t}\n\n\t\tjson_object_add_value_float(tmp, \"unit_mean\", ipc.cali_mean);\n\t\tjson_object_add_value_float(tmp, \"unit_stddev\", ipc.cali_stddev);\n\t}\n}\n"
        },
        {
          "name": "idletime.h",
          "type": "blob",
          "size": 1.2919921875,
          "content": "#ifndef FIO_IDLETIME_H\n#define FIO_IDLETIME_H\n\n#include <sys/time.h>\n#include <sys/types.h>\n#include \"os/os.h\"\n\n#define CALIBRATE_RUNS  10\n#define CALIBRATE_SCALE 1000\n#define MAX_CPU_STR_LEN 32\n\nenum {\n\tIDLE_PROF_OPT_NONE,\n\tIDLE_PROF_OPT_CALI,                /* calibration only */\n\tIDLE_PROF_OPT_SYSTEM,\n\tIDLE_PROF_OPT_PERCPU\n};\n\nenum {\n\t IDLE_PROF_STATUS_OK,\n\t IDLE_PROF_STATUS_CALI_STOP,\n\t IDLE_PROF_STATUS_PROF_STOP,\n\t IDLE_PROF_STATUS_ABORT\n};\n\nstruct idle_prof_thread {\n\tpthread_t thread;\n\tint cpu;\n\tint state;\n\tstruct timespec tps;\n\tstruct timespec tpe;\n\tdouble cali_time; /* microseconds to finish a unit work */\n\tdouble loops;\n\tdouble idleness;\n\tunsigned char *data;             /* bytes to be touched */\n\tpthread_cond_t  cond;\n\tpthread_mutex_t init_lock;\n\tpthread_mutex_t start_lock;\n\n\tos_cpu_mask_t cpu_mask;\n};\n\nstruct idle_prof_common {\n\tstruct idle_prof_thread *ipts;\n\tint nr_cpus;\n\tint status;\n\tint opt;\n\tdouble cali_mean;\n\tdouble cali_stddev;\n\tvoid *buf;    /* single data allocation for all threads */\n};\n\nextern int fio_idle_prof_parse_opt(const char *);\n\nextern void fio_idle_prof_init(void);\nextern void fio_idle_prof_start(void);\nextern void fio_idle_prof_stop(void);\n\nextern void show_idle_prof_stats(int, struct json_object *, struct buf_output *);\n\nextern void fio_idle_prof_cleanup(void);\n\n#endif\n"
        },
        {
          "name": "init.c",
          "type": "blob",
          "size": 71.3544921875,
          "content": "/*\n * This file contains job initialization and setup functions.\n */\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <string.h>\n#include <errno.h>\n#include <sys/ipc.h>\n#include <sys/types.h>\n#include <dlfcn.h>\n#ifdef CONFIG_VALGRIND_DEV\n#include <valgrind/drd.h>\n#else\n#define DRD_IGNORE_VAR(x) do { } while (0)\n#endif\n\n#include \"fio.h\"\n#ifndef FIO_NO_HAVE_SHM_H\n#include <sys/shm.h>\n#endif\n\n#include \"parse.h\"\n#include \"smalloc.h\"\n#include \"filehash.h\"\n#include \"verify.h\"\n#include \"profile.h\"\n#include \"server.h\"\n#include \"idletime.h\"\n#include \"filelock.h\"\n#include \"steadystate.h\"\n#include \"blktrace.h\"\n\n#include \"oslib/asprintf.h\"\n#include \"oslib/getopt.h\"\n#include \"oslib/strcasestr.h\"\n\n#include \"crc/test.h\"\n#include \"lib/pow2.h\"\n#include \"lib/memcpy.h\"\n\nconst char fio_version_string[] = FIO_VERSION;\n\n#define FIO_RANDSEED\t\t(0xb1899bedUL)\n\nstatic char **ini_file;\nstatic bool dump_cmdline;\nstatic bool parse_only;\nstatic bool merge_blktrace_only;\n\nstatic struct thread_data def_thread;\nstruct thread_segment segments[REAL_MAX_SEG];\nstatic char **job_sections;\nstatic int nr_job_sections;\n\nbool exitall_on_terminate = false;\nint output_format = FIO_OUTPUT_NORMAL;\nint eta_print = FIO_ETA_AUTO;\nunsigned int eta_interval_msec = 1000;\nint eta_new_line = 0;\nFILE *f_out = NULL;\nFILE *f_err = NULL;\nchar *exec_profile = NULL;\nint warnings_fatal = 0;\nint terse_version = 3;\nbool is_backend = false;\nbool is_local_backend = false;\nint nr_clients = 0;\nbool log_syslog = false;\n\nbool write_bw_log = false;\nbool read_only = false;\nint status_interval = 0;\n\nchar *trigger_file = NULL;\nlong long trigger_timeout = 0;\nchar *trigger_cmd = NULL;\nchar *trigger_remote_cmd = NULL;\n\nchar *aux_path = NULL;\n\nstatic int prev_group_jobs;\n\nunsigned long fio_debug = 0;\nunsigned int fio_debug_jobno = -1;\nunsigned int *fio_debug_jobp = NULL;\nunsigned int *fio_warned = NULL;\n\nstatic char cmd_optstr[256];\nstatic bool did_arg;\n\n#define FIO_CLIENT_FLAG\t\t(1 << 16)\n\n/*\n * Command line options. These will contain the above, plus a few\n * extra that only pertain to fio itself and not jobs.\n */\nstatic struct option l_opts[FIO_NR_OPTIONS] = {\n\t{\n\t\t.name\t\t= (char *) \"output\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'o' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"latency-log\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'l' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"bandwidth-log\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'b' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"minimal\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'm' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"output-format\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'F' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"append-terse\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'f',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"version\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'v' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"help\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'h' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"cmdhelp\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'c' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"enghelp\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'i' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"showcmd\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 's' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"readonly\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'r' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"eta\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'e' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"eta-interval\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'O' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"eta-newline\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'E' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"debug\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'd' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"parse-only\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'P' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"section\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'x' | FIO_CLIENT_FLAG,\n\t},\n#ifdef CONFIG_ZLIB\n\t{\n\t\t.name\t\t= (char *) \"inflate-log\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'X' | FIO_CLIENT_FLAG,\n\t},\n#endif\n\t{\n\t\t.name\t\t= (char *) \"alloc-size\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'a' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"profile\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'p' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"warnings-fatal\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'w' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"max-jobs\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'j' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"terse-version\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'V' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"server\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'S',\n\t},\n#ifdef WIN32\n\t{\n\t\t.name\t\t= (char *) \"server-internal\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'N',\n\t},\n#endif\n\t{\t.name\t\t= (char *) \"daemonize\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'D',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"client\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'C',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"remote-config\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'R',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"cpuclock-test\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'T',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"crctest\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'G',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"memcpytest\",\n\t\t.has_arg\t= optional_argument,\n\t\t.val\t\t= 'M',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"idle-prof\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'I',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"status-interval\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'L' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= (char *) \"trigger-file\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'W',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"trigger-timeout\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'B',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"trigger\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'H',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"trigger-remote\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'J',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"aux-path\",\n\t\t.has_arg\t= required_argument,\n\t\t.val\t\t= 'K',\n\t},\n\t{\n\t\t.name\t\t= (char *) \"merge-blktrace-only\",\n\t\t.has_arg\t= no_argument,\n\t\t.val\t\t= 'A' | FIO_CLIENT_FLAG,\n\t},\n\t{\n\t\t.name\t\t= NULL,\n\t},\n};\n\nvoid free_threads_shm(void)\n{\n\tint i;\n\n\tfor (i = 0; i < nr_segments; i++) {\n\t\tstruct thread_segment *seg = &segments[i];\n\n\t\tif (seg->threads) {\n\t\t\tvoid *tp = seg->threads;\n#ifndef CONFIG_NO_SHM\n\t\t\tstruct shmid_ds sbuf;\n\n\t\t\tseg->threads = NULL;\n\t\t\tshmdt(tp);\n\t\t\tshmctl(seg->shm_id, IPC_RMID, &sbuf);\n\t\t\tseg->shm_id = -1;\n#else\n\t\t\tseg->threads = NULL;\n\t\t\tfree(tp);\n#endif\n\t\t}\n\t}\n\n\tnr_segments = 0;\n\tcur_segment = 0;\n}\n\nstatic void free_shm(void)\n{\n#ifndef FUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION\n\tif (nr_segments) {\n\t\tflow_exit();\n\t\tfio_debug_jobp = NULL;\n\t\tfio_warned = NULL;\n\t\tfree_threads_shm();\n\t}\n\n\tfree(trigger_file);\n\tfree(trigger_cmd);\n\tfree(trigger_remote_cmd);\n\ttrigger_file = trigger_cmd = trigger_remote_cmd = NULL;\n\n\toptions_free(fio_options, &def_thread.o);\n\tfio_filelock_exit();\n\tfile_hash_exit();\n\tscleanup();\n#endif\n}\n\nstatic int add_thread_segment(void)\n{\n\tstruct thread_segment *seg = &segments[nr_segments];\n\tsize_t size = JOBS_PER_SEG * sizeof(struct thread_data);\n\tint i;\n\n\tif (nr_segments + 1 >= REAL_MAX_SEG) {\n\t\tlog_err(\"error: maximum number of jobs reached.\\n\");\n\t\treturn -1;\n\t}\n\n\tsize += 2 * sizeof(unsigned int);\n\n#ifndef CONFIG_NO_SHM\n\tseg->shm_id = shmget(0, size, IPC_CREAT | 0600);\n\tif (seg->shm_id == -1) {\n\t\tif (errno != EINVAL && errno != ENOMEM && errno != ENOSPC)\n\t\t\tperror(\"shmget\");\n\t\treturn -1;\n\t}\n#else\n\tseg->threads = malloc(size);\n\tif (!seg->threads)\n\t\treturn -1;\n#endif\n\n#ifndef CONFIG_NO_SHM\n\tseg->threads = shmat(seg->shm_id, NULL, 0);\n\tif (seg->threads == (void *) -1) {\n\t\tperror(\"shmat\");\n\t\treturn 1;\n\t}\n\tif (shm_attach_to_open_removed())\n\t\tshmctl(seg->shm_id, IPC_RMID, NULL);\n#endif\n\n\tnr_segments++;\n\n\tmemset(seg->threads, 0, JOBS_PER_SEG * sizeof(struct thread_data));\n\tfor (i = 0; i < JOBS_PER_SEG; i++)\n\t\tDRD_IGNORE_VAR(seg->threads[i]);\n\tseg->nr_threads = 0;\n\n\t/* Not first segment, we're done */\n\tif (nr_segments != 1) {\n\t\tcur_segment++;\n\t\treturn 0;\n\t}\n\n\tfio_debug_jobp = (unsigned int *)(seg->threads + JOBS_PER_SEG);\n\t*fio_debug_jobp = -1;\n\tfio_warned = fio_debug_jobp + 1;\n\t*fio_warned = 0;\n\n\tflow_init();\n\treturn 0;\n}\n\n/*\n * The thread areas are shared between the main process and the job\n * threads/processes, and is split into chunks of JOBS_PER_SEG. If the current\n * segment has no more room, add a new chunk.\n */\nstatic int expand_thread_area(void)\n{\n\tstruct thread_segment *seg = &segments[cur_segment];\n\n\tif (nr_segments && seg->nr_threads < JOBS_PER_SEG)\n\t\treturn 0;\n\n\treturn add_thread_segment();\n}\n\nstatic void dump_print_option(struct print_option *p)\n{\n\tconst char *delim;\n\n\tif (!strcmp(\"description\", p->name))\n\t\tdelim = \"\\\"\";\n\telse\n\t\tdelim = \"\";\n\n\tlog_info(\"--%s%s\", p->name, p->value ? \"\" : \" \");\n\tif (p->value)\n\t\tlog_info(\"=%s%s%s \", delim, p->value, delim);\n}\n\nstatic void dump_opt_list(struct thread_data *td)\n{\n\tstruct flist_head *entry;\n\tstruct print_option *p;\n\n\tif (flist_empty(&td->opt_list))\n\t\treturn;\n\n\tflist_for_each(entry, &td->opt_list) {\n\t\tp = flist_entry(entry, struct print_option, list);\n\t\tdump_print_option(p);\n\t}\n}\n\nstatic void copy_opt_list(struct thread_data *dst, struct thread_data *src)\n{\n\tstruct flist_head *entry;\n\n\tif (flist_empty(&src->opt_list))\n\t\treturn;\n\n\tflist_for_each(entry, &src->opt_list) {\n\t\tstruct print_option *srcp, *dstp;\n\n\t\tsrcp = flist_entry(entry, struct print_option, list);\n\t\tdstp = malloc(sizeof(*dstp));\n\t\tdstp->name = strdup(srcp->name);\n\t\tif (srcp->value)\n\t\t\tdstp->value = strdup(srcp->value);\n\t\telse\n\t\t\tdstp->value = NULL;\n\t\tflist_add_tail(&dstp->list, &dst->opt_list);\n\t}\n}\n\n/*\n * Return a free job structure.\n */\nstatic struct thread_data *get_new_job(bool global, struct thread_data *parent,\n\t\t\t\t       bool preserve_eo, const char *jobname)\n{\n\tstruct thread_segment *seg;\n\tstruct thread_data *td;\n\n\tif (global)\n\t\treturn &def_thread;\n\tif (expand_thread_area()) {\n\t\tlog_err(\"error: failed to setup shm segment\\n\");\n\t\treturn NULL;\n\t}\n\n\tseg = &segments[cur_segment];\n\ttd = &seg->threads[seg->nr_threads++];\n\tthread_number++;\n\t*td = *parent;\n\n\tINIT_FLIST_HEAD(&td->opt_list);\n\tif (parent != &def_thread)\n\t\tcopy_opt_list(td, parent);\n\n\ttd->io_ops = NULL;\n\ttd->io_ops_init = 0;\n\tif (!preserve_eo)\n\t\ttd->eo = NULL;\n\n\ttd->o.uid = td->o.gid = -1U;\n\n\tdup_files(td, parent);\n\tfio_options_mem_dupe(td);\n\n\tprofile_add_hooks(td);\n\n\ttd->thread_number = thread_number;\n\ttd->subjob_number = 0;\n\n\tif (jobname)\n\t\ttd->o.name = strdup(jobname);\n\n\tif (!parent->o.group_reporting || parent == &def_thread)\n\t\tstat_number++;\n\n\treturn td;\n}\n\nstatic void put_job(struct thread_data *td)\n{\n\tif (td == &def_thread)\n\t\treturn;\n\n\tprofile_td_exit(td);\n\tflow_exit_job(td);\n\n\tif (td->error)\n\t\tlog_info(\"fio: %s\\n\", td->verror);\n\n\tfio_options_free(td);\n\tfio_dump_options_free(td);\n\tif (td->io_ops)\n\t\tfree_ioengine(td);\n\n\tif (td->o.name)\n\t\tfree(td->o.name);\n\n\tmemset(td, 0, sizeof(*td));\n\tsegments[cur_segment].nr_threads--;\n\tthread_number--;\n}\n\nstatic int __setup_rate(struct thread_data *td, enum fio_ddir ddir)\n{\n\tunsigned long long bs = td->o.min_bs[ddir];\n\n\tassert(ddir_rw(ddir));\n\n\tif (td->o.rate[ddir])\n\t\ttd->rate_bps[ddir] = td->o.rate[ddir];\n\telse\n\t\ttd->rate_bps[ddir] = (uint64_t) td->o.rate_iops[ddir] * bs;\n\n\tif (!td->rate_bps[ddir]) {\n\t\tlog_err(\"rate lower than supported\\n\");\n\t\treturn -1;\n\t}\n\n\ttd->rate_next_io_time[ddir] = 0;\n\ttd->rate_io_issue_bytes[ddir] = 0;\n\ttd->last_usec[ddir] = 0;\n\treturn 0;\n}\n\nstatic int setup_rate(struct thread_data *td)\n{\n\tint ret = 0;\n\n\tfor_each_rw_ddir(ddir) {\n\t\tif (td->o.rate[ddir] || td->o.rate_iops[ddir]) {\n\t\t\tret |= __setup_rate(td, ddir);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int fixed_block_size(struct thread_options *o)\n{\n\treturn o->min_bs[DDIR_READ] == o->max_bs[DDIR_READ] &&\n\t\to->min_bs[DDIR_WRITE] == o->max_bs[DDIR_WRITE] &&\n\t\to->min_bs[DDIR_TRIM] == o->max_bs[DDIR_TRIM] &&\n\t\to->min_bs[DDIR_READ] == o->min_bs[DDIR_WRITE] &&\n\t\to->min_bs[DDIR_READ] == o->min_bs[DDIR_TRIM];\n}\n\n/*\n * <3 Johannes\n */\nstatic unsigned int gcd(unsigned int m, unsigned int n)\n{\n\tif (!n)\n\t\treturn m;\n\n\treturn gcd(n, m % n);\n}\n\n/*\n * Lazy way of fixing up options that depend on each other. We could also\n * define option callback handlers, but this is easier.\n */\nstatic int fixup_options(struct thread_data *td)\n{\n\tstruct thread_options *o = &td->o;\n\tint ret = 0;\n\n\tif (read_only && (td_write(td) || td_trim(td))) {\n\t\tlog_err(\"fio: trim and write operations are not allowed\"\n\t\t\t \" with the --readonly parameter.\\n\");\n\t\tret |= 1;\n\t}\n\n\tif (td_trimwrite(td) && o->num_range > 1) {\n\t\tlog_err(\"fio: trimwrite cannot be used with multiple\"\n\t\t\t\" ranges.\\n\");\n\t\tret |= 1;\n\t}\n\n\tif (td_trim(td) && o->num_range > 1 &&\n\t    !td_ioengine_flagged(td, FIO_MULTI_RANGE_TRIM)) {\n\t\tlog_err(\"fio: can't use multiple ranges with IO engine %s\\n\",\n\t\t\ttd->io_ops->name);\n\t\tret |= 1;\n\t}\n\n#ifndef CONFIG_PSHARED\n\tif (!o->use_thread) {\n\t\tlog_info(\"fio: this platform does not support process shared\"\n\t\t\t \" mutexes, forcing use of threads. Use the 'thread'\"\n\t\t\t \" option to get rid of this warning.\\n\");\n\t\to->use_thread = 1;\n\t\tret |= warnings_fatal;\n\t}\n#endif\n\n\tif (o->write_iolog_file && o->read_iolog_file) {\n\t\tlog_err(\"fio: read iolog overrides write_iolog\\n\");\n\t\tfree(o->write_iolog_file);\n\t\to->write_iolog_file = NULL;\n\t\tret |= warnings_fatal;\n\t}\n\n\tif (o->zone_mode == ZONE_MODE_NONE && o->zone_size) {\n\t\tlog_err(\"fio: --zonemode=none and --zonesize are not compatible.\\n\");\n\t\tret |= 1;\n\t}\n\n\tif (o->zone_mode == ZONE_MODE_ZBD && !o->create_serialize) {\n\t\tlog_err(\"fio: --zonemode=zbd and --create_serialize=0 are not compatible.\\n\");\n\t\tret |= 1;\n\t}\n\n\tif (o->zone_mode == ZONE_MODE_STRIDED && !o->zone_size) {\n\t\tlog_err(\"fio: --zonesize must be specified when using --zonemode=strided.\\n\");\n\t\tret |= 1;\n\t}\n\n\tif (o->zone_mode == ZONE_MODE_NOT_SPECIFIED) {\n\t\tif (o->zone_size)\n\t\t\to->zone_mode = ZONE_MODE_STRIDED;\n\t\telse\n\t\t\to->zone_mode = ZONE_MODE_NONE;\n\t}\n\n\t/*\n\t * Strided zone mode only really works with 1 file.\n\t */\n\tif (o->zone_mode == ZONE_MODE_STRIDED && o->open_files > 1)\n\t\to->zone_mode = ZONE_MODE_NONE;\n\n\t/*\n\t * If zone_range isn't specified, backward compatibility dictates it\n\t * should be made equal to zone_size.\n\t */\n\tif (o->zone_mode == ZONE_MODE_STRIDED && !o->zone_range)\n\t\to->zone_range = o->zone_size;\n\n\t/*\n\t * Reads can do overwrites, we always need to pre-create the file\n\t */\n\tif (td_read(td))\n\t\to->overwrite = 1;\n\n\tfor_each_rw_ddir(ddir) {\n\t\tif (!o->min_bs[ddir])\n\t\t\to->min_bs[ddir] = o->bs[ddir];\n\t\tif (!o->max_bs[ddir])\n\t\t\to->max_bs[ddir] = o->bs[ddir];\n\t}\n\n\to->rw_min_bs = -1;\n\tfor_each_rw_ddir(ddir) {\n\t\to->rw_min_bs = min(o->rw_min_bs, o->min_bs[ddir]);\n\t}\n\n\t/*\n\t * For random IO, allow blockalign offset other than min_bs.\n\t */\n\tfor_each_rw_ddir(ddir) {\n\t\tif (!o->ba[ddir] || !td_random(td))\n\t\t\to->ba[ddir] = o->min_bs[ddir];\n\t}\n\n\tif ((o->ba[DDIR_READ] != o->min_bs[DDIR_READ] ||\n\t    o->ba[DDIR_WRITE] != o->min_bs[DDIR_WRITE] ||\n\t    o->ba[DDIR_TRIM] != o->min_bs[DDIR_TRIM]) &&\n\t    !o->norandommap) {\n\t\tlog_err(\"fio: Any use of blockalign= turns off randommap\\n\");\n\t\to->norandommap = 1;\n\t\tret |= warnings_fatal;\n\t}\n\n\tif (!o->file_size_high)\n\t\to->file_size_high = o->file_size_low;\n\n\tif (o->start_delay_high) {\n\t\tif (!o->start_delay_orig)\n\t\t\to->start_delay_orig = o->start_delay;\n\t\to->start_delay = rand_between(&td->delay_state,\n\t\t\t\t\t\to->start_delay_orig,\n\t\t\t\t\t\to->start_delay_high);\n\t}\n\n\tif (o->norandommap && o->verify != VERIFY_NONE\n\t    && !fixed_block_size(o))  {\n\t\tlog_err(\"fio: norandommap given for variable block sizes, \"\n\t\t\t\"verify limited\\n\");\n\t\tret |= warnings_fatal;\n\t}\n\tif (o->bs_unaligned && (o->odirect || td_ioengine_flagged(td, FIO_RAWIO)))\n\t\tlog_err(\"fio: bs_unaligned may not work with raw io\\n\");\n\n\t/*\n\t * thinktime_spin must be less than thinktime\n\t */\n\tif (o->thinktime_spin > o->thinktime)\n\t\to->thinktime_spin = o->thinktime;\n\n\t/*\n\t * The low water mark cannot be bigger than the iodepth\n\t */\n\tif (o->iodepth_low > o->iodepth || !o->iodepth_low)\n\t\to->iodepth_low = o->iodepth;\n\n\t/*\n\t * If batch number isn't set, default to the same as iodepth\n\t */\n\tif (o->iodepth_batch > o->iodepth || !o->iodepth_batch)\n\t\to->iodepth_batch = o->iodepth;\n\n\t/*\n\t * If max batch complete number isn't set or set incorrectly,\n\t * default to the same as iodepth_batch_complete_min\n\t */\n\tif (o->iodepth_batch_complete_min > o->iodepth_batch_complete_max)\n\t\to->iodepth_batch_complete_max = o->iodepth_batch_complete_min;\n\n\t/*\n\t * There's no need to check for in-flight overlapping IOs if the job\n\t * isn't changing data or the maximum iodepth is guaranteed to be 1\n\t * when we are not in offload mode\n\t */\n\tif (o->serialize_overlap && !(td->flags & TD_F_READ_IOLOG) &&\n\t    (!(td_write(td) || td_trim(td)) || o->iodepth == 1) &&\n\t    o->io_submit_mode != IO_MODE_OFFLOAD)\n\t\to->serialize_overlap = 0;\n\n\tif (o->nr_files > td->files_index)\n\t\to->nr_files = td->files_index;\n\n\tif (o->open_files > o->nr_files || !o->open_files)\n\t\to->open_files = o->nr_files;\n\n\tif (((o->rate[DDIR_READ] + o->rate[DDIR_WRITE] + o->rate[DDIR_TRIM]) &&\n\t    (o->rate_iops[DDIR_READ] + o->rate_iops[DDIR_WRITE] + o->rate_iops[DDIR_TRIM])) ||\n\t    ((o->ratemin[DDIR_READ] + o->ratemin[DDIR_WRITE] + o->ratemin[DDIR_TRIM]) &&\n\t    (o->rate_iops_min[DDIR_READ] + o->rate_iops_min[DDIR_WRITE] + o->rate_iops_min[DDIR_TRIM]))) {\n\t\tlog_err(\"fio: rate and rate_iops are mutually exclusive\\n\");\n\t\tret |= 1;\n\t}\n\tfor_each_rw_ddir(ddir) {\n\t\tif ((o->rate[ddir] && (o->rate[ddir] < o->ratemin[ddir])) ||\n\t\t    (o->rate_iops[ddir] && (o->rate_iops[ddir] < o->rate_iops_min[ddir]))) {\n\t\t\tlog_err(\"fio: minimum rate exceeds rate, ddir %d\\n\", +ddir);\n\t\t\tret |= 1;\n\t\t}\n\t}\n\n\tif (!o->timeout && o->time_based) {\n\t\tlog_err(\"fio: time_based requires a runtime/timeout setting\\n\");\n\t\to->time_based = 0;\n\t\tret |= warnings_fatal;\n\t}\n\n\tif (o->fill_device && !o->size)\n\t\to->size = -1ULL;\n\n\tif (o->verify != VERIFY_NONE) {\n\t\tif (td_write(td) && o->do_verify && o->numjobs > 1 &&\n\t\t    (o->filename ||\n\t\t     !(o->unique_filename &&\n\t\t       strstr(o->filename_format, \"$jobname\") &&\n\t\t       strstr(o->filename_format, \"$jobnum\") &&\n\t\t       strstr(o->filename_format, \"$filenum\")))) {\n\t\t\tlog_info(\"fio: multiple writers may overwrite blocks \"\n\t\t\t\t\"that belong to other jobs. This can cause \"\n\t\t\t\t\"verification failures.\\n\");\n\t\t\tret |= warnings_fatal;\n\t\t}\n\n\t\t/*\n\t\t * Warn if verification is requested but no verification of any\n\t\t * kind can be started due to time constraints\n\t\t */\n\t\tif (td_write(td) && o->do_verify && o->timeout &&\n\t\t    o->time_based && !td_read(td) && !o->verify_backlog) {\n\t\t\tlog_info(\"fio: verification read phase will never \"\n\t\t\t\t \"start because write phase uses all of \"\n\t\t\t\t \"runtime\\n\");\n\t\t\tret |= warnings_fatal;\n\t\t}\n\n\t\tif (!fio_option_is_set(o, refill_buffers))\n\t\t\to->refill_buffers = 1;\n\n\t\tif (o->max_bs[DDIR_WRITE] != o->min_bs[DDIR_WRITE] &&\n\t\t    !o->verify_interval)\n\t\t\to->verify_interval = o->min_bs[DDIR_WRITE];\n\n\t\t/*\n\t\t * Verify interval must be smaller or equal to the\n\t\t * write size.\n\t\t */\n\t\tif (o->verify_interval > o->min_bs[DDIR_WRITE])\n\t\t\to->verify_interval = o->min_bs[DDIR_WRITE];\n\t\telse if (td_read(td) && o->verify_interval > o->min_bs[DDIR_READ])\n\t\t\to->verify_interval = o->min_bs[DDIR_READ];\n\n\t\t/*\n\t\t * Verify interval must be a factor of both min and max\n\t\t * write size\n\t\t */\n\t\tif (!o->verify_interval ||\n\t\t    (o->min_bs[DDIR_WRITE] % o->verify_interval) ||\n\t\t    (o->max_bs[DDIR_WRITE] % o->verify_interval))\n\t\t\to->verify_interval = gcd(o->min_bs[DDIR_WRITE],\n\t\t\t\t\t\t\to->max_bs[DDIR_WRITE]);\n\n\t\tif (td->o.verify_only)\n\t\t\to->verify_write_sequence = 0;\n\t}\n\n\tif (td->o.oatomic) {\n\t\tif (!td_ioengine_flagged(td, FIO_ATOMICWRITES)) {\n\t\t\tlog_err(\"fio: engine does not support atomic writes\\n\");\n\t\t\ttd->o.oatomic = 0;\n\t\t\tret |= 1;\n\t\t}\n\n\t\tif (!td_write(td))\n\t\t\ttd->o.oatomic = 0;\n\t}\n\n\tif (o->pre_read) {\n\t\tif (o->invalidate_cache)\n\t\t\to->invalidate_cache = 0;\n\t\tif (td_ioengine_flagged(td, FIO_PIPEIO)) {\n\t\t\tlog_info(\"fio: cannot pre-read files with an IO engine\"\n\t\t\t\t \" that isn't seekable. Pre-read disabled.\\n\");\n\t\t\tret |= warnings_fatal;\n\t\t}\n\t}\n\n\tif (o->unit_base == N2S_NONE) {\n\t\tif (td_ioengine_flagged(td, FIO_BIT_BASED))\n\t\t\to->unit_base = N2S_BITPERSEC;\n\t\telse\n\t\t\to->unit_base = N2S_BYTEPERSEC;\n\t}\n\n#ifndef CONFIG_FDATASYNC\n\tif (o->fdatasync_blocks) {\n\t\tlog_info(\"fio: this platform does not support fdatasync()\"\n\t\t\t \" falling back to using fsync().  Use the 'fsync'\"\n\t\t\t \" option instead of 'fdatasync' to get rid of\"\n\t\t\t \" this warning\\n\");\n\t\to->fsync_blocks = o->fdatasync_blocks;\n\t\to->fdatasync_blocks = 0;\n\t\tret |= warnings_fatal;\n\t}\n#endif\n\n#ifdef WIN32\n\t/*\n\t * Windows doesn't support O_DIRECT or O_SYNC with the _open interface,\n\t * so fail if we're passed those flags\n\t */\n\tif (td_ioengine_flagged(td, FIO_SYNCIO) && (o->odirect || o->sync_io)) {\n\t\tlog_err(\"fio: Windows does not support direct or non-buffered io with\"\n\t\t\t\t\" the synchronous ioengines. Use the 'windowsaio' ioengine\"\n\t\t\t\t\" with 'direct=1' and 'iodepth=1' instead.\\n\");\n\t\tret |= 1;\n\t}\n#endif\n\n\t/*\n\t * For fully compressible data, just zero them at init time.\n\t * It's faster than repeatedly filling it. For non-zero\n\t * compression, we should have refill_buffers set. Set it, unless\n\t * the job file already changed it.\n\t */\n\tif (o->compress_percentage) {\n\t\tif (o->compress_percentage == 100) {\n\t\t\to->zero_buffers = 1;\n\t\t\to->compress_percentage = 0;\n\t\t} else if (!fio_option_is_set(o, refill_buffers)) {\n\t\t\to->refill_buffers = 1;\n\t\t\ttd->flags |= TD_F_REFILL_BUFFERS;\n\t\t}\n\t}\n\n\t/*\n\t * Using a non-uniform random distribution excludes usage of\n\t * a random map\n\t */\n\tif (o->random_distribution != FIO_RAND_DIST_RANDOM)\n\t\to->norandommap = 1;\n\n\t/*\n\t * If size is set but less than the min block size, complain\n\t */\n\tif (o->size && o->size < td_min_bs(td)) {\n\t\tlog_err(\"fio: size too small, must not be less than minimum block size: %llu < %llu\\n\",\n\t\t\t(unsigned long long) o->size, td_min_bs(td));\n\t\tret |= 1;\n\t}\n\n\t/*\n\t * If randseed is set, that overrides randrepeat\n\t */\n\tif (fio_option_is_set(o, rand_seed))\n\t\to->rand_repeatable = 0;\n\n\tif (td_ioengine_flagged(td, FIO_NOEXTEND) && o->file_append) {\n\t\tlog_err(\"fio: can't append/extent with IO engine %s\\n\", td->io_ops->name);\n\t\tret |= 1;\n\t}\n\n\tif (fio_option_is_set(o, gtod_cpu)) {\n\t\tfio_gtod_init();\n\t\tfio_gtod_set_cpu(o->gtod_cpu);\n\t\tfio_gtod_offload = 1;\n\t}\n\n\ttd->loops = o->loops;\n\tif (!td->loops)\n\t\ttd->loops = 1;\n\n\tif (o->block_error_hist && o->nr_files != 1) {\n\t\tlog_err(\"fio: block error histogram only available \"\n\t\t\t\"with a single file per job, but %d files \"\n\t\t\t\"provided\\n\", o->nr_files);\n\t\tret |= 1;\n\t}\n\n\tif (o->disable_lat)\n\t\to->lat_percentiles = 0;\n\tif (o->disable_clat)\n\t\to->clat_percentiles = 0;\n\tif (o->disable_slat)\n\t\to->slat_percentiles = 0;\n\n\t/* Do this only for the parent job */\n\tif (!td->subjob_number) {\n\t\t/*\n\t\t * Fix these up to be nsec internally\n\t\t */\n\t\tfor_each_rw_ddir(ddir)\n\t\t\to->max_latency[ddir] *= 1000ULL;\n\n\t\to->latency_target *= 1000ULL;\n\t}\n\n\t/*\n\t * Dedupe working set verifications\n\t */\n\tif (o->dedupe_percentage && o->dedupe_mode == DEDUPE_MODE_WORKING_SET) {\n\t\tif (!fio_option_is_set(o, size)) {\n\t\t\tlog_err(\"fio: pregenerated dedupe working set \"\n\t\t\t\t\t\"requires size to be set\\n\");\n\t\t\tret |= 1;\n\t\t} else if (o->nr_files != 1) {\n\t\t\tlog_err(\"fio: dedupe working set mode supported with \"\n\t\t\t\t\t\"single file per job, but %d files \"\n\t\t\t\t\t\"provided\\n\", o->nr_files);\n\t\t\tret |= 1;\n\t\t} else if (o->dedupe_working_set_percentage + o->dedupe_percentage > 100) {\n\t\t\tlog_err(\"fio: impossible to reach expected dedupe percentage %u \"\n\t\t\t\t\t\"since %u percentage of size is reserved to dedupe working set \"\n\t\t\t\t\t\"(those are unique pages)\\n\",\n\t\t\t\t\to->dedupe_percentage, o->dedupe_working_set_percentage);\n\t\t\tret |= 1;\n\t\t}\n\t}\n\n\tfor_each_td(td2) {\n\t\tif (td->o.ss_check_interval != td2->o.ss_check_interval) {\n\t\t\tlog_err(\"fio: conflicting ss_check_interval: %llu and %llu, must be globally equal\\n\",\n\t\t\t\t\ttd->o.ss_check_interval, td2->o.ss_check_interval);\n\t\t\tret |= 1;\n\t\t}\n\t} end_for_each();\n\tif (td->o.ss_dur && td->o.ss_check_interval / 1000L < 1000) {\n\t\tlog_err(\"fio: ss_check_interval must be at least 1s\\n\");\n\t\tret |= 1;\n\n\t}\n\tif (td->o.ss_dur && (td->o.ss_dur % td->o.ss_check_interval != 0 || td->o.ss_dur <= td->o.ss_check_interval)) {\n\t\tlog_err(\"fio: ss_duration %lluus must be multiple of ss_check_interval %lluus\\n\",\n\t\t\t\ttd->o.ss_dur, td->o.ss_check_interval);\n\t\tret |= 1;\n\t}\n\n\tif (td->o.fdp) {\n\t\tif (fio_option_is_set(&td->o, dp_type) &&\n\t\t\t(td->o.dp_type == FIO_DP_STREAMS || td->o.dp_type == FIO_DP_NONE)) {\n\t\t\tlog_err(\"fio: fdp=1 is not compatible with dataplacement={streams, none}\\n\");\n\t\t\tret |= 1;\n\t\t} else {\n\t\t\ttd->o.dp_type = FIO_DP_FDP;\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic void init_rand_file_service(struct thread_data *td)\n{\n\tunsigned long nranges = td->o.nr_files << FIO_FSERVICE_SHIFT;\n\tconst unsigned int seed = td->rand_seeds[FIO_RAND_FILE_OFF];\n\n\tif (td->o.file_service_type == FIO_FSERVICE_ZIPF) {\n\t\tzipf_init(&td->next_file_zipf, nranges, td->zipf_theta, td->random_center, seed);\n\t\tzipf_disable_hash(&td->next_file_zipf);\n\t} else if (td->o.file_service_type == FIO_FSERVICE_PARETO) {\n\t\tpareto_init(&td->next_file_zipf, nranges, td->pareto_h, td->random_center, seed);\n\t\tzipf_disable_hash(&td->next_file_zipf);\n\t} else if (td->o.file_service_type == FIO_FSERVICE_GAUSS) {\n\t\tgauss_init(&td->next_file_gauss, nranges, td->gauss_dev, td->random_center, seed);\n\t\tgauss_disable_hash(&td->next_file_gauss);\n\t}\n}\n\nvoid td_fill_rand_seeds(struct thread_data *td)\n{\n\tuint64_t read_seed = td->rand_seeds[FIO_RAND_BS_OFF];\n\tuint64_t write_seed = td->rand_seeds[FIO_RAND_BS1_OFF];\n\tuint64_t trim_seed = td->rand_seeds[FIO_RAND_BS2_OFF];\n\tint i;\n\tbool use64;\n\n\tif (td->o.random_generator == FIO_RAND_GEN_TAUSWORTHE64)\n\t\tuse64 = true;\n\telse\n\t\tuse64 = false;\n\n\t/*\n\t * trimwrite is special in that we need to generate the same\n\t * offsets to get the \"write after trim\" effect. If we are\n\t * using bssplit to set buffer length distributions, ensure that\n\t * we seed the trim and write generators identically. Ditto for\n\t * verify, read and writes must have the same seed, if we are doing\n\t * read verify.\n\t */\n\tif (td->o.verify != VERIFY_NONE)\n\t\twrite_seed = read_seed;\n\tif (td_trimwrite(td))\n\t\ttrim_seed = write_seed;\n\tinit_rand_seed(&td->bsrange_state[DDIR_READ], read_seed, use64);\n\tinit_rand_seed(&td->bsrange_state[DDIR_WRITE], write_seed, use64);\n\tinit_rand_seed(&td->bsrange_state[DDIR_TRIM], trim_seed, use64);\n\n\tinit_rand_seed(&td->verify_state, td->rand_seeds[FIO_RAND_VER_OFF],\n\t\tuse64);\n\tinit_rand_seed(&td->rwmix_state, td->rand_seeds[FIO_RAND_MIX_OFF], false);\n\n\tif (td->o.file_service_type == FIO_FSERVICE_RANDOM)\n\t\tinit_rand_seed(&td->next_file_state, td->rand_seeds[FIO_RAND_FILE_OFF], use64);\n\telse if (td->o.file_service_type & __FIO_FSERVICE_NONUNIFORM)\n\t\tinit_rand_file_service(td);\n\n\tinit_rand_seed(&td->file_size_state, td->rand_seeds[FIO_RAND_FILE_SIZE_OFF], use64);\n\tinit_rand_seed(&td->trim_state, td->rand_seeds[FIO_RAND_TRIM_OFF], use64);\n\tinit_rand_seed(&td->delay_state, td->rand_seeds[FIO_RAND_START_DELAY], use64);\n\tinit_rand_seed(&td->poisson_state[0], td->rand_seeds[FIO_RAND_POISSON_OFF], 0);\n\tinit_rand_seed(&td->poisson_state[1], td->rand_seeds[FIO_RAND_POISSON2_OFF], 0);\n\tinit_rand_seed(&td->poisson_state[2], td->rand_seeds[FIO_RAND_POISSON3_OFF], 0);\n\tinit_rand_seed(&td->dedupe_state, td->rand_seeds[FIO_DEDUPE_OFF], false);\n\tinit_rand_seed(&td->zone_state, td->rand_seeds[FIO_RAND_ZONE_OFF], false);\n\tinit_rand_seed(&td->prio_state, td->rand_seeds[FIO_RAND_PRIO_CMDS], false);\n\tinit_rand_seed(&td->dedupe_working_set_index_state, td->rand_seeds[FIO_RAND_DEDUPE_WORKING_SET_IX], use64);\n\n\tinit_rand_seed(&td->random_state, td->rand_seeds[FIO_RAND_BLOCK_OFF], use64);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tstruct frand_state *s = &td->seq_rand_state[i];\n\n\t\tinit_rand_seed(s, td->rand_seeds[FIO_RAND_SEQ_RAND_READ_OFF], false);\n\t}\n\n\tinit_rand_seed(&td->buf_state, td->rand_seeds[FIO_RAND_BUF_OFF], use64);\n\tfrand_copy(&td->buf_state_prev, &td->buf_state);\n\n\tinit_rand_seed(&td->fdp_state, td->rand_seeds[FIO_RAND_FDP_OFF], use64);\n}\n\nstatic int setup_random_seeds(struct thread_data *td)\n{\n\tuint64_t seed;\n\tunsigned int i;\n\n\tif (!td->o.rand_repeatable && !fio_option_is_set(&td->o, rand_seed)) {\n\t\tint ret = init_random_seeds(td->rand_seeds, sizeof(td->rand_seeds));\n\t\tdprint(FD_RANDOM, \"using system RNG for random seeds\\n\");\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tseed = td->o.rand_seed;\n\t\tfor (i = 0; i < 4; i++)\n\t\t\tseed *= 0x9e370001UL;\n\n\t\tfor (i = 0; i < FIO_RAND_NR_OFFS; i++) {\n\t\t\ttd->rand_seeds[i] = seed * td->thread_number + i;\n\t\t\tseed *= 0x9e370001UL;\n\t\t}\n\t}\n\n\ttd_fill_rand_seeds(td);\n\n\tdprint(FD_RANDOM, \"FIO_RAND_NR_OFFS=%d\\n\", FIO_RAND_NR_OFFS);\n\tfor (int i = 0; i < FIO_RAND_NR_OFFS; i++)\n\t\tdprint(FD_RANDOM, \"rand_seeds[%d]=%\" PRIu64 \"\\n\", i, td->rand_seeds[i]);\n\n\treturn 0;\n}\n\n/*\n * Initializes the ioengine configured for a job, if it has not been done so\n * already.\n */\nint ioengine_load(struct thread_data *td)\n{\n\tif (!td->o.ioengine) {\n\t\tlog_err(\"fio: internal fault, no IO engine specified\\n\");\n\t\treturn 1;\n\t}\n\n\tif (td->io_ops) {\n\t\tstruct ioengine_ops *ops;\n\t\tvoid *dlhandle;\n\n\t\t/* An engine is loaded, but the requested ioengine\n\t\t * may have changed.\n\t\t */\n\t\tif (!strcmp(td->io_ops->name, td->o.ioengine)) {\n\t\t\t/* The right engine is already loaded */\n\t\t\treturn 0;\n\t\t}\n\n\t\t/*\n\t\t * Name of file and engine may be different, load ops\n\t\t * for this name and see if they match. If they do, then\n\t\t * the engine is unchanged.\n\t\t */\n\t\tdlhandle = td->io_ops->dlhandle;\n\t\tops = load_ioengine(td);\n\t\tif (!ops)\n\t\t\tgoto fail;\n\n\t\tif (ops == td->io_ops && dlhandle == td->io_ops->dlhandle)\n\t\t\treturn 0;\n\n\t\tif (dlhandle && dlhandle != td->io_ops->dlhandle)\n\t\t\tdlclose(dlhandle);\n\n\t\t/* Unload the old engine. */\n\t\tfree_ioengine(td);\n\t}\n\n\ttd->io_ops = load_ioengine(td);\n\tif (!td->io_ops)\n\t\tgoto fail;\n\n\tif (td->io_ops->option_struct_size && td->io_ops->options) {\n\t\t/*\n\t\t * In cases where td->eo is set, clone it for a child thread.\n\t\t * This requires that the parent thread has the same ioengine,\n\t\t * but that requirement must be enforced by the code which\n\t\t * cloned the thread.\n\t\t */\n\t\tvoid *origeo = td->eo;\n\t\t/*\n\t\t * Otherwise use the default thread options.\n\t\t */\n\t\tif (!origeo && td != &def_thread && def_thread.eo &&\n\t\t    def_thread.io_ops->options == td->io_ops->options)\n\t\t\torigeo = def_thread.eo;\n\n\t\toptions_init(td->io_ops->options);\n\t\ttd->eo = malloc(td->io_ops->option_struct_size);\n\t\t/*\n\t\t * Use the default thread as an option template if this uses the\n\t\t * same options structure and there are non-default options\n\t\t * used.\n\t\t */\n\t\tif (origeo) {\n\t\t\tmemcpy(td->eo, origeo, td->io_ops->option_struct_size);\n\t\t\toptions_mem_dupe(td->io_ops->options, td->eo);\n\t\t} else {\n\t\t\tmemset(td->eo, 0, td->io_ops->option_struct_size);\n\t\t\tfill_default_options(td->eo, td->io_ops->options);\n\t\t}\n\t\t*(struct thread_data **)td->eo = td;\n\t}\n\n\tif (td->o.odirect)\n\t\ttd->io_ops->flags |= FIO_RAWIO;\n\n\ttd_set_ioengine_flags(td);\n\treturn 0;\n\nfail:\n\tlog_err(\"fio: failed to load engine\\n\");\n\treturn 1;\n\n}\n\nstatic void init_flags(struct thread_data *td)\n{\n\tstruct thread_options *o = &td->o;\n\tint i;\n\n\tif (o->verify_backlog)\n\t\ttd->flags |= TD_F_VER_BACKLOG;\n\tif (o->trim_backlog)\n\t\ttd->flags |= TD_F_TRIM_BACKLOG;\n\tif (o->read_iolog_file)\n\t\ttd->flags |= TD_F_READ_IOLOG;\n\tif (o->refill_buffers)\n\t\ttd->flags |= TD_F_REFILL_BUFFERS;\n\t/*\n\t * Always scramble buffers if asked to\n\t */\n\tif (o->scramble_buffers && fio_option_is_set(o, scramble_buffers))\n\t\ttd->flags |= TD_F_SCRAMBLE_BUFFERS;\n\t/*\n\t * But also scramble buffers, unless we were explicitly asked\n\t * to zero them.\n\t */\n\tif (o->scramble_buffers && !(o->zero_buffers &&\n\t    fio_option_is_set(o, zero_buffers)))\n\t\ttd->flags |= TD_F_SCRAMBLE_BUFFERS;\n\tif (o->verify != VERIFY_NONE)\n\t\ttd->flags |= TD_F_DO_VERIFY;\n\n\tif (o->verify_async || o->io_submit_mode == IO_MODE_OFFLOAD)\n\t\ttd->flags |= TD_F_NEED_LOCK;\n\n\tif (o->mem_type == MEM_CUDA_MALLOC)\n\t\ttd->flags &= ~TD_F_SCRAMBLE_BUFFERS;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (option_check_rate(td, i)) {\n\t\t\ttd->flags |= TD_F_CHECK_RATE;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nenum {\n\tFPRE_NONE = 0,\n\tFPRE_JOBNAME,\n\tFPRE_JOBNUM,\n\tFPRE_FILENUM,\n\tFPRE_CLIENTUID\n};\n\nstatic struct fpre_keyword {\n\tconst char *keyword;\n\tsize_t strlen;\n\tint key;\n} fpre_keywords[] = {\n\t{ .keyword = \"$jobname\",\t.key = FPRE_JOBNAME, },\n\t{ .keyword = \"$jobnum\",\t\t.key = FPRE_JOBNUM, },\n\t{ .keyword = \"$filenum\",\t.key = FPRE_FILENUM, },\n\t{ .keyword = \"$clientuid\",\t.key = FPRE_CLIENTUID, },\n\t{ .keyword = NULL, },\n\t};\n\nstatic char *make_filename(char *buf, size_t buf_size,struct thread_options *o,\n\t\t\t   const char *jobname, int jobnum, int filenum)\n{\n\tstruct fpre_keyword *f;\n\tchar copy[PATH_MAX];\n\tsize_t dst_left = PATH_MAX - 1;\n\n\tif (!o->filename_format || !strlen(o->filename_format)) {\n\t\tsprintf(buf, \"%s.%d.%d\", jobname, jobnum, filenum);\n\t\treturn buf;\n\t}\n\n\tfor (f = &fpre_keywords[0]; f->keyword; f++)\n\t\tf->strlen = strlen(f->keyword);\n\n\tsnprintf(buf, buf_size, \"%s\", o->filename_format);\n\n\tmemset(copy, 0, sizeof(copy));\n\tfor (f = &fpre_keywords[0]; f->keyword; f++) {\n\t\tdo {\n\t\t\tsize_t pre_len, post_start = 0;\n\t\t\tchar *str, *dst = copy;\n\n\t\t\tstr = strcasestr(buf, f->keyword);\n\t\t\tif (!str)\n\t\t\t\tbreak;\n\n\t\t\tpre_len = str - buf;\n\t\t\tif (strlen(str) != f->strlen)\n\t\t\t\tpost_start = pre_len + f->strlen;\n\n\t\t\tif (pre_len) {\n\t\t\t\tstrncpy(dst, buf, pre_len);\n\t\t\t\tdst += pre_len;\n\t\t\t\tdst_left -= pre_len;\n\t\t\t}\n\n\t\t\tswitch (f->key) {\n\t\t\tcase FPRE_JOBNAME: {\n\t\t\t\tint ret;\n\n\t\t\t\tret = snprintf(dst, dst_left, \"%s\", jobname);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tbreak;\n\t\t\t\telse if (ret > dst_left) {\n\t\t\t\t\tlog_err(\"fio: truncated filename\\n\");\n\t\t\t\t\tdst += dst_left;\n\t\t\t\t\tdst_left = 0;\n\t\t\t\t} else {\n\t\t\t\t\tdst += ret;\n\t\t\t\t\tdst_left -= ret;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase FPRE_JOBNUM: {\n\t\t\t\tint ret;\n\n\t\t\t\tret = snprintf(dst, dst_left, \"%d\", jobnum);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tbreak;\n\t\t\t\telse if (ret > dst_left) {\n\t\t\t\t\tlog_err(\"fio: truncated filename\\n\");\n\t\t\t\t\tdst += dst_left;\n\t\t\t\t\tdst_left = 0;\n\t\t\t\t} else {\n\t\t\t\t\tdst += ret;\n\t\t\t\t\tdst_left -= ret;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase FPRE_FILENUM: {\n\t\t\t\tint ret;\n\n\t\t\t\tret = snprintf(dst, dst_left, \"%d\", filenum);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tbreak;\n\t\t\t\telse if (ret > dst_left) {\n\t\t\t\t\tlog_err(\"fio: truncated filename\\n\");\n\t\t\t\t\tdst += dst_left;\n\t\t\t\t\tdst_left = 0;\n\t\t\t\t} else {\n\t\t\t\t\tdst += ret;\n\t\t\t\t\tdst_left -= ret;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase FPRE_CLIENTUID: {\n\t\t\t\tint ret;\n\t\t\t\tret = snprintf(dst, dst_left, \"%s\", client_sockaddr_str);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tbreak;\n\t\t\t\telse if (ret > dst_left) {\n\t\t\t\t\tlog_err(\"fio: truncated filename\\n\");\n\t\t\t\t\tdst += dst_left;\n\t\t\t\t\tdst_left = 0;\n\t\t\t\t} else {\n\t\t\t\t\tdst += ret;\n\t\t\t\t\tdst_left -= ret;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tassert(0);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (post_start)\n\t\t\t\tstrncpy(dst, buf + post_start, dst_left);\n\n\t\t\tsnprintf(buf, buf_size, \"%s\", copy);\n\t\t} while (1);\n\t}\n\n\treturn buf;\n}\n\nbool parse_dryrun(void)\n{\n\treturn dump_cmdline || parse_only;\n}\n\nstatic void gen_log_name(char *name, size_t size, const char *logtype,\n\t\t\t const char *logname, unsigned int num,\n\t\t\t const char *suf, int per_job)\n{\n\tif (per_job)\n\t\tsnprintf(name, size, \"%s_%s.%d.%s\", logname, logtype, num, suf);\n\telse\n\t\tsnprintf(name, size, \"%s_%s.%s\", logname, logtype, suf);\n}\n\nstatic int check_waitees(char *waitee)\n{\n\tint ret = 0;\n\n\tfor_each_td(td) {\n\t\tif (td->subjob_number)\n\t\t\tcontinue;\n\n\t\tret += !strcmp(td->o.name, waitee);\n\t} end_for_each();\n\n\treturn ret;\n}\n\nstatic bool wait_for_ok(const char *jobname, struct thread_options *o)\n{\n\tint nw;\n\n\tif (!o->wait_for)\n\t\treturn true;\n\n\tif (!strcmp(jobname, o->wait_for)) {\n\t\tlog_err(\"%s: a job cannot wait for itself (wait_for=%s).\\n\",\n\t\t\t\tjobname, o->wait_for);\n\t\treturn false;\n\t}\n\n\tif (!(nw = check_waitees(o->wait_for))) {\n\t\tlog_err(\"%s: waitee job %s unknown.\\n\", jobname, o->wait_for);\n\t\treturn false;\n\t}\n\n\tif (nw > 1) {\n\t\tlog_err(\"%s: multiple waitees %s found,\\n\"\n\t\t\t\"please avoid duplicates when using wait_for option.\\n\",\n\t\t\t\tjobname, o->wait_for);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int verify_per_group_options(struct thread_data *td, const char *jobname)\n{\n\tfor_each_td(td2) {\n\t\tif (td->groupid != td2->groupid)\n\t\t\tcontinue;\n\n\t\tif (td->o.stats &&\n\t\t    td->o.lat_percentiles != td2->o.lat_percentiles) {\n\t\t\tlog_err(\"fio: lat_percentiles in job: %s differs from group\\n\",\n\t\t\t\tjobname);\n\t\t\treturn 1;\n\t\t}\n\t} end_for_each();\n\n\treturn 0;\n}\n\n/*\n * Treat an empty log file name the same as a one not given\n */\nstatic const char *make_log_name(const char *logname, const char *jobname)\n{\n\tif (logname && strcmp(logname, \"\"))\n\t\treturn logname;\n\n\treturn jobname;\n}\n\n/*\n * Adds a job to the list of things todo. Sanitizes the various options\n * to make sure we don't have conflicts, and initializes various\n * members of td.\n */\nstatic int add_job(struct thread_data *td, const char *jobname, int job_add_num,\n\t\t   int recursed, int client_type)\n{\n\tunsigned int i;\n\tchar fname[PATH_MAX + 1];\n\tint numjobs, file_alloced;\n\tstruct thread_options *o = &td->o;\n\tchar logname[PATH_MAX + 32];\n\n\t/*\n\t * the def_thread is just for options, it's not a real job\n\t */\n\tif (td == &def_thread)\n\t\treturn 0;\n\n\tinit_flags(td);\n\n\t/*\n\t * if we are just dumping the output command line, don't add the job\n\t */\n\tif (parse_dryrun()) {\n\t\tput_job(td);\n\t\treturn 0;\n\t}\n\n\ttd->client_type = client_type;\n\n\tif (profile_td_init(td))\n\t\tgoto err;\n\n\tif (ioengine_load(td))\n\t\tgoto err;\n\n\tfile_alloced = 0;\n\tif (!o->filename && !td->files_index && !o->read_iolog_file) {\n\t\tfile_alloced = 1;\n\n\t\tif (o->nr_files == 1 && exists_and_not_regfile(jobname))\n\t\t\tadd_file(td, jobname, job_add_num, 0);\n\t\telse {\n\t\t\tfor (i = 0; i < o->nr_files; i++)\n\t\t\t\tadd_file(td, make_filename(fname, sizeof(fname), o, jobname, job_add_num, i), job_add_num, 0);\n\t\t}\n\t}\n\n\tif (setup_random_seeds(td)) {\n\t\ttd_verror(td, errno, \"setup_random_seeds\");\n\t\tgoto err;\n\t}\n\n\tif (fixup_options(td))\n\t\tgoto err;\n\n\tif (!td->o.dedupe_global && init_dedupe_working_set_seeds(td, 0))\n\t\tgoto err;\n\n\t/*\n\t * Belongs to fixup_options, but o->name is not necessarily set as yet\n\t */\n\tif (!wait_for_ok(jobname, o))\n\t\tgoto err;\n\n\tflow_init_job(td);\n\n\t/*\n\t * IO engines only need this for option callbacks, and the address may\n\t * change in subprocesses.\n\t */\n\tif (td->eo)\n\t\t*(struct thread_data **)td->eo = NULL;\n\n\tif (td_ioengine_flagged(td, FIO_DISKLESSIO)) {\n\t\tstruct fio_file *f;\n\n\t\tfor_each_file(td, f, i)\n\t\t\tf->real_file_size = -1ULL;\n\t}\n\n\ttd->sem = fio_sem_init(FIO_SEM_LOCKED);\n\n\ttd->ts.clat_percentiles = o->clat_percentiles;\n\ttd->ts.lat_percentiles = o->lat_percentiles;\n\ttd->ts.slat_percentiles = o->slat_percentiles;\n\ttd->ts.percentile_precision = o->percentile_precision;\n\tmemcpy(td->ts.percentile_list, o->percentile_list, sizeof(o->percentile_list));\n\ttd->ts.sig_figs = o->sig_figs;\n\n\tinit_thread_stat_min_vals(&td->ts);\n\n\t/*\n\t * td->>ddir_seq_nr needs to be initialized to 1, NOT o->ddir_seq_nr,\n\t * so that get_next_offset gets a new random offset the first time it\n\t * is called, instead of keeping an initial offset of 0 for the first\n\t * nr-1 calls\n\t */\n\ttd->ddir_seq_nr = 1;\n\n\tif ((o->stonewall || o->new_group) && prev_group_jobs) {\n\t\tprev_group_jobs = 0;\n\t\tgroupid++;\n\t\tif (groupid == INT_MAX) {\n\t\t\tlog_err(\"fio: too many groups defined\\n\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\ttd->groupid = groupid;\n\tprev_group_jobs++;\n\n\tif (td->o.group_reporting && prev_group_jobs > 1 &&\n\t    verify_per_group_options(td, jobname))\n\t\tgoto err;\n\n\tif (setup_rate(td))\n\t\tgoto err;\n\n\tif (o->write_lat_log) {\n\t\tstruct log_params p = {\n\t\t\t.td = td,\n\t\t\t.avg_msec = o->log_avg_msec,\n\t\t\t.hist_msec = o->log_hist_msec,\n\t\t\t.hist_coarseness = o->log_hist_coarseness,\n\t\t\t.log_type = IO_LOG_TYPE_LAT,\n\t\t\t.log_offset = o->log_offset,\n\t\t\t.log_prio = o->log_prio,\n\t\t\t.log_issue_time = o->log_issue_time,\n\t\t\t.log_gz = o->log_gz,\n\t\t\t.log_gz_store = o->log_gz_store,\n\t\t};\n\t\tconst char *pre = make_log_name(o->lat_log_file, o->name);\n\t\tconst char *suf;\n\n\t\tif (o->log_issue_time && !o->log_offset) {\n\t\t\tlog_err(\"fio: log_issue_time option requires write_lat_log and log_offset options\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (p.log_gz_store)\n\t\t\tsuf = \"log.fz\";\n\t\telse\n\t\t\tsuf = \"log\";\n\n\t\tif (!o->disable_lat) {\n\t\t\tgen_log_name(logname, sizeof(logname), \"lat\", pre,\n\t\t\t\t     td->thread_number, suf, o->per_job_logs);\n\t\t\tsetup_log(&td->lat_log, &p, logname);\n\t\t}\n\n\t\tif (!o->disable_slat) {\n\t\t\tgen_log_name(logname, sizeof(logname), \"slat\", pre,\n\t\t\t\t     td->thread_number, suf, o->per_job_logs);\n\t\t\tsetup_log(&td->slat_log, &p, logname);\n\t\t}\n\n\t\tif (!o->disable_clat) {\n\t\t\tgen_log_name(logname, sizeof(logname), \"clat\", pre,\n\t\t\t\t     td->thread_number, suf, o->per_job_logs);\n\t\t\tsetup_log(&td->clat_log, &p, logname);\n\t\t}\n\n\t} else if (o->log_issue_time) {\n\t\tlog_err(\"fio: log_issue_time option requires write_lat_log and log_offset options\\n\");\n\t\tgoto err;\n\t}\n\n\tif (o->write_hist_log) {\n\t\tstruct log_params p = {\n\t\t\t.td = td,\n\t\t\t.avg_msec = o->log_avg_msec,\n\t\t\t.hist_msec = o->log_hist_msec,\n\t\t\t.hist_coarseness = o->log_hist_coarseness,\n\t\t\t.log_type = IO_LOG_TYPE_HIST,\n\t\t\t.log_offset = o->log_offset,\n\t\t\t.log_prio = o->log_prio,\n\t\t\t.log_issue_time = o->log_issue_time,\n\t\t\t.log_gz = o->log_gz,\n\t\t\t.log_gz_store = o->log_gz_store,\n\t\t};\n\t\tconst char *pre = make_log_name(o->hist_log_file, o->name);\n\t\tconst char *suf;\n\n#ifndef CONFIG_ZLIB\n\t\tif (td->client_type) {\n\t\t\tlog_err(\"fio: --write_hist_log requires zlib in client/server mode\\n\");\n\t\t\tgoto err;\n\t\t}\n#endif\n\n\t\tif (p.log_gz_store)\n\t\t\tsuf = \"log.fz\";\n\t\telse\n\t\t\tsuf = \"log\";\n\n\t\tgen_log_name(logname, sizeof(logname), \"clat_hist\", pre,\n\t\t\t\ttd->thread_number, suf, o->per_job_logs);\n\t\tsetup_log(&td->clat_hist_log, &p, logname);\n\t}\n\n\tif (o->write_bw_log) {\n\t\tstruct log_params p = {\n\t\t\t.td = td,\n\t\t\t.avg_msec = o->log_avg_msec,\n\t\t\t.hist_msec = o->log_hist_msec,\n\t\t\t.hist_coarseness = o->log_hist_coarseness,\n\t\t\t.log_type = IO_LOG_TYPE_BW,\n\t\t\t.log_offset = o->log_offset,\n\t\t\t.log_prio = o->log_prio,\n\t\t\t.log_issue_time = o->log_issue_time,\n\t\t\t.log_gz = o->log_gz,\n\t\t\t.log_gz_store = o->log_gz_store,\n\t\t};\n\t\tconst char *pre = make_log_name(o->bw_log_file, o->name);\n\t\tconst char *suf;\n\n\t\tif (fio_option_is_set(o, bw_avg_time))\n\t\t\tp.avg_msec = min(o->log_avg_msec, o->bw_avg_time);\n\t\telse\n\t\t\to->bw_avg_time = p.avg_msec;\n\n\t\tp.hist_msec = o->log_hist_msec;\n\t\tp.hist_coarseness = o->log_hist_coarseness;\n\n\t\tif (p.log_gz_store)\n\t\t\tsuf = \"log.fz\";\n\t\telse\n\t\t\tsuf = \"log\";\n\n\t\tgen_log_name(logname, sizeof(logname), \"bw\", pre,\n\t\t\t\ttd->thread_number, suf, o->per_job_logs);\n\t\tsetup_log(&td->bw_log, &p, logname);\n\t}\n\tif (o->write_iops_log) {\n\t\tstruct log_params p = {\n\t\t\t.td = td,\n\t\t\t.avg_msec = o->log_avg_msec,\n\t\t\t.hist_msec = o->log_hist_msec,\n\t\t\t.hist_coarseness = o->log_hist_coarseness,\n\t\t\t.log_type = IO_LOG_TYPE_IOPS,\n\t\t\t.log_offset = o->log_offset,\n\t\t\t.log_prio = o->log_prio,\n\t\t\t.log_issue_time = o->log_issue_time,\n\t\t\t.log_gz = o->log_gz,\n\t\t\t.log_gz_store = o->log_gz_store,\n\t\t};\n\t\tconst char *pre = make_log_name(o->iops_log_file, o->name);\n\t\tconst char *suf;\n\n\t\tif (fio_option_is_set(o, iops_avg_time))\n\t\t\tp.avg_msec = min(o->log_avg_msec, o->iops_avg_time);\n\t\telse\n\t\t\to->iops_avg_time = p.avg_msec;\n\n\t\tp.hist_msec = o->log_hist_msec;\n\t\tp.hist_coarseness = o->log_hist_coarseness;\n\n\t\tif (p.log_gz_store)\n\t\t\tsuf = \"log.fz\";\n\t\telse\n\t\t\tsuf = \"log\";\n\n\t\tgen_log_name(logname, sizeof(logname), \"iops\", pre,\n\t\t\t\ttd->thread_number, suf, o->per_job_logs);\n\t\tsetup_log(&td->iops_log, &p, logname);\n\t}\n\n\tif (!o->name)\n\t\to->name = strdup(jobname);\n\n\tif (output_format & FIO_OUTPUT_NORMAL) {\n\t\tif (!job_add_num) {\n\t\t\tif (is_backend && !recursed)\n\t\t\t\tfio_server_send_add_job(td);\n\n\t\t\tif (!td_ioengine_flagged(td, FIO_NOIO)) {\n\t\t\t\tchar *c1, *c2, *c3, *c4;\n\t\t\t\tchar *c5 = NULL, *c6 = NULL;\n\t\t\t\tint i2p = is_power_of_2(o->kb_base);\n\t\t\t\tstruct buf_output out;\n\n\t\t\t\tc1 = num2str(o->min_bs[DDIR_READ], o->sig_figs, 1, i2p, N2S_BYTE);\n\t\t\t\tc2 = num2str(o->max_bs[DDIR_READ], o->sig_figs, 1, i2p, N2S_BYTE);\n\t\t\t\tc3 = num2str(o->min_bs[DDIR_WRITE], o->sig_figs, 1, i2p, N2S_BYTE);\n\t\t\t\tc4 = num2str(o->max_bs[DDIR_WRITE], o->sig_figs, 1, i2p, N2S_BYTE);\n\n\t\t\t\tif (!o->bs_is_seq_rand) {\n\t\t\t\t\tc5 = num2str(o->min_bs[DDIR_TRIM], o->sig_figs, 1, i2p, N2S_BYTE);\n\t\t\t\t\tc6 = num2str(o->max_bs[DDIR_TRIM], o->sig_figs, 1, i2p, N2S_BYTE);\n\t\t\t\t}\n\n\t\t\t\tbuf_output_init(&out);\n\t\t\t\t__log_buf(&out, \"%s: (g=%d): rw=%s, \", td->o.name,\n\t\t\t\t\t\t\ttd->groupid,\n\t\t\t\t\t\t\tddir_str(o->td_ddir));\n\n\t\t\t\tif (o->bs_is_seq_rand)\n\t\t\t\t\t__log_buf(&out, \"bs=(R) %s-%s, (W) %s-%s, bs_is_seq_rand, \",\n\t\t\t\t\t\t\tc1, c2, c3, c4);\n\t\t\t\telse\n\t\t\t\t\t__log_buf(&out, \"bs=(R) %s-%s, (W) %s-%s, (T) %s-%s, \",\n\t\t\t\t\t\t\tc1, c2, c3, c4, c5, c6);\n\n\t\t\t\t__log_buf(&out, \"ioengine=%s, iodepth=%u\\n\",\n\t\t\t\t\t\ttd->io_ops->name, o->iodepth);\n\t\t\t\tlog_info_buf(out.buf, out.buflen);\n\t\t\t\tbuf_output_free(&out);\n\n\t\t\t\tfree(c1);\n\t\t\t\tfree(c2);\n\t\t\t\tfree(c3);\n\t\t\t\tfree(c4);\n\t\t\t\tfree(c5);\n\t\t\t\tfree(c6);\n\t\t\t}\n\t\t} else if (job_add_num == 1)\n\t\t\tlog_info(\"...\\n\");\n\t}\n\n\tif (td_steadystate_init(td))\n\t\tgoto err;\n\n\tif (o->merge_blktrace_file && !merge_blktrace_iologs(td))\n\t\tgoto err;\n\n\tif (merge_blktrace_only) {\n\t\tput_job(td);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * recurse add identical jobs, clear numjobs and stonewall options\n\t * as they don't apply to sub-jobs\n\t */\n\tnumjobs = o->numjobs;\n\twhile (--numjobs) {\n\t\tstruct thread_data *td_new = get_new_job(false, td, true, jobname);\n\n\t\tif (!td_new)\n\t\t\tgoto err;\n\n\t\ttd_new->o.numjobs = 1;\n\t\ttd_new->o.stonewall = 0;\n\t\ttd_new->o.new_group = 0;\n\t\ttd_new->subjob_number = numjobs;\n\t\ttd_new->o.ss_dur = o->ss_dur * 1000000l;\n\t\ttd_new->o.ss_limit = o->ss_limit;\n\n\t\tif (file_alloced) {\n\t\t\tif (td_new->files) {\n\t\t\t\tstruct fio_file *f;\n\t\t\t\tfor_each_file(td_new, f, i)\n\t\t\t\t\tfio_file_free(f);\n\t\t\t\tfree(td_new->files);\n\t\t\t\ttd_new->files = NULL;\n\t\t\t}\n\t\t\ttd_new->files_index = 0;\n\t\t\ttd_new->files_size = 0;\n\t\t\tif (td_new->o.filename) {\n\t\t\t\tfree(td_new->o.filename);\n\t\t\t\ttd_new->o.filename = NULL;\n\t\t\t}\n\t\t}\n\n\t\tif (add_job(td_new, jobname, numjobs, 1, client_type))\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tput_job(td);\n\treturn -1;\n}\n\n/*\n * Parse as if 'o' was a command line\n */\nvoid add_job_opts(const char **o, int client_type)\n{\n\tstruct thread_data *td, *td_parent;\n\tint i, in_global = 1;\n\tchar jobname[32];\n\n\ti = 0;\n\ttd_parent = td = NULL;\n\twhile (o[i]) {\n\t\tif (!strncmp(o[i], \"name\", 4)) {\n\t\t\tin_global = 0;\n\t\t\tif (td)\n\t\t\t\tadd_job(td, jobname, 0, 0, client_type);\n\t\t\ttd = NULL;\n\t\t\tsprintf(jobname, \"%s\", o[i] + 5);\n\t\t}\n\t\tif (in_global && !td_parent)\n\t\t\ttd_parent = get_new_job(true, &def_thread, false, jobname);\n\t\telse if (!in_global && !td) {\n\t\t\tif (!td_parent)\n\t\t\t\ttd_parent = &def_thread;\n\t\t\ttd = get_new_job(false, td_parent, false, jobname);\n\t\t}\n\t\tif (in_global)\n\t\t\tfio_options_parse(td_parent, (char **) &o[i], 1);\n\t\telse\n\t\t\tfio_options_parse(td, (char **) &o[i], 1);\n\t\ti++;\n\t}\n\n\tif (td)\n\t\tadd_job(td, jobname, 0, 0, client_type);\n}\n\nstatic int skip_this_section(const char *name)\n{\n\tint i;\n\n\tif (!nr_job_sections)\n\t\treturn 0;\n\tif (!strncmp(name, \"global\", 6))\n\t\treturn 0;\n\n\tfor (i = 0; i < nr_job_sections; i++)\n\t\tif (!strcmp(job_sections[i], name))\n\t\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int is_empty_or_comment(char *line)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < strlen(line); i++) {\n\t\tif (line[i] == ';')\n\t\t\treturn 1;\n\t\tif (line[i] == '#')\n\t\t\treturn 1;\n\t\tif (!isspace((int) line[i]) && !iscntrl((int) line[i]))\n\t\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n/*\n * This is our [ini] type file parser.\n */\nstatic int __parse_jobs_ini(struct thread_data *td,\n\t\tchar *file, int is_buf, int stonewall_flag, int type,\n\t\tint nested, char *name, char ***popts, int *aopts, int *nopts)\n{\n\tbool global = false;\n\tbool stdin_occupied = false;\n\tchar *string;\n\tFILE *f;\n\tchar *p;\n\tint ret = 0, stonewall;\n\tint first_sect = 1;\n\tint skip_fgets = 0;\n\tint inside_skip = 0;\n\tchar **opts;\n\tint i, alloc_opts, num_opts;\n\n\tdprint(FD_PARSE, \"Parsing ini file %s\\n\", file);\n\tassert(td || !nested);\n\n\tif (is_buf)\n\t\tf = NULL;\n\telse {\n\t\tif (!strcmp(file, \"-\")) {\n\t\t\tf = stdin;\n\t\t\tstdin_occupied = true;\n\t\t} else\n\t\t\tf = fopen(file, \"r\");\n\n\t\tif (!f) {\n\t\t\tint __err = errno;\n\n\t\t\tlog_err(\"fio: unable to open '%s' job file\\n\", file);\n\t\t\tif (td)\n\t\t\t\ttd_verror(td, __err, \"job file open\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tstring = malloc(OPT_LEN_MAX);\n\n\t/*\n\t * it's really 256 + small bit, 280 should suffice\n\t */\n\tif (!nested) {\n\t\tname = calloc(1, 280);\n\t}\n\n\topts = NULL;\n\tif (nested && popts) {\n\t\topts = *popts;\n\t\talloc_opts = *aopts;\n\t\tnum_opts = *nopts;\n\t}\n\n\tif (!opts) {\n\t\talloc_opts = 8;\n\t\topts = malloc(sizeof(char *) * alloc_opts);\n\t\tnum_opts = 0;\n\t}\n\n\tstonewall = stonewall_flag;\n\tdo {\n\t\t/*\n\t\t * if skip_fgets is set, we already have loaded a line we\n\t\t * haven't handled.\n\t\t */\n\t\tif (!skip_fgets) {\n\t\t\tif (is_buf)\n\t\t\t\tp = strsep(&file, \"\\n\");\n\t\t\telse\n\t\t\t\tp = fgets(string, OPT_LEN_MAX, f);\n\t\t\tif (!p)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tskip_fgets = 0;\n\t\tstrip_blank_front(&p);\n\t\tstrip_blank_end(p);\n\n\t\tdprint(FD_PARSE, \"%s\\n\", p);\n\t\tif (is_empty_or_comment(p))\n\t\t\tcontinue;\n\n\t\tif (!nested) {\n\t\t\tif (sscanf(p, \"[%255[^\\n]]\", name) != 1) {\n\t\t\t\tif (inside_skip)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tlog_err(\"fio: option <%s> outside of \"\n\t\t\t\t\t\"[] job section\\n\", p);\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tname[strlen(name) - 1] = '\\0';\n\n\t\t\tif (skip_this_section(name)) {\n\t\t\t\tinside_skip = 1;\n\t\t\t\tcontinue;\n\t\t\t} else\n\t\t\t\tinside_skip = 0;\n\n\t\t\tdprint(FD_PARSE, \"Parsing section [%s]\\n\", name);\n\n\t\t\tglobal = !strncmp(name, \"global\", 6);\n\n\t\t\tif (dump_cmdline) {\n\t\t\t\tif (first_sect)\n\t\t\t\t\tlog_info(\"fio \");\n\t\t\t\tif (!global)\n\t\t\t\t\tlog_info(\"--name=%s \", name);\n\t\t\t\tfirst_sect = 0;\n\t\t\t}\n\n\t\t\ttd = get_new_job(global, &def_thread, false, name);\n\t\t\tif (!td) {\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Separate multiple job files by a stonewall\n\t\t\t */\n\t\t\tif (!global && stonewall) {\n\t\t\t\ttd->o.stonewall = stonewall;\n\t\t\t\tstonewall = 0;\n\t\t\t}\n\n\t\t\tnum_opts = 0;\n\t\t\tmemset(opts, 0, alloc_opts * sizeof(char *));\n\t\t}\n\t\telse\n\t\t\tskip_fgets = 1;\n\n\t\twhile (1) {\n\t\t\tif (!skip_fgets) {\n\t\t\t\tif (is_buf)\n\t\t\t\t\tp = strsep(&file, \"\\n\");\n\t\t\t\telse\n\t\t\t\t\tp = fgets(string, OPT_LEN_MAX, f);\n\t\t\t\tif (!p)\n\t\t\t\t\tbreak;\n\t\t\t\tdprint(FD_PARSE, \"%s\", p);\n\t\t\t}\n\t\t\telse\n\t\t\t\tskip_fgets = 0;\n\n\t\t\tif (is_empty_or_comment(p))\n\t\t\t\tcontinue;\n\n\t\t\tstrip_blank_front(&p);\n\n\t\t\t/*\n\t\t\t * new section, break out and make sure we don't\n\t\t\t * fgets() a new line at the top.\n\t\t\t */\n\t\t\tif (p[0] == '[') {\n\t\t\t\tif (nested) {\n\t\t\t\t\tlog_err(\"No new sections in included files\\n\");\n\t\t\t\t\tret = 1;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tskip_fgets = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tstrip_blank_end(p);\n\n\t\t\tif (!strncmp(p, \"include\", strlen(\"include\"))) {\n\t\t\t\tchar *filename = p + strlen(\"include\") + 1,\n\t\t\t\t\t*ts, *full_fn = NULL;\n\n\t\t\t\t/*\n\t\t\t\t * Allow for the include filename\n\t\t\t\t * specification to be relative.\n\t\t\t\t */\n\t\t\t\tif (access(filename, F_OK) &&\n\t\t\t\t    (ts = strrchr(file, '/'))) {\n\t\t\t\t\tif (asprintf(&full_fn, \"%.*s%s\",\n\t\t\t\t\t\t (int)(ts - file + 1), file,\n\t\t\t\t\t\t filename) < 0) {\n\t\t\t\t\t\tret = ENOMEM;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tfilename = full_fn;\n\t\t\t\t}\n\n\t\t\t\tret = __parse_jobs_ini(td, filename, is_buf,\n\t\t\t\t\t\t       stonewall_flag, type, 1,\n\t\t\t\t\t\t       name, &opts,\n\t\t\t\t\t\t       &alloc_opts, &num_opts);\n\n\t\t\t\tif (ret) {\n\t\t\t\t\tlog_err(\"Error %d while parsing \"\n\t\t\t\t\t\t\"include file %s\\n\",\n\t\t\t\t\t\tret, filename);\n\t\t\t\t}\n\n\t\t\t\tif (full_fn)\n\t\t\t\t\tfree(full_fn);\n\n\t\t\t\tif (ret)\n\t\t\t\t\tbreak;\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (num_opts == alloc_opts) {\n\t\t\t\talloc_opts <<= 1;\n\t\t\t\topts = realloc(opts,\n\t\t\t\t\t\talloc_opts * sizeof(char *));\n\t\t\t}\n\n\t\t\topts[num_opts] = strdup(p);\n\t\t\tnum_opts++;\n\t\t}\n\n\t\tif (nested) {\n\t\t\t*popts = opts;\n\t\t\t*aopts = alloc_opts;\n\t\t\t*nopts = num_opts;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = fio_options_parse(td, opts, num_opts);\n\n\t\tif (!ret && td->o.read_iolog_file != NULL) {\n\t\t\tchar *fname = get_name_by_idx(td->o.read_iolog_file,\n\t\t\t\t\t\t      td->subjob_number);\n\t\t\tif (!strcmp(fname, \"-\")) {\n\t\t\t\tif (stdin_occupied) {\n\t\t\t\t\tlog_err(\"fio: only one user (read_iolog_file/job \"\n\t\t\t\t\t\t\"file) of stdin is permitted at once but \"\n\t\t\t\t\t\t\"more than one was found.\\n\");\n\t\t\t\t\tret = 1;\n\t\t\t\t}\n\t\t\t\tstdin_occupied = true;\n\t\t\t}\n\t\t}\n\t\tif (!ret) {\n\t\t\tif (dump_cmdline)\n\t\t\t\tdump_opt_list(td);\n\n\t\t\tret = add_job(td, name, 0, 0, type);\n\t\t} else {\n\t\t\tlog_err(\"fio: job %s dropped\\n\", name);\n\t\t\tput_job(td);\n\t\t}\n\n\t\tfor (i = 0; i < num_opts; i++)\n\t\t\tfree(opts[i]);\n\t\tnum_opts = 0;\n\t} while (!ret);\n\n\tif (dump_cmdline)\n\t\tlog_info(\"\\n\");\n\n\ti = 0;\n\twhile (i < nr_job_sections) {\n\t\tfree(job_sections[i]);\n\t\ti++;\n\t}\n\n\tfree(job_sections);\n\tjob_sections = NULL;\n\tnr_job_sections = 0;\n\n\tfree(opts);\nout:\n\tfree(string);\n\tif (!nested)\n\t\tfree(name);\n\tif (!is_buf && f != stdin)\n\t\tfclose(f);\n\treturn ret;\n}\n\nint parse_jobs_ini(char *file, int is_buf, int stonewall_flag, int type)\n{\n\treturn __parse_jobs_ini(NULL, file, is_buf, stonewall_flag, type,\n\t\t\t0, NULL, NULL, NULL, NULL);\n}\n\nstatic int fill_def_thread(void)\n{\n\tmemset(&def_thread, 0, sizeof(def_thread));\n\tINIT_FLIST_HEAD(&def_thread.opt_list);\n\n\tfio_getaffinity(getpid(), &def_thread.o.cpumask);\n\tdef_thread.o.error_dump = 1;\n\n\t/*\n\t * fill default options\n\t */\n\tfio_fill_default_options(&def_thread);\n\treturn 0;\n}\n\nstatic void show_debug_categories(void)\n{\n#ifdef FIO_INC_DEBUG\n\tconst struct debug_level *dl = &debug_levels[0];\n\tint curlen, first = 1;\n\n\tcurlen = 0;\n\twhile (dl->name) {\n\t\tint has_next = (dl + 1)->name != NULL;\n\n\t\tif (first || curlen + strlen(dl->name) >= 80) {\n\t\t\tif (!first) {\n\t\t\t\tprintf(\"\\n\");\n\t\t\t\tcurlen = 0;\n\t\t\t}\n\t\t\tcurlen += printf(\"\\t\\t\\t%s\", dl->name);\n\t\t\tcurlen += 3 * (8 - 1);\n\t\t\tif (has_next)\n\t\t\t\tcurlen += printf(\",\");\n\t\t} else {\n\t\t\tcurlen += printf(\"%s\", dl->name);\n\t\t\tif (has_next)\n\t\t\t\tcurlen += printf(\",\");\n\t\t}\n\t\tdl++;\n\t\tfirst = 0;\n\t}\n\tprintf(\"\\n\");\n#endif\n}\n\n/*\n * Following options aren't printed by usage().\n * --append-terse - Equivalent to --output-format=terse, see f6a7df53.\n * --latency-log - Deprecated option.\n */\nstatic void usage(const char *name)\n{\n\tprintf(\"%s\\n\", fio_version_string);\n\tprintf(\"%s [options] [job options] <job file(s)>\\n\", name);\n\tprintf(\"  --debug=options\\tEnable debug logging. May be one/more of:\\n\");\n\tshow_debug_categories();\n\tprintf(\"  --parse-only\\t\\tParse options only, don't start any IO\\n\");\n\tprintf(\"  --merge-blktrace-only\\tMerge blktraces only, don't start any IO\\n\");\n\tprintf(\"  --output\\t\\tWrite output to file\\n\");\n\tprintf(\"  --bandwidth-log\\tGenerate aggregate bandwidth logs\\n\");\n\tprintf(\"  --minimal\\t\\tMinimal (terse) output\\n\");\n\tprintf(\"  --output-format=type\\tOutput format (terse,json,json+,normal)\\n\");\n\tprintf(\"  --terse-version=type\\tSet terse version output format\"\n\t\t\" (default 3, or 2 or 4 or 5)\\n\");\n\tprintf(\"  --version\\t\\tPrint version info and exit\\n\");\n\tprintf(\"  --help\\t\\tPrint this page\\n\");\n\tprintf(\"  --cpuclock-test\\tPerform test/validation of CPU clock\\n\");\n\tprintf(\"  --crctest=[type]\\tTest speed of checksum functions\\n\");\n\tprintf(\"  --cmdhelp=cmd\\t\\tPrint command help, \\\"all\\\" for all of\"\n\t\t\" them\\n\");\n\tprintf(\"  --enghelp=engine\\tPrint ioengine help, or list\"\n\t\t\" available ioengines\\n\");\n\tprintf(\"  --enghelp=engine,cmd\\tPrint help for an ioengine\"\n\t\t\" cmd\\n\");\n\tprintf(\"  --showcmd\\t\\tTurn a job file into command line options\\n\");\n\tprintf(\"  --eta=when\\t\\tWhen ETA estimate should be printed\\n\");\n\tprintf(\"            \\t\\tMay be \\\"always\\\", \\\"never\\\" or \\\"auto\\\"\\n\");\n\tprintf(\"  --eta-newline=t\\tForce a new line for every 't'\");\n\tprintf(\" period passed\\n\");\n\tprintf(\"  --status-interval=t\\tForce full status dump every\");\n\tprintf(\" 't' period passed\\n\");\n\tprintf(\"  --readonly\\t\\tTurn on safety read-only checks, preventing\"\n\t\t\" writes\\n\");\n\tprintf(\"  --section=name\\tOnly run specified section in job file,\"\n\t\t\" multiple sections can be specified\\n\");\n\tprintf(\"  --alloc-size=kb\\tSet smalloc pool to this size in kb\"\n\t\t\" (def 16384)\\n\");\n\tprintf(\"  --warnings-fatal\\tFio parser warnings are fatal\\n\");\n\tprintf(\"  --max-jobs=nr\\t\\tMaximum number of threads/processes to support\\n\");\n\tprintf(\"  --server=args\\t\\tStart a backend fio server\\n\");\n\tprintf(\"  --daemonize=pidfile\\tBackground fio server, write pid to file\\n\");\n\tprintf(\"  --client=hostname\\tTalk to remote backend(s) fio server at hostname\\n\");\n\tprintf(\"  --remote-config=file\\tTell fio server to load this local job file\\n\");\n\tprintf(\"  --idle-prof=option\\tReport cpu idleness on a system or percpu basis\\n\"\n\t\t\"\\t\\t\\t(option=system,percpu) or run unit work\\n\"\n\t\t\"\\t\\t\\tcalibration only (option=calibrate)\\n\");\n#ifdef CONFIG_ZLIB\n\tprintf(\"  --inflate-log=log\\tInflate and output compressed log\\n\");\n#endif\n\tprintf(\"  --trigger-file=file\\tExecute trigger cmd when file exists\\n\");\n\tprintf(\"  --trigger-timeout=t\\tExecute trigger at this time\\n\");\n\tprintf(\"  --trigger=cmd\\t\\tSet this command as local trigger\\n\");\n\tprintf(\"  --trigger-remote=cmd\\tSet this command as remote trigger\\n\");\n\tprintf(\"  --aux-path=path\\tUse this path for fio state generated files\\n\");\n\tprintf(\"\\nFio was written by Jens Axboe <axboe@kernel.dk>\\n\");\n}\n\n#ifdef FIO_INC_DEBUG\nconst struct debug_level debug_levels[] = {\n\t{ .name = \"process\",\n\t  .help = \"Process creation/exit logging\",\n\t  .shift = FD_PROCESS,\n\t},\n\t{ .name = \"file\",\n\t  .help = \"File related action logging\",\n\t  .shift = FD_FILE,\n\t},\n\t{ .name = \"io\",\n\t  .help = \"IO and IO engine action logging (offsets, queue, completions, etc)\",\n\t  .shift = FD_IO,\n\t},\n\t{ .name = \"mem\",\n\t  .help = \"Memory allocation/freeing logging\",\n\t  .shift = FD_MEM,\n\t},\n\t{ .name = \"blktrace\",\n\t  .help = \"blktrace action logging\",\n\t  .shift = FD_BLKTRACE,\n\t},\n\t{ .name = \"verify\",\n\t  .help = \"IO verification action logging\",\n\t  .shift = FD_VERIFY,\n\t},\n\t{ .name = \"random\",\n\t  .help = \"Random generation logging\",\n\t  .shift = FD_RANDOM,\n\t},\n\t{ .name = \"parse\",\n\t  .help = \"Parser logging\",\n\t  .shift = FD_PARSE,\n\t},\n\t{ .name = \"diskutil\",\n\t  .help = \"Disk utility logging actions\",\n\t  .shift = FD_DISKUTIL,\n\t},\n\t{ .name = \"job\",\n\t  .help = \"Logging related to creating/destroying jobs\",\n\t  .shift = FD_JOB,\n\t},\n\t{ .name = \"mutex\",\n\t  .help = \"Mutex logging\",\n\t  .shift = FD_MUTEX\n\t},\n\t{ .name\t= \"profile\",\n\t  .help = \"Logging related to profiles\",\n\t  .shift = FD_PROFILE,\n\t},\n\t{ .name = \"time\",\n\t  .help = \"Logging related to time keeping functions\",\n\t  .shift = FD_TIME,\n\t},\n\t{ .name = \"net\",\n\t  .help = \"Network logging\",\n\t  .shift = FD_NET,\n\t},\n\t{ .name = \"rate\",\n\t  .help = \"Rate logging\",\n\t  .shift = FD_RATE,\n\t},\n\t{ .name = \"compress\",\n\t  .help = \"Log compression logging\",\n\t  .shift = FD_COMPRESS,\n\t},\n\t{ .name = \"steadystate\",\n\t  .help = \"Steady state detection logging\",\n\t  .shift = FD_STEADYSTATE,\n\t},\n\t{ .name = \"helperthread\",\n\t  .help = \"Helper thread logging\",\n\t  .shift = FD_HELPERTHREAD,\n\t},\n\t{ .name = \"zbd\",\n\t  .help = \"Zoned Block Device logging\",\n\t  .shift = FD_ZBD,\n\t},\n\t{ .name = NULL, },\n};\n\nstatic int set_debug(const char *string)\n{\n\tconst struct debug_level *dl;\n\tchar *p = (char *) string;\n\tchar *opt;\n\tint i;\n\n\tif (!string)\n\t\treturn 0;\n\n\tif (!strcmp(string, \"?\") || !strcmp(string, \"help\")) {\n\t\tlog_info(\"fio: dumping debug options:\");\n\t\tfor (i = 0; debug_levels[i].name; i++) {\n\t\t\tdl = &debug_levels[i];\n\t\t\tlog_info(\"%s,\", dl->name);\n\t\t}\n\t\tlog_info(\"all\\n\");\n\t\treturn 1;\n\t}\n\n\twhile ((opt = strsep(&p, \",\")) != NULL) {\n\t\tint found = 0;\n\n\t\tif (!strncmp(opt, \"all\", 3)) {\n\t\t\tlog_info(\"fio: set all debug options\\n\");\n\t\t\tfio_debug = ~0UL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor (i = 0; debug_levels[i].name; i++) {\n\t\t\tdl = &debug_levels[i];\n\t\t\tfound = !strncmp(opt, dl->name, strlen(dl->name));\n\t\t\tif (!found)\n\t\t\t\tcontinue;\n\n\t\t\tif (dl->shift == FD_JOB) {\n\t\t\t\topt = strchr(opt, ':');\n\t\t\t\tif (!opt) {\n\t\t\t\t\tlog_err(\"fio: missing job number\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\topt++;\n\t\t\t\tfio_debug_jobno = atoi(opt);\n\t\t\t\tlog_info(\"fio: set debug jobno %d\\n\",\n\t\t\t\t\t\t\tfio_debug_jobno);\n\t\t\t} else {\n\t\t\t\tlog_info(\"fio: set debug option %s\\n\", opt);\n\t\t\t\tfio_debug |= (1UL << dl->shift);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!found)\n\t\t\tlog_err(\"fio: debug mask %s not found\\n\", opt);\n\t}\n\treturn 0;\n}\n#else\nstatic int set_debug(const char *string)\n{\n\tlog_err(\"fio: debug tracing not included in build\\n\");\n\treturn 1;\n}\n#endif\n\nstatic void fio_options_fill_optstring(void)\n{\n\tchar *ostr = cmd_optstr;\n\tint i, c;\n\n\tc = i = 0;\n\twhile (l_opts[i].name) {\n\t\tostr[c++] = l_opts[i].val;\n\t\tif (l_opts[i].has_arg == required_argument)\n\t\t\tostr[c++] = ':';\n\t\telse if (l_opts[i].has_arg == optional_argument) {\n\t\t\tostr[c++] = ':';\n\t\t\tostr[c++] = ':';\n\t\t}\n\t\ti++;\n\t}\n\tostr[c] = '\\0';\n}\n\nstatic int client_flag_set(char c)\n{\n\tint i;\n\n\ti = 0;\n\twhile (l_opts[i].name) {\n\t\tint val = l_opts[i].val;\n\n\t\tif (c == (val & 0xff))\n\t\t\treturn (val & FIO_CLIENT_FLAG);\n\n\t\ti++;\n\t}\n\n\treturn 0;\n}\n\nstatic void parse_cmd_client(void *client, char *opt)\n{\n\tfio_client_add_cmd_option(client, opt);\n}\n\nstatic void show_closest_option(const char *name)\n{\n\tint best_option, best_distance;\n\tint i, distance;\n\n\twhile (*name == '-')\n\t\tname++;\n\n\tbest_option = -1;\n\tbest_distance = INT_MAX;\n\ti = 0;\n\twhile (l_opts[i].name) {\n\t\tdistance = string_distance(name, l_opts[i].name);\n\t\tif (distance < best_distance) {\n\t\t\tbest_distance = distance;\n\t\t\tbest_option = i;\n\t\t}\n\t\ti++;\n\t}\n\n\tif (best_option != -1 && string_distance_ok(name, best_distance))\n\t\tlog_err(\"Did you mean %s?\\n\", l_opts[best_option].name);\n}\n\nstatic int parse_output_format(const char *optarg)\n{\n\tchar *p, *orig, *opt;\n\tint ret = 0;\n\n\tp = orig = strdup(optarg);\n\n\toutput_format = 0;\n\n\twhile ((opt = strsep(&p, \",\")) != NULL) {\n\t\tif (!strcmp(opt, \"minimal\") ||\n\t\t    !strcmp(opt, \"terse\") ||\n\t\t    !strcmp(opt, \"csv\"))\n\t\t\toutput_format |= FIO_OUTPUT_TERSE;\n\t\telse if (!strcmp(opt, \"json\"))\n\t\t\toutput_format |= FIO_OUTPUT_JSON;\n\t\telse if (!strcmp(opt, \"json+\"))\n\t\t\toutput_format |= (FIO_OUTPUT_JSON | FIO_OUTPUT_JSON_PLUS);\n\t\telse if (!strcmp(opt, \"normal\"))\n\t\t\toutput_format |= FIO_OUTPUT_NORMAL;\n\t\telse {\n\t\t\tlog_err(\"fio: invalid output format %s\\n\", opt);\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfree(orig);\n\treturn ret;\n}\n\nint parse_cmd_line(int argc, char *argv[], int client_type)\n{\n\tstruct thread_data *td = NULL;\n\tint c, ini_idx = 0, lidx, ret = 0, do_exit = 0, exit_val = 0;\n\tchar *ostr = cmd_optstr;\n\tchar *pid_file = NULL;\n\tvoid *cur_client = NULL;\n\tbool backend = false;\n\n\t/*\n\t * Reset optind handling, since we may call this multiple times\n\t * for the backend.\n\t */\n\toptind = 1;\n\n\twhile ((c = getopt_long_only(argc, argv, ostr, l_opts, &lidx)) != -1) {\n\t\tif ((c & FIO_CLIENT_FLAG) || client_flag_set(c)) {\n\t\t\tparse_cmd_client(cur_client, argv[optind - 1]);\n\t\t\tc &= ~FIO_CLIENT_FLAG;\n\t\t}\n\n\t\tswitch (c) {\n\t\tcase 'a':\n\t\t\tsmalloc_pool_size = atoi(optarg);\n\t\t\tsmalloc_pool_size <<= 10;\n\t\t\tsinit();\n\t\t\tbreak;\n\t\tcase 'l':\n\t\t\tlog_err(\"fio: --latency-log is deprecated. Use per-job latency log options.\\n\");\n\t\t\tdo_exit++;\n\t\t\texit_val = 1;\n\t\t\tbreak;\n\t\tcase 'b':\n\t\t\twrite_bw_log = true;\n\t\t\tbreak;\n\t\tcase 'o': {\n\t\t\tFILE *tmp;\n\n\t\t\tif (f_out && f_out != stdout)\n\t\t\t\tfclose(f_out);\n\n\t\t\ttmp = fopen(optarg, \"w+\");\n\t\t\tif (!tmp) {\n\t\t\t\tlog_err(\"fio: output file open error: %s\\n\", strerror(errno));\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tf_err = f_out = tmp;\n\t\t\tbreak;\n\t\t\t}\n\t\tcase 'm':\n\t\t\toutput_format = FIO_OUTPUT_TERSE;\n\t\t\tbreak;\n\t\tcase 'F':\n\t\t\tif (parse_output_format(optarg)) {\n\t\t\t\tlog_err(\"fio: failed parsing output-format\\n\");\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\toutput_format |= FIO_OUTPUT_TERSE;\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tdid_arg = true;\n\t\t\tif (!cur_client) {\n\t\t\t\tusage(argv[0]);\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'c':\n\t\t\tdid_arg = true;\n\t\t\tif (!cur_client) {\n\t\t\t\tfio_show_option_help(optarg);\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tdid_arg = true;\n\t\t\tif (!cur_client) {\n\t\t\t\texit_val = fio_show_ioengine_help(optarg);\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tdid_arg = true;\n\t\t\tdump_cmdline = true;\n\t\t\tbreak;\n\t\tcase 'r':\n\t\t\tread_only = 1;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tdid_arg = true;\n\t\t\tif (!cur_client) {\n\t\t\t\tlog_info(\"%s\\n\", fio_version_string);\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'V':\n\t\t\tterse_version = atoi(optarg);\n\t\t\tif (!(terse_version >= 2 && terse_version <= 5)) {\n\t\t\t\tlog_err(\"fio: bad terse version format\\n\");\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'e':\n\t\t\tif (!strcmp(\"always\", optarg))\n\t\t\t\teta_print = FIO_ETA_ALWAYS;\n\t\t\telse if (!strcmp(\"never\", optarg))\n\t\t\t\teta_print = FIO_ETA_NEVER;\n\t\t\tbreak;\n\t\tcase 'E': {\n\t\t\tlong long t = 0;\n\n\t\t\tif (check_str_time(optarg, &t, 1)) {\n\t\t\t\tlog_err(\"fio: failed parsing eta time %s\\n\", optarg);\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\teta_new_line = t / 1000;\n\t\t\tif (!eta_new_line) {\n\t\t\t\tlog_err(\"fio: eta new line time too short\\n\");\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\t\t}\n\t\tcase 'O': {\n\t\t\tlong long t = 0;\n\n\t\t\tif (check_str_time(optarg, &t, 1)) {\n\t\t\t\tlog_err(\"fio: failed parsing eta interval %s\\n\", optarg);\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\teta_interval_msec = t / 1000;\n\t\t\tif (eta_interval_msec < DISK_UTIL_MSEC) {\n\t\t\t\tlog_err(\"fio: eta interval time too short (%umsec min)\\n\", DISK_UTIL_MSEC);\n\t\t\t\texit_val = 1;\n\t\t\t\tdo_exit++;\n\t\t\t}\n\t\t\tbreak;\n\t\t\t}\n\t\tcase 'd':\n\t\t\tif (set_debug(optarg))\n\t\t\t\tdo_exit++;\n\t\t\tbreak;\n\t\tcase 'P':\n\t\t\tdid_arg = true;\n\t\t\tparse_only = true;\n\t\t\tbreak;\n\t\tcase 'x': {\n\t\t\tsize_t new_size;\n\n\t\t\tif (!strcmp(optarg, \"global\")) {\n\t\t\t\tlog_err(\"fio: can't use global as only \"\n\t\t\t\t\t\"section\\n\");\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tnew_size = (nr_job_sections + 1) * sizeof(char *);\n\t\t\tjob_sections = realloc(job_sections, new_size);\n\t\t\tjob_sections[nr_job_sections] = strdup(optarg);\n\t\t\tnr_job_sections++;\n\t\t\tbreak;\n\t\t\t}\n#ifdef CONFIG_ZLIB\n\t\tcase 'X':\n\t\t\texit_val = iolog_file_inflate(optarg);\n\t\t\tdid_arg = true;\n\t\t\tdo_exit++;\n\t\t\tbreak;\n#endif\n\t\tcase 'p':\n\t\t\tdid_arg = true;\n\t\t\tif (exec_profile)\n\t\t\t\tfree(exec_profile);\n\t\t\texec_profile = strdup(optarg);\n\t\t\tbreak;\n\t\tcase FIO_GETOPT_JOB: {\n\t\t\tconst char *opt = l_opts[lidx].name;\n\t\t\tchar *val = optarg;\n\n\t\t\tif (!strncmp(opt, \"name\", 4) && td) {\n\t\t\t\tret = add_job(td, td->o.name ?: \"fio\", 0, 0, client_type);\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out_free;\n\t\t\t\ttd = NULL;\n\t\t\t\tdid_arg = true;\n\t\t\t}\n\t\t\tif (!td) {\n\t\t\t\tint is_section = !strncmp(opt, \"name\", 4);\n\t\t\t\tint global = 0;\n\n\t\t\t\tif (!is_section || !strncmp(val, \"global\", 6))\n\t\t\t\t\tglobal = 1;\n\n\t\t\t\tif (is_section && skip_this_section(val))\n\t\t\t\t\tcontinue;\n\n\t\t\t\ttd = get_new_job(global, &def_thread, true, NULL);\n\t\t\t\tif (!td || ioengine_load(td)) {\n\t\t\t\t\tif (td) {\n\t\t\t\t\t\tput_job(td);\n\t\t\t\t\t\ttd = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tdo_exit++;\n\t\t\t\t\texit_val = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tfio_options_set_ioengine_opts(l_opts, td);\n\t\t\t}\n\n\t\t\tif ((!val || !strlen(val)) &&\n\t\t\t    l_opts[lidx].has_arg == required_argument) {\n\t\t\t\tlog_err(\"fio: option %s requires an argument\\n\", opt);\n\t\t\t\tret = 1;\n\t\t\t} else\n\t\t\t\tret = fio_cmd_option_parse(td, opt, val);\n\n\t\t\tif (ret) {\n\t\t\t\tif (td) {\n\t\t\t\t\tput_job(td);\n\t\t\t\t\ttd = NULL;\n\t\t\t\t}\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t}\n\n\t\t\tif (!ret && !strcmp(opt, \"ioengine\")) {\n\t\t\t\tif (ioengine_load(td)) {\n\t\t\t\t\tput_job(td);\n\t\t\t\t\ttd = NULL;\n\t\t\t\t\tdo_exit++;\n\t\t\t\t\texit_val = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tfio_options_set_ioengine_opts(l_opts, td);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase FIO_GETOPT_IOENGINE: {\n\t\t\tconst char *opt = l_opts[lidx].name;\n\t\t\tchar *val = optarg;\n\n\t\t\tif (!td)\n\t\t\t\tbreak;\n\n\t\t\tret = fio_cmd_ioengine_option_parse(td, opt, val);\n\n\t\t\tif (ret) {\n\t\t\t\tif (td) {\n\t\t\t\t\tput_job(td);\n\t\t\t\t\ttd = NULL;\n\t\t\t\t}\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase 'w':\n\t\t\twarnings_fatal = 1;\n\t\t\tbreak;\n\t\tcase 'j':\n\t\t\t/* we don't track/need this anymore, ignore it */\n\t\t\tbreak;\n\t\tcase 'S':\n\t\t\tdid_arg = true;\n#ifndef CONFIG_NO_SHM\n\t\t\tif (nr_clients) {\n\t\t\t\tlog_err(\"fio: can't be both client and server\\n\");\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (optarg)\n\t\t\t\tfio_server_set_arg(optarg);\n\t\t\tis_backend = true;\n\t\t\tbackend = true;\n#else\n\t\t\tlog_err(\"fio: client/server requires SHM support\\n\");\n\t\t\tdo_exit++;\n\t\t\texit_val = 1;\n#endif\n\t\t\tbreak;\n#ifdef WIN32\n\t\tcase 'N':\n\t\t\tdid_arg = true;\n\t\t\tfio_server_internal_set(optarg);\n\t\t\tbreak;\n#endif\n\t\tcase 'D':\n\t\t\tif (pid_file)\n\t\t\t\tfree(pid_file);\n\t\t\tpid_file = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'I':\n\t\t\tif ((ret = fio_idle_prof_parse_opt(optarg))) {\n\t\t\t\t/* exit on error and calibration only */\n\t\t\t\tdid_arg = true;\n\t\t\t\tdo_exit++;\n\t\t\t\tif (ret == -1)\n\t\t\t\t\texit_val = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'C':\n\t\t\tdid_arg = true;\n\t\t\tif (is_backend) {\n\t\t\t\tlog_err(\"fio: can't be both client and server\\n\");\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* if --client parameter contains a pathname */\n\t\t\tif (0 == access(optarg, R_OK)) {\n\t\t\t\t/* file contains a list of host addrs or names */\n\t\t\t\tchar hostaddr[PATH_MAX] = {0};\n\t\t\t\tchar formatstr[8];\n\t\t\t\tFILE * hostf = fopen(optarg, \"r\");\n\t\t\t\tif (!hostf) {\n\t\t\t\t\tlog_err(\"fio: could not open client list file %s for read\\n\", optarg);\n\t\t\t\t\tdo_exit++;\n\t\t\t\t\texit_val = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsprintf(formatstr, \"%%%ds\", PATH_MAX - 1);\n\t\t\t\t/*\n\t\t\t\t * read at most PATH_MAX-1 chars from each\n\t\t\t\t * record in this file\n\t\t\t\t */\n\t\t\t\twhile (fscanf(hostf, formatstr, hostaddr) == 1) {\n\t\t\t\t\t/* expect EVERY host in file to be valid */\n\t\t\t\t\tif (fio_client_add(&fio_client_ops, hostaddr, &cur_client)) {\n\t\t\t\t\t\tlog_err(\"fio: failed adding client %s from file %s\\n\", hostaddr, optarg);\n\t\t\t\t\t\tdo_exit++;\n\t\t\t\t\t\texit_val = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfclose(hostf);\n\t\t\t\tbreak; /* no possibility of job file for \"this client only\" */\n\t\t\t}\n\t\t\tif (fio_client_add(&fio_client_ops, optarg, &cur_client)) {\n\t\t\t\tlog_err(\"fio: failed adding client %s\\n\", optarg);\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/*\n\t\t\t * If the next argument exists and isn't an option,\n\t\t\t * assume it's a job file for this client only.\n\t\t\t */\n\t\t\twhile (optind < argc) {\n\t\t\t\tif (!strncmp(argv[optind], \"--\", 2) ||\n\t\t\t\t    !strncmp(argv[optind], \"-\", 1))\n\t\t\t\t\tbreak;\n\n\t\t\t\tif (fio_client_add_ini_file(cur_client, argv[optind], false))\n\t\t\t\t\tbreak;\n\t\t\t\toptind++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'R':\n\t\t\tdid_arg = true;\n\t\t\tif (fio_client_add_ini_file(cur_client, optarg, true)) {\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'T':\n\t\t\tdid_arg = true;\n\t\t\tdo_exit++;\n\t\t\texit_val = fio_monotonic_clocktest(1);\n\t\t\tbreak;\n\t\tcase 'G':\n\t\t\tdid_arg = true;\n\t\t\tdo_exit++;\n\t\t\texit_val = fio_crctest(optarg);\n\t\t\tbreak;\n\t\tcase 'M':\n\t\t\tdid_arg = true;\n\t\t\tdo_exit++;\n\t\t\texit_val = fio_memcpy_test(optarg);\n\t\t\tbreak;\n\t\tcase 'L': {\n\t\t\tlong long val;\n\n\t\t\tif (check_str_time(optarg, &val, 1)) {\n\t\t\t\tlog_err(\"fio: failed parsing time %s\\n\", optarg);\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (val < 1000) {\n\t\t\t\tlog_err(\"fio: status interval too small\\n\");\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t}\n\t\t\tstatus_interval = val / 1000;\n\t\t\tbreak;\n\t\t\t}\n\t\tcase 'W':\n\t\t\tif (trigger_file)\n\t\t\t\tfree(trigger_file);\n\t\t\ttrigger_file = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'H':\n\t\t\tif (trigger_cmd)\n\t\t\t\tfree(trigger_cmd);\n\t\t\ttrigger_cmd = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'J':\n\t\t\tif (trigger_remote_cmd)\n\t\t\t\tfree(trigger_remote_cmd);\n\t\t\ttrigger_remote_cmd = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'K':\n\t\t\tif (aux_path)\n\t\t\t\tfree(aux_path);\n\t\t\taux_path = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'B':\n\t\t\tif (check_str_time(optarg, &trigger_timeout, 1)) {\n\t\t\t\tlog_err(\"fio: failed parsing time %s\\n\", optarg);\n\t\t\t\tdo_exit++;\n\t\t\t\texit_val = 1;\n\t\t\t}\n\t\t\ttrigger_timeout /= 1000000;\n\t\t\tbreak;\n\n\t\tcase 'A':\n\t\t\tdid_arg = true;\n\t\t\tmerge_blktrace_only = true;\n\t\t\tbreak;\n\t\tcase '?':\n\t\t\tlog_err(\"%s: unrecognized option '%s'\\n\", argv[0],\n\t\t\t\t\t\t\targv[optind - 1]);\n\t\t\tshow_closest_option(argv[optind - 1]);\n\t\t\tfio_fallthrough;\n\t\tdefault:\n\t\t\tdo_exit++;\n\t\t\texit_val = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (do_exit)\n\t\t\tbreak;\n\t}\n\n\tif (do_exit && !(is_backend || nr_clients))\n\t\texit(exit_val);\n\n\tif (nr_clients && fio_clients_connect())\n\t\texit(1);\n\n\tif (is_backend && backend)\n\t\treturn fio_start_server(pid_file);\n\telse if (pid_file)\n\t\tfree(pid_file);\n\n\tif (td) {\n\t\tif (!ret) {\n\t\t\tret = add_job(td, td->o.name ?: \"fio\", 0, 0, client_type);\n\t\t\tif (ret)\n\t\t\t\texit(1);\n\t\t}\n\t}\n\n\twhile (!ret && optind < argc) {\n\t\tini_idx++;\n\t\tini_file = realloc(ini_file, ini_idx * sizeof(char *));\n\t\tini_file[ini_idx - 1] = strdup(argv[optind]);\n\t\toptind++;\n\t}\n\nout_free:\n\treturn ini_idx;\n}\n\nint fio_init_options(void)\n{\n\tf_out = stdout;\n\tf_err = stderr;\n\n\tfio_options_fill_optstring();\n\tfio_options_dup_and_init(l_opts);\n\n\tatexit(free_shm);\n\n\tif (fill_def_thread())\n\t\treturn 1;\n\n\treturn 0;\n}\n\nextern int fio_check_options(struct thread_options *);\n\nint parse_options(int argc, char *argv[])\n{\n\tconst int type = FIO_CLIENT_TYPE_CLI;\n\tint job_files, i;\n\n\tif (fio_init_options())\n\t\treturn 1;\n\tif (fio_test_cconv(&def_thread.o))\n\t\tlog_err(\"fio: failed internal cconv test\\n\");\n\n\tjob_files = parse_cmd_line(argc, argv, type);\n\n\tif (job_files > 0) {\n\t\tfor (i = 0; i < job_files; i++) {\n\t\t\tif (i && fill_def_thread())\n\t\t\t\treturn 1;\n\t\t\tif (nr_clients) {\n\t\t\t\tif (fio_clients_send_ini(ini_file[i]))\n\t\t\t\t\treturn 1;\n\t\t\t\tfree(ini_file[i]);\n\t\t\t} else if (!is_backend) {\n\t\t\t\tif (parse_jobs_ini(ini_file[i], 0, i, type))\n\t\t\t\t\treturn 1;\n\t\t\t\tfree(ini_file[i]);\n\t\t\t}\n\t\t}\n\t} else if (nr_clients) {\n\t\tif (fill_def_thread())\n\t\t\treturn 1;\n\t\tif (fio_clients_send_ini(NULL))\n\t\t\treturn 1;\n\t}\n\n\tfree(ini_file);\n\tfio_options_free(&def_thread);\n\tfilesetup_mem_free();\n\n\tif (!thread_number) {\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\tif (exec_profile)\n\t\t\treturn 0;\n\t\tif (is_backend || nr_clients)\n\t\t\treturn 0;\n\t\tif (did_arg)\n\t\t\treturn 0;\n\n\t\tlog_err(\"No job(s) defined\\n\\n\");\n\t\tusage(argv[0]);\n\t\treturn 1;\n\t}\n\n\tif (output_format & FIO_OUTPUT_NORMAL)\n\t\tlog_info(\"%s\\n\", fio_version_string);\n\n\treturn 0;\n}\n\nvoid options_default_fill(struct thread_options *o)\n{\n\tmemcpy(o, &def_thread.o, sizeof(*o));\n}\n\nstruct thread_data *get_global_options(void)\n{\n\treturn &def_thread;\n}\n"
        },
        {
          "name": "io_ddir.h",
          "type": "blob",
          "size": 2.2275390625,
          "content": "#ifndef FIO_DDIR_H\n#define FIO_DDIR_H\n\nenum fio_ddir {\n\tDDIR_READ = 0,\n\tDDIR_WRITE = 1,\n\tDDIR_TRIM = 2,\n\tDDIR_SYNC = 3,\n\tDDIR_DATASYNC,\n\tDDIR_SYNC_FILE_RANGE,\n\tDDIR_WAIT,\n\tDDIR_LAST,\n\tDDIR_INVAL = -1,\n\tDDIR_TIMEOUT = -2,\n\n\tDDIR_RWDIR_CNT = 3,\n\tDDIR_RWDIR_SYNC_CNT = 4,\n};\n\n#define for_each_rw_ddir(ddir)\tfor (enum fio_ddir ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++)\n\nstatic inline const char *io_ddir_name(enum fio_ddir ddir)\n{\n\tstatic const char *name[] = { \"read\", \"write\", \"trim\", \"sync\",\n\t\t\t\t\t\"datasync\", \"sync_file_range\",\n\t\t\t\t\t\"wait\", };\n\n\tif (ddir >= 0 && ddir < DDIR_LAST)\n\t\treturn name[ddir];\n\n\treturn \"invalid\";\n}\n\nenum td_ddir {\n\tTD_DDIR_READ\t\t= 1 << 0,\n\tTD_DDIR_WRITE\t\t= 1 << 1,\n\tTD_DDIR_RAND\t\t= 1 << 2,\n\tTD_DDIR_TRIM\t\t= 1 << 3,\n\tTD_DDIR_RW\t\t= TD_DDIR_READ | TD_DDIR_WRITE,\n\tTD_DDIR_RANDREAD\t= TD_DDIR_READ | TD_DDIR_RAND,\n\tTD_DDIR_RANDWRITE\t= TD_DDIR_WRITE | TD_DDIR_RAND,\n\tTD_DDIR_RANDRW\t\t= TD_DDIR_RW | TD_DDIR_RAND,\n\tTD_DDIR_RANDTRIM\t= TD_DDIR_TRIM | TD_DDIR_RAND,\n\tTD_DDIR_TRIMWRITE\t= TD_DDIR_TRIM | TD_DDIR_WRITE,\n\tTD_DDIR_RANDTRIMWRITE\t= TD_DDIR_RANDTRIM | TD_DDIR_WRITE,\n};\n\n#define td_read(td)\t\t((td)->o.td_ddir & TD_DDIR_READ)\n#define td_write(td)\t\t((td)->o.td_ddir & TD_DDIR_WRITE)\n#define td_trim(td)\t\t((td)->o.td_ddir & TD_DDIR_TRIM)\n#define td_rw(td)\t\t(((td)->o.td_ddir & TD_DDIR_RW) == TD_DDIR_RW)\n#define td_random(td)\t\t((td)->o.td_ddir & TD_DDIR_RAND)\n#define file_randommap(td, f)\t(!(td)->o.norandommap && fio_file_axmap((f)))\n#define td_trimwrite(td)\t(((td)->o.td_ddir & TD_DDIR_TRIMWRITE) \\\n\t\t\t\t\t== TD_DDIR_TRIMWRITE)\n#define td_randtrimwrite(td)\t(((td)->o.td_ddir & TD_DDIR_RANDTRIMWRITE) \\\n\t\t\t\t\t== TD_DDIR_RANDTRIMWRITE)\n\nstatic inline int ddir_sync(enum fio_ddir ddir)\n{\n\treturn ddir == DDIR_SYNC || ddir == DDIR_DATASYNC ||\n\t       ddir == DDIR_SYNC_FILE_RANGE;\n}\n\nstatic inline int ddir_rw(enum fio_ddir ddir)\n{\n\treturn ddir == DDIR_READ || ddir == DDIR_WRITE || ddir == DDIR_TRIM;\n}\n\nstatic inline const char *ddir_str(enum td_ddir ddir)\n{\n\tstatic const char *__str[] = { NULL, \"read\", \"write\", \"rw\", \"rand\",\n\t\t\t\t\"randread\", \"randwrite\", \"randrw\",\n\t\t\t\t\"trim\", NULL, \"trimwrite\", NULL, \"randtrim\",\n\t\t\t\tNULL, \"randtrimwrite\" };\n\n\treturn __str[ddir];\n}\n\n#define ddir_rw_sum(arr)\t\\\n\t((arr)[DDIR_READ] + (arr)[DDIR_WRITE] + (arr)[DDIR_TRIM])\n\n#endif\n"
        },
        {
          "name": "io_u.c",
          "type": "blob",
          "size": 55.5400390625,
          "content": "#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n\n#include \"fio.h\"\n#include \"verify.h\"\n#include \"trim.h\"\n#include \"lib/rand.h\"\n#include \"lib/axmap.h\"\n#include \"err.h\"\n#include \"lib/pow2.h\"\n#include \"minmax.h\"\n#include \"zbd.h\"\n\nstruct io_completion_data {\n\tint nr;\t\t\t\t/* input */\n\n\tint error;\t\t\t/* output */\n\tuint64_t bytes_done[DDIR_RWDIR_CNT];\t/* output */\n\tstruct timespec time;\t\t/* output */\n};\n\n/*\n * The ->io_axmap contains a map of blocks we have or have not done io\n * to yet. Used to make sure we cover the entire range in a fair fashion.\n */\nstatic bool random_map_free(struct fio_file *f, const uint64_t block)\n{\n\treturn !axmap_isset(f->io_axmap, block);\n}\n\n/*\n * Mark a given offset as used in the map.\n */\nstatic uint64_t mark_random_map(struct thread_data *td, struct io_u *io_u,\n\t\t\t\tuint64_t offset, uint64_t buflen)\n{\n\tunsigned long long min_bs = td->o.min_bs[io_u->ddir];\n\tstruct fio_file *f = io_u->file;\n\tunsigned long long nr_blocks;\n\tuint64_t block;\n\n\tblock = (offset - f->file_offset) / (uint64_t) min_bs;\n\tnr_blocks = (buflen + min_bs - 1) / min_bs;\n\tassert(nr_blocks > 0);\n\n\tif (!(io_u->flags & IO_U_F_BUSY_OK)) {\n\t\tnr_blocks = axmap_set_nr(f->io_axmap, block, nr_blocks);\n\t\tassert(nr_blocks > 0);\n\t}\n\n\tif ((nr_blocks * min_bs) < buflen)\n\t\tbuflen = nr_blocks * min_bs;\n\n\treturn buflen;\n}\n\nstatic uint64_t last_block(struct thread_data *td, struct fio_file *f,\n\t\t\t   enum fio_ddir ddir)\n{\n\tuint64_t max_blocks;\n\tuint64_t max_size;\n\n\tassert(ddir_rw(ddir));\n\n\t/*\n\t * Hmm, should we make sure that ->io_size <= ->real_file_size?\n\t * -> not for now since there is code assuming it could go either.\n\t */\n\tmax_size = f->io_size;\n\tif (max_size > f->real_file_size)\n\t\tmax_size = f->real_file_size;\n\n\tif (td->o.zone_mode == ZONE_MODE_STRIDED && td->o.zone_range)\n\t\tmax_size = td->o.zone_range;\n\n\tif (td->o.min_bs[ddir] > td->o.ba[ddir])\n\t\tmax_size -= td->o.min_bs[ddir] - td->o.ba[ddir];\n\n\tmax_blocks = max_size / (uint64_t) td->o.ba[ddir];\n\tif (!max_blocks)\n\t\treturn 0;\n\n\treturn max_blocks;\n}\n\nstatic int __get_next_rand_offset(struct thread_data *td, struct fio_file *f,\n\t\t\t\t  enum fio_ddir ddir, uint64_t *b,\n\t\t\t\t  uint64_t lastb)\n{\n\tuint64_t r;\n\n\tif (td->o.random_generator == FIO_RAND_GEN_TAUSWORTHE ||\n\t    td->o.random_generator == FIO_RAND_GEN_TAUSWORTHE64) {\n\n\t\tr = __rand(&td->random_state);\n\n\t\tdprint(FD_RANDOM, \"off rand %llu\\n\", (unsigned long long) r);\n\n\t\t*b = lastb * (r / (rand_max(&td->random_state) + 1.0));\n\t} else {\n\t\tuint64_t off = 0;\n\n\t\tassert(fio_file_lfsr(f));\n\n\t\tif (lfsr_next(&f->lfsr, &off))\n\t\t\treturn 1;\n\n\t\t*b = off;\n\t}\n\n\t/*\n\t * if we are not maintaining a random map, we are done.\n\t */\n\tif (!file_randommap(td, f))\n\t\tgoto ret;\n\n\t/*\n\t * calculate map offset and check if it's free\n\t */\n\tif (random_map_free(f, *b))\n\t\tgoto ret;\n\n\tdprint(FD_RANDOM, \"get_next_rand_offset: offset %llu busy\\n\",\n\t\t\t\t\t\t(unsigned long long) *b);\n\n\t*b = axmap_next_free(f->io_axmap, *b);\n\tif (*b == (uint64_t) -1ULL)\n\t\treturn 1;\nret:\n\treturn 0;\n}\n\nstatic int __get_next_rand_offset_zipf(struct thread_data *td,\n\t\t\t\t       struct fio_file *f, enum fio_ddir ddir,\n\t\t\t\t       uint64_t *b)\n{\n\t*b = zipf_next(&f->zipf);\n\treturn 0;\n}\n\nstatic int __get_next_rand_offset_pareto(struct thread_data *td,\n\t\t\t\t\t struct fio_file *f, enum fio_ddir ddir,\n\t\t\t\t\t uint64_t *b)\n{\n\t*b = pareto_next(&f->zipf);\n\treturn 0;\n}\n\nstatic int __get_next_rand_offset_gauss(struct thread_data *td,\n\t\t\t\t\tstruct fio_file *f, enum fio_ddir ddir,\n\t\t\t\t\tuint64_t *b)\n{\n\t*b = gauss_next(&f->gauss);\n\treturn 0;\n}\n\nstatic int __get_next_rand_offset_zoned_abs(struct thread_data *td,\n\t\t\t\t\t    struct fio_file *f,\n\t\t\t\t\t    enum fio_ddir ddir, uint64_t *b)\n{\n\tstruct zone_split_index *zsi;\n\tuint64_t lastb, send, stotal;\n\tunsigned int v;\n\n\tlastb = last_block(td, f, ddir);\n\tif (!lastb)\n\t\treturn 1;\n\n\tif (!td->o.zone_split_nr[ddir]) {\nbail:\n\t\treturn __get_next_rand_offset(td, f, ddir, b, lastb);\n\t}\n\n\t/*\n\t * Generate a value, v, between 1 and 100, both inclusive\n\t */\n\tv = rand_between(&td->zone_state, 1, 100);\n\n\t/*\n\t * Find our generated table. 'send' is the end block of this zone,\n\t * 'stotal' is our start offset.\n\t */\n\tzsi = &td->zone_state_index[ddir][v - 1];\n\tstotal = zsi->size_prev / td->o.ba[ddir];\n\tsend = zsi->size / td->o.ba[ddir];\n\n\t/*\n\t * Should never happen\n\t */\n\tif (send == -1U) {\n\t\tif (!fio_did_warn(FIO_WARN_ZONED_BUG))\n\t\t\tlog_err(\"fio: bug in zoned generation\\n\");\n\t\tgoto bail;\n\t} else if (send > lastb) {\n\t\t/*\n\t\t * This happens if the user specifies ranges that exceed\n\t\t * the file/device size. We can't handle that gracefully,\n\t\t * so error and exit.\n\t\t */\n\t\tlog_err(\"fio: zoned_abs sizes exceed file size\\n\");\n\t\treturn 1;\n\t}\n\n\t/*\n\t * Generate index from 0..send-stotal\n\t */\n\tif (__get_next_rand_offset(td, f, ddir, b, send - stotal) == 1)\n\t\treturn 1;\n\n\t*b += stotal;\n\treturn 0;\n}\n\nstatic int __get_next_rand_offset_zoned(struct thread_data *td,\n\t\t\t\t\tstruct fio_file *f, enum fio_ddir ddir,\n\t\t\t\t\tuint64_t *b)\n{\n\tunsigned int v, send, stotal;\n\tuint64_t offset, lastb;\n\tstruct zone_split_index *zsi;\n\n\tlastb = last_block(td, f, ddir);\n\tif (!lastb)\n\t\treturn 1;\n\n\tif (!td->o.zone_split_nr[ddir]) {\nbail:\n\t\treturn __get_next_rand_offset(td, f, ddir, b, lastb);\n\t}\n\n\t/*\n\t * Generate a value, v, between 1 and 100, both inclusive\n\t */\n\tv = rand_between(&td->zone_state, 1, 100);\n\n\tzsi = &td->zone_state_index[ddir][v - 1];\n\tstotal = zsi->size_perc_prev;\n\tsend = zsi->size_perc;\n\n\t/*\n\t * Should never happen\n\t */\n\tif (send == -1U) {\n\t\tif (!fio_did_warn(FIO_WARN_ZONED_BUG))\n\t\t\tlog_err(\"fio: bug in zoned generation\\n\");\n\t\tgoto bail;\n\t}\n\n\t/*\n\t * 'send' is some percentage below or equal to 100 that\n\t * marks the end of the current IO range. 'stotal' marks\n\t * the start, in percent.\n\t */\n\tif (stotal)\n\t\toffset = stotal * lastb / 100ULL;\n\telse\n\t\toffset = 0;\n\n\tlastb = lastb * (send - stotal) / 100ULL;\n\n\t/*\n\t * Generate index from 0..send-of-lastb\n\t */\n\tif (__get_next_rand_offset(td, f, ddir, b, lastb) == 1)\n\t\treturn 1;\n\n\t/*\n\t * Add our start offset, if any\n\t */\n\tif (offset)\n\t\t*b += offset;\n\n\treturn 0;\n}\n\nstatic int get_next_rand_offset(struct thread_data *td, struct fio_file *f,\n\t\t\t\tenum fio_ddir ddir, uint64_t *b)\n{\n\tif (td->o.random_distribution == FIO_RAND_DIST_RANDOM) {\n\t\tuint64_t lastb;\n\n\t\tlastb = last_block(td, f, ddir);\n\t\tif (!lastb)\n\t\t\treturn 1;\n\n\t\treturn __get_next_rand_offset(td, f, ddir, b, lastb);\n\t} else if (td->o.random_distribution == FIO_RAND_DIST_ZIPF)\n\t\treturn __get_next_rand_offset_zipf(td, f, ddir, b);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_PARETO)\n\t\treturn __get_next_rand_offset_pareto(td, f, ddir, b);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_GAUSS)\n\t\treturn __get_next_rand_offset_gauss(td, f, ddir, b);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_ZONED)\n\t\treturn __get_next_rand_offset_zoned(td, f, ddir, b);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_ZONED_ABS)\n\t\treturn __get_next_rand_offset_zoned_abs(td, f, ddir, b);\n\n\tlog_err(\"fio: unknown random distribution: %d\\n\", td->o.random_distribution);\n\treturn 1;\n}\n\nstatic bool should_do_random(struct thread_data *td, enum fio_ddir ddir)\n{\n\tunsigned int v;\n\n\tif (td->o.perc_rand[ddir] == 100)\n\t\treturn true;\n\n\tv = rand_between(&td->seq_rand_state[ddir], 1, 100);\n\n\treturn v <= td->o.perc_rand[ddir];\n}\n\nstatic void loop_cache_invalidate(struct thread_data *td, struct fio_file *f)\n{\n\tstruct thread_options *o = &td->o;\n\n\tif (o->invalidate_cache && !o->odirect) {\n\t\tint fio_unused ret;\n\n\t\tret = file_invalidate_cache(td, f);\n\t}\n}\n\nstatic int get_next_rand_block(struct thread_data *td, struct fio_file *f,\n\t\t\t       enum fio_ddir ddir, uint64_t *b)\n{\n\tif (!get_next_rand_offset(td, f, ddir, b))\n\t\treturn 0;\n\n\tif (td->o.time_based ||\n\t    (td->o.file_service_type & __FIO_FSERVICE_NONUNIFORM)) {\n\t\tfio_file_reset(td, f);\n\t\tloop_cache_invalidate(td, f);\n\t\tif (!get_next_rand_offset(td, f, ddir, b))\n\t\t\treturn 0;\n\t}\n\n\tdprint(FD_IO, \"%s: rand offset failed, last=%llu, size=%llu\\n\",\n\t\t\tf->file_name, (unsigned long long) f->last_pos[ddir],\n\t\t\t(unsigned long long) f->real_file_size);\n\treturn 1;\n}\n\nstatic int get_next_seq_offset(struct thread_data *td, struct fio_file *f,\n\t\t\t       enum fio_ddir ddir, uint64_t *offset)\n{\n\tstruct thread_options *o = &td->o;\n\n\tassert(ddir_rw(ddir));\n\n\t/*\n\t * If we reach the end for a time based run, reset us back to 0\n\t * and invalidate the cache, if we need to.\n\t */\n\tif (f->last_pos[ddir] >= f->io_size + get_start_offset(td, f) &&\n\t    o->time_based && o->nr_files == 1) {\n\t\tf->last_pos[ddir] = f->file_offset;\n\t\tloop_cache_invalidate(td, f);\n\t}\n\n\t/*\n\t * If we reach the end for a rw-io-size based run, reset us back to 0\n\t * and invalidate the cache, if we need to.\n\t */\n\tif (td_rw(td) && o->io_size > o->size) {\n\t\tif (f->last_pos[ddir] >= f->io_size + get_start_offset(td, f)) {\n\t\t\tf->last_pos[ddir] = f->file_offset;\n\t\t\tloop_cache_invalidate(td, f);\n\t\t}\n        }\n\n\tif (f->last_pos[ddir] < f->real_file_size) {\n\t\tuint64_t pos;\n\n\t\t/*\n\t\t * Only rewind if we already hit the end\n\t\t */\n\t\tif (f->last_pos[ddir] == f->file_offset &&\n\t\t    f->file_offset && o->ddir_seq_add < 0) {\n\t\t\tif (f->real_file_size > f->io_size)\n\t\t\t\tf->last_pos[ddir] = f->io_size;\n\t\t\telse\n\t\t\t\tf->last_pos[ddir] = f->real_file_size;\n\t\t}\n\n\t\tpos = f->last_pos[ddir] - f->file_offset;\n\t\tif (pos && o->ddir_seq_add) {\n\t\t\tpos += o->ddir_seq_add;\n\n\t\t\t/*\n\t\t\t * If we reach beyond the end of the file\n\t\t\t * with holed IO, wrap around to the\n\t\t\t * beginning again. If we're doing backwards IO,\n\t\t\t * wrap to the end.\n\t\t\t */\n\t\t\tif (pos >= f->real_file_size) {\n\t\t\t\tif (o->ddir_seq_add > 0)\n\t\t\t\t\tpos = f->file_offset;\n\t\t\t\telse {\n\t\t\t\t\tif (f->real_file_size > f->io_size)\n\t\t\t\t\t\tpos = f->io_size;\n\t\t\t\t\telse\n\t\t\t\t\t\tpos = f->real_file_size;\n\n\t\t\t\t\tpos += o->ddir_seq_add;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t*offset = pos;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic int get_next_block(struct thread_data *td, struct io_u *io_u,\n\t\t\t  enum fio_ddir ddir, int rw_seq,\n\t\t\t  bool *is_random)\n{\n\tstruct fio_file *f = io_u->file;\n\tuint64_t b, offset;\n\tint ret;\n\n\tassert(ddir_rw(ddir));\n\n\tb = offset = -1ULL;\n\n\tif (td_randtrimwrite(td) && ddir == DDIR_WRITE) {\n\t\t/* don't mark randommap for these writes */\n\t\tio_u_set(td, io_u, IO_U_F_BUSY_OK);\n\t\toffset = f->last_start[DDIR_TRIM];\n\t\t*is_random = true;\n\t\tret = 0;\n\t} else if (rw_seq) {\n\t\tif (td_random(td)) {\n\t\t\tif (should_do_random(td, ddir)) {\n\t\t\t\tret = get_next_rand_block(td, f, ddir, &b);\n\t\t\t\t*is_random = true;\n\t\t\t} else {\n\t\t\t\t*is_random = false;\n\t\t\t\tio_u_set(td, io_u, IO_U_F_BUSY_OK);\n\t\t\t\tret = get_next_seq_offset(td, f, ddir, &offset);\n\t\t\t\tif (ret)\n\t\t\t\t\tret = get_next_rand_block(td, f, ddir, &b);\n\t\t\t}\n\t\t} else {\n\t\t\t*is_random = false;\n\t\t\tret = get_next_seq_offset(td, f, ddir, &offset);\n\t\t}\n\t} else {\n\t\tio_u_set(td, io_u, IO_U_F_BUSY_OK);\n\t\t*is_random = false;\n\n\t\tif (td->o.rw_seq == RW_SEQ_SEQ) {\n\t\t\tret = get_next_seq_offset(td, f, ddir, &offset);\n\t\t\tif (ret) {\n\t\t\t\tret = get_next_rand_block(td, f, ddir, &b);\n\t\t\t\t*is_random = false;\n\t\t\t}\n\t\t} else if (td->o.rw_seq == RW_SEQ_IDENT) {\n\t\t\tif (f->last_start[ddir] != -1ULL)\n\t\t\t\toffset = f->last_start[ddir] - f->file_offset;\n\t\t\telse\n\t\t\t\toffset = 0;\n\t\t\tret = 0;\n\t\t} else {\n\t\t\tlog_err(\"fio: unknown rw_seq=%d\\n\", td->o.rw_seq);\n\t\t\tret = 1;\n\t\t}\n\t}\n\n\tif (!ret) {\n\t\tif (offset != -1ULL)\n\t\t\tio_u->offset = offset;\n\t\telse if (b != -1ULL)\n\t\t\tio_u->offset = b * td->o.ba[ddir];\n\t\telse {\n\t\t\tlog_err(\"fio: bug in offset generation: offset=%llu, b=%llu\\n\", (unsigned long long) offset, (unsigned long long) b);\n\t\t\tret = 1;\n\t\t}\n\t\tio_u->verify_offset = io_u->offset;\n\t}\n\n\treturn ret;\n}\n\n/*\n * For random io, generate a random new block and see if it's used. Repeat\n * until we find a free one. For sequential io, just return the end of\n * the last io issued.\n */\nstatic int get_next_offset(struct thread_data *td, struct io_u *io_u,\n\t\t\t   bool *is_random)\n{\n\tstruct fio_file *f = io_u->file;\n\tenum fio_ddir ddir = io_u->ddir;\n\tint rw_seq_hit = 0;\n\n\tassert(ddir_rw(ddir));\n\n\tif (td->o.ddir_seq_nr && !--td->ddir_seq_nr) {\n\t\trw_seq_hit = 1;\n\t\ttd->ddir_seq_nr = td->o.ddir_seq_nr;\n\t}\n\n\tif (get_next_block(td, io_u, ddir, rw_seq_hit, is_random))\n\t\treturn 1;\n\n\tif (io_u->offset >= f->io_size) {\n\t\tdprint(FD_IO, \"get_next_offset: offset %llu >= io_size %llu\\n\",\n\t\t\t\t\t(unsigned long long) io_u->offset,\n\t\t\t\t\t(unsigned long long) f->io_size);\n\t\treturn 1;\n\t}\n\n\tio_u->offset += f->file_offset;\n\tif (io_u->offset >= f->real_file_size) {\n\t\tdprint(FD_IO, \"get_next_offset: offset %llu >= size %llu\\n\",\n\t\t\t\t\t(unsigned long long) io_u->offset,\n\t\t\t\t\t(unsigned long long) f->real_file_size);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * For randtrimwrite, we decide whether to issue a trim or a write\n\t * based on whether the offsets for the most recent trim and write\n\t * operations match. If they don't match that means we just issued a\n\t * new trim and the next operation should be a write. If they *do*\n\t * match that means we just completed a trim+write pair and the next\n\t * command should be a trim.\n\t *\n\t * This works fine for sequential workloads but for random workloads\n\t * it's possible to complete a trim+write pair and then have the next\n\t * randomly generated offset match the previous offset. If that happens\n\t * we need to alter the offset for the last write operation in order\n\t * to ensure that we issue a write operation the next time through.\n\t */\n\tif (td_randtrimwrite(td) && ddir == DDIR_TRIM &&\n\t    f->last_start[DDIR_TRIM] == io_u->offset)\n\t\tf->last_start[DDIR_WRITE]--;\n\n\tio_u->verify_offset = io_u->offset;\n\treturn 0;\n}\n\nstatic inline bool io_u_fits(struct thread_data *td, struct io_u *io_u,\n\t\t\t     unsigned long long buflen)\n{\n\tstruct fio_file *f = io_u->file;\n\n\treturn io_u->offset + buflen <= f->io_size + get_start_offset(td, f);\n}\n\nstatic unsigned long long get_next_buflen(struct thread_data *td, struct io_u *io_u,\n\t\t\t\t    bool is_random)\n{\n\tint ddir = io_u->ddir;\n\tunsigned long long buflen = 0;\n\tunsigned long long minbs, maxbs;\n\tuint64_t frand_max, r;\n\tbool power_2;\n\n\tassert(ddir_rw(ddir));\n\n\tif (td_randtrimwrite(td) && ddir == DDIR_WRITE) {\n\t\tstruct fio_file *f = io_u->file;\n\n\t\treturn f->last_pos[DDIR_TRIM] - f->last_start[DDIR_TRIM];\n\t}\n\n\tif (td->o.bs_is_seq_rand)\n\t\tddir = is_random ? DDIR_WRITE : DDIR_READ;\n\n\tminbs = td->o.min_bs[ddir];\n\tmaxbs = td->o.max_bs[ddir];\n\n\tif (minbs == maxbs)\n\t\treturn minbs;\n\n\t/*\n\t * If we can't satisfy the min block size from here, then fail\n\t */\n\tif (!io_u_fits(td, io_u, minbs))\n\t\treturn 0;\n\n\tfrand_max = rand_max(&td->bsrange_state[ddir]);\n\tdo {\n\t\tr = __rand(&td->bsrange_state[ddir]);\n\n\t\tif (!td->o.bssplit_nr[ddir]) {\n\t\t\tbuflen = minbs + (unsigned long long) ((double) maxbs *\n\t\t\t\t\t(r / (frand_max + 1.0)));\n\t\t} else {\n\t\t\tlong long perc = 0;\n\t\t\tunsigned int i;\n\n\t\t\tfor (i = 0; i < td->o.bssplit_nr[ddir]; i++) {\n\t\t\t\tstruct bssplit *bsp = &td->o.bssplit[ddir][i];\n\n\t\t\t\tif (!bsp->perc)\n\t\t\t\t\tcontinue;\n\t\t\t\tbuflen = bsp->bs;\n\t\t\t\tperc += bsp->perc;\n\t\t\t\tif ((r / perc <= frand_max / 100ULL) &&\n\t\t\t\t    io_u_fits(td, io_u, buflen))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tpower_2 = is_power_of_2(minbs);\n\t\tif (!td->o.bs_unaligned && power_2)\n\t\t\tbuflen &= ~(minbs - 1);\n\t\telse if (!td->o.bs_unaligned && !power_2)\n\t\t\tbuflen -= buflen % minbs;\n\t\tif (buflen > maxbs)\n\t\t\tbuflen = maxbs;\n\t} while (!io_u_fits(td, io_u, buflen));\n\n\treturn buflen;\n}\n\nstatic void set_rwmix_bytes(struct thread_data *td)\n{\n\tunsigned int diff;\n\n\t/*\n\t * we do time or byte based switch. this is needed because\n\t * buffered writes may issue a lot quicker than they complete,\n\t * whereas reads do not.\n\t */\n\tdiff = td->o.rwmix[td->rwmix_ddir ^ 1];\n\ttd->rwmix_issues = (td->io_issues[td->rwmix_ddir] * diff) / 100;\n}\n\nstatic inline enum fio_ddir get_rand_ddir(struct thread_data *td)\n{\n\tunsigned int v;\n\n\tv = rand_between(&td->rwmix_state, 1, 100);\n\n\tif (v <= td->o.rwmix[DDIR_READ])\n\t\treturn DDIR_READ;\n\n\treturn DDIR_WRITE;\n}\n\nint io_u_quiesce(struct thread_data *td)\n{\n\tint ret = 0, completed = 0, err = 0;\n\n\t/*\n\t * We are going to sleep, ensure that we flush anything pending as\n\t * not to skew our latency numbers.\n\t *\n\t * Changed to only monitor 'in flight' requests here instead of the\n\t * td->cur_depth, b/c td->cur_depth does not accurately represent\n\t * io's that have been actually submitted to an async engine,\n\t * and cur_depth is meaningless for sync engines.\n\t */\n\tif (td->io_u_queued || td->cur_depth)\n\t\ttd_io_commit(td);\n\n\twhile (td->io_u_in_flight) {\n\t\tret = io_u_queued_complete(td, 1);\n\t\tif (ret > 0)\n\t\t\tcompleted += ret;\n\t\telse if (ret < 0)\n\t\t\terr = ret;\n\t}\n\n\tif (td->flags & TD_F_REGROW_LOGS)\n\t\tregrow_logs(td);\n\n\tif (completed)\n\t\treturn completed;\n\n\treturn err;\n}\n\nstatic enum fio_ddir rate_ddir(struct thread_data *td, enum fio_ddir ddir)\n{\n\tenum fio_ddir odir = ddir ^ 1;\n\tuint64_t usec;\n\tuint64_t now;\n\n\tassert(ddir_rw(ddir));\n\tnow = utime_since_now(&td->epoch);\n\n\t/*\n\t * if rate_next_io_time is in the past, need to catch up to rate\n\t */\n\tif (td->rate_next_io_time[ddir] <= now)\n\t\treturn ddir;\n\n\t/*\n\t * We are ahead of rate in this direction. See if we\n\t * should switch.\n\t */\n\tif (td_rw(td) && td->o.rwmix[odir]) {\n\t\t/*\n\t\t * Other direction is behind rate, switch\n\t\t */\n\t\tif (td->rate_next_io_time[odir] <= now)\n\t\t\treturn odir;\n\n\t\t/*\n\t\t * Both directions are ahead of rate. sleep the min,\n\t\t * switch if necessary\n\t\t */\n\t\tif (td->rate_next_io_time[ddir] <=\n\t\t    td->rate_next_io_time[odir]) {\n\t\t\tusec = td->rate_next_io_time[ddir] - now;\n\t\t} else {\n\t\t\tusec = td->rate_next_io_time[odir] - now;\n\t\t\tddir = odir;\n\t\t}\n\t} else\n\t\tusec = td->rate_next_io_time[ddir] - now;\n\n\tif (td->o.io_submit_mode == IO_MODE_INLINE)\n\t\tio_u_quiesce(td);\n\n\tif (td->o.timeout && ((usec + now) > td->o.timeout)) {\n\t\t/*\n\t\t * check if the usec is capable of taking negative values\n\t\t */\n\t\tif (now > td->o.timeout) {\n\t\t\tddir = DDIR_TIMEOUT;\n\t\t\treturn ddir;\n\t\t}\n\t\tusec = td->o.timeout - now;\n\t}\n\tusec_sleep(td, usec);\n\n\tnow = utime_since_now(&td->epoch);\n\tif ((td->o.timeout && (now > td->o.timeout)) || td->terminate)\n\t\tddir = DDIR_TIMEOUT;\n\n\treturn ddir;\n}\n\n/*\n * Return the data direction for the next io_u. If the job is a\n * mixed read/write workload, check the rwmix cycle and switch if\n * necessary.\n */\nstatic enum fio_ddir get_rw_ddir(struct thread_data *td)\n{\n\tenum fio_ddir ddir;\n\n\t/*\n\t * See if it's time to fsync/fdatasync/sync_file_range first,\n\t * and if not then move on to check regular I/Os.\n\t */\n\tif (should_fsync(td) && td->last_ddir_issued == DDIR_WRITE) {\n\t\tif (td->o.fsync_blocks && td->io_issues[DDIR_WRITE] &&\n\t\t    !(td->io_issues[DDIR_WRITE] % td->o.fsync_blocks))\n\t\t\treturn DDIR_SYNC;\n\n\t\tif (td->o.fdatasync_blocks && td->io_issues[DDIR_WRITE] &&\n\t\t    !(td->io_issues[DDIR_WRITE] % td->o.fdatasync_blocks))\n\t\t\treturn DDIR_DATASYNC;\n\n\t\tif (td->sync_file_range_nr && td->io_issues[DDIR_WRITE] &&\n\t\t    !(td->io_issues[DDIR_WRITE] % td->sync_file_range_nr))\n\t\t\treturn DDIR_SYNC_FILE_RANGE;\n\t}\n\n\tif (td_rw(td)) {\n\t\t/*\n\t\t * Check if it's time to seed a new data direction.\n\t\t */\n\t\tif (td->io_issues[td->rwmix_ddir] >= td->rwmix_issues) {\n\t\t\t/*\n\t\t\t * Put a top limit on how many bytes we do for\n\t\t\t * one data direction, to avoid overflowing the\n\t\t\t * ranges too much\n\t\t\t */\n\t\t\tddir = get_rand_ddir(td);\n\n\t\t\tif (ddir != td->rwmix_ddir)\n\t\t\t\tset_rwmix_bytes(td);\n\n\t\t\ttd->rwmix_ddir = ddir;\n\t\t}\n\t\tddir = td->rwmix_ddir;\n\t} else if (td_read(td))\n\t\tddir = DDIR_READ;\n\telse if (td_write(td))\n\t\tddir = DDIR_WRITE;\n\telse if (td_trim(td))\n\t\tddir = DDIR_TRIM;\n\telse\n\t\tddir = DDIR_INVAL;\n\n\tif (!should_check_rate(td)) {\n\t\t/*\n\t\t * avoid time-consuming call to utime_since_now() if rate checking\n\t\t * isn't being used. this imrpoves IOPs 50%. See:\n\t\t * https://github.com/axboe/fio/issues/1501#issuecomment-1418327049\n\t\t */\n\t\ttd->rwmix_ddir = ddir;\n\t} else\n\t\ttd->rwmix_ddir = rate_ddir(td, ddir);\n\treturn td->rwmix_ddir;\n}\n\nstatic void set_rw_ddir(struct thread_data *td, struct io_u *io_u)\n{\n\tenum fio_ddir ddir = get_rw_ddir(td);\n\n\tif (td->o.zone_mode == ZONE_MODE_ZBD)\n\t\tddir = zbd_adjust_ddir(td, io_u, ddir);\n\n\tif (td_trimwrite(td) && !ddir_sync(ddir)) {\n\t\tstruct fio_file *f = io_u->file;\n\t\tif (f->last_start[DDIR_WRITE] == f->last_start[DDIR_TRIM])\n\t\t\tddir = DDIR_TRIM;\n\t\telse\n\t\t\tddir = DDIR_WRITE;\n\t}\n\n\tio_u->ddir = io_u->acct_ddir = ddir;\n\n\tif (io_u->ddir == DDIR_WRITE && td_ioengine_flagged(td, FIO_BARRIER) &&\n\t    td->o.barrier_blocks &&\n\t   !(td->io_issues[DDIR_WRITE] % td->o.barrier_blocks) &&\n\t     td->io_issues[DDIR_WRITE])\n\t\tio_u_set(td, io_u, IO_U_F_BARRIER);\n}\n\nvoid put_file_log(struct thread_data *td, struct fio_file *f)\n{\n\tunsigned int ret = put_file(td, f);\n\n\tif (ret)\n\t\ttd_verror(td, ret, \"file close\");\n}\n\nvoid put_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\n\tzbd_put_io_u(td, io_u);\n\n\tif (td->parent)\n\t\ttd = td->parent;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tif (io_u->file && !(io_u->flags & IO_U_F_NO_FILE_PUT))\n\t\tput_file_log(td, io_u->file);\n\n\tio_u->file = NULL;\n\tio_u_set(td, io_u, IO_U_F_FREE);\n\n\tif (io_u->flags & IO_U_F_IN_CUR_DEPTH) {\n\t\ttd->cur_depth--;\n\t\tassert(!(td->flags & TD_F_CHILD));\n\t}\n\tio_u_qpush(&td->io_u_freelist, io_u);\n\ttd_io_u_free_notify(td);\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nvoid clear_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tio_u_clear(td, io_u, IO_U_F_FLIGHT);\n\tput_io_u(td, io_u);\n}\n\nvoid requeue_io_u(struct thread_data *td, struct io_u **io_u)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct io_u *__io_u = *io_u;\n\tenum fio_ddir ddir = acct_ddir(__io_u);\n\n\tdprint(FD_IO, \"requeue %p\\n\", __io_u);\n\n\tif (td->parent)\n\t\ttd = td->parent;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tio_u_set(td, __io_u, IO_U_F_FREE);\n\tif ((__io_u->flags & IO_U_F_FLIGHT) && ddir_rw(ddir))\n\t\ttd->io_issues[ddir]--;\n\n\tio_u_clear(td, __io_u, IO_U_F_FLIGHT);\n\tif (__io_u->flags & IO_U_F_IN_CUR_DEPTH) {\n\t\ttd->cur_depth--;\n\t\tassert(!(td->flags & TD_F_CHILD));\n\t}\n\n\tio_u_rpush(&td->io_u_requeues, __io_u);\n\ttd_io_u_free_notify(td);\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n\n\t*io_u = NULL;\n}\n\nstatic void setup_strided_zone_mode(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f = io_u->file;\n\n\tassert(td->o.zone_mode == ZONE_MODE_STRIDED);\n\tassert(td->o.zone_size);\n\tassert(td->o.zone_range);\n\n\t/*\n\t * See if it's time to switch to a new zone\n\t */\n\tif (td->zone_bytes >= td->o.zone_size) {\n\t\ttd->zone_bytes = 0;\n\t\tf->file_offset += td->o.zone_range + td->o.zone_skip;\n\n\t\t/*\n\t\t * Wrap from the beginning, if we exceed the file size\n\t\t */\n\t\tif (f->file_offset >= f->real_file_size)\n\t\t\tf->file_offset = get_start_offset(td, f);\n\n\t\tf->last_pos[io_u->ddir] = f->file_offset;\n\t\ttd->io_skip_bytes += td->o.zone_skip;\n\t}\n\n\t/*\n\t * If zone_size > zone_range, then maintain the same zone until\n\t * zone_bytes >= zone_size.\n\t */\n\tif (f->last_pos[io_u->ddir] >= (f->file_offset + td->o.zone_range)) {\n\t\tdprint(FD_IO, \"io_u maintain zone offset=%\" PRIu64 \"/last_pos=%\" PRIu64 \"\\n\",\n\t\t\t\tf->file_offset, f->last_pos[io_u->ddir]);\n\t\tf->last_pos[io_u->ddir] = f->file_offset;\n\t}\n\n\t/*\n\t * For random: if 'norandommap' is not set and zone_size > zone_range,\n\t * map needs to be reset as it's done with zone_range everytime.\n\t */\n\tif ((td->zone_bytes % td->o.zone_range) == 0)\n\t\tfio_file_reset(td, f);\n}\n\nstatic int fill_multi_range_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tbool is_random;\n\tuint64_t buflen, i = 0;\n\tstruct trim_range *range;\n\tstruct fio_file *f = io_u->file;\n\tuint8_t *buf;\n\n\tbuf = io_u->buf;\n\tbuflen = 0;\n\n\twhile (i < td->o.num_range) {\n\t\trange = (struct trim_range *)buf;\n\t\tif (get_next_offset(td, io_u, &is_random)) {\n\t\t\tdprint(FD_IO, \"io_u %p, failed getting offset\\n\",\n\t\t\t       io_u);\n\t\t\tbreak;\n\t\t}\n\n\t\tio_u->buflen = get_next_buflen(td, io_u, is_random);\n\t\tif (!io_u->buflen) {\n\t\t\tdprint(FD_IO, \"io_u %p, failed getting buflen\\n\", io_u);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (io_u->offset + io_u->buflen > io_u->file->real_file_size) {\n\t\t\tdprint(FD_IO, \"io_u %p, off=0x%llx + len=0x%llx exceeds file size=0x%llx\\n\",\n\t\t\t       io_u,\n\t\t\t       (unsigned long long) io_u->offset, io_u->buflen,\n\t\t\t       (unsigned long long) io_u->file->real_file_size);\n\t\t\tbreak;\n\t\t}\n\n\t\trange->start = io_u->offset;\n\t\trange->len = io_u->buflen;\n\t\tbuflen += io_u->buflen;\n\t\tf->last_start[io_u->ddir] = io_u->offset;\n\t\tf->last_pos[io_u->ddir] = io_u->offset + range->len;\n\n\t\tbuf += sizeof(struct trim_range);\n\t\ti++;\n\n\t\tif (td_random(td) && file_randommap(td, io_u->file))\n\t\t\tmark_random_map(td, io_u, io_u->offset, io_u->buflen);\n\t\tdprint_io_u(io_u, \"fill\");\n\t}\n\tif (buflen) {\n\t\t/*\n\t\t * Set buffer length as overall trim length for this IO, and\n\t\t * tell the ioengine about the number of ranges to be trimmed.\n\t\t */\n\t\tio_u->buflen = buflen;\n\t\tio_u->number_trim = i;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic int fill_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tbool is_random;\n\tuint64_t offset;\n\tenum io_u_action ret;\n\n\tif (td_ioengine_flagged(td, FIO_NOIO))\n\t\tgoto out;\n\n\tset_rw_ddir(td, io_u);\n\n\tif (io_u->ddir == DDIR_INVAL || io_u->ddir == DDIR_TIMEOUT) {\n\t\tdprint(FD_IO, \"invalid direction received ddir = %d\", io_u->ddir);\n\t\treturn 1;\n\t}\n\t/*\n\t * fsync() or fdatasync() or trim etc, we are done\n\t */\n\tif (!ddir_rw(io_u->ddir))\n\t\tgoto out;\n\n\tif (td->o.zone_mode == ZONE_MODE_STRIDED)\n\t\tsetup_strided_zone_mode(td, io_u);\n\telse if (td->o.zone_mode == ZONE_MODE_ZBD)\n\t\tsetup_zbd_zone_mode(td, io_u);\n\n\tif (multi_range_trim(td, io_u)) {\n\t\tif (fill_multi_range_io_u(td, io_u))\n\t\t\treturn 1;\n\t} else {\n\t\t/*\n\t\t * No log, let the seq/rand engine retrieve the next buflen and\n\t\t * position.\n\t\t */\n\t\tif (get_next_offset(td, io_u, &is_random)) {\n\t\t\tdprint(FD_IO, \"io_u %p, failed getting offset\\n\", io_u);\n\t\t\treturn 1;\n\t\t}\n\n\t\tio_u->buflen = get_next_buflen(td, io_u, is_random);\n\t\tif (!io_u->buflen) {\n\t\t\tdprint(FD_IO, \"io_u %p, failed getting buflen\\n\", io_u);\n\t\t\treturn 1;\n\t\t}\n\t}\n\toffset = io_u->offset;\n\n\tif (td->o.zone_mode == ZONE_MODE_ZBD) {\n\t\tret = zbd_adjust_block(td, io_u);\n\t\tif (ret == io_u_eof) {\n\t\t\tdprint(FD_IO, \"zbd_adjust_block() returned io_u_eof\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tif (td->o.dp_type != FIO_DP_NONE)\n\t\tdp_fill_dspec_data(td, io_u);\n\n\tif (io_u->offset + io_u->buflen > io_u->file->real_file_size) {\n\t\tdprint(FD_IO, \"io_u %p, off=0x%llx + len=0x%llx exceeds file size=0x%llx\\n\",\n\t\t\tio_u,\n\t\t\t(unsigned long long) io_u->offset, io_u->buflen,\n\t\t\t(unsigned long long) io_u->file->real_file_size);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * mark entry before potentially trimming io_u\n\t */\n\tif (!multi_range_trim(td, io_u) && td_random(td) && file_randommap(td, io_u->file))\n\t\tio_u->buflen = mark_random_map(td, io_u, offset, io_u->buflen);\n\nout:\n\tif (!multi_range_trim(td, io_u))\n\t\tdprint_io_u(io_u, \"fill\");\n\tio_u->verify_offset = io_u->offset;\n\ttd->zone_bytes += io_u->buflen;\n\treturn 0;\n}\n\nstatic void __io_u_mark_map(uint64_t *map, unsigned int nr)\n{\n\tint idx = 0;\n\n\tswitch (nr) {\n\tdefault:\n\t\tidx = 6;\n\t\tbreak;\n\tcase 33 ... 64:\n\t\tidx = 5;\n\t\tbreak;\n\tcase 17 ... 32:\n\t\tidx = 4;\n\t\tbreak;\n\tcase 9 ... 16:\n\t\tidx = 3;\n\t\tbreak;\n\tcase 5 ... 8:\n\t\tidx = 2;\n\t\tbreak;\n\tcase 1 ... 4:\n\t\tidx = 1;\n\t\tfio_fallthrough;\n\tcase 0:\n\t\tbreak;\n\t}\n\n\tmap[idx]++;\n}\n\nvoid io_u_mark_submit(struct thread_data *td, unsigned int nr)\n{\n\t__io_u_mark_map(td->ts.io_u_submit, nr);\n\ttd->ts.total_submit++;\n}\n\nvoid io_u_mark_complete(struct thread_data *td, unsigned int nr)\n{\n\t__io_u_mark_map(td->ts.io_u_complete, nr);\n\ttd->ts.total_complete++;\n}\n\nvoid io_u_mark_depth(struct thread_data *td, unsigned int nr)\n{\n\tint idx = 0;\n\n\tswitch (td->cur_depth) {\n\tdefault:\n\t\tidx = 6;\n\t\tbreak;\n\tcase 32 ... 63:\n\t\tidx = 5;\n\t\tbreak;\n\tcase 16 ... 31:\n\t\tidx = 4;\n\t\tbreak;\n\tcase 8 ... 15:\n\t\tidx = 3;\n\t\tbreak;\n\tcase 4 ... 7:\n\t\tidx = 2;\n\t\tbreak;\n\tcase 2 ... 3:\n\t\tidx = 1;\n\t\tfio_fallthrough;\n\tcase 1:\n\t\tbreak;\n\t}\n\n\ttd->ts.io_u_map[idx] += nr;\n}\n\nstatic void io_u_mark_lat_nsec(struct thread_data *td, unsigned long long nsec)\n{\n\tint idx = 0;\n\n\tassert(nsec < 1000);\n\n\tswitch (nsec) {\n\tcase 750 ... 999:\n\t\tidx = 9;\n\t\tbreak;\n\tcase 500 ... 749:\n\t\tidx = 8;\n\t\tbreak;\n\tcase 250 ... 499:\n\t\tidx = 7;\n\t\tbreak;\n\tcase 100 ... 249:\n\t\tidx = 6;\n\t\tbreak;\n\tcase 50 ... 99:\n\t\tidx = 5;\n\t\tbreak;\n\tcase 20 ... 49:\n\t\tidx = 4;\n\t\tbreak;\n\tcase 10 ... 19:\n\t\tidx = 3;\n\t\tbreak;\n\tcase 4 ... 9:\n\t\tidx = 2;\n\t\tbreak;\n\tcase 2 ... 3:\n\t\tidx = 1;\n\t\tfio_fallthrough;\n\tcase 0 ... 1:\n\t\tbreak;\n\t}\n\n\tassert(idx < FIO_IO_U_LAT_N_NR);\n\ttd->ts.io_u_lat_n[idx]++;\n}\n\nstatic void io_u_mark_lat_usec(struct thread_data *td, unsigned long long usec)\n{\n\tint idx = 0;\n\n\tassert(usec < 1000 && usec >= 1);\n\n\tswitch (usec) {\n\tcase 750 ... 999:\n\t\tidx = 9;\n\t\tbreak;\n\tcase 500 ... 749:\n\t\tidx = 8;\n\t\tbreak;\n\tcase 250 ... 499:\n\t\tidx = 7;\n\t\tbreak;\n\tcase 100 ... 249:\n\t\tidx = 6;\n\t\tbreak;\n\tcase 50 ... 99:\n\t\tidx = 5;\n\t\tbreak;\n\tcase 20 ... 49:\n\t\tidx = 4;\n\t\tbreak;\n\tcase 10 ... 19:\n\t\tidx = 3;\n\t\tbreak;\n\tcase 4 ... 9:\n\t\tidx = 2;\n\t\tbreak;\n\tcase 2 ... 3:\n\t\tidx = 1;\n\t\tfio_fallthrough;\n\tcase 0 ... 1:\n\t\tbreak;\n\t}\n\n\tassert(idx < FIO_IO_U_LAT_U_NR);\n\ttd->ts.io_u_lat_u[idx]++;\n}\n\nstatic void io_u_mark_lat_msec(struct thread_data *td, unsigned long long msec)\n{\n\tint idx = 0;\n\n\tassert(msec >= 1);\n\n\tswitch (msec) {\n\tdefault:\n\t\tidx = 11;\n\t\tbreak;\n\tcase 1000 ... 1999:\n\t\tidx = 10;\n\t\tbreak;\n\tcase 750 ... 999:\n\t\tidx = 9;\n\t\tbreak;\n\tcase 500 ... 749:\n\t\tidx = 8;\n\t\tbreak;\n\tcase 250 ... 499:\n\t\tidx = 7;\n\t\tbreak;\n\tcase 100 ... 249:\n\t\tidx = 6;\n\t\tbreak;\n\tcase 50 ... 99:\n\t\tidx = 5;\n\t\tbreak;\n\tcase 20 ... 49:\n\t\tidx = 4;\n\t\tbreak;\n\tcase 10 ... 19:\n\t\tidx = 3;\n\t\tbreak;\n\tcase 4 ... 9:\n\t\tidx = 2;\n\t\tbreak;\n\tcase 2 ... 3:\n\t\tidx = 1;\n\t\tfio_fallthrough;\n\tcase 0 ... 1:\n\t\tbreak;\n\t}\n\n\tassert(idx < FIO_IO_U_LAT_M_NR);\n\ttd->ts.io_u_lat_m[idx]++;\n}\n\nstatic void io_u_mark_latency(struct thread_data *td, unsigned long long nsec)\n{\n\tif (nsec < 1000)\n\t\tio_u_mark_lat_nsec(td, nsec);\n\telse if (nsec < 1000000)\n\t\tio_u_mark_lat_usec(td, nsec / 1000);\n\telse\n\t\tio_u_mark_lat_msec(td, nsec / 1000000);\n}\n\nstatic unsigned int __get_next_fileno_rand(struct thread_data *td)\n{\n\tunsigned long fileno;\n\n\tif (td->o.file_service_type == FIO_FSERVICE_RANDOM) {\n\t\tuint64_t frand_max = rand_max(&td->next_file_state);\n\t\tunsigned long r;\n\n\t\tr = __rand(&td->next_file_state);\n\t\treturn (unsigned int) ((double) td->o.nr_files\n\t\t\t\t* (r / (frand_max + 1.0)));\n\t}\n\n\tif (td->o.file_service_type == FIO_FSERVICE_ZIPF)\n\t\tfileno = zipf_next(&td->next_file_zipf);\n\telse if (td->o.file_service_type == FIO_FSERVICE_PARETO)\n\t\tfileno = pareto_next(&td->next_file_zipf);\n\telse if (td->o.file_service_type == FIO_FSERVICE_GAUSS)\n\t\tfileno = gauss_next(&td->next_file_gauss);\n\telse {\n\t\tlog_err(\"fio: bad file service type: %d\\n\", td->o.file_service_type);\n\t\tassert(0);\n\t\treturn 0;\n\t}\n\n\treturn fileno >> FIO_FSERVICE_SHIFT;\n}\n\n/*\n * Get next file to service by choosing one at random\n */\nstatic struct fio_file *get_next_file_rand(struct thread_data *td,\n\t\t\t\t\t   enum fio_file_flags goodf,\n\t\t\t\t\t   enum fio_file_flags badf)\n{\n\tstruct fio_file *f;\n\tint fno;\n\n\tdo {\n\t\tint opened = 0;\n\n\t\tfno = __get_next_fileno_rand(td);\n\n\t\tf = td->files[fno];\n\t\tif (fio_file_done(f))\n\t\t\tcontinue;\n\n\t\tif (!fio_file_open(f)) {\n\t\t\tint err;\n\n\t\t\tif (td->nr_open_files >= td->o.open_files)\n\t\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t\terr = td_io_open_file(td, f);\n\t\t\tif (err)\n\t\t\t\tcontinue;\n\t\t\topened = 1;\n\t\t}\n\n\t\tif ((!goodf || (f->flags & goodf)) && !(f->flags & badf)) {\n\t\t\tdprint(FD_FILE, \"get_next_file_rand: %p\\n\", f);\n\t\t\treturn f;\n\t\t}\n\t\tif (opened)\n\t\t\ttd_io_close_file(td, f);\n\t} while (1);\n}\n\n/*\n * Get next file to service by doing round robin between all available ones\n */\nstatic struct fio_file *get_next_file_rr(struct thread_data *td, int goodf,\n\t\t\t\t\t int badf)\n{\n\tunsigned int old_next_file = td->next_file;\n\tstruct fio_file *f;\n\n\tdo {\n\t\tint opened = 0;\n\n\t\tf = td->files[td->next_file];\n\n\t\ttd->next_file++;\n\t\tif (td->next_file >= td->o.nr_files)\n\t\t\ttd->next_file = 0;\n\n\t\tdprint(FD_FILE, \"trying file %s %x\\n\", f->file_name, f->flags);\n\t\tif (fio_file_done(f)) {\n\t\t\tf = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!fio_file_open(f)) {\n\t\t\tint err;\n\n\t\t\tif (td->nr_open_files >= td->o.open_files)\n\t\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t\terr = td_io_open_file(td, f);\n\t\t\tif (err) {\n\t\t\t\tdprint(FD_FILE, \"error %d on open of %s\\n\",\n\t\t\t\t\terr, f->file_name);\n\t\t\t\tf = NULL;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\topened = 1;\n\t\t}\n\n\t\tdprint(FD_FILE, \"goodf=%x, badf=%x, ff=%x\\n\", goodf, badf,\n\t\t\t\t\t\t\t\tf->flags);\n\t\tif ((!goodf || (f->flags & goodf)) && !(f->flags & badf))\n\t\t\tbreak;\n\n\t\tif (opened)\n\t\t\ttd_io_close_file(td, f);\n\n\t\tf = NULL;\n\t} while (td->next_file != old_next_file);\n\n\tdprint(FD_FILE, \"get_next_file_rr: %p\\n\", f);\n\treturn f;\n}\n\nstatic struct fio_file *__get_next_file(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\n\tassert(td->o.nr_files <= td->files_index);\n\n\tif (td->nr_done_files >= td->o.nr_files) {\n\t\tdprint(FD_FILE, \"get_next_file: nr_open=%d, nr_done=%d,\"\n\t\t\t\t\" nr_files=%d\\n\", td->nr_open_files,\n\t\t\t\t\t\t  td->nr_done_files,\n\t\t\t\t\t\t  td->o.nr_files);\n\t\treturn NULL;\n\t}\n\n\tf = td->file_service_file;\n\tif (f && fio_file_open(f) && !fio_file_closing(f)) {\n\t\tif (td->o.file_service_type == FIO_FSERVICE_SEQ)\n\t\t\tgoto out;\n\t\tif (td->file_service_left) {\n\t\t\ttd->file_service_left--;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (td->o.file_service_type == FIO_FSERVICE_RR ||\n\t    td->o.file_service_type == FIO_FSERVICE_SEQ)\n\t\tf = get_next_file_rr(td, FIO_FILE_open, FIO_FILE_closing);\n\telse\n\t\tf = get_next_file_rand(td, FIO_FILE_open, FIO_FILE_closing);\n\n\tif (IS_ERR(f))\n\t\treturn f;\n\n\ttd->file_service_file = f;\n\ttd->file_service_left = td->file_service_nr - 1;\nout:\n\tif (f)\n\t\tdprint(FD_FILE, \"get_next_file: %p [%s]\\n\", f, f->file_name);\n\telse\n\t\tdprint(FD_FILE, \"get_next_file: NULL\\n\");\n\treturn f;\n}\n\nstatic struct fio_file *get_next_file(struct thread_data *td)\n{\n\treturn __get_next_file(td);\n}\n\nstatic long set_io_u_file(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f;\n\n\tdo {\n\t\tf = get_next_file(td);\n\t\tif (IS_ERR_OR_NULL(f))\n\t\t\treturn PTR_ERR(f);\n\n\t\tio_u->file = f;\n\t\tget_file(f);\n\n\t\tif (!fill_io_u(td, io_u))\n\t\t\tbreak;\n\n\t\tzbd_put_io_u(td, io_u);\n\n\t\tput_file_log(td, f);\n\t\ttd_io_close_file(td, f);\n\t\tio_u->file = NULL;\n\n\t\tif (io_u->ddir == DDIR_TIMEOUT)\n\t\t\treturn 1;\n\n\t\tif (td->o.file_service_type & __FIO_FSERVICE_NONUNIFORM)\n\t\t\tfio_file_reset(td, f);\n\t\telse {\n\t\t\tfio_file_set_done(f);\n\t\t\ttd->nr_done_files++;\n\t\t\tdprint(FD_FILE, \"%s: is done (%d of %d)\\n\", f->file_name,\n\t\t\t\t\ttd->nr_done_files, td->o.nr_files);\n\t\t}\n\t} while (1);\n\n\treturn 0;\n}\n\nstatic void lat_fatal(struct thread_data *td, struct io_u *io_u, struct io_completion_data *icd,\n\t\t      unsigned long long tnsec, unsigned long long max_nsec)\n{\n\tif (!td->error) {\n\t\tlog_err(\"fio: latency of %llu nsec exceeds specified max (%llu nsec): %s %s %llu %llu\\n\",\n\t\t\t\t\ttnsec, max_nsec,\n\t\t\t\t\tio_u->file->file_name,\n\t\t\t\t\tio_ddir_name(io_u->ddir),\n\t\t\t\t\tio_u->offset, io_u->buflen);\n\t}\n\ttd_verror(td, ETIMEDOUT, \"max latency exceeded\");\n\ticd->error = ETIMEDOUT;\n}\n\nstatic void lat_new_cycle(struct thread_data *td)\n{\n\tfio_gettime(&td->latency_ts, NULL);\n\ttd->latency_ios = ddir_rw_sum(td->io_blocks);\n\ttd->latency_failed = 0;\n}\n\n/*\n * We had an IO outside the latency target. Reduce the queue depth. If we\n * are at QD=1, then it's time to give up.\n */\nstatic bool __lat_target_failed(struct thread_data *td)\n{\n\tif (td->latency_qd == 1)\n\t\treturn true;\n\n\ttd->latency_qd_high = td->latency_qd;\n\n\tif (td->latency_qd == td->latency_qd_low)\n\t\ttd->latency_qd_low--;\n\n\ttd->latency_qd = (td->latency_qd + td->latency_qd_low) / 2;\n\ttd->latency_stable_count = 0;\n\n\tdprint(FD_RATE, \"Ramped down: %d %d %d\\n\", td->latency_qd_low, td->latency_qd, td->latency_qd_high);\n\n\t/*\n\t * When we ramp QD down, quiesce existing IO to prevent\n\t * a storm of ramp downs due to pending higher depth.\n\t */\n\tio_u_quiesce(td);\n\tlat_new_cycle(td);\n\treturn false;\n}\n\nstatic bool lat_target_failed(struct thread_data *td)\n{\n\tif (td->o.latency_percentile.u.f == 100.0)\n\t\treturn __lat_target_failed(td);\n\n\ttd->latency_failed++;\n\treturn false;\n}\n\nvoid lat_target_init(struct thread_data *td)\n{\n\ttd->latency_end_run = 0;\n\n\tif (td->o.latency_target) {\n\t\tdprint(FD_RATE, \"Latency target=%llu\\n\", td->o.latency_target);\n\t\tfio_gettime(&td->latency_ts, NULL);\n\t\ttd->latency_qd = 1;\n\t\ttd->latency_qd_high = td->o.iodepth;\n\t\ttd->latency_qd_low = 1;\n\t\ttd->latency_ios = ddir_rw_sum(td->io_blocks);\n\t} else\n\t\ttd->latency_qd = td->o.iodepth;\n}\n\nvoid lat_target_reset(struct thread_data *td)\n{\n\tif (!td->latency_end_run)\n\t\tlat_target_init(td);\n}\n\nstatic void lat_target_success(struct thread_data *td)\n{\n\tconst unsigned int qd = td->latency_qd;\n\tstruct thread_options *o = &td->o;\n\n\ttd->latency_qd_low = td->latency_qd;\n\n\tif (td->latency_qd + 1 == td->latency_qd_high) {\n\t\t/*\n\t\t * latency_qd will not incease on lat_target_success(), so\n\t\t * called stable. If we stick with this queue depth, the\n\t\t * final latency is likely lower than latency_target. Fix\n\t\t * this by increasing latency_qd_high slowly. Use a naive\n\t\t * heuristic here. If we get lat_target_success() 3 times\n\t\t * in a row, increase latency_qd_high by 1.\n\t\t */\n\t\tif (++td->latency_stable_count >= 3) {\n\t\t\ttd->latency_qd_high++;\n\t\t\ttd->latency_stable_count = 0;\n\t\t}\n\t}\n\n\t/*\n\t * If we haven't failed yet, we double up to a failing value instead\n\t * of bisecting from highest possible queue depth. If we have set\n\t * a limit other than td->o.iodepth, bisect between that.\n\t */\n\tif (td->latency_qd_high != o->iodepth)\n\t\ttd->latency_qd = (td->latency_qd + td->latency_qd_high) / 2;\n\telse\n\t\ttd->latency_qd *= 2;\n\n\tif (td->latency_qd > o->iodepth)\n\t\ttd->latency_qd = o->iodepth;\n\n\tdprint(FD_RATE, \"Ramped up: %d %d %d\\n\", td->latency_qd_low, td->latency_qd, td->latency_qd_high);\n\n\t/*\n\t * Same as last one, we are done. Let it run a latency cycle, so\n\t * we get only the results from the targeted depth.\n\t */\n\tif (!o->latency_run && td->latency_qd == qd) {\n\t\tif (td->latency_end_run) {\n\t\t\tdprint(FD_RATE, \"We are done\\n\");\n\t\t\ttd->done = 1;\n\t\t} else {\n\t\t\tdprint(FD_RATE, \"Quiesce and final run\\n\");\n\t\t\tio_u_quiesce(td);\n\t\t\ttd->latency_end_run = 1;\n\t\t\treset_all_stats(td);\n\t\t\treset_io_stats(td);\n\t\t}\n\t}\n\n\tlat_new_cycle(td);\n}\n\n/*\n * Check if we can bump the queue depth\n */\nvoid lat_target_check(struct thread_data *td)\n{\n\tuint64_t usec_window;\n\tuint64_t ios;\n\tdouble success_ios;\n\n\tusec_window = utime_since_now(&td->latency_ts);\n\tif (usec_window < td->o.latency_window)\n\t\treturn;\n\n\tios = ddir_rw_sum(td->io_blocks) - td->latency_ios;\n\tsuccess_ios = (double) (ios - td->latency_failed) / (double) ios;\n\tsuccess_ios *= 100.0;\n\n\tdprint(FD_RATE, \"Success rate: %.2f%% (target %.2f%%)\\n\", success_ios, td->o.latency_percentile.u.f);\n\n\tif (success_ios >= td->o.latency_percentile.u.f)\n\t\tlat_target_success(td);\n\telse\n\t\t__lat_target_failed(td);\n}\n\n/*\n * If latency target is enabled, we might be ramping up or down and not\n * using the full queue depth available.\n */\nbool queue_full(const struct thread_data *td)\n{\n\tconst int qempty = io_u_qempty(&td->io_u_freelist);\n\n\tif (qempty)\n\t\treturn true;\n\tif (!td->o.latency_target)\n\t\treturn false;\n\n\treturn td->cur_depth >= td->latency_qd;\n}\n\nstruct io_u *__get_io_u(struct thread_data *td)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct io_u *io_u = NULL;\n\n\tif (td->stop_io)\n\t\treturn NULL;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\nagain:\n\tif (!io_u_rempty(&td->io_u_requeues)) {\n\t\tio_u = io_u_rpop(&td->io_u_requeues);\n\t\tio_u->resid = 0;\n\t} else if (!queue_full(td)) {\n\t\tio_u = io_u_qpop(&td->io_u_freelist);\n\n\t\tio_u->file = NULL;\n\t\tio_u->buflen = 0;\n\t\tio_u->resid = 0;\n\t\tio_u->end_io = NULL;\n\t}\n\n\tif (io_u) {\n\t\tassert(io_u->flags & IO_U_F_FREE);\n\t\tio_u_clear(td, io_u, IO_U_F_FREE | IO_U_F_NO_FILE_PUT |\n\t\t\t\t IO_U_F_TRIMMED | IO_U_F_BARRIER |\n\t\t\t\t IO_U_F_VER_LIST);\n\n\t\tio_u->error = 0;\n\t\tio_u->acct_ddir = -1;\n\t\ttd->cur_depth++;\n\t\tassert(!(td->flags & TD_F_CHILD));\n\t\tio_u_set(td, io_u, IO_U_F_IN_CUR_DEPTH);\n\t\tio_u->ipo = NULL;\n\t} else if (td_async_processing(td)) {\n\t\tint ret;\n\t\t/*\n\t\t * We ran out, wait for async verify threads to finish and\n\t\t * return one\n\t\t */\n\t\tassert(!(td->flags & TD_F_CHILD));\n\t\tret = pthread_cond_wait(&td->free_cond, &td->io_u_lock);\n\t\tif (fio_unlikely(ret != 0)) {\n\t\t\ttd->error = errno;\n\t\t} else if (!td->error)\n\t\t\tgoto again;\n\t}\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n\n\treturn io_u;\n}\n\nstatic bool check_get_trim(struct thread_data *td, struct io_u *io_u)\n{\n\tif (!(td->flags & TD_F_TRIM_BACKLOG))\n\t\treturn false;\n\tif (!td->trim_entries)\n\t\treturn false;\n\n\tif (td->trim_batch) {\n\t\ttd->trim_batch--;\n\t\tif (get_next_trim(td, io_u))\n\t\t\treturn true;\n\t} else if (!(td->io_hist_len % td->o.trim_backlog) &&\n\t\t     td->last_ddir_completed != DDIR_READ) {\n\t\ttd->trim_batch = td->o.trim_batch;\n\t\tif (!td->trim_batch)\n\t\t\ttd->trim_batch = td->o.trim_backlog;\n\t\tif (get_next_trim(td, io_u))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool check_get_verify(struct thread_data *td, struct io_u *io_u)\n{\n\tif (!(td->flags & TD_F_VER_BACKLOG))\n\t\treturn false;\n\n\tif (td->io_hist_len) {\n\t\tint get_verify = 0;\n\n\t\tif (td->verify_batch)\n\t\t\tget_verify = 1;\n\t\telse if (!(td->io_hist_len % td->o.verify_backlog) &&\n\t\t\t td->last_ddir_completed != DDIR_READ) {\n\t\t\ttd->verify_batch = td->o.verify_batch;\n\t\t\tif (!td->verify_batch)\n\t\t\t\ttd->verify_batch = td->o.verify_backlog;\n\t\t\tget_verify = 1;\n\t\t}\n\n\t\tif (get_verify && !get_next_verify(td, io_u)) {\n\t\t\ttd->verify_batch--;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\n/*\n * Fill offset and start time into the buffer content, to prevent too\n * easy compressible data for simple de-dupe attempts. Do this for every\n * 512b block in the range, since that should be the smallest block size\n * we can expect from a device.\n */\nstatic void small_content_scramble(struct io_u *io_u)\n{\n\tunsigned long long i, nr_blocks = io_u->buflen >> 9;\n\tunsigned int offset;\n\tuint64_t boffset, *iptr;\n\tchar *p;\n\n\tif (!nr_blocks)\n\t\treturn;\n\n\tp = io_u->xfer_buf;\n\tboffset = io_u->offset;\n\n\tif (io_u->buf_filled_len)\n\t\tio_u->buf_filled_len = 0;\n\n\t/*\n\t * Generate random index between 0..7. We do chunks of 512b, if\n\t * we assume a cacheline is 64 bytes, then we have 8 of those.\n\t * Scramble content within the blocks in the same cacheline to\n\t * speed things up.\n\t */\n\toffset = (io_u->start_time.tv_nsec ^ boffset) & 7;\n\n\tfor (i = 0; i < nr_blocks; i++) {\n\t\t/*\n\t\t * Fill offset into start of cacheline, time into end\n\t\t * of cacheline\n\t\t */\n\t\tiptr = (void *) p + (offset << 6);\n\t\t*iptr = boffset;\n\n\t\tiptr = (void *) p + 64 - 2 * sizeof(uint64_t);\n\t\tiptr[0] = io_u->start_time.tv_sec;\n\t\tiptr[1] = io_u->start_time.tv_nsec;\n\n\t\tp += 512;\n\t\tboffset += 512;\n\t}\n}\n\n/*\n * Return an io_u to be processed. Gets a buflen and offset, sets direction,\n * etc. The returned io_u is fully ready to be prepped, populated and submitted.\n */\nstruct io_u *get_io_u(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tstruct io_u *io_u;\n\tint do_scramble = 0;\n\tlong ret = 0;\n\n\tio_u = __get_io_u(td);\n\tif (!io_u) {\n\t\tdprint(FD_IO, \"__get_io_u failed\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (check_get_verify(td, io_u))\n\t\tgoto out;\n\tif (check_get_trim(td, io_u))\n\t\tgoto out;\n\n\t/*\n\t * from a requeue, io_u already setup\n\t */\n\tif (io_u->file)\n\t\tgoto out;\n\n\t/*\n\t * If using an iolog, grab next piece if any available.\n\t */\n\tif (td->flags & TD_F_READ_IOLOG) {\n\t\tif (read_iolog_get(td, io_u))\n\t\t\tgoto err_put;\n\t} else if (set_io_u_file(td, io_u)) {\n\t\tret = -EBUSY;\n\t\tdprint(FD_IO, \"io_u %p, setting file failed\\n\", io_u);\n\t\tgoto err_put;\n\t}\n\n\tf = io_u->file;\n\tif (!f) {\n\t\tdprint(FD_IO, \"io_u %p, setting file failed\\n\", io_u);\n\t\tgoto err_put;\n\t}\n\n\tassert(fio_file_open(f));\n\n\tif (ddir_rw(io_u->ddir) && !multi_range_trim(td, io_u)) {\n\t\tif (!io_u->buflen && !td_ioengine_flagged(td, FIO_NOIO)) {\n\t\t\tdprint(FD_IO, \"get_io_u: zero buflen on %p\\n\", io_u);\n\t\t\tgoto err_put;\n\t\t}\n\n\t\tf->last_start[io_u->ddir] = io_u->offset;\n\t\tf->last_pos[io_u->ddir] = io_u->offset + io_u->buflen;\n\n\t\tif (io_u->ddir == DDIR_WRITE) {\n\t\t\tif (td->flags & TD_F_REFILL_BUFFERS) {\n\t\t\t\tio_u_fill_buffer(td, io_u,\n\t\t\t\t\ttd->o.min_bs[DDIR_WRITE],\n\t\t\t\t\tio_u->buflen);\n\t\t\t} else if ((td->flags & TD_F_SCRAMBLE_BUFFERS) &&\n\t\t\t\t   !(td->flags & TD_F_COMPRESS) &&\n\t\t\t\t   !(td->flags & TD_F_DO_VERIFY)) {\n\t\t\t\tdo_scramble = 1;\n\t\t\t}\n\t\t} else if (io_u->ddir == DDIR_READ) {\n\t\t\t/*\n\t\t\t * Reset the buf_filled parameters so next time if the\n\t\t\t * buffer is used for writes it is refilled.\n\t\t\t */\n\t\t\tio_u->buf_filled_len = 0;\n\t\t}\n\t}\n\n\t/*\n\t * Set io data pointers.\n\t */\n\tio_u->xfer_buf = io_u->buf;\n\tio_u->xfer_buflen = io_u->buflen;\n\n\t/*\n\t * Remember the issuing context priority. The IO engine may change this.\n\t */\n\tio_u->ioprio = td->ioprio;\n\tio_u->clat_prio_index = 0;\nout:\n\tassert(io_u->file);\n\tif (!td_io_prep(td, io_u)) {\n\t\tif (!td->o.disable_lat)\n\t\t\tfio_gettime(&io_u->start_time, NULL);\n\n\t\tif (do_scramble)\n\t\t\tsmall_content_scramble(io_u);\n\n\t\treturn io_u;\n\t}\nerr_put:\n\tdprint(FD_IO, \"get_io_u failed\\n\");\n\tput_io_u(td, io_u);\n\treturn ERR_PTR(ret);\n}\n\nstatic void __io_u_log_error(struct thread_data *td, struct io_u *io_u)\n{\n\tenum error_type_bit eb = td_error_type(io_u->ddir, io_u->error);\n\n\tif (td_non_fatal_error(td, eb, io_u->error) && !td->o.error_dump)\n\t\treturn;\n\n\tlog_err(\"fio: io_u error%s%s: %s: %s offset=%llu, buflen=%llu\\n\",\n\t\tio_u->file ? \" on file \" : \"\",\n\t\tio_u->file ? io_u->file->file_name : \"\",\n\t\t(io_u->flags & IO_U_F_DEVICE_ERROR) ?\n\t\t\t\"Device-specific error\" : strerror(io_u->error),\n\t\tio_ddir_name(io_u->ddir),\n\t\tio_u->offset, io_u->xfer_buflen);\n\n\tzbd_log_err(td, io_u);\n\n\tif (td->io_ops->errdetails) {\n\t\tchar *err = td->io_ops->errdetails(td, io_u);\n\n\t\tif (err) {\n\t\t\tlog_err(\"fio: %s\\n\", err);\n\t\t\tfree(err);\n\t\t}\n\t}\n\n\tif (!td->error)\n\t\ttd_verror(td, io_u->error, \"io_u error\");\n}\n\nvoid io_u_log_error(struct thread_data *td, struct io_u *io_u)\n{\n\t__io_u_log_error(td, io_u);\n\tif (td->parent)\n\t\t__io_u_log_error(td->parent, io_u);\n}\n\nstatic inline bool gtod_reduce(struct thread_data *td)\n{\n\treturn (td->o.disable_clat && td->o.disable_slat && td->o.disable_bw)\n\t\t\t|| td->o.gtod_reduce;\n}\n\nstatic void trim_block_info(struct thread_data *td, struct io_u *io_u)\n{\n\tuint32_t *info = io_u_block_info(td, io_u);\n\n\tif (BLOCK_INFO_STATE(*info) >= BLOCK_STATE_TRIM_FAILURE)\n\t\treturn;\n\n\t*info = BLOCK_INFO(BLOCK_STATE_TRIMMED, BLOCK_INFO_TRIMS(*info) + 1);\n}\n\nstatic void account_io_completion(struct thread_data *td, struct io_u *io_u,\n\t\t\t\t  struct io_completion_data *icd,\n\t\t\t\t  const enum fio_ddir idx, unsigned int bytes)\n{\n\tconst int no_reduce = !gtod_reduce(td);\n\tunsigned long long llnsec = 0;\n\n\tif (td->parent)\n\t\ttd = td->parent;\n\n\tif (!td->o.stats || td_ioengine_flagged(td, FIO_NOSTATS))\n\t\treturn;\n\n\tif (no_reduce)\n\t\tllnsec = ntime_since(&io_u->issue_time, &icd->time);\n\n\tif (!td->o.disable_lat) {\n\t\tunsigned long long tnsec;\n\n\t\ttnsec = ntime_since(&io_u->start_time, &icd->time);\n\t\tadd_lat_sample(td, idx, tnsec, bytes, io_u);\n\n\t\tif (td->flags & TD_F_PROFILE_OPS) {\n\t\t\tstruct prof_io_ops *ops = &td->prof_io_ops;\n\n\t\t\tif (ops->io_u_lat)\n\t\t\t\ticd->error = ops->io_u_lat(td, tnsec);\n\t\t}\n\n\t\tif (ddir_rw(idx)) {\n\t\t\tif (td->o.max_latency[idx] && tnsec > td->o.max_latency[idx])\n\t\t\t\tlat_fatal(td, io_u, icd, tnsec, td->o.max_latency[idx]);\n\t\t\tif (td->o.latency_target && tnsec > td->o.latency_target) {\n\t\t\t\tif (lat_target_failed(td))\n\t\t\t\t\tlat_fatal(td, io_u, icd, tnsec, td->o.latency_target);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ddir_rw(idx)) {\n\t\tif (!td->o.disable_clat) {\n\t\t\tadd_clat_sample(td, idx, llnsec, bytes, io_u);\n\t\t\tio_u_mark_latency(td, llnsec);\n\t\t}\n\n\t\tif (!td->o.disable_bw && per_unit_log(td->bw_log))\n\t\t\tadd_bw_sample(td, io_u, bytes, llnsec);\n\n\t\tif (no_reduce && per_unit_log(td->iops_log))\n\t\t\tadd_iops_sample(td, io_u, bytes);\n\t} else if (ddir_sync(idx) && !td->o.disable_clat)\n\t\tadd_sync_clat_sample(&td->ts, llnsec);\n\n\tif (td->ts.nr_block_infos && io_u->ddir == DDIR_TRIM)\n\t\ttrim_block_info(td, io_u);\n}\n\nstatic void file_log_write_comp(const struct thread_data *td, struct fio_file *f,\n\t\t\t\tuint64_t offset, unsigned int bytes)\n{\n\tint idx;\n\n\tif (!f)\n\t\treturn;\n\n\tif (f->first_write == -1ULL || offset < f->first_write)\n\t\tf->first_write = offset;\n\tif (f->last_write == -1ULL || ((offset + bytes) > f->last_write))\n\t\tf->last_write = offset + bytes;\n\n\tif (!f->last_write_comp)\n\t\treturn;\n\n\tidx = f->last_write_idx++;\n\tf->last_write_comp[idx] = offset;\n\tif (f->last_write_idx == td->o.iodepth)\n\t\tf->last_write_idx = 0;\n}\n\nstatic bool should_account(struct thread_data *td)\n{\n\treturn ramp_time_over(td) && (td->runstate == TD_RUNNING ||\n\t\t\t\t\t   td->runstate == TD_VERIFYING);\n}\n\nstatic void io_completed(struct thread_data *td, struct io_u **io_u_ptr,\n\t\t\t struct io_completion_data *icd)\n{\n\tstruct io_u *io_u = *io_u_ptr;\n\tenum fio_ddir ddir = io_u->ddir;\n\tstruct fio_file *f = io_u->file;\n\n\tdprint_io_u(io_u, \"complete\");\n\n\tassert(io_u->flags & IO_U_F_FLIGHT);\n\tio_u_clear(td, io_u, IO_U_F_FLIGHT | IO_U_F_BUSY_OK | IO_U_F_PATTERN_DONE);\n\n\t/*\n\t * Mark IO ok to verify\n\t */\n\tif (io_u->ipo) {\n\t\t/*\n\t\t * Remove errored entry from the verification list\n\t\t */\n\t\tif (io_u->error)\n\t\t\tunlog_io_piece(td, io_u);\n\t\telse {\n\t\t\tatomic_store_release(&io_u->ipo->flags,\n\t\t\t\t\tio_u->ipo->flags & ~IP_F_IN_FLIGHT);\n\t\t}\n\t}\n\n\tif (ddir_sync(ddir)) {\n\t\tif (io_u->error)\n\t\t\tgoto error;\n\t\tif (f) {\n\t\t\tf->first_write = -1ULL;\n\t\t\tf->last_write = -1ULL;\n\t\t}\n\t\tif (should_account(td))\n\t\t\taccount_io_completion(td, io_u, icd, ddir, io_u->buflen);\n\t\treturn;\n\t}\n\n\ttd->last_ddir_completed = ddir;\n\n\tif (!io_u->error && ddir_rw(ddir)) {\n\t\tunsigned long long bytes = io_u->xfer_buflen - io_u->resid;\n\t\tint ret;\n\n\t\t/*\n\t\t * Make sure we notice short IO from here, and requeue them\n\t\t * appropriately!\n\t\t */\n\t\tif (bytes && io_u->resid) {\n\t\t\tio_u->xfer_buflen = io_u->resid;\n\t\t\tio_u->xfer_buf += bytes;\n\t\t\tio_u->offset += bytes;\n\t\t\ttd->ts.short_io_u[io_u->ddir]++;\n\t\t\tif (io_u->offset < io_u->file->real_file_size) {\n\t\t\t\trequeue_io_u(td, io_u_ptr);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\ttd->io_blocks[ddir]++;\n\t\ttd->io_bytes[ddir] += bytes;\n\n\t\tif (!(io_u->flags & IO_U_F_VER_LIST)) {\n\t\t\ttd->this_io_blocks[ddir]++;\n\t\t\ttd->this_io_bytes[ddir] += bytes;\n\t\t}\n\n\t\tif (ddir == DDIR_WRITE)\n\t\t\tfile_log_write_comp(td, f, io_u->offset, bytes);\n\n\t\tif (should_account(td))\n\t\t\taccount_io_completion(td, io_u, icd, ddir, bytes);\n\n\t\ticd->bytes_done[ddir] += bytes;\n\n\t\tif (io_u->end_io) {\n\t\t\tret = io_u->end_io(td, io_u_ptr);\n\t\t\tio_u = *io_u_ptr;\n\t\t\tif (ret && !icd->error)\n\t\t\t\ticd->error = ret;\n\t\t}\n\t} else if (io_u->error) {\nerror:\n\t\ticd->error = io_u->error;\n\t\tio_u_log_error(td, io_u);\n\t}\n\tif (icd->error) {\n\t\tenum error_type_bit eb = td_error_type(ddir, icd->error);\n\n\t\tif (!td_non_fatal_error(td, eb, icd->error))\n\t\t\treturn;\n\n\t\t/*\n\t\t * If there is a non_fatal error, then add to the error count\n\t\t * and clear all the errors.\n\t\t */\n\t\tupdate_error_count(td, icd->error);\n\t\ttd_clear_error(td);\n\t\ticd->error = 0;\n\t\tif (io_u)\n\t\t\tio_u->error = 0;\n\t}\n}\n\nstatic void init_icd(struct thread_data *td, struct io_completion_data *icd,\n\t\t     int nr)\n{\n\tint ddir;\n\n\tif (!gtod_reduce(td))\n\t\tfio_gettime(&icd->time, NULL);\n\n\ticd->nr = nr;\n\n\ticd->error = 0;\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++)\n\t\ticd->bytes_done[ddir] = 0;\n}\n\nstatic void ios_completed(struct thread_data *td,\n\t\t\t  struct io_completion_data *icd)\n{\n\tstruct io_u *io_u;\n\tint i;\n\n\tfor (i = 0; i < icd->nr; i++) {\n\t\tio_u = td->io_ops->event(td, i);\n\n\t\tio_completed(td, &io_u, icd);\n\n\t\tif (io_u)\n\t\t\tput_io_u(td, io_u);\n\t}\n}\n\nstatic void io_u_update_bytes_done(struct thread_data *td,\n\t\t\t\t   struct io_completion_data *icd)\n{\n\tint ddir;\n\n\tif (td->runstate == TD_VERIFYING) {\n\t\ttd->bytes_verified += icd->bytes_done[DDIR_READ];\n\t\tif (td_write(td))\n\t\t\treturn;\n\t}\n\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++)\n\t\ttd->bytes_done[ddir] += icd->bytes_done[ddir];\n}\n\n/*\n * Complete a single io_u for the sync engines.\n */\nint io_u_sync_complete(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct io_completion_data icd;\n\n\tinit_icd(td, &icd, 1);\n\tio_completed(td, &io_u, &icd);\n\n\tif (io_u)\n\t\tput_io_u(td, io_u);\n\n\tif (icd.error) {\n\t\ttd_verror(td, icd.error, \"io_u_sync_complete\");\n\t\treturn -1;\n\t}\n\n\tio_u_update_bytes_done(td, &icd);\n\n\treturn 0;\n}\n\n/*\n * Called to complete min_events number of io for the async engines.\n */\nint io_u_queued_complete(struct thread_data *td, int min_evts)\n{\n\tstruct io_completion_data icd;\n\tstruct timespec *tvp = NULL;\n\tint ret;\n\tstruct timespec ts = { .tv_sec = 0, .tv_nsec = 0, };\n\n\tdprint(FD_IO, \"io_u_queued_complete: min=%d\\n\", min_evts);\n\n\tif (!min_evts)\n\t\ttvp = &ts;\n\telse if (min_evts > td->cur_depth)\n\t\tmin_evts = td->cur_depth;\n\n\t/* No worries, td_io_getevents fixes min and max if they are\n\t * set incorrectly */\n\tret = td_io_getevents(td, min_evts, td->o.iodepth_batch_complete_max, tvp);\n\tif (ret < 0) {\n\t\ttd_verror(td, -ret, \"td_io_getevents\");\n\t\treturn ret;\n\t} else if (!ret)\n\t\treturn ret;\n\n\tinit_icd(td, &icd, ret);\n\tios_completed(td, &icd);\n\tif (icd.error) {\n\t\ttd_verror(td, icd.error, \"io_u_queued_complete\");\n\t\treturn -1;\n\t}\n\n\tio_u_update_bytes_done(td, &icd);\n\n\treturn ret;\n}\n\n/*\n * Call when io_u is really queued, to update the submission latency.\n */\nvoid io_u_queued(struct thread_data *td, struct io_u *io_u)\n{\n\tif (!td->o.disable_slat && ramp_time_over(td) && td->o.stats) {\n\t\tif (td->parent)\n\t\t\ttd = td->parent;\n\t\tadd_slat_sample(td, io_u);\n\t}\n}\n\n/*\n * See if we should reuse the last seed, if dedupe is enabled\n */\nstatic struct frand_state *get_buf_state(struct thread_data *td)\n{\n\tunsigned int v;\n\tunsigned long long i;\n\n\tif (!td->o.dedupe_percentage)\n\t\treturn &td->buf_state;\n\telse if (td->o.dedupe_percentage == 100) {\n\t\tfrand_copy(&td->buf_state_prev, &td->buf_state);\n\t\treturn &td->buf_state;\n\t}\n\n\tv = rand_between(&td->dedupe_state, 1, 100);\n\n\tif (v <= td->o.dedupe_percentage)\n\t\tswitch (td->o.dedupe_mode) {\n\t\tcase DEDUPE_MODE_REPEAT:\n\t\t\t/*\n\t\t\t* The caller advances the returned frand_state.\n\t\t\t* A copy of prev should be returned instead since\n\t\t\t* a subsequent intention to generate a deduped buffer\n\t\t\t* might result in generating a unique one\n\t\t\t*/\n\t\t\tfrand_copy(&td->buf_state_ret, &td->buf_state_prev);\n\t\t\treturn &td->buf_state_ret;\n\t\tcase DEDUPE_MODE_WORKING_SET:\n\t\t\ti = rand_between(&td->dedupe_working_set_index_state, 0, td->num_unique_pages - 1);\n\t\t\tfrand_copy(&td->buf_state_ret, &td->dedupe_working_set_states[i]);\n\t\t\treturn &td->buf_state_ret;\n\t\tdefault:\n\t\t\tlog_err(\"unexpected dedupe mode %u\\n\", td->o.dedupe_mode);\n\t\t\tassert(0);\n\t\t}\n\n\treturn &td->buf_state;\n}\n\nstatic void save_buf_state(struct thread_data *td, struct frand_state *rs)\n{\n\tif (td->o.dedupe_percentage == 100)\n\t\tfrand_copy(rs, &td->buf_state_prev);\n\telse if (rs == &td->buf_state)\n\t\tfrand_copy(&td->buf_state_prev, rs);\n}\n\nvoid fill_io_buffer(struct thread_data *td, void *buf, unsigned long long min_write,\n\t\t    unsigned long long max_bs)\n{\n\tstruct thread_options *o = &td->o;\n\n\tif (o->mem_type == MEM_CUDA_MALLOC)\n\t\treturn;\n\n\tif (o->compress_percentage || o->dedupe_percentage) {\n\t\tunsigned int perc = td->o.compress_percentage;\n\t\tstruct frand_state *rs = NULL;\n\t\tunsigned long long left = max_bs;\n\t\tunsigned long long this_write;\n\n\t\tdo {\n\t\t\t/*\n\t\t\t * Buffers are either entirely dedupe-able or not.\n\t\t\t * If we choose to dedup, the buffer should undergo\n\t\t\t * the same manipulation as the original write. Which\n\t\t\t * means we should retrack the steps we took for compression\n\t\t\t * as well.\n\t\t\t */\n\t\t\tif (!rs)\n\t\t\t\trs = get_buf_state(td);\n\n\t\t\tmin_write = min(min_write, left);\n\n\t\t\tthis_write = min_not_zero(min_write,\n\t\t\t\t\t\t(unsigned long long) td->o.compress_chunk);\n\n\t\t\tfill_random_buf_percentage(rs, buf, perc,\n\t\t\t\tthis_write, this_write,\n\t\t\t\to->buffer_pattern,\n\t\t\t\to->buffer_pattern_bytes);\n\n\t\t\tbuf += this_write;\n\t\t\tleft -= this_write;\n\t\t\tsave_buf_state(td, rs);\n\t\t} while (left);\n\t} else if (o->buffer_pattern_bytes)\n\t\tfill_buffer_pattern(td, buf, max_bs);\n\telse if (o->zero_buffers)\n\t\tmemset(buf, 0, max_bs);\n\telse\n\t\tfill_random_buf(get_buf_state(td), buf, max_bs);\n}\n\n/*\n * \"randomly\" fill the buffer contents\n */\nvoid io_u_fill_buffer(struct thread_data *td, struct io_u *io_u,\n\t\t      unsigned long long min_write, unsigned long long max_bs)\n{\n\tio_u->buf_filled_len = 0;\n\tfill_io_buffer(td, io_u->buf, min_write, max_bs);\n}\n\nstatic int do_sync_file_range(const struct thread_data *td,\n\t\t\t      struct fio_file *f)\n{\n\tuint64_t offset, nbytes;\n\n\toffset = f->first_write;\n\tnbytes = f->last_write - f->first_write;\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\treturn sync_file_range(f->fd, offset, nbytes, td->o.sync_file_range);\n}\n\nint do_io_u_sync(const struct thread_data *td, struct io_u *io_u)\n{\n\tint ret;\n\n\tif (io_u->ddir == DDIR_SYNC) {\n#ifdef CONFIG_FCNTL_SYNC\n\t\tret = fcntl(io_u->file->fd, F_FULLFSYNC);\n#else\n\t\tret = fsync(io_u->file->fd);\n#endif\n\t} else if (io_u->ddir == DDIR_DATASYNC) {\n#ifdef CONFIG_FDATASYNC\n\t\tret = fdatasync(io_u->file->fd);\n#else\n\t\tret = io_u->xfer_buflen;\n\t\tio_u->error = EINVAL;\n#endif\n\t} else if (io_u->ddir == DDIR_SYNC_FILE_RANGE)\n\t\tret = do_sync_file_range(td, io_u->file);\n\telse {\n\t\tret = io_u->xfer_buflen;\n\t\tio_u->error = EINVAL;\n\t}\n\n\tif (ret < 0)\n\t\tio_u->error = errno;\n\n\treturn ret;\n}\n\nint do_io_u_trim(struct thread_data *td, struct io_u *io_u)\n{\n#ifndef FIO_HAVE_TRIM\n\tio_u->error = EINVAL;\n\treturn 0;\n#else\n\tstruct fio_file *f = io_u->file;\n\tint ret;\n\n\tif (td->o.zone_mode == ZONE_MODE_ZBD) {\n\t\tret = zbd_do_io_u_trim(td, io_u);\n\t\tif (ret == io_u_completed)\n\t\t\treturn io_u->xfer_buflen;\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tret = os_trim(f, io_u->offset, io_u->xfer_buflen);\n\tif (!ret)\n\t\treturn io_u->xfer_buflen;\n\nerr:\n\tio_u->error = ret;\n\treturn 0;\n#endif\n}\n"
        },
        {
          "name": "io_u.h",
          "type": "blob",
          "size": 4.8740234375,
          "content": "#ifndef FIO_IO_U\n#define FIO_IO_U\n\n#include \"compiler/compiler.h\"\n#include \"os/os.h\"\n#include \"io_ddir.h\"\n#include \"debug.h\"\n#include \"file.h\"\n#include \"workqueue.h\"\n\n#ifdef CONFIG_LIBAIO\n#include <libaio.h>\n#endif\n\nenum {\n\tIO_U_F_FREE\t\t= 1 << 0,\n\tIO_U_F_FLIGHT\t\t= 1 << 1,\n\tIO_U_F_NO_FILE_PUT\t= 1 << 2,\n\tIO_U_F_IN_CUR_DEPTH\t= 1 << 3,\n\tIO_U_F_BUSY_OK\t\t= 1 << 4,\n\tIO_U_F_TRIMMED\t\t= 1 << 5,\n\tIO_U_F_BARRIER\t\t= 1 << 6,\n\tIO_U_F_VER_LIST\t\t= 1 << 7,\n\tIO_U_F_PATTERN_DONE\t= 1 << 8,\n\tIO_U_F_DEVICE_ERROR\t= 1 << 9,\n\tIO_U_F_VER_IN_DEV\t= 1 << 10, /* Verify data in device */\n};\n\n/*\n * The io unit\n */\nstruct io_u {\n\tstruct timespec start_time;\n\tstruct timespec issue_time;\n\n\tstruct fio_file *file;\n\tunsigned int flags;\n\tenum fio_ddir ddir;\n\n\t/*\n\t * For replay workloads, we may want to account as a different\n\t * IO type than what is being submitted.\n\t */\n\tenum fio_ddir acct_ddir;\n\n\t/*\n\t * Write generation\n\t */\n\tunsigned short numberio;\n\n\t/*\n\t * IO priority.\n\t */\n\tunsigned short ioprio;\n\tunsigned short clat_prio_index;\n\n\t/*\n\t * number of trim ranges for this IO.\n\t */\n\tunsigned int number_trim;\n\n\t/*\n\t * Allocated/set buffer and length\n\t */\n\tunsigned long long buflen;\n\tunsigned long long offset;\t/* is really ->xfer_offset... */\n\tunsigned long long verify_offset;\t/* is really ->offset */\n\tvoid *buf;\n\n\t/*\n\t * Initial seed for generating the buffer contents\n\t */\n\tuint64_t rand_seed;\n\n\t/*\n\t * IO engine state, may be different from above when we get\n\t * partial transfers / residual data counts\n\t */\n\tvoid *xfer_buf;\n\tunsigned long long xfer_buflen;\n\n\t/*\n\t * Parameter related to pre-filled buffers and\n\t * their size to handle variable block sizes.\n\t */\n\tunsigned long long buf_filled_len;\n\n\tstruct io_piece *ipo;\n\n\tunsigned long long resid;\n\tunsigned int error;\n\n\t/*\n\t * io engine private data\n\t */\n\tunion {\n\t\tunsigned int index;\n\t\tunsigned int seen;\n\t};\n\tvoid *engine_data;\n\n\tunion {\n\t\tstruct flist_head verify_list;\n\t\tstruct workqueue_work work;\n\t};\n\n\t/*\n\t * ZBD mode zbd_queue_io callback: called after engine->queue operation\n\t * to advance a zone write pointer and eventually unlock the I/O zone.\n\t * @q indicates the I/O queue status (busy, queued or completed).\n\t * @success == true means that the I/O operation has been queued or\n\t * completed successfully.\n\t */\n\tvoid (*zbd_queue_io)(struct thread_data *td, struct io_u *, int q,\n\t\t\t     bool success);\n\n\t/*\n\t * ZBD mode zbd_put_io callback: called in after completion of an I/O\n\t * or commit of an async I/O to unlock the I/O target zone.\n\t */\n\tvoid (*zbd_put_io)(struct thread_data *td, const struct io_u *);\n\n\t/*\n\t * Callback for io completion\n\t */\n\tint (*end_io)(struct thread_data *, struct io_u **);\n\n\tuint32_t dtype;\n\tuint32_t dspec;\n\n\tunion {\n#ifdef CONFIG_LIBAIO\n\t\tstruct iocb iocb;\n#endif\n#ifdef CONFIG_POSIXAIO\n\t\tos_aiocb_t aiocb;\n#endif\n#ifdef FIO_HAVE_SGIO\n\t\tstruct sg_io_hdr hdr;\n#endif\n#ifdef CONFIG_SOLARISAIO\n\t\taio_result_t resultp;\n#endif\n#ifdef CONFIG_RDMA\n\t\tstruct ibv_mr *mr;\n#endif\n\t\tvoid *mmap_data;\n\t};\n};\n\n/*\n * io unit handling\n */\nextern struct io_u *__get_io_u(struct thread_data *);\nextern struct io_u *get_io_u(struct thread_data *);\nextern void put_io_u(struct thread_data *, struct io_u *);\nextern void clear_io_u(struct thread_data *, struct io_u *);\nextern void requeue_io_u(struct thread_data *, struct io_u **);\nextern int __must_check io_u_sync_complete(struct thread_data *, struct io_u *);\nextern int __must_check io_u_queued_complete(struct thread_data *, int);\nextern void io_u_queued(struct thread_data *, struct io_u *);\nextern int io_u_quiesce(struct thread_data *);\nextern void io_u_log_error(struct thread_data *, struct io_u *);\nextern void io_u_mark_depth(struct thread_data *, unsigned int);\nextern void fill_io_buffer(struct thread_data *, void *, unsigned long long, unsigned long long);\nextern void io_u_fill_buffer(struct thread_data *td, struct io_u *, unsigned long long, unsigned long long);\nvoid io_u_mark_complete(struct thread_data *, unsigned int);\nvoid io_u_mark_submit(struct thread_data *, unsigned int);\nbool queue_full(const struct thread_data *);\n\nint do_io_u_sync(const struct thread_data *, struct io_u *);\nint do_io_u_trim(struct thread_data *, struct io_u *);\n\n#ifdef FIO_INC_DEBUG\nstatic inline void dprint_io_u(struct io_u *io_u, const char *p)\n{\n\tstruct fio_file *f = io_u->file;\n\n\tif (f)\n\t\tdprint(FD_IO, \"%s: io_u %p: off=0x%llx,len=0x%llx,ddir=%d,file=%s\\n\",\n\t\t\t\tp, io_u,\n\t\t\t\t(unsigned long long) io_u->offset,\n\t\t\t\tio_u->buflen, io_u->ddir,\n\t\t\t\tf->file_name);\n\telse\n\t\tdprint(FD_IO, \"%s: io_u %p: off=0x%llx,len=0x%llx,ddir=%d\\n\",\n\t\t\t\tp, io_u,\n\t\t\t\t(unsigned long long) io_u->offset,\n\t\t\t\tio_u->buflen, io_u->ddir);\n}\n#else\n#define dprint_io_u(io_u, p)\n#endif\n\nstatic inline enum fio_ddir acct_ddir(struct io_u *io_u)\n{\n\tif (io_u->acct_ddir != -1)\n\t\treturn io_u->acct_ddir;\n\n\treturn io_u->ddir;\n}\n\n#define io_u_clear(td, io_u, val)\t\\\n\ttd_flags_clear((td), &(io_u->flags), (val))\n#define io_u_set(td, io_u, val)\t\t\\\n\ttd_flags_set((td), &(io_u)->flags, (val))\n\n#endif\n"
        },
        {
          "name": "io_u_queue.c",
          "type": "blob",
          "size": 0.9462890625,
          "content": "#include <stdlib.h>\n#include <string.h>\n#include \"io_u_queue.h\"\n#include \"smalloc.h\"\n\nbool io_u_qinit(struct io_u_queue *q, unsigned int nr, bool shared)\n{\n\tif (shared)\n\t\tq->io_us = smalloc(nr * sizeof(struct io_u *));\n\telse\n\t\tq->io_us = calloc(nr, sizeof(struct io_u *));\n\n\tif (!q->io_us)\n\t\treturn false;\n\n\tq->nr = 0;\n\tq->max = nr;\n\treturn true;\n}\n\nvoid io_u_qexit(struct io_u_queue *q, bool shared)\n{\n\tif (shared)\n\t\tsfree(q->io_us);\n\telse\n\t\tfree(q->io_us);\n}\n\nbool io_u_rinit(struct io_u_ring *ring, unsigned int nr)\n{\n\tring->max = nr + 1;\n\tif (ring->max & (ring->max - 1)) {\n\t\tring->max--;\n\t\tring->max |= ring->max >> 1;\n\t\tring->max |= ring->max >> 2;\n\t\tring->max |= ring->max >> 4;\n\t\tring->max |= ring->max >> 8;\n\t\tring->max |= ring->max >> 16;\n\t\tring->max++;\n\t}\n\n\tring->ring = calloc(ring->max, sizeof(struct io_u *));\n\tif (!ring->ring)\n\t\treturn false;\n\n\tring->head = ring->tail = 0;\n\treturn true;\n}\n\nvoid io_u_rexit(struct io_u_ring *ring)\n{\n\tfree(ring->ring);\n}\n"
        },
        {
          "name": "io_u_queue.h",
          "type": "blob",
          "size": 1.5390625,
          "content": "#ifndef FIO_IO_U_QUEUE\n#define FIO_IO_U_QUEUE\n\n#include <assert.h>\n#include <stddef.h>\n\n#include \"lib/types.h\"\n\nstruct io_u;\n\nstruct io_u_queue {\n\tstruct io_u **io_us;\n\tunsigned int nr;\n\tunsigned int max;\n};\n\nstatic inline struct io_u *io_u_qpop(struct io_u_queue *q)\n{\n\tif (q->nr) {\n\t\tconst unsigned int next = --q->nr;\n\t\tstruct io_u *io_u = q->io_us[next];\n\n\t\tq->io_us[next] = NULL;\n\t\treturn io_u;\n\t}\n\n\treturn NULL;\n}\n\nstatic inline void io_u_qpush(struct io_u_queue *q, struct io_u *io_u)\n{\n\tif (q->nr < q->max) {\n\t\tq->io_us[q->nr++] = io_u;\n\t\treturn;\n\t}\n\n\tassert(0);\n}\n\nstatic inline int io_u_qempty(const struct io_u_queue *q)\n{\n\treturn !q->nr;\n}\n\n#define io_u_qiter(q, io_u, i)\t\\\n\tfor (i = 0; i < (q)->nr && (io_u = (q)->io_us[i]); i++)\n\nbool io_u_qinit(struct io_u_queue *q, unsigned int nr, bool shared);\nvoid io_u_qexit(struct io_u_queue *q, bool shared);\n\nstruct io_u_ring {\n\tunsigned int head;\n\tunsigned int tail;\n\tunsigned int max;\n\tstruct io_u **ring;\n};\n\nbool io_u_rinit(struct io_u_ring *ring, unsigned int nr);\nvoid io_u_rexit(struct io_u_ring *ring);\n\nstatic inline void io_u_rpush(struct io_u_ring *r, struct io_u *io_u)\n{\n\tif (r->head + 1 != r->tail) {\n\t\tr->ring[r->head] = io_u;\n\t\tr->head = (r->head + 1) & (r->max - 1);\n\t\treturn;\n\t}\n\n\tassert(0);\n}\n\nstatic inline struct io_u *io_u_rpop(struct io_u_ring *r)\n{\n\tif (r->head != r->tail) {\n\t\tstruct io_u *io_u = r->ring[r->tail];\n\n\t\tr->tail = (r->tail + 1) & (r->max - 1);\n\t\treturn io_u;\n\t}\n\n\treturn NULL;\n}\n\nstatic inline int io_u_rempty(struct io_u_ring *ring)\n{\n\treturn ring->head == ring->tail;\n}\n\n#endif\n"
        },
        {
          "name": "ioengines.c",
          "type": "blob",
          "size": 16.609375,
          "content": "/*\n * The io parts of the fio tool, includes workers for sync and mmap'ed\n * io, as well as both posix and linux libaio support.\n *\n * sync io is implemented on top of aio.\n *\n * This is not really specific to fio, if the get_io_u/put_io_u and\n * structures was pulled into this as well it would be a perfectly\n * generic io engine that could be used for other projects.\n *\n */\n#include <stdlib.h>\n#include <unistd.h>\n#include <string.h>\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <assert.h>\n#include <sys/types.h>\n#include <dirent.h>\n#include <errno.h>\n\n#include \"fio.h\"\n#include \"diskutil.h\"\n#include \"zbd.h\"\n\nstatic FLIST_HEAD(engine_list);\n\nstatic inline bool async_ioengine_sync_trim(struct thread_data *td,\n\t\t\t\t\t    struct io_u\t*io_u)\n{\n\treturn td_ioengine_flagged(td, FIO_ASYNCIO_SYNC_TRIM) &&\n\t\tio_u->ddir == DDIR_TRIM;\n}\n\nstatic bool check_engine_ops(struct thread_data *td, struct ioengine_ops *ops)\n{\n\tif (ops->version != FIO_IOOPS_VERSION) {\n\t\tlog_err(\"bad ioops version %d (want %d)\\n\", ops->version,\n\t\t\t\t\t\t\tFIO_IOOPS_VERSION);\n\t\treturn true;\n\t}\n\n\tif (!ops->queue) {\n\t\tlog_err(\"%s: no queue handler\\n\", ops->name);\n\t\treturn true;\n\t}\n\n\t/*\n\t * sync engines only need a ->queue()\n\t */\n\tif (ops->flags & FIO_SYNCIO)\n\t\treturn false;\n\n\t/*\n\t * async engines aren't reliable with offload\n\t */\n\tif ((td->o.io_submit_mode == IO_MODE_OFFLOAD) &&\n\t    (ops->flags & FIO_NO_OFFLOAD)) {\n\t\tlog_err(\"%s: can't be used with offloaded submit. Use a sync \"\n\t\t\t\"engine\\n\", ops->name);\n\t\treturn true;\n\t}\n\n\tif (!ops->event || !ops->getevents) {\n\t\tlog_err(\"%s: no event/getevents handler\\n\", ops->name);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nvoid unregister_ioengine(struct ioengine_ops *ops)\n{\n\tdprint(FD_IO, \"ioengine %s unregistered\\n\", ops->name);\n\tflist_del_init(&ops->list);\n}\n\nvoid register_ioengine(struct ioengine_ops *ops)\n{\n\tdprint(FD_IO, \"ioengine %s registered\\n\", ops->name);\n\tflist_add_tail(&ops->list, &engine_list);\n}\n\nstatic struct ioengine_ops *find_ioengine(const char *name)\n{\n\tstruct ioengine_ops *ops;\n\tstruct flist_head *entry;\n\n\tflist_for_each(entry, &engine_list) {\n\t\tops = flist_entry(entry, struct ioengine_ops, list);\n\t\tif (!strcmp(name, ops->name))\n\t\t\treturn ops;\n\t}\n\n\treturn NULL;\n}\n\n#ifdef CONFIG_DYNAMIC_ENGINES\nstatic void *dlopen_external(struct thread_data *td, const char *engine)\n{\n\tchar engine_path[PATH_MAX];\n\tvoid *dlhandle;\n\n\tsprintf(engine_path, \"%s/fio-%s.so\", FIO_EXT_ENG_DIR, engine);\n\n\tdprint(FD_IO, \"dlopen external %s\\n\", engine_path);\n\tdlhandle = dlopen(engine_path, RTLD_LAZY);\n\tif (!dlhandle)\n\t\tlog_info(\"Engine %s not found; Either name is invalid, was not built, or fio-engine-%s package is missing.\\n\",\n\t\t\t engine, engine);\n\n\treturn dlhandle;\n}\n#else\n#define dlopen_external(td, engine) (NULL)\n#endif\n\nstatic struct ioengine_ops *dlopen_ioengine(struct thread_data *td,\n\t\t\t\t\t    const char *engine_lib)\n{\n\tstruct ioengine_ops *ops;\n\tvoid *dlhandle;\n\n\tif (!strncmp(engine_lib, \"linuxaio\", 8) ||\n\t    !strncmp(engine_lib, \"aio\", 3))\n\t\tengine_lib = \"libaio\";\n\n\tdprint(FD_IO, \"dlopen engine %s\\n\", engine_lib);\n\n\tdlerror();\n\tdlhandle = dlopen(engine_lib, RTLD_LAZY);\n\tif (!dlhandle) {\n\t\tdlhandle = dlopen_external(td, engine_lib);\n\t\tif (!dlhandle) {\n\t\t\ttd_vmsg(td, -1, dlerror(), \"dlopen\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/*\n\t * Unlike the included modules, external engines should have a\n\t * non-static ioengine structure that we can reference.\n\t */\n\tops = dlsym(dlhandle, engine_lib);\n\tif (!ops)\n\t\tops = dlsym(dlhandle, \"ioengine\");\n\n\t/*\n\t * For some external engines (like C++ ones) it is not that trivial\n\t * to provide a non-static ionengine structure that we can reference.\n\t * Instead we call a method which allocates the required ioengine\n\t * structure.\n\t */\n\tif (!ops) {\n\t\tget_ioengine_t get_ioengine = dlsym(dlhandle, \"get_ioengine\");\n\n\t\tif (get_ioengine)\n\t\t\tget_ioengine(&ops);\n\t}\n\n\tif (!ops) {\n\t\ttd_vmsg(td, -1, dlerror(), \"dlsym\");\n\t\tdlclose(dlhandle);\n\t\treturn NULL;\n\t}\n\n\tops->dlhandle = dlhandle;\n\treturn ops;\n}\n\nstatic struct ioengine_ops *__load_ioengine(const char *engine)\n{\n\t/*\n\t * linux libaio has alias names, so convert to what we want\n\t */\n\tif (!strncmp(engine, \"linuxaio\", 8) || !strncmp(engine, \"aio\", 3)) {\n\t\tdprint(FD_IO, \"converting ioengine name: %s -> libaio\\n\",\n\t\t       engine);\n\t\tengine = \"libaio\";\n\t}\n\n\tdprint(FD_IO, \"load ioengine %s\\n\", engine);\n\treturn find_ioengine(engine);\n}\n\nstruct ioengine_ops *load_ioengine(struct thread_data *td)\n{\n\tstruct ioengine_ops *ops = NULL;\n\tconst char *name;\n\n\t/*\n\t * Use ->ioengine_so_path if an external ioengine path is specified.\n\t * In this case, ->ioengine is \"external\" which also means the prefix\n\t * for external ioengines \"external:\" is properly used.\n\t */\n\tname = td->o.ioengine_so_path ?: td->o.ioengine;\n\n\t/*\n\t * Try to load ->ioengine first, and if failed try to dlopen(3) either\n\t * ->ioengine or ->ioengine_so_path.  This is redundant for an external\n\t * ioengine with prefix, and also leaves the possibility of unexpected\n\t * behavior (e.g. if the \"external\" ioengine exists), but we do this\n\t * so as not to break job files not using the prefix.\n\t */\n\tops = __load_ioengine(td->o.ioengine);\n\n\t/* We do re-dlopen existing handles, for reference counting */\n\tif (!ops || ops->dlhandle)\n\t\tops = dlopen_ioengine(td, name);\n\n\t/*\n\t * If ops is NULL, we failed to load ->ioengine, and also failed to\n\t * dlopen(3) either ->ioengine or ->ioengine_so_path as a path.\n\t */\n\tif (!ops) {\n\t\tlog_err(\"fio: engine %s not loadable\\n\", name);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * Check that the required methods are there.\n\t */\n\tif (check_engine_ops(td, ops))\n\t\treturn NULL;\n\n\treturn ops;\n}\n\n/*\n * For cleaning up an ioengine which never made it to init().\n */\nvoid free_ioengine(struct thread_data *td)\n{\n\tassert(td != NULL && td->io_ops != NULL);\n\n\tdprint(FD_IO, \"free ioengine %s\\n\", td->io_ops->name);\n\n\tif (td->eo && td->io_ops->options) {\n\t\toptions_free(td->io_ops->options, td->eo);\n\t\tfree(td->eo);\n\t\ttd->eo = NULL;\n\t}\n\n\tif (td->io_ops->dlhandle) {\n\t\tdprint(FD_IO, \"dlclose ioengine %s\\n\", td->io_ops->name);\n\t\tdlclose(td->io_ops->dlhandle);\n\t}\n\n\ttd->io_ops = NULL;\n}\n\nvoid close_ioengine(struct thread_data *td)\n{\n\tdprint(FD_IO, \"close ioengine %s\\n\", td->io_ops->name);\n\n\tif (td->io_ops->cleanup) {\n\t\ttd->io_ops->cleanup(td);\n\t\ttd->io_ops_data = NULL;\n\t}\n\n\tfree_ioengine(td);\n}\n\nint td_io_prep(struct thread_data *td, struct io_u *io_u)\n{\n\tdprint_io_u(io_u, \"prep\");\n\tfio_ro_check(td, io_u);\n\n\tlock_file(td, io_u->file, io_u->ddir);\n\n\tif (td->io_ops->prep) {\n\t\tint ret = td->io_ops->prep(td, io_u);\n\n\t\tdprint(FD_IO, \"prep: io_u %p: ret=%d\\n\", io_u, ret);\n\n\t\tif (ret)\n\t\t\tunlock_file(td, io_u->file);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint td_io_getevents(struct thread_data *td, unsigned int min, unsigned int max,\n\t\t    const struct timespec *t)\n{\n\tint r = 0;\n\n\t/*\n\t * For ioengine=rdma one side operation RDMA_WRITE or RDMA_READ,\n\t * server side gets a message from the client\n\t * side that the task is finished, and\n\t * td->done is set to 1 after td_io_commit(). In this case,\n\t * there is no need to reap complete event in server side.\n\t */\n\tif (td->done)\n\t\treturn 0;\n\n\tif (min > 0 && td->io_ops->commit) {\n\t\tr = td->io_ops->commit(td);\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t}\n\tif (max > td->cur_depth)\n\t\tmax = td->cur_depth;\n\tif (min > max)\n\t\tmax = min;\n\n\tr = 0;\n\tif (max && td->io_ops->getevents)\n\t\tr = td->io_ops->getevents(td, min, max, t);\nout:\n\tif (r >= 0) {\n\t\t/*\n\t\t * Reflect that our submitted requests were retrieved with\n\t\t * whatever OS async calls are in the underlying engine.\n\t\t */\n\t\ttd->io_u_in_flight -= r;\n\t\tio_u_mark_complete(td, r);\n\t} else\n\t\ttd_verror(td, r, \"get_events\");\n\n\tdprint(FD_IO, \"getevents: %d\\n\", r);\n\treturn r;\n}\n\nenum fio_q_status td_io_queue(struct thread_data *td, struct io_u *io_u)\n{\n\tconst enum fio_ddir ddir = acct_ddir(io_u);\n\tunsigned long long buflen = io_u->xfer_buflen;\n\tenum fio_q_status ret;\n\n\tdprint_io_u(io_u, \"queue\");\n\tfio_ro_check(td, io_u);\n\n\tassert((io_u->flags & IO_U_F_FLIGHT) == 0);\n\tio_u_set(td, io_u, IO_U_F_FLIGHT);\n\n\t/*\n\t * If overlap checking was enabled in offload mode we\n\t * can release this lock that was acquired when we\n\t * started the overlap check because the IO_U_F_FLIGHT\n\t * flag is now set\n\t */\n\tif (td_offload_overlap(td)) {\n\t\tint res;\n\n\t\tres = pthread_mutex_unlock(&overlap_check);\n\t\tif (fio_unlikely(res != 0)) {\n\t\t\tlog_err(\"failed to unlock overlap check mutex, err: %i:%s\", errno, strerror(errno));\n\t\t\tabort();\n\t\t}\n\t}\n\n\tassert(fio_file_open(io_u->file));\n\n\t/*\n\t * If using a write iolog, store this entry.\n\t */\n\tlog_io_u(td, io_u);\n\n\tio_u->error = 0;\n\tio_u->resid = 0;\n\n\tif (td_ioengine_flagged(td, FIO_SYNCIO) ||\n\t\tasync_ioengine_sync_trim(td, io_u)) {\n\t\tif (fio_fill_issue_time(td)) {\n\t\t\tfio_gettime(&io_u->issue_time, NULL);\n\n\t\t\t/*\n\t\t\t * only used for iolog\n\t\t\t */\n\t\t\tif (td->o.read_iolog_file)\n\t\t\t\tmemcpy(&td->last_issue, &io_u->issue_time,\n\t\t\t\t\t\tsizeof(io_u->issue_time));\n\t\t}\n\t}\n\n\n\tif (ddir_rw(ddir)) {\n\t\tif (!(io_u->flags & IO_U_F_VER_LIST)) {\n\t\t\ttd->io_issues[ddir]++;\n\t\t\ttd->io_issue_bytes[ddir] += buflen;\n\t\t}\n\t\ttd->rate_io_issue_bytes[ddir] += buflen;\n\t}\n\n\tret = td->io_ops->queue(td, io_u);\n\tzbd_queue_io_u(td, io_u, ret);\n\n\tunlock_file(td, io_u->file);\n\n\tif (ret == FIO_Q_BUSY && ddir_rw(ddir)) {\n\t\ttd->io_issues[ddir]--;\n\t\ttd->io_issue_bytes[ddir] -= buflen;\n\t\ttd->rate_io_issue_bytes[ddir] -= buflen;\n\t\tio_u_clear(td, io_u, IO_U_F_FLIGHT);\n\t}\n\n\t/*\n\t * If an error was seen and the io engine didn't propagate it\n\t * back to 'td', do so.\n\t */\n\tif (io_u->error && !td->error)\n\t\ttd_verror(td, io_u->error, \"td_io_queue\");\n\n\t/*\n\t * Add warning for O_DIRECT so that users have an easier time\n\t * spotting potentially bad alignment. If this triggers for the first\n\t * IO, then it's likely an alignment problem or because the host fs\n\t * does not support O_DIRECT\n\t */\n\tif (io_u->error == EINVAL && td->io_issues[io_u->ddir & 1] == 1 &&\n\t    td->o.odirect) {\n\n\t\tlog_info(\"fio: first direct IO errored. File system may not \"\n\t\t\t \"support direct IO, or iomem_align= is bad, or \"\n\t\t\t \"invalid block size. Try setting direct=0.\\n\");\n\t}\n\n\tif (zbd_unaligned_write(io_u->error) &&\n\t    td->io_issues[io_u->ddir & 1] == 1 &&\n\t    td->o.zone_mode != ZONE_MODE_ZBD) {\n\t\tlog_info(\"fio: first I/O failed. If %s is a zoned block device, consider --zonemode=zbd\\n\",\n\t\t\t io_u->file->file_name);\n\t}\n\n\tif (!td->io_ops->commit) {\n\t\tio_u_mark_submit(td, 1);\n\t\tio_u_mark_complete(td, 1);\n\t}\n\n\tif (ret == FIO_Q_COMPLETED) {\n\t\tif (ddir_rw(io_u->ddir) ||\n\t\t    (ddir_sync(io_u->ddir) && td->runstate != TD_FSYNCING)) {\n\t\t\tio_u_mark_depth(td, 1);\n\t\t\ttd->ts.total_io_u[io_u->ddir]++;\n\t\t}\n\n\t\ttd->last_ddir_issued = ddir;\n\t} else if (ret == FIO_Q_QUEUED) {\n\t\ttd->io_u_queued++;\n\n\t\tif (ddir_rw(io_u->ddir) ||\n\t\t    (ddir_sync(io_u->ddir) && td->runstate != TD_FSYNCING))\n\t\t\ttd->ts.total_io_u[io_u->ddir]++;\n\n\t\tif (td->io_u_queued >= td->o.iodepth_batch)\n\t\t\ttd_io_commit(td);\n\n\t\ttd->last_ddir_issued = ddir;\n\t}\n\n\tif (!td_ioengine_flagged(td, FIO_SYNCIO) &&\n\t\t!async_ioengine_sync_trim(td, io_u)) {\n\t\tif (fio_fill_issue_time(td) &&\n\t\t\t!td_ioengine_flagged(td, FIO_ASYNCIO_SETS_ISSUE_TIME)) {\n\t\t\tfio_gettime(&io_u->issue_time, NULL);\n\n\t\t\t/*\n\t\t\t * only used for iolog\n\t\t\t */\n\t\t\tif (td->o.read_iolog_file)\n\t\t\t\tmemcpy(&td->last_issue, &io_u->issue_time,\n\t\t\t\t\t\tsizeof(io_u->issue_time));\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nint td_io_init(struct thread_data *td)\n{\n\tint ret = 0;\n\n\tif (td->io_ops->init) {\n\t\tret = td->io_ops->init(td);\n\t\tif (ret)\n\t\t\tlog_err(\"fio: io engine %s init failed.%s\\n\",\n\t\t\t\ttd->io_ops->name,\n\t\t\t\ttd->o.iodepth > 1 ?\n\t\t\t\t\" Perhaps try reducing io depth?\" : \"\");\n\t\telse\n\t\t\ttd->io_ops_init = 1;\n\t\tif (!td->error)\n\t\t\ttd->error = ret;\n\t}\n\n\treturn ret;\n}\n\nvoid td_io_commit(struct thread_data *td)\n{\n\tint ret;\n\n\tdprint(FD_IO, \"calling ->commit(), depth %d\\n\", td->cur_depth);\n\n\tif (!td->cur_depth || !td->io_u_queued)\n\t\treturn;\n\n\tio_u_mark_depth(td, td->io_u_queued);\n\n\tif (td->io_ops->commit) {\n\t\tret = td->io_ops->commit(td);\n\t\tif (ret)\n\t\t\ttd_verror(td, -ret, \"io commit\");\n\t}\n\n\t/*\n\t * Reflect that events were submitted as async IO requests.\n\t */\n\ttd->io_u_in_flight += td->io_u_queued;\n\ttd->io_u_queued = 0;\n}\n\nint td_io_open_file(struct thread_data *td, struct fio_file *f)\n{\n\tif (fio_file_closing(f)) {\n\t\t/*\n\t\t * Open translates to undo closing.\n\t\t */\n\t\tfio_file_clear_closing(f);\n\t\tget_file(f);\n\t\treturn 0;\n\t}\n\tassert(!fio_file_open(f));\n\tassert(f->fd == -1);\n\tassert(td->io_ops->open_file);\n\n\tif (td->io_ops->open_file(td, f)) {\n\t\tif (td->error == EINVAL && td->o.odirect)\n\t\t\tlog_err(\"fio: destination does not support O_DIRECT\\n\");\n\t\tif (td->error == EMFILE) {\n\t\t\tlog_err(\"fio: try reducing/setting openfiles (failed\"\n\t\t\t\t\" at %u of %u)\\n\", td->nr_open_files,\n\t\t\t\t\t\t\ttd->o.nr_files);\n\t\t}\n\n\t\tassert(f->fd == -1);\n\t\tassert(!fio_file_open(f));\n\t\treturn 1;\n\t}\n\n\tfio_file_reset(td, f);\n\tfio_file_set_open(f);\n\tfio_file_clear_closing(f);\n\tdisk_util_inc(f->du);\n\n\ttd->nr_open_files++;\n\tget_file(f);\n\n\tif (f->filetype == FIO_TYPE_PIPE) {\n\t\tif (td_random(td)) {\n\t\t\tlog_err(\"fio: can't seek on pipes (no random io)\\n\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (td_ioengine_flagged(td, FIO_DISKLESSIO))\n\t\tgoto done;\n\n\tif (td->o.invalidate_cache && file_invalidate_cache(td, f))\n\t\tgoto err;\n\n\tif (td->o.fadvise_hint != F_ADV_NONE &&\n\t    (f->filetype == FIO_TYPE_BLOCK || f->filetype == FIO_TYPE_FILE)) {\n\t\tint flags;\n\n\t\tif (td->o.fadvise_hint == F_ADV_TYPE) {\n\t\t\tif (td_random(td))\n\t\t\t\tflags = POSIX_FADV_RANDOM;\n\t\t\telse\n\t\t\t\tflags = POSIX_FADV_SEQUENTIAL;\n\t\t} else if (td->o.fadvise_hint == F_ADV_RANDOM)\n\t\t\tflags = POSIX_FADV_RANDOM;\n\t\telse if (td->o.fadvise_hint == F_ADV_SEQUENTIAL)\n\t\t\tflags = POSIX_FADV_SEQUENTIAL;\n#ifdef POSIX_FADV_NOREUSE\n\t\telse if (td->o.fadvise_hint == F_ADV_NOREUSE)\n\t\t\tflags = POSIX_FADV_NOREUSE;\n#endif\n\t\telse {\n\t\t\tlog_err(\"fio: unknown fadvise type %d\\n\",\n\t\t\t\t\t\t\ttd->o.fadvise_hint);\n\t\t\tflags = POSIX_FADV_NORMAL;\n\t\t}\n\n\t\tif (posix_fadvise(f->fd, f->file_offset, f->io_size, flags) < 0) {\n\t\t\tif (!fio_did_warn(FIO_WARN_FADVISE))\n\t\t\t\tlog_err(\"fio: fadvise hint failed\\n\");\n\t\t}\n\t}\n#ifdef FIO_HAVE_WRITE_HINT\n\tif (fio_option_is_set(&td->o, write_hint) &&\n\t    (f->filetype == FIO_TYPE_BLOCK || f->filetype == FIO_TYPE_FILE)) {\n\t\tuint64_t hint = td->o.write_hint;\n\t\tint res;\n\n\t\t/*\n\t\t * For direct IO, set the hint on the file descriptor if that is\n\t\t * supported. Otherwise set it on the inode. For buffered IO, we\n\t\t * need to set it on the inode.\n\t\t */\n\t\tif (td->o.odirect) {\n\t\t\tres = fcntl(f->fd, F_SET_FILE_RW_HINT, &hint);\n\t\t\tif (res < 0)\n\t\t\t\tres = fcntl(f->fd, F_SET_RW_HINT, &hint);\n\t\t} else {\n\t\t\tres = fcntl(f->fd, F_SET_RW_HINT, &hint);\n\t\t}\n\t\tif (res < 0) {\n\t\t\ttd_verror(td, errno, \"fcntl write hint\");\n\t\t\tgoto err;\n\t\t}\n\t}\n#endif\n\n\tif (td->o.odirect && !OS_O_DIRECT && fio_set_directio(td, f))\n\t\tgoto err;\n\ndone:\n\tlog_file(td, f, FIO_LOG_OPEN_FILE);\n\treturn 0;\nerr:\n\tdisk_util_dec(f->du);\n\tif (td->io_ops->close_file)\n\t\ttd->io_ops->close_file(td, f);\n\treturn 1;\n}\n\nint td_io_close_file(struct thread_data *td, struct fio_file *f)\n{\n\tif (!fio_file_closing(f))\n\t\tlog_file(td, f, FIO_LOG_CLOSE_FILE);\n\n\t/*\n\t * mark as closing, do real close when last io on it has completed\n\t */\n\tfio_file_set_closing(f);\n\n\treturn put_file(td, f);\n}\n\nint td_io_unlink_file(struct thread_data *td, struct fio_file *f)\n{\n\tif (td->io_ops->unlink_file)\n\t\treturn td->io_ops->unlink_file(td, f);\n\telse {\n\t\tint ret;\n\n\t\tret = unlink(f->file_name);\n\t\tif (ret < 0)\n\t\t\treturn errno;\n\n\t\treturn 0;\n\t}\n}\n\nint td_io_get_file_size(struct thread_data *td, struct fio_file *f)\n{\n\tif (!td->io_ops->get_file_size)\n\t\treturn 0;\n\n\treturn td->io_ops->get_file_size(td, f);\n}\n\n#ifdef CONFIG_DYNAMIC_ENGINES\n/* Load all dynamic engines in FIO_EXT_ENG_DIR for enghelp command */\nstatic void\nfio_load_dynamic_engines(struct thread_data *td)\n{\n\tDIR *dirhandle = NULL;\n\tstruct dirent *dirent = NULL;\n\tchar engine_path[PATH_MAX];\n\n\tdirhandle = opendir(FIO_EXT_ENG_DIR);\n\tif (!dirhandle)\n\t\treturn;\n\n\twhile ((dirent = readdir(dirhandle)) != NULL) {\n\t\tif (!strcmp(dirent->d_name, \".\") ||\n\t\t    !strcmp(dirent->d_name, \"..\"))\n\t\t\tcontinue;\n\n\t\tsprintf(engine_path, \"%s/%s\", FIO_EXT_ENG_DIR, dirent->d_name);\n\t\tdlopen_ioengine(td, engine_path);\n\t}\n\n\tclosedir(dirhandle);\n}\n#else\n#define fio_load_dynamic_engines(td) do { } while (0)\n#endif\n\nint fio_show_ioengine_help(const char *engine)\n{\n\tstruct flist_head *entry;\n\tstruct thread_data td;\n\tstruct ioengine_ops *io_ops;\n\tchar *sep;\n\tint ret = 1;\n\n\tmemset(&td, 0, sizeof(struct thread_data));\n\n\tif (!engine || !*engine) {\n\t\tlog_info(\"Available IO engines:\\n\");\n\t\tfio_load_dynamic_engines(&td);\n\t\tflist_for_each(entry, &engine_list) {\n\t\t\tio_ops = flist_entry(entry, struct ioengine_ops, list);\n\t\t\tlog_info(\"\\t%s\\n\", io_ops->name);\n\t\t}\n\t\treturn 0;\n\t}\n\tsep = strchr(engine, ',');\n\tif (sep) {\n\t\t*sep = 0;\n\t\tsep++;\n\t}\n\n\ttd.o.ioengine = (char *)engine;\n\ttd.io_ops = load_ioengine(&td);\n\n\tif (!td.io_ops) {\n\t\tlog_info(\"IO engine %s not found\\n\", engine);\n\t\treturn 1;\n\t}\n\n\tif (td.io_ops->options)\n\t\tret = show_cmd_help(td.io_ops->options, sep);\n\telse\n\t\tlog_info(\"IO engine %s has no options\\n\", td.io_ops->name);\n\n\tfree_ioengine(&td);\n\treturn ret;\n}\n"
        },
        {
          "name": "ioengines.h",
          "type": "blob",
          "size": 5.9716796875,
          "content": "#ifndef FIO_IOENGINE_H\n#define FIO_IOENGINE_H\n\n#include <stddef.h>\n\n#include \"compiler/compiler.h\"\n#include \"flist.h\"\n#include \"io_u.h\"\n#include \"zbd_types.h\"\n#include \"dataplacement.h\"\n\n#define FIO_IOOPS_VERSION\t36\n\n#ifndef CONFIG_DYNAMIC_ENGINES\n#define FIO_STATIC\tstatic\n#else\n#define FIO_STATIC\n#endif\n\n/*\n * io_ops->queue() return values\n */\nenum fio_q_status {\n\tFIO_Q_COMPLETED\t= 0,\t\t/* completed sync */\n\tFIO_Q_QUEUED\t= 1,\t\t/* queued, will complete async */\n\tFIO_Q_BUSY\t= 2,\t\t/* no more room, call ->commit() */\n};\n\nstruct ioengine_ops {\n\tstruct flist_head list;\n\tconst char *name;\n\tint version;\n\tint flags;\n\tvoid *dlhandle;\n\tint (*setup)(struct thread_data *);\n\tint (*init)(struct thread_data *);\n\tint (*post_init)(struct thread_data *);\n\tint (*prep)(struct thread_data *, struct io_u *);\n\tenum fio_q_status (*queue)(struct thread_data *, struct io_u *);\n\tint (*commit)(struct thread_data *);\n\tint (*getevents)(struct thread_data *, unsigned int, unsigned int, const struct timespec *);\n\tstruct io_u *(*event)(struct thread_data *, int);\n\tchar *(*errdetails)(struct thread_data *, struct io_u *);\n\tint (*cancel)(struct thread_data *, struct io_u *);\n\tvoid (*cleanup)(struct thread_data *);\n\tint (*open_file)(struct thread_data *, struct fio_file *);\n\tint (*close_file)(struct thread_data *, struct fio_file *);\n\tint (*invalidate)(struct thread_data *, struct fio_file *);\n\tint (*unlink_file)(struct thread_data *, struct fio_file *);\n\tint (*get_file_size)(struct thread_data *, struct fio_file *);\n\tint (*prepopulate_file)(struct thread_data *, struct fio_file *);\n\tvoid (*terminate)(struct thread_data *);\n\tint (*iomem_alloc)(struct thread_data *, size_t);\n\tvoid (*iomem_free)(struct thread_data *);\n\tint (*io_u_init)(struct thread_data *, struct io_u *);\n\tvoid (*io_u_free)(struct thread_data *, struct io_u *);\n\tint (*get_zoned_model)(struct thread_data *td,\n\t\t\t       struct fio_file *f, enum zbd_zoned_model *);\n\tint (*report_zones)(struct thread_data *, struct fio_file *,\n\t\t\t    uint64_t, struct zbd_zone *, unsigned int);\n\tint (*reset_wp)(struct thread_data *, struct fio_file *,\n\t\t\tuint64_t, uint64_t);\n\tint (*get_max_open_zones)(struct thread_data *, struct fio_file *,\n\t\t\t\t  unsigned int *);\n\tint (*get_max_active_zones)(struct thread_data *, struct fio_file *,\n\t\t\t\t    unsigned int *);\n\tint (*finish_zone)(struct thread_data *, struct fio_file *,\n\t\t\t   uint64_t, uint64_t);\n\tint (*fdp_fetch_ruhs)(struct thread_data *, struct fio_file *,\n\t\t\t      struct fio_ruhs_info *);\n\tint option_struct_size;\n\tstruct fio_option *options;\n};\n\nenum {\n\t__FIO_SYNCIO = 0,\t\t/* io engine has synchronous ->queue */\n\t__FIO_RAWIO,\t\t\t/* some sort of direct/raw io */\n\t__FIO_DISKLESSIO,\t\t/* no disk involved */\n\t__FIO_NOEXTEND,\t\t\t/* engine can't extend file */\n\t__FIO_NODISKUTIL,\t\t/* diskutil can't handle filename */\n\t__FIO_UNIDIR,\t\t\t/* engine is uni-directional */\n\t__FIO_NOIO,\t\t\t/* thread does only pseudo IO */\n\t__FIO_PIPEIO,\t\t\t/* input/output no seekable */\n\t__FIO_BARRIER,\t\t\t/* engine supports barriers */\n\t__FIO_MEMALIGN,\t\t\t/* engine wants aligned memory */\n\t__FIO_BIT_BASED,\t\t/* engine uses a bit base (e.g. uses Kbit as opposed to\n\t\t\t\t\t   KB) */\n\t__FIO_FAKEIO,\t\t\t/* engine pretends to do IO */\n\t__FIO_NOSTATS,\t\t\t/* don't do IO stats */\n\t__FIO_NOFILEHASH,\t\t/* doesn't hash the files for lookup later. */\n\t__FIO_ASYNCIO_SYNC_TRIM,\t/* io engine has async ->queue except for trim */\n\t__FIO_NO_OFFLOAD,\t\t/* no async offload */\n\t__FIO_ASYNCIO_SETS_ISSUE_TIME,\t/* async ioengine with commit function that sets\n\t\t\t\t\t   issue_time */\n\t__FIO_SKIPPABLE_IOMEM_ALLOC,\t/* skip iomem_alloc & iomem_free if job sets mem/iomem */\n\t__FIO_RO_NEEDS_RW_OPEN,\t\t/* open files in rw mode even if we have a read job; only\n\t\t\t\t\t   affects ioengines using generic_open_file */\n\t__FIO_MULTI_RANGE_TRIM,\t\t/* ioengine supports trim with more than one range */\n\t__FIO_ATOMICWRITES,\t\t/* ioengine supports atomic writes */\n\t__FIO_IOENGINE_F_LAST,\t\t/* not a real bit; used to count number of bits */\n};\n\nenum fio_ioengine_flags {\n\tFIO_SYNCIO\t\t\t= 1 << __FIO_SYNCIO,\n\tFIO_RAWIO\t\t\t= 1 << __FIO_RAWIO,\n\tFIO_DISKLESSIO\t\t\t= 1 << __FIO_DISKLESSIO,\n\tFIO_NOEXTEND\t\t\t= 1 << __FIO_NOEXTEND,\n\tFIO_NODISKUTIL  \t\t= 1 << __FIO_NODISKUTIL,\n\tFIO_UNIDIR\t\t\t= 1 << __FIO_UNIDIR,\n\tFIO_NOIO\t\t\t= 1 << __FIO_NOIO,\n\tFIO_PIPEIO\t\t\t= 1 << __FIO_PIPEIO,\n\tFIO_BARRIER\t\t\t= 1 << __FIO_BARRIER,\n\tFIO_MEMALIGN\t\t\t= 1 << __FIO_MEMALIGN,\n\tFIO_BIT_BASED\t\t\t= 1 << __FIO_BIT_BASED,\n\tFIO_FAKEIO\t\t\t= 1 << __FIO_FAKEIO,\n\tFIO_NOSTATS\t\t\t= 1 << __FIO_NOSTATS,\n\tFIO_NOFILEHASH\t\t\t= 1 << __FIO_NOFILEHASH,\n\tFIO_ASYNCIO_SYNC_TRIM\t\t= 1 << __FIO_ASYNCIO_SYNC_TRIM,\n\tFIO_NO_OFFLOAD\t\t\t= 1 << __FIO_NO_OFFLOAD,\n\tFIO_ASYNCIO_SETS_ISSUE_TIME\t= 1 << __FIO_ASYNCIO_SETS_ISSUE_TIME,\n\tFIO_SKIPPABLE_IOMEM_ALLOC\t= 1 << __FIO_SKIPPABLE_IOMEM_ALLOC,\n\tFIO_RO_NEEDS_RW_OPEN\t\t= 1 << __FIO_RO_NEEDS_RW_OPEN,\n\tFIO_MULTI_RANGE_TRIM\t\t= 1 << __FIO_MULTI_RANGE_TRIM,\n\tFIO_ATOMICWRITES\t\t= 1 << __FIO_ATOMICWRITES,\n};\n\n/*\n * External engine defined symbol to fill in the engine ops structure\n */\ntypedef void (*get_ioengine_t)(struct ioengine_ops **);\n\n/*\n * io engine entry points\n */\nextern int __must_check td_io_init(struct thread_data *);\nextern int __must_check td_io_prep(struct thread_data *, struct io_u *);\nextern enum fio_q_status __must_check td_io_queue(struct thread_data *, struct io_u *);\nextern int __must_check td_io_getevents(struct thread_data *, unsigned int, unsigned int, const struct timespec *);\nextern void td_io_commit(struct thread_data *);\nextern int __must_check td_io_open_file(struct thread_data *, struct fio_file *);\nextern int td_io_close_file(struct thread_data *, struct fio_file *);\nextern int td_io_unlink_file(struct thread_data *, struct fio_file *);\nextern int __must_check td_io_get_file_size(struct thread_data *, struct fio_file *);\n\nextern struct ioengine_ops *load_ioengine(struct thread_data *);\nextern void register_ioengine(struct ioengine_ops *);\nextern void unregister_ioengine(struct ioengine_ops *);\nextern void free_ioengine(struct thread_data *);\nextern void close_ioengine(struct thread_data *);\n\nextern int fio_show_ioengine_help(const char *engine);\n\n#endif\n"
        },
        {
          "name": "iolog.c",
          "type": "blob",
          "size": 40.5859375,
          "content": "/*\n * Code related to writing an iolog of what a thread is doing, and to\n * later read that back and replay\n */\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <unistd.h>\n#ifdef CONFIG_ZLIB\n#include <zlib.h>\n#endif\n\n#include \"flist.h\"\n#include \"fio.h\"\n#include \"trim.h\"\n#include \"filelock.h\"\n#include \"smalloc.h\"\n#include \"blktrace.h\"\n#include \"pshared.h\"\n#include \"lib/roundup.h\"\n\n#include <netinet/in.h>\n#include <netinet/tcp.h>\n#include <arpa/inet.h>\n#include <sys/stat.h>\n#include <sys/socket.h>\n#include <sys/un.h>\n\nstatic int iolog_flush(struct io_log *log);\n\nstatic const char iolog_ver2[] = \"fio version 2 iolog\";\nstatic const char iolog_ver3[] = \"fio version 3 iolog\";\n\nvoid queue_io_piece(struct thread_data *td, struct io_piece *ipo)\n{\n\tflist_add_tail(&ipo->list, &td->io_log_list);\n\ttd->total_io_size += ipo->len;\n}\n\nvoid log_io_u(const struct thread_data *td, const struct io_u *io_u)\n{\n\tstruct timespec now;\n\n\tif (!td->o.write_iolog_file)\n\t\treturn;\n\n\tfio_gettime(&now, NULL);\n\tfprintf(td->iolog_f, \"%llu %s %s %llu %llu\\n\",\n\t\t(unsigned long long) utime_since_now(&td->io_log_start_time),\n\t\tio_u->file->file_name, io_ddir_name(io_u->ddir), io_u->offset,\n\t\tio_u->buflen);\n\n}\n\nvoid log_file(struct thread_data *td, struct fio_file *f,\n\t      enum file_log_act what)\n{\n\tconst char *act[] = { \"add\", \"open\", \"close\" };\n\tstruct timespec now;\n\n\tassert(what < 3);\n\n\tif (!td->o.write_iolog_file)\n\t\treturn;\n\n\n\t/*\n\t * this happens on the pre-open/close done before the job starts\n\t */\n\tif (!td->iolog_f)\n\t\treturn;\n\n\tfio_gettime(&now, NULL);\n\tfprintf(td->iolog_f, \"%llu %s %s\\n\",\n\t\t(unsigned long long) utime_since_now(&td->io_log_start_time),\n\t\tf->file_name, act[what]);\n}\n\nstatic void iolog_delay(struct thread_data *td, unsigned long delay)\n{\n\tuint64_t usec = utime_since_now(&td->last_issue);\n\tunsigned long orig_delay = delay;\n\tstruct timespec ts;\n\tint ret = 0;\n\n\tif (delay < td->time_offset) {\n\t\ttd->time_offset = 0;\n\t\treturn;\n\t}\n\n\tdelay -= td->time_offset;\n\tif (delay < usec)\n\t\treturn;\n\n\tdelay -= usec;\n\n\tfio_gettime(&ts, NULL);\n\n\twhile (delay && !td->terminate) {\n\t\tret = io_u_queued_complete(td, 0);\n\t\tif (ret < 0)\n\t\t\ttd_verror(td, -ret, \"io_u_queued_complete\");\n\t\tif (td->flags & TD_F_REGROW_LOGS)\n\t\t\tregrow_logs(td);\n\t\tif (utime_since_now(&ts) > delay)\n\t\t\tbreak;\n\t}\n\n\tusec = utime_since_now(&ts);\n\tif (usec > orig_delay)\n\t\ttd->time_offset = usec - orig_delay;\n\telse\n\t\ttd->time_offset = 0;\n}\n\nstatic int ipo_special(struct thread_data *td, struct io_piece *ipo)\n{\n\tstruct fio_file *f;\n\tint ret;\n\n\t/*\n\t * Not a special ipo\n\t */\n\tif (ipo->ddir != DDIR_INVAL)\n\t\treturn 0;\n\n\tf = td->files[ipo->fileno];\n\n\tif (ipo->delay)\n\t\tiolog_delay(td, ipo->delay);\n\tif (fio_fill_issue_time(td))\n\t\tfio_gettime(&td->last_issue, NULL);\n\tswitch (ipo->file_action) {\n\tcase FIO_LOG_OPEN_FILE:\n\t\tif (td->o.replay_redirect && fio_file_open(f)) {\n\t\t\tdprint(FD_FILE, \"iolog: ignoring re-open of file %s\\n\",\n\t\t\t\t\tf->file_name);\n\t\t\tbreak;\n\t\t}\n\t\tret = td_io_open_file(td, f);\n\t\tif (!ret) {\n\t\t\tif (td->o.dp_type != FIO_DP_NONE) {\n\t\t\t\tint dp_init_ret = dp_init(td);\n\n\t\t\t\tif (dp_init_ret != 0) {\n\t\t\t\t\ttd_verror(td, abs(dp_init_ret), \"dp_init\");\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\ttd_verror(td, ret, \"iolog open file\");\n\t\treturn -1;\n\tcase FIO_LOG_CLOSE_FILE:\n\t\ttd_io_close_file(td, f);\n\t\tbreak;\n\tcase FIO_LOG_UNLINK_FILE:\n\t\ttd_io_unlink_file(td, f);\n\t\tbreak;\n\tcase FIO_LOG_ADD_FILE:\n\t\t/*\n\t\t * Nothing to do\n\t\t */\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: bad file action %d\\n\", ipo->file_action);\n\t\tbreak;\n\t}\n\n\treturn 1;\n}\n\nstatic bool read_iolog(struct thread_data *td);\n\nunsigned long long delay_since_ttime(const struct thread_data *td,\n\t       unsigned long long time)\n{\n\tdouble tmp;\n\tdouble scale;\n\tconst unsigned long long *last_ttime = &td->io_log_last_ttime;\n\n\tif (!*last_ttime || td->o.no_stall || time < *last_ttime)\n\t\treturn 0;\n\telse if (td->o.replay_time_scale == 100)\n\t\treturn time - *last_ttime;\n\n\n\tscale = (double) 100.0 / (double) td->o.replay_time_scale;\n\ttmp = time - *last_ttime;\n\treturn tmp * scale;\n}\n\nint read_iolog_get(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct io_piece *ipo;\n\tunsigned long elapsed;\n\n\twhile (!flist_empty(&td->io_log_list)) {\n\t\tint ret;\n\n\t\tif (td->o.read_iolog_chunked) {\n\t\t\tif (td->io_log_checkmark == td->io_log_current) {\n\t\t\t\tif (td->io_log_blktrace) {\n\t\t\t\t\tif (!read_blktrace(td))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t} else {\n\t\t\t\t\tif (!read_iolog(td))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttd->io_log_current--;\n\t\t}\n\t\tipo = flist_first_entry(&td->io_log_list, struct io_piece, list);\n\t\tflist_del(&ipo->list);\n\t\tremove_trim_entry(td, ipo);\n\n\t\tret = ipo_special(td, ipo);\n\t\tif (ret < 0) {\n\t\t\tfree(ipo);\n\t\t\tbreak;\n\t\t} else if (ret > 0) {\n\t\t\tfree(ipo);\n\t\t\tcontinue;\n\t\t}\n\n\t\tio_u->ddir = ipo->ddir;\n\t\tif (ipo->ddir != DDIR_WAIT) {\n\t\t\tio_u->offset = ipo->offset;\n\t\t\tio_u->verify_offset = ipo->offset;\n\t\t\tio_u->buflen = ipo->len;\n\t\t\tio_u->file = td->files[ipo->fileno];\n\t\t\tget_file(io_u->file);\n\t\t\tdprint(FD_IO, \"iolog: get %llu/%llu/%s\\n\", io_u->offset,\n\t\t\t\t\t\tio_u->buflen, io_u->file->file_name);\n\t\t\tif (ipo->delay)\n\t\t\t\tiolog_delay(td, ipo->delay);\n\n\t\t\tif (td->o.dp_type != FIO_DP_NONE)\n\t\t\t\tdp_fill_dspec_data(td, io_u);\n\t\t} else {\n\t\t\telapsed = mtime_since_genesis();\n\t\t\tif (ipo->delay > elapsed)\n\t\t\t\tusec_sleep(td, (ipo->delay - elapsed) * 1000);\n\t\t}\n\n\t\tfree(ipo);\n\n\t\tif (io_u->ddir != DDIR_WAIT)\n\t\t\treturn 0;\n\t}\n\n\ttd->done = 1;\n\treturn 1;\n}\n\nvoid prune_io_piece_log(struct thread_data *td)\n{\n\tstruct io_piece *ipo;\n\tstruct fio_rb_node *n;\n\n\twhile ((n = rb_first(&td->io_hist_tree)) != NULL) {\n\t\tipo = rb_entry(n, struct io_piece, rb_node);\n\t\trb_erase(n, &td->io_hist_tree);\n\t\tremove_trim_entry(td, ipo);\n\t\ttd->io_hist_len--;\n\t\tfree(ipo);\n\t}\n\n\twhile (!flist_empty(&td->io_hist_list)) {\n\t\tipo = flist_first_entry(&td->io_hist_list, struct io_piece, list);\n\t\tflist_del(&ipo->list);\n\t\tremove_trim_entry(td, ipo);\n\t\ttd->io_hist_len--;\n\t\tfree(ipo);\n\t}\n}\n\n/*\n * log a successful write, so we can unwind the log for verify\n */\nvoid log_io_piece(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_rb_node **p, *parent;\n\tstruct io_piece *ipo, *__ipo;\n\n\tipo = calloc(1, sizeof(struct io_piece));\n\tinit_ipo(ipo);\n\tipo->file = io_u->file;\n\tipo->offset = io_u->offset;\n\tipo->len = io_u->buflen;\n\tipo->numberio = io_u->numberio;\n\tipo->flags = IP_F_IN_FLIGHT;\n\n\tio_u->ipo = ipo;\n\n\tif (io_u_should_trim(td, io_u)) {\n\t\tflist_add_tail(&ipo->trim_list, &td->trim_list);\n\t\ttd->trim_entries++;\n\t}\n\n\t/*\n\t * Only sort writes if we don't have a random map in which case we need\n\t * to check for duplicate blocks and drop the old one, which we rely on\n\t * the rb insert/lookup for handling.\n\t */\n\tif (file_randommap(td, ipo->file)) {\n\t\tINIT_FLIST_HEAD(&ipo->list);\n\t\tflist_add_tail(&ipo->list, &td->io_hist_list);\n\t\tipo->flags |= IP_F_ONLIST;\n\t\ttd->io_hist_len++;\n\t\treturn;\n\t}\n\n\tRB_CLEAR_NODE(&ipo->rb_node);\n\n\t/*\n\t * Sort the entry into the verification list\n\t */\nrestart:\n\tp = &td->io_hist_tree.rb_node;\n\tparent = NULL;\n\twhile (*p) {\n\t\tint overlap = 0;\n\t\tparent = *p;\n\n\t\t__ipo = rb_entry(parent, struct io_piece, rb_node);\n\t\tif (ipo->file < __ipo->file)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (ipo->file > __ipo->file)\n\t\t\tp = &(*p)->rb_right;\n\t\telse if (ipo->offset < __ipo->offset) {\n\t\t\tp = &(*p)->rb_left;\n\t\t\toverlap = ipo->offset + ipo->len > __ipo->offset;\n\t\t}\n\t\telse if (ipo->offset > __ipo->offset) {\n\t\t\tp = &(*p)->rb_right;\n\t\t\toverlap = __ipo->offset + __ipo->len > ipo->offset;\n\t\t}\n\t\telse\n\t\t\toverlap = 1;\n\n\t\tif (overlap) {\n\t\t\tdprint(FD_IO, \"iolog: overlap %llu/%lu, %llu/%lu\\n\",\n\t\t\t\t__ipo->offset, __ipo->len,\n\t\t\t\tipo->offset, ipo->len);\n\t\t\ttd->io_hist_len--;\n\t\t\trb_erase(parent, &td->io_hist_tree);\n\t\t\tremove_trim_entry(td, __ipo);\n\t\t\tif (!(__ipo->flags & IP_F_IN_FLIGHT))\n\t\t\t\tfree(__ipo);\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\trb_link_node(&ipo->rb_node, parent, p);\n\trb_insert_color(&ipo->rb_node, &td->io_hist_tree);\n\tipo->flags |= IP_F_ONRB;\n\ttd->io_hist_len++;\n}\n\nvoid unlog_io_piece(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct io_piece *ipo = io_u->ipo;\n\n\tif (td->ts.nr_block_infos) {\n\t\tuint32_t *info = io_u_block_info(td, io_u);\n\t\tif (BLOCK_INFO_STATE(*info) < BLOCK_STATE_TRIM_FAILURE) {\n\t\t\tif (io_u->ddir == DDIR_TRIM)\n\t\t\t\t*info = BLOCK_INFO_SET_STATE(*info,\n\t\t\t\t\t\tBLOCK_STATE_TRIM_FAILURE);\n\t\t\telse if (io_u->ddir == DDIR_WRITE)\n\t\t\t\t*info = BLOCK_INFO_SET_STATE(*info,\n\t\t\t\t\t\tBLOCK_STATE_WRITE_FAILURE);\n\t\t}\n\t}\n\n\tif (!ipo)\n\t\treturn;\n\n\tif (ipo->flags & IP_F_ONRB)\n\t\trb_erase(&ipo->rb_node, &td->io_hist_tree);\n\telse if (ipo->flags & IP_F_ONLIST)\n\t\tflist_del(&ipo->list);\n\n\tfree(ipo);\n\tio_u->ipo = NULL;\n\ttd->io_hist_len--;\n}\n\nvoid trim_io_piece(const struct io_u *io_u)\n{\n\tstruct io_piece *ipo = io_u->ipo;\n\n\tif (!ipo)\n\t\treturn;\n\n\tipo->len = io_u->xfer_buflen - io_u->resid;\n}\n\nvoid write_iolog_close(struct thread_data *td)\n{\n\tif (!td->iolog_f)\n\t\treturn;\n\n\tfflush(td->iolog_f);\n\tfclose(td->iolog_f);\n\tfree(td->iolog_buf);\n\ttd->iolog_f = NULL;\n\ttd->iolog_buf = NULL;\n}\n\nint64_t iolog_items_to_fetch(struct thread_data *td)\n{\n\tstruct timespec now;\n\tuint64_t elapsed;\n\tuint64_t for_1s;\n\tint64_t items_to_fetch;\n\n\tif (!td->io_log_highmark)\n\t\treturn 10;\n\n\n\tfio_gettime(&now, NULL);\n\telapsed = ntime_since(&td->io_log_highmark_time, &now);\n\tif (elapsed) {\n\t\tfor_1s = (td->io_log_highmark - td->io_log_current) * 1000000000 / elapsed;\n\t\titems_to_fetch = for_1s - td->io_log_current;\n\t\tif (items_to_fetch < 0)\n\t\t\titems_to_fetch = 0;\n\t} else\n\t\titems_to_fetch = 0;\n\n\ttd->io_log_highmark = td->io_log_current + items_to_fetch;\n\ttd->io_log_checkmark = (td->io_log_highmark + 1) / 2;\n\tfio_gettime(&td->io_log_highmark_time, NULL);\n\n\treturn items_to_fetch;\n}\n\n#define io_act(_td, _r) (((_td)->io_log_version == 3 && (r) == 5) || \\\n\t\t\t\t\t((_td)->io_log_version == 2 && (r) == 4))\n#define file_act(_td, _r) (((_td)->io_log_version == 3 && (r) == 3) || \\\n\t\t\t\t\t((_td)->io_log_version == 2 && (r) == 2))\n\n/*\n * Read version 2 and 3 iolog data. It is enhanced to include per-file logging,\n * syncs, etc.\n */\nstatic bool read_iolog(struct thread_data *td)\n{\n\tunsigned long long offset;\n\tunsigned int bytes;\n\tunsigned long long delay = 0;\n\tint reads, writes, trims, waits, fileno = 0, file_action = 0; /* stupid gcc */\n\tchar *rfname, *fname, *act;\n\tchar *str, *p;\n\tenum fio_ddir rw;\n\tbool realloc = false;\n\tint64_t items_to_fetch = 0;\n\tint syncs;\n\n\tif (td->o.read_iolog_chunked) {\n\t\titems_to_fetch = iolog_items_to_fetch(td);\n\t\tif (!items_to_fetch)\n\t\t\treturn true;\n\t}\n\n\t/*\n\t * Read in the read iolog and store it, reuse the infrastructure\n\t * for doing verifications.\n\t */\n\tstr = malloc(4096);\n\trfname = fname = malloc(256+16);\n\tact = malloc(256+16);\n\n\tsyncs = reads = writes = trims = waits = 0;\n\twhile ((p = fgets(str, 4096, td->io_log_rfile)) != NULL) {\n\t\tstruct io_piece *ipo;\n\t\tint r;\n\t\tunsigned long long ttime;\n\n\t\tif (td->io_log_version == 3) {\n\t\t\tr = sscanf(p, \"%llu %256s %256s %llu %u\", &ttime, rfname, act,\n\t\t\t\t\t\t\t&offset, &bytes);\n\t\t\tdelay = delay_since_ttime(td, ttime);\n\t\t\ttd->io_log_last_ttime = ttime;\n\t\t\t/*\n\t\t\t * \"wait\" is not allowed with version 3\n\t\t\t */\n\t\t\tif (!strcmp(act, \"wait\")) {\n\t\t\t\tlog_err(\"iolog: ignoring wait command with\"\n\t\t\t\t\t\" version 3 for file %s\\n\", fname);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else /* version 2 */\n\t\t\tr = sscanf(p, \"%256s %256s %llu %u\", rfname, act, &offset, &bytes);\n\n\t\tif (td->o.replay_redirect)\n\t\t\tfname = td->o.replay_redirect;\n\n\t\tif (io_act(td, r)) {\n\t\t\t/*\n\t\t\t * Check action first\n\t\t\t */\n\t\t\tif (!strcmp(act, \"wait\"))\n\t\t\t\trw = DDIR_WAIT;\n\t\t\telse if (!strcmp(act, \"read\")) {\n\t\t\t\tif (td->o.replay_skip & (1u << DDIR_READ))\n\t\t\t\t\tcontinue;\n\t\t\t\trw = DDIR_READ;\n\t\t\t} else if (!strcmp(act, \"write\")) {\n\t\t\t\tif (td->o.replay_skip & (1u << DDIR_WRITE))\n\t\t\t\t\tcontinue;\n\t\t\t\trw = DDIR_WRITE;\n\t\t\t} else if (!strcmp(act, \"sync\")) {\n\t\t\t\tif (td->o.replay_skip & (1u << DDIR_SYNC))\n\t\t\t\t\tcontinue;\n\t\t\t\trw = DDIR_SYNC;\n\t\t\t} else if (!strcmp(act, \"datasync\"))\n\t\t\t\trw = DDIR_DATASYNC;\n\t\t\telse if (!strcmp(act, \"trim\")) {\n\t\t\t\tif (td->o.replay_skip & (1u << DDIR_TRIM))\n\t\t\t\t\tcontinue;\n\t\t\t\trw = DDIR_TRIM;\n\t\t\t} else {\n\t\t\t\tlog_err(\"fio: bad iolog file action: %s\\n\",\n\t\t\t\t\t\t\t\t\tact);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfileno = get_fileno(td, fname);\n\t\t} else if (file_act(td, r)) {\n\t\t\trw = DDIR_INVAL;\n\t\t\tif (!strcmp(act, \"add\")) {\n\t\t\t\tif (td->o.replay_redirect &&\n\t\t\t\t    get_fileno(td, fname) != -1) {\n\t\t\t\t\tdprint(FD_FILE, \"iolog: ignoring\"\n\t\t\t\t\t\t\" re-add of file %s\\n\", fname);\n\t\t\t\t} else {\n\t\t\t\t\tfileno = add_file(td, fname, td->subjob_number, 1);\n\t\t\t\t\tfile_action = FIO_LOG_ADD_FILE;\n\t\t\t\t}\n\t\t\t} else if (!strcmp(act, \"open\")) {\n\t\t\t\tfileno = get_fileno(td, fname);\n\t\t\t\tfile_action = FIO_LOG_OPEN_FILE;\n\t\t\t} else if (!strcmp(act, \"close\")) {\n\t\t\t\tfileno = get_fileno(td, fname);\n\t\t\t\tfile_action = FIO_LOG_CLOSE_FILE;\n\t\t\t} else {\n\t\t\t\tlog_err(\"fio: bad iolog file action: %s\\n\",\n\t\t\t\t\t\t\t\t\tact);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\tlog_err(\"bad iolog%d: %s\\n\", td->io_log_version, p);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (rw == DDIR_READ)\n\t\t\treads++;\n\t\telse if (rw == DDIR_WRITE) {\n\t\t\t/*\n\t\t\t * Don't add a write for ro mode\n\t\t\t */\n\t\t\tif (read_only)\n\t\t\t\tcontinue;\n\t\t\twrites++;\n\t\t} else if (rw == DDIR_TRIM) {\n\t\t\t/*\n\t\t\t * Don't add a trim for ro mode\n\t\t\t */\n\t\t\tif (read_only)\n\t\t\t\tcontinue;\n\t\t\ttrims++;\n\t\t} else if (rw == DDIR_WAIT) {\n\t\t\tif (td->o.no_stall)\n\t\t\t\tcontinue;\n\t\t\twaits++;\n\t\t} else if (rw == DDIR_INVAL) {\n\t\t} else if (ddir_sync(rw)) {\n\t\t\tsyncs++;\n\t\t} else {\n\t\t\tlog_err(\"bad ddir: %d\\n\", rw);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Make note of file\n\t\t */\n\t\tipo = calloc(1, sizeof(*ipo));\n\t\tinit_ipo(ipo);\n\t\tipo->ddir = rw;\n\t\tif (td->io_log_version == 3)\n\t\t\tipo->delay = delay;\n\t\tif (rw == DDIR_WAIT) {\n\t\t\tipo->delay = offset;\n\t\t} else {\n\t\t\tif (td->o.replay_scale)\n\t\t\t\tipo->offset = offset / td->o.replay_scale;\n\t\t\telse\n\t\t\t\tipo->offset = offset;\n\t\t\tipo_bytes_align(td->o.replay_align, ipo);\n\n\t\t\tipo->len = bytes;\n\t\t\tif (rw != DDIR_INVAL && bytes > td->o.max_bs[rw]) {\n\t\t\t\trealloc = true;\n\t\t\t\ttd->o.max_bs[rw] = bytes;\n\t\t\t}\n\t\t\tipo->fileno = fileno;\n\t\t\tipo->file_action = file_action;\n\t\t\ttd->o.size += bytes;\n\t\t}\n\n\t\tqueue_io_piece(td, ipo);\n\n\t\tif (td->o.read_iolog_chunked) {\n\t\t\ttd->io_log_current++;\n\t\t\titems_to_fetch--;\n\t\t\tif (items_to_fetch == 0)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tfree(str);\n\tfree(act);\n\tfree(rfname);\n\n\tif (td->o.read_iolog_chunked) {\n\t\ttd->io_log_highmark = td->io_log_current;\n\t\ttd->io_log_checkmark = (td->io_log_highmark + 1) / 2;\n\t\tfio_gettime(&td->io_log_highmark_time, NULL);\n\t}\n\n\tif (writes && read_only) {\n\t\tlog_err(\"fio: <%s> skips replay of %d writes due to\"\n\t\t\t\" read-only\\n\", td->o.name, writes);\n\t\twrites = 0;\n\t}\n\tif (syncs)\n\t\ttd->flags |= TD_F_SYNCS;\n\n\tif (td->o.read_iolog_chunked) {\n\t\tif (td->io_log_current == 0) {\n\t\t\treturn false;\n\t\t}\n\t\ttd->o.td_ddir = TD_DDIR_RW;\n\t\tif (realloc && td->orig_buffer)\n\t\t{\n\t\t\tio_u_quiesce(td);\n\t\t\tfree_io_mem(td);\n\t\t\tif (init_io_u_buffers(td))\n\t\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\n\tif (!reads && !writes && !waits && !trims)\n\t\treturn false;\n\n\ttd->o.td_ddir = 0;\n\tif (reads)\n\t\ttd->o.td_ddir |= TD_DDIR_READ;\n\tif (writes)\n\t\ttd->o.td_ddir |= TD_DDIR_WRITE;\n\tif (trims)\n\t\ttd->o.td_ddir |= TD_DDIR_TRIM;\n\n\treturn true;\n}\n\nstatic bool is_socket(const char *path)\n{\n\tstruct stat buf;\n\tint r;\n\n\tr = stat(path, &buf);\n\tif (r == -1)\n\t\treturn false;\n\n\treturn S_ISSOCK(buf.st_mode);\n}\n\nstatic int open_socket(const char *path)\n{\n\tstruct sockaddr_un addr;\n\tint ret, fd;\n\n\tfd = socket(AF_UNIX, SOCK_STREAM, 0);\n\tif (fd < 0)\n\t\treturn fd;\n\n\taddr.sun_family = AF_UNIX;\n\tif (snprintf(addr.sun_path, sizeof(addr.sun_path), \"%s\", path) >=\n\t    sizeof(addr.sun_path)) {\n\t\tlog_err(\"%s: path name %s is too long for a Unix socket\\n\",\n\t\t\t__func__, path);\n\t}\n\n\tret = connect(fd, (const struct sockaddr *)&addr, strlen(path) + sizeof(addr.sun_family));\n\tif (!ret)\n\t\treturn fd;\n\n\tclose(fd);\n\treturn -1;\n}\n\n/*\n * open iolog, check version, and call appropriate parser\n */\nstatic bool init_iolog_read(struct thread_data *td, char *fname)\n{\n\tchar buffer[256], *p;\n\tFILE *f = NULL;\n\n\tdprint(FD_IO, \"iolog: name=%s\\n\", fname);\n\n\tif (is_socket(fname)) {\n\t\tint fd;\n\n\t\tfd = open_socket(fname);\n\t\tif (fd >= 0)\n\t\t\tf = fdopen(fd, \"r\");\n\t} else if (!strcmp(fname, \"-\")) {\n\t\tf = stdin;\n\t} else\n\t\tf = fopen(fname, \"r\");\n\n\tif (!f) {\n\t\tperror(\"fopen read iolog\");\n\t\treturn false;\n\t}\n\n\tp = fgets(buffer, sizeof(buffer), f);\n\tif (!p) {\n\t\ttd_verror(td, errno, \"iolog read\");\n\t\tlog_err(\"fio: unable to read iolog\\n\");\n\t\tfclose(f);\n\t\treturn false;\n\t}\n\n\t/*\n\t * versions 2 and 3 of the iolog store a specific string as the\n\t * first line, check for that\n\t */\n\tif (!strncmp(iolog_ver2, buffer, strlen(iolog_ver2)))\n\t\ttd->io_log_version = 2;\n\telse if (!strncmp(iolog_ver3, buffer, strlen(iolog_ver3)))\n\t\ttd->io_log_version = 3;\n\telse {\n\t\tlog_err(\"fio: iolog version 1 is no longer supported\\n\");\n\t\tfclose(f);\n\t\treturn false;\n\t}\n\n\tfree_release_files(td);\n\ttd->io_log_rfile = f;\n\treturn read_iolog(td);\n}\n\n/*\n * Set up a log for storing io patterns.\n */\nstatic bool init_iolog_write(struct thread_data *td)\n{\n\tstruct fio_file *ff;\n\tFILE *f;\n\tunsigned int i;\n\n\tf = fopen(td->o.write_iolog_file, \"a\");\n\tif (!f) {\n\t\tperror(\"fopen write iolog\");\n\t\treturn false;\n\t}\n\n\t/*\n\t * That's it for writing, setup a log buffer and we're done.\n\t  */\n\ttd->iolog_f = f;\n\ttd->iolog_buf = malloc(8192);\n\tsetvbuf(f, td->iolog_buf, _IOFBF, 8192);\n\tfio_gettime(&td->io_log_start_time, NULL);\n\n\t/*\n\t * write our version line\n\t */\n\tif (fprintf(f, \"%s\\n\", iolog_ver3) < 0) {\n\t\tperror(\"iolog init\\n\");\n\t\treturn false;\n\t}\n\n\t/*\n\t * add all known files\n\t */\n\tfor_each_file(td, ff, i)\n\t\tlog_file(td, ff, FIO_LOG_ADD_FILE);\n\n\treturn true;\n}\n\nbool init_iolog(struct thread_data *td)\n{\n\tbool ret;\n\n\tif (td->o.read_iolog_file) {\n\t\tint need_swap;\n\t\tchar * fname = get_name_by_idx(td->o.read_iolog_file, td->subjob_number);\n\n\t\t/*\n\t\t * Check if it's a blktrace file and load that if possible.\n\t\t * Otherwise assume it's a normal log file and load that.\n\t\t */\n\t\tif (is_blktrace(fname, &need_swap)) {\n\t\t\ttd->io_log_blktrace = 1;\n\t\t\tret = init_blktrace_read(td, fname, need_swap);\n\t\t} else {\n\t\t\ttd->io_log_blktrace = 0;\n\t\t\tret = init_iolog_read(td, fname);\n\t\t}\n\t\tfree(fname);\n\t} else if (td->o.write_iolog_file)\n\t\tret = init_iolog_write(td);\n\telse\n\t\tret = true;\n\n\tif (!ret)\n\t\ttd_verror(td, EINVAL, \"failed initializing iolog\");\n\n\tinit_disk_util(td);\n\n\treturn ret;\n}\n\nvoid setup_log(struct io_log **log, struct log_params *p,\n\t       const char *filename)\n{\n\tstruct io_log *l;\n\tint i;\n\tstruct io_u_plat_entry *entry;\n\tstruct flist_head *list;\n\n\tl = scalloc(1, sizeof(*l));\n\tassert(l);\n\tINIT_FLIST_HEAD(&l->io_logs);\n\tl->log_type = p->log_type;\n\tl->log_offset = p->log_offset;\n\tl->log_prio = p->log_prio;\n\tl->log_issue_time = p->log_issue_time;\n\tl->log_gz = p->log_gz;\n\tl->log_gz_store = p->log_gz_store;\n\tl->avg_msec = p->avg_msec;\n\tl->hist_msec = p->hist_msec;\n\tl->hist_coarseness = p->hist_coarseness;\n\tl->filename = strdup(filename);\n\tl->td = p->td;\n\n\t/* Initialize histogram lists for each r/w direction,\n\t * with initial io_u_plat of all zeros:\n\t */\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tlist = &l->hist_window[i].list;\n\t\tINIT_FLIST_HEAD(list);\n\t\tentry = calloc(1, sizeof(struct io_u_plat_entry));\n\t\tflist_add(&entry->list, list);\n\t}\n\n\tif (l->td && l->td->o.io_submit_mode != IO_MODE_OFFLOAD) {\n\t\tunsigned int def_samples = DEF_LOG_ENTRIES;\n\t\tstruct io_logs *__p;\n\n\t\t__p = calloc(1, sizeof(*l->pending));\n\t\tif (l->td->o.iodepth > DEF_LOG_ENTRIES)\n\t\t\tdef_samples = roundup_pow2(l->td->o.iodepth);\n\t\t__p->max_samples = def_samples;\n\t\t__p->log = calloc(__p->max_samples, log_entry_sz(l));\n\t\tl->pending = __p;\n\t}\n\n\tif (l->log_offset)\n\t\tl->log_ddir_mask = LOG_OFFSET_SAMPLE_BIT;\n\tif (l->log_prio)\n\t\tl->log_ddir_mask |= LOG_PRIO_SAMPLE_BIT;\n\t/*\n\t * The bandwidth-log option generates agg-read_bw.log,\n\t * agg-write_bw.log and agg-trim_bw.log for which l->td is NULL.\n\t * Check if l->td is valid before dereferencing it.\n\t */\n\tif (l->td && l->td->o.log_max == IO_LOG_SAMPLE_BOTH)\n\t\tl->log_ddir_mask |= LOG_AVG_MAX_SAMPLE_BIT;\n\n\tif (l->log_issue_time)\n\t\tl->log_ddir_mask |= LOG_ISSUE_TIME_SAMPLE_BIT;\n\n\tINIT_FLIST_HEAD(&l->chunk_list);\n\n\tif (l->log_gz && !p->td)\n\t\tl->log_gz = 0;\n\telse if (l->log_gz || l->log_gz_store) {\n\t\tmutex_init_pshared(&l->chunk_lock);\n\t\tmutex_init_pshared(&l->deferred_free_lock);\n\t\tp->td->flags |= TD_F_COMPRESS_LOG;\n\t}\n\n\t*log = l;\n}\n\n#ifdef CONFIG_SETVBUF\nstatic void *set_file_buffer(FILE *f)\n{\n\tsize_t size = 1048576;\n\tvoid *buf;\n\n\tbuf = malloc(size);\n\tsetvbuf(f, buf, _IOFBF, size);\n\treturn buf;\n}\n\nstatic void clear_file_buffer(void *buf)\n{\n\tfree(buf);\n}\n#else\nstatic void *set_file_buffer(FILE *f)\n{\n\treturn NULL;\n}\n\nstatic void clear_file_buffer(void *buf)\n{\n}\n#endif\n\nvoid free_log(struct io_log *log)\n{\n\twhile (!flist_empty(&log->io_logs)) {\n\t\tstruct io_logs *cur_log;\n\n\t\tcur_log = flist_first_entry(&log->io_logs, struct io_logs, list);\n\t\tflist_del_init(&cur_log->list);\n\t\tfree(cur_log->log);\n\t\tsfree(cur_log);\n\t}\n\n\tif (log->pending) {\n\t\tfree(log->pending->log);\n\t\tfree(log->pending);\n\t\tlog->pending = NULL;\n\t}\n\n\tfree(log->pending);\n\tfree(log->filename);\n\tsfree(log);\n}\n\nuint64_t hist_sum(int j, int stride, uint64_t *io_u_plat,\n\t\tuint64_t *io_u_plat_last)\n{\n\tuint64_t sum;\n\tint k;\n\n\tif (io_u_plat_last) {\n\t\tfor (k = sum = 0; k < stride; k++)\n\t\t\tsum += io_u_plat[j + k] - io_u_plat_last[j + k];\n\t} else {\n\t\tfor (k = sum = 0; k < stride; k++)\n\t\t\tsum += io_u_plat[j + k];\n\t}\n\n\treturn sum;\n}\n\nstatic void flush_hist_samples(FILE *f, int hist_coarseness, void *samples,\n\t\t\t       uint64_t sample_size)\n{\n\tstruct io_sample *s;\n\tbool log_offset, log_issue_time;\n\tuint64_t i, j, nr_samples;\n\tstruct io_u_plat_entry *entry, *entry_before;\n\tuint64_t *io_u_plat;\n\tuint64_t *io_u_plat_before;\n\n\tint stride = 1 << hist_coarseness;\n\t\n\tif (!sample_size)\n\t\treturn;\n\n\ts = __get_sample(samples, 0, 0, 0);\n\tlog_offset = (s->__ddir & LOG_OFFSET_SAMPLE_BIT) != 0;\n\tlog_issue_time = (s->__ddir & LOG_ISSUE_TIME_SAMPLE_BIT) != 0;\n\n\tnr_samples = sample_size / __log_entry_sz(log_offset, log_issue_time);\n\n\tfor (i = 0; i < nr_samples; i++) {\n\t\ts = __get_sample(samples, log_offset, log_issue_time, i);\n\n\t\tentry = s->data.plat_entry;\n\t\tio_u_plat = entry->io_u_plat;\n\n\t\tentry_before = flist_first_entry(&entry->list, struct io_u_plat_entry, list);\n\t\tio_u_plat_before = entry_before->io_u_plat;\n\n\t\tfprintf(f, \"%lu, %u, %llu, \", (unsigned long) s->time,\n\t\t\t\t\t\tio_sample_ddir(s), (unsigned long long) s->bs);\n\t\tfor (j = 0; j < FIO_IO_U_PLAT_NR - stride; j += stride) {\n\t\t\tfprintf(f, \"%llu, \", (unsigned long long)\n\t\t\t        hist_sum(j, stride, io_u_plat, io_u_plat_before));\n\t\t}\n\t\tfprintf(f, \"%llu\\n\", (unsigned long long)\n\t\t        hist_sum(FIO_IO_U_PLAT_NR - stride, stride, io_u_plat,\n\t\t\t\t\tio_u_plat_before));\n\n\t\tflist_del(&entry_before->list);\n\t\tfree(entry_before);\n\t}\n}\n\nstatic int print_sample_fields(char **p, size_t *left, const char *fmt, ...) {\n\tva_list ap;\n\tint ret;\n\n\tva_start(ap, fmt);\n\tret = vsnprintf(*p, *left, fmt, ap);\n\tif (ret < 0 || ret >= *left) {\n\t\tlog_err(\"sample file write failed: %d\\n\", ret);\n\t\tva_end(ap);\n\t\treturn -1;\n\t}\n\tva_end(ap);\n\n\t*p += ret;\n\t*left -= ret;\n\n\treturn 0;\n}\n\n/*\n * flush_samples - Generate output for log samples\n * Each sample output is built using a temporary buffer. This buffer size\n * assumptions are:\n * - Each sample has less than 10 fields\n * - Each sample field fits in 25 characters (20 digits for 64 bit number\n *   and a few bytes delimiter)\n */\nvoid flush_samples(FILE *f, void *samples, uint64_t sample_size)\n{\n\tstruct io_sample *s;\n\tbool log_offset, log_prio, log_avg_max, log_issue_time;\n\tuint64_t i, nr_samples;\n\tchar buf[256];\n\tchar *p;\n\tsize_t left;\n\tint ret;\n\n\tif (!sample_size)\n\t\treturn;\n\n\ts = __get_sample(samples, 0, 0, 0);\n\tlog_offset = (s->__ddir & LOG_OFFSET_SAMPLE_BIT) != 0;\n\tlog_prio = (s->__ddir & LOG_PRIO_SAMPLE_BIT) != 0;\n\tlog_avg_max = (s->__ddir & LOG_AVG_MAX_SAMPLE_BIT) != 0;\n\tlog_issue_time = (s->__ddir & LOG_ISSUE_TIME_SAMPLE_BIT) != 0;\n\n\tnr_samples = sample_size / __log_entry_sz(log_offset, log_issue_time);\n\n\tfor (i = 0; i < nr_samples; i++) {\n\t\ts = __get_sample(samples, log_offset, log_issue_time, i);\n\t\tp = buf;\n\t\tleft = sizeof(buf);\n\n\t\tret = print_sample_fields(&p, &left, \"%\" PRIu64 \", %\" PRId64,\n\t\t\t\t\t  s->time, s->data.val.val0);\n\t\tif (ret)\n\t\t\treturn;\n\n\t\tif (log_avg_max) {\n\t\t\tret = print_sample_fields(&p, &left, \", %\" PRId64,\n\t\t\t\t\t\t  s->data.val.val1);\n\t\t\tif (ret)\n\t\t\t\treturn;\n\t\t}\n\n\t\tret = print_sample_fields(&p, &left, \", %u, %llu\",\n\t\t\t\t\t  io_sample_ddir(s),\n\t\t\t\t\t  (unsigned long long) s->bs);\n\t\tif (ret)\n\t\t\treturn;\n\n\t\tif (log_offset) {\n\t\t\tret = print_sample_fields(&p, &left, \", %llu\",\n\t\t\t\t\t\t  (unsigned long long) s->aux[IOS_AUX_OFFSET_INDEX]);\n\t\t\tif (ret)\n\t\t\t\treturn;\n\t\t}\n\n\t\tif (log_prio)\n\t\t\tret = print_sample_fields(&p, &left, \", 0x%04x\",\n\t\t\t\t\t\t  s->priority);\n\t\telse\n\t\t\tret = print_sample_fields(&p, &left, \", %u\",\n\t\t\t\t\t\t  ioprio_value_is_class_rt(s->priority));\n\t\tif (ret)\n\t\t\treturn;\n\n\t\tif (log_issue_time) {\n\t\t\tret = print_sample_fields(&p, &left, \", %llu\",\n\t\t\t\t\t\t  (unsigned long long) s->aux[IOS_AUX_ISSUE_TIME_INDEX]);\n\t\t\tif (ret)\n\t\t\t\treturn;\n\t\t}\n\n\t\tfprintf(f, \"%s\\n\", buf);\n\t}\n}\n\n#ifdef CONFIG_ZLIB\n\nstruct iolog_flush_data {\n\tstruct workqueue_work work;\n\tstruct io_log *log;\n\tvoid *samples;\n\tuint32_t nr_samples;\n\tbool free;\n};\n\n#define GZ_CHUNK\t131072\n\nstatic struct iolog_compress *get_new_chunk(unsigned int seq)\n{\n\tstruct iolog_compress *c;\n\n\tc = malloc(sizeof(*c));\n\tINIT_FLIST_HEAD(&c->list);\n\tc->buf = malloc(GZ_CHUNK);\n\tc->len = 0;\n\tc->seq = seq;\n\treturn c;\n}\n\nstatic void free_chunk(struct iolog_compress *ic)\n{\n\tfree(ic->buf);\n\tfree(ic);\n}\n\nstatic int z_stream_init(z_stream *stream, int gz_hdr)\n{\n\tint wbits = 15;\n\n\tmemset(stream, 0, sizeof(*stream));\n\tstream->zalloc = Z_NULL;\n\tstream->zfree = Z_NULL;\n\tstream->opaque = Z_NULL;\n\tstream->next_in = Z_NULL;\n\n\t/*\n\t * zlib magic - add 32 for auto-detection of gz header or not,\n\t * if we decide to store files in a gzip friendly format.\n\t */\n\tif (gz_hdr)\n\t\twbits += 32;\n\n\tif (inflateInit2(stream, wbits) != Z_OK)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstruct inflate_chunk_iter {\n\tunsigned int seq;\n\tint err;\n\tvoid *buf;\n\tsize_t buf_size;\n\tsize_t buf_used;\n\tsize_t chunk_sz;\n};\n\nstatic void finish_chunk(z_stream *stream, FILE *f,\n\t\t\t struct inflate_chunk_iter *iter)\n{\n\tint ret;\n\n\tret = inflateEnd(stream);\n\tif (ret != Z_OK)\n\t\tlog_err(\"fio: failed to end log inflation seq %d (%d)\\n\",\n\t\t\t\titer->seq, ret);\n\n\tflush_samples(f, iter->buf, iter->buf_used);\n\tfree(iter->buf);\n\titer->buf = NULL;\n\titer->buf_size = iter->buf_used = 0;\n}\n\n/*\n * Iterative chunk inflation. Handles cases where we cross into a new\n * sequence, doing flush finish of previous chunk if needed.\n */\nstatic size_t inflate_chunk(struct iolog_compress *ic, int gz_hdr, FILE *f,\n\t\t\t    z_stream *stream, struct inflate_chunk_iter *iter)\n{\n\tsize_t ret;\n\n\tdprint(FD_COMPRESS, \"inflate chunk size=%lu, seq=%u\\n\",\n\t\t\t\t(unsigned long) ic->len, ic->seq);\n\n\tif (ic->seq != iter->seq) {\n\t\tif (iter->seq)\n\t\t\tfinish_chunk(stream, f, iter);\n\n\t\tz_stream_init(stream, gz_hdr);\n\t\titer->seq = ic->seq;\n\t}\n\n\tstream->avail_in = ic->len;\n\tstream->next_in = ic->buf;\n\n\tif (!iter->buf_size) {\n\t\titer->buf_size = iter->chunk_sz;\n\t\titer->buf = malloc(iter->buf_size);\n\t}\n\n\twhile (stream->avail_in) {\n\t\tsize_t this_out = iter->buf_size - iter->buf_used;\n\t\tint err;\n\n\t\tstream->avail_out = this_out;\n\t\tstream->next_out = iter->buf + iter->buf_used;\n\n\t\terr = inflate(stream, Z_NO_FLUSH);\n\t\tif (err < 0) {\n\t\t\tlog_err(\"fio: failed inflating log: %d\\n\", err);\n\t\t\titer->err = err;\n\t\t\tbreak;\n\t\t}\n\n\t\titer->buf_used += this_out - stream->avail_out;\n\n\t\tif (!stream->avail_out) {\n\t\t\titer->buf_size += iter->chunk_sz;\n\t\t\titer->buf = realloc(iter->buf, iter->buf_size);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (err == Z_STREAM_END)\n\t\t\tbreak;\n\t}\n\n\tret = (void *) stream->next_in - ic->buf;\n\n\tdprint(FD_COMPRESS, \"inflated to size=%lu\\n\", (unsigned long) iter->buf_size);\n\n\treturn ret;\n}\n\n/*\n * Inflate stored compressed chunks, or write them directly to the log\n * file if so instructed.\n */\nstatic int inflate_gz_chunks(struct io_log *log, FILE *f)\n{\n\tstruct inflate_chunk_iter iter = { .chunk_sz = log->log_gz, };\n\tz_stream stream;\n\n\twhile (!flist_empty(&log->chunk_list)) {\n\t\tstruct iolog_compress *ic;\n\n\t\tic = flist_first_entry(&log->chunk_list, struct iolog_compress, list);\n\t\tflist_del(&ic->list);\n\n\t\tif (log->log_gz_store) {\n\t\t\tsize_t ret;\n\n\t\t\tdprint(FD_COMPRESS, \"log write chunk size=%lu, \"\n\t\t\t\t\"seq=%u\\n\", (unsigned long) ic->len, ic->seq);\n\n\t\t\tret = fwrite(ic->buf, ic->len, 1, f);\n\t\t\tif (ret != 1 || ferror(f)) {\n\t\t\t\titer.err = errno;\n\t\t\t\tlog_err(\"fio: error writing compressed log\\n\");\n\t\t\t}\n\t\t} else\n\t\t\tinflate_chunk(ic, log->log_gz_store, f, &stream, &iter);\n\n\t\tfree_chunk(ic);\n\t}\n\n\tif (iter.seq) {\n\t\tfinish_chunk(&stream, f, &iter);\n\t\tfree(iter.buf);\n\t}\n\n\treturn iter.err;\n}\n\n/*\n * Open compressed log file and decompress the stored chunks and\n * write them to stdout. The chunks are stored sequentially in the\n * file, so we iterate over them and do them one-by-one.\n */\nint iolog_file_inflate(const char *file)\n{\n\tstruct inflate_chunk_iter iter = { .chunk_sz = 64 * 1024 * 1024, };\n\tstruct iolog_compress ic;\n\tz_stream stream;\n\tstruct stat sb;\n\tsize_t ret;\n\tsize_t total;\n\tvoid *buf;\n\tFILE *f;\n\n\tf = fopen(file, \"rb\");\n\tif (!f) {\n\t\tperror(\"fopen\");\n\t\treturn 1;\n\t}\n\n\tif (stat(file, &sb) < 0) {\n\t\tfclose(f);\n\t\tperror(\"stat\");\n\t\treturn 1;\n\t}\n\n\tic.buf = buf = malloc(sb.st_size);\n\tic.len = sb.st_size;\n\tic.seq = 1;\n\n\tret = fread(ic.buf, ic.len, 1, f);\n\tif (ret == 0 && ferror(f)) {\n\t\tperror(\"fread\");\n\t\tfclose(f);\n\t\tfree(buf);\n\t\treturn 1;\n\t} else if (ferror(f) || (!feof(f) && ret != 1)) {\n\t\tlog_err(\"fio: short read on reading log\\n\");\n\t\tfclose(f);\n\t\tfree(buf);\n\t\treturn 1;\n\t}\n\n\tfclose(f);\n\n\t/*\n\t * Each chunk will return Z_STREAM_END. We don't know how many\n\t * chunks are in the file, so we just keep looping and incrementing\n\t * the sequence number until we have consumed the whole compressed\n\t * file.\n\t */\n\ttotal = ic.len;\n\tdo {\n\t\tsize_t iret;\n\n\t\tiret = inflate_chunk(&ic,  1, stdout, &stream, &iter);\n\t\ttotal -= iret;\n\t\tif (!total)\n\t\t\tbreak;\n\t\tif (iter.err)\n\t\t\tbreak;\n\n\t\tic.seq++;\n\t\tic.len -= iret;\n\t\tic.buf += iret;\n\t} while (1);\n\n\tif (iter.seq) {\n\t\tfinish_chunk(&stream, stdout, &iter);\n\t\tfree(iter.buf);\n\t}\n\n\tfree(buf);\n\treturn iter.err;\n}\n\n#else\n\nstatic int inflate_gz_chunks(struct io_log *log, FILE *f)\n{\n\treturn 0;\n}\n\nint iolog_file_inflate(const char *file)\n{\n\tlog_err(\"fio: log inflation not possible without zlib\\n\");\n\treturn 1;\n}\n\n#endif\n\nvoid flush_log(struct io_log *log, bool do_append)\n{\n\tvoid *buf;\n\tFILE *f;\n\n\t/*\n\t * If log_gz_store is true, we are writing a binary file.\n\t * Set the mode appropriately (on all platforms) to avoid issues\n\t * on windows (line-ending conversions, etc.)\n\t */\n\tif (!do_append)\n\t\tif (log->log_gz_store)\n\t\t\tf = fopen(log->filename, \"wb\");\n\t\telse\n\t\t\tf = fopen(log->filename, \"w\");\n\telse\n\t\tif (log->log_gz_store)\n\t\t\tf = fopen(log->filename, \"ab\");\n\t\telse\n\t\t\tf = fopen(log->filename, \"a\");\n\tif (!f) {\n\t\tperror(\"fopen log\");\n\t\treturn;\n\t}\n\n\tbuf = set_file_buffer(f);\n\n\tinflate_gz_chunks(log, f);\n\n\twhile (!flist_empty(&log->io_logs)) {\n\t\tstruct io_logs *cur_log;\n\n\t\tcur_log = flist_first_entry(&log->io_logs, struct io_logs, list);\n\t\tflist_del_init(&cur_log->list);\n\t\t\n\t\tif (log->td && log == log->td->clat_hist_log)\n\t\t\tflush_hist_samples(f, log->hist_coarseness, cur_log->log,\n\t\t\t                   log_sample_sz(log, cur_log));\n\t\telse\n\t\t\tflush_samples(f, cur_log->log, log_sample_sz(log, cur_log));\n\t\t\n\t\tsfree(cur_log);\n\t}\n\n\tfclose(f);\n\tclear_file_buffer(buf);\n}\n\nstatic int finish_log(struct thread_data *td, struct io_log *log, int trylock)\n{\n\tif (td->flags & TD_F_COMPRESS_LOG)\n\t\tiolog_flush(log);\n\n\tif (trylock) {\n\t\tif (fio_trylock_file(log->filename))\n\t\t\treturn 1;\n\t} else\n\t\tfio_lock_file(log->filename);\n\n\tif (td->client_type == FIO_CLIENT_TYPE_GUI || is_backend)\n\t\tfio_send_iolog(td, log, log->filename);\n\telse\n\t\tflush_log(log, !td->o.per_job_logs);\n\n\tfio_unlock_file(log->filename);\n\tfree_log(log);\n\treturn 0;\n}\n\nsize_t log_chunk_sizes(struct io_log *log)\n{\n\tstruct flist_head *entry;\n\tsize_t ret;\n\n\tif (flist_empty(&log->chunk_list))\n\t\treturn 0;\n\n\tret = 0;\n\tpthread_mutex_lock(&log->chunk_lock);\n\tflist_for_each(entry, &log->chunk_list) {\n\t\tstruct iolog_compress *c;\n\n\t\tc = flist_entry(entry, struct iolog_compress, list);\n\t\tret += c->len;\n\t}\n\tpthread_mutex_unlock(&log->chunk_lock);\n\treturn ret;\n}\n\n#ifdef CONFIG_ZLIB\n\nstatic void iolog_put_deferred(struct io_log *log, void *ptr)\n{\n\tif (!ptr)\n\t\treturn;\n\n\tpthread_mutex_lock(&log->deferred_free_lock);\n\tif (log->deferred < IOLOG_MAX_DEFER) {\n\t\tlog->deferred_items[log->deferred] = ptr;\n\t\tlog->deferred++;\n\t} else if (!fio_did_warn(FIO_WARN_IOLOG_DROP))\n\t\tlog_err(\"fio: had to drop log entry free\\n\");\n\tpthread_mutex_unlock(&log->deferred_free_lock);\n}\n\nstatic void iolog_free_deferred(struct io_log *log)\n{\n\tint i;\n\n\tif (!log->deferred)\n\t\treturn;\n\n\tpthread_mutex_lock(&log->deferred_free_lock);\n\n\tfor (i = 0; i < log->deferred; i++) {\n\t\tfree(log->deferred_items[i]);\n\t\tlog->deferred_items[i] = NULL;\n\t}\n\n\tlog->deferred = 0;\n\tpthread_mutex_unlock(&log->deferred_free_lock);\n}\n\nstatic int gz_work(struct iolog_flush_data *data)\n{\n\tstruct iolog_compress *c = NULL;\n\tstruct flist_head list;\n\tunsigned int seq;\n\tz_stream stream;\n\tsize_t total = 0;\n\tint ret;\n\n\tINIT_FLIST_HEAD(&list);\n\n\tmemset(&stream, 0, sizeof(stream));\n\tstream.zalloc = Z_NULL;\n\tstream.zfree = Z_NULL;\n\tstream.opaque = Z_NULL;\n\n\tret = deflateInit(&stream, Z_DEFAULT_COMPRESSION);\n\tif (ret != Z_OK) {\n\t\tlog_err(\"fio: failed to init gz stream\\n\");\n\t\tgoto err;\n\t}\n\n\tseq = ++data->log->chunk_seq;\n\n\tstream.next_in = (void *) data->samples;\n\tstream.avail_in = data->nr_samples * log_entry_sz(data->log);\n\n\tdprint(FD_COMPRESS, \"deflate input size=%lu, seq=%u, log=%s\\n\",\n\t\t\t\t(unsigned long) stream.avail_in, seq,\n\t\t\t\tdata->log->filename);\n\tdo {\n\t\tif (c)\n\t\t\tdprint(FD_COMPRESS, \"seq=%d, chunk=%lu\\n\", seq,\n\t\t\t\t(unsigned long) c->len);\n\t\tc = get_new_chunk(seq);\n\t\tstream.avail_out = GZ_CHUNK;\n\t\tstream.next_out = c->buf;\n\t\tret = deflate(&stream, Z_NO_FLUSH);\n\t\tif (ret < 0) {\n\t\t\tlog_err(\"fio: deflate log (%d)\\n\", ret);\n\t\t\tfree_chunk(c);\n\t\t\tgoto err;\n\t\t}\n\n\t\tc->len = GZ_CHUNK - stream.avail_out;\n\t\tflist_add_tail(&c->list, &list);\n\t\ttotal += c->len;\n\t} while (stream.avail_in);\n\n\tstream.next_out = c->buf + c->len;\n\tstream.avail_out = GZ_CHUNK - c->len;\n\n\tret = deflate(&stream, Z_FINISH);\n\tif (ret < 0) {\n\t\t/*\n\t\t * Z_BUF_ERROR is special, it just means we need more\n\t\t * output space. We'll handle that below. Treat any other\n\t\t * error as fatal.\n\t\t */\n\t\tif (ret != Z_BUF_ERROR) {\n\t\t\tlog_err(\"fio: deflate log (%d)\\n\", ret);\n\t\t\tflist_del(&c->list);\n\t\t\tfree_chunk(c);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\ttotal -= c->len;\n\tc->len = GZ_CHUNK - stream.avail_out;\n\ttotal += c->len;\n\tdprint(FD_COMPRESS, \"seq=%d, chunk=%lu\\n\", seq, (unsigned long) c->len);\n\n\tif (ret != Z_STREAM_END) {\n\t\tdo {\n\t\t\tc = get_new_chunk(seq);\n\t\t\tstream.avail_out = GZ_CHUNK;\n\t\t\tstream.next_out = c->buf;\n\t\t\tret = deflate(&stream, Z_FINISH);\n\t\t\tc->len = GZ_CHUNK - stream.avail_out;\n\t\t\ttotal += c->len;\n\t\t\tflist_add_tail(&c->list, &list);\n\t\t\tdprint(FD_COMPRESS, \"seq=%d, chunk=%lu\\n\", seq,\n\t\t\t\t(unsigned long) c->len);\n\t\t} while (ret != Z_STREAM_END);\n\t}\n\n\tdprint(FD_COMPRESS, \"deflated to size=%lu\\n\", (unsigned long) total);\n\n\tret = deflateEnd(&stream);\n\tif (ret != Z_OK)\n\t\tlog_err(\"fio: deflateEnd %d\\n\", ret);\n\n\tiolog_put_deferred(data->log, data->samples);\n\n\tif (!flist_empty(&list)) {\n\t\tpthread_mutex_lock(&data->log->chunk_lock);\n\t\tflist_splice_tail(&list, &data->log->chunk_list);\n\t\tpthread_mutex_unlock(&data->log->chunk_lock);\n\t}\n\n\tret = 0;\ndone:\n\tif (data->free)\n\t\tsfree(data);\n\treturn ret;\nerr:\n\twhile (!flist_empty(&list)) {\n\t\tc = flist_first_entry(list.next, struct iolog_compress, list);\n\t\tflist_del(&c->list);\n\t\tfree_chunk(c);\n\t}\n\tret = 1;\n\tgoto done;\n}\n\n/*\n * Invoked from our compress helper thread, when logging would have exceeded\n * the specified memory limitation. Compresses the previously stored\n * entries.\n */\nstatic int gz_work_async(struct submit_worker *sw, struct workqueue_work *work)\n{\n\treturn gz_work(container_of(work, struct iolog_flush_data, work));\n}\n\nstatic int gz_init_worker(struct submit_worker *sw)\n{\n\tstruct thread_data *td = sw->wq->td;\n\n\tif (!fio_option_is_set(&td->o, log_gz_cpumask))\n\t\treturn 0;\n\n\tif (fio_setaffinity(gettid(), td->o.log_gz_cpumask) == -1) {\n\t\tlog_err(\"gz: failed to set CPU affinity\\n\");\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic struct workqueue_ops log_compress_wq_ops = {\n\t.fn\t\t= gz_work_async,\n\t.init_worker_fn\t= gz_init_worker,\n\t.nice\t\t= 1,\n};\n\nint iolog_compress_init(struct thread_data *td, struct sk_out *sk_out)\n{\n\tif (!(td->flags & TD_F_COMPRESS_LOG))\n\t\treturn 0;\n\n\tworkqueue_init(td, &td->log_compress_wq, &log_compress_wq_ops, 1, sk_out);\n\treturn 0;\n}\n\nvoid iolog_compress_exit(struct thread_data *td)\n{\n\tif (!(td->flags & TD_F_COMPRESS_LOG))\n\t\treturn;\n\n\tworkqueue_exit(&td->log_compress_wq);\n}\n\n/*\n * Queue work item to compress the existing log entries. We reset the\n * current log to a small size, and reference the existing log in the\n * data that we queue for compression. Once compression has been done,\n * this old log is freed. Will not return until the log compression\n * has completed, and will flush all previous logs too\n */\nstatic int iolog_flush(struct io_log *log)\n{\n\tstruct iolog_flush_data *data;\n\n\tworkqueue_flush(&log->td->log_compress_wq);\n\tdata = malloc(sizeof(*data));\n\tif (!data)\n\t\treturn 1;\n\n\tdata->log = log;\n\tdata->free = false;\n\n\twhile (!flist_empty(&log->io_logs)) {\n\t\tstruct io_logs *cur_log;\n\n\t\tcur_log = flist_first_entry(&log->io_logs, struct io_logs, list);\n\t\tflist_del_init(&cur_log->list);\n\n\t\tdata->samples = cur_log->log;\n\t\tdata->nr_samples = cur_log->nr_samples;\n\n\t\tsfree(cur_log);\n\n\t\tgz_work(data);\n\t}\n\n\tfree(data);\n\treturn 0;\n}\n\nint iolog_cur_flush(struct io_log *log, struct io_logs *cur_log)\n{\n\tstruct iolog_flush_data *data;\n\n\tdata = smalloc(sizeof(*data));\n\tif (!data)\n\t\treturn 1;\n\n\tdata->log = log;\n\n\tdata->samples = cur_log->log;\n\tdata->nr_samples = cur_log->nr_samples;\n\tdata->free = true;\n\n\tcur_log->nr_samples = cur_log->max_samples = 0;\n\tcur_log->log = NULL;\n\n\tworkqueue_enqueue(&log->td->log_compress_wq, &data->work);\n\n\tiolog_free_deferred(log);\n\n\treturn 0;\n}\n#else\n\nstatic int iolog_flush(struct io_log *log)\n{\n\treturn 1;\n}\n\nint iolog_cur_flush(struct io_log *log, struct io_logs *cur_log)\n{\n\treturn 1;\n}\n\nint iolog_compress_init(struct thread_data *td, struct sk_out *sk_out)\n{\n\treturn 0;\n}\n\nvoid iolog_compress_exit(struct thread_data *td)\n{\n}\n\n#endif\n\nstruct io_logs *iolog_cur_log(struct io_log *log)\n{\n\tif (flist_empty(&log->io_logs))\n\t\treturn NULL;\n\n\treturn flist_last_entry(&log->io_logs, struct io_logs, list);\n}\n\nuint64_t iolog_nr_samples(struct io_log *iolog)\n{\n\tstruct flist_head *entry;\n\tuint64_t ret = 0;\n\n\tflist_for_each(entry, &iolog->io_logs) {\n\t\tstruct io_logs *cur_log;\n\n\t\tcur_log = flist_entry(entry, struct io_logs, list);\n\t\tret += cur_log->nr_samples;\n\t}\n\n\treturn ret;\n}\n\nstatic int __write_log(struct thread_data *td, struct io_log *log, int try)\n{\n\tif (log)\n\t\treturn finish_log(td, log, try);\n\n\treturn 0;\n}\n\nstatic int write_iops_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (per_unit_log(td->iops_log) != unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->iops_log, try);\n\tif (!ret)\n\t\ttd->iops_log = NULL;\n\n\treturn ret;\n}\n\nstatic int write_slat_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (!unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->slat_log, try);\n\tif (!ret)\n\t\ttd->slat_log = NULL;\n\n\treturn ret;\n}\n\nstatic int write_clat_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (!unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->clat_log, try);\n\tif (!ret)\n\t\ttd->clat_log = NULL;\n\n\treturn ret;\n}\n\nstatic int write_clat_hist_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (!unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->clat_hist_log, try);\n\tif (!ret)\n\t\ttd->clat_hist_log = NULL;\n\n\treturn ret;\n}\n\nstatic int write_lat_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (!unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->lat_log, try);\n\tif (!ret)\n\t\ttd->lat_log = NULL;\n\n\treturn ret;\n}\n\nstatic int write_bandw_log(struct thread_data *td, int try, bool unit_log)\n{\n\tint ret;\n\n\tif (per_unit_log(td->bw_log) != unit_log)\n\t\treturn 0;\n\n\tret = __write_log(td, td->bw_log, try);\n\tif (!ret)\n\t\ttd->bw_log = NULL;\n\n\treturn ret;\n}\n\nenum {\n\tBW_LOG_MASK\t= 1,\n\tLAT_LOG_MASK\t= 2,\n\tSLAT_LOG_MASK\t= 4,\n\tCLAT_LOG_MASK\t= 8,\n\tIOPS_LOG_MASK\t= 16,\n\tCLAT_HIST_LOG_MASK = 32,\n\n\tALL_LOG_NR\t= 6,\n};\n\nstruct log_type {\n\tunsigned int mask;\n\tint (*fn)(struct thread_data *, int, bool);\n};\n\nstatic struct log_type log_types[] = {\n\t{\n\t\t.mask\t= BW_LOG_MASK,\n\t\t.fn\t= write_bandw_log,\n\t},\n\t{\n\t\t.mask\t= LAT_LOG_MASK,\n\t\t.fn\t= write_lat_log,\n\t},\n\t{\n\t\t.mask\t= SLAT_LOG_MASK,\n\t\t.fn\t= write_slat_log,\n\t},\n\t{\n\t\t.mask\t= CLAT_LOG_MASK,\n\t\t.fn\t= write_clat_log,\n\t},\n\t{\n\t\t.mask\t= IOPS_LOG_MASK,\n\t\t.fn\t= write_iops_log,\n\t},\n\t{\n\t\t.mask\t= CLAT_HIST_LOG_MASK,\n\t\t.fn\t= write_clat_hist_log,\n\t}\n};\n\nvoid td_writeout_logs(struct thread_data *td, bool unit_logs)\n{\n\tunsigned int log_mask = 0;\n\tunsigned int log_left = ALL_LOG_NR;\n\tint old_state, i;\n\n\told_state = td_bump_runstate(td, TD_FINISHING);\n\n\tfinalize_logs(td, unit_logs);\n\n\twhile (log_left) {\n\t\tint prev_log_left = log_left;\n\n\t\tfor (i = 0; i < ALL_LOG_NR && log_left; i++) {\n\t\t\tstruct log_type *lt = &log_types[i];\n\t\t\tint ret;\n\n\t\t\tif (!(log_mask & lt->mask)) {\n\t\t\t\tret = lt->fn(td, log_left != 1, unit_logs);\n\t\t\t\tif (!ret) {\n\t\t\t\t\tlog_left--;\n\t\t\t\t\tlog_mask |= lt->mask;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (prev_log_left == log_left)\n\t\t\tusleep(5000);\n\t}\n\n\ttd_restore_runstate(td, old_state);\n}\n\nvoid fio_writeout_logs(bool unit_logs)\n{\n\tfor_each_td(td) {\n\t\ttd_writeout_logs(td, unit_logs);\n\t} end_for_each();\n}\n"
        },
        {
          "name": "iolog.h",
          "type": "blob",
          "size": 7.9052734375,
          "content": "#ifndef FIO_IOLOG_H\n#define FIO_IOLOG_H\n\n#include <stdio.h>\n\n#include \"lib/rbtree.h\"\n#include \"lib/ieee754.h\"\n#include \"flist.h\"\n#include \"ioengines.h\"\n\n/*\n * Use for maintaining statistics\n */\nstruct io_stat {\n\tuint64_t max_val;\n\tuint64_t min_val;\n\tuint64_t samples;\n\n\tfio_fp64_t mean;\n\tfio_fp64_t S;\n};\n\nstruct io_hist {\n\tuint64_t samples;\n\tunsigned long hist_last;\n\tstruct flist_head list;\n};\n\nenum {\n\tIO_LOG_SAMPLE_AVG = 0,\n\tIO_LOG_SAMPLE_MAX,\n\tIO_LOG_SAMPLE_BOTH,\n};\n\nstruct io_sample_value {\n\tuint64_t val0;\n\tuint64_t val1;\n};\n\nunion io_sample_data {\n\tstruct io_sample_value val;\n\tstruct io_u_plat_entry *plat_entry;\n};\n\n#define sample_val(value) ((union io_sample_data) { .val.val0 = value })\n#define sample_plat(plat) ((union io_sample_data) { .plat_entry = plat })\n\n/*\n * A single data sample\n */\nstruct io_sample {\n\tuint64_t time;\n\tunion io_sample_data data;\n\tuint32_t __ddir;\n\tuint16_t priority;\n\tuint64_t bs;\n\tuint64_t aux[];\n};\n\n/*\n * Enumerate indexes of auxiliary log data in struct io_sample aux[] array\n */\nenum {\n\tIOS_AUX_OFFSET_INDEX,\n\tIOS_AUX_ISSUE_TIME_INDEX,\n};\n\nenum {\n\tIO_LOG_TYPE_LAT = 1,\n\tIO_LOG_TYPE_CLAT,\n\tIO_LOG_TYPE_SLAT,\n\tIO_LOG_TYPE_BW,\n\tIO_LOG_TYPE_IOPS,\n\tIO_LOG_TYPE_HIST,\n};\n\n#define DEF_LOG_ENTRIES\t\t1024\n#define MAX_LOG_ENTRIES\t\t(1024 * DEF_LOG_ENTRIES)\n\nstruct io_logs {\n\tstruct flist_head list;\n\tuint64_t nr_samples;\n\tuint64_t max_samples;\n\tvoid *log;\n};\n\n/*\n * Dynamically growing data sample log\n */\nstruct io_log {\n\t/*\n\t * Entries already logged\n\t */\n\tstruct flist_head io_logs;\n\tuint32_t cur_log_max;\n\n\t/*\n\t * When the current log runs out of space, store events here until\n\t * we have a chance to regrow\n\t */\n\tstruct io_logs *pending;\n\n\tunsigned int log_ddir_mask;\n\n\tchar *filename;\n\n\tstruct thread_data *td;\n\n\tunsigned int log_type;\n\n\t/*\n\t * If we fail extending the log, stop collecting more entries.\n\t */\n\tbool disabled;\n\n\t/*\n\t * Log offsets\n\t */\n\tunsigned int log_offset;\n\n\t/*\n\t * Log I/O priorities\n\t */\n\tunsigned int log_prio;\n\n\t/*\n\t * Log I/O issuing time\n\t */\n\tunsigned int log_issue_time;\n\n\t/*\n\t * Max size of log entries before a chunk is compressed\n\t */\n\tunsigned int log_gz;\n\n\t/*\n\t * Don't deflate for storing, just store the compressed bits\n\t */\n\tunsigned int log_gz_store;\n\n\t/*\n\t * Windowed average, for logging single entries average over some\n\t * period of time.\n\t */\n\tstruct io_stat avg_window[DDIR_RWDIR_CNT];\n\tunsigned long avg_msec;\n\tunsigned long avg_last[DDIR_RWDIR_CNT];\n\n\t/*\n\t * Windowed latency histograms, for keeping track of when we need to\n\t * save a copy of the histogram every approximately hist_msec\n\t * milliseconds.\n\t */\n\tstruct io_hist hist_window[DDIR_RWDIR_CNT];\n\tunsigned long hist_msec;\n\tunsigned int hist_coarseness;\n\n\tpthread_mutex_t chunk_lock;\n\tunsigned int chunk_seq;\n\tstruct flist_head chunk_list;\n\n\tpthread_mutex_t deferred_free_lock;\n#define IOLOG_MAX_DEFER\t8\n\tvoid *deferred_items[IOLOG_MAX_DEFER];\n\tunsigned int deferred;\n};\n\n/*\n * If the upper bit is set, then we have the offset as well\n */\n#define LOG_OFFSET_SAMPLE_BIT\t0x80000000U\n/*\n * If the bit following the upper bit is set, then we have the priority\n */\n#define LOG_PRIO_SAMPLE_BIT\t0x40000000U\n/*\n * If the bit following prioity sample vit is set, we report both avg and max\n */\n#define LOG_AVG_MAX_SAMPLE_BIT\t0x20000000U\n/*\n * If the bit following AVG_MAX_SAMPLE_BIT is set, we report the issue time also\n */\n#define LOG_ISSUE_TIME_SAMPLE_BIT\t0x10000000U\n\n#define LOG_SAMPLE_BITS\t\t(LOG_OFFSET_SAMPLE_BIT | LOG_PRIO_SAMPLE_BIT |\\\n\t\t\t\t\tLOG_AVG_MAX_SAMPLE_BIT |\\\n\t\t\t\t\tLOG_ISSUE_TIME_SAMPLE_BIT)\n#define io_sample_ddir(io)\t((io)->__ddir & ~LOG_SAMPLE_BITS)\n\nstatic inline void io_sample_set_ddir(struct io_log *log,\n\t\t\t\t      struct io_sample *io,\n\t\t\t\t      enum fio_ddir ddir)\n{\n\tio->__ddir = ddir | log->log_ddir_mask;\n}\n\nstatic inline size_t __log_entry_sz(bool log_offset, bool log_issue_time)\n{\n\tsize_t ret = sizeof(struct io_sample);\n\n\tif (log_offset)\n\t\tret += sizeof(uint64_t);\n\n\tif (log_issue_time)\n\t\tret += sizeof(uint64_t);\n\n\treturn ret;\n}\n\nstatic inline size_t log_entry_sz(struct io_log *log)\n{\n\treturn __log_entry_sz(log->log_offset, log->log_issue_time);\n}\n\nstatic inline size_t log_sample_sz(struct io_log *log, struct io_logs *cur_log)\n{\n\treturn cur_log->nr_samples * log_entry_sz(log);\n}\n\nstatic inline struct io_sample *__get_sample(void *samples, bool log_offset,\n\t\t\t\t\t     bool log_issue_time,\n\t\t\t\t\t     uint64_t sample)\n{\n\tuint64_t sample_offset = sample *\n\t\t__log_entry_sz(log_offset, log_issue_time);\n\treturn (struct io_sample *) ((char *) samples + sample_offset);\n}\n\nstruct io_logs *iolog_cur_log(struct io_log *);\nuint64_t iolog_nr_samples(struct io_log *);\nvoid regrow_logs(struct thread_data *);\nvoid regrow_agg_logs(void);\n\nstatic inline struct io_sample *get_sample(struct io_log *iolog,\n\t\t\t\t\t   struct io_logs *cur_log,\n\t\t\t\t\t   uint64_t sample)\n{\n\treturn __get_sample(cur_log->log,\n\t\t\t    iolog->log_offset, iolog->log_issue_time, sample);\n}\n\nenum {\n\tIP_F_ONRB\t= 1,\n\tIP_F_ONLIST\t= 2,\n\tIP_F_TRIMMED\t= 4,\n\tIP_F_IN_FLIGHT\t= 8,\n};\n\n/*\n * When logging io actions, this matches a single sent io_u\n */\nstruct io_piece {\n\tunion {\n\t\tstruct fio_rb_node rb_node;\n\t\tstruct flist_head list;\n\t};\n\tstruct flist_head trim_list;\n\tunion {\n\t\tint fileno;\n\t\tstruct fio_file *file;\n\t};\n\tunsigned long long offset;\n\tunsigned short numberio;\n\tunsigned long len;\n\tunsigned int flags;\n\tenum fio_ddir ddir;\n\tunsigned long delay;\n\tunsigned int file_action;\n};\n\n/*\n * Log exports\n */\nenum file_log_act {\n\tFIO_LOG_ADD_FILE,\n\tFIO_LOG_OPEN_FILE,\n\tFIO_LOG_CLOSE_FILE,\n\tFIO_LOG_UNLINK_FILE,\n};\n\nstruct io_u;\nextern int __must_check read_iolog_get(struct thread_data *, struct io_u *);\nextern void log_io_u(const struct thread_data *, const struct io_u *);\nextern void log_file(struct thread_data *, struct fio_file *, enum file_log_act);\nextern bool __must_check init_iolog(struct thread_data *td);\nextern void log_io_piece(struct thread_data *, struct io_u *);\nextern void unlog_io_piece(struct thread_data *, struct io_u *);\nextern void trim_io_piece(const struct io_u *);\nextern void queue_io_piece(struct thread_data *, struct io_piece *);\nextern void prune_io_piece_log(struct thread_data *);\nextern void write_iolog_close(struct thread_data *);\nint64_t iolog_items_to_fetch(struct thread_data *td);\nextern int iolog_compress_init(struct thread_data *, struct sk_out *);\nextern void iolog_compress_exit(struct thread_data *);\nextern size_t log_chunk_sizes(struct io_log *);\nextern int init_io_u_buffers(struct thread_data *);\nextern unsigned long long delay_since_ttime(const struct thread_data *,\n\t\t\t\t\t     unsigned long long);\n\n#ifdef CONFIG_ZLIB\nextern int iolog_file_inflate(const char *);\n#endif\n\n/*\n * Logging\n */\nstruct log_params {\n\tstruct thread_data *td;\n\tunsigned long avg_msec;\n\tunsigned long hist_msec;\n\tint hist_coarseness;\n\tint log_type;\n\tint log_offset;\n\tint log_prio;\n\tint log_issue_time;\n\tint log_gz;\n\tint log_gz_store;\n\tint log_compress;\n};\n\nstatic inline bool per_unit_log(struct io_log *log)\n{\n\treturn log && (!log->avg_msec || log->log_gz || log->log_gz_store);\n}\n\nstatic inline bool inline_log(struct io_log *log)\n{\n\treturn log->log_type == IO_LOG_TYPE_LAT ||\n\t\tlog->log_type == IO_LOG_TYPE_CLAT ||\n\t\tlog->log_type == IO_LOG_TYPE_SLAT;\n}\n\nstatic inline void ipo_bytes_align(unsigned int replay_align, struct io_piece *ipo)\n{\n\tif (!replay_align)\n\t\treturn;\n\n\tipo->offset &= ~(replay_align - (uint64_t)1);\n}\n\nextern void finalize_logs(struct thread_data *td, bool);\nextern void setup_log(struct io_log **, struct log_params *, const char *);\nextern void flush_log(struct io_log *, bool);\nextern void flush_samples(FILE *, void *, uint64_t);\nextern uint64_t hist_sum(int, int, uint64_t *, uint64_t *);\nextern void free_log(struct io_log *);\nextern void fio_writeout_logs(bool);\nextern void td_writeout_logs(struct thread_data *, bool);\nextern int iolog_cur_flush(struct io_log *, struct io_logs *);\n\nstatic inline void init_ipo(struct io_piece *ipo)\n{\n\tINIT_FLIST_HEAD(&ipo->list);\n\tINIT_FLIST_HEAD(&ipo->trim_list);\n}\n\nstruct iolog_compress {\n\tstruct flist_head list;\n\tvoid *buf;\n\tsize_t len;\n\tunsigned int seq;\n};\n\n#endif\n"
        },
        {
          "name": "json.c",
          "type": "blob",
          "size": 7.748046875,
          "content": "#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <stdarg.h>\n#include \"json.h\"\n#include \"log.h\"\n\nstruct json_object *json_create_object(void)\n{\n\treturn calloc(1, sizeof(struct json_object));\n}\n\nstruct json_array *json_create_array(void)\n{\n\treturn calloc(1, sizeof(struct json_array));\n}\n\nstatic struct json_pair *json_create_pair(const char *name, struct json_value *value)\n{\n\tstruct json_pair *pair = malloc(sizeof(struct json_pair));\n\tif (pair) {\n\t\tpair->name = strdup(name);\n\t\tpair->value = value;\n\n\t\tvalue->parent_type = JSON_PARENT_TYPE_PAIR;\n\t\tvalue->parent_pair = pair;\n\t}\n\treturn pair;\n}\n\nstatic struct json_value *json_create_value_int(long long number)\n{\n\tstruct json_value *value = malloc(sizeof(struct json_value));\n\n\tif (value) {\n\t\tvalue->type = JSON_TYPE_INTEGER;\n\t\tvalue->integer_number = number;\n\t}\n\treturn value;\n}\n\nstatic struct json_value *json_create_value_float(double number)\n{\n\tstruct json_value *value = malloc(sizeof(struct json_value));\n\n\tif (value) {\n\t\tvalue->type = JSON_TYPE_FLOAT;\n\t\tvalue->float_number = number;\n\t}\n\treturn value;\n}\n\nstatic char *strdup_escape(const char *str)\n{\n\tconst char *input = str;\n\tchar *p, *ret;\n\tint escapes;\n\n\tif (!strlen(str))\n\t\treturn NULL;\n\n\tescapes = 0;\n\twhile ((input = strpbrk(input, \"\\\\\\\"\")) != NULL) {\n\t\tescapes++;\n\t\tinput++;\n\t}\n\n\tp = ret = malloc(strlen(str) + escapes + 1);\n\twhile (*str) {\n\t\tif (*str == '\\\\' || *str == '\\\"')\n\t\t\t*p++ = '\\\\';\n\t\t*p++ = *str++;\n\t}\n\t*p = '\\0';\n\n\treturn ret;\n}\n\n/*\n * Valid JSON strings must escape '\"' and '/' with a preceding '/'\n */\nstatic struct json_value *json_create_value_string(const char *str)\n{\n\tstruct json_value *value = malloc(sizeof(struct json_value));\n\n\tif (value) {\n\t\tvalue->type = JSON_TYPE_STRING;\n\t\tvalue->string = strdup_escape(str);\n\t\tif (!value->string) {\n\t\t\tfree(value);\n\t\t\tvalue = NULL;\n\t\t}\n\t}\n\treturn value;\n}\n\nstatic struct json_value *json_create_value_object(struct json_object *obj)\n{\n\tstruct json_value *value = malloc(sizeof(struct json_value));\n\n\tif (value) {\n\t\tvalue->type = JSON_TYPE_OBJECT;\n\t\tvalue->object = obj;\n\t\tobj->parent = value;\n\t}\n\treturn value;\n}\n\nstatic struct json_value *json_create_value_array(struct json_array *array)\n{\n\tstruct json_value *value = malloc(sizeof(struct json_value));\n\n\tif (value) {\n\t\tvalue->type = JSON_TYPE_ARRAY;\n\t\tvalue->array = array;\n\t\tarray->parent = value;\n\t}\n\treturn value;\n}\n\nstatic void json_free_pair(struct json_pair *pair);\nstatic void json_free_value(struct json_value *value);\n\nvoid json_free_object(struct json_object *obj)\n{\n\tint i;\n\n\tfor (i = 0; i < obj->pair_cnt; i++)\n\t\tjson_free_pair(obj->pairs[i]);\n\tfree(obj->pairs);\n\tfree(obj);\n}\n\nstatic void json_free_array(struct json_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->value_cnt; i++)\n\t\tjson_free_value(array->values[i]);\n\tfree(array->values);\n\tfree(array);\n}\n\nstatic void json_free_pair(struct json_pair *pair)\n{\n\tjson_free_value(pair->value);\n\tfree(pair->name);\n\tfree(pair);\n}\n\nstatic void json_free_value(struct json_value *value)\n{\n\tswitch (value->type) {\n\tcase JSON_TYPE_STRING:\n\t\tfree(value->string);\n\t\tbreak;\n\tcase JSON_TYPE_OBJECT:\n\t\tjson_free_object(value->object);\n\t\tbreak;\n\tcase JSON_TYPE_ARRAY:\n\t\tjson_free_array(value->array);\n\t\tbreak;\n\t}\n\tfree(value);\n}\n\nstatic int json_array_add_value(struct json_array *array, struct json_value *value)\n{\n\tstruct json_value **values = realloc(array->values,\n\t\tsizeof(struct json_value *) * (array->value_cnt + 1));\n\n\tif (!values)\n\t\treturn ENOMEM;\n\tvalues[array->value_cnt] = value;\n\tarray->value_cnt++;\n\tarray->values = values;\n\n\tvalue->parent_type = JSON_PARENT_TYPE_ARRAY;\n\tvalue->parent_array = array;\n\treturn 0;\n}\n\nstatic int json_object_add_pair(struct json_object *obj, struct json_pair *pair)\n{\n\tstruct json_pair **pairs = realloc(obj->pairs,\n\t\tsizeof(struct json_pair *) * (obj->pair_cnt + 1));\n\tif (!pairs)\n\t\treturn ENOMEM;\n\tpairs[obj->pair_cnt] = pair;\n\tobj->pair_cnt++;\n\tobj->pairs = pairs;\n\n\tpair->parent = obj;\n\treturn 0;\n}\n\nint json_object_add_value_type(struct json_object *obj, const char *name,\n\t\t\t       const struct json_value *arg)\n{\n\tstruct json_value *value;\n\tstruct json_pair *pair;\n\tint ret;\n\n\tswitch (arg->type) {\n\tcase JSON_TYPE_STRING:\n\t\tvalue = json_create_value_string(arg->string);\n\t\tbreak;\n\tcase JSON_TYPE_INTEGER:\n\t\tvalue = json_create_value_int(arg->integer_number);\n\t\tbreak;\n\tcase JSON_TYPE_FLOAT:\n\t\tvalue = json_create_value_float(arg->float_number);\n\t\tbreak;\n\tcase JSON_TYPE_OBJECT:\n\t\tvalue = json_create_value_object(arg->object);\n\t\tbreak;\n\tdefault:\n\tcase JSON_TYPE_ARRAY:\n\t\tvalue = json_create_value_array(arg->array);\n\t\tbreak;\n\t}\n\n\tif (!value)\n\t\treturn ENOMEM;\n\n\tpair = json_create_pair(name, value);\n\tif (!pair) {\n\t\tjson_free_value(value);\n\t\treturn ENOMEM;\n\t}\n\tret = json_object_add_pair(obj, pair);\n\tif (ret) {\n\t\tjson_free_pair(pair);\n\t\treturn ENOMEM;\n\t}\n\treturn 0;\n}\n\nint json_array_add_value_type(struct json_array *array,\n\t\t\t      const struct json_value *arg)\n{\n\tstruct json_value *value;\n\tint ret;\n\n\tswitch (arg->type) {\n\tcase JSON_TYPE_STRING:\n\t\tvalue = json_create_value_string(arg->string);\n\t\tbreak;\n\tcase JSON_TYPE_INTEGER:\n\t\tvalue = json_create_value_int(arg->integer_number);\n\t\tbreak;\n\tcase JSON_TYPE_FLOAT:\n\t\tvalue = json_create_value_float(arg->float_number);\n\t\tbreak;\n\tcase JSON_TYPE_OBJECT:\n\t\tvalue = json_create_value_object(arg->object);\n\t\tbreak;\n\tdefault:\n\tcase JSON_TYPE_ARRAY:\n\t\tvalue = json_create_value_array(arg->array);\n\t\tbreak;\n\t}\n\n\tif (!value)\n\t\treturn ENOMEM;\n\n\tret = json_array_add_value(array, value);\n\tif (ret) {\n\t\tjson_free_value(value);\n\t\treturn ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic int json_value_level(struct json_value *value);\nstatic int json_pair_level(struct json_pair *pair);\nstatic int json_array_level(struct json_array *array);\nstatic int json_object_level(struct json_object *object)\n{\n\tif (object->parent == NULL)\n\t\treturn 0;\n\treturn json_value_level(object->parent);\n}\n\nstatic int json_pair_level(struct json_pair *pair)\n{\n\treturn json_object_level(pair->parent) + 1;\n}\n\nstatic int json_array_level(struct json_array *array)\n{\n\treturn json_value_level(array->parent);\n}\n\nstatic int json_value_level(struct json_value *value)\n{\n\tif (value->parent_type == JSON_PARENT_TYPE_PAIR)\n\t\treturn json_pair_level(value->parent_pair);\n\telse\n\t\treturn json_array_level(value->parent_array) + 1;\n}\n\nstatic void json_print_level(int level, struct buf_output *out)\n{\n\twhile (level-- > 0)\n\t\tlog_buf(out, \"  \");\n}\n\nstatic void json_print_pair(struct json_pair *pair, struct buf_output *);\nstatic void json_print_value(struct json_value *value, struct buf_output *);\n\nvoid json_print_object(struct json_object *obj, struct buf_output *out)\n{\n\tint i;\n\n\tlog_buf(out, \"{\\n\");\n\tfor (i = 0; i < obj->pair_cnt; i++) {\n\t\tif (i > 0)\n\t\t\tlog_buf(out, \",\\n\");\n\t\tjson_print_pair(obj->pairs[i], out);\n\t}\n\tlog_buf(out, \"\\n\");\n\tjson_print_level(json_object_level(obj), out);\n\tlog_buf(out, \"}\");\n}\n\nstatic void json_print_pair(struct json_pair *pair, struct buf_output *out)\n{\n\tjson_print_level(json_pair_level(pair), out);\n\tlog_buf(out, \"\\\"%s\\\" : \", pair->name);\n\tjson_print_value(pair->value, out);\n}\n\nstatic void json_print_array(struct json_array *array, struct buf_output *out)\n{\n\tint i;\n\n\tlog_buf(out, \"[\\n\");\n\tfor (i = 0; i < array->value_cnt; i++) {\n\t\tif (i > 0)\n\t\t\tlog_buf(out, \",\\n\");\n\t\tjson_print_level(json_value_level(array->values[i]), out);\n\t\tjson_print_value(array->values[i], out);\n\t}\n\tlog_buf(out, \"\\n\");\n\tjson_print_level(json_array_level(array), out);\n\tlog_buf(out, \"]\");\n}\n\nstatic void json_print_value(struct json_value *value, struct buf_output *out)\n{\n\tswitch (value->type) {\n\tcase JSON_TYPE_STRING:\n\t\tlog_buf(out, \"\\\"%s\\\"\", value->string);\n\t\tbreak;\n\tcase JSON_TYPE_INTEGER:\n\t\tlog_buf(out, \"%lld\", value->integer_number);\n\t\tbreak;\n\tcase JSON_TYPE_FLOAT:\n\t\tlog_buf(out, \"%f\", value->float_number);\n\t\tbreak;\n\tcase JSON_TYPE_OBJECT:\n\t\tjson_print_object(value->object, out);\n\t\tbreak;\n\tcase JSON_TYPE_ARRAY:\n\t\tjson_print_array(value->array, out);\n\t\tbreak;\n\t}\n}\n"
        },
        {
          "name": "json.h",
          "type": "blob",
          "size": 3.8173828125,
          "content": "#ifndef __JSON__H\n#define __JSON__H\n\n#include \"lib/output_buffer.h\"\n\n#define JSON_TYPE_STRING 0\n#define JSON_TYPE_INTEGER 1\n#define JSON_TYPE_FLOAT 2\n#define JSON_TYPE_OBJECT 3\n#define JSON_TYPE_ARRAY 4\n#define JSON_PARENT_TYPE_PAIR 0\n#define JSON_PARENT_TYPE_ARRAY 1\nstruct json_value {\n\tint type;\n\tunion {\n\t\tlong long integer_number;\n\t\tdouble float_number;\n\t\tchar *string;\n\t\tstruct json_object *object;\n\t\tstruct json_array *array;\n\t};\n\tint parent_type;\n\tunion {\n\t\tstruct json_pair *parent_pair;\n\t\tstruct json_array *parent_array;\n\t};\n};\n\nstruct json_array {\n\tstruct json_value **values;\n\tint value_cnt;\n\tstruct json_value *parent;\n};\n\nstruct json_object {\n\tstruct json_pair **pairs;\n\tint pair_cnt;\n\tstruct json_value *parent;\n};\n\nstruct json_pair {\n\tchar *name;\n\tstruct json_value *value;\n\tstruct json_object *parent;\n};\n\nstruct json_object *json_create_object(void);\nstruct json_array *json_create_array(void);\n\nvoid json_free_object(struct json_object *obj);\n\nint json_object_add_value_type(struct json_object *obj, const char *name,\n\t\t\t       const struct json_value *val);\n\nstatic inline int json_object_add_value_int(struct json_object *obj,\n\t\t\t\t\t    const char *name, long long val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_INTEGER,\n\t};\n\n\targ.integer_number = val;\n\treturn json_object_add_value_type(obj, name, &arg);\n}\n\nstatic inline int json_object_add_value_float(struct json_object *obj,\n\t\t\t\t\t      const char *name, double val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_FLOAT,\n\t};\n\n\targ.float_number = val;\n\treturn json_object_add_value_type(obj, name, &arg);\n}\n\nstatic inline int json_object_add_value_string(struct json_object *obj,\n\t\t\t\t\t       const char *name,\n\t\t\t\t\t       const char *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_STRING,\n\t};\n\tunion {\n\t\tconst char *a;\n\t\tchar *b;\n\t} string;\n\n\tstring.a = val ? val : \"\";\n\targ.string = string.b;\n\treturn json_object_add_value_type(obj, name, &arg);\n}\n\nstatic inline int json_object_add_value_object(struct json_object *obj,\n\t\t\t\t\t       const char *name,\n\t\t\t\t\t       struct json_object *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_OBJECT,\n\t};\n\n\targ.object = val;\n\treturn json_object_add_value_type(obj, name, &arg);\n}\n\nstatic inline int json_object_add_value_array(struct json_object *obj,\n\t\t\t\t\t      const char *name,\n\t\t\t\t\t      struct json_array *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_ARRAY,\n\t};\n\n\targ.array = val;\n\treturn json_object_add_value_type(obj, name, &arg);\n}\n\nint json_array_add_value_type(struct json_array *array,\n\t\t\t      const struct json_value *val);\n\nstatic inline int json_array_add_value_int(struct json_array *obj,\n\t\t\t\t\t   long long val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_INTEGER,\n\t};\n\n\targ.integer_number = val;\n\treturn json_array_add_value_type(obj, &arg);\n}\n\nstatic inline int json_array_add_value_float(struct json_array *obj,\n\t\t\t\t\t     double val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_FLOAT,\n\t};\n\n\targ.float_number = val;\n\treturn json_array_add_value_type(obj, &arg);\n}\n\nstatic inline int json_array_add_value_string(struct json_array *obj,\n\t\t\t\t\t      const char *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_STRING,\n\t};\n\n\targ.string = (char *)val;\n\treturn json_array_add_value_type(obj, &arg);\n}\n\nstatic inline int json_array_add_value_object(struct json_array *obj,\n\t\t\t\t\t      struct json_object *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_OBJECT,\n\t};\n\n\targ.object = val;\n\treturn json_array_add_value_type(obj, &arg);\n}\n\nstatic inline int json_array_add_value_array(struct json_array *obj,\n\t\t\t\t\t     struct json_array *val)\n{\n\tstruct json_value arg = {\n\t\t.type = JSON_TYPE_ARRAY,\n\t};\n\n\targ.array = val;\n\treturn json_array_add_value_type(obj, &arg);\n}\n\n#define json_array_last_value_object(obj) \\\n\t(obj->values[obj->value_cnt - 1]->object)\n\nvoid json_print_object(struct json_object *obj, struct buf_output *out);\n#endif\n"
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "libfio.c",
          "type": "blob",
          "size": 9.77734375,
          "content": "/*\n * fio - the flexible io tester\n *\n * Copyright (C) 2005 Jens Axboe <axboe@suse.de>\n * Copyright (C) 2006-2012 Jens Axboe <axboe@kernel.dk>\n *\n * The license below covers all files distributed with fio unless otherwise\n * noted in the file itself.\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License version 2 as\n *  published by the Free Software Foundation.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; if not, write to the Free Software\n *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n *\n */\n\n#include <string.h>\n#include <signal.h>\n#include <stdint.h>\n#include <locale.h>\n#include <fcntl.h>\n\n#include \"fio.h\"\n#include \"smalloc.h\"\n#include \"os/os.h\"\n#include \"filelock.h\"\n#include \"helper_thread.h\"\n#include \"filehash.h\"\n\nFLIST_HEAD(disk_list);\n\nunsigned long arch_flags = 0;\n\nuintptr_t page_mask = 0;\nuintptr_t page_size = 0;\n\n/* see os/os.h */\nstatic const char *fio_os_strings[os_nr] = {\n\t\"Invalid\",\n\t\"Linux\",\n\t\"AIX\",\n\t\"FreeBSD\",\n\t\"HP-UX\",\n\t\"OSX\",\n\t\"NetBSD\",\n\t\"OpenBSD\",\n\t\"Solaris\",\n\t\"Windows\",\n\t\"Android\",\n\t\"DragonFly\",\n};\n\n/* see arch/arch.h */\nstatic const char *fio_arch_strings[arch_nr] = {\n\t\"Invalid\",\n\t\"x86-64\",\n\t\"x86\",\n\t\"ppc\",\n\t\"ia64\",\n\t\"s390\",\n\t\"alpha\",\n\t\"sparc\",\n\t\"sparc64\",\n\t\"arm\",\n\t\"sh\",\n\t\"hppa\",\n\t\"mips\",\n\t\"aarch64\",\n\t\"loongarch64\",\n\t\"riscv64\",\n\t\"generic\"\n};\n\nstatic void reset_io_counters(struct thread_data *td, int all)\n{\n\tint ddir;\n\n\tif (all) {\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\ttd->stat_io_bytes[ddir] = 0;\n\t\t\ttd->this_io_bytes[ddir] = 0;\n\t\t\ttd->stat_io_blocks[ddir] = 0;\n\t\t\ttd->this_io_blocks[ddir] = 0;\n\t\t\ttd->last_rate_check_bytes[ddir] = 0;\n\t\t\ttd->last_rate_check_blocks[ddir] = 0;\n\t\t\ttd->bytes_done[ddir] = 0;\n\t\t\ttd->rate_io_issue_bytes[ddir] = 0;\n\t\t\ttd->rate_next_io_time[ddir] = 0;\n\t\t\ttd->last_usec[ddir] = 0;\n\t\t}\n\t\ttd->bytes_verified = 0;\n\t}\n\n\ttd->zone_bytes = 0;\n\n\ttd->rwmix_issues = 0;\n\n\t/*\n\t * reset file done count if we are to start over\n\t */\n\tif (td->o.time_based || td->loops > 1 || td->o.do_verify)\n\t\ttd->nr_done_files = 0;\n}\n\nvoid clear_io_state(struct thread_data *td, int all)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\n\treset_io_counters(td, all);\n\n\tclose_files(td);\n\tfor_each_file(td, f, i) {\n\t\tfio_file_clear_done(f);\n\t\tf->file_offset = get_start_offset(td, f);\n\t}\n\n\t/*\n\t * Re-Seed random number generator if rand_repeatable is true\n\t */\n\tif (td->o.rand_repeatable)\n\t\ttd_fill_rand_seeds(td);\n}\n\nvoid reset_all_stats(struct thread_data *td)\n{\n\tunsigned long long b;\n\tint i;\n\n\treset_io_counters(td, 1);\n\n\tb = ddir_rw_sum(td->thinktime_blocks_counter);\n\ttd->last_thinktime_blocks -= b;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\ttd->io_bytes[i] = 0;\n\t\ttd->io_blocks[i] = 0;\n\t\ttd->io_issues[i] = 0;\n\t\ttd->ts.total_io_u[i] = 0;\n\t\ttd->ts.runtime[i] = 0;\n\t}\n\n\tset_epoch_time(td, td->o.log_alternate_epoch_clock_id, td->o.job_start_clock_id);\n\tmemcpy(&td->start, &td->epoch, sizeof(td->epoch));\n\tmemcpy(&td->iops_sample_time, &td->epoch, sizeof(td->epoch));\n\tmemcpy(&td->bw_sample_time, &td->epoch, sizeof(td->epoch));\n\tmemcpy(&td->ss.prev_time, &td->epoch, sizeof(td->epoch));\n\n\ttd->last_thinktime = td->epoch;\n\n\tlat_target_reset(td);\n\tclear_rusage_stat(td);\n\thelper_reset();\n}\n\nvoid reset_fio_state(void)\n{\n\tint i;\n\n\tgroupid = 0;\n\tthread_number = 0;\n\tcur_segment = 0;\n\tfor (i = 0; i < nr_segments; i++)\n\t\tsegments[i].nr_threads = 0;\n\tstat_number = 0;\n\tdone_secs = 0;\n}\n\nconst char *fio_get_os_string(int nr)\n{\n\tif (nr < os_nr)\n\t\treturn fio_os_strings[nr];\n\n\treturn NULL;\n}\n\nconst char *fio_get_arch_string(int nr)\n{\n\tif (nr < arch_nr)\n\t\treturn fio_arch_strings[nr];\n\n\treturn NULL;\n}\n\nstatic const char *td_runstates[] = {\n\t\"NOT_CREATED\",\n\t\"CREATED\",\n\t\"INITIALIZED\",\n\t\"RAMP\",\n\t\"SETTING_UP\",\n\t\"RUNNING\",\n\t\"PRE_READING\",\n\t\"VERIFYING\",\n\t\"FSYNCING\",\n\t\"FINISHING\",\n\t\"EXITED\",\n\t\"REAPED\",\n};\n\nconst char *runstate_to_name(int runstate)\n{\n\tcompiletime_assert(TD_LAST == 12, \"td runstate list\");\n\tif (runstate >= 0 && runstate < TD_LAST)\n\t\treturn td_runstates[runstate];\n\n\treturn \"invalid\";\n}\n\nvoid td_set_runstate(struct thread_data *td, int runstate)\n{\n\tif (td->runstate == runstate)\n\t\treturn;\n\n\tdprint(FD_PROCESS, \"pid=%d: runstate %s -> %s\\n\", (int) td->pid,\n\t\t\t\t\t\trunstate_to_name(td->runstate),\n\t\t\t\t\t\trunstate_to_name(runstate));\n\ttd->runstate = runstate;\n}\n\nint td_bump_runstate(struct thread_data *td, int new_state)\n{\n\tint old_state = td->runstate;\n\n\ttd_set_runstate(td, new_state);\n\treturn old_state;\n}\n\nvoid td_restore_runstate(struct thread_data *td, int old_state)\n{\n\ttd_set_runstate(td, old_state);\n}\n\nvoid fio_mark_td_terminate(struct thread_data *td)\n{\n\tfio_gettime(&td->terminate_time, NULL);\n\twrite_barrier();\n\ttd->terminate = true;\n}\n\nvoid fio_terminate_threads(unsigned int group_id, unsigned int terminate)\n{\n\tpid_t pid = getpid();\n\n\tdprint(FD_PROCESS, \"terminate group_id=%d\\n\", group_id);\n\n\tfor_each_td(td) {\n\t\tif ((terminate == TERMINATE_GROUP && group_id == TERMINATE_ALL) ||\n\t\t    (terminate == TERMINATE_GROUP && group_id == td->groupid) ||\n\t\t    (terminate == TERMINATE_STONEWALL && td->runstate >= TD_RUNNING) ||\n\t\t    (terminate == TERMINATE_ALL)) {\n\t\t\tdprint(FD_PROCESS, \"setting terminate on %s/%d\\n\",\n\t\t\t\t\t\ttd->o.name, (int) td->pid);\n\n\t\t\tif (td->terminate)\n\t\t\t\tcontinue;\n\n\t\t\tfio_mark_td_terminate(td);\n\t\t\ttd->o.start_delay = 0;\n\n\t\t\t/*\n\t\t\t * if the thread is running, just let it exit\n\t\t\t */\n\t\t\tif (!td->pid || pid == td->pid)\n\t\t\t\tcontinue;\n\t\t\telse if (td->runstate < TD_RAMP)\n\t\t\t\tkill(td->pid, SIGTERM);\n\t\t\telse {\n\t\t\t\tstruct ioengine_ops *ops = td->io_ops;\n\n\t\t\t\tif (ops && ops->terminate)\n\t\t\t\t\tops->terminate(td);\n\t\t\t}\n\t\t}\n\t} end_for_each();\n}\n\nint fio_running_or_pending_io_threads(void)\n{\n\tint nr_io_threads = 0;\n\n\tfor_each_td(td) {\n\t\tif (td->io_ops_init && td_ioengine_flagged(td, FIO_NOIO))\n\t\t\tcontinue;\n\t\tnr_io_threads++;\n\t\tif (td->runstate < TD_EXITED)\n\t\t\treturn 1;\n\t} end_for_each();\n\n\tif (!nr_io_threads)\n\t\treturn -1; /* we only had cpuio threads to begin with */\n\treturn 0;\n}\n\nint fio_set_fd_nonblocking(int fd, const char *who)\n{\n\tint flags;\n\n\tflags = fcntl(fd, F_GETFL);\n\tif (flags < 0)\n\t\tlog_err(\"fio: %s failed to get file flags: %s\\n\", who, strerror(errno));\n\telse {\n\t\tint new_flags = flags | O_NONBLOCK;\n\n\t\tnew_flags = fcntl(fd, F_SETFL, new_flags);\n\t\tif (new_flags < 0)\n\t\t\tlog_err(\"fio: %s failed to get file flags: %s\\n\", who, strerror(errno));\n\t}\n\n\treturn flags;\n}\n\nenum {\n\tENDIAN_INVALID_BE = 1,\n\tENDIAN_INVALID_LE,\n\tENDIAN_INVALID_CONFIG,\n\tENDIAN_BROKEN,\n};\n\nstatic int endian_check(void)\n{\n\tunion {\n\t\tuint8_t c[8];\n\t\tuint64_t v;\n\t} u;\n\tint le = 0, be = 0;\n\n\tu.v = 0x12;\n\tif (u.c[7] == 0x12)\n\t\tbe = 1;\n\telse if (u.c[0] == 0x12)\n\t\tle = 1;\n\n#if defined(CONFIG_LITTLE_ENDIAN)\n\tif (be)\n\t\treturn ENDIAN_INVALID_BE;\n#elif defined(CONFIG_BIG_ENDIAN)\n\tif (le)\n\t\treturn ENDIAN_INVALID_LE;\n#else\n\treturn ENDIAN_INVALID_CONFIG;\n#endif\n\n\tif (!le && !be)\n\t\treturn ENDIAN_BROKEN;\n\n\treturn 0;\n}\n\nint initialize_fio(char *envp[])\n{\n\tlong ps;\n\tint err;\n\n\t/*\n\t * We need these to be properly 64-bit aligned, otherwise we\n\t * can run into problems on archs that fault on unaligned fp\n\t * access (ARM).\n\t */\n\tcompiletime_assert((offsetof(struct thread_data, ts) % sizeof(void *)) == 0, \"ts\");\n\tcompiletime_assert((offsetof(struct thread_stat, percentile_list) % 8) == 0, \"stat percentile_list\");\n\tcompiletime_assert((offsetof(struct thread_stat, total_run_time) % 8) == 0, \"total_run_time\");\n\tcompiletime_assert((offsetof(struct thread_stat, total_err_count) % 8) == 0, \"total_err_count\");\n\tcompiletime_assert((offsetof(struct thread_stat, latency_percentile) % 8) == 0, \"stat latency_percentile\");\n\tcompiletime_assert((offsetof(struct thread_data, ts.clat_stat) % 8) == 0, \"ts.clat_stat\");\n\tcompiletime_assert((offsetof(struct thread_options_pack, zipf_theta) % 8) == 0, \"zipf_theta\");\n\tcompiletime_assert((offsetof(struct thread_options_pack, pareto_h) % 8) == 0, \"pareto_h\");\n\tcompiletime_assert((offsetof(struct thread_options_pack, percentile_list) % 8) == 0, \"percentile_list\");\n\tcompiletime_assert((offsetof(struct thread_options_pack, latency_percentile) % 8) == 0, \"latency_percentile\");\n\tcompiletime_assert((offsetof(struct jobs_eta, m_rate) % 8) == 0, \"m_rate\");\n\n\tcompiletime_assert(__TD_F_LAST <= TD_ENG_FLAG_SHIFT, \"TD_ENG_FLAG_SHIFT\");\n\tcompiletime_assert((__TD_F_LAST + __FIO_IOENGINE_F_LAST) <= 8*sizeof(((struct thread_data *)0)->flags), \"td->flags\");\n\tcompiletime_assert(BSSPLIT_MAX <= ZONESPLIT_MAX, \"bsssplit/zone max\");\n\n\terr = endian_check();\n\tif (err) {\n\t\tlog_err(\"fio: endianness settings appear wrong.\\n\");\n\t\tswitch (err) {\n\t\tcase ENDIAN_INVALID_BE:\n\t\t\tlog_err(\"fio: got big-endian when configured for little\\n\");\n\t\t\tbreak;\n\t\tcase ENDIAN_INVALID_LE:\n\t\t\tlog_err(\"fio: got little-endian when configured for big\\n\");\n\t\t\tbreak;\n\t\tcase ENDIAN_INVALID_CONFIG:\n\t\t\tlog_err(\"fio: not configured to any endianness\\n\");\n\t\t\tbreak;\n\t\tcase ENDIAN_BROKEN:\n\t\t\tlog_err(\"fio: failed to detect endianness\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\tbreak;\n\t\t}\n\t\tlog_err(\"fio: please report this to fio@vger.kernel.org\\n\");\n\t\treturn 1;\n\t}\n\n#if !defined(CONFIG_GETTIMEOFDAY) && !defined(CONFIG_CLOCK_GETTIME)\n#error \"No available clock source!\"\n#endif\n\n\tarch_init(envp);\n\n\tsinit();\n\n\tif (fio_filelock_init()) {\n\t\tlog_err(\"fio: failed initializing filelock subsys\\n\");\n\t\treturn 1;\n\t}\n\n\tfile_hash_init();\n\n\t/*\n\t * We need locale for number printing, if it isn't set then just\n\t * go with the US format.\n\t */\n\tif (!getenv(\"LC_NUMERIC\"))\n\t\tsetlocale(LC_NUMERIC, \"en_US\");\n\n\tps = sysconf(_SC_PAGESIZE);\n\tif (ps < 0) {\n\t\tlog_err(\"Failed to get page size\\n\");\n\t\treturn 1;\n\t}\n\n\tpage_size = ps;\n\tpage_mask = ps - 1;\n\n\tfio_keywords_init();\n\treturn 0;\n}\n\nvoid deinitialize_fio(void)\n{\n\tfio_keywords_exit();\n}\n"
        },
        {
          "name": "log.c",
          "type": "blob",
          "size": 2.470703125,
          "content": "#include \"log.h\"\n\n#include <unistd.h>\n#include <string.h>\n#include <stdarg.h>\n#include <syslog.h>\n\n#include \"fio.h\"\n#include \"oslib/asprintf.h\"\n\nsize_t log_info_buf(const char *buf, size_t len)\n{\n\t/*\n\t * buf could be NULL (not just \"\").\n\t */\n\tif (!buf)\n\t\treturn 0;\n\n\tif (is_backend) {\n\t\tssize_t ret = fio_server_text_output(FIO_LOG_INFO, buf, len);\n\t\tif (ret != -1)\n\t\t\treturn ret;\n\t}\n\n\tif (log_syslog) {\n\t\tsyslog(LOG_INFO, \"%s\", buf);\n\t\treturn len;\n\t} else\n\t\treturn fwrite(buf, len, 1, f_out);\n}\n\nsize_t log_valist(const char *fmt, va_list args)\n{\n\tchar *buffer;\n\tint len;\n\n\tlen = vasprintf(&buffer, fmt, args);\n\tif (len < 0)\n\t\treturn 0;\n\tlen = log_info_buf(buffer, len);\n\tfree(buffer);\n\n\treturn len;\n}\n\n/* add prefix for the specified type in front of the valist */\n#ifdef FIO_INC_DEBUG\nvoid log_prevalist(int type, const char *fmt, va_list args)\n{\n\tchar *buf1, *buf2;\n\tint len;\n\tpid_t pid;\n\n\tpid = gettid();\n\tif (fio_debug_jobp && *fio_debug_jobp != -1U\n\t    && pid != *fio_debug_jobp)\n\t\treturn;\n\n\tlen = vasprintf(&buf1, fmt, args);\n\tif (len < 0)\n\t\treturn;\n\tlen = asprintf(&buf2, \"%-8s %-5u %s\", debug_levels[type].name,\n\t\t       (int) pid, buf1);\n\tfree(buf1);\n\tif (len < 0)\n\t\treturn;\n\tlog_info_buf(buf2, len);\n\tfree(buf2);\n}\n#endif\n\nssize_t log_info(const char *format, ...)\n{\n\tva_list args;\n\tssize_t ret;\n\n\tva_start(args, format);\n\tret = log_valist(format, args);\n\tva_end(args);\n\n\treturn ret;\n}\n\nsize_t __log_buf(struct buf_output *buf, const char *format, ...)\n{\n\tchar *buffer;\n\tva_list args;\n\tint len;\n\n\tva_start(args, format);\n\tlen = vasprintf(&buffer, format, args);\n\tva_end(args);\n\tif (len < 0)\n\t\treturn 0;\n\tlen = buf_output_add(buf, buffer, len);\n\tfree(buffer);\n\n\treturn len;\n}\n\nint log_info_flush(void)\n{\n\tif (is_backend || log_syslog)\n\t\treturn 0;\n\n\treturn fflush(f_out);\n}\n\nssize_t log_err(const char *format, ...)\n{\n\tssize_t ret;\n\tint len;\n\tchar *buffer;\n\tva_list args;\n\n\tva_start(args, format);\n\tlen = vasprintf(&buffer, format, args);\n\tva_end(args);\n\tif (len < 0)\n\t\treturn len;\n\n\tif (is_backend) {\n\t\tret = fio_server_text_output(FIO_LOG_ERR, buffer, len);\n\t\tif (ret != -1)\n\t\t\tgoto done;\n\t}\n\n\tif (log_syslog) {\n\t\tsyslog(LOG_INFO, \"%s\", buffer);\n\t\tret = len;\n\t} else {\n\t\tif (f_err != stderr)\n\t\t\tret = fwrite(buffer, len, 1, stderr);\n\n\t\tret = fwrite(buffer, len, 1, f_err);\n\t}\n\ndone:\n\tfree(buffer);\n\treturn ret;\n}\n\nconst char *log_get_level(int level)\n{\n\tstatic const char *levels[] = { \"Unknown\", \"Debug\", \"Info\", \"Error\",\n\t\t\t\t\t\t\"Unknown\" };\n\n\tif (level >= FIO_LOG_NR)\n\t\tlevel = FIO_LOG_NR;\n\n\treturn levels[level];\n}\n"
        },
        {
          "name": "log.h",
          "type": "blob",
          "size": 1.0166015625,
          "content": "#ifndef FIO_LOG_H\n#define FIO_LOG_H\n\n#include <stdio.h>\n#include <stdarg.h>\n#include <unistd.h>\n\n#include \"lib/output_buffer.h\"\n\nextern FILE *f_out;\nextern FILE *f_err;\n\nextern ssize_t log_err(const char *format, ...) __attribute__ ((__format__ (__printf__, 1, 2)));\nextern ssize_t log_info(const char *format, ...) __attribute__ ((__format__ (__printf__, 1, 2)));\nextern size_t __log_buf(struct buf_output *, const char *format, ...) __attribute__ ((__format__ (__printf__, 2, 3)));\nextern size_t log_valist(const char *str, va_list);\nextern void log_prevalist(int type, const char *str, va_list);\nextern size_t log_info_buf(const char *buf, size_t len);\nextern int log_info_flush(void);\n\n#define log_buf(buf, format, args...)\t\t\t\\\n({\t\t\t\t\t\t\t\\\n\tsize_t __ret;\t\t\t\t\t\\\n\tif ((buf) != NULL)\t\t\t\t\\\n\t\t__ret = __log_buf(buf, format, ##args);\t\\\n\telse\t\t\t\t\t\t\\\n\t\t__ret = log_info(format, ##args);\t\\\n\t__ret;\t\t\t\t\t\t\\\n})\n\nenum {\n\tFIO_LOG_DEBUG\t= 1,\n\tFIO_LOG_INFO\t= 2,\n\tFIO_LOG_ERR\t= 3,\n\tFIO_LOG_NR\t= 4,\n};\n\nextern const char *log_get_level(int level);\n\n#endif\n"
        },
        {
          "name": "memory.c",
          "type": "blob",
          "size": 9.0517578125,
          "content": "/*\n * Memory helpers\n */\n#include <fcntl.h>\n#include <unistd.h>\n#include <sys/mman.h>\n#include <sys/stat.h>\n\n#include \"fio.h\"\n#ifndef FIO_NO_HAVE_SHM_H\n#include <sys/shm.h>\n#endif\n\nvoid fio_unpin_memory(struct thread_data *td)\n{\n\tif (td->pinned_mem) {\n\t\tdprint(FD_MEM, \"unpinning %llu bytes\\n\", td->o.lockmem);\n\t\tif (munlock(td->pinned_mem, td->o.lockmem) < 0)\n\t\t\tperror(\"munlock\");\n\t\tmunmap(td->pinned_mem, td->o.lockmem);\n\t\ttd->pinned_mem = NULL;\n\t}\n}\n\nint fio_pin_memory(struct thread_data *td)\n{\n\tunsigned long long phys_mem;\n\n\tif (!td->o.lockmem)\n\t\treturn 0;\n\n\tdprint(FD_MEM, \"pinning %llu bytes\\n\", td->o.lockmem);\n\n\t/*\n\t * Don't allow mlock of more than real_mem-128MiB\n\t */\n\tphys_mem = os_phys_mem();\n\tif (phys_mem) {\n\t\tif ((td->o.lockmem + 128 * 1024 * 1024) > phys_mem) {\n\t\t\ttd->o.lockmem = phys_mem - 128 * 1024 * 1024;\n\t\t\tlog_info(\"fio: limiting mlocked memory to %lluMiB\\n\",\n\t\t\t\t\t\t\ttd->o.lockmem >> 20);\n\t\t}\n\t}\n\n\ttd->pinned_mem = mmap(NULL, td->o.lockmem, PROT_READ | PROT_WRITE,\n\t\t\t\tMAP_PRIVATE | OS_MAP_ANON, -1, 0);\n\tif (td->pinned_mem == MAP_FAILED) {\n\t\tperror(\"malloc locked mem\");\n\t\ttd->pinned_mem = NULL;\n\t\treturn 1;\n\t}\n\tif (mlock(td->pinned_mem, td->o.lockmem) < 0) {\n\t\tperror(\"mlock\");\n\t\tmunmap(td->pinned_mem, td->o.lockmem);\n\t\ttd->pinned_mem = NULL;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic int alloc_mem_shm(struct thread_data *td, unsigned int total_mem)\n{\n#ifndef CONFIG_NO_SHM\n\tint flags = IPC_CREAT | S_IRUSR | S_IWUSR;\n\n\tif (td->o.mem_type == MEM_SHMHUGE) {\n\t\tunsigned long mask = td->o.hugepage_size - 1;\n\n\t\tflags |= SHM_HUGETLB;\n\t\ttotal_mem = (total_mem + mask) & ~mask;\n\t}\n\n\ttd->shm_id = shmget(IPC_PRIVATE, total_mem, flags);\n\tdprint(FD_MEM, \"shmget %u, %d\\n\", total_mem, td->shm_id);\n\tif (td->shm_id < 0) {\n\t\ttd_verror(td, errno, \"shmget\");\n\t\tif (geteuid() != 0 && (errno == ENOMEM || errno == EPERM))\n\t\t\tlog_err(\"fio: you may need to run this job as root\\n\");\n\t\tif (td->o.mem_type == MEM_SHMHUGE) {\n\t\t\tif (errno == EINVAL) {\n\t\t\t\tlog_err(\"fio: check that you have free huge\"\n\t\t\t\t\t\" pages and that hugepage-size is\"\n\t\t\t\t\t\" correct.\\n\");\n\t\t\t} else if (errno == ENOSYS) {\n\t\t\t\tlog_err(\"fio: your system does not appear to\"\n\t\t\t\t\t\" support huge pages.\\n\");\n\t\t\t} else if (errno == ENOMEM) {\n\t\t\t\tlog_err(\"fio: no huge pages available, do you\"\n\t\t\t\t\t\" need to allocate some? See HOWTO.\\n\");\n\t\t\t}\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\ttd->orig_buffer = shmat(td->shm_id, NULL, 0);\n\tdprint(FD_MEM, \"shmat %d, %p\\n\", td->shm_id, td->orig_buffer);\n\tif (td->orig_buffer == (void *) -1) {\n\t\ttd_verror(td, errno, \"shmat\");\n\t\ttd->orig_buffer = NULL;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n#else\n\tlog_err(\"fio: shm not supported\\n\");\n\treturn 1;\n#endif\n}\n\nstatic void free_mem_shm(struct thread_data *td)\n{\n#ifndef CONFIG_NO_SHM\n\tstruct shmid_ds sbuf;\n\n\tdprint(FD_MEM, \"shmdt/ctl %d %p\\n\", td->shm_id, td->orig_buffer);\n\tshmdt(td->orig_buffer);\n\tshmctl(td->shm_id, IPC_RMID, &sbuf);\n#endif\n}\n\nstatic int alloc_mem_mmap(struct thread_data *td, size_t total_mem)\n{\n\tint flags = 0;\n\n\ttd->mmapfd = -1;\n\n\tif (td->o.mem_type == MEM_MMAPHUGE) {\n\t\tunsigned long mask = td->o.hugepage_size - 1;\n\n\t\t/* TODO: make sure the file is a real hugetlbfs file */\n\t\tif (!td->o.mmapfile)\n\t\t\tflags |= MAP_HUGETLB;\n\t\ttotal_mem = (total_mem + mask) & ~mask;\n\t}\n\n\tif (td->o.mmapfile) {\n\t\tif (access(td->o.mmapfile, F_OK) == 0)\n\t\t\ttd->flags |= TD_F_MMAP_KEEP;\n\n\t\ttd->mmapfd = open(td->o.mmapfile, O_RDWR|O_CREAT, 0644);\n\n\t\tif (td->mmapfd < 0) {\n\t\t\ttd_verror(td, errno, \"open mmap file\");\n\t\t\ttd->orig_buffer = NULL;\n\t\t\treturn 1;\n\t\t}\n\t\tif (td->o.mem_type != MEM_MMAPHUGE &&\n\t\t    td->o.mem_type != MEM_MMAPSHARED &&\n\t\t    ftruncate(td->mmapfd, total_mem) < 0) {\n\t\t\ttd_verror(td, errno, \"truncate mmap file\");\n\t\t\ttd->orig_buffer = NULL;\n\t\t\treturn 1;\n\t\t}\n\t\tif (td->o.mem_type == MEM_MMAPHUGE ||\n\t\t    td->o.mem_type == MEM_MMAPSHARED)\n\t\t\tflags |= MAP_SHARED;\n\t\telse\n\t\t\tflags |= MAP_PRIVATE;\n\t} else\n\t\tflags |= OS_MAP_ANON | MAP_PRIVATE;\n\n\ttd->orig_buffer = mmap(NULL, total_mem, PROT_READ | PROT_WRITE, flags,\n\t\t\t\ttd->mmapfd, 0);\n\tdprint(FD_MEM, \"mmap %llu/%d %p\\n\", (unsigned long long) total_mem,\n\t\t\t\t\t\ttd->mmapfd, td->orig_buffer);\n\tif (td->orig_buffer == MAP_FAILED) {\n\t\ttd_verror(td, errno, \"mmap\");\n\t\ttd->orig_buffer = NULL;\n\t\tif (td->mmapfd != 1 && td->mmapfd != -1) {\n\t\t\tclose(td->mmapfd);\n\t\t\tif (td->o.mmapfile && !(td->flags & TD_F_MMAP_KEEP))\n\t\t\t\tunlink(td->o.mmapfile);\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic void free_mem_mmap(struct thread_data *td, size_t total_mem)\n{\n\tdprint(FD_MEM, \"munmap %llu %p\\n\", (unsigned long long) total_mem,\n\t\t\t\t\t\ttd->orig_buffer);\n\tmunmap(td->orig_buffer, td->orig_buffer_size);\n\tif (td->o.mmapfile) {\n\t\tif (td->mmapfd != -1)\n\t\t\tclose(td->mmapfd);\n\t\tif (!(td->flags & TD_F_MMAP_KEEP))\n\t\t\tunlink(td->o.mmapfile);\n\t\tfree(td->o.mmapfile);\n\t}\n}\n\nstatic int alloc_mem_malloc(struct thread_data *td, size_t total_mem)\n{\n\ttd->orig_buffer = malloc(total_mem);\n\tdprint(FD_MEM, \"malloc %llu %p\\n\", (unsigned long long) total_mem,\n\t\t\t\t\t\t\ttd->orig_buffer);\n\n\treturn td->orig_buffer == NULL;\n}\n\nstatic void free_mem_malloc(struct thread_data *td)\n{\n\tdprint(FD_MEM, \"free malloc mem %p\\n\", td->orig_buffer);\n\tfree(td->orig_buffer);\n}\n\nstatic int alloc_mem_cudamalloc(struct thread_data *td, size_t total_mem)\n{\n#ifdef CONFIG_CUDA\n\tCUresult ret;\n\tchar name[128];\n\n\tret = cuInit(0);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: failed initialize cuda driver api\\n\");\n\t\treturn 1;\n\t}\n\n\tret = cuDeviceGetCount(&td->gpu_dev_cnt);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: failed get device count\\n\");\n\t\treturn 1;\n\t}\n\tdprint(FD_MEM, \"found %d GPU devices\\n\", td->gpu_dev_cnt);\n\n\tif (td->gpu_dev_cnt == 0) {\n\t\tlog_err(\"fio: no GPU device found. \"\n\t\t\t\"Can not perform GPUDirect RDMA.\\n\");\n\t\treturn 1;\n\t}\n\n\ttd->gpu_dev_id = td->o.gpu_dev_id;\n\tret = cuDeviceGet(&td->cu_dev, td->gpu_dev_id);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: failed get GPU device\\n\");\n\t\treturn 1;\n\t}\n\n\tret = cuDeviceGetName(name, sizeof(name), td->gpu_dev_id);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: failed get device name\\n\");\n\t\treturn 1;\n\t}\n\tdprint(FD_MEM, \"dev_id = [%d], device name = [%s]\\n\", \\\n\t       td->gpu_dev_id, name);\n\n\tret = cuCtxCreate(&td->cu_ctx, CU_CTX_MAP_HOST, td->cu_dev);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: failed to create cuda context: %d\\n\", ret);\n\t\treturn 1;\n\t}\n\n\tret = cuMemAlloc(&td->dev_mem_ptr, total_mem);\n\tif (ret != CUDA_SUCCESS) {\n\t\tlog_err(\"fio: cuMemAlloc %zu bytes failed\\n\", total_mem);\n\t\treturn 1;\n\t}\n\ttd->orig_buffer = (void *) td->dev_mem_ptr;\n\n\tdprint(FD_MEM, \"cudaMalloc %llu %p\\n\",\t\t\t\t\\\n\t       (unsigned long long) total_mem, td->orig_buffer);\n\treturn 0;\n#else\n\treturn -EINVAL;\n#endif\n}\n\nstatic void free_mem_cudamalloc(struct thread_data *td)\n{\n#ifdef CONFIG_CUDA\n\tif (td->dev_mem_ptr)\n\t\tcuMemFree(td->dev_mem_ptr);\n\n\tif (cuCtxDestroy(td->cu_ctx) != CUDA_SUCCESS)\n\t\tlog_err(\"fio: failed to destroy cuda context\\n\");\n#endif\n}\n\n/*\n * Set up the buffer area we need for io.\n */\nint allocate_io_mem(struct thread_data *td)\n{\n\tsize_t total_mem;\n\tint ret = 0;\n\n\tif (td_ioengine_flagged(td, FIO_NOIO))\n\t\treturn 0;\n\n\ttotal_mem = td->orig_buffer_size;\n\n\tif (td->o.odirect || td->o.mem_align ||\n\t    td_ioengine_flagged(td, FIO_MEMALIGN)) {\n\t\ttotal_mem += page_mask;\n\t\tif (td->o.mem_align && td->o.mem_align > page_size)\n\t\t\ttotal_mem += td->o.mem_align - page_size;\n\t}\n\n\tdprint(FD_MEM, \"Alloc %llu for buffers\\n\", (unsigned long long) total_mem);\n\n\t/*\n\t * If the IO engine has hooks to allocate/free memory and the user\n\t * doesn't explicitly ask for something else, use those. But fail if the\n\t * user asks for something else with an engine that doesn't allow that.\n\t */\n\tif (td->io_ops->iomem_alloc && fio_option_is_set(&td->o, mem_type) &&\n\t    !td_ioengine_flagged(td, FIO_SKIPPABLE_IOMEM_ALLOC)) {\n\t\tlog_err(\"fio: option 'mem/iomem' conflicts with specified IO engine\\n\");\n\t\tret = 1;\n\t} else if (td->io_ops->iomem_alloc &&\n\t\t   !fio_option_is_set(&td->o, mem_type))\n\t\tret = td->io_ops->iomem_alloc(td, total_mem);\n\telse if (td->o.mem_type == MEM_MALLOC)\n\t\tret = alloc_mem_malloc(td, total_mem);\n\telse if (td->o.mem_type == MEM_SHM || td->o.mem_type == MEM_SHMHUGE)\n\t\tret = alloc_mem_shm(td, total_mem);\n\telse if (td->o.mem_type == MEM_MMAP || td->o.mem_type == MEM_MMAPHUGE ||\n\t\t td->o.mem_type == MEM_MMAPSHARED)\n\t\tret = alloc_mem_mmap(td, total_mem);\n\telse if (td->o.mem_type == MEM_CUDA_MALLOC)\n\t\tret = alloc_mem_cudamalloc(td, total_mem);\n\telse {\n\t\tlog_err(\"fio: bad mem type: %d\\n\", td->o.mem_type);\n\t\tret = 1;\n\t}\n\n\tif (ret)\n\t\ttd_verror(td, ENOMEM, \"iomem allocation\");\n\n\treturn ret;\n}\n\nvoid free_io_mem(struct thread_data *td)\n{\n\tunsigned int total_mem;\n\n\ttotal_mem = td->orig_buffer_size;\n\tif (td->o.odirect)\n\t\ttotal_mem += page_mask;\n\n\tif (td->io_ops->iomem_alloc && !fio_option_is_set(&td->o, mem_type)) {\n\t\tif (td->io_ops->iomem_free)\n\t\t\ttd->io_ops->iomem_free(td);\n\t} else if (td->o.mem_type == MEM_MALLOC)\n\t\tfree_mem_malloc(td);\n\telse if (td->o.mem_type == MEM_SHM || td->o.mem_type == MEM_SHMHUGE)\n\t\tfree_mem_shm(td);\n\telse if (td->o.mem_type == MEM_MMAP || td->o.mem_type == MEM_MMAPHUGE ||\n\t\t td->o.mem_type == MEM_MMAPSHARED)\n\t\tfree_mem_mmap(td, total_mem);\n\telse if (td->o.mem_type == MEM_CUDA_MALLOC)\n\t\tfree_mem_cudamalloc(td);\n\telse\n\t\tlog_err(\"Bad memory type %u\\n\", td->o.mem_type);\n\n\ttd->orig_buffer = NULL;\n\ttd->orig_buffer_size = 0;\n}\n"
        },
        {
          "name": "minmax.h",
          "type": "blob",
          "size": 0.4775390625,
          "content": "#ifndef FIO_MIN_MAX_H\n#define FIO_MIN_MAX_H\n\n#ifndef min\n#define min(x,y) ({ \\\n\t__typeof__(x) _x = (x);\t\\\n\t__typeof__(y) _y = (y);\t\\\n\t(void) (&_x == &_y);\t\t\\\n\t_x < _y ? _x : _y; })\n#endif\n\n#ifndef max\n#define max(x,y) ({ \\\n\t__typeof__(x) _x = (x);\t\\\n\t__typeof__(y) _y = (y);\t\\\n\t(void) (&_x == &_y);\t\t\\\n\t_x > _y ? _x : _y; })\n#endif\n\n#define min_not_zero(x, y) ({\t\t\\\n\t__typeof__(x) __x = (x);\t\t\\\n\t__typeof__(y) __y = (y);\t\t\\\n\t__x == 0 ? __y : ((__y == 0) ? __x : min(__x, __y)); })\n\n#endif\n"
        },
        {
          "name": "optgroup.c",
          "type": "blob",
          "size": 3.6865234375,
          "content": "#include <stdio.h>\n#include <inttypes.h>\n#include \"optgroup.h\"\n#include \"compiler/compiler.h\"\n\n/*\n * Option grouping\n */\nstatic const struct opt_group fio_opt_groups[] = {\n\t{\n\t\t.name\t= \"General\",\n\t\t.mask\t= FIO_OPT_C_GENERAL,\n\t},\n\t{\n\t\t.name\t= \"I/O\",\n\t\t.mask\t= FIO_OPT_C_IO,\n\t},\n\t{\n\t\t.name\t= \"File\",\n\t\t.mask\t= FIO_OPT_C_FILE,\n\t},\n\t{\n\t\t.name\t= \"Statistics\",\n\t\t.mask\t= FIO_OPT_C_STAT,\n\t},\n\t{\n\t\t.name\t= \"Logging\",\n\t\t.mask\t= FIO_OPT_C_LOG,\n\t},\n\t{\n\t\t.name\t= \"Profiles\",\n\t\t.mask\t= FIO_OPT_C_PROFILE,\n\t},\n\t{\n\t\t.name\t= \"I/O engines\",\n\t\t.mask\t= FIO_OPT_C_ENGINE,\n\t},\n\t{\n\t\t.name\t= NULL,\n\t},\n};\n\nstatic const struct opt_group fio_opt_cat_groups[] = {\n\t{\n\t\t.name\t= \"Rate\",\n\t\t.mask\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"Zone\",\n\t\t.mask\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"Read/write mix\",\n\t\t.mask\t= FIO_OPT_G_RWMIX,\n\t},\n\t{\n\t\t.name\t= \"Verify\",\n\t\t.mask\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"Trim\",\n\t\t.mask\t= FIO_OPT_G_TRIM,\n\t},\n\t{\n\t\t.name\t= \"I/O Logging\",\n\t\t.mask\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"I/O Depth\",\n\t\t.mask\t= FIO_OPT_G_IO_DEPTH,\n\t},\n\t{\n\t\t.name\t= \"I/O Flow\",\n\t\t.mask\t= FIO_OPT_G_IO_FLOW,\n\t},\n\t{\n\t\t.name\t= \"Description\",\n\t\t.mask\t= FIO_OPT_G_DESC,\n\t},\n\t{\n\t\t.name\t= \"Filename\",\n\t\t.mask\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"General I/O\",\n\t\t.mask\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"Cgroups\",\n\t\t.mask\t= FIO_OPT_G_CGROUP,\n\t},\n\t{\n\t\t.name\t= \"Runtime\",\n\t\t.mask\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"Process\",\n\t\t.mask\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"Job credentials / priority\",\n\t\t.mask\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"Clock settings\",\n\t\t.mask\t= FIO_OPT_G_CLOCK,\n\t},\n\t{\n\t\t.name\t= \"I/O Type\",\n\t\t.mask\t= FIO_OPT_G_IO_TYPE,\n\t},\n\t{\n\t\t.name\t= \"I/O Thinktime\",\n\t\t.mask\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"Randomizations\",\n\t\t.mask\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"I/O buffers\",\n\t\t.mask\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"Tiobench profile\",\n\t\t.mask\t= FIO_OPT_G_TIOBENCH,\n\t},\n\t{\n\t\t.name\t= \"Error handling\",\n\t\t.mask\t= FIO_OPT_G_ERR,\n\t},\n\t{\n\t\t.name\t= \"Ext4 defrag I/O engine\", /* e4defrag */\n\t\t.mask\t= FIO_OPT_G_E4DEFRAG,\n\t},\n\t{\n\t\t.name\t= \"Network I/O engine\", /* net */\n\t\t.mask\t= FIO_OPT_G_NETIO,\n\t},\n\t{\n\t\t.name\t= \"RDMA I/O engine\", /* rdma */\n\t\t.mask\t= FIO_OPT_G_RDMA,\n\t},\n\t{\n\t\t.name\t= \"libaio I/O engine\", /* libaio */\n\t\t.mask\t= FIO_OPT_G_LIBAIO,\n\t},\n\t{\n\t\t.name\t= \"ACT Aerospike like benchmark profile\",\n\t\t.mask\t= FIO_OPT_G_ACT,\n\t},\n\t{\n\t\t.name\t= \"Latency profiling\",\n\t\t.mask\t= FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"RBD I/O engine\", /* rbd */\n\t\t.mask\t= FIO_OPT_G_RBD,\n\t},\n\t{\n\t\t.name\t= \"GlusterFS I/O engine\", /* gfapi,gfapi_async */\n\t\t.mask\t= FIO_OPT_G_GFAPI,\n\t},\n\t{\n\t\t.name\t= \"MTD I/O engine\", /* mtd */\n\t\t.mask\t= FIO_OPT_G_MTD,\n\t},\n\t{\n\t\t.name\t= \"libhdfs I/O engine\", /* libhdfs */\n\t\t.mask\t= FIO_OPT_G_HDFS,\n\t},\n\t{\n\t\t.name\t= \"NBD I/O engine\", /* NBD */\n\t\t.mask\t= FIO_OPT_G_NBD,\n\t},\n\t{\n\t\t.name\t= \"libcufile I/O engine\", /* libcufile */\n\t\t.mask\t= FIO_OPT_G_LIBCUFILE,\n\t},\n\t{\n\t\t.name\t= \"DAOS File System (dfs) I/O engine\", /* dfs */\n\t\t.mask\t= FIO_OPT_G_DFS,\n\t},\n\t{\n\t\t.name\t= \"NFS I/O engine\", /* nfs */\n\t\t.mask\t= FIO_OPT_G_NFS,\n\t},\n\t{\n\t\t.name\t= NULL,\n\t},\n};\n\nstatic const struct opt_group *group_from_mask(const struct opt_group *ogs,\n\t\t\t\t\t       uint64_t *mask,\n\t\t\t\t\t       uint64_t inv_mask)\n{\n\tint i;\n\n\tif (*mask == inv_mask || !*mask)\n\t\treturn NULL;\n\n\tfor (i = 0; ogs[i].name; i++) {\n\t\tconst struct opt_group *og = &ogs[i];\n\n\t\tif (*mask & og->mask) {\n\t\t\t*mask &= ~(og->mask);\n\t\t\treturn og;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nconst struct opt_group *opt_group_from_mask(uint64_t *mask)\n{\n\treturn group_from_mask(fio_opt_groups, mask, FIO_OPT_C_INVALID);\n}\n\nconst struct opt_group *opt_group_cat_from_mask(uint64_t *mask)\n{\n\tcompiletime_assert(__FIO_OPT_G_NR <= 8 * sizeof(uint64_t),\n\t\t\t\t\"__FIO_OPT_G_NR\");\n\n\treturn group_from_mask(fio_opt_cat_groups, mask, FIO_OPT_G_INVALID);\n}\n"
        },
        {
          "name": "optgroup.h",
          "type": "blob",
          "size": 3.998046875,
          "content": "#ifndef FIO_OPT_GROUP_H\n#define FIO_OPT_GROUP_H\n\nstruct opt_group {\n\tconst char *name;\n\tuint64_t mask;\n};\n\nenum opt_category {\n\t__FIO_OPT_C_GENERAL\t= 0,\n\t__FIO_OPT_C_IO,\n\t__FIO_OPT_C_FILE,\n\t__FIO_OPT_C_STAT,\n\t__FIO_OPT_C_LOG,\n\t__FIO_OPT_C_PROFILE,\n\t__FIO_OPT_C_ENGINE,\n\t__FIO_OPT_C_NR,\n\n\tFIO_OPT_C_GENERAL\t= (1ULL << __FIO_OPT_C_GENERAL),\n\tFIO_OPT_C_IO\t\t= (1ULL << __FIO_OPT_C_IO),\n\tFIO_OPT_C_FILE\t\t= (1ULL << __FIO_OPT_C_FILE),\n\tFIO_OPT_C_STAT\t\t= (1ULL << __FIO_OPT_C_STAT),\n\tFIO_OPT_C_LOG\t\t= (1ULL << __FIO_OPT_C_LOG),\n\tFIO_OPT_C_PROFILE\t= (1ULL << __FIO_OPT_C_PROFILE),\n\tFIO_OPT_C_ENGINE\t= (1ULL << __FIO_OPT_C_ENGINE),\n\tFIO_OPT_C_INVALID\t= (1ULL << __FIO_OPT_C_NR),\n};\n\nenum opt_category_group {\n\t__FIO_OPT_G_RATE\t= 0,\n\t__FIO_OPT_G_ZONE,\n\t__FIO_OPT_G_RWMIX,\n\t__FIO_OPT_G_VERIFY,\n\t__FIO_OPT_G_TRIM,\n\t__FIO_OPT_G_IOLOG,\n\t__FIO_OPT_G_IO_DEPTH,\n\t__FIO_OPT_G_IO_FLOW,\n\t__FIO_OPT_G_DESC,\n\t__FIO_OPT_G_FILENAME,\n\t__FIO_OPT_G_IO_BASIC,\n\t__FIO_OPT_G_CGROUP,\n\t__FIO_OPT_G_RUNTIME,\n\t__FIO_OPT_G_PROCESS,\n\t__FIO_OPT_G_CRED,\n\t__FIO_OPT_G_CLOCK,\n\t__FIO_OPT_G_IO_TYPE,\n\t__FIO_OPT_G_THINKTIME,\n\t__FIO_OPT_G_RANDOM,\n\t__FIO_OPT_G_IO_BUF,\n\t__FIO_OPT_G_TIOBENCH,\n\t__FIO_OPT_G_ERR,\n\t__FIO_OPT_G_E4DEFRAG,\n\t__FIO_OPT_G_NETIO,\n\t__FIO_OPT_G_RDMA,\n\t__FIO_OPT_G_LIBAIO,\n\t__FIO_OPT_G_ACT,\n\t__FIO_OPT_G_LATPROF,\n\t__FIO_OPT_G_RBD,\n\t__FIO_OPT_G_HTTP,\n\t__FIO_OPT_G_GFAPI,\n\t__FIO_OPT_G_MTD,\n\t__FIO_OPT_G_HDFS,\n\t__FIO_OPT_G_SG,\n\t__FIO_OPT_G_MMAP,\n\t__FIO_OPT_G_ISCSI,\n\t__FIO_OPT_G_NBD,\n\t__FIO_OPT_G_IOURING,\n\t__FIO_OPT_G_FILESTAT,\n\t__FIO_OPT_G_NR,\n\t__FIO_OPT_G_LIBCUFILE,\n\t__FIO_OPT_G_DFS,\n\t__FIO_OPT_G_NFS,\n\t__FIO_OPT_G_WINDOWSAIO,\n\t__FIO_OPT_G_XNVME,\n\t__FIO_OPT_G_LIBBLKIO,\n\n\tFIO_OPT_G_RATE\t\t= (1ULL << __FIO_OPT_G_RATE),\n\tFIO_OPT_G_ZONE\t\t= (1ULL << __FIO_OPT_G_ZONE),\n\tFIO_OPT_G_RWMIX\t\t= (1ULL << __FIO_OPT_G_RWMIX),\n\tFIO_OPT_G_VERIFY\t= (1ULL << __FIO_OPT_G_VERIFY),\n\tFIO_OPT_G_TRIM\t\t= (1ULL << __FIO_OPT_G_TRIM),\n\tFIO_OPT_G_IOLOG\t\t= (1ULL << __FIO_OPT_G_IOLOG),\n\tFIO_OPT_G_IO_DEPTH\t= (1ULL << __FIO_OPT_G_IO_DEPTH),\n\tFIO_OPT_G_IO_FLOW\t= (1ULL << __FIO_OPT_G_IO_FLOW),\n\tFIO_OPT_G_DESC\t\t= (1ULL << __FIO_OPT_G_DESC),\n\tFIO_OPT_G_FILENAME\t= (1ULL << __FIO_OPT_G_FILENAME),\n\tFIO_OPT_G_IO_BASIC\t= (1ULL << __FIO_OPT_G_IO_BASIC),\n\tFIO_OPT_G_CGROUP\t= (1ULL << __FIO_OPT_G_CGROUP),\n\tFIO_OPT_G_RUNTIME\t= (1ULL << __FIO_OPT_G_RUNTIME),\n\tFIO_OPT_G_PROCESS\t= (1ULL << __FIO_OPT_G_PROCESS),\n\tFIO_OPT_G_CRED\t\t= (1ULL << __FIO_OPT_G_CRED),\n\tFIO_OPT_G_CLOCK\t\t= (1ULL << __FIO_OPT_G_CLOCK),\n\tFIO_OPT_G_IO_TYPE\t= (1ULL << __FIO_OPT_G_IO_TYPE),\n\tFIO_OPT_G_THINKTIME\t= (1ULL << __FIO_OPT_G_THINKTIME),\n\tFIO_OPT_G_RANDOM\t= (1ULL << __FIO_OPT_G_RANDOM),\n\tFIO_OPT_G_IO_BUF\t= (1ULL << __FIO_OPT_G_IO_BUF),\n\tFIO_OPT_G_TIOBENCH\t= (1ULL << __FIO_OPT_G_TIOBENCH),\n\tFIO_OPT_G_ERR\t\t= (1ULL << __FIO_OPT_G_ERR),\n\tFIO_OPT_G_E4DEFRAG\t= (1ULL << __FIO_OPT_G_E4DEFRAG),\n\tFIO_OPT_G_NETIO\t\t= (1ULL << __FIO_OPT_G_NETIO),\n\tFIO_OPT_G_RDMA\t\t= (1ULL << __FIO_OPT_G_RDMA),\n\tFIO_OPT_G_LIBAIO\t= (1ULL << __FIO_OPT_G_LIBAIO),\n\tFIO_OPT_G_ACT\t\t= (1ULL << __FIO_OPT_G_ACT),\n\tFIO_OPT_G_LATPROF\t= (1ULL << __FIO_OPT_G_LATPROF),\n\tFIO_OPT_G_RBD\t\t= (1ULL << __FIO_OPT_G_RBD),\n\tFIO_OPT_G_HTTP\t\t= (1ULL << __FIO_OPT_G_HTTP),\n\tFIO_OPT_G_GFAPI\t\t= (1ULL << __FIO_OPT_G_GFAPI),\n\tFIO_OPT_G_MTD\t\t= (1ULL << __FIO_OPT_G_MTD),\n\tFIO_OPT_G_HDFS\t\t= (1ULL << __FIO_OPT_G_HDFS),\n\tFIO_OPT_G_SG\t\t= (1ULL << __FIO_OPT_G_SG),\n\tFIO_OPT_G_MMAP\t\t= (1ULL << __FIO_OPT_G_MMAP),\n\tFIO_OPT_G_INVALID\t= (1ULL << __FIO_OPT_G_NR),\n\tFIO_OPT_G_ISCSI         = (1ULL << __FIO_OPT_G_ISCSI),\n\tFIO_OPT_G_NBD\t\t= (1ULL << __FIO_OPT_G_NBD),\n\tFIO_OPT_G_NFS\t\t= (1ULL << __FIO_OPT_G_NFS),\n\tFIO_OPT_G_IOURING\t= (1ULL << __FIO_OPT_G_IOURING),\n\tFIO_OPT_G_FILESTAT\t= (1ULL << __FIO_OPT_G_FILESTAT),\n\tFIO_OPT_G_LIBCUFILE\t= (1ULL << __FIO_OPT_G_LIBCUFILE),\n\tFIO_OPT_G_DFS\t\t= (1ULL << __FIO_OPT_G_DFS),\n\tFIO_OPT_G_WINDOWSAIO\t= (1ULL << __FIO_OPT_G_WINDOWSAIO),\n\tFIO_OPT_G_XNVME         = (1ULL << __FIO_OPT_G_XNVME),\n\tFIO_OPT_G_LIBBLKIO\t= (1ULL << __FIO_OPT_G_LIBBLKIO),\n};\n\nextern const struct opt_group *opt_group_from_mask(uint64_t *mask);\nextern const struct opt_group *opt_group_cat_from_mask(uint64_t *mask);\n\n#endif\n"
        },
        {
          "name": "options.c",
          "type": "blob",
          "size": 145.23046875,
          "content": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <string.h>\n#include <assert.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <netinet/in.h>\n\n#include \"fio.h\"\n#include \"verify.h\"\n#include \"parse.h\"\n#include \"lib/pattern.h\"\n#include \"options.h\"\n#include \"optgroup.h\"\n#include \"zbd.h\"\n\nchar client_sockaddr_str[INET6_ADDRSTRLEN] = { 0 };\n\n#define cb_data_to_td(data)\tcontainer_of(data, struct thread_data, o)\n\nstatic const struct pattern_fmt_desc fmt_desc[] = {\n\t{\n\t\t.fmt   = \"%o\",\n\t\t.len   = FIO_FIELD_SIZE(struct io_u *, offset),\n\t\t.paste = paste_blockoff\n\t},\n\t{ }\n};\n\n/*\n * Check if mmap/mmaphuge has a :/foo/bar/file at the end. If so, return that.\n */\nstatic char *get_opt_postfix(const char *str)\n{\n\tchar *p = strstr(str, \":\");\n\n\tif (!p)\n\t\treturn NULL;\n\n\tp++;\n\tstrip_blank_front(&p);\n\tstrip_blank_end(p);\n\treturn strdup(p);\n}\n\nstatic bool split_parse_distr(const char *str, double *val, double *center)\n{\n\tchar *cp, *p;\n\tbool r;\n\n\tp = strdup(str);\n\tif (!p)\n\t\treturn false;\n\n\tcp = strstr(p, \":\");\n\tr = true;\n\tif (cp) {\n\t\t*cp = '\\0';\n\t\tcp++;\n\t\tr = str_to_float(cp, center, 0);\n\t}\n\tr = r && str_to_float(p, val, 0);\n\tfree(p);\n\treturn r;\n}\n\nstatic int bs_cmp(const void *p1, const void *p2)\n{\n\tconst struct bssplit *bsp1 = p1;\n\tconst struct bssplit *bsp2 = p2;\n\n\treturn (int) bsp1->perc - (int) bsp2->perc;\n}\n\nint split_parse_ddir(struct thread_options *o, struct split *split,\n\t\t\t    char *str, bool absolute, unsigned int max_splits)\n{\n\tunsigned long long perc;\n\tunsigned int i;\n\tlong long val;\n\tchar *fname;\n\n\tsplit->nr = 0;\n\n\ti = 0;\n\twhile ((fname = strsep(&str, \":\")) != NULL) {\n\t\tchar *perc_str;\n\n\t\tif (!strlen(fname))\n\t\t\tbreak;\n\n\t\tperc_str = strstr(fname, \"/\");\n\t\tif (perc_str) {\n\t\t\t*perc_str = '\\0';\n\t\t\tperc_str++;\n\t\t\tif (absolute) {\n\t\t\t\tif (str_to_decimal(perc_str, &val, 1, o, 0, 0)) {\n\t\t\t\t\tlog_err(\"fio: split conversion failed\\n\");\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t\tperc = val;\n\t\t\t} else {\n\t\t\t\tperc = atoi(perc_str);\n\t\t\t\tif (perc > 100)\n\t\t\t\t\tperc = 100;\n\t\t\t\telse if (!perc)\n\t\t\t\t\tperc = -1U;\n\t\t\t}\n\t\t} else {\n\t\t\tif (absolute)\n\t\t\t\tperc = 0;\n\t\t\telse\n\t\t\t\tperc = -1U;\n\t\t}\n\n\t\tif (str_to_decimal(fname, &val, 1, o, 0, 0)) {\n\t\t\tlog_err(\"fio: split conversion failed\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\tsplit->val1[i] = val;\n\t\tsplit->val2[i] = perc;\n\t\ti++;\n\t\tif (i == max_splits) {\n\t\t\tlog_err(\"fio: hit max of %d split entries\\n\", i);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tsplit->nr = i;\n\treturn 0;\n}\n\nstatic int bssplit_ddir(struct thread_options *o, void *eo,\n\t\t\tenum fio_ddir ddir, char *str, bool data)\n{\n\tunsigned int i, perc, perc_missing;\n\tunsigned long long max_bs, min_bs;\n\tstruct split split;\n\n\tmemset(&split, 0, sizeof(split));\n\n\tif (split_parse_ddir(o, &split, str, data, BSSPLIT_MAX))\n\t\treturn 1;\n\tif (!split.nr)\n\t\treturn 0;\n\n\tmax_bs = 0;\n\tmin_bs = -1;\n\to->bssplit[ddir] = malloc(split.nr * sizeof(struct bssplit));\n\to->bssplit_nr[ddir] = split.nr;\n\tfor (i = 0; i < split.nr; i++) {\n\t\tif (split.val1[i] > max_bs)\n\t\t\tmax_bs = split.val1[i];\n\t\tif (split.val1[i] < min_bs)\n\t\t\tmin_bs = split.val1[i];\n\n\t\to->bssplit[ddir][i].bs = split.val1[i];\n\t\to->bssplit[ddir][i].perc =split.val2[i];\n\t}\n\n\t/*\n\t * Now check if the percentages add up, and how much is missing\n\t */\n\tperc = perc_missing = 0;\n\tfor (i = 0; i < o->bssplit_nr[ddir]; i++) {\n\t\tstruct bssplit *bsp = &o->bssplit[ddir][i];\n\n\t\tif (bsp->perc == -1U)\n\t\t\tperc_missing++;\n\t\telse\n\t\t\tperc += bsp->perc;\n\t}\n\n\tif (perc > 100 && perc_missing > 1) {\n\t\tlog_err(\"fio: bssplit percentages add to more than 100%%\\n\");\n\t\tfree(o->bssplit[ddir]);\n\t\to->bssplit[ddir] = NULL;\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If values didn't have a percentage set, divide the remains between\n\t * them.\n\t */\n\tif (perc_missing) {\n\t\tif (perc_missing == 1 && o->bssplit_nr[ddir] == 1)\n\t\t\tperc = 100;\n\t\tfor (i = 0; i < o->bssplit_nr[ddir]; i++) {\n\t\t\tstruct bssplit *bsp = &o->bssplit[ddir][i];\n\n\t\t\tif (bsp->perc == -1U)\n\t\t\t\tbsp->perc = (100 - perc) / perc_missing;\n\t\t}\n\t}\n\n\to->min_bs[ddir] = min_bs;\n\to->max_bs[ddir] = max_bs;\n\n\t/*\n\t * now sort based on percentages, for ease of lookup\n\t */\n\tqsort(o->bssplit[ddir], o->bssplit_nr[ddir], sizeof(struct bssplit), bs_cmp);\n\treturn 0;\n}\n\nint str_split_parse(struct thread_data *td, char *str,\n\t\t    split_parse_fn *fn, void *eo, bool data)\n{\n\tchar *odir, *ddir;\n\tint ret = 0;\n\n\todir = strchr(str, ',');\n\tif (odir) {\n\t\tddir = strchr(odir + 1, ',');\n\t\tif (ddir) {\n\t\t\tret = fn(&td->o, eo, DDIR_TRIM, ddir + 1, data);\n\t\t\tif (!ret)\n\t\t\t\t*ddir = '\\0';\n\t\t} else {\n\t\t\tchar *op;\n\n\t\t\top = strdup(odir + 1);\n\t\t\tret = fn(&td->o, eo, DDIR_TRIM, op, data);\n\n\t\t\tfree(op);\n\t\t}\n\t\tif (!ret)\n\t\t\tret = fn(&td->o, eo, DDIR_WRITE, odir + 1, data);\n\t\tif (!ret) {\n\t\t\t*odir = '\\0';\n\t\t\tret = fn(&td->o, eo, DDIR_READ, str, data);\n\t\t}\n\t} else {\n\t\tchar *op;\n\n\t\top = strdup(str);\n\t\tret = fn(&td->o, eo, DDIR_WRITE, op, data);\n\t\tfree(op);\n\n\t\tif (!ret) {\n\t\t\top = strdup(str);\n\t\t\tret = fn(&td->o, eo, DDIR_TRIM, op, data);\n\t\t\tfree(op);\n\t\t}\n\t\tif (!ret)\n\t\t\tret = fn(&td->o, eo, DDIR_READ, str, data);\n\t}\n\n\treturn ret;\n}\n\nstatic int fio_fdp_cmp(const void *p1, const void *p2)\n{\n\tconst uint16_t *t1 = p1;\n\tconst uint16_t *t2 = p2;\n\n\treturn *t1 - *t2;\n}\n\nstatic int str_fdp_pli_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *str, *p, *id1;\n\tint i = 0, ret = 0;\n\n\tp = str = strdup(input);\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\twhile ((id1 = strsep(&str, \",\")) != NULL) {\n\t\tchar *str2, *id2;\n\t\tunsigned int start, end;\n\n\t\tif (!strlen(id1))\n\t\t\tbreak;\n\n\t\tstr2 = id1;\n\t\tend = -1;\n\t\twhile ((id2 = strsep(&str2, \"-\")) != NULL) {\n\t\t\tif (!strlen(id2))\n\t\t\t\tbreak;\n\n\t\t\tend = strtoull(id2, NULL, 0);\n\t\t}\n\n\t\tstart = strtoull(id1, NULL, 0);\n\t\tif (end == -1)\n\t\t\tend = start;\n\t\tif (start > end) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\twhile (start <= end) {\n\t\t\tif (i >= FIO_MAX_DP_IDS) {\n\t\t\t\tlog_err(\"fio: only %d IDs supported\\n\", FIO_MAX_DP_IDS);\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (start > 0xFFFF) {\n\t\t\t\tlog_err(\"Placement IDs cannot exceed 0xFFFF\\n\");\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttd->o.dp_ids[i++] = start++;\n\t\t}\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tfree(p);\n\n\tqsort(td->o.dp_ids, i, sizeof(*td->o.dp_ids), fio_fdp_cmp);\n\ttd->o.dp_nr_ids = i;\n\n\treturn ret;\n}\n\n/* str_dp_scheme_cb() is a callback function for parsing the fdp_scheme option\n\tThis function validates the fdp_scheme filename. */\nstatic int str_dp_scheme_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct stat sb;\n\tchar *filename;\n\tint ret = 0;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tfilename = strdup(td->o.dp_scheme_file);\n\tstrip_blank_front(&filename);\n\tstrip_blank_end(filename);\n\n\tstrcpy(td->o.dp_scheme_file, filename);\n\n\tif (lstat(filename, &sb) < 0){\n\t\tret = errno;\n\t\tlog_err(\"fio: lstat() error related to %s\\n\", filename);\n\t\ttd_verror(td, ret, \"lstat\");\n\t\tgoto out;\n\t}\n\n\tif (!S_ISREG(sb.st_mode)) {\n\t\tret = errno;\n\t\tlog_err(\"fio: %s is not a file\\n\", filename);\n\t\ttd_verror(td, ret, \"S_ISREG\");\n\t\tgoto out;\n\t}\n\nout:\n\tfree(filename);\n\treturn ret;\n}\n\nstatic int str_bssplit_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *str, *p;\n\tint ret = 0;\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\tret = str_split_parse(td, str, bssplit_ddir, NULL, false);\n\n\tif (parse_dryrun()) {\n\t\tint i;\n\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tfree(td->o.bssplit[i]);\n\t\t\ttd->o.bssplit[i] = NULL;\n\t\t\ttd->o.bssplit_nr[i] = 0;\n\t\t}\n\t}\n\n\tfree(p);\n\treturn ret;\n}\n\nstatic int parse_cmdprio_bssplit_entry(struct thread_options *o,\n\t\t\t\t       struct split_prio *entry, char *str)\n{\n\tint matches = 0;\n\tchar *bs_str = NULL;\n\tlong long bs_val;\n\tunsigned int perc = 0, class, level, hint;\n\n\t/*\n\t * valid entry formats:\n\t * bs/ - %s/ - set perc to 0, prio to -1.\n\t * bs/perc - %s/%u - set prio to -1.\n\t * bs/perc/class/level - %s/%u/%u/%u\n\t * bs/perc/class/level/hint - %s/%u/%u/%u/%u\n\t */\n\tmatches = sscanf(str, \"%m[^/]/%u/%u/%u/%u\",\n\t\t\t &bs_str, &perc, &class, &level, &hint);\n\tif (matches < 1) {\n\t\tlog_err(\"fio: invalid cmdprio_bssplit format\\n\");\n\t\treturn 1;\n\t}\n\n\tif (str_to_decimal(bs_str, &bs_val, 1, o, 0, 0)) {\n\t\tlog_err(\"fio: split conversion failed\\n\");\n\t\tfree(bs_str);\n\t\treturn 1;\n\t}\n\tfree(bs_str);\n\n\tentry->bs = bs_val;\n\tentry->perc = min(perc, 100u);\n\tentry->prio = -1;\n\tswitch (matches) {\n\tcase 1: /* bs/ case */\n\tcase 2: /* bs/perc case */\n\t\tbreak;\n\tcase 4: /* bs/perc/class/level case */\n\tcase 5: /* bs/perc/class/level/hint case */\n\t\tclass = min(class, (unsigned int) IOPRIO_MAX_PRIO_CLASS);\n\t\tlevel = min(level, (unsigned int) IOPRIO_MAX_PRIO);\n\t\tif (matches == 5)\n\t\t\thint = min(hint, (unsigned int) IOPRIO_MAX_PRIO_HINT);\n\t\telse\n\t\t\thint = 0;\n\t\tentry->prio = ioprio_value(class, level, hint);\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: invalid cmdprio_bssplit format\\n\");\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n/*\n * Returns a negative integer if the first argument should be before the second\n * argument in the sorted list. A positive integer if the first argument should\n * be after the second argument in the sorted list. A zero if they are equal.\n */\nstatic int fio_split_prio_cmp(const void *p1, const void *p2)\n{\n\tconst struct split_prio *tmp1 = p1;\n\tconst struct split_prio *tmp2 = p2;\n\n\tif (tmp1->bs > tmp2->bs)\n\t\treturn 1;\n\tif (tmp1->bs < tmp2->bs)\n\t\treturn -1;\n\treturn 0;\n}\n\nint split_parse_prio_ddir(struct thread_options *o, struct split_prio **entries,\n\t\t\t  int *nr_entries, char *str)\n{\n\tstruct split_prio *tmp_entries;\n\tunsigned int nr_bssplits;\n\tchar *str_cpy, *p, *fname;\n\n\t/* strsep modifies the string, dup it so that we can use strsep twice */\n\tp = str_cpy = strdup(str);\n\tif (!p)\n\t\treturn 1;\n\n\tnr_bssplits = 0;\n\twhile ((fname = strsep(&str_cpy, \":\")) != NULL) {\n\t\tif (!strlen(fname))\n\t\t\tbreak;\n\t\tnr_bssplits++;\n\t}\n\tfree(p);\n\n\tif (nr_bssplits > BSSPLIT_MAX) {\n\t\tlog_err(\"fio: too many cmdprio_bssplit entries\\n\");\n\t\treturn 1;\n\t}\n\n\ttmp_entries = calloc(nr_bssplits, sizeof(*tmp_entries));\n\tif (!tmp_entries)\n\t\treturn 1;\n\n\tnr_bssplits = 0;\n\twhile ((fname = strsep(&str, \":\")) != NULL) {\n\t\tstruct split_prio *entry;\n\n\t\tif (!strlen(fname))\n\t\t\tbreak;\n\n\t\tentry = &tmp_entries[nr_bssplits];\n\n\t\tif (parse_cmdprio_bssplit_entry(o, entry, fname)) {\n\t\t\tlog_err(\"fio: failed to parse cmdprio_bssplit entry\\n\");\n\t\t\tfree(tmp_entries);\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* skip zero perc entries, they provide no useful information */\n\t\tif (entry->perc)\n\t\t\tnr_bssplits++;\n\t}\n\n\tqsort(tmp_entries, nr_bssplits, sizeof(*tmp_entries),\n\t      fio_split_prio_cmp);\n\n\t*entries = tmp_entries;\n\t*nr_entries = nr_bssplits;\n\n\treturn 0;\n}\n\nstatic int str2error(char *str)\n{\n\tconst char *err[] = { \"EPERM\", \"ENOENT\", \"ESRCH\", \"EINTR\", \"EIO\",\n\t\t\t    \"ENXIO\", \"E2BIG\", \"ENOEXEC\", \"EBADF\",\n\t\t\t    \"ECHILD\", \"EAGAIN\", \"ENOMEM\", \"EACCES\",\n\t\t\t    \"EFAULT\", \"ENOTBLK\", \"EBUSY\", \"EEXIST\",\n\t\t\t    \"EXDEV\", \"ENODEV\", \"ENOTDIR\", \"EISDIR\",\n\t\t\t    \"EINVAL\", \"ENFILE\", \"EMFILE\", \"ENOTTY\",\n\t\t\t    \"ETXTBSY\",\"EFBIG\", \"ENOSPC\", \"ESPIPE\",\n\t\t\t    \"EROFS\",\"EMLINK\", \"EPIPE\", \"EDOM\", \"ERANGE\" };\n\tint i = 0, num = sizeof(err) / sizeof(char *);\n\n\twhile (i < num) {\n\t\tif (!strcmp(err[i], str))\n\t\t\treturn i + 1;\n\t\ti++;\n\t}\n\treturn 0;\n}\n\nstatic int ignore_error_type(struct thread_data *td, enum error_type_bit etype,\n\t\t\t\tchar *str)\n{\n\tunsigned int i;\n\tint *error;\n\tchar *fname;\n\n\tif (etype >= ERROR_TYPE_CNT) {\n\t\tlog_err(\"Illegal error type\\n\");\n\t\treturn 1;\n\t}\n\n\ttd->o.ignore_error_nr[etype] = 4;\n\terror = calloc(4, sizeof(int));\n\n\ti = 0;\n\twhile ((fname = strsep(&str, \":\")) != NULL) {\n\n\t\tif (!strlen(fname))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * grow struct buffer, if needed\n\t\t */\n\t\tif (i == td->o.ignore_error_nr[etype]) {\n\t\t\ttd->o.ignore_error_nr[etype] <<= 1;\n\t\t\terror = realloc(error, td->o.ignore_error_nr[etype]\n\t\t\t\t\t\t  * sizeof(int));\n\t\t}\n\t\tif (fname[0] == 'E') {\n\t\t\terror[i] = str2error(fname);\n\t\t} else {\n\t\t\tint base = 10;\n\t\t\tif (!strncmp(fname, \"0x\", 2) ||\n\t\t\t\t\t!strncmp(fname, \"0X\", 2))\n\t\t\t\tbase = 16;\n\t\t\terror[i] = strtol(fname, NULL, base);\n\t\t\tif (error[i] < 0)\n\t\t\t\terror[i] = -error[i];\n\t\t}\n\t\tif (!error[i]) {\n\t\t\tlog_err(\"Unknown error %s, please use number value\\n\",\n\t\t\t\t  fname);\n\t\t\ttd->o.ignore_error_nr[etype] = 0;\n\t\t\tfree(error);\n\t\t\treturn 1;\n\t\t}\n\t\ti++;\n\t}\n\tif (i) {\n\t\ttd->o.continue_on_error |= 1 << etype;\n\t\ttd->o.ignore_error_nr[etype] = i;\n\t\ttd->o.ignore_error[etype] = error;\n\t} else {\n\t\ttd->o.ignore_error_nr[etype] = 0;\n\t\tfree(error);\n\t}\n\n\treturn 0;\n\n}\n\nstatic int str_replay_skip_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *str, *p, *n;\n\tint ret = 0;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\twhile (p) {\n\t\tn = strchr(p, ',');\n\t\tif (n)\n\t\t\t*n++ = '\\0';\n\t\tif (!strcmp(p, \"read\"))\n\t\t\ttd->o.replay_skip |= 1u << DDIR_READ;\n\t\telse if (!strcmp(p, \"write\"))\n\t\t\ttd->o.replay_skip |= 1u << DDIR_WRITE;\n\t\telse if (!strcmp(p, \"trim\"))\n\t\t\ttd->o.replay_skip |= 1u << DDIR_TRIM;\n\t\telse if (!strcmp(p, \"sync\"))\n\t\t\ttd->o.replay_skip |= 1u << DDIR_SYNC;\n\t\telse {\n\t\t\tlog_err(\"Unknown skip type: %s\\n\", p);\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tp = n;\n\t}\n\tfree(str);\n\treturn ret;\n}\n\nstatic int str_ignore_error_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *str, *p, *n;\n\tint ret = 1;\n\tenum error_type_bit type = 0;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\twhile (p) {\n\t\tn = strchr(p, ',');\n\t\tif (n)\n\t\t\t*n++ = '\\0';\n\t\tret = ignore_error_type(td, type, p);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tp = n;\n\t\ttype++;\n\t}\n\tfree(str);\n\treturn ret;\n}\n\nstatic int str_rw_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct thread_options *o = &td->o;\n\tchar *nr;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\to->ddir_seq_nr = 1;\n\to->ddir_seq_add = 0;\n\n\tnr = get_opt_postfix(str);\n\tif (!nr)\n\t\treturn 0;\n\n\tif (td_random(td)) {\n\t\tlong long val;\n\n\t\tif (str_to_decimal(nr, &val, 1, o, 0, 0)) {\n\t\t\tlog_err(\"fio: randrw postfix parsing failed\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\t\tif ((val <= 0) || (val > UINT_MAX)) {\n\t\t\tlog_err(\"fio: randrw postfix parsing out of range\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\t\to->ddir_seq_nr = (unsigned int) val;\n\t} else {\n\t\tlong long val;\n\n\t\tif (str_to_decimal(nr, &val, 1, o, 0, 0)) {\n\t\t\tlog_err(\"fio: rw postfix parsing failed\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\n\t\to->ddir_seq_add = val;\n\t}\n\n\tfree(nr);\n\treturn 0;\n}\n\nstatic int str_mem_cb(void *data, const char *mem)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (td->o.mem_type == MEM_MMAPHUGE || td->o.mem_type == MEM_MMAP ||\n\t    td->o.mem_type == MEM_MMAPSHARED)\n\t\ttd->o.mmapfile = get_opt_postfix(mem);\n\n\treturn 0;\n}\n\nstatic int fio_clock_source_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tfio_clock_source = td->o.clocksource;\n\tfio_clock_source_set = 1;\n\tfio_clock_init();\n\treturn 0;\n}\n\nstatic int str_rwmix_read_cb(void *data, long long *val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\ttd->o.rwmix[DDIR_READ] = *val;\n\ttd->o.rwmix[DDIR_WRITE] = 100 - *val;\n\treturn 0;\n}\n\nstatic int str_rwmix_write_cb(void *data, long long *val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\ttd->o.rwmix[DDIR_WRITE] = *val;\n\ttd->o.rwmix[DDIR_READ] = 100 - *val;\n\treturn 0;\n}\n\nstatic int str_exitall_cb(void)\n{\n\texitall_on_terminate = true;\n\treturn 0;\n}\n\n#ifdef FIO_HAVE_CPU_AFFINITY\nint fio_cpus_split(os_cpu_mask_t *mask, unsigned int cpu_index)\n{\n\tunsigned int i, index, cpus_in_mask;\n\tconst long max_cpu = cpus_configured();\n\n\tcpus_in_mask = fio_cpu_count(mask);\n\tif (!cpus_in_mask)\n\t\treturn 0;\n\n\tcpu_index = cpu_index % cpus_in_mask;\n\n\tindex = 0;\n\tfor (i = 0; i < max_cpu; i++) {\n\t\tif (!fio_cpu_isset(mask, i))\n\t\t\tcontinue;\n\n\t\tif (cpu_index != index)\n\t\t\tfio_cpu_clear(mask, i);\n\n\t\tindex++;\n\t}\n\n\treturn fio_cpu_count(mask);\n}\n\nstatic int str_cpumask_cb(void *data, unsigned long long *val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned int i;\n\tlong max_cpu;\n\tint ret;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tret = fio_cpuset_init(&td->o.cpumask);\n\tif (ret < 0) {\n\t\tlog_err(\"fio: cpuset_init failed\\n\");\n\t\ttd_verror(td, ret, \"fio_cpuset_init\");\n\t\treturn 1;\n\t}\n\n\tmax_cpu = cpus_configured();\n\n\tfor (i = 0; i < sizeof(int) * 8; i++) {\n\t\tif ((1 << i) & *val) {\n\t\t\tif (i >= max_cpu) {\n\t\t\t\tlog_err(\"fio: CPU %d too large (max=%ld)\\n\", i,\n\t\t\t\t\t\t\t\tmax_cpu - 1);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tdprint(FD_PARSE, \"set cpu allowed %d\\n\", i);\n\t\t\tfio_cpu_set(&td->o.cpumask, i);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int set_cpus_allowed(struct thread_data *td, os_cpu_mask_t *mask,\n\t\t\t    const char *input)\n{\n\tchar *cpu, *str, *p;\n\tlong max_cpu;\n\tint ret = 0;\n\n\tret = fio_cpuset_init(mask);\n\tif (ret < 0) {\n\t\tlog_err(\"fio: cpuset_init failed\\n\");\n\t\ttd_verror(td, ret, \"fio_cpuset_init\");\n\t\treturn 1;\n\t}\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\tmax_cpu = cpus_configured();\n\n\twhile ((cpu = strsep(&str, \",\")) != NULL) {\n\t\tchar *str2, *cpu2;\n\t\tint icpu, icpu2;\n\n\t\tif (!strlen(cpu))\n\t\t\tbreak;\n\n\t\tstr2 = cpu;\n\t\ticpu2 = -1;\n\t\twhile ((cpu2 = strsep(&str2, \"-\")) != NULL) {\n\t\t\tif (!strlen(cpu2))\n\t\t\t\tbreak;\n\n\t\t\ticpu2 = atoi(cpu2);\n\t\t}\n\n\t\ticpu = atoi(cpu);\n\t\tif (icpu2 == -1)\n\t\t\ticpu2 = icpu;\n\t\twhile (icpu <= icpu2) {\n\t\t\tif (icpu >= FIO_MAX_CPUS) {\n\t\t\t\tlog_err(\"fio: your OS only supports up to\"\n\t\t\t\t\t\" %d CPUs\\n\", (int) FIO_MAX_CPUS);\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (icpu >= max_cpu) {\n\t\t\t\tlog_err(\"fio: CPU %d too large (max=%ld)\\n\",\n\t\t\t\t\t\t\ticpu, max_cpu - 1);\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdprint(FD_PARSE, \"set cpu allowed %d\\n\", icpu);\n\t\t\tfio_cpu_set(mask, icpu);\n\t\t\ticpu++;\n\t\t}\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tfree(p);\n\treturn ret;\n}\n\nstatic int str_cpus_allowed_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\treturn set_cpus_allowed(td, &td->o.cpumask, input);\n}\n\nstatic int str_verify_cpus_allowed_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\treturn set_cpus_allowed(td, &td->o.verify_cpumask, input);\n}\n\n#ifdef CONFIG_ZLIB\nstatic int str_log_cpus_allowed_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\treturn set_cpus_allowed(td, &td->o.log_gz_cpumask, input);\n}\n#endif /* CONFIG_ZLIB */\n\n#endif /* FIO_HAVE_CPU_AFFINITY */\n\n#ifdef CONFIG_LIBNUMA\nstatic int str_numa_cpunodes_cb(void *data, char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct bitmask *verify_bitmask;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\t/* numa_parse_nodestring() parses a character string list\n\t * of nodes into a bit mask. The bit mask is allocated by\n\t * numa_allocate_nodemask(), so it should be freed by\n\t * numa_free_nodemask().\n\t */\n\tverify_bitmask = numa_parse_nodestring(input);\n\tif (verify_bitmask == NULL) {\n\t\tlog_err(\"fio: numa_parse_nodestring failed\\n\");\n\t\ttd_verror(td, 1, \"str_numa_cpunodes_cb\");\n\t\treturn 1;\n\t}\n\tnuma_free_nodemask(verify_bitmask);\n\n\ttd->o.numa_cpunodes = strdup(input);\n\treturn 0;\n}\n\nstatic int str_numa_mpol_cb(void *data, char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tconst char * const policy_types[] =\n\t\t{ \"default\", \"prefer\", \"bind\", \"interleave\", \"local\", NULL };\n\tint i;\n\tchar *nodelist;\n\tstruct bitmask *verify_bitmask;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tnodelist = strchr(input, ':');\n\tif (nodelist) {\n\t\t/* NUL-terminate mode */\n\t\t*nodelist++ = '\\0';\n\t}\n\n\tfor (i = 0; i <= MPOL_LOCAL; i++) {\n\t\tif (!strcmp(input, policy_types[i])) {\n\t\t\ttd->o.numa_mem_mode = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (i > MPOL_LOCAL) {\n\t\tlog_err(\"fio: memory policy should be: default, prefer, bind, interleave, local\\n\");\n\t\tgoto out;\n\t}\n\n\tswitch (td->o.numa_mem_mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest) {\n\t\t\t\tlog_err(\"fio: one node only for \\'prefer\\'\\n\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tlog_err(\"fio: one node is needed for \\'prefer\\'\\n\");\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodelist = strdup(\"all\");\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Don't allow a nodelist\n\t\t */\n\t\tif (nodelist) {\n\t\t\tlog_err(\"fio: NO nodelist for \\'local\\'\\n\");\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist) {\n\t\t\tlog_err(\"fio: a nodelist is needed for \\'bind\\'\\n\");\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\t}\n\n\n\t/* numa_parse_nodestring() parses a character string list\n\t * of nodes into a bit mask. The bit mask is allocated by\n\t * numa_allocate_nodemask(), so it should be freed by\n\t * numa_free_nodemask().\n\t */\n\tswitch (td->o.numa_mem_mode) {\n\tcase MPOL_PREFERRED:\n\t\ttd->o.numa_mem_prefer_node = atoi(nodelist);\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\tcase MPOL_BIND:\n\t\tverify_bitmask = numa_parse_nodestring(nodelist);\n\t\tif (verify_bitmask == NULL) {\n\t\t\tlog_err(\"fio: numa_parse_nodestring failed\\n\");\n\t\t\ttd_verror(td, 1, \"str_numa_memnodes_cb\");\n\t\t\treturn 1;\n\t\t}\n\t\ttd->o.numa_memnodes = strdup(nodelist);\n\t\tnuma_free_nodemask(verify_bitmask);\n\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\tcase MPOL_DEFAULT:\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\nout:\n\treturn 1;\n}\n#endif\n\nstatic int str_fst_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tdouble val;\n\tdouble center = -1;\n\tbool done = false;\n\tchar *nr;\n\n\ttd->file_service_nr = 1;\n\n\tswitch (td->o.file_service_type) {\n\tcase FIO_FSERVICE_RANDOM:\n\tcase FIO_FSERVICE_RR:\n\tcase FIO_FSERVICE_SEQ:\n\t\tnr = get_opt_postfix(str);\n\t\tif (nr) {\n\t\t\ttd->file_service_nr = atoi(nr);\n\t\t\tfree(nr);\n\t\t}\n\t\tdone = true;\n\t\tbreak;\n\tcase FIO_FSERVICE_ZIPF:\n\t\tval = FIO_DEF_ZIPF;\n\t\tbreak;\n\tcase FIO_FSERVICE_PARETO:\n\t\tval = FIO_DEF_PARETO;\n\t\tbreak;\n\tcase FIO_FSERVICE_GAUSS:\n\t\tval = 0.0;\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: bad file service type: %d\\n\", td->o.file_service_type);\n\t\treturn 1;\n\t}\n\n\tif (done)\n\t\treturn 0;\n\n\tnr = get_opt_postfix(str);\n\tif (nr && !split_parse_distr(nr, &val, &center)) {\n\t\tlog_err(\"fio: file service type random postfix parsing failed\\n\");\n\t\tfree(nr);\n\t\treturn 1;\n\t}\n\n\tfree(nr);\n\n\tif (center != -1 && (center < 0.00 || center > 1.00)) {\n\t\tlog_err(\"fio: distribution center out of range (0 <= center <= 1.0)\\n\");\n\t\treturn 1;\n\t}\n\ttd->random_center = center;\n\n\tswitch (td->o.file_service_type) {\n\tcase FIO_FSERVICE_ZIPF:\n\t\tif (val == 1.00) {\n\t\t\tlog_err(\"fio: zipf theta must be different than 1.0\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->zipf_theta = val;\n\t\tbreak;\n\tcase FIO_FSERVICE_PARETO:\n\t\tif (val <= 0.00 || val >= 1.00) {\n                          log_err(\"fio: pareto input out of range (0 < input < 1.0)\\n\");\n                          return 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->pareto_h = val;\n\t\tbreak;\n\tcase FIO_FSERVICE_GAUSS:\n\t\tif (val < 0.00 || val >= 100.00) {\n                          log_err(\"fio: normal deviation out of range (0 <= input < 100.0)\\n\");\n                          return 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->gauss_dev = val;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_SYNC_FILE_RANGE\nstatic int str_sfr_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *nr = get_opt_postfix(str);\n\n\ttd->sync_file_range_nr = 1;\n\tif (nr) {\n\t\ttd->sync_file_range_nr = atoi(nr);\n\t\tfree(nr);\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic int zone_split_ddir(struct thread_options *o, void *eo,\n\t\t\t   enum fio_ddir ddir, char *str, bool absolute)\n{\n\tunsigned int i, perc, perc_missing, sperc, sperc_missing;\n\tstruct split split;\n\n\tmemset(&split, 0, sizeof(split));\n\n\tif (split_parse_ddir(o, &split, str, absolute, ZONESPLIT_MAX))\n\t\treturn 1;\n\tif (!split.nr)\n\t\treturn 0;\n\n\to->zone_split[ddir] = malloc(split.nr * sizeof(struct zone_split));\n\to->zone_split_nr[ddir] = split.nr;\n\tfor (i = 0; i < split.nr; i++) {\n\t\to->zone_split[ddir][i].access_perc = split.val1[i];\n\t\tif (absolute)\n\t\t\to->zone_split[ddir][i].size = split.val2[i];\n\t\telse\n\t\t\to->zone_split[ddir][i].size_perc = split.val2[i];\n\t}\n\n\t/*\n\t * Now check if the percentages add up, and how much is missing\n\t */\n\tperc = perc_missing = 0;\n\tsperc = sperc_missing = 0;\n\tfor (i = 0; i < o->zone_split_nr[ddir]; i++) {\n\t\tstruct zone_split *zsp = &o->zone_split[ddir][i];\n\n\t\tif (zsp->access_perc == (uint8_t) -1U)\n\t\t\tperc_missing++;\n\t\telse\n\t\t\tperc += zsp->access_perc;\n\n\t\tif (!absolute) {\n\t\t\tif (zsp->size_perc == (uint8_t) -1U)\n\t\t\t\tsperc_missing++;\n\t\t\telse\n\t\t\t\tsperc += zsp->size_perc;\n\t\t}\n\t}\n\n\tif (perc > 100 || sperc > 100) {\n\t\tlog_err(\"fio: zone_split percentages add to more than 100%%\\n\");\n\t\tfree(o->zone_split[ddir]);\n\t\to->zone_split[ddir] = NULL;\n\t\treturn 1;\n\t}\n\tif (perc < 100) {\n\t\tlog_err(\"fio: access percentage don't add up to 100 for zoned \"\n\t\t\t\"random distribution (got=%u)\\n\", perc);\n\t\tfree(o->zone_split[ddir]);\n\t\to->zone_split[ddir] = NULL;\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If values didn't have a percentage set, divide the remains between\n\t * them.\n\t */\n\tif (perc_missing) {\n\t\tif (perc_missing == 1 && o->zone_split_nr[ddir] == 1)\n\t\t\tperc = 100;\n\t\tfor (i = 0; i < o->zone_split_nr[ddir]; i++) {\n\t\t\tstruct zone_split *zsp = &o->zone_split[ddir][i];\n\n\t\t\tif (zsp->access_perc == (uint8_t) -1U)\n\t\t\t\tzsp->access_perc = (100 - perc) / perc_missing;\n\t\t}\n\t}\n\tif (sperc_missing) {\n\t\tif (sperc_missing == 1 && o->zone_split_nr[ddir] == 1)\n\t\t\tsperc = 100;\n\t\tfor (i = 0; i < o->zone_split_nr[ddir]; i++) {\n\t\t\tstruct zone_split *zsp = &o->zone_split[ddir][i];\n\n\t\t\tif (zsp->size_perc == (uint8_t) -1U)\n\t\t\t\tzsp->size_perc = (100 - sperc) / sperc_missing;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int parse_zoned_distribution(struct thread_data *td, const char *input,\n\t\t\t\t    bool absolute)\n{\n\tconst char *pre = absolute ? \"zoned_abs:\" : \"zoned:\";\n\tchar *str, *p;\n\tint i, ret = 0;\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\t/* We expect it to start like that, bail if not */\n\tif (strncmp(str, pre, strlen(pre))) {\n\t\tlog_err(\"fio: mismatch in zoned input <%s>\\n\", str);\n\t\tfree(p);\n\t\treturn 1;\n\t}\n\tstr += strlen(pre);\n\n\tret = str_split_parse(td, str, zone_split_ddir, NULL, absolute);\n\n\tfree(p);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tint j;\n\n\t\tdprint(FD_PARSE, \"zone ddir %d (nr=%u): \\n\", i, td->o.zone_split_nr[i]);\n\n\t\tfor (j = 0; j < td->o.zone_split_nr[i]; j++) {\n\t\t\tstruct zone_split *zsp = &td->o.zone_split[i][j];\n\n\t\t\tif (absolute) {\n\t\t\t\tdprint(FD_PARSE, \"\\t%d: %u/%llu\\n\", j,\n\t\t\t\t\t\tzsp->access_perc,\n\t\t\t\t\t\t(unsigned long long) zsp->size);\n\t\t\t} else {\n\t\t\t\tdprint(FD_PARSE, \"\\t%d: %u/%u\\n\", j,\n\t\t\t\t\t\tzsp->access_perc,\n\t\t\t\t\t\tzsp->size_perc);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (parse_dryrun()) {\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tfree(td->o.zone_split[i]);\n\t\t\ttd->o.zone_split[i] = NULL;\n\t\t\ttd->o.zone_split_nr[i] = 0;\n\t\t}\n\n\t\treturn ret;\n\t}\n\n\tif (ret) {\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\t\ttd->o.zone_split_nr[i] = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int str_random_distribution_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tdouble val;\n\tdouble center = -1;\n\tchar *nr;\n\n\tif (td->o.random_distribution == FIO_RAND_DIST_ZIPF)\n\t\tval = FIO_DEF_ZIPF;\n\telse if (td->o.random_distribution == FIO_RAND_DIST_PARETO)\n\t\tval = FIO_DEF_PARETO;\n\telse if (td->o.random_distribution == FIO_RAND_DIST_GAUSS)\n\t\tval = 0.0;\n\telse if (td->o.random_distribution == FIO_RAND_DIST_ZONED)\n\t\treturn parse_zoned_distribution(td, str, false);\n\telse if (td->o.random_distribution == FIO_RAND_DIST_ZONED_ABS)\n\t\treturn parse_zoned_distribution(td, str, true);\n\telse\n\t\treturn 0;\n\n\tnr = get_opt_postfix(str);\n\tif (nr && !split_parse_distr(nr, &val, &center)) {\n\t\tlog_err(\"fio: random postfix parsing failed\\n\");\n\t\tfree(nr);\n\t\treturn 1;\n\t}\n\n\tfree(nr);\n\n\tif (center != -1 && (center < 0.00 || center > 1.00)) {\n\t\tlog_err(\"fio: distribution center out of range (0 <= center <= 1.0)\\n\");\n\t\treturn 1;\n\t}\n\ttd->o.random_center.u.f = center;\n\n\tif (td->o.random_distribution == FIO_RAND_DIST_ZIPF) {\n\t\tif (val == 1.00) {\n\t\t\tlog_err(\"fio: zipf theta must different than 1.0\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->o.zipf_theta.u.f = val;\n\t} else if (td->o.random_distribution == FIO_RAND_DIST_PARETO) {\n\t\tif (val <= 0.00 || val >= 1.00) {\n\t\t\tlog_err(\"fio: pareto input out of range (0 < input < 1.0)\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->o.pareto_h.u.f = val;\n\t} else {\n\t\tif (val < 0.00 || val >= 100.0) {\n\t\t\tlog_err(\"fio: normal deviation out of range (0 <= input < 100.0)\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\t\ttd->o.gauss_dev.u.f = val;\n\t}\n\n\treturn 0;\n}\n\nstatic int str_steadystate_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tdouble val;\n\tchar *nr;\n\tchar *pct;\n\tlong long ll;\n\n\tif (td->o.ss_state != FIO_SS_IOPS && td->o.ss_state != FIO_SS_IOPS_SLOPE &&\n\t    td->o.ss_state != FIO_SS_BW && td->o.ss_state != FIO_SS_BW_SLOPE) {\n\t\t/* should be impossible to get here */\n\t\tlog_err(\"fio: unknown steady state criterion\\n\");\n\t\treturn 1;\n\t}\n\n\tnr = get_opt_postfix(str);\n\tif (!nr) {\n\t\tlog_err(\"fio: steadystate threshold must be specified in addition to criterion\\n\");\n\t\tfree(nr);\n\t\treturn 1;\n\t}\n\n\t/* ENHANCEMENT Allow fio to understand size=10.2% and use here */\n\tpct = strstr(nr, \"%\");\n\tif (pct) {\n\t\t*pct = '\\0';\n\t\tstrip_blank_end(nr);\n\t\tif (!str_to_float(nr, &val, 0))\t{\n\t\t\tlog_err(\"fio: could not parse steadystate threshold percentage\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdprint(FD_PARSE, \"set steady state threshold to %f%%\\n\", val);\n\t\tfree(nr);\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\n\t\ttd->o.ss_state |= FIO_SS_PCT;\n\t\ttd->o.ss_limit.u.f = val;\n\t} else if (td->o.ss_state & FIO_SS_IOPS) {\n\t\tif (!str_to_float(nr, &val, 0)) {\n\t\t\tlog_err(\"fio: steadystate IOPS threshold postfix parsing failed\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdprint(FD_PARSE, \"set steady state IOPS threshold to %f\\n\", val);\n\t\tfree(nr);\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\n\t\ttd->o.ss_limit.u.f = val;\n\t} else {\t/* bandwidth criterion */\n\t\tif (str_to_decimal(nr, &ll, 1, td, 0, 0)) {\n\t\t\tlog_err(\"fio: steadystate BW threshold postfix parsing failed\\n\");\n\t\t\tfree(nr);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdprint(FD_PARSE, \"set steady state BW threshold to %lld\\n\", ll);\n\t\tfree(nr);\n\t\tif (parse_dryrun())\n\t\t\treturn 0;\n\n\t\ttd->o.ss_limit.u.f = (double) ll;\n\t}\n\n\ttd->ss.state = td->o.ss_state;\n\treturn 0;\n}\n\n/*\n * Return next name in the string. Files are separated with ':'. If the ':'\n * is escaped with a '\\', then that ':' is part of the filename and does not\n * indicate a new file.\n */\nchar *get_next_str(char **ptr)\n{\n\tchar *str = *ptr;\n\tchar *p, *start;\n\n\tif (!str || !strlen(str))\n\t\treturn NULL;\n\n\tstart = str;\n\tdo {\n\t\t/*\n\t\t * No colon, we are done\n\t\t */\n\t\tp = strchr(str, ':');\n\t\tif (!p) {\n\t\t\t*ptr = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * We got a colon, but it's the first character. Skip and\n\t\t * continue\n\t\t */\n\t\tif (p == start) {\n\t\t\tstr = ++start;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (*(p - 1) != '\\\\') {\n\t\t\t*p = '\\0';\n\t\t\t*ptr = p + 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tmemmove(p - 1, p, strlen(p) + 1);\n\t\tstr = p;\n\t} while (1);\n\n\treturn start;\n}\n\n\nint get_max_str_idx(char *input)\n{\n\tunsigned int cur_idx;\n\tchar *str, *p;\n\n\tp = str = strdup(input);\n\tfor (cur_idx = 0; ; cur_idx++)\n\t\tif (get_next_str(&str) == NULL)\n\t\t\tbreak;\n\n\tfree(p);\n\treturn cur_idx;\n}\n\n/*\n * Returns the directory at the index, indexes > entries will be\n * assigned via modulo division of the index\n */\nint set_name_idx(char *target, size_t tlen, char *input, int index,\n\t\t bool unique_filename)\n{\n\tunsigned int cur_idx;\n\tint len;\n\tchar *fname, *str, *p;\n\n\tp = str = strdup(input);\n\n\tindex %= get_max_str_idx(input);\n\tfor (cur_idx = 0; cur_idx <= index; cur_idx++)\n\t\tfname = get_next_str(&str);\n\n\tif (client_sockaddr_str[0] && unique_filename) {\n\t\tlen = snprintf(target, tlen, \"%s/%s.\", fname,\n\t\t\t\tclient_sockaddr_str);\n\t} else\n\t\tlen = snprintf(target, tlen, \"%s%c\", fname,\n\t\t\t\tFIO_OS_PATH_SEPARATOR);\n\n\ttarget[tlen - 1] = '\\0';\n\tfree(p);\n\n\treturn len;\n}\n\nchar* get_name_by_idx(char *input, int index)\n{\n\tunsigned int cur_idx;\n\tchar *fname, *str, *p;\n\n\tp = str = strdup(input);\n\n\tindex %= get_max_str_idx(input);\n\tfor (cur_idx = 0; cur_idx <= index; cur_idx++)\n\t\tfname = get_next_str(&str);\n\n\tfname = strdup(fname);\n\tfree(p);\n\n\treturn fname;\n}\n\nstatic int str_filename_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tchar *fname, *str, *p;\n\n\tp = str = strdup(input);\n\n\tstrip_blank_front(&str);\n\tstrip_blank_end(str);\n\n\t/*\n\t * Ignore what we may already have from nrfiles option.\n\t */\n\tif (!td->files_index)\n\t\ttd->o.nr_files = 0;\n\n\twhile ((fname = get_next_str(&str)) != NULL) {\n\t\tif (!strlen(fname))\n\t\t\tbreak;\n\t\tadd_file(td, fname, 0, 1);\n\t}\n\n\tfree(p);\n\treturn 0;\n}\n\nstatic int str_directory_cb(void *data, const char fio_unused *unused)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct stat sb;\n\tchar *dirname, *str, *p;\n\tint ret = 0;\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tp = str = strdup(td->o.directory);\n\twhile ((dirname = get_next_str(&str)) != NULL) {\n\t\tif (lstat(dirname, &sb) < 0) {\n\t\t\tret = errno;\n\n\t\t\tlog_err(\"fio: %s is not a directory\\n\", dirname);\n\t\t\ttd_verror(td, ret, \"lstat\");\n\t\t\tgoto out;\n\t\t}\n\t\tif (!S_ISDIR(sb.st_mode)) {\n\t\t\tlog_err(\"fio: %s is not a directory\\n\", dirname);\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tfree(p);\n\treturn ret;\n}\n\nstatic int str_opendir_cb(void *data, const char fio_unused *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (parse_dryrun())\n\t\treturn 0;\n\n\tif (!td->files_index)\n\t\ttd->o.nr_files = 0;\n\n\treturn add_dir_files(td, td->o.opendir);\n}\n\nstatic int str_buffer_pattern_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tint ret;\n\n\t/* FIXME: for now buffer pattern does not support formats */\n\tret = parse_and_fill_pattern_alloc(input, strlen(input),\n\t\t\t\t&td->o.buffer_pattern, NULL, NULL, NULL);\n\tif (ret < 0)\n\t\treturn 1;\n\n\tassert(ret != 0);\n\ttd->o.buffer_pattern_bytes = ret;\n\n\t/*\n\t * If this job is doing any reading or has compression set,\n\t * ensure that we refill buffers for writes or we could be\n\t * invalidating the pattern through reads.\n\t */\n\tif (!td->o.compress_percentage && !td_read(td))\n\t\ttd->o.refill_buffers = 0;\n\telse\n\t\ttd->o.refill_buffers = 1;\n\n\ttd->o.scramble_buffers = 0;\n\ttd->o.zero_buffers = 0;\n\n\treturn 0;\n}\n\nstatic int str_buffer_compress_cb(void *data, unsigned long long *il)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\ttd->flags |= TD_F_COMPRESS;\n\ttd->o.compress_percentage = *il;\n\treturn 0;\n}\n\nstatic int str_dedupe_cb(void *data, unsigned long long *il)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\ttd->flags |= TD_F_COMPRESS;\n\ttd->o.dedupe_percentage = *il;\n\ttd->o.refill_buffers = 1;\n\treturn 0;\n}\n\nstatic int str_verify_pattern_cb(void *data, const char *input)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tint ret;\n\n\ttd->o.verify_fmt_sz = FIO_ARRAY_SIZE(td->o.verify_fmt);\n\tret = parse_and_fill_pattern_alloc(input, strlen(input),\n\t\t\t&td->o.verify_pattern, fmt_desc, td->o.verify_fmt,\n\t\t\t&td->o.verify_fmt_sz);\n\tif (ret < 0)\n\t\treturn 1;\n\n\tassert(ret != 0);\n\ttd->o.verify_pattern_bytes = ret;\n\t/*\n\t * VERIFY_* could already be set\n\t */\n\tif (!fio_option_is_set(&td->o, verify))\n\t\ttd->o.verify = VERIFY_PATTERN;\n\n\treturn 0;\n}\n\nstatic int str_gtod_reduce_cb(void *data, int *il)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tint val = *il;\n\n\t/*\n\t * Only modify options if gtod_reduce==1\n\t * Otherwise leave settings alone.\n\t */\n\tif (val) {\n\t\ttd->o.disable_lat = 1;\n\t\ttd->o.disable_clat = 1;\n\t\ttd->o.disable_slat = 1;\n\t\ttd->o.disable_bw = 1;\n\t\ttd->o.clat_percentiles = 0;\n\t\ttd->o.lat_percentiles = 0;\n\t\ttd->o.slat_percentiles = 0;\n\t\ttd->ts_cache_mask = 63;\n\t}\n\n\treturn 0;\n}\n\nstatic int str_offset_cb(void *data, long long *__val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned long long v = *__val;\n\n\tif (parse_is_percent(v)) {\n\t\ttd->o.start_offset = 0;\n\t\ttd->o.start_offset_percent = -1ULL - v;\n\t\ttd->o.start_offset_nz = 0;\n\t\tdprint(FD_PARSE, \"SET start_offset_percent %d\\n\",\n\t\t\t\t\ttd->o.start_offset_percent);\n\t} else if (parse_is_zone(v)) {\n\t\ttd->o.start_offset = 0;\n\t\ttd->o.start_offset_percent = 0;\n\t\ttd->o.start_offset_nz = v - ZONE_BASE_VAL;\n\t} else\n\t\ttd->o.start_offset = v;\n\n\treturn 0;\n}\n\nstatic int str_offset_increment_cb(void *data, long long *__val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned long long v = *__val;\n\n\tif (parse_is_percent(v)) {\n\t\ttd->o.offset_increment = 0;\n\t\ttd->o.offset_increment_percent = -1ULL - v;\n\t\ttd->o.offset_increment_nz = 0;\n\t\tdprint(FD_PARSE, \"SET offset_increment_percent %d\\n\",\n\t\t\t\t\ttd->o.offset_increment_percent);\n\t} else if (parse_is_zone(v)) {\n\t\ttd->o.offset_increment = 0;\n\t\ttd->o.offset_increment_percent = 0;\n\t\ttd->o.offset_increment_nz = v - ZONE_BASE_VAL;\n\t} else\n\t\ttd->o.offset_increment = v;\n\n\treturn 0;\n}\n\nstatic int str_size_cb(void *data, long long *__val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned long long v = *__val;\n\n\tif (parse_is_percent(v)) {\n\t\ttd->o.size = 0;\n\t\ttd->o.size_percent = -1ULL - v;\n\t\tdprint(FD_PARSE, \"SET size_percent %d\\n\",\n\t\t\t\t\ttd->o.size_percent);\n\t} else if (parse_is_zone(v)) {\n\t\ttd->o.size = 0;\n\t\ttd->o.size_percent = 0;\n\t\ttd->o.size_nz = v - ZONE_BASE_VAL;\n\t} else\n\t\ttd->o.size = v;\n\n\treturn 0;\n}\n\nstatic int str_io_size_cb(void *data, unsigned long long *__val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned long long v = *__val;\n\n\tif (parse_is_percent_uncapped(v)) {\n\t\ttd->o.io_size = 0;\n\t\ttd->o.io_size_percent = -1ULL - v;\n\t\tif (td->o.io_size_percent > 100) {\n\t\t\tlog_err(\"fio: io_size values greater than 100%% aren't supported\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tdprint(FD_PARSE, \"SET io_size_percent %d\\n\",\n\t\t\t\t\ttd->o.io_size_percent);\n\t} else if (parse_is_zone(v)) {\n\t\ttd->o.io_size = 0;\n\t\ttd->o.io_size_percent = 0;\n\t\ttd->o.io_size_nz = v - ZONE_BASE_VAL;\n\t} else\n\t\ttd->o.io_size = v;\n\n\treturn 0;\n}\n\nstatic int str_zoneskip_cb(void *data, long long *__val)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tunsigned long long v = *__val;\n\n\tif (parse_is_zone(v)) {\n\t\ttd->o.zone_skip = 0;\n\t\ttd->o.zone_skip_nz = v - ZONE_BASE_VAL;\n\t} else\n\t\ttd->o.zone_skip = v;\n\n\treturn 0;\n}\n\nstatic int str_write_bw_log_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (str)\n\t\ttd->o.bw_log_file = strdup(str);\n\n\ttd->o.write_bw_log = 1;\n\treturn 0;\n}\n\nstatic int str_write_lat_log_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (str)\n\t\ttd->o.lat_log_file = strdup(str);\n\n\ttd->o.write_lat_log = 1;\n\treturn 0;\n}\n\nstatic int str_write_iops_log_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (str)\n\t\ttd->o.iops_log_file = strdup(str);\n\n\ttd->o.write_iops_log = 1;\n\treturn 0;\n}\n\nstatic int str_write_hist_log_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (str)\n\t\ttd->o.hist_log_file = strdup(str);\n\n\ttd->o.write_hist_log = 1;\n\treturn 0;\n}\n\n/*\n * str is supposed to be a substring of the strdup'd original string,\n * and is valid only if it's a regular file path.\n * This function keeps the pointer to the path as needed later.\n *\n * \"external:/path/to/so\\0\" <- original pointer updated with strdup'd\n * \"external\\0\"             <- above pointer after parsed, i.e. ->ioengine\n *          \"/path/to/so\\0\" <- str argument, i.e. ->ioengine_so_path\n */\nstatic int str_ioengine_external_cb(void *data, const char *str)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct stat sb;\n\tchar *p;\n\n\tif (!str) {\n\t\tlog_err(\"fio: null external ioengine path\\n\");\n\t\treturn 1;\n\t}\n\n\tp = (char *)str; /* str is mutable */\n\tstrip_blank_front(&p);\n\tstrip_blank_end(p);\n\n\tif (stat(p, &sb) || !S_ISREG(sb.st_mode)) {\n\t\tlog_err(\"fio: invalid external ioengine path \\\"%s\\\"\\n\", p);\n\t\treturn 1;\n\t}\n\n\ttd->o.ioengine_so_path = p;\n\treturn 0;\n}\n\nstatic int rw_verify(const struct fio_option *o, void *data)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (read_only && (td_write(td) || td_trim(td))) {\n\t\tlog_err(\"fio: job <%s> has write or trim bit set, but\"\n\t\t\t\" fio is in read-only mode\\n\", td->o.name);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic int gtod_cpu_verify(const struct fio_option *o, void *data)\n{\n#ifndef FIO_HAVE_CPU_AFFINITY\n\tstruct thread_data *td = cb_data_to_td(data);\n\n\tif (td->o.gtod_cpu) {\n\t\tlog_err(\"fio: platform must support CPU affinity for\"\n\t\t\t\"gettimeofday() offloading\\n\");\n\t\treturn 1;\n\t}\n#endif\n\n\treturn 0;\n}\n\n/*\n * Map of job/command line options\n */\nstruct fio_option fio_options[FIO_MAX_OPTS] = {\n\t{\n\t\t.name\t= \"description\",\n\t\t.lname\t= \"Description of job\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, description),\n\t\t.help\t= \"Text job description\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_DESC,\n\t},\n\t{\n\t\t.name\t= \"name\",\n\t\t.lname\t= \"Job name\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, name),\n\t\t.help\t= \"Name of this job\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_DESC,\n\t},\n\t{\n\t\t.name\t= \"wait_for\",\n\t\t.lname\t= \"Waitee name\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, wait_for),\n\t\t.help\t= \"Name of the job this one wants to wait for before starting\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_DESC,\n\t},\n\t{\n\t\t.name\t= \"filename\",\n\t\t.lname\t= \"Filename(s)\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, filename),\n\t\t.maxlen\t= PATH_MAX,\n\t\t.cb\t= str_filename_cb,\n\t\t.prio\t= -1, /* must come after \"directory\" */\n\t\t.help\t= \"File(s) to use for the workload\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"directory\",\n\t\t.lname\t= \"Directory\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, directory),\n\t\t.cb\t= str_directory_cb,\n\t\t.help\t= \"Directory to store files in\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"filename_format\",\n\t\t.lname\t= \"Filename Format\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, filename_format),\n\t\t.prio\t= -1, /* must come after \"directory\" */\n\t\t.help\t= \"Override default $jobname.$jobnum.$filenum naming\",\n\t\t.def\t= \"$jobname.$jobnum.$filenum\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"unique_filename\",\n\t\t.lname\t= \"Unique Filename\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, unique_filename),\n\t\t.help\t= \"For network clients, prefix file with source IP\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"lockfile\",\n\t\t.lname\t= \"Lockfile\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, file_lock_mode),\n\t\t.help\t= \"Lock file when doing IO to it\",\n\t\t.prio\t= 1,\n\t\t.parent\t= \"filename\",\n\t\t.hide\t= 0,\n\t\t.def\t= \"none\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t\t.posval = {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = FILE_LOCK_NONE,\n\t\t\t    .help = \"No file locking\",\n\t\t\t  },\n\t\t\t  { .ival = \"exclusive\",\n\t\t\t    .oval = FILE_LOCK_EXCLUSIVE,\n\t\t\t    .help = \"Exclusive file lock\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"readwrite\",\n\t\t\t    .oval = FILE_LOCK_READWRITE,\n\t\t\t    .help = \"Read vs write lock\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"opendir\",\n\t\t.lname\t= \"Open directory\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, opendir),\n\t\t.cb\t= str_opendir_cb,\n\t\t.help\t= \"Recursively add files from this directory and down\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"rw\",\n\t\t.lname\t= \"Read/write\",\n\t\t.alias\t= \"readwrite\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_rw_cb,\n\t\t.off1\t= offsetof(struct thread_options, td_ddir),\n\t\t.help\t= \"IO direction\",\n\t\t.def\t= \"read\",\n\t\t.verify\t= rw_verify,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t\t.posval = {\n\t\t\t  { .ival = \"read\",\n\t\t\t    .oval = TD_DDIR_READ,\n\t\t\t    .help = \"Sequential read\",\n\t\t\t  },\n\t\t\t  { .ival = \"write\",\n\t\t\t    .oval = TD_DDIR_WRITE,\n\t\t\t    .help = \"Sequential write\",\n\t\t\t  },\n\t\t\t  { .ival = \"trim\",\n\t\t\t    .oval = TD_DDIR_TRIM,\n\t\t\t    .help = \"Sequential trim\",\n\t\t\t  },\n\t\t\t  { .ival = \"randread\",\n\t\t\t    .oval = TD_DDIR_RANDREAD,\n\t\t\t    .help = \"Random read\",\n\t\t\t  },\n\t\t\t  { .ival = \"randwrite\",\n\t\t\t    .oval = TD_DDIR_RANDWRITE,\n\t\t\t    .help = \"Random write\",\n\t\t\t  },\n\t\t\t  { .ival = \"randtrim\",\n\t\t\t    .oval = TD_DDIR_RANDTRIM,\n\t\t\t    .help = \"Random trim\",\n\t\t\t  },\n\t\t\t  { .ival = \"rw\",\n\t\t\t    .oval = TD_DDIR_RW,\n\t\t\t    .help = \"Sequential read and write mix\",\n\t\t\t  },\n\t\t\t  { .ival = \"readwrite\",\n\t\t\t    .oval = TD_DDIR_RW,\n\t\t\t    .help = \"Sequential read and write mix\",\n\t\t\t  },\n\t\t\t  { .ival = \"randrw\",\n\t\t\t    .oval = TD_DDIR_RANDRW,\n\t\t\t    .help = \"Random read and write mix\"\n\t\t\t  },\n\t\t\t  { .ival = \"trimwrite\",\n\t\t\t    .oval = TD_DDIR_TRIMWRITE,\n\t\t\t    .help = \"Trim and write mix, trims preceding writes\"\n\t\t\t  },\n\t\t\t  { .ival = \"randtrimwrite\",\n\t\t\t    .oval = TD_DDIR_RANDTRIMWRITE,\n\t\t\t    .help = \"Randomly trim and write mix, trims preceding writes\"\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"rw_sequencer\",\n\t\t.lname\t= \"RW Sequencer\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, rw_seq),\n\t\t.help\t= \"IO offset generator modifier\",\n\t\t.def\t= \"sequential\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t\t.posval = {\n\t\t\t  { .ival = \"sequential\",\n\t\t\t    .oval = RW_SEQ_SEQ,\n\t\t\t    .help = \"Generate sequential offsets\",\n\t\t\t  },\n\t\t\t  { .ival = \"identical\",\n\t\t\t    .oval = RW_SEQ_IDENT,\n\t\t\t    .help = \"Generate identical offsets\",\n\t\t\t  },\n\t\t},\n\t},\n\n\t{\n\t\t.name\t= \"ioengine\",\n\t\t.lname\t= \"IO Engine\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, ioengine),\n\t\t.help\t= \"IO engine to use\",\n\t\t.def\t= FIO_PREFERRED_ENGINE,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"sync\",\n\t\t\t    .help = \"Use read/write\",\n\t\t\t  },\n\t\t\t  { .ival = \"psync\",\n\t\t\t    .help = \"Use pread/pwrite\",\n\t\t\t  },\n\t\t\t  { .ival = \"vsync\",\n\t\t\t    .help = \"Use readv/writev\",\n\t\t\t  },\n#ifdef CONFIG_PWRITEV\n\t\t\t  { .ival = \"pvsync\",\n\t\t\t    .help = \"Use preadv/pwritev\",\n\t\t\t  },\n#endif\n#ifdef FIO_HAVE_PWRITEV2\n\t\t\t  { .ival = \"pvsync2\",\n\t\t\t    .help = \"Use preadv2/pwritev2\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LIBAIO\n\t\t\t  { .ival = \"libaio\",\n\t\t\t    .help = \"Linux native asynchronous IO\",\n\t\t\t  },\n#endif\n#ifdef ARCH_HAVE_IOURING\n\t\t\t  { .ival = \"io_uring\",\n\t\t\t    .help = \"Fast Linux native aio\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_POSIXAIO\n\t\t\t  { .ival = \"posixaio\",\n\t\t\t    .help = \"POSIX asynchronous IO\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_SOLARISAIO\n\t\t\t  { .ival = \"solarisaio\",\n\t\t\t    .help = \"Solaris native asynchronous IO\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_WINDOWSAIO\n\t\t\t  { .ival = \"windowsaio\",\n\t\t\t    .help = \"Windows native asynchronous IO\"\n\t\t\t  },\n#endif\n#ifdef CONFIG_RBD\n\t\t\t  { .ival = \"rbd\",\n\t\t\t    .help = \"Rados Block Device asynchronous IO\"\n\t\t\t  },\n#endif\n\t\t\t  { .ival = \"mmap\",\n\t\t\t    .help = \"Memory mapped IO\"\n\t\t\t  },\n#ifdef CONFIG_LINUX_SPLICE\n\t\t\t  { .ival = \"splice\",\n\t\t\t    .help = \"splice/vmsplice based IO\",\n\t\t\t  },\n\t\t\t  { .ival = \"netsplice\",\n\t\t\t    .help = \"splice/vmsplice to/from the network\",\n\t\t\t  },\n#endif\n#ifdef FIO_HAVE_SGIO\n\t\t\t  { .ival = \"sg\",\n\t\t\t    .help = \"SCSI generic v3 IO\",\n\t\t\t  },\n#endif\n\t\t\t  { .ival = \"null\",\n\t\t\t    .help = \"Testing engine (no data transfer)\",\n\t\t\t  },\n\t\t\t  { .ival = \"net\",\n\t\t\t    .help = \"Network IO\",\n\t\t\t  },\n\t\t\t  { .ival = \"cpuio\",\n\t\t\t    .help = \"CPU cycle burner engine\",\n\t\t\t  },\n#ifdef CONFIG_RDMA\n\t\t\t  { .ival = \"rdma\",\n\t\t\t    .help = \"RDMA IO engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LINUX_EXT4_MOVE_EXTENT\n\t\t\t  { .ival = \"e4defrag\",\n\t\t\t    .help = \"ext4 defrag engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LINUX_FALLOCATE\n\t\t\t  { .ival = \"falloc\",\n\t\t\t    .help = \"fallocate() file based engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_GFAPI\n\t\t\t  { .ival = \"gfapi\",\n\t\t\t    .help = \"Glusterfs libgfapi(sync) based engine\"\n\t\t\t  },\n\t\t\t  { .ival = \"gfapi_async\",\n\t\t\t    .help = \"Glusterfs libgfapi(async) based engine\"\n\t\t\t  },\n#endif\n#ifdef CONFIG_LIBHDFS\n\t\t\t  { .ival = \"libhdfs\",\n\t\t\t    .help = \"Hadoop Distributed Filesystem (HDFS) engine\"\n\t\t\t  },\n#endif\n#ifdef CONFIG_IME\n\t\t\t  { .ival = \"ime_psync\",\n\t\t\t    .help = \"DDN's IME synchronous IO engine\",\n\t\t\t  },\n\t\t\t  { .ival = \"ime_psyncv\",\n\t\t\t    .help = \"DDN's IME synchronous IO engine using iovecs\",\n\t\t\t  },\n\t\t\t  { .ival = \"ime_aio\",\n\t\t\t    .help = \"DDN's IME asynchronous IO engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LINUX_DEVDAX\n\t\t\t  { .ival = \"dev-dax\",\n\t\t\t    .help = \"DAX Device based IO engine\",\n\t\t\t  },\n#endif\n\t\t\t  {\n\t\t\t    .ival = \"filecreate\",\n\t\t\t    .help = \"File creation engine\",\n\t\t\t  },\n\t\t\t  { .ival = \"external\",\n\t\t\t    .help = \"Load external engine (append name)\",\n\t\t\t    .cb = str_ioengine_external_cb,\n\t\t\t  },\n#ifdef CONFIG_LIBPMEM\n\t\t\t  { .ival = \"libpmem\",\n\t\t\t    .help = \"PMDK libpmem based IO engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_HTTP\n\t\t\t  { .ival = \"http\",\n\t\t\t    .help = \"HTTP (WebDAV/S3) IO engine\",\n\t\t\t  },\n#endif\n\t\t\t  { .ival = \"nbd\",\n\t\t\t    .help = \"Network Block Device (NBD) IO engine\"\n\t\t\t  },\n#ifdef CONFIG_DFS\n\t\t\t  { .ival = \"dfs\",\n\t\t\t    .help = \"DAOS File System (dfs) IO engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LIBNFS\n\t\t\t  { .ival = \"nfs\",\n\t\t\t    .help = \"NFS IO engine\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LIBXNVME\n\t\t\t  { .ival = \"xnvme\",\n\t\t\t    .help = \"XNVME IO engine\",\n\t\t\t  },\n#endif\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"iodepth\",\n\t\t.lname\t= \"IO Depth\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iodepth),\n\t\t.help\t= \"Number of IO buffers to keep in flight\",\n\t\t.minval = 1,\n\t\t.interval = 1,\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"iodepth_batch\",\n\t\t.lname\t= \"IO Depth batch\",\n\t\t.alias\t= \"iodepth_batch_submit\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iodepth_batch),\n\t\t.help\t= \"Number of IO buffers to submit in one go\",\n\t\t.parent\t= \"iodepth\",\n\t\t.hide\t= 1,\n\t\t.interval = 1,\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"iodepth_batch_complete_min\",\n\t\t.lname\t= \"Min IO depth batch complete\",\n\t\t.alias\t= \"iodepth_batch_complete\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iodepth_batch_complete_min),\n\t\t.help\t= \"Min number of IO buffers to retrieve in one go\",\n\t\t.parent\t= \"iodepth\",\n\t\t.hide\t= 1,\n\t\t.minval\t= 0,\n\t\t.interval = 1,\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"iodepth_batch_complete_max\",\n\t\t.lname\t= \"Max IO depth batch complete\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iodepth_batch_complete_max),\n\t\t.help\t= \"Max number of IO buffers to retrieve in one go\",\n\t\t.parent\t= \"iodepth\",\n\t\t.hide\t= 1,\n\t\t.minval\t= 0,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"iodepth_low\",\n\t\t.lname\t= \"IO Depth batch low\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iodepth_low),\n\t\t.help\t= \"Low water mark for queuing depth\",\n\t\t.parent\t= \"iodepth\",\n\t\t.hide\t= 1,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"serialize_overlap\",\n\t\t.lname\t= \"Serialize overlap\",\n\t\t.off1\t= offsetof(struct thread_options, serialize_overlap),\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.help\t= \"Wait for in-flight IOs that collide to complete\",\n\t\t.parent\t= \"iodepth\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t},\n\t{\n\t\t.name\t= \"io_submit_mode\",\n\t\t.lname\t= \"IO submit mode\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, io_submit_mode),\n\t\t.help\t= \"How IO submissions and completions are done\",\n\t\t.def\t= \"inline\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BASIC,\n\t\t.posval = {\n\t\t\t  { .ival = \"inline\",\n\t\t\t    .oval = IO_MODE_INLINE,\n\t\t\t    .help = \"Submit and complete IO inline\",\n\t\t\t  },\n\t\t\t  { .ival = \"offload\",\n\t\t\t    .oval = IO_MODE_OFFLOAD,\n\t\t\t    .help = \"Offload submit and complete to threads\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"size\",\n\t\t.lname\t= \"Size\",\n\t\t.type\t= FIO_OPT_STR_VAL_ZONE,\n\t\t.cb\t= str_size_cb,\n\t\t.off1\t= offsetof(struct thread_options, size),\n\t\t.help\t= \"Total size of device or files\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"io_size\",\n\t\t.alias\t= \"io_limit\",\n\t\t.lname\t= \"IO Size\",\n\t\t.type\t= FIO_OPT_STR_VAL_ZONE,\n\t\t.cb\t= str_io_size_cb,\n\t\t.off1\t= offsetof(struct thread_options, io_size),\n\t\t.help\t= \"Total size of I/O to be performed\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"fill_device\",\n\t\t.lname\t= \"Fill device\",\n\t\t.alias\t= \"fill_fs\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, fill_device),\n\t\t.help\t= \"Write until an ENOSPC error occurs\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"filesize\",\n\t\t.lname\t= \"File size\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, file_size_low),\n\t\t.off2\t= offsetof(struct thread_options, file_size_high),\n\t\t.minval = 1,\n\t\t.help\t= \"Size of individual files\",\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"file_append\",\n\t\t.lname\t= \"File append\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, file_append),\n\t\t.help\t= \"IO will start at the end of the file(s)\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"offset\",\n\t\t.lname\t= \"IO offset\",\n\t\t.alias\t= \"fileoffset\",\n\t\t.type\t= FIO_OPT_STR_VAL_ZONE,\n\t\t.cb\t= str_offset_cb,\n\t\t.off1\t= offsetof(struct thread_options, start_offset),\n\t\t.help\t= \"Start IO from this offset\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"offset_align\",\n\t\t.lname\t= \"IO offset alignment\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, start_offset_align),\n\t\t.help\t= \"Start IO from this offset alignment\",\n\t\t.def\t= \"0\",\n\t\t.interval = 512,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"offset_increment\",\n\t\t.lname\t= \"IO offset increment\",\n\t\t.type\t= FIO_OPT_STR_VAL_ZONE,\n\t\t.cb\t= str_offset_increment_cb,\n\t\t.off1\t= offsetof(struct thread_options, offset_increment),\n\t\t.help\t= \"What is the increment from one offset to the next\",\n\t\t.parent = \"offset\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"number_ios\",\n\t\t.lname\t= \"Number of IOs to perform\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, number_ios),\n\t\t.help\t= \"Force job completion after this number of IOs\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"num_range\",\n\t\t.lname\t= \"Number of ranges\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, num_range),\n\t\t.maxval\t= MAX_TRIM_RANGE,\n\t\t.help\t= \"Number of ranges for trim command\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bs\",\n\t\t.lname\t= \"Block size\",\n\t\t.alias\t= \"blocksize\",\n\t\t.type\t= FIO_OPT_ULL,\n\t\t.off1\t= offsetof(struct thread_options, bs[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, bs[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, bs[DDIR_TRIM]),\n\t\t.minval = 1,\n\t\t.help\t= \"Block size unit\",\n\t\t.def\t= \"4096\",\n\t\t.parent = \"rw\",\n\t\t.hide\t= 1,\n\t\t.interval = 512,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"ba\",\n\t\t.lname\t= \"Block size align\",\n\t\t.alias\t= \"blockalign\",\n\t\t.type\t= FIO_OPT_ULL,\n\t\t.off1\t= offsetof(struct thread_options, ba[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, ba[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, ba[DDIR_TRIM]),\n\t\t.minval\t= 1,\n\t\t.help\t= \"IO block offset alignment\",\n\t\t.parent\t= \"rw\",\n\t\t.hide\t= 1,\n\t\t.interval = 512,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bsrange\",\n\t\t.lname\t= \"Block size range\",\n\t\t.alias\t= \"blocksize_range\",\n\t\t.type\t= FIO_OPT_RANGE,\n\t\t.off1\t= offsetof(struct thread_options, min_bs[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, max_bs[DDIR_READ]),\n\t\t.off3\t= offsetof(struct thread_options, min_bs[DDIR_WRITE]),\n\t\t.off4\t= offsetof(struct thread_options, max_bs[DDIR_WRITE]),\n\t\t.off5\t= offsetof(struct thread_options, min_bs[DDIR_TRIM]),\n\t\t.off6\t= offsetof(struct thread_options, max_bs[DDIR_TRIM]),\n\t\t.minval = 1,\n\t\t.help\t= \"Set block size range (in more detail than bs)\",\n\t\t.parent = \"rw\",\n\t\t.hide\t= 1,\n\t\t.interval = 4096,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bssplit\",\n\t\t.lname\t= \"Block size split\",\n\t\t.type\t= FIO_OPT_STR_ULL,\n\t\t.cb\t= str_bssplit_cb,\n\t\t.off1\t= offsetof(struct thread_options, bssplit),\n\t\t.help\t= \"Set a specific mix of block sizes\",\n\t\t.parent\t= \"rw\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bs_unaligned\",\n\t\t.lname\t= \"Block size unaligned\",\n\t\t.alias\t= \"blocksize_unaligned\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, bs_unaligned),\n\t\t.help\t= \"Don't sector align IO buffer sizes\",\n\t\t.parent = \"rw\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bs_is_seq_rand\",\n\t\t.lname\t= \"Block size division is seq/random (not read/write)\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, bs_is_seq_rand),\n\t\t.help\t= \"Consider any blocksize setting to be sequential,random\",\n\t\t.def\t= \"0\",\n\t\t.parent = \"blocksize\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"randrepeat\",\n\t\t.alias\t= \"allrandrepeat\",\n\t\t.lname\t= \"Random repeatable\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, rand_repeatable),\n\t\t.help\t= \"Use repeatable random IO pattern\",\n\t\t.def\t= \"1\",\n\t\t.parent = \"rw\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"randseed\",\n\t\t.lname\t= \"The random generator seed\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, rand_seed),\n\t\t.help\t= \"Set the random generator seed value\",\n\t\t.def\t= \"0x89\",\n\t\t.parent = \"rw\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"norandommap\",\n\t\t.lname\t= \"No randommap\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, norandommap),\n\t\t.help\t= \"Accept potential duplicate random blocks\",\n\t\t.parent = \"rw\",\n\t\t.hide\t= 1,\n\t\t.hide_on_set = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"softrandommap\",\n\t\t.lname\t= \"Soft randommap\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, softrandommap),\n\t\t.help\t= \"Set norandommap if randommap allocation fails\",\n\t\t.parent\t= \"norandommap\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"random_generator\",\n\t\t.lname\t= \"Random Generator\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, random_generator),\n\t\t.help\t= \"Type of random number generator to use\",\n\t\t.def\t= \"tausworthe\",\n\t\t.posval\t= {\n\t\t\t  { .ival = \"tausworthe\",\n\t\t\t    .oval = FIO_RAND_GEN_TAUSWORTHE,\n\t\t\t    .help = \"Strong Tausworthe generator\",\n\t\t\t  },\n\t\t\t  { .ival = \"lfsr\",\n\t\t\t    .oval = FIO_RAND_GEN_LFSR,\n\t\t\t    .help = \"Variable length LFSR\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"tausworthe64\",\n\t\t\t    .oval = FIO_RAND_GEN_TAUSWORTHE64,\n\t\t\t    .help = \"64-bit Tausworthe variant\",\n\t\t\t  },\n\t\t},\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"random_distribution\",\n\t\t.lname\t= \"Random Distribution\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, random_distribution),\n\t\t.cb\t= str_random_distribution_cb,\n\t\t.help\t= \"Random offset distribution generator\",\n\t\t.def\t= \"random\",\n\t\t.posval\t= {\n\t\t\t  { .ival = \"random\",\n\t\t\t    .oval = FIO_RAND_DIST_RANDOM,\n\t\t\t    .help = \"Completely random\",\n\t\t\t  },\n\t\t\t  { .ival = \"zipf\",\n\t\t\t    .oval = FIO_RAND_DIST_ZIPF,\n\t\t\t    .help = \"Zipf distribution\",\n\t\t\t  },\n\t\t\t  { .ival = \"pareto\",\n\t\t\t    .oval = FIO_RAND_DIST_PARETO,\n\t\t\t    .help = \"Pareto distribution\",\n\t\t\t  },\n\t\t\t  { .ival = \"normal\",\n\t\t\t    .oval = FIO_RAND_DIST_GAUSS,\n\t\t\t    .help = \"Normal (Gaussian) distribution\",\n\t\t\t  },\n\t\t\t  { .ival = \"zoned\",\n\t\t\t    .oval = FIO_RAND_DIST_ZONED,\n\t\t\t    .help = \"Zoned random distribution\",\n\t\t\t  },\n\t\t\t  { .ival = \"zoned_abs\",\n\t\t\t    .oval = FIO_RAND_DIST_ZONED_ABS,\n\t\t\t    .help = \"Zoned absolute random distribution\",\n\t\t\t  },\n\t\t},\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"percentage_random\",\n\t\t.lname\t= \"Percentage Random\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, perc_rand[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, perc_rand[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, perc_rand[DDIR_TRIM]),\n\t\t.maxval\t= 100,\n\t\t.help\t= \"Percentage of seq/random mix that should be random\",\n\t\t.def\t= \"100,100,100\",\n\t\t.interval = 5,\n\t\t.inverse = \"percentage_sequential\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"percentage_sequential\",\n\t\t.lname\t= \"Percentage Sequential\",\n\t\t.type\t= FIO_OPT_DEPRECATED,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RANDOM,\n\t},\n\t{\n\t\t.name\t= \"nrfiles\",\n\t\t.lname\t= \"Number of files\",\n\t\t.alias\t= \"nr_files\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, nr_files),\n\t\t.help\t= \"Split job workload between this number of files\",\n\t\t.def\t= \"1\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"openfiles\",\n\t\t.lname\t= \"Number of open files\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, open_files),\n\t\t.help\t= \"Number of files to keep open at the same time\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"file_service_type\",\n\t\t.lname\t= \"File service type\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_fst_cb,\n\t\t.off1\t= offsetof(struct thread_options, file_service_type),\n\t\t.help\t= \"How to select which file to service next\",\n\t\t.def\t= \"roundrobin\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"random\",\n\t\t\t    .oval = FIO_FSERVICE_RANDOM,\n\t\t\t    .help = \"Choose a file at random (uniform)\",\n\t\t\t  },\n\t\t\t  { .ival = \"zipf\",\n\t\t\t    .oval = FIO_FSERVICE_ZIPF,\n\t\t\t    .help = \"Zipf randomized\",\n\t\t\t  },\n\t\t\t  { .ival = \"pareto\",\n\t\t\t    .oval = FIO_FSERVICE_PARETO,\n\t\t\t    .help = \"Pareto randomized\",\n\t\t\t  },\n\t\t\t  { .ival = \"normal\",\n\t\t\t    .oval = FIO_FSERVICE_GAUSS,\n\t\t\t    .help = \"Normal (Gaussian) randomized\",\n\t\t\t  },\n\t\t\t  { .ival = \"gauss\",\n\t\t\t    .oval = FIO_FSERVICE_GAUSS,\n\t\t\t    .help = \"Alias for normal\",\n\t\t\t  },\n\t\t\t  { .ival = \"roundrobin\",\n\t\t\t    .oval = FIO_FSERVICE_RR,\n\t\t\t    .help = \"Round robin select files\",\n\t\t\t  },\n\t\t\t  { .ival = \"sequential\",\n\t\t\t    .oval = FIO_FSERVICE_SEQ,\n\t\t\t    .help = \"Finish one file before moving to the next\",\n\t\t\t  },\n\t\t},\n\t\t.parent = \"nrfiles\",\n\t\t.hide\t= 1,\n\t},\n\t{\n\t\t.name\t= \"fallocate\",\n\t\t.lname\t= \"Fallocate\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, fallocate_mode),\n\t\t.help\t= \"Whether pre-allocation is performed when laying out files\",\n#ifdef FIO_HAVE_DEFAULT_FALLOCATE\n\t\t.def\t= \"native\",\n#else\n\t\t.def\t= \"none\",\n#endif\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = FIO_FALLOCATE_NONE,\n\t\t\t    .help = \"Do not pre-allocate space\",\n\t\t\t  },\n\t\t\t  { .ival = \"native\",\n\t\t\t    .oval = FIO_FALLOCATE_NATIVE,\n\t\t\t    .help = \"Use native pre-allocation if possible\",\n\t\t\t  },\n#ifdef CONFIG_POSIX_FALLOCATE\n\t\t\t  { .ival = \"posix\",\n\t\t\t    .oval = FIO_FALLOCATE_POSIX,\n\t\t\t    .help = \"Use posix_fallocate()\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_LINUX_FALLOCATE\n\t\t\t  { .ival = \"keep\",\n\t\t\t    .oval = FIO_FALLOCATE_KEEP_SIZE,\n\t\t\t    .help = \"Use fallocate(..., FALLOC_FL_KEEP_SIZE, ...)\",\n\t\t\t  },\n#endif\n\t\t\t  { .ival = \"truncate\",\n\t\t\t    .oval = FIO_FALLOCATE_TRUNCATE,\n\t\t\t    .help = \"Truncate file to final size instead of allocating\"\n\t\t\t  },\n\t\t\t  /* Compatibility with former boolean values */\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = FIO_FALLOCATE_NONE,\n\t\t\t    .help = \"Alias for 'none'\",\n\t\t\t  },\n#ifdef CONFIG_POSIX_FALLOCATE\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = FIO_FALLOCATE_POSIX,\n\t\t\t    .help = \"Alias for 'posix'\",\n\t\t\t  },\n#endif\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"fadvise_hint\",\n\t\t.lname\t= \"Fadvise hint\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, fadvise_hint),\n\t\t.posval\t= {\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = F_ADV_NONE,\n\t\t\t    .help = \"Don't issue fadvise/madvise\",\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = F_ADV_TYPE,\n\t\t\t    .help = \"Advise using fio IO pattern\",\n\t\t\t  },\n\t\t\t  { .ival = \"random\",\n\t\t\t    .oval = F_ADV_RANDOM,\n\t\t\t    .help = \"Advise using FADV_RANDOM\",\n\t\t\t  },\n\t\t\t  { .ival = \"sequential\",\n\t\t\t    .oval = F_ADV_SEQUENTIAL,\n\t\t\t    .help = \"Advise using FADV_SEQUENTIAL\",\n\t\t\t  },\n#ifdef POSIX_FADV_NOREUSE\n\t\t\t  { .ival = \"noreuse\",\n\t\t\t    .oval = F_ADV_NOREUSE,\n\t\t\t    .help = \"Advise using FADV_NOREUSE\",\n\t\t\t  },\n#endif\n\t\t},\n\t\t.help\t= \"Use fadvise() to advise the kernel on IO pattern\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"fsync\",\n\t\t.lname\t= \"Fsync\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, fsync_blocks),\n\t\t.help\t= \"Issue fsync for writes every given number of blocks\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"fdatasync\",\n\t\t.lname\t= \"Fdatasync\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, fdatasync_blocks),\n\t\t.help\t= \"Issue fdatasync for writes every given number of blocks\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"write_barrier\",\n\t\t.lname\t= \"Write barrier\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, barrier_blocks),\n\t\t.help\t= \"Make every Nth write a barrier write\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#ifdef CONFIG_SYNC_FILE_RANGE\n\t{\n\t\t.name\t= \"sync_file_range\",\n\t\t.lname\t= \"Sync file range\",\n\t\t.posval\t= {\n\t\t\t  { .ival = \"wait_before\",\n\t\t\t    .oval = SYNC_FILE_RANGE_WAIT_BEFORE,\n\t\t\t    .help = \"SYNC_FILE_RANGE_WAIT_BEFORE\",\n\t\t\t    .orval  = 1,\n\t\t\t  },\n\t\t\t  { .ival = \"write\",\n\t\t\t    .oval = SYNC_FILE_RANGE_WRITE,\n\t\t\t    .help = \"SYNC_FILE_RANGE_WRITE\",\n\t\t\t    .orval  = 1,\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"wait_after\",\n\t\t\t    .oval = SYNC_FILE_RANGE_WAIT_AFTER,\n\t\t\t    .help = \"SYNC_FILE_RANGE_WAIT_AFTER\",\n\t\t\t    .orval  = 1,\n\t\t\t  },\n\t\t},\n\t\t.type\t= FIO_OPT_STR_MULTI,\n\t\t.cb\t= str_sfr_cb,\n\t\t.off1\t= offsetof(struct thread_options, sync_file_range),\n\t\t.help\t= \"Use sync_file_range()\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"sync_file_range\",\n\t\t.lname\t= \"Sync file range\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support sync_file_range\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"direct\",\n\t\t.lname\t= \"Direct I/O\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, odirect),\n\t\t.help\t= \"Use O_DIRECT IO (negates buffered)\",\n\t\t.def\t= \"0\",\n\t\t.inverse = \"buffered\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_TYPE,\n\t},\n#ifdef FIO_HAVE_RWF_ATOMIC\n\t{\n\t\t.name\t= \"atomic\",\n\t\t.lname\t= \"Atomic I/O\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, oatomic),\n\t\t.help\t= \"Use Atomic IO with O_DIRECT (implies O_DIRECT)\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_TYPE,\n\t},\n#endif\n\t{\n\t\t.name\t= \"buffered\",\n\t\t.lname\t= \"Buffered I/O\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, odirect),\n\t\t.neg\t= 1,\n\t\t.help\t= \"Use buffered IO (negates direct)\",\n\t\t.def\t= \"1\",\n\t\t.inverse = \"direct\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_TYPE,\n\t},\n\t{\n\t\t.name\t= \"overwrite\",\n\t\t.lname\t= \"Overwrite\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, overwrite),\n\t\t.help\t= \"When writing, set whether to overwrite current data\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"loops\",\n\t\t.lname\t= \"Loops\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, loops),\n\t\t.help\t= \"Number of times to run the job\",\n\t\t.def\t= \"1\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"numjobs\",\n\t\t.lname\t= \"Number of jobs\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, numjobs),\n\t\t.help\t= \"Duplicate this job this many times\",\n\t\t.def\t= \"1\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"startdelay\",\n\t\t.lname\t= \"Start delay\",\n\t\t.type\t= FIO_OPT_STR_VAL_TIME,\n\t\t.off1\t= offsetof(struct thread_options, start_delay),\n\t\t.off2\t= offsetof(struct thread_options, start_delay_high),\n\t\t.help\t= \"Only start job when this period has passed\",\n\t\t.def\t= \"0\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"runtime\",\n\t\t.lname\t= \"Runtime\",\n\t\t.alias\t= \"timeout\",\n\t\t.type\t= FIO_OPT_STR_VAL_TIME,\n\t\t.off1\t= offsetof(struct thread_options, timeout),\n\t\t.help\t= \"Stop workload when this amount of time has passed\",\n\t\t.def\t= \"0\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"time_based\",\n\t\t.lname\t= \"Time based\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, time_based),\n\t\t.help\t= \"Keep running until runtime/timeout is met\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"verify_only\",\n\t\t.lname\t= \"Verify only\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, verify_only),\n\t\t.help\t= \"Verifies previously written data is still valid\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"ramp_time\",\n\t\t.lname\t= \"Ramp time\",\n\t\t.type\t= FIO_OPT_STR_VAL_TIME,\n\t\t.off1\t= offsetof(struct thread_options, ramp_time),\n\t\t.help\t= \"Ramp up time before measuring performance\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name\t= \"clocksource\",\n\t\t.lname\t= \"Clock source\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= fio_clock_source_cb,\n\t\t.off1\t= offsetof(struct thread_options, clocksource),\n\t\t.help\t= \"What type of timing source to use\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CLOCK,\n\t\t.posval\t= {\n#ifdef CONFIG_GETTIMEOFDAY\n\t\t\t  { .ival = \"gettimeofday\",\n\t\t\t    .oval = CS_GTOD,\n\t\t\t    .help = \"Use gettimeofday(2) for timing\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_CLOCK_GETTIME\n\t\t\t  { .ival = \"clock_gettime\",\n\t\t\t    .oval = CS_CGETTIME,\n\t\t\t    .help = \"Use clock_gettime(2) for timing\",\n\t\t\t  },\n#endif\n#ifdef ARCH_HAVE_CPU_CLOCK\n\t\t\t  { .ival = \"cpu\",\n\t\t\t    .oval = CS_CPUCLOCK,\n\t\t\t    .help = \"Use CPU private clock\",\n\t\t\t  },\n#endif\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"mem\",\n\t\t.alias\t= \"iomem\",\n\t\t.lname\t= \"I/O Memory\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_mem_cb,\n\t\t.off1\t= offsetof(struct thread_options, mem_type),\n\t\t.help\t= \"Backing type for IO buffers\",\n\t\t.def\t= \"malloc\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"malloc\",\n\t\t\t    .oval = MEM_MALLOC,\n\t\t\t    .help = \"Use malloc(3) for IO buffers\",\n\t\t\t  },\n#ifndef CONFIG_NO_SHM\n\t\t\t  { .ival = \"shm\",\n\t\t\t    .oval = MEM_SHM,\n\t\t\t    .help = \"Use shared memory segments for IO buffers\",\n\t\t\t  },\n#ifdef FIO_HAVE_HUGETLB\n\t\t\t  { .ival = \"shmhuge\",\n\t\t\t    .oval = MEM_SHMHUGE,\n\t\t\t    .help = \"Like shm, but use huge pages\",\n\t\t\t  },\n#endif\n#endif\n\t\t\t  { .ival = \"mmap\",\n\t\t\t    .oval = MEM_MMAP,\n\t\t\t    .help = \"Use mmap(2) (file or anon) for IO buffers\",\n\t\t\t  },\n\t\t\t  { .ival = \"mmapshared\",\n\t\t\t    .oval = MEM_MMAPSHARED,\n\t\t\t    .help = \"Like mmap, but use the shared flag\",\n\t\t\t  },\n#ifdef FIO_HAVE_HUGETLB\n\t\t\t  { .ival = \"mmaphuge\",\n\t\t\t    .oval = MEM_MMAPHUGE,\n\t\t\t    .help = \"Like mmap, but use huge pages\",\n\t\t\t  },\n#endif\n#ifdef CONFIG_CUDA\n\t\t\t  { .ival = \"cudamalloc\",\n\t\t\t    .oval = MEM_CUDA_MALLOC,\n\t\t\t    .help = \"Allocate GPU device memory for GPUDirect RDMA\",\n\t\t\t  },\n#endif\n\t\t  },\n\t},\n\t{\n\t\t.name\t= \"iomem_align\",\n\t\t.alias\t= \"mem_align\",\n\t\t.lname\t= \"I/O memory alignment\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, mem_align),\n\t\t.minval\t= 0,\n\t\t.help\t= \"IO memory buffer offset alignment\",\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"iomem\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"verify\",\n\t\t.lname\t= \"Verify\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, verify),\n\t\t.help\t= \"Verify data written\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t\t.posval = {\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = VERIFY_NONE,\n\t\t\t    .help = \"Don't do IO verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"md5\",\n\t\t\t    .oval = VERIFY_MD5,\n\t\t\t    .help = \"Use md5 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc64\",\n\t\t\t    .oval = VERIFY_CRC64,\n\t\t\t    .help = \"Use crc64 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc32\",\n\t\t\t    .oval = VERIFY_CRC32,\n\t\t\t    .help = \"Use crc32 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc32c-intel\",\n\t\t\t    .oval = VERIFY_CRC32C,\n\t\t\t    .help = \"Use crc32c checksums for verification (hw assisted, if available)\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc32c\",\n\t\t\t    .oval = VERIFY_CRC32C,\n\t\t\t    .help = \"Use crc32c checksums for verification (hw assisted, if available)\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc16\",\n\t\t\t    .oval = VERIFY_CRC16,\n\t\t\t    .help = \"Use crc16 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"crc7\",\n\t\t\t    .oval = VERIFY_CRC7,\n\t\t\t    .help = \"Use crc7 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha1\",\n\t\t\t    .oval = VERIFY_SHA1,\n\t\t\t    .help = \"Use sha1 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha256\",\n\t\t\t    .oval = VERIFY_SHA256,\n\t\t\t    .help = \"Use sha256 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha512\",\n\t\t\t    .oval = VERIFY_SHA512,\n\t\t\t    .help = \"Use sha512 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha3-224\",\n\t\t\t    .oval = VERIFY_SHA3_224,\n\t\t\t    .help = \"Use sha3-224 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha3-256\",\n\t\t\t    .oval = VERIFY_SHA3_256,\n\t\t\t    .help = \"Use sha3-256 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha3-384\",\n\t\t\t    .oval = VERIFY_SHA3_384,\n\t\t\t    .help = \"Use sha3-384 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"sha3-512\",\n\t\t\t    .oval = VERIFY_SHA3_512,\n\t\t\t    .help = \"Use sha3-512 checksums for verification\",\n\t\t\t  },\n\t\t\t  { .ival = \"xxhash\",\n\t\t\t    .oval = VERIFY_XXHASH,\n\t\t\t    .help = \"Use xxhash checksums for verification\",\n\t\t\t  },\n\t\t\t  /* Meta information was included into verify_header,\n\t\t\t   * 'meta' verification is implied by default. */\n\t\t\t  { .ival = \"meta\",\n\t\t\t    .oval = VERIFY_HDR_ONLY,\n\t\t\t    .help = \"Use io information for verification. \"\n\t\t\t\t    \"Now is implied by default, thus option is obsolete, \"\n\t\t\t\t    \"don't use it\",\n\t\t\t  },\n\t\t\t  { .ival = \"pattern\",\n\t\t\t    .oval = VERIFY_PATTERN_NO_HDR,\n\t\t\t    .help = \"Verify strict pattern\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"null\",\n\t\t\t    .oval = VERIFY_NULL,\n\t\t\t    .help = \"Pretend to verify\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"do_verify\",\n\t\t.lname\t= \"Perform verify step\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, do_verify),\n\t\t.help\t= \"Run verification stage after write\",\n\t\t.def\t= \"1\",\n\t\t.parent = \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verifysort\",\n\t\t.lname\t= \"Verify sort\",\n\t\t.type\t= FIO_OPT_SOFT_DEPRECATED,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verifysort_nr\",\n\t\t.lname\t= \"Verify Sort Nr\",\n\t\t.type\t= FIO_OPT_SOFT_DEPRECATED,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name   = \"verify_interval\",\n\t\t.lname\t= \"Verify interval\",\n\t\t.type   = FIO_OPT_INT,\n\t\t.off1   = offsetof(struct thread_options, verify_interval),\n\t\t.minval\t= 2 * sizeof(struct verify_header),\n\t\t.help   = \"Store verify buffer header every N bytes\",\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.interval = 2 * sizeof(struct verify_header),\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_offset\",\n\t\t.lname\t= \"Verify offset\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.help\t= \"Offset verify header location by N bytes\",\n\t\t.off1\t= offsetof(struct thread_options, verify_offset),\n\t\t.minval\t= sizeof(struct verify_header),\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_pattern\",\n\t\t.lname\t= \"Verify pattern\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_verify_pattern_cb,\n\t\t.off1\t= offsetof(struct thread_options, verify_pattern),\n\t\t.help\t= \"Fill pattern for IO buffers\",\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_fatal\",\n\t\t.lname\t= \"Verify fatal\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, verify_fatal),\n\t\t.def\t= \"0\",\n\t\t.help\t= \"Exit on a single verify failure, don't continue\",\n\t\t.parent = \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_dump\",\n\t\t.lname\t= \"Verify dump\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, verify_dump),\n\t\t.def\t= \"0\",\n\t\t.help\t= \"Dump contents of good and bad blocks on failure\",\n\t\t.parent = \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_async\",\n\t\t.lname\t= \"Verify asynchronously\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, verify_async),\n\t\t.def\t= \"0\",\n\t\t.help\t= \"Number of async verifier threads to use\",\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_backlog\",\n\t\t.lname\t= \"Verify backlog\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, verify_backlog),\n\t\t.help\t= \"Verify after this number of blocks are written\",\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_backlog_batch\",\n\t\t.lname\t= \"Verify backlog batch\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, verify_batch),\n\t\t.help\t= \"Verify this number of IO blocks\",\n\t\t.parent\t= \"verify\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n#ifdef FIO_HAVE_CPU_AFFINITY\n\t{\n\t\t.name\t= \"verify_async_cpus\",\n\t\t.lname\t= \"Async verify CPUs\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_verify_cpus_allowed_cb,\n\t\t.off1\t= offsetof(struct thread_options, verify_cpumask),\n\t\t.help\t= \"Set CPUs allowed for async verify threads\",\n\t\t.parent\t= \"verify_async\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n#else\n\t{\n\t\t.name\t= \"verify_async_cpus\",\n\t\t.lname\t= \"Async verify CPUs\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support CPU affinities\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"experimental_verify\",\n\t\t.lname\t= \"Experimental Verify\",\n\t\t.off1\t= offsetof(struct thread_options, experimental_verify),\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.help\t= \"Enable experimental verification\",\n\t\t.parent\t= \"verify\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_state_load\",\n\t\t.lname\t= \"Load verify state\",\n\t\t.off1\t= offsetof(struct thread_options, verify_state),\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.help\t= \"Load verify termination state\",\n\t\t.parent\t= \"verify\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_state_save\",\n\t\t.lname\t= \"Save verify state\",\n\t\t.off1\t= offsetof(struct thread_options, verify_state_save),\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.def\t= \"1\",\n\t\t.help\t= \"Save verify state on termination\",\n\t\t.parent\t= \"verify\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n\t{\n\t\t.name\t= \"verify_write_sequence\",\n\t\t.lname\t= \"Verify write sequence number\",\n\t\t.off1\t= offsetof(struct thread_options, verify_write_sequence),\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.def\t= \"1\",\n\t\t.help\t= \"Verify header write sequence number\",\n\t\t.parent\t= \"verify\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_VERIFY,\n\t},\n#ifdef FIO_HAVE_TRIM\n\t{\n\t\t.name\t= \"trim_percentage\",\n\t\t.lname\t= \"Trim percentage\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, trim_percentage),\n\t\t.minval = 0,\n\t\t.maxval = 100,\n\t\t.help\t= \"Number of verify blocks to trim (i.e., discard)\",\n\t\t.parent\t= \"verify\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1,\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_TRIM,\n\t},\n\t{\n\t\t.name\t= \"trim_verify_zero\",\n\t\t.lname\t= \"Verify trim zero\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.help\t= \"Verify that trimmed (i.e., discarded) blocks are returned as zeroes\",\n\t\t.off1\t= offsetof(struct thread_options, trim_zero),\n\t\t.parent\t= \"trim_percentage\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_TRIM,\n\t},\n\t{\n\t\t.name\t= \"trim_backlog\",\n\t\t.lname\t= \"Trim backlog\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, trim_backlog),\n\t\t.help\t= \"Trim after this number of blocks are written\",\n\t\t.parent\t= \"trim_percentage\",\n\t\t.hide\t= 1,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_TRIM,\n\t},\n\t{\n\t\t.name\t= \"trim_backlog_batch\",\n\t\t.lname\t= \"Trim backlog batch\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, trim_batch),\n\t\t.help\t= \"Trim this number of IO blocks\",\n\t\t.parent\t= \"trim_percentage\",\n\t\t.hide\t= 1,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_TRIM,\n\t},\n#else\n\t{\n\t\t.name\t= \"trim_percentage\",\n\t\t.lname\t= \"Trim percentage\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Fio does not support TRIM on your platform\",\n\t},\n\t{\n\t\t.name\t= \"trim_verify_zero\",\n\t\t.lname\t= \"Verify trim zero\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Fio does not support TRIM on your platform\",\n\t},\n\t{\n\t\t.name\t= \"trim_backlog\",\n\t\t.lname\t= \"Trim backlog\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Fio does not support TRIM on your platform\",\n\t},\n\t{\n\t\t.name\t= \"trim_backlog_batch\",\n\t\t.lname\t= \"Trim backlog batch\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Fio does not support TRIM on your platform\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"write_iolog\",\n\t\t.lname\t= \"Write I/O log\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, write_iolog_file),\n\t\t.help\t= \"Store IO pattern to file\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"read_iolog\",\n\t\t.lname\t= \"Read I/O log\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, read_iolog_file),\n\t\t.help\t= \"Playback IO pattern from file\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"read_iolog_chunked\",\n\t\t.lname\t= \"Read I/O log in parts\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, read_iolog_chunked),\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"read_iolog\",\n\t\t.help\t= \"Parse IO pattern in chunks\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"replay_no_stall\",\n\t\t.lname\t= \"Don't stall on replay\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, no_stall),\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"read_iolog\",\n\t\t.hide\t= 1,\n\t\t.help\t= \"Playback IO pattern file as fast as possible without stalls\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"replay_redirect\",\n\t\t.lname\t= \"Redirect device for replay\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, replay_redirect),\n\t\t.parent\t= \"read_iolog\",\n\t\t.hide\t= 1,\n\t\t.help\t= \"Replay all I/O onto this device, regardless of trace device\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"replay_scale\",\n\t\t.lname\t= \"Replace offset scale factor\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, replay_scale),\n\t\t.parent\t= \"read_iolog\",\n\t\t.def\t= \"1\",\n\t\t.help\t= \"Align offsets to this blocksize\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"replay_align\",\n\t\t.lname\t= \"Replace alignment\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, replay_align),\n\t\t.parent\t= \"read_iolog\",\n\t\t.help\t= \"Scale offset down by this factor\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t\t.pow2\t= 1,\n\t},\n\t{\n\t\t.name\t= \"replay_time_scale\",\n\t\t.lname\t= \"Replay Time Scale\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, replay_time_scale),\n\t\t.def\t= \"100\",\n\t\t.minval\t= 1,\n\t\t.parent\t= \"read_iolog\",\n\t\t.hide\t= 1,\n\t\t.help\t= \"Scale time for replay events\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"replay_skip\",\n\t\t.lname\t= \"Replay Skip\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_replay_skip_cb,\n\t\t.off1\t= offsetof(struct thread_options, replay_skip),\n\t\t.parent\t= \"read_iolog\",\n\t\t.help\t= \"Skip certain IO types (read,write,trim,flush)\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"merge_blktrace_file\",\n\t\t.lname\t= \"Merged blktrace output filename\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, merge_blktrace_file),\n\t\t.help\t= \"Merged blktrace output filename\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group = FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"merge_blktrace_scalars\",\n\t\t.lname\t= \"Percentage to scale each trace\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.off1\t= offsetof(struct thread_options, merge_blktrace_scalars),\n\t\t.maxlen\t= FIO_IO_U_LIST_MAX_LEN,\n\t\t.help\t= \"Percentage to scale each trace\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"merge_blktrace_iters\",\n\t\t.lname\t= \"Number of iterations to run per trace\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.off1\t= offsetof(struct thread_options, merge_blktrace_iters),\n\t\t.maxlen\t= FIO_IO_U_LIST_MAX_LEN,\n\t\t.help\t= \"Number of iterations to run per trace\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IOLOG,\n\t},\n\t{\n\t\t.name\t= \"exec_prerun\",\n\t\t.lname\t= \"Pre-execute runnable\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, exec_prerun),\n\t\t.help\t= \"Execute this file prior to running job\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"exec_postrun\",\n\t\t.lname\t= \"Post-execute runnable\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, exec_postrun),\n\t\t.help\t= \"Execute this file after running job\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#ifdef FIO_HAVE_IOSCHED_SWITCH\n\t{\n\t\t.name\t= \"ioscheduler\",\n\t\t.lname\t= \"I/O scheduler\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, ioscheduler),\n\t\t.help\t= \"Use this IO scheduler on the backing device\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"ioscheduler\",\n\t\t.lname\t= \"I/O scheduler\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support IO scheduler switching\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"zonemode\",\n\t\t.lname\t= \"Zone mode\",\n\t\t.help\t= \"Mode for the zonesize, zonerange and zoneskip parameters\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, zone_mode),\n\t\t.def\t= \"none\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t\t.posval\t= {\n\t\t\t   { .ival = \"none\",\n\t\t\t     .oval = ZONE_MODE_NONE,\n\t\t\t     .help = \"no zoning\",\n\t\t\t   },\n\t\t\t   { .ival = \"strided\",\n\t\t\t     .oval = ZONE_MODE_STRIDED,\n\t\t\t     .help = \"strided mode - random I/O is restricted to a single zone\",\n\t\t\t   },\n\t\t\t   { .ival = \"zbd\",\n\t\t\t     .oval = ZONE_MODE_ZBD,\n\t\t\t     .help = \"zoned block device mode - random I/O selects one of multiple zones randomly\",\n\t\t\t   },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"zonesize\",\n\t\t.lname\t= \"Zone size\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, zone_size),\n\t\t.help\t= \"Amount of data to read per zone\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"zonecapacity\",\n\t\t.lname\t= \"Zone capacity\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, zone_capacity),\n\t\t.help\t= \"Capacity per zone\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"zonerange\",\n\t\t.lname\t= \"Zone range\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, zone_range),\n\t\t.help\t= \"Give size of an IO zone\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"zoneskip\",\n\t\t.lname\t= \"Zone skip\",\n\t\t.type\t= FIO_OPT_STR_VAL_ZONE,\n\t\t.cb\t= str_zoneskip_cb,\n\t\t.off1\t= offsetof(struct thread_options, zone_skip),\n\t\t.help\t= \"Space between IO zones\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"read_beyond_wp\",\n\t\t.lname\t= \"Allow reads beyond the zone write pointer\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, read_beyond_wp),\n\t\t.help\t= \"Allow reads beyond the zone write pointer\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"max_open_zones\",\n\t\t.lname\t= \"Per device/file maximum number of open zones\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, max_open_zones),\n\t\t.maxval\t= ZBD_MAX_WRITE_ZONES,\n\t\t.help\t= \"Limit on the number of simultaneously opened sequential write zones with zonemode=zbd\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"job_max_open_zones\",\n\t\t.lname\t= \"Job maximum number of open zones\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, job_max_open_zones),\n\t\t.maxval\t= ZBD_MAX_WRITE_ZONES,\n\t\t.help\t= \"Limit on the number of simultaneously opened sequential write zones with zonemode=zbd by one thread/process\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"ignore_zone_limits\",\n\t\t.lname\t= \"Ignore zone resource limits\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, ignore_zone_limits),\n\t\t.def\t= \"0\",\n\t\t.help\t= \"Ignore the zone resource limits (max open/active zones) reported by the device\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"zone_reset_threshold\",\n\t\t.lname\t= \"Zone reset threshold\",\n\t\t.help\t= \"Zoned block device reset threshold\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.maxlen\t= 1,\n\t\t.off1\t= offsetof(struct thread_options, zrt),\n\t\t.minfp\t= 0,\n\t\t.maxfp\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name\t= \"zone_reset_frequency\",\n\t\t.lname\t= \"Zone reset frequency\",\n\t\t.help\t= \"Zoned block device zone reset frequency in HZ\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.maxlen\t= 1,\n\t\t.off1\t= offsetof(struct thread_options, zrf),\n\t\t.minfp\t= 0,\n\t\t.maxfp\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_ZONE,\n\t},\n\t{\n\t\t.name   = \"fdp\",\n\t\t.lname  = \"Flexible data placement\",\n\t\t.type   = FIO_OPT_BOOL,\n\t\t.off1   = offsetof(struct thread_options, fdp),\n\t\t.help   = \"Use Data placement directive (FDP)\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group  = FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"dataplacement\",\n\t\t.alias\t= \"data_placement\",\n\t\t.lname\t= \"Data Placement interface\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, dp_type),\n\t\t.help\t= \"Data Placement interface to use\",\n\t\t.def\t= \"none\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = FIO_DP_NONE,\n\t\t\t    .help = \"Do not specify a data placement interface\",\n\t\t\t  },\n\t\t\t  { .ival = \"fdp\",\n\t\t\t    .oval = FIO_DP_FDP,\n\t\t\t    .help = \"Use Flexible Data Placement interface\",\n\t\t\t  },\n\t\t\t  { .ival = \"streams\",\n\t\t\t    .oval = FIO_DP_STREAMS,\n\t\t\t    .help = \"Use Streams interface\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"plid_select\",\n\t\t.alias\t= \"fdp_pli_select\",\n\t\t.lname\t= \"Data Placement ID selection strategy\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, dp_id_select),\n\t\t.help\t= \"Strategy for selecting next Data Placement ID\",\n\t\t.def\t= \"roundrobin\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"random\",\n\t\t\t    .oval = FIO_DP_RANDOM,\n\t\t\t    .help = \"Choose a Placement ID at random (uniform)\",\n\t\t\t  },\n\t\t\t  { .ival = \"roundrobin\",\n\t\t\t    .oval = FIO_DP_RR,\n\t\t\t    .help = \"Round robin select Placement IDs\",\n\t\t\t  },\n\t\t\t  { .ival = \"scheme\",\n\t\t\t    .oval = FIO_DP_SCHEME,\n\t\t\t    .help = \"Use a scheme(based on LBA) to select Placement IDs\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"plids\",\n\t\t.alias\t= \"fdp_pli\",\n\t\t.lname\t= \"Stream IDs/Data Placement ID indices\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_fdp_pli_cb,\n\t\t.off1\t= offsetof(struct thread_options, dp_ids),\n\t\t.help\t= \"Sets which Data Placement ids to use (defaults to all for FDP)\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"dp_scheme\",\n\t\t.lname\t= \"Data Placement Scheme\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.cb\t= str_dp_scheme_cb,\n\t\t.off1\t= offsetof(struct thread_options, dp_scheme_file),\n\t\t.maxlen\t= PATH_MAX,\n\t\t.help\t= \"scheme file that specifies offset-RUH mapping\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"lockmem\",\n\t\t.lname\t= \"Lock memory\",\n\t\t.type\t= FIO_OPT_STR_VAL,\n\t\t.off1\t= offsetof(struct thread_options, lockmem),\n\t\t.help\t= \"Lock down this amount of memory (per worker)\",\n\t\t.def\t= \"0\",\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"rwmixread\",\n\t\t.lname\t= \"Read/write mix read\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.cb\t= str_rwmix_read_cb,\n\t\t.off1\t= offsetof(struct thread_options, rwmix[DDIR_READ]),\n\t\t.maxval\t= 100,\n\t\t.help\t= \"Percentage of mixed workload that is reads\",\n\t\t.def\t= \"50\",\n\t\t.interval = 5,\n\t\t.inverse = \"rwmixwrite\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RWMIX,\n\t},\n\t{\n\t\t.name\t= \"rwmixwrite\",\n\t\t.lname\t= \"Read/write mix write\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.cb\t= str_rwmix_write_cb,\n\t\t.off1\t= offsetof(struct thread_options, rwmix[DDIR_WRITE]),\n\t\t.maxval\t= 100,\n\t\t.help\t= \"Percentage of mixed workload that is writes\",\n\t\t.def\t= \"50\",\n\t\t.interval = 5,\n\t\t.inverse = \"rwmixread\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RWMIX,\n\t},\n\t{\n\t\t.name\t= \"rwmixcycle\",\n\t\t.lname\t= \"Read/write mix cycle\",\n\t\t.type\t= FIO_OPT_DEPRECATED,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RWMIX,\n\t},\n\t{\n\t\t.name\t= \"nice\",\n\t\t.lname\t= \"Nice\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, nice),\n\t\t.help\t= \"Set job CPU nice value\",\n\t\t.minval\t= -20,\n\t\t.maxval\t= 19,\n\t\t.def\t= \"0\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n#ifdef FIO_HAVE_IOPRIO\n\t{\n\t\t.name\t= \"prio\",\n\t\t.lname\t= \"I/O nice priority\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, ioprio),\n\t\t.help\t= \"Set job IO priority value\",\n\t\t.minval\t= IOPRIO_MIN_PRIO,\n\t\t.maxval\t= IOPRIO_MAX_PRIO,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n#else\n\t{\n\t\t.name\t= \"prio\",\n\t\t.lname\t= \"I/O nice priority\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support IO priorities\",\n\t},\n#endif\n#ifdef FIO_HAVE_IOPRIO_CLASS\n#ifndef FIO_HAVE_IOPRIO\n#error \"FIO_HAVE_IOPRIO_CLASS requires FIO_HAVE_IOPRIO\"\n#endif\n\t{\n\t\t.name\t= \"prioclass\",\n\t\t.lname\t= \"I/O nice priority class\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, ioprio_class),\n\t\t.help\t= \"Set job IO priority class\",\n\t\t.minval\t= IOPRIO_MIN_PRIO_CLASS,\n\t\t.maxval\t= IOPRIO_MAX_PRIO_CLASS,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"priohint\",\n\t\t.lname\t= \"I/O nice priority hint\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, ioprio_hint),\n\t\t.help\t= \"Set job IO priority hint\",\n\t\t.minval\t= IOPRIO_MIN_PRIO_HINT,\n\t\t.maxval\t= IOPRIO_MAX_PRIO_HINT,\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n#else\n\t{\n\t\t.name\t= \"prioclass\",\n\t\t.lname\t= \"I/O nice priority class\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support IO priority classes\",\n\t},\n\t{\n\t\t.name\t= \"priohint\",\n\t\t.lname\t= \"I/O nice priority hint\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support IO priority hints\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"thinktime\",\n\t\t.lname\t= \"Thinktime\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, thinktime),\n\t\t.help\t= \"Idle time between IO buffers (usec)\",\n\t\t.def\t= \"0\",\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"thinktime_spin\",\n\t\t.lname\t= \"Thinktime spin\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, thinktime_spin),\n\t\t.help\t= \"Start think time by spinning this amount (usec)\",\n\t\t.def\t= \"0\",\n\t\t.is_time = 1,\n\t\t.parent\t= \"thinktime\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"thinkcycles\",\n\t\t.lname\t= \"Think cycles\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, thinkcycles),\n\t\t.help\t= \"Spin for a constant amount of cycles between requests\",\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"thinktime\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"thinktime_blocks\",\n\t\t.lname\t= \"Thinktime blocks\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, thinktime_blocks),\n\t\t.help\t= \"IO buffer period between 'thinktime'\",\n\t\t.def\t= \"1\",\n\t\t.parent\t= \"thinktime\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"thinktime_blocks_type\",\n\t\t.lname\t= \"Thinktime blocks type\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, thinktime_blocks_type),\n\t\t.help\t= \"How thinktime_blocks takes effect\",\n\t\t.def\t= \"complete\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t\t.posval = {\n\t\t\t  { .ival = \"complete\",\n\t\t\t    .oval = THINKTIME_BLOCKS_TYPE_COMPLETE,\n\t\t\t    .help = \"thinktime_blocks takes effect at the completion side\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"issue\",\n\t\t\t    .oval = THINKTIME_BLOCKS_TYPE_ISSUE,\n\t\t\t    .help = \"thinktime_blocks takes effect at the issue side\",\n\t\t\t  },\n\t\t},\n\t\t.parent = \"thinktime\",\n\t},\n\t{\n\t\t.name\t= \"thinktime_iotime\",\n\t\t.lname\t= \"Thinktime interval\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, thinktime_iotime),\n\t\t.help\t= \"IO time interval between 'thinktime'\",\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"thinktime\",\n\t\t.hide\t= 1,\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_THINKTIME,\n\t},\n\t{\n\t\t.name\t= \"rate\",\n\t\t.lname\t= \"I/O rate\",\n\t\t.type\t= FIO_OPT_ULL,\n\t\t.off1\t= offsetof(struct thread_options, rate[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, rate[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, rate[DDIR_TRIM]),\n\t\t.help\t= \"Set bandwidth rate\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"rate_min\",\n\t\t.alias\t= \"ratemin\",\n\t\t.lname\t= \"I/O min rate\",\n\t\t.type\t= FIO_OPT_ULL,\n\t\t.off1\t= offsetof(struct thread_options, ratemin[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, ratemin[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, ratemin[DDIR_TRIM]),\n\t\t.help\t= \"Job must meet this rate or it will be shutdown\",\n\t\t.parent\t= \"rate\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"rate_iops\",\n\t\t.lname\t= \"I/O rate IOPS\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, rate_iops[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, rate_iops[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, rate_iops[DDIR_TRIM]),\n\t\t.help\t= \"Limit IO used to this number of IO operations/sec\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"rate_iops_min\",\n\t\t.lname\t= \"I/O min rate IOPS\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, rate_iops_min[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, rate_iops_min[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, rate_iops_min[DDIR_TRIM]),\n\t\t.help\t= \"Job must meet this rate or it will be shut down\",\n\t\t.parent\t= \"rate_iops\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"rate_process\",\n\t\t.lname\t= \"Rate Process\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, rate_process),\n\t\t.help\t= \"What process controls how rated IO is managed\",\n\t\t.def\t= \"linear\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t\t.posval = {\n\t\t\t  { .ival = \"linear\",\n\t\t\t    .oval = RATE_PROCESS_LINEAR,\n\t\t\t    .help = \"Linear rate of IO\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"poisson\",\n\t\t\t    .oval = RATE_PROCESS_POISSON,\n\t\t\t    .help = \"Rate follows Poisson process\",\n\t\t\t  },\n\t\t},\n\t\t.parent = \"rate\",\n\t},\n\t{\n\t\t.name\t= \"rate_cycle\",\n\t\t.alias\t= \"ratecycle\",\n\t\t.lname\t= \"I/O rate cycle\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, ratecycle),\n\t\t.help\t= \"Window average for rate limits (msec)\",\n\t\t.def\t= \"1000\",\n\t\t.parent = \"rate\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"rate_ignore_thinktime\",\n\t\t.lname\t= \"Rate ignore thinktime\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, rate_ign_think),\n\t\t.help\t= \"Rated IO ignores thinktime settings\",\n\t\t.parent = \"rate\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_RATE,\n\t},\n\t{\n\t\t.name\t= \"max_latency\",\n\t\t.lname\t= \"Max Latency (usec)\",\n\t\t.type\t= FIO_OPT_ULL,\n\t\t.off1\t= offsetof(struct thread_options, max_latency[DDIR_READ]),\n\t\t.off2\t= offsetof(struct thread_options, max_latency[DDIR_WRITE]),\n\t\t.off3\t= offsetof(struct thread_options, max_latency[DDIR_TRIM]),\n\t\t.help\t= \"Maximum tolerated IO latency (usec)\",\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group = FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"latency_target\",\n\t\t.lname\t= \"Latency Target (usec)\",\n\t\t.type\t= FIO_OPT_STR_VAL_TIME,\n\t\t.off1\t= offsetof(struct thread_options, latency_target),\n\t\t.help\t= \"Ramp to max queue depth supporting this latency\",\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"latency_window\",\n\t\t.lname\t= \"Latency Window (usec)\",\n\t\t.type\t= FIO_OPT_STR_VAL_TIME,\n\t\t.off1\t= offsetof(struct thread_options, latency_window),\n\t\t.help\t= \"Time to sustain latency_target\",\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"latency_percentile\",\n\t\t.lname\t= \"Latency Percentile\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.off1\t= offsetof(struct thread_options, latency_percentile),\n\t\t.help\t= \"Percentile of IOs must be below latency_target\",\n\t\t.def\t= \"100\",\n\t\t.maxlen\t= 1,\n\t\t.minfp\t= 0.0,\n\t\t.maxfp\t= 100.0,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"latency_run\",\n\t\t.lname\t= \"Latency Run\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, latency_run),\n\t\t.help\t= \"Keep adjusting queue depth to match latency_target\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_LATPROF,\n\t},\n\t{\n\t\t.name\t= \"invalidate\",\n\t\t.lname\t= \"Cache invalidate\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, invalidate_cache),\n\t\t.help\t= \"Invalidate buffer/page cache prior to running job\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_TYPE,\n\t},\n\t{\n\t\t.name\t= \"sync\",\n\t\t.lname\t= \"Synchronous I/O\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, sync_io),\n\t\t.help\t= \"Use synchronous write IO\",\n\t\t.def\t= \"none\",\n\t\t.hide\t= 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_TYPE,\n\t\t.posval = {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = 0,\n\t\t\t  },\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = 0,\n\t\t\t  },\n\t\t\t  { .ival = \"sync\",\n\t\t\t    .oval = O_SYNC,\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = O_SYNC,\n\t\t\t  },\n#ifdef O_DSYNC\n\t\t\t  { .ival = \"dsync\",\n\t\t\t    .oval = O_DSYNC,\n\t\t\t  },\n#endif\n\t\t},\n\t},\n#ifdef FIO_HAVE_WRITE_HINT\n\t{\n\t\t.name\t= \"write_hint\",\n\t\t.lname\t= \"Write hint\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, write_hint),\n\t\t.help\t= \"Set expected write life time\",\n\t\t.category = FIO_OPT_C_ENGINE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval = {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = RWH_WRITE_LIFE_NONE,\n\t\t\t  },\n\t\t\t  { .ival = \"short\",\n\t\t\t    .oval = RWH_WRITE_LIFE_SHORT,\n\t\t\t  },\n\t\t\t  { .ival = \"medium\",\n\t\t\t    .oval = RWH_WRITE_LIFE_MEDIUM,\n\t\t\t  },\n\t\t\t  { .ival = \"long\",\n\t\t\t    .oval = RWH_WRITE_LIFE_LONG,\n\t\t\t  },\n\t\t\t  { .ival = \"extreme\",\n\t\t\t    .oval = RWH_WRITE_LIFE_EXTREME,\n\t\t\t  },\n\t\t},\n\t},\n#endif\n\t{\n\t\t.name\t= \"create_serialize\",\n\t\t.lname\t= \"Create serialize\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, create_serialize),\n\t\t.help\t= \"Serialize creation of job files\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"create_fsync\",\n\t\t.lname\t= \"Create fsync\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, create_fsync),\n\t\t.help\t= \"fsync file after creation\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"create_on_open\",\n\t\t.lname\t= \"Create on open\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, create_on_open),\n\t\t.help\t= \"Create files when they are opened for IO\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"create_only\",\n\t\t.lname\t= \"Create Only\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, create_only),\n\t\t.help\t= \"Only perform file creation phase\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.def\t= \"0\",\n\t},\n\t{\n\t\t.name\t= \"allow_file_create\",\n\t\t.lname\t= \"Allow file create\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, allow_create),\n\t\t.help\t= \"Permit fio to create files, if they don't exist\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"allow_mounted_write\",\n\t\t.lname\t= \"Allow mounted write\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, allow_mounted_write),\n\t\t.help\t= \"Allow writes to a mounted partition\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_FILENAME,\n\t},\n\t{\n\t\t.name\t= \"pre_read\",\n\t\t.lname\t= \"Pre-read files\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, pre_read),\n\t\t.help\t= \"Pre-read files before starting official testing\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#ifdef FIO_HAVE_CPU_AFFINITY\n\t{\n\t\t.name\t= \"cpumask\",\n\t\t.lname\t= \"CPU mask\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.cb\t= str_cpumask_cb,\n\t\t.off1\t= offsetof(struct thread_options, cpumask),\n\t\t.help\t= \"CPU affinity mask\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"cpus_allowed\",\n\t\t.lname\t= \"CPUs allowed\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_cpus_allowed_cb,\n\t\t.off1\t= offsetof(struct thread_options, cpumask),\n\t\t.help\t= \"Set CPUs allowed\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"cpus_allowed_policy\",\n\t\t.lname\t= \"CPUs allowed distribution policy\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, cpus_allowed_policy),\n\t\t.help\t= \"Distribution policy for cpus_allowed\",\n\t\t.parent = \"cpus_allowed\",\n\t\t.prio\t= 1,\n\t\t.posval = {\n\t\t\t  { .ival = \"shared\",\n\t\t\t    .oval = FIO_CPUS_SHARED,\n\t\t\t    .help = \"Mask shared between threads\",\n\t\t\t  },\n\t\t\t  { .ival = \"split\",\n\t\t\t    .oval = FIO_CPUS_SPLIT,\n\t\t\t    .help = \"Mask split between threads\",\n\t\t\t  },\n\t\t},\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n#else\n\t{\n\t\t.name\t= \"cpumask\",\n\t\t.lname\t= \"CPU mask\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support CPU affinities\",\n\t},\n\t{\n\t\t.name\t= \"cpus_allowed\",\n\t\t.lname\t= \"CPUs allowed\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support CPU affinities\",\n\t},\n\t{\n\t\t.name\t= \"cpus_allowed_policy\",\n\t\t.lname\t= \"CPUs allowed distribution policy\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support CPU affinities\",\n\t},\n#endif\n#ifdef CONFIG_LIBNUMA\n\t{\n\t\t.name\t= \"numa_cpu_nodes\",\n\t\t.lname\t= \"NUMA CPU Nodes\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_numa_cpunodes_cb,\n\t\t.off1\t= offsetof(struct thread_options, numa_cpunodes),\n\t\t.help\t= \"NUMA CPU nodes bind\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"numa_mem_policy\",\n\t\t.lname\t= \"NUMA Memory Policy\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_numa_mpol_cb,\n\t\t.off1\t= offsetof(struct thread_options, numa_memnodes),\n\t\t.help\t= \"NUMA memory policy setup\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"numa_cpu_nodes\",\n\t\t.lname\t= \"NUMA CPU Nodes\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Build fio with libnuma-dev(el) to enable this option\",\n\t},\n\t{\n\t\t.name\t= \"numa_mem_policy\",\n\t\t.lname\t= \"NUMA Memory Policy\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Build fio with libnuma-dev(el) to enable this option\",\n\t},\n#endif\n#ifdef CONFIG_CUDA\n\t{\n\t\t.name\t= \"gpu_dev_id\",\n\t\t.lname\t= \"GPU device ID\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, gpu_dev_id),\n\t\t.help\t= \"Set GPU device ID for GPUDirect RDMA\",\n\t\t.def    = \"0\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#endif\n\t{\n\t\t.name\t= \"end_fsync\",\n\t\t.lname\t= \"End fsync\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, end_fsync),\n\t\t.help\t= \"Include fsync at the end of job\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"fsync_on_close\",\n\t\t.lname\t= \"Fsync on close\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, fsync_on_close),\n\t\t.help\t= \"fsync files on close\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"unlink\",\n\t\t.lname\t= \"Unlink file\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, unlink),\n\t\t.help\t= \"Unlink created files after job has completed\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"unlink_each_loop\",\n\t\t.lname\t= \"Unlink file after each loop of a job\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, unlink_each_loop),\n\t\t.help\t= \"Unlink created files after each loop in a job has completed\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_FILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"exitall\",\n\t\t.lname\t= \"Exit-all on terminate\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.cb\t= str_exitall_cb,\n\t\t.help\t= \"Terminate all jobs when one exits\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"exit_what\",\n\t\t.lname\t= \"What jobs to quit on terminate\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, exit_what),\n\t\t.help\t= \"Fine-grained control for exitall\",\n\t\t.def\t= \"group\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"group\",\n\t\t\t    .oval = TERMINATE_GROUP,\n\t\t\t    .help = \"exit_all=1 default behaviour\",\n\t\t\t  },\n\t\t\t  { .ival = \"stonewall\",\n\t\t\t    .oval = TERMINATE_STONEWALL,\n\t\t\t    .help = \"quit all currently running jobs; continue with next stonewall\",\n\t\t\t  },\n\t\t\t  { .ival = \"all\",\n\t\t\t    .oval = TERMINATE_ALL,\n\t\t\t    .help = \"Quit everything\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"exitall_on_error\",\n\t\t.lname\t= \"Exit-all on terminate in error\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, exitall_error),\n\t\t.help\t= \"Terminate all jobs when one exits in error\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"stonewall\",\n\t\t.lname\t= \"Wait for previous\",\n\t\t.alias\t= \"wait_for_previous\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, stonewall),\n\t\t.help\t= \"Insert a hard barrier between this job and previous\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"new_group\",\n\t\t.lname\t= \"New group\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, new_group),\n\t\t.help\t= \"Mark the start of a new group (for reporting)\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"thread\",\n\t\t.lname\t= \"Thread\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, use_thread),\n\t\t.help\t= \"Use threads instead of processes\",\n#ifdef CONFIG_NO_SHM\n\t\t.def\t= \"1\",\n\t\t.no_warn_def = 1,\n#endif\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_PROCESS,\n\t},\n\t{\n\t\t.name\t= \"per_job_logs\",\n\t\t.lname\t= \"Per Job Logs\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, per_job_logs),\n\t\t.help\t= \"Include job number in generated log files or not\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"write_bw_log\",\n\t\t.lname\t= \"Write bandwidth log\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, bw_log_file),\n\t\t.cb\t= str_write_bw_log_cb,\n\t\t.help\t= \"Write log of bandwidth during run\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"write_lat_log\",\n\t\t.lname\t= \"Write latency log\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, lat_log_file),\n\t\t.cb\t= str_write_lat_log_cb,\n\t\t.help\t= \"Write log of latency during run\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"write_iops_log\",\n\t\t.lname\t= \"Write IOPS log\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, iops_log_file),\n\t\t.cb\t= str_write_iops_log_cb,\n\t\t.help\t= \"Write log of IOPS during run\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_entries\",\n\t\t.lname\t= \"Log entries\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, log_entries),\n\t\t.help\t= \"Initial number of entries in a job IO log\",\n\t\t.def\t= __fio_stringify(DEF_LOG_ENTRIES),\n\t\t.minval\t= DEF_LOG_ENTRIES,\n\t\t.maxval\t= MAX_LOG_ENTRIES,\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_avg_msec\",\n\t\t.lname\t= \"Log averaging (msec)\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, log_avg_msec),\n\t\t.help\t= \"Average bw/iops/lat logs over this period of time\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_hist_msec\",\n\t\t.lname\t= \"Log histograms (msec)\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, log_hist_msec),\n\t\t.help\t= \"Dump completion latency histograms at frequency of this time value\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_hist_coarseness\",\n\t\t.lname\t= \"Histogram logs coarseness\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, log_hist_coarseness),\n\t\t.help\t= \"Integer in range [0,6]. Higher coarseness outputs\"\n\t\t\t\" fewer histogram bins per sample. The number of bins for\"\n\t\t\t\" these are [1216, 608, 304, 152, 76, 38, 19] respectively.\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"write_hist_log\",\n\t\t.lname\t= \"Write latency histogram logs\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, hist_log_file),\n\t\t.cb\t= str_write_hist_log_cb,\n\t\t.help\t= \"Write log of latency histograms during run\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_window_value\",\n\t\t.alias  = \"log_max_value\",\n\t\t.lname\t= \"Log maximum, average or both values\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, log_max),\n\t\t.help\t= \"Log max, average or both sample in a window\",\n\t\t.def\t= \"avg\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"avg\",\n\t\t\t    .oval = IO_LOG_SAMPLE_AVG,\n\t\t\t    .help = \"Log average value over the window\",\n\t\t\t  },\n\t\t\t  { .ival = \"max\",\n\t\t\t    .oval = IO_LOG_SAMPLE_MAX,\n\t\t\t    .help = \"Log maximum value in the window\",\n\t\t\t  },\n\t\t\t  { .ival = \"both\",\n\t\t\t    .oval = IO_LOG_SAMPLE_BOTH,\n\t\t\t    .help = \"Log both average and maximum values over the window\"\n\t\t\t  },\n\t\t\t  /* Compatibility with former boolean values */\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = IO_LOG_SAMPLE_AVG,\n\t\t\t    .help = \"Alias for 'avg'\",\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = IO_LOG_SAMPLE_MAX,\n\t\t\t    .help = \"Alias for 'max'\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"log_offset\",\n\t\t.lname\t= \"Log offset of IO\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, log_offset),\n\t\t.help\t= \"Include offset of IO for each log entry\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_prio\",\n\t\t.lname\t= \"Log priority of IO\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, log_prio),\n\t\t.help\t= \"Include priority value of IO for each log entry\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"log_issue_time\",\n\t\t.lname\t= \"Log IO issue time\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, log_issue_time),\n\t\t.help\t= \"Include IO issue time for each log entry\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#ifdef CONFIG_ZLIB\n\t{\n\t\t.name\t= \"log_compression\",\n\t\t.lname\t= \"Log compression\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, log_gz),\n\t\t.help\t= \"Log in compressed chunks of this size\",\n\t\t.minval\t= 1024ULL,\n\t\t.maxval\t= 512 * 1024 * 1024ULL,\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#ifdef FIO_HAVE_CPU_AFFINITY\n\t{\n\t\t.name\t= \"log_compression_cpus\",\n\t\t.lname\t= \"Log Compression CPUs\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_log_cpus_allowed_cb,\n\t\t.off1\t= offsetof(struct thread_options, log_gz_cpumask),\n\t\t.parent = \"log_compression\",\n\t\t.help\t= \"Limit log compression to these CPUs\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"log_compression_cpus\",\n\t\t.lname\t= \"Log Compression CPUs\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support CPU affinities\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"log_store_compressed\",\n\t\t.lname\t= \"Log store compressed\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, log_gz_store),\n\t\t.help\t= \"Store logs in a compressed format\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"log_compression\",\n\t\t.lname\t= \"Log compression\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Install libz-dev(el) to get compression support\",\n\t},\n\t{\n\t\t.name\t= \"log_store_compressed\",\n\t\t.lname\t= \"Log store compressed\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Install libz-dev(el) to get compression support\",\n\t},\n#endif\n\t{\n\t\t.name = \"log_alternate_epoch\",\n\t\t.alias = \"log_unix_epoch\",\n\t\t.lname = \"Log epoch alternate\",\n\t\t.type = FIO_OPT_BOOL,\n\t\t.off1 = offsetof(struct thread_options, log_alternate_epoch),\n\t\t.help = \"Use alternate epoch time in log files. Uses the same epoch as that is used by clock_gettime with specified log_alternate_epoch_clock_id.\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group = FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name = \"log_alternate_epoch_clock_id\",\n\t\t.lname = \"Log alternate epoch clock_id\",\n\t\t.type = FIO_OPT_INT,\n\t\t.off1 = offsetof(struct thread_options, log_alternate_epoch_clock_id),\n\t\t.help = \"If log_alternate_epoch is true, this option specifies the clock_id from clock_gettime whose epoch should be used. If log_alternate_epoch is false, this option has no effect. Default value is 0, or CLOCK_REALTIME\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group = FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"block_error_percentiles\",\n\t\t.lname\t= \"Block error percentiles\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, block_error_hist),\n\t\t.help\t= \"Record trim block errors and make a histogram\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"bwavgtime\",\n\t\t.lname\t= \"Bandwidth average time\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, bw_avg_time),\n\t\t.help\t= \"Time window over which to calculate bandwidth\"\n\t\t\t  \" (msec)\",\n\t\t.def\t= \"500\",\n\t\t.parent\t= \"write_bw_log\",\n\t\t.hide\t= 1,\n\t\t.interval = 100,\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"iopsavgtime\",\n\t\t.lname\t= \"IOPS average time\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, iops_avg_time),\n\t\t.help\t= \"Time window over which to calculate IOPS (msec)\",\n\t\t.def\t= \"500\",\n\t\t.parent\t= \"write_iops_log\",\n\t\t.hide\t= 1,\n\t\t.interval = 100,\n\t\t.category = FIO_OPT_C_LOG,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"group_reporting\",\n\t\t.lname\t= \"Group reporting\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, group_reporting),\n\t\t.help\t= \"Do reporting on a per-group basis\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"stats\",\n\t\t.lname\t= \"Stats\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, stats),\n\t\t.help\t= \"Enable collection of stats\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"zero_buffers\",\n\t\t.lname\t= \"Zero I/O buffers\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, zero_buffers),\n\t\t.help\t= \"Init IO buffers to all zeroes\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"refill_buffers\",\n\t\t.lname\t= \"Refill I/O buffers\",\n\t\t.type\t= FIO_OPT_STR_SET,\n\t\t.off1\t= offsetof(struct thread_options, refill_buffers),\n\t\t.help\t= \"Refill IO buffers on every IO submit\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"scramble_buffers\",\n\t\t.lname\t= \"Scramble I/O buffers\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, scramble_buffers),\n\t\t.help\t= \"Slightly scramble buffers on every IO submit\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"buffer_pattern\",\n\t\t.lname\t= \"Buffer pattern\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_buffer_pattern_cb,\n\t\t.off1\t= offsetof(struct thread_options, buffer_pattern),\n\t\t.help\t= \"Fill pattern for IO buffers\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"buffer_compress_percentage\",\n\t\t.lname\t= \"Buffer compression percentage\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.cb\t= str_buffer_compress_cb,\n\t\t.off1\t= offsetof(struct thread_options, compress_percentage),\n\t\t.maxval\t= 100,\n\t\t.minval\t= 0,\n\t\t.help\t= \"How compressible the buffer is (approximately)\",\n\t\t.interval = 5,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"buffer_compress_chunk\",\n\t\t.lname\t= \"Buffer compression chunk size\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, compress_chunk),\n\t\t.parent\t= \"buffer_compress_percentage\",\n\t\t.hide\t= 1,\n\t\t.help\t= \"Size of compressible region in buffer\",\n\t\t.def\t= \"512\",\n\t\t.interval = 256,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"dedupe_percentage\",\n\t\t.lname\t= \"Dedupe percentage\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.cb\t= str_dedupe_cb,\n\t\t.off1\t= offsetof(struct thread_options, dedupe_percentage),\n\t\t.maxval\t= 100,\n\t\t.minval\t= 0,\n\t\t.help\t= \"Percentage of buffers that are dedupable\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"dedupe_global\",\n\t\t.lname\t= \"Global deduplication\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, dedupe_global),\n\t\t.help\t= \"Share deduplication buffers across jobs\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"dedupe_mode\",\n\t\t.lname\t= \"Dedupe mode\",\n\t\t.help\t= \"Mode for the deduplication buffer generation\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, dedupe_mode),\n\t\t.parent\t= \"dedupe_percentage\",\n\t\t.def\t= \"repeat\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t\t.posval\t= {\n\t\t\t   { .ival = \"repeat\",\n\t\t\t     .oval = DEDUPE_MODE_REPEAT,\n\t\t\t     .help = \"repeat previous page\",\n\t\t\t   },\n\t\t\t   { .ival = \"working_set\",\n\t\t\t     .oval = DEDUPE_MODE_WORKING_SET,\n\t\t\t     .help = \"choose a page randomly from limited working set defined in dedupe_working_set_percentage\",\n\t\t\t   },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"dedupe_working_set_percentage\",\n\t\t.lname\t= \"Dedupe working set percentage\",\n\t\t.help\t= \"Dedupe working set size in percentages from file or device size used to generate dedupe patterns from\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, dedupe_working_set_percentage),\n\t\t.parent\t= \"dedupe_percentage\",\n\t\t.def\t= \"5\",\n\t\t.maxval\t= 100,\n\t\t.minval\t= 0,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_BUF,\n\t},\n\t{\n\t\t.name\t= \"clat_percentiles\",\n\t\t.lname\t= \"Completion latency percentiles\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, clat_percentiles),\n\t\t.help\t= \"Enable the reporting of completion latency percentiles\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"lat_percentiles\",\n\t\t.lname\t= \"IO latency percentiles\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, lat_percentiles),\n\t\t.help\t= \"Enable the reporting of IO latency percentiles\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"slat_percentiles\",\n\t\t.lname\t= \"Submission latency percentiles\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, slat_percentiles),\n\t\t.help\t= \"Enable the reporting of submission latency percentiles\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"percentile_list\",\n\t\t.lname\t= \"Percentile list\",\n\t\t.type\t= FIO_OPT_FLOAT_LIST,\n\t\t.off1\t= offsetof(struct thread_options, percentile_list),\n\t\t.off2\t= offsetof(struct thread_options, percentile_precision),\n\t\t.help\t= \"Specify a custom list of percentiles to report for \"\n\t\t\t  \"completion latency and block errors\",\n\t\t.def    = \"1:5:10:20:30:40:50:60:70:80:90:95:99:99.5:99.9:99.95:99.99\",\n\t\t.maxlen\t= FIO_IO_U_LIST_MAX_LEN,\n\t\t.minfp\t= 0.0,\n\t\t.maxfp\t= 100.0,\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"significant_figures\",\n\t\t.lname\t= \"Significant figures\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, sig_figs),\n\t\t.maxval\t= 10,\n\t\t.minval\t= 1,\n\t\t.help\t= \"Significant figures for output-format set to normal\",\n\t\t.def\t= \"4\",\n\t\t.interval = 1,\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\n#ifdef FIO_HAVE_DISK_UTIL\n\t{\n\t\t.name\t= \"disk_util\",\n\t\t.lname\t= \"Disk utilization\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, do_disk_util),\n\t\t.help\t= \"Log disk utilization statistics\",\n\t\t.def\t= \"1\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n#else\n\t{\n\t\t.name\t= \"disk_util\",\n\t\t.lname\t= \"Disk utilization\",\n\t\t.type\t= FIO_OPT_UNSUPPORTED,\n\t\t.help\t= \"Your platform does not support disk utilization\",\n\t},\n#endif\n\t{\n\t\t.name\t= \"gtod_reduce\",\n\t\t.lname\t= \"Reduce gettimeofday() calls\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.help\t= \"Greatly reduce number of gettimeofday() calls\",\n\t\t.cb\t= str_gtod_reduce_cb,\n\t\t.def\t= \"0\",\n\t\t.hide_on_set = 1,\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"disable_lat\",\n\t\t.lname\t= \"Disable all latency stats\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, disable_lat),\n\t\t.help\t= \"Disable latency numbers\",\n\t\t.parent\t= \"gtod_reduce\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"disable_clat\",\n\t\t.lname\t= \"Disable completion latency stats\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, disable_clat),\n\t\t.help\t= \"Disable completion latency numbers\",\n\t\t.parent\t= \"gtod_reduce\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"disable_slat\",\n\t\t.lname\t= \"Disable submission latency stats\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, disable_slat),\n\t\t.help\t= \"Disable submission latency numbers\",\n\t\t.parent\t= \"gtod_reduce\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"disable_bw_measurement\",\n\t\t.alias\t= \"disable_bw\",\n\t\t.lname\t= \"Disable bandwidth stats\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, disable_bw),\n\t\t.help\t= \"Disable bandwidth logging\",\n\t\t.parent\t= \"gtod_reduce\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_STAT,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"gtod_cpu\",\n\t\t.lname\t= \"Dedicated gettimeofday() CPU\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, gtod_cpu),\n\t\t.help\t= \"Set up dedicated gettimeofday() thread on this CPU\",\n\t\t.verify\t= gtod_cpu_verify,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CLOCK,\n\t},\n\t{\n\t\t.name\t= \"job_start_clock_id\",\n\t\t.lname\t= \"Job start clock_id\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, job_start_clock_id),\n\t\t.help\t= \"The clock_id passed to the call to clock_gettime used to record job_start in the json output format. Default is 0, or CLOCK_REALTIME\",\n\t\t.verify\t= gtod_cpu_verify,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CLOCK,\n\t},\n\t{\n\t\t.name\t= \"unified_rw_reporting\",\n\t\t.lname\t= \"Unified RW Reporting\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, unified_rw_rep),\n\t\t.help\t= \"Unify reporting across data direction\",\n\t\t.def\t= \"none\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t\t.posval\t= {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = UNIFIED_SPLIT,\n\t\t\t    .help = \"Normal statistics reporting\",\n\t\t\t  },\n\t\t\t  { .ival = \"mixed\",\n\t\t\t    .oval = UNIFIED_MIXED,\n\t\t\t    .help = \"Statistics are summed per data direction and reported together\",\n\t\t\t  },\n\t\t\t  { .ival = \"both\",\n\t\t\t    .oval = UNIFIED_BOTH,\n\t\t\t    .help = \"Statistics are reported normally, followed by the mixed statistics\"\n\t\t\t  },\n\t\t\t  /* Compatibility with former boolean values */\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = UNIFIED_SPLIT,\n\t\t\t    .help = \"Alias for 'none'\",\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = UNIFIED_MIXED,\n\t\t\t    .help = \"Alias for 'mixed'\",\n\t\t\t  },\n\t\t\t  { .ival = \"2\",\n\t\t\t    .oval = UNIFIED_BOTH,\n\t\t\t    .help = \"Alias for 'both'\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"continue_on_error\",\n\t\t.lname\t= \"Continue on error\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, continue_on_error),\n\t\t.help\t= \"Continue on non-fatal errors during IO\",\n\t\t.def\t= \"none\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_ERR,\n\t\t.posval = {\n\t\t\t  { .ival = \"none\",\n\t\t\t    .oval = ERROR_TYPE_NONE,\n\t\t\t    .help = \"Exit when an error is encountered\",\n\t\t\t  },\n\t\t\t  { .ival = \"read\",\n\t\t\t    .oval = ERROR_TYPE_READ,\n\t\t\t    .help = \"Continue on read errors only\",\n\t\t\t  },\n\t\t\t  { .ival = \"write\",\n\t\t\t    .oval = ERROR_TYPE_WRITE,\n\t\t\t    .help = \"Continue on write errors only\",\n\t\t\t  },\n\t\t\t  { .ival = \"io\",\n\t\t\t    .oval = ERROR_TYPE_READ | ERROR_TYPE_WRITE,\n\t\t\t    .help = \"Continue on any IO errors\",\n\t\t\t  },\n\t\t\t  { .ival = \"verify\",\n\t\t\t    .oval = ERROR_TYPE_VERIFY,\n\t\t\t    .help = \"Continue on verify errors only\",\n\t\t\t  },\n\t\t\t  { .ival = \"all\",\n\t\t\t    .oval = ERROR_TYPE_ANY,\n\t\t\t    .help = \"Continue on all io and verify errors\",\n\t\t\t  },\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = ERROR_TYPE_NONE,\n\t\t\t    .help = \"Alias for 'none'\",\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = ERROR_TYPE_ANY,\n\t\t\t    .help = \"Alias for 'all'\",\n\t\t\t  },\n\t\t},\n\t},\n\t{\n\t\t.name\t= \"ignore_error\",\n\t\t.lname\t= \"Ignore Error\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.cb\t= str_ignore_error_cb,\n\t\t.off1\t= offsetof(struct thread_options, ignore_error_nr),\n\t\t.help\t= \"Set a specific list of errors to ignore\",\n\t\t.parent\t= \"rw\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_ERR,\n\t},\n\t{\n\t\t.name\t= \"error_dump\",\n\t\t.lname\t= \"Error Dump\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, error_dump),\n\t\t.def\t= \"0\",\n\t\t.help\t= \"Dump info on each error\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_ERR,\n\t},\n\t{\n\t\t.name\t= \"profile\",\n\t\t.lname\t= \"Profile\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, profile),\n\t\t.help\t= \"Select a specific builtin performance test\",\n\t\t.category = FIO_OPT_C_PROFILE,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"cgroup\",\n\t\t.lname\t= \"Cgroup\",\n\t\t.type\t= FIO_OPT_STR_STORE,\n\t\t.off1\t= offsetof(struct thread_options, cgroup),\n\t\t.help\t= \"Add job to cgroup of this name\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CGROUP,\n\t},\n\t{\n\t\t.name\t= \"cgroup_nodelete\",\n\t\t.lname\t= \"Cgroup no-delete\",\n\t\t.type\t= FIO_OPT_BOOL,\n\t\t.off1\t= offsetof(struct thread_options, cgroup_nodelete),\n\t\t.help\t= \"Do not delete cgroups after job completion\",\n\t\t.def\t= \"0\",\n\t\t.parent\t= \"cgroup\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CGROUP,\n\t},\n\t{\n\t\t.name\t= \"cgroup_weight\",\n\t\t.lname\t= \"Cgroup weight\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, cgroup_weight),\n\t\t.help\t= \"Use given weight for cgroup\",\n\t\t.minval = 100,\n\t\t.maxval\t= 1000,\n\t\t.parent\t= \"cgroup\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CGROUP,\n\t},\n\t{\n\t\t.name\t= \"uid\",\n\t\t.lname\t= \"User ID\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, uid),\n\t\t.help\t= \"Run job with this user ID\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"gid\",\n\t\t.lname\t= \"Group ID\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, gid),\n\t\t.help\t= \"Run job with this group ID\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_CRED,\n\t},\n\t{\n\t\t.name\t= \"kb_base\",\n\t\t.lname\t= \"KB Base\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, kb_base),\n\t\t.prio\t= 1,\n\t\t.def\t= \"1024\",\n\t\t.posval = {\n\t\t\t  { .ival = \"1024\",\n\t\t\t    .oval = 1024,\n\t\t\t    .help = \"Inputs invert IEC and SI prefixes (for compatibility); outputs prefer binary\",\n\t\t\t  },\n\t\t\t  { .ival = \"1000\",\n\t\t\t    .oval = 1000,\n\t\t\t    .help = \"Inputs use IEC and SI prefixes; outputs prefer SI\",\n\t\t\t  },\n\t\t},\n\t\t.help\t= \"Unit prefix interpretation for quantities of data (IEC and SI)\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"unit_base\",\n\t\t.lname\t= \"Unit for quantities of data (Bits or Bytes)\",\n\t\t.type\t= FIO_OPT_STR,\n\t\t.off1\t= offsetof(struct thread_options, unit_base),\n\t\t.prio\t= 1,\n\t\t.posval = {\n\t\t\t  { .ival = \"0\",\n\t\t\t    .oval = N2S_NONE,\n\t\t\t    .help = \"Auto-detect\",\n\t\t\t  },\n\t\t\t  { .ival = \"8\",\n\t\t\t    .oval = N2S_BYTEPERSEC,\n\t\t\t    .help = \"Normal (byte based)\",\n\t\t\t  },\n\t\t\t  { .ival = \"1\",\n\t\t\t    .oval = N2S_BITPERSEC,\n\t\t\t    .help = \"Bit based\",\n\t\t\t  },\n\t\t},\n\t\t.help\t= \"Bit multiple of result summary data (8 for byte, 1 for bit)\",\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"hugepage-size\",\n\t\t.lname\t= \"Hugepage size\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, hugepage_size),\n\t\t.help\t= \"When using hugepages, specify size of each page\",\n\t\t.def\t= __fio_stringify(FIO_HUGE_PAGE),\n\t\t.interval = 1024 * 1024,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group\t= FIO_OPT_G_INVALID,\n\t},\n\t{\n\t\t.name\t= \"flow_id\",\n\t\t.lname\t= \"I/O flow ID\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, flow_id),\n\t\t.help\t= \"The flow index ID to use\",\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_FLOW,\n\t},\n\t{\n\t\t.name\t= \"flow\",\n\t\t.lname\t= \"I/O flow weight\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, flow),\n\t\t.help\t= \"Weight for flow control of this job\",\n\t\t.parent\t= \"flow_id\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.maxval\t= FLOW_MAX_WEIGHT,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_FLOW,\n\t},\n\t{\n\t\t.name\t= \"flow_watermark\",\n\t\t.lname\t= \"I/O flow watermark\",\n\t\t.type\t= FIO_OPT_SOFT_DEPRECATED,\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_FLOW,\n\t},\n\t{\n\t\t.name\t= \"flow_sleep\",\n\t\t.lname\t= \"I/O flow sleep\",\n\t\t.type\t= FIO_OPT_INT,\n\t\t.off1\t= offsetof(struct thread_options, flow_sleep),\n\t\t.help\t= \"How many microseconds to sleep after being held\"\n\t\t\t\" back by the flow control mechanism\",\n\t\t.parent\t= \"flow_id\",\n\t\t.hide\t= 1,\n\t\t.def\t= \"0\",\n\t\t.category = FIO_OPT_C_IO,\n\t\t.group\t= FIO_OPT_G_IO_FLOW,\n\t},\n\t{\n\t\t.name   = \"steadystate\",\n\t\t.lname  = \"Steady state threshold\",\n\t\t.alias  = \"ss\",\n\t\t.type   = FIO_OPT_STR,\n\t\t.off1   = offsetof(struct thread_options, ss_state),\n\t\t.cb\t= str_steadystate_cb,\n\t\t.help   = \"Define the criterion and limit to judge when a job has reached steady state\",\n\t\t.def\t= \"iops_slope:0.01%\",\n\t\t.posval\t= {\n\t\t\t  { .ival = \"iops\",\n\t\t\t    .oval = FIO_SS_IOPS,\n\t\t\t    .help = \"maximum mean deviation of IOPS measurements\",\n\t\t\t  },\n\t\t\t  { .ival = \"iops_slope\",\n\t\t\t    .oval = FIO_SS_IOPS_SLOPE,\n\t\t\t    .help = \"slope calculated from IOPS measurements\",\n\t\t\t  },\n\t\t\t  { .ival = \"bw\",\n\t\t\t    .oval = FIO_SS_BW,\n\t\t\t    .help = \"maximum mean deviation of bandwidth measurements\",\n\t\t\t  },\n\t\t\t  {\n\t\t\t    .ival = \"bw_slope\",\n\t\t\t    .oval = FIO_SS_BW_SLOPE,\n\t\t\t    .help = \"slope calculated from bandwidth measurements\",\n\t\t\t  },\n\t\t},\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group  = FIO_OPT_G_RUNTIME,\n\t},\n        {\n\t\t.name   = \"steadystate_duration\",\n\t\t.lname  = \"Steady state duration\",\n\t\t.alias  = \"ss_dur\",\n\t\t.parent\t= \"steadystate\",\n\t\t.type   = FIO_OPT_STR_VAL_TIME,\n\t\t.off1   = offsetof(struct thread_options, ss_dur),\n\t\t.help   = \"Stop workload upon attaining steady state for specified duration\",\n\t\t.def    = \"0\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group  = FIO_OPT_G_RUNTIME,\n\t},\n        {\n\t\t.name   = \"steadystate_ramp_time\",\n\t\t.lname  = \"Steady state ramp time\",\n\t\t.alias  = \"ss_ramp\",\n\t\t.parent\t= \"steadystate\",\n\t\t.type   = FIO_OPT_STR_VAL_TIME,\n\t\t.off1   = offsetof(struct thread_options, ss_ramp_time),\n\t\t.help   = \"Delay before initiation of data collection for steady state job termination testing\",\n\t\t.def    = \"0\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group  = FIO_OPT_G_RUNTIME,\n\t},\n        {\n\t\t.name   = \"steadystate_check_interval\",\n\t\t.lname  = \"Steady state check interval\",\n\t\t.alias  = \"ss_interval\",\n\t\t.parent\t= \"steadystate\",\n\t\t.type   = FIO_OPT_STR_VAL_TIME,\n\t\t.off1   = offsetof(struct thread_options, ss_check_interval),\n\t\t.help   = \"Polling interval for the steady state check (too low means steadystate will not converge)\",\n\t\t.def    = \"1\",\n\t\t.is_seconds = 1,\n\t\t.is_time = 1,\n\t\t.category = FIO_OPT_C_GENERAL,\n\t\t.group  = FIO_OPT_G_RUNTIME,\n\t},\n\t{\n\t\t.name = NULL,\n\t},\n};\n\nstatic void add_to_lopt(struct option *lopt, struct fio_option *o,\n\t\t\tconst char *name, int val)\n{\n\tlopt->name = (char *) name;\n\tlopt->val = val;\n\tif (o->type == FIO_OPT_STR_SET)\n\t\tlopt->has_arg = optional_argument;\n\telse\n\t\tlopt->has_arg = required_argument;\n}\n\nstatic void options_to_lopts(struct fio_option *opts,\n\t\t\t      struct option *long_options,\n\t\t\t      int i, int option_type)\n{\n\tstruct fio_option *o = &opts[0];\n\twhile (o->name) {\n\t\tadd_to_lopt(&long_options[i], o, o->name, option_type);\n\t\tif (o->alias) {\n\t\t\ti++;\n\t\t\tadd_to_lopt(&long_options[i], o, o->alias, option_type);\n\t\t}\n\n\t\ti++;\n\t\to++;\n\t\tassert(i < FIO_NR_OPTIONS);\n\t}\n}\n\nvoid fio_options_set_ioengine_opts(struct option *long_options,\n\t\t\t\t   struct thread_data *td)\n{\n\tunsigned int i;\n\n\ti = 0;\n\twhile (long_options[i].name) {\n\t\tif (long_options[i].val == FIO_GETOPT_IOENGINE) {\n\t\t\tmemset(&long_options[i], 0, sizeof(*long_options));\n\t\t\tbreak;\n\t\t}\n\t\ti++;\n\t}\n\n\t/*\n\t * Just clear out the prior ioengine options.\n\t */\n\tif (!td || !td->eo)\n\t\treturn;\n\n\toptions_to_lopts(td->io_ops->options, long_options, i,\n\t\t\t FIO_GETOPT_IOENGINE);\n}\n\nvoid fio_options_dup_and_init(struct option *long_options)\n{\n\tunsigned int i;\n\n\toptions_init(fio_options);\n\n\ti = 0;\n\twhile (long_options[i].name)\n\t\ti++;\n\n\toptions_to_lopts(fio_options, long_options, i, FIO_GETOPT_JOB);\n}\n\nstruct fio_keyword {\n\tconst char *word;\n\tconst char *desc;\n\tchar *replace;\n};\n\nstatic struct fio_keyword fio_keywords[] = {\n\t{\n\t\t.word\t= \"$pagesize\",\n\t\t.desc\t= \"Page size in the system\",\n\t},\n\t{\n\t\t.word\t= \"$mb_memory\",\n\t\t.desc\t= \"Megabytes of memory online\",\n\t},\n\t{\n\t\t.word\t= \"$ncpus\",\n\t\t.desc\t= \"Number of CPUs online in the system\",\n\t},\n\t{\n\t\t.word\t= NULL,\n\t},\n};\n\nvoid fio_keywords_exit(void)\n{\n\tstruct fio_keyword *kw;\n\n\tkw = &fio_keywords[0];\n\twhile (kw->word) {\n\t\tfree(kw->replace);\n\t\tkw->replace = NULL;\n\t\tkw++;\n\t}\n}\n\nvoid fio_keywords_init(void)\n{\n\tunsigned long long mb_memory;\n\tchar buf[128];\n\tlong l;\n\n\tsprintf(buf, \"%lu\", (unsigned long) page_size);\n\tfio_keywords[0].replace = strdup(buf);\n\n\tmb_memory = os_phys_mem() / (1024 * 1024);\n\tsprintf(buf, \"%llu\", mb_memory);\n\tfio_keywords[1].replace = strdup(buf);\n\n\tl = cpus_configured();\n\tsprintf(buf, \"%lu\", l);\n\tfio_keywords[2].replace = strdup(buf);\n}\n\n#define BC_APP\t\t\"bc\"\n\nstatic char *bc_calc(char *str)\n{\n\tchar buf[128], *tmp;\n\tFILE *f;\n\tint ret;\n\n\t/*\n\t * No math, just return string\n\t */\n\tif ((!strchr(str, '+') && !strchr(str, '-') && !strchr(str, '*') &&\n\t     !strchr(str, '/')) || strchr(str, '\\''))\n\t\treturn str;\n\n\t/*\n\t * Split option from value, we only need to calculate the value\n\t */\n\ttmp = strchr(str, '=');\n\tif (!tmp)\n\t\treturn str;\n\n\ttmp++;\n\n\t/*\n\t * Prevent buffer overflows; such a case isn't reasonable anyway\n\t */\n\tif (strlen(str) >= 128 || strlen(tmp) > 100)\n\t\treturn str;\n\n\tsprintf(buf, \"which %s > /dev/null\", BC_APP);\n\tif (system(buf)) {\n\t\tlog_err(\"fio: bc is needed for performing math\\n\");\n\t\treturn NULL;\n\t}\n\n\tsprintf(buf, \"echo '%s' | %s\", tmp, BC_APP);\n\tf = popen(buf, \"r\");\n\tif (!f)\n\t\treturn NULL;\n\n\tret = fread(&buf[tmp - str], 1, 128 - (tmp - str), f);\n\tif (ret <= 0) {\n\t\tpclose(f);\n\t\treturn NULL;\n\t}\n\n\tpclose(f);\n\tbuf[(tmp - str) + ret - 1] = '\\0';\n\tmemcpy(buf, str, tmp - str);\n\tfree(str);\n\treturn strdup(buf);\n}\n\n/*\n * Return a copy of the input string with substrings of the form ${VARNAME}\n * substituted with the value of the environment variable VARNAME.  The\n * substitution always occurs, even if VARNAME is empty or the corresponding\n * environment variable undefined.\n */\nchar *fio_option_dup_subs(const char *opt)\n{\n\tchar out[OPT_LEN_MAX+1];\n\tchar in[OPT_LEN_MAX+1];\n\tchar *outptr = out;\n\tchar *inptr = in;\n\tchar *ch1, *ch2, *env;\n\tssize_t nchr = OPT_LEN_MAX;\n\tsize_t envlen;\n\n\tif (strlen(opt) + 1 > OPT_LEN_MAX) {\n\t\tlog_err(\"OPT_LEN_MAX (%d) is too small\\n\", OPT_LEN_MAX);\n\t\treturn NULL;\n\t}\n\n\tsnprintf(in, sizeof(in), \"%s\", opt);\n\n\twhile (*inptr && nchr > 0) {\n\t\tif (inptr[0] == '$' && inptr[1] == '{') {\n\t\t\tch2 = strchr(inptr, '}');\n\t\t\tif (ch2 && inptr+1 < ch2) {\n\t\t\t\tch1 = inptr+2;\n\t\t\t\tinptr = ch2+1;\n\t\t\t\t*ch2 = '\\0';\n\n\t\t\t\tenv = getenv(ch1);\n\t\t\t\tif (env) {\n\t\t\t\t\tenvlen = strlen(env);\n\t\t\t\t\tif (envlen <= nchr) {\n\t\t\t\t\t\tmemcpy(outptr, env, envlen);\n\t\t\t\t\t\toutptr += envlen;\n\t\t\t\t\t\tnchr -= envlen;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t*outptr++ = *inptr++;\n\t\t--nchr;\n\t}\n\n\t*outptr = '\\0';\n\treturn strdup(out);\n}\n\n/*\n * Look for reserved variable names and replace them with real values\n */\nstatic char *fio_keyword_replace(char *opt)\n{\n\tchar *s;\n\tint i;\n\tint docalc = 0;\n\n\tfor (i = 0; fio_keywords[i].word != NULL; i++) {\n\t\tstruct fio_keyword *kw = &fio_keywords[i];\n\n\t\twhile ((s = strstr(opt, kw->word)) != NULL) {\n\t\t\tchar *new = calloc(strlen(opt) + 1, 1);\n\t\t\tchar *o_org = opt;\n\t\t\tint olen = s - opt;\n\t\t\tint len;\n\n\t\t\t/*\n\t\t\t * Copy part of the string before the keyword and\n\t\t\t * sprintf() the replacement after it.\n\t\t\t */\n\t\t\tmemcpy(new, opt, olen);\n\t\t\tlen = sprintf(new + olen, \"%s\", kw->replace);\n\n\t\t\t/*\n\t\t\t * If there's more in the original string, copy that\n\t\t\t * in too\n\t\t\t */\n\t\t\topt += olen + strlen(kw->word);\n\t\t\t/* keeps final zero thanks to calloc */\n\t\t\tif (strlen(opt))\n\t\t\t\tmemcpy(new + olen + len, opt, strlen(opt));\n\n\t\t\t/*\n\t\t\t * replace opt and free the old opt\n\t\t\t */\n\t\t\topt = new;\n\t\t\tfree(o_org);\n\n\t\t\tdocalc = 1;\n\t\t}\n\t}\n\n\t/*\n\t * Check for potential math and invoke bc, if possible\n\t */\n\tif (docalc)\n\t\topt = bc_calc(opt);\n\n\treturn opt;\n}\n\nstatic char **dup_and_sub_options(char **opts, int num_opts)\n{\n\tint i;\n\tchar **opts_copy = malloc(num_opts * sizeof(*opts));\n\tfor (i = 0; i < num_opts; i++) {\n\t\topts_copy[i] = fio_option_dup_subs(opts[i]);\n\t\tif (!opts_copy[i])\n\t\t\tcontinue;\n\t\topts_copy[i] = fio_keyword_replace(opts_copy[i]);\n\t}\n\treturn opts_copy;\n}\n\nstatic void show_closest_option(const char *opt)\n{\n\tint best_option, best_distance;\n\tint i, distance;\n\tchar *name;\n\n\tif (!strlen(opt))\n\t\treturn;\n\n\tname = strdup(opt);\n\ti = 0;\n\twhile (name[i] != '\\0' && name[i] != '=')\n\t\ti++;\n\tname[i] = '\\0';\n\n\tbest_option = -1;\n\tbest_distance = INT_MAX;\n\ti = 0;\n\twhile (fio_options[i].name) {\n\t\tdistance = string_distance(name, fio_options[i].name);\n\t\tif (distance < best_distance) {\n\t\t\tbest_distance = distance;\n\t\t\tbest_option = i;\n\t\t}\n\t\ti++;\n\t}\n\n\tif (best_option != -1 && string_distance_ok(name, best_distance) &&\n\t    fio_options[best_option].type != FIO_OPT_UNSUPPORTED)\n\t\tlog_err(\"Did you mean %s?\\n\", fio_options[best_option].name);\n\n\tfree(name);\n}\n\nint fio_options_parse(struct thread_data *td, char **opts, int num_opts)\n{\n\tint i, ret, unknown;\n\tchar **opts_copy;\n\n\tsort_options(opts, fio_options, num_opts);\n\topts_copy = dup_and_sub_options(opts, num_opts);\n\n\tfor (ret = 0, i = 0, unknown = 0; i < num_opts; i++) {\n\t\tconst struct fio_option *o;\n\t\tint newret = parse_option(opts_copy[i], opts[i], fio_options,\n\t\t\t\t\t\t&o, &td->o, &td->opt_list);\n\n\t\tif (!newret && o)\n\t\t\tfio_option_mark_set(&td->o, o);\n\n\t\tif (opts_copy[i]) {\n\t\t\tif (newret && !o) {\n\t\t\t\tunknown++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfree(opts_copy[i]);\n\t\t\topts_copy[i] = NULL;\n\t\t}\n\n\t\tret |= newret;\n\t}\n\n\tif (unknown) {\n\t\tret |= ioengine_load(td);\n\t\tif (td->eo) {\n\t\t\tsort_options(opts_copy, td->io_ops->options, num_opts);\n\t\t\topts = opts_copy;\n\t\t}\n\t\tfor (i = 0; i < num_opts; i++) {\n\t\t\tconst struct fio_option *o = NULL;\n\t\t\tint newret = 1;\n\n\t\t\tif (!opts_copy[i])\n\t\t\t\tcontinue;\n\n\t\t\tif (td->eo)\n\t\t\t\tnewret = parse_option(opts_copy[i], opts[i],\n\t\t\t\t\t\t      td->io_ops->options, &o,\n\t\t\t\t\t\t      td->eo, &td->opt_list);\n\n\t\t\tret |= newret;\n\t\t\tif (!o) {\n\t\t\t\tlog_err(\"Bad option <%s>\\n\", opts[i]);\n\t\t\t\tshow_closest_option(opts[i]);\n\t\t\t}\n\t\t\tfree(opts_copy[i]);\n\t\t\topts_copy[i] = NULL;\n\t\t}\n\t}\n\n\tfree(opts_copy);\n\treturn ret;\n}\n\nint fio_cmd_option_parse(struct thread_data *td, const char *opt, char *val)\n{\n\tint ret;\n\n\tret = parse_cmd_option(opt, val, fio_options, &td->o, &td->opt_list);\n\tif (!ret) {\n\t\tconst struct fio_option *o;\n\n\t\to = find_option_c(fio_options, opt);\n\t\tif (o)\n\t\t\tfio_option_mark_set(&td->o, o);\n\t}\n\n\treturn ret;\n}\n\nint fio_cmd_ioengine_option_parse(struct thread_data *td, const char *opt,\n\t\t\t\tchar *val)\n{\n\treturn parse_cmd_option(opt, val, td->io_ops->options, td->eo,\n\t\t\t\t\t&td->opt_list);\n}\n\nvoid fio_fill_default_options(struct thread_data *td)\n{\n\ttd->o.magic = OPT_MAGIC;\n\tfill_default_options(&td->o, fio_options);\n}\n\nint fio_show_option_help(const char *opt)\n{\n\treturn show_cmd_help(fio_options, opt);\n}\n\n/*\n * dupe FIO_OPT_STR_STORE options\n */\nvoid fio_options_mem_dupe(struct thread_data *td)\n{\n\toptions_mem_dupe(fio_options, &td->o);\n\n\tif (td->eo && td->io_ops) {\n\t\tvoid *oldeo = td->eo;\n\n\t\ttd->eo = malloc(td->io_ops->option_struct_size);\n\t\tmemcpy(td->eo, oldeo, td->io_ops->option_struct_size);\n\t\toptions_mem_dupe(td->io_ops->options, td->eo);\n\t}\n}\n\nunsigned int fio_get_kb_base(void *data)\n{\n\tstruct thread_data *td = cb_data_to_td(data);\n\tstruct thread_options *o = &td->o;\n\tunsigned int kb_base = 0;\n\n\t/*\n\t * This is a hack... For private options, *data is not holding\n\t * a pointer to the thread_options, but to private data. This means\n\t * we can't safely dereference it, but magic is first so mem wise\n\t * it is valid. But this also means that if the job first sets\n\t * kb_base and expects that to be honored by private options,\n\t * it will be disappointed. We will return the global default\n\t * for this.\n\t */\n\tif (o && o->magic == OPT_MAGIC)\n\t\tkb_base = o->kb_base;\n\tif (!kb_base)\n\t\tkb_base = 1024;\n\n\treturn kb_base;\n}\n\nint add_option(const struct fio_option *o)\n{\n\tstruct fio_option *__o;\n\tint opt_index = 0;\n\n\t__o = fio_options;\n\twhile (__o->name) {\n\t\topt_index++;\n\t\t__o++;\n\t}\n\n\tif (opt_index + 1 == FIO_MAX_OPTS) {\n\t\tlog_err(\"fio: FIO_MAX_OPTS is too small\\n\");\n\t\treturn 1;\n\t}\n\n\tmemcpy(&fio_options[opt_index], o, sizeof(*o));\n\tfio_options[opt_index + 1].name = NULL;\n\treturn 0;\n}\n\nvoid invalidate_profile_options(const char *prof_name)\n{\n\tstruct fio_option *o;\n\n\to = fio_options;\n\twhile (o->name) {\n\t\tif (o->prof_name && !strcmp(o->prof_name, prof_name)) {\n\t\t\to->type = FIO_OPT_INVALID;\n\t\t\to->prof_name = NULL;\n\t\t}\n\t\to++;\n\t}\n}\n\nvoid add_opt_posval(const char *optname, const char *ival, const char *help)\n{\n\tstruct fio_option *o;\n\tunsigned int i;\n\n\to = find_option(fio_options, optname);\n\tif (!o)\n\t\treturn;\n\n\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\tif (o->posval[i].ival)\n\t\t\tcontinue;\n\n\t\to->posval[i].ival = ival;\n\t\to->posval[i].help = help;\n\t\tbreak;\n\t}\n}\n\nvoid del_opt_posval(const char *optname, const char *ival)\n{\n\tstruct fio_option *o;\n\tunsigned int i;\n\n\to = find_option(fio_options, optname);\n\tif (!o)\n\t\treturn;\n\n\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\tif (!o->posval[i].ival)\n\t\t\tcontinue;\n\t\tif (strcmp(o->posval[i].ival, ival))\n\t\t\tcontinue;\n\n\t\to->posval[i].ival = NULL;\n\t\to->posval[i].help = NULL;\n\t}\n}\n\nvoid fio_options_free(struct thread_data *td)\n{\n\toptions_free(fio_options, &td->o);\n\tif (td->eo && td->io_ops && td->io_ops->options) {\n\t\toptions_free(td->io_ops->options, td->eo);\n\t\tfree(td->eo);\n\t\ttd->eo = NULL;\n\t}\n}\n\nvoid fio_dump_options_free(struct thread_data *td)\n{\n\twhile (!flist_empty(&td->opt_list)) {\n\t\tstruct print_option *p;\n\n\t\tp = flist_first_entry(&td->opt_list, struct print_option, list);\n\t\tflist_del_init(&p->list);\n\t\tfree(p->name);\n\t\tfree(p->value);\n\t\tfree(p);\n\t}\n}\n\nstruct fio_option *fio_option_find(const char *name)\n{\n\treturn find_option(fio_options, name);\n}\n\nstatic struct fio_option *find_next_opt(struct fio_option *from,\n\t\t\t\t\tunsigned int off1)\n{\n\tstruct fio_option *opt;\n\n\tif (!from)\n\t\tfrom = &fio_options[0];\n\telse\n\t\tfrom++;\n\n\topt = NULL;\n\tdo {\n\t\tif (off1 == from->off1) {\n\t\t\topt = from;\n\t\t\tbreak;\n\t\t}\n\t\tfrom++;\n\t} while (from->name);\n\n\treturn opt;\n}\n\nstatic int opt_is_set(struct thread_options *o, struct fio_option *opt)\n{\n\tunsigned int opt_off, index, offset;\n\n\topt_off = opt - &fio_options[0];\n\tindex = opt_off / (8 * sizeof(uint64_t));\n\toffset = opt_off & ((8 * sizeof(uint64_t)) - 1);\n\treturn (o->set_options[index] & ((uint64_t)1 << offset)) != 0;\n}\n\nbool __fio_option_is_set(struct thread_options *o, unsigned int off1)\n{\n\tstruct fio_option *opt, *next;\n\n\tnext = NULL;\n\twhile ((opt = find_next_opt(next, off1)) != NULL) {\n\t\tif (opt_is_set(o, opt))\n\t\t\treturn true;\n\n\t\tnext = opt;\n\t}\n\n\treturn false;\n}\n\nvoid fio_option_mark_set(struct thread_options *o, const struct fio_option *opt)\n{\n\tunsigned int opt_off, index, offset;\n\n\topt_off = opt - &fio_options[0];\n\tindex = opt_off / (8 * sizeof(uint64_t));\n\toffset = opt_off & ((8 * sizeof(uint64_t)) - 1);\n\to->set_options[index] |= (uint64_t)1 << offset;\n}\n"
        },
        {
          "name": "options.h",
          "type": "blob",
          "size": 1.5810546875,
          "content": "#ifndef FIO_OPTION_H\n#define FIO_OPTION_H\n\n#define FIO_MAX_OPTS\t\t512\n\n#include <string.h>\n#include <inttypes.h>\n#include \"parse.h\"\n#include \"lib/types.h\"\n\nint add_option(const struct fio_option *);\nvoid invalidate_profile_options(const char *);\nextern char *exec_profile;\n\nvoid add_opt_posval(const char *, const char *, const char *);\nvoid del_opt_posval(const char *, const char *);\nstruct thread_data;\nvoid fio_options_free(struct thread_data *);\nvoid fio_dump_options_free(struct thread_data *);\nchar *get_next_str(char **ptr);\nint get_max_str_idx(char *input);\nchar* get_name_by_idx(char *input, int index);\nint set_name_idx(char *, size_t, char *, int, bool);\n\nextern char client_sockaddr_str[];  /* used with --client option */\n\nextern struct fio_option fio_options[FIO_MAX_OPTS];\n\nextern bool __fio_option_is_set(struct thread_options *, unsigned int off);\n\n#define fio_option_is_set(__td, name)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tconst unsigned int off = offsetof(struct thread_options, name);\t\\\n\tbool __r = __fio_option_is_set((__td), off);\t\t\t\\\n\t__r;\t\t\t\t\t\t\t\t\\\n})\n\nextern void fio_option_mark_set(struct thread_options *,\n\t\t\t\tconst struct fio_option *);\n\nstatic inline bool o_match(const struct fio_option *o, const char *opt)\n{\n\tif (!strcmp(o->name, opt))\n\t\treturn true;\n\telse if (o->alias && !strcmp(o->alias, opt))\n\t\treturn true;\n\n\treturn false;\n}\n\nextern struct fio_option *find_option(struct fio_option *, const char *);\nextern const struct fio_option *\nfind_option_c(const struct fio_option *, const char *);\nextern struct fio_option *fio_option_find(const char *);\nextern unsigned int fio_get_kb_base(void *);\n\n#endif\n"
        },
        {
          "name": "os",
          "type": "tree",
          "content": null
        },
        {
          "name": "oslib",
          "type": "tree",
          "content": null
        },
        {
          "name": "parse.c",
          "type": "blob",
          "size": 30.00390625,
          "content": "/*\n * This file contains the ini and command liner parser main.\n */\n#include <stdio.h>\n#include <stdlib.h>\n#include <ctype.h>\n#include <string.h>\n#include <errno.h>\n#include <limits.h>\n#include <float.h>\n\n#include \"compiler/compiler.h\"\n#include \"parse.h\"\n#include \"debug.h\"\n#include \"log.h\"\n#include \"options.h\"\n#include \"optgroup.h\"\n#include \"minmax.h\"\n#include \"lib/ieee754.h\"\n#include \"lib/pow2.h\"\n\n#ifdef CONFIG_ARITHMETIC\n#include \"y.tab.h\"\n#endif\n\nstatic const char *opt_type_names[] = {\n\t\"OPT_INVALID\",\n\t\"OPT_STR\",\n\t\"OPT_STR_ULL\",\n\t\"OPT_STR_MULTI\",\n\t\"OPT_STR_VAL\",\n\t\"OPT_STR_VAL_TIME\",\n\t\"OPT_STR_STORE\",\n\t\"OPT_RANGE\",\n\t\"OPT_INT\",\n\t\"OPT_ULL\",\n\t\"OPT_BOOL\",\n\t\"OPT_FLOAT_LIST\",\n\t\"OPT_STR_SET\",\n\t\"OPT_STR_VAL_ZONE\",\n\t\"OPT_DEPRECATED\",\n\t\"OPT_SOFT_DEPRECATED\",\n\t\"OPT_UNSUPPORTED\",\n};\n\nstatic const struct fio_option *__fio_options;\n\nstatic int vp_cmp(const void *p1, const void *p2)\n{\n\tconst struct value_pair *vp1 = p1;\n\tconst struct value_pair *vp2 = p2;\n\n\treturn strlen(vp2->ival) - strlen(vp1->ival);\n}\n\nstatic void posval_sort(const struct fio_option *o, struct value_pair *vpmap)\n{\n\tconst struct value_pair *vp;\n\tint entries;\n\n\tmemset(vpmap, 0, PARSE_MAX_VP * sizeof(struct value_pair));\n\n\tfor (entries = 0; entries < PARSE_MAX_VP; entries++) {\n\t\tvp = &o->posval[entries];\n\t\tif (!vp->ival || vp->ival[0] == '\\0')\n\t\t\tbreak;\n\n\t\tmemcpy(&vpmap[entries], vp, sizeof(*vp));\n\t}\n\n\tqsort(vpmap, entries, sizeof(struct value_pair), vp_cmp);\n}\n\nstatic void show_option_range(const struct fio_option *o,\n\t\t\t      ssize_t (*logger)(const char *format, ...))\n{\n\tif (o->type == FIO_OPT_FLOAT_LIST) {\n\t\tconst char *sep = \"\";\n\t\tif (!o->minfp && !o->maxfp)\n\t\t\treturn;\n\n\t\tlogger(\"%20s: \", \"range\");\n\t\tif (o->minfp != DBL_MIN) {\n\t\t\tlogger(\"min=%f\", o->minfp);\n\t\t\tsep = \", \";\n\t\t}\n\t\tif (o->maxfp != DBL_MAX)\n\t\t\tlogger(\"%smax=%f\", sep, o->maxfp);\n\t\tlogger(\"\\n\");\n\t} else if (!o->posval[0].ival) {\n\t\tif (!o->minval && !o->maxval)\n\t\t\treturn;\n\n\t\tlogger(\"%20s: min=%d\", \"range\", o->minval);\n\t\tif (o->maxval)\n\t\t\tlogger(\", max=%d\", o->maxval);\n\t\tlogger(\"\\n\");\n\t}\n}\n\nstatic void show_option_values(const struct fio_option *o)\n{\n\tint i;\n\n\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\tconst struct value_pair *vp = &o->posval[i];\n\n\t\tif (!vp->ival)\n\t\t\tcontinue;\n\n\t\tlog_info(\"%20s: %-10s\", i == 0 ? \"valid values\" : \"\", vp->ival);\n\t\tif (vp->help)\n\t\t\tlog_info(\" %s\", vp->help);\n\t\tlog_info(\"\\n\");\n\t}\n\n\tif (i)\n\t\tlog_info(\"\\n\");\n}\n\nstatic void show_option_help(const struct fio_option *o, int is_err)\n{\n\tconst char *typehelp[] = {\n\t\t[FIO_OPT_INVALID]\t  = \"invalid\",\n\t\t[FIO_OPT_STR]\t\t  = \"string (opt=bla)\",\n\t\t[FIO_OPT_STR_ULL]\t  = \"string (opt=bla)\",\n\t\t[FIO_OPT_STR_MULTI]\t  = \"string with possible k/m/g postfix (opt=4k)\",\n\t\t[FIO_OPT_STR_VAL]\t  = \"string (opt=bla)\",\n\t\t[FIO_OPT_STR_VAL_TIME]\t  = \"string with time postfix (opt=10s)\",\n\t\t[FIO_OPT_STR_STORE]\t  = \"string (opt=bla)\",\n\t\t[FIO_OPT_RANGE]\t\t  = \"one to three ranges (opt=1k-4k[,4k-8k[,1k-8k]])\",\n\t\t[FIO_OPT_INT]\t\t  = \"integer value (opt=100)\",\n\t\t[FIO_OPT_ULL]\t\t  = \"integer value (opt=100)\",\n\t\t[FIO_OPT_BOOL]\t\t  = \"boolean value (opt=1)\",\n\t\t[FIO_OPT_FLOAT_LIST]\t  = \"list of floating point values separated by ':' (opt=5.9:7.8)\",\n\t\t[FIO_OPT_STR_SET]\t  = \"empty or boolean value ([0|1])\",\n\t\t[FIO_OPT_DEPRECATED]\t  = \"deprecated\",\n\t\t[FIO_OPT_SOFT_DEPRECATED] = \"deprecated\",\n\t\t[FIO_OPT_UNSUPPORTED]\t  = \"unsupported\",\n\t};\n\tssize_t (*logger)(const char *format, ...);\n\n\tif (is_err)\n\t\tlogger = log_err;\n\telse\n\t\tlogger = log_info;\n\n\tif (o->alias)\n\t\tlogger(\"%20s: %s\\n\", \"alias\", o->alias);\n\n\tlogger(\"%20s: %s\\n\", \"type\", typehelp[o->type]);\n\tlogger(\"%20s: %s\\n\", \"default\", o->def ? o->def : \"no default\");\n\tif (o->prof_name)\n\t\tlogger(\"%20s: only for profile '%s'\\n\", \"valid\", o->prof_name);\n\tshow_option_range(o, logger);\n\tshow_option_values(o);\n}\n\nstatic unsigned long long get_mult_time(const char *str, int len,\n\t\t\t\t\tint is_seconds)\n{\n\tconst char *p = str;\n\tchar *c;\n\tunsigned long long mult = 1;\n\tint i;\n\n\t/*\n         * Go forward until we hit a non-digit, or +/- sign\n         */\n\twhile ((p - str) <= len) {\n\t\tif (!isdigit((int) *p) && (*p != '+') && (*p != '-'))\n\t\t\tbreak;\n\t\tp++;\n\t}\n\n\tif (!isalpha((int) *p)) {\n\t\tif (is_seconds)\n\t\t\treturn 1000000UL;\n\t\telse\n\t\t\treturn 1;\n\t}\n\n\tc = strdup(p);\n\tfor (i = 0; i < strlen(c); i++)\n\t\tc[i] = tolower((unsigned char)c[i]);\n\n\tif (!strncmp(\"us\", c, 2) || !strncmp(\"usec\", c, 4))\n\t\tmult = 1;\n\telse if (!strncmp(\"ms\", c, 2) || !strncmp(\"msec\", c, 4))\n\t\tmult = 1000;\n\telse if (!strcmp(\"s\", c))\n\t\tmult = 1000000;\n\telse if (!strcmp(\"m\", c))\n\t\tmult = 60 * 1000000UL;\n\telse if (!strcmp(\"h\", c))\n\t\tmult = 60 * 60 * 1000000UL;\n\telse if (!strcmp(\"d\", c))\n\t\tmult = 24 * 60 * 60 * 1000000ULL;\n\n\tfree(c);\n\treturn mult;\n}\n\nstatic int is_separator(char c)\n{\n\tswitch (c) {\n\tcase ':':\n\tcase '-':\n\tcase ',':\n\tcase '/':\n\t\treturn 1;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic unsigned long long __get_mult_bytes(const char *p, void *data,\n\t\t\t\t\t   int *percent)\n{\n\tunsigned int kb_base = fio_get_kb_base(data);\n\tunsigned long long ret = 1;\n\tunsigned int i, pow = 0, mult = kb_base;\n\tchar *c;\n\n\tif (!p)\n\t\treturn 1;\n\n\tc = strdup(p);\n\n\tfor (i = 0; i < strlen(c); i++) {\n\t\tc[i] = tolower((unsigned char)c[i]);\n\t\tif (is_separator(c[i])) {\n\t\t\tc[i] = '\\0';\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* If kb_base is 1000, use true units.\n\t * If kb_base is 1024, use opposite units.\n\t */\n\tif (!strncmp(\"pib\", c, 3)) {\n\t\tpow = 5;\n\t\tif (kb_base == 1000)\n\t\t\tmult = 1024;\n\t\telse if (kb_base == 1024)\n\t\t\tmult = 1000;\n\t} else if (!strncmp(\"tib\", c, 3)) {\n\t\tpow = 4;\n\t\tif (kb_base == 1000)\n\t\t\tmult = 1024;\n\t\telse if (kb_base == 1024)\n\t\t\tmult = 1000;\n\t} else if (!strncmp(\"gib\", c, 3)) {\n\t\tpow = 3;\n\t\tif (kb_base == 1000)\n\t\t\tmult = 1024;\n\t\telse if (kb_base == 1024)\n\t\t\tmult = 1000;\n\t} else if (!strncmp(\"mib\", c, 3)) {\n\t\tpow = 2;\n\t\tif (kb_base == 1000)\n\t\t\tmult = 1024;\n\t\telse if (kb_base == 1024)\n\t\t\tmult = 1000;\n\t} else if (!strncmp(\"kib\", c, 3)) {\n\t\tpow = 1;\n\t\tif (kb_base == 1000)\n\t\t\tmult = 1024;\n\t\telse if (kb_base == 1024)\n\t\t\tmult = 1000;\n\t} else if (!strncmp(\"p\", c, 1) || !strncmp(\"pb\", c, 2)) {\n\t\tpow = 5;\n\t} else if (!strncmp(\"t\", c, 1) || !strncmp(\"tb\", c, 2)) {\n\t\tpow = 4;\n\t} else if (!strncmp(\"g\", c, 1) || !strncmp(\"gb\", c, 2)) {\n\t\tpow = 3;\n\t} else if (!strncmp(\"m\", c, 1) || !strncmp(\"mb\", c, 2)) {\n\t\tpow = 2;\n\t} else if (!strncmp(\"k\", c, 1) || !strncmp(\"kb\", c, 2)) {\n\t\tpow = 1;\n\t} else if (!strncmp(\"%\", c, 1)) {\n\t\t*percent = 1;\n\t\tfree(c);\n\t\treturn ret;\n\t}\n\n\twhile (pow--)\n\t\tret *= (unsigned long long) mult;\n\n\tfree(c);\n\treturn ret;\n}\n\nstatic unsigned long long get_mult_bytes(const char *str, int len, void *data,\n\t\t\t\t\t int *percent)\n{\n\tconst char *p = str;\n\tint digit_seen = 0;\n\n\tif (len < 2)\n\t\treturn __get_mult_bytes(str, data, percent);\n\n\t/*\n\t * Go forward until we hit a non-digit, or +/- sign\n\t */\n\twhile ((p - str) <= len) {\n\t\tif (!isdigit((int) *p) &&\n\t\t    (((*p != '+') && (*p != '-')) || digit_seen))\n\t\t\tbreak;\n\t\tdigit_seen |= isdigit((int) *p);\n\t\tp++;\n\t}\n\n\tif (!isalpha((int) *p) && (*p != '%'))\n\t\tp = NULL;\n\n\treturn __get_mult_bytes(p, data, percent);\n}\n\nextern int evaluate_arithmetic_expression(const char *buffer, long long *ival,\n\t\t\t\t\t  double *dval, double implied_units,\n\t\t\t\t\t  int is_time);\n\n/*\n * Convert string into a floating number. Return 1 for success and 0 otherwise.\n */\nint str_to_float(const char *str, double *val, int is_time)\n{\n#ifdef CONFIG_ARITHMETIC\n\tint rc;\n\tlong long ival;\n\tdouble dval;\n\n\tif (str[0] == '(') {\n\t\trc = evaluate_arithmetic_expression(str, &ival, &dval, 1.0, is_time);\n\t\tif (!rc) {\n\t\t\t*val = dval;\n\t\t\treturn 1;\n\t\t}\n\t}\n#endif\n\treturn 1 == sscanf(str, \"%lf\", val);\n}\n\n/*\n * convert string into decimal value, noting any size suffix\n */\nint str_to_decimal(const char *str, long long *val, int kilo, void *data,\n\t\t   int is_seconds, int is_time)\n{\n\tint len, base;\n\tint rc = 1;\n#ifdef CONFIG_ARITHMETIC\n\tlong long ival;\n\tdouble dval;\n\tdouble implied_units = 1.0;\n#endif\n\n\tlen = strlen(str);\n\tif (!len)\n\t\treturn 1;\n\n#ifdef CONFIG_ARITHMETIC\n\tif (is_seconds)\n\t\timplied_units = 1000000.0;\n\tif (str[0] == '(')\n\t\trc = evaluate_arithmetic_expression(str, &ival, &dval, implied_units, is_time);\n\tif (str[0] == '(' && !rc) {\n\t\tif (!kilo && is_seconds)\n\t\t\t*val = ival / 1000000LL;\n\t\telse\n\t\t\t*val = ival;\n\t}\n#endif\n\n\tif (rc == 1) {\n\t\tchar *endptr;\n\n\t\tif (strstr(str, \"0x\") || strstr(str, \"0X\"))\n\t\t\tbase = 16;\n\t\telse\n\t\t\tbase = 10;\n\n\t\t*val = strtoll(str, &endptr, base);\n\t\tif (*val == 0 && endptr == str)\n\t\t\treturn 1;\n\t\tif (*val == LONG_MAX && errno == ERANGE)\n\t\t\treturn 1;\n\t}\n\n\tif (kilo) {\n\t\tunsigned long long mult;\n\t\tint perc = 0;\n\n\t\tmult = get_mult_bytes(str, len, data, &perc);\n\t\tif (perc)\n\t\t\t*val = -1ULL - *val;\n\t\telse\n\t\t\t*val *= mult;\n\t} else\n\t\t*val *= get_mult_time(str, len, is_seconds);\n\n\treturn 0;\n}\n\nint check_str_bytes(const char *p, long long *val, void *data)\n{\n\treturn str_to_decimal(p, val, 1, data, 0, 0);\n}\n\nint check_str_time(const char *p, long long *val, int is_seconds)\n{\n\treturn str_to_decimal(p, val, 0, NULL, is_seconds, 1);\n}\n\nvoid strip_blank_front(char **p)\n{\n\tchar *s = *p;\n\n\tif (!strlen(s))\n\t\treturn;\n\twhile (isspace((int) *s))\n\t\ts++;\n\n\t*p = s;\n}\n\nvoid strip_blank_end(char *p)\n{\n\tchar *start = p, *s;\n\n\tif (!strlen(p))\n\t\treturn;\n\n\ts = strchr(p, ';');\n\tif (s)\n\t\t*s = '\\0';\n\ts = strchr(p, '#');\n\tif (s)\n\t\t*s = '\\0';\n\tif (s)\n\t\tp = s;\n\n\ts = p + strlen(p);\n\twhile ((isspace((int) *s) || iscntrl((int) *s)) && (s > start))\n\t\ts--;\n\n\t*(s + 1) = '\\0';\n}\n\nstatic int check_range_bytes(const char *str, long long *val, void *data)\n{\n\tlong long __val;\n\n\tif (!str_to_decimal(str, &__val, 1, data, 0, 0)) {\n\t\t*val = __val;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic int check_int(const char *p, int *val)\n{\n\tif (!strlen(p))\n\t\treturn 1;\n\tif (strstr(p, \"0x\") || strstr(p, \"0X\")) {\n\t\tif (sscanf(p, \"%x\", val) == 1)\n\t\t\treturn 0;\n\t} else {\n\t\tif (sscanf(p, \"%u\", val) == 1)\n\t\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic size_t opt_len(const char *str)\n{\n\tchar delimiter[] = {',', ':'};\n\tchar *postfix;\n\tunsigned int i;\n\n\tfor (i = 0; i < FIO_ARRAY_SIZE(delimiter); i++) {\n\t\tpostfix = strchr(str, delimiter[i]);\n\t\tif (postfix)\n\t\t\treturn (int)(postfix - str);\n\t}\n\n\treturn strlen(str);\n}\n\nstatic int str_match_len(const struct value_pair *vp, const char *str)\n{\n\treturn max(strlen(vp->ival), opt_len(str));\n}\n\n#define val_store(ptr, val, off, or, data, o)\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\tptr = td_var((data), (o), (off));\t\\\n\t\tif ((or))\t\t\t\t\\\n\t\t\t*ptr |= (val);\t\t\t\\\n\t\telse\t\t\t\t\t\\\n\t\t\t*ptr = (val);\t\t\t\\\n\t} while (0)\n\nstatic const char *opt_type_name(const struct fio_option *o)\n{\n\tcompiletime_assert(FIO_ARRAY_SIZE(opt_type_names) - 1 == FIO_OPT_UNSUPPORTED,\n\t\t\t\t\"opt_type_names[] index\");\n\n\tif (o->type <= FIO_OPT_UNSUPPORTED)\n\t\treturn opt_type_names[o->type];\n\n\treturn \"OPT_UNKNOWN?\";\n}\n\nstatic bool val_too_large(const struct fio_option *o, unsigned long long val,\n\t\t\t  bool is_uint)\n{\n\tif (!o->maxval)\n\t\treturn false;\n\n\tif (is_uint) {\n\t\tif ((int) val < 0)\n\t\t\treturn (int) val > (int) o->maxval;\n\t\treturn (unsigned int) val > o->maxval;\n\t}\n\n\treturn val > o->maxval;\n}\n\nstatic bool val_too_small(const struct fio_option *o, unsigned long long val,\n\t\t\t  bool is_uint)\n{\n\tif (!o->minval)\n\t\treturn false;\n\n\tif (is_uint)\n\t\treturn (int) val < o->minval;\n\n\treturn val < o->minval;\n}\n\nstatic int __handle_option(const struct fio_option *o, const char *ptr,\n\t\t\t   void *data, int first, int more, int curr)\n{\n\tint il=0, *ilp;\n\tfio_fp64_t *flp;\n\tlong long ull, *ullp;\n\tlong ul2;\n\tlong long ull1, ull2;\n\tdouble uf;\n\tchar **cp = NULL;\n\tint ret = 0, is_time = 0;\n\tconst struct value_pair *vp;\n\tstruct value_pair posval[PARSE_MAX_VP];\n\tint i, all_skipped = 1;\n\n\tdprint(FD_PARSE, \"__handle_option=%s, type=%s, ptr=%s\\n\", o->name,\n\t\t\t\t\t\t\topt_type_name(o), ptr);\n\n\tif (!ptr && o->type != FIO_OPT_STR_SET && o->type != FIO_OPT_STR) {\n\t\tlog_err(\"Option %s requires an argument\\n\", o->name);\n\t\treturn 1;\n\t}\n\n\tswitch (o->type) {\n\tcase FIO_OPT_STR:\n\tcase FIO_OPT_STR_ULL:\n\tcase FIO_OPT_STR_MULTI: {\n\t\tfio_opt_str_fn *fn = o->cb;\n\n\t\tposval_sort(o, posval);\n\n\t\tret = 1;\n\t\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\t\tvp = &posval[i];\n\t\t\tif (!vp->ival || vp->ival[0] == '\\0')\n\t\t\t\tcontinue;\n\t\t\tall_skipped = 0;\n\t\t\tif (!ptr)\n\t\t\t\tbreak;\n\t\t\tif (!strncmp(vp->ival, ptr, str_match_len(vp, ptr))) {\n\t\t\t\tret = 0;\n\t\t\t\tif (!o->off1)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (o->type == FIO_OPT_STR_ULL)\n\t\t\t\t\tval_store(ullp, vp->oval, o->off1, vp->orval, data, o);\n\t\t\t\telse\n\t\t\t\t\tval_store(ilp, vp->oval, o->off1, vp->orval, data, o);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (ret && !all_skipped)\n\t\t\tshow_option_values(o);\n\t\telse if (fn)\n\t\t\tret = fn(data, ptr);\n\t\tbreak;\n\t}\n\tcase FIO_OPT_STR_VAL_TIME:\n\t\tis_time = 1;\n\t\tfio_fallthrough;\n\tcase FIO_OPT_ULL:\n\tcase FIO_OPT_INT:\n\tcase FIO_OPT_STR_VAL:\n\tcase FIO_OPT_STR_VAL_ZONE:\n\t{\n\t\tfio_opt_str_val_fn *fn = o->cb;\n\t\tchar tmp[128], *p;\n\t\tsize_t len = strlen(ptr);\n\n\t\tif (len > 0 && ptr[len - 1] == 'z') {\n\t\t\tif (o->type == FIO_OPT_STR_VAL_ZONE) {\n\t\t\t\tchar *ep;\n\t\t\t\tunsigned long long val;\n\n\t\t\t\terrno = 0;\n\t\t\t\tval = strtoul(ptr, &ep, 10);\n\t\t\t\tif (errno == 0 && ep != ptr && *ep == 'z') {\n\t\t\t\t\tull = ZONE_BASE_VAL + (uint32_t)val;\n\t\t\t\t\tret = 0;\n\t\t\t\t\tgoto store_option_value;\n\t\t\t\t} else {\n\t\t\t\t\tlog_err(\"%s: unexpected zone value '%s'\\n\",\n\t\t\t\t\t\to->name, ptr);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog_err(\"%s: 'z' suffix isn't applicable\\n\",\n\t\t\t\t\to->name);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_time && o->is_time)\n\t\t\tis_time = o->is_time;\n\n\t\tsnprintf(tmp, sizeof(tmp), \"%s\", ptr);\n\t\tp = strchr(tmp, ',');\n\t\tif (p)\n\t\t\t*p = '\\0';\n\n\t\tif (is_time)\n\t\t\tret = check_str_time(tmp, &ull, o->is_seconds);\n\t\telse\n\t\t\tret = check_str_bytes(tmp, &ull, data);\n\n\t\tdprint(FD_PARSE, \"  ret=%d, out=%llu\\n\", ret, ull);\n\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (o->pow2 && !is_power_of_2(ull)) {\n\t\t\tlog_err(\"%s: must be a power-of-2\\n\", o->name);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (val_too_large(o, ull, o->type == FIO_OPT_INT)) {\n\t\t\tlog_err(\"%s: max value out of range: %llu\"\n\t\t\t\t\" (%llu max)\\n\", o->name, ull, o->maxval);\n\t\t\treturn 1;\n\t\t}\n\t\tif (val_too_small(o, ull, o->type == FIO_OPT_INT)) {\n\t\t\tlog_err(\"%s: min value out of range: %lld\"\n\t\t\t\t\" (%d min)\\n\", o->name, ull, o->minval);\n\t\t\treturn 1;\n\t\t}\n\t\tif (o->posval[0].ival) {\n\t\t\tposval_sort(o, posval);\n\n\t\t\tret = 1;\n\t\t\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\t\t\tvp = &posval[i];\n\t\t\t\tif (!vp->ival || vp->ival[0] == '\\0')\n\t\t\t\t\tcontinue;\n\t\t\t\tif (vp->oval == ull) {\n\t\t\t\t\tret = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tlog_err(\"fio: value %llu not allowed:\\n\", ull);\n\t\t\t\tshow_option_values(o);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\nstore_option_value:\n\t\tif (fn)\n\t\t\tret = fn(data, &ull);\n\t\telse {\n\t\t\tif (o->type == FIO_OPT_INT) {\n\t\t\t\tif (first)\n\t\t\t\t\tval_store(ilp, ull, o->off1, 0, data, o);\n\t\t\t\tif (curr == 1) {\n\t\t\t\t\tif (o->off2)\n\t\t\t\t\t\tval_store(ilp, ull, o->off2, 0, data, o);\n\t\t\t\t}\n\t\t\t\tif (curr == 2) {\n\t\t\t\t\tif (o->off3)\n\t\t\t\t\t\tval_store(ilp, ull, o->off3, 0, data, o);\n\t\t\t\t}\n\t\t\t\tif (!more) {\n\t\t\t\t\tif (curr < 1) {\n\t\t\t\t\t\tif (o->off2)\n\t\t\t\t\t\t\tval_store(ilp, ull, o->off2, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t\tif (curr < 2) {\n\t\t\t\t\t\tif (o->off3)\n\t\t\t\t\t\t\tval_store(ilp, ull, o->off3, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (o->type == FIO_OPT_ULL) {\n\t\t\t\tif (first)\n\t\t\t\t\tval_store(ullp, ull, o->off1, 0, data, o);\n\t\t\t\tif (curr == 1) {\n\t\t\t\t\tif (o->off2)\n\t\t\t\t\t\tval_store(ullp, ull, o->off2, 0, data, o);\n\t\t\t\t}\n\t\t\t\tif (curr == 2) {\n\t\t\t\t\tif (o->off3)\n\t\t\t\t\t\tval_store(ullp, ull, o->off3, 0, data, o);\n\t\t\t\t}\n\t\t\t\tif (!more) {\n\t\t\t\t\tif (curr < 1) {\n\t\t\t\t\t\tif (o->off2)\n\t\t\t\t\t\t\tval_store(ullp, ull, o->off2, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t\tif (curr < 2) {\n\t\t\t\t\t\tif (o->off3)\n\t\t\t\t\t\t\tval_store(ullp, ull, o->off3, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (first)\n\t\t\t\t\tval_store(ullp, ull, o->off1, 0, data, o);\n\t\t\t\tif (!more) {\n\t\t\t\t\tif (o->off2)\n\t\t\t\t\t\tval_store(ullp, ull, o->off2, 0, data, o);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FIO_OPT_FLOAT_LIST: {\n\t\tchar *cp2;\n\n\t\tif (first) {\n\t\t\t/*\n\t\t\t** Initialize precision to 0 and zero out list\n\t\t\t** in case specified list is shorter than default\n\t\t\t*/\n\t\t\tif (o->off2) {\n\t\t\t\tul2 = 0;\n\t\t\t\tilp = td_var(data, o, o->off2);\n\t\t\t\t*ilp = ul2;\n\t\t\t}\n\n\t\t\tflp = td_var(data, o, o->off1);\n\t\t\tfor(i = 0; i < o->maxlen; i++)\n\t\t\t\tflp[i].u.f = 0.0;\n\t\t}\n\t\tif (curr >= o->maxlen) {\n\t\t\tlog_err(\"the list exceeding max length %d\\n\",\n\t\t\t\t\to->maxlen);\n\t\t\treturn 1;\n\t\t}\n\t\tif (!str_to_float(ptr, &uf, 0)) { /* this breaks if we ever have lists of times */\n\t\t\tlog_err(\"not a floating point value: %s\\n\", ptr);\n\t\t\treturn 1;\n\t\t}\n\t\tif (o->minfp || o->maxfp) {\n\t\t\tif (uf > o->maxfp) {\n\t\t\t\tlog_err(\"value out of range: %f\"\n\t\t\t\t\t\" (range max: %f)\\n\", uf, o->maxfp);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tif (uf < o->minfp) {\n\t\t\t\tlog_err(\"value out of range: %f\"\n\t\t\t\t\t\" (range min: %f)\\n\", uf, o->minfp);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tflp = td_var(data, o, o->off1);\n\t\tflp[curr].u.f = uf;\n\n\t\tdprint(FD_PARSE, \"  out=%f\\n\", uf);\n\n\t\t/*\n\t\t** Calculate precision for output by counting\n\t\t** number of digits after period. Find first\n\t\t** period in entire remaining list each time\n\t\t*/\n\t\tcp2 = strchr(ptr, '.');\n\t\tif (cp2 != NULL) {\n\t\t\tint len = 0;\n\n\t\t\twhile (*++cp2 != '\\0' && *cp2 >= '0' && *cp2 <= '9')\n\t\t\t\tlen++;\n\n\t\t\tif (o->off2) {\n\t\t\t\tilp = td_var(data, o, o->off2);\n\t\t\t\tif (len > *ilp)\n\t\t\t\t\t*ilp = len;\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase FIO_OPT_STR_STORE: {\n\t\tfio_opt_str_fn *fn = o->cb;\n\n\t\tif (!strlen(ptr))\n\t\t\treturn 1;\n\n\t\tif (o->off1) {\n\t\t\tcp = td_var(data, o, o->off1);\n\t\t\tif (*cp)\n\t\t\t\tfree(*cp);\n\t\t\t*cp = strdup(ptr);\n\t\t\tif (strlen(ptr) > o->maxlen - 1) {\n\t\t\t\tlog_err(\"value exceeds max length of %d\\n\",\n\t\t\t\t\to->maxlen);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tif (fn)\n\t\t\tret = fn(data, ptr);\n\t\telse if (o->posval[0].ival) {\n\t\t\tposval_sort(o, posval);\n\n\t\t\tret = 1;\n\t\t\tfor (i = 0; i < PARSE_MAX_VP; i++) {\n\t\t\t\tvp = &posval[i];\n\t\t\t\tif (!vp->ival || vp->ival[0] == '\\0' || !cp)\n\t\t\t\t\tcontinue;\n\t\t\t\tall_skipped = 0;\n\t\t\t\tif (!strncmp(vp->ival, ptr, str_match_len(vp, ptr))) {\n\t\t\t\t\tchar *rest;\n\n\t\t\t\t\tret = 0;\n\t\t\t\t\tif (vp->cb)\n\t\t\t\t\t\tfn = vp->cb;\n\t\t\t\t\trest = strstr(*cp ?: ptr, \":\");\n\t\t\t\t\tif (rest) {\n\t\t\t\t\t\tif (*cp)\n\t\t\t\t\t\t\t*rest = '\\0';\n\t\t\t\t\t\tptr = rest + 1;\n\t\t\t\t\t} else\n\t\t\t\t\t\tptr = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (!all_skipped) {\n\t\t\tif (ret && !*cp)\n\t\t\t\tshow_option_values(o);\n\t\t\telse if (ret && *cp)\n\t\t\t\tret = 0;\n\t\t\telse if (fn && ptr)\n\t\t\t\tret = fn(data, ptr);\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase FIO_OPT_RANGE: {\n\t\tchar tmp[128];\n\t\tchar *p1, *p2;\n\n\t\tsnprintf(tmp, sizeof(tmp), \"%s\", ptr);\n\n\t\t/* Handle bsrange with separate read,write values: */\n\t\tp1 = strchr(tmp, ',');\n\t\tif (p1)\n\t\t\t*p1 = '\\0';\n\n\t\tp1 = strchr(tmp, '-');\n\t\tif (!p1) {\n\t\t\tp1 = strchr(tmp, ':');\n\t\t\tif (!p1) {\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tp2 = p1 + 1;\n\t\t*p1 = '\\0';\n\t\tp1 = tmp;\n\n\t\tret = 1;\n\t\tif (!check_range_bytes(p1, &ull1, data) &&\n\t\t\t!check_range_bytes(p2, &ull2, data)) {\n\t\t\tret = 0;\n\t\t\tif (ull1 > ull2) {\n\t\t\t\tunsigned long long foo = ull1;\n\n\t\t\t\tull1 = ull2;\n\t\t\t\tull2 = foo;\n\t\t\t}\n\n\t\t\tif (first) {\n\t\t\t\tval_store(ullp, ull1, o->off1, 0, data, o);\n\t\t\t\tval_store(ullp, ull2, o->off2, 0, data, o);\n\t\t\t}\n\t\t\tif (curr == 1) {\n\t\t\t\tif (o->off3 && o->off4) {\n\t\t\t\t\tval_store(ullp, ull1, o->off3, 0, data, o);\n\t\t\t\t\tval_store(ullp, ull2, o->off4, 0, data, o);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (curr == 2) {\n\t\t\t\tif (o->off5 && o->off6) {\n\t\t\t\t\tval_store(ullp, ull1, o->off5, 0, data, o);\n\t\t\t\t\tval_store(ullp, ull2, o->off6, 0, data, o);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!more) {\n\t\t\t\tif (curr < 1) {\n\t\t\t\t\tif (o->off3 && o->off4) {\n\t\t\t\t\t\tval_store(ullp, ull1, o->off3, 0, data, o);\n\t\t\t\t\t\tval_store(ullp, ull2, o->off4, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (curr < 2) {\n\t\t\t\t\tif (o->off5 && o->off6) {\n\t\t\t\t\t\tval_store(ullp, ull1, o->off5, 0, data, o);\n\t\t\t\t\t\tval_store(ullp, ull2, o->off6, 0, data, o);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase FIO_OPT_BOOL:\n\tcase FIO_OPT_STR_SET: {\n\t\tfio_opt_int_fn *fn = o->cb;\n\n\t\tif (ptr)\n\t\t\tret = check_int(ptr, &il);\n\t\telse if (o->type == FIO_OPT_BOOL)\n\t\t\tret = 1;\n\t\telse\n\t\t\til = 1;\n\n\t\tdprint(FD_PARSE, \"  ret=%d, out=%d\\n\", ret, il);\n\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (o->maxval && il > (int) o->maxval) {\n\t\t\tlog_err(\"max value out of range: %d (%llu max)\\n\",\n\t\t\t\t\t\t\t\til, o->maxval);\n\t\t\treturn 1;\n\t\t}\n\t\tif (o->minval && il < o->minval) {\n\t\t\tlog_err(\"min value out of range: %d (%d min)\\n\",\n\t\t\t\t\t\t\t\til, o->minval);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (o->neg)\n\t\t\til = !il;\n\n\t\tif (fn)\n\t\t\tret = fn(data, &il);\n\t\telse {\n\t\t\tif (first)\n\t\t\t\tval_store(ilp, il, o->off1, 0, data, o);\n\t\t\tif (!more) {\n\t\t\t\tif (o->off2)\n\t\t\t\t\tval_store(ilp, il, o->off2, 0, data, o);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FIO_OPT_DEPRECATED:\n\t\tret = 1;\n\t\tfio_fallthrough;\n\tcase FIO_OPT_SOFT_DEPRECATED:\n\t\tlog_info(\"Option %s is deprecated\\n\", o->name);\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"Bad option type %u\\n\", o->type);\n\t\tret = 1;\n\t}\n\n\tif (ret)\n\t\treturn ret;\n\n\tif (o->verify) {\n\t\tret = o->verify(o, data);\n\t\tif (ret) {\n\t\t\tlog_err(\"Correct format for offending option\\n\");\n\t\t\tlog_err(\"%20s: %s\\n\", o->name, o->help);\n\t\t\tshow_option_help(o, 1);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int handle_option(const struct fio_option *o, const char *__ptr,\n\t\t\t void *data)\n{\n\tchar *o_ptr, *ptr, *ptr2;\n\tint ret, done;\n\n\tdprint(FD_PARSE, \"handle_option=%s, ptr=%s\\n\", o->name, __ptr);\n\n\to_ptr = ptr = NULL;\n\tif (__ptr)\n\t\to_ptr = ptr = strdup(__ptr);\n\n\t/*\n\t * See if we have another set of parameters, hidden after a comma.\n\t * Do this before parsing this round, to check if we should\n\t * copy set 1 options to set 2.\n\t */\n\tdone = 0;\n\tret = 1;\n\tdo {\n\t\tint __ret;\n\n\t\tptr2 = NULL;\n\t\tif (ptr &&\n\t\t    (o->type != FIO_OPT_STR_STORE) &&\n\t\t    (o->type != FIO_OPT_STR) &&\n\t\t    (o->type != FIO_OPT_STR_ULL) &&\n\t\t    (o->type != FIO_OPT_FLOAT_LIST)) {\n\t\t\tptr2 = strchr(ptr, ',');\n\t\t\tif (ptr2 && *(ptr2 + 1) == '\\0')\n\t\t\t\t*ptr2 = '\\0';\n\t\t\tif (o->type != FIO_OPT_STR_MULTI && o->type != FIO_OPT_RANGE) {\n\t\t\t\tif (!ptr2)\n\t\t\t\t\tptr2 = strchr(ptr, ':');\n\t\t\t\tif (!ptr2)\n\t\t\t\t\tptr2 = strchr(ptr, '-');\n\t\t\t}\n\t\t} else if (ptr && o->type == FIO_OPT_FLOAT_LIST) {\n\t\t\tptr2 = strchr(ptr, ':');\n\t\t}\n\n\t\t/*\n\t\t * Don't return early if parsing the first option fails - if\n\t\t * we are doing multiple arguments, we can allow the first one\n\t\t * being empty.\n\t\t */\n\t\t__ret = __handle_option(o, ptr, data, !done, !!ptr2, done);\n\t\tif (ret)\n\t\t\tret = __ret;\n\n\t\tif (!ptr2)\n\t\t\tbreak;\n\n\t\tptr = ptr2 + 1;\n\t\tdone++;\n\t} while (1);\n\n\tif (o_ptr)\n\t\tfree(o_ptr);\n\treturn ret;\n}\n\nstruct fio_option *find_option(struct fio_option *options, const char *opt)\n{\n\tstruct fio_option *o;\n\n\tfor (o = &options[0]; o->name; o++) {\n\t\tif (!o_match(o, opt))\n\t\t\tcontinue;\n\t\tif (o->type == FIO_OPT_UNSUPPORTED) {\n\t\t\tlog_err(\"Option <%s>: %s\\n\", o->name, o->help);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn o;\n\t}\n\n\treturn NULL;\n}\n\nconst struct fio_option *\nfind_option_c(const struct fio_option *options, const char *opt)\n{\n\tconst struct fio_option *o;\n\n\tfor (o = &options[0]; o->name; o++) {\n\t\tif (!o_match(o, opt))\n\t\t\tcontinue;\n\t\tif (o->type == FIO_OPT_UNSUPPORTED) {\n\t\t\tlog_err(\"Option <%s>: %s\\n\", o->name, o->help);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn o;\n\t}\n\n\treturn NULL;\n}\n\nstatic const struct fio_option *\nget_option(char *opt, const struct fio_option *options, char **post)\n{\n\tconst struct fio_option *o;\n\tchar *ret;\n\n\tret = strchr(opt, '=');\n\tif (ret) {\n\t\t*post = ret;\n\t\t*ret = '\\0';\n\t\tret = opt;\n\t\t(*post)++;\n\t\tstrip_blank_end(ret);\n\t\to = find_option_c(options, ret);\n\t} else {\n\t\to = find_option_c(options, opt);\n\t\t*post = NULL;\n\t}\n\n\treturn o;\n}\n\nstatic int opt_cmp(const void *p1, const void *p2)\n{\n\tconst struct fio_option *o;\n\tchar *s, *foo;\n\tint prio1, prio2;\n\n\tprio1 = prio2 = 0;\n\n\tif (*(char **)p1) {\n\t\ts = strdup(*((char **) p1));\n\t\to = get_option(s, __fio_options, &foo);\n\t\tif (o)\n\t\t\tprio1 = o->prio;\n\t\tfree(s);\n\t}\n\tif (*(char **)p2) {\n\t\ts = strdup(*((char **) p2));\n\t\to = get_option(s, __fio_options, &foo);\n\t\tif (o)\n\t\t\tprio2 = o->prio;\n\t\tfree(s);\n\t}\n\n\treturn prio2 - prio1;\n}\n\nvoid sort_options(char **opts, const struct fio_option *options, int num_opts)\n{\n\t__fio_options = options;\n\tqsort(opts, num_opts, sizeof(char *), opt_cmp);\n\t__fio_options = NULL;\n}\n\nstatic void add_to_dump_list(const struct fio_option *o,\n\t\t\t     struct flist_head *dump_list, const char *post)\n{\n\tstruct print_option *p;\n\n\tif (!dump_list)\n\t\treturn;\n\n\tp = malloc(sizeof(*p));\n\tp->name = strdup(o->name);\n\tif (post)\n\t\tp->value = strdup(post);\n\telse\n\t\tp->value = NULL;\n\n\tflist_add_tail(&p->list, dump_list);\n}\n\nint parse_cmd_option(const char *opt, const char *val,\n\t\t     const struct fio_option *options, void *data,\n\t\t     struct flist_head *dump_list)\n{\n\tconst struct fio_option *o;\n\n\to = find_option_c(options, opt);\n\tif (!o) {\n\t\tlog_err(\"Bad option <%s>\\n\", opt);\n\t\treturn 1;\n\t}\n\n\tif (handle_option(o, val, data)) {\n\t\tlog_err(\"fio: failed parsing %s=%s\\n\", opt, val);\n\t\treturn 1;\n\t}\n\n\tadd_to_dump_list(o, dump_list, val);\n\treturn 0;\n}\n\nint parse_option(char *opt, const char *input, const struct fio_option *options,\n\t\t const struct fio_option **o, void *data,\n\t\t struct flist_head *dump_list)\n{\n\tchar *post;\n\n\tif (!opt) {\n\t\tlog_err(\"fio: failed parsing %s\\n\", input);\n\t\t*o = NULL;\n\t\treturn 1;\n\t}\n\n\t*o = get_option(opt, options, &post);\n\tif (!*o) {\n\t\tif (post) {\n\t\t\tint len = strlen(opt);\n\t\t\tif (opt + len + 1 != post)\n\t\t\t\tmemmove(opt + len + 1, post, strlen(post));\n\t\t\topt[len] = '=';\n\t\t}\n\t\treturn 1;\n\t}\n\n\tif (handle_option(*o, post, data)) {\n\t\tlog_err(\"fio: failed parsing %s\\n\", input);\n\t\treturn 1;\n\t}\n\n\tadd_to_dump_list(*o, dump_list, post);\n\treturn 0;\n}\n\n/*\n * Option match, levenshtein distance. Handy for not quite remembering what\n * the option name is.\n */\nint string_distance(const char *s1, const char *s2)\n{\n\tunsigned int s1_len = strlen(s1);\n\tunsigned int s2_len = strlen(s2);\n\tunsigned int *p, *q, *r;\n\tunsigned int i, j;\n\n\tp = malloc(sizeof(unsigned int) * (s2_len + 1));\n\tq = malloc(sizeof(unsigned int) * (s2_len + 1));\n\n\tp[0] = 0;\n\tfor (i = 1; i <= s2_len; i++)\n\t\tp[i] = p[i - 1] + 1;\n\n\tfor (i = 1; i <= s1_len; i++) {\n\t\tq[0] = p[0] + 1;\n\t\tfor (j = 1; j <= s2_len; j++) {\n\t\t\tunsigned int sub = p[j - 1];\n\t\t\tunsigned int pmin;\n\n\t\t\tif (s1[i - 1] != s2[j - 1])\n\t\t\t\tsub++;\n\n\t\t\tpmin = min(q[j - 1] + 1, sub);\n\t\t\tq[j] = min(p[j] + 1, pmin);\n\t\t}\n\t\tr = p;\n\t\tp = q;\n\t\tq = r;\n\t}\n\n\ti = p[s2_len];\n\tfree(p);\n\tfree(q);\n\treturn i;\n}\n\n/*\n * Make a guess of whether the distance from 's1' is significant enough\n * to warrant printing the guess. We set this to a 1/2 match.\n */\nint string_distance_ok(const char *opt, int distance)\n{\n\tsize_t len;\n\n\tlen = strlen(opt);\n\tlen = (len + 1) / 2;\n\treturn distance <= len;\n}\n\nstatic const struct fio_option *find_child(const struct fio_option *options,\n\t\t\t\t\t   const struct fio_option *o)\n{\n\tconst struct fio_option *__o;\n\n\tfor (__o = options + 1; __o->name; __o++)\n\t\tif (__o->parent && !strcmp(__o->parent, o->name))\n\t\t\treturn __o;\n\n\treturn NULL;\n}\n\nstatic void __print_option(const struct fio_option *o,\n\t\t\t   const struct fio_option *org,\n\t\t\t   int level)\n{\n\tchar name[256], *p;\n\tint depth;\n\n\tif (!o)\n\t\treturn;\n\n\tp = name;\n\tdepth = level;\n\twhile (depth--)\n\t\tp += sprintf(p, \"%s\", \"  \");\n\n\tsprintf(p, \"%s\", o->name);\n\n\tlog_info(\"%-24s: %s\\n\", name, o->help);\n}\n\nstatic void print_option(const struct fio_option *o)\n{\n\tconst struct fio_option *parent;\n\tconst struct fio_option *__o;\n\tunsigned int printed;\n\tunsigned int level;\n\n\t__print_option(o, NULL, 0);\n\tparent = o;\n\tlevel = 0;\n\tdo {\n\t\tlevel++;\n\t\tprinted = 0;\n\n\t\twhile ((__o = find_child(o, parent)) != NULL) {\n\t\t\t__print_option(__o, o, level);\n\t\t\to = __o;\n\t\t\tprinted++;\n\t\t}\n\n\t\tparent = o;\n\t} while (printed);\n}\n\nint show_cmd_help(const struct fio_option *options, const char *name)\n{\n\tconst struct fio_option *o, *closest;\n\tunsigned int best_dist = -1U;\n\tint found = 0;\n\tint show_all = 0;\n\n\tif (!name || !strcmp(name, \"all\"))\n\t\tshow_all = 1;\n\n\tclosest = NULL;\n\tbest_dist = -1;\n\tfor (o = &options[0]; o->name; o++) {\n\t\tint match = 0;\n\n\t\tif (o->type == FIO_OPT_DEPRECATED ||\n\t\t    o->type == FIO_OPT_SOFT_DEPRECATED)\n\t\t\tcontinue;\n\t\tif (!exec_profile && o->prof_name)\n\t\t\tcontinue;\n\t\tif (exec_profile && !(o->prof_name && !strcmp(exec_profile, o->prof_name)))\n\t\t\tcontinue;\n\n\t\tif (name) {\n\t\t\tif (!strcmp(name, o->name) ||\n\t\t\t    (o->alias && !strcmp(name, o->alias)))\n\t\t\t\tmatch = 1;\n\t\t\telse {\n\t\t\t\tunsigned int dist;\n\n\t\t\t\tdist = string_distance(name, o->name);\n\t\t\t\tif (dist < best_dist) {\n\t\t\t\t\tbest_dist = dist;\n\t\t\t\t\tclosest = o;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (show_all || match) {\n\t\t\tfound = 1;\n\t\t\tif (match)\n\t\t\t\tlog_info(\"%20s: %s\\n\", o->name, o->help);\n\t\t\tif (show_all) {\n\t\t\t\tif (!o->parent)\n\t\t\t\t\tprint_option(o);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (!match)\n\t\t\tcontinue;\n\n\t\tshow_option_help(o, 0);\n\t}\n\n\tif (found)\n\t\treturn 0;\n\n\tlog_err(\"No such command: %s\", name);\n\n\t/*\n\t * Only print an appropriately close option, one where the edit\n\t * distance isn't too big. Otherwise we get crazy matches.\n\t */\n\tif (closest && best_dist < 3) {\n\t\tlog_info(\" - showing closest match\\n\");\n\t\tlog_info(\"%20s: %s\\n\", closest->name, closest->help);\n\t\tshow_option_help(closest, 0);\n\t} else\n\t\tlog_info(\"\\n\");\n\n\treturn 1;\n}\n\n/*\n * Handle parsing of default parameters.\n */\nvoid fill_default_options(void *data, const struct fio_option *options)\n{\n\tconst struct fio_option *o;\n\n\tdprint(FD_PARSE, \"filling default options\\n\");\n\n\tfor (o = &options[0]; o->name; o++)\n\t\tif (o->def)\n\t\t\thandle_option(o, o->def, data);\n}\n\nstatic void option_init(struct fio_option *o)\n{\n\tif (o->type == FIO_OPT_DEPRECATED || o->type == FIO_OPT_UNSUPPORTED ||\n\t    o->type == FIO_OPT_SOFT_DEPRECATED)\n\t\treturn;\n\tif (o->name && !o->lname)\n\t\tlog_err(\"Option %s: missing long option name\\n\", o->name);\n\tif (o->type == FIO_OPT_BOOL) {\n\t\to->minval = 0;\n\t\to->maxval = 1;\n\t}\n\tif (o->type == FIO_OPT_INT) {\n\t\tif (!o->maxval)\n\t\t\to->maxval = UINT_MAX;\n\t}\n\tif (o->type == FIO_OPT_ULL) {\n\t\tif (!o->maxval)\n\t\t\to->maxval = ULLONG_MAX;\n\t}\n\tif (o->type == FIO_OPT_STR_SET && o->def && !o->no_warn_def) {\n\t\tlog_err(\"Option %s: string set option with\"\n\t\t\t\t\" default will always be true\\n\", o->name);\n\t}\n\tif (!o->cb && !o->off1)\n\t\tlog_err(\"Option %s: neither cb nor offset given\\n\", o->name);\n\tif (!o->category) {\n\t\tlog_info(\"Option %s: no category defined. Setting to misc\\n\", o->name);\n\t\to->category = FIO_OPT_C_GENERAL;\n\t\to->group = FIO_OPT_G_INVALID;\n\t}\n}\n\n/*\n * Sanitize the options structure. For now it just sets min/max for bool\n * values and whether both callback and offsets are given.\n */\nvoid options_init(struct fio_option *options)\n{\n\tstruct fio_option *o;\n\n\tdprint(FD_PARSE, \"init options\\n\");\n\n\tfor (o = &options[0]; o->name; o++) {\n\t\toption_init(o);\n\t\tif (o->inverse)\n\t\t\to->inv_opt = find_option(options, o->inverse);\n\t}\n}\n\nvoid options_mem_dupe(const struct fio_option *options, void *data)\n{\n\tconst struct fio_option *o;\n\tchar **ptr;\n\n\tdprint(FD_PARSE, \"dup options\\n\");\n\n\tfor (o = &options[0]; o->name; o++) {\n\t\tif (o->type != FIO_OPT_STR_STORE)\n\t\t\tcontinue;\n\n\t\tptr = td_var(data, o, o->off1);\n\t\tif (*ptr)\n\t\t\t*ptr = strdup(*ptr);\n\t}\n}\n\nvoid options_free(const struct fio_option *options, void *data)\n{\n\tconst struct fio_option *o;\n\tchar **ptr;\n\n\tdprint(FD_PARSE, \"free options\\n\");\n\n\tfor (o = &options[0]; o->name; o++) {\n\t\tif (o->type != FIO_OPT_STR_STORE || !o->off1 || o->no_free)\n\t\t\tcontinue;\n\n\t\tptr = td_var(data, o, o->off1);\n\t\tif (*ptr) {\n\t\t\tfree(*ptr);\n\t\t\t*ptr = NULL;\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "parse.h",
          "type": "blob",
          "size": 4.1865234375,
          "content": "#ifndef FIO_PARSE_H\n#define FIO_PARSE_H\n\n#include <inttypes.h>\n#include \"flist.h\"\n\n/*\n * Option types\n */\nenum fio_opt_type {\n\tFIO_OPT_INVALID = 0,\n\tFIO_OPT_STR,\n\tFIO_OPT_STR_ULL,\n\tFIO_OPT_STR_MULTI,\n\tFIO_OPT_STR_VAL,\n\tFIO_OPT_STR_VAL_TIME,\n\tFIO_OPT_STR_STORE,\n\tFIO_OPT_RANGE,\n\tFIO_OPT_INT,\n\tFIO_OPT_ULL,\n\tFIO_OPT_BOOL,\n\tFIO_OPT_FLOAT_LIST,\n\tFIO_OPT_STR_SET,\n\tFIO_OPT_STR_VAL_ZONE,\n\tFIO_OPT_DEPRECATED,\n\tFIO_OPT_SOFT_DEPRECATED,\n\tFIO_OPT_UNSUPPORTED,\t/* keep this last */\n};\n\n/*\n * Match a possible value string with the integer option.\n */\nstruct value_pair {\n\tconst char *ival;\t\t/* string option */\n\tunsigned long long oval;\t/* output value */\n\tconst char *help;\t\t/* help text for sub option */\n\tint orval;\t\t\t/* OR value */\n\tvoid *cb;\t\t\t/* sub-option callback */\n};\n\n#define OPT_LEN_MAX \t8192\n#define PARSE_MAX_VP\t32\n\n/*\n * Option define\n */\nstruct fio_option {\n\tconst char *name;\t\t/* option name */\n\tconst char *lname;\t\t/* long option name */\n\tconst char *alias;\t\t/* possible old allowed name */\n\tenum fio_opt_type type;\t\t/* option type */\n\tunsigned int off1;\t\t/* potential parameters */\n\tunsigned int off2;\n\tunsigned int off3;\n\tunsigned int off4;\n\tunsigned int off5;\n\tunsigned int off6;\n\tunsigned long long maxval;\t\t/* max and min value */\n\tint minval;\n\tdouble maxfp;\t\t\t/* max and min floating value */\n\tdouble minfp;\n\tunsigned int interval;\t\t/* client hint for suitable interval */\n\tunsigned int maxlen;\t\t/* max length */\n\tint neg;\t\t\t/* negate value stored */\n\tint prio;\n\tvoid *cb;\t\t\t/* callback */\n\tconst char *help;\t\t/* help text for option */\n\tconst char *def;\t\t/* default setting */\n\tstruct value_pair posval[PARSE_MAX_VP];/* possible values */\n\tconst char *parent;\t\t/* parent option */\n\tint hide;\t\t\t/* hide if parent isn't set */\n\tint hide_on_set;\t\t/* hide on set, not on unset */\n\tconst char *inverse;\t\t/* if set, apply opposite action to this option */\n\tstruct fio_option *inv_opt;\t/* cached lookup */\n\tint (*verify)(const struct fio_option *, void *);\n\tconst char *prof_name;\t\t/* only valid for specific profile */\n\tvoid *prof_opts;\n\tuint64_t category;\t\t/* what type of option */\n\tuint64_t group;\t\t\t/* who to group with */\n\tvoid *gui_data;\n\tint is_seconds;\t\t\t/* time value with seconds base */\n\tint is_time;\t\t\t/* time based value */\n\tint no_warn_def;\n\tint pow2;\t\t\t/* must be a power-of-2 */\n\tint no_free;\n};\n\nextern int parse_option(char *, const char *, const struct fio_option *,\n\t\t\tconst struct fio_option **, void *,\n\t\t\tstruct flist_head *);\nextern void sort_options(char **, const struct fio_option *, int);\nextern int parse_cmd_option(const char *t, const char *l,\n\t\t\t    const struct fio_option *, void *,\n\t\t\t    struct flist_head *);\nextern int show_cmd_help(const struct fio_option *, const char *);\nextern void fill_default_options(void *, const struct fio_option *);\nextern void options_init(struct fio_option *);\nextern void options_mem_dupe(const struct fio_option *, void *);\nextern void options_free(const struct fio_option *, void *);\n\nextern void strip_blank_front(char **);\nextern void strip_blank_end(char *);\nextern int str_to_decimal(const char *, long long *, int, void *, int, int);\nextern int check_str_bytes(const char *p, long long *val, void *data);\nextern int check_str_time(const char *p, long long *val, int);\nextern int str_to_float(const char *str, double *val, int is_time);\n\nextern int string_distance(const char *s1, const char *s2);\nextern int string_distance_ok(const char *s1, int dist);\n\n/*\n * Handlers for the options\n */\ntypedef int (fio_opt_str_fn)(void *, const char *);\ntypedef int (fio_opt_str_val_fn)(void *, long long *);\ntypedef int (fio_opt_int_fn)(void *, int *);\n\nstruct thread_options;\nstatic inline void *td_var(void *to, const struct fio_option *o,\n\t\t\t   unsigned int offset)\n{\n\tvoid *ret;\n\n\tif (o->prof_opts)\n\t\tret = o->prof_opts;\n\telse\n\t\tret = to;\n\n\treturn (void *) ((uintptr_t) ret + offset);\n}\n\nstatic inline int parse_is_percent(unsigned long long val)\n{\n\treturn val >= -101ULL;\n}\n\n#define ZONE_BASE_VAL ((-1ULL >> 1) + 1)\nstatic inline int parse_is_percent_uncapped(unsigned long long val)\n{\n\treturn ZONE_BASE_VAL + -1U < val;\n}\n\nstatic inline int parse_is_zone(unsigned long long val)\n{\n\treturn (val - ZONE_BASE_VAL) <= -1U;\n}\n\nstruct print_option {\n\tstruct flist_head list;\n\tchar *name;\n\tchar *value;\n};\n\n#endif\n"
        },
        {
          "name": "printing.c",
          "type": "blob",
          "size": 4.240234375,
          "content": "#include <gtk/gtk.h>\n#include <cairo.h>\n\n#include \"gfio.h\"\n#include \"cairo_text_helpers.h\"\n#include \"printing.h\"\n\n\nstatic struct printing_parameters {\n\tgdouble width, height, xdpi, ydpi;\n\tGtkPrintSettings *settings;\n\tGtkPageSetup *page_setup;\n} print_params = { 0 };\n\nstatic void begin_print(GtkPrintOperation *operation,\n\t\t\tGtkPrintContext *context, gpointer data)\n{\n\tprint_params.page_setup = gtk_print_context_get_page_setup(context);\n\n\tprint_params.width = gtk_print_context_get_width(context);\n\tprint_params.height = gtk_print_context_get_height(context);\n\tprint_params.xdpi = gtk_print_context_get_dpi_x(context);\n\tprint_params.ydpi = gtk_print_context_get_dpi_y(context);\n\n\t/* assume 1 page for now. */\n\tgtk_print_operation_set_n_pages(operation, 1);\n}\n\nstatic void results_draw_page(GtkPrintOperation *operation,\n\t\t\t      GtkPrintContext *context, gint page_nr,\n\t\t\t      gpointer data)\n{\n\tcairo_t *cr;\n\tchar str[32];\n\tdouble x, y;\n\n\tcr = gtk_print_context_get_cairo_context(context);\n\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tcairo_set_line_width(cr, 5.0);\n\tcairo_move_to(cr, 0.0, 0.0);\n\tcairo_line_to(cr, print_params.width, print_params.height);\n\tcairo_move_to(cr, 0.0, print_params.height);\n\tcairo_line_to(cr, print_params.width, 0.0);\n\tcairo_stroke(cr);\n\n\tx = print_params.width / 4.0;\n\ty = print_params.height / 5.0;\n\tsprintf(str, \"(%g,%g)\", x, y);\n\tdraw_right_justified_text(cr, \"Sans\", x, y, 12.0, str);\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tcairo_set_line_width(cr, 2.0);\n\tcairo_move_to(cr, x, y - 30.0);\n\tcairo_line_to(cr, x, y + 30.0);\n\tcairo_move_to(cr, x - 30, y);\n\tcairo_line_to(cr, x + 30, y);\n\n\ty *= 4.0;\n\tx *= 2.0;\n\tsprintf(str, \"(%g,%g)\", x, y);\n\tdraw_right_justified_text(cr, \"Sans\", x, y, 12.0, str);\n\tcairo_set_source_rgb(cr, 0, 0, 0);\n\tcairo_set_line_width(cr, 2.0);\n\tcairo_move_to(cr, x, y - 30.0);\n\tcairo_line_to(cr, x, y + 30.0);\n\tcairo_move_to(cr, x - 30, y);\n\tcairo_line_to(cr, x + 30, y);\n\tcairo_stroke(cr);\n}\n\nstatic void printing_error_dialog(GtkWidget *window, GError *print_error)\n{\n\tGtkWidget *error_dialog;\n\n\tprintf(\"printing_error_dialog called\\n\");\n\tprintf(\"error message = %s\\n\", print_error->message);\n\terror_dialog = gtk_message_dialog_new(GTK_WINDOW(window),\n\t\t\tGTK_DIALOG_DESTROY_WITH_PARENT, GTK_MESSAGE_ERROR,\n\t\t\tGTK_BUTTONS_CLOSE, \"Print error:\\n%s\",\n\t\t\tprint_error->message);\n\tg_signal_connect(error_dialog, \"response\",\n\t\t\tG_CALLBACK(gtk_widget_destroy), NULL);\n\tgtk_widget_show(error_dialog);\n}\n\nstatic void results_print_done(GtkPrintOperation *operation,\n\t\t\tGtkPrintOperationResult result, gpointer data)\n{\n\tGError *print_error;\n\tstruct gui_entry *ge = data;\n\n\tif (result != GTK_PRINT_OPERATION_RESULT_ERROR)\n\t\treturn;\n\n\tgtk_print_operation_get_error(operation, &print_error);\n\tprinting_error_dialog(ge->results_window, print_error);\n\tg_error_free(print_error);\n}\n\nvoid gfio_print_results(struct gui_entry *ge)\n{\n\tGtkPrintOperation *print;\n\tGtkPrintOperationResult res;\n\tGError *print_error;\n\n\tprint = gtk_print_operation_new();\n\tif (print_params.settings != NULL)\n\t\tgtk_print_operation_set_print_settings(print, print_params.settings);\n\n\tif (print_params.page_setup != NULL)\n\t\tgtk_print_operation_set_default_page_setup(print, print_params.page_setup);\n\n\tg_signal_connect(print, \"begin_print\", G_CALLBACK(begin_print), NULL);\n\tg_signal_connect(print, \"draw_page\", G_CALLBACK(results_draw_page), NULL);\n\tg_signal_connect(print, \"done\", G_CALLBACK(results_print_done), NULL);\n\tgtk_print_operation_set_allow_async(print, TRUE);\n\tres = gtk_print_operation_run(print, GTK_PRINT_OPERATION_ACTION_PRINT_DIALOG,\n\t\tGTK_WINDOW(ge->results_window), &print_error);\n\n\t/*\n\t * Something's not quite right about the error handling.  If I print\n\t * to a file, and the file exists, and I don't have write permission\n\t * on that file but attempt to replace it anyway, then it just kind of\n\t * hangs and I don't get into any of this error handling stuff at all,\n\t * neither here, nor in results_print_done().\n\t */\n\n\tif (res == GTK_PRINT_OPERATION_RESULT_ERROR) {\n\t\tprinting_error_dialog(ge->results_window, print_error);\n\t\tg_error_free(print_error);\n\t} else {\n\t\tif (res == GTK_PRINT_OPERATION_RESULT_APPLY) {\n\t\t\tif (print_params.settings != NULL)\n\t\t\t\tg_object_unref(print_params.settings);\n\t\t\tprint_params.settings = g_object_ref(gtk_print_operation_get_print_settings(print));\n\t\t}\n\t}\n\tg_object_unref(print);\n}\n"
        },
        {
          "name": "printing.h",
          "type": "blob",
          "size": 0.091796875,
          "content": "#ifndef PRINTING_H\n#define PRINTING_H\n\nvoid gfio_print_results(struct gui_entry *ge);\n\n#endif\n"
        },
        {
          "name": "profile.c",
          "type": "blob",
          "size": 2.1220703125,
          "content": "#include \"fio.h\"\n#include \"profile.h\"\n#include \"debug.h\"\n#include \"flist.h\"\n#include \"options.h\"\n\nstatic FLIST_HEAD(profile_list);\n\nstruct profile_ops *find_profile(const char *profile)\n{\n\tstruct profile_ops *ops = NULL;\n\tstruct flist_head *n;\n\n\tflist_for_each(n, &profile_list) {\n\t\tops = flist_entry(n, struct profile_ops, list);\n\t\tif (!strcmp(profile, ops->name))\n\t\t\tbreak;\n\n\t\tops = NULL;\n\t}\n\n\treturn ops;\n}\n\nint load_profile(const char *profile)\n{\n\tstruct profile_ops *ops;\n\n\tdprint(FD_PROFILE, \"loading profile '%s'\\n\", profile);\n\n\tops = find_profile(profile);\n\tif (ops) {\n\t\tif (ops->prep_cmd()) {\n\t\t\tlog_err(\"fio: profile %s prep failed\\n\", profile);\n\t\t\treturn 1;\n\t\t}\n\t\tadd_job_opts(ops->cmdline, FIO_CLIENT_TYPE_CLI);\n\t\treturn 0;\n\t}\n\n\tlog_err(\"fio: profile '%s' not found\\n\", profile);\n\treturn 1;\n}\n\nstatic int add_profile_options(struct profile_ops *ops)\n{\n\tstruct fio_option *o;\n\n\tif (!ops->options)\n\t\treturn 0;\n\n\to = ops->options;\n\twhile (o->name) {\n\t\to->prof_name = ops->name;\n\t\to->prof_opts = ops->opt_data;\n\t\tif (add_option(o))\n\t\t\treturn 1;\n\t\to++;\n\t}\n\n\treturn 0;\n}\n\nint register_profile(struct profile_ops *ops)\n{\n\tint ret;\n\n\tdprint(FD_PROFILE, \"register profile '%s'\\n\", ops->name);\n\n\tret = add_profile_options(ops);\n\tif (!ret) {\n\t\tflist_add_tail(&ops->list, &profile_list);\n\t\tadd_opt_posval(\"profile\", ops->name, ops->desc);\n\t\treturn 0;\n\t}\n\n\tinvalidate_profile_options(ops->name);\n\treturn ret;\n}\n\nvoid unregister_profile(struct profile_ops *ops)\n{\n\tdprint(FD_PROFILE, \"unregister profile '%s'\\n\", ops->name);\n\tflist_del(&ops->list);\n\tinvalidate_profile_options(ops->name);\n\tdel_opt_posval(\"profile\", ops->name);\n}\n\nvoid profile_add_hooks(struct thread_data *td)\n{\n\tstruct profile_ops *ops;\n\n\tif (!exec_profile)\n\t\treturn;\n\n\tops = find_profile(exec_profile);\n\tif (!ops)\n\t\treturn;\n\n\tif (ops->io_ops) {\n\t\ttd->prof_io_ops = *ops->io_ops;\n\t\ttd->flags |= TD_F_PROFILE_OPS;\n\t}\n}\n\nint profile_td_init(struct thread_data *td)\n{\n\tstruct prof_io_ops *ops = &td->prof_io_ops;\n\n\tif (ops->td_init)\n\t\treturn ops->td_init(td);\n\n\treturn 0;\n}\n\nvoid profile_td_exit(struct thread_data *td)\n{\n\tstruct prof_io_ops *ops = &td->prof_io_ops;\n\n\tif (ops->td_exit)\n\t\tops->td_exit(td);\n}\n"
        },
        {
          "name": "profile.h",
          "type": "blob",
          "size": 0.9345703125,
          "content": "#ifndef FIO_PROFILE_H\n#define FIO_PROFILE_H\n\n#include \"flist.h\"\n\n/*\n * Functions for overriding internal fio io_u functions\n */\nstruct prof_io_ops {\n\tint (*td_init)(struct thread_data *);\n\tvoid (*td_exit)(struct thread_data *);\n\n\tint (*io_u_lat)(struct thread_data *, uint64_t);\n};\n\nstruct profile_ops {\n\tstruct flist_head list;\n\tchar name[32];\n\tchar desc[64];\n\tint flags;\n\n\t/*\n\t * Profile specific options\n\t */\n\tstruct fio_option *options;\n\tvoid *opt_data;\n\n\t/*\n\t * Called after parsing options, to prepare 'cmdline'\n\t */\n\tint (*prep_cmd)(void);\n\n\t/*\n\t * The complete command line\n\t */\n\tconst char **cmdline;\n\n\tstruct prof_io_ops *io_ops;\n};\n\nint register_profile(struct profile_ops *);\nvoid unregister_profile(struct profile_ops *);\nint load_profile(const char *);\nstruct profile_ops *find_profile(const char *);\nvoid profile_add_hooks(struct thread_data *);\n\nint profile_td_init(struct thread_data *);\nvoid profile_td_exit(struct thread_data *);\n\n#endif\n"
        },
        {
          "name": "profiles",
          "type": "tree",
          "content": null
        },
        {
          "name": "pshared.c",
          "type": "blob",
          "size": 2.0439453125,
          "content": "#include <string.h>\n\n#include \"log.h\"\n#include \"pshared.h\"\n\nint cond_init_pshared(pthread_cond_t *cond)\n{\n\tpthread_condattr_t cattr;\n\tint ret;\n\n\tret = pthread_condattr_init(&cattr);\n\tif (ret) {\n\t\tlog_err(\"pthread_condattr_init: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n\n#ifdef CONFIG_PSHARED\n\tret = pthread_condattr_setpshared(&cattr, PTHREAD_PROCESS_SHARED);\n\tif (ret) {\n\t\tlog_err(\"pthread_condattr_setpshared: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n#endif\n\n#ifdef CONFIG_PTHREAD_CONDATTR_SETCLOCK\n\tret = pthread_condattr_setclock(&cattr, CLOCK_MONOTONIC);\n\tif (ret) {\n\t\tlog_err(\"pthread_condattr_setclock: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n#endif\n\n\tret = pthread_cond_init(cond, &cattr);\n\tif (ret) {\n\t\tlog_err(\"pthread_cond_init: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n/*\n * 'type' must be a mutex type, e.g. PTHREAD_MUTEX_NORMAL,\n * PTHREAD_MUTEX_ERRORCHECK, PTHREAD_MUTEX_RECURSIVE or PTHREAD_MUTEX_DEFAULT.\n */\nint mutex_init_pshared_with_type(pthread_mutex_t *mutex, int type)\n{\n\tpthread_mutexattr_t mattr;\n\tint ret;\n\n\tret = pthread_mutexattr_init(&mattr);\n\tif (ret) {\n\t\tlog_err(\"pthread_mutexattr_init: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n\n\t/*\n\t * Not all platforms support process shared mutexes (NetBSD/OpenBSD)\n\t */\n#ifdef CONFIG_PSHARED\n\tret = pthread_mutexattr_setpshared(&mattr, PTHREAD_PROCESS_SHARED);\n\tif (ret) {\n\t\tlog_err(\"pthread_mutexattr_setpshared: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n#endif\n\tret = pthread_mutexattr_settype(&mattr, type);\n\tif (ret) {\n\t\tlog_err(\"pthread_mutexattr_settype: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n\tret = pthread_mutex_init(mutex, &mattr);\n\tif (ret) {\n\t\tlog_err(\"pthread_mutex_init: %s\\n\", strerror(ret));\n\t\treturn ret;\n\t}\n\tpthread_mutexattr_destroy(&mattr);\n\n\treturn 0;\n}\n\nint mutex_init_pshared(pthread_mutex_t *mutex)\n{\n\treturn mutex_init_pshared_with_type(mutex, PTHREAD_MUTEX_DEFAULT);\n}\n\nint mutex_cond_init_pshared(pthread_mutex_t *mutex, pthread_cond_t *cond)\n{\n\tint ret;\n\n\tret = mutex_init_pshared(mutex);\n\tif (ret)\n\t\treturn ret;\n\n\tret = cond_init_pshared(cond);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n"
        },
        {
          "name": "pshared.h",
          "type": "blob",
          "size": 0.3037109375,
          "content": "#ifndef FIO_PSHARED_H\n#define FIO_PSHARED_H\n\n#include <pthread.h>\n\nextern int mutex_init_pshared_with_type(pthread_mutex_t *, int);\nextern int mutex_init_pshared(pthread_mutex_t *);\nextern int cond_init_pshared(pthread_cond_t *);\nextern int mutex_cond_init_pshared(pthread_mutex_t *, pthread_cond_t *);\n\n#endif\n"
        },
        {
          "name": "rate-submit.c",
          "type": "blob",
          "size": 7.4267578125,
          "content": "/*\n * Rated submission helpers\n *\n * Copyright (C) 2015 Jens Axboe <axboe@kernel.dk>\n *\n */\n#include <assert.h>\n#include <errno.h>\n#include <pthread.h>\n\n#include \"fio.h\"\n#include \"ioengines.h\"\n#include \"lib/getrusage.h\"\n#include \"rate-submit.h\"\n\nstatic void check_overlap(struct io_u *io_u)\n{\n\tint res;\n\n\t/*\n\t * Allow only one thread to check for overlap at a time to prevent two\n\t * threads from thinking the coast is clear and then submitting IOs\n\t * that overlap with each other.\n\t *\n\t * If an overlap is found, release the lock and re-acquire it before\n\t * checking again to give other threads a chance to make progress.\n\t *\n\t * If no overlap is found, release the lock when the io_u's\n\t * IO_U_F_FLIGHT flag is set so that this io_u can be checked by other\n\t * threads as they assess overlap.\n\t */\n\tres = pthread_mutex_lock(&overlap_check);\n\tif (fio_unlikely(res != 0)) {\n\t\tlog_err(\"failed to lock overlap check mutex, err: %i:%s\", errno, strerror(errno));\n\t\tabort();\n\t}\n\nretry:\n\tfor_each_td(td) {\n\t\tif (td->runstate <= TD_SETTING_UP ||\n\t\t    td->runstate >= TD_FINISHING ||\n\t\t    !td->o.serialize_overlap ||\n\t\t    td->o.io_submit_mode != IO_MODE_OFFLOAD)\n\t\t\tcontinue;\n\n\t\tif (!in_flight_overlap(&td->io_u_all, io_u))\n\t\t\tcontinue;\n\n\t\tres = pthread_mutex_unlock(&overlap_check);\n\t\tif (fio_unlikely(res != 0)) {\n\t\t\tlog_err(\"failed to unlock overlap check mutex, err: %i:%s\", errno, strerror(errno));\n\t\t\tabort();\n\t\t}\n\t\tres = pthread_mutex_lock(&overlap_check);\n\t\tif (fio_unlikely(res != 0)) {\n\t\t\tlog_err(\"failed to lock overlap check mutex, err: %i:%s\", errno, strerror(errno));\n\t\t\tabort();\n\t\t}\n\t\tgoto retry;\n\t} end_for_each();\n}\n\nstatic int io_workqueue_fn(struct submit_worker *sw,\n\t\t\t   struct workqueue_work *work)\n{\n\tstruct io_u *io_u = container_of(work, struct io_u, work);\n\tconst enum fio_ddir ddir = io_u->ddir;\n\tstruct thread_data *td = sw->priv;\n\tint ret, error;\n\n\tif (td->o.serialize_overlap)\n\t\tcheck_overlap(io_u);\n\n\tdprint(FD_RATE, \"io_u %p queued by %u\\n\", io_u, gettid());\n\n\tio_u_set(td, io_u, IO_U_F_NO_FILE_PUT);\n\n\ttd->cur_depth++;\n\n\tdo {\n\t\tret = td_io_queue(td, io_u);\n\t\tif (ret != FIO_Q_BUSY)\n\t\t\tbreak;\n\t\tret = io_u_queued_complete(td, 1);\n\t\tif (ret > 0)\n\t\t\ttd->cur_depth -= ret;\n\t\telse if (ret < 0)\n\t\t\tbreak;\n\t\tio_u_clear(td, io_u, IO_U_F_FLIGHT);\n\t} while (1);\n\n\tdprint(FD_RATE, \"io_u %p ret %d by %u\\n\", io_u, ret, gettid());\n\n\terror = io_queue_event(td, io_u, &ret, ddir, NULL, 0, NULL);\n\n\tif (ret == FIO_Q_COMPLETED)\n\t\ttd->cur_depth--;\n\telse if (ret == FIO_Q_QUEUED) {\n\t\tunsigned int min_evts;\n\n\t\tif (td->o.iodepth == 1)\n\t\t\tmin_evts = 1;\n\t\telse\n\t\t\tmin_evts = 0;\n\n\t\tret = io_u_queued_complete(td, min_evts);\n\t\tif (ret > 0)\n\t\t\ttd->cur_depth -= ret;\n\t}\n\n\tif (error || td->error) {\n\t\tpthread_mutex_lock(&td->io_u_lock);\n\t\tpthread_cond_signal(&td->parent->free_cond);\n\t\tpthread_mutex_unlock(&td->io_u_lock);\n\t}\n\n\treturn 0;\n}\n\nstatic bool io_workqueue_pre_sleep_flush_fn(struct submit_worker *sw)\n{\n\tstruct thread_data *td = sw->priv;\n\n\tif (td->error)\n\t\treturn false;\n\tif (td->io_u_queued || td->cur_depth || td->io_u_in_flight)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void io_workqueue_pre_sleep_fn(struct submit_worker *sw)\n{\n\tstruct thread_data *td = sw->priv;\n\tint ret;\n\n\tret = io_u_quiesce(td);\n\tif (ret > 0)\n\t\ttd->cur_depth -= ret;\n}\n\nstatic int io_workqueue_alloc_fn(struct submit_worker *sw)\n{\n\tstruct thread_data *td;\n\n\ttd = calloc(1, sizeof(*td));\n\tsw->priv = td;\n\treturn 0;\n}\n\nstatic void io_workqueue_free_fn(struct submit_worker *sw)\n{\n\tfree(sw->priv);\n\tsw->priv = NULL;\n}\n\nstatic int io_workqueue_init_worker_fn(struct submit_worker *sw)\n{\n\tstruct thread_data *parent = sw->wq->td;\n\tstruct thread_data *td = sw->priv;\n\n\tmemcpy(&td->o, &parent->o, sizeof(td->o));\n\tmemcpy(&td->ts, &parent->ts, sizeof(td->ts));\n\ttd->o.uid = td->o.gid = -1U;\n\tdup_files(td, parent);\n\ttd->eo = parent->eo;\n\tfio_options_mem_dupe(td);\n\ttd->iolog_f = parent->iolog_f;\n\n\tif (ioengine_load(td))\n\t\tgoto err;\n\n\ttd->pid = gettid();\n\n\tINIT_FLIST_HEAD(&td->io_log_list);\n\tINIT_FLIST_HEAD(&td->io_hist_list);\n\tINIT_FLIST_HEAD(&td->verify_list);\n\tINIT_FLIST_HEAD(&td->trim_list);\n\ttd->io_hist_tree = RB_ROOT;\n\n\ttd->o.iodepth = 1;\n\tif (td_io_init(td))\n\t\tgoto err_io_init;\n\n\tif (td->io_ops->post_init && td->io_ops->post_init(td))\n\t\tgoto err_io_init;\n\n\tset_epoch_time(td, td->o.log_alternate_epoch_clock_id, td->o.job_start_clock_id);\n\tfio_getrusage(&td->ru_start);\n\tclear_io_state(td, 1);\n\n\ttd_set_runstate(td, TD_RUNNING);\n\ttd->flags |= TD_F_CHILD | TD_F_NEED_LOCK;\n\ttd->parent = parent;\n\treturn 0;\n\nerr_io_init:\n\tclose_ioengine(td);\nerr:\n\treturn 1;\n\n}\n\nstatic void io_workqueue_exit_worker_fn(struct submit_worker *sw,\n\t\t\t\t\tunsigned int *sum_cnt)\n{\n\tstruct thread_data *td = sw->priv;\n\n\t(*sum_cnt)++;\n\n\t/*\n\t * io_workqueue_update_acct_fn() doesn't support per prio stats, and\n\t * even if it did, offload can't be used with all async IO engines.\n\t * If group reporting is set in the parent td, the group result\n\t * generated by __show_run_stats() can still contain multiple prios\n\t * from different offloaded jobs.\n\t */\n\tsw->wq->td->ts.disable_prio_stat = 1;\n\tsum_thread_stats(&sw->wq->td->ts, &td->ts);\n\n\tfio_options_free(td);\n\tclose_and_free_files(td);\n\tif (td->io_ops)\n\t\tclose_ioengine(td);\n\ttd_set_runstate(td, TD_EXITED);\n}\n\n#ifdef CONFIG_SFAA\nstatic void sum_val(uint64_t *dst, uint64_t *src)\n{\n\tif (*src) {\n\t\t__sync_fetch_and_add(dst, *src);\n\t\t*src = 0;\n\t}\n}\n#else\nstatic void sum_val(uint64_t *dst, uint64_t *src)\n{\n\tif (*src) {\n\t\t*dst += *src;\n\t\t*src = 0;\n\t}\n}\n#endif\n\nstatic void pthread_double_unlock(pthread_mutex_t *lock1,\n\t\t\t\t  pthread_mutex_t *lock2)\n{\n#ifndef CONFIG_SFAA\n\tpthread_mutex_unlock(lock1);\n\tpthread_mutex_unlock(lock2);\n#endif\n}\n\nstatic void pthread_double_lock(pthread_mutex_t *lock1, pthread_mutex_t *lock2)\n{\n#ifndef CONFIG_SFAA\n\tif (lock1 < lock2) {\n\t\tpthread_mutex_lock(lock1);\n\t\tpthread_mutex_lock(lock2);\n\t} else {\n\t\tpthread_mutex_lock(lock2);\n\t\tpthread_mutex_lock(lock1);\n\t}\n#endif\n}\n\nstatic void sum_ddir(struct thread_data *dst, struct thread_data *src,\n\t\t     enum fio_ddir ddir)\n{\n\tpthread_double_lock(&dst->io_wq.stat_lock, &src->io_wq.stat_lock);\n\n\tsum_val(&dst->io_bytes[ddir], &src->io_bytes[ddir]);\n\tsum_val(&dst->io_blocks[ddir], &src->io_blocks[ddir]);\n\tsum_val(&dst->this_io_blocks[ddir], &src->this_io_blocks[ddir]);\n\tsum_val(&dst->this_io_bytes[ddir], &src->this_io_bytes[ddir]);\n\tsum_val(&dst->bytes_done[ddir], &src->bytes_done[ddir]);\n\tif (ddir == DDIR_READ)\n\t\tsum_val(&dst->bytes_verified, &src->bytes_verified);\n\n\tpthread_double_unlock(&dst->io_wq.stat_lock, &src->io_wq.stat_lock);\n}\n\nstatic void io_workqueue_update_acct_fn(struct submit_worker *sw)\n{\n\tstruct thread_data *src = sw->priv;\n\tstruct thread_data *dst = sw->wq->td;\n\n\tif (td_read(src))\n\t\tsum_ddir(dst, src, DDIR_READ);\n\tif (td_write(src))\n\t\tsum_ddir(dst, src, DDIR_WRITE);\n\tif (td_trim(src))\n\t\tsum_ddir(dst, src, DDIR_TRIM);\n\n}\n\nstatic struct workqueue_ops rated_wq_ops = {\n\t.fn\t\t\t= io_workqueue_fn,\n\t.pre_sleep_flush_fn\t= io_workqueue_pre_sleep_flush_fn,\n\t.pre_sleep_fn\t\t= io_workqueue_pre_sleep_fn,\n\t.update_acct_fn\t\t= io_workqueue_update_acct_fn,\n\t.alloc_worker_fn\t= io_workqueue_alloc_fn,\n\t.free_worker_fn\t\t= io_workqueue_free_fn,\n\t.init_worker_fn\t\t= io_workqueue_init_worker_fn,\n\t.exit_worker_fn\t\t= io_workqueue_exit_worker_fn,\n};\n\nint rate_submit_init(struct thread_data *td, struct sk_out *sk_out)\n{\n\tif (td->o.io_submit_mode != IO_MODE_OFFLOAD)\n\t\treturn 0;\n\n\treturn workqueue_init(td, &td->io_wq, &rated_wq_ops, td->o.iodepth, sk_out);\n}\n\nvoid rate_submit_exit(struct thread_data *td)\n{\n\tif (td->o.io_submit_mode != IO_MODE_OFFLOAD)\n\t\treturn;\n\n\tworkqueue_exit(&td->io_wq);\n}\n"
        },
        {
          "name": "rate-submit.h",
          "type": "blob",
          "size": 0.1591796875,
          "content": "#ifndef FIO_RATE_SUBMIT\n#define FIO_RATE_SUBMIT\n\nint rate_submit_init(struct thread_data *, struct sk_out *);\nvoid rate_submit_exit(struct thread_data *);\n\n#endif\n"
        },
        {
          "name": "rwlock.c",
          "type": "blob",
          "size": 1.6884765625,
          "content": "#include <stdio.h>\n#include <string.h>\n#include <sys/mman.h>\n#include <assert.h>\n\n#include \"log.h\"\n#include \"rwlock.h\"\n#include \"os/os.h\"\n\nvoid fio_rwlock_write(struct fio_rwlock *lock)\n{\n\tassert(lock->magic == FIO_RWLOCK_MAGIC);\n\tpthread_rwlock_wrlock(&lock->lock);\n}\n\nvoid fio_rwlock_read(struct fio_rwlock *lock)\n{\n\tassert(lock->magic == FIO_RWLOCK_MAGIC);\n\tpthread_rwlock_rdlock(&lock->lock);\n}\n\nvoid fio_rwlock_unlock(struct fio_rwlock *lock)\n{\n\tassert(lock->magic == FIO_RWLOCK_MAGIC);\n\tpthread_rwlock_unlock(&lock->lock);\n}\n\nvoid fio_rwlock_remove(struct fio_rwlock *lock)\n{\n\tassert(lock->magic == FIO_RWLOCK_MAGIC);\n\tpthread_rwlock_destroy(&lock->lock);\n\tmunmap((void *) lock, sizeof(*lock));\n}\n\nstruct fio_rwlock *fio_rwlock_init(void)\n{\n\tstruct fio_rwlock *lock;\n\tpthread_rwlockattr_t attr;\n\tint ret;\n\n\tlock = (void *) mmap(NULL, sizeof(struct fio_rwlock),\n\t\t\t\tPROT_READ | PROT_WRITE,\n\t\t\t\tOS_MAP_ANON | MAP_SHARED, -1, 0);\n\tif (lock == MAP_FAILED) {\n\t\tperror(\"mmap rwlock\");\n\t\tlock = NULL;\n\t\tgoto err;\n\t}\n\n\tlock->magic = FIO_RWLOCK_MAGIC;\n\n\tret = pthread_rwlockattr_init(&attr);\n\tif (ret) {\n\t\tlog_err(\"pthread_rwlockattr_init: %s\\n\", strerror(ret));\n\t\tgoto err;\n\t}\n#ifdef CONFIG_PSHARED\n\tret = pthread_rwlockattr_setpshared(&attr, PTHREAD_PROCESS_SHARED);\n\tif (ret) {\n\t\tlog_err(\"pthread_rwlockattr_setpshared: %s\\n\", strerror(ret));\n\t\tgoto destroy_attr;\n\t}\n\n\tret = pthread_rwlock_init(&lock->lock, &attr);\n#else\n\tret = pthread_rwlock_init(&lock->lock, NULL);\n#endif\n\n\tif (ret) {\n\t\tlog_err(\"pthread_rwlock_init: %s\\n\", strerror(ret));\n\t\tgoto destroy_attr;\n\t}\n\n\tpthread_rwlockattr_destroy(&attr);\n\n\treturn lock;\ndestroy_attr:\n\tpthread_rwlockattr_destroy(&attr);\nerr:\n\tif (lock)\n\t\tfio_rwlock_remove(lock);\n\treturn NULL;\n}\n"
        },
        {
          "name": "rwlock.h",
          "type": "blob",
          "size": 0.4150390625,
          "content": "#ifndef FIO_RWLOCK_H\n#define FIO_RWLOCK_H\n\n#include <pthread.h>\n\n#define FIO_RWLOCK_MAGIC\t0x52574c4fU\n\nstruct fio_rwlock {\n\tpthread_rwlock_t lock;\n\tint magic;\n};\n\nextern void fio_rwlock_read(struct fio_rwlock *);\nextern void fio_rwlock_write(struct fio_rwlock *);\nextern void fio_rwlock_unlock(struct fio_rwlock *);\nextern struct fio_rwlock *fio_rwlock_init(void);\nextern void fio_rwlock_remove(struct fio_rwlock *);\n\n#endif\n"
        },
        {
          "name": "server.c",
          "type": "blob",
          "size": 65.4208984375,
          "content": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <errno.h>\n#include <poll.h>\n#include <sys/types.h>\n#include <sys/wait.h>\n#include <sys/socket.h>\n#include <sys/stat.h>\n#include <sys/un.h>\n#include <sys/uio.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <netdb.h>\n#include <syslog.h>\n#include <signal.h>\n#ifdef CONFIG_ZLIB\n#include <zlib.h>\n#endif\n\n#include \"fio.h\"\n#include \"options.h\"\n#include \"server.h\"\n#include \"crc/crc16.h\"\n#include \"lib/ieee754.h\"\n#include \"verify-state.h\"\n#include \"smalloc.h\"\n\nint fio_net_port = FIO_NET_PORT;\n\nbool exit_backend = false;\n\nenum {\n\tSK_F_FREE\t= 1,\n\tSK_F_COPY\t= 2,\n\tSK_F_SIMPLE\t= 4,\n\tSK_F_VEC\t= 8,\n\tSK_F_INLINE\t= 16,\n};\n\nstruct sk_entry {\n\tstruct flist_head list;\t/* link on sk_out->list */\n\tint flags;\t\t/* SK_F_* */\n\tint opcode;\t\t/* Actual command fields */\n\tvoid *buf;\n\toff_t size;\n\tuint64_t tag;\n\tstruct flist_head next;\t/* Other sk_entry's, if linked command */\n};\n\nstatic char *fio_server_arg;\nstatic char *bind_sock;\nstatic struct sockaddr_in saddr_in;\nstatic struct sockaddr_in6 saddr_in6;\nstatic int use_ipv6;\n#ifdef CONFIG_ZLIB\nstatic unsigned int has_zlib = 1;\n#else\nstatic unsigned int has_zlib = 0;\n#endif\nstatic unsigned int use_zlib;\nstatic char me[128];\n\nstatic pthread_key_t sk_out_key;\n\n#ifdef WIN32\nstatic char *fio_server_pipe_name  = NULL;\nstatic HANDLE hjob = INVALID_HANDLE_VALUE;\nstruct ffi_element {\n\tunion {\n\t\tpthread_t thread;\n\t\tHANDLE hProcess;\n\t};\n\tbool is_thread;\n};\n#endif\n\nstruct fio_fork_item {\n\tstruct flist_head list;\n\tint exitval;\n\tint signal;\n\tint exited;\n#ifdef WIN32\n\tstruct ffi_element element;\n#else\n\tpid_t pid;\n#endif\n};\n\nstruct cmd_reply {\n\tstruct fio_sem lock;\n\tvoid *data;\n\tsize_t size;\n\tint error;\n};\n\nstatic const char *fio_server_ops[FIO_NET_CMD_NR] = {\n\t\"\",\n\t\"QUIT\",\n\t\"EXIT\",\n\t\"JOB\",\n\t\"JOBLINE\",\n\t\"TEXT\",\n\t\"TS\",\n\t\"GS\",\n\t\"SEND_ETA\",\n\t\"ETA\",\n\t\"PROBE\",\n\t\"START\",\n\t\"STOP\",\n\t\"DISK_UTIL\",\n\t\"SERVER_START\",\n\t\"ADD_JOB\",\n\t\"RUN\",\n\t\"IOLOG\",\n\t\"UPDATE_JOB\",\n\t\"LOAD_FILE\",\n\t\"VTRIGGER\",\n\t\"SENDFILE\",\n\t\"JOB_OPT\",\n};\n\nstatic void sk_lock(struct sk_out *sk_out)\n{\n\tfio_sem_down(&sk_out->lock);\n}\n\nstatic void sk_unlock(struct sk_out *sk_out)\n{\n\tfio_sem_up(&sk_out->lock);\n}\n\nvoid sk_out_assign(struct sk_out *sk_out)\n{\n\tif (!sk_out)\n\t\treturn;\n\n\tsk_lock(sk_out);\n\tsk_out->refs++;\n\tsk_unlock(sk_out);\n\tpthread_setspecific(sk_out_key, sk_out);\n}\n\nstatic void sk_out_free(struct sk_out *sk_out)\n{\n\t__fio_sem_remove(&sk_out->lock);\n\t__fio_sem_remove(&sk_out->wait);\n\t__fio_sem_remove(&sk_out->xmit);\n\tsfree(sk_out);\n}\n\nstatic int __sk_out_drop(struct sk_out *sk_out)\n{\n\tif (sk_out) {\n\t\tint refs;\n\n\t\tsk_lock(sk_out);\n\t\tassert(sk_out->refs != 0);\n\t\trefs = --sk_out->refs;\n\t\tsk_unlock(sk_out);\n\n\t\tif (!refs) {\n\t\t\tsk_out_free(sk_out);\n\t\t\tpthread_setspecific(sk_out_key, NULL);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nvoid sk_out_drop(void)\n{\n\tstruct sk_out *sk_out;\n\n\tsk_out = pthread_getspecific(sk_out_key);\n\t__sk_out_drop(sk_out);\n}\n\nstatic void __fio_init_net_cmd(struct fio_net_cmd *cmd, uint16_t opcode,\n\t\t\t       uint32_t pdu_len, uint64_t tag)\n{\n\tmemset(cmd, 0, sizeof(*cmd));\n\n\tcmd->version\t= __cpu_to_le16(FIO_SERVER_VER);\n\tcmd->opcode\t= cpu_to_le16(opcode);\n\tcmd->tag\t= cpu_to_le64(tag);\n\tcmd->pdu_len\t= cpu_to_le32(pdu_len);\n}\n\n\nstatic void fio_init_net_cmd(struct fio_net_cmd *cmd, uint16_t opcode,\n\t\t\t     const void *pdu, uint32_t pdu_len, uint64_t tag)\n{\n\t__fio_init_net_cmd(cmd, opcode, pdu_len, tag);\n\n\tif (pdu)\n\t\tmemcpy(&cmd->payload, pdu, pdu_len);\n}\n\nconst char *fio_server_op(unsigned int op)\n{\n\tstatic char buf[32];\n\n\tif (op < FIO_NET_CMD_NR)\n\t\treturn fio_server_ops[op];\n\n\tsprintf(buf, \"UNKNOWN/%d\", op);\n\treturn buf;\n}\n\nstatic ssize_t iov_total_len(const struct iovec *iov, int count)\n{\n\tssize_t ret = 0;\n\n\twhile (count--) {\n\t\tret += iov->iov_len;\n\t\tiov++;\n\t}\n\n\treturn ret;\n}\n\nstatic int fio_sendv_data(int sk, struct iovec *iov, int count)\n{\n\tssize_t total_len = iov_total_len(iov, count);\n\tssize_t ret;\n\n\tdo {\n\t\tret = writev(sk, iov, count);\n\t\tif (ret > 0) {\n\t\t\ttotal_len -= ret;\n\t\t\tif (!total_len)\n\t\t\t\tbreak;\n\n\t\t\twhile (ret) {\n\t\t\t\tif (ret >= iov->iov_len) {\n\t\t\t\t\tret -= iov->iov_len;\n\t\t\t\t\tiov++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tiov->iov_base += ret;\n\t\t\t\tiov->iov_len -= ret;\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t} else if (!ret)\n\t\t\tbreak;\n\t\telse if (errno == EAGAIN || errno == EINTR)\n\t\t\tcontinue;\n\t\telse\n\t\t\tbreak;\n\t} while (!exit_backend);\n\n\tif (!total_len)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int fio_send_data(int sk, const void *p, unsigned int len)\n{\n\tstruct iovec iov = { .iov_base = (void *) p, .iov_len = len };\n\n\tassert(len <= sizeof(struct fio_net_cmd) + FIO_SERVER_MAX_FRAGMENT_PDU);\n\n\treturn fio_sendv_data(sk, &iov, 1);\n}\n\nbool fio_server_poll_fd(int fd, short events, int timeout)\n{\n\tstruct pollfd pfd = {\n\t\t.fd\t= fd,\n\t\t.events\t= events,\n\t};\n\tint ret;\n\n\tret = poll(&pfd, 1, timeout);\n\tif (ret < 0) {\n\t\tif (errno == EINTR)\n\t\t\treturn false;\n\t\tlog_err(\"fio: poll: %s\\n\", strerror(errno));\n\t\treturn false;\n\t} else if (!ret) {\n\t\treturn false;\n\t}\n\tif (pfd.revents & events)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int fio_recv_data(int sk, void *buf, unsigned int len, bool wait)\n{\n\tint flags;\n\tchar *p = buf;\n\n\tif (wait)\n\t\tflags = MSG_WAITALL;\n\telse\n\t\tflags = OS_MSG_DONTWAIT;\n\n\tdo {\n\t\tint ret = recv(sk, p, len, flags);\n\n\t\tif (ret > 0) {\n\t\t\tlen -= ret;\n\t\t\tif (!len)\n\t\t\t\tbreak;\n\t\t\tp += ret;\n\t\t\tcontinue;\n\t\t} else if (!ret)\n\t\t\tbreak;\n\t\telse if (errno == EAGAIN || errno == EINTR) {\n\t\t\tif (wait)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t} else\n\t\t\tbreak;\n\t} while (!exit_backend);\n\n\tif (!len)\n\t\treturn 0;\n\n\treturn -1;\n}\n\nstatic int verify_convert_cmd(struct fio_net_cmd *cmd)\n{\n\tuint16_t crc;\n\n\tcmd->cmd_crc16 = le16_to_cpu(cmd->cmd_crc16);\n\tcmd->pdu_crc16 = le16_to_cpu(cmd->pdu_crc16);\n\n\tcrc = fio_crc16(cmd, FIO_NET_CMD_CRC_SZ);\n\tif (crc != cmd->cmd_crc16) {\n\t\tlog_err(\"fio: server bad crc on command (got %x, wanted %x)\\n\",\n\t\t\t\tcmd->cmd_crc16, crc);\n\t\tfprintf(f_err, \"fio: server bad crc on command (got %x, wanted %x)\\n\",\n\t\t\t\tcmd->cmd_crc16, crc);\n\t\treturn 1;\n\t}\n\n\tcmd->version\t= le16_to_cpu(cmd->version);\n\tcmd->opcode\t= le16_to_cpu(cmd->opcode);\n\tcmd->flags\t= le32_to_cpu(cmd->flags);\n\tcmd->tag\t= le64_to_cpu(cmd->tag);\n\tcmd->pdu_len\t= le32_to_cpu(cmd->pdu_len);\n\n\tswitch (cmd->version) {\n\tcase FIO_SERVER_VER:\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: bad server cmd version %d\\n\", cmd->version);\n\t\tfprintf(f_err, \"fio: client/server version mismatch (%d != %d)\\n\",\n\t\t\t\tcmd->version, FIO_SERVER_VER);\n\t\treturn 1;\n\t}\n\n\tif (cmd->pdu_len > FIO_SERVER_MAX_FRAGMENT_PDU) {\n\t\tlog_err(\"fio: command payload too large: %u\\n\", cmd->pdu_len);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n/*\n * Read (and defragment, if necessary) incoming commands\n */\nstruct fio_net_cmd *fio_net_recv_cmd(int sk, bool wait)\n{\n\tstruct fio_net_cmd cmd, *tmp, *cmdret = NULL;\n\tsize_t cmd_size = 0, pdu_offset = 0;\n\tuint16_t crc;\n\tint ret, first = 1;\n\tvoid *pdu = NULL;\n\n\tdo {\n\t\tret = fio_recv_data(sk, &cmd, sizeof(cmd), wait);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t/* We have a command, verify it and swap if need be */\n\t\tret = verify_convert_cmd(&cmd);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (first) {\n\t\t\t/* if this is text, add room for \\0 at the end */\n\t\t\tcmd_size = sizeof(cmd) + cmd.pdu_len + 1;\n\t\t\tassert(!cmdret);\n\t\t} else\n\t\t\tcmd_size += cmd.pdu_len;\n\n\t\tif (cmd_size / 1024 > FIO_SERVER_MAX_CMD_MB * 1024) {\n\t\t\tlog_err(\"fio: cmd+pdu too large (%llu)\\n\", (unsigned long long) cmd_size);\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\ttmp = realloc(cmdret, cmd_size);\n\t\tif (!tmp) {\n\t\t\tlog_err(\"fio: server failed allocating cmd\\n\");\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tcmdret = tmp;\n\n\t\tif (first)\n\t\t\tmemcpy(cmdret, &cmd, sizeof(cmd));\n\t\telse if (cmdret->opcode != cmd.opcode) {\n\t\t\tlog_err(\"fio: fragment opcode mismatch (%d != %d)\\n\",\n\t\t\t\t\tcmdret->opcode, cmd.opcode);\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!cmd.pdu_len)\n\t\t\tbreak;\n\n\t\t/* There's payload, get it */\n\t\tpdu = (char *) cmdret->payload + pdu_offset;\n\t\tret = fio_recv_data(sk, pdu, cmd.pdu_len, wait);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t/* Verify payload crc */\n\t\tcrc = fio_crc16(pdu, cmd.pdu_len);\n\t\tif (crc != cmd.pdu_crc16) {\n\t\t\tlog_err(\"fio: server bad crc on payload \");\n\t\t\tlog_err(\"(got %x, wanted %x)\\n\", cmd.pdu_crc16, crc);\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tpdu_offset += cmd.pdu_len;\n\t\tif (!first)\n\t\t\tcmdret->pdu_len += cmd.pdu_len;\n\t\tfirst = 0;\n\t} while (cmd.flags & FIO_NET_CMD_F_MORE);\n\n\tif (ret) {\n\t\tfree(cmdret);\n\t\tcmdret = NULL;\n\t} else if (cmdret) {\n\t\t/* zero-terminate text input */\n\t\tif (cmdret->pdu_len) {\n\t\t\tif (cmdret->opcode == FIO_NET_CMD_TEXT) {\n\t\t\t\tstruct cmd_text_pdu *__pdu = (struct cmd_text_pdu *) cmdret->payload;\n\t\t\t\tchar *buf = (char *) __pdu->buf;\n\t\t\t\tint len = le32_to_cpu(__pdu->buf_len);\n\n\t\t\t\tbuf[len] = '\\0';\n\t\t\t} else if (cmdret->opcode == FIO_NET_CMD_JOB) {\n\t\t\t\tstruct cmd_job_pdu *__pdu = (struct cmd_job_pdu *) cmdret->payload;\n\t\t\t\tchar *buf = (char *) __pdu->buf;\n\t\t\t\tint len = le32_to_cpu(__pdu->buf_len);\n\n\t\t\t\tbuf[len] = '\\0';\n\t\t\t}\n\t\t}\n\n\t\t/* frag flag is internal */\n\t\tcmdret->flags &= ~FIO_NET_CMD_F_MORE;\n\t}\n\n\treturn cmdret;\n}\n\nstatic void add_reply(uint64_t tag, struct flist_head *list)\n{\n\tstruct fio_net_cmd_reply *reply;\n\n\treply = (struct fio_net_cmd_reply *) (uintptr_t) tag;\n\tflist_add_tail(&reply->list, list);\n}\n\nstatic uint64_t alloc_reply(uint64_t tag, uint16_t opcode)\n{\n\tstruct fio_net_cmd_reply *reply;\n\n\treply = calloc(1, sizeof(*reply));\n\tINIT_FLIST_HEAD(&reply->list);\n\tfio_gettime(&reply->ts, NULL);\n\treply->saved_tag = tag;\n\treply->opcode = opcode;\n\n\treturn (uintptr_t) reply;\n}\n\nstatic void free_reply(uint64_t tag)\n{\n\tstruct fio_net_cmd_reply *reply;\n\n\treply = (struct fio_net_cmd_reply *) (uintptr_t) tag;\n\tfree(reply);\n}\n\nstatic void fio_net_cmd_crc_pdu(struct fio_net_cmd *cmd, const void *pdu)\n{\n\tuint32_t pdu_len;\n\n\tcmd->cmd_crc16 = __cpu_to_le16(fio_crc16(cmd, FIO_NET_CMD_CRC_SZ));\n\n\tpdu_len = le32_to_cpu(cmd->pdu_len);\n\tcmd->pdu_crc16 = __cpu_to_le16(fio_crc16(pdu, pdu_len));\n}\n\nstatic void fio_net_cmd_crc(struct fio_net_cmd *cmd)\n{\n\tfio_net_cmd_crc_pdu(cmd, cmd->payload);\n}\n\nint fio_net_send_cmd(int fd, uint16_t opcode, const void *buf, off_t size,\n\t\t     uint64_t *tagptr, struct flist_head *list)\n{\n\tstruct fio_net_cmd *cmd = NULL;\n\tsize_t this_len, cur_len = 0;\n\tuint64_t tag;\n\tint ret;\n\n\tif (list) {\n\t\tassert(tagptr);\n\t\ttag = *tagptr = alloc_reply(*tagptr, opcode);\n\t} else\n\t\ttag = tagptr ? *tagptr : 0;\n\n\tdo {\n\t\tthis_len = size;\n\t\tif (this_len > FIO_SERVER_MAX_FRAGMENT_PDU)\n\t\t\tthis_len = FIO_SERVER_MAX_FRAGMENT_PDU;\n\n\t\tif (!cmd || cur_len < sizeof(*cmd) + this_len) {\n\t\t\tif (cmd)\n\t\t\t\tfree(cmd);\n\n\t\t\tcur_len = sizeof(*cmd) + this_len;\n\t\t\tcmd = malloc(cur_len);\n\t\t}\n\n\t\tfio_init_net_cmd(cmd, opcode, buf, this_len, tag);\n\n\t\tif (this_len < size)\n\t\t\tcmd->flags = __cpu_to_le32(FIO_NET_CMD_F_MORE);\n\n\t\tfio_net_cmd_crc(cmd);\n\n\t\tret = fio_send_data(fd, cmd, sizeof(*cmd) + this_len);\n\t\tsize -= this_len;\n\t\tbuf += this_len;\n\t} while (!ret && size);\n\n\tif (list) {\n\t\tif (ret)\n\t\t\tfree_reply(tag);\n\t\telse\n\t\t\tadd_reply(tag, list);\n\t}\n\n\tif (cmd)\n\t\tfree(cmd);\n\n\treturn ret;\n}\n\nstatic struct sk_entry *fio_net_prep_cmd(uint16_t opcode, void *buf,\n\t\t\t\t\t size_t size, uint64_t *tagptr,\n\t\t\t\t\t int flags)\n{\n\tstruct sk_entry *entry;\n\n\tentry = smalloc(sizeof(*entry));\n\tif (!entry)\n\t\treturn NULL;\n\n\tINIT_FLIST_HEAD(&entry->next);\n\tentry->opcode = opcode;\n\tif (flags & SK_F_COPY) {\n\t\tentry->buf = smalloc(size);\n\t\tmemcpy(entry->buf, buf, size);\n\t} else\n\t\tentry->buf = buf;\n\n\tentry->size = size;\n\tif (tagptr)\n\t\tentry->tag = *tagptr;\n\telse\n\t\tentry->tag = 0;\n\tentry->flags = flags;\n\treturn entry;\n}\n\nstatic int handle_sk_entry(struct sk_out *sk_out, struct sk_entry *entry);\n\nstatic void fio_net_queue_entry(struct sk_entry *entry)\n{\n\tstruct sk_out *sk_out = pthread_getspecific(sk_out_key);\n\n\tif (entry->flags & SK_F_INLINE)\n\t\thandle_sk_entry(sk_out, entry);\n\telse {\n\t\tsk_lock(sk_out);\n\t\tflist_add_tail(&entry->list, &sk_out->list);\n\t\tsk_unlock(sk_out);\n\n\t\tfio_sem_up(&sk_out->wait);\n\t}\n}\n\nstatic int fio_net_queue_cmd(uint16_t opcode, void *buf, off_t size,\n\t\t\t     uint64_t *tagptr, int flags)\n{\n\tstruct sk_entry *entry;\n\n\tentry = fio_net_prep_cmd(opcode, buf, size, tagptr, flags);\n\tif (entry) {\n\t\tfio_net_queue_entry(entry);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic int fio_net_send_simple_stack_cmd(int sk, uint16_t opcode, uint64_t tag)\n{\n\tstruct fio_net_cmd cmd;\n\n\tfio_init_net_cmd(&cmd, opcode, NULL, 0, tag);\n\tfio_net_cmd_crc(&cmd);\n\n\treturn fio_send_data(sk, &cmd, sizeof(cmd));\n}\n\n/*\n * If 'list' is non-NULL, then allocate and store the sent command for\n * later verification.\n */\nint fio_net_send_simple_cmd(int sk, uint16_t opcode, uint64_t tag,\n\t\t\t    struct flist_head *list)\n{\n\tint ret;\n\n\tif (list)\n\t\ttag = alloc_reply(tag, opcode);\n\n\tret = fio_net_send_simple_stack_cmd(sk, opcode, tag);\n\tif (ret) {\n\t\tif (list)\n\t\t\tfree_reply(tag);\n\n\t\treturn ret;\n\t}\n\n\tif (list)\n\t\tadd_reply(tag, list);\n\n\treturn 0;\n}\n\nstatic int fio_net_queue_quit(void)\n{\n\tdprint(FD_NET, \"server: sending quit\\n\");\n\n\treturn fio_net_queue_cmd(FIO_NET_CMD_QUIT, NULL, 0, NULL, SK_F_SIMPLE);\n}\n\nint fio_net_send_quit(int sk)\n{\n\tdprint(FD_NET, \"server: sending quit\\n\");\n\n\treturn fio_net_send_simple_cmd(sk, FIO_NET_CMD_QUIT, 0, NULL);\n}\n\nstatic int fio_net_send_ack(struct fio_net_cmd *cmd, int error, int signal)\n{\n\tstruct cmd_end_pdu epdu;\n\tuint64_t tag = 0;\n\n\tif (cmd)\n\t\ttag = cmd->tag;\n\n\tepdu.error = __cpu_to_le32(error);\n\tepdu.signal = __cpu_to_le32(signal);\n\treturn fio_net_queue_cmd(FIO_NET_CMD_STOP, &epdu, sizeof(epdu), &tag, SK_F_COPY);\n}\n\nstatic int fio_net_queue_stop(int error, int signal)\n{\n\tdprint(FD_NET, \"server: sending stop (%d, %d)\\n\", error, signal);\n\treturn fio_net_send_ack(NULL, error, signal);\n}\n\n#ifdef WIN32\nstatic void fio_server_add_fork_item(struct ffi_element *element, struct flist_head *list)\n{\n\tstruct fio_fork_item *ffi;\n\n\tffi = malloc(sizeof(*ffi));\n\tffi->exitval = 0;\n\tffi->signal = 0;\n\tffi->exited = 0;\n\tffi->element = *element;\n\tflist_add_tail(&ffi->list, list);\n}\n\nstatic void fio_server_add_conn_pid(struct flist_head *conn_list, HANDLE hProcess)\n{\n\tstruct ffi_element element = {.hProcess = hProcess, .is_thread=FALSE};\n\tdprint(FD_NET, \"server: forked off connection job (tid=%u)\\n\", (int) element.thread);\n\n\tfio_server_add_fork_item(&element, conn_list);\n}\n\nstatic void fio_server_add_job_pid(struct flist_head *job_list, pthread_t thread)\n{\n\tstruct ffi_element element = {.thread = thread, .is_thread=TRUE};\n\tdprint(FD_NET, \"server: forked off job job (tid=%u)\\n\", (int) element.thread);\n\tfio_server_add_fork_item(&element, job_list);\n}\n\nstatic void fio_server_check_fork_item(struct fio_fork_item *ffi)\n{\n\tint ret;\n\n\tif (ffi->element.is_thread) {\n\n\t\tret = pthread_kill(ffi->element.thread, 0);\n\t\tif (ret) {\n\t\t\tint rev_val;\n\t\t\tpthread_join(ffi->element.thread, (void**) &rev_val); /*if the thread is dead, then join it to get status*/\n\n\t\t\tffi->exitval = rev_val;\n\t\t\tif (ffi->exitval)\n\t\t\t\tlog_err(\"thread (tid=%u) exited with %x\\n\", (int) ffi->element.thread, (int) ffi->exitval);\n\t\t\tdprint(FD_PROCESS, \"thread (tid=%u) exited with %x\\n\", (int) ffi->element.thread, (int) ffi->exitval);\n\t\t\tffi->exited = 1;\n\t\t}\n\t} else {\n\t\tDWORD exit_val;\n\t\tGetExitCodeProcess(ffi->element.hProcess, &exit_val);\n\n\t\tif (exit_val != STILL_ACTIVE) {\n\t\t\tdprint(FD_PROCESS, \"process %u exited with %d\\n\", GetProcessId(ffi->element.hProcess), exit_val);\n\t\t\tffi->exited = 1;\n\t\t\tffi->exitval = exit_val;\n\t\t}\n\t}\n}\n#else\nstatic void fio_server_add_fork_item(pid_t pid, struct flist_head *list)\n{\n\tstruct fio_fork_item *ffi;\n\n\tffi = malloc(sizeof(*ffi));\n\tffi->exitval = 0;\n\tffi->signal = 0;\n\tffi->exited = 0;\n\tffi->pid = pid;\n\tflist_add_tail(&ffi->list, list);\n}\n\nstatic void fio_server_add_conn_pid(struct flist_head *conn_list, pid_t pid)\n{\n\tdprint(FD_NET, \"server: forked off connection job (pid=%u)\\n\", (int) pid);\n\tfio_server_add_fork_item(pid, conn_list);\n}\n\nstatic void fio_server_add_job_pid(struct flist_head *job_list, pid_t pid)\n{\n\tdprint(FD_NET, \"server: forked off job job (pid=%u)\\n\", (int) pid);\n\tfio_server_add_fork_item(pid, job_list);\n}\n\nstatic void fio_server_check_fork_item(struct fio_fork_item *ffi)\n{\n\tint ret, status;\n\n\tret = waitpid(ffi->pid, &status, WNOHANG);\n\tif (ret < 0) {\n\t\tif (errno == ECHILD) {\n\t\t\tlog_err(\"fio: connection pid %u disappeared\\n\", (int) ffi->pid);\n\t\t\tffi->exited = 1;\n\t\t} else\n\t\t\tlog_err(\"fio: waitpid: %s\\n\", strerror(errno));\n\t} else if (ret == ffi->pid) {\n\t\tif (WIFSIGNALED(status)) {\n\t\t\tffi->signal = WTERMSIG(status);\n\t\t\tffi->exited = 1;\n\t\t}\n\t\tif (WIFEXITED(status)) {\n\t\t\tif (WEXITSTATUS(status))\n\t\t\t\tffi->exitval = WEXITSTATUS(status);\n\t\t\tffi->exited = 1;\n\t\t}\n\t}\n}\n#endif\n\nstatic void fio_server_fork_item_done(struct fio_fork_item *ffi, bool stop)\n{\n#ifdef WIN32\n\tif (ffi->element.is_thread)\n\t\tdprint(FD_NET, \"tid %u exited, sig=%u, exitval=%d\\n\", (int) ffi->element.thread, ffi->signal, ffi->exitval);\n\telse {\n\t\tdprint(FD_NET, \"pid %u exited, sig=%u, exitval=%d\\n\", (int)  GetProcessId(ffi->element.hProcess), ffi->signal, ffi->exitval);\n\t\tCloseHandle(ffi->element.hProcess);\n\t\tffi->element.hProcess = INVALID_HANDLE_VALUE;\n\t}\n#else\n\tdprint(FD_NET, \"pid %u exited, sig=%u, exitval=%d\\n\", (int) ffi->pid, ffi->signal, ffi->exitval);\n#endif\n\n\t/*\n\t * Fold STOP and QUIT...\n\t */\n\tif (stop) {\n\t\tfio_net_queue_stop(ffi->exitval, ffi->signal);\n\t\tfio_net_queue_quit();\n\t}\n\n\tflist_del(&ffi->list);\n\tfree(ffi);\n}\n\nstatic void fio_server_check_fork_items(struct flist_head *list, bool stop)\n{\n\tstruct flist_head *entry, *tmp;\n\tstruct fio_fork_item *ffi;\n\n\tflist_for_each_safe(entry, tmp, list) {\n\t\tffi = flist_entry(entry, struct fio_fork_item, list);\n\n\t\tfio_server_check_fork_item(ffi);\n\n\t\tif (ffi->exited)\n\t\t\tfio_server_fork_item_done(ffi, stop);\n\t}\n}\n\nstatic void fio_server_check_jobs(struct flist_head *job_list)\n{\n\tfio_server_check_fork_items(job_list, true);\n}\n\nstatic void fio_server_check_conns(struct flist_head *conn_list)\n{\n\tfio_server_check_fork_items(conn_list, false);\n}\n\nstatic int handle_load_file_cmd(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_load_file_pdu *pdu = (struct cmd_load_file_pdu *) cmd->payload;\n\tvoid *file_name = pdu->file;\n\tstruct cmd_start_pdu spdu;\n\n\tdprint(FD_NET, \"server: loading local file %s\\n\", (char *) file_name);\n\n\tpdu->name_len = le16_to_cpu(pdu->name_len);\n\tpdu->client_type = le16_to_cpu(pdu->client_type);\n\n\tif (parse_jobs_ini(file_name, 0, 0, pdu->client_type)) {\n\t\tfio_net_queue_quit();\n\t\treturn -1;\n\t}\n\n\tspdu.jobs = cpu_to_le32(thread_number);\n\tspdu.stat_outputs = cpu_to_le32(stat_number);\n\tfio_net_queue_cmd(FIO_NET_CMD_START, &spdu, sizeof(spdu), NULL, SK_F_COPY);\n\treturn 0;\n}\n\n#ifdef WIN32\nstatic void *fio_backend_thread(void *data)\n{\n\tint ret;\n\tstruct sk_out *sk_out = (struct sk_out *) data;\n\n\tsk_out_assign(sk_out);\n\n\tret = fio_backend(sk_out);\n\tsk_out_drop();\n\n\tpthread_exit((void*) (intptr_t) ret);\n\treturn NULL;\n}\n#endif\n\nstatic int handle_run_cmd(struct sk_out *sk_out, struct flist_head *job_list,\n\t\t\t  struct fio_net_cmd *cmd)\n{\n\tint ret;\n\n\tfio_time_init();\n\tset_genesis_time();\n\n#ifdef WIN32\n\t{\n\t\tpthread_t thread;\n\t\t/* both this thread and backend_thread call sk_out_assign() to double increment\n\t\t * the ref count.  This ensures struct is valid until both threads are done with it\n\t\t */\n\t\tsk_out_assign(sk_out);\n\t\tret = pthread_create(&thread, NULL,\tfio_backend_thread, sk_out);\n\t\tif (ret) {\n\t\t\tlog_err(\"pthread_create: %s\\n\", strerror(ret));\n\t\t\treturn ret;\n\t\t}\n\n\t\tfio_server_add_job_pid(job_list, thread);\n\t\treturn ret;\n\t}\n#else\n    {\n\t\tpid_t pid;\n\t\tsk_out_assign(sk_out);\n\t\tpid = fork();\n\t\tif (pid) {\n\t\t\tfio_server_add_job_pid(job_list, pid);\n\t\t\treturn 0;\n\t\t}\n\n\t\tret = fio_backend(sk_out);\n\t\tfree_threads_shm();\n\t\tsk_out_drop();\n\t\t_exit(ret);\n\t}\n#endif\n}\n\nstatic int handle_job_cmd(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_job_pdu *pdu = (struct cmd_job_pdu *) cmd->payload;\n\tvoid *buf = pdu->buf;\n\tstruct cmd_start_pdu spdu;\n\n\tpdu->buf_len = le32_to_cpu(pdu->buf_len);\n\tpdu->client_type = le32_to_cpu(pdu->client_type);\n\n\tif (parse_jobs_ini(buf, 1, 0, pdu->client_type)) {\n\t\tfio_net_queue_quit();\n\t\treturn -1;\n\t}\n\n\tspdu.jobs = cpu_to_le32(thread_number);\n\tspdu.stat_outputs = cpu_to_le32(stat_number);\n\n\tfio_net_queue_cmd(FIO_NET_CMD_START, &spdu, sizeof(spdu), NULL, SK_F_COPY);\n\treturn 0;\n}\n\nstatic int handle_jobline_cmd(struct fio_net_cmd *cmd)\n{\n\tvoid *pdu = cmd->payload;\n\tstruct cmd_single_line_pdu *cslp;\n\tstruct cmd_line_pdu *clp;\n\tunsigned long offset;\n\tstruct cmd_start_pdu spdu;\n\tchar **argv;\n\tint i;\n\n\tclp = pdu;\n\tclp->lines = le16_to_cpu(clp->lines);\n\tclp->client_type = le16_to_cpu(clp->client_type);\n\targv = malloc(clp->lines * sizeof(char *));\n\toffset = sizeof(*clp);\n\n\tdprint(FD_NET, \"server: %d command line args\\n\", clp->lines);\n\n\tfor (i = 0; i < clp->lines; i++) {\n\t\tcslp = pdu + offset;\n\t\targv[i] = (char *) cslp->text;\n\n\t\toffset += sizeof(*cslp) + le16_to_cpu(cslp->len);\n\t\tdprint(FD_NET, \"server: %d: %s\\n\", i, argv[i]);\n\t}\n\n\tif (parse_cmd_line(clp->lines, argv, clp->client_type)) {\n\t\tfio_net_queue_quit();\n\t\tfree(argv);\n\t\treturn -1;\n\t}\n\n\tfree(argv);\n\n\tspdu.jobs = cpu_to_le32(thread_number);\n\tspdu.stat_outputs = cpu_to_le32(stat_number);\n\n\tfio_net_queue_cmd(FIO_NET_CMD_START, &spdu, sizeof(spdu), NULL, SK_F_COPY);\n\treturn 0;\n}\n\nstatic int handle_probe_cmd(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_client_probe_pdu *pdu = (struct cmd_client_probe_pdu *) cmd->payload;\n\tuint64_t tag = cmd->tag;\n\tstruct cmd_probe_reply_pdu probe = {\n#ifdef CONFIG_BIG_ENDIAN\n\t\t.bigendian\t= 1,\n#endif\n\t\t.os\t\t= FIO_OS,\n\t\t.arch\t\t= FIO_ARCH,\n\t\t.bpp\t\t= sizeof(void *),\n\t\t.cpus\t\t= __cpu_to_le32(cpus_configured()),\n\t};\n\n\tdprint(FD_NET, \"server: sending probe reply\\n\");\n\n\tstrcpy(me, (char *) pdu->server);\n\n\tgethostname((char *) probe.hostname, sizeof(probe.hostname));\n\tsnprintf((char *) probe.fio_version, sizeof(probe.fio_version), \"%s\",\n\t\t fio_version_string);\n\n\t/*\n\t * If the client supports compression and we do too, then enable it\n\t */\n\tif (has_zlib && le64_to_cpu(pdu->flags) & FIO_PROBE_FLAG_ZLIB) {\n\t\tprobe.flags = __cpu_to_le64(FIO_PROBE_FLAG_ZLIB);\n\t\tuse_zlib = 1;\n\t} else {\n\t\tprobe.flags = 0;\n\t\tuse_zlib = 0;\n\t}\n\n\treturn fio_net_queue_cmd(FIO_NET_CMD_PROBE, &probe, sizeof(probe), &tag, SK_F_COPY);\n}\n\nstatic int handle_send_eta_cmd(struct fio_net_cmd *cmd)\n{\n\tstruct jobs_eta *je;\n\tuint64_t tag = cmd->tag;\n\tsize_t size;\n\tint i;\n\n\tdprint(FD_NET, \"server sending status\\n\");\n\n\t/*\n\t * Fake ETA return if we don't have a local one, otherwise the client\n\t * will end up timing out waiting for a response to the ETA request\n\t */\n\tje = get_jobs_eta(true, &size);\n\tif (!je) {\n\t\tsize = sizeof(*je);\n\t\tje = calloc(1, size);\n\t} else {\n\t\tje->nr_running\t\t= cpu_to_le32(je->nr_running);\n\t\tje->nr_ramp\t\t= cpu_to_le32(je->nr_ramp);\n\t\tje->nr_pending\t\t= cpu_to_le32(je->nr_pending);\n\t\tje->nr_setting_up\t= cpu_to_le32(je->nr_setting_up);\n\t\tje->files_open\t\t= cpu_to_le32(je->files_open);\n\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tje->m_rate[i]\t= cpu_to_le64(je->m_rate[i]);\n\t\t\tje->t_rate[i]\t= cpu_to_le64(je->t_rate[i]);\n\t\t\tje->m_iops[i]\t= cpu_to_le32(je->m_iops[i]);\n\t\t\tje->t_iops[i]\t= cpu_to_le32(je->t_iops[i]);\n\t\t\tje->rate[i]\t= cpu_to_le64(je->rate[i]);\n\t\t\tje->iops[i]\t= cpu_to_le32(je->iops[i]);\n\t\t}\n\n\t\tje->elapsed_sec\t\t= cpu_to_le64(je->elapsed_sec);\n\t\tje->eta_sec\t\t= cpu_to_le64(je->eta_sec);\n\t\tje->nr_threads\t\t= cpu_to_le32(je->nr_threads);\n\t\tje->is_pow2\t\t= cpu_to_le32(je->is_pow2);\n\t\tje->unit_base\t\t= cpu_to_le32(je->unit_base);\n\t}\n\n\tfio_net_queue_cmd(FIO_NET_CMD_ETA, je, size, &tag, SK_F_FREE);\n\treturn 0;\n}\n\nstatic int send_update_job_reply(uint64_t __tag, int error)\n{\n\tuint64_t tag = __tag;\n\tuint32_t pdu_error;\n\n\tpdu_error = __cpu_to_le32(error);\n\treturn fio_net_queue_cmd(FIO_NET_CMD_UPDATE_JOB, &pdu_error, sizeof(pdu_error), &tag, SK_F_COPY);\n}\n\nstatic int handle_update_job_cmd(struct fio_net_cmd *cmd)\n{\n\tstruct cmd_add_job_pdu *pdu = (struct cmd_add_job_pdu *) cmd->payload;\n\tstruct thread_data *td;\n\tuint32_t tnumber;\n\tint ret;\n\n\ttnumber = le32_to_cpu(pdu->thread_number);\n\n\tdprint(FD_NET, \"server: updating options for job %u\\n\", tnumber);\n\n\tif (!tnumber || tnumber > thread_number) {\n\t\tsend_update_job_reply(cmd->tag, ENODEV);\n\t\treturn 0;\n\t}\n\n\ttd = tnumber_to_td(tnumber);\n\tret = convert_thread_options_to_cpu(&td->o, &pdu->top,\n\t\t\tcmd->pdu_len - offsetof(struct cmd_add_job_pdu, top));\n\tsend_update_job_reply(cmd->tag, ret);\n\treturn 0;\n}\n\nstatic int handle_trigger_cmd(struct fio_net_cmd *cmd, struct flist_head *job_list)\n{\n\tstruct cmd_vtrigger_pdu *pdu = (struct cmd_vtrigger_pdu *) cmd->payload;\n\tchar *buf = (char *) pdu->cmd;\n\tstruct all_io_list *rep;\n\tsize_t sz;\n\n\tpdu->len = le16_to_cpu(pdu->len);\n\tbuf[pdu->len] = '\\0';\n\n\trep = get_all_io_list(IO_LIST_ALL, &sz);\n\tif (!rep) {\n\t\tstruct all_io_list state;\n\n\t\tstate.threads = cpu_to_le64((uint64_t) 0);\n\t\tfio_net_queue_cmd(FIO_NET_CMD_VTRIGGER, &state, sizeof(state), NULL, SK_F_COPY | SK_F_INLINE);\n\t} else\n\t\tfio_net_queue_cmd(FIO_NET_CMD_VTRIGGER, rep, sz, NULL, SK_F_FREE | SK_F_INLINE);\n\n\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n\tfio_server_check_jobs(job_list);\n\texec_trigger(buf);\n\treturn 0;\n}\n\nstatic int handle_command(struct sk_out *sk_out, struct flist_head *job_list,\n\t\t\t  struct fio_net_cmd *cmd)\n{\n\tint ret;\n\n\tdprint(FD_NET, \"server: got op [%s], pdu=%u, tag=%llx\\n\",\n\t\t\tfio_server_op(cmd->opcode), cmd->pdu_len,\n\t\t\t(unsigned long long) cmd->tag);\n\n\tswitch (cmd->opcode) {\n\tcase FIO_NET_CMD_QUIT:\n\t\tfio_terminate_threads(TERMINATE_ALL, TERMINATE_ALL);\n\t\tret = 0;\n\t\tbreak;\n\tcase FIO_NET_CMD_EXIT:\n\t\texit_backend = true;\n\t\treturn -1;\n\tcase FIO_NET_CMD_LOAD_FILE:\n\t\tret = handle_load_file_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_JOB:\n\t\tret = handle_job_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_JOBLINE:\n\t\tret = handle_jobline_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_PROBE:\n\t\tret = handle_probe_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_SEND_ETA:\n\t\tret = handle_send_eta_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_RUN:\n\t\tret = handle_run_cmd(sk_out, job_list, cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_UPDATE_JOB:\n\t\tret = handle_update_job_cmd(cmd);\n\t\tbreak;\n\tcase FIO_NET_CMD_VTRIGGER:\n\t\tret = handle_trigger_cmd(cmd, job_list);\n\t\tbreak;\n\tcase FIO_NET_CMD_SENDFILE: {\n\t\tstruct cmd_sendfile_reply *in;\n\t\tstruct cmd_reply *rep;\n\n\t\trep = (struct cmd_reply *) (uintptr_t) cmd->tag;\n\n\t\tin = (struct cmd_sendfile_reply *) cmd->payload;\n\t\tin->size = le32_to_cpu(in->size);\n\t\tin->error = le32_to_cpu(in->error);\n\t\tif (in->error) {\n\t\t\tret = 1;\n\t\t\trep->error = in->error;\n\t\t} else {\n\t\t\tret = 0;\n\t\t\trep->data = smalloc(in->size);\n\t\t\tif (!rep->data) {\n\t\t\t\tret = 1;\n\t\t\t\trep->error = ENOMEM;\n\t\t\t} else {\n\t\t\t\trep->size = in->size;\n\t\t\t\tmemcpy(rep->data, in->data, in->size);\n\t\t\t}\n\t\t}\n\t\tfio_sem_up(&rep->lock);\n\t\tbreak;\n\t\t}\n\tdefault:\n\t\tlog_err(\"fio: unknown opcode: %s\\n\", fio_server_op(cmd->opcode));\n\t\tret = 1;\n\t}\n\n\treturn ret;\n}\n\n/*\n * Send a command with a separate PDU, not inlined in the command\n */\nstatic int fio_send_cmd_ext_pdu(int sk, uint16_t opcode, const void *buf,\n\t\t\t\toff_t size, uint64_t tag, uint32_t flags)\n{\n\tstruct fio_net_cmd cmd;\n\tstruct iovec iov[2];\n\tsize_t this_len;\n\tint ret;\n\n\tiov[0].iov_base = (void *) &cmd;\n\tiov[0].iov_len = sizeof(cmd);\n\n\tdo {\n\t\tuint32_t this_flags = flags;\n\n\t\tthis_len = size;\n\t\tif (this_len > FIO_SERVER_MAX_FRAGMENT_PDU)\n\t\t\tthis_len = FIO_SERVER_MAX_FRAGMENT_PDU;\n\n\t\tif (this_len < size)\n\t\t\tthis_flags |= FIO_NET_CMD_F_MORE;\n\n\t\t__fio_init_net_cmd(&cmd, opcode, this_len, tag);\n\t\tcmd.flags = __cpu_to_le32(this_flags);\n\t\tfio_net_cmd_crc_pdu(&cmd, buf);\n\n\t\tiov[1].iov_base = (void *) buf;\n\t\tiov[1].iov_len = this_len;\n\n\t\tret = fio_sendv_data(sk, iov, 2);\n\t\tsize -= this_len;\n\t\tbuf += this_len;\n\t} while (!ret && size);\n\n\treturn ret;\n}\n\nstatic void finish_entry(struct sk_entry *entry)\n{\n\tif (entry->flags & SK_F_FREE)\n\t\tfree(entry->buf);\n\telse if (entry->flags & SK_F_COPY)\n\t\tsfree(entry->buf);\n\n\tsfree(entry);\n}\n\nstatic void entry_set_flags(struct sk_entry *entry, struct flist_head *list,\n\t\t\t    unsigned int *flags)\n{\n\tif (!flist_empty(list))\n\t\t*flags = FIO_NET_CMD_F_MORE;\n\telse\n\t\t*flags = 0;\n}\n\nstatic int send_vec_entry(struct sk_out *sk_out, struct sk_entry *first)\n{\n\tunsigned int flags;\n\tint ret;\n\n\tentry_set_flags(first, &first->next, &flags);\n\n\tret = fio_send_cmd_ext_pdu(sk_out->sk, first->opcode, first->buf,\n\t\t\t\t\tfirst->size, first->tag, flags);\n\n\twhile (!flist_empty(&first->next)) {\n\t\tstruct sk_entry *next;\n\n\t\tnext = flist_first_entry(&first->next, struct sk_entry, list);\n\t\tflist_del_init(&next->list);\n\n\t\tentry_set_flags(next, &first->next, &flags);\n\n\t\tret += fio_send_cmd_ext_pdu(sk_out->sk, next->opcode, next->buf,\n\t\t\t\t\t\tnext->size, next->tag, flags);\n\t\tfinish_entry(next);\n\t}\n\n\treturn ret;\n}\n\nstatic int handle_sk_entry(struct sk_out *sk_out, struct sk_entry *entry)\n{\n\tint ret;\n\n\tfio_sem_down(&sk_out->xmit);\n\n\tif (entry->flags & SK_F_VEC)\n\t\tret = send_vec_entry(sk_out, entry);\n\telse if (entry->flags & SK_F_SIMPLE) {\n\t\tret = fio_net_send_simple_cmd(sk_out->sk, entry->opcode,\n\t\t\t\t\t\tentry->tag, NULL);\n\t} else {\n\t\tret = fio_net_send_cmd(sk_out->sk, entry->opcode, entry->buf,\n\t\t\t\t\tentry->size, &entry->tag, NULL);\n\t}\n\n\tfio_sem_up(&sk_out->xmit);\n\n\tif (ret)\n\t\tlog_err(\"fio: failed handling cmd %s\\n\", fio_server_op(entry->opcode));\n\n\tfinish_entry(entry);\n\treturn ret;\n}\n\nstatic int handle_xmits(struct sk_out *sk_out)\n{\n\tstruct sk_entry *entry;\n\tFLIST_HEAD(list);\n\tint ret = 0;\n\n\tsk_lock(sk_out);\n\tif (flist_empty(&sk_out->list)) {\n\t\tsk_unlock(sk_out);\n\t\treturn 0;\n\t}\n\n\tflist_splice_init(&sk_out->list, &list);\n\tsk_unlock(sk_out);\n\n\twhile (!flist_empty(&list)) {\n\t\tentry = flist_first_entry(&list, struct sk_entry, list);\n\t\tflist_del(&entry->list);\n\t\tret += handle_sk_entry(sk_out, entry);\n\t}\n\n\treturn ret;\n}\n\nstatic int handle_connection(struct sk_out *sk_out)\n{\n\tstruct fio_net_cmd *cmd = NULL;\n\tFLIST_HEAD(job_list);\n\tint ret = 0;\n\n\treset_fio_state();\n\n\t/* read forever */\n\twhile (!exit_backend) {\n\t\tstruct pollfd pfd = {\n\t\t\t.fd\t= sk_out->sk,\n\t\t\t.events\t= POLLIN,\n\t\t};\n\n\t\tdo {\n\t\t\tint timeout = 1000;\n\n\t\t\tif (!flist_empty(&job_list))\n\t\t\t\ttimeout = 100;\n\n\t\t\thandle_xmits(sk_out);\n\n\t\t\tret = poll(&pfd, 1, 0);\n\t\t\tif (ret < 0) {\n\t\t\t\tif (errno == EINTR)\n\t\t\t\t\tbreak;\n\t\t\t\tlog_err(\"fio: poll: %s\\n\", strerror(errno));\n\t\t\t\tbreak;\n\t\t\t} else if (!ret) {\n\t\t\t\tfio_server_check_jobs(&job_list);\n\t\t\t\tfio_sem_down_timeout(&sk_out->wait, timeout);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (pfd.revents & POLLIN)\n\t\t\t\tbreak;\n\t\t\tif (pfd.revents & (POLLERR|POLLHUP)) {\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} while (!exit_backend);\n\n\t\tfio_server_check_jobs(&job_list);\n\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\tif (pfd.revents & POLLIN)\n\t\t\tcmd = fio_net_recv_cmd(sk_out->sk, true);\n\t\tif (!cmd) {\n\t\t\tret = -1;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = handle_command(sk_out, &job_list, cmd);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tfree(cmd);\n\t\tcmd = NULL;\n\t}\n\n\tif (cmd)\n\t\tfree(cmd);\n\n\thandle_xmits(sk_out);\n\n\tclose(sk_out->sk);\n\tsk_out->sk = -1;\n\t__sk_out_drop(sk_out);\n\t_exit(ret);\n}\n\n/* get the address on this host bound by the input socket,\n * whether it is ipv6 or ipv4 */\n\nstatic int get_my_addr_str(int sk)\n{\n\tstruct sockaddr_in6 myaddr6 = { 0, };\n\tstruct sockaddr_in myaddr4 = { 0, };\n\tstruct sockaddr *sockaddr_p;\n\tchar *net_addr;\n\tsocklen_t len;\n\tint ret;\n\n\tif (use_ipv6) {\n\t\tlen = sizeof(myaddr6);\n\t\tsockaddr_p = (struct sockaddr * )&myaddr6;\n\t\tnet_addr = (char * )&myaddr6.sin6_addr;\n\t} else {\n\t\tlen = sizeof(myaddr4);\n\t\tsockaddr_p = (struct sockaddr * )&myaddr4;\n\t\tnet_addr = (char * )&myaddr4.sin_addr;\n\t}\n\n\tret = getsockname(sk, sockaddr_p, &len);\n\tif (ret) {\n\t\tlog_err(\"fio: getsockname: %s\\n\", strerror(errno));\n\t\treturn -1;\n\t}\n\n\tif (!inet_ntop(use_ipv6?AF_INET6:AF_INET, net_addr, client_sockaddr_str, INET6_ADDRSTRLEN - 1)) {\n\t\tlog_err(\"inet_ntop: failed to convert addr to string\\n\");\n\t\treturn -1;\n\t}\n\n\tdprint(FD_NET, \"fio server bound to addr %s\\n\", client_sockaddr_str);\n\treturn 0;\n}\n\n#ifdef WIN32\nstatic int handle_connection_process(void)\n{\n\tWSAPROTOCOL_INFO protocol_info;\n\tDWORD bytes_read;\n\tHANDLE hpipe;\n\tint sk;\n\tstruct sk_out *sk_out;\n\tint ret;\n\tchar *msg = (char *) \"connected\";\n\n\tlog_info(\"server enter accept loop.  ProcessID %d\\n\", GetCurrentProcessId());\n\n\thpipe = CreateFile(\n\t\t\t\t\tfio_server_pipe_name,\n\t\t\t\t\tGENERIC_READ | GENERIC_WRITE,\n\t\t\t\t\t0, NULL,\n\t\t\t\t\tOPEN_EXISTING,\n\t\t\t\t\t0, NULL);\n\n\tif (hpipe == INVALID_HANDLE_VALUE) {\n\t\tlog_err(\"couldnt open pipe %s error %lu\\n\",\n\t\t\t\tfio_server_pipe_name, GetLastError());\n\t\treturn -1;\n\t}\n\n\tif (!ReadFile(hpipe, &protocol_info, sizeof(protocol_info), &bytes_read, NULL)) {\n\t\tlog_err(\"couldnt read pi from pipe %s error %lu\\n\", fio_server_pipe_name,\n\t\t\t\tGetLastError());\n\t}\n\n\tif (use_ipv6) /* use protocol_info to create a duplicate of parents socket */\n\t\tsk = WSASocket(AF_INET6, SOCK_STREAM, 0, &protocol_info, 0, 0);\n\telse\n\t\tsk = WSASocket(AF_INET,  SOCK_STREAM, 0, &protocol_info, 0, 0);\n\n\tsk_out = scalloc(1, sizeof(*sk_out));\n\tif (!sk_out) {\n\t\tCloseHandle(hpipe);\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n\n\tsk_out->sk = sk;\n\tsk_out->hProcess = INVALID_HANDLE_VALUE;\n\tINIT_FLIST_HEAD(&sk_out->list);\n\t__fio_sem_init(&sk_out->lock, FIO_SEM_UNLOCKED);\n\t__fio_sem_init(&sk_out->wait, FIO_SEM_LOCKED);\n\t__fio_sem_init(&sk_out->xmit, FIO_SEM_UNLOCKED);\n\n\tget_my_addr_str(sk);\n\n\tif (!WriteFile(hpipe, msg, strlen(msg), NULL, NULL)) {\n\t\tlog_err(\"couldnt write pipe\\n\");\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n\tCloseHandle(hpipe);\n\n\tsk_out_assign(sk_out);\n\n\tret = handle_connection(sk_out);\n\t__sk_out_drop(sk_out);\n\treturn ret;\n}\n#endif\n\nstatic int accept_loop(int listen_sk)\n{\n\tstruct sockaddr_in addr;\n\tstruct sockaddr_in6 addr6;\n\tsocklen_t len = use_ipv6 ? sizeof(addr6) : sizeof(addr);\n\tstruct pollfd pfd;\n\tint ret = 0, sk, exitval = 0;\n\tFLIST_HEAD(conn_list);\n\n\tdprint(FD_NET, \"server enter accept loop\\n\");\n\n\tfio_set_fd_nonblocking(listen_sk, \"server\");\n\n\twhile (!exit_backend) {\n\t\tstruct sk_out *sk_out;\n\t\tconst char *from;\n\t\tchar buf[64];\n#ifdef WIN32\n\t\tHANDLE hProcess;\n#else\n\t\tpid_t pid;\n#endif\n\t\tpfd.fd = listen_sk;\n\t\tpfd.events = POLLIN;\n\t\tdo {\n\t\t\tint timeout = 1000;\n\n\t\t\tif (!flist_empty(&conn_list))\n\t\t\t\ttimeout = 100;\n\n\t\t\tret = poll(&pfd, 1, timeout);\n\t\t\tif (ret < 0) {\n\t\t\t\tif (errno == EINTR)\n\t\t\t\t\tbreak;\n\t\t\t\tlog_err(\"fio: poll: %s\\n\", strerror(errno));\n\t\t\t\tbreak;\n\t\t\t} else if (!ret) {\n\t\t\t\tfio_server_check_conns(&conn_list);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (pfd.revents & POLLIN)\n\t\t\t\tbreak;\n\t\t} while (!exit_backend);\n\n\t\tfio_server_check_conns(&conn_list);\n\n\t\tif (exit_backend || ret < 0)\n\t\t\tbreak;\n\n\t\tif (use_ipv6)\n\t\t\tsk = accept(listen_sk, (struct sockaddr *) &addr6, &len);\n\t\telse\n\t\t\tsk = accept(listen_sk, (struct sockaddr *) &addr, &len);\n\n\t\tif (sk < 0) {\n\t\t\tlog_err(\"fio: accept: %s\\n\", strerror(errno));\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (use_ipv6)\n\t\t\tfrom = inet_ntop(AF_INET6, (struct sockaddr *) &addr6.sin6_addr, buf, sizeof(buf));\n\t\telse\n\t\t\tfrom = inet_ntop(AF_INET, (struct sockaddr *) &addr.sin_addr, buf, sizeof(buf));\n\n\t\tdprint(FD_NET, \"server: connect from %s\\n\", from);\n\n\t\tsk_out = scalloc(1, sizeof(*sk_out));\n\t\tif (!sk_out) {\n\t\t\tclose(sk);\n\t\t\treturn -1;\n\t\t}\n\n\t\tsk_out->sk = sk;\n\t\tINIT_FLIST_HEAD(&sk_out->list);\n\t\t__fio_sem_init(&sk_out->lock, FIO_SEM_UNLOCKED);\n\t\t__fio_sem_init(&sk_out->wait, FIO_SEM_LOCKED);\n\t\t__fio_sem_init(&sk_out->xmit, FIO_SEM_UNLOCKED);\n\n#ifdef WIN32\n\t\thProcess = windows_handle_connection(hjob, sk);\n\t\tif (hProcess == INVALID_HANDLE_VALUE)\n\t\t\treturn -1;\n\t\tsk_out->hProcess = hProcess;\n\t\tfio_server_add_conn_pid(&conn_list, hProcess);\n#else\n\t\tpid = fork();\n\t\tif (pid) {\n\t\t\tclose(sk);\n\t\t\tfio_server_add_conn_pid(&conn_list, pid);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* if error, it's already logged, non-fatal */\n\t\tget_my_addr_str(sk);\n\n\t\t/*\n\t\t * Assign sk_out here, it'll be dropped in handle_connection()\n\t\t * since that function calls _exit() when done\n\t\t */\n\t\tsk_out_assign(sk_out);\n\t\thandle_connection(sk_out);\n#endif\n\t}\n\n\treturn exitval;\n}\n\nint fio_server_text_output(int level, const char *buf, size_t len)\n{\n\tstruct sk_out *sk_out = pthread_getspecific(sk_out_key);\n\tstruct cmd_text_pdu *pdu;\n\tunsigned int tlen;\n\tstruct timeval tv;\n\n\tif (!sk_out || sk_out->sk == -1)\n\t\treturn -1;\n\n\ttlen = sizeof(*pdu) + len;\n\tpdu = malloc(tlen);\n\n\tpdu->level\t= __cpu_to_le32(level);\n\tpdu->buf_len\t= __cpu_to_le32(len);\n\n\tgettimeofday(&tv, NULL);\n\tpdu->log_sec\t= __cpu_to_le64(tv.tv_sec);\n\tpdu->log_usec\t= __cpu_to_le64(tv.tv_usec);\n\n\tmemcpy(pdu->buf, buf, len);\n\n\tfio_net_queue_cmd(FIO_NET_CMD_TEXT, pdu, tlen, NULL, SK_F_COPY);\n\tfree(pdu);\n\treturn len;\n}\n\nstatic void convert_io_stat(struct io_stat *dst, struct io_stat *src)\n{\n\tdst->max_val\t= cpu_to_le64(src->max_val);\n\tdst->min_val\t= cpu_to_le64(src->min_val);\n\tdst->samples\t= cpu_to_le64(src->samples);\n\n\t/*\n\t * Encode to IEEE 754 for network transfer\n\t */\n\tdst->mean.u.i\t= cpu_to_le64(fio_double_to_uint64(src->mean.u.f));\n\tdst->S.u.i\t= cpu_to_le64(fio_double_to_uint64(src->S.u.f));\n}\n\nstatic void convert_gs(struct group_run_stats *dst, struct group_run_stats *src)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tdst->max_run[i]\t\t= cpu_to_le64(src->max_run[i]);\n\t\tdst->min_run[i]\t\t= cpu_to_le64(src->min_run[i]);\n\t\tdst->max_bw[i]\t\t= cpu_to_le64(src->max_bw[i]);\n\t\tdst->min_bw[i]\t\t= cpu_to_le64(src->min_bw[i]);\n\t\tdst->iobytes[i]\t\t= cpu_to_le64(src->iobytes[i]);\n\t\tdst->agg[i]\t\t= cpu_to_le64(src->agg[i]);\n\t}\n\n\tdst->kb_base\t= cpu_to_le32(src->kb_base);\n\tdst->unit_base\t= cpu_to_le32(src->unit_base);\n\tdst->groupid\t= cpu_to_le32(src->groupid);\n\tdst->unified_rw_rep\t= cpu_to_le32(src->unified_rw_rep);\n\tdst->sig_figs\t= cpu_to_le32(src->sig_figs);\n}\n\n/*\n * Send a CMD_TS, which packs struct thread_stat and group_run_stats\n * into a single payload.\n */\nvoid fio_server_send_ts(struct thread_stat *ts, struct group_run_stats *rs)\n{\n\tstruct cmd_ts_pdu p;\n\tint i, j, k;\n\tsize_t clat_prio_stats_extra_size = 0;\n\tsize_t ss_extra_size = 0;\n\tsize_t extended_buf_size = 0;\n\tvoid *extended_buf;\n\tvoid *extended_buf_wp;\n\n\tdprint(FD_NET, \"server sending end stats\\n\");\n\n\tmemset(&p, 0, sizeof(p));\n\n\tsnprintf(p.ts.name, sizeof(p.ts.name), \"%s\", ts->name);\n\tsnprintf(p.ts.verror, sizeof(p.ts.verror), \"%s\", ts->verror);\n\tsnprintf(p.ts.description, sizeof(p.ts.description), \"%s\",\n\t\t ts->description);\n\n\tp.ts.error\t\t= cpu_to_le32(ts->error);\n\tp.ts.thread_number\t= cpu_to_le32(ts->thread_number);\n\tp.ts.groupid\t\t= cpu_to_le32(ts->groupid);\n\tp.ts.job_start\t\t= cpu_to_le64(ts->job_start);\n\tp.ts.pid\t\t= cpu_to_le32(ts->pid);\n\tp.ts.members\t\t= cpu_to_le32(ts->members);\n\tp.ts.unified_rw_rep\t= cpu_to_le32(ts->unified_rw_rep);\n\tp.ts.ioprio\t\t= cpu_to_le32(ts->ioprio);\n\tp.ts.disable_prio_stat\t= cpu_to_le32(ts->disable_prio_stat);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tconvert_io_stat(&p.ts.clat_stat[i], &ts->clat_stat[i]);\n\t\tconvert_io_stat(&p.ts.slat_stat[i], &ts->slat_stat[i]);\n\t\tconvert_io_stat(&p.ts.lat_stat[i], &ts->lat_stat[i]);\n\t\tconvert_io_stat(&p.ts.bw_stat[i], &ts->bw_stat[i]);\n\t\tconvert_io_stat(&p.ts.iops_stat[i], &ts->iops_stat[i]);\n\t}\n\tconvert_io_stat(&p.ts.sync_stat, &ts->sync_stat);\n\n\tp.ts.usr_time\t\t= cpu_to_le64(ts->usr_time);\n\tp.ts.sys_time\t\t= cpu_to_le64(ts->sys_time);\n\tp.ts.ctx\t\t= cpu_to_le64(ts->ctx);\n\tp.ts.minf\t\t= cpu_to_le64(ts->minf);\n\tp.ts.majf\t\t= cpu_to_le64(ts->majf);\n\tp.ts.clat_percentiles\t= cpu_to_le32(ts->clat_percentiles);\n\tp.ts.lat_percentiles\t= cpu_to_le32(ts->lat_percentiles);\n\tp.ts.slat_percentiles\t= cpu_to_le32(ts->slat_percentiles);\n\tp.ts.percentile_precision = cpu_to_le64(ts->percentile_precision);\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++) {\n\t\tfio_fp64_t *src = &ts->percentile_list[i];\n\t\tfio_fp64_t *dst = &p.ts.percentile_list[i];\n\n\t\tdst->u.i = cpu_to_le64(fio_double_to_uint64(src->u.f));\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_MAP_NR; i++) {\n\t\tp.ts.io_u_map[i]\t= cpu_to_le64(ts->io_u_map[i]);\n\t\tp.ts.io_u_submit[i]\t= cpu_to_le64(ts->io_u_submit[i]);\n\t\tp.ts.io_u_complete[i]\t= cpu_to_le64(ts->io_u_complete[i]);\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_LAT_N_NR; i++)\n\t\tp.ts.io_u_lat_n[i]\t= cpu_to_le64(ts->io_u_lat_n[i]);\n\tfor (i = 0; i < FIO_IO_U_LAT_U_NR; i++)\n\t\tp.ts.io_u_lat_u[i]\t= cpu_to_le64(ts->io_u_lat_u[i]);\n\tfor (i = 0; i < FIO_IO_U_LAT_M_NR; i++)\n\t\tp.ts.io_u_lat_m[i]\t= cpu_to_le64(ts->io_u_lat_m[i]);\n\n\tfor (i = 0; i < FIO_LAT_CNT; i++)\n\t\tfor (j = 0; j < DDIR_RWDIR_CNT; j++)\n\t\t\tfor (k = 0; k < FIO_IO_U_PLAT_NR; k++)\n\t\t\t\tp.ts.io_u_plat[i][j][k] = cpu_to_le64(ts->io_u_plat[i][j][k]);\n\n\tfor (j = 0; j < FIO_IO_U_PLAT_NR; j++)\n\t\tp.ts.io_u_sync_plat[j] = cpu_to_le64(ts->io_u_sync_plat[j]);\n\n\tfor (i = 0; i < DDIR_RWDIR_SYNC_CNT; i++)\n\t\tp.ts.total_io_u[i]\t= cpu_to_le64(ts->total_io_u[i]);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tp.ts.short_io_u[i]\t= cpu_to_le64(ts->short_io_u[i]);\n\t\tp.ts.drop_io_u[i]\t= cpu_to_le64(ts->drop_io_u[i]);\n\t}\n\n\tp.ts.total_submit\t= cpu_to_le64(ts->total_submit);\n\tp.ts.total_complete\t= cpu_to_le64(ts->total_complete);\n\tp.ts.nr_zone_resets\t= cpu_to_le64(ts->nr_zone_resets);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tp.ts.io_bytes[i]\t= cpu_to_le64(ts->io_bytes[i]);\n\t\tp.ts.runtime[i]\t\t= cpu_to_le64(ts->runtime[i]);\n\t}\n\n\tp.ts.total_run_time\t= cpu_to_le64(ts->total_run_time);\n\tp.ts.continue_on_error\t= cpu_to_le16(ts->continue_on_error);\n\tp.ts.total_err_count\t= cpu_to_le64(ts->total_err_count);\n\tp.ts.first_error\t= cpu_to_le32(ts->first_error);\n\tp.ts.kb_base\t\t= cpu_to_le32(ts->kb_base);\n\tp.ts.unit_base\t\t= cpu_to_le32(ts->unit_base);\n\n\tp.ts.latency_depth\t= cpu_to_le32(ts->latency_depth);\n\tp.ts.latency_target\t= cpu_to_le64(ts->latency_target);\n\tp.ts.latency_window\t= cpu_to_le64(ts->latency_window);\n\tp.ts.latency_percentile.u.i = cpu_to_le64(fio_double_to_uint64(ts->latency_percentile.u.f));\n\n\tp.ts.sig_figs\t\t= cpu_to_le32(ts->sig_figs);\n\n\tp.ts.nr_block_infos\t= cpu_to_le64(ts->nr_block_infos);\n\tfor (i = 0; i < p.ts.nr_block_infos; i++)\n\t\tp.ts.block_infos[i] = cpu_to_le32(ts->block_infos[i]);\n\n\tp.ts.ss_dur\t\t= cpu_to_le64(ts->ss_dur);\n\tp.ts.ss_state\t\t= cpu_to_le32(ts->ss_state);\n\tp.ts.ss_head\t\t= cpu_to_le32(ts->ss_head);\n\tp.ts.ss_limit.u.i\t= cpu_to_le64(fio_double_to_uint64(ts->ss_limit.u.f));\n\tp.ts.ss_slope.u.i\t= cpu_to_le64(fio_double_to_uint64(ts->ss_slope.u.f));\n\tp.ts.ss_deviation.u.i\t= cpu_to_le64(fio_double_to_uint64(ts->ss_deviation.u.f));\n\tp.ts.ss_criterion.u.i\t= cpu_to_le64(fio_double_to_uint64(ts->ss_criterion.u.f));\n\n\tp.ts.cachehit\t\t= cpu_to_le64(ts->cachehit);\n\tp.ts.cachemiss\t\t= cpu_to_le64(ts->cachemiss);\n\n\tconvert_gs(&p.rs, rs);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (ts->nr_clat_prio[i])\n\t\t\tclat_prio_stats_extra_size += ts->nr_clat_prio[i] * sizeof(*ts->clat_prio[i]);\n\t}\n\textended_buf_size += clat_prio_stats_extra_size;\n\n\tdprint(FD_NET, \"ts->ss_state = %d\\n\", ts->ss_state);\n\tif (ts->ss_state & FIO_SS_DATA)\n\t\tss_extra_size = 2 * ts->ss_dur * sizeof(uint64_t);\n\n\textended_buf_size += ss_extra_size;\n\tif (!extended_buf_size) {\n\t\tfio_net_queue_cmd(FIO_NET_CMD_TS, &p, sizeof(p), NULL, SK_F_COPY);\n\t\treturn;\n\t}\n\n\textended_buf_size += sizeof(p);\n\textended_buf = calloc(1, extended_buf_size);\n\tif (!extended_buf) {\n\t\tlog_err(\"fio: failed to allocate FIO_NET_CMD_TS buffer\\n\");\n\t\treturn;\n\t}\n\n\tmemcpy(extended_buf, &p, sizeof(p));\n\textended_buf_wp = (struct cmd_ts_pdu *)extended_buf + 1;\n\n\tif (clat_prio_stats_extra_size) {\n\t\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\t\tstruct clat_prio_stat *prio = (struct clat_prio_stat *) extended_buf_wp;\n\n\t\t\tfor (j = 0; j < ts->nr_clat_prio[i]; j++) {\n\t\t\t\tfor (k = 0; k < FIO_IO_U_PLAT_NR; k++)\n\t\t\t\t\tprio->io_u_plat[k] =\n\t\t\t\t\t\tcpu_to_le64(ts->clat_prio[i][j].io_u_plat[k]);\n\t\t\t\tconvert_io_stat(&prio->clat_stat,\n\t\t\t\t\t\t&ts->clat_prio[i][j].clat_stat);\n\t\t\t\tprio->ioprio = cpu_to_le32(ts->clat_prio[i][j].ioprio);\n\t\t\t\tprio++;\n\t\t\t}\n\n\t\t\tif (ts->nr_clat_prio[i]) {\n\t\t\t\tuint64_t offset = (char *)extended_buf_wp - (char *)extended_buf;\n\t\t\t\tstruct cmd_ts_pdu *ptr = extended_buf;\n\n\t\t\t\tptr->ts.clat_prio_offset[i] = cpu_to_le64(offset);\n\t\t\t\tptr->ts.nr_clat_prio[i] = cpu_to_le32(ts->nr_clat_prio[i]);\n\t\t\t}\n\n\t\t\textended_buf_wp = prio;\n\t\t}\n\t}\n\n\tif (ss_extra_size) {\n\t\tuint64_t *ss_iops, *ss_bw;\n\t\tuint64_t offset;\n\t\tstruct cmd_ts_pdu *ptr = extended_buf;\n\n\t\tdprint(FD_NET, \"server sending steadystate ring buffers\\n\");\n\n\t\t/* ss iops */\n\t\tss_iops = (uint64_t *) extended_buf_wp;\n\t\tfor (i = 0; i < ts->ss_dur; i++)\n\t\t\tss_iops[i] = cpu_to_le64(ts->ss_iops_data[i]);\n\n\t\toffset = (char *)extended_buf_wp - (char *)extended_buf;\n\t\tptr->ts.ss_iops_data_offset = cpu_to_le64(offset);\n\t\textended_buf_wp = ss_iops + (int) ts->ss_dur;\n\n\t\t/* ss bw */\n\t\tss_bw = extended_buf_wp;\n\t\tfor (i = 0; i < ts->ss_dur; i++)\n\t\t\tss_bw[i] = cpu_to_le64(ts->ss_bw_data[i]);\n\n\t\toffset = (char *)extended_buf_wp - (char *)extended_buf;\n\t\tptr->ts.ss_bw_data_offset = cpu_to_le64(offset);\n\t}\n\n\tfio_net_queue_cmd(FIO_NET_CMD_TS, extended_buf, extended_buf_size, NULL, SK_F_COPY);\n\tfree(extended_buf);\n}\n\nvoid fio_server_send_gs(struct group_run_stats *rs)\n{\n\tstruct group_run_stats gs;\n\n\tdprint(FD_NET, \"server sending group run stats\\n\");\n\n\tconvert_gs(&gs, rs);\n\tfio_net_queue_cmd(FIO_NET_CMD_GS, &gs, sizeof(gs), NULL, SK_F_COPY);\n}\n\nvoid fio_server_send_job_options(struct flist_head *opt_list,\n\t\t\t\t unsigned int gid)\n{\n\tstruct cmd_job_option pdu;\n\tstruct flist_head *entry;\n\n\tif (flist_empty(opt_list))\n\t\treturn;\n\n\tflist_for_each(entry, opt_list) {\n\t\tstruct print_option *p;\n\t\tsize_t len;\n\n\t\tp = flist_entry(entry, struct print_option, list);\n\t\tmemset(&pdu, 0, sizeof(pdu));\n\n\t\tif (gid == -1U) {\n\t\t\tpdu.global = __cpu_to_le16(1);\n\t\t\tpdu.groupid = 0;\n\t\t} else {\n\t\t\tpdu.global = 0;\n\t\t\tpdu.groupid = cpu_to_le32(gid);\n\t\t}\n\t\tlen = strlen(p->name);\n\t\tif (len >= sizeof(pdu.name)) {\n\t\t\tlen = sizeof(pdu.name) - 1;\n\t\t\tpdu.truncated = __cpu_to_le16(1);\n\t\t}\n\t\tmemcpy(pdu.name, p->name, len);\n\t\tif (p->value) {\n\t\t\tlen = strlen(p->value);\n\t\t\tif (len >= sizeof(pdu.value)) {\n\t\t\t\tlen = sizeof(pdu.value) - 1;\n\t\t\t\tpdu.truncated = __cpu_to_le16(1);\n\t\t\t}\n\t\t\tmemcpy(pdu.value, p->value, len);\n\t\t}\n\t\tfio_net_queue_cmd(FIO_NET_CMD_JOB_OPT, &pdu, sizeof(pdu), NULL, SK_F_COPY);\n\t}\n}\n\nstatic void convert_agg(struct disk_util_agg *dst, struct disk_util_agg *src)\n{\n\tint i;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tdst->ios[i]\t= cpu_to_le64(src->ios[i]);\n\t\tdst->merges[i]\t= cpu_to_le64(src->merges[i]);\n\t\tdst->sectors[i]\t= cpu_to_le64(src->sectors[i]);\n\t\tdst->ticks[i]\t= cpu_to_le64(src->ticks[i]);\n\t}\n\n\tdst->io_ticks\t\t= cpu_to_le64(src->io_ticks);\n\tdst->time_in_queue\t= cpu_to_le64(src->time_in_queue);\n\tdst->slavecount\t\t= cpu_to_le32(src->slavecount);\n\tdst->max_util.u.i\t= cpu_to_le64(fio_double_to_uint64(src->max_util.u.f));\n}\n\nstatic void convert_dus(struct disk_util_stat *dst, struct disk_util_stat *src)\n{\n\tint i;\n\n\tsnprintf((char *) dst->name, sizeof(dst->name), \"%s\", src->name);\n\n\tfor (i = 0; i < 2; i++) {\n\t\tdst->s.ios[i]\t\t= cpu_to_le64(src->s.ios[i]);\n\t\tdst->s.merges[i]\t= cpu_to_le64(src->s.merges[i]);\n\t\tdst->s.sectors[i]\t= cpu_to_le64(src->s.sectors[i]);\n\t\tdst->s.ticks[i]\t\t= cpu_to_le64(src->s.ticks[i]);\n\t}\n\n\tdst->s.io_ticks\t\t= cpu_to_le64(src->s.io_ticks);\n\tdst->s.time_in_queue\t= cpu_to_le64(src->s.time_in_queue);\n\tdst->s.msec\t\t= cpu_to_le64(src->s.msec);\n}\n\nvoid fio_server_send_du(void)\n{\n\tstruct disk_util *du;\n\tstruct flist_head *entry;\n\tstruct cmd_du_pdu pdu;\n\n\tdprint(FD_NET, \"server: sending disk_util %d\\n\", !flist_empty(&disk_list));\n\n\tmemset(&pdu, 0, sizeof(pdu));\n\n\tflist_for_each(entry, &disk_list) {\n\t\tdu = flist_entry(entry, struct disk_util, list);\n\n\t\tconvert_dus(&pdu.dus, &du->dus);\n\t\tconvert_agg(&pdu.agg, &du->agg);\n\n\t\tfio_net_queue_cmd(FIO_NET_CMD_DU, &pdu, sizeof(pdu), NULL, SK_F_COPY);\n\t}\n}\n\n#ifdef CONFIG_ZLIB\n\nstatic inline void __fio_net_prep_tail(z_stream *stream, void *out_pdu,\n\t\t\t\t\tstruct sk_entry **last_entry,\n\t\t\t\t\tstruct sk_entry *first)\n{\n\tunsigned int this_len = FIO_SERVER_MAX_FRAGMENT_PDU - stream->avail_out;\n\n\t*last_entry = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, out_pdu, this_len,\n\t\t\t\t NULL, SK_F_VEC | SK_F_INLINE | SK_F_FREE);\n\tif (*last_entry)\n\t\tflist_add_tail(&(*last_entry)->list, &first->next);\n}\n\n/*\n * Deflates the next input given, creating as many new packets in the\n * linked list as necessary.\n */\nstatic int __deflate_pdu_buffer(void *next_in, unsigned int next_sz, void **out_pdu,\n\t\t\t\tstruct sk_entry **last_entry, z_stream *stream,\n\t\t\t\tstruct sk_entry *first)\n{\n\tint ret;\n\n\tstream->next_in = next_in;\n\tstream->avail_in = next_sz;\n\tdo {\n\t\tif (!stream->avail_out) {\n\t\t\t__fio_net_prep_tail(stream, *out_pdu, last_entry, first);\n\t\t\tif (*last_entry == NULL)\n\t\t\t\treturn 1;\n\n\t\t\t*out_pdu = malloc(FIO_SERVER_MAX_FRAGMENT_PDU);\n\n\t\t\tstream->avail_out = FIO_SERVER_MAX_FRAGMENT_PDU;\n\t\t\tstream->next_out = *out_pdu;\n\t\t}\n\n\t\tret = deflate(stream, Z_BLOCK);\n\n\t\tif (ret < 0) {\n\t\t\tfree(*out_pdu);\n\t\t\treturn 1;\n\t\t}\n\t} while (stream->avail_in);\n\n\treturn 0;\n}\n\nstatic int __fio_append_iolog_gz_hist(struct sk_entry *first, struct io_log *log,\n\t\t\t\t      struct io_logs *cur_log, z_stream *stream)\n{\n\tstruct sk_entry *entry;\n\tvoid *out_pdu;\n\tint ret, i, j;\n\tint sample_sz = log_entry_sz(log);\n\n\tout_pdu = malloc(FIO_SERVER_MAX_FRAGMENT_PDU);\n\tstream->avail_out = FIO_SERVER_MAX_FRAGMENT_PDU;\n\tstream->next_out = out_pdu;\n\n\tfor (i = 0; i < cur_log->nr_samples; i++) {\n\t\tstruct io_sample *s;\n\t\tstruct io_u_plat_entry *cur_plat_entry, *prev_plat_entry;\n\t\tuint64_t *cur_plat, *prev_plat;\n\n\t\ts = get_sample(log, cur_log, i);\n\t\tret = __deflate_pdu_buffer(s, sample_sz, &out_pdu, &entry, stream, first);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t/* Do the subtraction on server side so that client doesn't have to\n\t\t * reconstruct our linked list from packets.\n\t\t */\n\t\tcur_plat_entry  = s->data.plat_entry;\n\t\tprev_plat_entry = flist_first_entry(&cur_plat_entry->list, struct io_u_plat_entry, list);\n\t\tcur_plat  = cur_plat_entry->io_u_plat;\n\t\tprev_plat = prev_plat_entry->io_u_plat;\n\n\t\tfor (j = 0; j < FIO_IO_U_PLAT_NR; j++) {\n\t\t\tcur_plat[j] -= prev_plat[j];\n\t\t}\n\n\t\tflist_del(&prev_plat_entry->list);\n\t\tfree(prev_plat_entry);\n\n\t\tret = __deflate_pdu_buffer(cur_plat_entry, sizeof(*cur_plat_entry),\n\t\t\t\t\t   &out_pdu, &entry, stream, first);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t__fio_net_prep_tail(stream, out_pdu, &entry, first);\n\treturn entry == NULL;\n}\n\nstatic int __fio_append_iolog_gz(struct sk_entry *first, struct io_log *log,\n\t\t\t\t struct io_logs *cur_log, z_stream *stream)\n{\n\tunsigned int this_len;\n\tvoid *out_pdu;\n\tint ret;\n\n\tif (log->log_type == IO_LOG_TYPE_HIST)\n\t\treturn __fio_append_iolog_gz_hist(first, log, cur_log, stream);\n\n\tstream->next_in = (void *) cur_log->log;\n\tstream->avail_in = cur_log->nr_samples * log_entry_sz(log);\n\n\tdo {\n\t\tstruct sk_entry *entry;\n\n\t\t/*\n\t\t * Dirty - since the log is potentially huge, compress it into\n\t\t * FIO_SERVER_MAX_FRAGMENT_PDU chunks and let the receiving\n\t\t * side defragment it.\n\t\t */\n\t\tout_pdu = malloc(FIO_SERVER_MAX_FRAGMENT_PDU);\n\n\t\tstream->avail_out = FIO_SERVER_MAX_FRAGMENT_PDU;\n\t\tstream->next_out = out_pdu;\n\t\tret = deflate(stream, Z_BLOCK);\n\t\t/* may be Z_OK, or Z_STREAM_END */\n\t\tif (ret < 0) {\n\t\t\tfree(out_pdu);\n\t\t\treturn 1;\n\t\t}\n\n\t\tthis_len = FIO_SERVER_MAX_FRAGMENT_PDU - stream->avail_out;\n\n\t\tentry = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, out_pdu, this_len,\n\t\t\t\t\t NULL, SK_F_VEC | SK_F_INLINE | SK_F_FREE);\n\t\tif (!entry) {\n\t\t\tfree(out_pdu);\n\t\t\treturn 1;\n\t\t}\n\t\tflist_add_tail(&entry->list, &first->next);\n\t} while (stream->avail_in);\n\n\treturn 0;\n}\n\nstatic int fio_append_iolog_gz(struct sk_entry *first, struct io_log *log)\n{\n\tz_stream stream = {\n\t\t.zalloc\t= Z_NULL,\n\t\t.zfree\t= Z_NULL,\n\t\t.opaque\t= Z_NULL,\n\t};\n\tint ret = 0;\n\n\tif (deflateInit(&stream, Z_DEFAULT_COMPRESSION) != Z_OK)\n\t\treturn 1;\n\n\twhile (!flist_empty(&log->io_logs)) {\n\t\tstruct io_logs *cur_log;\n\n\t\tcur_log = flist_first_entry(&log->io_logs, struct io_logs, list);\n\t\tflist_del_init(&cur_log->list);\n\n\t\tret = __fio_append_iolog_gz(first, log, cur_log, &stream);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tret = deflate(&stream, Z_FINISH);\n\n\twhile (ret != Z_STREAM_END) {\n\t\tstruct sk_entry *entry;\n\t\tunsigned int this_len;\n\t\tvoid *out_pdu;\n\n\t\tout_pdu = malloc(FIO_SERVER_MAX_FRAGMENT_PDU);\n\t\tstream.avail_out = FIO_SERVER_MAX_FRAGMENT_PDU;\n\t\tstream.next_out = out_pdu;\n\n\t\tret = deflate(&stream, Z_FINISH);\n\t\t/* may be Z_OK, or Z_STREAM_END */\n\t\tif (ret < 0) {\n\t\t\tfree(out_pdu);\n\t\t\tbreak;\n\t\t}\n\n\t\tthis_len = FIO_SERVER_MAX_FRAGMENT_PDU - stream.avail_out;\n\n\t\tentry = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, out_pdu, this_len,\n\t\t\t\t\t NULL, SK_F_VEC | SK_F_INLINE | SK_F_FREE);\n\t\tif (!entry) {\n\t\t\tfree(out_pdu);\n\t\t\tbreak;\n\t\t}\n\t\tflist_add_tail(&entry->list, &first->next);\n\t}\n\n\tret = deflateEnd(&stream);\n\tif (ret == Z_OK)\n\t\treturn 0;\n\n\treturn 1;\n}\n#else\nstatic int fio_append_iolog_gz(struct sk_entry *first, struct io_log *log)\n{\n\treturn 1;\n}\n#endif\n\nstatic int fio_append_gz_chunks(struct sk_entry *first, struct io_log *log)\n{\n\tstruct sk_entry *entry;\n\tstruct flist_head *node;\n\tint ret = 0;\n\n\tpthread_mutex_lock(&log->chunk_lock);\n\tflist_for_each(node, &log->chunk_list) {\n\t\tstruct iolog_compress *c;\n\n\t\tc = flist_entry(node, struct iolog_compress, list);\n\t\tentry = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, c->buf, c->len,\n\t\t\t\t\t\tNULL, SK_F_VEC | SK_F_INLINE);\n\t\tif (!entry) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tflist_add_tail(&entry->list, &first->next);\n\t}\n\tpthread_mutex_unlock(&log->chunk_lock);\n\treturn ret;\n}\n\nstatic int fio_append_text_log(struct sk_entry *first, struct io_log *log)\n{\n\tstruct sk_entry *entry;\n\tint ret = 0;\n\n\twhile (!flist_empty(&log->io_logs)) {\n\t\tstruct io_logs *cur_log;\n\t\tsize_t size;\n\n\t\tcur_log = flist_first_entry(&log->io_logs, struct io_logs, list);\n\t\tflist_del_init(&cur_log->list);\n\n\t\tsize = cur_log->nr_samples * log_entry_sz(log);\n\n\t\tentry = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, cur_log->log, size,\n\t\t\t\t\t\tNULL, SK_F_VEC | SK_F_INLINE);\n\t\tif (!entry) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tflist_add_tail(&entry->list, &first->next);\n\t}\n\n\treturn ret;\n}\n\nint fio_send_iolog(struct thread_data *td, struct io_log *log, const char *name)\n{\n\tstruct cmd_iolog_pdu pdu = {\n\t\t.nr_samples\t\t= cpu_to_le64(iolog_nr_samples(log)),\n\t\t.thread_number\t\t= cpu_to_le32(td->thread_number),\n\t\t.log_type\t\t= cpu_to_le32(log->log_type),\n\t\t.log_hist_coarseness\t= cpu_to_le32(log->hist_coarseness),\n\t\t.per_job_logs\t\t= cpu_to_le32(td->o.per_job_logs),\n\t};\n\tstruct sk_entry *first;\n\tstruct flist_head *entry;\n\tint ret = 0;\n\n\tif (!flist_empty(&log->chunk_list))\n\t\tpdu.compressed = __cpu_to_le32(STORE_COMPRESSED);\n\telse if (use_zlib)\n\t\tpdu.compressed = __cpu_to_le32(XMIT_COMPRESSED);\n\telse\n\t\tpdu.compressed = 0;\n\n\tsnprintf((char *) pdu.name, sizeof(pdu.name), \"%s\", name);\n\n\t/*\n\t * We can't do this for a pre-compressed log, but for that case,\n\t * log->nr_samples is zero anyway.\n\t */\n\tflist_for_each(entry, &log->io_logs) {\n\t\tstruct io_logs *cur_log;\n\t\tint i;\n\n\t\tcur_log = flist_entry(entry, struct io_logs, list);\n\n\t\tfor (i = 0; i < cur_log->nr_samples; i++) {\n\t\t\tstruct io_sample *s = get_sample(log, cur_log, i);\n\n\t\t\ts->time\t\t= cpu_to_le64(s->time);\n\t\t\tif (log->log_type != IO_LOG_TYPE_HIST) {\n\t\t\t\ts->data.val.val0\t= cpu_to_le64(s->data.val.val0);\n\t\t\t\ts->data.val.val1\t= cpu_to_le64(s->data.val.val1);\n\t\t\t}\n\t\t\ts->__ddir\t= __cpu_to_le32(s->__ddir);\n\t\t\ts->bs\t\t= cpu_to_le64(s->bs);\n\n\t\t\tif (log->log_offset)\n\t\t\t\ts->aux[IOS_AUX_OFFSET_INDEX] =\n\t\t\t\t\tcpu_to_le64(s->aux[IOS_AUX_OFFSET_INDEX]);\n\n\t\t\tif (log->log_issue_time)\n\t\t\t\ts->aux[IOS_AUX_ISSUE_TIME_INDEX] =\n\t\t\t\t\tcpu_to_le64(s->aux[IOS_AUX_ISSUE_TIME_INDEX]);\n\t\t}\n\t}\n\n\t/*\n\t * Assemble header entry first\n\t */\n\tfirst = fio_net_prep_cmd(FIO_NET_CMD_IOLOG, &pdu, sizeof(pdu), NULL, SK_F_VEC | SK_F_INLINE | SK_F_COPY);\n\tif (!first)\n\t\treturn 1;\n\n\t/*\n\t * Now append actual log entries. If log compression was enabled on\n\t * the job, just send out the compressed chunks directly. If we\n\t * have a plain log, compress if we can, then send. Otherwise, send\n\t * the plain text output.\n\t */\n\tif (!flist_empty(&log->chunk_list))\n\t\tret = fio_append_gz_chunks(first, log);\n\telse if (use_zlib)\n\t\tret = fio_append_iolog_gz(first, log);\n\telse\n\t\tret = fio_append_text_log(first, log);\n\n\tfio_net_queue_entry(first);\n\treturn ret;\n}\n\nvoid fio_server_send_add_job(struct thread_data *td)\n{\n\tstruct cmd_add_job_pdu *pdu;\n\tsize_t cmd_sz = offsetof(struct cmd_add_job_pdu, top) +\n\t\tthread_options_pack_size(&td->o);\n\n\tpdu = malloc(cmd_sz);\n\tpdu->thread_number = cpu_to_le32(td->thread_number);\n\tpdu->groupid = cpu_to_le32(td->groupid);\n\n\tconvert_thread_options_to_net(&pdu->top, &td->o);\n\n\tfio_net_queue_cmd(FIO_NET_CMD_ADD_JOB, pdu, cmd_sz, NULL, SK_F_COPY);\n\tfree(pdu);\n}\n\nvoid fio_server_send_start(struct thread_data *td)\n{\n\tstruct sk_out *sk_out = pthread_getspecific(sk_out_key);\n\n\tif (sk_out->sk == -1) {\n\t\tlog_err(\"pthread getting specific for key failed, sk_out %p, sk %i, err: %i:%s\",\n\t\t\tsk_out, sk_out->sk, errno, strerror(errno));\n\t\tabort();\n\t}\n\n\tfio_net_queue_cmd(FIO_NET_CMD_SERVER_START, NULL, 0, NULL, SK_F_SIMPLE);\n}\n\nint fio_server_get_verify_state(const char *name, int threadnumber,\n\t\t\t\tvoid **datap)\n{\n\tstruct thread_io_list *s;\n\tstruct cmd_sendfile out;\n\tstruct cmd_reply *rep;\n\tuint64_t tag;\n\tvoid *data;\n\tint ret;\n\n\tdprint(FD_NET, \"server: request verify state\\n\");\n\n\trep = smalloc(sizeof(*rep));\n\tif (!rep)\n\t\treturn ENOMEM;\n\n\t__fio_sem_init(&rep->lock, FIO_SEM_LOCKED);\n\trep->data = NULL;\n\trep->error = 0;\n\n\tverify_state_gen_name((char *) out.path, sizeof(out.path), name, me,\n\t\t\t\tthreadnumber);\n\ttag = (uint64_t) (uintptr_t) rep;\n\tfio_net_queue_cmd(FIO_NET_CMD_SENDFILE, &out, sizeof(out), &tag,\n\t\t\t\tSK_F_COPY);\n\n\t/*\n\t * Wait for the backend to receive the reply\n\t */\n\tif (fio_sem_down_timeout(&rep->lock, 10000)) {\n\t\tlog_err(\"fio: timed out waiting for reply\\n\");\n\t\tret = ETIMEDOUT;\n\t\tgoto fail;\n\t}\n\n\tif (rep->error) {\n\t\tlog_err(\"fio: failure on receiving state file %s: %s\\n\",\n\t\t\t\tout.path, strerror(rep->error));\n\t\tret = rep->error;\nfail:\n\t\t*datap = NULL;\n\t\tsfree(rep);\n\t\tfio_net_queue_quit();\n\t\treturn ret;\n\t}\n\n\t/*\n\t * The format is verify_state_hdr, then thread_io_list. Verify\n\t * the header, and the thread_io_list checksum\n\t */\n\ts = rep->data + sizeof(struct verify_state_hdr);\n\tif (verify_state_hdr(rep->data, s)) {\n\t\tret = EILSEQ;\n\t\tgoto fail;\n\t}\n\n\t/*\n\t * Don't need the header from now, copy just the thread_io_list\n\t */\n\tret = 0;\n\trep->size -= sizeof(struct verify_state_hdr);\n\tdata = malloc(rep->size);\n\tmemcpy(data, s, rep->size);\n\t*datap = data;\n\n\tsfree(rep->data);\n\t__fio_sem_remove(&rep->lock);\n\tsfree(rep);\n\treturn ret;\n}\n\nstatic int fio_init_server_ip(void)\n{\n\tstruct sockaddr *addr;\n\tsocklen_t socklen;\n\tchar buf[80];\n\tconst char *str;\n\tint sk, opt;\n\n\tif (use_ipv6)\n\t\tsk = socket(AF_INET6, SOCK_STREAM, 0);\n\telse\n\t\tsk = socket(AF_INET, SOCK_STREAM, 0);\n\n\tif (sk < 0) {\n\t\tlog_err(\"fio: socket: %s\\n\", strerror(errno));\n\t\treturn -1;\n\t}\n\n\topt = 1;\n\tif (setsockopt(sk, SOL_SOCKET, SO_REUSEADDR, (void *)&opt, sizeof(opt)) < 0) {\n\t\tlog_err(\"fio: setsockopt(REUSEADDR): %s\\n\", strerror(errno));\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n#ifdef SO_REUSEPORT\n\t/*\n\t * Not fatal if fails, so just ignore it if that happens\n\t */\n\tif (setsockopt(sk, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt))) {\n\t}\n#endif\n\n\tif (use_ipv6) {\n\t\tvoid *src = &saddr_in6.sin6_addr;\n\n\t\taddr = (struct sockaddr *) &saddr_in6;\n\t\tsocklen = sizeof(saddr_in6);\n\t\tsaddr_in6.sin6_family = AF_INET6;\n\t\tstr = inet_ntop(AF_INET6, src, buf, sizeof(buf));\n\t} else {\n\t\tvoid *src = &saddr_in.sin_addr;\n\n\t\taddr = (struct sockaddr *) &saddr_in;\n\t\tsocklen = sizeof(saddr_in);\n\t\tsaddr_in.sin_family = AF_INET;\n\t\tstr = inet_ntop(AF_INET, src, buf, sizeof(buf));\n\t}\n\n\tif (bind(sk, addr, socklen) < 0) {\n\t\tlog_err(\"fio: bind: %s\\n\", strerror(errno));\n\t\tlog_info(\"fio: failed with IPv%c %s\\n\", use_ipv6 ? '6' : '4', str);\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n\n\treturn sk;\n}\n\nstatic int fio_init_server_sock(void)\n{\n\tstruct sockaddr_un addr;\n\tsocklen_t len;\n\tmode_t mode;\n\tint sk;\n\n\tsk = socket(AF_UNIX, SOCK_STREAM, 0);\n\tif (sk < 0) {\n\t\tlog_err(\"fio: socket: %s\\n\", strerror(errno));\n\t\treturn -1;\n\t}\n\n\tmode = umask(000);\n\n\taddr.sun_family = AF_UNIX;\n\tsnprintf(addr.sun_path, sizeof(addr.sun_path), \"%s\", bind_sock);\n\n\tlen = sizeof(addr.sun_family) + strlen(bind_sock) + 1;\n\n\tif (bind(sk, (struct sockaddr *) &addr, len) < 0) {\n\t\tlog_err(\"fio: bind: %s\\n\", strerror(errno));\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n\n\tumask(mode);\n\treturn sk;\n}\n\nstatic int fio_init_server_connection(void)\n{\n\tchar bind_str[128];\n\tint sk;\n\n\tdprint(FD_NET, \"starting server\\n\");\n\n\tif (!bind_sock)\n\t\tsk = fio_init_server_ip();\n\telse\n\t\tsk = fio_init_server_sock();\n\n\tif (sk < 0)\n\t\treturn sk;\n\n\tmemset(bind_str, 0, sizeof(bind_str));\n\n\tif (!bind_sock) {\n\t\tchar *p, port[16];\n\t\tvoid *src;\n\t\tint af;\n\n\t\tif (use_ipv6) {\n\t\t\taf = AF_INET6;\n\t\t\tsrc = &saddr_in6.sin6_addr;\n\t\t} else {\n\t\t\taf = AF_INET;\n\t\t\tsrc = &saddr_in.sin_addr;\n\t\t}\n\n\t\tp = (char *) inet_ntop(af, src, bind_str, sizeof(bind_str));\n\n\t\tsprintf(port, \",%u\", fio_net_port);\n\t\tif (p)\n\t\t\tstrcat(p, port);\n\t\telse\n\t\t\tsnprintf(bind_str, sizeof(bind_str), \"%s\", port);\n\t} else\n\t\tsnprintf(bind_str, sizeof(bind_str), \"%s\", bind_sock);\n\n\tlog_info(\"fio: server listening on %s\\n\", bind_str);\n\n\tif (listen(sk, 4) < 0) {\n\t\tlog_err(\"fio: listen: %s\\n\", strerror(errno));\n\t\tclose(sk);\n\t\treturn -1;\n\t}\n\n\treturn sk;\n}\n\nint fio_server_parse_host(const char *host, int ipv6, struct in_addr *inp,\n\t\t\t  struct in6_addr *inp6)\n\n{\n\tint ret = 0;\n\n\tif (ipv6)\n\t\tret = inet_pton(AF_INET6, host, inp6);\n\telse\n\t\tret = inet_pton(AF_INET, host, inp);\n\n\tif (ret != 1) {\n\t\tstruct addrinfo *res, hints = {\n\t\t\t.ai_family = ipv6 ? AF_INET6 : AF_INET,\n\t\t\t.ai_socktype = SOCK_STREAM,\n\t\t};\n\n\t\tret = getaddrinfo(host, NULL, &hints, &res);\n\t\tif (ret) {\n\t\t\tlog_err(\"fio: failed to resolve <%s> (%s)\\n\", host,\n\t\t\t\t\tgai_strerror(ret));\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (ipv6)\n\t\t\tmemcpy(inp6, &((struct sockaddr_in6 *) res->ai_addr)->sin6_addr, sizeof(*inp6));\n\t\telse\n\t\t\tmemcpy(inp, &((struct sockaddr_in *) res->ai_addr)->sin_addr, sizeof(*inp));\n\n\t\tret = 1;\n\t\tfreeaddrinfo(res);\n\t}\n\n\treturn !(ret == 1);\n}\n\n/*\n * Parse a host/ip/port string. Reads from 'str'.\n *\n * Outputs:\n *\n * For IPv4:\n *\t*ptr is the host, *port is the port, inp is the destination.\n * For IPv6:\n *\t*ptr is the host, *port is the port, inp6 is the dest, and *ipv6 is 1.\n * For local domain sockets:\n *\t*ptr is the filename, *is_sock is 1.\n */\nint fio_server_parse_string(const char *str, char **ptr, bool *is_sock,\n\t\t\t    int *port, struct in_addr *inp,\n\t\t\t    struct in6_addr *inp6, int *ipv6)\n{\n\tconst char *host = str;\n\tchar *portp;\n\tint lport = 0;\n\n\t*ptr = NULL;\n\t*is_sock = false;\n\t*port = fio_net_port;\n\t*ipv6 = 0;\n\n\tif (!strncmp(str, \"sock:\", 5)) {\n\t\t*ptr = strdup(str + 5);\n\t\t*is_sock = true;\n\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Is it ip:<ip or host>:port\n\t */\n\tif (!strncmp(host, \"ip:\", 3))\n\t\thost += 3;\n\telse if (!strncmp(host, \"ip4:\", 4))\n\t\thost += 4;\n\telse if (!strncmp(host, \"ip6:\", 4)) {\n\t\thost += 4;\n\t\t*ipv6 = 1;\n\t} else if (host[0] == ':') {\n\t\t/* String is :port */\n\t\thost++;\n\t\tlport = atoi(host);\n\t\tif (!lport || lport > 65535) {\n\t\t\tlog_err(\"fio: bad server port %u\\n\", lport);\n\t\t\treturn 1;\n\t\t}\n\t\t/* no hostname given, we are done */\n\t\t*port = lport;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * If no port seen yet, check if there's a last ',' at the end\n\t */\n\tif (!lport) {\n\t\tportp = strchr(host, ',');\n\t\tif (portp) {\n\t\t\t*portp = '\\0';\n\t\t\tportp++;\n\t\t\tlport = atoi(portp);\n\t\t\tif (!lport || lport > 65535) {\n\t\t\t\tlog_err(\"fio: bad server port %u\\n\", lport);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (lport)\n\t\t*port = lport;\n\n\tif (!strlen(host))\n\t\treturn 0;\n\n\t*ptr = strdup(host);\n\n\tif (fio_server_parse_host(*ptr, *ipv6, inp, inp6)) {\n\t\tfree(*ptr);\n\t\t*ptr = NULL;\n\t\treturn 1;\n\t}\n\n\tif (*port == 0)\n\t\t*port = fio_net_port;\n\n\treturn 0;\n}\n\n/*\n * Server arg should be one of:\n *\n * sock:/path/to/socket\n *   ip:1.2.3.4\n *      1.2.3.4\n *\n * Where sock uses unix domain sockets, and ip binds the server to\n * a specific interface. If no arguments are given to the server, it\n * uses IP and binds to 0.0.0.0.\n *\n */\nstatic int fio_handle_server_arg(void)\n{\n\tint port = fio_net_port;\n\tbool is_sock;\n\tint ret = 0;\n\n\tsaddr_in.sin_addr.s_addr = htonl(INADDR_ANY);\n\n\tif (!fio_server_arg)\n\t\tgoto out;\n\n\tret = fio_server_parse_string(fio_server_arg, &bind_sock, &is_sock,\n\t\t\t\t\t&port, &saddr_in.sin_addr,\n\t\t\t\t\t&saddr_in6.sin6_addr, &use_ipv6);\n\n\tif (!is_sock && bind_sock) {\n\t\tfree(bind_sock);\n\t\tbind_sock = NULL;\n\t}\n\nout:\n\tfio_net_port = port;\n\tsaddr_in.sin_port = htons(port);\n\tsaddr_in6.sin6_port = htons(port);\n\treturn ret;\n}\n\nstatic void sig_int(int sig)\n{\n\tif (bind_sock)\n\t\tunlink(bind_sock);\n}\n\nstatic void set_sig_handlers(void)\n{\n\tstruct sigaction act = {\n\t\t.sa_handler = sig_int,\n\t\t.sa_flags = SA_RESTART,\n\t};\n\n\tsigaction(SIGINT, &act, NULL);\n\n\t/* Windows uses SIGBREAK as a quit signal from other applications */\n#ifdef WIN32\n\tsigaction(SIGBREAK, &act, NULL);\n#endif\n}\n\nvoid fio_server_destroy_sk_key(void)\n{\n\tpthread_key_delete(sk_out_key);\n}\n\nint fio_server_create_sk_key(void)\n{\n\tif (pthread_key_create(&sk_out_key, NULL)) {\n\t\tlog_err(\"fio: can't create sk_out backend key\\n\");\n\t\treturn 1;\n\t}\n\n\tpthread_setspecific(sk_out_key, NULL);\n\treturn 0;\n}\n\nstatic int fio_server(void)\n{\n\tint sk, ret;\n\n\tdprint(FD_NET, \"starting server\\n\");\n\n\tif (fio_handle_server_arg())\n\t\treturn -1;\n\n\tset_sig_handlers();\n\n#ifdef WIN32\n\t/* if this is a child process, go handle the connection */\n\tif (fio_server_pipe_name != NULL) {\n\t\tret = handle_connection_process();\n\t\treturn ret;\n\t}\n\n\t/* job to link child processes so they terminate together */\n\thjob = windows_create_job();\n\tif (hjob == INVALID_HANDLE_VALUE)\n\t\treturn -1;\n#endif\n\n\tsk = fio_init_server_connection();\n\tif (sk < 0)\n\t\treturn -1;\n\n\tret = accept_loop(sk);\n\n\tclose(sk);\n\n\tif (fio_server_arg) {\n\t\tfree(fio_server_arg);\n\t\tfio_server_arg = NULL;\n\t}\n\tif (bind_sock)\n\t\tfree(bind_sock);\n\n\treturn ret;\n}\n\nvoid fio_server_got_signal(int signal)\n{\n\tstruct sk_out *sk_out = pthread_getspecific(sk_out_key);\n\n\tassert(sk_out);\n\n\tif (signal == SIGPIPE)\n\t\tsk_out->sk = -1;\n\telse {\n\t\tlog_info(\"\\nfio: terminating on signal %d\\n\", signal);\n\t\texit_backend = true;\n\t}\n}\n\nstatic int check_existing_pidfile(const char *pidfile)\n{\n\tstruct stat sb;\n\tchar buf[16];\n\tpid_t pid;\n\tFILE *f;\n\n\tif (stat(pidfile, &sb))\n\t\treturn 0;\n\n\tf = fopen(pidfile, \"r\");\n\tif (!f)\n\t\treturn 0;\n\n\tif (fread(buf, sb.st_size, 1, f) <= 0) {\n\t\tfclose(f);\n\t\treturn 1;\n\t}\n\tfclose(f);\n\n\tpid = atoi(buf);\n\tif (kill(pid, SIGCONT) < 0)\n\t\treturn errno != ESRCH;\n\n\treturn 1;\n}\n\nstatic int write_pid(pid_t pid, const char *pidfile)\n{\n\tFILE *fpid;\n\n\tfpid = fopen(pidfile, \"w\");\n\tif (!fpid) {\n\t\tlog_err(\"fio: failed opening pid file %s\\n\", pidfile);\n\t\treturn 1;\n\t}\n\n\tfprintf(fpid, \"%u\\n\", (unsigned int) pid);\n\tfclose(fpid);\n\treturn 0;\n}\n\n/*\n * If pidfile is specified, background us.\n */\nint fio_start_server(char *pidfile)\n{\n\tFILE *file;\n\tpid_t pid;\n\tint ret;\n\n#if defined(WIN32)\n\tWSADATA wsd;\n\tWSAStartup(MAKEWORD(2, 2), &wsd);\n#endif\n\n\tif (!pidfile)\n\t\treturn fio_server();\n\n\tif (check_existing_pidfile(pidfile)) {\n\t\tlog_err(\"fio: pidfile %s exists and server appears alive\\n\",\n\t\t\t\t\t\t\t\tpidfile);\n\t\tfree(pidfile);\n\t\treturn -1;\n\t}\n\n\tpid = fork();\n\tif (pid < 0) {\n\t\tlog_err(\"fio: failed server fork: %s\\n\", strerror(errno));\n\t\tfree(pidfile);\n\t\treturn -1;\n\t} else if (pid) {\n\t\tret = write_pid(pid, pidfile);\n\t\tfree(pidfile);\n\t\t_exit(ret);\n\t}\n\n\tsetsid();\n\topenlog(\"fio\", LOG_NDELAY|LOG_NOWAIT|LOG_PID, LOG_USER);\n\tlog_syslog = true;\n\n\tfile = freopen(\"/dev/null\", \"r\", stdin);\n\tif (!file)\n\t\tperror(\"freopen\");\n\n\tfile = freopen(\"/dev/null\", \"w\", stdout);\n\tif (!file)\n\t\tperror(\"freopen\");\n\n\tfile = freopen(\"/dev/null\", \"w\", stderr);\n\tif (!file)\n\t\tperror(\"freopen\");\n\n\tf_out = NULL;\n\tf_err = NULL;\n\n\tret = fio_server();\n\n\tfclose(stdin);\n\tfclose(stdout);\n\tfclose(stderr);\n\n\tcloselog();\n\tunlink(pidfile);\n\tfree(pidfile);\n\treturn ret;\n}\n\nvoid fio_server_set_arg(const char *arg)\n{\n\tfio_server_arg = strdup(arg);\n}\n\n#ifdef WIN32\nvoid fio_server_internal_set(const char *arg)\n{\n\tfio_server_pipe_name = strdup(arg);\n}\n#endif\n"
        },
        {
          "name": "server.h",
          "type": "blob",
          "size": 5.544921875,
          "content": "#ifndef FIO_SERVER_H\n#define FIO_SERVER_H\n\n#include <inttypes.h>\n#include <string.h>\n#include <sys/time.h>\n#include <netinet/in.h>\n\n#include \"stat.h\"\n#include \"diskutil.h\"\n\n#define FIO_NET_PORT 8765\n\nstruct sk_out {\n\tunsigned int refs;\t/* frees sk_out when it drops to zero.\n\t\t\t\t * protected by below ->lock */\n\n#ifdef WIN32\n\tHANDLE hProcess;\t\t/* process handle of handle_connection_process*/\n#endif\n\tint sk;\t\t\t/* socket fd to talk to client */\n\tstruct fio_sem lock;\t/* protects ref and below list */\n\tstruct flist_head list;\t/* list of pending transmit work */\n\tstruct fio_sem wait;\t/* wake backend when items added to list */\n\tstruct fio_sem xmit;\t/* held while sending data */\n};\n\n/*\n * On-wire encoding is little endian\n */\nstruct fio_net_cmd {\n\tuint16_t version;\t/* protocol version */\n\tuint16_t opcode;\t/* command opcode */\n\tuint32_t flags;\t\t/* modifier flags */\n\tuint64_t tag;\t\t/* passed back on reply */\n\tuint32_t pdu_len;\t/* length of post-cmd layload */\n\t/*\n\t * These must be immediately before the payload, anything before\n\t * these fields are checksummed.\n\t */\n\tuint16_t cmd_crc16;\t/* cmd checksum */\n\tuint16_t pdu_crc16;\t/* payload checksum */\n\tuint8_t payload[];\t/* payload */\n};\n\nstruct fio_net_cmd_reply {\n\tstruct flist_head list;\n\tstruct timespec ts;\n\tuint64_t saved_tag;\n\tuint16_t opcode;\n};\n\nenum {\n\tFIO_SERVER_VER\t\t\t= 107,\n\n\tFIO_SERVER_MAX_FRAGMENT_PDU\t= 1024,\n\tFIO_SERVER_MAX_CMD_MB\t\t= 2048,\n\n\tFIO_NET_CMD_QUIT\t\t= 1,\n\tFIO_NET_CMD_EXIT\t\t= 2,\n\tFIO_NET_CMD_JOB\t\t\t= 3,\n\tFIO_NET_CMD_JOBLINE\t\t= 4,\n\tFIO_NET_CMD_TEXT\t\t= 5,\n\tFIO_NET_CMD_TS\t\t\t= 6,\n\tFIO_NET_CMD_GS\t\t\t= 7,\n\tFIO_NET_CMD_SEND_ETA\t\t= 8,\n\tFIO_NET_CMD_ETA\t\t\t= 9,\n\tFIO_NET_CMD_PROBE\t\t= 10,\n\tFIO_NET_CMD_START\t\t= 11,\n\tFIO_NET_CMD_STOP\t\t= 12,\n\tFIO_NET_CMD_DU\t\t\t= 13,\n\tFIO_NET_CMD_SERVER_START\t= 14,\n\tFIO_NET_CMD_ADD_JOB\t\t= 15,\n\tFIO_NET_CMD_RUN\t\t\t= 16,\n\tFIO_NET_CMD_IOLOG\t\t= 17,\n\tFIO_NET_CMD_UPDATE_JOB\t\t= 18,\n\tFIO_NET_CMD_LOAD_FILE\t\t= 19,\n\tFIO_NET_CMD_VTRIGGER\t\t= 20,\n\tFIO_NET_CMD_SENDFILE\t\t= 21,\n\tFIO_NET_CMD_JOB_OPT\t\t= 22,\n\tFIO_NET_CMD_NR\t\t\t= 23,\n\n\tFIO_NET_CMD_F_MORE\t\t= 1UL << 0,\n\n\t/* crc does not include the crc fields */\n\tFIO_NET_CMD_CRC_SZ\t\t= sizeof(struct fio_net_cmd) -\n\t\t\t\t\t\t2 * sizeof(uint16_t),\n\n\tFIO_NET_NAME_MAX\t\t= 256,\n\n\tFIO_NET_CLIENT_TIMEOUT\t\t= 5000,\n\n\tFIO_PROBE_FLAG_ZLIB\t\t= 1UL << 0,\n};\n\nstruct cmd_sendfile {\n\tuint8_t path[FIO_NET_NAME_MAX];\n};\n\nstruct cmd_sendfile_reply {\n\tuint32_t size;\n\tuint32_t error;\n\tuint8_t data[0];\n};\n\n/*\n * Client sends this to server on VTRIGGER, server sends back a full\n * all_io_list structure.\n */\nstruct cmd_vtrigger_pdu {\n\tuint16_t len;\n\tuint8_t cmd[];\n};\n\nstruct cmd_load_file_pdu {\n\tuint16_t name_len;\n\tuint16_t client_type;\n\tuint8_t file[];\n};\n\nstruct cmd_ts_pdu {\n\tstruct thread_stat ts;\n\tstruct group_run_stats rs;\n};\n\nstruct cmd_du_pdu {\n\tstruct disk_util_stat dus;\n\tstruct disk_util_agg agg;\n};\n\nstruct cmd_client_probe_pdu {\n\tuint64_t flags;\n\tuint8_t server[128];\n};\n\nstruct cmd_probe_reply_pdu {\n\tuint8_t hostname[64];\n\tuint8_t bigendian;\n\tuint8_t fio_version[32];\n\tuint8_t os;\n\tuint8_t arch;\n\tuint8_t bpp;\n\tuint32_t cpus;\n\tuint64_t flags;\n};\n\nstruct cmd_single_line_pdu {\n\tuint16_t len;\n\tuint8_t text[];\n};\n\nstruct cmd_line_pdu {\n\tuint16_t lines;\n\tuint16_t client_type;\n\tstruct cmd_single_line_pdu options[];\n};\n\nstruct cmd_job_pdu {\n\tuint32_t buf_len;\n\tuint32_t client_type;\n\tuint8_t buf[0];\n};\n\nstruct cmd_start_pdu {\n\tuint32_t jobs;\n\tuint32_t stat_outputs;\n};\n\nstruct cmd_end_pdu {\n\tuint32_t error;\n\tuint32_t signal;\n};\n\nstruct cmd_add_job_pdu {\n\tuint32_t thread_number;\n\tuint32_t groupid;\n\tstruct thread_options_pack top;\n};\n\nstruct cmd_text_pdu {\n\tuint32_t level;\n\tuint32_t buf_len;\n\tuint64_t log_sec;\n\tuint64_t log_usec;\n\tuint8_t buf[0];\n};\n\nenum {\n\tXMIT_COMPRESSED\t\t= 1U,\n\tSTORE_COMPRESSED\t= 2U,\n};\n\nstruct cmd_iolog_pdu {\n\tuint64_t nr_samples;\n\tuint32_t thread_number;\n\tuint32_t log_type;\n\tuint32_t compressed;\n\tuint32_t log_offset;\n\tuint32_t log_prio;\n\tuint32_t log_issue_time;\n\tuint32_t log_hist_coarseness;\n\tuint32_t per_job_logs;\n\tuint8_t name[FIO_NET_NAME_MAX];\n\tstruct io_sample samples[0];\n};\n\nstruct cmd_job_option {\n\tuint16_t global;\n\tuint16_t truncated;\n\tuint32_t groupid;\n\tuint8_t name[64];\n\tuint8_t value[128];\n};\n\nextern int fio_start_server(char *);\nextern int fio_server_text_output(int, const char *, size_t);\nextern int fio_net_send_cmd(int, uint16_t, const void *, off_t, uint64_t *, struct flist_head *);\nextern int fio_net_send_simple_cmd(int, uint16_t, uint64_t, struct flist_head *);\nextern void fio_server_set_arg(const char *);\nextern void fio_server_internal_set(const char *);\nextern int fio_server_parse_string(const char *, char **, bool *, int *, struct in_addr *, struct in6_addr *, int *);\nextern int fio_server_parse_host(const char *, int, struct in_addr *, struct in6_addr *);\nextern const char *fio_server_op(unsigned int);\nextern void fio_server_got_signal(int);\n\nextern void fio_server_send_ts(struct thread_stat *, struct group_run_stats *);\nextern void fio_server_send_gs(struct group_run_stats *);\nextern void fio_server_send_du(void);\nextern void fio_server_send_job_options(struct flist_head *, unsigned int);\nextern int fio_server_get_verify_state(const char *, int, void **);\nextern bool fio_server_poll_fd(int fd, short events, int timeout);\n\nextern struct fio_net_cmd *fio_net_recv_cmd(int sk, bool wait);\n\nextern int fio_send_iolog(struct thread_data *, struct io_log *, const char *);\nextern void fio_server_send_add_job(struct thread_data *);\nextern void fio_server_send_start(struct thread_data *);\nextern int fio_net_send_quit(int sk);\n\nextern int fio_server_create_sk_key(void);\nextern void fio_server_destroy_sk_key(void);\n\nextern bool exit_backend;\nextern int fio_net_port;\n\n#endif\n"
        },
        {
          "name": "smalloc.c",
          "type": "blob",
          "size": 11.7119140625,
          "content": "/*\n * simple memory allocator, backed by mmap() so that it hands out memory\n * that can be shared across processes and threads\n */\n#include <sys/mman.h>\n#include <assert.h>\n#include <string.h>\n\n#include \"fio.h\"\n#include \"fio_sem.h\"\n#include \"os/os.h\"\n#include \"smalloc.h\"\n#include \"log.h\"\n\n#define SMALLOC_REDZONE\t\t/* define to detect memory corruption */\n\n#define SMALLOC_BPB\t32\t/* block size, bytes-per-bit in bitmap */\n#define SMALLOC_BPI\t(sizeof(unsigned int) * 8)\n#define SMALLOC_BPL\t(SMALLOC_BPB * SMALLOC_BPI)\n\n#define INITIAL_SIZE\t16*1024*1024\t/* new pool size */\n#define INITIAL_POOLS\t8\t\t/* maximum number of pools to setup */\n\n#define MAX_POOLS\t16\n\n#define SMALLOC_PRE_RED\t\t0xdeadbeefU\n#define SMALLOC_POST_RED\t0x5aa55aa5U\n\nunsigned int smalloc_pool_size = INITIAL_SIZE;\n#ifdef SMALLOC_REDZONE\nstatic const int int_mask = sizeof(int) - 1;\n#endif\n\nstruct pool {\n\tstruct fio_sem *lock;\t\t\t/* protects this pool */\n\tvoid *map;\t\t\t\t/* map of blocks */\n\tunsigned int *bitmap;\t\t\t/* blocks free/busy map */\n\tsize_t free_blocks;\t\t/* free blocks */\n\tsize_t nr_blocks;\t\t\t/* total blocks */\n\tsize_t next_non_full;\n\tsize_t mmap_size;\n};\n\nstruct block_hdr {\n\tsize_t size;\n#ifdef SMALLOC_REDZONE\n\tunsigned int prered;\n#endif\n};\n\n/*\n * This suppresses the voluminous potential bitmap printout when\n * smalloc encounters an OOM error\n */\nstatic const bool enable_smalloc_debug = false;\n\nstatic struct pool *mp;\nstatic unsigned int nr_pools;\nstatic unsigned int last_pool;\n\nstatic inline int ptr_valid(struct pool *pool, void *ptr)\n{\n\tunsigned int pool_size = pool->nr_blocks * SMALLOC_BPL;\n\n\treturn (ptr >= pool->map) && (ptr < pool->map + pool_size);\n}\n\nstatic inline size_t size_to_blocks(size_t size)\n{\n\treturn (size + SMALLOC_BPB - 1) / SMALLOC_BPB;\n}\n\nstatic int blocks_iter(struct pool *pool, unsigned int pool_idx,\n\t\t       unsigned int idx, size_t nr_blocks,\n\t\t       int (*func)(unsigned int *map, unsigned int mask))\n{\n\n\twhile (nr_blocks) {\n\t\tunsigned int this_blocks, mask;\n\t\tunsigned int *map;\n\n\t\tif (pool_idx >= pool->nr_blocks)\n\t\t\treturn 0;\n\n\t\tmap = &pool->bitmap[pool_idx];\n\n\t\tthis_blocks = nr_blocks;\n\t\tif (this_blocks + idx > SMALLOC_BPI) {\n\t\t\tthis_blocks = SMALLOC_BPI - idx;\n\t\t\tidx = SMALLOC_BPI - this_blocks;\n\t\t}\n\n\t\tif (this_blocks == SMALLOC_BPI)\n\t\t\tmask = -1U;\n\t\telse\n\t\t\tmask = ((1U << this_blocks) - 1) << idx;\n\n\t\tif (!func(map, mask))\n\t\t\treturn 0;\n\n\t\tnr_blocks -= this_blocks;\n\t\tidx = 0;\n\t\tpool_idx++;\n\t}\n\n\treturn 1;\n}\n\nstatic int mask_cmp(unsigned int *map, unsigned int mask)\n{\n\treturn !(*map & mask);\n}\n\nstatic int mask_clear(unsigned int *map, unsigned int mask)\n{\n\tassert((*map & mask) == mask);\n\t*map &= ~mask;\n\treturn 1;\n}\n\nstatic int mask_set(unsigned int *map, unsigned int mask)\n{\n\tassert(!(*map & mask));\n\t*map |= mask;\n\treturn 1;\n}\n\nstatic int blocks_free(struct pool *pool, unsigned int pool_idx,\n\t\t       unsigned int idx, size_t nr_blocks)\n{\n\treturn blocks_iter(pool, pool_idx, idx, nr_blocks, mask_cmp);\n}\n\nstatic void set_blocks(struct pool *pool, unsigned int pool_idx,\n\t\t       unsigned int idx, size_t nr_blocks)\n{\n\tblocks_iter(pool, pool_idx, idx, nr_blocks, mask_set);\n}\n\nstatic void clear_blocks(struct pool *pool, unsigned int pool_idx,\n\t\t\t unsigned int idx, size_t nr_blocks)\n{\n\tblocks_iter(pool, pool_idx, idx, nr_blocks, mask_clear);\n}\n\nstatic int find_next_zero(int word, int start)\n{\n\tassert(word != -1U);\n\tword >>= start;\n\treturn ffz(word) + start;\n}\n\nstatic bool add_pool(struct pool *pool, unsigned int alloc_size)\n{\n\tint bitmap_blocks;\n\tint mmap_flags;\n\tvoid *ptr;\n\n\tif (nr_pools == MAX_POOLS)\n\t\treturn false;\n\n#ifdef SMALLOC_REDZONE\n\talloc_size += sizeof(unsigned int);\n#endif\n\talloc_size += sizeof(struct block_hdr);\n\tif (alloc_size < INITIAL_SIZE)\n\t\talloc_size = INITIAL_SIZE;\n\n\t/* round up to nearest full number of blocks */\n\talloc_size = (alloc_size + SMALLOC_BPL - 1) & ~(SMALLOC_BPL - 1);\n\tbitmap_blocks = alloc_size / SMALLOC_BPL;\n\talloc_size += bitmap_blocks * sizeof(unsigned int);\n\tpool->mmap_size = alloc_size;\n\n\tpool->nr_blocks = bitmap_blocks;\n\tpool->free_blocks = bitmap_blocks * SMALLOC_BPI;\n\n\tmmap_flags = OS_MAP_ANON;\n#ifdef CONFIG_ESX\n\tmmap_flags |= MAP_PRIVATE;\n#else\n\tmmap_flags |= MAP_SHARED;\n#endif\n\tptr = mmap(NULL, alloc_size, PROT_READ|PROT_WRITE, mmap_flags, -1, 0);\n\n\tif (ptr == MAP_FAILED)\n\t\tgoto out_fail;\n\n\tpool->map = ptr;\n\tpool->bitmap = (unsigned int *)((char *) ptr + (pool->nr_blocks * SMALLOC_BPL));\n\tmemset(pool->bitmap, 0, bitmap_blocks * sizeof(unsigned int));\n\n\tpool->lock = fio_sem_init(FIO_SEM_UNLOCKED);\n\tif (!pool->lock)\n\t\tgoto out_fail;\n\n\tnr_pools++;\n\treturn true;\nout_fail:\n\tlog_err(\"smalloc: failed adding pool\\n\");\n\tif (pool->map)\n\t\tmunmap(pool->map, pool->mmap_size);\n\treturn false;\n}\n\nvoid sinit(void)\n{\n\tbool ret;\n\tint i;\n\n\t/*\n\t * sinit() can be called more than once if alloc-size is\n\t * set. But we want to allocate space for the struct pool\n\t * instances only once.\n\t */\n\tif (!mp) {\n\t\tmp = (struct pool *) mmap(NULL,\n\t\t\tMAX_POOLS * sizeof(struct pool),\n\t\t\tPROT_READ | PROT_WRITE,\n\t\t\tOS_MAP_ANON | MAP_SHARED, -1, 0);\n\n\t\tassert(mp != MAP_FAILED);\n\t}\n\n\tfor (i = 0; i < INITIAL_POOLS; i++) {\n\t\tret = add_pool(&mp[nr_pools], smalloc_pool_size);\n\t\tif (!ret)\n\t\t\tbreak;\n\t}\n\n\t/*\n\t * If we added at least one pool, we should be OK for most\n\t * cases.\n\t */\n\tassert(i);\n}\n\nstatic void cleanup_pool(struct pool *pool)\n{\n\t/*\n\t * This will also remove the temporary file we used as a backing\n\t * store, it was already unlinked\n\t */\n\tmunmap(pool->map, pool->mmap_size);\n\n\tif (pool->lock)\n\t\tfio_sem_remove(pool->lock);\n}\n\nvoid scleanup(void)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < nr_pools; i++)\n\t\tcleanup_pool(&mp[i]);\n\n\tmunmap(mp, MAX_POOLS * sizeof(struct pool));\n}\n\n#ifdef SMALLOC_REDZONE\nstatic void *postred_ptr(struct block_hdr *hdr)\n{\n\tuintptr_t ptr;\n\n\tptr = (uintptr_t) hdr + hdr->size - sizeof(unsigned int);\n\tptr = (uintptr_t) PTR_ALIGN(ptr, int_mask);\n\n\treturn (void *) ptr;\n}\n\nstatic void fill_redzone(struct block_hdr *hdr)\n{\n\tunsigned int *postred = postred_ptr(hdr);\n\n\thdr->prered = SMALLOC_PRE_RED;\n\t*postred = SMALLOC_POST_RED;\n}\n\nstatic void sfree_check_redzone(struct block_hdr *hdr)\n{\n\tunsigned int *postred = postred_ptr(hdr);\n\n\tif (hdr->prered != SMALLOC_PRE_RED) {\n\t\tlog_err(\"smalloc pre redzone destroyed!\\n\"\n\t\t\t\" ptr=%p, prered=%x, expected %x\\n\",\n\t\t\t\thdr+1, hdr->prered, SMALLOC_PRE_RED);\n\t\tassert(0);\n\t}\n\tif (*postred != SMALLOC_POST_RED) {\n\t\tlog_err(\"smalloc post redzone destroyed!\\n\"\n\t\t\t\"  ptr=%p, postred=%x, expected %x\\n\",\n\t\t\t\thdr+1, *postred, SMALLOC_POST_RED);\n\t\tassert(0);\n\t}\n}\n#else\nstatic void fill_redzone(struct block_hdr *hdr)\n{\n}\n\nstatic void sfree_check_redzone(struct block_hdr *hdr)\n{\n}\n#endif\n\nstatic void sfree_pool(struct pool *pool, void *ptr)\n{\n\tstruct block_hdr *hdr;\n\tunsigned int i, idx;\n\tunsigned long offset;\n\n\tif (!ptr)\n\t\treturn;\n\n\tptr -= sizeof(*hdr);\n\thdr = ptr;\n\n\tassert(ptr_valid(pool, ptr));\n\n\tsfree_check_redzone(hdr);\n\n\toffset = ptr - pool->map;\n\ti = offset / SMALLOC_BPL;\n\tidx = (offset % SMALLOC_BPL) / SMALLOC_BPB;\n\n\tfio_sem_down(pool->lock);\n\tclear_blocks(pool, i, idx, size_to_blocks(hdr->size));\n\tif (i < pool->next_non_full)\n\t\tpool->next_non_full = i;\n\tpool->free_blocks += size_to_blocks(hdr->size);\n\tfio_sem_up(pool->lock);\n}\n\nvoid sfree(void *ptr)\n{\n\tstruct pool *pool = NULL;\n\tunsigned int i;\n\n\tif (!ptr)\n\t\treturn;\n\n\tfor (i = 0; i < nr_pools; i++) {\n\t\tif (ptr_valid(&mp[i], ptr)) {\n\t\t\tpool = &mp[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (pool) {\n\t\tsfree_pool(pool, ptr);\n\t\treturn;\n\t}\n\n\tlog_err(\"smalloc: ptr %p not from smalloc pool\\n\", ptr);\n}\n\nstatic unsigned int find_best_index(struct pool *pool)\n{\n\tunsigned int i;\n\n\tassert(pool->free_blocks);\n\n\tfor (i = pool->next_non_full; pool->bitmap[i] == -1U; i++) {\n\t\tif (i == pool->nr_blocks - 1) {\n\t\t\tunsigned int j;\n\n\t\t\tfor (j = 0; j < pool->nr_blocks; j++)\n\t\t\t\tif (pool->bitmap[j] != -1U)\n\t\t\t\t\treturn j;\n\t\t}\n\t}\n\n\treturn i;\n}\n\nstatic void *__smalloc_pool(struct pool *pool, size_t size)\n{\n\tsize_t nr_blocks;\n\tunsigned int i;\n\tunsigned int offset;\n\tunsigned int last_idx;\n\tvoid *ret = NULL;\n\n\tfio_sem_down(pool->lock);\n\n\tnr_blocks = size_to_blocks(size);\n\tif (nr_blocks > pool->free_blocks)\n\t\tgoto fail;\n\n\tpool->next_non_full = find_best_index(pool);\n\n\tlast_idx = 0;\n\toffset = -1U;\n\ti = pool->next_non_full;\n\twhile (i < pool->nr_blocks) {\n\t\tunsigned int idx;\n\n\t\tif (pool->bitmap[i] == -1U) {\n\t\t\ti++;\n\t\t\tlast_idx = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tidx = find_next_zero(pool->bitmap[i], last_idx);\n\t\tif (!blocks_free(pool, i, idx, nr_blocks)) {\n\t\t\tidx += nr_blocks;\n\t\t\tif (idx < SMALLOC_BPI)\n\t\t\t\tlast_idx = idx;\n\t\t\telse {\n\t\t\t\tlast_idx = 0;\n\t\t\t\twhile (idx >= SMALLOC_BPI) {\n\t\t\t\t\ti++;\n\t\t\t\t\tidx -= SMALLOC_BPI;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tset_blocks(pool, i, idx, nr_blocks);\n\t\toffset = i * SMALLOC_BPL + idx * SMALLOC_BPB;\n\t\tbreak;\n\t}\n\n\tif (i < pool->nr_blocks) {\n\t\tpool->free_blocks -= nr_blocks;\n\t\tret = pool->map + offset;\n\t}\nfail:\n\tfio_sem_up(pool->lock);\n\treturn ret;\n}\n\nstatic size_t size_to_alloc_size(size_t size)\n{\n\tsize_t alloc_size = size + sizeof(struct block_hdr);\n\n\t/*\n\t * Round to int alignment, so that the postred pointer will\n\t * be naturally aligned as well.\n\t */\n#ifdef SMALLOC_REDZONE\n\talloc_size += sizeof(unsigned int);\n\talloc_size = (alloc_size + int_mask) & ~int_mask;\n#endif\n\n\treturn alloc_size;\n}\n\nstatic void *smalloc_pool(struct pool *pool, size_t size)\n{\n\tsize_t alloc_size = size_to_alloc_size(size);\n\tvoid *ptr;\n\n\tptr = __smalloc_pool(pool, alloc_size);\n\tif (ptr) {\n\t\tstruct block_hdr *hdr = ptr;\n\n\t\thdr->size = alloc_size;\n\t\tfill_redzone(hdr);\n\n\t\tptr += sizeof(*hdr);\n\t\tmemset(ptr, 0, size);\n\t}\n\n\treturn ptr;\n}\n\nstatic void smalloc_print_bitmap(struct pool *pool)\n{\n\tsize_t nr_blocks = pool->nr_blocks;\n\tunsigned int *bitmap = pool->bitmap;\n\tunsigned int i, j;\n\tchar *buffer;\n\n\tif (!enable_smalloc_debug)\n\t\treturn;\n\n\tbuffer = malloc(SMALLOC_BPI + 1);\n\tif (!buffer)\n\t\treturn;\n\tbuffer[SMALLOC_BPI] = '\\0';\n\n\tfor (i = 0; i < nr_blocks; i++) {\n\t\tunsigned int line = bitmap[i];\n\n\t\t/* skip completely full lines */\n\t\tif (line == -1U)\n\t\t\tcontinue;\n\n\t\tfor (j = 0; j < SMALLOC_BPI; j++)\n\t\t\tif ((1 << j) & line)\n\t\t\t\tbuffer[SMALLOC_BPI-1-j] = '1';\n\t\t\telse\n\t\t\t\tbuffer[SMALLOC_BPI-1-j] = '0';\n\n\t\tlog_err(\"smalloc: bitmap %5u, %s\\n\", i, buffer);\n\t}\n\n\tfree(buffer);\n}\n\nvoid smalloc_debug(size_t size)\n{\n\tunsigned int i;\n\tsize_t alloc_size = size_to_alloc_size(size);\n\tsize_t alloc_blocks;\n\n\talloc_blocks = size_to_blocks(alloc_size);\n\n\tif (size)\n\t\tlog_err(\"smalloc: size = %lu, alloc_size = %lu, blocks = %lu\\n\",\n\t\t\t(unsigned long) size, (unsigned long) alloc_size,\n\t\t\t(unsigned long) alloc_blocks);\n\tfor (i = 0; i < nr_pools; i++) {\n\t\tlog_err(\"smalloc: pool %u, free/total blocks %u/%u\\n\", i,\n\t\t\t(unsigned int) (mp[i].free_blocks),\n\t\t\t(unsigned int) (mp[i].nr_blocks*sizeof(unsigned int)*8));\n\t\tif (size && mp[i].free_blocks >= alloc_blocks) {\n\t\t\tvoid *ptr = smalloc_pool(&mp[i], size);\n\t\t\tif (ptr) {\n\t\t\t\tsfree(ptr);\n\t\t\t\tlast_pool = i;\n\t\t\t\tlog_err(\"smalloc: smalloc_pool %u succeeded\\n\", i);\n\t\t\t} else {\n\t\t\t\tlog_err(\"smalloc: smalloc_pool %u failed\\n\", i);\n\t\t\t\tlog_err(\"smalloc: next_non_full=%u, nr_blocks=%u\\n\",\n\t\t\t\t\t(unsigned int) mp[i].next_non_full, (unsigned int) mp[i].nr_blocks);\n\t\t\t\tsmalloc_print_bitmap(&mp[i]);\n\t\t\t}\n\t\t}\n\t}\n}\n\nvoid *smalloc(size_t size)\n{\n\tunsigned int i, end_pool;\n\n\tif (size != (unsigned int) size)\n\t\treturn NULL;\n\n\ti = last_pool;\n\tend_pool = nr_pools;\n\n\tdo {\n\t\tfor (; i < end_pool; i++) {\n\t\t\tvoid *ptr = smalloc_pool(&mp[i], size);\n\n\t\t\tif (ptr) {\n\t\t\t\tlast_pool = i;\n\t\t\t\treturn ptr;\n\t\t\t}\n\t\t}\n\t\tif (last_pool) {\n\t\t\tend_pool = last_pool;\n\t\t\tlast_pool = i = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tbreak;\n\t} while (1);\n\n\tlog_err(\"smalloc: OOM. Consider using --alloc-size to increase the \"\n\t\t\"shared memory available.\\n\");\n\tsmalloc_debug(size);\n\treturn NULL;\n}\n\nvoid *scalloc(size_t nmemb, size_t size)\n{\n\t/*\n\t * smalloc_pool (called by smalloc) will zero the memory, so we don't\n\t * need to do it here.\n\t */\n\treturn smalloc(nmemb * size);\n}\n\nchar *smalloc_strdup(const char *str)\n{\n\tchar *ptr = NULL;\n\n\tptr = smalloc(strlen(str) + 1);\n\tif (ptr)\n\t\tstrcpy(ptr, str);\n\treturn ptr;\n}\n"
        },
        {
          "name": "smalloc.h",
          "type": "blob",
          "size": 0.33203125,
          "content": "#ifndef FIO_SMALLOC_H\n#define FIO_SMALLOC_H\n\n#include <stddef.h>\n\nextern void *smalloc(size_t);\nextern void *scalloc(size_t, size_t);\nextern void sfree(void *);\nextern char *smalloc_strdup(const char *);\nextern void sinit(void);\nextern void scleanup(void);\nextern void smalloc_debug(size_t);\n\nextern unsigned int smalloc_pool_size;\n\n#endif\n"
        },
        {
          "name": "stat.c",
          "type": "blob",
          "size": 99.6806640625,
          "content": "#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <sys/time.h>\n#include <sys/stat.h>\n#include <math.h>\n\n#include \"fio.h\"\n#include \"diskutil.h\"\n#include \"lib/ieee754.h\"\n#include \"json.h\"\n#include \"lib/getrusage.h\"\n#include \"idletime.h\"\n#include \"lib/pow2.h\"\n#include \"lib/output_buffer.h\"\n#include \"helper_thread.h\"\n#include \"smalloc.h\"\n#include \"zbd.h\"\n#include \"oslib/asprintf.h\"\n\n#ifdef WIN32\n#define LOG_MSEC_SLACK\t2\n#else\n#define LOG_MSEC_SLACK\t1\n#endif\n\nstruct log_sample {\n\tunion io_sample_data data;\n\tuint32_t ddir;\n\tuint64_t bs;\n\tuint64_t offset;\n\tuint16_t priority;\n\tuint64_t issue_time;\n};\n\nstruct fio_sem *stat_sem;\n\nvoid clear_rusage_stat(struct thread_data *td)\n{\n\tstruct thread_stat *ts = &td->ts;\n\n\tfio_getrusage(&td->ru_start);\n\tts->usr_time = ts->sys_time = 0;\n\tts->ctx = 0;\n\tts->minf = ts->majf = 0;\n}\n\nvoid update_rusage_stat(struct thread_data *td)\n{\n\tstruct thread_stat *ts = &td->ts;\n\n\tfio_getrusage(&td->ru_end);\n\tts->usr_time += mtime_since_tv(&td->ru_start.ru_utime,\n\t\t\t\t\t&td->ru_end.ru_utime);\n\tts->sys_time += mtime_since_tv(&td->ru_start.ru_stime,\n\t\t\t\t\t&td->ru_end.ru_stime);\n\tts->ctx += td->ru_end.ru_nvcsw + td->ru_end.ru_nivcsw\n\t\t\t- (td->ru_start.ru_nvcsw + td->ru_start.ru_nivcsw);\n\tts->minf += td->ru_end.ru_minflt - td->ru_start.ru_minflt;\n\tts->majf += td->ru_end.ru_majflt - td->ru_start.ru_majflt;\n\n\tmemcpy(&td->ru_start, &td->ru_end, sizeof(td->ru_end));\n}\n\n/*\n * Given a latency, return the index of the corresponding bucket in\n * the structure tracking percentiles.\n *\n * (1) find the group (and error bits) that the value (latency)\n * belongs to by looking at its MSB. (2) find the bucket number in the\n * group by looking at the index bits.\n *\n */\nstatic unsigned int plat_val_to_idx(unsigned long long val)\n{\n\tunsigned int msb, error_bits, base, offset, idx;\n\n\t/* Find MSB starting from bit 0 */\n\tif (val == 0)\n\t\tmsb = 0;\n\telse\n\t\tmsb = (sizeof(val)*8) - __builtin_clzll(val) - 1;\n\n\t/*\n\t * MSB <= (FIO_IO_U_PLAT_BITS-1), cannot be rounded off. Use\n\t * all bits of the sample as index\n\t */\n\tif (msb <= FIO_IO_U_PLAT_BITS)\n\t\treturn val;\n\n\t/* Compute the number of error bits to discard*/\n\terror_bits = msb - FIO_IO_U_PLAT_BITS;\n\n\t/* Compute the number of buckets before the group */\n\tbase = (error_bits + 1) << FIO_IO_U_PLAT_BITS;\n\n\t/*\n\t * Discard the error bits and apply the mask to find the\n\t * index for the buckets in the group\n\t */\n\toffset = (FIO_IO_U_PLAT_VAL - 1) & (val >> error_bits);\n\n\t/* Make sure the index does not exceed (array size - 1) */\n\tidx = (base + offset) < (FIO_IO_U_PLAT_NR - 1) ?\n\t\t(base + offset) : (FIO_IO_U_PLAT_NR - 1);\n\n\treturn idx;\n}\n\n/*\n * Convert the given index of the bucket array to the value\n * represented by the bucket\n */\nstatic unsigned long long plat_idx_to_val(unsigned int idx)\n{\n\tunsigned int error_bits;\n\tunsigned long long k, base;\n\n\tassert(idx < FIO_IO_U_PLAT_NR);\n\n\t/* MSB <= (FIO_IO_U_PLAT_BITS-1), cannot be rounded off. Use\n\t * all bits of the sample as index */\n\tif (idx < (FIO_IO_U_PLAT_VAL << 1))\n\t\treturn idx;\n\n\t/* Find the group and compute the minimum value of that group */\n\terror_bits = (idx >> FIO_IO_U_PLAT_BITS) - 1;\n\tbase = ((unsigned long long) 1) << (error_bits + FIO_IO_U_PLAT_BITS);\n\n\t/* Find its bucket number of the group */\n\tk = idx % FIO_IO_U_PLAT_VAL;\n\n\t/* Return the mean of the range of the bucket */\n\treturn base + ((k + 0.5) * (1 << error_bits));\n}\n\nstatic int double_cmp(const void *a, const void *b)\n{\n\tconst fio_fp64_t fa = *(const fio_fp64_t *) a;\n\tconst fio_fp64_t fb = *(const fio_fp64_t *) b;\n\tint cmp = 0;\n\n\tif (fa.u.f > fb.u.f)\n\t\tcmp = 1;\n\telse if (fa.u.f < fb.u.f)\n\t\tcmp = -1;\n\n\treturn cmp;\n}\n\nunsigned int calc_clat_percentiles(uint64_t *io_u_plat, unsigned long long nr,\n\t\t\t\t   fio_fp64_t *plist, unsigned long long **output,\n\t\t\t\t   unsigned long long *maxv, unsigned long long *minv)\n{\n\tunsigned long long sum = 0;\n\tunsigned int len, i, j = 0;\n\tunsigned long long *ovals = NULL;\n\tbool is_last;\n\n\t*minv = -1ULL;\n\t*maxv = 0;\n\n\tlen = 0;\n\twhile (len < FIO_IO_U_LIST_MAX_LEN && plist[len].u.f != 0.0)\n\t\tlen++;\n\n\tif (!len)\n\t\treturn 0;\n\n\t/*\n\t * Sort the percentile list. Note that it may already be sorted if\n\t * we are using the default values, but since it's a short list this\n\t * isn't a worry. Also note that this does not work for NaN values.\n\t */\n\tif (len > 1)\n\t\tqsort(plist, len, sizeof(plist[0]), double_cmp);\n\n\tovals = malloc(len * sizeof(*ovals));\n\tif (!ovals)\n\t\treturn 0;\n\n\t/*\n\t * Calculate bucket values, note down max and min values\n\t */\n\tis_last = false;\n\tfor (i = 0; i < FIO_IO_U_PLAT_NR && !is_last; i++) {\n\t\tsum += io_u_plat[i];\n\t\twhile (sum >= ((long double) plist[j].u.f / 100.0 * nr)) {\n\t\t\tassert(plist[j].u.f <= 100.0);\n\n\t\t\tovals[j] = plat_idx_to_val(i);\n\t\t\tif (ovals[j] < *minv)\n\t\t\t\t*minv = ovals[j];\n\t\t\tif (ovals[j] > *maxv)\n\t\t\t\t*maxv = ovals[j];\n\n\t\t\tis_last = (j == len - 1) != 0;\n\t\t\tif (is_last)\n\t\t\t\tbreak;\n\n\t\t\tj++;\n\t\t}\n\t}\n\n\tif (!is_last)\n\t\tlog_err(\"fio: error calculating latency percentiles\\n\");\n\n\t*output = ovals;\n\treturn len;\n}\n\n/*\n * Find and display the p-th percentile of clat\n */\nstatic void show_clat_percentiles(uint64_t *io_u_plat, unsigned long long nr,\n\t\t\t\t  fio_fp64_t *plist, unsigned int precision,\n\t\t\t\t  const char *pre, struct buf_output *out)\n{\n\tunsigned int divisor, len, i, j = 0;\n\tunsigned long long minv, maxv;\n\tunsigned long long *ovals;\n\tint per_line, scale_down, time_width;\n\tbool is_last;\n\tchar fmt[32];\n\n\tlen = calc_clat_percentiles(io_u_plat, nr, plist, &ovals, &maxv, &minv);\n\tif (!len || !ovals)\n\t\treturn;\n\n\t/*\n\t * We default to nsecs, but if the value range is such that we\n\t * should scale down to usecs or msecs, do that.\n\t */\n\tif (minv > 2000000 && maxv > 99999999ULL) {\n\t\tscale_down = 2;\n\t\tdivisor = 1000000;\n\t\tlog_buf(out, \"    %s percentiles (msec):\\n     |\", pre);\n\t} else if (minv > 2000 && maxv > 99999) {\n\t\tscale_down = 1;\n\t\tdivisor = 1000;\n\t\tlog_buf(out, \"    %s percentiles (usec):\\n     |\", pre);\n\t} else {\n\t\tscale_down = 0;\n\t\tdivisor = 1;\n\t\tlog_buf(out, \"    %s percentiles (nsec):\\n     |\", pre);\n\t}\n\n\n\ttime_width = max(5, (int) (log10(maxv / divisor) + 1));\n\tsnprintf(fmt, sizeof(fmt), \" %%%u.%ufth=[%%%dllu]%%c\", precision + 3,\n\t\t\tprecision, time_width);\n\t/* fmt will be something like \" %5.2fth=[%4llu]%c\" */\n\tper_line = (80 - 7) / (precision + 10 + time_width);\n\n\tfor (j = 0; j < len; j++) {\n\t\t/* for formatting */\n\t\tif (j != 0 && (j % per_line) == 0)\n\t\t\tlog_buf(out, \"     |\");\n\n\t\t/* end of the list */\n\t\tis_last = (j == len - 1) != 0;\n\n\t\tfor (i = 0; i < scale_down; i++)\n\t\t\tovals[j] = (ovals[j] + 999) / 1000;\n\n\t\tlog_buf(out, fmt, plist[j].u.f, ovals[j], is_last ? '\\n' : ',');\n\n\t\tif (is_last)\n\t\t\tbreak;\n\n\t\tif ((j % per_line) == per_line - 1)\t/* for formatting */\n\t\t\tlog_buf(out, \"\\n\");\n\t}\n\n\tfree(ovals);\n}\n\nstatic int get_nr_prios_with_samples(struct thread_stat *ts, enum fio_ddir ddir)\n{\n\tint i, nr_prios_with_samples = 0;\n\n\tfor (i = 0; i < ts->nr_clat_prio[ddir]; i++) {\n\t\tif (ts->clat_prio[ddir][i].clat_stat.samples)\n\t\t\tnr_prios_with_samples++;\n\t}\n\n\treturn nr_prios_with_samples;\n}\n\nbool calc_lat(struct io_stat *is, unsigned long long *min,\n\t      unsigned long long *max, double *mean, double *dev)\n{\n\tdouble n = (double) is->samples;\n\n\tif (n == 0)\n\t\treturn false;\n\n\t*min = is->min_val;\n\t*max = is->max_val;\n\t*mean = is->mean.u.f;\n\n\tif (n > 1.0)\n\t\t*dev = sqrt(is->S.u.f / (n - 1.0));\n\telse\n\t\t*dev = 0;\n\n\treturn true;\n}\n\nvoid show_mixed_group_stats(struct group_run_stats *rs, struct buf_output *out) \n{\n\tchar *io, *agg, *min, *max;\n\tchar *ioalt, *aggalt, *minalt, *maxalt;\n\tuint64_t io_mix = 0, agg_mix = 0, min_mix = -1, max_mix = 0;\n\tuint64_t min_run = -1, max_run = 0;\n\tconst int i2p = is_power_of_2(rs->kb_base);\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (!rs->max_run[i])\n\t\t\tcontinue;\n\t\tio_mix += rs->iobytes[i];\n\t\tagg_mix += rs->agg[i];\n\t\tmin_mix = min_mix < rs->min_bw[i] ? min_mix : rs->min_bw[i];\n\t\tmax_mix = max_mix > rs->max_bw[i] ? max_mix : rs->max_bw[i];\n\t\tmin_run = min_run < rs->min_run[i] ? min_run : rs->min_run[i];\n\t\tmax_run = max_run > rs->max_run[i] ? max_run : rs->max_run[i];\n\t}\n\tio = num2str(io_mix, rs->sig_figs, 1, i2p, N2S_BYTE);\n\tioalt = num2str(io_mix, rs->sig_figs, 1, !i2p, N2S_BYTE);\n\tagg = num2str(agg_mix, rs->sig_figs, 1, i2p, rs->unit_base);\n\taggalt = num2str(agg_mix, rs->sig_figs, 1, !i2p, rs->unit_base);\n\tmin = num2str(min_mix, rs->sig_figs, 1, i2p, rs->unit_base);\n\tminalt = num2str(min_mix, rs->sig_figs, 1, !i2p, rs->unit_base);\n\tmax = num2str(max_mix, rs->sig_figs, 1, i2p, rs->unit_base);\n\tmaxalt = num2str(max_mix, rs->sig_figs, 1, !i2p, rs->unit_base);\n\tlog_buf(out, \"  MIXED: bw=%s (%s), %s-%s (%s-%s), io=%s (%s), run=%llu-%llumsec\\n\",\n\t\t\tagg, aggalt, min, max, minalt, maxalt, io, ioalt,\n\t\t\t(unsigned long long) min_run,\n\t\t\t(unsigned long long) max_run);\n\tfree(io);\n\tfree(agg);\n\tfree(min);\n\tfree(max);\n\tfree(ioalt);\n\tfree(aggalt);\n\tfree(minalt);\n\tfree(maxalt);\n}\n\nvoid show_group_stats(struct group_run_stats *rs, struct buf_output *out)\n{\n\tchar *io, *agg, *min, *max;\n\tchar *ioalt, *aggalt, *minalt, *maxalt;\n\tconst char *str[] = { \"   READ\", \"  WRITE\" , \"   TRIM\"};\n\tint i;\n\n\tlog_buf(out, \"\\nRun status group %d (all jobs):\\n\", rs->groupid);\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tconst int i2p = is_power_of_2(rs->kb_base);\n\n\t\tif (!rs->max_run[i])\n\t\t\tcontinue;\n\n\t\tio = num2str(rs->iobytes[i], rs->sig_figs, 1, i2p, N2S_BYTE);\n\t\tioalt = num2str(rs->iobytes[i], rs->sig_figs, 1, !i2p, N2S_BYTE);\n\t\tagg = num2str(rs->agg[i], rs->sig_figs, 1, i2p, rs->unit_base);\n\t\taggalt = num2str(rs->agg[i], rs->sig_figs, 1, !i2p, rs->unit_base);\n\t\tmin = num2str(rs->min_bw[i], rs->sig_figs, 1, i2p, rs->unit_base);\n\t\tminalt = num2str(rs->min_bw[i], rs->sig_figs, 1, !i2p, rs->unit_base);\n\t\tmax = num2str(rs->max_bw[i], rs->sig_figs, 1, i2p, rs->unit_base);\n\t\tmaxalt = num2str(rs->max_bw[i], rs->sig_figs, 1, !i2p, rs->unit_base);\n\t\tlog_buf(out, \"%s: bw=%s (%s), %s-%s (%s-%s), io=%s (%s), run=%llu-%llumsec\\n\",\n\t\t\t\t(rs->unified_rw_rep == UNIFIED_MIXED) ? \"  MIXED\" : str[i],\n\t\t\t\tagg, aggalt, min, max, minalt, maxalt, io, ioalt,\n\t\t\t\t(unsigned long long) rs->min_run[i],\n\t\t\t\t(unsigned long long) rs->max_run[i]);\n\n\t\tfree(io);\n\t\tfree(agg);\n\t\tfree(min);\n\t\tfree(max);\n\t\tfree(ioalt);\n\t\tfree(aggalt);\n\t\tfree(minalt);\n\t\tfree(maxalt);\n\t}\n\n\t/* Need to aggregate statistics to show mixed values */\n\tif (rs->unified_rw_rep == UNIFIED_BOTH)\n\t\tshow_mixed_group_stats(rs, out);\n}\n\nvoid stat_calc_dist(uint64_t *map, unsigned long total, double *io_u_dist)\n{\n\tint i;\n\n\t/*\n\t * Do depth distribution calculations\n\t */\n\tfor (i = 0; i < FIO_IO_U_MAP_NR; i++) {\n\t\tif (total) {\n\t\t\tio_u_dist[i] = (double) map[i] / (double) total;\n\t\t\tio_u_dist[i] *= 100.0;\n\t\t\tif (io_u_dist[i] < 0.1 && map[i])\n\t\t\t\tio_u_dist[i] = 0.1;\n\t\t} else\n\t\t\tio_u_dist[i] = 0.0;\n\t}\n}\n\nstatic void stat_calc_lat(struct thread_stat *ts, double *dst,\n\t\t\t  uint64_t *src, int nr)\n{\n\tunsigned long total = ddir_rw_sum(ts->total_io_u);\n\tint i;\n\n\t/*\n\t * Do latency distribution calculations\n\t */\n\tfor (i = 0; i < nr; i++) {\n\t\tif (total) {\n\t\t\tdst[i] = (double) src[i] / (double) total;\n\t\t\tdst[i] *= 100.0;\n\t\t\tif (dst[i] < 0.01 && src[i])\n\t\t\t\tdst[i] = 0.01;\n\t\t} else\n\t\t\tdst[i] = 0.0;\n\t}\n}\n\n/*\n * To keep the terse format unaltered, add all of the ns latency\n * buckets to the first us latency bucket\n */\nstatic void stat_calc_lat_nu(struct thread_stat *ts, double *io_u_lat_u)\n{\n\tunsigned long ntotal = 0, total = ddir_rw_sum(ts->total_io_u);\n\tint i;\n\n\tstat_calc_lat(ts, io_u_lat_u, ts->io_u_lat_u, FIO_IO_U_LAT_U_NR);\n\n\tfor (i = 0; i < FIO_IO_U_LAT_N_NR; i++)\n\t\tntotal += ts->io_u_lat_n[i];\n\n\tio_u_lat_u[0] += 100.0 * (double) ntotal / (double) total;\n}\n\nvoid stat_calc_lat_n(struct thread_stat *ts, double *io_u_lat)\n{\n\tstat_calc_lat(ts, io_u_lat, ts->io_u_lat_n, FIO_IO_U_LAT_N_NR);\n}\n\nvoid stat_calc_lat_u(struct thread_stat *ts, double *io_u_lat)\n{\n\tstat_calc_lat(ts, io_u_lat, ts->io_u_lat_u, FIO_IO_U_LAT_U_NR);\n}\n\nvoid stat_calc_lat_m(struct thread_stat *ts, double *io_u_lat)\n{\n\tstat_calc_lat(ts, io_u_lat, ts->io_u_lat_m, FIO_IO_U_LAT_M_NR);\n}\n\nstatic void display_lat(const char *name, unsigned long long min,\n\t\t\tunsigned long long max, double mean, double dev,\n\t\t\tstruct buf_output *out)\n{\n\tconst char *base = \"(nsec)\";\n\tchar *minp, *maxp;\n\n\tif (nsec_to_msec(&min, &max, &mean, &dev))\n\t\tbase = \"(msec)\";\n\telse if (nsec_to_usec(&min, &max, &mean, &dev))\n\t\tbase = \"(usec)\";\n\n\tminp = num2str(min, 6, 1, 0, N2S_NONE);\n\tmaxp = num2str(max, 6, 1, 0, N2S_NONE);\n\n\tlog_buf(out, \"    %s %s: min=%s, max=%s, avg=%5.02f,\"\n\t\t \" stdev=%5.02f\\n\", name, base, minp, maxp, mean, dev);\n\n\tfree(minp);\n\tfree(maxp);\n}\n\nstatic struct thread_stat *gen_mixed_ddir_stats_from_ts(struct thread_stat *ts)\n{\n\tstruct thread_stat *ts_lcl;\n\n\t/*\n\t * Handle aggregation of Reads (ddir = 0), Writes (ddir = 1), and\n\t * Trims (ddir = 2)\n\t */\n\tts_lcl = malloc(sizeof(struct thread_stat));\n\tif (!ts_lcl) {\n\t\tlog_err(\"fio: failed to allocate local thread stat\\n\");\n\t\treturn NULL;\n\t}\n\n\tinit_thread_stat(ts_lcl);\n\n\t/* calculate mixed stats  */\n\tts_lcl->unified_rw_rep = UNIFIED_MIXED;\n\tts_lcl->lat_percentiles = ts->lat_percentiles;\n\tts_lcl->clat_percentiles = ts->clat_percentiles;\n\tts_lcl->slat_percentiles = ts->slat_percentiles;\n\tts_lcl->percentile_precision = ts->percentile_precision;\n\tmemcpy(ts_lcl->percentile_list, ts->percentile_list, sizeof(ts->percentile_list));\n\tts_lcl->sig_figs = ts->sig_figs;\n\n\tsum_thread_stats(ts_lcl, ts);\n\n\treturn ts_lcl;\n}\n\nstatic double convert_agg_kbytes_percent(struct group_run_stats *rs,\n\t\t\t\t\t enum fio_ddir ddir, int mean)\n{\n\tdouble p_of_agg = 100.0;\n\tif (rs && rs->agg[ddir] > 1024) {\n\t\tp_of_agg = mean * 100.0 / (double) (rs->agg[ddir] / 1024.0);\n\n\t\tif (p_of_agg > 100.0)\n\t\t\tp_of_agg = 100.0;\n\t}\n\treturn p_of_agg;\n}\n\nstatic void show_ddir_status(struct group_run_stats *rs, struct thread_stat *ts,\n\t\t\t     enum fio_ddir ddir, struct buf_output *out)\n{\n\tunsigned long runt;\n\tunsigned long long min, max, bw, iops;\n\tdouble mean, dev;\n\tchar *io_p, *bw_p, *bw_p_alt, *iops_p, *post_st = NULL;\n\tint i2p, i;\n\tconst char *clat_type = ts->lat_percentiles ? \"lat\" : \"clat\";\n\n\tif (ddir_sync(ddir)) {\n\t\tif (calc_lat(&ts->sync_stat, &min, &max, &mean, &dev)) {\n\t\t\tlog_buf(out, \"  %s:\\n\", \"fsync/fdatasync/sync_file_range\");\n\t\t\tdisplay_lat(io_ddir_name(ddir), min, max, mean, dev, out);\n\t\t\tshow_clat_percentiles(ts->io_u_sync_plat,\n\t\t\t\t\t\tts->sync_stat.samples,\n\t\t\t\t\t\tts->percentile_list,\n\t\t\t\t\t\tts->percentile_precision,\n\t\t\t\t\t\tio_ddir_name(ddir), out);\n\t\t}\n\t\treturn;\n\t}\n\n\tassert(ddir_rw(ddir));\n\n\tif (!ts->runtime[ddir])\n\t\treturn;\n\n\ti2p = is_power_of_2(rs->kb_base);\n\trunt = ts->runtime[ddir];\n\n\tbw = (1000 * ts->io_bytes[ddir]) / runt;\n\tio_p = num2str(ts->io_bytes[ddir], ts->sig_figs, 1, i2p, N2S_BYTE);\n\tbw_p = num2str(bw, ts->sig_figs, 1, i2p, ts->unit_base);\n\tbw_p_alt = num2str(bw, ts->sig_figs, 1, !i2p, ts->unit_base);\n\n\tiops = (1000 * (uint64_t)ts->total_io_u[ddir]) / runt;\n\tiops_p = num2str(iops, ts->sig_figs, 1, 0, N2S_NONE);\n\tif (ddir == DDIR_WRITE || ddir == DDIR_TRIM)\n\t\tpost_st = zbd_write_status(ts);\n\telse if (ddir == DDIR_READ && ts->cachehit && ts->cachemiss) {\n\t\tuint64_t total;\n\t\tdouble hit;\n\n\t\ttotal = ts->cachehit + ts->cachemiss;\n\t\thit = (double) ts->cachehit / (double) total;\n\t\thit *= 100.0;\n\t\tif (asprintf(&post_st, \"; Cachehit=%0.2f%%\", hit) < 0)\n\t\t\tpost_st = NULL;\n\t}\n\n\tlog_buf(out, \"  %s: IOPS=%s, BW=%s (%s)(%s/%llumsec)%s\\n\",\n\t\t\t(ts->unified_rw_rep == UNIFIED_MIXED) ? \"mixed\" : io_ddir_name(ddir),\n\t\t\tiops_p, bw_p, bw_p_alt, io_p,\n\t\t\t(unsigned long long) ts->runtime[ddir],\n\t\t\tpost_st ? : \"\");\n\n\tfree(post_st);\n\tfree(io_p);\n\tfree(bw_p);\n\tfree(bw_p_alt);\n\tfree(iops_p);\n\n\tif (calc_lat(&ts->slat_stat[ddir], &min, &max, &mean, &dev))\n\t\tdisplay_lat(\"slat\", min, max, mean, dev, out);\n\tif (calc_lat(&ts->clat_stat[ddir], &min, &max, &mean, &dev))\n\t\tdisplay_lat(\"clat\", min, max, mean, dev, out);\n\tif (calc_lat(&ts->lat_stat[ddir], &min, &max, &mean, &dev))\n\t\tdisplay_lat(\" lat\", min, max, mean, dev, out);\n\n\t/* Only print per prio stats if there are >= 2 prios with samples */\n\tif (get_nr_prios_with_samples(ts, ddir) >= 2) {\n\t\tfor (i = 0; i < ts->nr_clat_prio[ddir]; i++) {\n\t\t\tchar buf[64];\n\n\t\t\tif (!calc_lat(&ts->clat_prio[ddir][i].clat_stat, &min,\n\t\t\t\t      &max, &mean, &dev))\n\t\t\t\tcontinue;\n\n\t\t\tsnprintf(buf, sizeof(buf),\n\t\t\t\t \"%s prio %u/%u/%u\",\n\t\t\t\t clat_type,\n\t\t\t\t ioprio_class(ts->clat_prio[ddir][i].ioprio),\n\t\t\t\t ioprio(ts->clat_prio[ddir][i].ioprio),\n\t\t\t\t ioprio_hint(ts->clat_prio[ddir][i].ioprio));\n\t\t\tdisplay_lat(buf, min, max, mean, dev, out);\n\t\t}\n\t}\n\n\tif (ts->slat_percentiles && ts->slat_stat[ddir].samples > 0)\n\t\tshow_clat_percentiles(ts->io_u_plat[FIO_SLAT][ddir],\n\t\t\t\t\tts->slat_stat[ddir].samples,\n\t\t\t\t\tts->percentile_list,\n\t\t\t\t\tts->percentile_precision, \"slat\", out);\n\tif (ts->clat_percentiles && ts->clat_stat[ddir].samples > 0)\n\t\tshow_clat_percentiles(ts->io_u_plat[FIO_CLAT][ddir],\n\t\t\t\t\tts->clat_stat[ddir].samples,\n\t\t\t\t\tts->percentile_list,\n\t\t\t\t\tts->percentile_precision, \"clat\", out);\n\tif (ts->lat_percentiles && ts->lat_stat[ddir].samples > 0)\n\t\tshow_clat_percentiles(ts->io_u_plat[FIO_LAT][ddir],\n\t\t\t\t\tts->lat_stat[ddir].samples,\n\t\t\t\t\tts->percentile_list,\n\t\t\t\t\tts->percentile_precision, \"lat\", out);\n\n\tif (ts->clat_percentiles || ts->lat_percentiles) {\n\t\tchar prio_name[64];\n\t\tuint64_t samples;\n\n\t\tif (ts->lat_percentiles)\n\t\t\tsamples = ts->lat_stat[ddir].samples;\n\t\telse\n\t\t\tsamples = ts->clat_stat[ddir].samples;\n\n\t\t/* Only print per prio stats if there are >= 2 prios with samples */\n\t\tif (get_nr_prios_with_samples(ts, ddir) >= 2) {\n\t\t\tfor (i = 0; i < ts->nr_clat_prio[ddir]; i++) {\n\t\t\t\tuint64_t prio_samples =\n\t\t\t\t\tts->clat_prio[ddir][i].clat_stat.samples;\n\n\t\t\t\tif (!prio_samples)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tsnprintf(prio_name, sizeof(prio_name),\n\t\t\t\t\t \"%s prio %u/%u/%u (%.2f%% of IOs)\",\n\t\t\t\t\t clat_type,\n\t\t\t\t\t ioprio_class(ts->clat_prio[ddir][i].ioprio),\n\t\t\t\t\t ioprio(ts->clat_prio[ddir][i].ioprio),\n\t\t\t\t\t ioprio_hint(ts->clat_prio[ddir][i].ioprio),\n\t\t\t\t\t 100. * (double) prio_samples / (double) samples);\n\t\t\t\tshow_clat_percentiles(ts->clat_prio[ddir][i].io_u_plat,\n\t\t\t\t\t\tprio_samples, ts->percentile_list,\n\t\t\t\t\t\tts->percentile_precision,\n\t\t\t\t\t\tprio_name, out);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (calc_lat(&ts->bw_stat[ddir], &min, &max, &mean, &dev)) {\n\t\tdouble p_of_agg = 100.0, fkb_base = (double)rs->kb_base;\n\t\tconst char *bw_str;\n\n\t\tif ((rs->unit_base == 1) && i2p)\n\t\t\tbw_str = \"Kibit\";\n\t\telse if (rs->unit_base == 1)\n\t\t\tbw_str = \"kbit\";\n\t\telse if (i2p)\n\t\t\tbw_str = \"KiB\";\n\t\telse\n\t\t\tbw_str = \"kB\";\n\n\t\tp_of_agg = convert_agg_kbytes_percent(rs, ddir, mean);\n\n\t\tif (rs->unit_base == 1) {\n\t\t\tmin *= 8.0;\n\t\t\tmax *= 8.0;\n\t\t\tmean *= 8.0;\n\t\t\tdev *= 8.0;\n\t\t}\n\n\t\tif (mean > fkb_base * fkb_base) {\n\t\t\tmin /= fkb_base;\n\t\t\tmax /= fkb_base;\n\t\t\tmean /= fkb_base;\n\t\t\tdev /= fkb_base;\n\t\t\tbw_str = (rs->unit_base == 1 ? \"Mibit\" : \"MiB\");\n\t\t}\n\n\t\tlog_buf(out, \"   bw (%5s/s): min=%5llu, max=%5llu, per=%3.2f%%, \"\n\t\t\t\"avg=%5.02f, stdev=%5.02f, samples=%\" PRIu64 \"\\n\",\n\t\t\tbw_str, min, max, p_of_agg, mean, dev,\n\t\t\t(&ts->bw_stat[ddir])->samples);\n\t}\n\tif (calc_lat(&ts->iops_stat[ddir], &min, &max, &mean, &dev)) {\n\t\tlog_buf(out, \"   iops        : min=%5llu, max=%5llu, \"\n\t\t\t\"avg=%5.02f, stdev=%5.02f, samples=%\" PRIu64 \"\\n\",\n\t\t\tmin, max, mean, dev, (&ts->iops_stat[ddir])->samples);\n\t}\n}\n\nstatic void show_mixed_ddir_status(struct group_run_stats *rs,\n\t\t\t\t   struct thread_stat *ts,\n\t\t\t\t   struct buf_output *out)\n{\n\tstruct thread_stat *ts_lcl = gen_mixed_ddir_stats_from_ts(ts);\n\n\tif (ts_lcl)\n\t\tshow_ddir_status(rs, ts_lcl, DDIR_READ, out);\n\n\tfree_clat_prio_stats(ts_lcl);\n\tfree(ts_lcl);\n}\n\nstatic bool show_lat(double *io_u_lat, int nr, const char **ranges,\n\t\t     const char *msg, struct buf_output *out)\n{\n\tbool new_line = true, shown = false;\n\tint i, line = 0;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tif (io_u_lat[i] <= 0.0)\n\t\t\tcontinue;\n\t\tshown = true;\n\t\tif (new_line) {\n\t\t\tif (line)\n\t\t\t\tlog_buf(out, \"\\n\");\n\t\t\tlog_buf(out, \"  lat (%s)   : \", msg);\n\t\t\tnew_line = false;\n\t\t\tline = 0;\n\t\t}\n\t\tif (line)\n\t\t\tlog_buf(out, \", \");\n\t\tlog_buf(out, \"%s%3.2f%%\", ranges[i], io_u_lat[i]);\n\t\tline++;\n\t\tif (line == 5)\n\t\t\tnew_line = true;\n\t}\n\n\tif (shown)\n\t\tlog_buf(out, \"\\n\");\n\n\treturn true;\n}\n\nstatic void show_lat_n(double *io_u_lat_n, struct buf_output *out)\n{\n\tconst char *ranges[] = { \"2=\", \"4=\", \"10=\", \"20=\", \"50=\", \"100=\",\n\t\t\t\t \"250=\", \"500=\", \"750=\", \"1000=\", };\n\n\tshow_lat(io_u_lat_n, FIO_IO_U_LAT_N_NR, ranges, \"nsec\", out);\n}\n\nstatic void show_lat_u(double *io_u_lat_u, struct buf_output *out)\n{\n\tconst char *ranges[] = { \"2=\", \"4=\", \"10=\", \"20=\", \"50=\", \"100=\",\n\t\t\t\t \"250=\", \"500=\", \"750=\", \"1000=\", };\n\n\tshow_lat(io_u_lat_u, FIO_IO_U_LAT_U_NR, ranges, \"usec\", out);\n}\n\nstatic void show_lat_m(double *io_u_lat_m, struct buf_output *out)\n{\n\tconst char *ranges[] = { \"2=\", \"4=\", \"10=\", \"20=\", \"50=\", \"100=\",\n\t\t\t\t \"250=\", \"500=\", \"750=\", \"1000=\", \"2000=\",\n\t\t\t\t \">=2000=\", };\n\n\tshow_lat(io_u_lat_m, FIO_IO_U_LAT_M_NR, ranges, \"msec\", out);\n}\n\nstatic void show_latencies(struct thread_stat *ts, struct buf_output *out)\n{\n\tdouble io_u_lat_n[FIO_IO_U_LAT_N_NR];\n\tdouble io_u_lat_u[FIO_IO_U_LAT_U_NR];\n\tdouble io_u_lat_m[FIO_IO_U_LAT_M_NR];\n\n\tstat_calc_lat_n(ts, io_u_lat_n);\n\tstat_calc_lat_u(ts, io_u_lat_u);\n\tstat_calc_lat_m(ts, io_u_lat_m);\n\n\tshow_lat_n(io_u_lat_n, out);\n\tshow_lat_u(io_u_lat_u, out);\n\tshow_lat_m(io_u_lat_m, out);\n}\n\nstatic int block_state_category(int block_state)\n{\n\tswitch (block_state) {\n\tcase BLOCK_STATE_UNINIT:\n\t\treturn 0;\n\tcase BLOCK_STATE_TRIMMED:\n\tcase BLOCK_STATE_WRITTEN:\n\t\treturn 1;\n\tcase BLOCK_STATE_WRITE_FAILURE:\n\tcase BLOCK_STATE_TRIM_FAILURE:\n\t\treturn 2;\n\tdefault:\n\t\t/* Silence compile warning on some BSDs and have a return */\n\t\tassert(0);\n\t\treturn -1;\n\t}\n}\n\nstatic int compare_block_infos(const void *bs1, const void *bs2)\n{\n\tuint64_t block1 = *(uint64_t *)bs1;\n\tuint64_t block2 = *(uint64_t *)bs2;\n\tint state1 = BLOCK_INFO_STATE(block1);\n\tint state2 = BLOCK_INFO_STATE(block2);\n\tint bscat1 = block_state_category(state1);\n\tint bscat2 = block_state_category(state2);\n\tint cycles1 = BLOCK_INFO_TRIMS(block1);\n\tint cycles2 = BLOCK_INFO_TRIMS(block2);\n\n\tif (bscat1 < bscat2)\n\t\treturn -1;\n\tif (bscat1 > bscat2)\n\t\treturn 1;\n\n\tif (cycles1 < cycles2)\n\t\treturn -1;\n\tif (cycles1 > cycles2)\n\t\treturn 1;\n\n\tif (state1 < state2)\n\t\treturn -1;\n\tif (state1 > state2)\n\t\treturn 1;\n\n\tassert(block1 == block2);\n\treturn 0;\n}\n\nstatic int calc_block_percentiles(int nr_block_infos, uint32_t *block_infos,\n\t\t\t\t  fio_fp64_t *plist, unsigned int **percentiles,\n\t\t\t\t  unsigned int *types)\n{\n\tint len = 0;\n\tint i, nr_uninit;\n\n\tqsort(block_infos, nr_block_infos, sizeof(uint32_t), compare_block_infos);\n\n\twhile (len < FIO_IO_U_LIST_MAX_LEN && plist[len].u.f != 0.0)\n\t\tlen++;\n\n\tif (!len)\n\t\treturn 0;\n\n\t/*\n\t * Sort the percentile list. Note that it may already be sorted if\n\t * we are using the default values, but since it's a short list this\n\t * isn't a worry. Also note that this does not work for NaN values.\n\t */\n\tif (len > 1)\n\t\tqsort(plist, len, sizeof(plist[0]), double_cmp);\n\n\t/* Start only after the uninit entries end */\n\tfor (nr_uninit = 0;\n\t     nr_uninit < nr_block_infos\n\t\t&& BLOCK_INFO_STATE(block_infos[nr_uninit]) == BLOCK_STATE_UNINIT;\n\t     nr_uninit ++)\n\t\t;\n\n\tif (nr_uninit == nr_block_infos)\n\t\treturn 0;\n\n\t*percentiles = calloc(len, sizeof(**percentiles));\n\n\tfor (i = 0; i < len; i++) {\n\t\tint idx = (plist[i].u.f * (nr_block_infos - nr_uninit) / 100)\n\t\t\t\t+ nr_uninit;\n\t\t(*percentiles)[i] = BLOCK_INFO_TRIMS(block_infos[idx]);\n\t}\n\n\tmemset(types, 0, sizeof(*types) * BLOCK_STATE_COUNT);\n\tfor (i = 0; i < nr_block_infos; i++)\n\t\ttypes[BLOCK_INFO_STATE(block_infos[i])]++;\n\n\treturn len;\n}\n\nstatic const char *block_state_names[] = {\n\t[BLOCK_STATE_UNINIT] = \"unwritten\",\n\t[BLOCK_STATE_TRIMMED] = \"trimmed\",\n\t[BLOCK_STATE_WRITTEN] = \"written\",\n\t[BLOCK_STATE_TRIM_FAILURE] = \"trim failure\",\n\t[BLOCK_STATE_WRITE_FAILURE] = \"write failure\",\n};\n\nstatic void show_block_infos(int nr_block_infos, uint32_t *block_infos,\n\t\t\t     fio_fp64_t *plist, struct buf_output *out)\n{\n\tint len, pos, i;\n\tunsigned int *percentiles = NULL;\n\tunsigned int block_state_counts[BLOCK_STATE_COUNT];\n\n\tlen = calc_block_percentiles(nr_block_infos, block_infos, plist,\n\t\t\t\t     &percentiles, block_state_counts);\n\n\tlog_buf(out, \"  block lifetime percentiles :\\n   |\");\n\tpos = 0;\n\tfor (i = 0; i < len; i++) {\n\t\tuint32_t block_info = percentiles[i];\n#define LINE_LENGTH\t75\n\t\tchar str[LINE_LENGTH];\n\t\tint strln = snprintf(str, LINE_LENGTH, \" %3.2fth=%u%c\",\n\t\t\t\t     plist[i].u.f, block_info,\n\t\t\t\t     i == len - 1 ? '\\n' : ',');\n\t\tassert(strln < LINE_LENGTH);\n\t\tif (pos + strln > LINE_LENGTH) {\n\t\t\tpos = 0;\n\t\t\tlog_buf(out, \"\\n   |\");\n\t\t}\n\t\tlog_buf(out, \"%s\", str);\n\t\tpos += strln;\n#undef LINE_LENGTH\n\t}\n\tif (percentiles)\n\t\tfree(percentiles);\n\n\tlog_buf(out, \"        states               :\");\n\tfor (i = 0; i < BLOCK_STATE_COUNT; i++)\n\t\tlog_buf(out, \" %s=%u%c\",\n\t\t\t block_state_names[i], block_state_counts[i],\n\t\t\t i == BLOCK_STATE_COUNT - 1 ? '\\n' : ',');\n}\n\nstatic void show_ss_normal(struct thread_stat *ts, struct buf_output *out)\n{\n\tchar *p1, *p1alt, *p2;\n\tunsigned long long bw_mean, iops_mean;\n\tconst int i2p = is_power_of_2(ts->kb_base);\n\n\tif (!ts->ss_dur)\n\t\treturn;\n\n\tbw_mean = steadystate_bw_mean(ts);\n\tiops_mean = steadystate_iops_mean(ts);\n\n\tp1 = num2str(bw_mean / ts->kb_base, ts->sig_figs, ts->kb_base, i2p, ts->unit_base);\n\tp1alt = num2str(bw_mean / ts->kb_base, ts->sig_figs, ts->kb_base, !i2p, ts->unit_base);\n\tp2 = num2str(iops_mean, ts->sig_figs, 1, 0, N2S_NONE);\n\n\tlog_buf(out, \"  steadystate  : attained=%s, bw=%s (%s), iops=%s, %s%s=%.3f%s\\n\",\n\t\tts->ss_state & FIO_SS_ATTAINED ? \"yes\" : \"no\",\n\t\tp1, p1alt, p2,\n\t\tts->ss_state & FIO_SS_IOPS ? \"iops\" : \"bw\",\n\t\tts->ss_state & FIO_SS_SLOPE ? \" slope\": \" mean dev\",\n\t\tts->ss_criterion.u.f,\n\t\tts->ss_state & FIO_SS_PCT ? \"%\" : \"\");\n\n\tfree(p1);\n\tfree(p1alt);\n\tfree(p2);\n}\n\nstatic void show_agg_stats(struct disk_util_agg *agg, int terse,\n\t\t\t   struct buf_output *out)\n{\n\tif (!agg->slavecount)\n\t\treturn;\n\n\tif (!terse) {\n\t\tlog_buf(out, \", aggrios=%llu/%llu, aggsectors=%llu/%llu, \"\n\t\t\t \"aggrmerge=%llu/%llu, aggrticks=%llu/%llu, \"\n\t\t\t \"aggrin_queue=%llu, aggrutil=%3.2f%%\",\n\t\t\t(unsigned long long) agg->ios[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ios[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->sectors[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->sectors[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->merges[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->merges[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ticks[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ticks[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->time_in_queue / agg->slavecount,\n\t\t\tagg->max_util.u.f);\n\t} else {\n\t\tlog_buf(out, \";slaves;%llu;%llu;%llu;%llu;%llu;%llu;%llu;%3.2f%%\",\n\t\t\t(unsigned long long) agg->ios[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ios[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->merges[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->merges[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ticks[0] / agg->slavecount,\n\t\t\t(unsigned long long) agg->ticks[1] / agg->slavecount,\n\t\t\t(unsigned long long) agg->time_in_queue / agg->slavecount,\n\t\t\tagg->max_util.u.f);\n\t}\n}\n\nstatic void aggregate_slaves_stats(struct disk_util *masterdu)\n{\n\tstruct disk_util_agg *agg = &masterdu->agg;\n\tstruct disk_util_stat *dus;\n\tstruct flist_head *entry;\n\tstruct disk_util *slavedu;\n\tdouble util;\n\n\tflist_for_each(entry, &masterdu->slaves) {\n\t\tslavedu = flist_entry(entry, struct disk_util, slavelist);\n\t\tdus = &slavedu->dus;\n\t\tagg->ios[0] += dus->s.ios[0];\n\t\tagg->ios[1] += dus->s.ios[1];\n\t\tagg->merges[0] += dus->s.merges[0];\n\t\tagg->merges[1] += dus->s.merges[1];\n\t\tagg->sectors[0] += dus->s.sectors[0];\n\t\tagg->sectors[1] += dus->s.sectors[1];\n\t\tagg->ticks[0] += dus->s.ticks[0];\n\t\tagg->ticks[1] += dus->s.ticks[1];\n\t\tagg->time_in_queue += dus->s.time_in_queue;\n\t\tagg->slavecount++;\n\n\t\tutil = (double) (100 * dus->s.io_ticks / (double) slavedu->dus.s.msec);\n\t\t/* System utilization is the utilization of the\n\t\t * component with the highest utilization.\n\t\t */\n\t\tif (util > agg->max_util.u.f)\n\t\t\tagg->max_util.u.f = util;\n\n\t}\n\n\tif (agg->max_util.u.f > 100.0)\n\t\tagg->max_util.u.f = 100.0;\n}\n\nvoid print_disk_util(struct disk_util_stat *dus, struct disk_util_agg *agg,\n\t\t     int terse, struct buf_output *out)\n{\n\tdouble util = 0;\n\n\tif (dus->s.msec)\n\t\tutil = (double) 100 * dus->s.io_ticks / (double) dus->s.msec;\n\tif (util > 100.0)\n\t\tutil = 100.0;\n\n\tif (!terse) {\n\t\tif (agg->slavecount)\n\t\t\tlog_buf(out, \"  \");\n\n\t\tlog_buf(out, \"  %s: ios=%llu/%llu, sectors=%llu/%llu, \"\n\t\t\t\"merge=%llu/%llu, ticks=%llu/%llu, in_queue=%llu, \"\n\t\t\t\"util=%3.2f%%\",\n\t\t\t\tdus->name,\n\t\t\t\t(unsigned long long) dus->s.ios[0],\n\t\t\t\t(unsigned long long) dus->s.ios[1],\n\t\t\t\t(unsigned long long) dus->s.sectors[0],\n\t\t\t\t(unsigned long long) dus->s.sectors[1],\n\t\t\t\t(unsigned long long) dus->s.merges[0],\n\t\t\t\t(unsigned long long) dus->s.merges[1],\n\t\t\t\t(unsigned long long) dus->s.ticks[0],\n\t\t\t\t(unsigned long long) dus->s.ticks[1],\n\t\t\t\t(unsigned long long) dus->s.time_in_queue,\n\t\t\t\tutil);\n\t} else {\n\t\tlog_buf(out, \";%s;%llu;%llu;%llu;%llu;%llu;%llu;%llu;%3.2f%%\",\n\t\t\t\tdus->name,\n\t\t\t\t(unsigned long long) dus->s.ios[0],\n\t\t\t\t(unsigned long long) dus->s.ios[1],\n\t\t\t\t(unsigned long long) dus->s.merges[0],\n\t\t\t\t(unsigned long long) dus->s.merges[1],\n\t\t\t\t(unsigned long long) dus->s.ticks[0],\n\t\t\t\t(unsigned long long) dus->s.ticks[1],\n\t\t\t\t(unsigned long long) dus->s.time_in_queue,\n\t\t\t\tutil);\n\t}\n\n\t/*\n\t * If the device has slaves, aggregate the stats for\n\t * those slave devices also.\n\t */\n\tshow_agg_stats(agg, terse, out);\n\n\tif (!terse)\n\t\tlog_buf(out, \"\\n\");\n}\n\nvoid json_array_add_disk_util(struct disk_util_stat *dus,\n\t\tstruct disk_util_agg *agg, struct json_array *array)\n{\n\tstruct json_object *obj;\n\tdouble util = 0;\n\n\tif (dus->s.msec)\n\t\tutil = (double) 100 * dus->s.io_ticks / (double) dus->s.msec;\n\tif (util > 100.0)\n\t\tutil = 100.0;\n\n\tobj = json_create_object();\n\tjson_array_add_value_object(array, obj);\n\n\tjson_object_add_value_string(obj, \"name\", (const char *)dus->name);\n\tjson_object_add_value_int(obj, \"read_ios\", dus->s.ios[0]);\n\tjson_object_add_value_int(obj, \"write_ios\", dus->s.ios[1]);\n\tjson_object_add_value_int(obj, \"read_sectors\", dus->s.sectors[0]);\n\tjson_object_add_value_int(obj, \"write_sectors\", dus->s.sectors[1]);\n\tjson_object_add_value_int(obj, \"read_merges\", dus->s.merges[0]);\n\tjson_object_add_value_int(obj, \"write_merges\", dus->s.merges[1]);\n\tjson_object_add_value_int(obj, \"read_ticks\", dus->s.ticks[0]);\n\tjson_object_add_value_int(obj, \"write_ticks\", dus->s.ticks[1]);\n\tjson_object_add_value_int(obj, \"in_queue\", dus->s.time_in_queue);\n\tjson_object_add_value_float(obj, \"util\", util);\n\n\t/*\n\t * If the device has slaves, aggregate the stats for\n\t * those slave devices also.\n\t */\n\tif (!agg->slavecount)\n\t\treturn;\n\tjson_object_add_value_int(obj, \"aggr_read_ios\",\n\t\t\t\tagg->ios[0] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_write_ios\",\n\t\t\t\tagg->ios[1] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_read_sectors\",\n\t\t\t\tagg->sectors[0] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_write_sectors\",\n\t\t\t\tagg->sectors[1] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_read_merges\",\n\t\t\t\tagg->merges[0] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_write_merge\",\n\t\t\t\tagg->merges[1] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_read_ticks\",\n\t\t\t\tagg->ticks[0] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_write_ticks\",\n\t\t\t\tagg->ticks[1] / agg->slavecount);\n\tjson_object_add_value_int(obj, \"aggr_in_queue\",\n\t\t\t\tagg->time_in_queue / agg->slavecount);\n\tjson_object_add_value_float(obj, \"aggr_util\", agg->max_util.u.f);\n}\n\nstatic void json_object_add_disk_utils(struct json_object *obj,\n\t\t\t\t       struct flist_head *head)\n{\n\tstruct json_array *array = json_create_array();\n\tstruct flist_head *entry;\n\tstruct disk_util *du;\n\n\tjson_object_add_value_array(obj, \"disk_util\", array);\n\n\tflist_for_each(entry, head) {\n\t\tdu = flist_entry(entry, struct disk_util, list);\n\n\t\taggregate_slaves_stats(du);\n\t\tjson_array_add_disk_util(&du->dus, &du->agg, array);\n\t}\n}\n\nvoid show_disk_util(int terse, struct json_object *parent,\n\t\t    struct buf_output *out)\n{\n\tstruct flist_head *entry;\n\tstruct disk_util *du;\n\tbool do_json;\n\n\tif (!is_running_backend())\n\t\treturn;\n\n\tif (flist_empty(&disk_list))\n\t\treturn;\n\n\tif ((output_format & FIO_OUTPUT_JSON) && parent)\n\t\tdo_json = true;\n\telse\n\t\tdo_json = false;\n\n\tif (!terse && !do_json)\n\t\tlog_buf(out, \"\\nDisk stats (read/write):\\n\");\n\n\tif (do_json) {\n\t\tjson_object_add_disk_utils(parent, &disk_list);\n\t} else if (output_format & ~(FIO_OUTPUT_JSON | FIO_OUTPUT_JSON_PLUS)) {\n\t\tflist_for_each(entry, &disk_list) {\n\t\t\tdu = flist_entry(entry, struct disk_util, list);\n\n\t\t\taggregate_slaves_stats(du);\n\t\t\tprint_disk_util(&du->dus, &du->agg, terse, out);\n\t\t}\n\t}\n}\n\nstatic void show_thread_status_normal(struct thread_stat *ts,\n\t\t\t\t      struct group_run_stats *rs,\n\t\t\t\t      struct buf_output *out)\n{\n\tdouble usr_cpu, sys_cpu;\n\tunsigned long runtime;\n\tdouble io_u_dist[FIO_IO_U_MAP_NR];\n\ttime_t time_p;\n\tchar time_buf[32];\n\n\tif (!ddir_rw_sum(ts->io_bytes) && !ddir_rw_sum(ts->total_io_u))\n\t\treturn;\n\n\tmemset(time_buf, 0, sizeof(time_buf));\n\n\ttime(&time_p);\n\tos_ctime_r((const time_t *) &time_p, time_buf, sizeof(time_buf));\n\n\tif (!ts->error) {\n\t\tlog_buf(out, \"%s: (groupid=%d, jobs=%d): err=%2d: pid=%d: %s\",\n\t\t\t\t\tts->name, ts->groupid, ts->members,\n\t\t\t\t\tts->error, (int) ts->pid, time_buf);\n\t} else {\n\t\tlog_buf(out, \"%s: (groupid=%d, jobs=%d): err=%2d (%s): pid=%d: %s\",\n\t\t\t\t\tts->name, ts->groupid, ts->members,\n\t\t\t\t\tts->error, ts->verror, (int) ts->pid,\n\t\t\t\t\ttime_buf);\n\t}\n\n\tif (strlen(ts->description))\n\t\tlog_buf(out, \"  Description  : [%s]\\n\", ts->description);\n\n\tfor_each_rw_ddir(ddir) {\n\t\tif (ts->io_bytes[ddir])\n\t\t\tshow_ddir_status(rs, ts, ddir, out);\n\t}\n\n\tif (ts->unified_rw_rep == UNIFIED_BOTH)\n\t\tshow_mixed_ddir_status(rs, ts, out);\n\n\tshow_latencies(ts, out);\n\n\tif (ts->sync_stat.samples)\n\t\tshow_ddir_status(rs, ts, DDIR_SYNC, out);\n\n\truntime = ts->total_run_time;\n\tif (runtime) {\n\t\tdouble runt = (double) runtime;\n\n\t\tusr_cpu = (double) ts->usr_time * 100 / runt;\n\t\tsys_cpu = (double) ts->sys_time * 100 / runt;\n\t} else {\n\t\tusr_cpu = 0;\n\t\tsys_cpu = 0;\n\t}\n\n\tlog_buf(out, \"  cpu          : usr=%3.2f%%, sys=%3.2f%%, ctx=%llu,\"\n\t\t \" majf=%llu, minf=%llu\\n\", usr_cpu, sys_cpu,\n\t\t\t(unsigned long long) ts->ctx,\n\t\t\t(unsigned long long) ts->majf,\n\t\t\t(unsigned long long) ts->minf);\n\n\tstat_calc_dist(ts->io_u_map, ddir_rw_sum(ts->total_io_u), io_u_dist);\n\tlog_buf(out, \"  IO depths    : 1=%3.1f%%, 2=%3.1f%%, 4=%3.1f%%, 8=%3.1f%%,\"\n\t\t \" 16=%3.1f%%, 32=%3.1f%%, >=64=%3.1f%%\\n\", io_u_dist[0],\n\t\t\t\t\tio_u_dist[1], io_u_dist[2],\n\t\t\t\t\tio_u_dist[3], io_u_dist[4],\n\t\t\t\t\tio_u_dist[5], io_u_dist[6]);\n\n\tstat_calc_dist(ts->io_u_submit, ts->total_submit, io_u_dist);\n\tlog_buf(out, \"     submit    : 0=%3.1f%%, 4=%3.1f%%, 8=%3.1f%%, 16=%3.1f%%,\"\n\t\t \" 32=%3.1f%%, 64=%3.1f%%, >=64=%3.1f%%\\n\", io_u_dist[0],\n\t\t\t\t\tio_u_dist[1], io_u_dist[2],\n\t\t\t\t\tio_u_dist[3], io_u_dist[4],\n\t\t\t\t\tio_u_dist[5], io_u_dist[6]);\n\tstat_calc_dist(ts->io_u_complete, ts->total_complete, io_u_dist);\n\tlog_buf(out, \"     complete  : 0=%3.1f%%, 4=%3.1f%%, 8=%3.1f%%, 16=%3.1f%%,\"\n\t\t \" 32=%3.1f%%, 64=%3.1f%%, >=64=%3.1f%%\\n\", io_u_dist[0],\n\t\t\t\t\tio_u_dist[1], io_u_dist[2],\n\t\t\t\t\tio_u_dist[3], io_u_dist[4],\n\t\t\t\t\tio_u_dist[5], io_u_dist[6]);\n\tlog_buf(out, \"     issued rwts: total=%llu,%llu,%llu,%llu\"\n\t\t\t\t \" short=%llu,%llu,%llu,0\"\n\t\t\t\t \" dropped=%llu,%llu,%llu,0\\n\",\n\t\t\t\t\t(unsigned long long) ts->total_io_u[0],\n\t\t\t\t\t(unsigned long long) ts->total_io_u[1],\n\t\t\t\t\t(unsigned long long) ts->total_io_u[2],\n\t\t\t\t\t(unsigned long long) ts->total_io_u[3],\n\t\t\t\t\t(unsigned long long) ts->short_io_u[0],\n\t\t\t\t\t(unsigned long long) ts->short_io_u[1],\n\t\t\t\t\t(unsigned long long) ts->short_io_u[2],\n\t\t\t\t\t(unsigned long long) ts->drop_io_u[0],\n\t\t\t\t\t(unsigned long long) ts->drop_io_u[1],\n\t\t\t\t\t(unsigned long long) ts->drop_io_u[2]);\n\tif (ts->continue_on_error) {\n\t\tlog_buf(out, \"     errors    : total=%llu, first_error=%d/<%s>\\n\",\n\t\t\t\t\t(unsigned long long)ts->total_err_count,\n\t\t\t\t\tts->first_error,\n\t\t\t\t\tstrerror(ts->first_error));\n\t}\n\tif (ts->latency_depth) {\n\t\tlog_buf(out, \"     latency   : target=%llu, window=%llu, percentile=%.2f%%, depth=%u\\n\",\n\t\t\t\t\t(unsigned long long)ts->latency_target,\n\t\t\t\t\t(unsigned long long)ts->latency_window,\n\t\t\t\t\tts->latency_percentile.u.f,\n\t\t\t\t\tts->latency_depth);\n\t}\n\n\tif (ts->nr_block_infos)\n\t\tshow_block_infos(ts->nr_block_infos, ts->block_infos,\n\t\t\t\t  ts->percentile_list, out);\n\n\tif (ts->ss_dur)\n\t\tshow_ss_normal(ts, out);\n}\n\nstatic void show_ddir_status_terse(struct thread_stat *ts,\n\t\t\t\t   struct group_run_stats *rs,\n\t\t\t\t   enum fio_ddir ddir, int ver,\n\t\t\t\t   struct buf_output *out)\n{\n\tunsigned long long min, max, minv, maxv, bw, iops;\n\tunsigned long long *ovals = NULL;\n\tdouble mean, dev;\n\tunsigned int len;\n\tint i, bw_stat;\n\n\tassert(ddir_rw(ddir));\n\n\tiops = bw = 0;\n\tif (ts->runtime[ddir]) {\n\t\tuint64_t runt = ts->runtime[ddir];\n\n\t\tbw = ((1000 * ts->io_bytes[ddir]) / runt) / 1024; /* KiB/s */\n\t\tiops = (1000 * (uint64_t) ts->total_io_u[ddir]) / runt;\n\t}\n\n\tlog_buf(out, \";%llu;%llu;%llu;%llu\",\n\t\t(unsigned long long) ts->io_bytes[ddir] >> 10, bw, iops,\n\t\t\t\t\t(unsigned long long) ts->runtime[ddir]);\n\n\tif (calc_lat(&ts->slat_stat[ddir], &min, &max, &mean, &dev))\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", min/1000, max/1000, mean/1000, dev/1000);\n\telse\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", 0ULL, 0ULL, 0.0, 0.0);\n\n\tif (calc_lat(&ts->clat_stat[ddir], &min, &max, &mean, &dev))\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", min/1000, max/1000, mean/1000, dev/1000);\n\telse\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", 0ULL, 0ULL, 0.0, 0.0);\n\n\tif (ts->lat_percentiles) {\n\t\tlen = calc_clat_percentiles(ts->io_u_plat[FIO_LAT][ddir],\n\t\t\t\t\tts->lat_stat[ddir].samples,\n\t\t\t\t\tts->percentile_list, &ovals, &maxv,\n\t\t\t\t\t&minv);\n\t} else if (ts->clat_percentiles) {\n\t\tlen = calc_clat_percentiles(ts->io_u_plat[FIO_CLAT][ddir],\n\t\t\t\t\tts->clat_stat[ddir].samples,\n\t\t\t\t\tts->percentile_list, &ovals, &maxv,\n\t\t\t\t\t&minv);\n\t} else {\n\t\tlen = 0;\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_LIST_MAX_LEN; i++) {\n\t\tif (i >= len) {\n\t\t\tlog_buf(out, \";0%%=0\");\n\t\t\tcontinue;\n\t\t}\n\t\tlog_buf(out, \";%f%%=%llu\", ts->percentile_list[i].u.f, ovals[i]/1000);\n\t}\n\n\tif (calc_lat(&ts->lat_stat[ddir], &min, &max, &mean, &dev))\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", min/1000, max/1000, mean/1000, dev/1000);\n\telse\n\t\tlog_buf(out, \";%llu;%llu;%f;%f\", 0ULL, 0ULL, 0.0, 0.0);\n\n\tfree(ovals);\n\n\tbw_stat = calc_lat(&ts->bw_stat[ddir], &min, &max, &mean, &dev);\n\tif (bw_stat) {\n\t\tdouble p_of_agg = 100.0;\n\n\t\tif (rs->agg[ddir]) {\n\t\t\tp_of_agg = mean * 100 / (double) (rs->agg[ddir] / 1024);\n\t\t\tif (p_of_agg > 100.0)\n\t\t\t\tp_of_agg = 100.0;\n\t\t}\n\n\t\tlog_buf(out, \";%llu;%llu;%f%%;%f;%f\", min, max, p_of_agg, mean, dev);\n\t} else {\n\t\tlog_buf(out, \";%llu;%llu;%f%%;%f;%f\", 0ULL, 0ULL, 0.0, 0.0, 0.0);\n\t}\n\n\tif (ver == 5) {\n\t\tif (bw_stat)\n\t\t\tlog_buf(out, \";%\" PRIu64, (&ts->bw_stat[ddir])->samples);\n\t\telse\n\t\t\tlog_buf(out, \";%lu\", 0UL);\n\n\t\tif (calc_lat(&ts->iops_stat[ddir], &min, &max, &mean, &dev))\n\t\t\tlog_buf(out, \";%llu;%llu;%f;%f;%\" PRIu64, min, max,\n\t\t\t\tmean, dev, (&ts->iops_stat[ddir])->samples);\n\t\telse\n\t\t\tlog_buf(out, \";%llu;%llu;%f;%f;%lu\", 0ULL, 0ULL, 0.0, 0.0, 0UL);\n\t}\n}\n\nstatic void show_mixed_ddir_status_terse(struct thread_stat *ts,\n\t\t\t\t   struct group_run_stats *rs,\n\t\t\t\t   int ver, struct buf_output *out)\n{\n\tstruct thread_stat *ts_lcl = gen_mixed_ddir_stats_from_ts(ts);\n\n\tif (ts_lcl)\n\t\tshow_ddir_status_terse(ts_lcl, rs, DDIR_READ, ver, out);\n\n\tfree_clat_prio_stats(ts_lcl);\n\tfree(ts_lcl);\n}\n\nstatic struct json_object *add_ddir_lat_json(struct thread_stat *ts,\n\t\t\t\t\t     uint32_t percentiles,\n\t\t\t\t\t     struct io_stat *lat_stat,\n\t\t\t\t\t     uint64_t *io_u_plat)\n{\n\tchar buf[120];\n\tdouble mean, dev;\n\tunsigned int i, len;\n\tstruct json_object *lat_object, *percentile_object, *clat_bins_object;\n\tunsigned long long min, max, maxv, minv, *ovals = NULL;\n\n\tif (!calc_lat(lat_stat, &min, &max, &mean, &dev)) {\n\t\tmin = max = 0;\n\t\tmean = dev = 0.0;\n\t}\n\tlat_object = json_create_object();\n\tjson_object_add_value_int(lat_object, \"min\", min);\n\tjson_object_add_value_int(lat_object, \"max\", max);\n\tjson_object_add_value_float(lat_object, \"mean\", mean);\n\tjson_object_add_value_float(lat_object, \"stddev\", dev);\n\tjson_object_add_value_int(lat_object, \"N\", lat_stat->samples);\n\n\tif (percentiles && lat_stat->samples) {\n\t\tlen = calc_clat_percentiles(io_u_plat, lat_stat->samples,\n\t\t\t\tts->percentile_list, &ovals, &maxv, &minv);\n\n\t\tif (len > FIO_IO_U_LIST_MAX_LEN)\n\t\t\tlen = FIO_IO_U_LIST_MAX_LEN;\n\n\t\tpercentile_object = json_create_object();\n\t\tjson_object_add_value_object(lat_object, \"percentile\", percentile_object);\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tsnprintf(buf, sizeof(buf), \"%f\", ts->percentile_list[i].u.f);\n\t\t\tjson_object_add_value_int(percentile_object, buf, ovals[i]);\n\t\t}\n\t\tfree(ovals);\n\n\t\tif (output_format & FIO_OUTPUT_JSON_PLUS) {\n\t\t\tclat_bins_object = json_create_object();\n\t\t\tjson_object_add_value_object(lat_object, \"bins\", clat_bins_object);\n\n\t\t\tfor(i = 0; i < FIO_IO_U_PLAT_NR; i++)\n\t\t\t\tif (io_u_plat[i]) {\n\t\t\t\t\tsnprintf(buf, sizeof(buf), \"%llu\", plat_idx_to_val(i));\n\t\t\t\t\tjson_object_add_value_int(clat_bins_object, buf, io_u_plat[i]);\n\t\t\t\t}\n\t\t}\n\t}\n\n\treturn lat_object;\n}\n\nstatic void add_ddir_status_json(struct thread_stat *ts,\n\t\t\t\t struct group_run_stats *rs, enum fio_ddir ddir,\n\t\t\t\t struct json_object *parent)\n{\n\tunsigned long long min, max;\n\tunsigned long long bw_bytes, bw;\n\tdouble mean, dev, iops;\n\tstruct json_object *dir_object, *tmp_object;\n\tdouble p_of_agg = 100.0;\n\n\tassert(ddir_rw(ddir) || ddir_sync(ddir));\n\n\tif ((ts->unified_rw_rep == UNIFIED_MIXED) && ddir != DDIR_READ)\n\t\treturn;\n\n\tdir_object = json_create_object();\n\tjson_object_add_value_object(parent,\n\t\t(ts->unified_rw_rep == UNIFIED_MIXED) ? \"mixed\" : io_ddir_name(ddir), dir_object);\n\n\tif (ddir_rw(ddir)) {\n\t\tbw_bytes = 0;\n\t\tbw = 0;\n\t\tiops = 0.0;\n\t\tif (ts->runtime[ddir]) {\n\t\t\tuint64_t runt = ts->runtime[ddir];\n\n\t\t\tbw_bytes = ((1000 * ts->io_bytes[ddir]) / runt); /* Bytes/s */\n\t\t\tbw = bw_bytes / 1024; /* KiB/s */\n\t\t\tiops = (1000.0 * (uint64_t) ts->total_io_u[ddir]) / runt;\n\t\t}\n\n\t\tjson_object_add_value_int(dir_object, \"io_bytes\", ts->io_bytes[ddir]);\n\t\tjson_object_add_value_int(dir_object, \"io_kbytes\", ts->io_bytes[ddir] >> 10);\n\t\tjson_object_add_value_int(dir_object, \"bw_bytes\", bw_bytes);\n\t\tjson_object_add_value_int(dir_object, \"bw\", bw);\n\t\tjson_object_add_value_float(dir_object, \"iops\", iops);\n\t\tjson_object_add_value_int(dir_object, \"runtime\", ts->runtime[ddir]);\n\t\tjson_object_add_value_int(dir_object, \"total_ios\", ts->total_io_u[ddir]);\n\t\tjson_object_add_value_int(dir_object, \"short_ios\", ts->short_io_u[ddir]);\n\t\tjson_object_add_value_int(dir_object, \"drop_ios\", ts->drop_io_u[ddir]);\n\n\t\ttmp_object = add_ddir_lat_json(ts, ts->slat_percentiles,\n\t\t\t\t&ts->slat_stat[ddir], ts->io_u_plat[FIO_SLAT][ddir]);\n\t\tjson_object_add_value_object(dir_object, \"slat_ns\", tmp_object);\n\n\t\ttmp_object = add_ddir_lat_json(ts, ts->clat_percentiles,\n\t\t\t\t&ts->clat_stat[ddir], ts->io_u_plat[FIO_CLAT][ddir]);\n\t\tjson_object_add_value_object(dir_object, \"clat_ns\", tmp_object);\n\n\t\ttmp_object = add_ddir_lat_json(ts, ts->lat_percentiles,\n\t\t\t\t&ts->lat_stat[ddir], ts->io_u_plat[FIO_LAT][ddir]);\n\t\tjson_object_add_value_object(dir_object, \"lat_ns\", tmp_object);\n\t} else {\n\t\tjson_object_add_value_int(dir_object, \"total_ios\", ts->total_io_u[DDIR_SYNC]);\n\t\ttmp_object = add_ddir_lat_json(ts, ts->lat_percentiles | ts->clat_percentiles,\n\t\t\t\t&ts->sync_stat, ts->io_u_sync_plat);\n\t\tjson_object_add_value_object(dir_object, \"lat_ns\", tmp_object);\n\t}\n\n\tif (!ddir_rw(ddir))\n\t\treturn;\n\n\t/* Only include per prio stats if there are >= 2 prios with samples */\n\tif (get_nr_prios_with_samples(ts, ddir) >= 2) {\n\t\tstruct json_array *array = json_create_array();\n\t\tconst char *obj_name;\n\t\tint i;\n\n\t\tif (ts->lat_percentiles)\n\t\t\tobj_name = \"lat_ns\";\n\t\telse\n\t\t\tobj_name = \"clat_ns\";\n\n\t\tjson_object_add_value_array(dir_object, \"prios\", array);\n\n\t\tfor (i = 0; i < ts->nr_clat_prio[ddir]; i++) {\n\t\t\tstruct json_object *obj;\n\n\t\t\tif (!ts->clat_prio[ddir][i].clat_stat.samples)\n\t\t\t\tcontinue;\n\n\t\t\tobj = json_create_object();\n\n\t\t\tjson_object_add_value_int(obj, \"prioclass\",\n\t\t\t\tioprio_class(ts->clat_prio[ddir][i].ioprio));\n\t\t\tjson_object_add_value_int(obj, \"prio\",\n\t\t\t\tioprio(ts->clat_prio[ddir][i].ioprio));\n\t\t\tjson_object_add_value_int(obj, \"priohint\",\n\t\t\t\tioprio_hint(ts->clat_prio[ddir][i].ioprio));\n\n\t\t\ttmp_object = add_ddir_lat_json(ts,\n\t\t\t\t\tts->clat_percentiles | ts->lat_percentiles,\n\t\t\t\t\t&ts->clat_prio[ddir][i].clat_stat,\n\t\t\t\t\tts->clat_prio[ddir][i].io_u_plat);\n\t\t\tjson_object_add_value_object(obj, obj_name, tmp_object);\n\t\t\tjson_array_add_value_object(array, obj);\n\t\t}\n\t}\n\n\tif (calc_lat(&ts->bw_stat[ddir], &min, &max, &mean, &dev)) {\n\t\tp_of_agg = convert_agg_kbytes_percent(rs, ddir, mean);\n\t} else {\n\t\tmin = max = 0;\n\t\tp_of_agg = mean = dev = 0.0;\n\t}\n\n\tjson_object_add_value_int(dir_object, \"bw_min\", min);\n\tjson_object_add_value_int(dir_object, \"bw_max\", max);\n\tjson_object_add_value_float(dir_object, \"bw_agg\", p_of_agg);\n\tjson_object_add_value_float(dir_object, \"bw_mean\", mean);\n\tjson_object_add_value_float(dir_object, \"bw_dev\", dev);\n\tjson_object_add_value_int(dir_object, \"bw_samples\",\n\t\t\t\t(&ts->bw_stat[ddir])->samples);\n\n\tif (!calc_lat(&ts->iops_stat[ddir], &min, &max, &mean, &dev)) {\n\t\tmin = max = 0;\n\t\tmean = dev = 0.0;\n\t}\n\tjson_object_add_value_int(dir_object, \"iops_min\", min);\n\tjson_object_add_value_int(dir_object, \"iops_max\", max);\n\tjson_object_add_value_float(dir_object, \"iops_mean\", mean);\n\tjson_object_add_value_float(dir_object, \"iops_stddev\", dev);\n\tjson_object_add_value_int(dir_object, \"iops_samples\",\n\t\t\t\t(&ts->iops_stat[ddir])->samples);\n\n\tif (ts->cachehit + ts->cachemiss) {\n\t\tuint64_t total;\n\t\tdouble hit;\n\n\t\ttotal = ts->cachehit + ts->cachemiss;\n\t\thit = (double) ts->cachehit / (double) total;\n\t\thit *= 100.0;\n\t\tjson_object_add_value_float(dir_object, \"cachehit\", hit);\n\t}\n}\n\nstatic void add_mixed_ddir_status_json(struct thread_stat *ts,\n\t\tstruct group_run_stats *rs, struct json_object *parent)\n{\n\tstruct thread_stat *ts_lcl = gen_mixed_ddir_stats_from_ts(ts);\n\n\t/* add the aggregated stats to json parent */\n\tif (ts_lcl)\n\t\tadd_ddir_status_json(ts_lcl, rs, DDIR_READ, parent);\n\n\tfree_clat_prio_stats(ts_lcl);\n\tfree(ts_lcl);\n}\n\nstatic void show_thread_status_terse_all(struct thread_stat *ts,\n\t\t\t\t\t struct group_run_stats *rs, int ver,\n\t\t\t\t\t struct buf_output *out)\n{\n\tdouble io_u_dist[FIO_IO_U_MAP_NR];\n\tdouble io_u_lat_u[FIO_IO_U_LAT_U_NR];\n\tdouble io_u_lat_m[FIO_IO_U_LAT_M_NR];\n\tdouble usr_cpu, sys_cpu;\n\tint i;\n\n\t/* General Info */\n\tif (ver == 2)\n\t\tlog_buf(out, \"2;%s;%d;%d\", ts->name, ts->groupid, ts->error);\n\telse\n\t\tlog_buf(out, \"%d;%s;%s;%d;%d\", ver, fio_version_string,\n\t\t\tts->name, ts->groupid, ts->error);\n\n\t/* Log Read Status, or mixed if unified_rw_rep = 1 */\n\tshow_ddir_status_terse(ts, rs, DDIR_READ, ver, out);\n\tif (ts->unified_rw_rep != UNIFIED_MIXED) {\n\t\t/* Log Write Status */\n\t\tshow_ddir_status_terse(ts, rs, DDIR_WRITE, ver, out);\n\t\t/* Log Trim Status */\n\t\tif (ver == 2 || ver == 4 || ver == 5)\n\t\t\tshow_ddir_status_terse(ts, rs, DDIR_TRIM, ver, out);\n\t}\n\tif (ts->unified_rw_rep == UNIFIED_BOTH)\n\t\tshow_mixed_ddir_status_terse(ts, rs, ver, out);\n\t/* CPU Usage */\n\tif (ts->total_run_time) {\n\t\tdouble runt = (double) ts->total_run_time;\n\n\t\tusr_cpu = (double) ts->usr_time * 100 / runt;\n\t\tsys_cpu = (double) ts->sys_time * 100 / runt;\n\t} else {\n\t\tusr_cpu = 0;\n\t\tsys_cpu = 0;\n\t}\n\n\tlog_buf(out, \";%f%%;%f%%;%llu;%llu;%llu\", usr_cpu, sys_cpu,\n\t\t\t\t\t\t(unsigned long long) ts->ctx,\n\t\t\t\t\t\t(unsigned long long) ts->majf,\n\t\t\t\t\t\t(unsigned long long) ts->minf);\n\n\t/* Calc % distribution of IO depths, usecond, msecond latency */\n\tstat_calc_dist(ts->io_u_map, ddir_rw_sum(ts->total_io_u), io_u_dist);\n\tstat_calc_lat_nu(ts, io_u_lat_u);\n\tstat_calc_lat_m(ts, io_u_lat_m);\n\n\t/* Only show fixed 7 I/O depth levels*/\n\tlog_buf(out, \";%3.1f%%;%3.1f%%;%3.1f%%;%3.1f%%;%3.1f%%;%3.1f%%;%3.1f%%\",\n\t\t\tio_u_dist[0], io_u_dist[1], io_u_dist[2], io_u_dist[3],\n\t\t\tio_u_dist[4], io_u_dist[5], io_u_dist[6]);\n\n\t/* Microsecond latency */\n\tfor (i = 0; i < FIO_IO_U_LAT_U_NR; i++)\n\t\tlog_buf(out, \";%3.2f%%\", io_u_lat_u[i]);\n\t/* Millisecond latency */\n\tfor (i = 0; i < FIO_IO_U_LAT_M_NR; i++)\n\t\tlog_buf(out, \";%3.2f%%\", io_u_lat_m[i]);\n\n\t/* disk util stats, if any */\n\tif (ver >= 3 && is_running_backend())\n\t\tshow_disk_util(1, NULL, out);\n\n\t/* Additional output if continue_on_error set - default off*/\n\tif (ts->continue_on_error)\n\t\tlog_buf(out, \";%llu;%d\", (unsigned long long) ts->total_err_count, ts->first_error);\n\n\t/* Additional output if description is set */\n\tif (strlen(ts->description)) {\n\t\tif (ver == 2)\n\t\t\tlog_buf(out, \"\\n\");\n\t\tlog_buf(out, \";%s\", ts->description);\n\t}\n\n\tlog_buf(out, \"\\n\");\n}\n\nstatic void json_add_job_opts(struct json_object *root, const char *name,\n\t\t\t      struct flist_head *opt_list)\n{\n\tstruct json_object *dir_object;\n\tstruct flist_head *entry;\n\tstruct print_option *p;\n\n\tif (flist_empty(opt_list))\n\t\treturn;\n\n\tdir_object = json_create_object();\n\tjson_object_add_value_object(root, name, dir_object);\n\n\tflist_for_each(entry, opt_list) {\n\t\tp = flist_entry(entry, struct print_option, list);\n\t\tjson_object_add_value_string(dir_object, p->name, p->value);\n\t}\n}\n\nstatic struct json_object *show_thread_status_json(struct thread_stat *ts,\n\t\t\t\t\t\t   struct group_run_stats *rs,\n\t\t\t\t\t\t   struct flist_head *opt_list)\n{\n\tstruct json_object *root, *tmp;\n\tstruct jobs_eta *je;\n\tdouble io_u_dist[FIO_IO_U_MAP_NR];\n\tdouble io_u_lat_n[FIO_IO_U_LAT_N_NR];\n\tdouble io_u_lat_u[FIO_IO_U_LAT_U_NR];\n\tdouble io_u_lat_m[FIO_IO_U_LAT_M_NR];\n\tdouble usr_cpu, sys_cpu;\n\tint i;\n\tsize_t size;\n\n\troot = json_create_object();\n\tjson_object_add_value_string(root, \"jobname\", ts->name);\n\tjson_object_add_value_int(root, \"groupid\", ts->groupid);\n\tjson_object_add_value_int(root, \"job_start\", ts->job_start);\n\tjson_object_add_value_int(root, \"error\", ts->error);\n\n\t/* ETA Info */\n\tje = get_jobs_eta(true, &size);\n\tif (je) {\n\t\tjson_object_add_value_int(root, \"eta\", je->eta_sec);\n\t\tjson_object_add_value_int(root, \"elapsed\", je->elapsed_sec);\n\t\tfree(je);\n\t}\n\n\tif (opt_list)\n\t\tjson_add_job_opts(root, \"job options\", opt_list);\n\n\tadd_ddir_status_json(ts, rs, DDIR_READ, root);\n\tadd_ddir_status_json(ts, rs, DDIR_WRITE, root);\n\tadd_ddir_status_json(ts, rs, DDIR_TRIM, root);\n\tadd_ddir_status_json(ts, rs, DDIR_SYNC, root);\n\n\tif (ts->unified_rw_rep == UNIFIED_BOTH)\n\t\tadd_mixed_ddir_status_json(ts, rs, root);\n\n\t/* CPU Usage */\n\tif (ts->total_run_time) {\n\t\tdouble runt = (double) ts->total_run_time;\n\n\t\tusr_cpu = (double) ts->usr_time * 100 / runt;\n\t\tsys_cpu = (double) ts->sys_time * 100 / runt;\n\t} else {\n\t\tusr_cpu = 0;\n\t\tsys_cpu = 0;\n\t}\n\tjson_object_add_value_int(root, \"job_runtime\", ts->total_run_time);\n\tjson_object_add_value_float(root, \"usr_cpu\", usr_cpu);\n\tjson_object_add_value_float(root, \"sys_cpu\", sys_cpu);\n\tjson_object_add_value_int(root, \"ctx\", ts->ctx);\n\tjson_object_add_value_int(root, \"majf\", ts->majf);\n\tjson_object_add_value_int(root, \"minf\", ts->minf);\n\n\t/* Calc % distribution of IO depths */\n\tstat_calc_dist(ts->io_u_map, ddir_rw_sum(ts->total_io_u), io_u_dist);\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"iodepth_level\", tmp);\n\t/* Only show fixed 7 I/O depth levels*/\n\tfor (i = 0; i < 7; i++) {\n\t\tchar name[20];\n\t\tif (i < 6)\n\t\t\tsnprintf(name, 20, \"%d\", 1 << i);\n\t\telse\n\t\t\tsnprintf(name, 20, \">=%d\", 1 << i);\n\t\tjson_object_add_value_float(tmp, (const char *)name, io_u_dist[i]);\n\t}\n\n\t/* Calc % distribution of submit IO depths */\n\tstat_calc_dist(ts->io_u_submit, ts->total_submit, io_u_dist);\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"iodepth_submit\", tmp);\n\t/* Only show fixed 7 I/O depth levels*/\n\tfor (i = 0; i < 7; i++) {\n\t\tchar name[20];\n\t\tif (i == 0)\n\t\t\tsnprintf(name, 20, \"0\");\n\t\telse if (i < 6)\n\t\t\tsnprintf(name, 20, \"%d\", 1 << (i+1));\n\t\telse\n\t\t\tsnprintf(name, 20, \">=%d\", 1 << i);\n\t\tjson_object_add_value_float(tmp, (const char *)name, io_u_dist[i]);\n\t}\n\n\t/* Calc % distribution of completion IO depths */\n\tstat_calc_dist(ts->io_u_complete, ts->total_complete, io_u_dist);\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"iodepth_complete\", tmp);\n\t/* Only show fixed 7 I/O depth levels*/\n\tfor (i = 0; i < 7; i++) {\n\t\tchar name[20];\n\t\tif (i == 0)\n\t\t\tsnprintf(name, 20, \"0\");\n\t\telse if (i < 6)\n\t\t\tsnprintf(name, 20, \"%d\", 1 << (i+1));\n\t\telse\n\t\t\tsnprintf(name, 20, \">=%d\", 1 << i);\n\t\tjson_object_add_value_float(tmp, (const char *)name, io_u_dist[i]);\n\t}\n\n\t/* Calc % distribution of nsecond, usecond, msecond latency */\n\tstat_calc_dist(ts->io_u_map, ddir_rw_sum(ts->total_io_u), io_u_dist);\n\tstat_calc_lat_n(ts, io_u_lat_n);\n\tstat_calc_lat_u(ts, io_u_lat_u);\n\tstat_calc_lat_m(ts, io_u_lat_m);\n\n\t/* Nanosecond latency */\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"latency_ns\", tmp);\n\tfor (i = 0; i < FIO_IO_U_LAT_N_NR; i++) {\n\t\tconst char *ranges[] = { \"2\", \"4\", \"10\", \"20\", \"50\", \"100\",\n\t\t\t\t \"250\", \"500\", \"750\", \"1000\", };\n\t\tjson_object_add_value_float(tmp, ranges[i], io_u_lat_n[i]);\n\t}\n\t/* Microsecond latency */\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"latency_us\", tmp);\n\tfor (i = 0; i < FIO_IO_U_LAT_U_NR; i++) {\n\t\tconst char *ranges[] = { \"2\", \"4\", \"10\", \"20\", \"50\", \"100\",\n\t\t\t\t \"250\", \"500\", \"750\", \"1000\", };\n\t\tjson_object_add_value_float(tmp, ranges[i], io_u_lat_u[i]);\n\t}\n\t/* Millisecond latency */\n\ttmp = json_create_object();\n\tjson_object_add_value_object(root, \"latency_ms\", tmp);\n\tfor (i = 0; i < FIO_IO_U_LAT_M_NR; i++) {\n\t\tconst char *ranges[] = { \"2\", \"4\", \"10\", \"20\", \"50\", \"100\",\n\t\t\t\t \"250\", \"500\", \"750\", \"1000\", \"2000\",\n\t\t\t\t \">=2000\", };\n\t\tjson_object_add_value_float(tmp, ranges[i], io_u_lat_m[i]);\n\t}\n\n\t/* Additional output if continue_on_error set - default off*/\n\tif (ts->continue_on_error) {\n\t\tjson_object_add_value_int(root, \"total_err\", ts->total_err_count);\n\t\tjson_object_add_value_int(root, \"first_error\", ts->first_error);\n\t}\n\n\tif (ts->latency_depth) {\n\t\tjson_object_add_value_int(root, \"latency_depth\", ts->latency_depth);\n\t\tjson_object_add_value_int(root, \"latency_target\", ts->latency_target);\n\t\tjson_object_add_value_float(root, \"latency_percentile\", ts->latency_percentile.u.f);\n\t\tjson_object_add_value_int(root, \"latency_window\", ts->latency_window);\n\t}\n\n\t/* Additional output if description is set */\n\tif (strlen(ts->description))\n\t\tjson_object_add_value_string(root, \"desc\", ts->description);\n\n\tif (ts->nr_block_infos) {\n\t\t/* Block error histogram and types */\n\t\tint len;\n\t\tunsigned int *percentiles = NULL;\n\t\tunsigned int block_state_counts[BLOCK_STATE_COUNT];\n\n\t\tlen = calc_block_percentiles(ts->nr_block_infos, ts->block_infos,\n\t\t\t\t\t     ts->percentile_list,\n\t\t\t\t\t     &percentiles, block_state_counts);\n\n\t\tif (len) {\n\t\t\tstruct json_object *block, *percentile_object, *states;\n\t\t\tint state;\n\t\t\tblock = json_create_object();\n\t\t\tjson_object_add_value_object(root, \"block\", block);\n\n\t\t\tpercentile_object = json_create_object();\n\t\t\tjson_object_add_value_object(block, \"percentiles\",\n\t\t\t\t\t\t     percentile_object);\n\t\t\tfor (i = 0; i < len; i++) {\n\t\t\t\tchar buf[20];\n\t\t\t\tsnprintf(buf, sizeof(buf), \"%f\",\n\t\t\t\t\t ts->percentile_list[i].u.f);\n\t\t\t\tjson_object_add_value_int(percentile_object,\n\t\t\t\t\t\t\t  buf,\n\t\t\t\t\t\t\t  percentiles[i]);\n\t\t\t}\n\n\t\t\tstates = json_create_object();\n\t\t\tjson_object_add_value_object(block, \"states\", states);\n\t\t\tfor (state = 0; state < BLOCK_STATE_COUNT; state++) {\n\t\t\t\tjson_object_add_value_int(states,\n\t\t\t\t\tblock_state_names[state],\n\t\t\t\t\tblock_state_counts[state]);\n\t\t\t}\n\t\t\tfree(percentiles);\n\t\t}\n\t}\n\n\tif (ts->ss_dur) {\n\t\tstruct json_object *data;\n\t\tstruct json_array *iops, *bw;\n\t\tint j, k, l;\n\t\tchar ss_buf[64];\n\t\tint intervals = ts->ss_dur / (ss_check_interval / 1000L);\n\n\t\tsnprintf(ss_buf, sizeof(ss_buf), \"%s%s:%f%s\",\n\t\t\tts->ss_state & FIO_SS_IOPS ? \"iops\" : \"bw\",\n\t\t\tts->ss_state & FIO_SS_SLOPE ? \"_slope\" : \"\",\n\t\t\t(float) ts->ss_limit.u.f,\n\t\t\tts->ss_state & FIO_SS_PCT ? \"%\" : \"\");\n\n\t\ttmp = json_create_object();\n\t\tjson_object_add_value_object(root, \"steadystate\", tmp);\n\t\tjson_object_add_value_string(tmp, \"ss\", ss_buf);\n\t\tjson_object_add_value_int(tmp, \"duration\", (int)ts->ss_dur);\n\t\tjson_object_add_value_int(tmp, \"attained\", (ts->ss_state & FIO_SS_ATTAINED) > 0);\n\n\t\tsnprintf(ss_buf, sizeof(ss_buf), \"%f%s\", (float) ts->ss_criterion.u.f,\n\t\t\tts->ss_state & FIO_SS_PCT ? \"%\" : \"\");\n\t\tjson_object_add_value_string(tmp, \"criterion\", ss_buf);\n\t\tjson_object_add_value_float(tmp, \"max_deviation\", ts->ss_deviation.u.f);\n\t\tjson_object_add_value_float(tmp, \"slope\", ts->ss_slope.u.f);\n\n\t\tdata = json_create_object();\n\t\tjson_object_add_value_object(tmp, \"data\", data);\n\t\tbw = json_create_array();\n\t\tiops = json_create_array();\n\n\t\t/*\n\t\t** if ss was attained or the buffer is not full,\n\t\t** ss->head points to the first element in the list.\n\t\t** otherwise it actually points to the second element\n\t\t** in the list\n\t\t*/\n\t\tif ((ts->ss_state & FIO_SS_ATTAINED) || !(ts->ss_state & FIO_SS_BUFFER_FULL))\n\t\t\tj = ts->ss_head;\n\t\telse\n\t\t\tj = ts->ss_head == 0 ? intervals - 1 : ts->ss_head - 1;\n\t\tfor (l = 0; l < intervals; l++) {\n\t\t\tk = (j + l) % intervals;\n\t\t\tjson_array_add_value_int(bw, ts->ss_bw_data[k]);\n\t\t\tjson_array_add_value_int(iops, ts->ss_iops_data[k]);\n\t\t}\n\t\tjson_object_add_value_int(data, \"bw_mean\", steadystate_bw_mean(ts));\n\t\tjson_object_add_value_int(data, \"iops_mean\", steadystate_iops_mean(ts));\n\t\tjson_object_add_value_array(data, \"iops\", iops);\n\t\tjson_object_add_value_array(data, \"bw\", bw);\n\t}\n\n\treturn root;\n}\n\nstatic void show_thread_status_terse(struct thread_stat *ts,\n\t\t\t\t     struct group_run_stats *rs,\n\t\t\t\t     struct buf_output *out)\n{\n\tif (terse_version >= 2 && terse_version <= 5)\n\t\tshow_thread_status_terse_all(ts, rs, terse_version, out);\n\telse\n\t\tlog_err(\"fio: bad terse version!? %d\\n\", terse_version);\n}\n\nstruct json_object *show_thread_status(struct thread_stat *ts,\n\t\t\t\t       struct group_run_stats *rs,\n\t\t\t\t       struct flist_head *opt_list,\n\t\t\t\t       struct buf_output *out)\n{\n\tstruct json_object *ret = NULL;\n\n\tif (output_format & FIO_OUTPUT_TERSE)\n\t\tshow_thread_status_terse(ts, rs,  out);\n\tif (output_format & FIO_OUTPUT_JSON)\n\t\tret = show_thread_status_json(ts, rs, opt_list);\n\tif (output_format & FIO_OUTPUT_NORMAL)\n\t\tshow_thread_status_normal(ts, rs,  out);\n\n\treturn ret;\n}\n\nstatic void __sum_stat(struct io_stat *dst, struct io_stat *src, bool first)\n{\n\tdouble mean, S;\n\n\tdst->min_val = min(dst->min_val, src->min_val);\n\tdst->max_val = max(dst->max_val, src->max_val);\n\n\t/*\n\t * Compute new mean and S after the merge\n\t * <http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n\t *  #Parallel_algorithm>\n\t */\n\tif (first) {\n\t\tmean = src->mean.u.f;\n\t\tS = src->S.u.f;\n\t} else {\n\t\tdouble delta = src->mean.u.f - dst->mean.u.f;\n\n\t\tmean = ((src->mean.u.f * src->samples) +\n\t\t\t(dst->mean.u.f * dst->samples)) /\n\t\t\t(dst->samples + src->samples);\n\n\t\tS =  src->S.u.f + dst->S.u.f + pow(delta, 2.0) *\n\t\t\t(dst->samples * src->samples) /\n\t\t\t(dst->samples + src->samples);\n\t}\n\n\tdst->samples += src->samples;\n\tdst->mean.u.f = mean;\n\tdst->S.u.f = S;\n\n}\n\n/*\n * We sum two kinds of stats - one that is time based, in which case we\n * apply the proper summing technique, and then one that is iops/bw\n * numbers. For group_reporting, we should just add those up, not make\n * them the mean of everything.\n */\nstatic void sum_stat(struct io_stat *dst, struct io_stat *src, bool pure_sum)\n{\n\tbool first = dst->samples == 0;\n\n\tif (src->samples == 0)\n\t\treturn;\n\n\tif (!pure_sum) {\n\t\t__sum_stat(dst, src, first);\n\t\treturn;\n\t}\n\n\tif (first) {\n\t\tdst->min_val = src->min_val;\n\t\tdst->max_val = src->max_val;\n\t\tdst->samples = src->samples;\n\t\tdst->mean.u.f = src->mean.u.f;\n\t\tdst->S.u.f = src->S.u.f;\n\t} else {\n\t\tdst->min_val += src->min_val;\n\t\tdst->max_val += src->max_val;\n\t\tdst->samples += src->samples;\n\t\tdst->mean.u.f += src->mean.u.f;\n\t\tdst->S.u.f += src->S.u.f;\n\t}\n}\n\nvoid sum_group_stats(struct group_run_stats *dst, struct group_run_stats *src)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tif (dst->max_run[i] < src->max_run[i])\n\t\t\tdst->max_run[i] = src->max_run[i];\n\t\tif (dst->min_run[i] && dst->min_run[i] > src->min_run[i])\n\t\t\tdst->min_run[i] = src->min_run[i];\n\t\tif (dst->max_bw[i] < src->max_bw[i])\n\t\t\tdst->max_bw[i] = src->max_bw[i];\n\t\tif (dst->min_bw[i] && dst->min_bw[i] > src->min_bw[i])\n\t\t\tdst->min_bw[i] = src->min_bw[i];\n\n\t\tdst->iobytes[i] += src->iobytes[i];\n\t\tdst->agg[i] += src->agg[i];\n\t}\n\n\tif (!dst->kb_base)\n\t\tdst->kb_base = src->kb_base;\n\tif (!dst->unit_base)\n\t\tdst->unit_base = src->unit_base;\n\tif (!dst->sig_figs)\n\t\tdst->sig_figs = src->sig_figs;\n}\n\n/*\n * Free the clat_prio_stat arrays allocated by alloc_clat_prio_stat_ddir().\n */\nvoid free_clat_prio_stats(struct thread_stat *ts)\n{\n\tenum fio_ddir ddir;\n\n\tif (!ts)\n\t\treturn;\n\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\tsfree(ts->clat_prio[ddir]);\n\t\tts->clat_prio[ddir] = NULL;\n\t\tts->nr_clat_prio[ddir] = 0;\n\t}\n}\n\n/*\n * Allocate a clat_prio_stat array. The array has to be allocated/freed using\n * smalloc/sfree, so that it is accessible by the process/thread summing the\n * thread_stats.\n */\nint alloc_clat_prio_stat_ddir(struct thread_stat *ts, enum fio_ddir ddir,\n\t\t\t      int nr_prios)\n{\n\tstruct clat_prio_stat *clat_prio;\n\tint i;\n\n\tclat_prio = scalloc(nr_prios, sizeof(*ts->clat_prio[ddir]));\n\tif (!clat_prio) {\n\t\tlog_err(\"fio: failed to allocate ts clat data\\n\");\n\t\treturn 1;\n\t}\n\n\tfor (i = 0; i < nr_prios; i++)\n\t\tclat_prio[i].clat_stat.min_val = ULONG_MAX;\n\n\tts->clat_prio[ddir] = clat_prio;\n\tts->nr_clat_prio[ddir] = nr_prios;\n\n\treturn 0;\n}\n\nstatic int grow_clat_prio_stat(struct thread_stat *dst, enum fio_ddir ddir)\n{\n\tint curr_len = dst->nr_clat_prio[ddir];\n\tvoid *new_arr;\n\n\tnew_arr = scalloc(curr_len + 1, sizeof(*dst->clat_prio[ddir]));\n\tif (!new_arr) {\n\t\tlog_err(\"fio: failed to grow clat prio array\\n\");\n\t\treturn 1;\n\t}\n\n\tmemcpy(new_arr, dst->clat_prio[ddir],\n\t       curr_len * sizeof(*dst->clat_prio[ddir]));\n\tsfree(dst->clat_prio[ddir]);\n\n\tdst->clat_prio[ddir] = new_arr;\n\tdst->clat_prio[ddir][curr_len].clat_stat.min_val = ULONG_MAX;\n\tdst->nr_clat_prio[ddir]++;\n\n\treturn 0;\n}\n\nstatic int find_clat_prio_index(struct thread_stat *dst, enum fio_ddir ddir,\n\t\t\t\tuint32_t ioprio)\n{\n\tint i, nr_prios = dst->nr_clat_prio[ddir];\n\n\tfor (i = 0; i < nr_prios; i++) {\n\t\tif (dst->clat_prio[ddir][i].ioprio == ioprio)\n\t\t\treturn i;\n\t}\n\n\treturn -1;\n}\n\nstatic int alloc_or_get_clat_prio_index(struct thread_stat *dst,\n\t\t\t\t\tenum fio_ddir ddir, uint32_t ioprio,\n\t\t\t\t\tint *idx)\n{\n\tint index = find_clat_prio_index(dst, ddir, ioprio);\n\n\tif (index == -1) {\n\t\tindex = dst->nr_clat_prio[ddir];\n\n\t\tif (grow_clat_prio_stat(dst, ddir))\n\t\t\treturn 1;\n\n\t\tdst->clat_prio[ddir][index].ioprio = ioprio;\n\t}\n\n\t*idx = index;\n\n\treturn 0;\n}\n\nstatic int clat_prio_stats_copy(struct thread_stat *dst, struct thread_stat *src,\n\t\t\t\tenum fio_ddir dst_ddir, enum fio_ddir src_ddir)\n{\n\tsize_t sz = sizeof(*src->clat_prio[src_ddir]) *\n\t\tsrc->nr_clat_prio[src_ddir];\n\n\tdst->clat_prio[dst_ddir] = smalloc(sz);\n\tif (!dst->clat_prio[dst_ddir]) {\n\t\tlog_err(\"fio: failed to alloc clat prio array\\n\");\n\t\treturn 1;\n\t}\n\n\tmemcpy(dst->clat_prio[dst_ddir], src->clat_prio[src_ddir], sz);\n\tdst->nr_clat_prio[dst_ddir] = src->nr_clat_prio[src_ddir];\n\n\treturn 0;\n}\n\nstatic int clat_prio_stat_add_samples(struct thread_stat *dst,\n\t\t\t\t      enum fio_ddir dst_ddir, uint32_t ioprio,\n\t\t\t\t      struct io_stat *io_stat,\n\t\t\t\t      uint64_t *io_u_plat)\n{\n\tint i, dst_index;\n\n\tif (!io_stat->samples)\n\t\treturn 0;\n\n\tif (alloc_or_get_clat_prio_index(dst, dst_ddir, ioprio, &dst_index))\n\t\treturn 1;\n\n\tsum_stat(&dst->clat_prio[dst_ddir][dst_index].clat_stat, io_stat,\n\t\t false);\n\n\tfor (i = 0; i < FIO_IO_U_PLAT_NR; i++)\n\t\tdst->clat_prio[dst_ddir][dst_index].io_u_plat[i] += io_u_plat[i];\n\n\treturn 0;\n}\n\nstatic int sum_clat_prio_stats_src_single_prio(struct thread_stat *dst,\n\t\t\t\t\t       struct thread_stat *src,\n\t\t\t\t\t       enum fio_ddir dst_ddir,\n\t\t\t\t\t       enum fio_ddir src_ddir)\n{\n\tstruct io_stat *io_stat;\n\tuint64_t *io_u_plat;\n\n\t/*\n\t * If src ts has no clat_prio_stat array, then all I/Os were submitted\n\t * using src->ioprio. Thus, the global samples in src->clat_stat (or\n\t * src->lat_stat) can be used as the 'per prio' samples for src->ioprio.\n\t */\n\tassert(!src->clat_prio[src_ddir]);\n\tassert(src->nr_clat_prio[src_ddir] == 0);\n\n\tif (src->lat_percentiles) {\n\t\tio_u_plat = src->io_u_plat[FIO_LAT][src_ddir];\n\t\tio_stat = &src->lat_stat[src_ddir];\n\t} else {\n\t\tio_u_plat = src->io_u_plat[FIO_CLAT][src_ddir];\n\t\tio_stat = &src->clat_stat[src_ddir];\n\t}\n\n\treturn clat_prio_stat_add_samples(dst, dst_ddir, src->ioprio, io_stat,\n\t\t\t\t\t  io_u_plat);\n}\n\nstatic int sum_clat_prio_stats_src_multi_prio(struct thread_stat *dst,\n\t\t\t\t\t      struct thread_stat *src,\n\t\t\t\t\t      enum fio_ddir dst_ddir,\n\t\t\t\t\t      enum fio_ddir src_ddir)\n{\n\tint i;\n\n\t/*\n\t * If src ts has a clat_prio_stat array, then there are multiple prios\n\t * in use (i.e. src ts had cmdprio_percentage or cmdprio_bssplit set).\n\t * The samples for the default prio will exist in the src->clat_prio\n\t * array, just like the samples for any other prio.\n\t */\n\tassert(src->clat_prio[src_ddir]);\n\tassert(src->nr_clat_prio[src_ddir]);\n\n\t/* If the dst ts doesn't yet have a clat_prio array, simply memcpy. */\n\tif (!dst->clat_prio[dst_ddir])\n\t\treturn clat_prio_stats_copy(dst, src, dst_ddir, src_ddir);\n\n\t/* The dst ts already has a clat_prio_array, add src stats into it. */\n\tfor (i = 0; i < src->nr_clat_prio[src_ddir]; i++) {\n\t\tstruct io_stat *io_stat = &src->clat_prio[src_ddir][i].clat_stat;\n\t\tuint64_t *io_u_plat = src->clat_prio[src_ddir][i].io_u_plat;\n\t\tuint32_t ioprio = src->clat_prio[src_ddir][i].ioprio;\n\n\t\tif (clat_prio_stat_add_samples(dst, dst_ddir, ioprio, io_stat, io_u_plat))\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic int sum_clat_prio_stats(struct thread_stat *dst, struct thread_stat *src,\n\t\t\t       enum fio_ddir dst_ddir, enum fio_ddir src_ddir)\n{\n\tif (dst->disable_prio_stat)\n\t\treturn 0;\n\n\tif (!src->clat_prio[src_ddir])\n\t\treturn sum_clat_prio_stats_src_single_prio(dst, src, dst_ddir,\n\t\t\t\t\t\t\t   src_ddir);\n\n\treturn sum_clat_prio_stats_src_multi_prio(dst, src, dst_ddir, src_ddir);\n}\n\nvoid sum_thread_stats(struct thread_stat *dst, struct thread_stat *src)\n{\n\tint k, l, m;\n\n\tfor (l = 0; l < DDIR_RWDIR_CNT; l++) {\n\t\tif (dst->unified_rw_rep != UNIFIED_MIXED) {\n\t\t\tsum_stat(&dst->clat_stat[l], &src->clat_stat[l], false);\n\t\t\tsum_stat(&dst->slat_stat[l], &src->slat_stat[l], false);\n\t\t\tsum_stat(&dst->lat_stat[l], &src->lat_stat[l], false);\n\t\t\tsum_stat(&dst->bw_stat[l], &src->bw_stat[l], true);\n\t\t\tsum_stat(&dst->iops_stat[l], &src->iops_stat[l], true);\n\t\t\tsum_clat_prio_stats(dst, src, l, l);\n\n\t\t\tdst->io_bytes[l] += src->io_bytes[l];\n\n\t\t\tif (dst->runtime[l] < src->runtime[l])\n\t\t\t\tdst->runtime[l] = src->runtime[l];\n\t\t} else {\n\t\t\tsum_stat(&dst->clat_stat[0], &src->clat_stat[l], false);\n\t\t\tsum_stat(&dst->slat_stat[0], &src->slat_stat[l], false);\n\t\t\tsum_stat(&dst->lat_stat[0], &src->lat_stat[l], false);\n\t\t\tsum_stat(&dst->bw_stat[0], &src->bw_stat[l], true);\n\t\t\tsum_stat(&dst->iops_stat[0], &src->iops_stat[l], true);\n\t\t\tsum_clat_prio_stats(dst, src, 0, l);\n\n\t\t\tdst->io_bytes[0] += src->io_bytes[l];\n\n\t\t\tif (dst->runtime[0] < src->runtime[l])\n\t\t\t\tdst->runtime[0] = src->runtime[l];\n\t\t}\n\t}\n\n\tsum_stat(&dst->sync_stat, &src->sync_stat, false);\n\tdst->usr_time += src->usr_time;\n\tdst->sys_time += src->sys_time;\n\tdst->ctx += src->ctx;\n\tdst->majf += src->majf;\n\tdst->minf += src->minf;\n\n\tfor (k = 0; k < FIO_IO_U_MAP_NR; k++) {\n\t\tdst->io_u_map[k] += src->io_u_map[k];\n\t\tdst->io_u_submit[k] += src->io_u_submit[k];\n\t\tdst->io_u_complete[k] += src->io_u_complete[k];\n\t}\n\n\tfor (k = 0; k < FIO_IO_U_LAT_N_NR; k++)\n\t\tdst->io_u_lat_n[k] += src->io_u_lat_n[k];\n\tfor (k = 0; k < FIO_IO_U_LAT_U_NR; k++)\n\t\tdst->io_u_lat_u[k] += src->io_u_lat_u[k];\n\tfor (k = 0; k < FIO_IO_U_LAT_M_NR; k++)\n\t\tdst->io_u_lat_m[k] += src->io_u_lat_m[k];\n\n\tfor (k = 0; k < DDIR_RWDIR_CNT; k++) {\n\t\tif (dst->unified_rw_rep != UNIFIED_MIXED) {\n\t\t\tdst->total_io_u[k] += src->total_io_u[k];\n\t\t\tdst->short_io_u[k] += src->short_io_u[k];\n\t\t\tdst->drop_io_u[k] += src->drop_io_u[k];\n\t\t} else {\n\t\t\tdst->total_io_u[0] += src->total_io_u[k];\n\t\t\tdst->short_io_u[0] += src->short_io_u[k];\n\t\t\tdst->drop_io_u[0] += src->drop_io_u[k];\n\t\t}\n\t}\n\n\tdst->total_io_u[DDIR_SYNC] += src->total_io_u[DDIR_SYNC];\n\n\tfor (k = 0; k < FIO_LAT_CNT; k++)\n\t\tfor (l = 0; l < DDIR_RWDIR_CNT; l++)\n\t\t\tfor (m = 0; m < FIO_IO_U_PLAT_NR; m++)\n\t\t\t\tif (dst->unified_rw_rep != UNIFIED_MIXED)\n\t\t\t\t\tdst->io_u_plat[k][l][m] += src->io_u_plat[k][l][m];\n\t\t\t\telse\n\t\t\t\t\tdst->io_u_plat[k][0][m] += src->io_u_plat[k][l][m];\n\n\tfor (k = 0; k < FIO_IO_U_PLAT_NR; k++)\n\t\tdst->io_u_sync_plat[k] += src->io_u_sync_plat[k];\n\n\tdst->total_run_time += src->total_run_time;\n\tdst->total_submit += src->total_submit;\n\tdst->total_complete += src->total_complete;\n\tdst->nr_zone_resets += src->nr_zone_resets;\n\tdst->cachehit += src->cachehit;\n\tdst->cachemiss += src->cachemiss;\n}\n\nvoid init_group_run_stat(struct group_run_stats *gs)\n{\n\tint i;\n\tmemset(gs, 0, sizeof(*gs));\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\tgs->min_bw[i] = gs->min_run[i] = ~0UL;\n}\n\nvoid init_thread_stat_min_vals(struct thread_stat *ts)\n{\n\tint i;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tts->clat_stat[i].min_val = ULONG_MAX;\n\t\tts->slat_stat[i].min_val = ULONG_MAX;\n\t\tts->lat_stat[i].min_val = ULONG_MAX;\n\t\tts->bw_stat[i].min_val = ULONG_MAX;\n\t\tts->iops_stat[i].min_val = ULONG_MAX;\n\t}\n\tts->sync_stat.min_val = ULONG_MAX;\n}\n\nvoid init_thread_stat(struct thread_stat *ts)\n{\n\tmemset(ts, 0, sizeof(*ts));\n\n\tinit_thread_stat_min_vals(ts);\n\tts->groupid = -1;\n}\n\nstatic void init_per_prio_stats(struct thread_stat *threadstats, int nr_ts)\n{\n\tstruct thread_stat *ts;\n\tint i, j, last_ts, idx;\n\tenum fio_ddir ddir;\n\n\tj = 0;\n\tlast_ts = -1;\n\tidx = 0;\n\n\t/*\n\t * Loop through all tds, if a td requires per prio stats, temporarily\n\t * store a 1 in ts->disable_prio_stat, and then do an additional\n\t * loop at the end where we invert the ts->disable_prio_stat values.\n\t */\n\tfor_each_td(td) {\n\t\tif (!td->o.stats)\n\t\t\tcontinue;\n\t\tif (idx &&\n\t\t    (!td->o.group_reporting ||\n\t\t     (td->o.group_reporting && last_ts != td->groupid))) {\n\t\t\tidx = 0;\n\t\t\tj++;\n\t\t}\n\n\t\tlast_ts = td->groupid;\n\t\tts = &threadstats[j];\n\n\t\t/* idx == 0 means first td in group, or td is not in a group. */\n\t\tif (idx == 0)\n\t\t\tts->ioprio = td->ioprio;\n\t\telse if (td->ioprio != ts->ioprio)\n\t\t\tts->disable_prio_stat = 1;\n\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\tif (td->ts.clat_prio[ddir]) {\n\t\t\t\tts->disable_prio_stat = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tidx++;\n\t} end_for_each();\n\n\t/* Loop through all dst threadstats and fixup the values. */\n\tfor (i = 0; i < nr_ts; i++) {\n\t\tts = &threadstats[i];\n\t\tts->disable_prio_stat = !ts->disable_prio_stat;\n\t}\n}\n\nvoid __show_run_stats(void)\n{\n\tstruct group_run_stats *runstats, *rs;\n\tstruct thread_stat *threadstats, *ts;\n\tint i, j, k, nr_ts, last_ts, idx;\n\tbool kb_base_warned = false;\n\tbool unit_base_warned = false;\n\tstruct json_object *root = NULL;\n\tstruct json_array *array = NULL;\n\tstruct buf_output output[FIO_OUTPUT_NR];\n\tstruct flist_head **opt_lists;\n\n\trunstats = malloc(sizeof(struct group_run_stats) * (groupid + 1));\n\n\tfor (i = 0; i < groupid + 1; i++)\n\t\tinit_group_run_stat(&runstats[i]);\n\n\t/*\n\t * find out how many threads stats we need. if group reporting isn't\n\t * enabled, it's one-per-td.\n\t */\n\tnr_ts = 0;\n\tlast_ts = -1;\n\tfor_each_td(td) {\n\t\tif (!td->o.group_reporting) {\n\t\t\tnr_ts++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (last_ts == td->groupid)\n\t\t\tcontinue;\n\t\tif (!td->o.stats)\n\t\t\tcontinue;\n\n\t\tlast_ts = td->groupid;\n\t\tnr_ts++;\n\t} end_for_each();\n\n\tthreadstats = malloc(nr_ts * sizeof(struct thread_stat));\n\topt_lists = malloc(nr_ts * sizeof(struct flist_head *));\n\n\tfor (i = 0; i < nr_ts; i++) {\n\t\tinit_thread_stat(&threadstats[i]);\n\t\topt_lists[i] = NULL;\n\t}\n\n\tinit_per_prio_stats(threadstats, nr_ts);\n\n\tj = 0;\n\tlast_ts = -1;\n\tidx = 0;\n\tfor_each_td(td) {\n\t\tif (!td->o.stats)\n\t\t\tcontinue;\n\t\tif (idx && (!td->o.group_reporting ||\n\t\t    (td->o.group_reporting && last_ts != td->groupid))) {\n\t\t\tidx = 0;\n\t\t\tj++;\n\t\t}\n\n\t\tlast_ts = td->groupid;\n\n\t\tts = &threadstats[j];\n\n\t\tts->clat_percentiles = td->o.clat_percentiles;\n\t\tts->lat_percentiles = td->o.lat_percentiles;\n\t\tts->slat_percentiles = td->o.slat_percentiles;\n\t\tts->percentile_precision = td->o.percentile_precision;\n\t\tmemcpy(ts->percentile_list, td->o.percentile_list, sizeof(td->o.percentile_list));\n\t\topt_lists[j] = &td->opt_list;\n\n\t\tidx++;\n\n\t\tif (ts->groupid == -1) {\n\t\t\t/*\n\t\t\t * These are per-group shared already\n\t\t\t */\n\t\t\tsnprintf(ts->name, sizeof(ts->name), \"%s\", td->o.name);\n\t\t\tif (td->o.description)\n\t\t\t\tsnprintf(ts->description,\n\t\t\t\t\t sizeof(ts->description), \"%s\",\n\t\t\t\t\t td->o.description);\n\t\t\telse\n\t\t\t\tmemset(ts->description, 0, FIO_JOBDESC_SIZE);\n\n\t\t\t/*\n\t\t\t * If multiple entries in this group, this is\n\t\t\t * the first member.\n\t\t\t */\n\t\t\tts->thread_number = td->thread_number;\n\t\t\tts->groupid = td->groupid;\n\t\t\tts->job_start = td->job_start;\n\n\t\t\t/*\n\t\t\t * first pid in group, not very useful...\n\t\t\t */\n\t\t\tts->pid = td->pid;\n\n\t\t\tts->kb_base = td->o.kb_base;\n\t\t\tts->unit_base = td->o.unit_base;\n\t\t\tts->sig_figs = td->o.sig_figs;\n\t\t\tts->unified_rw_rep = td->o.unified_rw_rep;\n\t\t} else if (ts->kb_base != td->o.kb_base && !kb_base_warned) {\n\t\t\tlog_info(\"fio: kb_base differs for jobs in group, using\"\n\t\t\t\t \" %u as the base\\n\", ts->kb_base);\n\t\t\tkb_base_warned = true;\n\t\t} else if (ts->unit_base != td->o.unit_base && !unit_base_warned) {\n\t\t\tlog_info(\"fio: unit_base differs for jobs in group, using\"\n\t\t\t\t \" %u as the base\\n\", ts->unit_base);\n\t\t\tunit_base_warned = true;\n\t\t}\n\n\t\tts->continue_on_error = td->o.continue_on_error;\n\t\tts->total_err_count += td->total_err_count;\n\t\tts->first_error = td->first_error;\n\t\tif (!ts->error) {\n\t\t\tif (!td->error && td->o.continue_on_error &&\n\t\t\t    td->first_error) {\n\t\t\t\tts->error = td->first_error;\n\t\t\t\tsnprintf(ts->verror, sizeof(ts->verror), \"%s\",\n\t\t\t\t\t td->verror);\n\t\t\t} else  if (td->error) {\n\t\t\t\tts->error = td->error;\n\t\t\t\tsnprintf(ts->verror, sizeof(ts->verror), \"%s\",\n\t\t\t\t\t td->verror);\n\t\t\t}\n\t\t}\n\n\t\tts->latency_depth = td->latency_qd;\n\t\tts->latency_target = td->o.latency_target;\n\t\tts->latency_percentile = td->o.latency_percentile;\n\t\tts->latency_window = td->o.latency_window;\n\n\t\tts->nr_block_infos = td->ts.nr_block_infos;\n\t\tfor (k = 0; k < ts->nr_block_infos; k++)\n\t\t\tts->block_infos[k] = td->ts.block_infos[k];\n\n\t\tsum_thread_stats(ts, &td->ts);\n\n\t\tts->members++;\n\n\t\tif (td->o.ss_dur) {\n\t\t\tts->ss_state = td->ss.state;\n\t\t\tts->ss_dur = td->ss.dur;\n\t\t\tts->ss_head = td->ss.head;\n\t\t\tts->ss_bw_data = td->ss.bw_data;\n\t\t\tts->ss_iops_data = td->ss.iops_data;\n\t\t\tts->ss_limit.u.f = td->ss.limit;\n\t\t\tts->ss_slope.u.f = td->ss.slope;\n\t\t\tts->ss_deviation.u.f = td->ss.deviation;\n\t\t\tts->ss_criterion.u.f = td->ss.criterion;\n\t\t}\n\t\telse\n\t\t\tts->ss_dur = ts->ss_state = 0;\n\t} end_for_each();\n\n\tfor (i = 0; i < nr_ts; i++) {\n\t\tunsigned long long bw;\n\n\t\tts = &threadstats[i];\n\t\tif (ts->groupid == -1)\n\t\t\tcontinue;\n\t\trs = &runstats[ts->groupid];\n\t\trs->kb_base = ts->kb_base;\n\t\trs->unit_base = ts->unit_base;\n\t\trs->sig_figs = ts->sig_figs;\n\t\trs->unified_rw_rep |= ts->unified_rw_rep;\n\n\t\tfor (j = 0; j < DDIR_RWDIR_CNT; j++) {\n\t\t\tif (!ts->runtime[j])\n\t\t\t\tcontinue;\n\t\t\tif (ts->runtime[j] < rs->min_run[j] || !rs->min_run[j])\n\t\t\t\trs->min_run[j] = ts->runtime[j];\n\t\t\tif (ts->runtime[j] > rs->max_run[j])\n\t\t\t\trs->max_run[j] = ts->runtime[j];\n\n\t\t\tbw = 0;\n\t\t\tif (ts->runtime[j])\n\t\t\t\tbw = ts->io_bytes[j] * 1000 / ts->runtime[j];\n\t\t\tif (bw < rs->min_bw[j])\n\t\t\t\trs->min_bw[j] = bw;\n\t\t\tif (bw > rs->max_bw[j])\n\t\t\t\trs->max_bw[j] = bw;\n\n\t\t\trs->iobytes[j] += ts->io_bytes[j];\n\t\t}\n\t}\n\n\tfor (i = 0; i < groupid + 1; i++) {\n\t\tenum fio_ddir ddir;\n\n\t\trs = &runstats[i];\n\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\tif (rs->max_run[ddir])\n\t\t\t\trs->agg[ddir] = (rs->iobytes[ddir] * 1000) /\n\t\t\t\t\t\trs->max_run[ddir];\n\t\t}\n\t}\n\n\tfor (i = 0; i < FIO_OUTPUT_NR; i++)\n\t\tbuf_output_init(&output[i]);\n\n\t/*\n\t * don't overwrite last signal output\n\t */\n\tif (output_format & FIO_OUTPUT_NORMAL)\n\t\tlog_buf(&output[__FIO_OUTPUT_NORMAL], \"\\n\");\n\tif (output_format & FIO_OUTPUT_JSON) {\n\t\tstruct thread_data *global;\n\t\tchar time_buf[32];\n\t\tstruct timeval now;\n\t\tunsigned long long ms_since_epoch;\n\t\ttime_t tv_sec;\n\n\t\tgettimeofday(&now, NULL);\n\t\tms_since_epoch = (unsigned long long)(now.tv_sec) * 1000 +\n\t\t                 (unsigned long long)(now.tv_usec) / 1000;\n\n\t\ttv_sec = now.tv_sec;\n\t\tos_ctime_r(&tv_sec, time_buf, sizeof(time_buf));\n\t\tif (time_buf[strlen(time_buf) - 1] == '\\n')\n\t\t\ttime_buf[strlen(time_buf) - 1] = '\\0';\n\n\t\troot = json_create_object();\n\t\tjson_object_add_value_string(root, \"fio version\", fio_version_string);\n\t\tjson_object_add_value_int(root, \"timestamp\", now.tv_sec);\n\t\tjson_object_add_value_int(root, \"timestamp_ms\", ms_since_epoch);\n\t\tjson_object_add_value_string(root, \"time\", time_buf);\n\t\tglobal = get_global_options();\n\t\tjson_add_job_opts(root, \"global options\", &global->opt_list);\n\t\tarray = json_create_array();\n\t\tjson_object_add_value_array(root, \"jobs\", array);\n\t}\n\n\tif (is_backend)\n\t\tfio_server_send_job_options(&get_global_options()->opt_list, -1U);\n\n\tfor (i = 0; i < nr_ts; i++) {\n\t\tts = &threadstats[i];\n\t\trs = &runstats[ts->groupid];\n\n\t\tif (is_backend) {\n\t\t\tfio_server_send_job_options(opt_lists[i], i);\n\t\t\tfio_server_send_ts(ts, rs);\n\t\t} else {\n\t\t\tif (output_format & FIO_OUTPUT_TERSE)\n\t\t\t\tshow_thread_status_terse(ts, rs, &output[__FIO_OUTPUT_TERSE]);\n\t\t\tif (output_format & FIO_OUTPUT_JSON) {\n\t\t\t\tstruct json_object *tmp = show_thread_status_json(ts, rs, opt_lists[i]);\n\t\t\t\tjson_array_add_value_object(array, tmp);\n\t\t\t}\n\t\t\tif (output_format & FIO_OUTPUT_NORMAL)\n\t\t\t\tshow_thread_status_normal(ts, rs, &output[__FIO_OUTPUT_NORMAL]);\n\t\t}\n\t}\n\tif (!is_backend && (output_format & FIO_OUTPUT_JSON)) {\n\t\t/* disk util stats, if any */\n\t\tshow_disk_util(1, root, &output[__FIO_OUTPUT_JSON]);\n\n\t\tshow_idle_prof_stats(FIO_OUTPUT_JSON, root, &output[__FIO_OUTPUT_JSON]);\n\n\t\tjson_print_object(root, &output[__FIO_OUTPUT_JSON]);\n\t\tlog_buf(&output[__FIO_OUTPUT_JSON], \"\\n\");\n\t\tjson_free_object(root);\n\t}\n\n\tfor (i = 0; i < groupid + 1; i++) {\n\t\trs = &runstats[i];\n\n\t\trs->groupid = i;\n\t\tif (is_backend)\n\t\t\tfio_server_send_gs(rs);\n\t\telse if (output_format & FIO_OUTPUT_NORMAL)\n\t\t\tshow_group_stats(rs, &output[__FIO_OUTPUT_NORMAL]);\n\t}\n\n\tif (is_backend)\n\t\tfio_server_send_du();\n\telse if (output_format & FIO_OUTPUT_NORMAL) {\n\t\tshow_disk_util(0, NULL, &output[__FIO_OUTPUT_NORMAL]);\n\t\tshow_idle_prof_stats(FIO_OUTPUT_NORMAL, NULL, &output[__FIO_OUTPUT_NORMAL]);\n\t}\n\n\tfor (i = 0; i < FIO_OUTPUT_NR; i++) {\n\t\tstruct buf_output *out = &output[i];\n\n\t\tlog_info_buf(out->buf, out->buflen);\n\t\tbuf_output_free(out);\n\t}\n\n\tfio_idle_prof_cleanup();\n\n\tlog_info_flush();\n\tfree(runstats);\n\n\t/* free arrays allocated by sum_thread_stats(), if any */\n\tfor (i = 0; i < nr_ts; i++) {\n\t\tts = &threadstats[i];\n\t\tfree_clat_prio_stats(ts);\n\t}\n\tfree(threadstats);\n\tfree(opt_lists);\n}\n\nint __show_running_run_stats(void)\n{\n\tunsigned long long *rt;\n\tstruct timespec ts;\n\n\tfio_sem_down(stat_sem);\n\n\trt = malloc(thread_number * sizeof(unsigned long long));\n\tfio_gettime(&ts, NULL);\n\n\tfor_each_td(td) {\n\t\tif (td->runstate >= TD_EXITED)\n\t\t\tcontinue;\n\n\t\ttd->update_rusage = 1;\n\t\tfor_each_rw_ddir(ddir) {\n\t\t\ttd->ts.io_bytes[ddir] = td->io_bytes[ddir];\n\t\t}\n\t\ttd->ts.total_run_time = mtime_since(&td->epoch, &ts);\n\n\t\trt[__td_index] = mtime_since(&td->start, &ts);\n\t\tif (td_read(td) && td->ts.io_bytes[DDIR_READ])\n\t\t\ttd->ts.runtime[DDIR_READ] += rt[__td_index];\n\t\tif (td_write(td) && td->ts.io_bytes[DDIR_WRITE])\n\t\t\ttd->ts.runtime[DDIR_WRITE] += rt[__td_index];\n\t\tif (td_trim(td) && td->ts.io_bytes[DDIR_TRIM])\n\t\t\ttd->ts.runtime[DDIR_TRIM] += rt[__td_index];\n\t} end_for_each();\n\n\tfor_each_td(td) {\n\t\tif (td->runstate >= TD_EXITED)\n\t\t\tcontinue;\n\t\tif (td->rusage_sem) {\n\t\t\ttd->update_rusage = 1;\n\t\t\tfio_sem_down(td->rusage_sem);\n\t\t}\n\t\ttd->update_rusage = 0;\n\t} end_for_each();\n\n\t__show_run_stats();\n\n\tfor_each_td(td) {\n\t\tif (td->runstate >= TD_EXITED)\n\t\t\tcontinue;\n\n\t\tif (td_read(td) && td->ts.io_bytes[DDIR_READ])\n\t\t\ttd->ts.runtime[DDIR_READ] -= rt[__td_index];\n\t\tif (td_write(td) && td->ts.io_bytes[DDIR_WRITE])\n\t\t\ttd->ts.runtime[DDIR_WRITE] -= rt[__td_index];\n\t\tif (td_trim(td) && td->ts.io_bytes[DDIR_TRIM])\n\t\t\ttd->ts.runtime[DDIR_TRIM] -= rt[__td_index];\n\t} end_for_each();\n\n\tfree(rt);\n\tfio_sem_up(stat_sem);\n\n\treturn 0;\n}\n\nstatic bool status_file_disabled;\n\n#define FIO_STATUS_FILE\t\t\"fio-dump-status\"\n\nstatic int check_status_file(void)\n{\n\tstruct stat sb;\n\tconst char *temp_dir;\n\tchar fio_status_file_path[PATH_MAX];\n\n\tif (status_file_disabled)\n\t\treturn 0;\n\n\ttemp_dir = getenv(\"TMPDIR\");\n\tif (temp_dir == NULL) {\n\t\ttemp_dir = getenv(\"TEMP\");\n\t\tif (temp_dir && strlen(temp_dir) >= PATH_MAX)\n\t\t\ttemp_dir = NULL;\n\t}\n\tif (temp_dir == NULL)\n\t\ttemp_dir = \"/tmp\";\n#ifdef __COVERITY__\n\t__coverity_tainted_data_sanitize__(temp_dir);\n#endif\n\n\tsnprintf(fio_status_file_path, sizeof(fio_status_file_path), \"%s/%s\", temp_dir, FIO_STATUS_FILE);\n\n\tif (stat(fio_status_file_path, &sb))\n\t\treturn 0;\n\n\tif (unlink(fio_status_file_path) < 0) {\n\t\tlog_err(\"fio: failed to unlink %s: %s\\n\", fio_status_file_path,\n\t\t\t\t\t\t\tstrerror(errno));\n\t\tlog_err(\"fio: disabling status file updates\\n\");\n\t\tstatus_file_disabled = true;\n\t}\n\n\treturn 1;\n}\n\nvoid check_for_running_stats(void)\n{\n\tif (check_status_file()) {\n\t\tshow_running_run_stats();\n\t\treturn;\n\t}\n}\n\nstatic inline void add_stat_sample(struct io_stat *is, unsigned long long data)\n{\n\tdouble val = data;\n\tdouble delta;\n\n\tif (data > is->max_val)\n\t\tis->max_val = data;\n\tif (data < is->min_val)\n\t\tis->min_val = data;\n\n\tdelta = val - is->mean.u.f;\n\tif (delta) {\n\t\tis->mean.u.f += delta / (is->samples + 1.0);\n\t\tis->S.u.f += delta * (val - is->mean.u.f);\n\t}\n\n\tis->samples++;\n}\n\nstatic inline void add_stat_prio_sample(struct clat_prio_stat *clat_prio,\n\t\t\t\t\tunsigned short clat_prio_index,\n\t\t\t\t\tunsigned long long nsec)\n{\n\tif (clat_prio)\n\t\tadd_stat_sample(&clat_prio[clat_prio_index].clat_stat, nsec);\n}\n\n/*\n * Return a struct io_logs, which is added to the tail of the log\n * list for 'iolog'.\n */\nstatic struct io_logs *get_new_log(struct io_log *iolog)\n{\n\tsize_t new_samples;\n\tstruct io_logs *cur_log;\n\n\t/*\n\t * Cap the size at MAX_LOG_ENTRIES, so we don't keep doubling\n\t * forever\n\t */\n\tif (!iolog->cur_log_max) {\n\t\tif (iolog->td)\n\t\t\tnew_samples = iolog->td->o.log_entries;\n\t\telse\n\t\t\tnew_samples = DEF_LOG_ENTRIES;\n\t} else {\n\t\tnew_samples = iolog->cur_log_max * 2;\n\t\tif (new_samples > MAX_LOG_ENTRIES)\n\t\t\tnew_samples = MAX_LOG_ENTRIES;\n\t}\n\n\tcur_log = smalloc(sizeof(*cur_log));\n\tif (cur_log) {\n\t\tINIT_FLIST_HEAD(&cur_log->list);\n\t\tcur_log->log = calloc(new_samples, log_entry_sz(iolog));\n\t\tif (cur_log->log) {\n\t\t\tcur_log->nr_samples = 0;\n\t\t\tcur_log->max_samples = new_samples;\n\t\t\tflist_add_tail(&cur_log->list, &iolog->io_logs);\n\t\t\tiolog->cur_log_max = new_samples;\n\t\t\treturn cur_log;\n\t\t}\n\t\tsfree(cur_log);\n\t}\n\n\treturn NULL;\n}\n\n/*\n * Add and return a new log chunk, or return current log if big enough\n */\nstatic struct io_logs *regrow_log(struct io_log *iolog)\n{\n\tstruct io_logs *cur_log;\n\tint i;\n\n\tif (!iolog || iolog->disabled)\n\t\tgoto disable;\n\n\tcur_log = iolog_cur_log(iolog);\n\tif (!cur_log) {\n\t\tcur_log = get_new_log(iolog);\n\t\tif (!cur_log)\n\t\t\treturn NULL;\n\t}\n\n\tif (cur_log->nr_samples < cur_log->max_samples)\n\t\treturn cur_log;\n\n\t/*\n\t * No room for a new sample. If we're compressing on the fly, flush\n\t * out the current chunk\n\t */\n\tif (iolog->log_gz) {\n\t\tif (iolog_cur_flush(iolog, cur_log)) {\n\t\t\tlog_err(\"fio: failed flushing iolog! Will stop logging.\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/*\n\t * Get a new log array, and add to our list\n\t */\n\tcur_log = get_new_log(iolog);\n\tif (!cur_log) {\n\t\tlog_err(\"fio: failed extending iolog! Will stop logging.\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!iolog->pending || !iolog->pending->nr_samples)\n\t\treturn cur_log;\n\n\t/*\n\t * Flush pending items to new log\n\t */\n\tfor (i = 0; i < iolog->pending->nr_samples; i++) {\n\t\tstruct io_sample *src, *dst;\n\n\t\tsrc = get_sample(iolog, iolog->pending, i);\n\t\tdst = get_sample(iolog, cur_log, i);\n\t\tmemcpy(dst, src, log_entry_sz(iolog));\n\t}\n\tcur_log->nr_samples = iolog->pending->nr_samples;\n\n\tiolog->pending->nr_samples = 0;\n\treturn cur_log;\ndisable:\n\tif (iolog)\n\t\tiolog->disabled = true;\n\treturn NULL;\n}\n\nvoid regrow_logs(struct thread_data *td)\n{\n\tregrow_log(td->slat_log);\n\tregrow_log(td->clat_log);\n\tregrow_log(td->clat_hist_log);\n\tregrow_log(td->lat_log);\n\tregrow_log(td->bw_log);\n\tregrow_log(td->iops_log);\n\ttd->flags &= ~TD_F_REGROW_LOGS;\n}\n\nvoid regrow_agg_logs(void)\n{\n\tenum fio_ddir ddir;\n\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++)\n\t\tregrow_log(agg_io_log[ddir]);\n}\n\nstatic struct io_logs *get_cur_log(struct io_log *iolog)\n{\n\tstruct io_logs *cur_log;\n\n\tcur_log = iolog_cur_log(iolog);\n\tif (!cur_log) {\n\t\tcur_log = get_new_log(iolog);\n\t\tif (!cur_log)\n\t\t\treturn NULL;\n\t}\n\n\tif (cur_log->nr_samples < cur_log->max_samples)\n\t\treturn cur_log;\n\n\t/*\n\t * Out of space. If we're in IO offload mode, or we're not doing\n\t * per unit logging (hence logging happens outside of the IO thread\n\t * as well), add a new log chunk inline. If we're doing inline\n\t * submissions, flag 'td' as needing a log regrow and we'll take\n\t * care of it on the submission side.\n\t */\n\tif ((iolog->td && iolog->td->o.io_submit_mode == IO_MODE_OFFLOAD) ||\n\t    !per_unit_log(iolog))\n\t\treturn regrow_log(iolog);\n\n\tif (iolog->td)\n\t\tiolog->td->flags |= TD_F_REGROW_LOGS;\n\tif (iolog->pending)\n\t\tassert(iolog->pending->nr_samples < iolog->pending->max_samples);\n\treturn iolog->pending;\n}\n\nstatic void __add_log_sample(struct io_log *iolog, unsigned long t,\n\t\t\t     struct log_sample *sample)\n{\n\tstruct io_logs *cur_log;\n\n\tif (iolog->disabled)\n\t\treturn;\n\tif (flist_empty(&iolog->io_logs))\n\t\tiolog->avg_last[sample->ddir] = t;\n\n\tcur_log = get_cur_log(iolog);\n\tif (cur_log) {\n\t\tstruct io_sample *s;\n\n\t\ts = get_sample(iolog, cur_log, cur_log->nr_samples);\n\n\t\ts->data = sample->data;\n\t\ts->time = t;\n\t\tif (iolog->td && iolog->td->o.log_alternate_epoch)\n\t\t\ts->time += iolog->td->alternate_epoch;\n\t\tio_sample_set_ddir(iolog, s, sample->ddir);\n\t\ts->bs = sample->bs;\n\t\ts->priority = sample->priority;\n\n\t\tif (iolog->log_offset)\n\t\t\ts->aux[IOS_AUX_OFFSET_INDEX] = sample->offset;\n\n\t\tif (iolog->log_issue_time)\n\t\t\ts->aux[IOS_AUX_ISSUE_TIME_INDEX] = sample->issue_time;\n\n\t\tcur_log->nr_samples++;\n\t\treturn;\n\t}\n\n\tiolog->disabled = true;\n}\n\nstatic inline void reset_io_stat(struct io_stat *ios)\n{\n\tios->min_val = -1ULL;\n\tios->max_val = ios->samples = 0;\n\tios->mean.u.f = ios->S.u.f = 0;\n}\n\nstatic inline void reset_io_u_plat(uint64_t *io_u_plat)\n{\n\tint i;\n\n\tfor (i = 0; i < FIO_IO_U_PLAT_NR; i++)\n\t\tio_u_plat[i] = 0;\n}\n\nstatic inline void reset_clat_prio_stats(struct thread_stat *ts)\n{\n\tenum fio_ddir ddir;\n\tint i;\n\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\tif (!ts->clat_prio[ddir])\n\t\t\tcontinue;\n\n\t\tfor (i = 0; i < ts->nr_clat_prio[ddir]; i++) {\n\t\t\treset_io_stat(&ts->clat_prio[ddir][i].clat_stat);\n\t\t\treset_io_u_plat(ts->clat_prio[ddir][i].io_u_plat);\n\t\t}\n\t}\n}\n\nvoid reset_io_stats(struct thread_data *td)\n{\n\tstruct thread_stat *ts = &td->ts;\n\tint i, j;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\treset_io_stat(&ts->clat_stat[i]);\n\t\treset_io_stat(&ts->slat_stat[i]);\n\t\treset_io_stat(&ts->lat_stat[i]);\n\t\treset_io_stat(&ts->bw_stat[i]);\n\t\treset_io_stat(&ts->iops_stat[i]);\n\n\t\tts->io_bytes[i] = 0;\n\t\tts->runtime[i] = 0;\n\t\tts->total_io_u[i] = 0;\n\t\tts->short_io_u[i] = 0;\n\t\tts->drop_io_u[i] = 0;\n\t}\n\n\tfor (i = 0; i < FIO_LAT_CNT; i++)\n\t\tfor (j = 0; j < DDIR_RWDIR_CNT; j++)\n\t\t\treset_io_u_plat(ts->io_u_plat[i][j]);\n\n\treset_clat_prio_stats(ts);\n\n\tts->total_io_u[DDIR_SYNC] = 0;\n\treset_io_u_plat(ts->io_u_sync_plat);\n\n\tfor (i = 0; i < FIO_IO_U_MAP_NR; i++) {\n\t\tts->io_u_map[i] = 0;\n\t\tts->io_u_submit[i] = 0;\n\t\tts->io_u_complete[i] = 0;\n\t}\n\n\tfor (i = 0; i < FIO_IO_U_LAT_N_NR; i++)\n\t\tts->io_u_lat_n[i] = 0;\n\tfor (i = 0; i < FIO_IO_U_LAT_U_NR; i++)\n\t\tts->io_u_lat_u[i] = 0;\n\tfor (i = 0; i < FIO_IO_U_LAT_M_NR; i++)\n\t\tts->io_u_lat_m[i] = 0;\n\n\tts->total_submit = 0;\n\tts->total_complete = 0;\n\tts->nr_zone_resets = 0;\n\tts->cachehit = ts->cachemiss = 0;\n}\n\nstatic void __add_stat_to_log(struct io_log *iolog, enum fio_ddir ddir,\n\t\t\t      unsigned long elapsed, int log_max)\n{\n\t/*\n\t * Note an entry in the log. Use the mean from the logged samples,\n\t * making sure to properly round up. Only write a log entry if we\n\t * had actual samples done.\n\t */\n\tif (iolog->avg_window[ddir].samples) {\n\t\tstruct log_sample sample = { {{ 0, 0 }}, ddir, 0, 0, 0, 0 };\n\t\tunion io_sample_data *d = &sample.data;\n\n\t\tif (log_max == IO_LOG_SAMPLE_AVG) {\n\t\t\td->val.val0 = iolog->avg_window[ddir].mean.u.f + 0.50;\n\t\t\td->val.val1 = 0;\n\t\t} else if (log_max == IO_LOG_SAMPLE_MAX) {\n\t\t\td->val.val0 = iolog->avg_window[ddir].max_val;\n\t\t\td->val.val1 = 0;\n\t\t} else {\n\t\t\td->val.val0 = iolog->avg_window[ddir].mean.u.f + 0.50;\n\t\t\td->val.val1 = iolog->avg_window[ddir].max_val;\n\t\t}\n\n\t\t__add_log_sample(iolog, elapsed, &sample);\n\t}\n\n\treset_io_stat(&iolog->avg_window[ddir]);\n}\n\nstatic void _add_stat_to_log(struct io_log *iolog, unsigned long elapsed,\n\t\t\t     int log_max)\n{\n\tenum fio_ddir ddir;\n\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++)\n\t\t__add_stat_to_log(iolog, ddir, elapsed, log_max);\n}\n\nstatic unsigned long add_log_sample(struct thread_data *td,\n\t\t\t\t    struct io_log *iolog,\n\t\t\t\t    struct log_sample *sample)\n{\n\tunsigned long elapsed, this_window;\n\tenum fio_ddir ddir = sample->ddir;\n\n\tif (!ddir_rw(ddir))\n\t\treturn 0;\n\n\telapsed = mtime_since_now(&td->epoch);\n\n\t/*\n\t * If no time averaging, just add the log sample.\n\t */\n\tif (!iolog->avg_msec) {\n\t\t__add_log_sample(iolog, elapsed, sample);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Add the sample. If the time period has passed, then\n\t * add that entry to the log and clear.\n\t */\n\tadd_stat_sample(&iolog->avg_window[ddir], sample->data.val.val0);\n\n\t/*\n\t * If period hasn't passed, adding the above sample is all we\n\t * need to do.\n\t */\n\tthis_window = elapsed - iolog->avg_last[ddir];\n\tif (elapsed < iolog->avg_last[ddir])\n\t\treturn iolog->avg_last[ddir] - elapsed;\n\telse if (this_window < iolog->avg_msec) {\n\t\tunsigned long diff = iolog->avg_msec - this_window;\n\n\t\tif (inline_log(iolog) || diff > LOG_MSEC_SLACK)\n\t\t\treturn diff;\n\t}\n\n\t__add_stat_to_log(iolog, ddir, elapsed, td->o.log_max);\n\n\tiolog->avg_last[ddir] = elapsed - (elapsed % iolog->avg_msec);\n\n\treturn iolog->avg_msec;\n}\n\nvoid finalize_logs(struct thread_data *td, bool unit_logs)\n{\n\tunsigned long elapsed;\n\n\telapsed = mtime_since_now(&td->epoch);\n\n\tif (td->clat_log && unit_logs)\n\t\t_add_stat_to_log(td->clat_log, elapsed, td->o.log_max);\n\tif (td->slat_log && unit_logs)\n\t\t_add_stat_to_log(td->slat_log, elapsed, td->o.log_max);\n\tif (td->lat_log && unit_logs)\n\t\t_add_stat_to_log(td->lat_log, elapsed, td->o.log_max);\n\tif (td->bw_log && (unit_logs == per_unit_log(td->bw_log)))\n\t\t_add_stat_to_log(td->bw_log, elapsed, td->o.log_max);\n\tif (td->iops_log && (unit_logs == per_unit_log(td->iops_log)))\n\t\t_add_stat_to_log(td->iops_log, elapsed, td->o.log_max);\n}\n\nvoid add_agg_sample(union io_sample_data data, enum fio_ddir ddir,\n\t\t    unsigned long long bs)\n{\n\tstruct io_log *iolog;\n\tstruct log_sample sample = { data, ddir, bs, 0, 0, 0 };\n\n\tif (!ddir_rw(ddir))\n\t\treturn;\n\n\tiolog = agg_io_log[ddir];\n\t__add_log_sample(iolog, mtime_since_genesis(), &sample);\n}\n\nvoid add_sync_clat_sample(struct thread_stat *ts, unsigned long long nsec)\n{\n\tunsigned int idx = plat_val_to_idx(nsec);\n\tassert(idx < FIO_IO_U_PLAT_NR);\n\n\tts->io_u_sync_plat[idx]++;\n\tadd_stat_sample(&ts->sync_stat, nsec);\n}\n\nstatic inline void add_lat_percentile_sample(struct thread_stat *ts,\n\t\t\t\t\t     unsigned long long nsec,\n\t\t\t\t\t     enum fio_ddir ddir,\n\t\t\t\t\t     enum fio_lat lat)\n{\n\tunsigned int idx = plat_val_to_idx(nsec);\n\tassert(idx < FIO_IO_U_PLAT_NR);\n\n\tts->io_u_plat[lat][ddir][idx]++;\n}\n\nstatic inline void\nadd_lat_percentile_prio_sample(struct thread_stat *ts, unsigned long long nsec,\n\t\t\t       enum fio_ddir ddir,\n\t\t\t       unsigned short clat_prio_index)\n{\n\tunsigned int idx = plat_val_to_idx(nsec);\n\n\tif (ts->clat_prio[ddir])\n\t\tts->clat_prio[ddir][clat_prio_index].io_u_plat[idx]++;\n}\n\nvoid add_clat_sample(struct thread_data *td, enum fio_ddir ddir,\n\t\t     unsigned long long nsec, unsigned long long bs,\n\t\t     struct io_u *io_u)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tunsigned long elapsed, this_window;\n\tstruct thread_stat *ts = &td->ts;\n\tstruct io_log *iolog = td->clat_hist_log;\n\tuint64_t offset = 0;\n\tunsigned int ioprio = 0;\n\tunsigned short clat_prio_index = 0;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tif (io_u) {\n\t\toffset = io_u->offset;\n\t\tioprio = io_u->ioprio;\n\t\tclat_prio_index = io_u->clat_prio_index;\n\t}\n\n\tadd_stat_sample(&ts->clat_stat[ddir], nsec);\n\n\t/*\n\t * When lat_percentiles=1 (default 0), the reported per priority\n\t * percentiles and stats are used for describing total latency values,\n\t * even though the variable names themselves start with clat_.\n\t *\n\t * Because of the above definition, add a prio stat sample only when\n\t * lat_percentiles=0. add_lat_sample() will add the prio stat sample\n\t * when lat_percentiles=1.\n\t */\n\tif (!ts->lat_percentiles)\n\t\tadd_stat_prio_sample(ts->clat_prio[ddir], clat_prio_index,\n\t\t\t\t     nsec);\n\n\tif (td->clat_log) {\n\t\tstruct log_sample sample = { sample_val(nsec), ddir, bs,\n\t\t\toffset, ioprio, 0 };\n\n\t\tif (io_u)\n\t\t\tsample.issue_time =\n\t\t\t\tntime_since(&td->epoch, &io_u->issue_time);\n\n\t\tadd_log_sample(td, td->clat_log, &sample);\n\t}\n\n\tif (ts->clat_percentiles) {\n\t\t/*\n\t\t * Because of the above definition, add a prio lat percentile\n\t\t * sample only when lat_percentiles=0. add_lat_sample() will add\n\t\t * the prio lat percentile sample when lat_percentiles=1.\n\t\t */\n\t\tadd_lat_percentile_sample(ts, nsec, ddir, FIO_CLAT);\n\t\tif (!ts->lat_percentiles)\n\t\t\tadd_lat_percentile_prio_sample(ts, nsec, ddir,\n\t\t\t\t\t\t       clat_prio_index);\n\t}\n\n\tif (iolog && iolog->hist_msec) {\n\t\tstruct io_hist *hw = &iolog->hist_window[ddir];\n\n\t\thw->samples++;\n\t\telapsed = mtime_since_now(&td->epoch);\n\t\tif (!hw->hist_last)\n\t\t\thw->hist_last = elapsed;\n\t\tthis_window = elapsed - hw->hist_last;\n\n\t\tif (this_window >= iolog->hist_msec) {\n\t\t\tuint64_t *io_u_plat;\n\t\t\tstruct io_u_plat_entry *dst;\n\t\t\tstruct log_sample sample = { {{ 0, 0 }}, ddir, bs,\n\t\t\t\toffset, ioprio, 0 };\n\n\t\t\t/*\n\t\t\t * Make a byte-for-byte copy of the latency histogram\n\t\t\t * stored in td->ts.io_u_plat[ddir], recording it in a\n\t\t\t * log sample. Note that the matching call to free() is\n\t\t\t * located in iolog.c after printing this sample to the\n\t\t\t * log file.\n\t\t\t */\n\t\t\tio_u_plat = (uint64_t *) td->ts.io_u_plat[FIO_CLAT][ddir];\n\t\t\tdst = malloc(sizeof(struct io_u_plat_entry));\n\t\t\tmemcpy(&(dst->io_u_plat), io_u_plat,\n\t\t\t\tFIO_IO_U_PLAT_NR * sizeof(uint64_t));\n\t\t\tflist_add(&dst->list, &hw->list);\n\n\t\t\tsample.data = sample_plat(dst);\n\t\t\t__add_log_sample(iolog, elapsed, &sample);\n\n\t\t\t/*\n\t\t\t * Update the last time we recorded as being now, minus\n\t\t\t * any drift in time we encountered before actually\n\t\t\t * making the record.\n\t\t\t */\n\t\t\thw->hist_last = elapsed - (this_window - iolog->hist_msec);\n\t\t\thw->samples = 0;\n\t\t}\n\t}\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nvoid add_slat_sample(struct thread_data *td, struct io_u *io_u)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct thread_stat *ts = &td->ts;\n\tenum fio_ddir ddir;\n\tunsigned long long nsec;\n\n\tddir = io_u->ddir;\n\tif (!ddir_rw(ddir))\n\t\treturn;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tnsec = ntime_since(&io_u->start_time, &io_u->issue_time);\n\n\tadd_stat_sample(&ts->slat_stat[ddir], nsec);\n\n\tif (td->slat_log) {\n\t\tstruct log_sample sample = { sample_val(nsec), ddir,\n\t\t\tio_u->xfer_buflen, io_u->offset, io_u->ioprio,\n\t\t\tntime_since(&td->epoch, &io_u->issue_time) };\n\n\t\tadd_log_sample(td, td->slat_log, &sample);\n\t}\n\n\tif (ts->slat_percentiles)\n\t\tadd_lat_percentile_sample(ts, nsec, ddir, FIO_SLAT);\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nvoid add_lat_sample(struct thread_data *td, enum fio_ddir ddir,\n\t\t    unsigned long long nsec, unsigned long long bs,\n\t\t    struct io_u * io_u)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct thread_stat *ts = &td->ts;\n\n\tif (!ddir_rw(ddir))\n\t\treturn;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tadd_stat_sample(&ts->lat_stat[ddir], nsec);\n\n\tif (td->lat_log) {\n\t\tstruct log_sample sample = { sample_val(nsec), ddir, bs,\n\t\t\tio_u->offset, io_u->ioprio, 0 };\n\n\t\tadd_log_sample(td, td->lat_log, &sample);\n\t}\n\n\t/*\n\t * When lat_percentiles=1 (default 0), the reported per priority\n\t * percentiles and stats are used for describing total latency values,\n\t * even though the variable names themselves start with clat_.\n\t *\n\t * Because of the above definition, add a prio stat and prio lat\n\t * percentile sample only when lat_percentiles=1. add_clat_sample() will\n\t * add the prio stat and prio lat percentile sample when\n\t * lat_percentiles=0.\n\t */\n\tif (ts->lat_percentiles) {\n\t\tadd_lat_percentile_sample(ts, nsec, ddir, FIO_LAT);\n\t\tadd_lat_percentile_prio_sample(ts, nsec, ddir,\n\t\t\t\t\t       io_u->clat_prio_index);\n\t\tadd_stat_prio_sample(ts->clat_prio[ddir], io_u->clat_prio_index,\n\t\t\t\t     nsec);\n\t}\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nvoid add_bw_sample(struct thread_data *td, struct io_u *io_u,\n\t\t   unsigned int bytes, unsigned long long spent)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct thread_stat *ts = &td->ts;\n\tunsigned long rate;\n\n\tif (spent)\n\t\trate = (unsigned long) (bytes * 1000000ULL / spent);\n\telse\n\t\trate = 0;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tadd_stat_sample(&ts->bw_stat[io_u->ddir], rate);\n\n\tif (td->bw_log) {\n\t\tstruct log_sample sample = { sample_val(rate), io_u->ddir,\n\t\t\tbytes, io_u->offset, io_u->ioprio, 0 };\n\n\t\tadd_log_sample(td, td->bw_log, &sample);\n\t}\n\n\ttd->stat_io_bytes[io_u->ddir] = td->this_io_bytes[io_u->ddir];\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nstatic int __add_samples(struct thread_data *td, struct timespec *parent_tv,\n\t\t\t struct timespec *t, unsigned int avg_time,\n\t\t\t uint64_t *this_io_bytes, uint64_t *stat_io_bytes,\n\t\t\t struct io_stat *stat, struct io_log *log,\n\t\t\t bool is_kb)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tunsigned long spent, rate;\n\tenum fio_ddir ddir;\n\tunsigned long next, next_log;\n\n\tnext_log = avg_time;\n\n\tspent = mtime_since(parent_tv, t);\n\tif (spent < avg_time && avg_time - spent > LOG_MSEC_SLACK)\n\t\treturn avg_time - spent;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\t/*\n\t * Compute both read and write rates for the interval.\n\t */\n\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\tuint64_t delta;\n\n\t\tdelta = this_io_bytes[ddir] - stat_io_bytes[ddir];\n\t\tif (!delta)\n\t\t\tcontinue; /* No entries for interval */\n\n\t\tif (spent) {\n\t\t\tif (is_kb)\n\t\t\t\trate = delta * 1000 / spent / 1024; /* KiB/s */\n\t\t\telse\n\t\t\t\trate = (delta * 1000) / spent;\n\t\t} else\n\t\t\trate = 0;\n\n\t\tadd_stat_sample(&stat[ddir], rate);\n\n\t\tif (log) {\n\t\t\tstruct log_sample sample = {\n\t\t\t\tsample_val(rate), ddir, 0, 0, 0, 0 };\n\n\t\t\tif (td->o.min_bs[ddir] == td->o.max_bs[ddir])\n\t\t\t\tsample.bs = td->o.min_bs[ddir];\n\t\t\tnext = add_log_sample(td, log, &sample);\n\t\t\tnext_log = min(next_log, next);\n\t\t}\n\n\t\tstat_io_bytes[ddir] = this_io_bytes[ddir];\n\t}\n\n\t*parent_tv = *t;\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n\n\tif (spent <= avg_time)\n\t\tnext = avg_time;\n\telse\n\t\tnext = avg_time - (1 + spent - avg_time);\n\n\treturn min(next, next_log);\n}\n\nstatic int add_bw_samples(struct thread_data *td, struct timespec *t)\n{\n\treturn __add_samples(td, &td->bw_sample_time, t, td->o.bw_avg_time,\n\t\t\t\ttd->this_io_bytes, td->stat_io_bytes,\n\t\t\t\ttd->ts.bw_stat, td->bw_log, true);\n}\n\nvoid add_iops_sample(struct thread_data *td, struct io_u *io_u,\n\t\t     unsigned int bytes)\n{\n\tconst bool needs_lock = td_async_processing(td);\n\tstruct thread_stat *ts = &td->ts;\n\n\tif (needs_lock)\n\t\t__td_io_u_lock(td);\n\n\tadd_stat_sample(&ts->iops_stat[io_u->ddir], 1);\n\n\tif (td->iops_log) {\n\t\tstruct log_sample sample = { sample_val(1), io_u->ddir, bytes,\n\t\t\tio_u->offset, io_u->ioprio, 0 };\n\n\t\tadd_log_sample(td, td->iops_log, &sample);\n\t}\n\n\ttd->stat_io_blocks[io_u->ddir] = td->this_io_blocks[io_u->ddir];\n\n\tif (needs_lock)\n\t\t__td_io_u_unlock(td);\n}\n\nstatic int add_iops_samples(struct thread_data *td, struct timespec *t)\n{\n\treturn __add_samples(td, &td->iops_sample_time, t, td->o.iops_avg_time,\n\t\t\t\ttd->this_io_blocks, td->stat_io_blocks,\n\t\t\t\ttd->ts.iops_stat, td->iops_log, false);\n}\n\nstatic bool td_in_logging_state(struct thread_data *td)\n{\n\tif (in_ramp_time(td))\n\t\treturn false;\n\n\tswitch(td->runstate) {\n\tcase TD_RUNNING:\n\tcase TD_VERIFYING:\n\tcase TD_FINISHING:\n\tcase TD_EXITED:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n/*\n * Returns msecs to next event\n */\nint calc_log_samples(void)\n{\n\tunsigned int next = ~0U, tmp = 0, next_mod = 0, log_avg_msec_min = -1U;\n\tstruct timespec now;\n\tlong elapsed_time = 0;\n\n\tfor_each_td(td) {\n\t\tfio_gettime(&now, NULL);\n\t\telapsed_time = mtime_since(&td->epoch, &now);\n\n\t\tif (!td->o.stats)\n\t\t\tcontinue;\n\t\tif (!td_in_logging_state(td)) {\n\t\t\tnext = min(td->o.iops_avg_time, td->o.bw_avg_time);\n\t\t\tcontinue;\n\t\t}\n\t\tif (!td->bw_log ||\n\t\t\t(td->bw_log && !per_unit_log(td->bw_log))) {\n\t\t\ttmp = add_bw_samples(td, &now);\n\n\t\t\tif (td->bw_log)\n\t\t\t\tlog_avg_msec_min = min(log_avg_msec_min, (unsigned int)td->bw_log->avg_msec);\n\t\t}\n\t\tif (!td->iops_log ||\n\t\t\t(td->iops_log && !per_unit_log(td->iops_log))) {\n\t\t\ttmp = add_iops_samples(td, &now);\n\n\t\t\tif (td->iops_log)\n\t\t\t\tlog_avg_msec_min = min(log_avg_msec_min, (unsigned int)td->iops_log->avg_msec);\n\t\t}\n\n\t\tif (tmp < next)\n\t\t\tnext = tmp;\n\t} end_for_each();\n\n\t/* if log_avg_msec_min has not been changed, set it to 0 */\n\tif (log_avg_msec_min == -1U)\n\t\tlog_avg_msec_min = 0;\n\n\tif (log_avg_msec_min == 0)\n\t\tnext_mod = elapsed_time;\n\telse\n\t\tnext_mod = elapsed_time % log_avg_msec_min;\n\n\t/* correction to keep the time on the log avg msec boundary */\n\tnext = min(next, (log_avg_msec_min - next_mod));\n\n\treturn next == ~0U ? 0 : next;\n}\n\nvoid stat_init(void)\n{\n\tstat_sem = fio_sem_init(FIO_SEM_UNLOCKED);\n}\n\nvoid stat_exit(void)\n{\n\t/*\n\t * When we have the mutex, we know out-of-band access to it\n\t * have ended.\n\t */\n\tfio_sem_down(stat_sem);\n\tfio_sem_remove(stat_sem);\n}\n\n/*\n * Called from signal handler. Wake up status thread.\n */\nvoid show_running_run_stats(void)\n{\n\thelper_do_stat();\n}\n\nuint32_t *io_u_block_info(struct thread_data *td, struct io_u *io_u)\n{\n\t/* Ignore io_u's which span multiple blocks--they will just get\n\t * inaccurate counts. */\n\tint idx = (io_u->offset - io_u->file->file_offset)\n\t\t\t/ td->o.bs[DDIR_TRIM];\n\tuint32_t *info = &td->ts.block_infos[idx];\n\tassert(idx < td->ts.nr_block_infos);\n\treturn info;\n}\n\n"
        },
        {
          "name": "stat.h",
          "type": "blob",
          "size": 13.0048828125,
          "content": "#ifndef FIO_STAT_H\n#define FIO_STAT_H\n\n#include \"iolog.h\"\n#include \"lib/output_buffer.h\"\n#include \"diskutil.h\"\n#include \"json.h\"\n\nstruct group_run_stats {\n\tuint64_t max_run[DDIR_RWDIR_CNT], min_run[DDIR_RWDIR_CNT];\n\tuint64_t max_bw[DDIR_RWDIR_CNT], min_bw[DDIR_RWDIR_CNT];\n\tuint64_t iobytes[DDIR_RWDIR_CNT];\n\tuint64_t agg[DDIR_RWDIR_CNT];\n\tuint32_t kb_base;\n\tuint32_t unit_base;\n\tuint32_t sig_figs;\n\tuint32_t groupid;\n\tuint32_t unified_rw_rep;\n} __attribute__((packed));\n\n/*\n * How many depth levels to log\n */\n#define FIO_IO_U_MAP_NR\t7\n#define FIO_IO_U_LAT_N_NR 10\n#define FIO_IO_U_LAT_U_NR 10\n#define FIO_IO_U_LAT_M_NR 12\n\n/*\n * Constants for clat percentiles\n */\n#define FIO_IO_U_PLAT_BITS 6\n#define FIO_IO_U_PLAT_VAL (1 << FIO_IO_U_PLAT_BITS)\n#define FIO_IO_U_PLAT_GROUP_NR 29\n#define FIO_IO_U_PLAT_NR (FIO_IO_U_PLAT_GROUP_NR * FIO_IO_U_PLAT_VAL)\n#define FIO_IO_U_LIST_MAX_LEN 20 /* The size of the default and user-specified\n\t\t\t\t\tlist of percentiles */\n\n/*\n * Aggregate latency samples for reporting percentile(s).\n *\n * EXECUTIVE SUMMARY\n *\n * FIO_IO_U_PLAT_BITS determines the maximum statistical error on the\n * value of resulting percentiles. The error will be approximately\n * 1/2^(FIO_IO_U_PLAT_BITS+1) of the value.\n *\n * FIO_IO_U_PLAT_GROUP_NR and FIO_IO_U_PLAT_BITS determine the maximum\n * range being tracked for latency samples. The maximum value tracked\n * accurately will be 2^(GROUP_NR + PLAT_BITS - 1) nanoseconds.\n *\n * FIO_IO_U_PLAT_GROUP_NR and FIO_IO_U_PLAT_BITS determine the memory\n * requirement of storing those aggregate counts. The memory used will\n * be (FIO_IO_U_PLAT_GROUP_NR * 2^FIO_IO_U_PLAT_BITS) * sizeof(uint64_t)\n * bytes.\n *\n * FIO_IO_U_PLAT_NR is the total number of buckets.\n *\n * DETAILS\n *\n * Suppose the lat varies from 0 to 999 (usec), the straightforward\n * method is to keep an array of (999 + 1) buckets, in which a counter\n * keeps the count of samples which fall in the bucket, e.g.,\n * {[0],[1],...,[999]}. However this consumes a huge amount of space,\n * and can be avoided if an approximation is acceptable.\n *\n * One such method is to let the range of the bucket to be greater\n * than one. This method has low accuracy when the value is small. For\n * example, let the buckets be {[0,99],[100,199],...,[900,999]}, and\n * the represented value of each bucket be the mean of the range. Then\n * a value 0 has a round-off error of 49.5. To improve on this, we\n * use buckets with non-uniform ranges, while bounding the error of\n * each bucket within a ratio of the sample value. A simple example\n * would be when error_bound = 0.005, buckets are {\n * {[0],[1],...,[99]}, {[100,101],[102,103],...,[198,199]},..,\n * {[900,909],[910,919]...}  }. The total range is partitioned into\n * groups with different ranges, then buckets with uniform ranges. An\n * upper bound of the error is (range_of_bucket/2)/value_of_bucket\n *\n * For better efficiency, we implement this using base two. We group\n * samples by their Most Significant Bit (MSB), extract the next M bit\n * of them as an index within the group, and discard the rest of the\n * bits.\n *\n * E.g., assume a sample 'x' whose MSB is bit n (starting from bit 0),\n * and use M bit for indexing\n *\n *        | n |    M bits   | bit (n-M-1) ... bit 0 |\n *\n * Because x is at least 2^n, and bit 0 to bit (n-M-1) is at most\n * (2^(n-M) - 1), discarding bit 0 to (n-M-1) makes the round-off\n * error\n *\n *           2^(n-M)-1    2^(n-M)    1\n *      e <= --------- <= ------- = ---\n *             2^n          2^n     2^M\n *\n * Furthermore, we use \"mean\" of the range to represent the bucket,\n * the error e can be lowered by half to 1 / 2^(M+1). By using M bits\n * as the index, each group must contains 2^M buckets.\n *\n * E.g. Let M (FIO_IO_U_PLAT_BITS) be 6\n *      Error bound is 1/2^(6+1) = 0.0078125 (< 1%)\n *\n *\tGroup\tMSB\t#discarded\trange of\t\t#buckets\n *\t\t\terror_bits\tvalue\n *\t----------------------------------------------------------------\n *\t0*\t0~5\t0\t\t[0,63]\t\t\t64\n *\t1*\t6\t0\t\t[64,127]\t\t64\n *\t2\t7\t1\t\t[128,255]\t\t64\n *\t3\t8\t2\t\t[256,511]\t\t64\n *\t4\t9\t3\t\t[512,1023]\t\t64\n *\t...\t...\t...\t\t[...,...]\t\t...\n *\t28\t33\t27\t\t[8589934592,+inf]**\t64\n *\n *  * Special cases: when n < (M-1) or when n == (M-1), in both cases,\n *    the value cannot be rounded off. Use all bits of the sample as\n *    index.\n *\n *  ** If a sample's MSB is greater than 33, it will be counted as 33.\n */\n\n/*\n * Trim cycle count measurements\n */\n#define MAX_NR_BLOCK_INFOS\t8192\n#define BLOCK_INFO_STATE_SHIFT\t29\n#define BLOCK_INFO_TRIMS(block_info)\t\\\n\t((block_info) & ((1 << BLOCK_INFO_STATE_SHIFT) - 1))\n#define BLOCK_INFO_STATE(block_info)\t\t\\\n\t((block_info) >> BLOCK_INFO_STATE_SHIFT)\n#define BLOCK_INFO(state, trim_cycles)\t\\\n\t((trim_cycles) | ((unsigned int) (state) << BLOCK_INFO_STATE_SHIFT))\n#define BLOCK_INFO_SET_STATE(block_info, state)\t\\\n\tBLOCK_INFO(state, BLOCK_INFO_TRIMS(block_info))\nenum block_info_state {\n\tBLOCK_STATE_UNINIT,\n\tBLOCK_STATE_TRIMMED,\n\tBLOCK_STATE_WRITTEN,\n\tBLOCK_STATE_TRIM_FAILURE,\n\tBLOCK_STATE_WRITE_FAILURE,\n\tBLOCK_STATE_COUNT,\n};\n\n#define FIO_JOBNAME_SIZE\t128\n#define FIO_JOBDESC_SIZE\t256\n#define FIO_VERROR_SIZE\t\t128\n#define UNIFIED_SPLIT\t\t0\n#define UNIFIED_MIXED\t\t1\n#define UNIFIED_BOTH\t\t2\n\nenum fio_lat {\n\tFIO_SLAT = 0,\n\tFIO_CLAT,\n\tFIO_LAT,\n\n\tFIO_LAT_CNT = 3,\n};\n\nstruct clat_prio_stat {\n\tuint64_t io_u_plat[FIO_IO_U_PLAT_NR];\n\tstruct io_stat clat_stat;\n\tuint32_t ioprio;\n};\n\nstruct thread_stat {\n\tchar name[FIO_JOBNAME_SIZE];\n\tchar verror[FIO_VERROR_SIZE];\n\tuint32_t error;\n\tuint32_t thread_number;\n\tuint32_t groupid;\n\tuint64_t job_start; /* Time job was started, as clock_gettime(job_start_clock_id) */\n\tuint32_t pid;\n\tchar description[FIO_JOBDESC_SIZE];\n\tuint32_t members;\n\tuint32_t unified_rw_rep;\n\tuint32_t disable_prio_stat;\n\n\t/*\n\t * bandwidth and latency stats\n\t */\n\tstruct io_stat sync_stat __attribute__((aligned(8)));/* fsync etc stats */\n\tstruct io_stat clat_stat[DDIR_RWDIR_CNT]; /* completion latency */\n\tstruct io_stat slat_stat[DDIR_RWDIR_CNT]; /* submission latency */\n\tstruct io_stat lat_stat[DDIR_RWDIR_CNT]; /* total latency */\n\tstruct io_stat bw_stat[DDIR_RWDIR_CNT]; /* bandwidth stats */\n\tstruct io_stat iops_stat[DDIR_RWDIR_CNT]; /* IOPS stats */\n\n\t/*\n\t * fio system usage accounting\n\t */\n\tuint64_t usr_time;\n\tuint64_t sys_time;\n\tuint64_t ctx;\n\tuint64_t minf, majf;\n\n\t/*\n\t * IO depth and latency stats\n\t */\n\tuint32_t clat_percentiles;\n\tuint32_t lat_percentiles;\n\tuint32_t slat_percentiles;\n\tuint32_t pad;\n\tuint64_t percentile_precision;\n\tfio_fp64_t percentile_list[FIO_IO_U_LIST_MAX_LEN];\n\n\tuint64_t io_u_map[FIO_IO_U_MAP_NR];\n\tuint64_t io_u_submit[FIO_IO_U_MAP_NR];\n\tuint64_t io_u_complete[FIO_IO_U_MAP_NR];\n\tuint64_t io_u_lat_n[FIO_IO_U_LAT_N_NR];\n\tuint64_t io_u_lat_u[FIO_IO_U_LAT_U_NR];\n\tuint64_t io_u_lat_m[FIO_IO_U_LAT_M_NR];\n\tuint64_t io_u_plat[FIO_LAT_CNT][DDIR_RWDIR_CNT][FIO_IO_U_PLAT_NR];\n\tuint64_t io_u_sync_plat[FIO_IO_U_PLAT_NR];\n\n\tuint64_t total_io_u[DDIR_RWDIR_SYNC_CNT];\n\tuint64_t short_io_u[DDIR_RWDIR_CNT];\n\tuint64_t drop_io_u[DDIR_RWDIR_CNT];\n\tuint64_t total_submit;\n\tuint64_t total_complete;\n\n\tuint64_t io_bytes[DDIR_RWDIR_CNT];\n\tuint64_t runtime[DDIR_RWDIR_CNT];\n\tuint64_t total_run_time;\n\n\t/*\n\t * IO Error related stats\n\t */\n\tunion {\n\t\tuint16_t continue_on_error;\n\t\tuint32_t pad2;\n\t};\n\tuint32_t first_error;\n\tuint64_t total_err_count;\n\n\t/* ZBD stats */\n\tuint64_t nr_zone_resets;\n\n\tuint64_t nr_block_infos;\n\tuint32_t block_infos[MAX_NR_BLOCK_INFOS];\n\n\tuint32_t kb_base;\n\tuint32_t unit_base;\n\n\tuint32_t latency_depth;\n\tuint32_t pad3;\n\tuint64_t latency_target;\n\tfio_fp64_t latency_percentile;\n\tuint64_t latency_window;\n\n\tuint32_t sig_figs;\n\n\tuint64_t ss_dur;\n\tuint32_t ss_state;\n\tuint32_t ss_head;\n\n\tfio_fp64_t ss_limit;\n\tfio_fp64_t ss_slope;\n\tfio_fp64_t ss_deviation;\n\tfio_fp64_t ss_criterion;\n\n\t/* A mirror of td->ioprio. */\n\tuint32_t ioprio;\n\n\tunion {\n\t\tuint64_t *ss_iops_data;\n\t\t/*\n\t\t * For FIO_NET_CMD_TS, the pointed to data will temporarily\n\t\t * be stored at this offset from the start of the payload.\n\t\t */\n\t\tuint64_t ss_iops_data_offset;\n\t\tuint64_t pad4;\n\t};\n\n\tunion {\n\t\tuint64_t *ss_bw_data;\n\t\t/*\n\t\t * For FIO_NET_CMD_TS, the pointed to data will temporarily\n\t\t * be stored at this offset from the start of the payload.\n\t\t */\n\t\tuint64_t ss_bw_data_offset;\n\t\tuint64_t pad5;\n\t};\n\n\tunion {\n\t\tstruct clat_prio_stat *clat_prio[DDIR_RWDIR_CNT];\n\t\t/*\n\t\t * For FIO_NET_CMD_TS, the pointed to data will temporarily\n\t\t * be stored at this offset from the start of the payload.\n\t\t */\n\t\tuint64_t clat_prio_offset[DDIR_RWDIR_CNT];\n\t\tuint64_t pad6;\n\t};\n\tuint32_t nr_clat_prio[DDIR_RWDIR_CNT];\n\n\tuint64_t cachehit;\n\tuint64_t cachemiss;\n} __attribute__((packed));\n\n#define JOBS_ETA {\t\t\t\t\t\t\t\\\n\tuint32_t nr_running;\t\t\t\t\t\t\\\n\tuint32_t nr_ramp;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tuint32_t nr_pending;\t\t\t\t\t\t\\\n\tuint32_t nr_setting_up;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tuint64_t m_rate[DDIR_RWDIR_CNT];\t\t\t\t\\\n\tuint64_t t_rate[DDIR_RWDIR_CNT];\t\t\t\t\\\n\tuint64_t rate[DDIR_RWDIR_CNT];\t\t\t\t\t\\\n\tuint32_t m_iops[DDIR_RWDIR_CNT];\t\t\t\t\\\n\tuint32_t t_iops[DDIR_RWDIR_CNT];\t\t\t\t\\\n\tuint32_t iops[DDIR_RWDIR_CNT];\t\t\t\t\t\\\n\tuint32_t pad;\t\t\t\t\t\t\t\\\n\tuint64_t elapsed_sec;\t\t\t\t\t\t\\\n\tuint64_t eta_sec;\t\t\t\t\t\t\\\n\tuint32_t is_pow2;\t\t\t\t\t\t\\\n\tuint32_t unit_base;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tuint32_t sig_figs;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tuint32_t files_open;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t/*\t\t\t\t\t\t\t\t\\\n\t * Network 'copy' of run_str[]\t\t\t\t\t\\\n\t */\t\t\t\t\t\t\t\t\\\n\tuint32_t nr_threads;\t\t\t\t\t\t\\\n\tuint32_t pad2;\t\t\t\t\t\t\t\\\n\tuint8_t run_str[];\t\t\t\t\t\t\\\n}\n\nstruct jobs_eta JOBS_ETA;\nstruct jobs_eta_packed JOBS_ETA __attribute__((packed));\n\nstruct io_u_plat_entry {\n\tstruct flist_head list;\n\tuint64_t io_u_plat[FIO_IO_U_PLAT_NR];\n};\n\nextern struct fio_sem *stat_sem;\n\nextern struct jobs_eta *get_jobs_eta(bool force, size_t *size);\n\nextern void stat_init(void);\nextern void stat_exit(void);\n\nextern struct json_object * show_thread_status(struct thread_stat *ts, struct group_run_stats *rs, struct flist_head *, struct buf_output *);\nextern void show_group_stats(struct group_run_stats *rs, struct buf_output *);\nextern void display_thread_status(struct jobs_eta *je);\nextern void __show_run_stats(void);\nextern int __show_running_run_stats(void);\nextern void show_running_run_stats(void);\nextern void check_for_running_stats(void);\nextern void sum_thread_stats(struct thread_stat *dst, struct thread_stat *src);\nextern void sum_group_stats(struct group_run_stats *dst, struct group_run_stats *src);\nextern void init_thread_stat_min_vals(struct thread_stat *ts);\nextern void init_thread_stat(struct thread_stat *ts);\nextern void init_group_run_stat(struct group_run_stats *gs);\nextern void eta_to_str(char *str, unsigned long eta_sec);\nextern bool calc_lat(struct io_stat *is, unsigned long long *min, unsigned long long *max, double *mean, double *dev);\nextern unsigned int calc_clat_percentiles(uint64_t *io_u_plat, unsigned long long nr, fio_fp64_t *plist, unsigned long long **output, unsigned long long *maxv, unsigned long long *minv);\nextern void stat_calc_lat_n(struct thread_stat *ts, double *io_u_lat);\nextern void stat_calc_lat_m(struct thread_stat *ts, double *io_u_lat);\nextern void stat_calc_lat_u(struct thread_stat *ts, double *io_u_lat);\nextern void stat_calc_dist(uint64_t *map, unsigned long total, double *io_u_dist);\nextern void reset_io_stats(struct thread_data *);\nextern void update_rusage_stat(struct thread_data *);\nextern void clear_rusage_stat(struct thread_data *);\n\nextern void add_lat_sample(struct thread_data *, enum fio_ddir,\n\t\t\t   unsigned long long, unsigned long long,\n\t\t\t   struct io_u *);\nextern void add_clat_sample(struct thread_data *, enum fio_ddir,\n\t\t\t    unsigned long long, unsigned long long,\n\t\t\t    struct io_u *);\nextern void add_slat_sample(struct thread_data *, struct io_u *);\nextern void add_agg_sample(union io_sample_data, enum fio_ddir, unsigned long long);\nextern void add_iops_sample(struct thread_data *, struct io_u *,\n\t\t\t\tunsigned int);\nextern void add_bw_sample(struct thread_data *, struct io_u *,\n\t\t\t\tunsigned int, unsigned long long);\nextern void add_sync_clat_sample(struct thread_stat *ts,\n\t\t\t\tunsigned long long nsec);\nextern int calc_log_samples(void);\nextern void free_clat_prio_stats(struct thread_stat *);\nextern int alloc_clat_prio_stat_ddir(struct thread_stat *, enum fio_ddir, int);\n\nextern void print_disk_util(struct disk_util_stat *, struct disk_util_agg *, int terse, struct buf_output *);\nextern void json_array_add_disk_util(struct disk_util_stat *dus,\n\t\t\t\tstruct disk_util_agg *agg, struct json_array *parent);\n\nextern struct io_log *agg_io_log[DDIR_RWDIR_CNT];\nextern bool write_bw_log;\n\nstatic inline bool nsec_to_usec(unsigned long long *min,\n\t\t\t\tunsigned long long *max, double *mean,\n\t\t\t\tdouble *dev)\n{\n\tif (*min > 2000 && *max > 99999 && *dev > 1000.0) {\n\t\t*min /= 1000;\n\t\t*max /= 1000;\n\t\t*mean /= 1000.0;\n\t\t*dev /= 1000.0;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic inline bool nsec_to_msec(unsigned long long *min,\n\t\t\t\tunsigned long long *max, double *mean,\n\t\t\t\tdouble *dev)\n{\n\tif (*min > 2000000 && *max > 99999999ULL && *dev > 1000000.0) {\n\t\t*min /= 1000000;\n\t\t*max /= 1000000;\n\t\t*mean /= 1000000.0;\n\t\t*dev /= 1000000.0;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n/*\n * Worst level condensing would be 1:5, so allow enough room for that\n */\n#define __THREAD_RUNSTR_SZ(nr)\t((nr) * 5)\n#define THREAD_RUNSTR_SZ\t__THREAD_RUNSTR_SZ(thread_number)\n\nuint32_t *io_u_block_info(struct thread_data *td, struct io_u *io_u);\n\n#endif\n"
        },
        {
          "name": "steadystate.c",
          "type": "blob",
          "size": 9.3798828125,
          "content": "#include <stdlib.h>\n\n#include \"fio.h\"\n#include \"steadystate.h\"\n\nbool steadystate_enabled = false;\nunsigned int ss_check_interval = 1000;\n\nvoid steadystate_free(struct thread_data *td)\n{\n\tfree(td->ss.iops_data);\n\tfree(td->ss.bw_data);\n\ttd->ss.iops_data = NULL;\n\ttd->ss.bw_data = NULL;\n}\n\nstatic void steadystate_alloc(struct thread_data *td)\n{\n\tint intervals = td->ss.dur / (ss_check_interval / 1000L);\n\n\ttd->ss.bw_data = calloc(intervals, sizeof(uint64_t));\n\ttd->ss.iops_data = calloc(intervals, sizeof(uint64_t));\n\n\ttd->ss.state |= FIO_SS_DATA;\n}\n\nvoid steadystate_setup(void)\n{\n\tstruct thread_data *prev_td;\n\tint prev_groupid;\n\n\tif (!steadystate_enabled)\n\t\treturn;\n\n\t/*\n\t * if group reporting is enabled, identify the last td\n\t * for each group and use it for storing steady state\n\t * data\n\t */\n\tprev_groupid = -1;\n\tprev_td = NULL;\n\tfor_each_td(td) {\n\t\tif (!td->ss.dur)\n\t\t\tcontinue;\n\n\t\tif (!td->o.group_reporting) {\n\t\t\tsteadystate_alloc(td);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prev_groupid != td->groupid) {\n\t\t\tif (prev_td)\n\t\t\t\tsteadystate_alloc(prev_td);\n\t\t\tprev_groupid = td->groupid;\n\t\t}\n\t\tprev_td = td;\n\t} end_for_each();\n\n\tif (prev_td && prev_td->o.group_reporting)\n\t\tsteadystate_alloc(prev_td);\n}\n\nstatic bool steadystate_slope(uint64_t iops, uint64_t bw,\n\t\t\t      struct thread_data *td)\n{\n\tint i, j;\n\tdouble result;\n\tstruct steadystate_data *ss = &td->ss;\n\tuint64_t new_val;\n\tint intervals = ss->dur / (ss_check_interval / 1000L);\n\n\tss->bw_data[ss->tail] = bw;\n\tss->iops_data[ss->tail] = iops;\n\n\tif (ss->state & FIO_SS_IOPS)\n\t\tnew_val = iops;\n\telse\n\t\tnew_val = bw;\n\n\tif (ss->state & FIO_SS_BUFFER_FULL || ss->tail - ss->head == intervals - 1) {\n\t\tif (!(ss->state & FIO_SS_BUFFER_FULL)) {\n\t\t\t/* first time through */\n\t\t\tfor (i = 0, ss->sum_y = 0; i < intervals; i++) {\n\t\t\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\t\t\tss->sum_y += ss->iops_data[i];\n\t\t\t\telse\n\t\t\t\t\tss->sum_y += ss->bw_data[i];\n\t\t\t\tj = (ss->head + i) % intervals;\n\t\t\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\t\t\tss->sum_xy += i * ss->iops_data[j];\n\t\t\t\telse\n\t\t\t\t\tss->sum_xy += i * ss->bw_data[j];\n\t\t\t}\n\t\t\tss->state |= FIO_SS_BUFFER_FULL;\n\t\t} else {\t\t/* easy to update the sums */\n\t\t\tss->sum_y -= ss->oldest_y;\n\t\t\tss->sum_y += new_val;\n\t\t\tss->sum_xy = ss->sum_xy - ss->sum_y + intervals * new_val;\n\t\t}\n\n\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\tss->oldest_y = ss->iops_data[ss->head];\n\t\telse\n\t\t\tss->oldest_y = ss->bw_data[ss->head];\n\n\t\t/*\n\t\t * calculate slope as (sum_xy - sum_x * sum_y / n) / (sum_(x^2)\n\t\t * - (sum_x)^2 / n) This code assumes that all x values are\n\t\t * equally spaced when they are often off by a few milliseconds.\n\t\t * This assumption greatly simplifies the calculations.\n\t\t */\n\t\tss->slope = (ss->sum_xy - (double) ss->sum_x * ss->sum_y / intervals) /\n\t\t\t\t(ss->sum_x_sq - (double) ss->sum_x * ss->sum_x / intervals);\n\t\tif (ss->state & FIO_SS_PCT)\n\t\t\tss->criterion = 100.0 * ss->slope / (ss->sum_y / intervals);\n\t\telse\n\t\t\tss->criterion = ss->slope;\n\n\t\tdprint(FD_STEADYSTATE, \"sum_y: %llu, sum_xy: %llu, slope: %f, \"\n\t\t\t\t\t\"criterion: %f, limit: %f\\n\",\n\t\t\t\t\t(unsigned long long) ss->sum_y,\n\t\t\t\t\t(unsigned long long) ss->sum_xy,\n\t\t\t\t\tss->slope, ss->criterion, ss->limit);\n\n\t\tresult = ss->criterion * (ss->criterion < 0.0 ? -1.0 : 1.0);\n\t\tif (result < ss->limit)\n\t\t\treturn true;\n\t}\n\n\tss->tail = (ss->tail + 1) % intervals;\n\tif (ss->tail <= ss->head)\n\t\tss->head = (ss->head + 1) % intervals;\n\n\treturn false;\n}\n\nstatic bool steadystate_deviation(uint64_t iops, uint64_t bw,\n\t\t\t\t  struct thread_data *td)\n{\n\tint i;\n\tdouble diff;\n\tdouble mean;\n\n\tstruct steadystate_data *ss = &td->ss;\n\tint intervals = ss->dur / (ss_check_interval / 1000L);\n\n\tss->bw_data[ss->tail] = bw;\n\tss->iops_data[ss->tail] = iops;\n\n\tif (ss->state & FIO_SS_BUFFER_FULL || ss->tail - ss->head == intervals  - 1) {\n\t\tif (!(ss->state & FIO_SS_BUFFER_FULL)) {\n\t\t\t/* first time through */\n\t\t\tfor (i = 0, ss->sum_y = 0; i < intervals; i++) {\n\t\t\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\t\t\tss->sum_y += ss->iops_data[i];\n\t\t\t\telse\n\t\t\t\t\tss->sum_y += ss->bw_data[i];\n\t\t\t}\n\t\t\tss->state |= FIO_SS_BUFFER_FULL;\n\t\t} else {\t\t/* easy to update the sum */\n\t\t\tss->sum_y -= ss->oldest_y;\n\t\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\t\tss->sum_y += ss->iops_data[ss->tail];\n\t\t\telse\n\t\t\t\tss->sum_y += ss->bw_data[ss->tail];\n\t\t}\n\n\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\tss->oldest_y = ss->iops_data[ss->head];\n\t\telse\n\t\t\tss->oldest_y = ss->bw_data[ss->head];\n\n\t\tmean = (double) ss->sum_y / intervals;\n\t\tss->deviation = 0.0;\n\n\t\tfor (i = 0; i < intervals; i++) {\n\t\t\tif (ss->state & FIO_SS_IOPS)\n\t\t\t\tdiff = ss->iops_data[i] - mean;\n\t\t\telse\n\t\t\t\tdiff = ss->bw_data[i] - mean;\n\t\t\tss->deviation = max(ss->deviation, diff * (diff < 0.0 ? -1.0 : 1.0));\n\t\t}\n\n\t\tif (ss->state & FIO_SS_PCT)\n\t\t\tss->criterion = 100.0 * ss->deviation / mean;\n\t\telse\n\t\t\tss->criterion = ss->deviation;\n\n\t\tdprint(FD_STEADYSTATE, \"intervals: %d, sum_y: %llu, mean: %f, max diff: %f, \"\n\t\t\t\t\t\"objective: %f, limit: %f\\n\",\n\t\t\t\t\tintervals,\n\t\t\t\t\t(unsigned long long) ss->sum_y, mean,\n\t\t\t\t\tss->deviation, ss->criterion, ss->limit);\n\n\t\tif (ss->criterion < ss->limit)\n\t\t\treturn true;\n\t}\n\n\tss->tail = (ss->tail + 1) % intervals;\n\tif (ss->tail == ss->head)\n\t\tss->head = (ss->head + 1) % intervals;\n\n\treturn false;\n}\n\nint steadystate_check(void)\n{\n\tint  ddir, prev_groupid, group_ramp_time_over = 0;\n\tunsigned long rate_time;\n\tstruct timespec now;\n\tuint64_t group_bw = 0, group_iops = 0;\n\tuint64_t td_iops, td_bytes;\n\tbool ret;\n\n\tprev_groupid = -1;\n\tfor_each_td(td) {\n\t\tconst bool needs_lock = td_async_processing(td);\n\t\tstruct steadystate_data *ss = &td->ss;\n\n\t\tif (!ss->dur || td->runstate <= TD_SETTING_UP ||\n\t\t    td->runstate >= TD_EXITED || !ss->state ||\n\t\t    ss->state & FIO_SS_ATTAINED)\n\t\t\tcontinue;\n\n\t\ttd_iops = 0;\n\t\ttd_bytes = 0;\n\t\tif (!td->o.group_reporting ||\n\t\t    (td->o.group_reporting && td->groupid != prev_groupid)) {\n\t\t\tgroup_bw = 0;\n\t\t\tgroup_iops = 0;\n\t\t\tgroup_ramp_time_over = 0;\n\t\t}\n\t\tprev_groupid = td->groupid;\n\n\t\tfio_gettime(&now, NULL);\n\t\tif (ss->ramp_time && !(ss->state & FIO_SS_RAMP_OVER)) {\n\t\t\t/*\n\t\t\t * Begin recording data one check interval after ss->ramp_time\n\t\t\t * has elapsed\n\t\t\t */\n\t\t\tif (utime_since(&td->epoch, &now) >= (ss->ramp_time + ss_check_interval * 1000L))\n\t\t\t\tss->state |= FIO_SS_RAMP_OVER;\n\t\t}\n\n\t\tif (needs_lock)\n\t\t\t__td_io_u_lock(td);\n\n\t\tfor (ddir = 0; ddir < DDIR_RWDIR_CNT; ddir++) {\n\t\t\ttd_iops += td->io_blocks[ddir];\n\t\t\ttd_bytes += td->io_bytes[ddir];\n\t\t}\n\n\t\tif (needs_lock)\n\t\t\t__td_io_u_unlock(td);\n\n\t\trate_time = mtime_since(&ss->prev_time, &now);\n\t\tmemcpy(&ss->prev_time, &now, sizeof(now));\n\n\t\tif (ss->state & FIO_SS_RAMP_OVER) {\n\t\t\tgroup_bw += rate_time * (td_bytes - ss->prev_bytes) /\n\t\t\t\t(ss_check_interval * ss_check_interval / 1000L);\n\t\t\tgroup_iops += rate_time * (td_iops - ss->prev_iops) /\n\t\t\t\t(ss_check_interval * ss_check_interval / 1000L);\n\t\t\t++group_ramp_time_over;\n\t\t}\n\t\tss->prev_iops = td_iops;\n\t\tss->prev_bytes = td_bytes;\n\n\t\tif (td->o.group_reporting && !(ss->state & FIO_SS_DATA))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Don't begin checking criterion until ss->ramp_time is over\n\t\t * for at least one thread in group\n\t\t */\n\t\tif (!group_ramp_time_over)\n\t\t\tcontinue;\n\n\t\tdprint(FD_STEADYSTATE, \"steadystate_check() thread: %d, \"\n\t\t\t\t\t\"groupid: %u, rate_msec: %ld, \"\n\t\t\t\t\t\"iops: %llu, bw: %llu, head: %d, tail: %d\\n\",\n\t\t\t\t\t__td_index, td->groupid, rate_time,\n\t\t\t\t\t(unsigned long long) group_iops,\n\t\t\t\t\t(unsigned long long) group_bw,\n\t\t\t\t\tss->head, ss->tail);\n\n\t\tif (ss->state & FIO_SS_SLOPE)\n\t\t\tret = steadystate_slope(group_iops, group_bw, td);\n\t\telse\n\t\t\tret = steadystate_deviation(group_iops, group_bw, td);\n\n\t\tif (ret) {\n\t\t\tif (td->o.group_reporting) {\n\t\t\t\tfor_each_td(td2) {\n\t\t\t\t\tif (td2->groupid == td->groupid) {\n\t\t\t\t\t\ttd2->ss.state |= FIO_SS_ATTAINED;\n\t\t\t\t\t\tfio_mark_td_terminate(td2);\n\t\t\t\t\t}\n\t\t\t\t} end_for_each();\n\t\t\t} else {\n\t\t\t\tss->state |= FIO_SS_ATTAINED;\n\t\t\t\tfio_mark_td_terminate(td);\n\t\t\t}\n\t\t}\n\t} end_for_each();\n\treturn 0;\n}\n\nint td_steadystate_init(struct thread_data *td)\n{\n\tstruct steadystate_data *ss = &td->ss;\n\tstruct thread_options *o = &td->o;\n\tint intervals;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tif (o->ss_dur) {\n\t\tsteadystate_enabled = true;\n\t\to->ss_dur /= 1000000L;\n\n\t\t/* put all steady state info in one place */\n\t\tss->dur = o->ss_dur;\n\t\tss->limit = o->ss_limit.u.f;\n\t\tss->ramp_time = o->ss_ramp_time;\n\t\tss_check_interval = o->ss_check_interval / 1000L;\n\n\t\tss->state = o->ss_state;\n\t\tif (!td->ss.ramp_time)\n\t\t\tss->state |= FIO_SS_RAMP_OVER;\n\n\t\tintervals = ss->dur / (ss_check_interval / 1000L);\n\t\tss->sum_x = intervals * (intervals - 1) / 2;\n\t\tss->sum_x_sq = (intervals - 1) * (intervals) * (2*intervals - 1) / 6;\n\t}\n\n\t/* make sure that ss options are consistent within reporting group */\n\tfor_each_td(td2) {\n\t\tif (td2->groupid == td->groupid) {\n\t\t\tstruct steadystate_data *ss2 = &td2->ss;\n\n\t\t\tif (ss2->dur != ss->dur ||\n\t\t\t    ss2->limit != ss->limit ||\n\t\t\t    ss2->ramp_time != ss->ramp_time ||\n\t\t\t    ss2->state != ss->state ||\n\t\t\t    ss2->sum_x != ss->sum_x ||\n\t\t\t    ss2->sum_x_sq != ss->sum_x_sq) {\n\t\t\t\ttd_verror(td, EINVAL, \"job rejected: steadystate options must be consistent within reporting groups\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t} end_for_each();\n\n\treturn 0;\n}\n\nuint64_t steadystate_bw_mean(struct thread_stat *ts)\n{\n\tint i;\n\tuint64_t sum;\n\tint intervals = ts->ss_dur / (ss_check_interval / 1000L);\n\t\n\tif (!ts->ss_dur)\n\t\treturn 0;\n\n\tfor (i = 0, sum = 0; i < intervals; i++)\n\t\tsum += ts->ss_bw_data[i];\n\n\treturn sum / intervals;\n}\n\nuint64_t steadystate_iops_mean(struct thread_stat *ts)\n{\n\tint i;\n\tuint64_t sum;\n\tint intervals = ts->ss_dur / (ss_check_interval / 1000L);\n\n\tif (!ts->ss_dur)\n\t\treturn 0;\n\n\tfor (i = 0, sum = 0; i < intervals; i++)\n\t\tsum += ts->ss_iops_data[i];\n\n\treturn sum / intervals;\n}\n"
        },
        {
          "name": "steadystate.h",
          "type": "blob",
          "size": 1.4267578125,
          "content": "#ifndef FIO_STEADYSTATE_H\n#define FIO_STEADYSTATE_H\n\n#include \"thread_options.h\"\n\nextern void steadystate_free(struct thread_data *);\nextern int steadystate_check(void);\nextern void steadystate_setup(void);\nextern int td_steadystate_init(struct thread_data *);\nextern uint64_t steadystate_bw_mean(struct thread_stat *);\nextern uint64_t steadystate_iops_mean(struct thread_stat *);\n\nextern bool steadystate_enabled;\nextern unsigned int ss_check_interval;\n\nstruct steadystate_data {\n\tdouble limit;\n\tunsigned long long dur;\n\tunsigned long long ramp_time;\n\n\tuint32_t state;\n\n\tunsigned int head;\n\tunsigned int tail;\n\tuint64_t *iops_data;\n\tuint64_t *bw_data;\n\n\tdouble slope;\n\tdouble deviation;\n\tdouble criterion;\n\n\tuint64_t sum_y;\n\tuint64_t sum_x;\n\tuint64_t sum_x_sq;\n\tuint64_t sum_xy;\n\tuint64_t oldest_y;\n\n\tstruct timespec prev_time;\n\tuint64_t prev_iops;\n\tuint64_t prev_bytes;\n};\n\nenum {\n\t__FIO_SS_IOPS = 0,\n\t__FIO_SS_BW,\n\t__FIO_SS_SLOPE,\n\t__FIO_SS_ATTAINED,\n\t__FIO_SS_RAMP_OVER,\n\t__FIO_SS_DATA,\n\t__FIO_SS_PCT,\n\t__FIO_SS_BUFFER_FULL,\n};\n\nenum {\n\tFIO_SS_IOPS\t\t= 1 << __FIO_SS_IOPS,\n\tFIO_SS_BW\t\t= 1 << __FIO_SS_BW,\n\tFIO_SS_SLOPE\t\t= 1 << __FIO_SS_SLOPE,\n\tFIO_SS_ATTAINED\t\t= 1 << __FIO_SS_ATTAINED,\n\tFIO_SS_RAMP_OVER\t= 1 << __FIO_SS_RAMP_OVER,\n\tFIO_SS_DATA\t\t= 1 << __FIO_SS_DATA,\n\tFIO_SS_PCT\t\t= 1 << __FIO_SS_PCT,\n\tFIO_SS_BUFFER_FULL\t= 1 << __FIO_SS_BUFFER_FULL,\n\n\tFIO_SS_IOPS_SLOPE\t= FIO_SS_IOPS | FIO_SS_SLOPE,\n\tFIO_SS_BW_SLOPE\t\t= FIO_SS_BW | FIO_SS_SLOPE,\n};\n\n#endif\n"
        },
        {
          "name": "t",
          "type": "tree",
          "content": null
        },
        {
          "name": "td_error.c",
          "type": "blob",
          "size": 0.880859375,
          "content": "#include \"fio.h\"\n#include \"io_ddir.h\"\n#include \"td_error.h\"\n\nstatic int __NON_FATAL_ERR[] = { EIO, EILSEQ };\n\nenum error_type_bit td_error_type(enum fio_ddir ddir, int err)\n{\n\tif (err == EILSEQ)\n\t\treturn ERROR_TYPE_VERIFY_BIT;\n\tif (ddir == DDIR_READ)\n\t\treturn ERROR_TYPE_READ_BIT;\n\treturn ERROR_TYPE_WRITE_BIT;\n}\n\nint td_non_fatal_error(struct thread_data *td, enum error_type_bit etype,\n\t\t       int err)\n{\n\tunsigned int i;\n\n\tif (!td->o.ignore_error[etype]) {\n\t\ttd->o.ignore_error[etype] = __NON_FATAL_ERR;\n\t\ttd->o.ignore_error_nr[etype] = FIO_ARRAY_SIZE(__NON_FATAL_ERR);\n\t}\n\n\tif (!(td->o.continue_on_error & (1 << etype)))\n\t\treturn 0;\n\tfor (i = 0; i < td->o.ignore_error_nr[etype]; i++)\n\t\tif (td->o.ignore_error[etype][i] == err)\n\t\t\treturn 1;\n\n\treturn 0;\n}\n\nvoid update_error_count(struct thread_data *td, int err)\n{\n\ttd->total_err_count++;\n\tif (td->total_err_count == 1)\n\t\ttd->first_error = err;\n}\n"
        },
        {
          "name": "td_error.h",
          "type": "blob",
          "size": 0.7880859375,
          "content": "#ifndef FIO_TD_ERROR_H\n#define FIO_TD_ERROR_H\n\n#include \"io_ddir.h\"\n\n/*\n * What type of errors to continue on when continue_on_error is used,\n * and what type of errors to ignore when ignore_error is used.\n */\nenum error_type_bit {\n\tERROR_TYPE_READ_BIT = 0,\n\tERROR_TYPE_WRITE_BIT = 1,\n\tERROR_TYPE_VERIFY_BIT = 2,\n\tERROR_TYPE_CNT = 3,\n};\n\nenum error_type {\n        ERROR_TYPE_NONE = 0,\n        ERROR_TYPE_READ = 1 << ERROR_TYPE_READ_BIT,\n        ERROR_TYPE_WRITE = 1 << ERROR_TYPE_WRITE_BIT,\n        ERROR_TYPE_VERIFY = 1 << ERROR_TYPE_VERIFY_BIT,\n        ERROR_TYPE_ANY = 0xffff,\n};\n\nenum error_type_bit td_error_type(enum fio_ddir ddir, int err);\nint td_non_fatal_error(struct thread_data *td, enum error_type_bit etype,\n\t\t       int err);\nvoid update_error_count(struct thread_data *td, int err);\n\n#endif\n"
        },
        {
          "name": "thread_options.h",
          "type": "blob",
          "size": 17.5986328125,
          "content": "#ifndef FIO_THREAD_OPTIONS_H\n#define FIO_THREAD_OPTIONS_H\n\n#include \"arch/arch.h\"\n#include \"os/os.h\"\n#include \"options.h\"\n#include \"stat.h\"\n#include \"gettime.h\"\n#include \"lib/ieee754.h\"\n#include \"lib/pattern.h\"\n#include \"td_error.h\"\n\nenum fio_zone_mode {\n\tZONE_MODE_NOT_SPECIFIED\t= 0,\n\tZONE_MODE_NONE\t\t= 1,\n\tZONE_MODE_STRIDED\t= 2, /* perform I/O in one zone at a time */\n\t/* perform I/O across multiple zones simultaneously */\n\tZONE_MODE_ZBD\t\t= 3,\n};\n\n/*\n * What type of allocation to use for io buffers\n */\nenum fio_memtype {\n\tMEM_MALLOC = 0,\t/* ordinary malloc */\n\tMEM_SHM,\t/* use shared memory segments */\n\tMEM_SHMHUGE,\t/* use shared memory segments with huge pages */\n\tMEM_MMAP,\t/* use anonynomous mmap */\n\tMEM_MMAPHUGE,\t/* memory mapped huge file */\n\tMEM_MMAPSHARED, /* use mmap with shared flag */\n\tMEM_CUDA_MALLOC,/* use GPU memory */\n};\n\n/*\n * What mode to use for deduped data generation\n */\nenum dedupe_mode {\n\tDEDUPE_MODE_REPEAT = 0,\n\tDEDUPE_MODE_WORKING_SET = 1,\n};\n\n#define ERROR_STR_MAX\t128\n\n#define BSSPLIT_MAX\t64\n#define ZONESPLIT_MAX\t256\n\nstruct split {\n\tunsigned int nr;\n\tunsigned long long val1[ZONESPLIT_MAX];\n\tunsigned long long val2[ZONESPLIT_MAX];\n};\n\nstruct split_prio {\n\tuint64_t bs;\n\tint32_t prio;\n\tuint32_t perc;\n};\n\nstruct bssplit {\n\tuint64_t bs;\n\tuint32_t perc;\n};\n\nstruct zone_split {\n\tuint8_t access_perc;\n\tuint8_t size_perc;\n\tuint8_t pad[6];\n\tuint64_t size;\n};\n\n#define NR_OPTS_SZ\t(FIO_MAX_OPTS / (8 * sizeof(uint64_t)))\n\n#define OPT_MAGIC\t0x4f50544e\n\nstruct thread_options {\n\tint magic;\n\tuint64_t set_options[NR_OPTS_SZ];\n\tchar *description;\n\tchar *name;\n\tchar *wait_for;\n\tchar *directory;\n\tchar *filename;\n\tchar *filename_format;\n\tchar *opendir;\n\tchar *ioengine;\n\tchar *ioengine_so_path;\n\tchar *mmapfile;\n\tenum td_ddir td_ddir;\n\tunsigned int rw_seq;\n\tunsigned int kb_base;\n\tunsigned int unit_base;\n\tunsigned int ddir_seq_nr;\n\tlong long ddir_seq_add;\n\tunsigned int iodepth;\n\tunsigned int iodepth_low;\n\tunsigned int iodepth_batch;\n\tunsigned int iodepth_batch_complete_min;\n\tunsigned int iodepth_batch_complete_max;\n\tunsigned int serialize_overlap;\n\n\tunsigned int unique_filename;\n\n\tunsigned long long size;\n\tunsigned long long io_size;\n\tunsigned int size_percent;\n\tunsigned int size_nz;\n\tunsigned int io_size_percent;\n\tunsigned int io_size_nz;\n\tunsigned int fill_device;\n\tunsigned int file_append;\n\tunsigned long long file_size_low;\n\tunsigned long long file_size_high;\n\tunsigned long long start_offset;\n\tunsigned long long start_offset_align;\n\tunsigned int start_offset_nz;\n\n\tunsigned long long bs[DDIR_RWDIR_CNT];\n\tunsigned long long ba[DDIR_RWDIR_CNT];\n\tunsigned long long min_bs[DDIR_RWDIR_CNT];\n\tunsigned long long max_bs[DDIR_RWDIR_CNT];\n\tstruct bssplit *bssplit[DDIR_RWDIR_CNT];\n\tunsigned int bssplit_nr[DDIR_RWDIR_CNT];\n\n\tint *ignore_error[ERROR_TYPE_CNT];\n\tunsigned int ignore_error_nr[ERROR_TYPE_CNT];\n\tunsigned int error_dump;\n\n\tunsigned int nr_files;\n\tunsigned int open_files;\n\tenum file_lock_mode file_lock_mode;\n\n\tunsigned int odirect;\n\tunsigned int oatomic;\n\tunsigned int invalidate_cache;\n\tunsigned int create_serialize;\n\tunsigned int create_fsync;\n\tunsigned int create_on_open;\n\tunsigned int create_only;\n\tunsigned int end_fsync;\n\tunsigned int pre_read;\n\tunsigned int sync_io;\n\tunsigned int write_hint;\n\tunsigned int verify;\n\tunsigned int do_verify;\n\tunsigned int verify_interval;\n\tunsigned int verify_offset;\n\tchar *verify_pattern;\n\tunsigned int verify_pattern_bytes;\n\tstruct pattern_fmt verify_fmt[8];\n\tunsigned int verify_fmt_sz;\n\tunsigned int verify_fatal;\n\tunsigned int verify_dump;\n\tunsigned int verify_async;\n\tunsigned long long verify_backlog;\n\tunsigned int verify_batch;\n\tunsigned int experimental_verify;\n\tunsigned int verify_state;\n\tunsigned int verify_state_save;\n\tunsigned int verify_write_sequence;\n\tunsigned int use_thread;\n\tunsigned int unlink;\n\tunsigned int unlink_each_loop;\n\tunsigned int do_disk_util;\n\tunsigned int override_sync;\n\tunsigned int rand_repeatable;\n\tunsigned long long rand_seed;\n\tunsigned int log_avg_msec;\n\tunsigned int log_hist_msec;\n\tunsigned int log_hist_coarseness;\n\tunsigned int log_max;\n\tunsigned int log_offset;\n\tunsigned int log_gz;\n\tunsigned int log_gz_store;\n\tunsigned int log_alternate_epoch;\n\tunsigned int log_alternate_epoch_clock_id;\n\tunsigned int norandommap;\n\tunsigned int softrandommap;\n\tunsigned int bs_unaligned;\n\tunsigned int fsync_on_close;\n\tunsigned int bs_is_seq_rand;\n\n\tunsigned int verify_only;\n\n\tunsigned int random_distribution;\n\tunsigned int exitall_error;\n\n\tstruct zone_split *zone_split[DDIR_RWDIR_CNT];\n\tunsigned int zone_split_nr[DDIR_RWDIR_CNT];\n\n\tfio_fp64_t zipf_theta;\n\tfio_fp64_t pareto_h;\n\tfio_fp64_t gauss_dev;\n\tfio_fp64_t random_center;\n\n\tunsigned int random_generator;\n\n\tunsigned int perc_rand[DDIR_RWDIR_CNT];\n\n\tunsigned int hugepage_size;\n\tunsigned long long rw_min_bs;\n\tunsigned int fsync_blocks;\n\tunsigned int fdatasync_blocks;\n\tunsigned int barrier_blocks;\n\tunsigned long long start_delay;\n\tunsigned long long start_delay_orig;\n\tunsigned long long start_delay_high;\n\tunsigned long long timeout;\n\tunsigned long long ramp_time;\n\tunsigned int ss_state;\n\tfio_fp64_t ss_limit;\n\tunsigned long long ss_dur;\n\tunsigned long long ss_ramp_time;\n\tunsigned long long ss_check_interval;\n\tunsigned int overwrite;\n\tunsigned int bw_avg_time;\n\tunsigned int iops_avg_time;\n\tunsigned int loops;\n\tunsigned long long zone_range;\n\tunsigned long long zone_size;\n\tunsigned long long zone_capacity;\n\tunsigned long long zone_skip;\n\tuint32_t zone_skip_nz;\n\tenum fio_zone_mode zone_mode;\n\tunsigned long long lockmem;\n\tenum fio_memtype mem_type;\n\tunsigned int mem_align;\n\n\tunsigned long long max_latency[DDIR_RWDIR_CNT];\n\n\tunsigned int exit_what;\n\tunsigned int stonewall;\n\tunsigned int new_group;\n\tunsigned int numjobs;\n\tos_cpu_mask_t cpumask;\n\tos_cpu_mask_t verify_cpumask;\n\tos_cpu_mask_t log_gz_cpumask;\n\tunsigned int cpus_allowed_policy;\n\tchar *numa_cpunodes;\n\tunsigned short numa_mem_mode;\n\tunsigned int numa_mem_prefer_node;\n\tchar *numa_memnodes;\n\tunsigned int gpu_dev_id;\n\tunsigned int start_offset_percent;\n\n\tunsigned int iolog;\n\tunsigned int rwmixcycle;\n\tunsigned int rwmix[DDIR_RWDIR_CNT];\n\tunsigned int nice;\n\tunsigned int ioprio;\n\tunsigned int ioprio_class;\n\tunsigned int ioprio_hint;\n\tunsigned int file_service_type;\n\tunsigned int group_reporting;\n\tunsigned int stats;\n\tunsigned int fadvise_hint;\n\tenum fio_fallocate_mode fallocate_mode;\n\tunsigned int zero_buffers;\n\tunsigned int refill_buffers;\n\tunsigned int scramble_buffers;\n\tchar *buffer_pattern;\n\tunsigned int buffer_pattern_bytes;\n\tunsigned int compress_percentage;\n\tunsigned int compress_chunk;\n\tunsigned int dedupe_percentage;\n\tunsigned int dedupe_mode;\n\tunsigned int dedupe_working_set_percentage;\n\tunsigned int dedupe_global;\n\tunsigned int time_based;\n\tunsigned int disable_lat;\n\tunsigned int disable_clat;\n\tunsigned int disable_slat;\n\tunsigned int disable_bw;\n\tunsigned int unified_rw_rep;\n\tunsigned int gtod_reduce;\n\tunsigned int gtod_cpu;\n\tunsigned int job_start_clock_id;\n\tenum fio_cs clocksource;\n\tunsigned int no_stall;\n\tunsigned int trim_percentage;\n\tunsigned int trim_batch;\n\tunsigned int trim_zero;\n\tunsigned long long trim_backlog;\n\tunsigned int clat_percentiles;\n\tunsigned int slat_percentiles;\n\tunsigned int lat_percentiles;\n\tunsigned int percentile_precision;\t/* digits after decimal for percentiles */\n\tfio_fp64_t percentile_list[FIO_IO_U_LIST_MAX_LEN];\n\n\tchar *read_iolog_file;\n\tbool read_iolog_chunked;\n\tchar *write_iolog_file;\n\tchar *merge_blktrace_file;\n\tfio_fp64_t merge_blktrace_scalars[FIO_IO_U_LIST_MAX_LEN];\n\tfio_fp64_t merge_blktrace_iters[FIO_IO_U_LIST_MAX_LEN];\n\n\tunsigned int write_bw_log;\n\tunsigned int write_lat_log;\n\tunsigned int write_iops_log;\n\tunsigned int write_hist_log;\n\n\tchar *bw_log_file;\n\tchar *lat_log_file;\n\tchar *iops_log_file;\n\tchar *hist_log_file;\n\tchar *replay_redirect;\n\n\t/*\n\t * Pre-run and post-run shell\n\t */\n\tchar *exec_prerun;\n\tchar *exec_postrun;\n\n\tunsigned int thinkcycles;\n\n\tunsigned int thinktime;\n\tunsigned int thinktime_spin;\n\tunsigned int thinktime_blocks;\n\tunsigned int thinktime_blocks_type;\n\tunsigned int thinktime_iotime;\n\n\tuint64_t rate[DDIR_RWDIR_CNT];\n\tuint64_t ratemin[DDIR_RWDIR_CNT];\n\tunsigned int ratecycle;\n\tunsigned int io_submit_mode;\n\tunsigned int rate_iops[DDIR_RWDIR_CNT];\n\tunsigned int rate_iops_min[DDIR_RWDIR_CNT];\n\tunsigned int rate_process;\n\tunsigned int rate_ign_think;\n\n\tchar *ioscheduler;\n\n\t/*\n\t * I/O Error handling\n\t */\n\tenum error_type continue_on_error;\n\n\t/*\n\t * Benchmark profile type\n\t */\n\tchar *profile;\n\n\t/*\n\t * blkio cgroup support\n\t */\n\tchar *cgroup;\n\tunsigned int cgroup_weight;\n\tunsigned int cgroup_nodelete;\n\n\tunsigned int uid;\n\tunsigned int gid;\n\n\tunsigned int offset_increment_percent;\n\tunsigned int offset_increment_nz;\n\tunsigned long long offset_increment;\n\tunsigned long long number_ios;\n\n\tunsigned int num_range;\n\n\tunsigned int sync_file_range;\n\n\tunsigned long long latency_target;\n\tunsigned long long latency_window;\n\tuint32_t latency_run;\n\tfio_fp64_t latency_percentile;\n\n\t/*\n\t * flow support\n\t */\n\tint flow_id;\n\tunsigned int flow;\n\tunsigned int flow_sleep;\n\n\tunsigned int sig_figs;\n\n\tunsigned block_error_hist;\n\n\tunsigned int replay_align;\n\tunsigned int replay_scale;\n\tunsigned int replay_time_scale;\n\tunsigned int replay_skip;\n\n\tunsigned int per_job_logs;\n\n\tunsigned int allow_create;\n\tunsigned int allow_mounted_write;\n\n\t/* Parameters that affect zonemode=zbd */\n\tunsigned int read_beyond_wp;\n\tint max_open_zones;\n\tunsigned int job_max_open_zones;\n\tunsigned int ignore_zone_limits;\n\tfio_fp64_t zrt;\n\tfio_fp64_t zrf;\n\n\tunsigned int fdp;\n\tunsigned int dp_type;\n\tunsigned int dp_id_select;\n\tuint16_t dp_ids[FIO_MAX_DP_IDS];\n\tunsigned int dp_nr_ids;\n\tchar *dp_scheme_file;\n\n\tunsigned int log_entries;\n\tunsigned int log_prio;\n\tunsigned int log_issue_time;\n};\n\n#define FIO_TOP_STR_MAX\t\t256\n\nstruct thread_options_pack {\n\tuint64_t set_options[NR_OPTS_SZ];\n\tuint8_t description[FIO_TOP_STR_MAX];\n\tuint8_t name[FIO_TOP_STR_MAX];\n\tuint8_t wait_for[FIO_TOP_STR_MAX];\n\tuint8_t directory[FIO_TOP_STR_MAX];\n\tuint8_t filename[FIO_TOP_STR_MAX];\n\tuint8_t filename_format[FIO_TOP_STR_MAX];\n\tuint8_t opendir[FIO_TOP_STR_MAX];\n\tuint8_t ioengine[FIO_TOP_STR_MAX];\n\tuint8_t mmapfile[FIO_TOP_STR_MAX];\n\tuint32_t td_ddir;\n\tuint32_t rw_seq;\n\tuint32_t kb_base;\n\tuint32_t unit_base;\n\tuint32_t ddir_seq_nr;\n\tuint64_t ddir_seq_add;\n\tuint32_t iodepth;\n\tuint32_t iodepth_low;\n\tuint32_t iodepth_batch;\n\tuint32_t iodepth_batch_complete_min;\n\tuint32_t iodepth_batch_complete_max;\n\tuint32_t serialize_overlap;\n\n\tuint64_t size;\n\tuint64_t io_size;\n\tuint32_t size_percent;\n\tuint32_t size_nz;\n\tuint32_t io_size_percent;\n\tuint32_t io_size_nz;\n\tuint32_t fill_device;\n\tuint32_t file_append;\n\tuint32_t unique_filename;\n\tuint64_t file_size_low;\n\tuint64_t file_size_high;\n\tuint64_t start_offset;\n\tuint64_t start_offset_align;\n\tuint32_t start_offset_nz;\n\n\tuint64_t bs[DDIR_RWDIR_CNT];\n\tuint64_t ba[DDIR_RWDIR_CNT];\n\tuint64_t min_bs[DDIR_RWDIR_CNT];\n\tuint64_t max_bs[DDIR_RWDIR_CNT];\n\tstruct bssplit bssplit[DDIR_RWDIR_CNT][BSSPLIT_MAX];\n\tuint32_t bssplit_nr[DDIR_RWDIR_CNT];\n\n\tuint32_t ignore_error[ERROR_TYPE_CNT][ERROR_STR_MAX];\n\tuint32_t ignore_error_nr[ERROR_TYPE_CNT];\n\tuint32_t error_dump;\n\n\tuint32_t nr_files;\n\tuint32_t open_files;\n\tuint32_t file_lock_mode;\n\n\tuint32_t odirect;\n\tuint32_t oatomic;\n\tuint32_t invalidate_cache;\n\tuint32_t create_serialize;\n\tuint32_t create_fsync;\n\tuint32_t create_on_open;\n\tuint32_t create_only;\n\tuint32_t end_fsync;\n\tuint32_t pre_read;\n\tuint32_t sync_io;\n\tuint32_t write_hint;\n\tuint32_t verify;\n\tuint32_t do_verify;\n\tuint32_t verify_interval;\n\tuint32_t verify_offset;\n\tuint32_t verify_pattern_bytes;\n\tuint32_t verify_fatal;\n\tuint32_t verify_dump;\n\tuint32_t verify_async;\n\tuint64_t verify_backlog;\n\tuint32_t verify_batch;\n\tuint32_t experimental_verify;\n\tuint32_t verify_state;\n\tuint32_t verify_state_save;\n\tuint32_t use_thread;\n\tuint32_t unlink;\n\tuint32_t unlink_each_loop;\n\tuint32_t do_disk_util;\n\tuint32_t override_sync;\n\tuint32_t rand_repeatable;\n\tuint64_t rand_seed;\n\tuint32_t log_avg_msec;\n\tuint32_t log_hist_msec;\n\tuint32_t log_hist_coarseness;\n\tuint32_t log_max;\n\tuint32_t log_offset;\n\tuint32_t log_gz;\n\tuint32_t log_gz_store;\n\tuint32_t log_alternate_epoch;\n\tuint32_t log_alternate_epoch_clock_id;\n\tuint32_t norandommap;\n\tuint32_t softrandommap;\n\tuint32_t bs_unaligned;\n\tuint32_t fsync_on_close;\n\tuint32_t bs_is_seq_rand;\n\n\tuint32_t random_distribution;\n\tuint32_t exitall_error;\n\n\tuint32_t sync_file_range;\n\n\tstruct zone_split zone_split[DDIR_RWDIR_CNT][ZONESPLIT_MAX];\n\tuint32_t zone_split_nr[DDIR_RWDIR_CNT];\n\n\tfio_fp64_t zipf_theta;\n\tfio_fp64_t pareto_h;\n\tfio_fp64_t gauss_dev;\n\tfio_fp64_t random_center;\n\n\tuint32_t random_generator;\n\n\tuint32_t perc_rand[DDIR_RWDIR_CNT];\n\n\tuint32_t hugepage_size;\n\tuint64_t rw_min_bs;\n\tuint32_t fsync_blocks;\n\tuint32_t fdatasync_blocks;\n\tuint32_t barrier_blocks;\n\tuint64_t start_delay;\n\tuint64_t start_delay_high;\n\tuint64_t timeout;\n\tuint64_t ramp_time;\n\tuint64_t ss_dur;\n\tuint64_t ss_ramp_time;\n\tuint32_t ss_state;\n\tfio_fp64_t ss_limit;\n\tuint64_t ss_check_interval;\n\tuint32_t overwrite;\n\tuint32_t bw_avg_time;\n\tuint32_t iops_avg_time;\n\tuint32_t loops;\n\tuint64_t zone_range;\n\tuint64_t zone_size;\n\tuint64_t zone_capacity;\n\tuint64_t zone_skip;\n\tuint64_t lockmem;\n\tuint32_t zone_skip_nz;\n\tuint32_t mem_type;\n\tuint32_t mem_align;\n\n\tuint32_t exit_what;\n\tuint32_t stonewall;\n\tuint32_t new_group;\n\tuint32_t numjobs;\n\n\t/*\n\t * We currently can't convert these, so don't enable them\n\t */\n#if 0\n\tuint8_t cpumask[FIO_TOP_STR_MAX];\n\tuint8_t verify_cpumask[FIO_TOP_STR_MAX];\n\tuint8_t log_gz_cpumask[FIO_TOP_STR_MAX];\n#endif\n\tuint32_t gpu_dev_id;\n\tuint32_t start_offset_percent;\n\tuint32_t cpus_allowed_policy;\n\tuint32_t iolog;\n\tuint32_t rwmixcycle;\n\tuint32_t rwmix[DDIR_RWDIR_CNT];\n\tuint32_t nice;\n\tuint32_t ioprio;\n\tuint32_t ioprio_class;\n\tuint32_t ioprio_hint;\n\tuint32_t file_service_type;\n\tuint32_t group_reporting;\n\tuint32_t stats;\n\tuint32_t fadvise_hint;\n\tuint32_t fallocate_mode;\n\tuint32_t zero_buffers;\n\tuint32_t refill_buffers;\n\tuint32_t scramble_buffers;\n\tuint32_t buffer_pattern_bytes;\n\tuint32_t compress_percentage;\n\tuint32_t compress_chunk;\n\tuint32_t dedupe_percentage;\n\tuint32_t dedupe_mode;\n\tuint32_t dedupe_working_set_percentage;\n\tuint32_t dedupe_global;\n\tuint32_t time_based;\n\tuint32_t disable_lat;\n\tuint32_t disable_clat;\n\tuint32_t disable_slat;\n\tuint32_t disable_bw;\n\tuint32_t unified_rw_rep;\n\tuint32_t gtod_reduce;\n\tuint32_t gtod_cpu;\n\tuint32_t job_start_clock_id;\n\tuint32_t clocksource;\n\tuint32_t no_stall;\n\tuint32_t trim_percentage;\n\tuint32_t trim_batch;\n\tuint32_t trim_zero;\n\tuint64_t trim_backlog;\n\tuint32_t clat_percentiles;\n\tuint32_t lat_percentiles;\n\tuint32_t slat_percentiles;\n\tuint32_t percentile_precision;\n\tuint32_t pad;\n\tfio_fp64_t percentile_list[FIO_IO_U_LIST_MAX_LEN];\n\n\tuint8_t read_iolog_file[FIO_TOP_STR_MAX];\n\tuint8_t write_iolog_file[FIO_TOP_STR_MAX];\n\tuint8_t merge_blktrace_file[FIO_TOP_STR_MAX];\n\tfio_fp64_t merge_blktrace_scalars[FIO_IO_U_LIST_MAX_LEN];\n\tfio_fp64_t merge_blktrace_iters[FIO_IO_U_LIST_MAX_LEN];\n\n\tuint32_t write_bw_log;\n\tuint32_t write_lat_log;\n\tuint32_t write_iops_log;\n\tuint32_t write_hist_log;\n\n\tuint8_t bw_log_file[FIO_TOP_STR_MAX];\n\tuint8_t lat_log_file[FIO_TOP_STR_MAX];\n\tuint8_t iops_log_file[FIO_TOP_STR_MAX];\n\tuint8_t hist_log_file[FIO_TOP_STR_MAX];\n\tuint8_t replay_redirect[FIO_TOP_STR_MAX];\n\n\t/*\n\t * Pre-run and post-run shell\n\t */\n\tuint8_t exec_prerun[FIO_TOP_STR_MAX];\n\tuint8_t exec_postrun[FIO_TOP_STR_MAX];\n\n\tuint32_t thinkcycles;\n\n\tuint32_t thinktime;\n\tuint32_t thinktime_spin;\n\tuint32_t thinktime_blocks;\n\tuint32_t thinktime_blocks_type;\n\tuint32_t thinktime_iotime;\n\n\tuint64_t rate[DDIR_RWDIR_CNT];\n\tuint64_t ratemin[DDIR_RWDIR_CNT];\n\tuint32_t ratecycle;\n\tuint32_t io_submit_mode;\n\tuint32_t rate_iops[DDIR_RWDIR_CNT];\n\tuint32_t rate_iops_min[DDIR_RWDIR_CNT];\n\tuint32_t rate_process;\n\tuint32_t rate_ign_think;\n\n\tuint8_t ioscheduler[FIO_TOP_STR_MAX];\n\n\t/*\n\t * I/O Error handling\n\t */\n\tuint32_t continue_on_error;\n\n\t/*\n\t * Benchmark profile type\n\t */\n\tuint8_t profile[FIO_TOP_STR_MAX];\n\n\t/*\n\t * blkio cgroup support\n\t */\n\tuint8_t cgroup[FIO_TOP_STR_MAX];\n\tuint32_t cgroup_weight;\n\tuint32_t cgroup_nodelete;\n\n\tuint32_t uid;\n\tuint32_t gid;\n\n\tuint32_t offset_increment_percent;\n\tuint32_t offset_increment_nz;\n\tuint64_t offset_increment;\n\tuint64_t number_ios;\n\n\tuint64_t latency_target;\n\tuint64_t latency_window;\n\tuint64_t max_latency[DDIR_RWDIR_CNT];\n\tuint32_t latency_run;\n\tfio_fp64_t latency_percentile;\n\n\t/*\n\t * flow support\n\t */\n\tint32_t flow_id;\n\tuint32_t flow;\n\tuint32_t flow_sleep;\n\n\tuint32_t sig_figs;\n\n\tuint32_t block_error_hist;\n\n\tuint32_t replay_align;\n\tuint32_t replay_scale;\n\tuint32_t replay_time_scale;\n\tuint32_t replay_skip;\n\n\tuint32_t per_job_logs;\n\n\tuint32_t allow_create;\n\tuint32_t allow_mounted_write;\n\n\tuint32_t zone_mode;\n\tint32_t max_open_zones;\n\tuint32_t ignore_zone_limits;\n\n\tuint32_t log_entries;\n\tuint32_t log_prio;\n\tuint32_t log_issue_time;\n\n\tuint32_t fdp;\n\tuint32_t dp_type;\n\tuint32_t dp_id_select;\n\tuint16_t dp_ids[FIO_MAX_DP_IDS];\n\tuint32_t dp_nr_ids;\n\tuint8_t dp_scheme_file[FIO_TOP_STR_MAX];\n\n\tuint32_t num_range;\n\t/*\n\t * verify_pattern followed by buffer_pattern from the unpacked struct\n\t */\n\tuint8_t patterns[];\n} __attribute__((packed));\n\nextern int convert_thread_options_to_cpu(struct thread_options *o,\n\t\tstruct thread_options_pack *top, size_t top_sz);\nextern size_t thread_options_pack_size(struct thread_options *o);\nextern void convert_thread_options_to_net(struct thread_options_pack *top, struct thread_options *);\nextern int fio_test_cconv(struct thread_options *);\nextern void options_default_fill(struct thread_options *o);\n\ntypedef int (split_parse_fn)(struct thread_options *, void *,\n\t\t\t     enum fio_ddir, char *, bool);\n\nextern int str_split_parse(struct thread_data *td, char *str,\n\t\t\t   split_parse_fn *fn, void *eo, bool data);\n\nextern int split_parse_ddir(struct thread_options *o, struct split *split,\n\t\t\t    char *str, bool absolute, unsigned int max_splits);\n\nextern int split_parse_prio_ddir(struct thread_options *o,\n\t\t\t\t struct split_prio **entries, int *nr_entries,\n\t\t\t\t char *str);\n\n#endif\n"
        },
        {
          "name": "tickmarks.c",
          "type": "blob",
          "size": 3.162109375,
          "content": "#include <stdio.h>\n#include <math.h>\n#include <stdlib.h>\n#include <string.h>\n\n/*\n * adapted from Paul Heckbert's algorithm on p 657-659 of\n * Andrew S. Glassner's book, \"Graphics Gems\"\n * ISBN 0-12-286166-3\n *\n */\n\n#include \"tickmarks.h\"\n\n#define MAX(a, b) (((a) < (b)) ? (b) : (a))\n\nstatic double nicenum(double x, int round)\n{\n\tint exp;\t/* exponent of x */\n\tdouble f;\t/* fractional part of x */\n\n\texp = floor(log10(x));\n\tf = x / pow(10.0, exp);\n\tif (round) {\n\t\tif (f < 1.5)\n\t\t\treturn 1.0 * pow(10.0, exp);\n\t\tif (f < 3.0)\n\t\t\treturn 2.0 * pow(10.0, exp);\n\t\tif (f < 7.0)\n\t\t\treturn 5.0 * pow(10.0, exp);\n\t\treturn 10.0 * pow(10.0, exp);\n\t}\n\tif (f <= 1.0)\n\t\treturn 1.0 * pow(10.0, exp);\n\tif (f <= 2.0)\n\t\treturn 2.0 * pow(10.0, exp);\n\tif (f <= 5.0)\n\t\treturn 5.0 * pow(10.0, exp);\n\treturn 10.0 * pow(10.0, exp);\n}\n\nstatic void shorten(struct tickmark *tm, int nticks, int *power_of_ten,\n\t\t\tint use_KMG_symbols, int base_offset)\n{\n\tconst char shorten_chr[] = { 0, 'K', 'M', 'G', 'P', 'E', 0 };\n\tint i, l, minshorten, shorten_idx = 0;\n\tchar *str;\n\n\tminshorten = 100;\n\tfor (i = 0; i < nticks; i++) {\n\t\tstr = tm[i].string;\n\t\tl = strlen(str);\n\n\t\tif (strcmp(str, \"0\") == 0)\n\t\t\tcontinue;\n\t\tif (l > 9 && strcmp(&str[l - 9], \"000000000\") == 0) {\n\t\t\t*power_of_ten = 9;\n\t\t\tshorten_idx = 3;\n\t\t} else if (6 < minshorten && l > 6 &&\n\t\t\t\tstrcmp(&str[l - 6], \"000000\") == 0) {\n\t\t\t*power_of_ten = 6;\n\t\t\tshorten_idx = 2;\n\t\t} else if (l > 3 && strcmp(&str[l - 3], \"000\") == 0) {\n\t\t\t*power_of_ten = 3;\n\t\t\tshorten_idx = 1;\n\t\t} else {\n\t\t\t*power_of_ten = 0;\n\t\t}\n\n\t\tif (*power_of_ten < minshorten)\n\t\t\tminshorten = *power_of_ten;\n\t}\n\n\tif (minshorten == 0)\n\t\treturn;\n\tif (!use_KMG_symbols)\n\t\tshorten_idx = 0;\n\telse if (base_offset)\n\t\tshorten_idx += base_offset;\n\n\tfor (i = 0; i < nticks; i++) {\n\t\tstr = tm[i].string;\n\t\tl = strlen(str);\n\t\tstr[l - minshorten] = shorten_chr[shorten_idx];\n\t\tif (shorten_idx)\n\t\t\tstr[l - minshorten + 1] = '\\0';\n\t}\n}\n\nint calc_tickmarks(double min, double max, int nticks, struct tickmark **tm,\n\t\tint *power_of_ten, int use_KMG_symbols, int base_offset)\n{\n\tchar str[100];\n\tint nfrac;\n\tdouble d;\t/* tick mark spacing */\n\tdouble graphmin, graphmax;\t/* graph range min and max */\n\tdouble range, x;\n\tint count, i;\n\n\t/* we expect min != max */\n\trange = nicenum(max - min, 0);\n\td = nicenum(range / (nticks - 1), 1);\n\tgraphmin = floor(min / d) * d;\n\tgraphmax = ceil(max / d) * d;\n\tnfrac = MAX(-floor(log10(d)), 0);\n\tsnprintf(str, sizeof(str)-1, \"%%.%df\", nfrac);\n\n\tcount = ((graphmax + 0.5 * d) - graphmin) / d + 1;\n\t*tm = malloc(sizeof(**tm) * count);\n\n\ti = 0;\n\tfor (x = graphmin; x < graphmax + 0.5 * d; x += d) {\n\t\t(*tm)[i].value = x;\n\t\tsprintf((*tm)[i].string, str, x);\n\t\ti++;\n\t}\n\tshorten(*tm, i, power_of_ten, use_KMG_symbols, base_offset);\n\treturn i;\n}\n\n#if 0\n\nstatic void test_range(double x, double y)\n{\n\tint nticks, i;\n\n\tstruct tickmark *tm = NULL;\n\tprintf(\"Testing range %g - %g\\n\", x, y);\n\tnticks = calc_tickmarks(x, y, 10, &tm);\n\n\tfor (i = 0; i < nticks; i++)\n\t\tprintf(\"   (%s) %g\\n\", tm[i].string, tm[i].value);\n\n\tprintf(\"\\n\\n\");\n\tfree(tm);\n}\n\nint main(int argc, char *argv[])\n{\n\ttest_range(0.0005, 0.008);\n\ttest_range(0.5, 0.8);\n\ttest_range(5.5, 8.8);\n\ttest_range(50.5, 80.8);\n\ttest_range(-20, 20.8);\n\ttest_range(-30, 700.8);\n}\n#endif\n"
        },
        {
          "name": "tickmarks.h",
          "type": "blob",
          "size": 0.2333984375,
          "content": "#ifndef TICKMARKS_H\n#define TICKMARKS_H\n\nstruct tickmark {\n\tdouble value;\n\tchar string[20];\n};\n\nint calc_tickmarks(double min, double max, int nticks, struct tickmark **tm,\n\t\t\tint *power_of_ten, int use_KMG_symbols, int base_off);\n\n#endif\n"
        },
        {
          "name": "time.c",
          "type": "blob",
          "size": 3.81640625,
          "content": "#include <time.h>\n#include <sys/time.h>\n\n#include \"fio.h\"\n\nstatic struct timespec genesis;\nstatic unsigned long ns_granularity;\n\nvoid timespec_add_msec(struct timespec *ts, unsigned int msec)\n{\n\tuint64_t adj_nsec = 1000000ULL * msec;\n\n\tts->tv_nsec += adj_nsec;\n\tif (adj_nsec >= 1000000000) {\n\t\tuint64_t adj_sec = adj_nsec / 1000000000;\n\n\t\tts->tv_nsec -= adj_sec * 1000000000;\n\t\tts->tv_sec += adj_sec;\n\t}\n\tif (ts->tv_nsec >= 1000000000){\n\t\tts->tv_nsec -= 1000000000;\n\t\tts->tv_sec++;\n\t}\n}\n\n/*\n * busy looping version for the last few usec\n */\nuint64_t usec_spin(unsigned int usec)\n{\n\tstruct timespec start;\n\tuint64_t t;\n\n\tfio_gettime(&start, NULL);\n\twhile ((t = utime_since_now(&start)) < usec)\n\t\tnop;\n\n\treturn t;\n}\n\n/*\n * busy loop for a fixed amount of cycles\n */\nvoid cycles_spin(unsigned int n)\n{\n\tunsigned long i;\n\n\tfor (i=0; i < n; i++)\n\t\tnop;\n}\n\nuint64_t usec_sleep(struct thread_data *td, unsigned long usec)\n{\n\tstruct timespec req;\n\tstruct timespec tv;\n\tuint64_t t = 0;\n\n\tdo {\n\t\tunsigned long ts = usec;\n\n\t\tif (usec < ns_granularity) {\n\t\t\tt += usec_spin(usec);\n\t\t\tbreak;\n\t\t}\n\n\t\tts = usec - ns_granularity;\n\n\t\tif (ts >= 1000000) {\n\t\t\treq.tv_sec = ts / 1000000;\n\t\t\tts -= 1000000 * req.tv_sec;\n\t\t\t/*\n\t\t\t * Limit sleep to ~1 second at most, otherwise we\n\t\t\t * don't notice then someone signaled the job to\n\t\t\t * exit manually.\n\t\t\t */\n\t\t\tif (req.tv_sec > 1)\n\t\t\t\treq.tv_sec = 1;\n\t\t} else\n\t\t\treq.tv_sec = 0;\n\n\t\treq.tv_nsec = ts * 1000;\n\t\tfio_gettime(&tv, NULL);\n\n\t\tif (nanosleep(&req, NULL) < 0)\n\t\t\tbreak;\n\n\t\tts = utime_since_now(&tv);\n\t\tt += ts;\n\t\tif (ts >= usec)\n\t\t\tbreak;\n\n\t\tusec -= ts;\n\t} while (!td->terminate);\n\n\treturn t;\n}\n\nuint64_t time_since_genesis(void)\n{\n\treturn time_since_now(&genesis);\n}\n\nuint64_t mtime_since_genesis(void)\n{\n\treturn mtime_since_now(&genesis);\n}\n\nuint64_t utime_since_genesis(void)\n{\n\treturn utime_since_now(&genesis);\n}\n\nbool in_ramp_time(struct thread_data *td)\n{\n\treturn td->o.ramp_time && !td->ramp_time_over;\n}\n\nstatic bool parent_update_ramp(struct thread_data *td)\n{\n\tstruct thread_data *parent = td->parent;\n\n\tif (!parent || parent->ramp_time_over)\n\t\treturn false;\n\n\treset_all_stats(parent);\n\tparent->ramp_time_over = true;\n\ttd_set_runstate(parent, TD_RAMP);\n\treturn true;\n}\n\nbool ramp_time_over(struct thread_data *td)\n{\n\tif (!td->o.ramp_time || td->ramp_time_over)\n\t\treturn true;\n\n\tif (utime_since_now(&td->epoch) >= td->o.ramp_time) {\n\t\ttd->ramp_time_over = true;\n\t\treset_all_stats(td);\n\t\treset_io_stats(td);\n\t\ttd_set_runstate(td, TD_RAMP);\n\n\t\t/*\n\t\t * If we have a parent, the parent isn't doing IO. Hence\n\t\t * the parent never enters do_io(), which will switch us\n\t\t * from RAMP -> RUNNING. Do this manually here.\n\t\t */\n\t\tif (parent_update_ramp(td))\n\t\t\ttd_set_runstate(td, TD_RUNNING);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nvoid fio_time_init(void)\n{\n\tint i;\n\n\tfio_clock_init();\n\n\t/*\n\t * Check the granularity of the nanosleep function\n\t */\n\tfor (i = 0; i < 10; i++) {\n\t\tstruct timespec tv, ts;\n\t\tunsigned long elapsed;\n\n\t\tfio_gettime(&tv, NULL);\n\t\tts.tv_sec = 0;\n\t\tts.tv_nsec = 1000;\n\n\t\tnanosleep(&ts, NULL);\n\t\telapsed = utime_since_now(&tv);\n\n\t\tif (elapsed > ns_granularity)\n\t\t\tns_granularity = elapsed;\n\t}\n}\n\nvoid set_genesis_time(void)\n{\n\tfio_gettime(&genesis, NULL);\n}\n\nvoid set_epoch_time(struct thread_data *td, clockid_t log_alternate_epoch_clock_id, clockid_t job_start_clock_id)\n{\n\tstruct timespec ts;\n\tfio_gettime(&td->epoch, NULL);\n\tclock_gettime(log_alternate_epoch_clock_id, &ts);\n\ttd->alternate_epoch = (unsigned long long)(ts.tv_sec) * 1000 +\n\t\t\t\t\t\t  (unsigned long long)(ts.tv_nsec) / 1000000;\n\tif (job_start_clock_id == log_alternate_epoch_clock_id)\n\t{\n\t\ttd->job_start = td->alternate_epoch;\n\t}\n\telse\n\t{\n\t\tclock_gettime(job_start_clock_id, &ts);\n\t\ttd->job_start = (unsigned long long)(ts.tv_sec) * 1000 +\n\t\t\t\t\t\t(unsigned long long)(ts.tv_nsec) / 1000000;\n\t}\n}\n\nvoid fill_start_time(struct timespec *t)\n{\n\tmemcpy(t, &genesis, sizeof(genesis));\n}\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "trim.c",
          "type": "blob",
          "size": 1.6728515625,
          "content": "/*\n * TRIM/DISCARD support\n */\n#include <string.h>\n#include <assert.h>\n\n#include \"fio.h\"\n#include \"trim.h\"\n\n#ifdef FIO_HAVE_TRIM\nbool get_next_trim(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct io_piece *ipo;\n\n\t/*\n\t * this io_u is from a requeue, we already filled the offsets\n\t */\n\tif (io_u->file)\n\t\treturn true;\n\tif (flist_empty(&td->trim_list))\n\t\treturn false;\n\n\tassert(td->trim_entries);\n\tipo = flist_first_entry(&td->trim_list, struct io_piece, trim_list);\n\tremove_trim_entry(td, ipo);\n\n\tio_u->offset = ipo->offset;\n\tio_u->buflen = ipo->len;\n\tio_u->file = ipo->file;\n\n\t/*\n\t * If not verifying that trimmed ranges return zeroed data,\n\t * remove this from the to-read verify lists\n\t */\n\tif (!td->o.trim_zero) {\n\t\tif (ipo->flags & IP_F_ONLIST)\n\t\t\tflist_del(&ipo->list);\n\t\telse {\n\t\t\tassert(ipo->flags & IP_F_ONRB);\n\t\t\trb_erase(&ipo->rb_node, &td->io_hist_tree);\n\t\t}\n\t\ttd->io_hist_len--;\n\t\tfree(ipo);\n\t} else\n\t\tipo->flags |= IP_F_TRIMMED;\n\n\tif (!fio_file_open(io_u->file)) {\n\t\tint r = td_io_open_file(td, io_u->file);\n\n\t\tif (r) {\n\t\t\tdprint(FD_VERIFY, \"failed file %s open\\n\",\n\t\t\t\t\tio_u->file->file_name);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tget_file(io_u->file);\n\tassert(fio_file_open(io_u->file));\n\tio_u->ddir = DDIR_TRIM;\n\tio_u->xfer_buf = NULL;\n\tio_u->xfer_buflen = io_u->buflen;\n\n\tdprint(FD_VERIFY, \"get_next_trim: ret io_u %p\\n\", io_u);\n\treturn true;\n}\n\nbool io_u_should_trim(struct thread_data *td, struct io_u *io_u)\n{\n\tunsigned long long val;\n\tuint64_t frand_max;\n\tunsigned long r;\n\n\tif (!td->o.trim_percentage)\n\t\treturn false;\n\n\tfrand_max = rand_max(&td->trim_state);\n\tr = __rand(&td->trim_state);\n\tval = (frand_max / 100ULL);\n\n\tval *= (unsigned long long) td->o.trim_percentage;\n\treturn r <= val;\n}\n#endif\n"
        },
        {
          "name": "trim.h",
          "type": "blob",
          "size": 0.8818359375,
          "content": "#ifndef FIO_TRIM_H\n#define FIO_TRIM_H\n\n#ifdef FIO_HAVE_TRIM\n#include \"flist.h\"\n#include \"iolog.h\"\n#include \"compiler/compiler.h\"\n#include \"lib/types.h\"\n#include \"os/os.h\"\n\nextern bool __must_check get_next_trim(struct thread_data *td, struct io_u *io_u);\nextern bool io_u_should_trim(struct thread_data *td, struct io_u *io_u);\n\n/*\n * Determine whether a given io_u should be logged for verify or\n * for discard\n */\nstatic inline void remove_trim_entry(struct thread_data *td, struct io_piece *ipo)\n{\n\tif (!flist_empty(&ipo->trim_list)) {\n\t\tflist_del_init(&ipo->trim_list);\n\t\ttd->trim_entries--;\n\t}\n}\n\n#else\nstatic inline bool get_next_trim(struct thread_data *td, struct io_u *io_u)\n{\n\treturn false;\n}\nstatic inline bool io_u_should_trim(struct thread_data *td, struct io_u *io_u)\n{\n\treturn false;\n}\nstatic inline void remove_trim_entry(struct thread_data *td, struct io_piece *ipo)\n{\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "unittests",
          "type": "tree",
          "content": null
        },
        {
          "name": "verify-state.h",
          "type": "blob",
          "size": 2.2919921875,
          "content": "#ifndef FIO_VERIFY_STATE_H\n#define FIO_VERIFY_STATE_H\n\n#include <stdint.h>\n#include <string.h>\n#include <limits.h>\n#include \"lib/nowarn_snprintf.h\"\n\nstruct thread_rand32_state {\n\tuint32_t s[4];\n};\n\nstruct thread_rand64_state {\n\tuint64_t s[6];\n};\n\nstruct thread_rand_state {\n\tuint64_t use64;\n\tunion {\n\t\tstruct thread_rand32_state state32;\n\t\tstruct thread_rand64_state state64;\n\t};\n};\n\n/*\n * For dumping current write state\n */\nstruct file_comp {\n\tuint64_t fileno;\n\tuint64_t offset;\n};\n\nstruct thread_io_list {\n\tuint64_t no_comps;\n\tuint32_t depth;\n\tuint32_t nofiles;\n\tuint64_t numberio;\n\tuint64_t index;\n\tstruct thread_rand_state rand;\n\tuint8_t name[64];\n\tstruct file_comp comps[0];\n};\n\nstruct all_io_list {\n\tuint64_t threads;\n\tstruct thread_io_list state[0];\n};\n\n#define VSTATE_HDR_VERSION\t0x03\n\nstruct verify_state_hdr {\n\tuint64_t version;\n\tuint64_t size;\n\tuint64_t crc;\n};\n\n#define IO_LIST_ALL\t\t0xffffffff\n\nstruct io_u;\nextern struct all_io_list *get_all_io_list(int, size_t *);\nextern void __verify_save_state(struct all_io_list *, const char *);\nextern void verify_save_state(int mask);\nextern int verify_load_state(struct thread_data *, const char *);\nextern void verify_free_state(struct thread_data *);\nextern int verify_state_should_stop(struct thread_data *, struct io_u *);\nextern void verify_assign_state(struct thread_data *, void *);\nextern int verify_state_hdr(struct verify_state_hdr *, struct thread_io_list *);\n\nstatic inline size_t __thread_io_list_sz(uint32_t depth, uint32_t nofiles)\n{\n\treturn sizeof(struct thread_io_list) + depth * nofiles * sizeof(struct file_comp);\n}\n\nstatic inline size_t thread_io_list_sz(struct thread_io_list *s)\n{\n\treturn __thread_io_list_sz(le32_to_cpu(s->depth), le32_to_cpu(s->nofiles));\n}\n\nstatic inline struct thread_io_list *io_list_next(struct thread_io_list *s)\n{\n\treturn (struct thread_io_list *)((char *) s + thread_io_list_sz(s));\n}\n\nstatic inline void verify_state_gen_name(char *out, size_t size,\n\t\t\t\t\t const char *name, const char *prefix,\n\t\t\t\t\t int num)\n{\n\tchar ename[PATH_MAX];\n\tchar *ptr;\n\n\t/*\n\t * Escape '/', just turn them into '.'\n\t */\n\tptr = ename;\n\tdo {\n\t\t*ptr = *name;\n\t\tif (*ptr == '\\0')\n\t\t\tbreak;\n\t\telse if (*ptr == '/')\n\t\t\t*ptr = '.';\n\t\tptr++;\n\t\tname++;\n\t} while (1);\n\n\tnowarn_snprintf(out, size, \"%s-%s-%d-verify.state\", prefix, ename, num);\n\tout[size - 1] = '\\0';\n}\n\n#endif\n"
        },
        {
          "name": "verify.c",
          "type": "blob",
          "size": 43.529296875,
          "content": "/*\n * IO verification helpers\n */\n#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n#include <assert.h>\n#include <pthread.h>\n#include <libgen.h>\n\n#include \"arch/arch.h\"\n#include \"fio.h\"\n#include \"verify.h\"\n#include \"trim.h\"\n#include \"lib/rand.h\"\n#include \"lib/hweight.h\"\n#include \"lib/pattern.h\"\n#include \"oslib/asprintf.h\"\n\n#include \"crc/md5.h\"\n#include \"crc/crc64.h\"\n#include \"crc/crc32.h\"\n#include \"crc/crc32c.h\"\n#include \"crc/crc16.h\"\n#include \"crc/crc7.h\"\n#include \"crc/sha256.h\"\n#include \"crc/sha512.h\"\n#include \"crc/sha1.h\"\n#include \"crc/xxhash.h\"\n#include \"crc/sha3.h\"\n\nstatic void populate_hdr(struct thread_data *td, struct io_u *io_u,\n\t\t\t struct verify_header *hdr, unsigned int header_num,\n\t\t\t unsigned int header_len);\nstatic void __fill_hdr(struct thread_data *td, struct io_u *io_u,\n\t\t       struct verify_header *hdr, unsigned int header_num,\n\t\t       unsigned int header_len, uint64_t rand_seed);\n\nvoid fill_buffer_pattern(struct thread_data *td, void *p, unsigned int len)\n{\n\t(void)cpy_pattern(td->o.buffer_pattern, td->o.buffer_pattern_bytes, p, len);\n}\n\nstatic void __fill_buffer(struct thread_options *o, uint64_t seed, void *p,\n\t\t\t  unsigned int len)\n{\n\t__fill_random_buf_percentage(seed, p, o->compress_percentage, len, len, o->buffer_pattern, o->buffer_pattern_bytes);\n}\n\nvoid fill_verify_pattern(struct thread_data *td, void *p, unsigned int len,\n\t\t\t struct io_u *io_u, uint64_t seed, int use_seed)\n{\n\tstruct thread_options *o = &td->o;\n\n\tif (!o->verify_pattern_bytes) {\n\t\tdprint(FD_VERIFY, \"fill random bytes len=%u\\n\", len);\n\n\t\tif (!use_seed) {\n\t\t\tseed = __rand(&td->verify_state);\n\t\t\tif (sizeof(int) != sizeof(long *))\n\t\t\t\tseed *= (unsigned long)__rand(&td->verify_state);\n\t\t}\n\t\tio_u->rand_seed = seed;\n\t\t__fill_buffer(o, seed, p, len);\n\t\treturn;\n\t}\n\n\t/* Skip if we were here and we do not need to patch pattern\n\t * with format */\n\tif (!td->o.verify_fmt_sz && io_u->buf_filled_len >= len) {\n\t\tdprint(FD_VERIFY, \"using already filled verify pattern b=%d len=%u\\n\",\n\t\t\to->verify_pattern_bytes, len);\n\t\treturn;\n\t}\n\n\t(void)paste_format(td->o.verify_pattern, td->o.verify_pattern_bytes,\n\t\t\t   td->o.verify_fmt, td->o.verify_fmt_sz,\n\t\t\t   p, len, io_u);\n\tio_u->buf_filled_len = len;\n}\n\nstatic unsigned int get_hdr_inc(struct thread_data *td, struct io_u *io_u)\n{\n\tunsigned int hdr_inc;\n\n\t/*\n\t * If we use bs_unaligned, buflen can be larger than the verify\n\t * interval (which just defaults to the smallest blocksize possible).\n\t */\n\thdr_inc = io_u->buflen;\n\tif (td->o.verify_interval && td->o.verify_interval <= io_u->buflen &&\n\t    !td->o.bs_unaligned)\n\t\thdr_inc = td->o.verify_interval;\n\n\treturn hdr_inc;\n}\n\nstatic void fill_pattern_headers(struct thread_data *td, struct io_u *io_u,\n\t\t\t\t uint64_t seed, int use_seed)\n{\n\tunsigned int hdr_inc, header_num;\n\tstruct verify_header *hdr;\n\tvoid *p = io_u->buf;\n\n\tfill_verify_pattern(td, p, io_u->buflen, io_u, seed, use_seed);\n\n\thdr_inc = get_hdr_inc(td, io_u);\n\theader_num = 0;\n\tfor (; p < io_u->buf + io_u->buflen; p += hdr_inc) {\n\t\thdr = p;\n\t\tpopulate_hdr(td, io_u, hdr, header_num, hdr_inc);\n\t\theader_num++;\n\t}\n}\n\nstatic void memswp(void *buf1, void *buf2, unsigned int len)\n{\n\tchar swap[200];\n\n\tassert(len <= sizeof(swap));\n\n\tmemcpy(&swap, buf1, len);\n\tmemcpy(buf1, buf2, len);\n\tmemcpy(buf2, &swap, len);\n}\n\nstatic void hexdump(void *buffer, int len)\n{\n\tunsigned char *p = buffer;\n\tint i;\n\n\tfor (i = 0; i < len; i++)\n\t\tlog_err(\"%02x\", p[i]);\n\tlog_err(\"\\n\");\n}\n\n/*\n * Prepare for separation of verify_header and checksum header\n */\nstatic inline unsigned int __hdr_size(int verify_type)\n{\n\tunsigned int len = 0;\n\n\tswitch (verify_type) {\n\tcase VERIFY_NONE:\n\tcase VERIFY_HDR_ONLY:\n\tcase VERIFY_NULL:\n\tcase VERIFY_PATTERN:\n\t\tlen = 0;\n\t\tbreak;\n\tcase VERIFY_MD5:\n\t\tlen = sizeof(struct vhdr_md5);\n\t\tbreak;\n\tcase VERIFY_CRC64:\n\t\tlen = sizeof(struct vhdr_crc64);\n\t\tbreak;\n\tcase VERIFY_CRC32C:\n\tcase VERIFY_CRC32:\n\tcase VERIFY_CRC32C_INTEL:\n\t\tlen = sizeof(struct vhdr_crc32);\n\t\tbreak;\n\tcase VERIFY_CRC16:\n\t\tlen = sizeof(struct vhdr_crc16);\n\t\tbreak;\n\tcase VERIFY_CRC7:\n\t\tlen = sizeof(struct vhdr_crc7);\n\t\tbreak;\n\tcase VERIFY_SHA256:\n\t\tlen = sizeof(struct vhdr_sha256);\n\t\tbreak;\n\tcase VERIFY_SHA512:\n\t\tlen = sizeof(struct vhdr_sha512);\n\t\tbreak;\n\tcase VERIFY_SHA3_224:\n\t\tlen = sizeof(struct vhdr_sha3_224);\n\t\tbreak;\n\tcase VERIFY_SHA3_256:\n\t\tlen = sizeof(struct vhdr_sha3_256);\n\t\tbreak;\n\tcase VERIFY_SHA3_384:\n\t\tlen = sizeof(struct vhdr_sha3_384);\n\t\tbreak;\n\tcase VERIFY_SHA3_512:\n\t\tlen = sizeof(struct vhdr_sha3_512);\n\t\tbreak;\n\tcase VERIFY_XXHASH:\n\t\tlen = sizeof(struct vhdr_xxhash);\n\t\tbreak;\n\tcase VERIFY_SHA1:\n\t\tlen = sizeof(struct vhdr_sha1);\n\t\tbreak;\n\tcase VERIFY_PATTERN_NO_HDR:\n\t\treturn 0;\n\tdefault:\n\t\tlog_err(\"fio: unknown verify header!\\n\");\n\t\tassert(0);\n\t}\n\n\treturn len + sizeof(struct verify_header);\n}\n\nstatic inline unsigned int hdr_size(struct thread_data *td,\n\t\t\t\t    struct verify_header *hdr)\n{\n\tif (td->o.verify == VERIFY_PATTERN_NO_HDR)\n\t\treturn 0;\n\n\treturn __hdr_size(hdr->verify_type);\n}\n\nstatic void *hdr_priv(struct verify_header *hdr)\n{\n\tvoid *priv = hdr;\n\n\treturn priv + sizeof(struct verify_header);\n}\n\n/*\n * Verify container, pass info to verify handlers and allow them to\n * pass info back in case of error\n */\nstruct vcont {\n\t/*\n\t * Input\n\t */\n\tstruct io_u *io_u;\n\tunsigned int hdr_num;\n\tstruct thread_data *td;\n\n\t/*\n\t * Output, only valid in case of error\n\t */\n\tconst char *name;\n\tvoid *good_crc;\n\tvoid *bad_crc;\n\tunsigned int crc_len;\n};\n\n#define DUMP_BUF_SZ\t255\n\nstatic void dump_buf(char *buf, unsigned int len, unsigned long long offset,\n\t\t     const char *type, struct fio_file *f)\n{\n\tchar *ptr, *fname;\n\tchar sep[2] = { FIO_OS_PATH_SEPARATOR, 0 };\n\tint ret, fd;\n\n\tptr = strdup(f->file_name);\n\n\tif (asprintf(&fname, \"%s%s%s.%llu.%s\", aux_path ? : \"\",\n\t\t     aux_path ? sep : \"\", basename(ptr), offset, type) < 0) {\n\t\tif (!fio_did_warn(FIO_WARN_VERIFY_BUF))\n\t\t\tlog_err(\"fio: not enough memory for dump buffer filename\\n\");\n\t\tgoto free_ptr;\n\t}\n\n\tfd = open(fname, O_CREAT | O_TRUNC | O_WRONLY, 0644);\n\tif (fd < 0) {\n\t\tperror(\"open verify buf file\");\n\t\tgoto free_fname;\n\t}\n\n\twhile (len) {\n\t\tret = write(fd, buf, len);\n\t\tif (!ret)\n\t\t\tbreak;\n\t\telse if (ret < 0) {\n\t\t\tperror(\"write verify buf file\");\n\t\t\tbreak;\n\t\t}\n\t\tlen -= ret;\n\t\tbuf += ret;\n\t}\n\n\tclose(fd);\n\tlog_err(\"       %s data dumped as %s\\n\", type, fname);\n\nfree_fname:\n\tfree(fname);\n\nfree_ptr:\n\tfree(ptr);\n}\n\n/*\n * Dump the contents of the read block and re-generate the correct data\n * and dump that too.\n */\nstatic void __dump_verify_buffers(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct thread_data *td = vc->td;\n\tstruct io_u *io_u = vc->io_u;\n\tunsigned long hdr_offset;\n\tstruct io_u dummy;\n\tvoid *buf;\n\n\tif (!td->o.verify_dump)\n\t\treturn;\n\n\t/*\n\t * Dump the contents we just read off disk\n\t */\n\thdr_offset = vc->hdr_num * hdr->len;\n\n\tdump_buf(io_u->buf + hdr_offset, hdr->len, io_u->verify_offset + hdr_offset,\n\t\t\t\"received\", vc->io_u->file);\n\n\t/*\n\t * Allocate a new buf and re-generate the original data\n\t */\n\tbuf = malloc(io_u->buflen);\n\tdummy = *io_u;\n\tdummy.buf = buf;\n\tdummy.rand_seed = hdr->rand_seed;\n\tdummy.buf_filled_len = 0;\n\tdummy.buflen = io_u->buflen;\n\n\tfill_pattern_headers(td, &dummy, hdr->rand_seed, 1);\n\n\tdump_buf(buf + hdr_offset, hdr->len, io_u->verify_offset + hdr_offset,\n\t\t\t\"expected\", vc->io_u->file);\n\tfree(buf);\n}\n\nstatic void dump_verify_buffers(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct thread_data *td = vc->td;\n\tstruct verify_header shdr;\n\n\tif (td->o.verify == VERIFY_PATTERN_NO_HDR) {\n\t\t__fill_hdr(td, vc->io_u, &shdr, 0, vc->io_u->buflen, 0);\n\t\thdr = &shdr;\n\t}\n\n\t__dump_verify_buffers(hdr, vc);\n}\n\nstatic void log_verify_failure(struct verify_header *hdr, struct vcont *vc)\n{\n\tunsigned long long offset;\n\tuint32_t len;\n\tstruct thread_data *td = vc->td;\n\n\toffset = vc->io_u->verify_offset;\n\tif (td->o.verify != VERIFY_PATTERN_NO_HDR) {\n\t\tlen = hdr->len;\n\t\toffset += (unsigned long long) vc->hdr_num * len;\n\t} else {\n\t\tlen = vc->io_u->buflen;\n\t}\n\n\tlog_err(\"%.8s: verify failed at file %s offset %llu, length %u\"\n\t\t\t\" (requested block: offset=%llu, length=%llu, flags=%x)\\n\",\n\t\t\tvc->name, vc->io_u->file->file_name, offset, len,\n\t\t\tvc->io_u->verify_offset, vc->io_u->buflen, vc->io_u->flags);\n\n\tif (vc->good_crc && vc->bad_crc) {\n\t\tlog_err(\"       Expected CRC: \");\n\t\thexdump(vc->good_crc, vc->crc_len);\n\t\tlog_err(\"       Received CRC: \");\n\t\thexdump(vc->bad_crc, vc->crc_len);\n\t}\n\n\tdump_verify_buffers(hdr, vc);\n}\n\n/*\n * Return data area 'header_num'\n */\nstatic inline void *io_u_verify_off(struct verify_header *hdr, struct vcont *vc)\n{\n\treturn vc->io_u->buf + vc->hdr_num * hdr->len + hdr_size(vc->td, hdr);\n}\n\nstatic int verify_io_u_pattern(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct thread_data *td = vc->td;\n\tstruct io_u *io_u = vc->io_u;\n\tchar *buf, *pattern;\n\tunsigned int header_size = __hdr_size(td->o.verify);\n\tunsigned int len, mod, i, pattern_size;\n\tint rc;\n\n\tpattern = td->o.verify_pattern;\n\tpattern_size = td->o.verify_pattern_bytes;\n\tassert(pattern_size != 0);\n\n\t(void)paste_format_inplace(pattern, pattern_size,\n\t\t\t\t   td->o.verify_fmt, td->o.verify_fmt_sz, io_u);\n\n\tbuf = (char *) hdr + header_size;\n\tlen = get_hdr_inc(td, io_u) - header_size;\n\tmod = (get_hdr_inc(td, io_u) * vc->hdr_num + header_size) % pattern_size;\n\n\trc = cmp_pattern(pattern, pattern_size, mod, buf, len);\n\tif (!rc)\n\t\treturn 0;\n\n\t/* Slow path, compare each byte */\n\tfor (i = 0; i < len; i++) {\n\t\tif (buf[i] != pattern[mod]) {\n\t\t\tunsigned int bits;\n\n\t\t\tbits = hweight8(buf[i] ^ pattern[mod]);\n\t\t\tlog_err(\"fio: got pattern '%02x', wanted '%02x'. Bad bits %d\\n\",\n\t\t\t\t(unsigned char)buf[i],\n\t\t\t\t(unsigned char)pattern[mod],\n\t\t\t\tbits);\n\t\t\tlog_err(\"fio: bad pattern block offset %u\\n\",\n\t\t\t\ti + header_size);\n\t\t\tvc->name = \"pattern\";\n\t\t\tlog_verify_failure(hdr, vc);\n\t\t\treturn EILSEQ;\n\t\t}\n\t\tmod++;\n\t\tif (mod == td->o.verify_pattern_bytes)\n\t\t\tmod = 0;\n\t}\n\n\t/* Unreachable line */\n\tassert(0);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_xxhash(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_xxhash *vh = hdr_priv(hdr);\n\tuint32_t hash;\n\tvoid *state;\n\n\tdprint(FD_VERIFY, \"xxhash verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tstate = XXH32_init(1);\n\tXXH32_update(state, p, hdr->len - hdr_size(vc->td, hdr));\n\thash = XXH32_digest(state);\n\n\tif (vh->hash == hash)\n\t\treturn 0;\n\n\tvc->name = \"xxhash\";\n\tvc->good_crc = &vh->hash;\n\tvc->bad_crc = &hash;\n\tvc->crc_len = sizeof(hash);\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_sha3(struct verify_header *hdr, struct vcont *vc,\n\t\t\t    struct fio_sha3_ctx *sha3_ctx, uint8_t *sha,\n\t\t\t    unsigned int sha_size, const char *name)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\n\tdprint(FD_VERIFY, \"%s verify io_u %p, len %u\\n\", name, vc->io_u, hdr->len);\n\n\tfio_sha3_update(sha3_ctx, p, hdr->len - hdr_size(vc->td, hdr));\n\tfio_sha3_final(sha3_ctx);\n\n\tif (!memcmp(sha, sha3_ctx->sha, sha_size))\n\t\treturn 0;\n\n\tvc->name = name;\n\tvc->good_crc = sha;\n\tvc->bad_crc = sha3_ctx->sha;\n\tvc->crc_len = sha_size;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_sha3_224(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct vhdr_sha3_224 *vh = hdr_priv(hdr);\n\tuint8_t sha[SHA3_224_DIGEST_SIZE];\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = sha,\n\t};\n\n\tfio_sha3_224_init(&sha3_ctx);\n\n\treturn verify_io_u_sha3(hdr, vc, &sha3_ctx, vh->sha,\n\t\t\t\tSHA3_224_DIGEST_SIZE, \"sha3-224\");\n}\n\nstatic int verify_io_u_sha3_256(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct vhdr_sha3_256 *vh = hdr_priv(hdr);\n\tuint8_t sha[SHA3_256_DIGEST_SIZE];\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = sha,\n\t};\n\n\tfio_sha3_256_init(&sha3_ctx);\n\n\treturn verify_io_u_sha3(hdr, vc, &sha3_ctx, vh->sha,\n\t\t\t\tSHA3_256_DIGEST_SIZE, \"sha3-256\");\n}\n\nstatic int verify_io_u_sha3_384(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct vhdr_sha3_384 *vh = hdr_priv(hdr);\n\tuint8_t sha[SHA3_384_DIGEST_SIZE];\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = sha,\n\t};\n\n\tfio_sha3_384_init(&sha3_ctx);\n\n\treturn verify_io_u_sha3(hdr, vc, &sha3_ctx, vh->sha,\n\t\t\t\tSHA3_384_DIGEST_SIZE, \"sha3-384\");\n}\n\nstatic int verify_io_u_sha3_512(struct verify_header *hdr, struct vcont *vc)\n{\n\tstruct vhdr_sha3_512 *vh = hdr_priv(hdr);\n\tuint8_t sha[SHA3_512_DIGEST_SIZE];\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = sha,\n\t};\n\n\tfio_sha3_512_init(&sha3_ctx);\n\n\treturn verify_io_u_sha3(hdr, vc, &sha3_ctx, vh->sha,\n\t\t\t\tSHA3_512_DIGEST_SIZE, \"sha3-512\");\n}\n\nstatic int verify_io_u_sha512(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_sha512 *vh = hdr_priv(hdr);\n\tuint8_t sha512[128];\n\tstruct fio_sha512_ctx sha512_ctx = {\n\t\t.buf = sha512,\n\t};\n\n\tdprint(FD_VERIFY, \"sha512 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tfio_sha512_init(&sha512_ctx);\n\tfio_sha512_update(&sha512_ctx, p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (!memcmp(vh->sha512, sha512_ctx.buf, sizeof(sha512)))\n\t\treturn 0;\n\n\tvc->name = \"sha512\";\n\tvc->good_crc = vh->sha512;\n\tvc->bad_crc = sha512_ctx.buf;\n\tvc->crc_len = sizeof(vh->sha512);\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_sha256(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_sha256 *vh = hdr_priv(hdr);\n\tuint8_t sha256[64];\n\tstruct fio_sha256_ctx sha256_ctx = {\n\t\t.buf = sha256,\n\t};\n\n\tdprint(FD_VERIFY, \"sha256 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tfio_sha256_init(&sha256_ctx);\n\tfio_sha256_update(&sha256_ctx, p, hdr->len - hdr_size(vc->td, hdr));\n\tfio_sha256_final(&sha256_ctx);\n\n\tif (!memcmp(vh->sha256, sha256_ctx.buf, sizeof(sha256)))\n\t\treturn 0;\n\n\tvc->name = \"sha256\";\n\tvc->good_crc = vh->sha256;\n\tvc->bad_crc = sha256_ctx.buf;\n\tvc->crc_len = sizeof(vh->sha256);\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_sha1(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_sha1 *vh = hdr_priv(hdr);\n\tuint32_t sha1[5];\n\tstruct fio_sha1_ctx sha1_ctx = {\n\t\t.H = sha1,\n\t};\n\n\tdprint(FD_VERIFY, \"sha1 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tfio_sha1_init(&sha1_ctx);\n\tfio_sha1_update(&sha1_ctx, p, hdr->len - hdr_size(vc->td, hdr));\n\tfio_sha1_final(&sha1_ctx);\n\n\tif (!memcmp(vh->sha1, sha1_ctx.H, sizeof(sha1)))\n\t\treturn 0;\n\n\tvc->name = \"sha1\";\n\tvc->good_crc = vh->sha1;\n\tvc->bad_crc = sha1_ctx.H;\n\tvc->crc_len = sizeof(vh->sha1);\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_crc7(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_crc7 *vh = hdr_priv(hdr);\n\tunsigned char c;\n\n\tdprint(FD_VERIFY, \"crc7 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tc = fio_crc7(p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (c == vh->crc7)\n\t\treturn 0;\n\n\tvc->name = \"crc7\";\n\tvc->good_crc = &vh->crc7;\n\tvc->bad_crc = &c;\n\tvc->crc_len = 1;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_crc16(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_crc16 *vh = hdr_priv(hdr);\n\tunsigned short c;\n\n\tdprint(FD_VERIFY, \"crc16 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tc = fio_crc16(p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (c == vh->crc16)\n\t\treturn 0;\n\n\tvc->name = \"crc16\";\n\tvc->good_crc = &vh->crc16;\n\tvc->bad_crc = &c;\n\tvc->crc_len = 2;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_crc64(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_crc64 *vh = hdr_priv(hdr);\n\tunsigned long long c;\n\n\tdprint(FD_VERIFY, \"crc64 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tc = fio_crc64(p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (c == vh->crc64)\n\t\treturn 0;\n\n\tvc->name = \"crc64\";\n\tvc->good_crc = &vh->crc64;\n\tvc->bad_crc = &c;\n\tvc->crc_len = 8;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_crc32(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_crc32 *vh = hdr_priv(hdr);\n\tuint32_t c;\n\n\tdprint(FD_VERIFY, \"crc32 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tc = fio_crc32(p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (c == vh->crc32)\n\t\treturn 0;\n\n\tvc->name = \"crc32\";\n\tvc->good_crc = &vh->crc32;\n\tvc->bad_crc = &c;\n\tvc->crc_len = 4;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_crc32c(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_crc32 *vh = hdr_priv(hdr);\n\tuint32_t c;\n\n\tdprint(FD_VERIFY, \"crc32c verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tc = fio_crc32c(p, hdr->len - hdr_size(vc->td, hdr));\n\n\tif (c == vh->crc32)\n\t\treturn 0;\n\n\tvc->name = \"crc32c\";\n\tvc->good_crc = &vh->crc32;\n\tvc->bad_crc = &c;\n\tvc->crc_len = 4;\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\nstatic int verify_io_u_md5(struct verify_header *hdr, struct vcont *vc)\n{\n\tvoid *p = io_u_verify_off(hdr, vc);\n\tstruct vhdr_md5 *vh = hdr_priv(hdr);\n\tuint32_t hash[MD5_HASH_WORDS];\n\tstruct fio_md5_ctx md5_ctx = {\n\t\t.hash = hash,\n\t};\n\n\tdprint(FD_VERIFY, \"md5 verify io_u %p, len %u\\n\", vc->io_u, hdr->len);\n\n\tfio_md5_init(&md5_ctx);\n\tfio_md5_update(&md5_ctx, p, hdr->len - hdr_size(vc->td, hdr));\n\tfio_md5_final(&md5_ctx);\n\n\tif (!memcmp(vh->md5_digest, md5_ctx.hash, sizeof(hash)))\n\t\treturn 0;\n\n\tvc->name = \"md5\";\n\tvc->good_crc = vh->md5_digest;\n\tvc->bad_crc = md5_ctx.hash;\n\tvc->crc_len = sizeof(hash);\n\tlog_verify_failure(hdr, vc);\n\treturn EILSEQ;\n}\n\n/*\n * Push IO verification to a separate thread\n */\nint verify_io_u_async(struct thread_data *td, struct io_u **io_u_ptr)\n{\n\tstruct io_u *io_u = *io_u_ptr;\n\n\tpthread_mutex_lock(&td->io_u_lock);\n\n\tif (io_u->file)\n\t\tput_file_log(td, io_u->file);\n\n\tif (io_u->flags & IO_U_F_IN_CUR_DEPTH) {\n\t\ttd->cur_depth--;\n\t\tio_u_clear(td, io_u, IO_U_F_IN_CUR_DEPTH);\n\t}\n\tflist_add_tail(&io_u->verify_list, &td->verify_list);\n\t*io_u_ptr = NULL;\n\n\tpthread_cond_signal(&td->verify_cond);\n\tpthread_mutex_unlock(&td->io_u_lock);\n\treturn 0;\n}\n\n/*\n * Thanks Rusty, for spending the time so I don't have to.\n *\n * http://rusty.ozlabs.org/?p=560\n */\nstatic int mem_is_zero(const void *data, size_t length)\n{\n\tconst unsigned char *p = data;\n\tsize_t len;\n\n\t/* Check first 16 bytes manually */\n\tfor (len = 0; len < 16; len++) {\n\t\tif (!length)\n\t\t\treturn 1;\n\t\tif (*p)\n\t\t\treturn 0;\n\t\tp++;\n\t\tlength--;\n\t}\n\n\t/* Now we know that's zero, memcmp with self. */\n\treturn memcmp(data, p, length) == 0;\n}\n\nstatic int mem_is_zero_slow(const void *data, size_t length, size_t *offset)\n{\n\tconst unsigned char *p = data;\n\n\t*offset = 0;\n\twhile (length) {\n\t\tif (*p)\n\t\t\tbreak;\n\t\t(*offset)++;\n\t\tlength--;\n\t\tp++;\n\t}\n\n\treturn !length;\n}\n\nstatic int verify_trimmed_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tsize_t offset;\n\n\tif (!td->o.trim_zero)\n\t\treturn 0;\n\n\tif (mem_is_zero(io_u->buf, io_u->buflen))\n\t\treturn 0;\n\n\tmem_is_zero_slow(io_u->buf, io_u->buflen, &offset);\n\n\tlog_err(\"trim: verify failed at file %s offset %llu, length %llu\"\n\t\t\", block offset %lu\\n\",\n\t\t\tio_u->file->file_name, io_u->verify_offset, io_u->buflen,\n\t\t\t(unsigned long) offset);\n\treturn EILSEQ;\n}\n\nstatic int verify_header(struct io_u *io_u, struct thread_data *td,\n\t\t\t struct verify_header *hdr, unsigned int hdr_num,\n\t\t\t unsigned int hdr_len)\n{\n\tvoid *p = hdr;\n\tuint32_t crc;\n\n\tif (hdr->magic != FIO_HDR_MAGIC) {\n\t\tlog_err(\"verify: bad magic header %x, wanted %x\",\n\t\t\thdr->magic, FIO_HDR_MAGIC);\n\t\tgoto err;\n\t}\n\tif (hdr->len != hdr_len) {\n\t\tlog_err(\"verify: bad header length %u, wanted %u\",\n\t\t\thdr->len, hdr_len);\n\t\tgoto err;\n\t}\n\tif (hdr->rand_seed != io_u->rand_seed) {\n\t\tlog_err(\"verify: bad header rand_seed %\"PRIu64\n\t\t\t\", wanted %\"PRIu64,\n\t\t\thdr->rand_seed, io_u->rand_seed);\n\t\tgoto err;\n\t}\n\tif (hdr->offset != io_u->verify_offset + hdr_num * td->o.verify_interval) {\n\t\tlog_err(\"verify: bad header offset %\"PRIu64\n\t\t\t\", wanted %llu\",\n\t\t\thdr->offset, io_u->verify_offset);\n\t\tgoto err;\n\t}\n\n\t/*\n\t * For read-only workloads, the program cannot be certain of the\n\t * last numberio written to a block. Checking of numberio will be\n\t * done only for workloads that write data.  For verify_only or\n\t * any mode de-selecting verify_write_sequence, numberio check is\n\t * skipped.\n\t */\n\tif (td_write(td) && (td_min_bs(td) == td_max_bs(td)) &&\n\t    !td->o.time_based)\n\t\tif (td->o.verify_write_sequence)\n\t\t\tif (hdr->numberio != io_u->numberio) {\n\t\t\t\tlog_err(\"verify: bad header numberio %\"PRIu16\n\t\t\t\t\t\", wanted %\"PRIu16,\n\t\t\t\t\thdr->numberio, io_u->numberio);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\tcrc = fio_crc32c(p, offsetof(struct verify_header, crc32));\n\tif (crc != hdr->crc32) {\n\t\tlog_err(\"verify: bad header crc %x, calculated %x\",\n\t\t\thdr->crc32, crc);\n\t\tgoto err;\n\t}\n\treturn 0;\n\nerr:\n\tlog_err(\" at file %s offset %llu, length %u\"\n\t\t\" (requested block: offset=%llu, length=%llu)\\n\",\n\t\tio_u->file->file_name,\n\t\tio_u->verify_offset + hdr_num * hdr_len, hdr_len,\n\t\tio_u->verify_offset, io_u->buflen);\n\n\tif (td->o.verify_dump)\n\t\tdump_buf(p, hdr_len, io_u->verify_offset + hdr_num * hdr_len,\n\t\t\t\t\"hdr_fail\", io_u->file);\n\n\treturn EILSEQ;\n}\n\nint verify_io_u(struct thread_data *td, struct io_u **io_u_ptr)\n{\n\tstruct verify_header *hdr;\n\tstruct io_u *io_u = *io_u_ptr;\n\tunsigned int header_size, hdr_inc, hdr_num = 0;\n\tvoid *p;\n\tint ret;\n\n\tif (td->o.verify == VERIFY_NULL || io_u->ddir != DDIR_READ)\n\t\treturn 0;\n\t/*\n\t * If the IO engine is faking IO (like null), then just pretend\n\t * we verified everything.\n\t */\n\tif (td_ioengine_flagged(td, FIO_FAKEIO))\n\t\treturn 0;\n\n\t/*\n\t * If data has already been verified from the device, we can skip\n\t * the actual verification phase here.\n\t */\n\tif (io_u->flags & IO_U_F_VER_IN_DEV)\n\t\treturn 0;\n\n\tif (io_u->flags & IO_U_F_TRIMMED) {\n\t\tret = verify_trimmed_io_u(td, io_u);\n\t\tgoto done;\n\t}\n\n\thdr_inc = get_hdr_inc(td, io_u);\n\n\tret = 0;\n\tfor (p = io_u->buf; p < io_u->buf + io_u->buflen;\n\t     p += hdr_inc, hdr_num++) {\n\t\tstruct vcont vc = {\n\t\t\t.io_u\t\t= io_u,\n\t\t\t.hdr_num\t= hdr_num,\n\t\t\t.td\t\t= td,\n\t\t};\n\t\tunsigned int verify_type;\n\n\t\tif (ret && td->o.verify_fatal)\n\t\t\tbreak;\n\n\t\theader_size = __hdr_size(td->o.verify);\n\t\tif (td->o.verify_offset)\n\t\t\tmemswp(p, p + td->o.verify_offset, header_size);\n\t\thdr = p;\n\n\t\t/*\n\t\t * Make rand_seed check pass when have verify_backlog or\n\t\t * zone reset frequency for zonemode=zbd.\n\t\t */\n\t\tif (!td_rw(td) || (td->flags & TD_F_VER_BACKLOG) ||\n\t\t    td->o.zrf.u.f)\n\t\t\tio_u->rand_seed = hdr->rand_seed;\n\n\t\tif (td->o.verify != VERIFY_PATTERN_NO_HDR) {\n\t\t\tret = verify_header(io_u, td, hdr, hdr_num, hdr_inc);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (td->o.verify != VERIFY_NONE)\n\t\t\tverify_type = td->o.verify;\n\t\telse\n\t\t\tverify_type = hdr->verify_type;\n\n\t\tswitch (verify_type) {\n\t\tcase VERIFY_HDR_ONLY:\n\t\t\t/* Header is always verified, check if pattern is left\n\t\t\t * for verification. */\n\t\t\tif (td->o.verify_pattern_bytes)\n\t\t\t\tret = verify_io_u_pattern(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_MD5:\n\t\t\tret = verify_io_u_md5(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_CRC64:\n\t\t\tret = verify_io_u_crc64(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_CRC32C:\n\t\tcase VERIFY_CRC32C_INTEL:\n\t\t\tret = verify_io_u_crc32c(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_CRC32:\n\t\t\tret = verify_io_u_crc32(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_CRC16:\n\t\t\tret = verify_io_u_crc16(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_CRC7:\n\t\t\tret = verify_io_u_crc7(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA256:\n\t\t\tret = verify_io_u_sha256(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA512:\n\t\t\tret = verify_io_u_sha512(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA3_224:\n\t\t\tret = verify_io_u_sha3_224(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA3_256:\n\t\t\tret = verify_io_u_sha3_256(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA3_384:\n\t\t\tret = verify_io_u_sha3_384(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA3_512:\n\t\t\tret = verify_io_u_sha3_512(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_XXHASH:\n\t\t\tret = verify_io_u_xxhash(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_SHA1:\n\t\t\tret = verify_io_u_sha1(hdr, &vc);\n\t\t\tbreak;\n\t\tcase VERIFY_PATTERN:\n\t\tcase VERIFY_PATTERN_NO_HDR:\n\t\t\tret = verify_io_u_pattern(hdr, &vc);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog_err(\"Bad verify type %u\\n\", hdr->verify_type);\n\t\t\tret = EINVAL;\n\t\t}\n\n\t\tif (ret && verify_type != hdr->verify_type)\n\t\t\tlog_err(\"fio: verify type mismatch (%u media, %u given)\\n\",\n\t\t\t\t\thdr->verify_type, verify_type);\n\t}\n\ndone:\n\tif (ret && td->o.verify_fatal)\n\t\tfio_mark_td_terminate(td);\n\n\treturn ret;\n}\n\nstatic void fill_xxhash(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_xxhash *vh = hdr_priv(hdr);\n\tvoid *state;\n\n\tstate = XXH32_init(1);\n\tXXH32_update(state, p, len);\n\tvh->hash = XXH32_digest(state);\n}\n\nstatic void fill_sha3(struct fio_sha3_ctx *sha3_ctx, void *p, unsigned int len)\n{\n\tfio_sha3_update(sha3_ctx, p, len);\n\tfio_sha3_final(sha3_ctx);\n}\n\nstatic void fill_sha3_224(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha3_224 *vh = hdr_priv(hdr);\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = vh->sha,\n\t};\n\n\tfio_sha3_224_init(&sha3_ctx);\n\tfill_sha3(&sha3_ctx, p, len);\n}\n\nstatic void fill_sha3_256(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha3_256 *vh = hdr_priv(hdr);\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = vh->sha,\n\t};\n\n\tfio_sha3_256_init(&sha3_ctx);\n\tfill_sha3(&sha3_ctx, p, len);\n}\n\nstatic void fill_sha3_384(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha3_384 *vh = hdr_priv(hdr);\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = vh->sha,\n\t};\n\n\tfio_sha3_384_init(&sha3_ctx);\n\tfill_sha3(&sha3_ctx, p, len);\n}\n\nstatic void fill_sha3_512(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha3_512 *vh = hdr_priv(hdr);\n\tstruct fio_sha3_ctx sha3_ctx = {\n\t\t.sha = vh->sha,\n\t};\n\n\tfio_sha3_512_init(&sha3_ctx);\n\tfill_sha3(&sha3_ctx, p, len);\n}\n\nstatic void fill_sha512(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha512 *vh = hdr_priv(hdr);\n\tstruct fio_sha512_ctx sha512_ctx = {\n\t\t.buf = vh->sha512,\n\t};\n\n\tfio_sha512_init(&sha512_ctx);\n\tfio_sha512_update(&sha512_ctx, p, len);\n}\n\nstatic void fill_sha256(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha256 *vh = hdr_priv(hdr);\n\tstruct fio_sha256_ctx sha256_ctx = {\n\t\t.buf = vh->sha256,\n\t};\n\n\tfio_sha256_init(&sha256_ctx);\n\tfio_sha256_update(&sha256_ctx, p, len);\n\tfio_sha256_final(&sha256_ctx);\n}\n\nstatic void fill_sha1(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_sha1 *vh = hdr_priv(hdr);\n\tstruct fio_sha1_ctx sha1_ctx = {\n\t\t.H = vh->sha1,\n\t};\n\n\tfio_sha1_init(&sha1_ctx);\n\tfio_sha1_update(&sha1_ctx, p, len);\n\tfio_sha1_final(&sha1_ctx);\n}\n\nstatic void fill_crc7(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_crc7 *vh = hdr_priv(hdr);\n\n\tvh->crc7 = fio_crc7(p, len);\n}\n\nstatic void fill_crc16(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_crc16 *vh = hdr_priv(hdr);\n\n\tvh->crc16 = fio_crc16(p, len);\n}\n\nstatic void fill_crc32(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_crc32 *vh = hdr_priv(hdr);\n\n\tvh->crc32 = fio_crc32(p, len);\n}\n\nstatic void fill_crc32c(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_crc32 *vh = hdr_priv(hdr);\n\n\tvh->crc32 = fio_crc32c(p, len);\n}\n\nstatic void fill_crc64(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_crc64 *vh = hdr_priv(hdr);\n\n\tvh->crc64 = fio_crc64(p, len);\n}\n\nstatic void fill_md5(struct verify_header *hdr, void *p, unsigned int len)\n{\n\tstruct vhdr_md5 *vh = hdr_priv(hdr);\n\tstruct fio_md5_ctx md5_ctx = {\n\t\t.hash = (uint32_t *) vh->md5_digest,\n\t};\n\n\tfio_md5_init(&md5_ctx);\n\tfio_md5_update(&md5_ctx, p, len);\n\tfio_md5_final(&md5_ctx);\n}\n\nstatic void __fill_hdr(struct thread_data *td, struct io_u *io_u,\n\t\t       struct verify_header *hdr, unsigned int header_num,\n\t\t       unsigned int header_len, uint64_t rand_seed)\n{\n\tvoid *p = hdr;\n\n\thdr->magic = FIO_HDR_MAGIC;\n\thdr->verify_type = td->o.verify;\n\thdr->len = header_len;\n\thdr->rand_seed = rand_seed;\n\thdr->offset = io_u->verify_offset + header_num * td->o.verify_interval;\n\thdr->time_sec = io_u->start_time.tv_sec;\n\thdr->time_nsec = io_u->start_time.tv_nsec;\n\thdr->thread = td->thread_number;\n\thdr->numberio = io_u->numberio;\n\thdr->crc32 = fio_crc32c(p, offsetof(struct verify_header, crc32));\n}\n\n\nstatic void fill_hdr(struct thread_data *td, struct io_u *io_u,\n\t\t     struct verify_header *hdr, unsigned int header_num,\n\t\t     unsigned int header_len, uint64_t rand_seed)\n{\n\tif (td->o.verify != VERIFY_PATTERN_NO_HDR)\n\t\t__fill_hdr(td, io_u, hdr, header_num, header_len, rand_seed);\n}\n\nstatic void populate_hdr(struct thread_data *td, struct io_u *io_u,\n\t\t\t struct verify_header *hdr, unsigned int header_num,\n\t\t\t unsigned int header_len)\n{\n\tunsigned int data_len;\n\tvoid *data;\n\tchar *p;\n\n\tp = (char *) hdr;\n\n\tfill_hdr(td, io_u, hdr, header_num, header_len, io_u->rand_seed);\n\n\tif (header_len <= hdr_size(td, hdr)) {\n\t\ttd_verror(td, EINVAL, \"Blocksize too small\");\n\t\treturn;\n\t}\n\tdata_len = header_len - hdr_size(td, hdr);\n\n\tdata = p + hdr_size(td, hdr);\n\tswitch (td->o.verify) {\n\tcase VERIFY_MD5:\n\t\tdprint(FD_VERIFY, \"fill md5 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_md5(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_CRC64:\n\t\tdprint(FD_VERIFY, \"fill crc64 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_crc64(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_CRC32C:\n\tcase VERIFY_CRC32C_INTEL:\n\t\tdprint(FD_VERIFY, \"fill crc32c io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_crc32c(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_CRC32:\n\t\tdprint(FD_VERIFY, \"fill crc32 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_crc32(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_CRC16:\n\t\tdprint(FD_VERIFY, \"fill crc16 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_crc16(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_CRC7:\n\t\tdprint(FD_VERIFY, \"fill crc7 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_crc7(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA256:\n\t\tdprint(FD_VERIFY, \"fill sha256 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha256(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA512:\n\t\tdprint(FD_VERIFY, \"fill sha512 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha512(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA3_224:\n\t\tdprint(FD_VERIFY, \"fill sha3-224 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha3_224(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA3_256:\n\t\tdprint(FD_VERIFY, \"fill sha3-256 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha3_256(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA3_384:\n\t\tdprint(FD_VERIFY, \"fill sha3-384 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha3_384(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA3_512:\n\t\tdprint(FD_VERIFY, \"fill sha3-512 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha3_512(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_XXHASH:\n\t\tdprint(FD_VERIFY, \"fill xxhash io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_xxhash(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_SHA1:\n\t\tdprint(FD_VERIFY, \"fill sha1 io_u %p, len %u\\n\",\n\t\t\t\t\t\tio_u, hdr->len);\n\t\tfill_sha1(hdr, data, data_len);\n\t\tbreak;\n\tcase VERIFY_HDR_ONLY:\n\tcase VERIFY_PATTERN:\n\tcase VERIFY_PATTERN_NO_HDR:\n\t\t/* nothing to do here */\n\t\tbreak;\n\tdefault:\n\t\tlog_err(\"fio: bad verify type: %d\\n\", td->o.verify);\n\t\tassert(0);\n\t}\n\n\tif (td->o.verify_offset && hdr_size(td, hdr))\n\t\tmemswp(p, p + td->o.verify_offset, hdr_size(td, hdr));\n}\n\n/*\n * fill body of io_u->buf with random data and add a header with the\n * checksum of choice\n */\nvoid populate_verify_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tif (td->o.verify == VERIFY_NULL)\n\t\treturn;\n\n\tfill_pattern_headers(td, io_u, 0, 0);\n}\n\nint get_next_verify(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct io_piece *ipo = NULL;\n\n\t/*\n\t * this io_u is from a requeue, we already filled the offsets\n\t */\n\tif (io_u->file)\n\t\treturn 0;\n\n\tif (!RB_EMPTY_ROOT(&td->io_hist_tree)) {\n\t\tstruct fio_rb_node *n = rb_first(&td->io_hist_tree);\n\n\t\tipo = rb_entry(n, struct io_piece, rb_node);\n\n\t\t/*\n\t\t * Ensure that the associated IO has completed\n\t\t */\n\t\tif (atomic_load_acquire(&ipo->flags) & IP_F_IN_FLIGHT)\n\t\t\tgoto nothing;\n\n\t\trb_erase(n, &td->io_hist_tree);\n\t\tassert(ipo->flags & IP_F_ONRB);\n\t\tipo->flags &= ~IP_F_ONRB;\n\t} else if (!flist_empty(&td->io_hist_list)) {\n\t\tipo = flist_first_entry(&td->io_hist_list, struct io_piece, list);\n\n\t\t/*\n\t\t * Ensure that the associated IO has completed\n\t\t */\n\t\tif (atomic_load_acquire(&ipo->flags) & IP_F_IN_FLIGHT)\n\t\t\tgoto nothing;\n\n\t\tflist_del(&ipo->list);\n\t\tassert(ipo->flags & IP_F_ONLIST);\n\t\tipo->flags &= ~IP_F_ONLIST;\n\t}\n\n\tif (ipo) {\n\t\ttd->io_hist_len--;\n\n\t\tio_u->offset = ipo->offset;\n\t\tio_u->verify_offset = ipo->offset;\n\t\tio_u->buflen = ipo->len;\n\t\tio_u->numberio = ipo->numberio;\n\t\tio_u->file = ipo->file;\n\t\tio_u_set(td, io_u, IO_U_F_VER_LIST);\n\n\t\tif (ipo->flags & IP_F_TRIMMED)\n\t\t\tio_u_set(td, io_u, IO_U_F_TRIMMED);\n\n\t\tif (!fio_file_open(io_u->file)) {\n\t\t\tint r = td_io_open_file(td, io_u->file);\n\n\t\t\tif (r) {\n\t\t\t\tdprint(FD_VERIFY, \"failed file %s open\\n\",\n\t\t\t\t\t\tio_u->file->file_name);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tget_file(ipo->file);\n\t\tassert(fio_file_open(io_u->file));\n\t\tio_u->ddir = DDIR_READ;\n\t\tio_u->xfer_buf = io_u->buf;\n\t\tio_u->xfer_buflen = io_u->buflen;\n\n\t\tremove_trim_entry(td, ipo);\n\t\tfree(ipo);\n\t\tdprint(FD_VERIFY, \"get_next_verify: ret io_u %p\\n\", io_u);\n\n\t\tif (!td->o.verify_pattern_bytes) {\n\t\t\tio_u->rand_seed = __rand(&td->verify_state);\n\t\t\tif (sizeof(int) != sizeof(long *))\n\t\t\t\tio_u->rand_seed *= __rand(&td->verify_state);\n\t\t}\n\t\treturn 0;\n\t}\n\nnothing:\n\tdprint(FD_VERIFY, \"get_next_verify: empty\\n\");\n\treturn 1;\n}\n\nvoid fio_verify_init(struct thread_data *td)\n{\n\tif (td->o.verify == VERIFY_CRC32C_INTEL ||\n\t    td->o.verify == VERIFY_CRC32C) {\n\t\tcrc32c_arm64_probe();\n\t\tcrc32c_intel_probe();\n\t}\n}\n\nstatic void *verify_async_thread(void *data)\n{\n\tstruct thread_data *td = data;\n\tstruct io_u *io_u;\n\tint ret = 0;\n\n\tif (fio_option_is_set(&td->o, verify_cpumask) &&\n\t    fio_setaffinity(td->pid, td->o.verify_cpumask)) {\n\t\tlog_err(\"fio: failed setting verify thread affinity\\n\");\n\t\tgoto done;\n\t}\n\n\tdo {\n\t\tFLIST_HEAD(list);\n\n\t\tread_barrier();\n\t\tif (td->verify_thread_exit)\n\t\t\tbreak;\n\n\t\tpthread_mutex_lock(&td->io_u_lock);\n\n\t\twhile (flist_empty(&td->verify_list) &&\n\t\t       !td->verify_thread_exit) {\n\t\t\tret = pthread_cond_wait(&td->verify_cond,\n\t\t\t\t\t\t\t&td->io_u_lock);\n\t\t\tif (ret) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tflist_splice_init(&td->verify_list, &list);\n\t\tpthread_mutex_unlock(&td->io_u_lock);\n\n\t\tif (flist_empty(&list))\n\t\t\tcontinue;\n\n\t\twhile (!flist_empty(&list)) {\n\t\t\tio_u = flist_first_entry(&list, struct io_u, verify_list);\n\t\t\tflist_del_init(&io_u->verify_list);\n\n\t\t\tio_u_set(td, io_u, IO_U_F_NO_FILE_PUT);\n\t\t\tret = verify_io_u(td, &io_u);\n\n\t\t\tput_io_u(td, io_u);\n\t\t\tif (!ret)\n\t\t\t\tcontinue;\n\t\t\tif (td_non_fatal_error(td, ERROR_TYPE_VERIFY_BIT, ret)) {\n\t\t\t\tupdate_error_count(td, ret);\n\t\t\t\ttd_clear_error(td);\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t}\n\t} while (!ret);\n\n\tif (ret) {\n\t\ttd_verror(td, ret, \"async_verify\");\n\t\tif (td->o.verify_fatal)\n\t\t\tfio_mark_td_terminate(td);\n\t}\n\ndone:\n\tpthread_mutex_lock(&td->io_u_lock);\n\ttd->nr_verify_threads--;\n\tpthread_cond_signal(&td->free_cond);\n\tpthread_mutex_unlock(&td->io_u_lock);\n\n\treturn NULL;\n}\n\nint verify_async_init(struct thread_data *td)\n{\n\tint i, ret;\n\tpthread_attr_t attr;\n\n\tpthread_attr_init(&attr);\n\tpthread_attr_setstacksize(&attr, 2 * PTHREAD_STACK_MIN);\n\n\ttd->verify_thread_exit = 0;\n\n\ttd->verify_threads = malloc(sizeof(pthread_t) * td->o.verify_async);\n\tfor (i = 0; i < td->o.verify_async; i++) {\n\t\tret = pthread_create(&td->verify_threads[i], &attr,\n\t\t\t\t\tverify_async_thread, td);\n\t\tif (ret) {\n\t\t\tlog_err(\"fio: async verify creation failed: %s\\n\",\n\t\t\t\t\tstrerror(ret));\n\t\t\tbreak;\n\t\t}\n\t\tret = pthread_detach(td->verify_threads[i]);\n\t\tif (ret) {\n\t\t\tlog_err(\"fio: async verify thread detach failed: %s\\n\",\n\t\t\t\t\tstrerror(ret));\n\t\t\tbreak;\n\t\t}\n\t\ttd->nr_verify_threads++;\n\t}\n\n\tpthread_attr_destroy(&attr);\n\n\tif (i != td->o.verify_async) {\n\t\tlog_err(\"fio: only %d verify threads started, exiting\\n\", i);\n\n\t\tpthread_mutex_lock(&td->io_u_lock);\n\t\ttd->verify_thread_exit = 1;\n\t\tpthread_cond_broadcast(&td->verify_cond);\n\t\tpthread_mutex_unlock(&td->io_u_lock);\n\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nvoid verify_async_exit(struct thread_data *td)\n{\n\tpthread_mutex_lock(&td->io_u_lock);\n\ttd->verify_thread_exit = 1;\n\tpthread_cond_broadcast(&td->verify_cond);\n\n\twhile (td->nr_verify_threads)\n\t\tpthread_cond_wait(&td->free_cond, &td->io_u_lock);\n\n\tpthread_mutex_unlock(&td->io_u_lock);\n\tfree(td->verify_threads);\n\ttd->verify_threads = NULL;\n}\n\nint paste_blockoff(char *buf, unsigned int len, void *priv)\n{\n\tstruct io_u *io = priv;\n\tunsigned long long off;\n\n\ttypecheck(__typeof__(off), io->offset);\n\toff = cpu_to_le64((uint64_t)io->offset);\n\tlen = min(len, (unsigned int)sizeof(off));\n\tmemcpy(buf, &off, len);\n\treturn 0;\n}\n\nstatic int __fill_file_completions(struct thread_data *td,\n\t\t\t\t   struct thread_io_list *s,\n\t\t\t\t   struct fio_file *f, unsigned int *index)\n{\n\tunsigned int comps;\n\tint i, j;\n\n\tif (!f->last_write_comp)\n\t\treturn 0;\n\n\tif (td->io_blocks[DDIR_WRITE] < td->o.iodepth)\n\t\tcomps = td->io_blocks[DDIR_WRITE];\n\telse\n\t\tcomps = td->o.iodepth;\n\n\tj = f->last_write_idx - 1;\n\tfor (i = 0; i < comps; i++) {\n\t\tif (j == -1)\n\t\t\tj = td->o.iodepth - 1;\n\t\ts->comps[*index].fileno = __cpu_to_le64(f->fileno);\n\t\ts->comps[*index].offset = cpu_to_le64(f->last_write_comp[j]);\n\t\t(*index)++;\n\t\tj--;\n\t}\n\n\treturn comps;\n}\n\nstatic int fill_file_completions(struct thread_data *td,\n\t\t\t\t struct thread_io_list *s, unsigned int *index)\n{\n\tstruct fio_file *f;\n\tunsigned int i;\n\tint comps = 0;\n\n\tfor_each_file(td, f, i)\n\t\tcomps += __fill_file_completions(td, s, f, index);\n\n\treturn comps;\n}\n\nstruct all_io_list *get_all_io_list(int save_mask, size_t *sz)\n{\n\tstruct all_io_list *rep;\n\tsize_t depth;\n\tvoid *next;\n\tint nr;\n\n\tcompiletime_assert(sizeof(struct all_io_list) == 8, \"all_io_list\");\n\n\t/*\n\t * Calculate reply space needed. We need one 'io_state' per thread,\n\t * and the size will vary depending on depth.\n\t */\n\tdepth = 0;\n\tnr = 0;\n\tfor_each_td(td) {\n\t\tif (save_mask != IO_LIST_ALL && (__td_index + 1) != save_mask)\n\t\t\tcontinue;\n\t\ttd->stop_io = 1;\n\t\ttd->flags |= TD_F_VSTATE_SAVED;\n\t\tdepth += (td->o.iodepth * td->o.nr_files);\n\t\tnr++;\n\t} end_for_each();\n\n\tif (!nr)\n\t\treturn NULL;\n\n\t*sz = sizeof(*rep);\n\t*sz += nr * sizeof(struct thread_io_list);\n\t*sz += depth * sizeof(struct file_comp);\n\trep = calloc(1, *sz);\n\n\trep->threads = cpu_to_le64((uint64_t) nr);\n\n\tnext = &rep->state[0];\n\tfor_each_td(td) {\n\t\tstruct thread_io_list *s = next;\n\t\tunsigned int comps, index = 0;\n\n\t\tif (save_mask != IO_LIST_ALL && (__td_index + 1) != save_mask)\n\t\t\tcontinue;\n\n\t\tcomps = fill_file_completions(td, s, &index);\n\n\t\ts->no_comps = cpu_to_le64((uint64_t) comps);\n\t\ts->depth = cpu_to_le32((uint32_t) td->o.iodepth);\n\t\ts->nofiles = cpu_to_le32((uint32_t) td->o.nr_files);\n\t\ts->numberio = cpu_to_le64((uint64_t) td->io_issues[DDIR_WRITE]);\n\t\ts->index = cpu_to_le64((uint64_t) __td_index);\n\t\tif (td->random_state.use64) {\n\t\t\ts->rand.state64.s[0] = cpu_to_le64(td->random_state.state64.s1);\n\t\t\ts->rand.state64.s[1] = cpu_to_le64(td->random_state.state64.s2);\n\t\t\ts->rand.state64.s[2] = cpu_to_le64(td->random_state.state64.s3);\n\t\t\ts->rand.state64.s[3] = cpu_to_le64(td->random_state.state64.s4);\n\t\t\ts->rand.state64.s[4] = cpu_to_le64(td->random_state.state64.s5);\n\t\t\ts->rand.state64.s[5] = 0;\n\t\t\ts->rand.use64 = cpu_to_le64((uint64_t)1);\n\t\t} else {\n\t\t\ts->rand.state32.s[0] = cpu_to_le32(td->random_state.state32.s1);\n\t\t\ts->rand.state32.s[1] = cpu_to_le32(td->random_state.state32.s2);\n\t\t\ts->rand.state32.s[2] = cpu_to_le32(td->random_state.state32.s3);\n\t\t\ts->rand.state32.s[3] = 0;\n\t\t\ts->rand.use64 = 0;\n\t\t}\n\t\tsnprintf((char *) s->name, sizeof(s->name), \"%s\", td->o.name);\n\t\tnext = io_list_next(s);\n\t} end_for_each();\n\n\treturn rep;\n}\n\nstatic int open_state_file(const char *name, const char *prefix, int num,\n\t\t\t   int for_write)\n{\n\tchar out[PATH_MAX];\n\tint flags;\n\tint fd;\n\n\tif (for_write)\n\t\tflags = O_CREAT | O_TRUNC | O_WRONLY | O_SYNC;\n\telse\n\t\tflags = O_RDONLY;\n\n#ifdef _WIN32\n\tflags |= O_BINARY;\n#endif\n\n\tverify_state_gen_name(out, sizeof(out), name, prefix, num);\n\n\tfd = open(out, flags, 0644);\n\tif (fd == -1) {\n\t\tperror(\"fio: open state file\");\n\t\tlog_err(\"fio: state file: %s (for_write=%d)\\n\", out, for_write);\n\t\treturn -1;\n\t}\n\n\treturn fd;\n}\n\nstatic int write_thread_list_state(struct thread_io_list *s,\n\t\t\t\t   const char *prefix)\n{\n\tstruct verify_state_hdr hdr;\n\tuint64_t crc;\n\tssize_t ret;\n\tint fd;\n\n\tfd = open_state_file((const char *) s->name, prefix, s->index, 1);\n\tif (fd == -1)\n\t\treturn 1;\n\n\tcrc = fio_crc32c((void *)s, thread_io_list_sz(s));\n\n\thdr.version = cpu_to_le64((uint64_t) VSTATE_HDR_VERSION);\n\thdr.size = cpu_to_le64((uint64_t) thread_io_list_sz(s));\n\thdr.crc = cpu_to_le64(crc);\n\tret = write(fd, &hdr, sizeof(hdr));\n\tif (ret != sizeof(hdr))\n\t\tgoto write_fail;\n\n\tret = write(fd, s, thread_io_list_sz(s));\n\tif (ret != thread_io_list_sz(s)) {\nwrite_fail:\n\t\tif (ret < 0)\n\t\t\tperror(\"fio: write state file\");\n\t\tlog_err(\"fio: failed to write state file\\n\");\n\t\tret = 1;\n\t} else\n\t\tret = 0;\n\n\tclose(fd);\n\treturn ret;\n}\n\nvoid __verify_save_state(struct all_io_list *state, const char *prefix)\n{\n\tstruct thread_io_list *s = &state->state[0];\n\tunsigned int i;\n\n\tfor (i = 0; i < le64_to_cpu(state->threads); i++) {\n\t\twrite_thread_list_state(s,  prefix);\n\t\ts = io_list_next(s);\n\t}\n}\n\nvoid verify_save_state(int mask)\n{\n\tstruct all_io_list *state;\n\tsize_t sz;\n\n\tstate = get_all_io_list(mask, &sz);\n\tif (state) {\n\t\tchar prefix[PATH_MAX];\n\n\t\tif (aux_path)\n\t\t\tsprintf(prefix, \"%s%clocal\", aux_path, FIO_OS_PATH_SEPARATOR);\n\t\telse\n\t\t\tstrcpy(prefix, \"local\");\n\n\t\t__verify_save_state(state, prefix);\n\t\tfree(state);\n\t}\n}\n\nvoid verify_free_state(struct thread_data *td)\n{\n\tif (td->vstate)\n\t\tfree(td->vstate);\n}\n\nvoid verify_assign_state(struct thread_data *td, void *p)\n{\n\tstruct thread_io_list *s = p;\n\tint i;\n\n\ts->no_comps = le64_to_cpu(s->no_comps);\n\ts->depth = le32_to_cpu(s->depth);\n\ts->nofiles = le32_to_cpu(s->nofiles);\n\ts->numberio = le64_to_cpu(s->numberio);\n\ts->rand.use64 = le64_to_cpu(s->rand.use64);\n\n\tif (s->rand.use64) {\n\t\tfor (i = 0; i < 6; i++)\n\t\t\ts->rand.state64.s[i] = le64_to_cpu(s->rand.state64.s[i]);\n\t} else {\n\t\tfor (i = 0; i < 4; i++)\n\t\t\ts->rand.state32.s[i] = le32_to_cpu(s->rand.state32.s[i]);\n\t}\n\n\tfor (i = 0; i < s->no_comps; i++) {\n\t\ts->comps[i].fileno = le64_to_cpu(s->comps[i].fileno);\n\t\ts->comps[i].offset = le64_to_cpu(s->comps[i].offset);\n\t}\n\n\ttd->vstate = p;\n}\n\nint verify_state_hdr(struct verify_state_hdr *hdr, struct thread_io_list *s)\n{\n\tuint64_t crc;\n\n\thdr->version = le64_to_cpu(hdr->version);\n\thdr->size = le64_to_cpu(hdr->size);\n\thdr->crc = le64_to_cpu(hdr->crc);\n\n\tif (hdr->version != VSTATE_HDR_VERSION)\n\t\treturn 1;\n\n\tcrc = fio_crc32c((void *)s, hdr->size);\n\tif (crc != hdr->crc)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nint verify_load_state(struct thread_data *td, const char *prefix)\n{\n\tstruct verify_state_hdr hdr;\n\tvoid *s = NULL;\n\tuint64_t crc;\n\tssize_t ret;\n\tint fd;\n\n\tif (!td->o.verify_state)\n\t\treturn 0;\n\n\tfd = open_state_file(td->o.name, prefix, td->thread_number - 1, 0);\n\tif (fd == -1)\n\t\treturn 1;\n\n\tret = read(fd, &hdr, sizeof(hdr));\n\tif (ret != sizeof(hdr)) {\n\t\tif (ret < 0)\n\t\t\ttd_verror(td, errno, \"read verify state hdr\");\n\t\tlog_err(\"fio: failed reading verify state header\\n\");\n\t\tgoto err;\n\t}\n\n\thdr.version = le64_to_cpu(hdr.version);\n\thdr.size = le64_to_cpu(hdr.size);\n\thdr.crc = le64_to_cpu(hdr.crc);\n\n\tif (hdr.version != VSTATE_HDR_VERSION) {\n\t\tlog_err(\"fio: unsupported (%d) version in verify state header\\n\",\n\t\t\t\t(unsigned int) hdr.version);\n\t\tgoto err;\n\t}\n\n\ts = malloc(hdr.size);\n\tret = read(fd, s, hdr.size);\n\tif (ret != hdr.size) {\n\t\tif (ret < 0)\n\t\t\ttd_verror(td, errno, \"read verify state\");\n\t\tlog_err(\"fio: failed reading verity state\\n\");\n\t\tgoto err;\n\t}\n\n\tcrc = fio_crc32c(s, hdr.size);\n\tif (crc != hdr.crc) {\n\t\tlog_err(\"fio: verify state is corrupt\\n\");\n\t\tgoto err;\n\t}\n\n\tclose(fd);\n\n\tverify_assign_state(td, s);\n\treturn 0;\nerr:\n\tif (s)\n\t\tfree(s);\n\tclose(fd);\n\treturn 1;\n}\n\n/*\n * Use the loaded verify state to know when to stop doing verification\n */\nint verify_state_should_stop(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct thread_io_list *s = td->vstate;\n\tstruct fio_file *f = io_u->file;\n\tint i;\n\n\tif (!s || !f)\n\t\treturn 0;\n\n\t/*\n\t * If we're not into the window of issues - depth yet, continue. If\n\t * issue is shorter than depth, do check.\n\t */\n\tif ((td->io_blocks[DDIR_READ] < s->depth ||\n\t    s->numberio - td->io_blocks[DDIR_READ] > s->depth) &&\n\t    s->numberio > s->depth)\n\t\treturn 0;\n\n\t/*\n\t * We're in the window of having to check if this io was\n\t * completed or not. If the IO was seen as completed, then\n\t * lets verify it.\n\t */\n\tfor (i = 0; i < s->no_comps; i++) {\n\t\tif (s->comps[i].fileno != f->fileno)\n\t\t\tcontinue;\n\t\tif (io_u->verify_offset == s->comps[i].offset)\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * Not found, we have to stop\n\t */\n\treturn 1;\n}\n"
        },
        {
          "name": "verify.h",
          "type": "blob",
          "size": 2.951171875,
          "content": "#ifndef FIO_VERIFY_H\n#define FIO_VERIFY_H\n\n#include <stdint.h>\n#include \"compiler/compiler.h\"\n#include \"verify-state.h\"\n\n#define FIO_HDR_MAGIC\t0xacca\n\nenum {\n\tVERIFY_NONE = 0,\t\t/* no verification */\n\tVERIFY_HDR_ONLY,\t\t/* verify header only, kept for sake of\n\t\t\t\t\t * compatibility with old configurations\n\t\t\t\t\t * which use 'verify=meta' */\n\tVERIFY_MD5,\t\t\t/* md5 sum data blocks */\n\tVERIFY_CRC64,\t\t\t/* crc64 sum data blocks */\n\tVERIFY_CRC32,\t\t\t/* crc32 sum data blocks */\n\tVERIFY_CRC32C,\t\t\t/* crc32c sum data blocks */\n\tVERIFY_CRC32C_INTEL,\t\t/* crc32c sum data blocks with hw */\n\tVERIFY_CRC16,\t\t\t/* crc16 sum data blocks */\n\tVERIFY_CRC7,\t\t\t/* crc7 sum data blocks */\n\tVERIFY_SHA256,\t\t\t/* sha256 sum data blocks */\n\tVERIFY_SHA512,\t\t\t/* sha512 sum data blocks */\n\tVERIFY_SHA3_224,\t\t/* sha3-224 sum data blocks */\n\tVERIFY_SHA3_256,\t\t/* sha3-256 sum data blocks */\n\tVERIFY_SHA3_384,\t\t/* sha3-384 sum data blocks */\n\tVERIFY_SHA3_512,\t\t/* sha3-512 sum data blocks */\n\tVERIFY_XXHASH,\t\t\t/* xxhash sum data blocks */\n\tVERIFY_SHA1,\t\t\t/* sha1 sum data blocks */\n\tVERIFY_PATTERN,\t\t\t/* verify specific patterns */\n\tVERIFY_PATTERN_NO_HDR,\t\t/* verify specific patterns, no hdr */\n\tVERIFY_NULL,\t\t\t/* pretend to verify */\n};\n\n/*\n * A header structure associated with each checksummed data block. It is\n * followed by a checksum specific header that contains the verification\n * data.\n */\nstruct verify_header {\n\tuint16_t magic;\n\tuint16_t verify_type;\n\tuint32_t len;\n\tuint64_t rand_seed;\n\tuint64_t offset;\n\tuint32_t time_sec;\n\tuint32_t time_nsec;\n\tuint16_t thread;\n\tuint16_t numberio;\n\tuint32_t crc32;\n};\n\nstruct vhdr_md5 {\n\tuint32_t md5_digest[4];\n};\nstruct vhdr_sha3_224 {\n\tuint8_t sha[224 / 8];\n};\nstruct vhdr_sha3_256 {\n\tuint8_t sha[256 / 8];\n};\nstruct vhdr_sha3_384 {\n\tuint8_t sha[384 / 8];\n};\nstruct vhdr_sha3_512 {\n\tuint8_t sha[512 / 8];\n};\nstruct vhdr_sha512 {\n\tuint8_t sha512[128];\n};\nstruct vhdr_sha256 {\n\tuint8_t sha256[64];\n};\nstruct vhdr_sha1 {\n\tuint32_t sha1[5];\n};\nstruct vhdr_crc64 {\n\tuint64_t crc64;\n};\nstruct vhdr_crc32 {\n\tuint32_t crc32;\n};\nstruct vhdr_crc16 {\n\tuint16_t crc16;\n};\nstruct vhdr_crc7 {\n\tuint8_t crc7;\n};\nstruct vhdr_xxhash {\n\tuint32_t hash;\n};\n\n/*\n * Verify helpers\n */\nextern void populate_verify_io_u(struct thread_data *, struct io_u *);\nextern int __must_check get_next_verify(struct thread_data *td, struct io_u *);\nextern int __must_check verify_io_u(struct thread_data *, struct io_u **);\nextern int verify_io_u_async(struct thread_data *, struct io_u **);\nextern void fill_verify_pattern(struct thread_data *td, void *p, unsigned int len, struct io_u *io_u, uint64_t seed, int use_seed);\nextern void fill_buffer_pattern(struct thread_data *td, void *p, unsigned int len);\nextern void fio_verify_init(struct thread_data *td);\n\n/*\n * Async verify offload\n */\nextern int verify_async_init(struct thread_data *);\nextern void verify_async_exit(struct thread_data *);\n\n/*\n * Callbacks for pasting formats in the pattern buffer\n */\nextern int paste_blockoff(char *buf, unsigned int len, void *priv);\n\n#endif\n"
        },
        {
          "name": "workqueue.c",
          "type": "blob",
          "size": 7.5732421875,
          "content": "/*\n * Generic workqueue offload mechanism\n *\n * Copyright (C) 2015 Jens Axboe <axboe@kernel.dk>\n *\n */\n#include <unistd.h>\n\n#include \"fio.h\"\n#include \"flist.h\"\n#include \"workqueue.h\"\n#include \"smalloc.h\"\n#include \"pshared.h\"\n\nenum {\n\tSW_F_IDLE\t= 1 << 0,\n\tSW_F_RUNNING\t= 1 << 1,\n\tSW_F_EXIT\t= 1 << 2,\n\tSW_F_ACCOUNTED\t= 1 << 3,\n\tSW_F_ERROR\t= 1 << 4,\n};\n\nstatic struct submit_worker *__get_submit_worker(struct workqueue *wq,\n\t\t\t\t\t\t unsigned int start,\n\t\t\t\t\t\t unsigned int end,\n\t\t\t\t\t\t struct submit_worker **best)\n{\n\tstruct submit_worker *sw = NULL;\n\n\twhile (start <= end) {\n\t\tsw = &wq->workers[start];\n\t\tif (sw->flags & SW_F_IDLE)\n\t\t\treturn sw;\n\t\tif (!(*best) || sw->seq < (*best)->seq)\n\t\t\t*best = sw;\n\t\tstart++;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct submit_worker *get_submit_worker(struct workqueue *wq)\n{\n\tunsigned int next = wq->next_free_worker;\n\tstruct submit_worker *sw, *best = NULL;\n\n\tassert(next < wq->max_workers);\n\n\tsw = __get_submit_worker(wq, next, wq->max_workers - 1, &best);\n\tif (!sw && next)\n\t\tsw = __get_submit_worker(wq, 0, next - 1, &best);\n\n\t/*\n\t * No truly idle found, use best match\n\t */\n\tif (!sw)\n\t\tsw = best;\n\n\tif (sw->index == wq->next_free_worker) {\n\t\tif (sw->index + 1 < wq->max_workers)\n\t\t\twq->next_free_worker = sw->index + 1;\n\t\telse\n\t\t\twq->next_free_worker = 0;\n\t}\n\n\treturn sw;\n}\n\nstatic bool all_sw_idle(struct workqueue *wq)\n{\n\tint i;\n\n\tfor (i = 0; i < wq->max_workers; i++) {\n\t\tstruct submit_worker *sw = &wq->workers[i];\n\n\t\tif (!(sw->flags & SW_F_IDLE))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n/*\n * Must be serialized wrt workqueue_enqueue() by caller\n */\nvoid workqueue_flush(struct workqueue *wq)\n{\n\tpthread_mutex_lock(&wq->flush_lock);\n\twq->wake_idle = 1;\n\n\twhile (!all_sw_idle(wq))\n\t\tpthread_cond_wait(&wq->flush_cond, &wq->flush_lock);\n\n\twq->wake_idle = 0;\n\tpthread_mutex_unlock(&wq->flush_lock);\n}\n\n/*\n * Must be serialized by caller.\n */\nvoid workqueue_enqueue(struct workqueue *wq, struct workqueue_work *work)\n{\n\tstruct submit_worker *sw;\n\n\tsw = get_submit_worker(wq);\n\tassert(sw);\n\n\tpthread_mutex_lock(&sw->lock);\n\tflist_add_tail(&work->list, &sw->work_list);\n\tsw->seq = ++wq->work_seq;\n\tsw->flags &= ~SW_F_IDLE;\n\n\tpthread_cond_signal(&sw->cond);\n\tpthread_mutex_unlock(&sw->lock);\n}\n\nstatic void handle_list(struct submit_worker *sw, struct flist_head *list)\n{\n\tstruct workqueue *wq = sw->wq;\n\tstruct workqueue_work *work;\n\n\twhile (!flist_empty(list)) {\n\t\twork = flist_first_entry(list, struct workqueue_work, list);\n\t\tflist_del_init(&work->list);\n\t\twq->ops.fn(sw, work);\n\t}\n}\n\nstatic void *worker_thread(void *data)\n{\n\tstruct submit_worker *sw = data;\n\tstruct workqueue *wq = sw->wq;\n\tunsigned int ret = 0;\n\tFLIST_HEAD(local_list);\n\n\tsk_out_assign(sw->sk_out);\n\n\tif (wq->ops.nice) {\n\t\terrno = 0;\n\t\tif (nice(wq->ops.nice) == -1 && errno != 0) {\n\t\t\tlog_err(\"workqueue: nice %s\\n\", strerror(errno));\n\t\t\tret = 1;\n\t\t}\n\t}\n\n\tif (!ret)\n\t\tret = workqueue_init_worker(sw);\n\n\tpthread_mutex_lock(&sw->lock);\n\tsw->flags |= SW_F_RUNNING;\n\tif (ret)\n\t\tsw->flags |= SW_F_ERROR;\n\tpthread_mutex_unlock(&sw->lock);\n\n\tpthread_mutex_lock(&wq->flush_lock);\n\tpthread_cond_signal(&wq->flush_cond);\n\tpthread_mutex_unlock(&wq->flush_lock);\n\n\tif (sw->flags & SW_F_ERROR)\n\t\tgoto done;\n\n\tpthread_mutex_lock(&sw->lock);\n\twhile (1) {\n\t\tif (flist_empty(&sw->work_list)) {\n\t\t\tif (sw->flags & SW_F_EXIT) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (workqueue_pre_sleep_check(sw)) {\n\t\t\t\tpthread_mutex_unlock(&sw->lock);\n\t\t\t\tworkqueue_pre_sleep(sw);\n\t\t\t\tpthread_mutex_lock(&sw->lock);\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * We may have dropped and reaquired the lock, check state\n\t\t * again.\n\t\t */\n\t\tif (flist_empty(&sw->work_list)) {\n\t\t\tif (sw->flags & SW_F_EXIT) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!(sw->flags & SW_F_IDLE)) {\n\t\t\t\tsw->flags |= SW_F_IDLE;\n\t\t\t\twq->next_free_worker = sw->index;\n\t\t\t\tpthread_mutex_unlock(&sw->lock);\n\t\t\t\tpthread_mutex_lock(&wq->flush_lock);\n\t\t\t\tif (wq->wake_idle)\n\t\t\t\t\tpthread_cond_signal(&wq->flush_cond);\n\t\t\t\tpthread_mutex_unlock(&wq->flush_lock);\n\t\t\t\tpthread_mutex_lock(&sw->lock);\n\t\t\t}\n\t\t}\n\t\tif (flist_empty(&sw->work_list)) {\n\t\t\tif (sw->flags & SW_F_EXIT) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpthread_cond_wait(&sw->cond, &sw->lock);\n\t\t} else {\n\t\t\tflist_splice_init(&sw->work_list, &local_list);\n\t\t}\n\t\tpthread_mutex_unlock(&sw->lock);\n\t\thandle_list(sw, &local_list);\n\t\tif (wq->ops.update_acct_fn)\n\t\t\twq->ops.update_acct_fn(sw);\n\t\tpthread_mutex_lock(&sw->lock);\n\t}\n\tpthread_mutex_unlock(&sw->lock);\n\ndone:\n\tsk_out_drop();\n\treturn NULL;\n}\n\nstatic void free_worker(struct submit_worker *sw, unsigned int *sum_cnt)\n{\n\tstruct workqueue *wq = sw->wq;\n\n\tworkqueue_exit_worker(sw, sum_cnt);\n\n\tpthread_cond_destroy(&sw->cond);\n\tpthread_mutex_destroy(&sw->lock);\n\n\tif (wq->ops.free_worker_fn)\n\t\twq->ops.free_worker_fn(sw);\n}\n\nstatic void shutdown_worker(struct submit_worker *sw, unsigned int *sum_cnt)\n{\n\tpthread_join(sw->thread, NULL);\n\tfree_worker(sw, sum_cnt);\n}\n\nvoid workqueue_exit(struct workqueue *wq)\n{\n\tunsigned int shutdown, sum_cnt = 0;\n\tstruct submit_worker *sw;\n\tint i;\n\n\tif (!wq->workers)\n\t\treturn;\n\n\tfor (i = 0; i < wq->max_workers; i++) {\n\t\tsw = &wq->workers[i];\n\n\t\tpthread_mutex_lock(&sw->lock);\n\t\tsw->flags |= SW_F_EXIT;\n\t\tpthread_cond_signal(&sw->cond);\n\t\tpthread_mutex_unlock(&sw->lock);\n\t}\n\n\tdo {\n\t\tshutdown = 0;\n\t\tfor (i = 0; i < wq->max_workers; i++) {\n\t\t\tsw = &wq->workers[i];\n\t\t\tif (sw->flags & SW_F_ACCOUNTED)\n\t\t\t\tcontinue;\n\t\t\tpthread_mutex_lock(&sw->lock);\n\t\t\tsw->flags |= SW_F_ACCOUNTED;\n\t\t\tpthread_mutex_unlock(&sw->lock);\n\t\t\tshutdown_worker(sw, &sum_cnt);\n\t\t\tshutdown++;\n\t\t}\n\t} while (shutdown && shutdown != wq->max_workers);\n\n\tsfree(wq->workers);\n\twq->workers = NULL;\n\tpthread_mutex_destroy(&wq->flush_lock);\n\tpthread_cond_destroy(&wq->flush_cond);\n\tpthread_mutex_destroy(&wq->stat_lock);\n}\n\nstatic int start_worker(struct workqueue *wq, unsigned int index,\n\t\t\tstruct sk_out *sk_out)\n{\n\tstruct submit_worker *sw = &wq->workers[index];\n\tint ret;\n\n\tINIT_FLIST_HEAD(&sw->work_list);\n\n\tret = mutex_cond_init_pshared(&sw->lock, &sw->cond);\n\tif (ret)\n\t\treturn ret;\n\n\tsw->wq = wq;\n\tsw->index = index;\n\tsw->sk_out = sk_out;\n\n\tif (wq->ops.alloc_worker_fn) {\n\t\tret = wq->ops.alloc_worker_fn(sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = pthread_create(&sw->thread, NULL, worker_thread, sw);\n\tif (!ret) {\n\t\tpthread_mutex_lock(&sw->lock);\n\t\tsw->flags = SW_F_IDLE;\n\t\tpthread_mutex_unlock(&sw->lock);\n\t\treturn 0;\n\t}\n\n\tfree_worker(sw, NULL);\n\treturn 1;\n}\n\nint workqueue_init(struct thread_data *td, struct workqueue *wq,\n\t\t   struct workqueue_ops *ops, unsigned int max_workers,\n\t\t   struct sk_out *sk_out)\n{\n\tunsigned int running;\n\tint i, error;\n\tint ret;\n\n\twq->max_workers = max_workers;\n\twq->td = td;\n\twq->ops = *ops;\n\twq->work_seq = 0;\n\twq->next_free_worker = 0;\n\n\tret = mutex_cond_init_pshared(&wq->flush_lock, &wq->flush_cond);\n\tif (ret)\n\t\tgoto err;\n\tret = mutex_init_pshared(&wq->stat_lock);\n\tif (ret)\n\t\tgoto err;\n\n\twq->workers = smalloc(wq->max_workers * sizeof(struct submit_worker));\n\tif (!wq->workers)\n\t\tgoto err;\n\n\tfor (i = 0; i < wq->max_workers; i++)\n\t\tif (start_worker(wq, i, sk_out))\n\t\t\tbreak;\n\n\twq->max_workers = i;\n\tif (!wq->max_workers)\n\t\tgoto err;\n\n\t/*\n\t * Wait for them all to be started and initialized\n\t */\n\terror = 0;\n\tpthread_mutex_lock(&wq->flush_lock);\n\tdo {\n\t\tstruct submit_worker *sw;\n\n\t\trunning = 0;\n\t\tfor (i = 0; i < wq->max_workers; i++) {\n\t\t\tsw = &wq->workers[i];\n\t\t\tpthread_mutex_lock(&sw->lock);\n\t\t\tif (sw->flags & SW_F_RUNNING)\n\t\t\t\trunning++;\n\t\t\tif (sw->flags & SW_F_ERROR)\n\t\t\t\terror++;\n\t\t\tpthread_mutex_unlock(&sw->lock);\n\t\t}\n\n\t\tif (error || running == wq->max_workers)\n\t\t\tbreak;\n\n\t\tpthread_cond_wait(&wq->flush_cond, &wq->flush_lock);\n\t} while (1);\n\tpthread_mutex_unlock(&wq->flush_lock);\n\n\tif (!error)\n\t\treturn 0;\n\nerr:\n\tlog_err(\"Can't create rate workqueue\\n\");\n\ttd_verror(td, ESRCH, \"workqueue_init\");\n\tworkqueue_exit(wq);\n\treturn 1;\n}\n"
        },
        {
          "name": "workqueue.h",
          "type": "blob",
          "size": 2.74609375,
          "content": "#ifndef FIO_RATE_H\n#define FIO_RATE_H\n\n#include <inttypes.h>\n#include <pthread.h>\n\n#include \"flist.h\"\n#include \"lib/types.h\"\n\nstruct sk_out;\nstruct thread_data;\n\nstruct workqueue_work {\n\tstruct flist_head list;\n};\n\nstruct submit_worker {\n\tpthread_t thread;\n\tpthread_mutex_t lock;\n\tpthread_cond_t cond;\n\tstruct flist_head work_list;\n\tunsigned int flags;\n\tunsigned int index;\n\tuint64_t seq;\n\tstruct workqueue *wq;\n\tvoid *priv;\n\tstruct sk_out *sk_out;\n};\n\ntypedef int (workqueue_work_fn)(struct submit_worker *, struct workqueue_work *);\ntypedef bool (workqueue_pre_sleep_flush_fn)(struct submit_worker *);\ntypedef void (workqueue_pre_sleep_fn)(struct submit_worker *);\ntypedef int (workqueue_alloc_worker_fn)(struct submit_worker *);\ntypedef void (workqueue_free_worker_fn)(struct submit_worker *);\ntypedef int (workqueue_init_worker_fn)(struct submit_worker *);\ntypedef void (workqueue_exit_worker_fn)(struct submit_worker *, unsigned int *);\ntypedef void (workqueue_update_acct_fn)(struct submit_worker *);\n\nstruct workqueue_ops {\n\tworkqueue_work_fn *fn;\n\tworkqueue_pre_sleep_flush_fn *pre_sleep_flush_fn;\n\tworkqueue_pre_sleep_fn *pre_sleep_fn;\n\n\tworkqueue_update_acct_fn *update_acct_fn;\n\n\tworkqueue_alloc_worker_fn *alloc_worker_fn;\n\tworkqueue_free_worker_fn *free_worker_fn;\n\n\tworkqueue_init_worker_fn *init_worker_fn;\n\tworkqueue_exit_worker_fn *exit_worker_fn;\n\n\tunsigned int nice;\n};\n\nstruct workqueue {\n\tunsigned int max_workers;\n\n\tstruct thread_data *td;\n\tstruct workqueue_ops ops;\n\n\tuint64_t work_seq;\n\tstruct submit_worker *workers;\n\tunsigned int next_free_worker;\n\n\tpthread_cond_t flush_cond;\n\tpthread_mutex_t flush_lock;\n\tpthread_mutex_t stat_lock;\n\tvolatile int wake_idle;\n};\n\nint workqueue_init(struct thread_data *td, struct workqueue *wq, struct workqueue_ops *ops, unsigned int max_workers, struct sk_out *sk_out);\nvoid workqueue_exit(struct workqueue *wq);\n\nvoid workqueue_enqueue(struct workqueue *wq, struct workqueue_work *work);\nvoid workqueue_flush(struct workqueue *wq);\n\nstatic inline bool workqueue_pre_sleep_check(struct submit_worker *sw)\n{\n\tstruct workqueue *wq = sw->wq;\n\n\tif (!wq->ops.pre_sleep_flush_fn)\n\t\treturn false;\n\n\treturn wq->ops.pre_sleep_flush_fn(sw);\n}\n\nstatic inline void workqueue_pre_sleep(struct submit_worker *sw)\n{\n\tstruct workqueue *wq = sw->wq;\n\n\tif (wq->ops.pre_sleep_fn)\n\t\twq->ops.pre_sleep_fn(sw);\n}\n\nstatic inline int workqueue_init_worker(struct submit_worker *sw)\n{\n\tstruct workqueue *wq = sw->wq;\n\n\tif (!wq->ops.init_worker_fn)\n\t\treturn 0;\n\n\treturn wq->ops.init_worker_fn(sw);\n}\n\nstatic inline void workqueue_exit_worker(struct submit_worker *sw,\n\t\t\t\t\t unsigned int *sum_cnt)\n{\n\tstruct workqueue *wq = sw->wq;\n\tunsigned int tmp = 1;\n\n\tif (!wq->ops.exit_worker_fn)\n\t\treturn;\n\n\tif (!sum_cnt)\n\t\tsum_cnt = &tmp;\n\n\twq->ops.exit_worker_fn(sw, sum_cnt);\n}\n#endif\n"
        },
        {
          "name": "zbd.c",
          "type": "blob",
          "size": 57.5546875,
          "content": "/*\n * Copyright (C) 2018 Western Digital Corporation or its affiliates.\n *\n * This file is released under the GPL.\n */\n\n#include <errno.h>\n#include <string.h>\n#include <stdlib.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <unistd.h>\n\n#include \"compiler/compiler.h\"\n#include \"os/os.h\"\n#include \"file.h\"\n#include \"fio.h\"\n#include \"lib/pow2.h\"\n#include \"log.h\"\n#include \"oslib/asprintf.h\"\n#include \"smalloc.h\"\n#include \"verify.h\"\n#include \"pshared.h\"\n#include \"zbd.h\"\n\nstatic bool is_valid_offset(const struct fio_file *f, uint64_t offset)\n{\n\treturn (uint64_t)(offset - f->file_offset) < f->io_size;\n}\n\nstatic inline unsigned int zbd_zone_idx(const struct fio_file *f,\n\t\t\t\t\tstruct fio_zone_info *zone)\n{\n\treturn zone - f->zbd_info->zone_info;\n}\n\n/**\n * zbd_offset_to_zone_idx - convert an offset into a zone number\n * @f: file pointer.\n * @offset: offset in bytes. If this offset is in the first zone_size bytes\n *\t    past the disk size then the index of the sentinel is returned.\n */\nstatic unsigned int zbd_offset_to_zone_idx(const struct fio_file *f,\n\t\t\t\t\t   uint64_t offset)\n{\n\tuint32_t zone_idx;\n\n\tif (f->zbd_info->zone_size_log2 > 0)\n\t\tzone_idx = offset >> f->zbd_info->zone_size_log2;\n\telse\n\t\tzone_idx = offset / f->zbd_info->zone_size;\n\n\treturn min(zone_idx, f->zbd_info->nr_zones);\n}\n\n/**\n * zbd_zone_end - Return zone end location\n * @z: zone info pointer.\n */\nstatic inline uint64_t zbd_zone_end(const struct fio_zone_info *z)\n{\n\treturn (z+1)->start;\n}\n\n/**\n * zbd_zone_capacity_end - Return zone capacity limit end location\n * @z: zone info pointer.\n */\nstatic inline uint64_t zbd_zone_capacity_end(const struct fio_zone_info *z)\n{\n\treturn z->start + z->capacity;\n}\n\n/**\n * zbd_zone_remainder - Return the number of bytes that are still available for\n *                      writing before the zone gets full\n * @z: zone info pointer.\n */\nstatic inline uint64_t zbd_zone_remainder(struct fio_zone_info *z)\n{\n\tif (z->wp >= zbd_zone_capacity_end(z))\n\t\treturn 0;\n\n\treturn zbd_zone_capacity_end(z) - z->wp;\n}\n\n/**\n * zbd_zone_full - verify whether a minimum number of bytes remain in a zone\n * @f: file pointer.\n * @z: zone info pointer.\n * @required: minimum number of bytes that must remain in a zone.\n *\n * The caller must hold z->mutex.\n */\nstatic bool zbd_zone_full(const struct fio_file *f, struct fio_zone_info *z,\n\t\t\t  uint64_t required)\n{\n\tassert((required & 511) == 0);\n\n\treturn z->has_wp && required > zbd_zone_remainder(z);\n}\n\nstatic void zone_lock(struct thread_data *td, const struct fio_file *f,\n\t\t      struct fio_zone_info *z)\n{\n#ifndef NDEBUG\n\tunsigned int const nz = zbd_zone_idx(f, z);\n\t/* A thread should never lock zones outside its working area. */\n\tassert(f->min_zone <= nz && nz < f->max_zone);\n\tassert(z->has_wp);\n#endif\n\n\t/*\n\t * Lock the io_u target zone. The zone will be unlocked if io_u offset\n\t * is changed or when io_u completes and zbd_put_io() executed.\n\t * To avoid multiple jobs doing asynchronous I/Os from deadlocking each\n\t * other waiting for zone locks when building an io_u batch, first\n\t * only trylock the zone. If the zone is already locked by another job,\n\t * process the currently queued I/Os so that I/O progress is made and\n\t * zones unlocked.\n\t */\n\tif (pthread_mutex_trylock(&z->mutex) != 0) {\n\t\tif (!td_ioengine_flagged(td, FIO_SYNCIO))\n\t\t\tio_u_quiesce(td);\n\t\tpthread_mutex_lock(&z->mutex);\n\t}\n}\n\nstatic inline void zone_unlock(struct fio_zone_info *z)\n{\n\tassert(z->has_wp);\n\tpthread_mutex_unlock(&z->mutex);\n}\n\nstatic inline struct fio_zone_info *zbd_get_zone(const struct fio_file *f,\n\t\t\t\t\t\t unsigned int zone_idx)\n{\n\treturn &f->zbd_info->zone_info[zone_idx];\n}\n\nstatic inline struct fio_zone_info *\nzbd_offset_to_zone(const struct fio_file *f,  uint64_t offset)\n{\n\treturn zbd_get_zone(f, zbd_offset_to_zone_idx(f, offset));\n}\n\nstatic bool accounting_vdb(struct thread_data *td, const struct fio_file *f)\n{\n\treturn td->o.zrt.u.f && td_write(td);\n}\n\n/**\n * zbd_get_zoned_model - Get a device zoned model\n * @td: FIO thread data\n * @f: FIO file for which to get model information\n */\nstatic int zbd_get_zoned_model(struct thread_data *td, struct fio_file *f,\n\t\t\t       enum zbd_zoned_model *model)\n{\n\tint ret;\n\n\tif (f->filetype == FIO_TYPE_PIPE) {\n\t\tlog_err(\"zonemode=zbd does not support pipes\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* If regular file, always emulate zones inside the file. */\n\tif (f->filetype == FIO_TYPE_FILE) {\n\t\t*model = ZBD_NONE;\n\t\treturn 0;\n\t}\n\n\tif (td->io_ops && td->io_ops->get_zoned_model)\n\t\tret = td->io_ops->get_zoned_model(td, f, model);\n\telse\n\t\tret = blkzoned_get_zoned_model(td, f, model);\n\tif (ret < 0) {\n\t\ttd_verror(td, errno, \"get zoned model failed\");\n\t\tlog_err(\"%s: get zoned model failed (%d).\\n\",\n\t\t\tf->file_name, errno);\n\t}\n\n\treturn ret;\n}\n\n/**\n * zbd_report_zones - Get zone information\n * @td: FIO thread data.\n * @f: FIO file for which to get zone information\n * @offset: offset from which to report zones\n * @zones: Array of struct zbd_zone\n * @nr_zones: Size of @zones array\n *\n * Get zone information into @zones starting from the zone at offset @offset\n * for the device specified by @f.\n *\n * Returns the number of zones reported upon success and a negative error code\n * upon failure. If the zone report is empty, always assume an error (device\n * problem) and return -EIO.\n */\nstatic int zbd_report_zones(struct thread_data *td, struct fio_file *f,\n\t\t\t    uint64_t offset, struct zbd_zone *zones,\n\t\t\t    unsigned int nr_zones)\n{\n\tint ret;\n\n\tif (td->io_ops && td->io_ops->report_zones)\n\t\tret = td->io_ops->report_zones(td, f, offset, zones, nr_zones);\n\telse\n\t\tret = blkzoned_report_zones(td, f, offset, zones, nr_zones);\n\tif (ret < 0) {\n\t\ttd_verror(td, errno, \"report zones failed\");\n\t\tlog_err(\"%s: report zones from sector %\"PRIu64\" failed (nr_zones=%d; errno=%d).\\n\",\n\t\t\tf->file_name, offset >> 9, nr_zones, errno);\n\t} else if (ret == 0) {\n\t\ttd_verror(td, errno, \"Empty zone report\");\n\t\tlog_err(\"%s: report zones from sector %\"PRIu64\" is empty.\\n\",\n\t\t\tf->file_name, offset >> 9);\n\t\tret = -EIO;\n\t}\n\n\treturn ret;\n}\n\n/**\n * zbd_reset_wp - reset the write pointer of a range of zones\n * @td: FIO thread data.\n * @f: FIO file for which to reset zones\n * @offset: Starting offset of the first zone to reset\n * @length: Length of the range of zones to reset\n *\n * Reset the write pointer of all zones in the range @offset...@offset+@length.\n * Returns 0 upon success and a negative error code upon failure.\n */\nstatic int zbd_reset_wp(struct thread_data *td, struct fio_file *f,\n\t\t\tuint64_t offset, uint64_t length)\n{\n\tint ret;\n\n\tif (td->io_ops && td->io_ops->reset_wp)\n\t\tret = td->io_ops->reset_wp(td, f, offset, length);\n\telse\n\t\tret = blkzoned_reset_wp(td, f, offset, length);\n\tif (ret < 0) {\n\t\ttd_verror(td, errno, \"resetting wp failed\");\n\t\tlog_err(\"%s: resetting wp for %\"PRIu64\" sectors at sector %\"PRIu64\" failed (%d).\\n\",\n\t\t\tf->file_name, length >> 9, offset >> 9, errno);\n\t}\n\n\treturn ret;\n}\n\n/**\n * __zbd_reset_zone - reset the write pointer of a single zone\n * @td: FIO thread data.\n * @f: FIO file associated with the disk for which to reset a write pointer.\n * @z: Zone to reset.\n *\n * Returns 0 upon success and a negative error code upon failure.\n *\n * The caller must hold z->mutex.\n */\nstatic int __zbd_reset_zone(struct thread_data *td, struct fio_file *f,\n\t\t\t    struct fio_zone_info *z)\n{\n\tuint64_t offset = z->start;\n\tuint64_t length = (z+1)->start - offset;\n\tuint64_t data_in_zone = z->wp - z->start;\n\tint ret = 0;\n\n\tif (!data_in_zone)\n\t\treturn 0;\n\n\tassert(is_valid_offset(f, offset + length - 1));\n\n\tdprint(FD_ZBD, \"%s: resetting wp of zone %u.\\n\",\n\t       f->file_name, zbd_zone_idx(f, z));\n\n\tswitch (f->zbd_info->model) {\n\tcase ZBD_HOST_AWARE:\n\tcase ZBD_HOST_MANAGED:\n\t\tret = zbd_reset_wp(td, f, offset, length);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (accounting_vdb(td, f)) {\n\t\tpthread_mutex_lock(&f->zbd_info->mutex);\n\t\tf->zbd_info->wp_valid_data_bytes -= data_in_zone;\n\t\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\t}\n\n\tz->wp = z->start;\n\n\ttd->ts.nr_zone_resets++;\n\n\treturn ret;\n}\n\n/**\n * zbd_write_zone_put - Remove a zone from the write target zones array.\n * @td: FIO thread data.\n * @f: FIO file that has the write zones array to remove.\n * @zone_idx: Index of the zone to remove.\n *\n * The caller must hold f->zbd_info->mutex.\n */\nstatic void zbd_write_zone_put(struct thread_data *td, const struct fio_file *f,\n\t\t\t       struct fio_zone_info *z)\n{\n\tuint32_t zi;\n\n\tif (!z->write)\n\t\treturn;\n\n\tfor (zi = 0; zi < f->zbd_info->num_write_zones; zi++) {\n\t\tif (zbd_get_zone(f, f->zbd_info->write_zones[zi]) == z)\n\t\t\tbreak;\n\t}\n\tif (zi == f->zbd_info->num_write_zones)\n\t\treturn;\n\n\tdprint(FD_ZBD, \"%s: removing zone %u from write zone array\\n\",\n\t       f->file_name, zbd_zone_idx(f, z));\n\n\tmemmove(f->zbd_info->write_zones + zi,\n\t\tf->zbd_info->write_zones + zi + 1,\n\t\t(ZBD_MAX_WRITE_ZONES - (zi + 1)) *\n\t\tsizeof(f->zbd_info->write_zones[0]));\n\n\tf->zbd_info->num_write_zones--;\n\ttd->num_write_zones--;\n\tz->write = 0;\n}\n\n/**\n * zbd_reset_zone - reset the write pointer of a single zone and remove the zone\n *                  from the array of write zones.\n * @td: FIO thread data.\n * @f: FIO file associated with the disk for which to reset a write pointer.\n * @z: Zone to reset.\n *\n * Returns 0 upon success and a negative error code upon failure.\n *\n * The caller must hold z->mutex.\n */\nstatic int zbd_reset_zone(struct thread_data *td, struct fio_file *f,\n\t\t\t  struct fio_zone_info *z)\n{\n\tint ret;\n\n\tret = __zbd_reset_zone(td, f, z);\n\tif (ret)\n\t\treturn ret;\n\n\tpthread_mutex_lock(&f->zbd_info->mutex);\n\tzbd_write_zone_put(td, f, z);\n\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\treturn 0;\n}\n\n/**\n * zbd_finish_zone - finish the specified zone\n * @td: FIO thread data.\n * @f: FIO file for which to finish a zone\n * @z: Zone to finish.\n *\n * Finish the zone at @offset with open or close status.\n */\nstatic int zbd_finish_zone(struct thread_data *td, struct fio_file *f,\n\t\t\t   struct fio_zone_info *z)\n{\n\tuint64_t offset = z->start;\n\tuint64_t length = f->zbd_info->zone_size;\n\tint ret = 0;\n\n\tswitch (f->zbd_info->model) {\n\tcase ZBD_HOST_AWARE:\n\tcase ZBD_HOST_MANAGED:\n\t\tif (td->io_ops && td->io_ops->finish_zone)\n\t\t\tret = td->io_ops->finish_zone(td, f, offset, length);\n\t\telse\n\t\t\tret = blkzoned_finish_zone(td, f, offset, length);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ret < 0) {\n\t\ttd_verror(td, errno, \"finish zone failed\");\n\t\tlog_err(\"%s: finish zone at sector %\"PRIu64\" failed (%d).\\n\",\n\t\t\tf->file_name, offset >> 9, errno);\n\t} else {\n\t\tz->wp = (z+1)->start;\n\t}\n\n\treturn ret;\n}\n\n/**\n * zbd_reset_zones - Reset a range of zones.\n * @td: fio thread data.\n * @f: fio file for which to reset zones\n * @zb: first zone to reset.\n * @ze: first zone not to reset.\n *\n * Returns 0 upon success and 1 upon failure.\n */\nstatic int zbd_reset_zones(struct thread_data *td, struct fio_file *f,\n\t\t\t   struct fio_zone_info *const zb,\n\t\t\t   struct fio_zone_info *const ze)\n{\n\tstruct fio_zone_info *z;\n\tconst uint64_t min_bs = td->o.min_bs[DDIR_WRITE];\n\tint res = 0;\n\n\tif (fio_unlikely(0 == min_bs))\n\t\treturn 1;\n\n\tdprint(FD_ZBD, \"%s: examining zones %u .. %u\\n\",\n\t       f->file_name, zbd_zone_idx(f, zb), zbd_zone_idx(f, ze));\n\n\tfor (z = zb; z < ze; z++) {\n\t\tif (!z->has_wp)\n\t\t\tcontinue;\n\n\t\tzone_lock(td, f, z);\n\n\t\tif (z->wp != z->start) {\n\t\t\tdprint(FD_ZBD, \"%s: resetting zone %u\\n\",\n\t\t\t       f->file_name, zbd_zone_idx(f, z));\n\t\t\tif (zbd_reset_zone(td, f, z) < 0)\n\t\t\t\tres = 1;\n\t\t}\n\n\t\tzone_unlock(z);\n\t}\n\n\treturn res;\n}\n\n/**\n * zbd_get_max_open_zones - Get the maximum number of open zones\n * @td: FIO thread data\n * @f: FIO file for which to get max open zones\n * @max_open_zones: Upon success, result will be stored here.\n *\n * A @max_open_zones value set to zero means no limit.\n *\n * Returns 0 upon success and a negative error code upon failure.\n */\nstatic int zbd_get_max_open_zones(struct thread_data *td, struct fio_file *f,\n\t\t\t\t  unsigned int *max_open_zones)\n{\n\tint ret;\n\n\tif (td->io_ops && td->io_ops->get_max_open_zones)\n\t\tret = td->io_ops->get_max_open_zones(td, f, max_open_zones);\n\telse\n\t\tret = blkzoned_get_max_open_zones(td, f, max_open_zones);\n\tif (ret < 0) {\n\t\ttd_verror(td, errno, \"get max open zones failed\");\n\t\tlog_err(\"%s: get max open zones failed (%d).\\n\",\n\t\t\tf->file_name, errno);\n\t}\n\n\treturn ret;\n}\n\n/**\n * zbd_get_max_active_zones - Get the maximum number of active zones\n * @td: FIO thread data\n * @f: FIO file for which to get max active zones\n *\n * Returns max_active_zones limit value of the target file if it is available.\n * Otherwise return zero, which means no limit.\n */\nstatic unsigned int zbd_get_max_active_zones(struct thread_data *td,\n\t\t\t\t\t     struct fio_file *f)\n{\n\tunsigned int max_active_zones;\n\tint ret;\n\n\tif (td->io_ops && td->io_ops->get_max_active_zones)\n\t\tret = td->io_ops->get_max_active_zones(td, f,\n\t\t\t\t\t\t       &max_active_zones);\n\telse\n\t\tret = blkzoned_get_max_active_zones(td, f, &max_active_zones);\n\tif (ret < 0) {\n\t\tdprint(FD_ZBD, \"%s: max_active_zones is not available\\n\",\n\t\t       f->file_name);\n\t\treturn 0;\n\t}\n\n\treturn max_active_zones;\n}\n\n/**\n * __zbd_write_zone_get - Add a zone to the array of write zones.\n * @td: fio thread data.\n * @f: fio file that has the write zones array to add.\n * @zone_idx: Index of the zone to add.\n *\n * Do same operation as @zbd_write_zone_get, except it adds the zone at\n * @zone_idx to write target zones array even when it does not have remainder\n * space to write one block.\n */\nstatic bool __zbd_write_zone_get(struct thread_data *td,\n\t\t\t\t const struct fio_file *f,\n\t\t\t\t struct fio_zone_info *z)\n{\n\tstruct zoned_block_device_info *zbdi = f->zbd_info;\n\tuint32_t zone_idx = zbd_zone_idx(f, z);\n\tbool res = true;\n\n\tif (z->cond == ZBD_ZONE_COND_OFFLINE)\n\t\treturn false;\n\n\t/*\n\t * Skip full zones with data verification enabled because resetting a\n\t * zone causes data loss and hence causes verification to fail.\n\t */\n\tif (td->o.verify != VERIFY_NONE && zbd_zone_remainder(z) == 0)\n\t\treturn false;\n\n\t/*\n\t * zbdi->max_write_zones == 0 means that there is no limit on the\n\t * maximum number of write target zones. In this case, do no track write\n\t * target zones in zbdi->write_zones array.\n\t */\n\tif (!zbdi->max_write_zones)\n\t\treturn true;\n\n\tpthread_mutex_lock(&zbdi->mutex);\n\n\tif (z->write) {\n\t\t/*\n\t\t * If the zone is going to be completely filled by writes\n\t\t * already in-flight, handle it as a full zone instead of a\n\t\t * write target zone.\n\t\t */\n\t\tif (!zbd_zone_remainder(z))\n\t\t\tres = false;\n\t\tgoto out;\n\t}\n\n\tres = false;\n\t/* Zero means no limit */\n\tif (td->o.job_max_open_zones > 0 &&\n\t    td->num_write_zones >= td->o.job_max_open_zones)\n\t\tgoto out;\n\tif (zbdi->num_write_zones >= zbdi->max_write_zones)\n\t\tgoto out;\n\n\tdprint(FD_ZBD, \"%s: adding zone %u to write zone array\\n\",\n\t       f->file_name, zone_idx);\n\n\tzbdi->write_zones[zbdi->num_write_zones++] = zone_idx;\n\ttd->num_write_zones++;\n\tz->write = 1;\n\tres = true;\n\nout:\n\tpthread_mutex_unlock(&zbdi->mutex);\n\treturn res;\n}\n\n/**\n * zbd_write_zone_get - Add a zone to the array of write zones.\n * @td: fio thread data.\n * @f: fio file that has the open zones to add.\n * @zone_idx: Index of the zone to add.\n *\n * Add a ZBD zone to write target zones array, if it is not yet added. Returns\n * true if either the zone was already added or if the zone was successfully\n * added to the array without exceeding the maximum number of write zones.\n * Returns false if the zone was not already added and addition of the zone\n * would cause the zone limit to be exceeded.\n */\nstatic bool zbd_write_zone_get(struct thread_data *td, const struct fio_file *f,\n\t\t\t       struct fio_zone_info *z)\n{\n\tconst uint64_t min_bs = td->o.min_bs[DDIR_WRITE];\n\n\t/*\n\t * Skip full zones with data verification enabled because resetting a\n\t * zone causes data loss and hence causes verification to fail.\n\t */\n\tif (td->o.verify != VERIFY_NONE && zbd_zone_full(f, z, min_bs))\n\t\treturn false;\n\n\treturn __zbd_write_zone_get(td, f, z);\n}\n\n/* Verify whether direct I/O is used for all host-managed zoned block drives. */\nstatic bool zbd_using_direct_io(void)\n{\n\tstruct fio_file *f;\n\tint j;\n\n\tfor_each_td(td) {\n\t\tif (td->o.odirect || !(td->o.td_ddir & TD_DDIR_WRITE))\n\t\t\tcontinue;\n\t\tfor_each_file(td, f, j) {\n\t\t\tif (f->zbd_info && f->filetype == FIO_TYPE_BLOCK &&\n\t\t\t    f->zbd_info->model == ZBD_HOST_MANAGED)\n\t\t\t\treturn false;\n\t\t}\n\t} end_for_each();\n\n\treturn true;\n}\n\n/* Whether or not the I/O range for f includes one or more sequential zones */\nstatic bool zbd_is_seq_job(const struct fio_file *f)\n{\n\tuint32_t zone_idx, zone_idx_b, zone_idx_e;\n\n\tassert(f->zbd_info);\n\n\tif (f->io_size == 0)\n\t\treturn false;\n\n\tzone_idx_b = zbd_offset_to_zone_idx(f, f->file_offset);\n\tzone_idx_e =\n\t\tzbd_offset_to_zone_idx(f, f->file_offset + f->io_size - 1);\n\tfor (zone_idx = zone_idx_b; zone_idx <= zone_idx_e; zone_idx++)\n\t\tif (zbd_get_zone(f, zone_idx)->has_wp)\n\t\t\treturn true;\n\n\treturn false;\n}\n\n/*\n * Verify whether the file offset and size parameters are aligned with zone\n * boundaries. If the file offset is not aligned, align it down to the start of\n * the zone containing the start offset and align up the file io_size parameter.\n */\nstatic bool zbd_zone_align_file_sizes(struct thread_data *td,\n\t\t\t\t      struct fio_file *f)\n{\n\tconst struct fio_zone_info *z;\n\tuint64_t new_offset, new_end;\n\n\tif (!f->zbd_info)\n\t\treturn true;\n\tif (f->file_offset >= f->real_file_size)\n\t\treturn true;\n\tif (!zbd_is_seq_job(f))\n\t\treturn true;\n\n\tif (!td->o.zone_size) {\n\t\ttd->o.zone_size = f->zbd_info->zone_size;\n\t\tif (!td->o.zone_size) {\n\t\t\tlog_err(\"%s: invalid 0 zone size\\n\",\n\t\t\t\tf->file_name);\n\t\t\treturn false;\n\t\t}\n\t} else if (td->o.zone_size != f->zbd_info->zone_size) {\n\t\tlog_err(\"%s: zonesize %llu does not match the device zone size %\"PRIu64\".\\n\",\n\t\t\tf->file_name, td->o.zone_size,\n\t\t\tf->zbd_info->zone_size);\n\t\treturn false;\n\t}\n\n\tif (td->o.zone_skip % td->o.zone_size) {\n\t\tlog_err(\"%s: zoneskip %llu is not a multiple of the device zone size %llu.\\n\",\n\t\t\tf->file_name, td->o.zone_skip,\n\t\t\ttd->o.zone_size);\n\t\treturn false;\n\t}\n\n\tif (td->o.td_ddir == TD_DDIR_READ) {\n\t\tz = zbd_offset_to_zone(f, f->file_offset + f->io_size);\n\t\tnew_end = z->start;\n\t\tif (f->file_offset + f->io_size > new_end) {\n\t\t\tlog_info(\"%s: rounded io_size from %\"PRIu64\" to %\"PRIu64\"\\n\",\n\t\t\t\t f->file_name, f->io_size,\n\t\t\t\t new_end - f->file_offset);\n\t\t\tf->io_size = new_end - f->file_offset;\n\t\t}\n\t\treturn true;\n\t}\n\n\tz = zbd_offset_to_zone(f, f->file_offset);\n\tif (f->file_offset != z->start) {\n\t\tnew_offset = zbd_zone_end(z);\n\t\tif (new_offset >= f->file_offset + f->io_size) {\n\t\t\tlog_info(\"%s: io_size must be at least one zone\\n\",\n\t\t\t\t f->file_name);\n\t\t\treturn false;\n\t\t}\n\t\tlog_info(\"%s: rounded up offset from %\"PRIu64\" to %\"PRIu64\"\\n\",\n\t\t\t f->file_name, f->file_offset,\n\t\t\t new_offset);\n\t\tf->io_size -= (new_offset - f->file_offset);\n\t\tf->file_offset = new_offset;\n\t}\n\n\tz = zbd_offset_to_zone(f, f->file_offset + f->io_size);\n\tnew_end = z->start;\n\tif (f->file_offset + f->io_size != new_end) {\n\t\tif (new_end <= f->file_offset) {\n\t\t\tlog_info(\"%s: io_size must be at least one zone\\n\",\n\t\t\t\t f->file_name);\n\t\t\treturn false;\n\t\t}\n\t\tlog_info(\"%s: rounded down io_size from %\"PRIu64\" to %\"PRIu64\"\\n\",\n\t\t\t f->file_name, f->io_size,\n\t\t\t new_end - f->file_offset);\n\t\tf->io_size = new_end - f->file_offset;\n\t}\n\n\treturn true;\n}\n\n/*\n * Verify whether offset and size parameters are aligned with zone boundaries.\n */\nstatic bool zbd_verify_sizes(void)\n{\n\tstruct fio_file *f;\n\tint j;\n\n\tfor_each_td(td) {\n\t\tfor_each_file(td, f, j) {\n\t\t\tif (!zbd_zone_align_file_sizes(td, f))\n\t\t\t\treturn false;\n\t\t}\n\t} end_for_each();\n\n\treturn true;\n}\n\nstatic bool zbd_verify_bs(void)\n{\n\tstruct fio_file *f;\n\tint j;\n\n\tfor_each_td(td) {\n\t\tif (td_trim(td) &&\n\t\t    (td->o.min_bs[DDIR_TRIM] != td->o.max_bs[DDIR_TRIM] ||\n\t\t     td->o.bssplit_nr[DDIR_TRIM])) {\n\t\t\tlog_info(\"bsrange and bssplit are not allowed for trim with zonemode=zbd\\n\");\n\t\t\treturn false;\n\t\t}\n\t\tfor_each_file(td, f, j) {\n\t\t\tuint64_t zone_size;\n\n\t\t\tif (!f->zbd_info)\n\t\t\t\tcontinue;\n\n\t\t\tzone_size = f->zbd_info->zone_size;\n\t\t\tif (td_trim(td) && td->o.bs[DDIR_TRIM] != zone_size) {\n\t\t\t\tlog_info(\"%s: trim block size %llu is not the zone size %\"PRIu64\"\\n\",\n\t\t\t\t\t f->file_name, td->o.bs[DDIR_TRIM],\n\t\t\t\t\t zone_size);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t} end_for_each();\n\treturn true;\n}\n\nstatic int ilog2(uint64_t i)\n{\n\tint log = -1;\n\n\twhile (i) {\n\t\ti >>= 1;\n\t\tlog++;\n\t}\n\treturn log;\n}\n\n/*\n * Initialize f->zbd_info for devices that are not zoned block devices. This\n * allows to execute a ZBD workload against a non-ZBD device.\n */\nstatic int init_zone_info(struct thread_data *td, struct fio_file *f)\n{\n\tuint32_t nr_zones;\n\tstruct fio_zone_info *p;\n\tuint64_t zone_size = td->o.zone_size;\n\tuint64_t zone_capacity = td->o.zone_capacity;\n\tstruct zoned_block_device_info *zbd_info = NULL;\n\tint i;\n\n\tif (zone_size == 0) {\n\t\tlog_err(\"%s: Specifying the zone size is mandatory for regular file/block device with --zonemode=zbd\\n\\n\",\n\t\t\tf->file_name);\n\t\treturn 1;\n\t}\n\n\tif (zone_size < 512) {\n\t\tlog_err(\"%s: zone size must be at least 512 bytes for --zonemode=zbd\\n\\n\",\n\t\t\tf->file_name);\n\t\treturn 1;\n\t}\n\n\tif (zone_capacity == 0)\n\t\tzone_capacity = zone_size;\n\n\tif (zone_capacity > zone_size) {\n\t\tlog_err(\"%s: job parameter zonecapacity %llu is larger than zone size %llu\\n\",\n\t\t\tf->file_name, td->o.zone_capacity, td->o.zone_size);\n\t\treturn 1;\n\t}\n\n\tif (f->real_file_size < zone_size) {\n\t\tlog_err(\"%s: file/device size %\"PRIu64\" is smaller than zone size %\"PRIu64\"\\n\",\n\t\t\tf->file_name, f->real_file_size, zone_size);\n\t\treturn -EINVAL;\n\t}\n\n\tnr_zones = (f->real_file_size + zone_size - 1) / zone_size;\n\tzbd_info = scalloc(1, sizeof(*zbd_info) +\n\t\t\t   (nr_zones + 1) * sizeof(zbd_info->zone_info[0]));\n\tif (!zbd_info)\n\t\treturn -ENOMEM;\n\n\tmutex_init_pshared(&zbd_info->mutex);\n\tzbd_info->refcount = 1;\n\tp = &zbd_info->zone_info[0];\n\tfor (i = 0; i < nr_zones; i++, p++) {\n\t\tmutex_init_pshared_with_type(&p->mutex,\n\t\t\t\t\t     PTHREAD_MUTEX_RECURSIVE);\n\t\tp->start = i * zone_size;\n\t\tp->wp = p->start;\n\t\tp->type = ZBD_ZONE_TYPE_SWR;\n\t\tp->cond = ZBD_ZONE_COND_EMPTY;\n\t\tp->capacity = zone_capacity;\n\t\tp->has_wp = 1;\n\t}\n\t/* a sentinel */\n\tp->start = nr_zones * zone_size;\n\n\tf->zbd_info = zbd_info;\n\tf->zbd_info->zone_size = zone_size;\n\tf->zbd_info->zone_size_log2 = is_power_of_2(zone_size) ?\n\t\tilog2(zone_size) : 0;\n\tf->zbd_info->nr_zones = nr_zones;\n\treturn 0;\n}\n\n/*\n * Maximum number of zones to report in one operation.\n */\n#define ZBD_REPORT_MAX_ZONES\t8192U\n\n/*\n * Parse the device zone report and store it in f->zbd_info. Must be called\n * only for devices that are zoned, namely those with a model != ZBD_NONE.\n */\nstatic int parse_zone_info(struct thread_data *td, struct fio_file *f)\n{\n\tint nr_zones, nrz;\n\tstruct zbd_zone *zones, *z;\n\tstruct fio_zone_info *p;\n\tuint64_t zone_size, offset, capacity;\n\tbool same_zone_cap = true;\n\tstruct zoned_block_device_info *zbd_info = NULL;\n\tint i, j, ret = -ENOMEM;\n\n\tzones = calloc(ZBD_REPORT_MAX_ZONES, sizeof(struct zbd_zone));\n\tif (!zones)\n\t\tgoto out;\n\n\tnrz = zbd_report_zones(td, f, 0, zones, ZBD_REPORT_MAX_ZONES);\n\tif (nrz < 0) {\n\t\tret = nrz;\n\t\tlog_info(\"fio: report zones (offset 0) failed for %s (%d).\\n\",\n\t\t\t f->file_name, -ret);\n\t\tgoto out;\n\t}\n\n\tzone_size = zones[0].len;\n\tcapacity = zones[0].capacity;\n\tnr_zones = (f->real_file_size + zone_size - 1) / zone_size;\n\n\tif (td->o.zone_size == 0) {\n\t\ttd->o.zone_size = zone_size;\n\t} else if (td->o.zone_size != zone_size) {\n\t\tlog_err(\"fio: %s job parameter zonesize %llu does not match disk zone size %\"PRIu64\".\\n\",\n\t\t\tf->file_name, td->o.zone_size, zone_size);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tdprint(FD_ZBD, \"Device %s has %d zones of size %\"PRIu64\" KB\\n\",\n\t       f->file_name, nr_zones, zone_size / 1024);\n\n\tzbd_info = scalloc(1, sizeof(*zbd_info) +\n\t\t\t   (nr_zones + 1) * sizeof(zbd_info->zone_info[0]));\n\tif (!zbd_info)\n\t\tgoto out;\n\tmutex_init_pshared(&zbd_info->mutex);\n\tzbd_info->refcount = 1;\n\tp = &zbd_info->zone_info[0];\n\tfor (offset = 0, j = 0; j < nr_zones;) {\n\t\tz = &zones[0];\n\t\tfor (i = 0; i < nrz; i++, j++, z++, p++) {\n\t\t\tmutex_init_pshared_with_type(&p->mutex,\n\t\t\t\t\t\t     PTHREAD_MUTEX_RECURSIVE);\n\t\t\tp->start = z->start;\n\t\t\tp->capacity = z->capacity;\n\t\t\tif (capacity != z->capacity)\n\t\t\t\tsame_zone_cap = false;\n\n\t\t\tswitch (z->cond) {\n\t\t\tcase ZBD_ZONE_COND_NOT_WP:\n\t\t\tcase ZBD_ZONE_COND_FULL:\n\t\t\t\tp->wp = p->start + p->capacity;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tassert(z->start <= z->wp);\n\t\t\t\tassert(z->wp <= z->start + zone_size);\n\t\t\t\tp->wp = z->wp;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (z->type) {\n\t\t\tcase ZBD_ZONE_TYPE_SWR:\n\t\t\t\tp->has_wp = 1;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tp->has_wp = 0;\n\t\t\t}\n\t\t\tp->type = z->type;\n\t\t\tp->cond = z->cond;\n\n\t\t\tif (j > 0 && p->start != p[-1].start + zone_size) {\n\t\t\t\tlog_info(\"%s: invalid zone data [%d:%d]: %\"PRIu64\" + %\"PRIu64\" != %\"PRIu64\"\\n\",\n\t\t\t\t\t f->file_name, j, i,\n\t\t\t\t\t p[-1].start, zone_size, p->start);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tz--;\n\t\toffset = z->start + z->len;\n\t\tif (j >= nr_zones)\n\t\t\tbreak;\n\n\t\tnrz = zbd_report_zones(td, f, offset, zones,\n\t\t\t\t       min((uint32_t)(nr_zones - j),\n\t\t\t\t\t   ZBD_REPORT_MAX_ZONES));\n\t\tif (nrz < 0) {\n\t\t\tret = nrz;\n\t\t\tlog_info(\"fio: report zones (offset %\"PRIu64\") failed for %s (%d).\\n\",\n\t\t\t\t offset, f->file_name, -ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* a sentinel */\n\tzbd_info->zone_info[nr_zones].start = offset;\n\n\tf->zbd_info = zbd_info;\n\tf->zbd_info->zone_size = zone_size;\n\tf->zbd_info->zone_size_log2 = is_power_of_2(zone_size) ?\n\t\tilog2(zone_size) : 0;\n\tf->zbd_info->nr_zones = nr_zones;\n\tf->zbd_info->max_active_zones = zbd_get_max_active_zones(td, f);\n\n\tif (same_zone_cap)\n\t\tdprint(FD_ZBD, \"Zone capacity = %\"PRIu64\" KB\\n\",\n\t\t       capacity / 1024);\n\n\tzbd_info = NULL;\n\tret = 0;\n\nout:\n\tsfree(zbd_info);\n\tfree(zones);\n\treturn ret;\n}\n\nstatic int zbd_set_max_write_zones(struct thread_data *td, struct fio_file *f)\n{\n\tstruct zoned_block_device_info *zbd = f->zbd_info;\n\tunsigned int max_open_zones;\n\tint ret;\n\n\tif (zbd->model != ZBD_HOST_MANAGED || td->o.ignore_zone_limits) {\n\t\t/* Only host-managed devices have a max open limit */\n\t\tzbd->max_write_zones = td->o.max_open_zones;\n\t\tgoto out;\n\t}\n\n\t/* If host-managed, get the max open limit */\n\tret = zbd_get_max_open_zones(td, f, &max_open_zones);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!max_open_zones) {\n\t\t/* No device limit */\n\t\tzbd->max_write_zones = td->o.max_open_zones;\n\t} else if (!td->o.max_open_zones) {\n\t\t/* No user limit. Set limit to device limit */\n\t\tzbd->max_write_zones = max_open_zones;\n\t} else if (td->o.max_open_zones <= max_open_zones) {\n\t\t/* Both user limit and dev limit. User limit not too large */\n\t\tzbd->max_write_zones = td->o.max_open_zones;\n\t} else {\n\t\t/* Both user limit and dev limit. User limit too large */\n\t\ttd_verror(td, EINVAL,\n\t\t\t  \"Specified --max_open_zones is too large\");\n\t\tlog_err(\"Specified --max_open_zones (%d) is larger than max (%u)\\n\",\n\t\t\ttd->o.max_open_zones, max_open_zones);\n\t\treturn -EINVAL;\n\t}\n\nout:\n\t/* Ensure that the limit is not larger than FIO's internal limit */\n\tif (zbd->max_write_zones > ZBD_MAX_WRITE_ZONES) {\n\t\ttd_verror(td, EINVAL, \"'max_open_zones' value is too large\");\n\t\tlog_err(\"'max_open_zones' value is larger than %u\\n\",\n\t\t\tZBD_MAX_WRITE_ZONES);\n\t\treturn -EINVAL;\n\t}\n\n\tdprint(FD_ZBD, \"%s: using max write zones limit: %\"PRIu32\"\\n\",\n\t       f->file_name, zbd->max_write_zones);\n\n\treturn 0;\n}\n\n/*\n * Allocate zone information and store it into f->zbd_info if zonemode=zbd.\n *\n * Returns 0 upon success and a negative error code upon failure.\n */\nstatic int zbd_create_zone_info(struct thread_data *td, struct fio_file *f)\n{\n\tenum zbd_zoned_model zbd_model;\n\tint ret;\n\n\tassert(td->o.zone_mode == ZONE_MODE_ZBD);\n\n\tret = zbd_get_zoned_model(td, f, &zbd_model);\n\tif (ret)\n\t\treturn ret;\n\n\tswitch (zbd_model) {\n\tcase ZBD_HOST_AWARE:\n\tcase ZBD_HOST_MANAGED:\n\t\tret = parse_zone_info(td, f);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tbreak;\n\tcase ZBD_NONE:\n\t\tret = init_zone_info(td, f);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tbreak;\n\tdefault:\n\t\ttd_verror(td, EINVAL, \"Unsupported zoned model\");\n\t\tlog_err(\"Unsupported zoned model\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tassert(f->zbd_info);\n\tf->zbd_info->model = zbd_model;\n\n\tret = zbd_set_max_write_zones(td, f);\n\tif (ret) {\n\t\tzbd_free_zone_info(f);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nvoid zbd_free_zone_info(struct fio_file *f)\n{\n\tuint32_t refcount;\n\n\tassert(f->zbd_info);\n\n\tpthread_mutex_lock(&f->zbd_info->mutex);\n\trefcount = --f->zbd_info->refcount;\n\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\n\tassert((int32_t)refcount >= 0);\n\tif (refcount == 0)\n\t\tsfree(f->zbd_info);\n\tf->zbd_info = NULL;\n}\n\n/*\n * Initialize f->zbd_info.\n *\n * Returns 0 upon success and a negative error code upon failure.\n *\n * Note: this function can only work correctly if it is called before the first\n * fio fork() call.\n */\nstatic int zbd_init_zone_info(struct thread_data *td, struct fio_file *file)\n{\n\tstruct fio_file *f2;\n\tint j, ret;\n\n\tfor_each_td(td2) {\n\t\tfor_each_file(td2, f2, j) {\n\t\t\tif (td2 == td && f2 == file)\n\t\t\t\tcontinue;\n\t\t\tif (!f2->zbd_info ||\n\t\t\t    strcmp(f2->file_name, file->file_name) != 0)\n\t\t\t\tcontinue;\n\t\t\tfile->zbd_info = f2->zbd_info;\n\t\t\tfile->zbd_info->refcount++;\n\t\t\treturn 0;\n\t\t}\n\t} end_for_each();\n\n\tret = zbd_create_zone_info(td, file);\n\tif (ret < 0)\n\t\ttd_verror(td, -ret, \"zbd_create_zone_info() failed\");\n\n\treturn ret;\n}\n\nint zbd_init_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tint i;\n\n\tfor_each_file(td, f, i) {\n\t\tif (zbd_init_zone_info(td, f))\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nvoid zbd_recalc_options_with_zone_granularity(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tint i;\n\n\tfor_each_file(td, f, i) {\n\t\tstruct zoned_block_device_info *zbd = f->zbd_info;\n\t\tuint64_t zone_size;\n\n\t\t/* zonemode=strided doesn't get per-file zone size. */\n\t\tzone_size = zbd ? zbd->zone_size : td->o.zone_size;\n\t\tif (zone_size == 0)\n\t\t\tcontinue;\n\n\t\tif (td->o.size_nz > 0)\n\t\t\ttd->o.size = td->o.size_nz * zone_size;\n\t\tif (td->o.io_size_nz > 0)\n\t\t\ttd->o.io_size = td->o.io_size_nz * zone_size;\n\t\tif (td->o.start_offset_nz > 0)\n\t\t\ttd->o.start_offset = td->o.start_offset_nz * zone_size;\n\t\tif (td->o.offset_increment_nz > 0)\n\t\t\ttd->o.offset_increment =\n\t\t\t\ttd->o.offset_increment_nz * zone_size;\n\t\tif (td->o.zone_skip_nz > 0)\n\t\t\ttd->o.zone_skip = td->o.zone_skip_nz * zone_size;\n\t}\n}\n\nstatic uint64_t zbd_verify_and_set_vdb(struct thread_data *td,\n\t\t\t\t       const struct fio_file *f)\n{\n\tstruct fio_zone_info *zb, *ze, *z;\n\tuint64_t wp_vdb = 0;\n\tstruct zoned_block_device_info *zbdi = f->zbd_info;\n\n\tassert(td->runstate < TD_RUNNING);\n\tassert(zbdi);\n\n\tif (!accounting_vdb(td, f))\n\t\treturn 0;\n\n\t/*\n\t * Ensure that the I/O range includes one or more sequential zones so\n\t * that f->min_zone and f->max_zone have different values.\n\t */\n\tif (!zbd_is_seq_job(f))\n\t\treturn 0;\n\n\tif (zbdi->write_min_zone != zbdi->write_max_zone) {\n\t\tif (zbdi->write_min_zone != f->min_zone ||\n\t\t    zbdi->write_max_zone != f->max_zone) {\n\t\t\ttd_verror(td, EINVAL,\n\t\t\t\t  \"multi-jobs with different write ranges are \"\n\t\t\t\t  \"not supported with zone_reset_threshold\");\n\t\t\tlog_err(\"multi-jobs with different write ranges are \"\n\t\t\t\t\"not supported with zone_reset_threshold\\n\");\n\t\t}\n\t\treturn 0;\n\t}\n\n\tzbdi->write_min_zone = f->min_zone;\n\tzbdi->write_max_zone = f->max_zone;\n\n\tzb = zbd_get_zone(f, f->min_zone);\n\tze = zbd_get_zone(f, f->max_zone);\n\tfor (z = zb; z < ze; z++)\n\t\tif (z->has_wp)\n\t\t\twp_vdb += z->wp - z->start;\n\n\tzbdi->wp_valid_data_bytes = wp_vdb;\n\n\treturn wp_vdb;\n}\n\nint zbd_setup_files(struct thread_data *td)\n{\n\tstruct fio_file *f;\n\tint i;\n\n\tif (!zbd_using_direct_io()) {\n\t\tlog_err(\"Using direct I/O is mandatory for writing to ZBD drives\\n\\n\");\n\t\treturn 1;\n\t}\n\n\tif (!zbd_verify_sizes())\n\t\treturn 1;\n\n\tif (!zbd_verify_bs())\n\t\treturn 1;\n\n\tif (td->o.experimental_verify) {\n\t\tlog_err(\"zonemode=zbd does not support experimental verify\\n\");\n\t\treturn 1;\n\t}\n\n\tfor_each_file(td, f, i) {\n\t\tstruct zoned_block_device_info *zbd = f->zbd_info;\n\t\tstruct fio_zone_info *z;\n\t\tint zi;\n\t\tuint64_t vdb;\n\n\t\tassert(zbd);\n\n\t\tf->min_zone = zbd_offset_to_zone_idx(f, f->file_offset);\n\t\tf->max_zone =\n\t\t\tzbd_offset_to_zone_idx(f, f->file_offset + f->io_size);\n\n\t\tvdb = zbd_verify_and_set_vdb(td, f);\n\n\t\tdprint(FD_ZBD, \"%s(%s): valid data bytes = %\" PRIu64 \"\\n\",\n\t\t       __func__, f->file_name, vdb);\n\n\t\t/*\n\t\t * When all zones in the I/O range are conventional, io_size\n\t\t * can be smaller than zone size, making min_zone the same\n\t\t * as max_zone. This is why the assert below needs to be made\n\t\t * conditional.\n\t\t */\n\t\tif (zbd_is_seq_job(f))\n\t\t\tassert(f->min_zone < f->max_zone);\n\n\t\tif (td->o.max_open_zones > 0 &&\n\t\t    zbd->max_write_zones != td->o.max_open_zones) {\n\t\t\tlog_err(\"Different 'max_open_zones' values\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/*\n\t\t * The per job max open zones limit cannot be used without a\n\t\t * global max open zones limit. (As the tracking of open zones\n\t\t * is disabled when there is no global max open zones limit.)\n\t\t */\n\t\tif (td->o.job_max_open_zones && !zbd->max_write_zones) {\n\t\t\tlog_err(\"'job_max_open_zones' cannot be used without a global open zones limit\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/*\n\t\t * zbd->max_write_zones is the global limit shared for all jobs\n\t\t * that target the same zoned block device. Force sync the per\n\t\t * thread global limit with the actual global limit. (The real\n\t\t * per thread/job limit is stored in td->o.job_max_open_zones).\n\t\t */\n\t\ttd->o.max_open_zones = zbd->max_write_zones;\n\n\t\tfor (zi = f->min_zone; zi < f->max_zone; zi++) {\n\t\t\tz = &zbd->zone_info[zi];\n\t\t\tif (z->cond != ZBD_ZONE_COND_IMP_OPEN &&\n\t\t\t    z->cond != ZBD_ZONE_COND_EXP_OPEN &&\n\t\t\t    z->cond != ZBD_ZONE_COND_CLOSED)\n\t\t\t\tcontinue;\n\t\t\tif (!zbd->max_active_zones &&\n\t\t\t    z->cond == ZBD_ZONE_COND_CLOSED)\n\t\t\t\tcontinue;\n\t\t\tif (__zbd_write_zone_get(td, f, z))\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * If the number of open zones exceeds specified limits,\n\t\t\t * error out.\n\t\t\t */\n\t\t\tlog_err(\"Number of open zones exceeds max_open_zones limit\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * Reset zbd_info.write_cnt, the counter that counts down towards the next\n * zone reset.\n */\nstatic void _zbd_reset_write_cnt(const struct thread_data *td,\n\t\t\t\t const struct fio_file *f)\n{\n\tassert(0 <= td->o.zrf.u.f && td->o.zrf.u.f <= 1);\n\n\tf->zbd_info->write_cnt = td->o.zrf.u.f ?\n\t\tmin(1.0 / td->o.zrf.u.f, 0.0 + UINT_MAX) : UINT_MAX;\n}\n\nstatic void zbd_reset_write_cnt(const struct thread_data *td,\n\t\t\t\tconst struct fio_file *f)\n{\n\tpthread_mutex_lock(&f->zbd_info->mutex);\n\t_zbd_reset_write_cnt(td, f);\n\tpthread_mutex_unlock(&f->zbd_info->mutex);\n}\n\nstatic bool zbd_dec_and_reset_write_cnt(const struct thread_data *td,\n\t\t\t\t\tconst struct fio_file *f)\n{\n\tuint32_t write_cnt = 0;\n\n\tpthread_mutex_lock(&f->zbd_info->mutex);\n\tassert(f->zbd_info->write_cnt);\n\tif (f->zbd_info->write_cnt)\n\t\twrite_cnt = --f->zbd_info->write_cnt;\n\tif (write_cnt == 0)\n\t\t_zbd_reset_write_cnt(td, f);\n\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\n\treturn write_cnt == 0;\n}\n\nvoid zbd_file_reset(struct thread_data *td, struct fio_file *f)\n{\n\tstruct fio_zone_info *zb, *ze;\n\tbool verify_data_left = false;\n\n\tif (!f->zbd_info || !td_write(td))\n\t\treturn;\n\n\tzb = zbd_get_zone(f, f->min_zone);\n\tze = zbd_get_zone(f, f->max_zone);\n\n\t/*\n\t * If data verification is enabled reset the affected zones before\n\t * writing any data to avoid that a zone reset has to be issued while\n\t * writing data, which causes data loss.\n\t */\n\tif (td->o.verify != VERIFY_NONE) {\n\t\tverify_data_left = td->runstate == TD_VERIFYING ||\n\t\t\ttd->io_hist_len || td->verify_batch;\n\t\tif (!verify_data_left)\n\t\t\tzbd_reset_zones(td, f, zb, ze);\n\t}\n\n\tzbd_reset_write_cnt(td, f);\n}\n\n/* Return random zone index for one of the write target zones. */\nstatic uint32_t pick_random_zone_idx(const struct fio_file *f,\n\t\t\t\t     const struct io_u *io_u)\n{\n\treturn (io_u->offset - f->file_offset) *\n\t\tf->zbd_info->num_write_zones / f->io_size;\n}\n\nstatic bool any_io_in_flight(void)\n{\n\tfor_each_td(td) {\n\t\tif (td->io_u_in_flight)\n\t\t\treturn true;\n\t} end_for_each();\n\n\treturn false;\n}\n\n/*\n * Modify the offset of an I/O unit that does not refer to a zone such that\n * in write target zones array. Add a zone to or remove a zone from the lsit if\n * necessary. The write target zone is searched across sequential zones.\n * This algorithm can only work correctly if all write pointers are\n * a multiple of the fio block size. The caller must neither hold z->mutex\n * nor f->zbd_info->mutex. Returns with z->mutex held upon success.\n */\nstatic struct fio_zone_info *zbd_convert_to_write_zone(struct thread_data *td,\n\t\t\t\t\t\t       struct io_u *io_u)\n{\n\tconst uint64_t min_bs = td->o.min_bs[io_u->ddir];\n\tstruct fio_file *f = io_u->file;\n\tstruct zoned_block_device_info *zbdi = f->zbd_info;\n\tstruct fio_zone_info *z;\n\tunsigned int write_zone_idx = -1;\n\tuint32_t zone_idx, new_zone_idx;\n\tint i;\n\tbool wait_zone_write;\n\tbool in_flight;\n\tbool should_retry = true;\n\n\tassert(is_valid_offset(f, io_u->offset));\n\n\tif (zbdi->max_write_zones || td->o.job_max_open_zones) {\n\t\t/*\n\t\t * This statement accesses zbdi->write_zones[] on purpose\n\t\t * without locking.\n\t\t */\n\t\tzone_idx = zbdi->write_zones[pick_random_zone_idx(f, io_u)];\n\t} else {\n\t\tzone_idx = zbd_offset_to_zone_idx(f, io_u->offset);\n\t}\n\tif (zone_idx < f->min_zone)\n\t\tzone_idx = f->min_zone;\n\telse if (zone_idx >= f->max_zone)\n\t\tzone_idx = f->max_zone - 1;\n\n\tdprint(FD_ZBD,\n\t       \"%s(%s): starting from zone %d (offset %lld, buflen %lld)\\n\",\n\t       __func__, f->file_name, zone_idx, io_u->offset, io_u->buflen);\n\n\t/*\n\t * Since z->mutex is the outer lock and zbdi->mutex the inner\n\t * lock it can happen that the state of the zone with index zone_idx\n\t * has changed after 'z' has been assigned and before zbdi->mutex\n\t * has been obtained. Hence the loop.\n\t */\n\tfor (;;) {\n\t\tuint32_t tmp_idx;\n\n\t\tz = zbd_get_zone(f, zone_idx);\n\t\tif (z->has_wp)\n\t\t\tzone_lock(td, f, z);\n\n\t\tpthread_mutex_lock(&zbdi->mutex);\n\n\t\tif (z->has_wp) {\n\t\t\tif (z->cond != ZBD_ZONE_COND_OFFLINE &&\n\t\t\t    zbdi->max_write_zones == 0 &&\n\t\t\t    td->o.job_max_open_zones == 0)\n\t\t\t\tgoto examine_zone;\n\t\t\tif (zbdi->num_write_zones == 0) {\n\t\t\t\tdprint(FD_ZBD, \"%s(%s): no zone is write target\\n\",\n\t\t\t\t       __func__, f->file_name);\n\t\t\t\tgoto choose_other_zone;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Array of write target zones is per-device, shared across all\n\t\t * threads. Start with quasi-random candidate zone. Ignore\n\t\t * zones which don't belong to thread's offset/size area.\n\t\t */\n\t\twrite_zone_idx = pick_random_zone_idx(f, io_u);\n\t\tassert(!write_zone_idx ||\n\t\t       write_zone_idx < zbdi->num_write_zones);\n\t\ttmp_idx = write_zone_idx;\n\n\t\tfor (i = 0; i < zbdi->num_write_zones; i++) {\n\t\t\tuint32_t tmpz;\n\n\t\t\tif (tmp_idx >= zbdi->num_write_zones)\n\t\t\t\ttmp_idx = 0;\n\t\t\ttmpz = zbdi->write_zones[tmp_idx];\n\t\t\tif (f->min_zone <= tmpz && tmpz < f->max_zone) {\n\t\t\t\twrite_zone_idx = tmp_idx;\n\t\t\t\tgoto found_candidate_zone;\n\t\t\t}\n\n\t\t\ttmp_idx++;\n\t\t}\n\n\t\tdprint(FD_ZBD, \"%s(%s): no candidate zone\\n\",\n\t\t\t__func__, f->file_name);\n\n\t\tpthread_mutex_unlock(&zbdi->mutex);\n\n\t\tif (z->has_wp)\n\t\t\tzone_unlock(z);\n\n\t\treturn NULL;\n\nfound_candidate_zone:\n\t\tnew_zone_idx = zbdi->write_zones[write_zone_idx];\n\t\tif (new_zone_idx == zone_idx)\n\t\t\tbreak;\n\t\tzone_idx = new_zone_idx;\n\n\t\tpthread_mutex_unlock(&zbdi->mutex);\n\n\t\tif (z->has_wp)\n\t\t\tzone_unlock(z);\n\t}\n\n\t/* Both z->mutex and zbdi->mutex are held. */\n\nexamine_zone:\n\tif (zbd_zone_remainder(z) >= min_bs) {\n\t\tpthread_mutex_unlock(&zbdi->mutex);\n\t\tgoto out;\n\t}\n\nchoose_other_zone:\n\t/* Check if number of write target zones reaches one of limits. */\n\twait_zone_write =\n\t\tzbdi->num_write_zones == f->max_zone - f->min_zone ||\n\t\t(zbdi->max_write_zones &&\n\t\t zbdi->num_write_zones == zbdi->max_write_zones) ||\n\t\t(td->o.job_max_open_zones &&\n\t\t td->num_write_zones == td->o.job_max_open_zones);\n\n\tpthread_mutex_unlock(&zbdi->mutex);\n\n\t/* Only z->mutex is held. */\n\n\t/*\n\t * When number of write target zones reaches to one of limits, wait for\n\t * zone write completion to one of them before trying a new zone.\n\t */\n\tif (wait_zone_write) {\n\t\tdprint(FD_ZBD,\n\t\t       \"%s(%s): quiesce to remove a zone from write target zones array\\n\",\n\t\t       __func__, f->file_name);\n\t\tio_u_quiesce(td);\n\t}\n\nretry:\n\t/* Zone 'z' is full, so try to choose a new zone. */\n\tfor (i = f->io_size / zbdi->zone_size; i > 0; i--) {\n\t\tzone_idx++;\n\t\tif (z->has_wp)\n\t\t\tzone_unlock(z);\n\t\tz++;\n\t\tif (!is_valid_offset(f, z->start)) {\n\t\t\t/* Wrap-around. */\n\t\t\tzone_idx = f->min_zone;\n\t\t\tz = zbd_get_zone(f, zone_idx);\n\t\t}\n\t\tassert(is_valid_offset(f, z->start));\n\t\tif (!z->has_wp)\n\t\t\tcontinue;\n\t\tzone_lock(td, f, z);\n\t\tif (z->write)\n\t\t\tcontinue;\n\t\tif (zbd_write_zone_get(td, f, z))\n\t\t\tgoto out;\n\t}\n\n\t/* Only z->mutex is held. */\n\n\t/* Check whether the write fits in any of the write target zones. */\n\tpthread_mutex_lock(&zbdi->mutex);\n\tfor (i = 0; i < zbdi->num_write_zones; i++) {\n\t\tzone_idx = zbdi->write_zones[i];\n\t\tif (zone_idx < f->min_zone || zone_idx >= f->max_zone)\n\t\t\tcontinue;\n\t\tpthread_mutex_unlock(&zbdi->mutex);\n\t\tzone_unlock(z);\n\n\t\tz = zbd_get_zone(f, zone_idx);\n\n\t\tzone_lock(td, f, z);\n\t\tif (zbd_zone_remainder(z) >= min_bs)\n\t\t\tgoto out;\n\t\tpthread_mutex_lock(&zbdi->mutex);\n\t}\n\n\t/*\n\t * When any I/O is in-flight or when all I/Os in-flight get completed,\n\t * the I/Os might have removed zones from the write target array then\n\t * retry the steps to choose a zone. Before retry, call io_u_quiesce()\n\t * to complete in-flight writes.\n\t */\n\tin_flight = any_io_in_flight();\n\tif (in_flight || should_retry) {\n\t\tdprint(FD_ZBD,\n\t\t       \"%s(%s): wait zone write and retry write target zone selection\\n\",\n\t\t       __func__, f->file_name);\n\t\tshould_retry = in_flight;\n\t\tpthread_mutex_unlock(&zbdi->mutex);\n\t\tzone_unlock(z);\n\t\tio_u_quiesce(td);\n\t\tzone_lock(td, f, z);\n\t\tgoto retry;\n\t}\n\n\tpthread_mutex_unlock(&zbdi->mutex);\n\n\tzone_unlock(z);\n\n\tdprint(FD_ZBD, \"%s(%s): did not choose another write zone\\n\",\n\t       __func__, f->file_name);\n\n\treturn NULL;\n\nout:\n\tdprint(FD_ZBD, \"%s(%s): returning zone %d\\n\",\n\t       __func__, f->file_name, zone_idx);\n\n\tio_u->offset = z->start;\n\tassert(z->has_wp);\n\tassert(z->cond != ZBD_ZONE_COND_OFFLINE);\n\n\treturn z;\n}\n\n/*\n * Find another zone which has @min_bytes of readable data. Search in zones\n * @zb + 1 .. @zl. For random workload, also search in zones @zb - 1 .. @zf.\n *\n * Either returns NULL or returns a zone pointer. When the zone has write\n * pointer, hold the mutex for the zone.\n */\nstatic struct fio_zone_info *\nzbd_find_zone(struct thread_data *td, struct io_u *io_u, uint64_t min_bytes,\n\t      struct fio_zone_info *zb, struct fio_zone_info *zl)\n{\n\tstruct fio_file *f = io_u->file;\n\tstruct fio_zone_info *z1, *z2;\n\tconst struct fio_zone_info *const zf = zbd_get_zone(f, f->min_zone);\n\n\t/*\n\t * Skip to the next non-empty zone in case of sequential I/O and to\n\t * the nearest non-empty zone in case of random I/O.\n\t */\n\tfor (z1 = zb + 1, z2 = zb - 1; z1 < zl || z2 >= zf; z1++, z2--) {\n\t\tif (z1 < zl && z1->cond != ZBD_ZONE_COND_OFFLINE) {\n\t\t\tif (z1->has_wp)\n\t\t\t\tzone_lock(td, f, z1);\n\t\t\tif (z1->start + min_bytes <= z1->wp)\n\t\t\t\treturn z1;\n\t\t\tif (z1->has_wp)\n\t\t\t\tzone_unlock(z1);\n\t\t} else if (!td_random(td)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tif (td_random(td) && z2 >= zf &&\n\t\t    z2->cond != ZBD_ZONE_COND_OFFLINE) {\n\t\t\tif (z2->has_wp)\n\t\t\t\tzone_lock(td, f, z2);\n\t\t\tif (z2->start + min_bytes <= z2->wp)\n\t\t\t\treturn z2;\n\t\t\tif (z2->has_wp)\n\t\t\t\tzone_unlock(z2);\n\t\t}\n\t}\n\n\tdprint(FD_ZBD,\n\t       \"%s: no zone has %\"PRIu64\" bytes of readable data\\n\",\n\t       f->file_name, min_bytes);\n\n\treturn NULL;\n}\n\n/**\n * zbd_end_zone_io - update zone status at command completion\n * @io_u: I/O unit\n * @z: zone info pointer\n *\n * If the write command made the zone full, remove it from the write target\n * zones array.\n *\n * The caller must hold z->mutex.\n */\nstatic void zbd_end_zone_io(struct thread_data *td, const struct io_u *io_u,\n\t\t\t    struct fio_zone_info *z)\n{\n\tconst struct fio_file *f = io_u->file;\n\n\tif (io_u->ddir == DDIR_WRITE &&\n\t    io_u->offset + io_u->buflen >= zbd_zone_capacity_end(z)) {\n\t\tpthread_mutex_lock(&f->zbd_info->mutex);\n\t\tzbd_write_zone_put(td, f, z);\n\t\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\t}\n}\n\n/**\n * zbd_queue_io - update the write pointer of a sequential zone\n * @io_u: I/O unit\n * @success: Whether or not the I/O unit has been queued successfully\n * @q: queueing status (busy, completed or queued).\n *\n * For write and trim operations, update the write pointer of the I/O unit\n * target zone.\n */\nstatic void zbd_queue_io(struct thread_data *td, struct io_u *io_u, int q,\n\t\t\t bool success)\n{\n\tconst struct fio_file *f = io_u->file;\n\tstruct zoned_block_device_info *zbd_info = f->zbd_info;\n\tstruct fio_zone_info *z;\n\tuint64_t zone_end;\n\n\tassert(zbd_info);\n\n\tz = zbd_offset_to_zone(f, io_u->offset);\n\tassert(z->has_wp);\n\n\tif (!success)\n\t\tgoto unlock;\n\n\tdprint(FD_ZBD,\n\t       \"%s: queued I/O (%lld, %llu) for zone %u\\n\",\n\t       f->file_name, io_u->offset, io_u->buflen, zbd_zone_idx(f, z));\n\n\tswitch (io_u->ddir) {\n\tcase DDIR_WRITE:\n\t\tzone_end = min((uint64_t)(io_u->offset + io_u->buflen),\n\t\t\t       zbd_zone_capacity_end(z));\n\n\t\t/*\n\t\t * z->wp > zone_end means that one or more I/O errors\n\t\t * have occurred.\n\t\t */\n\t\tif (accounting_vdb(td, f) && z->wp <= zone_end) {\n\t\t\tpthread_mutex_lock(&zbd_info->mutex);\n\t\t\tzbd_info->wp_valid_data_bytes += zone_end - z->wp;\n\t\t\tpthread_mutex_unlock(&zbd_info->mutex);\n\t\t}\n\t\tz->wp = zone_end;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (q == FIO_Q_COMPLETED && !io_u->error)\n\t\tzbd_end_zone_io(td, io_u, z);\n\nunlock:\n\tif (!success || q != FIO_Q_QUEUED) {\n\t\t/* BUSY or COMPLETED: unlock the zone */\n\t\tzone_unlock(z);\n\t\tio_u->zbd_put_io = NULL;\n\t}\n}\n\n/**\n * zbd_put_io - Unlock an I/O unit target zone lock\n * @io_u: I/O unit\n */\nstatic void zbd_put_io(struct thread_data *td, const struct io_u *io_u)\n{\n\tconst struct fio_file *f = io_u->file;\n\tstruct fio_zone_info *z;\n\n\tassert(f->zbd_info);\n\n\tz = zbd_offset_to_zone(f, io_u->offset);\n\tassert(z->has_wp);\n\n\tdprint(FD_ZBD,\n\t       \"%s: terminate I/O (%lld, %llu) for zone %u\\n\",\n\t       f->file_name, io_u->offset, io_u->buflen, zbd_zone_idx(f, z));\n\n\tzbd_end_zone_io(td, io_u, z);\n\n\tzone_unlock(z);\n}\n\n/*\n * Windows and MacOS do not define this.\n */\n#ifndef EREMOTEIO\n#define EREMOTEIO\t121\t/* POSIX value */\n#endif\n\nbool zbd_unaligned_write(int error_code)\n{\n\tswitch (error_code) {\n\tcase EIO:\n\tcase EREMOTEIO:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n/**\n * setup_zbd_zone_mode - handle zoneskip as necessary for ZBD drives\n * @td: FIO thread data.\n * @io_u: FIO I/O unit.\n *\n * For sequential workloads, change the file offset to skip zoneskip bytes when\n * no more IO can be performed in the current zone.\n * - For read workloads, zoneskip is applied when the io has reached the end of\n *   the zone or the zone write position (when td->o.read_beyond_wp is false).\n * - For write workloads, zoneskip is applied when the zone is full.\n * This applies only to read and write operations.\n */\nvoid setup_zbd_zone_mode(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f = io_u->file;\n\tenum fio_ddir ddir = io_u->ddir;\n\tstruct fio_zone_info *z;\n\n\tassert(td->o.zone_mode == ZONE_MODE_ZBD);\n\tassert(td->o.zone_size);\n\tassert(f->zbd_info);\n\n\tz = zbd_offset_to_zone(f, f->last_pos[ddir]);\n\n\t/*\n\t * When the zone capacity is smaller than the zone size and the I/O is\n\t * sequential write, skip to zone end if the latest position is at the\n\t * zone capacity limit.\n\t */\n\tif (z->capacity < f->zbd_info->zone_size &&\n\t    !td_random(td) && ddir == DDIR_WRITE &&\n\t    f->last_pos[ddir] >= zbd_zone_capacity_end(z)) {\n\t\tdprint(FD_ZBD,\n\t\t       \"%s: Jump from zone capacity limit to zone end:\"\n\t\t       \" (%\"PRIu64\" -> %\"PRIu64\") for zone %u (%\"PRIu64\")\\n\",\n\t\t       f->file_name, f->last_pos[ddir],\n\t\t       zbd_zone_end(z), zbd_zone_idx(f, z), z->capacity);\n\t\ttd->io_skip_bytes += zbd_zone_end(z) - f->last_pos[ddir];\n\t\tf->last_pos[ddir] = zbd_zone_end(z);\n\t}\n\n\t/*\n\t * zone_skip is valid only for sequential workloads.\n\t */\n\tif (td_random(td) || !td->o.zone_skip)\n\t\treturn;\n\n\t/*\n\t * It is time to switch to a new zone if:\n\t * - zone_bytes == zone_size bytes have already been accessed\n\t * - The last position reached the end of the current zone.\n\t * - For reads with td->o.read_beyond_wp == false, the last position\n\t *   reached the zone write pointer.\n\t */\n\tif (td->zone_bytes >= td->o.zone_size ||\n\t    f->last_pos[ddir] >= zbd_zone_end(z) ||\n\t    (ddir == DDIR_READ &&\n\t     (!td->o.read_beyond_wp) && f->last_pos[ddir] >= z->wp)) {\n\t\t/*\n\t\t * Skip zones.\n\t\t */\n\t\ttd->zone_bytes = 0;\n\t\tf->file_offset += td->o.zone_size + td->o.zone_skip;\n\n\t\t/*\n\t\t * Wrap from the beginning, if we exceed the file size\n\t\t */\n\t\tif (f->file_offset >= f->real_file_size)\n\t\t\tf->file_offset = get_start_offset(td, f);\n\n\t\tf->last_pos[ddir] = f->file_offset;\n\t\ttd->io_skip_bytes += td->o.zone_skip;\n\t}\n}\n\n/**\n * zbd_adjust_ddir - Adjust an I/O direction for zonemode=zbd.\n *\n * @td: FIO thread data.\n * @io_u: FIO I/O unit.\n * @ddir: I/O direction before adjustment.\n *\n * Return adjusted I/O direction.\n */\nenum fio_ddir zbd_adjust_ddir(struct thread_data *td, struct io_u *io_u,\n\t\t\t      enum fio_ddir ddir)\n{\n\t/*\n\t * In case read direction is chosen for the first random I/O, fio with\n\t * zonemode=zbd stops because no data can be read from zoned block\n\t * devices with all empty zones. Overwrite the first I/O direction as\n\t * write to make sure data to read exists.\n\t */\n\tassert(io_u->file->zbd_info);\n\tif (ddir != DDIR_READ || !td_rw(td))\n\t\treturn ddir;\n\n\tif (io_u->file->last_start[DDIR_WRITE] != -1ULL ||\n\t    td->o.read_beyond_wp || td->o.rwmix[DDIR_WRITE] == 0)\n\t\treturn DDIR_READ;\n\n\treturn DDIR_WRITE;\n}\n\n/**\n * zbd_adjust_block - adjust the offset and length as necessary for ZBD drives\n * @td: FIO thread data.\n * @io_u: FIO I/O unit.\n *\n * Locking strategy: returns with z->mutex locked if and only if z refers\n * to a sequential zone and if io_u_accept is returned. z is the zone that\n * corresponds to io_u->offset at the end of this function.\n */\nenum io_u_action zbd_adjust_block(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f = io_u->file;\n\tstruct zoned_block_device_info *zbdi = f->zbd_info;\n\tstruct fio_zone_info *zb, *zl, *orig_zb;\n\tuint32_t orig_len = io_u->buflen;\n\tuint64_t min_bs = td->o.min_bs[io_u->ddir];\n\tuint64_t new_len;\n\tint64_t range;\n\n\tassert(zbdi);\n\tassert(min_bs);\n\tassert(is_valid_offset(f, io_u->offset));\n\tassert(io_u->buflen);\n\n\tzb = zbd_offset_to_zone(f, io_u->offset);\n\torig_zb = zb;\n\n\tif (!zb->has_wp) {\n\t\t/* Accept non-write I/Os for conventional zones. */\n\t\tif (io_u->ddir != DDIR_WRITE)\n\t\t\treturn io_u_accept;\n\n\t\t/*\n\t\t * Make sure that writes to conventional zones\n\t\t * don't cross over to any sequential zones.\n\t\t */\n\t\tif (!(zb + 1)->has_wp ||\n\t\t    io_u->offset + io_u->buflen <= (zb + 1)->start)\n\t\t\treturn io_u_accept;\n\n\t\tif (io_u->offset + min_bs > (zb + 1)->start) {\n\t\t\tdprint(FD_IO,\n\t\t\t       \"%s: off=%llu + min_bs=%\"PRIu64\" > next zone %\"PRIu64\"\\n\",\n\t\t\t       f->file_name, io_u->offset,\n\t\t\t       min_bs, (zb + 1)->start);\n\t\t\tio_u->offset =\n\t\t\t\tzb->start + (zb + 1)->start - io_u->offset;\n\t\t\tnew_len = min(io_u->buflen,\n\t\t\t\t      (zb + 1)->start - io_u->offset);\n\t\t} else {\n\t\t\tnew_len = (zb + 1)->start - io_u->offset;\n\t\t}\n\n\t\tio_u->buflen = new_len / min_bs * min_bs;\n\n\t\treturn io_u_accept;\n\t}\n\n\t/*\n\t * Accept the I/O offset for reads if reading beyond the write pointer\n\t * is enabled.\n\t */\n\tif (zb->cond != ZBD_ZONE_COND_OFFLINE &&\n\t    io_u->ddir == DDIR_READ && td->o.read_beyond_wp)\n\t\treturn io_u_accept;\n\n\tzone_lock(td, f, zb);\n\n\tswitch (io_u->ddir) {\n\tcase DDIR_READ:\n\t\tif (td->runstate == TD_VERIFYING && td_write(td))\n\t\t\tgoto accept;\n\n\t\t/*\n\t\t * Check that there is enough written data in the zone to do an\n\t\t * I/O of at least min_bs B. If there isn't, find a new zone for\n\t\t * the I/O.\n\t\t */\n\t\trange = zb->cond != ZBD_ZONE_COND_OFFLINE ?\n\t\t\tzb->wp - zb->start : 0;\n\t\tif (range < min_bs ||\n\t\t    ((!td_random(td)) && (io_u->offset + min_bs > zb->wp))) {\n\t\t\tzone_unlock(zb);\n\t\t\tzl = zbd_get_zone(f, f->max_zone);\n\t\t\tzb = zbd_find_zone(td, io_u, min_bs, zb, zl);\n\t\t\tif (!zb) {\n\t\t\t\tdprint(FD_ZBD,\n\t\t\t\t       \"%s: zbd_find_zone(%lld, %llu) failed\\n\",\n\t\t\t\t       f->file_name, io_u->offset,\n\t\t\t\t       io_u->buflen);\n\t\t\t\tgoto eof;\n\t\t\t}\n\t\t\t/*\n\t\t\t * zbd_find_zone() returned a zone with a range of at\n\t\t\t * least min_bs.\n\t\t\t */\n\t\t\trange = zb->wp - zb->start;\n\t\t\tassert(range >= min_bs);\n\n\t\t\tif (!td_random(td))\n\t\t\t\tio_u->offset = zb->start;\n\t\t}\n\n\t\t/*\n\t\t * Make sure the I/O is within the zone valid data range while\n\t\t * maximizing the I/O size and preserving randomness.\n\t\t */\n\t\tif (range <= io_u->buflen)\n\t\t\tio_u->offset = zb->start;\n\t\telse if (td_random(td))\n\t\t\tio_u->offset = zb->start +\n\t\t\t\t((io_u->offset - orig_zb->start) %\n\t\t\t\t (range - io_u->buflen)) / min_bs * min_bs;\n\n\t\t/*\n\t\t * When zbd_find_zone() returns a conventional zone,\n\t\t * we can simply accept the new i/o offset here.\n\t\t */\n\t\tif (!zb->has_wp)\n\t\t\treturn io_u_accept;\n\n\t\t/*\n\t\t * Make sure the I/O does not cross over the zone wp position.\n\t\t */\n\t\tnew_len = min((unsigned long long)io_u->buflen,\n\t\t\t      (unsigned long long)(zb->wp - io_u->offset));\n\t\tnew_len = new_len / min_bs * min_bs;\n\t\tif (new_len < io_u->buflen) {\n\t\t\tio_u->buflen = new_len;\n\t\t\tdprint(FD_IO, \"Changed length from %u into %llu\\n\",\n\t\t\t       orig_len, io_u->buflen);\n\t\t}\n\n\t\tassert(zb->start <= io_u->offset);\n\t\tassert(io_u->offset + io_u->buflen <= zb->wp);\n\n\t\tgoto accept;\n\n\tcase DDIR_WRITE:\n\t\tif (io_u->buflen > zbdi->zone_size) {\n\t\t\ttd_verror(td, EINVAL, \"I/O buflen exceeds zone size\");\n\t\t\tdprint(FD_IO,\n\t\t\t       \"%s: I/O buflen %llu exceeds zone size %\"PRIu64\"\\n\",\n\t\t\t       f->file_name, io_u->buflen, zbdi->zone_size);\n\t\t\tgoto eof;\n\t\t}\n\nretry:\n\t\tif (zbd_zone_remainder(zb) > 0 &&\n\t\t    zbd_zone_remainder(zb) < min_bs) {\n\t\t\tpthread_mutex_lock(&f->zbd_info->mutex);\n\t\t\tzbd_write_zone_put(td, f, zb);\n\t\t\tpthread_mutex_unlock(&f->zbd_info->mutex);\n\t\t\tdprint(FD_ZBD,\n\t\t\t       \"%s: finish zone %d\\n\",\n\t\t\t       f->file_name, zbd_zone_idx(f, zb));\n\t\t\tio_u_quiesce(td);\n\t\t\tzbd_finish_zone(td, f, zb);\n\t\t\tif (zbd_zone_idx(f, zb) + 1 >= f->max_zone) {\n\t\t\t\tif (!td_random(td))\n\t\t\t\t\tgoto eof;\n\t\t\t}\n\t\t\tzone_unlock(zb);\n\n\t\t\t/* Find the next write pointer zone */\n\t\t\tdo {\n\t\t\t\tzb++;\n\t\t\t\tif (zbd_zone_idx(f, zb) >= f->max_zone)\n\t\t\t\t\tzb = zbd_get_zone(f, f->min_zone);\n\t\t\t} while (!zb->has_wp);\n\n\t\t\tzone_lock(td, f, zb);\n\t\t}\n\n\t\tif (!zbd_write_zone_get(td, f, zb)) {\n\t\t\tzone_unlock(zb);\n\t\t\tzb = zbd_convert_to_write_zone(td, io_u);\n\t\t\tif (!zb) {\n\t\t\t\tdprint(FD_IO, \"%s: can't convert to write target zone\",\n\t\t\t\t       f->file_name);\n\t\t\t\tgoto eof;\n\t\t\t}\n\t\t}\n\n\t\tif (zbd_zone_remainder(zb) > 0 &&\n\t\t    zbd_zone_remainder(zb) < min_bs)\n\t\t\tgoto retry;\n\n\t\t/* Check whether the zone reset threshold has been exceeded */\n\t\tif (td->o.zrf.u.f) {\n\t\t\tif (zbdi->wp_valid_data_bytes >=\n\t\t\t    f->io_size * td->o.zrt.u.f &&\n\t\t\t    zbd_dec_and_reset_write_cnt(td, f))\n\t\t\t\tzb->reset_zone = 1;\n\t\t}\n\n\t\t/* Reset the zone pointer if necessary */\n\t\tif (zb->reset_zone || zbd_zone_full(f, zb, min_bs)) {\n\t\t\tif (td->o.verify != VERIFY_NONE) {\n\t\t\t\t/*\n\t\t\t\t * Unset io-u->file to tell get_next_verify()\n\t\t\t\t * that this IO is not requeue.\n\t\t\t\t */\n\t\t\t\tio_u->file = NULL;\n\t\t\t\tif (!get_next_verify(td, io_u)) {\n\t\t\t\t\tzone_unlock(zb);\n\t\t\t\t\treturn io_u_accept;\n\t\t\t\t}\n\t\t\t\tio_u->file = f;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Since previous write requests may have been submitted\n\t\t\t * asynchronously and since we will submit the zone\n\t\t\t * reset synchronously, wait until previously submitted\n\t\t\t * write requests have completed before issuing a\n\t\t\t * zone reset.\n\t\t\t */\n\t\t\tio_u_quiesce(td);\n\t\t\tzb->reset_zone = 0;\n\t\t\tif (__zbd_reset_zone(td, f, zb) < 0)\n\t\t\t\tgoto eof;\n\n\t\t\tif (zb->capacity < min_bs) {\n\t\t\t\ttd_verror(td, EINVAL, \"ZCAP is less min_bs\");\n\t\t\t\tlog_err(\"zone capacity %\"PRIu64\" smaller than minimum block size %\"PRIu64\"\\n\",\n\t\t\t\t\tzb->capacity, min_bs);\n\t\t\t\tgoto eof;\n\t\t\t}\n\t\t}\n\n\t\t/* Make writes occur at the write pointer */\n\t\tassert(!zbd_zone_full(f, zb, min_bs));\n\t\tio_u->offset = zb->wp;\n\t\tif (!is_valid_offset(f, io_u->offset)) {\n\t\t\ttd_verror(td, EINVAL, \"invalid WP value\");\n\t\t\tdprint(FD_ZBD, \"%s: dropped request with offset %llu\\n\",\n\t\t\t       f->file_name, io_u->offset);\n\t\t\tgoto eof;\n\t\t}\n\n\t\t/*\n\t\t * Make sure that the buflen is a multiple of the minimal\n\t\t * block size. Give up if shrinking would make the request too\n\t\t * small.\n\t\t */\n\t\tnew_len = min((unsigned long long)io_u->buflen,\n\t\t\t      zbd_zone_capacity_end(zb) - io_u->offset);\n\t\tnew_len = new_len / min_bs * min_bs;\n\t\tif (new_len == io_u->buflen)\n\t\t\tgoto accept;\n\t\tif (new_len >= min_bs) {\n\t\t\tio_u->buflen = new_len;\n\t\t\tdprint(FD_IO, \"Changed length from %u into %llu\\n\",\n\t\t\t       orig_len, io_u->buflen);\n\t\t\tgoto accept;\n\t\t}\n\n\t\ttd_verror(td, EIO, \"zone remainder too small\");\n\t\tlog_err(\"zone remainder %lld smaller than min block size %\"PRIu64\"\\n\",\n\t\t\t(zbd_zone_capacity_end(zb) - io_u->offset), min_bs);\n\n\t\tgoto eof;\n\n\tcase DDIR_TRIM:\n\t\t/* Check random trim targets a non-empty zone */\n\t\tif (!td_random(td) || zb->wp > zb->start)\n\t\t\tgoto accept;\n\n\t\t/* Find out a non-empty zone to trim */\n\t\tzone_unlock(zb);\n\t\tzl = zbd_get_zone(f, f->max_zone);\n\t\tzb = zbd_find_zone(td, io_u, 1, zb, zl);\n\t\tif (zb) {\n\t\t\tio_u->offset = zb->start;\n\t\t\tdprint(FD_ZBD, \"%s: found new zone(%lld) for trim\\n\",\n\t\t\t       f->file_name, io_u->offset);\n\t\t\tgoto accept;\n\t\t}\n\n\t\tgoto eof;\n\n\tcase DDIR_SYNC:\n\t\t/* fall-through */\n\tcase DDIR_DATASYNC:\n\tcase DDIR_SYNC_FILE_RANGE:\n\tcase DDIR_WAIT:\n\tcase DDIR_LAST:\n\tcase DDIR_INVAL:\n\tcase DDIR_TIMEOUT:\n\t\tgoto accept;\n\t}\n\n\tassert(false);\n\naccept:\n\tassert(zb->has_wp);\n\tassert(zb->cond != ZBD_ZONE_COND_OFFLINE);\n\tassert(!io_u->zbd_queue_io);\n\tassert(!io_u->zbd_put_io);\n\n\tio_u->zbd_queue_io = zbd_queue_io;\n\tio_u->zbd_put_io = zbd_put_io;\n\n\t/*\n\t * Since we return with the zone lock still held,\n\t * add an annotation to let Coverity know that it\n\t * is intentional.\n\t */\n\t/* coverity[missing_unlock] */\n\n\treturn io_u_accept;\n\neof:\n\tif (zb && zb->has_wp)\n\t\tzone_unlock(zb);\n\n\treturn io_u_eof;\n}\n\n/* Return a string with ZBD statistics */\nchar *zbd_write_status(const struct thread_stat *ts)\n{\n\tchar *res;\n\n\tif (asprintf(&res, \"; %\"PRIu64\" zone resets\", ts->nr_zone_resets) < 0)\n\t\treturn NULL;\n\treturn res;\n}\n\n/**\n * zbd_do_io_u_trim - If reset zone is applicable, do reset zone instead of trim\n *\n * @td: FIO thread data.\n * @io_u: FIO I/O unit.\n *\n * It is assumed that z->mutex is already locked.\n * Return io_u_completed when reset zone succeeds. Return 0 when the target zone\n * does not have write pointer. On error, return negative errno.\n */\nint zbd_do_io_u_trim(struct thread_data *td, struct io_u *io_u)\n{\n\tstruct fio_file *f = io_u->file;\n\tstruct fio_zone_info *z;\n\tint ret;\n\n\tz = zbd_offset_to_zone(f, io_u->offset);\n\tif (!z->has_wp)\n\t\treturn 0;\n\n\tif (io_u->offset != z->start) {\n\t\tlog_err(\"Trim offset not at zone start (%lld)\\n\",\n\t\t\tio_u->offset);\n\t\treturn -EINVAL;\n\t}\n\n\tret = zbd_reset_zone((struct thread_data *)td, f, z);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn io_u_completed;\n}\n\nvoid zbd_log_err(const struct thread_data *td, const struct io_u *io_u)\n{\n\tconst struct fio_file *f = io_u->file;\n\n\tif (td->o.zone_mode != ZONE_MODE_ZBD)\n\t\treturn;\n\n\tif (io_u->error == EOVERFLOW)\n\t\tlog_err(\"%s: Exceeded max_active_zones limit. Check conditions of zones out of I/O ranges.\\n\",\n\t\t\tf->file_name);\n}\n"
        },
        {
          "name": "zbd.h",
          "type": "blob",
          "size": 4.4638671875,
          "content": "/*\n * Copyright (C) 2018 Western Digital Corporation or its affiliates.\n *\n * This file is released under the GPL.\n */\n\n#ifndef FIO_ZBD_H\n#define FIO_ZBD_H\n\n#include \"io_u.h\"\n#include \"ioengines.h\"\n#include \"oslib/blkzoned.h\"\n#include \"zbd_types.h\"\n\nstruct fio_file;\n\nenum io_u_action {\n\tio_u_accept\t= 0,\n\tio_u_eof\t= 1,\n\tio_u_completed  = 2,\n};\n\n/**\n * struct fio_zone_info - information about a single ZBD zone\n * @start: zone start location (bytes)\n * @wp: zone write pointer location (bytes)\n * @capacity: maximum size usable from the start of a zone (bytes)\n * @mutex: protects the modifiable members in this structure\n * @type: zone type (BLK_ZONE_TYPE_*)\n * @cond: zone state (BLK_ZONE_COND_*)\n * @has_wp: whether or not this zone can have a valid write pointer\n * @write: whether or not this zone is the write target at this moment. Only\n *              relevant if zbd->max_open_zones > 0.\n * @reset_zone: whether or not this zone should be reset before writing to it\n */\nstruct fio_zone_info {\n\tpthread_mutex_t\t\tmutex;\n\tuint64_t\t\tstart;\n\tuint64_t\t\twp;\n\tuint64_t\t\tcapacity;\n\tenum zbd_zone_type\ttype:2;\n\tenum zbd_zone_cond\tcond:4;\n\tunsigned int\t\thas_wp:1;\n\tunsigned int\t\twrite:1;\n\tunsigned int\t\treset_zone:1;\n};\n\n/**\n * zoned_block_device_info - zoned block device characteristics\n * @model: Device model.\n * @max_write_zones: global limit on the number of sequential write zones which\n *      are simultaneously written. A zero value means unlimited zones of\n *      simultaneous writes and that write target zones will not be tracked in\n *      the write_zones array.\n * @max_active_zones: device side limit on the number of sequential write zones\n *\tin open or closed conditions. A zero value means unlimited number of\n *\tzones in the conditions.\n * @mutex: Protects the modifiable members in this structure (refcount and\n *\t\tnum_open_zones).\n * @zone_size: size of a single zone in bytes.\n * @wp_valid_data_bytes: total size of data in zones with write pointers\n * @write_min_zone: Minimum zone index of all job's write ranges. Inclusive.\n * @write_max_zone: Maximum zone index of all job's write ranges. Exclusive.\n * @zone_size_log2: log2 of the zone size in bytes if it is a power of 2 or 0\n *\t\tif the zone size is not a power of 2.\n * @nr_zones: number of zones\n * @refcount: number of fio files that share this structure\n * @num_write_zones: number of write target zones\n * @write_cnt: Number of writes since the latest zone reset triggered by\n *\t       the zone_reset_frequency fio job parameter.\n * @write_zones: zone numbers of write target zones\n * @zone_info: description of the individual zones\n *\n * Only devices for which all zones have the same size are supported.\n * Note: if the capacity is not a multiple of the zone size then the last zone\n * will be smaller than 'zone_size'.\n */\nstruct zoned_block_device_info {\n\tenum zbd_zoned_model\tmodel;\n\tuint32_t\t\tmax_write_zones;\n\tuint32_t\t\tmax_active_zones;\n\tpthread_mutex_t\t\tmutex;\n\tuint64_t\t\tzone_size;\n\tuint64_t\t\twp_valid_data_bytes;\n\tuint32_t\t\twrite_min_zone;\n\tuint32_t\t\twrite_max_zone;\n\tuint32_t\t\tzone_size_log2;\n\tuint32_t\t\tnr_zones;\n\tuint32_t\t\trefcount;\n\tuint32_t\t\tnum_write_zones;\n\tuint32_t\t\twrite_cnt;\n\tuint32_t\t\twrite_zones[ZBD_MAX_WRITE_ZONES];\n\tstruct fio_zone_info\tzone_info[0];\n};\n\nint zbd_init_files(struct thread_data *td);\nvoid zbd_recalc_options_with_zone_granularity(struct thread_data *td);\nint zbd_setup_files(struct thread_data *td);\nvoid zbd_free_zone_info(struct fio_file *f);\nvoid zbd_file_reset(struct thread_data *td, struct fio_file *f);\nbool zbd_unaligned_write(int error_code);\nvoid setup_zbd_zone_mode(struct thread_data *td, struct io_u *io_u);\nenum fio_ddir zbd_adjust_ddir(struct thread_data *td, struct io_u *io_u,\n\t\t\t      enum fio_ddir ddir);\nenum io_u_action zbd_adjust_block(struct thread_data *td, struct io_u *io_u);\nchar *zbd_write_status(const struct thread_stat *ts);\nint zbd_do_io_u_trim(struct thread_data *td, struct io_u *io_u);\nvoid zbd_log_err(const struct thread_data *td, const struct io_u *io_u);\n\nstatic inline void zbd_close_file(struct fio_file *f)\n{\n\tif (f->zbd_info)\n\t\tzbd_free_zone_info(f);\n}\n\nstatic inline void zbd_queue_io_u(struct thread_data *td, struct io_u *io_u,\n\t\t\t\t  enum fio_q_status status)\n{\n\tif (io_u->zbd_queue_io) {\n\t\tio_u->zbd_queue_io(td, io_u, status, io_u->error == 0);\n\t\tio_u->zbd_queue_io = NULL;\n\t}\n}\n\nstatic inline void zbd_put_io_u(struct thread_data *td, struct io_u *io_u)\n{\n\tif (io_u->zbd_put_io) {\n\t\tio_u->zbd_put_io(td, io_u);\n\t\tio_u->zbd_queue_io = NULL;\n\t\tio_u->zbd_put_io = NULL;\n\t}\n}\n\n#endif /* FIO_ZBD_H */\n"
        },
        {
          "name": "zbd_types.h",
          "type": "blob",
          "size": 1.2119140625,
          "content": "/*\n * Copyright (C) 2020 Western Digital Corporation or its affiliates.\n *\n * This file is released under the GPL.\n */\n#ifndef FIO_ZBD_TYPES_H\n#define FIO_ZBD_TYPES_H\n\n#include <inttypes.h>\n\n#define ZBD_MAX_WRITE_ZONES\t4096\n\n/*\n * Zoned block device models.\n */\nenum zbd_zoned_model {\n\tZBD_NONE\t\t= 0x1,\t/* No zone support. Emulate zones. */\n\tZBD_HOST_AWARE\t\t= 0x2,\t/* Host-aware zoned block device */\n\tZBD_HOST_MANAGED\t= 0x3,\t/* Host-managed zoned block device */\n};\n\n/*\n * Zone types.\n */\nenum zbd_zone_type {\n\tZBD_ZONE_TYPE_CNV\t= 0x1,\t/* Conventional */\n\tZBD_ZONE_TYPE_SWR\t= 0x2,\t/* Sequential write required */\n\tZBD_ZONE_TYPE_SWP\t= 0x3,\t/* Sequential write preferred */\n};\n\n/*\n * Zone conditions.\n */\nenum zbd_zone_cond {\n        ZBD_ZONE_COND_NOT_WP    = 0x0,\n        ZBD_ZONE_COND_EMPTY     = 0x1,\n        ZBD_ZONE_COND_IMP_OPEN  = 0x2,\n        ZBD_ZONE_COND_EXP_OPEN  = 0x3,\n        ZBD_ZONE_COND_CLOSED    = 0x4,\n        ZBD_ZONE_COND_READONLY  = 0xD,\n        ZBD_ZONE_COND_FULL      = 0xE,\n        ZBD_ZONE_COND_OFFLINE   = 0xF,\n};\n\n/*\n * Zone descriptor.\n */\nstruct zbd_zone {\n\tuint64_t\t\tstart;\n\tuint64_t\t\twp;\n\tuint64_t\t\tlen;\n\tuint64_t\t\tcapacity;\n\tenum zbd_zone_type\ttype;\n\tenum zbd_zone_cond\tcond;\n};\n\n#endif /* FIO_ZBD_TYPES_H */\n"
        },
        {
          "name": "zone-dist.c",
          "type": "blob",
          "size": 1.5185546875,
          "content": "#include <stdlib.h>\n#include \"fio.h\"\n#include \"zone-dist.h\"\n\nstatic void __td_zone_gen_index(struct thread_data *td, enum fio_ddir ddir)\n{\n\tunsigned int i, j, sprev, aprev;\n\tuint64_t sprev_sz;\n\n\ttd->zone_state_index[ddir] = malloc(sizeof(struct zone_split_index) * 100);\n\n\tsprev_sz = sprev = aprev = 0;\n\tfor (i = 0; i < td->o.zone_split_nr[ddir]; i++) {\n\t\tstruct zone_split *zsp = &td->o.zone_split[ddir][i];\n\n\t\tfor (j = aprev; j < aprev + zsp->access_perc; j++) {\n\t\t\tstruct zone_split_index *zsi = &td->zone_state_index[ddir][j];\n\n\t\t\tzsi->size_perc = sprev + zsp->size_perc;\n\t\t\tzsi->size_perc_prev = sprev;\n\n\t\t\tzsi->size = sprev_sz + zsp->size;\n\t\t\tzsi->size_prev = sprev_sz;\n\t\t}\n\n\t\taprev += zsp->access_perc;\n\t\tsprev += zsp->size_perc;\n\t\tsprev_sz += zsp->size;\n\t}\n}\n\nstatic bool has_zones(struct thread_data *td)\n{\n\tint i, zones = 0;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\tzones += td->o.zone_split_nr[i];\n\n\treturn zones != 0;\n}\n\n/*\n * Generate state table for indexes, so we don't have to do it inline from\n * the hot IO path\n */\nvoid td_zone_gen_index(struct thread_data *td)\n{\n\tint i;\n\n\tif (!has_zones(td))\n\t\treturn;\n\n\ttd->zone_state_index = malloc(DDIR_RWDIR_CNT *\n\t\t\t\t\tsizeof(struct zone_split_index *));\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++)\n\t\t__td_zone_gen_index(td, i);\n}\n\nvoid td_zone_free_index(struct thread_data *td)\n{\n\tint i;\n\n\tif (!td->zone_state_index)\n\t\treturn;\n\n\tfor (i = 0; i < DDIR_RWDIR_CNT; i++) {\n\t\tfree(td->zone_state_index[i]);\n\t\ttd->zone_state_index[i] = NULL;\n\t}\n\n\tfree(td->zone_state_index);\n\ttd->zone_state_index = NULL;\n}\n"
        },
        {
          "name": "zone-dist.h",
          "type": "blob",
          "size": 0.150390625,
          "content": "#ifndef FIO_ZONE_DIST_H\n#define FIO_ZONE_DIST_H\n\nvoid td_zone_gen_index(struct thread_data *td);\nvoid td_zone_free_index(struct thread_data *td);\n\n#endif\n"
        }
      ]
    }
  ]
}