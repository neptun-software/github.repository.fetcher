{
  "metadata": {
    "timestamp": 1736710369598,
    "page": 185,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "littlefs-project/littlefs",
      "stars": 5349,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1884765625,
          "content": "# GitHub really wants to mark littlefs as a python project, telling it to\n# reclassify our test .toml files as C code (which they are 95% of anyways)\n# remedies this\n*.toml linguist-language=c\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3759765625,
          "content": "# Compilation output\n*.o\n*.d\n*.a\n*.ci\n*.csv\n*.t.*\n*.b.*\n*.gcno\n*.gcda\n*.perf\nlfs\nliblfs.a\n\n# Testing things\nrunners/test_runner\nrunners/bench_runner\nlfs.code.csv\nlfs.data.csv\nlfs.stack.csv\nlfs.structs.csv\nlfs.cov.csv\nlfs.perf.csv\nlfs.perfbd.csv\nlfs.test.csv\nlfs.bench.csv\n\n# Misc\ntags\n.gdb_history\nscripts/__pycache__\n\n# Historical, probably should remove at some point\ntests/*.toml.*\n"
        },
        {
          "name": "DESIGN.md",
          "type": "blob",
          "size": 93.9794921875,
          "content": "## The design of littlefs\n\nA little fail-safe filesystem designed for microcontrollers.\n\n```\n   | | |     .---._____\n  .-----.   |          |\n--|o    |---| littlefs |\n--|     |---|          |\n  '-----'   '----------'\n   | | |\n```\n\nlittlefs was originally built as an experiment to learn about filesystem design\nin the context of microcontrollers. The question was: How would you build a\nfilesystem that is resilient to power-loss and flash wear without using\nunbounded memory?\n\nThis document covers the high-level design of littlefs, how it is different\nthan other filesystems, and the design decisions that got us here. For the\nlow-level details covering every bit on disk, check out [SPEC.md](SPEC.md).\n\n## The problem\n\nThe embedded systems littlefs targets are usually 32-bit microcontrollers with\naround 32 KiB of RAM and 512 KiB of ROM. These are often paired with SPI NOR\nflash chips with about 4 MiB of flash storage. These devices are too small for\nLinux and most existing filesystems, requiring code written specifically with\nsize in mind.\n\nFlash itself is an interesting piece of technology with its own quirks and\nnuance. Unlike other forms of storage, writing to flash requires two\noperations: erasing and programming. Programming (setting bits to 0) is\nrelatively cheap and can be very granular. Erasing however (setting bits to 1),\nrequires an expensive and destructive operation which gives flash its name.\n[Wikipedia][wikipedia-flash] has more information on how exactly flash works.\n\nTo make the situation more annoying, it's very common for these embedded\nsystems to lose power at any time. Usually, microcontroller code is simple and\nreactive, with no concept of a shutdown routine. This presents a big challenge\nfor persistent storage, where an unlucky power loss can corrupt the storage and\nleave a device unrecoverable.\n\nThis leaves us with three major requirements for an embedded filesystem.\n\n1. **Power-loss resilience** - On these systems, power can be lost at any time.\n   If a power loss corrupts any persistent data structures, this can cause the\n   device to become unrecoverable. An embedded filesystem must be designed to\n   recover from a power loss during any write operation.\n\n1. **Wear leveling** - Writing to flash is destructive. If a filesystem\n   repeatedly writes to the same block, eventually that block will wear out.\n   Filesystems that don't take wear into account can easily burn through blocks\n   used to store frequently updated metadata and cause a device's early death.\n\n1. **Bounded RAM/ROM** - If the above requirements weren't enough, these\n   systems also have very limited amounts of memory. This prevents many\n   existing filesystem designs, which can lean on relatively large amounts of\n   RAM to temporarily store filesystem metadata.\n\n   For ROM, this means we need to keep our design simple and reuse code paths\n   where possible. For RAM we have a stronger requirement, all RAM usage is\n   bounded. This means RAM usage does not grow as the filesystem changes in\n   size or number of files. This creates a unique challenge as even presumably\n   simple operations, such as traversing the filesystem, become surprisingly\n   difficult.\n\n## Existing designs?\n\nSo, what's already out there? There are, of course, many different filesystems,\nhowever they often share and borrow feature from each other. If we look at\npower-loss resilience and wear leveling, we can narrow these down to a handful\nof designs.\n\n1. First we have the non-resilient, block based filesystems, such as [FAT] and\n   [ext2]. These are the earliest filesystem designs and often the most simple.\n   Here storage is divided into blocks, with each file being stored in a\n   collection of blocks. Without modifications, these filesystems are not\n   power-loss resilient, so updating a file is a simple as rewriting the blocks\n   in place.\n\n   ```\n               .--------.\n               |  root  |\n               |        |\n               |        |\n               '--------'\n               .-'    '-.\n              v          v\n         .--------.  .--------.\n         |   A    |  |   B    |\n         |        |  |        |\n         |        |  |        |\n         '--------'  '--------'\n         .-'         .-'    '-.\n        v           v          v\n   .--------.  .--------.  .--------.\n   |   C    |  |   D    |  |   E    |\n   |        |  |        |  |        |\n   |        |  |        |  |        |\n   '--------'  '--------'  '--------'\n   ```\n\n   Because of their simplicity, these filesystems are usually both the fastest\n   and smallest. However the lack of power resilience is not great, and the\n   binding relationship of storage location and data removes the filesystem's\n   ability to manage wear.\n\n2. In a completely different direction, we have logging filesystems, such as\n   [JFFS], [YAFFS], and [SPIFFS], storage location is not bound to a piece of\n   data, instead the entire storage is used for a circular log which is\n   appended with every change made to the filesystem. Writing appends new\n   changes, while reading requires traversing the log to reconstruct a file.\n   Some logging filesystems cache files to avoid the read cost, but this comes\n   at a tradeoff of RAM.\n\n   ```\n                                                             v\n   .--------.--------.--------.--------.--------.--------.--------.--------.\n   |        C        | new B  | new A  |                 |   A    |   B    |\n   |                 |        |        |->               |        |        |\n   |                 |        |        |                 |        |        |\n   '--------'--------'--------'--------'--------'--------'--------'--------'\n   ```\n\n   Logging filesystem are beautifully elegant. With a checksum, we can easily\n   detect power-loss and fall back to the previous state by ignoring failed\n   appends. And if that wasn't good enough, their cyclic nature means that\n   logging filesystems distribute wear across storage perfectly.\n\n   The main downside is performance. If we look at garbage collection, the\n   process of cleaning up outdated data from the end of the log, I've yet to\n   see a pure logging filesystem that does not have one of these two costs:\n\n   1. _O(n&sup2;)_ runtime\n   2. _O(n)_ RAM\n\n   SPIFFS is a very interesting case here, as it uses the fact that repeated\n   programs to NOR flash is both atomic and masking. This is a very neat\n   solution, however it limits the type of storage you can support.\n\n3. Perhaps the most common type of filesystem, a journaling filesystem is the\n   offspring that happens when you mate a block based filesystem with a logging\n   filesystem. [ext4] and [NTFS] are good examples. Here, we take a normal\n   block based filesystem and add a bounded log where we note every change\n   before it occurs.\n\n   ```\n                             journal\n                            .--------.--------.\n               .--------.   | C'| D'|     | E'|\n               |  root  |-->|   |   |->   |   |\n               |        |   |   |   |     |   |\n               |        |   '--------'--------'\n               '--------'\n               .-'    '-.\n              v          v\n         .--------.  .--------.\n         |   A    |  |   B    |\n         |        |  |        |\n         |        |  |        |\n         '--------'  '--------'\n         .-'         .-'    '-.\n        v           v          v\n   .--------.  .--------.  .--------.\n   |   C    |  |   D    |  |   E    |\n   |        |  |        |  |        |\n   |        |  |        |  |        |\n   '--------'  '--------'  '--------'\n   ```\n\n\n   This sort of filesystem takes the best from both worlds. Performance can be\n   as fast as a block based filesystem (though updating the journal does have\n   a small cost), and atomic updates to the journal allow the filesystem to\n   recover in the event of a power loss.\n\n   Unfortunately, journaling filesystems have a couple of problems. They are\n   fairly complex, since there are effectively two filesystems running in\n   parallel, which comes with a code size cost. They also offer no protection\n   against wear because of the strong relationship between storage location\n   and data.\n\n4. Last but not least we have copy-on-write (COW) filesystems, such as\n   [btrfs] and [ZFS]. These are very similar to other block based filesystems,\n   but instead of updating block inplace, all updates are performed by creating\n   a copy with the changes and replacing any references to the old block with\n   our new block. This recursively pushes all of our problems upwards until we\n   reach the root of our filesystem, which is often stored in a very small log.\n\n   ```\n               .--------.                  .--------.\n               |  root  |       write      |new root|\n               |        |        ==>       |        |\n               |        |                  |        |\n               '--------'                  '--------'\n               .-'    '-.                    |    '-.\n              |  .-------|------------------'        v\n              v v        v                       .--------.\n         .--------.  .--------.                  | new B  |\n         |   A    |  |   B    |                  |        |\n         |        |  |        |                  |        |\n         |        |  |        |                  '--------'\n         '--------'  '--------'                  .-'    |\n         .-'         .-'    '-.    .------------|------'\n        |           |          |  |             v\n        v           v          v  v        .--------.\n   .--------.  .--------.  .--------.      | new D  |\n   |   C    |  |   D    |  |   E    |      |        |\n   |        |  |        |  |        |      |        |\n   |        |  |        |  |        |      '--------'\n   '--------'  '--------'  '--------'\n   ```\n\n   COW filesystems are interesting. They offer very similar performance to\n   block based filesystems while managing to pull off atomic updates without\n   storing data changes directly in a log. They even disassociate the storage\n   location of data, which creates an opportunity for wear leveling.\n\n   Well, almost. The unbounded upwards movement of updates causes some\n   problems. Because updates to a COW filesystem don't stop until they've\n   reached the root, an update can cascade into a larger set of writes than\n   would be needed for the original data. On top of this, the upward motion\n   focuses these writes into the block, which can wear out much earlier than\n   the rest of the filesystem.\n\n## littlefs\n\nSo what does littlefs do?\n\nIf we look at existing filesystems, there are two interesting design patterns\nthat stand out, but each have their own set of problems. Logging, which\nprovides independent atomicity, has poor runtime performance. And COW data\nstructures, which perform well, push the atomicity problem upwards.\n\nCan we work around these limitations?\n\nConsider logging. It has either a _O(n&sup2;)_ runtime or _O(n)_ RAM cost. We\ncan't avoid these costs, _but_ if we put an upper bound on the size we can at\nleast prevent the theoretical cost from becoming problem. This relies on the\nsuper secret computer science hack where you can pretend any algorithmic\ncomplexity is _O(1)_ by bounding the input.\n\nIn the case of COW data structures, we can try twisting the definition a bit.\nLet's say that our COW structure doesn't copy after a single write, but instead\ncopies after _n_ writes. This doesn't change most COW properties (assuming you\ncan write atomically!), but what it does do is prevent the upward motion of\nwear. This sort of copy-on-bounded-writes (CObW) still focuses wear, but at\neach level we divide the propagation of wear by _n_. With a sufficiently\nlarge _n_ (&gt; branching factor) wear propagation is no longer a problem.\n\nSee where this is going? Separate, logging and COW are imperfect solutions and\nhave weaknesses that limit their usefulness. But if we merge the two they can\nmutually solve each other's limitations.\n\nThis is the idea behind littlefs. At the sub-block level, littlefs is built\nout of small, two block logs that provide atomic updates to metadata anywhere\non the filesystem. At the super-block level, littlefs is a CObW tree of blocks\nthat can be evicted on demand.\n\n```\n                    root\n                   .--------.--------.\n                   | A'| B'|         |\n                   |   |   |->       |\n                   |   |   |         |\n                   '--------'--------'\n                .----'   '--------------.\n       A       v                 B       v\n      .--------.--------.       .--------.--------.\n      | C'| D'|         |       | E'|new|         |\n      |   |   |->       |       |   | E'|->       |\n      |   |   |         |       |   |   |         |\n      '--------'--------'       '--------'--------'\n      .-'   '--.                  |   '------------------.\n     v          v              .-'                        v\n.--------.  .--------.        v                       .--------.\n|   C    |  |   D    |   .--------.       write       | new E  |\n|        |  |        |   |   E    |        ==>        |        |\n|        |  |        |   |        |                   |        |\n'--------'  '--------'   |        |                   '--------'\n                         '--------'                   .-'    |\n                         .-'    '-.    .-------------|------'\n                        v          v  v              v\n                   .--------.  .--------.       .--------.\n                   |   F    |  |   G    |       | new F  |\n                   |        |  |        |       |        |\n                   |        |  |        |       |        |\n                   '--------'  '--------'       '--------'\n```\n\nThere are still some minor issues. Small logs can be expensive in terms of\nstorage, in the worst case a small log costs 4x the size of the original data.\nCObW structures require an efficient block allocator since allocation occurs\nevery _n_ writes. And there is still the challenge of keeping the RAM usage\nconstant.\n\n## Metadata pairs\n\nMetadata pairs are the backbone of littlefs. These are small, two block logs\nthat allow atomic updates anywhere in the filesystem.\n\nWhy two blocks? Well, logs work by appending entries to a circular buffer\nstored on disk. But remember that flash has limited write granularity. We can\nincrementally program new data onto erased blocks, but we need to erase a full\nblock at a time. This means that in order for our circular buffer to work, we\nneed more than one block.\n\nWe could make our logs larger than two blocks, but the next challenge is how\ndo we store references to these logs? Because the blocks themselves are erased\nduring writes, using a data structure to track these blocks is complicated.\nThe simple solution here is to store a two block addresses for every metadata\npair. This has the added advantage that we can change out blocks in the\nmetadata pair independently, and we don't reduce our block granularity for\nother operations.\n\nIn order to determine which metadata block is the most recent, we store a\nrevision count that we compare using [sequence arithmetic][wikipedia-sna]\n(very handy for avoiding problems with integer overflow). Conveniently, this\nrevision count also gives us a rough idea of how many erases have occurred on\nthe block.\n\n```\nmetadata pair pointer: {block 0, block 1}\n                           |        '--------------------.\n                            '-.                           |\ndisk                           v                          v\n.--------.--------.--------.--------.--------.--------.--------.--------.\n|                 |        |metadata|                 |metadata|        |\n|                 |        |block 0 |                 |block 1 |        |\n|                 |        |        |                 |        |        |\n'--------'--------'--------'--------'--------'--------'--------'--------'\n                               '--.                  .----'\n                                   v                v\n             metadata pair .----------------.----------------.\n                           |   revision 11  |   revision 12  |\n             block 1 is    |----------------|----------------|\n             most recent   |       A        |       A''      |\n                           |----------------|----------------|\n                           |    checksum    |    checksum    |\n                           |----------------|----------------|\n                           |       B        |       A'''     | <- most recent A\n                           |----------------|----------------|\n                           |       A''      |    checksum    |\n                           |----------------|----------------|\n                           |    checksum    |       |        |\n                           |----------------|       v        |\n                           '----------------'----------------'\n```\n\nSo how do we atomically update our metadata pairs? Atomicity (a type of\npower-loss resilience) requires two parts: redundancy and error detection.\nError detection can be provided with a checksum, and in littlefs's case we\nuse a 32-bit [CRC][wikipedia-crc]. Maintaining redundancy, on the other hand,\nrequires multiple stages.\n\n1. If our block is not full and the program size is small enough to let us\n   append more entries, we can simply append the entries to the log. Because\n   we don't overwrite the original entries (remember rewriting flash requires\n   an erase), we still have the original entries if we lose power during the\n   append.\n\n   ```\n                                    commit A\n   .----------------.----------------.    .----------------.----------------.\n   |   revision 1   |   revision 0   | => |   revision 1   |   revision 0   |\n   |----------------|----------------|    |----------------|----------------|\n   |       |        |                |    |       A        |                |\n   |       v        |                |    |----------------|                |\n   |                |                |    |    checksum    |                |\n   |                |                |    |----------------|                |\n   |                |                |    |       |        |                |\n   |                |                |    |       v        |                |\n   |                |                |    |                |                |\n   |                |                |    |                |                |\n   |                |                |    |                |                |\n   |                |                |    |                |                |\n   '----------------'----------------'    '----------------'----------------'\n   ```\n\n   Note that littlefs doesn't maintain a checksum for each entry. Many logging\n   filesystems do this, but it limits what you can update in a single atomic\n   operation. What we can do instead is group multiple entries into a commit\n   that shares a single checksum. This lets us update multiple unrelated pieces\n   of metadata as long as they reside on the same metadata pair.\n\n   ```\n                                 commit B and A'\n   .----------------.----------------.    .----------------.----------------.\n   |   revision 1   |   revision 0   | => |   revision 1   |   revision 0   |\n   |----------------|----------------|    |----------------|----------------|\n   |       A        |                |    |       A        |                |\n   |----------------|                |    |----------------|                |\n   |    checksum    |                |    |    checksum    |                |\n   |----------------|                |    |----------------|                |\n   |       |        |                |    |       B        |                |\n   |       v        |                |    |----------------|                |\n   |                |                |    |       A'       |                |\n   |                |                |    |----------------|                |\n   |                |                |    |    checksum    |                |\n   |                |                |    |----------------|                |\n   '----------------'----------------'    '----------------'----------------'\n   ```\n\n2. If our block _is_ full of entries, we need to somehow remove outdated\n   entries to make space for new ones. This process is called garbage\n   collection, but because littlefs has multiple garbage collectors, we\n   also call this specific case compaction.\n\n   Compared to other filesystems, littlefs's garbage collector is relatively\n   simple. We want to avoid RAM consumption, so we use a sort of brute force\n   solution where for each entry we check to see if a newer entry has been\n   written. If the entry is the most recent we append it to our new block. This\n   is where having two blocks becomes important, if we lose power we still have\n   everything in our original block.\n\n   During this compaction step we also erase the metadata block and increment\n   the revision count. Because we can commit multiple entries at once, we can\n   write all of these changes to the second block without worrying about power\n   loss. It's only when the commit's checksum is written that the compacted\n   entries and revision count become committed and readable.\n\n   ```\n                           commit B', need to compact\n   .----------------.----------------.    .----------------.----------------.\n   |   revision 1   |   revision 0   | => |   revision 1   |   revision 2   |\n   |----------------|----------------|    |----------------|----------------|\n   |       A        |                |    |       A        |       A'       |\n   |----------------|                |    |----------------|----------------|\n   |    checksum    |                |    |    checksum    |       B'       |\n   |----------------|                |    |----------------|----------------|\n   |       B        |                |    |       B        |    checksum    |\n   |----------------|                |    |----------------|----------------|\n   |       A'       |                |    |       A'       |       |        |\n   |----------------|                |    |----------------|       v        |\n   |    checksum    |                |    |    checksum    |                |\n   |----------------|                |    |----------------|                |\n   '----------------'----------------'    '----------------'----------------'\n   ```\n\n3. If our block is full of entries _and_ we can't find any garbage, then what?\n   At this point, most logging filesystems would return an error indicating no\n   more space is available, but because we have small logs, overflowing a log\n   isn't really an error condition.\n\n   Instead, we split our original metadata pair into two metadata pairs, each\n   containing half of the entries, connected by a tail pointer. Instead of\n   increasing the size of the log and dealing with the scalability issues\n   associated with larger logs, we form a linked list of small bounded logs.\n   This is a tradeoff as this approach does use more storage space, but at the\n   benefit of improved scalability.\n\n   Despite writing to two metadata pairs, we can still maintain power\n   resilience during this split step by first preparing the new metadata pair,\n   and then inserting the tail pointer during the commit to the original\n   metadata pair.\n\n   ```\n                         commit C and D, need to split\n   .----------------.----------------.    .----------------.----------------.\n   |   revision 1   |   revision 2   | => |   revision 3   |   revision 2   |\n   |----------------|----------------|    |----------------|----------------|\n   |       A        |       A'       |    |       A'       |       A'       |\n   |----------------|----------------|    |----------------|----------------|\n   |    checksum    |       B'       |    |       B'       |       B'       |\n   |----------------|----------------|    |----------------|----------------|\n   |       B        |    checksum    |    |      tail    ---------------------.\n   |----------------|----------------|    |----------------|----------------| |\n   |       A'       |       |        |    |    checksum    |                | |\n   |----------------|       v        |    |----------------|                | |\n   |    checksum    |                |    |       |        |                | |\n   |----------------|                |    |       v        |                | |\n   '----------------'----------------'    '----------------'----------------' |\n                                                   .----------------.---------'\n                                                  v                v\n                                          .----------------.----------------.\n                                          |   revision 1   |   revision 0   |\n                                          |----------------|----------------|\n                                          |       C        |                |\n                                          |----------------|                |\n                                          |       D        |                |\n                                          |----------------|                |\n                                          |    checksum    |                |\n                                          |----------------|                |\n                                          |       |        |                |\n                                          |       v        |                |\n                                          |                |                |\n                                          |                |                |\n                                          '----------------'----------------'\n   ```\n\nThere is another complexity the crops up when dealing with small logs. The\namortized runtime cost of garbage collection is not only dependent on its\none time cost (_O(n&sup2;)_ for littlefs), but also depends on how often\ngarbage collection occurs.\n\nConsider two extremes:\n\n1. Log is empty, garbage collection occurs once every _n_ updates\n2. Log is full, garbage collection occurs **every** update\n\nClearly we need to be more aggressive than waiting for our metadata pair to\nbe full. As the metadata pair approaches fullness the frequency of compactions\ngrows very rapidly.\n\nLooking at the problem generically, consider a log with ![n] bytes for each\nentry, ![d] dynamic entries (entries that are outdated during garbage\ncollection), and ![s] static entries (entries that need to be copied during\ngarbage collection). If we look at the amortized runtime complexity of updating\nthis log we get this formula:\n\n![cost = n + n (s / d+1)][metadata-formula1]\n\nIf we let ![r] be the ratio of static space to the size of our log in bytes, we\nfind an alternative representation of the number of static and dynamic entries:\n\n![s = r (size/n)][metadata-formula2]\n\n![d = (1 - r) (size/n)][metadata-formula3]\n\nSubstituting these in for ![d] and ![s] gives us a nice formula for the cost of\nupdating an entry given how full the log is:\n\n![cost = n + n (r (size/n) / ((1-r) (size/n) + 1))][metadata-formula4]\n\nAssuming 100 byte entries in a 4 KiB log, we can graph this using the entry\nsize to find a multiplicative cost:\n\n![Metadata pair update cost graph][metadata-cost-graph]\n\nSo at 50% usage, we're seeing an average of 2x cost per update, and at 75%\nusage, we're already at an average of 4x cost per update.\n\nTo avoid this exponential growth, instead of waiting for our metadata pair\nto be full, we split the metadata pair once we exceed 50% capacity. We do this\nlazily, waiting until we need to compact before checking if we fit in our 50%\nlimit. This limits the overhead of garbage collection to 2x the runtime cost,\ngiving us an amortized runtime complexity of _O(1)_.\n\n---\n\nIf we look at metadata pairs and linked-lists of metadata pairs at a high\nlevel, they have fairly nice runtime costs. Assuming _n_ metadata pairs,\neach containing _m_ metadata entries, the _lookup_ cost for a specific\nentry has a worst case runtime complexity of _O(nm)_. For _updating_ a specific\nentry, the worst case complexity is _O(nm&sup2;)_, with an amortized complexity\nof only _O(nm)_.\n\nHowever, splitting at 50% capacity does mean that in the best case our\nmetadata pairs will only be 1/2 full. If we include the overhead of the second\nblock in our metadata pair, each metadata entry has an effective storage cost\nof 4x the original size. I imagine users would not be happy if they found\nthat they can only use a quarter of their original storage. Metadata pairs\nprovide a mechanism for performing atomic updates, but we need a separate\nmechanism for storing the bulk of our data.\n\n## CTZ skip-lists\n\nMetadata pairs provide efficient atomic updates but unfortunately have a large\nstorage cost. But we can work around this storage cost by only using the\nmetadata pairs to store references to more dense, copy-on-write (COW) data\nstructures.\n\n[Copy-on-write data structures][wikipedia-cow], also called purely functional\ndata structures, are a category of data structures where the underlying\nelements are immutable.  Making changes to the data requires creating new\nelements containing a copy of the updated data and replacing any references\nwith references to the new elements. Generally, the performance of a COW data\nstructure depends on how many old elements can be reused after replacing parts\nof the data.\n\nlittlefs has several requirements of its COW structures. They need to be\nefficient to read and write, but most frustrating, they need to be traversable\nwith a constant amount of RAM. Notably this rules out\n[B-trees][wikipedia-B-tree], which can not be traversed with constant RAM, and\n[B+-trees][wikipedia-B+-tree], which are not possible to update with COW\noperations.\n\n---\n\nSo, what can we do? First let's consider storing files in a simple COW\nlinked-list. Appending a block, which is the basis for writing files, means we\nhave to update the last block to point to our new block. This requires a COW\noperation, which means we need to update the second-to-last block, and then the\nthird-to-last, and so on until we've copied out the entire file.\n\n```\nA linked-list\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| data 0 |->| data 1 |->| data 2 |->| data 4 |->| data 5 |->| data 6 |\n|        |  |        |  |        |  |        |  |        |  |        |\n|        |  |        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nTo avoid a full copy during appends, we can store the data backwards. Appending\nblocks just requires adding the new block and no other blocks need to be\nupdated. If we update a block in the middle, we still need to copy the\nfollowing blocks, but can reuse any blocks before it. Since most file writes\nare linear, this design gambles that appends are the most common type of data\nupdate.\n\n```\nA backwards linked-list\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| data 0 |<-| data 1 |<-| data 2 |<-| data 4 |<-| data 5 |<-| data 6 |\n|        |  |        |  |        |  |        |  |        |  |        |\n|        |  |        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nHowever, a backwards linked-list does have a rather glaring problem. Iterating\nover a file _in order_ has a runtime cost of _O(n&sup2;)_. A quadratic runtime\njust to read a file! That's awful.\n\nFortunately we can do better. Instead of a singly linked list, littlefs\nuses a multilayered linked-list often called a\n[skip-list][wikipedia-skip-list]. However, unlike the most common type of\nskip-list, littlefs's skip-lists are strictly deterministic built around some\ninteresting properties of the count-trailing-zeros (CTZ) instruction.\n\nThe rules CTZ skip-lists follow are that for every _n_&zwj;th block where _n_\nis divisible by 2&zwj;_&#739;_, that block contains a pointer to block\n_n_-2&zwj;_&#739;_. This means that each block contains anywhere from 1 to\nlog&#8322;_n_ pointers that skip to different preceding elements of the\nskip-list.\n\nThe name comes from heavy use of the [CTZ instruction][wikipedia-ctz], which\nlets us calculate the power-of-two factors efficiently. For a given block _n_,\nthat block contains ctz(_n_)+1 pointers.\n\n```\nA backwards CTZ skip-list\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |<-| data 4 |<-| data 5 |\n|        |<-|        |--|        |<-|        |--|        |  |        |\n|        |<-|        |--|        |--|        |--|        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nThe additional pointers let us navigate the data-structure on disk much more\nefficiently than in a singly linked list.\n\nConsider a path from data block 5 to data block 1. You can see how data block 3\nwas completely skipped:\n```\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| data 0 |  | data 1 |<-| data 2 |  | data 3 |  | data 4 |<-| data 5 |\n|        |  |        |  |        |<-|        |--|        |  |        |\n|        |  |        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nThe path to data block 0 is even faster, requiring only two jumps:\n```\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| data 0 |  | data 1 |  | data 2 |  | data 3 |  | data 4 |<-| data 5 |\n|        |  |        |  |        |  |        |  |        |  |        |\n|        |<-|        |--|        |--|        |--|        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nWe can find the runtime complexity by looking at the path to any block from\nthe block containing the most pointers. Every step along the path divides\nthe search space for the block in half, giving us a runtime of _O(log n)_.\nTo get _to_ the block with the most pointers, we can perform the same steps\nbackwards, which puts the runtime at _O(2 log n)_ = _O(log n)_. An interesting\nnote is that this optimal path occurs naturally if we greedily choose the\npointer that covers the most distance without passing our target.\n\nSo now we have a [COW] data structure that is cheap to append with a runtime\nof _O(1)_, and can be read with a worst case runtime of _O(n log n)_. Given\nthat this runtime is also divided by the amount of data we can store in a\nblock, this cost is fairly reasonable.\n\n---\n\nThis is a new data structure, so we still have several questions. What is the\nstorage overhead? Can the number of pointers exceed the size of a block? How do\nwe store a CTZ skip-list in our metadata pairs?\n\nTo find the storage overhead, we can look at the data structure as multiple\nlinked-lists. Each linked-list skips twice as many blocks as the previous,\nor from another perspective, each linked-list uses half as much storage as\nthe previous. As we approach infinity, the storage overhead forms a geometric\nseries. Solving this tells us that on average our storage overhead is only\n2 pointers per block.\n\n![lim,n->inf((1/n)sum,i,0->n(ctz(i)+1)) = sum,i,0->inf(1/2^i) = 2][ctz-formula1]\n\nBecause our file size is limited the word width we use to store sizes, we can\nalso solve for the maximum number of pointers we would ever need to store in a\nblock. If we set the overhead of pointers equal to the block size, we get the\nfollowing equation. Note that both a smaller block size (![B][bigB]) and larger\nword width (![w]) result in more storage overhead.\n\n![B = (w/8)ceil(log2(2^w / (B-2w/8)))][ctz-formula2]\n\nSolving the equation for ![B][bigB] gives us the minimum block size for some\ncommon word widths:\n\n1. 32-bit CTZ skip-list => minimum block size of 104 bytes\n2. 64-bit CTZ skip-list => minimum block size of 448 bytes\n\nlittlefs uses a 32-bit word width, so our blocks can only overflow with\npointers if they are smaller than 104 bytes. This is an easy requirement, as\nin practice, most block sizes start at 512 bytes. As long as our block size\nis larger than 104 bytes, we can avoid the extra logic needed to handle\npointer overflow.\n\nThis last question is how do we store CTZ skip-lists? We need a pointer to the\nhead block, the size of the skip-list, the index of the head block, and our\noffset in the head block. But it's worth noting that each size maps to a unique\nindex + offset pair. So in theory we can store only a single pointer and size.\n\nHowever, calculating the index + offset pair from the size is a bit\ncomplicated. We can start with a summation that loops through all of the blocks\nup until our given size. Let ![B][bigB] be the block size in bytes, ![w] be the\nword width in bits, ![n] be the index of the block in the skip-list, and\n![N][bigN] be the file size in bytes:\n\n![N = sum,i,0->n(B-(w/8)(ctz(i)+1))][ctz-formula3]\n\nThis works quite well, but requires _O(n)_ to compute, which brings the full\nruntime of reading a file up to _O(n&sup2; log n)_. Fortunately, that summation\ndoesn't need to touch the disk, so the practical impact is minimal.\n\nHowever, despite the integration of a bitwise operation, we can actually reduce\nthis equation to a _O(1)_ form.  While browsing the amazing resource that is\nthe [On-Line Encyclopedia of Integer Sequences (OEIS)][oeis], I managed to find\n[A001511], which matches the iteration of the CTZ instruction,\nand [A005187], which matches its partial summation. Much to my\nsurprise, these both result from simple equations, leading us to a rather\nunintuitive property that ties together two seemingly unrelated bitwise\ninstructions:\n\n![sum,i,0->n(ctz(i)+1) = 2n-popcount(n)][ctz-formula4]\n\nwhere:\n\n1. ctz(![x]) = the number of trailing bits that are 0 in ![x]\n2. popcount(![x]) = the number of bits that are 1 in ![x]\n\nInitial tests of this surprising property seem to hold. As ![n] approaches\ninfinity, we end up with an average overhead of 2 pointers, which matches our\nassumption from earlier. During iteration, the popcount function seems to\nhandle deviations from this average. Of course, just to make sure I wrote a\nquick script that verified this property for all 32-bit integers.\n\nNow we can substitute into our original equation to find a more efficient\nequation for file size:\n\n![N = Bn - (w/8)(2n-popcount(n))][ctz-formula5]\n\nUnfortunately, the popcount function is non-injective, so we can't solve this\nequation for our index. But what we can do is solve for an ![n'] index that\nis greater than ![n] with error bounded by the range of the popcount function.\nWe can repeatedly substitute ![n'] into the original equation until the error\nis smaller than our integer resolution. As it turns out, we only need to\nperform this substitution once, which gives us this formula for our index:\n\n![n = floor((N-(w/8)popcount(N/(B-2w/8))) / (B-2w/8))][ctz-formula6]\n\nNow that we have our index ![n], we can just plug it back into the above\nequation to find the offset. We run into a bit of a problem with integer\noverflow, but we can avoid this by rearranging the equation a bit:\n\n![off = N - (B-2w/8)n - (w/8)popcount(n)][ctz-formula7]\n\nOur solution requires quite a bit of math, but computers are very good at math.\nNow we can find both our block index and offset from a size in _O(1)_, letting\nus store CTZ skip-lists with only a pointer and size.\n\nCTZ skip-lists give us a COW data structure that is easily traversable in\n_O(n)_, can be appended in _O(1)_, and can be read in _O(n log n)_. All of\nthese operations work in a bounded amount of RAM and require only two words of\nstorage overhead per block. In combination with metadata pairs, CTZ skip-lists\nprovide power resilience and compact storage of data.\n\n```\n                                    .--------.\n                                   .|metadata|\n                                   ||        |\n                                   ||        |\n                                   |'--------'\n                                   '----|---'\n                                        v\n.--------.  .--------.  .--------.  .--------.\n| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |\n|        |<-|        |--|        |  |        |\n|        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'\n\nwrite data to disk, create copies\n=>\n                                    .--------.\n                                   .|metadata|\n                                   ||        |\n                                   ||        |\n                                   |'--------'\n                                   '----|---'\n                                        v\n.--------.  .--------.  .--------.  .--------.\n| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |\n|        |<-|        |--|        |  |        |\n|        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'\n     ^ ^           ^\n     | |           |    .--------.  .--------.  .--------.  .--------.\n     | |           '----| new    |<-| new    |<-| new    |<-| new    |\n     | '----------------| data 2 |<-| data 3 |--| data 4 |  | data 5 |\n     '------------------|        |--|        |--|        |  |        |\n                        '--------'  '--------'  '--------'  '--------'\n\ncommit to metadata pair\n=>\n                                                            .--------.\n                                                           .|new     |\n                                                           ||metadata|\n                                                           ||        |\n                                                           |'--------'\n                                                           '----|---'\n                                                                |\n.--------.  .--------.  .--------.  .--------.                  |\n| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |                  |\n|        |<-|        |--|        |  |        |                  |\n|        |  |        |  |        |  |        |                  |\n'--------'  '--------'  '--------'  '--------'                  |\n     ^ ^           ^                                            v\n     | |           |    .--------.  .--------.  .--------.  .--------.\n     | |           '----| new    |<-| new    |<-| new    |<-| new    |\n     | '----------------| data 2 |<-| data 3 |--| data 4 |  | data 5 |\n     '------------------|        |--|        |--|        |  |        |\n                        '--------'  '--------'  '--------'  '--------'\n```\n\n## The block allocator\n\nSo we now have the framework for an atomic, wear leveling filesystem. Small two\nblock metadata pairs provide atomic updates, while CTZ skip-lists provide\ncompact storage of data in COW blocks.\n\nBut now we need to look at the [elephant] in the room. Where do all these\nblocks come from?\n\nDeciding which block to use next is the responsibility of the block allocator.\nIn filesystem design, block allocation is often a second-class citizen, but in\na COW filesystem its role becomes much more important as it is needed for\nnearly every write to the filesystem.\n\nNormally, block allocation involves some sort of free list or bitmap stored on\nthe filesystem that is updated with free blocks. However, with power\nresilience, keeping these structures consistent becomes difficult. It doesn't\nhelp that any mistake in updating these structures can result in lost blocks\nthat are impossible to recover.\n\nlittlefs takes a cautious approach. Instead of trusting a free list on disk,\nlittlefs relies on the fact that the filesystem on disk is a mirror image of\nthe free blocks on the disk. The block allocator operates much like a garbage\ncollector in a scripting language, scanning for unused blocks on demand.\n\n```\n          .----.\n          |root|\n          |    |\n          '----'\n   v-------'  '-------v\n.----.    .    .    .----.\n| A  |    .    .    | B  |\n|    |    .    .    |    |\n'----'    .    .    '----'\n.    .    .    .  v--'  '------------v---------v\n.    .    .    .----.    .         .----.    .----.\n.    .    .    | C  |    .         | D  |    | E  |\n.    .    .    |    |    .         |    |    |    |\n.    .    .    '----'    .         '----'    '----'\n.    .    .    .    .    .         .    .    .    .\n.----.----.----.----.----.----.----.----.----.----.----.----.\n| A  |    |root| C  | B  |         | D  |    | E  |         |\n|    |    |    |    |    |         |    |    |    |         |\n'----'----'----'----'----'----'----'----'----'----'----'----'\n        ^                   ^    ^                   ^    ^\n         '-------------------'----'-------------------'----'-- free blocks\n```\n\nWhile this approach may sound complicated, the decision to not maintain a free\nlist greatly simplifies the overall design of littlefs. Unlike programming\nlanguages, there are only a handful of data structures we need to traverse.\nAnd block deallocation, which occurs nearly as often as block allocation,\nis simply a noop. This \"drop it on the floor\" strategy greatly reduces the\ncomplexity of managing on disk data structures, especially when handling\nhigh-risk error conditions.\n\n---\n\nOur block allocator needs to find free blocks efficiently. You could traverse\nthrough every block on storage and check each one against our filesystem tree;\nhowever, the runtime would be abhorrent. We need to somehow collect multiple\nblocks per traversal.\n\nLooking at existing designs, some larger filesystems that use a similar \"drop\nit on the floor\" strategy store a bitmap of the entire storage in [RAM]. This\nworks well because bitmaps are surprisingly compact. We can't use the same\nstrategy here, as it violates our constant RAM requirement, but we may be able\nto modify the idea into a workable solution.\n\n```\n.----.----.----.----.----.----.----.----.----.----.----.----.\n| A  |    |root| C  | B  |         | D  |    | E  |         |\n|    |    |    |    |    |         |    |    |    |         |\n'----'----'----'----'----'----'----'----'----'----'----'----'\n  1    0    1    1    1    0    0    1    0    1    0    0\n \\---------------------------+----------------------------/\n                             v\n               bitmap: 0xb94 (0b101110010100)\n```\n\nThe block allocator in littlefs is a compromise between a disk-sized bitmap and\na brute force traversal. Instead of a bitmap the size of storage, we keep track\nof a small, fixed-size bitmap called the lookahead buffer. During block\nallocation, we take blocks from the lookahead buffer. If the lookahead buffer\nis empty, we scan the filesystem for more free blocks, populating our lookahead\nbuffer. In each scan we use an increasing offset, circling the storage as\nblocks are allocated.\n\nHere's what it might look like to allocate 4 blocks on a decently busy\nfilesystem with a 32 bit lookahead and a total of 128 blocks (512 KiB\nof storage if blocks are 4 KiB):\n```\nboot...         lookahead:\n                fs blocks: fffff9fffffffffeffffffffffff0000\nscanning...     lookahead: fffff9ff\n                fs blocks: fffff9fffffffffeffffffffffff0000\nalloc = 21      lookahead: fffffdff\n                fs blocks: fffffdfffffffffeffffffffffff0000\nalloc = 22      lookahead: ffffffff\n                fs blocks: fffffffffffffffeffffffffffff0000\nscanning...     lookahead:         fffffffe\n                fs blocks: fffffffffffffffeffffffffffff0000\nalloc = 63      lookahead:         ffffffff\n                fs blocks: ffffffffffffffffffffffffffff0000\nscanning...     lookahead:         ffffffff\n                fs blocks: ffffffffffffffffffffffffffff0000\nscanning...     lookahead:                 ffffffff\n                fs blocks: ffffffffffffffffffffffffffff0000\nscanning...     lookahead:                         ffff0000\n                fs blocks: ffffffffffffffffffffffffffff0000\nalloc = 112     lookahead:                         ffff8000\n                fs blocks: ffffffffffffffffffffffffffff8000\n```\n\nThis lookahead approach has a runtime complexity of _O(n&sup2;)_ to completely\nscan storage; however, bitmaps are surprisingly compact, and in practice only\none or two passes are usually needed to find free blocks. Additionally, the\nperformance of the allocator can be optimized by adjusting the block size or\nsize of the lookahead buffer, trading either write granularity or RAM for\nallocator performance.\n\n## Wear leveling\n\nThe block allocator has a secondary role: wear leveling.\n\nWear leveling is the process of distributing wear across all blocks in the\nstorage to prevent the filesystem from experiencing an early death due to\nwear on a single block in the storage.\n\nlittlefs has two methods of protecting against wear:\n1. Detection and recovery from bad blocks\n2. Evenly distributing wear across dynamic blocks\n\n---\n\nRecovery from bad blocks doesn't actually have anything to do with the block\nallocator itself. Instead, it relies on the ability of the filesystem to detect\nand evict bad blocks when they occur.\n\nIn littlefs, it is fairly straightforward to detect bad blocks at write time.\nAll writes must be sourced by some form of data in RAM, so immediately after we\nwrite to a block, we can read the data back and verify that it was written\ncorrectly. If we find that the data on disk does not match the copy we have in\nRAM, a write error has occurred and we most likely have a bad block.\n\nOnce we detect a bad block, we need to recover from it. In the case of write\nerrors, we have a copy of the corrupted data in RAM, so all we need to do is\nevict the bad block, allocate a new, hopefully good block, and repeat the write\nthat previously failed.\n\nThe actual act of evicting the bad block and replacing it with a new block is\nleft up to the filesystem's copy-on-bounded-writes (CObW) data structures. One\nproperty of CObW data structures is that any block can be replaced during a\nCOW operation. The bounded-writes part is normally triggered by a counter, but\nnothing prevents us from triggering a COW operation as soon as we find a bad\nblock.\n\n```\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.\n| A  |                        | B  |\n|    |                        |    |\n'----'                        '----'\n.    .                      v---'  .\n.    .                   .----.    .\n.    .                   | C  |    .\n.    .                   |    |    .\n.    .                   '----'    .\n.    .                   .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              | C  | B  |              |\n|    |    |              |    |    |              |\n'----'----'----'----'----'----'----'----'----'----'\n\nupdate C\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.\n| A  |                        | B  |\n|    |                        |    |\n'----'                        '----'\n.    .                      v---'  .\n.    .                   .----.    .\n.    .                   |bad |    .\n.    .                   |blck|    .\n.    .                   '----'    .\n.    .                   .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              |bad | B  |              |\n|    |    |              |blck|    |              |\n'----'----'----'----'----'----'----'----'----'----'\n\noh no! bad block! relocate C\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.\n| A  |                        | B  |\n|    |                        |    |\n'----'                        '----'\n.    .                      v---'  .\n.    .                   .----.    .\n.    .                   |bad |    .\n.    .                   |blck|    .\n.    .                   '----'    .\n.    .                   .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              |bad | B  |bad |         |\n|    |    |              |blck|    |blck|         |\n'----'----'----'----'----'----'----'----'----'----'\n                            --------->\noh no! bad block! relocate C\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.\n| A  |                        | B  |\n|    |                        |    |\n'----'                        '----'\n.    .                      v---'  .\n.    .                   .----.    .    .----.\n.    .                   |bad |    .    | C' |\n.    .                   |blck|    .    |    |\n.    .                   '----'    .    '----'\n.    .                   .    .    .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              |bad | B  |bad | C' |    |\n|    |    |              |blck|    |blck|    |    |\n'----'----'----'----'----'----'----'----'----'----'\n                            -------------->\nsuccessfully relocated C, update B\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.\n| A  |                        |bad |\n|    |                        |blck|\n'----'                        '----'\n.    .                      v---'  .\n.    .                   .----.    .    .----.\n.    .                   |bad |    .    | C' |\n.    .                   |blck|    .    |    |\n.    .                   '----'    .    '----'\n.    .                   .    .    .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              |bad |bad |bad | C' |    |\n|    |    |              |blck|blck|blck|    |    |\n'----'----'----'----'----'----'----'----'----'----'\n\noh no! bad block! relocate B\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.                        .----.         .----.\n| A  |                        |bad |         |bad |\n|    |                        |blck|         |blck|\n'----'                        '----'         '----'\n.    .                      v---'  .         .    .\n.    .                   .----.    .    .----.    .\n.    .                   |bad |    .    | C' |    .\n.    .                   |blck|    .    |    |    .\n.    .                   '----'    .    '----'    .\n.    .                   .    .    .    .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root|              |bad |bad |bad | C' |bad |\n|    |    |              |blck|blck|blck|    |blck|\n'----'----'----'----'----'----'----'----'----'----'\n                                 -------------->\noh no! bad block! relocate B\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '----------------------v\n.----.    .----.              .----.\n| A  |    | B' |              |bad |\n|    |    |    |              |blck|\n'----'    '----'              '----'\n.    .    .  | .            .---'  .\n.    .    .  '--------------v-------------v\n.    .    .    .         .----.    .    .----.\n.    .    .    .         |bad |    .    | C' |\n.    .    .    .         |blck|    .    |    |\n.    .    .    .         '----'    .    '----'\n.    .    .    .         .    .    .    .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root| B' |         |bad |bad |bad | C' |bad |\n|    |    |    |         |blck|blck|blck|    |blck|\n'----'----'----'----'----'----'----'----'----'----'\n------------>                    ------------------\nsuccessfully relocated B, update root\n=>\n     .----.\n     |root|\n     |    |\n     '----'\n   v--'  '--v\n.----.    .----.\n| A  |    | B' |\n|    |    |    |\n'----'    '----'\n.    .    .   '---------------------------v\n.    .    .    .                        .----.\n.    .    .    .                        | C' |\n.    .    .    .                        |    |\n.    .    .    .                        '----'\n.    .    .    .                        .    .\n.----.----.----.----.----.----.----.----.----.----.\n| A  |root| B' |         |bad |bad |bad | C' |bad |\n|    |    |    |         |blck|blck|blck|    |blck|\n'----'----'----'----'----'----'----'----'----'----'\n```\n\nWe may find that the new block is also bad, but hopefully after repeating this\ncycle we'll eventually find a new block where a write succeeds. If we don't,\nthat means that all blocks in our storage are bad, and we've reached the end of\nour device's usable life. At this point, littlefs will return an \"out of space\"\nerror. This is technically true, as there are no more good blocks, but as an\nadded benefit it also matches the error condition expected by users of\ndynamically sized data.\n\n---\n\nRead errors, on the other hand, are quite a bit more complicated. We don't have\na copy of the data lingering around in RAM, so we need a way to reconstruct the\noriginal data even after it has been corrupted. One such mechanism for this is\n[error-correction-codes (ECC)][wikipedia-ecc].\n\nECC is an extension to the idea of a checksum. Where a checksum such as CRC can\ndetect that an error has occurred in the data, ECC can detect and actually\ncorrect some amount of errors. However, there is a limit to how many errors ECC\ncan detect: the [Hamming bound][wikipedia-hamming-bound]. As the number of\nerrors approaches the Hamming bound, we may still be able to detect errors, but\ncan no longer fix the data. If we've reached this point the block is\nunrecoverable.\n\nlittlefs by itself does **not** provide ECC. The block nature and relatively\nlarge footprint of ECC does not work well with the dynamically sized data of\nfilesystems, correcting errors without RAM is complicated, and ECC fits better\nwith the geometry of block devices. In fact, several NOR flash chips have extra\nstorage intended for ECC, and many NAND chips can even calculate ECC on the\nchip itself.\n\nIn littlefs, ECC is entirely optional. Read errors can instead be prevented\nproactively by wear leveling. But it's important to note that ECC can be used\nat the block device level to modestly extend the life of a device. littlefs\nrespects any errors reported by the block device, allowing a block device to\nprovide additional aggressive error detection.\n\n---\n\nTo avoid read errors, we need to be proactive, as opposed to reactive as we\nwere with write errors.\n\nOne way to do this is to detect when the number of errors in a block exceeds\nsome threshold, but is still recoverable. With ECC we can do this at write\ntime, and treat the error as a write error, evicting the block before fatal\nread errors have a chance to develop.\n\nA different, more generic strategy, is to proactively distribute wear across\nall blocks in the storage, with the hope that no single block fails before the\nrest of storage is approaching the end of its usable life. This is called\nwear leveling.\n\nGenerally, wear leveling algorithms fall into one of two categories:\n\n1. [Dynamic wear leveling][wikipedia-dynamic-wear-leveling], where we\n   distribute wear over \"dynamic\" blocks. The can be accomplished by\n   only considering unused blocks.\n\n2. [Static wear leveling][wikipedia-static-wear-leveling], where we\n   distribute wear over both \"dynamic\" and \"static\" blocks. To make this work,\n   we need to consider all blocks, including blocks that already contain data.\n\nAs a tradeoff for code size and complexity, littlefs (currently) only provides\ndynamic wear leveling. This is a best effort solution. Wear is not distributed\nperfectly, but it is distributed among the free blocks and greatly extends the\nlife of a device.\n\nOn top of this, littlefs uses a statistical wear leveling algorithm. What this\nmeans is that we dont actively track wear, instead we rely on a uniform\ndistribution of wear across storage to approximate a dynamic wear leveling\nalgorithm. Despite the long name, this is actually a simplification of dynamic\nwear leveling.\n\nThe uniform distribution of wear is left up to the block allocator, which\ncreates a uniform distribution in two parts. The easy part is when the device\nis powered, in which case we allocate the blocks linearly, circling the device.\nThe harder part is what to do when the device loses power. We can't just\nrestart the allocator at the beginning of storage, as this would bias the wear.\nInstead, we start the allocator as a random offset every time we mount the\nfilesystem. As long as this random offset is uniform, the combined allocation\npattern is also a uniform distribution.\n\n![Cumulative wear distribution graph][wear-distribution-graph]\n\nInitially, this approach to wear leveling looks like it creates a difficult\ndependency on a power-independent random number generator, which must return\ndifferent random numbers on each boot. However, the filesystem is in a\nrelatively unique situation in that it is sitting on top of a large of amount\nof entropy that persists across power loss.\n\nWe can actually use the data on disk to directly drive our random number\ngenerator. In practice, this is implemented by xoring the checksums of each\nmetadata pair, which is already calculated to fetch and mount the filesystem.\n\n```\n            .--------. \\                         probably random\n           .|metadata| |                                ^\n           ||        | +-> crc ----------------------> xor\n           ||        | |                                ^\n           |'--------' /                                |\n           '---|--|-'                                   |\n            .-'    '-------------------------.          |\n           |                                  |         |\n           |        .--------------> xor ------------> xor\n           |        |                 ^       |         ^\n           v       crc               crc      v        crc\n      .--------. \\  ^   .--------. \\  ^   .--------. \\  ^\n     .|metadata|-|--|-->|metadata| |  |  .|metadata| |  |\n     ||        | +--'  ||        | +--'  ||        | +--'\n     ||        | |     ||        | |     ||        | |\n     |'--------' /     |'--------' /     |'--------' /\n     '---|--|-'        '----|---'        '---|--|-'\n      .-'    '-.            |             .-'    '-.\n     v          v           v            v          v\n.--------.  .--------.  .--------.  .--------.  .--------.\n|  data  |  |  data  |  |  data  |  |  data  |  |  data  |\n|        |  |        |  |        |  |        |  |        |\n|        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nNote that this random number generator is not perfect. It only returns unique\nrandom numbers when the filesystem is modified. This is exactly what we want\nfor distributing wear in the allocator, but means this random number generator\nis not useful for general use.\n\n---\n\nTogether, bad block detection and dynamic wear leveling provide a best effort\nsolution for avoiding the early death of a filesystem due to wear. Importantly,\nlittlefs's wear leveling algorithm provides a key feature: You can increase the\nlife of a device simply by increasing the size of storage. And if more\naggressive wear leveling is desired, you can always combine littlefs with a\n[flash translation layer (FTL)][wikipedia-ftl] to get a small power resilient\nfilesystem with static wear leveling.\n\n## Files\n\nNow that we have our building blocks out of the way, we can start looking at\nour filesystem as a whole.\n\nThe first step: How do we actually store our files?\n\nWe've determined that CTZ skip-lists are pretty good at storing data compactly,\nso following the precedent found in other filesystems we could give each file\na skip-list stored in a metadata pair that acts as an inode for the file.\n\n\n```\n                                    .--------.\n                                   .|metadata|\n                                   ||        |\n                                   ||        |\n                                   |'--------'\n                                   '----|---'\n                                        v\n.--------.  .--------.  .--------.  .--------.\n| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |\n|        |<-|        |--|        |  |        |\n|        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'\n```\n\nHowever, this doesn't work well when files are small, which is common for\nembedded systems. Compared to PCs, _all_ data in an embedded system is small.\n\nConsider a small 4-byte file. With a two block metadata-pair and one block for\nthe CTZ skip-list, we find ourselves using a full 3 blocks. On most NOR flash\nwith 4 KiB blocks, this is 12 KiB of overhead. A ridiculous 3072x increase.\n\n```\nfile stored as inode, 4 bytes costs ~12 KiB\n\n .----------------.                  \\\n.|    revision    |                  |\n||----------------|    \\             |\n||    skiplist   ---.  +- metadata   |\n||----------------| |  /  4x8 bytes  |\n||    checksum    | |     32 bytes   |\n||----------------| |                |\n||       |        | |                +- metadata pair\n||       v        | |                |  2x4 KiB\n||                | |                |  8 KiB\n||                | |                |\n||                | |                |\n||                | |                |\n|'----------------' |                |\n'----------------'  |                /\n          .--------'\n         v\n .----------------.    \\             \\\n |      data      |    +- data       |\n |----------------|    /  4 bytes    |\n |                |                  |\n |                |                  |\n |                |                  |\n |                |                  +- data block\n |                |                  |  4 KiB\n |                |                  |\n |                |                  |\n |                |                  |\n |                |                  |\n |                |                  |\n '----------------'                  /\n```\n\nWe can make several improvements. First, instead of giving each file its own\nmetadata pair, we can store multiple files in a single metadata pair. One way\nto do this is to directly associate a directory with a metadata pair (or a\nlinked list of metadata pairs). This makes it easy for multiple files to share\nthe directory's metadata pair for logging and reduces the collective storage\noverhead.\n\nThe strict binding of metadata pairs and directories also gives users\ndirect control over storage utilization depending on how they organize their\ndirectories.\n\n```\nmultiple files stored in metadata pair, 4 bytes costs ~4 KiB\n\n       .----------------.\n      .|    revision    |\n      ||----------------|\n      ||    A name      |\n      ||   A skiplist  -----.\n      ||----------------|   |  \\\n      ||    B name      |   |  +- metadata\n      ||   B skiplist  ---. |  |  4x8 bytes\n      ||----------------| | |  /  32 bytes\n      ||    checksum    | | |\n      ||----------------| | |\n      ||       |        | | |\n      ||       v        | | |\n      |'----------------' | |\n      '----------------'  | |\n         .----------------' |\n        v                   v\n.----------------.  .----------------.  \\           \\\n|     A data     |  |     B data     |  +- data     |\n|                |  |----------------|  /  4 bytes  |\n|                |  |                |              |\n|                |  |                |              |\n|                |  |                |              |\n|                |  |                |              + data block\n|                |  |                |              | 4 KiB\n|                |  |                |              |\n|----------------|  |                |              |\n|                |  |                |              |\n|                |  |                |              |\n|                |  |                |              |\n'----------------'  '----------------'              /\n```\n\nThe second improvement we can make is noticing that for very small files, our\nattempts to use CTZ skip-lists for compact storage backfires. Metadata pairs\nhave a ~4x storage cost, so if our file is smaller than 1/4 the block size,\nthere's actually no benefit in storing our file outside of our metadata pair.\n\nIn this case, we can store the file directly in our directory's metadata pair.\nWe call this an inline file, and it allows a directory to store many small\nfiles quite efficiently. Our previous 4 byte file now only takes up a\ntheoretical 16 bytes on disk.\n\n```\ninline files stored in metadata pair, 4 bytes costs ~16 bytes\n\n .----------------.\n.|    revision    |\n||----------------|\n||    A name      |\n||   A skiplist  ---.\n||----------------| |  \\\n||    B name      | |  +- data\n||    B data      | |  |  4x4 bytes\n||----------------| |  /  16 bytes\n||    checksum    | |\n||----------------| |\n||       |        | |\n||       v        | |\n|'----------------' |\n'----------------'  |\n          .---------'\n         v\n .----------------.\n |     A data     |\n |                |\n |                |\n |                |\n |                |\n |                |\n |                |\n |                |\n |----------------|\n |                |\n |                |\n |                |\n '----------------'\n```\n\nOnce the file exceeds 1/4 the block size, we switch to a CTZ skip-list. This\nmeans that our files never use more than 4x storage overhead, decreasing as\nthe file grows in size.\n\n![File storage cost graph][file-cost-graph]\n\n## Directories\n\nNow we just need directories to store our files. As mentioned above we want\na strict binding of directories and metadata pairs, but there are a few\ncomplications we need to sort out.\n\nOn their own, each directory is a linked-list of metadata pairs. This lets us\nstore an unlimited number of files in each directory, and we don't need to\nworry about the runtime complexity of unbounded logs. We can store other\ndirectory pointers in our metadata pairs, which gives us a directory tree, much\nlike what you find on other filesystems.\n\n```\n            .--------.\n           .| root   |\n           ||        |\n           ||        |\n           |'--------'\n           '---|--|-'\n            .-'    '-------------------------.\n           v                                  v\n      .--------.        .--------.        .--------.\n     .| dir A  |------->| dir A  |       .| dir B  |\n     ||        |       ||        |       ||        |\n     ||        |       ||        |       ||        |\n     |'--------'       |'--------'       |'--------'\n     '---|--|-'        '----|---'        '---|--|-'\n      .-'    '-.            |             .-'    '-.\n     v          v           v            v          v\n.--------.  .--------.  .--------.  .--------.  .--------.\n| file C |  | file D |  | file E |  | file F |  | file G |\n|        |  |        |  |        |  |        |  |        |\n|        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nThe main complication is, once again, traversal with a constant amount of\n[RAM]. The directory tree is a tree, and the unfortunate fact is you can't\ntraverse a tree with constant RAM.\n\nFortunately, the elements of our tree are metadata pairs, so unlike CTZ\nskip-lists, we're not limited to strict COW operations. One thing we can do is\nthread a linked-list through our tree, explicitly enabling cheap traversal\nover the entire filesystem.\n\n```\n            .--------.\n           .| root   |-.\n           ||        | |\n   .-------||        |-'\n   |       |'--------'\n   |       '---|--|-'\n   |        .-'    '-------------------------.\n   |       v                                  v\n   |  .--------.        .--------.        .--------.\n   '->| dir A  |------->| dir A  |------->| dir B  |\n     ||        |       ||        |       ||        |\n     ||        |       ||        |       ||        |\n     |'--------'       |'--------'       |'--------'\n     '---|--|-'        '----|---'        '---|--|-'\n      .-'    '-.            |             .-'    '-.\n     v          v           v            v          v\n.--------.  .--------.  .--------.  .--------.  .--------.\n| file C |  | file D |  | file E |  | file F |  | file G |\n|        |  |        |  |        |  |        |  |        |\n|        |  |        |  |        |  |        |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nUnfortunately, not sticking to pure COW operations creates some problems. Now,\nwhenever we want to manipulate the directory tree, multiple pointers need to be\nupdated. If you're familiar with designing atomic data structures this should\nset off a bunch of red flags.\n\nTo work around this, our threaded linked-list has a bit of leeway. Instead of\nonly containing metadata pairs found in our filesystem, it is allowed to\ncontain metadata pairs that have no parent because of a power loss. These are\ncalled orphaned metadata pairs.\n\nWith the possibility of orphans, we can build power loss resilient operations\nthat maintain a filesystem tree threaded with a linked-list for traversal.\n\nAdding a directory to our tree:\n\n```\n         .--------.\n        .| root   |-.\n        ||        | |\n.-------||        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-.\n|       v          v\n|  .--------.  .--------.\n'->| dir A  |->| dir C  |\n  ||        | ||        |\n  ||        | ||        |\n  |'--------' |'--------'\n  '--------'  '--------'\n\nallocate dir B\n=>\n         .--------.\n        .| root   |-.\n        ||        | |\n.-------||        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-.\n|       v          v\n|  .--------.    .--------.\n'->| dir A  |--->| dir C  |\n  ||        | .->|        |\n  ||        | | ||        |\n  |'--------' | |'--------'\n  '--------'  | '--------'\n              |\n   .--------. |\n  .| dir B  |-'\n  ||        |\n  ||        |\n  |'--------'\n  '--------'\n\ninsert dir B into threaded linked-list, creating an orphan\n=>\n         .--------.\n        .| root   |-.\n        ||        | |\n.-------||        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-------------.\n|       v                      v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | || orphan!| ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n\nadd dir B to parent directory\n=>\n               .--------.\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n```\n\nRemoving a directory:\n\n```\n               .--------.\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n\nremove dir B from parent directory, creating an orphan\n=>\n         .--------.\n        .| root   |-.\n        ||        | |\n.-------||        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-------------.\n|       v                      v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | || orphan!| ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n\nremove dir B from threaded linked-list, returning dir B to free blocks\n=>\n         .--------.\n        .| root   |-.\n        ||        | |\n.-------||        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-.\n|       v          v\n|  .--------.  .--------.\n'->| dir A  |->| dir C  |\n  ||        | ||        |\n  ||        | ||        |\n  |'--------' |'--------'\n  '--------'  '--------'\n```\n\nIn addition to normal directory tree operations, we can use orphans to evict\nblocks in a metadata pair when the block goes bad or exceeds its allocated\nerases. If we lose power while evicting a metadata block we may end up with\na situation where the filesystem references the replacement block while the\nthreaded linked-list still contains the evicted block. We call this a\nhalf-orphan.\n\n```\n               .--------.\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n\ntry to write to dir B\n=>\n                  .--------.\n                 .| root   |-.\n                 ||        | |\n.----------------||        |-'\n|                |'--------'\n|                '-|-||-|-'\n|        .--------'  ||  '-----.\n|       v            |v         v\n|  .--------.     .--------.  .--------.\n'->| dir A  |---->| dir B  |->| dir C  |\n  ||        |-.   |        | ||        |\n  ||        | |   |        | ||        |\n  |'--------' |   '--------' |'--------'\n  '--------'  |      v       '--------'\n              |  .--------.\n              '->| dir B  |\n                 | bad    |\n                 | block! |\n                 '--------'\n\noh no! bad block detected, allocate replacement\n=>\n                  .--------.\n                 .| root   |-.\n                 ||        | |\n.----------------||        |-'\n|                |'--------'\n|                '-|-||-|-'\n|        .--------'  ||  '-------.\n|       v            |v           v\n|  .--------.     .--------.    .--------.\n'->| dir A  |---->| dir B  |--->| dir C  |\n  ||        |-.   |        | .->|        |\n  ||        | |   |        | | ||        |\n  |'--------' |   '--------' | |'--------'\n  '--------'  |      v       | '--------'\n              |  .--------.  |\n              '->| dir B  |  |\n                 | bad    |  |\n                 | block! |  |\n                 '--------'  |\n                             |\n                 .--------.  |\n                 | dir B  |--'\n                 |        |\n                 |        |\n                 '--------'\n\ninsert replacement in threaded linked-list, creating a half-orphan\n=>\n                  .--------.\n                 .| root   |-.\n                 ||        | |\n.----------------||        |-'\n|                |'--------'\n|                '-|-||-|-'\n|        .--------'  ||  '-------.\n|       v            |v           v\n|  .--------.     .--------.    .--------.\n'->| dir A  |---->| dir B  |--->| dir C  |\n  ||        |-.   |        | .->|        |\n  ||        | |   |        | | ||        |\n  |'--------' |   '--------' | |'--------'\n  '--------'  |      v       | '--------'\n              |  .--------.  |\n              |  | dir B  |  |\n              |  | bad    |  |\n              |  | block! |  |\n              |  '--------'  |\n              |              |\n              |  .--------.  |\n              '->| dir B  |--'\n                 | half   |\n                 | orphan!|\n                 '--------'\n\nfix reference in parent directory\n=>\n               .--------.\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n```\n\nFinding orphans and half-orphans is expensive, requiring a _O(n&sup2;)_\ncomparison of every metadata pair with every directory entry. But the tradeoff\nis a power resilient filesystem that works with only a bounded amount of RAM.\nFortunately, we only need to check for orphans on the first allocation after\nboot, and a read-only littlefs can ignore the threaded linked-list entirely.\n\nIf we only had some sort of global state, then we could also store a flag and\navoid searching for orphans unless we knew we were specifically interrupted\nwhile manipulating the directory tree (foreshadowing!).\n\n## The move problem\n\nWe have one last challenge: the move problem. Phrasing the problem is simple:\n\nHow do you atomically move a file between two directories?\n\nIn littlefs we can atomically commit to directories, but we can't create\nan atomic commit that spans multiple directories. The filesystem must go\nthrough a minimum of two distinct states to complete a move.\n\nTo make matters worse, file moves are a common form of synchronization for\nfilesystems. As a filesystem designed for power-loss, it's important we get\natomic moves right.\n\nSo what can we do?\n\n- We definitely can't just let power-loss result in duplicated or lost files.\n  This could easily break users' code and would only reveal itself in extreme\n  cases. We were only able to be lazy about the threaded linked-list because\n  it isn't user facing and we can handle the corner cases internally.\n\n- Some filesystems propagate COW operations up the tree until a common parent\n  is found. Unfortunately this interacts poorly with our threaded tree and\n  brings back the issue of upward propagation of wear.\n\n- In a previous version of littlefs we tried to solve this problem by going\n  back and forth between the source and destination, marking and unmarking the\n  file as moving in order to make the move atomic from the user perspective.\n  This worked, but not well. Finding failed moves was expensive and required\n  a unique identifier for each file.\n\nIn the end, solving the move problem required creating a new mechanism for\nsharing knowledge between multiple metadata pairs. In littlefs this led to the\nintroduction of a mechanism called \"global state\".\n\n---\n\nGlobal state is a small set of state that can be updated from _any_ metadata\npair. Combining global state with metadata pairs' ability to update multiple\nentries in one commit gives us a powerful tool for crafting complex atomic\noperations.\n\nHow does global state work?\n\nGlobal state exists as a set of deltas that are distributed across the metadata\npairs in the filesystem. The actual global state can be built out of these\ndeltas by xoring together all of the deltas in the filesystem.\n\n```\n .--------.  .--------.  .--------.  .--------.  .--------.\n.|        |->| gdelta |->|        |->| gdelta |->| gdelta |\n||        | || 0x23   | ||        | || 0xff   | || 0xce   |\n||        | ||        | ||        | ||        | ||        |\n|'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '----|---'  '--------'  '----|---'  '----|---'\n                 v                       v           v\n       0x00 --> xor ------------------> xor ------> xor --> gstate 0x12\n```\n\nTo update the global state from a metadata pair, we take the global state we\nknow and xor it with both our changes and any existing delta in the metadata\npair. Committing this new delta to the metadata pair commits the changes to\nthe filesystem's global state.\n\n```\n .--------.  .--------.  .--------.  .--------.  .--------.\n.|        |->| gdelta |->|        |->| gdelta |->| gdelta |\n||        | || 0x23   | ||        | || 0xff   | || 0xce   |\n||        | ||        | ||        | ||        | ||        |\n|'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '----|---'  '--------'  '--|---|-'  '----|---'\n                 v                     v   |         v\n       0x00 --> xor ----------------> xor -|------> xor --> gstate = 0x12\n                                           |                          |\n                                           |                          |\nchange gstate to 0xab --> xor <------------|--------------------------'\n=>                         |               v\n                           '------------> xor\n                                           |\n                                           v\n .--------.  .--------.  .--------.  .--------.  .--------.\n.|        |->| gdelta |->|        |->| gdelta |->| gdelta |\n||        | || 0x23   | ||        | || 0x46   | || 0xce   |\n||        | ||        | ||        | ||        | ||        |\n|'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '----|---'  '--------'  '----|---'  '----|---'\n                 v                       v           v\n       0x00 --> xor ------------------> xor ------> xor --> gstate = 0xab\n```\n\nTo make this efficient, we always keep a copy of the global state in RAM. We\nonly need to iterate over our metadata pairs and build the global state when\nthe filesystem is mounted.\n\nYou may have noticed that global state is very expensive. We keep a copy in\nRAM and a delta in an unbounded number of metadata pairs. Even if we reset\nthe global state to its initial value, we can't easily clean up the deltas on\ndisk. For this reason, it's very important that we keep the size of global\nstate bounded and extremely small. But, even with a strict budget, global\nstate is incredibly valuable.\n\n---\n\nNow we can solve the move problem. We can create global state describing our\nmove atomically with the creation of the new file, and we can clear this move\nstate atomically with the removal of the old file.\n\n```\n               .--------.    gstate = no move\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '----|---'  '--------'  '--------'\n       v\n   .--------.\n   | file D |\n   |        |\n   |        |\n   '--------'\n\nbegin move, add reference in dir C, change gstate to have move\n=>\n               .--------.    gstate = moving file D in dir A (m1)\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  ||        | ||        | || gdelta |\n  ||        | ||        | || =m1    |\n  |'--------' |'--------' |'--------'\n  '----|---'  '--------'  '----|---'\n       |     .----------------'\n       v    v\n     .--------.\n     | file D |\n     |        |\n     |        |\n     '--------'\n\ncomplete move, remove reference in dir A, change gstate to no move\n=>\n               .--------.    gstate = no move (m1^~m1)\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  || gdelta | ||        | || gdelta |\n  || =~m1   | ||        | || =m1    |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '----|---'\n                               v\n                           .--------.\n                           | file D |\n                           |        |\n                           |        |\n                           '--------'\n```\n\n\nIf, after building our global state during mount, we find information\ndescribing an ongoing move, we know we lost power during a move and the file\nis duplicated in both the source and destination directories. If this happens,\nwe can resolve the move using the information in the global state to remove\none of the files.\n\n```\n                 .--------.    gstate = moving file D in dir A (m1)\n                .| root   |-.             ^\n                ||        |------------> xor\n.---------------||        |-'             ^\n|               |'--------'               |\n|               '--|-|-|-'                |\n|        .--------'  |  '---------.       |\n|       |            |             |      |\n|       |     .----------> xor --------> xor\n|       v     |      v      ^      v      ^\n|  .--------. |  .--------. |  .--------. |\n'->| dir A  |-|->| dir B  |-|->| dir C  | |\n  ||        |-' ||        |-' || gdelta |-'\n  ||        |   ||        |   || =m1    |\n  |'--------'   |'--------'   |'--------'\n  '----|---'    '--------'    '----|---'\n       |     .---------------------'\n       v    v\n     .--------.\n     | file D |\n     |        |\n     |        |\n     '--------'\n```\n\nWe can also move directories the same way we move files. There is the threaded\nlinked-list to consider, but leaving the threaded linked-list unchanged works\nfine as the order doesn't really matter.\n\n```\n               .--------.    gstate = no move (m1^~m1)\n              .| root   |-.\n              ||        | |\n.-------------||        |-'\n|             |'--------'\n|             '--|-|-|-'\n|        .------'  |  '-------.\n|       v          v           v\n|  .--------.  .--------.  .--------.\n'->| dir A  |->| dir B  |->| dir C  |\n  || gdelta | ||        | || gdelta |\n  || =~m1   | ||        | || =m1    |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '----|---'\n                               v\n                           .--------.\n                           | file D |\n                           |        |\n                           |        |\n                           '--------'\n\nbegin move, add reference in dir C, change gstate to have move\n=>\n                .--------.    gstate = moving dir B in root (m1^~m1^m2)\n               .| root   |-.\n               ||        | |\n.--------------||        |-'\n|              |'--------'\n|              '--|-|-|-'\n|        .-------'  |  '----------.\n|       v           |              v\n|  .--------.       |          .--------.\n'->| dir A  |-.     |       .->| dir C  |\n  || gdelta | |     |       | || gdelta |\n  || =~m1   | |     |       | || =m1^m2 |\n  |'--------' |     |       | |'--------'\n  '--------'  |     |       | '---|--|-'\n              |     |    .-------'   |\n              |     v   v   |        v\n              |  .--------. |    .--------.\n              '->| dir B  |-'    | file D |\n                ||        |      |        |\n                ||        |      |        |\n                |'--------'      '--------'\n                '--------'\n\ncomplete move, remove reference in root, change gstate to no move\n=>\n             .--------.    gstate = no move (m1^~m1^m2^~m2)\n            .| root   |-.\n            || gdelta | |\n.-----------|| =~m2   |-'\n|           |'--------'\n|           '---|--|-'\n|        .-----'    '-----.\n|       v                  v\n|  .--------.          .--------.\n'->| dir A  |-.     .->| dir C  |\n  || gdelta | |     | || gdelta |\n  || =~m1   | |     '-|| =m1^m2 |-------.\n  |'--------' |       |'--------'       |\n  '--------'  |       '---|--|-'        |\n              |        .-'    '-.       |\n              |       v          v      |\n              |  .--------.  .--------. |\n              '->| dir B  |--| file D |-'\n                ||        |  |        |\n                ||        |  |        |\n                |'--------'  '--------'\n                '--------'\n```\n\nGlobal state gives us a powerful tool we can use to solve the move problem.\nAnd the result is surprisingly performant, only needing the minimum number\nof states and using the same number of commits as a naive move. Additionally,\nglobal state gives us a bit of persistent state we can use for some other\nsmall improvements.\n\n## Conclusion\n\nAnd that's littlefs, thanks for reading!\n\n\n[wikipedia-flash]: https://en.wikipedia.org/wiki/Flash_memory\n[wikipedia-sna]: https://en.wikipedia.org/wiki/Serial_number_arithmetic\n[wikipedia-crc]: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n[wikipedia-cow]: https://en.wikipedia.org/wiki/Copy-on-write\n[wikipedia-B-tree]: https://en.wikipedia.org/wiki/B-tree\n[wikipedia-B+-tree]: https://en.wikipedia.org/wiki/B%2B_tree\n[wikipedia-skip-list]: https://en.wikipedia.org/wiki/Skip_list\n[wikipedia-ctz]: https://en.wikipedia.org/wiki/Count_trailing_zeros\n[wikipedia-ecc]: https://en.wikipedia.org/wiki/Error_correction_code\n[wikipedia-hamming-bound]: https://en.wikipedia.org/wiki/Hamming_bound\n[wikipedia-dynamic-wear-leveling]: https://en.wikipedia.org/wiki/Wear_leveling#Dynamic_wear_leveling\n[wikipedia-static-wear-leveling]: https://en.wikipedia.org/wiki/Wear_leveling#Static_wear_leveling\n[wikipedia-ftl]: https://en.wikipedia.org/wiki/Flash_translation_layer\n\n[oeis]: https://oeis.org\n[A001511]: https://oeis.org/A001511\n[A005187]: https://oeis.org/A005187\n\n[fat]: https://en.wikipedia.org/wiki/Design_of_the_FAT_file_system\n[ext2]: http://e2fsprogs.sourceforge.net/ext2intro.html\n[jffs]: https://www.sourceware.org/jffs2/jffs2-html\n[yaffs]: https://yaffs.net/documents/how-yaffs-works\n[spiffs]: https://github.com/pellepl/spiffs/blob/master/docs/TECH_SPEC\n[ext4]: https://ext4.wiki.kernel.org/index.php/Ext4_Design\n[ntfs]: https://en.wikipedia.org/wiki/NTFS\n[btrfs]: https://btrfs.wiki.kernel.org/index.php/Btrfs_design\n[zfs]: https://en.wikipedia.org/wiki/ZFS\n\n[cow]: https://upload.wikimedia.org/wikipedia/commons/0/0c/Cow_female_black_white.jpg\n[elephant]: https://upload.wikimedia.org/wikipedia/commons/3/37/African_Bush_Elephant.jpg\n[ram]: https://upload.wikimedia.org/wikipedia/commons/9/97/New_Mexico_Bighorn_Sheep.JPG\n\n[metadata-formula1]: https://latex.codecogs.com/svg.latex?cost%20%3D%20n%20&plus;%20n%20%5Cfrac%7Bs%7D%7Bd&plus;1%7D\n[metadata-formula2]: https://latex.codecogs.com/svg.latex?s%20%3D%20r%20%5Cfrac%7Bsize%7D%7Bn%7D\n[metadata-formula3]: https://latex.codecogs.com/svg.latex?d%20%3D%20%281-r%29%20%5Cfrac%7Bsize%7D%7Bn%7D\n[metadata-formula4]: https://latex.codecogs.com/svg.latex?cost%20%3D%20n%20&plus;%20n%20%5Cfrac%7Br%5Cfrac%7Bsize%7D%7Bn%7D%7D%7B%281-r%29%5Cfrac%7Bsize%7D%7Bn%7D&plus;1%7D\n\n[ctz-formula1]: https://latex.codecogs.com/svg.latex?%5Clim_%7Bn%5Cto%5Cinfty%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%20%3D%20%5Csum_%7Bi%3D0%7D%5Cfrac%7B1%7D%7B2%5Ei%7D%20%3D%202\n[ctz-formula2]: https://latex.codecogs.com/svg.latex?B%20%3D%20%5Cfrac%7Bw%7D%7B8%7D%5Cleft%5Clceil%5Clog_2%5Cleft%28%5Cfrac%7B2%5Ew%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D%5Cright%29%5Cright%5Crceil\n[ctz-formula3]: https://latex.codecogs.com/svg.latex?N%20%3D%20%5Csum_i%5En%5Cleft%5BB-%5Cfrac%7Bw%7D%7B8%7D%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%5Cright%5D\n[ctz-formula4]: https://latex.codecogs.com/svg.latex?%5Csum_i%5En%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%20%3D%202n-%5Ctext%7Bpopcount%7D%28n%29\n[ctz-formula5]: https://latex.codecogs.com/svg.latex?N%20%3D%20Bn%20-%20%5Cfrac%7Bw%7D%7B8%7D%5Cleft%282n-%5Ctext%7Bpopcount%7D%28n%29%5Cright%29\n[ctz-formula6]: https://latex.codecogs.com/svg.latex?n%20%3D%20%5Cleft%5Clfloor%5Cfrac%7BN-%5Cfrac%7Bw%7D%7B8%7D%5Cleft%28%5Ctext%7Bpopcount%7D%5Cleft%28%5Cfrac%7BN%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D-1%5Cright%29&plus;2%5Cright%29%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D%5Cright%5Crfloor\n[ctz-formula7]: https://latex.codecogs.com/svg.latex?%5Cmathit%7Boff%7D%20%3D%20N%20-%20%5Cleft%28B-2%5Cfrac%7Bw%7D%7B8%7D%5Cright%29n%20-%20%5Cfrac%7Bw%7D%7B8%7D%5Ctext%7Bpopcount%7D%28n%29\n\n[bigB]: https://latex.codecogs.com/svg.latex?B\n[d]: https://latex.codecogs.com/svg.latex?d\n[m]: https://latex.codecogs.com/svg.latex?m\n[bigN]: https://latex.codecogs.com/svg.latex?N\n[n]: https://latex.codecogs.com/svg.latex?n\n[n']: https://latex.codecogs.com/svg.latex?n%27\n[r]: https://latex.codecogs.com/svg.latex?r\n[s]: https://latex.codecogs.com/svg.latex?s\n[w]: https://latex.codecogs.com/svg.latex?w\n[x]: https://latex.codecogs.com/svg.latex?x\n\n[metadata-cost-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/metadata-cost.svg?sanitize=true\n[wear-distribution-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/wear-distribution.svg?sanitize=true\n[file-cost-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/file-cost.svg?sanitize=true\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.4873046875,
          "content": "Copyright (c) 2022, The littlefs authors.  \nCopyright (c) 2017, Arm Limited. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n-  Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n-  Redistributions in binary form must reproduce the above copyright notice, this\n   list of conditions and the following disclaimer in the documentation and/or\n   other materials provided with the distribution.\n-  Neither the name of ARM nor the names of its contributors may be used to\n   endorse or promote products derived from this software without specific prior\n   written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 14.376953125,
          "content": "# overrideable build dir, default is in-place\nBUILDDIR ?= .\n# overridable target/src/tools/flags/etc\nifneq ($(wildcard test.c main.c),)\nTARGET ?= $(BUILDDIR)/lfs\nelse\nTARGET ?= $(BUILDDIR)/liblfs.a\nendif\n\n\nCC       ?= gcc\nAR       ?= ar\nSIZE     ?= size\nCTAGS    ?= ctags\nNM       ?= nm\nOBJDUMP  ?= objdump\nVALGRIND ?= valgrind\nGDB\t\t ?= gdb\nPERF\t ?= perf\n\nSRC  ?= $(filter-out $(wildcard *.t.* *.b.*),$(wildcard *.c))\nOBJ  := $(SRC:%.c=$(BUILDDIR)/%.o)\nDEP  := $(SRC:%.c=$(BUILDDIR)/%.d)\nASM  := $(SRC:%.c=$(BUILDDIR)/%.s)\nCI   := $(SRC:%.c=$(BUILDDIR)/%.ci)\nGCDA := $(SRC:%.c=$(BUILDDIR)/%.t.gcda)\n\nTESTS ?= $(wildcard tests/*.toml)\nTEST_SRC ?= $(SRC) \\\n\t\t$(filter-out $(wildcard bd/*.t.* bd/*.b.*),$(wildcard bd/*.c)) \\\n\t\trunners/test_runner.c\nTEST_RUNNER ?= $(BUILDDIR)/runners/test_runner\nTEST_A     := $(TESTS:%.toml=$(BUILDDIR)/%.t.a.c) \\\n\t\t$(TEST_SRC:%.c=$(BUILDDIR)/%.t.a.c)\nTEST_C     := $(TEST_A:%.t.a.c=%.t.c)\nTEST_OBJ   := $(TEST_C:%.t.c=%.t.o)\nTEST_DEP   := $(TEST_C:%.t.c=%.t.d)\nTEST_CI\t   := $(TEST_C:%.t.c=%.t.ci)\nTEST_GCNO  := $(TEST_C:%.t.c=%.t.gcno)\nTEST_GCDA  := $(TEST_C:%.t.c=%.t.gcda)\nTEST_PERF  := $(TEST_RUNNER:%=%.perf)\nTEST_TRACE := $(TEST_RUNNER:%=%.trace)\nTEST_CSV   := $(TEST_RUNNER:%=%.csv)\n\nBENCHES ?= $(wildcard benches/*.toml)\nBENCH_SRC ?= $(SRC) \\\n\t\t$(filter-out $(wildcard bd/*.t.* bd/*.b.*),$(wildcard bd/*.c)) \\\n\t\trunners/bench_runner.c\nBENCH_RUNNER ?= $(BUILDDIR)/runners/bench_runner\nBENCH_A     := $(BENCHES:%.toml=$(BUILDDIR)/%.b.a.c) \\\n\t\t$(BENCH_SRC:%.c=$(BUILDDIR)/%.b.a.c)\nBENCH_C     := $(BENCH_A:%.b.a.c=%.b.c)\nBENCH_OBJ   := $(BENCH_C:%.b.c=%.b.o)\nBENCH_DEP   := $(BENCH_C:%.b.c=%.b.d)\nBENCH_CI    := $(BENCH_C:%.b.c=%.b.ci)\nBENCH_GCNO  := $(BENCH_C:%.b.c=%.b.gcno)\nBENCH_GCDA  := $(BENCH_C:%.b.c=%.b.gcda)\nBENCH_PERF  := $(BENCH_RUNNER:%=%.perf)\nBENCH_TRACE := $(BENCH_RUNNER:%=%.trace)\nBENCH_CSV   := $(BENCH_RUNNER:%=%.csv)\n\nCFLAGS += -fcallgraph-info=su\nCFLAGS += -g3\nCFLAGS += -I.\nCFLAGS += -std=c99 -Wall -Wextra -pedantic\nCFLAGS += -Wmissing-prototypes\nCFLAGS += -ftrack-macro-expansion=0\nifdef DEBUG\nCFLAGS += -O0\nelse\nCFLAGS += -Os\nendif\nifdef TRACE\nCFLAGS += -DLFS_YES_TRACE\nendif\nifdef YES_COV\nCFLAGS += --coverage\nendif\nifdef YES_PERF\nCFLAGS += -fno-omit-frame-pointer\nendif\nifdef YES_PERFBD\nCFLAGS += -fno-omit-frame-pointer\nendif\n\nifdef VERBOSE\nCODEFLAGS    += -v\nDATAFLAGS    += -v\nSTACKFLAGS   += -v\nSTRUCTSFLAGS += -v\nCOVFLAGS     += -v\nPERFFLAGS    += -v\nPERFBDFLAGS  += -v\nendif\n# forward -j flag\nPERFFLAGS   += $(filter -j%,$(MAKEFLAGS))\nPERFBDFLAGS += $(filter -j%,$(MAKEFLAGS))\nifneq ($(NM),nm)\nCODEFLAGS += --nm-path=\"$(NM)\"\nDATAFLAGS += --nm-path=\"$(NM)\"\nendif\nifneq ($(OBJDUMP),objdump)\nCODEFLAGS    += --objdump-path=\"$(OBJDUMP)\"\nDATAFLAGS    += --objdump-path=\"$(OBJDUMP)\"\nSTRUCTSFLAGS += --objdump-path=\"$(OBJDUMP)\"\nPERFFLAGS    += --objdump-path=\"$(OBJDUMP)\"\nPERFBDFLAGS  += --objdump-path=\"$(OBJDUMP)\"\nendif\nifneq ($(PERF),perf)\nPERFFLAGS += --perf-path=\"$(PERF)\"\nendif\n\nTESTFLAGS  += -b\nBENCHFLAGS += -b\n# forward -j flag\nTESTFLAGS  += $(filter -j%,$(MAKEFLAGS))\nBENCHFLAGS += $(filter -j%,$(MAKEFLAGS))\nifdef YES_PERF\nTESTFLAGS  += -p $(TEST_PERF)\nBENCHFLAGS += -p $(BENCH_PERF)\nendif\nifdef YES_PERFBD\nTESTFLAGS += -t $(TEST_TRACE) --trace-backtrace --trace-freq=100\nendif\nifndef NO_PERFBD\nBENCHFLAGS += -t $(BENCH_TRACE) --trace-backtrace --trace-freq=100\nendif\nifdef YES_TESTMARKS\nTESTFLAGS += -o $(TEST_CSV)\nendif\nifndef NO_BENCHMARKS\nBENCHFLAGS += -o $(BENCH_CSV)\nendif\nifdef VERBOSE\nTESTFLAGS   += -v\nTESTCFLAGS  += -v\nBENCHFLAGS  += -v\nBENCHCFLAGS += -v\nendif\nifdef EXEC\nTESTFLAGS  += --exec=\"$(EXEC)\"\nBENCHFLAGS += --exec=\"$(EXEC)\"\nendif\nifneq ($(GDB),gdb)\nTESTFLAGS  += --gdb-path=\"$(GDB)\"\nBENCHFLAGS += --gdb-path=\"$(GDB)\"\nendif\nifneq ($(VALGRIND),valgrind)\nTESTFLAGS  += --valgrind-path=\"$(VALGRIND)\"\nBENCHFLAGS += --valgrind-path=\"$(VALGRIND)\"\nendif\nifneq ($(PERF),perf)\nTESTFLAGS  += --perf-path=\"$(PERF)\"\nBENCHFLAGS += --perf-path=\"$(PERF)\"\nendif\n\n# this is a bit of a hack, but we want to make sure the BUILDDIR\n# directory structure is correct before we run any commands\nifneq ($(BUILDDIR),.)\n$(if $(findstring n,$(MAKEFLAGS)),, $(shell mkdir -p \\\n\t$(addprefix $(BUILDDIR)/,$(dir \\\n\t\t$(SRC) \\\n\t\t$(TESTS) \\\n\t\t$(TEST_SRC) \\\n\t\t$(BENCHES) \\\n\t\t$(BENCH_SRC)))))\nendif\n\n\n# commands\n\n## Build littlefs\n.PHONY: all build\nall build: $(TARGET)\n\n## Build assembly files\n.PHONY: asm\nasm: $(ASM)\n\n## Find the total size\n.PHONY: size\nsize: $(OBJ)\n\t$(SIZE) -t $^\n\n## Generate a ctags file\n.PHONY: tags\ntags:\n\t$(CTAGS) --totals --c-types=+p $(shell find -H -name '*.h') $(SRC)\n\n## Show this help text\n.PHONY: help\nhelp:\n\t@$(strip awk '/^## / { \\\n\t\t\tsub(/^## /,\"\"); \\\n\t\t\tgetline rule; \\\n\t\t\twhile (rule ~ /^(#|\\.PHONY|ifdef|ifndef)/) getline rule; \\\n\t\t\tgsub(/:.*/, \"\", rule); \\\n\t\t\tprintf \" \"\" %-25s %s\\n\", rule, $$0 \\\n\t\t}' $(MAKEFILE_LIST))\n\n## Find the per-function code size\n.PHONY: code\ncode: CODEFLAGS+=-S\ncode: $(OBJ) $(BUILDDIR)/lfs.code.csv\n\t./scripts/code.py $(OBJ) $(CODEFLAGS)\n\n## Compare per-function code size\n.PHONY: code-diff\ncode-diff: $(OBJ)\n\t./scripts/code.py $^ $(CODEFLAGS) -d $(BUILDDIR)/lfs.code.csv\n\n## Find the per-function data size\n.PHONY: data\ndata: DATAFLAGS+=-S\ndata: $(OBJ) $(BUILDDIR)/lfs.data.csv\n\t./scripts/data.py $(OBJ) $(DATAFLAGS)\n\n## Compare per-function data size\n.PHONY: data-diff\ndata-diff: $(OBJ)\n\t./scripts/data.py $^ $(DATAFLAGS) -d $(BUILDDIR)/lfs.data.csv\n\n## Find the per-function stack usage\n.PHONY: stack\nstack: STACKFLAGS+=-S\nstack: $(CI) $(BUILDDIR)/lfs.stack.csv\n\t./scripts/stack.py $(CI) $(STACKFLAGS)\n\n## Compare per-function stack usage\n.PHONY: stack-diff\nstack-diff: $(CI)\n\t./scripts/stack.py $^ $(STACKFLAGS) -d $(BUILDDIR)/lfs.stack.csv\n\n## Find function sizes\n.PHONY: funcs\nfuncs: SUMMARYFLAGS+=-S\nfuncs: \\\n\t\t$(BUILDDIR)/lfs.code.csv \\\n\t\t$(BUILDDIR)/lfs.data.csv \\\n\t\t$(BUILDDIR)/lfs.stack.csv\n\t$(strip ./scripts/summary.py $^ \\\n\t\t-bfunction \\\n\t\t-fcode=code_size \\\n\t\t-fdata=data_size \\\n\t\t-fstack=stack_limit --max=stack \\\n\t\t$(SUMMARYFLAGS))\n\n## Compare function sizes\n.PHONY: funcs-diff\nfuncs-diff: SHELL=/bin/bash\nfuncs-diff: $(OBJ) $(CI)\n\t$(strip ./scripts/summary.py \\\n\t\t<(./scripts/code.py $(OBJ) -q $(CODEFLAGS) -o-) \\\n\t\t<(./scripts/data.py $(OBJ) -q $(DATAFLAGS) -o-) \\\n\t\t<(./scripts/stack.py $(CI) -q $(STACKFLAGS) -o-) \\\n\t\t-bfunction \\\n\t\t-fcode=code_size \\\n\t\t-fdata=data_size \\\n\t\t-fstack=stack_limit --max=stack \\\n\t\t$(SUMMARYFLAGS) -d <(./scripts/summary.py \\\n\t\t\t$(BUILDDIR)/lfs.code.csv \\\n\t\t\t$(BUILDDIR)/lfs.data.csv \\\n\t\t\t$(BUILDDIR)/lfs.stack.csv \\\n\t\t\t-q $(SUMMARYFLAGS) -o-))\n\n## Find struct sizes\n.PHONY: structs\nstructs: STRUCTSFLAGS+=-S\nstructs: $(OBJ) $(BUILDDIR)/lfs.structs.csv\n\t./scripts/structs.py $(OBJ) $(STRUCTSFLAGS)\n\n## Compare struct sizes\n.PHONY: structs-diff\nstructs-diff: $(OBJ)\n\t./scripts/structs.py $^ $(STRUCTSFLAGS) -d $(BUILDDIR)/lfs.structs.csv\n\n## Find the line/branch coverage after a test run\n.PHONY: cov\ncov: COVFLAGS+=-s\ncov: $(GCDA) $(BUILDDIR)/lfs.cov.csv\n\t$(strip ./scripts/cov.py $(GCDA) \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(COVFLAGS))\n\n## Compare line/branch coverage\n.PHONY: cov-diff\ncov-diff: $(GCDA)\n\t$(strip ./scripts/cov.py $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(COVFLAGS) -d $(BUILDDIR)/lfs.cov.csv)\n\n## Find the perf results after bench run with YES_PERF\n.PHONY: perf\nperf: PERFFLAGS+=-S\nperf: $(BENCH_PERF) $(BUILDDIR)/lfs.perf.csv\n\t$(strip ./scripts/perf.py $(BENCH_PERF) \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(PERFFLAGS))\n\n## Compare perf results\n.PHONY: perf-diff\nperf-diff: $(BENCH_PERF)\n\t$(strip ./scripts/perf.py $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(PERFFLAGS) -d $(BUILDDIR)/lfs.perf.csv)\n\n## Find the perfbd results after a bench run\n.PHONY: perfbd\nperfbd: PERFBDFLAGS+=-S\nperfbd: $(BENCH_TRACE) $(BUILDDIR)/lfs.perfbd.csv\n\t$(strip ./scripts/perfbd.py $(BENCH_RUNNER) $(BENCH_TRACE) \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(PERFBDFLAGS))\n\n## Compare perfbd results\n.PHONY: perfbd-diff\nperfbd-diff: $(BENCH_TRACE)\n\t$(strip ./scripts/perfbd.py $(BENCH_RUNNER) $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t$(PERFBDFLAGS) -d $(BUILDDIR)/lfs.perfbd.csv)\n\n## Find a summary of compile-time sizes\n.PHONY: summary sizes\nsummary sizes: \\\n\t\t$(BUILDDIR)/lfs.code.csv \\\n\t\t$(BUILDDIR)/lfs.data.csv \\\n\t\t$(BUILDDIR)/lfs.stack.csv \\\n\t\t$(BUILDDIR)/lfs.structs.csv\n\t$(strip ./scripts/summary.py $^ \\\n\t\t-fcode=code_size \\\n\t\t-fdata=data_size \\\n\t\t-fstack=stack_limit --max=stack \\\n\t\t-fstructs=struct_size \\\n\t\t-Y $(SUMMARYFLAGS))\n\n## Compare compile-time sizes\n.PHONY: summary-diff sizes-diff\nsummary-diff sizes-diff: SHELL=/bin/bash\nsummary-diff sizes-diff: $(OBJ) $(CI)\n\t$(strip ./scripts/summary.py \\\n\t\t<(./scripts/code.py $(OBJ) -q $(CODEFLAGS) -o-) \\\n\t\t<(./scripts/data.py $(OBJ) -q $(DATAFLAGS) -o-) \\\n\t\t<(./scripts/stack.py $(CI) -q $(STACKFLAGS) -o-) \\\n\t\t<(./scripts/structs.py $(OBJ) -q $(STRUCTSFLAGS) -o-) \\\n\t\t-fcode=code_size \\\n\t\t-fdata=data_size \\\n\t\t-fstack=stack_limit --max=stack \\\n\t\t-fstructs=struct_size \\\n\t\t-Y $(SUMMARYFLAGS) -d <(./scripts/summary.py \\\n\t\t\t$(BUILDDIR)/lfs.code.csv \\\n\t\t\t$(BUILDDIR)/lfs.data.csv \\\n\t\t\t$(BUILDDIR)/lfs.stack.csv \\\n\t\t\t$(BUILDDIR)/lfs.structs.csv \\\n\t\t\t-q $(SUMMARYFLAGS) -o-))\n\n## Build the test-runner\n.PHONY: test-runner build-test\ntest-runner build-test: CFLAGS+=-Wno-missing-prototypes\nifndef NO_COV\ntest-runner build-test: CFLAGS+=--coverage\nendif\nifdef YES_PERF\ntest-runner build-test: CFLAGS+=-fno-omit-frame-pointer\nendif\nifdef YES_PERFBD\ntest-runner build-test: CFLAGS+=-fno-omit-frame-pointer\nendif\n# note we remove some binary dependent files during compilation,\n# otherwise it's way to easy to end up with outdated results\ntest-runner build-test: $(TEST_RUNNER)\nifndef NO_COV\n\trm -f $(TEST_GCDA)\nendif\nifdef YES_PERF\n\trm -f $(TEST_PERF)\nendif\nifdef YES_PERFBD\n\trm -f $(TEST_TRACE)\nendif\n\n## Run the tests, -j enables parallel tests\n.PHONY: test\ntest: test-runner\n\t./scripts/test.py $(TEST_RUNNER) $(TESTFLAGS)\n\n## List the tests\n.PHONY: test-list\ntest-list: test-runner\n\t./scripts/test.py $(TEST_RUNNER) $(TESTFLAGS) -l\n\n## Summarize the testmarks\n.PHONY: testmarks\ntestmarks: SUMMARYFLAGS+=-spassed\ntestmarks: $(TEST_CSV) $(BUILDDIR)/lfs.test.csv\n\t$(strip ./scripts/summary.py $(TEST_CSV) \\\n\t\t-bsuite \\\n\t\t-fpassed=test_passed \\\n\t\t$(SUMMARYFLAGS))\n\n## Compare testmarks against a previous run\n.PHONY: testmarks-diff\ntestmarks-diff: $(TEST_CSV)\n\t$(strip ./scripts/summary.py $^ \\\n\t\t-bsuite \\\n\t\t-fpassed=test_passed \\\n\t\t$(SUMMARYFLAGS) -d $(BUILDDIR)/lfs.test.csv)\n\n## Build the bench-runner\n.PHONY: bench-runner build-bench\nbench-runner build-bench: CFLAGS+=-Wno-missing-prototypes\nifdef YES_COV\nbench-runner build-bench: CFLAGS+=--coverage\nendif\nifdef YES_PERF\nbench-runner build-bench: CFLAGS+=-fno-omit-frame-pointer\nendif\nifndef NO_PERFBD\nbench-runner build-bench: CFLAGS+=-fno-omit-frame-pointer\nendif\n# note we remove some binary dependent files during compilation,\n# otherwise it's way to easy to end up with outdated results\nbench-runner build-bench: $(BENCH_RUNNER)\nifdef YES_COV \n\trm -f $(BENCH_GCDA)\nendif\nifdef YES_PERF\n\trm -f $(BENCH_PERF)\nendif\nifndef NO_PERFBD\n\trm -f $(BENCH_TRACE)\nendif\n\n## Run the benchmarks, -j enables parallel benchmarks\n.PHONY: bench\nbench: bench-runner\n\t./scripts/bench.py $(BENCH_RUNNER) $(BENCHFLAGS)\n\n## List the benchmarks\n.PHONY: bench-list\nbench-list: bench-runner\n\t./scripts/bench.py $(BENCH_RUNNER) $(BENCHFLAGS) -l\n\n## Summarize the benchmarks\n.PHONY: benchmarks\nbenchmarks: SUMMARYFLAGS+=-Serased -Sproged -Sreaded\nbenchmarks: $(BENCH_CSV) $(BUILDDIR)/lfs.bench.csv\n\t$(strip ./scripts/summary.py $(BENCH_CSV) \\\n\t\t-bsuite \\\n\t\t-freaded=bench_readed \\\n\t\t-fproged=bench_proged \\\n\t\t-ferased=bench_erased \\\n\t\t$(SUMMARYFLAGS))\n\n## Compare benchmarks against a previous run\n.PHONY: benchmarks-diff\nbenchmarks-diff: $(BENCH_CSV)\n\t$(strip ./scripts/summary.py $^ \\\n\t\t-bsuite \\\n\t\t-freaded=bench_readed \\\n\t\t-fproged=bench_proged \\\n\t\t-ferased=bench_erased \\\n\t\t$(SUMMARYFLAGS) -d $(BUILDDIR)/lfs.bench.csv)\n\n\n\n# rules\n-include $(DEP)\n-include $(TEST_DEP)\n.SUFFIXES:\n.SECONDARY:\n\n$(BUILDDIR)/lfs: $(OBJ)\n\t$(CC) $(CFLAGS) $^ $(LFLAGS) -o $@\n\n$(BUILDDIR)/liblfs.a: $(OBJ)\n\t$(AR) rcs $@ $^\n\n$(BUILDDIR)/lfs.code.csv: $(OBJ)\n\t./scripts/code.py $^ -q $(CODEFLAGS) -o $@\n\n$(BUILDDIR)/lfs.data.csv: $(OBJ)\n\t./scripts/data.py $^ -q $(DATAFLAGS) -o $@\n\n$(BUILDDIR)/lfs.stack.csv: $(CI)\n\t./scripts/stack.py $^ -q $(STACKFLAGS) -o $@\n\n$(BUILDDIR)/lfs.structs.csv: $(OBJ)\n\t./scripts/structs.py $^ -q $(STRUCTSFLAGS) -o $@\n\n$(BUILDDIR)/lfs.cov.csv: $(GCDA)\n\t$(strip ./scripts/cov.py $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t-q $(COVFLAGS) -o $@)\n\n$(BUILDDIR)/lfs.perf.csv: $(BENCH_PERF)\n\t$(strip ./scripts/perf.py $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t-q $(PERFFLAGS) -o $@)\n\n$(BUILDDIR)/lfs.perfbd.csv: $(BENCH_TRACE)\n\t$(strip ./scripts/perfbd.py $(BENCH_RUNNER) $^ \\\n\t\t$(patsubst %,-F%,$(SRC)) \\\n\t\t-q $(PERFBDFLAGS) -o $@)\n\n$(BUILDDIR)/lfs.test.csv: $(TEST_CSV)\n\tcp $^ $@\n\n$(BUILDDIR)/lfs.bench.csv: $(BENCH_CSV)\n\tcp $^ $@\n\n$(BUILDDIR)/runners/test_runner: $(TEST_OBJ)\n\t$(CC) $(CFLAGS) $^ $(LFLAGS) -o $@\n\n$(BUILDDIR)/runners/bench_runner: $(BENCH_OBJ)\n\t$(CC) $(CFLAGS) $^ $(LFLAGS) -o $@\n\n# our main build rule generates .o, .d, and .ci files, the latter\n# used for stack analysis\n$(BUILDDIR)/%.o $(BUILDDIR)/%.ci: %.c\n\t$(CC) -c -MMD $(CFLAGS) $< -o $(BUILDDIR)/$*.o\n\n$(BUILDDIR)/%.o $(BUILDDIR)/%.ci: $(BUILDDIR)/%.c\n\t$(CC) -c -MMD $(CFLAGS) $< -o $(BUILDDIR)/$*.o\n\n$(BUILDDIR)/%.s: %.c\n\t$(CC) -S $(CFLAGS) $< -o $@\n\n$(BUILDDIR)/%.c: %.a.c\n\t./scripts/prettyasserts.py -p LFS_ASSERT $< -o $@\n\n$(BUILDDIR)/%.c: $(BUILDDIR)/%.a.c\n\t./scripts/prettyasserts.py -p LFS_ASSERT $< -o $@\n\n$(BUILDDIR)/%.t.a.c: %.toml\n\t./scripts/test.py -c $< $(TESTCFLAGS) -o $@\n\n$(BUILDDIR)/%.t.a.c: %.c $(TESTS)\n\t./scripts/test.py -c $(TESTS) -s $< $(TESTCFLAGS) -o $@\n\n$(BUILDDIR)/%.b.a.c: %.toml\n\t./scripts/bench.py -c $< $(BENCHCFLAGS) -o $@\n\n$(BUILDDIR)/%.b.a.c: %.c $(BENCHES)\n\t./scripts/bench.py -c $(BENCHES) -s $< $(BENCHCFLAGS) -o $@\n\n## Clean everything\n.PHONY: clean\nclean:\n\trm -f $(BUILDDIR)/lfs\n\trm -f $(BUILDDIR)/liblfs.a\n\trm -f $(BUILDDIR)/lfs.code.csv\n\trm -f $(BUILDDIR)/lfs.data.csv\n\trm -f $(BUILDDIR)/lfs.stack.csv\n\trm -f $(BUILDDIR)/lfs.structs.csv\n\trm -f $(BUILDDIR)/lfs.cov.csv\n\trm -f $(BUILDDIR)/lfs.perf.csv\n\trm -f $(BUILDDIR)/lfs.perfbd.csv\n\trm -f $(BUILDDIR)/lfs.test.csv\n\trm -f $(BUILDDIR)/lfs.bench.csv\n\trm -f $(OBJ)\n\trm -f $(DEP)\n\trm -f $(ASM)\n\trm -f $(CI)\n\trm -f $(TEST_RUNNER)\n\trm -f $(TEST_A)\n\trm -f $(TEST_C)\n\trm -f $(TEST_OBJ)\n\trm -f $(TEST_DEP)\n\trm -f $(TEST_CI)\n\trm -f $(TEST_GCNO)\n\trm -f $(TEST_GCDA)\n\trm -f $(TEST_PERF)\n\trm -f $(TEST_TRACE)\n\trm -f $(TEST_CSV)\n\trm -f $(BENCH_RUNNER)\n\trm -f $(BENCH_A)\n\trm -f $(BENCH_C)\n\trm -f $(BENCH_OBJ)\n\trm -f $(BENCH_DEP)\n\trm -f $(BENCH_CI)\n\trm -f $(BENCH_GCNO)\n\trm -f $(BENCH_GCDA)\n\trm -f $(BENCH_PERF)\n\trm -f $(BENCH_TRACE)\n\trm -f $(BENCH_CSV)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.71484375,
          "content": "## littlefs\n\nA little fail-safe filesystem designed for microcontrollers.\n\n```\n   | | |     .---._____\n  .-----.   |          |\n--|o    |---| littlefs |\n--|     |---|          |\n  '-----'   '----------'\n   | | |\n```\n\n**Power-loss resilience** - littlefs is designed to handle random power\nfailures. All file operations have strong copy-on-write guarantees and if\npower is lost the filesystem will fall back to the last known good state.\n\n**Dynamic wear leveling** - littlefs is designed with flash in mind, and\nprovides wear leveling over dynamic blocks. Additionally, littlefs can\ndetect bad blocks and work around them.\n\n**Bounded RAM/ROM** - littlefs is designed to work with a small amount of\nmemory. RAM usage is strictly bounded, which means RAM consumption does not\nchange as the filesystem grows. The filesystem contains no unbounded\nrecursion and dynamic memory is limited to configurable buffers that can be\nprovided statically.\n\n## Example\n\nHere's a simple example that updates a file named `boot_count` every time\nmain runs. The program can be interrupted at any time without losing track\nof how many times it has been booted and without corrupting the filesystem:\n\n``` c\n#include \"lfs.h\"\n\n// variables used by the filesystem\nlfs_t lfs;\nlfs_file_t file;\n\n// configuration of the filesystem is provided by this struct\nconst struct lfs_config cfg = {\n    // block device operations\n    .read  = user_provided_block_device_read,\n    .prog  = user_provided_block_device_prog,\n    .erase = user_provided_block_device_erase,\n    .sync  = user_provided_block_device_sync,\n\n    // block device configuration\n    .read_size = 16,\n    .prog_size = 16,\n    .block_size = 4096,\n    .block_count = 128,\n    .cache_size = 16,\n    .lookahead_size = 16,\n    .block_cycles = 500,\n};\n\n// entry point\nint main(void) {\n    // mount the filesystem\n    int err = lfs_mount(&lfs, &cfg);\n\n    // reformat if we can't mount the filesystem\n    // this should only happen on the first boot\n    if (err) {\n        lfs_format(&lfs, &cfg);\n        lfs_mount(&lfs, &cfg);\n    }\n\n    // read current count\n    uint32_t boot_count = 0;\n    lfs_file_open(&lfs, &file, \"boot_count\", LFS_O_RDWR | LFS_O_CREAT);\n    lfs_file_read(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // update boot count\n    boot_count += 1;\n    lfs_file_rewind(&lfs, &file);\n    lfs_file_write(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // remember the storage is not updated until the file is closed successfully\n    lfs_file_close(&lfs, &file);\n\n    // release any resources we were using\n    lfs_unmount(&lfs);\n\n    // print the boot count\n    printf(\"boot_count: %d\\n\", boot_count);\n}\n```\n\n## Usage\n\nDetailed documentation (or at least as much detail as is currently available)\ncan be found in the comments in [lfs.h](lfs.h).\n\nlittlefs takes in a configuration structure that defines how the filesystem\noperates. The configuration struct provides the filesystem with the block\ndevice operations and dimensions, tweakable parameters that tradeoff memory\nusage for performance, and optional static buffers if the user wants to avoid\ndynamic memory.\n\nThe state of the littlefs is stored in the `lfs_t` type which is left up\nto the user to allocate, allowing multiple filesystems to be in use\nsimultaneously. With the `lfs_t` and configuration struct, a user can\nformat a block device or mount the filesystem.\n\nOnce mounted, the littlefs provides a full set of POSIX-like file and\ndirectory functions, with the deviation that the allocation of filesystem\nstructures must be provided by the user.\n\nAll POSIX operations, such as remove and rename, are atomic, even in event\nof power-loss. Additionally, file updates are not actually committed to\nthe filesystem until sync or close is called on the file.\n\n## Other notes\n\nLittlefs is written in C, and specifically should compile with any compiler\nthat conforms to the `C99` standard.\n\nAll littlefs calls have the potential to return a negative error code. The\nerrors can be either one of those found in the `enum lfs_error` in\n[lfs.h](lfs.h), or an error returned by the user's block device operations.\n\nIn the configuration struct, the `prog` and `erase` function provided by the\nuser may return a `LFS_ERR_CORRUPT` error if the implementation already can\ndetect corrupt blocks. However, the wear leveling does not depend on the return\ncode of these functions, instead all data is read back and checked for\nintegrity.\n\nIf your storage caches writes, make sure that the provided `sync` function\nflushes all the data to memory and ensures that the next read fetches the data\nfrom memory, otherwise data integrity can not be guaranteed. If the `write`\nfunction does not perform caching, and therefore each `read` or `write` call\nhits the memory, the `sync` function can simply return 0.\n\n## Design\n\nAt a high level, littlefs is a block based filesystem that uses small logs to\nstore metadata and larger copy-on-write (COW) structures to store file data.\n\nIn littlefs, these ingredients form a sort of two-layered cake, with the small\nlogs (called metadata pairs) providing fast updates to metadata anywhere on\nstorage, while the COW structures store file data compactly and without any\nwear amplification cost.\n\nBoth of these data structures are built out of blocks, which are fed by a\ncommon block allocator. By limiting the number of erases allowed on a block\nper allocation, the allocator provides dynamic wear leveling over the entire\nfilesystem.\n\n```\n                    root\n                   .--------.--------.\n                   | A'| B'|         |\n                   |   |   |->       |\n                   |   |   |         |\n                   '--------'--------'\n                .----'   '--------------.\n       A       v                 B       v\n      .--------.--------.       .--------.--------.\n      | C'| D'|         |       | E'|new|         |\n      |   |   |->       |       |   | E'|->       |\n      |   |   |         |       |   |   |         |\n      '--------'--------'       '--------'--------'\n      .-'   '--.                  |   '------------------.\n     v          v              .-'                        v\n.--------.  .--------.        v                       .--------.\n|   C    |  |   D    |   .--------.       write       | new E  |\n|        |  |        |   |   E    |        ==>        |        |\n|        |  |        |   |        |                   |        |\n'--------'  '--------'   |        |                   '--------'\n                         '--------'                   .-'    |\n                         .-'    '-.    .-------------|------'\n                        v          v  v              v\n                   .--------.  .--------.       .--------.\n                   |   F    |  |   G    |       | new F  |\n                   |        |  |        |       |        |\n                   |        |  |        |       |        |\n                   '--------'  '--------'       '--------'\n```\n\nMore details on how littlefs works can be found in [DESIGN.md](DESIGN.md) and\n[SPEC.md](SPEC.md).\n\n- [DESIGN.md](DESIGN.md) - A fully detailed dive into how littlefs works.\n  I would suggest reading it as the tradeoffs at work are quite interesting.\n\n- [SPEC.md](SPEC.md) - The on-disk specification of littlefs with all the\n  nitty-gritty details. May be useful for tooling development.\n\n## Testing\n\nThe littlefs comes with a test suite designed to run on a PC using the\n[emulated block device](bd/lfs_testbd.h) found in the `bd` directory.\nThe tests assume a Linux environment and can be started with make:\n\n``` bash\nmake test\n```\n\n## License\n\nThe littlefs is provided under the [BSD-3-Clause] license. See\n[LICENSE.md](LICENSE.md) for more information. Contributions to this project\nare accepted under the same license.\n\nIndividual files contain the following tag instead of the full license text.\n\n    SPDX-License-Identifier:    BSD-3-Clause\n\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are here available: http://spdx.org/licenses/\n\n## Related projects\n\n- [littlefs-fuse] - A [FUSE] wrapper for littlefs. The project allows you to\n  mount littlefs directly on a Linux machine. Can be useful for debugging\n  littlefs if you have an SD card handy.\n\n- [littlefs-js] - A javascript wrapper for littlefs. I'm not sure why you would\n  want this, but it is handy for demos.  You can see it in action\n  [here][littlefs-js-demo].\n  \n- [littlefs-python] - A Python wrapper for littlefs. The project allows you\n  to create images of the filesystem on your PC. Check if littlefs will fit\n  your needs, create images for a later download to the target memory or\n  inspect the content of a binary image of the target memory.\n  \n- [littlefs2-rust] - A Rust wrapper for littlefs. This project allows you\n  to use littlefs in a Rust-friendly API, reaping the benefits of Rust's memory\n  safety and other guarantees.\n\n- [nim-littlefs] - A Nim wrapper and API for littlefs. Includes a fuse\n  implementation based on [littlefs-fuse]\n\n- [chamelon] - A pure-OCaml implementation of (most of) littlefs, designed for\n  use with the MirageOS library operating system project. It is interoperable\n  with the reference implementation, with some caveats.\n\n- [littlefs-disk-img-viewer] - A memory-efficient web application for viewing\n  littlefs disk images in your web browser.\n\n- [mklfs] - A command line tool for creating littlefs images. Used in the Lua\n  RTOS ecosystem.\n\n- [mklittlefs] - A command line tool for creating littlefs images. Used in the\n  ESP8266 and RP2040 ecosystem.\n\n- [pico-littlefs-usb] - An interface for littlefs that emulates a FAT12\n  filesystem over USB. Allows mounting littlefs on a host PC without additional\n  drivers.\n\n- [ramcrc32bd] - An example block device using littlefs's 32-bit CRC for\n  error-correction.\n\n- [ramrsbd] - An example block device using Reed-Solomon codes for\n  error-correction.\n\n- [Mbed OS] - The easiest way to get started with littlefs is to jump into Mbed\n  which already has block device drivers for most forms of embedded storage.\n  littlefs is available in Mbed OS as the [LittleFileSystem] class.\n\n- [SPIFFS] - Another excellent embedded filesystem for NOR flash. As a more\n  traditional logging filesystem with full static wear-leveling, SPIFFS will\n  likely outperform littlefs on small memories such as the internal flash on\n  microcontrollers.\n\n- [Dhara] - An interesting NAND flash translation layer designed for small\n  MCUs. It offers static wear-leveling and power-resilience with only a fixed\n  _O(|address|)_ pointer structure stored on each block and in RAM.\n\n- [ChaN's FatFs] - A lightweight reimplementation of the infamous FAT filesystem\n  for microcontroller-scale devices. Due to limitations of FAT it can't provide\n  power-loss resilience, but it does allow easy interop with PCs.\n\n[BSD-3-Clause]: https://spdx.org/licenses/BSD-3-Clause.html\n[littlefs-fuse]: https://github.com/geky/littlefs-fuse\n[FUSE]: https://github.com/libfuse/libfuse\n[littlefs-js]: https://github.com/geky/littlefs-js\n[littlefs-js-demo]:http://littlefs.geky.net/demo.html\n[littlefs-python]: https://pypi.org/project/littlefs-python/\n[littlefs2-rust]: https://crates.io/crates/littlefs2\n[nim-littlefs]: https://github.com/Graveflo/nim-littlefs\n[chamelon]: https://github.com/yomimono/chamelon\n[littlefs-disk-img-viewer]: https://github.com/tniessen/littlefs-disk-img-viewer\n[mklfs]: https://github.com/whitecatboard/Lua-RTOS-ESP32/tree/master/components/mklfs/src\n[mklittlefs]: https://github.com/earlephilhower/mklittlefs\n[pico-littlefs-usb]: https://github.com/oyama/pico-littlefs-usb\n[ramcrc32bd]: https://github.com/geky/ramcrc32bd\n[ramrsbd]: https://github.com/geky/ramrsbd\n[Mbed OS]: https://github.com/armmbed/mbed-os\n[LittleFileSystem]: https://os.mbed.com/docs/mbed-os/latest/apis/littlefilesystem.html\n[SPIFFS]: https://github.com/pellepl/spiffs\n[Dhara]: https://github.com/dlbeer/dhara\n[ChaN's FatFs]: http://elm-chan.org/fsw/ff/00index_e.html\n"
        },
        {
          "name": "SPEC.md",
          "type": "blob",
          "size": 32.908203125,
          "content": "## littlefs technical specification\n\nThis is the technical specification of the little filesystem with on-disk\nversion lfs2.1. This document covers the technical details of how the littlefs\nis stored on disk for introspection and tooling. This document assumes you are\nfamiliar with the design of the littlefs, for more info on how littlefs works\ncheck out [DESIGN.md](DESIGN.md).\n\n```\n   | | |     .---._____\n  .-----.   |          |\n--|o    |---| littlefs |\n--|     |---|          |\n  '-----'   '----------'\n   | | |\n```\n\n## Some quick notes\n\n- littlefs is a block-based filesystem. The disk is divided into an array of\n  evenly sized blocks that are used as the logical unit of storage.\n\n- Block pointers are stored in 32 bits, with the special value `0xffffffff`\n  representing a null block address.\n\n- In addition to the logical block size (which usually matches the erase\n  block size), littlefs also uses a program block size and read block size.\n  These determine the alignment of block device operations, but don't need\n  to be consistent for portability.\n\n- By default, all values in littlefs are stored in little-endian byte order.\n\n## Directories / Metadata pairs\n\nMetadata pairs form the backbone of littlefs and provide a system for\ndistributed atomic updates. Even the superblock is stored in a metadata pair.\n\nAs their name suggests, a metadata pair is stored in two blocks, with one block\nproviding a backup during erase cycles in case power is lost. These two blocks\nare not necessarily sequential and may be anywhere on disk, so a \"pointer\" to a\nmetadata pair is stored as two block pointers.\n\nOn top of this, each metadata block behaves as an appendable log, containing a\nvariable number of commits. Commits can be appended to the metadata log in\norder to update the metadata without requiring an erase cycles. Note that\nsuccessive commits may supersede the metadata in previous commits. Only the\nmost recent metadata should be considered valid.\n\nThe high-level layout of a metadata block is fairly simple:\n\n```\n  .---------------------------------------.\n.-|  revision count   |      entries      |  \\\n| |-------------------+                   |  |\n| |                                       |  |\n| |                                       |  +-- 1st commit\n| |                                       |  |\n| |                   +-------------------|  |\n| |                   |        CRC        |  /\n| |-------------------+-------------------|\n| |                entries                |  \\\n| |                                       |  |\n| |                                       |  +-- 2nd commit\n| |    +-------------------+--------------|  |\n| |    |        CRC        |    padding   |  /\n| |----+-------------------+--------------|\n| |                entries                |  \\\n| |                                       |  |\n| |                                       |  +-- 3rd commit\n| |         +-------------------+---------|  |\n| |         |        CRC        |         |  /\n| |---------+-------------------+         |\n| |           unwritten storage           |  more commits\n| |                                       |       |\n| |                                       |       v\n| |                                       |\n| |                                       |\n| '---------------------------------------'\n'---------------------------------------'\n```\n\nEach metadata block contains a 32-bit revision count followed by a number of\ncommits. Each commit contains a variable number of metadata entries followed\nby a 32-bit CRC.\n\nNote also that entries aren't necessarily word-aligned. This allows us to\nstore metadata more compactly, however we can only write to addresses that are\naligned to our program block size. This means each commit may have padding for\nalignment.\n\nMetadata block fields:\n\n1. **Revision count (32-bits)** - Incremented every erase cycle. If both blocks\n   contain valid commits, only the block with the most recent revision count\n   should be used. Sequence comparison must be used to avoid issues with\n   integer overflow.\n\n2. **CRC (32-bits)** - Detects corruption from power-loss or other write\n   issues.  Uses a CRC-32 with a polynomial of `0x04c11db7` initialized\n   with `0xffffffff`.\n\nEntries themselves are stored as a 32-bit tag followed by a variable length\nblob of data. But exactly how these tags are stored is a little bit tricky.\n\nMetadata blocks support both forward and backward iteration. In order to do\nthis without duplicating the space for each tag, neighboring entries have their\ntags XORed together, starting with `0xffffffff`.\n\n```\n Forward iteration                        Backward iteration\n\n.-------------------.  0xffffffff        .-------------------.\n|  revision count   |      |             |  revision count   |\n|-------------------|      v             |-------------------|\n|      tag ~A       |---> xor -> tag A   |      tag ~A       |---> xor -> 0xffffffff\n|-------------------|      |             |-------------------|      ^\n|       data A      |      |             |       data A      |      |\n|                   |      |             |                   |      |\n|                   |      |             |                   |      |\n|-------------------|      v             |-------------------|      |\n|      tag AxB      |---> xor -> tag B   |      tag AxB      |---> xor -> tag A\n|-------------------|      |             |-------------------|      ^\n|       data B      |      |             |       data B      |      |\n|                   |      |             |                   |      |\n|                   |      |             |                   |      |\n|-------------------|      v             |-------------------|      |\n|      tag BxC      |---> xor -> tag C   |      tag BxC      |---> xor -> tag B\n|-------------------|                    |-------------------|      ^\n|       data C      |                    |       data C      |      |\n|                   |                    |                   |    tag C\n|                   |                    |                   |\n|                   |                    |                   |\n'-------------------'                    '-------------------'\n```\n\nHere's a more complete example of metadata block containing 4 entries:\n\n```\n  .---------------------------------------.\n.-|  revision count   |      tag ~A       |        \\\n| |-------------------+-------------------|        |\n| |                 data A                |        |\n| |                                       |        |\n| |-------------------+-------------------|        |\n| |      tag AxB      |       data B      | <--.   |\n| |-------------------+                   |    |   |\n| |                                       |    |   +-- 1st commit\n| |         +-------------------+---------|    |   |\n| |         |      tag BxC      |         | <-.|   |\n| |---------+-------------------+         |   ||   |\n| |                 data C                |   ||   |\n| |                                       |   ||   |\n| |-------------------+-------------------|   ||   |\n| |     tag CxCRC     |        CRC        |   ||   /\n| |-------------------+-------------------|   ||\n| |     tag CRCxA'    |      data A'      |   ||   \\\n| |-------------------+                   |   ||   |\n| |                                       |   ||   |\n| |              +-------------------+----|   ||   +-- 2nd commit\n| |              |     tag CRCxA'    |    |   ||   |\n| |--------------+-------------------+----|   ||   |\n| | CRC          |        padding         |   ||   /\n| |--------------+----+-------------------|   ||\n| |     tag CRCxA''   |      data A''     | <---.  \\\n| |-------------------+                   |   |||  |\n| |                                       |   |||  |\n| |         +-------------------+---------|   |||  |\n| |         |     tag A''xD     |         | < |||  |\n| |---------+-------------------+         |  ||||  +-- 3rd commit\n| |                data D                 |  ||||  |\n| |                             +---------|  ||||  |\n| |                             |   tag Dx|  ||||  |\n| |---------+-------------------+---------|  ||||  |\n| |CRC      |        CRC        |         |  ||||  /\n| |---------+-------------------+         |  ||||\n| |           unwritten storage           |  ||||  more commits\n| |                                       |  ||||       |\n| |                                       |  ||||       v\n| |                                       |  ||||\n| |                                       |  ||||\n| '---------------------------------------'  ||||\n'---------------------------------------'    |||'- most recent A\n                                             ||'-- most recent B\n                                             |'--- most recent C\n                                             '---- most recent D\n```\n\nTwo things to note before we get into the details around tag encoding:\n\n1. Each tag contains a valid bit used to indicate if the tag and containing\n   commit is valid. After XORing, this bit should always be zero.\n\n   At the end of each commit, the valid bit of the previous tag is XORed\n   with the lowest bit in the type field of the CRC tag. This allows\n   the CRC tag to force the next commit to fail the valid bit test if it\n   has not yet been written to.\n\n2. The valid bit alone is not enough info to know if the next commit has been\n   erased. We don't know the order bits will be programmed in a program block,\n   so it's possible that the next commit had an attempted program that left the\n   valid bit unchanged.\n\n   To ensure we only ever program erased bytes, each commit can contain an\n   optional forward-CRC (FCRC). An FCRC contains a checksum of some amount of\n   bytes in the next commit at the time it was erased.\n\n   ```\n   .-------------------. \\      \\\n   |  revision count   | |      |\n   |-------------------| |      |\n   |     metadata      | |      |\n   |                   | +---.  +-- current commit\n   |                   | |   |  |\n   |-------------------| |   |  |\n   |       FCRC       ---|-. |  |\n   |-------------------| / | |  |\n   |        CRC       -----|-'  /\n   |-------------------|   |\n   |      padding      |   |        padding (does't need CRC)\n   |                   |   |\n   |-------------------| \\ |    \\\n   |      erased?      | +-'    |\n   |         |         | |      +-- next commit\n   |         v         | /      |\n   |                   |        /\n   |                   |\n   '-------------------'\n   ```\n\n   If the FCRC is missing or the checksum does not match, we must assume a\n   commit was attempted but failed due to power-loss.\n\n   Note that end-of-block commits do not need an FCRC.\n\n## Metadata tags\n\nSo in littlefs, 32-bit tags describe every type of metadata. And this means\n_every_ type of metadata, including file entries, directory fields, and\nglobal state. Even the CRCs used to mark the end of commits get their own tag.\n\nBecause of this, the tag format contains some densely packed information. Note\nthat there are multiple levels of types which break down into more info:\n\n```\n[----            32             ----]\n[1|--  11   --|--  10  --|--  10  --]\n ^.     ^     .     ^          ^- length\n |.     |     .     '------------ id\n |.     '-----.------------------ type (type3)\n '.-----------.------------------ valid bit\n  [-3-|-- 8 --]\n    ^     ^- chunk\n    '------- type (type1)\n```\n\n\nBefore we go further, there's one important thing to note. These tags are\n**not** stored in little-endian. Tags stored in commits are actually stored\nin big-endian (and is the only thing in littlefs stored in big-endian). This\nlittle bit of craziness comes from the fact that the valid bit must be the\nfirst bit in a commit, and when converted to little-endian, the valid bit finds\nitself in byte 4. We could restructure the tag to store the valid bit lower,\nbut, because none of the fields are byte-aligned, this would be more\ncomplicated than just storing the tag in big-endian.\n\nAnother thing to note is that both the tags `0x00000000` and `0xffffffff` are\ninvalid and can be used for null values.\n\nMetadata tag fields:\n\n1. **Valid bit (1-bit)** - Indicates if the tag is valid.\n\n2. **Type3 (11-bits)** - Type of the tag. This field is broken down further\n   into a 3-bit abstract type and an 8-bit chunk field. Note that the value\n   `0x000` is invalid and not assigned a type.\n\n    1. **Type1 (3-bits)** - Abstract type of the tag. Groups the tags into\n       8 categories that facilitate bitmasked lookups.\n\n    2. **Chunk (8-bits)** - Chunk field used for various purposes by the different\n       abstract types.  type1+chunk+id form a unique identifier for each tag in the\n       metadata block.\n\n3. **Id (10-bits)** - File id associated with the tag. Each file in a metadata\n   block gets a unique id which is used to associate tags with that file. The\n   special value `0x3ff` is used for any tags that are not associated with a\n   file, such as directory and global metadata.\n\n4. **Length (10-bits)** - Length of the data in bytes. The special value\n   `0x3ff` indicates that this tag has been deleted.\n\n## Metadata types\n\nWhat follows is an exhaustive list of metadata in littlefs.\n\n---\n#### `0x401` LFS_TYPE_CREATE\n\nCreates a new file with this id. Note that files in a metadata block\ndon't necessarily need a create tag. All a create does is move over any\nfiles using this id. In this sense a create is similar to insertion into\nan imaginary array of files.\n\nThe create and delete tags allow littlefs to keep files in a directory\nordered alphabetically by filename.\n\n---\n#### `0x4ff` LFS_TYPE_DELETE\n\nDeletes the file with this id. An inverse to create, this tag moves over\nany files neighboring this id similar to a deletion from an imaginary\narray of files.\n\n---\n#### `0x0xx` LFS_TYPE_NAME\n\nAssociates the id with a file name and file type.\n\nThe data contains the file name stored as an ASCII string (may be expanded to\nUTF8 in the future).\n\nThe chunk field in this tag indicates an 8-bit file type which can be one of\nthe following.\n\nCurrently, the name tag must precede any other tags associated with the id and\ncan not be reassigned without deleting the file.\n\nLayout of the name tag:\n\n```\n        tag                          data\n[--      32      --][---        variable length        ---]\n[1| 3| 8 | 10 | 10 ][---          (size * 8)           ---]\n ^  ^  ^    ^    ^- size                   ^- file name\n |  |  |    '------ id\n |  |  '----------- file type\n |  '-------------- type1 (0x0)\n '----------------- valid bit\n```\n\nName fields:\n\n1. **file type (8-bits)** - Type of the file.\n\n2. **file name** - File name stored as an ASCII string.\n\n---\n#### `0x001` LFS_TYPE_REG\n\nInitializes the id + name as a regular file.\n\nHow each file is stored depends on its struct tag, which is described below.\n\n---\n#### `0x002` LFS_TYPE_DIR\n\nInitializes the id + name as a directory.\n\nDirectories in littlefs are stored on disk as a linked-list of metadata pairs,\neach pair containing any number of files in alphabetical order. A pointer to\nthe directory is stored in the struct tag, which is described below.\n\n---\n#### `0x0ff` LFS_TYPE_SUPERBLOCK\n\nInitializes the id as a superblock entry.\n\nThe superblock entry is a special entry used to store format-time configuration\nand identify the filesystem.\n\nThe name is a bit of a misnomer. While the superblock entry serves the same\npurpose as a superblock found in other filesystems, in littlefs the superblock\ndoes not get a dedicated block. Instead, the superblock entry is duplicated\nacross a linked-list of metadata pairs rooted on the blocks 0 and 1. The last\nmetadata pair doubles as the root directory of the filesystem.\n\n```\n .--------.  .--------.  .--------.  .--------.  .--------.\n.| super  |->| super  |->| super  |->| super  |->| file B |\n|| block  | || block  | || block  | || block  | || file C |\n||        | ||        | ||        | || file A | || file D |\n|'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '--------'  '--------'  '--------'  '--------'\n\n\\----------------+----------------/ \\----------+----------/\n          superblock pairs               root directory\n```\n\nThe filesystem starts with only the root directory. The superblock metadata\npairs grow every time the root pair is compacted in order to prolong the\nlife of the device exponentially.\n\nThe contents of the superblock entry are stored in a name tag with the\nsuperblock type and an inline-struct tag. The name tag contains the magic\nstring \"littlefs\", while the inline-struct tag contains version and\nconfiguration information.\n\nLayout of the superblock name tag and inline-struct tag:\n\n```\n        tag                          data\n[--      32      --][--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][---              64               ---]\n ^    ^     ^    ^- size (8)           ^- magic string (\"littlefs\")\n |    |     '------ id (0)\n |    '------------ type (0x0ff)\n '----------------- valid bit\n\n        tag                          data\n[--      32      --][--      32      --|--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][--      32      --|--      32      --|--      32      --]\n ^    ^     ^    ^            ^- version         ^- block size      ^- block count\n |    |     |    |  [--      32      --|--      32      --|--      32      --]\n |    |     |    |  [--      32      --|--      32      --|--      32      --]\n |    |     |    |            ^- name max        ^- file max        ^- attr max\n |    |     |    '- size (24)\n |    |     '------ id (0)\n |    '------------ type (0x201)\n '----------------- valid bit\n```\n\nSuperblock fields:\n\n1. **Magic string (8-bytes)** - Magic string indicating the presence of\n   littlefs on the device. Must be the string \"littlefs\".\n\n2. **Version (32-bits)** - The version of littlefs at format time. The version\n   is encoded in a 32-bit value with the upper 16-bits containing the major\n   version, and the lower 16-bits containing the minor version.\n\n   This specification describes version 2.0 (`0x00020000`).\n\n3. **Block size (32-bits)** - Size of the logical block size used by the\n   filesystem in bytes.\n\n4. **Block count (32-bits)** - Number of blocks in the filesystem.\n\n5. **Name max (32-bits)** - Maximum size of file names in bytes.\n\n6. **File max (32-bits)** - Maximum size of files in bytes.\n\n7. **Attr max (32-bits)** - Maximum size of file attributes in bytes.\n\nThe superblock must always be the first entry (id 0) in the metadata pair, and\nthe name tag must always be the first tag in the metadata pair. This makes it\nso that the magic string \"littlefs\" will always reside at offset=8 in a valid\nlittlefs superblock.\n\n---\n#### `0x2xx` LFS_TYPE_STRUCT\n\nAssociates the id with an on-disk data structure.\n\nThe exact layout of the data depends on the data structure type stored in the\nchunk field and can be one of the following.\n\nAny type of struct supersedes all other structs associated with the id. For\nexample, appending a ctz-struct replaces an inline-struct on the same file.\n\n---\n#### `0x200` LFS_TYPE_DIRSTRUCT\n\nGives the id a directory data structure.\n\nDirectories in littlefs are stored on disk as a linked-list of metadata pairs,\neach pair containing any number of files in alphabetical order.\n\n```\n     |\n     v\n .--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n.| file A |->| file D |->| file G |->| file I |->| file J |->| file M |\n|| file B | || file E | || file H | ||        | || file K | || file N |\n|| file C | || file F | ||        | ||        | || file L | ||        |\n|'--------' |'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n```\n\nThe dir-struct tag contains only the pointer to the first metadata-pair in the\ndirectory. The directory size is not known without traversing the directory.\n\nThe pointer to the next metadata-pair in the directory is stored in a tail tag,\nwhich is described below.\n\nLayout of the dir-struct tag:\n\n```\n        tag                          data\n[--      32      --][--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][---              64               ---]\n ^    ^     ^    ^- size (8)           ^- metadata pair\n |    |     '------ id\n |    '------------ type (0x200)\n '----------------- valid bit\n```\n\nDir-struct fields:\n\n1. **Metadata pair (8-bytes)** - Pointer to the first metadata-pair\n   in the directory.\n\n---\n#### `0x201` LFS_TYPE_INLINESTRUCT\n\nGives the id an inline data structure.\n\nInline structs store small files that can fit in the metadata pair. In this\ncase, the file data is stored directly in the tag's data area.\n\nLayout of the inline-struct tag:\n\n```\n        tag                          data\n[--      32      --][---        variable length        ---]\n[1|- 11 -| 10 | 10 ][---           (size * 8)          ---]\n ^    ^     ^    ^- size                    ^- inline data\n |    |     '------ id\n |    '------------ type (0x201)\n '----------------- valid bit\n```\n\nInline-struct fields:\n\n1. **Inline data** - File data stored directly in the metadata-pair.\n\n---\n#### `0x202` LFS_TYPE_CTZSTRUCT\n\nGives the id a CTZ skip-list data structure.\n\nCTZ skip-lists store files that can not fit in the metadata pair. These files\nare stored in a skip-list in reverse, with a pointer to the head of the\nskip-list. Note that the head of the skip-list and the file size is enough\ninformation to read the file.\n\nHow exactly CTZ skip-lists work is a bit complicated. A full explanation can be\nfound in the [DESIGN.md](DESIGN.md#ctz-skip-lists).\n\nA quick summary: For every _n_&zwj;th block where _n_ is divisible by\n2&zwj;_&#739;_, that block contains a pointer to block _n_-2&zwj;_&#739;_.\nThese pointers are stored in increasing order of _x_ in each block of the file\nbefore the actual data.\n\n```\n                                                               |\n                                                               v\n.--------.  .--------.  .--------.  .--------.  .--------.  .--------.\n| A      |<-| D      |<-| G      |<-| J      |<-| M      |<-| P      |\n| B      |<-| E      |--| H      |<-| K      |--| N      |  | Q      |\n| C      |<-| F      |--| I      |--| L      |--| O      |  |        |\n'--------'  '--------'  '--------'  '--------'  '--------'  '--------'\n  block 0     block 1     block 2     block 3     block 4     block 5\n              1 skip      2 skips     1 skip      3 skips     1 skip\n```\n\nNote that the maximum number of pointers in a block is bounded by the maximum\nfile size divided by the block size. With 32 bits for file size, this results\nin a minimum block size of 104 bytes.\n\nLayout of the CTZ-struct tag:\n\n```\n        tag                          data\n[--      32      --][--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][--      32      --|--      32      --]\n ^    ^     ^    ^            ^                  ^- file size\n |    |     |    |            '-------------------- file head\n |    |     |    '- size (8)\n |    |     '------ id\n |    '------------ type (0x202)\n '----------------- valid bit\n```\n\nCTZ-struct fields:\n\n1. **File head (32-bits)** - Pointer to the block that is the head of the\n   file's CTZ skip-list.\n\n2. **File size (32-bits)** - Size of the file in bytes.\n\n---\n#### `0x3xx` LFS_TYPE_USERATTR\n\nAttaches a user attribute to an id.\n\nlittlefs has a concept of \"user attributes\". These are small user-provided\nattributes that can be used to store things like timestamps, hashes,\npermissions, etc.\n\nEach user attribute is uniquely identified by an 8-bit type which is stored in\nthe chunk field, and the user attribute itself can be found in the tag's data.\n\nThere are currently no standard user attributes and a portable littlefs\nimplementation should work with any user attributes missing.\n\nLayout of the user-attr tag:\n\n```\n        tag                          data\n[--      32      --][---        variable length        ---]\n[1| 3| 8 | 10 | 10 ][---           (size * 8)          ---]\n ^  ^  ^    ^    ^- size                    ^- attr data\n |  |  |    '------ id\n |  |  '----------- attr type\n |  '-------------- type1 (0x3)\n '----------------- valid bit\n```\n\nUser-attr fields:\n\n1. **Attr type (8-bits)** - Type of the user attributes.\n\n2. **Attr data** - The data associated with the user attribute.\n\n---\n#### `0x6xx` LFS_TYPE_TAIL\n\nProvides the tail pointer for the metadata pair itself.\n\nThe metadata pair's tail pointer is used in littlefs for a linked-list\ncontaining all metadata pairs. The chunk field contains the type of the tail,\nwhich indicates if the following metadata pair is a part of the directory\n(hard-tail) or only used to traverse the filesystem (soft-tail).\n\n```\n         .--------.\n        .| dir A  |-.\n        ||softtail| |\n.--------|        |-'\n|       |'--------'\n|       '---|--|-'\n|        .-'    '-------------.\n|       v                      v\n|  .--------.  .--------.  .--------.\n'->| dir B  |->| dir B  |->| dir C  |\n  ||hardtail| ||softtail| ||        |\n  ||        | ||        | ||        |\n  |'--------' |'--------' |'--------'\n  '--------'  '--------'  '--------'\n```\n\nCurrently any type supersedes any other preceding tails in the metadata pair,\nbut this may change if additional metadata pair state is added.\n\nA note about the metadata pair linked-list: Normally, this linked-list contains\nevery metadata pair in the filesystem. However, there are some operations that\ncan cause this linked-list to become out of sync if a power-loss were to occur.\nWhen this happens, littlefs sets the \"sync\" flag in the global state. How\nexactly this flag is stored is described below.\n\nWhen the sync flag is set:\n\n1. The linked-list may contain an orphaned directory that has been removed in\n   the filesystem.\n2. The linked-list may contain a metadata pair with a bad block that has been\n   replaced in the filesystem.\n\nIf the sync flag is set, the threaded linked-list must be checked for these\nerrors before it can be used reliably. Note that the threaded linked-list can\nbe ignored if littlefs is mounted read-only.\n\nLayout of the tail tag:\n\n```\n        tag                          data\n[--      32      --][--      32      --|--      32      --]\n[1| 3| 8 | 10 | 10 ][---              64               ---]\n ^  ^  ^   ^    ^- size (8)            ^- metadata pair\n |  |  |   '------ id\n |  |  '---------- tail type\n |  '------------- type1 (0x6)\n '---------------- valid bit\n```\n\nTail fields:\n\n1. **Tail type (8-bits)** - Type of the tail pointer.\n\n2. **Metadata pair (8-bytes)** - Pointer to the next metadata-pair.\n\n---\n#### `0x600` LFS_TYPE_SOFTTAIL\n\nProvides a tail pointer that points to the next metadata pair in the\nfilesystem.\n\nIn this case, the next metadata pair is not a part of our current directory\nand should only be followed when traversing the entire filesystem.\n\n---\n#### `0x601` LFS_TYPE_HARDTAIL\n\nProvides a tail pointer that points to the next metadata pair in the\ndirectory.\n\nIn this case, the next metadata pair belongs to the current directory. Note\nthat because directories in littlefs are sorted alphabetically, the next\nmetadata pair should only contain filenames greater than any filename in the\ncurrent pair.\n\n---\n#### `0x7xx` LFS_TYPE_GSTATE\n\nProvides delta bits for global state entries.\n\nlittlefs has a concept of \"global state\". This is a small set of state that\ncan be updated by a commit to _any_ metadata pair in the filesystem.\n\nThe way this works is that the global state is stored as a set of deltas\ndistributed across the filesystem such that the global state can be found by\nthe xor-sum of these deltas.\n\n```\n .--------.  .--------.  .--------.  .--------.  .--------.\n.|        |->| gdelta |->|        |->| gdelta |->| gdelta |\n||        | || 0x23   | ||        | || 0xff   | || 0xce   |\n||        | ||        | ||        | ||        | ||        |\n|'--------' |'--------' |'--------' |'--------' |'--------'\n'--------'  '----|---'  '--------'  '----|---'  '----|---'\n                 v                       v           v\n       0x00 --> xor ------------------> xor ------> xor --> gstate = 0x12\n```\n\nNote that storing globals this way is very expensive in terms of storage usage,\nso any global state should be kept very small.\n\nThe size and format of each piece of global state depends on the type, which\nis stored in the chunk field. Currently, the only global state is move state,\nwhich is outlined below.\n\n---\n#### `0x7ff` LFS_TYPE_MOVESTATE\n\nProvides delta bits for the global move state.\n\nThe move state in littlefs is used to store info about operations that could\ncause to filesystem to go out of sync if the power is lost. The operations\nwhere this could occur is moves of files between metadata pairs and any\noperation that changes metadata pairs on the threaded linked-list.\n\nIn the case of moves, the move state contains a tag + metadata pair describing\nthe source of the ongoing move. If this tag is non-zero, that means that power\nwas lost during a move, and the file exists in two different locations. If this\nhappens, the source of the move should be considered deleted, and the move\nshould be completed (the source should be deleted) before any other write\noperations to the filesystem.\n\nIn the case of operations to the threaded linked-list, a single \"sync\" bit is\nused to indicate that a modification is ongoing. If this sync flag is set, the\nthreaded linked-list will need to be checked for errors before it can be used\nreliably. The exact cases to check for are described above in the tail tag.\n\nLayout of the move state:\n\n```\n        tag                                    data\n[--      32      --][--      32      --|--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][1|- 11 -| 10 | 10 |---              64               ---]\n ^    ^     ^    ^   ^    ^     ^    ^- padding (0)       ^- metadata pair\n |    |     |    |   |    |     '------ move id\n |    |     |    |   |    '------------ move type\n |    |     |    |   '----------------- sync bit\n |    |     |    |\n |    |     |    '- size (12)\n |    |     '------ id (0x3ff)\n |    '------------ type (0x7ff)\n '----------------- valid bit\n```\n\nMove state fields:\n\n1. **Sync bit (1-bit)** - Indicates if the metadata pair threaded linked-list\n   is in-sync. If set, the threaded linked-list should be checked for errors.\n\n2. **Move type (11-bits)** - Type of move being performed. Must be either\n   `0x000`, indicating no move, or `0x4ff` indicating the source file should\n   be deleted.\n\n3. **Move id (10-bits)** - The file id being moved.\n\n4. **Metadata pair (8-bytes)** - Pointer to the metadata-pair containing\n   the move.\n\n---\n#### `0x5xx` LFS_TYPE_CRC\n\nLast but not least, the CRC tag marks the end of a commit and provides a\nchecksum for any commits to the metadata block.\n\nThe first 32-bits of the data contain a CRC-32 with a polynomial of\n`0x04c11db7` initialized with `0xffffffff`. This CRC provides a checksum for\nall metadata since the previous CRC tag, including the CRC tag itself. For\nthe first commit, this includes the revision count for the metadata block.\n\nHowever, the size of the data is not limited to 32-bits. The data field may\nlarger to pad the commit to the next program-aligned boundary.\n\nIn addition, the CRC tag's chunk field contains a set of flags which can\nchange the behaviour of commits. Currently the only flag in use is the lowest\nbit, which determines the expected state of the valid bit for any following\ntags. This is used to guarantee that unwritten storage in a metadata block\nwill be detected as invalid.\n\nLayout of the CRC tag:\n\n```\n        tag                                    data\n[--      32      --][--      32      --|---        variable length        ---]\n[1| 3| 8 | 10 | 10 ][--      32      --|---        (size * 8 - 32)        ---]\n ^  ^  ^    ^    ^            ^- crc                             ^- padding\n |  |  |    |    '- size\n |  |  |    '------ id (0x3ff)\n |  |  '----------- valid state\n |  '-------------- type1 (0x5)\n '----------------- valid bit\n```\n\nCRC fields:\n\n1. **Valid state (1-bit)** - Indicates the expected value of the valid bit for\n   any tags in the next commit.\n\n2. **CRC (32-bits)** - CRC-32 with a polynomial of `0x04c11db7` initialized\n   with `0xffffffff`.\n\n3. **Padding** - Padding to the next program-aligned boundary. No guarantees\n   are made about the contents.\n\n---\n#### `0x5ff` LFS_TYPE_FCRC\n\nAdded in lfs2.1, the optional FCRC tag contains a checksum of some amount of\nbytes in the next commit at the time it was erased. This allows us to ensure\nthat we only ever program erased bytes, even if a previous commit failed due\nto power-loss.\n\nWhen programming a commit, the FCRC size must be at least as large as the\nprogram block size. However, the program block is not saved on disk, and can\nchange between mounts, so the FCRC size on disk may be different than the\ncurrent program block size.\n\nIf the FCRC is missing or the checksum does not match, we must assume a\ncommit was attempted but failed due to power-loss.\n\nLayout of the FCRC tag:\n\n```\n        tag                          data\n[--      32      --][--      32      --|--      32      --]\n[1|- 11 -| 10 | 10 ][--      32      --|--      32      --]\n ^    ^     ^    ^            ^- fcrc size       ^- fcrc\n |    |     |    '- size (8)\n |    |     '------ id (0x3ff)\n |    '------------ type (0x5ff)\n '----------------- valid bit\n```\n\nFCRC fields:\n\n1. **FCRC size (32-bits)** - Number of bytes after this commit's CRC tag's\n   padding to include in the FCRC.\n\n2. **FCRC (32-bits)** - CRC of the bytes after this commit's CRC tag's padding\n   when erased. Like the CRC tag, this uses a CRC-32 with a polynomial of\n   `0x04c11db7` initialized with `0xffffffff`.\n\n---\n"
        },
        {
          "name": "bd",
          "type": "tree",
          "content": null
        },
        {
          "name": "benches",
          "type": "tree",
          "content": null
        },
        {
          "name": "lfs.c",
          "type": "blob",
          "size": 192.1416015625,
          "content": "/*\n * The little filesystem\n *\n * Copyright (c) 2022, The littlefs authors.\n * Copyright (c) 2017, Arm Limited. All rights reserved.\n * SPDX-License-Identifier: BSD-3-Clause\n */\n#include \"lfs.h\"\n#include \"lfs_util.h\"\n\n\n// some constants used throughout the code\n#define LFS_BLOCK_NULL ((lfs_block_t)-1)\n#define LFS_BLOCK_INLINE ((lfs_block_t)-2)\n\nenum {\n    LFS_OK_RELOCATED = 1,\n    LFS_OK_DROPPED   = 2,\n    LFS_OK_ORPHANED  = 3,\n};\n\nenum {\n    LFS_CMP_EQ = 0,\n    LFS_CMP_LT = 1,\n    LFS_CMP_GT = 2,\n};\n\n\n/// Caching block device operations ///\n\nstatic inline void lfs_cache_drop(lfs_t *lfs, lfs_cache_t *rcache) {\n    // do not zero, cheaper if cache is readonly or only going to be\n    // written with identical data (during relocates)\n    (void)lfs;\n    rcache->block = LFS_BLOCK_NULL;\n}\n\nstatic inline void lfs_cache_zero(lfs_t *lfs, lfs_cache_t *pcache) {\n    // zero to avoid information leak\n    memset(pcache->buffer, 0xff, lfs->cfg->cache_size);\n    pcache->block = LFS_BLOCK_NULL;\n}\n\nstatic int lfs_bd_read(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    if (off+size > lfs->cfg->block_size\n            || (lfs->block_count && block >= lfs->block_count)) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    while (size > 0) {\n        lfs_size_t diff = size;\n\n        if (pcache && block == pcache->block &&\n                off < pcache->off + pcache->size) {\n            if (off >= pcache->off) {\n                // is already in pcache?\n                diff = lfs_min(diff, pcache->size - (off-pcache->off));\n                memcpy(data, &pcache->buffer[off-pcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // pcache takes priority\n            diff = lfs_min(diff, pcache->off-off);\n        }\n\n        if (block == rcache->block &&\n                off < rcache->off + rcache->size) {\n            if (off >= rcache->off) {\n                // is already in rcache?\n                diff = lfs_min(diff, rcache->size - (off-rcache->off));\n                memcpy(data, &rcache->buffer[off-rcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // rcache takes priority\n            diff = lfs_min(diff, rcache->off-off);\n        }\n\n        if (size >= hint && off % lfs->cfg->read_size == 0 &&\n                size >= lfs->cfg->read_size) {\n            // bypass cache?\n            diff = lfs_aligndown(diff, lfs->cfg->read_size);\n            int err = lfs->cfg->read(lfs->cfg, block, off, data, diff);\n            if (err) {\n                return err;\n            }\n\n            data += diff;\n            off += diff;\n            size -= diff;\n            continue;\n        }\n\n        // load to cache, first condition can no longer fail\n        LFS_ASSERT(!lfs->block_count || block < lfs->block_count);\n        rcache->block = block;\n        rcache->off = lfs_aligndown(off, lfs->cfg->read_size);\n        rcache->size = lfs_min(\n                lfs_min(\n                    lfs_alignup(off+hint, lfs->cfg->read_size),\n                    lfs->cfg->block_size)\n                - rcache->off,\n                lfs->cfg->cache_size);\n        int err = lfs->cfg->read(lfs->cfg, rcache->block,\n                rcache->off, rcache->buffer, rcache->size);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n\nstatic int lfs_bd_cmp(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off,\n        const void *buffer, lfs_size_t size) {\n    const uint8_t *data = buffer;\n    lfs_size_t diff = 0;\n\n    for (lfs_off_t i = 0; i < size; i += diff) {\n        uint8_t dat[8];\n\n        diff = lfs_min(size-i, sizeof(dat));\n        int err = lfs_bd_read(lfs,\n                pcache, rcache, hint-i,\n                block, off+i, &dat, diff);\n        if (err) {\n            return err;\n        }\n\n        int res = memcmp(dat, data + i, diff);\n        if (res) {\n            return res < 0 ? LFS_CMP_LT : LFS_CMP_GT;\n        }\n    }\n\n    return LFS_CMP_EQ;\n}\n\nstatic int lfs_bd_crc(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_block_t block, lfs_off_t off, lfs_size_t size, uint32_t *crc) {\n    lfs_size_t diff = 0;\n\n    for (lfs_off_t i = 0; i < size; i += diff) {\n        uint8_t dat[8];\n        diff = lfs_min(size-i, sizeof(dat));\n        int err = lfs_bd_read(lfs,\n                pcache, rcache, hint-i,\n                block, off+i, &dat, diff);\n        if (err) {\n            return err;\n        }\n\n        *crc = lfs_crc(*crc, &dat, diff);\n    }\n\n    return 0;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_bd_flush(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache, bool validate) {\n    if (pcache->block != LFS_BLOCK_NULL && pcache->block != LFS_BLOCK_INLINE) {\n        LFS_ASSERT(pcache->block < lfs->block_count);\n        lfs_size_t diff = lfs_alignup(pcache->size, lfs->cfg->prog_size);\n        int err = lfs->cfg->prog(lfs->cfg, pcache->block,\n                pcache->off, pcache->buffer, diff);\n        LFS_ASSERT(err <= 0);\n        if (err) {\n            return err;\n        }\n\n        if (validate) {\n            // check data on disk\n            lfs_cache_drop(lfs, rcache);\n            int res = lfs_bd_cmp(lfs,\n                    NULL, rcache, diff,\n                    pcache->block, pcache->off, pcache->buffer, diff);\n            if (res < 0) {\n                return res;\n            }\n\n            if (res != LFS_CMP_EQ) {\n                return LFS_ERR_CORRUPT;\n            }\n        }\n\n        lfs_cache_zero(lfs, pcache);\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_bd_sync(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache, bool validate) {\n    lfs_cache_drop(lfs, rcache);\n\n    int err = lfs_bd_flush(lfs, pcache, rcache, validate);\n    if (err) {\n        return err;\n    }\n\n    err = lfs->cfg->sync(lfs->cfg);\n    LFS_ASSERT(err <= 0);\n    return err;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_bd_prog(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache, bool validate,\n        lfs_block_t block, lfs_off_t off,\n        const void *buffer, lfs_size_t size) {\n    const uint8_t *data = buffer;\n    LFS_ASSERT(block == LFS_BLOCK_INLINE || block < lfs->block_count);\n    LFS_ASSERT(off + size <= lfs->cfg->block_size);\n\n    while (size > 0) {\n        if (block == pcache->block &&\n                off >= pcache->off &&\n                off < pcache->off + lfs->cfg->cache_size) {\n            // already fits in pcache?\n            lfs_size_t diff = lfs_min(size,\n                    lfs->cfg->cache_size - (off-pcache->off));\n            memcpy(&pcache->buffer[off-pcache->off], data, diff);\n\n            data += diff;\n            off += diff;\n            size -= diff;\n\n            pcache->size = lfs_max(pcache->size, off - pcache->off);\n            if (pcache->size == lfs->cfg->cache_size) {\n                // eagerly flush out pcache if we fill up\n                int err = lfs_bd_flush(lfs, pcache, rcache, validate);\n                if (err) {\n                    return err;\n                }\n            }\n\n            continue;\n        }\n\n        // pcache must have been flushed, either by programming and\n        // entire block or manually flushing the pcache\n        LFS_ASSERT(pcache->block == LFS_BLOCK_NULL);\n\n        // prepare pcache, first condition can no longer fail\n        pcache->block = block;\n        pcache->off = lfs_aligndown(off, lfs->cfg->prog_size);\n        pcache->size = 0;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_bd_erase(lfs_t *lfs, lfs_block_t block) {\n    LFS_ASSERT(block < lfs->block_count);\n    int err = lfs->cfg->erase(lfs->cfg, block);\n    LFS_ASSERT(err <= 0);\n    return err;\n}\n#endif\n\n\n/// Small type-level utilities ///\n\n// some operations on paths\nstatic inline lfs_size_t lfs_path_namelen(const char *path) {\n    return strcspn(path, \"/\");\n}\n\nstatic inline bool lfs_path_islast(const char *path) {\n    lfs_size_t namelen = lfs_path_namelen(path);\n    return path[namelen + strspn(path + namelen, \"/\")] == '\\0';\n}\n\nstatic inline bool lfs_path_isdir(const char *path) {\n    return path[lfs_path_namelen(path)] != '\\0';\n}\n\n// operations on block pairs\nstatic inline void lfs_pair_swap(lfs_block_t pair[2]) {\n    lfs_block_t t = pair[0];\n    pair[0] = pair[1];\n    pair[1] = t;\n}\n\nstatic inline bool lfs_pair_isnull(const lfs_block_t pair[2]) {\n    return pair[0] == LFS_BLOCK_NULL || pair[1] == LFS_BLOCK_NULL;\n}\n\nstatic inline int lfs_pair_cmp(\n        const lfs_block_t paira[2],\n        const lfs_block_t pairb[2]) {\n    return !(paira[0] == pairb[0] || paira[1] == pairb[1] ||\n             paira[0] == pairb[1] || paira[1] == pairb[0]);\n}\n\nstatic inline bool lfs_pair_issync(\n        const lfs_block_t paira[2],\n        const lfs_block_t pairb[2]) {\n    return (paira[0] == pairb[0] && paira[1] == pairb[1]) ||\n           (paira[0] == pairb[1] && paira[1] == pairb[0]);\n}\n\nstatic inline void lfs_pair_fromle32(lfs_block_t pair[2]) {\n    pair[0] = lfs_fromle32(pair[0]);\n    pair[1] = lfs_fromle32(pair[1]);\n}\n\n#ifndef LFS_READONLY\nstatic inline void lfs_pair_tole32(lfs_block_t pair[2]) {\n    pair[0] = lfs_tole32(pair[0]);\n    pair[1] = lfs_tole32(pair[1]);\n}\n#endif\n\n// operations on 32-bit entry tags\ntypedef uint32_t lfs_tag_t;\ntypedef int32_t lfs_stag_t;\n\n#define LFS_MKTAG(type, id, size) \\\n    (((lfs_tag_t)(type) << 20) | ((lfs_tag_t)(id) << 10) | (lfs_tag_t)(size))\n\n#define LFS_MKTAG_IF(cond, type, id, size) \\\n    ((cond) ? LFS_MKTAG(type, id, size) : LFS_MKTAG(LFS_FROM_NOOP, 0, 0))\n\n#define LFS_MKTAG_IF_ELSE(cond, type1, id1, size1, type2, id2, size2) \\\n    ((cond) ? LFS_MKTAG(type1, id1, size1) : LFS_MKTAG(type2, id2, size2))\n\nstatic inline bool lfs_tag_isvalid(lfs_tag_t tag) {\n    return !(tag & 0x80000000);\n}\n\nstatic inline bool lfs_tag_isdelete(lfs_tag_t tag) {\n    return ((int32_t)(tag << 22) >> 22) == -1;\n}\n\nstatic inline uint16_t lfs_tag_type1(lfs_tag_t tag) {\n    return (tag & 0x70000000) >> 20;\n}\n\nstatic inline uint16_t lfs_tag_type2(lfs_tag_t tag) {\n    return (tag & 0x78000000) >> 20;\n}\n\nstatic inline uint16_t lfs_tag_type3(lfs_tag_t tag) {\n    return (tag & 0x7ff00000) >> 20;\n}\n\nstatic inline uint8_t lfs_tag_chunk(lfs_tag_t tag) {\n    return (tag & 0x0ff00000) >> 20;\n}\n\nstatic inline int8_t lfs_tag_splice(lfs_tag_t tag) {\n    return (int8_t)lfs_tag_chunk(tag);\n}\n\nstatic inline uint16_t lfs_tag_id(lfs_tag_t tag) {\n    return (tag & 0x000ffc00) >> 10;\n}\n\nstatic inline lfs_size_t lfs_tag_size(lfs_tag_t tag) {\n    return tag & 0x000003ff;\n}\n\nstatic inline lfs_size_t lfs_tag_dsize(lfs_tag_t tag) {\n    return sizeof(tag) + lfs_tag_size(tag + lfs_tag_isdelete(tag));\n}\n\n// operations on attributes in attribute lists\nstruct lfs_mattr {\n    lfs_tag_t tag;\n    const void *buffer;\n};\n\nstruct lfs_diskoff {\n    lfs_block_t block;\n    lfs_off_t off;\n};\n\n#define LFS_MKATTRS(...) \\\n    (struct lfs_mattr[]){__VA_ARGS__}, \\\n    sizeof((struct lfs_mattr[]){__VA_ARGS__}) / sizeof(struct lfs_mattr)\n\n// operations on global state\nstatic inline void lfs_gstate_xor(lfs_gstate_t *a, const lfs_gstate_t *b) {\n    for (int i = 0; i < 3; i++) {\n        ((uint32_t*)a)[i] ^= ((const uint32_t*)b)[i];\n    }\n}\n\nstatic inline bool lfs_gstate_iszero(const lfs_gstate_t *a) {\n    for (int i = 0; i < 3; i++) {\n        if (((uint32_t*)a)[i] != 0) {\n            return false;\n        }\n    }\n    return true;\n}\n\n#ifndef LFS_READONLY\nstatic inline bool lfs_gstate_hasorphans(const lfs_gstate_t *a) {\n    return lfs_tag_size(a->tag);\n}\n\nstatic inline uint8_t lfs_gstate_getorphans(const lfs_gstate_t *a) {\n    return lfs_tag_size(a->tag) & 0x1ff;\n}\n\nstatic inline bool lfs_gstate_hasmove(const lfs_gstate_t *a) {\n    return lfs_tag_type1(a->tag);\n}\n#endif\n\nstatic inline bool lfs_gstate_needssuperblock(const lfs_gstate_t *a) {\n    return lfs_tag_size(a->tag) >> 9;\n}\n\nstatic inline bool lfs_gstate_hasmovehere(const lfs_gstate_t *a,\n        const lfs_block_t *pair) {\n    return lfs_tag_type1(a->tag) && lfs_pair_cmp(a->pair, pair) == 0;\n}\n\nstatic inline void lfs_gstate_fromle32(lfs_gstate_t *a) {\n    a->tag     = lfs_fromle32(a->tag);\n    a->pair[0] = lfs_fromle32(a->pair[0]);\n    a->pair[1] = lfs_fromle32(a->pair[1]);\n}\n\n#ifndef LFS_READONLY\nstatic inline void lfs_gstate_tole32(lfs_gstate_t *a) {\n    a->tag     = lfs_tole32(a->tag);\n    a->pair[0] = lfs_tole32(a->pair[0]);\n    a->pair[1] = lfs_tole32(a->pair[1]);\n}\n#endif\n\n// operations on forward-CRCs used to track erased state\nstruct lfs_fcrc {\n    lfs_size_t size;\n    uint32_t crc;\n};\n\nstatic void lfs_fcrc_fromle32(struct lfs_fcrc *fcrc) {\n    fcrc->size = lfs_fromle32(fcrc->size);\n    fcrc->crc = lfs_fromle32(fcrc->crc);\n}\n\n#ifndef LFS_READONLY\nstatic void lfs_fcrc_tole32(struct lfs_fcrc *fcrc) {\n    fcrc->size = lfs_tole32(fcrc->size);\n    fcrc->crc = lfs_tole32(fcrc->crc);\n}\n#endif\n\n// other endianness operations\nstatic void lfs_ctz_fromle32(struct lfs_ctz *ctz) {\n    ctz->head = lfs_fromle32(ctz->head);\n    ctz->size = lfs_fromle32(ctz->size);\n}\n\n#ifndef LFS_READONLY\nstatic void lfs_ctz_tole32(struct lfs_ctz *ctz) {\n    ctz->head = lfs_tole32(ctz->head);\n    ctz->size = lfs_tole32(ctz->size);\n}\n#endif\n\nstatic inline void lfs_superblock_fromle32(lfs_superblock_t *superblock) {\n    superblock->version     = lfs_fromle32(superblock->version);\n    superblock->block_size  = lfs_fromle32(superblock->block_size);\n    superblock->block_count = lfs_fromle32(superblock->block_count);\n    superblock->name_max    = lfs_fromle32(superblock->name_max);\n    superblock->file_max    = lfs_fromle32(superblock->file_max);\n    superblock->attr_max    = lfs_fromle32(superblock->attr_max);\n}\n\n#ifndef LFS_READONLY\nstatic inline void lfs_superblock_tole32(lfs_superblock_t *superblock) {\n    superblock->version     = lfs_tole32(superblock->version);\n    superblock->block_size  = lfs_tole32(superblock->block_size);\n    superblock->block_count = lfs_tole32(superblock->block_count);\n    superblock->name_max    = lfs_tole32(superblock->name_max);\n    superblock->file_max    = lfs_tole32(superblock->file_max);\n    superblock->attr_max    = lfs_tole32(superblock->attr_max);\n}\n#endif\n\n#ifndef LFS_NO_ASSERT\nstatic bool lfs_mlist_isopen(struct lfs_mlist *head,\n        struct lfs_mlist *node) {\n    for (struct lfs_mlist **p = &head; *p; p = &(*p)->next) {\n        if (*p == (struct lfs_mlist*)node) {\n            return true;\n        }\n    }\n\n    return false;\n}\n#endif\n\nstatic void lfs_mlist_remove(lfs_t *lfs, struct lfs_mlist *mlist) {\n    for (struct lfs_mlist **p = &lfs->mlist; *p; p = &(*p)->next) {\n        if (*p == mlist) {\n            *p = (*p)->next;\n            break;\n        }\n    }\n}\n\nstatic void lfs_mlist_append(lfs_t *lfs, struct lfs_mlist *mlist) {\n    mlist->next = lfs->mlist;\n    lfs->mlist = mlist;\n}\n\n// some other filesystem operations\nstatic uint32_t lfs_fs_disk_version(lfs_t *lfs) {\n    (void)lfs;\n#ifdef LFS_MULTIVERSION\n    if (lfs->cfg->disk_version) {\n        return lfs->cfg->disk_version;\n    } else\n#endif\n    {\n        return LFS_DISK_VERSION;\n    }\n}\n\nstatic uint16_t lfs_fs_disk_version_major(lfs_t *lfs) {\n    return 0xffff & (lfs_fs_disk_version(lfs) >> 16);\n\n}\n\nstatic uint16_t lfs_fs_disk_version_minor(lfs_t *lfs) {\n    return 0xffff & (lfs_fs_disk_version(lfs) >> 0);\n}\n\n\n/// Internal operations predeclared here ///\n#ifndef LFS_READONLY\nstatic int lfs_dir_commit(lfs_t *lfs, lfs_mdir_t *dir,\n        const struct lfs_mattr *attrs, int attrcount);\nstatic int lfs_dir_compact(lfs_t *lfs,\n        lfs_mdir_t *dir, const struct lfs_mattr *attrs, int attrcount,\n        lfs_mdir_t *source, uint16_t begin, uint16_t end);\nstatic lfs_ssize_t lfs_file_flushedwrite(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size);\nstatic lfs_ssize_t lfs_file_write_(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size);\nstatic int lfs_file_sync_(lfs_t *lfs, lfs_file_t *file);\nstatic int lfs_file_outline(lfs_t *lfs, lfs_file_t *file);\nstatic int lfs_file_flush(lfs_t *lfs, lfs_file_t *file);\n\nstatic int lfs_fs_deorphan(lfs_t *lfs, bool powerloss);\nstatic int lfs_fs_preporphans(lfs_t *lfs, int8_t orphans);\nstatic void lfs_fs_prepmove(lfs_t *lfs,\n        uint16_t id, const lfs_block_t pair[2]);\nstatic int lfs_fs_pred(lfs_t *lfs, const lfs_block_t dir[2],\n        lfs_mdir_t *pdir);\nstatic lfs_stag_t lfs_fs_parent(lfs_t *lfs, const lfs_block_t dir[2],\n        lfs_mdir_t *parent);\nstatic int lfs_fs_forceconsistency(lfs_t *lfs);\n#endif\n\nstatic void lfs_fs_prepsuperblock(lfs_t *lfs, bool needssuperblock);\n\n#ifdef LFS_MIGRATE\nstatic int lfs1_traverse(lfs_t *lfs,\n        int (*cb)(void*, lfs_block_t), void *data);\n#endif\n\nstatic int lfs_dir_rewind_(lfs_t *lfs, lfs_dir_t *dir);\n\nstatic lfs_ssize_t lfs_file_flushedread(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size);\nstatic lfs_ssize_t lfs_file_read_(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size);\nstatic int lfs_file_close_(lfs_t *lfs, lfs_file_t *file);\nstatic lfs_soff_t lfs_file_size_(lfs_t *lfs, lfs_file_t *file);\n\nstatic lfs_ssize_t lfs_fs_size_(lfs_t *lfs);\nstatic int lfs_fs_traverse_(lfs_t *lfs,\n        int (*cb)(void *data, lfs_block_t block), void *data,\n        bool includeorphans);\n\nstatic int lfs_deinit(lfs_t *lfs);\nstatic int lfs_unmount_(lfs_t *lfs);\n\n\n/// Block allocator ///\n\n// allocations should call this when all allocated blocks are committed to\n// the filesystem\n//\n// after a checkpoint, the block allocator may realloc any untracked blocks\nstatic void lfs_alloc_ckpoint(lfs_t *lfs) {\n    lfs->lookahead.ckpoint = lfs->block_count;\n}\n\n// drop the lookahead buffer, this is done during mounting and failed\n// traversals in order to avoid invalid lookahead state\nstatic void lfs_alloc_drop(lfs_t *lfs) {\n    lfs->lookahead.size = 0;\n    lfs->lookahead.next = 0;\n    lfs_alloc_ckpoint(lfs);\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_alloc_lookahead(void *p, lfs_block_t block) {\n    lfs_t *lfs = (lfs_t*)p;\n    lfs_block_t off = ((block - lfs->lookahead.start)\n            + lfs->block_count) % lfs->block_count;\n\n    if (off < lfs->lookahead.size) {\n        lfs->lookahead.buffer[off / 8] |= 1U << (off % 8);\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_alloc_scan(lfs_t *lfs) {\n    // move lookahead buffer to the first unused block\n    //\n    // note we limit the lookahead buffer to at most the amount of blocks\n    // checkpointed, this prevents the math in lfs_alloc from underflowing\n    lfs->lookahead.start = (lfs->lookahead.start + lfs->lookahead.next) \n            % lfs->block_count;\n    lfs->lookahead.next = 0;\n    lfs->lookahead.size = lfs_min(\n            8*lfs->cfg->lookahead_size,\n            lfs->lookahead.ckpoint);\n\n    // find mask of free blocks from tree\n    memset(lfs->lookahead.buffer, 0, lfs->cfg->lookahead_size);\n    int err = lfs_fs_traverse_(lfs, lfs_alloc_lookahead, lfs, true);\n    if (err) {\n        lfs_alloc_drop(lfs);\n        return err;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_alloc(lfs_t *lfs, lfs_block_t *block) {\n    while (true) {\n        // scan our lookahead buffer for free blocks\n        while (lfs->lookahead.next < lfs->lookahead.size) {\n            if (!(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                    & (1U << (lfs->lookahead.next % 8)))) {\n                // found a free block\n                *block = (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count;\n\n                // eagerly find next free block to maximize how many blocks\n                // lfs_alloc_ckpoint makes available for scanning\n                while (true) {\n                    lfs->lookahead.next += 1;\n                    lfs->lookahead.ckpoint -= 1;\n\n                    if (lfs->lookahead.next >= lfs->lookahead.size\n                            || !(lfs->lookahead.buffer[lfs->lookahead.next / 8]\n                                & (1U << (lfs->lookahead.next % 8)))) {\n                        return 0;\n                    }\n                }\n            }\n\n            lfs->lookahead.next += 1;\n            lfs->lookahead.ckpoint -= 1;\n        }\n\n        // In order to keep our block allocator from spinning forever when our\n        // filesystem is full, we mark points where there are no in-flight\n        // allocations with a checkpoint before starting a set of allocations.\n        //\n        // If we've looked at all blocks since the last checkpoint, we report\n        // the filesystem as out of storage.\n        //\n        if (lfs->lookahead.ckpoint <= 0) {\n            LFS_ERROR(\"No more free space 0x%\"PRIx32,\n                    (lfs->lookahead.start + lfs->lookahead.next)\n                        % lfs->block_count);\n            return LFS_ERR_NOSPC;\n        }\n\n        // No blocks in our lookahead buffer, we need to scan the filesystem for\n        // unused blocks in the next lookahead window.\n        int err = lfs_alloc_scan(lfs);\n        if(err) {\n            return err;\n        }\n    }\n}\n#endif\n\n/// Metadata pair and directory operations ///\nstatic lfs_stag_t lfs_dir_getslice(lfs_t *lfs, const lfs_mdir_t *dir,\n        lfs_tag_t gmask, lfs_tag_t gtag,\n        lfs_off_t goff, void *gbuffer, lfs_size_t gsize) {\n    lfs_off_t off = dir->off;\n    lfs_tag_t ntag = dir->etag;\n    lfs_stag_t gdiff = 0;\n\n    // synthetic moves\n    if (lfs_gstate_hasmovehere(&lfs->gdisk, dir->pair) &&\n            lfs_tag_id(gmask) != 0) {\n        if (lfs_tag_id(lfs->gdisk.tag) == lfs_tag_id(gtag)) {\n            return LFS_ERR_NOENT;\n        } else if (lfs_tag_id(lfs->gdisk.tag) < lfs_tag_id(gtag)) {\n            gdiff -= LFS_MKTAG(0, 1, 0);\n        }\n    }\n\n    // iterate over dir block backwards (for faster lookups)\n    while (off >= sizeof(lfs_tag_t) + lfs_tag_dsize(ntag)) {\n        off -= lfs_tag_dsize(ntag);\n        lfs_tag_t tag = ntag;\n        int err = lfs_bd_read(lfs,\n                NULL, &lfs->rcache, sizeof(ntag),\n                dir->pair[0], off, &ntag, sizeof(ntag));\n        if (err) {\n            return err;\n        }\n\n        ntag = (lfs_frombe32(ntag) ^ tag) & 0x7fffffff;\n\n        if (lfs_tag_id(gmask) != 0 &&\n                lfs_tag_type1(tag) == LFS_TYPE_SPLICE &&\n                lfs_tag_id(tag) <= lfs_tag_id(gtag - gdiff)) {\n            if (tag == (LFS_MKTAG(LFS_TYPE_CREATE, 0, 0) |\n                    (LFS_MKTAG(0, 0x3ff, 0) & (gtag - gdiff)))) {\n                // found where we were created\n                return LFS_ERR_NOENT;\n            }\n\n            // move around splices\n            gdiff += LFS_MKTAG(0, lfs_tag_splice(tag), 0);\n        }\n\n        if ((gmask & tag) == (gmask & (gtag - gdiff))) {\n            if (lfs_tag_isdelete(tag)) {\n                return LFS_ERR_NOENT;\n            }\n\n            lfs_size_t diff = lfs_min(lfs_tag_size(tag), gsize);\n            err = lfs_bd_read(lfs,\n                    NULL, &lfs->rcache, diff,\n                    dir->pair[0], off+sizeof(tag)+goff, gbuffer, diff);\n            if (err) {\n                return err;\n            }\n\n            memset((uint8_t*)gbuffer + diff, 0, gsize - diff);\n\n            return tag + gdiff;\n        }\n    }\n\n    return LFS_ERR_NOENT;\n}\n\nstatic lfs_stag_t lfs_dir_get(lfs_t *lfs, const lfs_mdir_t *dir,\n        lfs_tag_t gmask, lfs_tag_t gtag, void *buffer) {\n    return lfs_dir_getslice(lfs, dir,\n            gmask, gtag,\n            0, buffer, lfs_tag_size(gtag));\n}\n\nstatic int lfs_dir_getread(lfs_t *lfs, const lfs_mdir_t *dir,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache, lfs_size_t hint,\n        lfs_tag_t gmask, lfs_tag_t gtag,\n        lfs_off_t off, void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    if (off+size > lfs->cfg->block_size) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    while (size > 0) {\n        lfs_size_t diff = size;\n\n        if (pcache && pcache->block == LFS_BLOCK_INLINE &&\n                off < pcache->off + pcache->size) {\n            if (off >= pcache->off) {\n                // is already in pcache?\n                diff = lfs_min(diff, pcache->size - (off-pcache->off));\n                memcpy(data, &pcache->buffer[off-pcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // pcache takes priority\n            diff = lfs_min(diff, pcache->off-off);\n        }\n\n        if (rcache->block == LFS_BLOCK_INLINE &&\n                off < rcache->off + rcache->size) {\n            if (off >= rcache->off) {\n                // is already in rcache?\n                diff = lfs_min(diff, rcache->size - (off-rcache->off));\n                memcpy(data, &rcache->buffer[off-rcache->off], diff);\n\n                data += diff;\n                off += diff;\n                size -= diff;\n                continue;\n            }\n\n            // rcache takes priority\n            diff = lfs_min(diff, rcache->off-off);\n        }\n\n        // load to cache, first condition can no longer fail\n        rcache->block = LFS_BLOCK_INLINE;\n        rcache->off = lfs_aligndown(off, lfs->cfg->read_size);\n        rcache->size = lfs_min(lfs_alignup(off+hint, lfs->cfg->read_size),\n                lfs->cfg->cache_size);\n        int err = lfs_dir_getslice(lfs, dir, gmask, gtag,\n                rcache->off, rcache->buffer, rcache->size);\n        if (err < 0) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_traverse_filter(void *p,\n        lfs_tag_t tag, const void *buffer) {\n    lfs_tag_t *filtertag = p;\n    (void)buffer;\n\n    // which mask depends on unique bit in tag structure\n    uint32_t mask = (tag & LFS_MKTAG(0x100, 0, 0))\n            ? LFS_MKTAG(0x7ff, 0x3ff, 0)\n            : LFS_MKTAG(0x700, 0x3ff, 0);\n\n    // check for redundancy\n    if ((mask & tag) == (mask & *filtertag) ||\n            lfs_tag_isdelete(*filtertag) ||\n            (LFS_MKTAG(0x7ff, 0x3ff, 0) & tag) == (\n                LFS_MKTAG(LFS_TYPE_DELETE, 0, 0) |\n                    (LFS_MKTAG(0, 0x3ff, 0) & *filtertag))) {\n        *filtertag = LFS_MKTAG(LFS_FROM_NOOP, 0, 0);\n        return true;\n    }\n\n    // check if we need to adjust for created/deleted tags\n    if (lfs_tag_type1(tag) == LFS_TYPE_SPLICE &&\n            lfs_tag_id(tag) <= lfs_tag_id(*filtertag)) {\n        *filtertag += LFS_MKTAG(0, lfs_tag_splice(tag), 0);\n    }\n\n    return false;\n}\n#endif\n\n#ifndef LFS_READONLY\n// maximum recursive depth of lfs_dir_traverse, the deepest call:\n//\n// traverse with commit\n// '-> traverse with move\n//     '-> traverse with filter\n//\n#define LFS_DIR_TRAVERSE_DEPTH 3\n\nstruct lfs_dir_traverse {\n    const lfs_mdir_t *dir;\n    lfs_off_t off;\n    lfs_tag_t ptag;\n    const struct lfs_mattr *attrs;\n    int attrcount;\n\n    lfs_tag_t tmask;\n    lfs_tag_t ttag;\n    uint16_t begin;\n    uint16_t end;\n    int16_t diff;\n\n    int (*cb)(void *data, lfs_tag_t tag, const void *buffer);\n    void *data;\n\n    lfs_tag_t tag;\n    const void *buffer;\n    struct lfs_diskoff disk;\n};\n\nstatic int lfs_dir_traverse(lfs_t *lfs,\n        const lfs_mdir_t *dir, lfs_off_t off, lfs_tag_t ptag,\n        const struct lfs_mattr *attrs, int attrcount,\n        lfs_tag_t tmask, lfs_tag_t ttag,\n        uint16_t begin, uint16_t end, int16_t diff,\n        int (*cb)(void *data, lfs_tag_t tag, const void *buffer), void *data) {\n    // This function in inherently recursive, but bounded. To allow tool-based\n    // analysis without unnecessary code-cost we use an explicit stack\n    struct lfs_dir_traverse stack[LFS_DIR_TRAVERSE_DEPTH-1];\n    unsigned sp = 0;\n    int res;\n\n    // iterate over directory and attrs\n    lfs_tag_t tag;\n    const void *buffer;\n    struct lfs_diskoff disk = {0};\n    while (true) {\n        {\n            if (off+lfs_tag_dsize(ptag) < dir->off) {\n                off += lfs_tag_dsize(ptag);\n                int err = lfs_bd_read(lfs,\n                        NULL, &lfs->rcache, sizeof(tag),\n                        dir->pair[0], off, &tag, sizeof(tag));\n                if (err) {\n                    return err;\n                }\n\n                tag = (lfs_frombe32(tag) ^ ptag) | 0x80000000;\n                disk.block = dir->pair[0];\n                disk.off = off+sizeof(lfs_tag_t);\n                buffer = &disk;\n                ptag = tag;\n            } else if (attrcount > 0) {\n                tag = attrs[0].tag;\n                buffer = attrs[0].buffer;\n                attrs += 1;\n                attrcount -= 1;\n            } else {\n                // finished traversal, pop from stack?\n                res = 0;\n                break;\n            }\n\n            // do we need to filter?\n            lfs_tag_t mask = LFS_MKTAG(0x7ff, 0, 0);\n            if ((mask & tmask & tag) != (mask & tmask & ttag)) {\n                continue;\n            }\n\n            if (lfs_tag_id(tmask) != 0) {\n                LFS_ASSERT(sp < LFS_DIR_TRAVERSE_DEPTH);\n                // recurse, scan for duplicates, and update tag based on\n                // creates/deletes\n                stack[sp] = (struct lfs_dir_traverse){\n                    .dir        = dir,\n                    .off        = off,\n                    .ptag       = ptag,\n                    .attrs      = attrs,\n                    .attrcount  = attrcount,\n                    .tmask      = tmask,\n                    .ttag       = ttag,\n                    .begin      = begin,\n                    .end        = end,\n                    .diff       = diff,\n                    .cb         = cb,\n                    .data       = data,\n                    .tag        = tag,\n                    .buffer     = buffer,\n                    .disk       = disk,\n                };\n                sp += 1;\n\n                tmask = 0;\n                ttag = 0;\n                begin = 0;\n                end = 0;\n                diff = 0;\n                cb = lfs_dir_traverse_filter;\n                data = &stack[sp-1].tag;\n                continue;\n            }\n        }\n\npopped:\n        // in filter range?\n        if (lfs_tag_id(tmask) != 0 &&\n                !(lfs_tag_id(tag) >= begin && lfs_tag_id(tag) < end)) {\n            continue;\n        }\n\n        // handle special cases for mcu-side operations\n        if (lfs_tag_type3(tag) == LFS_FROM_NOOP) {\n            // do nothing\n        } else if (lfs_tag_type3(tag) == LFS_FROM_MOVE) {\n            // Without this condition, lfs_dir_traverse can exhibit an\n            // extremely expensive O(n^3) of nested loops when renaming.\n            // This happens because lfs_dir_traverse tries to filter tags by\n            // the tags in the source directory, triggering a second\n            // lfs_dir_traverse with its own filter operation.\n            //\n            // traverse with commit\n            // '-> traverse with filter\n            //     '-> traverse with move\n            //         '-> traverse with filter\n            //\n            // However we don't actually care about filtering the second set of\n            // tags, since duplicate tags have no effect when filtering.\n            //\n            // This check skips this unnecessary recursive filtering explicitly,\n            // reducing this runtime from O(n^3) to O(n^2).\n            if (cb == lfs_dir_traverse_filter) {\n                continue;\n            }\n\n            // recurse into move\n            stack[sp] = (struct lfs_dir_traverse){\n                .dir        = dir,\n                .off        = off,\n                .ptag       = ptag,\n                .attrs      = attrs,\n                .attrcount  = attrcount,\n                .tmask      = tmask,\n                .ttag       = ttag,\n                .begin      = begin,\n                .end        = end,\n                .diff       = diff,\n                .cb         = cb,\n                .data       = data,\n                .tag        = LFS_MKTAG(LFS_FROM_NOOP, 0, 0),\n            };\n            sp += 1;\n\n            uint16_t fromid = lfs_tag_size(tag);\n            uint16_t toid = lfs_tag_id(tag);\n            dir = buffer;\n            off = 0;\n            ptag = 0xffffffff;\n            attrs = NULL;\n            attrcount = 0;\n            tmask = LFS_MKTAG(0x600, 0x3ff, 0);\n            ttag = LFS_MKTAG(LFS_TYPE_STRUCT, 0, 0);\n            begin = fromid;\n            end = fromid+1;\n            diff = toid-fromid+diff;\n        } else if (lfs_tag_type3(tag) == LFS_FROM_USERATTRS) {\n            for (unsigned i = 0; i < lfs_tag_size(tag); i++) {\n                const struct lfs_attr *a = buffer;\n                res = cb(data, LFS_MKTAG(LFS_TYPE_USERATTR + a[i].type,\n                        lfs_tag_id(tag) + diff, a[i].size), a[i].buffer);\n                if (res < 0) {\n                    return res;\n                }\n\n                if (res) {\n                    break;\n                }\n            }\n        } else {\n            res = cb(data, tag + LFS_MKTAG(0, diff, 0), buffer);\n            if (res < 0) {\n                return res;\n            }\n\n            if (res) {\n                break;\n            }\n        }\n    }\n\n    if (sp > 0) {\n        // pop from the stack and return, fortunately all pops share\n        // a destination\n        dir         = stack[sp-1].dir;\n        off         = stack[sp-1].off;\n        ptag        = stack[sp-1].ptag;\n        attrs       = stack[sp-1].attrs;\n        attrcount   = stack[sp-1].attrcount;\n        tmask       = stack[sp-1].tmask;\n        ttag        = stack[sp-1].ttag;\n        begin       = stack[sp-1].begin;\n        end         = stack[sp-1].end;\n        diff        = stack[sp-1].diff;\n        cb          = stack[sp-1].cb;\n        data        = stack[sp-1].data;\n        tag         = stack[sp-1].tag;\n        buffer      = stack[sp-1].buffer;\n        disk        = stack[sp-1].disk;\n        sp -= 1;\n        goto popped;\n    } else {\n        return res;\n    }\n}\n#endif\n\nstatic lfs_stag_t lfs_dir_fetchmatch(lfs_t *lfs,\n        lfs_mdir_t *dir, const lfs_block_t pair[2],\n        lfs_tag_t fmask, lfs_tag_t ftag, uint16_t *id,\n        int (*cb)(void *data, lfs_tag_t tag, const void *buffer), void *data) {\n    // we can find tag very efficiently during a fetch, since we're already\n    // scanning the entire directory\n    lfs_stag_t besttag = -1;\n\n    // if either block address is invalid we return LFS_ERR_CORRUPT here,\n    // otherwise later writes to the pair could fail\n    if (lfs->block_count \n            && (pair[0] >= lfs->block_count || pair[1] >= lfs->block_count)) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    // find the block with the most recent revision\n    uint32_t revs[2] = {0, 0};\n    int r = 0;\n    for (int i = 0; i < 2; i++) {\n        int err = lfs_bd_read(lfs,\n                NULL, &lfs->rcache, sizeof(revs[i]),\n                pair[i], 0, &revs[i], sizeof(revs[i]));\n        revs[i] = lfs_fromle32(revs[i]);\n        if (err && err != LFS_ERR_CORRUPT) {\n            return err;\n        }\n\n        if (err != LFS_ERR_CORRUPT &&\n                lfs_scmp(revs[i], revs[(i+1)%2]) > 0) {\n            r = i;\n        }\n    }\n\n    dir->pair[0] = pair[(r+0)%2];\n    dir->pair[1] = pair[(r+1)%2];\n    dir->rev = revs[(r+0)%2];\n    dir->off = 0; // nonzero = found some commits\n\n    // now scan tags to fetch the actual dir and find possible match\n    for (int i = 0; i < 2; i++) {\n        lfs_off_t off = 0;\n        lfs_tag_t ptag = 0xffffffff;\n\n        uint16_t tempcount = 0;\n        lfs_block_t temptail[2] = {LFS_BLOCK_NULL, LFS_BLOCK_NULL};\n        bool tempsplit = false;\n        lfs_stag_t tempbesttag = besttag;\n\n        // assume not erased until proven otherwise\n        bool maybeerased = false;\n        bool hasfcrc = false;\n        struct lfs_fcrc fcrc;\n\n        dir->rev = lfs_tole32(dir->rev);\n        uint32_t crc = lfs_crc(0xffffffff, &dir->rev, sizeof(dir->rev));\n        dir->rev = lfs_fromle32(dir->rev);\n\n        while (true) {\n            // extract next tag\n            lfs_tag_t tag;\n            off += lfs_tag_dsize(ptag);\n            int err = lfs_bd_read(lfs,\n                    NULL, &lfs->rcache, lfs->cfg->block_size,\n                    dir->pair[0], off, &tag, sizeof(tag));\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    // can't continue?\n                    break;\n                }\n                return err;\n            }\n\n            crc = lfs_crc(crc, &tag, sizeof(tag));\n            tag = lfs_frombe32(tag) ^ ptag;\n\n            // next commit not yet programmed?\n            if (!lfs_tag_isvalid(tag)) {\n                // we only might be erased if the last tag was a crc\n                maybeerased = (lfs_tag_type2(ptag) == LFS_TYPE_CCRC);\n                break;\n            // out of range?\n            } else if (off + lfs_tag_dsize(tag) > lfs->cfg->block_size) {\n                break;\n            }\n\n            ptag = tag;\n\n            if (lfs_tag_type2(tag) == LFS_TYPE_CCRC) {\n                // check the crc attr\n                uint32_t dcrc;\n                err = lfs_bd_read(lfs,\n                        NULL, &lfs->rcache, lfs->cfg->block_size,\n                        dir->pair[0], off+sizeof(tag), &dcrc, sizeof(dcrc));\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        break;\n                    }\n                    return err;\n                }\n                dcrc = lfs_fromle32(dcrc);\n\n                if (crc != dcrc) {\n                    break;\n                }\n\n                // reset the next bit if we need to\n                ptag ^= (lfs_tag_t)(lfs_tag_chunk(tag) & 1U) << 31;\n\n                // toss our crc into the filesystem seed for\n                // pseudorandom numbers, note we use another crc here\n                // as a collection function because it is sufficiently\n                // random and convenient\n                lfs->seed = lfs_crc(lfs->seed, &crc, sizeof(crc));\n\n                // update with what's found so far\n                besttag = tempbesttag;\n                dir->off = off + lfs_tag_dsize(tag);\n                dir->etag = ptag;\n                dir->count = tempcount;\n                dir->tail[0] = temptail[0];\n                dir->tail[1] = temptail[1];\n                dir->split = tempsplit;\n\n                // reset crc, hasfcrc\n                crc = 0xffffffff;\n                continue;\n            }\n\n            // crc the entry first, hopefully leaving it in the cache\n            err = lfs_bd_crc(lfs,\n                    NULL, &lfs->rcache, lfs->cfg->block_size,\n                    dir->pair[0], off+sizeof(tag),\n                    lfs_tag_dsize(tag)-sizeof(tag), &crc);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    break;\n                }\n                return err;\n            }\n\n            // directory modification tags?\n            if (lfs_tag_type1(tag) == LFS_TYPE_NAME) {\n                // increase count of files if necessary\n                if (lfs_tag_id(tag) >= tempcount) {\n                    tempcount = lfs_tag_id(tag) + 1;\n                }\n            } else if (lfs_tag_type1(tag) == LFS_TYPE_SPLICE) {\n                tempcount += lfs_tag_splice(tag);\n\n                if (tag == (LFS_MKTAG(LFS_TYPE_DELETE, 0, 0) |\n                        (LFS_MKTAG(0, 0x3ff, 0) & tempbesttag))) {\n                    tempbesttag |= 0x80000000;\n                } else if (tempbesttag != -1 &&\n                        lfs_tag_id(tag) <= lfs_tag_id(tempbesttag)) {\n                    tempbesttag += LFS_MKTAG(0, lfs_tag_splice(tag), 0);\n                }\n            } else if (lfs_tag_type1(tag) == LFS_TYPE_TAIL) {\n                tempsplit = (lfs_tag_chunk(tag) & 1);\n\n                err = lfs_bd_read(lfs,\n                        NULL, &lfs->rcache, lfs->cfg->block_size,\n                        dir->pair[0], off+sizeof(tag), &temptail, 8);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        break;\n                    }\n                    return err;\n                }\n                lfs_pair_fromle32(temptail);\n            } else if (lfs_tag_type3(tag) == LFS_TYPE_FCRC) {\n                err = lfs_bd_read(lfs,\n                        NULL, &lfs->rcache, lfs->cfg->block_size,\n                        dir->pair[0], off+sizeof(tag),\n                        &fcrc, sizeof(fcrc));\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        break;\n                    }\n                }\n\n                lfs_fcrc_fromle32(&fcrc);\n                hasfcrc = true;\n            }\n\n            // found a match for our fetcher?\n            if ((fmask & tag) == (fmask & ftag)) {\n                int res = cb(data, tag, &(struct lfs_diskoff){\n                        dir->pair[0], off+sizeof(tag)});\n                if (res < 0) {\n                    if (res == LFS_ERR_CORRUPT) {\n                        break;\n                    }\n                    return res;\n                }\n\n                if (res == LFS_CMP_EQ) {\n                    // found a match\n                    tempbesttag = tag;\n                } else if ((LFS_MKTAG(0x7ff, 0x3ff, 0) & tag) ==\n                        (LFS_MKTAG(0x7ff, 0x3ff, 0) & tempbesttag)) {\n                    // found an identical tag, but contents didn't match\n                    // this must mean that our besttag has been overwritten\n                    tempbesttag = -1;\n                } else if (res == LFS_CMP_GT &&\n                        lfs_tag_id(tag) <= lfs_tag_id(tempbesttag)) {\n                    // found a greater match, keep track to keep things sorted\n                    tempbesttag = tag | 0x80000000;\n                }\n            }\n        }\n\n        // found no valid commits?\n        if (dir->off == 0) {\n            // try the other block?\n            lfs_pair_swap(dir->pair);\n            dir->rev = revs[(r+1)%2];\n            continue;\n        }\n\n        // did we end on a valid commit? we may have an erased block\n        dir->erased = false;\n        if (maybeerased && dir->off % lfs->cfg->prog_size == 0) {\n        #ifdef LFS_MULTIVERSION\n            // note versions < lfs2.1 did not have fcrc tags, if\n            // we're < lfs2.1 treat missing fcrc as erased data\n            //\n            // we don't strictly need to do this, but otherwise writing\n            // to lfs2.0 disks becomes very inefficient\n            if (lfs_fs_disk_version(lfs) < 0x00020001) {\n                dir->erased = true;\n\n            } else\n        #endif\n            if (hasfcrc) {\n                // check for an fcrc matching the next prog's erased state, if\n                // this failed most likely a previous prog was interrupted, we\n                // need a new erase\n                uint32_t fcrc_ = 0xffffffff;\n                int err = lfs_bd_crc(lfs,\n                        NULL, &lfs->rcache, lfs->cfg->block_size,\n                        dir->pair[0], dir->off, fcrc.size, &fcrc_);\n                if (err && err != LFS_ERR_CORRUPT) {\n                    return err;\n                }\n\n                // found beginning of erased part?\n                dir->erased = (fcrc_ == fcrc.crc);\n            }\n        }\n\n        // synthetic move\n        if (lfs_gstate_hasmovehere(&lfs->gdisk, dir->pair)) {\n            if (lfs_tag_id(lfs->gdisk.tag) == lfs_tag_id(besttag)) {\n                besttag |= 0x80000000;\n            } else if (besttag != -1 &&\n                    lfs_tag_id(lfs->gdisk.tag) < lfs_tag_id(besttag)) {\n                besttag -= LFS_MKTAG(0, 1, 0);\n            }\n        }\n\n        // found tag? or found best id?\n        if (id) {\n            *id = lfs_min(lfs_tag_id(besttag), dir->count);\n        }\n\n        if (lfs_tag_isvalid(besttag)) {\n            return besttag;\n        } else if (lfs_tag_id(besttag) < dir->count) {\n            return LFS_ERR_NOENT;\n        } else {\n            return 0;\n        }\n    }\n\n    LFS_ERROR(\"Corrupted dir pair at {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n            dir->pair[0], dir->pair[1]);\n    return LFS_ERR_CORRUPT;\n}\n\nstatic int lfs_dir_fetch(lfs_t *lfs,\n        lfs_mdir_t *dir, const lfs_block_t pair[2]) {\n    // note, mask=-1, tag=-1 can never match a tag since this\n    // pattern has the invalid bit set\n    return (int)lfs_dir_fetchmatch(lfs, dir, pair,\n            (lfs_tag_t)-1, (lfs_tag_t)-1, NULL, NULL, NULL);\n}\n\nstatic int lfs_dir_getgstate(lfs_t *lfs, const lfs_mdir_t *dir,\n        lfs_gstate_t *gstate) {\n    lfs_gstate_t temp;\n    lfs_stag_t res = lfs_dir_get(lfs, dir, LFS_MKTAG(0x7ff, 0, 0),\n            LFS_MKTAG(LFS_TYPE_MOVESTATE, 0, sizeof(temp)), &temp);\n    if (res < 0 && res != LFS_ERR_NOENT) {\n        return res;\n    }\n\n    if (res != LFS_ERR_NOENT) {\n        // xor together to find resulting gstate\n        lfs_gstate_fromle32(&temp);\n        lfs_gstate_xor(gstate, &temp);\n    }\n\n    return 0;\n}\n\nstatic int lfs_dir_getinfo(lfs_t *lfs, lfs_mdir_t *dir,\n        uint16_t id, struct lfs_info *info) {\n    if (id == 0x3ff) {\n        // special case for root\n        strcpy(info->name, \"/\");\n        info->type = LFS_TYPE_DIR;\n        return 0;\n    }\n\n    lfs_stag_t tag = lfs_dir_get(lfs, dir, LFS_MKTAG(0x780, 0x3ff, 0),\n            LFS_MKTAG(LFS_TYPE_NAME, id, lfs->name_max+1), info->name);\n    if (tag < 0) {\n        return (int)tag;\n    }\n\n    info->type = lfs_tag_type3(tag);\n\n    struct lfs_ctz ctz;\n    tag = lfs_dir_get(lfs, dir, LFS_MKTAG(0x700, 0x3ff, 0),\n            LFS_MKTAG(LFS_TYPE_STRUCT, id, sizeof(ctz)), &ctz);\n    if (tag < 0) {\n        return (int)tag;\n    }\n    lfs_ctz_fromle32(&ctz);\n\n    if (lfs_tag_type3(tag) == LFS_TYPE_CTZSTRUCT) {\n        info->size = ctz.size;\n    } else if (lfs_tag_type3(tag) == LFS_TYPE_INLINESTRUCT) {\n        info->size = lfs_tag_size(tag);\n    }\n\n    return 0;\n}\n\nstruct lfs_dir_find_match {\n    lfs_t *lfs;\n    const void *name;\n    lfs_size_t size;\n};\n\nstatic int lfs_dir_find_match(void *data,\n        lfs_tag_t tag, const void *buffer) {\n    struct lfs_dir_find_match *name = data;\n    lfs_t *lfs = name->lfs;\n    const struct lfs_diskoff *disk = buffer;\n\n    // compare with disk\n    lfs_size_t diff = lfs_min(name->size, lfs_tag_size(tag));\n    int res = lfs_bd_cmp(lfs,\n            NULL, &lfs->rcache, diff,\n            disk->block, disk->off, name->name, diff);\n    if (res != LFS_CMP_EQ) {\n        return res;\n    }\n\n    // only equal if our size is still the same\n    if (name->size != lfs_tag_size(tag)) {\n        return (name->size < lfs_tag_size(tag)) ? LFS_CMP_LT : LFS_CMP_GT;\n    }\n\n    // found a match!\n    return LFS_CMP_EQ;\n}\n\n// lfs_dir_find tries to set path and id even if file is not found\n//\n// returns:\n// - 0                  if file is found\n// - LFS_ERR_NOENT      if file or parent is not found\n// - LFS_ERR_NOTDIR     if parent is not a dir\nstatic lfs_stag_t lfs_dir_find(lfs_t *lfs, lfs_mdir_t *dir,\n        const char **path, uint16_t *id) {\n    // we reduce path to a single name if we can find it\n    const char *name = *path;\n\n    // default to root dir\n    lfs_stag_t tag = LFS_MKTAG(LFS_TYPE_DIR, 0x3ff, 0);\n    dir->tail[0] = lfs->root[0];\n    dir->tail[1] = lfs->root[1];\n\n    // empty paths are not allowed\n    if (*name == '\\0') {\n        return LFS_ERR_INVAL;\n    }\n\n    while (true) {\nnextname:\n        // skip slashes if we're a directory\n        if (lfs_tag_type3(tag) == LFS_TYPE_DIR) {\n            name += strspn(name, \"/\");\n        }\n        lfs_size_t namelen = strcspn(name, \"/\");\n\n        // skip '.'\n        if (namelen == 1 && memcmp(name, \".\", 1) == 0) {\n            name += namelen;\n            goto nextname;\n        }\n\n        // error on unmatched '..', trying to go above root?\n        if (namelen == 2 && memcmp(name, \"..\", 2) == 0) {\n            return LFS_ERR_INVAL;\n        }\n\n        // skip if matched by '..' in name\n        const char *suffix = name + namelen;\n        lfs_size_t sufflen;\n        int depth = 1;\n        while (true) {\n            suffix += strspn(suffix, \"/\");\n            sufflen = strcspn(suffix, \"/\");\n            if (sufflen == 0) {\n                break;\n            }\n\n            if (sufflen == 1 && memcmp(suffix, \".\", 1) == 0) {\n                // noop\n            } else if (sufflen == 2 && memcmp(suffix, \"..\", 2) == 0) {\n                depth -= 1;\n                if (depth == 0) {\n                    name = suffix + sufflen;\n                    goto nextname;\n                }\n            } else {\n                depth += 1;\n            }\n\n            suffix += sufflen;\n        }\n\n        // found path\n        if (*name == '\\0') {\n            return tag;\n        }\n\n        // update what we've found so far\n        *path = name;\n\n        // only continue if we're a directory\n        if (lfs_tag_type3(tag) != LFS_TYPE_DIR) {\n            return LFS_ERR_NOTDIR;\n        }\n\n        // grab the entry data\n        if (lfs_tag_id(tag) != 0x3ff) {\n            lfs_stag_t res = lfs_dir_get(lfs, dir, LFS_MKTAG(0x700, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_STRUCT, lfs_tag_id(tag), 8), dir->tail);\n            if (res < 0) {\n                return res;\n            }\n            lfs_pair_fromle32(dir->tail);\n        }\n\n        // find entry matching name\n        while (true) {\n            tag = lfs_dir_fetchmatch(lfs, dir, dir->tail,\n                    LFS_MKTAG(0x780, 0, 0),\n                    LFS_MKTAG(LFS_TYPE_NAME, 0, namelen),\n                    id,\n                    lfs_dir_find_match, &(struct lfs_dir_find_match){\n                        lfs, name, namelen});\n            if (tag < 0) {\n                return tag;\n            }\n\n            if (tag) {\n                break;\n            }\n\n            if (!dir->split) {\n                return LFS_ERR_NOENT;\n            }\n        }\n\n        // to next name\n        name += namelen;\n    }\n}\n\n// commit logic\nstruct lfs_commit {\n    lfs_block_t block;\n    lfs_off_t off;\n    lfs_tag_t ptag;\n    uint32_t crc;\n\n    lfs_off_t begin;\n    lfs_off_t end;\n};\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_commitprog(lfs_t *lfs, struct lfs_commit *commit,\n        const void *buffer, lfs_size_t size) {\n    int err = lfs_bd_prog(lfs,\n            &lfs->pcache, &lfs->rcache, false,\n            commit->block, commit->off ,\n            (const uint8_t*)buffer, size);\n    if (err) {\n        return err;\n    }\n\n    commit->crc = lfs_crc(commit->crc, buffer, size);\n    commit->off += size;\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_commitattr(lfs_t *lfs, struct lfs_commit *commit,\n        lfs_tag_t tag, const void *buffer) {\n    // check if we fit\n    lfs_size_t dsize = lfs_tag_dsize(tag);\n    if (commit->off + dsize > commit->end) {\n        return LFS_ERR_NOSPC;\n    }\n\n    // write out tag\n    lfs_tag_t ntag = lfs_tobe32((tag & 0x7fffffff) ^ commit->ptag);\n    int err = lfs_dir_commitprog(lfs, commit, &ntag, sizeof(ntag));\n    if (err) {\n        return err;\n    }\n\n    if (!(tag & 0x80000000)) {\n        // from memory\n        err = lfs_dir_commitprog(lfs, commit, buffer, dsize-sizeof(tag));\n        if (err) {\n            return err;\n        }\n    } else {\n        // from disk\n        const struct lfs_diskoff *disk = buffer;\n        for (lfs_off_t i = 0; i < dsize-sizeof(tag); i++) {\n            // rely on caching to make this efficient\n            uint8_t dat;\n            err = lfs_bd_read(lfs,\n                    NULL, &lfs->rcache, dsize-sizeof(tag)-i,\n                    disk->block, disk->off+i, &dat, 1);\n            if (err) {\n                return err;\n            }\n\n            err = lfs_dir_commitprog(lfs, commit, &dat, 1);\n            if (err) {\n                return err;\n            }\n        }\n    }\n\n    commit->ptag = tag & 0x7fffffff;\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\n\nstatic int lfs_dir_commitcrc(lfs_t *lfs, struct lfs_commit *commit) {\n    // align to program units\n    //\n    // this gets a bit complex as we have two types of crcs:\n    // - 5-word crc with fcrc to check following prog (middle of block)\n    // - 2-word crc with no following prog (end of block)\n    const lfs_off_t end = lfs_alignup(\n            lfs_min(commit->off + 5*sizeof(uint32_t), lfs->cfg->block_size),\n            lfs->cfg->prog_size);\n\n    lfs_off_t off1 = 0;\n    uint32_t crc1 = 0;\n\n    // create crc tags to fill up remainder of commit, note that\n    // padding is not crced, which lets fetches skip padding but\n    // makes committing a bit more complicated\n    while (commit->off < end) {\n        lfs_off_t noff = (\n                lfs_min(end - (commit->off+sizeof(lfs_tag_t)), 0x3fe)\n                + (commit->off+sizeof(lfs_tag_t)));\n        // too large for crc tag? need padding commits\n        if (noff < end) {\n            noff = lfs_min(noff, end - 5*sizeof(uint32_t));\n        }\n\n        // space for fcrc?\n        uint8_t eperturb = (uint8_t)-1;\n        if (noff >= end && noff <= lfs->cfg->block_size - lfs->cfg->prog_size) {\n            // first read the leading byte, this always contains a bit\n            // we can perturb to avoid writes that don't change the fcrc\n            int err = lfs_bd_read(lfs,\n                    NULL, &lfs->rcache, lfs->cfg->prog_size,\n                    commit->block, noff, &eperturb, 1);\n            if (err && err != LFS_ERR_CORRUPT) {\n                return err;\n            }\n\n        #ifdef LFS_MULTIVERSION\n            // unfortunately fcrcs break mdir fetching < lfs2.1, so only write\n            // these if we're a >= lfs2.1 filesystem\n            if (lfs_fs_disk_version(lfs) <= 0x00020000) {\n                // don't write fcrc\n            } else\n        #endif\n            {\n                // find the expected fcrc, don't bother avoiding a reread\n                // of the eperturb, it should still be in our cache\n                struct lfs_fcrc fcrc = {\n                    .size = lfs->cfg->prog_size,\n                    .crc = 0xffffffff\n                };\n                err = lfs_bd_crc(lfs,\n                        NULL, &lfs->rcache, lfs->cfg->prog_size,\n                        commit->block, noff, fcrc.size, &fcrc.crc);\n                if (err && err != LFS_ERR_CORRUPT) {\n                    return err;\n                }\n\n                lfs_fcrc_tole32(&fcrc);\n                err = lfs_dir_commitattr(lfs, commit,\n                        LFS_MKTAG(LFS_TYPE_FCRC, 0x3ff, sizeof(struct lfs_fcrc)),\n                        &fcrc);\n                if (err) {\n                    return err;\n                }\n            }\n        }\n\n        // build commit crc\n        struct {\n            lfs_tag_t tag;\n            uint32_t crc;\n        } ccrc;\n        lfs_tag_t ntag = LFS_MKTAG(\n                LFS_TYPE_CCRC + (((uint8_t)~eperturb) >> 7), 0x3ff,\n                noff - (commit->off+sizeof(lfs_tag_t)));\n        ccrc.tag = lfs_tobe32(ntag ^ commit->ptag);\n        commit->crc = lfs_crc(commit->crc, &ccrc.tag, sizeof(lfs_tag_t));\n        ccrc.crc = lfs_tole32(commit->crc);\n\n        int err = lfs_bd_prog(lfs,\n                &lfs->pcache, &lfs->rcache, false,\n                commit->block, commit->off, &ccrc, sizeof(ccrc));\n        if (err) {\n            return err;\n        }\n\n        // keep track of non-padding checksum to verify\n        if (off1 == 0) {\n            off1 = commit->off + sizeof(lfs_tag_t);\n            crc1 = commit->crc;\n        }\n\n        commit->off = noff;\n        // perturb valid bit?\n        commit->ptag = ntag ^ ((0x80UL & ~eperturb) << 24);\n        // reset crc for next commit\n        commit->crc = 0xffffffff;\n\n        // manually flush here since we don't prog the padding, this confuses\n        // the caching layer\n        if (noff >= end || noff >= lfs->pcache.off + lfs->cfg->cache_size) {\n            // flush buffers\n            int err = lfs_bd_sync(lfs, &lfs->pcache, &lfs->rcache, false);\n            if (err) {\n                return err;\n            }\n        }\n    }\n\n    // successful commit, check checksums to make sure\n    //\n    // note that we don't need to check padding commits, worst\n    // case if they are corrupted we would have had to compact anyways\n    lfs_off_t off = commit->begin;\n    uint32_t crc = 0xffffffff;\n    int err = lfs_bd_crc(lfs,\n            NULL, &lfs->rcache, off1+sizeof(uint32_t),\n            commit->block, off, off1-off, &crc);\n    if (err) {\n        return err;\n    }\n\n    // check non-padding commits against known crc\n    if (crc != crc1) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    // make sure to check crc in case we happen to pick\n    // up an unrelated crc (frozen block?)\n    err = lfs_bd_crc(lfs,\n            NULL, &lfs->rcache, sizeof(uint32_t),\n            commit->block, off1, sizeof(uint32_t), &crc);\n    if (err) {\n        return err;\n    }\n\n    if (crc != 0) {\n        return LFS_ERR_CORRUPT;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_alloc(lfs_t *lfs, lfs_mdir_t *dir) {\n    // allocate pair of dir blocks (backwards, so we write block 1 first)\n    for (int i = 0; i < 2; i++) {\n        int err = lfs_alloc(lfs, &dir->pair[(i+1)%2]);\n        if (err) {\n            return err;\n        }\n    }\n\n    // zero for reproducibility in case initial block is unreadable\n    dir->rev = 0;\n\n    // rather than clobbering one of the blocks we just pretend\n    // the revision may be valid\n    int err = lfs_bd_read(lfs,\n            NULL, &lfs->rcache, sizeof(dir->rev),\n            dir->pair[0], 0, &dir->rev, sizeof(dir->rev));\n    dir->rev = lfs_fromle32(dir->rev);\n    if (err && err != LFS_ERR_CORRUPT) {\n        return err;\n    }\n\n    // to make sure we don't immediately evict, align the new revision count\n    // to our block_cycles modulus, see lfs_dir_compact for why our modulus\n    // is tweaked this way\n    if (lfs->cfg->block_cycles > 0) {\n        dir->rev = lfs_alignup(dir->rev, ((lfs->cfg->block_cycles+1)|1));\n    }\n\n    // set defaults\n    dir->off = sizeof(dir->rev);\n    dir->etag = 0xffffffff;\n    dir->count = 0;\n    dir->tail[0] = LFS_BLOCK_NULL;\n    dir->tail[1] = LFS_BLOCK_NULL;\n    dir->erased = false;\n    dir->split = false;\n\n    // don't write out yet, let caller take care of that\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_drop(lfs_t *lfs, lfs_mdir_t *dir, lfs_mdir_t *tail) {\n    // steal state\n    int err = lfs_dir_getgstate(lfs, tail, &lfs->gdelta);\n    if (err) {\n        return err;\n    }\n\n    // steal tail\n    lfs_pair_tole32(tail->tail);\n    err = lfs_dir_commit(lfs, dir, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_TAIL + tail->split, 0x3ff, 8), tail->tail}));\n    lfs_pair_fromle32(tail->tail);\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_split(lfs_t *lfs,\n        lfs_mdir_t *dir, const struct lfs_mattr *attrs, int attrcount,\n        lfs_mdir_t *source, uint16_t split, uint16_t end) {\n    // create tail metadata pair\n    lfs_mdir_t tail;\n    int err = lfs_dir_alloc(lfs, &tail);\n    if (err) {\n        return err;\n    }\n\n    tail.split = dir->split;\n    tail.tail[0] = dir->tail[0];\n    tail.tail[1] = dir->tail[1];\n\n    // note we don't care about LFS_OK_RELOCATED\n    int res = lfs_dir_compact(lfs, &tail, attrs, attrcount, source, split, end);\n    if (res < 0) {\n        return res;\n    }\n\n    dir->tail[0] = tail.pair[0];\n    dir->tail[1] = tail.pair[1];\n    dir->split = true;\n\n    // update root if needed\n    if (lfs_pair_cmp(dir->pair, lfs->root) == 0 && split == 0) {\n        lfs->root[0] = tail.pair[0];\n        lfs->root[1] = tail.pair[1];\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_commit_size(void *p, lfs_tag_t tag, const void *buffer) {\n    lfs_size_t *size = p;\n    (void)buffer;\n\n    *size += lfs_tag_dsize(tag);\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstruct lfs_dir_commit_commit {\n    lfs_t *lfs;\n    struct lfs_commit *commit;\n};\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_commit_commit(void *p, lfs_tag_t tag, const void *buffer) {\n    struct lfs_dir_commit_commit *commit = p;\n    return lfs_dir_commitattr(commit->lfs, commit->commit, tag, buffer);\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic bool lfs_dir_needsrelocation(lfs_t *lfs, lfs_mdir_t *dir) {\n    // If our revision count == n * block_cycles, we should force a relocation,\n    // this is how littlefs wear-levels at the metadata-pair level. Note that we\n    // actually use (block_cycles+1)|1, this is to avoid two corner cases:\n    // 1. block_cycles = 1, which would prevent relocations from terminating\n    // 2. block_cycles = 2n, which, due to aliasing, would only ever relocate\n    //    one metadata block in the pair, effectively making this useless\n    return (lfs->cfg->block_cycles > 0\n            && ((dir->rev + 1) % ((lfs->cfg->block_cycles+1)|1) == 0));\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_compact(lfs_t *lfs,\n        lfs_mdir_t *dir, const struct lfs_mattr *attrs, int attrcount,\n        lfs_mdir_t *source, uint16_t begin, uint16_t end) {\n    // save some state in case block is bad\n    bool relocated = false;\n    bool tired = lfs_dir_needsrelocation(lfs, dir);\n\n    // increment revision count\n    dir->rev += 1;\n\n    // do not proactively relocate blocks during migrations, this\n    // can cause a number of failure states such: clobbering the\n    // v1 superblock if we relocate root, and invalidating directory\n    // pointers if we relocate the head of a directory. On top of\n    // this, relocations increase the overall complexity of\n    // lfs_migration, which is already a delicate operation.\n#ifdef LFS_MIGRATE\n    if (lfs->lfs1) {\n        tired = false;\n    }\n#endif\n\n    if (tired && lfs_pair_cmp(dir->pair, (const lfs_block_t[2]){0, 1}) != 0) {\n        // we're writing too much, time to relocate\n        goto relocate;\n    }\n\n    // begin loop to commit compaction to blocks until a compact sticks\n    while (true) {\n        {\n            // setup commit state\n            struct lfs_commit commit = {\n                .block = dir->pair[1],\n                .off = 0,\n                .ptag = 0xffffffff,\n                .crc = 0xffffffff,\n\n                .begin = 0,\n                .end = (lfs->cfg->metadata_max ?\n                    lfs->cfg->metadata_max : lfs->cfg->block_size) - 8,\n            };\n\n            // erase block to write to\n            int err = lfs_bd_erase(lfs, dir->pair[1]);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            // write out header\n            dir->rev = lfs_tole32(dir->rev);\n            err = lfs_dir_commitprog(lfs, &commit,\n                    &dir->rev, sizeof(dir->rev));\n            dir->rev = lfs_fromle32(dir->rev);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            // traverse the directory, this time writing out all unique tags\n            err = lfs_dir_traverse(lfs,\n                    source, 0, 0xffffffff, attrs, attrcount,\n                    LFS_MKTAG(0x400, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_NAME, 0, 0),\n                    begin, end, -begin,\n                    lfs_dir_commit_commit, &(struct lfs_dir_commit_commit){\n                        lfs, &commit});\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            // commit tail, which may be new after last size check\n            if (!lfs_pair_isnull(dir->tail)) {\n                lfs_pair_tole32(dir->tail);\n                err = lfs_dir_commitattr(lfs, &commit,\n                        LFS_MKTAG(LFS_TYPE_TAIL + dir->split, 0x3ff, 8),\n                        dir->tail);\n                lfs_pair_fromle32(dir->tail);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n            }\n\n            // bring over gstate?\n            lfs_gstate_t delta = {0};\n            if (!relocated) {\n                lfs_gstate_xor(&delta, &lfs->gdisk);\n                lfs_gstate_xor(&delta, &lfs->gstate);\n            }\n            lfs_gstate_xor(&delta, &lfs->gdelta);\n            delta.tag &= ~LFS_MKTAG(0, 0, 0x3ff);\n\n            err = lfs_dir_getgstate(lfs, dir, &delta);\n            if (err) {\n                return err;\n            }\n\n            if (!lfs_gstate_iszero(&delta)) {\n                lfs_gstate_tole32(&delta);\n                err = lfs_dir_commitattr(lfs, &commit,\n                        LFS_MKTAG(LFS_TYPE_MOVESTATE, 0x3ff,\n                            sizeof(delta)), &delta);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n            }\n\n            // complete commit with crc\n            err = lfs_dir_commitcrc(lfs, &commit);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            // successful compaction, swap dir pair to indicate most recent\n            LFS_ASSERT(commit.off % lfs->cfg->prog_size == 0);\n            lfs_pair_swap(dir->pair);\n            dir->count = end - begin;\n            dir->off = commit.off;\n            dir->etag = commit.ptag;\n            // update gstate\n            lfs->gdelta = (lfs_gstate_t){0};\n            if (!relocated) {\n                lfs->gdisk = lfs->gstate;\n            }\n        }\n        break;\n\nrelocate:\n        // commit was corrupted, drop caches and prepare to relocate block\n        relocated = true;\n        lfs_cache_drop(lfs, &lfs->pcache);\n        if (!tired) {\n            LFS_DEBUG(\"Bad block at 0x%\"PRIx32, dir->pair[1]);\n        }\n\n        // can't relocate superblock, filesystem is now frozen\n        if (lfs_pair_cmp(dir->pair, (const lfs_block_t[2]){0, 1}) == 0) {\n            LFS_WARN(\"Superblock 0x%\"PRIx32\" has become unwritable\",\n                    dir->pair[1]);\n            return LFS_ERR_NOSPC;\n        }\n\n        // relocate half of pair\n        int err = lfs_alloc(lfs, &dir->pair[1]);\n        if (err && (err != LFS_ERR_NOSPC || !tired)) {\n            return err;\n        }\n\n        tired = false;\n        continue;\n    }\n\n    return relocated ? LFS_OK_RELOCATED : 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_splittingcompact(lfs_t *lfs, lfs_mdir_t *dir,\n        const struct lfs_mattr *attrs, int attrcount,\n        lfs_mdir_t *source, uint16_t begin, uint16_t end) {\n    while (true) {\n        // find size of first split, we do this by halving the split until\n        // the metadata is guaranteed to fit\n        //\n        // Note that this isn't a true binary search, we never increase the\n        // split size. This may result in poorly distributed metadata but isn't\n        // worth the extra code size or performance hit to fix.\n        lfs_size_t split = begin;\n        while (end - split > 1) {\n            lfs_size_t size = 0;\n            int err = lfs_dir_traverse(lfs,\n                    source, 0, 0xffffffff, attrs, attrcount,\n                    LFS_MKTAG(0x400, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_NAME, 0, 0),\n                    split, end, -split,\n                    lfs_dir_commit_size, &size);\n            if (err) {\n                return err;\n            }\n\n            // space is complicated, we need room for:\n            //\n            // - tail:         4+2*4 = 12 bytes\n            // - gstate:       4+3*4 = 16 bytes\n            // - move delete:  4     = 4 bytes\n            // - crc:          4+4   = 8 bytes\n            //                 total = 40 bytes\n            //\n            // And we cap at half a block to avoid degenerate cases with\n            // nearly-full metadata blocks.\n            //\n            lfs_size_t metadata_max = (lfs->cfg->metadata_max)\n                    ? lfs->cfg->metadata_max\n                    : lfs->cfg->block_size;\n            if (end - split < 0xff\n                    && size <= lfs_min(\n                        metadata_max - 40,\n                        lfs_alignup(\n                            metadata_max/2,\n                            lfs->cfg->prog_size))) {\n                break;\n            }\n\n            split = split + ((end - split) / 2);\n        }\n\n        if (split == begin) {\n            // no split needed\n            break;\n        }\n\n        // split into two metadata pairs and continue\n        int err = lfs_dir_split(lfs, dir, attrs, attrcount,\n                source, split, end);\n        if (err && err != LFS_ERR_NOSPC) {\n            return err;\n        }\n\n        if (err) {\n            // we can't allocate a new block, try to compact with degraded\n            // performance\n            LFS_WARN(\"Unable to split {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                    dir->pair[0], dir->pair[1]);\n            break;\n        } else {\n            end = split;\n        }\n    }\n\n    if (lfs_dir_needsrelocation(lfs, dir)\n            && lfs_pair_cmp(dir->pair, (const lfs_block_t[2]){0, 1}) == 0) {\n        // oh no! we're writing too much to the superblock,\n        // should we expand?\n        lfs_ssize_t size = lfs_fs_size_(lfs);\n        if (size < 0) {\n            return size;\n        }\n\n        // littlefs cannot reclaim expanded superblocks, so expand cautiously\n        //\n        // if our filesystem is more than ~88% full, don't expand, this is\n        // somewhat arbitrary\n        if (lfs->block_count - size > lfs->block_count/8) {\n            LFS_DEBUG(\"Expanding superblock at rev %\"PRIu32, dir->rev);\n            int err = lfs_dir_split(lfs, dir, attrs, attrcount,\n                    source, begin, end);\n            if (err && err != LFS_ERR_NOSPC) {\n                return err;\n            }\n\n            if (err) {\n                // welp, we tried, if we ran out of space there's not much\n                // we can do, we'll error later if we've become frozen\n                LFS_WARN(\"Unable to expand superblock\");\n            } else {\n                // duplicate the superblock entry into the new superblock\n                end = 1;\n            }\n        }\n    }\n\n    return lfs_dir_compact(lfs, dir, attrs, attrcount, source, begin, end);\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_relocatingcommit(lfs_t *lfs, lfs_mdir_t *dir,\n        const lfs_block_t pair[2],\n        const struct lfs_mattr *attrs, int attrcount,\n        lfs_mdir_t *pdir) {\n    int state = 0;\n\n    // calculate changes to the directory\n    bool hasdelete = false;\n    for (int i = 0; i < attrcount; i++) {\n        if (lfs_tag_type3(attrs[i].tag) == LFS_TYPE_CREATE) {\n            dir->count += 1;\n        } else if (lfs_tag_type3(attrs[i].tag) == LFS_TYPE_DELETE) {\n            LFS_ASSERT(dir->count > 0);\n            dir->count -= 1;\n            hasdelete = true;\n        } else if (lfs_tag_type1(attrs[i].tag) == LFS_TYPE_TAIL) {\n            dir->tail[0] = ((lfs_block_t*)attrs[i].buffer)[0];\n            dir->tail[1] = ((lfs_block_t*)attrs[i].buffer)[1];\n            dir->split = (lfs_tag_chunk(attrs[i].tag) & 1);\n            lfs_pair_fromle32(dir->tail);\n        }\n    }\n\n    // should we actually drop the directory block?\n    if (hasdelete && dir->count == 0) {\n        LFS_ASSERT(pdir);\n        int err = lfs_fs_pred(lfs, dir->pair, pdir);\n        if (err && err != LFS_ERR_NOENT) {\n            return err;\n        }\n\n        if (err != LFS_ERR_NOENT && pdir->split) {\n            state = LFS_OK_DROPPED;\n            goto fixmlist;\n        }\n    }\n\n    if (dir->erased) {\n        // try to commit\n        struct lfs_commit commit = {\n            .block = dir->pair[0],\n            .off = dir->off,\n            .ptag = dir->etag,\n            .crc = 0xffffffff,\n\n            .begin = dir->off,\n            .end = (lfs->cfg->metadata_max ?\n                lfs->cfg->metadata_max : lfs->cfg->block_size) - 8,\n        };\n\n        // traverse attrs that need to be written out\n        lfs_pair_tole32(dir->tail);\n        int err = lfs_dir_traverse(lfs,\n                dir, dir->off, dir->etag, attrs, attrcount,\n                0, 0, 0, 0, 0,\n                lfs_dir_commit_commit, &(struct lfs_dir_commit_commit){\n                    lfs, &commit});\n        lfs_pair_fromle32(dir->tail);\n        if (err) {\n            if (err == LFS_ERR_NOSPC || err == LFS_ERR_CORRUPT) {\n                goto compact;\n            }\n            return err;\n        }\n\n        // commit any global diffs if we have any\n        lfs_gstate_t delta = {0};\n        lfs_gstate_xor(&delta, &lfs->gstate);\n        lfs_gstate_xor(&delta, &lfs->gdisk);\n        lfs_gstate_xor(&delta, &lfs->gdelta);\n        delta.tag &= ~LFS_MKTAG(0, 0, 0x3ff);\n        if (!lfs_gstate_iszero(&delta)) {\n            err = lfs_dir_getgstate(lfs, dir, &delta);\n            if (err) {\n                return err;\n            }\n\n            lfs_gstate_tole32(&delta);\n            err = lfs_dir_commitattr(lfs, &commit,\n                    LFS_MKTAG(LFS_TYPE_MOVESTATE, 0x3ff,\n                        sizeof(delta)), &delta);\n            if (err) {\n                if (err == LFS_ERR_NOSPC || err == LFS_ERR_CORRUPT) {\n                    goto compact;\n                }\n                return err;\n            }\n        }\n\n        // finalize commit with the crc\n        err = lfs_dir_commitcrc(lfs, &commit);\n        if (err) {\n            if (err == LFS_ERR_NOSPC || err == LFS_ERR_CORRUPT) {\n                goto compact;\n            }\n            return err;\n        }\n\n        // successful commit, update dir\n        LFS_ASSERT(commit.off % lfs->cfg->prog_size == 0);\n        dir->off = commit.off;\n        dir->etag = commit.ptag;\n        // and update gstate\n        lfs->gdisk = lfs->gstate;\n        lfs->gdelta = (lfs_gstate_t){0};\n\n        goto fixmlist;\n    }\n\ncompact:\n    // fall back to compaction\n    lfs_cache_drop(lfs, &lfs->pcache);\n\n    state = lfs_dir_splittingcompact(lfs, dir, attrs, attrcount,\n            dir, 0, dir->count);\n    if (state < 0) {\n        return state;\n    }\n\n    goto fixmlist;\n\nfixmlist:;\n    // this complicated bit of logic is for fixing up any active\n    // metadata-pairs that we may have affected\n    //\n    // note we have to make two passes since the mdir passed to\n    // lfs_dir_commit could also be in this list, and even then\n    // we need to copy the pair so they don't get clobbered if we refetch\n    // our mdir.\n    lfs_block_t oldpair[2] = {pair[0], pair[1]};\n    for (struct lfs_mlist *d = lfs->mlist; d; d = d->next) {\n        if (lfs_pair_cmp(d->m.pair, oldpair) == 0) {\n            d->m = *dir;\n            if (d->m.pair != pair) {\n                for (int i = 0; i < attrcount; i++) {\n                    if (lfs_tag_type3(attrs[i].tag) == LFS_TYPE_DELETE &&\n                            d->id == lfs_tag_id(attrs[i].tag)) {\n                        d->m.pair[0] = LFS_BLOCK_NULL;\n                        d->m.pair[1] = LFS_BLOCK_NULL;\n                    } else if (lfs_tag_type3(attrs[i].tag) == LFS_TYPE_DELETE &&\n                            d->id > lfs_tag_id(attrs[i].tag)) {\n                        d->id -= 1;\n                        if (d->type == LFS_TYPE_DIR) {\n                            ((lfs_dir_t*)d)->pos -= 1;\n                        }\n                    } else if (lfs_tag_type3(attrs[i].tag) == LFS_TYPE_CREATE &&\n                            d->id >= lfs_tag_id(attrs[i].tag)) {\n                        d->id += 1;\n                        if (d->type == LFS_TYPE_DIR) {\n                            ((lfs_dir_t*)d)->pos += 1;\n                        }\n                    }\n                }\n            }\n\n            while (d->id >= d->m.count && d->m.split) {\n                // we split and id is on tail now\n                if (lfs_pair_cmp(d->m.tail, lfs->root) != 0) {\n                    d->id -= d->m.count;\n                }\n                int err = lfs_dir_fetch(lfs, &d->m, d->m.tail);\n                if (err) {\n                    return err;\n                }\n            }\n        }\n    }\n\n    return state;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_orphaningcommit(lfs_t *lfs, lfs_mdir_t *dir,\n        const struct lfs_mattr *attrs, int attrcount) {\n    // check for any inline files that aren't RAM backed and\n    // forcefully evict them, needed for filesystem consistency\n    for (lfs_file_t *f = (lfs_file_t*)lfs->mlist; f; f = f->next) {\n        if (dir != &f->m && lfs_pair_cmp(f->m.pair, dir->pair) == 0 &&\n                f->type == LFS_TYPE_REG && (f->flags & LFS_F_INLINE) &&\n                f->ctz.size > lfs->cfg->cache_size) {\n            int err = lfs_file_outline(lfs, f);\n            if (err) {\n                return err;\n            }\n\n            err = lfs_file_flush(lfs, f);\n            if (err) {\n                return err;\n            }\n        }\n    }\n\n    lfs_block_t lpair[2] = {dir->pair[0], dir->pair[1]};\n    lfs_mdir_t ldir = *dir;\n    lfs_mdir_t pdir;\n    int state = lfs_dir_relocatingcommit(lfs, &ldir, dir->pair,\n            attrs, attrcount, &pdir);\n    if (state < 0) {\n        return state;\n    }\n\n    // update if we're not in mlist, note we may have already been\n    // updated if we are in mlist\n    if (lfs_pair_cmp(dir->pair, lpair) == 0) {\n        *dir = ldir;\n    }\n\n    // commit was successful, but may require other changes in the\n    // filesystem, these would normally be tail recursive, but we have\n    // flattened them here avoid unbounded stack usage\n\n    // need to drop?\n    if (state == LFS_OK_DROPPED) {\n        // steal state\n        int err = lfs_dir_getgstate(lfs, dir, &lfs->gdelta);\n        if (err) {\n            return err;\n        }\n\n        // steal tail, note that this can't create a recursive drop\n        lpair[0] = pdir.pair[0];\n        lpair[1] = pdir.pair[1];\n        lfs_pair_tole32(dir->tail);\n        state = lfs_dir_relocatingcommit(lfs, &pdir, lpair, LFS_MKATTRS(\n                    {LFS_MKTAG(LFS_TYPE_TAIL + dir->split, 0x3ff, 8),\n                        dir->tail}),\n                NULL);\n        lfs_pair_fromle32(dir->tail);\n        if (state < 0) {\n            return state;\n        }\n\n        ldir = pdir;\n    }\n\n    // need to relocate?\n    bool orphans = false;\n    while (state == LFS_OK_RELOCATED) {\n        LFS_DEBUG(\"Relocating {0x%\"PRIx32\", 0x%\"PRIx32\"} \"\n                    \"-> {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                lpair[0], lpair[1], ldir.pair[0], ldir.pair[1]);\n        state = 0;\n\n        // update internal root\n        if (lfs_pair_cmp(lpair, lfs->root) == 0) {\n            lfs->root[0] = ldir.pair[0];\n            lfs->root[1] = ldir.pair[1];\n        }\n\n        // update internally tracked dirs\n        for (struct lfs_mlist *d = lfs->mlist; d; d = d->next) {\n            if (lfs_pair_cmp(lpair, d->m.pair) == 0) {\n                d->m.pair[0] = ldir.pair[0];\n                d->m.pair[1] = ldir.pair[1];\n            }\n\n            if (d->type == LFS_TYPE_DIR &&\n                    lfs_pair_cmp(lpair, ((lfs_dir_t*)d)->head) == 0) {\n                ((lfs_dir_t*)d)->head[0] = ldir.pair[0];\n                ((lfs_dir_t*)d)->head[1] = ldir.pair[1];\n            }\n        }\n\n        // find parent\n        lfs_stag_t tag = lfs_fs_parent(lfs, lpair, &pdir);\n        if (tag < 0 && tag != LFS_ERR_NOENT) {\n            return tag;\n        }\n\n        bool hasparent = (tag != LFS_ERR_NOENT);\n        if (tag != LFS_ERR_NOENT) {\n            // note that if we have a parent, we must have a pred, so this will\n            // always create an orphan\n            int err = lfs_fs_preporphans(lfs, +1);\n            if (err) {\n                return err;\n            }\n\n            // fix pending move in this pair? this looks like an optimization but\n            // is in fact _required_ since relocating may outdate the move.\n            uint16_t moveid = 0x3ff;\n            if (lfs_gstate_hasmovehere(&lfs->gstate, pdir.pair)) {\n                moveid = lfs_tag_id(lfs->gstate.tag);\n                LFS_DEBUG(\"Fixing move while relocating \"\n                        \"{0x%\"PRIx32\", 0x%\"PRIx32\"} 0x%\"PRIx16\"\\n\",\n                        pdir.pair[0], pdir.pair[1], moveid);\n                lfs_fs_prepmove(lfs, 0x3ff, NULL);\n                if (moveid < lfs_tag_id(tag)) {\n                    tag -= LFS_MKTAG(0, 1, 0);\n                }\n            }\n\n            lfs_block_t ppair[2] = {pdir.pair[0], pdir.pair[1]};\n            lfs_pair_tole32(ldir.pair);\n            state = lfs_dir_relocatingcommit(lfs, &pdir, ppair, LFS_MKATTRS(\n                        {LFS_MKTAG_IF(moveid != 0x3ff,\n                            LFS_TYPE_DELETE, moveid, 0), NULL},\n                        {tag, ldir.pair}),\n                    NULL);\n            lfs_pair_fromle32(ldir.pair);\n            if (state < 0) {\n                return state;\n            }\n\n            if (state == LFS_OK_RELOCATED) {\n                lpair[0] = ppair[0];\n                lpair[1] = ppair[1];\n                ldir = pdir;\n                orphans = true;\n                continue;\n            }\n        }\n\n        // find pred\n        int err = lfs_fs_pred(lfs, lpair, &pdir);\n        if (err && err != LFS_ERR_NOENT) {\n            return err;\n        }\n        LFS_ASSERT(!(hasparent && err == LFS_ERR_NOENT));\n\n        // if we can't find dir, it must be new\n        if (err != LFS_ERR_NOENT) {\n            if (lfs_gstate_hasorphans(&lfs->gstate)) {\n                // next step, clean up orphans\n                err = lfs_fs_preporphans(lfs, -hasparent);\n                if (err) {\n                    return err;\n                }\n            }\n\n            // fix pending move in this pair? this looks like an optimization\n            // but is in fact _required_ since relocating may outdate the move.\n            uint16_t moveid = 0x3ff;\n            if (lfs_gstate_hasmovehere(&lfs->gstate, pdir.pair)) {\n                moveid = lfs_tag_id(lfs->gstate.tag);\n                LFS_DEBUG(\"Fixing move while relocating \"\n                        \"{0x%\"PRIx32\", 0x%\"PRIx32\"} 0x%\"PRIx16\"\\n\",\n                        pdir.pair[0], pdir.pair[1], moveid);\n                lfs_fs_prepmove(lfs, 0x3ff, NULL);\n            }\n\n            // replace bad pair, either we clean up desync, or no desync occured\n            lpair[0] = pdir.pair[0];\n            lpair[1] = pdir.pair[1];\n            lfs_pair_tole32(ldir.pair);\n            state = lfs_dir_relocatingcommit(lfs, &pdir, lpair, LFS_MKATTRS(\n                        {LFS_MKTAG_IF(moveid != 0x3ff,\n                            LFS_TYPE_DELETE, moveid, 0), NULL},\n                        {LFS_MKTAG(LFS_TYPE_TAIL + pdir.split, 0x3ff, 8),\n                            ldir.pair}),\n                    NULL);\n            lfs_pair_fromle32(ldir.pair);\n            if (state < 0) {\n                return state;\n            }\n\n            ldir = pdir;\n        }\n    }\n\n    return orphans ? LFS_OK_ORPHANED : 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_dir_commit(lfs_t *lfs, lfs_mdir_t *dir,\n        const struct lfs_mattr *attrs, int attrcount) {\n    int orphans = lfs_dir_orphaningcommit(lfs, dir, attrs, attrcount);\n    if (orphans < 0) {\n        return orphans;\n    }\n\n    if (orphans) {\n        // make sure we've removed all orphans, this is a noop if there\n        // are none, but if we had nested blocks failures we may have\n        // created some\n        int err = lfs_fs_deorphan(lfs, false);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\n\n/// Top level directory operations ///\n#ifndef LFS_READONLY\nstatic int lfs_mkdir_(lfs_t *lfs, const char *path) {\n    // deorphan if we haven't yet, needed at most once after poweron\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    struct lfs_mlist cwd;\n    cwd.next = lfs->mlist;\n    uint16_t id;\n    err = lfs_dir_find(lfs, &cwd.m, &path, &id);\n    if (!(err == LFS_ERR_NOENT && lfs_path_islast(path))) {\n        return (err < 0) ? err : LFS_ERR_EXIST;\n    }\n\n    // check that name fits\n    lfs_size_t nlen = lfs_path_namelen(path);\n    if (nlen > lfs->name_max) {\n        return LFS_ERR_NAMETOOLONG;\n    }\n\n    // build up new directory\n    lfs_alloc_ckpoint(lfs);\n    lfs_mdir_t dir;\n    err = lfs_dir_alloc(lfs, &dir);\n    if (err) {\n        return err;\n    }\n\n    // find end of list\n    lfs_mdir_t pred = cwd.m;\n    while (pred.split) {\n        err = lfs_dir_fetch(lfs, &pred, pred.tail);\n        if (err) {\n            return err;\n        }\n    }\n\n    // setup dir\n    lfs_pair_tole32(pred.tail);\n    err = lfs_dir_commit(lfs, &dir, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8), pred.tail}));\n    lfs_pair_fromle32(pred.tail);\n    if (err) {\n        return err;\n    }\n\n    // current block not end of list?\n    if (cwd.m.split) {\n        // update tails, this creates a desync\n        err = lfs_fs_preporphans(lfs, +1);\n        if (err) {\n            return err;\n        }\n\n        // it's possible our predecessor has to be relocated, and if\n        // our parent is our predecessor's predecessor, this could have\n        // caused our parent to go out of date, fortunately we can hook\n        // ourselves into littlefs to catch this\n        cwd.type = 0;\n        cwd.id = 0;\n        lfs->mlist = &cwd;\n\n        lfs_pair_tole32(dir.pair);\n        err = lfs_dir_commit(lfs, &pred, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8), dir.pair}));\n        lfs_pair_fromle32(dir.pair);\n        if (err) {\n            lfs->mlist = cwd.next;\n            return err;\n        }\n\n        lfs->mlist = cwd.next;\n        err = lfs_fs_preporphans(lfs, -1);\n        if (err) {\n            return err;\n        }\n    }\n\n    // now insert into our parent block\n    lfs_pair_tole32(dir.pair);\n    err = lfs_dir_commit(lfs, &cwd.m, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_CREATE, id, 0), NULL},\n            {LFS_MKTAG(LFS_TYPE_DIR, id, nlen), path},\n            {LFS_MKTAG(LFS_TYPE_DIRSTRUCT, id, 8), dir.pair},\n            {LFS_MKTAG_IF(!cwd.m.split,\n                LFS_TYPE_SOFTTAIL, 0x3ff, 8), dir.pair}));\n    lfs_pair_fromle32(dir.pair);\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n#endif\n\nstatic int lfs_dir_open_(lfs_t *lfs, lfs_dir_t *dir, const char *path) {\n    lfs_stag_t tag = lfs_dir_find(lfs, &dir->m, &path, NULL);\n    if (tag < 0) {\n        return tag;\n    }\n\n    if (lfs_tag_type3(tag) != LFS_TYPE_DIR) {\n        return LFS_ERR_NOTDIR;\n    }\n\n    lfs_block_t pair[2];\n    if (lfs_tag_id(tag) == 0x3ff) {\n        // handle root dir separately\n        pair[0] = lfs->root[0];\n        pair[1] = lfs->root[1];\n    } else {\n        // get dir pair from parent\n        lfs_stag_t res = lfs_dir_get(lfs, &dir->m, LFS_MKTAG(0x700, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_STRUCT, lfs_tag_id(tag), 8), pair);\n        if (res < 0) {\n            return res;\n        }\n        lfs_pair_fromle32(pair);\n    }\n\n    // fetch first pair\n    int err = lfs_dir_fetch(lfs, &dir->m, pair);\n    if (err) {\n        return err;\n    }\n\n    // setup entry\n    dir->head[0] = dir->m.pair[0];\n    dir->head[1] = dir->m.pair[1];\n    dir->id = 0;\n    dir->pos = 0;\n\n    // add to list of mdirs\n    dir->type = LFS_TYPE_DIR;\n    lfs_mlist_append(lfs, (struct lfs_mlist *)dir);\n\n    return 0;\n}\n\nstatic int lfs_dir_close_(lfs_t *lfs, lfs_dir_t *dir) {\n    // remove from list of mdirs\n    lfs_mlist_remove(lfs, (struct lfs_mlist *)dir);\n\n    return 0;\n}\n\nstatic int lfs_dir_read_(lfs_t *lfs, lfs_dir_t *dir, struct lfs_info *info) {\n    memset(info, 0, sizeof(*info));\n\n    // special offset for '.' and '..'\n    if (dir->pos == 0) {\n        info->type = LFS_TYPE_DIR;\n        strcpy(info->name, \".\");\n        dir->pos += 1;\n        return true;\n    } else if (dir->pos == 1) {\n        info->type = LFS_TYPE_DIR;\n        strcpy(info->name, \"..\");\n        dir->pos += 1;\n        return true;\n    }\n\n    while (true) {\n        if (dir->id == dir->m.count) {\n            if (!dir->m.split) {\n                return false;\n            }\n\n            int err = lfs_dir_fetch(lfs, &dir->m, dir->m.tail);\n            if (err) {\n                return err;\n            }\n\n            dir->id = 0;\n        }\n\n        int err = lfs_dir_getinfo(lfs, &dir->m, dir->id, info);\n        if (err && err != LFS_ERR_NOENT) {\n            return err;\n        }\n\n        dir->id += 1;\n        if (err != LFS_ERR_NOENT) {\n            break;\n        }\n    }\n\n    dir->pos += 1;\n    return true;\n}\n\nstatic int lfs_dir_seek_(lfs_t *lfs, lfs_dir_t *dir, lfs_off_t off) {\n    // simply walk from head dir\n    int err = lfs_dir_rewind_(lfs, dir);\n    if (err) {\n        return err;\n    }\n\n    // first two for ./..\n    dir->pos = lfs_min(2, off);\n    off -= dir->pos;\n\n    // skip superblock entry\n    dir->id = (off > 0 && lfs_pair_cmp(dir->head, lfs->root) == 0);\n\n    while (off > 0) {\n        if (dir->id == dir->m.count) {\n            if (!dir->m.split) {\n                return LFS_ERR_INVAL;\n            }\n\n            err = lfs_dir_fetch(lfs, &dir->m, dir->m.tail);\n            if (err) {\n                return err;\n            }\n\n            dir->id = 0;\n        }\n\n        int diff = lfs_min(dir->m.count - dir->id, off);\n        dir->id += diff;\n        dir->pos += diff;\n        off -= diff;\n    }\n\n    return 0;\n}\n\nstatic lfs_soff_t lfs_dir_tell_(lfs_t *lfs, lfs_dir_t *dir) {\n    (void)lfs;\n    return dir->pos;\n}\n\nstatic int lfs_dir_rewind_(lfs_t *lfs, lfs_dir_t *dir) {\n    // reload the head dir\n    int err = lfs_dir_fetch(lfs, &dir->m, dir->head);\n    if (err) {\n        return err;\n    }\n\n    dir->id = 0;\n    dir->pos = 0;\n    return 0;\n}\n\n\n/// File index list operations ///\nstatic int lfs_ctz_index(lfs_t *lfs, lfs_off_t *off) {\n    lfs_off_t size = *off;\n    lfs_off_t b = lfs->cfg->block_size - 2*4;\n    lfs_off_t i = size / b;\n    if (i == 0) {\n        return 0;\n    }\n\n    i = (size - 4*(lfs_popc(i-1)+2)) / b;\n    *off = size - b*i - 4*lfs_popc(i);\n    return i;\n}\n\nstatic int lfs_ctz_find(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache,\n        lfs_block_t head, lfs_size_t size,\n        lfs_size_t pos, lfs_block_t *block, lfs_off_t *off) {\n    if (size == 0) {\n        *block = LFS_BLOCK_NULL;\n        *off = 0;\n        return 0;\n    }\n\n    lfs_off_t current = lfs_ctz_index(lfs, &(lfs_off_t){size-1});\n    lfs_off_t target = lfs_ctz_index(lfs, &pos);\n\n    while (current > target) {\n        lfs_size_t skip = lfs_min(\n                lfs_npw2(current-target+1) - 1,\n                lfs_ctz(current));\n\n        int err = lfs_bd_read(lfs,\n                pcache, rcache, sizeof(head),\n                head, 4*skip, &head, sizeof(head));\n        head = lfs_fromle32(head);\n        if (err) {\n            return err;\n        }\n\n        current -= 1 << skip;\n    }\n\n    *block = head;\n    *off = pos;\n    return 0;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_ctz_extend(lfs_t *lfs,\n        lfs_cache_t *pcache, lfs_cache_t *rcache,\n        lfs_block_t head, lfs_size_t size,\n        lfs_block_t *block, lfs_off_t *off) {\n    while (true) {\n        // go ahead and grab a block\n        lfs_block_t nblock;\n        int err = lfs_alloc(lfs, &nblock);\n        if (err) {\n            return err;\n        }\n\n        {\n            err = lfs_bd_erase(lfs, nblock);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n\n            if (size == 0) {\n                *block = nblock;\n                *off = 0;\n                return 0;\n            }\n\n            lfs_size_t noff = size - 1;\n            lfs_off_t index = lfs_ctz_index(lfs, &noff);\n            noff = noff + 1;\n\n            // just copy out the last block if it is incomplete\n            if (noff != lfs->cfg->block_size) {\n                for (lfs_off_t i = 0; i < noff; i++) {\n                    uint8_t data;\n                    err = lfs_bd_read(lfs,\n                            NULL, rcache, noff-i,\n                            head, i, &data, 1);\n                    if (err) {\n                        return err;\n                    }\n\n                    err = lfs_bd_prog(lfs,\n                            pcache, rcache, true,\n                            nblock, i, &data, 1);\n                    if (err) {\n                        if (err == LFS_ERR_CORRUPT) {\n                            goto relocate;\n                        }\n                        return err;\n                    }\n                }\n\n                *block = nblock;\n                *off = noff;\n                return 0;\n            }\n\n            // append block\n            index += 1;\n            lfs_size_t skips = lfs_ctz(index) + 1;\n            lfs_block_t nhead = head;\n            for (lfs_off_t i = 0; i < skips; i++) {\n                nhead = lfs_tole32(nhead);\n                err = lfs_bd_prog(lfs, pcache, rcache, true,\n                        nblock, 4*i, &nhead, 4);\n                nhead = lfs_fromle32(nhead);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n\n                if (i != skips-1) {\n                    err = lfs_bd_read(lfs,\n                            NULL, rcache, sizeof(nhead),\n                            nhead, 4*i, &nhead, sizeof(nhead));\n                    nhead = lfs_fromle32(nhead);\n                    if (err) {\n                        return err;\n                    }\n                }\n            }\n\n            *block = nblock;\n            *off = 4*skips;\n            return 0;\n        }\n\nrelocate:\n        LFS_DEBUG(\"Bad block at 0x%\"PRIx32, nblock);\n\n        // just clear cache and try a new block\n        lfs_cache_drop(lfs, pcache);\n    }\n}\n#endif\n\nstatic int lfs_ctz_traverse(lfs_t *lfs,\n        const lfs_cache_t *pcache, lfs_cache_t *rcache,\n        lfs_block_t head, lfs_size_t size,\n        int (*cb)(void*, lfs_block_t), void *data) {\n    if (size == 0) {\n        return 0;\n    }\n\n    lfs_off_t index = lfs_ctz_index(lfs, &(lfs_off_t){size-1});\n\n    while (true) {\n        int err = cb(data, head);\n        if (err) {\n            return err;\n        }\n\n        if (index == 0) {\n            return 0;\n        }\n\n        lfs_block_t heads[2];\n        int count = 2 - (index & 1);\n        err = lfs_bd_read(lfs,\n                pcache, rcache, count*sizeof(head),\n                head, 0, &heads, count*sizeof(head));\n        heads[0] = lfs_fromle32(heads[0]);\n        heads[1] = lfs_fromle32(heads[1]);\n        if (err) {\n            return err;\n        }\n\n        for (int i = 0; i < count-1; i++) {\n            err = cb(data, heads[i]);\n            if (err) {\n                return err;\n            }\n        }\n\n        head = heads[count-1];\n        index -= count;\n    }\n}\n\n\n/// Top level file operations ///\nstatic int lfs_file_opencfg_(lfs_t *lfs, lfs_file_t *file,\n        const char *path, int flags,\n        const struct lfs_file_config *cfg) {\n#ifndef LFS_READONLY\n    // deorphan if we haven't yet, needed at most once after poweron\n    if ((flags & LFS_O_WRONLY) == LFS_O_WRONLY) {\n        int err = lfs_fs_forceconsistency(lfs);\n        if (err) {\n            return err;\n        }\n    }\n#else\n    LFS_ASSERT((flags & LFS_O_RDONLY) == LFS_O_RDONLY);\n#endif\n\n    // setup simple file details\n    int err;\n    file->cfg = cfg;\n    file->flags = flags;\n    file->pos = 0;\n    file->off = 0;\n    file->cache.buffer = NULL;\n\n    // allocate entry for file if it doesn't exist\n    lfs_stag_t tag = lfs_dir_find(lfs, &file->m, &path, &file->id);\n    if (tag < 0 && !(tag == LFS_ERR_NOENT && lfs_path_islast(path))) {\n        err = tag;\n        goto cleanup;\n    }\n\n    // get id, add to list of mdirs to catch update changes\n    file->type = LFS_TYPE_REG;\n    lfs_mlist_append(lfs, (struct lfs_mlist *)file);\n\n#ifdef LFS_READONLY\n    if (tag == LFS_ERR_NOENT) {\n        err = LFS_ERR_NOENT;\n        goto cleanup;\n#else\n    if (tag == LFS_ERR_NOENT) {\n        if (!(flags & LFS_O_CREAT)) {\n            err = LFS_ERR_NOENT;\n            goto cleanup;\n        }\n\n        // don't allow trailing slashes\n        if (lfs_path_isdir(path)) {\n            err = LFS_ERR_NOTDIR;\n            goto cleanup;\n        }\n\n        // check that name fits\n        lfs_size_t nlen = lfs_path_namelen(path);\n        if (nlen > lfs->name_max) {\n            err = LFS_ERR_NAMETOOLONG;\n            goto cleanup;\n        }\n\n        // get next slot and create entry to remember name\n        err = lfs_dir_commit(lfs, &file->m, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_CREATE, file->id, 0), NULL},\n                {LFS_MKTAG(LFS_TYPE_REG, file->id, nlen), path},\n                {LFS_MKTAG(LFS_TYPE_INLINESTRUCT, file->id, 0), NULL}));\n\n        // it may happen that the file name doesn't fit in the metadata blocks, e.g., a 256 byte file name will\n        // not fit in a 128 byte block.\n        err = (err == LFS_ERR_NOSPC) ? LFS_ERR_NAMETOOLONG : err;\n        if (err) {\n            goto cleanup;\n        }\n\n        tag = LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, 0);\n    } else if (flags & LFS_O_EXCL) {\n        err = LFS_ERR_EXIST;\n        goto cleanup;\n#endif\n    } else if (lfs_tag_type3(tag) != LFS_TYPE_REG) {\n        err = LFS_ERR_ISDIR;\n        goto cleanup;\n#ifndef LFS_READONLY\n    } else if (flags & LFS_O_TRUNC) {\n        // truncate if requested\n        tag = LFS_MKTAG(LFS_TYPE_INLINESTRUCT, file->id, 0);\n        file->flags |= LFS_F_DIRTY;\n#endif\n    } else {\n        // try to load what's on disk, if it's inlined we'll fix it later\n        tag = lfs_dir_get(lfs, &file->m, LFS_MKTAG(0x700, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_STRUCT, file->id, 8), &file->ctz);\n        if (tag < 0) {\n            err = tag;\n            goto cleanup;\n        }\n        lfs_ctz_fromle32(&file->ctz);\n    }\n\n    // fetch attrs\n    for (unsigned i = 0; i < file->cfg->attr_count; i++) {\n        // if opened for read / read-write operations\n        if ((file->flags & LFS_O_RDONLY) == LFS_O_RDONLY) {\n            lfs_stag_t res = lfs_dir_get(lfs, &file->m,\n                    LFS_MKTAG(0x7ff, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_USERATTR + file->cfg->attrs[i].type,\n                        file->id, file->cfg->attrs[i].size),\n                        file->cfg->attrs[i].buffer);\n            if (res < 0 && res != LFS_ERR_NOENT) {\n                err = res;\n                goto cleanup;\n            }\n        }\n\n#ifndef LFS_READONLY\n        // if opened for write / read-write operations\n        if ((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY) {\n            if (file->cfg->attrs[i].size > lfs->attr_max) {\n                err = LFS_ERR_NOSPC;\n                goto cleanup;\n            }\n\n            file->flags |= LFS_F_DIRTY;\n        }\n#endif\n    }\n\n    // allocate buffer if needed\n    if (file->cfg->buffer) {\n        file->cache.buffer = file->cfg->buffer;\n    } else {\n        file->cache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!file->cache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // zero to avoid information leak\n    lfs_cache_zero(lfs, &file->cache);\n\n    if (lfs_tag_type3(tag) == LFS_TYPE_INLINESTRUCT) {\n        // load inline files\n        file->ctz.head = LFS_BLOCK_INLINE;\n        file->ctz.size = lfs_tag_size(tag);\n        file->flags |= LFS_F_INLINE;\n        file->cache.block = file->ctz.head;\n        file->cache.off = 0;\n        file->cache.size = lfs->cfg->cache_size;\n\n        // don't always read (may be new/trunc file)\n        if (file->ctz.size > 0) {\n            lfs_stag_t res = lfs_dir_get(lfs, &file->m,\n                    LFS_MKTAG(0x700, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_STRUCT, file->id,\n                        lfs_min(file->cache.size, 0x3fe)),\n                    file->cache.buffer);\n            if (res < 0) {\n                err = res;\n                goto cleanup;\n            }\n        }\n    }\n\n    return 0;\n\ncleanup:\n    // clean up lingering resources\n#ifndef LFS_READONLY\n    file->flags |= LFS_F_ERRED;\n#endif\n    lfs_file_close_(lfs, file);\n    return err;\n}\n\n#ifndef LFS_NO_MALLOC\nstatic int lfs_file_open_(lfs_t *lfs, lfs_file_t *file,\n        const char *path, int flags) {\n    static const struct lfs_file_config defaults = {0};\n    int err = lfs_file_opencfg_(lfs, file, path, flags, &defaults);\n    return err;\n}\n#endif\n\nstatic int lfs_file_close_(lfs_t *lfs, lfs_file_t *file) {\n#ifndef LFS_READONLY\n    int err = lfs_file_sync_(lfs, file);\n#else\n    int err = 0;\n#endif\n\n    // remove from list of mdirs\n    lfs_mlist_remove(lfs, (struct lfs_mlist*)file);\n\n    // clean up memory\n    if (!file->cfg->buffer) {\n        lfs_free(file->cache.buffer);\n    }\n\n    return err;\n}\n\n\n#ifndef LFS_READONLY\nstatic int lfs_file_relocate(lfs_t *lfs, lfs_file_t *file) {\n    while (true) {\n        // just relocate what exists into new block\n        lfs_block_t nblock;\n        int err = lfs_alloc(lfs, &nblock);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_bd_erase(lfs, nblock);\n        if (err) {\n            if (err == LFS_ERR_CORRUPT) {\n                goto relocate;\n            }\n            return err;\n        }\n\n        // either read from dirty cache or disk\n        for (lfs_off_t i = 0; i < file->off; i++) {\n            uint8_t data;\n            if (file->flags & LFS_F_INLINE) {\n                err = lfs_dir_getread(lfs, &file->m,\n                        // note we evict inline files before they can be dirty\n                        NULL, &file->cache, file->off-i,\n                        LFS_MKTAG(0xfff, 0x1ff, 0),\n                        LFS_MKTAG(LFS_TYPE_INLINESTRUCT, file->id, 0),\n                        i, &data, 1);\n                if (err) {\n                    return err;\n                }\n            } else {\n                err = lfs_bd_read(lfs,\n                        &file->cache, &lfs->rcache, file->off-i,\n                        file->block, i, &data, 1);\n                if (err) {\n                    return err;\n                }\n            }\n\n            err = lfs_bd_prog(lfs,\n                    &lfs->pcache, &lfs->rcache, true,\n                    nblock, i, &data, 1);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                return err;\n            }\n        }\n\n        // copy over new state of file\n        memcpy(file->cache.buffer, lfs->pcache.buffer, lfs->cfg->cache_size);\n        file->cache.block = lfs->pcache.block;\n        file->cache.off = lfs->pcache.off;\n        file->cache.size = lfs->pcache.size;\n        lfs_cache_zero(lfs, &lfs->pcache);\n\n        file->block = nblock;\n        file->flags |= LFS_F_WRITING;\n        return 0;\n\nrelocate:\n        LFS_DEBUG(\"Bad block at 0x%\"PRIx32, nblock);\n\n        // just clear cache and try a new block\n        lfs_cache_drop(lfs, &lfs->pcache);\n    }\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_file_outline(lfs_t *lfs, lfs_file_t *file) {\n    file->off = file->pos;\n    lfs_alloc_ckpoint(lfs);\n    int err = lfs_file_relocate(lfs, file);\n    if (err) {\n        return err;\n    }\n\n    file->flags &= ~LFS_F_INLINE;\n    return 0;\n}\n#endif\n\nstatic int lfs_file_flush(lfs_t *lfs, lfs_file_t *file) {\n    if (file->flags & LFS_F_READING) {\n        if (!(file->flags & LFS_F_INLINE)) {\n            lfs_cache_drop(lfs, &file->cache);\n        }\n        file->flags &= ~LFS_F_READING;\n    }\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        lfs_off_t pos = file->pos;\n\n        if (!(file->flags & LFS_F_INLINE)) {\n            // copy over anything after current branch\n            lfs_file_t orig = {\n                .ctz.head = file->ctz.head,\n                .ctz.size = file->ctz.size,\n                .flags = LFS_O_RDONLY,\n                .pos = file->pos,\n                .cache = lfs->rcache,\n            };\n            lfs_cache_drop(lfs, &lfs->rcache);\n\n            while (file->pos < file->ctz.size) {\n                // copy over a byte at a time, leave it up to caching\n                // to make this efficient\n                uint8_t data;\n                lfs_ssize_t res = lfs_file_flushedread(lfs, &orig, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                res = lfs_file_flushedwrite(lfs, file, &data, 1);\n                if (res < 0) {\n                    return res;\n                }\n\n                // keep our reference to the rcache in sync\n                if (lfs->rcache.block != LFS_BLOCK_NULL) {\n                    lfs_cache_drop(lfs, &orig.cache);\n                    lfs_cache_drop(lfs, &lfs->rcache);\n                }\n            }\n\n            // write out what we have\n            while (true) {\n                int err = lfs_bd_flush(lfs, &file->cache, &lfs->rcache, true);\n                if (err) {\n                    if (err == LFS_ERR_CORRUPT) {\n                        goto relocate;\n                    }\n                    return err;\n                }\n\n                break;\n\nrelocate:\n                LFS_DEBUG(\"Bad block at 0x%\"PRIx32, file->block);\n                err = lfs_file_relocate(lfs, file);\n                if (err) {\n                    return err;\n                }\n            }\n        } else {\n            file->pos = lfs_max(file->pos, file->ctz.size);\n        }\n\n        // actual file updates\n        file->ctz.head = file->block;\n        file->ctz.size = file->pos;\n        file->flags &= ~LFS_F_WRITING;\n        file->flags |= LFS_F_DIRTY;\n\n        file->pos = pos;\n    }\n#endif\n\n    return 0;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_file_sync_(lfs_t *lfs, lfs_file_t *file) {\n    if (file->flags & LFS_F_ERRED) {\n        // it's not safe to do anything if our file errored\n        return 0;\n    }\n\n    int err = lfs_file_flush(lfs, file);\n    if (err) {\n        file->flags |= LFS_F_ERRED;\n        return err;\n    }\n\n\n    if ((file->flags & LFS_F_DIRTY) &&\n            !lfs_pair_isnull(file->m.pair)) {\n        // before we commit metadata, we need sync the disk to make sure\n        // data writes don't complete after metadata writes\n        if (!(file->flags & LFS_F_INLINE)) {\n            err = lfs_bd_sync(lfs, &lfs->pcache, &lfs->rcache, false);\n            if (err) {\n                return err;\n            }\n        }\n\n        // update dir entry\n        uint16_t type;\n        const void *buffer;\n        lfs_size_t size;\n        struct lfs_ctz ctz;\n        if (file->flags & LFS_F_INLINE) {\n            // inline the whole file\n            type = LFS_TYPE_INLINESTRUCT;\n            buffer = file->cache.buffer;\n            size = file->ctz.size;\n        } else {\n            // update the ctz reference\n            type = LFS_TYPE_CTZSTRUCT;\n            // copy ctz so alloc will work during a relocate\n            ctz = file->ctz;\n            lfs_ctz_tole32(&ctz);\n            buffer = &ctz;\n            size = sizeof(ctz);\n        }\n\n        // commit file data and attributes\n        err = lfs_dir_commit(lfs, &file->m, LFS_MKATTRS(\n                {LFS_MKTAG(type, file->id, size), buffer},\n                {LFS_MKTAG(LFS_FROM_USERATTRS, file->id,\n                    file->cfg->attr_count), file->cfg->attrs}));\n        if (err) {\n            file->flags |= LFS_F_ERRED;\n            return err;\n        }\n\n        file->flags &= ~LFS_F_DIRTY;\n    }\n\n    return 0;\n}\n#endif\n\nstatic lfs_ssize_t lfs_file_flushedread(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size) {\n    uint8_t *data = buffer;\n    lfs_size_t nsize = size;\n\n    if (file->pos >= file->ctz.size) {\n        // eof if past end\n        return 0;\n    }\n\n    size = lfs_min(size, file->ctz.size - file->pos);\n    nsize = size;\n\n    while (nsize > 0) {\n        // check if we need a new block\n        if (!(file->flags & LFS_F_READING) ||\n                file->off == lfs->cfg->block_size) {\n            if (!(file->flags & LFS_F_INLINE)) {\n                int err = lfs_ctz_find(lfs, NULL, &file->cache,\n                        file->ctz.head, file->ctz.size,\n                        file->pos, &file->block, &file->off);\n                if (err) {\n                    return err;\n                }\n            } else {\n                file->block = LFS_BLOCK_INLINE;\n                file->off = file->pos;\n            }\n\n            file->flags |= LFS_F_READING;\n        }\n\n        // read as much as we can in current block\n        lfs_size_t diff = lfs_min(nsize, lfs->cfg->block_size - file->off);\n        if (file->flags & LFS_F_INLINE) {\n            int err = lfs_dir_getread(lfs, &file->m,\n                    NULL, &file->cache, lfs->cfg->block_size,\n                    LFS_MKTAG(0xfff, 0x1ff, 0),\n                    LFS_MKTAG(LFS_TYPE_INLINESTRUCT, file->id, 0),\n                    file->off, data, diff);\n            if (err) {\n                return err;\n            }\n        } else {\n            int err = lfs_bd_read(lfs,\n                    NULL, &file->cache, lfs->cfg->block_size,\n                    file->block, file->off, data, diff);\n            if (err) {\n                return err;\n            }\n        }\n\n        file->pos += diff;\n        file->off += diff;\n        data += diff;\n        nsize -= diff;\n    }\n\n    return size;\n}\n\nstatic lfs_ssize_t lfs_file_read_(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size) {\n    LFS_ASSERT((file->flags & LFS_O_RDONLY) == LFS_O_RDONLY);\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        // flush out any writes\n        int err = lfs_file_flush(lfs, file);\n        if (err) {\n            return err;\n        }\n    }\n#endif\n\n    return lfs_file_flushedread(lfs, file, buffer, size);\n}\n\n\n#ifndef LFS_READONLY\nstatic lfs_ssize_t lfs_file_flushedwrite(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    const uint8_t *data = buffer;\n    lfs_size_t nsize = size;\n\n    if ((file->flags & LFS_F_INLINE) &&\n            lfs_max(file->pos+nsize, file->ctz.size) > lfs->inline_max) {\n        // inline file doesn't fit anymore\n        int err = lfs_file_outline(lfs, file);\n        if (err) {\n            file->flags |= LFS_F_ERRED;\n            return err;\n        }\n    }\n\n    while (nsize > 0) {\n        // check if we need a new block\n        if (!(file->flags & LFS_F_WRITING) ||\n                file->off == lfs->cfg->block_size) {\n            if (!(file->flags & LFS_F_INLINE)) {\n                if (!(file->flags & LFS_F_WRITING) && file->pos > 0) {\n                    // find out which block we're extending from\n                    int err = lfs_ctz_find(lfs, NULL, &file->cache,\n                            file->ctz.head, file->ctz.size,\n                            file->pos-1, &file->block, &(lfs_off_t){0});\n                    if (err) {\n                        file->flags |= LFS_F_ERRED;\n                        return err;\n                    }\n\n                    // mark cache as dirty since we may have read data into it\n                    lfs_cache_zero(lfs, &file->cache);\n                }\n\n                // extend file with new blocks\n                lfs_alloc_ckpoint(lfs);\n                int err = lfs_ctz_extend(lfs, &file->cache, &lfs->rcache,\n                        file->block, file->pos,\n                        &file->block, &file->off);\n                if (err) {\n                    file->flags |= LFS_F_ERRED;\n                    return err;\n                }\n            } else {\n                file->block = LFS_BLOCK_INLINE;\n                file->off = file->pos;\n            }\n\n            file->flags |= LFS_F_WRITING;\n        }\n\n        // program as much as we can in current block\n        lfs_size_t diff = lfs_min(nsize, lfs->cfg->block_size - file->off);\n        while (true) {\n            int err = lfs_bd_prog(lfs, &file->cache, &lfs->rcache, true,\n                    file->block, file->off, data, diff);\n            if (err) {\n                if (err == LFS_ERR_CORRUPT) {\n                    goto relocate;\n                }\n                file->flags |= LFS_F_ERRED;\n                return err;\n            }\n\n            break;\nrelocate:\n            err = lfs_file_relocate(lfs, file);\n            if (err) {\n                file->flags |= LFS_F_ERRED;\n                return err;\n            }\n        }\n\n        file->pos += diff;\n        file->off += diff;\n        data += diff;\n        nsize -= diff;\n\n        lfs_alloc_ckpoint(lfs);\n    }\n\n    return size;\n}\n\nstatic lfs_ssize_t lfs_file_write_(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    LFS_ASSERT((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY);\n\n    if (file->flags & LFS_F_READING) {\n        // drop any reads\n        int err = lfs_file_flush(lfs, file);\n        if (err) {\n            return err;\n        }\n    }\n\n    if ((file->flags & LFS_O_APPEND) && file->pos < file->ctz.size) {\n        file->pos = file->ctz.size;\n    }\n\n    if (file->pos + size > lfs->file_max) {\n        // Larger than file limit?\n        return LFS_ERR_FBIG;\n    }\n\n    if (!(file->flags & LFS_F_WRITING) && file->pos > file->ctz.size) {\n        // fill with zeros\n        lfs_off_t pos = file->pos;\n        file->pos = file->ctz.size;\n\n        while (file->pos < pos) {\n            lfs_ssize_t res = lfs_file_flushedwrite(lfs, file, &(uint8_t){0}, 1);\n            if (res < 0) {\n                return res;\n            }\n        }\n    }\n\n    lfs_ssize_t nsize = lfs_file_flushedwrite(lfs, file, buffer, size);\n    if (nsize < 0) {\n        return nsize;\n    }\n\n    file->flags &= ~LFS_F_ERRED;\n    return nsize;\n}\n#endif\n\nstatic lfs_soff_t lfs_file_seek_(lfs_t *lfs, lfs_file_t *file,\n        lfs_soff_t off, int whence) {\n    // find new pos\n    //\n    // fortunately for us, littlefs is limited to 31-bit file sizes, so we\n    // don't have to worry too much about integer overflow\n    lfs_off_t npos = file->pos;\n    if (whence == LFS_SEEK_SET) {\n        npos = off;\n    } else if (whence == LFS_SEEK_CUR) {\n        npos = file->pos + (lfs_off_t)off;\n    } else if (whence == LFS_SEEK_END) {\n        npos = (lfs_off_t)lfs_file_size_(lfs, file) + (lfs_off_t)off;\n    }\n\n    if (npos > lfs->file_max) {\n        // file position out of range\n        return LFS_ERR_INVAL;\n    }\n\n    if (file->pos == npos) {\n        // noop - position has not changed\n        return npos;\n    }\n\n    // if we're only reading and our new offset is still in the file's cache\n    // we can avoid flushing and needing to reread the data\n    if ((file->flags & LFS_F_READING)\n            && file->off != lfs->cfg->block_size) {\n        int oindex = lfs_ctz_index(lfs, &(lfs_off_t){file->pos});\n        lfs_off_t noff = npos;\n        int nindex = lfs_ctz_index(lfs, &noff);\n        if (oindex == nindex\n                && noff >= file->cache.off\n                && noff < file->cache.off + file->cache.size) {\n            file->pos = npos;\n            file->off = noff;\n            return npos;\n        }\n    }\n\n    // write out everything beforehand, may be noop if rdonly\n    int err = lfs_file_flush(lfs, file);\n    if (err) {\n        return err;\n    }\n\n    // update pos\n    file->pos = npos;\n    return npos;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_file_truncate_(lfs_t *lfs, lfs_file_t *file, lfs_off_t size) {\n    LFS_ASSERT((file->flags & LFS_O_WRONLY) == LFS_O_WRONLY);\n\n    if (size > LFS_FILE_MAX) {\n        return LFS_ERR_INVAL;\n    }\n\n    lfs_off_t pos = file->pos;\n    lfs_off_t oldsize = lfs_file_size_(lfs, file);\n    if (size < oldsize) {\n        // revert to inline file?\n        if (size <= lfs->inline_max) {\n            // flush+seek to head\n            lfs_soff_t res = lfs_file_seek_(lfs, file, 0, LFS_SEEK_SET);\n            if (res < 0) {\n                return (int)res;\n            }\n\n            // read our data into rcache temporarily\n            lfs_cache_drop(lfs, &lfs->rcache);\n            res = lfs_file_flushedread(lfs, file,\n                    lfs->rcache.buffer, size);\n            if (res < 0) {\n                return (int)res;\n            }\n\n            file->ctz.head = LFS_BLOCK_INLINE;\n            file->ctz.size = size;\n            file->flags |= LFS_F_DIRTY | LFS_F_READING | LFS_F_INLINE;\n            file->cache.block = file->ctz.head;\n            file->cache.off = 0;\n            file->cache.size = lfs->cfg->cache_size;\n            memcpy(file->cache.buffer, lfs->rcache.buffer, size);\n\n        } else {\n            // need to flush since directly changing metadata\n            int err = lfs_file_flush(lfs, file);\n            if (err) {\n                return err;\n            }\n\n            // lookup new head in ctz skip list\n            err = lfs_ctz_find(lfs, NULL, &file->cache,\n                    file->ctz.head, file->ctz.size,\n                    size-1, &file->block, &(lfs_off_t){0});\n            if (err) {\n                return err;\n            }\n\n            // need to set pos/block/off consistently so seeking back to\n            // the old position does not get confused\n            file->pos = size;\n            file->ctz.head = file->block;\n            file->ctz.size = size;\n            file->flags |= LFS_F_DIRTY | LFS_F_READING;\n        }\n    } else if (size > oldsize) {\n        // flush+seek if not already at end\n        lfs_soff_t res = lfs_file_seek_(lfs, file, 0, LFS_SEEK_END);\n        if (res < 0) {\n            return (int)res;\n        }\n\n        // fill with zeros\n        while (file->pos < size) {\n            res = lfs_file_write_(lfs, file, &(uint8_t){0}, 1);\n            if (res < 0) {\n                return (int)res;\n            }\n        }\n    }\n\n    // restore pos\n    lfs_soff_t res = lfs_file_seek_(lfs, file, pos, LFS_SEEK_SET);\n    if (res < 0) {\n      return (int)res;\n    }\n\n    return 0;\n}\n#endif\n\nstatic lfs_soff_t lfs_file_tell_(lfs_t *lfs, lfs_file_t *file) {\n    (void)lfs;\n    return file->pos;\n}\n\nstatic int lfs_file_rewind_(lfs_t *lfs, lfs_file_t *file) {\n    lfs_soff_t res = lfs_file_seek_(lfs, file, 0, LFS_SEEK_SET);\n    if (res < 0) {\n        return (int)res;\n    }\n\n    return 0;\n}\n\nstatic lfs_soff_t lfs_file_size_(lfs_t *lfs, lfs_file_t *file) {\n    (void)lfs;\n\n#ifndef LFS_READONLY\n    if (file->flags & LFS_F_WRITING) {\n        return lfs_max(file->pos, file->ctz.size);\n    }\n#endif\n\n    return file->ctz.size;\n}\n\n\n/// General fs operations ///\nstatic int lfs_stat_(lfs_t *lfs, const char *path, struct lfs_info *info) {\n    lfs_mdir_t cwd;\n    lfs_stag_t tag = lfs_dir_find(lfs, &cwd, &path, NULL);\n    if (tag < 0) {\n        return (int)tag;\n    }\n\n    // only allow trailing slashes on dirs\n    if (strchr(path, '/') != NULL\n            && lfs_tag_type3(tag) != LFS_TYPE_DIR) {\n        return LFS_ERR_NOTDIR;\n    }\n\n    return lfs_dir_getinfo(lfs, &cwd, lfs_tag_id(tag), info);\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_remove_(lfs_t *lfs, const char *path) {\n    // deorphan if we haven't yet, needed at most once after poweron\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    lfs_mdir_t cwd;\n    lfs_stag_t tag = lfs_dir_find(lfs, &cwd, &path, NULL);\n    if (tag < 0 || lfs_tag_id(tag) == 0x3ff) {\n        return (tag < 0) ? (int)tag : LFS_ERR_INVAL;\n    }\n\n    struct lfs_mlist dir;\n    dir.next = lfs->mlist;\n    if (lfs_tag_type3(tag) == LFS_TYPE_DIR) {\n        // must be empty before removal\n        lfs_block_t pair[2];\n        lfs_stag_t res = lfs_dir_get(lfs, &cwd, LFS_MKTAG(0x700, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_STRUCT, lfs_tag_id(tag), 8), pair);\n        if (res < 0) {\n            return (int)res;\n        }\n        lfs_pair_fromle32(pair);\n\n        err = lfs_dir_fetch(lfs, &dir.m, pair);\n        if (err) {\n            return err;\n        }\n\n        if (dir.m.count > 0 || dir.m.split) {\n            return LFS_ERR_NOTEMPTY;\n        }\n\n        // mark fs as orphaned\n        err = lfs_fs_preporphans(lfs, +1);\n        if (err) {\n            return err;\n        }\n\n        // I know it's crazy but yes, dir can be changed by our parent's\n        // commit (if predecessor is child)\n        dir.type = 0;\n        dir.id = 0;\n        lfs->mlist = &dir;\n    }\n\n    // delete the entry\n    err = lfs_dir_commit(lfs, &cwd, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_DELETE, lfs_tag_id(tag), 0), NULL}));\n    if (err) {\n        lfs->mlist = dir.next;\n        return err;\n    }\n\n    lfs->mlist = dir.next;\n    if (lfs_tag_type3(tag) == LFS_TYPE_DIR) {\n        // fix orphan\n        err = lfs_fs_preporphans(lfs, -1);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_fs_pred(lfs, dir.m.pair, &cwd);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_dir_drop(lfs, &cwd, &dir.m);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_rename_(lfs_t *lfs, const char *oldpath, const char *newpath) {\n    // deorphan if we haven't yet, needed at most once after poweron\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    // find old entry\n    lfs_mdir_t oldcwd;\n    lfs_stag_t oldtag = lfs_dir_find(lfs, &oldcwd, &oldpath, NULL);\n    if (oldtag < 0 || lfs_tag_id(oldtag) == 0x3ff) {\n        return (oldtag < 0) ? (int)oldtag : LFS_ERR_INVAL;\n    }\n\n    // find new entry\n    lfs_mdir_t newcwd;\n    uint16_t newid;\n    lfs_stag_t prevtag = lfs_dir_find(lfs, &newcwd, &newpath, &newid);\n    if ((prevtag < 0 || lfs_tag_id(prevtag) == 0x3ff) &&\n            !(prevtag == LFS_ERR_NOENT && lfs_path_islast(newpath))) {\n        return (prevtag < 0) ? (int)prevtag : LFS_ERR_INVAL;\n    }\n\n    // if we're in the same pair there's a few special cases...\n    bool samepair = (lfs_pair_cmp(oldcwd.pair, newcwd.pair) == 0);\n    uint16_t newoldid = lfs_tag_id(oldtag);\n\n    struct lfs_mlist prevdir;\n    prevdir.next = lfs->mlist;\n    if (prevtag == LFS_ERR_NOENT) {\n        // if we're a file, don't allow trailing slashes\n        if (lfs_path_isdir(newpath)\n                && lfs_tag_type3(oldtag) != LFS_TYPE_DIR) {\n            return LFS_ERR_NOTDIR;\n        }\n\n        // check that name fits\n        lfs_size_t nlen = lfs_path_namelen(newpath);\n        if (nlen > lfs->name_max) {\n            return LFS_ERR_NAMETOOLONG;\n        }\n\n        // there is a small chance we are being renamed in the same\n        // directory/ to an id less than our old id, the global update\n        // to handle this is a bit messy\n        if (samepair && newid <= newoldid) {\n            newoldid += 1;\n        }\n    } else if (lfs_tag_type3(prevtag) != lfs_tag_type3(oldtag)) {\n        return (lfs_tag_type3(prevtag) == LFS_TYPE_DIR)\n                ? LFS_ERR_ISDIR\n                : LFS_ERR_NOTDIR;\n    } else if (samepair && newid == newoldid) {\n        // we're renaming to ourselves??\n        return 0;\n    } else if (lfs_tag_type3(prevtag) == LFS_TYPE_DIR) {\n        // must be empty before removal\n        lfs_block_t prevpair[2];\n        lfs_stag_t res = lfs_dir_get(lfs, &newcwd, LFS_MKTAG(0x700, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_STRUCT, newid, 8), prevpair);\n        if (res < 0) {\n            return (int)res;\n        }\n        lfs_pair_fromle32(prevpair);\n\n        // must be empty before removal\n        err = lfs_dir_fetch(lfs, &prevdir.m, prevpair);\n        if (err) {\n            return err;\n        }\n\n        if (prevdir.m.count > 0 || prevdir.m.split) {\n            return LFS_ERR_NOTEMPTY;\n        }\n\n        // mark fs as orphaned\n        err = lfs_fs_preporphans(lfs, +1);\n        if (err) {\n            return err;\n        }\n\n        // I know it's crazy but yes, dir can be changed by our parent's\n        // commit (if predecessor is child)\n        prevdir.type = 0;\n        prevdir.id = 0;\n        lfs->mlist = &prevdir;\n    }\n\n    if (!samepair) {\n        lfs_fs_prepmove(lfs, newoldid, oldcwd.pair);\n    }\n\n    // move over all attributes\n    err = lfs_dir_commit(lfs, &newcwd, LFS_MKATTRS(\n            {LFS_MKTAG_IF(prevtag != LFS_ERR_NOENT,\n                LFS_TYPE_DELETE, newid, 0), NULL},\n            {LFS_MKTAG(LFS_TYPE_CREATE, newid, 0), NULL},\n            {LFS_MKTAG(lfs_tag_type3(oldtag),\n                newid, lfs_path_namelen(newpath)), newpath},\n            {LFS_MKTAG(LFS_FROM_MOVE, newid, lfs_tag_id(oldtag)), &oldcwd},\n            {LFS_MKTAG_IF(samepair,\n                LFS_TYPE_DELETE, newoldid, 0), NULL}));\n    if (err) {\n        lfs->mlist = prevdir.next;\n        return err;\n    }\n\n    // let commit clean up after move (if we're different! otherwise move\n    // logic already fixed it for us)\n    if (!samepair && lfs_gstate_hasmove(&lfs->gstate)) {\n        // prep gstate and delete move id\n        lfs_fs_prepmove(lfs, 0x3ff, NULL);\n        err = lfs_dir_commit(lfs, &oldcwd, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_DELETE, lfs_tag_id(oldtag), 0), NULL}));\n        if (err) {\n            lfs->mlist = prevdir.next;\n            return err;\n        }\n    }\n\n    lfs->mlist = prevdir.next;\n    if (prevtag != LFS_ERR_NOENT\n            && lfs_tag_type3(prevtag) == LFS_TYPE_DIR) {\n        // fix orphan\n        err = lfs_fs_preporphans(lfs, -1);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_fs_pred(lfs, prevdir.m.pair, &newcwd);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_dir_drop(lfs, &newcwd, &prevdir.m);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\nstatic lfs_ssize_t lfs_getattr_(lfs_t *lfs, const char *path,\n        uint8_t type, void *buffer, lfs_size_t size) {\n    lfs_mdir_t cwd;\n    lfs_stag_t tag = lfs_dir_find(lfs, &cwd, &path, NULL);\n    if (tag < 0) {\n        return tag;\n    }\n\n    uint16_t id = lfs_tag_id(tag);\n    if (id == 0x3ff) {\n        // special case for root\n        id = 0;\n        int err = lfs_dir_fetch(lfs, &cwd, lfs->root);\n        if (err) {\n            return err;\n        }\n    }\n\n    tag = lfs_dir_get(lfs, &cwd, LFS_MKTAG(0x7ff, 0x3ff, 0),\n            LFS_MKTAG(LFS_TYPE_USERATTR + type,\n                id, lfs_min(size, lfs->attr_max)),\n            buffer);\n    if (tag < 0) {\n        if (tag == LFS_ERR_NOENT) {\n            return LFS_ERR_NOATTR;\n        }\n\n        return tag;\n    }\n\n    return lfs_tag_size(tag);\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_commitattr(lfs_t *lfs, const char *path,\n        uint8_t type, const void *buffer, lfs_size_t size) {\n    lfs_mdir_t cwd;\n    lfs_stag_t tag = lfs_dir_find(lfs, &cwd, &path, NULL);\n    if (tag < 0) {\n        return tag;\n    }\n\n    uint16_t id = lfs_tag_id(tag);\n    if (id == 0x3ff) {\n        // special case for root\n        id = 0;\n        int err = lfs_dir_fetch(lfs, &cwd, lfs->root);\n        if (err) {\n            return err;\n        }\n    }\n\n    return lfs_dir_commit(lfs, &cwd, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_USERATTR + type, id, size), buffer}));\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_setattr_(lfs_t *lfs, const char *path,\n        uint8_t type, const void *buffer, lfs_size_t size) {\n    if (size > lfs->attr_max) {\n        return LFS_ERR_NOSPC;\n    }\n\n    return lfs_commitattr(lfs, path, type, buffer, size);\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_removeattr_(lfs_t *lfs, const char *path, uint8_t type) {\n    return lfs_commitattr(lfs, path, type, NULL, 0x3ff);\n}\n#endif\n\n\n/// Filesystem operations ///\n\n// compile time checks, see lfs.h for why these limits exist\n#if LFS_NAME_MAX > 1022\n#error \"Invalid LFS_NAME_MAX, must be <= 1022\"\n#endif\n\n#if LFS_FILE_MAX > 2147483647\n#error \"Invalid LFS_FILE_MAX, must be <= 2147483647\"\n#endif\n\n#if LFS_ATTR_MAX > 1022\n#error \"Invalid LFS_ATTR_MAX, must be <= 1022\"\n#endif\n\n// common filesystem initialization\nstatic int lfs_init(lfs_t *lfs, const struct lfs_config *cfg) {\n    lfs->cfg = cfg;\n    lfs->block_count = cfg->block_count;  // May be 0\n    int err = 0;\n\n#ifdef LFS_MULTIVERSION\n    // this driver only supports minor version < current minor version\n    LFS_ASSERT(!lfs->cfg->disk_version || (\n            (0xffff & (lfs->cfg->disk_version >> 16))\n                    == LFS_DISK_VERSION_MAJOR\n                && (0xffff & (lfs->cfg->disk_version >> 0))\n                    <= LFS_DISK_VERSION_MINOR));\n#endif\n\n    // check that bool is a truthy-preserving type\n    //\n    // note the most common reason for this failure is a before-c99 compiler,\n    // which littlefs currently does not support\n    LFS_ASSERT((bool)0x80000000);\n\n    // check that the required io functions are provided\n    LFS_ASSERT(lfs->cfg->read != NULL);\n#ifndef LFS_READONLY\n    LFS_ASSERT(lfs->cfg->prog != NULL);\n    LFS_ASSERT(lfs->cfg->erase != NULL);\n    LFS_ASSERT(lfs->cfg->sync != NULL);\n#endif\n\n    // validate that the lfs-cfg sizes were initiated properly before\n    // performing any arithmetic logics with them\n    LFS_ASSERT(lfs->cfg->read_size != 0);\n    LFS_ASSERT(lfs->cfg->prog_size != 0);\n    LFS_ASSERT(lfs->cfg->cache_size != 0);\n\n    // check that block size is a multiple of cache size is a multiple\n    // of prog and read sizes\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->read_size == 0);\n    LFS_ASSERT(lfs->cfg->cache_size % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(lfs->cfg->block_size % lfs->cfg->cache_size == 0);\n\n    // check that the block size is large enough to fit all ctz pointers\n    LFS_ASSERT(lfs->cfg->block_size >= 128);\n    // this is the exact calculation for all ctz pointers, if this fails\n    // and the simpler assert above does not, math must be broken\n    LFS_ASSERT(4*lfs_npw2(0xffffffff / (lfs->cfg->block_size-2*4))\n            <= lfs->cfg->block_size);\n\n    // block_cycles = 0 is no longer supported.\n    //\n    // block_cycles is the number of erase cycles before littlefs evicts\n    // metadata logs as a part of wear leveling. Suggested values are in the\n    // range of 100-1000, or set block_cycles to -1 to disable block-level\n    // wear-leveling.\n    LFS_ASSERT(lfs->cfg->block_cycles != 0);\n\n    // check that compact_thresh makes sense\n    //\n    // metadata can't be compacted below block_size/2, and metadata can't\n    // exceed a block_size\n    LFS_ASSERT(lfs->cfg->compact_thresh == 0\n            || lfs->cfg->compact_thresh >= lfs->cfg->block_size/2);\n    LFS_ASSERT(lfs->cfg->compact_thresh == (lfs_size_t)-1\n            || lfs->cfg->compact_thresh <= lfs->cfg->block_size);\n\n    // check that metadata_max is a multiple of read_size and prog_size,\n    // and a factor of the block_size\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->read_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->metadata_max % lfs->cfg->prog_size == 0);\n    LFS_ASSERT(!lfs->cfg->metadata_max\n            || lfs->cfg->block_size % lfs->cfg->metadata_max == 0);\n\n    // setup read cache\n    if (lfs->cfg->read_buffer) {\n        lfs->rcache.buffer = lfs->cfg->read_buffer;\n    } else {\n        lfs->rcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->rcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // setup program cache\n    if (lfs->cfg->prog_buffer) {\n        lfs->pcache.buffer = lfs->cfg->prog_buffer;\n    } else {\n        lfs->pcache.buffer = lfs_malloc(lfs->cfg->cache_size);\n        if (!lfs->pcache.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // zero to avoid information leaks\n    lfs_cache_zero(lfs, &lfs->rcache);\n    lfs_cache_zero(lfs, &lfs->pcache);\n\n    // setup lookahead buffer, note mount finishes initializing this after\n    // we establish a decent pseudo-random seed\n    LFS_ASSERT(lfs->cfg->lookahead_size > 0);\n    if (lfs->cfg->lookahead_buffer) {\n        lfs->lookahead.buffer = lfs->cfg->lookahead_buffer;\n    } else {\n        lfs->lookahead.buffer = lfs_malloc(lfs->cfg->lookahead_size);\n        if (!lfs->lookahead.buffer) {\n            err = LFS_ERR_NOMEM;\n            goto cleanup;\n        }\n    }\n\n    // check that the size limits are sane\n    LFS_ASSERT(lfs->cfg->name_max <= LFS_NAME_MAX);\n    lfs->name_max = lfs->cfg->name_max;\n    if (!lfs->name_max) {\n        lfs->name_max = LFS_NAME_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->file_max <= LFS_FILE_MAX);\n    lfs->file_max = lfs->cfg->file_max;\n    if (!lfs->file_max) {\n        lfs->file_max = LFS_FILE_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->attr_max <= LFS_ATTR_MAX);\n    lfs->attr_max = lfs->cfg->attr_max;\n    if (!lfs->attr_max) {\n        lfs->attr_max = LFS_ATTR_MAX;\n    }\n\n    LFS_ASSERT(lfs->cfg->metadata_max <= lfs->cfg->block_size);\n\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->cfg->cache_size);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= lfs->attr_max);\n    LFS_ASSERT(lfs->cfg->inline_max == (lfs_size_t)-1\n            || lfs->cfg->inline_max <= ((lfs->cfg->metadata_max)\n                ? lfs->cfg->metadata_max\n                : lfs->cfg->block_size)/8);\n    lfs->inline_max = lfs->cfg->inline_max;\n    if (lfs->inline_max == (lfs_size_t)-1) {\n        lfs->inline_max = 0;\n    } else if (lfs->inline_max == 0) {\n        lfs->inline_max = lfs_min(\n                lfs->cfg->cache_size,\n                lfs_min(\n                    lfs->attr_max,\n                    ((lfs->cfg->metadata_max)\n                        ? lfs->cfg->metadata_max\n                        : lfs->cfg->block_size)/8));\n    }\n\n    // setup default state\n    lfs->root[0] = LFS_BLOCK_NULL;\n    lfs->root[1] = LFS_BLOCK_NULL;\n    lfs->mlist = NULL;\n    lfs->seed = 0;\n    lfs->gdisk = (lfs_gstate_t){0};\n    lfs->gstate = (lfs_gstate_t){0};\n    lfs->gdelta = (lfs_gstate_t){0};\n#ifdef LFS_MIGRATE\n    lfs->lfs1 = NULL;\n#endif\n\n    return 0;\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n}\n\nstatic int lfs_deinit(lfs_t *lfs) {\n    // free allocated memory\n    if (!lfs->cfg->read_buffer) {\n        lfs_free(lfs->rcache.buffer);\n    }\n\n    if (!lfs->cfg->prog_buffer) {\n        lfs_free(lfs->pcache.buffer);\n    }\n\n    if (!lfs->cfg->lookahead_buffer) {\n        lfs_free(lfs->lookahead.buffer);\n    }\n\n    return 0;\n}\n\n\n\n#ifndef LFS_READONLY\nstatic int lfs_format_(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = 0;\n    {\n        err = lfs_init(lfs, cfg);\n        if (err) {\n            return err;\n        }\n\n        LFS_ASSERT(cfg->block_count != 0);\n\n        // create free lookahead\n        memset(lfs->lookahead.buffer, 0, lfs->cfg->lookahead_size);\n        lfs->lookahead.start = 0;\n        lfs->lookahead.size = lfs_min(8*lfs->cfg->lookahead_size,\n                lfs->block_count);\n        lfs->lookahead.next = 0;\n        lfs_alloc_ckpoint(lfs);\n\n        // create root dir\n        lfs_mdir_t root;\n        err = lfs_dir_alloc(lfs, &root);\n        if (err) {\n            goto cleanup;\n        }\n\n        // write one superblock\n        lfs_superblock_t superblock = {\n            .version     = lfs_fs_disk_version(lfs),\n            .block_size  = lfs->cfg->block_size,\n            .block_count = lfs->block_count,\n            .name_max    = lfs->name_max,\n            .file_max    = lfs->file_max,\n            .attr_max    = lfs->attr_max,\n        };\n\n        lfs_superblock_tole32(&superblock);\n        err = lfs_dir_commit(lfs, &root, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_CREATE, 0, 0), NULL},\n                {LFS_MKTAG(LFS_TYPE_SUPERBLOCK, 0, 8), \"littlefs\"},\n                {LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                    &superblock}));\n        if (err) {\n            goto cleanup;\n        }\n\n        // force compaction to prevent accidentally mounting any\n        // older version of littlefs that may live on disk\n        root.erased = false;\n        err = lfs_dir_commit(lfs, &root, NULL, 0);\n        if (err) {\n            goto cleanup;\n        }\n\n        // sanity check that fetch works\n        err = lfs_dir_fetch(lfs, &root, (const lfs_block_t[2]){0, 1});\n        if (err) {\n            goto cleanup;\n        }\n    }\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n\n}\n#endif\n\nstruct lfs_tortoise_t {\n    lfs_block_t pair[2];\n    lfs_size_t i;\n    lfs_size_t period;\n};\n\nstatic int lfs_tortoise_detectcycles(\n    const lfs_mdir_t *dir, struct lfs_tortoise_t *tortoise) {\n    // detect cycles with Brent's algorithm\n    if (lfs_pair_issync(dir->tail, tortoise->pair)) {\n        LFS_WARN(\"Cycle detected in tail list\");\n        return LFS_ERR_CORRUPT;\n    }\n    if (tortoise->i == tortoise->period) {\n        tortoise->pair[0] = dir->tail[0];\n        tortoise->pair[1] = dir->tail[1];\n        tortoise->i = 0;\n        tortoise->period *= 2;\n    }\n    tortoise->i += 1;\n\n    return LFS_ERR_OK;\n}\n\nstatic int lfs_mount_(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = lfs_init(lfs, cfg);\n    if (err) {\n        return err;\n    }\n\n    // scan directory blocks for superblock and any global updates\n    lfs_mdir_t dir = {.tail = {0, 1}};\n    struct lfs_tortoise_t tortoise = {\n        .pair = {LFS_BLOCK_NULL, LFS_BLOCK_NULL},\n        .i = 1,\n        .period = 1,\n    };\n    while (!lfs_pair_isnull(dir.tail)) {\n        err = lfs_tortoise_detectcycles(&dir, &tortoise);\n        if (err < 0) {\n            goto cleanup;\n        }\n\n        // fetch next block in tail list\n        lfs_stag_t tag = lfs_dir_fetchmatch(lfs, &dir, dir.tail,\n                LFS_MKTAG(0x7ff, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_SUPERBLOCK, 0, 8),\n                NULL,\n                lfs_dir_find_match, &(struct lfs_dir_find_match){\n                    lfs, \"littlefs\", 8});\n        if (tag < 0) {\n            err = tag;\n            goto cleanup;\n        }\n\n        // has superblock?\n        if (tag && !lfs_tag_isdelete(tag)) {\n            // update root\n            lfs->root[0] = dir.pair[0];\n            lfs->root[1] = dir.pair[1];\n\n            // grab superblock\n            lfs_superblock_t superblock;\n            tag = lfs_dir_get(lfs, &dir, LFS_MKTAG(0x7ff, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                    &superblock);\n            if (tag < 0) {\n                err = tag;\n                goto cleanup;\n            }\n            lfs_superblock_fromle32(&superblock);\n\n            // check version\n            uint16_t major_version = (0xffff & (superblock.version >> 16));\n            uint16_t minor_version = (0xffff & (superblock.version >>  0));\n            if (major_version != lfs_fs_disk_version_major(lfs)\n                    || minor_version > lfs_fs_disk_version_minor(lfs)) {\n                LFS_ERROR(\"Invalid version \"\n                        \"v%\"PRIu16\".%\"PRIu16\" != v%\"PRIu16\".%\"PRIu16,\n                        major_version,\n                        minor_version,\n                        lfs_fs_disk_version_major(lfs),\n                        lfs_fs_disk_version_minor(lfs));\n                err = LFS_ERR_INVAL;\n                goto cleanup;\n            }\n\n            // found older minor version? set an in-device only bit in the\n            // gstate so we know we need to rewrite the superblock before\n            // the first write\n            bool needssuperblock = false;\n            if (minor_version < lfs_fs_disk_version_minor(lfs)) {\n                LFS_DEBUG(\"Found older minor version \"\n                        \"v%\"PRIu16\".%\"PRIu16\" < v%\"PRIu16\".%\"PRIu16,\n                        major_version,\n                        minor_version,\n                        lfs_fs_disk_version_major(lfs),\n                        lfs_fs_disk_version_minor(lfs));\n                needssuperblock = true;\n            }\n            // note this bit is reserved on disk, so fetching more gstate\n            // will not interfere here\n            lfs_fs_prepsuperblock(lfs, needssuperblock);\n\n            // check superblock configuration\n            if (superblock.name_max) {\n                if (superblock.name_max > lfs->name_max) {\n                    LFS_ERROR(\"Unsupported name_max (%\"PRIu32\" > %\"PRIu32\")\",\n                            superblock.name_max, lfs->name_max);\n                    err = LFS_ERR_INVAL;\n                    goto cleanup;\n                }\n\n                lfs->name_max = superblock.name_max;\n            }\n\n            if (superblock.file_max) {\n                if (superblock.file_max > lfs->file_max) {\n                    LFS_ERROR(\"Unsupported file_max (%\"PRIu32\" > %\"PRIu32\")\",\n                            superblock.file_max, lfs->file_max);\n                    err = LFS_ERR_INVAL;\n                    goto cleanup;\n                }\n\n                lfs->file_max = superblock.file_max;\n            }\n\n            if (superblock.attr_max) {\n                if (superblock.attr_max > lfs->attr_max) {\n                    LFS_ERROR(\"Unsupported attr_max (%\"PRIu32\" > %\"PRIu32\")\",\n                            superblock.attr_max, lfs->attr_max);\n                    err = LFS_ERR_INVAL;\n                    goto cleanup;\n                }\n\n                lfs->attr_max = superblock.attr_max;\n\n                // we also need to update inline_max in case attr_max changed\n                lfs->inline_max = lfs_min(lfs->inline_max, lfs->attr_max);\n            }\n\n            // this is where we get the block_count from disk if block_count=0\n            if (lfs->cfg->block_count\n                    && superblock.block_count != lfs->cfg->block_count) {\n                LFS_ERROR(\"Invalid block count (%\"PRIu32\" != %\"PRIu32\")\",\n                        superblock.block_count, lfs->cfg->block_count);\n                err = LFS_ERR_INVAL;\n                goto cleanup;\n            }\n\n            lfs->block_count = superblock.block_count;\n\n            if (superblock.block_size != lfs->cfg->block_size) {\n                LFS_ERROR(\"Invalid block size (%\"PRIu32\" != %\"PRIu32\")\",\n                        superblock.block_size, lfs->cfg->block_size);\n                err = LFS_ERR_INVAL;\n                goto cleanup;\n            }\n        }\n\n        // has gstate?\n        err = lfs_dir_getgstate(lfs, &dir, &lfs->gstate);\n        if (err) {\n            goto cleanup;\n        }\n    }\n\n    // update littlefs with gstate\n    if (!lfs_gstate_iszero(&lfs->gstate)) {\n        LFS_DEBUG(\"Found pending gstate 0x%08\"PRIx32\"%08\"PRIx32\"%08\"PRIx32,\n                lfs->gstate.tag,\n                lfs->gstate.pair[0],\n                lfs->gstate.pair[1]);\n    }\n    lfs->gstate.tag += !lfs_tag_isvalid(lfs->gstate.tag);\n    lfs->gdisk = lfs->gstate;\n\n    // setup free lookahead, to distribute allocations uniformly across\n    // boots, we start the allocator at a random location\n    lfs->lookahead.start = lfs->seed % lfs->block_count;\n    lfs_alloc_drop(lfs);\n\n    return 0;\n\ncleanup:\n    lfs_unmount_(lfs);\n    return err;\n}\n\nstatic int lfs_unmount_(lfs_t *lfs) {\n    return lfs_deinit(lfs);\n}\n\n\n/// Filesystem filesystem operations ///\nstatic int lfs_fs_stat_(lfs_t *lfs, struct lfs_fsinfo *fsinfo) {\n    // if the superblock is up-to-date, we must be on the most recent\n    // minor version of littlefs\n    if (!lfs_gstate_needssuperblock(&lfs->gstate)) {\n        fsinfo->disk_version = lfs_fs_disk_version(lfs);\n\n    // otherwise we need to read the minor version on disk\n    } else {\n        // fetch the superblock\n        lfs_mdir_t dir;\n        int err = lfs_dir_fetch(lfs, &dir, lfs->root);\n        if (err) {\n            return err;\n        }\n\n        lfs_superblock_t superblock;\n        lfs_stag_t tag = lfs_dir_get(lfs, &dir, LFS_MKTAG(0x7ff, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                &superblock);\n        if (tag < 0) {\n            return tag;\n        }\n        lfs_superblock_fromle32(&superblock);\n\n        // read the on-disk version\n        fsinfo->disk_version = superblock.version;\n    }\n\n    // filesystem geometry\n    fsinfo->block_size = lfs->cfg->block_size;\n    fsinfo->block_count = lfs->block_count;\n\n    // other on-disk configuration, we cache all of these for internal use\n    fsinfo->name_max = lfs->name_max;\n    fsinfo->file_max = lfs->file_max;\n    fsinfo->attr_max = lfs->attr_max;\n\n    return 0;\n}\n\nint lfs_fs_traverse_(lfs_t *lfs,\n        int (*cb)(void *data, lfs_block_t block), void *data,\n        bool includeorphans) {\n    // iterate over metadata pairs\n    lfs_mdir_t dir = {.tail = {0, 1}};\n\n#ifdef LFS_MIGRATE\n    // also consider v1 blocks during migration\n    if (lfs->lfs1) {\n        int err = lfs1_traverse(lfs, cb, data);\n        if (err) {\n            return err;\n        }\n\n        dir.tail[0] = lfs->root[0];\n        dir.tail[1] = lfs->root[1];\n    }\n#endif\n\n    struct lfs_tortoise_t tortoise = {\n        .pair = {LFS_BLOCK_NULL, LFS_BLOCK_NULL},\n        .i = 1,\n        .period = 1,\n    };\n    int err = LFS_ERR_OK;\n    while (!lfs_pair_isnull(dir.tail)) {\n        err = lfs_tortoise_detectcycles(&dir, &tortoise);\n        if (err < 0) {\n            return LFS_ERR_CORRUPT;\n        }\n\n        for (int i = 0; i < 2; i++) {\n            int err = cb(data, dir.tail[i]);\n            if (err) {\n                return err;\n            }\n        }\n\n        // iterate through ids in directory\n        int err = lfs_dir_fetch(lfs, &dir, dir.tail);\n        if (err) {\n            return err;\n        }\n\n        for (uint16_t id = 0; id < dir.count; id++) {\n            struct lfs_ctz ctz;\n            lfs_stag_t tag = lfs_dir_get(lfs, &dir, LFS_MKTAG(0x700, 0x3ff, 0),\n                    LFS_MKTAG(LFS_TYPE_STRUCT, id, sizeof(ctz)), &ctz);\n            if (tag < 0) {\n                if (tag == LFS_ERR_NOENT) {\n                    continue;\n                }\n                return tag;\n            }\n            lfs_ctz_fromle32(&ctz);\n\n            if (lfs_tag_type3(tag) == LFS_TYPE_CTZSTRUCT) {\n                err = lfs_ctz_traverse(lfs, NULL, &lfs->rcache,\n                        ctz.head, ctz.size, cb, data);\n                if (err) {\n                    return err;\n                }\n            } else if (includeorphans &&\n                    lfs_tag_type3(tag) == LFS_TYPE_DIRSTRUCT) {\n                for (int i = 0; i < 2; i++) {\n                    err = cb(data, (&ctz.head)[i]);\n                    if (err) {\n                        return err;\n                    }\n                }\n            }\n        }\n    }\n\n#ifndef LFS_READONLY\n    // iterate over any open files\n    for (lfs_file_t *f = (lfs_file_t*)lfs->mlist; f; f = f->next) {\n        if (f->type != LFS_TYPE_REG) {\n            continue;\n        }\n\n        if ((f->flags & LFS_F_DIRTY) && !(f->flags & LFS_F_INLINE)) {\n            int err = lfs_ctz_traverse(lfs, &f->cache, &lfs->rcache,\n                    f->ctz.head, f->ctz.size, cb, data);\n            if (err) {\n                return err;\n            }\n        }\n\n        if ((f->flags & LFS_F_WRITING) && !(f->flags & LFS_F_INLINE)) {\n            int err = lfs_ctz_traverse(lfs, &f->cache, &lfs->rcache,\n                    f->block, f->pos, cb, data);\n            if (err) {\n                return err;\n            }\n        }\n    }\n#endif\n\n    return 0;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_pred(lfs_t *lfs,\n        const lfs_block_t pair[2], lfs_mdir_t *pdir) {\n    // iterate over all directory directory entries\n    pdir->tail[0] = 0;\n    pdir->tail[1] = 1;\n    struct lfs_tortoise_t tortoise = {\n        .pair = {LFS_BLOCK_NULL, LFS_BLOCK_NULL},\n        .i = 1,\n        .period = 1,\n    };\n    int err = LFS_ERR_OK;\n    while (!lfs_pair_isnull(pdir->tail)) {\n        err = lfs_tortoise_detectcycles(pdir, &tortoise);\n        if (err < 0) {\n            return LFS_ERR_CORRUPT;\n        }\n\n        if (lfs_pair_cmp(pdir->tail, pair) == 0) {\n            return 0;\n        }\n\n        int err = lfs_dir_fetch(lfs, pdir, pdir->tail);\n        if (err) {\n            return err;\n        }\n    }\n\n    return LFS_ERR_NOENT;\n}\n#endif\n\n#ifndef LFS_READONLY\nstruct lfs_fs_parent_match {\n    lfs_t *lfs;\n    const lfs_block_t pair[2];\n};\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_parent_match(void *data,\n        lfs_tag_t tag, const void *buffer) {\n    struct lfs_fs_parent_match *find = data;\n    lfs_t *lfs = find->lfs;\n    const struct lfs_diskoff *disk = buffer;\n    (void)tag;\n\n    lfs_block_t child[2];\n    int err = lfs_bd_read(lfs,\n            &lfs->pcache, &lfs->rcache, lfs->cfg->block_size,\n            disk->block, disk->off, &child, sizeof(child));\n    if (err) {\n        return err;\n    }\n\n    lfs_pair_fromle32(child);\n    return (lfs_pair_cmp(child, find->pair) == 0) ? LFS_CMP_EQ : LFS_CMP_LT;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic lfs_stag_t lfs_fs_parent(lfs_t *lfs, const lfs_block_t pair[2],\n        lfs_mdir_t *parent) {\n    // use fetchmatch with callback to find pairs\n    parent->tail[0] = 0;\n    parent->tail[1] = 1;\n    struct lfs_tortoise_t tortoise = {\n        .pair = {LFS_BLOCK_NULL, LFS_BLOCK_NULL},\n        .i = 1,\n        .period = 1,\n    };\n    int err = LFS_ERR_OK;\n    while (!lfs_pair_isnull(parent->tail)) {\n        err = lfs_tortoise_detectcycles(parent, &tortoise);\n        if (err < 0) {\n            return err;\n        }\n\n        lfs_stag_t tag = lfs_dir_fetchmatch(lfs, parent, parent->tail,\n                LFS_MKTAG(0x7ff, 0, 0x3ff),\n                LFS_MKTAG(LFS_TYPE_DIRSTRUCT, 0, 8),\n                NULL,\n                lfs_fs_parent_match, &(struct lfs_fs_parent_match){\n                    lfs, {pair[0], pair[1]}});\n        if (tag && tag != LFS_ERR_NOENT) {\n            return tag;\n        }\n    }\n\n    return LFS_ERR_NOENT;\n}\n#endif\n\nstatic void lfs_fs_prepsuperblock(lfs_t *lfs, bool needssuperblock) {\n    lfs->gstate.tag = (lfs->gstate.tag & ~LFS_MKTAG(0, 0, 0x200))\n            | (uint32_t)needssuperblock << 9;\n}\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_preporphans(lfs_t *lfs, int8_t orphans) {\n    LFS_ASSERT(lfs_tag_size(lfs->gstate.tag) > 0x000 || orphans >= 0);\n    LFS_ASSERT(lfs_tag_size(lfs->gstate.tag) < 0x1ff || orphans <= 0);\n    lfs->gstate.tag += orphans;\n    lfs->gstate.tag = ((lfs->gstate.tag & ~LFS_MKTAG(0x800, 0, 0)) |\n            ((uint32_t)lfs_gstate_hasorphans(&lfs->gstate) << 31));\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic void lfs_fs_prepmove(lfs_t *lfs,\n        uint16_t id, const lfs_block_t pair[2]) {\n    lfs->gstate.tag = ((lfs->gstate.tag & ~LFS_MKTAG(0x7ff, 0x3ff, 0)) |\n            ((id != 0x3ff) ? LFS_MKTAG(LFS_TYPE_DELETE, id, 0) : 0));\n    lfs->gstate.pair[0] = (id != 0x3ff) ? pair[0] : 0;\n    lfs->gstate.pair[1] = (id != 0x3ff) ? pair[1] : 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_desuperblock(lfs_t *lfs) {\n    if (!lfs_gstate_needssuperblock(&lfs->gstate)) {\n        return 0;\n    }\n\n    LFS_DEBUG(\"Rewriting superblock {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n            lfs->root[0],\n            lfs->root[1]);\n\n    lfs_mdir_t root;\n    int err = lfs_dir_fetch(lfs, &root, lfs->root);\n    if (err) {\n        return err;\n    }\n\n    // write a new superblock\n    lfs_superblock_t superblock = {\n        .version     = lfs_fs_disk_version(lfs),\n        .block_size  = lfs->cfg->block_size,\n        .block_count = lfs->block_count,\n        .name_max    = lfs->name_max,\n        .file_max    = lfs->file_max,\n        .attr_max    = lfs->attr_max,\n    };\n\n    lfs_superblock_tole32(&superblock);\n    err = lfs_dir_commit(lfs, &root, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                &superblock}));\n    if (err) {\n        return err;\n    }\n\n    lfs_fs_prepsuperblock(lfs, false);\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_demove(lfs_t *lfs) {\n    if (!lfs_gstate_hasmove(&lfs->gdisk)) {\n        return 0;\n    }\n\n    // Fix bad moves\n    LFS_DEBUG(\"Fixing move {0x%\"PRIx32\", 0x%\"PRIx32\"} 0x%\"PRIx16,\n            lfs->gdisk.pair[0],\n            lfs->gdisk.pair[1],\n            lfs_tag_id(lfs->gdisk.tag));\n\n    // no other gstate is supported at this time, so if we found something else\n    // something most likely went wrong in gstate calculation\n    LFS_ASSERT(lfs_tag_type3(lfs->gdisk.tag) == LFS_TYPE_DELETE);\n\n    // fetch and delete the moved entry\n    lfs_mdir_t movedir;\n    int err = lfs_dir_fetch(lfs, &movedir, lfs->gdisk.pair);\n    if (err) {\n        return err;\n    }\n\n    // prep gstate and delete move id\n    uint16_t moveid = lfs_tag_id(lfs->gdisk.tag);\n    lfs_fs_prepmove(lfs, 0x3ff, NULL);\n    err = lfs_dir_commit(lfs, &movedir, LFS_MKATTRS(\n            {LFS_MKTAG(LFS_TYPE_DELETE, moveid, 0), NULL}));\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_deorphan(lfs_t *lfs, bool powerloss) {\n    if (!lfs_gstate_hasorphans(&lfs->gstate)) {\n        return 0;\n    }\n\n    // Check for orphans in two separate passes:\n    // - 1 for half-orphans (relocations)\n    // - 2 for full-orphans (removes/renames)\n    //\n    // Two separate passes are needed as half-orphans can contain outdated\n    // references to full-orphans, effectively hiding them from the deorphan\n    // search.\n    //\n    int pass = 0;\n    while (pass < 2) {\n        // Fix any orphans\n        lfs_mdir_t pdir = {.split = true, .tail = {0, 1}};\n        lfs_mdir_t dir;\n        bool moreorphans = false;\n\n        // iterate over all directory directory entries\n        while (!lfs_pair_isnull(pdir.tail)) {\n            int err = lfs_dir_fetch(lfs, &dir, pdir.tail);\n            if (err) {\n                return err;\n            }\n\n            // check head blocks for orphans\n            if (!pdir.split) {\n                // check if we have a parent\n                lfs_mdir_t parent;\n                lfs_stag_t tag = lfs_fs_parent(lfs, pdir.tail, &parent);\n                if (tag < 0 && tag != LFS_ERR_NOENT) {\n                    return tag;\n                }\n\n                if (pass == 0 && tag != LFS_ERR_NOENT) {\n                    lfs_block_t pair[2];\n                    lfs_stag_t state = lfs_dir_get(lfs, &parent,\n                            LFS_MKTAG(0x7ff, 0x3ff, 0), tag, pair);\n                    if (state < 0) {\n                        return state;\n                    }\n                    lfs_pair_fromle32(pair);\n\n                    if (!lfs_pair_issync(pair, pdir.tail)) {\n                        // we have desynced\n                        LFS_DEBUG(\"Fixing half-orphan \"\n                                \"{0x%\"PRIx32\", 0x%\"PRIx32\"} \"\n                                \"-> {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                                pdir.tail[0], pdir.tail[1], pair[0], pair[1]);\n\n                        // fix pending move in this pair? this looks like an\n                        // optimization but is in fact _required_ since\n                        // relocating may outdate the move.\n                        uint16_t moveid = 0x3ff;\n                        if (lfs_gstate_hasmovehere(&lfs->gstate, pdir.pair)) {\n                            moveid = lfs_tag_id(lfs->gstate.tag);\n                            LFS_DEBUG(\"Fixing move while fixing orphans \"\n                                    \"{0x%\"PRIx32\", 0x%\"PRIx32\"} 0x%\"PRIx16\"\\n\",\n                                    pdir.pair[0], pdir.pair[1], moveid);\n                            lfs_fs_prepmove(lfs, 0x3ff, NULL);\n                        }\n\n                        lfs_pair_tole32(pair);\n                        state = lfs_dir_orphaningcommit(lfs, &pdir, LFS_MKATTRS(\n                                {LFS_MKTAG_IF(moveid != 0x3ff,\n                                    LFS_TYPE_DELETE, moveid, 0), NULL},\n                                {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8),\n                                    pair}));\n                        lfs_pair_fromle32(pair);\n                        if (state < 0) {\n                            return state;\n                        }\n\n                        // did our commit create more orphans?\n                        if (state == LFS_OK_ORPHANED) {\n                            moreorphans = true;\n                        }\n\n                        // refetch tail\n                        continue;\n                    }\n                }\n\n                // note we only check for full orphans if we may have had a\n                // power-loss, otherwise orphans are created intentionally\n                // during operations such as lfs_mkdir\n                if (pass == 1 && tag == LFS_ERR_NOENT && powerloss) {\n                    // we are an orphan\n                    LFS_DEBUG(\"Fixing orphan {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                            pdir.tail[0], pdir.tail[1]);\n\n                    // steal state\n                    err = lfs_dir_getgstate(lfs, &dir, &lfs->gdelta);\n                    if (err) {\n                        return err;\n                    }\n\n                    // steal tail\n                    lfs_pair_tole32(dir.tail);\n                    int state = lfs_dir_orphaningcommit(lfs, &pdir, LFS_MKATTRS(\n                            {LFS_MKTAG(LFS_TYPE_TAIL + dir.split, 0x3ff, 8),\n                                dir.tail}));\n                    lfs_pair_fromle32(dir.tail);\n                    if (state < 0) {\n                        return state;\n                    }\n\n                    // did our commit create more orphans?\n                    if (state == LFS_OK_ORPHANED) {\n                        moreorphans = true;\n                    }\n\n                    // refetch tail\n                    continue;\n                }\n            }\n\n            pdir = dir;\n        }\n\n        pass = moreorphans ? 0 : pass+1;\n    }\n\n    // mark orphans as fixed\n    return lfs_fs_preporphans(lfs, -lfs_gstate_getorphans(&lfs->gstate));\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_forceconsistency(lfs_t *lfs) {\n    int err = lfs_fs_desuperblock(lfs);\n    if (err) {\n        return err;\n    }\n\n    err = lfs_fs_demove(lfs);\n    if (err) {\n        return err;\n    }\n\n    err = lfs_fs_deorphan(lfs, true);\n    if (err) {\n        return err;\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_mkconsistent_(lfs_t *lfs) {\n    // lfs_fs_forceconsistency does most of the work here\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    // do we have any pending gstate?\n    lfs_gstate_t delta = {0};\n    lfs_gstate_xor(&delta, &lfs->gdisk);\n    lfs_gstate_xor(&delta, &lfs->gstate);\n    if (!lfs_gstate_iszero(&delta)) {\n        // lfs_dir_commit will implicitly write out any pending gstate\n        lfs_mdir_t root;\n        err = lfs_dir_fetch(lfs, &root, lfs->root);\n        if (err) {\n            return err;\n        }\n\n        err = lfs_dir_commit(lfs, &root, NULL, 0);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\nstatic int lfs_fs_size_count(void *p, lfs_block_t block) {\n    (void)block;\n    lfs_size_t *size = p;\n    *size += 1;\n    return 0;\n}\n\nstatic lfs_ssize_t lfs_fs_size_(lfs_t *lfs) {\n    lfs_size_t size = 0;\n    int err = lfs_fs_traverse_(lfs, lfs_fs_size_count, &size, false);\n    if (err) {\n        return err;\n    }\n\n    return size;\n}\n\n// explicit garbage collection\n#ifndef LFS_READONLY\nstatic int lfs_fs_gc_(lfs_t *lfs) {\n    // force consistency, even if we're not necessarily going to write,\n    // because this function is supposed to take care of janitorial work\n    // isn't it?\n    int err = lfs_fs_forceconsistency(lfs);\n    if (err) {\n        return err;\n    }\n\n    // try to compact metadata pairs, note we can't really accomplish\n    // anything if compact_thresh doesn't at least leave a prog_size\n    // available\n    if (lfs->cfg->compact_thresh\n            < lfs->cfg->block_size - lfs->cfg->prog_size) {\n        // iterate over all mdirs\n        lfs_mdir_t mdir = {.tail = {0, 1}};\n        while (!lfs_pair_isnull(mdir.tail)) {\n            err = lfs_dir_fetch(lfs, &mdir, mdir.tail);\n            if (err) {\n                return err;\n            }\n\n            // not erased? exceeds our compaction threshold?\n            if (!mdir.erased || ((lfs->cfg->compact_thresh == 0)\n                    ? mdir.off > lfs->cfg->block_size - lfs->cfg->block_size/8\n                    : mdir.off > lfs->cfg->compact_thresh)) {\n                // the easiest way to trigger a compaction is to mark\n                // the mdir as unerased and add an empty commit\n                mdir.erased = false;\n                err = lfs_dir_commit(lfs, &mdir, NULL, 0);\n                if (err) {\n                    return err;\n                }\n            }\n        }\n    }\n\n    // try to populate the lookahead buffer, unless it's already full\n    if (lfs->lookahead.size < 8*lfs->cfg->lookahead_size) {\n        err = lfs_alloc_scan(lfs);\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\n#ifndef LFS_READONLY\nstatic int lfs_fs_grow_(lfs_t *lfs, lfs_size_t block_count) {\n    // shrinking is not supported\n    LFS_ASSERT(block_count >= lfs->block_count);\n\n    if (block_count > lfs->block_count) {\n        lfs->block_count = block_count;\n\n        // fetch the root\n        lfs_mdir_t root;\n        int err = lfs_dir_fetch(lfs, &root, lfs->root);\n        if (err) {\n            return err;\n        }\n\n        // update the superblock\n        lfs_superblock_t superblock;\n        lfs_stag_t tag = lfs_dir_get(lfs, &root, LFS_MKTAG(0x7ff, 0x3ff, 0),\n                LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                &superblock);\n        if (tag < 0) {\n            return tag;\n        }\n        lfs_superblock_fromle32(&superblock);\n\n        superblock.block_count = lfs->block_count;\n\n        lfs_superblock_tole32(&superblock);\n        err = lfs_dir_commit(lfs, &root, LFS_MKATTRS(\n                {tag, &superblock}));\n        if (err) {\n            return err;\n        }\n    }\n\n    return 0;\n}\n#endif\n\n#ifdef LFS_MIGRATE\n////// Migration from littelfs v1 below this //////\n\n/// Version info ///\n\n// Software library version\n// Major (top-nibble), incremented on backwards incompatible changes\n// Minor (bottom-nibble), incremented on feature additions\n#define LFS1_VERSION 0x00010007\n#define LFS1_VERSION_MAJOR (0xffff & (LFS1_VERSION >> 16))\n#define LFS1_VERSION_MINOR (0xffff & (LFS1_VERSION >>  0))\n\n// Version of On-disk data structures\n// Major (top-nibble), incremented on backwards incompatible changes\n// Minor (bottom-nibble), incremented on feature additions\n#define LFS1_DISK_VERSION 0x00010001\n#define LFS1_DISK_VERSION_MAJOR (0xffff & (LFS1_DISK_VERSION >> 16))\n#define LFS1_DISK_VERSION_MINOR (0xffff & (LFS1_DISK_VERSION >>  0))\n\n\n/// v1 Definitions ///\n\n// File types\nenum lfs1_type {\n    LFS1_TYPE_REG        = 0x11,\n    LFS1_TYPE_DIR        = 0x22,\n    LFS1_TYPE_SUPERBLOCK = 0x2e,\n};\n\ntypedef struct lfs1 {\n    lfs_block_t root[2];\n} lfs1_t;\n\ntypedef struct lfs1_entry {\n    lfs_off_t off;\n\n    struct lfs1_disk_entry {\n        uint8_t type;\n        uint8_t elen;\n        uint8_t alen;\n        uint8_t nlen;\n        union {\n            struct {\n                lfs_block_t head;\n                lfs_size_t size;\n            } file;\n            lfs_block_t dir[2];\n        } u;\n    } d;\n} lfs1_entry_t;\n\ntypedef struct lfs1_dir {\n    struct lfs1_dir *next;\n    lfs_block_t pair[2];\n    lfs_off_t off;\n\n    lfs_block_t head[2];\n    lfs_off_t pos;\n\n    struct lfs1_disk_dir {\n        uint32_t rev;\n        lfs_size_t size;\n        lfs_block_t tail[2];\n    } d;\n} lfs1_dir_t;\n\ntypedef struct lfs1_superblock {\n    lfs_off_t off;\n\n    struct lfs1_disk_superblock {\n        uint8_t type;\n        uint8_t elen;\n        uint8_t alen;\n        uint8_t nlen;\n        lfs_block_t root[2];\n        uint32_t block_size;\n        uint32_t block_count;\n        uint32_t version;\n        char magic[8];\n    } d;\n} lfs1_superblock_t;\n\n\n/// Low-level wrappers v1->v2 ///\nstatic void lfs1_crc(uint32_t *crc, const void *buffer, size_t size) {\n    *crc = lfs_crc(*crc, buffer, size);\n}\n\nstatic int lfs1_bd_read(lfs_t *lfs, lfs_block_t block,\n        lfs_off_t off, void *buffer, lfs_size_t size) {\n    // if we ever do more than writes to alternating pairs,\n    // this may need to consider pcache\n    return lfs_bd_read(lfs, &lfs->pcache, &lfs->rcache, size,\n            block, off, buffer, size);\n}\n\nstatic int lfs1_bd_crc(lfs_t *lfs, lfs_block_t block,\n        lfs_off_t off, lfs_size_t size, uint32_t *crc) {\n    for (lfs_off_t i = 0; i < size; i++) {\n        uint8_t c;\n        int err = lfs1_bd_read(lfs, block, off+i, &c, 1);\n        if (err) {\n            return err;\n        }\n\n        lfs1_crc(crc, &c, 1);\n    }\n\n    return 0;\n}\n\n\n/// Endian swapping functions ///\nstatic void lfs1_dir_fromle32(struct lfs1_disk_dir *d) {\n    d->rev     = lfs_fromle32(d->rev);\n    d->size    = lfs_fromle32(d->size);\n    d->tail[0] = lfs_fromle32(d->tail[0]);\n    d->tail[1] = lfs_fromle32(d->tail[1]);\n}\n\nstatic void lfs1_dir_tole32(struct lfs1_disk_dir *d) {\n    d->rev     = lfs_tole32(d->rev);\n    d->size    = lfs_tole32(d->size);\n    d->tail[0] = lfs_tole32(d->tail[0]);\n    d->tail[1] = lfs_tole32(d->tail[1]);\n}\n\nstatic void lfs1_entry_fromle32(struct lfs1_disk_entry *d) {\n    d->u.dir[0] = lfs_fromle32(d->u.dir[0]);\n    d->u.dir[1] = lfs_fromle32(d->u.dir[1]);\n}\n\nstatic void lfs1_entry_tole32(struct lfs1_disk_entry *d) {\n    d->u.dir[0] = lfs_tole32(d->u.dir[0]);\n    d->u.dir[1] = lfs_tole32(d->u.dir[1]);\n}\n\nstatic void lfs1_superblock_fromle32(struct lfs1_disk_superblock *d) {\n    d->root[0]     = lfs_fromle32(d->root[0]);\n    d->root[1]     = lfs_fromle32(d->root[1]);\n    d->block_size  = lfs_fromle32(d->block_size);\n    d->block_count = lfs_fromle32(d->block_count);\n    d->version     = lfs_fromle32(d->version);\n}\n\n\n///// Metadata pair and directory operations ///\nstatic inline lfs_size_t lfs1_entry_size(const lfs1_entry_t *entry) {\n    return 4 + entry->d.elen + entry->d.alen + entry->d.nlen;\n}\n\nstatic int lfs1_dir_fetch(lfs_t *lfs,\n        lfs1_dir_t *dir, const lfs_block_t pair[2]) {\n    // copy out pair, otherwise may be aliasing dir\n    const lfs_block_t tpair[2] = {pair[0], pair[1]};\n    bool valid = false;\n\n    // check both blocks for the most recent revision\n    for (int i = 0; i < 2; i++) {\n        struct lfs1_disk_dir test;\n        int err = lfs1_bd_read(lfs, tpair[i], 0, &test, sizeof(test));\n        lfs1_dir_fromle32(&test);\n        if (err) {\n            if (err == LFS_ERR_CORRUPT) {\n                continue;\n            }\n            return err;\n        }\n\n        if (valid && lfs_scmp(test.rev, dir->d.rev) < 0) {\n            continue;\n        }\n\n        if ((0x7fffffff & test.size) < sizeof(test)+4 ||\n            (0x7fffffff & test.size) > lfs->cfg->block_size) {\n            continue;\n        }\n\n        uint32_t crc = 0xffffffff;\n        lfs1_dir_tole32(&test);\n        lfs1_crc(&crc, &test, sizeof(test));\n        lfs1_dir_fromle32(&test);\n        err = lfs1_bd_crc(lfs, tpair[i], sizeof(test),\n                (0x7fffffff & test.size) - sizeof(test), &crc);\n        if (err) {\n            if (err == LFS_ERR_CORRUPT) {\n                continue;\n            }\n            return err;\n        }\n\n        if (crc != 0) {\n            continue;\n        }\n\n        valid = true;\n\n        // setup dir in case it's valid\n        dir->pair[0] = tpair[(i+0) % 2];\n        dir->pair[1] = tpair[(i+1) % 2];\n        dir->off = sizeof(dir->d);\n        dir->d = test;\n    }\n\n    if (!valid) {\n        LFS_ERROR(\"Corrupted dir pair at {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                tpair[0], tpair[1]);\n        return LFS_ERR_CORRUPT;\n    }\n\n    return 0;\n}\n\nstatic int lfs1_dir_next(lfs_t *lfs, lfs1_dir_t *dir, lfs1_entry_t *entry) {\n    while (dir->off + sizeof(entry->d) > (0x7fffffff & dir->d.size)-4) {\n        if (!(0x80000000 & dir->d.size)) {\n            entry->off = dir->off;\n            return LFS_ERR_NOENT;\n        }\n\n        int err = lfs1_dir_fetch(lfs, dir, dir->d.tail);\n        if (err) {\n            return err;\n        }\n\n        dir->off = sizeof(dir->d);\n        dir->pos += sizeof(dir->d) + 4;\n    }\n\n    int err = lfs1_bd_read(lfs, dir->pair[0], dir->off,\n            &entry->d, sizeof(entry->d));\n    lfs1_entry_fromle32(&entry->d);\n    if (err) {\n        return err;\n    }\n\n    entry->off = dir->off;\n    dir->off += lfs1_entry_size(entry);\n    dir->pos += lfs1_entry_size(entry);\n    return 0;\n}\n\n/// littlefs v1 specific operations ///\nint lfs1_traverse(lfs_t *lfs, int (*cb)(void*, lfs_block_t), void *data) {\n    if (lfs_pair_isnull(lfs->lfs1->root)) {\n        return 0;\n    }\n\n    // iterate over metadata pairs\n    lfs1_dir_t dir;\n    lfs1_entry_t entry;\n    lfs_block_t cwd[2] = {0, 1};\n\n    while (true) {\n        for (int i = 0; i < 2; i++) {\n            int err = cb(data, cwd[i]);\n            if (err) {\n                return err;\n            }\n        }\n\n        int err = lfs1_dir_fetch(lfs, &dir, cwd);\n        if (err) {\n            return err;\n        }\n\n        // iterate over contents\n        while (dir.off + sizeof(entry.d) <= (0x7fffffff & dir.d.size)-4) {\n            err = lfs1_bd_read(lfs, dir.pair[0], dir.off,\n                    &entry.d, sizeof(entry.d));\n            lfs1_entry_fromle32(&entry.d);\n            if (err) {\n                return err;\n            }\n\n            dir.off += lfs1_entry_size(&entry);\n            if ((0x70 & entry.d.type) == (0x70 & LFS1_TYPE_REG)) {\n                err = lfs_ctz_traverse(lfs, NULL, &lfs->rcache,\n                        entry.d.u.file.head, entry.d.u.file.size, cb, data);\n                if (err) {\n                    return err;\n                }\n            }\n        }\n\n        // we also need to check if we contain a threaded v2 directory\n        lfs_mdir_t dir2 = {.split=true, .tail={cwd[0], cwd[1]}};\n        while (dir2.split) {\n            err = lfs_dir_fetch(lfs, &dir2, dir2.tail);\n            if (err) {\n                break;\n            }\n\n            for (int i = 0; i < 2; i++) {\n                err = cb(data, dir2.pair[i]);\n                if (err) {\n                    return err;\n                }\n            }\n        }\n\n        cwd[0] = dir.d.tail[0];\n        cwd[1] = dir.d.tail[1];\n\n        if (lfs_pair_isnull(cwd)) {\n            break;\n        }\n    }\n\n    return 0;\n}\n\nstatic int lfs1_moved(lfs_t *lfs, const void *e) {\n    if (lfs_pair_isnull(lfs->lfs1->root)) {\n        return 0;\n    }\n\n    // skip superblock\n    lfs1_dir_t cwd;\n    int err = lfs1_dir_fetch(lfs, &cwd, (const lfs_block_t[2]){0, 1});\n    if (err) {\n        return err;\n    }\n\n    // iterate over all directory directory entries\n    lfs1_entry_t entry;\n    while (!lfs_pair_isnull(cwd.d.tail)) {\n        err = lfs1_dir_fetch(lfs, &cwd, cwd.d.tail);\n        if (err) {\n            return err;\n        }\n\n        while (true) {\n            err = lfs1_dir_next(lfs, &cwd, &entry);\n            if (err && err != LFS_ERR_NOENT) {\n                return err;\n            }\n\n            if (err == LFS_ERR_NOENT) {\n                break;\n            }\n\n            if (!(0x80 & entry.d.type) &&\n                 memcmp(&entry.d.u, e, sizeof(entry.d.u)) == 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n\n/// Filesystem operations ///\nstatic int lfs1_mount(lfs_t *lfs, struct lfs1 *lfs1,\n        const struct lfs_config *cfg) {\n    int err = 0;\n    {\n        err = lfs_init(lfs, cfg);\n        if (err) {\n            return err;\n        }\n\n        lfs->lfs1 = lfs1;\n        lfs->lfs1->root[0] = LFS_BLOCK_NULL;\n        lfs->lfs1->root[1] = LFS_BLOCK_NULL;\n\n        // setup free lookahead\n        lfs->lookahead.start = 0;\n        lfs->lookahead.size = 0;\n        lfs->lookahead.next = 0;\n        lfs_alloc_ckpoint(lfs);\n\n        // load superblock\n        lfs1_dir_t dir;\n        lfs1_superblock_t superblock;\n        err = lfs1_dir_fetch(lfs, &dir, (const lfs_block_t[2]){0, 1});\n        if (err && err != LFS_ERR_CORRUPT) {\n            goto cleanup;\n        }\n\n        if (!err) {\n            err = lfs1_bd_read(lfs, dir.pair[0], sizeof(dir.d),\n                    &superblock.d, sizeof(superblock.d));\n            lfs1_superblock_fromle32(&superblock.d);\n            if (err) {\n                goto cleanup;\n            }\n\n            lfs->lfs1->root[0] = superblock.d.root[0];\n            lfs->lfs1->root[1] = superblock.d.root[1];\n        }\n\n        if (err || memcmp(superblock.d.magic, \"littlefs\", 8) != 0) {\n            LFS_ERROR(\"Invalid superblock at {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                    0, 1);\n            err = LFS_ERR_CORRUPT;\n            goto cleanup;\n        }\n\n        uint16_t major_version = (0xffff & (superblock.d.version >> 16));\n        uint16_t minor_version = (0xffff & (superblock.d.version >>  0));\n        if ((major_version != LFS1_DISK_VERSION_MAJOR ||\n             minor_version > LFS1_DISK_VERSION_MINOR)) {\n            LFS_ERROR(\"Invalid version v%d.%d\", major_version, minor_version);\n            err = LFS_ERR_INVAL;\n            goto cleanup;\n        }\n\n        return 0;\n    }\n\ncleanup:\n    lfs_deinit(lfs);\n    return err;\n}\n\nstatic int lfs1_unmount(lfs_t *lfs) {\n    return lfs_deinit(lfs);\n}\n\n/// v1 migration ///\nstatic int lfs_migrate_(lfs_t *lfs, const struct lfs_config *cfg) {\n    struct lfs1 lfs1;\n\n    // Indeterminate filesystem size not allowed for migration.\n    LFS_ASSERT(cfg->block_count != 0);\n\n    int err = lfs1_mount(lfs, &lfs1, cfg);\n    if (err) {\n        return err;\n    }\n\n    {\n        // iterate through each directory, copying over entries\n        // into new directory\n        lfs1_dir_t dir1;\n        lfs_mdir_t dir2;\n        dir1.d.tail[0] = lfs->lfs1->root[0];\n        dir1.d.tail[1] = lfs->lfs1->root[1];\n        while (!lfs_pair_isnull(dir1.d.tail)) {\n            // iterate old dir\n            err = lfs1_dir_fetch(lfs, &dir1, dir1.d.tail);\n            if (err) {\n                goto cleanup;\n            }\n\n            // create new dir and bind as temporary pretend root\n            err = lfs_dir_alloc(lfs, &dir2);\n            if (err) {\n                goto cleanup;\n            }\n\n            dir2.rev = dir1.d.rev;\n            dir1.head[0] = dir1.pair[0];\n            dir1.head[1] = dir1.pair[1];\n            lfs->root[0] = dir2.pair[0];\n            lfs->root[1] = dir2.pair[1];\n\n            err = lfs_dir_commit(lfs, &dir2, NULL, 0);\n            if (err) {\n                goto cleanup;\n            }\n\n            while (true) {\n                lfs1_entry_t entry1;\n                err = lfs1_dir_next(lfs, &dir1, &entry1);\n                if (err && err != LFS_ERR_NOENT) {\n                    goto cleanup;\n                }\n\n                if (err == LFS_ERR_NOENT) {\n                    break;\n                }\n\n                // check that entry has not been moved\n                if (entry1.d.type & 0x80) {\n                    int moved = lfs1_moved(lfs, &entry1.d.u);\n                    if (moved < 0) {\n                        err = moved;\n                        goto cleanup;\n                    }\n\n                    if (moved) {\n                        continue;\n                    }\n\n                    entry1.d.type &= ~0x80;\n                }\n\n                // also fetch name\n                char name[LFS_NAME_MAX+1];\n                memset(name, 0, sizeof(name));\n                err = lfs1_bd_read(lfs, dir1.pair[0],\n                        entry1.off + 4+entry1.d.elen+entry1.d.alen,\n                        name, entry1.d.nlen);\n                if (err) {\n                    goto cleanup;\n                }\n\n                bool isdir = (entry1.d.type == LFS1_TYPE_DIR);\n\n                // create entry in new dir\n                err = lfs_dir_fetch(lfs, &dir2, lfs->root);\n                if (err) {\n                    goto cleanup;\n                }\n\n                uint16_t id;\n                err = lfs_dir_find(lfs, &dir2, &(const char*){name}, &id);\n                if (!(err == LFS_ERR_NOENT && id != 0x3ff)) {\n                    err = (err < 0) ? err : LFS_ERR_EXIST;\n                    goto cleanup;\n                }\n\n                lfs1_entry_tole32(&entry1.d);\n                err = lfs_dir_commit(lfs, &dir2, LFS_MKATTRS(\n                        {LFS_MKTAG(LFS_TYPE_CREATE, id, 0), NULL},\n                        {LFS_MKTAG_IF_ELSE(isdir,\n                            LFS_TYPE_DIR, id, entry1.d.nlen,\n                            LFS_TYPE_REG, id, entry1.d.nlen),\n                                name},\n                        {LFS_MKTAG_IF_ELSE(isdir,\n                            LFS_TYPE_DIRSTRUCT, id, sizeof(entry1.d.u),\n                            LFS_TYPE_CTZSTRUCT, id, sizeof(entry1.d.u)),\n                                &entry1.d.u}));\n                lfs1_entry_fromle32(&entry1.d);\n                if (err) {\n                    goto cleanup;\n                }\n            }\n\n            if (!lfs_pair_isnull(dir1.d.tail)) {\n                // find last block and update tail to thread into fs\n                err = lfs_dir_fetch(lfs, &dir2, lfs->root);\n                if (err) {\n                    goto cleanup;\n                }\n\n                while (dir2.split) {\n                    err = lfs_dir_fetch(lfs, &dir2, dir2.tail);\n                    if (err) {\n                        goto cleanup;\n                    }\n                }\n\n                lfs_pair_tole32(dir2.pair);\n                err = lfs_dir_commit(lfs, &dir2, LFS_MKATTRS(\n                        {LFS_MKTAG(LFS_TYPE_SOFTTAIL, 0x3ff, 8), dir1.d.tail}));\n                lfs_pair_fromle32(dir2.pair);\n                if (err) {\n                    goto cleanup;\n                }\n            }\n\n            // Copy over first block to thread into fs. Unfortunately\n            // if this fails there is not much we can do.\n            LFS_DEBUG(\"Migrating {0x%\"PRIx32\", 0x%\"PRIx32\"} \"\n                        \"-> {0x%\"PRIx32\", 0x%\"PRIx32\"}\",\n                    lfs->root[0], lfs->root[1], dir1.head[0], dir1.head[1]);\n\n            err = lfs_bd_erase(lfs, dir1.head[1]);\n            if (err) {\n                goto cleanup;\n            }\n\n            err = lfs_dir_fetch(lfs, &dir2, lfs->root);\n            if (err) {\n                goto cleanup;\n            }\n\n            for (lfs_off_t i = 0; i < dir2.off; i++) {\n                uint8_t dat;\n                err = lfs_bd_read(lfs,\n                        NULL, &lfs->rcache, dir2.off,\n                        dir2.pair[0], i, &dat, 1);\n                if (err) {\n                    goto cleanup;\n                }\n\n                err = lfs_bd_prog(lfs,\n                        &lfs->pcache, &lfs->rcache, true,\n                        dir1.head[1], i, &dat, 1);\n                if (err) {\n                    goto cleanup;\n                }\n            }\n\n            err = lfs_bd_flush(lfs, &lfs->pcache, &lfs->rcache, true);\n            if (err) {\n                goto cleanup;\n            }\n        }\n\n        // Create new superblock. This marks a successful migration!\n        err = lfs1_dir_fetch(lfs, &dir1, (const lfs_block_t[2]){0, 1});\n        if (err) {\n            goto cleanup;\n        }\n\n        dir2.pair[0] = dir1.pair[0];\n        dir2.pair[1] = dir1.pair[1];\n        dir2.rev = dir1.d.rev;\n        dir2.off = sizeof(dir2.rev);\n        dir2.etag = 0xffffffff;\n        dir2.count = 0;\n        dir2.tail[0] = lfs->lfs1->root[0];\n        dir2.tail[1] = lfs->lfs1->root[1];\n        dir2.erased = false;\n        dir2.split = true;\n\n        lfs_superblock_t superblock = {\n            .version     = LFS_DISK_VERSION,\n            .block_size  = lfs->cfg->block_size,\n            .block_count = lfs->cfg->block_count,\n            .name_max    = lfs->name_max,\n            .file_max    = lfs->file_max,\n            .attr_max    = lfs->attr_max,\n        };\n\n        lfs_superblock_tole32(&superblock);\n        err = lfs_dir_commit(lfs, &dir2, LFS_MKATTRS(\n                {LFS_MKTAG(LFS_TYPE_CREATE, 0, 0), NULL},\n                {LFS_MKTAG(LFS_TYPE_SUPERBLOCK, 0, 8), \"littlefs\"},\n                {LFS_MKTAG(LFS_TYPE_INLINESTRUCT, 0, sizeof(superblock)),\n                    &superblock}));\n        if (err) {\n            goto cleanup;\n        }\n\n        // sanity check that fetch works\n        err = lfs_dir_fetch(lfs, &dir2, (const lfs_block_t[2]){0, 1});\n        if (err) {\n            goto cleanup;\n        }\n\n        // force compaction to prevent accidentally mounting v1\n        dir2.erased = false;\n        err = lfs_dir_commit(lfs, &dir2, NULL, 0);\n        if (err) {\n            goto cleanup;\n        }\n    }\n\ncleanup:\n    lfs1_unmount(lfs);\n    return err;\n}\n\n#endif\n\n\n/// Public API wrappers ///\n\n// Here we can add tracing/thread safety easily\n\n// Thread-safe wrappers if enabled\n#ifdef LFS_THREADSAFE\n#define LFS_LOCK(cfg)   cfg->lock(cfg)\n#define LFS_UNLOCK(cfg) cfg->unlock(cfg)\n#else\n#define LFS_LOCK(cfg)   ((void)cfg, 0)\n#define LFS_UNLOCK(cfg) ((void)cfg)\n#endif\n\n// Public API\n#ifndef LFS_READONLY\nint lfs_format(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = LFS_LOCK(cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_format(%p, %p {.context=%p, \"\n                \".read=%p, .prog=%p, .erase=%p, .sync=%p, \"\n                \".read_size=%\"PRIu32\", .prog_size=%\"PRIu32\", \"\n                \".block_size=%\"PRIu32\", .block_count=%\"PRIu32\", \"\n                \".block_cycles=%\"PRId32\", .cache_size=%\"PRIu32\", \"\n                \".lookahead_size=%\"PRIu32\", .read_buffer=%p, \"\n                \".prog_buffer=%p, .lookahead_buffer=%p, \"\n                \".name_max=%\"PRIu32\", .file_max=%\"PRIu32\", \"\n                \".attr_max=%\"PRIu32\"})\",\n            (void*)lfs, (void*)cfg, cfg->context,\n            (void*)(uintptr_t)cfg->read, (void*)(uintptr_t)cfg->prog,\n            (void*)(uintptr_t)cfg->erase, (void*)(uintptr_t)cfg->sync,\n            cfg->read_size, cfg->prog_size, cfg->block_size, cfg->block_count,\n            cfg->block_cycles, cfg->cache_size, cfg->lookahead_size,\n            cfg->read_buffer, cfg->prog_buffer, cfg->lookahead_buffer,\n            cfg->name_max, cfg->file_max, cfg->attr_max);\n\n    err = lfs_format_(lfs, cfg);\n\n    LFS_TRACE(\"lfs_format -> %d\", err);\n    LFS_UNLOCK(cfg);\n    return err;\n}\n#endif\n\nint lfs_mount(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = LFS_LOCK(cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_mount(%p, %p {.context=%p, \"\n                \".read=%p, .prog=%p, .erase=%p, .sync=%p, \"\n                \".read_size=%\"PRIu32\", .prog_size=%\"PRIu32\", \"\n                \".block_size=%\"PRIu32\", .block_count=%\"PRIu32\", \"\n                \".block_cycles=%\"PRId32\", .cache_size=%\"PRIu32\", \"\n                \".lookahead_size=%\"PRIu32\", .read_buffer=%p, \"\n                \".prog_buffer=%p, .lookahead_buffer=%p, \"\n                \".name_max=%\"PRIu32\", .file_max=%\"PRIu32\", \"\n                \".attr_max=%\"PRIu32\"})\",\n            (void*)lfs, (void*)cfg, cfg->context,\n            (void*)(uintptr_t)cfg->read, (void*)(uintptr_t)cfg->prog,\n            (void*)(uintptr_t)cfg->erase, (void*)(uintptr_t)cfg->sync,\n            cfg->read_size, cfg->prog_size, cfg->block_size, cfg->block_count,\n            cfg->block_cycles, cfg->cache_size, cfg->lookahead_size,\n            cfg->read_buffer, cfg->prog_buffer, cfg->lookahead_buffer,\n            cfg->name_max, cfg->file_max, cfg->attr_max);\n\n    err = lfs_mount_(lfs, cfg);\n\n    LFS_TRACE(\"lfs_mount -> %d\", err);\n    LFS_UNLOCK(cfg);\n    return err;\n}\n\nint lfs_unmount(lfs_t *lfs) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_unmount(%p)\", (void*)lfs);\n\n    err = lfs_unmount_(lfs);\n\n    LFS_TRACE(\"lfs_unmount -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\n#ifndef LFS_READONLY\nint lfs_remove(lfs_t *lfs, const char *path) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_remove(%p, \\\"%s\\\")\", (void*)lfs, path);\n\n    err = lfs_remove_(lfs, path);\n\n    LFS_TRACE(\"lfs_remove -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifndef LFS_READONLY\nint lfs_rename(lfs_t *lfs, const char *oldpath, const char *newpath) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_rename(%p, \\\"%s\\\", \\\"%s\\\")\", (void*)lfs, oldpath, newpath);\n\n    err = lfs_rename_(lfs, oldpath, newpath);\n\n    LFS_TRACE(\"lfs_rename -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\nint lfs_stat(lfs_t *lfs, const char *path, struct lfs_info *info) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_stat(%p, \\\"%s\\\", %p)\", (void*)lfs, path, (void*)info);\n\n    err = lfs_stat_(lfs, path, info);\n\n    LFS_TRACE(\"lfs_stat -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nlfs_ssize_t lfs_getattr(lfs_t *lfs, const char *path,\n        uint8_t type, void *buffer, lfs_size_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_getattr(%p, \\\"%s\\\", %\"PRIu8\", %p, %\"PRIu32\")\",\n            (void*)lfs, path, type, buffer, size);\n\n    lfs_ssize_t res = lfs_getattr_(lfs, path, type, buffer, size);\n\n    LFS_TRACE(\"lfs_getattr -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\n#ifndef LFS_READONLY\nint lfs_setattr(lfs_t *lfs, const char *path,\n        uint8_t type, const void *buffer, lfs_size_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_setattr(%p, \\\"%s\\\", %\"PRIu8\", %p, %\"PRIu32\")\",\n            (void*)lfs, path, type, buffer, size);\n\n    err = lfs_setattr_(lfs, path, type, buffer, size);\n\n    LFS_TRACE(\"lfs_setattr -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifndef LFS_READONLY\nint lfs_removeattr(lfs_t *lfs, const char *path, uint8_t type) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_removeattr(%p, \\\"%s\\\", %\"PRIu8\")\", (void*)lfs, path, type);\n\n    err = lfs_removeattr_(lfs, path, type);\n\n    LFS_TRACE(\"lfs_removeattr -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifndef LFS_NO_MALLOC\nint lfs_file_open(lfs_t *lfs, lfs_file_t *file, const char *path, int flags) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_open(%p, %p, \\\"%s\\\", %x)\",\n            (void*)lfs, (void*)file, path, (unsigned)flags);\n    LFS_ASSERT(!lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_open_(lfs, file, path, flags);\n\n    LFS_TRACE(\"lfs_file_open -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\nint lfs_file_opencfg(lfs_t *lfs, lfs_file_t *file,\n        const char *path, int flags,\n        const struct lfs_file_config *cfg) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_opencfg(%p, %p, \\\"%s\\\", %x, %p {\"\n                 \".buffer=%p, .attrs=%p, .attr_count=%\"PRIu32\"})\",\n            (void*)lfs, (void*)file, path, (unsigned)flags,\n            (void*)cfg, cfg->buffer, (void*)cfg->attrs, cfg->attr_count);\n    LFS_ASSERT(!lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_opencfg_(lfs, file, path, flags, cfg);\n\n    LFS_TRACE(\"lfs_file_opencfg -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nint lfs_file_close(lfs_t *lfs, lfs_file_t *file) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_close(%p, %p)\", (void*)lfs, (void*)file);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_close_(lfs, file);\n\n    LFS_TRACE(\"lfs_file_close -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\n#ifndef LFS_READONLY\nint lfs_file_sync(lfs_t *lfs, lfs_file_t *file) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_sync(%p, %p)\", (void*)lfs, (void*)file);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_sync_(lfs, file);\n\n    LFS_TRACE(\"lfs_file_sync -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\nlfs_ssize_t lfs_file_read(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_read(%p, %p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)file, buffer, size);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_ssize_t res = lfs_file_read_(lfs, file, buffer, size);\n\n    LFS_TRACE(\"lfs_file_read -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\n#ifndef LFS_READONLY\nlfs_ssize_t lfs_file_write(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_write(%p, %p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)file, buffer, size);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_ssize_t res = lfs_file_write_(lfs, file, buffer, size);\n\n    LFS_TRACE(\"lfs_file_write -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n#endif\n\nlfs_soff_t lfs_file_seek(lfs_t *lfs, lfs_file_t *file,\n        lfs_soff_t off, int whence) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_seek(%p, %p, %\"PRId32\", %d)\",\n            (void*)lfs, (void*)file, off, whence);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_soff_t res = lfs_file_seek_(lfs, file, off, whence);\n\n    LFS_TRACE(\"lfs_file_seek -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\n#ifndef LFS_READONLY\nint lfs_file_truncate(lfs_t *lfs, lfs_file_t *file, lfs_off_t size) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_truncate(%p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)file, size);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    err = lfs_file_truncate_(lfs, file, size);\n\n    LFS_TRACE(\"lfs_file_truncate -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\nlfs_soff_t lfs_file_tell(lfs_t *lfs, lfs_file_t *file) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_tell(%p, %p)\", (void*)lfs, (void*)file);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_soff_t res = lfs_file_tell_(lfs, file);\n\n    LFS_TRACE(\"lfs_file_tell -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\nint lfs_file_rewind(lfs_t *lfs, lfs_file_t *file) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_rewind(%p, %p)\", (void*)lfs, (void*)file);\n\n    err = lfs_file_rewind_(lfs, file);\n\n    LFS_TRACE(\"lfs_file_rewind -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nlfs_soff_t lfs_file_size(lfs_t *lfs, lfs_file_t *file) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_file_size(%p, %p)\", (void*)lfs, (void*)file);\n    LFS_ASSERT(lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)file));\n\n    lfs_soff_t res = lfs_file_size_(lfs, file);\n\n    LFS_TRACE(\"lfs_file_size -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\n#ifndef LFS_READONLY\nint lfs_mkdir(lfs_t *lfs, const char *path) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_mkdir(%p, \\\"%s\\\")\", (void*)lfs, path);\n\n    err = lfs_mkdir_(lfs, path);\n\n    LFS_TRACE(\"lfs_mkdir -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\nint lfs_dir_open(lfs_t *lfs, lfs_dir_t *dir, const char *path) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_open(%p, %p, \\\"%s\\\")\", (void*)lfs, (void*)dir, path);\n    LFS_ASSERT(!lfs_mlist_isopen(lfs->mlist, (struct lfs_mlist*)dir));\n\n    err = lfs_dir_open_(lfs, dir, path);\n\n    LFS_TRACE(\"lfs_dir_open -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nint lfs_dir_close(lfs_t *lfs, lfs_dir_t *dir) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_close(%p, %p)\", (void*)lfs, (void*)dir);\n\n    err = lfs_dir_close_(lfs, dir);\n\n    LFS_TRACE(\"lfs_dir_close -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nint lfs_dir_read(lfs_t *lfs, lfs_dir_t *dir, struct lfs_info *info) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_read(%p, %p, %p)\",\n            (void*)lfs, (void*)dir, (void*)info);\n\n    err = lfs_dir_read_(lfs, dir, info);\n\n    LFS_TRACE(\"lfs_dir_read -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nint lfs_dir_seek(lfs_t *lfs, lfs_dir_t *dir, lfs_off_t off) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_seek(%p, %p, %\"PRIu32\")\",\n            (void*)lfs, (void*)dir, off);\n\n    err = lfs_dir_seek_(lfs, dir, off);\n\n    LFS_TRACE(\"lfs_dir_seek -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nlfs_soff_t lfs_dir_tell(lfs_t *lfs, lfs_dir_t *dir) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_tell(%p, %p)\", (void*)lfs, (void*)dir);\n\n    lfs_soff_t res = lfs_dir_tell_(lfs, dir);\n\n    LFS_TRACE(\"lfs_dir_tell -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\nint lfs_dir_rewind(lfs_t *lfs, lfs_dir_t *dir) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_dir_rewind(%p, %p)\", (void*)lfs, (void*)dir);\n\n    err = lfs_dir_rewind_(lfs, dir);\n\n    LFS_TRACE(\"lfs_dir_rewind -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nint lfs_fs_stat(lfs_t *lfs, struct lfs_fsinfo *fsinfo) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_stat(%p, %p)\", (void*)lfs, (void*)fsinfo);\n\n    err = lfs_fs_stat_(lfs, fsinfo);\n\n    LFS_TRACE(\"lfs_fs_stat -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\nlfs_ssize_t lfs_fs_size(lfs_t *lfs) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_size(%p)\", (void*)lfs);\n\n    lfs_ssize_t res = lfs_fs_size_(lfs);\n\n    LFS_TRACE(\"lfs_fs_size -> %\"PRId32, res);\n    LFS_UNLOCK(lfs->cfg);\n    return res;\n}\n\nint lfs_fs_traverse(lfs_t *lfs, int (*cb)(void *, lfs_block_t), void *data) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_traverse(%p, %p, %p)\",\n            (void*)lfs, (void*)(uintptr_t)cb, data);\n\n    err = lfs_fs_traverse_(lfs, cb, data, true);\n\n    LFS_TRACE(\"lfs_fs_traverse -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n\n#ifndef LFS_READONLY\nint lfs_fs_mkconsistent(lfs_t *lfs) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_mkconsistent(%p)\", (void*)lfs);\n\n    err = lfs_fs_mkconsistent_(lfs);\n\n    LFS_TRACE(\"lfs_fs_mkconsistent -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifndef LFS_READONLY\nint lfs_fs_gc(lfs_t *lfs) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_gc(%p)\", (void*)lfs);\n\n    err = lfs_fs_gc_(lfs);\n\n    LFS_TRACE(\"lfs_fs_gc -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifndef LFS_READONLY\nint lfs_fs_grow(lfs_t *lfs, lfs_size_t block_count) {\n    int err = LFS_LOCK(lfs->cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_fs_grow(%p, %\"PRIu32\")\", (void*)lfs, block_count);\n\n    err = lfs_fs_grow_(lfs, block_count);\n\n    LFS_TRACE(\"lfs_fs_grow -> %d\", err);\n    LFS_UNLOCK(lfs->cfg);\n    return err;\n}\n#endif\n\n#ifdef LFS_MIGRATE\nint lfs_migrate(lfs_t *lfs, const struct lfs_config *cfg) {\n    int err = LFS_LOCK(cfg);\n    if (err) {\n        return err;\n    }\n    LFS_TRACE(\"lfs_migrate(%p, %p {.context=%p, \"\n                \".read=%p, .prog=%p, .erase=%p, .sync=%p, \"\n                \".read_size=%\"PRIu32\", .prog_size=%\"PRIu32\", \"\n                \".block_size=%\"PRIu32\", .block_count=%\"PRIu32\", \"\n                \".block_cycles=%\"PRId32\", .cache_size=%\"PRIu32\", \"\n                \".lookahead_size=%\"PRIu32\", .read_buffer=%p, \"\n                \".prog_buffer=%p, .lookahead_buffer=%p, \"\n                \".name_max=%\"PRIu32\", .file_max=%\"PRIu32\", \"\n                \".attr_max=%\"PRIu32\"})\",\n            (void*)lfs, (void*)cfg, cfg->context,\n            (void*)(uintptr_t)cfg->read, (void*)(uintptr_t)cfg->prog,\n            (void*)(uintptr_t)cfg->erase, (void*)(uintptr_t)cfg->sync,\n            cfg->read_size, cfg->prog_size, cfg->block_size, cfg->block_count,\n            cfg->block_cycles, cfg->cache_size, cfg->lookahead_size,\n            cfg->read_buffer, cfg->prog_buffer, cfg->lookahead_buffer,\n            cfg->name_max, cfg->file_max, cfg->attr_max);\n\n    err = lfs_migrate_(lfs, cfg);\n\n    LFS_TRACE(\"lfs_migrate -> %d\", err);\n    LFS_UNLOCK(cfg);\n    return err;\n}\n#endif\n\n"
        },
        {
          "name": "lfs.h",
          "type": "blob",
          "size": 25.8193359375,
          "content": "/*\n * The little filesystem\n *\n * Copyright (c) 2022, The littlefs authors.\n * Copyright (c) 2017, Arm Limited. All rights reserved.\n * SPDX-License-Identifier: BSD-3-Clause\n */\n#ifndef LFS_H\n#define LFS_H\n\n#include \"lfs_util.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n\n/// Version info ///\n\n// Software library version\n// Major (top-nibble), incremented on backwards incompatible changes\n// Minor (bottom-nibble), incremented on feature additions\n#define LFS_VERSION 0x0002000a\n#define LFS_VERSION_MAJOR (0xffff & (LFS_VERSION >> 16))\n#define LFS_VERSION_MINOR (0xffff & (LFS_VERSION >>  0))\n\n// Version of On-disk data structures\n// Major (top-nibble), incremented on backwards incompatible changes\n// Minor (bottom-nibble), incremented on feature additions\n#define LFS_DISK_VERSION 0x00020001\n#define LFS_DISK_VERSION_MAJOR (0xffff & (LFS_DISK_VERSION >> 16))\n#define LFS_DISK_VERSION_MINOR (0xffff & (LFS_DISK_VERSION >>  0))\n\n\n/// Definitions ///\n\n// Type definitions\ntypedef uint32_t lfs_size_t;\ntypedef uint32_t lfs_off_t;\n\ntypedef int32_t  lfs_ssize_t;\ntypedef int32_t  lfs_soff_t;\n\ntypedef uint32_t lfs_block_t;\n\n// Maximum name size in bytes, may be redefined to reduce the size of the\n// info struct. Limited to <= 1022. Stored in superblock and must be\n// respected by other littlefs drivers.\n#ifndef LFS_NAME_MAX\n#define LFS_NAME_MAX 255\n#endif\n\n// Maximum size of a file in bytes, may be redefined to limit to support other\n// drivers. Limited on disk to <= 2147483647. Stored in superblock and must be\n// respected by other littlefs drivers.\n#ifndef LFS_FILE_MAX\n#define LFS_FILE_MAX 2147483647\n#endif\n\n// Maximum size of custom attributes in bytes, may be redefined, but there is\n// no real benefit to using a smaller LFS_ATTR_MAX. Limited to <= 1022. Stored\n// in superblock and must be respected by other littlefs drivers.\n#ifndef LFS_ATTR_MAX\n#define LFS_ATTR_MAX 1022\n#endif\n\n// Possible error codes, these are negative to allow\n// valid positive return values\nenum lfs_error {\n    LFS_ERR_OK          = 0,    // No error\n    LFS_ERR_IO          = -5,   // Error during device operation\n    LFS_ERR_CORRUPT     = -84,  // Corrupted\n    LFS_ERR_NOENT       = -2,   // No directory entry\n    LFS_ERR_EXIST       = -17,  // Entry already exists\n    LFS_ERR_NOTDIR      = -20,  // Entry is not a dir\n    LFS_ERR_ISDIR       = -21,  // Entry is a dir\n    LFS_ERR_NOTEMPTY    = -39,  // Dir is not empty\n    LFS_ERR_BADF        = -9,   // Bad file number\n    LFS_ERR_FBIG        = -27,  // File too large\n    LFS_ERR_INVAL       = -22,  // Invalid parameter\n    LFS_ERR_NOSPC       = -28,  // No space left on device\n    LFS_ERR_NOMEM       = -12,  // No more memory available\n    LFS_ERR_NOATTR      = -61,  // No data/attr available\n    LFS_ERR_NAMETOOLONG = -36,  // File name too long\n};\n\n// File types\nenum lfs_type {\n    // file types\n    LFS_TYPE_REG            = 0x001,\n    LFS_TYPE_DIR            = 0x002,\n\n    // internally used types\n    LFS_TYPE_SPLICE         = 0x400,\n    LFS_TYPE_NAME           = 0x000,\n    LFS_TYPE_STRUCT         = 0x200,\n    LFS_TYPE_USERATTR       = 0x300,\n    LFS_TYPE_FROM           = 0x100,\n    LFS_TYPE_TAIL           = 0x600,\n    LFS_TYPE_GLOBALS        = 0x700,\n    LFS_TYPE_CRC            = 0x500,\n\n    // internally used type specializations\n    LFS_TYPE_CREATE         = 0x401,\n    LFS_TYPE_DELETE         = 0x4ff,\n    LFS_TYPE_SUPERBLOCK     = 0x0ff,\n    LFS_TYPE_DIRSTRUCT      = 0x200,\n    LFS_TYPE_CTZSTRUCT      = 0x202,\n    LFS_TYPE_INLINESTRUCT   = 0x201,\n    LFS_TYPE_SOFTTAIL       = 0x600,\n    LFS_TYPE_HARDTAIL       = 0x601,\n    LFS_TYPE_MOVESTATE      = 0x7ff,\n    LFS_TYPE_CCRC           = 0x500,\n    LFS_TYPE_FCRC           = 0x5ff,\n\n    // internal chip sources\n    LFS_FROM_NOOP           = 0x000,\n    LFS_FROM_MOVE           = 0x101,\n    LFS_FROM_USERATTRS      = 0x102,\n};\n\n// File open flags\nenum lfs_open_flags {\n    // open flags\n    LFS_O_RDONLY = 1,         // Open a file as read only\n#ifndef LFS_READONLY\n    LFS_O_WRONLY = 2,         // Open a file as write only\n    LFS_O_RDWR   = 3,         // Open a file as read and write\n    LFS_O_CREAT  = 0x0100,    // Create a file if it does not exist\n    LFS_O_EXCL   = 0x0200,    // Fail if a file already exists\n    LFS_O_TRUNC  = 0x0400,    // Truncate the existing file to zero size\n    LFS_O_APPEND = 0x0800,    // Move to end of file on every write\n#endif\n\n    // internally used flags\n#ifndef LFS_READONLY\n    LFS_F_DIRTY   = 0x010000, // File does not match storage\n    LFS_F_WRITING = 0x020000, // File has been written since last flush\n#endif\n    LFS_F_READING = 0x040000, // File has been read since last flush\n#ifndef LFS_READONLY\n    LFS_F_ERRED   = 0x080000, // An error occurred during write\n#endif\n    LFS_F_INLINE  = 0x100000, // Currently inlined in directory entry\n};\n\n// File seek flags\nenum lfs_whence_flags {\n    LFS_SEEK_SET = 0,   // Seek relative to an absolute position\n    LFS_SEEK_CUR = 1,   // Seek relative to the current file position\n    LFS_SEEK_END = 2,   // Seek relative to the end of the file\n};\n\n\n// Configuration provided during initialization of the littlefs\nstruct lfs_config {\n    // Opaque user provided context that can be used to pass\n    // information to the block device operations\n    void *context;\n\n    // Read a region in a block. Negative error codes are propagated\n    // to the user.\n    int (*read)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, void *buffer, lfs_size_t size);\n\n    // Program a region in a block. The block must have previously\n    // been erased. Negative error codes are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*prog)(const struct lfs_config *c, lfs_block_t block,\n            lfs_off_t off, const void *buffer, lfs_size_t size);\n\n    // Erase a block. A block must be erased before being programmed.\n    // The state of an erased block is undefined. Negative error codes\n    // are propagated to the user.\n    // May return LFS_ERR_CORRUPT if the block should be considered bad.\n    int (*erase)(const struct lfs_config *c, lfs_block_t block);\n\n    // Sync the state of the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*sync)(const struct lfs_config *c);\n\n#ifdef LFS_THREADSAFE\n    // Lock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*lock)(const struct lfs_config *c);\n\n    // Unlock the underlying block device. Negative error codes\n    // are propagated to the user.\n    int (*unlock)(const struct lfs_config *c);\n#endif\n\n    // Minimum size of a block read in bytes. All read operations will be a\n    // multiple of this value.\n    lfs_size_t read_size;\n\n    // Minimum size of a block program in bytes. All program operations will be\n    // a multiple of this value.\n    lfs_size_t prog_size;\n\n    // Size of an erasable block in bytes. This does not impact ram consumption\n    // and may be larger than the physical erase size. However, non-inlined\n    // files take up at minimum one block. Must be a multiple of the read and\n    // program sizes.\n    lfs_size_t block_size;\n\n    // Number of erasable blocks on the device. Defaults to block_count stored\n    // on disk when zero.\n    lfs_size_t block_count;\n\n    // Number of erase cycles before littlefs evicts metadata logs and moves\n    // the metadata to another block. Suggested values are in the\n    // range 100-1000, with large values having better performance at the cost\n    // of less consistent wear distribution.\n    //\n    // Set to -1 to disable block-level wear-leveling.\n    int32_t block_cycles;\n\n    // Size of block caches in bytes. Each cache buffers a portion of a block in\n    // RAM. The littlefs needs a read cache, a program cache, and one additional\n    // cache per file. Larger caches can improve performance by storing more\n    // data and reducing the number of disk accesses. Must be a multiple of the\n    // read and program sizes, and a factor of the block size.\n    lfs_size_t cache_size;\n\n    // Size of the lookahead buffer in bytes. A larger lookahead buffer\n    // increases the number of blocks found during an allocation pass. The\n    // lookahead buffer is stored as a compact bitmap, so each byte of RAM\n    // can track 8 blocks.\n    lfs_size_t lookahead_size;\n\n    // Threshold for metadata compaction during lfs_fs_gc in bytes. Metadata\n    // pairs that exceed this threshold will be compacted during lfs_fs_gc.\n    // Defaults to ~88% block_size when zero, though the default may change\n    // in the future.\n    //\n    // Note this only affects lfs_fs_gc. Normal compactions still only occur\n    // when full.\n    //\n    // Set to -1 to disable metadata compaction during lfs_fs_gc.\n    lfs_size_t compact_thresh;\n\n    // Optional statically allocated read buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *read_buffer;\n\n    // Optional statically allocated program buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *prog_buffer;\n\n    // Optional statically allocated lookahead buffer. Must be lookahead_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *lookahead_buffer;\n\n    // Optional upper limit on length of file names in bytes. No downside for\n    // larger names except the size of the info struct which is controlled by\n    // the LFS_NAME_MAX define. Defaults to LFS_NAME_MAX or name_max stored on\n    // disk when zero.\n    lfs_size_t name_max;\n\n    // Optional upper limit on files in bytes. No downside for larger files\n    // but must be <= LFS_FILE_MAX. Defaults to LFS_FILE_MAX or file_max stored\n    // on disk when zero.\n    lfs_size_t file_max;\n\n    // Optional upper limit on custom attributes in bytes. No downside for\n    // larger attributes size but must be <= LFS_ATTR_MAX. Defaults to\n    // LFS_ATTR_MAX or attr_max stored on disk when zero.\n    lfs_size_t attr_max;\n\n    // Optional upper limit on total space given to metadata pairs in bytes. On\n    // devices with large blocks (e.g. 128kB) setting this to a low size (2-8kB)\n    // can help bound the metadata compaction time. Must be <= block_size.\n    // Defaults to block_size when zero.\n    lfs_size_t metadata_max;\n\n    // Optional upper limit on inlined files in bytes. Inlined files live in\n    // metadata and decrease storage requirements, but may be limited to\n    // improve metadata-related performance. Must be <= cache_size, <=\n    // attr_max, and <= block_size/8. Defaults to the largest possible\n    // inline_max when zero.\n    //\n    // Set to -1 to disable inlined files.\n    lfs_size_t inline_max;\n\n#ifdef LFS_MULTIVERSION\n    // On-disk version to use when writing in the form of 16-bit major version\n    // + 16-bit minor version. This limiting metadata to what is supported by\n    // older minor versions. Note that some features will be lost. Defaults to \n    // to the most recent minor version when zero.\n    uint32_t disk_version;\n#endif\n};\n\n// File info structure\nstruct lfs_info {\n    // Type of the file, either LFS_TYPE_REG or LFS_TYPE_DIR\n    uint8_t type;\n\n    // Size of the file, only valid for REG files. Limited to 32-bits.\n    lfs_size_t size;\n\n    // Name of the file stored as a null-terminated string. Limited to\n    // LFS_NAME_MAX+1, which can be changed by redefining LFS_NAME_MAX to\n    // reduce RAM. LFS_NAME_MAX is stored in superblock and must be\n    // respected by other littlefs drivers.\n    char name[LFS_NAME_MAX+1];\n};\n\n// Filesystem info structure\nstruct lfs_fsinfo {\n    // On-disk version.\n    uint32_t disk_version;\n\n    // Size of a logical block in bytes.\n    lfs_size_t block_size;\n\n    // Number of logical blocks in filesystem.\n    lfs_size_t block_count;\n\n    // Upper limit on the length of file names in bytes.\n    lfs_size_t name_max;\n\n    // Upper limit on the size of files in bytes.\n    lfs_size_t file_max;\n\n    // Upper limit on the size of custom attributes in bytes.\n    lfs_size_t attr_max;\n};\n\n// Custom attribute structure, used to describe custom attributes\n// committed atomically during file writes.\nstruct lfs_attr {\n    // 8-bit type of attribute, provided by user and used to\n    // identify the attribute\n    uint8_t type;\n\n    // Pointer to buffer containing the attribute\n    void *buffer;\n\n    // Size of attribute in bytes, limited to LFS_ATTR_MAX\n    lfs_size_t size;\n};\n\n// Optional configuration provided during lfs_file_opencfg\nstruct lfs_file_config {\n    // Optional statically allocated file buffer. Must be cache_size.\n    // By default lfs_malloc is used to allocate this buffer.\n    void *buffer;\n\n    // Optional list of custom attributes related to the file. If the file\n    // is opened with read access, these attributes will be read from disk\n    // during the open call. If the file is opened with write access, the\n    // attributes will be written to disk every file sync or close. This\n    // write occurs atomically with update to the file's contents.\n    //\n    // Custom attributes are uniquely identified by an 8-bit type and limited\n    // to LFS_ATTR_MAX bytes. When read, if the stored attribute is smaller\n    // than the buffer, it will be padded with zeros. If the stored attribute\n    // is larger, then it will be silently truncated. If the attribute is not\n    // found, it will be created implicitly.\n    struct lfs_attr *attrs;\n\n    // Number of custom attributes in the list\n    lfs_size_t attr_count;\n};\n\n\n/// internal littlefs data structures ///\ntypedef struct lfs_cache {\n    lfs_block_t block;\n    lfs_off_t off;\n    lfs_size_t size;\n    uint8_t *buffer;\n} lfs_cache_t;\n\ntypedef struct lfs_mdir {\n    lfs_block_t pair[2];\n    uint32_t rev;\n    lfs_off_t off;\n    uint32_t etag;\n    uint16_t count;\n    bool erased;\n    bool split;\n    lfs_block_t tail[2];\n} lfs_mdir_t;\n\n// littlefs directory type\ntypedef struct lfs_dir {\n    struct lfs_dir *next;\n    uint16_t id;\n    uint8_t type;\n    lfs_mdir_t m;\n\n    lfs_off_t pos;\n    lfs_block_t head[2];\n} lfs_dir_t;\n\n// littlefs file type\ntypedef struct lfs_file {\n    struct lfs_file *next;\n    uint16_t id;\n    uint8_t type;\n    lfs_mdir_t m;\n\n    struct lfs_ctz {\n        lfs_block_t head;\n        lfs_size_t size;\n    } ctz;\n\n    uint32_t flags;\n    lfs_off_t pos;\n    lfs_block_t block;\n    lfs_off_t off;\n    lfs_cache_t cache;\n\n    const struct lfs_file_config *cfg;\n} lfs_file_t;\n\ntypedef struct lfs_superblock {\n    uint32_t version;\n    lfs_size_t block_size;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n} lfs_superblock_t;\n\ntypedef struct lfs_gstate {\n    uint32_t tag;\n    lfs_block_t pair[2];\n} lfs_gstate_t;\n\n// The littlefs filesystem type\ntypedef struct lfs {\n    lfs_cache_t rcache;\n    lfs_cache_t pcache;\n\n    lfs_block_t root[2];\n    struct lfs_mlist {\n        struct lfs_mlist *next;\n        uint16_t id;\n        uint8_t type;\n        lfs_mdir_t m;\n    } *mlist;\n    uint32_t seed;\n\n    lfs_gstate_t gstate;\n    lfs_gstate_t gdisk;\n    lfs_gstate_t gdelta;\n\n    struct lfs_lookahead {\n        lfs_block_t start;\n        lfs_block_t size;\n        lfs_block_t next;\n        lfs_block_t ckpoint;\n        uint8_t *buffer;\n    } lookahead;\n\n    const struct lfs_config *cfg;\n    lfs_size_t block_count;\n    lfs_size_t name_max;\n    lfs_size_t file_max;\n    lfs_size_t attr_max;\n    lfs_size_t inline_max;\n\n#ifdef LFS_MIGRATE\n    struct lfs1 *lfs1;\n#endif\n} lfs_t;\n\n\n/// Filesystem functions ///\n\n#ifndef LFS_READONLY\n// Format a block device with the littlefs\n//\n// Requires a littlefs object and config struct. This clobbers the littlefs\n// object, and does not leave the filesystem mounted. The config struct must\n// be zeroed for defaults and backwards compatibility.\n//\n// Returns a negative error code on failure.\nint lfs_format(lfs_t *lfs, const struct lfs_config *config);\n#endif\n\n// Mounts a littlefs\n//\n// Requires a littlefs object and config struct. Multiple filesystems\n// may be mounted simultaneously with multiple littlefs objects. Both\n// lfs and config must be allocated while mounted. The config struct must\n// be zeroed for defaults and backwards compatibility.\n//\n// Returns a negative error code on failure.\nint lfs_mount(lfs_t *lfs, const struct lfs_config *config);\n\n// Unmounts a littlefs\n//\n// Does nothing besides releasing any allocated resources.\n// Returns a negative error code on failure.\nint lfs_unmount(lfs_t *lfs);\n\n/// General operations ///\n\n#ifndef LFS_READONLY\n// Removes a file or directory\n//\n// If removing a directory, the directory must be empty.\n// Returns a negative error code on failure.\nint lfs_remove(lfs_t *lfs, const char *path);\n#endif\n\n#ifndef LFS_READONLY\n// Rename or move a file or directory\n//\n// If the destination exists, it must match the source in type.\n// If the destination is a directory, the directory must be empty.\n//\n// Returns a negative error code on failure.\nint lfs_rename(lfs_t *lfs, const char *oldpath, const char *newpath);\n#endif\n\n// Find info about a file or directory\n//\n// Fills out the info structure, based on the specified file or directory.\n// Returns a negative error code on failure.\nint lfs_stat(lfs_t *lfs, const char *path, struct lfs_info *info);\n\n// Get a custom attribute\n//\n// Custom attributes are uniquely identified by an 8-bit type and limited\n// to LFS_ATTR_MAX bytes. When read, if the stored attribute is smaller than\n// the buffer, it will be padded with zeros. If the stored attribute is larger,\n// then it will be silently truncated. If no attribute is found, the error\n// LFS_ERR_NOATTR is returned and the buffer is filled with zeros.\n//\n// Returns the size of the attribute, or a negative error code on failure.\n// Note, the returned size is the size of the attribute on disk, irrespective\n// of the size of the buffer. This can be used to dynamically allocate a buffer\n// or check for existence.\nlfs_ssize_t lfs_getattr(lfs_t *lfs, const char *path,\n        uint8_t type, void *buffer, lfs_size_t size);\n\n#ifndef LFS_READONLY\n// Set custom attributes\n//\n// Custom attributes are uniquely identified by an 8-bit type and limited\n// to LFS_ATTR_MAX bytes. If an attribute is not found, it will be\n// implicitly created.\n//\n// Returns a negative error code on failure.\nint lfs_setattr(lfs_t *lfs, const char *path,\n        uint8_t type, const void *buffer, lfs_size_t size);\n#endif\n\n#ifndef LFS_READONLY\n// Removes a custom attribute\n//\n// If an attribute is not found, nothing happens.\n//\n// Returns a negative error code on failure.\nint lfs_removeattr(lfs_t *lfs, const char *path, uint8_t type);\n#endif\n\n\n/// File operations ///\n\n#ifndef LFS_NO_MALLOC\n// Open a file\n//\n// The mode that the file is opened in is determined by the flags, which\n// are values from the enum lfs_open_flags that are bitwise-ored together.\n//\n// Returns a negative error code on failure.\nint lfs_file_open(lfs_t *lfs, lfs_file_t *file,\n        const char *path, int flags);\n\n// if LFS_NO_MALLOC is defined, lfs_file_open() will fail with LFS_ERR_NOMEM\n// thus use lfs_file_opencfg() with config.buffer set.\n#endif\n\n// Open a file with extra configuration\n//\n// The mode that the file is opened in is determined by the flags, which\n// are values from the enum lfs_open_flags that are bitwise-ored together.\n//\n// The config struct provides additional config options per file as described\n// above. The config struct must remain allocated while the file is open, and\n// the config struct must be zeroed for defaults and backwards compatibility.\n//\n// Returns a negative error code on failure.\nint lfs_file_opencfg(lfs_t *lfs, lfs_file_t *file,\n        const char *path, int flags,\n        const struct lfs_file_config *config);\n\n// Close a file\n//\n// Any pending writes are written out to storage as though\n// sync had been called and releases any allocated resources.\n//\n// Returns a negative error code on failure.\nint lfs_file_close(lfs_t *lfs, lfs_file_t *file);\n\n// Synchronize a file on storage\n//\n// Any pending writes are written out to storage.\n// Returns a negative error code on failure.\nint lfs_file_sync(lfs_t *lfs, lfs_file_t *file);\n\n// Read data from file\n//\n// Takes a buffer and size indicating where to store the read data.\n// Returns the number of bytes read, or a negative error code on failure.\nlfs_ssize_t lfs_file_read(lfs_t *lfs, lfs_file_t *file,\n        void *buffer, lfs_size_t size);\n\n#ifndef LFS_READONLY\n// Write data to file\n//\n// Takes a buffer and size indicating the data to write. The file will not\n// actually be updated on the storage until either sync or close is called.\n//\n// Returns the number of bytes written, or a negative error code on failure.\nlfs_ssize_t lfs_file_write(lfs_t *lfs, lfs_file_t *file,\n        const void *buffer, lfs_size_t size);\n#endif\n\n// Change the position of the file\n//\n// The change in position is determined by the offset and whence flag.\n// Returns the new position of the file, or a negative error code on failure.\nlfs_soff_t lfs_file_seek(lfs_t *lfs, lfs_file_t *file,\n        lfs_soff_t off, int whence);\n\n#ifndef LFS_READONLY\n// Truncates the size of the file to the specified size\n//\n// Returns a negative error code on failure.\nint lfs_file_truncate(lfs_t *lfs, lfs_file_t *file, lfs_off_t size);\n#endif\n\n// Return the position of the file\n//\n// Equivalent to lfs_file_seek(lfs, file, 0, LFS_SEEK_CUR)\n// Returns the position of the file, or a negative error code on failure.\nlfs_soff_t lfs_file_tell(lfs_t *lfs, lfs_file_t *file);\n\n// Change the position of the file to the beginning of the file\n//\n// Equivalent to lfs_file_seek(lfs, file, 0, LFS_SEEK_SET)\n// Returns a negative error code on failure.\nint lfs_file_rewind(lfs_t *lfs, lfs_file_t *file);\n\n// Return the size of the file\n//\n// Similar to lfs_file_seek(lfs, file, 0, LFS_SEEK_END)\n// Returns the size of the file, or a negative error code on failure.\nlfs_soff_t lfs_file_size(lfs_t *lfs, lfs_file_t *file);\n\n\n/// Directory operations ///\n\n#ifndef LFS_READONLY\n// Create a directory\n//\n// Returns a negative error code on failure.\nint lfs_mkdir(lfs_t *lfs, const char *path);\n#endif\n\n// Open a directory\n//\n// Once open a directory can be used with read to iterate over files.\n// Returns a negative error code on failure.\nint lfs_dir_open(lfs_t *lfs, lfs_dir_t *dir, const char *path);\n\n// Close a directory\n//\n// Releases any allocated resources.\n// Returns a negative error code on failure.\nint lfs_dir_close(lfs_t *lfs, lfs_dir_t *dir);\n\n// Read an entry in the directory\n//\n// Fills out the info structure, based on the specified file or directory.\n// Returns a positive value on success, 0 at the end of directory,\n// or a negative error code on failure.\nint lfs_dir_read(lfs_t *lfs, lfs_dir_t *dir, struct lfs_info *info);\n\n// Change the position of the directory\n//\n// The new off must be a value previous returned from tell and specifies\n// an absolute offset in the directory seek.\n//\n// Returns a negative error code on failure.\nint lfs_dir_seek(lfs_t *lfs, lfs_dir_t *dir, lfs_off_t off);\n\n// Return the position of the directory\n//\n// The returned offset is only meant to be consumed by seek and may not make\n// sense, but does indicate the current position in the directory iteration.\n//\n// Returns the position of the directory, or a negative error code on failure.\nlfs_soff_t lfs_dir_tell(lfs_t *lfs, lfs_dir_t *dir);\n\n// Change the position of the directory to the beginning of the directory\n//\n// Returns a negative error code on failure.\nint lfs_dir_rewind(lfs_t *lfs, lfs_dir_t *dir);\n\n\n/// Filesystem-level filesystem operations\n\n// Find on-disk info about the filesystem\n//\n// Fills out the fsinfo structure based on the filesystem found on-disk.\n// Returns a negative error code on failure.\nint lfs_fs_stat(lfs_t *lfs, struct lfs_fsinfo *fsinfo);\n\n// Finds the current size of the filesystem\n//\n// Note: Result is best effort. If files share COW structures, the returned\n// size may be larger than the filesystem actually is.\n//\n// Returns the number of allocated blocks, or a negative error code on failure.\nlfs_ssize_t lfs_fs_size(lfs_t *lfs);\n\n// Traverse through all blocks in use by the filesystem\n//\n// The provided callback will be called with each block address that is\n// currently in use by the filesystem. This can be used to determine which\n// blocks are in use or how much of the storage is available.\n//\n// Returns a negative error code on failure.\nint lfs_fs_traverse(lfs_t *lfs, int (*cb)(void*, lfs_block_t), void *data);\n\n#ifndef LFS_READONLY\n// Attempt to make the filesystem consistent and ready for writing\n//\n// Calling this function is not required, consistency will be implicitly\n// enforced on the first operation that writes to the filesystem, but this\n// function allows the work to be performed earlier and without other\n// filesystem changes.\n//\n// Returns a negative error code on failure.\nint lfs_fs_mkconsistent(lfs_t *lfs);\n#endif\n\n#ifndef LFS_READONLY\n// Attempt any janitorial work\n//\n// This currently:\n// 1. Calls mkconsistent if not already consistent\n// 2. Compacts metadata > compact_thresh\n// 3. Populates the block allocator\n//\n// Though additional janitorial work may be added in the future.\n//\n// Calling this function is not required, but may allow the offloading of\n// expensive janitorial work to a less time-critical code path.\n//\n// Returns a negative error code on failure. Accomplishing nothing is not\n// an error.\nint lfs_fs_gc(lfs_t *lfs);\n#endif\n\n#ifndef LFS_READONLY\n// Grows the filesystem to a new size, updating the superblock with the new\n// block count.\n//\n// Note: This is irreversible.\n//\n// Returns a negative error code on failure.\nint lfs_fs_grow(lfs_t *lfs, lfs_size_t block_count);\n#endif\n\n#ifndef LFS_READONLY\n#ifdef LFS_MIGRATE\n// Attempts to migrate a previous version of littlefs\n//\n// Behaves similarly to the lfs_format function. Attempts to mount\n// the previous version of littlefs and update the filesystem so it can be\n// mounted with the current version of littlefs.\n//\n// Requires a littlefs object and config struct. This clobbers the littlefs\n// object, and does not leave the filesystem mounted. The config struct must\n// be zeroed for defaults and backwards compatibility.\n//\n// Returns a negative error code on failure.\nint lfs_migrate(lfs_t *lfs, const struct lfs_config *cfg);\n#endif\n#endif\n\n\n#ifdef __cplusplus\n} /* extern \"C\" */\n#endif\n\n#endif\n"
        },
        {
          "name": "lfs_util.c",
          "type": "blob",
          "size": 0.96484375,
          "content": "/*\n * lfs util functions\n *\n * Copyright (c) 2022, The littlefs authors.\n * Copyright (c) 2017, Arm Limited. All rights reserved.\n * SPDX-License-Identifier: BSD-3-Clause\n */\n#include \"lfs_util.h\"\n\n// Only compile if user does not provide custom config\n#ifndef LFS_CONFIG\n\n\n// If user provides their own CRC impl we don't need this\n#ifndef LFS_CRC\n// Software CRC implementation with small lookup table\nuint32_t lfs_crc(uint32_t crc, const void *buffer, size_t size) {\n    static const uint32_t rtable[16] = {\n        0x00000000, 0x1db71064, 0x3b6e20c8, 0x26d930ac,\n        0x76dc4190, 0x6b6b51f4, 0x4db26158, 0x5005713c,\n        0xedb88320, 0xf00f9344, 0xd6d6a3e8, 0xcb61b38c,\n        0x9b64c2b0, 0x86d3d2d4, 0xa00ae278, 0xbdbdf21c,\n    };\n\n    const uint8_t *data = buffer;\n\n    for (size_t i = 0; i < size; i++) {\n        crc = (crc >> 4) ^ rtable[(crc ^ (data[i] >> 0)) & 0xf];\n        crc = (crc >> 4) ^ rtable[(crc ^ (data[i] >> 4)) & 0xf];\n    }\n\n    return crc;\n}\n#endif\n\n\n#endif\n"
        },
        {
          "name": "lfs_util.h",
          "type": "blob",
          "size": 7.767578125,
          "content": "/*\n * lfs utility functions\n *\n * Copyright (c) 2022, The littlefs authors.\n * Copyright (c) 2017, Arm Limited. All rights reserved.\n * SPDX-License-Identifier: BSD-3-Clause\n */\n#ifndef LFS_UTIL_H\n#define LFS_UTIL_H\n\n#define LFS_STRINGIZE(x) LFS_STRINGIZE2(x)\n#define LFS_STRINGIZE2(x) #x\n\n// Users can override lfs_util.h with their own configuration by defining\n// LFS_CONFIG as a header file to include (-DLFS_CONFIG=lfs_config.h).\n//\n// If LFS_CONFIG is used, none of the default utils will be emitted and must be\n// provided by the config file. To start, I would suggest copying lfs_util.h\n// and modifying as needed.\n#ifdef LFS_CONFIG\n#include LFS_STRINGIZE(LFS_CONFIG)\n#else\n\n// Alternatively, users can provide a header file which defines\n// macros and other things consumed by littlefs.\n//\n// For example, provide my_defines.h, which contains\n// something like:\n//\n// #include <stddef.h>\n// extern void *my_malloc(size_t sz);\n// #define LFS_MALLOC(sz) my_malloc(sz)\n//\n// And build littlefs with the header by defining LFS_DEFINES.\n// (-DLFS_DEFINES=my_defines.h)\n\n#ifdef LFS_DEFINES\n#include LFS_STRINGIZE(LFS_DEFINES)\n#endif\n\n// System includes\n#include <stdint.h>\n#include <stdbool.h>\n#include <string.h>\n#include <inttypes.h>\n\n#ifndef LFS_NO_MALLOC\n#include <stdlib.h>\n#endif\n#ifndef LFS_NO_ASSERT\n#include <assert.h>\n#endif\n#if !defined(LFS_NO_DEBUG) || \\\n        !defined(LFS_NO_WARN) || \\\n        !defined(LFS_NO_ERROR) || \\\n        defined(LFS_YES_TRACE)\n#include <stdio.h>\n#endif\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n\n// Macros, may be replaced by system specific wrappers. Arguments to these\n// macros must not have side-effects as the macros can be removed for a smaller\n// code footprint\n\n// Logging functions\n#ifndef LFS_TRACE\n#ifdef LFS_YES_TRACE\n#define LFS_TRACE_(fmt, ...) \\\n    printf(\"%s:%d:trace: \" fmt \"%s\\n\", __FILE__, __LINE__, __VA_ARGS__)\n#define LFS_TRACE(...) LFS_TRACE_(__VA_ARGS__, \"\")\n#else\n#define LFS_TRACE(...)\n#endif\n#endif\n\n#ifndef LFS_DEBUG\n#ifndef LFS_NO_DEBUG\n#define LFS_DEBUG_(fmt, ...) \\\n    printf(\"%s:%d:debug: \" fmt \"%s\\n\", __FILE__, __LINE__, __VA_ARGS__)\n#define LFS_DEBUG(...) LFS_DEBUG_(__VA_ARGS__, \"\")\n#else\n#define LFS_DEBUG(...)\n#endif\n#endif\n\n#ifndef LFS_WARN\n#ifndef LFS_NO_WARN\n#define LFS_WARN_(fmt, ...) \\\n    printf(\"%s:%d:warn: \" fmt \"%s\\n\", __FILE__, __LINE__, __VA_ARGS__)\n#define LFS_WARN(...) LFS_WARN_(__VA_ARGS__, \"\")\n#else\n#define LFS_WARN(...)\n#endif\n#endif\n\n#ifndef LFS_ERROR\n#ifndef LFS_NO_ERROR\n#define LFS_ERROR_(fmt, ...) \\\n    printf(\"%s:%d:error: \" fmt \"%s\\n\", __FILE__, __LINE__, __VA_ARGS__)\n#define LFS_ERROR(...) LFS_ERROR_(__VA_ARGS__, \"\")\n#else\n#define LFS_ERROR(...)\n#endif\n#endif\n\n// Runtime assertions\n#ifndef LFS_ASSERT\n#ifndef LFS_NO_ASSERT\n#define LFS_ASSERT(test) assert(test)\n#else\n#define LFS_ASSERT(test)\n#endif\n#endif\n\n\n// Builtin functions, these may be replaced by more efficient\n// toolchain-specific implementations. LFS_NO_INTRINSICS falls back to a more\n// expensive basic C implementation for debugging purposes\n\n// Min/max functions for unsigned 32-bit numbers\nstatic inline uint32_t lfs_max(uint32_t a, uint32_t b) {\n    return (a > b) ? a : b;\n}\n\nstatic inline uint32_t lfs_min(uint32_t a, uint32_t b) {\n    return (a < b) ? a : b;\n}\n\n// Align to nearest multiple of a size\nstatic inline uint32_t lfs_aligndown(uint32_t a, uint32_t alignment) {\n    return a - (a % alignment);\n}\n\nstatic inline uint32_t lfs_alignup(uint32_t a, uint32_t alignment) {\n    return lfs_aligndown(a + alignment-1, alignment);\n}\n\n// Find the smallest power of 2 greater than or equal to a\nstatic inline uint32_t lfs_npw2(uint32_t a) {\n#if !defined(LFS_NO_INTRINSICS) && (defined(__GNUC__) || defined(__CC_ARM))\n    return 32 - __builtin_clz(a-1);\n#else\n    uint32_t r = 0;\n    uint32_t s;\n    a -= 1;\n    s = (a > 0xffff) << 4; a >>= s; r |= s;\n    s = (a > 0xff  ) << 3; a >>= s; r |= s;\n    s = (a > 0xf   ) << 2; a >>= s; r |= s;\n    s = (a > 0x3   ) << 1; a >>= s; r |= s;\n    return (r | (a >> 1)) + 1;\n#endif\n}\n\n// Count the number of trailing binary zeros in a\n// lfs_ctz(0) may be undefined\nstatic inline uint32_t lfs_ctz(uint32_t a) {\n#if !defined(LFS_NO_INTRINSICS) && defined(__GNUC__)\n    return __builtin_ctz(a);\n#else\n    return lfs_npw2((a & -a) + 1) - 1;\n#endif\n}\n\n// Count the number of binary ones in a\nstatic inline uint32_t lfs_popc(uint32_t a) {\n#if !defined(LFS_NO_INTRINSICS) && (defined(__GNUC__) || defined(__CC_ARM))\n    return __builtin_popcount(a);\n#else\n    a = a - ((a >> 1) & 0x55555555);\n    a = (a & 0x33333333) + ((a >> 2) & 0x33333333);\n    return (((a + (a >> 4)) & 0xf0f0f0f) * 0x1010101) >> 24;\n#endif\n}\n\n// Find the sequence comparison of a and b, this is the distance\n// between a and b ignoring overflow\nstatic inline int lfs_scmp(uint32_t a, uint32_t b) {\n    return (int)(unsigned)(a - b);\n}\n\n// Convert between 32-bit little-endian and native order\nstatic inline uint32_t lfs_fromle32(uint32_t a) {\n#if (defined(  BYTE_ORDER  ) && defined(  ORDER_LITTLE_ENDIAN  ) &&   BYTE_ORDER   ==   ORDER_LITTLE_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER  ) && defined(__ORDER_LITTLE_ENDIAN  ) && __BYTE_ORDER   == __ORDER_LITTLE_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER__) && defined(__ORDER_LITTLE_ENDIAN__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)\n    return a;\n#elif !defined(LFS_NO_INTRINSICS) && ( \\\n    (defined(  BYTE_ORDER  ) && defined(  ORDER_BIG_ENDIAN  ) &&   BYTE_ORDER   ==   ORDER_BIG_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER  ) && defined(__ORDER_BIG_ENDIAN  ) && __BYTE_ORDER   == __ORDER_BIG_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER__) && defined(__ORDER_BIG_ENDIAN__) && __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__))\n    return __builtin_bswap32(a);\n#else\n    return (((uint8_t*)&a)[0] <<  0) |\n           (((uint8_t*)&a)[1] <<  8) |\n           (((uint8_t*)&a)[2] << 16) |\n           (((uint8_t*)&a)[3] << 24);\n#endif\n}\n\nstatic inline uint32_t lfs_tole32(uint32_t a) {\n    return lfs_fromle32(a);\n}\n\n// Convert between 32-bit big-endian and native order\nstatic inline uint32_t lfs_frombe32(uint32_t a) {\n#if !defined(LFS_NO_INTRINSICS) && ( \\\n    (defined(  BYTE_ORDER  ) && defined(  ORDER_LITTLE_ENDIAN  ) &&   BYTE_ORDER   ==   ORDER_LITTLE_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER  ) && defined(__ORDER_LITTLE_ENDIAN  ) && __BYTE_ORDER   == __ORDER_LITTLE_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER__) && defined(__ORDER_LITTLE_ENDIAN__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__))\n    return __builtin_bswap32(a);\n#elif (defined(  BYTE_ORDER  ) && defined(  ORDER_BIG_ENDIAN  ) &&   BYTE_ORDER   ==   ORDER_BIG_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER  ) && defined(__ORDER_BIG_ENDIAN  ) && __BYTE_ORDER   == __ORDER_BIG_ENDIAN  ) || \\\n    (defined(__BYTE_ORDER__) && defined(__ORDER_BIG_ENDIAN__) && __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)\n    return a;\n#else\n    return (((uint8_t*)&a)[0] << 24) |\n           (((uint8_t*)&a)[1] << 16) |\n           (((uint8_t*)&a)[2] <<  8) |\n           (((uint8_t*)&a)[3] <<  0);\n#endif\n}\n\nstatic inline uint32_t lfs_tobe32(uint32_t a) {\n    return lfs_frombe32(a);\n}\n\n// Calculate CRC-32 with polynomial = 0x04c11db7\n#ifdef LFS_CRC\nuint32_t lfs_crc(uint32_t crc, const void *buffer, size_t size) {\n    return LFS_CRC(crc, buffer, size)\n}\n#else\nuint32_t lfs_crc(uint32_t crc, const void *buffer, size_t size);\n#endif\n\n// Allocate memory, only used if buffers are not provided to littlefs\n//\n// littlefs current has no alignment requirements, as it only allocates\n// byte-level buffers.\nstatic inline void *lfs_malloc(size_t size) {\n#if defined(LFS_MALLOC)\n    return LFS_MALLOC(size);\n#elif !defined(LFS_NO_MALLOC)\n    return malloc(size);\n#else\n    (void)size;\n    return NULL;\n#endif\n}\n\n// Deallocate memory, only used if buffers are not provided to littlefs\nstatic inline void lfs_free(void *p) {\n#if defined(LFS_FREE)\n    LFS_FREE(p);\n#elif !defined(LFS_NO_MALLOC)\n    free(p);\n#else\n    (void)p;\n#endif\n}\n\n\n#ifdef __cplusplus\n} /* extern \"C\" */\n#endif\n\n#endif\n#endif\n"
        },
        {
          "name": "runners",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}