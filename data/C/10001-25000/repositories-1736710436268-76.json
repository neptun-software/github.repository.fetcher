{
  "metadata": {
    "timestamp": 1736710436268,
    "page": 76,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "libevent/libevent",
      "stars": 11278,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 1.5859375,
          "content": "---\nLanguage:          Cpp\nBasedOnStyle:      LLVM\n\nAccessModifierOffset: -4\n\nAlignAfterOpenBracket: DontAlign\nAlignEscapedNewlinesLeft: true\n# AlignOperands: true\nAlignTrailingComments: true\n\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: All\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\n\nAlwaysBreakAfterDefinitionReturnType: All\nAlwaysBreakBeforeMultilineStrings: false\nAlwaysBreakTemplateDeclarations: false\n\n# BinPackArguments: false\n# BinPackParameters: true\n\nBreakBeforeBinaryOperators: false\nBreakBeforeBraces: Custom\nBraceWrapping: { AfterFunction: true }\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: true\n\nColumnLimit:     80\n\nContinuationIndentWidth: 4\n\nDerivePointerAlignment: false #XXX\nDisableFormat:   false\nExperimentalAutoDetectBinPacking: false #XXX\nForEachMacros:   [ LIST_FOREACH, SIMPLEQ_FOREACH, CIRCLEQ_FOREACH, TAILQ_FOREACH, TAILQ_FOREACH_REVERSE, HT_FOREACH ]\n\nIndentCaseLabels: false\nIndentFunctionDeclarationAfterType: false\nIndentWidth:     4\nIndentWrappedFunctionNames: false\n\nKeepEmptyLinesAtTheStartOfBlocks: true\nMaxEmptyLinesToKeep: 2\n\nPointerAlignment: Right #XXX\n\n# SpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles:  false\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nStandard:        Cpp03\nTabWidth:        4\nUseTab:          Always\nSortIncludes:    false\n...\n"
        },
        {
          "name": ".exrc",
          "type": "blob",
          "size": 0.296875,
          "content": "\"\n\" Add this into your .vimrc, to allow vim handle this file.\n\"\n\" set exrc\n\" set secure \" even after this this is kind of dangerous\n\"\n\nset tabstop=4\nset softtabstop=4\nset shiftwidth=4\nset noexpandtab\n\n\" for detectindent plugin\nlet detectindent_preferred_indent=4\nlet g:detectindent_preferred_expandtab=0\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.6787109375,
          "content": "### These files should get ignored no matter where they appear.\n\n# Editors leave these lying around\n\\#*\\#\n.#*\n*~\n*.swp\n\n# Windows stuff\n*.obj\n*.exe\n*.lib\n\n# Patch leaves these lying around\n*.orig\n*.rej\n\n# gcov stuff\n*.gcno\n*.gcov\n*.gcda\n\n# gdb stuff\n.gdb_history\n\n# ctags stuff\nTAGS\ntags\n\n# cscope stuff\ncscope*\n\n# Stuff made by our makefiles\n*.trs\n\n# configure in progress\n*.err\n*.tmp\n/.cyg*\n/confdefs.*\n/conftest\n/conftest.*\n\n# files generated by autotools (`./autogen.sh`)\n## The initial / makes these files only get ignored in particular directories.\n/aclocal.m4\n/autom4te.cache\n/build-aux/\n/configure\n/config.h.in\n/m4/libtool.m4\n/m4/ltoptions.m4\n/m4/ltsugar.m4\n/m4/ltversion.m4\n/m4/lt~obsolete.m4\n/Makefile.in\n\n# files generated by configure (`mkdir build; cd build && ../configure`)\n*.log\n*.pc\n.deps/\nconfig.h\nconfig.log\nconfig.status\nevconfig-private.h\nlibtool\nMakefile\nstamp-h1\nstamp-h2\n\n# other generated config files (which command?)\nconfig.cache\nconfig.guess\nconfig.sub\n\n# files generated by doxygen\ndoxygen\nCMakeDoxyfile.in\nCMakeDoxygenDefaults.cmake\nDoxyfile.doxygen\n\n# files generated by make (`mkdir build; cd build && ../configure && make`)\n.dirstamp\n.libs/\n*.la\n*.lo\n*.o\nevent-config.h\n\n## make generated files under /sample\nbecat\ndns-example\nevent-read-fifo\nevent-test\nhello-world\nhttp-connect\nhttp-server\nhttps-client\nhttps-client-mbedtls\nle-proxy\nsignal-test\nssl-client-mbedtls\ntime-test\nwatch-timing\nws-chat-server\n\n## make generated files under /test\nbench\nbench_cascade\nbench_http\nbench_httpclient\nregress\nrpcgen-attempted\ntest-changelist\ntest-closed\ntest-driver\ntest-dumpevents\ntest-eof\ntest-fdleak\ntest-init\ntest-kq-collision\ntest-ratelim\ntest-script.sh\ntest-time\ntest-weof\n\n# files generated by event_rpcgen.py (`python3 event_rpcgen.py test/regress.rpc`)\nregress.gen.c\nregress.gen.h\n\n# files generated by cmake (`cmake -B build && cmake --build build`)\n/build/\nCMakeCache.txt\nCMakeFiles/\nCTestTestfile.cmake\nCTestCostData.txt\nDartConfiguration.tcl\nLibeventConfig.cmake\nLibeventConfigVersion.cmake\nLibeventTargets*.cmake\nUninstall.cmake\nbin/\ncmake_install.cmake\ncompile_commands.json\nevent.dir\nevent_core.dir\nevent_extra.dir\ninstall_manifest.txt\nlib/\ntmp/\nverify_tests.sh\nverify_tests.bat\n*.vcxproj\n*.sln\n*.filters\n\n# files generated by Xcode (`cmake -B build -G Xcode && cmake --build build`)\n*.resp\n*.d\n*.dia\nDebug/\nRelease/\nXCBuildData/\nCMakeScripts/\nlibevent.xcodeproj/\n\n# files generated by Ninja (`cmake -B build -G Ninja && cmake --build build`)\nbuild.ninja\nrules.ninja\n.ninja_deps\n.ninja_log\n\n# make dist (`mkdir build; cd build && ../configure && make distcheck`)\n/COPYING\n/INSTALL\n*.tar.gz\n\n/.vagrant\n\n# clangd\n.cache\n\n# Project files from IDE or editors\n\n# VS/VSCode\n.vs/\n.vscode/\n\n# IntelliJ/Clion\n.idea/\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 0.2431640625,
          "content": "# name -> email\nAzat Khuzhin           <azat@libevent.org>\nyuangongji             <yuangongji@foxmail.com>\n\n# primary email -> alias\n<azat@libevent.org>                   <a3at.mail@gmail.com>\nyuangongji <yuangongji@foxmail.com>   <82787816@qq.com>\n"
        },
        {
          "name": ".uncrustify",
          "type": "blob",
          "size": 2.6123046875,
          "content": "input_tab_size                           = 8\noutput_tab_size                          = 8\nindent_with_tabs                         = 2\nindent_cmt_with_tabs                     = false\nindent_brace_parent                      = false\nindent_func_call_param                   = true\nindent_func_def_param                    = true\nsp_enum_before_assign                    = add\nsp_enum_after_assign                     = add\nsp_inside_paren                          = remove\nsp_paren_brace                           = add\nsp_before_ptr_star                       = add\nsp_before_unnamed_ptr_star               = add\nsp_between_ptr_star                      = remove\nsp_after_ptr_star                        = remove\nsp_after_ptr_star_func                   = add\nsp_before_ptr_star_func                  = add\nsp_before_sparen                         = add\nsp_inside_sparen                         = remove\nsp_inside_sparen_close                   = remove\nsp_after_sparen                          = add\nsp_sparen_brace                          = add\nsp_special_semi                          = remove\nsp_before_semi_for                       = remove\nsp_after_comma                           = add\nsp_after_cast                            = remove\nsp_inside_braces_struct                  = add\nsp_type_func                             = remove\nsp_func_def_paren                        = remove\nsp_inside_fparen                         = remove\nsp_fparen_brace                          = add\nsp_func_call_paren                       = remove\nsp_else_brace                            = add\nsp_after_oc_block_caret                  = remove\nalign_keep_tabs                          = true\nalign_with_tabs                          = true\nalign_on_tabstop                         = true\nnl_fcall_brace                           = remove\nnl_enum_brace                            = remove\nnl_struct_brace                          = remove\nnl_union_brace                           = remove\nnl_if_brace                              = remove\nnl_brace_else                            = remove\nnl_elseif_brace                          = remove\nnl_else_brace                            = remove\nnl_else_if                               = remove\nnl_for_brace                             = remove\nsp_after_semi_for_empty                  = remove\nnl_while_brace                           = remove\nnl_do_brace                              = remove\nnl_brace_while                           = remove\nnl_switch_brace                          = remove\nnl_func_type_name                        = add\nnl_fdef_brace                            = add\nmod_paren_on_return                      = ignore\n"
        },
        {
          "name": ".yamllint",
          "type": "blob",
          "size": 0.1875,
          "content": "# vi: ft=yaml\n---\nextends: default\n\nrules:\n    indentation:\n        level: warning\n        indent-sequences: consistent\n    line-length: disable\n    # github-actions \"on:\"\n    truthy: disable\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 51.552734375,
          "content": "#\n# Libevent CMake project\n#\n# Based on initial work by:\n#    Alexey Ozeritsky\n#\n# Additional changes:\n#   Brodie Thiesfield\n#   Joakim Soderberg\n#   Trond Norbye\n#   Sergei Nikulov\n#\n#   Build example:\n#\n#       cd libevent\n#       md build\n#       cd build\n#       cmake -G \"Visual Studio 10\" ..\n#       start libevent.sln\n#\n\ncmake_minimum_required(VERSION 3.10 FATAL_ERROR)\n\nif (POLICY CMP0074)\n    cmake_policy(SET CMP0074 NEW)\nendif()\nif (POLICY CMP0075)\n    cmake_policy(SET CMP0075 NEW)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE Release\n        CACHE STRING \"Set build type to Debug or Release (default Release)\" FORCE)\n    message(STATUS \"Set CMAKE_BUILD_TYPE to Release (default)\")\nendif()\nstring(TOLOWER \"${CMAKE_BUILD_TYPE}\" CMAKE_BUILD_TYPE_LOWER)\n\n# Usually it is OK to define it unconditionally, but the problem is that we use\n# CMAKE_DEBUG_POSTFIX in *.pc.in\nif (CMAKE_BUILD_TYPE_LOWER STREQUAL \"debug\")\n    if(NOT DEFINED CMAKE_DEBUG_POSTFIX)\n        set(CMAKE_DEBUG_POSTFIX d)\n    endif()\nendif()\n\nset(EVENT__LIBRARY_TYPE DEFAULT CACHE STRING\n    \"Set library type to SHARED/STATIC/BOTH (default SHARED for MSVC, otherwise BOTH)\")\n\nproject(libevent C)\n\nlist(APPEND CMAKE_MODULE_PATH \"${PROJECT_SOURCE_DIR}/cmake/\")\nstring(REGEX MATCH \"SunOS\" SOLARIS \"${CMAKE_SYSTEM_NAME}\")\n\n\ninclude(CheckTypeSize)\ninclude(CheckFileOffsetBits)\ninclude(Macros)\ninclude(CheckVariableExists)\ninclude(CheckSymbolExists)\ninclude(CheckStructHasMember)\ninclude(CheckCSourceCompiles)\ninclude(CheckPrototypeDefinition)\ninclude(CheckFunctionKeywords)\ninclude(CheckConstExists)\ninclude(AddCompilerFlags)\ninclude(AddLinkerFlags)\ninclude(VersionViaGit)\n\nevent_fuzzy_version_from_git()\n\nset(EVENT_VERSION_MAJOR ${EVENT_GIT___VERSION_MAJOR})\nset(EVENT_VERSION_MINOR ${EVENT_GIT___VERSION_MINOR})\nset(EVENT_VERSION_PATCH ${EVENT_GIT___VERSION_PATCH})\nset(EVENT_VERSION_STAGE ${EVENT_GIT___VERSION_STAGE})\n\n\nset(EVENT_ABI_MAJOR ${EVENT_VERSION_MAJOR})\nset(EVENT_ABI_MINOR ${EVENT_VERSION_MINOR})\nset(EVENT_ABI_PATCH ${EVENT_VERSION_PATCH})\n\nset(EVENT_ABI_LIBVERSION\n    \"${EVENT_ABI_MAJOR}.${EVENT_ABI_MINOR}.${EVENT_ABI_PATCH}\")\n\nset(EVENT_PACKAGE_VERSION\n    \"${EVENT_VERSION_MAJOR}.${EVENT_VERSION_MINOR}.${EVENT_VERSION_PATCH}\")\n\n# equals to VERSION_INFO in Makefile.am\nset(EVENT_ABI_LIBVERSION_CURRENT   1)\nset(EVENT_ABI_LIBVERSION_REVISION  0)\nset(EVENT_ABI_LIBVERSION_AGE       0)\n\n# equals to RELEASE in Makefile.am\nset(EVENT_PACKAGE_RELEASE 2.2)\n\n# The last number is development version or not.\nset(EVENT_NUMERIC_VERSION 0x02020100)\n\n# only a subset of names can be used, defaults to \"beta\"\nset(EVENT_STAGE_NAME ${EVENT_VERSION_STAGE})\n\n# a list that defines what can set for EVENT_STAGE_VERSION\nset(EVENT__ALLOWED_STAGE_NAMES\n\trc\n\tbeta\n\talpha\n\talpha-dev\n\trelease\n\tstable\n)\nlist(\n\tFIND EVENT__ALLOWED_STAGE_NAMES\n\t\"${EVENT_STAGE_NAME}\"\n\tEVENT__STAGE_RET\n)\nif (EVENT__STAGE_RET EQUAL -1)\n\tmessage(WARNING\n\t\t\"stage ${EVENT_STAGE_NAME} is not allowed, reset to beta\")\n\tset(EVENT_STAGE_NAME beta)\nendif()\n\nset(EVENT_VERSION\n\t\"${EVENT_VERSION_MAJOR}.${EVENT_VERSION_MINOR}.${EVENT_VERSION_PATCH}-${EVENT_STAGE_NAME}\")\n\noption(EVENT__DISABLE_DEBUG_MODE\n    \"Define if libevent should build without support for a debug mode\" OFF)\n\noption(EVENT__ENABLE_VERBOSE_DEBUG\n    \"Enables verbose debugging\" OFF)\n\noption(EVENT__DISABLE_MM_REPLACEMENT\n    \"Define if libevent should not allow replacing the mm functions\" OFF)\n\noption(EVENT__DISABLE_THREAD_SUPPORT\n    \"Define if libevent should not be compiled with thread support\" OFF)\n\nset(EVENT__DISABLE_OPENSSL AUTO CACHE STRING\n    \"OpenSSL library support: AUTO (use if present), ON (ignore), OFF (require presence)\")\nset_property(CACHE EVENT__DISABLE_OPENSSL PROPERTY STRINGS AUTO ON OFF)\n\nset(EVENT__DISABLE_MBEDTLS AUTO CACHE STRING\n    \"Mbed TLS library support: AUTO (use if present), ON (ignore), OFF (require presence)\")\nset_property(CACHE EVENT__DISABLE_MBEDTLS PROPERTY STRINGS AUTO ON OFF)\n\noption(EVENT__DISABLE_BENCHMARK\n    \"Defines if libevent should build without the benchmark executables\" OFF)\n\noption(EVENT__DISABLE_TESTS\n    \"If tests should be compiled or not\" OFF)\n\noption(EVENT__DISABLE_REGRESS\n    \"Disable the regress tests\" OFF)\n\noption(EVENT__DISABLE_SAMPLES\n    \"Disable sample files\" OFF)\n\noption(EVENT__DISABLE_CLOCK_GETTIME\n    \"Do not use clock_gettime even if it is available\" OFF)\n\noption(EVENT__FORCE_KQUEUE_CHECK\n    \"When crosscompiling forces running a test program that verifies that Kqueue works with pipes. Note that this requires you to manually run the test program on the cross compilation target to verify that it works. See cmake documentation for try_run for more details\" OFF)\n\n# TODO: Add --disable-largefile     omit support for large files\noption(EVENT__COVERAGE\n\"Enable running gcov to get a test coverage report (only works with GCC/CLang). Make sure to enable -DCMAKE_BUILD_TYPE=Debug as well.\" OFF)\n\n# Put the libaries and binaries that get built into directories at the\n# top of the build tree rather than in hard-to-find leaf directories.\n#\n# But only if this variables are not defined yet\n# (i.e. libevent is used via add_subdirectory())\nif (NOT DEFINED CMAKE_RUNTIME_OUTPUT_DIRECTORY)\n    set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/bin)\nendif()\nif (NOT DEFINED CMAKE_LIBRARY_OUTPUT_DIRECTORY)\n    set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/lib)\nendif()\nif (NOT DEFINED CMAKE_ARCHIVE_OUTPUT_DIRECTORY)\n    set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/lib)\nendif()\n\ninclude(GNUInstallDirs)\n\n# The RPATH to be used when installing, but only if it's not a system directory\n#\n# Refs: https://gitlab.kitware.com/cmake/community/-/wikis/doc/cmake/RPATH-handling\nmacro(Configure_RPATH)\n    # NOTE: that CMAKE_INSTALL_FULL_LIBDIR not always normalized correctly, i.e.:\n    # - \"///\" -> \"/\"\n    # - \"/////usr///\" -> \"//usr\"\n    # So it should be normalized again.\n    get_filename_component(CMAKE_INSTALL_LIBDIR_NORMALIZED \"${CMAKE_INSTALL_FULL_LIBDIR}\" REALPATH)\n    list(FIND CMAKE_PLATFORM_IMPLICIT_LINK_DIRECTORIES \"${CMAKE_INSTALL_LIBDIR_NORMALIZED}\" isSystemDir)\n\n    if(DEFINED CMAKE_INSTALL_RPATH)\n        message(STATUS \"CMAKE_INSTALL_RPATH already set\")\n    elseif(\"${isSystemDir}\" STREQUAL \"-1\")\n        set(CMAKE_INSTALL_RPATH \"${CMAKE_INSTALL_LIBDIR_NORMALIZED}\")\n    else()\n        message(STATUS \"Detected install to system directory\")\n    endif()\nendmacro()\nConfigure_RPATH()\n\nif (EVENT__ENABLE_VERBOSE_DEBUG)\n    add_definitions(-DUSE_DEBUG=1)\nendif()\n\nadd_linker_flags(-Wl,-z,max-page-size=16384)\n\n# make it colorful under ninja-build\nif (\"${CMAKE_GENERATOR}\" STREQUAL \"Ninja\")\n    add_compiler_flags(-fdiagnostics-color=always)\nendif()\n\n# Setup compiler flags for coverage.\nif (EVENT__COVERAGE)\n    if (NOT \"${CMAKE_BUILD_TYPE_LOWER}\" STREQUAL \"debug\")\n        message(FATAL_ERROR \"Coverage requires -DCMAKE_BUILD_TYPE=Debug\")\n    endif()\n\n    message(STATUS \"Setting coverage compiler flags\")\n\n    list(APPEND CMAKE_REQUIRED_LIBRARIES \"--coverage\")\n    add_compiler_flags(-g -O0 --coverage)\n    list(REMOVE_ITEM CMAKE_REQUIRED_LIBRARIES \"--coverage\")\nendif()\n\nset(GNUC 0)\nset(CLANG 0)\nset(MSVC 0)\nif ((\"${CMAKE_C_COMPILER_ID}\" STREQUAL \"Clang\") OR\n    (\"${CMAKE_C_COMPILER_ID}\" STREQUAL \"AppleClang\"))\n    set(CLANG 1)\nendif()\nif ((\"${CMAKE_C_COMPILER_ID}\" STREQUAL \"GNU\") OR (${CLANG}))\n    set(GNUC 1)\nendif()\nif ((\"${CMAKE_C_COMPILER_ID}\" STREQUAL \"MSVC\") OR (\"${CMAKE_C_SIMULATE_ID}\" STREQUAL \"MSVC\"))\n    set(MSVC 1)\nendif()\n\n# Detect library type\nset(EVENT_LIBRARY_TYPE)\nif (\"${EVENT__LIBRARY_TYPE}\" STREQUAL \"DEFAULT\")\n    if (${MSVC})\n        set(EVENT_LIBRARY_TYPE SHARED)\n    else()\n        set(EVENT_LIBRARY_TYPE BOTH)\n    endif()\nelse()\n    string(TOUPPER \"${EVENT__LIBRARY_TYPE}\" EVENT_LIBRARY_TYPE)\nendif()\nif ((${MSVC}) AND (\"${EVENT_LIBRARY_TYPE}\" STREQUAL \"BOTH\"))\n    message(WARNING\n      \"Building SHARED and STATIC is not supported for MSVC \"\n      \"(due to conflicts in library name\"\n      \" between STATIC library and IMPORTED library for SHARED libraries)\")\nendif()\nset(EVENT_LIBRARY_STATIC OFF)\nset(EVENT_LIBRARY_SHARED OFF)\nif (\"${EVENT_LIBRARY_TYPE}\" STREQUAL \"BOTH\")\n    set(EVENT_LIBRARY_STATIC ON)\n    set(EVENT_LIBRARY_SHARED ON)\nelseif (\"${EVENT_LIBRARY_TYPE}\" STREQUAL \"STATIC\")\n    set(EVENT_LIBRARY_STATIC ON)\nelseif (\"${EVENT_LIBRARY_TYPE}\" STREQUAL \"SHARED\")\n    set(EVENT_LIBRARY_SHARED ON)\nelse()\n    message(FATAL_ERROR \"${EVENT_LIBRARY_TYPE} is not supported\")\nendif()\n\n# brew support\nif (APPLE)\n    find_program(BREW brew)\nendif()\n\nif (${MSVC})\n    set(msvc_static_runtime OFF)\n    if (\"${EVENT_LIBRARY_TYPE}\" STREQUAL \"STATIC\")\n        set(msvc_static_runtime ON)\n    endif()\n\n    # For more info:\n    # - https://docs.microsoft.com/en-us/cpp/build/reference/md-mt-ld-use-run-time-library?view=vs-2017\n    # - https://gitlab.kitware.com/cmake/community/wikis/FAQ#how-can-i-build-my-msvc-application-with-a-static-runtime\n    option(EVENT__MSVC_STATIC_RUNTIME\n           \"Link static runtime libraries\"\n           ${msvc_static_runtime})\n\n    if (EVENT__MSVC_STATIC_RUNTIME)\n        foreach (flag_var\n                 CMAKE_C_FLAGS_DEBUG\n                 CMAKE_C_FLAGS_RELEASE\n                 CMAKE_C_FLAGS_MINSIZEREL\n                 CMAKE_C_FLAGS_RELWITHDEBINFO\n        )\n            if (${flag_var} MATCHES \"/MD\")\n                string(REGEX REPLACE \"/MD\" \"/MT\" ${flag_var} \"${${flag_var}}\")\n            endif()\n        endforeach()\n    endif()\nendif()\n\n# GNUC specific options.\nif (${GNUC})\n    option(EVENT__DISABLE_GCC_WARNINGS \"Disable verbose warnings with GCC\" OFF)\n    option(EVENT__ENABLE_GCC_HARDENING \"Enable compiler security checks\" OFF)\n    option(EVENT__ENABLE_GCC_FUNCTION_SECTIONS \"Enable gcc function sections\" OFF)\n    option(EVENT__ENABLE_GCC_WARNINGS \"Make all GCC warnings into errors\" OFF)\n\n    list(APPEND __FLAGS\n         -Wall -Wextra -Wno-unused-parameter -Wstrict-aliasing -Wstrict-prototypes\n         -Wundef\n\n         -fno-strict-aliasing # gcc 2.9.5+\n         -Wmissing-prototypes\n\n         # gcc 4\n         -Winit-self\n         -Wmissing-field-initializers\n         -Wdeclaration-after-statement\n\n         # gcc 4.2\n         -Waddress\n         -Wnormalized=id\n         -Woverride-init\n\n         # gcc 4.5\n         -Wlogical-op\n\n         -Wwrite-strings\n\n         # Disable unused-function warnings. These trigger for minheap-internal.h.\n         -Wno-unused-function\n\n         -Wno-pragmas\n\n         -Wvla\n    )\n\n    if (${CLANG})\n        list(APPEND __FLAGS\n             # we use this hack in tests\n             -Wno-void-pointer-to-enum-cast)\n    endif()\n\n    if (EVENT__DISABLE_GCC_WARNINGS)\n        list(APPEND __FLAGS -w)\n    endif()\n\n    if (EVENT__ENABLE_GCC_HARDENING)\n        list(APPEND __FLAGS\n             -fstack-protector-all\n             -fwrapv\n             -fPIE\n             -Wstack-protector\n             \"--param ssp-buffer-size=1\")\n\n        add_definitions(-D_FORTIFY_SOURCE=3)\n    endif()\n\n    if (EVENT__ENABLE_GCC_FUNCTION_SECTIONS)\n        list(APPEND __FLAGS -ffunction-sections)\n        # TODO: Add --gc-sections support. We need some checks for NetBSD to ensure this works.\n    endif()\n\n    if (EVENT__ENABLE_GCC_WARNINGS)\n        list(APPEND __FLAGS -Werror)\n    endif()\n\n    add_compiler_flags(${__FLAGS})\nendif()\n\nif (APPLE)\n    # Clang on macOS emits warnings for each directory specified which isn't used\n    add_compiler_flags(\n        -Qunused-arguments\n    )\nendif()\n\nif (MINGW OR CYGWIN)\n    set(WIN32 TRUE)\nendif()\n\n# Winsock.\nif(WIN32)\n    list(APPEND CMAKE_REQUIRED_LIBRARIES\n        ws2_32\n        shell32\n        advapi32\n        bcrypt\n    )\n    set(CMAKE_REQUIRED_DEFINITIONS -FIwinsock2.h -FIws2tcpip.h -D_WIN32_WINNT=0x0600)\nendif()\nif (SOLARIS)\n    list(APPEND CMAKE_REQUIRED_LIBRARIES\n        socket\n        nsl\n    )\nendif()\n\n# Check if _GNU_SOURCE is available.\nif (NOT DEFINED _GNU_SOURCE)\n  CHECK_SYMBOL_EXISTS(__GNU_LIBRARY__ \"features.h\" _GNU_SOURCE)\n\n  if (NOT _GNU_SOURCE)\n    unset(_GNU_SOURCE CACHE)\n    CHECK_SYMBOL_EXISTS(_GNU_SOURCE \"features.h\" _GNU_SOURCE)\n  endif()\n\n  if (ANDROID)\n    set(_GNU_SOURCE TRUE)\n  endif()\nendif()\n\nif (_GNU_SOURCE)\n    set(CMAKE_REQUIRED_DEFINITIONS -D_GNU_SOURCE)\nendif()\n\n# Check if header files exist\nlist(APPEND FILES_TO_CHECK\n    fcntl.h\n    inttypes.h\n    memory.h\n    signal.h\n    stdarg.h\n    stddef.h\n    stdint.h\n    stdlib.h\n    string.h\n    errno.h\n    unistd.h\n    time.h\n    sys/types.h\n    sys/stat.h\n    sys/time.h\n    sys/param.h\n)\nif (WIN32)\n    list(APPEND FILES_TO_CHECK\n        io.h\n        winsock2.h\n        ws2tcpip.h\n        afunix.h\n    )\nelse()\n    list(APPEND FILES_TO_CHECK\n        netdb.h\n        dlfcn.h\n        arpa/inet.h\n        poll.h\n        port.h\n        sys/socket.h\n        sys/random.h\n        sys/un.h\n        sys/devpoll.h\n        sys/epoll.h\n        sys/eventfd.h\n        sys/event.h\n        sys/ioctl.h\n        sys/mman.h\n        sys/queue.h\n        sys/tree.h\n        sys/select.h\n        sys/sendfile.h\n        sys/uio.h\n        sys/wait.h\n        sys/resource.h\n        sys/timerfd.h\n        sys/signalfd.h\n        netinet/in.h\n        netinet/in6.h\n        netinet/tcp.h\n        ifaddrs.h\n    )\nendif()\n\nif (NOT \"${CMAKE_HOST_SYSTEM_NAME}\" STREQUAL \"Linux\")\n    list(APPEND FILES_TO_CHECK sys/sysctl.h)\nendif()\n\nif (APPLE)\n    list(APPEND FILES_TO_CHECK\n        mach/mach_time.h\n        mach/mach.h\n    )\nendif()\n\nif (NOT EVENT__DISABLE_THREAD_SUPPORT AND NOT WIN32)\n    list(APPEND FILES_TO_CHECK pthread.h)\n    # (Only `CHECK_TYPE_SIZE()' will use `CMAKE_EXTRA_INCLUDE_FILES')\n    list(APPEND CMAKE_EXTRA_INCLUDE_FILES pthread.h)\nendif()\n\n# Fills EVENT_INCLUDES\nforeach(FILE ${FILES_TO_CHECK})\n    CHECK_INCLUDE_FILE_CONCAT(${FILE} \"EVENT\")\nendforeach()\nunset(FILES_TO_CHECK)\n\n# Check if functions exist\nlist(APPEND SYMBOLS_TO_CHECK\n    getaddrinfo\n    gethostbyname\n    getnameinfo\n    getprotobynumber\n    getservbyname\n    gettimeofday\n    inet_ntop\n    inet_pton\n    nanosleep\n    putenv\n    signal\n    socketpair\n    strlcpy\n    strsep\n    strtok_r\n    strtoll\n    timeradd\n    timerclear\n    timerisset\n    umask\n)\nif (NOT EVENT__DISABLE_CLOCK_GETTIME)\n    list(APPEND SYMBOLS_TO_CHECK clock_gettime)\nendif()\n\nif (WIN32)\n    list(APPEND SYMBOLS_TO_CHECK\n        _gmtime64\n        _gmtime64_s\n    )\nelse()\n    list(APPEND SYMBOLS_TO_CHECK\n        accept4\n        arc4random\n        arc4random_buf\n        arc4random_stir\n        epoll_create\n        epoll_create1\n        epoll_ctl\n        epoll_pwait2\n        eventfd\n        fcntl\n        getegid\n        geteuid\n        gethostbyname_r\n        getifaddrs\n        getrandom\n        issetugid\n        kqueue\n        mmap\n        mmap64\n        pipe\n        pipe2\n        poll\n        port_create\n        pread\n        select\n        sendfile\n        setenv\n        setrlimit\n        sigaction\n        strsignal\n        sysctl\n        timerfd_create\n        unsetenv\n        usleep\n    )\n    if (APPLE)\n        list(APPEND SYMBOLS_TO_CHECK mach_absolute_time)\n    endif()\nendif()\n\nset(PTHREADS_AVAILABLE OFF)\nif (NOT EVENT__DISABLE_THREAD_SUPPORT)\n    if (WIN32)\n        list(APPEND SRC_CORE evthread_win32.c)\n    elseif(ANDROID)\n        # pthreads is built in to bionic\n        set(EVENT__HAVE_PTHREADS 1)\n        CHECK_TYPE_SIZE(pthread_t EVENT__SIZEOF_PTHREAD_T)\n        list(APPEND SYMBOLS_TO_CHECK pthread_mutexattr_setprotocol)\n        set(PTHREADS_AVAILABLE ON)\n    else()\n        find_package(Threads REQUIRED)\n        if (NOT CMAKE_USE_PTHREADS_INIT)\n            message(FATAL_ERROR\n                    \"Failed to find Pthreads, set EVENT__DISABLE_THREAD_SUPPORT to disable\")\n        endif()\n        set(PTHREADS_AVAILABLE ON)\n\n        set(EVENT__HAVE_PTHREADS 1)\n        # for CHECK_SYMBOLS_EXIST()\n        list(APPEND CMAKE_REQUIRED_LIBRARIES ${CMAKE_THREAD_LIBS_INIT})\n        list(APPEND LIB_APPS Threads::Threads)\n\n        CHECK_TYPE_SIZE(pthread_t EVENT__SIZEOF_PTHREAD_T)\n        list(APPEND SYMBOLS_TO_CHECK pthread_mutexattr_setprotocol)\n    endif()\nendif()\n\nlist(APPEND CMAKE_EXTRA_INCLUDE_FILES ${EVENT_INCLUDES} stdio.h)\nCHECK_SYMBOLS_EXIST(\"${SYMBOLS_TO_CHECK}\" \"${CMAKE_EXTRA_INCLUDE_FILES}\" \"EVENT\")\nunset(SYMBOLS_TO_CHECK)\nset(EVENT__HAVE_EPOLL ${EVENT__HAVE_EPOLL_CREATE})\nset(EVENT__HAVE_SIGNALFD ${EVENT__HAVE_SYS_SIGNALFD_H})\nif(WIN32 AND NOT CYGWIN)\n    set(EVENT__HAVE_WEPOLL 1)\nendif()\n\n# Get the gethostbyname_r prototype.\nif(EVENT__HAVE_GETHOSTBYNAME_R)\n    CHECK_PROTOTYPE_DEFINITION(gethostbyname_r\n        \"int gethostbyname_r(const char *name, struct hostent *hp, struct hostent_data *hdata)\"\n        \"0\"\n        \"netdb.h\"\n        EVENT__HAVE_GETHOSTBYNAME_R_3_ARG)\n\n    CHECK_PROTOTYPE_DEFINITION(gethostbyname_r\n        \"struct hostent *gethostbyname_r(const char *name, struct hostent *hp, char *buf, size_t buflen, int *herr)\"\n        \"NULL\"\n        \"netdb.h\"\n        EVENT__HAVE_GETHOSTBYNAME_R_5_ARG)\n\n    CHECK_PROTOTYPE_DEFINITION(gethostbyname_r\n        \"int gethostbyname_r(const char *name, struct hostent *hp, char *buf, size_t buflen, struct hostent **result, int *herr)\"\n        \"0\"\n        \"netdb.h\"\n        EVENT__HAVE_GETHOSTBYNAME_R_6_ARG)\nendif()\n\nif(HAVE_PORT_H AND HAVE_PORT_CREATE)\n    set(EVENT__HAVE_EVENT_PORTS 1)\nendif()\n\nCHECK_TYPE_SIZE(\"struct sockaddr_un\" EVENT__HAVE_STRUCT_SOCKADDR_UN)\nCHECK_TYPE_SIZE(\"uint8_t\" EVENT__HAVE_UINT8_T)\nCHECK_TYPE_SIZE(\"uint16_t\" EVENT__HAVE_UINT16_T)\nCHECK_TYPE_SIZE(\"uint32_t\" EVENT__HAVE_UINT32_T)\nCHECK_TYPE_SIZE(\"uint64_t\" EVENT__HAVE_UINT64_T)\nCHECK_TYPE_SIZE(\"short\" EVENT__SIZEOF_SHORT BUILTIN_TYPES_ONLY)\nCHECK_TYPE_SIZE(\"int\" EVENT__SIZEOF_INT BUILTIN_TYPES_ONLY)\nCHECK_TYPE_SIZE(\"unsigned\" EVENT__SIZEOF_UNSIGNED BUILTIN_TYPES_ONLY)\nCHECK_TYPE_SIZE(\"unsigned int\" EVENT__SIZEOF_UNSIGNED_INT BUILTIN_TYPES_ONLY)\nCHECK_TYPE_SIZE(\"long\" EVENT__SIZEOF_LONG BUILTIN_TYPES_ONLY)\nCHECK_TYPE_SIZE(\"long long\" EVENT__SIZEOF_LONG_LONG BUILTIN_TYPES_ONLY)\n\nif(WIN32)\n    # These aren't available until Windows Vista.\n    # But you can still link them. They just won't be found when running the exe.\n    set(EVENT__HAVE_INET_NTOP 0)\n    set(EVENT__HAVE_INET_PTON 0)\nendif()\n\n# Check for different inline keyword versions.\ncheck_function_keywords(\"inline\" \"__inline\" \"__inline__\")\n\nif (HAVE_INLINE)\n    set(EVENT__inline inline)\nelseif (HAVE___INLINE)\n    set(EVENT__inline __inline)\nelseif(HAVE___INLINE__)\n    set(EVENT__inline __inline__)\nelse()\n    set(EVENT__inline)\nendif()\n\n# __func__/__FUNCTION__ is not a macros in general\nCHECK_SYMBOL_EXISTS(\"__func__\"     \"\" EVENT__HAVE___func__)\nCHECK_SYMBOL_EXISTS(\"__FUNCTION__\" \"\" EVENT__HAVE___FUNCTION__)\n\nCHECK_CONST_EXISTS(CTL_KERN sys/sysctl.h EVENT__HAVE_DECL_CTL_KERN)\nCHECK_CONST_EXISTS(KERN_ARND sys/sysctl.h EVENT__HAVE_DECL_KERN_ARND)\nCHECK_SYMBOL_EXISTS(F_SETFD fcntl.h EVENT__HAVE_SETFD)\n\nCHECK_TYPE_SIZE(fd_mask EVENT__HAVE_FD_MASK)\n\nCHECK_TYPE_SIZE(size_t EVENT__SIZEOF_SIZE_T)\nif(NOT EVENT__SIZEOF_SIZE_T)\n  set(EVENT__SIZEOF_SIZE_T ${EVENT__SIZEOF_UNSIGNED})\nendif()\n\nCHECK_TYPE_SIZE(\"off_t\" EVENT__SIZEOF_OFF_T LANGUAGE C)\n\n\n# XXX we should functionalize these size and type sets. --elley\n\n# Winssck.\nif (_MSC_VER)\n    list(APPEND CMAKE_EXTRA_INCLUDE_FILES BaseTsd.h)\nendif()\nCHECK_TYPE_SIZE(\"ssize_t\" EVENT__SIZEOF_SSIZE_T_LOWER LANGUAGE C)\nCHECK_TYPE_SIZE(\"SSIZE_T\" EVENT__SIZEOF_SSIZE_T_UPPER LANGUAGE C)\n\nif (EVENT__SIZEOF_SSIZE_T_LOWER)\n    set(EVENT__ssize_t \"ssize_t\")\nelseif (EVENT__SIZEOF_SSIZE_T_UPPER)\n    set(EVENT__ssize_t \"SSIZE_T\")\nelse()\n    set(EVENT__ssize_t \"int\")\nendif()\n\nCHECK_TYPE_SIZE(socklen_t EVENT__SIZEOF_SOCKLEN_T)\nif(NOT EVENT__SIZEOF_SOCKLEN_T)\n  set(EVENT__socklen_t \"unsigned int\")\n  set(EVENT__SIZEOF_SOCKLEN_T ${EVENT__SIZEOF_UNSIGNED_INT})\nelse()\n    set(EVENT__socklen_t \"socklen_t\")\nendif()\n\nCHECK_TYPE_SIZE(pid_t EVENT__SIZEOF_PID_T)\nif(NOT EVENT__SIZEOF_PID_T)\n  set(EVENT__SIZEOF_PID_T ${EVENT__SIZEOF_INT})\nelse()\n\tset(EVENT__SIZEOF_PID_T EVENT__SIZEOF_PID_T)\nendif()\n\n# we're just getting lazy now.\nCHECK_TYPE_SIZE(\"uintptr_t\" EVENT__HAVE_UINTPTR_T)\nCHECK_TYPE_SIZE(\"void *\" EVENT__SIZEOF_VOID_P)\nCHECK_TYPE_SIZE(\"time_t\" EVENT__SIZEOF_TIME_T)\n\n# Tests file offset bits.\n# TODO: Add AIX test for if -D_LARGE_FILES is needed.\n\n# XXX: Why is this here? we don't even use it. Well, we don't even use it\n#      on top of that, why is it set in the config.h?! IT_MAKES_NO_SENSE\n#      I'm commenting it out for now.\n#      - ellzey\n\n#CHECK_FILE_OFFSET_BITS()\n\n# Verify kqueue works with pipes.\nif (EVENT__HAVE_KQUEUE)\n    if (CMAKE_CROSSCOMPILING AND NOT EVENT__FORCE_KQUEUE_CHECK)\n        message(WARNING \"Cannot check if kqueue works with pipes when crosscompiling.\n            Use EVENT__FORCE_KQUEUE_CHECK to be sure (this requires running a test program on the cross compilation target)\")\n        set(EVENT__HAVE_WORKING_KQUEUE 1)\n    elseif (APPLE AND NOT EVENT__FORCE_KQUEUE_CHECK)\n        message(WARNING \"Cannot check if kqueue works with pipes on macOS.\n            Use EVENT__FORCE_KQUEUE_CHECK to be sure (this requires running a test program).\")\n        set(EVENT__HAVE_WORKING_KQUEUE 1)\n    else()\n        message(STATUS \"Checking if kqueue works with pipes...\")\n        include(CheckWorkingKqueue)\n    endif()\nendif()\n\nif(EVENT__HAVE_NETDB_H)\n    list(APPEND CMAKE_EXTRA_INCLUDE_FILES netdb.h)\n    CHECK_TYPE_SIZE(\"struct addrinfo\" EVENT__HAVE_STRUCT_ADDRINFO)\nelseif(WIN32)\n    list(APPEND CMAKE_EXTRA_INCLUDE_FILES ws2tcpip.h)\n    CHECK_TYPE_SIZE(\"struct addrinfo\" EVENT__HAVE_STRUCT_ADDRINFO)\nendif()\n\n# Check for sockaddr structure sizes.\nset(SOCKADDR_HEADERS)\nif (WIN32)\n    set(CMAKE_REQUIRED_DEFINITIONS \"-DWIN32_LEAN_AND_MEAN\")\n    if (_MSC_VER LESS 1300)\n        set(SOCKADDR_HEADERS winsock.h)\n    else()\n        set(SOCKADDR_HEADERS winsock2.h ws2tcpip.h)\n    endif()\nelse()\n    if (EVENT__HAVE_NETINET_IN_H)\n        set(SOCKADDR_HEADERS ${SOCKADDR_HEADERS} netinet/in.h)\n    endif()\n\n    if (EVENT__HAVE_NETINET_IN6_H)\n        set(SOCKADDR_HEADERS ${SOCKADDR_HEADERS} netinet/in6.h)\n    endif()\n\n    if (EVENT__HAVE_SYS_SOCKET_H)\n        set(SOCKADDR_HEADERS ${SOCKADDR_HEADERS} sys/socket.h)\n    endif()\n\n    if (EVENT__HAVE_NETDB_H)\n        set(SOCKADDR_HEADERS ${SOCKADDR_HEADERS} netdb.h)\n    endif()\nendif()\n\nCHECK_TYPE_SIZE(\"struct in6_addr\" EVENT__HAVE_STRUCT_IN6_ADDR)\n\nCHECK_TYPE_SIZE(\"sa_family_t\" EVENT__HAVE_SA_FAMILY_T)\nCHECK_TYPE_SIZE(\"struct sockaddr_in6\" EVENT__HAVE_STRUCT_SOCKADDR_IN6)\n\nif(EVENT__HAVE_STRUCT_SOCKADDR_IN6)\n    CHECK_STRUCT_HAS_MEMBER(\"struct sockaddr_in6\"\n            sin6_len \"${SOCKADDR_HEADERS}\"\n            EVENT__HAVE_STRUCT_SOCKADDR_IN6_SIN6_LEN)\n\n    CHECK_STRUCT_HAS_MEMBER(\"struct sockaddr_in6\"\n            sin_len \"${SOCKADDR_HEADERS}\"\n            EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN)\nendif()\n\nCHECK_TYPE_SIZE(\"struct sockaddr_storage\" EVENT__HAVE_STRUCT_SOCKADDR_STORAGE)\nif(EVENT__HAVE_STRUCT_SOCKADDR_STORAGE)\n    CHECK_STRUCT_HAS_MEMBER(\"struct sockaddr_storage\"\n            ss_family \"${SOCKADDR_HEADERS}\"\n            EVENT__HAVE_STRUCT_SOCKADDR_STORAGE_SS_FAMILY)\n\n    CHECK_STRUCT_HAS_MEMBER(\"struct sockaddr_storage\"\n            __ss_family \"${SOCKADDR_HEADERS}\" EVENT__HAVE_STRUCT_SOCKADDR_STORAGE___SS_FAMILY)\nendif()\n\nCHECK_TYPE_SIZE(\"struct linger\" EVENT__HAVE_STRUCT_LINGER)\n\n# Group the source files.\nset(HDR_PRIVATE\n    bufferevent-internal.h\n    changelist-internal.h\n    defer-internal.h\n    epolltable-internal.h\n    evbuffer-internal.h\n    event-internal.h\n    evmap-internal.h\n    evrpc-internal.h\n    evsignal-internal.h\n    evthread-internal.h\n    evdns-internal.h\n    ht-internal.h\n    http-internal.h\n    iocp-internal.h\n    ipv6-internal.h\n    log-internal.h\n    minheap-internal.h\n    mm-internal.h\n    ratelim-internal.h\n    strlcpy-internal.h\n    util-internal.h\n    openssl-compat.h\n    evconfig-private.h\n    sha1.h\n    compat/sys/queue.h\n    compat/sys/tree.h)\n\nset(HDR_COMPAT\n    include/evdns.h\n    include/evrpc.h\n    include/event.h\n    include/evhttp.h\n    include/evutil.h)\n\nset(HDR_PUBLIC\n    include/event2/buffer.h\n    include/event2/bufferevent.h\n    include/event2/bufferevent_compat.h\n    include/event2/bufferevent_struct.h\n    include/event2/buffer_compat.h\n    include/event2/dns.h\n    include/event2/dns_compat.h\n    include/event2/dns_struct.h\n    include/event2/event.h\n    include/event2/event_compat.h\n    include/event2/event_struct.h\n    include/event2/watch.h\n    include/event2/http.h\n    include/event2/http_compat.h\n    include/event2/http_struct.h\n    include/event2/keyvalq_struct.h\n    include/event2/listener.h\n    include/event2/rpc.h\n    include/event2/rpc_compat.h\n    include/event2/rpc_struct.h\n    include/event2/tag.h\n    include/event2/tag_compat.h\n    include/event2/thread.h\n    include/event2/util.h\n    include/event2/ws.h\n    include/event2/visibility.h\n    ${PROJECT_BINARY_DIR}/include/event2/event-config.h)\n\nlist(APPEND SRC_CORE\n    buffer.c\n    bufferevent.c\n    bufferevent_filter.c\n    bufferevent_pair.c\n    bufferevent_ratelim.c\n    bufferevent_sock.c\n    event.c\n    evmap.c\n    evthread.c\n    evutil.c\n    evutil_rand.c\n    evutil_time.c\n    watch.c\n    listener.c\n    log.c\n    signal.c\n    strlcpy.c)\n\nif(EVENT__HAVE_SELECT)\n    list(APPEND SRC_CORE select.c)\nendif()\n\nif(EVENT__HAVE_POLL)\n    list(APPEND SRC_CORE poll.c)\nendif()\n\nif(EVENT__HAVE_KQUEUE)\n    list(APPEND SRC_CORE kqueue.c)\nendif()\n\nif(EVENT__HAVE_DEVPOLL)\n    list(APPEND SRC_CORE devpoll.c)\nendif()\n\nif(EVENT__HAVE_EPOLL)\n    list(APPEND SRC_CORE epoll.c)\nendif()\n\nif(EVENT__HAVE_SIGNALFD)\n    list(APPEND SRC_CORE signalfd.c)\nendif()\n\nif(EVENT__HAVE_WEPOLL)\n    list(APPEND SRC_CORE\n        epoll.c\n        wepoll.c)\nendif()\n\nif(EVENT__HAVE_EVENT_PORTS)\n    list(APPEND SRC_CORE evport.c)\nendif()\n\nif (EVENT__DISABLE_OPENSSL STREQUAL \"OFF\" OR EVENT__DISABLE_OPENSSL STREQUAL \"AUTO\")\n    # only if OPENSSL_ROOT_DIR is not set yet\n    if (BREW AND NOT OPENSSL_ROOT_DIR AND NOT \"$ENV{OPENSSL_ROOT_DIR}\")\n        execute_process(COMMAND ${BREW} --prefix openssl\n            OUTPUT_VARIABLE BREW_OPENSSL_PREFIX\n            RESULT_VARIABLE BREW_OPENSSL_RESULT\n            ERROR_QUIET\n            OUTPUT_STRIP_TRAILING_WHITESPACE\n        )\n        if (BREW_OPENSSL_RESULT EQUAL 0)\n            message(STATUS \"Set OPENSSL_ROOT_DIR=${BREW_OPENSSL_PREFIX} (from brew)\")\n            set(OPENSSL_ROOT_DIR \"${BREW_OPENSSL_PREFIX}\" CACHE PATH \"\")\n        endif()\n    endif()\n\n    find_package(OpenSSL)\n\n    if (OPENSSL_FOUND)\n        set(EVENT__HAVE_OPENSSL 1)\n        set(OPENSSL_TARGETS OpenSSL::SSL)\n\n        message(STATUS \"OpenSSL include: ${OPENSSL_INCLUDE_DIR}\")\n        message(STATUS \"OpenSSL lib: ${OPENSSL_LIBRARIES}\")\n\n        list(APPEND SRC_OPENSSL bufferevent_openssl.c bufferevent_ssl.c)\n        list(APPEND HDR_PUBLIC include/event2/bufferevent_ssl.h)\n        list(APPEND LIB_APPS ${OPENSSL_TARGETS})\n    elseif (EVENT__DISABLE_OPENSSL STREQUAL \"OFF\")\n        message(FATAL_ERROR \"OpenSSL required, but not found.\")\n    endif()\nelseif (EVENT__DISABLE_OPENSSL STREQUAL \"ON\")\n    message(STATUS \"Disable OpenSSL support\")\nelse()\n    message(FATAL_ERROR \"EVENT__DISABLE_OPENSSL must be set to one of: AUTO, ON or OFF\")\nendif()\n\nif (EVENT__DISABLE_MBEDTLS STREQUAL \"OFF\" OR EVENT__DISABLE_MBEDTLS STREQUAL \"AUTO\")\n    # only if MBEDTLS_ROOT_DIR is not set yet\n    if (BREW AND NOT MBEDTLS_ROOT_DIR AND NOT \"$ENV{MBEDTLS_ROOT_DIR}\")\n        execute_process(COMMAND ${BREW} --prefix mbedtls\n            OUTPUT_VARIABLE BREW_MBEDTLS_PREFIX\n            RESULT_VARIABLE BREW_MBEDTLS_RESULT\n            ERROR_QUIET\n            OUTPUT_STRIP_TRAILING_WHITESPACE\n        )\n        if (BREW_MBEDTLS_RESULT EQUAL 0)\n            message(STATUS \"Set MBEDTLS_ROOT_DIR=${BREW_MBEDTLS_PREFIX} (from brew)\")\n            set(MBEDTLS_ROOT_DIR \"${BREW_MBEDTLS_PREFIX}\" CACHE PATH \"\")\n        endif()\n    endif()\n\n    find_package(MbedTLS)\n\n    if (MBEDTLS_FOUND)\n        set(EVENT__HAVE_MBEDTLS 1)\n        set(MBEDTLS_TARGETS MbedTLS::mbedtls MbedTLS::mbedcrypto MbedTLS::mbedx509)\n\n        message(STATUS \"mbed TLS include: ${MBEDTLS_INCLUDE_DIR}\")\n        message(STATUS \"mbed TLS lib: ${MBEDTLS_LIBRARIES}\")\n\n        list(APPEND SRC_MBEDTLS bufferevent_mbedtls.c bufferevent_ssl.c)\n        list(APPEND HDR_PUBLIC include/event2/bufferevent_ssl.h)\n        list(APPEND LIB_APPS ${MBEDTLS_TARGETS})\n    elseif (EVENT__DISABLE_MBEDTLS STREQUAL \"OFF\")\n        message(FATAL_ERROR \"MbedTLS required, but not found.\")\n    endif()\nelseif (EVENT__DISABLE_MBEDTLS STREQUAL \"ON\")\n    message(STATUS \"Disable MbedTLS support\")\nelse()\n    message(FATAL_ERROR \"EVENT__DISABLE_MBEDTLS must be set to one of: AUTO, ON or OFF\")\nendif()\n\nif (NOT EVENT__DISABLE_TESTS)\n    # Zlib is only used for testing.\n    find_package(ZLIB)\n\n    if (ZLIB_LIBRARY AND ZLIB_INCLUDE_DIR)\n        set(EVENT__HAVE_LIBZ 1)\n        list(APPEND LIB_APPS ZLIB::ZLIB)\n    endif()\nendif()\n\nset(SRC_EXTRA\n    event_tagging.c\n    http.c\n    evdns.c\n    ws.c\n    sha1.c\n    evrpc.c)\n\nif(${CMAKE_VERSION} VERSION_LESS \"3.20\")\n  include(TestBigEndian)\n  TEST_BIG_ENDIAN(IS_BIG_ENDIAN)\n  if(IS_BIG_ENDIAN)\n    set(CMAKE_C_BYTE_ORDER BIG_ENDIAN)\n  else()\n    set(CMAKE_C_BYTE_ORDER LITTLE_ENDIAN)\n  endif()\nendif()\nset_source_files_properties(sha1.c PROPERTIES COMPILE_FLAGS\n    -D${CMAKE_C_BYTE_ORDER}=1)\nadd_definitions(-DHAVE_CONFIG_H)\n\n# We use BEFORE here so we don't accidentally look in system directories\n# first for some previous versions of the headers that are installed.\ninclude_directories(BEFORE ${PROJECT_SOURCE_DIR}\n    ${PROJECT_SOURCE_DIR}/compat\n    ${PROJECT_SOURCE_DIR}/include)\n\nif(WIN32)\n    list(APPEND SRC_CORE\n        buffer_iocp.c\n        bufferevent_async.c\n        event_iocp.c\n        win32select.c)\n\n    list(APPEND HDR_PRIVATE WIN32-Code/getopt.h)\n\n    set(LIB_PLATFORM ws2_32 shell32 advapi32 bcrypt iphlpapi)\n    add_definitions(\n            -D_CRT_SECURE_NO_WARNINGS\n            -D_CRT_NONSTDC_NO_DEPRECATE)\n\n    include_directories(./WIN32-Code)\nendif()\n\nif (SOLARIS)\n    list(APPEND LIB_PLATFORM socket nsl)\nendif()\n\nsource_group(\"Headers Private\"  FILES ${HDR_PRIVATE})\nsource_group(\"Header Compat\"    FILES ${HDR_COMPAT})\nsource_group(\"Headers Public\"   FILES ${HDR_PUBLIC})\nsource_group(\"Source Core\"      FILES ${SRC_CORE})\nsource_group(\"Source Extra\"     FILES ${SRC_EXTRA})\n\n# Generate the configure headers.\n# (Place them in the build dir so we don't polute the source tree with generated files).\ninclude_directories(BEFORE ${CMAKE_CURRENT_BINARY_DIR}/include)\n\nif (${GNUC})\n    set(EVENT_SHARED_FLAGS -fvisibility=hidden)\nelseif (\"${CMAKE_C_COMPILER_ID}\" STREQUAL \"SunPro\")\n    set(EVENT_SHARED_FLAGS -xldscope=hidden)\nendif()\n\nconfigure_file(\n    ${CMAKE_CURRENT_SOURCE_DIR}/event-config.h.cmake\n    ${CMAKE_CURRENT_BINARY_DIR}/include/event2/event-config.h\n        NEWLINE_STYLE UNIX)\n\nconfigure_file(\n    ${CMAKE_CURRENT_SOURCE_DIR}/evconfig-private.h.cmake\n    ${CMAKE_CURRENT_BINARY_DIR}/include/evconfig-private.h)\n\n#\n# Create the libraries.\n#\ninclude(AddEventLibrary)\nadd_event_library(event_core SOURCES ${SRC_CORE})\nadd_event_library(event_extra\n    INNER_LIBRARIES event_core\n    SOURCES ${SRC_EXTRA})\n\nif (EVENT__HAVE_OPENSSL)\n    add_event_library(event_openssl\n        INNER_LIBRARIES event_core\n        LIBRARIES ${OPENSSL_TARGETS}\n        SOURCES ${SRC_OPENSSL})\nendif()\n\nif (EVENT__HAVE_MBEDTLS)\n    add_event_library(event_mbedtls\n        INNER_LIBRARIES event_core\n        LIBRARIES ${MBEDTLS_TARGETS}\n        SOURCES ${SRC_MBEDTLS})\nendif()\n\nif (EVENT__HAVE_PTHREADS)\n    set(SRC_PTHREADS evthread_pthread.c)\n    if(ANDROID)\n        add_event_library(event_pthreads\n            INNER_LIBRARIES event_core\n            SOURCES ${SRC_PTHREADS})\n    else()\n        add_event_library(event_pthreads\n            INNER_LIBRARIES event_core\n            LIBRARIES Threads::Threads\n            SOURCES ${SRC_PTHREADS})\n    endif()\nendif()\n\n# library exists for historical reasons; it contains the contents of\n# both libevent_core and libevent_extra. You shouldn’t use it; it may\n# go away in a future version of Libevent.\nadd_event_library(event SOURCES ${SRC_CORE} ${SRC_EXTRA})\n\nset(WIN32_GETOPT)\nif (WIN32)\n    set(_TMPLIBS)\n    if (${EVENT_LIBRARY_STATIC})\n        list(APPEND _TMPLIBS event_core_static event_static)\n    endif()\n    if (${EVENT_LIBRARY_SHARED})\n        list(APPEND _TMPLIBS event_core_shared event_shared)\n    endif()\n    foreach(lib ${_TMPLIBS})\n        target_link_libraries(${lib} iphlpapi)\n    endforeach()\n    unset(_TMPLIBS)\n\n    list(APPEND WIN32_GETOPT\n         WIN32-Code/getopt.c\n         WIN32-Code/getopt_long.c)\nendif()\n\n#\n# Samples.\n#\nmacro(add_sample_prog ssl name)\n    add_executable(${name} ${ARGN})\n\n    target_link_libraries(${name}\n                          event_extra\n                          event_core\n                          ${LIB_APPS}\n                          ${LIB_PLATFORM})\n\n    if (TARGET ${ssl})\n        target_link_libraries(${name} ${ssl})\n        if(WIN32)\n            target_link_libraries(${name} crypt32)\n        endif()\n    endif()\nendmacro()\nif (NOT EVENT__DISABLE_SAMPLES)\n    set(SAMPLES\n        event-read-fifo\n        hello-world\n        signal-test\n        http-connect\n        time-test\n        watch-timing)\n\n    foreach(SAMPLE ${SAMPLES})\n        add_sample_prog(OFF ${SAMPLE} sample/${SAMPLE}.c)\n    endforeach()\n    if (NOT WIN32)\n        target_link_libraries(watch-timing m)\n    endif()\n\n    if (EVENT__HAVE_OPENSSL)\n        add_sample_prog(event_openssl https-client\n                        sample/https-client.c\n                        sample/openssl_hostname_validation.c\n                        sample/hostcheck.c)\n        add_sample_prog(event_openssl le-proxy\n                        sample/le-proxy.c)\n        add_sample_prog(event_openssl becat sample/becat.c ${WIN32_GETOPT})\n    endif()\n\n    if (EVENT__HAVE_MBEDTLS)\n        add_sample_prog(event_mbedtls https-client-mbedtls\n                sample/https-client.c)\n        target_compile_definitions(https-client-mbedtls PRIVATE USE_MBEDTLS)\n        add_sample_prog(event_mbedtls ssl-client-mbedtls\n                sample/ssl-client-mbedtls.c)\n    endif()\n\n    set(SAMPLES_WOPT\n        dns-example\n        ws-chat-server\n        http-server\n    )\n    foreach (SAMPLE ${SAMPLES_WOPT})\n        add_sample_prog(OFF ${SAMPLE} sample/${SAMPLE}.c ${WIN32_GETOPT})\n    endforeach()\nendif()\n\n#\n# Benchmarks\n#\nmacro(add_bench_prog prog)\n    add_executable(${prog} ${ARGN})\n    target_link_libraries(${prog}\n                          event_extra\n                          event_core\n                          ${LIB_APPS}\n                          ${LIB_PLATFORM})\nendmacro()\nif (NOT EVENT__DISABLE_BENCHMARK)\n    foreach (BENCHMARK bench_http bench_httpclient)\n        add_bench_prog(${BENCHMARK} test/${BENCHMARK}.c)\n    endforeach()\n\n    add_bench_prog(bench test/bench.c ${WIN32_GETOPT})\n    add_bench_prog(bench_cascade test/bench_cascade.c ${WIN32_GETOPT})\nendif()\n\n#\n# Tests\n#\nmacro(add_test_prog prog)\n    add_executable(${prog} test/${prog}.c)\n    target_link_libraries(${prog}\n                          ${LIB_APPS}\n                          ${LIB_PLATFORM}\n                          event_core\n                          event_extra\n                          ${ARGN})\nendmacro()\n\nif (NOT EVENT__DISABLE_TESTS)\n    #\n    # Generate Regress tests.\n    #\n    if (NOT EVENT__DISABLE_REGRESS)\n        # (We require python to generate the regress tests)\n        find_package(Python3 COMPONENTS Interpreter)\n\n        if (Python3_FOUND)\n            set(__FOUND_USABLE_PYTHON 1)\n            set(PYTHON_EXECUTABLE ${Python3_EXECUTABLE})\n        else()\n            find_package(Python2 COMPONENTS Interpreter)\n            if (Python2_FOUND)\n                set(__FOUND_USABLE_PYTHON 1)\n                set(PYTHON_EXECUTABLE ${Python2_EXECUTABLE})\n            else()\n                message(ERROR \"No suitable Python version found, bailing...\")\n            endif()\n        endif()\n\n        if (__FOUND_USABLE_PYTHON)\n            message(STATUS \"Generating regress tests...\")\n\n            add_definitions(-DTINYTEST_LOCAL)\n\n            add_custom_command(\n                OUTPUT\n                    ${CMAKE_CURRENT_SOURCE_DIR}/test/regress.gen.c\n                    ${CMAKE_CURRENT_SOURCE_DIR}/test/regress.gen.h\n                DEPENDS\n                    event_rpcgen.py\n                    test/regress.rpc\n                COMMAND ${PYTHON_EXECUTABLE} ../event_rpcgen.py --quiet regress.rpc\n                WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/test)\n\n            list(APPEND SRC_REGRESS\n                 test/regress.c\n                 test/regress.gen.c\n                 test/regress.gen.h\n                 test/regress_buffer.c\n                 test/regress_bufferevent.c\n                 test/regress_dns.c\n                 test/regress_et.c\n                 test/regress_finalize.c\n                 test/regress_http.c\n                 test/regress_http.h\n                 test/regress_listener.c\n                 test/regress_main.c\n                 test/regress_minheap.c\n                 test/regress_rpc.c\n                 test/regress_testutils.c\n                 test/regress_testutils.h\n                 test/regress_util.c\n                 test/regress_watch.c\n                 test/regress_timer_timeout.c\n                 test/regress_ws.c\n                 test/regress_ws.h\n                 test/tinytest.c)\n\n            if (WIN32)\n                list(APPEND SRC_REGRESS test/regress_iocp.c)\n                if (NOT EVENT__DISABLE_THREAD_SUPPORT)\n                    list(APPEND SRC_REGRESS test/regress_thread.c)\n                endif()\n            elseif (EVENT__HAVE_PTHREADS)\n                list(APPEND SRC_REGRESS test/regress_thread.c)\n            endif()\n\n            if (ZLIB_LIBRARY AND ZLIB_INCLUDE_DIR)\n                list(APPEND SRC_REGRESS test/regress_zlib.c)\n            endif()\n\n            if (EVENT__HAVE_OPENSSL)\n                list(APPEND SRC_REGRESS test/regress_openssl.c)\n            endif()\n\n            if (EVENT__HAVE_MBEDTLS)\n                list(APPEND SRC_REGRESS test/regress_mbedtls.c)\n            endif()\n\n            add_executable(regress ${SRC_REGRESS})\n\n            target_link_libraries(regress\n                                  ${LIB_APPS}\n                                  ${LIB_PLATFORM}\n                                  event_core\n                                  event_extra)\n            if (EVENT__HAVE_OPENSSL)\n                target_link_libraries(regress event_openssl)\n            endif()\n            if (EVENT__HAVE_MBEDTLS)\n                target_link_libraries(regress event_mbedtls)\n            endif()\n            if (PTHREADS_AVAILABLE)\n                target_link_libraries(regress event_pthreads)\n            endif()\n        else()\n            message(WARNING \"No suitable Python interpreter found, cannot generate regress tests!\")\n        endif()\n    endif()\n\n    #\n    # Test programs.\n    #\n    # all of these, including the cmakelists.txt should be moved\n    # into the dirctory 'tests' first.\n    #\n    # doing this, we can remove all the DISABLE_TESTS stuff, and simply\n    # do something like:\n    #\n    # add_custom_targets(tests)\n    # add_executable(... EXCLUDE_FROM_ALL ...c)\n    # add_dependencis(tests testa testb testc)\n    # add_test(....)\n    #\n    # then you can just run 'make tests' instead of them all\n    # auto-compile|running\n    # - ellzey\n    set(TESTPROGS test-changelist\n                  test-eof\n                  test-closed\n                  test-fdleak\n                  test-init\n                  test-time\n                  test-weof)\n\n    foreach (TESTPROG ${TESTPROGS} test-dumpevents)\n        add_test_prog(${TESTPROG})\n    endforeach()\n    if (UNIX)\n        add_test_prog(test-ratelim m)\n    else()\n        add_test_prog(test-ratelim)\n    endif()\n\n    set(ALL_TESTPROGS\n        ${TESTPROGS}\n        test-dumpevents\n        test-ratelim\n    )\n\n    if(PTHREADS_AVAILABLE AND EVENT__HAVE_KQUEUE)\n        add_test_prog(test-kq-collision event_pthreads)\n        list(APPEND ALL_TESTPROGS test-kq-collision)\n        add_test(test-test-kq-collision ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/test-kq-collision)\n    endif()\n\n    #\n    # We run all tests with the different backends turned on one at a time.\n    #\n\n    # Add event backends based on system introspection result.\n    set(BACKENDS \"\")\n\n    if (EVENT__HAVE_EPOLL)\n        list(APPEND BACKENDS EPOLL)\n    endif()\n\n    if (EVENT__HAVE_SELECT)\n        list(APPEND BACKENDS SELECT)\n    endif()\n\n    if (EVENT__HAVE_POLL)\n        list(APPEND BACKENDS POLL)\n    endif()\n\n    if (EVENT__HAVE_KQUEUE)\n        list(APPEND BACKENDS KQUEUE)\n    endif()\n\n    if (EVENT__HAVE_EVENT_PORTS)\n        list(APPEND BACKENDS EVPORT)\n    endif()\n\n    if (EVENT__HAVE_DEVPOLL)\n        list(APPEND BACKENDS DEVPOLL)\n    endif()\n\n    if (EVENT__HAVE_WEPOLL)\n        list(APPEND BACKENDS WEPOLL)\n    endif()\n\n    if (WIN32)\n        list(APPEND BACKENDS WIN32)\n    endif()\n\n\n    # Default environment variables turns off all event systems,\n    # then we enable each one, one at a time when creating the tests.\n    set(DEFAULT_TEST_ENV_VARS)\n    foreach(BACKEND ${BACKENDS})\n        set(BACKEND_ENV_VAR \"EVENT_NO${BACKEND}=1\")\n        list(APPEND DEFAULT_TEST_ENV_VARS \"${BACKEND_ENV_VAR}\")\n    endforeach()\n\n    # Macro that creates the ctest test for a backend.\n    macro(add_backend_test BACKEND_TEST_NAME ENV_VARS)\n        set(TEST_NAMES \"\")\n\n        foreach (TESTPROG ${TESTPROGS})\n            set(TEST_NAME ${TESTPROG}__${BACKEND_TEST_NAME})\n\n            add_test(${TEST_NAME}\n                     ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/${TESTPROG})\n\n            list(APPEND TEST_NAMES ${TEST_NAME})\n\n            set_tests_properties(${TEST_NAME}\n                                 PROPERTIES ENVIRONMENT \"${ENV_VARS}\")\n        endforeach()\n\n        # Dump events test.\n        if (__FOUND_USABLE_PYTHON)\n            set(TEST_NAME test-dumpevents__${BACKEND_TEST_NAME})\n\n            add_test(${TEST_NAME}\n                     ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/test-dumpevents |\n                     ${PYTHON_EXECUTABLE}\n                     ${CMAKE_CURRENT_SOURCE_DIR}/test/check-dumpevents.py)\n\n            set_tests_properties(${TEST_NAME}\n                                 PROPERTIES ENVIRONMENT \"${ENV_VARS}\")\n        else()\n            message(WARNING \"test-dumpevents will be run without output check since python was not found!\")\n            set(TEST_NAME test-dumpevents__${BACKEND_TEST_NAME}_no_check)\n\n            add_test(${TEST_NAME}\n                     ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/test-dumpevents)\n\n            set_tests_properties(${TEST_NAME}\n                                 PROPERTIES ENVIRONMENT \"${ENV_VARS}\")\n        endif()\n\n        # Regress tests.\n        if (NOT EVENT__DISABLE_REGRESS AND __FOUND_USABLE_PYTHON)\n            set(TEST_NAME regress__${BACKEND_TEST_NAME})\n\n            add_test(${TEST_NAME}\n                     ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/regress --quiet)\n\n            set_tests_properties(${TEST_NAME}\n                                 PROPERTIES ENVIRONMENT \"${ENV_VARS}\")\n\n            add_test(${TEST_NAME}_debug\n                     ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/regress --quiet)\n\n            set_tests_properties(${TEST_NAME}_debug\n                                 PROPERTIES ENVIRONMENT \"${ENV_VARS};EVENT_DEBUG_MODE=1\")\n        endif()\n    endmacro()\n\n    # Add the tests for each backend.\n    foreach(BACKEND ${BACKENDS})\n        # Enable this backend only.\n        set(BACKEND_ENV_VARS ${DEFAULT_TEST_ENV_VARS})\n        list(REMOVE_ITEM BACKEND_ENV_VARS EVENT_NO${BACKEND}=1)\n\n        # Epoll has some extra settings.\n        if (${BACKEND} STREQUAL \"EPOLL\")\n            add_backend_test(timerfd_${BACKEND}\n                            \"${BACKEND_ENV_VARS};EVENT_PRECISE_TIMER=1\")\n\n            add_backend_test(changelist_${BACKEND}\n                            \"${BACKEND_ENV_VARS};EVENT_EPOLL_USE_CHANGELIST=yes\")\n\n            add_backend_test(timerfd_changelist_${BACKEND}\n                            \"${BACKEND_ENV_VARS};EVENT_EPOLL_USE_CHANGELIST=yes;EVENT_PRECISE_TIMER=1\")\n        else()\n            add_backend_test(${BACKEND} \"${BACKEND_ENV_VARS}\")\n        endif()\n        add_backend_test(signalfd_${BACKEND} \"${BACKEND_ENV_VARS};EVENT_USE_SIGNALFD=1\")\n    endforeach()\n\n    #\n    # Rate limiter tests.\n    #\n\n    # Group limits, no connection limit.\n    set(RL_BIN ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/test-ratelim)\n\n    add_test(test-ratelim__group_lim\n             ${RL_BIN}\n             -g 30000\n             -n 30\n             -t 100\n             --check-grouplimit 1000\n             --check-stddev 100)\n\n    # Connection limit, no group limit.\n    add_test(test-ratelim__con_lim\n             ${RL_BIN}\n             -c 1000\n             -n 30\n             -t 100\n             --check-connlimit 50\n             --check-stddev 50)\n\n    # Connection limit and group limit.\n    add_test(test-ratelim__group_con_lim\n             ${RL_BIN}\n             -c 1000\n             -g 30000\n             -n 30\n             -t 100\n             --check-grouplimit 1000\n             --check-connlimit 50\n             --check-stddev 50)\n\n    # Connection limit and group limit with independent drain.\n    add_test(test-ratelim__group_con_lim_drain\n             ${RL_BIN}\n             -c 1000\n             -g 35000\n             -n 30\n             -t 100\n             -G 500\n             --check-grouplimit 1000\n             --check-connlimit 50\n             --check-stddev 50)\n\n    # Add a \"make verify\" target, same as for autoconf.\n    # (Important! This will unset all EVENT_NO* environment variables.\n    #  If they are set in the shell the tests are running using simply \"ctest\" or \"make test\" will fail)\n    if (WIN32)\n        # Windows doesn't have \"unset\". But you can use \"set VAR=\" instead.\n        file(TO_NATIVE_PATH ${CMAKE_CTEST_COMMAND} WINDOWS_CTEST_COMMAND)\n\n        file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/tmp/verify_tests.bat\n            \"\n            set EVENT_NOWIN32=\n            set EVENT_NOWEPOLL=\n            \\\"${WINDOWS_CTEST_COMMAND}\\\"\n            \")\n\n        message(STATUS \"${WINDOWS_CTEST_COMMAND}\")\n\n        file(COPY ${CMAKE_CURRENT_BINARY_DIR}/tmp/verify_tests.bat\n             DESTINATION ${CMAKE_CURRENT_BINARY_DIR}\n             FILE_PERMISSIONS\n                             OWNER_READ\n                             OWNER_WRITE\n                             OWNER_EXECUTE\n                             GROUP_READ\n                             GROUP_EXECUTE\n                             WORLD_READ WORLD_EXECUTE)\n\n        file(TO_NATIVE_PATH\n                    \"${CMAKE_CURRENT_BINARY_DIR}/verify_tests.bat\" VERIFY_PATH)\n\n        add_custom_target(verify COMMAND \"${VERIFY_PATH}\"\n                          DEPENDS event ${ALL_TESTPROGS})\n    else()\n        # On some platforms doing exec(unset) as CMake doesn't work, so make sure\n        # we run the unset command in a shell instead.\n        # First we write the script contents.\n        file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/tmp/verify_tests.sh\n            \"\n            #!/bin/bash\n            unset EVENT_NOEPOLL; unset EVENT_NOPOLL; unset EVENT_NOSELECT; unset EVENT_NOWIN32; unset EVENT_NOEVPORT; unset EVENT_NOKQUEUE; unset EVENT_NODEVPOLL\n            ${CMAKE_CTEST_COMMAND}\n            \")\n\n        # Then we copy the file (this allows us to set execute permission on it)\n        file(COPY ${CMAKE_CURRENT_BINARY_DIR}/tmp/verify_tests.sh\n             DESTINATION ${CMAKE_CURRENT_BINARY_DIR}\n             FILE_PERMISSIONS\n                             OWNER_READ\n                             OWNER_WRITE\n                             OWNER_EXECUTE\n                             GROUP_READ\n                             GROUP_EXECUTE\n                             WORLD_READ\n                             WORLD_EXECUTE)\n\n        # Create the target that runs the script.\n        add_custom_target(verify\n                          COMMAND ${CMAKE_CURRENT_BINARY_DIR}/verify_tests.sh\n                          DEPENDS event ${ALL_TESTPROGS})\n    endif()\n\n    if (NOT EVENT__DISABLE_REGRESS AND __FOUND_USABLE_PYTHON)\n        add_dependencies(verify regress)\n    endif()\n\n    if (EVENT__COVERAGE)\n        include(CodeCoverage)\n\n        setup_target_for_coverage(\n            verify_coverage # Coverage target name \"make verify_coverage\"\n            make            # Test runner.\n            coverage        # Output directory.\n            verify)         # Arguments passed to test runner. \"make verify\"\n    endif()\n\n    enable_testing()\n\n    include(CTest)\nendif()\n\n#\n# Installation preparation.\n#\n\nset(EVENT_INSTALL_CMAKE_DIR\n    \"${CMAKE_INSTALL_LIBDIR}/cmake/libevent\")\n\nexport(PACKAGE libevent)\n\nconfigure_file(${PROJECT_SOURCE_DIR}/cmake/LibeventConfig.cmake.in\n    \"${PROJECT_BINARY_DIR}/LibeventConfig.cmake\"\n    @ONLY)\n\n# Generate the config file for the build-tree.\nset(EVENT__INCLUDE_DIRS\n    \"${PROJECT_SOURCE_DIR}/include\"\n    \"${PROJECT_BINARY_DIR}/include\")\n\nset(LIBEVENT_INCLUDE_DIRS\n    ${EVENT__INCLUDE_DIRS}\n    CACHE PATH \"Libevent include directories\")\n\n# Generate version info for both build-tree and install-tree.\nconfigure_file(${PROJECT_SOURCE_DIR}/cmake/LibeventConfigVersion.cmake.in\n               ${PROJECT_BINARY_DIR}/LibeventConfigVersion.cmake\n               @ONLY)\n\n# Install compat headers\ninstall(FILES ${HDR_COMPAT}\n        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\"\n        COMPONENT dev)\n\n# Install public headers\ninstall(FILES ${HDR_PUBLIC}\n        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/event2\"\n        COMPONENT dev)\n\n# Install the configs.\ninstall(FILES\n        ${PROJECT_BINARY_DIR}/LibeventConfig.cmake\n        ${PROJECT_BINARY_DIR}/LibeventConfigVersion.cmake\n        DESTINATION \"${EVENT_INSTALL_CMAKE_DIR}\"\n        COMPONENT dev)\n\n# Install exports for the install-tree.\nmacro(install_export type)\n    install(EXPORT LibeventTargets-${type}\n        NAMESPACE ${PROJECT_NAME}::\n        DESTINATION \"${EVENT_INSTALL_CMAKE_DIR}\"\n        COMPONENT dev)\nendmacro()\n\nif (${EVENT_LIBRARY_STATIC})\n    install_export(static)\nendif()\nif (${EVENT_LIBRARY_SHARED})\n    install_export(shared)\nendif()\n\n# Install the scripts.\ninstall(PROGRAMS\n       ${CMAKE_CURRENT_SOURCE_DIR}/event_rpcgen.py\n       DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n       COMPONENT runtime)\n\n# Create documents with doxygen.\noption(EVENT__DOXYGEN\n    \"Enables doxygen documentation\" OFF)\nif (EVENT__DOXYGEN)\n    include(UseDoxygen)\n    UseDoxygen()\nendif()\n\n\nif (NOT TARGET uninstall)\n\t# Create the uninstall target.\n\t# https://gitlab.kitware.com/cmake/community/wikis/FAQ#can-i-do-make-uninstall-with-cmake\n\tconfigure_file(${PROJECT_SOURCE_DIR}/cmake/Uninstall.cmake.in\n\t\t\t\t   ${PROJECT_BINARY_DIR}/Uninstall.cmake\n\t\t\t\t   @ONLY)\n\n\tadd_custom_target(uninstall\n\t\t\t\t\t  COMMAND ${CMAKE_COMMAND} -P ${PROJECT_BINARY_DIR}/Uninstall.cmake)\nendif()\n\nmessage(STATUS \"\")\nmessage(STATUS \"        ---( Libevent \" ${EVENT_VERSION} \" )---\")\nmessage(STATUS \"\")\nmessage(STATUS \"Available event backends: ${BACKENDS}\")\nmessage(STATUS \"CMAKE_BINARY_DIR:         ${CMAKE_BINARY_DIR}\")\nmessage(STATUS \"CMAKE_CURRENT_BINARY_DIR: ${CMAKE_CURRENT_BINARY_DIR}\")\nmessage(STATUS \"CMAKE_SOURCE_DIR:         ${CMAKE_SOURCE_DIR}\")\nmessage(STATUS \"CMAKE_CURRENT_SOURCE_DIR: ${CMAKE_CURRENT_SOURCE_DIR}\")\nmessage(STATUS \"PROJECT_BINARY_DIR:       ${PROJECT_BINARY_DIR}\")\nmessage(STATUS \"PROJECT_SOURCE_DIR:       ${PROJECT_SOURCE_DIR}\")\nmessage(STATUS \"CMAKE_MODULE_PATH:        ${CMAKE_MODULE_PATH}\")\nmessage(STATUS \"CMAKE_COMMAND:            ${CMAKE_COMMAND}\")\nmessage(STATUS \"CMAKE_ROOT:               ${CMAKE_ROOT}\")\nmessage(STATUS \"CMAKE_SYSTEM:             ${CMAKE_SYSTEM}\")\nmessage(STATUS \"CMAKE_SYSTEM_NAME:        ${CMAKE_SYSTEM_NAME}\")\nmessage(STATUS \"CMAKE_SYSTEM_VERSION:     ${CMAKE_SYSTEM_VERSION}\")\nmessage(STATUS \"CMAKE_SYSTEM_PROCESSOR:   ${CMAKE_SYSTEM_PROCESSOR}\")\nmessage(STATUS \"CMAKE_SKIP_RPATH:         ${CMAKE_SKIP_RPATH}\")\nmessage(STATUS \"CMAKE_SKIP_INSTALL_RPATH: ${CMAKE_SKIP_INSTALL_RPATH}\")\nmessage(STATUS \"CMAKE_INSTALL_RPATH:      ${CMAKE_INSTALL_RPATH}\")\nmessage(STATUS \"CMAKE_VERBOSE_MAKEFILE:   ${CMAKE_VERBOSE_MAKEFILE}\")\nmessage(STATUS \"CMAKE_C_FLAGS:            ${CMAKE_C_FLAGS}\")\nmessage(STATUS \"CMAKE_BUILD_TYPE:         ${CMAKE_BUILD_TYPE}\")\nmessage(STATUS \"CMAKE_C_COMPILER:         ${CMAKE_C_COMPILER} (id ${CMAKE_C_COMPILER_ID}, clang ${CLANG}, GNUC ${GNUC}, version ${CMAKE_C_COMPILER_VERSION})\")\nmessage(STATUS \"CMAKE_SHARED_LINKER_FLAGS:${CMAKE_SHARED_LINKER_FLAGS}\")\nmessage(STATUS \"CMAKE_EXE_LINKER_FLAGS:   ${CMAKE_EXE_LINKER_FLAGS}\")\nmessage(STATUS \"CMAKE_AR:                 ${CMAKE_AR}\")\nmessage(STATUS \"CMAKE_RANLIB:             ${CMAKE_RANLIB}\")\nmessage(STATUS \"CMAKE_INSTALL_PREFIX:     ${CMAKE_INSTALL_PREFIX}\")\nmessage(STATUS \"CMAKE_DEBUG_POSTFIX:      ${CMAKE_DEBUG_POSTFIX}\")\nmessage(STATUS \"\")\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.8544921875,
          "content": "# Contributing to libevent\n\n## Coding style\n\nFirst and most generic rule: **just look around**.\n\nBut, we have a script for checking patches/files/git-refs:\n```shell\n# Chech HEAD git ref\n./checkpatch.sh -r\n./checkpatch.sh -r HEAD\n\n# Check patch\ngit format-patch --stdout -1 | ./checkpatch.sh -p\ngit show -1 | ./checkpatch.sh -p\n\n# Or via regular files\ngit format-patch --stdout -2\n./checkpatch.sh *.patch\n\n# Over a file\n./checkpatch.sh -d event.c\n./checkpatch.sh -d < event.c\n\n# And print the whole file not only summary\n./checkpatch.sh -f event.c\n./checkpatch.sh -f < event.c\n\n# See\n./checkpatch.sh -h\n```\n\n## Testing\n- Write new unit test in `test/regress_{MORE_SUITABLE_FOR_YOU}.c`\n- `make verify`\n\n## Asking Questions\nIt's all right to have questions! Instead of filing an issue here, go ahead and leave a message in our [Gitter Room](https://gitter.im/libevent/libevent)\n"
        },
        {
          "name": "CONTRIBUTORS.md",
          "type": "blob",
          "size": 5.775390625,
          "content": "_If we have forgotten your name, please contact us_\n\n## Libevent Contributors\n * Samy Al Bahra\n * Antony Antony\n * Jacob Appelbaum\n * Arno Bakker\n * Weston Andros Adamson\n * William Ahern\n * Ivan Andropov\n * Sergey Avseyev\n * Avi Bab\n * Joachim Bauch\n * Andrey Belobrov\n * Gilad Benjamini\n * Stas Bekman\n * Denis Bilenko\n * Julien Blache\n * Kevin Bowling\n * Tomash Brechko\n * Kelly Brock\n * Ralph Castain\n * Adrian Chadd\n * Lawnstein Chan\n * Shuo Chen\n * Ka-Hing Cheung\n * Andrew Cox\n * Paul Croome\n * George Danchev\n * Andrew Danforth\n * Ed Day\n * Christopher Davis\n * Mike Davis\n * Frank Denis\n * Antony Dovgal\n * Mihai Draghicioiu\n * Alexander Drozdov\n * Mark Ellzey\n * Shie Erlich\n * Leonid Evdokimov\n * Juan Pablo Fernandez\n * Christophe Fillot\n * Mike Frysinger\n * Remi Gacogne\n * Artem Germanov\n * Alexander von Gernler\n * Diego Giagio\n * Artur Grabowski\n * Diwaker Gupta\n * Kuldeep Gupta\n * Sebastian Hahn\n * Dave Hart\n * Greg Hazel\n * Nicholas Heath\n * Michael Herf\n * Savg He\n * Mark Heily\n * Maxime Henrion\n * Michael Herf\n * Greg Hewgill\n * Andrew Hochhaus\n * Aaron Hopkins\n * Tani Hosokawa\n * Jamie Iles\n * Xiuqiang Jiang\n * Claudio Jeker\n * Evan Jones\n * Marcin Juszkiewicz\n * George Kadianakis\n * Makoto Kato\n * Phua Keat\n * Azat Khuzhin\n * Alexander Klauer\n * Kevin Ko\n * Brian Koehmstedt\n * Marko Kreen\n * Ondřej Kuzník\n * Valery Kyholodov\n * Ross Lagerwall\n * Scott Lamb\n * Christopher Layne\n * Adam Langley\n * Graham Leggett\n * Volker Lendecke\n * Philip Lewis\n * Zhou Li\n * David Libenzi\n * Yan Lin\n * Moshe Litvin\n * Simon Liu\n * Mitchell Livingston\n * Hagne Mahre\n * Lubomir Marinov\n * Abilio Marques\n * Nicolas Martyanoff\n * Abel Mathew\n * Nick Mathewson\n * James Mansion\n * Nicholas Marriott\n * Andrey Matveev\n * Caitlin Mercer\n * Dagobert Michelsen\n * Andrea Montefusco\n * Mansour Moufid\n * Mina Naguib\n * Felix Nawothnig\n * Trond Norbye\n * Linus Nordberg\n * Richard Nyberg\n * Jon Oberheide\n * John Ohl\n * Phil Oleson\n * Alexey Ozeritsky\n * Dave Pacheco\n * Derrick Pallas\n * Tassilo von Parseval\n * Catalin Patulea\n * Patrick Pelletier\n * Simon Perreault\n * Dan Petro\n * Pierre Phaneuf\n * Amarin Phaosawasdi\n * Ryan Phillips\n * Dimitre Piskyulev\n * Pavel Plesov\n * Jon Poland\n * Roman Puls\n * Nate R\n * Robert Ransom\n * Balint Reczey\n * Bert JW Regeer\n * Nate Rosenblum\n * Peter Rosin\n * Maseeb Abdul Qadir\n * Wang Qin\n * Alex S\n * Gyepi Sam\n * Hanna Schroeter\n * Ralf Schmitt\n * Mike Smellie\n * Steve Snyder\n * Nir Soffer\n * Dug Song\n * Dongsheng Song\n * Hannes Sowa\n * Joakim Soderberg\n * Joseph Spadavecchia\n * Kevin Springborn\n * Harlan Stenn\n * Andrew Sweeney\n * Ferenc Szalai\n * Brodie Thiesfield\n * Jason Toffaletti\n * Brian Utterback\n * Gisle Vanem\n * Bas Verhoeven\n * Constantine Verutin\n * Colin Watt\n * Zack Weinberg\n * Jardel Weyrich\n * Jay R. Wren\n * Zack Weinberg\n * Mobai Zhang\n * Alejo\n * Alex\n * Taral\n * propanbutan\n * masksqwe\n * mmadia\n * yangacer\n * Andrey Skriabin\n * basavesh.as\n * billsegall\n * Bill Vaughan\n * Christopher Wiley\n * David Paschich\n * Ed Schouten\n * Eduardo Panisset\n * Jan Heylen\n * jer-gentoo\n * Joakim Söderberg\n * kirillDanshin\n * lzmths\n * Marcus Sundberg\n * Mark Mentovai\n * Mattes D\n * Matyas Dolak\n * Neeraj Badlani\n * Nick Mathewson\n * Rainer Keller\n * Seungmo Koo\n * Thomas Bernard\n * Xiao Bao Clark\n * zeliard\n * Zonr Chang\n * Kurt Roeckx\n * Seven\n * Simone Basso\n * Vlad Shcherban\n * Tim Hentenaar\n * Breaker\n * johnsonlee\n * Philip Prindeville\n * Vis Virial\n * Sayan Nandan\n * Aapeli\n * Aleksandr-Melnikov\n * Alex Budovski\n * Andreas Gustafsson\n * Andre Pereira Azevedo Pinto\n * Andrey Okoshkin\n * an-tao\n * ayuseleznev\n * baixiangcpp\n * Berbe\n * Bernard Spil\n * Biswapriyo Nath\n * Bogdan Harjoc\n * Boris.Dergachov\n * Borys Smejda\n * Carlo Marcelo Arenas Belón\n * chenguolong\n * Christopher Chavez\n * chux0519\n * Cristian Morales Vega\n * cui fliter\n * Dan Rosen\n * David Benjamin\n * David Disseldorp\n * Dimo Markov\n * Dmitry Alimov\n * Dmitry Antipov\n * Dmitry Ilyin\n * Dominic Chen\n * dota17\n * dpayne\n * ejurgensen\n * Emil Engler\n * Enji Cooper\n * Fabrice Fontaine\n * fanquake\n * Fredrik Strupe\n * Gerry Garvey\n * Gonçalo Ribeiro\n * guoxiang1996\n * Haowei Hsu\n * Igor Klemenski\n * ihsinme\n * Isidor Kouvelas\n * iysheng\n * JackBoosY\n * jackerli(李剑)\n * James Synge\n * Jan Beich\n * Jan Kasiak\n * Jay Freeman (saurik)\n * jeremyerb\n * Jesse Fang\n * Jessica Clarke\n * Jiri Luznicky\n * John Fremlin\n * José Luis Millán\n * Joseph Coffland\n * Kamil Rytarowski\n * Keelan Cannoo\n * Keith Smiley\n * kenping\n * Kiyoshi Aman\n * Leon George\n * Leon M. George\n * Leo Zhang\n * lightningkay\n * lilei\n * linxiaohui\n * Loïc Yhuel\n * Luke Dashjr\n * Marcin Szewczyk\n * Marek Sebera\n * mareksm\n * Mario Emmenlauer\n * Maximilian Brunner\n * Maya Rashish\n * Michael Davidsaver\n * Michael Madsen\n * Mike Sharov\n * MKCKR\n * mkm\n * mohuang\n * moonlightsh\n * Murat Demirten\n * Nathan French\n * neil\n * Nick Grifka\n * Nicolas J. Bouliane\n * Nikita Gorskikh\n * Nikolay Edigaryev\n * nntrab\n * OgreTransporter\n * okhowang(王沛文)\n * Paul Osborne\n * Paweł Wegner\n * Peter Edwards\n * Philip Herron\n * Philip Homburg\n * Pierce Lopez\n * Redfoxmoon\n * Ryan Pavlik\n * Sean Young\n * seleznevae\n * Seong-Joong Kim\n * Sergey Fionov\n * Sergey Matveychuk\n * Srivatsan Iyer\n * stenn\n * SuckShit\n * Syedh30\n * The Gitter Badger\n * Theo Buehler\n * Thomas Perrot\n * tim-le\n * Tobias Heider\n * Tobias Stoeckmann\n * Tomas Gonzalez\n * Vincent JARDIN\n * Wataru Ashihara\n * wenyg\n * William A Rowe Jr\n * William Marlow\n * Xiang Zhang\n * Xiaozhou Liu\n * yangyongsheng\n * Yi Fan Yu\n * yongqing.jiao\n * Yongsheng Xu\n * Yong Wu\n * yuangongji\n * Yury Korzhetsky\n * zhenhaonong\n * zhongzedu\n * zhuizhuhaomeng\n * Cœur\n * Daniel Kempenich\n * DavidKorczynski\n * Diogo Teles Sant'Anna\n * Edoardo Lolletti\n * Jonathan Ringer\n * liaotonglang\n * Liao Tonglang\n * lilinjie\n * mdavidsaver\n * Michael Ford\n * Tobias Mayer\n * Zhipeng Xue\n * Ingo Bauersachs\n * Jeremy W. Murphy\n * Thuan Tran\n"
        },
        {
          "name": "ChangeLog",
          "type": "blob",
          "size": 21.248046875,
          "content": "Changes in version 2.2.1-alpha (21 May 2023)\n\n Libevent 2.2.1-alpha includes a number of new features and performance\n improvements.\n\n The log below tries to organize them by rough area of effect.\n\n This release contains around 1000 patches (without merges) with 151 new\n contributors!\n\n This changelog omits some commits which were pure bugfixes on other commits\n listed below. typos, some minor CI changes and similar things.\n\n Some keywords highlights of this major release:\n - wepoll backend (by Nick Grifka)\n - signalfd backend (by Dmitry Antipov)\n - DNS over TCP for evdns (by ayuseleznev)\n - websockets layer (by Dmitry Ilyin)\n - \"prepare\" and \"check\" watchers (by Dan Rosen)\n - MbedTLS support (okhowang)\n - unix domain sockets for HTTP\n - cmake over autotools/automake\n - extensive CI\n\n For more detail, see the git changelogs. For more insight, see the\n \"whatsnew-2.2.txt\" document included in the Libevent 2.2.1-alpha\n distribution.\n\n SSL layer gains MbedTLS support, and had been tested with LibreSSL too. And\n of course with OpenSSL 1.1/3.0.\n\n From now on, the autotools is considered as deprecated, and you should use\n cmake instead.\n\n And now we are using github actions for CI, previously we had travis-ci for\n linux/macos and appveyor for win32 (removed in #951), and also I used testing\n vagrant for some time, but it had been moved into a separate repository\n (8c1838be). But actually this is not required anymore since github actions\n supports:\n - linux\n - freebsd\n - windows\n - macos\n - openbsd\n - and also tests under Thread/Address/Undefined sanitizers\n\n Now documentation is automatically deployed to https://libevent.org/doc/\n\n CI:\n  o Merge branch 'github-actions-v2' (#951) (0b6f29ac yuangongji, Azat Khuzhin)\n  o ci: add CIFuzz Github action (#1382) (d8ecb88f DavidKorczynski)\n  o Add CI checks for OpenBSD (#1326) (45c66e48 neil)\n  o ci/linux: add dist check (512c88ce Azat Khuzhin)\n  o Add API/ABI checker (using LVC) (735c891e, 448a478a, 889ad6d6, 15917b42, 1cea01d6 yuangongji, Azat Khuzhin)\n  o Merge branch 'tests-under-sanitizers' (d5aa783b Azat Khuzhin)\n  o Rework CI to keep everything in one workflow (by using reusable workflow) (587f26fb Azat Khuzhin)\n\n Samples:\n  o sample/https-client: use host SSL certificate store by default (e139cbac David Disseldorp)\n  o Improvements for internal http-server (9a4b8ec1 Azat Khuzhin)\n  o sample: add https-client-mbedtls (#1098) (b45a02ef okhowang(王沛文))\n  o http-server: add cli argument for max body size (852af060 Azat Khuzhin)\n  o New utility becat (analog of ncat but uses bufferevents, useful for testing) (d5b24cc0 Azat Khuzhin)\n  o https-client: add -4/-6 switches (67180f8c Azat Khuzhin)\n\n SSL:\n  o Mbed-TLS support (#1028) (0e339b04 Jesse Fang, okhowang(王沛文), Azat Khuzhin)\n  o Introduce new BUFFEREVENT_SSL_BATCH_WRITE flag to avoid Nagle effect in SSL (a490172d Azat Khuzhin)\n  o Do not try to do SSL handshake if the connect() fails (59e31c96 Azat Khuzhin)\n  o Support disabled renegotiation in mbedTLS (f02fa339 Azat Khuzhin)\n  o Merge branch 'mbedtls-3' (#1299) (20977eae William Marlow, Azat Khuzhin)\n  o Initial OpenSSL 3.0 support (#1288) (69e9f7ee William Marlow, Azat Khuzhin)\n  o More SSL_read() to fill big buffer (ef51444f Thuan Tran)\n  o Make bufferevent_set_max_single_read() effect (4ab3242d Thuan Tran)\n\n SSL bugfixes:\n  o Explicitly call SSL_clear when reseting the fd. (#498) (c6c74ce2 David Benjamin)\n  o fix handling of close_notify (ssl) in http with openssl bufferevents (da3f2ba2 Azat Khuzhin)\n  o be_openssl: avoid leaking of SSL structure (acf09c00 Azat Khuzhin)\n  o Fix ssl/bufferevent_wm_filter when bev does not reach watermark on break (9d93fbe7 Azat Khuzhin)\n  o Don't loose top error in SSL (a30d6d85 Yury Korzhetsky)\n  o Use heap-bases contexts for MbedTLS handles (#1355) (285fc7cc Dmitry Ilyin)\n  o Deal with partial writes on SSL write (fc568ff0 zhenhaonong)\n  o Avoid EOF in rare (or not that rare) cases - #1451 (e8cbe7b6 Azat Khuzhin)\n\n HTTP (evhttp):\n  o http: add callback to allow server to decline (and thereby close) incoming connections. (727bcea1 John Fremlin)\n  o Add evhttp_parse_query_str_flags() (26ef859a Azat Khuzhin)\n  o http: implement separate timeouts for read/write/connect phase (5ee507c8 Azat Khuzhin)\n  o http: add WebDAV methods support (#789) (68eb526d Alexander Drozdov)\n  o Added http method extending (c80f6be1 Thomas Bernard)\n  o Make http-connect workth with pproxy (462f2e97 Azat Khuzhin)\n  o Add callback support for error pages (02905413 nntrab)\n  o Added evhttp max simultaneous connection limiting (#592) (7426a568 Joseph Coffland, Azat Khuzhin)\n  o http: add EVHTTP_URI_HOST_STRIP_BRACKETS (67180f8c Azat Khuzhin)\n  o http: eliminate redundant bev fd manipulating and caching (afa66ea4 Azat Khuzhin)\n  o http: support unix domain sockets (f446229b Sean Young)\n  o Add more HTTP_ response codes (05a03d4a Dmitry Ilyin)\n  o evhttp_bound_set_bevcb() (77a9b60e Leon M. George, Azat Khuzhin)\n  o Add minimal WebSocket server implementation for evhttp (#1322) (e8313084 Dmitry Ilyin)\n\n HTTP bugfixes (evhttp):\n  o Fix crashing http server when callback do not reply in place (5ff8eb26 Azat Khuzhin)\n  o Do not crash when evhttp_send_reply_start() is called after a timeout. (99d0a952 Andreas Gustafsson)\n  o Allow bodies for GET/DELETE/OPTIONS/CONNECT (db483e3b Azat Khuzhin)\n  o Fix crashing http server when callback do not reply in place from *gencb* (306747e5 Azat Khuzhin)\n  o CONNECT method only takes an authority (65eb529a Greg Hazel)\n  o http: fix leaks in evhttp_uriencode() (61c21492 Azat Khuzhin)\n  o Fix evhttp_connection_get_addr() for incoming http connections (367cd9e5 Greg Hazel, e4edc7fc Azat Khuzhin)\n  o Improve request line parsing (0ec12bc8 Azat Khuzhin)\n  o Fix conceivable UAF of the bufferevent in evhttp_connection_free() (5dc88b38 Azat Khuzhin)\n  o http: fix connection retries when there more then one request for connection (f3f7aa5a Azat Khuzhin)\n  o http: Preserve socket error from listen across closesocket cleanup (28d7221b Luke Dashjr)\n  o http: try to read existing data in buffer under EVHTTP_CON_READ_ON_WRITE_ERROR (7bfe9388 Azat Khuzhin)\n  o http: avoid use of uninitialized value for AF_UNIX/AF_LOCAL sockaddr (76eded24 Azat Khuzhin)\n  o http: make sure the other fields in ext_method are not changed by the callback (1c78451f yuangongji)\n  o http: fix EVHTTP_CON_AUTOFREE in case of connection error (083c6d54 Azat Khuzhin)\n  o http: fix EVHTTP_CON_AUTOFREE in case of timeout (and some else) (eee26dee Azat Khuzhin)\n  o Check error code of evhttp_add_header_internal() in evhttp_parse_query_impl() (4528d8e9 Azat Khuzhin)\n  o http: fix undefined-shift in EVUTIL_IS*_ helpers (37dbb350 Azat Khuzhin)\n  o http: fix invalid unsigned arithmetic (#1134) (d13b7bbf ihsinme)\n  o Fix the value is never actually read from 'argument' in evhttp_parse_query_impl() (#1424) (3bcc92cf Cœur)\n\n DNS (evdns):\n  o evdns: handle NULL filename explicitly (3e6553a1 Bogdan Harjoc)\n  o Added DNS header mask definitions. (fb134939 Nathan French)\n  o evdns: add DNS_OPTION_NAMESERVERS_NO_DEFAULT/EVDNS_BASE_NAMESERVERS_NO_DEFAULT (e5b8f4c1 Azat Khuzhin)\n  o evdns: add new options -- so-rcvbuf/so-sndbuf (538141eb Azat Khuzhin)\n  o evdns: Add additional validation for values of dns options (#1018) (8fe35c76 ayuseleznev)\n  o DNS over TCP (#1004) (028842aa ayuseleznev, Azat Khuzhin)\n  o evdns: Add support for setting maximum UDP DNS message size. (#1032) (83c58d49 seleznevae)\n  o evdns: add max-probe-timeout/probe-backoff-factor settings (#1128) (617ba838 chux0519)\n  o evdns: add ability to get CNAME (#1154) (19b3fd0b Sergey Matveychuk)\n  o feat: add `evdns_base_get_nameserver_fd` method (#1238) (cd6a41ec Yongsheng Xu)\n  o evdns: integrate deferred_response_callback into evdns_request (#1367) (8800b17a mkm)\n  o Allow evdns_base_new to succeed with no nameservers configured (#1389) (3d138bda Daniel Kempenich)\n\n DNS bugfixes (evdns):\n  o evdns: fix race condition in evdns_getaddrinfo() (ee12c516 Sergey Fionov, Sergey Fionov)\n  o evdns: fix lock/unlock mismatch in evdns_close_server_port() (8701d0d3 zhuizhuhaomeng)\n  o Fix checking return value of the evdns_base_resolv_conf_parse() (c3f35345 Azat Khuzhin)\n  o evdns: fix a crash when evdns_base with waiting requests is freed (#962) (4da9f87c ayuseleznev)\n  o recreate socket when udp failed (#1031) (efbe563b okhowang(王沛文))\n  o evdns: do not pass NULL to memcpy() in evdns_server_request_format_response() (c424594b Azat Khuzhin)\n  o evdns: fix \"Branch condition evaluates to a garbage value\" in reply_parse (#1423) (e96e98ae Cœur)\n\n RPC (evrpc):\n  o evrpc: avoid NULL dereference on request is not EVHTTP_REQ_POST (8483c535 Azat Khuzhin)\n\n Core (events, buffers, utils, threads):\n  o Return from event_del() after the last event callback termination (0b4b0efd José Luis Millán, 5ff83989 Azat Khuzhin)\n  o Add convenience macros for user-triggered events (d2acf67e Philip Prindeville)\n  o Filter link-local IPv4 addresses in evutil_found_ifaddr() (b2667b76 Azat Khuzhin)\n  o assert that fds are nonblocking in debug mode (9d3a415a, 6f988ee1 Greg Hazel, Azat Khuzhin)\n  o buffer: make evbuffer_prepend() of zero-length array no-op (c4fbae3a Azat Khuzhin)\n  o Add support for EV_TIMEOUT to event_base_active_by_fd (62df1301 John Ohl)\n  o Maximum evbuffer read configuration (8c2001e9 Azat Khuzhin)\n  o evwatch: Add \"prepare\" and \"check\" watchers. (#793) (2f184f8b, 1cd8830d Dan Rosen)\n  o evutil: implement socketpair with unix domain socket on Win10 (#913) (dda8968c, 1ba94bdf yuangongji)\n  o Add support for priority inheritance (#934) (f76456b0 Andre Pereira Azevedo Pinto, 972289f3 Azat Khuzhin)\n  o evutil_time: Implements usleep() using wait function on Windows (#939) (6412f34f yuangongji)\n  o Add EVENT_BASE_FLAG_EPOLL_DISALLOW_TIMERFD flag (fixes: #958) (9a9b92ed Azat Khuzhin)\n  o evutil_time: improve evutil_gettimeofday on Windows (#1003) (f0b3160f Nick Grifka)\n  o Support EV_CLOSED on linux for poll(2) (4c13afae Azat Khuzhin)\n  o Add wepoll support to light up the epoll backend on Windows (#1006) (83ef3216 Nick Grifka, 45c3fc29 fanquake)\n  o Convert from WinCrypt to Windows BCrypt (eb7bed03 Gerry Garvey)\n  o Merge #1176 - make evthread_use_pthreads() a MT-Safe function (3d48c756 moonlightsh)\n  o buffer: do not round up allocation for reference-type chain objects (#1203) (b926af26 Pierce Lopez)\n  o Add check of mmap64 function and use it when available rather that mmap (#1320) (99fd68ab Dmitry Ilyin)\n  o Make rekey interval less predictable (#1331) (bb41229f Keelan Cannoo)\n  o epoll: use epoll_pwait2() if available (117ee9a0 Dmitry Antipov)\n  o signal: new signal handling backend based on signalfd (#1342) (1af745d0 Dmitry Antipov)\n  o Exclude arc4random_buf implementation if it's already present in the platform (#1375) (7a18af8c Srivatsan Iyer)\n  o buffer: use pread() for evbuffer_file_segment_materialize() (#1392) (0b79a002 Dmitry Antipov)\n\n Core bugfixes (events, buffers, utils):\n  o Fix wrong assert in evbuffer_drain() (b26996a0 Azat Khuzhin)\n  o Fix race in access to ev_res from event loop with event_active() (27934f0b James Synge)\n  o If precise_time is false, we should not set EVENT_BASE_FLAG_PRECISE_TIMER (6cce7458 yongqing.jiao)\n  o buffer: fix incorrect unlock of the buffer mutex (for deferred callbacks) (93913da1 Azat Khuzhin)\n  o Fix base unlocking in event_del() if event_base_set() runned in another thread (08a0d366 Azat Khuzhin)\n  o Fix assert() condition in evbuffer_drain() for IOCP (ab3224c3 SuckShit)\n  o Notify event base if there are no more events, so it can exit without delay (23c2914f Azat Khuzhin)\n  o Do not loose ET flag in case of multiple events for the same fd added (33053cdd Isidor Kouvelas, Azat Khuzhin)\n  o IOCP fixes (to make it possible to work with HTTP layer) (3d815cf2 Azat Khuzhin)\n  o Add error-handling routine for arc4_seed() #769 (8d5b14d4 Seong-Joong Kim)\n  o buffer: fix evbuffer_remove_buffer() with empty chain in front (fdfabbec Azat Khuzhin)\n  o buffer: do not rely on ->off in advance_last_with_data() (5b19c9f6 Azat Khuzhin)\n  o Protect min_heap_push_ against integer overflow. (176fd566 Tobias Stoeckmann)\n  o Prevent endless loop in evmap_make_space (#804) (c6becb26 Tobias Stoeckmann)\n  o Prevent integer overflow in kq_build_changes_list. (#811) (cf8acae3 Tobias Stoeckmann)\n  o kqueue: Avoid undefined behaviour. (2707a4ff Tobias Stoeckmann)\n  o evbuffer: fix last_with_datap after prepend with empty chain (401bd1c0 Azat Khuzhin)\n  o evutil: set the have_checked_interfaces in evutil_check_interfaces() (0de2b145 jeremyerb)\n  o buffer: fix possible NULL dereference in evbuffer_setcb() on ENOMEM (#856) (bdcade47 Azat Khuzhin)\n  o Fix memory corruption in EV_CLOSURE_EVENT_FINALIZE with debug enabled (#885) (445027a5 Jan Kasiak)\n  o arc4random: replace sysctl() with getrandom (on linux) (86f55b04, 194a5d82 Azat Khuzhin)\n  o evutil_time: detect and use _gmtime64_s()/_gmtime64() (#898) (148d12ad yuangongji)\n  o evbuffer_add_file: fix freeing of segment in the error path (4727150a Azat Khuzhin)\n  o Parse IPv6 scope IDs. (#923) (9fecb59a Philip Homburg)\n  o event_base_once: fix potential null pointer threat (#956) (968bbd5c chenguolong)\n  o increase segment refcnt only if evbuffer_add_file_segment() succeeds (#964) (114b3836 yuangongji)\n  o Avoid triggering wrong events with EV_ET set (9543f31a Azat Khuzhin)\n  o epoll: handle EV_ET for EV_CLOSED too (e703c034 Azat Khuzhin)\n  o Fix EV_CLOSED detection/reporting (epoll only) (972b456b Azat Khuzhin)\n  o There is typo in GetAdaptersAddresses windows library. It should be iphlpapi.dll (#1012) (61fc2bf2 Aleksandr-Melnikov)\n  o buffer: do not pass NULL to memcpy() from evbuffer_pullup() (a0c642ac Azat Khuzhin)\n  o Fix leaks of signal handlers for select/poll backends (f6bfa8b3 Azat Khuzhin)\n  o Handle return value from getrandom() (#1070) (efa57159 Gerry Garvey)\n  o Retry write on EINTR in signal handler (#1158) (4f8a6144 Mike Sharov)\n  o Properly initialize sockaddr length on systems with sin_len. (#1177) (5c0e75c3 Tobias Heider)\n  o buffer: fix CreateFileMapping() leak from evbuffer_add_file() (6f139b87 Azat Khuzhin)\n  o evutil: Fix evutil_freeaddrinfo (#1223) (9a38bc5f Tomas Gonzalez)\n  o Fix socketpair failure when temporary directory has non-latin character (f8bb9d84 zhenhaonong)\n  o fix: arc4_getword integer overflow, detected by -fsanitize=undefined (b5b4c7fe jackerli(李剑))\n  o fixed missing check for null after strdup in evutil_inet_pton_scope (#1366) (ff99f67a Michael Madsen)\n  o Optimize arc4random_uniform() (by syncing with OpenBSD implementation) (#1422) (557990ca Cœur)\n  o Always have evutil_secure_rng_add_bytes available (#1427) (4e6375e8 Kurt Roeckx)\n\n Bufferevent:\n  o Adjust evbuffer max read for bufferevents (5357c3d6 Azat Khuzhin)\n  o Implement bufferevent_socket_connect_hostname_hints() (5e137f37 Joseph Spadavecchia)\n  o bufferevent: allow setting priority on socket and openssl type (#1011) (bdc5200a Nicolas J. Bouliane)\n\n Bufferevent bugfixes:\n  o Remove check against passed bufferevent in bufferevent_socket_connect() (a10a6f4e Ivan Maidanski, Azat Khuzhin)\n  o Call underlying bev ctrl GET_FD on filtered bufferevents (40550814 Greg Hazel)\n  o Fix timeout resets for filters (4ba48739 Greg Hazel)\n  o bufferevent_socket_connect{,_hostname}() missing event callback and use ret code (f7bc1337 Jesse Fang)\n  o Fix hangs due to watermarks overruns in bufferevents implementations (878bb2d3 Azat Khuzhin)\n  o Simplify bufferevent timeout tests to reduce CPU usage in between start/compare (6ac8e775 Azat Khuzhin)\n  o Fix leaks in error path of the bufferevent_init_common_() (6995b9a8 Azat Khuzhin)\n  o Check return value of evbuffer_remove() in bufferevent_read() (#1133) (bc25889f lilei)\n\n Listeners:\n  o Immediately stop trying to accept more connections if listener disabled (416b48ba John Fremlin, Azat Khuzhin)\n  o listener: ipv6only socket bind support (387d91f9 Murat Demirten)\n  o listener: Preserve last error in evconnlistener_new_bind() before close (#1269) (d96457e1 kenping)\n  o Add LEV_OPT_BIND_IPV4_AND_IPV6 flag (#1400) (f9134df7 Edoardo Lolletti)\n\n Listeners bugfixes:\n  o Fix evconnlistener_free() closes already established connections (bc65ffc1 Azat Khuzhin)\n  o Fix deadlock in case of evconnlistener_disable() in parallel with callback (#1226) (12cedc8a moonlightsh)\n\n Docs:\n  o Move list of contributors into separate file (56c9551e Sayan Nandan)\n  o doc: cmake command on Windows (b002f04f yuangongji (A))\n  o Deploy documentation to https://libevent.org/doc/ (05467445 Azat Khuzhin)\n  o Doxygen documentation improvements (620a3fa1, 1d1c1909, f9c6a14e yuangongji)\n  o Add vcpkg installation instructions (#953) (ec775a96 JackBoosY)\n  o Remove man pages from repo (they can be generated via doxygen) (31a5cfd3 Azat Khuzhin)\n  o Various documentation improvements (#842) (cdeb3242 yuangongji)\n  o Merge pull request #1441 from fanquake/autoconf_doc_updates (612a74c7 fanquake)\n\n Tests:\n  o test: fix 32bit linux regress (#554) (63c4bf78 Carlo Marcelo Arenas Belón)\n  o test: avoid regress hanging in macOS (#757) (a86f89d3 Carlo Marcelo Arenas Belón)\n  o Avoid possible SEGVs in select() (in unit tests) (33baa4e5 Philip Prindeville)\n  o Introduce TT_RETRIABLE (4d2f013b Azat Khuzhin)\n  o test-ratelim: calculate timers bias (for slow CPUs) to avoid false-positive (8a348699 Azat Khuzhin)\n  o Merge branch 'osx-clock' (a6f81aa4 Azat Khuzhin)\n  o Fix some OpenSSL 3 test issues (#1291) (29032da6 Peter Edwards)\n\n Fixes for various OS:\n  o Enable kqueue for APPLE targets (#849) (0d7d85c2 Keith Smiley)\n  o Enable _GNU_SOURCE for Android (#850) (41c95abb Keith Smiley)\n  o Fix compat with NetBSD >= 10 (#909) (72e6eff0 Kamil Rytarowski)\n  o RTEMS has no SA_RESTART (#1172) (73ca1801 Michael Davidsaver)\n\n Build fixes:\n  o Include openssl-compat.h into dist archive (7bc822ca Azat Khuzhin)\n  o Unbreak build with LibreSSL after openssl 1.1 support added (d057c45e Jan Beich)\n  o Fix RPATH for APPLE (cc0e04d7 Trond Norbye)\n  o Fixes for ERR_remove_*state() (98faf198 Pierce Lopez)\n  o Various cmake fixes (65870949 Shuo Chen)\n  o cmake: autotools compatibility (5aade2d3, 489991a2, 882f537c, 8348b413 Marek Sebera, Azat Khuzhin)\n  o Fixes win32 builds after some previous patches (d84f0205 Azat Khuzhin)\n  o Fix arc4random_addrandom() detecting and fallback (regression) (266f43af Azat Khuzhin)\n  o Add missing print-winsock-errors.c into dist archive (8d89c212 Azat Khuzhin)\n  o Fix visibility issues (mostly on win32) (fb866645, ce3af533, cd285e42 Azat Khuzhin)\n  o Add configure check for midipix (94e5cc84 Redfoxmoon)\n  o autotools: pass $(OPENSSL_INCS) for samples (FTBFS macOS) (0ec5edde Carlo Marcelo Arenas Belón)\n  o autotools: confirm openssl is working before using (506df426 Carlo Marcelo Arenas Belón)\n  o Port `event_rpcgen.py` and `test/check-dumpevents.py` to Python 3. (8b0aa7b3 Kiyoshi Aman)\n  o Fix generation of LibeventConfig.cmake for the installation tree (#576) (6ee73ea9 Andrey Okoshkin)\n  o Provide Makefile variables LIBEVENT_{CFLAGS,CPPFLAGS,LDFLAGS} (1a448088 stenn)\n  o Fix build with LibreSSL 2.7 (28b80754 Bernard Spil)\n  o cmake: ensure windows dll's are installed as well as lib files (0fa43c99 Philip Herron)\n  o Fix out-of-tree builds (a5f19422 Cristian Morales Vega)\n  o config.h can't be prefixed unconditionally (587e9f58 Philip Prindeville)\n  o Define __EXT_POSIX2 for QNX (99a3887d Maya Rashish)\n  o libevent.pc: link against core/extra (731469b3 Mike Frysinger)\n  o Merge branch 'win32-visibility-event_debug_logging_mask_' (fb866645, cd285e42 Azat Khuzhin)\n  o cmake: introduce EVENT__LIBRARY_TYPE option (c9a073ea Azat Khuzhin)\n  o cmake: do not build both (SHARED and STATIC) for MSVC/win32 (90d80ef4 Azat Khuzhin)\n  o cmake: support static runtime (MSVC) (246f4404 Azat Khuzhin)\n  o Eliminate fd conversion warnings and introduce EVUTIL_INVALID_SOCKET (windows) (b29207dc Azat Khuzhin)\n  o Define `_GNU_SOURCE` properly/consistently per autoconf (5f87be42 Enji Cooper)\n  o Fixes for uchex static analyzer (da33f768 Azat Khuzhin)\n  o cmake: add missing autotools targets (doxygen, uninstall, event_rpcgen.py) (7201062f yuangongji)\n  o cmake: set library names to be the same as with autotools (669a53f3 yuangongji)\n  o cmake: install shared library only if it was requested (55d1e20e Azat Khuzhin)\n  o Added uninstall target check to cmakelists (#948) (f0e79baf Dimo Markov)\n  o Build doxygen documentation via cmake (to fill variables) (095c8ae1 Azat Khuzhin)\n  o Merge #929 -- cmake package improvements (8be8ac46 yuangongji)\n  o cmake: do not link libevent with libevent_core (#1123) (657e1806 Loïc Yhuel)\n  o cmake: Fix generted pkgconfig files. (#1165) (1fe8b3d6 Biswapriyo Nath)\n  o cmake: don't override CMAKE_CONFIGURATION_TYPES. (#1166) (087bbc57 Paweł Wegner)\n  o CheckWorkingKqueue.cmake: fix missing headers (#1225) (89505f85 Christopher Chavez)\n  o cmake: Fix Android build. (8f47d8de Ryan Pavlik)\n  o cmake: do influence CMAKE_DEBUG_POSTFIX of the outer project (if any) (650d8619 Azat Khuzhin)\n  o cmake: remove redundant _GNU_SOURCE definition (82af0ea4 Azat Khuzhin)\n  o Various autotools build improvements (#1171) (6d800fd6 fanquake)\n  o Require libevent_core not libevent for pkg-config (#1257) (66861f88 moonlightsh)\n  o -Werror fixes andCI (#1297) (7aeecb60 Azat Khuzhin)\n  o Add postfix for Debug configuration. (dd610b77 Haowei Hsu)\n  o Fix ignoring return value of arc4random() warning (with _FORTIFY_SOURCE defined) (#1394) (c01cb1d6 liaotonglang)\n  o Merge pull request #1418 from fanquake/use_fortify_source_3 (bcefdbc6 fanquake)\n  o Use GNUInstallDirs - #1397 (4dee61c0 Tobias Mayer, Jonathan Ringer, Azat Khuzhin)\n  o Make dependency paths relocatable (#1385) (acfac7ae Ingo Bauersachs)\n"
        },
        {
          "name": "ChangeLog-1.4",
          "type": "blob",
          "size": 16.9638671875,
          "content": "Changes in 1.4.14b-stable\n o Set the VERSION_INFO correctly for 1.4.14\n\nChanges in 1.4.14-stable\n o Add a .gitignore file for the 1.4 branch. (d014edb)\n o Backport evbuffer_readln(). (b04cc60 Nicholas Marriott)\n o Make the evbuffer_readln backport follow the current API (c545485)\n o Valgrind fix: Clear struct kevent before checking for OSX bug. (5713d5d William Ahern)\n o Fix a crash when reading badly formatted resolve.conf (5b10d00 Yasuoka Masahiko)\n o Fix memory-leak of signal handler array with kqueue. [backport] (01f3775)\n o Update sample/signal-test.c to use newer APIs and not leak. (891765c Evan Jones)\n o Correct all versions in 1.4 branch (ac0d213)\n o Make evutil_make_socket_nonblocking() leave any other flags alone. (81c26ba Jardel Weyrich)\n o Adjusted fcntl() retval comparison on evutil_make_socket_nonblocking(). (5f2e250 Jardel Weyrich)\n o Correct a debug message in evhttp_parse_request_line (35df59e)\n o Merge branch 'readln-backport' into patches-1.4 (8771d5b)\n o Do not send an HTTP error when we've already closed or responded. (4fd2dd9 Pavel Plesov)\n o Re-add event_siglcb; some old code _was_ still using it. :( (bd03d06)\n o Make Libevent 1.4 build on win32 with Unicode enabled. (bce58d6 Brodie Thiesfield)\n o Distribute nmake makefile for 1.4 (20d706d)\n o do not fail while sending on http connections the client closed. (5c8b446)\n o make evhttp_send() safe against terminated connections, too (01ea0c5)\n o Fix a free(NULL) in min_heap.h (2458934)\n o Fix memory leak when setting up priorities; reported by Alexander Drozdov (cb1a722)\n o Clean up properly when adding a signal handler fails. (ae6ece0 Gilad Benjamini)\n o Do not abort HTTP requests missing a reason string. (29d7b32 Pierre Phaneuf)\n o Fix compile warning in http.c (906d573)\n o Define _REENTRANT as needed on Solaris, elsewhere (6cbea13)\n\n\nChanges in 1.4.13-stable:\n o If the kernel tells us that there are a negative number of bytes to read from a socket, do not believe it.  Fixes bug 2841177; found by Alexander Pronchenkov.\n o Do not allocate the maximum event queue and fd array for the epoll backend at startup.  Instead, start out accepting 32 events at a time, and double the queue's size when it seems that the OS is generating events faster than we're requesting them.  Saves up to 512K per epoll-based event_base.  Resolves bug 2839240.\n o Fix compilation on Android, which forgot to define fd_mask in its sys/select.h\n o Do not drop data from evbuffer when out of memory; reported by Jacek Masiulaniec\n o Rename our replacement compat/sys/_time.h header to avoid build a conflict on HPUX; reported by Kathryn Hogg.\n o Build kqueue.c correctly on GNU/kFreeBSD platforms. Patch pulled upstream from Debian.\n o Fix a problem with excessive memory allocation when using multiple event priorities.\n o When running set[ug]id, don't check the environment. Based on a patch from OpenBSD.\n\n\nChanges in 1.4.12-stable:\n o Try to contain degree of failure when running on a win32 version so heavily firewalled that we can't fake a socketpair.\n o Fix an obscure timing-dependent, allocator-dependent crash in the evdns code.\n o Use __VA_ARGS__ syntax for varargs macros in event_rpcgen when compiler is not GCC.\n o Activate fd events in a pseudorandom order with O(N) backends, so that we don't systematically favor low fds (select) or earlier-added fds (poll, win32).\n o Fix another pair of fencepost bugs in epoll.c.  [Patch from Adam Langley.]\n o Do not break evdns connections to nameservers when our IP changes.\n o Set truncated flag correctly in evdns server replies.\n o Disable strict aliasing with GCC: our code is not compliant with it.\n\nChanges in 1.4.11-stable:\n o Fix a bug when removing a timeout from the heap. [Patch from Marko Kreen]\n o Remove the limit on size of HTTP headers by removing static buffers.\n o Fix a nasty dangling pointer bug in epoll.c that could occur after epoll_recalc(). [Patch from Kevin Springborn]\n o Distribute Win32-Code/event-config.h, not ./event-config.h\n\nChanges in 1.4.10-stable:\n o clean up buffered http connection data on reset; reported by Brian O'Kelley\n o bug fix and potential race condition in signal handling; from Alexander Drozdov\n o rename the Solaris event ports backend to evport\n o support compilation on Haiku\n o fix signal processing when a signal callback delivers a signal; from Alexander Drozdov\n o const-ify some arguments to evdns functions.\n o off-by-one error in epoll_recalc; reported by Victor Goya\n o include Doxyfile in tar ball; from Jeff Garzik\n o correctly parse queries with encoded \\r, \\n or + characters\n\nChanges in 1.4.9-stable:\n o event_add would not return error for some backends; from Dean McNamee\n o Clear the timer cache on entering the event loop; reported by Victor Chang\n o Only bind the socket on connect when a local address has been provided; reported by Alejo Sanchez\n o Allow setting of local port for evhttp connections to support millions of connections from a single system; from Richard Jones.\n o Clear the timer cache when leaving the event loop; reported by Robin Haberkorn\n o Fix a typo in setting the global event base; reported by lance.\n o Fix a memory leak when reading multi-line headers\n o Fix a memory leak by not running explicit close detection for server connections\n\nChanges in 1.4.8-stable:\n o Match the query in DNS replies to the query in the request; from Vsevolod Stakhov.\n o Fix a merge problem in which name_from_addr returned pointers to the stack; found by Jiang Hong.\n o Do not remove Accept-Encoding header\n\t\nChanges in 1.4.7-stable:\n o Fix a bug where headers arriving in multiple packets were not parsed; fix from Jiang Hong; test by me.\n\t\nChanges in 1.4.6-stable:\n o evutil.h now includes <stdarg.h> directly\n o switch all uses of [v]snprintf over to evutil\n o Correct handling of trailing headers in chunked replies; from Scott Lamb.\n o Support multi-line HTTP headers; based on a patch from Moshe Litvin\n o Reject negative Content-Length headers; anonymous bug report\n o Detect CLOCK_MONOTONIC at runtime for evdns; anonymous bug report\t\n o Fix a bug where deleting signals with the kqueue backend would cause subsequent adds to fail\n o Support multiple events listening on the same signal; make signals regular events that go on the same event queue; problem report by Alexander Drozdov.\n o Deal with evbuffer_read() returning -1 on EINTR|EAGAIN; from Adam Langley.\n o Fix a bug in which the DNS server would incorrectly set the type of a cname reply to a.\n o Fix a bug where setting the timeout on a bufferevent would take not effect if the event was already pending.\n o Fix a memory leak when using signals for some event bases; reported by Alexander Drozdov.\n o Add libevent.vcproj file to distribution to help with Windows build.\n o Fix a problem with epoll() and reinit; problem report by Alexander Drozdov.\t\n o Fix off-by-one errors in devpoll; from Ian Bell\n o Make event_add not change any state if it fails; reported by Ian Bell.\n o Do not warn on accept when errno is either EAGAIN or EINTR\n\nChanges in 1.4.5-stable:\n o Fix connection keep-alive behavior for HTTP/1.0\n o Fix use of freed memory in event_reinit; pointed out by Peter Postma\n o Constify struct timeval * where possible; pointed out by Forest Wilkinson\n o allow min_heap_erase to be called on removed members; from liusifan.\n o Rename INPUT and OUTPUT to EVRPC_INPUT and EVRPC_OUTPUT.  Retain INPUT/OUTPUT aliases on on-win32 platforms for backwards compatibility.\n o Do not use SO_REUSEADDR when connecting\n o Fix Windows build\n o Fix a bug in event_rpcgen when generated fixed-sized entries\n\nChanges in 1.4.4-stable:\n o Correct the documentation on buffer printf functions.\n o Don't warn on unimplemented epoll_create(): this isn't a problem, just a reason to fall back to poll or select.\n o Correctly handle timeouts larger than 35 minutes on Linux with epoll.c.  This is probably a kernel defect, but we'll have to support old kernels anyway even if it gets fixed.\n o Fix a potential stack corruption bug in tagging on 64-bit CPUs.\n o expose bufferevent_setwatermark via header files and fix high watermark on read\n o fix a bug in bufferevent read water marks and add a test for them\n o introduce bufferevent_setcb and bufferevent_setfd to allow better manipulation of bufferevents\n o use libevent's internal timercmp on all platforms, to avoid bugs on old platforms where timercmp(a,b,<=) is buggy.\n o reduce system calls for getting current time by caching it.\n o fix evhttp_bind_socket() so that multiple sockets can be bound by the same http server.\n o Build test directory correctly with CPPFLAGS set.\n o Fix build under Visual C++ 2005.\n o Expose evhttp_accept_socket() API.\n o Merge windows gettimeofday() replacement into a new evutil_gettimeofday() function.\n o Fix autoconf script behavior on IRIX.\n o Make sure winsock2.h include always comes before windows.h include.\n\nChanges in 1.4.3-stable:\n o include Content-Length in reply for HTTP/1.0 requests with keep-alive\n o Patch from Tani Hosokawa: make some functions in http.c threadsafe.\n o Do not free the kqop file descriptor in other processes, also allow it to be 0; from Andrei Nigmatulin\n o make event_rpcgen.py generate code include event-config.h; reported by Sam Banks.\n o make event methods static so that they are not exported; from Andrei Nigmatulin\n o make RPC replies use application/octet-stream as mime type\n o do not delete uninitialized timeout event in evdns\n\nChanges in 1.4.2-rc:\n o remove pending timeouts on event_base_free()\n o also check EAGAIN for Solaris' event ports; from W.C.A. Wijngaards\n o devpoll and evport need reinit; tested by W.C.A Wijngaards\n o event_base_get_method; from Springande Ulv\n o Send CRLF after each chunk in HTTP output, for compliance with RFC2626.  Patch from \"propanbutan\".  Fixes bug 1894184.\n o Add a int64_t parsing function, with unit tests, so we can apply Scott Lamb's fix to allow large HTTP values.\n o Use a 64-bit field to hold HTTP content-lengths.  Patch from Scott Lamb.\n o Allow regression code to build even without Python installed\n o remove NDEBUG ifdefs from evdns.c\n o update documentation of event_loop and event_base_loop; from Tani Hosokawa.\n o detect integer types properly on platforms without stdint.h\n o Remove \"AM_MAINTAINER_MODE\" declaration in configure.in: now makefiles and configure should get re-generated automatically when Makefile.am or configure.in changes.\n o do not insert event into list when evsel->add fails\n\nChanges in 1.4.1-beta:\n o free minheap on event_base_free(); from Christopher Layne\n o debug cleanups in signal.c; from Christopher Layne\n o provide event_base_new() that does not set the current_base global\n o bufferevent_write now uses a const source argument; report from Charles Kerr\n o better documentation for event_base_loopexit; from Scott Lamb.\n o Make kqueue have the same behavior as other backends when a signal is caught between event_add() and event_loop().  Previously, it would catch and ignore such signals.\n o Make kqueue restore signal handlers correctly when event_del() is called.\n o provide event_reinit() to reinitialize an event_base after fork\n o small improvements to evhttp documentation\n o always generate Date and Content-Length headers for HTTP/1.1 replies\n o set the correct event base for HTTP close events\n o New function, event_{base_}loopbreak.  Like event_loopexit, it makes an event loop stop executing and return.  Unlike event_loopexit, it keeps subsequent pending events from getting executed.  Patch from Scott Lamb\n o Removed obsoleted recalc code\n o pull setters/getters out of RPC structures into a base class to which we just need to store a pointer; this reduces the memory footprint of these structures.\n o fix a bug with event_rpcgen for integers\n o move EV_PERSIST handling out of the event backends\n o support for 32-bit tag numbers in rpc structures; this is wire compatible, but changes the API slightly.\n o prefix {encode,decode}_tag functions with evtag to avoid collisions\n o Correctly handle DNS replies with no answers set (Fixes bug 1846282)\n o The configure script now takes an --enable-gcc-warnings option that turns on many optional gcc warnings.  (Nick has been building with these for a while, but they might be useful to other developers.)\n o When building with GCC, use the \"format\" attribute to verify type correctness of calls to printf-like functions.\n o removed linger from http server socket; reported by Ilya Martynov\n o allow \\r or \\n individually to separate HTTP headers instead of the standard \"\\r\\n\"; from Charles Kerr.\n o demote most http warnings to debug messages\n o Fix Solaris compilation; from Magne Mahre\n o Add a \"Date\" header to HTTP responses, as required by HTTP 1.1.\n o Support specifying the local address of an evhttp_connection using set_local_address\n o Fix a memory leak in which failed HTTP connections would not free the request object\n o Make adding of array members in event_rpcgen more efficient, but doubling memory allocation\n o Fix a memory leak in the DNS server\n o Fix compilation when DNS_USE_OPENSSL_FOR_ID is enabled\n o Fix buffer size and string generation in evdns_resolve_reverse_ipv6().\n o Respond to nonstandard DNS queries with \"NOTIMPL\" rather than by ignoring them.\n o In DNS responses, the CD flag should be preserved, not the TC flag.\n o Fix http.c to compile properly with USE_DEBUG; from Christopher Layne\n o Handle NULL timeouts correctly on Solaris; from Trond Norbye\n o Recalculate pending events properly when reallocating event array on Solaris; from Trond Norbye\n o Add Doxygen documentation to header files; from Mark Heily\n o Add a evdns_set_transaction_id_fn() function to override the default\n   transaction ID generation code.\n o Add an evutil module (with header evutil.h) to implement our standard cross-platform hacks, on the theory that somebody else would like to use them too.\n o Fix signals implementation on windows.\n o Fix http module on windows to close sockets properly.\n o Make autogen.sh script run correctly on systems where /bin/sh isn't bash. (Patch from Trond Norbye, rewritten by Hagne Mahre and then Hannah Schroeter.)\n o Skip calling gettime() in timeout_process if we are not in fact waiting for any events. (Patch from Trond Norbye)\n o Make test subdirectory compile under mingw.\n o Fix win32 buffer.c behavior so that it is correct for sockets (which do not like ReadFile and WriteFile).\n o Make the test.sh script run unit tests for the evpoll method.\n o Make the entire evdns.h header enclosed in \"extern C\" as appropriate.\n o Fix implementation of strsep on platforms that lack it\n o Fix implementation of getaddrinfo on platforms that lack it; mainly, this will make Windows http.c work better.  Original patch by Lubomir Marinov.\n o Fix evport implementation: port_disassociate called on unassociated events resulting in bogus errors; more efficient memory management; from Trond Norbye and Prakash Sangappa\n o support for hooks on rpc input and output; can be used to implement rpc independent processing such as compression or authentication.\n o use a min heap instead of a red-black tree for timeouts; as a result finding the min is a O(1) operation now; from Maxim Yegorushkin\n o associate an event base with an rpc pool\n o added two additional libraries: libevent_core and libevent_extra in addition to the regular libevent.  libevent_core contains only the event core whereas libevent_extra contains dns, http and rpc support\n o Begin using libtool's library versioning support correctly.  If we don't mess up, this will more or less guarantee binaries linked against old versions of libevent continue working when we make changes to libevent that do not break backward compatibility.\n o Fix evhttp.h compilation when TAILQ_ENTRY is not defined.\n o Small code cleanups in epoll_dispatch().\n o Increase the maximum number of addresses read from a packet in evdns to 32.\n o Remove support for the rtsig method: it hasn't compiled for a while, and nobody seems to miss it very much.  Let us know if there's a good reason to put it back in.\n o Rename the \"class\" field in evdns_server_request to dns_question_class, so that it won't break compilation under C++.  Use a macro so that old code won't break.  Mark the macro as deprecated.\n o Fix DNS unit tests so that having a DNS server with broken IPv6 support is no longer cause for aborting the unit tests.\n o Make event_base_free() succeed even if there are pending non-internal events on a base.  This may still leak memory and fds, but at least it no longer crashes.\n o Post-process the config.h file into a new, installed event-config.h file that we can install, and whose macros will be safe to include in header files.\n o Remove the long-deprecated acconfig.h file.\n o Do not require #include <sys/types.h> before #include <event.h>.\n o Add new evutil_timer* functions to wrap (or replace) the regular timeval manipulation functions.\n o Fix many build issues when using the Microsoft C compiler.\n o Remove a bash-ism in autogen.sh\n o When calling event_del on a signal, restore the signal handler's previous value rather than setting it to SIG_DFL. Patch from Christopher Layne.\n o Make the logic for active events work better with internal events; patch from Christopher Layne.\n o We do not need to specially remove a timeout before calling event_del; patch from Christopher Layne.\n"
        },
        {
          "name": "ChangeLog-2.0",
          "type": "blob",
          "size": 81.3935546875,
          "content": "Changes in version 2.0.21-stable (18 Nov 2012)\nBUGFIXES:\n o ssl: Don't discard SSL read event when timeout and read come close together (576b29f)\n o ssl: Stop looping in \"consider_reading\" if reading is suspended. (f719b8a Joachim Bauch)\n o ssl: No need to reserve space if reading is suspended. (1acf2eb Joachim Bauch)\n o dns: Avoid a memory-leak on OOM in evdns. (73e85dd, f2bff75 George Danchev)\n o build: Use python2 rather than python (0eb0109 Ross Lagerwall)\n o build: Compile without warnings on mingw64 (94866c2)\n o build: Fix compilation on mingw64 with -DUSE_DEBUG (62bd2c4)\n o build: Make rpcgen_wrapper.sh work on systems without a \"python2\" binary (f3009e4)\n o iocp: Close IOCP listener socket on free when LEV_OPT_CLOSE_ON_FREE is set (cb853ea Juan Pablo Fernandez)\n o core: Avoid crash when event_pending() called with no event_base set on event (e3cccf3)\n o misc: remove stray 'x' so print_err will compile when uncommented (ac35650 Patrick Pelletier)\n o tests: Fix renegotiation test to work around openssl 1.0.1 bug (c2f3086)\n o tests: Warn when openssl version in unit test mismatches compiled version. (ac009f9)\n\n\nChanges in version 2.0.20-stable (23 Aug 2012)\nBUGFIXES:\n o core: Make event_pending() threadsafe. (be7a95c Simon Liu)\n o win32: avoid crash when waiting forever on zero fds. (160e58b)\n o evhttp: Fix a memory leak on error in evhttp_uriencode (11c8b31)\n o evbuffer: Avoid possible needless call to writev. Found by coverity. (6a4ec5c)\n o evdns: memset sockaddr_in before using it. Found by coverity. (a1a0e67)\n o evhttp: Check more setsockopt return values when binding sockets. Found by coverity (a0912e3)\n o evdns: Avoid segfault on weird timeout during name lookup. (dc32077 Greg Hazel)\n o bufferevent_ssl: Correctly invoke callbacks when a SSL bufferevent reads some and then blocks. (606ac43)\n\n\nPORTABILITY FIXES:\n o check for arc4random_buf at runtime, on OS X (bff5f94 Greg Hazel)\n o Correctly check for arc4random_buf (fcec3e8 Sebastian Hahn)\n o Add explicit AC_PROG_SED to configure.in so all autoconfs will expose $(SED) (ca80ea6)\n\nBUILD FIXES:\n o Add GCC annotations so that the vsprintf functions get checked properly (117e327)\n o Fix an unused variable warning on *BSD. (c0720c1)\n\nUNIT TEST FIXES:\n o Fix a couple of memory leaks (found with Valgrind). (3b2529a Ross Lagerwall)\n o Remove deadcode in http regression tests. Found by coverity. (5553346)\n o Fix possible uninitialized read in dns regression tests. Found by coverity. (2259777)\n o Set umask before calling mkstemp in unit tests. Found by coverity (f1ce15d)\n o Fix various check-after-dereference issues in unit tests: found by coverity (4f3732d)\n o Fix resource leaks in the unit tests; found by coverity (270f279)\n o Add some missing null checks to unit tests; found by coverity (f021c3d)\n o Avoid more crashes/bad calls in unit tests; found by coverity (3cde5bf)\n o Remove unused variable; spotted by coverity (6355b2a)\n o Add checks to various return values in unit tests. Found by coverity (b9e7329)\n o Move assignment outside tt_assert in ssl unit tests. Appeases coverity. (a2006c0)\n\n\n\nChanges in version 2.0.19-stable (3 May 2012)\nBUGFIXES (CORE):\n o Refactor event_persist_closure: raise and extract some common logic (bec22b4)\n o If time has jumped so we'd reschedule a periodic event in the past, schedule it for the future instead (dfd808c)\n o If a higher-priority event becomes active, don't continue running events of the current priority. (2bfda40)\n\nBUGFIXES (SSL):\n o Fixed potential double-readcb execution with openssl bufferevents. (4e62cd1 Mark Ellzey)\n\nBUGFIXES (DNS):\n o Cancel a probe request when the server is freed, and ignore cancelled probe callbacks (94d2336 Greg Hazel)\n o Remove redundant DNS_ERR_CANCEL check, move comment (46b8060 Greg Hazel)\n o When retransmitting a timed-out DNS request, pick a fresh nameserver. (3d9e52a)\n\nDOCUMENTATION FIXES:\n o Fix a typo in the bufferevent documentation (98e9119)\n o Add missing ) to changelog; spotted by rransom (4c7ee6b)\n o Fix the website URL in the readme (f775521)\n\nCOMPILATION FIXES:\n o Fix a compilation error with MSVC 2005 due to use of mode_t (336dcae)\n o Configure with gcc older than 2.95 (4a6fd43 Sebastian Hahn)\n o Generate event-config.h with a single sed script (30b6f88 Zack Weinberg)\n\nFORWARD-COMPATIBILITY:\n o Backport: provide EVENT_LOG_* names, and deprecate _EVENT_LOG_* (d1a03b2)\n\nTESTING/DEBUGGING SUPPORT:\n o dns-example.c can now take a resolv.conf file on the commandline (6610fa5)\n o Make some evdns.c debug logs more verbose (d873d67)\n o Work-around a stupid gcov-breaking bug in OSX 10.6 (b3887cd)\n\n\n\nChanges in version 2.0.18-stable (22 Mar 2012)\nBUGFIXES (core):\n o Make uses of open() close-on-exec safe by introducing an internal evutil_open_closeonexec. (d2b5f72 Ross Lagerwall, 03dce42)\n\nBUGFIXES (kqueue):\n o Properly zero the kevent in kq_setup_kevent() (c2c7b39 Sebastian Hahn)\n\nBUILD FIXES:\n o Added OPENSSL_LDFLAGS env variable which is appended to SSL checks. (9278196 Mark Ellzey)\n o Changed OPENSSL_LDFLAGS to OPENSSL_LIBADD (2d67b63 Mark Ellzey)\n o Don't do clang version detection when disabling some flags (083296b Sebastian Hahn)\n\nBUGFIXES (dns):\n o Stop crashing in evdns when nameserver probes give a weird error (bec5068)\n\n\nChanges in version 2.0.17-stable (10 Feb 2012)\n\nBUGFIXES (core):\n o Be absolutely sure to clear pncalls before leaving event_signal_closure (11f36a5)\n o check for sysctl before we use it (358c745 Mike Frysinger)\n o Remove bogus casts of socket to int before calling ev_callback (f032516)\n o Make evconnlistener work around bug in older Linux when getting nmapped (ecfc720)\n o Fix a list corruption bug when using event_reinit() with signals present (6e41cdc)\n o Fix a fd leak in event_reinit() (3f18ad1)\n o Do a memberwise comparison of threading function tables (c94a5f2 Nate R)\n o Use C-style comments in C source files (for compatibility with compilers such as xlc on AIX). (d84d917 Greg Hewgill)\n o Avoid crash when freeing event_iocp and using event_set_mem_functions (19715a6)\n o In the kqueue backend, do not report EBADF as an EV_READ (5d7bfa1 Nicholas Marriott)\n\nBUGFIXES (evbuffer and bufferevents):\n o Fix behavior of evbuffer_peek(buf,-1,NULL,NULL,0) (c986f23 Zack Weinberg)\n o Loop on filtering SSL reads until we are blocked or exhausted. (5b4b812)\n\nBUGFIXES (evhttp):\n o Force strict validation of HTTP version in response. (790f6b3 Catalin Patulea)\n\nBUGFIXES (evdns):\n o evdns: fix a bug in circular-queue implementation (d6094b1)\n\nBUILD FIXES:\n o Fix a silly compilation error with the sun compiler (1927776 Colin Watt)\n o Suppress a gcc warning from ignoring fwrite return in http-sample.c (7206e8c)\n\nDOCUMENTATION FIXES:\n o Slightly clarify evbuffer_peek documentation (7bbf6ca)\n o Update copyright notices to 2012 (e49e289)\n\nNEW APIS:\n o Backport evhttp_connection_get_bufferevent to Libevent 2.0 (da70fa7 Arno Bakker)\n\nTESTS AND TEST FIXES:\n o Fix a race condition in the dns/bufferevent_connect_hostname test. (cba48c7)\n o Add function to check referential integrity of an event_base (27737d5)\n o Check event_base correctness at end of each unit test (3312b02)\n o Workaround in the unit tests for an apparent epoll bug in Linux 3.2 (dab9187)\n o Better workaround for Linux 3.2 edge-triggered epoll bug (9f9e259)\n\nChanges in version 2.0.16-stable (18 Nov 2011)\nBUGFIXES (core):\n o More detailed message in case of libevent self-debugging failure. (9e6a4ef Leonid Evdokimov)\n o epoll: close fd on alloc fail at initialization (1aee718 Jamie Iles)\n o Fix compile warning from saying event2/*.h inside a comment (447b0ba)\n o Warn when unable to construct base because of failing make_base_notifiable (4e797f3)\n o Don't try to make notifiable event_base when no threading fns are configured (e787413)\n\nBUGFIXES (evbuffer):\n o unit test for remove_buffer bug (90bd620 Greg Hazel)\n o Fix an evbuffer crash in evbuffer_remove_buffer() (c37069c)\n\nBUGFIXES (bufferevent_openssl):\n o Refactor amount-to-read calculations in buffervent_ssl consider_reading() (a186e73 Mark Ellzey)\n o Move SSL rate-limit enforcement into bytes_to_read() (96c562f)\n o Avoid spinning on OpenSSL reads (2aa036f Mark Ellzey)\n\nBUGFIXES (dns)\n o Empty DNS reply with OK status is another way to say NODATA. (21a08d6 Leonid Evdokimov)\n\nTESTING:\n o Tests for 94fba5b and f72e8f6 (d58c15e Leonid Evdokimov)\n o Test for commit aff6ba1 (f7841bf Leonid Evdokimov)\n o Style and comment tweaks for dns/leak* tests (5e42202)\n o improve test to remove at least one buffer from src (7eb52eb Greg Hazel)\n\nDOCUMENTATION:\n o Add note about evhttp_send_reply_end to its doxygen (724bfb5)\n o Update copyright dates to 2011. (3c824bd)\n o Fix typo in whatsnew-2.0.txt (674bc6a Mansour Moufid)\n o Improve win32 behavior of dns-sample.c code (a3f320e Gisle Vanem)\n\n\n\nChanges in version 2.0.15-stable (12 Oct 2011)\nBUGFIXES (DNS):\n o DNS: add ttl for negative answers using RFC 2308 idea. (f72e8f6 Leonid Evdokimov)\n o Add DNS_ERR_NODATA error code to handle empty replies. (94fba5b Leonid Evdokimov)\n\nBUFGIXES (bufferevents and evbuffers):\n o Make evbuffer callbacks get the right n_added value after evbuffer_add (1ef1f68 Alex)\n o Prefer mmap to sendfile unless a DRAINS_TO_FD flag is set. Allows add_file to work with SSL. (0ba0af9)\n\nBUGFIXES (event loop):\n o When a signal callback is activated to run multiple times, allow event_base_loopbreak to work even before they all have run. (4e8eb6a)\n\nDOCUMENTATION FIXES:\n o Fix docstring in dns.h (2b6eae5 Leonid Evdokimov)\n o refer to non-deprecated evdns functions in comments (ba5c27d Greg Hazel)\n\nBUILD AND TESTING FIXES:\n o le-proxy and regress depend on openssl directly (9ae061a Sergey Avseyev)\n o Use _SOURCES, not _sources, in sample/Makefile.am (7f82382)\n o Fixed compiler warnings for unchecked read/write calls. (c3b62fd Mark Ellzey)\n o Make write-checking fixes use tt_fail_perror (2b76847)\n o Fix some \"value never used\" warnings with gcc 4.6.1 (39c0cf7)\n\n\n\nChanges in version 2.0.14-stable (31 Aug 2011)\nBUGFIXES (bufferevents and evbuffers):\n o Propagate errors on the underlying bufferevent to the user. (4a34394 Joachim Bauch)\n o Ignore OpenSSL deprecation warnings on OS X (5d1b255 Sebastian Hahn)\n o Fix handling of group rate limits under 64 bytes of burst (6d5440e)\n o Solaris sendfile: correctly detect amount of data sent (643922e Michael Herf)\n o Make rate limiting work with common_timeout logic (5b18f13)\n o clear read watermark on underlying bufferevent when creating filtering bev to fix potentially failing fragmented ssl handshakes (54f7e61 Joachim Bauch)\n\nBUGFIXES (IOCP):\n o IOCP: don't launch reads or writes on an unconnected socket (495c227)\n o Make IOCP rate-limiting group support stricter and less surprising. (a98da7b)\n o Have test-ratelim.c support IOCP (0ff2c5a)\n o Make overlapped reads result in evbuffer callbacks getting invoked (6acfbdd)\n o Correctly terminate IO on an async bufferevent on bufferevent_free (e6af35d)\n\nBUGFIXES (other):\n o Fix evsig_dealloc memory leak with debugging turned on. (9b724b2 Leonid Evdokimov)\n o Fix request_finished memory leak with debugging turned on. (aff6ba1 Leonid Evdokimov)\n\nBUILD AND TESTING FIXES:\n o Allow OS-neutral builds for platforms where some versions have arc4random_buf (b442302 Mitchell Livingston)\n o Try to fix 'make distcheck' errors when building out-of-tree (04656ea Dave Hart)\n o Clean up some problems identified by Coverity. (7c11e51 Harlan Stenn)\n\n\nChanges in version 2.0.13-stable (18 Jul 2011)\nBUGFIXES\n o Avoid race-condition when initializing global locks (b683cae)\n o Fix bug in SSL bufferevents backed by a bev with a write high-watermarks (e050703 Joachim Bauch)\n o Speed up invoke_callbacks on evbuffers when there are no callbacks (f87f568 Mark Ellzey)\n o Avoid a segfault when all methods are disabled or broken (27ce38b)\n o Fix incorrect results from evbuffer_search_eol(EOL_LF) (4461f1a)\n o Add some missing checks for mm_calloc failures (89d5e09)\n o Replace an assertion for event_base_free(NULL) with a check-and-warn (09fe97d)\n o Report kqueue ebadf, epipe, and eperm as EV_READ events (1fd34ab)\n o Check if the `evhttp_new_object' function in `http.c' returns NULL. (446cc7a Mansour Moufid)\n o Use the correct printf args when formatting size_t (3203f88)\n o Complain if the caller tries to change threading cbs after setting them (cb6ecee)\n\nDOCUMENTATION FIXES AND IMPROVEMENTS\n o Revise the event/evbuffer/bufferevent doxygen for clarity and accuracy (2888fac)\n o Update Doxyfile to produce more useful output (aea0555)\n\nTEST FIXES\n o Fix up test_evutil_snprintf (caf695a)\n o Fix tinytest invocation from windows shell (57def34 Ed Day)\n\nBUILD FIXES\n o Use AM_CPPFLAGS in sample/Makefile.am, not AM_CFLAGS (4a5c82d)\n o Fix select.c compilation on systems with no NFDBITS (49d1136)\n o Fix a few warnings on OpenBSD (8ee9f9c Nicholas Marriott)\n o Don't break when building tests from git without python installed (b031adf)\n o Don't install event_rpcgen.py when --disable-libevent-install is used (e23cda3 Harlan Stenn)\n o Fix AIX build issue with TAILQ_FOREACH definition (e934096)\n\n\nChanges in version 2.0.12-stable (4 Jun 2011)\nBUGFIXES\n o Fix a warn-and-fail bug in kqueue by providing kevent() room to report errors (28317a0)\n o Fix an assert-inducing fencepost bug in the select backend (d90149d)\n o Fix failing http assertion introduced in commit 0d6622e (0848814 Kevin Ko)\n o Fix a bug that prevented us from configuring IPv6 nameservers. (74760f1)\n o Prevent size_t overflow in evhttp_htmlescape. (06c51cd Mansour Moufid)\n o Added several checks for under/overflow conditions in evhttp_handle_chunked_read (a279272 Mark Ellzey)\n o Added overflow checks in evhttp_read_body and evhttp_get_body (84560fc Mark Ellzey)\n\nDOCUMENTATION:\n o Add missing words to EVLOOP_NONBLOCK documentation (9556a7d)\n\nBUILD FIXES\n o libssl depends on libcrypto, not the other way around. (274dd03 Peter Rosin)\n o Libtool brings in the dependencies of libevent_openssl.la automatically (7b819f2 Peter Rosin)\n o Use OPENSSL_LIBS in Makefile.am (292092e Sebastian Hahn)\n o Move the win32 detection in configure.in (ceb03b9 Sebastian Hahn)\n o Correctly detect openssl on windows (6619385 Sebastian Hahn)\n o Fix a compile warning with zlib 1.2.4 and 1.2.5 (5786b91 Sebastian Hahn)\n o Fix compilation with GCC 2, which had no __builtin_expect (09d39a1 Dave Hart)\n o Fix new warnings from GCC 4.6 (06a714f)\n o Link with -lshell32 and -ladvapi32 on Win32. (86090ee Peter Rosin)\n o Make the tests build when OpenSSL is not available. (07c41be Peter Rosin)\n o Bring in the compile script from automake, if needed. (f3c7a4c Peter Rosin)\n o MSVC does not provide S_ISDIR, so provide it manually. (70be7d1 Peter Rosin)\n o unistd.h and sys/time.h might not exist. (fe93022 Peter Rosin)\n o Make sure TINYTEST_LOCAL is defined when building tinytest.c (8fa030c Peter Rosin)\n o Fix winsock2.h #include issues with MSVC (3d768dc Peter Rosin)\n o Use evutil_gettimeofday instead of relying on the system gettimeofday. (0de87fe Peter Rosin)\n o Always use evutil_snprintf, even if OS provides it (d1b2d11 Sebastian Hahn)\n o InitializeCriticalSectionAndSpinCount requires _WIN32_WINNT >= 0x0403. (816115a Peter Rosin)\n o cygwin: make it possible to build DLLs (d54d3fc)\n\n\n\nChanges in version 2.0.11-stable (27 Apr 2011)\n  [Autogenerated from the Git log, sorted and cleaned by hand.]\nBUGFIXES:\n o Fix evport handling of POLLHUP and POLLERR (b42ce4b)\n o Fix compilation on Windows with NDEBUG (cb8059d)\n o Check for POLLERR, POLLHUP and POLLNVAL for Solaris event ports (0144886 Trond Norbye)\n o Detect and handle more allocation failures. (666b096 Jardel Weyrich)\n o Use event_err() only if the failure is truly unrecoverable. (3f8d22a Jardel Weyrich)\n o Handle resize failures in the select backend better. (83e805a)\n o Correctly free selectop fields when select_resize fails in select_init (0c0ec0b)\n o Make --enable-gcc-warnings a no-op if not using gcc (3267703)\n o Fix a type error in our (unused) arc4random_stir() (f736198)\n o Correctly detect and stop non-chunked http requests when the body is too long (63a715e)\n o Have event_base_gettimeofday_cached() always return wall-clock time (a459ef7)\n o Workaround for http crash bug 3078187 (5dc5662 Tomash Brechko)\n o Fix incorrect assertions and possible use-after-free in evrpc_free() (4b8f02f Christophe Fillot)\n o Reset outgoing http connection when read data in idle state. (272823f Tomash Brechko)\n o Fix subtle recursion in evhttp_connection_cb_cleanup(). (218cf19 Tomash Brechko)\n o Fix the case when failed evhttp_make_request() leaved request in the queue. (0d6622e Tomash Brechko)\n o Fix a crash bug in evdns server circular list code (00e91b3)\n o Handle calloc failure in evdns. (Found by Dave Hart) (364291e)\n o Fix a memory leak on win32 socket->event map. (b4f89f0)\n o Add a forgotten NULL check to evhttp_parse_headers (12311ff Sebastian Hahn)\n o Fix possible NULL-deref in evdns_cancel_request (5208544 Sebastian Hahn)\n\nPORTABILITY:\n o Fall back to sscanf if we have no other way to implement strtoll (453317b)\n o Build correctly on platforms without sockaddr_storage (9184563)\n o Try to build correctly on platforms with no IPv6 support (713c254)\n o Build on systems without AI_PASSIVE (cb92113)\n o Fix http unit test on non-windows platforms without getaddrinfo (6092f12)\n o Do not check for gethostbyname_r versions if we have getaddrinfo (c1260b0)\n o Include arpa/inet.h as needed on HPUX (10c834c Harlan Stenn)\n o Include util-internal.h as needed to build on platforms with no sockaddr_storage (bbf5515 Harlan Stenn)\n o Check for getservbyname even if not on win32. (af08a94 Harlan Stenn)\n o Add -D_OSF_SOURCE to fix hpux builds (0b33479 Harlan Stenn)\n o Check for allocation failures in apply_socktype_protocol_hack (637d17a)\n o Fix the check for multicast or broadcast addresses in evutil_check_interfaces (1a21d7b)\n o Avoid a free(NULL) if out-of-memory in evdns_getaddrinfo. Found by Dave Hart (3417f68)\n\nDEFENSIVE PROGRAMMING:\n o Add compile-time check for AF_UNSPEC==PF_UNSPEC (3c8f4e7)\n\nBUGS IN TESTS:\n o Fix test.sh output on solaris (b4f89b6 Dave Hart)\n o Make test-eof fail with a timeout if we never get an eof. (05a2c22 Harlan Stenn)\n o Use %s with printf in test.sh (039b9bd)\n o Add an assert to appease clang's static analyzer (b0ff7eb Sebastian Hahn)\n o Add a forgotten return value check in the unit tests (3819b62 Sebastian Hahn)\n o Actually send NULL request in http_bad_request_test (b693c32 Sebastian Hahn)\n o add some (void) casts for unused variables (65707d7 Sebastian Hahn)\n o Refactor test_getaddrinfo_async_cancel_stress() (48c44a6 Sebastian Hahn)\n o Be nice and \"handle\" error return values in sample code (4bac793 Sebastian Hahn)\n o Check return value of evbuffer_add_cb in tests (93a1abb Sebastian Hahn)\n o Remote some dead code from dns-example.c (744c745 Sebastian Hahn)\n o Zero a struct sockaddr_in before using it (646f9fe Sebastian Hahn)\n\nBUILD FIXES:\n o Fix warnings about AC_LANG_PROGRAM usage (f663112 Sebastian Hahn)\n o Skip check for zlib if we have no zlib.h (a317c06 Harlan Stenn)\n o Fix autoconf bracket issues; make check for getaddrinfo include netdb.h (833e5e9 Harlan Stenn)\n o Correct an AM_CFLAGS to an AM_CPPFLAGS in test/Makefile.am (9c469db Dave Hart)\n o Fix make distcheck & installation of libevent 1 headers (b5a1f9f Dave Hart)\n o Fix compilation under LLVM/clang with --enable-gcc-warnings (ad9ff58 Sebastian Hahn)\n\nFEATURES:\n o Make URI parser able to tolerate nonconformant URIs. (95060b5)\n\nDOCUMENTATION:\n o Clarify event_set_mem_functions doc (926f816)\n o Correct evhttp_del_accept_socket documentation on whether socket is closed (f665924)\n o fix spelling mistake in whatsnew-2.0.txt (deb2f73)\n o Fix sample/http-server ipv6 fixes (eb692be)\n o Comment internal headers used in sample code. (4eb281c)\n o Be explicit about how long event loops run in event.h documentation (f95bafb)\n o Add comment to configure.in to explain gc-sections test logic (c621359)\n o Fix a couple of memory leaks in samples/http-server.c. Found by Dave Hart. (2e9f665)\n\nBUILD IMPROVEMENTS:\n o Use the gcc -ffunction-segments feature to allow gc when linking with static libevent (0965c56 Dave Hart)\n o Add configure options to disable installation, regression tests (49e9bb7 Dave Hart)\n\n\n\nChanges in version 2.0.10-stable (16 Dec 2010)\n  [Autogenerated from the Git log, sorted and cleaned by hand.]\nBUGFIXES\n o Minor fix for IOCP shutdown handling fix (2599b2d Kelly Brock)\n o Correctly notify the main thread when activating an event from a subthread (5beeec9)\n o Reject overlong http requests early when Expect:100-continue is set (d23839f Constantine Verutin)\n o EVUTIL_ASSERT: Use sizeof() to avoid \"unused variable\" warnings with -DNDEBUG. (b63ab17 Evan Jones)\n\nCODE CLEANUPS\n o bufferevent-internal.h: Use the new event2/util.h header, not evutil.h (ef5e65a Evan Jones)\n o Use relative includes instead of system includes consistently. (fbe64f2 Evan Jones)\n o Make whitespace more consistent\n\nTESTING\n o tests: Use new event2 headers instead of old compatibility headers. (4f33209 Evan Jones)\n\nDOCUMENTATION\n o Document that the cpu_hint is only used on Windows with IOCP for now (57689c4)\n o Add stuff to \"whats new in 2.0\" based on reading include changes since August. (18adc3f)\n\n\nChanges in 2.0.9-rc (30 Nov 2010):\n  [Autogenerated from the Git log, sorted and cleaned by hand.]\nNEW AND MODIFIED APIs\n o Add a function to change a listener's callback. (46ee061)\n o Make evbuffer_add_file take ev_off_t, not off_t (ac7e52d)\n o Make rate-limits go up to SIZE_MAX/EV_SSIZE_MAX, not just INT32_MAX (2cbb1a1)\n o Add a bufferevent_get_base function (aab49b6)\n\nMAJOR BUGFIXES\n o Disable changelist for epoll by default because of Linux dup() bug; add an option and/or an envvar to reenable it for speed. (9531763)\n o Fix a 100%-CPU bug where an SSL connection would sometimes never stop trying to write (1213d3d)\n o Fix a nasty bug related to use of dup() with epoll on Linux (c281aba)\n o Fix bugs in posix thread-id calculation when sizeof(pthread_t) != sizeof(long) (fbaf077)\n o Fix some ints to evutil_socket_t; make tests pass on win64. (f817bfa Dimitre Piskyulev)\n o Set _EVENT_SIZEOF_VOID_P correctly on win32 and win64 (1ae82cd Dimitre Piskyulev)\n o Avoid double-invocation of user callback with EVUTIL_EAI_CANCEL (abf01ed)\n o Set SO_UPDATE_ACCEPT_CONTEXT on sockets from AcceptEx so that shutdown() can work (52aa419)\n o When closing a filtering bufferevent, clear callbacks on the underlying bufferevent (fc7b1b0)\n\nNEW AND MODIFIED HTTP APIs\n o Add evhttp_parse_query_str to be used with evhttp_uri_parse. (2075fbc)\n o Add evhttp_response_code to remove one more reason to include http_struct.h (22e0a9b)\n o Define enumerators for all HTTP methods, including PATCH from RFC5789 (75a7341 Felix Nawothnig)\n o Functions to actually use evhttp_bound_socket with/as evconnlistener. (006efa7)\n o Add evhttp_request_get_command so code can tell GET from POST without peeking at the struct. (49f4bf7)\n o Introduce absolute URI parsing helpers. (86dd720 Pavel Plesov)\n o Revise evhttp_uri_parse implementation to handle more of RFC3986 (eaa5f1d)\n o Add evhttp_connection_get_base() to get the event_base from an http connection (cd00079)\n o Let evhttp_parse_query return -1 on failure (b1756d0)\n o New evhttp_uri(encode|decode) functions to handle + and NUL characters right (a8148ce)\n o Add evhttp_response_code to remove one more reason to include http_struct.h (22e0a9b)\n o Tweak interface for allowed methods (f5b391e)\n o Add evhttp server alias interface, correct flagging of proxy requests. (aab8c38 Christopher Davis)\n\nHTTP BUGFIXES\n o Add some comments to http.c and make a few functions static. (90b3ed5)\n o Fix Content-Length when trying send more than 100GB of data (!) on an evhttp. (525da3e)\n o Fix a bug where we would read too much data in HTTP bodies or requests. (58a1cc6)\n o Correctly count req->body_size on http usage without Content-Length (8e342e5)\n o Avoid missed-request bug when entire http request arrives before data is flushed (74c0e86)\n o reset \"chunked\" flag when sending non-chunked reply (aa5f55f Joachim Bauch)\n o evhttp_encode_uri encodes all reserved characters, including !$'()*+,/:=@ (2e63a60)\n o Replace exact-version checks for HTTP/1.1 with >= or < checks (647e094)\n o evhttp: Return 501 when we get an unrecognized method, not 400. (536311a)\n o Don't disable reading from the HTTP connection after sending the request to be notified of connection-close in time (c76640b Felix Nawothnig)\n o Never call evhttp_readcb while writing. (0512487)\n o Try to fix an assertion failure related to close detection (0faaa39)\n o Correctly detect timeouts during http connects (04861d5)\n o Preliminary support for Continue expectation in evhttp. (fa9305f Christopher Davis)\n\nOTHER BUGFIXES\n o Correct logic for realigning a chain in evbuffer_add (e4f34e8)\n o Fix a minor syntax error that most compilers didn't care about (e56ff65)\n o Fix some uses of int for socket in regress (5d389dc)\n o Check return value for ioctlsocket on win32 (f5ad31c Trond Norbye)\n o Fix som event_warns that should have been event_warnx (19c71e7)\n o Fix signal handler types for win64. (b81217f)\n o Try to clear up more size_t vs int/long issues. (598d133)\n o Make sure IOCP evconnlistener uses virtual events. (7b40a00 Christopher Davis)\n o Don't free evdns_request handles until after the callback is invoked (9ed30de)\n o Fix some more cancel-related bugs in getaddrinfo_async (c7cfbcf)\n o Make evdns_getaddrinfo_cancel threadsafe (d51b2fc)\n o Only clear underlying callbacks when the user hasn't reset them. (1ac5b23)\n o Fix bug in bufferevent_connect on an openssl bufferevent that already had an fd (4f228a1)\n o Resolve an evport bug in the thread/forking test (3a67d0b)\n o Make sure the CLOEXEC flag is set on fds we open for base notification (3ab578f)\n o Fix IRIX build.  sa_family collides with a #define in sys/socket.h on IRIX. (e874982 Kevin Bowling)\n o If not WIN32, include <sys/socket.h> in event2/util.h. (1cd45e5 Kevin Bowling)\n o Fix some C99-style comments to work with the xlC compiler. (c2e5e22 Kevin Bowling)\n o Add some checks since lack of TAILQ_FOREACH doesn't imply lack of FIRST, END, NEXT, or INSERT_BEFORE.  Quiet some warnings in XL C. (c4dc335 Kevin Bowling)\n o Reworked AIX __ss_family workaround to use AC_STRUCT_MEMBER. (2e2a3d7 Kevin Bowling)\n o Take select from <sys/select.h> when testing in autoconf.  AIX build fix. (a3a9f6b Kevin Bowling)\n o Fix snprintf related failures on IRIX. (3239073 Kevin Bowling)\n o Remove _event_initialized(); make event_initialized() a function(); make it consistent on windows and non-windows (652024b)\n o Do not let EVLOOP_ONCE exit the loop until all deferred callbacks have run (2d5e1bd)\n o Make EVLOOP_ONCE ignore internal events (0617a81)\n o Possible crash fix when freeing an underlying bufferevent of an openssl bufferevent (29f7623)\n\nHTTP CLEANUPS\n o Stop using Libevent-1 headers in regress_http (1f507d7)\n o Modernize header usage in bench_http.c (e587069)\n o fix signed/unsigned warnings in http.c (74a91e5)\n o Update the HTTP regression tests to use Libevent2 apis for non-http stuff (d9ffa89)\n o Start porting http tests to not use legacy interfaces (8505a74)\n o Convert the rest of the http tests to be non-legacy unit tests. (9bb8239)\n o Rename the confusing \"base\" static variable in regress_http.c (353402a)\n o Stop accessing http request struct directly from in the unit tests. (0b137f4)\n o Refactor http version parsing into a single function (a38140b)\n\nTESTING\n o Improvements to tinytest_macros.h (ad923a1)\n o Add a huge pile of tests for the new URI functions, and make them pass. (a5a76e6)\n o Unit tests for evhttp_uri_set* (bc98f5e)\n o Increase the skew tolerance to 2 seconds in thread/deferred_cb_skew (f806476 Christopher Davis)\n o Reorder backends in test.sh to match preference order in event.c (ece974f)\n o Add a stress test for getaddrinfo_cancel (da1bf52)\n o Units test for unexpected evhttp methods. (75e3320)\n\nDOCUMENTATION\n o Document behavior of URI parsing more thoroughly. (3a33462)\n o Document that two bufferevent functions only work on socket bufferevents (70e1b60)\n o add a requested docstring for event_rpcgen.CommandLine.__init__ (f1250eb)\n o Fix a mistake in http documentation found by Julien Blache (229714d)\n o Add a basic example of how to write a static HTTP server. (4e794d5)\n o Document event_get_assignment (88be27d)\n o Note that reentrant calls to libevent from logging cbs may fail badly (e431bcd)\n o Clarify EVLOOP_* documentation to be more precise. (057a514)\n\nCLEANUPS\n o Simplify the logic for choosing EPOLL_CTL_ADD vs EPOLL_CTL_MOD (2c66983)\n o Rename \"size\" variables in win32select that were really fd counts. (b6a158c)\n o Fix even more win64 warnings (7484df6)\n o Fix even more win64 warnings: buffer, event_tagging, http, evdns, evrpc (545a611)\n o Fix more wn64 warnings. (34b84b9 Christopher Davis)\n o Use the label_len local variable in evdns instead of recalculating it over and over (ba01456)\n o Fix some irix compilation warnings spotted by Kevin Bowling (7bcace2)\n\n\n\nChanges in 2.0.8-rc (14 Oct 2010):\n [Autogenerated from the Git log, sorted and cleaned by hand.]\nNEW APIS\n o Add error callback to evconnlistener (c4be8d8 Simon Perreault)\n o Add a LEV_OPT_THREADSAFE option for threadsafe evconnlisteners (127d4f2)\n\nCHANGED BEHAVIOR\n o Correct logic on disabling underlying bufferevents when disabling a filter (ac27eb8)\n\nBUGFIXES\n o Obey enabled status when unsuspending (040a019 Simon Perreault)\n o Warn when using the error-prone EV_SIGNAL interface in an error-prone way.  Also, fix a couple of race conditions in signal.c (720bd93)\n O Make default signal backend fully threadsafe (95a7d41)\n o Put internal events at highest priority (90651b3)\n o Fix warnings in the main codebase flagged by -Wsigned-compare (9c8db0, 5e4bafb, 5c214a, 6be589a, e06f514)\n o Fix compile in kqueue.c (b395392 Sebastian Hahn)\n o Do not search outside of the system directory for windows DLLs (d49b5e3)\n o Fix a spurious-call bug on epoll.c (0faaee0)\n o Send a shutdown(SHUT_WR) before closing an http connection (e0fd870 Christopher Davis)\n o Fix warnings on mingw with gcc 4.5 (5b7a370)\n o Fix an EINVAL on evbuffer_write_iovec on OpenSolaris. (fdc640b)\n o Fix allocation error for IOCP listeners. Probably harmless, since struct event is big (481ef92)\n o Make iocp/listener/error work; don't accept again if lev is disabled. (62b429a Christopher Davis)\n o Handle rate-limiting for reading on OpenSSL bufferevents correctly. (819b171)\n o Fix serious bugs in per-bufferevent rate-limiting code (34d64f8)\n o Avoid spurious reads from just-created open openssl bufferevents (223ee40)\n o Fix a case where an ssl bufferevent with CLOSE_ON_FREE didn't close its fd (93bb7d8)\n o The corrected bufferevent filter semantics let us fix our openssl tests (34331e4)\n\nTESTING\n o Make SSL tests cover enabling/disabling EV_READ. (a5ce9ad)\n o Bump to the latest version of tinytest (f0bd83e)\n o Unit tests for listener error callbacks (045eef4)\n o New unit test for ssl bufferevents starting with connected SSLs. (02f6259)\n\nDEBUGGABILITY\n o Make debugging output for epoll backend more comprehensive (ec2b05e)\n o Make event.c debugging messages report fds (e119899)\n o Make the --enable-gcc-warnings option include signed comparison warnings (d3b096c)\n\nDEADCODE REMOVAL\n o Remove the now-useless evsig_caught and evsig_process (4858b79)\n o Remove event_base.evsigbase; nothing used it. (38d0960)\n\n\n\nChanges in 2.0.7-rc (9 Sep 2010):\n [Autogenerated from the Git log, sorted and cleaned by hand.]\nNEW APIS\n o Expose a evdns_base_nameserver_sockaddr_add() function to add a nameserver by sockaddr (1952143)\n o Add event_config_set_num_cpus_hint() for tuning win32 IOCP thread pools, etc. (2447fe8 Christopher Davis)\n\nBUGFIXES\n o Fix a nasty dangling-event bug when using rate-limiting groups (0bffe43)\n o Clean up syntax on TAILQ_ENTRY() usage to build correctly with recent MSVC (60433a0 Gilad Benjamini)\n o Make definition of WIN32_LEAN_AND_MEAN in event.h conditional (3920172 Gilad Benjamini)\n o Correctly detect failure to delete bufferevent read-timeout event (da6e7cd)\n o Set close-on-exec bit for filedescriptors created by dns subsystem (d0b8843)\n o Fix kqueue correctness test on x84_64 (6123d12)\n o Detect events with no ev_base; warn instead of crashing (f1074b7)\n o Fix an issue with forking and signal socketpairs in select/poll backends (d61b2f3)\n o Stop using global arrays to implement the EVUTIL_ctype functions (1fdec20)\n o On windows, make lock/thread function tables static (5de2bcb)\n o Close th_notify_fds and open a new pair on reinit (495ed66)\n o Declare signal handler function as \"__cdecl\" on Windows (f0056d0)\n o Use the _func() replacements for open, fstat, etc in evutil.c on win32 (e50c0fc)\n o Only process up to MAX_DEFERRED deferred_cbs at a time (17a14f1 Christopher Davis)\n\nTHREADING BUGFIXES\n o Avoid deadlock when activating signals (970e6ad)\n o Add a condition variable backend, with implementations for pthreads and win32 (d4977b5)\n o Use conditions instead of current_event_lock to fix a deadlock (e0972c2)\n o Fix logic error in win32 TRY_LOCK that caused problems with rate-limiting (4c32b9d)\n o Avoid needlessly calling evthread_notify_base() when the loop is not running (c7a06bf)\n o Minimize calls to base_notify implementation functions, thereby avoiding needless syscalls (4632b78)\n\nIOCP BUGFIXES\n o IOCP-related evbuffer fixes (03afa20 Christopher Davis)\n o Stop IOCP when freeing the event_base (d844242 Christopher Davis)\n o Some IOCP bufferevent tweaks (76f7e7a Christopher Davis)\n\nTESTS\n o Make the regress_pthread.c tests work on windows with current test APIs (d74ae38)\n o Add a unit test for conditions (5fb1095)\n o Allow more than one copy of regression tests to run at once (a97320a)\n o Fix event_del(0) instance in bench.c (b0f284c Shuo Chen)\n o Fix a few memory leaks in the tests (1115366)\n o IOCP-related unit test tweaks (499452f Christopher Davis)\n o Improve testing of when thread-notification occurs (ce85280)\n\nBUILD AND DISTRIBUTION\n o Add pkgconfig files for libevent_{openssl,pthreads} (ebcb1f0)\n o Change include order in Makefile.nmake (4022b28)\n o Make include/event2/event-config.h not included in source dist (a4af9be)\n o Honor NDEBUG; build without warnings with NDEBUG; make NDEBUG always-off in unit test code (743f866)\n o Declare evkeyvalq and event_list even if event_struct.h comes before sys/queue.h (d3ceca8)\n o Move evkeyvalq into a separate header for evhttp_parse_query users (ca9048f)\n o Prefer autoreconf -ivf to manual autogen.sh (7ea8e89)\n\nCLEANUP\n o Completely remove the (mostly-removed) obsolete thread functions (3808168)\n o Rename regress_pthread.c to regress_thread.c (041989f)\n o Make defer-internal.h use lock macros, not direct calls to lock fns (5218d2a)\n\nDOCUMENTATION\n o Document that DNS_NO_SEARCH is an obsolete alias for DNS_QUERY_NO_SEARCH (33200e7)\n o Update the whatsnew-2.0.txt document (4991669)\n\n\n\nChanges in 2.0.6-rc (6 Aug 2010):\n [Autogenerated from the Git log, sorted by hand.]\nDOCUMENTATION\n o Document a change in the semantics of event_get_struct_event_size() (e21f5d1)\n o Add a comment to describe our plan for library versioning (9659ece)\n o Fix sentence fragment in docs for event_get_struct_event_size() (7b259b6)\n\nNEW FEATURES AND INTERFACE CHANGES\n o Remove the obsolete evthread interfaces (c5bab56)\n o Let evhttp_send_error infer the right error reasons (3990669)\n o Add a function to retrieve the other side of a bufferevent pair (17a8e2d)\n o Add bufferevent_lock()/bufferevent_unlock() (215e629)\n o Stop asserting when asked for a (unsupported) TCP dns port. Just return NULL. (7e87a59)\n o Replace (unused,always 0) is_tcp argument to evdns_add_server_port*() with flags (e1c1167)\n o Constify a couple of arguments to evdns_server_request_add_*_reply (cc2379d)\n o Add an interface to expose min_share in ratelimiting groups (6ae53d6)\n\nBUGFIXES\n o Avoid event_del on uninitialized event in event_base_free (6d19510)\n o Add some missing includes to fix Linux build again (75701e8)\n o Avoid close of uninitialized socket in evbuffer unit test (bda21e7)\n o Correctly recognize .255 addresses as link-local when looking for interfaces (8c3452b)\n o If no evdns request can be launched, return NULL, not a handle (b14f151)\n o Use generic win32 interfaces, not ASCII-only ones, where possible. (899b0a3)\n o Fix the default HTTP error template (06bd056 Felix Nawothnig)\n o Close the file in evutil_read_file whether there's an error or not. (0798dd1 Pierre Phaneuf)\n o Fix possible nullptr dereference in evhttp_send_reply_end() (29b2e23 Felix Nawothnig)\n o never let bufferevent_rlim functions return negative (0859870)\n o Make sample/hello_world work on windows (d89fdba)\n o Fix a deadlock related to event-base notification.  Diagnosed by Zhou Li, Avi Bab, and Scott Lamb. (17522d2)\n o Possible fix to 100% cpu usage with epoll and openssl (cf249e7 Mike Smellie)\n o Don't race when calling event_active/event_add on a running signal event (fc5e0a2)\n o Suppress a spurious EPERM warning in epoll.c (e73cbde)\n o Fix wrong size calculation of iovec buffers when exact=1 (65abdc2 niks)\n o Change bufferevent_openssl::do_write so it doesn't call SSL_write with a 0 length buffer (c991317 Mike Smellie)\n o Fixed compilation of sample/le-proxy.c on win32 (13b912e Trond Norbye)\n o Fix rate-limit calculation on openssl bufferevents. (009f300)\n o Remember to initialize timeout events for bufferevent_async (de1f5d6 Christopher Davis)\n\nBUILD AND DISTRIBUTION CHANGES\n o Test the unlocked-deferred callback case of bufferevents (dfb75ab)\n o Remove the now-unusable EVTHREAD_LOCK/UNLOCK constants (fdfc3fc)\n o Use -Wlogical-op on gcc 4.5 or higher (d14bb92)\n o Add the libtool-generated /m4/* stuff to .gitignore (c21c663)\n o Remove some automake-generated files from version control. (9b14911)\n o Have autogen.sh pass --force-missing to automake (8a44062)\n o Set library version for libevent_pthreads correctly (b2d7440)\n o Really only add libevent_core.la to LIBADD on mingw (1425003 Sebastian Hahn)\n o Build more cleanly with NetBSDs that dislike toupper(char) (42a8c71)\n o Fix unit tests with -DUSE_DEBUG enabled (28f31a4)\n o Fix evdns build with -DUNICODE (5fa30d2)\n o Move event-config.h to include/event2 (ec347b9)\n\nTESTING\n o Add options to test-ratelim.c to check its results (2b44dcc)\n o Make test-ratelim clean up after itself better. (b5bfc44)\n o Remove the now-obsolete setup_test() and cleanup_test() functions (e73f1d7)\n o Remove all non-error prints from test/regress.c (8bc1e3d)\n o Make test.sh exit with nonzero status if tests fail (faf2a04)\n o Have the unit tests report errors from test.sh (3689bd2)\n o Fix logic in correcting high values from FIONREAD (3467f2f)\n o Add test for behavior on remote socket close (44d57ee)\n o Unit test for event_get_struct_event_size() (7510aac)\n o Make test/test.sh call test-changelist (7c92691)\n o Fix badly-behaved subtest of dns/bufferevent_connect_hostname (840a72f Joachim Bauch)\n o Add option to test-ratelim to test min_share (42f6b62)\n o Fix an assertion bug in test-ratelim (b2c6202)\n o Make tests quieter on local dns resolver failure (e996b3d)\n o Increase the tolerance in our unit tests for sloppy clocks. (170ffd2)\n o Use AF_INET socketpair to test sendfile on Solaris (9b60209)\n o Make test-changelist count cpu usage right on win32 (ea1ea3d)\n\nINTERNALS, PERFORMANCE, AND CODE CLEANUPS\n o Mark the event_err() functions as __attribute__((noreturn)) (33bbbed)\n o Do not check that event_base is set in EVBASE_ACQUIRE_LOCK (218a3c3)\n o Replace (safe) use of strcpy with memcpy to appease OpenBSD (caca2f4)\n o Remove some dead assignments (47c5dfb)\n o Fix a pedantic gcc 4.4 warning in event2/event.h (276e7ee)\n o Drain th_notify_fd[0] more bytes at a time. (a5bc15b)\n o Tidy up the code in evthread_make_base_notifiable a little (61e1eee)\n o Pass flags to fcntl(F_SETFL) and fcntl(F_SETFD) as int, not long (7c2dea1)\n o Remove unused variables in test/test-changelist.c (b00d4c0)\n o Fix whitespace. (cb927a5)\n o Improve error message for failed epoll to make debugging easier. (9e725f7)\n o Turn our socketpair() replacement into its own function (57b30cd)\n\n\n\nChanges in 2.0.5-beta (10 May 2010):\n [Autogenerated from the Git log, sorted by hand.]\nDOCUMENTATION\n o Update all our copyright notices to say \"2010\" (17efc1c)\n o Add Christopher Clark and Maxim Yegorushkin to the LICENSE file (38b7b57)\n o Clarify Christopher Clark's status as writer of original ht code. (78772c3)\n o Try to comment some of the event code more (cdd4c49)\n o Add a few more evmap/changelist comments (c247adc)\n o Add a comment to explain why evdns_request is now separte from request (ceefbe8)\n o Document evutil_secure_rng_init() and evutil_secure_rng_add_bytes() (a5bf43a)\n o Stop distributing and installing manpages: they were too inaccurate (7731ec8)\n\nNEW FEATURES AND INTERFACE CHANGES\n o Remove signal_assign() and signal_new() macros. (2fac0f7)\n o Make evdns use the regular logging system by default (b2f2be6)\n o Allow evbuffer_read() to split across more than 2 iovecs (e470ad3)\n o Functions to manipulate existing rate limiting groups. (ee41aca)\n o Functions to track the total bytes sent over a rate limit group. (fb366c1)\n o Detect and refuse reentrant event_base_loop() calls (b557b17)\n o Limit the maximum number of events on each socket to 65535 (819f949)\n o Add evbuffer_copyout to copy data from an evbuffer without draining (eb86c8c)\n o Expose the request and reply members of rpc_req_generic() (07edf78 Shuo Chen)\n o Add void* arguments to request_new and reply_new evrpc hooks (755fbf1 Shuo Chen)\n o Seed the RNG using sysctl() as well as /dev/urandom (71fc3eb)\n o Make evutil_secure_rng_init() work even with builtin arc4random (f980716)\n o Report DNS error when lookup fails during bufferevent_socket_connect_hostname. (0ef4070 Christopher Davis)\n o Release locks on bufferevents while executing callbacks (a5208fe Joachim Bauch) o Make debug mode catch mixed ET and non-ET events on an fd (cb67074)\n o Catch attempts to enable debug_mode too late (9ecf0d4)\n o Refuse null keys in evhttp_parse_query() (953e229 Frank Denis)\n\nBUGFIXES\n o Avoid a spurious close(-1) on Linux (70a44b6)\n o Do not close(-1) when freeing an uninitialized socket bufferevent (b34abf3)\n o Free evdns_base->req_heads on evdns_base_free (859af67)\n o Avoid an (untriggerable so far) crash bug in bufferevent_free() (0cf1431)\n o Set mem_offset for every bufferevent type (657d1b6)\n o Fix infrequent memory leak in bufferevent_init_common(). (8398641 Jardel Weyrich)\n o Make evutil_signal_active() match declaration. (e1e703d Patrick Galbraith)\n o Fix minheap code to use replacement malloc functions (a527618)\n o Fix a free(NULL) in minheap-internal.h (6f20492)\n o Fix critical bug in evbuffer_write when writev is not available (cda56ab)\n o Make the no_iovecs case of write_atmost compile (8e227b0)\n o Fix a memory leak when appending/prepending to a buffer with unused space. (45068a3)\n o Clean up a mistake in pointer manipulation in evbuffer_remove (28bfed4 Christopher Davis)\n o Always round up when there's a fractional number of msecs. (8f9e60c Christopher Davis)\n o Fix compiler warnings under WIN32 (d469c50 Giuseppe Scrivano)\n o Clean up properly when adding a signal handler fails. (b84b598 Gilad Benjamini) o Ensure that evdns_request is a persistent handle. (15bb82d Christopher Davis)\n o Free search state when finished searching to avoid an infinite loop. (a625840 Christopher Davis)\n o Assert for valid requests as necessary. (67072f3 Christopher Davis)\n o do not leak the request object on persistent connections (9d8edf2)\n o Make evdns logging threadsafe (b1c7950)\n o Fix a couple of bugs in the BSD sysctl arc4seed logic (a47a4b7)\n o Remove one last bug in last_with_datap logic. Found with valgrind (d49b92a)\n o fix a leak when unpausing evrpc requests (94ee125)\n o Fix a memory leak when unmarshalling RPC object arrays (f6ab2a2)\n o Fix compilation when openssl support is disabled (40c301b)\n o Allow empty reason line in HTTP status (739e688 Pierre Phaneuf)\n o Fix a compile warning introduced in 739e688 (bd1ed5f Sebastian Hahn)\n o Fix nonstandard TAILQ_FOREACH_REVERSE() definition (71afc52 Frank Denis)\n o Try /proc on Linux as entropy fallback; use sysctl as last resort (20fda29)\n o Fix symbol conflict between mm_*() macros and libmm (99e50e9)\n o Fix some crazy macro mistakes in arc4random.c (90d4225)\n o Make evbuffer_add_file() work on windows (dcdae6b)\n o Fix unused-variable warning when building with threads disabled (ad811cd)\n o Numerous opensolaris compilation fixes (c44de06)\n o Fix getaddrinfo with protocol unset on Solaris 9. Found by Dagobert Michelsen (2cf2a28)\n o Fix another nasty solaris getaddrinfo() behavior (3557071)\n o Define _REENTRANT as needed on Solaris, elsewhere (c1cd32a)\n o Fix some autoconf issues on OpenBSD (7c519df)\n\nBUILD AND DISTRIBUTION CHANGES\n o Distribute libevent.pc.in, not libevent.pc (22aff04)\n o Avoid errors in evutil.c when building with _UNICODE defined (b677032 Brodie Thiesfield)\n o Avoid errors in http.c when building with VC 2003 .NET (13e4f3b Brodie Thiesfield)\n o Support the standard 'make check' target in place of 'make verify' (426c8fb)\n o Remove redundant stuff from EXTRA_DIST (b660edf)\n o Switch to using AM conditionals in place of AC_LIBOBJ (2e898f5)\n o Remove an orphaned RELEASE flag in Makefile.am (0794b0d)\n o Give a better warning for bad automake versions. (77c917d)\n o Use dist_bin_SCRIPTS, not EXTRA_DIST, to distribute scripts (9eb2fd7)\n o Never test for select() on windows (3eb044d Trond Norbye)\n o Do not inhibit automake dependencies generation (10c4c90 Giuseppe Scrivano)\n o Create shared libraries under Windows (3cbca86 Giuseppe Scrivano)\n o Add ctags/etags files to .gitignore (0861d17)\n o Only specify -no-undefined on mingw (25433b9)\n o Only add libevent_core.la to LIBADD on mingw (fdc6297)\n\nTESTING\n o Get bench_http to work on Windows; add a switch to enable IOCP. (4ac38a5 Christopher Davis)\n o VC has no getopt(), so do without in bench_http. (1273d2f Christopher Davis)\n o Fix an obnoxious typo in the bufferevent_timeout_filter test (0d047c3)\n o Fix a write of uninitialized RAM in regression tests (68dc742)\n o Fix some memory leaks in the unit tests (274a7bd)\n o Make 'main/many_events' test 70 fds, not 64. (33874b0)\n o Unit-test every evbuffer_add_file() implementation. (06a4443)\n o Add more unit tests for evbuffer_expand (8c83e99)\n o Test another case of evbuffer_prepend (1234b95)\n o Fix a possible double-free bug in SSL bufferevents with CLOSE_ON_FREE (7501895) o Add dns/search_cancel unit test. (39b870b Christopher Davis)\n o Make http_base_test stop leaking an event_base. (96730d3)\n o Detect broken unsetenv at unit-test runtime (f37cd4c)\n o Implement regress_make_tempfile on win32 to test evbuffer_add_file (b4f12a1)\n o add more (currently skipped) add_file tests on win32 (05de45d)\n o Fix bench_http build on win32. (384d124)\n o Make unit test for add_file able to tell \"error\" from \"done\" (88a543f)\n o Make test for bufferevent_connect_hostname system-neutral (f89168e)\n o Make test.sh support mingw/msys on win32 (0ee6f6c)\n o Fix test.sh on freebsd (3d9e05b)\n\nINTERNALS, PERFORMANCE, AND AND CODE CLEANUPS\n o Improve the speed of evbuffer_readln() (cc1600a)\n o more whitespace normalization (2c2618d)\n o Revise evbuffer to add last_with_data (2a6d2a1)\n o Use last_with_data in place of previous_to_last (c8ac57f)\n o Remove previous_to_last from evbuffer (6f47bd1)\n o Fix last_with_data compilation on windows (1e7b986)\n o Add some glass-box tests for the last_with_data code. (17da042)\n o Improve robustness for refcounting (f1bc125)\n o Remove a needless min_heap_shift_up_() call (7204b91)\n o Increase MIN_BUFFER_SIZE to 512 (1024 on 64-bit) (2014ae4)\n o Do not use evbuffer_expand() to add the first chain to a buffer (5c0ebb3)\n o Make evbuffer_prepend handle empty buffers better (c87272b)\n o Replace last_with_data with a slightly smarter version (b7442f8)\n o Turn the increasingly complex *_CHAIN() macros into functions (96865c4)\n o Rewrite evbuffer_expand and its users (d5ebcf3)\n o Add evutil_tv_to_msec for safe conversion of timevals to milliseconds. (850c3ff Christopher Davis)\n o Initialize last_with_datap correctly in evbuffer_overlapped (a0983b6)\n o Replace EVUTIL_CLOSESOCKET macro with a function (899c1dc Sebastian Sjöberg)\n o Move domain search state to evdns_request. (beaa14a Christopher Davis)\n o Remove redundant checks for lock!=NULL before calling EVLOCK_LOCK (50ec59f)\n o Rename current_base symbol to event_global_current_base_ (c16e684)\n o Fix whitespace in evutil.c (935e150)\n o Replace users of \"int fd\" with \"evutil_socket_t fd\" in portable code (c7cf6f0)\n\n\n\nChanges in 2.0.4-alpha (28 Feb 2010):\n [Autogenerated from the Git log, sorted by hand.]\nDOCUMENTATION\n o Add stub header for 2.0.4-alpha changelog. (94d0065)\n o Improve the README with more information and links. (0b42726)\n o Add more people who wrote patches to the acknowledgments (0af10d5)\n o Add a warning about the use of event_initialized. (f32b575)\n o Add a LICENSE file so people can find our license easily (7067006)\n o Add a new \"hello world\" sample program (becb9f9)\n o Clarify status of example programs (d60a1bd)\n o Update time-test.c to use event2 (f4190bf)\n o Add the arc4random.c license to the LICENSE file. (e15e1e9)\n\nNEW FEATURES AND INTERFACE CHANGES\n o Improved optional lock debugging. (0cd3bb9)\n o Rate-limiting for bufferevents; group and individual limits are supported. (737c9cd)\n o Testing code for bufferevent rate-limiting. (f0c0124)\n o Make the initial nameserver probe timeout configurable. (1e56a32)\n o Revise the locking API: deprecate the old locking callbacks and add trylock. (347952f)\n o Do not make bufferevent_setfd implicitly disable EV_READ and EV_WRITE. (8274379)\n o Do not ignore bufferevent_enable(EV_READ) before bufferevent_connect(). (4a5b534)\n o Introduced evutil_make_socket_closeonexec() to preserve fd flags for F_SETFD. (d0939d2 Jardel Weyrich)\n o evdns_getaddrinfo() now supports the /etc/hosts file. (72dd666)\n o Look at the proper /etc/hosts file on windows. (66c02c7)\n o Allow http connections to use evdns for hostname looksups. (c698b77)\n o Changelist code to defer event changes until just before dispatch (27308aa)\n o do not use a function to assign the evdns base; instead assign it via evhttp_connection_base_new() which is a new function introduced in 2.0 (5032e52)\n o Functions to access more fields of struct event. (0683950)\n o Make kqueue use changelists. (45e5ae3)\n o Remove kqueue->pend_changes. (3225dfb)\n o Minimize epoll_ctl calls by using changelist (c8c6a89)\n o Add support for a \"debug mode\" to try to catch common errors. (cd17c3a)\n o Note a missing ratelim function (361da8f)\n o Add ev_[u]intptr_t to include/event2/util.h (1fa4c81)\n o const-ify a few more functions in event.h (d38a7a1)\n o Deprecate EVENT_FD and EVENT_SIGNAL. (f6b2694)\n o Remove EVUTIL_CHECK_FMT. (6c21c89)\n o Add EV_*_MAX macros to event2/util.h to expose limits for ev_* types. (aba1fff) o Functions to view and manipulate rate-limiting buckets. (85047a6)\n o Add the rest of the integer limits, and add a test for them. (60742d5)\n o Remove the 'flags' argument from evdns_base_set_option() (1dd7e6d)\n o Add an arc4random implementation for use by evdns (d4de062)\n o Use off_t for the length parameter of evbuffer_add_file (3fe60fd)\n o Construct Windows locks using InitializeCriticalSectionAndSpinCount (32c6f1b)\n o Expose view of current rate limit as constrained by group limit (162ce8a)\n o Provide consistent, tested semantics for bufferevent timeouts (d328829)\n\nBUGFIXES AND TESTS\n o Tolerate code that returns from a fatal_cb. (91fe23f)\n o Parenthesize macro arguments more aggressively (07e9e9b)\n o Fix memory-leak of signal handler array with kqueue. (e1ffbb8)\n o Stop passing EVTHREAD_READ and EVTHREAD_WRITE to non-rw locks. (76cd2b7)\n o Fix two use-after-free bugs in unit tests spoted by lock debugging (d84d838)\n o Fix a locking bug in event_base_loop() (da1718b)\n o Fix an evdns lock violation. (2df1f82 Zhuang Yuyao)\n o Valgrind fix: Clear struct kevent before checking for OSX bug. (56771a3 William Ahern)\n o Fix up evthread compilation on windows (bd6f1ba Roman Puls)\n o Fix regress_iocp.c usage of old lock allocation macros. (31687b4 unknown)\n o Update nmake makefile to build evthread.c (b62d979 unknown)\n o Fix a crash when reading badly formatted resolve.conf; from Yasuoka Masahiko (6c7c579 Yasuoka Masahiko)\n o Fix a snow leopard compile warning in the unit tests. (7ae9445)\n o Fix compile on Snow Leopard with gcc warnings enabled (70cdfe4 Sebastian Hahn)\n o Only define _GNU_SOURCE if it is not already defined. (ea6b1df Joachim Bauch)\n o Update sample/signal-test.c to use newer APIs and not leak. (f6430ac Evan Jones)\n o Fix a segfault when writing a very fragmented evbuffer onto an SSL (a6adeca Joachim Bauch)\n o Fix a segfault when freeing SSL bufferevents in an unusual order (a773df5 Joachim Bauch)\n o Drop install-sh from our git repo: a mismatched version could break \"make dist\" (6799527)\n o Set all instances of the version number correctly. (5a112d3)\n o Fix a few locking issues on windows. (c51bb3c unknown)\n o Use evutil_socket_t, not int, when logging socket errors. (292467c)\n o Fix up behavior of never-defered callbacks a little (390e056)\n o Replace some cases of uint32_t with ev_uint32_t. (a47d88d)\n o Fix compilation of devpoll.c by adding missing thread includes. (fee2c77 Dagobert Michelsen)\n o Make evutil_make_socket_nonblocking() leave any other flags alone. (4c8b7cd Jardel Weyrich)\n o Fix an fd leak in evconnlistener_new_bind(). (24fb502 Jardel Weyrich)\n o Fix a bogus free in evutil_new_addrinfo() (0d64051 Jardel Weyrich)\n o Adjusted fcntl() retval comparison on evutil_make_socket_nonblocking(). (4df7dbc Jardel Weyrich)\n o Fix the code that allowed DNS options to not end with : (ee4953f)\n o Fix crash bugs when a bufferevent's eventcb is not set. (2e8eeea)\n o Fix test-ratelim compilation on Linux. (885b427)\n o Fix compilation of rate-limiting code on win32. (165d30e)\n o Eradicated the last free() call. Let mm_free() take care of deallocation. (0546ce1 Jardel Weyrich)\n o Fix byte counts when mixing deferred and non-deferred evbuffer callbacks. (29151e6)\n o Fixed a memory leak on windows threads implementation. The CRITICAL_SECTION was not being free'd in evthread_win32_lock_free(). (2f33e00 Jardel Weyrich)\n o Fixed a fd leak in start_accepting(), plus cosmetic changes (4367a33 Jardel Weyrich)\n o Improved error handling in evconnlistener_new_async(). Also keeping the fd open because it is not opened by this function, so the caller is responsible for closing it. Additionally, since evconnlistener_new_bind() creates a socket and passes it to the function above, it required error checking to close the same socket. (fec66f9 Jardel Weyrich)\n o Don't use a bind address for nameservers on loopback (8d4aaf9)\n o Fix compilation of rate-limit code when threading support is disabled (97a8c79)\n o Detect setenv/unsetenv; skip main/base_environ test if we can't fake them. (7296971)\n o Check more internal event_add() calls for failure (ff3f6cd)\n o Fix windows and msvc build (5c7a7bc)\n o Call event_debug_unassign on internal events (a19b4a0)\n o Try to fix a warning in hash_debug_entry (137f2c6)\n o Fix a dumb typo in ev_intptr_t definitions. (27c9a40)\n o do not fail while sending on http connections the client closed. (93d7369)\n o make evhttp_send() safe against terminated connections, too (3978180)\n o Make Libevent 1.4.12 build on win32 with Unicode enabled. (000a33e Brodie Thiesfield)\n o Fix some additional -DUNICODE issues on win32. (a7a9431)\n o Add a check to make soure our EVUTIL_AI flags do not conflict with the native ones (c18490e)\n o Always use our own gai_strerror() replacement. (6810bdb)\n o Make RNG work when we have arc4random() but not arc4random_buf() (4ec8fea)\n o validate close cb on server when client connection closes (2f782af)\n o Fix two unlocked reads in evbuffer. (7116bf2)\n o When working without a current event base, don't try to use IOCP listeners (cb52838)\n o Fix getpid() usage on Windows (ff2a134)\n o Add a unit test for secure rng. (48a29b6)\n o Add some headers to fix freebsd compilation (b72be50)\n o When connect() succeeds immediately, don't invoke the callback immediately. (7515de9)\n o Suspend read/write on bufferevents during hostname lookup (db08f64)\n o Make bufferevent_free() clear all callbacks immediately. (b2fbeb3)\n o Fix some race conditions in persistent events and event_reinit (e2642f0)\n o Fix a bug in resetting timeouts on persistent events when IO triggers. (38ec0a7)\n o Add a test for timeouts on filtering bufferevents. (c02bfe1)\n o Add test for periodic timers that get activated for other reasons (8fcb7a1)\n o Use new timeval diff comparison function in bufferevent test (f3dfe46)\n o Delete stack-alloced event in new unit test before returning. (7ffd387)\n o Fix mingw compilation (23170a6)\n o Try to define a sane _EVENT_SIZEOF_SIZE_T for msvc compilation (1e14f82)\n o Fix arc4random compilation on MSVC. (98edb89)\n o deal with connect() failing immediately (7bc48bf)\n o Small cleanups on freebsd-connect-refused patch. (57b7248)\n\nBUILD AND DISTRIBUTION CHANGES\n o Remove the contents of WIN32-Prj as unmaintained. (c69d5a5)\n o Allow the user to redirect the verbose output of test/test.sh to a file (c382de6)\n o Allow test.sh to be run as ./test/test.sh (7dfbe94)\n o Never believe that we have pthreads on win32, even if gcc thinks we do. (78ed097)\n o Make it compile under gcc --std=c89. (e2ca403)\n o Fix a number of warnings from gcc -pedantic (918e9c5)\n o Add the msvc-generated .lib files to .gitignore. (e244a2e)\n o Add the \"compile\" script to gitignore. (1ba6bed)\n\nINTERNALS AND CODE CLEANUPS\n o Add a .gitignore file. (ba34071)\n o New EVTHREAD_TRY_LOCK function to try to grab a lock. (689fc09)\n o Add the ability to mark some buffer callbacks as never-deferred. (438f9ed)\n o Refactor our 'suspend operation' logic on bufferevents. (0d744aa)\n o Simplify the read high-watermark checking. (5846bf6)\n o Improve readability of evutil_unparse_protoname() (5a43df8 Jardel Weyrich)\n o Expose our cached gettimeofday value with a new interface (47854a8)\n o Whitespace fixes in test.sh (0b151a9)\n o Enable branch-prediction hints with EVUTIL_UNLIKELY. (eaaf27f)\n o Refactor code from evdns into a new internal \"read a file\" function. (0f7144f)\n o Cosmetic changes in evconnlistener_new(), new_accepting_socket(), accepted_socket_invoke_user_cb() and iocp_listener_enable(). (510ab6b Jardel Weyrich)\n o Add unit-test for bad_request bug fixed in 1.4 recently. (6cc79c6 Pavel Plesov) o Add a comment on evthread_enable_lock_debuging. (b9f43b2)\n o Fix test.sh on shells without echo -n (94131e9)\n o More unit tests for getaddrinfo_async: v4timeout and cancel. (a334b31)\n o Make http use evconnlistener. (ec34533)\n o move dns utility functions into a separate file so that we can use them for http testing (b822639)\n o add a test for evhttp_connection_base_new with a dns_base (26714ca)\n o forgot to add void to test function (78a50fe)\n o Add a forgotten header (changelist-internal.h) (4b9f307)\n o Remove some commented-out code in evutil (26e1b6f)\n o Remove a needless include of rpc_compat.h (70a4a3e)\n o Use less memory for each entry in a hashtable (a66e947)\n o Try to untangle the logic in server_port_flush(). (439aea0)\n o Use ev_[u]intptr_t types in place of [u]intptr_t (cef61a2)\n o Reduce windows header includes in our own headers. (da6135e)\n o clean up terminate_chunked test (e8a9782)\n o Increment the submicro version number. (63e868e)\n o Update event-config.h version number to match configure.in (aae7db5)\n o Clean up formatting: Disallow space-before-tab. (8fdf09c)\n o Clean up formatting: use tabs, not 8-spaces, to indent. (e5bbd40)\n o Clean up formatting: remove trailing spaces (e5cf987)\n o Clean up formatting: function/keyword spacing consistency. (4faeaea)\n\n\n\nChanges in 2.0.3-alpha (20 Nov 2009):\n o Add a new code to support SSL/TLS on bufferevents, using the OpenSSL library (where available).\n o Fix a bug where we didn't allocate enough memory in event_get_supported_methods().\n o Avoid segfault during failed allocation of locked evdns_base. (Found by Rocco Carbone.)\n o Export new evutil_ascii_* functions to perform locale-independent character type operations.\n o Try to compile better with MSVC: patches from Brodie Thiesfield\n o New evconnlistener_get_fd function to expose a listener's associated socket.\n o Expose an ev_socklen_t type for consistent use across platforms.\n o Make bufferevent_socket_connect() work when the original fd was -1.\n o Fix a bug in bufferevent_socket_connect() when the connection succeeds too quickly.\n o Export an evutil_sockaddr_cmp() to compare to sockaddr objects for equality.\n o Add a bufferevent_get_enabled() to tell what a bufferevent has been configured to do.\n o Add an evbuffer_search_eol() function to locate the end of a line nondestructively.\n o Add an evbuffer_search_range() function to search a bounded range of a buffer.\n o Fix a rare crash bug in evdns.\n o Have bufferevent_socket_connect() with no arguments put a bufferevent into connecting mode.\n o Support sendfile on Solaris: patch from Caitlin Mercer.\n o New functions to explicitly reference a socket used by an evhttp object. Patches from David Reiss.\n o When we send a BEV_EVENT_CONNECTED to indicate connected status, we no longer invoke the write callback as well unless we actually wrote data too.\n o If the kernel tells us that there are a negative number of bytes to read from a socket, do not believe it.  Fixes bug 2841177; found by Alexander Pronchenkov.\n o Do not detect whether we have monotonic clock support every time a new event base is created: instead do it only once.  Patch taken from Chromium.\n o Do not allocate the maximum event queue for the epoll backend at startup.  Instead, start out accepting 32 events at a time, and double the queue's size when it seems that the OS is generating events faster than we're requesting them.  Saves up to 374K per epoll-based event_base.  Resolves bug 2839240.\n o Treat an event with a negative fd as valid but untriggerable by Libevent.  This is useful for applications that want to manually activate events.\n o Fix compilation on Android, which forgot to define fd_mask in its sys/select.h\n o Do not drop data from evbuffer when out of memory; reported by Jacek Masiulaniec\n o New event_base_got_exit() and event_base_got_break() functions to tell whether an event loop exited because of an event_base_loopexit() or an event_base_loopbreak().  Patch from Ka-Hing Cheung.\n o When adding or deleting an event from a non-main thread, only wake up the main thread when its behavior actually needs to change.\n o Fix some bugs when using the old evdns interfaces to initialize the evdns module.\n o Detect errors during bufferevent_connect().  Patch from Christopher Davis.\n o Fix compilation for listener.h for C++ - missing extern \"C\".  Patch from Ferenc Szalai.\n o Make the event_base_loop() family of functions respect thread-safety better.  This should clear up a few hard-to-debug race conditions.\n o Fix a bug when using a specialized memory allocator on win32.\n o Have the win32 select() backend label TCP-socket-connected events as EV_WRITE, not EV_READ.  This should bring it in line with the other backends, and improve portability.  Patch from Christopher Davis.\n o Stop using enums as arguments or return values when what we mean is a bitfield of enum values.  C++ doesn't believe that you can OR two enum values together and get another enum, and C++ takes its typing seriously.  Patch from Christopher Davis.\n o Add an API to replace all fatal calls to exit() with a user-provided panic function.\n o Replace all assert() calls with a variant that is aware of the user-provided logging and panic functions.\n o Add a return value to event_assign so that it can fail rather than asserting when the user gives it bad input.  event_set still dies on bad input.\n o The event_base_new() and event_base_new_with_config() functions now never call exit() on failure.  For backward \"compatibility\", event_init() still does, but more consistently.\n o Remove compat/sys/_time.h.  It interfered with system headers on HPUX, and its functionality has been subsumed by event2/util.h and util-internal.h.\n o Add a new bufferevent_socket_connect_hostname() to encapsulate the resolve-then-connect operation.\n o Build kqueue.c correctly on GNU/kFreeBSD platforms. Patch pulled upstream from Debian.\n o Alternative queue-based timeout algorithm for programs that use a large number of timeouts with the same value.\n o New event_base_config option to disable the timeval cache entirely.\n o Make EV_PERSIST timeouts more accurate: schedule the next event based on the scheduled time of the previous event, not based on the current time.\n o Allow http.c to handle cases where getaddrinfo returns an IPv6 address.  Patch from Ryan Phillips.\n o Fix a problem with excessive memory allocation when using multiple event priorities.\n o Default to using arc4random for DNS transaction IDs on systems that have it; from OpenBSD.\n o Never check the environment when we're running setuid or setgid; from OpenBSD.\n o Options passed to evdns_set_option() no longer need to end with a colon.\n o Add an evutil_getaddrinfo() function to clone getaddrinfo on platforms that don't have it.\n o Add an evdns_getaddrinfo() function to provide a nonblocking getaddrinfo using evdns, so programs can perform useful hostname lookup.\n o Finally expose the IOCP-based bufferevent backend.  It passes its unit tests, but probably still has some bugs remaining.  Code by Nick Mathewson and Christopher Davis.\n o Numerous other bugfixes.\n o On FreeBSD and other OSes, connect can return ECONREFUSED immediately; instead of failing the function call, pretend with faileld in the callback.\n o Fix a race condition in the pthreads test case; found by Nick Mathewson\n o Remove most calls to event_err() in http and deal with memory errors instead\n\n\n\nChanges in 2.0.2-alpha (25 Jul 2009):\n o Add a new flag to bufferevents to make all callbacks automatically deferred.\n o Make evdns functionality locked, and automatically defer dns callbacks.\n o Fix a possible free(NULL) when freeing an event_base with no signals.\n o Add a flag to disable checking environment variables when making an event_base\n o Disallow setting less than 1 priority.\n o Fix a bug when removing a timeout from the heap. [Patch from Marko Kreen]\n o Use signal.h, not sys/signal.h. [Patch from mmadia]\n o Try harder to build with certain older c99 compilers.\n o Make sure that an event_config's flags field is always initialized to 0. [Bug report from Victor Goya]\n o Avoid data corruption when reading data entirely into the second-to-last chain of an evbuffer. [Bug report from Victor Goya]\n o Make sendfile work on FreeBSD\n o Do not use vararg macros for accessing evrpc structures; this is not backwards compatible, but we did not promise any backwards compatibility for the rpc code.\n o Actually define the event_config_set_flag() function.\n o Try harder to compile with Visual C++.\n o Move event_set() and its allies to event2/event_compat.h where they belong.\n o Remove the event_gotsig code, which has long been deprecated and unused.\n o Add an event_get_base() function to return the base assigned to an event.\n o New function to automate connecting on a socket-based bufferevent.\n o New functions to automate listening for incoming TCP connections.\n o Do case-insensitive checks with a locale-independent comparison function.\n o Rename the evbuffercb and everrorcb callbacks to bufferevent_data_cb and bufferevent_event_cb respectively.  The old names are available in bufferevent_compat.h.\n o Rename the EVBUFFER_* codes used by bufferevent event callbacks to BEV_EVENT_*, to avoid namespace collision with evbuffer flags.  The old names are available in bufferevent_compat.h.\n o Move the EVBUFFER_INPUT and EVBUFFER_OUTPUT macros to bufferevent_compat.h\n o Add a bufferevent_getfd() function to mirror bufferevent_setfd()\n o Make bufferevent_setfd() return an error code if the operation is not successful.\n o Shave 22 bytes off struct event on 32-bit platforms by shrinking and re-ordering fields.  The savings on 64-bit platforms is likely higher.\n o Cap the maximum number of priorities at 256.\n o Change the semantics of evbuffer_cb_set_flags() to be set-flag only; add a new evbuffer_cb_clear_flags() to remove set flags.\n o Change the interface of evbuffer_add_reference so that the cleanup callback gets more information\n o Revise the new evbuffer_reserve_space/evbuffer_commit_space() interfaces so that you can use them without causing extraneous copies or leaving gaps in the evbuffer.\n o Add a new evbuffer_peek() interface to inspect data in an evbuffer without removing it.\n o Fix a deadlock when suspending reads in a bufferevent due to a full buffer. (Spotted by Joachim Bauch.)\n o Fix a memory error when freeing a thread-enabled event base with registered events. (Spotted by Joachim Bauch.)\n o Try to contain degree of failure when running on a win32 version so heavily firewalled that we can't fake a socketpair.\n o Activate fd events in a pseudorandom order with O(N) backends, so that we don't systematically favor low fds (select) or earlier-added fds (poll, win32).\n o Replace some read()/write() instances with send()/recv() to work properly on win32.\n o Set truncated flag correctly in evdns server replies.\n o Raise RpcGenError in event_rpcgen.py; from jmanison and Zack Weinberg\n o Fix preamble of rpcgen-generated files to rely on event2 includes; based on work by jmansion; patch from Zack Weinberg.\n o Allow specifying the output filename for rpcgen; based on work by jmansion; patch from Zack Weinberg.\n o Allow C identifiers as struct names; allow multiple comments in .rpc files; from Zack Weinberg\n o Mitigate a race condition when using socket bufferevents in multiple threads.\n o Use AC_SEARCH_LIBS, not AC_CHECK_LIB to avoid needless library use.\n o Do not allow event_del(ev) to return while that event's callback is executing in another thread.  This fixes a nasty race condition.\n o event_get_supported_methods() now lists methods that have been disabled with the EVENT_NO* environment options.\n o Rename encode_int[64] to evtag_encode_int[64] to avoid polluting the global namespace.  The old method names are still available as macros in event2/tag_compat.h.\n\n\n\nChanges in 2.0.1-alpha (17 Apr 2009):\n o free minheap on event_base_free(); from Christopher Layne\n o debug cleanups in signal.c; from Christopher Layne\n o provide event_base_new() that does not set the current_base global\n o bufferevent_write now uses a const source argument; report from Charles Kerr\n o improve documentation on event_base_loopexit; patch from Scott Lamb\n o New function, event_{base_}loopbreak.  Like event_loopexit, it makes an event loop stop executing and return.  Unlike event_loopexit, it keeps subsequent pending events from getting executed.  Patch from Scott Lamb\n o Check return value of event_add in signal.c\n o provide event_reinit() to reintialize an event_base after fork\n o New function event_set_mem_functinons.  It allows the user to give libevent replacement functions to use for memory management in place of malloc(), free(), etc.  This should be generally useful for memory instrumentation, specialized allocators, and so on.\n o The kqueue implementation now catches signals that are raised after event_add() is called but before the event_loop() call.  This makes it match the other implementations.\n o The kqueue implementation now restores original signal handlers correctly when its signal events are removed.\n o Check return value of event_add in signal.c\n o Add a more powerful evbuffer_readln as a replacement for evbuffer_readline.  The new function handles more newline styles, and is more useful with buffers that may contain a nul characters.\n o Do not mangle socket handles on 64-bit windows.\n o The configure script now takes an --enable-gcc-warnings option that turns on many optional gcc warnings.  (Nick has been building with these for a while, but they might be useful to other developers.)\n o move EV_PERSIST handling out of the event backends\n o small improvements to evhttp documentation\n o always generate Date and Content-Length headers for HTTP/1.1 replies\n o set the correct event base for HTTP close events\n o When building with GCC, use the \"format\" attribute to verify type correctness of calls to printf-like functions.\n o Rewrite win32.c backend to be O(n lg n) rather than O(n^2).\n o Removed obsoleted recalc code\n o support for 32-bit tag numbers in rpc structures; this is wire compatible, but changes the API slightly.\n o pull setters/getters out of RPC structures into a base class to which we just need to store a pointer; this reduces the memory footprint of these structures.\n o prefix {encode,decode}_tag functions with evtag to avoid collisions\n o fix a bug with event_rpcgen for integers\n o Correctly handle DNS replies with no answers set (Fixes bug 1846282)\n o add -Wstrict-aliasing to warnings and more cleanup\n o removed linger from http server socket; reported by Ilya Martynov\n o event_rpcgen now allows creating integer arrays\n o support string arrays in event_rpcgen\n o change evrpc hooking to allow pausing of RPCs; this will make it possible for the hook to do some meaning ful work; this is not backwards compatible.\n o allow an http request callback to take ownership of a request structure\n o allow association of meta data with RPC requests for hook processing\n o associate more context for hooks to query such as the connection object\n o remove pending timeouts on event_base_free()\n o also check EAGAIN for Solaris' event ports; from W.C.A. Wijngaards\n o devpoll and evport need reinit; tested by W.C.A Wijngaards\n o event_base_get_method; from Springande Ulv\n o Send CRLF after each chunk in HTTP output, for compliance with RFC2626.  Patch from \"propanbutan\".  Fixes bug 1894184.\n o Add a int64_t parsing function, with unit tests, so we can apply Scott Lamb's fix to allow large HTTP values.\n o Use a 64-bit field to hold HTTP content-lengths.  Patch from Scott Lamb.\n o Allow regression code to build even without Python installed\n o remove NDEBUG ifdefs from evdns.c\n o detect integer types properly on platforms without stdint.h\n o udpate documentation of event_loop and event_base_loop; from Tani Hosokawa.\n o simplify evbuffer by removing orig_buffer\n o do not insert event into list when evsel->add fails\n o add support for PUT/DELETE requests; from Josh Rotenberg\n o introduce evhttp_accept_socket() to accept from an already created socket\n o include Content-Length in reply for HTTP/1.0 requests with keep-alive\n o increase listen queue for http sockets to 128; if that is not enough the evhttp_accpet_socket() api can be used with a prepared socket.\n o Patch from Tani Hosokawa: make some functions in http.c threadsafe.\n o test support for PUT/DELETE requests; from Josh Rotenberg\n o rewrite of the evbuffer code to reduce memory copies\n o Some older Solaris versions demand that _REENTRANT be defined to get strtok_r(); do so.\n o Do not free the kqop file descriptor in other processes, also allow it to be 0; from Andrei Nigmatulin\n o Provide OpenSSL style support for multiple threads accessing the same event_base\n o make event_rpcgen.py generate code include event-config.h; reported by Sam Banks.\n o switch thread support so that locks get allocated as they are needed.\n o make event methods static so that they are not exported; from Andrei Nigmatulin\n o make RPC replies use application/octet-stream as mime type\n o do not delete uninitialized timeout event in evdns\n o Correct the documentation on buffer printf functions.\n o Don't warn on unimplemented epoll_create(): this isn't a problem, just a reason to fall back to poll or select.\n o Correctly handle timeouts larger than 35 minutes on Linux with epoll.c.  This is probably a kernel defect, but we'll have to support old kernels anyway even if it gets fixed.\n o Make name_from_addr() threadsafe in http.c\n o Add new thread-safe interfaces to evdns functions.\n o Make all event_tagging interfaces threadsafe.\n o Rename internal memory management functions.\n o New functions (event_assign, event_new, event_free) for use by apps that want to be safely threadsafe, or want to remain ignorant of the contents of struct event.\n o introduce bufferevent_read_buffer; allows reading without memory copy.\n o expose bufferevent_setwatermark via header files and fix high watermark on read\n o fix a bug in buffrevent read water marks and add a test for them\n o fix a bug in which bufferevent_write_buffer would not schedule a write event\n o provide bufferevent_input and bufferevent_output without requiring knowledge of the structure\n o introduce bufferevent_setcb and bufferevent_setfd to allow better manipulation of bufferevents\n o convert evhttp_connection to use bufferevents.\n o use libevent's internal timercmp on all platforms, to avoid bugs on old platforms where timercmp(a,b,<=) is buggy.\n o Remove the never-exported, never-used evhttp_hostportfile function.\n o Support input/output filters for bufferevents; somewhat similar to libio's model.  This will allow us to implement SSL, compression, etc, transparently to users of bufferevents such as the http layer.\n o allow connections to be removed from an rpc pool\n o add new evtimer_assign, signal_assign, evtimer_new, and signal_new functions to manipulate timer and signal events, analagous to the now-recommended event_assign and event_new\n o switch internal uses of event_set over to use event_assign.\n o introduce evbuffer_contiguous_space() api that tells a user how much data is available in the first buffer chain\n o introduce evbuffer_reserve_space() and evbuffer_commit_space() to make processing in filters more efficient.\n o reduce system calls for getting current time by caching it.\n o separate signal events from io events; making the code less complex.\n o support for periodic timeouts\n o support for virtual HTTP hosts.\n o turn event_initialized() into a function, and add function equivalents to EVENT_SIGNAL and EVENT_FD so that people don't need to include event_struct.h\n o Build test directory correctly with CPPFLAGS set.\n o Provide an API for retrieving the supported event mechanisms.\n o event_base_new_with_config() and corresponding config APIs.\n o migrate the evhttp header to event2/ but accessors are still missing.\n o deprecate timeout_* event functions by moving them to event_compat.h\n o Move\twindows gettimeofday replacement into a new evutil_gettimeofday().\n o Make configure script work on IRIX.\n o provide a method for canceling ongoing http requests.\n o Make vsnprintf() returns consistent on win32.\n o Fix connection keep-alive behavior for HTTP/1.0\n o Fix use of freed memory in event_reinit; pointed out by Peter Postma\n o constify struct timeval * where possible\n o make event_get_supported_methods obey environment variables\n o support for edge-triggered events on epoll and kqueue backends: patch from Valery Kholodkov\n o support for selecting event backends by their features, and for querying the features of a backend.\n o change failing behavior of event_base_new_with_config: if a config is provided and no backend is selected, return NULL instead of aborting.\n o deliver partial data to request callbacks when chunked callback is set even if there is no chunking on the http level; allows cancelation of requests from within the chunked callback; from Scott Lamb.\n o allow min_heap_erase to be called on removed members; from liusifan.\n o Rename INPUT and OUTPUT to EVRPC_INPUT and EVRPC_OUTPUT.  Retain INPUT/OUTPUT aliases on on-win32 platforms for backwards compatibility.\n o Do not use SO_REUSEADDR when connecting\n o Support 64-bit integers in RPC structs\n o Correct handling of trailing headers in chunked replies; from Scott Lamb.\n o Support multi-line HTTP headers; based on a patch from Moshe Litvin\n o Reject negative Content-Length headers; anonymous bug report\n o Detect CLOCK_MONOTONIC at runtime for evdns; anonymous bug report\t\n o Various HTTP correctness fixes from Scott Lamb\n o Fix a bug where deleting signals with the kqueue backend would cause subsequent adds to fail\n o Support multiple events listening on the same signal; make signals regular events that go on the same event queue; problem report by Alexander Drozdov.\n o Fix a problem with epoll() and reinit; problem report by Alexander Drozdov.\t\n o Fix off-by-one errors in devpoll; from Ian Bell\n o Make event_add not change any state if it fails; reported by Ian Bell.\n o Fix a bug where headers arriving in multiple packets were not parsed; fix from Jiang Hong; test by me.\n o Match the query in DNS replies to the query in the request; from Vsevolod Stakhov.\n o Add new utility functions to correctly observe and log winsock errors.\n o Do not remove Accept-Encoding header\n o Clear the timer cache on entering the event loop; reported by Victor Chang\n o Only bind the socket on connect when a local address has been provided; reported by Alejo Sanchez\n o Allow setting of local port for evhttp connections to support millions of connections from a single system; from Richard Jones.\n o Clear the timer cache when leaving the event loop; reported by Robin Haberkorn\n o Fix a typo in setting the global event base; reported by lance.\n o Set the 0x20 bit on outgoing alphabetic characters in DNS requests randomly, and insist on a match in replies.  This helps resist DNS poisoning attacks.\n o Make the http connection close detection work properly with bufferevents and fix a potential memory leak associated with it.\n o Restructure the event backends so that they do not need to keep track of events themselves, as a side effect multiple events can use the same fd or signal.\n o Add generic implementations for parsing and emiting IPv6 addresses on platforms that do not have inet_ntop and/or inet_pton.\n o Allow DNS servers that have IPv6 addresses.\n o Add an evbuffer_write_atmost() function to write a limited number of bytes to an fd.\n o Refactor internal notify-main-thread logic to prefer eventfd to pipe, then pipe to socketpair, and only use socketpairs as a last resort.\n o Try harder to pack all evbuffer reads into as few chains as possible, using readv/WSARecv as appropriate.\n o New evthread_use_windows_threads() and evthread_use_pthreads() functions to set up the evthread callbacks with reasonable defaults.\n o Change the semantics of timeouts in conjunction with EV_PERSIST; timeouts in that case will now repeat until deleted.\n o sendfile, mmap and memory reference support for evbuffers.\n o New evutil_make_listen_socket_reuseable() to abstract SO_REUSEADDR.\n o New bind-to option to allow DNS clients to bind to an arbitrary port for outgoing requests.\n o evbuffers can now be \"frozen\" to prevent operations at one or both ends.\n o Bufferevents now notice external attempts to add data to an inbuf or remove it from an outbuf, and stop them.\n o Fix parsing of queries where the encoded queries contained \\r, \\n or +\n o Do not allow internal events to starve lower-priority events.\n\n"
        },
        {
          "name": "ChangeLog-2.1",
          "type": "blob",
          "size": 98.802734375,
          "content": "Changes in version 2.1.8-stable (22 January 2017)\n\n Libevent 2.1.8-stable, it contains openssl fixes for resetting fd and using\n bufferevent_openssl_filter_new(). vagrant fixes, some build fixes, increased\n timeout for some tests (to reduce number of failures due to timing issues),\n date in RFC1123 format and running tests in parallel.\n\n There are highlighted changes above.\n\n Build fixes:\n  o Fix _FILE_OFFSET_BITS redinition (solaris/autotools) (336f3b11 Azat Khuzhin)\n  o util-internal: fix __func__ redefinition (netbsd) (253e7fa9 Azat Khuzhin)\n  o Fix signedness differ for iov_base (solaris) (2c62062e Azat Khuzhin)\n  o evutil_time: include <unistd.h> when there is only sleep()/usleep() (3e75194c Azat Khuzhin)\n  o http: fix formatter for pritnf for req->ntoread (osx) (1cbf26f6 Azat Khuzhin)\n Testing environment:\n  o Merge branch 'automake-tests-parallel-v4' (*includes ci bits also*) (59e217df Azat Khuzhin)\n Vagrant env fixes:\n  o vagrant/netbsd: missing libtool (9c9be399 Azat Khuzhin)\n  o vagrant/netbsd: more reliable way of installing packages (36da6877 Azat Khuzhin)\n  o vagrant/osx: use make instead of gmake (there is no gmake) (f7c70aef Azat Khuzhin)\n  o vagrant: add centos box (ca591c5b Azat Khuzhin)\n Tests:\n  o test/dns: replace servname since solaris does not have \"http\" (d6bafbbe Azat Khuzhin)\n  o test/thread: netbsd is too slow, increase timeout for conditions_simple (3c7422fc Azat Khuzhin)\n  o test/dns: run async resolving after sync one (to avoid timeouts) (07862531 Azat Khuzhin)\n  o test/http: turn off some tests that based on backlog filling (falky) (26f416c1 Azat Khuzhin)\n Bugfixes:\n  o Merge branch 'openssl-filter-fixes-v4' (83e0f43b Azat Khuzhin)\n  o Merge branch 'date-rfc1123' (68def435,4798de6c,4545807d Azat Khuzhin)\n  o Merge branch 'be-openssl-fd-reset-fix-v2' (86fa0070,32adf434 Azat Khuzhin)\n  o Merge branch 'openssl-1.1-init-fixes-v2' (18a161f0 Azat Khuzhin)\n  o Fix incorrect MIME type (23f9a20e johnsonlee)\n Trivial fixes:\n Documentation updates:\n  o Update README.md (3821cca1 Breaker)\n\n\nChanges in version 2.1.7-rc (2 Novemer 2016)\n\n Libevent 2.1.7-rc contains openssl 1.1 support, build fixes, CI improvements\n and plus Vagrantfile for testing under multiple OS'es.\n\n\n Continuous Integration:\n  o Use coveralls.io via travis (9ac000c Azat Khuzhin)\n  o travis-ci: use container-based infrastructure (7e12e96 Azat Khuzhin)\n  o travis-ci/osx: fix compiling/linking openssl libraries (9d2f8d4 Azat Khuzhin)\n  o travis-ci: use gcc-5 (fixes osx|gcc failures) (d7ceae5 Azat Khuzhin)\n  o Testing with vagrant for 6 OS and cmake+autoconf (9585338 Azat Khuzhin)\n  o travis-ci/osx: install lcov (e4e099b Azat Khuzhin)\n\n Build Improvements/Fixes:\n  o Fix cmake -DEVENT__COVERAGE=ON (40fbffc Azat Khuzhin)\n  o autogen.sh: learn about gmake (9376ac4 Azat Khuzhin)\n  o autogen.sh: remove all autoconf/automake caches, if any (69cce25 Azat Khuzhin)\n  o cmake: fix finding python2, and check that it is really 2 (3453c08 Azat Khuzhin)\n  o cmake: fix CheckFunctionExistsEx/CheckPrototypeDefinition (CMP0054) (43b69b2 Azat Khuzhin)\n  o cmake: cleanup (dc624ad Zonr Chang)\n  o cmake/win32: fix running regress, but fixing finding python2 interpreter (bcb990a Azat Khuzhin)\n  o cmake: use PYTHON_EXECUTABLE to find python2 (a4d044c Azat Khuzhin)\n  o Merge branch 'force-disable-clockgettime' (83c7cdf Azat Khuzhin)\n\n Code Improvements (core)\n  o use ev_uint16_t instead of unsigned short for port (e983712 Thomas Bernard)\n  o Merge branch 'contrib-guide-v2' (b9c5077 Azat Khuzhin)\n  o poll: Prevent libevent from spinning if POLLNVAL occurs (675974c Tim Hentenaar)\n\n Testing:\n  o test/regress: cover a polling of invalid fd (cb0df5c Tim Hentenaar)\n\n Code Improvements (bufferevent_openssl)\n  o Make it build using OpenSSL 1.1.0 (3e9e0a0 Kurt Roeckx)\n  o Don't call BIO_number_{read|written} on NULL BIOs. (6702da1 Adam Langley)\n  o Switch from a 512 to 2048-bit RSA key. (f9803a6 Adam Langley)\n\n Trivial fixes:\n  o Ignore temporary configure files (8fb08ae Azat Khuzhin)\n  o README.md: fix typo: ar -> are (2361616 Simone Basso)\n  o be: just a simple mistake, reinclude the <errno.h> (7521664 Seven)\n\nChanges in version 2.1.6-beta (4 July 2016)\n\n Libevent 2.1.6-beta contains mostly bug fixes (evbuffers, evthread, evdns,\n bufferevents, core, http, samples), improvements but mostly to fix some\n possible issues (EVHTTP_CON_LINGERING_CLOSE), a lot of new unit tests and new\n appveyor integration.\n\n Security Fixes (utils)\n   o evutil_parse_sockaddr_port(): fix buffer overflow (329acc1 Azat Khuzhin)\n\n Security Fixes (evdns)\n   o evdns: name_parse(): fix remote stack overread (96f64a0 Azat Khuzhin)\n   o evdns: fix searching empty hostnames (ec65c42 Azat Khuzhin)\n\n New APIs (evdns)\n   o New function to get address for nameserver. (537177d Nick Mathewson)\n\n New APIs (bufferevents)\n   o expose bufferevent_incref/decref (with fewer modifications) (1ed6718 Mark Ellzey)\n\n New APIs (internal)\n   o evdns: export cancel via callbacks in util (like async lib core/extra issues) (8cbe65d Azat Khuzhin)\n\n New APIs/Improvements (http)\n   o http: take EVHTTP_CON_LINGERING_CLOSE into account for \"Expect: 100-Continue\" (ac448a7 Azat Khuzhin)\n   o http: lingering close (like nginx have) for entity-too-large (9fde518 Azat Khuzhin)\n   o http: read server response even after server closed the connection (680742e Azat Khuzhin)\n   o http: export evhttp_connection_set_family() (714fc70 Azat Khuzhin)\n   o http: reuse connected address only with EVHTTP_CON_REUSE_CONNECTED_ADDR (a50f5f0 Azat Khuzhin)\n   o http: use IP address that we got before (if any) during retrying (54c887d Azat Khuzhin)\n\n Bugfixes (core)\n   o Fix getaddrinfo under solaris (for multiprotocol case) (40730ae Azat Khuzhin)\n   o Check for Mac OS X 10.4 kqueue bug properly (df6f99e Mark Mentovai)\n   o event_reinit: make signals works after fork() without evsig_add() (88640aa Nicholas Marriott)\n   o event_reinit: always re-init signal's socketpair (ad0c237 Nicholas Marriott)\n   o Free event queues even for recursive finalizers (7c8d015 Azat Khuzhin)\n   o Fix checking for make_base_notifiable() (f337296 Azat Khuzhin)\n   o Set correct socklen for PF_INET6 sockaddr len (3499ad9 Mark Ellzey)\n   o Fix garbage value in socketpair util function, stdint? (043ae74 Mark Ellzey)\n   o fix the return value of event_deferred_cb_schedule_ (38cef64 Greg Hazel)\n   o event_free_debug_globals_locks(): disable lock debugging (e5c87d1 Azat Khuzhin)\n   o event: call event_disable_debug_mode() in libevent_global_shutdown() (941faae Azat Khuzhin)\n   o ht-internal: don't reset hth_table_length explicitly in name_##HT_CLEAR (597c7b2 Azat Khuzhin)\n\n Bugfixes (evthread)\n   o evthread: fix evthread_setup_global_lock_() for debug-lock with a real-lock case (e4556fc Azat Khuzhin)\n   o evthread: evthreadimpl_disable_lock_debugging_() for libevent_global_shutdown() (ccc5593 Azat Khuzhin)\n\n Bugfixes (evdns)\n   o evdns: avoid double-free in evdns_base_free() for probing requests (4db15e0 Azat Khuzhin)\n   o evdns: evdns_base_free(): fix UAF of evdns_base with @fail_requests (00313c5 Azat Khuzhin)\n   o evdns: evdns_base_free(): free requests before namservers (14f84bb Azat Khuzhin)\n   o evdns: fix randomize-case by make case-insensitive as required (9c238de Azat Khuzhin)\n\n Bugfixes (bufferevents)\n   o be_sock: handle readv() returns ECONNREFUSED (freebsd 9.2) (3189eb0 Azat Khuzhin)\n   o be_filter: avoid data stuck under active watermarks (b627ad8 Eduardo Panisset)\n   o Fix bufferevent_pair to properly set BEV_EVENT_{READING,WRITING} on flush. (2851889 David Paschich)\n   o be_openssl: clear all pending errors before SSL_*() calls (38e0f4a Azat Khuzhin)\n   o be_sock: cancel in-progress dns requests (86dfd2c Azat Khuzhin)\n   o be_sock: unfreeze buffers on fd changing (255525d Azat Khuzhin)\n   o be_sock: bufferevent_socket_connect_hostname(): make it thread-safe (809bb39 Azat Khuzhin)\n   o be_openssl: don't call do_write() directly from outbuf_cb (da52933 Azat Khuzhin)\n   o be_openssl: use bufferevent_enable() instead of bufferevent_add_event_() (0c66d32 Azat Khuzhin)\n   o be_openssl: don't add events during bev creation (like be_sock) (f4b6284 Azat Khuzhin)\n   o Fix lock leak in be_pair_flush() if flush type is BEV_NORMAL (f45d39d Bill Vaughan)\n   o be_openssl: don't use *_auto() in do_handshake() we can't have fd == -1 there (877280d Azat Khuzhin)\n   o be_openssl: don't call set_open_callbacks() if fd == -1 (e8a2da9 Azat Khuzhin)\n   o be_openssl: get rid off hackish \"fd_is_set\", to fix some corner cases (40b0379 Azat Khuzhin)\n   o be: we don't need to use getpeername() we we have conn_address (2c271e2 Azat Khuzhin)\n   o Call underlying bev ctrl SET_FD on filtered bufferevents (c2aa7dc Mark Ellzey)\n   o be_pair: release shared lock with the latest of bufferevent_pair (92a359e Azat Khuzhin)\n\n Bugfixes (http)\n   o [Issue #313] set method to ASCII \"NULL\" if evhttp_method() returns NULL (17cc636 Mark Ellzey)\n   o evhttp_have_expect(): fix -Wlogical-not-parentheses (24b5214 Azat Khuzhin)\n   o http: set fd to -1 unconditioally, to avoid leaking of DNS requests (7a4b472 Azat Khuzhin)\n   o http: avoid leaking of fd in evhttp_connection_free() (f0e1341 Azat Khuzhin)\n   o http: get fd from be layer during connection reset (4a53c54 Azat Khuzhin)\n   o http: fix EVHTTP_CON_READ_ON_WRITE_ERROR when it doesn't supported by OS (2ff164a Azat Khuzhin)\n   o http: do not do function calls under EVUTIL_ASSERT() to fix NDEBUG builds (7c89999 Azat Khuzhin)\n   o http: fix leaking of response_code_line (8f18a62 Azat Khuzhin)\n   o http: fix \"Expect: 100-continue\" client side (0b46b39 Azat Khuzhin)\n   o http: fix conflicts EVHTTP_CON_AUTOFREE and EVHTTP_CON_REUSE_CONNECTED_ADDR (4dc0979 Azat Khuzhin)\n   o http: avoid epoll_ctl() on already closed fd (triggers by http/chunk_out) (ab3bc69 Azat Khuzhin)\n   o http: install timeout for read too during connect for ssl (040000d Azat Khuzhin)\n   o http: fix evhttp_request_own() by checking EVHTTP_USER_OWNED in more cases (b0d3964 Azat Khuzhin)\n   o http: fix detecting EOF without write (7ed02ac Azat Khuzhin)\n   o evhttp: Fix failure to send all output data for POST/PUT requests (24eea0d John Ohl)\n   o Fix evhttp_uriencode() regression. (c6b1ec1 Mark Ellzey)\n   o removed unused vars (e94250c Mark Ellzey)\n   o pointer overflow checks for evhttp_uriencode (72afe4c Zonr Chang)\n\n Bugfixes (evbuffers)\n   o buffer: fix overflow check in evbuffer_expand_singlechain() (a3f4ccd Azat Khuzhin)\n   o buffer: evbuffer_add_buffer(): clean empty chains from destination buffer (26fd932 Azat Khuzhin)\n   o Fix n_add_for_cb in evbuffer_prepend() in case of new buffer required (0abd039 Azat Khuzhin)\n   o be_filter: actually disable output_filter during processing output (c031215 Simon Perreault)\n   o evbuffer_add: Use last_with_datap if set, not last. (a8769ef Marcus Sundberg)\n   o EVBUFFER_PTR_SET -> EVBUFFER_PTR_ADD (8674e4f jer-gentoo)\n\n Bugfixes (evconnlistener)\n   o listener: unlock lev on error in listener_read_cb() (2a71b33 Azat Khuzhin)\n   o Fix potential fd leak in listener_read_cb() (a695a72 Mark Ellzey)\n\n Testing\n   o tests: use waitpid(..., WNOWAIT) to fix failing of main/fork under solaris (43eb56c Azat Khuzhin)\n   o test: replace sleeping with syncing pair in main/fork (16d220c Azat Khuzhin)\n   o test/http: do not run tests that based on backlog filling (freebsd) (500b6b7 Azat Khuzhin)\n   o test/bufferevent/iocp: fix test name for \"bufferevent_connect_fail_eventcb\" (4410e9d Azat Khuzhin)\n   o test/ssl: use send()/recv()/EVUTIL_ERR_RW_RETRIABLE()/EVUTIL_SOCKET_ERROR() to fix win32 (a9e8cd6 Azat Khuzhin)\n   o test/https_basic: increase timeout for complete write (fixes win32) (d5a2f2f Azat Khuzhin)\n   o test: fix building with --disable-thread-support under win32 (a487706 Azat Khuzhin)\n   o test/buffer: evbuffer_add_buffer() with empty chains (a272bc4 Azat Khuzhin)\n   o test/buffer: evbuffer_remove_buffer() with empty chains (prepend) (f0cfa14 Azat Khuzhin)\n   o test/buffer: evbuffer_remove_buffer() with empty chains (evbuffer_add_buffer()) (2880ce6 Azat Khuzhin)\n   o test/buffer: cover evbuffer_expand() for overflow (48dab7a Azat Khuzhin)\n   o test/be_filter: creating test case for data stuck with active watermarks (766194b Eduardo Panisset)\n   o test/http: avoid using conditionals with omitted operands (fixes VS2015) (2a4bf29 Azat Khuzhin)\n   o test/http: don't mix declarations and code (fixes -Wdeclaration-after-statement) (aabf1c2 Azat Khuzhin)\n   o test/buffer: fix leak in test_evbuffer_prepend() (c08d90b Azat Khuzhin)\n   o test/buffer: avoid errors with --no-fork (reinitialize static vars) (e7d1e39 Azat Khuzhin)\n   o test/buffer: cover n_add_for_cb when evbuffer_prepend() need to allocate buffer (e77ff41 Azat Khuzhin)\n   o test/tinytest_macros: add new one tt_nstr_op() (bd19a28 Azat Khuzhin)\n   o test/bufferevent: check that output_filter disabled during processing output (ae28812 Azat Khuzhin)\n   o test/listener: regression for missing unlock in listener_read_cb() (7d85651 Azat Khuzhin)\n   o test/regress: add tests for evbuffer_add() breakage on empty last chain (d5ee739 Marcus Sundberg)\n   o test/http: fix running some tests sequential (with --no-fork) (bddad71 Azat Khuzhin)\n   o test/http: localize evhttp server structure (cbc3209 Azat Khuzhin)\n   o test/dns: regression for empty hostname (d7348ba Azat Khuzhin)\n   o test/http: fix SERVER_TIMEOUT tests under win32 (d49a658 Azat Khuzhin)\n   o test/http: add a helper for creating timedout/failed request (376f107 Azat Khuzhin)\n   o test/http: adopt for C90 (mixed code and declarations) (d02a285 Azat Khuzhin)\n   o test/http: cover NS timed out during request cancellations separatelly (0c343af Azat Khuzhin)\n   o test/http: request cancellation with resolving/{conn,write}-timeouts in progress (334340d Azat Khuzhin)\n   o test/http: exit from the loop in the errorcb to wait cancellation (927ab33 Azat Khuzhin)\n   o regress_clean_dnsserver(): reset global port vars (351207f Azat Khuzhin)\n   o test/http: read_on_write_error: fix it for win32 (3b58169 Azat Khuzhin)\n   o test/http: separate coverage for EVHTTP_CON_READ_ON_WRITE_ERROR (5c2b4c1 Azat Khuzhin)\n   o test/http: cover \"Expect: 100-continue\" client-server interaction (31d8116 Azat Khuzhin)\n   o test/http: *lingering tests shouldn't have \"Expect: 100-continue\" (ed469ab Azat Khuzhin)\n   o test: use EVUTIL_SHUT_WR (04fc82f Azat Khuzhin)\n   o test/http: avoid huge stack allocations to fix win32 builds (3166765 Azat Khuzhin)\n   o test: http/lingering_close: cover EVHTTP_SERVER_LINGERING_CLOSE (e122ca1 Azat Khuzhin)\n   o test: http/non_lingering_close: cover ~EVHTTP_SERVER_LINGERING_CLOSE (f41e1b0 Azat Khuzhin)\n   o test: http/*: update expected HTTP codes for body exceeds `max_body_size` (addf2b9 Azat Khuzhin)\n   o test: http/data_length_constrains: set EVHTTP_CON_READ_ON_WRITE_ERROR (d38a723 Azat Khuzhin)\n   o test: increase buffer size for http/data_length_constraints to trigger EPIPE (0792e1e Azat Khuzhin)\n   o test/tinytest_demo: include <windows.h> for win32 to fix tdm-gcc (f062bbe Azat Khuzhin)\n   o test/regress: cover event_del() waiting mechanism (5b58b70 Azat Khuzhin)\n   o test/regress: cover existing signal callbacks and fork() + event_reinit() (ceddc60 Azat Khuzhin)\n   o test/regress: cover signals after fork() + event_reinit() (b075b81 Azat Khuzhin)\n   o test/regress: main/fork: rewrite assertions by just removing event in callback (088d8b3 Azat Khuzhin)\n   o test/dns: check exit code of evdns_getaddrinfo() (0b9d432 Azat Khuzhin)\n   o test/dns: cover evdns_getaddrinfo() and evdns_base_free() with @fail_requests (4ad3483 Azat Khuzhin)\n   o test/dns: cover @fail_requests for evdns_base_free() (d6c6fb4 Azat Khuzhin)\n   o test/dns: more graceful coverage of @fail_requests (123d372 Azat Khuzhin)\n   o test/ssl: cover busy-loop (i.e. {read,write}-blocked-on-{write,read} stuff) (da0ea7a Azat Khuzhin)\n   o test/http: write_during_read for https (23c77b6 Azat Khuzhin)\n   o test/http: connection_fail for https (7ea26f7 Azat Khuzhin)\n   o test/http: stream_out for https (ac04968 Azat Khuzhin)\n   o test/http: chunk_out for https (a71ffb9 Azat Khuzhin)\n   o test/regress: fix ssl-less builds (need to make this prettier) (3160716 Azat Khuzhin)\n   o test/http: allow dirty shutdown for ssl to fix https_incomplete (1ede326 Azat Khuzhin)\n   o test/http: https basic (59714b4 Azat Khuzhin)\n   o test/http: incomplete{,_timeout} for https (615490d Azat Khuzhin)\n   o test/http: add simplest test for http/https/https_dirty_shutdown (93b19dc Azat Khuzhin)\n   o test/http: https: retry coverage (7c2d24a Azat Khuzhin)\n   o test/http: https server support (plus some helpers) (a7088ad Azat Khuzhin)\n   o test/http: more sanity checks (a27c53c Azat Khuzhin)\n   o test/ssl: export getkey()/getcert()/get_ssl_ctx()/init_ssl() for https (0c4c387 Azat Khuzhin)\n   o test/regress_be: basic coverage bufferevent_flush() for pair/sock layers (ad52602 Azat Khuzhin)\n   o test/regress_be: socket_filter_inactive: check bufferevent after creation (f8081af Azat Khuzhin)\n   o test/regress_be: cover finalizers from inactive to active queue (337684b Azat Khuzhin)\n   o test/regress_buffer: fix clang compilation warnings (d8fd4c0 Azat Khuzhin)\n   o test/regress_http: fix compilation warnings (-Wmissing-field-initializers) (cd422e0 Azat Khuzhin)\n   o test/regress_dns: fix compilation warnings (-Wmissing-field-initializers/for) (f55db98 Azat Khuzhin)\n   o tests/regress_dns: cover that randomize-case works case-insensitive (1e8bfbc Azat Khuzhin)\n   o test: fix bufferevent/bufferevent_pair_release_lock in debug mode (3f749e9 Azat Khuzhin)\n   o test: fix bufferevent/bufferevent_pair_release_lock for freebsd (79f9ace Azat Khuzhin)\n   o test/regress_be: bufferevent_enable() shouldn't call eventcb by it's own (a0f308d Azat Khuzhin)\n   o test/regress_be: introduce fake_listener_create() (37dc9e0 Azat Khuzhin)\n   o test/regress_http: cover evhttp_request_own() (6f6fa0d Azat Khuzhin)\n   o test/regress_http: cover write during read (3d15aeb Azat Khuzhin)\n   o test/regress_http: verify that closecb will be called without multiple write (4be6c70 Azat Khuzhin)\n   o test/regress: fix bufferevent_pair_release_lock with EVENT_DEBUG_MODE (6ea6655 Azat Khuzhin)\n   o test/regress_ssl: check events fd/pending after timeout triggered (cdafdf0 Azat Khuzhin)\n   o test/regress_ssl: cover case when server didn't up (failed with timeout) (74845f1 Azat Khuzhin)\n   o test/regress_ssl: covert that we can't change fd with underlying (df507af Azat Khuzhin)\n   o test/regress_ssl: cover that events (read/write) at finish not pending (762edb4 Azat Khuzhin)\n   o test/regress_ssl: cover fd manipulations (b78a829 Azat Khuzhin)\n   o test/regress_ssl: convert open_ssl_bufevs() to mask (46bba73 Azat Khuzhin)\n   o test/regress_ssl: convert client/server to mask too (3455991 Azat Khuzhin)\n   o test/regress_ssl: cover \"allow_dirty_shutdown\" (0430327 Azat Khuzhin)\n   o test/regress_ssl: convert regress_bufferevent_openssl() to bitmask (342e116 Azat Khuzhin)\n   o tests/regress_ssl: drop duplicated assert (25e56fd Azat Khuzhin)\n   o test/regress_http: initialize \"dns_base\" to avoid reading trash (9f0bff3 Azat Khuzhin)\n   o test/http: cover retrying with saved conn_address by shutting down dns server (f4874d8 Azat Khuzhin)\n   o be_pair/regress: cover use of shared lock (lock/unlock/free) (a558fcd Azat Khuzhin)\n   o regress_dns: drop hack for event_debug_map_HT_GROW in leak tests (3540a19 Azat Khuzhin)\n\n Sample code\n   o Fix memory leak in signal-test.c (666db91 basavesh.as)\n   o sample/hello-world: exAmple, not eXMple (2d3cd35 kirillDanshin)\n   o dns-example: allow to set ns from args (df19a97 Azat Khuzhin)\n   o dns-example: convert to getopt() (32f8592 Azat Khuzhin)\n   o http-connect: make it win32 compilable (1bf7595 Azat Khuzhin)\n   o sample/https-client: allow to change path to ca-certificates (fdf713a Azat Khuzhin)\n   o sample/https-client: check for ERR_remove_thread_state() existence (c4e9d9b Azat Khuzhin)\n   o sample/https-client: replace ERR_remove_state() by ERR_remove_thread_state() (77ad68a Azat Khuzhin)\n   o sample/https-client: add -timeout option (4637aa8 Azat Khuzhin)\n   o sample/https-client: don't try to free uninitialized SSL (f3d7ff5 Azat Khuzhin)\n   o sample/https-client: graceful exit with freeing memory (to make valgrind happy) (24a1f25 Azat Khuzhin)\n   o https-client: correctly handle URLs with no path (like \"https://host:port\") (29a0482 Andrey Skriabin)\n   o sample/http-connect: don't use assert() to make it work with NDEBUG (6dc71e7 Azat Khuzhin)\n   o sample/http-connect: made it compatible with C90 (f976d43 Azat Khuzhin)\n   o sample: add HTTP CONNECT tunnelling example using libevent http layer (1d34498 Azat Khuzhin)\n   o Update dns-example. (620ff24 Mark Ellzey)\n\n Documentation\n   o Update README.md (b8ec70c Mark Ellzey)\n   o Update README.md (80faee9 Mark Ellzey)\n   o Update README.md (ad4a897 Mark Ellzey)\n   o Update README.md (a2b2e1e Mark Ellzey)\n   o Update README.md (0dfa5dc Mark Ellzey)\n\n Code Improvements (evthread)\n   o evthread: add evthread_get_{lock,condition}_callbacks() helpers (c0b34f6 Azat Khuzhin)\n\n Code Improvements (core)\n   o util: make @sa const for evutil_socket_connect_() (a8d32c2 Azat Khuzhin)\n\n Code Improvements (http)\n   o http: assert's that evbuffer_drain() success on connection reset (2185e63 Azat Khuzhin)\n   o http: introduce evhttp_request_free_() helper (22061ac Azat Khuzhin)\n   o http: introduce evhttp_is_request_connection_close() helper (6540da3 Azat Khuzhin)\n\n Code Improvements (bufferevents)\n   o be_sock: bufferevent_socket_set_conn_address(): assert instead of silent no-op (0ab88c2 Azat Khuzhin)\n   o be_sock: sanity check in bufferevent_socket_set_conn_address() (eedbeff Azat Khuzhin)\n   o be: replace sockaddr_storage with sockaddr_in6 for conn_address (3889612 Azat Khuzhin)\n   o be: replace conn_address by full struct instead of pointer (e5615aa Azat Khuzhin)\n   o bufferevent: move conn_address out from http into bufferevent (8bb3842 Azat Khuzhin)\n   o be: make @sa const for bufferevent_socket_connect() (dc33c78 Azat Khuzhin)\n\n Cleanups (core)\n   o Refactoring conditional directives that break parts of statements. (4b41eeb lzmths)\n   o epoll: introduce PRINT_CHANGES() macro to avoid copy-pasting (a1b142b Azat Khuzhin)\n   o tab (6e7a580 Greg Hazel)\n\n Cleanups (evbuffers)\n   o buffer_compat: fix comment -- we have EVBUFFER_EOL_ANY not EOL_STYLE_ANY (575ff67 Azat Khuzhin)\n\n Cleanups (bufferevents)\n   o be_sock: evutil_getaddrinfo_async_() always return 0 (dbff101 Azat Khuzhin)\n   o be_sock: drop be_sock_add() macro (useless and debug unfriendly) (fad5fe2 Azat Khuzhin)\n   o be: introduce bufferevent_generic_adj_existing_timeouts_() (3c1f58f Azat Khuzhin)\n   o be: add_event: use evutil_timerisset() (a96b73b Azat Khuzhin)\n   o be_openssl: introduce be_openssl_auto_fd() helper (2a8a711 Azat Khuzhin)\n   o be_openssl: introduce set_open_callbacks_auto() (510da71 Azat Khuzhin)\n\n Cleanups (http)\n   o http: make fallback for EVHTTP_CON_READ_ON_WRITE_ERROR more cleaner (d405492 Azat Khuzhin)\n   o http: coding style issue (365f181 Azat Khuzhin)\n\n Cleanups (evdns)\n   o evnds: inline TEST_NAME macro to make debuggin easier (0c615f4 Azat Khuzhin)\n\n Portability Fixes\n   o [#372] check for errno.h (3031617 Mark Ellzey)\n   o Fixed Unicode issue in error messages. (e8b7895 Mattes D)\n   o Assume that ke_udata is an integer type on CloudABI. (5602e45 Ed Schouten)\n   o Add missing include of <netinet/in.h>. (b2c68bc Ed Schouten)\n   o Include <sys/ioctl.h>, <sys/resource.h> and <sys/wait.h> optionally. (c1404b5 Ed Schouten)\n   o Test against SO_REUSEADDR (along with _WIN32). (ce1776c Ed Schouten)\n   o Always define missing TAILQ functions from sys/queue.h (2828bdb Christopher Wiley)\n   o Don't use BSD u_* types. (fd36647 Ed Schouten)\n   o Remove BSD-ism: TIMEVAL_TO_TIMESPEC(). (193c7de Ed Schouten)\n   o be: include all variations of headers for sockaddr_in6 struct (c212291 Azat Khuzhin)\n   o be: fix sockaddr_in6 type definition for win32 (c42bc6b Azat Khuzhin)\n\n Continuous Integration:\n   o travis: split long lines, and make it cleaner (685a6a1 Azat Khuzhin)\n   o travis: fix autotools on osx by reinstalling libtool (088ea5e Azat Khuzhin)\n   o appveyor/autotools: link with openssl by passing LDFLAGS/CFLAGS (6fcfa25 Azat Khuzhin)\n   o appveyor: image already had openssl installed (4634b85 Azat Khuzhin)\n   o appveyor: check -DUNICODE -D_UNICODE according to ReleaseChecklist (cmake only) (e9acc44 Azat Khuzhin)\n   o appveyor: ignore failure of mingw-get (1810857 Azat Khuzhin)\n   o appveyor: drop shallow_clone, since we use tags for detecting version in cmake (ac90133 Azat Khuzhin)\n   o appveyor: support cmake & autotools using build matrix (like travis-ci has) (8f95015 Azat Khuzhin)\n   o travis-ci/osx: relink gcc/g++ instead of clang (481481d Azat Khuzhin)\n   o travis-ci: enable multi-os mode (osx, linux) (79917e4 Azat Khuzhin)\n   o travis-ci: increase matrix (--disable-foo) (59649f7 Azat Khuzhin)\n   o travis-ci: adjust alignment (c8be339 Azat Khuzhin)\n   o travis: add builds without debug mode into matrix (3e56da2 Azat Khuzhin)\n   o test: run regress with EVENT_DEBUG_MODE=1 and without (cf2cf2a Azat Khuzhin)\n   o Update travis config for status updates (37453ab Mark Ellzey)\n   o Use autotools for appveyor until cmake is fixed. (1cc2e29 Mark Ellzey)\n   o Fix the link for appveyor OpenSSL installer (WIN32) (107d565 Mark Ellzey)\n   o Forgot to install OpenSSL for appveyor (26164a5 Joakim Söderberg)\n   o Add support for appveyor.com windows CI (5f89c37 Joakim Söderberg)\n\n Build Improvements/Fixes:\n   o evutil: mark ai_find_protocol() static (prototype-less) (5a157c8 Azat Khuzhin)\n   o cmake/solaris: set CMAKE_REQUIRED_LIBRARIES to fix functions detections (dc95823 Azat Khuzhin)\n   o cmake/solaris: fix building (link with socket,nsl) (050bfc7 Azat Khuzhin)\n   o cmake: check for ZLIB_INCLUDE_DIR, since we can have only library without headers (c4dfb93 Azat Khuzhin)\n   o autotools/win32: fix searching ssl library (671a24f Azat Khuzhin)\n   o cmake/win32: do not compile regress_thread on -DEVENT__DISABLE_THREAD_SUPPORT=ON (de0c196 Azat Khuzhin)\n   o cmake/win32: do not compile evthread_win32 on -DEVENT__DISABLE_THREAD_SUPPORT=ON (ecb0ec8 Azat Khuzhin)\n   o cmake: fix -DEVENT__ENABLE_VERBOSE_DEBUG (typo on -DUSE_DEBUG) (e35f224 Azat Khuzhin)\n   o cmake: do not use stderr for notifications/version-info (38716c6 Azat Khuzhin)\n   o autoconf: fix --disable-thread-support build under win32 (bb09535 Azat Khuzhin)\n   o buffer: don't mix code and declarations (8892f4c Azat Khuzhin)\n   o Update gitignore file to ignore cscope gen'ed files (0aaa4fb Neeraj Badlani)\n   o For non GCC/clang on OSX the -Wno-deprecated-declarations may not be valid (b5ca365 Rainer Keller)\n   o automake: define serial-tests only if automake have this option (61179de Azat Khuzhin)\n   o test/automake: don't use paralell test harness (since automake 1.12) (44d755e Azat Khuzhin)\n   o Ignore all pkgconfig generated stuff (ce38993 Azat Khuzhin)\n   o libevent_core and libevent_extra also deserve a pkgconfig file (b8d7c62 Jan Heylen)\n   o Ignore verify_tests.bat (win32 version) (0f2de10 Azat Khuzhin)\n   o cmake: require 3.1 only for win32 to make it work under ubunty precise (87f7238 Azat Khuzhin)\n   o cmake: require at least 3.1 for target_sources() (c46ead5 Azat Khuzhin)\n   o cmake: fix adding of compiler flags, and now it will (36588e1 Azat Khuzhin)\n   o Replace -Wswitch-enum with -Wswitch, and add it into cmake rules too (f29f59e Azat Khuzhin)\n   o test/regress_ssl: Fix compile problems for win32 (73d0360 Trond Norbye)\n   o util: fix \"%zu\" format on TDM-gcc/MinGW-w64 (79b69d8 Azat Khuzhin)\n   o cmake: don't define EVENT__NEED_DLLIMPORT always (fixes VS2013 static build) (49bd790 Azat Khuzhin)\n   o Add missing return statement to del_wait_thread so libevent can build. (4f778ab Nick Mathewson)\n   o cmake: fix building dns-example under win32 (missing getopt) (a1609a8 Azat Khuzhin)\n   o visibility: align it to make it more readable (bb6b53d Azat Khuzhin)\n   o cmake: Fix detection of ssize_t/SSIZE_T (7707f6b Azat Khuzhin)\n   o Ignore more configure stuff (configure.lineno) (8d34302 Azat Khuzhin)\n   o Fixed issue with cmake version generation (d56efd9 Mark Ellzey)\n   o Cmake is now officially working. (7f9646d Mark Ellzey)\n   o More cmake updates, lot's of missing definitions (49a5381 Mark Ellzey)\n   o CMake syntax fixes fo .in files (6aad23d Mark Ellzey)\n   o Revert \"The Windows socket type is defined as SOCKET.\" (a264da8 Mark Ellzey)\n   o CMAKE CMAKE CMAKE CLEANUPS (a9db46a Mark Ellzey)\n   o Lot's of cmake updates (8b228e2 Mark Ellzey)\n   o Provide a mechanism for building the library on Windows with different compiler flags. Add a batch file that builds it for the M[DT][d] options and performs a hunt and gather of the different output libraries. (ded8086 billsegall)\n   o The Windows socket type is defined as SOCKET. (c9e6c3d billsegall)\n   o autotools: fix getservbyname() detection (959a4c2 Azat Khuzhin)\n   o Add missing <string.h> for openssl_hostname_validation module (3316a21 Azat Khuzhin)\n   o make test/regress_ssl.c compile without warnings (9f02a44 Thomas Bernard)\n   o test/regress_be: drop debug __asm__(int3) to fix arm build (8240379 Azat Khuzhin)\n   o event_debug_created_threadable_ctx_: fix compilation without debug mode (a068f2e Azat Khuzhin)\n   o Add a prototype for event_disable_debug_mode() (bfcedee Sebastian Hahn)\n   o http: eliminate warning about \"socklen\" in evhttp_connection_connect_() (dfad1a4 Azat Khuzhin)\n   o Updated gitignore (1dbb55d Mark Ellzey)\n   o Update bench_httpclient.c (cb96931 Seungmo Koo)\n   o *fix: bench_httpclient to support win32 (4e9325e zeliard)\n   o Commented out a WIN32 threading / timing test for now (e84e269 Mark Ellzey)\n   o Fix mixed declarations and code (forbidden by ISO C90) (0c7f217 Thomas Bernard)\n   o Fix \"function declaration isn’t a prototype\" (746d2c5 Thomas Bernard)\n   o This fixes a bug introduced in 27bd9faf498b91923296cc91643e03ec4055c230 (19ba454 Joakim Söderberg)\n   o changed strtotimeval signature as per #211 (bdbc823 Xiao Bao Clark)\n   o Added cmake-generated files to ignore list. (6c12bfe Matyas Dolak)\n   o Ignore `make dist` generated files (8a2c6c7 Azat Khuzhin)\n\n  Debugging\n   o Debug mode option to error on evthread init AFTER other event calls. (dcfb19a Mark Ellzey)\n\n\n\nChanges in version 2.1.5-beta (5 January 2015)\n\n Security Fixes (evbuffers)\n   o Avoid integer overflow bugs in evbuffer_add() and related functions.  See CVE-2014-6272 advisory for more information. (d49bc0e88b81a5812116074dc007f1db0ca1eecd)\n\n New APIs (evconnlistener)\n   o Provide support for SO_REUSEPORT through LEV_OPT_REUSABLE_PORT (b625361 Maciej Soltysiak)\n\n Bugfixes (core)\n    o Fix use-after-free error in EV_CLOSURE_EVENT callback (3cc0eac John Ohl)\n    o Fix race caused by event_active (3c7d6fc vjpai)\n\n Bugfixes (evbuffer)\n   o Fix evbuffer_peek() with len==-1 and start_at non-NULL. (ba59923)\n   o Consistently check for failure from evbuffer_pullup() (60f8f72)\n   o Fix evbuffer_peek() with len==-1 and start_at non-NULL. (fb7e76a)\n\n Bugfixes (windows, IOCP)\n   o be async: avoid double close() (f133b86 Azat Khuzhin)\n\n Bugfixes (bufferevents)\n   o Fix issue #127, double free for filterevents that use BEV_OPT_CLOSE_ON_FREE (2c82aa0 John Ohl)\n   o make bufferevent_getwatermark api more robust (a21e510 ufo2243)\n   o [Bugfix] fix bufferevent setwatermark suspend_read (b34e4ac ufo2243)\n   o bufferevent_openssl: reset fd_is_set when setfd with -1 is called (3da84c2 Azat Khuzhin)\n   o Fix compilation for older OpenSSL versions. (5c7282f Joakim Soderberg)\n\n New APIs (evhttp)\n   o Add evhttp_connection_set_family() to set addrinfo->family for DNS requests (12c29b0 Azat Khuzhin)\n   o Implement interface that provides the ability to have an outbound evhttp_connection free itself once all requests have completed (2b9ec4c,10fe4f John Ohl)\n\n New APIs (core)\n   o Implement new/free for struct evutil_monotonic_timer and export monotonic time functions (f2645f8 Andrea Shepard)\n\n Bugfixes (evdns)\n   o Load hosts file on Windows. (a0b247c Vilmos Nebehaj)\n   o Don't truncate hosts file path on Windows. (d0dc861 Vilmos Nebehaj)\n   o Fix a crash in evdns related to shutting down evdns (9f39c88,e8fe749)\n   o evdns: avoid read-after-free in evdns_request_timeout_callback() (61262a0 Azat Khuzhin)\n   o Correctly handle allocation failures in evdns_getaddrinfo (6a53d15)\n   o evdns: fix EVDNS_BASE_DISABLE_WHEN_INACTIVE in case retransmit/retry (74d0eee Azat Khuzhin)\n   o evdns: add retry/reissue tests for EVDNS_BASE_DISABLE_WHEN_INACTIVE (3ca9d43 Azat Khuzhin)\n   o evdns: fail ns after we are failing/retrasmitting request (97c750d Azat Khuzhin)\n\n Bugfixes (evhttp)\n   o http: reset connection before installing retry timer (fix http retries handling) (bc79cc5 Azat Khuzhin)\n\n\n Testing\n   o regress_dns: fix leaks in getaddrinfo_async{,_cancel_stress} tests (2fdc5f2 Azat Khuzhin)\n   o test: add family argument for http_connection_test_() (177b8a7 Azat Khuzhin)\n   o test: add regress for evhttp_connection_set_family() with AF_INET and AF_UNSPEC (42aefeb Azat Khuzhin)\n   o test/http: add regress test for set family to AF_INET6 (3fbf3cc Azat Khuzhin)\n   o Update to a more recent tinytest_macros. (8da5a18)\n   o test/regress: add simplestsignal: to track reorder bugs separately (b897bef Azat Khuzhin)\n   o test/evbuffer_peek: add regress in case we have first buffer greater (e2d139d Azat Khuzhin)\n   o More evbuffer_peek() test cases (154006a)\n   o use correct tt macro for pointer compare (08c88ea)\n   o regress_buffer: fix 'memcmp' compare size (79800df Maks Naumov)\n   o Fix a use-after-free in unit tests. CID 752027 (3739057)\n   o Fix a dead-code warning in unit tests. CID 1193548 (c119f24)\n   o Use evutil_weakrand() in unit tests. (a677b72, 364c110)\n   o Use a more precise calculation for max in time-ratelim.c (ca5b5c7)\n   o Make a buffer larger in the tests to avoid a scary evbuffer_copyout_from() (fb57b8b)\n   o Fix several memory leaks in the unit tests. (89c1a3b)\n   o Add test for evhttp_connection_free_on_completion (b0e9924 John Ohl)\n   o Fix annoying heisenbug in test-time.c (cb73704)\n\n Sample code\n   o Make http-server.c output into good html5 (6d72bdc)\n   o Use FindClose for handle from FindFirstFile in http-server.c (6466e88)\n   o https-client: add -retries argument, for connection retries (d9da844 Azat Khuzhin)\n\n Bugfixes (build)\n   o Add missing headerfile for cmake (15d90cc Trond Norbye)\n   o ignore one more test binary (b6593aa Michael Richardson)\n   o ignore config.cache/test-driver files (c83f333 Mike Frysinger)\n   o add a --disable-samples configure flag (0c492b3 Mike Frysinger)\n   o Add a few files created by \"make verify\" to .gitignore. (1a8295a Pierre Phaneuf)\n   o updates in cmake build (27bd9fa Sergey Nikulov)\n   o Fix cmake error when the Module path has more than one entry. (befbd13 Acer Yang)\n   o Fix CMake shared library build (e69d910 Nobuaki Sukegawa)\n   o Fix warnings when compiling with clang 3.5 (f5b4765 John Ohl)\n   o Fix mixed declarations and code (forbidden by ISO C90) (8afbdbc Thomas Bernard)\n\n Bugfixes (miscellaneous)\n   o tree.h: drop duplicated content of tree.h (6193187 Azat Khuzhin)\n   o evdns: disable probing with EVDNS_BASE_DISABLE_WHEN_INACTIVE (610410b,ad0493e,fea86a6,d83b337,5ca9e97 Azat Khuzhin)\n   o [Bugfix] fix grammer error (3a4d249 ufo2243)\n   o Change return type of evutil_load_windows_system_library_ to HMODULE (f691389)\n   o Fix a c90 warning (76643dd)\n   o Fix a typo in a doxygen comment. Reported by 亦得. (be1aeff)\n   o remove trailing comma from enum (b361b8a Jean-Philippe Ouellet)\n\n Bugfixes (FreeBSD)\n   o Handle ENOTCAPABLE from FreeBSD - this is returned if an event in the changelist is for an FD that has been closed. (6fd7394 Adrian Chadd)\n\n\n\nChanges in version 2.1.4-alpha (21 Mar 2014)\n\n Libevent 2.1.4-alpha adds a number of new miscellaneous APIs to make\n Libevent more useful, including support for early close detection with\n epoll via EPOLLRDHUP, triggering bufferevent callbacks, adding more\n evhttp callbacks, and more. There are also numerous bugfixes, including\n a number for finalize-related issues from 2.1.3-alpha; and an\n alternative (non-primary!) cmake-based build mechanism.\n\n New APIs (core)\n   o Added event_base_get_num_events() (0fa107d Mobai Zhang)\n   o New event_base_active_by_fd API (865a142 Greg Hazel, 5c9da9a, 87fa2b0)\n   o Add event_base_active_by_signal by analogy (4865943)\n   o Add access to max event count stats (5173bef, efbd3dc, 26230a2\n     Andrew Sweeney)\n   o Implemented EV_CLOSED event for epoll backend\n     (EPOLLRDHUP). (b1b69ac Diego Giagio, 53d2793, 43ffcf6, dfe1e52\n     Marcin Juszkiewicz, ff26633 Joakim Soderberg, 3908a5e)\n\n New APIs (evutil_secure_rng)\n   o Add evutil_secure_rng_set_urandom_device_file (2bbb5d7)\n\n New APIs (bufferevents)\n   o Add function to fetch underlying ratelimit cfg (4b3d5af Mark Ellzey)\n   o Pass and return const for bufferevent_get_token_bucket_cfg (1c77fbb\n     Mark Ellzey)\n   o Add watermark introspection (4ce242b Ondřej Kuzník)\n   o Add an option to trigger bufferevent I/O callbacks (61ee18b Ondřej Kuzník)\n   o Add an option to trigger bufferevent event callbacks (a7384c7\n     Ondřej Kuzník)\n   o Clarifications in response to merge req. comments (bd41947 Ondřej\n     Kuzník)\n   o Minor optimizations on bufferevent_trigger options (a3172a4)\n\n New APIs (evhttp)\n   o Add evhttp_connection_get_server(). (a7f82a3 Maxime Henrion)\n   o add a http default content type option (5a5acd9 Nicolas Martyanoff)\n   o http: implement new evhttp_connection_get_addr() api. (0c7f040 Azat\n     Khuzhin)\n   o Add a variant of evhttp_send_reply_chunk() with a callback on\n     evhttp_write_buffer() (8d8decf Julien BLACHE)\n   o Allow registering callback for parsing HTTP headers (b0bd7fe Balint Reczey)\n   o Provide on request complete callback facility (b083ca0 Andrew Sweeney)\n   o evhttp_request_set_on_complete_cb to be more specific about what\n     the function actually does and usage (da86dda Andrew Sweeney)\n   o Update unit test to make sure that the callback happens after the\n     output data is written (b85f398 Andrew Sweeney)\n\n Features (evdns)\n   o bug fix for issues #293 evdns_base_load_hosts doesn't remove\n     outdated addresses (954d2f9, f03d353, 45eba6f Kuldeep Gupta)\n\n Features: (cmake build support)\n   o Initial CMake commit. (e415196 Joakim Soderberg)\n   o Add all tests and benchmarks to CMake project. (e9fc014 Joakim Soderberg)\n   o More work on adding tests to CMake project (99c1dc3 Joakim Soderberg)\n   o Generate a dummy evconfig-private.h so things build\n     properly. (ce14def Joakim Soderberg)\n   o Link libm on unix platforms. (58fcd42 Joakim Soderberg)\n   o Added some GCC specific options. (19222e5 Joakim Soderberg)\n   o Use evutil_closesocket instead. (dbf2b51 Joakim Soderberg)\n   o Add copyright and licensing files for CMake modules. (c259d53\n     Joakim Soderberg)\n   o Only include WIN32 getopt where it is used. (9bbce0b Joakim Soderberg)\n   o Fix bench_cascade program on Windows. (78da644 Joakim Soderberg)\n   o Don't segfault on no found event backend. (8f2af50 Joakim Soderberg)\n   o Only test the event backends available on the system. (7ea4159\n     Joakim Soderberg)\n   o Added a \"make verify\" target. (e053c4f Joakim Soderberg)\n   o Fix the make \"verify\" target on Windows. (67e5d74 Joakim Soderberg)\n   o Get rid of deprecation warnings for OpenSSL on OSX 10.7+ (69c3516\n     Joakim Söderberg)\n   o Fix kqueue support. (a831f2f Joakim Söderberg)\n   o Added a test for testing if kqueue works with pipes. (2799b35\n     Joakim Söderberg)\n   o Change the BSD license from 4 to 3-clause. (86df3ed Joakim Soderberg)\n   o Minimum required python version is 2.4. (968e97b Joakim Soderberg)\n   o Get rid of unknown pragma warnings. (0ef1d04 Joakim Soderberg)\n   o Add a \"make verify_coverage\" target generation coverage\n     info. (f2483f8 Joakim Soderberg)\n   o Fix the \"make verify\" target on NetBSD (4ac086a Joakim Soderberg)\n   o Only look for ZLib when it is used (if tests are\n     included). (f780593 Joakim Soderberg)\n   o Added EVENT__ENABLE_GCC_WARNINGS, turns all warnings into\n     errors. (dd413bd Joakim Soderberg)\n   o Add CMake config and install targets. (f3446ed Joakim Soderberg)\n   o Fix typo (4b754df Joakim Soderberg)\n   o Some work on making it possible to simply do add_subdirectory() on\n     the project. (49ab363 Joakim Soderberg)\n   o Set USE_DEBUG=1 on EVENT__ENABLE_VERBOSE_DEBUG (fd42e70 Joakim Soderberg)\n   o Fix so that old nmake project still builds. (24d6466 Joakim\n     Soderberg)\n   o Rename README to README.md and use markdown to format. (d2bc39a\n     Joakim Soderberg)\n   o Update README with CMake build instructions. (604b8cc Joakim Soderberg)\n   o Clean up the README some. (8d4cb35 JoakimSoderberg)\n   o Forgotten headers for old nmake project compatibility. (8697b99\n     Joakim Soderberg)\n   o Change all uses of WIN32 to _WIN32 (4e14395 Joakim Söderberg)\n   o Fix include bug. (2024467 Joakim Söderberg)\n   o Check if we're on OSX before disabling deprecation in le-proxy\n     (8b40a5b Joakim Söderberg)\n   o Fix broken autotools build. (ae1bd82 Joakim Söderberg)\n   o Disclaimerize cmake a little in the README (d03b5bf)\n   o Fix CMake compile when OpenSSL is disabled. (e423d42 Joakim\n     Söderberg)\n   o CMake: Get rid of python not found warning when regress tests\n     turned off. (d38d798 Joakim Söderberg)\n   o Fix https-client compilation on Windows. (d7be788 Joakim Soderberg)\n   o Guard against EVENT_NOWIN32 being set during testing. (f1715b4\n     Joakim Soderberg)\n   o Check for OSX when checking for clang. (e212c54 Joakim Soderberg)\n   o Added a Travis-CI configuration file. (8c0f0a9 Joakim Soderberg)\n   o Added -Qunused-arguments for clang on macosx (ed99d92 Trond Norbye)\n   o Rename event_extras to event_extra (a0dd5df Trond Norbye)\n   o Add option to build shared library (4545fa9 Trond Norbye)\n   o Add -Qunused-arguments for clang on macos (b56611d Trond Norbye)\n   o Add cmake-related files to .gitignore (e061321 Trond Norbye)\n   o Export event_extra not event_extras. (2b41bcf Joakim Söderberg)\n\n Bugfixes (core)\n   o If evsel->del() fails, don't leave the evmap in an inconsistent\n     state (9b5a527 Maxime Henrion)\n   o Move event_debug_note_teardown_ before mm_free. (69b5c64)\n   o Check CLOCK_MONOTONIC_* at runtime if needed. (911abf3)\n   o Fix reinit of fds with EV_WRITE but not EV_READ. (ebfd8a8 maksqwe)\n   o Tweaked callbacks to prevent race condition\n     (https://github.com/libevent/libevent/issues/104) (40830f1, 2ea15ed\n     John Ohl)\n   o Move assert(ev) to before we use ev in EV_CLOSURE_EVENT_FINALIZE\n     case (9805972)\n\n Bugfixes (evhttp)\n   o Fix a double close() bug in evhttp when the underlying bufferevent uses\n     BEV_OPT_CLOSE_ON_FREE. (31db8a0 Maxime Henrion)\n   o Fix an unlikely but possible error case for http connections (f22049e)\n   o Avoid racy bufferevent activation (5eb1788 Nate Rosenblum)\n\n Bugfixes on 2.0 (Windows)\n   o Use windows vsnprintf fixup logic on all windows environments (e826f19)\n   o libevent/win32_dealloc() : fix sizeof(pointer) vs sizeof(*pointer)\n    (b8f5980 Frank Denis)\n\n Bugfixes (evutil_secure_rng)\n   o When we seed from /proc/sys/kernel/random/uuid, count it as success\n     (e35b540)\n   o We should return after arc4random_buf() (1ea1f26 Makoto Kato)\n   o Avoid other RNG initialization FS reads when urandom file is\n     specified (9695e9c)\n   o Really remove RNG seeds from the stack (f5ced88)\n   o Fix another arc4random_buf-related warning (e64a2b0)\n\n Bugfixes (bufferevents)\n   o Initialize async bufferevent timeout CBs unconditionally (af9b2a7)\n\n Bugfixes (evdns)\n   o Checking request nameserver for NULL, before using it. (5c710c0\n     Belobrov Andrey)\n   o Fix SEGFAULT after evdns_base_resume if no nameservers\n     installed. (14971a8 Azat Khuzhin)\n   o Actually use the log facility for reporting evdns problems. (e1766a1)\n   o Fix SEGFAULT after evdns_base_resume if no nameservers\n     installed. (f8d7df8 Azat Khuzhin)\n   o fix for ServFail from RIPE Atlas release (62f596b Antony Antony)\n\n Bugfixes (compilation)\n   o Fix test compilation with nmake: add the gdi.lib dependency (5ba8ab7)\n   o Whoops. It is gdi.lib, not gdi32.lib. (github issue #61) (8ab612e)\n   o Don't use return since return type is void and build error occurs\n     using clang (838161d Makoto Kato)\n   o Use void casts to suppress some \"unchecked return value\" warns (7080d55)\n   o rpcgen: Generate regress.gen.[c,h] in build rather than src dir\n     (243386c Ross Lagerwall)\n   o Fix a compiler warning when checking for arc4random_buf linker\n     breakage. (5cb3865)\n   o Fix 'make distcheck' by adding regress.gen.[ch] to DISTCLEANFILES\n    (239d834)\n\n   o Fix a c90 warning (c207682)\n   o Fix consts in WIN32-Code/getopt*.[ch] (57abb35)\n\n Bugfixes (locks, synchronization)\n   o Missed lock acquire/release in event_base_cancel_single_callback_()\n     (d3d999a Azat Khuzhin)\n   o Fix locking in bufferevent_get_options_(). (dbc9cd4 Maxime Henrion)\n\n Bugfixes (leaks)\n   o Avoid leaking segment mappings when offset is not a page multiple (d409514)\n\n Testing\n   o Add tests for evdns_base_resume(). (1cd9ff5 Azat Khuzhin)\n   o Fix dns/leak_resume_send_err test. (7e876df Azat Khuzhin)\n   o Add checks for evhttp_connection_get_server() in unit\n     tests. (fbc323b Maxime Henrion)\n   o Fix a (failure-only) null dereference in the unit tests (1104d0b)\n   o Fix a logic error in test_evbuffer_freeze (7765884)\n   o Add missing check to test_evbuffer_file_segment_add_cleanup_cb (eba4506)\n   o Fix some crash-on-fail cases in DNS regression tests (87cd6f0)\n   o DNS tests: add a missing check (f314900)\n   o Finalize tests: add a missing check (82b6956)\n   o test_evutil_rtrim: add another missing check. (e193c95)\n   o regress_main: logging all if env EVENT_DEBUG_LOGGING_ALL isset\n     (611e28b Azat Khuzhin)\n   o regress_http: add tests for evhttp_connection_get_addr() (4dd500c\n     Azat Khuzhin)\n   o Update to the latest version of tinytest (7a80476)\n   o Heap-allocate zlib data structure in regress_zlib tests (4947c18)\n\n Performance tweaks (core)\n   o Avoid redundant syscall to make a nonblocking socket nonblocking\n     (42c03da Maxime Henrion)\n   o Avoid redundant syscall if making a socket cloexec twice (1f29b18)\n   o Avoid redundant invocations of init_extension_functions for IOCP (3b77d62)\n\n Documentation\n   o Document that arc4random is not a great cryptographic PRNG. (6e49696)\n   o Small doxygen tweaks (6e67b51)\n   o Try another doxygen tweak (ccf432b)\n   o Clarify event_base_loop exit conditions (031a803)\n   o Fix a typo (be7bf2c Ondřej Kuzník)\n   o Document deferred eventcb behaviour (13a9a02 Ondřej Kuzník)\n   o Typo fixes from Linus Nordberg (cec62cb, 8cd695b)\n   o Fix duplicate paragraph in evbuffer_ptr documentation (58408ee)\n\n Code Improvements (coverity)\n   o Fix a pile of coverity warnings in the unit tests (867f401)\n   o Fix coverity warnings in benchmark tools. (ff7f739)\n   o Whoops; fix compilation in bench.c (544cf88)\n   o Remove spurious checks in evrpc.c error cases (coverity) (991b362)\n   o Fix a couple of compilation warnings in regress_http.c (860767e)\n   o Fix even more coverity warnings. (d240328)\n   o Stop checking for inet_aton; we don't use it. (f665d5c)\n   o Add an include to evrpc-internal to fix openbsd compilation warning\n     (5e161c6)\n\n Cleanups\n   o Remove an unreachable return statement in minheap-internal.h (e639a9e)\n   o Refactor evmap_{io,signal}_active_() to tolerate bad inputs (974c60e)\n   o Fix needless bufferevent includes in evdns.c (254c04e)\n   o Fix a couple of \"#ifdef WIN32\" instances (88ecda3)\n   o Remove unneeded declaration in bufferevent-internal.h (4c8ebcd)\n\n Sample code\n   o le-proxy: Fail more gracefully if opening listener fails (44b2491)\n   o http-server: drop uri_root from base_url in http-server. (6171e1c Azat Khuzhin)\n   o https-client: POST supported, args supported (c5887f7 Alexey Ozeritsky)\n   o https-client: code cleanup (29af65e Alexey Ozeritsky)\n   o https-client: Small tweaks to https-client.c (90786eb)\n   o https-client: Set hostname for SNI extension (by f69m) (d1976f8)\n   o https-client: add a cast to https-client.c (462e6b6)\n\n\n\nChanges in version 2.1.3-alpha (1 May 2013)\n\n Libevent 2.1.3-alpha fixes various bugs, adds new unit tests, and cleans\n up the code in a couple of places. It has a new callback in evhttp for\n reporting errors during a request, a new feature for allowing evdns to\n not keep the event_base looping when there are no requests inflight, and\n example code for writing an https client.\n\n Libevent 2.1.3-alpha also has an important new (experimental) event\n finalization feature to allow safe event teardown in multithreaded\n programs. This ought to fix the longstanding bug with deadlocks in\n multithreaded use of SSL-based bufferevents that some people have been\n experiencing since Libevent 2.0.\n\n\n Core (event finalization)\n   o Implement event_finalize() and related functions to avoid certain\n     deadlocks (8eedeab)\n   o Use finalization feature so bufferevents can avoid deadlocks (02fbf68)\n   o Always run pending finalizers when event_base_free() is called (e9ebef8)\n   o Remove bufferevent_del_generic_timeout_cbs as now unused (4ea4c6a)\n   o More documentation for finalization feature (a800b91)\n   o Make the event_finalize* functions return an error code (5d11f4f)\n   o Mark the finalize stuff as experimental in case it needs to\n     change (23e2e29)\n\n Evdns\n   o evdns: New flag to make evdns not prevent the event loop from\n     exiting (6b7fa62 Azat Khuzhin)\n\n Bugfixes (Core)\n   o Make event_remove_timer behave correctly with persistent timers (5623e80)\n   o Unit test for event_remove_timer with EV_PERSIST. (96150dd)\n   o Double-check next timeout when adding events (9443868 Nate Rosenblum)\n   o event_base_update_cache_time should be a no-op if the loop isn't\n     running (5e6fa2a)\n\n Bugfixes (evhttp, crash fix, from 2.0)\n   o fix #73 and fix http_connection_fail_test to catch it (b618204 Greg Hazel)\n\n Bugfixes (compilation and portability, from 2.0)\n   o Fix compilation with WIN32_HAVE_CONDITION_VARIABLES enabled (7e45739)\n   o Fix missing AC_PROG_SED on older Autoconfs (9ab2b3f Tay Ray Chuan)\n   o Backport libevent to vanilla Autoconf 2.59 (as used in RHEL5)\n     (74d4c44 Kevin Bowling)\n   o Use AC_CONFIG_HEADERS in place of AM_CONFIG_HEADERS for autmake\n     1.13 compat (817ea36)\n   o Rename configure.in to configure.ac to appease newer autoconfs (0c79787)\n   o Avoid using top_srcdir in TESTS: new automakes do not like this (a55514e)\n\n Bugfixes (resource leaks/lock errors on error, from 2.0)\n   o Avoid leaking fds on evconnlistener with no callback set (69db261)\n   o Avoid double-close on getsockname error in evutil_ersatz_socketpair\n     (0a822a6)\n   o Fix a locking error in bufferevent_socket_get_dns_error. (0a5eb2e)\n\n Documentation Fixes (from 2.0)\n   o Fix a mistake in evbuffer_remove() arguments in example http server code\n     (c322c20 Gyepi Sam)\n   o Fix a typo in a comment in buffer.h. Spotted by Alt_F4 (773b0a5)\n\n Documentation Fixes\n   o minor documentation typos (809586a Patrick Pelletier)\n   o Fix cut-and-paste err in whatsnew-2.1 (49905ac)\n   o Fix comment to refer to sample/include.am correctly (9e8cdf3 Sebastian\n     Hahn)\n   o Fix typo : Dispatching instead of Dispaching (0c2bacc Volker Lendecke)\n   o fix some hinky indentation in evhttp_make_request (80e220e Patrick\n     Pelletier)\n   o \"buffer\" spelling (a452811 Patrick Pelletier)\n   o Specify return behavior in header for evbuffer_pullup() in corner case\n     (cf8d1cd Dan Petro)\n   o Clarify an important point about event_base_foreach_event() (920a5e6)\n\n Compilation Fixes/Tool Support\n   o avoid valgrind false positive by zeroing epoll_event (1258614 Patrick\n     Pelletier)\n   o Fix harmless clang enum warning (b452a43 Sebastian Hahn)\n   o remove all exes on \"make clean\", not just regress.exe (974bfa0 Patrick\n     Pelletier)\n   o Make --disable-libevent-regress work again (787fd74)\n   o Do not build strlcpy.c when it will have no code. (4914620)\n\n Portability Fixes\n   o When EWOULDBLOCK is not EAGAIN, treat it as equivalent to it (bf7a0ff)\n   o Preliminary changes for Minix3. (0dda56a Nicholas Heath)\n   o Use AC_CONFIG_HEADERS in place of AM_CONFIG_HEADERS for autmake 1.13\n     compat (bf278b)\n   o Avoid using $(top_srcdir) in TESTS. (2863c83)\n   o build test/test-script.sh on systems with a less-featureful $< (f935e21)\n   o Implement EVUTIL_ERR_IS_EAGAIN on windows. (42aaf4d)\n\n Evhttp changes:\n   o Fix ipv6 support for http. When URL contain domain, not IP\n     address. (71e709c Azat Khuzhin)\n   o uri decode: fix for warning \"use of uninitialised value\" (64b6ece Azat\n     Khuzhin)\n   o uri decode: changed the test for the existence of the next character\n     (e1903e3 Azat Khuzhin)\n   o Move prototype of evhttp_decode_uri_internal() to http-internal.h\n     (de8101a Azat Khuzhin)\n   o Test: decoding just part of string with evhttp_decode_uri_internal()\n     (1367653 Azat Khuzhin)\n   o Add new error_cb for actual reporting of HTTP request errors. (7b07719\n     Azat Khuzhin)\n   o Add test for EVREQ_HTTP_REQUEST_CANCEL into http_cancel_test() (862c217\n     Azat Khuzhin)\n   o Drop extra header http_struct.h from regress_http.c (54cc800 Azat Khuzhin)\n\n Testing\n   o Add regress test ipv6_for_domain. (9ec88bd Azat Khuzhin)\n   o Add an environment variable (EVENT_DEBUG_MODE) to run unit tests in debug\n     mode (2fad0f3)\n   o Add a test with an active_later event at event_base_free time. (1c3147f)\n   o Make all tests pass under EVENT_DEBUG_MODE=1 (b1b054f)\n   o Add some verbose notes to bufferevent unit tests (9d893c9)\n   o New test for active_later->active transition on event_active (a153874)\n   o New tests for event_base_foreach_event() (0b096ef)\n   o Unit tests for event_base_gettimeofday_cached() and\n     event_base_update_cache_time() (30ea291)\n   o A test for event_get_assignment() (f09629e)\n   o More unit tests for initializing common timeouts. (d596739)\n   o Fix a bug in the new main/event_foreach test (702c9aa)\n\n Windows:\n   o use FormatMessage for winsock errors (0c6ec5d, 2078e9b, 4ccdd53, c9ad3af\n     Patrick Pelletier)\n   o a program to print out the error strings for winsock errors (7296512\n     Patrick Pelletier)\n   o Fix a warning introduced in 0c6ec5d8 (eeb700c)\n   o Fix another warning introduced in 0c6ec5d8 (ed26561)\n\n Examples (http)\n   o Add sample/https-client.c, an example of stacking evhttp as a client on\n     top of bufferevent_ssl. (be46c99 Catalin Patulea)\n   o use ${OPENSSL_LIBS} instead of -lssl -lcrypto (bf31fa5 Patrick Pelletier)\n   o https-client was putting newlines at 256-byte boundaries (42d7441 Patrick\n     Pelletier)\n   o better handling of OpenSSL errors (5754d96 Patrick Pelletier)\n   o use Debian's default root certificate location (aacd674 Patrick Pelletier)\n   o use iSECPartners code to validate hostname in certificate (64d9f16\n     Patrick Pelletier)\n   o avoid sign mismatch warning in openssl_hostname_validation.c (6021cb5\n     Patrick Pelletier)\n   o pull in wildcard matching code from cURL (4db9da6 Patrick Pelletier)\n   o Another tweak to https-client.c (95acdaa)\n   o Remove http_struct.h usage in sample/https-client.c (8a90a85)\n\n\n\nChanges in version 2.1.2-alpha (18 Nov 2012)\n\n Libevent 2.1.2-alpha includes more portable for monotonic timers,\n refactors much of Libevent's internal and external infrastructure,\n closes some longstanding gaps in the interface, makde other\n improvements.  Ths log below tries to organize features by rough area of\n effect.  It omits a few commits which were pure bugfixes on other commits\n listed below.  For more detail, see the git changelogs.  For more\n insight, see the \"whatsnew-2.1.txt\" document included in the Libevent\n 2.1.2-alpha distribution.\n\n Libevent 2.1.2-alpha also includes all changes made in 2.0.19-stable\n through 2.0.21-stable inclusive.\n\n Performance (core):\n   o Replace pipe-based notification with EVFILT_USER where possible. This\n     should make multithreaded programs on OSX and *BSD alert the main thread a\n     little faster. (53a07fe)\n   o Make th_base_lock nonrecursive. (9cd5acb)\n\n New/Changed API Functions:\n   o New event_get_priority() function to return an event's priority (f90e255)\n   o Add a bufferevent_get_priority() function (bd39554)\n   o Add an event_base_loopcontinue() to tell Libevent to rescan for more\n     events right away (7d6aa5e)\n   o Add a new callback to get called on evbuffer_file_segment free\n     (e9f8feb yangacer, 64051b9)\n   o Expose event_base_foreach_event() as a public API. (84fd6d7 Roman\n      Puls, 232055e, ffe1643)\n   o Add an event_remove_timer() to remove timer on an event without\n     deleting it (e3b2e08)\n   o Make bufferevent_set_timeouts(bev, NULL, NULL) have plausible\n     semantics (9dee36b)\n   o Rename event_enable_lock_debuging() to ..._debugging(). (The old name\n     should still work.) (07e132e)\n   o Add missing implementation for event_enable_debug_logging (3b3e21d)\n\n PORTABLE MONOTONIC TIMERS:\n\n   Libevent 2.1.2 includes internal support for monotonic timers on\n   (nearly) all supported platforms, including Windows, and OSX.  Libevent\n   applications should now be more resilient to jumps forwards or backwards\n   in the system clock.  Also, on Linux systems with epoll, we now\n   optionally support microsecond-level timeouts (whereas epoll only\n   supports millisecond-precision timeouts).\n\n   o Use mach_absolute_time() for monotonic clock support on OSX. (b8fd6f9)\n   o Do not track use_monotonic field when is no monotonic clock (cb653a0)\n   o EVENT_BASE_FLAG_PRECISE_TIMER indicates we want fine timer precision\n     (ddd69d3)\n   o On Linux, use CLOCK_MONOTONIC_COARSE by default (55780a7)\n   o Implement a GetTickCount-based monotonic timer for Windows (d5e1d5a)\n   o Refactor monotonic timer handling into a new type and set of\n     functions; add a gettimeofday-based ratcheting implementation (f5e4eb0)\n   o Add EVENT_PRECISE_TIMER environment var for selecting precise-but-slow\n     timer (a2598ec)\n   o Implement fast/precise monotonic clocks on Windows (2c47045)\n   o Simple unit tests for monotonic timers (630f077)\n   o Improve the monotonic-time unit test: make it check the step size (7428c78)\n   o When PRECISE_TIMERS is set with epoll, use timerfd for microsecond\n     precision (26c7582)\n   o Split out time-related evutil functions into a new evutil_time.c (c419485)\n   o Split out time-related prototypes into time-internal.h (71bca50)\n   o Add evutil_time.obj to Makefile.nmake (0ba0683)\n   o Avoid giving a spurious warning when timerfd support is unavailable\n     (1aaf9f0 Dave Hart)\n   o Make test_evutil_monotonic a little more tolerant (def3b83)\n   o Avoid unused-var warning on systems with clock_gettime but without\n     CLOCK_MONOTONIC_COARSE (9be5468)\n\nEVENT_BASE_ONCE LEAKS:\n   If a callback added by event_base_once() is never invoked, Libevent no\n   longer leaks internal memory.\n\n   o Free dangling event_once objects on event_base_free() (c17dd59)\n   o Add a unit test in which an event is created with event_base_once()\n     but never fires (4343edf)\n\nTESTING SUPPORT, FIXES AND IMPROVEMENTS:\n\n   Libevent now disables by default its unit tests that would touch the\n   network, or that tend to fail on heavily-loaded systems.  To re-enable\n   them, invoke the ./test/regress program with the @all alias.\n\n   o Simplify test.sh code significantly. (9b856fd Ross Lagerwall)\n   o Make all tests that hit the network disabled by default (f2cea87)\n   o Avoid a resource leak on error in http client benchmark (ea92fba)\n   o Update to latest tinytest (911b4f0349377) (ef7c4f7)\n   o Avoid (unlikely) overflow in bench_httpclient.c (5671033)\n   o Shave 700 msec off the persistent_timeout_jump test (21205b8)\n   o Check return value of write() in regress.c (c8009d2)\n   o Make load-dependent monotonic timer tests off-by-default (2b6fe8b)\n   o Add deferred_cb_skew to list of timing-dependent tests (34c8f31)\n   o Avoid test -e; older shs don't have one. (f1bd938)\n   o Fix renegotiation test to work around openssl 1.0.1 bug (c2f3086)\n   o Fix a couple of compile warnings in the unit tests (5a9a014)\n\nMISC:\n   o Change evutil_weakrand_() to avoid platform random() (e86af4b Nicholas\n     Marriott, 3aa4415)\n\nINFRASTRUCTURE (Active-later events):\n   As a simplification and optimization to Libevent's \"deferred callback\"\n   logic (introduced in 2.0 to avoid callback recursion), Libevent now\n   treats all of its deferrable callback types using the same logic it uses\n   for active events.  Now deferred events no longer cause priority\n   inversion, no longer require special code to cancel them, and so on.\n\n   o Refactor the callback part of an event into its own event_callback\n     type (cba59e5)\n   o Add \"active later\" event_callbacks to supersede deferred (745a63d)\n   o event_base_assert_ok: check value of event_active_count for\n     correctness (fec8bae)\n   o Replace deferred_cbs with event_callback-based implementation. (ae2b84b)\n   o Replace more deferred_cb names with event_callback (a4079aa)\n   o Give event_base_process_active a single exit path (581b5be)\n   o Restore our priority-inversion-prevention code with deferreds (c0e425a)\n   o Refactor event_persist_closure: raise and extract some common logic\n     (bec22b4)\n   o Remove the unused bits from EVLIST_ALL (9889a3d)\n||||||| merged common ancestors\nChanges in version 2.0.22-stable (?? Dec 2013)\n\n (As of 3b77d62829c4393bda6f9105a5d3b73b48a64b71.)\n\nBUGFIXES (evhttp)\n o fix #73 and fix http_connection_fail_test to catch it (crash fix) (b618204 Greg Hazel)\n o Avoid racy bufferevent activation (5eb1788 Nate Rosenblum)\n\nBUGFIXES (compilation and portability)\n o Fix compilation with WIN32_HAVE_CONDITION_VARIABLES enabled (7e45739)\n o Fix missing AC_PROG_SED on older Autoconfs (9ab2b3f Tay Ray Chuan)\n o Backport libevent to vanilla Autoconf 2.59 (as used in RHEL5) (74d4c44 Kevin Bowling)\n o Use AC_CONFIG_HEADERS in place of AM_CONFIG_HEADERS for autmake 1.13 compat (817ea36)\n o Rename configure.in to configure.ac to appease newer autoconfs (0c79787)\n o Avoid using top_srcdir in TESTS: new automakes do not like this (a55514e)\n o Use windows vsnprintf fixup logic on all windows environments (e826f19)\n o Fix a compiler warning when checking for arc4random_buf linker breakage. (5cb3865)\n o Fix another arc4random_buf-related warning (e64a2b0)\n\nBUGFIXES (resource leaks/lock errors on error)\n o Avoid leaking fds on evconnlistener with no callback set (69db261)\n o Avoid double-close on getsockname error in evutil_ersatz_socketpair (0a822a6)\n o Fix a locking error in bufferevent_socket_get_dns_error. (0a5eb2e)\n o libevent/win32_dealloc() : fix sizeof(pointer) vs sizeof(*pointer) (b8f5980 Frank Denis)\n\nBUGFIXES (miscellaneous)\n o Avoid other RNG initialization FS reads when urandom file is specified (9695e9c, bb52471)\n o Avoid redundant invocations of init_extension_functions for IOCP (3b77d62)\n\nBUFGIXES (evdns)\n o Checking request nameserver for NULL, before using it. (5c710c0 Belobrov Andrey)\n o Fix SEGFAULT after evdns_base_resume if no nameservers installed. (f8d7df8 Azat Khuzhin)\n\nBUGFIXES (evutil_secure_random)\n o When we seed from /proc/sys/kernel/random/uuid, count it as success (e35b540)\n o Document that arc4random is not a great cryptographic PRNG. (6e49696)\n o Add evutil_secure_rng_set_urandom_device_file (2bbb5d7)\n o Really remove RNG seeds from the stack (f5ced88)\n\n\nDOCUMENTATION FIXES\n o Fix a mistake in evbuffer_remove() arguments in example http server code (c322c20 Gyepi Sam)\n o Fix a typo in a comment in buffer.h. Spotted by Alt_F4 (773b0a5)\n\n\n\nChanges in version 2.0.21-stable (18 Nov 2012)\nBUGFIXES:\n o ssl: Don't discard SSL read event when timeout and read come close together (576b29f)\n o ssl: Stop looping in \"consider_reading\" if reading is suspended. (f719b8a Joachim Bauch)\n o ssl: No need to reserve space if reading is suspended. (1acf2eb Joachim Bauch)\n o dns: Avoid a memory-leak on OOM in evdns. (73e85dd, f2bff75 George Danchev)\n o build: Use python2 rather than python (0eb0109 Ross Lagerwall)\n o build: Compile without warnings on mingw64 (94866c2)\n o build: Fix compilation on mingw64 with -DUSE_DEBUG (62bd2c4)\n o build: Make rpcgen_wrapper.sh work on systems without a \"python2\" binary (f3009e4)\n o iocp: Close IOCP listener socket on free when LEV_OPT_CLOSE_ON_FREE is set (cb853ea Juan Pablo Fernandez)\n o core: Avoid crash when event_pending() called with no event_base set on event (e3cccf3)\n o misc: remove stray 'x' so print_err will compile when uncommented (ac35650 Patrick Pelletier)\n o tests: Fix renegotiation test to work around openssl 1.0.1 bug (c2f3086)\n o tests: Warn when openssl version in unit test mismatches compiled version. (ac009f9)\n\n\nChanges in version 2.0.20-stable (23 Aug 2012)\nBUGFIXES:\n o core: Make event_pending() threadsafe. (be7a95c Simon Liu)\n o win32: avoid crash when waiting forever on zero fds. (160e58b)\n o evhttp: Fix a memory leak on error in evhttp_uriencode (11c8b31)\n o evbuffer: Avoid possible needless call to writev. Found by coverity. (6a4ec5c)\n o evdns: memset sockaddr_in before using it. Found by coverity. (a1a0e67)\n o evhttp: Check more setsockopt return values when binding sockets. Found by coverity (a0912e3)\n o evdns: Avoid segfault on weird timeout during name lookup. (dc32077 Greg Hazel)\n o bufferevent_ssl: Correctly invoke callbacks when a SSL bufferevent reads some and then blocks. (606ac43)\n\n\nPORTABILITY FIXES:\n o check for arc4random_buf at runtime, on OS X (bff5f94 Greg Hazel)\n o Correctly check for arc4random_buf (fcec3e8 Sebastian Hahn)\n o Add explicit AC_PROG_SED to configure.in so all autoconfs will expose $(SED) (ca80ea6)\n\nBUILD FIXES:\n o Add GCC annotations so that the vsprintf functions get checked properly (117e327)\n o Fix an unused variable warning on *BSD. (c0720c1)\n\nUNIT TEST FIXES:\n o Fix a couple of memory leaks (found with Valgrind). (3b2529a Ross Lagerwall)\n o Remove deadcode in http regression tests. Found by coverity. (5553346)\n o Fix possible uninitialized read in dns regression tests. Found by coverity. (2259777)\n o Set umask before calling mkstemp in unit tests. Found by coverity (f1ce15d)\n o Fix various check-after-dereference issues in unit tests: found by coverity (4f3732d)\n o Fix resource leaks in the unit tests; found by coverity (270f279)\n o Add some missing null checks to unit tests; found by coverity (f021c3d)\n o Avoid more crashes/bad calls in unit tests; found by coverity (3cde5bf)\n o Remove unused variable; spotted by coverity (6355b2a)\n o Add checks to various return values in unit tests. Found by coverity (b9e7329)\n o Move assignment outside tt_assert in ssl unit tests. Appeases coverity. (a2006c0)\n\n\n\nChanges in version 2.0.19-stable (3 May 2012)\nBUGFIXES (CORE):\n o Refactor event_persist_closure: raise and extract some common logic (bec22b4)\n o If time has jumped so we'd reschedule a periodic event in the past, schedule it for the future instead (dfd808c)\n o If a higher-priority event becomes active, don't continue running events of the current priority. (2bfda40)\n\nBUGFIXES (SSL):\n o Fixed potential double-readcb execution with openssl bufferevents. (4e62cd1 Mark Ellzey)\n\nBUGFIXES (DNS):\n o Cancel a probe request when the server is freed, and ignore cancelled probe callbacks (94d2336 Greg Hazel)\n o Remove redundant DNS_ERR_CANCEL check, move comment (46b8060 Greg Hazel)\n o When retransmitting a timed-out DNS request, pick a fresh nameserver. (3d9e52a)\n\nDOCUMENTATION FIXES:\n o Fix a typo in the bufferevent documentation (98e9119)\n o Add missing ) to changelog; spotted by rransom (4c7ee6b)\n o Fix the website URL in the readme (f775521)\n\nCOMPILATION FIXES:\n o Fix a compilation error with MSVC 2005 due to use of mode_t (336dcae)\n o Configure with gcc older than 2.95 (4a6fd43 Sebastian Hahn)\n o Generate event-config.h with a single sed script (30b6f88 Zack Weinberg)\n\nFORWARD-COMPATIBILITY:\n o Backport: provide EVENT_LOG_* names, and deprecate _EVENT_LOG_* (d1a03b2)\n\nTESTING/DEBUGGING SUPPORT:\n o dns-example.c can now take a resolv.conf file on the commandline (6610fa5)\n o Make some evdns.c debug logs more verbose (d873d67)\n o Work-around a stupid gcov-breaking bug in OSX 10.6 (b3887cd)\n\n\n\nChanges in version 2.0.18-stable (22 Mar 2012)\nBUGFIXES (core):\n o Make uses of open() close-on-exec safe by introducing an internal evutil_open_closeonexec. (d2b5f72 Ross Lagerwall, 03dce42)\n\nBUGFIXES (kqueue):\n o Properly zero the kevent in kq_setup_kevent() (c2c7b39 Sebastian Hahn)\n\nBUILD FIXES:\n o Added OPENSSL_LDFLAGS env variable which is appended to SSL checks. (9278196 Mark Ellzey)\n o Changed OPENSSL_LDFLAGS to OPENSSL_LIBADD (2d67b63 Mark Ellzey)\n o Don't do clang version detection when disabling some flags (083296b Sebastian Hahn)\n\nBUGFIXES (dns):\n o Stop crashing in evdns when nameserver probes give a weird error (bec5068)\n\n\nChanges in version 2.0.17-stable (10 Feb 2012)\n\nBUGFIXES (core):\n o Be absolutely sure to clear pncalls before leaving event_signal_closure (11f36a5)\n o check for sysctl before we use it (358c745 Mike Frysinger)\n o Remove bogus casts of socket to int before calling ev_callback (f032516)\n o Make evconnlistener work around bug in older Linux when getting nmapped (ecfc720)\n o Fix a list corruption bug when using event_reinit() with signals present (6e41cdc)\n o Fix a fd leak in event_reinit() (3f18ad1)\n o Do a memberwise comparison of threading function tables (c94a5f2 Nate R)\n o Use C-style comments in C source files (for compatibility with compilers such as xlc on AIX). (d84d917 Greg Hewgill)\n o Avoid crash when freeing event_iocp and using event_set_mem_functions (19715a6)\n o In the kqueue backend, do not report EBADF as an EV_READ (5d7bfa1 Nicholas Marriott)\n\nBUGFIXES (evbuffer and bufferevents):\n o Fix behavior of evbuffer_peek(buf,-1,NULL,NULL,0) (c986f23 Zack Weinberg)\n o Loop on filtering SSL reads until we are blocked or exhausted. (5b4b812)\n\nBUGFIXES (evhttp):\n o Force strict validation of HTTP version in response. (790f6b3 Catalin Patulea)\n\nBUGFIXES (evdns):\n o evdns: fix a bug in circular-queue implementation (d6094b1)\n\nBUILD FIXES:\n o Fix a silly compilation error with the sun compiler (1927776 Colin Watt)\n o Suppress a gcc warning from ignoring fwrite return in http-sample.c (7206e8c)\n\nDOCUMENTATION FIXES:\n o Slightly clarify evbuffer_peek documentation (7bbf6ca)\n o Update copyright notices to 2012 (e49e289)\n\nNEW APIS:\n o Backport evhttp_connection_get_bufferevent to Libevent 2.0 (da70fa7 Arno Bakker)\n\nTESTS AND TEST FIXES:\n o Fix a race condition in the dns/bufferevent_connect_hostname test. (cba48c7)\n o Add function to check referential integrity of an event_base (27737d5)\n o Check event_base correctness at end of each unit test (3312b02)\n o Workaround in the unit tests for an apparent epoll bug in Linux 3.2 (dab9187)\n o Better workaround for Linux 3.2 edge-triggered epoll bug (9f9e259)\n\nChanges in version 2.0.16-stable (18 Nov 2011)\nBUGFIXES (core):\n o More detailed message in case of libevent self-debugging failure. (9e6a4ef Leonid Evdokimov)\n o epoll: close fd on alloc fail at initialization (1aee718 Jamie Iles)\n o Fix compile warning from saying event2/*.h inside a comment (447b0ba)\n o Warn when unable to construct base because of failing make_base_notifiable (4e797f3)\n o Don't try to make notifiable event_base when no threading fns are configured (e787413)\n\nBUGFIXES (evbuffer):\n o unit test for remove_buffer bug (90bd620 Greg Hazel)\n o Fix an evbuffer crash in evbuffer_remove_buffer() (c37069c)\n\nBUGFIXES (bufferevent_openssl):\n o Refactor amount-to-read calculations in buffervent_ssl consider_reading() (a186e73 Mark Ellzey)\n o Move SSL rate-limit enforcement into bytes_to_read() (96c562f)\n o Avoid spinning on OpenSSL reads (2aa036f Mark Ellzey)\n\nBUGFIXES (dns)\n o Empty DNS reply with OK status is another way to say NODATA. (21a08d6 Leonid Evdokimov)\n\nTESTING:\n o Tests for 94fba5b and f72e8f6 (d58c15e Leonid Evdokimov)\n o Test for commit aff6ba1 (f7841bf Leonid Evdokimov)\n o Style and comment tweaks for dns/leak* tests (5e42202)\n o improve test to remove at least one buffer from src (7eb52eb Greg Hazel)\n\nDOCUMENTATION:\n o Add note about evhttp_send_reply_end to its doxygen (724bfb5)\n o Update copyright dates to 2011. (3c824bd)\n o Fix typo in whatsnew-2.0.txt (674bc6a Mansour Moufid)\n o Improve win32 behavior of dns-sample.c code (a3f320e Gisle Vanem)\n\n\n\nChanges in version 2.0.15-stable (12 Oct 2011)\nBUGFIXES (DNS):\n o DNS: add ttl for negative answers using RFC 2308 idea. (f72e8f6 Leonid Evdokimov)\n o Add DNS_ERR_NODATA error code to handle empty replies. (94fba5b Leonid Evdokimov)\n\nBUFGIXES (bufferevents and evbuffers):\n o Make evbuffer callbacks get the right n_added value after evbuffer_add (1ef1f68 Alex)\n o Prefer mmap to sendfile unless a DRAINS_TO_FD flag is set. Allows add_file to work with SSL. (0ba0af9)\n\nBUGFIXES (event loop):\n o When a signal callback is activated to run multiple times, allow event_base_loopbreak to work even before they all have run. (4e8eb6a)\n\nDOCUMENTATION FIXES:\n o Fix docstring in dns.h (2b6eae5 Leonid Evdokimov)\n o refer to non-deprecated evdns functions in comments (ba5c27d Greg Hazel)\n\nBUILD AND TESTING FIXES:\n o le-proxy and regress depend on openssl directly (9ae061a Sergey Avseyev)\n o Use _SOURCES, not _sources, in sample/Makefile.am (7f82382)\n o Fixed compiler warnings for unchecked read/write calls. (c3b62fd Mark Ellzey)\n o Make write-checking fixes use tt_fail_perror (2b76847)\n o Fix some \"value never used\" warnings with gcc 4.6.1 (39c0cf7)\n\n\n\nChanges in version 2.0.14-stable (31 Aug 2011)\nBUGFIXES (bufferevents and evbuffers):\n o Propagate errors on the underlying bufferevent to the user. (4a34394 Joachim Bauch)\n o Ignore OpenSSL deprecation warnings on OS X (5d1b255 Sebastian Hahn)\n o Fix handling of group rate limits under 64 bytes of burst (6d5440e)\n o Solaris sendfile: correctly detect amount of data sent (643922e Michael Herf)\n o Make rate limiting work with common_timeout logic (5b18f13)\n o clear read watermark on underlying bufferevent when creating filtering bev to fix potentially failing fragmented ssl handshakes (54f7e61 Joachim Bauch)\n\nBUGFIXES (IOCP):\n o IOCP: don't launch reads or writes on an unconnected socket (495c227)\n o Make IOCP rate-limiting group support stricter and less surprising. (a98da7b)\n o Have test-ratelim.c support IOCP (0ff2c5a)\n o Make overlapped reads result in evbuffer callbacks getting invoked (6acfbdd)\n o Correctly terminate IO on an async bufferevent on bufferevent_free (e6af35d)\n\nBUGFIXES (other):\n o Fix evsig_dealloc memory leak with debugging turned on. (9b724b2 Leonid Evdokimov)\n o Fix request_finished memory leak with debugging turned on. (aff6ba1 Leonid Evdokimov)\n\nBUILD AND TESTING FIXES:\n o Allow OS-neutral builds for platforms where some versions have arc4random_buf (b442302 Mitchell Livingston)\n o Try to fix 'make distcheck' errors when building out-of-tree (04656ea Dave Hart)\n o Clean up some problems identified by Coverity. (7c11e51 Harlan Stenn)\n\n\nChanges in version 2.0.13-stable (18 Jul 2011)\nBUGFIXES\n o Avoid race-condition when initializing global locks (b683cae)\n o Fix bug in SSL bufferevents backed by a bev with a write high-watermarks (e050703 Joachim Bauch)\n o Speed up invoke_callbacks on evbuffers when there are no callbacks (f87f568 Mark Ellzey)\n o Avoid a segfault when all methods are disabled or broken (27ce38b)\n o Fix incorrect results from evbuffer_search_eol(EOL_LF) (4461f1a)\n o Add some missing checks for mm_calloc failures (89d5e09)\n o Replace an assertion for event_base_free(NULL) with a check-and-warn (09fe97d)\n o Report kqueue ebadf, epipe, and eperm as EV_READ events (1fd34ab)\n o Check if the `evhttp_new_object' function in `http.c' returns NULL. (446cc7a Mansour Moufid)\n o Use the correct printf args when formatting size_t (3203f88)\n o Complain if the caller tries to change threading cbs after setting them (cb6ecee)\n\nDOCUMENTATION FIXES AND IMPROVEMENTS\n o Revise the event/evbuffer/bufferevent doxygen for clarity and accuracy (2888fac)\n o Update Doxyfile to produce more useful output (aea0555)\n\nTEST FIXES\n o Fix up test_evutil_snprintf (caf695a)\n o Fix tinytest invocation from windows shell (57def34 Ed Day)\n\nBUILD FIXES\n o Use AM_CPPFLAGS in sample/Makefile.am, not AM_CFLAGS (4a5c82d)\n o Fix select.c compilation on systems with no NFDBITS (49d1136)\n o Fix a few warnings on OpenBSD (8ee9f9c Nicholas Marriott)\n o Don't break when building tests from git without python installed (b031adf)\n o Don't install event_rpcgen.py when --disable-libevent-install is used (e23cda3 Harlan Stenn)\n o Fix AIX build issue with TAILQ_FOREACH definition (e934096)\n\n\nChanges in version 2.0.12-stable (4 Jun 2011)\nBUGFIXES\n o Fix a warn-and-fail bug in kqueue by providing kevent() room to report errors (28317a0)\n o Fix an assert-inducing fencepost bug in the select backend (d90149d)\n o Fix failing http assertion introduced in commit 0d6622e (0848814 Kevin Ko)\n o Fix a bug that prevented us from configuring IPv6 nameservers. (74760f1)\n o Prevent size_t overflow in evhttp_htmlescape. (06c51cd Mansour Moufid)\n o Added several checks for under/overflow conditions in evhttp_handle_chunked_read (a279272 Mark Ellzey)\n o Added overflow checks in evhttp_read_body and evhttp_get_body (84560fc Mark Ellzey)\n\nDOCUMENTATION:\n o Add missing words to EVLOOP_NONBLOCK documentation (9556a7d)\n\nBUILD FIXES\n o libssl depends on libcrypto, not the other way around. (274dd03 Peter Rosin)\n o Libtool brings in the dependencies of libevent_openssl.la automatically (7b819f2 Peter Rosin)\n o Use OPENSSL_LIBS in Makefile.am (292092e Sebastian Hahn)\n o Move the win32 detection in configure.in (ceb03b9 Sebastian Hahn)\n o Correctly detect openssl on windows (6619385 Sebastian Hahn)\n o Fix a compile warning with zlib 1.2.4 and 1.2.5 (5786b91 Sebastian Hahn)\n o Fix compilation with GCC 2, which had no __builtin_expect (09d39a1 Dave Hart)\n o Fix new warnings from GCC 4.6 (06a714f)\n o Link with -lshell32 and -ladvapi32 on Win32. (86090ee Peter Rosin)\n o Make the tests build when OpenSSL is not available. (07c41be Peter Rosin)\n o Bring in the compile script from automake, if needed. (f3c7a4c Peter Rosin)\n o MSVC does not provide S_ISDIR, so provide it manually. (70be7d1 Peter Rosin)\n o unistd.h and sys/time.h might not exist. (fe93022 Peter Rosin)\n o Make sure TINYTEST_LOCAL is defined when building tinytest.c (8fa030c Peter Rosin)\n o Fix winsock2.h #include issues with MSVC (3d768dc Peter Rosin)\n o Use evutil_gettimeofday instead of relying on the system gettimeofday. (0de87fe Peter Rosin)\n o Always use evutil_snprintf, even if OS provides it (d1b2d11 Sebastian Hahn)\n o InitializeCriticalSectionAndSpinCount requires _WIN32_WINNT >= 0x0403. (816115a Peter Rosin)\n o cygwin: make it possible to build DLLs (d54d3fc)\n\n\n\nChanges in version 2.0.11-stable (27 Apr 2011)\n  [Autogenerated from the Git log, sorted and cleaned by hand.]\nBUGFIXES:\n o Fix evport handling of POLLHUP and POLLERR (b42ce4b)\n o Fix compilation on Windows with NDEBUG (cb8059d)\n o Check for POLLERR, POLLHUP and POLLNVAL for Solaris event ports (0144886 Trond Norbye)\n o Detect and handle more allocation failures. (666b096 Jardel Weyrich)\n o Use event_err() only if the failure is truly unrecoverable. (3f8d22a Jardel Weyrich)\n o Handle resize failures in the select backend better. (83e805a)\n o Correctly free selectop fields when select_resize fails in select_init (0c0ec0b)\n o Make --enable-gcc-warnings a no-op if not using gcc (3267703)\n o Fix a type error in our (unused) arc4random_stir() (f736198)\n o Correctly detect and stop non-chunked http requests when the body is too long (63a715e)\n o Have event_base_gettimeofday_cached() always return wall-clock time (a459ef7)\n o Workaround for http crash bug 3078187 (5dc5662 Tomash Brechko)\n o Fix incorrect assertions and possible use-after-free in evrpc_free() (4b8f02f Christophe Fillot)\n o Reset outgoing http connection when read data in idle state. (272823f Tomash Brechko)\n o Fix subtle recursion in evhttp_connection_cb_cleanup(). (218cf19 Tomash Brechko)\n o Fix the case when failed evhttp_make_request() leaved request in the queue. (0d6622e Tomash Brechko)\n o Fix a crash bug in evdns server circular list code (00e91b3)\n o Handle calloc failure in evdns. (Found by Dave Hart) (364291e)\n o Fix a memory leak on win32 socket->event map. (b4f89f0)\n o Add a forgotten NULL check to evhttp_parse_headers (12311ff Sebastian Hahn)\n o Fix possible NULL-deref in evdns_cancel_request (5208544 Sebastian Hahn)\n\nPORTABILITY:\n o Fall back to sscanf if we have no other way to implement strtoll (453317b)\n o Build correctly on platforms without sockaddr_storage (9184563)\n o Try to build correctly on platforms with no IPv6 support (713c254)\n o Build on systems without AI_PASSIVE (cb92113)\n o Fix http unit test on non-windows platforms without getaddrinfo (6092f12)\n o Do not check for gethostbyname_r versions if we have getaddrinfo (c1260b0)\n o Include arpa/inet.h as needed on HPUX (10c834c Harlan Stenn)\n o Include util-internal.h as needed to build on platforms with no sockaddr_storage (bbf5515 Harlan Stenn)\n o Check for getservbyname even if not on win32. (af08a94 Harlan Stenn)\n o Add -D_OSF_SOURCE to fix hpux builds (0b33479 Harlan Stenn)\n o Check for allocation failures in apply_socktype_protocol_hack (637d17a)\n o Fix the check for multicast or broadcast addresses in evutil_check_interfaces (1a21d7b)\n o Avoid a free(NULL) if out-of-memory in evdns_getaddrinfo. Found by Dave Hart (3417f68)\n\nDEFENSIVE PROGRAMMING:\n o Add compile-time check for AF_UNSPEC==PF_UNSPEC (3c8f4e7)\n\nBUGS IN TESTS:\n o Fix test.sh output on solaris (b4f89b6 Dave Hart)\n o Make test-eof fail with a timeout if we never get an eof. (05a2c22 Harlan Stenn)\n o Use %s with printf in test.sh (039b9bd)\n o Add an assert to appease clang's static analyzer (b0ff7eb Sebastian Hahn)\n o Add a forgotten return value check in the unit tests (3819b62 Sebastian Hahn)\n o Actually send NULL request in http_bad_request_test (b693c32 Sebastian Hahn)\n o add some (void) casts for unused variables (65707d7 Sebastian Hahn)\n o Refactor test_getaddrinfo_async_cancel_stress() (48c44a6 Sebastian Hahn)\n o Be nice and \"handle\" error return values in sample code (4bac793 Sebastian Hahn)\n o Check return value of evbuffer_add_cb in tests (93a1abb Sebastian Hahn)\n o Remote some dead code from dns-example.c (744c745 Sebastian Hahn)\n o Zero a struct sockaddr_in before using it (646f9fe Sebastian Hahn)\n\nBUILD FIXES:\n o Fix warnings about AC_LANG_PROGRAM usage (f663112 Sebastian Hahn)\n o Skip check for zlib if we have no zlib.h (a317c06 Harlan Stenn)\n o Fix autoconf bracket issues; make check for getaddrinfo include netdb.h (833e5e9 Harlan Stenn)\n o Correct an AM_CFLAGS to an AM_CPPFLAGS in test/Makefile.am (9c469db Dave Hart)\n o Fix make distcheck & installation of libevent 1 headers (b5a1f9f Dave Hart)\n o Fix compilation under LLVM/clang with --enable-gcc-warnings (ad9ff58 Sebastian Hahn)\n\nFEATURES:\n o Make URI parser able to tolerate nonconformant URIs. (95060b5)\n\nDOCUMENTATION:\n o Clarify event_set_mem_functions doc (926f816)\n o Correct evhttp_del_accept_socket documentation on whether socket is closed (f665924)\n o fix spelling mistake in whatsnew-2.0.txt (deb2f73)\n o Fix sample/http-server ipv6 fixes (eb692be)\n o Comment internal headers used in sample code. (4eb281c)\n o Be explicit about how long event loops run in event.h documentation (f95bafb)\n o Add comment to configure.in to explain gc-sections test logic (c621359)\n o Fix a couple of memory leaks in samples/http-server.c. Found by Dave Hart. (2e9f665)\n\n\n\nBUILD IMPROVEMENTS:\n Libevent 2.1.2-alpha modernizes Libevent's use of autotools, and makes\n numerous other build system. Parallel builds should be faster, and all\n builds should be quieter.\n\n   o Split long lists in Makefile.am into one-item-per-line (2711cda)\n   o Remove unnecessary code in configure.in. (e65914f Ross Lagerwall)\n   o attempt to support OpenSSL in Makefile.nmake (eba0eb2 Patrick Pelletier)\n   o Use newer syntax for autoconf/automake init (7d60ba8)\n   o Enable silent build rules by default. Override with V=1 (7b18e5c)\n   o Switch to non-recursive makefiles (7092f3b)\n   o Rename subordinate Makefile.ams to include.am (6cdfeeb)\n   o Make quiet build even quieter (371a123)\n   o New --quiet option for event_rpcgen.py (aa59c1e)\n   o Be quiet when making regress.gen.[ch] (607a8ff)\n   o Fix handling of no-python case for nonrecursive make (1e3123d)\n   o We now require automake 1.9 or later. Modernize! (b7f6e89)\n   o Rename configure.in to configure.ac. (b3fea67 Ross Lagerwall)\n   o Use correct openssl libs and includes in pkgconfig file (d70af27)\n   o Use the same CFLAGS for openssl when building unit tests as with\n     libevent (1d9d511)\n\nDOCUMENTATION\n   o Note that make_base_notifiable should not be necessary (26ee5f9)\n   o Be more clear that LEV_OPT_DEFERRED_ACCEPT has tricky prereqs (371efeb)\n   o Add caveat to docs about bufferevent_free() with data in outbuf (6fab9ee)\n   o Make it more clear that NOLOCK means \"I promise, no multithreading\"\n    (9444524)\n   o Fix a comment in test-fdleak after 077c7e949. (3881d8f Ross Lagerwall)\n   o Make the Makefile.nmake warning slightly less dire (e7bf4c8)\n   o Fix typo : events instead of evets (05f1aca Azat Khuzhin)\n   o Additional comments about OPENSSL_DIR variable, prompted by Dave Hart\n     (6bde2ef Patrick Pelletier)\n\nEVHTTP:\n   o ignore LWS after field-content in headers (370a2c0 Artem Germanov)\n   o Clean up rtrim implementation (aa59d80)\n   o Remove trailing tabs in HTTP headers as well. (ac42519)\n   o Remove internal ws from multiline http headers correctly (c6ff381)\n   o Move evutil_rtrim_lws_ to evutil.c where it belongs (61b93af)\n   o add evhttp_request_get_response_code_line (4f4d0c9 Jay R. Wren)\n   o Use EVUTIL_SOCKET_ERROR() wrapper to save/restore errno in\n     evhttp_connection_fail_ (7afbd60)\n   o preserve errno in evhttp_connection_fail_ for inspection by the\n     callback (36d0ee5 Patrick Pelletier)\n\nBUGFIXES:\n   o Correctly handle running on a system where accept4 doesn't work. (9fbfe9b)\n   o Avoid double-free on error in evbuffer_add_file. Found by\n     coverity. (6a81b1f)\n   o Fix another possible uninitialized read in dns regression tests. Found\n     by coverity. (13525c5)\n   o Add checks for functions in test-ratelim.c; found by Coverity (aa501e1)\n   o Avoid memory leak in test_event_calloc unit test; found by coverity\n     (92817a1)\n   o Fix a shadowed variable in addfile_test_readcb; found by coverity\n     (225344c)\n   o Check return value when using LEV_OPT_DEFERRED_ACCEPT. Found by\n     coverity (6487f63)\n   o Prevent reference leak of bufferevent if getaddrinfo fails. (b757786\n     Joachim Bauch)\n   o Make event_base_getnpriorities work with old \"implicit base\" code\n     (c46cb9c)\n   o Simplify and correct evutil_open_closeonexec_ (0de587f)\n   o Fix event_dlist definition when sys/queue not included (81b6209\n     Derrick Pallas)\n\n\n\nChanges in version 2.1.1-alpha (4 Apr 2012)\n\n Libevent 2.1.1-alpha includes a number of new features and performance\n improvements.  The log below tries to organize them by rough area of\n effect.  It omits some commits which were pure bugfixes on other commits\n listed below.  For more detail, see the git changelogs.  For more\n insight, see the \"whatsnew-2.1.txt\" document included in the Libevent\n 2.1.1-alpha distribution.\n\n Performance: Core\n   o Replace several TAILQ users with LIST. LIST can be a little faster than\n     TAILQ for cases where we don't need queue-like behavior. (f9db33d,\n     6494772, d313c29, 974d004)\n   o Disabled code to optimize the case where we reinsert an existing\n     timeout (e47042f, 09cbc3d)\n   o Remove a needless base-notify when rescheduling the first timeout (77a96fd)\n   o Save a needless comparison when removing/adjusting timeouts (dd5189b)\n   o Possible optimization: split event_queue_insert/remove into\n     separate functions. needs testing (efc4dc5)\n   o Make event_count maintenance branchless at the expense of an\n     extra shift. Needs benchmarking (d1cee3b)\n   o In the 2.1 branch, let's try out lazy gettimeofday/clock_gettime\n     comparison (2a83ecc)\n   o Optimization in event_process_active(): ignore maxcb & endtime\n     for highest priority events. (a9866aa Alexander Drozdov)\n   o Bypass event_add when using event_base_once() for a 0-sec timeout (35c5c95)\n   o Remove the eventqueue list and the ev_next pointers. (604569b 066775e)\n\n Performance: Evbuffers\n   o Roughly 20% speed increase when line-draining a buffer using\n     EVBUFFER_EOL_CRLF (5dde0f0 Mina Naguib)\n   o Try to squeeze a little more speed out of EVBUFFER_EOL_CRLF (7b9d139)\n   o Fix a bug in the improved EOL_CRLF code (d927965)\n   o Remove a needless branch in evbuffer_drain() (d19a326)\n\n Performance: Linux\n   o Infrastructure for using faster/fewer syscalls when creating\n     sockets (a1c042b)\n   o Minimize syscalls during socket creation in listener.c (7e9e289)\n   o Use a wrapper function to create the notification\n     pipe/socketpair/eventfd (ca76cd9)\n   o Use pipes for telling signals to main thread when possible (a35f396)\n   o Save syscalls when constructing listener sockets for evhttp (af6c9d8)\n   o Save some syscalls when creating evdns sockets (713e570)\n   o Save some syscalls when constructing a socket for a bufferevent (33fca62)\n   o Prefer epoll_create1 on Linuxen that have it (bac906c)\n\n Performance: Epoll backend\n   o Use current event set rather than current pending change when\n     deciding whether to no-op a del (04ba27e Mike Smellie)\n   o Replace big chain of if/thens in epoll.c with a table lookup (8c83eb6)\n   o Clean up error handling in epoll_apply_one_change() a little (2d55a19)\n\n Performance: Evport backend\n   o evport: use evmap_io to track fdinfo status. Should save time and\n     RAM. (4687ce4)\n   o evport: Remove a linear search over recent events when\n     reactivating them (0f77efe)\n   o evport: Use portev_user to remember fdinfo struct (276ec0e)\n   o evport: don't scan more events in ed_pending than needed (849a5cf)\n   o evport: Remove artificial low limit on max events per getn call (c04d927)\n   o Reenable main/many_events_slow_add for evport in 2.1 (e903db3)\n\n Performance: Windows\n   o Use GetSystemTimeAsFileTime to implement gettimeofday on\n     win32. It's faster and more accurate than our old\n     approach. (b8b8aa5)\n\n New functions and features: debugging\n   o Add event_enable_debug_logging() to control use of debug logs (e30a82f)\n\n New functions and features: core\n   o Add event_config function to limit time/callbacks between calls\n     to dispatch (fd4de1e, 9fa56bd, a37a0c0, 3c63edd)\n   o New EVLOOP_NO_EXIT_ON_EMPTY option to keep looping even when no\n     events are pending (084e68f)\n   o Add event_base_get_npriorities() function. (ee3a4ee Alexander Drozdov)\n   o Make evbase_priority_init() and evbase_get_npriorities()\n     threadsafe (3c55b5e)\n   o New event_base_update_cache_time() to set cached_tv to current\n     time (212533e Abel Mathew)\n   o Add event_self_cbarg() to be used in conjunction with\n     event_new(). (ed36e6a Ross Lagerwall, fa931bb, 09a1906, 1338e6c,\n     33e43ef)\n   o Add a new libevent_global_shutdown() to free all globals before\n     exiting. (041ca00 Mark Ellzey, f98c158, 15296d0, 55e991b)\n   o Use getifaddrs to detect our interfaces if possible (7085a45)\n   o Add event_base_get_running_event() to get the event* whose cb we\n     are in (c5732fd, 13dad99)\n\n New functions and features: building\n   o Implement --enable-gcc-hardening configure option (7550267 Sebastian Hahn)\n\n New functions and features: evbuffers\n   o Add evbuffer_add_file_segment() so one fd can be used efficiently\n     in more than one evbuffer_add_file at a time (e72afae, c2d9884,\n     3f405d2, 0aad014)\n   o Fix windows file segment mappings (8254de7)\n   o Allow evbuffer_ptr_set to yield a point just after the end of the\n     buffer. (e6fe1da)\n   o Allow evbuffer_ptr to point to position 0 in an empty evbuffer\n     (7aeb2fd Nir Soffer)\n   o Set the special \"not found\" evbuffer_ptr consistently. (e3e97ae Nir Soffer)\n   o support adding buffers to other buffers non-destructively\n     (9d7368a Joachim Bauch)\n   o prevent nested multicast references, reworked locking (26041a8\n     Joachim Bauch)\n   o New EVBUFFER_EOL_NUL to read NUL-terminated strings from an\n     evbuffer (d7a8b36 Andrea Montefusco, 54142c9)\n   o Make evbuffer_file_segment_types adaptable (c6bbbf1)\n   o Added evbuffer_add_iovec and unit tests. (aaec5ac Mark Ellzey, 27b5398)\n   o Add evbuffer_copyout_from to copy data from the middle of a\n     buffer (27e2225)\n\n New functions and features: bufferevents\n   o Allow users to set allow_dirty_shutdown (099d27d Catalin Patulea)\n   o Tweak allow_dirty_shutdown documentation (a44cd2b)\n   o Fix two issues in the allow_dirty_shutdown code. (f3b89de)\n   o Add a bufferevent_getcb() to find a bufferevent's current\n     callbacks (a650394)\n   o bufferevent: Add functions to set/get max_single_read/write\n     values. (998c813 Alexander Drozdov)\n   o bev_ssl: Be more specific in event callbacks. evhttp in particular gets\n     confused without at least one of BEV_EVENT_{READING|WRITING}. (f7eb69a\n     Catalin Patulea)\n\n New functions and features: evconnlisteners\n   o Support TCP_DEFER_ACCEPT sockopts for listeners (5880e4a Mark Ellzey,\n     a270728)\n   o Add another caveat to the TCP_DEFER_ACCEPT documentation (a270728)\n   o Allow evconnlistener to be created in disabled state. (9593a33\n     Alexander Drozdov)\n   o The LEV_OPT_CLOSE_ON_EXEC flag now applies to accepted listener\n     sockets too (4970329)\n\n Evhttp:\n   o Add new evhttp_{connection_}set_timeout_tv() functions to set\n     finger-grained http timeouts (6350e6c Constantine Verutin)\n   o Performance tweak to evhttp_parse_request_line. (aee1a97 Mark Ellzey)\n   o Add missing break to evhttp_parse_request_line (0fcc536)\n   o Add evhttp callback for bufferevent creation; this lets evhttp\n     support SSL. (8d3a850)\n   o Remove calls to deprecated bufferevent functions from evhttp.c (4d63758)\n   o evhttp: Add evhttp_foreach_bound_socket. (a2c48e3 Samy Al Bahra)\n\n Build improvements:\n   o Add AC_USE_SYSTEM_EXTENSIONS to configure.in. Requires follow on\n     patches for correctness and robustness. (1fa7dbe Kevin Bowling)\n   o Filter '# define' statements from autoconf and generate\n     event-private.h (321b558 Kevin Bowling)\n   o Remove internal usage of _GNU_SOURCE (3b26541 Kevin Bowling)\n   o Eliminate a couple more manual internal _GNU_SOURCE defines (c51ef93\n     Kevin Bowling)\n   o Add AC_GNU_SOURCE to the fallback case. (ea8fa4c Kevin Bowling)\n   o Use a Configuration Header Template for evconfig-private.h (868f888\n     Kevin Bowling)\n   o Fix a comment warning and add evconfig-private.h to .gitignore\n     (f6d66bc Kevin Bowling)\n   o Include evconfig-private.h in internal files for great good. (0915ca0\n     Kevin Bowling)\n   o Backport libevent to vanilla Autoconf 2.59 (as used in RHEL5)\n     (ad03952 Kevin Bowling)\n   o Prefer the ./configure evconfig-private.h in MinGW, just in\n     case. (f964b72 Kevin Bowling)\n   o Shell hack for weird mkdir -p commands (fd7b5a8 Kevin Bowling)\n   o Add evconfig-private to remaining files (ded0a09 Kevin Bowling)\n   o Allow use of --enable-silent-rules for quieter compilation with\n     automake 1.11 (f1f8514 Dave Hart)\n   o Use \"_WIN32\", not WIN32: it's standard and we don't need to fake it\n     (9f560b)\n   o In configure, test for _WIN32 not WIN32. (85078b1 Peter Rosin)\n   o Do not define WIN32 in Makefile.nmake (d41f3ea Peter Rosin)\n   o Provide the autoconf m4 macros for the new OpenSSL via pkg-config\n     stuff. (674dc3d Harlan Stenn)\n   o Use pkg-config (if available) to handle OpenSSL. (1c63860 Harlan Stenn)\n   o We need AM_CPPFLAGS when compiling bufferevent_openssl.c (6d2613b\n     Harlan Stenn)\n   o Fix OSX build: $(OPENSSL_INCS) needs to be after\n     $(AM_CPPFLAGS). (46f1769 Zack Weinberg)\n   o Make gcc warnings on by default, and --enable-gcc-warnings only add\n     -Werror (d46517e Sebastian Hahn)\n   o Split up extra-long AC_CHECK_FUNCS/HEADERS lines in configure.in (88a30ad)\n   o Move libevent 1.x headers to include/, to put all public headers in\n     one place. (bbea8d6)\n   o Put #ifdef around some files to support alternate build\n     systems. (76d4c92 Ross Lagerwall)\n   o Also make win32select.c conditional for IDE users (bf2c5a7)\n\n Debugging:\n   o Add a magic number to debug_locks to better catch lock-coding\n     errors. (b4a29c0 Dave Hart)\n   o munge the debug_lock signature before freeing it: it might help us\n     catch use-after-free (f28084d)\n   o Added --enable-event-debugging in configure (bc7b4e4, a9c2c9a Mark Ellzey)\n   o Debug addition for printing usec on TIMEOUT debugging. (ac43ce0 Mark Ellzey)\n   o Added usec debug in another area for debug (3baab0d Mark Ellzey)\n   o added timeout debug logs to include event ptr. (4b7d298 Mark Ellzey)\n   o more event dbg updates (6727543 Mark Ellzey)\n   o Clarify event_enable_debug_logging a little (6207826)\n   o Make --enable-verbose-debug option match its help text (10c3450)\n   o Add argument checks to some memory functions in `event.c'. (c8953d1\n     Mansour Moufid)\n\n Testing:\n   o More abstraction in test.sh (cd74c4e)\n   o Add failing test for evbuffer_search_range. (8e26154 Nir Soffer)\n   o Tweaks to return types with end-of-buf ptrs (9ab8ab8)\n   o Add an (internal) usleep function for use by unit tests (f25d9d3)\n   o Synchronize with upstream tinytest (6c81be7)\n   o Make test-changelist faster (7622d26)\n   o Reduce the timeout in the main/fork test. (ab14f7c)\n   o New evhttp function to adjust initial retry timeout (350a3c4)\n   o Make regression tests run over 3x faster. (67a1763)\n   o Use test_timeval_diff_eq more consistently (b77b43f)\n   o Allow more slop in deferred_cb_skew test; freebsd needs it (b9f7e5f)\n   o When including an -internal.h header outside the main tree, do so\n     early (95e2455)\n   o Add a new test: test-fdleak which tests for fd leaks by creating many\n     sockets. (2ef9278 Ross Lagerwall, f7af194, 1c4288f, etc)\n   o Add a unit test for event_base_dump_events() (7afe48a, 8d08cce)\n   o Test more bufferevent_ratelim features (c24f91a)\n\n Documentation:\n   o Improve evbuffer_ptr documentation (261ba63)\n   o added comments to describe refcounting of multicast chains (ba24f61\n     Joachim Bauch)\n   o Add doxygen for event_base_dump_events (cad5753)\n\n OSX:\n   o Use \"unlimited select\" on OSX so that we can have more than\n     FD_SETSIZE fds (1fb5cc6)\n\n KQueue:\n   o Use SIG_IGN instead of a do-nothing handler for signal events with\n     kqueue (148458e Zack Weinberg)\n\n evprc:\n   o event_rpcgen.py now prints status information to stdout and errors to\n     stderr. (ffb0ba0 Ross Lagerwall)\n\n Code improvement and refactoring:\n   o Make event_reinit() more robust and maintainable (272033e)\n   o Restore fast-path event_reinit() for slower backends (2c4b5de)\n   o Check changelist as part of checking representational integrity (39b3f38)\n   o Fix a compile warning in event_reinit (e4a56ed Sebastian Hahn)\n   o Refactor the functions that run over every event. (c89b4e6)\n   o Remove the last vestiges of _EVENT_USE_EVENTLIST (a3cec90)\n   o Make event-config.h depend on Makefile.am (2958a5c)\n\n Build fixes:\n   o Don't do clang version detection when disabling some flags (083296b\n     Sebastian Hahn)\n\n C standards conformance:\n   o Check for NULL return on win32 mm_calloc, and set ENOMEM. (af7ba69)\n   o Convert event-config.h macros to avoid reserved identifiers (68120d9)\n   o Generate event-config.h using the correct macros. (f82c57e)\n   o Convert include-guard macro convention to avoid reserved identifiers\n     (3f8c7cd)\n   o Make event_rpcgen.py output conform to identifier conventions (372bff1)\n   o Stop referring to an obsolete include guard in bench_http.h (5c0f7e0)\n   o Make the generated event-config.h use correct include guards (639383a)\n   o Fix all identifiers with names beginning with underscore. (cb9da0b)\n   o Make event_rpcgen.py output conform to identifier conventions, more\n     (bcefd24)\n   o Fix some problems introduced by automated identifier cleanup script\n     (c963534)\n   o Have all visible internal function names end with an underscore. (8ac3c4c)\n   o Apply the naming convention to our EVUTIL_IS* functions (c7848fa)\n   o Clean up lingering _identifiers. (946b584)\n   o Fix doxygen to use new macro conventions (da455e9)\n\n Bugfixes:\n   o Do not use system EAI/AI values if we are not using the system\n     getaddrinfo. (7bcac07)\n\n Sample Code:\n   o Fix up sample/event-test.c to use newer interfaces and make it\n     actually work. (19bab4f Ross Lagerwall)\n   o On Unix, remove event.fifo left by sample/event-test.c. (c0dacd2 Ross\n     Lagerwall)\n   o Rename event-test.c to event-read-fifo.c. (a5b370a Ross Lagerwall)\n   o event-read-fifo: Use EV_PERSIST appropriately (24dab0b)\n\n\n\n\n"
        },
        {
          "name": "Documentation",
          "type": "tree",
          "content": null
        },
        {
          "name": "Doxyfile",
          "type": "blob",
          "size": 10.287109375,
          "content": "# Doxyfile 1.5.1\n\n# This file describes the settings to be used by the documentation system\n# doxygen (www.doxygen.org) for a project\n#\n# All text after a hash (#) is considered a comment and will be ignored\n# The format is:\n#       TAG = value [value, ...]\n# For lists items can also be appended using:\n#       TAG += value [value, ...]\n# Values that contain spaces should be placed between quotes (\" \")\n\n#---------------------------------------------------------------------------\n# Project related configuration options\n#---------------------------------------------------------------------------\n\n# The PROJECT_NAME tag is a single word (or a sequence of words surrounded \n# by quotes) that should identify the project.\n\nPROJECT_NAME           = $(PROJECT)-$(VERSION)\n\n# Place all output under 'doxygen/'\n\nOUTPUT_DIRECTORY        = $(DOCDIR)\n\n# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen \n# will interpret the first line (until the first dot) of a JavaDoc-style \n# comment as the brief description. If set to NO, the JavaDoc \n# comments will behave just like the Qt-style comments (thus requiring an \n# explicit @brief command for a brief description.\n\nJAVADOC_AUTOBRIEF      = YES\n\n# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C \n# sources only. Doxygen will then generate output that is more tailored for C. \n# For instance, some of the names that are used will be different. The list \n# of all members will be omitted, etc.\n\nOPTIMIZE_OUTPUT_FOR_C  = YES\n\n# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the \n# brief documentation of file, namespace and class members alphabetically \n# by member name. If set to NO (the default) the members will appear in \n# declaration order.\n\nSORT_BRIEF_DOCS        = YES\n\n# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag \n# can be used to strip a user-defined part of the path. Stripping is \n# only done if one of the specified strings matches the left-hand part of \n# the path. The tag can be used to show relative paths in the file list. \n# If left blank the directory from which doxygen is run is used as the \n# path to strip.\n\nSTRIP_FROM_PATH        = $(SRCDIR)/include/\n\n#---------------------------------------------------------------------------\n# configuration options related to the input files\n#---------------------------------------------------------------------------\n\n# The INPUT tag can be used to specify the files and/or directories that contain \n# documented source files. You may enter file names like \"myfile.cpp\" or \n# directories like \"/usr/src/myproject\". Separate the files or directories \n# with spaces.\n\nINPUT                  = \\\n        $(SRCDIR)/include/event2/buffer.h \\\n        $(SRCDIR)/include/event2/buffer_compat.h \\\n        $(SRCDIR)/include/event2/bufferevent.h \\\n        $(SRCDIR)/include/event2/bufferevent_compat.h \\\n        $(SRCDIR)/include/event2/bufferevent_ssl.h \\\n        $(SRCDIR)/include/event2/dns.h \\\n        $(SRCDIR)/include/event2/dns_compat.h \\\n        $(SRCDIR)/include/event2/event.h \\\n        $(SRCDIR)/include/event2/event_compat.h \\\n        $(SRCDIR)/include/event2/http.h \\\n        $(SRCDIR)/include/event2/http_compat.h \\\n        $(SRCDIR)/include/event2/listener.h \\\n        $(SRCDIR)/include/event2/rpc.h \\\n        $(SRCDIR)/include/event2/rpc_compat.h \\\n        $(SRCDIR)/include/event2/tag.h \\\n        $(SRCDIR)/include/event2/tag_compat.h \\\n        $(SRCDIR)/include/event2/thread.h \\\n        $(SRCDIR)/include/event2/ws.h  \\\n        $(SRCDIR)/include/event2/util.h  \\\n        $(SRCDIR)/include/event2/watch.h\n\n#---------------------------------------------------------------------------\n# configuration options related to the HTML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will \n# generate HTML output.\n\nGENERATE_HTML          = $(GENERATE_HTML)\n\n#---------------------------------------------------------------------------\n# configuration options related to the LaTeX output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will \n# generate Latex output.\n\nGENERATE_LATEX         = $(GENERATE_LATEX)\n\n# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `latex' will be used as the default path.\n\nLATEX_OUTPUT           = latex\n\n# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be \n# invoked. If left blank `latex' will be used as the default command name.\n\nLATEX_CMD_NAME         = latex\n\n# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to \n# generate index for LaTeX. If left blank `makeindex' will be used as the \n# default command name.\n\nMAKEINDEX_CMD_NAME     = makeindex\n\n# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact \n# LaTeX documents. This may be useful for small projects and may help to \n# save some trees in general.\n\nCOMPACT_LATEX          = NO\n\n# The PAPER_TYPE tag can be used to set the paper type that is used \n# by the printer. Possible values are: a4, a4wide, letter, legal and \n# executive. If left blank a4wide will be used.\n\nPAPER_TYPE             = a4wide\n\n# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX \n# packages that should be included in the LaTeX output.\n\nEXTRA_PACKAGES         = \n\n# The LATEX_HEADER tag can be used to specify a personal LaTeX header for \n# the generated latex document. The header should contain everything until \n# the first chapter. If it is left blank doxygen will generate a \n# standard header. Notice: only use this tag if you know what you are doing!\n\nLATEX_HEADER           = \n\n# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated \n# is prepared for conversion to pdf (using ps2pdf). The pdf file will \n# contain links (just like the HTML output) instead of page references \n# This makes the output suitable for online browsing using a pdf viewer.\n\nPDF_HYPERLINKS         = NO\n\n# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of \n# plain latex in the generated Makefile. Set this option to YES to get a \n# higher quality PDF documentation.\n\nUSE_PDFLATEX           = YES\n\n# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\\\batchmode. \n# command to the generated LaTeX files. This will instruct LaTeX to keep \n# running if errors occur, instead of asking the user for help. \n# This option is also used when generating formulas in HTML.\n\nLATEX_BATCHMODE        = NO\n\n# If LATEX_HIDE_INDICES is set to YES then doxygen will not \n# include the index chapters (such as File Index, Compound Index, etc.) \n# in the output.\n\nLATEX_HIDE_INDICES     = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the man page output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_MAN tag is set to YES (the default) Doxygen will \n# generate man pages\n\nGENERATE_MAN           = $(GENERATE_MAN)\n\n# The MAN_EXTENSION tag determines the extension that is added to \n# the generated man pages (default is the subroutine's section .3)\n\nMAN_EXTENSION          = .3\n\n# If the MAN_LINKS tag is set to YES and Doxygen generates man output, \n# then it will generate one additional man file for each entity \n# documented in the real man page(s). These additional files \n# only source the real man page, but without them the man command \n# would be unable to find the correct page. The default is NO.\n\nMAN_LINKS              = NO\n\n#---------------------------------------------------------------------------\n# Configuration options related to the preprocessor   \n#---------------------------------------------------------------------------\n\n# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will \n# evaluate all C-preprocessor directives found in the sources and include \n# files.\n\nENABLE_PREPROCESSING   = YES\n\n# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro \n# names in the source code. If set to NO (the default) only conditional \n# compilation will be performed. Macro expansion can be done in a controlled \n# way by setting EXPAND_ONLY_PREDEF to YES.\n\nMACRO_EXPANSION        = NO\n\n# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES \n# then the macro expansion is limited to the macros specified with the \n# PREDEFINED and EXPAND_AS_DEFINED tags.\n\nEXPAND_ONLY_PREDEF     = NO\n\n# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files \n# in the INCLUDE_PATH (see below) will be search if a #include is found.\n\nSEARCH_INCLUDES        = YES\n\n# The INCLUDE_PATH tag can be used to specify one or more directories that \n# contain include files that are not input files but should be processed by \n# the preprocessor.\n\nINCLUDE_PATH           = \n\n# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard \n# patterns (like *.h and *.hpp) to filter out the header-files in the \n# directories. If left blank, the patterns specified with FILE_PATTERNS will \n# be used.\n\nINCLUDE_FILE_PATTERNS  = \n\n# The PREDEFINED tag can be used to specify one or more macro names that \n# are defined before the preprocessor is started (similar to the -D option of \n# gcc). The argument of the tag is a list of macros of the form: name \n# or name=definition (no spaces). If the definition and the = are \n# omitted =1 is assumed. To prevent a macro definition from being \n# undefined via #undef or recursively expanded use the := operator \n# instead of the = operator.\n\nPREDEFINED             = TAILQ_ENTRY RB_ENTRY EVENT_DEFINED_TQENTRY_ EVENT_IN_DOXYGEN_\n\n# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then \n# this tag can be used to specify a list of macro names that should be expanded. \n# The macro definition that is found in the sources will be used. \n# Use the PREDEFINED tag if you want to use a different macro definition.\n\nEXPAND_AS_DEFINED      = \n\n# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then \n# doxygen's preprocessor will remove all function-like macros that are alone \n# on a line, have an all uppercase name, and do not end with a semicolon. Such \n# function macros are typically used for boiler-plate code, and will confuse \n# the parser if not removed.\n\nSKIP_FUNCTION_MACROS   = YES\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 6.5927734375,
          "content": "Libevent is available for use under the following license, commonly known\nas the 3-clause (or \"modified\") BSD license:\n\n==============================\nCopyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2007-2012 Niels Provos and Nick Mathewson\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the distribution.\n3. The name of the author may not be used to endorse or promote products\n   derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\nOF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\nIN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\nNOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\nTHIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n==============================\n\nPortions of Libevent are based on works by others, also made available by\nthem under the three-clause BSD license above.  The copyright notices are\navailable in the corresponding source files; the license is as above.  Here's\na list:\n\nlog.c:\n   Copyright (c) 2000 Dug Song <dugsong@monkey.org>\n   Copyright (c) 1993 The Regents of the University of California.\n\nstrlcpy.c:\n   Copyright (c) 1998 Todd C. Miller <Todd.Miller@courtesan.com>\n\nwin32select.c:\n   Copyright (c) 2003 Michael A. Davis <mike@datanerds.net>\n\nevport.c:\n   Copyright (c) 2007 Sun Microsystems\n\nht-internal.h:\n   Copyright (c) 2002 Christopher Clark\n\nminheap-internal.h:\n   Copyright (c) 2006 Maxim Yegorushkin <maxim.yegorushkin@gmail.com>\n\n==============================\n\nThe arc4module is available under the following, sometimes called the\n\"OpenBSD\" license:\n\n   Copyright (c) 1996, David Mazieres <dm@uun.org>\n   Copyright (c) 2008, Damien Miller <djm@openbsd.org>\n\n   Permission to use, copy, modify, and distribute this software for any\n   purpose with or without fee is hereby granted, provided that the above\n   copyright notice and this permission notice appear in all copies.\n\n   THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n   WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n   MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n   ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n   WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n   ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n   OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n==============================\n\nThe Windows timer code is based on code from libutp, which is\ndistributed under this license, sometimes called the \"MIT\" license.\n\n\nCopyright (c) 2010 BitTorrent, Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\n==============================\n\nThe wepoll module is available under the following, sometimes called the\n\"FreeBSD\" license:\n\nCopyright 2012-2020, Bert Belder <bertbelder@gmail.com>\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n  * Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n  * Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n==============================\n\nThe ssl-client-mbedtls.c is available under the following license:\n\nCopyright (C) 2006-2015, ARM Limited, All Rights Reserved\nSPDX-License-Identifier: Apache-2.0\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may\nnot use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis file is part of mbed TLS (https://tls.mbed.org)\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 10.123046875,
          "content": "# Makefile.am for libevent\n# Copyright 2000-2007 Niels Provos\n# Copyright 2007-2012 Niels Provos and Nick Mathewson\n#\n# See LICENSE for copying information.\n\nACLOCAL_AMFLAGS = -I m4\n\n# This is the \"Release\" of the Libevent ABI.  It takes precedence over\n# the VERSION_INFO, so that two versions of Libevent with the same\n# \"Release\" are never binary-compatible.\n#\n# This number incremented once for the 2.0 release candidate, and\n# will increment for each series until we revise our interfaces enough\n# that we can seriously expect ABI compatibility between series.\n#\nRELEASE = -release 2.2\n\n# This is the version info for the libevent binary API.  It has three\n# numbers:\n#   Current  -- the number of the binary API that we're implementing\n#   Revision -- which iteration of the implementation of the binary\n#               API are we supplying?\n#   Age      -- How many previous binary API versions do we also\n#               support?\n#\n# To increment a VERSION_INFO (current:revision:age):\n#    If the ABI didn't change:\n#        Return (current:revision+1:age)\n#    If the ABI changed, but it's backward-compatible:\n#        Return (current+1:0:age+1)\n#    If the ABI changed and it isn't backward-compatible:\n#        Return (current+1:0:0)\n#\n# Once an RC is out, DO NOT MAKE ANY ABI-BREAKING CHANGES IN THAT SERIES\n# UNLESS YOU REALLY REALLY HAVE TO.\nVERSION_INFO = 1:0:0\n\n# History:          RELEASE    VERSION_INFO\n#  2.0.1-alpha --     2.0        1:0:0\n#  2.0.2-alpha --                2:0:0\n#  2.0.3-alpha --                2:0:0  (should have incremented; didn't.)\n#  2.0.4-alpha --                3:0:0\n#  2.0.5-beta  --                4:0:0\n#  2.0.6-rc    --     2.0        2:0:0\n#  2.0.7-rc    --     2.0        3:0:1\n#  2.0.8-rc    --     2.0        4:0:2\n#  2.0.9-rc    --     2.0        5:0:0 (ABI changed slightly)\n#  2.0.10-stable--    2.0        5:1:0 (No ABI change)\n#  2.0.11-stable--    2.0        6:0:1 (ABI changed, backward-compatible)\n#  2.0.12-stable--    2.0        6:1:1 (No ABI change)\n#  2.0.13-stable--    2.0        6:2:1 (No ABI change)\n#  2.0.14-stable--    2.0        6:3:1 (No ABI change)\n#  2.0.15-stable--    2.0        6:3:1 (Forgot to update :( )\n#  2.0.16-stable--    2.0        6:4:1 (No ABI change)\n#  2.0.17-stable--    2.0        6:5:1 (No ABI change)\n#  2.0.18-stable--    2.0        6:6:1 (No ABI change)\n#  2.0.19-stable--    2.0        6:7:1 (No ABI change)\n#  2.0.20-stable--    2.0        6:8:1 (No ABI change)\n#  2.0.21-stable--    2.0        6:9:1 (No ABI change)\n#\n# For Libevent 2.1:\n#  2.1.1-alpha --     2.1        1:0:0\n#  2.1.2-alpha --     2.1        1:0:0 (should have been 2:0:1)\n#  2.1.3-alpha --     2.1        3:0:0 (ABI changed slightly)\n#  2.1.4-alpha --     2.1        4:0:0 (ABI changed slightly)\n#  2.1.5-beta  --     2.1        5:0:0 (ABI changed slightly)\n#  2.1.6-beta  --     2.1        6:0:0 (ABI changed slightly)\n#  2.1.7-beta  --     2.1        6:1:0 (ABI changed slightly)\n#  2.1.8-stable--     2.1        6:2:0 (ABI changed slightly)\n#\n# For Libevent 2.2:\n#  2.2.1-alpha --     2.2        1:0:0\n\n# ABI version history for this package effectively restarts every time\n# we change RELEASE.  Version 1.4.x had RELEASE of 1.4.\n#\n# Ideally, we would not be using RELEASE at all; instead we could just\n# use the VERSION_INFO field to label our backward-incompatible ABI\n# changes, and those would be few and far between.  Unfortunately,\n# Libevent still exposes far too many volatile structures in its\n# headers, so we pretty much have to assume that most development\n# series will break ABI compatibility.  For now, it's simplest just to\n# keep incrementing the RELEASE between series and resetting VERSION_INFO.\n#\n# Eventually, when we get to the point where the structures in the\n# headers are all non-changing (or not there at all!), we can shift to\n# a more normal worldview where backward-incompatible ABI changes are\n# nice and rare.  For the next couple of years, though, 'struct event'\n# is user-visible, and so we can pretty much guarantee that release\n# series won't be binary-compatible.\n\nif INSTALL_LIBEVENT\ndist_bin_SCRIPTS = event_rpcgen.py\nendif\n\npkgconfigdir=$(libdir)/pkgconfig\nLIBEVENT_PKGCONFIG=libevent.pc libevent_core.pc libevent_extra.pc\n\n# These sources are conditionally added by configure.ac or conditionally\n# included from other files.\nPLATFORM_DEPENDENT_SRC = \\\n\tarc4random.c \\\n\tbufferevent_ssl.c \\\n\tepoll_sub.c \\\n\tPrivacyInfo.xcprivacy \\\n\ttest/regress_ssl.c\n\nCMAKE_FILES = \\\n\tcmake/AddCompilerFlags.cmake \\\n\tcmake/AddLinkerFlags.cmake \\\n\tcmake/AddEventLibrary.cmake \\\n\tcmake/CheckConstExists.cmake \\\n\tcmake/CheckFileOffsetBits.c \\\n\tcmake/CheckFileOffsetBits.cmake \\\n\tcmake/CheckFunctionKeywords.cmake \\\n\tcmake/CheckPrototypeDefinition.c.in \\\n\tcmake/CheckPrototypeDefinition.cmake \\\n\tcmake/CheckWorkingKqueue.cmake \\\n\tcmake/CodeCoverage.cmake \\\n\tcmake/COPYING-CMAKE-SCRIPTS \\\n\tcmake/Copyright.txt \\\n\tcmake/FindMbedTLS.cmake \\\n\tcmake/LibeventConfig.cmake.in \\\n\tcmake/LibeventConfigVersion.cmake.in \\\n\tcmake/Macros.cmake \\\n\tcmake/Uninstall.cmake.in \\\n\tcmake/UseDoxygen.cmake \\\n\tcmake/VersionViaGit.cmake \\\n\tevent-config.h.cmake \\\n\tevconfig-private.h.cmake \\\n\tCMakeLists.txt\n\nDOCUMENTATION_FILES = \\\n\tDocumentation/Building.md\n\nEXTRA_DIST = \\\n\tChangeLog-1.4 \\\n\tChangeLog-2.0 \\\n\tChangeLog-2.1 \\\n\tChangeLog \\\n\tDoxyfile \\\n\tLICENSE \\\n\tautogen.sh \\\n\tevent_rpcgen.py \\\n\tlibevent.pc.in \\\n\tmake-event-config.sed \\\n\twhatsnew-2.0.txt \\\n\twhatsnew-2.1.txt \\\n\tREADME.md \\\n\t$(CMAKE_FILES) \\\n\t$(DOCUMENTATION_FILES) \\\n\t$(PLATFORM_DEPENDENT_SRC)\n\nLIBEVENT_LIBS_LA = libevent.la libevent_core.la libevent_extra.la\nif PTHREADS\nLIBEVENT_LIBS_LA += libevent_pthreads.la\nLIBEVENT_PKGCONFIG += libevent_pthreads.pc\nendif\nif OPENSSL\nLIBEVENT_LIBS_LA += libevent_openssl.la\nLIBEVENT_PKGCONFIG += libevent_openssl.pc\nendif\nif MBEDTLS\nLIBEVENT_LIBS_LA += libevent_mbedtls.la\nLIBEVENT_PKGCONFIG += libevent_mbedtls.pc\nendif\n\nif INSTALL_LIBEVENT\nlib_LTLIBRARIES = $(LIBEVENT_LIBS_LA)\npkgconfig_DATA = $(LIBEVENT_PKGCONFIG)\nelse\nnoinst_LTLIBRARIES =  $(LIBEVENT_LIBS_LA)\nendif\n\nEXTRA_SOURCE=\nnoinst_HEADERS=\nnoinst_PROGRAMS=\nEXTRA_PROGRAMS=\nCLEANFILES=\nDISTCLEANFILES=\nBUILT_SOURCES =\ninclude include/include.am\ninclude sample/include.am\ninclude test/include.am\n\nif BUILD_WIN32\n\nSYS_CORE_LIBS = -liphlpapi\nSYS_LIBS = -lws2_32 -lshell32 -ladvapi32 -lbcrypt\nSYS_SRC = win32select.c buffer_iocp.c event_iocp.c \\\n\tbufferevent_async.c\nSYS_INCLUDES = -IWIN32-Code\n\nif THREADS\nSYS_SRC += evthread_win32.c\nendif\n\nelse\n\nSYS_CORE_LIBS =\nSYS_LIBS =\nSYS_SRC =\nSYS_INCLUDES =\n\nendif\n\nif STRLCPY_IMPL\nSYS_SRC += strlcpy.c\nendif\nif SELECT_BACKEND\nSYS_SRC += select.c\nendif\nif POLL_BACKEND\nSYS_SRC += poll.c\nendif\nif DEVPOLL_BACKEND\nSYS_SRC += devpoll.c\nendif\nif KQUEUE_BACKEND\nSYS_SRC += kqueue.c\nendif\nif EPOLL_BACKEND\nSYS_SRC += epoll.c\nendif\nif EVPORT_BACKEND\nSYS_SRC += evport.c\nendif\nif WEPOLL_BACKEND\nSYS_SRC += epoll.c\nSYS_SRC += wepoll.c\nendif\nif SIGNAL_SUPPORT\nSYS_SRC += signal.c\nendif\nif SIGNALFD_SUPPORT\nSYS_SRC += signalfd.c\nendif\n\nBUILT_SOURCES += include/event2/event-config.h\n\ninclude/event2/event-config.h: config.h make-event-config.sed\n\t$(AM_V_GEN)test -d include/event2 || $(MKDIR_P) include/event2\n\t$(AM_V_at)$(SED) -f $(srcdir)/make-event-config.sed < config.h > $@T\n\t$(AM_V_at)mv -f $@T $@\n\nCORE_SRC =\t\t\t\t\t\\\n\tbuffer.c\t\t\t\t\\\n\tbufferevent.c\t\t\t\t\\\n\tbufferevent_filter.c\t\t\t\\\n\tbufferevent_pair.c\t\t\t\\\n\tbufferevent_ratelim.c\t\t\t\\\n\tbufferevent_sock.c\t\t\t\\\n\tevent.c\t\t\t\t\t\\\n\tevmap.c\t\t\t\t\t\\\n\tevthread.c\t\t\t\t\\\n\tevutil.c\t\t\t\t\\\n\tevutil_rand.c\t\t\t\t\\\n\tevutil_time.c\t\t\t\t\\\n\twatch.c\t\t\t\t\t\\\n\tlistener.c\t\t\t\t\\\n\tlog.c\t\t\t\t\t\\\n\t$(SYS_SRC)\n\nEXTRAS_SRC =\t\t\t\t\t\\\n\tevdns.c\t\t\t\t\t\\\n\tevent_tagging.c\t\t\t\t\\\n\tevrpc.c\t\t\t\t\t\\\n\tsha1.c\t\t\t\t\t\\\n\tws.c\t\t\t\t\t\\\n\thttp.c\n\nif BUILD_WITH_NO_UNDEFINED\nNO_UNDEFINED = -no-undefined\nMAYBE_CORE = libevent_core.la\nelse\nNO_UNDEFINED =\nMAYBE_CORE =\nendif\n\nAM_CFLAGS = $(LIBEVENT_CFLAGS)\nAM_CPPFLAGS = -I$(srcdir)/compat -I./include -I$(srcdir)/include $(SYS_INCLUDES) $(LIBEVENT_CPPFLAGS)\nAM_LDFLAGS = $(LIBEVENT_LDFLAGS)\n\nGENERIC_LDFLAGS = -version-info $(VERSION_INFO) $(RELEASE) $(NO_UNDEFINED) $(AM_LDFLAGS)\n\nlibevent_la_SOURCES = $(CORE_SRC) $(EXTRAS_SRC)\nlibevent_la_LIBADD = @LTLIBOBJS@ $(SYS_LIBS) $(SYS_CORE_LIBS)\nlibevent_la_LDFLAGS = $(GENERIC_LDFLAGS)\n\nlibevent_core_la_SOURCES = $(CORE_SRC)\nlibevent_core_la_LIBADD = @LTLIBOBJS@ $(SYS_LIBS) $(SYS_CORE_LIBS)\nlibevent_core_la_LDFLAGS = $(GENERIC_LDFLAGS)\n\nif PTHREADS\nlibevent_pthreads_la_SOURCES = evthread_pthread.c\nlibevent_pthreads_la_LIBADD = $(MAYBE_CORE)\nlibevent_pthreads_la_LDFLAGS = $(GENERIC_LDFLAGS)\nendif\n\nlibevent_extra_la_SOURCES = $(EXTRAS_SRC)\nlibevent_extra_la_LIBADD = $(MAYBE_CORE) $(SYS_LIBS)\nlibevent_extra_la_LDFLAGS = $(GENERIC_LDFLAGS)\n\nif OPENSSL\nlibevent_openssl_la_SOURCES = bufferevent_openssl.c bufferevent_ssl.c\nlibevent_openssl_la_LIBADD = $(MAYBE_CORE) $(OPENSSL_LIBS)\nlibevent_openssl_la_LDFLAGS = $(GENERIC_LDFLAGS)\nlibevent_openssl_la_CPPFLAGS = $(AM_CPPFLAGS) $(OPENSSL_INCS)\nendif\n\nif MBEDTLS\nlibevent_mbedtls_la_SOURCES = bufferevent_mbedtls.c bufferevent_ssl.c\nlibevent_mbedtls_la_LIBADD = $(MAYBE_CORE) $(MBEDTLS_LIBS)\nlibevent_mbedtls_la_LDFLAGS = $(GENERIC_LDFLAGS)\nlibevent_mbedtls_la_CPPFLAGS = $(AM_CPPFLAGS) $(MBEDTLS_INCS)\nendif\n\nnoinst_HEADERS +=\t\t\t\t\\\n\tWIN32-Code/getopt.h\t\t\t\\\n\tWIN32-Code/getopt.c\t\t\t\\\n\tWIN32-Code/getopt_long.c\t\\\n\tWIN32-Code/tree.h\t\t\t\\\n\tbufferevent-internal.h\t\t\\\n\tchangelist-internal.h\t\t\\\n\tcompat/sys/queue.h\t\t\t\\\n\tcompat/sys/tree.h\t\t\t\\\n\tdefer-internal.h\t\t\t\\\n\tepolltable-internal.h\t\t\\\n\tevbuffer-internal.h\t\t\t\\\n\tevent-internal.h\t\t\t\\\n\tevmap-internal.h\t\t\t\\\n\tevrpc-internal.h\t\t\t\\\n\tevsignal-internal.h\t\t\t\\\n\tevthread-internal.h\t\t\t\\\n\tevdns-internal.h\t\t\t\\\n\tht-internal.h\t\t\t\t\\\n\thttp-internal.h\t\t\t\t\\\n\tiocp-internal.h\t\t\t\t\\\n\tipv6-internal.h\t\t\t\t\\\n\tkqueue-internal.h\t\t\t\\\n\tlog-internal.h\t\t\t\t\\\n\tminheap-internal.h\t\t\t\\\n\tmm-internal.h\t\t\t\t\\\n\tratelim-internal.h\t\t\t\\\n\tratelim-internal.h\t\t\t\\\n\tstrlcpy-internal.h\t\t\t\\\n\ttime-internal.h\t\t\t\t\\\n\tutil-internal.h\t\t\t\t\\\n\topenssl-compat.h\t\t\t\\\n\tmbedtls-compat.h\t\t\t\\\n\tsha1.h\t\t\t\t\t\t\\\n\tssl-compat.h\t\t\t    \\\n\twepoll.h\n\nEVENT1_HDRS = \\\n\tinclude/evdns.h \\\n\tinclude/event.h \\\n\tinclude/evhttp.h \\\n\tinclude/evrpc.h \\\n\tinclude/evutil.h\n\nif INSTALL_LIBEVENT\ninclude_HEADERS = $(EVENT1_HDRS)\nelse\nnoinst_HEADERS += $(EVENT1_HDRS)\nendif\n\nverify: check\n\ninclude doxygen.am\n\nDISTCLEANFILES += *~ libevent.pc libevent_core.pc libevent_extra.pc ./include/event2/event-config.h\n\n"
        },
        {
          "name": "PreLoad.cmake",
          "type": "blob",
          "size": 0.2607421875,
          "content": "# Disable RPATH for install tree by default.\n#\n# PreLoad is used to change the default, since CMakeLists.txt will already have\n# the default, and it will NO.\nif (NOT DEFINED CMAKE_SKIP_INSTALL_RPATH)\n    set(CMAKE_SKIP_INSTALL_RPATH ON CACHE STRING \"\" FORCE)\nendif()\n"
        },
        {
          "name": "PrivacyInfo.xcprivacy",
          "type": "blob",
          "size": 0.5849609375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>NSPrivacyTracking</key>\n\t<false/>\n\t<key>NSPrivacyCollectedDataTypes</key>\n\t<array/>\n\t<key>NSPrivacyTrackingDomains</key>\n\t<array/>\n\t<key>NSPrivacyAccessedAPITypes</key>\n\t<array>\n\t\t<dict>\n\t\t\t<key>NSPrivacyAccessedAPIType</key>\n\t\t\t<string>NSPrivacyAccessedAPICategoryFileTimestamp</string>\n\t\t\t<key>NSPrivacyAccessedAPITypeReasons</key>\n\t\t\t<array>\n\t\t\t\t<string>0A2A.1</string>\n\t\t\t</array>\n\t\t</dict>\n\t</array>\n</dict>\n</plist>\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.34375,
          "content": "<p align=\"center\">\n  <img src=\"https://libevent.org/images/libevent3.png\" alt=\"libevent logo\"/>\n</p>\n\n\n\n[![CI](https://github.com/libevent/libevent/actions/workflows/build.yml/badge.svg)](https://github.com/libevent/libevent/actions/workflows/build.yml)\n[![Coverage Status](https://coveralls.io/repos/github/libevent/libevent/badge.svg)](https://coveralls.io/github/libevent/libevent)\n[![Join the chat at https://gitter.im/libevent/libevent](https://badges.gitter.im/libevent/libevent.svg)](https://gitter.im/libevent/libevent?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![doxygen](https://img.shields.io/badge/doxygen-documentation-blue.svg)](https://libevent.org/doc)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/libevent/libevent/badge)](https://securityscorecards.dev/viewer/?uri=github.com/libevent/libevent)\n\n\n\n# 1. BUILDING AND INSTALLATION\n\n## CMake (Unix)\n\n```sh\nmkdir build && cd build\ncmake ..     # Default to Unix Makefiles.\nmake\nmake verify  # (optional)\n```\n\nSee [Documentation/Building#Building on Unix using CMake](/Documentation/Building.md#building-on-unix-cmake) for more information.\n\n## CMake (Windows)\n\nInstall CMake: <https://cmake.org/>\n\n```sh\nmd build && cd build\ncmake -G \"Visual Studio 10\" ..   # Or use any generator you want to use. Run cmake --help for a list\ncmake --build . --config Release # Or \"start libevent.sln\" and build with menu in Visual Studio.\n```\n\nSee [Documentation/Building#Building on Windows](/Documentation/Building.md#building-on-windows) for more information.\n\n## Package Managers\n\nYou can download and install libevent using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n```sh\ngit clone https://github.com/Microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.sh\n./vcpkg integrate install\n./vcpkg install libevent\n```\n\nThe libevent port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n## Autoconf\n\n*Note, since 2.2 it is deprecated*\n\n```sh\n./configure\nmake\nmake verify   # (optional)\nsudo make install\n```\n\nSee [Documentation/Building#Autoconf](/Documentation/Building.md#autotools-deprecated) for more information.\n\n# 2. USEFUL LINKS:\n\nFor the latest released version of Libevent, see the official website at\n<https://libevent.org/> .\n\nThere's a pretty good work-in-progress manual up at\n   <http://www.wangafu.net/~nickm/libevent-book/> .\n\nFor the latest development versions of Libevent, access our Git repository\nvia\n\n```sh\n$ git clone https://github.com/libevent/libevent.git\n```\n\nYou can browse the git repository online at:\n\n<https://github.com/libevent/libevent>\n\nTo report bugs, issues, or ask for new features:\n\n__Patches__: https://github.com/libevent/libevent/pulls\n> OK, those are not really _patches_. You fork, modify, and hit the \"Create Pull Request\" button.\n> You can still submit normal git patches via the mailing list.\n\n__Bugs, Features [RFC], and Issues__: https://github.com/libevent/libevent/issues\n> Or you can do it via the mailing list.\n\nThere's also a libevent-users mailing list for talking about Libevent\nuse and development: \n\n<https://archives.seul.org/libevent/users/>\n\n# 3. ACKNOWLEDGMENTS\n\nThe [following people](/CONTRIBUTORS.md) have helped with suggestions, ideas,\ncode or fixing bugs.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.671875,
          "content": "# Security Policy\n\n## Supported Versions\nSecurity updates are applied only to 2.1 and 2.2 latest stable releases.\n\n## Reporting a Vulnerability\nIf you have discovered a security vulnerability in this project, please report it privately. **Do not disclose it as a public issue.** This gives us time to work with you to fix the issue before public exposure, reducing the chance that the exploit will be used before a patch is released.\n\nPlease disclose it at [security advisory](https://github.com/libevent/libevent/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a reasonable-effort basis. As such, vulnerabilities will be disclosed in a best effort base.\n"
        },
        {
          "name": "WIN32-Code",
          "type": "tree",
          "content": null
        },
        {
          "name": "arc4random.c",
          "type": "blob",
          "size": 11.849609375,
          "content": "/* Portable arc4random.c based on arc4random.c from OpenBSD.\n * Portable version by Chris Davis, adapted for Libevent by Nick Mathewson\n * Copyright (c) 2010 Chris Davis, Niels Provos, and Nick Mathewson\n * Copyright (c) 2010-2012 Niels Provos and Nick Mathewson\n *\n * Note that in Libevent, this file isn't compiled directly.  Instead,\n * it's included from evutil_rand.c\n */\n\n/*\n * Copyright (c) 1996, David Mazieres <dm@uun.org>\n * Copyright (c) 2008, Damien Miller <djm@openbsd.org>\n *\n * Permission to use, copy, modify, and distribute this software for any\n * purpose with or without fee is hereby granted, provided that the above\n * copyright notice and this permission notice appear in all copies.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n */\n\n/*\n * Arc4 random number generator for OpenBSD.\n *\n * This code is derived from section 17.1 of Applied Cryptography,\n * second edition, which describes a stream cipher allegedly\n * compatible with RSA Labs \"RC4\" cipher (the actual description of\n * which is a trade secret).  The same algorithm is used as a stream\n * cipher called \"arcfour\" in Tatu Ylonen's ssh package.\n *\n * Here the stream cipher has been modified always to include the time\n * when initializing the state.  That makes it impossible to\n * regenerate the same random sequence twice, so this can't be used\n * for encryption, but will generate good random numbers.\n *\n * RC4 is a registered trademark of RSA Laboratories.\n */\n\n#ifndef ARC4RANDOM_EXPORT\n#define ARC4RANDOM_EXPORT\n#endif\n\n#ifndef ARC4RANDOM_UINT32\n#define ARC4RANDOM_UINT32 uint32_t\n#endif\n\n#ifndef ARC4RANDOM_NO_INCLUDES\n#include \"evconfig-private.h\"\n#ifdef _WIN32\n#include <bcrypt.h>\n#include <process.h>\n#include <winerror.h>\n#else\n#include <fcntl.h>\n#include <unistd.h>\n#include <sys/param.h>\n#include <sys/time.h>\n#ifdef EVENT__HAVE_SYS_SYSCTL_H\n#include <sys/sysctl.h>\n#endif\n#ifdef EVENT__HAVE_SYS_RANDOM_H\n#include <sys/random.h>\n#endif\n#endif\n#include <limits.h>\n#include <stdlib.h>\n#include <string.h>\n#endif\n\n/* Add platform entropy 32 bytes (256 bits) at a time. */\n#define ADD_ENTROPY 32\n\n#define REKEY_BASE (1024*1024) /* NB. should be a power of 2 */\n\nstruct arc4_stream {\n\tunsigned char i;\n\tunsigned char j;\n\tunsigned char s[256];\n};\n\n#ifdef _WIN32\n#define getpid _getpid\n#define pid_t int\n#endif\n\n#ifndef O_RDONLY\n#define O_RDONLY _O_RDONLY\n#endif\n\nstatic int rs_initialized;\nstatic struct arc4_stream rs;\nstatic pid_t arc4_stir_pid;\nstatic int arc4_count;\n\nstatic inline unsigned char arc4_getbyte(void);\n\nstatic inline void\narc4_init(void)\n{\n\tint     n;\n\n\tfor (n = 0; n < 256; n++)\n\t\trs.s[n] = n;\n\trs.i = 0;\n\trs.j = 0;\n}\n\nstatic inline void\narc4_addrandom(const unsigned char *dat, int datlen)\n{\n\tint     n;\n\tunsigned char si;\n\n\trs.i--;\n\tfor (n = 0; n < 256; n++) {\n\t\trs.i = (rs.i + 1);\n\t\tsi = rs.s[rs.i];\n\t\trs.j = (rs.j + si + dat[n % datlen]);\n\t\trs.s[rs.i] = rs.s[rs.j];\n\t\trs.s[rs.j] = si;\n\t}\n\trs.j = rs.i;\n}\n\n#ifndef _WIN32\nstatic ssize_t\nread_all(int fd, unsigned char *buf, size_t count)\n{\n\tsize_t numread = 0;\n\tssize_t result;\n\n\twhile (numread < count) {\n\t\tresult = read(fd, buf+numread, count-numread);\n\t\tif (result<0)\n\t\t\treturn -1;\n\t\telse if (result == 0)\n\t\t\tbreak;\n\t\tnumread += result;\n\t}\n\n\treturn (ssize_t)numread;\n}\n#endif\n\n#ifdef _WIN32\n#define TRY_SEED_WIN32\nstatic int\narc4_seed_win32(void)\n{\n\tunsigned char buf[ADD_ENTROPY];\n\n\tif (BCryptGenRandom(NULL, buf, sizeof(buf),\n\t\tBCRYPT_USE_SYSTEM_PREFERRED_RNG))\n\t\treturn -1;\n\tarc4_addrandom(buf, sizeof(buf));\n\tevutil_memclear_(buf, sizeof(buf));\n\treturn 0;\n}\n#endif\n\n#if defined(EVENT__HAVE_GETRANDOM)\n#define TRY_SEED_GETRANDOM\nstatic int\narc4_seed_getrandom(void)\n{\n\tunsigned char buf[ADD_ENTROPY];\n\tsize_t len;\n\tssize_t n = 0;\n\n\tfor (len = 0; len < sizeof(buf); len += n) {\n\t\tn = getrandom(&buf[len], sizeof(buf) - len, 0);\n\t\tif (n < 0)\n\t\t\treturn -1;\n\t}\n\tarc4_addrandom(buf, sizeof(buf));\n\tevutil_memclear_(buf, sizeof(buf));\n\treturn 0;\n}\n#endif /* EVENT__HAVE_GETRANDOM */\n\n#if defined(EVENT__HAVE_SYS_SYSCTL_H) && defined(EVENT__HAVE_SYSCTL)\n#if EVENT__HAVE_DECL_CTL_KERN && EVENT__HAVE_DECL_KERN_ARND\n#define TRY_SEED_SYSCTL_BSD\nstatic int\narc4_seed_sysctl_bsd(void)\n{\n\t/* Based on code from William Ahern and from OpenBSD, this function\n\t * tries to use the KERN_ARND syscall to get entropy from the kernel.\n\t * This can work even if /dev/urandom is inaccessible for some reason\n\t * (e.g., we're running in a chroot). */\n\tint mib[] = { CTL_KERN, KERN_ARND };\n\tunsigned char buf[ADD_ENTROPY];\n\tsize_t len, n;\n\tint i, any_set;\n\n\tmemset(buf, 0, sizeof(buf));\n\n\tlen = sizeof(buf);\n\tif (sysctl(mib, 2, buf, &len, NULL, 0) == -1) {\n\t\tfor (len = 0; len < sizeof(buf); len += sizeof(unsigned)) {\n\t\t\tn = sizeof(unsigned);\n\t\t\tif (n + len > sizeof(buf))\n\t\t\t    n = len - sizeof(buf);\n\t\t\tif (sysctl(mib, 2, &buf[len], &n, NULL, 0) == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\t/* make sure that the buffer actually got set. */\n\tfor (i=any_set=0; i<sizeof(buf); ++i) {\n\t\tany_set |= buf[i];\n\t}\n\tif (!any_set)\n\t\treturn -1;\n\n\tarc4_addrandom(buf, sizeof(buf));\n\tevutil_memclear_(buf, sizeof(buf));\n\treturn 0;\n}\n#endif\n#endif /* defined(EVENT__HAVE_SYS_SYSCTL_H) */\n\n#ifdef __linux__\n#define TRY_SEED_PROC_SYS_KERNEL_RANDOM_UUID\nstatic int\narc4_seed_proc_sys_kernel_random_uuid(void)\n{\n\t/* Occasionally, somebody will make /proc/sys accessible in a chroot,\n\t * but not /dev/urandom.  Let's try /proc/sys/kernel/random/uuid.\n\t * Its format is stupid, so we need to decode it from hex.\n\t */\n\tint fd;\n\tchar buf[128];\n\tunsigned char entropy[64];\n\tint bytes, n, i, nybbles;\n\tfor (bytes = 0; bytes<ADD_ENTROPY; ) {\n\t\tfd = evutil_open_closeonexec_(\"/proc/sys/kernel/random/uuid\", O_RDONLY, 0);\n\t\tif (fd < 0)\n\t\t\treturn -1;\n\t\tn = read(fd, buf, sizeof(buf));\n\t\tclose(fd);\n\t\tif (n<=0)\n\t\t\treturn -1;\n\t\tmemset(entropy, 0, sizeof(entropy));\n\t\tfor (i=nybbles=0; i<n; ++i) {\n\t\t\tif (EVUTIL_ISXDIGIT_(buf[i])) {\n\t\t\t\tint nyb = evutil_hex_char_to_int_(buf[i]);\n\t\t\t\tif (nybbles & 1) {\n\t\t\t\t\tentropy[nybbles/2] |= nyb;\n\t\t\t\t} else {\n\t\t\t\t\tentropy[nybbles/2] |= nyb<<4;\n\t\t\t\t}\n\t\t\t\t++nybbles;\n\t\t\t}\n\t\t}\n\t\tif (nybbles < 2)\n\t\t\treturn -1;\n\t\tarc4_addrandom(entropy, nybbles/2);\n\t\tbytes += nybbles/2;\n\t}\n\tevutil_memclear_(entropy, sizeof(entropy));\n\tevutil_memclear_(buf, sizeof(buf));\n\treturn 0;\n}\n#endif\n\n#ifndef _WIN32\n#define TRY_SEED_URANDOM\nstatic char *arc4random_urandom_filename = NULL;\n\nstatic int arc4_seed_urandom_helper_(const char *fname)\n{\n\tunsigned char buf[ADD_ENTROPY];\n\tint fd;\n\tsize_t n;\n\n\tfd = evutil_open_closeonexec_(fname, O_RDONLY, 0);\n\tif (fd<0)\n\t\treturn -1;\n\tn = read_all(fd, buf, sizeof(buf));\n\tclose(fd);\n\tif (n != sizeof(buf))\n\t\treturn -1;\n\tarc4_addrandom(buf, sizeof(buf));\n\tevutil_memclear_(buf, sizeof(buf));\n\treturn 0;\n}\n\nstatic int\narc4_seed_urandom(void)\n{\n\t/* This is adapted from Tor's crypto_seed_rng() */\n\tstatic const char *filenames[] = {\n\t\t\"/dev/srandom\", \"/dev/urandom\", \"/dev/random\", NULL\n\t};\n\tint i;\n\tif (arc4random_urandom_filename)\n\t\treturn arc4_seed_urandom_helper_(arc4random_urandom_filename);\n\n\tfor (i = 0; filenames[i]; ++i) {\n\t\tif (arc4_seed_urandom_helper_(filenames[i]) == 0) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -1;\n}\n#endif\n\nstatic int\narc4_seed(void)\n{\n\tint ok = 0;\n\t/* We try every method that might work, and don't give up even if one\n\t * does seem to work.  There's no real harm in over-seeding, and if\n\t * one of these sources turns out to be broken, that would be bad. */\n#ifdef TRY_SEED_WIN32\n\tif (0 == arc4_seed_win32())\n\t\tok = 1;\n#endif\n#ifdef TRY_SEED_GETRANDOM\n\tif (0 == arc4_seed_getrandom())\n\t\tok = 1;\n#endif\n#ifdef TRY_SEED_URANDOM\n\tif (0 == arc4_seed_urandom())\n\t\tok = 1;\n#endif\n#ifdef TRY_SEED_PROC_SYS_KERNEL_RANDOM_UUID\n\tif (arc4random_urandom_filename == NULL &&\n\t    0 == arc4_seed_proc_sys_kernel_random_uuid())\n\t\tok = 1;\n#endif\n#ifdef TRY_SEED_SYSCTL_BSD\n\tif (0 == arc4_seed_sysctl_bsd())\n\t\tok = 1;\n#endif\n\treturn ok ? 0 : -1;\n}\n\nstatic inline unsigned int\narc4_getword(void);\nstatic int\narc4_stir(void)\n{\n\tint     i;\n\tARC4RANDOM_UINT32 rekey_fuzz; \n\n\tif (!rs_initialized) {\n\t\tarc4_init();\n\t\trs_initialized = 1;\n\t}\n\n\tif (0 != arc4_seed())\n\t\treturn -1;\n\n\t/*\n\t * Discard early keystream, as per recommendations in\n\t * \"Weaknesses in the Key Scheduling Algorithm of RC4\" by\n\t * Scott Fluhrer, Itsik Mantin, and Adi Shamir.\n\t * http://www.wisdom.weizmann.ac.il/~itsik/RC4/Papers/Rc4_ksa.ps\n\t *\n\t * Ilya Mironov's \"(Not So) Random Shuffles of RC4\" suggests that\n\t * we drop at least 2*256 bytes, with 12*256 as a conservative\n\t * value.\n\t *\n\t * RFC4345 says to drop 6*256.\n\t *\n\t * At least some versions of this code drop 4*256, in a mistaken\n\t * belief that \"words\" in the Fluhrer/Mantin/Shamir paper refers\n\t * to processor words.\n\t *\n\t * We add another sect to the cargo cult, and choose 16*256.\n\t */\n\tfor (i = 0; i < 16*256; i++)\n\t\t(void)arc4_getbyte();\n\n\trekey_fuzz = arc4_getword();\n\t/* rekey interval should not be predictable */\n\tarc4_count = REKEY_BASE + (rekey_fuzz % REKEY_BASE);\n\n\treturn 0;\n}\n\n\nstatic void\narc4_stir_if_needed(void)\n{\n\tpid_t pid = getpid();\n\n\tif (arc4_count <= 0 || !rs_initialized || arc4_stir_pid != pid)\n\t{\n\t\tarc4_stir_pid = pid;\n\t\tarc4_stir();\n\t}\n}\n\nstatic inline unsigned char\narc4_getbyte(void)\n{\n\tunsigned char si, sj;\n\n\trs.i = (rs.i + 1);\n\tsi = rs.s[rs.i];\n\trs.j = (rs.j + si);\n\tsj = rs.s[rs.j];\n\trs.s[rs.i] = sj;\n\trs.s[rs.j] = si;\n\treturn (rs.s[(si + sj) & 0xff]);\n}\n\nstatic inline unsigned int\narc4_getword(void)\n{\n\tunsigned int val;\n\n\tval = (unsigned)arc4_getbyte() << 24;\n\tval |= arc4_getbyte() << 16;\n\tval |= arc4_getbyte() << 8;\n\tval |= arc4_getbyte();\n\n\treturn val;\n}\n\n#ifndef ARC4RANDOM_NOSTIR\nARC4RANDOM_EXPORT int\narc4random_stir(void)\n{\n\tint val;\n\tARC4_LOCK_();\n\tval = arc4_stir();\n\tARC4_UNLOCK_();\n\treturn val;\n}\n#endif\n\n#ifndef ARC4RANDOM_NOADDRANDOM\nARC4RANDOM_EXPORT void\narc4random_addrandom(const unsigned char *dat, int datlen)\n{\n\tint j;\n\tARC4_LOCK_();\n\tif (!rs_initialized)\n\t\tarc4_stir();\n\tfor (j = 0; j < datlen; j += 256) {\n\t\t/* arc4_addrandom() ignores all but the first 256 bytes of\n\t\t * its input.  We want to make sure to look at ALL the\n\t\t * data in 'dat', just in case the user is doing something\n\t\t * crazy like passing us all the files in /var/log. */\n\t\tarc4_addrandom(dat + j, datlen - j);\n\t}\n\tARC4_UNLOCK_();\n}\n#endif\n\n#ifndef ARC4RANDOM_NORANDOM\nARC4RANDOM_EXPORT ARC4RANDOM_UINT32\narc4random(void)\n{\n\tARC4RANDOM_UINT32 val;\n\tARC4_LOCK_();\n\tarc4_count -= 4;\n\tarc4_stir_if_needed();\n\tval = arc4_getword();\n\tARC4_UNLOCK_();\n\treturn val;\n}\n#endif\n\n#ifndef EVENT__HAVE_ARC4RANDOM_BUF\nARC4RANDOM_EXPORT void\narc4random_buf(void *buf_, size_t n)\n{\n\tunsigned char *buf = buf_;\n\tARC4_LOCK_();\n\tarc4_stir_if_needed();\n\twhile (n--) {\n\t\tif (--arc4_count <= 0)\n\t\t\tarc4_stir();\n\t\tbuf[n] = arc4_getbyte();\n\t}\n\tARC4_UNLOCK_();\n}\n#endif  /* #ifndef EVENT__HAVE_ARC4RANDOM_BUF */\n\n#ifndef ARC4RANDOM_NOUNIFORM\n/*\n * Calculate a uniformly distributed random number less than upper_bound\n * avoiding \"modulo bias\".\n *\n * Uniformity is achieved by generating new random numbers until the one\n * returned is outside the range [0, 2**32 % upper_bound).  This\n * guarantees the selected random number will be inside\n * [2**32 % upper_bound, 2**32) which maps back to [0, upper_bound)\n * after reduction modulo upper_bound.\n */\nARC4RANDOM_EXPORT unsigned int\narc4random_uniform(unsigned int upper_bound)\n{\n\tARC4RANDOM_UINT32 r, min;\n\n\tif (upper_bound < 2)\n\t\treturn 0;\n\n\t/* 2**32 % x == (2**32 - x) % x */\n\tmin = -upper_bound % upper_bound;\n\n\t/*\n\t * This could theoretically loop forever but each retry has\n\t * p > 0.5 (worst case, usually far better) of selecting a\n\t * number inside the range we need, so it should rarely need\n\t * to re-roll.\n\t */\n\tfor (;;) {\n\t\tr = arc4random();\n\t\tif (r >= min)\n\t\t\tbreak;\n\t}\n\n\treturn r % upper_bound;\n}\n#endif\n"
        },
        {
          "name": "autogen.sh",
          "type": "blob",
          "size": 0.4189453125,
          "content": "#!/bin/sh\n\nMAKE=make\nif command -v gmake >/dev/null 2>/dev/null; then\n  MAKE=gmake\nfi\n$MAKE maintainer-clean >/dev/null 2>/dev/null\n\nif [ -x \"`which autoreconf 2>/dev/null`\" ] ; then\n   exec autoreconf -ivf\nfi\n\nLIBTOOLIZE=libtoolize\nSYSNAME=`uname`\nif [ \"$SYSNAME\" = \"Darwin\" ] ; then\n  LIBTOOLIZE=glibtoolize\nfi\naclocal -I m4 && \\\n\tautoheader && \\\n\t$LIBTOOLIZE && \\\n\tautoconf && \\\n\tautomake --add-missing --force-missing --copy\n"
        },
        {
          "name": "buffer.c",
          "type": "blob",
          "size": 82.228515625,
          "content": "/*\n * Copyright (c) 2002-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <windows.h>\n#include <io.h>\n#endif\n\n#include <sys/types.h>\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_UIO_H\n#include <sys/uio.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_IOCTL_H\n#include <sys/ioctl.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_MMAN_H\n#include <sys/mman.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_SENDFILE_H\n#include <sys/sendfile.h>\n#endif\n#ifdef EVENT__HAVE_SYS_STAT_H\n#include <sys/stat.h>\n#endif\n\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#include <limits.h>\n\n#include \"event2/event.h\"\n#include \"event2/buffer.h\"\n#include \"event2/buffer_compat.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_compat.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/thread.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n#include \"evthread-internal.h\"\n#include \"evbuffer-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"event-internal.h\"\n\n/* some systems do not have MAP_FAILED */\n#ifndef MAP_FAILED\n#define MAP_FAILED\t((void *)-1)\n#endif\n\n/* send file support */\n#if defined(EVENT__HAVE_SYS_SENDFILE_H) && defined(EVENT__HAVE_SENDFILE) && defined(__linux__)\n#define USE_SENDFILE\t\t1\n#define SENDFILE_IS_LINUX\t1\n#elif defined(EVENT__HAVE_SENDFILE) && defined(__FreeBSD__)\n#define USE_SENDFILE\t\t1\n#define SENDFILE_IS_FREEBSD\t1\n#elif defined(EVENT__HAVE_SENDFILE) && defined(__APPLE__)\n#define USE_SENDFILE\t\t1\n#define SENDFILE_IS_MACOSX\t1\n#elif defined(EVENT__HAVE_SENDFILE) && defined(__sun__) && defined(__svr4__)\n#define USE_SENDFILE\t\t1\n#define SENDFILE_IS_SOLARIS\t1\n#endif\n\n/* Mask of user-selectable callback flags. */\n#define EVBUFFER_CB_USER_FLAGS\t    0xffff\n/* Mask of all internal-use-only flags. */\n#define EVBUFFER_CB_INTERNAL_FLAGS  0xffff0000\n\n/* Flag set if the callback is using the cb_obsolete function pointer  */\n#define EVBUFFER_CB_OBSOLETE\t       0x00040000\n\n/* evbuffer_chain support */\n#define CHAIN_SPACE_PTR(ch) ((ch)->buffer + (ch)->misalign + (ch)->off)\n#define CHAIN_SPACE_LEN(ch) ((ch)->flags & EVBUFFER_IMMUTABLE ? \\\n\t    0 : (ch)->buffer_len - ((ch)->misalign + (ch)->off))\n\n#define CHAIN_PINNED(ch)  (((ch)->flags & EVBUFFER_MEM_PINNED_ANY) != 0)\n#define CHAIN_PINNED_R(ch)  (((ch)->flags & EVBUFFER_MEM_PINNED_R) != 0)\n\n/* evbuffer_ptr support */\n#define PTR_NOT_FOUND(ptr) do {\t\t\t\\\n\t(ptr)->pos = -1;\t\t\t\t\t\\\n\t(ptr)->internal_.chain = NULL;\t\t\\\n\t(ptr)->internal_.pos_in_chain = 0;\t\\\n} while (0)\n\n#define EVBUFFER_MAX_READ_DEFAULT\t4096\n\nstatic void evbuffer_chain_align(struct evbuffer_chain *chain);\nstatic int evbuffer_chain_should_realign(struct evbuffer_chain *chain,\n    size_t datalen);\nstatic void evbuffer_deferred_callback(struct event_callback *cb, void *arg);\nstatic int evbuffer_ptr_memcmp(const struct evbuffer *buf,\n    const struct evbuffer_ptr *pos, const char *mem, size_t len);\nstatic struct evbuffer_chain *evbuffer_expand_singlechain(struct evbuffer *buf,\n    size_t datlen);\nstatic int evbuffer_ptr_subtract(struct evbuffer *buf, struct evbuffer_ptr *pos,\n    size_t howfar);\nstatic int evbuffer_file_segment_materialize(struct evbuffer_file_segment *seg);\nstatic inline void evbuffer_chain_incref(struct evbuffer_chain *chain);\n\nstatic struct evbuffer_chain *\nevbuffer_chain_new(size_t size)\n{\n\tstruct evbuffer_chain *chain;\n\tsize_t to_alloc;\n\n\tif (size > EVBUFFER_CHAIN_MAX - EVBUFFER_CHAIN_SIZE)\n\t\treturn (NULL);\n\n\tto_alloc = size + EVBUFFER_CHAIN_SIZE;\n\n\t/* we get everything in one chunk */\n\tif ((chain = mm_malloc(to_alloc)) == NULL)\n\t\treturn (NULL);\n\n\tmemset(chain, 0, EVBUFFER_CHAIN_SIZE);\n\n\tchain->buffer_len = to_alloc - EVBUFFER_CHAIN_SIZE;\n\n\t/* this way we can manipulate the buffer to different addresses,\n\t * which is required for mmap for example.\n\t */\n\tchain->buffer = EVBUFFER_CHAIN_EXTRA(unsigned char, chain);\n\n\tchain->refcnt = 1;\n\n\treturn (chain);\n}\n\nstatic struct evbuffer_chain *\nevbuffer_chain_new_membuf(size_t size)\n{\n\tsize_t to_alloc;\n\n\tif (size > EVBUFFER_CHAIN_MAX - EVBUFFER_CHAIN_SIZE)\n\t\treturn (NULL);\n\n\tsize += EVBUFFER_CHAIN_SIZE;\n\n\t/* get the next largest memory that can hold the buffer */\n\tif (size < EVBUFFER_CHAIN_MAX / 2) {\n\t\tto_alloc = MIN_BUFFER_SIZE;\n\t\twhile (to_alloc < size) {\n\t\t\tto_alloc <<= 1;\n\t\t}\n\t} else {\n\t\tto_alloc = size;\n\t}\n\n\treturn evbuffer_chain_new(to_alloc - EVBUFFER_CHAIN_SIZE);\n}\n\nstatic inline void\nevbuffer_chain_free(struct evbuffer_chain *chain)\n{\n\tEVUTIL_ASSERT(chain->refcnt > 0);\n\tif (--chain->refcnt > 0) {\n\t\t/* chain is still referenced by other chains */\n\t\treturn;\n\t}\n\n\tif (CHAIN_PINNED(chain)) {\n\t\t/* will get freed once no longer dangling */\n\t\tchain->refcnt++;\n\t\tchain->flags |= EVBUFFER_DANGLING;\n\t\treturn;\n\t}\n\n\t/* safe to release chain, it's either a referencing\n\t * chain or all references to it have been freed */\n\tif (chain->flags & EVBUFFER_REFERENCE) {\n\t\tstruct evbuffer_chain_reference *info =\n\t\t    EVBUFFER_CHAIN_EXTRA(\n\t\t\t    struct evbuffer_chain_reference,\n\t\t\t    chain);\n\t\tif (info->cleanupfn)\n\t\t\t(*info->cleanupfn)(chain->buffer,\n\t\t\t    chain->buffer_len,\n\t\t\t    info->extra);\n\t}\n\tif (chain->flags & EVBUFFER_FILESEGMENT) {\n\t\tstruct evbuffer_chain_file_segment *info =\n\t\t    EVBUFFER_CHAIN_EXTRA(\n\t\t\t    struct evbuffer_chain_file_segment,\n\t\t\t    chain);\n\t\tif (info->segment) {\n#ifdef _WIN32\n\t\t\tif (info->segment->is_mapping)\n\t\t\t\tUnmapViewOfFile(chain->buffer);\n#endif\n\t\t\tevbuffer_file_segment_free(info->segment);\n\t\t}\n\t}\n\tif (chain->flags & EVBUFFER_MULTICAST) {\n\t\tstruct evbuffer_multicast_parent *info =\n\t\t    EVBUFFER_CHAIN_EXTRA(\n\t\t\t    struct evbuffer_multicast_parent,\n\t\t\t    chain);\n\t\t/* referencing chain is being freed, decrease\n\t\t * refcounts of source chain and associated\n\t\t * evbuffer (which get freed once both reach\n\t\t * zero) */\n\t\tEVUTIL_ASSERT(info->source != NULL);\n\t\tEVUTIL_ASSERT(info->parent != NULL);\n\t\tEVBUFFER_LOCK(info->source);\n\t\tevbuffer_chain_free(info->parent);\n\t\tevbuffer_decref_and_unlock_(info->source);\n\t}\n\n\tmm_free(chain);\n}\n\nstatic void\nevbuffer_free_all_chains(struct evbuffer_chain *chain)\n{\n\tstruct evbuffer_chain *next;\n\tfor (; chain; chain = next) {\n\t\tnext = chain->next;\n\t\tevbuffer_chain_free(chain);\n\t}\n}\n\n#ifndef NDEBUG\nstatic int\nevbuffer_chains_all_empty(struct evbuffer_chain *chain)\n{\n\tfor (; chain; chain = chain->next) {\n\t\tif (chain->off)\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n#else\n/* The definition is needed for EVUTIL_ASSERT, which uses sizeof to avoid\n\"unused variable\" warnings. */\nstatic inline int evbuffer_chains_all_empty(struct evbuffer_chain *chain) {\n\treturn 1;\n}\n#endif\n\n/* Free all trailing chains in 'buf' that are neither pinned nor empty, prior\n * to replacing them all with a new chain.  Return a pointer to the place\n * where the new chain will go.\n *\n * Internal; requires lock.  The caller must fix up buf->last and buf->first\n * as needed; they might have been freed.\n */\nstatic struct evbuffer_chain **\nevbuffer_free_trailing_empty_chains(struct evbuffer *buf)\n{\n\tstruct evbuffer_chain **ch = buf->last_with_datap;\n\t/* Find the first victim chain.  It might be *last_with_datap */\n\twhile ((*ch) && ((*ch)->off != 0 || CHAIN_PINNED(*ch)))\n\t\tch = &(*ch)->next;\n\tif (*ch) {\n\t\tEVUTIL_ASSERT(evbuffer_chains_all_empty(*ch));\n\t\tevbuffer_free_all_chains(*ch);\n\t\t*ch = NULL;\n\t}\n\treturn ch;\n}\n\n/* Add a single chain 'chain' to the end of 'buf', freeing trailing empty\n * chains as necessary.  Requires lock.  Does not schedule callbacks.\n */\nstatic void\nevbuffer_chain_insert(struct evbuffer *buf,\n    struct evbuffer_chain *chain)\n{\n\tASSERT_EVBUFFER_LOCKED(buf);\n\tif (*buf->last_with_datap == NULL) {\n\t\t/* There are no chains data on the buffer at all. */\n\t\tEVUTIL_ASSERT(buf->last_with_datap == &buf->first);\n\t\tEVUTIL_ASSERT(buf->first == NULL);\n\t\tbuf->first = buf->last = chain;\n\t} else {\n\t\tstruct evbuffer_chain **chp;\n\t\tchp = evbuffer_free_trailing_empty_chains(buf);\n\t\t*chp = chain;\n\t\tif (chain->off)\n\t\t\tbuf->last_with_datap = chp;\n\t\tbuf->last = chain;\n\t}\n\tbuf->total_len += chain->off;\n}\n\nstatic inline struct evbuffer_chain *\nevbuffer_chain_insert_new(struct evbuffer *buf, size_t datlen)\n{\n\tstruct evbuffer_chain *chain;\n\tif ((chain = evbuffer_chain_new_membuf(datlen)) == NULL)\n\t\treturn NULL;\n\tevbuffer_chain_insert(buf, chain);\n\treturn chain;\n}\n\nvoid\nevbuffer_chain_pin_(struct evbuffer_chain *chain, unsigned flag)\n{\n\tEVUTIL_ASSERT((chain->flags & flag) == 0);\n\tchain->flags |= flag;\n}\n\nvoid\nevbuffer_chain_unpin_(struct evbuffer_chain *chain, unsigned flag)\n{\n\tEVUTIL_ASSERT((chain->flags & flag) != 0);\n\tchain->flags &= ~flag;\n\tif (chain->flags & EVBUFFER_DANGLING)\n\t\tevbuffer_chain_free(chain);\n}\n\nstatic inline void\nevbuffer_chain_incref(struct evbuffer_chain *chain)\n{\n    ++chain->refcnt;\n}\n\nstruct evbuffer *\nevbuffer_new(void)\n{\n\tstruct evbuffer *buffer;\n\n\tbuffer = mm_calloc(1, sizeof(struct evbuffer));\n\tif (buffer == NULL)\n\t\treturn (NULL);\n\n\tLIST_INIT(&buffer->callbacks);\n\tbuffer->refcnt = 1;\n\tbuffer->last_with_datap = &buffer->first;\n\tbuffer->max_read = EVBUFFER_MAX_READ_DEFAULT;\n\n\treturn (buffer);\n}\n\nint\nevbuffer_set_flags(struct evbuffer *buf, ev_uint64_t flags)\n{\n\tEVBUFFER_LOCK(buf);\n\tbuf->flags |= (ev_uint32_t)flags;\n\tEVBUFFER_UNLOCK(buf);\n\treturn 0;\n}\n\nint\nevbuffer_clear_flags(struct evbuffer *buf, ev_uint64_t flags)\n{\n\tEVBUFFER_LOCK(buf);\n\tbuf->flags &= ~(ev_uint32_t)flags;\n\tEVBUFFER_UNLOCK(buf);\n\treturn 0;\n}\n\nvoid\nevbuffer_incref_(struct evbuffer *buf)\n{\n\tEVBUFFER_LOCK(buf);\n\t++buf->refcnt;\n\tEVBUFFER_UNLOCK(buf);\n}\n\nvoid\nevbuffer_incref_and_lock_(struct evbuffer *buf)\n{\n\tEVBUFFER_LOCK(buf);\n\t++buf->refcnt;\n}\n\nint\nevbuffer_defer_callbacks(struct evbuffer *buffer, struct event_base *base)\n{\n\tEVBUFFER_LOCK(buffer);\n\tbuffer->cb_queue = base;\n\tbuffer->deferred_cbs = 1;\n\tevent_deferred_cb_init_(&buffer->deferred,\n\t    event_base_get_npriorities(base) / 2,\n\t    evbuffer_deferred_callback, buffer);\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\nint\nevbuffer_enable_locking(struct evbuffer *buf, void *lock)\n{\n#ifdef EVENT__DISABLE_THREAD_SUPPORT\n\treturn -1;\n#else\n\tif (buf->lock)\n\t\treturn -1;\n\n\tif (!lock) {\n\t\tEVTHREAD_ALLOC_LOCK(lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\t\tif (!lock)\n\t\t\treturn -1;\n\t\tbuf->lock = lock;\n\t\tbuf->own_lock = 1;\n\t} else {\n\t\tbuf->lock = lock;\n\t\tbuf->own_lock = 0;\n\t}\n\n\treturn 0;\n#endif\n}\n\nvoid\nevbuffer_set_parent_(struct evbuffer *buf, struct bufferevent *bev)\n{\n\tEVBUFFER_LOCK(buf);\n\tbuf->parent = bev;\n\tEVBUFFER_UNLOCK(buf);\n}\n\nstatic void\nevbuffer_run_callbacks(struct evbuffer *buffer, int running_deferred)\n{\n\tstruct evbuffer_cb_entry *cbent, *next;\n\tstruct evbuffer_cb_info info;\n\tsize_t new_size;\n\tev_uint32_t mask, masked_val;\n\tint clear = 1;\n\n\tif (running_deferred) {\n\t\tmask = EVBUFFER_CB_NODEFER|EVBUFFER_CB_ENABLED;\n\t\tmasked_val = EVBUFFER_CB_ENABLED;\n\t} else if (buffer->deferred_cbs) {\n\t\tmask = EVBUFFER_CB_NODEFER|EVBUFFER_CB_ENABLED;\n\t\tmasked_val = EVBUFFER_CB_NODEFER|EVBUFFER_CB_ENABLED;\n\t\t/* Don't zero-out n_add/n_del, since the deferred callbacks\n\t\t   will want to see them. */\n\t\tclear = 0;\n\t} else {\n\t\tmask = EVBUFFER_CB_ENABLED;\n\t\tmasked_val = EVBUFFER_CB_ENABLED;\n\t}\n\n\tASSERT_EVBUFFER_LOCKED(buffer);\n\n\tif (LIST_EMPTY(&buffer->callbacks)) {\n\t\tbuffer->n_add_for_cb = buffer->n_del_for_cb = 0;\n\t\treturn;\n\t}\n\tif (buffer->n_add_for_cb == 0 && buffer->n_del_for_cb == 0)\n\t\treturn;\n\n\tnew_size = buffer->total_len;\n\tinfo.orig_size = new_size + buffer->n_del_for_cb - buffer->n_add_for_cb;\n\tinfo.n_added = buffer->n_add_for_cb;\n\tinfo.n_deleted = buffer->n_del_for_cb;\n\tif (clear) {\n\t\tbuffer->n_add_for_cb = 0;\n\t\tbuffer->n_del_for_cb = 0;\n\t}\n\tfor (cbent = LIST_FIRST(&buffer->callbacks);\n\t     cbent != LIST_END(&buffer->callbacks);\n\t     cbent = next) {\n\t\t/* Get the 'next' pointer now in case this callback decides\n\t\t * to remove itself or something. */\n\t\tnext = LIST_NEXT(cbent, next);\n\n\t\tif ((cbent->flags & mask) != masked_val)\n\t\t\tcontinue;\n\n\t\tif ((cbent->flags & EVBUFFER_CB_OBSOLETE))\n\t\t\tcbent->cb.cb_obsolete(buffer,\n\t\t\t    info.orig_size, new_size, cbent->cbarg);\n\t\telse\n\t\t\tcbent->cb.cb_func(buffer, &info, cbent->cbarg);\n\t}\n}\n\nvoid\nevbuffer_invoke_callbacks_(struct evbuffer *buffer)\n{\n\tif (LIST_EMPTY(&buffer->callbacks)) {\n\t\tbuffer->n_add_for_cb = buffer->n_del_for_cb = 0;\n\t\treturn;\n\t}\n\n\tif (buffer->deferred_cbs) {\n\t\tif (event_deferred_cb_schedule_(buffer->cb_queue, &buffer->deferred)) {\n\t\t\tevbuffer_incref_and_lock_(buffer);\n\t\t\tif (buffer->parent)\n\t\t\t\tbufferevent_incref_(buffer->parent);\n\t\t\tEVBUFFER_UNLOCK(buffer);\n\t\t}\n\t}\n\n\tevbuffer_run_callbacks(buffer, 0);\n}\n\nstatic void\nevbuffer_deferred_callback(struct event_callback *cb, void *arg)\n{\n\tstruct bufferevent *parent = NULL;\n\tstruct evbuffer *buffer = arg;\n\n\t/* XXXX It would be better to run these callbacks without holding the\n\t * lock */\n\tEVBUFFER_LOCK(buffer);\n\tparent = buffer->parent;\n\tevbuffer_run_callbacks(buffer, 1);\n\tevbuffer_decref_and_unlock_(buffer);\n\tif (parent)\n\t\tbufferevent_decref_(parent);\n}\n\nstatic void\nevbuffer_remove_all_callbacks(struct evbuffer *buffer)\n{\n\tstruct evbuffer_cb_entry *cbent;\n\n\twhile ((cbent = LIST_FIRST(&buffer->callbacks))) {\n\t\tLIST_REMOVE(cbent, next);\n\t\tmm_free(cbent);\n\t}\n}\n\nvoid\nevbuffer_decref_and_unlock_(struct evbuffer *buffer)\n{\n\tstruct evbuffer_chain *chain, *next;\n\tASSERT_EVBUFFER_LOCKED(buffer);\n\n\tEVUTIL_ASSERT(buffer->refcnt > 0);\n\n\tif (--buffer->refcnt > 0) {\n\t\tEVBUFFER_UNLOCK(buffer);\n\t\treturn;\n\t}\n\n\tfor (chain = buffer->first; chain != NULL; chain = next) {\n\t\tnext = chain->next;\n\t\tevbuffer_chain_free(chain);\n\t}\n\tevbuffer_remove_all_callbacks(buffer);\n\tif (buffer->deferred_cbs)\n\t\tevent_deferred_cb_cancel_(buffer->cb_queue, &buffer->deferred);\n\n\tEVBUFFER_UNLOCK(buffer);\n\tif (buffer->own_lock)\n\t\tEVTHREAD_FREE_LOCK(buffer->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\tmm_free(buffer);\n}\n\nvoid\nevbuffer_free(struct evbuffer *buffer)\n{\n\tEVBUFFER_LOCK(buffer);\n\tevbuffer_decref_and_unlock_(buffer);\n}\n\nint evbuffer_set_max_read(struct evbuffer *buf, size_t max)\n{\n\tif (max > INT_MAX) {\n\t\treturn -1;\n\t}\n\n\tEVBUFFER_LOCK(buf);\n\tbuf->max_read = max;\n\tEVBUFFER_UNLOCK(buf);\n\treturn 0;\n}\nsize_t evbuffer_get_max_read(struct evbuffer *buf)\n{\n\tsize_t result;\n\tEVBUFFER_LOCK(buf);\n\tresult = buf->max_read;\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\nvoid\nevbuffer_lock(struct evbuffer *buf)\n{\n\tEVBUFFER_LOCK(buf);\n}\n\nvoid\nevbuffer_unlock(struct evbuffer *buf)\n{\n\tEVBUFFER_UNLOCK(buf);\n}\n\nsize_t\nevbuffer_get_length(const struct evbuffer *buffer)\n{\n\tsize_t result;\n\tEVBUFFER_LOCK(buffer);\n\tresult = buffer->total_len;\n\tEVBUFFER_UNLOCK(buffer);\n\treturn result;\n}\n\nsize_t\nevbuffer_get_contiguous_space(const struct evbuffer *buf)\n{\n\tstruct evbuffer_chain *chain;\n\tsize_t result;\n\n\tEVBUFFER_LOCK(buf);\n\tchain = buf->first;\n\tresult = (chain != NULL ? chain->off : 0);\n\tEVBUFFER_UNLOCK(buf);\n\n\treturn result;\n}\n\nsize_t\nevbuffer_add_iovec(struct evbuffer * buf, struct evbuffer_iovec * vec, int n_vec) {\n\tint n;\n\tsize_t res;\n\tsize_t to_alloc;\n\n\tEVBUFFER_LOCK(buf);\n\n\tres = to_alloc = 0;\n\n\tfor (n = 0; n < n_vec; n++) {\n\t\tto_alloc += vec[n].iov_len;\n\t}\n\n\tif (evbuffer_expand_fast_(buf, to_alloc, 2) < 0) {\n\t\tgoto done;\n\t}\n\n\tfor (n = 0; n < n_vec; n++) {\n\t\t/* XXX each 'add' call here does a bunch of setup that's\n\t\t * obviated by evbuffer_expand_fast_, and some cleanup that we\n\t\t * would like to do only once.  Instead we should just extract\n\t\t * the part of the code that's needed. */\n\n\t\tif (evbuffer_add(buf, vec[n].iov_base, vec[n].iov_len) < 0) {\n\t\t\tgoto done;\n\t\t}\n\n\t\tres += vec[n].iov_len;\n\t}\n\ndone:\n    EVBUFFER_UNLOCK(buf);\n    return res;\n}\n\nint\nevbuffer_reserve_space(struct evbuffer *buf, ev_ssize_t size,\n    struct evbuffer_iovec *vec, int n_vecs)\n{\n\tstruct evbuffer_chain *chain, **chainp;\n\tint n = -1;\n\n\tEVBUFFER_LOCK(buf);\n\tif (buf->freeze_end)\n\t\tgoto done;\n\tif (n_vecs < 1)\n\t\tgoto done;\n\tif (n_vecs == 1) {\n\t\tif ((chain = evbuffer_expand_singlechain(buf, size)) == NULL)\n\t\t\tgoto done;\n\n\t\tvec[0].iov_base = (void *)CHAIN_SPACE_PTR(chain);\n\t\tvec[0].iov_len = (size_t)CHAIN_SPACE_LEN(chain);\n\t\tEVUTIL_ASSERT(size<0 || (size_t)vec[0].iov_len >= (size_t)size);\n\t\tn = 1;\n\t} else {\n\t\tif (evbuffer_expand_fast_(buf, size, n_vecs)<0)\n\t\t\tgoto done;\n\t\tn = evbuffer_read_setup_vecs_(buf, size, vec, n_vecs,\n\t\t\t\t&chainp, 0);\n\t}\n\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn n;\n\n}\n\nstatic int\nadvance_last_with_data(struct evbuffer *buf)\n{\n\tint n = 0;\n\tstruct evbuffer_chain **chainp = buf->last_with_datap;\n\n\tASSERT_EVBUFFER_LOCKED(buf);\n\n\tif (!*chainp)\n\t\treturn 0;\n\n\twhile ((*chainp)->next) {\n\t\tchainp = &(*chainp)->next;\n\t\tif ((*chainp)->off)\n\t\t\tbuf->last_with_datap = chainp;\n\t\t++n;\n\t}\n\treturn n;\n}\n\nint\nevbuffer_commit_space(struct evbuffer *buf,\n    struct evbuffer_iovec *vec, int n_vecs)\n{\n\tstruct evbuffer_chain *chain, **firstchainp, **chainp;\n\tint result = -1;\n\tsize_t added = 0;\n\tint i;\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (buf->freeze_end)\n\t\tgoto done;\n\tif (n_vecs == 0) {\n\t\tresult = 0;\n\t\tgoto done;\n\t} else if (n_vecs == 1 &&\n\t    (buf->last && vec[0].iov_base == (void *)CHAIN_SPACE_PTR(buf->last))) {\n\t\t/* The user only got or used one chain; it might not\n\t\t * be the first one with space in it. */\n\t\tif ((size_t)vec[0].iov_len > (size_t)CHAIN_SPACE_LEN(buf->last))\n\t\t\tgoto done;\n\t\tbuf->last->off += vec[0].iov_len;\n\t\tadded = vec[0].iov_len;\n\t\tif (added)\n\t\t\tadvance_last_with_data(buf);\n\t\tgoto okay;\n\t}\n\n\t/* Advance 'firstchain' to the first chain with space in it. */\n\tfirstchainp = buf->last_with_datap;\n\tif (!*firstchainp)\n\t\tgoto done;\n\tif (CHAIN_SPACE_LEN(*firstchainp) == 0) {\n\t\tfirstchainp = &(*firstchainp)->next;\n\t}\n\n\tchain = *firstchainp;\n\t/* pass 1: make sure that the pointers and lengths of vecs[] are in\n\t * bounds before we try to commit anything. */\n\tfor (i=0; i<n_vecs; ++i) {\n\t\tif (!chain)\n\t\t\tgoto done;\n\t\tif (vec[i].iov_base != (void *)CHAIN_SPACE_PTR(chain) ||\n\t\t    (size_t)vec[i].iov_len > CHAIN_SPACE_LEN(chain))\n\t\t\tgoto done;\n\t\tchain = chain->next;\n\t}\n\t/* pass 2: actually adjust all the chains. */\n\tchainp = firstchainp;\n\tfor (i=0; i<n_vecs; ++i) {\n\t\t(*chainp)->off += vec[i].iov_len;\n\t\tadded += vec[i].iov_len;\n\t\tif (vec[i].iov_len) {\n\t\t\tbuf->last_with_datap = chainp;\n\t\t}\n\t\tchainp = &(*chainp)->next;\n\t}\n\nokay:\n\tbuf->total_len += added;\n\tbuf->n_add_for_cb += added;\n\tresult = 0;\n\tevbuffer_invoke_callbacks_(buf);\n\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\nstatic inline int\nHAS_PINNED_R(struct evbuffer *buf)\n{\n\treturn (buf->last && CHAIN_PINNED_R(buf->last));\n}\n\nstatic inline void\nZERO_CHAIN(struct evbuffer *dst)\n{\n\tASSERT_EVBUFFER_LOCKED(dst);\n\tdst->first = NULL;\n\tdst->last = NULL;\n\tdst->last_with_datap = &(dst)->first;\n\tdst->total_len = 0;\n}\n\n/* Prepares the contents of src to be moved to another buffer by removing\n * read-pinned chains. The first pinned chain is saved in first, and the\n * last in last. If src has no read-pinned chains, first and last are set\n * to NULL. */\nstatic int\nPRESERVE_PINNED(struct evbuffer *src, struct evbuffer_chain **first,\n\t\tstruct evbuffer_chain **last)\n{\n\tstruct evbuffer_chain *chain, **pinned;\n\n\tASSERT_EVBUFFER_LOCKED(src);\n\n\tif (!HAS_PINNED_R(src)) {\n\t\t*first = *last = NULL;\n\t\treturn 0;\n\t}\n\n\tpinned = src->last_with_datap;\n\tif (!CHAIN_PINNED_R(*pinned))\n\t\tpinned = &(*pinned)->next;\n\tEVUTIL_ASSERT(CHAIN_PINNED_R(*pinned));\n\tchain = *first = *pinned;\n\t*last = src->last;\n\n\t/* If there's data in the first pinned chain, we need to allocate\n\t * a new chain and copy the data over. */\n\tif (chain->off) {\n\t\tstruct evbuffer_chain *tmp;\n\n\t\tEVUTIL_ASSERT(pinned == src->last_with_datap);\n\t\ttmp = evbuffer_chain_new_membuf(chain->off);\n\t\tif (!tmp)\n\t\t\treturn -1;\n\t\tmemcpy(tmp->buffer, chain->buffer + chain->misalign,\n\t\t\tchain->off);\n\t\ttmp->off = chain->off;\n\t\t*src->last_with_datap = tmp;\n\t\tsrc->last = tmp;\n\t\tchain->misalign += chain->off;\n\t\tchain->off = 0;\n\t} else {\n\t\tsrc->last = *src->last_with_datap;\n\t\t*pinned = NULL;\n\t}\n\n\treturn 0;\n}\n\nstatic inline void\nRESTORE_PINNED(struct evbuffer *src, struct evbuffer_chain *pinned,\n\t\tstruct evbuffer_chain *last)\n{\n\tASSERT_EVBUFFER_LOCKED(src);\n\n\tif (!pinned) {\n\t\tZERO_CHAIN(src);\n\t\treturn;\n\t}\n\n\tsrc->first = pinned;\n\tsrc->last = last;\n\tsrc->last_with_datap = &src->first;\n\tsrc->total_len = 0;\n}\n\nstatic inline void\nCOPY_CHAIN(struct evbuffer *dst, struct evbuffer *src)\n{\n\tASSERT_EVBUFFER_LOCKED(dst);\n\tASSERT_EVBUFFER_LOCKED(src);\n\tdst->first = src->first;\n\tif (src->last_with_datap == &src->first)\n\t\tdst->last_with_datap = &dst->first;\n\telse\n\t\tdst->last_with_datap = src->last_with_datap;\n\tdst->last = src->last;\n\tdst->total_len = src->total_len;\n}\n\nstatic void\nAPPEND_CHAIN(struct evbuffer *dst, struct evbuffer *src)\n{\n\tstruct evbuffer_chain **chp;\n\n\tASSERT_EVBUFFER_LOCKED(dst);\n\tASSERT_EVBUFFER_LOCKED(src);\n\n\tchp = evbuffer_free_trailing_empty_chains(dst);\n\t*chp = src->first;\n\n\tif (src->last_with_datap == &src->first)\n\t\tdst->last_with_datap = chp;\n\telse\n\t\tdst->last_with_datap = src->last_with_datap;\n\tdst->last = src->last;\n\tdst->total_len += src->total_len;\n}\n\nstatic inline void\nAPPEND_CHAIN_MULTICAST(struct evbuffer *dst, struct evbuffer *src)\n{\n\tstruct evbuffer_chain *tmp;\n\tstruct evbuffer_chain *chain = src->first;\n\tstruct evbuffer_multicast_parent *extra;\n\n\tASSERT_EVBUFFER_LOCKED(dst);\n\tASSERT_EVBUFFER_LOCKED(src);\n\n\tfor (; chain; chain = chain->next) {\n\t\tif (!chain->off || chain->flags & EVBUFFER_DANGLING) {\n\t\t\t/* skip empty chains */\n\t\t\tcontinue;\n\t\t}\n\n\t\ttmp = evbuffer_chain_new(sizeof(struct evbuffer_multicast_parent));\n\t\tif (!tmp) {\n\t\t\tevent_warn(\"%s: out of memory\", __func__);\n\t\t\treturn;\n\t\t}\n\t\textra = EVBUFFER_CHAIN_EXTRA(struct evbuffer_multicast_parent, tmp);\n\t\t/* reference evbuffer containing source chain so it\n\t\t * doesn't get released while the chain is still\n\t\t * being referenced to */\n\t\tevbuffer_incref_(src);\n\t\textra->source = src;\n\t\t/* reference source chain which now becomes immutable */\n\t\tevbuffer_chain_incref(chain);\n\t\textra->parent = chain;\n\t\tchain->flags |= EVBUFFER_IMMUTABLE;\n\t\ttmp->buffer_len = chain->buffer_len;\n\t\ttmp->misalign = chain->misalign;\n\t\ttmp->off = chain->off;\n\t\ttmp->flags |= EVBUFFER_MULTICAST|EVBUFFER_IMMUTABLE;\n\t\ttmp->buffer = chain->buffer;\n\t\tevbuffer_chain_insert(dst, tmp);\n\t}\n}\n\nstatic void\nPREPEND_CHAIN(struct evbuffer *dst, struct evbuffer *src)\n{\n\tASSERT_EVBUFFER_LOCKED(dst);\n\tASSERT_EVBUFFER_LOCKED(src);\n\tsrc->last->next = dst->first;\n\tdst->first = src->first;\n\tdst->total_len += src->total_len;\n\tif (*dst->last_with_datap == NULL) {\n\t\tif (src->last_with_datap == &(src)->first)\n\t\t\tdst->last_with_datap = &dst->first;\n\t\telse\n\t\t\tdst->last_with_datap = src->last_with_datap;\n\t} else if (dst->last_with_datap == &dst->first) {\n\t\tdst->last_with_datap = &src->last->next;\n\t}\n}\n\nint\nevbuffer_add_buffer(struct evbuffer *outbuf, struct evbuffer *inbuf)\n{\n\tstruct evbuffer_chain *pinned, *last;\n\tsize_t in_total_len, out_total_len;\n\tint result = 0;\n\n\tEVBUFFER_LOCK2(inbuf, outbuf);\n\tin_total_len = inbuf->total_len;\n\tout_total_len = outbuf->total_len;\n\n\tif (in_total_len == 0 || outbuf == inbuf)\n\t\tgoto done;\n\n\tif (outbuf->freeze_end || inbuf->freeze_start) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tif (PRESERVE_PINNED(inbuf, &pinned, &last) < 0) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tif (out_total_len == 0) {\n\t\t/* There might be an empty chain at the start of outbuf; free\n\t\t * it. */\n\t\tevbuffer_free_all_chains(outbuf->first);\n\t\tCOPY_CHAIN(outbuf, inbuf);\n\t} else {\n\t\tAPPEND_CHAIN(outbuf, inbuf);\n\t}\n\n\tRESTORE_PINNED(inbuf, pinned, last);\n\n\tinbuf->n_del_for_cb += in_total_len;\n\toutbuf->n_add_for_cb += in_total_len;\n\n\tevbuffer_invoke_callbacks_(inbuf);\n\tevbuffer_invoke_callbacks_(outbuf);\n\ndone:\n\tEVBUFFER_UNLOCK2(inbuf, outbuf);\n\treturn result;\n}\n\nint\nevbuffer_add_buffer_reference(struct evbuffer *outbuf, struct evbuffer *inbuf)\n{\n\tsize_t in_total_len, out_total_len;\n\tstruct evbuffer_chain *chain;\n\tint result = 0;\n\n\tEVBUFFER_LOCK2(inbuf, outbuf);\n\tin_total_len = inbuf->total_len;\n\tout_total_len = outbuf->total_len;\n\tchain = inbuf->first;\n\n\tif (in_total_len == 0)\n\t\tgoto done;\n\n\tif (outbuf->freeze_end || outbuf == inbuf) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tfor (; chain; chain = chain->next) {\n\t\tif ((chain->flags & (EVBUFFER_FILESEGMENT|EVBUFFER_SENDFILE|EVBUFFER_MULTICAST)) != 0) {\n\t\t\t/* chain type can not be referenced */\n\t\t\tresult = -1;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tif (out_total_len == 0) {\n\t\t/* There might be an empty chain at the start of outbuf; free\n\t\t * it. */\n\t\tevbuffer_free_all_chains(outbuf->first);\n\t}\n\tAPPEND_CHAIN_MULTICAST(outbuf, inbuf);\n\n\toutbuf->n_add_for_cb += in_total_len;\n\tevbuffer_invoke_callbacks_(outbuf);\n\ndone:\n\tEVBUFFER_UNLOCK2(inbuf, outbuf);\n\treturn result;\n}\n\nint\nevbuffer_prepend_buffer(struct evbuffer *outbuf, struct evbuffer *inbuf)\n{\n\tstruct evbuffer_chain *pinned, *last;\n\tsize_t in_total_len, out_total_len;\n\tint result = 0;\n\n\tEVBUFFER_LOCK2(inbuf, outbuf);\n\n\tin_total_len = inbuf->total_len;\n\tout_total_len = outbuf->total_len;\n\n\tif (!in_total_len || inbuf == outbuf)\n\t\tgoto done;\n\n\tif (outbuf->freeze_start || inbuf->freeze_start) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tif (PRESERVE_PINNED(inbuf, &pinned, &last) < 0) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tif (out_total_len == 0) {\n\t\t/* There might be an empty chain at the start of outbuf; free\n\t\t * it. */\n\t\tevbuffer_free_all_chains(outbuf->first);\n\t\tCOPY_CHAIN(outbuf, inbuf);\n\t} else {\n\t\tPREPEND_CHAIN(outbuf, inbuf);\n\t}\n\n\tRESTORE_PINNED(inbuf, pinned, last);\n\n\tinbuf->n_del_for_cb += in_total_len;\n\toutbuf->n_add_for_cb += in_total_len;\n\n\tevbuffer_invoke_callbacks_(inbuf);\n\tevbuffer_invoke_callbacks_(outbuf);\ndone:\n\tEVBUFFER_UNLOCK2(inbuf, outbuf);\n\treturn result;\n}\n\nint\nevbuffer_drain(struct evbuffer *buf, size_t len)\n{\n\tstruct evbuffer_chain *chain, *next;\n\tsize_t remaining, old_len;\n\tint result = 0;\n\n\tEVBUFFER_LOCK(buf);\n\told_len = buf->total_len;\n\n\tif (old_len == 0)\n\t\tgoto done;\n\n\tif (buf->freeze_start) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tif (len >= old_len && !HAS_PINNED_R(buf)) {\n\t\tlen = old_len;\n\t\tfor (chain = buf->first; chain != NULL; chain = next) {\n\t\t\tnext = chain->next;\n\t\t\tevbuffer_chain_free(chain);\n\t\t}\n\n\t\tZERO_CHAIN(buf);\n\t} else {\n\t\tif (len >= old_len)\n\t\t\tlen = old_len;\n\n\t\tbuf->total_len -= len;\n\t\tremaining = len;\n\t\tfor (chain = buf->first;\n\t\t     remaining >= chain->off;\n\t\t     chain = next) {\n\t\t\tnext = chain->next;\n\t\t\tremaining -= chain->off;\n\n\t\t\tif (chain == *buf->last_with_datap) {\n\t\t\t\tbuf->last_with_datap = &buf->first;\n\t\t\t}\n\t\t\tif (&chain->next == buf->last_with_datap)\n\t\t\t\tbuf->last_with_datap = &buf->first;\n\n\t\t\tif (CHAIN_PINNED_R(chain)) {\n\t\t\t\tEVUTIL_ASSERT(remaining == 0);\n\t\t\t\tchain->misalign += chain->off;\n\t\t\t\tchain->off = 0;\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t\tevbuffer_chain_free(chain);\n\t\t}\n\n\t\tbuf->first = chain;\n\t\tEVUTIL_ASSERT(remaining <= chain->off);\n\t\tchain->misalign += remaining;\n\t\tchain->off -= remaining;\n\t}\n\n\tbuf->n_del_for_cb += len;\n\t/* Tell someone about changes in this buffer */\n\tevbuffer_invoke_callbacks_(buf);\n\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\n/* Reads data from an event buffer and drains the bytes read */\nint\nevbuffer_remove(struct evbuffer *buf, void *data_out, size_t datlen)\n{\n\tev_ssize_t n;\n\tEVBUFFER_LOCK(buf);\n\tn = evbuffer_copyout_from(buf, NULL, data_out, datlen);\n\tif (n > 0) {\n\t\tif (evbuffer_drain(buf, n)<0)\n\t\t\tn = -1;\n\t}\n\tEVBUFFER_UNLOCK(buf);\n\treturn (int)n;\n}\n\nev_ssize_t\nevbuffer_copyout(struct evbuffer *buf, void *data_out, size_t datlen)\n{\n\treturn evbuffer_copyout_from(buf, NULL, data_out, datlen);\n}\n\nev_ssize_t\nevbuffer_copyout_from(struct evbuffer *buf, const struct evbuffer_ptr *pos,\n    void *data_out, size_t datlen)\n{\n\t/*XXX fails badly on sendfile case. */\n\tstruct evbuffer_chain *chain;\n\tchar *data = data_out;\n\tsize_t nread;\n\tev_ssize_t result = 0;\n\tsize_t pos_in_chain;\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (pos) {\n\t\tif (datlen > (size_t)(EV_SSIZE_MAX - pos->pos)) {\n\t\t\tresult = -1;\n\t\t\tgoto done;\n\t\t}\n\t\tchain = pos->internal_.chain;\n\t\tpos_in_chain = pos->internal_.pos_in_chain;\n\t\tif (datlen + pos->pos > buf->total_len)\n\t\t\tdatlen = buf->total_len - pos->pos;\n\t} else {\n\t\tchain = buf->first;\n\t\tpos_in_chain = 0;\n\t\tif (datlen > buf->total_len)\n\t\t\tdatlen = buf->total_len;\n\t}\n\n\n\tif (datlen == 0)\n\t\tgoto done;\n\n\tif (buf->freeze_start) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tnread = datlen;\n\n\twhile (datlen && datlen >= chain->off - pos_in_chain) {\n\t\tsize_t copylen = chain->off - pos_in_chain;\n\t\tmemcpy(data,\n\t\t    chain->buffer + chain->misalign + pos_in_chain,\n\t\t    copylen);\n\t\tdata += copylen;\n\t\tdatlen -= copylen;\n\n\t\tchain = chain->next;\n\t\tpos_in_chain = 0;\n\t\tEVUTIL_ASSERT(chain || datlen==0);\n\t}\n\n\tif (datlen) {\n\t\tEVUTIL_ASSERT(chain);\n\t\tEVUTIL_ASSERT(datlen+pos_in_chain <= chain->off);\n\n\t\tmemcpy(data, chain->buffer + chain->misalign + pos_in_chain,\n\t\t    datlen);\n\t}\n\n\tresult = nread;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\n/* reads data from the src buffer to the dst buffer, avoids memcpy as\n * possible. */\n/*  XXXX should return ev_ssize_t */\nint\nevbuffer_remove_buffer(struct evbuffer *src, struct evbuffer *dst,\n    size_t datlen)\n{\n\t/*XXX We should have an option to force this to be zero-copy.*/\n\n\t/*XXX can fail badly on sendfile case. */\n\tstruct evbuffer_chain *chain, *previous;\n\tsize_t nread = 0;\n\tint result;\n\n\tEVBUFFER_LOCK2(src, dst);\n\n\tchain = previous = src->first;\n\n\tif (datlen == 0 || dst == src) {\n\t\tresult = 0;\n\t\tgoto done;\n\t}\n\n\tif (dst->freeze_end || src->freeze_start) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\t/* short-cut if there is no more data buffered */\n\tif (datlen >= src->total_len) {\n\t\tdatlen = src->total_len;\n\t\tevbuffer_add_buffer(dst, src);\n\t\tresult = (int)datlen; /*XXXX should return ev_ssize_t*/\n\t\tgoto done;\n\t}\n\n\t/* removes chains if possible */\n\twhile (chain->off <= datlen) {\n\t\t/* We can't remove the last with data from src unless we\n\t\t * remove all chains, in which case we would have done the if\n\t\t * block above */\n\t\tEVUTIL_ASSERT(chain != *src->last_with_datap);\n\t\tnread += chain->off;\n\t\tdatlen -= chain->off;\n\t\tprevious = chain;\n\t\tif (src->last_with_datap == &chain->next)\n\t\t\tsrc->last_with_datap = &src->first;\n\t\tchain = chain->next;\n\t}\n\n\tif (chain != src->first) {\n\t\t/* we can remove the chain */\n\t\tstruct evbuffer_chain **chp;\n\t\tchp = evbuffer_free_trailing_empty_chains(dst);\n\n\t\tif (dst->first == NULL) {\n\t\t\tdst->first = src->first;\n\t\t} else {\n\t\t\t*chp = src->first;\n\t\t}\n\t\tdst->last = previous;\n\t\tprevious->next = NULL;\n\t\tsrc->first = chain;\n\t\tadvance_last_with_data(dst);\n\n\t\tdst->total_len += nread;\n\t\tdst->n_add_for_cb += nread;\n\t}\n\n\t/* we know that there is more data in the src buffer than\n\t * we want to read, so we manually drain the chain */\n\tevbuffer_add(dst, chain->buffer + chain->misalign, datlen);\n\tchain->misalign += datlen;\n\tchain->off -= datlen;\n\tnread += datlen;\n\n\t/* You might think we would want to increment dst->n_add_for_cb\n\t * here too.  But evbuffer_add above already took care of that.\n\t */\n\tsrc->total_len -= nread;\n\tsrc->n_del_for_cb += nread;\n\n\tif (nread) {\n\t\tevbuffer_invoke_callbacks_(dst);\n\t\tevbuffer_invoke_callbacks_(src);\n\t}\n\tresult = (int)nread;/*XXXX should change return type */\n\ndone:\n\tEVBUFFER_UNLOCK2(src, dst);\n\treturn result;\n}\n\nunsigned char *\nevbuffer_pullup(struct evbuffer *buf, ev_ssize_t size)\n{\n\tstruct evbuffer_chain *chain, *next, *tmp, *last_with_data;\n\tunsigned char *buffer, *result = NULL;\n\tev_ssize_t remaining;\n\tint removed_last_with_data = 0;\n\tint removed_last_with_datap = 0;\n\n\tEVBUFFER_LOCK(buf);\n\n\tchain = buf->first;\n\n\tif (size < 0)\n\t\tsize = buf->total_len;\n\t/* if size > buf->total_len, we cannot guarantee to the user that she\n\t * is going to have a long enough buffer afterwards; so we return\n\t * NULL */\n\tif (size == 0 || (size_t)size > buf->total_len)\n\t\tgoto done;\n\n\t/* No need to pull up anything; the first size bytes are\n\t * already here. */\n\tif (chain->off >= (size_t)size) {\n\t\tresult = chain->buffer + chain->misalign;\n\t\tgoto done;\n\t}\n\n\t/* Make sure that none of the chains we need to copy from is pinned. */\n\tremaining = size - chain->off;\n\tEVUTIL_ASSERT(remaining >= 0);\n\tfor (tmp=chain->next; tmp; tmp=tmp->next) {\n\t\tif (CHAIN_PINNED(tmp))\n\t\t\tgoto done;\n\t\tif (tmp->off >= (size_t)remaining)\n\t\t\tbreak;\n\t\tremaining -= tmp->off;\n\t}\n\n\tif (CHAIN_PINNED(chain)) {\n\t\tsize_t old_off = chain->off;\n\t\tif (CHAIN_SPACE_LEN(chain) < size - chain->off) {\n\t\t\t/* not enough room at end of chunk. */\n\t\t\tgoto done;\n\t\t}\n\t\tbuffer = CHAIN_SPACE_PTR(chain);\n\t\ttmp = chain;\n\t\ttmp->off = size;\n\t\tsize -= old_off;\n\t\tchain = chain->next;\n\t} else if (chain->buffer_len - chain->misalign >= (size_t)size) {\n\t\t/* already have enough space in the first chain */\n\t\tsize_t old_off = chain->off;\n\t\tbuffer = chain->buffer + chain->misalign + chain->off;\n\t\ttmp = chain;\n\t\ttmp->off = size;\n\t\tsize -= old_off;\n\t\tchain = chain->next;\n\t} else {\n\t\tif ((tmp = evbuffer_chain_new_membuf(size)) == NULL) {\n\t\t\tevent_warn(\"%s: out of memory\", __func__);\n\t\t\tgoto done;\n\t\t}\n\t\tbuffer = tmp->buffer;\n\t\ttmp->off = size;\n\t\tbuf->first = tmp;\n\t}\n\n\t/* TODO(niels): deal with buffers that point to NULL like sendfile */\n\n\t/* Copy and free every chunk that will be entirely pulled into tmp */\n\tlast_with_data = *buf->last_with_datap;\n\tfor (; chain != NULL && (size_t)size >= chain->off; chain = next) {\n\t\tnext = chain->next;\n\n\t\tif (chain->buffer) {\n\t\t\tmemcpy(buffer, chain->buffer + chain->misalign, chain->off);\n\t\t\tsize -= chain->off;\n\t\t\tbuffer += chain->off;\n\t\t}\n\t\tif (chain == last_with_data)\n\t\t\tremoved_last_with_data = 1;\n\t\tif (&chain->next == buf->last_with_datap)\n\t\t\tremoved_last_with_datap = 1;\n\n\t\tevbuffer_chain_free(chain);\n\t}\n\n\tif (chain != NULL) {\n\t\tmemcpy(buffer, chain->buffer + chain->misalign, size);\n\t\tchain->misalign += size;\n\t\tchain->off -= size;\n\t} else {\n\t\tbuf->last = tmp;\n\t}\n\n\ttmp->next = chain;\n\n\tif (removed_last_with_data) {\n\t\tbuf->last_with_datap = &buf->first;\n\t} else if (removed_last_with_datap) {\n\t\tif (buf->first->next && buf->first->next->off)\n\t\t\tbuf->last_with_datap = &buf->first->next;\n\t\telse\n\t\t\tbuf->last_with_datap = &buf->first;\n\t}\n\n\tresult = (tmp->buffer + tmp->misalign);\n\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\n/*\n * Reads a line terminated by either '\\r\\n', '\\n\\r' or '\\r' or '\\n'.\n * The returned buffer needs to be freed by the called.\n */\nchar *\nevbuffer_readline(struct evbuffer *buffer)\n{\n\treturn evbuffer_readln(buffer, NULL, EVBUFFER_EOL_ANY);\n}\n\nstatic inline ev_ssize_t\nevbuffer_strchr(struct evbuffer_ptr *it, const char chr)\n{\n\tstruct evbuffer_chain *chain = it->internal_.chain;\n\tsize_t i = it->internal_.pos_in_chain;\n\twhile (chain != NULL) {\n\t\tchar *buffer = (char *)chain->buffer + chain->misalign;\n\t\tchar *cp = memchr(buffer+i, chr, chain->off-i);\n\t\tif (cp) {\n\t\t\tit->internal_.chain = chain;\n\t\t\tit->internal_.pos_in_chain = cp - buffer;\n\t\t\tit->pos += (cp - buffer - i);\n\t\t\treturn it->pos;\n\t\t}\n\t\tit->pos += chain->off - i;\n\t\ti = 0;\n\t\tchain = chain->next;\n\t}\n\n\treturn (-1);\n}\n\nstatic inline char *\nfind_eol_char(char *s, size_t len)\n{\n#define CHUNK_SZ 128\n\t/* Lots of benchmarking found this approach to be faster in practice\n\t * than doing two memchrs over the whole buffer, doin a memchr on each\n\t * char of the buffer, or trying to emulate memchr by hand. */\n\tchar *s_end, *cr, *lf;\n\ts_end = s+len;\n\twhile (s < s_end) {\n\t\tsize_t chunk = (s + CHUNK_SZ < s_end) ? CHUNK_SZ : (s_end - s);\n\t\tcr = memchr(s, '\\r', chunk);\n\t\tlf = memchr(s, '\\n', chunk);\n\t\tif (cr) {\n\t\t\tif (lf && lf < cr)\n\t\t\t\treturn lf;\n\t\t\treturn cr;\n\t\t} else if (lf) {\n\t\t\treturn lf;\n\t\t}\n\t\ts += CHUNK_SZ;\n\t}\n\n\treturn NULL;\n#undef CHUNK_SZ\n}\n\nstatic ev_ssize_t\nevbuffer_find_eol_char(struct evbuffer_ptr *it)\n{\n\tstruct evbuffer_chain *chain = it->internal_.chain;\n\tsize_t i = it->internal_.pos_in_chain;\n\twhile (chain != NULL) {\n\t\tchar *buffer = (char *)chain->buffer + chain->misalign;\n\t\tchar *cp = find_eol_char(buffer+i, chain->off-i);\n\t\tif (cp) {\n\t\t\tit->internal_.chain = chain;\n\t\t\tit->internal_.pos_in_chain = cp - buffer;\n\t\t\tit->pos += (cp - buffer) - i;\n\t\t\treturn it->pos;\n\t\t}\n\t\tit->pos += chain->off - i;\n\t\ti = 0;\n\t\tchain = chain->next;\n\t}\n\n\treturn (-1);\n}\n\nstatic inline size_t\nevbuffer_strspn(\n\tstruct evbuffer_ptr *ptr, const char *chrset)\n{\n\tsize_t count = 0;\n\tstruct evbuffer_chain *chain = ptr->internal_.chain;\n\tsize_t i = ptr->internal_.pos_in_chain;\n\n\tif (!chain)\n\t\treturn 0;\n\n\twhile (1) {\n\t\tchar *buffer = (char *)chain->buffer + chain->misalign;\n\t\tfor (; i < chain->off; ++i) {\n\t\t\tconst char *p = chrset;\n\t\t\twhile (*p) {\n\t\t\t\tif (buffer[i] == *p++)\n\t\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tptr->internal_.chain = chain;\n\t\t\tptr->internal_.pos_in_chain = i;\n\t\t\tptr->pos += count;\n\t\t\treturn count;\n\t\tnext:\n\t\t\t++count;\n\t\t}\n\t\ti = 0;\n\n\t\tif (! chain->next) {\n\t\t\tptr->internal_.chain = chain;\n\t\t\tptr->internal_.pos_in_chain = i;\n\t\t\tptr->pos += count;\n\t\t\treturn count;\n\t\t}\n\n\t\tchain = chain->next;\n\t}\n}\n\n\nstatic inline int\nevbuffer_getchr(struct evbuffer_ptr *it)\n{\n\tstruct evbuffer_chain *chain = it->internal_.chain;\n\tsize_t off = it->internal_.pos_in_chain;\n\n\tif (chain == NULL)\n\t\treturn -1;\n\n\treturn (unsigned char)chain->buffer[chain->misalign + off];\n}\n\nstruct evbuffer_ptr\nevbuffer_search_eol(struct evbuffer *buffer,\n    struct evbuffer_ptr *start, size_t *eol_len_out,\n    enum evbuffer_eol_style eol_style)\n{\n\tstruct evbuffer_ptr it, it2;\n\tsize_t extra_drain = 0;\n\tint ok = 0;\n\n\t/* Avoid locking in trivial edge cases */\n\tif (start && start->internal_.chain == NULL) {\n\t\tPTR_NOT_FOUND(&it);\n\t\tif (eol_len_out)\n\t\t\t*eol_len_out = extra_drain;\n\t\treturn it;\n\t}\n\n\tEVBUFFER_LOCK(buffer);\n\n\tif (start) {\n\t\tmemcpy(&it, start, sizeof(it));\n\t} else {\n\t\tit.pos = 0;\n\t\tit.internal_.chain = buffer->first;\n\t\tit.internal_.pos_in_chain = 0;\n\t}\n\n\t/* the eol_style determines our first stop character and how many\n\t * characters we are going to drain afterwards. */\n\tswitch (eol_style) {\n\tcase EVBUFFER_EOL_ANY:\n\t\tif (evbuffer_find_eol_char(&it) < 0)\n\t\t\tgoto done;\n\t\tmemcpy(&it2, &it, sizeof(it));\n\t\textra_drain = evbuffer_strspn(&it2, \"\\r\\n\");\n\t\tbreak;\n\tcase EVBUFFER_EOL_CRLF_STRICT: {\n\t\tit = evbuffer_search(buffer, \"\\r\\n\", 2, &it);\n\t\tif (it.pos < 0)\n\t\t\tgoto done;\n\t\textra_drain = 2;\n\t\tbreak;\n\t}\n\tcase EVBUFFER_EOL_CRLF: {\n\t\tev_ssize_t start_pos = it.pos;\n\t\t/* Look for a LF ... */\n\t\tif (evbuffer_strchr(&it, '\\n') < 0)\n\t\t\tgoto done;\n\t\textra_drain = 1;\n\t\t/* ... optionally preceded by a CR. */\n\t\tif (it.pos == start_pos)\n\t\t\tbreak; /* If the first character is \\n, don't back up */\n\t\t/* This potentially does an extra linear walk over the first\n\t\t * few chains.  Probably, that's not too expensive unless you\n\t\t * have a really pathological setup. */\n\t\tmemcpy(&it2, &it, sizeof(it));\n\t\tif (evbuffer_ptr_subtract(buffer, &it2, 1)<0)\n\t\t\tbreak;\n\t\tif (evbuffer_getchr(&it2) == '\\r') {\n\t\t\tmemcpy(&it, &it2, sizeof(it));\n\t\t\textra_drain = 2;\n\t\t}\n\t\tbreak;\n\t}\n\tcase EVBUFFER_EOL_LF:\n\t\tif (evbuffer_strchr(&it, '\\n') < 0)\n\t\t\tgoto done;\n\t\textra_drain = 1;\n\t\tbreak;\n\tcase EVBUFFER_EOL_NUL:\n\t\tif (evbuffer_strchr(&it, '\\0') < 0)\n\t\t\tgoto done;\n\t\textra_drain = 1;\n\t\tbreak;\n\tdefault:\n\t\tgoto done;\n\t}\n\n\tok = 1;\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\n\tif (!ok)\n\t\tPTR_NOT_FOUND(&it);\n\tif (eol_len_out)\n\t\t*eol_len_out = extra_drain;\n\n\treturn it;\n}\n\nchar *\nevbuffer_readln(struct evbuffer *buffer, size_t *n_read_out,\n\t\tenum evbuffer_eol_style eol_style)\n{\n\tstruct evbuffer_ptr it;\n\tchar *line;\n\tsize_t n_to_copy=0, extra_drain=0;\n\tchar *result = NULL;\n\n\tEVBUFFER_LOCK(buffer);\n\n\tif (buffer->freeze_start) {\n\t\tgoto done;\n\t}\n\n\tit = evbuffer_search_eol(buffer, NULL, &extra_drain, eol_style);\n\tif (it.pos < 0)\n\t\tgoto done;\n\tn_to_copy = it.pos;\n\n\tif ((line = mm_malloc(n_to_copy+1)) == NULL) {\n\t\tevent_warn(\"%s: out of memory\", __func__);\n\t\tgoto done;\n\t}\n\n\tevbuffer_remove(buffer, line, n_to_copy);\n\tline[n_to_copy] = '\\0';\n\n\tevbuffer_drain(buffer, extra_drain);\n\tresult = line;\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\n\tif (n_read_out)\n\t\t*n_read_out = result ? n_to_copy : 0;\n\n\treturn result;\n}\n\n#define EVBUFFER_CHAIN_MAX_AUTO_SIZE 4096\n\n/* Adds data to an event buffer */\n\nint\nevbuffer_add(struct evbuffer *buf, const void *data_in, size_t datlen)\n{\n\tstruct evbuffer_chain *chain, *tmp;\n\tconst unsigned char *data = data_in;\n\tsize_t remain, to_alloc;\n\tint result = -1;\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (buf->freeze_end) {\n\t\tgoto done;\n\t}\n\t/* Prevent buf->total_len overflow */\n\tif (datlen > EV_SIZE_MAX - buf->total_len) {\n\t\tgoto done;\n\t}\n\n\tif (*buf->last_with_datap == NULL) {\n\t\tchain = buf->last;\n\t} else {\n\t\tchain = *buf->last_with_datap;\n\t}\n\n\t/* If there are no chains allocated for this buffer, allocate one\n\t * big enough to hold all the data. */\n\tif (chain == NULL) {\n\t\tchain = evbuffer_chain_insert_new(buf, datlen);\n\t\tif (!chain)\n\t\t\tgoto done;\n\t}\n\n\tif ((chain->flags & EVBUFFER_IMMUTABLE) == 0) {\n\t\t/* Always true for mutable buffers */\n\t\tEVUTIL_ASSERT(chain->misalign >= 0 &&\n\t\t    (ev_uint64_t)chain->misalign <= EVBUFFER_CHAIN_MAX);\n\t\tremain = chain->buffer_len - (size_t)chain->misalign - chain->off;\n\t\tif (remain >= datlen) {\n\t\t\t/* there's enough space to hold all the data in the\n\t\t\t * current last chain */\n\t\t\tmemcpy(chain->buffer + chain->misalign + chain->off,\n\t\t\t    data, datlen);\n\t\t\tchain->off += datlen;\n\t\t\tbuf->total_len += datlen;\n\t\t\tbuf->n_add_for_cb += datlen;\n\t\t\tgoto out;\n\t\t} else if (!CHAIN_PINNED(chain) &&\n\t\t    evbuffer_chain_should_realign(chain, datlen)) {\n\t\t\t/* we can fit the data into the misalignment */\n\t\t\tevbuffer_chain_align(chain);\n\n\t\t\tmemcpy(chain->buffer + chain->off, data, datlen);\n\t\t\tchain->off += datlen;\n\t\t\tbuf->total_len += datlen;\n\t\t\tbuf->n_add_for_cb += datlen;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t/* we cannot write any data to the last chain */\n\t\tremain = 0;\n\t}\n\n\t/* we need to add another chain */\n\tto_alloc = chain->buffer_len;\n\tif (to_alloc <= EVBUFFER_CHAIN_MAX_AUTO_SIZE/2)\n\t\tto_alloc <<= 1;\n\tif (datlen > to_alloc)\n\t\tto_alloc = datlen;\n\ttmp = evbuffer_chain_new_membuf(to_alloc);\n\tif (tmp == NULL)\n\t\tgoto done;\n\n\tif (remain) {\n\t\tmemcpy(chain->buffer + chain->misalign + chain->off,\n\t\t    data, remain);\n\t\tchain->off += remain;\n\t\tbuf->total_len += remain;\n\t\tbuf->n_add_for_cb += remain;\n\t}\n\n\tdata += remain;\n\tdatlen -= remain;\n\n\tmemcpy(tmp->buffer, data, datlen);\n\ttmp->off = datlen;\n\tevbuffer_chain_insert(buf, tmp);\n\tbuf->n_add_for_cb += datlen;\n\nout:\n\tevbuffer_invoke_callbacks_(buf);\n\tresult = 0;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\nint\nevbuffer_prepend(struct evbuffer *buf, const void *data, size_t datlen)\n{\n\tstruct evbuffer_chain *chain, *tmp;\n\tint result = -1;\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (datlen == 0) {\n\t\tresult = 0;\n\t\tgoto done;\n\t}\n\tif (buf->freeze_start) {\n\t\tgoto done;\n\t}\n\tif (datlen > EV_SIZE_MAX - buf->total_len) {\n\t\tgoto done;\n\t}\n\n\tchain = buf->first;\n\n\tif (chain == NULL) {\n\t\tchain = evbuffer_chain_insert_new(buf, datlen);\n\t\tif (!chain)\n\t\t\tgoto done;\n\t}\n\n\t/* we cannot touch immutable buffers */\n\tif ((chain->flags & EVBUFFER_IMMUTABLE) == 0) {\n\t\t/* Always true for mutable buffers */\n\t\tEVUTIL_ASSERT(chain->misalign >= 0 &&\n\t\t    (ev_uint64_t)chain->misalign <= EVBUFFER_CHAIN_MAX);\n\n\t\t/* If this chain is empty, we can treat it as\n\t\t * 'empty at the beginning' rather than 'empty at the end' */\n\t\tif (chain->off == 0)\n\t\t\tchain->misalign = chain->buffer_len;\n\n\t\tif ((size_t)chain->misalign >= datlen) {\n\t\t\t/* we have enough space to fit everything */\n\t\t\tmemcpy(chain->buffer + chain->misalign - datlen,\n\t\t\t    data, datlen);\n\t\t\tchain->off += datlen;\n\t\t\tchain->misalign -= datlen;\n\t\t\tbuf->total_len += datlen;\n\t\t\tbuf->n_add_for_cb += datlen;\n\t\t\tgoto out;\n\t\t} else if (chain->misalign) {\n\t\t\t/* we can only fit some of the data. */\n\t\t\tmemcpy(chain->buffer,\n\t\t\t    (char*)data + datlen - chain->misalign,\n\t\t\t    (size_t)chain->misalign);\n\t\t\tchain->off += (size_t)chain->misalign;\n\t\t\tbuf->total_len += (size_t)chain->misalign;\n\t\t\tbuf->n_add_for_cb += (size_t)chain->misalign;\n\t\t\tdatlen -= (size_t)chain->misalign;\n\t\t\tchain->misalign = 0;\n\t\t}\n\t}\n\n\t/* we need to add another chain */\n\tif ((tmp = evbuffer_chain_new_membuf(datlen)) == NULL)\n\t\tgoto done;\n\tbuf->first = tmp;\n\tif (buf->last_with_datap == &buf->first && chain->off)\n\t\tbuf->last_with_datap = &tmp->next;\n\n\ttmp->next = chain;\n\n\ttmp->off = datlen;\n\tEVUTIL_ASSERT(datlen <= tmp->buffer_len);\n\ttmp->misalign = tmp->buffer_len - datlen;\n\n\tmemcpy(tmp->buffer + tmp->misalign, data, datlen);\n\tbuf->total_len += datlen;\n\tbuf->n_add_for_cb += datlen;\n\nout:\n\tevbuffer_invoke_callbacks_(buf);\n\tresult = 0;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\n/** Helper: realigns the memory in chain->buffer so that misalign is 0. */\nstatic void\nevbuffer_chain_align(struct evbuffer_chain *chain)\n{\n\tEVUTIL_ASSERT(!(chain->flags & EVBUFFER_IMMUTABLE));\n\tEVUTIL_ASSERT(!(chain->flags & EVBUFFER_MEM_PINNED_ANY));\n\tmemmove(chain->buffer, chain->buffer + chain->misalign, chain->off);\n\tchain->misalign = 0;\n}\n\n#define MAX_TO_COPY_IN_EXPAND 4096\n#define MAX_TO_REALIGN_IN_EXPAND 2048\n\n/** Helper: return true iff we should realign chain to fit datalen bytes of\n    data in it. */\nstatic int\nevbuffer_chain_should_realign(struct evbuffer_chain *chain,\n    size_t datlen)\n{\n\treturn chain->buffer_len - chain->off >= datlen &&\n\t    (chain->off < chain->buffer_len / 2) &&\n\t    (chain->off <= MAX_TO_REALIGN_IN_EXPAND);\n}\n\n/* Expands the available space in the event buffer to at least datlen, all in\n * a single chunk.  Return that chunk. */\nstatic struct evbuffer_chain *\nevbuffer_expand_singlechain(struct evbuffer *buf, size_t datlen)\n{\n\tstruct evbuffer_chain *chain, **chainp;\n\tstruct evbuffer_chain *result = NULL;\n\tASSERT_EVBUFFER_LOCKED(buf);\n\n\tchainp = buf->last_with_datap;\n\n\t/* XXX If *chainp is no longer writeable, but has enough space in its\n\t * misalign, this might be a bad idea: we could still use *chainp, not\n\t * (*chainp)->next. */\n\tif (*chainp && CHAIN_SPACE_LEN(*chainp) == 0)\n\t\tchainp = &(*chainp)->next;\n\n\t/* 'chain' now points to the first chain with writable space (if any)\n\t * We will either use it, realign it, replace it, or resize it. */\n\tchain = *chainp;\n\n\tif (chain == NULL ||\n\t    (chain->flags & (EVBUFFER_IMMUTABLE|EVBUFFER_MEM_PINNED_ANY))) {\n\t\t/* We can't use the last_with_data chain at all.  Just add a\n\t\t * new one that's big enough. */\n\t\tgoto insert_new;\n\t}\n\n\t/* If we can fit all the data, then we don't have to do anything */\n\tif (CHAIN_SPACE_LEN(chain) >= datlen) {\n\t\tresult = chain;\n\t\tgoto ok;\n\t}\n\n\t/* If the chain is completely empty, just replace it by adding a new\n\t * empty chain. */\n\tif (chain->off == 0) {\n\t\tgoto insert_new;\n\t}\n\n\t/* If the misalignment plus the remaining space fulfills our data\n\t * needs, we could just force an alignment to happen.  Afterwards, we\n\t * have enough space.  But only do this if we're saving a lot of space\n\t * and not moving too much data.  Otherwise the space savings are\n\t * probably offset by the time lost in copying.\n\t */\n\tif (evbuffer_chain_should_realign(chain, datlen)) {\n\t\tevbuffer_chain_align(chain);\n\t\tresult = chain;\n\t\tgoto ok;\n\t}\n\n\t/* At this point, we can either resize the last chunk with space in\n\t * it, use the next chunk after it, or   If we add a new chunk, we waste\n\t * CHAIN_SPACE_LEN(chain) bytes in the former last chunk.  If we\n\t * resize, we have to copy chain->off bytes.\n\t */\n\n\t/* Would expanding this chunk be affordable and worthwhile? */\n\tif (CHAIN_SPACE_LEN(chain) < chain->buffer_len / 8 ||\n\t    chain->off > MAX_TO_COPY_IN_EXPAND ||\n\t\tdatlen >= (EVBUFFER_CHAIN_MAX - chain->off)) {\n\t\t/* It's not worth resizing this chain. Can the next one be\n\t\t * used? */\n\t\tif (chain->next && CHAIN_SPACE_LEN(chain->next) >= datlen) {\n\t\t\t/* Yes, we can just use the next chain (which should\n\t\t\t * be empty. */\n\t\t\tresult = chain->next;\n\t\t\tgoto ok;\n\t\t} else {\n\t\t\t/* No; append a new chain (which will free all\n\t\t\t * terminal empty chains.) */\n\t\t\tgoto insert_new;\n\t\t}\n\t} else {\n\t\t/* Okay, we're going to try to resize this chain: Not doing so\n\t\t * would waste at least 1/8 of its current allocation, and we\n\t\t * can do so without having to copy more than\n\t\t * MAX_TO_COPY_IN_EXPAND bytes. */\n\t\t/* figure out how much space we need */\n\t\tsize_t length = chain->off + datlen;\n\t\tstruct evbuffer_chain *tmp = evbuffer_chain_new_membuf(length);\n\t\tif (tmp == NULL)\n\t\t\tgoto err;\n\n\t\t/* copy the data over that we had so far */\n\t\ttmp->off = chain->off;\n\t\tmemcpy(tmp->buffer, chain->buffer + chain->misalign,\n\t\t    chain->off);\n\t\t/* fix up the list */\n\t\tEVUTIL_ASSERT(*chainp == chain);\n\t\tresult = *chainp = tmp;\n\n\t\tif (buf->last == chain)\n\t\t\tbuf->last = tmp;\n\n\t\ttmp->next = chain->next;\n\t\tevbuffer_chain_free(chain);\n\t\tgoto ok;\n\t}\n\ninsert_new:\n\tresult = evbuffer_chain_insert_new(buf, datlen);\n\tif (!result)\n\t\tgoto err;\nok:\n\tEVUTIL_ASSERT(result);\n\tEVUTIL_ASSERT(CHAIN_SPACE_LEN(result) >= datlen);\nerr:\n\treturn result;\n}\n\n/* Make sure that datlen bytes are available for writing in the last n\n * chains.  Never copies or moves data. */\nint\nevbuffer_expand_fast_(struct evbuffer *buf, size_t datlen, int n)\n{\n\tstruct evbuffer_chain *chain = buf->last, *tmp, *next;\n\tsize_t avail;\n\tint used;\n\n\tASSERT_EVBUFFER_LOCKED(buf);\n\tEVUTIL_ASSERT(n >= 2);\n\n\tif (chain == NULL || (chain->flags & EVBUFFER_IMMUTABLE)) {\n\t\t/* There is no last chunk, or we can't touch the last chunk.\n\t\t * Just add a new chunk. */\n\t\tchain = evbuffer_chain_insert_new(buf, datlen);\n\t\tif (chain == NULL)\n\t\t\treturn (-1);\n\t\telse\n\t\t\treturn (0);\n\t}\n\n\tused = 0; /* number of chains we're using space in. */\n\tavail = 0; /* how much space they have. */\n\t/* How many bytes can we stick at the end of buffer as it is?  Iterate\n\t * over the chains at the end of the buffer, tring to see how much\n\t * space we have in the first n. */\n\tfor (chain = *buf->last_with_datap; chain; chain = chain->next) {\n\t\tif (chain->off) {\n\t\t\tsize_t space = (size_t) CHAIN_SPACE_LEN(chain);\n\t\t\tEVUTIL_ASSERT(chain == *buf->last_with_datap);\n\t\t\tif (space) {\n\t\t\t\tavail += space;\n\t\t\t\t++used;\n\t\t\t}\n\t\t} else {\n\t\t\t/* No data in chain; realign it. */\n\t\t\tchain->misalign = 0;\n\t\t\tavail += chain->buffer_len;\n\t\t\t++used;\n\t\t}\n\t\tif (avail >= datlen) {\n\t\t\t/* There is already enough space.  Just return */\n\t\t\treturn (0);\n\t\t}\n\t\tif (used == n)\n\t\t\tbreak;\n\t}\n\n\t/* There wasn't enough space in the first n chains with space in\n\t * them. Either add a new chain with enough space, or replace all\n\t * empty chains with one that has enough space, depending on n. */\n\tif (used < n) {\n\t\t/* The loop ran off the end of the chains before it hit n\n\t\t * chains; we can add another. */\n\t\tEVUTIL_ASSERT(chain == NULL);\n\n\t\ttmp = evbuffer_chain_new_membuf(datlen - avail);\n\t\tif (tmp == NULL)\n\t\t\treturn (-1);\n\n\t\tbuf->last->next = tmp;\n\t\tbuf->last = tmp;\n\t\t/* (we would only set last_with_data if we added the first\n\t\t * chain. But if the buffer had no chains, we would have\n\t\t * just allocated a new chain earlier) */\n\t\treturn (0);\n\t} else {\n\t\t/* Nuke _all_ the empty chains. */\n\t\tint rmv_all = 0; /* True iff we removed last_with_data. */\n\t\tchain = *buf->last_with_datap;\n\t\tif (!chain->off) {\n\t\t\tEVUTIL_ASSERT(chain == buf->first);\n\t\t\trmv_all = 1;\n\t\t\tavail = 0;\n\t\t} else {\n\t\t\t/* can't overflow, since only mutable chains have\n\t\t\t * huge misaligns. */\n\t\t\tavail = (size_t) CHAIN_SPACE_LEN(chain);\n\t\t\tchain = chain->next;\n\t\t}\n\n\n\t\tfor (; chain; chain = next) {\n\t\t\tnext = chain->next;\n\t\t\tEVUTIL_ASSERT(chain->off == 0);\n\t\t\tevbuffer_chain_free(chain);\n\t\t}\n\t\tEVUTIL_ASSERT(datlen >= avail);\n\t\ttmp = evbuffer_chain_new_membuf(datlen - avail);\n\t\tif (tmp == NULL) {\n\t\t\tif (rmv_all) {\n\t\t\t\tZERO_CHAIN(buf);\n\t\t\t} else {\n\t\t\t\tbuf->last = *buf->last_with_datap;\n\t\t\t\t(*buf->last_with_datap)->next = NULL;\n\t\t\t}\n\t\t\treturn (-1);\n\t\t}\n\n\t\tif (rmv_all) {\n\t\t\tbuf->first = buf->last = tmp;\n\t\t\tbuf->last_with_datap = &buf->first;\n\t\t} else {\n\t\t\t(*buf->last_with_datap)->next = tmp;\n\t\t\tbuf->last = tmp;\n\t\t}\n\t\treturn (0);\n\t}\n}\n\nint\nevbuffer_expand(struct evbuffer *buf, size_t datlen)\n{\n\tstruct evbuffer_chain *chain;\n\n\tEVBUFFER_LOCK(buf);\n\tchain = evbuffer_expand_singlechain(buf, datlen);\n\tEVBUFFER_UNLOCK(buf);\n\treturn chain ? 0 : -1;\n}\n\n/*\n * Reads data from a file descriptor into a buffer.\n */\n\n#if defined(EVENT__HAVE_SYS_UIO_H) || defined(_WIN32)\n#define USE_IOVEC_IMPL\n#endif\n\n#ifdef USE_IOVEC_IMPL\n\n#ifdef EVENT__HAVE_SYS_UIO_H\n/* number of iovec we use for writev, fragmentation is going to determine\n * how much we end up writing */\n\n#define DEFAULT_WRITE_IOVEC 128\n\n#if defined(UIO_MAXIOV) && UIO_MAXIOV < DEFAULT_WRITE_IOVEC\n#define NUM_WRITE_IOVEC UIO_MAXIOV\n#elif defined(IOV_MAX) && IOV_MAX < DEFAULT_WRITE_IOVEC\n#define NUM_WRITE_IOVEC IOV_MAX\n#else\n#define NUM_WRITE_IOVEC DEFAULT_WRITE_IOVEC\n#endif\n\n#define IOV_TYPE struct iovec\n#define IOV_PTR_FIELD iov_base\n#define IOV_LEN_FIELD iov_len\n#define IOV_LEN_TYPE size_t\n#else\n#define NUM_WRITE_IOVEC 16\n#define IOV_TYPE WSABUF\n#define IOV_PTR_FIELD buf\n#define IOV_LEN_FIELD len\n#define IOV_LEN_TYPE unsigned long\n#endif\n#endif\n#define NUM_READ_IOVEC 4\n\n/** Helper function to figure out which space to use for reading data into\n    an evbuffer.  Internal use only.\n\n    @param buf The buffer to read into\n    @param howmuch How much we want to read.\n    @param vecs An array of two or more iovecs or WSABUFs.\n    @param n_vecs_avail The length of vecs\n    @param chainp A pointer to a variable to hold the first chain we're\n      reading into.\n    @param exact Boolean: if true, we do not provide more than 'howmuch'\n      space in the vectors, even if more space is available.\n    @return The number of buffers we're using.\n */\nint\nevbuffer_read_setup_vecs_(struct evbuffer *buf, ev_ssize_t howmuch,\n    struct evbuffer_iovec *vecs, int n_vecs_avail,\n    struct evbuffer_chain ***chainp, int exact)\n{\n\tstruct evbuffer_chain *chain;\n\tstruct evbuffer_chain **firstchainp;\n\tsize_t so_far;\n\tint i;\n\tASSERT_EVBUFFER_LOCKED(buf);\n\n\tif (howmuch < 0)\n\t\treturn -1;\n\n\tso_far = 0;\n\t/* Let firstchain be the first chain with any space on it */\n\tfirstchainp = buf->last_with_datap;\n\tEVUTIL_ASSERT(*firstchainp);\n\tif (CHAIN_SPACE_LEN(*firstchainp) == 0) {\n\t\tfirstchainp = &(*firstchainp)->next;\n\t}\n\n\tchain = *firstchainp;\n\tEVUTIL_ASSERT(chain);\n\tfor (i = 0; i < n_vecs_avail && so_far < (size_t)howmuch; ++i) {\n\t\tsize_t avail = (size_t) CHAIN_SPACE_LEN(chain);\n\t\tif (avail > (howmuch - so_far) && exact)\n\t\t\tavail = howmuch - so_far;\n\t\tvecs[i].iov_base = (void *)CHAIN_SPACE_PTR(chain);\n\t\tvecs[i].iov_len = avail;\n\t\tso_far += avail;\n\t\tchain = chain->next;\n\t}\n\n\t*chainp = firstchainp;\n\treturn i;\n}\n\nstatic int\nget_n_bytes_readable_on_socket(evutil_socket_t fd)\n{\n#if defined(FIONREAD) && defined(_WIN32)\n\tunsigned long lng = EVBUFFER_MAX_READ_DEFAULT;\n\tif (ioctlsocket(fd, FIONREAD, &lng) < 0)\n\t\treturn -1;\n\t/* Can overflow, but mostly harmlessly. XXXX */\n\treturn (int)lng;\n#elif defined(FIONREAD)\n\tint n = EVBUFFER_MAX_READ_DEFAULT;\n\tif (ioctl(fd, FIONREAD, &n) < 0)\n\t\treturn -1;\n\treturn n;\n#else\n\treturn EVBUFFER_MAX_READ_DEFAULT;\n#endif\n}\n\n/* TODO(niels): should this function return ev_ssize_t and take ev_ssize_t\n * as howmuch? */\nint\nevbuffer_read(struct evbuffer *buf, evutil_socket_t fd, int howmuch)\n{\n\tint n;\n\tint result;\n\n#ifdef USE_IOVEC_IMPL\n\tstruct evbuffer_chain **chainp;\n\tint nvecs, i, remaining;\n#else\n\tstruct evbuffer_chain *chain;\n\tunsigned char *p;\n#endif\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (buf->freeze_end) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\tn = get_n_bytes_readable_on_socket(fd);\n\tif (n <= 0 || n > (int)buf->max_read)\n\t\tn = (int)buf->max_read;\n\tif (howmuch < 0 || howmuch > n)\n\t\thowmuch = n;\n\n#ifdef USE_IOVEC_IMPL\n\t/* Since we can use iovecs, we're willing to use the last\n\t * NUM_READ_IOVEC chains. */\n\tif (evbuffer_expand_fast_(buf, howmuch, NUM_READ_IOVEC) == -1) {\n\t\tresult = -1;\n\t\tgoto done;\n\t} else {\n\t\tIOV_TYPE vecs[NUM_READ_IOVEC];\n#ifdef EVBUFFER_IOVEC_IS_NATIVE_\n\t\tnvecs = evbuffer_read_setup_vecs_(buf, howmuch, vecs,\n\t\t    NUM_READ_IOVEC, &chainp, 1);\n#else\n\t\t/* We aren't using the native struct iovec.  Therefore,\n\t\t   we are on win32. */\n\t\tstruct evbuffer_iovec ev_vecs[NUM_READ_IOVEC];\n\t\tnvecs = evbuffer_read_setup_vecs_(buf, howmuch, ev_vecs, 2,\n\t\t    &chainp, 1);\n\n\t\tfor (i=0; i < nvecs; ++i)\n\t\t\tWSABUF_FROM_EVBUFFER_IOV(&vecs[i], &ev_vecs[i]);\n#endif\n\n#ifdef _WIN32\n\t\t{\n\t\t\tDWORD bytesRead;\n\t\t\tDWORD flags=0;\n\t\t\tif (WSARecv(fd, vecs, nvecs, &bytesRead, &flags, NULL, NULL)) {\n\t\t\t\t/* The read failed. It might be a close,\n\t\t\t\t * or it might be an error. */\n\t\t\t\tif (WSAGetLastError() == WSAECONNABORTED)\n\t\t\t\t\tn = 0;\n\t\t\t\telse\n\t\t\t\t\tn = -1;\n\t\t\t} else\n\t\t\t\tn = bytesRead;\n\t\t}\n#else\n\t\t/* TODO(panjf2000): wrap it with `unlikely` as compiler hint? */\n\t\tif (nvecs == 1)\n\t\t\tn = read(fd, vecs[0].IOV_PTR_FIELD, vecs[0].IOV_LEN_FIELD);\n\t\telse\n\t\t\tn = readv(fd, vecs, nvecs);\n#endif\n\t}\n\n#else /* !USE_IOVEC_IMPL */\n\t/* If we don't have FIONREAD, we might waste some space here */\n\t/* XXX we _will_ waste some space here if there is any space left\n\t * over on buf->last. */\n\tif ((chain = evbuffer_expand_singlechain(buf, howmuch)) == NULL) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\n\t/* We can append new data at this point */\n\tp = chain->buffer + chain->misalign + chain->off;\n\n#ifndef _WIN32\n\tn = read(fd, p, howmuch);\n#else\n\tn = recv(fd, p, howmuch, 0);\n#endif\n#endif /* USE_IOVEC_IMPL */\n\n\tif (n == -1) {\n\t\tresult = -1;\n\t\tgoto done;\n\t}\n\tif (n == 0) {\n\t\tresult = 0;\n\t\tgoto done;\n\t}\n\n#ifdef USE_IOVEC_IMPL\n\tremaining = n;\n\tfor (i=0; i < nvecs; ++i) {\n\t\t/* can't overflow, since only mutable chains have\n\t\t * huge misaligns. */\n\t\tsize_t space = (size_t) CHAIN_SPACE_LEN(*chainp);\n\t\t/* XXXX This is a kludge that can waste space in perverse\n\t\t * situations. */\n\t\tif (space > EVBUFFER_CHAIN_MAX)\n\t\t\tspace = EVBUFFER_CHAIN_MAX;\n\t\tif ((ev_ssize_t)space < remaining) {\n\t\t\t(*chainp)->off += space;\n\t\t\tremaining -= (int)space;\n\t\t} else {\n\t\t\t(*chainp)->off += remaining;\n\t\t\tbuf->last_with_datap = chainp;\n\t\t\tbreak;\n\t\t}\n\t\tchainp = &(*chainp)->next;\n\t}\n#else\n\tchain->off += n;\n\tadvance_last_with_data(buf);\n#endif\n\tbuf->total_len += n;\n\tbuf->n_add_for_cb += n;\n\n\t/* Tell someone about changes in this buffer */\n\tevbuffer_invoke_callbacks_(buf);\n\tresult = n;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\n#ifdef USE_IOVEC_IMPL\nstatic inline int\nevbuffer_write_iovec(struct evbuffer *buffer, evutil_socket_t fd,\n    ev_ssize_t howmuch)\n{\n\tIOV_TYPE iov[NUM_WRITE_IOVEC];\n\tstruct evbuffer_chain *chain = buffer->first;\n\tint n, i = 0;\n\n\tif (howmuch < 0)\n\t\treturn -1;\n\n\tASSERT_EVBUFFER_LOCKED(buffer);\n\t/* XXX make this top out at some maximal data length?  if the\n\t * buffer has (say) 1MB in it, split over 128 chains, there's\n\t * no way it all gets written in one go. */\n\twhile (chain != NULL && i < NUM_WRITE_IOVEC && howmuch) {\n#ifdef USE_SENDFILE\n\t\t/* we cannot write the file info via writev */\n\t\tif (chain->flags & EVBUFFER_SENDFILE)\n\t\t\tbreak;\n#endif\n\t\tiov[i].IOV_PTR_FIELD = (void *) (chain->buffer + chain->misalign);\n\t\tif ((size_t)howmuch >= chain->off) {\n\t\t\t/* XXXcould be problematic when windows supports mmap*/\n\t\t\tiov[i++].IOV_LEN_FIELD = (IOV_LEN_TYPE)chain->off;\n\t\t\thowmuch -= chain->off;\n\t\t} else {\n\t\t\t/* XXXcould be problematic when windows supports mmap*/\n\t\t\tiov[i++].IOV_LEN_FIELD = (IOV_LEN_TYPE)howmuch;\n\t\t\tbreak;\n\t\t}\n\t\tchain = chain->next;\n\t}\n\tif (! i)\n\t\treturn 0;\n\n#ifdef _WIN32\n\t{\n\t\tDWORD bytesSent;\n\t\tif (WSASend(fd, iov, i, &bytesSent, 0, NULL, NULL))\n\t\t\tn = -1;\n\t\telse\n\t\t\tn = bytesSent;\n\t}\n#else\n\t/* TODO(panjf2000): wrap it with `unlikely` as compiler hint? */\n\tif (i == 1)\n\t\tn = write(fd, iov[0].IOV_PTR_FIELD, iov[0].IOV_LEN_FIELD);\n\telse\n\t\tn = writev(fd, iov, i);\n#endif\n\treturn (n);\n}\n#endif\n\n#ifdef USE_SENDFILE\nstatic inline int\nevbuffer_write_sendfile(struct evbuffer *buffer, evutil_socket_t dest_fd,\n    ev_ssize_t howmuch)\n{\n\tstruct evbuffer_chain *chain = buffer->first;\n\tstruct evbuffer_chain_file_segment *info =\n\t    EVBUFFER_CHAIN_EXTRA(struct evbuffer_chain_file_segment,\n\t\tchain);\n\tconst int source_fd = info->segment->fd;\n#if defined(SENDFILE_IS_MACOSX) || defined(SENDFILE_IS_FREEBSD)\n\tint res;\n\tev_off_t len = chain->off;\n#elif defined(SENDFILE_IS_LINUX) || defined(SENDFILE_IS_SOLARIS)\n\tev_ssize_t res;\n\toff_t offset = chain->misalign;\n#endif\n\n\tASSERT_EVBUFFER_LOCKED(buffer);\n\n#if defined(SENDFILE_IS_MACOSX)\n\tres = sendfile(source_fd, dest_fd, chain->misalign, &len, NULL, 0);\n\tif (res == -1 && !EVUTIL_ERR_RW_RETRIABLE(errno))\n\t\treturn (-1);\n\n\treturn (len);\n#elif defined(SENDFILE_IS_FREEBSD)\n\tres = sendfile(source_fd, dest_fd, chain->misalign, chain->off, NULL, &len, 0);\n\tif (res == -1 && !EVUTIL_ERR_RW_RETRIABLE(errno))\n\t\treturn (-1);\n\n\treturn (len);\n#elif defined(SENDFILE_IS_LINUX)\n\tres = sendfile(dest_fd, source_fd, &offset, chain->off);\n\tif (res == -1 && EVUTIL_ERR_RW_RETRIABLE(errno)) {\n\t\t/* if this is EAGAIN or EINTR return 0; otherwise, -1 */\n\t\treturn (0);\n\t}\n\treturn (res);\n#elif defined(SENDFILE_IS_SOLARIS)\n\t{\n\t\tconst off_t offset_orig = offset;\n\t\tres = sendfile(dest_fd, source_fd, &offset, chain->off);\n\t\tif (res == -1 && EVUTIL_ERR_RW_RETRIABLE(errno)) {\n\t\t\tif (offset - offset_orig)\n\t\t\t\treturn offset - offset_orig;\n\t\t\t/* if this is EAGAIN or EINTR and no bytes were\n\t\t\t * written, return 0 */\n\t\t\treturn (0);\n\t\t}\n\t\treturn (res);\n\t}\n#endif\n}\n#endif\n\nint\nevbuffer_write_atmost(struct evbuffer *buffer, evutil_socket_t fd,\n    ev_ssize_t howmuch)\n{\n\tint n = -1;\n\n\tEVBUFFER_LOCK(buffer);\n\n\tif (buffer->freeze_start) {\n\t\tgoto done;\n\t}\n\n\tif (howmuch < 0 || (size_t)howmuch > buffer->total_len)\n\t\thowmuch = buffer->total_len;\n\n\tif (howmuch > 0) {\n#ifdef USE_SENDFILE\n\t\tstruct evbuffer_chain *chain = buffer->first;\n\t\tif (chain != NULL && (chain->flags & EVBUFFER_SENDFILE))\n\t\t\tn = evbuffer_write_sendfile(buffer, fd, howmuch);\n\t\telse {\n#endif\n#ifdef USE_IOVEC_IMPL\n\t\tn = evbuffer_write_iovec(buffer, fd, howmuch);\n#elif defined(_WIN32)\n\t\t/* XXX(nickm) Don't disable this code until we know if\n\t\t * the WSARecv code above works. */\n\t\tvoid *p = evbuffer_pullup(buffer, howmuch);\n\t\tEVUTIL_ASSERT(p || !howmuch);\n\t\tn = send(fd, p, howmuch, 0);\n#else\n\t\tvoid *p = evbuffer_pullup(buffer, howmuch);\n\t\tEVUTIL_ASSERT(p || !howmuch);\n\t\tn = write(fd, p, howmuch);\n#endif\n#ifdef USE_SENDFILE\n\t\t}\n#endif\n\t}\n\n\tif (n > 0)\n\t\tevbuffer_drain(buffer, n);\n\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\treturn (n);\n}\n\nint\nevbuffer_write(struct evbuffer *buffer, evutil_socket_t fd)\n{\n\treturn evbuffer_write_atmost(buffer, fd, -1);\n}\n\nunsigned char *\nevbuffer_find(struct evbuffer *buffer, const unsigned char *what, size_t len)\n{\n\tunsigned char *search;\n\tstruct evbuffer_ptr ptr;\n\n\tEVBUFFER_LOCK(buffer);\n\n\tptr = evbuffer_search(buffer, (const char *)what, len, NULL);\n\tif (ptr.pos < 0) {\n\t\tsearch = NULL;\n\t} else {\n\t\tsearch = evbuffer_pullup(buffer, ptr.pos + len);\n\t\tif (search)\n\t\t\tsearch += ptr.pos;\n\t}\n\tEVBUFFER_UNLOCK(buffer);\n\treturn search;\n}\n\n/* Subract <b>howfar</b> from the position of <b>pos</b> within\n * <b>buf</b>. Returns 0 on success, -1 on failure.\n *\n * This isn't exposed yet, because of potential inefficiency issues.\n * Maybe it should be. */\nstatic int\nevbuffer_ptr_subtract(struct evbuffer *buf, struct evbuffer_ptr *pos,\n    size_t howfar)\n{\n\tif (pos->pos < 0)\n\t\treturn -1;\n\tif (howfar > (size_t)pos->pos)\n\t\treturn -1;\n\tif (pos->internal_.chain && howfar <= pos->internal_.pos_in_chain) {\n\t\tpos->internal_.pos_in_chain -= howfar;\n\t\tpos->pos -= howfar;\n\t\treturn 0;\n\t} else {\n\t\tconst size_t newpos = pos->pos - howfar;\n\t\t/* Here's the inefficient part: it walks over the\n\t\t * chains until we hit newpos. */\n\t\treturn evbuffer_ptr_set(buf, pos, newpos, EVBUFFER_PTR_SET);\n\t}\n}\n\nint\nevbuffer_ptr_set(struct evbuffer *buf, struct evbuffer_ptr *pos,\n    size_t position, enum evbuffer_ptr_how how)\n{\n\tsize_t left = position;\n\tstruct evbuffer_chain *chain = NULL;\n\tint result = 0;\n\n\tEVBUFFER_LOCK(buf);\n\n\tswitch (how) {\n\tcase EVBUFFER_PTR_SET:\n\t\tchain = buf->first;\n\t\tpos->pos = position;\n\t\tposition = 0;\n\t\tbreak;\n\tcase EVBUFFER_PTR_ADD:\n\t\t/* this avoids iterating over all previous chains if\n\t\t   we just want to advance the position */\n\t\tif (pos->pos < 0 || EV_SIZE_MAX - position < (size_t)pos->pos) {\n\t\t\tEVBUFFER_UNLOCK(buf);\n\t\t\treturn -1;\n\t\t}\n\t\tchain = pos->internal_.chain;\n\t\tpos->pos += position;\n\t\tposition = pos->internal_.pos_in_chain;\n\t\tbreak;\n\t}\n\n\tEVUTIL_ASSERT(EV_SIZE_MAX - left >= position);\n\twhile (chain && position + left >= chain->off) {\n\t\tleft -= chain->off - position;\n\t\tchain = chain->next;\n\t\tposition = 0;\n\t}\n\tif (chain) {\n\t\tpos->internal_.chain = chain;\n\t\tpos->internal_.pos_in_chain = position + left;\n\t} else if (left == 0) {\n\t\t/* The first byte in the (nonexistent) chain after the last chain */\n\t\tpos->internal_.chain = NULL;\n\t\tpos->internal_.pos_in_chain = 0;\n\t} else {\n\t\tPTR_NOT_FOUND(pos);\n\t\tresult = -1;\n\t}\n\n\tEVBUFFER_UNLOCK(buf);\n\n\treturn result;\n}\n\n/**\n   Compare the bytes in buf at position pos to the len bytes in mem.  Return\n   less than 0, 0, or greater than 0 as memcmp.\n */\nstatic int\nevbuffer_ptr_memcmp(const struct evbuffer *buf, const struct evbuffer_ptr *pos,\n    const char *mem, size_t len)\n{\n\tstruct evbuffer_chain *chain;\n\tsize_t position;\n\tint r;\n\n\tASSERT_EVBUFFER_LOCKED(buf);\n\n\tif (pos->pos < 0 ||\n\t    EV_SIZE_MAX - len < (size_t)pos->pos ||\n\t    pos->pos + len > buf->total_len)\n\t\treturn -1;\n\n\tchain = pos->internal_.chain;\n\tposition = pos->internal_.pos_in_chain;\n\twhile (len && chain) {\n\t\tsize_t n_comparable;\n\t\tif (len + position > chain->off)\n\t\t\tn_comparable = chain->off - position;\n\t\telse\n\t\t\tn_comparable = len;\n\t\tr = memcmp(chain->buffer + chain->misalign + position, mem,\n\t\t    n_comparable);\n\t\tif (r)\n\t\t\treturn r;\n\t\tmem += n_comparable;\n\t\tlen -= n_comparable;\n\t\tposition = 0;\n\t\tchain = chain->next;\n\t}\n\n\treturn 0;\n}\n\nstruct evbuffer_ptr\nevbuffer_search(struct evbuffer *buffer, const char *what, size_t len, const struct evbuffer_ptr *start)\n{\n\treturn evbuffer_search_range(buffer, what, len, start, NULL);\n}\n\nstruct evbuffer_ptr\nevbuffer_search_range(struct evbuffer *buffer, const char *what, size_t len, const struct evbuffer_ptr *start, const struct evbuffer_ptr *end)\n{\n\tstruct evbuffer_ptr pos;\n\tstruct evbuffer_chain *chain, *last_chain = NULL;\n\tconst unsigned char *p;\n\tchar first;\n\n\tEVBUFFER_LOCK(buffer);\n\n\tif (start) {\n\t\tmemcpy(&pos, start, sizeof(pos));\n\t\tchain = pos.internal_.chain;\n\t} else {\n\t\tpos.pos = 0;\n\t\tchain = pos.internal_.chain = buffer->first;\n\t\tpos.internal_.pos_in_chain = 0;\n\t}\n\n\tif (end)\n\t\tlast_chain = end->internal_.chain;\n\n\tif (!len || len > EV_SSIZE_MAX)\n\t\tgoto done;\n\n\tfirst = what[0];\n\n\twhile (chain) {\n\t\tconst unsigned char *start_at =\n\t\t    chain->buffer + chain->misalign +\n\t\t    pos.internal_.pos_in_chain;\n\t\tp = memchr(start_at, first,\n\t\t    chain->off - pos.internal_.pos_in_chain);\n\t\tif (p) {\n\t\t\tpos.pos += p - start_at;\n\t\t\tpos.internal_.pos_in_chain += p - start_at;\n\t\t\tif (!evbuffer_ptr_memcmp(buffer, &pos, what, len)) {\n\t\t\t\tif (end && pos.pos + (ev_ssize_t)len > end->pos)\n\t\t\t\t\tgoto not_found;\n\t\t\t\telse\n\t\t\t\t\tgoto done;\n\t\t\t}\n\t\t\t++pos.pos;\n\t\t\t++pos.internal_.pos_in_chain;\n\t\t\tif (pos.internal_.pos_in_chain == chain->off) {\n\t\t\t\tchain = pos.internal_.chain = chain->next;\n\t\t\t\tpos.internal_.pos_in_chain = 0;\n\t\t\t}\n\t\t} else {\n\t\t\tif (chain == last_chain)\n\t\t\t\tgoto not_found;\n\t\t\tpos.pos += chain->off - pos.internal_.pos_in_chain;\n\t\t\tchain = pos.internal_.chain = chain->next;\n\t\t\tpos.internal_.pos_in_chain = 0;\n\t\t}\n\t}\n\nnot_found:\n\tPTR_NOT_FOUND(&pos);\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\treturn pos;\n}\n\nint\nevbuffer_peek(struct evbuffer *buffer, ev_ssize_t len,\n    struct evbuffer_ptr *start_at,\n    struct evbuffer_iovec *vec, int n_vec)\n{\n\tstruct evbuffer_chain *chain;\n\tint idx = 0;\n\tev_ssize_t len_so_far = 0;\n\n\t/* Avoid locking in trivial edge cases */\n\tif (start_at && start_at->internal_.chain == NULL)\n\t\treturn 0;\n\n\tEVBUFFER_LOCK(buffer);\n\n\tif (start_at) {\n\t\tchain = start_at->internal_.chain;\n\t\tlen_so_far = chain->off\n\t\t    - start_at->internal_.pos_in_chain;\n\t\tidx = 1;\n\t\tif (n_vec > 0) {\n\t\t\tvec[0].iov_base = (void *)(chain->buffer + chain->misalign\n\t\t\t    + start_at->internal_.pos_in_chain);\n\t\t\tvec[0].iov_len = len_so_far;\n\t\t}\n\t\tchain = chain->next;\n\t} else {\n\t\tchain = buffer->first;\n\t}\n\n\tif (n_vec == 0 && len < 0) {\n\t\t/* If no vectors are provided and they asked for \"everything\",\n\t\t * pretend they asked for the actual available amount. */\n\t\tlen = buffer->total_len;\n\t\tif (start_at) {\n\t\t\tlen -= start_at->pos;\n\t\t}\n\t}\n\n\twhile (chain) {\n\t\tif (len >= 0 && len_so_far >= len)\n\t\t\tbreak;\n\t\tif (idx<n_vec) {\n\t\t\tvec[idx].iov_base = (void *)(chain->buffer + chain->misalign);\n\t\t\tvec[idx].iov_len = chain->off;\n\t\t} else if (len<0) {\n\t\t\tbreak;\n\t\t}\n\t\t++idx;\n\t\tlen_so_far += chain->off;\n\t\tchain = chain->next;\n\t}\n\n\tEVBUFFER_UNLOCK(buffer);\n\n\treturn idx;\n}\n\n\nint\nevbuffer_add_vprintf(struct evbuffer *buf, const char *fmt, va_list ap)\n{\n\tchar *buffer;\n\tsize_t space;\n\tint sz, result = -1;\n\tva_list aq;\n\tstruct evbuffer_chain *chain;\n\n\n\tEVBUFFER_LOCK(buf);\n\n\tif (buf->freeze_end) {\n\t\tgoto done;\n\t}\n\n\t/* make sure that at least some space is available */\n\tif ((chain = evbuffer_expand_singlechain(buf, 64)) == NULL)\n\t\tgoto done;\n\n\tfor (;;) {\n#if 0\n\t\tsize_t used = chain->misalign + chain->off;\n\t\tbuffer = (char *)chain->buffer + chain->misalign + chain->off;\n\t\tEVUTIL_ASSERT(chain->buffer_len >= used);\n\t\tspace = chain->buffer_len - used;\n#endif\n\t\tbuffer = (char*) CHAIN_SPACE_PTR(chain);\n\t\tspace = (size_t) CHAIN_SPACE_LEN(chain);\n\n#ifndef va_copy\n#define\tva_copy(dst, src)\tmemcpy(&(dst), &(src), sizeof(va_list))\n#endif\n\t\tva_copy(aq, ap);\n\n\t\tsz = evutil_vsnprintf(buffer, space, fmt, aq);\n\n\t\tva_end(aq);\n\n\t\tif (sz < 0)\n\t\t\tgoto done;\n\t\tif (INT_MAX >= EVBUFFER_CHAIN_MAX &&\n\t\t    (size_t)sz >= EVBUFFER_CHAIN_MAX)\n\t\t\tgoto done;\n\t\tif ((size_t)sz < space) {\n\t\t\tchain->off += sz;\n\t\t\tbuf->total_len += sz;\n\t\t\tbuf->n_add_for_cb += sz;\n\n\t\t\tadvance_last_with_data(buf);\n\t\t\tevbuffer_invoke_callbacks_(buf);\n\t\t\tresult = sz;\n\t\t\tgoto done;\n\t\t}\n\t\tif ((chain = evbuffer_expand_singlechain(buf, sz + 1)) == NULL)\n\t\t\tgoto done;\n\t}\n\t/* NOTREACHED */\n\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn result;\n}\n\nint\nevbuffer_add_printf(struct evbuffer *buf, const char *fmt, ...)\n{\n\tint res = -1;\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tres = evbuffer_add_vprintf(buf, fmt, ap);\n\tva_end(ap);\n\n\treturn (res);\n}\n\nint\nevbuffer_add_reference(struct evbuffer *outbuf,\n    const void *data, size_t datlen,\n    evbuffer_ref_cleanup_cb cleanupfn, void *extra)\n{\n\treturn evbuffer_add_reference_with_offset(outbuf, data, /* offset= */ 0, datlen, cleanupfn, extra);\n}\n\nint\nevbuffer_add_reference_with_offset(struct evbuffer *outbuf, const void *data,\n\tsize_t offset, size_t datlen, evbuffer_ref_cleanup_cb cleanupfn,\n\tvoid *extra)\n{\n\tstruct evbuffer_chain *chain;\n\tstruct evbuffer_chain_reference *info;\n\tint result = -1;\n\n\tchain = evbuffer_chain_new(sizeof(struct evbuffer_chain_reference));\n\tif (!chain)\n\t\treturn (-1);\n\tchain->flags |= EVBUFFER_REFERENCE | EVBUFFER_IMMUTABLE;\n\tchain->buffer = (unsigned char *)data;\n\tchain->misalign = offset;\n\tchain->buffer_len = offset + datlen;\n\tchain->off = datlen;\n\n\tinfo = EVBUFFER_CHAIN_EXTRA(struct evbuffer_chain_reference, chain);\n\tinfo->cleanupfn = cleanupfn;\n\tinfo->extra = extra;\n\n\tEVBUFFER_LOCK(outbuf);\n\tif (outbuf->freeze_end) {\n\t\t/* don't call chain_free; we do not want to actually invoke\n\t\t * the cleanup function */\n\t\tmm_free(chain);\n\t\tgoto done;\n\t}\n\tevbuffer_chain_insert(outbuf, chain);\n\toutbuf->n_add_for_cb += datlen;\n\n\tevbuffer_invoke_callbacks_(outbuf);\n\n\tresult = 0;\ndone:\n\tEVBUFFER_UNLOCK(outbuf);\n\n\treturn result;\n}\n\n/* TODO(niels): we may want to add to automagically convert to mmap, in\n * case evbuffer_remove() or evbuffer_pullup() are being used.\n */\nstruct evbuffer_file_segment *\nevbuffer_file_segment_new(\n\tint fd, ev_off_t offset, ev_off_t length, unsigned flags)\n{\n\tstruct evbuffer_file_segment *seg =\n\t    mm_calloc(1, sizeof(struct evbuffer_file_segment));\n\tif (!seg)\n\t\treturn NULL;\n\tseg->refcnt = 1;\n\tseg->fd = fd;\n\tseg->flags = flags;\n\tseg->file_offset = offset;\n\tseg->cleanup_cb = NULL;\n\tseg->cleanup_cb_arg = NULL;\n\tif (length == -1) {\n\t\tlength = evutil_fd_filesize(fd);\n\t\tif (length == -1)\n\t\t\tgoto err;\n\t}\n\tseg->length = length;\n\n\tif (offset < 0 || length < 0 ||\n\t    ((ev_uint64_t)length > EVBUFFER_CHAIN_MAX) ||\n\t    (ev_uint64_t)offset > (ev_uint64_t)(EVBUFFER_CHAIN_MAX - length))\n\t\tgoto err;\n\n#if defined(USE_SENDFILE)\n\tif (!(flags & EVBUF_FS_DISABLE_SENDFILE)) {\n\t\tseg->can_sendfile = 1;\n\t\tgoto done;\n\t}\n#endif\n\n\tif (evbuffer_file_segment_materialize(seg)<0)\n\t\tgoto err;\n\n#if defined(USE_SENDFILE)\ndone:\n#endif\n\tif (!(flags & EVBUF_FS_DISABLE_LOCKING)) {\n\t\tEVTHREAD_ALLOC_LOCK(seg->lock, 0);\n\t}\n\treturn seg;\nerr:\n\tmm_free(seg);\n\treturn NULL;\n}\n\n#ifdef EVENT__HAVE_MMAP\nstatic long\nget_page_size(void)\n{\n#ifdef SC_PAGE_SIZE\n\treturn sysconf(SC_PAGE_SIZE);\n#elif defined(_SC_PAGE_SIZE)\n\treturn sysconf(_SC_PAGE_SIZE);\n#else\n\treturn 1;\n#endif\n}\n#endif\n\n/* DOCDOC */\n/* Requires lock */\nstatic int\nevbuffer_file_segment_materialize(struct evbuffer_file_segment *seg)\n{\n#if defined(EVENT__HAVE_MMAP) || defined(_WIN32)\n\tconst unsigned flags = seg->flags;\n#endif\n\tconst int fd = seg->fd;\n\tconst ev_off_t length = seg->length;\n\tconst ev_off_t offset = seg->file_offset;\n\n\tif (seg->contents || seg->is_mapping)\n\t\treturn 0; /* already materialized */\n\n#if defined(EVENT__HAVE_MMAP)\n\tif (!(flags & EVBUF_FS_DISABLE_MMAP)) {\n\t\toff_t offset_rounded = 0, offset_leftover = 0;\n\t\tint mmap_flags =\n#ifdef MAP_NOCACHE\n\t\t\tMAP_NOCACHE | /* ??? */\n#endif\n#ifdef MAP_FILE\n\t\t\tMAP_FILE |\n#endif\n\t\t\tMAP_PRIVATE;\n\t\tvoid *mapped;\n\t\tif (offset) {\n\t\t\t/* mmap implementations don't generally like us\n\t\t\t * to have an offset that isn't a round  */\n\t\t\tlong page_size = get_page_size();\n\t\t\tif (page_size == -1)\n\t\t\t\tgoto err;\n\t\t\toffset_leftover = offset % page_size;\n\t\t\toffset_rounded = offset - offset_leftover;\n\t\t}\n#if defined(EVENT__HAVE_MMAP64)\n\t\tmapped = mmap64(NULL, length + offset_leftover,\n#else\n\t\tmapped = mmap(NULL, length + offset_leftover,\n#endif\n\t\t\tPROT_READ, mmap_flags, fd, offset_rounded);\n\t\tif (mapped == MAP_FAILED) {\n\t\t\tevent_warn(\"%s: mmap(NULL, %zu, %d, %d, %d, %lld) failed\", __func__,\n\t\t\t\t(size_t)(length + offset_leftover), PROT_READ, mmap_flags, fd,\n\t\t\t\t(long long)offset_rounded);\n\t\t} else {\n\t\t\tseg->mapping = mapped;\n\t\t\tseg->contents = (char*)mapped+offset_leftover;\n\t\t\tseg->mmap_offset = 0;\n\t\t\tseg->is_mapping = 1;\n\t\t\tgoto done;\n\t\t}\n\t}\n#endif\n#ifdef _WIN32\n\tif (!(flags & EVBUF_FS_DISABLE_MMAP)) {\n\t\tintptr_t h = _get_osfhandle(fd);\n\t\tHANDLE m;\n\t\tev_uint64_t total_size = length+offset;\n\t\tif ((HANDLE)h == INVALID_HANDLE_VALUE)\n\t\t\tgoto err;\n\t\tm = CreateFileMapping((HANDLE)h, NULL, PAGE_READONLY,\n\t\t    (total_size >> 32), total_size & 0xfffffffful,\n\t\t    NULL);\n\t\tif (m != INVALID_HANDLE_VALUE) { /* Does h leak? */\n\t\t\tseg->mapping_handle = m;\n\t\t\tseg->mmap_offset = offset;\n\t\t\tseg->is_mapping = 1;\n\t\t\tgoto done;\n\t\t}\n\t}\n#endif\n\t{\n\t\tev_off_t read_so_far = 0;\n\t\tev_ssize_t n = 0;\n\t\tchar *mem;\n#ifndef EVENT__HAVE_PREAD\n#ifdef _WIN32\n#ifndef lseek\n#define lseek _lseeki64\n#endif\n#endif\n\t\tev_off_t start_pos = lseek(fd, 0, SEEK_CUR);\n\t\tev_off_t pos;\n\t\tint e;\n#endif /* no pread() */\n\t\tif (!(mem = mm_malloc(length)))\n\t\t\tgoto err;\n#ifdef EVENT__HAVE_PREAD\n\t\twhile (read_so_far < length) {\n\t\t\tn = pread(fd, mem + read_so_far, length - read_so_far,\n\t\t\t\t  offset + read_so_far);\n\t\t\tif (n <= 0)\n\t\t\t\tbreak;\n\t\t\tread_so_far += n;\n\t\t}\n\t\tif (n < 0 || (n == 0 && length > read_so_far)) {\n\t\t\tmm_free(mem);\n\t\t\tgoto err;\n\t\t}\n#else /* fallback to seek() and read() */\n\t\tif (start_pos < 0) {\n\t\t\tmm_free(mem);\n\t\t\tgoto err;\n\t\t}\n\t\tif (lseek(fd, offset, SEEK_SET) < 0) {\n\t\t\tmm_free(mem);\n\t\t\tgoto err;\n\t\t}\n\t\twhile (read_so_far < length) {\n\t\t\tn = read(fd, mem+read_so_far, length-read_so_far);\n\t\t\tif (n <= 0)\n\t\t\t\tbreak;\n\t\t\tread_so_far += n;\n\t\t}\n\n\t\te = errno;\n\t\tpos = lseek(fd, start_pos, SEEK_SET);\n\t\tif (n < 0 || (n == 0 && length > read_so_far)) {\n\t\t\tmm_free(mem);\n\t\t\terrno = e;\n\t\t\tgoto err;\n\t\t} else if (pos < 0) {\n\t\t\tmm_free(mem);\n\t\t\tgoto err;\n\t\t}\n#endif /* pread */\n\n\t\tseg->contents = mem;\n\t}\n#if defined(EVENT__HAVE_MMAP) || defined(_WIN32)\ndone:\n#endif\n\treturn 0;\nerr:\n\treturn -1;\n}\n\nvoid evbuffer_file_segment_add_cleanup_cb(struct evbuffer_file_segment *seg,\n\tevbuffer_file_segment_cleanup_cb cb, void* arg)\n{\n\tEVUTIL_ASSERT(seg->refcnt > 0);\n\tseg->cleanup_cb = cb;\n\tseg->cleanup_cb_arg = arg;\n}\n\nvoid\nevbuffer_file_segment_free(struct evbuffer_file_segment *seg)\n{\n\tint refcnt;\n\tEVLOCK_LOCK(seg->lock, 0);\n\trefcnt = --seg->refcnt;\n\tEVLOCK_UNLOCK(seg->lock, 0);\n\tif (refcnt > 0)\n\t\treturn;\n\tEVUTIL_ASSERT(refcnt == 0);\n\n\tif (seg->is_mapping) {\n#ifdef _WIN32\n\t\tCloseHandle(seg->mapping_handle);\n#elif defined (EVENT__HAVE_MMAP)\n\t\toff_t offset_leftover;\n\t\toffset_leftover = seg->file_offset % get_page_size();\n\t\tif (munmap(seg->mapping, seg->length + offset_leftover) == -1)\n\t\t\tevent_warn(\"%s: munmap failed\", __func__);\n#endif\n\t} else if (seg->contents) {\n\t\tmm_free(seg->contents);\n\t}\n\n\tif ((seg->flags & EVBUF_FS_CLOSE_ON_FREE) && seg->fd >= 0) {\n\t\tclose(seg->fd);\n\t}\n\n\tif (seg->cleanup_cb) {\n\t\t(*seg->cleanup_cb)((struct evbuffer_file_segment const*)seg,\n\t\t    seg->flags, seg->cleanup_cb_arg);\n\t\tseg->cleanup_cb = NULL;\n\t\tseg->cleanup_cb_arg = NULL;\n\t}\n\n\tEVTHREAD_FREE_LOCK(seg->lock, 0);\n\tmm_free(seg);\n}\n\nint\nevbuffer_add_file_segment(struct evbuffer *buf,\n    struct evbuffer_file_segment *seg, ev_off_t offset, ev_off_t length)\n{\n\tstruct evbuffer_chain *chain;\n\tstruct evbuffer_chain_file_segment *extra;\n\tint can_use_sendfile = 0;\n\n\tEVBUFFER_LOCK(buf);\n\tEVLOCK_LOCK(seg->lock, 0);\n\tif (buf->flags & EVBUFFER_FLAG_DRAINS_TO_FD) {\n\t\tcan_use_sendfile = 1;\n\t} else {\n\t\tif (evbuffer_file_segment_materialize(seg)<0) {\n\t\t\tEVLOCK_UNLOCK(seg->lock, 0);\n\t\t\tgoto err;\n\t\t}\n\t}\n\tEVLOCK_UNLOCK(seg->lock, 0);\n\n\tif (buf->freeze_end)\n\t\tgoto err;\n\n\tif (length < 0) {\n\t\tif (offset > seg->length)\n\t\t\tgoto err;\n\t\tlength = seg->length - offset;\n\t}\n\n\t/* Can we actually add this? */\n\tif (offset+length > seg->length)\n\t\tgoto err;\n\n\tchain = evbuffer_chain_new(sizeof(struct evbuffer_chain_file_segment));\n\tif (!chain)\n\t\tgoto err;\n\textra = EVBUFFER_CHAIN_EXTRA(struct evbuffer_chain_file_segment, chain);\n\n\tchain->flags |= EVBUFFER_IMMUTABLE|EVBUFFER_FILESEGMENT;\n\tif (can_use_sendfile && seg->can_sendfile) {\n\t\tchain->flags |= EVBUFFER_SENDFILE;\n\t\tchain->misalign = seg->file_offset + offset;\n\t\tchain->off = length;\n\t\tchain->buffer_len = chain->misalign + length;\n\t} else if (seg->is_mapping) {\n#ifdef _WIN32\n\t\tev_uint64_t total_offset = seg->mmap_offset+offset;\n\t\tev_uint64_t offset_rounded=0, offset_remaining=0;\n\t\tLPVOID data;\n\t\tif (total_offset) {\n\t\t\tSYSTEM_INFO si;\n\t\t\tmemset(&si, 0, sizeof(si)); /* cargo cult */\n\t\t\tGetSystemInfo(&si);\n\t\t\toffset_remaining = total_offset % si.dwAllocationGranularity;\n\t\t\toffset_rounded = total_offset - offset_remaining;\n\t\t}\n\t\tdata = MapViewOfFile(\n\t\t\tseg->mapping_handle,\n\t\t\tFILE_MAP_READ,\n\t\t\toffset_rounded >> 32,\n\t\t\toffset_rounded & 0xfffffffful,\n\t\t\tlength + offset_remaining);\n\t\tif (data == NULL) {\n\t\t\tmm_free(chain);\n\t\t\tgoto err;\n\t\t}\n\t\tchain->buffer = (unsigned char*) data;\n\t\tchain->buffer_len = length+offset_remaining;\n\t\tchain->misalign = offset_remaining;\n\t\tchain->off = length;\n#else\n\t\tchain->buffer = (unsigned char*)(seg->contents + offset);\n\t\tchain->buffer_len = length;\n\t\tchain->off = length;\n#endif\n\t} else {\n\t\tchain->buffer = (unsigned char*)(seg->contents + offset);\n\t\tchain->buffer_len = length;\n\t\tchain->off = length;\n\t}\n\n\tEVLOCK_LOCK(seg->lock, 0);\n\t++seg->refcnt;\n\tEVLOCK_UNLOCK(seg->lock, 0);\n\textra->segment = seg;\n\tbuf->n_add_for_cb += length;\n\tevbuffer_chain_insert(buf, chain);\n\n\tevbuffer_invoke_callbacks_(buf);\n\n\tEVBUFFER_UNLOCK(buf);\n\n\treturn 0;\nerr:\n\tEVBUFFER_UNLOCK(buf);\n\tevbuffer_file_segment_free(seg); /* Lowers the refcount */\n\treturn -1;\n}\n\nint\nevbuffer_add_file(struct evbuffer *buf, int fd, ev_off_t offset, ev_off_t length)\n{\n\tstruct evbuffer_file_segment *seg;\n\tunsigned flags = EVBUF_FS_CLOSE_ON_FREE;\n\tint r;\n\n\tseg = evbuffer_file_segment_new(fd, offset, length, flags);\n\tif (!seg)\n\t\treturn -1;\n\tr = evbuffer_add_file_segment(buf, seg, 0, length);\n\tif (r == 0)\n\t\tevbuffer_file_segment_free(seg);\n\treturn r;\n}\n\nint\nevbuffer_setcb(struct evbuffer *buffer, evbuffer_cb cb, void *cbarg)\n{\n\tEVBUFFER_LOCK(buffer);\n\n\tif (!LIST_EMPTY(&buffer->callbacks))\n\t\tevbuffer_remove_all_callbacks(buffer);\n\n\tif (cb) {\n\t\tstruct evbuffer_cb_entry *ent =\n\t\t    evbuffer_add_cb(buffer, NULL, cbarg);\n\t\tif (!ent) {\n\t\t\tEVBUFFER_UNLOCK(buffer);\n\t\t\treturn -1;\n\t\t}\n\t\tent->cb.cb_obsolete = cb;\n\t\tent->flags |= EVBUFFER_CB_OBSOLETE;\n\t}\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\nstruct evbuffer_cb_entry *\nevbuffer_add_cb(struct evbuffer *buffer, evbuffer_cb_func cb, void *cbarg)\n{\n\tstruct evbuffer_cb_entry *e;\n\tif (! (e = mm_calloc(1, sizeof(struct evbuffer_cb_entry))))\n\t\treturn NULL;\n\tEVBUFFER_LOCK(buffer);\n\te->cb.cb_func = cb;\n\te->cbarg = cbarg;\n\te->flags = EVBUFFER_CB_ENABLED;\n\tLIST_INSERT_HEAD(&buffer->callbacks, e, next);\n\tEVBUFFER_UNLOCK(buffer);\n\treturn e;\n}\n\nint\nevbuffer_remove_cb_entry(struct evbuffer *buffer,\n\t\t\t struct evbuffer_cb_entry *ent)\n{\n\tEVBUFFER_LOCK(buffer);\n\tLIST_REMOVE(ent, next);\n\tEVBUFFER_UNLOCK(buffer);\n\tmm_free(ent);\n\treturn 0;\n}\n\nint\nevbuffer_remove_cb(struct evbuffer *buffer, evbuffer_cb_func cb, void *cbarg)\n{\n\tstruct evbuffer_cb_entry *cbent;\n\tint result = -1;\n\tEVBUFFER_LOCK(buffer);\n\tLIST_FOREACH(cbent, &buffer->callbacks, next) {\n\t\tif (cb == cbent->cb.cb_func && cbarg == cbent->cbarg) {\n\t\t\tresult = evbuffer_remove_cb_entry(buffer, cbent);\n\t\t\tgoto done;\n\t\t}\n\t}\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\treturn result;\n}\n\nint\nevbuffer_cb_set_flags(struct evbuffer *buffer,\n\t\t      struct evbuffer_cb_entry *cb, ev_uint32_t flags)\n{\n\t/* the user isn't allowed to mess with these. */\n\tflags &= ~EVBUFFER_CB_INTERNAL_FLAGS;\n\tEVBUFFER_LOCK(buffer);\n\tcb->flags |= flags;\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\nint\nevbuffer_cb_clear_flags(struct evbuffer *buffer,\n\t\t      struct evbuffer_cb_entry *cb, ev_uint32_t flags)\n{\n\t/* the user isn't allowed to mess with these. */\n\tflags &= ~EVBUFFER_CB_INTERNAL_FLAGS;\n\tEVBUFFER_LOCK(buffer);\n\tcb->flags &= ~flags;\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\nint\nevbuffer_freeze(struct evbuffer *buffer, int start)\n{\n\tEVBUFFER_LOCK(buffer);\n\tif (start)\n\t\tbuffer->freeze_start = 1;\n\telse\n\t\tbuffer->freeze_end = 1;\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\nint\nevbuffer_unfreeze(struct evbuffer *buffer, int start)\n{\n\tEVBUFFER_LOCK(buffer);\n\tif (start)\n\t\tbuffer->freeze_start = 0;\n\telse\n\t\tbuffer->freeze_end = 0;\n\tEVBUFFER_UNLOCK(buffer);\n\treturn 0;\n}\n\n#if 0\nvoid\nevbuffer_cb_suspend(struct evbuffer *buffer, struct evbuffer_cb_entry *cb)\n{\n\tif (!(cb->flags & EVBUFFER_CB_SUSPENDED)) {\n\t\tcb->size_before_suspend = evbuffer_get_length(buffer);\n\t\tcb->flags |= EVBUFFER_CB_SUSPENDED;\n\t}\n}\n\nvoid\nevbuffer_cb_unsuspend(struct evbuffer *buffer, struct evbuffer_cb_entry *cb)\n{\n\tif ((cb->flags & EVBUFFER_CB_SUSPENDED)) {\n\t\tunsigned call = (cb->flags & EVBUFFER_CB_CALL_ON_UNSUSPEND);\n\t\tsize_t sz = cb->size_before_suspend;\n\t\tcb->flags &= ~(EVBUFFER_CB_SUSPENDED|\n\t\t\t       EVBUFFER_CB_CALL_ON_UNSUSPEND);\n\t\tcb->size_before_suspend = 0;\n\t\tif (call && (cb->flags & EVBUFFER_CB_ENABLED)) {\n\t\t\tcb->cb(buffer, sz, evbuffer_get_length(buffer), cb->cbarg);\n\t\t}\n\t}\n}\n#endif\n\nint\nevbuffer_get_callbacks_(struct evbuffer *buffer, struct event_callback **cbs,\n    int max_cbs)\n{\n\tint r = 0;\n\tEVBUFFER_LOCK(buffer);\n\tif (buffer->deferred_cbs) {\n\t\tif (max_cbs < 1) {\n\t\t\tr = -1;\n\t\t\tgoto done;\n\t\t}\n\t\tcbs[0] = &buffer->deferred;\n\t\tr = 1;\n\t}\ndone:\n\tEVBUFFER_UNLOCK(buffer);\n\treturn r;\n}\n"
        },
        {
          "name": "buffer_iocp.c",
          "type": "blob",
          "size": 8.458984375,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/**\n   @file buffer_iocp.c\n\n   This module implements overlapped read and write functions for evbuffer\n   objects on Windows.\n*/\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include \"event2/buffer.h\"\n#include \"event2/buffer_compat.h\"\n#include \"event2/util.h\"\n#include \"event2/thread.h\"\n#include \"util-internal.h\"\n#include \"evthread-internal.h\"\n#include \"evbuffer-internal.h\"\n#include \"iocp-internal.h\"\n#include \"mm-internal.h\"\n\n#include <winsock2.h>\n#include <winerror.h>\n#include <windows.h>\n#include <stdio.h>\n\n#define MAX_WSABUFS 16\n\n/** An evbuffer that can handle overlapped IO. */\nstruct evbuffer_overlapped {\n\tstruct evbuffer buffer;\n\t/** The socket that we're doing overlapped IO on. */\n\tevutil_socket_t fd;\n\n\t/** pending I/O type */\n\tunsigned read_in_progress : 1;\n\tunsigned write_in_progress : 1;\n\n\t/** The first pinned chain in the buffer. */\n\tstruct evbuffer_chain *first_pinned;\n\n\t/** How many chains are pinned; how many of the fields in buffers\n\t * are we using. */\n\tint n_buffers;\n\tWSABUF buffers[MAX_WSABUFS];\n};\n\n/** Given an evbuffer, return the corresponding evbuffer structure, or NULL if\n * the evbuffer isn't overlapped. */\nstatic inline struct evbuffer_overlapped *\nupcast_evbuffer(struct evbuffer *buf)\n{\n\tif (!buf || !buf->is_overlapped)\n\t\treturn NULL;\n\treturn EVUTIL_UPCAST(buf, struct evbuffer_overlapped, buffer);\n}\n\n/** Unpin all the chains noted as pinned in 'eo'. */\nstatic void\npin_release(struct evbuffer_overlapped *eo, unsigned flag)\n{\n\tint i;\n\tstruct evbuffer_chain *next, *chain = eo->first_pinned;\n\n\tfor (i = 0; i < eo->n_buffers; ++i) {\n\t\tEVUTIL_ASSERT(chain);\n\t\tnext = chain->next;\n\t\tevbuffer_chain_unpin_(chain, flag);\n\t\tchain = next;\n\t}\n}\n\nvoid\nevbuffer_commit_read_(struct evbuffer *evbuf, ev_ssize_t nBytes)\n{\n\tstruct evbuffer_overlapped *buf = upcast_evbuffer(evbuf);\n\tstruct evbuffer_chain **chainp;\n\tsize_t remaining, len;\n\tunsigned i;\n\n\tEVBUFFER_LOCK(evbuf);\n\tEVUTIL_ASSERT(buf->read_in_progress && !buf->write_in_progress);\n\tEVUTIL_ASSERT(nBytes >= 0); /* XXXX Can this be false? */\n\n\tevbuffer_unfreeze(evbuf, 0);\n\n\tchainp = evbuf->last_with_datap;\n\tif (!((*chainp)->flags & EVBUFFER_MEM_PINNED_R))\n\t\tchainp = &(*chainp)->next;\n\tremaining = nBytes;\n\tfor (i = 0; remaining > 0 && i < (unsigned)buf->n_buffers; ++i) {\n\t\tEVUTIL_ASSERT(*chainp);\n\t\tlen = buf->buffers[i].len;\n\t\tif (remaining < len)\n\t\t\tlen = remaining;\n\t\t(*chainp)->off += len;\n\t\tevbuf->last_with_datap = chainp;\n\t\tremaining -= len;\n\t\tchainp = &(*chainp)->next;\n\t}\n\n\tpin_release(buf, EVBUFFER_MEM_PINNED_R);\n\n\tbuf->read_in_progress = 0;\n\n\tevbuf->total_len += nBytes;\n\tevbuf->n_add_for_cb += nBytes;\n\n\tevbuffer_invoke_callbacks_(evbuf);\n\n\tevbuffer_decref_and_unlock_(evbuf);\n}\n\nvoid\nevbuffer_commit_write_(struct evbuffer *evbuf, ev_ssize_t nBytes)\n{\n\tstruct evbuffer_overlapped *buf = upcast_evbuffer(evbuf);\n\n\tEVBUFFER_LOCK(evbuf);\n\tEVUTIL_ASSERT(buf->write_in_progress && !buf->read_in_progress);\n\tevbuffer_unfreeze(evbuf, 1);\n\tevbuffer_drain(evbuf, nBytes);\n\tpin_release(buf,EVBUFFER_MEM_PINNED_W);\n\tbuf->write_in_progress = 0;\n\tevbuffer_decref_and_unlock_(evbuf);\n}\n\nstruct evbuffer *\nevbuffer_overlapped_new_(evutil_socket_t fd)\n{\n\tstruct evbuffer_overlapped *evo;\n\n\tevo = mm_calloc(1, sizeof(struct evbuffer_overlapped));\n\tif (!evo)\n\t\treturn NULL;\n\n\tLIST_INIT(&evo->buffer.callbacks);\n\tevo->buffer.refcnt = 1;\n\tevo->buffer.last_with_datap = &evo->buffer.first;\n\n\tevo->buffer.is_overlapped = 1;\n\tevo->fd = fd;\n\n\treturn &evo->buffer;\n}\n\nint\nevbuffer_launch_write_(struct evbuffer *buf, ev_ssize_t at_most,\n\t\tstruct event_overlapped *ol)\n{\n\tstruct evbuffer_overlapped *buf_o = upcast_evbuffer(buf);\n\tint r = -1;\n\tint i;\n\tstruct evbuffer_chain *chain;\n\tDWORD bytesSent;\n\n\tif (!buf) {\n\t\t/* No buffer, or it isn't overlapped */\n\t\treturn -1;\n\t}\n\n\tEVBUFFER_LOCK(buf);\n\tEVUTIL_ASSERT(!buf_o->read_in_progress);\n\tif (buf->freeze_start || buf_o->write_in_progress)\n\t\tgoto done;\n\tif (!buf->total_len) {\n\t\t/* Nothing to write */\n\t\tr = 0;\n\t\tgoto done;\n\t} else if (at_most < 0 || (size_t)at_most > buf->total_len) {\n\t\tat_most = buf->total_len;\n\t}\n\tevbuffer_freeze(buf, 1);\n\n\tbuf_o->first_pinned = NULL;\n\tbuf_o->n_buffers = 0;\n\tmemset(buf_o->buffers, 0, sizeof(buf_o->buffers));\n\n\tchain = buf_o->first_pinned = buf->first;\n\n\tfor (i=0; i < MAX_WSABUFS && chain; ++i, chain=chain->next) {\n\t\tWSABUF *b = &buf_o->buffers[i];\n\t\tb->buf = (char*)( chain->buffer + chain->misalign );\n\t\tevbuffer_chain_pin_(chain, EVBUFFER_MEM_PINNED_W);\n\n\t\tif ((size_t)at_most > chain->off) {\n\t\t\t/* XXXX Cast is safe for now, since win32 has no\n\t\t\t   mmaped chains.  But later, we need to have this\n\t\t\t   add more WSAbufs if chain->off is greater than\n\t\t\t   ULONG_MAX */\n\t\t\tb->len = (unsigned long)chain->off;\n\t\t\tat_most -= chain->off;\n\t\t} else {\n\t\t\tb->len = (unsigned long)at_most;\n\t\t\t++i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tbuf_o->n_buffers = i;\n\tevbuffer_incref_(buf);\n\tif (WSASend(buf_o->fd, buf_o->buffers, i, &bytesSent, 0,\n\t\t&ol->overlapped, NULL)) {\n\t\tint error = WSAGetLastError();\n\t\tif (error != WSA_IO_PENDING) {\n\t\t\t/* An actual error. */\n\t\t\tpin_release(buf_o, EVBUFFER_MEM_PINNED_W);\n\t\t\tevbuffer_unfreeze(buf, 1);\n\t\t\tevbuffer_free(buf); /* decref */\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tbuf_o->write_in_progress = 1;\n\tr = 0;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn r;\n}\n\nint\nevbuffer_launch_read_(struct evbuffer *buf, size_t at_most,\n\t\tstruct event_overlapped *ol)\n{\n\tstruct evbuffer_overlapped *buf_o = upcast_evbuffer(buf);\n\tint r = -1, i;\n\tint nvecs;\n\tint npin=0;\n\tstruct evbuffer_chain *chain=NULL, **chainp;\n\tDWORD bytesRead;\n\tDWORD flags = 0;\n\tstruct evbuffer_iovec vecs[MAX_WSABUFS];\n\n\tif (!buf_o)\n\t\treturn -1;\n\tEVBUFFER_LOCK(buf);\n\tEVUTIL_ASSERT(!buf_o->write_in_progress);\n\tif (buf->freeze_end || buf_o->read_in_progress)\n\t\tgoto done;\n\n\tbuf_o->first_pinned = NULL;\n\tbuf_o->n_buffers = 0;\n\tmemset(buf_o->buffers, 0, sizeof(buf_o->buffers));\n\n\tif (evbuffer_expand_fast_(buf, at_most, MAX_WSABUFS) == -1)\n\t\tgoto done;\n\tevbuffer_freeze(buf, 0);\n\n\tnvecs = evbuffer_read_setup_vecs_(buf, at_most,\n\t    vecs, MAX_WSABUFS, &chainp, 1);\n\tfor (i=0;i<nvecs;++i) {\n\t\tWSABUF_FROM_EVBUFFER_IOV(\n\t\t\t&buf_o->buffers[i],\n\t\t\t&vecs[i]);\n\t}\n\n\tbuf_o->n_buffers = nvecs;\n\tbuf_o->first_pinned = chain = *chainp;\n\n\tnpin=0;\n\tfor ( ; chain; chain = chain->next) {\n\t\tevbuffer_chain_pin_(chain, EVBUFFER_MEM_PINNED_R);\n\t\t++npin;\n\t}\n\tEVUTIL_ASSERT(npin == nvecs);\n\n\tevbuffer_incref_(buf);\n\tif (WSARecv(buf_o->fd, buf_o->buffers, nvecs, &bytesRead, &flags,\n\t\t    &ol->overlapped, NULL)) {\n\t\tint error = WSAGetLastError();\n\t\tif (error != WSA_IO_PENDING) {\n\t\t\t/* An actual error. */\n\t\t\tpin_release(buf_o, EVBUFFER_MEM_PINNED_R);\n\t\t\tevbuffer_unfreeze(buf, 0);\n\t\t\tevbuffer_free(buf); /* decref */\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tbuf_o->read_in_progress = 1;\n\tr = 0;\ndone:\n\tEVBUFFER_UNLOCK(buf);\n\treturn r;\n}\n\nevutil_socket_t\nevbuffer_overlapped_get_fd_(struct evbuffer *buf)\n{\n\tstruct evbuffer_overlapped *buf_o = upcast_evbuffer(buf);\n\treturn buf_o ? buf_o->fd : -1;\n}\n\nvoid\nevbuffer_overlapped_set_fd_(struct evbuffer *buf, evutil_socket_t fd)\n{\n\tstruct evbuffer_overlapped *buf_o = upcast_evbuffer(buf);\n\tEVBUFFER_LOCK(buf);\n\t/* XXX is this right?, should it cancel current I/O operations? */\n\tif (buf_o)\n\t\tbuf_o->fd = fd;\n\tEVBUFFER_UNLOCK(buf);\n}\n"
        },
        {
          "name": "bufferevent-internal.h",
          "type": "blob",
          "size": 19.166015625,
          "content": "/*\n * Copyright (c) 2008-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef BUFFEREVENT_INTERNAL_H_INCLUDED_\n#define BUFFEREVENT_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"event2/event_struct.h\"\n#include \"evconfig-private.h\"\n#include \"event2/util.h\"\n#include \"defer-internal.h\"\n#include \"evthread-internal.h\"\n#include \"event2/thread.h\"\n#include \"ratelim-internal.h\"\n#include \"event2/bufferevent_struct.h\"\n\n#include \"ipv6-internal.h\"\n#ifdef _WIN32\n#include <ws2tcpip.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n\n/* These flags are reasons that we might be declining to actually enable\n   reading or writing on a bufferevent.\n */\n\n/* On a all bufferevents, for reading: used when we have read up to the\n   watermark value.\n\n   On a filtering bufferevent, for writing: used when the underlying\n   bufferevent's write buffer has been filled up to its watermark\n   value.\n*/\n#define BEV_SUSPEND_WM 0x01\n/* On a base bufferevent: when we have emptied a bandwidth buckets */\n#define BEV_SUSPEND_BW 0x02\n/* On a base bufferevent: when we have emptied the group's bandwidth bucket. */\n#define BEV_SUSPEND_BW_GROUP 0x04\n/* On a socket bufferevent: can't do any operations while we're waiting for\n * name lookup to finish. */\n#define BEV_SUSPEND_LOOKUP 0x08\n/* On a base bufferevent, for reading: used when a filter has choked this\n * (underlying) bufferevent because it has stopped reading from it. */\n#define BEV_SUSPEND_FILT_READ 0x10\n\ntypedef ev_uint16_t bufferevent_suspend_flags;\n\nstruct bufferevent_rate_limit_group {\n\t/** List of all members in the group */\n\tLIST_HEAD(rlim_group_member_list, bufferevent_private) members;\n\t/** Current limits for the group. */\n\tstruct ev_token_bucket rate_limit;\n\tstruct ev_token_bucket_cfg rate_limit_cfg;\n\n\t/** True iff we don't want to read from any member of the group.until\n\t * the token bucket refills.  */\n\tunsigned read_suspended : 1;\n\t/** True iff we don't want to write from any member of the group.until\n\t * the token bucket refills.  */\n\tunsigned write_suspended : 1;\n\t/** True iff we were unable to suspend one of the bufferevents in the\n\t * group for reading the last time we tried, and we should try\n\t * again. */\n\tunsigned pending_unsuspend_read : 1;\n\t/** True iff we were unable to suspend one of the bufferevents in the\n\t * group for writing the last time we tried, and we should try\n\t * again. */\n\tunsigned pending_unsuspend_write : 1;\n\n\t/*@{*/\n\t/** Total number of bytes read or written in this group since last\n\t * reset. */\n\tev_uint64_t total_read;\n\tev_uint64_t total_written;\n\t/*@}*/\n\n\t/** The number of bufferevents in the group. */\n\tint n_members;\n\n\t/** The smallest number of bytes that any member of the group should\n\t * be limited to read or write at a time. */\n\tev_ssize_t min_share;\n\tev_ssize_t configured_min_share;\n\n\t/** Timeout event that goes off once a tick, when the bucket is ready\n\t * to refill. */\n\tstruct event master_refill_event;\n\n\t/** Seed for weak random number generator. Protected by 'lock' */\n\tstruct evutil_weakrand_state weakrand_seed;\n\n\t/** Lock to protect the members of this group.  This lock should nest\n\t * within every bufferevent lock: if you are holding this lock, do\n\t * not assume you can lock another bufferevent. */\n\tvoid *lock;\n};\n\n/** Fields for rate-limiting a single bufferevent. */\nstruct bufferevent_rate_limit {\n\t/* Linked-list elements for storing this bufferevent_private in a\n\t * group.\n\t *\n\t * Note that this field is supposed to be protected by the group\n\t * lock */\n\tLIST_ENTRY(bufferevent_private) next_in_group;\n\t/** The rate-limiting group for this bufferevent, or NULL if it is\n\t * only rate-limited on its own. */\n\tstruct bufferevent_rate_limit_group *group;\n\n\t/* This bufferevent's current limits. */\n\tstruct ev_token_bucket limit;\n\t/* Pointer to the rate-limit configuration for this bufferevent.\n\t * Can be shared.  XXX reference-count this? */\n\tstruct ev_token_bucket_cfg *cfg;\n\n\t/* Timeout event used when one this bufferevent's buckets are\n\t * empty. */\n\tstruct event refill_bucket_event;\n};\n\n/** Parts of the bufferevent structure that are shared among all bufferevent\n * types, but not exposed in bufferevent_struct.h. */\nstruct bufferevent_private {\n\t/** The underlying bufferevent structure. */\n\tstruct bufferevent bev;\n\n\t/** Evbuffer callback to enforce watermarks on input. */\n\tstruct evbuffer_cb_entry *read_watermarks_cb;\n\n\t/** If set, we should free the lock when we free the bufferevent. */\n\tunsigned own_lock : 1;\n\n\t/** Flag: set if we have deferred callbacks and a read callback is\n\t * pending. */\n\tunsigned readcb_pending : 1;\n\t/** Flag: set if we have deferred callbacks and a write callback is\n\t * pending. */\n\tunsigned writecb_pending : 1;\n\t/** Flag: set if we are currently busy connecting. */\n\tunsigned connecting : 1;\n\t/** Flag: set if a connect failed prematurely; this is a hack for\n\t * getting around the bufferevent abstraction. */\n\tunsigned connection_refused : 1;\n\t/** Set to the events pending if we have deferred callbacks and\n\t * an events callback is pending. */\n\tshort eventcb_pending;\n\n\t/** If set, read is suspended until one or more conditions are over.\n\t * The actual value here is a bitfield of those conditions; see the\n\t * BEV_SUSPEND_* flags above. */\n\tbufferevent_suspend_flags read_suspended;\n\n\t/** If set, writing is suspended until one or more conditions are over.\n\t * The actual value here is a bitfield of those conditions; see the\n\t * BEV_SUSPEND_* flags above. */\n\tbufferevent_suspend_flags write_suspended;\n\n\t/** Set to the current socket errno if we have deferred callbacks and\n\t * an events callback is pending. */\n\tint errno_pending;\n\n\t/** The DNS error code for bufferevent_socket_connect_hostname */\n\tint dns_error;\n\n\t/** Used to implement deferred callbacks */\n\tstruct event_callback deferred;\n\n\t/** The options this bufferevent was constructed with */\n\tenum bufferevent_options options;\n\n\t/** Current reference count for this bufferevent. */\n\tint refcnt;\n\n\t/** Lock for this bufferevent.  Shared by the inbuf and the outbuf.\n\t * If NULL, locking is disabled. */\n\tvoid *lock;\n\n\t/** No matter how big our bucket gets, don't try to read more than this\n\t * much in a single read operation. */\n\tev_ssize_t max_single_read;\n\n\t/** No matter how big our bucket gets, don't try to write more than this\n\t * much in a single write operation. */\n\tev_ssize_t max_single_write;\n\n\t/** Rate-limiting information for this bufferevent */\n\tstruct bufferevent_rate_limit *rate_limiting;\n\n\t/* Saved conn_addr, to extract IP address from it.\n\t *\n\t * Because some servers may reset/close connection without waiting clients,\n\t * in that case we can't extract IP address even in close_cb.\n\t * So we need to save it, just after we connected to remote server, or\n\t * after resolving (to avoid extra dns requests during retrying, since UDP\n\t * is slow) */\n\tunion {\n\t\tstruct sockaddr_in6 in6;\n\t\tstruct sockaddr_in in;\n\t} conn_address;\n\n\tstruct evdns_getaddrinfo_request *dns_request;\n};\n\n/** Possible operations for a control callback. */\nenum bufferevent_ctrl_op {\n\tBEV_CTRL_SET_FD,\n\tBEV_CTRL_GET_FD,\n\tBEV_CTRL_GET_UNDERLYING,\n\tBEV_CTRL_CANCEL_ALL\n};\n\n/** Possible data types for a control callback */\nunion bufferevent_ctrl_data {\n\tvoid *ptr;\n\tevutil_socket_t fd;\n};\n\n/**\n   Implementation table for a bufferevent: holds function pointers and other\n   information to make the various bufferevent types work.\n*/\nstruct bufferevent_ops {\n\t/** The name of the bufferevent's type. */\n\tconst char *type;\n\t/** At what offset into the implementation type will we find a\n\t    bufferevent structure?\n\n\t    Example: if the type is implemented as\n\t    struct bufferevent_x {\n\t       int extra_data;\n\t       struct bufferevent bev;\n\t    }\n\t    then mem_offset should be offsetof(struct bufferevent_x, bev)\n\t*/\n\toff_t mem_offset;\n\n\t/** Enables one or more of EV_READ|EV_WRITE on a bufferevent.  Does\n\t    not need to adjust the 'enabled' field.  Returns 0 on success, -1\n\t    on failure.\n\t */\n\tint (*enable)(struct bufferevent *, short);\n\n\t/** Disables one or more of EV_READ|EV_WRITE on a bufferevent.  Does\n\t    not need to adjust the 'enabled' field.  Returns 0 on success, -1\n\t    on failure.\n\t */\n\tint (*disable)(struct bufferevent *, short);\n\n\t/** Detatches the bufferevent from related data structures. Called as\n\t * soon as its reference count reaches 0. */\n\tvoid (*unlink)(struct bufferevent *);\n\n\t/** Free any storage and deallocate any extra data or structures used\n\t    in this implementation. Called when the bufferevent is\n\t    finalized.\n\t */\n\tvoid (*destruct)(struct bufferevent *);\n\n\t/** Called when the timeouts on the bufferevent have changed.*/\n\tint (*adj_timeouts)(struct bufferevent *);\n\n\t/** Called to flush data. */\n\tint (*flush)(struct bufferevent *, short, enum bufferevent_flush_mode);\n\n\t/** Called to access miscellaneous fields. */\n\tint (*ctrl)(struct bufferevent *, enum bufferevent_ctrl_op, union bufferevent_ctrl_data *);\n\n};\n\nextern const struct bufferevent_ops bufferevent_ops_socket;\nextern const struct bufferevent_ops bufferevent_ops_filter;\nextern const struct bufferevent_ops bufferevent_ops_pair;\n\n#define BEV_IS_SOCKET(bevp) ((bevp)->be_ops == &bufferevent_ops_socket)\n#define BEV_IS_FILTER(bevp) ((bevp)->be_ops == &bufferevent_ops_filter)\n#define BEV_IS_PAIR(bevp) ((bevp)->be_ops == &bufferevent_ops_pair)\n\n#if defined(EVENT__HAVE_OPENSSL) || defined(EVENT__HAVE_MBEDTLS)\n/* We cannot use the same trick with external declaration,\n * since there are copy of bufferevent_ops_ssl in each library:\n * - openssl\n * - mbedlts\n *\n * However we can just compare the name of the bufferevent type for now.\n * (It is totally fine to use memcmp() here since it will be optimized by the compiler).\n */\n#define BEV_IS_SSL(bevp) (!memcmp((bevp)->be_ops->type, \"ssl\", 3))\n#else\n#define BEV_IS_SSL(bevp) 0\n#endif\n\n#ifdef _WIN32\nextern const struct bufferevent_ops bufferevent_ops_async;\n#define BEV_IS_ASYNC(bevp) ((bevp)->be_ops == &bufferevent_ops_async)\n#else\n#define BEV_IS_ASYNC(bevp) 0\n#endif\n\n/** Initialize the shared parts of a bufferevent. */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_init_common_(struct bufferevent_private *, struct event_base *, const struct bufferevent_ops *, enum bufferevent_options options);\n\n/** For internal use: temporarily stop all reads on bufev, until the conditions\n * in 'what' are over. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_suspend_read_(struct bufferevent *bufev, bufferevent_suspend_flags what);\n/** For internal use: clear the conditions 'what' on bufev, and re-enable\n * reading if there are no conditions left. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_unsuspend_read_(struct bufferevent *bufev, bufferevent_suspend_flags what);\n\n/** For internal use: temporarily stop all writes on bufev, until the conditions\n * in 'what' are over. */\nvoid bufferevent_suspend_write_(struct bufferevent *bufev, bufferevent_suspend_flags what);\n/** For internal use: clear the conditions 'what' on bufev, and re-enable\n * writing if there are no conditions left. */\nvoid bufferevent_unsuspend_write_(struct bufferevent *bufev, bufferevent_suspend_flags what);\n\n#define bufferevent_wm_suspend_read(b) \\\n\tbufferevent_suspend_read_((b), BEV_SUSPEND_WM)\n#define bufferevent_wm_unsuspend_read(b) \\\n\tbufferevent_unsuspend_read_((b), BEV_SUSPEND_WM)\n\n/*\n  Disable a bufferevent.  Equivalent to bufferevent_disable(), but\n  first resets 'connecting' flag to force EV_WRITE down for sure.\n\n  XXXX this method will go away in the future; try not to add new users.\n    See comment in evhttp_connection_reset_() for discussion.\n\n  @param bufev the bufferevent to be disabled\n  @param event any combination of EV_READ | EV_WRITE.\n  @return 0 if successful, or -1 if an error occurred\n  @see bufferevent_disable()\n */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_disable_hard_(struct bufferevent *bufev, short event);\n\n/** Internal: Set up locking on a bufferevent.  If lock is set, use it.\n * Otherwise, use a new lock. */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_enable_locking_(struct bufferevent *bufev, void *lock);\n/** Internal: backwards compat macro for the now public function\n * Increment the reference count on bufev. */\n#define bufferevent_incref_(bufev) bufferevent_incref(bufev)\n/** Internal: Lock bufev and increase its reference count.\n * unlocking it otherwise. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_incref_and_lock_(struct bufferevent *bufev);\n/** Internal: backwards compat macro for the now public function\n * Decrement the reference count on bufev.  Returns 1 if it freed\n * the bufferevent.*/\n#define bufferevent_decref_(bufev) bufferevent_decref(bufev)\n\n/** Internal: Drop the reference count on bufev, freeing as necessary, and\n * unlocking it otherwise.  Returns 1 if it freed the bufferevent. */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_decref_and_unlock_(struct bufferevent *bufev);\n\n/** Internal: If callbacks are deferred and we have a read callback, schedule\n * a readcb.  Otherwise just run the readcb. Ignores watermarks. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_run_readcb_(struct bufferevent *bufev, int options);\n/** Internal: If callbacks are deferred and we have a write callback, schedule\n * a writecb.  Otherwise just run the writecb. Ignores watermarks. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_run_writecb_(struct bufferevent *bufev, int options);\n/** Internal: If callbacks are deferred and we have an eventcb, schedule\n * it to run with events \"what\".  Otherwise just run the eventcb.\n * See bufferevent_trigger_event for meaning of \"options\". */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_run_eventcb_(struct bufferevent *bufev, short what, int options);\n\n/** Internal: Run or schedule (if deferred or options contain\n * BEV_TRIG_DEFER_CALLBACKS) I/O callbacks specified in iotype.\n * Must already hold the bufev lock. Honors watermarks unless\n * BEV_TRIG_IGNORE_WATERMARKS is in options. */\nstatic inline void bufferevent_trigger_nolock_(struct bufferevent *bufev, short iotype, int options);\n\n/* Making this inline since all of the common-case calls to this function in\n * libevent use constant arguments. */\nstatic inline void\nbufferevent_trigger_nolock_(struct bufferevent *bufev, short iotype, int options)\n{\n\tif ((iotype & EV_READ) && ((options & BEV_TRIG_IGNORE_WATERMARKS) ||\n\t    evbuffer_get_length(bufev->input) >= bufev->wm_read.low))\n\t\tbufferevent_run_readcb_(bufev, options);\n\tif ((iotype & EV_WRITE) && ((options & BEV_TRIG_IGNORE_WATERMARKS) ||\n\t    evbuffer_get_length(bufev->output) <= bufev->wm_write.low))\n\t\tbufferevent_run_writecb_(bufev, options);\n}\n\n/** Internal: Add the event 'ev' with timeout tv, unless tv is set to 0, in\n * which case add ev with no timeout. */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_add_event_(struct event *ev, const struct timeval *tv);\n\n/* =========\n * These next functions implement timeouts for bufferevents that aren't doing\n * anything else with ev_read and ev_write, to handle timeouts.\n * ========= */\n/** Internal use: Set up the ev_read and ev_write callbacks so that\n * the other \"generic_timeout\" functions will work on it.  Call this from\n * the constructor function. */\nEVENT2_EXPORT_SYMBOL\nvoid bufferevent_init_generic_timeout_cbs_(struct bufferevent *bev);\n/** Internal use: Add or delete the generic timeout events as appropriate.\n * (If an event is enabled and a timeout is set, we add the event.  Otherwise\n * we delete it.)  Call this from anything that changes the timeout values,\n * that enabled EV_READ or EV_WRITE, or that disables EV_READ or EV_WRITE. */\nEVENT2_EXPORT_SYMBOL\nint bufferevent_generic_adj_timeouts_(struct bufferevent *bev);\nEVENT2_EXPORT_SYMBOL\nint bufferevent_generic_adj_existing_timeouts_(struct bufferevent *bev);\n\nEVENT2_EXPORT_SYMBOL\nenum bufferevent_options bufferevent_get_options_(struct bufferevent *bev);\n\nEVENT2_EXPORT_SYMBOL\nconst struct sockaddr*\nbufferevent_socket_get_conn_address_(struct bufferevent *bev);\n\nEVENT2_EXPORT_SYMBOL\nvoid\nbufferevent_socket_set_conn_address_fd_(struct bufferevent *bev, evutil_socket_t fd);\n\nEVENT2_EXPORT_SYMBOL\nvoid\nbufferevent_socket_set_conn_address_(struct bufferevent *bev, struct sockaddr *addr, size_t addrlen);\n\n\n/** Internal use: We have just successfully read data into an inbuf, so\n * reset the read timeout (if any). */\n#define BEV_RESET_GENERIC_READ_TIMEOUT(bev)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (evutil_timerisset(&(bev)->timeout_read))\t\t\\\n\t\t\tevent_add(&(bev)->ev_read, &(bev)->timeout_read); \\\n\t} while (0)\n/** Internal use: We have just successfully written data from an inbuf, so\n * reset the read timeout (if any). */\n#define BEV_RESET_GENERIC_WRITE_TIMEOUT(bev)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (evutil_timerisset(&(bev)->timeout_write))\t\t\\\n\t\t\tevent_add(&(bev)->ev_write, &(bev)->timeout_write); \\\n\t} while (0)\n#define BEV_DEL_GENERIC_READ_TIMEOUT(bev)\t\\\n\t\tevent_del(&(bev)->ev_read)\n#define BEV_DEL_GENERIC_WRITE_TIMEOUT(bev)\t\\\n\t\tevent_del(&(bev)->ev_write)\n\n\n/** Internal: Given a bufferevent, return its corresponding\n * bufferevent_private. */\n#define BEV_UPCAST(b) EVUTIL_UPCAST((b), struct bufferevent_private, bev)\n\n#ifdef EVENT__DISABLE_THREAD_SUPPORT\n#define BEV_LOCK(b) (void)(b)\n#define BEV_UNLOCK(b) (void)(b)\n#else\n/** Internal: Grab the lock (if any) on a bufferevent */\n#define BEV_LOCK(b) do {\t\t\t\t\t\t\\\n\t\tstruct bufferevent_private *locking =  BEV_UPCAST(b);\t\\\n\t\tEVLOCK_LOCK(locking->lock, 0);\t\t\t\t\\\n\t} while (0)\n\n/** Internal: Release the lock (if any) on a bufferevent */\n#define BEV_UNLOCK(b) do {\t\t\t\t\t\t\\\n\t\tstruct bufferevent_private *locking =  BEV_UPCAST(b);\t\\\n\t\tEVLOCK_UNLOCK(locking->lock, 0);\t\t\t\\\n\t} while (0)\n#endif\n\n\n/* ==== For rate-limiting. */\n\nEVENT2_EXPORT_SYMBOL\nint bufferevent_decrement_write_buckets_(struct bufferevent_private *bev,\n    ev_ssize_t bytes);\nEVENT2_EXPORT_SYMBOL\nint bufferevent_decrement_read_buckets_(struct bufferevent_private *bev,\n    ev_ssize_t bytes);\nEVENT2_EXPORT_SYMBOL\nev_ssize_t bufferevent_get_read_max_(struct bufferevent_private *bev);\nEVENT2_EXPORT_SYMBOL\nev_ssize_t bufferevent_get_write_max_(struct bufferevent_private *bev);\n\nint bufferevent_ratelim_init_(struct bufferevent_private *bev);\n\n#ifdef __cplusplus\n}\n#endif\n\n\n#endif /* BUFFEREVENT_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "bufferevent.c",
          "type": "blob",
          "size": 26.79296875,
          "content": "/*\n * Copyright (c) 2002-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"event2/buffer.h\"\n#include \"event2/buffer_compat.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/bufferevent_compat.h\"\n#include \"event2/event.h\"\n#include \"event-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"evbuffer-internal.h\"\n#include \"util-internal.h\"\n\nstatic void bufferevent_cancel_all_(struct bufferevent *bev);\nstatic void bufferevent_finalize_cb_(struct event_callback *evcb, void *arg_);\n\nvoid\nbufferevent_suspend_read_(struct bufferevent *bufev, bufferevent_suspend_flags what)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tBEV_LOCK(bufev);\n\tif (!bufev_private->read_suspended)\n\t\tbufev->be_ops->disable(bufev, EV_READ);\n\tbufev_private->read_suspended |= what;\n\tBEV_UNLOCK(bufev);\n}\n\nvoid\nbufferevent_unsuspend_read_(struct bufferevent *bufev, bufferevent_suspend_flags what)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tBEV_LOCK(bufev);\n\tbufev_private->read_suspended &= ~what;\n\tif (!bufev_private->read_suspended && (bufev->enabled & EV_READ))\n\t\tbufev->be_ops->enable(bufev, EV_READ);\n\tBEV_UNLOCK(bufev);\n}\n\nvoid\nbufferevent_suspend_write_(struct bufferevent *bufev, bufferevent_suspend_flags what)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tBEV_LOCK(bufev);\n\tif (!bufev_private->write_suspended)\n\t\tbufev->be_ops->disable(bufev, EV_WRITE);\n\tbufev_private->write_suspended |= what;\n\tBEV_UNLOCK(bufev);\n}\n\nvoid\nbufferevent_unsuspend_write_(struct bufferevent *bufev, bufferevent_suspend_flags what)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tBEV_LOCK(bufev);\n\tbufev_private->write_suspended &= ~what;\n\tif (!bufev_private->write_suspended && (bufev->enabled & EV_WRITE))\n\t\tbufev->be_ops->enable(bufev, EV_WRITE);\n\tBEV_UNLOCK(bufev);\n}\n\n/**\n * Sometimes bufferevent's implementation can overrun high watermarks\n * (one of examples is openssl) and in this case if the read callback\n * will not handle enough data do over condition above the read\n * callback will never be called again (due to suspend above).\n *\n * To avoid this we are scheduling read callback again here, but only\n * from the user callback to avoid multiple scheduling:\n * - when the data had been added to it\n * - when the data had been drained from it (user specified read callback)\n */\nstatic void bufferevent_inbuf_wm_check(struct bufferevent *bev)\n{\n\tif (!bev->wm_read.high)\n\t\treturn;\n\tif (!(bev->enabled & EV_READ))\n\t\treturn;\n\tif (evbuffer_get_length(bev->input) < bev->wm_read.high)\n\t\treturn;\n\n\tbufferevent_trigger(bev, EV_READ, BEV_OPT_DEFER_CALLBACKS);\n}\n\n/* Callback to implement watermarks on the input buffer.  Only enabled\n * if the watermark is set. */\nstatic void\nbufferevent_inbuf_wm_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo,\n    void *arg)\n{\n\tstruct bufferevent *bufev = arg;\n\tsize_t size;\n\n\tsize = evbuffer_get_length(buf);\n\n\tif (size >= bufev->wm_read.high)\n\t\tbufferevent_wm_suspend_read(bufev);\n\telse\n\t\tbufferevent_wm_unsuspend_read(bufev);\n}\n\nstatic void\nbufferevent_run_deferred_callbacks_locked(struct event_callback *cb, void *arg)\n{\n\tstruct bufferevent_private *bufev_private = arg;\n\tstruct bufferevent *bufev = &bufev_private->bev;\n\n\tBEV_LOCK(bufev);\n\tif ((bufev_private->eventcb_pending & BEV_EVENT_CONNECTED) &&\n\t    bufev->errorcb) {\n\t\t/* The \"connected\" happened before any reads or writes, so\n\t\t   send it first. */\n\t\tbufev_private->eventcb_pending &= ~BEV_EVENT_CONNECTED;\n\t\tbufev->errorcb(bufev, BEV_EVENT_CONNECTED, bufev->cbarg);\n\t}\n\tif (bufev_private->readcb_pending && bufev->readcb) {\n\t\tbufev_private->readcb_pending = 0;\n\t\tbufev->readcb(bufev, bufev->cbarg);\n\t\tbufferevent_inbuf_wm_check(bufev);\n\t}\n\tif (bufev_private->writecb_pending && bufev->writecb) {\n\t\tbufev_private->writecb_pending = 0;\n\t\tbufev->writecb(bufev, bufev->cbarg);\n\t}\n\tif (bufev_private->eventcb_pending && bufev->errorcb) {\n\t\tshort what = bufev_private->eventcb_pending;\n\t\tint err = bufev_private->errno_pending;\n\t\tbufev_private->eventcb_pending = 0;\n\t\tbufev_private->errno_pending = 0;\n\t\tEVUTIL_SET_SOCKET_ERROR(err);\n\t\tbufev->errorcb(bufev, what, bufev->cbarg);\n\t}\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nstatic void\nbufferevent_run_deferred_callbacks_unlocked(struct event_callback *cb, void *arg)\n{\n\tstruct bufferevent_private *bufev_private = arg;\n\tstruct bufferevent *bufev = &bufev_private->bev;\n\n\tBEV_LOCK(bufev);\n#define UNLOCKED(stmt) \\\n\tdo { BEV_UNLOCK(bufev); stmt; BEV_LOCK(bufev); } while(0)\n\n\tif ((bufev_private->eventcb_pending & BEV_EVENT_CONNECTED) &&\n\t    bufev->errorcb) {\n\t\t/* The \"connected\" happened before any reads or writes, so\n\t\t   send it first. */\n\t\tbufferevent_event_cb errorcb = bufev->errorcb;\n\t\tvoid *cbarg = bufev->cbarg;\n\t\tbufev_private->eventcb_pending &= ~BEV_EVENT_CONNECTED;\n\t\tUNLOCKED(errorcb(bufev, BEV_EVENT_CONNECTED, cbarg));\n\t}\n\tif (bufev_private->readcb_pending && bufev->readcb) {\n\t\tbufferevent_data_cb readcb = bufev->readcb;\n\t\tvoid *cbarg = bufev->cbarg;\n\t\tbufev_private->readcb_pending = 0;\n\t\tUNLOCKED(readcb(bufev, cbarg));\n\t\tbufferevent_inbuf_wm_check(bufev);\n\t}\n\tif (bufev_private->writecb_pending && bufev->writecb) {\n\t\tbufferevent_data_cb writecb = bufev->writecb;\n\t\tvoid *cbarg = bufev->cbarg;\n\t\tbufev_private->writecb_pending = 0;\n\t\tUNLOCKED(writecb(bufev, cbarg));\n\t}\n\tif (bufev_private->eventcb_pending && bufev->errorcb) {\n\t\tbufferevent_event_cb errorcb = bufev->errorcb;\n\t\tvoid *cbarg = bufev->cbarg;\n\t\tshort what = bufev_private->eventcb_pending;\n\t\tint err = bufev_private->errno_pending;\n\t\tbufev_private->eventcb_pending = 0;\n\t\tbufev_private->errno_pending = 0;\n\t\tEVUTIL_SET_SOCKET_ERROR(err);\n\t\tUNLOCKED(errorcb(bufev,what,cbarg));\n\t}\n\tbufferevent_decref_and_unlock_(bufev);\n#undef UNLOCKED\n}\n\n#define SCHEDULE_DEFERRED(bevp)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (event_deferred_cb_schedule_(\t\t\t\\\n\t\t\t    (bevp)->bev.ev_base,\t\t\t\\\n\t\t\t&(bevp)->deferred))\t\t\t\t\\\n\t\t\tbufferevent_incref_(&(bevp)->bev);\t\t\\\n\t} while (0)\n\n\nvoid\nbufferevent_run_readcb_(struct bufferevent *bufev, int options)\n{\n\t/* Requires that we hold the lock and a reference */\n\tstruct bufferevent_private *p = BEV_UPCAST(bufev);\n\tif (bufev->readcb == NULL)\n\t\treturn;\n\tif ((p->options|options) & BEV_OPT_DEFER_CALLBACKS) {\n\t\tp->readcb_pending = 1;\n\t\tSCHEDULE_DEFERRED(p);\n\t} else {\n\t\tbufev->readcb(bufev, bufev->cbarg);\n\t\tbufferevent_inbuf_wm_check(bufev);\n\t}\n}\n\nvoid\nbufferevent_run_writecb_(struct bufferevent *bufev, int options)\n{\n\t/* Requires that we hold the lock and a reference */\n\tstruct bufferevent_private *p = BEV_UPCAST(bufev);\n\tif (bufev->writecb == NULL)\n\t\treturn;\n\tif ((p->options|options) & BEV_OPT_DEFER_CALLBACKS) {\n\t\tp->writecb_pending = 1;\n\t\tSCHEDULE_DEFERRED(p);\n\t} else {\n\t\tbufev->writecb(bufev, bufev->cbarg);\n\t}\n}\n\n#define BEV_TRIG_ALL_OPTS (\t\t\t\\\n\t\tBEV_TRIG_IGNORE_WATERMARKS|\t\\\n\t\tBEV_TRIG_DEFER_CALLBACKS\t\\\n\t)\n\nvoid\nbufferevent_trigger(struct bufferevent *bufev, short iotype, int options)\n{\n\tbufferevent_incref_and_lock_(bufev);\n\tbufferevent_trigger_nolock_(bufev, iotype, options&BEV_TRIG_ALL_OPTS);\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nvoid\nbufferevent_run_eventcb_(struct bufferevent *bufev, short what, int options)\n{\n\t/* Requires that we hold the lock and a reference */\n\tstruct bufferevent_private *p = BEV_UPCAST(bufev);\n\tif (bufev->errorcb == NULL)\n\t\treturn;\n\tif ((p->options|options) & BEV_OPT_DEFER_CALLBACKS) {\n\t\tp->eventcb_pending |= what;\n\t\tp->errno_pending = EVUTIL_SOCKET_ERROR();\n\t\tSCHEDULE_DEFERRED(p);\n\t} else {\n\t\tbufev->errorcb(bufev, what, bufev->cbarg);\n\t}\n}\n\nvoid\nbufferevent_trigger_event(struct bufferevent *bufev, short what, int options)\n{\n\tbufferevent_incref_and_lock_(bufev);\n\tbufferevent_run_eventcb_(bufev, what, options&BEV_TRIG_ALL_OPTS);\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nint\nbufferevent_init_common_(struct bufferevent_private *bufev_private,\n    struct event_base *base,\n    const struct bufferevent_ops *ops,\n    enum bufferevent_options options)\n{\n\tstruct bufferevent *bufev = &bufev_private->bev;\n\n\tif (!bufev->input) {\n\t\tif ((bufev->input = evbuffer_new()) == NULL)\n\t\t\tgoto err;\n\t}\n\n\tif (!bufev->output) {\n\t\tif ((bufev->output = evbuffer_new()) == NULL)\n\t\t\tgoto err;\n\t}\n\n\tbufev_private->refcnt = 1;\n\tbufev->ev_base = base;\n\n\t/* Disable timeouts. */\n\tevutil_timerclear(&bufev->timeout_read);\n\tevutil_timerclear(&bufev->timeout_write);\n\n\tbufev->be_ops = ops;\n\n\tif (bufferevent_ratelim_init_(bufev_private))\n\t\tgoto err;\n\n\t/*\n\t * Set to EV_WRITE so that using bufferevent_write is going to\n\t * trigger a callback.  Reading needs to be explicitly enabled\n\t * because otherwise no data will be available.\n\t */\n\tbufev->enabled = EV_WRITE;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (options & BEV_OPT_THREADSAFE) {\n\t\tif (bufferevent_enable_locking_(bufev, NULL) < 0)\n\t\t\tgoto err;\n\t}\n#endif\n\tif ((options & (BEV_OPT_DEFER_CALLBACKS|BEV_OPT_UNLOCK_CALLBACKS))\n\t    == BEV_OPT_UNLOCK_CALLBACKS) {\n\t\tevent_warnx(\"UNLOCK_CALLBACKS requires DEFER_CALLBACKS\");\n\t\tgoto err;\n\t}\n\tif (options & BEV_OPT_UNLOCK_CALLBACKS)\n\t\tevent_deferred_cb_init_(\n\t\t    &bufev_private->deferred,\n\t\t    event_base_get_npriorities(base) / 2,\n\t\t    bufferevent_run_deferred_callbacks_unlocked,\n\t\t    bufev_private);\n\telse\n\t\tevent_deferred_cb_init_(\n\t\t    &bufev_private->deferred,\n\t\t    event_base_get_npriorities(base) / 2,\n\t\t    bufferevent_run_deferred_callbacks_locked,\n\t\t    bufev_private);\n\n\tbufev_private->options = options;\n\n\tevbuffer_set_parent_(bufev->input, bufev);\n\tevbuffer_set_parent_(bufev->output, bufev);\n\n\treturn 0;\n\nerr:\n\tif (bufev->input) {\n\t\tevbuffer_free(bufev->input);\n\t\tbufev->input = NULL;\n\t}\n\tif (bufev->output) {\n\t\tevbuffer_free(bufev->output);\n\t\tbufev->output = NULL;\n\t}\n\treturn -1;\n}\n\nvoid\nbufferevent_setcb(struct bufferevent *bufev,\n    bufferevent_data_cb readcb, bufferevent_data_cb writecb,\n    bufferevent_event_cb eventcb, void *cbarg)\n{\n\tBEV_LOCK(bufev);\n\n\tbufev->readcb = readcb;\n\tbufev->writecb = writecb;\n\tbufev->errorcb = eventcb;\n\n\tbufev->cbarg = cbarg;\n\tBEV_UNLOCK(bufev);\n}\n\nvoid\nbufferevent_getcb(struct bufferevent *bufev,\n    bufferevent_data_cb *readcb_ptr,\n    bufferevent_data_cb *writecb_ptr,\n    bufferevent_event_cb *eventcb_ptr,\n    void **cbarg_ptr)\n{\n\tBEV_LOCK(bufev);\n\tif (readcb_ptr)\n\t\t*readcb_ptr = bufev->readcb;\n\tif (writecb_ptr)\n\t\t*writecb_ptr = bufev->writecb;\n\tif (eventcb_ptr)\n\t\t*eventcb_ptr = bufev->errorcb;\n\tif (cbarg_ptr)\n\t\t*cbarg_ptr = bufev->cbarg;\n\n\tBEV_UNLOCK(bufev);\n}\n\nstruct evbuffer *\nbufferevent_get_input(struct bufferevent *bufev)\n{\n\treturn bufev->input;\n}\n\nstruct evbuffer *\nbufferevent_get_output(struct bufferevent *bufev)\n{\n\treturn bufev->output;\n}\n\nstruct event_base *\nbufferevent_get_base(struct bufferevent *bufev)\n{\n\treturn bufev->ev_base;\n}\n\nint\nbufferevent_get_priority(const struct bufferevent *bufev)\n{\n\tif (event_initialized(&bufev->ev_read)) {\n\t\treturn event_get_priority(&bufev->ev_read);\n\t} else {\n\t\treturn event_base_get_npriorities(bufev->ev_base) / 2;\n\t}\n}\n\nint\nbufferevent_write(struct bufferevent *bufev, const void *data, size_t size)\n{\n\tif (evbuffer_add(bufev->output, data, size) == -1)\n\t\treturn (-1);\n\n\treturn 0;\n}\n\nint\nbufferevent_write_buffer(struct bufferevent *bufev, struct evbuffer *buf)\n{\n\tif (evbuffer_add_buffer(bufev->output, buf) == -1)\n\t\treturn (-1);\n\n\treturn 0;\n}\n\nsize_t\nbufferevent_read(struct bufferevent *bufev, void *data, size_t size)\n{\n\tint r = evbuffer_remove(bufev->input, data, size);\n\n\tif (r == -1)\n\t\treturn 0;\n\n\treturn r;\n}\n\nint\nbufferevent_read_buffer(struct bufferevent *bufev, struct evbuffer *buf)\n{\n\treturn (evbuffer_add_buffer(buf, bufev->input));\n}\n\nint\nbufferevent_enable(struct bufferevent *bufev, short event)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tshort impl_events = event;\n\tint r = 0;\n\n\tbufferevent_incref_and_lock_(bufev);\n\tif (bufev_private->read_suspended)\n\t\timpl_events &= ~EV_READ;\n\tif (bufev_private->write_suspended)\n\t\timpl_events &= ~EV_WRITE;\n\n\tbufev->enabled |= event;\n\n\tif (impl_events && bufev->be_ops->enable(bufev, impl_events) < 0)\n\t\tr = -1;\n\tif (r)\n\t\tevent_debug((\"%s: cannot enable 0x%hx on %p\", __func__, event, (void *)bufev));\n\n\tbufferevent_decref_and_unlock_(bufev);\n\treturn r;\n}\n\nint\nbufferevent_set_timeouts(struct bufferevent *bufev,\n\t\t\t const struct timeval *tv_read,\n\t\t\t const struct timeval *tv_write)\n{\n\tint r = 0;\n\tBEV_LOCK(bufev);\n\tif (tv_read) {\n\t\tbufev->timeout_read = *tv_read;\n\t} else {\n\t\tevutil_timerclear(&bufev->timeout_read);\n\t}\n\tif (tv_write) {\n\t\tbufev->timeout_write = *tv_write;\n\t} else {\n\t\tevutil_timerclear(&bufev->timeout_write);\n\t}\n\n\tif (bufev->be_ops->adj_timeouts)\n\t\tr = bufev->be_ops->adj_timeouts(bufev);\n\tBEV_UNLOCK(bufev);\n\n\treturn r;\n}\n\n\n/* Obsolete; use bufferevent_set_timeouts */\nvoid\nbufferevent_settimeout(struct bufferevent *bufev,\n\t\t       int timeout_read, int timeout_write)\n{\n\tstruct timeval tv_read, tv_write;\n\tstruct timeval *ptv_read = NULL, *ptv_write = NULL;\n\n\tmemset(&tv_read, 0, sizeof(tv_read));\n\tmemset(&tv_write, 0, sizeof(tv_write));\n\n\tif (timeout_read) {\n\t\ttv_read.tv_sec = timeout_read;\n\t\tptv_read = &tv_read;\n\t}\n\tif (timeout_write) {\n\t\ttv_write.tv_sec = timeout_write;\n\t\tptv_write = &tv_write;\n\t}\n\n\tbufferevent_set_timeouts(bufev, ptv_read, ptv_write);\n}\n\n\nint\nbufferevent_disable_hard_(struct bufferevent *bufev, short event)\n{\n\tint r = 0;\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\n\tBEV_LOCK(bufev);\n\tbufev->enabled &= ~event;\n\n\tbufev_private->connecting = 0;\n\tif (bufev->be_ops->disable(bufev, event) < 0)\n\t\tr = -1;\n\n\tBEV_UNLOCK(bufev);\n\treturn r;\n}\n\nint\nbufferevent_disable(struct bufferevent *bufev, short event)\n{\n\tint r = 0;\n\n\tBEV_LOCK(bufev);\n\tbufev->enabled &= ~event;\n\n\tif (bufev->be_ops->disable(bufev, event) < 0)\n\t\tr = -1;\n\tif (r)\n\t\tevent_debug((\"%s: cannot disable 0x%hx on %p\", __func__, event, (void *)bufev));\n\n\tBEV_UNLOCK(bufev);\n\treturn r;\n}\n\n/*\n * Sets the water marks\n */\n\nvoid\nbufferevent_setwatermark(struct bufferevent *bufev, short events,\n    size_t lowmark, size_t highmark)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\n\tBEV_LOCK(bufev);\n\tif (events & EV_WRITE) {\n\t\tbufev->wm_write.low = lowmark;\n\t\tbufev->wm_write.high = highmark;\n\t}\n\n\tif (events & EV_READ) {\n\t\tbufev->wm_read.low = lowmark;\n\t\tbufev->wm_read.high = highmark;\n\n\t\tif (highmark) {\n\t\t\t/* There is now a new high-water mark for read.\n\t\t\t   enable the callback if needed, and see if we should\n\t\t\t   suspend/bufferevent_wm_unsuspend. */\n\n\t\t\tif (bufev_private->read_watermarks_cb == NULL) {\n\t\t\t\tbufev_private->read_watermarks_cb =\n\t\t\t\t    evbuffer_add_cb(bufev->input,\n\t\t\t\t\t\t    bufferevent_inbuf_wm_cb,\n\t\t\t\t\t\t    bufev);\n\t\t\t}\n\t\t\tevbuffer_cb_set_flags(bufev->input,\n\t\t\t\t      bufev_private->read_watermarks_cb,\n\t\t\t\t      EVBUFFER_CB_ENABLED|EVBUFFER_CB_NODEFER);\n\n\t\t\tif (evbuffer_get_length(bufev->input) >= highmark)\n\t\t\t\tbufferevent_wm_suspend_read(bufev);\n\t\t\telse if (evbuffer_get_length(bufev->input) < highmark)\n\t\t\t\tbufferevent_wm_unsuspend_read(bufev);\n\t\t} else {\n\t\t\t/* There is now no high-water mark for read. */\n\t\t\tif (bufev_private->read_watermarks_cb)\n\t\t\t\tevbuffer_cb_clear_flags(bufev->input,\n\t\t\t\t    bufev_private->read_watermarks_cb,\n\t\t\t\t    EVBUFFER_CB_ENABLED);\n\t\t\tbufferevent_wm_unsuspend_read(bufev);\n\t\t}\n\t}\n\tBEV_UNLOCK(bufev);\n}\n\nint\nbufferevent_getwatermark(struct bufferevent *bufev, short events,\n    size_t *lowmark, size_t *highmark)\n{\n\tif (events == EV_WRITE) {\n\t\tBEV_LOCK(bufev);\n\t\tif (lowmark)\n\t\t\t*lowmark = bufev->wm_write.low;\n\t\tif (highmark)\n\t\t\t*highmark = bufev->wm_write.high;\n\t\tBEV_UNLOCK(bufev);\n\t\treturn 0;\n\t}\n\n\tif (events == EV_READ) {\n\t\tBEV_LOCK(bufev);\n\t\tif (lowmark)\n\t\t\t*lowmark = bufev->wm_read.low;\n\t\tif (highmark)\n\t\t\t*highmark = bufev->wm_read.high;\n\t\tBEV_UNLOCK(bufev);\n\t\treturn 0;\n\t}\n\treturn -1;\n}\n\nint\nbufferevent_flush(struct bufferevent *bufev,\n    short iotype,\n    enum bufferevent_flush_mode mode)\n{\n\tint r = -1;\n\tBEV_LOCK(bufev);\n\tif (bufev->be_ops->flush)\n\t\tr = bufev->be_ops->flush(bufev, iotype, mode);\n\tBEV_UNLOCK(bufev);\n\treturn r;\n}\n\nvoid\nbufferevent_incref_and_lock_(struct bufferevent *bufev)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tBEV_LOCK(bufev);\n\t++bufev_private->refcnt;\n}\n\n#if 0\nstatic void\nbufferevent_transfer_lock_ownership_(struct bufferevent *donor,\n    struct bufferevent *recipient)\n{\n\tstruct bufferevent_private *d = BEV_UPCAST(donor);\n\tstruct bufferevent_private *r = BEV_UPCAST(recipient);\n\tif (d->lock != r->lock)\n\t\treturn;\n\tif (r->own_lock)\n\t\treturn;\n\tif (d->own_lock) {\n\t\td->own_lock = 0;\n\t\tr->own_lock = 1;\n\t}\n}\n#endif\n\nint\nbufferevent_decref_and_unlock_(struct bufferevent *bufev)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tint n_cbs = 0;\n#define MAX_CBS 16\n\tstruct event_callback *cbs[MAX_CBS];\n\n\tEVUTIL_ASSERT(bufev_private->refcnt > 0);\n\n\tif (--bufev_private->refcnt) {\n\t\tBEV_UNLOCK(bufev);\n\t\treturn 0;\n\t}\n\n\tif (bufev->be_ops->unlink)\n\t\tbufev->be_ops->unlink(bufev);\n\n\t/* Okay, we're out of references. Let's finalize this once all the\n\t * callbacks are done running. */\n\tcbs[0] = &bufev->ev_read.ev_evcallback;\n\tcbs[1] = &bufev->ev_write.ev_evcallback;\n\tcbs[2] = &bufev_private->deferred;\n\tn_cbs = 3;\n\tif (bufev_private->rate_limiting) {\n\t\tstruct event *e = &bufev_private->rate_limiting->refill_bucket_event;\n\t\tif (event_initialized(e))\n\t\t\tcbs[n_cbs++] = &e->ev_evcallback;\n\t}\n\tn_cbs += evbuffer_get_callbacks_(bufev->input, cbs+n_cbs, MAX_CBS-n_cbs);\n\tn_cbs += evbuffer_get_callbacks_(bufev->output, cbs+n_cbs, MAX_CBS-n_cbs);\n\n\tevent_callback_finalize_many_(bufev->ev_base, n_cbs, cbs,\n\t    bufferevent_finalize_cb_);\n\n#undef MAX_CBS\n\tBEV_UNLOCK(bufev);\n\n\treturn 1;\n}\n\nstatic void\nbufferevent_finalize_cb_(struct event_callback *evcb, void *arg_)\n{\n\tstruct bufferevent *bufev = arg_;\n\tstruct bufferevent *underlying;\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\n\tBEV_LOCK(bufev);\n\tunderlying = bufferevent_get_underlying(bufev);\n\n\t/* Clean up the shared info */\n\tif (bufev->be_ops->destruct)\n\t\tbufev->be_ops->destruct(bufev);\n\n\t/* XXX what happens if refcnt for these buffers is > 1?\n\t * The buffers can share a lock with this bufferevent object,\n\t * but the lock might be destroyed below. */\n\t/* evbuffer will free the callbacks */\n\tevbuffer_free(bufev->input);\n\tevbuffer_free(bufev->output);\n\n\tif (bufev_private->rate_limiting) {\n\t\tif (bufev_private->rate_limiting->group)\n\t\t\tbufferevent_remove_from_rate_limit_group_internal_(bufev,0);\n\t\tmm_free(bufev_private->rate_limiting);\n\t\tbufev_private->rate_limiting = NULL;\n\t}\n\n\n\tBEV_UNLOCK(bufev);\n\n\tif (bufev_private->own_lock)\n\t\tEVTHREAD_FREE_LOCK(bufev_private->lock,\n\t\t    EVTHREAD_LOCKTYPE_RECURSIVE);\n\n\t/* Free the actual allocated memory. */\n\tmm_free(((char*)bufev) - bufev->be_ops->mem_offset);\n\n\t/* Release the reference to underlying now that we no longer need the\n\t * reference to it.  We wait this long mainly in case our lock is\n\t * shared with underlying.\n\t *\n\t * The 'destruct' function will also drop a reference to underlying\n\t * if BEV_OPT_CLOSE_ON_FREE is set.\n\t *\n\t * XXX Should we/can we just refcount evbuffer/bufferevent locks?\n\t * It would probably save us some headaches.\n\t */\n\tif (underlying)\n\t\tbufferevent_decref_(underlying);\n}\n\nint\nbufferevent_decref(struct bufferevent *bufev)\n{\n\tBEV_LOCK(bufev);\n\treturn bufferevent_decref_and_unlock_(bufev);\n}\n\nvoid\nbufferevent_free(struct bufferevent *bufev)\n{\n\tBEV_LOCK(bufev);\n\tbufferevent_setcb(bufev, NULL, NULL, NULL, NULL);\n\tbufferevent_cancel_all_(bufev);\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nvoid\nbufferevent_incref(struct bufferevent *bufev)\n{\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\n\t/* XXX: now that this function is public, we might want to\n\t * - return the count from this function\n\t * - create a new function to atomically grab the current refcount\n\t */\n\tBEV_LOCK(bufev);\n\t++bufev_private->refcnt;\n\tBEV_UNLOCK(bufev);\n}\n\nint\nbufferevent_enable_locking_(struct bufferevent *bufev, void *lock)\n{\n#ifdef EVENT__DISABLE_THREAD_SUPPORT\n\treturn -1;\n#else\n\tstruct bufferevent *underlying;\n\n\tif (BEV_UPCAST(bufev)->lock)\n\t\treturn -1;\n\tunderlying = bufferevent_get_underlying(bufev);\n\n\tif (!lock && underlying && BEV_UPCAST(underlying)->lock) {\n\t\tlock = BEV_UPCAST(underlying)->lock;\n\t\tBEV_UPCAST(bufev)->lock = lock;\n\t\tBEV_UPCAST(bufev)->own_lock = 0;\n\t} else if (!lock) {\n\t\tEVTHREAD_ALLOC_LOCK(lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\t\tif (!lock)\n\t\t\treturn -1;\n\t\tBEV_UPCAST(bufev)->lock = lock;\n\t\tBEV_UPCAST(bufev)->own_lock = 1;\n\t} else {\n\t\tBEV_UPCAST(bufev)->lock = lock;\n\t\tBEV_UPCAST(bufev)->own_lock = 0;\n\t}\n\tevbuffer_enable_locking(bufev->input, lock);\n\tevbuffer_enable_locking(bufev->output, lock);\n\n\tif (underlying && !BEV_UPCAST(underlying)->lock)\n\t\tbufferevent_enable_locking_(underlying, lock);\n\n\treturn 0;\n#endif\n}\n\nint\nbufferevent_setfd(struct bufferevent *bev, evutil_socket_t fd)\n{\n\tunion bufferevent_ctrl_data d;\n\tint res = -1;\n\td.fd = fd;\n\tBEV_LOCK(bev);\n\tif (bev->be_ops->ctrl)\n\t\tres = bev->be_ops->ctrl(bev, BEV_CTRL_SET_FD, &d);\n\tif (res)\n\t\tevent_debug((\"%s: cannot set fd for %p to \"EV_SOCK_FMT, __func__, (void *)bev, fd));\n\tBEV_UNLOCK(bev);\n\treturn res;\n}\n\nint\nbufferevent_replacefd(struct bufferevent *bev, evutil_socket_t fd)\n{\n\tunion bufferevent_ctrl_data d;\n\tint err = -1;\n\tevutil_socket_t old_fd = EVUTIL_INVALID_SOCKET;\n\n\tBEV_LOCK(bev);\n\tif (bev->be_ops->ctrl) {\n\t\terr = bev->be_ops->ctrl(bev, BEV_CTRL_GET_FD, &d);\n\t\tif (!err) {\n\t\t\told_fd = d.fd;\n\t\t\tif (old_fd != EVUTIL_INVALID_SOCKET) {\n\t\t\t\terr = evutil_closesocket(old_fd);\n\t\t\t}\n\t\t}\n\t\tif (!err) {\n\t\t\td.fd = fd;\n\t\t\terr = bev->be_ops->ctrl(bev, BEV_CTRL_SET_FD, &d);\n\t\t}\n\t}\n\tif (err)\n\t\tevent_debug((\"%s: cannot replace fd for %p from \"EV_SOCK_FMT\" to \"EV_SOCK_FMT, __func__, (void *)bev, old_fd, fd));\n\tBEV_UNLOCK(bev);\n\n\treturn err;\n}\n\nevutil_socket_t\nbufferevent_getfd(struct bufferevent *bev)\n{\n\tunion bufferevent_ctrl_data d;\n\tint res = -1;\n\td.fd = -1;\n\tBEV_LOCK(bev);\n\tif (bev->be_ops->ctrl)\n\t\tres = bev->be_ops->ctrl(bev, BEV_CTRL_GET_FD, &d);\n\tif (res)\n\t\tevent_debug((\"%s: cannot get fd for %p\", __func__, (void *)bev));\n\tBEV_UNLOCK(bev);\n\treturn (res<0) ? -1 : d.fd;\n}\n\nenum bufferevent_options\nbufferevent_get_options_(struct bufferevent *bev)\n{\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\tenum bufferevent_options options;\n\n\tBEV_LOCK(bev);\n\toptions = bev_p->options;\n\tBEV_UNLOCK(bev);\n\treturn options;\n}\n\n\nstatic void\nbufferevent_cancel_all_(struct bufferevent *bev)\n{\n\tunion bufferevent_ctrl_data d;\n\tmemset(&d, 0, sizeof(d));\n\tBEV_LOCK(bev);\n\tif (bev->be_ops->ctrl)\n\t\tbev->be_ops->ctrl(bev, BEV_CTRL_CANCEL_ALL, &d);\n\tBEV_UNLOCK(bev);\n}\n\nshort\nbufferevent_get_enabled(struct bufferevent *bufev)\n{\n\tshort r;\n\tBEV_LOCK(bufev);\n\tr = bufev->enabled;\n\tBEV_UNLOCK(bufev);\n\treturn r;\n}\n\nstruct bufferevent *\nbufferevent_get_underlying(struct bufferevent *bev)\n{\n\tunion bufferevent_ctrl_data d;\n\tint res = -1;\n\td.ptr = NULL;\n\tBEV_LOCK(bev);\n\tif (bev->be_ops->ctrl)\n\t\tres = bev->be_ops->ctrl(bev, BEV_CTRL_GET_UNDERLYING, &d);\n\tBEV_UNLOCK(bev);\n\treturn (res<0) ? NULL : d.ptr;\n}\n\nstatic void\nbufferevent_generic_read_timeout_cb(evutil_socket_t fd, short event, void *ctx)\n{\n\tstruct bufferevent *bev = ctx;\n\tbufferevent_incref_and_lock_(bev);\n\tbufferevent_disable(bev, EV_READ);\n\tbufferevent_run_eventcb_(bev, BEV_EVENT_TIMEOUT|BEV_EVENT_READING, 0);\n\tbufferevent_decref_and_unlock_(bev);\n}\nstatic void\nbufferevent_generic_write_timeout_cb(evutil_socket_t fd, short event, void *ctx)\n{\n\tstruct bufferevent *bev = ctx;\n\tbufferevent_incref_and_lock_(bev);\n\tbufferevent_disable(bev, EV_WRITE);\n\tbufferevent_run_eventcb_(bev, BEV_EVENT_TIMEOUT|BEV_EVENT_WRITING, 0);\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nvoid\nbufferevent_init_generic_timeout_cbs_(struct bufferevent *bev)\n{\n\tevent_assign(&bev->ev_read, bev->ev_base, -1, EV_FINALIZE,\n\t    bufferevent_generic_read_timeout_cb, bev);\n\tevent_assign(&bev->ev_write, bev->ev_base, -1, EV_FINALIZE,\n\t    bufferevent_generic_write_timeout_cb, bev);\n}\n\nint\nbufferevent_generic_adj_timeouts_(struct bufferevent *bev)\n{\n\tconst short enabled = bev->enabled;\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\tint r1=0, r2=0;\n\tif ((enabled & EV_READ) && !bev_p->read_suspended &&\n\t    evutil_timerisset(&bev->timeout_read))\n\t\tr1 = event_add(&bev->ev_read, &bev->timeout_read);\n\telse\n\t\tr1 = event_del(&bev->ev_read);\n\n\tif ((enabled & EV_WRITE) && !bev_p->write_suspended &&\n\t    evutil_timerisset(&bev->timeout_write) &&\n\t    evbuffer_get_length(bev->output))\n\t\tr2 = event_add(&bev->ev_write, &bev->timeout_write);\n\telse\n\t\tr2 = event_del(&bev->ev_write);\n\tif (r1 < 0 || r2 < 0)\n\t\treturn -1;\n\treturn 0;\n}\n\nint\nbufferevent_generic_adj_existing_timeouts_(struct bufferevent *bev)\n{\n\tint r = 0;\n\tif (event_pending(&bev->ev_read, EV_READ, NULL)) {\n\t\tif (evutil_timerisset(&bev->timeout_read)) {\n\t\t\t    if (bufferevent_add_event_(&bev->ev_read, &bev->timeout_read) < 0)\n\t\t\t\t    r = -1;\n\t\t} else {\n\t\t\tevent_remove_timer(&bev->ev_read);\n\t\t}\n\t}\n\tif (event_pending(&bev->ev_write, EV_WRITE, NULL)) {\n\t\tif (evutil_timerisset(&bev->timeout_write)) {\n\t\t\tif (bufferevent_add_event_(&bev->ev_write, &bev->timeout_write) < 0)\n\t\t\t\tr = -1;\n\t\t} else {\n\t\t\tevent_remove_timer(&bev->ev_write);\n\t\t}\n\t}\n\treturn r;\n}\n\nint\nbufferevent_add_event_(struct event *ev, const struct timeval *tv)\n{\n\tif (!evutil_timerisset(tv))\n\t\treturn event_add(ev, NULL);\n\telse\n\t\treturn event_add(ev, tv);\n}\n\n/* For use by user programs only; internally, we should be calling\n   either bufferevent_incref_and_lock_(), or BEV_LOCK. */\nvoid\nbufferevent_lock(struct bufferevent *bev)\n{\n\tbufferevent_incref_and_lock_(bev);\n}\n\nvoid\nbufferevent_unlock(struct bufferevent *bev)\n{\n\tbufferevent_decref_and_unlock_(bev);\n}\n"
        },
        {
          "name": "bufferevent_async.c",
          "type": "blob",
          "size": 18.2373046875,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <winerror.h>\n#include <ws2tcpip.h>\n#endif\n\n#include <sys/queue.h>\n\n#include \"event2/util.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/event.h\"\n#include \"event2/util.h\"\n#include \"event-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"util-internal.h\"\n#include \"iocp-internal.h\"\n\n#ifndef SO_UPDATE_CONNECT_CONTEXT\n/* Mingw is sometimes missing this */\n#define SO_UPDATE_CONNECT_CONTEXT 0x7010\n#endif\n\n/* prototypes */\nstatic int be_async_enable(struct bufferevent *, short);\nstatic int be_async_disable(struct bufferevent *, short);\nstatic void be_async_destruct(struct bufferevent *);\nstatic int be_async_flush(struct bufferevent *, short, enum bufferevent_flush_mode);\nstatic int be_async_ctrl(struct bufferevent *, enum bufferevent_ctrl_op, union bufferevent_ctrl_data *);\n\nstruct bufferevent_async {\n\tstruct bufferevent_private bev;\n\tstruct event_overlapped connect_overlapped;\n\tstruct event_overlapped read_overlapped;\n\tstruct event_overlapped write_overlapped;\n\tsize_t read_in_progress;\n\tsize_t write_in_progress;\n\tunsigned ok : 1;\n\tunsigned read_added : 1;\n\tunsigned write_added : 1;\n};\n\nconst struct bufferevent_ops bufferevent_ops_async = {\n\t\"socket_async\",\n\tevutil_offsetof(struct bufferevent_async, bev.bev),\n\tbe_async_enable,\n\tbe_async_disable,\n\tNULL, /* Unlink */\n\tbe_async_destruct,\n\tbufferevent_generic_adj_timeouts_,\n\tbe_async_flush,\n\tbe_async_ctrl,\n};\n\nstatic inline void\nbe_async_run_eventcb(struct bufferevent *bev, short what, int options)\n{ bufferevent_run_eventcb_(bev, what, options|BEV_TRIG_DEFER_CALLBACKS); }\n\nstatic inline void\nbe_async_trigger_nolock(struct bufferevent *bev, short what, int options)\n{ bufferevent_trigger_nolock_(bev, what, options|BEV_TRIG_DEFER_CALLBACKS); }\n\nstatic inline int\nfatal_error(int err)\n{\n\tswitch (err) {\n\t\t/* We may have already associated this fd with a port.\n\t\t * Let's hope it's this port, and that the error code\n\t\t * for doing this neer changes. */\n\t\tcase ERROR_INVALID_PARAMETER:\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic inline struct bufferevent_async *\nupcast(struct bufferevent *bev)\n{\n\tstruct bufferevent_async *bev_a;\n\tif (!BEV_IS_ASYNC(bev))\n\t\treturn NULL;\n\tbev_a = EVUTIL_UPCAST(bev, struct bufferevent_async, bev.bev);\n\treturn bev_a;\n}\n\nstatic inline struct bufferevent_async *\nupcast_connect(struct event_overlapped *eo)\n{\n\tstruct bufferevent_async *bev_a;\n\tbev_a = EVUTIL_UPCAST(eo, struct bufferevent_async, connect_overlapped);\n\tEVUTIL_ASSERT(BEV_IS_ASYNC(&bev_a->bev.bev));\n\treturn bev_a;\n}\n\nstatic inline struct bufferevent_async *\nupcast_read(struct event_overlapped *eo)\n{\n\tstruct bufferevent_async *bev_a;\n\tbev_a = EVUTIL_UPCAST(eo, struct bufferevent_async, read_overlapped);\n\tEVUTIL_ASSERT(BEV_IS_ASYNC(&bev_a->bev.bev));\n\treturn bev_a;\n}\n\nstatic inline struct bufferevent_async *\nupcast_write(struct event_overlapped *eo)\n{\n\tstruct bufferevent_async *bev_a;\n\tbev_a = EVUTIL_UPCAST(eo, struct bufferevent_async, write_overlapped);\n\tEVUTIL_ASSERT(BEV_IS_ASYNC(&bev_a->bev.bev));\n\treturn bev_a;\n}\n\nstatic void\nbev_async_del_write(struct bufferevent_async *beva)\n{\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\tif (beva->write_added) {\n\t\tbeva->write_added = 0;\n\t\tevent_base_del_virtual_(bev->ev_base);\n\t}\n}\n\nstatic void\nbev_async_del_read(struct bufferevent_async *beva)\n{\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\tif (beva->read_added) {\n\t\tbeva->read_added = 0;\n\t\tevent_base_del_virtual_(bev->ev_base);\n\t}\n}\n\nstatic void\nbev_async_add_write(struct bufferevent_async *beva)\n{\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\tif (!beva->write_added) {\n\t\tbeva->write_added = 1;\n\t\tevent_base_add_virtual_(bev->ev_base);\n\t}\n}\n\nstatic void\nbev_async_add_read(struct bufferevent_async *beva)\n{\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\tif (!beva->read_added) {\n\t\tbeva->read_added = 1;\n\t\tevent_base_add_virtual_(bev->ev_base);\n\t}\n}\n\nstatic void\nbev_async_consider_writing(struct bufferevent_async *beva)\n{\n\tsize_t at_most;\n\tint limit;\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\t/* Don't write if there's a write in progress, or we do not\n\t * want to write, or when there's nothing left to write. */\n\tif (beva->write_in_progress || beva->bev.connecting)\n\t\treturn;\n\tif (!beva->ok || !(bev->enabled&EV_WRITE) ||\n\t    !evbuffer_get_length(bev->output)) {\n\t\tbev_async_del_write(beva);\n\t\treturn;\n\t}\n\n\tat_most = evbuffer_get_length(bev->output);\n\n\t/* This is safe so long as bufferevent_get_write_max never returns\n\t * more than INT_MAX.  That's true for now. XXXX */\n\tlimit = (int)bufferevent_get_write_max_(&beva->bev);\n\tif (at_most >= (size_t)limit && limit >= 0)\n\t\tat_most = limit;\n\n\tif (beva->bev.write_suspended) {\n\t\tbev_async_del_write(beva);\n\t\treturn;\n\t}\n\n\t/*  XXXX doesn't respect low-water mark very well. */\n\tbufferevent_incref_(bev);\n\tif (evbuffer_launch_write_(bev->output, at_most,\n\t    &beva->write_overlapped)) {\n\t\tbufferevent_decref_(bev);\n\t\tbeva->ok = 0;\n\t\tbe_async_run_eventcb(bev, BEV_EVENT_ERROR, 0);\n\t} else {\n\t\tbeva->write_in_progress = at_most;\n\t\tbufferevent_decrement_write_buckets_(&beva->bev, at_most);\n\t\tbev_async_add_write(beva);\n\t}\n}\n\nstatic void\nbev_async_consider_reading(struct bufferevent_async *beva)\n{\n\tsize_t cur_size;\n\tsize_t read_high;\n\tsize_t at_most;\n\tint limit;\n\tstruct bufferevent *bev = &beva->bev.bev;\n\n\t/* Don't read if there is a read in progress, or we do not\n\t * want to read. */\n\tif (beva->read_in_progress || beva->bev.connecting)\n\t\treturn;\n\tif (!beva->ok || !(bev->enabled&EV_READ)) {\n\t\tbev_async_del_read(beva);\n\t\treturn;\n\t}\n\n\t/* Don't read if we're full */\n\tcur_size = evbuffer_get_length(bev->input);\n\tread_high = bev->wm_read.high;\n\tif (read_high) {\n\t\tif (cur_size >= read_high) {\n\t\t\tbev_async_del_read(beva);\n\t\t\treturn;\n\t\t}\n\t\tat_most = read_high - cur_size;\n\t} else {\n\t\tat_most = 16384; /* FIXME totally magic. */\n\t}\n\n\t/* XXXX This over-commits. */\n\t/* XXXX see also not above on cast on bufferevent_get_write_max_() */\n\tlimit = (int)bufferevent_get_read_max_(&beva->bev);\n\tif (at_most >= (size_t)limit && limit >= 0)\n\t\tat_most = limit;\n\n\tif (beva->bev.read_suspended) {\n\t\tbev_async_del_read(beva);\n\t\treturn;\n\t}\n\n\tbufferevent_incref_(bev);\n\tif (evbuffer_launch_read_(bev->input, at_most, &beva->read_overlapped)) {\n\t\tbeva->ok = 0;\n\t\tbe_async_run_eventcb(bev, BEV_EVENT_ERROR, 0);\n\t\tbufferevent_decref_(bev);\n\t} else {\n\t\tbeva->read_in_progress = at_most;\n\t\tbufferevent_decrement_read_buckets_(&beva->bev, at_most);\n\t\tbev_async_add_read(beva);\n\t}\n\n\treturn;\n}\n\nstatic void\nbe_async_outbuf_callback(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo,\n    void *arg)\n{\n\tstruct bufferevent *bev = arg;\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\n\t/* If we added data to the outbuf and were not writing before,\n\t * we may want to write now. */\n\n\tbufferevent_incref_and_lock_(bev);\n\n\tif (cbinfo->n_added)\n\t\tbev_async_consider_writing(bev_async);\n\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nstatic void\nbe_async_inbuf_callback(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo,\n    void *arg)\n{\n\tstruct bufferevent *bev = arg;\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\n\t/* If we drained data from the inbuf and were not reading before,\n\t * we may want to read now */\n\n\tbufferevent_incref_and_lock_(bev);\n\n\tif (cbinfo->n_deleted)\n\t\tbev_async_consider_reading(bev_async);\n\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nstatic int\nbe_async_enable(struct bufferevent *buf, short what)\n{\n\tstruct bufferevent_async *bev_async = upcast(buf);\n\n\tif (!bev_async->ok)\n\t\treturn -1;\n\n\tif (bev_async->bev.connecting) {\n\t\t/* Don't launch anything during connection attempts. */\n\t\treturn 0;\n\t}\n\n\tif (what & EV_READ)\n\t\tBEV_RESET_GENERIC_READ_TIMEOUT(buf);\n\tif (what & EV_WRITE)\n\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(buf);\n\n\t/* If we newly enable reading or writing, and we aren't reading or\n\t   writing already, consider launching a new read or write. */\n\n\tif (what & EV_READ)\n\t\tbev_async_consider_reading(bev_async);\n\tif (what & EV_WRITE)\n\t\tbev_async_consider_writing(bev_async);\n\treturn 0;\n}\n\nstatic int\nbe_async_disable(struct bufferevent *bev, short what)\n{\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\t/* XXXX If we disable reading or writing, we may want to consider\n\t * canceling any in-progress read or write operation, though it might\n\t * not work. */\n\n\tif (what & EV_READ) {\n\t\tBEV_DEL_GENERIC_READ_TIMEOUT(bev);\n\t\tbev_async_del_read(bev_async);\n\t}\n\tif (what & EV_WRITE) {\n\t\tBEV_DEL_GENERIC_WRITE_TIMEOUT(bev);\n\t\tbev_async_del_write(bev_async);\n\t}\n\n\treturn 0;\n}\n\nstatic void\nbe_async_destruct(struct bufferevent *bev)\n{\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\tevutil_socket_t fd;\n\n\tEVUTIL_ASSERT(!upcast(bev)->write_in_progress &&\n\t\t\t!upcast(bev)->read_in_progress);\n\n\tbev_async_del_read(bev_async);\n\tbev_async_del_write(bev_async);\n\n\tfd = evbuffer_overlapped_get_fd_(bev->input);\n\tif (fd != (evutil_socket_t)EVUTIL_INVALID_SOCKET &&\n\t\t(bev_p->options & BEV_OPT_CLOSE_ON_FREE)) {\n\t\tevutil_closesocket(fd);\n\t\tevbuffer_overlapped_set_fd_(bev->input, EVUTIL_INVALID_SOCKET);\n\t}\n}\n\n/* GetQueuedCompletionStatus doesn't reliably yield WSA error codes, so\n * we use WSAGetOverlappedResult to translate. */\nstatic void\nbev_async_set_wsa_error(struct bufferevent *bev, struct event_overlapped *eo)\n{\n\tDWORD bytes, flags;\n\tevutil_socket_t fd;\n\n\tfd = evbuffer_overlapped_get_fd_(bev->input);\n\tWSAGetOverlappedResult(fd, &eo->overlapped, &bytes, FALSE, &flags);\n}\n\nstatic int\nbe_async_flush(struct bufferevent *bev, short what,\n    enum bufferevent_flush_mode mode)\n{\n\treturn 0;\n}\n\nstatic void\nconnect_complete(struct event_overlapped *eo, ev_uintptr_t key,\n    ev_ssize_t nbytes, int ok)\n{\n\tstruct bufferevent_async *bev_a = upcast_connect(eo);\n\tstruct bufferevent *bev = &bev_a->bev.bev;\n\tevutil_socket_t sock;\n\n\tBEV_LOCK(bev);\n\n\tEVUTIL_ASSERT(bev_a->bev.connecting);\n\tbev_a->bev.connecting = 0;\n\tsock = evbuffer_overlapped_get_fd_(bev_a->bev.bev.input);\n\t/* XXXX Handle error? */\n\tsetsockopt(sock, SOL_SOCKET, SO_UPDATE_CONNECT_CONTEXT, NULL, 0);\n\n\tif (ok)\n\t\tbufferevent_async_set_connected_(bev);\n\telse\n\t\tbev_async_set_wsa_error(bev, eo);\n\n\tbe_async_run_eventcb(bev, ok ? BEV_EVENT_CONNECTED : BEV_EVENT_ERROR, 0);\n\n\tevent_base_del_virtual_(bev->ev_base);\n\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nstatic void\nread_complete(struct event_overlapped *eo, ev_uintptr_t key,\n    ev_ssize_t nbytes, int ok)\n{\n\tstruct bufferevent_async *bev_a = upcast_read(eo);\n\tstruct bufferevent *bev = &bev_a->bev.bev;\n\tshort what = BEV_EVENT_READING;\n\tev_ssize_t amount_unread;\n\tBEV_LOCK(bev);\n\tEVUTIL_ASSERT(bev_a->read_in_progress);\n\n\tamount_unread = bev_a->read_in_progress - nbytes;\n\tevbuffer_commit_read_(bev->input, nbytes);\n\tbev_a->read_in_progress = 0;\n\tif (amount_unread)\n\t\tbufferevent_decrement_read_buckets_(&bev_a->bev, -amount_unread);\n\n\tif (!ok)\n\t\tbev_async_set_wsa_error(bev, eo);\n\n\tif (bev_a->ok) {\n\t\tif (ok && nbytes) {\n\t\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bev);\n\t\t\tbe_async_trigger_nolock(bev, EV_READ, 0);\n\t\t\tbev_async_consider_reading(bev_a);\n\t\t} else if (!ok) {\n\t\t\twhat |= BEV_EVENT_ERROR;\n\t\t\tbev_a->ok = 0;\n\t\t\tbe_async_run_eventcb(bev, what, 0);\n\t\t} else if (!nbytes) {\n\t\t\twhat |= BEV_EVENT_EOF;\n\t\t\tbev_a->ok = 0;\n\t\t\tbe_async_run_eventcb(bev, what, 0);\n\t\t}\n\t}\n\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nstatic void\nwrite_complete(struct event_overlapped *eo, ev_uintptr_t key,\n    ev_ssize_t nbytes, int ok)\n{\n\tstruct bufferevent_async *bev_a = upcast_write(eo);\n\tstruct bufferevent *bev = &bev_a->bev.bev;\n\tshort what = BEV_EVENT_WRITING;\n\tev_ssize_t amount_unwritten;\n\n\tBEV_LOCK(bev);\n\tEVUTIL_ASSERT(bev_a->write_in_progress);\n\n\tamount_unwritten = bev_a->write_in_progress - nbytes;\n\tevbuffer_commit_write_(bev->output, nbytes);\n\tbev_a->write_in_progress = 0;\n\n\tif (amount_unwritten)\n\t\tbufferevent_decrement_write_buckets_(&bev_a->bev,\n\t\t                                     -amount_unwritten);\n\n\n\tif (!ok)\n\t\tbev_async_set_wsa_error(bev, eo);\n\n\tif (bev_a->ok) {\n\t\tif (ok && nbytes) {\n\t\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bev);\n\t\t\tbe_async_trigger_nolock(bev, EV_WRITE, 0);\n\t\t\tbev_async_consider_writing(bev_a);\n\t\t} else if (!ok) {\n\t\t\twhat |= BEV_EVENT_ERROR;\n\t\t\tbev_a->ok = 0;\n\t\t\tbe_async_run_eventcb(bev, what, 0);\n\t\t} else if (!nbytes) {\n\t\t\twhat |= BEV_EVENT_EOF;\n\t\t\tbev_a->ok = 0;\n\t\t\tbe_async_run_eventcb(bev, what, 0);\n\t\t}\n\t}\n\n\tbufferevent_decref_and_unlock_(bev);\n}\n\nstruct bufferevent *\nbufferevent_async_new_(struct event_base *base,\n    evutil_socket_t fd, int options)\n{\n\tstruct bufferevent_async *bev_a;\n\tstruct bufferevent *bev;\n\tstruct event_iocp_port *iocp;\n\n\toptions |= BEV_OPT_THREADSAFE;\n\n\tif (!(iocp = event_base_get_iocp_(base)))\n\t\treturn NULL;\n\n\tif (fd >= 0 && event_iocp_port_associate_(iocp, fd, 1)<0) {\n\t\tif (fatal_error(GetLastError()))\n\t\t\treturn NULL;\n\t}\n\n\tif (!(bev_a = mm_calloc(1, sizeof(struct bufferevent_async))))\n\t\treturn NULL;\n\n\tbev = &bev_a->bev.bev;\n\tif (!(bev->input = evbuffer_overlapped_new_(fd))) {\n\t\tmm_free(bev_a);\n\t\treturn NULL;\n\t}\n\tif (!(bev->output = evbuffer_overlapped_new_(fd))) {\n\t\tevbuffer_free(bev->input);\n\t\tmm_free(bev_a);\n\t\treturn NULL;\n\t}\n\n\tif (bufferevent_init_common_(&bev_a->bev, base, &bufferevent_ops_async,\n\t\toptions)<0)\n\t\tgoto err;\n\n\tevbuffer_add_cb(bev->input, be_async_inbuf_callback, bev);\n\tevbuffer_add_cb(bev->output, be_async_outbuf_callback, bev);\n\n\tevent_overlapped_init_(&bev_a->connect_overlapped, connect_complete);\n\tevent_overlapped_init_(&bev_a->read_overlapped, read_complete);\n\tevent_overlapped_init_(&bev_a->write_overlapped, write_complete);\n\n\tbufferevent_init_generic_timeout_cbs_(bev);\n\n\tbev_a->ok = fd >= 0;\n\n\treturn bev;\nerr:\n\tbufferevent_free(&bev_a->bev.bev);\n\treturn NULL;\n}\n\nvoid\nbufferevent_async_set_connected_(struct bufferevent *bev)\n{\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\tbev_async->ok = 1;\n\t/* Now's a good time to consider reading/writing */\n\tbe_async_enable(bev, bev->enabled);\n}\n\nint\nbufferevent_async_can_connect_(struct bufferevent *bev)\n{\n\tconst struct win32_extension_fns *ext =\n\t    event_get_win32_extension_fns_();\n\n\tif (BEV_IS_ASYNC(bev) &&\n\t    event_base_get_iocp_(bev->ev_base) &&\n\t    ext && ext->ConnectEx)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nint\nbufferevent_async_connect_(struct bufferevent *bev, evutil_socket_t fd,\n\tconst struct sockaddr *sa, int socklen)\n{\n\tBOOL rc;\n\tstruct bufferevent_async *bev_async = upcast(bev);\n\tstruct sockaddr_storage ss;\n\tconst struct win32_extension_fns *ext =\n\t    event_get_win32_extension_fns_();\n\n\tEVUTIL_ASSERT(ext && ext->ConnectEx && fd >= 0 && sa != NULL);\n\n\t/* ConnectEx() requires that the socket be bound to an address\n\t * with bind() before using, otherwise it will fail. We attempt\n\t * to issue a bind() here, taking into account that the error\n\t * code is set to WSAEINVAL when the socket is already bound. */\n\tmemset(&ss, 0, sizeof(ss));\n\tif (sa->sa_family == AF_INET) {\n\t\tstruct sockaddr_in *sin = (struct sockaddr_in *)&ss;\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_addr.s_addr = INADDR_ANY;\n\t} else if (sa->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)&ss;\n\t\tsin6->sin6_family = AF_INET6;\n\t\tsin6->sin6_addr = in6addr_any;\n\t} else {\n\t\t/* Well, the user will have to bind() */\n\t\treturn -1;\n\t}\n\tif (bind(fd, (struct sockaddr *)&ss, sizeof(ss)) < 0 &&\n\t    WSAGetLastError() != WSAEINVAL)\n\t\treturn -1;\n\n\tevent_base_add_virtual_(bev->ev_base);\n\tbufferevent_incref_(bev);\n\trc = ext->ConnectEx(fd, sa, socklen, NULL, 0, NULL,\n\t\t\t    &bev_async->connect_overlapped.overlapped);\n\tif (rc || WSAGetLastError() == ERROR_IO_PENDING)\n\t\treturn 0;\n\n\tevent_base_del_virtual_(bev->ev_base);\n\tbufferevent_decref_(bev);\n\n\treturn -1;\n}\n\nstatic int\nbe_async_ctrl(struct bufferevent *bev, enum bufferevent_ctrl_op op,\n    union bufferevent_ctrl_data *data)\n{\n\tswitch (op) {\n\tcase BEV_CTRL_GET_FD:\n\t\tdata->fd = evbuffer_overlapped_get_fd_(bev->input);\n\t\treturn 0;\n\tcase BEV_CTRL_SET_FD: {\n\t\tstruct bufferevent_async *bev_a = upcast(bev);\n\t\tstruct event_iocp_port *iocp;\n\n\t\tif (data->fd == evbuffer_overlapped_get_fd_(bev->input))\n\t\t\treturn 0;\n\t\tif (!(iocp = event_base_get_iocp_(bev->ev_base)))\n\t\t\treturn -1;\n\t\tif (event_iocp_port_associate_(iocp, data->fd, 1) < 0) {\n\t\t\tif (fatal_error(GetLastError()))\n\t\t\t\treturn -1;\n\t\t}\n\t\tevbuffer_overlapped_set_fd_(bev->input, data->fd);\n\t\tevbuffer_overlapped_set_fd_(bev->output, data->fd);\n\t\tbev_a->ok = data->fd >= 0;\n\t\treturn 0;\n\t}\n\tcase BEV_CTRL_CANCEL_ALL: {\n\t\tstruct bufferevent_async *bev_a = upcast(bev);\n\t\tevutil_socket_t fd = evbuffer_overlapped_get_fd_(bev->input);\n\t\tif (fd != (evutil_socket_t)EVUTIL_INVALID_SOCKET &&\n\t\t    (bev_a->bev.options & BEV_OPT_CLOSE_ON_FREE)) {\n\t\t\tclosesocket(fd);\n\t\t\tevbuffer_overlapped_set_fd_(bev->input, EVUTIL_INVALID_SOCKET);\n\t\t}\n\t\tbev_a->ok = 0;\n\t\treturn 0;\n\t}\n\tcase BEV_CTRL_GET_UNDERLYING:\n\tdefault:\n\t\treturn -1;\n\t}\n}\n\n\n"
        },
        {
          "name": "bufferevent_filter.c",
          "type": "blob",
          "size": 17.521484375,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n * Copyright (c) 2002-2006 Niels Provos <provos@citi.umich.edu>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#include \"event2/event-config.h\"\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/event.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"util-internal.h\"\n\n/* prototypes */\nstatic int be_filter_enable(struct bufferevent *, short);\nstatic int be_filter_disable(struct bufferevent *, short);\nstatic void be_filter_unlink(struct bufferevent *);\nstatic void be_filter_destruct(struct bufferevent *);\n\nstatic void be_filter_readcb(struct bufferevent *, void *);\nstatic void be_filter_writecb(struct bufferevent *, void *);\nstatic void be_filter_eventcb(struct bufferevent *, short, void *);\nstatic int be_filter_flush(struct bufferevent *bufev,\n    short iotype, enum bufferevent_flush_mode mode);\nstatic int be_filter_ctrl(struct bufferevent *, enum bufferevent_ctrl_op, union bufferevent_ctrl_data *);\n\nstatic void bufferevent_filtered_inbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo, void *arg);\n\nstatic void bufferevent_filtered_outbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *info, void *arg);\n\nstruct bufferevent_filtered {\n\tstruct bufferevent_private bev;\n\n\t/** The bufferevent that we read/write filtered data from/to. */\n\tstruct bufferevent *underlying;\n\t/** A callback on our inbuf to notice somebody removes data */\n\tstruct evbuffer_cb_entry *inbuf_cb;\n\t/** A callback on our outbuf to notice when somebody adds data */\n\tstruct evbuffer_cb_entry *outbuf_cb;\n\t/** True iff we have received an EOF callback from the underlying\n\t * bufferevent. */\n\tunsigned got_eof;\n\n\t/** Function to free context when we're done. */\n\tvoid (*free_context)(void *);\n\t/** Input filter */\n\tbufferevent_filter_cb process_in;\n\t/** Output filter */\n\tbufferevent_filter_cb process_out;\n\t/** User-supplied argument to the filters. */\n\tvoid *context;\n};\n\nconst struct bufferevent_ops bufferevent_ops_filter = {\n\t\"filter\",\n\tevutil_offsetof(struct bufferevent_filtered, bev.bev),\n\tbe_filter_enable,\n\tbe_filter_disable,\n\tbe_filter_unlink,\n\tbe_filter_destruct,\n\tbufferevent_generic_adj_timeouts_,\n\tbe_filter_flush,\n\tbe_filter_ctrl,\n};\n\n/* Given a bufferevent that's really the bev filter of a bufferevent_filtered,\n * return that bufferevent_filtered. Returns NULL otherwise.*/\nstatic inline struct bufferevent_filtered *\nupcast(struct bufferevent *bev)\n{\n\tstruct bufferevent_filtered *bev_f;\n\tEVUTIL_ASSERT(BEV_IS_FILTER(bev));\n\tbev_f = (void*)( ((char*)bev) -\n\t\t\t evutil_offsetof(struct bufferevent_filtered, bev.bev));\n\tEVUTIL_ASSERT(BEV_IS_FILTER(&bev_f->bev.bev));\n\treturn bev_f;\n}\n\n#define downcast(bev_f) (&(bev_f)->bev.bev)\n\n/** Return 1 iff bevf's underlying bufferevent's output buffer is at or\n * over its high watermark such that we should not write to it in a given\n * flush mode. */\nstatic int\nbe_underlying_writebuf_full(struct bufferevent_filtered *bevf,\n    enum bufferevent_flush_mode state)\n{\n\tstruct bufferevent *u = bevf->underlying;\n\treturn state == BEV_NORMAL &&\n\t    u->wm_write.high &&\n\t    evbuffer_get_length(u->output) >= u->wm_write.high;\n}\n\n/** Return 1 if our input buffer is at or over its high watermark such that we\n * should not write to it in a given flush mode. */\nstatic int\nbe_readbuf_full(struct bufferevent_filtered *bevf,\n    enum bufferevent_flush_mode state)\n{\n\tstruct bufferevent *bufev = downcast(bevf);\n\treturn state == BEV_NORMAL &&\n\t    bufev->wm_read.high &&\n\t    evbuffer_get_length(bufev->input) >= bufev->wm_read.high;\n}\n\n\n/* Filter to use when we're created with a NULL filter. */\nstatic enum bufferevent_filter_result\nbe_null_filter(struct evbuffer *src, struct evbuffer *dst, ev_ssize_t lim,\n\t       enum bufferevent_flush_mode state, void *ctx)\n{\n\t(void)state;\n\tif (evbuffer_remove_buffer(src, dst, lim) >= 0)\n\t\treturn BEV_OK;\n\telse\n\t\treturn BEV_ERROR;\n}\n\nstruct bufferevent *\nbufferevent_filter_new(struct bufferevent *underlying,\n\t\t       bufferevent_filter_cb input_filter,\n\t\t       bufferevent_filter_cb output_filter,\n\t\t       int options,\n\t\t       void (*free_context)(void *),\n\t\t       void *ctx)\n{\n\tstruct bufferevent_filtered *bufev_f;\n\tint tmp_options = options & ~BEV_OPT_THREADSAFE;\n\n\tif (!underlying)\n\t\treturn NULL;\n\n\tif (!input_filter)\n\t\tinput_filter = be_null_filter;\n\tif (!output_filter)\n\t\toutput_filter = be_null_filter;\n\n\tbufev_f = mm_calloc(1, sizeof(struct bufferevent_filtered));\n\tif (!bufev_f)\n\t\treturn NULL;\n\n\tif (bufferevent_init_common_(&bufev_f->bev, underlying->ev_base,\n\t\t\t\t    &bufferevent_ops_filter, tmp_options) < 0) {\n\t\tmm_free(bufev_f);\n\t\treturn NULL;\n\t}\n\tif (options & BEV_OPT_THREADSAFE) {\n\t\tbufferevent_enable_locking_(downcast(bufev_f), NULL);\n\t}\n\n\tbufev_f->underlying = underlying;\n\n\tbufev_f->process_in = input_filter;\n\tbufev_f->process_out = output_filter;\n\tbufev_f->free_context = free_context;\n\tbufev_f->context = ctx;\n\n\tbufferevent_setcb(bufev_f->underlying,\n\t    be_filter_readcb, be_filter_writecb, be_filter_eventcb, bufev_f);\n\n\tbufev_f->inbuf_cb = evbuffer_add_cb(downcast(bufev_f)->input,\n\t\tbufferevent_filtered_inbuf_cb, bufev_f);\n\tevbuffer_cb_clear_flags(downcast(bufev_f)->input, bufev_f->inbuf_cb,\n\t\tEVBUFFER_CB_ENABLED);\n\n\tbufev_f->outbuf_cb = evbuffer_add_cb(downcast(bufev_f)->output,\n\t   bufferevent_filtered_outbuf_cb, bufev_f);\n\n\tbufferevent_init_generic_timeout_cbs_(downcast(bufev_f));\n\tbufferevent_incref_(underlying);\n\n\tbufferevent_enable(underlying, EV_READ|EV_WRITE);\n\tbufferevent_suspend_read_(underlying, BEV_SUSPEND_FILT_READ);\n\n\treturn downcast(bufev_f);\n}\n\nstatic void\nbe_filter_unlink(struct bufferevent *bev)\n{\n\tstruct bufferevent_filtered *bevf = upcast(bev);\n\tif (bevf->bev.options & BEV_OPT_CLOSE_ON_FREE) {\n\t\t/* Yes, there is also a decref in bufferevent_decref_.\n\t\t * That decref corresponds to the incref when we set\n\t\t * underlying for the first time.  This decref is an\n\t\t * extra one to remove the last reference.\n\t\t */\n\t\tif (BEV_UPCAST(bevf->underlying)->refcnt < 2) {\n\t\t\tevent_warnx(\"BEV_OPT_CLOSE_ON_FREE set on an \"\n\t\t\t    \"bufferevent with too few references\");\n\t\t} else {\n\t\t\tbufferevent_free(bevf->underlying);\n\t\t}\n\t} else {\n\t\tif (bevf->underlying) {\n\t\t\tif (bevf->underlying->errorcb == be_filter_eventcb)\n\t\t\t\tbufferevent_setcb(bevf->underlying,\n\t\t\t\t    NULL, NULL, NULL, NULL);\n\t\t\tbufferevent_unsuspend_read_(bevf->underlying,\n\t\t\t    BEV_SUSPEND_FILT_READ);\n\t\t}\n\t}\n}\n\nstatic void\nbe_filter_destruct(struct bufferevent *bev)\n{\n\tstruct bufferevent_filtered *bevf = upcast(bev);\n\tif (bevf->free_context)\n\t\tbevf->free_context(bevf->context);\n\n\tif (bevf->inbuf_cb)\n\t\tevbuffer_remove_cb_entry(bev->input, bevf->inbuf_cb);\n\n\tif (bevf->outbuf_cb)\n\t\tevbuffer_remove_cb_entry(bev->output, bevf->outbuf_cb);\n}\n\nstatic int\nbe_filter_enable(struct bufferevent *bev, short event)\n{\n\tstruct bufferevent_filtered *bevf = upcast(bev);\n\tif (event & EV_WRITE)\n\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bev);\n\n\tif (event & EV_READ) {\n\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bev);\n\t\tbufferevent_unsuspend_read_(bevf->underlying,\n\t\t    BEV_SUSPEND_FILT_READ);\n\t}\n\treturn 0;\n}\n\nstatic int\nbe_filter_disable(struct bufferevent *bev, short event)\n{\n\tstruct bufferevent_filtered *bevf = upcast(bev);\n\tif (event & EV_WRITE)\n\t\tBEV_DEL_GENERIC_WRITE_TIMEOUT(bev);\n\tif (event & EV_READ) {\n\t\tBEV_DEL_GENERIC_READ_TIMEOUT(bev);\n\t\tbufferevent_suspend_read_(bevf->underlying,\n\t\t    BEV_SUSPEND_FILT_READ);\n\t}\n\treturn 0;\n}\n\nstatic enum bufferevent_filter_result\nbe_filter_process_input(struct bufferevent_filtered *bevf,\n\t\t\tenum bufferevent_flush_mode state,\n\t\t\tint *processed_out)\n{\n\tenum bufferevent_filter_result res;\n\tstruct bufferevent *bev = downcast(bevf);\n\n\tif (state == BEV_NORMAL) {\n\t\t/* If we're in 'normal' mode, don't urge data on the filter\n\t\t * unless we're reading data and under our high-water mark.*/\n\t\tif (!(bev->enabled & EV_READ) ||\n\t\t    be_readbuf_full(bevf, state))\n\t\t\treturn BEV_OK;\n\t}\n\n\tdo {\n\t\tev_ssize_t limit = -1;\n\t\tif (state == BEV_NORMAL && bev->wm_read.high)\n\t\t\tlimit = bev->wm_read.high -\n\t\t\t    evbuffer_get_length(bev->input);\n\n\t\tres = bevf->process_in(bevf->underlying->input,\n\t\t    bev->input, limit, state, bevf->context);\n\n\t\tif (res == BEV_OK)\n\t\t\t*processed_out = 1;\n\t} while (res == BEV_OK &&\n\t\t (bev->enabled & EV_READ) &&\n\t\t evbuffer_get_length(bevf->underlying->input) &&\n\t\t !be_readbuf_full(bevf, state));\n\n\tif (*processed_out)\n\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bev);\n\n\treturn res;\n}\n\n\nstatic enum bufferevent_filter_result\nbe_filter_process_output(struct bufferevent_filtered *bevf,\n\t\t\t enum bufferevent_flush_mode state,\n\t\t\t int *processed_out)\n{\n\t/* Requires references and lock: might call writecb */\n\tenum bufferevent_filter_result res = BEV_OK;\n\tstruct bufferevent *bufev = downcast(bevf);\n\tint again = 0;\n\n\tif (state == BEV_NORMAL) {\n\t\t/* If we're in 'normal' mode, don't urge data on the\n\t\t * filter unless we're writing data, and the underlying\n\t\t * bufferevent is accepting data, and we have data to\n\t\t * give the filter.  If we're in 'flush' or 'finish',\n\t\t * call the filter no matter what. */\n\t\tif (!(bufev->enabled & EV_WRITE) ||\n\t\t    be_underlying_writebuf_full(bevf, state) ||\n\t\t    !evbuffer_get_length(bufev->output))\n\t\t\treturn BEV_OK;\n\t}\n\n\t/* disable the callback that calls this function\n\t   when the user adds to the output buffer. */\n\tevbuffer_cb_clear_flags(bufev->output, bevf->outbuf_cb,\n\t    EVBUFFER_CB_ENABLED);\n\n\tdo {\n\t\tint processed = 0;\n\t\tagain = 0;\n\n\t\tdo {\n\t\t\tev_ssize_t limit = -1;\n\t\t\tif (state == BEV_NORMAL &&\n\t\t\t    bevf->underlying->wm_write.high)\n\t\t\t\tlimit = bevf->underlying->wm_write.high -\n\t\t\t\t    evbuffer_get_length(bevf->underlying->output);\n\n\t\t\tres = bevf->process_out(downcast(bevf)->output,\n\t\t\t    bevf->underlying->output,\n\t\t\t    limit,\n\t\t\t    state,\n\t\t\t    bevf->context);\n\n\t\t\tif (res == BEV_OK)\n\t\t\t\tprocessed = *processed_out = 1;\n\t\t} while (/* Stop if the filter wasn't successful...*/\n\t\t\tres == BEV_OK &&\n\t\t\t/* Or if we aren't writing any more. */\n\t\t\t(bufev->enabled & EV_WRITE) &&\n\t\t\t/* Of if we have nothing more to write and we are\n\t\t\t * not flushing. */\n\t\t\tevbuffer_get_length(bufev->output) &&\n\t\t\t/* Or if we have filled the underlying output buffer. */\n\t\t\t!be_underlying_writebuf_full(bevf,state));\n\n\t\tif (processed) {\n\t\t\t/* call the write callback.*/\n\t\t\tbufferevent_trigger_nolock_(bufev, EV_WRITE, 0);\n\n\t\t\tif (res == BEV_OK &&\n\t\t\t    (bufev->enabled & EV_WRITE) &&\n\t\t\t    evbuffer_get_length(bufev->output) &&\n\t\t\t    !be_underlying_writebuf_full(bevf, state)) {\n\t\t\t\tagain = 1;\n\t\t\t}\n\t\t}\n\t} while (again);\n\n\t/* reenable the outbuf_cb */\n\tevbuffer_cb_set_flags(bufev->output,bevf->outbuf_cb,\n\t    EVBUFFER_CB_ENABLED);\n\n\tif (*processed_out)\n\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bufev);\n\n\treturn res;\n}\n\n/* Called when the size of our outbuf changes. */\nstatic void\nbufferevent_filtered_outbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo, void *arg)\n{\n\tstruct bufferevent_filtered *bevf = arg;\n\tstruct bufferevent *bev = downcast(bevf);\n\n\tif (cbinfo->n_added) {\n\t\tint processed_any = 0;\n\t\t/* Somebody added more data to the output buffer. Try to\n\t\t * process it, if we should. */\n\t\tbufferevent_incref_and_lock_(bev);\n\t\tbe_filter_process_output(bevf, BEV_NORMAL, &processed_any);\n\t\tbufferevent_decref_and_unlock_(bev);\n\t}\n}\n\nstatic void\nbe_filter_read_nolock_(struct bufferevent *underlying, void *me_)\n{\n\tstruct bufferevent_filtered *bevf = me_;\n\tenum bufferevent_filter_result res;\n\tenum bufferevent_flush_mode state;\n\tstruct bufferevent *bufev = downcast(bevf);\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bufev);\n\tint processed_any = 0;\n\n\t// It's possible our refcount is 0 at this point if another thread free'd our filterevent\n\tEVUTIL_ASSERT(bufev_private->refcnt >= 0);\n\n\t// If our refcount is > 0\n\tif (bufev_private->refcnt > 0) {\n\n\t\tif (bevf->got_eof)\n\t\t\tstate = BEV_FINISHED;\n\t\telse\n\t\t\tstate = BEV_NORMAL;\n\n\t\t/* XXXX use return value */\n\t\tres = be_filter_process_input(bevf, state, &processed_any);\n\t\t(void)res;\n\n\t\t/* XXX This should be in process_input, not here.  There are\n\t\t * other places that can call process-input, and they should\n\t\t * force readcb calls as needed. */\n\t\tif (processed_any) {\n\t\t\tbufferevent_trigger_nolock_(bufev, EV_READ, 0);\n\t\t\tif (evbuffer_get_length(underlying->input) > 0 &&\n\t\t\t\tbe_readbuf_full(bevf, state)) {\n\t\t\t\t/* data left in underlying buffer and filter input buffer\n\t\t\t\t * hit its read high watermark.\n\t\t\t\t * Schedule callback to avoid data gets stuck in underlying\n\t\t\t\t * input buffer.\n\t\t\t\t */\n\t\t\t\tevbuffer_cb_set_flags(bufev->input, bevf->inbuf_cb,\n\t\t\t\t\tEVBUFFER_CB_ENABLED);\n\t\t\t}\n\t\t}\n\t}\n}\n\n/* Called when the size of our inbuf changes. */\nstatic void\nbufferevent_filtered_inbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo, void *arg)\n{\n\tstruct bufferevent_filtered *bevf = arg;\n\tenum bufferevent_flush_mode state;\n\tstruct bufferevent *bev = downcast(bevf);\n\n\tBEV_LOCK(bev);\n\n\tif (bevf->got_eof)\n\t\tstate = BEV_FINISHED;\n\telse\n\t\tstate = BEV_NORMAL;\n\n\n\tif (!be_readbuf_full(bevf, state)) {\n\t\t/* opportunity to read data which was left in underlying\n\t\t * input buffer because filter input buffer hit read\n\t\t * high watermark.\n\t\t */\n\t\tevbuffer_cb_clear_flags(bev->input, bevf->inbuf_cb,\n\t\t\tEVBUFFER_CB_ENABLED);\n\t\tif (evbuffer_get_length(bevf->underlying->input) > 0)\n\t\t\tbe_filter_read_nolock_(bevf->underlying, bevf);\n\t}\n\n\tBEV_UNLOCK(bev);\n}\n\n/* Called when the underlying socket has read. */\nstatic void\nbe_filter_readcb(struct bufferevent *underlying, void *me_)\n{\n\tstruct bufferevent_filtered *bevf = me_;\n\tstruct bufferevent *bev = downcast(bevf);\n\n\tBEV_LOCK(bev);\n\n\tbe_filter_read_nolock_(underlying, me_);\n\n\tBEV_UNLOCK(bev);\n}\n\n/* Called when the underlying socket has drained enough that we can write to\n   it. */\nstatic void\nbe_filter_writecb(struct bufferevent *underlying, void *me_)\n{\n\tstruct bufferevent_filtered *bevf = me_;\n\tstruct bufferevent *bev = downcast(bevf);\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bev);\n\tint processed_any = 0;\n\n\tBEV_LOCK(bev);\n\n\t// It's possible our refcount is 0 at this point if another thread free'd our filterevent\n\tEVUTIL_ASSERT(bufev_private->refcnt >= 0);\n\n\t// If our refcount is > 0\n\tif (bufev_private->refcnt > 0) {\n\t\tbe_filter_process_output(bevf, BEV_NORMAL, &processed_any);\n\t}\n\n\tBEV_UNLOCK(bev);\n}\n\n/* Called when the underlying socket has given us an error */\nstatic void\nbe_filter_eventcb(struct bufferevent *underlying, short what, void *me_)\n{\n\tstruct bufferevent_filtered *bevf = me_;\n\tstruct bufferevent *bev = downcast(bevf);\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bev);\n\n\tBEV_LOCK(bev);\n\n\t// It's possible our refcount is 0 at this point if another thread free'd our filterevent\n\tEVUTIL_ASSERT(bufev_private->refcnt >= 0);\n\n\t// If our refcount is > 0\n\tif (bufev_private->refcnt > 0) {\n\n\t\t/* All we can really to is tell our own eventcb. */\n\t\tbufferevent_run_eventcb_(bev, what, 0);\n\t}\n\n\tBEV_UNLOCK(bev);\n}\n\nstatic int\nbe_filter_flush(struct bufferevent *bufev,\n    short iotype, enum bufferevent_flush_mode mode)\n{\n\tstruct bufferevent_filtered *bevf = upcast(bufev);\n\tint processed_any = 0;\n\n\tbufferevent_incref_and_lock_(bufev);\n\n\tif (iotype & EV_READ) {\n\t\tbe_filter_process_input(bevf, mode, &processed_any);\n\t}\n\tif (iotype & EV_WRITE) {\n\t\tbe_filter_process_output(bevf, mode, &processed_any);\n\t}\n\t/* XXX check the return value? */\n\t/* XXX does this want to recursively call lower-level flushes? */\n\tbufferevent_flush(bevf->underlying, iotype, mode);\n\n\tbufferevent_decref_and_unlock_(bufev);\n\n\treturn processed_any;\n}\n\nstatic int\nbe_filter_ctrl(struct bufferevent *bev, enum bufferevent_ctrl_op op,\n    union bufferevent_ctrl_data *data)\n{\n\tstruct bufferevent_filtered *bevf;\n\tswitch (op) {\n\tcase BEV_CTRL_GET_UNDERLYING:\n\t\tbevf = upcast(bev);\n\t\tdata->ptr = bevf->underlying;\n\t\treturn 0;\n\tcase BEV_CTRL_SET_FD:\n\tcase BEV_CTRL_GET_FD:\n\t\tbevf = upcast(bev);\n\n\t\tif (bevf->underlying &&\n\t\t\tbevf->underlying->be_ops &&\n\t\t\tbevf->underlying->be_ops->ctrl) {\n\t\t    return (bevf->underlying->be_ops->ctrl)(bevf->underlying, op, data);\n\t\t}\n\t\tEVUTIL_FALLTHROUGH;\n\n\tcase BEV_CTRL_CANCEL_ALL:\n\t\tEVUTIL_FALLTHROUGH;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\treturn -1;\n}\n"
        },
        {
          "name": "bufferevent_mbedtls.c",
          "type": "blob",
          "size": 10.46484375,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n\n/* Mbed-TLS 3.x does not currently expose a function to retrieve\n   the bio parameters from the SSL object. When the above issue has been\n   fixed, remove the MBEDTLS_ALLOW_PRIVATE_ACCESS define and use the\n   appropriate getter function in bufferevent_mbedtls_socket_new rather than\n   accessing the struct fields directly. */\n#define MBEDTLS_ALLOW_PRIVATE_ACCESS\n#include \"mbedtls-compat.h\"\n#include <mbedtls/version.h>\n#include <mbedtls/ssl.h>\n#include <mbedtls/error.h>\n\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/bufferevent_ssl.h\"\n\n#include \"ssl-compat.h\"\n#include \"mm-internal.h\"\n\nstruct mbedtls_context {\n\tmbedtls_dyncontext *ssl;\n\tmbedtls_net_context net;\n};\nstatic void *\nmbedtls_context_init(void *ssl)\n{\n\tstruct mbedtls_context *ctx = mm_malloc(sizeof(*ctx));\n\tif (ctx) {\n\t\tctx->ssl = ssl;\n\t\tctx->net.fd = -1;\n\t}\n\treturn ctx;\n}\nstatic void\nmbedtls_context_free(void *ssl, int flags)\n{\n\tstruct mbedtls_context *ctx = ssl;\n\tif (flags & BEV_OPT_CLOSE_ON_FREE)\n\t\tbufferevent_mbedtls_dyncontext_free(ctx->ssl);\n\tmm_free(ctx);\n}\nstatic int\nmbedtls_context_renegotiate(void *ssl)\n{\n#ifdef MBEDTLS_SSL_RENEGOTIATION\n\tstruct mbedtls_context *ctx = ssl;\n\treturn mbedtls_ssl_renegotiate(ctx->ssl);\n#else\n\treturn MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE;\n#endif\n}\nstatic int\nmbedtls_context_write(void *ssl, const unsigned char *buf, size_t len)\n{\n\tstruct mbedtls_context *ctx = ssl;\n\treturn mbedtls_ssl_write(ctx->ssl, buf, len);\n}\nstatic int\nmbedtls_context_read(void *ssl, unsigned char *buf, size_t len)\n{\n\tstruct mbedtls_context *ctx = ssl;\n\treturn mbedtls_ssl_read(ctx->ssl, buf, len);\n}\nstatic size_t\nmbedtls_context_pending(void *ssl)\n{\n\tstruct mbedtls_context *ctx = ssl;\n\treturn mbedtls_ssl_get_bytes_avail(ctx->ssl);\n}\nstatic int\nmbedtls_context_handshake(void *ssl)\n{\n\tstruct mbedtls_context *ctx = ssl;\n\treturn mbedtls_ssl_handshake(ctx->ssl);\n}\nstatic int\nmbedtls_get_error(void *ssl, int ret)\n{\n\treturn ret;\n}\nstatic void\nmbedtls_clear_error(void)\n{\n}\nstatic int\nmbedtls_clear(void *ssl)\n{\n\treturn 1;\n}\nstatic void\nmbedtls_set_ssl_noops(void *ssl)\n{\n}\nstatic int\nmbedtls_handshake_is_ok(int err)\n{\n\t/* What mbedtls_ssl_handshake() return on success */\n\treturn err == 0;\n}\nstatic int\nmbedtls_is_want_read(int err)\n{\n\treturn err == MBEDTLS_ERR_SSL_WANT_READ;\n}\nstatic int\nmbedtls_is_want_write(int err)\n{\n\treturn err == MBEDTLS_ERR_SSL_WANT_WRITE;\n}\n\nstatic evutil_socket_t\nbe_mbedtls_get_fd(void *ssl)\n{\n\tstruct bufferevent_ssl *bev = ssl;\n\tstruct mbedtls_context *ctx = bev->ssl;\n\treturn ctx->net.fd;\n}\n\nstatic int be_mbedtls_bio_set_fd(\n\tstruct bufferevent_ssl *bev_ssl, evutil_socket_t fd);\n\n#if 0\nstatic void\nprint_err(int val)\n{\n\tchar buf[1024];\n\tmbedtls_strerror(val, buf, sizeof(buf));\n\tprintf(\"Error was %d:%s\\n\", val, buf);\n}\n#else\nstatic void\nprint_err(int val)\n{\n}\n#endif\n\n/* Called to extract data from the BIO. */\nstatic int\nbio_bufferevent_read(void *ctx, unsigned char *out, size_t outlen)\n{\n\tstruct bufferevent *bufev = (struct bufferevent *)ctx;\n\tint r = 0;\n\tstruct evbuffer *input;\n\n\tif (!out)\n\t\treturn 0;\n\tif (!bufev)\n\t\treturn MBEDTLS_ERR_NET_INVALID_CONTEXT;\n\n\tinput = bufferevent_get_input(bufev);\n\tif (evbuffer_get_length(input) == 0) {\n\t\t/* If there's no data to read, say so. */\n\t\treturn MBEDTLS_ERR_SSL_WANT_READ;\n\t} else {\n\t\tr = evbuffer_remove(input, out, outlen);\n\t}\n\n\treturn r;\n}\n\n/* Called to write data into the BIO */\nstatic int\nbio_bufferevent_write(void *ctx, const unsigned char *in, size_t inlen)\n{\n\tstruct bufferevent *bufev = (struct bufferevent *)ctx;\n\tstruct evbuffer *output;\n\tsize_t outlen;\n\n\tif (!bufev)\n\t\treturn MBEDTLS_ERR_NET_INVALID_CONTEXT;\n\n\toutput = bufferevent_get_output(bufev);\n\toutlen = evbuffer_get_length(output);\n\n\t/* Copy only as much data onto the output buffer as can fit under the\n\t * high-water mark. */\n\tif (bufev->wm_write.high && bufev->wm_write.high <= (outlen + inlen)) {\n\t\tif (bufev->wm_write.high <= outlen) {\n\t\t\t/* If no data can fit, we'll need to retry later. */\n\t\t\treturn MBEDTLS_ERR_SSL_WANT_WRITE;\n\t\t}\n\t\tinlen = bufev->wm_write.high - outlen;\n\t}\n\n\tEVUTIL_ASSERT(inlen > 0);\n\tevbuffer_add(output, in, inlen);\n\treturn inlen;\n}\n\nstatic void\nconn_closed(struct bufferevent_ssl *bev_ssl, int when, int errcode, int ret)\n{\n\tint event = BEV_EVENT_ERROR;\n\tchar buf[100];\n\n\tif (when & BEV_EVENT_READING && ret == 0) {\n\t\tif (bev_ssl->flags & BUFFEREVENT_SSL_DIRTY_SHUTDOWN)\n\t\t\tevent = BEV_EVENT_EOF;\n\t} else {\n\t\tmbedtls_strerror(errcode, buf, sizeof(buf));\n\t\tswitch (errcode) {\n\t\tcase MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY:\n\t\t\tevent = BEV_EVENT_EOF;\n\t\t\tbreak;\n\t\tcase MBEDTLS_ERR_SSL_CLIENT_RECONNECT:\n\t\t\tevent_warnx(\"BUG: Unsupported feature %d: %s\", errcode, buf);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* should be impossible; treat as normal error. */\n\t\t\tevent_warnx(\n\t\t\t\t\"BUG: Unexpected mbedtls error code %d: %s\", errcode, buf);\n\t\t\tbreak;\n\t\t}\n\n\t\tbufferevent_ssl_put_error(bev_ssl, errcode);\n\t}\n\n\tbufferevent_ssl_stop_reading(bev_ssl);\n\tbufferevent_ssl_stop_writing(bev_ssl);\n\n\tbufferevent_run_eventcb_(&bev_ssl->bev.bev, when | event, 0);\n}\n\nstatic int\nbe_mbedtls_bio_set_fd(struct bufferevent_ssl *bev_ssl, evutil_socket_t fd)\n{\n\tstruct mbedtls_context *ctx = bev_ssl->ssl;\n\tif (!bev_ssl->underlying) {\n\t\tctx->net.fd = fd;\n\t\tmbedtls_ssl_set_bio(\n\t\t\tctx->ssl, &ctx->net, mbedtls_net_send, mbedtls_net_recv, NULL);\n\t} else {\n\t\tmbedtls_ssl_set_bio(ctx->ssl, bev_ssl->underlying,\n\t\t\tbio_bufferevent_write, bio_bufferevent_read, NULL);\n\t}\n\treturn 0;\n}\n\nint\nbufferevent_mbedtls_get_allow_dirty_shutdown(struct bufferevent *bev)\n{\n\treturn bufferevent_ssl_get_allow_dirty_shutdown(bev);\n}\n\nvoid\nbufferevent_mbedtls_set_allow_dirty_shutdown(\n\tstruct bufferevent *bev, int allow_dirty_shutdown)\n{\n\tbufferevent_ssl_set_allow_dirty_shutdown(bev, allow_dirty_shutdown);\n}\n\nmbedtls_ssl_context *\nbufferevent_mbedtls_get_ssl(struct bufferevent *bufev)\n{\n\tstruct mbedtls_context *ctx = NULL;\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bufev);\n\tif (!bev_ssl)\n\t\treturn NULL;\n\tctx = bev_ssl->ssl;\n\treturn ctx->ssl;\n}\n\nint\nbufferevent_mbedtls_renegotiate(struct bufferevent *bufev)\n{\n\treturn bufferevent_ssl_renegotiate_impl(bufev);\n}\n\nunsigned long\nbufferevent_get_mbedtls_error(struct bufferevent *bufev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bufev);\n\tif (!bev_ssl)\n\t\treturn 0;\n\treturn bufferevent_get_ssl_error(bufev);\n}\n\nstatic struct le_ssl_ops le_mbedtls_ops = {\n\tmbedtls_context_init,\n\tmbedtls_context_free,\n\t(void (*)(void *))bufferevent_mbedtls_dyncontext_free,\n\tmbedtls_context_renegotiate,\n\tmbedtls_context_write,\n\tmbedtls_context_read,\n\tmbedtls_context_pending,\n\tmbedtls_context_handshake,\n\tmbedtls_get_error,\n\tmbedtls_clear_error,\n\tmbedtls_clear,\n\tmbedtls_set_ssl_noops,\n\tmbedtls_set_ssl_noops,\n\tmbedtls_handshake_is_ok,\n\tmbedtls_is_want_read,\n\tmbedtls_is_want_write,\n\tbe_mbedtls_get_fd,\n\tbe_mbedtls_bio_set_fd,\n\t(void (*)(struct bufferevent_ssl *))mbedtls_set_ssl_noops,\n\t(void (*)(struct bufferevent_ssl *))mbedtls_set_ssl_noops,\n\tconn_closed,\n\tprint_err,\n};\n\nstruct bufferevent *\nbufferevent_mbedtls_filter_new(struct event_base *base,\n\tstruct bufferevent *underlying, mbedtls_ssl_context *ssl,\n\tenum bufferevent_ssl_state state, int options)\n{\n\tstruct bufferevent *bev;\n\n\tif (!underlying)\n\t\tgoto err;\n\n\tbev = bufferevent_ssl_new_impl(\n\t\tbase, underlying, -1, ssl, state, options, &le_mbedtls_ops);\n\n\tif (bev) {\n\t\tbe_mbedtls_bio_set_fd(bufferevent_ssl_upcast(bev), -1);\n\t}\n\n\treturn bev;\n\nerr:\n\tif (options & BEV_OPT_CLOSE_ON_FREE)\n\t\tbufferevent_mbedtls_dyncontext_free(ssl);\n\treturn NULL;\n}\n\nstruct bufferevent *\nbufferevent_mbedtls_socket_new(struct event_base *base, evutil_socket_t fd,\n\tmbedtls_ssl_context *ssl, enum bufferevent_ssl_state state, int options)\n{\n\tlong have_fd = -1;\n\tstruct bufferevent *bev;\n\n\tif (ssl->p_bio) {\n\t\t/* The SSL is already configured with bio. */\n\t\tif (ssl->f_send == mbedtls_net_send &&\n\t\t\tssl->f_recv == mbedtls_net_recv) {\n\t\t\thave_fd = ((mbedtls_net_context *)ssl->p_bio)->fd;\n\t\t} else if (ssl->f_send == bio_bufferevent_write &&\n\t\t\t\t   ssl->f_recv == bio_bufferevent_read) {\n\t\t\thave_fd = bufferevent_getfd(ssl->p_bio);\n\t\t} else {\n\t\t\t/* We don't known the fd. */\n\t\t\thave_fd = LONG_MAX;\n\t\t}\n\t}\n\n\tif (have_fd >= 0) {\n\t\tif (fd < 0) {\n\t\t\t/* We should learn the fd from the SSL. */\n\t\t\tfd = (evutil_socket_t)have_fd;\n\t\t} else if (have_fd == (long)fd) {\n\t\t\t/* We already know the fd from the SSL; do nothing */\n\t\t} else {\n\t\t\t/* We specified an fd different from that of the SSL.\n\t\t\t   This is probably an error on our part.  Fail. */\n\t\t\tgoto err;\n\t\t}\n\t} else {\n\t\tif (fd >= 0) {\n\t\t\t/* ... and we have an fd we want to use. */\n\t\t} else {\n\t\t\t/* Leave the fd unset. */\n\t\t}\n\t}\n\n\tbev = bufferevent_ssl_new_impl(\n\t\tbase, NULL, fd, ssl, state, options, &le_mbedtls_ops);\n\n\tif (bev) {\n\t\tbe_mbedtls_bio_set_fd(bufferevent_ssl_upcast(bev), fd);\n\t}\n\n\treturn bev;\nerr:\n\treturn NULL;\n}\n\nmbedtls_dyncontext *\nbufferevent_mbedtls_dyncontext_new(struct mbedtls_ssl_config *conf)\n{\n\tmbedtls_dyncontext *ctx = mm_calloc(1, sizeof(*ctx));\n\tmbedtls_ssl_init(ctx);\n\tmbedtls_ssl_setup(ctx, conf);\n\treturn ctx;\n}\n\nvoid\nbufferevent_mbedtls_dyncontext_free(mbedtls_dyncontext *ctx)\n{\n\tmbedtls_ssl_free(ctx);\n\tmm_free(ctx);\n}\n"
        },
        {
          "name": "bufferevent_openssl.c",
          "type": "blob",
          "size": 13.37890625,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#  include <winsock2.h>\n#endif\n\n#include <string.h>\n\n#include <openssl/ssl.h>\n#include <openssl/err.h>\n#include \"openssl-compat.h\"\n\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/buffer.h\"\n\n#include \"ssl-compat.h\"\n\n/*\n * Define an OpenSSL bio that targets a bufferevent.\n */\n\n/* --------------------\n   A BIO is an OpenSSL abstraction that handles reading and writing data.  The\n   library will happily speak SSL over anything that implements a BIO\n   interface.\n\n   Here we define a BIO implementation that directs its output to a\n   bufferevent.  We'll want to use this only when none of OpenSSL's built-in\n   IO mechanisms work for us.\n   -------------------- */\n\n/* every BIO type needs its own integer type value. */\n#define BIO_TYPE_LIBEVENT 57\n/* ???? Arguably, we should set BIO_TYPE_FILTER or BIO_TYPE_SOURCE_SINK on\n * this. */\n\n#if 0\nstatic void\nprint_err(int val)\n{\n\tint err;\n\tprintf(\"Error was %d\\n\", val);\n\n\twhile ((err = ERR_get_error())) {\n\t\tconst char *msg = (const char*)ERR_reason_error_string(err);\n\t\tconst char *lib = (const char*)ERR_lib_error_string(err);\n\t\tconst char *func = (const char*)ERR_func_error_string(err);\n\n\t\tprintf(\"%s in %s %s\\n\", msg, lib, func);\n\t}\n}\n#else\nstatic void\nprint_err(int val)\n{\n}\n#endif\n\n/* Called to initialize a new BIO */\nstatic int\nbio_bufferevent_new(BIO *b)\n{\n\tBIO_set_init(b, 0);\n\tBIO_set_data(b, NULL); /* We'll be putting the bufferevent in this field.*/\n\treturn 1;\n}\n\n/* Called to uninitialize the BIO. */\nstatic int\nbio_bufferevent_free(BIO *b)\n{\n\tif (!b)\n\t\treturn 0;\n\tif (BIO_get_shutdown(b)) {\n\t\tif (BIO_get_init(b) && BIO_get_data(b))\n\t\t\tbufferevent_free(BIO_get_data(b));\n\t\tBIO_free(b);\n\t}\n\treturn 1;\n}\n\n/* Called to extract data from the BIO. */\nstatic int\nbio_bufferevent_read(BIO *b, char *out, int outlen)\n{\n\tint r = 0;\n\tstruct evbuffer *input;\n\n\tBIO_clear_retry_flags(b);\n\n\tif (!out)\n\t\treturn 0;\n\tif (!BIO_get_data(b))\n\t\treturn -1;\n\n\tinput = bufferevent_get_input(BIO_get_data(b));\n\tif (evbuffer_get_length(input) == 0) {\n\t\t/* If there's no data to read, say so. */\n\t\tBIO_set_retry_read(b);\n\t\treturn -1;\n\t} else {\n\t\tr = evbuffer_remove(input, out, outlen);\n\t}\n\n\treturn r;\n}\n\n/* Called to write data into the BIO */\nstatic int\nbio_bufferevent_write(BIO *b, const char *in, int inlen)\n{\n\tstruct bufferevent *bufev = BIO_get_data(b);\n\tstruct evbuffer *output;\n\tsize_t outlen;\n\n\tBIO_clear_retry_flags(b);\n\n\tif (!bufev)\n\t\treturn -1;\n\n\toutput = bufferevent_get_output(bufev);\n\toutlen = evbuffer_get_length(output);\n\n\t/* Copy only as much data onto the output buffer as can fit under the\n\t * high-water mark. */\n\tif (bufev->wm_write.high && bufev->wm_write.high <= (outlen + inlen)) {\n\t\tif (bufev->wm_write.high <= outlen) {\n\t\t\t/* If no data can fit, we'll need to retry later. */\n\t\t\tBIO_set_retry_write(b);\n\t\t\treturn -1;\n\t\t}\n\t\tinlen = bufev->wm_write.high - outlen;\n\t}\n\n\tEVUTIL_ASSERT(inlen > 0);\n\tevbuffer_add(output, in, inlen);\n\treturn inlen;\n}\n\n/* Called to handle various requests */\nstatic long\nbio_bufferevent_ctrl(BIO *b, int cmd, long num, void *ptr)\n{\n\tstruct bufferevent *bufev = BIO_get_data(b);\n\tlong ret = 1;\n\n\tswitch (cmd) {\n\tcase BIO_CTRL_GET_CLOSE:\n\t\tret = BIO_get_shutdown(b);\n\t\tbreak;\n\tcase BIO_CTRL_SET_CLOSE:\n\t\tBIO_set_shutdown(b, (int)num);\n\t\tbreak;\n\tcase BIO_CTRL_PENDING:\n\t\tret = evbuffer_get_length(bufferevent_get_input(bufev)) != 0;\n\t\tbreak;\n\tcase BIO_CTRL_WPENDING:\n\t\tret = evbuffer_get_length(bufferevent_get_output(bufev)) != 0;\n\t\tbreak;\n\t/* XXXX These two are given a special-case treatment because\n\t * of cargo-cultism.  I should come up with a better reason. */\n\tcase BIO_CTRL_DUP:\n\tcase BIO_CTRL_FLUSH:\n\t\tret = 1;\n\t\tbreak;\n\tdefault:\n\t\tret = 0;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\n/* Called to write a string to the BIO */\nstatic int\nbio_bufferevent_puts(BIO *b, const char *s)\n{\n\treturn bio_bufferevent_write(b, s, strlen(s));\n}\n\n/* Method table for the bufferevent BIO */\nstatic BIO_METHOD *methods_bufferevent;\n\n/* Return the method table for the bufferevents BIO */\nstatic BIO_METHOD *\nBIO_s_bufferevent(void)\n{\n\tif (methods_bufferevent == NULL) {\n\t\tmethods_bufferevent = BIO_meth_new(BIO_TYPE_LIBEVENT, \"bufferevent\");\n\t\tif (methods_bufferevent == NULL)\n\t\t\treturn NULL;\n\t\tBIO_meth_set_write(methods_bufferevent, bio_bufferevent_write);\n\t\tBIO_meth_set_read(methods_bufferevent, bio_bufferevent_read);\n\t\tBIO_meth_set_puts(methods_bufferevent, bio_bufferevent_puts);\n\t\tBIO_meth_set_ctrl(methods_bufferevent, bio_bufferevent_ctrl);\n\t\tBIO_meth_set_create(methods_bufferevent, bio_bufferevent_new);\n\t\tBIO_meth_set_destroy(methods_bufferevent, bio_bufferevent_free);\n\t}\n\treturn methods_bufferevent;\n}\n\n/* Create a new BIO to wrap communication around a bufferevent.  If close_flag\n * is true, the bufferevent will be freed when the BIO is closed. */\nstatic BIO *\nBIO_new_bufferevent(struct bufferevent *bufferevent)\n{\n\tBIO *result;\n\tif (!bufferevent)\n\t\treturn NULL;\n\tif (!(result = BIO_new(BIO_s_bufferevent())))\n\t\treturn NULL;\n\tBIO_set_init(result, 1);\n\tBIO_set_data(result, bufferevent);\n\t/* We don't tell the BIO to close the bufferevent; we do it ourselves on\n\t * be_openssl_destruct() */\n\tBIO_set_shutdown(result, 0);\n\treturn result;\n}\n\nstatic void\nconn_closed(struct bufferevent_ssl *bev_ssl, int when, int errcode, int ret)\n{\n\tint event = BEV_EVENT_ERROR;\n\tint dirty_shutdown = 0;\n\tunsigned long err;\n\n\tswitch (errcode) {\n\tcase SSL_ERROR_ZERO_RETURN:\n\t\t/* Possibly a clean shutdown. */\n\t\tif (SSL_get_shutdown(bev_ssl->ssl) & SSL_RECEIVED_SHUTDOWN)\n\t\t\tevent = BEV_EVENT_EOF;\n\t\telse\n\t\t\tdirty_shutdown = 1;\n\t\tbreak;\n\tcase SSL_ERROR_SYSCALL:\n\t\t/* IO error; possibly a dirty shutdown. */\n\t\tif ((ret == 0 || ret == -1) && ERR_peek_error() == 0)\n\t\t\tdirty_shutdown = 1;\n\t\tbufferevent_ssl_put_error(bev_ssl, errcode);\n\t\tbreak;\n\tcase SSL_ERROR_SSL:\n\t\t/* Protocol error; possibly a dirty shutdown. */\n\t\tif (ret == 0 && SSL_is_init_finished(bev_ssl->ssl) == 0)\n\t\t\tdirty_shutdown = 1;\n\t\tbufferevent_ssl_put_error(bev_ssl, errcode);\n\t\tbreak;\n\tcase SSL_ERROR_WANT_X509_LOOKUP:\n\t\t/* XXXX handle this. */\n\t\tbufferevent_ssl_put_error(bev_ssl, errcode);\n\t\tbreak;\n\tcase SSL_ERROR_NONE:\n\tcase SSL_ERROR_WANT_READ:\n\tcase SSL_ERROR_WANT_WRITE:\n\tcase SSL_ERROR_WANT_CONNECT:\n\tcase SSL_ERROR_WANT_ACCEPT:\n\tdefault:\n\t\t/* should be impossible; treat as normal error. */\n\t\tevent_warnx(\"BUG: Unexpected OpenSSL error code %d\", errcode);\n\t\tbreak;\n\t}\n\n\twhile ((err = ERR_get_error())) {\n\t\tbufferevent_ssl_put_error(bev_ssl, err);\n\t}\n\n\tif (dirty_shutdown && bev_ssl->flags & BUFFEREVENT_SSL_DIRTY_SHUTDOWN)\n\t\tevent = BEV_EVENT_EOF;\n\n\tbufferevent_ssl_stop_reading(bev_ssl);\n\tbufferevent_ssl_stop_writing(bev_ssl);\n\n\t/* when is BEV_EVENT_{READING|WRITING} */\n\tevent = when | event;\n\tbufferevent_run_eventcb_(&bev_ssl->bev.bev, event, 0);\n}\n\nstatic void\ninit_bio_counts(struct bufferevent_ssl *bev_ssl)\n{\n\tBIO *rbio, *wbio;\n\n\twbio = SSL_get_wbio(bev_ssl->ssl);\n\tbev_ssl->counts.n_written = wbio ? BIO_number_written(wbio) : 0;\n\trbio = SSL_get_rbio(bev_ssl->ssl);\n\tbev_ssl->counts.n_read = rbio ? BIO_number_read(rbio) : 0;\n}\n\nstatic inline void\ndecrement_buckets(struct bufferevent_ssl *bev_ssl)\n{\n\tunsigned long num_w = BIO_number_written(SSL_get_wbio(bev_ssl->ssl));\n\tunsigned long num_r = BIO_number_read(SSL_get_rbio(bev_ssl->ssl));\n\t/* These next two subtractions can wrap around. That's okay. */\n\tunsigned long w = num_w - bev_ssl->counts.n_written;\n\tunsigned long r = num_r - bev_ssl->counts.n_read;\n\tif (w)\n\t\tbufferevent_decrement_write_buckets_(&bev_ssl->bev, w);\n\tif (r)\n\t\tbufferevent_decrement_read_buckets_(&bev_ssl->bev, r);\n\tbev_ssl->counts.n_written = num_w;\n\tbev_ssl->counts.n_read = num_r;\n}\n\nstatic void *\nSSL_init(void *ssl)\n{\n\t/* Don't explode if we decide to realloc a chunk we're writing from in\n\t * the output buffer. */\n\tSSL_set_mode(ssl, SSL_MODE_ACCEPT_MOVING_WRITE_BUFFER);\n\n\treturn ssl;\n}\n\nstatic void\nSSL_context_free(void *ssl, int flags)\n{\n\tif (flags & BEV_OPT_CLOSE_ON_FREE)\n\t\tSSL_free(ssl);\n}\n\nstatic int\nSSL_handshake_is_ok(int err)\n{\n\t/* What SSL_do_handshake() return on success */\n\treturn err == 1;\n}\n\nstatic int\nSSL_is_want_read(int err)\n{\n\treturn err == SSL_ERROR_WANT_READ;\n}\n\nstatic int\nSSL_is_want_write(int err)\n{\n\treturn err == SSL_ERROR_WANT_WRITE;\n}\n\nstatic int\nopenssl_read(void *ssl, unsigned char *buf, size_t len)\n{\n\treturn SSL_read(ssl, buf, len);\n}\n\nstatic int\nopenssl_write(void *ssl, const unsigned char *buf, size_t len)\n{\n\treturn SSL_write(ssl, buf, len);\n}\n\nstatic evutil_socket_t\nbe_openssl_get_fd(struct bufferevent_ssl *bev_ssl)\n{\n\tevutil_socket_t fd = EVUTIL_INVALID_SOCKET;\n\tBIO *bio = SSL_get_wbio(bev_ssl->ssl);\n\tif (bio)\n\t\tfd = BIO_get_fd(bio, NULL);\n\treturn fd;\n}\n\nstatic int\nbe_openssl_bio_set_fd(struct bufferevent_ssl *bev_ssl, evutil_socket_t fd)\n{\n\tif (!bev_ssl->underlying) {\n\t\tBIO *bio;\n\t\tbio = BIO_new_socket((int)fd, 0);\n\t\tSSL_set_bio(bev_ssl->ssl, bio, bio);\n\t} else {\n\t\tBIO *bio;\n\t\tif (!(bio = BIO_new_bufferevent(bev_ssl->underlying)))\n\t\t\treturn -1;\n\t\tSSL_set_bio(bev_ssl->ssl, bio, bio);\n\t}\n\treturn 0;\n}\n\nstatic size_t SSL_pending_wrap(void *ssl)\n{\n\treturn SSL_pending(ssl);\n}\n\nstatic struct le_ssl_ops le_openssl_ops = {\n\tSSL_init,\n\tSSL_context_free,\n\t(void (*)(void *))SSL_free,\n\t(int (*)(void *))SSL_renegotiate,\n\topenssl_write,\n\topenssl_read,\n\tSSL_pending_wrap,\n\t(int (*)(void *))SSL_do_handshake,\n\t(int (*)(void *, int))SSL_get_error,\n\tERR_clear_error,\n\t(int (*)(void *))SSL_clear,\n\t(void (*)(void *))SSL_set_connect_state,\n\t(void (*)(void *))SSL_set_accept_state,\n\tSSL_handshake_is_ok,\n\tSSL_is_want_read,\n\tSSL_is_want_write,\n\t(evutil_socket_t (*)(void *))be_openssl_get_fd,\n\tbe_openssl_bio_set_fd,\n\tinit_bio_counts,\n\tdecrement_buckets,\n\tconn_closed,\n\tprint_err,\n};\n\nstruct bufferevent *\nbufferevent_openssl_filter_new(struct event_base *base,\n    struct bufferevent *underlying,\n    SSL *ssl,\n    enum bufferevent_ssl_state state,\n    int options)\n{\n\tBIO *bio;\n\tstruct bufferevent *bev;\n\n\tif (!underlying)\n\t\tgoto err;\n\tif (!(bio = BIO_new_bufferevent(underlying)))\n\t\tgoto err;\n\n\tSSL_set_bio(ssl, bio, bio);\n\n\tbev = bufferevent_ssl_new_impl(\n\t\tbase, underlying, -1, ssl, state, options, &le_openssl_ops);\n\treturn bev;\n\nerr:\n\tif (options & BEV_OPT_CLOSE_ON_FREE)\n\t\tSSL_free(ssl);\n\treturn NULL;\n}\n\nstruct bufferevent *\nbufferevent_openssl_socket_new(struct event_base *base,\n    evutil_socket_t fd,\n    SSL *ssl,\n    enum bufferevent_ssl_state state,\n    int options)\n{\n\t/* Does the SSL already have an fd? */\n\tBIO *bio = SSL_get_wbio(ssl);\n\tlong have_fd = -1;\n\n\tif (bio)\n\t\thave_fd = BIO_get_fd(bio, NULL);\n\n\tif (have_fd >= 0) {\n\t\t/* The SSL is already configured with an fd. */\n\t\tif (fd < 0) {\n\t\t\t/* We should learn the fd from the SSL. */\n\t\t\tfd = (evutil_socket_t) have_fd;\n\t\t} else if (have_fd == (long)fd) {\n\t\t\t/* We already know the fd from the SSL; do nothing */\n\t\t} else {\n\t\t\t/* We specified an fd different from that of the SSL.\n\t\t\t   This is probably an error on our part.  Fail. */\n\t\t\tgoto err;\n\t\t}\n\t\t(void)BIO_set_close(bio, 0);\n\t} else {\n\t\t/* The SSL isn't configured with a BIO with an fd. */\n\t\tif (fd >= 0) {\n\t\t\t/* ... and we have an fd we want to use. */\n\t\t\tbio = BIO_new_socket((int)fd, 0);\n\t\t\tSSL_set_bio(ssl, bio, bio);\n\t\t} else {\n\t\t\t/* Leave the fd unset. */\n\t\t}\n\t}\n\n\treturn bufferevent_ssl_new_impl(\n\t\tbase, NULL, fd, ssl, state, options, &le_openssl_ops);\n\nerr:\n\tif (options & BEV_OPT_CLOSE_ON_FREE)\n\t\tSSL_free(ssl);\n\treturn NULL;\n}\n\nint\nbufferevent_ssl_renegotiate(struct bufferevent *bev)\n{\n\treturn bufferevent_ssl_renegotiate_impl(bev);\n}\n\nSSL *\nbufferevent_openssl_get_ssl(struct bufferevent *bufev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bufev);\n\tif (!bev_ssl)\n\t\treturn NULL;\n\treturn bev_ssl->ssl;\n}\n\nint\nbufferevent_openssl_get_allow_dirty_shutdown(struct bufferevent *bev)\n{\n\treturn bufferevent_ssl_get_allow_dirty_shutdown(bev);\n}\n\nvoid\nbufferevent_openssl_set_allow_dirty_shutdown(\n\tstruct bufferevent *bev, int allow_dirty_shutdown)\n{\n\tbufferevent_ssl_set_allow_dirty_shutdown(bev, allow_dirty_shutdown);\n}\n\nunsigned long\nbufferevent_get_openssl_error(struct bufferevent *bufev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bufev);\n\tif (!bev_ssl)\n\t\treturn 0;\n\treturn bufferevent_get_ssl_error(bufev);\n}\n"
        },
        {
          "name": "bufferevent_pair.c",
          "type": "blob",
          "size": 9.5380859375,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/event.h\"\n#include \"defer-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n\nstruct bufferevent_pair {\n\tstruct bufferevent_private bev;\n\tstruct bufferevent_pair *partner;\n\t/* For ->destruct() lock checking */\n\tstruct bufferevent_pair *unlinked_partner;\n};\n\n\n/* Given a bufferevent that's really a bev part of a bufferevent_pair,\n * return that bufferevent_filtered. Returns NULL otherwise.*/\nstatic inline struct bufferevent_pair *\nupcast(struct bufferevent *bev)\n{\n\tstruct bufferevent_pair *bev_p;\n\tbev_p = EVUTIL_UPCAST(bev, struct bufferevent_pair, bev.bev);\n\tEVUTIL_ASSERT(BEV_IS_PAIR(&bev_p->bev.bev));\n\treturn bev_p;\n}\n\n#define downcast(bev_pair) (&(bev_pair)->bev.bev)\n\nstatic inline void\nincref_and_lock(struct bufferevent *b)\n{\n\tstruct bufferevent_pair *bevp;\n\tbufferevent_incref_and_lock_(b);\n\tbevp = upcast(b);\n\tif (bevp->partner)\n\t\tbufferevent_incref_and_lock_(downcast(bevp->partner));\n}\n\nstatic inline void\ndecref_and_unlock(struct bufferevent *b)\n{\n\tstruct bufferevent_pair *bevp = upcast(b);\n\tif (bevp->partner)\n\t\tbufferevent_decref_and_unlock_(downcast(bevp->partner));\n\tbufferevent_decref_and_unlock_(b);\n}\n\n/* XXX Handle close */\n\nstatic void be_pair_outbuf_cb(struct evbuffer *,\n    const struct evbuffer_cb_info *, void *);\n\nstatic struct bufferevent_pair *\nbufferevent_pair_elt_new(struct event_base *base,\n    int options)\n{\n\tstruct bufferevent_pair *bufev;\n\tif (! (bufev = mm_calloc(1, sizeof(struct bufferevent_pair))))\n\t\treturn NULL;\n\tif (bufferevent_init_common_(&bufev->bev, base, &bufferevent_ops_pair,\n\t\toptions)) {\n\t\tmm_free(bufev);\n\t\treturn NULL;\n\t}\n\tif (!evbuffer_add_cb(bufev->bev.bev.output, be_pair_outbuf_cb, bufev)) {\n\t\tbufferevent_free(downcast(bufev));\n\t\treturn NULL;\n\t}\n\n\tbufferevent_init_generic_timeout_cbs_(&bufev->bev.bev);\n\n\treturn bufev;\n}\n\nint\nbufferevent_pair_new(struct event_base *base, int options,\n    struct bufferevent *pair[2])\n{\n\tstruct bufferevent_pair *bufev1 = NULL, *bufev2 = NULL;\n\tint tmp_options;\n\n\toptions |= BEV_OPT_DEFER_CALLBACKS;\n\ttmp_options = options & ~BEV_OPT_THREADSAFE;\n\n\tbufev1 = bufferevent_pair_elt_new(base, options);\n\tif (!bufev1)\n\t\treturn -1;\n\tbufev2 = bufferevent_pair_elt_new(base, tmp_options);\n\tif (!bufev2) {\n\t\tbufferevent_free(downcast(bufev1));\n\t\treturn -1;\n\t}\n\n\tif (options & BEV_OPT_THREADSAFE) {\n\t\t/*XXXX check return */\n\t\tbufferevent_enable_locking_(downcast(bufev2), bufev1->bev.lock);\n\t}\n\n\tbufev1->partner = bufev2;\n\tbufev2->partner = bufev1;\n\n\tevbuffer_freeze(downcast(bufev1)->input, 0);\n\tevbuffer_freeze(downcast(bufev1)->output, 1);\n\tevbuffer_freeze(downcast(bufev2)->input, 0);\n\tevbuffer_freeze(downcast(bufev2)->output, 1);\n\n\tpair[0] = downcast(bufev1);\n\tpair[1] = downcast(bufev2);\n\n\treturn 0;\n}\n\nstatic void\nbe_pair_transfer(struct bufferevent *src, struct bufferevent *dst,\n    int ignore_wm)\n{\n\tsize_t dst_size;\n\tsize_t n;\n\n\tevbuffer_unfreeze(src->output, 1);\n\tevbuffer_unfreeze(dst->input, 0);\n\n\tif (dst->wm_read.high) {\n\t\tdst_size = evbuffer_get_length(dst->input);\n\t\tif (dst_size < dst->wm_read.high) {\n\t\t\tn = dst->wm_read.high - dst_size;\n\t\t\tevbuffer_remove_buffer(src->output, dst->input, n);\n\t\t} else {\n\t\t\tif (!ignore_wm)\n\t\t\t\tgoto done;\n\t\t\tn = evbuffer_get_length(src->output);\n\t\t\tevbuffer_add_buffer(dst->input, src->output);\n\t\t}\n\t} else {\n\t\tn = evbuffer_get_length(src->output);\n\t\tevbuffer_add_buffer(dst->input, src->output);\n\t}\n\n\tif (n) {\n\t\tBEV_RESET_GENERIC_READ_TIMEOUT(dst);\n\n\t\tif (evbuffer_get_length(dst->output))\n\t\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(dst);\n\t\telse\n\t\t\tBEV_DEL_GENERIC_WRITE_TIMEOUT(dst);\n\t}\n\n\tbufferevent_trigger_nolock_(dst, EV_READ, 0);\n\tbufferevent_trigger_nolock_(src, EV_WRITE, 0);\ndone:\n\tevbuffer_freeze(src->output, 1);\n\tevbuffer_freeze(dst->input, 0);\n}\n\nstatic inline int\nbe_pair_wants_to_talk(struct bufferevent_pair *src,\n    struct bufferevent_pair *dst)\n{\n\treturn (downcast(src)->enabled & EV_WRITE) &&\n\t    (downcast(dst)->enabled & EV_READ) &&\n\t    !dst->bev.read_suspended &&\n\t    evbuffer_get_length(downcast(src)->output);\n}\n\nstatic void\nbe_pair_outbuf_cb(struct evbuffer *outbuf,\n    const struct evbuffer_cb_info *info, void *arg)\n{\n\tstruct bufferevent_pair *bev_pair = arg;\n\tstruct bufferevent_pair *partner = bev_pair->partner;\n\n\tincref_and_lock(downcast(bev_pair));\n\n\tif (info->n_added > info->n_deleted && partner) {\n\t\t/* We got more data.  If the other side's reading, then\n\t\t   hand it over. */\n\t\tif (be_pair_wants_to_talk(bev_pair, partner)) {\n\t\t\tbe_pair_transfer(downcast(bev_pair), downcast(partner), 0);\n\t\t}\n\t}\n\n\tdecref_and_unlock(downcast(bev_pair));\n}\n\nstatic int\nbe_pair_enable(struct bufferevent *bufev, short events)\n{\n\tstruct bufferevent_pair *bev_p = upcast(bufev);\n\tstruct bufferevent_pair *partner = bev_p->partner;\n\n\tincref_and_lock(bufev);\n\n\tif (events & EV_READ) {\n\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bufev);\n\t}\n\tif ((events & EV_WRITE) && evbuffer_get_length(bufev->output))\n\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bufev);\n\n\t/* We're starting to read! Does the other side have anything to write?*/\n\tif ((events & EV_READ) && partner &&\n\t    be_pair_wants_to_talk(partner, bev_p)) {\n\t\tbe_pair_transfer(downcast(partner), bufev, 0);\n\t}\n\t/* We're starting to write! Does the other side want to read? */\n\tif ((events & EV_WRITE) && partner &&\n\t    be_pair_wants_to_talk(bev_p, partner)) {\n\t\tbe_pair_transfer(bufev, downcast(partner), 0);\n\t}\n\tdecref_and_unlock(bufev);\n\treturn 0;\n}\n\nstatic int\nbe_pair_disable(struct bufferevent *bev, short events)\n{\n\tif (events & EV_READ) {\n\t\tBEV_DEL_GENERIC_READ_TIMEOUT(bev);\n\t}\n\tif (events & EV_WRITE) {\n\t\tBEV_DEL_GENERIC_WRITE_TIMEOUT(bev);\n\t}\n\treturn 0;\n}\n\nstatic void\nbe_pair_unlink(struct bufferevent *bev)\n{\n\tstruct bufferevent_pair *bev_p = upcast(bev);\n\n\tif (bev_p->partner) {\n\t\tbev_p->unlinked_partner = bev_p->partner;\n\t\tbev_p->partner->partner = NULL;\n\t\tbev_p->partner = NULL;\n\t}\n}\n\n/* Free *shared* lock in the latest be (since we share it between two of them). */\nstatic void\nbe_pair_destruct(struct bufferevent *bev)\n{\n\tstruct bufferevent_pair *bev_p = upcast(bev);\n\n\t/* Transfer ownership of the lock into partner, otherwise we will use\n\t * already free'd lock during freeing second bev, see next example:\n\t *\n\t * bev1->own_lock = 1\n\t * bev2->own_lock = 0\n\t * bev2->lock = bev1->lock\n\t *\n\t * bufferevent_free(bev1) # refcnt == 0 -> unlink\n\t * bufferevent_free(bev2) # refcnt == 0 -> unlink\n\t *\n\t * event_base_free() -> finalizers -> EVTHREAD_FREE_LOCK(bev1->lock)\n\t *                                 -> BEV_LOCK(bev2->lock) <-- already freed\n\t *\n\t * Where bev1 == pair[0], bev2 == pair[1].\n\t */\n\tif (bev_p->unlinked_partner && bev_p->bev.own_lock) {\n\t\tbev_p->unlinked_partner->bev.own_lock = 1;\n\t\tbev_p->bev.own_lock = 0;\n\t}\n\tbev_p->unlinked_partner = NULL;\n}\n\nstatic int\nbe_pair_flush(struct bufferevent *bev, short iotype,\n    enum bufferevent_flush_mode mode)\n{\n\tstruct bufferevent_pair *bev_p = upcast(bev);\n\tstruct bufferevent *partner;\n\n\tif (!bev_p->partner)\n\t\treturn -1;\n\n\tif (mode == BEV_NORMAL)\n\t\treturn 0;\n\n\tincref_and_lock(bev);\n\n\tpartner = downcast(bev_p->partner);\n\n\tif ((iotype & EV_READ) != 0)\n\t\tbe_pair_transfer(partner, bev, 1);\n\n\tif ((iotype & EV_WRITE) != 0)\n\t\tbe_pair_transfer(bev, partner, 1);\n\n\tif (mode == BEV_FINISHED) {\n\t\tshort what = BEV_EVENT_EOF;\n\t\tif (iotype & EV_READ)\n\t\t\twhat |= BEV_EVENT_WRITING;\n\t\tif (iotype & EV_WRITE)\n\t\t\twhat |= BEV_EVENT_READING;\n\t\tbufferevent_run_eventcb_(partner, what, 0);\n\t}\n\tdecref_and_unlock(bev);\n\treturn 0;\n}\n\nstruct bufferevent *\nbufferevent_pair_get_partner(struct bufferevent *bev)\n{\n\tstruct bufferevent_pair *bev_p;\n\tstruct bufferevent *partner = NULL;\n\tif (!BEV_IS_PAIR(bev))\n\t\treturn NULL;\n\tbev_p = upcast(bev);\n\tincref_and_lock(bev);\n\tif (bev_p->partner)\n\t\tpartner = downcast(bev_p->partner);\n\tdecref_and_unlock(bev);\n\treturn partner;\n}\n\nconst struct bufferevent_ops bufferevent_ops_pair = {\n\t\"pair_elt\",\n\tevutil_offsetof(struct bufferevent_pair, bev.bev),\n\tbe_pair_enable,\n\tbe_pair_disable,\n\tbe_pair_unlink,\n\tbe_pair_destruct,\n\tbufferevent_generic_adj_timeouts_,\n\tbe_pair_flush,\n\tNULL, /* ctrl */\n};\n"
        },
        {
          "name": "bufferevent_ratelim.c",
          "type": "blob",
          "size": 30.07421875,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n * Copyright (c) 2002-2006 Niels Provos <provos@citi.umich.edu>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n#include <limits.h>\n#include <string.h>\n#include <stdlib.h>\n\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/util.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/buffer.h\"\n\n#include \"ratelim-internal.h\"\n\n#include \"bufferevent-internal.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n#include \"event-internal.h\"\n\nint\nev_token_bucket_init_(struct ev_token_bucket *bucket,\n    const struct ev_token_bucket_cfg *cfg,\n    ev_uint32_t current_tick,\n    int reinitialize)\n{\n\tif (reinitialize) {\n\t\t/* on reinitialization, we only clip downwards, since we've\n\t\t   already used who-knows-how-much bandwidth this tick.  We\n\t\t   leave \"last_updated\" as it is; the next update will add the\n\t\t   appropriate amount of bandwidth to the bucket.\n\t\t*/\n\t\tif (bucket->read_limit > (ev_int64_t) cfg->read_maximum)\n\t\t\tbucket->read_limit = cfg->read_maximum;\n\t\tif (bucket->write_limit > (ev_int64_t) cfg->write_maximum)\n\t\t\tbucket->write_limit = cfg->write_maximum;\n\t} else {\n\t\tbucket->read_limit = cfg->read_rate;\n\t\tbucket->write_limit = cfg->write_rate;\n\t\tbucket->last_updated = current_tick;\n\t}\n\treturn 0;\n}\n\nint\nev_token_bucket_update_(struct ev_token_bucket *bucket,\n    const struct ev_token_bucket_cfg *cfg,\n    ev_uint32_t current_tick)\n{\n\t/* It's okay if the tick number overflows, since we'll just\n\t * wrap around when we do the unsigned subtraction. */\n\tunsigned n_ticks = current_tick - bucket->last_updated;\n\n\t/* Make sure some ticks actually happened, and that time didn't\n\t * roll back. */\n\tif (n_ticks == 0 || n_ticks > INT_MAX)\n\t\treturn 0;\n\n\t/* Naively, we would say\n\t\tbucket->limit += n_ticks * cfg->rate;\n\n\t\tif (bucket->limit > cfg->maximum)\n\t\t\tbucket->limit = cfg->maximum;\n\n\t   But we're worried about overflow, so we do it like this:\n\t*/\n\n\tif ((cfg->read_maximum - bucket->read_limit) / n_ticks < cfg->read_rate)\n\t\tbucket->read_limit = cfg->read_maximum;\n\telse\n\t\tbucket->read_limit += n_ticks * cfg->read_rate;\n\n\n\tif ((cfg->write_maximum - bucket->write_limit) / n_ticks < cfg->write_rate)\n\t\tbucket->write_limit = cfg->write_maximum;\n\telse\n\t\tbucket->write_limit += n_ticks * cfg->write_rate;\n\n\n\tbucket->last_updated = current_tick;\n\n\treturn 1;\n}\n\nstatic inline void\nbufferevent_update_buckets(struct bufferevent_private *bev)\n{\n\t/* Must hold lock on bev. */\n\tstruct timeval now;\n\tunsigned tick;\n\tevent_base_gettimeofday_cached(bev->bev.ev_base, &now);\n\ttick = ev_token_bucket_get_tick_(&now, bev->rate_limiting->cfg);\n\tif (tick != bev->rate_limiting->limit.last_updated)\n\t\tev_token_bucket_update_(&bev->rate_limiting->limit,\n\t\t    bev->rate_limiting->cfg, tick);\n}\n\nev_uint32_t\nev_token_bucket_get_tick_(const struct timeval *tv,\n    const struct ev_token_bucket_cfg *cfg)\n{\n\t/* This computation uses two multiplies and a divide.  We could do\n\t * fewer if we knew that the tick length was an integer number of\n\t * seconds, or if we knew it divided evenly into a second.  We should\n\t * investigate that more.\n\t */\n\n\t/* We cast to an ev_uint64_t first, since we don't want to overflow\n\t * before we do the final divide. */\n\tev_uint64_t msec = (ev_uint64_t)tv->tv_sec * 1000 + tv->tv_usec / 1000;\n\treturn (unsigned)(msec / cfg->msec_per_tick);\n}\n\nstruct ev_token_bucket_cfg *\nev_token_bucket_cfg_new(size_t read_rate, size_t read_burst,\n    size_t write_rate, size_t write_burst,\n    const struct timeval *tick_len)\n{\n\tstruct ev_token_bucket_cfg *r;\n\tstruct timeval g;\n\tunsigned msec_per_tick;\n\n\tif (! tick_len) {\n\t\tg.tv_sec = 1;\n\t\tg.tv_usec = 0;\n\t\ttick_len = &g;\n\t}\n\n\t/* Avoid possible overflow.\n\t * - there is no point in accepting values larger then INT_MAX/1000 anyway\n\t * - on windows tv_sec (tv_usec) is long, which is int, which has upper value limit INT_MAX\n\t * - and also negative values does not make any sense\n\t */\n\tif (tick_len->tv_sec < 0 || tick_len->tv_sec > INT_MAX/1000)\n\t\treturn NULL;\n\n\t/* Note, overflow with tv_usec is not possible since tv_sec is limited to\n\t * INT_MAX/1000 anyway */\n\tmsec_per_tick = (unsigned)(tick_len->tv_sec * 1000) +\n\t    (tick_len->tv_usec & COMMON_TIMEOUT_MICROSECONDS_MASK)/1000;\n\tif (!msec_per_tick)\n\t\treturn NULL;\n\n\tif (read_rate > read_burst || write_rate > write_burst ||\n\t    read_rate < 1 || write_rate < 1)\n\t\treturn NULL;\n\tif (read_rate > EV_RATE_LIMIT_MAX ||\n\t    write_rate > EV_RATE_LIMIT_MAX ||\n\t    read_burst > EV_RATE_LIMIT_MAX ||\n\t    write_burst > EV_RATE_LIMIT_MAX)\n\t\treturn NULL;\n\tr = mm_calloc(1, sizeof(struct ev_token_bucket_cfg));\n\tif (!r)\n\t\treturn NULL;\n\tr->read_rate = read_rate;\n\tr->write_rate = write_rate;\n\tr->read_maximum = read_burst;\n\tr->write_maximum = write_burst;\n\tmemcpy(&r->tick_timeout, tick_len, sizeof(struct timeval));\n\tr->msec_per_tick = msec_per_tick;\n\treturn r;\n}\n\nvoid\nev_token_bucket_cfg_free(struct ev_token_bucket_cfg *cfg)\n{\n\tmm_free(cfg);\n}\n\n/* Default values for max_single_read & max_single_write variables. */\n#define MAX_SINGLE_READ_DEFAULT 16384\n#define MAX_SINGLE_WRITE_DEFAULT 16384\n\n#define LOCK_GROUP(g) EVLOCK_LOCK((g)->lock, 0)\n#define UNLOCK_GROUP(g) EVLOCK_UNLOCK((g)->lock, 0)\n\nstatic int bev_group_suspend_reading_(struct bufferevent_rate_limit_group *g);\nstatic int bev_group_suspend_writing_(struct bufferevent_rate_limit_group *g);\nstatic void bev_group_unsuspend_reading_(struct bufferevent_rate_limit_group *g);\nstatic void bev_group_unsuspend_writing_(struct bufferevent_rate_limit_group *g);\n\n/** Helper: figure out the maximum amount we should write if is_write, or\n    the maximum amount we should read if is_read.  Return that maximum, or\n    0 if our bucket is wholly exhausted.\n */\nstatic inline ev_ssize_t\nbufferevent_get_rlim_max_(struct bufferevent_private *bev, int is_write)\n{\n\t/* needs lock on bev. */\n\tev_ssize_t max_so_far = is_write?bev->max_single_write:bev->max_single_read;\n\n#define LIM(x)\t\t\t\t\t\t\\\n\t(is_write ? (x).write_limit : (x).read_limit)\n\n#define GROUP_SUSPENDED(g)\t\t\t\\\n\t(is_write ? (g)->write_suspended : (g)->read_suspended)\n\n\t/* Sets max_so_far to MIN(x, max_so_far) */\n#define CLAMPTO(x)\t\t\t\t\\\n\tdo {\t\t\t\t\t\\\n\t\tif (max_so_far > (x))\t\t\\\n\t\t\tmax_so_far = (x);\t\\\n\t} while (0);\n\n\tif (!bev->rate_limiting)\n\t\treturn max_so_far;\n\n\t/* If rate-limiting is enabled at all, update the appropriate\n\t   bucket, and take the smaller of our rate limit and the group\n\t   rate limit.\n\t */\n\n\tif (bev->rate_limiting->cfg) {\n\t\tbufferevent_update_buckets(bev);\n\t\tmax_so_far = LIM(bev->rate_limiting->limit);\n\t}\n\tif (bev->rate_limiting->group) {\n\t\tstruct bufferevent_rate_limit_group *g =\n\t\t    bev->rate_limiting->group;\n\t\tev_ssize_t share;\n\t\tLOCK_GROUP(g);\n\t\tif (GROUP_SUSPENDED(g)) {\n\t\t\t/* We can get here if we failed to lock this\n\t\t\t * particular bufferevent while suspending the whole\n\t\t\t * group. */\n\t\t\tif (is_write)\n\t\t\t\tbufferevent_suspend_write_(&bev->bev,\n\t\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\telse\n\t\t\t\tbufferevent_suspend_read_(&bev->bev,\n\t\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\tshare = 0;\n\t\t} else {\n\t\t\t/* XXXX probably we should divide among the active\n\t\t\t * members, not the total members. */\n\t\t\tshare = LIM(g->rate_limit) / g->n_members;\n\t\t\tif (share < g->min_share)\n\t\t\t\tshare = g->min_share;\n\t\t}\n\t\tUNLOCK_GROUP(g);\n\t\tCLAMPTO(share);\n\t}\n\n\tif (max_so_far < 0)\n\t\tmax_so_far = 0;\n\treturn max_so_far;\n}\n\nev_ssize_t\nbufferevent_get_read_max_(struct bufferevent_private *bev)\n{\n\treturn bufferevent_get_rlim_max_(bev, 0);\n}\n\nev_ssize_t\nbufferevent_get_write_max_(struct bufferevent_private *bev)\n{\n\treturn bufferevent_get_rlim_max_(bev, 1);\n}\n\nint\nbufferevent_decrement_read_buckets_(struct bufferevent_private *bev, ev_ssize_t bytes)\n{\n\t/* XXXXX Make sure all users of this function check its return value */\n\tint r = 0;\n\t/* need to hold lock on bev */\n\tif (!bev->rate_limiting)\n\t\treturn 0;\n\n\tif (bev->rate_limiting->cfg) {\n\t\tbev->rate_limiting->limit.read_limit -= bytes;\n\t\tif (bev->rate_limiting->limit.read_limit <= 0) {\n\t\t\tbufferevent_suspend_read_(&bev->bev, BEV_SUSPEND_BW);\n\t\t\tif (event_add(&bev->rate_limiting->refill_bucket_event,\n\t\t\t\t&bev->rate_limiting->cfg->tick_timeout) < 0)\n\t\t\t\tr = -1;\n\t\t} else if (bev->read_suspended & BEV_SUSPEND_BW) {\n\t\t\tif (!(bev->write_suspended & BEV_SUSPEND_BW))\n\t\t\t\tevent_del(&bev->rate_limiting->refill_bucket_event);\n\t\t\tbufferevent_unsuspend_read_(&bev->bev, BEV_SUSPEND_BW);\n\t\t}\n\t}\n\n\tif (bev->rate_limiting->group) {\n\t\tLOCK_GROUP(bev->rate_limiting->group);\n\t\tbev->rate_limiting->group->rate_limit.read_limit -= bytes;\n\t\tbev->rate_limiting->group->total_read += bytes;\n\t\tif (bev->rate_limiting->group->rate_limit.read_limit <= 0) {\n\t\t\tbev_group_suspend_reading_(bev->rate_limiting->group);\n\t\t} else if (bev->rate_limiting->group->read_suspended) {\n\t\t\tbev_group_unsuspend_reading_(bev->rate_limiting->group);\n\t\t}\n\t\tUNLOCK_GROUP(bev->rate_limiting->group);\n\t}\n\n\treturn r;\n}\n\nint\nbufferevent_decrement_write_buckets_(struct bufferevent_private *bev, ev_ssize_t bytes)\n{\n\t/* XXXXX Make sure all users of this function check its return value */\n\tint r = 0;\n\t/* need to hold lock */\n\tif (!bev->rate_limiting)\n\t\treturn 0;\n\n\tif (bev->rate_limiting->cfg) {\n\t\tbev->rate_limiting->limit.write_limit -= bytes;\n\t\tif (bev->rate_limiting->limit.write_limit <= 0) {\n\t\t\tbufferevent_suspend_write_(&bev->bev, BEV_SUSPEND_BW);\n\t\t\tif (event_add(&bev->rate_limiting->refill_bucket_event,\n\t\t\t\t&bev->rate_limiting->cfg->tick_timeout) < 0)\n\t\t\t\tr = -1;\n\t\t} else if (bev->write_suspended & BEV_SUSPEND_BW) {\n\t\t\tif (!(bev->read_suspended & BEV_SUSPEND_BW))\n\t\t\t\tevent_del(&bev->rate_limiting->refill_bucket_event);\n\t\t\tbufferevent_unsuspend_write_(&bev->bev, BEV_SUSPEND_BW);\n\t\t}\n\t}\n\n\tif (bev->rate_limiting->group) {\n\t\tLOCK_GROUP(bev->rate_limiting->group);\n\t\tbev->rate_limiting->group->rate_limit.write_limit -= bytes;\n\t\tbev->rate_limiting->group->total_written += bytes;\n\t\tif (bev->rate_limiting->group->rate_limit.write_limit <= 0) {\n\t\t\tbev_group_suspend_writing_(bev->rate_limiting->group);\n\t\t} else if (bev->rate_limiting->group->write_suspended) {\n\t\t\tbev_group_unsuspend_writing_(bev->rate_limiting->group);\n\t\t}\n\t\tUNLOCK_GROUP(bev->rate_limiting->group);\n\t}\n\n\treturn r;\n}\n\n/** Stop reading on every bufferevent in <b>g</b> */\nstatic int\nbev_group_suspend_reading_(struct bufferevent_rate_limit_group *g)\n{\n\t/* Needs group lock */\n\tstruct bufferevent_private *bev;\n\tg->read_suspended = 1;\n\tg->pending_unsuspend_read = 0;\n\n\t/* Note that in this loop we call EVLOCK_TRY_LOCK_ instead of BEV_LOCK,\n\t   to prevent a deadlock.  (Ordinarily, the group lock nests inside\n\t   the bufferevent locks.  If we are unable to lock any individual\n\t   bufferevent, it will find out later when it looks at its limit\n\t   and sees that its group is suspended.)\n\t*/\n\tLIST_FOREACH(bev, &g->members, rate_limiting->next_in_group) {\n\t\tif (EVLOCK_TRY_LOCK_(bev->lock)) {\n\t\t\tbufferevent_suspend_read_(&bev->bev,\n\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\tEVLOCK_UNLOCK(bev->lock, 0);\n\t\t}\n\t}\n\treturn 0;\n}\n\n/** Stop writing on every bufferevent in <b>g</b> */\nstatic int\nbev_group_suspend_writing_(struct bufferevent_rate_limit_group *g)\n{\n\t/* Needs group lock */\n\tstruct bufferevent_private *bev;\n\tg->write_suspended = 1;\n\tg->pending_unsuspend_write = 0;\n\tLIST_FOREACH(bev, &g->members, rate_limiting->next_in_group) {\n\t\tif (EVLOCK_TRY_LOCK_(bev->lock)) {\n\t\t\tbufferevent_suspend_write_(&bev->bev,\n\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\tEVLOCK_UNLOCK(bev->lock, 0);\n\t\t}\n\t}\n\treturn 0;\n}\n\n/** Timer callback invoked on a single bufferevent with one or more exhausted\n    buckets when they are ready to refill. */\nstatic void\nbev_refill_callback_(evutil_socket_t fd, short what, void *arg)\n{\n\tunsigned tick;\n\tstruct timeval now;\n\tstruct bufferevent_private *bev = arg;\n\tint again = 0;\n\tBEV_LOCK(&bev->bev);\n\tif (!bev->rate_limiting || !bev->rate_limiting->cfg) {\n\t\tBEV_UNLOCK(&bev->bev);\n\t\treturn;\n\t}\n\n\t/* First, update the bucket */\n\tevent_base_gettimeofday_cached(bev->bev.ev_base, &now);\n\ttick = ev_token_bucket_get_tick_(&now,\n\t    bev->rate_limiting->cfg);\n\tev_token_bucket_update_(&bev->rate_limiting->limit,\n\t    bev->rate_limiting->cfg,\n\t    tick);\n\n\t/* Now unsuspend any read/write operations as appropriate. */\n\tif ((bev->read_suspended & BEV_SUSPEND_BW)) {\n\t\tif (bev->rate_limiting->limit.read_limit > 0)\n\t\t\tbufferevent_unsuspend_read_(&bev->bev, BEV_SUSPEND_BW);\n\t\telse\n\t\t\tagain = 1;\n\t}\n\tif ((bev->write_suspended & BEV_SUSPEND_BW)) {\n\t\tif (bev->rate_limiting->limit.write_limit > 0)\n\t\t\tbufferevent_unsuspend_write_(&bev->bev, BEV_SUSPEND_BW);\n\t\telse\n\t\t\tagain = 1;\n\t}\n\tif (again) {\n\t\t/* One or more of the buckets may need another refill if they\n\t\t   started negative.\n\n\t\t   XXXX if we need to be quiet for more ticks, we should\n\t\t   maybe figure out what timeout we really want.\n\t\t*/\n\t\t/* XXXX Handle event_add failure somehow */\n\t\tevent_add(&bev->rate_limiting->refill_bucket_event,\n\t\t    &bev->rate_limiting->cfg->tick_timeout);\n\t}\n\tBEV_UNLOCK(&bev->bev);\n}\n\n/** Helper: grab a random element from a bufferevent group.\n *\n * Requires that we hold the lock on the group.\n */\nstatic struct bufferevent_private *\nbev_group_random_element_(struct bufferevent_rate_limit_group *group)\n{\n\tint which;\n\tstruct bufferevent_private *bev;\n\n\t/* requires group lock */\n\n\tif (!group->n_members)\n\t\treturn NULL;\n\n\tEVUTIL_ASSERT(! LIST_EMPTY(&group->members));\n\n\twhich = evutil_weakrand_range_(&group->weakrand_seed, group->n_members);\n\n\tbev = LIST_FIRST(&group->members);\n\twhile (which--)\n\t\tbev = LIST_NEXT(bev, rate_limiting->next_in_group);\n\n\treturn bev;\n}\n\n/** Iterate over the elements of a rate-limiting group 'g' with a random\n    starting point, assigning each to the variable 'bev', and executing the\n    block 'block'.\n\n    We do this in a half-baked effort to get fairness among group members.\n    XXX Round-robin or some kind of priority queue would be even more fair.\n */\n#define FOREACH_RANDOM_ORDER(block)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\tfirst = bev_group_random_element_(g);\t\\\n\t\tfor (bev = first; bev != LIST_END(&g->members); \\\n\t\t    bev = LIST_NEXT(bev, rate_limiting->next_in_group)) { \\\n\t\t\tblock ;\t\t\t\t\t \\\n\t\t}\t\t\t\t\t\t \\\n\t\tfor (bev = LIST_FIRST(&g->members); bev && bev != first; \\\n\t\t    bev = LIST_NEXT(bev, rate_limiting->next_in_group)) { \\\n\t\t\tblock ;\t\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\nstatic void\nbev_group_unsuspend_reading_(struct bufferevent_rate_limit_group *g)\n{\n\tint again = 0;\n\tstruct bufferevent_private *bev, *first;\n\n\tg->read_suspended = 0;\n\tFOREACH_RANDOM_ORDER({\n\t\tif (EVLOCK_TRY_LOCK_(bev->lock)) {\n\t\t\tbufferevent_unsuspend_read_(&bev->bev,\n\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\tEVLOCK_UNLOCK(bev->lock, 0);\n\t\t} else {\n\t\t\tagain = 1;\n\t\t}\n\t});\n\tg->pending_unsuspend_read = again;\n}\n\nstatic void\nbev_group_unsuspend_writing_(struct bufferevent_rate_limit_group *g)\n{\n\tint again = 0;\n\tstruct bufferevent_private *bev, *first;\n\tg->write_suspended = 0;\n\n\tFOREACH_RANDOM_ORDER({\n\t\tif (EVLOCK_TRY_LOCK_(bev->lock)) {\n\t\t\tbufferevent_unsuspend_write_(&bev->bev,\n\t\t\t    BEV_SUSPEND_BW_GROUP);\n\t\t\tEVLOCK_UNLOCK(bev->lock, 0);\n\t\t} else {\n\t\t\tagain = 1;\n\t\t}\n\t});\n\tg->pending_unsuspend_write = again;\n}\n\n/** Callback invoked every tick to add more elements to the group bucket\n    and unsuspend group members as needed.\n */\nstatic void\nbev_group_refill_callback_(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct bufferevent_rate_limit_group *g = arg;\n\tunsigned tick;\n\tstruct timeval now;\n\n\tevent_base_gettimeofday_cached(event_get_base(&g->master_refill_event), &now);\n\n\tLOCK_GROUP(g);\n\n\ttick = ev_token_bucket_get_tick_(&now, &g->rate_limit_cfg);\n\tev_token_bucket_update_(&g->rate_limit, &g->rate_limit_cfg, tick);\n\n\tif (g->pending_unsuspend_read ||\n\t    (g->read_suspended && (g->rate_limit.read_limit >= g->min_share))) {\n\t\tbev_group_unsuspend_reading_(g);\n\t}\n\tif (g->pending_unsuspend_write ||\n\t    (g->write_suspended && (g->rate_limit.write_limit >= g->min_share))){\n\t\tbev_group_unsuspend_writing_(g);\n\t}\n\n\t/* XXXX Rather than waiting to the next tick to unsuspend stuff\n\t * with pending_unsuspend_write/read, we should do it on the\n\t * next iteration of the mainloop.\n\t */\n\n\tUNLOCK_GROUP(g);\n}\n\nint\nbufferevent_set_rate_limit(struct bufferevent *bev,\n    struct ev_token_bucket_cfg *cfg)\n{\n\tstruct bufferevent_private *bevp = BEV_UPCAST(bev);\n\tint r = -1;\n\tstruct bufferevent_rate_limit *rlim;\n\tstruct timeval now;\n\tev_uint32_t tick;\n\tint reinit = 0, suspended = 0;\n\t/* XXX reference-count cfg */\n\n\tBEV_LOCK(bev);\n\n\tif (cfg == NULL) {\n\t\tif (bevp->rate_limiting) {\n\t\t\trlim = bevp->rate_limiting;\n\t\t\trlim->cfg = NULL;\n\t\t\tbufferevent_unsuspend_read_(bev, BEV_SUSPEND_BW);\n\t\t\tbufferevent_unsuspend_write_(bev, BEV_SUSPEND_BW);\n\t\t\tif (event_initialized(&rlim->refill_bucket_event))\n\t\t\t\tevent_del(&rlim->refill_bucket_event);\n\t\t}\n\t\tr = 0;\n\t\tgoto done;\n\t}\n\n\tevent_base_gettimeofday_cached(bev->ev_base, &now);\n\ttick = ev_token_bucket_get_tick_(&now, cfg);\n\n\tif (bevp->rate_limiting && bevp->rate_limiting->cfg == cfg) {\n\t\t/* no-op */\n\t\tr = 0;\n\t\tgoto done;\n\t}\n\tif (bevp->rate_limiting == NULL) {\n\t\trlim = mm_calloc(1, sizeof(struct bufferevent_rate_limit));\n\t\tif (!rlim)\n\t\t\tgoto done;\n\t\tbevp->rate_limiting = rlim;\n\t} else {\n\t\trlim = bevp->rate_limiting;\n\t}\n\treinit = rlim->cfg != NULL;\n\n\trlim->cfg = cfg;\n\tev_token_bucket_init_(&rlim->limit, cfg, tick, reinit);\n\n\tif (reinit) {\n\t\tEVUTIL_ASSERT(event_initialized(&rlim->refill_bucket_event));\n\t\tevent_del(&rlim->refill_bucket_event);\n\t}\n\tevent_assign(&rlim->refill_bucket_event, bev->ev_base,\n\t    -1, EV_FINALIZE, bev_refill_callback_, bevp);\n\n\tif (rlim->limit.read_limit > 0) {\n\t\tbufferevent_unsuspend_read_(bev, BEV_SUSPEND_BW);\n\t} else {\n\t\tbufferevent_suspend_read_(bev, BEV_SUSPEND_BW);\n\t\tsuspended=1;\n\t}\n\tif (rlim->limit.write_limit > 0) {\n\t\tbufferevent_unsuspend_write_(bev, BEV_SUSPEND_BW);\n\t} else {\n\t\tbufferevent_suspend_write_(bev, BEV_SUSPEND_BW);\n\t\tsuspended = 1;\n\t}\n\n\tif (suspended)\n\t\tevent_add(&rlim->refill_bucket_event, &cfg->tick_timeout);\n\n\tr = 0;\n\ndone:\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nstruct bufferevent_rate_limit_group *\nbufferevent_rate_limit_group_new(struct event_base *base,\n    const struct ev_token_bucket_cfg *cfg)\n{\n\tstruct bufferevent_rate_limit_group *g;\n\tstruct timeval now;\n\tev_uint32_t tick;\n\n\tevent_base_gettimeofday_cached(base, &now);\n\ttick = ev_token_bucket_get_tick_(&now, cfg);\n\n\tg = mm_calloc(1, sizeof(struct bufferevent_rate_limit_group));\n\tif (!g)\n\t\treturn NULL;\n\tmemcpy(&g->rate_limit_cfg, cfg, sizeof(g->rate_limit_cfg));\n\tLIST_INIT(&g->members);\n\n\tev_token_bucket_init_(&g->rate_limit, cfg, tick, 0);\n\n\tevent_assign(&g->master_refill_event, base, -1, EV_PERSIST|EV_FINALIZE,\n\t    bev_group_refill_callback_, g);\n\t/*XXXX handle event_add failure */\n\tevent_add(&g->master_refill_event, &cfg->tick_timeout);\n\n\tEVTHREAD_ALLOC_LOCK(g->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\n\tbufferevent_rate_limit_group_set_min_share(g, 64);\n\n\tevutil_weakrand_seed_(&g->weakrand_seed,\n\t    (ev_uint32_t) ((now.tv_sec + now.tv_usec) + (ev_intptr_t)g));\n\n\treturn g;\n}\n\nint\nbufferevent_rate_limit_group_set_cfg(\n\tstruct bufferevent_rate_limit_group *g,\n\tconst struct ev_token_bucket_cfg *cfg)\n{\n\tint same_tick;\n\tif (!g || !cfg)\n\t\treturn -1;\n\n\tLOCK_GROUP(g);\n\tsame_tick = evutil_timercmp(\n\t\t&g->rate_limit_cfg.tick_timeout, &cfg->tick_timeout, ==);\n\tmemcpy(&g->rate_limit_cfg, cfg, sizeof(g->rate_limit_cfg));\n\n\tif (g->rate_limit.read_limit > (ev_ssize_t)cfg->read_maximum)\n\t\tg->rate_limit.read_limit = cfg->read_maximum;\n\tif (g->rate_limit.write_limit > (ev_ssize_t)cfg->write_maximum)\n\t\tg->rate_limit.write_limit = cfg->write_maximum;\n\n\tif (!same_tick) {\n\t\t/* This can cause a hiccup in the schedule */\n\t\tevent_add(&g->master_refill_event, &cfg->tick_timeout);\n\t}\n\n\t/* The new limits might force us to adjust min_share differently. */\n\tbufferevent_rate_limit_group_set_min_share(g, g->configured_min_share);\n\n\tUNLOCK_GROUP(g);\n\treturn 0;\n}\n\nint\nbufferevent_rate_limit_group_set_min_share(\n\tstruct bufferevent_rate_limit_group *g,\n\tsize_t share)\n{\n\tif (share > EV_SSIZE_MAX)\n\t\treturn -1;\n\n\tg->configured_min_share = share;\n\n\t/* Can't set share to less than the one-tick maximum.  IOW, at steady\n\t * state, at least one connection can go per tick. */\n\tif (share > g->rate_limit_cfg.read_rate)\n\t\tshare = g->rate_limit_cfg.read_rate;\n\tif (share > g->rate_limit_cfg.write_rate)\n\t\tshare = g->rate_limit_cfg.write_rate;\n\n\tg->min_share = share;\n\treturn 0;\n}\n\nvoid\nbufferevent_rate_limit_group_free(struct bufferevent_rate_limit_group *g)\n{\n\tLOCK_GROUP(g);\n\tEVUTIL_ASSERT(0 == g->n_members);\n\tevent_del(&g->master_refill_event);\n\tUNLOCK_GROUP(g);\n\tEVTHREAD_FREE_LOCK(g->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\tmm_free(g);\n}\n\nint\nbufferevent_add_to_rate_limit_group(struct bufferevent *bev,\n    struct bufferevent_rate_limit_group *g)\n{\n\tint wsuspend, rsuspend;\n\tstruct bufferevent_private *bevp = BEV_UPCAST(bev);\n\tBEV_LOCK(bev);\n\n\tif (!bevp->rate_limiting) {\n\t\tstruct bufferevent_rate_limit *rlim;\n\t\trlim = mm_calloc(1, sizeof(struct bufferevent_rate_limit));\n\t\tif (!rlim) {\n\t\t\tBEV_UNLOCK(bev);\n\t\t\treturn -1;\n\t\t}\n\t\tevent_assign(&rlim->refill_bucket_event, bev->ev_base,\n\t\t    -1, EV_FINALIZE, bev_refill_callback_, bevp);\n\t\tbevp->rate_limiting = rlim;\n\t}\n\n\tif (bevp->rate_limiting->group == g) {\n\t\tBEV_UNLOCK(bev);\n\t\treturn 0;\n\t}\n\tif (bevp->rate_limiting->group)\n\t\tbufferevent_remove_from_rate_limit_group(bev);\n\n\tLOCK_GROUP(g);\n\tbevp->rate_limiting->group = g;\n\t++g->n_members;\n\tLIST_INSERT_HEAD(&g->members, bevp, rate_limiting->next_in_group);\n\n\trsuspend = g->read_suspended;\n\twsuspend = g->write_suspended;\n\n\tUNLOCK_GROUP(g);\n\n\tif (rsuspend)\n\t\tbufferevent_suspend_read_(bev, BEV_SUSPEND_BW_GROUP);\n\tif (wsuspend)\n\t\tbufferevent_suspend_write_(bev, BEV_SUSPEND_BW_GROUP);\n\n\tBEV_UNLOCK(bev);\n\treturn 0;\n}\n\nint\nbufferevent_remove_from_rate_limit_group(struct bufferevent *bev)\n{\n\treturn bufferevent_remove_from_rate_limit_group_internal_(bev, 1);\n}\n\nint\nbufferevent_remove_from_rate_limit_group_internal_(struct bufferevent *bev,\n    int unsuspend)\n{\n\tstruct bufferevent_private *bevp = BEV_UPCAST(bev);\n\tBEV_LOCK(bev);\n\tif (bevp->rate_limiting && bevp->rate_limiting->group) {\n\t\tstruct bufferevent_rate_limit_group *g =\n\t\t    bevp->rate_limiting->group;\n\t\tLOCK_GROUP(g);\n\t\tbevp->rate_limiting->group = NULL;\n\t\t--g->n_members;\n\t\tLIST_REMOVE(bevp, rate_limiting->next_in_group);\n\t\tUNLOCK_GROUP(g);\n\t}\n\tif (unsuspend) {\n\t\tbufferevent_unsuspend_read_(bev, BEV_SUSPEND_BW_GROUP);\n\t\tbufferevent_unsuspend_write_(bev, BEV_SUSPEND_BW_GROUP);\n\t}\n\tBEV_UNLOCK(bev);\n\treturn 0;\n}\n\n/* ===\n * API functions to expose rate limits.\n *\n * Don't use these from inside Libevent; they're meant to be for use by\n * the program.\n * === */\n\n/* Mostly you don't want to use this function from inside libevent;\n * bufferevent_get_read_max_() is more likely what you want*/\nev_ssize_t\nbufferevent_get_read_limit(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\tstruct bufferevent_private *bevp;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tif (bevp->rate_limiting && bevp->rate_limiting->cfg) {\n\t\tbufferevent_update_buckets(bevp);\n\t\tr = bevp->rate_limiting->limit.read_limit;\n\t} else {\n\t\tr = EV_SSIZE_MAX;\n\t}\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\n/* Mostly you don't want to use this function from inside libevent;\n * bufferevent_get_write_max_() is more likely what you want*/\nev_ssize_t\nbufferevent_get_write_limit(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\tstruct bufferevent_private *bevp;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tif (bevp->rate_limiting && bevp->rate_limiting->cfg) {\n\t\tbufferevent_update_buckets(bevp);\n\t\tr = bevp->rate_limiting->limit.write_limit;\n\t} else {\n\t\tr = EV_SSIZE_MAX;\n\t}\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nint\nbufferevent_set_max_single_read(struct bufferevent *bev, size_t size)\n{\n\tstruct bufferevent_private *bevp;\n\tint ret = 0;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tif (size == 0 || size > EV_SSIZE_MAX)\n\t\tbevp->max_single_read = MAX_SINGLE_READ_DEFAULT;\n\telse\n\t\tbevp->max_single_read = size;\n\tret = evbuffer_set_max_read(bev->input, bevp->max_single_read);\n\tBEV_UNLOCK(bev);\n\treturn ret;\n}\n\nint\nbufferevent_set_max_single_write(struct bufferevent *bev, size_t size)\n{\n\tstruct bufferevent_private *bevp;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tif (size == 0 || size > EV_SSIZE_MAX)\n\t\tbevp->max_single_write = MAX_SINGLE_WRITE_DEFAULT;\n\telse\n\t\tbevp->max_single_write = size;\n\tBEV_UNLOCK(bev);\n\treturn 0;\n}\n\nev_ssize_t\nbufferevent_get_max_single_read(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\n\tBEV_LOCK(bev);\n\tr = BEV_UPCAST(bev)->max_single_read;\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nev_ssize_t\nbufferevent_get_max_single_write(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\n\tBEV_LOCK(bev);\n\tr = BEV_UPCAST(bev)->max_single_write;\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nev_ssize_t\nbufferevent_get_max_to_read(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\tBEV_LOCK(bev);\n\tr = bufferevent_get_read_max_(BEV_UPCAST(bev));\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nev_ssize_t\nbufferevent_get_max_to_write(struct bufferevent *bev)\n{\n\tev_ssize_t r;\n\tBEV_LOCK(bev);\n\tr = bufferevent_get_write_max_(BEV_UPCAST(bev));\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nconst struct ev_token_bucket_cfg *\nbufferevent_get_token_bucket_cfg(const struct bufferevent *bev) {\n\tstruct bufferevent_private *bufev_private = BEV_UPCAST(bev);\n\tstruct ev_token_bucket_cfg *cfg;\n\n\tBEV_LOCK(bev);\n\n\tif (bufev_private->rate_limiting) {\n\t\tcfg = bufev_private->rate_limiting->cfg;\n\t} else {\n\t\tcfg = NULL;\n\t}\n\n\tBEV_UNLOCK(bev);\n\n\treturn cfg;\n}\n\n/* Mostly you don't want to use this function from inside libevent;\n * bufferevent_get_read_max_() is more likely what you want*/\nev_ssize_t\nbufferevent_rate_limit_group_get_read_limit(\n\tstruct bufferevent_rate_limit_group *grp)\n{\n\tev_ssize_t r;\n\tLOCK_GROUP(grp);\n\tr = grp->rate_limit.read_limit;\n\tUNLOCK_GROUP(grp);\n\treturn r;\n}\n\n/* Mostly you don't want to use this function from inside libevent;\n * bufferevent_get_write_max_() is more likely what you want. */\nev_ssize_t\nbufferevent_rate_limit_group_get_write_limit(\n\tstruct bufferevent_rate_limit_group *grp)\n{\n\tev_ssize_t r;\n\tLOCK_GROUP(grp);\n\tr = grp->rate_limit.write_limit;\n\tUNLOCK_GROUP(grp);\n\treturn r;\n}\n\nint\nbufferevent_decrement_read_limit(struct bufferevent *bev, ev_ssize_t decr)\n{\n\tint r = 0;\n\tev_ssize_t old_limit, new_limit;\n\tstruct bufferevent_private *bevp;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tEVUTIL_ASSERT(bevp->rate_limiting && bevp->rate_limiting->cfg);\n\told_limit = bevp->rate_limiting->limit.read_limit;\n\n\tnew_limit = (bevp->rate_limiting->limit.read_limit -= decr);\n\tif (old_limit > 0 && new_limit <= 0) {\n\t\tbufferevent_suspend_read_(bev, BEV_SUSPEND_BW);\n\t\tif (event_add(&bevp->rate_limiting->refill_bucket_event,\n\t\t\t&bevp->rate_limiting->cfg->tick_timeout) < 0)\n\t\t\tr = -1;\n\t} else if (old_limit <= 0 && new_limit > 0) {\n\t\tif (!(bevp->write_suspended & BEV_SUSPEND_BW))\n\t\t\tevent_del(&bevp->rate_limiting->refill_bucket_event);\n\t\tbufferevent_unsuspend_read_(bev, BEV_SUSPEND_BW);\n\t}\n\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nint\nbufferevent_decrement_write_limit(struct bufferevent *bev, ev_ssize_t decr)\n{\n\t/* XXXX this is mostly copy-and-paste from\n\t * bufferevent_decrement_read_limit */\n\tint r = 0;\n\tev_ssize_t old_limit, new_limit;\n\tstruct bufferevent_private *bevp;\n\tBEV_LOCK(bev);\n\tbevp = BEV_UPCAST(bev);\n\tEVUTIL_ASSERT(bevp->rate_limiting && bevp->rate_limiting->cfg);\n\told_limit = bevp->rate_limiting->limit.write_limit;\n\n\tnew_limit = (bevp->rate_limiting->limit.write_limit -= decr);\n\tif (old_limit > 0 && new_limit <= 0) {\n\t\tbufferevent_suspend_write_(bev, BEV_SUSPEND_BW);\n\t\tif (event_add(&bevp->rate_limiting->refill_bucket_event,\n\t\t\t&bevp->rate_limiting->cfg->tick_timeout) < 0)\n\t\t\tr = -1;\n\t} else if (old_limit <= 0 && new_limit > 0) {\n\t\tif (!(bevp->read_suspended & BEV_SUSPEND_BW))\n\t\t\tevent_del(&bevp->rate_limiting->refill_bucket_event);\n\t\tbufferevent_unsuspend_write_(bev, BEV_SUSPEND_BW);\n\t}\n\n\tBEV_UNLOCK(bev);\n\treturn r;\n}\n\nint\nbufferevent_rate_limit_group_decrement_read(\n\tstruct bufferevent_rate_limit_group *grp, ev_ssize_t decr)\n{\n\tint r = 0;\n\tev_ssize_t old_limit, new_limit;\n\tLOCK_GROUP(grp);\n\told_limit = grp->rate_limit.read_limit;\n\tnew_limit = (grp->rate_limit.read_limit -= decr);\n\n\tif (old_limit > 0 && new_limit <= 0) {\n\t\tbev_group_suspend_reading_(grp);\n\t} else if (old_limit <= 0 && new_limit > 0) {\n\t\tbev_group_unsuspend_reading_(grp);\n\t}\n\n\tUNLOCK_GROUP(grp);\n\treturn r;\n}\n\nint\nbufferevent_rate_limit_group_decrement_write(\n\tstruct bufferevent_rate_limit_group *grp, ev_ssize_t decr)\n{\n\tint r = 0;\n\tev_ssize_t old_limit, new_limit;\n\tLOCK_GROUP(grp);\n\told_limit = grp->rate_limit.write_limit;\n\tnew_limit = (grp->rate_limit.write_limit -= decr);\n\n\tif (old_limit > 0 && new_limit <= 0) {\n\t\tbev_group_suspend_writing_(grp);\n\t} else if (old_limit <= 0 && new_limit > 0) {\n\t\tbev_group_unsuspend_writing_(grp);\n\t}\n\n\tUNLOCK_GROUP(grp);\n\treturn r;\n}\n\nvoid\nbufferevent_rate_limit_group_get_totals(struct bufferevent_rate_limit_group *grp,\n    ev_uint64_t *total_read_out, ev_uint64_t *total_written_out)\n{\n\tEVUTIL_ASSERT(grp != NULL);\n\tif (total_read_out)\n\t\t*total_read_out = grp->total_read;\n\tif (total_written_out)\n\t\t*total_written_out = grp->total_written;\n}\n\nvoid\nbufferevent_rate_limit_group_reset_totals(struct bufferevent_rate_limit_group *grp)\n{\n\tgrp->total_read = grp->total_written = 0;\n}\n\nint\nbufferevent_ratelim_init_(struct bufferevent_private *bev)\n{\n\tbev->rate_limiting = NULL;\n\tbev->max_single_read = MAX_SINGLE_READ_DEFAULT;\n\tbev->max_single_write = MAX_SINGLE_WRITE_DEFAULT;\n\n\tif (evbuffer_set_max_read(bev->bev.input, bev->max_single_read))\n\t\treturn -1;\n\n\treturn 0;\n}\n"
        },
        {
          "name": "bufferevent_sock.c",
          "type": "blob",
          "size": 18.375,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n * Copyright (c) 2002-2006 Niels Provos <provos@citi.umich.edu>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/bufferevent_compat.h\"\n#include \"event2/event.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"util-internal.h\"\n#ifdef _WIN32\n#include \"iocp-internal.h\"\n#endif\n\n/* prototypes */\nstatic int be_socket_enable(struct bufferevent *, short);\nstatic int be_socket_disable(struct bufferevent *, short);\nstatic void be_socket_destruct(struct bufferevent *);\nstatic int be_socket_flush(struct bufferevent *, short, enum bufferevent_flush_mode);\nstatic int be_socket_ctrl(struct bufferevent *, enum bufferevent_ctrl_op, union bufferevent_ctrl_data *);\n\nstatic void be_socket_setfd(struct bufferevent *, evutil_socket_t);\n\nconst struct bufferevent_ops bufferevent_ops_socket = {\n\t\"socket\",\n\tevutil_offsetof(struct bufferevent_private, bev),\n\tbe_socket_enable,\n\tbe_socket_disable,\n\tNULL, /* unlink */\n\tbe_socket_destruct,\n\tbufferevent_generic_adj_existing_timeouts_,\n\tbe_socket_flush,\n\tbe_socket_ctrl,\n};\n\nconst struct sockaddr*\nbufferevent_socket_get_conn_address_(struct bufferevent *bev)\n{\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\treturn (struct sockaddr *)&bev_p->conn_address;\n}\n\nvoid\nbufferevent_socket_set_conn_address_fd_(struct bufferevent *bev,\n\tevutil_socket_t fd)\n{\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\n\tsocklen_t len = sizeof(bev_p->conn_address);\n\n\tstruct sockaddr *addr = (struct sockaddr *)&bev_p->conn_address;\n\tif (addr->sa_family != AF_UNSPEC)\n\t\tgetpeername(fd, addr, &len);\n}\n\nvoid\nbufferevent_socket_set_conn_address_(struct bufferevent *bev,\n\tstruct sockaddr *addr, size_t addrlen)\n{\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\tEVUTIL_ASSERT(addrlen <= sizeof(bev_p->conn_address));\n\tmemcpy(&bev_p->conn_address, addr, addrlen);\n}\n\nstatic void\nbufferevent_socket_outbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo,\n    void *arg)\n{\n\tstruct bufferevent *bufev = arg;\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\n\tif (cbinfo->n_added &&\n\t    (bufev->enabled & EV_WRITE) &&\n\t    !event_pending(&bufev->ev_write, EV_WRITE, NULL) &&\n\t    !bufev_p->write_suspended) {\n\t\t/* Somebody added data to the buffer, and we would like to\n\t\t * write, and we were not writing.  So, start writing. */\n\t\tif (bufferevent_add_event_(&bufev->ev_write, &bufev->timeout_write) == -1) {\n\t\t    /* Should we log this? */\n\t\t}\n\t}\n}\n\nstatic void\nbufferevent_readcb(evutil_socket_t fd, short event, void *arg)\n{\n\tstruct bufferevent *bufev = arg;\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\tstruct evbuffer *input;\n\tint res = 0;\n\tshort what = BEV_EVENT_READING;\n\tev_ssize_t howmuch = -1, readmax=-1;\n\n\tbufferevent_incref_and_lock_(bufev);\n\n\tif (event == EV_TIMEOUT) {\n\t\t/* Note that we only check for event==EV_TIMEOUT. If\n\t\t * event==EV_TIMEOUT|EV_READ, we can safely ignore the\n\t\t * timeout, since a read has occurred */\n\t\twhat |= BEV_EVENT_TIMEOUT;\n\t\tgoto error;\n\t}\n\n\tinput = bufev->input;\n\n\t/*\n\t * If we have a high watermark configured then we don't want to\n\t * read more data than would make us reach the watermark.\n\t */\n\tif (bufev->wm_read.high != 0) {\n\t\thowmuch = bufev->wm_read.high - evbuffer_get_length(input);\n\t\t/* we somehow lowered the watermark, stop reading */\n\t\tif (howmuch <= 0) {\n\t\t\tbufferevent_wm_suspend_read(bufev);\n\t\t\tgoto done;\n\t\t}\n\t}\n\treadmax = bufferevent_get_read_max_(bufev_p);\n\tif (howmuch < 0 || howmuch > readmax) /* The use of -1 for \"unlimited\"\n\t\t\t\t\t       * uglifies this code. XXXX */\n\t\thowmuch = readmax;\n\tif (bufev_p->read_suspended)\n\t\tgoto done;\n\n\tevbuffer_unfreeze(input, 0);\n\tres = evbuffer_read(input, fd, (int)howmuch); /* XXXX evbuffer_read would do better to take and return ev_ssize_t */\n\tevbuffer_freeze(input, 0);\n\n\tif (res == -1) {\n\t\tint err = evutil_socket_geterror(fd);\n\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\tgoto reschedule;\n\t\t/* NOTE: sometimes on FreeBSD 9.2 the connect() does not returns an\n\t\t * error, and instead, first readv() will */\n\t\tif (EVUTIL_ERR_CONNECT_REFUSED(err)) {\n\t\t\tbufev_p->connection_refused = 1;\n\t\t\tgoto done;\n\t\t}\n\t\t/* error case */\n\t\twhat |= BEV_EVENT_ERROR;\n\t} else if (res == 0) {\n\t\t/* eof case */\n\t\twhat |= BEV_EVENT_EOF;\n\t}\n\n\tif (res <= 0)\n\t\tgoto error;\n\n\tbufferevent_decrement_read_buckets_(bufev_p, res);\n\n\t/* Invoke the user callback - must always be called last */\n\tbufferevent_trigger_nolock_(bufev, EV_READ, 0);\n\n\tgoto done;\n\n reschedule:\n\tgoto done;\n\n error:\n\tbufferevent_disable(bufev, EV_READ);\n\tbufferevent_run_eventcb_(bufev, what, 0);\n\n done:\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nstatic void\nbufferevent_writecb(evutil_socket_t fd, short event, void *arg)\n{\n\tstruct bufferevent *bufev = arg;\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\tint res = 0;\n\tshort what = BEV_EVENT_WRITING;\n\tint connected = 0;\n\tev_ssize_t atmost = -1;\n\n\tbufferevent_incref_and_lock_(bufev);\n\n\tif (event == EV_TIMEOUT) {\n\t\t/* Note that we only check for event==EV_TIMEOUT. If\n\t\t * event==EV_TIMEOUT|EV_WRITE, we can safely ignore the\n\t\t * timeout, since a read has occurred */\n\t\twhat |= BEV_EVENT_TIMEOUT;\n\t\tgoto error;\n\t}\n\tif (bufev_p->connecting) {\n\t\tint c = evutil_socket_finished_connecting_(fd);\n\t\t/* we need to fake the error if the connection was refused\n\t\t * immediately - usually connection to localhost on BSD */\n\t\tif (bufev_p->connection_refused) {\n\t\t\tbufev_p->connection_refused = 0;\n\t\t\tc = -1;\n\t\t}\n\n\t\tif (c == 0)\n\t\t\tgoto done;\n\n\t\tbufev_p->connecting = 0;\n\t\tif (c < 0) {\n\t\t\tevent_del(&bufev->ev_write);\n\t\t\tevent_del(&bufev->ev_read);\n\t\t\tbufferevent_run_eventcb_(bufev, BEV_EVENT_ERROR, 0);\n\t\t\tgoto done;\n\t\t} else {\n\t\t\tconnected = 1;\n\t\t\tbufferevent_socket_set_conn_address_fd_(bufev, fd);\n#ifdef _WIN32\n\t\t\tif (BEV_IS_ASYNC(bufev)) {\n\t\t\t\tevent_del(&bufev->ev_write);\n\t\t\t\tbufferevent_async_set_connected_(bufev);\n\t\t\t\tbufferevent_run_eventcb_(bufev,\n\t\t\t\t\t\tBEV_EVENT_CONNECTED, 0);\n\t\t\t\tgoto done;\n\t\t\t}\n#endif\n\t\t\tbufferevent_run_eventcb_(bufev,\n\t\t\t\t\tBEV_EVENT_CONNECTED, 0);\n\t\t\tif (!(bufev->enabled & EV_WRITE) ||\n\t\t\t    bufev_p->write_suspended) {\n\t\t\t\tevent_del(&bufev->ev_write);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\n\tatmost = bufferevent_get_write_max_(bufev_p);\n\n\tif (bufev_p->write_suspended)\n\t\tgoto done;\n\n\tif (evbuffer_get_length(bufev->output)) {\n\t\tevbuffer_unfreeze(bufev->output, 1);\n\t\tres = evbuffer_write_atmost(bufev->output, fd, atmost);\n\t\tevbuffer_freeze(bufev->output, 1);\n\t\tif (res == -1) {\n\t\t\tint err = evutil_socket_geterror(fd);\n\t\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\t\tgoto reschedule;\n\t\t\twhat |= BEV_EVENT_ERROR;\n\t\t} else if (res == 0) {\n\t\t\t/* eof case\n\t\t\t   XXXX Actually, a 0 on write doesn't indicate\n\t\t\t   an EOF. An ECONNRESET might be more typical.\n\t\t\t */\n\t\t\twhat |= BEV_EVENT_EOF;\n\t\t}\n\t\tif (res <= 0)\n\t\t\tgoto error;\n\n\t\tbufferevent_decrement_write_buckets_(bufev_p, res);\n\t}\n\n\tif (evbuffer_get_length(bufev->output) == 0) {\n\t\tevent_del(&bufev->ev_write);\n\t}\n\n\t/*\n\t * Invoke the user callback if our buffer is drained or below the\n\t * low watermark.\n\t */\n\tif (res || !connected) {\n\t\tbufferevent_trigger_nolock_(bufev, EV_WRITE, 0);\n\t}\n\n\tgoto done;\n\n reschedule:\n\tif (evbuffer_get_length(bufev->output) == 0) {\n\t\tevent_del(&bufev->ev_write);\n\t}\n\tgoto done;\n\n error:\n\tbufferevent_disable(bufev, EV_WRITE);\n\tbufferevent_run_eventcb_(bufev, what, 0);\n\n done:\n\tbufferevent_decref_and_unlock_(bufev);\n}\n\nstruct bufferevent *\nbufferevent_socket_new(struct event_base *base, evutil_socket_t fd,\n    int options)\n{\n\tstruct bufferevent_private *bufev_p;\n\tstruct bufferevent *bufev;\n\n#ifdef _WIN32\n\tif (base && event_base_get_iocp_(base))\n\t\treturn bufferevent_async_new_(base, fd, options);\n#endif\n\n\tif ((bufev_p = mm_calloc(1, sizeof(struct bufferevent_private)))== NULL)\n\t\treturn NULL;\n\n\tif (bufferevent_init_common_(bufev_p, base, &bufferevent_ops_socket,\n\t\t\t\t    options) < 0) {\n\t\tmm_free(bufev_p);\n\t\treturn NULL;\n\t}\n\tbufev = &bufev_p->bev;\n\tevbuffer_set_flags(bufev->output, EVBUFFER_FLAG_DRAINS_TO_FD);\n\n\tevent_assign(&bufev->ev_read, bufev->ev_base, fd,\n\t    EV_READ|EV_PERSIST|EV_FINALIZE, bufferevent_readcb, bufev);\n\tevent_assign(&bufev->ev_write, bufev->ev_base, fd,\n\t    EV_WRITE|EV_PERSIST|EV_FINALIZE, bufferevent_writecb, bufev);\n\n\tevbuffer_add_cb(bufev->output, bufferevent_socket_outbuf_cb, bufev);\n\n\tevbuffer_freeze(bufev->input, 0);\n\tevbuffer_freeze(bufev->output, 1);\n\n\treturn bufev;\n}\n\nint\nbufferevent_socket_connect(struct bufferevent *bev,\n    const struct sockaddr *sa, int socklen)\n{\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bev);\n\n\tevutil_socket_t fd;\n\tint r = 0;\n\tint result=-1;\n\tint ownfd = 0;\n\n\tbufferevent_incref_and_lock_(bev);\n\n\tfd = bufferevent_getfd(bev);\n\tif (fd < 0) {\n\t\tif (!sa)\n\t\t\tgoto done;\n\t\tfd = evutil_socket_(sa->sa_family,\n\t\t    SOCK_STREAM|EVUTIL_SOCK_NONBLOCK, 0);\n\t\tif (fd < 0)\n\t\t\tgoto done;\n\t\townfd = 1;\n\t}\n\tif (sa) {\n#ifdef _WIN32\n\t\tif (bufferevent_async_can_connect_(bev)) {\n\t\t\tbufferevent_setfd(bev, fd);\n\t\t\tr = bufferevent_async_connect_(bev, fd, sa, socklen);\n\t\t\tif (r < 0)\n\t\t\t\tgoto freesock;\n\t\t\tbufev_p->connecting = 1;\n\t\t\tresult = 0;\n\t\t\tgoto done;\n\t\t} else {\n#endif\n\t\tr = evutil_socket_connect_(&fd, sa, socklen);\n\t\tif (r < 0)\n\t\t\tgoto freesock;\n#ifdef _WIN32\n\t\t}\n#endif\n\t}\n#ifdef _WIN32\n\t/* ConnectEx() isn't always around, even when IOCP is enabled.\n\t * Here, we borrow the socket object's write handler to fall back\n\t * on a non-blocking connect() when ConnectEx() is unavailable. */\n\tif (BEV_IS_ASYNC(bev)) {\n\t\tevent_assign(&bev->ev_write, bev->ev_base, fd,\n\t\t    EV_WRITE|EV_PERSIST|EV_FINALIZE, bufferevent_writecb, bev);\n\t}\n#endif\n\tbufferevent_setfd(bev, fd);\n\tif (r == 0) {\n\t\tif (! be_socket_enable(bev, EV_WRITE)) {\n\t\t\tbufev_p->connecting = 1;\n\t\t\tresult = 0;\n\t\t\tgoto done;\n\t\t}\n\t} else if (r == 1) {\n\t\t/* The connect succeeded already. How very BSD of it. */\n\t\tresult = 0;\n\t\tbufev_p->connecting = 1;\n\t\tbufferevent_trigger_nolock_(bev, EV_WRITE, BEV_OPT_DEFER_CALLBACKS);\n\t} else {\n\t\t/* The connect failed already (only ECONNREFUSED case). How very BSD of it. */\n\t\tresult = 0;\n\t\tbufferevent_run_eventcb_(bev, BEV_EVENT_ERROR, BEV_OPT_DEFER_CALLBACKS);\n\t\tbufferevent_disable(bev, EV_WRITE|EV_READ);\n\t}\n\n\tgoto done;\n\nfreesock:\n\tif (ownfd)\n\t\tevutil_closesocket(fd);\ndone:\n\tbufferevent_decref_and_unlock_(bev);\n\treturn result;\n}\n\nstatic void\nbufferevent_connect_getaddrinfo_cb(int result, struct evutil_addrinfo *ai,\n    void *arg)\n{\n\tstruct bufferevent *bev = arg;\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\tint r;\n\tBEV_LOCK(bev);\n\n\tbufferevent_unsuspend_write_(bev, BEV_SUSPEND_LOOKUP);\n\tbufferevent_unsuspend_read_(bev, BEV_SUSPEND_LOOKUP);\n\n\tbev_p->dns_request = NULL;\n\n\tif (result == EVUTIL_EAI_CANCEL) {\n\t\tbev_p->dns_error = result;\n\t\tbufferevent_decref_and_unlock_(bev);\n\t\treturn;\n\t}\n\tif (result != 0) {\n\t\tbev_p->dns_error = result;\n\t\tbufferevent_run_eventcb_(bev, BEV_EVENT_ERROR, 0);\n\t\tbufferevent_decref_and_unlock_(bev);\n\t\tif (ai)\n\t\t\tevutil_freeaddrinfo(ai);\n\t\treturn;\n\t}\n\n\t/* XXX use the other addrinfos? */\n\tbufferevent_socket_set_conn_address_(bev, ai->ai_addr, (int)ai->ai_addrlen);\n\tr = bufferevent_socket_connect(bev, ai->ai_addr, (int)ai->ai_addrlen);\n\tif (r < 0)\n\t\tbufferevent_run_eventcb_(bev, BEV_EVENT_ERROR, 0);\n\tbufferevent_decref_and_unlock_(bev);\n\tevutil_freeaddrinfo(ai);\n}\n\nint\nbufferevent_socket_connect_hostname(struct bufferevent *bev,\n    struct evdns_base *evdns_base, int family, const char *hostname, int port)\n{\n\tstruct evutil_addrinfo hint;\n\tmemset(&hint, 0, sizeof(hint));\n\thint.ai_family = family;\n\thint.ai_protocol = IPPROTO_TCP;\n\thint.ai_socktype = SOCK_STREAM;\n\n\treturn bufferevent_socket_connect_hostname_hints(bev, evdns_base, &hint, hostname, port);\n}\n\nint\nbufferevent_socket_connect_hostname_hints(struct bufferevent *bev,\n    struct evdns_base *evdns_base, const struct evutil_addrinfo *hints_in,\n    const char *hostname, int port)\n{\n\tchar portbuf[10];\n\tstruct bufferevent_private *bev_p =\n\t    EVUTIL_UPCAST(bev, struct bufferevent_private, bev);\n\n\tif (hints_in->ai_family != AF_INET && hints_in->ai_family != AF_INET6 &&\n\t    hints_in->ai_family != AF_UNSPEC)\n\t\treturn -1;\n\tif (port < 1 || port > 65535)\n\t\treturn -1;\n\n\tBEV_LOCK(bev);\n\tbev_p->dns_error = 0;\n\n\tevutil_snprintf(portbuf, sizeof(portbuf), \"%d\", port);\n\n\tbufferevent_suspend_write_(bev, BEV_SUSPEND_LOOKUP);\n\tbufferevent_suspend_read_(bev, BEV_SUSPEND_LOOKUP);\n\n\tbufferevent_incref_(bev);\n\tbev_p->dns_request = evutil_getaddrinfo_async_(evdns_base, hostname,\n\t    portbuf, hints_in, bufferevent_connect_getaddrinfo_cb, bev);\n\n\tBEV_UNLOCK(bev);\n\n\treturn 0;\n}\n\nint\nbufferevent_socket_get_dns_error(struct bufferevent *bev)\n{\n\tint rv;\n\tstruct bufferevent_private *bev_p = BEV_UPCAST(bev);\n\n\tBEV_LOCK(bev);\n\trv = bev_p->dns_error;\n\tBEV_UNLOCK(bev);\n\n\treturn rv;\n}\n\n/*\n * Create a new buffered event object.\n *\n * The read callback is invoked whenever we read new data.\n * The write callback is invoked whenever the output buffer is drained.\n * The error callback is invoked on a write/read error or on EOF.\n *\n * Both read and write callbacks maybe NULL.  The error callback is not\n * allowed to be NULL and have to be provided always.\n */\n\nstruct bufferevent *\nbufferevent_new(evutil_socket_t fd,\n    bufferevent_data_cb readcb, bufferevent_data_cb writecb,\n    bufferevent_event_cb eventcb, void *cbarg)\n{\n\tstruct bufferevent *bufev;\n\n\tif (!(bufev = bufferevent_socket_new(NULL, fd, 0)))\n\t\treturn NULL;\n\n\tbufferevent_setcb(bufev, readcb, writecb, eventcb, cbarg);\n\n\treturn bufev;\n}\n\n\nstatic int\nbe_socket_enable(struct bufferevent *bufev, short event)\n{\n\tif (event & EV_READ &&\n\t    bufferevent_add_event_(&bufev->ev_read, &bufev->timeout_read) == -1)\n\t\t\treturn -1;\n\tif (event & EV_WRITE &&\n\t    bufferevent_add_event_(&bufev->ev_write, &bufev->timeout_write) == -1)\n\t\t\treturn -1;\n\treturn 0;\n}\n\nstatic int\nbe_socket_disable(struct bufferevent *bufev, short event)\n{\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\tif (event & EV_READ) {\n\t\tif (event_del(&bufev->ev_read) == -1)\n\t\t\treturn -1;\n\t}\n\t/* Don't actually disable the write if we are trying to connect. */\n\tif ((event & EV_WRITE) && ! bufev_p->connecting) {\n\t\tif (event_del(&bufev->ev_write) == -1)\n\t\t\treturn -1;\n\t}\n\treturn 0;\n}\n\nstatic void\nbe_socket_destruct(struct bufferevent *bufev)\n{\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\tevutil_socket_t fd;\n\tEVUTIL_ASSERT(BEV_IS_SOCKET(bufev));\n\n\tfd = event_get_fd(&bufev->ev_read);\n\n\tif ((bufev_p->options & BEV_OPT_CLOSE_ON_FREE) && fd >= 0)\n\t\tEVUTIL_CLOSESOCKET(fd);\n\n\tevutil_getaddrinfo_cancel_async_(bufev_p->dns_request);\n}\n\nstatic int\nbe_socket_flush(struct bufferevent *bev, short iotype,\n    enum bufferevent_flush_mode mode)\n{\n\treturn 0;\n}\n\n\nstatic void\nbe_socket_setfd(struct bufferevent *bufev, evutil_socket_t fd)\n{\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\n\tBEV_LOCK(bufev);\n\tEVUTIL_ASSERT(BEV_IS_SOCKET(bufev));\n\n\tevent_del(&bufev->ev_read);\n\tevent_del(&bufev->ev_write);\n\n\tevbuffer_unfreeze(bufev->input, 0);\n\tevbuffer_unfreeze(bufev->output, 1);\n\n\tevent_assign(&bufev->ev_read, bufev->ev_base, fd,\n\t    EV_READ|EV_PERSIST|EV_FINALIZE, bufferevent_readcb, bufev);\n\tevent_assign(&bufev->ev_write, bufev->ev_base, fd,\n\t    EV_WRITE|EV_PERSIST|EV_FINALIZE, bufferevent_writecb, bufev);\n\n\tif (fd >= 0)\n\t\tbufferevent_enable(bufev, bufev->enabled);\n\n\tevutil_getaddrinfo_cancel_async_(bufev_p->dns_request);\n\n\tBEV_UNLOCK(bufev);\n}\n\n/* XXXX Should non-socket bufferevents support this? */\nint\nbufferevent_priority_set(struct bufferevent *bufev, int priority)\n{\n\tint r = -1;\n\tstruct bufferevent_private *bufev_p = BEV_UPCAST(bufev);\n\n\tBEV_LOCK(bufev);\n\tif (BEV_IS_ASYNC(bufev) || BEV_IS_FILTER(bufev) || BEV_IS_PAIR(bufev))\n\t\tgoto done;\n\n\tif (event_priority_set(&bufev->ev_read, priority) == -1)\n\t\tgoto done;\n\tif (event_priority_set(&bufev->ev_write, priority) == -1)\n\t\tgoto done;\n\n\tevent_deferred_cb_set_priority_(&bufev_p->deferred, priority);\n\n\tr = 0;\ndone:\n\tBEV_UNLOCK(bufev);\n\treturn r;\n}\n\n/* XXXX Should non-socket bufferevents support this? */\nint\nbufferevent_base_set(struct event_base *base, struct bufferevent *bufev)\n{\n\tint res = -1;\n\n\tBEV_LOCK(bufev);\n\tif (!BEV_IS_SOCKET(bufev))\n\t\tgoto done;\n\n\tbufev->ev_base = base;\n\n\tres = event_base_set(base, &bufev->ev_read);\n\tif (res == -1)\n\t\tgoto done;\n\n\tres = event_base_set(base, &bufev->ev_write);\ndone:\n\tBEV_UNLOCK(bufev);\n\treturn res;\n}\n\nstatic int\nbe_socket_ctrl(struct bufferevent *bev, enum bufferevent_ctrl_op op,\n    union bufferevent_ctrl_data *data)\n{\n\tswitch (op) {\n\tcase BEV_CTRL_SET_FD:\n\t\tbe_socket_setfd(bev, data->fd);\n\t\treturn 0;\n\tcase BEV_CTRL_GET_FD:\n\t\tdata->fd = event_get_fd(&bev->ev_read);\n\t\treturn 0;\n\tcase BEV_CTRL_GET_UNDERLYING:\n\tcase BEV_CTRL_CANCEL_ALL:\n\tdefault:\n\t\treturn -1;\n\t}\n}\n"
        },
        {
          "name": "bufferevent_ssl.c",
          "type": "blob",
          "size": 30.978515625,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n// Get rid of OSX 10.7 and greater deprecation warnings.\n#if defined(__APPLE__) && defined(__clang__)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_STDARG_H\n#include <stdarg.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n\n#include \"event2/bufferevent.h\"\n#include \"event2/bufferevent_struct.h\"\n#include \"event2/bufferevent_ssl.h\"\n#include \"event2/buffer.h\"\n#include \"event2/event.h\"\n\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n#include \"log-internal.h\"\n#include \"ssl-compat.h\"\n\n/* --------------------\n   Now, here's the OpenSSL-based implementation of bufferevent.\n\n   The implementation comes in two flavors: one that connects its SSL object\n   to an underlying bufferevent using a BIO_bufferevent, and one that has the\n   SSL object connect to a socket directly.  The latter should generally be\n   faster, except on Windows, where your best bet is using a\n   bufferevent_async.\n\n   (OpenSSL supports many other BIO types, too.  But we can't use any unless\n   we have a good way to get notified when they become readable/writable.)\n   -------------------- */\n\n\nstatic int be_ssl_enable(struct bufferevent *, short);\nstatic int be_ssl_disable(struct bufferevent *, short);\nstatic void be_ssl_unlink(struct bufferevent *);\nstatic void be_ssl_destruct(struct bufferevent *);\nstatic int be_ssl_adj_timeouts(struct bufferevent *);\nstatic int be_ssl_flush(struct bufferevent *bufev,\n    short iotype, enum bufferevent_flush_mode mode);\nstatic int be_ssl_ctrl(struct bufferevent *, enum bufferevent_ctrl_op, union bufferevent_ctrl_data *);\n\nconst struct bufferevent_ops bufferevent_ops_ssl = {\n\t\"ssl\",\n\tevutil_offsetof(struct bufferevent_ssl, bev.bev),\n\tbe_ssl_enable,\n\tbe_ssl_disable,\n\tbe_ssl_unlink,\n\tbe_ssl_destruct,\n\tbe_ssl_adj_timeouts,\n\tbe_ssl_flush,\n\tbe_ssl_ctrl,\n};\n\n/* Given a bufferevent, return a pointer to the bufferevent_ssl that\n * contains it, if any. */\nstruct bufferevent_ssl *\nbufferevent_ssl_upcast(struct bufferevent *bev)\n{\n\tstruct bufferevent_ssl *bev_o;\n\tEVUTIL_ASSERT(BEV_IS_SSL(bev));\n\tbev_o = (void*)( ((char*)bev) -\n\t\t\t evutil_offsetof(struct bufferevent_ssl, bev.bev));\n\tEVUTIL_ASSERT(BEV_IS_SSL(&bev_o->bev.bev));\n\treturn bev_o;\n}\n\nvoid\nbufferevent_ssl_put_error(struct bufferevent_ssl *bev_ssl, unsigned long err)\n{\n\tif (bev_ssl->n_errors == NUM_ERRORS)\n\t\treturn;\n\t/* The error type according to openssl is \"unsigned long\", but\n\t   openssl never uses more than 32 bits of it.  It _can't_ use more\n\t   than 32 bits of it, since it needs to report errors on systems\n\t   where long is only 32 bits.\n\t */\n\tbev_ssl->errors[bev_ssl->n_errors++] = (ev_uint32_t) err;\n}\n\n/* Have the base communications channel (either the underlying bufferevent or\n * ev_read and ev_write) start reading.  Take the read-blocked-on-write flag\n * into account. */\nstatic int\nstart_reading(struct bufferevent_ssl *bev_ssl)\n{\n\tif (bev_ssl->underlying) {\n\t\tbufferevent_unsuspend_read_(bev_ssl->underlying,\n\t\t    BEV_SUSPEND_FILT_READ);\n\t\treturn 0;\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tint r;\n\t\tr = bufferevent_add_event_(&bev->ev_read, &bev->timeout_read);\n\t\tif (r == 0 && bev_ssl->read_blocked_on_write)\n\t\t\tr = bufferevent_add_event_(&bev->ev_write,\n\t\t\t    &bev->timeout_write);\n\t\treturn r;\n\t}\n}\n\n/* Have the base communications channel (either the underlying bufferevent or\n * ev_read and ev_write) start writing.  Take the write-blocked-on-read flag\n * into account. */\nstatic int\nstart_writing(struct bufferevent_ssl *bev_ssl)\n{\n\tint r = 0;\n\tif (bev_ssl->underlying) {\n\t\tif (bev_ssl->write_blocked_on_read) {\n\t\t\tbufferevent_unsuspend_read_(bev_ssl->underlying,\n\t\t\t    BEV_SUSPEND_FILT_READ);\n\t\t}\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tr = bufferevent_add_event_(&bev->ev_write, &bev->timeout_write);\n\t\tif (!r && bev_ssl->write_blocked_on_read)\n\t\t\tr = bufferevent_add_event_(&bev->ev_read,\n\t\t\t    &bev->timeout_read);\n\t}\n\treturn r;\n}\n\nvoid\nbufferevent_ssl_stop_reading(struct bufferevent_ssl *bev_ssl)\n{\n\tif (bev_ssl->write_blocked_on_read)\n\t\treturn;\n\tif (bev_ssl->underlying) {\n\t\tbufferevent_suspend_read_(bev_ssl->underlying,\n\t\t    BEV_SUSPEND_FILT_READ);\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tevent_del(&bev->ev_read);\n\t}\n}\n\nvoid\nbufferevent_ssl_stop_writing(struct bufferevent_ssl *bev_ssl)\n{\n\tif (bev_ssl->read_blocked_on_write)\n\t\treturn;\n\tif (bev_ssl->underlying) {\n\t\tbufferevent_unsuspend_read_(bev_ssl->underlying,\n\t\t    BEV_SUSPEND_FILT_READ);\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tevent_del(&bev->ev_write);\n\t}\n}\n\nstatic int\nset_rbow(struct bufferevent_ssl *bev_ssl)\n{\n\tif (!bev_ssl->underlying)\n\t\tbufferevent_ssl_stop_reading(bev_ssl);\n\tbev_ssl->read_blocked_on_write = 1;\n\treturn start_writing(bev_ssl);\n}\n\nstatic int\nset_wbor(struct bufferevent_ssl *bev_ssl)\n{\n\tif (!bev_ssl->underlying)\n\t\tbufferevent_ssl_stop_writing(bev_ssl);\n\tbev_ssl->write_blocked_on_read = 1;\n\treturn start_reading(bev_ssl);\n}\n\nstatic int\nclear_rbow(struct bufferevent_ssl *bev_ssl)\n{\n\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\tint r = 0;\n\tbev_ssl->read_blocked_on_write = 0;\n\tif (!(bev->enabled & EV_WRITE))\n\t\tbufferevent_ssl_stop_writing(bev_ssl);\n\tif (bev->enabled & EV_READ)\n\t\tr = start_reading(bev_ssl);\n\treturn r;\n}\n\n\nstatic int\nclear_wbor(struct bufferevent_ssl *bev_ssl)\n{\n\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\tint r = 0;\n\tbev_ssl->write_blocked_on_read = 0;\n\tif (!(bev->enabled & EV_READ))\n\t\tbufferevent_ssl_stop_reading(bev_ssl);\n\tif (bev->enabled & EV_WRITE)\n\t\tr = start_writing(bev_ssl);\n\treturn r;\n}\n\n#define OP_MADE_PROGRESS 1\n#define OP_BLOCKED 2\n#define OP_ERR 4\n\n/* Return a bitmask of OP_MADE_PROGRESS (if we read anything); OP_BLOCKED (if\n   we're now blocked); and OP_ERR (if an error occurred). */\nstatic int\ndo_read(struct bufferevent_ssl *bev_ssl, int n_to_read) {\n\t/* Requires lock */\n\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\tstruct evbuffer *input = bev->input;\n\tint r, n, i = 0, atmost;\n\tstruct evbuffer_iovec space[2];\n\tint result = 0;\n\tsize_t len = 0;\n\n\tif (bev_ssl->bev.read_suspended)\n\t\treturn 0;\n\n\tatmost = bufferevent_get_read_max_(&bev_ssl->bev);\n\tif (n_to_read > atmost)\n\t\tn_to_read = atmost;\n\n\tn = evbuffer_reserve_space(input, n_to_read, space, 2);\n\tif (n < 0)\n\t\treturn OP_ERR;\n\n\tfor (i = 0; i < n;) {\n\t\tif (bev_ssl->bev.read_suspended)\n\t\t\tbreak;\n\t\tbev_ssl->ssl_ops->clear_error();\n\t\tr = bev_ssl->ssl_ops->read(\n\t\t\tbev_ssl->ssl, (unsigned char *)space[i].iov_base + len, space[i].iov_len - len);\n\t\tif (r > 0) {\n\t\t\tresult |= OP_MADE_PROGRESS;\n\t\t\tif (bev_ssl->read_blocked_on_write)\n\t\t\t\tif (clear_rbow(bev_ssl) < 0)\n\t\t\t\t\treturn OP_ERR | result;\n\t\t\tbev_ssl->ssl_ops->decrement_buckets(bev_ssl);\n\t\t\tlen += r;\n\t\t\tif (space[i].iov_len - len > 0) {\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tspace[i].iov_len = len;\n\t\t\t\tlen = 0;\n\t\t\t\t++i;\n\t\t\t}\n\t\t} else {\n\t\t\tint err = bev_ssl->ssl_ops->get_error(bev_ssl->ssl, r);\n\t\t\tbev_ssl->ssl_ops->print_err(err);\n\t\t\t/* NOTE: we ignore the error in case of some progress was done,\n\t\t\t * because currently we do not send close_notify, and this will\n\t\t\t * lead to error from SSL_read() (it will return 0, and\n\t\t\t * SSL_get_error() will return SSL_ERROR_SSL), and this is because\n\t\t\t * of lack of close_notify\n\t\t\t *\n\t\t\t * But AFAICS some code uses it the same way (i.e. nginx) */\n\t\t\tif (result & OP_MADE_PROGRESS) {\n\t\t\t\t/* Process existing data */\n\t\t\t\tbreak;\n\t\t\t} else if (bev_ssl->ssl_ops->err_is_want_read(err)) {\n\t\t\t\t/* Can't read until underlying has more data. */\n\t\t\t\tif (bev_ssl->read_blocked_on_write)\n\t\t\t\t\tif (clear_rbow(bev_ssl) < 0)\n\t\t\t\t\t\treturn OP_ERR | result;\n\t\t\t} else if (bev_ssl->ssl_ops->err_is_want_write(err)) {\n\t\t\t\t/* This read operation requires a write, and the\n\t\t\t\t * underlying is full */\n\t\t\t\tif (!bev_ssl->read_blocked_on_write)\n\t\t\t\t\tif (set_rbow(bev_ssl) < 0)\n\t\t\t\t\t\treturn OP_ERR | result;\n\t\t\t} else {\n\t\t\t\tbev_ssl->ssl_ops->conn_closed(bev_ssl, BEV_EVENT_READING, err, r);\n\t\t\t}\n\t\t\tresult |= OP_BLOCKED;\n\t\t\tbreak; /* out of the loop */\n\t\t}\n\t}\n\n\tif (len > 0) {\n\t\tspace[i].iov_len = len;\n\t\t++i;\n\t}\n\n\tif (i) {\n\t\tevbuffer_commit_space(input, space, i);\n\t\tif (bev_ssl->underlying)\n\t\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bev);\n\t}\n\n\treturn result;\n}\n\n/* Return a bitmask of OP_MADE_PROGRESS (if we wrote anything); OP_BLOCKED (if\n   we're now blocked); and OP_ERR (if an error occurred). */\nstatic int\ndo_write(struct bufferevent_ssl *bev_ssl, int atmost)\n{\n\tint i, r, n, n_written = 0;\n\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\tstruct evbuffer *output = bev->output;\n\tstruct evbuffer_iovec space[8];\n\tint result = 0;\n\n\tif (bev_ssl->last_write > 0)\n\t\tatmost = bev_ssl->last_write;\n\telse\n\t\tatmost = bufferevent_get_write_max_(&bev_ssl->bev);\n\n\tif (bev_ssl->flags & BUFFEREVENT_SSL_BATCH_WRITE) {\n\t\t/* Try to send as many as we can to avoid Nagle effect */\n\t\tevbuffer_pullup(output, -1);\n\t}\n\n\tn = evbuffer_peek(output, atmost, NULL, space, 8);\n\tif (n < 0)\n\t\treturn OP_ERR | result;\n\n\tif (n > 8)\n\t\tn = 8;\n\tfor (i=0; i < n;) {\n\t\tif (bev_ssl->bev.write_suspended)\n\t\t\tbreak;\n\n\t\t/* SSL_write will (reasonably) return 0 if we tell it to\n\t\t   send 0 data.  Skip this case so we don't interpret the\n\t\t   result as an error */\n\t\tif (space[i].iov_len == 0) {\n\t\t\t++i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tbev_ssl->ssl_ops->clear_error();\n\t\tr = bev_ssl->ssl_ops->write(bev_ssl->ssl, space[i].iov_base,\n\t\t    space[i].iov_len);\n\t\tif (r > 0) {\n\t\t\tresult |= OP_MADE_PROGRESS;\n\t\t\tif (bev_ssl->write_blocked_on_read)\n\t\t\t\tif (clear_wbor(bev_ssl) < 0)\n\t\t\t\t\treturn OP_ERR | result;\n\t\t\tn_written += r;\n\t\t\tbev_ssl->last_write = -1;\n\t\t\tbev_ssl->ssl_ops->decrement_buckets(bev_ssl);\n\t\t\tspace[i].iov_base = (unsigned char *)space[i].iov_base + r;\n\t\t\tspace[i].iov_len -= r;\n\t\t\tif (space[i].iov_len == 0)\n\t\t\t\t++i;\n\t\t} else {\n\t\t\tint err = bev_ssl->ssl_ops->get_error(bev_ssl->ssl, r);\n\t\t\tbev_ssl->ssl_ops->print_err(err);\n\t\t\tif (bev_ssl->ssl_ops->err_is_want_write(err)) {\n\t\t\t\t/* Can't read until underlying has more data. */\n\t\t\t\tif (bev_ssl->write_blocked_on_read)\n\t\t\t\t\tif (clear_wbor(bev_ssl) < 0)\n\t\t\t\t\t\treturn OP_ERR | result;\n\t\t\t\tbev_ssl->last_write = space[i].iov_len;\n\t\t\t} else if (bev_ssl->ssl_ops->err_is_want_read(err)) {\n\t\t\t\t/* This read operation requires a write, and the\n\t\t\t\t * underlying is full */\n\t\t\t\tif (!bev_ssl->write_blocked_on_read)\n\t\t\t\t\tif (set_wbor(bev_ssl) < 0)\n\t\t\t\t\t\treturn OP_ERR | result;\n\t\t\t\tbev_ssl->last_write = space[i].iov_len;\n\t\t\t} else {\n\t\t\t\tbev_ssl->ssl_ops->conn_closed(bev_ssl, BEV_EVENT_WRITING, err, r);\n\t\t\t\tbev_ssl->last_write = -1;\n\t\t\t}\n\t\t\tresult |= OP_BLOCKED;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (n_written) {\n\t\tif (evbuffer_drain(output, n_written))\n\t\t\treturn OP_ERR | result;\n\n\t\tif (bev_ssl->underlying)\n\t\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bev);\n\n\t\tbufferevent_trigger_nolock_(bev, EV_WRITE, BEV_OPT_DEFER_CALLBACKS);\n\t}\n\treturn result;\n}\n\n#define WRITE_FRAME 15000\n\n/* Try to figure out how many bytes to read; return 0 if we shouldn't be\n * reading. */\nstatic int\nbytes_to_read(struct bufferevent_ssl *bev)\n{\n\tstruct evbuffer *input = bev->bev.bev.input;\n\tstruct event_watermark *wm = &bev->bev.bev.wm_read;\n\tint result = 0;\n\tev_ssize_t limit;\n\t/* XXX 99% of this is generic code that nearly all bufferevents will\n\t * want. */\n\n\tif (bev->write_blocked_on_read) {\n\t\treturn 0;\n\t}\n\n\tif (! (bev->bev.bev.enabled & EV_READ)) {\n\t\treturn 0;\n\t}\n\n\tif (bev->bev.read_suspended) {\n\t\treturn 0;\n\t}\n\n\tif (wm->high) {\n\t\tif (evbuffer_get_length(input) >= wm->high) {\n\t\t\treturn 0;\n\t\t}\n\n\t\tresult = wm->high - evbuffer_get_length(input);\n\t}\n\n\t/* Respect the rate limit */\n\tlimit = bufferevent_get_read_max_(&bev->bev);\n\tif (result == 0 || result > limit) {\n\t\tresult = limit;\n\t}\n\n\treturn result;\n}\n\n\n/* Things look readable.  If write is blocked on read, write till it isn't.\n * Read from the underlying buffer until we block or we hit our high-water\n * mark.\n */\nstatic void\nconsider_reading(struct bufferevent_ssl *bev_ssl)\n{\n\tint r;\n\tint n_to_read;\n\tint all_result_flags = 0;\n\n\twhile (bev_ssl->write_blocked_on_read) {\n\t\tr = do_write(bev_ssl, WRITE_FRAME);\n\t\tif (r & (OP_BLOCKED|OP_ERR))\n\t\t\tbreak;\n\t}\n\tif (bev_ssl->write_blocked_on_read)\n\t\treturn;\n\n\tn_to_read = bytes_to_read(bev_ssl);\n\n\twhile (n_to_read) {\n\t\tr = do_read(bev_ssl, n_to_read);\n\t\tall_result_flags |= r;\n\n\t\tif (r & (OP_BLOCKED|OP_ERR))\n\t\t\tbreak;\n\n\t\tif (bev_ssl->bev.read_suspended)\n\t\t\tbreak;\n\n\t\t/* Read all pending data.  This won't hit the network\n\t\t * again, and will (most importantly) put us in a state\n\t\t * where we don't need to read anything else until the\n\t\t * socket is readable again.  It'll potentially make us\n\t\t * overrun our read high-watermark (somewhat\n\t\t * regrettable).  The damage to the rate-limit has\n\t\t * already been done, since OpenSSL went and read a\n\t\t * whole SSL record anyway. */\n\t\tn_to_read = bev_ssl->ssl_ops->pending(bev_ssl->ssl);\n\n\t\t/* XXX This if statement is actually a bad bug, added to avoid\n\t\t * XXX a worse bug.\n\t\t *\n\t\t * The bad bug: It can potentially cause resource unfairness\n\t\t * by reading too much data from the underlying bufferevent;\n\t\t * it can potentially cause read looping if the underlying\n\t\t * bufferevent is a bufferevent_pair and deferred callbacks\n\t\t * aren't used.\n\t\t *\n\t\t * The worse bug: If we didn't do this, then we would\n\t\t * potentially not read any more from bev_ssl->underlying\n\t\t * until more data arrived there, which could lead to us\n\t\t * waiting forever.\n\t\t */\n\t\tif (!n_to_read && bev_ssl->underlying)\n\t\t\tn_to_read = bytes_to_read(bev_ssl);\n\t}\n\n\tif (all_result_flags & OP_MADE_PROGRESS) {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\n\t\tbufferevent_trigger_nolock_(bev, EV_READ, 0);\n\t}\n\n\tif (!bev_ssl->underlying) {\n\t\t/* Should be redundant, but let's avoid busy-looping */\n\t\tif (bev_ssl->bev.read_suspended ||\n\t\t    !(bev_ssl->bev.bev.enabled & EV_READ)) {\n\t\t\tevent_del(&bev_ssl->bev.bev.ev_read);\n\t\t}\n\t}\n}\n\nstatic void\nconsider_writing(struct bufferevent_ssl *bev_ssl)\n{\n\tint r;\n\tstruct evbuffer *output = bev_ssl->bev.bev.output;\n\tstruct evbuffer *target = NULL;\n\tstruct event_watermark *wm = NULL;\n\n\twhile (bev_ssl->read_blocked_on_write) {\n\t\tr = do_read(bev_ssl, 1024); /* XXXX 1024 is a hack */\n\t\tif (r & OP_MADE_PROGRESS) {\n\t\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\n\t\t\tbufferevent_trigger_nolock_(bev, EV_READ, 0);\n\t\t}\n\t\tif (r & (OP_ERR|OP_BLOCKED))\n\t\t\tbreak;\n\t}\n\tif (bev_ssl->read_blocked_on_write)\n\t\treturn;\n\tif (bev_ssl->underlying) {\n\t\ttarget = bev_ssl->underlying->output;\n\t\twm = &bev_ssl->underlying->wm_write;\n\t}\n\twhile ((bev_ssl->bev.bev.enabled & EV_WRITE) &&\n\t    (! bev_ssl->bev.write_suspended) &&\n\t    evbuffer_get_length(output) &&\n\t    (!target || (! wm->high || evbuffer_get_length(target) < wm->high))) {\n\t\tint n_to_write;\n\t\tif (wm && wm->high)\n\t\t\tn_to_write = wm->high - evbuffer_get_length(target);\n\t\telse\n\t\t\tn_to_write = WRITE_FRAME;\n\t\tr = do_write(bev_ssl, n_to_write);\n\t\tif (r & (OP_BLOCKED|OP_ERR))\n\t\t\tbreak;\n\t}\n\n\tif (!bev_ssl->underlying) {\n\t\tif (evbuffer_get_length(output) == 0) {\n\t\t\tevent_del(&bev_ssl->bev.bev.ev_write);\n\t\t} else if (bev_ssl->bev.write_suspended ||\n\t\t    !(bev_ssl->bev.bev.enabled & EV_WRITE)) {\n\t\t\t/* Should be redundant, but let's avoid busy-looping */\n\t\t\tevent_del(&bev_ssl->bev.bev.ev_write);\n\t\t}\n\t}\n}\n\nstatic void\nbe_ssl_readcb(struct bufferevent *bev_base, void *ctx)\n{\n\tstruct bufferevent_ssl *bev_ssl = ctx;\n\tconsider_reading(bev_ssl);\n}\n\nstatic void\nbe_ssl_writecb(struct bufferevent *bev_base, void *ctx)\n{\n\tstruct bufferevent_ssl *bev_ssl = ctx;\n\tconsider_writing(bev_ssl);\n}\n\nstatic void\nbe_ssl_eventcb(struct bufferevent *bev_base, short what, void *ctx)\n{\n\tstruct bufferevent_ssl *bev_ssl = ctx;\n\tint event = 0;\n\n\tif (what & BEV_EVENT_EOF) {\n\t\tif (bev_ssl->flags & BUFFEREVENT_SSL_DIRTY_SHUTDOWN)\n\t\t\tevent = BEV_EVENT_EOF;\n\t\telse\n\t\t\tevent = BEV_EVENT_ERROR;\n\t} else if (what & BEV_EVENT_TIMEOUT) {\n\t\t/* We sure didn't set this.  Propagate it to the user. */\n\t\tevent = what;\n\t} else if (what & BEV_EVENT_ERROR) {\n\t\t/* An error occurred on the connection.  Propagate it to the user. */\n\t\tevent = what;\n\t} else if (what & BEV_EVENT_CONNECTED) {\n\t\t/* Ignore it.  We're saying SSL_connect() already, which will\n\t\t   eat it. */\n\t}\n\tif (event)\n\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev, event, 0);\n}\n\nstatic void\nbe_ssl_readeventcb(evutil_socket_t fd, short what, void *ptr)\n{\n\tstruct bufferevent_ssl *bev_ssl = ptr;\n\tbufferevent_incref_and_lock_(&bev_ssl->bev.bev);\n\tif (what == EV_TIMEOUT) {\n\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev,\n\t\t    BEV_EVENT_TIMEOUT|BEV_EVENT_READING, 0);\n\t} else {\n\t\tconsider_reading(bev_ssl);\n\t}\n\tbufferevent_decref_and_unlock_(&bev_ssl->bev.bev);\n}\n\nstatic void\nbe_ssl_writeeventcb(evutil_socket_t fd, short what, void *ptr)\n{\n\tstruct bufferevent_ssl *bev_ssl = ptr;\n\tbufferevent_incref_and_lock_(&bev_ssl->bev.bev);\n\tif (what == EV_TIMEOUT) {\n\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev,\n\t\t    BEV_EVENT_TIMEOUT|BEV_EVENT_WRITING, 0);\n\t} else {\n\t\tconsider_writing(bev_ssl);\n\t}\n\tbufferevent_decref_and_unlock_(&bev_ssl->bev.bev);\n}\n\nstatic evutil_socket_t\nbe_ssl_auto_fd(struct bufferevent_ssl *bev_ssl, evutil_socket_t fd)\n{\n\tif (!bev_ssl->underlying) {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tif (event_initialized(&bev->ev_read) && fd < 0) {\n\t\t\tfd = event_get_fd(&bev->ev_read);\n\t\t}\n\t}\n\treturn fd;\n}\n\nstatic int\nset_open_callbacks(struct bufferevent_ssl *bev_ssl, evutil_socket_t fd)\n{\n\tif (bev_ssl->underlying) {\n\t\tbufferevent_setcb(bev_ssl->underlying,\n\t\t    be_ssl_readcb, be_ssl_writecb, be_ssl_eventcb,\n\t\t    bev_ssl);\n\t\treturn 0;\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\t\tint rpending=0, wpending=0, r1=0, r2=0;\n\n\t\tif (event_initialized(&bev->ev_read)) {\n\t\t\trpending = event_pending(&bev->ev_read, EV_READ, NULL);\n\t\t\twpending = event_pending(&bev->ev_write, EV_WRITE, NULL);\n\n\t\t\tevent_del(&bev->ev_read);\n\t\t\tevent_del(&bev->ev_write);\n\t\t}\n\n\t\tevent_assign(&bev->ev_read, bev->ev_base, fd,\n\t\t    EV_READ|EV_PERSIST|EV_FINALIZE,\n\t\t    be_ssl_readeventcb, bev_ssl);\n\t\tevent_assign(&bev->ev_write, bev->ev_base, fd,\n\t\t    EV_WRITE|EV_PERSIST|EV_FINALIZE,\n\t\t    be_ssl_writeeventcb, bev_ssl);\n\n\t\tif (rpending)\n\t\t\tr1 = bufferevent_add_event_(&bev->ev_read, &bev->timeout_read);\n\t\tif (wpending)\n\t\t\tr2 = bufferevent_add_event_(&bev->ev_write, &bev->timeout_write);\n\n\t\treturn (r1<0 || r2<0) ? -1 : 0;\n\t}\n}\n\nstatic int\ndo_handshake(struct bufferevent_ssl *bev_ssl)\n{\n\tint r;\n\n\tswitch (bev_ssl->state) {\n\tdefault:\n\tcase BUFFEREVENT_SSL_OPEN:\n\t\tEVUTIL_ASSERT(0);\n\t\treturn -1;\n\tcase BUFFEREVENT_SSL_CONNECTING:\n\tcase BUFFEREVENT_SSL_ACCEPTING:\n\t\tbev_ssl->ssl_ops->clear_error();\n\t\tr = bev_ssl->ssl_ops->handshake(bev_ssl->ssl);\n\t\tbreak;\n\t}\n\tbev_ssl->ssl_ops->decrement_buckets(bev_ssl);\n\n\tif (bev_ssl->ssl_ops->handshake_is_ok(r)) {\n\t\tevutil_socket_t fd = event_get_fd(&bev_ssl->bev.bev.ev_read);\n\t\t/* We're done! */\n\t\tbev_ssl->state = BUFFEREVENT_SSL_OPEN;\n\t\tset_open_callbacks(bev_ssl, fd); /* XXXX handle failure */\n\t\t/* Call do_read and do_write as needed */\n\t\tbufferevent_enable(&bev_ssl->bev.bev, bev_ssl->bev.bev.enabled);\n\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev,\n\t\t    BEV_EVENT_CONNECTED, 0);\n\t\treturn 1;\n\t} else {\n\t\tint err = bev_ssl->ssl_ops->get_error(bev_ssl->ssl, r);\n\t\tbev_ssl->ssl_ops->print_err(err);\n\t\tif (bev_ssl->ssl_ops->err_is_want_write(err)) {\n\t\t\tbufferevent_ssl_stop_reading(bev_ssl);\n\t\t\treturn start_writing(bev_ssl);\n\t\t} else if (bev_ssl->ssl_ops->err_is_want_read(err)) {\n\t\t\tbufferevent_ssl_stop_writing(bev_ssl);\n\t\t\treturn start_reading(bev_ssl);\n\t\t} else {\n\t\t\tbev_ssl->ssl_ops->conn_closed(bev_ssl, BEV_EVENT_READING, err, r);\n\t\t\treturn -1;\n\t\t}\n\t}\n}\n\nstatic void\nbe_ssl_handshakecb(struct bufferevent *bev_base, void *ctx)\n{\n\tstruct bufferevent_ssl *bev_ssl = ctx;\n\tdo_handshake(bev_ssl);/* XXX handle failure */\n}\n\nstatic void\nbe_ssl_handshakeeventcb(evutil_socket_t fd, short what, void *ptr)\n{\n\tstruct bufferevent_ssl *bev_ssl = ptr;\n\n\tbufferevent_incref_and_lock_(&bev_ssl->bev.bev);\n\tif (what & EV_TIMEOUT) {\n\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev, BEV_EVENT_TIMEOUT, 0);\n\t} else {\n\t\tint c = evutil_socket_finished_connecting_(fd);\n\t\tif (c < 0)\n\t\t\tbufferevent_run_eventcb_(&bev_ssl->bev.bev, BEV_EVENT_ERROR, 0);\n\t\telse\n\t\t\tdo_handshake(bev_ssl);/* XXX handle failure */\n\t}\n\tbufferevent_decref_and_unlock_(&bev_ssl->bev.bev);\n}\n\nstatic int\nset_handshake_callbacks(struct bufferevent_ssl *bev_ssl, evutil_socket_t fd)\n{\n\tif (bev_ssl->underlying) {\n\t\tbufferevent_setcb(bev_ssl->underlying,\n\t\t    be_ssl_handshakecb, be_ssl_handshakecb,\n\t\t    be_ssl_eventcb,\n\t\t    bev_ssl);\n\n\t\tif (fd < 0)\n\t\t\treturn 0;\n\n\t\tif (bufferevent_setfd(bev_ssl->underlying, fd))\n\t\t\treturn 1;\n\n\t\treturn do_handshake(bev_ssl);\n\t} else {\n\t\tstruct bufferevent *bev = &bev_ssl->bev.bev;\n\n\t\tif (event_initialized(&bev->ev_read)) {\n\t\t\tevent_del(&bev->ev_read);\n\t\t\tevent_del(&bev->ev_write);\n\t\t}\n\n\t\tevent_assign(&bev->ev_read, bev->ev_base, fd,\n\t\t    EV_READ|EV_PERSIST|EV_FINALIZE,\n\t\t    be_ssl_handshakeeventcb, bev_ssl);\n\t\tevent_assign(&bev->ev_write, bev->ev_base, fd,\n\t\t    EV_WRITE|EV_PERSIST|EV_FINALIZE,\n\t\t    be_ssl_handshakeeventcb, bev_ssl);\n\t\tif (fd >= 0)\n\t\t\tbufferevent_enable(bev, bev->enabled);\n\t\treturn 0;\n\t}\n}\n\nint\nbufferevent_ssl_renegotiate_impl(struct bufferevent *bev)\n{\n\tstruct bufferevent_ssl *bev_ssl;\n\tif (!BEV_IS_SSL(bev))\n\t\treturn -1;\n\n\tbev_ssl = bufferevent_ssl_upcast(bev);\n\tif (bev_ssl->ssl_ops->renegotiate(bev_ssl->ssl) < 0)\n\t\treturn -1;\n\tbev_ssl->state = BUFFEREVENT_SSL_CONNECTING;\n\tif (set_handshake_callbacks(bev_ssl, be_ssl_auto_fd(bev_ssl, -1)) < 0)\n\t\treturn -1;\n\tif (!bev_ssl->underlying)\n\t\treturn do_handshake(bev_ssl);\n\treturn 0;\n}\n\nstatic void\nbe_ssl_outbuf_cb(struct evbuffer *buf,\n    const struct evbuffer_cb_info *cbinfo, void *arg)\n{\n\tstruct bufferevent_ssl *bev_ssl = arg;\n\tint r = 0;\n\t/* XXX need to hold a reference here. */\n\n\tif (cbinfo->n_added && bev_ssl->state == BUFFEREVENT_SSL_OPEN) {\n\t\tif (cbinfo->orig_size == 0)\n\t\t\tr = bufferevent_add_event_(&bev_ssl->bev.bev.ev_write,\n\t\t\t    &bev_ssl->bev.bev.timeout_write);\n\n\t\tif (bev_ssl->underlying)\n\t\t\tconsider_writing(bev_ssl);\n\t}\n\t/* XXX Handle r < 0 */\n\t(void)r;\n}\n\n\nstatic int\nbe_ssl_enable(struct bufferevent *bev, short events)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\tint r1 = 0, r2 = 0;\n\n\tif (events & EV_READ)\n\t\tr1 = start_reading(bev_ssl);\n\tif (events & EV_WRITE)\n\t\tr2 = start_writing(bev_ssl);\n\n\tif (bev_ssl->underlying) {\n\t\tif (events & EV_READ)\n\t\t\tBEV_RESET_GENERIC_READ_TIMEOUT(bev);\n\t\tif (events & EV_WRITE)\n\t\t\tBEV_RESET_GENERIC_WRITE_TIMEOUT(bev);\n\n\t\tif (events & EV_READ)\n\t\t\tconsider_reading(bev_ssl);\n\t\tif (events & EV_WRITE)\n\t\t\tconsider_writing(bev_ssl);\n\t}\n\treturn (r1 < 0 || r2 < 0) ? -1 : 0;\n}\n\nstatic int\nbe_ssl_disable(struct bufferevent *bev, short events)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\n\tif (events & EV_READ)\n\t\tbufferevent_ssl_stop_reading(bev_ssl);\n\tif (events & EV_WRITE)\n\t\tbufferevent_ssl_stop_writing(bev_ssl);\n\n\tif (bev_ssl->underlying) {\n\t\tif (events & EV_READ)\n\t\t\tBEV_DEL_GENERIC_READ_TIMEOUT(bev);\n\t\tif (events & EV_WRITE)\n\t\t\tBEV_DEL_GENERIC_WRITE_TIMEOUT(bev);\n\t}\n\treturn 0;\n}\n\nstatic void\nbe_ssl_unlink(struct bufferevent *bev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\n\tif (bev_ssl->bev.options & BEV_OPT_CLOSE_ON_FREE) {\n\t\tif (bev_ssl->underlying) {\n\t\t\tif (BEV_UPCAST(bev_ssl->underlying)->refcnt < 2) {\n\t\t\t\tevent_warnx(\"BEV_OPT_CLOSE_ON_FREE set on an \"\n\t\t\t\t    \"bufferevent with too few references\");\n\t\t\t} else {\n\t\t\t\tbufferevent_free(bev_ssl->underlying);\n\t\t\t\t/* We still have a reference to it, via our\n\t\t\t\t * BIO. So we don't drop this. */\n\t\t\t\t// bev_ssl->underlying = NULL;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (bev_ssl->underlying) {\n\t\t\tif (bev_ssl->underlying->errorcb == be_ssl_eventcb)\n\t\t\t\tbufferevent_setcb(bev_ssl->underlying,\n\t\t\t\t    NULL,NULL,NULL,NULL);\n\t\t\tbufferevent_unsuspend_read_(bev_ssl->underlying,\n\t\t\t    BEV_SUSPEND_FILT_READ);\n\t\t}\n\t}\n}\n\nstatic void\nbe_ssl_destruct(struct bufferevent *bev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\n\tif (bev_ssl->bev.options & BEV_OPT_CLOSE_ON_FREE) {\n\t\tif (! bev_ssl->underlying) {\n\t\t\tevutil_socket_t fd = bev_ssl->ssl_ops->get_fd(bev_ssl);\n\t\t\t/* NOTE: This is dirty shutdown, to send close_notify one of the\n\t\t\t * following should be used:\n\t\t\t * - SSL_shutdown()\n\t\t\t * - mbedtls_ssl_close_notify() */\n\t\t\tif (fd >= 0)\n\t\t\t\tevutil_closesocket(fd);\n\t\t}\n\t}\n\tbev_ssl->ssl_ops->free(bev_ssl->ssl, bev_ssl->bev.options);\n}\n\nstatic int\nbe_ssl_adj_timeouts(struct bufferevent *bev)\n{\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\n\tif (bev_ssl->underlying) {\n\t\treturn bufferevent_generic_adj_timeouts_(bev);\n\t} else {\n\t\treturn bufferevent_generic_adj_existing_timeouts_(bev);\n\t}\n}\n\nstatic int\nbe_ssl_flush(struct bufferevent *bufev,\n    short iotype, enum bufferevent_flush_mode mode)\n{\n\t/* XXXX Implement this. */\n\treturn 0;\n}\n\nstatic int\nbe_ssl_set_fd(struct bufferevent_ssl *bev_ssl,\n    enum bufferevent_ssl_state state, evutil_socket_t fd)\n{\n\tbev_ssl->state = state;\n\n\tswitch (state) {\n\tcase BUFFEREVENT_SSL_ACCEPTING:\n\t\tif (!bev_ssl->ssl_ops->clear(bev_ssl->ssl))\n\t\t\treturn -1;\n\t\tbev_ssl->ssl_ops->set_accept_state(bev_ssl->ssl);\n\t\tif (set_handshake_callbacks(bev_ssl, fd) < 0)\n\t\t\treturn -1;\n\t\tbreak;\n\tcase BUFFEREVENT_SSL_CONNECTING:\n\t\tif (!bev_ssl->ssl_ops->clear(bev_ssl->ssl))\n\t\t\treturn -1;\n\t\tbev_ssl->ssl_ops->set_connect_state(bev_ssl->ssl);\n\t\tif (set_handshake_callbacks(bev_ssl, fd) < 0)\n\t\t\treturn -1;\n\t\tbreak;\n\tcase BUFFEREVENT_SSL_OPEN:\n\t\tif (set_open_callbacks(bev_ssl, fd) < 0)\n\t\t\treturn -1;\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nbe_ssl_ctrl(struct bufferevent *bev,\n    enum bufferevent_ctrl_op op, union bufferevent_ctrl_data *data)\n{\n\tint ret = 0;\n\tstruct bufferevent_ssl *bev_ssl = bufferevent_ssl_upcast(bev);\n\tswitch (op) {\n\tcase BEV_CTRL_SET_FD:\n\t\tif ((ret = bev_ssl->ssl_ops->bio_set_fd(bev_ssl, data->fd)) != 0)\n\t\t\treturn ret;\n\t\treturn be_ssl_set_fd(bev_ssl, bev_ssl->old_state, data->fd);\n\tcase BEV_CTRL_GET_FD:\n\t\tif (bev_ssl->underlying) {\n\t\t\tdata->fd = event_get_fd(&bev_ssl->underlying->ev_read);\n\t\t} else {\n\t\t\tdata->fd = event_get_fd(&bev->ev_read);\n\t\t}\n\t\treturn 0;\n\tcase BEV_CTRL_GET_UNDERLYING:\n\t\tdata->ptr = bev_ssl->underlying;\n\t\treturn 0;\n\tcase BEV_CTRL_CANCEL_ALL:\n\tdefault:\n\t\treturn -1;\n\t}\n}\n\nstruct bufferevent *\nbufferevent_ssl_new_impl(struct event_base *base,\n    struct bufferevent *underlying,\n    evutil_socket_t fd,\n    void *ssl,\n    enum bufferevent_ssl_state state,\n    int options,\n\tstruct le_ssl_ops *ssl_ops)\n{\n\tstruct bufferevent_ssl *bev_ssl = NULL;\n\tstruct bufferevent_private *bev_p = NULL;\n\tint tmp_options = options & ~BEV_OPT_THREADSAFE;\n\n\t/* Only one can be set. */\n\tif (underlying != NULL && fd >= 0)\n\t\tgoto err;\n\n\tif (!(bev_ssl = mm_calloc(1, sizeof(struct bufferevent_ssl))))\n\t\tgoto err;\n\n\tbev_p = &bev_ssl->bev;\n\n\tif (bufferevent_init_common_(bev_p, base,\n\t\t&bufferevent_ops_ssl, tmp_options) < 0)\n\t\tgoto err;\n\n\tbev_ssl->ssl_ops = ssl_ops;\n\n\tbev_ssl->ssl = bev_ssl->ssl_ops->init(ssl);\n\n\tbev_ssl->underlying = underlying;\n\n\tbev_ssl->outbuf_cb = evbuffer_add_cb(bev_p->bev.output,\n\t    be_ssl_outbuf_cb, bev_ssl);\n\n\tif (options & BEV_OPT_THREADSAFE)\n\t\tbufferevent_enable_locking_(&bev_ssl->bev.bev, NULL);\n\n\tif (underlying) {\n\t\tbufferevent_init_generic_timeout_cbs_(&bev_ssl->bev.bev);\n\t\tbufferevent_incref_(underlying);\n\t}\n\n\tbev_ssl->old_state = state;\n\tbev_ssl->last_write = -1;\n\n\tbev_ssl->ssl_ops->init_bio_counts(bev_ssl);\n\n\tfd = be_ssl_auto_fd(bev_ssl, fd);\n\tif (be_ssl_set_fd(bev_ssl, state, fd))\n\t\tgoto err;\n\n\tif (underlying) {\n\t\tbufferevent_setwatermark(underlying, EV_READ, 0, 0);\n\t\tbufferevent_enable(underlying, EV_READ|EV_WRITE);\n\t\tif (state == BUFFEREVENT_SSL_OPEN)\n\t\t\tbufferevent_suspend_read_(underlying,\n\t\t\t    BEV_SUSPEND_FILT_READ);\n\t}\n\n\treturn &bev_ssl->bev.bev;\nerr:\n\tif (bev_ssl) {\n\t\tif (bev_ssl->ssl && bev_ssl->ssl_ops && options & BEV_OPT_CLOSE_ON_FREE)\n\t\t\tbev_ssl->ssl_ops->free(bev_ssl->ssl, options);\n\t\tbev_ssl->ssl = NULL;\n\t\tbufferevent_free(&bev_ssl->bev.bev);\n\t} else {\n\t\tif (ssl && options & BEV_OPT_CLOSE_ON_FREE)\n\t\t\tssl_ops->free_raw(ssl);\n\t}\n\treturn NULL;\n}\n\nunsigned long\nbufferevent_get_ssl_error(struct bufferevent *bev)\n{\n\tunsigned long err = 0;\n\tstruct bufferevent_ssl *bev_ssl;\n\n\tif (BEV_IS_SSL(bev))\n\t\treturn err;\n\n\tBEV_LOCK(bev);\n\tbev_ssl = bufferevent_ssl_upcast(bev);\n\tif (bev_ssl->n_errors) {\n\t\terr = bev_ssl->errors[--bev_ssl->n_errors];\n\t}\n\tBEV_UNLOCK(bev);\n\treturn err;\n}\n\nev_uint64_t bufferevent_ssl_get_flags(struct bufferevent *bev)\n{\n\tev_uint64_t flags = EV_UINT64_MAX;\n\tstruct bufferevent_ssl *bev_ssl;\n\n\tif (!BEV_IS_SSL(bev))\n\t\treturn flags;\n\n\tBEV_LOCK(bev);\n\tbev_ssl = bufferevent_ssl_upcast(bev);\n\tflags = bev_ssl->flags;\n\tBEV_UNLOCK(bev);\n\n\treturn flags;\n}\nev_uint64_t bufferevent_ssl_set_flags(struct bufferevent *bev, ev_uint64_t flags)\n{\n\tev_uint64_t old_flags = EV_UINT64_MAX;\n\tstruct bufferevent_ssl *bev_ssl;\n\n\tflags &= (BUFFEREVENT_SSL_DIRTY_SHUTDOWN|BUFFEREVENT_SSL_BATCH_WRITE);\n\tif (!flags || !BEV_IS_SSL(bev))\n\t\treturn old_flags;\n\n\tBEV_LOCK(bev);\n\tbev_ssl = bufferevent_ssl_upcast(bev);\n\told_flags = bev_ssl->flags;\n\tbev_ssl->flags |= flags;\n\tBEV_UNLOCK(bev);\n\n\treturn old_flags;\n}\nev_uint64_t bufferevent_ssl_clear_flags(struct bufferevent *bev, ev_uint64_t flags)\n{\n\tev_uint64_t old_flags = EV_UINT64_MAX;\n\tstruct bufferevent_ssl *bev_ssl;\n\n\tflags &= (BUFFEREVENT_SSL_DIRTY_SHUTDOWN|BUFFEREVENT_SSL_BATCH_WRITE);\n\tif (!flags || !BEV_IS_SSL(bev))\n\t\treturn old_flags;\n\n\tBEV_LOCK(bev);\n\tbev_ssl = bufferevent_ssl_upcast(bev);\n\told_flags = bev_ssl->flags;\n\tbev_ssl->flags &= ~flags;\n\tBEV_UNLOCK(bev);\n\n\treturn old_flags;\n}\n\nint\nbufferevent_ssl_get_allow_dirty_shutdown(struct bufferevent *bev)\n{\n\tev_uint64_t flags = bufferevent_ssl_get_flags(bev);\n\tif (flags == EV_UINT64_MAX)\n\t\treturn flags;\n\treturn !!(flags & BUFFEREVENT_SSL_DIRTY_SHUTDOWN);\n}\n\nvoid\nbufferevent_ssl_set_allow_dirty_shutdown(\n\tstruct bufferevent *bev, int allow_dirty_shutdown)\n{\n\tBEV_LOCK(bev);\n\n\tif (allow_dirty_shutdown)\n\t\tbufferevent_ssl_set_flags(bev, BUFFEREVENT_SSL_DIRTY_SHUTDOWN);\n\telse\n\t\tbufferevent_ssl_clear_flags(bev, BUFFEREVENT_SSL_DIRTY_SHUTDOWN);\n\n\tBEV_UNLOCK(bev);\n}\n"
        },
        {
          "name": "changelist-internal.h",
          "type": "blob",
          "size": 4.5185546875,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef CHANGELIST_INTERNAL_H_INCLUDED_\n#define CHANGELIST_INTERNAL_H_INCLUDED_\n\n/*\n  A \"changelist\" is a list of all the fd status changes that should be made\n  between calls to the backend's dispatch function.  There are a few reasons\n  that a backend would want to queue changes like this rather than processing\n  them immediately.\n\n    1) Sometimes applications will add and delete the same event more than\n       once between calls to dispatch.  Processing these changes immediately\n       is needless, and potentially expensive (especially if we're on a system\n       that makes one syscall per changed event).\n\n    2) Sometimes we can coalesce multiple changes on the same fd into a single\n       syscall if we know about them in advance.  For example, epoll can do an\n       add and a delete at the same time, but only if we have found out about\n       both of them before we tell epoll.\n\n    3) Sometimes adding an event that we immediately delete can cause\n       unintended consequences: in kqueue, this makes pending events get\n       reported spuriously.\n */\n\n#include \"event2/util.h\"\n\n/** Represents a */\nstruct event_change {\n\t/** The fd or signal whose events are to be changed */\n\tevutil_socket_t fd;\n\t/* The events that were enabled on the fd before any of these changes\n\t   were made.  May include EV_READ or EV_WRITE. */\n\tshort old_events;\n\n\t/* The changes that we want to make in reading and writing on this fd.\n\t * If this is a signal, then read_change has EV_CHANGE_SIGNAL set,\n\t * and write_change is unused. */\n\tev_uint8_t read_change;\n\tev_uint8_t write_change;\n\tev_uint8_t close_change;\n};\n\n/* Flags for read_change and write_change. */\n\n/* If set, add the event. */\n#define EV_CHANGE_ADD     0x01\n/* If set, delete the event.  Exclusive with EV_CHANGE_ADD */\n#define EV_CHANGE_DEL     0x02\n/* If set, this event refers a signal, not an fd. */\n#define EV_CHANGE_SIGNAL  EV_SIGNAL\n/* Set for persistent events.  Currently not used. */\n#define EV_CHANGE_PERSIST EV_PERSIST\n/* Set for adding edge-triggered events. */\n#define EV_CHANGE_ET      EV_ET\n\n/* The value of fdinfo_size that a backend should use if it is letting\n * changelist handle its add and delete functions. */\n#define EVENT_CHANGELIST_FDINFO_SIZE sizeof(int)\n\n/** Set up the data fields in a changelist. */\nvoid event_changelist_init_(struct event_changelist *changelist);\n/** Remove every change in the changelist, and make corresponding changes\n * in the event maps in the base.  This function is generally used right\n * after making all the changes in the changelist. */\nvoid event_changelist_remove_all_(struct event_changelist *changelist,\n    struct event_base *base);\n/** Free all memory held in a changelist. */\nvoid event_changelist_freemem_(struct event_changelist *changelist);\n\n/** Implementation of eventop_add that queues the event in a changelist. */\nint event_changelist_add_(struct event_base *base, evutil_socket_t fd, short old, short events,\n    void *p);\n/** Implementation of eventop_del that queues the event in a changelist. */\nint event_changelist_del_(struct event_base *base, evutil_socket_t fd, short old, short events,\n    void *p);\n\n#endif\n"
        },
        {
          "name": "checkpatch.sh",
          "type": "blob",
          "size": 6.8818359375,
          "content": "#!/usr/bin/env bash\n\n# TODO:\n# - inline replace\n# - clang-format-diff replacement\n# - uncrustify for patches (not git refs)\n# - maybe integrate into travis-ci?\n\nfunction usage()\n{\n    cat <<EOL\n$0 [ OPTS ] [ file-or-gitref [ ... ] ]\n\nExample:\n  # Chech HEAD git ref\n  $ $0 -r\n  $ $0 -r HEAD\n\n  # Check patch\n  $ git format-patch --stdout -1 | $0 -p\n  $ git show -1 | $0 -p\n\n  # Or via regular files\n  $ git format-patch --stdout -2\n  $ $0 *.patch\n\n  # Over a file\n  $ $0 -d event.c\n  $ $0 -d < event.c\n\n  # And print the whole file not only summary\n  $ $0 -f event.c\n  $ $0 -f < event.c\n\nOPTS:\n  -p   - treat as patch\n  -f   - treat as regular file\n  -d   - treat as regular file and print diff\n  -r   - treat as git revision (default)\n  -C   - check using clang-format (default)\n  -U   - check with uncrustify\n  -c   - config for clang-format/uncrustify\n  -h   - print this message\nEOL\n}\nfunction cfg()\n{\n    [ -z \"${options[cfg]}\" ] || {\n        echo \"${options[cfg]}\"\n        return\n    }\n\n    local dir=\"$(dirname \"${BASH_SOURCE[0]}\")\"\n    [ \"${options[clang]}\" -eq 0 ] || {\n        echo \"$dir/.clang-format\"\n        return\n    }\n    [ \"${options[uncrustify]}\" -eq 0 ] || {\n        echo \"$dir/.uncrustify\"\n        return\n    }\n}\nfunction abort()\n{\n    local msg=\"$1\"\n    shift\n\n    printf \"$msg\\n\" \"$@\" >&2\n    exit 1\n}\nfunction default_arg()\n{\n    if [ \"${options[ref]}\" -eq 1 ]; then\n        echo \"HEAD\"\n    else\n        [ ! -t 0 ] || abort \"<stdin> is a tty\"\n        echo \"/dev/stdin\"\n    fi\n}\nfunction parse_options()\n{\n    options[patch]=0\n    options[file]=0\n    options[file_diff]=0\n    options[ref]=1\n    options[clang]=1\n    options[uncrustify]=0\n    options[cfg]=\n\n    local OPTARG OPTIND c\n    while getopts \"pfrdCUc:h?\" c; do\n        case \"$c\" in\n            p)\n                options[patch]=1\n                options[ref]=0\n                options[file]=0\n                options[file_diff]=0\n                ;;\n            f)\n                options[file]=1\n                options[ref]=0\n                options[patch]=0\n                options[file_diff]=0\n                ;;\n            r)\n                options[ref]=1\n                options[file]=0\n                options[patch]=0\n                options[file_diff]=0\n                ;;\n            d)\n                options[file_diff]=1\n                options[file]=0\n                options[patch]=0\n                options[ref]=0\n                ;;\n            C)\n                options[clang]=1\n                options[uncrustify]=0\n                ;;\n            U)\n                options[uncrustify]=1\n                options[clang]=0\n                ;;\n            c) options[cfg]=\"$OPTIND\" ;;\n            ?|h)\n                usage\n                exit 0\n                ;;\n            *)\n                usage\n                exit 1\n                ;;\n        esac\n    done\n\n    options[cfg]=\"$(cfg)\"\n\n    [ -f \"${options[cfg]}\" ] || \\\n        abort \"Config '%s' does not exist\" \"${options[cfg]}\"\n\n    shift $((OPTIND - 1))\n    args=( \"$@\" )\n\n    if [ ${#args[@]} -eq 0 ]; then\n        # exit on error globally, not only in subshell\n        default_arg > /dev/null\n        args=( \"$(default_arg)\" )\n    fi\n\n    if [ \"${args[0]}\" = \"/dev/stdin\" ]; then\n        TMP_FILE=\"/tmp/libevent.checkpatch.$RANDOM\"\n        cat > \"$TMP_FILE\"\n        trap \"rm '$TMP_FILE'\" EXIT\n\n        args[0]=\"$TMP_FILE\"\n    fi\n}\n\nfunction diff() { command diff --color=always \"$@\"; }\n\nfunction clang_style()\n{\n    local c=\"${options[cfg]}\"\n    echo \"{ $(sed -e 's/#.*//' -e '/---/d' -e '/\\.\\.\\./d' \"$c\" | tr $'\\n' ,) }\"\n}\nfunction clang_format() { clang-format -style=\"$(clang_style)\" \"$@\"; }\nfunction clang_format_diff() { cat \"$@\" | clang-format-diff -p1 -style=\"$(clang_style)\"; }\n# for non-bare repo will work\nfunction clang_format_git()\n{ git format-patch --stdout \"$@\" -1 | clang_format_diff; }\n\nfunction uncrustify() { command uncrustify -c \"${options[cfg]}\" \"$@\"; }\nfunction uncrustify_frag() { uncrustify -l C --frag \"$@\"; }\nfunction uncrustify_indent_off() { echo '/* *INDENT-OFF* */'; }\nfunction uncrustify_indent_on() { echo '/* *INDENT-ON* */'; }\nfunction git_hunk()\n{\n    local ref=$1 f=$2\n    shift 2\n    git cat-file -p $ref:$f\n}\nfunction uncrustify_git_indent_hunk()\n{\n    local start=$1 end=$2\n    shift 2\n\n    # Will be beatier with tee(1), but doh bash async substitution\n    { uncrustify_indent_off; git_hunk \"$@\" | head -n$((start - 1)); }\n    { uncrustify_indent_on;  git_hunk \"$@\" | head -n$((end - 1)) | tail -n+$start; }\n    { uncrustify_indent_off; git_hunk \"$@\" | tail -n+$((end + 1)); }\n}\nfunction strip()\n{\n    local start=$1 end=$2\n    shift 2\n\n    # seek indent_{on,off}()\n    let start+=2\n    head -n$end | tail -n+$start\n}\nfunction patch_ranges()\n{\n    egrep -o '^@@ -[0-9]+(,[0-9]+|) \\+[0-9]+(,[0-9]+|) @@' | \\\n        cut -d' ' -f3\n}\nfunction git_ranges()\n{\n    local ref=$1 f=$2\n    shift 2\n\n    git diff -W $ref^..$ref -- $f | patch_ranges\n}\nfunction diff_substitute()\n{\n    local f=\"$1\"\n    shift\n\n    sed \\\n        -e \"s#^--- /dev/fd.*\\$#--- a/$f#\" \\\n        -e \"s#^+++ /dev/fd.*\\$#+++ b/$f#\"\n}\nfunction uncrustify_git()\n{\n    local ref=$1 r f start end length\n    shift\n\n    local files=( $(git diff --name-only $ref^..$ref | egrep \"\\.(c|h)$\") )\n    for f in \"${files[@]}\"; do\n        local ranges=( $(git_ranges $ref \"$f\") )\n        for r in \"${ranges[@]}\"; do\n            [[ ! \"$r\" =~ ^\\+([0-9]+)(,([0-9]+)|)$ ]] && continue\n            start=${BASH_REMATCH[1]}\n            [ -n \"${BASH_REMATCH[3]}\" ] && \\\n                length=${BASH_REMATCH[3]} || \\\n                length=1\n            end=$((start + length))\n            echo \"Range: $start:$end ($length)\" >&2\n\n            diff -u \\\n                <(uncrustify_git_indent_hunk $start $end $ref \"$f\" | strip $start $end) \\\n                <(uncrustify_git_indent_hunk $start $end $ref \"$f\" | uncrustify_frag | strip $start $end) \\\n            | diff_substitute \"$f\"\n        done\n    done\n}\nfunction uncrustify_diff() { abort \"Not implemented\"; }\nfunction uncrustify_file() { uncrustify -f \"$@\"; }\n\nfunction checker()\n{\n    local c=$1 u=$2\n    shift 2\n\n    [ \"${options[clang]}\" -eq 0 ] || {\n        $c \"$@\"\n        return\n    }\n    [ \"${options[uncrustify]}\" -eq 0 ] || {\n        $u \"$@\"\n        return\n    }\n}\nfunction check_patch() { checker clang_format_diff uncrustify_diff \"$@\"; }\nfunction check_file() { checker clang_format uncrustify_file \"$@\"; }\nfunction check_ref() { checker clang_format_git uncrustify_git \"$@\"; }\n\nfunction check_arg()\n{\n    [ \"${options[patch]}\" -eq 0 ] || {\n        check_patch \"$@\"\n        return\n    }\n    [ \"${options[file]}\" -eq 0 ] || {\n        check_file \"$@\"\n        return\n    }\n    [ \"${options[file_diff]}\" -eq 0 ] || {\n        diff -u \"$@\" <(check_file \"$@\") | diff_substitute \"$@\"\n        return\n    }\n    [ \"${options[ref]}\" -eq 0 ] || {\n        check_ref \"$@\"\n        return\n    }\n}\n\nfunction main()\n{\n    local a\n    for a in \"${args}\"; do\n        check_arg \"$a\"\n    done\n}\n\ndeclare -A options\nparse_options \"$@\"\n\nmain \"$@\" | less -FRSX\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "compat",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 25.158203125,
          "content": "dnl Copyright 2000-2007 Niels Provos\ndnl Copyright 2007-2012 Niels Provos and Nick Mathewson\ndnl\ndnl See LICENSE for copying information.\ndnl\ndnl Original version Dug Song <dugsong@monkey.org>\n\nAC_PREREQ([2.67])\nAC_INIT(libevent,2.2.1-alpha-dev)\nAC_CONFIG_SRCDIR(event.c)\n\nAC_CONFIG_MACRO_DIR([m4])\nAC_CONFIG_AUX_DIR([build-aux])\n\ndnl Automake setup\ndnl 'foreign' means that GNU package rules are not strictly enforced.\nAM_INIT_AUTOMAKE([1.13 foreign subdir-objects])\n\ndnl make compilation quiet unless V=1 is used\nAM_SILENT_RULES([yes])\n\nAC_CONFIG_HEADERS(config.h  evconfig-private.h:evconfig-private.h.in)\ndnl The last number is development version or not.\nAC_DEFINE(NUMERIC_VERSION, 0x02020100, [Numeric representation of the version])\n\ndnl Try and get a full POSIX environment on obscure systems\nAC_USE_SYSTEM_EXTENSIONS\n\ndnl the 'build' machine is where we run configure and compile\ndnl the 'host' machine is where the resulting stuff runs.\nAC_CANONICAL_BUILD\nAC_CANONICAL_HOST\n\ndnl Checks for programs.\nAM_PROG_CC_C_O\nAC_PROG_INSTALL\nAC_PROG_LN_S\nAC_PROG_SED\n\nAC_ARG_ENABLE([gcc-warnings],\n     AS_HELP_STRING([--disable-gcc-warnings, disable verbose warnings with GCC]))\n\nAC_ARG_ENABLE([gcc-hardening],\n     AS_HELP_STRING([--enable-gcc-hardening, enable compiler security checks]),\n[if test \"$enableval\" = \"yes\"; then\n    CFLAGS=\"$CFLAGS -D_FORTIFY_SOURCE=3 -fstack-protector-all\"\n    CFLAGS=\"$CFLAGS -fwrapv -fPIE -Wstack-protector\"\n    CFLAGS=\"$CFLAGS --param ssp-buffer-size=1\"\nfi])\n\nAC_ARG_ENABLE([thread-support],\n    AS_HELP_STRING([--disable-thread-support, disable support for threading]),\n\t[], [enable_thread_support=yes])\nAC_ARG_ENABLE([malloc-replacement],\n    AS_HELP_STRING([--disable-malloc-replacement, disable support for replacing the memory mgt functions]),\n    [], [enable_malloc_replacement=yes])\nAC_ARG_ENABLE([openssl],\n     AS_HELP_STRING([--disable-openssl, disable support for openssl encryption]),\n    [], [enable_openssl=auto])\nAC_ARG_ENABLE([mbedtls],\n     AS_HELP_STRING([--disable-mbedtls, disable support for mbedtls encryption]),\n    [], [enable_mbedtls=auto])\nAC_ARG_ENABLE([debug-mode],\n     AS_HELP_STRING([--disable-debug-mode, disable support for running in debug mode]),\n    [], [enable_debug_mode=yes])\nAC_ARG_ENABLE([libevent-install],\n     AS_HELP_STRING([--disable-libevent-install, disable installation of libevent]),\n\t[], [enable_libevent_install=yes])\nAC_ARG_ENABLE([libevent-regress],\n     AS_HELP_STRING([--disable-libevent-regress, skip regress in make check]),\n\t[], [enable_libevent_regress=yes])\nAC_ARG_ENABLE([samples],\n     AS_HELP_STRING([--disable-samples, skip building of sample programs]),\n\t[], [enable_samples=yes])\nAC_ARG_ENABLE([function-sections],\n     AS_HELP_STRING([--enable-function-sections, make static library allow smaller binaries with --gc-sections]),\n\t[], [enable_function_sections=no])\nAC_ARG_ENABLE([verbose-debug],\n\t\tAS_HELP_STRING([--enable-verbose-debug, verbose debug logging]),\n\t[], [enable_verbose_debug=no])\nAC_ARG_ENABLE([clock-gettime],\n     AS_HELP_STRING([--disable-clock-gettime, do not use clock_gettime even if it is available]),\n  [], [enable_clock_gettime=yes])\n\n\nLT_PREREQ([2.4.2])\nLT_INIT\n\nAC_SUBST(LIBTOOL_DEPS)\n\nAM_CONDITIONAL([BUILD_SAMPLES], [test \"$enable_samples\" = \"yes\"])\nAM_CONDITIONAL([BUILD_REGRESS], [test \"$enable_libevent_regress\" = \"yes\"])\n\ndnl Checks for libraries.\nAC_SEARCH_LIBS([inet_ntoa], [nsl])\nAC_SEARCH_LIBS([socket], [socket])\nAC_SEARCH_LIBS([inet_aton], [resolv])\nif test \"$enable_clock_gettime\" = \"yes\"; then\n  AC_SEARCH_LIBS([clock_gettime], [rt])\n  AC_CHECK_FUNCS([clock_gettime])\nfi\nAC_SEARCH_LIBS([sendfile], [sendfile])\n\ndnl - check if the macro _WIN32 is defined on this compiler.\ndnl - (this is how we check for a windows compiler)\nAC_MSG_CHECKING(for WIN32)\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([],\n    [\n#ifndef _WIN32\ndie horribly\n#endif\n    ]\n  )],\n\t[bwin32=true; AC_MSG_RESULT(yes)],\n\t[bwin32=false; AC_MSG_RESULT(no)]\n)\n\ndnl - check if the macro __midipix__ is defined on this compiler.\ndnl - (this is how we check for a midipix version of GCC)\nAC_MSG_CHECKING(for MIDIPIX)\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([],\n    [\n#ifndef __midipix__\ndie horribly\n#endif\n    ]\n  )],\n\t[midipix=true; AC_MSG_RESULT(yes)],\n\t[midipix=false; AC_MSG_RESULT(no)]\n)\n\ndnl - check if the macro __CYGWIN__ is defined on this compiler.\ndnl - (this is how we check for a cygwin version of GCC)\nAC_MSG_CHECKING(for CYGWIN)\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([],\n    [\n#ifndef __CYGWIN__\ndie horribly\n#endif\n    ]\n  )],\n\t[cygwin=true; AC_MSG_RESULT(yes)],\n\t[cygwin=false; AC_MSG_RESULT(no)]\n)\n\nAC_CHECK_HEADERS([zlib.h])\n\nif test \"$ac_cv_header_zlib_h\" = \"yes\"; then\ndnl Determine if we have zlib for regression tests\ndnl Don't put this one in LIBS\nsave_LIBS=\"$LIBS\"\nLIBS=\"\"\nZLIB_LIBS=\"\"\nhave_zlib=no\nAC_SEARCH_LIBS([inflateEnd], [z],\n\t[have_zlib=yes\n\tZLIB_LIBS=\"$LIBS\"\n\tAC_DEFINE(HAVE_LIBZ, 1, [Define if the system has zlib])])\nLIBS=\"$save_LIBS\"\nAC_SUBST(ZLIB_LIBS)\nfi\nAM_CONDITIONAL(ZLIB_REGRESS, [test \"$have_zlib\" = \"yes\"])\n\ndnl See if we have openssl.  This doesn't go in LIBS either.\nif test \"$bwin32\" = \"true\"; then\n  EV_LIB_WS32=-lws2_32\n  EV_LIB_GDI=-lgdi32\nelse\n  EV_LIB_WS32=\n  EV_LIB_GDI=\nfi\nAC_SUBST(EV_LIB_WS32)\nAC_SUBST(EV_LIB_GDI)\nAC_SUBST(OPENSSL_LIBADD)\n\nAC_SYS_LARGEFILE\n\nLIBEVENT_OPENSSL\nLIBEVENT_MBEDTLS\n\ndnl Checks for header files.\nAC_CHECK_HEADERS([arpa/inet.h fcntl.h ifaddrs.h mach/mach_time.h mach/mach.h netdb.h netinet/in.h netinet/in6.h netinet/tcp.h sys/un.h poll.h port.h stdarg.h stddef.h sys/devpoll.h sys/epoll.h sys/event.h sys/eventfd.h sys/ioctl.h sys/mman.h sys/param.h sys/queue.h sys/resource.h sys/select.h sys/sendfile.h sys/socket.h sys/stat.h sys/time.h sys/timerfd.h sys/signalfd.h sys/uio.h sys/wait.h sys/random.h errno.h afunix.h])\n\ncase \"${host_os}\" in\n    linux*) ;;\n    *)\n        AC_CHECK_HEADERS(sys/sysctl.h, [], [], [\n        #ifdef HAVE_SYS_PARAM_H\n        #include <sys/param.h>\n        #endif\n        ])\nesac\n\ndnl if we have sys/time.h, check for timer* macros\nif test \"$ac_cv_header_sys_time_h\" = \"yes\"; then\n\nAC_MSG_CHECKING(for timeradd in sys/time.h)\nAC_EGREP_CPP(yes, [\n    #include <sys/time.h>\n    #ifdef timeradd\n     yes\n    #endif],\n    [AC_MSG_RESULT(yes); AC_DEFINE(HAVE_TIMERADD, 1, [Define if timeradd is defined in <sys/time.h>])],\n    [AC_MSG_RESULT(no)]\n)\n\nAC_MSG_CHECKING(for timerclear in sys/time.h)\nAC_EGREP_CPP(yes, [\n    #include <sys/time.h>\n    #ifdef timerclear\n     yes\n    #endif],\n    [AC_MSG_RESULT(yes); AC_DEFINE(HAVE_TIMERCLEAR, 1, [Define if timerclear is defined in <sys/time.h>])],\n    [AC_MSG_RESULT(no)]\n)\n\nAC_MSG_CHECKING(for timerisset in sys/time.h)\nAC_EGREP_CPP(yes, [\n    #include <sys/time.h>\n    #ifdef timerisset\n     yes\n    #endif],\n    [AC_MSG_RESULT(yes); AC_DEFINE(HAVE_TIMERISSET, 1, [Define if timerisset is defined in <sys/time.h>])],\n    [AC_MSG_RESULT(no)]\n)\nfi\n\nif test \"$ac_cv_header_sys_sysctl_h\" = \"yes\"; then\n\tAC_CHECK_DECLS([CTL_KERN, KERN_ARND], [], [],\n\t   [[#include <sys/types.h>\n\t     #include <sys/sysctl.h>]]\n\t)\nfi\n\nAM_CONDITIONAL(BUILD_WIN32, test \"$bwin32\" = \"true\")\nAM_CONDITIONAL(BUILD_CYGWIN, test \"$cygwin\" = \"true\")\nAM_CONDITIONAL(BUILD_MIDIPIX, test \"$midipix\" = \"true\")\nAM_CONDITIONAL(BUILD_WITH_NO_UNDEFINED, test x$bwin32 = xtrue || test x$cygwin = xtrue || test x$midipix = xtrue)\n\nif test \"$bwin32\" = \"true\"; then\n  AC_CHECK_LIB([ws2_32], [main])\n  AC_CHECK_LIB([iphlpapi], [GetAdaptersAddresses])\nfi\n\ndnl Checks for typedefs, structures, and compiler characteristics.\nAC_C_INLINE\n\ndnl Checks for library functions.\nAC_CHECK_FUNCS([accept4 arc4random arc4random_buf arc4random_stir epoll_create1 epoll_pwait2 eventfd fcntl getegid geteuid getifaddrs getrandom gettimeofday issetugid mach_absolute_time mmap mmap64 nanosleep pipe pipe2 pread putenv sendfile setenv setrlimit sigaction signal socketpair strlcpy strsep strsignal strtok_r strtoll sysctl timerfd_create umask unsetenv usleep])\n\nAS_IF([test \"$bwin32\" = \"true\"],\n  AC_CHECK_FUNCS(_gmtime64_s, , [AC_CHECK_FUNCS(_gmtime64)])\n)\n\nAM_CONDITIONAL(STRLCPY_IMPL, [test \"$ac_cv_func_strlcpy\" = \"no\"])\n\nm4_define([funcstochk], [getnameinfo getprotobynumber getservbyname inet_ntop inet_pton])\n\nAS_IF([test \"$bwin32\" = \"true\"],\n  [AX_CHECK_DECLS_EX([funcstochk getaddrinfo],\n    [#ifdef _WIN32\n    #include <winsock2.h>\n    #include <ws2tcpip.h>\n    #endif])],\n  [AC_CHECK_FUNCS(m4_normalize(funcstochk))]\n)\n\nm4_undefine([funcstochk])\n\ndnl check getaddrinfo and gethostbyname_r for non-windows\nAS_IF([test x$bwin32 = xfalse], [\nAC_CACHE_CHECK(\n    [for getaddrinfo],\n    [libevent_cv_getaddrinfo],\n    [AC_LINK_IFELSE(\n\t[AC_LANG_PROGRAM(\n\t    [[\n\t\t#ifdef HAVE_NETDB_H\n\t\t#include <netdb.h>\n\t\t#endif\n\t    ]],\n\t    [[\n\t\tgetaddrinfo;\n\t    ]]\n\t)],\n\t[libevent_cv_getaddrinfo=yes],\n\t[libevent_cv_getaddrinfo=no]\n    )]\n)\nif test \"$libevent_cv_getaddrinfo\" = \"yes\" ; then\n    AC_DEFINE([HAVE_GETADDRINFO], [1], [Do we have getaddrinfo()?])\nelse\n\ndnl Check for gethostbyname_r in all its glorious incompatible versions.\ndnl   (This is cut-and-pasted from Tor, which based its logic on\ndnl   Python's configure.in.)\nAH_TEMPLATE(HAVE_GETHOSTBYNAME_R,\n  [Define this if you have any gethostbyname_r()])\n\nAC_CHECK_FUNC(gethostbyname_r, [\n  AC_MSG_CHECKING([how many arguments gethostbyname_r() wants])\n  OLD_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS $MY_CPPFLAGS $MY_THREAD_CPPFLAGS $MY_CFLAGS\"\n  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#include <netdb.h>\n  ], [[\n    char *cp1, *cp2;\n    struct hostent *h1, *h2;\n    int i1, i2;\n    (void)gethostbyname_r(cp1,h1,cp2,i1,&h2,&i2);\n  ]])],[\n    AC_DEFINE(HAVE_GETHOSTBYNAME_R)\n    AC_DEFINE(HAVE_GETHOSTBYNAME_R_6_ARG, 1,\n     [Define this if gethostbyname_r takes 6 arguments])\n    AC_MSG_RESULT(6)\n  ], [\n    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#include <netdb.h>\n    ], [\n      char *cp1, *cp2;\n      struct hostent *h1;\n      int i1, i2;\n      (void)gethostbyname_r(cp1,h1,cp2,i1,&i2);\n    ])], [\n      AC_DEFINE(HAVE_GETHOSTBYNAME_R)\n      AC_DEFINE(HAVE_GETHOSTBYNAME_R_5_ARG, 1,\n        [Define this if gethostbyname_r takes 5 arguments])\n      AC_MSG_RESULT(5)\n    ], [\n      AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#include <netdb.h>\n     ], [\n       char *cp1;\n       struct hostent *h1;\n       struct hostent_data hd;\n       (void) gethostbyname_r(cp1,h1,&hd);\n     ])], [\n       AC_DEFINE(HAVE_GETHOSTBYNAME_R)\n       AC_DEFINE(HAVE_GETHOSTBYNAME_R_3_ARG, 1,\n         [Define this if gethostbyname_r takes 3 arguments])\n       AC_MSG_RESULT(3)\n     ], [\n       AC_MSG_RESULT(0)\n     ])\n  ])\n ])\n CFLAGS=$OLD_CFLAGS\n])\n\nfi\n]) dnl end of checking getaddrinfo and gethostbyname_r\n\nAC_MSG_CHECKING(for F_SETFD in fcntl.h)\nAC_EGREP_CPP(yes,\n[\n#define _GNU_SOURCE 1\n#include <fcntl.h>\n#ifdef F_SETFD\nyes\n#endif\n],\t[ AC_DEFINE(HAVE_SETFD, 1,\n\t      [Define if F_SETFD is defined in <fcntl.h>])\n\t  AC_MSG_RESULT(yes) ], AC_MSG_RESULT(no))\n\nneedsignal=no\nhaveselect=no\nif test \"$bwin32\" != \"true\"; then\n    AC_CHECK_FUNCS(select, [haveselect=yes], )\n    if test \"$haveselect\" = \"yes\" ; then\n \tneedsignal=yes\n    fi\nfi\nAM_CONDITIONAL(SELECT_BACKEND, [test \"$haveselect\" = \"yes\"])\n\nhavepoll=no\nAC_CHECK_FUNCS(poll, [havepoll=yes], )\nif test \"$havepoll\" = \"yes\" ; then\n\tneedsignal=yes\nfi\nAM_CONDITIONAL(POLL_BACKEND, [test \"$havepoll\" = \"yes\"])\n\nhavedevpoll=no\nif test \"$ac_cv_header_sys_devpoll_h\" = \"yes\"; then\n\tAC_DEFINE(HAVE_DEVPOLL, 1,\n\t\t    [Define if /dev/poll is available])\nfi\nAM_CONDITIONAL(DEVPOLL_BACKEND, [test \"$ac_cv_header_sys_devpoll_h\" = \"yes\"])\n\nhavekqueue=no\nif test \"$ac_cv_header_sys_event_h\" = \"yes\"; then\n\tAC_CHECK_FUNCS(kqueue, [havekqueue=yes], )\n\tif test \"$havekqueue\" = \"yes\" ; then\n\t\tAC_MSG_CHECKING(for working kqueue)\n\t\tAC_RUN_IFELSE(\n      [AC_LANG_PROGRAM([\n#ifdef HAVE_STDLIB_H\n#include <stdlib.h>\n#endif\n#ifdef HAVE_STRING_H\n#include <string.h>\n#endif\n#include <sys/types.h>\n#include <sys/time.h>\n#include <sys/event.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\n        ], [[\n\tint kq;\n\tint n;\n\tint fd[2];\n\tstruct kevent ev;\n\tstruct timespec ts;\n\tchar buf[80000];\n\n\tif (pipe(fd) == -1)\n  \t\treturn 1;\n\tif (fcntl(fd[1], F_SETFL, O_NONBLOCK) == -1)\n\t\treturn 1;\n\n\twhile ((n = write(fd[1], buf, sizeof(buf))) == sizeof(buf))\n\t\t;\n\n\tif ((kq = kqueue()) == -1)\n\t\treturn 1;\n\n\tmemset(&ev, 0, sizeof(ev));\n\tev.ident = fd[1];\n\tev.filter = EVFILT_WRITE;\n\tev.flags = EV_ADD | EV_ENABLE;\n\tn = kevent(kq, &ev, 1, NULL, 0, NULL);\n\tif (n == -1)\n\t\treturn 1;\n\n\tread(fd[0], buf, sizeof(buf));\n\n\tts.tv_sec = 0;\n\tts.tv_nsec = 0;\n\tn = kevent(kq, NULL, 0, &ev, 1, &ts);\n\tif (n == -1 || n == 0)\n\t\treturn 1;\n\n\treturn 0;\n        ]]\n      )],\n      [AC_MSG_RESULT(yes)\n      AC_DEFINE(HAVE_WORKING_KQUEUE, 1,\n        [Define if kqueue works correctly with pipes])\n      havekqueue=yes\n      ], [AC_MSG_RESULT(no)], [AC_MSG_RESULT(no)]\n    )\n\tfi\nfi\nAM_CONDITIONAL(KQUEUE_BACKEND, [test \"$havekqueue\" = \"yes\"])\n\nhaveepollsyscall=no\nhaveepoll=no\nAC_CHECK_FUNCS(epoll_ctl, [haveepoll=yes], )\nif test \"$haveepoll\" = \"yes\" ; then\n\tAC_DEFINE(HAVE_EPOLL, 1,\n\t\t[Define if your system supports the epoll system calls])\n\tneedsignal=yes\nfi\nif test \"$ac_cv_header_sys_epoll_h\" = \"yes\"; then\n\tif test \"$haveepoll\" = \"no\" ; then\n\t\tAC_MSG_CHECKING(for epoll system call)\n\t\tAC_RUN_IFELSE(\n      [AC_LANG_PROGRAM([[\n#include <stdint.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/syscall.h>\n#include <sys/epoll.h>\n#include <unistd.h>\n\nint\nepoll_create(int size)\n{\n\treturn (syscall(__NR_epoll_create, size));\n}\n        ]],[[\n\tint epfd;\n\n\tepfd = epoll_create(256);\n\treturn (epfd == -1 ? 1 : 0);\n        ]]\n      )], \n      [AC_MSG_RESULT(yes)\n      AC_DEFINE(HAVE_EPOLL, 1,\n\t      [Define if your system supports the epoll system calls])\n      needsignal=yes\n      have_epoll=yes\n      AC_LIBOBJ(epoll_sub)\n      ], [AC_MSG_RESULT(no)], [AC_MSG_RESULT(no)]\n    )\n\tfi\nfi\nAM_CONDITIONAL(EPOLL_BACKEND, [test \"$haveepoll\" = \"yes\"])\n\nhaveeventports=no\nAC_CHECK_FUNCS(port_create, [haveeventports=yes], )\nif test \"$haveeventports\" = \"yes\" ; then\n\tAC_DEFINE(HAVE_EVENT_PORTS, 1,\n\t\t[Define if your system supports event ports])\n\tneedsignal=yes\nfi\nAM_CONDITIONAL(EVPORT_BACKEND, [test \"$haveeventports\" = \"yes\"])\n\nhavewepoll=no\nif test \"$bwin32\" = \"true\"; then\n\tneedsignal=yes\n  if test \"$cygwin\" = \"false\"; then\n    havewepoll=yes\n    AC_DEFINE(HAVE_WEPOLL, 1,\n      [Define if your system supports the wepoll module])\n  fi\nfi\nAM_CONDITIONAL(WEPOLL_BACKEND, [test \"$havewepoll\" = \"yes\"])\nAM_CONDITIONAL(SIGNAL_SUPPORT, [test \"$needsignal\" = \"yes\"])\nAM_CONDITIONAL(SIGNALFD_SUPPORT, [test \"$ac_cv_header_sys_signalfd_h\" = \"yes\"])\n\nAC_TYPE_PID_T\nAC_TYPE_SIZE_T\nAC_TYPE_SSIZE_T\n\nAC_CHECK_TYPES([uint64_t, uint32_t, uint16_t, uint8_t, uintptr_t], , ,\n[#ifdef HAVE_STDINT_H\n#include <stdint.h>\n#elif defined(HAVE_INTTYPES_H)\n#include <inttypes.h>\n#endif\n#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif])\n\nAC_CHECK_TYPES([fd_mask], , ,\n[#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n#ifdef HAVE_SYS_SELECT_H\n#include <sys/select.h>\n#endif])\n\nAC_CHECK_SIZEOF(long long)\nAC_CHECK_SIZEOF(long)\nAC_CHECK_SIZEOF(int)\nAC_CHECK_SIZEOF(short)\nAC_CHECK_SIZEOF(size_t)\nAC_CHECK_SIZEOF(void *)\nAC_CHECK_SIZEOF(off_t)\nAC_CHECK_SIZEOF(time_t)\n\nAC_CHECK_TYPES([struct in6_addr, struct sockaddr_in6, struct sockaddr_un, sa_family_t, struct addrinfo, struct sockaddr_storage], , ,\n[#define _GNU_SOURCE 1\n#include <sys/types.h>\n#ifdef HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n#ifdef HAVE_SYS_UN_H\n#include <sys/un.h>\n#endif\n#ifdef HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef HAVE_NETDB_H\n#include <netdb.h>\n#endif\n#ifdef _WIN32\n#define WIN32_WINNT 0x400\n#define _WIN32_WINNT 0x400\n#define WIN32_LEAN_AND_MEAN\n#if defined(_MSC_VER) && (_MSC_VER < 1300)\n#include <winsock.h>\n#else\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#endif\n#endif\n])\nAC_CHECK_MEMBERS([struct in6_addr.s6_addr32, struct in6_addr.s6_addr16, struct sockaddr_in.sin_len, struct sockaddr_in6.sin6_len, struct sockaddr_storage.ss_family, struct sockaddr_storage.__ss_family], , ,\n[#include <sys/types.h>\n#ifdef HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n#ifdef HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef _WIN32\n#define WIN32_WINNT 0x400\n#define _WIN32_WINNT 0x400\n#define WIN32_LEAN_AND_MEAN\n#if defined(_MSC_VER) && (_MSC_VER < 1300)\n#include <winsock.h>\n#else\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#endif\n#endif\n])\n\nAC_CHECK_TYPES([struct linger],,,\n[\n#ifdef HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n])\n\nAC_MSG_CHECKING([for socklen_t])\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([\n #include <sys/types.h>\n #ifdef _WIN32\n #include <ws2tcpip.h>\n #else\n #include <sys/socket.h>\n #endif\n    ],[socklen_t x;]\n  )],\n\t[AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])\n  AC_DEFINE(socklen_t, unsigned int,\n\t  [Define to unsigned int if you dont have it])]\n)\n\ndnl __func__/__FUNCTION__ is not a macros in general\nAC_MSG_CHECKING([whether our compiler supports __func__])\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([],\n    [ const char *cp = __func__; ]\n  )],\n\t[ AC_DEFINE(HAVE___func__, 1, [Define to 1 if compiler have __func__])\n    AC_MSG_RESULT([yes])\n  ],\n  [AC_MSG_RESULT([no])]\n)\nAC_MSG_CHECKING([whether our compiler supports __FUNCTION__])\nAC_COMPILE_IFELSE(\n  [AC_LANG_PROGRAM([],\n    [ const char *cp = __FUNCTION__; ]\n  )],\n\t[ AC_DEFINE(HAVE___FUNCTION__, 1, [Define to 1 if compiler have __FUNCTION__])\n    AC_MSG_RESULT([yes])\n  ],\n  [AC_MSG_RESULT([no])]\n)\n\ndnl check if we can compile with pthreads\nhave_pthreads=no\nif test \"$bwin32\" != \"true\" && test \"$enable_thread_support\" != \"no\"; then\n  AX_PTHREAD([\n    AC_DEFINE([HAVE_PTHREADS], [1], [Define if we have pthreads on this system])\n    have_pthreads=yes\n  ])\n  CFLAGS=\"$CFLAGS $PTHREAD_CFLAGS\"\n  AC_CHECK_SIZEOF([pthread_t], [], [AC_INCLUDES_DEFAULT() #include <pthread.h> ])\n  AC_CHECK_FUNCS([pthread_mutexattr_setprotocol])\nfi\nAM_CONDITIONAL(THREADS, [test \"$enable_thread_support\" != \"no\"])\nAM_CONDITIONAL(PTHREADS, [test \"$have_pthreads\" != \"no\" && test \"$enable_thread_support\" != \"no\"])\n\ndnl check if we should compile locking into the library\nif test \"$enable_thread_support\" = \"no\"; then\n   AC_DEFINE(DISABLE_THREAD_SUPPORT, 1,\n\t[Define if libevent should not be compiled with thread support])\nfi\n\ndnl check if we should hard-code the mm functions.\nif test \"$enable_malloc_replacement\" = \"no\"; then\n  AC_DEFINE(DISABLE_MM_REPLACEMENT, 1,\n        [Define if libevent should not allow replacing the mm functions])\nfi\n\ndnl check if we should hard-code debugging out\nif test \"$enable_debug_mode\" = \"no\"; then\n  AC_DEFINE(DISABLE_DEBUG_MODE, 1,\n        [Define if libevent should build without support for a debug mode])\nfi\n\ndnl check if we should enable verbose debugging\nif test \"$enable_verbose_debug\" = \"yes\"; then\n\tCFLAGS=\"$CFLAGS -DUSE_DEBUG\"\nfi\n\ndnl enable some warnings by default\nAX_CHECK_COMPILE_FLAG([-Wall], [CFLAGS=\"$CFLAGS -Wall\"],[],[-Werror])\n\ndnl Disable the strict-aliasing optimization, since it breaks\ndnl our sockaddr-handling code in strange ways.\ndnl See 52eb4951302554dd696d6a0120ad5d3f6cffb7bb.\nAX_CHECK_COMPILE_FLAG([-fno-strict-aliasing], [CFLAGS=\"$CFLAGS -fno-strict-aliasing\"],[],[-Werror])\n\ndnl Add warnings which we use in development but not for releases.\nif test \"$enable_gcc_warnings\" != \"no\" && test \"$GCC\" = \"yes\"; then\n\n  dnl -W is the same as -Wextra\n  AX_CHECK_COMPILE_FLAG([-W], [CFLAGS=\"$CFLAGS -W\"],[],[-Werror])\n\n  dnl The AX_CHECK_COMPILE_FLAG macro ignores warnings, so -Werror is used\n  dnl to convert warnings into errors and prevent the addition of unknown flags.\n  AX_CHECK_COMPILE_FLAG([-Waddress],[CFLAGS=\"$CFLAGS -Waddress\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wbad-function-cast],[CFLAGS=\"$CFLAGS -Wbad-function-cast\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wdeclaration-after-statement],[CFLAGS=\"$CFLAGS -Wdeclaration-after-statement\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wfloat-equal],[CFLAGS=\"$CFLAGS -Wfloat-equal\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Winit-self],[CFLAGS=\"$CFLAGS -Winit-self\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wlogical-op],[CFLAGS=\"$CFLAGS -Wlogical-op\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wmissing-declarations],[CFLAGS=\"$CFLAGS -Wmissing-declarations\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wmissing-field-initializers],[CFLAGS=\"$CFLAGS -Wmissing-field-initializers\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wmissing-prototypes],[CFLAGS=\"$CFLAGS -Wmissing-prototypes\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wnested-externs],[CFLAGS=\"$CFLAGS -Wnested-externs\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wnormalized=id],[CFLAGS=\"$CFLAGS -Wnormalized=id\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Woverride-init],[CFLAGS=\"$CFLAGS -Woverride-init\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wpointer-arith],[CFLAGS=\"$CFLAGS -Wpointer-arith\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wredundant-decls],[CFLAGS=\"$CFLAGS -Wredundant-decls\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wstrict-prototypes],[CFLAGS=\"$CFLAGS -Wstrict-prototypes\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wundef],[CFLAGS=\"$CFLAGS -Wundef\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wwrite-strings],[CFLAGS=\"$CFLAGS -Wwrite-strings\"],[],[-Werror])\n\n  dnl Convert warnings into errors\n  if test \"$enable_gcc_warnings\" = \"yes\"; then\n    AX_CHECK_COMPILE_FLAG([-Werror], [CFLAGS=\"$CFLAGS -Werror\"])\n  fi\n\n  dnl Disable warnings for unused parameters\n  AX_CHECK_COMPILE_FLAG([-Wunused-parameter], [CFLAGS=\"$CFLAGS -Wno-unused-parameter\"],[],[-Werror])\n  AX_CHECK_COMPILE_FLAG([-Wvoid-pointer-to-enum-cast], [CFLAGS=\"$CFLAGS -Wno-void-pointer-to-enum-cast\"],[],[-Werror])\n\n  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([], [\n  #if !defined(__clang__)\n  #error\n  #endif])], have_clang=yes, have_clang=no)\n\n   dnl Disable unused-function warnings. These trigger for minheap-internal.h.\n   AX_CHECK_COMPILE_FLAG([-Wno-unused-function], [CFLAGS=\"$CFLAGS -Wno-unused-function\"],[],[-Werror])\n\n   dnl Disable unknown pragmas warnings.\n   AX_CHECK_COMPILE_FLAG([-Wno-pragmas], [CFLAGS=\"$CFLAGS -Wno-pragmas\"],[],[-Werror])\n\n   dnl Disable Variable Length Array\n   AX_CHECK_COMPILE_FLAG([-Wvla], [CFLAGS=\"$CFLAGS -Wvla\"],[],[-Werror])\n\n  if test \"$have_clang\" = \"yes\"; then\n    case \"$host_os\" in\n      darwin*)\n        dnl Clang on macOS emits warnings for each directory specified which\n        dnl isn't \"used\", generating a lot of build noise.\n        AX_CHECK_COMPILE_FLAG([-Qunused-arguments], [CFLAGS=\"$CFLAGS -Qunused-arguments\"],[],[-Werror])\n    esac\n  fi\nfi\n\nLIBEVENT_GC_SECTIONS=\nif test \"$GCC\" = yes && test \"$enable_function_sections\" = yes ; then\n    AC_CACHE_CHECK(\n\t[if linker supports omitting unused code and data],\n\t[libevent_cv_gc_sections_runs],\n\t[\n\t    dnl  NetBSD will link but likely not run with --gc-sections\n\t    dnl  http://bugs.ntp.org/1844\n\t    dnl  http://gnats.netbsd.org/40401\n\t    dnl  --gc-sections causes attempt to load as linux elf, with\n\t    dnl  wrong syscalls in place.  Test a little gauntlet of\n\t    dnl  simple stdio read code checking for errors, expecting\n\t    dnl  enough syscall differences that the NetBSD code will\n\t    dnl  fail even with Linux emulation working as designed.\n\t    dnl  A shorter test could be refined by someone with access\n\t    dnl  to a NetBSD host with Linux emulation working.\n\t    origCFLAGS=\"$CFLAGS\"\n\t    CFLAGS=\"$CFLAGS -Wl,--gc-sections\"\n\t    AC_LINK_IFELSE(\n\t\t[AC_LANG_PROGRAM(\n\t\t    [[\n\t\t\t#include <stdlib.h>\n\t\t\t#include <stdio.h>\n\t\t    ]],\n\t\t    [[\n\t\t\tFILE *\tfpC;\n\t\t\tchar\tbuf[32];\n\t\t\tsize_t\tcch;\n\t\t\tint\tread_success_once;\n\n\t\t\tfpC = fopen(\"conftest.c\", \"r\");\n\t\t\tif (NULL == fpC)\n\t\t\t\texit(1);\n\t\t\tdo {\n\t\t\t\tcch = fread(buf, sizeof(buf), 1, fpC);\n\t\t\t\tread_success_once |= (0 != cch);\n\t\t\t} while (0 != cch);\n\t\t\tif (!read_success_once)\n\t\t\t\texit(2);\n\t\t\tif (!feof(fpC))\n\t\t\t\texit(3);\n\t\t\tif (0 != fclose(fpC))\n\t\t\t\texit(4);\n\n\t\t\texit(EXIT_SUCCESS);\n\t\t    ]]\n\t\t)],\n\t\t[\n                    dnl We have to do this invocation manually so that we can\n                    dnl get the output of conftest.err to make sure it doesn't\n                    dnl mention gc-sections.\n\t\t    if test \"$cross_compiling\" = \"yes\" || grep gc-sections conftest.err ; then\n\t\t\tlibevent_cv_gc_sections_runs=no\n\t\t    else\n\t\t\tlibevent_cv_gc_sections_runs=no\n\t\t\t./conftest >/dev/null 2>&1 && libevent_cv_gc_sections_runs=yes\n\t\t    fi\n\t\t],\n\t\t[libevent_cv_gc_sections_runs=no]\n\t    )\n\t    CFLAGS=\"$origCFLAGS\"\n\t    AS_UNSET([origCFLAGS])\n\t]\n    )\n    case \"$libevent_cv_gc_sections_runs\" in\n     yes)\n\tCFLAGS=\"-ffunction-sections -fdata-sections $CFLAGS\"\n\tLIBEVENT_GC_SECTIONS=\"-Wl,--gc-sections\"\n\t;;\n    esac\nfi\nAC_SUBST([LIBEVENT_GC_SECTIONS])\n\nAM_CONDITIONAL([INSTALL_LIBEVENT], [test \"$enable_libevent_install\" = \"yes\"])\n\ndnl Allow additional flags from a containing package such as NTP\nAC_SUBST([LIBEVENT_CFLAGS])\nAC_SUBST([LIBEVENT_CPPFLAGS])\nAC_SUBST([LIBEVENT_LDFLAGS])\n\nAC_C_BIGENDIAN([CFLAGS=\"$CFLAGS -DBIG_ENDIAN\"], [CFLAGS=\"$CFLAGS -DLITTLE_ENDIAN\"])\n\ndnl Doxygen support\nDX_HTML_FEATURE(ON)\nDX_MAN_FEATURE(OFF)\nDX_RTF_FEATURE(OFF)\nDX_XML_FEATURE(OFF)\nDX_PDF_FEATURE(OFF)\nDX_PS_FEATURE(OFF)\nDX_CHM_FEATURE(OFF)\nDX_CHI_FEATURE(OFF)\nDX_INIT_DOXYGEN([libevent], [${top_srcdir}/Doxyfile], [doxygen])\n\nAM_CONDITIONAL([ENABLE_DOXYGEN], [test \"$DX_FLAG_doc\" = \"1\"])\nAM_CONDITIONAL([ENABLE_DOXYGEN_MAN], [test \"$DX_FLAG_man\" = \"1\"])\n\ndnl autotools uses the same pkg-config templates as cmake, and in cmake we have\ndnl CMAKE_DEBUG_POSTFIX, so define it to empty value to simply replace it in\ndnl *.pc.in\nCMAKE_DEBUG_POSTFIX=\"\"\nAC_SUBST([CMAKE_DEBUG_POSTFIX])\n\nAC_CONFIG_FILES([Makefile libevent.pc libevent_mbedtls.pc libevent_openssl.pc libevent_pthreads.pc libevent_core.pc libevent_extra.pc] )\nAC_OUTPUT\n"
        },
        {
          "name": "defer-internal.h",
          "type": "blob",
          "size": 2.7626953125,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef DEFER_INTERNAL_H_INCLUDED_\n#define DEFER_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/queue.h>\n\nstruct event_callback;\ntypedef void (*deferred_cb_fn)(struct event_callback *, void *);\n\n/**\n   Initialize an empty, non-pending event_callback.\n\n   @param deferred The struct event_callback structure to initialize.\n   @param priority The priority that the callback should run at.\n   @param cb The function to run when the struct event_callback executes.\n   @param arg The function's second argument.\n */\nEVENT2_EXPORT_SYMBOL\nvoid event_deferred_cb_init_(struct event_callback *, ev_uint8_t, deferred_cb_fn, void *);\n/**\n   Change the priority of a non-pending event_callback.\n */\nvoid event_deferred_cb_set_priority_(struct event_callback *, ev_uint8_t);\n/**\n   Cancel a struct event_callback if it is currently scheduled in an event_base.\n */\nEVENT2_EXPORT_SYMBOL\nvoid event_deferred_cb_cancel_(struct event_base *, struct event_callback *);\n/**\n   Activate a struct event_callback if it is not currently scheduled in an event_base.\n\n   Return true if it was not previously scheduled.\n */\nEVENT2_EXPORT_SYMBOL\nint event_deferred_cb_schedule_(struct event_base *, struct event_callback *);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* EVENT_INTERNAL_H_INCLUDED_ */\n\n"
        },
        {
          "name": "devpoll.c",
          "type": "blob",
          "size": 7.7041015625,
          "content": "/*\n * Copyright 2000-2009 Niels Provos <provos@citi.umich.edu>\n * Copyright 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_DEVPOLL\n\n#include <sys/types.h>\n#include <sys/resource.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <sys/devpoll.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <errno.h>\n\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/thread.h\"\n#include \"event-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"evthread-internal.h\"\n\nstruct devpollop {\n\tstruct pollfd *events;\n\tint nevents;\n\tint dpfd;\n\tstruct pollfd *changes;\n\tint nchanges;\n};\n\nstatic void *devpoll_init(struct event_base *);\nstatic int devpoll_add(struct event_base *, int fd, short old, short events, void *);\nstatic int devpoll_del(struct event_base *, int fd, short old, short events, void *);\nstatic int devpoll_dispatch(struct event_base *, struct timeval *);\nstatic void devpoll_dealloc(struct event_base *);\n\nconst struct eventop devpollops = {\n\t\"devpoll\",\n\tdevpoll_init,\n\tdevpoll_add,\n\tdevpoll_del,\n\tdevpoll_dispatch,\n\tdevpoll_dealloc,\n\t1, /* need reinit */\n\tEV_FEATURE_FDS|EV_FEATURE_O1,\n\t0\n};\n\n#define NEVENT\t32000\n\nstatic int\ndevpoll_commit(struct devpollop *devpollop)\n{\n\t/*\n\t * Due to a bug in Solaris, we have to use pwrite with an offset of 0.\n\t * Write is limited to 2GB of data, until it will fail.\n\t */\n\tif (pwrite(devpollop->dpfd, devpollop->changes,\n\t\tsizeof(struct pollfd) * devpollop->nchanges, 0) == -1)\n\t\treturn (-1);\n\n\tdevpollop->nchanges = 0;\n\treturn (0);\n}\n\nstatic int\ndevpoll_queue(struct devpollop *devpollop, int fd, int events) {\n\tstruct pollfd *pfd;\n\n\tif (devpollop->nchanges >= devpollop->nevents) {\n\t\t/*\n\t\t * Change buffer is full, must commit it to /dev/poll before\n\t\t * adding more\n\t\t */\n\t\tif (devpoll_commit(devpollop) != 0)\n\t\t\treturn (-1);\n\t}\n\n\tpfd = &devpollop->changes[devpollop->nchanges++];\n\tpfd->fd = fd;\n\tpfd->events = events;\n\tpfd->revents = 0;\n\n\treturn (0);\n}\n\nstatic void *\ndevpoll_init(struct event_base *base)\n{\n\tint dpfd, nfiles = NEVENT;\n\tstruct rlimit rl;\n\tstruct devpollop *devpollop;\n\n\tif (!(devpollop = mm_calloc(1, sizeof(struct devpollop))))\n\t\treturn (NULL);\n\n\tif (getrlimit(RLIMIT_NOFILE, &rl) == 0 &&\n\t    rl.rlim_cur != RLIM_INFINITY)\n\t\tnfiles = rl.rlim_cur;\n\n\t/* Initialize the kernel queue */\n\tif ((dpfd = evutil_open_closeonexec_(\"/dev/poll\", O_RDWR, 0)) == -1) {\n\t\tevent_warn(\"open: /dev/poll\");\n\t\tmm_free(devpollop);\n\t\treturn (NULL);\n\t}\n\n\tdevpollop->dpfd = dpfd;\n\n\t/* Initialize fields */\n\t/* FIXME: allocating 'nfiles' worth of space here can be\n\t * expensive and unnecessary.  See how epoll.c does it instead. */\n\tdevpollop->events = mm_calloc(nfiles, sizeof(struct pollfd));\n\tif (devpollop->events == NULL) {\n\t\tmm_free(devpollop);\n\t\tclose(dpfd);\n\t\treturn (NULL);\n\t}\n\tdevpollop->nevents = nfiles;\n\n\tdevpollop->changes = mm_calloc(nfiles, sizeof(struct pollfd));\n\tif (devpollop->changes == NULL) {\n\t\tmm_free(devpollop->events);\n\t\tmm_free(devpollop);\n\t\tclose(dpfd);\n\t\treturn (NULL);\n\t}\n\n\tevsig_init_(base);\n\n\treturn (devpollop);\n}\n\nstatic int\ndevpoll_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tstruct devpollop *devpollop = base->evbase;\n\tstruct pollfd *events = devpollop->events;\n\tstruct dvpoll dvp;\n\tint i, res, timeout = -1;\n\n\tif (devpollop->nchanges)\n\t\tdevpoll_commit(devpollop);\n\n\tif (tv != NULL)\n\t\ttimeout = tv->tv_sec * 1000 + (tv->tv_usec + 999) / 1000;\n\n\tdvp.dp_fds = devpollop->events;\n\tdvp.dp_nfds = devpollop->nevents;\n\tdvp.dp_timeout = timeout;\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\tres = ioctl(devpollop->dpfd, DP_POLL, &dvp);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (res == -1) {\n\t\tif (errno != EINTR) {\n\t\t\tevent_warn(\"ioctl: DP_POLL\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tevent_debug((\"%s: devpoll_wait reports %d\", __func__, res));\n\n\tfor (i = 0; i < res; i++) {\n\t\tint which = 0;\n\t\tint what = events[i].revents;\n\n\t\tif (what & POLLHUP)\n\t\t\twhat |= POLLIN | POLLOUT;\n\t\telse if (what & POLLERR)\n\t\t\twhat |= POLLIN | POLLOUT;\n\n\t\tif (what & POLLIN)\n\t\t\twhich |= EV_READ;\n\t\tif (what & POLLOUT)\n\t\t\twhich |= EV_WRITE;\n\n\t\tif (!which)\n\t\t\tcontinue;\n\n\t\t/* XXX(niels): not sure if this works for devpoll */\n\t\tevmap_io_active_(base, events[i].fd, which);\n\t}\n\n\treturn (0);\n}\n\n\nstatic int\ndevpoll_add(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct devpollop *devpollop = base->evbase;\n\tint res;\n\t(void)p;\n\n\t/*\n\t * It's not necessary to OR the existing read/write events that we\n\t * are currently interested in with the new event we are adding.\n\t * The /dev/poll driver ORs any new events with the existing events\n\t * that it has cached for the fd.\n\t */\n\n\tres = 0;\n\tif (events & EV_READ)\n\t\tres |= POLLIN;\n\tif (events & EV_WRITE)\n\t\tres |= POLLOUT;\n\n\tif (devpoll_queue(devpollop, fd, res) != 0)\n\t\treturn (-1);\n\n\treturn (0);\n}\n\nstatic int\ndevpoll_del(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct devpollop *devpollop = base->evbase;\n\tint res;\n\t(void)p;\n\n\tres = 0;\n\tif (events & EV_READ)\n\t\tres |= POLLIN;\n\tif (events & EV_WRITE)\n\t\tres |= POLLOUT;\n\n\t/*\n\t * The only way to remove an fd from the /dev/poll monitored set is\n\t * to use POLLREMOVE by itself.  This removes ALL events for the fd\n\t * provided so if we care about two events and are only removing one\n\t * we must re-add the other event after POLLREMOVE.\n\t */\n\n\tif (devpoll_queue(devpollop, fd, POLLREMOVE) != 0)\n\t\treturn (-1);\n\n\tif ((res & (POLLIN|POLLOUT)) != (POLLIN|POLLOUT)) {\n\t\t/*\n\t\t * We're not deleting all events, so we must resubmit the\n\t\t * event that we are still interested in if one exists.\n\t\t */\n\n\t\tif ((res & POLLIN) && (old & EV_WRITE)) {\n\t\t\t/* Deleting read, still care about write */\n\t\t\tdevpoll_queue(devpollop, fd, POLLOUT);\n\t\t} else if ((res & POLLOUT) && (old & EV_READ)) {\n\t\t\t/* Deleting write, still care about read */\n\t\t\tdevpoll_queue(devpollop, fd, POLLIN);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\nstatic void\ndevpoll_dealloc(struct event_base *base)\n{\n\tstruct devpollop *devpollop = base->evbase;\n\n\tevsig_dealloc_(base);\n\tif (devpollop->events)\n\t\tmm_free(devpollop->events);\n\tif (devpollop->changes)\n\t\tmm_free(devpollop->changes);\n\tif (devpollop->dpfd >= 0)\n\t\tclose(devpollop->dpfd);\n\n\tmemset(devpollop, 0, sizeof(struct devpollop));\n\tmm_free(devpollop);\n}\n\n#endif /* EVENT__HAVE_DEVPOLL */\n"
        },
        {
          "name": "doxygen.am",
          "type": "blob",
          "size": 2.5859375,
          "content": "# Doxygen documentation will not be generated with default configuration,\n# unless '--enable-doxygen-doc' is configured.\n# The following targets are all about doxygen:\n# make                # 'make doxygen' would be auto executed\n# make doxygen        # generating doxygen documentation\n# make doxygen-doc    # same as 'make doxygen'\n# make clean          # clean docs generated by doxygen\n# make install        # install doxygen documentation\n# make uninstall      # uninstall doxygen documentation\n\nif ENABLE_DOXYGEN\n\n# Add all needed rules defined in ax_prog_doxygen.m4\n@DX_RULES@\n\n# Use 'make clean' to clean docs generated by doxygen.\nclean-local:\n\t-rm -rf $(DX_CLEANFILES)\n\nif ENABLE_DOXYGEN_MAN\nman3_MAN_DIR = @DX_DOCDIR@/man/man3\n\n# add \"libevent_\" prefix for man pages\n#\n# XXX: we cannot clean old man pages here since\n# doxygen-rename-man-pages will be called twice:\n# - for make\n# - for make install\n# (cmake works differently)\n#\n# Once this will be solved add the following to the target:\n#\n#     -rm -fr $(man3_MAN_DIR)/libevent_*\ndoxygen-rename-man-pages: doxygen-doc\n\techo \"Rename man pages in $(man3_MAN_DIR)\"\n\t@for p in $(man3_MAN_DIR)/*; do \\\n\t  p=`basename $$p`; \\\n\t  p_strip=$${p/libevent_/}; \\\n\t  if [ ! \"$$p_strip\" = \"$$p\" ]; then continue; fi; \\\n\t  mv '$(man3_MAN_DIR)/'$$p '$(man3_MAN_DIR)/'libevent_$$p; \\\n\tdone\n\n# integrate doxygen with automake targets\nman3_MANS = $(man3_MAN_DIR)/*\n$(man3_MANS): doxygen-doc doxygen-rename-man-pages\nendif ENABLE_DOXYGEN_MAN\n\n# Docs will be installed. It may be one or more docs supported\n# by doxygen, but does not include 'man'.\ndocdirs = $(DX_INSTALL_DOCS)\n\n# Rules for installing docs generated by doxygen into $(htmldir),\n# The typical value of $(htmldir) is '/usr/local/share/doc/$(PACKAGE)'\ninstall-data-local:\n\t@if ! test -d \"$(DESTDIR)$(htmldir)\"; then \\\n\t  echo \"$(mkinstalldirs) '$(DESTDIR)$(htmldir)'\"; \\\n\t  $(mkinstalldirs) '$(DESTDIR)$(htmldir)'; \\\n\tfi\n\t@for d in $(docdirs); do \\\n\t  echo \"cp -pR $$d '$(DESTDIR)$(htmldir)/'\"; \\\n\t  cp -pR $$d '$(DESTDIR)$(htmldir)/'; \\\n\tdone\n\n# Rules for uninstalling docs generated by doxygen from $(htmldir)\nuninstall-local:\n\t@for d in $(docdirs); do \\\n\t  d=`basename $$d`; \\\n\t  echo \"test ! -d '$(DESTDIR)$(htmldir)/'$$d || \\\n\t  { find '$(DESTDIR)$(htmldir)/'$$d -type d ! -perm -200 -exec chmod u+w '{}' ';' && \\\n\t  rm -rf '$(DESTDIR)$(htmldir)/'$$d; }\"; \\\n\t  test ! -d '$(DESTDIR)$(htmldir)/'$$d || \\\n\t  { find '$(DESTDIR)$(htmldir)/'$$d -type d ! -perm -200 -exec chmod u+w '{}' ';' && \\\n\t  rm -rf '$(DESTDIR)$(htmldir)/'$$d; }; \\\n\tdone\n\trmdir \"$(DESTDIR)$(htmldir)/\" || true\n\ndoxygen: doxygen-doc\nall: doxygen\n\nendif ENABLE_DOXYGEN\n"
        },
        {
          "name": "epoll.c",
          "type": "blob",
          "size": 16.259765625,
          "content": "/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#if defined EVENT__HAVE_EPOLL || defined EVENT__HAVE_WEPOLL\n\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <limits.h>\n#include <string.h>\n\n#ifdef EVENT__HAVE_WEPOLL\n#include \"wepoll.h\"\n#define EPOLLET 0\n#else\n#include <sys/types.h>\n#include <sys/resource.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <sys/epoll.h>\n#include <signal.h>\n#include <unistd.h>\n#include <errno.h>\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n#ifdef EVENT__HAVE_SYS_TIMERFD_H\n#include <sys/timerfd.h>\n#endif\n#endif\n\n#include \"event-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"event2/thread.h\"\n#include \"evthread-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"changelist-internal.h\"\n#include \"time-internal.h\"\n\n/* Since Linux 2.6.17, epoll is able to report about peer half-closed connection\n   using special EPOLLRDHUP flag on a read event.\n*/\n#if !defined(EPOLLRDHUP)\n#define EPOLLRDHUP 0\n#define EARLY_CLOSE_IF_HAVE_RDHUP 0\n#else\n#define EARLY_CLOSE_IF_HAVE_RDHUP EV_FEATURE_EARLY_CLOSE\n#endif\n\n#include \"epolltable-internal.h\"\n\n#if defined(EVENT__HAVE_SYS_TIMERFD_H) &&\t\t\t  \\\n\tdefined(EVENT__HAVE_TIMERFD_CREATE) &&\t\t\t  \\\n\tdefined(HAVE_POSIX_MONOTONIC) && defined(TFD_NONBLOCK) && \\\n\tdefined(TFD_CLOEXEC) && !defined(EVENT__HAVE_EPOLL_PWAIT2)\n/* Note that we only use timerfd if TFD_NONBLOCK and TFD_CLOEXEC are available\n   and working.  This means that we can't support it on 2.6.25 (where timerfd\n   was introduced) or 2.6.26, since 2.6.27 introduced those flags. On recent\n   enough systems (with 5.11 and never) and so epoll_pwait2() with nanosecond\n   precision for timeouts, timerfd is not needed at all.\n*/\n#define USING_TIMERFD\n#endif\n\n#ifdef EVENT__HAVE_WEPOLL\ntypedef HANDLE epoll_handle;\n#define INVALID_EPOLL_HANDLE NULL\nstatic void close_epoll_handle(HANDLE h) { epoll_close(h); }\n#else\ntypedef int epoll_handle;\n#define INVALID_EPOLL_HANDLE -1\nstatic void close_epoll_handle(int h) { close(h); }\n#endif\n\nstruct epollop {\n\tstruct epoll_event *events;\n\tint nevents;\n\tepoll_handle epfd;\n#ifdef USING_TIMERFD\n\tint timerfd;\n#endif\n};\n\nstatic void *epoll_init(struct event_base *);\nstatic int epoll_dispatch(struct event_base *, struct timeval *);\nstatic void epoll_dealloc(struct event_base *);\n\nstatic const struct eventop epollops_changelist = {\n\t\"epoll (with changelist)\",\n\tepoll_init,\n\tevent_changelist_add_,\n\tevent_changelist_del_,\n\tepoll_dispatch,\n\tepoll_dealloc,\n\t1, /* need reinit */\n\tEV_FEATURE_ET|EV_FEATURE_O1| EARLY_CLOSE_IF_HAVE_RDHUP,\n\tEVENT_CHANGELIST_FDINFO_SIZE\n};\n\n\nstatic int epoll_nochangelist_add(struct event_base *base, evutil_socket_t fd,\n    short old, short events, void *p);\nstatic int epoll_nochangelist_del(struct event_base *base, evutil_socket_t fd,\n    short old, short events, void *p);\n\n#ifdef EVENT__HAVE_WEPOLL\nconst struct eventop wepollops = {\n\t\"wepoll\",\n\tepoll_init,\n\tepoll_nochangelist_add,\n\tepoll_nochangelist_del,\n\tepoll_dispatch,\n\tepoll_dealloc,\n\t1, /* need reinit */\n\tEV_FEATURE_O1|EV_FEATURE_EARLY_CLOSE,\n\t0\n};\n#else\nconst struct eventop epollops = {\n\t\"epoll\",\n\tepoll_init,\n\tepoll_nochangelist_add,\n\tepoll_nochangelist_del,\n\tepoll_dispatch,\n\tepoll_dealloc,\n\t1, /* need reinit */\n\tEV_FEATURE_ET|EV_FEATURE_O1|EV_FEATURE_EARLY_CLOSE,\n\t0\n};\n#endif\n\n\n#define INITIAL_NEVENT 32\n#define MAX_NEVENT 4096\n\n/* On Linux kernels at least up to 2.6.24.4, epoll can't handle timeout\n * values bigger than (LONG_MAX - 999ULL)/HZ.  HZ in the wild can be\n * as big as 1000, and LONG_MAX can be as small as (1<<31)-1, so the\n * largest number of msec we can support here is 2147482.  Let's\n * round that down by 47 seconds.\n */\n#define MAX_EPOLL_TIMEOUT_MSEC (35*60*1000)\n\nstatic void *\nepoll_init(struct event_base *base)\n{\n\tepoll_handle epfd = INVALID_EPOLL_HANDLE;\n\tstruct epollop *epollop;\n\n#ifdef EVENT__HAVE_EPOLL_CREATE1\n\t/* First, try the shiny new epoll_create1 interface, if we have it. */\n\tepfd = epoll_create1(EPOLL_CLOEXEC);\n#endif\n\tif (epfd == INVALID_EPOLL_HANDLE) {\n\t\t/* Initialize the kernel queue using the old interface.  (The\n\t\tsize field is ignored   since 2.6.8.) */\n\t\tif ((epfd = epoll_create(32000)) == INVALID_EPOLL_HANDLE) {\n\t\t\tif (errno != ENOSYS)\n\t\t\t\tevent_warn(\"epoll_create\");\n\t\t\treturn (NULL);\n\t\t}\n#ifndef EVENT__HAVE_WEPOLL\n\t\tevutil_make_socket_closeonexec(epfd);\n#endif\n\t}\n\n\tif (!(epollop = mm_calloc(1, sizeof(struct epollop)))) {\n\t\tclose_epoll_handle(epfd);\n\t\treturn (NULL);\n\t}\n\n\tepollop->epfd = epfd;\n\n\t/* Initialize fields */\n\tepollop->events = mm_calloc(INITIAL_NEVENT, sizeof(struct epoll_event));\n\tif (epollop->events == NULL) {\n\t\tmm_free(epollop);\n\t\tclose_epoll_handle(epfd);\n\t\treturn (NULL);\n\t}\n\tepollop->nevents = INITIAL_NEVENT;\n\n#ifndef EVENT__HAVE_WEPOLL\n\tif ((base->flags & EVENT_BASE_FLAG_EPOLL_USE_CHANGELIST) != 0 ||\n\t    ((base->flags & EVENT_BASE_FLAG_IGNORE_ENV) == 0 &&\n\t\tevutil_getenv_(\"EVENT_EPOLL_USE_CHANGELIST\") != NULL)) {\n\n\t\tbase->evsel = &epollops_changelist;\n\t}\n#endif\n\n#ifdef USING_TIMERFD\n\t/*\n\t  The epoll interface ordinarily gives us one-millisecond precision,\n\t  so on Linux it makes perfect sense to use the CLOCK_MONOTONIC_COARSE\n\t  timer.  But when the user has set the new PRECISE_TIMER flag for an\n\t  event_base, we can try to use timerfd to give them finer granularity.\n\t*/\n\tif ((base->flags & EVENT_BASE_FLAG_PRECISE_TIMER) &&\n\t    !(base->flags & EVENT_BASE_FLAG_EPOLL_DISALLOW_TIMERFD) &&\n\t    base->monotonic_timer.monotonic_clock == CLOCK_MONOTONIC) {\n\t\tint fd;\n\t\tfd = epollop->timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK|TFD_CLOEXEC);\n\t\tif (epollop->timerfd >= 0) {\n\t\t\tstruct epoll_event epev;\n\t\t\tmemset(&epev, 0, sizeof(epev));\n\t\t\tepev.data.fd = epollop->timerfd;\n\t\t\tepev.events = EPOLLIN;\n\t\t\tif (epoll_ctl(epollop->epfd, EPOLL_CTL_ADD, fd, &epev) < 0) {\n\t\t\t\tevent_warn(\"epoll_ctl(timerfd)\");\n\t\t\t\tclose(fd);\n\t\t\t\tepollop->timerfd = -1;\n\t\t\t}\n\t\t} else {\n\t\t\tif (errno != EINVAL && errno != ENOSYS) {\n\t\t\t\t/* These errors probably mean that we were\n\t\t\t\t * compiled with timerfd/TFD_* support, but\n\t\t\t\t * we're running on a kernel that lacks those.\n\t\t\t\t */\n\t\t\t\tevent_warn(\"timerfd_create\");\n\t\t\t}\n\t\t\tepollop->timerfd = -1;\n\t\t}\n\t} else {\n\t\tepollop->timerfd = -1;\n\t}\n#endif\n\n\tif (sigfd_init_(base) < 0)\n\t\tevsig_init_(base);\n\n\treturn (epollop);\n}\n\nstatic const char *\nchange_to_string(int change)\n{\n\tchange &= (EV_CHANGE_ADD|EV_CHANGE_DEL);\n\tif (change == EV_CHANGE_ADD) {\n\t\treturn \"add\";\n\t} else if (change == EV_CHANGE_DEL) {\n\t\treturn \"del\";\n\t} else if (change == 0) {\n\t\treturn \"none\";\n\t} else {\n\t\treturn \"???\";\n\t}\n}\n\nstatic const char *\nepoll_op_to_string(int op)\n{\n\treturn op == EPOLL_CTL_ADD?\"ADD\":\n\t    op == EPOLL_CTL_DEL?\"DEL\":\n\t    op == EPOLL_CTL_MOD?\"MOD\":\n\t    \"???\";\n}\n\n#define PRINT_CHANGES(op, events, ch, status)  \\\n\t\"Epoll %s(%d) on fd %d \" status \". \"       \\\n\t\"Old events were %d; \"                     \\\n\t\"read change was %d (%s); \"                \\\n\t\"write change was %d (%s); \"               \\\n\t\"close change was %d (%s)\",                \\\n\tepoll_op_to_string(op),                    \\\n\tevents,                                    \\\n\tch->fd,                                    \\\n\tch->old_events,                            \\\n\tch->read_change,                           \\\n\tchange_to_string(ch->read_change),         \\\n\tch->write_change,                          \\\n\tchange_to_string(ch->write_change),        \\\n\tch->close_change,                          \\\n\tchange_to_string(ch->close_change)\n\nstatic int\nepoll_apply_one_change(struct event_base *base,\n    struct epollop *epollop,\n    const struct event_change *ch)\n{\n\tstruct epoll_event epev;\n\tint op, events = 0;\n\tint idx;\n\n\tidx = EPOLL_OP_TABLE_INDEX(ch);\n\top = epoll_op_table[idx].op;\n\tevents = epoll_op_table[idx].events;\n\n\tif (!events) {\n\t\tEVUTIL_ASSERT(op == 0);\n\t\treturn 0;\n\t}\n\n\tif ((ch->read_change|ch->write_change|ch->close_change) & EV_CHANGE_ET)\n\t\tevents |= EPOLLET;\n\n\tmemset(&epev, 0, sizeof(epev));\n#ifdef EVENT__HAVE_WEPOLL\n\tepev.data.sock = ch->fd;\n#else\n\tepev.data.fd = ch->fd;\n#endif\n\tepev.events = events;\n\tif (epoll_ctl(epollop->epfd, op, ch->fd, &epev) == 0) {\n\t\tevent_debug((PRINT_CHANGES(op, epev.events, ch, \"okay\")));\n\t\treturn 0;\n\t}\n\n\tswitch (op) {\n\tcase EPOLL_CTL_MOD:\n\t\tif (errno == ENOENT) {\n\t\t\t/* If a MOD operation fails with ENOENT, the\n\t\t\t * fd was probably closed and re-opened.  We\n\t\t\t * should retry the operation as an ADD.\n\t\t\t */\n\t\t\tif (epoll_ctl(epollop->epfd, EPOLL_CTL_ADD, ch->fd, &epev) == -1) {\n\t\t\t\tevent_warn(\"Epoll MOD(%d) on %d retried as ADD; that failed too\",\n\t\t\t\t    (int)epev.events, ch->fd);\n\t\t\t\treturn -1;\n\t\t\t} else {\n\t\t\t\tevent_debug((\"Epoll MOD(%d) on %d retried as ADD; succeeded.\",\n\t\t\t\t\t(int)epev.events,\n\t\t\t\t\tch->fd));\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase EPOLL_CTL_ADD:\n\t\tif (errno == EEXIST) {\n\t\t\t/* If an ADD operation fails with EEXIST,\n\t\t\t * either the operation was redundant (as with a\n\t\t\t * precautionary add), or we ran into a fun\n\t\t\t * kernel bug where using dup*() to duplicate the\n\t\t\t * same file into the same fd gives you the same epitem\n\t\t\t * rather than a fresh one.  For the second case,\n\t\t\t * we must retry with MOD. */\n\t\t\tif (epoll_ctl(epollop->epfd, EPOLL_CTL_MOD, ch->fd, &epev) == -1) {\n\t\t\t\tevent_warn(\"Epoll ADD(%d) on %d retried as MOD; that failed too\",\n\t\t\t\t    (int)epev.events, ch->fd);\n\t\t\t\treturn -1;\n\t\t\t} else {\n\t\t\t\tevent_debug((\"Epoll ADD(%d) on %d retried as MOD; succeeded.\",\n\t\t\t\t\t(int)epev.events,\n\t\t\t\t\tch->fd));\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase EPOLL_CTL_DEL:\n\t\tif (errno == ENOENT || errno == EBADF || errno == EPERM) {\n\t\t\t/* If a delete fails with one of these errors,\n\t\t\t * that's fine too: we closed the fd before we\n\t\t\t * got around to calling epoll_dispatch. */\n\t\t\tevent_debug((\"Epoll DEL(%d) on fd %d gave %s: DEL was unnecessary.\",\n\t\t\t\t(int)epev.events,\n\t\t\t\tch->fd,\n\t\t\t\tstrerror(errno)));\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tevent_warn(PRINT_CHANGES(op, epev.events, ch, \"failed\"));\n\treturn -1;\n}\n\nstatic int\nepoll_apply_changes(struct event_base *base)\n{\n\tstruct event_changelist *changelist = &base->changelist;\n\tstruct epollop *epollop = base->evbase;\n\tstruct event_change *ch;\n\n\tint r = 0;\n\tint i;\n\n\tfor (i = 0; i < changelist->n_changes; ++i) {\n\t\tch = &changelist->changes[i];\n\t\tif (epoll_apply_one_change(base, epollop, ch) < 0)\n\t\t\tr = -1;\n\t}\n\n\treturn (r);\n}\n\nstatic int\nepoll_nochangelist_add(struct event_base *base, evutil_socket_t fd,\n    short old, short events, void *p)\n{\n\tstruct event_change ch;\n\tch.fd = fd;\n\tch.old_events = old;\n\tch.read_change = ch.write_change = ch.close_change = 0;\n\tif (events & EV_WRITE)\n\t\tch.write_change = EV_CHANGE_ADD |\n\t\t    (events & EV_ET);\n\tif (events & EV_READ)\n\t\tch.read_change = EV_CHANGE_ADD |\n\t\t    (events & EV_ET);\n\tif (events & EV_CLOSED)\n\t\tch.close_change = EV_CHANGE_ADD |\n\t\t    (events & EV_ET);\n\n\treturn epoll_apply_one_change(base, base->evbase, &ch);\n}\n\nstatic int\nepoll_nochangelist_del(struct event_base *base, evutil_socket_t fd,\n    short old, short events, void *p)\n{\n\tstruct event_change ch;\n\tch.fd = fd;\n\tch.old_events = old;\n\tch.read_change = ch.write_change = ch.close_change = 0;\n\tif (events & EV_WRITE)\n\t\tch.write_change = EV_CHANGE_DEL |\n\t\t    (events & EV_ET);\n\tif (events & EV_READ)\n\t\tch.read_change = EV_CHANGE_DEL |\n\t\t    (events & EV_ET);\n\tif (events & EV_CLOSED)\n\t\tch.close_change = EV_CHANGE_DEL |\n\t\t    (events & EV_ET);\n\n\treturn epoll_apply_one_change(base, base->evbase, &ch);\n}\n\nstatic int\nepoll_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tstruct epollop *epollop = base->evbase;\n\tstruct epoll_event *events = epollop->events;\n\tint i, res;\n#if defined(EVENT__HAVE_EPOLL_PWAIT2)\n\tstruct timespec ts = { 0, 0 };\n#else /* no epoll_pwait2() */\n\tlong timeout = -1;\n#endif /* EVENT__HAVE_EPOLL_PWAIT2 */\n\n#ifdef USING_TIMERFD\n\tif (epollop->timerfd >= 0) {\n\t\tstruct itimerspec is;\n\t\tis.it_interval.tv_sec = 0;\n\t\tis.it_interval.tv_nsec = 0;\n\t\tif (tv == NULL) {\n\t\t\t/* No timeout; disarm the timer. */\n\t\t\tis.it_value.tv_sec = 0;\n\t\t\tis.it_value.tv_nsec = 0;\n\t\t} else {\n\t\t\tif (tv->tv_sec == 0 && tv->tv_usec == 0) {\n\t\t\t\t/* we need to exit immediately; timerfd can't\n\t\t\t\t * do that. */\n\t\t\t\ttimeout = 0;\n\t\t\t}\n\t\t\tis.it_value.tv_sec = tv->tv_sec;\n\t\t\tis.it_value.tv_nsec = tv->tv_usec * 1000;\n\t\t}\n\t\t/* TODO: we could avoid unnecessary syscalls here by only\n\t\t   calling timerfd_settime when the top timeout changes, or\n\t\t   when we're called with a different timeval.\n\t\t*/\n\t\tif (timerfd_settime(epollop->timerfd, 0, &is, NULL) < 0) {\n\t\t\tevent_warn(\"timerfd_settime\");\n\t\t}\n\t} else\n#endif\n\tif (tv != NULL) {\n#if defined(EVENT__HAVE_EPOLL_PWAIT2)\n\t\tTIMEVAL_TO_TIMESPEC(tv, &ts);\n#else /* no epoll_pwait2() */\n\t\ttimeout = evutil_tv_to_msec_(tv);\n\t\tif (timeout < 0 || timeout > MAX_EPOLL_TIMEOUT_MSEC) {\n\t\t\t/* Linux kernels can wait forever if the timeout is\n\t\t\t * too big; see comment on MAX_EPOLL_TIMEOUT_MSEC. */\n\t\t\ttimeout = MAX_EPOLL_TIMEOUT_MSEC;\n\t\t}\n#endif /* EVENT__HAVE_EPOLL_PWAIT2 */\n\t}\n\n\tepoll_apply_changes(base);\n\tevent_changelist_remove_all_(&base->changelist, base);\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n#if defined(EVENT__HAVE_EPOLL_PWAIT2)\n\tres = epoll_pwait2(epollop->epfd, events, epollop->nevents, tv ? &ts : NULL, NULL);\n#else /* no epoll_pwait2() */\n\tres = epoll_wait(epollop->epfd, events, epollop->nevents, timeout);\n#endif /* EVENT__HAVE_EPOLL_PWAIT2 */\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (res == -1) {\n\t\tif (errno != EINTR) {\n\t\t\tevent_warn(\"epoll_wait\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tevent_debug((\"%s: epoll_wait reports %d\", __func__, res));\n\tEVUTIL_ASSERT(res <= epollop->nevents);\n\n\tfor (i = 0; i < res; i++) {\n\t\tint what = events[i].events;\n\t\tshort ev = 0;\n#ifdef USING_TIMERFD\n\t\tif (events[i].data.fd == epollop->timerfd)\n\t\t\tcontinue;\n#endif\n\n\t\tif (what & EPOLLERR) {\n\t\t\tev = EV_READ | EV_WRITE;\n\t\t} else if ((what & EPOLLHUP) && !(what & EPOLLRDHUP)) {\n\t\t\tev = EV_READ | EV_WRITE;\n\t\t} else {\n\t\t\tif (what & EPOLLIN)\n\t\t\t\tev |= EV_READ;\n\t\t\tif (what & EPOLLOUT)\n\t\t\t\tev |= EV_WRITE;\n\t\t\tif (what & EPOLLRDHUP)\n\t\t\t\tev |= EV_CLOSED;\n\t\t}\n\n\t\tif (!ev)\n\t\t\tcontinue;\n\n#ifdef EVENT__HAVE_WEPOLL\n\t\tevmap_io_active_(base, events[i].data.sock, ev);\n#else\n\t\tevmap_io_active_(base, events[i].data.fd, ev | EV_ET);\n#endif\n\t}\n\n\tif (res == epollop->nevents && epollop->nevents < MAX_NEVENT) {\n\t\t/* We used all of the event space this time.  We should\n\t\t   be ready for more events next time. */\n\t\tint new_nevents = epollop->nevents * 2;\n\t\tstruct epoll_event *new_events;\n\n\t\tnew_events = mm_realloc(epollop->events,\n\t\t    new_nevents * sizeof(struct epoll_event));\n\t\tif (new_events) {\n\t\t\tepollop->events = new_events;\n\t\t\tepollop->nevents = new_nevents;\n\t\t}\n\t}\n\n\treturn (0);\n}\n\n\nstatic void\nepoll_dealloc(struct event_base *base)\n{\n\tstruct epollop *epollop = base->evbase;\n\n\tevsig_dealloc_(base);\n\tif (epollop->events)\n\t\tmm_free(epollop->events);\n\tif (epollop->epfd != INVALID_EPOLL_HANDLE)\n\t\tclose_epoll_handle(epollop->epfd);\n#ifdef USING_TIMERFD\n\tif (epollop->timerfd >= 0)\n\t\tclose(epollop->timerfd);\n#endif\n\n\tmemset(epollop, 0, sizeof(struct epollop));\n\tmm_free(epollop);\n}\n\n#endif /* defined EVENT__HAVE_EPOLL || defined EVENT__HAVE_WEPOLL */\n"
        },
        {
          "name": "epoll_sub.c",
          "type": "blob",
          "size": 2.3349609375,
          "content": "/*\n * Copyright 2003-2009 Niels Provos <provos@citi.umich.edu>\n * Copyright 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"evconfig-private.h\"\n#include <stdint.h>\n\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/syscall.h>\n#include <sys/epoll.h>\n#include <unistd.h>\n#include <errno.h>\n\nint\nepoll_create(int size)\n{\n#if !defined(__NR_epoll_create) && defined(__NR_epoll_create1)\n\tif (size <= 0) {\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\treturn (syscall(__NR_epoll_create1, 0));\n#else\n\treturn (syscall(__NR_epoll_create, size));\n#endif\n}\n\nint\nepoll_ctl(int epfd, int op, int fd, struct epoll_event *event)\n{\n\n\treturn (syscall(__NR_epoll_ctl, epfd, op, fd, event));\n}\n\nint\nepoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)\n{\n#if !defined(__NR_epoll_wait) && defined(__NR_epoll_pwait)\n\treturn (syscall(__NR_epoll_pwait, epfd, events, maxevents, timeout, NULL, 0));\n#else\n\treturn (syscall(__NR_epoll_wait, epfd, events, maxevents, timeout));\n#endif\n}\n"
        },
        {
          "name": "epolltable-internal.h",
          "type": "blob",
          "size": 40.390625,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EPOLLTABLE_INTERNAL_H_INCLUDED_\n#define EPOLLTABLE_INTERNAL_H_INCLUDED_\n\n/*\n  Here are the values we're masking off to decide what operations to do.\n  Note that since EV_READ|EV_WRITE.\n\n  Note also that this table is a little sparse, since ADD+DEL is\n  nonsensical (\"xxx\" in the list below.)\n\n  Note also that we are shifting old_events by only 5 bits, since\n  EV_READ is 2 and EV_WRITE is 4.\n\n  The table was auto-generated with a python script, according to this\n  pseudocode:[*0]\n\n      If either the read or the write change is add+del:\n\t This is impossible; Set op==-1, events=0.\n      Else, if either the read or the write change is add:\n\t Set events to 0.\n\t If the read change is add, or\n\t    (the read change is not del, and ev_read is in old_events):\n\t       Add EPOLLIN to events.\n\t If the write change is add, or\n\t    (the write change is not del, and ev_write is in old_events):\n\t       Add EPOLLOUT to events.\n\n\t If old_events is set:\n\t       Set op to EPOLL_CTL_MOD [*1,*2]\n\tElse:\n\t       Set op to EPOLL_CTL_ADD [*3]\n\n      Else, if the read or the write change is del:\n\t Set op to EPOLL_CTL_DEL.\n\t If the read change is del:\n\t     If the write change is del:\n\t\t Set events to EPOLLIN|EPOLLOUT\n\t     Else if ev_write is in old_events:\n\t\t Set events to EPOLLOUT\n\t\tSet op to EPOLL_CTL_MOD\n\t     Else\n\t\t Set events to EPOLLIN\n\t Else:\n\t     {The write change is del.}\n\t    If ev_read is in old_events:\n\t\t Set events to EPOLLIN\n\t\tSet op to EPOLL_CTL_MOD\n\t    Else:\n\t\tSet the events to EPOLLOUT\n\n      Else:\n\t   There is no read or write change; set op to 0 and events to 0.\n\n      The logic is a little tricky, since we had no events set on the fd before,\n      we need to set op=\"ADD\" and set events=the events we want to add.\t If we\n      had any events set on the fd before, and we want any events to remain on\n      the fd, we need to say op=\"MOD\" and set events=the events we want to\n      remain.  But if we want to delete the last event, we say op=\"DEL\" and\n      set events=(any non-null pointer).\n\n  [*0] Actually, the Python script has gotten a bit more complicated, to\n       support EPOLLRDHUP.\n\n  [*1] This MOD is only a guess.  MOD might fail with ENOENT if the file was\n       closed and a new file was opened with the same fd.  If so, we'll retry\n       with ADD.\n\n  [*2] We can't replace this with a no-op even if old_events is the same as\n       the new events: if the file was closed and reopened, we need to retry\n       with an ADD.  (We do a MOD in this case since \"no change\" is more\n       common than \"close and reopen\", so we'll usually wind up doing 1\n       syscalls instead of 2.)\n\n  [*3] This ADD is only a guess.  There is a fun Linux kernel issue where if\n       you have two fds for the same file (via dup) and you ADD one to an\n       epfd, then close it, then re-create it with the same fd (via dup2 or an\n       unlucky dup), then try to ADD it again, you'll get an EEXIST, since the\n       struct epitem is not actually removed from the struct eventpoll until\n       the file itself is closed.\n\n  EV_CHANGE_ADD==1\n  EV_CHANGE_DEL==2\n  EV_READ      ==2\n  EV_WRITE     ==4\n  EV_CLOSED    ==0x80\n\n  Bit 0: close change is add\n  Bit 1: close change is del\n  Bit 2: read change is add\n  Bit 3: read change is del\n  Bit 4: write change is add\n  Bit 5: write change is del\n  Bit 6: old events had EV_READ\n  Bit 7: old events had EV_WRITE\n  Bit 8: old events had EV_CLOSED\n*/\n\n#define EPOLL_OP_TABLE_INDEX(c) \\\n\t(   (((c)->close_change&(EV_CHANGE_ADD|EV_CHANGE_DEL))) |\t\t\\\n\t    (((c)->read_change&(EV_CHANGE_ADD|EV_CHANGE_DEL)) << 2) |\t\\\n\t    (((c)->write_change&(EV_CHANGE_ADD|EV_CHANGE_DEL)) << 4) |\t\\\n\t    (((c)->old_events&(EV_READ|EV_WRITE)) << 5) |\t\t\\\n\t    (((c)->old_events&(EV_CLOSED)) << 1)\t\t\t\t\\\n\t    )\n\n#if EV_READ != 2 || EV_WRITE != 4 || EV_CLOSED != 0x80 || EV_CHANGE_ADD != 1 || EV_CHANGE_DEL != 2\n#error \"Libevent's internals changed!  Regenerate the op_table in epolltable-internal.h\"\n#endif\n\nstatic const struct operation {\n\tint events;\n\tint op;\n} epoll_op_table[] = {\n\t/* old=  0, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old=  0, write:  0, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:  0, read:  0, close:del */\n\t{ EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  0, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_ADD },\n\t/* old=  0, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:  0, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_ADD },\n\t/* old=  0, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:del, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_DEL },\n\t/* old=  0, write:  0, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:  0, read:del, close:del */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  0, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:  0, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_ADD },\n\t/* old=  0, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:  0, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old=  0, write:del, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:del, read:  0, close:del */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  0, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_ADD },\n\t/* old=  0, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_ADD },\n\t/* old=  0, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:del, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old=  0, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_ADD },\n\t/* old=  0, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  0, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  0, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old=  r, write:  0, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:del, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_DEL },\n\t/* old=  r, write:  0, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:  0, read:del, close:del */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  r, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  r, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:  0, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:del, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old=  r, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  r, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  r, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  r, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old=  w, write:  0, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:  0, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  w, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:  0, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old=  w, write:del, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:del, read:  0, close:del */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  w, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  w, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  w, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:del, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old=  w, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  w, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  w, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  w, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old= rw, write:  0, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:del, close:  0 */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= rw, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:  0, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:add, close:  0 */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:del, close:  0 */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_DEL },\n\t/* old= rw, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= rw, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old= rw, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= rw, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old=  c, write:  0, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:  0, close:del */\n\t{ EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  c, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:  0, read:del, close:del */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  c, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:  0, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=  c, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:  0, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:  0, close:del */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  c, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=  c, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=  c, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=  c, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old= cr, write:  0, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:  0, read:del, close:del */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old= cr, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cr, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cr, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old= cr, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cr, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old= cw, write:  0, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:  0, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:  0, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:  0, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old= cw, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:  0, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:  0, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:  0, close:del */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old= cw, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old= cw, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old= cw, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old= cw, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:  0, close:  0 */\n\t{ 0, 0 },\n\t/* old=crw, write:  0, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:  0, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:  0, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:  0, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:  0, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:add, close:add */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:add, close:del */\n\t{ EPOLLIN|EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:del, close:  0 */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:del, close:add */\n\t{ EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:del, close:del */\n\t{ EPOLLOUT, EPOLL_CTL_MOD },\n\t/* old=crw, write:add, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:add, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:  0, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:  0, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:  0, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:add, close:  0 */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:add, close:add */\n\t{ EPOLLIN|EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:add, close:del */\n\t{ EPOLLIN, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:del, close:  0 */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:del, close:add */\n\t{ EPOLLRDHUP, EPOLL_CTL_MOD },\n\t/* old=crw, write:del, read:del, close:del */\n\t{ EPOLLIN|EPOLLOUT|EPOLLRDHUP, EPOLL_CTL_DEL },\n\t/* old=crw, write:del, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:del, read:xxx, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:  0, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:  0, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:  0, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:  0, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:add, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:add, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:add, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:add, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:del, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:del, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:del, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:del, close:xxx */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:xxx, close:  0 */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:xxx, close:add */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:xxx, close:del */\n\t{ 0, 255 },\n\t/* old=crw, write:xxx, read:xxx, close:xxx */\n\t{ 0, 255 },\n};\n\n#endif\n"
        },
        {
          "name": "evbuffer-internal.h",
          "type": "blob",
          "size": 12.5576171875,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVBUFFER_INTERNAL_H_INCLUDED_\n#define EVBUFFER_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n#include \"event2/util.h\"\n#include \"event2/event_struct.h\"\n#include \"util-internal.h\"\n#include \"defer-internal.h\"\n\n/* Experimental cb flag: \"never deferred.\"  Implementation note:\n * these callbacks may get an inaccurate view of n_del/n_added in their\n * arguments. */\n#define EVBUFFER_CB_NODEFER 2\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n#include <sys/queue.h>\n\n/* Minimum allocation for a chain.  We define this so that we're burning no\n * more than 5% of each allocation on overhead.  It would be nice to lose even\n * less space, though. */\n#if EVENT__SIZEOF_VOID_P < 8\n#define MIN_BUFFER_SIZE\t512\n#else\n#define MIN_BUFFER_SIZE\t1024\n#endif\n\n/** A single evbuffer callback for an evbuffer. This function will be invoked\n * when bytes are added to or removed from the evbuffer. */\nstruct evbuffer_cb_entry {\n\t/** Structures to implement a doubly-linked queue of callbacks */\n\tLIST_ENTRY(evbuffer_cb_entry) next;\n\t/** The callback function to invoke when this callback is called.\n\t    If EVBUFFER_CB_OBSOLETE is set in flags, the cb_obsolete field is\n\t    valid; otherwise, cb_func is valid. */\n\tunion {\n\t\tevbuffer_cb_func cb_func;\n\t\tevbuffer_cb cb_obsolete;\n\t} cb;\n\t/** Argument to pass to cb. */\n\tvoid *cbarg;\n\t/** Currently set flags on this callback. */\n\tev_uint32_t flags;\n};\n\nstruct bufferevent;\nstruct evbuffer_chain;\nstruct evbuffer {\n\t/** The first chain in this buffer's linked list of chains. */\n\tstruct evbuffer_chain *first;\n\t/** The last chain in this buffer's linked list of chains. */\n\tstruct evbuffer_chain *last;\n\n\t/** Pointer to the next pointer pointing at the 'last_with_data' chain.\n\t *\n\t * To unpack:\n\t *\n\t * The last_with_data chain is the last chain that has any data in it.\n\t * If all chains in the buffer are empty, it is the first chain.\n\t * If the buffer has no chains, it is NULL.\n\t *\n\t * The last_with_datap pointer points at _whatever 'next' pointer_\n\t * pointing at the last_with_data chain. If the last_with_data chain\n\t * is the first chain, or it is NULL, then the last_with_datap pointer\n\t * is &buf->first.\n\t */\n\tstruct evbuffer_chain **last_with_datap;\n\n\t/** Total amount of bytes stored in all chains.*/\n\tsize_t total_len;\n\t/** Maximum bytes per one read */\n\tsize_t max_read;\n\n\t/** Number of bytes we have added to the buffer since we last tried to\n\t * invoke callbacks. */\n\tsize_t n_add_for_cb;\n\t/** Number of bytes we have removed from the buffer since we last\n\t * tried to invoke callbacks. */\n\tsize_t n_del_for_cb;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\t/** A lock used to mediate access to this buffer. */\n\tvoid *lock;\n#endif\n\t/** True iff we should free the lock field when we free this\n\t * evbuffer. */\n\tunsigned own_lock : 1;\n\t/** True iff we should not allow changes to the front of the buffer\n\t * (drains or prepends). */\n\tunsigned freeze_start : 1;\n\t/** True iff we should not allow changes to the end of the buffer\n\t * (appends) */\n\tunsigned freeze_end : 1;\n\t/** True iff this evbuffer's callbacks are not invoked immediately\n\t * upon a change in the buffer, but instead are deferred to be invoked\n\t * from the event_base's loop.\tUseful for preventing enormous stack\n\t * overflows when we have mutually recursive callbacks, and for\n\t * serializing callbacks in a single thread. */\n\tunsigned deferred_cbs : 1;\n#ifdef _WIN32\n\t/** True iff this buffer is set up for overlapped IO. */\n\tunsigned is_overlapped : 1;\n#endif\n\t/** Zero or more EVBUFFER_FLAG_* bits */\n\tev_uint32_t flags;\n\n\t/** Used to implement deferred callbacks. */\n\tstruct event_base *cb_queue;\n\n\t/** A reference count on this evbuffer.\t When the reference count\n\t * reaches 0, the buffer is destroyed.\tManipulated with\n\t * evbuffer_incref and evbuffer_decref_and_unlock and\n\t * evbuffer_free. */\n\tint refcnt;\n\n\t/** A struct event_callback handle to make all of this buffer's callbacks\n\t * invoked from the event loop. */\n\tstruct event_callback deferred;\n\n\t/** A doubly-linked-list of callback functions */\n\tLIST_HEAD(evbuffer_cb_queue, evbuffer_cb_entry) callbacks;\n\n\t/** The parent bufferevent object this evbuffer belongs to.\n\t * NULL if the evbuffer stands alone. */\n\tstruct bufferevent *parent;\n};\n\n#if EVENT__SIZEOF_OFF_T < EVENT__SIZEOF_SIZE_T\ntypedef ev_ssize_t ev_misalign_t;\n#define EVBUFFER_CHAIN_MAX ((size_t)EV_SSIZE_MAX)\n#else\ntypedef ev_off_t ev_misalign_t;\n#if EVENT__SIZEOF_OFF_T > EVENT__SIZEOF_SIZE_T\n#define EVBUFFER_CHAIN_MAX EV_SIZE_MAX\n#else\n#define EVBUFFER_CHAIN_MAX ((size_t)EV_SSIZE_MAX)\n#endif\n#endif\n\n/** A single item in an evbuffer. */\nstruct evbuffer_chain {\n\t/** points to next buffer in the chain */\n\tstruct evbuffer_chain *next;\n\n\t/** total allocation available in the buffer field. */\n\tsize_t buffer_len;\n\n\t/** unused space at the beginning of buffer or an offset into a\n\t * file for sendfile buffers. */\n\tev_misalign_t misalign;\n\n\t/** Offset into buffer + misalign at which to start writing.\n\t * In other words, the total number of bytes actually stored\n\t * in buffer. */\n\tsize_t off;\n\n\t/** Set if special handling is required for this chain */\n\tunsigned flags;\n#define EVBUFFER_FILESEGMENT\t0x0001  /**< A chain used for a file segment */\n#define EVBUFFER_SENDFILE\t0x0002\t/**< a chain used with sendfile */\n#define EVBUFFER_REFERENCE\t0x0004\t/**< a chain with a mem reference */\n#define EVBUFFER_IMMUTABLE\t0x0008\t/**< read-only chain */\n\t/** a chain that mustn't be reallocated or freed, or have its contents\n\t * memmoved, until the chain is un-pinned. */\n#define EVBUFFER_MEM_PINNED_R\t0x0010\n#define EVBUFFER_MEM_PINNED_W\t0x0020\n#define EVBUFFER_MEM_PINNED_ANY (EVBUFFER_MEM_PINNED_R|EVBUFFER_MEM_PINNED_W)\n\t/** a chain that should be freed, but can't be freed until it is\n\t * un-pinned. */\n#define EVBUFFER_DANGLING\t0x0040\n\t/** a chain that is a referenced copy of another chain */\n#define EVBUFFER_MULTICAST\t0x0080\n\n\t/** number of references to this chain */\n\tint refcnt;\n\n\t/** Usually points to the read-write memory belonging to this\n\t * buffer allocated as part of the evbuffer_chain allocation.\n\t * For mmap, this can be a read-only buffer and\n\t * EVBUFFER_IMMUTABLE will be set in flags.  For sendfile, it\n\t * may point to NULL.\n\t */\n\tunsigned char *buffer;\n};\n\n/** callback for a reference chain; lets us know what to do with it when\n * we're done with it. Lives at the end of an evbuffer_chain with the\n * EVBUFFER_REFERENCE flag set */\nstruct evbuffer_chain_reference {\n\tevbuffer_ref_cleanup_cb cleanupfn;\n\tvoid *extra;\n};\n\n/** File segment for a file-segment chain.  Lives at the end of an\n * evbuffer_chain with the EVBUFFER_FILESEGMENT flag set.  */\nstruct evbuffer_chain_file_segment {\n\tstruct evbuffer_file_segment *segment;\n#ifdef _WIN32\n\t/** If we're using CreateFileMapping, this is the handle to the view. */\n\tHANDLE view_handle;\n#endif\n};\n\n/* Declared in event2/buffer.h; defined here. */\nstruct evbuffer_file_segment {\n\tvoid *lock; /**< lock prevent concurrent access to refcnt */\n\tint refcnt; /**< Reference count for this file segment */\n\tunsigned flags; /**< combination of EVBUF_FS_* flags  */\n\n\t/** What kind of file segment is this? */\n\tunsigned can_sendfile : 1;\n\tunsigned is_mapping : 1;\n\n\t/** The fd that we read the data from. */\n\tint fd;\n\t/** If we're using mmap, this is the raw mapped memory. */\n\tvoid *mapping;\n#ifdef _WIN32\n\t/** If we're using CreateFileMapping, this is the mapping */\n\tHANDLE mapping_handle;\n#endif\n\t/** If we're using mmap or IO, this is the content of the file\n\t * segment. */\n\tchar *contents;\n\t/** Position of this segment within the file. */\n\tev_off_t file_offset;\n\t/** If we're using mmap, this is the offset within 'mapping' where\n\t * this data segment begins. */\n\tev_off_t mmap_offset;\n\t/** The length of this segment. */\n\tev_off_t length;\n\t/** Cleanup callback function */\n\tevbuffer_file_segment_cleanup_cb cleanup_cb;\n\t/** Argument to be pass to cleanup callback function */\n\tvoid *cleanup_cb_arg;\n};\n\n/** Information about the multicast parent of a chain.  Lives at the\n * end of an evbuffer_chain with the EVBUFFER_MULTICAST flag set.  */\nstruct evbuffer_multicast_parent {\n\t/** source buffer the multicast parent belongs to */\n\tstruct evbuffer *source;\n\t/** multicast parent for this chain */\n\tstruct evbuffer_chain *parent;\n};\n\n#define EVBUFFER_CHAIN_SIZE sizeof(struct evbuffer_chain)\n/** Return a pointer to extra data allocated along with an evbuffer. */\n#define EVBUFFER_CHAIN_EXTRA(t, c) (t *)((struct evbuffer_chain *)(c) + 1)\n\n/** Assert that we are holding the lock on an evbuffer */\n#define ASSERT_EVBUFFER_LOCKED(buffer)\t\t\t\\\n\tEVLOCK_ASSERT_LOCKED((buffer)->lock)\n\n#define EVBUFFER_LOCK(buffer)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tEVLOCK_LOCK((buffer)->lock, 0);\t\t\t\t\\\n\t} while (0)\n#define EVBUFFER_UNLOCK(buffer)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tEVLOCK_UNLOCK((buffer)->lock, 0);\t\t\t\\\n\t} while (0)\n#define EVBUFFER_LOCK2(buffer1, buffer2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tEVLOCK_LOCK2((buffer1)->lock, (buffer2)->lock, 0, 0);\t\\\n\t} while (0)\n#define EVBUFFER_UNLOCK2(buffer1, buffer2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tEVLOCK_UNLOCK2((buffer1)->lock, (buffer2)->lock, 0, 0);\t\\\n\t} while (0)\n\n/** Increase the reference count of buf by one. */\nvoid evbuffer_incref_(struct evbuffer *buf);\n/** Increase the reference count of buf by one and acquire the lock. */\nvoid evbuffer_incref_and_lock_(struct evbuffer *buf);\n/** Pin a single buffer chain using a given flag. A pinned chunk may not be\n * moved or freed until it is unpinned. */\nvoid evbuffer_chain_pin_(struct evbuffer_chain *chain, unsigned flag);\n/** Unpin a single buffer chain using a given flag. */\nvoid evbuffer_chain_unpin_(struct evbuffer_chain *chain, unsigned flag);\n/** As evbuffer_free, but requires that we hold a lock on the buffer, and\n * releases the lock before freeing it and the buffer. */\nvoid evbuffer_decref_and_unlock_(struct evbuffer *buffer);\n\n/** As evbuffer_expand, but does not guarantee that the newly allocated memory\n * is contiguous.  Instead, it may be split across two or more chunks. */\nint evbuffer_expand_fast_(struct evbuffer *, size_t, int);\n\n/** Helper: prepares for a readv/WSARecv call by expanding the buffer to\n * hold enough memory to read 'howmuch' bytes in possibly noncontiguous memory.\n * Sets up the one or two iovecs in 'vecs' to point to the free memory and its\n * extent, and *chainp to point to the first chain that we'll try to read into.\n * Returns the number of vecs used.\n */\nint evbuffer_read_setup_vecs_(struct evbuffer *buf, ev_ssize_t howmuch,\n    struct evbuffer_iovec *vecs, int n_vecs, struct evbuffer_chain ***chainp,\n    int exact);\n\n/* Helper macro: copies an evbuffer_iovec in ei to a win32 WSABUF in i. */\n#define WSABUF_FROM_EVBUFFER_IOV(i,ei) do {\t\t\\\n\t\t(i)->buf = (ei)->iov_base;\t\t\\\n\t\t(i)->len = (unsigned long)(ei)->iov_len;\t\\\n\t} while (0)\n/* XXXX the cast above is safe for now, but not if we allow mmaps on win64.\n * See note in buffer_iocp's launch_write function */\n\n/** Set the parent bufferevent object for buf to bev */\nvoid evbuffer_set_parent_(struct evbuffer *buf, struct bufferevent *bev);\n\nvoid evbuffer_invoke_callbacks_(struct evbuffer *buf);\n\n\nint evbuffer_get_callbacks_(struct evbuffer *buffer,\n    struct event_callback **cbs,\n    int max_cbs);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* EVBUFFER_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "evconfig-private.h.cmake",
          "type": "blob",
          "size": 1.0205078125,
          "content": "\n#ifndef EVCONFIG_PRIVATE_H_INCLUDED_\n#define EVCONFIG_PRIVATE_H_INCLUDED_\n\n/* Enable extensions on AIX 3, Interix.  */\n#cmakedefine _ALL_SOURCE\n\n/* Enable GNU extensions on systems that have them.  */\n#cmakedefine _GNU_SOURCE 1\n\n/* Enable threading extensions on Solaris.  */\n#cmakedefine _POSIX_PTHREAD_SEMANTICS 1\n\n/* Enable extensions on HP NonStop.  */\n#cmakedefine _TANDEM_SOURCE 1\n\n/* Enable general extensions on Solaris.  */\n#cmakedefine __EXTENSIONS__\n\n/* Number of bits in a file offset, on hosts where this is settable. */\n#cmakedefine _FILE_OFFSET_BITS 1\n/* Define for large files, on AIX-style hosts. */\n#cmakedefine _LARGE_FILES 1\n\n/* Define to 1 if on MINIX. */\n#cmakedefine _MINIX 1\n\n/* Define to 2 if the system does not provide POSIX.1 features except with\n   this defined. */\n#cmakedefine _POSIX_1_SOURCE 1\n\n/* Define to 1 if you need to in order for `stat' and other things to work. */\n#cmakedefine _POSIX_SOURCE 1\n\n/* Enable POSIX.2 extensions on QNX for getopt */\n#ifdef __QNX__\n#cmakedefine __EXT_POSIX2 1\n#endif\n\n#endif\n"
        },
        {
          "name": "evconfig-private.h.in",
          "type": "blob",
          "size": 1.33203125,
          "content": "/* evconfig-private.h template - see \"Configuration Header Templates\" */\n/* in AC manual.  Kevin Bowling <kevin.bowling@kev009.com */\n#ifndef EVCONFIG_PRIVATE_H_INCLUDED_\n#define EVCONFIG_PRIVATE_H_INCLUDED_\n\n/* Enable extensions on AIX 3, Interix.  */\n#ifndef _ALL_SOURCE\n# undef _ALL_SOURCE\n#endif\n/* Enable GNU extensions on systems that have them.  */\n#ifndef _GNU_SOURCE\n# undef _GNU_SOURCE\n#endif\n/* Enable threading extensions on Solaris.  */\n#ifndef _POSIX_PTHREAD_SEMANTICS\n# undef _POSIX_PTHREAD_SEMANTICS\n#endif\n/* Enable extensions on HP NonStop.  */\n#ifndef _TANDEM_SOURCE\n# undef _TANDEM_SOURCE\n#endif\n/* Enable general extensions on Solaris.  */\n#ifndef __EXTENSIONS__\n# undef __EXTENSIONS__\n#endif\n\n/* Number of bits in a file offset, on hosts where this is settable. */\n#undef _FILE_OFFSET_BITS\n/* Define for large files, on AIX-style hosts. */\n#undef _LARGE_FILES\n\n/* Define to 1 if on MINIX. */\n#ifndef _MINIX\n#undef _MINIX\n#endif\n\n/* Define to 2 if the system does not provide POSIX.1 features except with\n   this defined. */\n#ifndef _POSIX_1_SOURCE\n#undef _POSIX_1_SOURCE\n#endif\n\n/* Define to 1 if you need to in order for `stat' and other things to work. */\n#ifndef _POSIX_SOURCE\n#undef _POSIX_SOURCE\n#endif\n\n/* Enable POSIX.2 extensions on QNX for getopt */\n#ifdef __QNX__\n# ifndef __EXT_POSIX2\n#  define __EXT_POSIX2\n# endif\n#endif\n\n#endif\n"
        },
        {
          "name": "evdns-internal.h",
          "type": "blob",
          "size": 0.29296875,
          "content": "#ifndef EVDNS_INTERNAL_H_INCLUDED_\n#define EVDNS_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event_struct.h\"\n\n#ifdef _WIN32\n\nEVENT2_EXPORT_SYMBOL\nint load_nameservers_with_getadaptersaddresses(struct evdns_base *base);\n\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n\n"
        },
        {
          "name": "evdns.c",
          "type": "blob",
          "size": 161.4814453125,
          "content": "/* Copyright 2006-2007 Niels Provos\n * Copyright 2007-2012 Nick Mathewson and Niels Provos\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* Based on software by Adam Langly. Adam's original message:\n *\n * Async DNS Library\n * Adam Langley <agl@imperialviolet.org>\n * Public Domain code\n *\n * This software is Public Domain. To view a copy of the public domain dedication,\n * visit http://creativecommons.org/licenses/publicdomain/ or send a letter to\n * Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.\n *\n * I ask and expect, but do not require, that all derivative works contain an\n * attribution similar to:\n *\tParts developed by Adam Langley <agl@imperialviolet.org>\n *\n * You may wish to replace the word \"Parts\" with something else depending on\n * the amount of original code.\n *\n * (Derivative works does not include programs which link against, run or include\n * the source verbatim in their source distributions)\n *\n * Version: 0.1b\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifndef _FORTIFY_SOURCE\n#define _FORTIFY_SOURCE 3\n#endif\n\n#include <string.h>\n#include <fcntl.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#ifdef EVENT__HAVE_STDINT_H\n#include <stdint.h>\n#endif\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#include <limits.h>\n#include <sys/stat.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <sys/tree.h>\n#ifdef _WIN32\n#include <winsock2.h>\n#include <winerror.h>\n#include <ws2tcpip.h>\n#ifndef _WIN32_IE\n#define _WIN32_IE 0x400\n#endif\n#include <shlobj.h>\n#define strcasecmp strcmpi\n#endif\n\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/dns.h\"\n#include \"event2/dns_struct.h\"\n#include \"event2/dns_compat.h\"\n#include \"event2/util.h\"\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/listener.h\"\n#include \"event2/thread.h\"\n\n#include \"defer-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"strlcpy-internal.h\"\n#include \"ipv6-internal.h\"\n#include \"util-internal.h\"\n#include \"evthread-internal.h\"\n#include \"evdns-internal.h\"\n#ifdef _WIN32\n#include <ctype.h>\n#include <winsock2.h>\n#include <windows.h>\n#include <iphlpapi.h>\n#include <io.h>\n#else\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#endif\n\n#ifdef EVENT__HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n\n#define EVDNS_LOG_DEBUG EVENT_LOG_DEBUG\n#define EVDNS_LOG_WARN EVENT_LOG_WARN\n#define EVDNS_LOG_MSG EVENT_LOG_MSG\n\n#ifndef EVDNS_NAME_MAX\n#define EVDNS_NAME_MAX 255\n#endif\n\n#include <stdio.h>\n\n#undef MIN\n#undef MAX\n#define MIN(a,b) ((a)<(b)?(a):(b))\n#define MAX(a,b) ((a)>(b)?(a):(b))\n\n#define ASSERT_VALID_REQUEST(req) \\\n\tEVUTIL_ASSERT((req)->handle && (req)->handle->current_req == (req))\n\n#define u64 ev_uint64_t\n#define u32 ev_uint32_t\n#define u16 ev_uint16_t\n#define u8  ev_uint8_t\n\n/* maximum number of addresses from a single packet */\n/* that we bother recording */\n#define MAX_V4_ADDRS 32\n#define MAX_V6_ADDRS 32\n\n/* Maximum allowable size of a DNS message over UDP without EDNS.*/\n#define DNS_MAX_UDP_SIZE 512\n/* Maximum allowable size of a DNS message over UDP with EDNS.*/\n#define EDNS_MAX_UDP_SIZE 65535\n\n#define EDNS_ENABLED(base) \\\n\t(((base)->global_max_udp_size) > DNS_MAX_UDP_SIZE)\n\n#define TYPE_A\t       EVDNS_TYPE_A\n#define TYPE_CNAME     5\n#define TYPE_PTR       EVDNS_TYPE_PTR\n#define TYPE_SOA       EVDNS_TYPE_SOA\n#define TYPE_AAAA      EVDNS_TYPE_AAAA\n#define TYPE_OPT       41\n\n#define CLASS_INET     EVDNS_CLASS_INET\n\n/* Timeout in seconds for idle TCP connections that server keeps alive. */\n#define SERVER_IDLE_CONN_TIMEOUT 10\n/* Timeout in seconds for idle TCP connections that client keeps alive. */\n#define CLIENT_IDLE_CONN_TIMEOUT 5\n/* Default maximum number of simultaneous TCP client connections that DNS server can hold. */\n#define MAX_CLIENT_CONNECTIONS 10\n\nstruct reply {\n\tunsigned int type;\n\tunsigned int have_answer : 1;\n\tu32 rr_count;\n\tunion {\n\t\tu32 *a;\n\t\tstruct in6_addr *aaaa;\n\t\tchar *ptr_name;\n\t\tvoid *raw;\n\t} data;\n\tchar *cname;\n};\n\n\n/* Persistent handle.  We keep this separate from 'struct request' since we\n * need some object to last for as long as an evdns_request is outstanding so\n * that it can be canceled, whereas a search request can lead to multiple\n * 'struct request' instances being created over its lifetime. */\nstruct evdns_request {\n\tstruct request *current_req;\n\tstruct evdns_base *base;\n\n\tint pending_cb; /* Waiting for its callback to be invoked; not\n\t\t\t * owned by event base any more. */\n\n\t/* data used when fulfilling the callback */\n\tstruct event_callback deferred;\n\tevdns_callback_type user_callback;\n\tvoid *user_pointer;\n\tu8 request_type;\n\tu8 have_reply;\n\tu32 ttl;\n\tu32 err;\n\tstruct reply reply;\n\n\t/* elements used by the searching code */\n\tint search_index;\n\tstruct search_state *search_state;\n\tchar *search_origname;\t/* needs to be free()ed */\n\tint search_flags;\n\tu16 tcp_flags;\n};\n\nstruct request {\n\tu8 *request;  /* the dns packet data */\n\tu16 request_size; /* size of memory block stored in request field */\n\tu8 request_type; /* TYPE_PTR or TYPE_A or TYPE_AAAA */\n\tunsigned int request_len;\n\tint reissue_count;\n\tint tx_count;  /* the number of times that this packet has been sent */\n\tstruct nameserver *ns;\t/* the server which we last sent it */\n\n\t/* these objects are kept in a circular list */\n\t/* XXX We could turn this into a CIRCLEQ. */\n\tstruct request *next, *prev;\n\n\tstruct event timeout_event;\n\n\tu16 trans_id;  /* the transaction id */\n\tunsigned request_appended :1;\t/* true if the request pointer is data which follows this struct */\n\tunsigned transmit_me :1;  /* needs to be transmitted */\n\tunsigned need_cname :1;   /* make a separate callback for CNAME */\n\n\t/* XXXX This is a horrible hack. */\n\tchar **put_cname_in_ptr; /* store the cname here if we get one. */\n\n\tstruct evdns_base *base;\n\n\tstruct evdns_request *handle;\n};\n\nenum tcp_state {\n\tTS_DISCONNECTED,\n\tTS_CONNECTING,\n\tTS_CONNECTED\n};\n\nstruct tcp_connection {\n\tstruct bufferevent *bev;\n\tenum tcp_state state;\n\tu16 awaiting_packet_size;\n};\n\nstruct evdns_server_port;\n\nstruct client_tcp_connection {\n\tLIST_ENTRY(client_tcp_connection) next;\n\tstruct tcp_connection connection;\n\tstruct evdns_server_port *port;\n};\n\nstruct nameserver {\n\tevutil_socket_t socket;\t /* a connected UDP socket */\n\tstruct tcp_connection *connection; /* intended for TCP support */\n\tstruct sockaddr_storage address;\n\tev_socklen_t addrlen;\n\tint failed_times;  /* number of times which we have given this server a chance */\n\tint timedout;  /* number of times in a row a request has timed out */\n\tstruct event event;\n\t/* these objects are kept in a circular list */\n\tstruct nameserver *next, *prev;\n\tstruct event timeout_event;  /* used to keep the timeout for */\n\t\t\t\t     /* when we next probe this server. */\n\t\t\t\t     /* Valid if state == 0 */\n\t/* Outstanding probe request for this nameserver, if any */\n\tstruct evdns_request *probe_request;\n\tchar state;  /* zero if we think that this server is down */\n\tchar choked;  /* true if we have an EAGAIN from this server's socket */\n\tchar write_waiting;  /* true if we are waiting for EV_WRITE events */\n\tstruct evdns_base *base;\n\n\t/* Number of currently inflight requests: used\n\t * to track when we should add/del the event. */\n\tint requests_inflight;\n};\n\n\n/* Represents a local port where we're listening for DNS requests. */\nstruct evdns_server_port {\n\tevutil_socket_t socket; /* socket we use to read queries and write replies. */\n\tint refcnt; /* reference count. */\n\tchar choked; /* Are we currently blocked from writing? */\n\tchar closing; /* Are we trying to close this port, pending writes? */\n\tevdns_request_callback_fn_type user_callback; /* Fn to handle requests */\n\tvoid *user_data; /* Opaque pointer passed to user_callback */\n\tstruct event event; /* Read/write event */\n\t/* circular list of replies that we want to write. */\n\tstruct server_request *pending_replies;\n\tstruct event_base *event_base;\n\n\t/* Structures for tcp support */\n\tstruct evconnlistener *listener;\n\tLIST_HEAD(client_list, client_tcp_connection) client_connections;\n\tunsigned client_connections_count;\n\tunsigned max_client_connections;\n\tstruct timeval tcp_idle_timeout;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tvoid *lock;\n#endif\n};\n\n/* Represents part of a reply being built.\t(That is, a single RR.) */\nstruct server_reply_item {\n\tstruct server_reply_item *next; /* next item in sequence. */\n\tchar *name; /* name part of the RR */\n\tu16 type; /* The RR type */\n\tu16 class; /* The RR class (usually CLASS_INET) */\n\tu32 ttl; /* The RR TTL */\n\tchar is_name; /* True iff data is a label */\n\tu16 datalen; /* Length of data; -1 if data is a label */\n\tvoid *data; /* The contents of the RR */\n};\n\n/* Represents a request that we've received as a DNS server, and holds */\n/* the components of the reply as we're constructing it. */\nstruct server_request {\n\t/* Pointers to the next and previous entries on the list of replies */\n\t/* that we're waiting to write.\t Only set if we have tried to respond */\n\t/* and gotten EAGAIN. */\n\tstruct server_request *next_pending;\n\tstruct server_request *prev_pending;\n\n\tu16 trans_id; /* Transaction id. */\n\tstruct evdns_server_port *port; /* Which port received this request on? */\n\tstruct client_tcp_connection *client; /* Equal to NULL in case of UDP connection. */\n\tstruct sockaddr_storage addr; /* Where to send the response in case of UDP. Equal to NULL in case of TCP connection.*/\n\tev_socklen_t addrlen; /* length of addr */\n\tu16 max_udp_reply_size; /* Maximum size of udp reply that client can handle. */\n\n\tint n_answer; /* how many answer RRs have been set? */\n\tint n_authority; /* how many authority RRs have been set? */\n\tint n_additional; /* how many additional RRs have been set? */\n\n\tstruct server_reply_item *answer; /* linked list of answer RRs */\n\tstruct server_reply_item *authority; /* linked list of authority RRs */\n\tstruct server_reply_item *additional; /* linked list of additional RRs */\n\n\t/* Constructed response.  Only set once we're ready to send a reply. */\n\t/* Once this is set, the RR fields are cleared, and no more should be set. */\n\tchar *response;\n\tsize_t response_len;\n\n\t/* Caller-visible fields: flags, questions. */\n\tstruct evdns_server_request base;\n};\n\nstruct evdns_base {\n\t/* An array of n_req_heads circular lists for inflight requests.\n\t * Each inflight request req is in req_heads[req->trans_id % n_req_heads].\n\t */\n\tstruct request **req_heads;\n\t/* A circular list of requests that we're waiting to send, but haven't\n\t * sent yet because there are too many requests inflight */\n\tstruct request *req_waiting_head;\n\t/* A circular list of nameservers. */\n\tstruct nameserver *server_head;\n\tint n_req_heads;\n\n\tstruct event_base *event_base;\n\n\t/* The number of good nameservers that we have */\n\tint global_good_nameservers;\n\n\t/* inflight requests are contained in the req_head list */\n\t/* and are actually going out across the network */\n\tint global_requests_inflight;\n\t/* requests which aren't inflight are in the waiting list */\n\t/* and are counted here */\n\tint global_requests_waiting;\n\n\tint global_max_requests_inflight;\n\n\tstruct timeval global_timeout;\t/* 5 seconds by default */\n\tint global_max_reissues;  /* a reissue occurs when we get some errors from the server */\n\tint global_max_retransmits;  /* number of times we'll retransmit a request which timed out */\n\t/* number of timeouts in a row before we consider this server to be down */\n\tint global_max_nameserver_timeout;\n\t/* true iff we will use the 0x20 hack to prevent poisoning attacks. */\n\tint global_randomize_case;\n\t/* Maximum size of a UDP DNS packet. */\n\tu16 global_max_udp_size;\n\n\t/* The first time that a nameserver fails, how long do we wait before\n\t * probing to see if it has returned?  */\n\tstruct timeval global_nameserver_probe_initial_timeout;\n\n\t/* Combination of DNS_QUERY_USEVC, DNS_QUERY_IGNTC flags\n\t * to control requests via TCP. */\n\tu16 global_tcp_flags;\n\t/* Idle timeout for outgoing TCP connections. */\n\tstruct timeval global_tcp_idle_timeout;\n\n\t/** Port to bind to for outgoing DNS packets. */\n\tstruct sockaddr_storage global_outgoing_address;\n\t/** ev_socklen_t for global_outgoing_address. 0 if it isn't set. */\n\tev_socklen_t global_outgoing_addrlen;\n\n\tstruct timeval global_getaddrinfo_allow_skew;\n\n\tint so_rcvbuf;\n\tint so_sndbuf;\n\n\tint getaddrinfo_ipv4_timeouts;\n\tint getaddrinfo_ipv6_timeouts;\n\tint getaddrinfo_ipv4_answered;\n\tint getaddrinfo_ipv6_answered;\n\n\tstruct search_state *global_search_state;\n\n\tTAILQ_HEAD(hosts_list, hosts_entry) hostsdb;\n\n\tSPLAY_HEAD(evdns_tree, evdns_cache) cache_root;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tvoid *lock;\n#endif\n\n\tint disable_when_inactive;\n\tint disable_cache;\n\n\t/* Maximum timeout between two probe packets\n\t * will change `global_nameserver_probe_initial_timeout`\n\t * when this value is smaller */\n\tint ns_max_probe_timeout;\n\t/* Backoff factor of probe timeout */\n\tint ns_timeout_backoff_factor;\n};\n\nstruct hosts_entry {\n\tTAILQ_ENTRY(hosts_entry) next;\n\tunion {\n\t\tstruct sockaddr sa;\n\t\tstruct sockaddr_in sin;\n\t\tstruct sockaddr_in6 sin6;\n\t} addr;\n\tint addrlen;\n\tchar hostname[1];\n};\n\nstruct evdns_cache {\n\tSPLAY_ENTRY(evdns_cache) node;\n\tchar *name;\n\tstruct evutil_addrinfo *ai;\n\tstruct event ev_timeout;\n\tstruct evdns_base *base;\n};\n\nstatic struct evdns_base *current_base = NULL;\n\nstruct evdns_base *\nevdns_get_global_base(void)\n{\n\treturn current_base;\n}\n\n/* Given a pointer to an evdns_server_request, get the corresponding */\n/* server_request. */\n#define TO_SERVER_REQUEST(base_ptr)\t\t\t\t\t\\\n\t((struct server_request*)\t\t\t\t\t\\\n\t  (((char*)(base_ptr) - evutil_offsetof(struct server_request, base))))\n\n#define REQ_HEAD(base, id) ((base)->req_heads[id % (base)->n_req_heads])\n\nstatic struct nameserver *nameserver_pick(struct evdns_base *base);\nstatic void evdns_request_insert(struct request *req, struct request **head);\nstatic void evdns_request_remove(struct request *req, struct request **head);\nstatic void nameserver_ready_callback(evutil_socket_t fd, short events, void *arg);\nstatic int evdns_transmit(struct evdns_base *base);\nstatic int evdns_request_transmit(struct request *req);\nstatic void nameserver_send_probe(struct nameserver *const ns);\nstatic void search_request_finished(struct evdns_request *const);\nstatic int search_try_next(struct evdns_request *const req);\nstatic struct request *search_request_new(struct evdns_base *base, struct evdns_request *handle, int type, const char *const name, int flags);\nstatic void evdns_requests_pump_waiting_queue(struct evdns_base *base);\nstatic u16 transaction_id_pick(struct evdns_base *base);\nstatic struct request *request_new(struct evdns_base *base, struct evdns_request *handle, int type, const char *name, int flags);\nstatic struct request *request_clone(struct evdns_base *base, struct request* current);\nstatic void request_submit(struct request *const req);\n\nstatic int server_request_free(struct server_request *req);\nstatic void server_request_free_answers(struct server_request *req);\nstatic void server_port_free(struct evdns_server_port *port);\nstatic void server_port_ready_callback(evutil_socket_t fd, short events, void *arg);\nstatic int evdns_base_resolv_conf_parse_impl(struct evdns_base *base, int flags, const char *const filename);\nstatic int evdns_base_set_option_impl(struct evdns_base *base,\n    const char *option, const char *val, int flags);\nstatic void evdns_base_free_and_unlock(struct evdns_base *base, int fail_requests);\nstatic void evdns_request_timeout_callback(evutil_socket_t fd, short events, void *arg);\nstatic int evdns_server_request_format_response(struct server_request *req, int err);\nstatic void incoming_conn_cb(struct evconnlistener *listener, evutil_socket_t fd,\n    struct sockaddr *address, int socklen, void *arg);\n\nstatic int strtoint(const char *const str);\n\n#ifdef EVENT__DISABLE_THREAD_SUPPORT\n#define EVDNS_LOCK(base)  EVUTIL_NIL_CONDITION_(base)\n#define EVDNS_UNLOCK(base) EVUTIL_NIL_STMT_\n#define ASSERT_LOCKED(base) EVUTIL_NIL_STMT_\n#else\n#define EVDNS_LOCK(base)\t\t\t\\\n\tEVLOCK_LOCK((base)->lock, 0)\n#define EVDNS_UNLOCK(base)\t\t\t\\\n\tEVLOCK_UNLOCK((base)->lock, 0)\n#define ASSERT_LOCKED(base)\t\t\t\\\n\tEVLOCK_ASSERT_LOCKED((base)->lock)\n#endif\n\nstatic evdns_debug_log_fn_type evdns_log_fn = NULL;\n\nvoid\nevdns_set_log_fn(evdns_debug_log_fn_type fn)\n{\n\tevdns_log_fn = fn;\n}\n\n#ifdef __GNUC__\n#define EVDNS_LOG_CHECK\t __attribute__ ((format(printf, 2, 3)))\n#else\n#define EVDNS_LOG_CHECK\n#endif\n\nstatic void evdns_log_(int severity, const char *fmt, ...) EVDNS_LOG_CHECK;\nstatic void\nevdns_log_(int severity, const char *fmt, ...)\n{\n\tva_list args;\n\tva_start(args,fmt);\n\tif (evdns_log_fn) {\n\t\tchar buf[512];\n\t\tint is_warn = (severity == EVDNS_LOG_WARN);\n\t\tevutil_vsnprintf(buf, sizeof(buf), fmt, args);\n\t\tevdns_log_fn(is_warn, buf);\n\t} else {\n\t\tevent_logv_(severity, NULL, fmt, args);\n\t}\n\tva_end(args);\n}\n\n#define log evdns_log_\n\n/* Initialize tcp_connection structure. */\nstatic void\ninit_tcp_connection(struct tcp_connection *conn, struct bufferevent *bev)\n{\n\tmemset(conn, 0, sizeof(*conn));\n\tconn->state = TS_DISCONNECTED;\n\tconn->bev = bev;\n\tconn->awaiting_packet_size = 0;\n}\n\n/* Disconnect tcp connection. */\nstatic void\nevdns_tcp_disconnect(struct tcp_connection *conn)\n{\n\tif (!conn)\n\t\treturn;\n\tconn->state = TS_DISCONNECTED;\n\tconn->awaiting_packet_size = 0;\n\tif (conn->bev) {\n\t\tbufferevent_free(conn->bev);\n\t\tconn->bev = NULL;\n\t}\n}\n\n/* Add new tcp client to the list of TCP clients in the TCP DNS server. */\nstatic struct client_tcp_connection*\nevdns_add_tcp_client(struct evdns_server_port *port, struct bufferevent *bev)\n{\n\tstruct client_tcp_connection *client;\n\tEVUTIL_ASSERT(port && bev);\n\tif (port->max_client_connections == port->client_connections_count)\n\t\tgoto error;\n\n\tclient = mm_calloc(1, sizeof(*client));\n\tif (!client)\n\t\tgoto error;\n\tinit_tcp_connection(&client->connection, bev);\n\tclient->port = port;\n\tLIST_INSERT_HEAD(&port->client_connections, client, next);\n\n\t++port->client_connections_count;\n\t/* we need to hold evdns_server_port as long as one connection at least stays alive */\n\t++port->refcnt;\n\treturn client;\nerror:\n\treturn NULL;\n}\n\n/* Remove tcp client and free all associated data from the TCP DNS server. */\nstatic int\nevdns_remove_tcp_client(struct evdns_server_port *port, struct client_tcp_connection *client)\n{\n\tif (!port || !client)\n\t\tgoto error;\n\n\tevdns_tcp_disconnect(&client->connection);\n\tLIST_REMOVE(client, next);\n\tmm_free(client);\n\t--port->client_connections_count;\n\t--port->refcnt;\n\treturn 0;\nerror:\n\treturn -1;\n}\n\n/* Remove all tcp clients and free all associated data from the TCP DNS server. */\nstatic void\nevdns_remove_all_tcp_clients(struct evdns_server_port *port)\n{\n\tstruct client_tcp_connection *client;\n\twhile ((client = LIST_FIRST(&port->client_connections))) {\n\t\tevdns_remove_tcp_client(port, client);\n\t}\n}\n\n/* Create new tcp connection structure for DNS client. */\nstatic struct tcp_connection *\nnew_tcp_connection(struct bufferevent *bev)\n{\n\tstruct tcp_connection *conn;\n\tif (!bev)\n\t\treturn NULL;\n\n\tconn = mm_calloc(1, sizeof(*conn));\n\tif (!conn)\n\t\treturn NULL;\n\tinit_tcp_connection(conn, bev);\n\treturn conn;\n}\n\n/* Disconnect and free all associated data for the tcp connection in DNS client. */\nstatic void\ndisconnect_and_free_connection(struct tcp_connection *conn)\n{\n\tif (!conn)\n\t\treturn;\n\tevdns_tcp_disconnect(conn);\n\tmm_free(conn);\n}\n\n/* This walks the list of inflight requests to find the */\n/* one with a matching transaction id. Returns NULL on */\n/* failure */\nstatic struct request *\nrequest_find_from_trans_id(struct evdns_base *base, u16 trans_id) {\n\tstruct request *req = REQ_HEAD(base, trans_id);\n\tstruct request *const started_at = req;\n\n\tASSERT_LOCKED(base);\n\n\tif (req) {\n\t\tdo {\n\t\t\tif (req->trans_id == trans_id) return req;\n\t\t\treq = req->next;\n\t\t} while (req != started_at);\n\t}\n\n\treturn NULL;\n}\n\n/* a libevent callback function which is called when a nameserver */\n/* has gone down and we want to test if it has came back to life yet */\nstatic void\nnameserver_prod_callback(evutil_socket_t fd, short events, void *arg) {\n\tstruct nameserver *const ns = (struct nameserver *) arg;\n\t(void)fd;\n\t(void)events;\n\n\tEVDNS_LOCK(ns->base);\n\tnameserver_send_probe(ns);\n\tEVDNS_UNLOCK(ns->base);\n}\n\n/* a libevent callback which is called when a nameserver probe (to see if */\n/* it has come back to life) times out. We increment the count of failed_times */\n/* and wait longer to send the next probe packet. */\nstatic void\nnameserver_probe_failed(struct nameserver *const ns) {\n\tstruct timeval timeout;\n\tint i;\n\n\tASSERT_LOCKED(ns->base);\n\t(void) evtimer_del(&ns->timeout_event);\n\tif (ns->state == 1) {\n\t\t/* This can happen if the nameserver acts in a way which makes us mark */\n\t\t/* it as bad and then starts sending good replies. */\n\t\treturn;\n\t}\n\n\tmemcpy(&timeout, &ns->base->global_nameserver_probe_initial_timeout,\n\t    sizeof(struct timeval));\n\tfor (i = ns->failed_times; i > 0 && timeout.tv_sec < ns->base->ns_max_probe_timeout; --i) {\n\t\ttimeout.tv_sec *= ns->base->ns_timeout_backoff_factor;\n\t\ttimeout.tv_usec *= ns->base->ns_timeout_backoff_factor;\n\t\tif (timeout.tv_usec > 1000000) {\n\t\t\ttimeout.tv_sec += timeout.tv_usec / 1000000;\n\t\t\ttimeout.tv_usec %= 1000000;\n\t\t}\n\t}\n\tif (timeout.tv_sec > ns->base->ns_max_probe_timeout) {\n\t\ttimeout.tv_sec = ns->base->ns_max_probe_timeout;\n\t\ttimeout.tv_usec = 0;\n\t}\n\n\tns->failed_times++;\n\n\tif (evtimer_add(&ns->timeout_event, &timeout) < 0) {\n\t\tchar addrbuf[128];\n\t\tlog(EVDNS_LOG_WARN,\n\t\t    \"Error from libevent when adding timer event for %s\",\n\t\t    evutil_format_sockaddr_port_(\n\t\t\t    (struct sockaddr *)&ns->address,\n\t\t\t    addrbuf, sizeof(addrbuf)));\n\t}\n}\n\nstatic void\nrequest_swap_ns(struct request *req, struct nameserver *ns) {\n\tif (ns && req->ns != ns) {\n\t\tEVUTIL_ASSERT(req->ns->requests_inflight > 0);\n\t\treq->ns->requests_inflight--;\n\t\tns->requests_inflight++;\n\n\t\treq->ns = ns;\n\t}\n}\n\n/* called when a nameserver has been deemed to have failed. For example, too */\n/* many packets have timed out etc */\nstatic void\nnameserver_failed(struct nameserver *const ns, const char *msg, int err) {\n\tstruct request *req, *started_at;\n\tstruct evdns_base *base = ns->base;\n\tint i;\n\tchar addrbuf[128];\n\n\tASSERT_LOCKED(base);\n\t/* if this nameserver has already been marked as failed */\n\t/* then don't do anything */\n\tif (!ns->state) return;\n\n\tlog(EVDNS_LOG_MSG, \"Nameserver %s has failed: %s\",\n\t    evutil_format_sockaddr_port_(\n\t\t    (struct sockaddr *)&ns->address,\n\t\t    addrbuf, sizeof(addrbuf)),\n\t    msg);\n\n\tbase->global_good_nameservers--;\n\tEVUTIL_ASSERT(base->global_good_nameservers >= 0);\n\tif (base->global_good_nameservers == 0) {\n\t\tlog(EVDNS_LOG_MSG, \"All nameservers have failed\");\n\t}\n\n\tns->state = 0;\n\tns->failed_times = 1;\n\n\tif (ns->connection) {\n\t\tdisconnect_and_free_connection(ns->connection);\n\t\tns->connection = NULL;\n\t} else if (err == ENOTCONN) {\n\t\t/* XXX: If recvfrom results in ENOTCONN, the socket remains readable\n\t\t * which triggers another recvfrom. The observed behavior is 100% CPU use.\n\t\t * This occurs on iOS (kqueue) after the process has been backgrounded\n\t\t * for a long time (~300 seconds) and then resumed.\n\t\t * All sockets, TCP and UDP, seem to get ENOTCONN and must be closed.\n\t\t * https://github.com/libevent/libevent/issues/265 */\n\t\tconst struct sockaddr *address = (const struct sockaddr *)&ns->address;\n\t\tevutil_closesocket(ns->socket);\n\t\tns->socket = evutil_socket_(address->sa_family,\n\t\t\tSOCK_DGRAM | EVUTIL_SOCK_NONBLOCK | EVUTIL_SOCK_CLOEXEC, 0);\n\n\t\tif (base->global_outgoing_addrlen &&\n\t\t\t!evutil_sockaddr_is_loopback_(address)) {\n\t\t\tif (bind(ns->socket,\n\t\t\t\t\t(struct sockaddr *)&base->global_outgoing_address,\n\t\t\t\t\tbase->global_outgoing_addrlen) < 0) {\n\t\t\t\tlog(EVDNS_LOG_WARN, \"Couldn't bind to outgoing address\");\n\t\t\t}\n\t\t}\n\n\t\tevent_del(&ns->event);\n\t\tevent_assign(&ns->event, ns->base->event_base, ns->socket,\n\t\t\tEV_READ | (ns->write_waiting ? EV_WRITE : 0) | EV_PERSIST,\n\t\t\tnameserver_ready_callback, ns);\n\t\tif (!base->disable_when_inactive && event_add(&ns->event, NULL) < 0) {\n\t\t\tlog(EVDNS_LOG_WARN, \"Couldn't add %s event\",\n\t\t\t\tns->write_waiting ? \"rw\": \"read\");\n\t\t}\n\t}\n\tif (evtimer_add(&ns->timeout_event,\n\t\t&base->global_nameserver_probe_initial_timeout) < 0) {\n\t\tlog(EVDNS_LOG_WARN,\n\t\t    \"Error from libevent when adding timer event for %s\",\n\t\t    evutil_format_sockaddr_port_(\n\t\t\t    (struct sockaddr *)&ns->address,\n\t\t\t    addrbuf, sizeof(addrbuf)));\n\t\t/* ???? Do more? */\n\t}\n\n\t/* walk the list of inflight requests to see if any can be reassigned to */\n\t/* a different server. Requests in the waiting queue don't have a */\n\t/* nameserver assigned yet */\n\n\t/* if we don't have *any* good nameservers then there's no point */\n\t/* trying to reassign requests to one */\n\tif (!base->global_good_nameservers) return;\n\n\tfor (i = 0; i < base->n_req_heads; ++i) {\n\t\treq = started_at = base->req_heads[i];\n\t\tif (req) {\n\t\t\tdo {\n\t\t\t\tif (req->tx_count == 0 && req->ns == ns) {\n\t\t\t\t\t/* still waiting to go out, can be moved */\n\t\t\t\t\t/* to another server */\n\t\t\t\t\trequest_swap_ns(req, nameserver_pick(base));\n\t\t\t\t}\n\t\t\t\treq = req->next;\n\t\t\t} while (req != started_at);\n\t\t}\n\t}\n}\n\nstatic void\nnameserver_up(struct nameserver *const ns)\n{\n\tchar addrbuf[128];\n\tASSERT_LOCKED(ns->base);\n\tif (ns->state) return;\n\tlog(EVDNS_LOG_MSG, \"Nameserver %s is back up\",\n\t    evutil_format_sockaddr_port_(\n\t\t    (struct sockaddr *)&ns->address,\n\t\t    addrbuf, sizeof(addrbuf)));\n\tevtimer_del(&ns->timeout_event);\n\tif (ns->probe_request) {\n\t\tevdns_cancel_request(ns->base, ns->probe_request);\n\t\tns->probe_request = NULL;\n\t}\n\tns->state = 1;\n\tns->failed_times = 0;\n\tns->timedout = 0;\n\tns->base->global_good_nameservers++;\n}\n\nstatic void\nrequest_trans_id_set(struct request *const req, const u16 trans_id) {\n\treq->trans_id = trans_id;\n\t*((u16 *) req->request) = htons(trans_id);\n}\n\n/* Called to remove a request from a list and dealloc it. */\n/* head is a pointer to the head of the list it should be */\n/* removed from or NULL if the request isn't in a list. */\n/* when free_handle is one, free the handle as well. */\nstatic void\nrequest_finished(struct request *const req, struct request **head, int free_handle) {\n\tstruct evdns_base *base = req->base;\n\tint was_inflight = (head != &base->req_waiting_head);\n\tEVDNS_LOCK(base);\n\tASSERT_VALID_REQUEST(req);\n\n\tif (head)\n\t\tevdns_request_remove(req, head);\n\n\tlog(EVDNS_LOG_DEBUG, \"Removing timeout for request %p\", (void *)req);\n\tif (was_inflight) {\n\t\tevtimer_del(&req->timeout_event);\n\t\tbase->global_requests_inflight--;\n\t\treq->ns->requests_inflight--;\n\t} else {\n\t\tbase->global_requests_waiting--;\n\t}\n\t/* it was initialized during request_new / evtimer_assign */\n\tevent_debug_unassign(&req->timeout_event);\n\n\tif (req->ns &&\n\t    req->ns->requests_inflight == 0 &&\n\t    req->base->disable_when_inactive) {\n\t\tevent_del(&req->ns->event);\n\t\tevtimer_del(&req->ns->timeout_event);\n\t}\n\n\tif (!req->request_appended) {\n\t\t/* need to free the request data on it's own */\n\t\tmm_free(req->request);\n\t} else {\n\t\t/* the request data is appended onto the header */\n\t\t/* so everything gets free()ed when we: */\n\t}\n\n\tif (req->handle) {\n\t\tEVUTIL_ASSERT(req->handle->current_req == req);\n\n\t\tif (free_handle) {\n\t\t\tsearch_request_finished(req->handle);\n\t\t\treq->handle->current_req = NULL;\n\t\t\tif (! req->handle->pending_cb) {\n\t\t\t\t/* If we're planning to run the callback,\n\t\t\t\t * don't free the handle until later. */\n\t\t\t\tmm_free(req->handle);\n\t\t\t}\n\t\t\treq->handle = NULL; /* If we have a bug, let's crash\n\t\t\t\t\t     * early */\n\t\t} else {\n\t\t\treq->handle->current_req = NULL;\n\t\t}\n\t}\n\n\tmm_free(req);\n\n\tevdns_requests_pump_waiting_queue(base);\n\tEVDNS_UNLOCK(base);\n}\n\n/* This is called when a server returns a funny error code. */\n/* We try the request again with another server. */\n/* */\n/* return: */\n/*   0 ok */\n/*   1 failed/reissue is pointless */\nstatic int\nrequest_reissue(struct request *req) {\n\tconst struct nameserver *const last_ns = req->ns;\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\t/* the last nameserver should have been marked as failing */\n\t/* by the caller of this function, therefore pick will try */\n\t/* not to return it */\n\trequest_swap_ns(req, nameserver_pick(req->base));\n\tif (req->ns == last_ns) {\n\t\t/* ... but pick did return it */\n\t\t/* not a lot of point in trying again with the */\n\t\t/* same server */\n\t\treturn 1;\n\t}\n\n\treq->reissue_count++;\n\treq->tx_count = 0;\n\treq->transmit_me = 1;\n\n\treturn 0;\n}\n\n/* this function looks for space on the inflight queue and promotes */\n/* requests from the waiting queue if it can. */\n/* */\n/* TODO: */\n/* add return code, see at nameserver_pick() and other functions. */\nstatic void\nevdns_requests_pump_waiting_queue(struct evdns_base *base) {\n\tASSERT_LOCKED(base);\n\twhile (base->global_requests_inflight < base->global_max_requests_inflight &&\n\t\t   base->global_requests_waiting) {\n\t\tstruct request *req;\n\n\t\tEVUTIL_ASSERT(base->req_waiting_head);\n\t\treq = base->req_waiting_head;\n\n\t\treq->ns = nameserver_pick(base);\n\t\tif (!req->ns)\n\t\t\treturn;\n\n\t\t/* move a request from the waiting queue to the inflight queue */\n\t\treq->ns->requests_inflight++;\n\n\t\tevdns_request_remove(req, &base->req_waiting_head);\n\n\t\tbase->global_requests_waiting--;\n\t\tbase->global_requests_inflight++;\n\n\t\trequest_trans_id_set(req, transaction_id_pick(base));\n\n\t\tevdns_request_insert(req, &REQ_HEAD(base, req->trans_id));\n\t\tevdns_request_transmit(req);\n\t\tevdns_transmit(base);\n\t}\n}\n\nstatic void\nreply_run_callback(struct event_callback *d, void *user_pointer)\n{\n\tstruct evdns_request *handle =\n\t    EVUTIL_UPCAST(d, struct evdns_request, deferred);\n\n\tswitch (handle->request_type) {\n\tcase TYPE_A:\n\t\tif (handle->have_reply) {\n\t\t\thandle->user_callback(DNS_ERR_NONE, DNS_IPv4_A,\n\t\t\t    handle->reply.rr_count, handle->ttl,\n\t\t\t    handle->reply.data.a,\n\t\t\t    user_pointer);\n\t\t\tif (handle->reply.cname)\n\t\t\t\thandle->user_callback(DNS_ERR_NONE, DNS_CNAME, 1,\n\t\t\t\t    handle->ttl, handle->reply.cname, user_pointer);\n\t\t} else\n\t\t\thandle->user_callback(handle->err, DNS_IPv4_A, 0, handle->ttl, NULL, user_pointer);\n\t\tbreak;\n\tcase TYPE_PTR:\n\t\tif (handle->have_reply) {\n\t\t\tchar *name = handle->reply.data.ptr_name;\n\t\t\thandle->user_callback(DNS_ERR_NONE, DNS_PTR, 1, handle->ttl,\n\t\t\t    &name, user_pointer);\n\t\t} else {\n\t\t\thandle->user_callback(handle->err, DNS_PTR, 0, handle->ttl, NULL, user_pointer);\n\t\t}\n\t\tbreak;\n\tcase TYPE_AAAA:\n\t\tif (handle->have_reply) {\n\t\t\thandle->user_callback(DNS_ERR_NONE, DNS_IPv6_AAAA,\n\t\t\t    handle->reply.rr_count, handle->ttl,\n\t\t\t    handle->reply.data.aaaa,\n\t\t\t    user_pointer);\n\t\t\tif (handle->reply.cname)\n\t\t\t\thandle->user_callback(DNS_ERR_NONE, DNS_CNAME, 1,\n\t\t\t\t    handle->ttl, handle->reply.cname, user_pointer);\n\t\t} else\n\t\t\thandle->user_callback(handle->err, DNS_IPv6_AAAA, 0, handle->ttl, NULL, user_pointer);\n\t\tbreak;\n\tdefault:\n\t\tEVUTIL_ASSERT(0);\n\t}\n\n\tif (handle->reply.data.raw) {\n\t\tmm_free(handle->reply.data.raw);\n\t}\n\n\tif (handle->reply.cname) {\n\t\tmm_free(handle->reply.cname);\n\t}\n\n\tmm_free(handle);\n}\n\nstatic void\nreply_schedule_callback(struct request *const req, u32 ttl, u32 err, struct reply *reply)\n{\n\tstruct evdns_request* handle = req->handle;\n\n\tASSERT_LOCKED(req->base);\n\n\thandle->request_type = req->request_type;\n\thandle->ttl = ttl;\n\thandle->err = err;\n\tif (reply) {\n\t\thandle->have_reply = 1;\n\t\tmemcpy(&handle->reply, reply, sizeof(struct reply));\n\t\t/* We've taken ownership of the data. */\n\t\treply->data.raw = NULL;\n\t}\n\n\thandle->pending_cb = 1;\n\n\tevent_deferred_cb_init_(\n\t    &handle->deferred,\n\t    event_get_priority(&req->timeout_event),\n\t    reply_run_callback,\n\t    handle->user_pointer);\n\tevent_deferred_cb_schedule_(\n\t\treq->base->event_base,\n\t\t&handle->deferred);\n}\n\nstatic int\nclient_retransmit_through_tcp(struct evdns_request *handle)\n{\n\tstruct request *req = handle->current_req;\n\tstruct evdns_base *base = req->base;\n\tstruct request *newreq = request_clone(base, req);\n\tASSERT_LOCKED(base);\n\tif (!newreq)\n\t\treturn 1;\n\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 0);\n\thandle->current_req = newreq;\n\tnewreq->handle = handle;\n\trequest_submit(newreq);\n\treturn 0;\n}\n\n#define _QR_MASK    0x8000U\n#define _OP_MASK    0x7800U\n#define _AA_MASK    0x0400U\n#define _TC_MASK    0x0200U\n#define _RD_MASK    0x0100U\n#define _RA_MASK    0x0080U\n#define _Z_MASK     0x0040U\n#define _AD_MASK    0x0020U\n#define _CD_MASK    0x0010U\n#define _RCODE_MASK 0x000fU\n#define _Z_MASK_DEPRECATED 0x0070U\n\n/* this processes a parsed reply packet */\nstatic void\nreply_handle(struct request *const req, u16 flags, u32 ttl, struct reply *reply) {\n\tint error;\n\tchar addrbuf[128];\n\tint retransmit_via_tcp = 0;\n\tstatic const int error_codes[] = {\n\t\tDNS_ERR_FORMAT, DNS_ERR_SERVERFAILED, DNS_ERR_NOTEXIST,\n\t\tDNS_ERR_NOTIMPL, DNS_ERR_REFUSED\n\t};\n\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\n\tif (flags & (_RCODE_MASK | _TC_MASK) || !reply || !reply->have_answer) {\n\t\t/* there was an error */\n\t\tif (flags & _TC_MASK) {\n\t\t\terror = DNS_ERR_TRUNCATED;\n\t\t\tretransmit_via_tcp = (req->handle->tcp_flags & (DNS_QUERY_IGNTC | DNS_QUERY_USEVC)) == 0;\n\t\t} else if (flags & _RCODE_MASK) {\n\t\t\tu16 error_code = (flags & _RCODE_MASK) - 1;\n\t\t\tif (error_code > 4) {\n\t\t\t\terror = DNS_ERR_UNKNOWN;\n\t\t\t} else {\n\t\t\t\terror = error_codes[error_code];\n\t\t\t}\n\t\t} else if (reply && !reply->have_answer) {\n\t\t\terror = DNS_ERR_NODATA;\n\t\t} else {\n\t\t\terror = DNS_ERR_UNKNOWN;\n\t\t}\n\n\t\tswitch (error) {\n\t\tcase DNS_ERR_NOTIMPL:\n\t\tcase DNS_ERR_REFUSED:\n\t\t\t/* we regard these errors as marking a bad nameserver */\n\t\t\tif (req->reissue_count < req->base->global_max_reissues) {\n\t\t\t\tchar msg[64];\n\t\t\t\tevutil_snprintf(msg, sizeof(msg), \"Bad response %d (%s)\",\n\t\t\t\t\t error, evdns_err_to_string(error));\n\t\t\t\tnameserver_failed(req->ns, msg, 0);\n\t\t\t\tif (!request_reissue(req)) return;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase DNS_ERR_SERVERFAILED:\n\t\t\t/* rcode 2 (servfailed) sometimes means \"we\n\t\t\t * are broken\" and sometimes (with some binds)\n\t\t\t * means \"that request was very confusing.\"\n\t\t\t * Treat this as a timeout, not a failure.\n\t\t\t */\n\t\t\tlog(EVDNS_LOG_DEBUG, \"Got a SERVERFAILED from nameserver\"\n\t\t\t\t\"at %s; will allow the request to time out.\",\n\t\t\t    evutil_format_sockaddr_port_(\n\t\t\t\t    (struct sockaddr *)&req->ns->address,\n\t\t\t\t    addrbuf, sizeof(addrbuf)));\n\t\t\t/* Call the timeout function */\n\t\t\tevdns_request_timeout_callback(0, 0, req);\n\t\t\treturn;\n\t\tdefault:\n\t\t\t/* we got a good reply from the nameserver: it is up. */\n\t\t\tif (req->handle == req->ns->probe_request) {\n\t\t\t\t/* Avoid double-free */\n\t\t\t\treq->ns->probe_request = NULL;\n\t\t\t}\n\n\t\t\tnameserver_up(req->ns);\n\t\t}\n\n\t\tif (retransmit_via_tcp) {\n\t\t\tlog(EVDNS_LOG_DEBUG, \"Received truncated reply(flags 0x%x, transac ID: %d). Retransmitting via TCP.\",\n\t\t\t\treq->handle->tcp_flags, req->trans_id);\n\t\t\treq->handle->tcp_flags |= DNS_QUERY_USEVC;\n\t\t\tclient_retransmit_through_tcp(req->handle);\n\t\t\treturn;\n\t\t}\n\n\t\tif (req->handle->search_state &&\n\t\t    req->request_type != TYPE_PTR) {\n\t\t\t/* if we have a list of domains to search in,\n\t\t\t * try the next one */\n\t\t\tif (!search_try_next(req->handle)) {\n\t\t\t\t/* a new request was issued so this\n\t\t\t\t * request is finished and */\n\t\t\t\t/* the user callback will be made when\n\t\t\t\t * that request (or a */\n\t\t\t\t/* child of it) finishes. */\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\t/* all else failed. Pass the failure up */\n\t\treply_schedule_callback(req, ttl, error, NULL);\n\t\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 1);\n\t} else {\n\t\t/* all ok, tell the user */\n\t\treply_schedule_callback(req, ttl, 0, reply);\n\t\tif (req->handle == req->ns->probe_request)\n\t\t\treq->ns->probe_request = NULL; /* Avoid double-free */\n\t\tnameserver_up(req->ns);\n\t\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 1);\n\t}\n}\n\nstatic int\nname_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tif (j + label_len > length) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}\n\n/* parses a raw request from a nameserver */\nstatic int\nreply_parse(struct evdns_base *base, u8 *packet, int length)\n{\n\tint j = 0, k = 0;  /* index into packet */\n\tu16 t_;\t /* used by the macros */\n\tu32 t32_;  /* used by the macros */\n\tchar tmp_name[256], cmp_name[256]; /* used by the macros */\n\tint name_matches = 0;\n\n\tu16 trans_id, questions, answers, authority, additional, datalength;\n\tu16 flags = 0;\n\tu32 ttl, ttl_r = 0xffffffff;\n\tstruct reply reply;\n\tstruct request *req = NULL;\n\tunsigned int i, buf_size;\n\n\tmemset(&reply, 0, sizeof(reply));\n\n\tASSERT_LOCKED(base);\n\n\tGET16(trans_id);\n\tGET16(flags);\n\tGET16(questions);\n\tGET16(answers);\n\tGET16(authority);\n\tGET16(additional);\n\t(void) authority; /* suppress \"unused variable\" warnings. */\n\t(void) additional; /* suppress \"unused variable\" warnings. */\n\n\treq = request_find_from_trans_id(base, trans_id);\n\tif (!req) return -1;\n\tEVUTIL_ASSERT(req->base == base);\n\n\t/* If it's not an answer, it doesn't correspond to any request. */\n\tif (!(flags & _QR_MASK)) return -1;  /* must be an answer */\n\tif ((flags & (_RCODE_MASK|_TC_MASK)) && (flags & (_RCODE_MASK|_TC_MASK)) != DNS_ERR_NOTEXIST) {\n\t\t/* there was an error and it's not NXDOMAIN */\n\t\tgoto err;\n\t}\n\t/* if (!answers) return; */  /* must have an answer of some form */\n\n\t/* This macro skips a name in the DNS reply. */\n#define SKIP_NAME\t\t\t\t\t\t\\\n\tdo { tmp_name[0] = '\\0';\t\t\t\t\\\n\t\tif (name_parse(packet, length, &j, tmp_name,\t\\\n\t\t\tsizeof(tmp_name))<0)\t\t\t\\\n\t\t\tgoto err;\t\t\t\t\\\n\t} while (0)\n\n\treply.type = req->request_type;\n\n\t/* skip over each question in the reply */\n\tfor (i = 0; i < questions; ++i) {\n\t\t/* the question looks like\n\t\t *   <label:name><u16:type><u16:class>\n\t\t */\n\t\ttmp_name[0] = '\\0';\n\t\tcmp_name[0] = '\\0';\n\t\tk = j;\n\t\tif (name_parse(packet, length, &j, tmp_name, sizeof(tmp_name)) < 0)\n\t\t\tgoto err;\n\t\tif (name_parse(req->request, req->request_len, &k,\n\t\t\tcmp_name, sizeof(cmp_name))<0)\n\t\t\tgoto err;\n\t\tif (!base->global_randomize_case) {\n\t\t\tif (strcmp(tmp_name, cmp_name) == 0)\n\t\t\t\tname_matches = 1;\n\t\t} else {\n\t\t\tif (evutil_ascii_strcasecmp(tmp_name, cmp_name) == 0)\n\t\t\t\tname_matches = 1;\n\t\t}\n\n\t\tj += 4;\n\t\tif (j > length)\n\t\t\tgoto err;\n\t}\n\n\tif (!name_matches)\n\t\tgoto err;\n\n\t/* We can allocate less for the reply data, but to do it we'll have\n\t * to parse the response. To simplify things let's just allocate\n\t * a little bit more to avoid complex evaluations.\n\t */\n\tbuf_size = MAX(length - j, EVDNS_NAME_MAX);\n\treply.data.raw = mm_malloc(buf_size);\n\n\t/* now we have the answer section which looks like\n\t * <label:name><u16:type><u16:class><u32:ttl><u16:len><data...>\n\t */\n\n\tfor (i = 0; i < answers; ++i) {\n\t\tu16 type, class;\n\n\t\tSKIP_NAME;\n\t\tGET16(type);\n\t\tGET16(class);\n\t\tGET32(ttl);\n\t\tGET16(datalength);\n\n\t\tif (type == TYPE_A && class == CLASS_INET) {\n\t\t\tint addrcount;\n\t\t\tif (req->request_type != TYPE_A) {\n\t\t\t\tj += datalength; continue;\n\t\t\t}\n\t\t\tif ((datalength & 3) != 0) /* not an even number of As. */\n\t\t\t    goto err;\n\t\t\taddrcount = datalength >> 2;\n\n\t\t\tttl_r = MIN(ttl_r, ttl);\n\t\t\t/* we only bother with the first four addresses. */\n\t\t\tif (j + 4*addrcount > length) goto err;\n\t\t\tmemcpy(&reply.data.a[reply.rr_count],\n\t\t\t\t   packet + j, 4*addrcount);\n\t\t\tj += 4*addrcount;\n\t\t\treply.rr_count += addrcount;\n\t\t\treply.have_answer = 1;\n\t\t} else if (type == TYPE_PTR && class == CLASS_INET) {\n\t\t\tif (req->request_type != TYPE_PTR) {\n\t\t\t\tj += datalength; continue;\n\t\t\t}\n\t\t\tif (name_parse(packet, length, &j, reply.data.ptr_name,\n\t\t\t\t\t\t   buf_size)<0)\n\t\t\t\tgoto err;\n\t\t\tttl_r = MIN(ttl_r, ttl);\n\t\t\treply.have_answer = 1;\n\t\t\tbreak;\n\t\t} else if (type == TYPE_CNAME) {\n\t\t\tchar cname[EVDNS_NAME_MAX];\n\t\t\tif (name_parse(packet, length, &j, cname,\n\t\t\t\tsizeof(cname))<0)\n\t\t\t\tgoto err;\n\t\t\tif (req->need_cname)\n\t\t\t\treply.cname = mm_strdup(cname);\n\t\t\tif (req->put_cname_in_ptr && !*req->put_cname_in_ptr)\n\t\t\t\t*req->put_cname_in_ptr = mm_strdup(cname);\n\t\t} else if (type == TYPE_AAAA && class == CLASS_INET) {\n\t\t\tint addrcount;\n\t\t\tif (req->request_type != TYPE_AAAA) {\n\t\t\t\tj += datalength; continue;\n\t\t\t}\n\t\t\tif ((datalength & 15) != 0) /* not an even number of AAAAs. */\n\t\t\t\tgoto err;\n\t\t\taddrcount = datalength >> 4;  /* each address is 16 bytes long */\n\t\t\tttl_r = MIN(ttl_r, ttl);\n\n\t\t\t/* we only bother with the first four addresses. */\n\t\t\tif (j + 16*addrcount > length) goto err;\n\t\t\tmemcpy(&reply.data.aaaa[reply.rr_count],\n\t\t\t\t   packet + j, 16*addrcount);\n\t\t\treply.rr_count += addrcount;\n\t\t\tj += 16*addrcount;\n\t\t\treply.have_answer = 1;\n\t\t} else {\n\t\t\t/* skip over any other type of resource */\n\t\t\tj += datalength;\n\t\t}\n\t}\n\n\tif (!reply.have_answer) {\n\t\tfor (i = 0; i < authority; ++i) {\n\t\t\tu16 type, class;\n\t\t\tSKIP_NAME;\n\t\t\tGET16(type);\n\t\t\tGET16(class);\n\t\t\tGET32(ttl);\n\t\t\tGET16(datalength);\n\t\t\tif (type == TYPE_SOA && class == CLASS_INET) {\n\t\t\t\tu32 serial, refresh, retry, expire, minimum;\n\t\t\t\tSKIP_NAME;\n\t\t\t\tSKIP_NAME;\n\t\t\t\tGET32(serial);\n\t\t\t\tGET32(refresh);\n\t\t\t\tGET32(retry);\n\t\t\t\tGET32(expire);\n\t\t\t\tGET32(minimum);\n\t\t\t\t(void)expire;\n\t\t\t\t(void)retry;\n\t\t\t\t(void)refresh;\n\t\t\t\t(void)serial;\n\t\t\t\tttl_r = MIN(ttl_r, ttl);\n\t\t\t\tttl_r = MIN(ttl_r, minimum);\n\t\t\t} else {\n\t\t\t\t/* skip over any other type of resource */\n\t\t\t\tj += datalength;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ttl_r == 0xffffffff)\n\t\tttl_r = 0;\n\n\treply_handle(req, flags, ttl_r, &reply);\n\tif (reply.data.raw)\n\t\tmm_free(reply.data.raw);\n\treturn 0;\n err:\n\tif (req)\n\t\treply_handle(req, flags, 0, NULL);\n\tif (reply.data.raw)\n\t\tmm_free(reply.data.raw);\n\treturn -1;\n}\n\n/* Parse a raw request (packet,length) sent to a nameserver port (port) from */\n/* a DNS client (addr,addrlen), and if it's well-formed, call the corresponding */\n/* callback. */\nstatic int\nrequest_parse(u8 *packet, int length, struct evdns_server_port *port,\n\t\t\t\tstruct sockaddr *addr, ev_socklen_t addrlen, struct client_tcp_connection *client)\n{\n\tint j = 0;\t/* index into packet */\n\tu16 t_;\t /* used by the macros */\n\tu32 t32_;  /* used by the macros */\n\tchar tmp_name[256]; /* used by the macros */\n\n\tint i;\n\tu16 trans_id, flags, questions, answers, authority, additional;\n\tstruct server_request *server_req = NULL;\n\tu32 ttl;\n\tu16 type, class, rdlen;\n\n\tASSERT_LOCKED(port);\n\n\t/* Get the header fields */\n\tGET16(trans_id);\n\tGET16(flags);\n\tGET16(questions);\n\tGET16(answers);\n\tGET16(authority);\n\tGET16(additional);\n\n\tif (flags & _QR_MASK) return -1; /* Must not be an answer. */\n\tflags &= (_RD_MASK|_CD_MASK); /* Only RD and CD get preserved. */\n\n\tserver_req = mm_malloc(sizeof(struct server_request));\n\tif (server_req == NULL) return -1;\n\tmemset(server_req, 0, sizeof(struct server_request));\n\n\tserver_req->trans_id = trans_id;\n\tif (addr) {\n\t\tmemcpy(&server_req->addr, addr, addrlen);\n\t\tserver_req->addrlen = addrlen;\n\t}\n\n\tserver_req->port = port;\n\tserver_req->client = client;\n\tserver_req->base.flags = flags;\n\tserver_req->base.nquestions = 0;\n\tserver_req->base.questions = mm_calloc(sizeof(struct evdns_server_question *), questions);\n\tif (server_req->base.questions == NULL)\n\t\tgoto err;\n\n\tfor (i = 0; i < questions; ++i) {\n\t\tu16 type, class;\n\t\tstruct evdns_server_question *q;\n\t\tint namelen;\n\t\tif (name_parse(packet, length, &j, tmp_name, sizeof(tmp_name))<0)\n\t\t\tgoto err;\n\t\tGET16(type);\n\t\tGET16(class);\n\t\tnamelen = (int)strlen(tmp_name);\n\t\tq = mm_malloc(sizeof(struct evdns_server_question) + namelen);\n\t\tif (!q)\n\t\t\tgoto err;\n\t\tq->type = type;\n\t\tq->dns_question_class = class;\n\t\tmemcpy(q->name, tmp_name, namelen+1);\n\t\tserver_req->base.questions[server_req->base.nquestions++] = q;\n\t}\n\n#define SKIP_RR \\\n\tdo { \\\n\t\tSKIP_NAME; \\\n\t\tj += 2 /* type */ + 2 /* class */ + 4 /* ttl */; \\\n\t\tGET16(rdlen); \\\n\t\tj += rdlen; \\\n\t} while (0)\n\n\tfor (i = 0; i < answers; ++i) {\n\t\tSKIP_RR;\n\t}\n\n\tfor (i = 0; i < authority; ++i) {\n\t\tSKIP_RR;\n\t}\n\n\tserver_req->max_udp_reply_size = DNS_MAX_UDP_SIZE;\n\tfor (i = 0; i < additional; ++i) {\n\t\tSKIP_NAME;\n\t\tGET16(type);\n\t\tGET16(class);\n\t\tGET32(ttl);\n\t\tGET16(rdlen);\n\t\t(void)ttl;\n\t\tj += rdlen;\n\t\tif (type == TYPE_OPT) {\n\t\t\t/* In case of OPT pseudo-RR `class` field is treated\n\t\t\t * as a requestor's UDP payload size. */\n\t\t\tserver_req->max_udp_reply_size = MAX(class, DNS_MAX_UDP_SIZE);\n\t\t\tevdns_server_request_add_reply(&(server_req->base),\n\t\t\t\tEVDNS_ADDITIONAL_SECTION,\n\t\t\t\t\"\", /* name */\n\t\t\t\tTYPE_OPT, /* type */\n\t\t\t\tDNS_MAX_UDP_SIZE, /* class */\n\t\t\t\t0, /* ttl */\n\t\t\t\t0, /* datalen */\n\t\t\t\t0, /* is_name */\n\t\t\t\tNULL /* data */\n\t\t\t);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tport->refcnt++;\n\n\t/* Only standard queries are supported. */\n\tif (flags & _OP_MASK) {\n\t\tevdns_server_request_respond(&(server_req->base), DNS_ERR_NOTIMPL);\n\t\treturn -1;\n\t}\n\n\tport->user_callback(&(server_req->base), port->user_data);\n\n\treturn 0;\nerr:\n\tif (server_req) {\n\t\tif (server_req->base.questions) {\n\t\t\tfor (i = 0; i < server_req->base.nquestions; ++i)\n\t\t\t\tmm_free(server_req->base.questions[i]);\n\t\t\tmm_free(server_req->base.questions);\n\t\t}\n\t\tmm_free(server_req);\n\t}\n\treturn -1;\n\n#undef SKIP_RR\n#undef SKIP_NAME\n#undef GET32\n#undef GET16\n#undef GET8\n}\n\n/* Try to choose a strong transaction id which isn't already in flight */\nstatic u16\ntransaction_id_pick(struct evdns_base *base) {\n\tASSERT_LOCKED(base);\n\tfor (;;) {\n\t\tu16 trans_id;\n\t\tevutil_secure_rng_get_bytes(&trans_id, sizeof(trans_id));\n\n\t\tif (trans_id == 0xffff) continue;\n\t\t/* now check to see if that id is already inflight */\n\t\tif (request_find_from_trans_id(base, trans_id) == NULL)\n\t\t\treturn trans_id;\n\t}\n}\n\n/* choose a namesever to use. This function will try to ignore */\n/* nameservers which we think are down and load balance across the rest */\n/* by updating the server_head global each time. */\nstatic struct nameserver *\nnameserver_pick(struct evdns_base *base) {\n\tstruct nameserver *started_at = base->server_head, *picked;\n\tASSERT_LOCKED(base);\n\tif (!base->server_head) return NULL;\n\n\t/* if we don't have any good nameservers then there's no */\n\t/* point in trying to find one. */\n\tif (!base->global_good_nameservers) {\n\t\tbase->server_head = base->server_head->next;\n\t\treturn base->server_head;\n\t}\n\n\t/* remember that nameservers are in a circular list */\n\tfor (;;) {\n\t\tif (base->server_head->state) {\n\t\t\t/* we think this server is currently good */\n\t\t\tpicked = base->server_head;\n\t\t\tbase->server_head = base->server_head->next;\n\t\t\treturn picked;\n\t\t}\n\n\t\tbase->server_head = base->server_head->next;\n\t\tif (base->server_head == started_at) {\n\t\t\t/* all the nameservers seem to be down */\n\t\t\t/* so we just return this one and hope for the */\n\t\t\t/* best */\n\t\t\tEVUTIL_ASSERT(base->global_good_nameservers == 0);\n\t\t\tpicked = base->server_head;\n\t\t\tbase->server_head = base->server_head->next;\n\t\t\treturn picked;\n\t\t}\n\t}\n}\n\n/* this is called when a namesever socket is ready for reading */\nstatic void\nnameserver_read(struct nameserver *ns) {\n\tstruct sockaddr_storage ss;\n\tev_socklen_t addrlen = sizeof(ss);\n\tchar addrbuf[128];\n\tconst size_t max_packet_size = ns->base->global_max_udp_size;\n\tu8 *packet = mm_malloc(max_packet_size);\n\tASSERT_LOCKED(ns->base);\n\n\tif (!packet) {\n\t\tnameserver_failed(ns, \"not enough memory\", 0);\n\t\treturn;\n\t}\n\n\tfor (;;) {\n\t\tconst int r = recvfrom(ns->socket, (void*)packet,\n\t\t    max_packet_size, 0,\n\t\t    (struct sockaddr*)&ss, &addrlen);\n\t\tif (r < 0) {\n\t\t\tint err = evutil_socket_geterror(ns->socket);\n\t\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\t\tgoto done;\n\t\t\tnameserver_failed(ns,\n\t\t\t    evutil_socket_error_to_string(err), err);\n\t\t\tgoto done;\n\t\t}\n\t\tif (evutil_sockaddr_cmp((struct sockaddr*)&ss,\n\t\t\t(struct sockaddr*)&ns->address, 0)) {\n\t\t\tlog(EVDNS_LOG_WARN, \"Address mismatch on received \"\n\t\t\t    \"DNS packet.  Apparent source was %s\",\n\t\t\t    evutil_format_sockaddr_port_(\n\t\t\t\t    (struct sockaddr *)&ss,\n\t\t\t\t    addrbuf, sizeof(addrbuf)));\n\t\t\tgoto done;\n\t\t}\n\n\t\tns->timedout = 0;\n\t\treply_parse(ns->base, packet, r);\n\t}\ndone:\n\tmm_free(packet);\n}\n\n/* Read a packet from a DNS client on a server port s, parse it, and */\n/* act accordingly. */\nstatic void\nserver_udp_port_read(struct evdns_server_port *s) {\n\tu8 packet[1500];\n\tstruct sockaddr_storage addr;\n\tev_socklen_t addrlen;\n\tint r;\n\tASSERT_LOCKED(s);\n\n\tfor (;;) {\n\t\taddrlen = sizeof(struct sockaddr_storage);\n\t\tr = recvfrom(s->socket, (void*)packet, sizeof(packet), 0,\n\t\t\t\t\t (struct sockaddr*) &addr, &addrlen);\n\t\tif (r < 0) {\n\t\t\tint err = evutil_socket_geterror(s->socket);\n\t\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\t\treturn;\n\t\t\tlog(EVDNS_LOG_WARN,\n\t\t\t    \"Error %s (%d) while reading request.\",\n\t\t\t    evutil_socket_error_to_string(err), err);\n\t\t\treturn;\n\t\t}\n\t\trequest_parse(packet, r, s, (struct sockaddr*) &addr, addrlen, NULL);\n\t}\n}\n\nstatic int\nserver_send_response(struct evdns_server_port *port, struct server_request *req)\n{\n\tu16 packet_size = 0;\n\tstruct bufferevent *bev = NULL;\n\tif (req->client) {\n\t\tbev = req->client->connection.bev;\n\t\tEVUTIL_ASSERT(bev);\n\t\tEVUTIL_ASSERT(req->response_len <= 65535);\n\t\tpacket_size = htons((u16)req->response_len);\n\t\tif (bufferevent_write(bev, &packet_size, sizeof(packet_size)))\n\t\t\tgoto beferevent_error;\n\t\tif (bufferevent_write(bev, (void*)req->response, req->response_len))\n\t\t\tgoto beferevent_error;\n\t\treturn (int)req->response_len;\n\t} else {\n\t\tint r = sendto(port->socket, req->response, (int)req->response_len, 0,\n\t\t\t\t\t(struct sockaddr*) &req->addr, (ev_socklen_t)req->addrlen);\n\t\treturn r;\n\t}\n\nbeferevent_error:\n\tlog(EVDNS_LOG_WARN, \"Failed to send reply to request %p for client %p\", (void *)req, (void *)req->client);\n\t/* disconnect if we got bufferevent error */\n\tevdns_remove_tcp_client(port, req->client);\n\treturn -1;\n}\n\n/* Try to write all pending replies on a given DNS server port. */\nstatic void\nserver_port_flush(struct evdns_server_port *port)\n{\n\tstruct server_request *req = port->pending_replies;\n\tASSERT_LOCKED(port);\n\twhile (req) {\n\t\tint r = server_send_response(port, req);\n\t\tif (r < 0) {\n\t\t\tint err = evutil_socket_geterror(port->socket);\n\t\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\t\treturn;\n\t\t\tlog(EVDNS_LOG_WARN, \"Error %s (%d) while writing response to port; dropping\", evutil_socket_error_to_string(err), err);\n\t\t}\n\t\tif (server_request_free(req)) {\n\t\t\t/* we released the last reference to req->port. */\n\t\t\treturn;\n\t\t} else {\n\t\t\tEVUTIL_ASSERT(req != port->pending_replies);\n\t\t\treq = port->pending_replies;\n\t\t}\n\t}\n\n\t/* We have no more pending requests; stop listening for 'writeable' events. */\n\t(void) event_del(&port->event);\n\tevent_assign(&port->event, port->event_base,\n\t\t\t\t port->socket, EV_READ | EV_PERSIST,\n\t\t\t\t server_port_ready_callback, port);\n\n\tif (event_add(&port->event, NULL) < 0) {\n\t\tlog(EVDNS_LOG_WARN, \"Error from libevent when adding event for DNS server.\");\n\t\t/* ???? Do more? */\n\t}\n}\n\n/* set if we are waiting for the ability to write to this server. */\n/* if waiting is true then we ask libevent for EV_WRITE events, otherwise */\n/* we stop these events. */\nstatic void\nnameserver_write_waiting(struct nameserver *ns, char waiting) {\n\tASSERT_LOCKED(ns->base);\n\tif (ns->write_waiting == waiting) return;\n\n\tns->write_waiting = waiting;\n\t(void) event_del(&ns->event);\n\tevent_assign(&ns->event, ns->base->event_base,\n\t    ns->socket, EV_READ | (waiting ? EV_WRITE : 0) | EV_PERSIST,\n\t    nameserver_ready_callback, ns);\n\tif (event_add(&ns->event, NULL) < 0) {\n\t\tchar addrbuf[128];\n\t\tlog(EVDNS_LOG_WARN, \"Error from libevent when adding event for %s\",\n\t\t    evutil_format_sockaddr_port_(\n\t\t\t    (struct sockaddr *)&ns->address,\n\t\t\t    addrbuf, sizeof(addrbuf)));\n\t\t/* ???? Do more? */\n\t}\n}\n\n/* a callback function. Called by libevent when the kernel says that */\n/* a nameserver socket is ready for writing or reading */\nstatic void\nnameserver_ready_callback(evutil_socket_t fd, short events, void *arg) {\n\tstruct nameserver *ns = (struct nameserver *) arg;\n\t(void)fd;\n\n\tEVDNS_LOCK(ns->base);\n\tif (events & EV_WRITE) {\n\t\tns->choked = 0;\n\t\tif (!evdns_transmit(ns->base)) {\n\t\t\tnameserver_write_waiting(ns, 0);\n\t\t}\n\t}\n\tif (events & EV_READ) {\n\t\tnameserver_read(ns);\n\t}\n\tEVDNS_UNLOCK(ns->base);\n}\n\n/* a callback function. Called by libevent when the kernel says that */\n/* a server socket is ready for writing or reading. */\nstatic void\nserver_port_ready_callback(evutil_socket_t fd, short events, void *arg) {\n\tstruct evdns_server_port *port = (struct evdns_server_port *) arg;\n\t(void) fd;\n\n\tEVDNS_LOCK(port);\n\tif (events & EV_WRITE) {\n\t\tport->choked = 0;\n\t\tserver_port_flush(port);\n\t}\n\tif (events & EV_READ) {\n\t\tserver_udp_port_read(port);\n\t}\n\tEVDNS_UNLOCK(port);\n}\n\n/* This is an inefficient representation; only use it via the dnslabel_table_*\n * functions, so that is can be safely replaced with something smarter later. */\n#define MAX_LABELS 128\n/* Structures used to implement name compression */\nstruct dnslabel_entry { char *v; off_t pos; };\nstruct dnslabel_table {\n\tint n_labels; /* number of current entries */\n\t/* map from name to position in message */\n\tstruct dnslabel_entry labels[MAX_LABELS];\n};\n\n/* Initialize dnslabel_table. */\nstatic void\ndnslabel_table_init(struct dnslabel_table *table)\n{\n\ttable->n_labels = 0;\n}\n\n/* Free all storage held by table, but not the table itself. */\nstatic void\ndnslabel_clear(struct dnslabel_table *table)\n{\n\tint i;\n\tfor (i = 0; i < table->n_labels; ++i)\n\t\tmm_free(table->labels[i].v);\n\ttable->n_labels = 0;\n}\n\n/* return the position of the label in the current message, or -1 if the label */\n/* hasn't been used yet. */\nstatic int\ndnslabel_table_get_pos(const struct dnslabel_table *table, const char *label)\n{\n\tint i;\n\tfor (i = 0; i < table->n_labels; ++i) {\n\t\tif (!strcmp(label, table->labels[i].v))\n\t\t\treturn table->labels[i].pos;\n\t}\n\treturn -1;\n}\n\n/* remember that we've used the label at position pos */\nstatic int\ndnslabel_table_add(struct dnslabel_table *table, const char *label, off_t pos)\n{\n\tchar *v;\n\tint p;\n\tif (table->n_labels == MAX_LABELS)\n\t\treturn (-1);\n\tv = mm_strdup(label);\n\tif (v == NULL)\n\t\treturn (-1);\n\tp = table->n_labels++;\n\ttable->labels[p].v = v;\n\ttable->labels[p].pos = pos;\n\n\treturn (0);\n}\n\n/* Converts a string to a length-prefixed set of DNS labels, starting */\n/* at buf[j]. name and buf must not overlap. name_len should be the length */\n/* of name.\t table is optional, and is used for compression. */\n/* */\n/* Input: abc.def */\n/* Output: <3>abc<3>def<0> */\n/* */\n/* Returns the first index after the encoded name, or negative on error. */\n/*\t -1\t label was > 63 bytes */\n/*\t -2\t name too long to fit in buffer. */\n/* */\nstatic off_t\ndnsname_to_labels(u8 *const buf, size_t buf_len, off_t j,\n\t\t\t\t  const char *name, const size_t name_len,\n\t\t\t\t  struct dnslabel_table *table) {\n\tconst char *end = name + name_len;\n\tint ref = 0;\n\tu16 t_;\n\n#define APPEND16(x) do {\t\t\t\t\t\t\\\n\t\tif (j + 2 > (off_t)buf_len)\t\t\t\t\\\n\t\t\tgoto overflow;\t\t\t\t\t\\\n\t\tt_ = htons(x);\t\t\t\t\t\t\\\n\t\tmemcpy(buf + j, &t_, 2);\t\t\t\t\\\n\t\tj += 2;\t\t\t\t\t\t\t\\\n\t} while (0)\n#define APPEND32(x) do {\t\t\t\t\t\t\\\n\t\tif (j + 4 > (off_t)buf_len)\t\t\t\t\\\n\t\t\tgoto overflow;\t\t\t\t\t\\\n\t\tt32_ = htonl(x);\t\t\t\t\t\\\n\t\tmemcpy(buf + j, &t32_, 4);\t\t\t\t\\\n\t\tj += 4;\t\t\t\t\t\t\t\\\n\t} while (0)\n\n\tif (name_len > 255) return -2;\n\n\tfor (;;) {\n\t\tconst char *const start = name;\n\t\tif (table && (ref = dnslabel_table_get_pos(table, name)) >= 0) {\n\t\t\tAPPEND16(ref | 0xc000);\n\t\t\treturn j;\n\t\t}\n\t\tname = strchr(name, '.');\n\t\tif (!name) {\n\t\t\tconst size_t label_len = end - start;\n\t\t\tif (label_len > 63) return -1;\n\t\t\tif ((size_t)(j+label_len+1) > buf_len) return -2;\n\t\t\tif (table) dnslabel_table_add(table, start, j);\n\t\t\tbuf[j++] = (ev_uint8_t)label_len;\n\n\t\t\tmemcpy(buf + j, start, label_len);\n\t\t\tj += (int) label_len;\n\t\t\tbreak;\n\t\t} else {\n\t\t\t/* append length of the label. */\n\t\t\tconst size_t label_len = name - start;\n\t\t\tif (label_len > 63) return -1;\n\t\t\tif ((size_t)(j+label_len+1) > buf_len) return -2;\n\t\t\tif (table) dnslabel_table_add(table, start, j);\n\t\t\tbuf[j++] = (ev_uint8_t)label_len;\n\n\t\t\tmemcpy(buf + j, start, label_len);\n\t\t\tj += (int) label_len;\n\t\t\t/* hop over the '.' */\n\t\t\tname++;\n\t\t}\n\t}\n\n\t/* the labels must be terminated by a 0. */\n\t/* It's possible that the name ended in a . */\n\t/* in which case the zero is already there */\n\tif (!j || buf[j-1]) buf[j++] = 0;\n\treturn j;\n overflow:\n\treturn (-2);\n}\n\n/* Finds the length of a dns request for a DNS name of the given */\n/* length. The actual request may be smaller than the value returned */\n/* here */\nstatic size_t\nevdns_request_len(const struct evdns_base *base, const size_t name_len)\n{\n\tint additional_section_len = 0;\n\tif (EDNS_ENABLED(base)) {\n\t\tadditional_section_len = 1 + /* length of domain name string, always 0 */\n\t\t\t2 + /* space for resource type */\n\t\t\t2 + /* space for UDP payload size */\n\t\t\t4 + /* space for extended RCODE flags */\n\t\t\t2;  /* space for length of RDATA, always 0 */\n\t}\n\treturn 96 + /* length of the DNS standard header */\n\t\tname_len + 2 +\n\t\t4 /* space for the resource type */ +\n\t\tadditional_section_len;\n}\n\n/* build a dns request packet into buf. buf should be at least as long */\n/* as evdns_request_len told you it should be. */\n/* */\n/* Returns the amount of space used. Negative on error. */\nstatic int\nevdns_request_data_build(const struct evdns_base *base,\n\tconst char *const name, const size_t name_len,\n\tconst u16 trans_id, const u16 type, const u16 class, u8 *const buf,\n\tsize_t buf_len)\n{\n\toff_t j = 0;  /* current offset into buf */\n\tu16 t_;\t /* used by the macros */\n\tu32 t32_;  /* used by the macros */\n\n\tAPPEND16(trans_id);\n\tAPPEND16(0x0100);  /* standard query, recusion needed */\n\tAPPEND16(1);  /* one question */\n\tAPPEND16(0);  /* no answers */\n\tAPPEND16(0);  /* no authority */\n\tAPPEND16(EDNS_ENABLED(base) ? 1 : 0); /* additional */\n\n\tj = dnsname_to_labels(buf, buf_len, j, name, name_len, NULL);\n\tif (j < 0) {\n\t\treturn (int)j;\n\t}\n\n\tAPPEND16(type);\n\tAPPEND16(class);\n\n\tif (EDNS_ENABLED(base)) {\n\t\t/* The OPT pseudo-RR format\n\t\t * (https://tools.ietf.org/html/rfc6891#section-6.1.2)\n\t\t * +------------+--------------+------------------------------+\n\t\t * | Field Name | Field Type   | Description                  |\n\t\t * +------------+--------------+------------------------------+\n\t\t * | NAME       | domain name  | MUST be 0 (root domain)      |\n\t\t * | TYPE       | u_int16_t    | OPT (41)                     |\n\t\t * | CLASS      | u_int16_t    | requestor's UDP payload size |\n\t\t * | TTL        | u_int32_t    | extended RCODE and flags     |\n\t\t * | RDLEN      | u_int16_t    | length of all RDATA          |\n\t\t * | RDATA      | octet stream | {attribute,value} pairs      |\n\t\t * +------------+--------------+------------------------------+ */\n\t\tbuf[j++] = 0;  /* NAME, always 0 */\n\t\tAPPEND16(TYPE_OPT);  /* OPT type */\n\t\tAPPEND16(base->global_max_udp_size);  /* max UDP payload size */\n\t\tAPPEND32(0);  /* No extended RCODE flags set */\n\t\tAPPEND16(0);  /* length of RDATA is 0 */\n\t}\n\n\treturn (int)j;\n overflow:\n\treturn (-1);\n}\n\n/* exported function */\nstruct evdns_server_port *\nevdns_add_server_port_with_base(struct event_base *base, evutil_socket_t socket, int flags, evdns_request_callback_fn_type cb, void *user_data)\n{\n\tstruct evdns_server_port *port;\n\tif (flags)\n\t\treturn NULL; /* flags not yet implemented */\n\tif (!(port = mm_malloc(sizeof(struct evdns_server_port))))\n\t\treturn NULL;\n\tmemset(port, 0, sizeof(struct evdns_server_port));\n\n\n\tport->socket = socket;\n\tport->refcnt = 1;\n\tport->choked = 0;\n\tport->closing = 0;\n\tport->user_callback = cb;\n\tport->user_data = user_data;\n\tport->pending_replies = NULL;\n\tport->event_base = base;\n\tport->max_client_connections = MAX_CLIENT_CONNECTIONS;\n\tport->tcp_idle_timeout.tv_sec = SERVER_IDLE_CONN_TIMEOUT;\n\tport->tcp_idle_timeout.tv_usec = 0;\n\tport->client_connections_count = 0;\n\tLIST_INIT(&port->client_connections);\n\tevent_assign(&port->event, port->event_base,\n\t\t\t\t port->socket, EV_READ | EV_PERSIST,\n\t\t\t\t server_port_ready_callback, port);\n\tif (event_add(&port->event, NULL) < 0) {\n\t\tmm_free(port);\n\t\treturn NULL;\n\t}\n\tEVTHREAD_ALLOC_LOCK(port->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\treturn port;\n}\n\n/* exported function */\nstruct evdns_server_port *\nevdns_add_server_port_with_listener(struct event_base *base, struct evconnlistener *listener, int flags, evdns_request_callback_fn_type cb, void *user_data)\n{\n\tstruct evdns_server_port *port;\n\tif (!listener)\n\t\treturn NULL;\n\tif (flags)\n\t\treturn NULL; /* flags not yet implemented */\n\n\tif (!(port = mm_calloc(1, sizeof(struct evdns_server_port))))\n\t\treturn NULL;\n\tport->socket = -1;\n\tport->refcnt = 1;\n\tport->choked = 0;\n\tport->closing = 0;\n\tport->user_callback = cb;\n\tport->user_data = user_data;\n\tport->pending_replies = NULL;\n\tport->event_base = base;\n\tport->max_client_connections = MAX_CLIENT_CONNECTIONS;\n\tport->client_connections_count = 0;\n\tLIST_INIT(&port->client_connections);\n\tport->listener = listener;\n\tevconnlistener_set_cb(port->listener, incoming_conn_cb, port);\n\n\tEVTHREAD_ALLOC_LOCK(port->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\treturn port;\n}\n\nstatic void\nserver_tcp_event_cb(struct bufferevent *bev, short events, void *ctx);\n\nstatic int\ntcp_read_message(struct tcp_connection *conn, u8 **msg, int *msg_len)\n{\n\tstruct bufferevent *bev = conn->bev;\n\tstruct evbuffer *input = bufferevent_get_input(bev);\n\tu8 *packet = NULL;\n\tint r = 0;\n\n\tEVUTIL_ASSERT(conn);\n\tEVUTIL_ASSERT(conn->state == TS_CONNECTED);\n\n\t/* reading new packet size */\n\tif (!conn->awaiting_packet_size) {\n\t\tif (evbuffer_get_length(input) < sizeof(ev_uint16_t))\n\t\t\tgoto awaiting_next;\n\n\t\tbufferevent_read(bev, (void*)&conn->awaiting_packet_size,\n\t\t\tsizeof(conn->awaiting_packet_size));\n\t\tconn->awaiting_packet_size = ntohs(conn->awaiting_packet_size);\n\t\tif (conn->awaiting_packet_size <= 0)\n\t\t\tgoto fail;\n\t}\n\n\t/* reading new packet content */\n\tif (evbuffer_get_length(input) < conn->awaiting_packet_size)\n\t\tgoto awaiting_next;\n\n\tpacket = mm_malloc(conn->awaiting_packet_size);\n\tif (!packet)\n\t\tgoto fail;\n\n\tr = (int)bufferevent_read(bev, (void*)packet, conn->awaiting_packet_size);\n\tif (r != conn->awaiting_packet_size) {\n\t\tmm_free(packet);\n\t\tpacket = NULL;\n\t\tgoto fail;\n\t}\n\n\t*msg = packet;\n\t*msg_len = r;\nawaiting_next:\n\treturn 0;\nfail:\n\treturn 1;\n}\n\nstatic void\nserver_tcp_read_packet_cb(struct bufferevent *bev, void *ctx)\n{\n\tu8 *msg = NULL;\n\tint msg_len = 0;\n\tint rc;\n\tstruct client_tcp_connection *client = (struct client_tcp_connection *)ctx;\n\tstruct evdns_server_port *port = client->port;\n\tstruct tcp_connection *conn = &client->connection;\n\tEVUTIL_ASSERT(port && bev);\n\tEVDNS_LOCK(port);\n\n\twhile (1) {\n\t\tif (tcp_read_message(conn, &msg, &msg_len)) {\n\t\t\tlog(EVDNS_LOG_MSG, \"Closing client connection %p due to error\", (void *)bev);\n\t\t\tevdns_remove_tcp_client(port, client);\n\t\t\trc = port->refcnt;\n\t\t\tEVDNS_UNLOCK(port);\n\t\t\tif (!rc)\n\t\t\t\tserver_port_free(port);\n\t\t\treturn;\n\t\t}\n\n\t\t/* Only part of the message was received. */\n\t\tif (!msg)\n\t\t\tbreak;\n\n\t\trequest_parse(msg, msg_len, port, NULL, 0, client);\n\t\tmm_free(msg);\n\t\tmsg = NULL;\n\t\tconn->awaiting_packet_size = 0;\n\t}\n\n\tbufferevent_setwatermark(bev, EV_READ,\n\t\t\tconn->awaiting_packet_size ? conn->awaiting_packet_size : sizeof(ev_uint16_t), 0);\n\tbufferevent_setcb(bev, server_tcp_read_packet_cb, NULL, server_tcp_event_cb, ctx);\n\tEVDNS_UNLOCK(port);\n}\n\nstatic void\nserver_tcp_event_cb(struct bufferevent *bev, short events, void *ctx)\n{\n\tstruct client_tcp_connection *client = (struct client_tcp_connection *)ctx;\n\tstruct evdns_server_port *port = client->port;\n\tint rc;\n\tEVUTIL_ASSERT(port && bev);\n\tEVDNS_LOCK(port);\n\tif (events & (BEV_EVENT_EOF | BEV_EVENT_ERROR | BEV_EVENT_TIMEOUT)) {\n\t\tlog(EVDNS_LOG_DEBUG, \"Closing connection %p\", (void *)bev);\n\t\tevdns_remove_tcp_client(port, client);\n\t}\n\trc = port->refcnt;\n\tEVDNS_UNLOCK(port);\n\tif (!rc)\n\t\tserver_port_free(port);\n}\n\nstatic void\nincoming_conn_cb(struct evconnlistener *listener, evutil_socket_t fd,\n\t\t\t\t  struct sockaddr *address, int socklen, void *arg)\n{\n\tstruct evdns_server_port *port = (struct evdns_server_port*)arg;\n\tstruct bufferevent *bev = bufferevent_socket_new(port->event_base, fd, BEV_OPT_CLOSE_ON_FREE);\n\tstruct client_tcp_connection *client = NULL;\n\tstruct tcp_connection *cd = NULL;\n\n\tif (!bev)\n\t\tgoto error;\n\tlog(EVDNS_LOG_DEBUG, \"New incoming client connection %p\", (void *)bev);\n\n\tbufferevent_set_timeouts(bev, &port->tcp_idle_timeout, &port->tcp_idle_timeout);\n\n\tclient = evdns_add_tcp_client(port, bev);\n\tif (!client)\n\t\tgoto error;\n\tcd = &client->connection;\n\n\tcd->state = TS_CONNECTED;\n\tbufferevent_setwatermark(bev, EV_READ, sizeof(ev_uint16_t), 0);\n\tbufferevent_setcb(bev, server_tcp_read_packet_cb, NULL, server_tcp_event_cb, (void *)client);\n\tbufferevent_enable(bev, EV_READ);\n\n\treturn;\nerror:\n\tif (bev)\n\t\tbufferevent_free(bev);\n\treturn;\n}\n\nstruct evdns_server_port *\nevdns_add_server_port(evutil_socket_t socket, int flags, evdns_request_callback_fn_type cb, void *user_data)\n{\n\treturn evdns_add_server_port_with_base(NULL, socket, flags, cb, user_data);\n}\n\n/* exported function */\nvoid\nevdns_close_server_port(struct evdns_server_port *port)\n{\n\tEVDNS_LOCK(port);\n\tevdns_remove_all_tcp_clients(port);\n\tif (--port->refcnt == 0) {\n\t\tEVDNS_UNLOCK(port);\n\t\tserver_port_free(port);\n\t} else {\n\t\tport->closing = 1;\n\t\tEVDNS_UNLOCK(port);\n\t}\n}\n\n/* exported function */\nint\nevdns_server_request_add_reply(struct evdns_server_request *req_, int section, const char *name, int type, int class, int ttl, int datalen, int is_name, const char *data)\n{\n\tstruct server_request *req = TO_SERVER_REQUEST(req_);\n\tstruct server_reply_item **itemp, *item;\n\tint *countp;\n\tint result = -1;\n\n\tEVDNS_LOCK(req->port);\n\tif (req->response) /* have we already answered? */\n\t\tgoto done;\n\n\tswitch (section) {\n\tcase EVDNS_ANSWER_SECTION:\n\t\titemp = &req->answer;\n\t\tcountp = &req->n_answer;\n\t\tbreak;\n\tcase EVDNS_AUTHORITY_SECTION:\n\t\titemp = &req->authority;\n\t\tcountp = &req->n_authority;\n\t\tbreak;\n\tcase EVDNS_ADDITIONAL_SECTION:\n\t\titemp = &req->additional;\n\t\tcountp = &req->n_additional;\n\t\tbreak;\n\tdefault:\n\t\tgoto done;\n\t}\n\twhile (*itemp) {\n\t\titemp = &((*itemp)->next);\n\t}\n\titem = mm_malloc(sizeof(struct server_reply_item));\n\tif (!item)\n\t\tgoto done;\n\titem->next = NULL;\n\tif (!(item->name = mm_strdup(name))) {\n\t\tmm_free(item);\n\t\tgoto done;\n\t}\n\titem->type = type;\n\titem->dns_question_class = class;\n\titem->ttl = ttl;\n\titem->is_name = is_name != 0;\n\titem->datalen = 0;\n\titem->data = NULL;\n\tif (data) {\n\t\tif (item->is_name) {\n\t\t\tif (!(item->data = mm_strdup(data))) {\n\t\t\t\tmm_free(item->name);\n\t\t\t\tmm_free(item);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\titem->datalen = (u16)-1;\n\t\t} else {\n\t\t\tif (!(item->data = mm_malloc(datalen))) {\n\t\t\t\tmm_free(item->name);\n\t\t\t\tmm_free(item);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\titem->datalen = datalen;\n\t\t\tmemcpy(item->data, data, datalen);\n\t\t}\n\t}\n\n\t*itemp = item;\n\t++(*countp);\n\tresult = 0;\ndone:\n\tEVDNS_UNLOCK(req->port);\n\treturn result;\n}\n\n/* exported function */\nint\nevdns_server_request_add_a_reply(struct evdns_server_request *req, const char *name, int n, const void *addrs, int ttl)\n{\n\treturn evdns_server_request_add_reply(\n\t\t  req, EVDNS_ANSWER_SECTION, name, TYPE_A, CLASS_INET,\n\t\t  ttl, n*4, 0, addrs);\n}\n\n/* exported function */\nint\nevdns_server_request_add_aaaa_reply(struct evdns_server_request *req, const char *name, int n, const void *addrs, int ttl)\n{\n\treturn evdns_server_request_add_reply(\n\t\t  req, EVDNS_ANSWER_SECTION, name, TYPE_AAAA, CLASS_INET,\n\t\t  ttl, n*16, 0, addrs);\n}\n\n/* exported function */\nint\nevdns_server_request_add_ptr_reply(struct evdns_server_request *req, struct in_addr *in, const char *inaddr_name, const char *hostname, int ttl)\n{\n\tu32 a;\n\tchar buf[32];\n\tif (in && inaddr_name)\n\t\treturn -1;\n\telse if (!in && !inaddr_name)\n\t\treturn -1;\n\tif (in) {\n\t\ta = ntohl(in->s_addr);\n\t\tevutil_snprintf(buf, sizeof(buf), \"%d.%d.%d.%d.in-addr.arpa\",\n\t\t\t\t(int)(u8)((a\t)&0xff),\n\t\t\t\t(int)(u8)((a>>8 )&0xff),\n\t\t\t\t(int)(u8)((a>>16)&0xff),\n\t\t\t\t(int)(u8)((a>>24)&0xff));\n\t\tinaddr_name = buf;\n\t}\n\treturn evdns_server_request_add_reply(\n\t\t  req, EVDNS_ANSWER_SECTION, inaddr_name, TYPE_PTR, CLASS_INET,\n\t\t  ttl, -1, 1, hostname);\n}\n\n/* exported function */\nint\nevdns_server_request_add_cname_reply(struct evdns_server_request *req, const char *name, const char *cname, int ttl)\n{\n\treturn evdns_server_request_add_reply(\n\t\t  req, EVDNS_ANSWER_SECTION, name, TYPE_CNAME, CLASS_INET,\n\t\t  ttl, -1, 1, cname);\n}\n\n/* exported function */\nvoid\nevdns_server_request_set_flags(struct evdns_server_request *exreq, int flags)\n{\n\tstruct server_request *req = TO_SERVER_REQUEST(exreq);\n\treq->base.flags &= ~(EVDNS_FLAGS_AA|EVDNS_FLAGS_RD);\n\treq->base.flags |= flags;\n}\n\nstatic int\nevdns_server_request_format_response(struct server_request *req, int err)\n{\n\tunsigned char buf[1024 * 64];\n\tsize_t buf_len = sizeof(buf);\n\toff_t j = 0, r;\n\tu16 t_;\n\tu32 t32_;\n\tint i;\n\tu16 flags;\n\tstruct dnslabel_table table;\n\n\tif (err < 0 || err > 15) return -1;\n\n\t/* Set response bit and error code; copy OPCODE and RD fields from\n\t * question; copy RA and AA if set by caller. */\n\tflags = req->base.flags;\n\tflags |= (_QR_MASK | err);\n\n\tdnslabel_table_init(&table);\n\tAPPEND16(req->trans_id);\n\tAPPEND16(flags);\n\tAPPEND16(req->base.nquestions);\n\tAPPEND16(req->n_answer);\n\tAPPEND16(req->n_authority);\n\tAPPEND16(req->n_additional);\n\n\t/* Add questions. */\n\tfor (i=0; i < req->base.nquestions; ++i) {\n\t\tconst char *s = req->base.questions[i]->name;\n\t\tj = dnsname_to_labels(buf, buf_len, j, s, strlen(s), &table);\n\t\tif (j < 0) {\n\t\t\tdnslabel_clear(&table);\n\t\t\treturn (int) j;\n\t\t}\n\t\tAPPEND16(req->base.questions[i]->type);\n\t\tAPPEND16(req->base.questions[i]->dns_question_class);\n\t}\n\n\t/* Add answer, authority, and additional sections. */\n\tfor (i=0; i<3; ++i) {\n\t\tstruct server_reply_item *item;\n\t\tif (i==0)\n\t\t\titem = req->answer;\n\t\telse if (i==1)\n\t\t\titem = req->authority;\n\t\telse\n\t\t\titem = req->additional;\n\t\twhile (item) {\n\t\t\tr = dnsname_to_labels(buf, buf_len, j, item->name, strlen(item->name), &table);\n\t\t\tif (r < 0)\n\t\t\t\tgoto overflow;\n\t\t\tj = r;\n\n\t\t\tAPPEND16(item->type);\n\t\t\tAPPEND16(item->dns_question_class);\n\t\t\tAPPEND32(item->ttl);\n\t\t\tif (item->is_name) {\n\t\t\t\toff_t len_idx = j, name_start;\n\t\t\t\tj += 2;\n\t\t\t\tname_start = j;\n\t\t\t\tr = dnsname_to_labels(buf, buf_len, j, item->data, strlen(item->data), &table);\n\t\t\t\tif (r < 0)\n\t\t\t\t\tgoto overflow;\n\t\t\t\tj = r;\n\t\t\t\tt_ = htons( (short) (j-name_start) );\n\t\t\t\tmemcpy(buf+len_idx, &t_, 2);\n\t\t\t} else {\n\t\t\t\tAPPEND16(item->datalen);\n\t\t\t\tif (j+item->datalen > (off_t)buf_len)\n\t\t\t\t\tgoto overflow;\n\t\t\t\tif (item->data) {\n\t\t\t\t\tmemcpy(buf+j, item->data, item->datalen);\n\t\t\t\t\tj += item->datalen;\n\t\t\t\t} else {\n\t\t\t\t\tEVUTIL_ASSERT(item->datalen == 0);\n\t\t\t\t}\n\t\t\t}\n\t\t\titem = item->next;\n\t\t}\n\t}\n\n\tif (j > req->max_udp_reply_size && !req->client) {\noverflow:\n\t\tj = req->max_udp_reply_size;\n\t\tbuf[2] |= 0x02; /* set the truncated bit. */\n\t}\n\n\treq->response_len = j;\n\n\tif (!(req->response = mm_malloc(req->response_len))) {\n\t\tserver_request_free_answers(req);\n\t\tdnslabel_clear(&table);\n\t\treturn (-1);\n\t}\n\tmemcpy(req->response, buf, req->response_len);\n\tserver_request_free_answers(req);\n\tdnslabel_clear(&table);\n\treturn (0);\n}\n\n/* exported function */\nint\nevdns_server_request_respond(struct evdns_server_request *req_, int err)\n{\n\tstruct server_request *req = TO_SERVER_REQUEST(req_);\n\tstruct evdns_server_port *port = req->port;\n\tint r = -1;\n\n\tEVDNS_LOCK(port);\n\tif (!req->response) {\n\t\tif ((r = evdns_server_request_format_response(req, err))<0)\n\t\t\tgoto done;\n\t}\n\n\tr = server_send_response(port, req);\n\tif (r < 0 && req->client) {\n\t\tint sock_err = evutil_socket_geterror(port->socket);\n\t\tif (EVUTIL_ERR_RW_RETRIABLE(sock_err))\n\t\t\tgoto done;\n\n\t\tif (port->pending_replies) {\n\t\t\treq->prev_pending = port->pending_replies->prev_pending;\n\t\t\treq->next_pending = port->pending_replies;\n\t\t\treq->prev_pending->next_pending =\n\t\t\t\treq->next_pending->prev_pending = req;\n\t\t} else {\n\t\t\treq->prev_pending = req->next_pending = req;\n\t\t\tport->pending_replies = req;\n\t\t\tport->choked = 1;\n\n\t\t\t(void) event_del(&port->event);\n\t\t\tevent_assign(&port->event, port->event_base, port->socket, (port->closing?0:EV_READ) | EV_WRITE | EV_PERSIST, server_port_ready_callback, port);\n\n\t\t\tif (event_add(&port->event, NULL) < 0) {\n\t\t\t\tlog(EVDNS_LOG_WARN, \"Error from libevent when adding event for DNS server\");\n\t\t\t}\n\n\t\t}\n\n\t\tr = 1;\n\t\tgoto done;\n\t}\n\tif (server_request_free(req)) {\n\t\tr = 0;\n\t\tgoto done;\n\t}\n\n\tif (port->pending_replies)\n\t\tserver_port_flush(port);\n\n\tr = 0;\ndone:\n\tEVDNS_UNLOCK(port);\n\treturn r;\n}\n\n/* Free all storage held by RRs in req. */\nstatic void\nserver_request_free_answers(struct server_request *req)\n{\n\tstruct server_reply_item *victim, *next, **list;\n\tint i;\n\tfor (i = 0; i < 3; ++i) {\n\t\tif (i==0)\n\t\t\tlist = &req->answer;\n\t\telse if (i==1)\n\t\t\tlist = &req->authority;\n\t\telse\n\t\t\tlist = &req->additional;\n\n\t\tvictim = *list;\n\t\twhile (victim) {\n\t\t\tnext = victim->next;\n\t\t\tmm_free(victim->name);\n\t\t\tvictim->name = NULL;\n\t\t\tif (victim->data) {\n\t\t\t\tmm_free(victim->data);\n\t\t\t\tvictim->data = NULL;\n\t\t\t}\n\t\t\tmm_free(victim);\n\t\t\tvictim = next;\n\t\t}\n\t\t*list = NULL;\n\t}\n}\n\n/* Free all storage held by req, and remove links to it. */\n/* return true iff we just wound up freeing the server_port. */\nstatic int\nserver_request_free(struct server_request *req)\n{\n\tint i, rc=1, lock=0;\n\tif (req->base.questions) {\n\t\tfor (i = 0; i < req->base.nquestions; ++i) {\n\t\t\tmm_free(req->base.questions[i]);\n\t\t\treq->base.questions[i] = NULL;\n\t\t}\n\t\tmm_free(req->base.questions);\n\t\treq->base.questions = NULL;\n\t}\n\n\tif (req->port) {\n\t\tEVDNS_LOCK(req->port);\n\t\tlock=1;\n\t\tif (req->port->pending_replies == req) {\n\t\t\tif (req->next_pending && req->next_pending != req)\n\t\t\t\treq->port->pending_replies = req->next_pending;\n\t\t\telse\n\t\t\t\treq->port->pending_replies = NULL;\n\t\t}\n\t\trc = --req->port->refcnt;\n\t}\n\n\tif (req->response) {\n\t\tmm_free(req->response);\n\t\treq->response = NULL;\n\t}\n\n\tserver_request_free_answers(req);\n\n\tif (req->next_pending && req->next_pending != req) {\n\t\treq->next_pending->prev_pending = req->prev_pending;\n\t\treq->prev_pending->next_pending = req->next_pending;\n\t}\n\n\tif (rc == 0) {\n\t\tEVDNS_UNLOCK(req->port); /* ????? nickm */\n\t\tserver_port_free(req->port);\n\t\tmm_free(req);\n\t\treturn (1);\n\t}\n\tif (lock)\n\t\tEVDNS_UNLOCK(req->port);\n\tmm_free(req);\n\treturn (0);\n}\n\n/* Free all storage held by an evdns_server_port.  Only called when  */\nstatic void\nserver_port_free(struct evdns_server_port *port)\n{\n\tEVUTIL_ASSERT(port);\n\tEVUTIL_ASSERT(!port->refcnt);\n\tEVUTIL_ASSERT(!port->pending_replies);\n\tif (port->socket > 0) {\n\t\tevutil_closesocket(port->socket);\n\t\tport->socket = -1;\n\t}\n\n\t/* if tcp server */\n\tif (port->listener) {\n\t\tevconnlistener_free(port->listener);\n\t} else {\n\t\t(void) event_del(&port->event);\n\t\tevent_debug_unassign(&port->event);\n\t}\n\n\tEVTHREAD_FREE_LOCK(port->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\tmm_free(port);\n}\n\n/* exported function */\nint\nevdns_server_request_drop(struct evdns_server_request *req_)\n{\n\tstruct server_request *req = TO_SERVER_REQUEST(req_);\n\tserver_request_free(req);\n\treturn 0;\n}\n\n/* exported function */\nint\nevdns_server_request_get_requesting_addr(struct evdns_server_request *req_, struct sockaddr *sa, int addr_len)\n{\n\tstruct server_request *req = TO_SERVER_REQUEST(req_);\n\tif (addr_len < (int)req->addrlen)\n\t\treturn -1;\n\tmemcpy(sa, &(req->addr), req->addrlen);\n\treturn req->addrlen;\n}\n\nstatic void\nretransmit_all_tcp_requests_for(struct nameserver *server)\n{\n\tint i = 0;\n\tfor (i = 0; i < server->base->n_req_heads; ++i) {\n\t\tstruct request *started_at = server->base->req_heads[i];\n\t\tstruct request *req = started_at;\n\t\tif (!req)\n\t\t\tcontinue;\n\n\t\tdo {\n\t\t\tif (req->ns == server && (req->handle->tcp_flags & DNS_QUERY_USEVC)) {\n\t\t\t\tif (req->tx_count >= req->base->global_max_retransmits) {\n\t\t\t\t\tlog(EVDNS_LOG_DEBUG, \"Giving up on request %p; tx_count==%d\",\n\t\t\t\t\t\t(void *)req, req->tx_count);\n\t\t\t\t\treply_schedule_callback(req, 0, DNS_ERR_TIMEOUT, NULL);\n\t\t\t\t\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 1);\n\t\t\t\t} else {\n\t\t\t\t\t(void) evtimer_del(&req->timeout_event);\n\t\t\t\t\tevdns_request_transmit(req);\n\t\t\t\t}\n\t\t\t}\n\t\t\treq = req->next;\n\t\t} while (req != started_at);\n\t}\n}\n\n/* this is a libevent callback function which is called when a request */\n/* has timed out. */\nstatic void\nevdns_request_timeout_callback(evutil_socket_t fd, short events, void *arg) {\n\tstruct request *const req = (struct request *) arg;\n\tstruct evdns_base *base = req->base;\n\n\t(void) fd;\n\t(void) events;\n\n\tlog(EVDNS_LOG_DEBUG, \"Request %p timed out\", arg);\n\tEVDNS_LOCK(base);\n\n\tif (req->tx_count >= req->base->global_max_retransmits) {\n\t\tstruct nameserver *ns = req->ns;\n\t\t/* this request has failed */\n\t\tlog(EVDNS_LOG_DEBUG, \"Giving up on request %p; tx_count==%d\",\n\t\t    arg, req->tx_count);\n\t\treply_schedule_callback(req, 0, DNS_ERR_TIMEOUT, NULL);\n\n\t\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 1);\n\t\tnameserver_failed(ns, \"request timed out.\", 0);\n\t} else {\n\t\t/* if request is using tcp connection, so tear connection */\n\t\tif (req->handle->tcp_flags & DNS_QUERY_USEVC) {\n\t\t\tdisconnect_and_free_connection(req->ns->connection);\n\t\t\treq->ns->connection = NULL;\n\n\t\t\t/* client can have the only connection to DNS server */\n\t\t\tretransmit_all_tcp_requests_for(req->ns);\n\t\t} else {\n\t\t\t/* retransmit it */\n\t\t\tlog(EVDNS_LOG_DEBUG, \"Retransmitting request %p; tx_count==%d by udp\", arg, req->tx_count);\n\t\t\t(void) evtimer_del(&req->timeout_event);\n\t\t\trequest_swap_ns(req, nameserver_pick(base));\n\t\t\tevdns_request_transmit(req);\n\n\t\t\treq->ns->timedout++;\n\t\t\tif (req->ns->timedout > req->base->global_max_nameserver_timeout) {\n\t\t\t\treq->ns->timedout = 0;\n\t\t\t\tnameserver_failed(req->ns, \"request timed out.\", 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tEVDNS_UNLOCK(base);\n}\n\n/* try to send a request to a given server. */\n/* */\n/* return: */\n/*   0 ok */\n/*   1 temporary failure */\n/*   2 other failure */\nstatic int\nevdns_request_transmit_to(struct request *req, struct nameserver *server) {\n\tint r;\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\n\tif (server->requests_inflight == 1 &&\n\t\treq->base->disable_when_inactive &&\n\t\tevent_add(&server->event, NULL) < 0) {\n\t\treturn 1;\n\t}\n\n\tr = sendto(server->socket, (void*)req->request, req->request_len, 0,\n\t    (struct sockaddr *)&server->address, server->addrlen);\n\tif (r < 0) {\n\t\tint err = evutil_socket_geterror(server->socket);\n\t\tif (EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\treturn 1;\n\t\tnameserver_failed(req->ns, evutil_socket_error_to_string(err), err);\n\t\treturn 2;\n\t} else if (r != (int)req->request_len) {\n\t\treturn 1;  /* short write */\n\t} else {\n\t\treturn 0;\n\t}\n}\n\n/* try to connect to a given server. */\n/* */\n/* return: */\n/*   0 ok */\n/*   1 temporary failure */\n/*   2 other failure */\nstatic int\nevdns_tcp_connect_if_disconnected(struct nameserver *server)\n{\n\tstruct tcp_connection *conn = server->connection;\n\tstruct timeval *timeout = &server->base->global_tcp_idle_timeout;\n\tif (conn && conn->state != TS_DISCONNECTED && conn->bev != NULL)\n\t\treturn 0;\n\n\tdisconnect_and_free_connection(conn);\n\tconn = new_tcp_connection(bufferevent_socket_new(server->base->event_base, -1, BEV_OPT_CLOSE_ON_FREE));\n\tif (!conn)\n\t\treturn 2;\n\tserver->connection = conn;\n\n\tif (bufferevent_set_timeouts(conn->bev, timeout, timeout))\n\t\treturn 1;\n\n\tEVUTIL_ASSERT(conn->state == TS_DISCONNECTED);\n\tif (bufferevent_socket_connect(conn->bev, (struct sockaddr *)&server->address, server->addrlen))\n\t\treturn 1;\n\n\tconn->state = TS_CONNECTING;\n\tlog(EVDNS_LOG_DEBUG, \"New tcp connection %p created\", (void *)conn);\n\treturn 0;\n}\n\nstatic void\nclient_tcp_event_cb(struct bufferevent *bev, short events, void *ctx);\n\n\nstatic void\nclient_tcp_read_packet_cb(struct bufferevent *bev, void *ctx)\n{\n\tu8 *msg = NULL;\n\tint msg_len = 0;\n\tstruct nameserver *server = (struct nameserver*)ctx;\n\tstruct tcp_connection *conn = server->connection;\n\tEVUTIL_ASSERT(server && bev);\n\tEVDNS_LOCK(server->base);\n\n\twhile (1) {\n\t\tif (tcp_read_message(conn, &msg, &msg_len)) {\n\t\t\tdisconnect_and_free_connection(server->connection);\n\t\t\tserver->connection = NULL;\n\t\t\tEVDNS_UNLOCK(server->base);\n\t\t\treturn;\n\t\t}\n\n\t\t/* Only part of the message was received. */\n\t\tif (!msg)\n\t\t\tbreak;\n\n\t\treply_parse(server->base, msg, msg_len);\n\t\tmm_free(msg);\n\t\tmsg = NULL;\n\t\tconn->awaiting_packet_size = 0;\n\t}\n\n\tbufferevent_setwatermark(bev, EV_READ,\n\t\tconn->awaiting_packet_size ? conn->awaiting_packet_size : sizeof(ev_uint16_t), 0);\n\tbufferevent_setcb(bev, client_tcp_read_packet_cb, NULL, client_tcp_event_cb, ctx);\n\tEVDNS_UNLOCK(server->base);\n}\n\nstatic void\nclient_tcp_event_cb(struct bufferevent *bev, short events, void *ctx) {\n\tstruct nameserver *server = (struct nameserver*)ctx;\n\tstruct tcp_connection *conn = server->connection;\n\tEVUTIL_ASSERT(server);\n\tEVDNS_LOCK(server->base);\n\tEVUTIL_ASSERT(conn && conn->bev == bev && bev);\n\n\tlog(EVDNS_LOG_DEBUG, \"Event %d on connection %p\", events, (void *)conn);\n\n\tif (events & (BEV_EVENT_TIMEOUT)) {\n\t\tdisconnect_and_free_connection(server->connection);\n\t\tserver->connection = NULL;\n\t} else if (events & (BEV_EVENT_EOF | BEV_EVENT_ERROR)) {\n\t\tdisconnect_and_free_connection(server->connection);\n\t\tserver->connection = NULL;\n\t} else if (events & BEV_EVENT_CONNECTED) {\n\t\tEVUTIL_ASSERT (conn->state == TS_CONNECTING);\n\t\tconn->state = TS_CONNECTED;\n\t\tevutil_make_socket_nonblocking(bufferevent_getfd(bev));\n\t\tbufferevent_setcb(bev, client_tcp_read_packet_cb, NULL, client_tcp_event_cb, server);\n\t\tbufferevent_setwatermark(bev, EV_READ, sizeof(ev_uint16_t), 0);\n\t}\n\tEVDNS_UNLOCK(server->base);\n}\n\n/* try to send a request to a given server. */\n/* */\n/* return: */\n/*   0 ok */\n/*   1 temporary failure */\n/*   2 other failure */\nstatic int\nevdns_request_transmit_through_tcp(struct request *req, struct nameserver *server) {\n\tuint16_t packet_size;\n\tstruct tcp_connection *conn = NULL;\n\tint r;\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\n\tif ((r = evdns_tcp_connect_if_disconnected(server)))\n\t\treturn r;\n\n\tconn = server->connection;\n\tbufferevent_setcb(conn->bev, client_tcp_read_packet_cb, NULL, client_tcp_event_cb, server);\n\n\tlog(EVDNS_LOG_DEBUG, \"Sending request %p via tcp connection %p\", (void *)req, (void *)conn);\n\tpacket_size = htons(req->request_len);\n\tif (bufferevent_write(conn->bev, &packet_size, sizeof(packet_size)) )\n\t\tgoto fail;\n\tif (bufferevent_write(conn->bev, (void*)req->request, req->request_len) )\n\t\tgoto fail;\n\tif (bufferevent_enable(conn->bev, EV_READ))\n\t\tgoto fail;\n\tif (evtimer_add(&req->timeout_event, &req->base->global_timeout) < 0)\n\t\tgoto fail;\n\n\treturn 0;\nfail:\n\tlog(EVDNS_LOG_WARN, \"Failed to send request %p via tcp connection %p\", (void *)req, (void *)conn);\n\tdisconnect_and_free_connection(server->connection);\n\tserver->connection = NULL;\n\treturn 2;\n}\n\n/* try to send a request, updating the fields of the request */\n/* as needed */\n/* */\n/* return: */\n/*   0 ok */\n/*   1 failed */\nstatic int\nevdns_request_transmit(struct request *req) {\n\tint retcode = 0, r;\n\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\t/* if we fail to send this packet then this flag marks it */\n\t/* for evdns_transmit */\n\treq->transmit_me = 1;\n\tEVUTIL_ASSERT(req->trans_id != 0xffff);\n\n\tif (!req->ns)\n\t{\n\t\t/* unable to transmit request if no nameservers */\n\t\treturn 1;\n\t}\n\n\tif (req->ns->choked) {\n\t\t/* don't bother trying to write to a socket */\n\t\t/* which we have had EAGAIN from */\n\t\treturn 1;\n\t}\n\n\tif (req->handle->tcp_flags & DNS_QUERY_USEVC) {\n\t\tr = evdns_request_transmit_through_tcp(req, req->ns);\n\t\t/*\n\t\tIf connection didn't initiated now, so report about temporary problems.\n\t\tWe don't mark name server as chocked so udp packets possibly have no\n\t\tproblems during transmit. Simply we will retry attempt later */\n\t\tif (r == 1) {\n\t\t\treturn r;\n\t\t}\n\t} else {\n\t\tr = evdns_request_transmit_to(req, req->ns);\n\t}\n\tswitch (r) {\n\tcase 1:\n\t\t/* temp failure */\n\t\treq->ns->choked = 1;\n\t\tnameserver_write_waiting(req->ns, 1);\n\t\treturn 1;\n\tcase 2:\n\t\t/* failed to transmit the request entirely. we can fallthrough since\n\t\t * we'll set a timeout, which will time out, and make us retransmit the\n\t\t * request anyway. */\n\t\tretcode = 1;\n\t\tEVUTIL_FALLTHROUGH;\n\tdefault:\n\t\t/* all ok */\n\t\tlog(EVDNS_LOG_DEBUG,\n\t\t    \"Setting timeout for request %p, sent to nameserver %p\", (void *)req, (void *)req->ns);\n\t\tif (evtimer_add(&req->timeout_event, &req->base->global_timeout) < 0) {\n\t\t\tlog(EVDNS_LOG_WARN,\n\t\t      \"Error from libevent when adding timer for request %p\",\n\t\t\t    (void *)req);\n\t\t\t/* ???? Do more? */\n\t\t}\n\t\treq->tx_count++;\n\t\treq->transmit_me = 0;\n\t\treturn retcode;\n\t}\n}\n\nstatic void\nnameserver_probe_callback(int result, char type, int count, int ttl, void *addresses, void *arg) {\n\tstruct nameserver *const ns = (struct nameserver *) arg;\n\t(void) type;\n\t(void) count;\n\t(void) ttl;\n\t(void) addresses;\n\n\tif (result == DNS_ERR_CANCEL) {\n\t\t/* We canceled this request because the nameserver came up\n\t\t * for some other reason.  Do not change our opinion about\n\t\t * the nameserver. */\n\t\treturn;\n\t}\n\n\tEVDNS_LOCK(ns->base);\n\tns->probe_request = NULL;\n\tif (result == DNS_ERR_NONE || result == DNS_ERR_NOTEXIST) {\n\t\t/* this is a good reply */\n\t\tnameserver_up(ns);\n\t} else {\n\t\tnameserver_probe_failed(ns);\n\t}\n\tEVDNS_UNLOCK(ns->base);\n}\n\nstatic void\nnameserver_send_probe(struct nameserver *const ns) {\n\tstruct evdns_request *handle;\n\tstruct request *req;\n\tchar addrbuf[128];\n\t/* here we need to send a probe to a given nameserver */\n\t/* in the hope that it is up now. */\n\n\tASSERT_LOCKED(ns->base);\n\tlog(EVDNS_LOG_DEBUG, \"Sending probe to %s\",\n\t    evutil_format_sockaddr_port_(\n\t\t    (struct sockaddr *)&ns->address,\n\t\t    addrbuf, sizeof(addrbuf)));\n\thandle = mm_calloc(1, sizeof(*handle));\n\tif (!handle) return;\n\thandle->user_callback = nameserver_probe_callback;\n\thandle->user_pointer = ns;\n\treq = request_new(ns->base, handle, TYPE_A, \"google.com\", DNS_QUERY_NO_SEARCH);\n\tif (!req) {\n\t\tmm_free(handle);\n\t\treturn;\n\t}\n\tns->probe_request = handle;\n\t/* we force this into the inflight queue no matter what */\n\trequest_trans_id_set(req, transaction_id_pick(ns->base));\n\treq->ns = ns;\n\trequest_submit(req);\n}\n\n/* returns: */\n/*   0 didn't try to transmit anything */\n/*   1 tried to transmit something */\nstatic int\nevdns_transmit(struct evdns_base *base) {\n\tchar did_try_to_transmit = 0;\n\tint i;\n\n\tASSERT_LOCKED(base);\n\tfor (i = 0; i < base->n_req_heads; ++i) {\n\t\tif (base->req_heads[i]) {\n\t\t\tstruct request *const started_at = base->req_heads[i], *req = started_at;\n\t\t\t/* first transmit all the requests which are currently waiting */\n\t\t\tdo {\n\t\t\t\tif (req->transmit_me) {\n\t\t\t\t\tdid_try_to_transmit = 1;\n\t\t\t\t\tevdns_request_transmit(req);\n\t\t\t\t}\n\n\t\t\t\treq = req->next;\n\t\t\t} while (req != started_at);\n\t\t}\n\t}\n\n\treturn did_try_to_transmit;\n}\n\n/* exported function */\nint\nevdns_base_count_nameservers(struct evdns_base *base)\n{\n\tconst struct nameserver *server;\n\tint n = 0;\n\n\tEVDNS_LOCK(base);\n\tserver = base->server_head;\n\tif (!server)\n\t\tgoto done;\n\tdo {\n\t\t++n;\n\t\tserver = server->next;\n\t} while (server != base->server_head);\ndone:\n\tEVDNS_UNLOCK(base);\n\treturn n;\n}\n\nint\nevdns_count_nameservers(void)\n{\n\treturn evdns_base_count_nameservers(current_base);\n}\n\n/* exported function */\nint\nevdns_base_clear_nameservers_and_suspend(struct evdns_base *base)\n{\n\tstruct nameserver *server, *started_at;\n\tint i;\n\n\tEVDNS_LOCK(base);\n\tserver = base->server_head;\n\tstarted_at = base->server_head;\n\tif (!server) {\n\t\tEVDNS_UNLOCK(base);\n\t\treturn 0;\n\t}\n\twhile (1) {\n\t\tstruct nameserver *next = server->next;\n\t\tdisconnect_and_free_connection(server->connection);\n\t\tserver->connection = NULL;\n\t\t(void) event_del(&server->event);\n\t\tif (evtimer_initialized(&server->timeout_event))\n\t\t\t(void) evtimer_del(&server->timeout_event);\n\t\tif (server->probe_request) {\n\t\t\tevdns_cancel_request(server->base, server->probe_request);\n\t\t\tserver->probe_request = NULL;\n\t\t}\n\t\tif (server->socket >= 0)\n\t\t\tevutil_closesocket(server->socket);\n\t\tmm_free(server);\n\t\tif (next == started_at)\n\t\t\tbreak;\n\t\tserver = next;\n\t}\n\tbase->server_head = NULL;\n\tbase->global_good_nameservers = 0;\n\n\tfor (i = 0; i < base->n_req_heads; ++i) {\n\t\tstruct request *req, *req_started_at;\n\t\treq = req_started_at = base->req_heads[i];\n\t\twhile (req) {\n\t\t\tstruct request *next = req->next;\n\t\t\treq->tx_count = req->reissue_count = 0;\n\t\t\treq->ns = NULL;\n\t\t\t/* ???? What to do about searches? */\n\t\t\t(void) evtimer_del(&req->timeout_event);\n\t\t\treq->trans_id = 0;\n\t\t\treq->transmit_me = 0;\n\n\t\t\tbase->global_requests_waiting++;\n\t\t\tevdns_request_insert(req, &base->req_waiting_head);\n\t\t\t/* We want to insert these suspended elements at the front of\n\t\t\t * the waiting queue, since they were pending before any of\n\t\t\t * the waiting entries were added.  This is a circular list,\n\t\t\t * so we can just shift the start back by one.*/\n\t\t\tbase->req_waiting_head = base->req_waiting_head->prev;\n\n\t\t\tif (next == req_started_at)\n\t\t\t\tbreak;\n\t\t\treq = next;\n\t\t}\n\t\tbase->req_heads[i] = NULL;\n\t}\n\n\tbase->global_requests_inflight = 0;\n\n\tEVDNS_UNLOCK(base);\n\treturn 0;\n}\n\nint\nevdns_clear_nameservers_and_suspend(void)\n{\n\treturn evdns_base_clear_nameservers_and_suspend(current_base);\n}\n\n\n/* exported function */\nint\nevdns_base_resume(struct evdns_base *base)\n{\n\tEVDNS_LOCK(base);\n\tevdns_requests_pump_waiting_queue(base);\n\tEVDNS_UNLOCK(base);\n\n\treturn 0;\n}\n\nint\nevdns_resume(void)\n{\n\treturn evdns_base_resume(current_base);\n}\n\nstatic int\nevdns_nameserver_add_impl_(struct evdns_base *base, const struct sockaddr *address, int addrlen) {\n\t/* first check to see if we already have this nameserver */\n\n\tconst struct nameserver *server = base->server_head, *const started_at = base->server_head;\n\tstruct nameserver *ns;\n\tint err = 0;\n\tchar addrbuf[128];\n\n\tASSERT_LOCKED(base);\n\tif (server) {\n\t\tdo {\n\t\t\tif (!evutil_sockaddr_cmp((struct sockaddr*)&server->address, address, 1)) return 3;\n\t\t\tserver = server->next;\n\t\t} while (server != started_at);\n\t}\n\tif (addrlen > (int)sizeof(ns->address)) {\n\t\tlog(EVDNS_LOG_DEBUG, \"Addrlen %d too long.\", (int)addrlen);\n\t\treturn 2;\n\t}\n\n\tns = (struct nameserver *) mm_malloc(sizeof(struct nameserver));\n\tif (!ns) return -1;\n\n\tmemset(ns, 0, sizeof(struct nameserver));\n\tns->base = base;\n\n\tevtimer_assign(&ns->timeout_event, ns->base->event_base, nameserver_prod_callback, ns);\n\n\tns->socket = evutil_socket_(address->sa_family,\n\t    SOCK_DGRAM|EVUTIL_SOCK_NONBLOCK|EVUTIL_SOCK_CLOEXEC, 0);\n\tif (ns->socket < 0) { err = 1; goto out1; }\n\n\tif (base->global_outgoing_addrlen &&\n\t    !evutil_sockaddr_is_loopback_(address)) {\n\t\tif (bind(ns->socket,\n\t\t\t(struct sockaddr*)&base->global_outgoing_address,\n\t\t\tbase->global_outgoing_addrlen) < 0) {\n\t\t\tlog(EVDNS_LOG_WARN,\"Couldn't bind to outgoing address\");\n\t\t\terr = 2;\n\t\t\tgoto out2;\n\t\t}\n\t}\n\n\tif (base->so_rcvbuf) {\n\t\tif (setsockopt(ns->socket, SOL_SOCKET, SO_RCVBUF,\n\t\t    (void *)&base->so_rcvbuf, sizeof(base->so_rcvbuf))) {\n\t\t\tlog(EVDNS_LOG_WARN, \"Couldn't set SO_RCVBUF to %i\", base->so_rcvbuf);\n\t\t\terr = -SO_RCVBUF;\n\t\t\tgoto out2;\n\t\t}\n\t}\n\tif (base->so_sndbuf) {\n\t\tif (setsockopt(ns->socket, SOL_SOCKET, SO_SNDBUF,\n\t\t    (void *)&base->so_sndbuf, sizeof(base->so_sndbuf))) {\n\t\t\tlog(EVDNS_LOG_WARN, \"Couldn't set SO_SNDBUF to %i\", base->so_sndbuf);\n\t\t\terr = -SO_SNDBUF;\n\t\t\tgoto out2;\n\t\t}\n\t}\n\n\tmemcpy(&ns->address, address, addrlen);\n\tns->addrlen = addrlen;\n\tns->state = 1;\n\tns->connection = NULL;\n\tevent_assign(&ns->event, ns->base->event_base, ns->socket,\n\t\t\t\t EV_READ | EV_PERSIST, nameserver_ready_callback, ns);\n\tif (!base->disable_when_inactive && event_add(&ns->event, NULL) < 0) {\n\t\terr = 2;\n\t\tgoto out2;\n\t}\n\n\tlog(EVDNS_LOG_DEBUG, \"Added nameserver %s as %p\",\n\t    evutil_format_sockaddr_port_(address, addrbuf, sizeof(addrbuf)), (void *)ns);\n\n\t/* insert this nameserver into the list of them */\n\tif (!base->server_head) {\n\t\tns->next = ns->prev = ns;\n\t\tbase->server_head = ns;\n\t} else {\n\t\tns->next = base->server_head->next;\n\t\tns->prev = base->server_head;\n\t\tbase->server_head->next = ns;\n\t\tns->next->prev = ns;\n\t}\n\n\tbase->global_good_nameservers++;\n\n\treturn 0;\n\nout2:\n\tevutil_closesocket(ns->socket);\nout1:\n\tevent_debug_unassign(&ns->event);\n\tmm_free(ns);\n\tlog(EVDNS_LOG_WARN, \"Unable to add nameserver %s: error %d\",\n\t    evutil_format_sockaddr_port_(address, addrbuf, sizeof(addrbuf)), err);\n\treturn err;\n}\n\n/* exported function */\nint\nevdns_base_nameserver_add(struct evdns_base *base, unsigned long int address)\n{\n\tstruct sockaddr_in sin;\n\tint res;\n\tmemset(&sin, 0, sizeof(sin));\n\tsin.sin_addr.s_addr = address;\n\tsin.sin_port = htons(53);\n\tsin.sin_family = AF_INET;\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN\n\tsin.sin_len = sizeof(sin);\n#endif\n\tEVDNS_LOCK(base);\n\tres = evdns_nameserver_add_impl_(base, (struct sockaddr*)&sin, sizeof(sin));\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\nint\nevdns_nameserver_add(unsigned long int address) {\n\tif (!current_base)\n\t\tcurrent_base = evdns_base_new(NULL, 0);\n\treturn evdns_base_nameserver_add(current_base, address);\n}\n\nstatic void\nsockaddr_setport(struct sockaddr *sa, ev_uint16_t port)\n{\n\tif (sa->sa_family == AF_INET) {\n\t\t((struct sockaddr_in *)sa)->sin_port = htons(port);\n\t} else if (sa->sa_family == AF_INET6) {\n\t\t((struct sockaddr_in6 *)sa)->sin6_port = htons(port);\n\t}\n}\n\nstatic ev_uint16_t\nsockaddr_getport(struct sockaddr *sa)\n{\n\tif (sa->sa_family == AF_INET) {\n\t\treturn ntohs(((struct sockaddr_in *)sa)->sin_port);\n\t} else if (sa->sa_family == AF_INET6) {\n\t\treturn ntohs(((struct sockaddr_in6 *)sa)->sin6_port);\n\t} else {\n\t\treturn 0;\n\t}\n}\n\n/* exported function */\nint\nevdns_base_nameserver_ip_add(struct evdns_base *base, const char *ip_as_string) {\n\tstruct sockaddr_storage ss;\n\tstruct sockaddr *sa;\n\tint len = sizeof(ss);\n\tint res;\n\tif (evutil_parse_sockaddr_port(ip_as_string, (struct sockaddr *)&ss,\n\t\t&len)) {\n\t\tlog(EVDNS_LOG_WARN, \"Unable to parse nameserver address %s\",\n\t\t\tip_as_string);\n\t\treturn 4;\n\t}\n\tsa = (struct sockaddr *) &ss;\n\tif (sockaddr_getport(sa) == 0)\n\t\tsockaddr_setport(sa, 53);\n\n\tEVDNS_LOCK(base);\n\tres = evdns_nameserver_add_impl_(base, sa, len);\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\nint\nevdns_nameserver_ip_add(const char *ip_as_string) {\n\tif (!current_base)\n\t\tcurrent_base = evdns_base_new(NULL, 0);\n\treturn evdns_base_nameserver_ip_add(current_base, ip_as_string);\n}\n\nint\nevdns_base_nameserver_sockaddr_add(struct evdns_base *base,\n    const struct sockaddr *sa, ev_socklen_t len, unsigned flags)\n{\n\tint res;\n\tEVUTIL_ASSERT(base);\n\tEVDNS_LOCK(base);\n\tres = evdns_nameserver_add_impl_(base, sa, len);\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\nint\nevdns_base_get_nameserver_addr(struct evdns_base *base, int idx,\n    struct sockaddr *sa, ev_socklen_t len)\n{\n\tint result = -1;\n\tint i;\n\tstruct nameserver *server;\n\tEVDNS_LOCK(base);\n\tserver = base->server_head;\n\tfor (i = 0; i < idx && server; ++i, server = server->next) {\n\t\tif (server->next == base->server_head)\n\t\t\tgoto done;\n\t}\n\tif (! server)\n\t\tgoto done;\n\n\tif (server->addrlen > len) {\n\t\tresult = (int) server->addrlen;\n\t\tgoto done;\n\t}\n\n\tmemcpy(sa, &server->address, server->addrlen);\n\tresult = (int) server->addrlen;\ndone:\n\tEVDNS_UNLOCK(base);\n\treturn result;\n}\n\nint\nevdns_base_get_nameserver_fd(struct evdns_base *base, int idx)\n{\n\tint result = -1;\n\tint i;\n\tstruct nameserver *server;\n\tEVDNS_LOCK(base);\n\tserver = base->server_head;\n\tfor (i = 0; i < idx && server; ++i, server = server->next) {\n\t\tif (server->next == base->server_head)\n\t\t\tgoto done;\n\t}\n\tif (! server)\n\t\tgoto done;\n\tresult = server->socket;\ndone:\n\tEVDNS_UNLOCK(base);\n\treturn result;\n}\n\n\n/* remove from the queue */\nstatic void\nevdns_request_remove(struct request *req, struct request **head)\n{\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\n#if 0\n\t{\n\t\tstruct request *ptr;\n\t\tint found = 0;\n\t\tEVUTIL_ASSERT(*head != NULL);\n\n\t\tptr = *head;\n\t\tdo {\n\t\t\tif (ptr == req) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tptr = ptr->next;\n\t\t} while (ptr != *head);\n\t\tEVUTIL_ASSERT(found);\n\n\t\tEVUTIL_ASSERT(req->next);\n\t}\n#endif\n\n\tif (req->next == req) {\n\t\t/* only item in the list */\n\t\t*head = NULL;\n\t} else {\n\t\treq->next->prev = req->prev;\n\t\treq->prev->next = req->next;\n\t\tif (*head == req) *head = req->next;\n\t}\n\treq->next = req->prev = NULL;\n}\n\n/* insert into the tail of the queue */\nstatic void\nevdns_request_insert(struct request *req, struct request **head) {\n\tASSERT_LOCKED(req->base);\n\tASSERT_VALID_REQUEST(req);\n\tif (!*head) {\n\t\t*head = req;\n\t\treq->next = req->prev = req;\n\t\treturn;\n\t}\n\n\treq->prev = (*head)->prev;\n\treq->prev->next = req;\n\treq->next = *head;\n\t(*head)->prev = req;\n}\n\nstatic int\nstring_num_dots(const char *s) {\n\tint count = 0;\n\twhile ((s = strchr(s, '.'))) {\n\t\ts++;\n\t\tcount++;\n\t}\n\treturn count;\n}\n\nstatic struct request *\nrequest_new(struct evdns_base *base, struct evdns_request *handle, int type,\n\t    const char *name, int flags) {\n\n\tconst char issuing_now =\n\t    (base->global_requests_inflight < base->global_max_requests_inflight) ? 1 : 0;\n\n\tconst size_t name_len = strlen(name);\n\tconst size_t request_max_len = evdns_request_len(base, name_len);\n\tconst u16 trans_id = issuing_now ? transaction_id_pick(base) : 0xffff;\n\t/* the request data is alloced in a single block with the header */\n\tstruct request *const req =\n\t    mm_malloc(sizeof(struct request) + request_max_len);\n\tint rlen;\n\tchar namebuf[256];\n\t(void) flags;\n\n\tASSERT_LOCKED(base);\n\n\tif (!req) return NULL;\n\n\tif (name_len >= sizeof(namebuf)) {\n\t\tmm_free(req);\n\t\treturn NULL;\n\t}\n\n\tmemset(req, 0, sizeof(struct request));\n\treq->request_size = (u16)(sizeof(struct request) + request_max_len);\n\treq->base = base;\n\n\tevtimer_assign(&req->timeout_event, req->base->event_base, evdns_request_timeout_callback, req);\n\n\tif (base->global_randomize_case) {\n\t\tunsigned i;\n\t\tchar randbits[(sizeof(namebuf)+7)/8];\n\t\tstrlcpy(namebuf, name, sizeof(namebuf));\n\t\tevutil_secure_rng_get_bytes(randbits, (name_len+7)/8);\n\t\tfor (i = 0; i < name_len; ++i) {\n\t\t\tif (EVUTIL_ISALPHA_(namebuf[i])) {\n\t\t\t\tif ((randbits[i >> 3] & (1<<(i & 7))))\n\t\t\t\t\tnamebuf[i] |= 0x20;\n\t\t\t\telse\n\t\t\t\t\tnamebuf[i] &= ~0x20;\n\t\t\t}\n\t\t}\n\t\tname = namebuf;\n\t}\n\n\t/* request data lives just after the header */\n\treq->request = ((u8 *) req) + sizeof(struct request);\n\t/* denotes that the request data shouldn't be free()ed */\n\treq->request_appended = 1;\n\trlen = evdns_request_data_build(base, name, name_len, trans_id,\n\t    type, CLASS_INET, req->request, request_max_len);\n\tif (rlen < 0)\n\t\tgoto err1;\n\n\treq->request_len = rlen;\n\treq->trans_id = trans_id;\n\treq->tx_count = 0;\n\treq->request_type = type;\n\treq->ns = issuing_now ? nameserver_pick(base) : NULL;\n\treq->next = req->prev = NULL;\n\treq->handle = handle;\n\tif (handle) {\n\t\thandle->current_req = req;\n\t\thandle->base = base;\n\t}\n\n\tif (flags & DNS_CNAME_CALLBACK)\n\t\treq->need_cname = 1;\n\n\treturn req;\nerr1:\n\tmm_free(req);\n\treturn NULL;\n}\n\nstatic struct request *\nrequest_clone(struct evdns_base *base, struct request* current)\n{\n\tconst char issuing_now =\n\t    (base->global_requests_inflight < base->global_max_requests_inflight) ? 1 : 0;\n\tconst u16 trans_id = issuing_now ? transaction_id_pick(base) : 0xffff;\n\t/* the request data is alloced in a single block with the header */\n\tstruct request *const req = mm_malloc(current->request_size);\n\tEVUTIL_ASSERT(current && base);\n\tASSERT_LOCKED(base);\n\n\tif (!req)\n\t\treturn NULL;\n\tmemcpy(req, current, current->request_size);\n\n\tevtimer_assign(&req->timeout_event, req->base->event_base, evdns_request_timeout_callback, req);\n\n\t/* request data lives just after the header */\n\treq->request = ((u8 *) req) + sizeof(struct request);\n\t/* We need to replace transact id */\n\trequest_trans_id_set(req, trans_id);\n\n\treq->tx_count = 0;\n\treq->ns = issuing_now ? nameserver_pick(base) : NULL;\n\treq->next = req->prev = NULL;\n\treq->handle = NULL;\n\tlog(EVDNS_LOG_DEBUG, \"Clone new request TID %d from TID %d\", req->trans_id, current->trans_id);\n\n\treturn req;\n}\n\nstatic void\nrequest_submit(struct request *const req) {\n\tstruct evdns_base *base = req->base;\n\tASSERT_LOCKED(base);\n\tASSERT_VALID_REQUEST(req);\n\tif (req->ns) {\n\t\t/* if it has a nameserver assigned then this is going */\n\t\t/* straight into the inflight queue */\n\t\tevdns_request_insert(req, &REQ_HEAD(base, req->trans_id));\n\n\t\tbase->global_requests_inflight++;\n\t\treq->ns->requests_inflight++;\n\n\t\tevdns_request_transmit(req);\n\t} else {\n\t\tevdns_request_insert(req, &base->req_waiting_head);\n\t\tbase->global_requests_waiting++;\n\t}\n}\n\n/* exported function */\nvoid\nevdns_cancel_request(struct evdns_base *base, struct evdns_request *handle)\n{\n\tstruct request *req;\n\n\tif (!handle->current_req)\n\t\treturn;\n\n\tif (!base) {\n\t\t/* This redundancy is silly; can we fix it? (Not for 2.0) XXXX */\n\t\tbase = handle->base;\n\t\tif (!base)\n\t\t\tbase = handle->current_req->base;\n\t}\n\n\tEVDNS_LOCK(base);\n\tif (handle->pending_cb) {\n\t\tEVDNS_UNLOCK(base);\n\t\treturn;\n\t}\n\n\treq = handle->current_req;\n\tASSERT_VALID_REQUEST(req);\n\n\treply_schedule_callback(req, 0, DNS_ERR_CANCEL, NULL);\n\tif (req->ns) {\n\t\t/* remove from inflight queue */\n\t\trequest_finished(req, &REQ_HEAD(base, req->trans_id), 1);\n\t} else {\n\t\t/* remove from global_waiting head */\n\t\trequest_finished(req, &base->req_waiting_head, 1);\n\t}\n\tEVDNS_UNLOCK(base);\n}\n\n/* exported function */\nstruct evdns_request *\nevdns_base_resolve_ipv4(struct evdns_base *base, const char *name, int flags,\n    evdns_callback_type callback, void *ptr) {\n\tstruct evdns_request *handle;\n\tstruct request *req;\n\tlog(EVDNS_LOG_DEBUG, \"Resolve requested for %s\", name);\n\thandle = mm_calloc(1, sizeof(*handle));\n\tif (handle == NULL)\n\t\treturn NULL;\n\thandle->user_callback = callback;\n\thandle->user_pointer = ptr;\n\tEVDNS_LOCK(base);\n\thandle->tcp_flags = base->global_tcp_flags;\n\thandle->tcp_flags |= flags & (DNS_QUERY_USEVC | DNS_QUERY_IGNTC);\n\tif (flags & DNS_QUERY_NO_SEARCH) {\n\t\treq =\n\t\t\trequest_new(base, handle, TYPE_A, name, flags);\n\t\tif (req)\n\t\t\trequest_submit(req);\n\t} else {\n\t\tsearch_request_new(base, handle, TYPE_A, name, flags);\n\t}\n\tif (handle->current_req == NULL) {\n\t\tmm_free(handle);\n\t\thandle = NULL;\n\t}\n\tEVDNS_UNLOCK(base);\n\treturn handle;\n}\n\nint evdns_resolve_ipv4(const char *name, int flags,\n\t\t\t\t\t   evdns_callback_type callback, void *ptr)\n{\n\treturn evdns_base_resolve_ipv4(current_base, name, flags, callback, ptr)\n\t\t? 0 : -1;\n}\n\n\n/* exported function */\nstruct evdns_request *\nevdns_base_resolve_ipv6(struct evdns_base *base,\n    const char *name, int flags,\n    evdns_callback_type callback, void *ptr)\n{\n\tstruct evdns_request *handle;\n\tstruct request *req;\n\tlog(EVDNS_LOG_DEBUG, \"Resolve requested for %s\", name);\n\thandle = mm_calloc(1, sizeof(*handle));\n\tif (handle == NULL)\n\t\treturn NULL;\n\thandle->user_callback = callback;\n\thandle->user_pointer = ptr;\n\tEVDNS_LOCK(base);\n\thandle->tcp_flags = base->global_tcp_flags;\n\thandle->tcp_flags |= flags & (DNS_QUERY_USEVC | DNS_QUERY_IGNTC);\n\tif (flags & DNS_QUERY_NO_SEARCH) {\n\t\treq = request_new(base, handle, TYPE_AAAA, name, flags);\n\t\tif (req)\n\t\t\trequest_submit(req);\n\t} else {\n\t\tsearch_request_new(base, handle, TYPE_AAAA, name, flags);\n\t}\n\tif (handle->current_req == NULL) {\n\t\tmm_free(handle);\n\t\thandle = NULL;\n\t}\n\tEVDNS_UNLOCK(base);\n\treturn handle;\n}\n\nint evdns_resolve_ipv6(const char *name, int flags,\n    evdns_callback_type callback, void *ptr) {\n\treturn evdns_base_resolve_ipv6(current_base, name, flags, callback, ptr)\n\t\t? 0 : -1;\n}\n\nstruct evdns_request *\nevdns_base_resolve_reverse(struct evdns_base *base, const struct in_addr *in, int flags, evdns_callback_type callback, void *ptr) {\n\tchar buf[32];\n\tstruct evdns_request *handle;\n\tstruct request *req;\n\tu32 a;\n\tEVUTIL_ASSERT(in);\n\ta = ntohl(in->s_addr);\n\tevutil_snprintf(buf, sizeof(buf), \"%d.%d.%d.%d.in-addr.arpa\",\n\t\t\t(int)(u8)((a\t)&0xff),\n\t\t\t(int)(u8)((a>>8 )&0xff),\n\t\t\t(int)(u8)((a>>16)&0xff),\n\t\t\t(int)(u8)((a>>24)&0xff));\n\thandle = mm_calloc(1, sizeof(*handle));\n\tif (handle == NULL)\n\t\treturn NULL;\n\thandle->user_callback = callback;\n\thandle->user_pointer = ptr;\n\tlog(EVDNS_LOG_DEBUG, \"Resolve requested for %s (reverse)\", buf);\n\tEVDNS_LOCK(base);\n\thandle->tcp_flags = base->global_tcp_flags;\n\thandle->tcp_flags |= flags & (DNS_QUERY_USEVC | DNS_QUERY_IGNTC);\n\treq = request_new(base, handle, TYPE_PTR, buf, flags);\n\tif (req)\n\t\trequest_submit(req);\n\tif (handle->current_req == NULL) {\n\t\tmm_free(handle);\n\t\thandle = NULL;\n\t}\n\tEVDNS_UNLOCK(base);\n\treturn (handle);\n}\n\nint evdns_resolve_reverse(const struct in_addr *in, int flags, evdns_callback_type callback, void *ptr) {\n\treturn evdns_base_resolve_reverse(current_base, in, flags, callback, ptr)\n\t\t? 0 : -1;\n}\n\nstruct evdns_request *\nevdns_base_resolve_reverse_ipv6(struct evdns_base *base, const struct in6_addr *in, int flags, evdns_callback_type callback, void *ptr) {\n\t/* 32 nybbles, 32 periods, \"ip6.arpa\", NUL. */\n\tchar buf[73];\n\tchar *cp;\n\tstruct evdns_request *handle;\n\tstruct request *req;\n\tint i;\n\tEVUTIL_ASSERT(in);\n\tcp = buf;\n\tfor (i=15; i >= 0; --i) {\n\t\tu8 byte = in->s6_addr[i];\n\t\t*cp++ = \"0123456789abcdef\"[byte & 0x0f];\n\t\t*cp++ = '.';\n\t\t*cp++ = \"0123456789abcdef\"[byte >> 4];\n\t\t*cp++ = '.';\n\t}\n\tEVUTIL_ASSERT(cp + strlen(\"ip6.arpa\") < buf+sizeof(buf));\n\tmemcpy(cp, \"ip6.arpa\", strlen(\"ip6.arpa\")+1);\n\thandle = mm_calloc(1, sizeof(*handle));\n\tif (handle == NULL)\n\t\treturn NULL;\n\thandle->user_callback = callback;\n\thandle->user_pointer = ptr;\n\tlog(EVDNS_LOG_DEBUG, \"Resolve requested for %s (reverse)\", buf);\n\tEVDNS_LOCK(base);\n\thandle->tcp_flags = base->global_tcp_flags;\n\thandle->tcp_flags |= flags & (DNS_QUERY_USEVC | DNS_QUERY_IGNTC);\n\treq = request_new(base, handle, TYPE_PTR, buf, flags);\n\tif (req)\n\t\trequest_submit(req);\n\tif (handle->current_req == NULL) {\n\t\tmm_free(handle);\n\t\thandle = NULL;\n\t}\n\tEVDNS_UNLOCK(base);\n\treturn (handle);\n}\n\nint evdns_resolve_reverse_ipv6(const struct in6_addr *in, int flags, evdns_callback_type callback, void *ptr) {\n\treturn evdns_base_resolve_reverse_ipv6(current_base, in, flags, callback, ptr)\n\t\t? 0 : -1;\n}\n\n/* ================================================================= */\n/* Search support */\n/* */\n/* the libc resolver has support for searching a number of domains */\n/* to find a name. If nothing else then it takes the single domain */\n/* from the gethostname() call. */\n/* */\n/* It can also be configured via the domain and search options in a */\n/* resolv.conf. */\n/* */\n/* The ndots option controls how many dots it takes for the resolver */\n/* to decide that a name is non-local and so try a raw lookup first. */\n\nstruct search_domain {\n\tint len;\n\tstruct search_domain *next;\n\t/* the text string is appended to this structure */\n};\n\nstruct search_state {\n\tint refcount;\n\tint ndots;\n\tint num_domains;\n\tstruct search_domain *head;\n};\n\nstatic void\nsearch_state_decref(struct search_state *const state) {\n\tif (!state) return;\n\tstate->refcount--;\n\tif (!state->refcount) {\n\t\tstruct search_domain *next, *dom;\n\t\tfor (dom = state->head; dom; dom = next) {\n\t\t\tnext = dom->next;\n\t\t\tmm_free(dom);\n\t\t}\n\t\tmm_free(state);\n\t}\n}\n\nstatic struct search_state *\nsearch_state_new(void) {\n\tstruct search_state *state = (struct search_state *) mm_malloc(sizeof(struct search_state));\n\tif (!state) return NULL;\n\tmemset(state, 0, sizeof(struct search_state));\n\tstate->refcount = 1;\n\tstate->ndots = 1;\n\n\treturn state;\n}\n\nstatic void\nsearch_postfix_clear(struct evdns_base *base) {\n\tsearch_state_decref(base->global_search_state);\n\n\tbase->global_search_state = search_state_new();\n}\n\n/* exported function */\nvoid\nevdns_base_search_clear(struct evdns_base *base)\n{\n\tEVDNS_LOCK(base);\n\tsearch_postfix_clear(base);\n\tEVDNS_UNLOCK(base);\n}\n\nvoid\nevdns_search_clear(void) {\n\tevdns_base_search_clear(current_base);\n}\n\nstatic void\nsearch_postfix_add(struct evdns_base *base, const char *domain) {\n\tsize_t domain_len;\n\tstruct search_domain *sdomain;\n\twhile (domain[0] == '.') domain++;\n\tdomain_len = strlen(domain);\n\n\tASSERT_LOCKED(base);\n\tif (!base->global_search_state) base->global_search_state = search_state_new();\n\tif (!base->global_search_state) return;\n\tbase->global_search_state->num_domains++;\n\n\tsdomain = (struct search_domain *) mm_malloc(sizeof(struct search_domain) + domain_len);\n\tif (!sdomain) return;\n\tmemcpy( ((u8 *) sdomain) + sizeof(struct search_domain), domain, domain_len);\n\tsdomain->next = base->global_search_state->head;\n\tsdomain->len = (int) domain_len;\n\n\tbase->global_search_state->head = sdomain;\n}\n\n/* reverse the order of members in the postfix list. This is needed because, */\n/* when parsing resolv.conf we push elements in the wrong order */\nstatic void\nsearch_reverse(struct evdns_base *base) {\n\tstruct search_domain *cur, *prev = NULL, *next;\n\tASSERT_LOCKED(base);\n\tcur = base->global_search_state->head;\n\twhile (cur) {\n\t\tnext = cur->next;\n\t\tcur->next = prev;\n\t\tprev = cur;\n\t\tcur = next;\n\t}\n\n\tbase->global_search_state->head = prev;\n}\n\n/* exported function */\nvoid\nevdns_base_search_add(struct evdns_base *base, const char *domain) {\n\tEVDNS_LOCK(base);\n\tsearch_postfix_add(base, domain);\n\tEVDNS_UNLOCK(base);\n}\nvoid\nevdns_search_add(const char *domain) {\n\tevdns_base_search_add(current_base, domain);\n}\n\n/* exported function */\nvoid\nevdns_base_search_ndots_set(struct evdns_base *base, const int ndots) {\n\tEVDNS_LOCK(base);\n\tif (!base->global_search_state) base->global_search_state = search_state_new();\n\tif (base->global_search_state)\n\t\tbase->global_search_state->ndots = ndots;\n\tEVDNS_UNLOCK(base);\n}\nvoid\nevdns_search_ndots_set(const int ndots) {\n\tevdns_base_search_ndots_set(current_base, ndots);\n}\n\nstatic void\nsearch_set_from_hostname(struct evdns_base *base) {\n\tchar hostname[EVDNS_NAME_MAX + 1], *domainname;\n\n\tASSERT_LOCKED(base);\n\tsearch_postfix_clear(base);\n\tif (gethostname(hostname, sizeof(hostname))) return;\n\tdomainname = strchr(hostname, '.');\n\tif (!domainname) return;\n\tsearch_postfix_add(base, domainname);\n}\n\n/* warning: returns malloced string */\nstatic char *\nsearch_make_new(const struct search_state *const state, int n, const char *const base_name) {\n\tconst size_t base_len = strlen(base_name);\n\tchar need_to_append_dot;\n\tstruct search_domain *dom;\n\n\tif (!base_len) return NULL;\n\tneed_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n\n\tfor (dom = state->head; dom; dom = dom->next) {\n\t\tif (!n--) {\n\t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}\n\nstatic struct request *\nsearch_request_new(struct evdns_base *base, struct evdns_request *handle,\n\t\t   int type, const char *const name, int flags) {\n\tASSERT_LOCKED(base);\n\tEVUTIL_ASSERT(type == TYPE_A || type == TYPE_AAAA);\n\tEVUTIL_ASSERT(handle->current_req == NULL);\n\tif ( ((flags & DNS_QUERY_NO_SEARCH) == 0) &&\n\t     base->global_search_state &&\n\t\t base->global_search_state->num_domains) {\n\t\t/* we have some domains to search */\n\t\tstruct request *req;\n\t\tif (string_num_dots(name) >= base->global_search_state->ndots) {\n\t\t\treq = request_new(base, handle, type, name, flags);\n\t\t\tif (!req) return NULL;\n\t\t\thandle->search_index = -1;\n\t\t} else {\n\t\t\tchar *const new_name = search_make_new(base->global_search_state, 0, name);\n\t\t\tif (!new_name) return NULL;\n\t\t\treq = request_new(base, handle, type, new_name, flags);\n\t\t\tmm_free(new_name);\n\t\t\tif (!req) return NULL;\n\t\t\thandle->search_index = 0;\n\t\t}\n\t\tEVUTIL_ASSERT(handle->search_origname == NULL);\n\t\thandle->search_origname = mm_strdup(name);\n\t\tif (handle->search_origname == NULL) {\n\t\t\t/* XXX Should we dealloc req? If yes, how? */\n\t\t\tif (req)\n\t\t\t\tmm_free(req);\n\t\t\treturn NULL;\n\t\t}\n\t\thandle->search_state = base->global_search_state;\n\t\thandle->search_flags = flags;\n\t\tbase->global_search_state->refcount++;\n\t\trequest_submit(req);\n\t\treturn req;\n\t} else {\n\t\tstruct request *const req = request_new(base, handle, type, name, flags);\n\t\tif (!req) return NULL;\n\t\trequest_submit(req);\n\t\treturn req;\n\t}\n}\n\n/* this is called when a request has failed to find a name. We need to check */\n/* if it is part of a search and, if so, try the next name in the list */\n/* returns: */\n/*   0 another request has been submitted */\n/*   1 no more requests needed */\nstatic int\nsearch_try_next(struct evdns_request *const handle) {\n\tstruct request *req = handle->current_req;\n\tstruct evdns_base *base = req->base;\n\tstruct request *newreq;\n\tASSERT_LOCKED(base);\n\tif (handle->search_state) {\n\t\t/* it is part of a search */\n\t\tchar *new_name;\n\t\thandle->search_index++;\n\t\tif (handle->search_index >= handle->search_state->num_domains) {\n\t\t\t/* no more postfixes to try, however we may need to try */\n\t\t\t/* this name without a postfix */\n\t\t\tif (string_num_dots(handle->search_origname) < handle->search_state->ndots) {\n\t\t\t\t/* yep, we need to try it raw */\n\t\t\t\tnewreq = request_new(base, NULL, req->request_type, handle->search_origname, handle->search_flags);\n\t\t\t\tlog(EVDNS_LOG_DEBUG, \"Search: trying raw query %s\", handle->search_origname);\n\t\t\t\tif (newreq) {\n\t\t\t\t\tsearch_request_finished(handle);\n\t\t\t\t\tgoto submit_next;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\n\t\tnew_name = search_make_new(handle->search_state, handle->search_index, handle->search_origname);\n\t\tif (!new_name) return 1;\n\t\tlog(EVDNS_LOG_DEBUG, \"Search: now trying %s (%d)\", new_name, handle->search_index);\n\t\tnewreq = request_new(base, NULL, req->request_type, new_name, handle->search_flags);\n\t\tmm_free(new_name);\n\t\tif (!newreq) return 1;\n\t\tgoto submit_next;\n\t}\n\treturn 1;\n\nsubmit_next:\n\trequest_finished(req, &REQ_HEAD(req->base, req->trans_id), 0);\n\thandle->current_req = newreq;\n\tnewreq->handle = handle;\n\trequest_submit(newreq);\n\treturn 0;\n}\n\nstatic void\nsearch_request_finished(struct evdns_request *const handle) {\n\tASSERT_LOCKED(handle->current_req->base);\n\tif (handle->search_state) {\n\t\tsearch_state_decref(handle->search_state);\n\t\thandle->search_state = NULL;\n\t}\n\tif (handle->search_origname) {\n\t\tmm_free(handle->search_origname);\n\t\thandle->search_origname = NULL;\n\t}\n}\n\n/* ================================================================= */\n/* Parsing resolv.conf files */\n\nstatic void\nevdns_resolv_set_defaults(struct evdns_base *base, int flags) {\n\tint add_default = flags & DNS_OPTION_NAMESERVERS;\n\tif (flags & DNS_OPTION_NAMESERVERS_NO_DEFAULT)\n\t\tadd_default = 0;\n\n\t/* if the file isn't found then we assume a local resolver */\n\tASSERT_LOCKED(base);\n\tif (flags & DNS_OPTION_SEARCH)\n\t\tsearch_set_from_hostname(base);\n\tif (add_default)\n\t\tevdns_base_nameserver_ip_add(base, \"127.0.0.1\");\n}\n\n#ifndef EVENT__HAVE_STRTOK_R\nstatic char *\nstrtok_r(char *s, const char *delim, char **state) {\n\tchar *cp, *start;\n\tstart = cp = s ? s : *state;\n\tif (!cp)\n\t\treturn NULL;\n\twhile (*cp && !strchr(delim, *cp))\n\t\t++cp;\n\tif (!*cp) {\n\t\tif (cp == start)\n\t\t\treturn NULL;\n\t\t*state = NULL;\n\t\treturn start;\n\t} else {\n\t\t*cp++ = '\\0';\n\t\t*state = cp;\n\t\treturn start;\n\t}\n}\n#endif\n\n/* helper version of atoi which returns -1 on error */\nstatic int\nstrtoint(const char *const str)\n{\n\tchar *endptr;\n\tconst int r = strtol(str, &endptr, 10);\n\tif (*endptr) return -1;\n\treturn r;\n}\n\n/* Parse a number of seconds into a timeval; return -1 on error. */\nstatic int\nevdns_strtotimeval(const char *const str, struct timeval *out)\n{\n\tdouble d;\n\tchar *endptr;\n\td = strtod(str, &endptr);\n\tif (*endptr) return -1;\n\tif (d < 0) return -1;\n\tout->tv_sec = (int) d;\n\tout->tv_usec = (int) ((d - (int) d)*1000000);\n\tif (out->tv_sec == 0 && out->tv_usec < 1000) /* less than 1 msec */\n\t\treturn -1;\n\treturn 0;\n}\n\n/* helper version of atoi that returns -1 on error and clips to bounds. */\nstatic int\nstrtoint_clipped(const char *const str, int min, int max)\n{\n\tint r = strtoint(str);\n\tif (r == -1)\n\t\treturn r;\n\telse if (r<min)\n\t\treturn min;\n\telse if (r>max)\n\t\treturn max;\n\telse\n\t\treturn r;\n}\n\nstatic int\nevdns_base_set_max_requests_inflight(struct evdns_base *base, int maxinflight)\n{\n\tint old_n_heads = base->n_req_heads, n_heads;\n\tstruct request **old_heads = base->req_heads, **new_heads, *req;\n\tint i;\n\n\tASSERT_LOCKED(base);\n\tif (maxinflight < 1)\n\t\tmaxinflight = 1;\n\tn_heads = (maxinflight+4) / 5;\n\tEVUTIL_ASSERT(n_heads > 0);\n\tnew_heads = mm_calloc(n_heads, sizeof(struct request*));\n\tif (!new_heads)\n\t\treturn (-1);\n\tif (old_heads) {\n\t\tfor (i = 0; i < old_n_heads; ++i) {\n\t\t\twhile (old_heads[i]) {\n\t\t\t\treq = old_heads[i];\n\t\t\t\tevdns_request_remove(req, &old_heads[i]);\n\t\t\t\tevdns_request_insert(req, &new_heads[req->trans_id % n_heads]);\n\t\t\t}\n\t\t}\n\t\tmm_free(old_heads);\n\t}\n\tbase->req_heads = new_heads;\n\tbase->n_req_heads = n_heads;\n\tbase->global_max_requests_inflight = maxinflight;\n\treturn (0);\n}\n\n/* exported function */\nint\nevdns_base_set_option(struct evdns_base *base,\n    const char *option, const char *val)\n{\n\tint res;\n\tEVDNS_LOCK(base);\n\tres = evdns_base_set_option_impl(base, option, val, DNS_OPTIONS_ALL);\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\nstatic inline int\nstr_matches_option(const char *s1, const char *optionname)\n{\n\t/* Option names are given as \"option:\" We accept either 'option' in\n\t * s1, or 'option:randomjunk'.  The latter form is to implement the\n\t * resolv.conf parser. */\n\tsize_t optlen = strlen(optionname);\n\tsize_t slen = strlen(s1);\n\tif (slen == optlen || slen == optlen - 1)\n\t\treturn !strncmp(s1, optionname, slen);\n\telse if (slen > optlen)\n\t\treturn !strncmp(s1, optionname, optlen);\n\telse\n\t\treturn 0;\n}\n\n/* exported function */\nint\nevdns_server_port_set_option(struct evdns_server_port *port,\n\tenum evdns_server_option option, size_t value)\n{\n\tint res = 0;\n\tEVDNS_LOCK(port);\n\tswitch (option) {\n\tcase EVDNS_SOPT_TCP_MAX_CLIENTS:\n\t\tif (!port->listener) {\n\t\t\tlog(EVDNS_LOG_WARN, \"EVDNS_SOPT_TCP_MAX_CLIENTS option can be set only on TCP server\");\n\t\t\tres = -1;\n\t\t\tgoto end;\n\t\t}\n\t\tport->max_client_connections = value;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting EVDNS_SOPT_TCP_MAX_CLIENTS to %u\", port->max_client_connections);\n\t\tbreak;\n\tcase EVDNS_SOPT_TCP_IDLE_TIMEOUT:\n\t\tif (!port->listener) {\n\t\t\tlog(EVDNS_LOG_WARN, \"EVDNS_SOPT_TCP_IDLE_TIMEOUT option can be set only on TCP server\");\n\t\t\tres = -1;\n\t\t\tgoto end;\n\t\t}\n\t\tport->tcp_idle_timeout.tv_sec = value;\n\t\tport->tcp_idle_timeout.tv_usec = 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting EVDNS_SOPT_TCP_IDLE_TIMEOUT to %u seconds\",\n\t\t\t(unsigned)port->tcp_idle_timeout.tv_sec);\n\t\tbreak;\n\tdefault:\n\t\tlog(EVDNS_LOG_WARN, \"Invalid DNS server option %d\", (int)option);\n\t\tres = -1;\n\t\tbreak;\n\t}\nend:\n\tEVDNS_UNLOCK(port);\n\treturn res;\n}\n\nstatic int\nevdns_base_set_option_impl(struct evdns_base *base,\n    const char *option, const char *val, int flags)\n{\n\tASSERT_LOCKED(base);\n\tif (str_matches_option(option, \"ndots:\")) {\n\t\tconst int ndots = strtoint(val);\n\t\tif (ndots == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_SEARCH)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting ndots to %d\", ndots);\n\t\tif (!base->global_search_state) base->global_search_state = search_state_new();\n\t\tif (!base->global_search_state) return -1;\n\t\tbase->global_search_state->ndots = ndots;\n\t} else if (str_matches_option(option, \"timeout:\")) {\n\t\tstruct timeval tv;\n\t\tif (evdns_strtotimeval(val, &tv) == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting timeout to %s\", val);\n\t\tmemcpy(&base->global_timeout, &tv, sizeof(struct timeval));\n\t} else if (str_matches_option(option, \"getaddrinfo-allow-skew:\")) {\n\t\tstruct timeval tv;\n\t\tif (evdns_strtotimeval(val, &tv) == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting getaddrinfo-allow-skew to %s\",\n\t\t    val);\n\t\tmemcpy(&base->global_getaddrinfo_allow_skew, &tv,\n\t\t    sizeof(struct timeval));\n\t} else if (str_matches_option(option, \"max-timeouts:\")) {\n\t\tconst int maxtimeout = strtoint_clipped(val, 1, 255);\n\t\tif (maxtimeout == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting maximum allowed timeouts to %d\",\n\t\t\tmaxtimeout);\n\t\tbase->global_max_nameserver_timeout = maxtimeout;\n\t} else if (str_matches_option(option, \"max-inflight:\")) {\n\t\tconst int maxinflight = strtoint_clipped(val, 1, 65000);\n\t\tif (maxinflight == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting maximum inflight requests to %d\",\n\t\t\tmaxinflight);\n\t\tevdns_base_set_max_requests_inflight(base, maxinflight);\n\t} else if (str_matches_option(option, \"attempts:\")) {\n\t\tint retries = strtoint(val);\n\t\tif (retries == -1) return -1;\n\t\tif (retries > 255) retries = 255;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting retries to %d\", retries);\n\t\tbase->global_max_retransmits = retries;\n\t} else if (str_matches_option(option, \"randomize-case:\")) {\n\t\tint randcase = strtoint(val);\n\t\tif (randcase == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tbase->global_randomize_case = randcase;\n\t} else if (str_matches_option(option, \"bind-to:\")) {\n\t\t/* XXX This only applies to successive nameservers, not\n\t\t * to already-configured ones.\tWe might want to fix that. */\n\t\tint len = sizeof(base->global_outgoing_address);\n\t\tif (!(flags & DNS_OPTION_NAMESERVERS)) return 0;\n\t\tif (evutil_parse_sockaddr_port(val,\n\t\t\t(struct sockaddr*)&base->global_outgoing_address, &len))\n\t\t\treturn -1;\n\t\tbase->global_outgoing_addrlen = len;\n\t} else if (str_matches_option(option, \"initial-probe-timeout:\")) {\n\t\tstruct timeval tv;\n\t\tif (evdns_strtotimeval(val, &tv) == -1) return -1;\n\t\tif (tv.tv_sec > 3600)\n\t\t\ttv.tv_sec = 3600;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting initial probe timeout to %s\",\n\t\t    val);\n\t\tmemcpy(&base->global_nameserver_probe_initial_timeout, &tv,\n\t\t    sizeof(tv));\n\t} else if (str_matches_option(option, \"max-probe-timeout:\")) {\n\t\tconst int max_probe_timeout = strtoint_clipped(val, 1, 3600);\n\t\tif (max_probe_timeout == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting maximum probe timeout to %d\",\n\t\t\tmax_probe_timeout);\n\t\tbase->ns_max_probe_timeout = max_probe_timeout;\n\t\tif (base->global_nameserver_probe_initial_timeout.tv_sec > max_probe_timeout) {\n\t\t\tbase->global_nameserver_probe_initial_timeout.tv_sec = max_probe_timeout;\n\t\t\tbase->global_nameserver_probe_initial_timeout.tv_usec = 0;\n\t\t\tlog(EVDNS_LOG_DEBUG, \"Setting initial probe timeout to %s\",\n\t\t\t\tval);\n\t\t}\n\t} else if (str_matches_option(option, \"probe-backoff-factor:\")) {\n\t\tconst int backoff_backtor = strtoint_clipped(val, 1, 10);\n\t\tif (backoff_backtor == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting probe timeout backoff factor to %d\",\n\t\t\tbackoff_backtor);\n\t\tbase->ns_timeout_backoff_factor = backoff_backtor;\n\t} else if (str_matches_option(option, \"so-rcvbuf:\")) {\n\t\tint buf = strtoint(val);\n\t\tif (buf == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting SO_RCVBUF to %s\", val);\n\t\tbase->so_rcvbuf = buf;\n\t} else if (str_matches_option(option, \"so-sndbuf:\")) {\n\t\tint buf = strtoint(val);\n\t\tif (buf == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting SO_SNDBUF to %s\", val);\n\t\tbase->so_sndbuf = buf;\n\t} else if (str_matches_option(option, \"tcp-idle-timeout:\")) {\n\t\tstruct timeval tv;\n\t\tif (evdns_strtotimeval(val, &tv) == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting tcp idle timeout to %s\", val);\n\t\tmemcpy(&base->global_tcp_idle_timeout, &tv, sizeof(tv));\n\t} else if (str_matches_option(option, \"use-vc:\")) {\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tif (val && strlen(val)) return -1;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting use-vc option\");\n\t\tbase->global_tcp_flags |= DNS_QUERY_USEVC;\n\t} else if (str_matches_option(option, \"ignore-tc:\")) {\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tif (val && strlen(val)) return -1;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting ignore-tc option\");\n\t\tbase->global_tcp_flags |= DNS_QUERY_IGNTC;\n\t} else if (str_matches_option(option, \"edns-udp-size:\")) {\n\t\tconst int sz = strtoint_clipped(val, DNS_MAX_UDP_SIZE, EDNS_MAX_UDP_SIZE);\n\t\tif (sz == -1) return -1;\n\t\tif (!(flags & DNS_OPTION_MISC)) return 0;\n\t\tlog(EVDNS_LOG_DEBUG, \"Setting edns-udp-size to %d\", sz);\n\t\tbase->global_max_udp_size = sz;\n\t}\n\treturn 0;\n}\n\nint\nevdns_set_option(const char *option, const char *val, int flags)\n{\n\tif (!current_base)\n\t\tcurrent_base = evdns_base_new(NULL, 0);\n\treturn evdns_base_set_option(current_base, option, val);\n}\n\nstatic void\nresolv_conf_parse_line(struct evdns_base *base, char *const start, int flags) {\n\tchar *strtok_state;\n\tstatic const char *const delims = \" \\t\";\n#define NEXT_TOKEN strtok_r(NULL, delims, &strtok_state)\n\n\n\tchar *const first_token = strtok_r(start, delims, &strtok_state);\n\tASSERT_LOCKED(base);\n\tif (!first_token) return;\n\n\tif (!strcmp(first_token, \"nameserver\") && (flags & DNS_OPTION_NAMESERVERS)) {\n\t\tconst char *const nameserver = NEXT_TOKEN;\n\n\t\tif (nameserver)\n\t\t\tevdns_base_nameserver_ip_add(base, nameserver);\n\t} else if (!strcmp(first_token, \"domain\") && (flags & DNS_OPTION_SEARCH)) {\n\t\tconst char *const domain = NEXT_TOKEN;\n\t\tif (domain) {\n\t\t\tsearch_postfix_clear(base);\n\t\t\tsearch_postfix_add(base, domain);\n\t\t}\n\t} else if (!strcmp(first_token, \"search\") && (flags & DNS_OPTION_SEARCH)) {\n\t\tconst char *domain;\n\t\tsearch_postfix_clear(base);\n\n\t\twhile ((domain = NEXT_TOKEN)) {\n\t\t\tsearch_postfix_add(base, domain);\n\t\t}\n\t\tsearch_reverse(base);\n\t} else if (!strcmp(first_token, \"options\")) {\n\t\tconst char *option;\n\t\twhile ((option = NEXT_TOKEN)) {\n\t\t\tconst char *val = strchr(option, ':');\n\t\t\tevdns_base_set_option_impl(base, option, val ? val+1 : \"\", flags);\n\t\t}\n\t}\n#undef NEXT_TOKEN\n}\n\n/* exported function */\n/* returns: */\n/*   EVDNS_ERROR_NONE (0) no errors */\n/*   EVDNS_ERROR_FAILED_TO_OPEN_FILE (1) failed to open file */\n/*   EVDNS_ERROR_FAILED_TO_STAT_FILE (2) failed to stat file */\n/*   EVDNS_ERROR_FILE_TOO_LARGE (3) file too large */\n/*   EVDNS_ERROR_OUT_OF_MEMORY (4) out of memory */\n/*   EVDNS_ERROR_SHORT_READ_FROM_FILE (5) short read from file */\n/*   EVDNS_ERROR_NO_NAMESERVERS_CONFIGURED (6) no nameservers configured */\nint\nevdns_base_resolv_conf_parse(struct evdns_base *base, int flags, const char *const filename) {\n\tint res;\n\tEVDNS_LOCK(base);\n\tres = evdns_base_resolv_conf_parse_impl(base, flags, filename);\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\nstatic char *\nevdns_get_default_hosts_filename(void)\n{\n#ifdef _WIN32\n\t/* Windows is a little coy about where it puts its configuration\n\t * files.  Sure, they're _usually_ in C:\\windows\\system32, but\n\t * there's no reason in principle they couldn't be in\n\t * W:\\hoboken chicken emergency\\\n\t */\n\tchar path[MAX_PATH+1];\n\tstatic const char hostfile[] = \"\\\\drivers\\\\etc\\\\hosts\";\n\tchar *path_out;\n\tsize_t len_out;\n\n\tif (! SHGetSpecialFolderPathA(NULL, path, CSIDL_SYSTEM, 0))\n\t\treturn NULL;\n\tlen_out = strlen(path)+strlen(hostfile)+1;\n\tpath_out = mm_malloc(len_out);\n\tevutil_snprintf(path_out, len_out, \"%s%s\", path, hostfile);\n\treturn path_out;\n#else\n\treturn mm_strdup(\"/etc/hosts\");\n#endif\n}\n\nstatic int\nevdns_base_resolv_conf_parse_impl(struct evdns_base *base, int flags, const char *const filename) {\n\tsize_t n;\n\tchar *resolv;\n\tchar *start;\n\tint err = EVDNS_ERROR_NONE;\n\tint add_default;\n\n\tlog(EVDNS_LOG_DEBUG, \"Parsing resolv.conf file %s\", filename);\n\n\tadd_default = flags & DNS_OPTION_NAMESERVERS;\n\tif (flags & DNS_OPTION_NAMESERVERS_NO_DEFAULT)\n\t\tadd_default = 0;\n\n\tif (flags & DNS_OPTION_HOSTSFILE) {\n\t\tchar *fname = evdns_get_default_hosts_filename();\n\t\tevdns_base_load_hosts(base, fname);\n\t\tif (fname)\n\t\t\tmm_free(fname);\n\t}\n\n\tif (!filename) {\n\t\tevdns_resolv_set_defaults(base, flags);\n\t\treturn EVDNS_ERROR_FAILED_TO_OPEN_FILE;\n\t}\n\n\tif ((err = evutil_read_file_(filename, &resolv, &n, 0)) < 0) {\n\t\tif (err == -1) {\n\t\t\t/* No file. */\n\t\t\tevdns_resolv_set_defaults(base, flags);\n\t\t\treturn EVDNS_ERROR_FAILED_TO_OPEN_FILE;\n\t\t} else {\n\t\t\treturn EVDNS_ERROR_FAILED_TO_STAT_FILE;\n\t\t}\n\t}\n\n\tstart = resolv;\n\tfor (;;) {\n\t\tchar *const newline = strchr(start, '\\n');\n\t\tif (!newline) {\n\t\t\tresolv_conf_parse_line(base, start, flags);\n\t\t\tbreak;\n\t\t} else {\n\t\t\t*newline = 0;\n\t\t\tresolv_conf_parse_line(base, start, flags);\n\t\t\tstart = newline + 1;\n\t\t}\n\t}\n\n\tif (!base->server_head && add_default) {\n\t\t/* no nameservers were configured. */\n\t\tevdns_base_nameserver_ip_add(base, \"127.0.0.1\");\n\t\terr = EVDNS_ERROR_NO_NAMESERVERS_CONFIGURED;\n\t}\n\tif (flags & DNS_OPTION_SEARCH && (!base->global_search_state || base->global_search_state->num_domains == 0)) {\n\t\tsearch_set_from_hostname(base);\n\t}\n\n\tmm_free(resolv);\n\treturn err;\n}\n\nint\nevdns_resolv_conf_parse(int flags, const char *const filename) {\n\tif (!current_base)\n\t\tcurrent_base = evdns_base_new(NULL, 0);\n\treturn evdns_base_resolv_conf_parse(current_base, flags, filename);\n}\n\n\n#ifdef _WIN32\n/* Add multiple nameservers from a space-or-comma-separated list. */\nstatic int\nevdns_nameserver_ip_add_line(struct evdns_base *base, const char *ips) {\n\tconst char *addr;\n\tchar *buf;\n\tint r;\n\tASSERT_LOCKED(base);\n\twhile (*ips) {\n\t\twhile (isspace(*ips) || *ips == ',' || *ips == '\\t')\n\t\t\t++ips;\n\t\taddr = ips;\n\t\twhile (isdigit(*ips) || *ips == '.' || *ips == ':' ||\n\t\t    *ips=='[' || *ips==']')\n\t\t\t++ips;\n\t\tbuf = mm_malloc(ips-addr+1);\n\t\tif (!buf) return 4;\n\t\tmemcpy(buf, addr, ips-addr);\n\t\tbuf[ips-addr] = '\\0';\n\t\tr = evdns_base_nameserver_ip_add(base, buf);\n\t\tmm_free(buf);\n\t\tif (r) return r;\n\t}\n\treturn 0;\n}\n\ntypedef DWORD(WINAPI *GetAdaptersAddresses_fn_t)(ULONG, ULONG, PVOID, PIP_ADAPTER_ADDRESSES, PULONG);\n\n/* Use the windows GetAdaptersAddresses interface in iphlpapi.dll to */\n/* figure out what our nameservers are. */\nstatic int\nload_nameservers_with_getadaptersaddresses_unlocked(struct evdns_base *base)\n{\n\tPIP_ADAPTER_ADDRESSES addresses = NULL;\n\tHMODULE handle = 0;\n\tULONG size = sizeof(IP_ADAPTER_ADDRESSES);\n\tvoid *buf = NULL;\n\tint status = 0, r, added_any = 0;\n\tGetAdaptersAddresses_fn_t fn;\n\tIP_ADAPTER_DNS_SERVER_ADDRESS *dnsserver = NULL;\n\n\tASSERT_LOCKED(base);\n\tif (!(handle = evutil_load_windows_system_library_(\n\t\t\tTEXT(\"iphlpapi.dll\")))) {\n\t\tlog(EVDNS_LOG_WARN, \"Could not open iphlpapi.dll\");\n\t\tstatus = -1;\n\t\tgoto done;\n\t}\n\tif (!(fn = (GetAdaptersAddresses_fn_t) GetProcAddress(handle, \"GetAdaptersAddresses\"))) {\n\t\tlog(EVDNS_LOG_WARN, \"Could not get address of function.\");\n\t\tstatus = -1;\n\t\tgoto done;\n\t}\n\n\tbuf = mm_malloc(size);\n\tif (!buf) { status = 4; goto done; }\n\taddresses = buf;\n\tr = fn(AF_UNSPEC, GAA_FLAG_INCLUDE_PREFIX, NULL, addresses, &size);\n\tif (r != NO_ERROR && r != ERROR_BUFFER_OVERFLOW) {\n\t\tstatus = -1;\n\t\tgoto done;\n\t}\n\tif (r != NO_ERROR) {\n\t\tmm_free(buf);\n\t\tbuf = mm_malloc(size);\n\t\tif (!buf) { status = 4; goto done; }\n\t\taddresses = buf;\n\t\tr = fn(AF_UNSPEC, GAA_FLAG_INCLUDE_PREFIX, NULL, addresses, &size);\n\t\tif (r != NO_ERROR) {\n\t\t\tlog(EVDNS_LOG_DEBUG, \"fn() failed.\");\n\t\t\tstatus = -1;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\twhile (addresses) {\n\t\tdnsserver = addresses->FirstDnsServerAddress;\n\t\twhile (dnsserver && (addresses->OperStatus == IfOperStatusUp)) {\n\t\t\tchar ip[INET6_ADDRSTRLEN] = {0};\n\t\t\tif (AF_INET == dnsserver->Address.lpSockaddr->sa_family) {\n\t\t\t\tinet_ntop(AF_INET, &((SOCKADDR_IN *)dnsserver->Address.lpSockaddr)->sin_addr, ip, sizeof(ip));\n\t\t\t} else if (AF_INET6 == dnsserver->Address.lpSockaddr->sa_family) {\n\t\t\t\tinet_ntop(AF_INET6, &((SOCKADDR_IN6 *)dnsserver->Address.lpSockaddr)->sin6_addr, ip, sizeof(ip));\n\t\t\t}\n\n\t\t\tdnsserver = dnsserver->Next;\n\t\t\tif (strncmp(ip, \"fec0:\", 5) == 0) { /* remove ipv6 reserved address */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\n\t\t\tr = evdns_base_nameserver_ip_add(base, ip);\n\t\t\tif (r) {\n\t\t\t\tlog(EVDNS_LOG_DEBUG, \"Could not add nameserver %s to list, error: %d\", ip, r);\n\t\t\t\tstatus = r;\n\t\t\t} else {\n\t\t\t\t++added_any;\n\t\t\t\tlog(EVDNS_LOG_DEBUG, \"Successfully added %s as nameserver\", ip);\n\t\t\t}\n\t\t}\n\t\t\n\t\taddresses = addresses->Next;\n\t}\n\n\tif (!added_any) {\n\t\tlog(EVDNS_LOG_DEBUG, \"No nameservers added.\");\n\t\tif (status == 0)\n\t\t\tstatus = -1;\n\t} else {\n\t\tstatus = 0;\n\t}\n\n done:\n\tif (buf)\n\t\tmm_free(buf);\n\tif (handle)\n\t\tFreeLibrary(handle);\n\treturn status;\n}\n\nint\nload_nameservers_with_getadaptersaddresses(struct evdns_base *base)\n{\n\tint r;\n\tEVDNS_LOCK(base);\n\tr = load_nameservers_with_getadaptersaddresses_unlocked(base);\n\tEVDNS_UNLOCK(base);\n\treturn r;\n}\n\nstatic int\nconfig_nameserver_from_reg_key(struct evdns_base *base, HKEY key, const TCHAR *subkey)\n{\n\tchar *buf;\n\tDWORD bufsz = 0, type = 0;\n\tint status = 0;\n\n\tASSERT_LOCKED(base);\n\tif (RegQueryValueEx(key, subkey, 0, &type, NULL, &bufsz)\n\t    != ERROR_MORE_DATA)\n\t\treturn -1;\n\tif (!(buf = mm_malloc(bufsz)))\n\t\treturn -1;\n\n\tif (RegQueryValueEx(key, subkey, 0, &type, (LPBYTE)buf, &bufsz)\n\t    == ERROR_SUCCESS && bufsz > 1) {\n\t\tstatus = evdns_nameserver_ip_add_line(base,buf);\n\t}\n\n\tmm_free(buf);\n\treturn status;\n}\n\n#define SERVICES_KEY TEXT(\"System\\\\CurrentControlSet\\\\Services\\\\\")\n#define WIN_NS_9X_KEY  SERVICES_KEY TEXT(\"VxD\\\\MSTCP\")\n#define WIN_NS_NT_KEY  SERVICES_KEY TEXT(\"Tcpip\\\\Parameters\")\n\nstatic int\nload_nameservers_from_registry(struct evdns_base *base)\n{\n\tint found = 0;\n\tint r;\n#define TRY(k, name) \\\n\tif (!found && config_nameserver_from_reg_key(base,k,TEXT(name)) == 0) { \\\n\t\tlog(EVDNS_LOG_DEBUG,\"Found nameservers in %s/%s\",#k,name); \\\n\t\tfound = 1;\t\t\t\t\t\t\\\n\t} else if (!found) {\t\t\t\t\t\t\\\n\t\tlog(EVDNS_LOG_DEBUG,\"Didn't find nameservers in %s/%s\", \\\n\t\t    #k,#name);\t\t\t\t\t\t\\\n\t}\n\n\tASSERT_LOCKED(base);\n\n\tif (((int)GetVersion()) > 0) { /* NT */\n\t\tHKEY nt_key = 0, interfaces_key = 0;\n\n\t\tif (RegOpenKeyEx(HKEY_LOCAL_MACHINE, WIN_NS_NT_KEY, 0,\n\t\t\t\t KEY_READ, &nt_key) != ERROR_SUCCESS) {\n\t\t\tlog(EVDNS_LOG_DEBUG,\"Couldn't open nt key, %d\",(int)GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t\tr = RegOpenKeyEx(nt_key, TEXT(\"Interfaces\"), 0,\n\t\t\t     KEY_QUERY_VALUE|KEY_ENUMERATE_SUB_KEYS,\n\t\t\t     &interfaces_key);\n\t\tif (r != ERROR_SUCCESS) {\n\t\t\tlog(EVDNS_LOG_DEBUG,\"Couldn't open interfaces key, %d\",(int)GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t\tTRY(nt_key, \"NameServer\");\n\t\tTRY(nt_key, \"DhcpNameServer\");\n\t\tTRY(interfaces_key, \"NameServer\");\n\t\tTRY(interfaces_key, \"DhcpNameServer\");\n\t\tRegCloseKey(interfaces_key);\n\t\tRegCloseKey(nt_key);\n\t} else {\n\t\tHKEY win_key = 0;\n\t\tif (RegOpenKeyEx(HKEY_LOCAL_MACHINE, WIN_NS_9X_KEY, 0,\n\t\t\t\t KEY_READ, &win_key) != ERROR_SUCCESS) {\n\t\t\tlog(EVDNS_LOG_DEBUG, \"Couldn't open registry key, %d\", (int)GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t\tTRY(win_key, \"NameServer\");\n\t\tRegCloseKey(win_key);\n\t}\n\n\tif (found == 0) {\n\t\tlog(EVDNS_LOG_WARN,\"Didn't find any nameservers.\");\n\t}\n\n\treturn found ? 0 : -1;\n#undef TRY\n}\n\nint\nevdns_base_config_windows_nameservers(struct evdns_base *base)\n{\n\tint r;\n\tchar *fname;\n\tif (base == NULL)\n\t\tbase = current_base;\n\tif (base == NULL)\n\t\treturn -1;\n\tEVDNS_LOCK(base);\n\tfname = evdns_get_default_hosts_filename();\n\tlog(EVDNS_LOG_DEBUG, \"Loading hosts entries from %s\", fname);\n\tevdns_base_load_hosts(base, fname);\n\tif (fname)\n\t\tmm_free(fname);\n\n\tif (load_nameservers_with_getadaptersaddresses_unlocked(base) == 0) {\n\t\tEVDNS_UNLOCK(base);\n\t\treturn 0;\n\t}\n\tr = load_nameservers_from_registry(base);\n\n\tEVDNS_UNLOCK(base);\n\treturn r;\n}\n\nint\nevdns_config_windows_nameservers(void)\n{\n\tif (!current_base) {\n\t\tcurrent_base = evdns_base_new(NULL, 1);\n\t\treturn current_base == NULL ? -1 : 0;\n\t} else {\n\t\treturn evdns_base_config_windows_nameservers(current_base);\n\t}\n}\n#endif\n\nstruct evdns_base *\nevdns_base_new(struct event_base *event_base, int flags)\n{\n\tstruct evdns_base *base;\n\n\tif (evutil_secure_rng_init() < 0) {\n\t\tlog(EVDNS_LOG_WARN, \"Unable to seed random number generator; \"\n\t\t    \"DNS can't run.\");\n\t\treturn NULL;\n\t}\n\n\t/* Give the evutil library a hook into its evdns-enabled\n\t * functionality.  We can't just call evdns_getaddrinfo directly or\n\t * else libevent-core will depend on libevent-extras. */\n\tevutil_set_evdns_getaddrinfo_fn_(evdns_getaddrinfo);\n\tevutil_set_evdns_getaddrinfo_cancel_fn_(evdns_getaddrinfo_cancel);\n\n\tbase = mm_malloc(sizeof(struct evdns_base));\n\tif (base == NULL)\n\t\treturn (NULL);\n\tmemset(base, 0, sizeof(struct evdns_base));\n\tbase->req_waiting_head = NULL;\n\n\tEVTHREAD_ALLOC_LOCK(base->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\tEVDNS_LOCK(base);\n\n\t/* Set max requests inflight and allocate req_heads. */\n\tbase->req_heads = NULL;\n\n\tevdns_base_set_max_requests_inflight(base, 64);\n\n\tbase->server_head = NULL;\n\tbase->event_base = event_base;\n\tbase->global_good_nameservers = base->global_requests_inflight =\n\t\tbase->global_requests_waiting = 0;\n\n\tbase->global_timeout.tv_sec = 5;\n\tbase->global_timeout.tv_usec = 0;\n\tbase->global_max_reissues = 1;\n\tbase->global_max_retransmits = 3;\n\tbase->global_max_nameserver_timeout = 3;\n\tbase->global_search_state = NULL;\n\tbase->global_randomize_case = 1;\n\tbase->global_max_udp_size = DNS_MAX_UDP_SIZE;\n\tbase->global_getaddrinfo_allow_skew.tv_sec = 3;\n\tbase->global_getaddrinfo_allow_skew.tv_usec = 0;\n\tbase->global_nameserver_probe_initial_timeout.tv_sec = 10;\n\tbase->global_nameserver_probe_initial_timeout.tv_usec = 0;\n\tbase->ns_max_probe_timeout = 3600;\n\tbase->ns_timeout_backoff_factor = 3;\n\tbase->global_tcp_idle_timeout.tv_sec = CLIENT_IDLE_CONN_TIMEOUT;\n\n\tTAILQ_INIT(&base->hostsdb);\n\tSPLAY_INIT(&base->cache_root);\n\n#define EVDNS_BASE_ALL_FLAGS ( \\\n\tEVDNS_BASE_INITIALIZE_NAMESERVERS | \\\n\tEVDNS_BASE_DISABLE_WHEN_INACTIVE  | \\\n\tEVDNS_BASE_NAMESERVERS_NO_DEFAULT | \\\n\tEVDNS_BASE_NO_CACHE               | \\\n\t0)\n\n\tif (flags & ~EVDNS_BASE_ALL_FLAGS) {\n\t\tflags = EVDNS_BASE_INITIALIZE_NAMESERVERS;\n\t\tlog(EVDNS_LOG_WARN,\n\t\t    \"Unrecognized flag passed to evdns_base_new(). Assuming \"\n\t\t    \"you meant EVDNS_BASE_INITIALIZE_NAMESERVERS.\");\n\t}\n#undef EVDNS_BASE_ALL_FLAGS\n\n\tif (flags & EVDNS_BASE_DISABLE_WHEN_INACTIVE) {\n\t\tbase->disable_when_inactive = 1;\n\t}\n\n\tif (flags & EVDNS_BASE_INITIALIZE_NAMESERVERS) {\n\t\tint r;\n\t\tint opts = DNS_OPTIONS_ALL;\n\t\tif (flags & EVDNS_BASE_NAMESERVERS_NO_DEFAULT) {\n\t\t\topts |= DNS_OPTION_NAMESERVERS_NO_DEFAULT;\n\t\t}\n\n#ifdef _WIN32\n\t\tr = evdns_base_config_windows_nameservers(base);\n#else\n\t\tr = evdns_base_resolv_conf_parse(base, opts, evutil_resolvconf_filename_());\n#endif\n\t\tif (r && (EVDNS_ERROR_NO_NAMESERVERS_CONFIGURED != r)) {\n\t\t\tevdns_base_free_and_unlock(base, 0);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tbase->disable_cache = flags & EVDNS_BASE_NO_CACHE;\n\n\tEVDNS_UNLOCK(base);\n\treturn base;\n}\n\nint\nevdns_init(void)\n{\n\tstruct evdns_base *base = evdns_base_new(NULL, 1);\n\tif (base) {\n\t\tcurrent_base = base;\n\t\treturn 0;\n\t} else {\n\t\treturn -1;\n\t}\n}\n\nconst char *\nevdns_err_to_string(int err)\n{\n    switch (err) {\n\tcase DNS_ERR_NONE: return \"no error\";\n\tcase DNS_ERR_FORMAT: return \"misformatted query\";\n\tcase DNS_ERR_SERVERFAILED: return \"server failed\";\n\tcase DNS_ERR_NOTEXIST: return \"name does not exist\";\n\tcase DNS_ERR_NOTIMPL: return \"query not implemented\";\n\tcase DNS_ERR_REFUSED: return \"refused\";\n\n\tcase DNS_ERR_TRUNCATED: return \"reply truncated or ill-formed\";\n\tcase DNS_ERR_UNKNOWN: return \"unknown\";\n\tcase DNS_ERR_TIMEOUT: return \"request timed out\";\n\tcase DNS_ERR_SHUTDOWN: return \"dns subsystem shut down\";\n\tcase DNS_ERR_CANCEL: return \"dns request canceled\";\n\tcase DNS_ERR_NODATA: return \"no records in the reply\";\n\tdefault: return \"[Unknown error code]\";\n    }\n}\n\nstatic void\nevdns_nameserver_free(struct nameserver *server)\n{\n\tif (server->socket >= 0)\n\t\tevutil_closesocket(server->socket);\n\t(void) event_del(&server->event);\n\tevent_debug_unassign(&server->event);\n\tif (server->state == 0)\n\t\t(void) event_del(&server->timeout_event);\n\tif (server->probe_request) {\n\t\tevdns_cancel_request(server->base, server->probe_request);\n\t\tserver->probe_request = NULL;\n\t}\n\tevent_debug_unassign(&server->timeout_event);\n\tdisconnect_and_free_connection(server->connection);\n\tmm_free(server);\n}\n\nstatic int\nevdns_cache_compare(struct evdns_cache *a, struct evdns_cache *b)\n{\n\treturn strcasecmp(a->name, b->name);\n}\n\nSPLAY_PROTOTYPE(evdns_tree, evdns_cache, node, evdns_cache_compare);\nSPLAY_GENERATE(evdns_tree, evdns_cache, node, evdns_cache_compare);\n\nstatic void\nevdns_cache_free(struct evdns_cache *cache)\n{\n\tSPLAY_REMOVE(evdns_tree, &cache->base->cache_root, cache);\n\tmm_free(cache->name);\n\tevtimer_del(&cache->ev_timeout);\n\tevutil_freeaddrinfo(cache->ai);\n\tmm_free(cache);\n}\n\nstatic void\nevdns_base_free_and_unlock(struct evdns_base *base, int fail_requests)\n{\n\tstruct nameserver *server, *server_next;\n\tstruct search_domain *dom, *dom_next;\n\tint i;\n\n\t/* Requires that we hold the lock. */\n\n\t/* TODO(nickm) we might need to refcount here. */\n\n\twhile (base->req_waiting_head) {\n\t\tif (fail_requests)\n\t\t\treply_schedule_callback(base->req_waiting_head, 0, DNS_ERR_SHUTDOWN, NULL);\n\t\trequest_finished(base->req_waiting_head, &base->req_waiting_head, 1);\n\t}\n\tfor (i = 0; i < base->n_req_heads; ++i) {\n\t\twhile (base->req_heads[i]) {\n\t\t\tif (fail_requests)\n\t\t\t\treply_schedule_callback(base->req_heads[i], 0, DNS_ERR_SHUTDOWN, NULL);\n\t\t\trequest_finished(base->req_heads[i], &REQ_HEAD(base, base->req_heads[i]->trans_id), 1);\n\t\t}\n\t}\n\tbase->global_requests_inflight = base->global_requests_waiting = 0;\n\n\tfor (server = base->server_head; server; server = server_next) {\n\t\tserver_next = server->next;\n\t\t/** already done something before */\n\t\tserver->probe_request = NULL;\n\t\tevdns_nameserver_free(server);\n\t\tif (server_next == base->server_head)\n\t\t\tbreak;\n\t}\n\tbase->server_head = NULL;\n\tbase->global_good_nameservers = 0;\n\n\tif (base->global_search_state) {\n\t\tfor (dom = base->global_search_state->head; dom; dom = dom_next) {\n\t\t\tdom_next = dom->next;\n\t\t\tmm_free(dom);\n\t\t}\n\t\tmm_free(base->global_search_state);\n\t\tbase->global_search_state = NULL;\n\t}\n\n\t{\n\t\tstruct hosts_entry *victim;\n\t\twhile ((victim = TAILQ_FIRST(&base->hostsdb))) {\n\t\t\tTAILQ_REMOVE(&base->hostsdb, victim, next);\n\t\t\tmm_free(victim);\n\t\t}\n\t}\n\n\tmm_free(base->req_heads);\n\n\twhile (!SPLAY_EMPTY(&base->cache_root)) {\n\t\tevdns_cache_free(SPLAY_ROOT(&base->cache_root));\n\t}\n\n\tEVDNS_UNLOCK(base);\n\tEVTHREAD_FREE_LOCK(base->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\n\tmm_free(base);\n}\n\nvoid\nevdns_base_free(struct evdns_base *base, int fail_requests)\n{\n\tEVDNS_LOCK(base);\n\tevdns_base_free_and_unlock(base, fail_requests);\n}\n\nvoid\nevdns_base_clear_host_addresses(struct evdns_base *base)\n{\n\tstruct hosts_entry *victim;\n\tEVDNS_LOCK(base);\n\twhile ((victim = TAILQ_FIRST(&base->hostsdb))) {\n\t\tTAILQ_REMOVE(&base->hostsdb, victim, next);\n\t\tmm_free(victim);\n\t}\n\tEVDNS_UNLOCK(base);\n}\n\nvoid\nevdns_shutdown(int fail_requests)\n{\n\tif (current_base) {\n\t\tstruct evdns_base *b = current_base;\n\t\tcurrent_base = NULL;\n\t\tevdns_base_free(b, fail_requests);\n\t}\n\tevdns_log_fn = NULL;\n}\n\nstatic int\nevdns_base_parse_hosts_line(struct evdns_base *base, char *line)\n{\n\tchar *strtok_state;\n\tstatic const char *const delims = \" \\t\";\n\tchar *const addr = strtok_r(line, delims, &strtok_state);\n\tchar *hostname, *hash;\n\tstruct sockaddr_storage ss;\n\tint socklen = sizeof(ss);\n\tASSERT_LOCKED(base);\n\n#define NEXT_TOKEN strtok_r(NULL, delims, &strtok_state)\n\n\tif (!addr || *addr == '#')\n\t\treturn 0;\n\n\tmemset(&ss, 0, sizeof(ss));\n\tif (evutil_parse_sockaddr_port(addr, (struct sockaddr*)&ss, &socklen)<0)\n\t\treturn -1;\n\tif (socklen > (int)sizeof(struct sockaddr_in6))\n\t\treturn -1;\n\n\tif (sockaddr_getport((struct sockaddr*)&ss))\n\t\treturn -1;\n\n\twhile ((hostname = NEXT_TOKEN)) {\n\t\tstruct hosts_entry *he;\n\t\tsize_t namelen;\n\t\tif ((hash = strchr(hostname, '#'))) {\n\t\t\tif (hash == hostname)\n\t\t\t\treturn 0;\n\t\t\t*hash = '\\0';\n\t\t}\n\n\t\tnamelen = strlen(hostname);\n\n\t\the = mm_calloc(1, sizeof(struct hosts_entry)+namelen);\n\t\tif (!he)\n\t\t\treturn -1;\n\t\tEVUTIL_ASSERT(socklen <= (int)sizeof(he->addr));\n\t\tmemcpy(&he->addr, &ss, socklen);\n\t\tmemcpy(he->hostname, hostname, namelen+1);\n\t\the->addrlen = socklen;\n\n\t\tTAILQ_INSERT_TAIL(&base->hostsdb, he, next);\n\n\t\tif (hash)\n\t\t\treturn 0;\n\t}\n\n\treturn 0;\n#undef NEXT_TOKEN\n}\n\nstatic int\nevdns_base_load_hosts_impl(struct evdns_base *base, const char *hosts_fname)\n{\n\tchar *str=NULL, *cp, *eol;\n\tsize_t len;\n\tint err=0;\n\n\tASSERT_LOCKED(base);\n\n\tif (hosts_fname == NULL ||\n\t    (err = evutil_read_file_(hosts_fname, &str, &len, 0)) < 0) {\n\t\tchar tmp[64];\n\t\tstrlcpy(tmp, \"127.0.0.1   localhost\", sizeof(tmp));\n\t\tevdns_base_parse_hosts_line(base, tmp);\n\t\tstrlcpy(tmp, \"::1   localhost\", sizeof(tmp));\n\t\tevdns_base_parse_hosts_line(base, tmp);\n\t\treturn err ? -1 : 0;\n\t}\n\n\t/* This will break early if there is a NUL in the hosts file.\n\t * Probably not a problem.*/\n\tcp = str;\n\tfor (;;) {\n\t\teol = strchr(cp, '\\n');\n\n\t\tif (eol) {\n\t\t\t*eol = '\\0';\n\t\t\tevdns_base_parse_hosts_line(base, cp);\n\t\t\tcp = eol+1;\n\t\t} else {\n\t\t\tevdns_base_parse_hosts_line(base, cp);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmm_free(str);\n\treturn 0;\n}\n\nint\nevdns_base_load_hosts(struct evdns_base *base, const char *hosts_fname)\n{\n\tint res;\n\tif (!base)\n\t\tbase = current_base;\n\tEVDNS_LOCK(base);\n\tres = evdns_base_load_hosts_impl(base, hosts_fname);\n\tEVDNS_UNLOCK(base);\n\treturn res;\n}\n\n/* A single request for a getaddrinfo, either v4 or v6. */\nstruct getaddrinfo_subrequest {\n\tstruct evdns_request *r;\n\tev_uint32_t type;\n};\n\n/* State data used to implement an in-progress getaddrinfo. */\nstruct evdns_getaddrinfo_request {\n\tstruct evdns_base *evdns_base;\n\t/* Copy of the modified 'hints' data that we'll use to build\n\t * answers. */\n\tstruct evutil_addrinfo hints;\n\t/* The original requested nodename */\n\tchar *nodename;\n\t/* The callback to invoke when we're done */\n\tevdns_getaddrinfo_cb user_cb;\n\t/* User-supplied data to give to the callback. */\n\tvoid *user_data;\n\t/* The port to use when building sockaddrs. */\n\tev_uint16_t port;\n\t/* The sub_request for an A record (if any) */\n\tstruct getaddrinfo_subrequest ipv4_request;\n\t/* The sub_request for an AAAA record (if any) */\n\tstruct getaddrinfo_subrequest ipv6_request;\n\n\t/* The cname result that we were told (if any) */\n\tchar *cname_result;\n\n\t/* If we have one request answered and one request still inflight,\n\t * then this field holds the answer from the first request... */\n\tstruct evutil_addrinfo *pending_result;\n\tint pending_result_ttl;\n\t/* And this event is a timeout that will tell us to cancel the second\n\t * request if it's taking a long time. */\n\tstruct event timeout;\n\n\t/* And this field holds the error code from the first request... */\n\tint pending_error;\n\t/* If this is set, the user canceled this request. */\n\tunsigned user_canceled : 1;\n\t/* If this is set, the user can no longer cancel this request; we're\n\t * just waiting for the free. */\n\tunsigned request_done : 1;\n};\n\n/* Convert an evdns errors to the equivalent getaddrinfo error. */\nstatic int\nevdns_err_to_getaddrinfo_err(int e1)\n{\n\t/* XXX Do this better! */\n\tif (e1 == DNS_ERR_NONE)\n\t\treturn 0;\n\telse if (e1 == DNS_ERR_NOTEXIST)\n\t\treturn EVUTIL_EAI_NONAME;\n\telse\n\t\treturn EVUTIL_EAI_FAIL;\n}\n\n/* Return the more informative of two getaddrinfo errors. */\nstatic int\ngetaddrinfo_merge_err(int e1, int e2)\n{\n\t/* XXXX be cleverer here. */\n\tif (e1 == 0)\n\t\treturn e2;\n\telse\n\t\treturn e1;\n}\n\nstatic void\nfree_getaddrinfo_request(struct evdns_getaddrinfo_request *data)\n{\n\t/* DO NOT CALL this if either of the requests is pending.  Only once\n\t * both callbacks have been invoked is it safe to free the request */\n\tif (data->pending_result)\n\t\tevutil_freeaddrinfo(data->pending_result);\n\tif (data->cname_result)\n\t\tmm_free(data->cname_result);\n\tevent_del(&data->timeout);\n\tmm_free(data->nodename);\n\tmm_free(data);\n\treturn;\n}\n\nstatic void\nadd_cname_to_reply(struct evdns_getaddrinfo_request *data,\n    struct evutil_addrinfo *ai)\n{\n\tif (data->cname_result && ai) {\n\t\tai->ai_canonname = data->cname_result;\n\t\tdata->cname_result = NULL;\n\t}\n}\n\n/* Callback: invoked when one request in a mixed-format A/AAAA getaddrinfo\n * request has finished, but the other one took too long to answer. Pass\n * along the answer we got, and cancel the other request.\n */\nstatic void\nevdns_getaddrinfo_timeout_cb(evutil_socket_t fd, short what, void *ptr)\n{\n\tint v4_timedout = 0, v6_timedout = 0;\n\tstruct evdns_getaddrinfo_request *data = ptr;\n\n\t/* Cancel any pending requests, and note which one */\n\tif (data->ipv4_request.r) {\n\t\t/* XXXX This does nothing if the request's callback is already\n\t\t * running (pending_cb is set). */\n\t\tevdns_cancel_request(NULL, data->ipv4_request.r);\n\t\tv4_timedout = 1;\n\t\tEVDNS_LOCK(data->evdns_base);\n\t\t++data->evdns_base->getaddrinfo_ipv4_timeouts;\n\t\tEVDNS_UNLOCK(data->evdns_base);\n\t}\n\tif (data->ipv6_request.r) {\n\t\t/* XXXX This does nothing if the request's callback is already\n\t\t * running (pending_cb is set). */\n\t\tevdns_cancel_request(NULL, data->ipv6_request.r);\n\t\tv6_timedout = 1;\n\t\tEVDNS_LOCK(data->evdns_base);\n\t\t++data->evdns_base->getaddrinfo_ipv6_timeouts;\n\t\tEVDNS_UNLOCK(data->evdns_base);\n\t}\n\n\t/* We only use this timeout callback when we have an answer for\n\t * one address. */\n\tEVUTIL_ASSERT(!v4_timedout || !v6_timedout);\n\n\t/* Report the outcome of the other request that didn't time out. */\n\tif (data->pending_result) {\n\t\tadd_cname_to_reply(data, data->pending_result);\n\t\tdata->user_cb(0, data->pending_result, data->user_data);\n\t\tdata->pending_result = NULL;\n\t} else {\n\t\tint e = data->pending_error;\n\t\tif (!e)\n\t\t\te = EVUTIL_EAI_AGAIN;\n\t\tdata->user_cb(e, NULL, data->user_data);\n\t}\n\n\tdata->user_cb = NULL; /* prevent double-call if evdns callbacks are\n\t\t\t       * in-progress. XXXX It would be better if this\n\t\t\t       * weren't necessary. */\n\n\tif (!v4_timedout && !v6_timedout) {\n\t\t/* should be impossible? XXXX */\n\t\tfree_getaddrinfo_request(data);\n\t}\n}\n\nstatic int\nevdns_getaddrinfo_set_timeout(struct evdns_base *evdns_base,\n    struct evdns_getaddrinfo_request *data)\n{\n\treturn event_add(&data->timeout, &evdns_base->global_getaddrinfo_allow_skew);\n}\n\nstatic inline int\nevdns_result_is_answer(int result)\n{\n\treturn (result != DNS_ERR_NOTIMPL && result != DNS_ERR_REFUSED &&\n\t    result != DNS_ERR_SERVERFAILED && result != DNS_ERR_CANCEL);\n}\n\nstatic void\nevdns_ttl_expired(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct evdns_cache *cache = arg;\n\tstruct evdns_base *base = cache->base;\n\tlog(EVDNS_LOG_DEBUG, \"Expiring cache for %s\", cache->name);\n\tEVDNS_LOCK(base);\n\tevdns_cache_free(cache);\n\tEVDNS_UNLOCK(base);\n}\n\nvoid\nevdns_cache_write(struct evdns_base *dns_base, char *nodename, struct evutil_addrinfo *res, int ttl)\n{\n\tstruct timeval tv;\n\tstruct evdns_cache *cache;\n\tstruct evdns_cache find;\n\n\tlog(EVDNS_LOG_DEBUG, \"Writing cache for %s\", nodename);\n\tEVDNS_LOCK(dns_base);\n\tfind.name = (char *)nodename;\n\tcache = SPLAY_FIND(evdns_tree, &dns_base->cache_root, &find);\n\tif (cache) {\n\t\tlog(EVDNS_LOG_DEBUG, \"Ejecting old cache for %s\", nodename);\n\t\tevdns_cache_free(cache);\n\t}\n\tif (res) {\n\t\tcache = mm_calloc(1, sizeof(struct evdns_cache));\n\t\tcache->base = dns_base;\n\t\tcache->name = mm_strdup(nodename);\n\t\tcache->ai = evutil_dup_addrinfo_(res);\n\t\tSPLAY_INSERT(evdns_tree, &cache->base->cache_root, cache);\n\t\tevtimer_assign(&cache->ev_timeout, dns_base->event_base, evdns_ttl_expired, cache);\n\t\ttimerclear(&tv);\n\t\ttv.tv_sec = ttl;\n\t\tevtimer_add(&cache->ev_timeout, &tv);\n\t}\n\tEVDNS_UNLOCK(dns_base);\n}\n\nint\nevdns_cache_lookup(struct evdns_base *base,\n    const char *nodename, struct evutil_addrinfo *hints, ev_uint16_t port,\n    struct evutil_addrinfo **res)\n{\n\tint n_found = 0;\n\tstruct evdns_cache *cache;\n\tstruct evdns_cache find;\n\tstruct evutil_addrinfo *ai = NULL;\n\tint want_cname = hints->ai_flags & EVUTIL_AI_CANONNAME;\n\tint f = hints->ai_family;\n\n\tlog(EVDNS_LOG_DEBUG, \"Looking in cache for %s\", nodename);\n\tEVDNS_LOCK(base);\n\tfind.name = (char *)nodename;\n\tcache = SPLAY_FIND(evdns_tree, &base->cache_root, &find);\n\tif (cache) {\n\t\tstruct evutil_addrinfo *e = cache->ai;\n\t\tlog(EVDNS_LOG_DEBUG, \"Found cache for %s\", cache->name);\n\t\tfor (; e; e = e->ai_next) {\n\t\t\tstruct evutil_addrinfo *ai_new;\n\t\t\t// an existing record might not have the canonname\n\t\t\tif (want_cname && e->ai_canonname == NULL)\n\t\t\t\tcontinue;\n\t\t\t++n_found;\n\t\t\tif ((e->ai_addr->sa_family == AF_INET && f == PF_INET6) ||\n\t\t\t\t(e->ai_addr->sa_family == AF_INET6 && f == PF_INET))\n\t\t\t\tcontinue;\n\t\t\tai_new = evutil_new_addrinfo_(e->ai_addr, e->ai_addrlen, hints);\n\t\t\tif (want_cname) {\n\t\t\t\tai_new->ai_canonname = mm_strdup(e->ai_canonname);\n\t\t\t}\n\t\t\tif (!ai_new) {\n\t\t\t\tn_found = 0;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsockaddr_setport(ai_new->ai_addr, port);\n\t\t\tai = evutil_addrinfo_append_(ai, ai_new);\n\t\t}\n\t}\n\tEVDNS_UNLOCK(base);\nout:\n\tif (n_found) {\n\t\tif (!ai) {\n\t\t\treturn EVUTIL_EAI_ADDRFAMILY;\n\t\t}\n\t\t*res = ai;\n\t\treturn 0;\n\t} else {\n\t\tif (ai)\n\t\t\tevutil_freeaddrinfo(ai);\n\t\treturn -1;\n\t}\n}\n\nstatic void\nevdns_getaddrinfo_gotresolve(int result, char type, int count,\n    int ttl, void *addresses, void *arg)\n{\n\tint i;\n\tstruct getaddrinfo_subrequest *req = arg;\n\tstruct getaddrinfo_subrequest *other_req;\n\tstruct evdns_getaddrinfo_request *data;\n\n\tstruct evutil_addrinfo *res;\n\n\tstruct sockaddr_in sin;\n\tstruct sockaddr_in6 sin6;\n\tstruct sockaddr *sa;\n\tint socklen, addrlen;\n\tvoid *addrp;\n\tint err;\n\tint user_canceled;\n\n\tEVUTIL_ASSERT(req->type == DNS_IPv4_A || req->type == DNS_IPv6_AAAA);\n\tif (req->type == DNS_IPv4_A) {\n\t\tdata = EVUTIL_UPCAST(req, struct evdns_getaddrinfo_request, ipv4_request);\n\t\tother_req = &data->ipv6_request;\n\t} else {\n\t\tdata = EVUTIL_UPCAST(req, struct evdns_getaddrinfo_request, ipv6_request);\n\t\tother_req = &data->ipv4_request;\n\t}\n\n\t/** Called from evdns_base_free() with @fail_requests == 1 */\n\tif (result != DNS_ERR_SHUTDOWN) {\n\t\tEVDNS_LOCK(data->evdns_base);\n\t\tif (evdns_result_is_answer(result)) {\n\t\t\tif (req->type == DNS_IPv4_A)\n\t\t\t\t++data->evdns_base->getaddrinfo_ipv4_answered;\n\t\t\telse\n\t\t\t\t++data->evdns_base->getaddrinfo_ipv6_answered;\n\t\t}\n\t\tuser_canceled = data->user_canceled;\n\t\tif (other_req->r == NULL)\n\t\t\tdata->request_done = 1;\n\t\tEVDNS_UNLOCK(data->evdns_base);\n\t} else {\n\t\tdata->evdns_base = NULL;\n\t\tuser_canceled = data->user_canceled;\n\t}\n\n\treq->r = NULL;\n\n\tif (result == DNS_ERR_CANCEL && ! user_canceled) {\n\t\t/* Internal cancel request from timeout or internal error.\n\t\t * we already answered the user. */\n\t\tif (other_req->r == NULL)\n\t\t\tfree_getaddrinfo_request(data);\n\t\treturn;\n\t}\n\n\tif (data->user_cb == NULL) {\n\t\t/* We already answered.  XXXX This shouldn't be needed; see\n\t\t * comments in evdns_getaddrinfo_timeout_cb */\n\t\tfree_getaddrinfo_request(data);\n\t\treturn;\n\t}\n\n\tif (result == DNS_ERR_NONE) {\n\t\tif (count == 0)\n\t\t\terr = EVUTIL_EAI_NODATA;\n\t\telse\n\t\t\terr = 0;\n\t} else {\n\t\terr = evdns_err_to_getaddrinfo_err(result);\n\t}\n\n\tif (err) {\n\t\t/* Looks like we got an error. */\n\t\tif (other_req->r) {\n\t\t\t/* The other request is still working; maybe it will\n\t\t\t * succeed. */\n\t\t\t/* XXXX handle failure from set_timeout */\n\t\t\tif (result != DNS_ERR_SHUTDOWN) {\n\t\t\t\tevdns_getaddrinfo_set_timeout(data->evdns_base, data);\n\t\t\t}\n\t\t\tdata->pending_error = err;\n\t\t\treturn;\n\t\t}\n\n\t\tif (user_canceled) {\n\t\t\tdata->user_cb(EVUTIL_EAI_CANCEL, NULL, data->user_data);\n\t\t} else if (data->pending_result) {\n\t\t\t/* If we have an answer waiting, and we weren't\n\t\t\t * canceled, ignore this error. */\n\t\t\tadd_cname_to_reply(data, data->pending_result);\n\t\t\tif (data->evdns_base && !data->evdns_base->disable_cache) {\n\t\t\t\tevdns_cache_write(data->evdns_base, data->nodename, data->pending_result, data->pending_result_ttl);\n\t\t\t}\n\t\t\tdata->user_cb(0, data->pending_result, data->user_data);\n\t\t\tdata->pending_result = NULL;\n\t\t} else {\n\t\t\tif (data->pending_error)\n\t\t\t\terr = getaddrinfo_merge_err(err,\n\t\t\t\t    data->pending_error);\n\t\t\tdata->user_cb(err, NULL, data->user_data);\n\t\t}\n\t\tfree_getaddrinfo_request(data);\n\t\treturn;\n\t} else if (user_canceled) {\n\t\tif (other_req->r) {\n\t\t\t/* The other request is still working; let it hit this\n\t\t\t * callback with EVUTIL_EAI_CANCEL callback and report\n\t\t\t * the failure. */\n\t\t\treturn;\n\t\t}\n\t\tdata->user_cb(EVUTIL_EAI_CANCEL, NULL, data->user_data);\n\t\tfree_getaddrinfo_request(data);\n\t\treturn;\n\t}\n\n\t/* Looks like we got some answers. We should turn them into addrinfos\n\t * and then either queue those or return them all. */\n\tEVUTIL_ASSERT(type == DNS_IPv4_A || type == DNS_IPv6_AAAA);\n\n\tif (type == DNS_IPv4_A) {\n\t\tmemset(&sin, 0, sizeof(sin));\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_port = htons(data->port);\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN\n\t\tsin.sin_len = sizeof(sin);\n#endif\n\n\t\tsa = (struct sockaddr *)&sin;\n\t\tsocklen = sizeof(sin);\n\t\taddrlen = 4;\n\t\taddrp = &sin.sin_addr.s_addr;\n\t} else {\n\t\tmemset(&sin6, 0, sizeof(sin6));\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_port = htons(data->port);\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN6_SIN6_LEN\n\t\tsin6.sin6_len = sizeof(sin6);\n#endif\n\n\t\tsa = (struct sockaddr *)&sin6;\n\t\tsocklen = sizeof(sin6);\n\t\taddrlen = 16;\n\t\taddrp = &sin6.sin6_addr.s6_addr;\n\t}\n\n\tres = NULL;\n\tfor (i=0; i < count; ++i) {\n\t\tstruct evutil_addrinfo *ai;\n\t\tmemcpy(addrp, ((char*)addresses)+i*addrlen, addrlen);\n\t\tai = evutil_new_addrinfo_(sa, socklen, &data->hints);\n\t\tif (!ai) {\n\t\t\tif (other_req->r) {\n\t\t\t\tevdns_cancel_request(NULL, other_req->r);\n\t\t\t}\n\t\t\tdata->user_cb(EVUTIL_EAI_MEMORY, NULL, data->user_data);\n\t\t\tif (res)\n\t\t\t\tevutil_freeaddrinfo(res);\n\n\t\t\tif (other_req->r == NULL)\n\t\t\t\tfree_getaddrinfo_request(data);\n\t\t\treturn;\n\t\t}\n\t\tres = evutil_addrinfo_append_(res, ai);\n\t}\n\n\tif (other_req->r) {\n\t\t/* The other request is still in progress; wait for it */\n\t\t/* XXXX handle failure from set_timeout */\n\t\tevdns_getaddrinfo_set_timeout(data->evdns_base, data);\n\t\tdata->pending_result = res;\n\t\tdata->pending_result_ttl = ttl;\n\t\treturn;\n\t} else {\n\t\t/* The other request is done or never started; append its\n\t\t * results (if any) and return them. */\n\t\tint res_ttl = ttl;\n\t\tif (data->pending_result) {\n\t\t\tif (req->type == DNS_IPv4_A)\n\t\t\t\tres = evutil_addrinfo_append_(res,\n\t\t\t\t    data->pending_result);\n\t\t\telse\n\t\t\t\tres = evutil_addrinfo_append_(\n\t\t\t\t    data->pending_result, res);\n\t\t\tres_ttl = data->pending_result_ttl;\n\t\t\tdata->pending_result = NULL;\n\t\t}\n\n\t\t/* Call the user callback. */\n\t\tadd_cname_to_reply(data, res);\n\t\tif (data->evdns_base && !data->evdns_base->disable_cache) {\n\t\t\tevdns_cache_write(data->evdns_base, data->nodename, res, res_ttl);\n\t\t}\n\t\tdata->user_cb(0, res, data->user_data);\n\n\t\t/* Free data. */\n\t\tfree_getaddrinfo_request(data);\n\t}\n}\n\nstatic struct hosts_entry *\nfind_hosts_entry(struct evdns_base *base, const char *hostname,\n    struct hosts_entry *find_after)\n{\n\tstruct hosts_entry *e;\n\n\tif (find_after)\n\t\te = TAILQ_NEXT(find_after, next);\n\telse\n\t\te = TAILQ_FIRST(&base->hostsdb);\n\n\tfor (; e; e = TAILQ_NEXT(e, next)) {\n\t\tif (!evutil_ascii_strcasecmp(e->hostname, hostname))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}\n\nstatic int\nevdns_getaddrinfo_fromhosts(struct evdns_base *base,\n    const char *nodename, struct evutil_addrinfo *hints, ev_uint16_t port,\n    struct evutil_addrinfo **res)\n{\n\tint n_found = 0;\n\tstruct hosts_entry *e;\n\tstruct evutil_addrinfo *ai = NULL;\n\tint f = hints->ai_family;\n\n\tEVDNS_LOCK(base);\n\tfor (e = find_hosts_entry(base, nodename, NULL); e;\n\t    e = find_hosts_entry(base, nodename, e)) {\n\t\tstruct evutil_addrinfo *ai_new;\n\t\t++n_found;\n\t\tif ((e->addr.sa.sa_family == AF_INET && f == PF_INET6) ||\n\t\t    (e->addr.sa.sa_family == AF_INET6 && f == PF_INET))\n\t\t\tcontinue;\n\t\tai_new = evutil_new_addrinfo_(&e->addr.sa, e->addrlen, hints);\n\t\tif (!ai_new) {\n\t\t\tn_found = 0;\n\t\t\tgoto out;\n\t\t}\n\t\tsockaddr_setport(ai_new->ai_addr, port);\n\t\tai = evutil_addrinfo_append_(ai, ai_new);\n\t}\n\tEVDNS_UNLOCK(base);\nout:\n\tif (n_found) {\n\t\tif (!ai) {\n\t\t\treturn EVUTIL_EAI_ADDRFAMILY;\n\t\t}\n\t\t*res = ai;\n\t\treturn 0;\n\t} else {\n\t\tif (ai)\n\t\t\tevutil_freeaddrinfo(ai);\n\t\treturn -1;\n\t}\n}\n\nstruct evdns_getaddrinfo_request *\nevdns_getaddrinfo(struct evdns_base *dns_base,\n    const char *nodename, const char *servname,\n    const struct evutil_addrinfo *hints_in,\n    evdns_getaddrinfo_cb cb, void *arg)\n{\n\tstruct evdns_getaddrinfo_request *data;\n\tstruct evutil_addrinfo hints;\n\tstruct evutil_addrinfo *res = NULL;\n\tint err;\n\tint port = 0;\n\tint want_cname = 0;\n\tint started = 0;\n\n\tif (!dns_base) {\n\t\tdns_base = current_base;\n\t\tif (!dns_base) {\n\t\t\tlog(EVDNS_LOG_WARN,\n\t\t\t    \"Call to getaddrinfo_async with no \"\n\t\t\t    \"evdns_base configured.\");\n\t\t\tcb(EVUTIL_EAI_FAIL, NULL, arg); /* ??? better error? */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* If we _must_ answer this immediately, do so. */\n\tif ((hints_in && (hints_in->ai_flags & EVUTIL_AI_NUMERICHOST))) {\n\t\tres = NULL;\n\t\terr = evutil_getaddrinfo(nodename, servname, hints_in, &res);\n\t\tcb(err, res, arg);\n\t\treturn NULL;\n\t}\n\n\tif (hints_in) {\n\t\tmemcpy(&hints, hints_in, sizeof(hints));\n\t} else {\n\t\tmemset(&hints, 0, sizeof(hints));\n\t\thints.ai_family = PF_UNSPEC;\n\t}\n\n\tevutil_adjust_hints_for_addrconfig_(&hints);\n\n\t/* Now try to see if we _can_ answer immediately. */\n\t/* (It would be nice to do this by calling getaddrinfo directly, with\n\t * AI_NUMERICHOST, on platforms that have it, but we can't: there isn't\n\t * a reliable way to distinguish the \"that wasn't a numeric host!\" case\n\t * from any other EAI_NONAME cases.) */\n\terr = evutil_getaddrinfo_common_(nodename, servname, &hints, &res, &port);\n\tif (err != EVUTIL_EAI_NEED_RESOLVE) {\n\t\tcb(err, res, arg);\n\t\treturn NULL;\n\t}\n\n\t/* If there is an entry in the hosts file, we should give it now. */\n\terr = evdns_getaddrinfo_fromhosts(dns_base, nodename, &hints, port, &res);\n\tif (!err || err == EVUTIL_EAI_ADDRFAMILY) {\n\t\tcb(err, res, arg);\n\t\treturn NULL;\n\t}\n\n\t/* See if we have it in the cache */\n\tif (!dns_base->disable_cache) {\n\t\terr = evdns_cache_lookup(dns_base, nodename, &hints, port, &res);\n\t\tif (!err || err == EVUTIL_EAI_ADDRFAMILY) {\n\t\t\tcb(err, res, arg);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Okay, things are serious now. We're going to need to actually\n\t * launch a request.\n\t */\n\tdata = mm_calloc(1,sizeof(struct evdns_getaddrinfo_request));\n\tif (!data) {\n\t\tcb(EVUTIL_EAI_MEMORY, NULL, arg);\n\t\treturn NULL;\n\t}\n\n\tmemcpy(&data->hints, &hints, sizeof(data->hints));\n\tdata->port = (ev_uint16_t)port;\n\tdata->ipv4_request.type = DNS_IPv4_A;\n\tdata->ipv6_request.type = DNS_IPv6_AAAA;\n\tdata->user_cb = cb;\n\tdata->user_data = arg;\n\tdata->evdns_base = dns_base;\n\tdata->nodename = mm_strdup(nodename);\n\n\twant_cname = (hints.ai_flags & EVUTIL_AI_CANONNAME);\n\n\t/* If we are asked for a PF_UNSPEC address, we launch two requests in\n\t * parallel: one for an A address and one for an AAAA address.  We\n\t * can't send just one request, since many servers only answer one\n\t * question per DNS request.\n\t *\n\t * Once we have the answer to one request, we allow for a short\n\t * timeout before we report it, to see if the other one arrives.  If\n\t * they both show up in time, then we report both the answers.\n\t *\n\t * If too many addresses of one type time out or fail, we should stop\n\t * launching those requests. (XXX we don't do that yet.)\n\t */\n\n\tEVDNS_LOCK(dns_base);\n\n\tif (hints.ai_family != PF_INET6) {\n\t\tlog(EVDNS_LOG_DEBUG, \"Sending request for %s on ipv4 as %p\",\n\t\t    nodename, (void *)&data->ipv4_request);\n\n\t\tdata->ipv4_request.r = evdns_base_resolve_ipv4(dns_base,\n\t\t    nodename, 0, evdns_getaddrinfo_gotresolve,\n\t\t    &data->ipv4_request);\n\t\tif (want_cname && data->ipv4_request.r)\n\t\t\tdata->ipv4_request.r->current_req->put_cname_in_ptr =\n\t\t\t    &data->cname_result;\n\t}\n\tif (hints.ai_family != PF_INET) {\n\t\tlog(EVDNS_LOG_DEBUG, \"Sending request for %s on ipv6 as %p\",\n\t\t    nodename, (void *)&data->ipv6_request);\n\n\t\tdata->ipv6_request.r = evdns_base_resolve_ipv6(dns_base,\n\t\t    nodename, 0, evdns_getaddrinfo_gotresolve,\n\t\t    &data->ipv6_request);\n\t\tif (want_cname && data->ipv6_request.r)\n\t\t\tdata->ipv6_request.r->current_req->put_cname_in_ptr =\n\t\t\t    &data->cname_result;\n\t}\n\n\tevtimer_assign(&data->timeout, dns_base->event_base,\n\t    evdns_getaddrinfo_timeout_cb, data);\n\n\tstarted = (data->ipv4_request.r || data->ipv6_request.r);\n\n\tEVDNS_UNLOCK(dns_base);\n\n\tif (started) {\n\t\treturn data;\n\t} else {\n\t\tfree_getaddrinfo_request(data);\n\t\tcb(EVUTIL_EAI_FAIL, NULL, arg);\n\t\treturn NULL;\n\t}\n}\n\nvoid\nevdns_getaddrinfo_cancel(struct evdns_getaddrinfo_request *data)\n{\n\tEVDNS_LOCK(data->evdns_base);\n\tif (data->request_done) {\n\t\tEVDNS_UNLOCK(data->evdns_base);\n\t\treturn;\n\t}\n\tevent_del(&data->timeout);\n\tdata->user_canceled = 1;\n\tif (data->ipv4_request.r)\n\t\tevdns_cancel_request(data->evdns_base, data->ipv4_request.r);\n\tif (data->ipv6_request.r)\n\t\tevdns_cancel_request(data->evdns_base, data->ipv6_request.r);\n\tEVDNS_UNLOCK(data->evdns_base);\n}\n"
        },
        {
          "name": "event-config.h.cmake",
          "type": "blob",
          "size": 14.7919921875,
          "content": "/* event-config.h\n *\n * This file was generated by cmake when the makefiles were generated.\n *\n * DO NOT EDIT THIS FILE.\n *\n * Do not rely on macros in this file existing in later versions.\n */\n#ifndef EVENT2_EVENT_CONFIG_H_INCLUDED_\n#define EVENT2_EVENT_CONFIG_H_INCLUDED_\n\n/* Numeric representation of the version */\n#define EVENT__NUMERIC_VERSION @EVENT_NUMERIC_VERSION@\n#define EVENT__PACKAGE_VERSION \"@EVENT_PACKAGE_VERSION@\"\n\n#define EVENT__VERSION_MAJOR @EVENT_VERSION_MAJOR@\n#define EVENT__VERSION_MINOR @EVENT_VERSION_MINOR@\n#define EVENT__VERSION_PATCH @EVENT_VERSION_PATCH@\n\n/* Version number of package */\n#define EVENT__VERSION \"@EVENT_VERSION@\"\n\n/* Name of package */\n#define EVENT__PACKAGE \"libevent\"\n\n/* Define to the address where bug reports for this package should be sent. */\n#define EVENT__PACKAGE_BUGREPORT \"\"\n\n/* Define to the full name of this package. */\n#define EVENT__PACKAGE_NAME \"\"\n\n/* Define to the full name and version of this package. */\n#define EVENT__PACKAGE_STRING \"\"\n\n/* Define to the one symbol short name of this package. */\n#define EVENT__PACKAGE_TARNAME \"\"\n\n/* Define if libevent should build without support for a debug mode */\n#cmakedefine EVENT__DISABLE_DEBUG_MODE 1\n\n/* Define if libevent should not allow replacing the mm functions */\n#cmakedefine EVENT__DISABLE_MM_REPLACEMENT 1\n\n/* Define if libevent should not be compiled with thread support */\n#cmakedefine EVENT__DISABLE_THREAD_SUPPORT 1\n\n/* Define to 1 if you have the `accept4' function. */\n#cmakedefine EVENT__HAVE_ACCEPT4 1\n\n/* Define to 1 if you have the `arc4random' function. */\n#cmakedefine EVENT__HAVE_ARC4RANDOM 1\n\n/* Define to 1 if you have the `arc4random_buf' function. */\n#cmakedefine EVENT__HAVE_ARC4RANDOM_BUF 1\n\n/* Define to 1 if you have the `arc4random_stir' function. */\n#cmakedefine EVENT__HAVE_ARC4RANDOM_STIR 1\n\n/* Define to 1 if you have the <arpa/inet.h> header file. */\n#cmakedefine EVENT__HAVE_ARPA_INET_H 1\n\n/* Define to 1 if you have the `clock_gettime' function. */\n#cmakedefine EVENT__HAVE_CLOCK_GETTIME 1\n\n/* Define to 1 if you have the declaration of `CTL_KERN'. */\n#define EVENT__HAVE_DECL_CTL_KERN @EVENT__HAVE_DECL_CTL_KERN@\n\n/* Define to 1 if you have the declaration of `KERN_ARND'. */\n#define EVENT__HAVE_DECL_KERN_ARND @EVENT__HAVE_DECL_KERN_ARND@\n\n/* Define to 1 if you have `getrandom' function. */\n#cmakedefine EVENT__HAVE_GETRANDOM 1\n\n/* Define if /dev/poll is available */\n#cmakedefine EVENT__HAVE_DEVPOLL 1\n\n/* Define to 1 if you have the <netdb.h> header file. */\n#cmakedefine EVENT__HAVE_NETDB_H 1\n\n/* Define to 1 if fd_mask type is defined */\n#cmakedefine EVENT__HAVE_FD_MASK 1\n\n/* Define if your system supports the epoll system calls */\n#cmakedefine EVENT__HAVE_EPOLL 1\n\n/* Define to 1 if you have the `epoll_create1' function. */\n#cmakedefine EVENT__HAVE_EPOLL_CREATE1 1\n\n/* Define to 1 if you have the `epoll_pwait2' function. */\n#cmakedefine EVENT__HAVE_EPOLL_PWAIT2 1\n\n/* Define if your system supports the wepoll module */\n#cmakedefine EVENT__HAVE_WEPOLL 1\n\n/* Define to 1 if you have the `eventfd' function. */\n#cmakedefine EVENT__HAVE_EVENTFD 1\n\n/* Define if your system supports event ports */\n#cmakedefine EVENT__HAVE_EVENT_PORTS 1\n\n/* Define to 1 if you have the `fcntl' function. */\n#cmakedefine EVENT__HAVE_FCNTL 1\n\n/* Define to 1 if you have the <fcntl.h> header file. */\n#cmakedefine EVENT__HAVE_FCNTL_H 1\n\n/* Define to 1 if you have the `getaddrinfo' function. */\n#cmakedefine EVENT__HAVE_GETADDRINFO 1\n\n/* Define to 1 if you have the `getegid' function. */\n#cmakedefine EVENT__HAVE_GETEGID 1\n\n/* Define to 1 if you have the `geteuid' function. */\n#cmakedefine EVENT__HAVE_GETEUID 1\n\n/* TODO: Check for different gethostname argument counts. CheckPrototypeDefinition.cmake can be used. */\n/* Define this if you have any gethostbyname_r() */\n#cmakedefine EVENT__HAVE_GETHOSTBYNAME_R 1\n\n/* Define this if gethostbyname_r takes 3 arguments */\n#cmakedefine EVENT__HAVE_GETHOSTBYNAME_R_3_ARG 1\n\n/* Define this if gethostbyname_r takes 5 arguments */\n#cmakedefine EVENT__HAVE_GETHOSTBYNAME_R_5_ARG 1\n\n/* Define this if gethostbyname_r takes 6 arguments */\n#cmakedefine EVENT__HAVE_GETHOSTBYNAME_R_6_ARG 1\n\n/* Define to 1 if you have the `getifaddrs' function. */\n#cmakedefine EVENT__HAVE_GETIFADDRS 1\n\n/* Define to 1 if you have the `getnameinfo' function. */\n#cmakedefine EVENT__HAVE_GETNAMEINFO 1\n\n/* Define to 1 if you have the `getprotobynumber' function. */\n#cmakedefine EVENT__HAVE_GETPROTOBYNUMBER 1\n\n/* Define to 1 if you have the `getservbyname' function. */\n#cmakedefine EVENT__HAVE_GETSERVBYNAME 1\n\n/* Define to 1 if you have the `gettimeofday' function. */\n#cmakedefine EVENT__HAVE_GETTIMEOFDAY 1\n\n/* Define to 1 if you have the <ifaddrs.h> header file. */\n#cmakedefine EVENT__HAVE_IFADDRS_H 1\n\n/* Define to 1 if you have the `inet_ntop' function. */\n#cmakedefine EVENT__HAVE_INET_NTOP 1\n\n/* Define to 1 if you have the `inet_pton' function. */\n#cmakedefine EVENT__HAVE_INET_PTON 1\n\n/* Define to 1 if you have the <inttypes.h> header file. */\n#cmakedefine EVENT__HAVE_INTTYPES_H 1\n\n/* Define to 1 if you have the `issetugid' function. */\n#cmakedefine EVENT__HAVE_ISSETUGID 1\n\n/* Define to 1 if you have the `kqueue' function. */\n#cmakedefine EVENT__HAVE_KQUEUE 1\n\n/* Define if the system has zlib */\n#cmakedefine EVENT__HAVE_LIBZ 1\n\n/* Define to 1 if you have the `mach_absolute_time' function. */\n#cmakedefine EVENT__HAVE_MACH_ABSOLUTE_TIME 1\n\n/* Define to 1 if you have the <mach/mach_time.h> header file. */\n#cmakedefine EVENT__HAVE_MACH_MACH_TIME_H 1\n\n/* Define to 1 if you have the <mach/mach.h> header file. */\n#cmakedefine EVENT__HAVE_MACH_MACH_H 1\n\n/* Define to 1 if you have the `mmap' function. */\n#cmakedefine EVENT__HAVE_MMAP 1\n\n/* Define to 1 if you have the `mmap64' function. */\n#cmakedefine EVENT__HAVE_MMAP64 1\n\n/* Define to 1 if you have the `nanosleep' function. */\n#cmakedefine EVENT__HAVE_NANOSLEEP 1\n\n/* Define to 1 if you have the `usleep' function. */\n#cmakedefine EVENT__HAVE_USLEEP 1\n\n/* Define to 1 if you have the <netinet/in6.h> header file. */\n#cmakedefine EVENT__HAVE_NETINET_IN6_H 1\n\n/* Define to 1 if you have the <netinet/in.h> header file. */\n#cmakedefine EVENT__HAVE_NETINET_IN_H 1\n\n/* Define to 1 if you have the <netinet/tcp.h> header file. */\n#cmakedefine EVENT__HAVE_NETINET_TCP_H 1\n\n/* Define to 1 if you have the <sys/un.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_UN_H 1\n\n/* Define to 1 if you have the <afunix.h> header file. */\n#cmakedefine EVENT__HAVE_AFUNIX_H 1\n\n/* Define if the system has openssl */\n#cmakedefine EVENT__HAVE_OPENSSL 1\n\n/* Define if the system has mbedtls */\n#cmakedefine EVENT__HAVE_MBEDTLS 1\n\n/* Define to 1 if you have the `pipe' function. */\n#cmakedefine EVENT__HAVE_PIPE 1\n\n/* Define to 1 if you have the `pipe2' function. */\n#cmakedefine EVENT__HAVE_PIPE2 1\n\n/* Define to 1 if you have the `poll' function. */\n#cmakedefine EVENT__HAVE_POLL 1\n\n/* Define if we have pthreads on this system */\n#cmakedefine EVENT__HAVE_PTHREADS 1\n\n/* Define to 1 if you have the `pthread_mutexattr_setprotocol' function. */\n#cmakedefine EVENT__HAVE_PTHREAD_MUTEXATTR_SETPROTOCOL 1\n\n/* Define to 1 if you have the `putenv' function. */\n#cmakedefine EVENT__HAVE_PUTENV 1\n\n/* Define to 1 if the system has the type `sa_family_t'. */\n#cmakedefine EVENT__HAVE_SA_FAMILY_T 1\n\n/* Define to 1 if you have the `select' function. */\n#cmakedefine EVENT__HAVE_SELECT 1\n\n/* Define to 1 if you have the `setenv' function. */\n#cmakedefine EVENT__HAVE_SETENV 1\n\n/* Define if F_SETFD is defined in <fcntl.h> */\n#cmakedefine EVENT__HAVE_SETFD 1\n\n/* Define to 1 if you have the `setrlimit' function. */\n#cmakedefine EVENT__HAVE_SETRLIMIT 1\n\n/* Define to 1 if you have the `sendfile' function. */\n#cmakedefine EVENT__HAVE_SENDFILE 1\n\n/* Define to 1 if you have the `pread' function. */\n#cmakedefine EVENT__HAVE_PREAD 1\n\n/* Define to 1 if you have the `sigaction' function. */\n#cmakedefine EVENT__HAVE_SIGACTION 1\n\n/* Define to 1 if you have the `socketpair` function. */\n#cmakedefine EVENT__HAVE_SOCKETPAIR 1\n\n/* Define to 1 if you have the `strsignal' function. */\n#cmakedefine EVENT__HAVE_STRSIGNAL 1\n\n/* Define to 1 if you have the <stdarg.h> header file. */\n#cmakedefine EVENT__HAVE_STDARG_H 1\n\n/* Define to 1 if you have the <stddef.h> header file. */\n#cmakedefine EVENT__HAVE_STDDEF_H 1\n\n/* Define to 1 if you have the <stdint.h> header file. */\n#cmakedefine EVENT__HAVE_STDINT_H 1\n\n/* Define to 1 if you have the <stdlib.h> header file. */\n#cmakedefine EVENT__HAVE_STDLIB_H 1\n\n/* Define to 1 if you have the `strlcpy' function. */\n#cmakedefine EVENT__HAVE_STRLCPY 1\n\n/* Define to 1 if you have the `strsep' function. */\n#cmakedefine EVENT__HAVE_STRSEP 1\n\n/* Define to 1 if you have the `strtok_r' function. */\n#cmakedefine EVENT__HAVE_STRTOK_R 1\n\n/* Define to 1 if you have the `strtoll' function. */\n#cmakedefine EVENT__HAVE_STRTOLL 1\n\n/* Define to 1 if you have the `_gmtime64_s' function. */\n#cmakedefine EVENT__HAVE__GMTIME64_S 1\n\n/* Define to 1 if you have the `_gmtime64' function. */\n#cmakedefine EVENT__HAVE__GMTIME64 1\n\n/* Define to 1 if the system has the type `struct addrinfo'. */\n#cmakedefine EVENT__HAVE_STRUCT_ADDRINFO 1\n\n/* Define to 1 if the system has the type `struct in6_addr'. */\n#cmakedefine EVENT__HAVE_STRUCT_IN6_ADDR 1\n\n/* Define to 1 if the system has the type `struct sockaddr_in6'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_IN6 1\n\n/* Define to 1 if `sin6_len' is member of `struct sockaddr_in6'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_IN6_SIN6_LEN 1\n\n/* Define to 1 if `sin_len' is member of `struct sockaddr_in'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN 1\n\n/* Define to 1 if the system has the type `struct sockaddr_un'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_UN 1\n\n/* Define to 1 if the system has the type `struct sockaddr_storage'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_STORAGE 1\n\n/* Define to 1 if `ss_family' is a member of `struct sockaddr_storage'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_STORAGE_SS_FAMILY 1\n\n/* Define to 1 if `__ss_family' is a member of `struct sockaddr_storage'. */\n#cmakedefine EVENT__HAVE_STRUCT_SOCKADDR_STORAGE___SS_FAMILY 1\n\n/* Define to 1 if the system has the type `struct linger'. */\n#cmakedefine EVENT__HAVE_STRUCT_LINGER 1\n\n/* Define to 1 if you have the `sysctl' function. */\n#cmakedefine EVENT__HAVE_SYSCTL 1\n\n/* Define to 1 if you have the <sys/eventfd.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_EVENTFD_H 1\n\n/* Define to 1 if you have the <sys/ioctl.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_IOCTL_H 1\n\n/* Define to 1 if you have the <sys/mman.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_MMAN_H 1\n\n/* Define to 1 if you have the <sys/param.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_PARAM_H 1\n\n/* Define to 1 if you have the <sys/resource.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_RESOURCE_H 1\n\n/* Define to 1 if you have the <sys/select.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_SELECT_H 1\n\n/* Define to 1 if you have the <sys/sendfile.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_SENDFILE_H 1\n\n/* Define to 1 if you have the <sys/socket.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_SOCKET_H 1\n\n/* Define to 1 if you have the <sys/stat.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_STAT_H 1\n\n/* Define to 1 if you have the <sys/random.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_RANDOM_H 1\n\n/* Define to 1 if you have the <sys/sysctl.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_SYSCTL_H 1\n\n/* Define to 1 if you have the <sys/timerfd.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_TIMERFD_H 1\n\n/* Define to 1 if you have the <sys/signalfd.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_SIGNALFD_H 1\n\n/* Define to 1 if you have the <sys/time.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_TIME_H 1\n\n/* Define to 1 if you have the <sys/types.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_TYPES_H 1\n\n/* Define to 1 if you have the <sys/uio.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_UIO_H 1\n\n/* Define to 1 if you have the <sys/wait.h> header file. */\n#cmakedefine EVENT__HAVE_SYS_WAIT_H 1\n\n/* Define to 1 if you have the <errno.h> header file. */\n#cmakedefine EVENT__HAVE_ERRNO_H 1\n\n/* Define if timeradd is defined in <sys/time.h> */\n#cmakedefine EVENT__HAVE_TIMERADD 1\n\n/* Define if timerclear is defined in <sys/time.h> */\n#cmakedefine EVENT__HAVE_TIMERCLEAR 1\n\n/* Define to 1 if you have the `timerfd_create' function. */\n#cmakedefine EVENT__HAVE_TIMERFD_CREATE 1\n\n/* Define if timerisset is defined in <sys/time.h> */\n#cmakedefine EVENT__HAVE_TIMERISSET 1\n\n/* Define to 1 if the system has the type `uint8_t'. */\n#cmakedefine EVENT__HAVE_UINT8_T 1\n\n/* Define to 1 if the system has the type `uint16_t'. */\n#cmakedefine EVENT__HAVE_UINT16_T 1\n\n/* Define to 1 if the system has the type `uint32_t'. */\n#cmakedefine EVENT__HAVE_UINT32_T 1\n\n/* Define to 1 if the system has the type `uint64_t'. */\n#cmakedefine EVENT__HAVE_UINT64_T 1\n\n/* Define to 1 if the system has the type `uintptr_t'. */\n#cmakedefine EVENT__HAVE_UINTPTR_T 1\n\n/* Define to 1 if you have the `umask' function. */\n#cmakedefine EVENT__HAVE_UMASK 1\n\n/* Define to 1 if you have the <unistd.h> header file. */\n#cmakedefine EVENT__HAVE_UNISTD_H 1\n\n/* Define to 1 if you have the `unsetenv' function. */\n#cmakedefine EVENT__HAVE_UNSETENV 1\n\n/* Define if kqueue works correctly with pipes */\n#cmakedefine EVENT__HAVE_WORKING_KQUEUE 1\n\n/* The size of `pthread_t', as computed by sizeof. */\n#define EVENT__SIZEOF_PTHREAD_T @EVENT__SIZEOF_PTHREAD_T@\n\n/* The size of a `int', as computed by sizeof. */\n#define EVENT__SIZEOF_INT @EVENT__SIZEOF_INT@\n\n/* The size of a `long', as computed by sizeof. */\n#define EVENT__SIZEOF_LONG @EVENT__SIZEOF_LONG@\n\n/* The size of a `long long', as computed by sizeof. */\n#define EVENT__SIZEOF_LONG_LONG @EVENT__SIZEOF_LONG_LONG@\n\n/* The size of `off_t', as computed by sizeof. */\n#define EVENT__SIZEOF_OFF_T @EVENT__SIZEOF_OFF_T@\n\n/* The size of a `short', as computed by sizeof. */\n#define EVENT__SIZEOF_SHORT @EVENT__SIZEOF_SHORT@\n\n/* The size of `size_t', as computed by sizeof. */\n#define EVENT__SIZEOF_SIZE_T @EVENT__SIZEOF_SIZE_T@\n\n/* The size of `socklen_t', as computed by sizeof. */\n#define EVENT__SIZEOF_SOCKLEN_T @EVENT__SIZEOF_SOCKLEN_T@\n\n/* The size of 'void *', as computer by sizeof */\n#define EVENT__SIZEOF_VOID_P @EVENT__SIZEOF_VOID_P@\n\n/* The size of 'time_t', as computer by sizeof */\n#define EVENT__SIZEOF_TIME_T @EVENT__SIZEOF_TIME_T@\n\n/* Define to `__inline__' or `__inline' if that's what the C compiler\n   calls it, or do nothing if 'inline' is not supported under any name.  */\n#ifndef __cplusplus\n/* why not c++?\n *\n *  and are we really expected to use EVENT__inline everywhere,\n *  shouldn't we just do:\n *     ifdef EVENT__inline\n *     define inline EVENT__inline\n *\n * - Ellzey\n */\n\n#define EVENT__inline @EVENT__inline@\n#endif\n\n#cmakedefine EVENT__HAVE___func__ 1\n#cmakedefine EVENT__HAVE___FUNCTION__ 1\n\n/* Define to unsigned int if you dont have it */\n#define EVENT__socklen_t @EVENT__socklen_t@\n\n/* Define to `int' if <sys/types.h> does not define. */\n#define EVENT__ssize_t @EVENT__ssize_t@\n\n#endif /* \\EVENT2_EVENT_CONFIG_H_INCLUDED_ */\n"
        },
        {
          "name": "event-internal.h",
          "type": "blob",
          "size": 18.548828125,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVENT_INTERNAL_H_INCLUDED_\n#define EVENT_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"event2/watch.h\"\n#include \"evconfig-private.h\"\n\n#include <time.h>\n#include <sys/queue.h>\n#include \"event2/event_struct.h\"\n#include \"minheap-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"mm-internal.h\"\n#include \"defer-internal.h\"\n\n/* map union members back */\n\n/* mutually exclusive */\n#define ev_signal_next\tev_.ev_signal.ev_signal_next\n#define ev_io_next\tev_.ev_io.ev_io_next\n#define ev_io_timeout\tev_.ev_io.ev_timeout\n\n/* used only by signals */\n#define ev_ncalls\tev_.ev_signal.ev_ncalls\n#define ev_pncalls\tev_.ev_signal.ev_pncalls\n\n#define ev_pri ev_evcallback.evcb_pri\n#define ev_flags ev_evcallback.evcb_flags\n#define ev_closure ev_evcallback.evcb_closure\n#define ev_callback ev_evcallback.evcb_cb_union.evcb_callback\n#define ev_arg ev_evcallback.evcb_arg\n\n/** @name Event closure codes\n\n    Possible values for evcb_closure in struct event_callback\n\n    @{\n */\n/** A regular event. Uses the evcb_callback callback */\n#define EV_CLOSURE_EVENT 0\n/** A signal event. Uses the evcb_callback callback */\n#define EV_CLOSURE_EVENT_SIGNAL 1\n/** A persistent non-signal event. Uses the evcb_callback callback */\n#define EV_CLOSURE_EVENT_PERSIST 2\n/** A simple callback. Uses the evcb_selfcb callback. */\n#define EV_CLOSURE_CB_SELF 3\n/** A finalizing callback. Uses the evcb_cbfinalize callback. */\n#define EV_CLOSURE_CB_FINALIZE 4\n/** A finalizing event. Uses the evcb_evfinalize callback. */\n#define EV_CLOSURE_EVENT_FINALIZE 5\n/** A finalizing event that should get freed after. Uses the evcb_evfinalize\n * callback. */\n#define EV_CLOSURE_EVENT_FINALIZE_FREE 6\n/** @} */\n\n/** Structure to define the backend of a given event_base. */\nstruct eventop {\n\t/** The name of this backend. */\n\tconst char *name;\n\t/** Function to set up an event_base to use this backend.  It should\n\t * create a new structure holding whatever information is needed to\n\t * run the backend, and return it.  The returned pointer will get\n\t * stored by event_init into the event_base.evbase field.  On failure,\n\t * this function should return NULL. */\n\tvoid *(*init)(struct event_base *);\n\t/** Enable reading/writing on a given fd or signal.  'events' will be\n\t * the events that we're trying to enable: one or more of EV_READ,\n\t * EV_WRITE, EV_SIGNAL, and EV_ET.  'old' will be those events that\n\t * were enabled on this fd previously.  'fdinfo' will be a structure\n\t * associated with the fd by the evmap; its size is defined by the\n\t * fdinfo field below.  It will be set to 0 the first time the fd is\n\t * added.  The function should return 0 on success and -1 on error.\n\t */\n\tint (*add)(struct event_base *, evutil_socket_t fd, short old, short events, void *fdinfo);\n\t/** As \"add\", except 'events' contains the events we mean to disable. */\n\tint (*del)(struct event_base *, evutil_socket_t fd, short old, short events, void *fdinfo);\n\t/** Function to implement the core of an event loop.  It must see which\n\t    added events are ready, and cause event_active to be called for each\n\t    active event (usually via event_io_active or such).  It should\n\t    return 0 on success and -1 on error.\n\t */\n\tint (*dispatch)(struct event_base *, struct timeval *);\n\t/** Function to clean up and free our data from the event_base. */\n\tvoid (*dealloc)(struct event_base *);\n\t/** Flag: set if we need to reinitialize the event base after we fork.\n\t */\n\tint need_reinit;\n\t/** Bit-array of supported event_method_features that this backend can\n\t * provide. */\n\tenum event_method_feature features;\n\t/** Length of the extra information we should record for each fd that\n\t    has one or more active events.  This information is recorded\n\t    as part of the evmap entry for each fd, and passed as an argument\n\t    to the add and del functions above.\n\t */\n\tsize_t fdinfo_len;\n};\n\n#ifdef _WIN32\n/* If we're on win32, then file descriptors are not nice low densely packed\n   integers.  Instead, they are pointer-like windows handles, and we want to\n   use a hashtable instead of an array to map fds to events.\n*/\n#define EVMAP_USE_HT\n#endif\n\n/* #define HT_CACHE_HASH_VALS */\n\n#ifdef EVMAP_USE_HT\n#define HT_NO_CACHE_HASH_VALUES\n#include \"ht-internal.h\"\nstruct event_map_entry;\nHT_HEAD(event_io_map, event_map_entry);\n#else\n#define event_io_map event_signal_map\n#endif\n\n/* Used to map signal numbers to a list of events.  If EVMAP_USE_HT is not\n   defined, this structure is also used as event_io_map, which maps fds to a\n   list of events.\n*/\nstruct event_signal_map {\n\t/* An array of evmap_io * or of evmap_signal *; empty entries are\n\t * set to NULL. */\n\tvoid **entries;\n\t/* The number of entries available in entries */\n\tint nentries;\n};\n\n/* A list of events waiting on a given 'common' timeout value.  Ordinarily,\n * events waiting for a timeout wait on a minheap.  Sometimes, however, a\n * queue can be faster.\n **/\nstruct common_timeout_list {\n\t/* List of events currently waiting in the queue. */\n\tstruct event_list events;\n\t/* 'magic' timeval used to indicate the duration of events in this\n\t * queue. */\n\tstruct timeval duration;\n\t/* Event that triggers whenever one of the events in the queue is\n\t * ready to activate */\n\tstruct event timeout_event;\n\t/* The event_base that this timeout list is part of */\n\tstruct event_base *base;\n};\n\n/** Mask used to get the real tv_usec value from a common timeout. */\n#define COMMON_TIMEOUT_MICROSECONDS_MASK       0x000fffff\n\nstruct event_change;\n\n/* List of 'changes' since the last call to eventop.dispatch.  Only maintained\n * if the backend is using changesets. */\nstruct event_changelist {\n\tstruct event_change *changes;\n\tint n_changes;\n\tint changes_size;\n};\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\n/* Global internal flag: set to one if debug mode is on. */\nextern int event_debug_mode_on_;\n#define EVENT_DEBUG_MODE_IS_ON() (event_debug_mode_on_)\n#else\n#define EVENT_DEBUG_MODE_IS_ON() (0)\n#endif\n\nTAILQ_HEAD(evcallback_list, event_callback);\n\n/* Sets up an event for processing once */\nstruct event_once {\n\tLIST_ENTRY(event_once) next_once;\n\tstruct event ev;\n\n\tvoid (*cb)(evutil_socket_t, short, void *);\n\tvoid *arg;\n};\n\n/** Contextual information passed from event_base_loop to the \"prepare\" watcher\n * callbacks. We define this as a struct rather than individual parameters to\n * the callback function for the sake of future extensibility. */\nstruct evwatch_prepare_cb_info {\n\t/** The timeout duration passed to the underlying implementation's `dispatch`.\n\t * See evwatch_prepare_get_timeout. */\n\tconst struct timeval *timeout;\n};\n\n/** Contextual information passed from event_base_loop to the \"check\" watcher\n * callbacks. We define this as a struct rather than individual parameters to\n * the callback function for the sake of future extensibility. */\nstruct evwatch_check_cb_info {\n\t/** Placeholder, since empty struct is not allowed by some compilers. */\n\tvoid *unused;\n};\n\n/** Watcher types (prepare and check, perhaps others in the future). */\n#define EVWATCH_PREPARE 0\n#define EVWATCH_CHECK   1\n#define EVWATCH_MAX     2\n\n/** Handle to a \"prepare\" or \"check\" callback, registered in event_base. */\nunion evwatch_cb {\n\tevwatch_prepare_cb prepare;\n\tevwatch_check_cb check;\n};\nstruct evwatch {\n\t/** Tail queue pointers, called \"next\" by convention in libevent.\n\t * See <sys/queue.h> */\n\tTAILQ_ENTRY(evwatch) next;\n\n\t/** Pointer to owning event loop */\n\tstruct event_base *base;\n\n\t/** Watcher type (see above) */\n\tunsigned type;\n\n\t/** Callback function */\n\tunion evwatch_cb callback;\n\n\t/** User-defined argument for callback function */\n\tvoid *arg;\n};\nTAILQ_HEAD(evwatch_list, evwatch);\n\nstruct event_base {\n\t/** Function pointers and other data to describe this event_base's\n\t * backend. */\n\tconst struct eventop *evsel;\n\t/** Pointer to backend-specific data. */\n\tvoid *evbase;\n\n\t/** List of changes to tell backend about at next dispatch.  Only used\n\t * by the O(1) backends. */\n\tstruct event_changelist changelist;\n\n\t/** Function pointers used to describe the backend that this event_base\n\t * uses for signals */\n\tconst struct eventop *evsigsel;\n\t/** Data to implement the common signal handler code. */\n\tstruct evsig_info sig;\n\n\t/** Number of virtual events */\n\tint virtual_event_count;\n\t/** Maximum number of virtual events active */\n\tint virtual_event_count_max;\n\t/** Number of total events added to this event_base */\n\tint event_count;\n\t/** Maximum number of total events added to this event_base */\n\tint event_count_max;\n\t/** Number of total events active in this event_base */\n\tint event_count_active;\n\t/** Maximum number of total events active in this event_base */\n\tint event_count_active_max;\n\n\t/** Set if we should terminate the loop once we're done processing\n\t * events. */\n\tint event_gotterm;\n\t/** Set if we should terminate the loop immediately */\n\tint event_break;\n\t/** Set if we should start a new instance of the loop immediately. */\n\tint event_continue;\n\n\t/** The currently running priority of events */\n\tint event_running_priority;\n\n\t/** Set if we're running the event_base_loop function, to prevent\n\t * reentrant invocation. */\n\tint running_loop;\n\n\t/** Set to the number of deferred_cbs we've made 'active' in the\n\t * loop.  This is a hack to prevent starvation; it would be smarter\n\t * to just use event_config_set_max_dispatch_interval's max_callbacks\n\t * feature */\n\tint n_deferreds_queued;\n\n\t/* Active event management. */\n\t/** An array of nactivequeues queues for active event_callbacks (ones\n\t * that have triggered, and whose callbacks need to be called).  Low\n\t * priority numbers are more important, and stall higher ones.\n\t */\n\tstruct evcallback_list *activequeues;\n\t/** The length of the activequeues array */\n\tint nactivequeues;\n\t/** A list of event_callbacks that should become active the next time\n\t * we process events, but not this time. */\n\tstruct evcallback_list active_later_queue;\n\n\t/* common timeout logic */\n\n\t/** An array of common_timeout_list* for all of the common timeout\n\t * values we know. */\n\tstruct common_timeout_list **common_timeout_queues;\n\t/** The number of entries used in common_timeout_queues */\n\tint n_common_timeouts;\n\t/** The total size of common_timeout_queues. */\n\tint n_common_timeouts_allocated;\n\n\t/** Mapping from file descriptors to enabled (added) events */\n\tstruct event_io_map io;\n\n\t/** Mapping from signal numbers to enabled (added) events. */\n\tstruct event_signal_map sigmap;\n\n\t/** Priority queue of events with timeouts. */\n\tstruct min_heap timeheap;\n\n\t/** Stored timeval: used to avoid calling gettimeofday/clock_gettime\n\t * too often. */\n\tstruct timeval tv_cache;\n\n\tstruct evutil_monotonic_timer monotonic_timer;\n\n\t/** Difference between internal time (maybe from clock_gettime) and\n\t * gettimeofday. */\n\tstruct timeval tv_clock_diff;\n\t/** Second in which we last updated tv_clock_diff, in monotonic time. */\n\ttime_t last_updated_clock_diff;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\t/* threading support */\n\t/** The thread currently running the event_loop for this base */\n\tunsigned long th_owner_id;\n\t/** A lock to prevent conflicting accesses to this event_base */\n\tvoid *th_base_lock;\n\t/** A condition that gets signalled when we're done processing an\n\t * event with waiters on it. */\n\tvoid *current_event_cond;\n\t/** Number of threads blocking on current_event_cond. */\n\tint current_event_waiters;\n#endif\n\t/** The event whose callback is executing right now */\n\tstruct event_callback *current_event;\n\n#ifdef _WIN32\n\t/** IOCP support structure, if IOCP is enabled. */\n\tstruct event_iocp_port *iocp;\n#endif\n\n\t/** Flags that this base was configured with */\n\tenum event_base_config_flag flags;\n\n\tstruct timeval max_dispatch_time;\n\tint max_dispatch_callbacks;\n\tint limit_callbacks_after_prio;\n\n\t/* Notify main thread to wake up break, etc. */\n\t/** True if the base already has a pending notify, and we don't need\n\t * to add any more. */\n\tint is_notify_pending;\n\t/** A socketpair used by some th_notify functions to wake up the main\n\t * thread. */\n\tevutil_socket_t th_notify_fd[2];\n\t/** An event used by some th_notify functions to wake up the main\n\t * thread. */\n\tstruct event th_notify;\n\t/** A function used to wake up the main thread from another thread. */\n\tint (*th_notify_fn)(struct event_base *base);\n\n\t/** Saved seed for weak random number generator. Some backends use\n\t * this to produce fairness among sockets. Protected by th_base_lock. */\n\tstruct evutil_weakrand_state weakrand_seed;\n\n\t/** List of event_onces that have not yet fired. */\n\tLIST_HEAD(once_event_list, event_once) once_events;\n\n\t/** \"Prepare\" and \"check\" watchers. */\n\tstruct evwatch_list watchers[EVWATCH_MAX];\n};\n\nstruct event_config_entry {\n\tTAILQ_ENTRY(event_config_entry) next;\n\n\tconst char *avoid_method;\n};\n\n/** Internal structure: describes the configuration we want for an event_base\n * that we're about to allocate. */\nstruct event_config {\n\tTAILQ_HEAD(event_configq, event_config_entry) entries;\n\n\tint n_cpus_hint;\n\tstruct timeval max_dispatch_interval;\n\tint max_dispatch_callbacks;\n\tint limit_callbacks_after_prio;\n\tenum event_method_feature require_features;\n\tenum event_base_config_flag flags;\n};\n\n/* Internal use only: Functions that might be missing from <sys/queue.h> */\n#ifndef LIST_END\n#define LIST_END(head)\t\t\tNULL\n#endif\n\n#ifndef TAILQ_FIRST\n#define\tTAILQ_FIRST(head)\t\t((head)->tqh_first)\n#endif\n#ifndef TAILQ_END\n#define\tTAILQ_END(head)\t\t\tNULL\n#endif\n#ifndef TAILQ_NEXT\n#define\tTAILQ_NEXT(elm, field)\t\t((elm)->field.tqe_next)\n#endif\n\n#ifndef TAILQ_FOREACH\n#define TAILQ_FOREACH(var, head, field)\t\t\t\t\t\\\n\tfor ((var) = TAILQ_FIRST(head);\t\t\t\t\t\\\n\t     (var) != TAILQ_END(head);\t\t\t\t\t\\\n\t     (var) = TAILQ_NEXT(var, field))\n#endif\n\n#ifndef TAILQ_INSERT_BEFORE\n#define\tTAILQ_INSERT_BEFORE(listelm, elm, field) do {\t\t\t\\\n\t(elm)->field.tqe_prev = (listelm)->field.tqe_prev;\t\t\\\n\t(elm)->field.tqe_next = (listelm);\t\t\t\t\\\n\t*(listelm)->field.tqe_prev = (elm);\t\t\t\t\\\n\t(listelm)->field.tqe_prev = &(elm)->field.tqe_next;\t\t\\\n} while (0)\n#endif\n\n#define N_ACTIVE_CALLBACKS(base)\t\t\t\t\t\\\n\t((base)->event_count_active)\n\nint evsig_set_handler_(struct event_base *base, int evsignal,\n\t\t\t  void (*fn)(int));\nint evsig_restore_handler_(struct event_base *base, int evsignal);\n\nint event_add_nolock_(struct event *ev,\n    const struct timeval *tv, int tv_is_absolute);\n/** Argument for event_del_nolock_. Tells event_del not to block on the event\n * if it's running in another thread. */\n#define EVENT_DEL_NOBLOCK 0\n/** Argument for event_del_nolock_. Tells event_del to block on the event\n * if it's running in another thread, regardless of its value for EV_FINALIZE\n */\n#define EVENT_DEL_BLOCK 1\n/** Argument for event_del_nolock_. Tells event_del to block on the event\n * if it is running in another thread and it doesn't have EV_FINALIZE set.\n */\n#define EVENT_DEL_AUTOBLOCK 2\n/** Argument for event_del_nolock_. Tells event_del to proceed even if the\n * event is set up for finalization rather for regular use.*/\n#define EVENT_DEL_EVEN_IF_FINALIZING 3\nint event_del_nolock_(struct event *ev, int blocking);\nint event_remove_timer_nolock_(struct event *ev);\n\nvoid event_active_nolock_(struct event *ev, int res, short count);\nEVENT2_EXPORT_SYMBOL\nint event_callback_activate_(struct event_base *, struct event_callback *);\nint event_callback_activate_nolock_(struct event_base *, struct event_callback *);\nint event_callback_cancel_(struct event_base *base,\n    struct event_callback *evcb);\n\nvoid event_callback_finalize_nolock_(struct event_base *base, unsigned flags, struct event_callback *evcb, void (*cb)(struct event_callback *, void *));\nEVENT2_EXPORT_SYMBOL\nvoid event_callback_finalize_(struct event_base *base, unsigned flags, struct event_callback *evcb, void (*cb)(struct event_callback *, void *));\nint event_callback_finalize_many_(struct event_base *base, int n_cbs, struct event_callback **evcb, void (*cb)(struct event_callback *, void *));\n\n\nEVENT2_EXPORT_SYMBOL\nvoid event_active_later_(struct event *ev, int res);\nvoid event_active_later_nolock_(struct event *ev, int res);\nint event_callback_activate_later_nolock_(struct event_base *base,\n    struct event_callback *evcb);\nint event_callback_cancel_nolock_(struct event_base *base,\n    struct event_callback *evcb, int even_if_finalizing);\nvoid event_callback_init_(struct event_base *base,\n    struct event_callback *cb);\n\n/* FIXME document. */\nEVENT2_EXPORT_SYMBOL\nvoid event_base_add_virtual_(struct event_base *base);\nvoid event_base_del_virtual_(struct event_base *base);\n\n/** For debugging: unless assertions are disabled, verify the referential\n    integrity of the internal data structures of 'base'.  This operation can\n    be expensive.\n\n    Returns on success; aborts on failure.\n*/\nEVENT2_EXPORT_SYMBOL\nvoid event_base_assert_ok_(struct event_base *base);\nvoid event_base_assert_ok_nolock_(struct event_base *base);\n\n\n/* Helper function: Call 'fn' exactly once every inserted or active event in\n * the event_base 'base'.\n *\n * If fn returns 0, continue on to the next event. Otherwise, return the same\n * value that fn returned.\n *\n * Requires that 'base' be locked.\n */\nint event_base_foreach_event_nolock_(struct event_base *base,\n    event_base_foreach_event_cb cb, void *arg);\n\n/* Cleanup function to reset debug mode during shutdown.\n *\n * Calling this function doesn't mean it'll be possible to re-enable\n * debug mode if any events were added.\n */\nvoid event_disable_debug_mode(void);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* EVENT_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "event.c",
          "type": "blob",
          "size": 104.39453125,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#define WIN32_LEAN_AND_MEAN\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n#include <sys/types.h>\n#if !defined(_WIN32) && defined(EVENT__HAVE_SYS_TIME_H)\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#include <stdio.h>\n#include <stdlib.h>\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#include <ctype.h>\n#include <errno.h>\n#include <signal.h>\n#include <string.h>\n#include <time.h>\n#include <limits.h>\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/event_compat.h\"\n#include \"event2/watch.h\"\n#include \"event-internal.h\"\n#include \"defer-internal.h\"\n#include \"evthread-internal.h\"\n#include \"event2/thread.h\"\n#include \"event2/util.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"iocp-internal.h\"\n#include \"changelist-internal.h\"\n#define HT_NO_CACHE_HASH_VALUES\n#include \"ht-internal.h\"\n#include \"util-internal.h\"\n\n\n#ifdef EVENT__HAVE_WORKING_KQUEUE\n#include \"kqueue-internal.h\"\n#endif\n\n#ifdef EVENT__HAVE_EVENT_PORTS\nextern const struct eventop evportops;\n#endif\n#ifdef EVENT__HAVE_SELECT\nextern const struct eventop selectops;\n#endif\n#ifdef EVENT__HAVE_POLL\nextern const struct eventop pollops;\n#endif\n#ifdef EVENT__HAVE_EPOLL\nextern const struct eventop epollops;\n#endif\n#ifdef EVENT__HAVE_WORKING_KQUEUE\nextern const struct eventop kqops;\n#endif\n#ifdef EVENT__HAVE_DEVPOLL\nextern const struct eventop devpollops;\n#endif\n#ifdef EVENT__HAVE_WEPOLL\nextern const struct eventop wepollops;\n#endif\n#ifdef _WIN32\nextern const struct eventop win32ops;\n#endif\n\n/* Array of backends in order of preference. */\nstatic const struct eventop *eventops[] = {\n#ifdef EVENT__HAVE_EVENT_PORTS\n\t&evportops,\n#endif\n#ifdef EVENT__HAVE_WORKING_KQUEUE\n\t&kqops,\n#endif\n#ifdef EVENT__HAVE_EPOLL\n\t&epollops,\n#endif\n#ifdef EVENT__HAVE_DEVPOLL\n\t&devpollops,\n#endif\n#ifdef EVENT__HAVE_POLL\n\t&pollops,\n#endif\n#ifdef EVENT__HAVE_SELECT\n\t&selectops,\n#endif\n#ifdef _WIN32\n\t&win32ops,\n#endif\n#ifdef EVENT__HAVE_WEPOLL\n\t&wepollops,\n#endif\n\tNULL\n};\n\n/* Global state; deprecated */\nEVENT2_EXPORT_SYMBOL\nstruct event_base *event_global_current_base_ = NULL;\n#define current_base event_global_current_base_\n\n/* Global state */\n\nstatic void *event_self_cbarg_ptr_ = NULL;\n\n/* Prototypes */\nstatic void\tevent_queue_insert_active(struct event_base *, struct event_callback *);\nstatic void\tevent_queue_insert_active_later(struct event_base *, struct event_callback *);\nstatic void\tevent_queue_insert_timeout(struct event_base *, struct event *);\nstatic void\tevent_queue_insert_inserted(struct event_base *, struct event *);\nstatic void\tevent_queue_remove_active(struct event_base *, struct event_callback *);\nstatic void\tevent_queue_remove_active_later(struct event_base *, struct event_callback *);\nstatic void\tevent_queue_remove_timeout(struct event_base *, struct event *);\nstatic void\tevent_queue_remove_inserted(struct event_base *, struct event *);\nstatic void event_queue_make_later_events_active(struct event_base *base);\n\nstatic int evthread_make_base_notifiable_nolock_(struct event_base *base);\nstatic int event_del_(struct event *ev, int blocking);\n\n#ifdef USE_REINSERT_TIMEOUT\n/* This code seems buggy; only turn it on if we find out what the trouble is. */\nstatic void\tevent_queue_reinsert_timeout(struct event_base *,struct event *, int was_common, int is_common, int old_timeout_idx);\n#endif\n\nstatic int\tevent_haveevents(struct event_base *);\n\nstatic int\tevent_process_active(struct event_base *);\n\nstatic int\ttimeout_next(struct event_base *, struct timeval **);\nstatic void\ttimeout_process(struct event_base *);\n\nstatic inline void\tevent_signal_closure(struct event_base *, struct event *ev);\nstatic inline void\tevent_persist_closure(struct event_base *, struct event *ev);\n\nstatic int\tevthread_notify_base(struct event_base *base);\n\nstatic void insert_common_timeout_inorder(struct common_timeout_list *ctl,\n    struct event *ev);\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\n/* These functions implement a hashtable of which 'struct event *' structures\n * have been setup or added.  We don't want to trust the content of the struct\n * event itself, since we're trying to work through cases where an event gets\n * clobbered or freed.  Instead, we keep a hashtable indexed by the pointer.\n */\n\nstruct event_debug_entry {\n\tHT_ENTRY(event_debug_entry) node;\n\tconst struct event *ptr;\n\tunsigned added : 1;\n};\n\nstatic inline unsigned\nhash_debug_entry(const struct event_debug_entry *e)\n{\n\t/* We need to do this silliness to convince compilers that we\n\t * honestly mean to cast e->ptr to an integer, and discard any\n\t * part of it that doesn't fit in an unsigned.\n\t */\n\tunsigned u = (unsigned) ((ev_uintptr_t) e->ptr);\n\t/* Our hashtable implementation is pretty sensitive to low bits,\n\t * and every struct event is over 64 bytes in size, so we can\n\t * just say >>6. */\n\treturn (u >> 6);\n}\n\nstatic inline int\neq_debug_entry(const struct event_debug_entry *a,\n    const struct event_debug_entry *b)\n{\n\treturn a->ptr == b->ptr;\n}\n\nint event_debug_mode_on_ = 0;\n\n\n#if !defined(EVENT__DISABLE_THREAD_SUPPORT) && !defined(EVENT__DISABLE_DEBUG_MODE)\n/**\n * @brief debug mode variable which is set for any function/structure that needs\n *        to be shared across threads (if thread support is enabled).\n *\n *        When and if evthreads are initialized, this variable will be evaluated,\n *        and if set to something other than zero, this means the evthread setup\n *        functions were called out of order.\n *\n *        See: \"Locks and threading\" in the documentation.\n */\nint event_debug_created_threadable_ctx_ = 0;\n#endif\n\n/* Set if it's too late to enable event_debug_mode. */\nstatic int event_debug_mode_too_late = 0;\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nstatic void *event_debug_map_lock_ = NULL;\n#endif\nstatic HT_HEAD(event_debug_map, event_debug_entry) global_debug_map =\n\tHT_INITIALIZER();\n\nHT_PROTOTYPE(event_debug_map, event_debug_entry, node, hash_debug_entry,\n    eq_debug_entry)\nHT_GENERATE(event_debug_map, event_debug_entry, node, hash_debug_entry,\n    eq_debug_entry, 0.5, mm_malloc, mm_realloc, mm_free)\n\n/* record that ev is now setup (that is, ready for an add) */\nstatic void event_debug_note_setup_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent, find;\n\n\tif (!event_debug_mode_on_)\n\t\tgoto out;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_FIND(event_debug_map, &global_debug_map, &find);\n\tif (dent) {\n\t\tdent->added = 0;\n\t} else {\n\t\tdent = mm_malloc(sizeof(*dent));\n\t\tif (!dent)\n\t\t\tevent_err(1,\n\t\t\t    \"Out of memory in debugging code\");\n\t\tdent->ptr = ev;\n\t\tdent->added = 0;\n\t\tHT_INSERT(event_debug_map, &global_debug_map, dent);\n\t}\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n\nout:\n\tevent_debug_mode_too_late = 1;\n}\n/* record that ev is no longer setup */\nstatic void event_debug_note_teardown_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent, find;\n\n\tif (!event_debug_mode_on_)\n\t\tgoto out;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_REMOVE(event_debug_map, &global_debug_map, &find);\n\tif (dent)\n\t\tmm_free(dent);\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n\nout:\n\tevent_debug_mode_too_late = 1;\n}\n/* Macro: record that ev is now added */\nstatic void event_debug_note_add_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent,find;\n\n\tif (!event_debug_mode_on_)\n\t\tgoto out;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_FIND(event_debug_map, &global_debug_map, &find);\n\tif (dent) {\n\t\tdent->added = 1;\n\t} else {\n\t\tevent_errx(EVENT_ERR_ABORT_,\n\t\t    \"%s: noting an add on a non-setup event %p\"\n\t\t    \" (events: 0x%x, fd: \"EV_SOCK_FMT\n\t\t    \", flags: 0x%x)\",\n\t\t    __func__, (void *)ev, ev->ev_events,\n\t\t    EV_SOCK_ARG(ev->ev_fd), ev->ev_flags);\n\t}\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n\nout:\n\tevent_debug_mode_too_late = 1;\n}\n/* record that ev is no longer added */\nstatic void event_debug_note_del_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent, find;\n\n\tif (!event_debug_mode_on_)\n\t\tgoto out;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_FIND(event_debug_map, &global_debug_map, &find);\n\tif (dent) {\n\t\tdent->added = 0;\n\t} else {\n\t\tevent_errx(EVENT_ERR_ABORT_,\n\t\t    \"%s: noting a del on a non-setup event %p\"\n\t\t    \" (events: 0x%x, fd: \"EV_SOCK_FMT\n\t\t    \", flags: 0x%x)\",\n\t\t    __func__, (void *)ev, ev->ev_events,\n\t\t    EV_SOCK_ARG(ev->ev_fd), ev->ev_flags);\n\t}\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n\nout:\n\tevent_debug_mode_too_late = 1;\n}\n/* assert that ev is setup (i.e., okay to add or inspect) */\nstatic void event_debug_assert_is_setup_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent, find;\n\n\tif (!event_debug_mode_on_)\n\t\treturn;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_FIND(event_debug_map, &global_debug_map, &find);\n\tif (!dent) {\n\t\tevent_errx(EVENT_ERR_ABORT_,\n\t\t    \"%s called on a non-initialized event %p\"\n\t\t    \" (events: 0x%x, fd: \"EV_SOCK_FMT\n\t\t    \", flags: 0x%x)\",\n\t\t    __func__, (void *)ev, ev->ev_events,\n\t\t    EV_SOCK_ARG(ev->ev_fd), ev->ev_flags);\n\t}\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n}\n/* assert that ev is not added (i.e., okay to tear down or set up again) */\nstatic void event_debug_assert_not_added_(const struct event *ev)\n{\n\tstruct event_debug_entry *dent, find;\n\n\tif (!event_debug_mode_on_)\n\t\treturn;\n\n\tfind.ptr = ev;\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tdent = HT_FIND(event_debug_map, &global_debug_map, &find);\n\tif (dent && dent->added) {\n\t\tevent_errx(EVENT_ERR_ABORT_,\n\t\t    \"%s called on an already added event %p\"\n\t\t    \" (events: 0x%x, fd: \"EV_SOCK_FMT\", \"\n\t\t    \"flags: 0x%x)\",\n\t\t    __func__, (void *)ev, ev->ev_events,\n\t\t    EV_SOCK_ARG(ev->ev_fd), ev->ev_flags);\n\t}\n\tEVLOCK_UNLOCK(event_debug_map_lock_, 0);\n}\nstatic void event_debug_assert_socket_nonblocking_(evutil_socket_t fd)\n{\n\tif (!event_debug_mode_on_)\n\t\treturn;\n\tif (fd < 0)\n\t\treturn;\n\n#ifndef _WIN32\n\t{\n\t\tint flags;\n\t\tif ((flags = fcntl(fd, F_GETFL, NULL)) >= 0) {\n\t\t\tEVUTIL_ASSERT(flags & O_NONBLOCK);\n\t\t}\n\t}\n#endif\n}\n#else\nstatic void event_debug_note_setup_(const struct event *ev) { (void)ev; }\nstatic void event_debug_note_teardown_(const struct event *ev) { (void)ev; }\nstatic void event_debug_note_add_(const struct event *ev) { (void)ev; }\nstatic void event_debug_note_del_(const struct event *ev) { (void)ev; }\nstatic void event_debug_assert_is_setup_(const struct event *ev) { (void)ev; }\nstatic void event_debug_assert_not_added_(const struct event *ev) { (void)ev; }\nstatic void event_debug_assert_socket_nonblocking_(evutil_socket_t fd) { (void)fd; }\n#endif\n\n#define EVENT_BASE_ASSERT_LOCKED(base)\t\t\\\n\tEVLOCK_ASSERT_LOCKED((base)->th_base_lock)\n\n/* How often (in seconds) do we check for changes in wall clock time relative\n * to monotonic time?  Set this to -1 for 'never.' */\n#define CLOCK_SYNC_INTERVAL -1\n\n/** Set 'tp' to the current time according to 'base'.  We must hold the lock\n * on 'base'.  If there is a cached time, return it.  Otherwise, use\n * clock_gettime or gettimeofday as appropriate to find out the right time.\n * Return 0 on success, -1 on failure.\n */\nstatic int\ngettime(struct event_base *base, struct timeval *tp)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (base->tv_cache.tv_sec) {\n\t\t*tp = base->tv_cache;\n\t\treturn (0);\n\t}\n\n\tif (evutil_gettime_monotonic_(&base->monotonic_timer, tp) == -1) {\n\t\treturn -1;\n\t}\n\n\tif (base->last_updated_clock_diff + CLOCK_SYNC_INTERVAL\n\t    < tp->tv_sec) {\n\t\tstruct timeval tv;\n\t\tevutil_gettimeofday(&tv,NULL);\n\t\tevutil_timersub(&tv, tp, &base->tv_clock_diff);\n\t\tbase->last_updated_clock_diff = tp->tv_sec;\n\t}\n\n\treturn 0;\n}\n\nint\nevent_base_gettimeofday_cached(struct event_base *base, struct timeval *tv)\n{\n\tint r;\n\tif (!base) {\n\t\tbase = current_base;\n\t\tif (!current_base)\n\t\t\treturn evutil_gettimeofday(tv, NULL);\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (base->tv_cache.tv_sec == 0) {\n\t\tr = evutil_gettimeofday(tv, NULL);\n\t} else {\n\t\tevutil_timeradd(&base->tv_cache, &base->tv_clock_diff, tv);\n\t\tr = 0;\n\t}\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\n/** Make 'base' have no current cached time. */\nstatic inline void\nclear_time_cache(struct event_base *base)\n{\n\tbase->tv_cache.tv_sec = 0;\n}\n\n/** Replace the cached time in 'base' with the current time. */\nstatic inline void\nupdate_time_cache(struct event_base *base)\n{\n\tbase->tv_cache.tv_sec = 0;\n\tif (!(base->flags & EVENT_BASE_FLAG_NO_CACHE_TIME))\n\t\tgettime(base, &base->tv_cache);\n}\n\nint\nevent_base_update_cache_time(struct event_base *base)\n{\n\n\tif (!base) {\n\t\tbase = current_base;\n\t\tif (!current_base)\n\t\t\treturn -1;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (base->running_loop)\n\t\tupdate_time_cache(base);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn 0;\n}\n\nstatic inline struct event *\nevent_callback_to_event(struct event_callback *evcb)\n{\n\tEVUTIL_ASSERT((evcb->evcb_flags & EVLIST_INIT));\n\treturn EVUTIL_UPCAST(evcb, struct event, ev_evcallback);\n}\n\nstatic inline struct event_callback *\nevent_to_event_callback(struct event *ev)\n{\n\treturn &ev->ev_evcallback;\n}\n\nstruct event_base *\nevent_init(void)\n{\n\tstruct event_base *base = event_base_new_with_config(NULL);\n\n\tif (base == NULL) {\n\t\tevent_errx(1, \"%s: Unable to construct event_base\", __func__);\n\t\treturn NULL;\n\t}\n\n\tcurrent_base = base;\n\n\treturn (base);\n}\n\nstruct event_base *\nevent_base_new(void)\n{\n\tstruct event_base *base = NULL;\n\tstruct event_config *cfg = event_config_new();\n\tif (cfg) {\n\t\tbase = event_base_new_with_config(cfg);\n\t\tevent_config_free(cfg);\n\t}\n\treturn base;\n}\n\n/** Return true iff 'method' is the name of a method that 'cfg' tells us to\n * avoid. */\nstatic int\nevent_config_is_avoided_method(const struct event_config *cfg,\n    const char *method)\n{\n\tstruct event_config_entry *entry;\n\n\tTAILQ_FOREACH(entry, &cfg->entries, next) {\n\t\tif (entry->avoid_method != NULL &&\n\t\t    strcmp(entry->avoid_method, method) == 0)\n\t\t\treturn (1);\n\t}\n\n\treturn (0);\n}\n\n/** Return true iff 'method' is disabled according to the environment. */\nstatic int\nevent_is_method_disabled(const char *name)\n{\n\tchar environment[64];\n\tint i;\n\n\tevutil_snprintf(environment, sizeof(environment), \"EVENT_NO%s\", name);\n\tfor (i = 8; environment[i] != '\\0'; ++i)\n\t\tenvironment[i] = EVUTIL_TOUPPER_(environment[i]);\n\t/* Note that evutil_getenv_() ignores the environment entirely if\n\t * we're setuid */\n\treturn (evutil_getenv_(environment) != NULL);\n}\n\nint\nevent_base_get_features(const struct event_base *base)\n{\n\treturn base->evsel->features;\n}\n\nvoid\nevent_enable_debug_mode(void)\n{\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_mode_on_)\n\t\tevent_errx(1, \"%s was called twice!\", __func__);\n\tif (event_debug_mode_too_late)\n\t\tevent_errx(1, \"%s must be called *before* creating any events \"\n\t\t    \"or event_bases\",__func__);\n\n\tevent_debug_mode_on_ = 1;\n\n\tHT_INIT(event_debug_map, &global_debug_map);\n#endif\n}\n\nvoid\nevent_disable_debug_mode(void)\n{\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tstruct event_debug_entry **ent, *victim;\n\n\tEVLOCK_LOCK(event_debug_map_lock_, 0);\n\tfor (ent = HT_START(event_debug_map, &global_debug_map); ent; ) {\n\t\tvictim = *ent;\n\t\tent = HT_NEXT_RMV(event_debug_map, &global_debug_map, ent);\n\t\tmm_free(victim);\n\t}\n\tHT_CLEAR(event_debug_map, &global_debug_map);\n\tEVLOCK_UNLOCK(event_debug_map_lock_ , 0);\n\n\tevent_debug_mode_on_  = 0;\n#endif\n}\n\nstruct event_base *\nevent_base_new_with_config(const struct event_config *cfg)\n{\n\tint i;\n\tstruct event_base *base;\n\tint should_check_environment;\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tevent_debug_mode_too_late = 1;\n#endif\n\n\tif ((base = mm_calloc(1, sizeof(struct event_base))) == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\treturn NULL;\n\t}\n\n\tif (cfg)\n\t\tbase->flags = cfg->flags;\n\n\tshould_check_environment =\n\t    !(cfg && (cfg->flags & EVENT_BASE_FLAG_IGNORE_ENV));\n\n\t{\n\t\tstruct timeval tmp;\n\t\tint precise_time =\n\t\t    cfg && (cfg->flags & EVENT_BASE_FLAG_PRECISE_TIMER);\n\t\tint flags;\n\t\tif (should_check_environment && !precise_time) {\n\t\t\tprecise_time = evutil_getenv_(\"EVENT_PRECISE_TIMER\") != NULL;\n\t\t\tif (precise_time) {\n\t\t\t\tbase->flags |= EVENT_BASE_FLAG_PRECISE_TIMER;\n\t\t\t}\n\t\t}\n\t\tflags = precise_time ? EV_MONOT_PRECISE : 0;\n\t\tevutil_configure_monotonic_time_(&base->monotonic_timer, flags);\n\n\t\tgettime(base, &tmp);\n\t}\n\n\tmin_heap_ctor_(&base->timeheap);\n\n\tbase->sig.ev_signal_pair[0] = -1;\n\tbase->sig.ev_signal_pair[1] = -1;\n\tbase->th_notify_fd[0] = -1;\n\tbase->th_notify_fd[1] = -1;\n\n\tTAILQ_INIT(&base->active_later_queue);\n\n\tevmap_io_initmap_(&base->io);\n\tevmap_signal_initmap_(&base->sigmap);\n\tevent_changelist_init_(&base->changelist);\n\n\tbase->evbase = NULL;\n\n\tif (cfg) {\n\t\tmemcpy(&base->max_dispatch_time,\n\t\t    &cfg->max_dispatch_interval, sizeof(struct timeval));\n\t\tbase->limit_callbacks_after_prio =\n\t\t    cfg->limit_callbacks_after_prio;\n\t} else {\n\t\tbase->max_dispatch_time.tv_sec = -1;\n\t\tbase->limit_callbacks_after_prio = 1;\n\t}\n\tif (cfg && cfg->max_dispatch_callbacks >= 0) {\n\t\tbase->max_dispatch_callbacks = cfg->max_dispatch_callbacks;\n\t} else {\n\t\tbase->max_dispatch_callbacks = INT_MAX;\n\t}\n\tif (base->max_dispatch_callbacks == INT_MAX &&\n\t    base->max_dispatch_time.tv_sec == -1)\n\t\tbase->limit_callbacks_after_prio = INT_MAX;\n\n\tfor (i = 0; eventops[i] && !base->evbase; i++) {\n\t\tif (cfg != NULL) {\n\t\t\t/* determine if this backend should be avoided */\n\t\t\tif (event_config_is_avoided_method(cfg,\n\t\t\t\teventops[i]->name))\n\t\t\t\tcontinue;\n\t\t\tif ((eventops[i]->features & cfg->require_features)\n\t\t\t    != cfg->require_features)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\t/* also obey the environment variables */\n\t\tif (should_check_environment &&\n\t\t    event_is_method_disabled(eventops[i]->name))\n\t\t\tcontinue;\n\n\t\tbase->evsel = eventops[i];\n\n\t\tbase->evbase = base->evsel->init(base);\n\t}\n\n\tif (base->evbase == NULL) {\n\t\tevent_warnx(\"%s: no event mechanism available\",\n\t\t    __func__);\n\t\tbase->evsel = NULL;\n\t\tevent_base_free(base);\n\t\treturn NULL;\n\t}\n\n\tif (evutil_getenv_(\"EVENT_SHOW_METHOD\"))\n\t\tevent_msgx(\"libevent using: %s\", base->evsel->name);\n\n\t/* allocate a single active event queue */\n\tif (event_base_priority_init(base, 1) < 0) {\n\t\tevent_base_free(base);\n\t\treturn NULL;\n\t}\n\n\t/* prepare for threading */\n\n#if !defined(EVENT__DISABLE_THREAD_SUPPORT) && !defined(EVENT__DISABLE_DEBUG_MODE)\n\tevent_debug_created_threadable_ctx_ = 1;\n#endif\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (EVTHREAD_LOCKING_ENABLED() &&\n\t    (!cfg || !(cfg->flags & EVENT_BASE_FLAG_NOLOCK))) {\n\t\tint r;\n\t\tEVTHREAD_ALLOC_LOCK(base->th_base_lock, 0);\n\t\tEVTHREAD_ALLOC_COND(base->current_event_cond);\n\t\tr = evthread_make_base_notifiable(base);\n\t\tif (r<0) {\n\t\t\tevent_warnx(\"%s: Unable to make base notifiable.\", __func__);\n\t\t\tevent_base_free(base);\n\t\t\treturn NULL;\n\t\t}\n\t}\n#endif\n\n#ifdef _WIN32\n\tif (cfg && (cfg->flags & EVENT_BASE_FLAG_STARTUP_IOCP))\n\t\tevent_base_start_iocp_(base, cfg->n_cpus_hint);\n#endif\n\n\t/* initialize watcher lists */\n\tfor (i = 0; i < EVWATCH_MAX; ++i)\n\t\tTAILQ_INIT(&base->watchers[i]);\n\n\treturn (base);\n}\n\nint\nevent_base_start_iocp_(struct event_base *base, int n_cpus)\n{\n#ifdef _WIN32\n\tif (base->iocp)\n\t\treturn 0;\n\tbase->iocp = event_iocp_port_launch_(n_cpus);\n\tif (!base->iocp) {\n\t\tevent_warnx(\"%s: Couldn't launch IOCP\", __func__);\n\t\treturn -1;\n\t}\n\treturn 0;\n#else\n\treturn -1;\n#endif\n}\n\nvoid\nevent_base_stop_iocp_(struct event_base *base)\n{\n#ifdef _WIN32\n\tint rv;\n\n\tif (!base->iocp)\n\t\treturn;\n\trv = event_iocp_shutdown_(base->iocp, -1);\n\tEVUTIL_ASSERT(rv >= 0);\n\tbase->iocp = NULL;\n#endif\n}\n\nstatic int\nevent_base_cancel_single_callback_(struct event_base *base,\n    struct event_callback *evcb,\n    int run_finalizers)\n{\n\tint result = 0;\n\n\tif (evcb->evcb_flags & EVLIST_INIT) {\n\t\tstruct event *ev = event_callback_to_event(evcb);\n\t\tif (!(ev->ev_flags & EVLIST_INTERNAL)) {\n\t\t\tevent_del_(ev, EVENT_DEL_EVEN_IF_FINALIZING);\n\t\t\tresult = 1;\n\t\t}\n\t} else {\n\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\tevent_callback_cancel_nolock_(base, evcb, 1);\n\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\tresult = 1;\n\t}\n\n\tif (run_finalizers && (evcb->evcb_flags & EVLIST_FINALIZING)) {\n\t\tswitch (evcb->evcb_closure) {\n\t\tcase EV_CLOSURE_EVENT_FINALIZE:\n\t\tcase EV_CLOSURE_EVENT_FINALIZE_FREE: {\n\t\t\tstruct event *ev = event_callback_to_event(evcb);\n\t\t\tev->ev_evcallback.evcb_cb_union.evcb_evfinalize(ev, ev->ev_arg);\n\t\t\tif (evcb->evcb_closure == EV_CLOSURE_EVENT_FINALIZE_FREE)\n\t\t\t\tmm_free(ev);\n\t\t\tbreak;\n\t\t}\n\t\tcase EV_CLOSURE_CB_FINALIZE:\n\t\t\tevcb->evcb_cb_union.evcb_cbfinalize(evcb, evcb->evcb_arg);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn result;\n}\n\nstatic int event_base_free_queues_(struct event_base *base, int run_finalizers)\n{\n\tint deleted = 0, i;\n\n\tfor (i = 0; i < base->nactivequeues; ++i) {\n\t\tstruct event_callback *evcb, *next;\n\t\tfor (evcb = TAILQ_FIRST(&base->activequeues[i]); evcb; ) {\n\t\t\tnext = TAILQ_NEXT(evcb, evcb_active_next);\n\t\t\tdeleted += event_base_cancel_single_callback_(base, evcb, run_finalizers);\n\t\t\tevcb = next;\n\t\t}\n\t}\n\n\t{\n\t\tstruct event_callback *evcb;\n\t\twhile ((evcb = TAILQ_FIRST(&base->active_later_queue))) {\n\t\t\tdeleted += event_base_cancel_single_callback_(base, evcb, run_finalizers);\n\t\t}\n\t}\n\n\treturn deleted;\n}\n\nstatic void\nevent_base_free_(struct event_base *base, int run_finalizers)\n{\n\tint i;\n\tsize_t n_deleted=0;\n\tstruct event *ev;\n\tstruct evwatch *watcher;\n\t/* XXXX grab the lock? If there is contention when one thread frees\n\t * the base, then the contending thread will be very sad soon. */\n\n\t/* event_base_free(NULL) is how to free the current_base if we\n\t * made it with event_init and forgot to hold a reference to it. */\n\tif (base == NULL && current_base)\n\t\tbase = current_base;\n\t/* Don't actually free NULL. */\n\tif (base == NULL) {\n\t\tevent_warnx(\"%s: no base to free\", __func__);\n\t\treturn;\n\t}\n\t/* XXX(niels) - check for internal events first */\n\n#ifdef _WIN32\n\tevent_base_stop_iocp_(base);\n#endif\n\n\t/* threading fds if we have them */\n\tif (base->th_notify_fd[0] != -1) {\n\t\tevent_del(&base->th_notify);\n\t\tEVUTIL_CLOSESOCKET(base->th_notify_fd[0]);\n\t\tif (base->th_notify_fd[1] != -1)\n\t\t\tEVUTIL_CLOSESOCKET(base->th_notify_fd[1]);\n\t\tbase->th_notify_fd[0] = -1;\n\t\tbase->th_notify_fd[1] = -1;\n\t\tevent_debug_unassign(&base->th_notify);\n\t}\n\n\t/* Delete all non-internal events. */\n\tevmap_delete_all_(base);\n\n\twhile ((ev = min_heap_top_(&base->timeheap)) != NULL) {\n\t\tevent_del(ev);\n\t\t++n_deleted;\n\t}\n\tfor (i = 0; i < base->n_common_timeouts; ++i) {\n\t\tstruct common_timeout_list *ctl =\n\t\t    base->common_timeout_queues[i];\n\t\tevent_del(&ctl->timeout_event); /* Internal; doesn't count */\n\t\tevent_debug_unassign(&ctl->timeout_event);\n\t\tfor (ev = TAILQ_FIRST(&ctl->events); ev; ) {\n\t\t\tstruct event *next = TAILQ_NEXT(ev,\n\t\t\t    ev_timeout_pos.ev_next_with_common_timeout);\n\t\t\tif (!(ev->ev_flags & EVLIST_INTERNAL)) {\n\t\t\t\tevent_del(ev);\n\t\t\t\t++n_deleted;\n\t\t\t}\n\t\t\tev = next;\n\t\t}\n\t\tmm_free(ctl);\n\t}\n\tif (base->common_timeout_queues)\n\t\tmm_free(base->common_timeout_queues);\n\n\tfor (;;) {\n\t\t/* For finalizers we can register yet another finalizer out from\n\t\t * finalizer, and iff finalizer will be in active_later_queue we can\n\t\t * add finalizer to activequeues, and we will have events in\n\t\t * activequeues after this function returns, which is not what we want\n\t\t * (we even have an assertion for this).\n\t\t *\n\t\t * A simple case is bufferevent with underlying (i.e. filters).\n\t\t */\n\t\tint i = event_base_free_queues_(base, run_finalizers);\n\t\tevent_debug((\"%s: %d events freed\", __func__, i));\n\t\tif (!i) {\n\t\t\tbreak;\n\t\t}\n\t\tn_deleted += i;\n\t}\n\n\tif (n_deleted)\n\t\tevent_debug((\"%s: \"EV_SIZE_FMT\" events were still set in base\",\n\t\t\t__func__, n_deleted));\n\n\twhile (LIST_FIRST(&base->once_events)) {\n\t\tstruct event_once *eonce = LIST_FIRST(&base->once_events);\n\t\tLIST_REMOVE(eonce, next_once);\n\t\tmm_free(eonce);\n\t}\n\n\tif (base->evsel != NULL && base->evsel->dealloc != NULL)\n\t\tbase->evsel->dealloc(base);\n\n\tfor (i = 0; i < base->nactivequeues; ++i)\n\t\tEVUTIL_ASSERT(TAILQ_EMPTY(&base->activequeues[i]));\n\n\tEVUTIL_ASSERT(min_heap_empty_(&base->timeheap));\n\tmin_heap_dtor_(&base->timeheap);\n\n\tmm_free(base->activequeues);\n\n\tevmap_io_clear_(&base->io);\n\tevmap_signal_clear_(&base->sigmap);\n\tevent_changelist_freemem_(&base->changelist);\n\n\tEVTHREAD_FREE_LOCK(base->th_base_lock, 0);\n\tEVTHREAD_FREE_COND(base->current_event_cond);\n\n\t/* Free all event watchers */\n\tfor (i = 0; i < EVWATCH_MAX; ++i) {\n\t\twhile (!TAILQ_EMPTY(&base->watchers[i])) {\n\t\t\twatcher = TAILQ_FIRST(&base->watchers[i]);\n\t\t\tTAILQ_REMOVE(&base->watchers[i], watcher, next);\n\t\t\tmm_free(watcher);\n\t\t}\n\t}\n\n\t/* If we're freeing current_base, there won't be a current_base. */\n\tif (base == current_base)\n\t\tcurrent_base = NULL;\n\tmm_free(base);\n}\n\nvoid\nevent_base_free_nofinalize(struct event_base *base)\n{\n\tevent_base_free_(base, 0);\n}\n\nvoid\nevent_base_free(struct event_base *base)\n{\n\tevent_base_free_(base, 1);\n}\n\n/* Fake eventop; used to disable the backend temporarily inside event_reinit\n * so that we can call event_del() on an event without telling the backend.\n */\nstatic int\nnil_backend_del(struct event_base *b, evutil_socket_t fd, short old,\n    short events, void *fdinfo)\n{\n\treturn 0;\n}\nconst struct eventop nil_eventop = {\n\t\"nil\",\n\tNULL, /* init: unused. */\n\tNULL, /* add: unused. */\n\tnil_backend_del, /* del: used, so needs to be killed. */\n\tNULL, /* dispatch: unused. */\n\tNULL, /* dealloc: unused. */\n\t0, 0, 0\n};\n\n/* reinitialize the event base after a fork */\nint\nevent_reinit(struct event_base *base)\n{\n\tconst struct eventop *evsel;\n\tint res = 0;\n\tint was_notifiable = 0;\n\tint had_signal_added = 0;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tevsel = base->evsel;\n\n\t/* check if this event mechanism requires reinit on the backend */\n\tif (evsel->need_reinit) {\n\t\t/* We're going to call event_del() on our notify events (the\n\t\t * ones that tell about signals and wakeup events).  But we\n\t\t * don't actually want to tell the backend to change its\n\t\t * state, since it might still share some resource (a kqueue,\n\t\t * an epoll fd) with the parent process, and we don't want to\n\t\t * delete the fds from _that_ backend, we temporarily stub out\n\t\t * the evsel with a replacement.\n\t\t */\n\t\tbase->evsel = &nil_eventop;\n\t}\n\n\t/* We need to re-create a new signal-notification fd and a new\n\t * thread-notification fd.  Otherwise, we'll still share those with\n\t * the parent process, which would make any notification sent to them\n\t * get received by one or both of the event loops, more or less at\n\t * random.\n\t */\n\tif (base->sig.ev_signal_added) {\n\t\tevent_del_nolock_(&base->sig.ev_signal, EVENT_DEL_AUTOBLOCK);\n\t\tevent_debug_unassign(&base->sig.ev_signal);\n\t\tmemset(&base->sig.ev_signal, 0, sizeof(base->sig.ev_signal));\n\t\thad_signal_added = 1;\n\t\tbase->sig.ev_signal_added = 0;\n\t}\n\tif (base->sig.ev_signal_pair[0] != -1)\n\t\tEVUTIL_CLOSESOCKET(base->sig.ev_signal_pair[0]);\n\tif (base->sig.ev_signal_pair[1] != -1)\n\t\tEVUTIL_CLOSESOCKET(base->sig.ev_signal_pair[1]);\n\tif (base->th_notify_fn != NULL) {\n\t\twas_notifiable = 1;\n\t\tbase->th_notify_fn = NULL;\n\t}\n\tif (base->th_notify_fd[0] != -1) {\n\t\tevent_del_nolock_(&base->th_notify, EVENT_DEL_AUTOBLOCK);\n\t\tEVUTIL_CLOSESOCKET(base->th_notify_fd[0]);\n\t\tif (base->th_notify_fd[1] != -1)\n\t\t\tEVUTIL_CLOSESOCKET(base->th_notify_fd[1]);\n\t\tbase->th_notify_fd[0] = -1;\n\t\tbase->th_notify_fd[1] = -1;\n\t\tevent_debug_unassign(&base->th_notify);\n\t}\n\n\t/* Replace the original evsel. */\n        base->evsel = evsel;\n\n\tif (evsel->need_reinit) {\n\t\t/* Reconstruct the backend through brute-force, so that we do\n\t\t * not share any structures with the parent process. For some\n\t\t * backends, this is necessary: epoll and kqueue, for\n\t\t * instance, have events associated with a kernel\n\t\t * structure. If didn't reinitialize, we'd share that\n\t\t * structure with the parent process, and any changes made by\n\t\t * the parent would affect our backend's behavior (and vice\n\t\t * versa).\n\t\t */\n\t\tif (base->evsel->dealloc != NULL)\n\t\t\tbase->evsel->dealloc(base);\n\t\tbase->evbase = evsel->init(base);\n\t\tif (base->evbase == NULL) {\n\t\t\tevent_errx(1,\n\t\t\t   \"%s: could not reinitialize event mechanism\",\n\t\t\t   __func__);\n\t\t\tres = -1;\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Empty out the changelist (if any): we are starting from a\n\t\t * blank slate. */\n\t\tevent_changelist_freemem_(&base->changelist);\n\n\t\t/* Tell the event maps to re-inform the backend about all\n\t\t * pending events. This will make the signal notification\n\t\t * event get re-created if necessary. */\n\t\tif (evmap_reinit_(base) < 0)\n\t\t\tres = -1;\n\t} else {\n\t\tres = evsig_init_(base);\n\t\tif (res == 0 && had_signal_added) {\n\t\t\tres = event_add_nolock_(&base->sig.ev_signal, NULL, 0);\n\t\t\tif (res == 0)\n\t\t\t\tbase->sig.ev_signal_added = 1;\n\t\t}\n\t}\n\n\t/* If we were notifiable before, and nothing just exploded, become\n\t * notifiable again. */\n\tif (was_notifiable && res == 0)\n\t\tres = evthread_make_base_notifiable_nolock_(base);\n\ndone:\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn (res);\n}\n\n/* Get the monotonic time for this event_base' timer */\nint\nevent_gettime_monotonic(struct event_base *base, struct timeval *tv)\n{\n\tint rv = -1;\n\n\tif (base && tv) {\n\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\trv = evutil_gettime_monotonic_(&(base->monotonic_timer), tv);\n\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t}\n\n\treturn rv;\n}\n\nconst char **\nevent_get_supported_methods(void)\n{\n\tstatic const char **methods = NULL;\n\tconst struct eventop **method;\n\tconst char **tmp;\n\tint i = 0, k;\n\n\t/* count all methods */\n\tfor (method = &eventops[0]; *method != NULL; ++method) {\n\t\t++i;\n\t}\n\n\t/* allocate one more than we need for the NULL pointer */\n\ttmp = mm_calloc((i + 1), sizeof(char *));\n\tif (tmp == NULL)\n\t\treturn (NULL);\n\n\t/* populate the array with the supported methods */\n\tfor (k = 0, i = 0; eventops[k] != NULL; ++k) {\n\t\ttmp[i++] = eventops[k]->name;\n\t}\n\ttmp[i] = NULL;\n\n\tif (methods != NULL)\n\t\tmm_free((char**)methods);\n\n\tmethods = tmp;\n\n\treturn (methods);\n}\n\nstruct event_config *\nevent_config_new(void)\n{\n\tstruct event_config *cfg = mm_calloc(1, sizeof(*cfg));\n\n\tif (cfg == NULL)\n\t\treturn (NULL);\n\n\tTAILQ_INIT(&cfg->entries);\n\tcfg->max_dispatch_interval.tv_sec = -1;\n\tcfg->max_dispatch_callbacks = INT_MAX;\n\tcfg->limit_callbacks_after_prio = 1;\n\n\treturn (cfg);\n}\n\nstatic void\nevent_config_entry_free(struct event_config_entry *entry)\n{\n\tif (entry->avoid_method != NULL)\n\t\tmm_free((char *)entry->avoid_method);\n\tmm_free(entry);\n}\n\nvoid\nevent_config_free(struct event_config *cfg)\n{\n\tstruct event_config_entry *entry;\n\n\twhile ((entry = TAILQ_FIRST(&cfg->entries)) != NULL) {\n\t\tTAILQ_REMOVE(&cfg->entries, entry, next);\n\t\tevent_config_entry_free(entry);\n\t}\n\tmm_free(cfg);\n}\n\nint\nevent_config_set_flag(struct event_config *cfg, int flag)\n{\n\tif (!cfg)\n\t\treturn -1;\n\tcfg->flags |= flag;\n\treturn 0;\n}\n\nint\nevent_config_avoid_method(struct event_config *cfg, const char *method)\n{\n\tstruct event_config_entry *entry = mm_malloc(sizeof(*entry));\n\tif (entry == NULL)\n\t\treturn (-1);\n\n\tif ((entry->avoid_method = mm_strdup(method)) == NULL) {\n\t\tmm_free(entry);\n\t\treturn (-1);\n\t}\n\n\tTAILQ_INSERT_TAIL(&cfg->entries, entry, next);\n\n\treturn (0);\n}\n\nint\nevent_config_require_features(struct event_config *cfg,\n    int features)\n{\n\tif (!cfg)\n\t\treturn (-1);\n\tcfg->require_features = features;\n\treturn (0);\n}\n\nint\nevent_config_set_num_cpus_hint(struct event_config *cfg, int cpus)\n{\n\tif (!cfg)\n\t\treturn (-1);\n\tcfg->n_cpus_hint = cpus;\n\treturn (0);\n}\n\nint\nevent_config_set_max_dispatch_interval(struct event_config *cfg,\n    const struct timeval *max_interval, int max_callbacks, int min_priority)\n{\n\tif (max_interval)\n\t\tmemcpy(&cfg->max_dispatch_interval, max_interval,\n\t\t    sizeof(struct timeval));\n\telse\n\t\tcfg->max_dispatch_interval.tv_sec = -1;\n\tcfg->max_dispatch_callbacks =\n\t    max_callbacks >= 0 ? max_callbacks : INT_MAX;\n\tif (min_priority < 0)\n\t\tmin_priority = 0;\n\tcfg->limit_callbacks_after_prio = min_priority;\n\treturn (0);\n}\n\nint\nevent_priority_init(int npriorities)\n{\n\treturn event_base_priority_init(current_base, npriorities);\n}\n\nint\nevent_base_priority_init(struct event_base *base, int npriorities)\n{\n\tint i, r;\n\tr = -1;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (N_ACTIVE_CALLBACKS(base) || npriorities < 1\n\t    || npriorities >= EVENT_MAX_PRIORITIES)\n\t\tgoto err;\n\n\tif (npriorities == base->nactivequeues)\n\t\tgoto ok;\n\n\tif (base->nactivequeues) {\n\t\tmm_free(base->activequeues);\n\t\tbase->nactivequeues = 0;\n\t}\n\n\t/* Allocate our priority queues */\n\tbase->activequeues = (struct evcallback_list *)\n\t  mm_calloc(npriorities, sizeof(struct evcallback_list));\n\tif (base->activequeues == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto err;\n\t}\n\tbase->nactivequeues = npriorities;\n\n\tfor (i = 0; i < base->nactivequeues; ++i) {\n\t\tTAILQ_INIT(&base->activequeues[i]);\n\t}\n\nok:\n\tr = 0;\nerr:\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn (r);\n}\n\nint\nevent_base_get_npriorities(struct event_base *base)\n{\n\n\tint n;\n\tif (base == NULL)\n\t\tbase = current_base;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tn = base->nactivequeues;\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn (n);\n}\n\nint\nevent_base_get_num_events(struct event_base *base, unsigned int type)\n{\n\tint r = 0;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (type & EVENT_BASE_COUNT_ACTIVE)\n\t\tr += base->event_count_active;\n\n\tif (type & EVENT_BASE_COUNT_VIRTUAL)\n\t\tr += base->virtual_event_count;\n\n\tif (type & EVENT_BASE_COUNT_ADDED)\n\t\tr += base->event_count;\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\treturn r;\n}\n\nint\nevent_base_get_max_events(struct event_base *base, unsigned int type, int clear)\n{\n\tint r = 0;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (type & EVENT_BASE_COUNT_ACTIVE) {\n\t\tr += base->event_count_active_max;\n\t\tif (clear)\n\t\t\tbase->event_count_active_max = 0;\n\t}\n\n\tif (type & EVENT_BASE_COUNT_VIRTUAL) {\n\t\tr += base->virtual_event_count_max;\n\t\tif (clear)\n\t\t\tbase->virtual_event_count_max = 0;\n\t}\n\n\tif (type & EVENT_BASE_COUNT_ADDED) {\n\t\tr += base->event_count_max;\n\t\tif (clear)\n\t\t\tbase->event_count_max = 0;\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\treturn r;\n}\n\n/* Returns true iff we're currently watching any events. */\nstatic int\nevent_haveevents(struct event_base *base)\n{\n\t/* Caller must hold th_base_lock */\n\treturn (base->virtual_event_count > 0 || base->event_count > 0);\n}\n\n/* \"closure\" function called when processing active signal events */\nstatic inline void\nevent_signal_closure(struct event_base *base, struct event *ev)\n{\n#if defined(__clang__)\n#elif defined(__GNUC__)\n#pragma GCC diagnostic push\n/* NOTE: it is better to avoid such code all together, by using separate\n * variable to break the loop in the event structure, but now this code is safe\n * */\n#pragma GCC diagnostic ignored \"-Wdangling-pointer\"\n#endif\n\n\tshort ncalls;\n\tint should_break;\n\n\t/* Allows deletes to work, see also event_del_nolock_() that has\n\t * special treatment for signals */\n\tncalls = ev->ev_ncalls;\n\tif (ncalls != 0)\n\t\tev->ev_pncalls = &ncalls;\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\twhile (ncalls) {\n\t\tncalls--;\n\t\tev->ev_ncalls = ncalls;\n\t\tif (ncalls == 0)\n\t\t\tev->ev_pncalls = NULL;\n\t\t(*ev->ev_callback)(ev->ev_fd, ev->ev_res, ev->ev_arg);\n\n\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\tshould_break = base->event_break;\n\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\t\tif (should_break) {\n\t\t\tif (ncalls != 0)\n\t\t\t\tev->ev_pncalls = NULL;\n\t\t\treturn;\n\t\t}\n\t}\n\n#if defined(__clang__)\n#elif defined(__GNUC__)\n#pragma GCC diagnostic pop\n#endif\n}\n\n/* Common timeouts are special timeouts that are handled as queues rather than\n * in the minheap.  This is more efficient than the minheap if we happen to\n * know that we're going to get several thousands of timeout events all with\n * the same timeout value.\n *\n * Since all our timeout handling code assumes timevals can be copied,\n * assigned, etc, we can't use \"magic pointer\" to encode these common\n * timeouts.  Searching through a list to see if every timeout is common could\n * also get inefficient.  Instead, we take advantage of the fact that tv_usec\n * is 32 bits long, but only uses 20 of those bits (since it can never be over\n * 999999.)  We use the top bits to encode 4 bites of magic number, and 8 bits\n * of index into the event_base's aray of common timeouts.\n */\n\n#define MICROSECONDS_MASK       COMMON_TIMEOUT_MICROSECONDS_MASK\n#define COMMON_TIMEOUT_IDX_MASK 0x0ff00000\n#define COMMON_TIMEOUT_IDX_SHIFT 20\n#define COMMON_TIMEOUT_MASK     0xf0000000\n#define COMMON_TIMEOUT_MAGIC    0x50000000\n\n#define COMMON_TIMEOUT_IDX(tv) \\\n\t(((tv)->tv_usec & COMMON_TIMEOUT_IDX_MASK)>>COMMON_TIMEOUT_IDX_SHIFT)\n\n/** Return true iff if 'tv' is a common timeout in 'base' */\nstatic inline int\nis_common_timeout(const struct timeval *tv,\n    const struct event_base *base)\n{\n\tint idx;\n\tif ((tv->tv_usec & COMMON_TIMEOUT_MASK) != COMMON_TIMEOUT_MAGIC)\n\t\treturn 0;\n\tidx = COMMON_TIMEOUT_IDX(tv);\n\treturn idx < base->n_common_timeouts;\n}\n\n/* True iff tv1 and tv2 have the same common-timeout index, or if neither\n * one is a common timeout. */\nstatic inline int\nis_same_common_timeout(const struct timeval *tv1, const struct timeval *tv2)\n{\n\treturn (tv1->tv_usec & ~MICROSECONDS_MASK) ==\n\t    (tv2->tv_usec & ~MICROSECONDS_MASK);\n}\n\n/** Requires that 'tv' is a common timeout.  Return the corresponding\n * common_timeout_list. */\nstatic inline struct common_timeout_list *\nget_common_timeout_list(struct event_base *base, const struct timeval *tv)\n{\n\treturn base->common_timeout_queues[COMMON_TIMEOUT_IDX(tv)];\n}\n\n#if 0\nstatic inline int\ncommon_timeout_ok(const struct timeval *tv,\n    struct event_base *base)\n{\n\tconst struct timeval *expect =\n\t    &get_common_timeout_list(base, tv)->duration;\n\treturn tv->tv_sec == expect->tv_sec &&\n\t    tv->tv_usec == expect->tv_usec;\n}\n#endif\n\n/* Add the timeout for the first event in given common timeout list to the\n * event_base's minheap. */\nstatic void\ncommon_timeout_schedule(struct common_timeout_list *ctl,\n    const struct timeval *now, struct event *head)\n{\n\tstruct timeval timeout = head->ev_timeout;\n\ttimeout.tv_usec &= MICROSECONDS_MASK;\n\tevent_add_nolock_(&ctl->timeout_event, &timeout, 1);\n}\n\n/* Callback: invoked when the timeout for a common timeout queue triggers.\n * This means that (at least) the first event in that queue should be run,\n * and the timeout should be rescheduled if there are more events. */\nstatic void\ncommon_timeout_callback(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct timeval now;\n\tstruct common_timeout_list *ctl = arg;\n\tstruct event_base *base = ctl->base;\n\tstruct event *ev = NULL;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tgettime(base, &now);\n\twhile (1) {\n\t\tint was_active;\n\t\tev = TAILQ_FIRST(&ctl->events);\n\t\tif (!ev || ev->ev_timeout.tv_sec > now.tv_sec ||\n\t\t    (ev->ev_timeout.tv_sec == now.tv_sec &&\n\t\t\t(ev->ev_timeout.tv_usec&MICROSECONDS_MASK) > now.tv_usec))\n\t\t\tbreak;\n\t\twas_active = ev->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER);\n\t\tif (!was_active)\n\t\t\tevent_del_nolock_(ev, EVENT_DEL_NOBLOCK);\n\t\telse\n\t\t\tevent_queue_remove_timeout(base, ev);\n\t\tevent_active_nolock_(ev, EV_TIMEOUT, 1);\n\t}\n\tif (ev)\n\t\tcommon_timeout_schedule(ctl, &now, ev);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\n#define MAX_COMMON_TIMEOUTS 256\n\nconst struct timeval *\nevent_base_init_common_timeout(struct event_base *base,\n    const struct timeval *duration)\n{\n\tint i;\n\tstruct timeval tv;\n\tconst struct timeval *result=NULL;\n\tstruct common_timeout_list *new_ctl;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (duration->tv_usec > 1000000) {\n\t\tmemcpy(&tv, duration, sizeof(struct timeval));\n\t\tif (is_common_timeout(duration, base))\n\t\t\ttv.tv_usec &= MICROSECONDS_MASK;\n\t\ttv.tv_sec += tv.tv_usec / 1000000;\n\t\ttv.tv_usec %= 1000000;\n\t\tduration = &tv;\n\t}\n\tfor (i = 0; i < base->n_common_timeouts; ++i) {\n\t\tconst struct common_timeout_list *ctl =\n\t\t    base->common_timeout_queues[i];\n\t\tif (duration->tv_sec == ctl->duration.tv_sec &&\n\t\t    duration->tv_usec ==\n\t\t    (ctl->duration.tv_usec & MICROSECONDS_MASK)) {\n\t\t\tEVUTIL_ASSERT(is_common_timeout(&ctl->duration, base));\n\t\t\tresult = &ctl->duration;\n\t\t\tgoto done;\n\t\t}\n\t}\n\tif (base->n_common_timeouts == MAX_COMMON_TIMEOUTS) {\n\t\tevent_warnx(\"%s: Too many common timeouts already in use; \"\n\t\t    \"we only support %d per event_base\", __func__,\n\t\t    MAX_COMMON_TIMEOUTS);\n\t\tgoto done;\n\t}\n\tif (base->n_common_timeouts_allocated == base->n_common_timeouts) {\n\t\tint n = base->n_common_timeouts < 16 ? 16 :\n\t\t    base->n_common_timeouts*2;\n\t\tstruct common_timeout_list **newqueues =\n\t\t    mm_realloc(base->common_timeout_queues,\n\t\t\tn*sizeof(struct common_timeout_queue *));\n\t\tif (!newqueues) {\n\t\t\tevent_warn(\"%s: realloc\",__func__);\n\t\t\tgoto done;\n\t\t}\n\t\tbase->n_common_timeouts_allocated = n;\n\t\tbase->common_timeout_queues = newqueues;\n\t}\n\tnew_ctl = mm_calloc(1, sizeof(struct common_timeout_list));\n\tif (!new_ctl) {\n\t\tevent_warn(\"%s: calloc\",__func__);\n\t\tgoto done;\n\t}\n\tTAILQ_INIT(&new_ctl->events);\n\tnew_ctl->duration.tv_sec = duration->tv_sec;\n\tnew_ctl->duration.tv_usec =\n\t    duration->tv_usec | COMMON_TIMEOUT_MAGIC |\n\t    (base->n_common_timeouts << COMMON_TIMEOUT_IDX_SHIFT);\n\tevtimer_assign(&new_ctl->timeout_event, base,\n\t    common_timeout_callback, new_ctl);\n\tnew_ctl->timeout_event.ev_flags |= EVLIST_INTERNAL;\n\tevent_priority_set(&new_ctl->timeout_event, 0);\n\tnew_ctl->base = base;\n\tbase->common_timeout_queues[base->n_common_timeouts++] = new_ctl;\n\tresult = &new_ctl->duration;\n\ndone:\n\tif (result)\n\t\tEVUTIL_ASSERT(is_common_timeout(result, base));\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn result;\n}\n\n/* Closure function invoked when we're activating a persistent event. */\nstatic inline void\nevent_persist_closure(struct event_base *base, struct event *ev)\n{\n\tvoid (*evcb_callback)(evutil_socket_t, short, void *);\n\n\t// Other fields of *ev that must be stored before executing\n\tevutil_socket_t evcb_fd;\n\tshort evcb_res;\n\tvoid *evcb_arg;\n\n\t/* reschedule the persistent event if we have a timeout. */\n\tif (ev->ev_io_timeout.tv_sec || ev->ev_io_timeout.tv_usec) {\n\t\t/* If there was a timeout, we want it to run at an interval of\n\t\t * ev_io_timeout after the last time it was _scheduled_ for,\n\t\t * not ev_io_timeout after _now_.  If it fired for another\n\t\t * reason, though, the timeout ought to start ticking _now_. */\n\t\tstruct timeval run_at, relative_to, delay, now;\n\t\tev_uint32_t usec_mask = 0;\n\t\tEVUTIL_ASSERT(is_same_common_timeout(&ev->ev_timeout,\n\t\t\t&ev->ev_io_timeout));\n\t\tgettime(base, &now);\n\t\tif (is_common_timeout(&ev->ev_timeout, base)) {\n\t\t\tdelay = ev->ev_io_timeout;\n\t\t\tusec_mask = delay.tv_usec & ~MICROSECONDS_MASK;\n\t\t\tdelay.tv_usec &= MICROSECONDS_MASK;\n\t\t\tif (ev->ev_res & EV_TIMEOUT) {\n\t\t\t\trelative_to = ev->ev_timeout;\n\t\t\t\trelative_to.tv_usec &= MICROSECONDS_MASK;\n\t\t\t} else {\n\t\t\t\trelative_to = now;\n\t\t\t}\n\t\t} else {\n\t\t\tdelay = ev->ev_io_timeout;\n\t\t\tif (ev->ev_res & EV_TIMEOUT) {\n\t\t\t\trelative_to = ev->ev_timeout;\n\t\t\t} else {\n\t\t\t\trelative_to = now;\n\t\t\t}\n\t\t}\n\t\tevutil_timeradd(&relative_to, &delay, &run_at);\n\t\tif (evutil_timercmp(&run_at, &now, <)) {\n\t\t\t/* Looks like we missed at least one invocation due to\n\t\t\t * a clock jump, not running the event loop for a\n\t\t\t * while, really slow callbacks, or\n\t\t\t * something. Reschedule relative to now.\n\t\t\t */\n\t\t\tevutil_timeradd(&now, &delay, &run_at);\n\t\t}\n\t\trun_at.tv_usec |= usec_mask;\n\t\tevent_add_nolock_(ev, &run_at, 1);\n\t}\n\n\t// Save our callback before we release the lock\n\tevcb_callback = ev->ev_callback;\n\tevcb_fd = ev->ev_fd;\n\tevcb_res = ev->ev_res;\n\tevcb_arg = ev->ev_arg;\n\n\t// Release the lock\n \tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\t// Execute the callback\n\t(evcb_callback)(evcb_fd, evcb_res, evcb_arg);\n}\n\n/*\n  Helper for event_process_active to process all the events in a single queue,\n  releasing the lock as we go.  This function requires that the lock be held\n  when it's invoked.  Returns -1 if we get a signal or an event_break that\n  means we should stop processing any active events now.  Otherwise returns\n  the number of non-internal event_callbacks that we processed.\n*/\nstatic int\nevent_process_active_single_queue(struct event_base *base,\n    struct evcallback_list *activeq,\n    int max_to_process, const struct timeval *endtime)\n{\n\tstruct event_callback *evcb;\n\tint count = 0;\n\n\tEVUTIL_ASSERT(activeq != NULL);\n\n\tfor (evcb = TAILQ_FIRST(activeq); evcb; evcb = TAILQ_FIRST(activeq)) {\n\t\tstruct event *ev = NULL;\n\t\tif (evcb->evcb_flags & EVLIST_INIT) {\n\t\t\tev = event_callback_to_event(evcb);\n\n\t\t\tif (ev->ev_events & EV_PERSIST || ev->ev_flags & EVLIST_FINALIZING)\n\t\t\t\tevent_queue_remove_active(base, evcb);\n\t\t\telse\n\t\t\t\tevent_del_nolock_(ev, EVENT_DEL_NOBLOCK);\n\t\t\tevent_debug((\n\t\t\t    \"event_process_active: event: %p, %s%s%scall %p\",\n\t\t\t    (void *)ev,\n\t\t\t    ev->ev_res & EV_READ ? \"EV_READ \" : \" \",\n\t\t\t    ev->ev_res & EV_WRITE ? \"EV_WRITE \" : \" \",\n\t\t\t    ev->ev_res & EV_CLOSED ? \"EV_CLOSED \" : \" \",\n\t\t\t    (void *)ev->ev_callback));\n\t\t} else {\n\t\t\tevent_queue_remove_active(base, evcb);\n\t\t\tevent_debug((\"event_process_active: event_callback %p, \"\n\t\t\t\t\"closure %d, call %p\",\n\t\t\t\t(void *)evcb, evcb->evcb_closure, (void *)evcb->evcb_cb_union.evcb_callback));\n\t\t}\n\t\t// We don't want an infinite loop or use of memory after it is freed.\n\t\t// Hence, for next loop iteration, it is expected that `event_queue_remove_active` or `event_del_nolock_` have removed current event from the queue at this point.\n\t\tEVUTIL_ASSERT(evcb != TAILQ_FIRST(activeq));\n\n\t\tif (!(evcb->evcb_flags & EVLIST_INTERNAL))\n\t\t\t++count;\n\n\n\t\tbase->current_event = evcb;\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\t\tbase->current_event_waiters = 0;\n#endif\n\n\t\tswitch (evcb->evcb_closure) {\n\t\tcase EV_CLOSURE_EVENT_SIGNAL:\n\t\t\tEVUTIL_ASSERT(ev != NULL);\n\t\t\tevent_signal_closure(base, ev);\n\t\t\tbreak;\n\t\tcase EV_CLOSURE_EVENT_PERSIST:\n\t\t\tEVUTIL_ASSERT(ev != NULL);\n\t\t\tevent_persist_closure(base, ev);\n\t\t\tbreak;\n\t\tcase EV_CLOSURE_EVENT: {\n\t\t\tvoid (*evcb_callback)(evutil_socket_t, short, void *);\n\t\t\tshort res;\n\t\t\tEVUTIL_ASSERT(ev != NULL);\n\t\t\tevcb_callback = *ev->ev_callback;\n\t\t\tres = ev->ev_res;\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\tevcb_callback(ev->ev_fd, res, ev->ev_arg);\n\t\t}\n\t\tbreak;\n\t\tcase EV_CLOSURE_CB_SELF: {\n\t\t\tvoid (*evcb_selfcb)(struct event_callback *, void *) = evcb->evcb_cb_union.evcb_selfcb;\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\tevcb_selfcb(evcb, evcb->evcb_arg);\n\t\t}\n\t\tbreak;\n\t\tcase EV_CLOSURE_EVENT_FINALIZE:\n\t\tcase EV_CLOSURE_EVENT_FINALIZE_FREE: {\n\t\t\tvoid (*evcb_evfinalize)(struct event *, void *);\n\t\t\tint evcb_closure = evcb->evcb_closure;\n\t\t\tEVUTIL_ASSERT(ev != NULL);\n\t\t\tbase->current_event = NULL;\n\t\t\tevcb_evfinalize = ev->ev_evcallback.evcb_cb_union.evcb_evfinalize;\n\t\t\tEVUTIL_ASSERT((evcb->evcb_flags & EVLIST_FINALIZING));\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\tevent_debug_note_teardown_(ev);\n\t\t\tevcb_evfinalize(ev, ev->ev_arg);\n\t\t\tif (evcb_closure == EV_CLOSURE_EVENT_FINALIZE_FREE)\n\t\t\t\tmm_free(ev);\n\t\t}\n\t\tbreak;\n\t\tcase EV_CLOSURE_CB_FINALIZE: {\n\t\t\tvoid (*evcb_cbfinalize)(struct event_callback *, void *) = evcb->evcb_cb_union.evcb_cbfinalize;\n\t\t\tbase->current_event = NULL;\n\t\t\tEVUTIL_ASSERT((evcb->evcb_flags & EVLIST_FINALIZING));\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\tevcb_cbfinalize(evcb, evcb->evcb_arg);\n\t\t}\n\t\tbreak;\n\t\tdefault:\n\t\t\tEVUTIL_ASSERT(0);\n\t\t}\n\n\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\tbase->current_event = NULL;\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\t\tif (base->current_event_waiters) {\n\t\t\tbase->current_event_waiters = 0;\n\t\t\tEVTHREAD_COND_BROADCAST(base->current_event_cond);\n\t\t}\n#endif\n\n\t\tif (base->event_break)\n\t\t\treturn -1;\n\t\tif (count >= max_to_process)\n\t\t\treturn count;\n\t\tif (count && endtime) {\n\t\t\tstruct timeval now;\n\t\t\tupdate_time_cache(base);\n\t\t\tgettime(base, &now);\n\t\t\tif (evutil_timercmp(&now, endtime, >=))\n\t\t\t\treturn count;\n\t\t}\n\t\tif (base->event_continue)\n\t\t\tbreak;\n\t}\n\treturn count;\n}\n\n/*\n * Active events are stored in priority queues.  Lower priorities are always\n * process before higher priorities.  Low priority events can starve high\n * priority ones.\n */\n\nstatic int\nevent_process_active(struct event_base *base)\n{\n\t/* Caller must hold th_base_lock */\n\tstruct evcallback_list *activeq = NULL;\n\tint i, c = 0;\n\tconst struct timeval *endtime;\n\tstruct timeval tv;\n\tconst int maxcb = base->max_dispatch_callbacks;\n\tconst int limit_after_prio = base->limit_callbacks_after_prio;\n\tif (base->max_dispatch_time.tv_sec >= 0) {\n\t\tupdate_time_cache(base);\n\t\tgettime(base, &tv);\n\t\tevutil_timeradd(&base->max_dispatch_time, &tv, &tv);\n\t\tendtime = &tv;\n\t} else {\n\t\tendtime = NULL;\n\t}\n\n\tfor (i = 0; i < base->nactivequeues; ++i) {\n\t\tif (TAILQ_FIRST(&base->activequeues[i]) != NULL) {\n\t\t\tbase->event_running_priority = i;\n\t\t\tactiveq = &base->activequeues[i];\n\t\t\tif (i < limit_after_prio)\n\t\t\t\tc = event_process_active_single_queue(base, activeq,\n\t\t\t\t    INT_MAX, NULL);\n\t\t\telse\n\t\t\t\tc = event_process_active_single_queue(base, activeq,\n\t\t\t\t    maxcb, endtime);\n\t\t\tif (c < 0) {\n\t\t\t\tgoto done;\n\t\t\t} else if (c > 0)\n\t\t\t\tbreak; /* Processed a real event; do not\n\t\t\t\t\t* consider lower-priority events */\n\t\t\t/* If we get here, all of the events we processed\n\t\t\t * were internal.  Continue. */\n\t\t}\n\t}\n\ndone:\n\tbase->event_running_priority = -1;\n\n\treturn c;\n}\n\n/*\n * Wait continuously for events.  We exit only if no events are left.\n */\n\nint\nevent_dispatch(void)\n{\n\treturn (event_loop(0));\n}\n\nint\nevent_base_dispatch(struct event_base *event_base)\n{\n\treturn (event_base_loop(event_base, 0));\n}\n\nconst char *\nevent_base_get_method(const struct event_base *base)\n{\n\tEVUTIL_ASSERT(base);\n\treturn (base->evsel->name);\n}\n\nconst char *\nevent_base_get_signal_method(const struct event_base *base)\n{\n\tEVUTIL_ASSERT(base);\n\treturn (base->evsigsel->name);\n}\n\n/** Callback: used to implement event_base_loopexit by telling the event_base\n * that it's time to exit its loop. */\nstatic void\nevent_loopexit_cb(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct event_base *base = arg;\n\tbase->event_gotterm = 1;\n}\n\nint\nevent_loopexit(const struct timeval *tv)\n{\n\treturn (event_once(-1, EV_TIMEOUT, event_loopexit_cb,\n\t\t    current_base, tv));\n}\n\nint\nevent_base_loopexit(struct event_base *event_base, const struct timeval *tv)\n{\n\treturn (event_base_once(event_base, -1, EV_TIMEOUT, event_loopexit_cb,\n\t\t    event_base, tv));\n}\n\nint\nevent_loopbreak(void)\n{\n\treturn (event_base_loopbreak(current_base));\n}\n\nint\nevent_base_loopbreak(struct event_base *event_base)\n{\n\tint r = 0;\n\tif (event_base == NULL)\n\t\treturn (-1);\n\n\tEVBASE_ACQUIRE_LOCK(event_base, th_base_lock);\n\tevent_base->event_break = 1;\n\n\tif (EVBASE_NEED_NOTIFY(event_base)) {\n\t\tr = evthread_notify_base(event_base);\n\t} else {\n\t\tr = (0);\n\t}\n\tEVBASE_RELEASE_LOCK(event_base, th_base_lock);\n\treturn r;\n}\n\nint\nevent_base_loopcontinue(struct event_base *event_base)\n{\n\tint r = 0;\n\tif (event_base == NULL)\n\t\treturn (-1);\n\n\tEVBASE_ACQUIRE_LOCK(event_base, th_base_lock);\n\tevent_base->event_continue = 1;\n\n\tif (EVBASE_NEED_NOTIFY(event_base)) {\n\t\tr = evthread_notify_base(event_base);\n\t} else {\n\t\tr = (0);\n\t}\n\tEVBASE_RELEASE_LOCK(event_base, th_base_lock);\n\treturn r;\n}\n\nint\nevent_base_got_break(struct event_base *event_base)\n{\n\tint res;\n\tEVBASE_ACQUIRE_LOCK(event_base, th_base_lock);\n\tres = event_base->event_break;\n\tEVBASE_RELEASE_LOCK(event_base, th_base_lock);\n\treturn res;\n}\n\nint\nevent_base_got_exit(struct event_base *event_base)\n{\n\tint res;\n\tEVBASE_ACQUIRE_LOCK(event_base, th_base_lock);\n\tres = event_base->event_gotterm;\n\tEVBASE_RELEASE_LOCK(event_base, th_base_lock);\n\treturn res;\n}\n\n/* not thread safe */\n\nint\nevent_loop(int flags)\n{\n\treturn event_base_loop(current_base, flags);\n}\n\nint\nevent_base_loop(struct event_base *base, int flags)\n{\n\tconst struct eventop *evsel = base->evsel;\n\tstruct timeval *tv_p;\n\tint res, done, retval = 0;\n\tstruct evwatch_prepare_cb_info prepare_info;\n\tstruct evwatch_check_cb_info check_info;\n\tstruct evwatch *watcher;\n\n\t/* Grab the lock.  We will release it inside evsel.dispatch, and again\n\t * as we invoke watchers and user callbacks. */\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (base->running_loop) {\n\t\tevent_warnx(\"%s: reentrant invocation.  Only one event_base_loop\"\n\t\t    \" can run on each event_base at once.\", __func__);\n\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\treturn -1;\n\t}\n\n\tbase->running_loop = 1;\n\n\tclear_time_cache(base);\n\n\tif (base->sig.ev_signal_added && base->sig.ev_n_signals_added)\n\t\tevsig_set_base_(base);\n\n\tdone = 0;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tbase->th_owner_id = EVTHREAD_GET_ID();\n#endif\n\n\tbase->event_gotterm = base->event_break = 0;\n\n\twhile (!done) {\n\t\tstruct timeval tv;\n\n\t\tbase->event_continue = 0;\n\t\tbase->n_deferreds_queued = 0;\n\n\t\t/* Terminate the loop if we have been asked to */\n\t\tif (base->event_gotterm) {\n\t\t\tbreak;\n\t\t}\n\n\t\tif (base->event_break) {\n\t\t\tbreak;\n\t\t}\n\n\t\ttv_p = &tv;\n\t\tif (!N_ACTIVE_CALLBACKS(base) && !(flags & EVLOOP_NONBLOCK)) {\n\t\t\ttimeout_next(base, &tv_p);\n\t\t} else {\n\t\t\t/*\n\t\t\t * if we have active events, we just poll new events\n\t\t\t * without waiting.\n\t\t\t */\n\t\t\tevutil_timerclear(&tv);\n\t\t}\n\n\t\t/* If we have no events, we just exit */\n\t\tif (0==(flags&EVLOOP_NO_EXIT_ON_EMPTY) &&\n\t\t    !event_haveevents(base) && !N_ACTIVE_CALLBACKS(base)) {\n\t\t\tevent_debug((\"%s: no events registered.\", __func__));\n\t\t\tretval = 1;\n\t\t\tgoto done;\n\t\t}\n\n\t\tevent_queue_make_later_events_active(base);\n\n\t\t/* Invoke prepare watchers before polling for events */\n\t\tprepare_info.timeout = tv_p;\n\t\tTAILQ_FOREACH(watcher, &base->watchers[EVWATCH_PREPARE], next) {\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\t(*watcher->callback.prepare)(watcher, &prepare_info, watcher->arg);\n\t\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\t}\n\n\t\tclear_time_cache(base);\n\n\t\tres = evsel->dispatch(base, tv_p);\n\n\t\tif (res == -1) {\n\t\t\tevent_debug((\"%s: dispatch returned unsuccessfully.\",\n\t\t\t\t__func__));\n\t\t\tretval = -1;\n\t\t\tgoto done;\n\t\t}\n\n\t\tupdate_time_cache(base);\n\n\t\t/* Invoke check watchers after polling for events, and before\n\t\t * processing them */\n\t\tTAILQ_FOREACH(watcher, &base->watchers[EVWATCH_CHECK], next) {\n\t\t\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\t\t\t(*watcher->callback.check)(watcher, &check_info, watcher->arg);\n\t\t\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\t\t}\n\n\t\ttimeout_process(base);\n\n\t\tif (N_ACTIVE_CALLBACKS(base)) {\n\t\t\tint n = event_process_active(base);\n\t\t\tif ((flags & EVLOOP_ONCE)\n\t\t\t    && N_ACTIVE_CALLBACKS(base) == 0\n\t\t\t    && n != 0)\n\t\t\t\tdone = 1;\n\t\t} else if (flags & EVLOOP_NONBLOCK)\n\t\t\tdone = 1;\n\t}\n\tevent_debug((\"%s: asked to terminate loop.\", __func__));\n\ndone:\n\tclear_time_cache(base);\n\tbase->running_loop = 0;\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\treturn (retval);\n}\n\n/* One-time callback to implement event_base_once: invokes the user callback,\n * then deletes the allocated storage */\nstatic void\nevent_once_cb(evutil_socket_t fd, short events, void *arg)\n{\n\tstruct event_once *eonce = arg;\n\n\t(*eonce->cb)(fd, events, eonce->arg);\n\tEVBASE_ACQUIRE_LOCK(eonce->ev.ev_base, th_base_lock);\n\tLIST_REMOVE(eonce, next_once);\n\tEVBASE_RELEASE_LOCK(eonce->ev.ev_base, th_base_lock);\n\tevent_debug_unassign(&eonce->ev);\n\tmm_free(eonce);\n}\n\n/* not threadsafe, event scheduled once. */\nint\nevent_once(evutil_socket_t fd, short events,\n    void (*callback)(evutil_socket_t, short, void *),\n    void *arg, const struct timeval *tv)\n{\n\treturn event_base_once(current_base, fd, events, callback, arg, tv);\n}\n\n/* Schedules an event once */\nint\nevent_base_once(struct event_base *base, evutil_socket_t fd, short events,\n    void (*callback)(evutil_socket_t, short, void *),\n    void *arg, const struct timeval *tv)\n{\n\tstruct event_once *eonce;\n\tint res = 0;\n\tint activate = 0;\n\n\tif (!base)\n\t\treturn (-1);\n\n\t/* We cannot support signals that just fire once, or persistent\n\t * events. */\n\tif (events & (EV_SIGNAL|EV_PERSIST))\n\t\treturn (-1);\n\n\tif ((eonce = mm_calloc(1, sizeof(struct event_once))) == NULL)\n\t\treturn (-1);\n\n\teonce->cb = callback;\n\teonce->arg = arg;\n\n\tif ((events & (EV_TIMEOUT|EV_SIGNAL|EV_READ|EV_WRITE|EV_CLOSED)) == EV_TIMEOUT) {\n\t\tevtimer_assign(&eonce->ev, base, event_once_cb, eonce);\n\n\t\tif (tv == NULL || ! evutil_timerisset(tv)) {\n\t\t\t/* If the event is going to become active immediately,\n\t\t\t * don't put it on the timeout queue.  This is one\n\t\t\t * idiom for scheduling a callback, so let's make\n\t\t\t * it fast (and order-preserving). */\n\t\t\tactivate = 1;\n\t\t}\n\t} else if (events & (EV_READ|EV_WRITE|EV_CLOSED)) {\n\t\tevents &= EV_READ|EV_WRITE|EV_CLOSED;\n\n\t\tevent_assign(&eonce->ev, base, fd, events, event_once_cb, eonce);\n\t} else {\n\t\t/* Bad event combination */\n\t\tmm_free(eonce);\n\t\treturn (-1);\n\t}\n\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (activate)\n\t\tevent_active_nolock_(&eonce->ev, EV_TIMEOUT, 1);\n\telse\n\t\tres = event_add_nolock_(&eonce->ev, tv, 0);\n\n\tif (res != 0) {\n\t\tmm_free(eonce);\n\t\treturn (res);\n\t} else {\n\t\tLIST_INSERT_HEAD(&base->once_events, eonce, next_once);\n\t}\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\treturn (0);\n}\n\nint\n/* workaround for -Werror=maybe-uninitialized bug in gcc 11/12 */\n#if defined(__GNUC__) && (__GNUC__ == 11 || __GNUC__ == 12)\n__attribute__((noinline))\n#endif\nevent_assign(struct event *ev, struct event_base *base, evutil_socket_t fd, short events, void (*callback)(evutil_socket_t, short, void *), void *arg)\n{\n\tif (!base)\n\t\tbase = current_base;\n\tif (arg == &event_self_cbarg_ptr_)\n\t\targ = ev;\n\n\tif (!(events & EV_SIGNAL))\n\t\tevent_debug_assert_socket_nonblocking_(fd);\n\tevent_debug_assert_not_added_(ev);\n\n\tev->ev_base = base;\n\n\tev->ev_callback = callback;\n\tev->ev_arg = arg;\n\tev->ev_fd = fd;\n\tev->ev_events = events;\n\tev->ev_res = 0;\n\tev->ev_flags = EVLIST_INIT;\n\tev->ev_ncalls = 0;\n\tev->ev_pncalls = NULL;\n\n\tif (events & EV_SIGNAL) {\n\t\tif ((events & (EV_READ|EV_WRITE|EV_CLOSED)) != 0) {\n\t\t\tevent_warnx(\"%s: EV_SIGNAL is not compatible with \"\n\t\t\t    \"EV_READ, EV_WRITE or EV_CLOSED\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t\tev->ev_closure = EV_CLOSURE_EVENT_SIGNAL;\n\t} else {\n\t\tif (events & EV_PERSIST) {\n\t\t\tevutil_timerclear(&ev->ev_io_timeout);\n\t\t\tev->ev_closure = EV_CLOSURE_EVENT_PERSIST;\n\t\t} else {\n\t\t\tev->ev_closure = EV_CLOSURE_EVENT;\n\t\t}\n\t}\n\n\tmin_heap_elem_init_(ev);\n\n\tif (base != NULL) {\n\t\t/* by default, we put new events into the middle priority */\n\t\tev->ev_pri = base->nactivequeues / 2;\n\t}\n\n\tevent_debug_note_setup_(ev);\n\n\treturn 0;\n}\n\nint\nevent_base_set(struct event_base *base, struct event *ev)\n{\n\t/* Only innocent events may be assigned to a different base */\n\tif (ev->ev_flags != EVLIST_INIT)\n\t\treturn (-1);\n\n\tevent_debug_assert_is_setup_(ev);\n\n\tev->ev_base = base;\n\tev->ev_pri = base->nactivequeues/2;\n\n\treturn (0);\n}\n\nvoid\nevent_set(struct event *ev, evutil_socket_t fd, short events,\n\t  void (*callback)(evutil_socket_t, short, void *), void *arg)\n{\n\tint r;\n\tr = event_assign(ev, current_base, fd, events, callback, arg);\n\tEVUTIL_ASSERT(r == 0);\n}\n\nvoid *\nevent_self_cbarg(void)\n{\n\treturn &event_self_cbarg_ptr_;\n}\n\nstruct event *\nevent_base_get_running_event(struct event_base *base)\n{\n\tstruct event *ev = NULL;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (EVBASE_IN_THREAD(base)) {\n\t\tstruct event_callback *evcb = base->current_event;\n\t\tif (evcb->evcb_flags & EVLIST_INIT)\n\t\t\tev = event_callback_to_event(evcb);\n\t}\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn ev;\n}\n\nstruct event *\nevent_new(struct event_base *base, evutil_socket_t fd, short events, void (*cb)(evutil_socket_t, short, void *), void *arg)\n{\n\tstruct event *ev;\n\tev = mm_malloc(sizeof(struct event));\n\tif (ev == NULL)\n\t\treturn (NULL);\n\tif (event_assign(ev, base, fd, events, cb, arg) < 0) {\n\t\tmm_free(ev);\n\t\treturn (NULL);\n\t}\n\n\treturn (ev);\n}\n\nvoid\nevent_free(struct event *ev)\n{\n\t/* This is disabled, so that events which have been finalized be a\n\t * valid target for event_free(). That's */\n\t// event_debug_assert_is_setup_(ev);\n\n\t/* make sure that this event won't be coming back to haunt us. */\n\tevent_del(ev);\n\tevent_debug_note_teardown_(ev);\n\tmm_free(ev);\n\n}\n\nvoid\nevent_debug_unassign(struct event *ev)\n{\n\tevent_debug_assert_not_added_(ev);\n\tevent_debug_note_teardown_(ev);\n\n\tev->ev_flags &= ~EVLIST_INIT;\n}\n\n#define EVENT_FINALIZE_FREE_ 0x10000\nstatic int\nevent_finalize_nolock_(struct event_base *base, unsigned flags, struct event *ev, event_finalize_callback_fn cb)\n{\n\tev_uint8_t closure = (flags & EVENT_FINALIZE_FREE_) ?\n\t    EV_CLOSURE_EVENT_FINALIZE_FREE : EV_CLOSURE_EVENT_FINALIZE;\n\n\tevent_del_nolock_(ev, EVENT_DEL_NOBLOCK);\n\tev->ev_closure = closure;\n\tev->ev_evcallback.evcb_cb_union.evcb_evfinalize = cb;\n\tevent_active_nolock_(ev, EV_FINALIZE, 1);\n\tev->ev_flags |= EVLIST_FINALIZING;\n\treturn 0;\n}\n\nstatic int\nevent_finalize_impl_(unsigned flags, struct event *ev, event_finalize_callback_fn cb)\n{\n\tint r;\n\tstruct event_base *base = ev->ev_base;\n\tif (EVUTIL_FAILURE_CHECK(!base)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn -1;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tr = event_finalize_nolock_(base, flags, ev, cb);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\nint\nevent_finalize(unsigned flags, struct event *ev, event_finalize_callback_fn cb)\n{\n\treturn event_finalize_impl_(flags, ev, cb);\n}\n\nint\nevent_free_finalize(unsigned flags, struct event *ev, event_finalize_callback_fn cb)\n{\n\treturn event_finalize_impl_(flags|EVENT_FINALIZE_FREE_, ev, cb);\n}\n\nvoid\nevent_callback_finalize_nolock_(struct event_base *base, unsigned flags, struct event_callback *evcb, void (*cb)(struct event_callback *, void *))\n{\n\tstruct event *ev = NULL;\n\tif (evcb->evcb_flags & EVLIST_INIT) {\n\t\tev = event_callback_to_event(evcb);\n\t\tevent_del_nolock_(ev, EVENT_DEL_NOBLOCK);\n\t} else {\n\t\tevent_callback_cancel_nolock_(base, evcb, 0); /*XXX can this fail?*/\n\t}\n\n\tevcb->evcb_closure = EV_CLOSURE_CB_FINALIZE;\n\tevcb->evcb_cb_union.evcb_cbfinalize = cb;\n\tevent_callback_activate_nolock_(base, evcb); /* XXX can this really fail?*/\n\tevcb->evcb_flags |= EVLIST_FINALIZING;\n}\n\nvoid\nevent_callback_finalize_(struct event_base *base, unsigned flags, struct event_callback *evcb, void (*cb)(struct event_callback *, void *))\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tevent_callback_finalize_nolock_(base, flags, evcb, cb);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\n/** Internal: Finalize all of the n_cbs callbacks in evcbs.  The provided\n * callback will be invoked on *one of them*, after they have *all* been\n * finalized. */\nint\nevent_callback_finalize_many_(struct event_base *base, int n_cbs, struct event_callback **evcbs, void (*cb)(struct event_callback *, void *))\n{\n\tint n_pending = 0, i;\n\n\tif (base == NULL)\n\t\tbase = current_base;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tevent_debug((\"%s: %d events finalizing\", __func__, n_cbs));\n\n\t/* At most one can be currently executing; the rest we just\n\t * cancel... But we always make sure that the finalize callback\n\t * runs. */\n\tfor (i = 0; i < n_cbs; ++i) {\n\t\tstruct event_callback *evcb = evcbs[i];\n\t\tif (evcb == base->current_event) {\n\t\t\tevent_callback_finalize_nolock_(base, 0, evcb, cb);\n\t\t\t++n_pending;\n\t\t} else {\n\t\t\tevent_callback_cancel_nolock_(base, evcb, 0);\n\t\t}\n\t}\n\n\tif (n_pending == 0) {\n\t\t/* Just do the first one. */\n\t\tevent_callback_finalize_nolock_(base, 0, evcbs[0], cb);\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn 0;\n}\n\n/*\n * Set's the priority of an event - if an event is already scheduled\n * changing the priority is going to fail.\n */\n\nint\nevent_priority_set(struct event *ev, int pri)\n{\n\tevent_debug_assert_is_setup_(ev);\n\n\tif (ev->ev_flags & EVLIST_ACTIVE)\n\t\treturn (-1);\n\tif (pri < 0 || pri >= ev->ev_base->nactivequeues)\n\t\treturn (-1);\n\n\tev->ev_pri = pri;\n\n\treturn (0);\n}\n\n/*\n * Checks if a specific event is pending or scheduled.\n */\n\nint\nevent_pending(const struct event *ev, short event, struct timeval *tv)\n{\n\tint flags = 0;\n\n\tif (EVUTIL_FAILURE_CHECK(ev->ev_base == NULL)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn 0;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(ev->ev_base, th_base_lock);\n\tevent_debug_assert_is_setup_(ev);\n\n\tif (ev->ev_flags & EVLIST_INSERTED)\n\t\tflags |= (ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED|EV_SIGNAL));\n\tif (ev->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER))\n\t\tflags |= ev->ev_res;\n\tif (ev->ev_flags & EVLIST_TIMEOUT)\n\t\tflags |= EV_TIMEOUT;\n\n\tevent &= (EV_TIMEOUT|EV_READ|EV_WRITE|EV_CLOSED|EV_SIGNAL);\n\n\t/* See if there is a timeout that we should report */\n\tif (tv != NULL && (flags & event & EV_TIMEOUT)) {\n\t\tstruct timeval tmp = ev->ev_timeout;\n\t\ttmp.tv_usec &= MICROSECONDS_MASK;\n\t\t/* correctly remamp to real time */\n\t\tevutil_timeradd(&ev->ev_base->tv_clock_diff, &tmp, tv);\n\t}\n\n\tEVBASE_RELEASE_LOCK(ev->ev_base, th_base_lock);\n\n\treturn (flags & event);\n}\n\nint\nevent_initialized(const struct event *ev)\n{\n\tif (!(ev->ev_flags & EVLIST_INIT))\n\t\treturn 0;\n\n\treturn 1;\n}\n\nvoid\nevent_get_assignment(const struct event *event, struct event_base **base_out, evutil_socket_t *fd_out, short *events_out, event_callback_fn *callback_out, void **arg_out)\n{\n\tevent_debug_assert_is_setup_(event);\n\n\tif (base_out)\n\t\t*base_out = event->ev_base;\n\tif (fd_out)\n\t\t*fd_out = event->ev_fd;\n\tif (events_out)\n\t\t*events_out = event->ev_events;\n\tif (callback_out)\n\t\t*callback_out = event->ev_callback;\n\tif (arg_out)\n\t\t*arg_out = event->ev_arg;\n}\n\nsize_t\nevent_get_struct_event_size(void)\n{\n\treturn sizeof(struct event);\n}\n\nevutil_socket_t\nevent_get_fd(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_fd;\n}\n\nstruct event_base *\nevent_get_base(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_base;\n}\n\nshort\nevent_get_events(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_events;\n}\n\nevent_callback_fn\nevent_get_callback(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_callback;\n}\n\nvoid *\nevent_get_callback_arg(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_arg;\n}\n\nint\nevent_get_priority(const struct event *ev)\n{\n\tevent_debug_assert_is_setup_(ev);\n\treturn ev->ev_pri;\n}\n\nint\nevent_add(struct event *ev, const struct timeval *tv)\n{\n\tint res;\n\n\tif (EVUTIL_FAILURE_CHECK(!ev->ev_base)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn -1;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(ev->ev_base, th_base_lock);\n\n\tres = event_add_nolock_(ev, tv, 0);\n\n\tEVBASE_RELEASE_LOCK(ev->ev_base, th_base_lock);\n\n\treturn (res);\n}\n\n/* Helper callback: wake an event_base from another thread.  This version\n * works by writing a byte to one end of a socketpair, so that the event_base\n * listening on the other end will wake up as the corresponding event\n * triggers */\nstatic int\nevthread_notify_base_default(struct event_base *base)\n{\n\tchar buf[1];\n\tev_ssize_t r;\n\tbuf[0] = (char) 0;\n#ifdef _WIN32\n\tr = send(base->th_notify_fd[1], buf, 1, 0);\n#else\n\tr = write(base->th_notify_fd[1], buf, 1);\n#endif\n\treturn (r < 0 && ! EVUTIL_ERR_IS_EAGAIN(errno)) ? -1 : 0;\n}\n\n#ifdef EVENT__HAVE_EVENTFD\n/* Helper callback: wake an event_base from another thread.  This version\n * assumes that you have a working eventfd() implementation. */\nstatic int\nevthread_notify_base_eventfd(struct event_base *base)\n{\n\tint efd = base->th_notify_fd[0];\n\teventfd_t val;\n\tint ret;\n\tfor (val=1;;val=1) {\n\t\tret = eventfd_write(efd, val);\n\t\tif (ret < 0) {\n\t\t\t// When EAGAIN occurs, the eventfd counter hits the maximum value of the unsigned 64-bit.\n\t\t\t// We need to first drain the eventfd and then write again.\n\t\t\t//\n\t\t\t// Check out https://man7.org/linux/man-pages/man2/eventfd.2.html for details.\n\t\t\tif (errno == EAGAIN) {\n\t\t\t\t// It's ready to retry.\n\t\t\t\tif (eventfd_read(efd, &val) == 0 || errno == EAGAIN) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Unknown error occurs.\n\t\t\tret = -1;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n#endif\n\n\n/** Tell the thread currently running the event_loop for base (if any) that it\n * needs to stop waiting in its dispatch function (if it is) and process all\n * active callbacks. */\nstatic int\nevthread_notify_base(struct event_base *base)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (!base->th_notify_fn)\n\t\treturn -1;\n\tif (base->is_notify_pending)\n\t\treturn 0;\n\tbase->is_notify_pending = 1;\n\treturn base->th_notify_fn(base);\n}\n\n/* Implementation function to remove a timeout on a currently pending event.\n */\nint\nevent_remove_timer_nolock_(struct event *ev)\n{\n\tstruct event_base *base = ev->ev_base;\n\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tevent_debug_assert_is_setup_(ev);\n\n\tevent_debug((\"event_remove_timer_nolock: event: %p\", (void *)ev));\n\n\t/* If it's not pending on a timeout, we don't need to do anything. */\n\tif (ev->ev_flags & EVLIST_TIMEOUT) {\n\t\tevent_queue_remove_timeout(base, ev);\n\t\tevutil_timerclear(&ev->ev_io_timeout);\n\t}\n\n\treturn (0);\n}\n\nint\nevent_remove_timer(struct event *ev)\n{\n\tint res;\n\n\tif (EVUTIL_FAILURE_CHECK(!ev->ev_base)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn -1;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(ev->ev_base, th_base_lock);\n\n\tres = event_remove_timer_nolock_(ev);\n\n\tEVBASE_RELEASE_LOCK(ev->ev_base, th_base_lock);\n\n\treturn (res);\n}\n\n/* Implementation function to add an event.  Works just like event_add,\n * except: 1) it requires that we have the lock.  2) if tv_is_absolute is set,\n * we treat tv as an absolute time, not as an interval to add to the current\n * time */\nint\nevent_add_nolock_(struct event *ev, const struct timeval *tv,\n    int tv_is_absolute)\n{\n\tstruct event_base *base = ev->ev_base;\n\tint res = 0;\n\tint notify = 0;\n\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tevent_debug_assert_is_setup_(ev);\n\n\tevent_debug((\n\t\t \"event_add: event: %p (fd \"EV_SOCK_FMT\"), %s%s%s%scall %p\",\n\t\t (void *)ev,\n\t\t EV_SOCK_ARG(ev->ev_fd),\n\t\t ev->ev_events & EV_READ ? \"EV_READ \" : \" \",\n\t\t ev->ev_events & EV_WRITE ? \"EV_WRITE \" : \" \",\n\t\t ev->ev_events & EV_CLOSED ? \"EV_CLOSED \" : \" \",\n\t\t tv ? \"EV_TIMEOUT \" : \" \",\n\t\t (void *)ev->ev_callback));\n\n\tEVUTIL_ASSERT(!(ev->ev_flags & ~EVLIST_ALL));\n\n\tif (ev->ev_flags & EVLIST_FINALIZING) {\n\t\t/* XXXX debug */\n\t\treturn (-1);\n\t}\n\n\t/*\n\t * prepare for timeout insertion further below, if we get a\n\t * failure on any step, we should not change any state.\n\t */\n\tif (tv != NULL && !(ev->ev_flags & EVLIST_TIMEOUT)) {\n\t\tif (min_heap_reserve_(&base->timeheap,\n\t\t\t1 + min_heap_size_(&base->timeheap)) == -1)\n\t\t\treturn (-1);  /* ENOMEM == errno */\n\t}\n\n\t/* If the main thread is currently executing a signal event's\n\t * callback, and we are not the main thread, then we want to wait\n\t * until the callback is done before we mess with the event, or else\n\t * we can race on ev_ncalls and ev_pncalls below. */\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (base->current_event == event_to_event_callback(ev) &&\n\t    (ev->ev_events & EV_SIGNAL)\n\t    && !EVBASE_IN_THREAD(base)) {\n\t\t++base->current_event_waiters;\n\t\tEVTHREAD_COND_WAIT(base->current_event_cond, base->th_base_lock);\n\t}\n#endif\n\n\tif ((ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED|EV_SIGNAL)) &&\n\t    !(ev->ev_flags & (EVLIST_INSERTED|EVLIST_ACTIVE|EVLIST_ACTIVE_LATER))) {\n\t\tif (ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED))\n\t\t\tres = evmap_io_add_(base, ev->ev_fd, ev);\n\t\telse if (ev->ev_events & EV_SIGNAL)\n\t\t\tres = evmap_signal_add_(base, (int)ev->ev_fd, ev);\n\t\tif (res != -1)\n\t\t\tevent_queue_insert_inserted(base, ev);\n\t\tif (res == 1) {\n\t\t\t/* evmap says we need to notify the main thread. */\n\t\t\tnotify = 1;\n\t\t\tres = 0;\n\t\t}\n\t}\n\n\t/*\n\t * we should change the timeout state only if the previous event\n\t * addition succeeded.\n\t */\n\tif (res != -1 && tv != NULL) {\n\t\tstruct timeval now;\n\t\tint common_timeout;\n#ifdef USE_REINSERT_TIMEOUT\n\t\tint was_common;\n\t\tint old_timeout_idx;\n#endif\n\n\t\t/*\n\t\t * for persistent timeout events, we remember the\n\t\t * timeout value and re-add the event.\n\t\t *\n\t\t * If tv_is_absolute, this was already set.\n\t\t */\n\t\tif (ev->ev_closure == EV_CLOSURE_EVENT_PERSIST && !tv_is_absolute)\n\t\t\tev->ev_io_timeout = *tv;\n\n#ifndef USE_REINSERT_TIMEOUT\n\t\tif (ev->ev_flags & EVLIST_TIMEOUT) {\n\t\t\tevent_queue_remove_timeout(base, ev);\n\t\t}\n#endif\n\n\t\t/* Check if it is active due to a timeout.  Rescheduling\n\t\t * this timeout before the callback can be executed\n\t\t * removes it from the active list. */\n\t\tif ((ev->ev_flags & EVLIST_ACTIVE) &&\n\t\t    (ev->ev_res & EV_TIMEOUT)) {\n\t\t\tif (ev->ev_events & EV_SIGNAL) {\n\t\t\t\t/* See if we are just active executing\n\t\t\t\t * this event in a loop\n\t\t\t\t */\n\t\t\t\tif (ev->ev_ncalls && ev->ev_pncalls) {\n\t\t\t\t\t/* Abort loop */\n\t\t\t\t\t*ev->ev_pncalls = 0;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tevent_queue_remove_active(base, event_to_event_callback(ev));\n\t\t}\n\n\t\tgettime(base, &now);\n\n\t\tcommon_timeout = is_common_timeout(tv, base);\n#ifdef USE_REINSERT_TIMEOUT\n\t\twas_common = is_common_timeout(&ev->ev_timeout, base);\n\t\told_timeout_idx = COMMON_TIMEOUT_IDX(&ev->ev_timeout);\n#endif\n\n\t\tif (tv_is_absolute) {\n\t\t\tev->ev_timeout = *tv;\n\t\t} else if (common_timeout) {\n\t\t\tstruct timeval tmp = *tv;\n\t\t\ttmp.tv_usec &= MICROSECONDS_MASK;\n\t\t\tevutil_timeradd(&now, &tmp, &ev->ev_timeout);\n\t\t\tev->ev_timeout.tv_usec |=\n\t\t\t    (tv->tv_usec & ~MICROSECONDS_MASK);\n\t\t} else {\n\t\t\tevutil_timeradd(&now, tv, &ev->ev_timeout);\n\t\t}\n\n\t\tevent_debug((\n\t\t\t \"event_add: event %p, timeout in %d seconds %d useconds, call %p\",\n\t\t\t (void *)ev, (int)tv->tv_sec, (int)tv->tv_usec, (void *)ev->ev_callback));\n\n#ifdef USE_REINSERT_TIMEOUT\n\t\tevent_queue_reinsert_timeout(base, ev, was_common, common_timeout, old_timeout_idx);\n#else\n\t\tevent_queue_insert_timeout(base, ev);\n#endif\n\n\t\tif (common_timeout) {\n\t\t\tstruct common_timeout_list *ctl =\n\t\t\t    get_common_timeout_list(base, &ev->ev_timeout);\n\t\t\tif (ev == TAILQ_FIRST(&ctl->events)) {\n\t\t\t\tcommon_timeout_schedule(ctl, &now, ev);\n\t\t\t}\n\t\t} else {\n\t\t\tstruct event* top = NULL;\n\t\t\t/* See if the earliest timeout is now earlier than it\n\t\t\t * was before: if so, we will need to tell the main\n\t\t\t * thread to wake up earlier than it would otherwise.\n\t\t\t * We double check the timeout of the top element to\n\t\t\t * handle time distortions due to system suspension.\n\t\t\t */\n\t\t\tif (min_heap_elt_is_top_(ev))\n\t\t\t\tnotify = 1;\n\t\t\telse if ((top = min_heap_top_(&base->timeheap)) != NULL &&\n\t\t\t\t\t evutil_timercmp(&top->ev_timeout, &now, <))\n\t\t\t\tnotify = 1;\n\t\t}\n\t}\n\n\t/* if we are not in the right thread, we need to wake up the loop */\n\tif (res != -1 && notify && EVBASE_NEED_NOTIFY(base))\n\t\tevthread_notify_base(base);\n\n\tevent_debug_note_add_(ev);\n\n\treturn (res);\n}\n\nstatic int\nevent_del_(struct event *ev, int blocking)\n{\n\tint res;\n\tstruct event_base *base = ev->ev_base;\n\n\tif (EVUTIL_FAILURE_CHECK(!base)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn -1;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tres = event_del_nolock_(ev, blocking);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\treturn (res);\n}\n\nint\nevent_del(struct event *ev)\n{\n\treturn event_del_(ev, EVENT_DEL_AUTOBLOCK);\n}\n\nint\nevent_del_block(struct event *ev)\n{\n\treturn event_del_(ev, EVENT_DEL_BLOCK);\n}\n\nint\nevent_del_noblock(struct event *ev)\n{\n\treturn event_del_(ev, EVENT_DEL_NOBLOCK);\n}\n\n/** Helper for event_del: always called with th_base_lock held.\n *\n * \"blocking\" must be one of the EVENT_DEL_{BLOCK, NOBLOCK, AUTOBLOCK,\n * EVEN_IF_FINALIZING} values. See those for more information.\n */\nint\nevent_del_nolock_(struct event *ev, int blocking)\n{\n\tstruct event_base *base;\n\tint res = 0, notify = 0;\n\n\tevent_debug((\"event_del: %p (fd \"EV_SOCK_FMT\"), callback %p\",\n\t\t(void *)ev, EV_SOCK_ARG(ev->ev_fd), (void *)ev->ev_callback));\n\n\t/* An event without a base has not been added */\n\tif (ev->ev_base == NULL)\n\t\treturn (-1);\n\n\tEVENT_BASE_ASSERT_LOCKED(ev->ev_base);\n\n\tif (blocking != EVENT_DEL_EVEN_IF_FINALIZING) {\n\t\tif (ev->ev_flags & EVLIST_FINALIZING) {\n\t\t\t/* XXXX Debug */\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tbase = ev->ev_base;\n\n\tEVUTIL_ASSERT(!(ev->ev_flags & ~EVLIST_ALL));\n\n\t/* See if we are just active executing this event in a loop */\n\tif (ev->ev_events & EV_SIGNAL) {\n\t\tif (ev->ev_ncalls && ev->ev_pncalls) {\n\t\t\t/* Abort loop */\n\t\t\t*ev->ev_pncalls = 0;\n\t\t}\n\t}\n\n\tif (ev->ev_flags & EVLIST_TIMEOUT) {\n\t\t/* Notify the base if this was the minimal timeout */\n\t\tif (min_heap_top_(&base->timeheap) == ev)\n\t\t\tnotify = 1;\n\t\tevent_queue_remove_timeout(base, ev);\n\t}\n\n\tif (ev->ev_flags & EVLIST_ACTIVE)\n\t\tevent_queue_remove_active(base, event_to_event_callback(ev));\n\telse if (ev->ev_flags & EVLIST_ACTIVE_LATER)\n\t\tevent_queue_remove_active_later(base, event_to_event_callback(ev));\n\n\tif (ev->ev_flags & EVLIST_INSERTED) {\n\t\tevent_queue_remove_inserted(base, ev);\n\t\tif (ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED))\n\t\t\tres = evmap_io_del_(base, ev->ev_fd, ev);\n\t\telse\n\t\t\tres = evmap_signal_del_(base, (int)ev->ev_fd, ev);\n\t\tif (res == 1) {\n\t\t\t/* evmap says we need to notify the main thread. */\n\t\t\tnotify = 1;\n\t\t\tres = 0;\n\t\t}\n\t\t/* If we do not have events, let's notify event base so it can\n\t\t * exit without waiting */\n\t\tif (!event_haveevents(base) && !N_ACTIVE_CALLBACKS(base))\n\t\t\tnotify = 1;\n\t}\n\n\t/* if we are not in the right thread, we need to wake up the loop */\n\tif (res != -1 && notify && EVBASE_NEED_NOTIFY(base))\n\t\tevthread_notify_base(base);\n\n\tevent_debug_note_del_(ev);\n\n\t/* If the main thread is currently executing this event's callback,\n\t * and we are not the main thread, then we want to wait until the\n\t * callback is done before returning. That way, when this function\n\t * returns, it will be safe to free the user-supplied argument.\n\t */\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (blocking != EVENT_DEL_NOBLOCK &&\n\t    base->current_event == event_to_event_callback(ev) &&\n\t    !EVBASE_IN_THREAD(base) &&\n\t    (blocking == EVENT_DEL_BLOCK || !(ev->ev_events & EV_FINALIZE))) {\n\t\t++base->current_event_waiters;\n\t\tEVTHREAD_COND_WAIT(base->current_event_cond, base->th_base_lock);\n\t}\n#endif\n\n\treturn (res);\n}\n\nvoid\nevent_active(struct event *ev, int res, short ncalls)\n{\n\tif (EVUTIL_FAILURE_CHECK(!ev->ev_base)) {\n\t\tevent_warnx(\"%s: event has no event_base set.\", __func__);\n\t\treturn;\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(ev->ev_base, th_base_lock);\n\n\tevent_debug_assert_is_setup_(ev);\n\n\tevent_active_nolock_(ev, res, ncalls);\n\n\tEVBASE_RELEASE_LOCK(ev->ev_base, th_base_lock);\n}\n\n\nvoid\nevent_active_nolock_(struct event *ev, int res, short ncalls)\n{\n\tstruct event_base *base;\n\n\tevent_debug((\"event_active: %p (fd \"EV_SOCK_FMT\"), res %d, callback %p\",\n\t\t(void *)ev, EV_SOCK_ARG(ev->ev_fd), (int)res, (void *)ev->ev_callback));\n\n\tbase = ev->ev_base;\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (ev->ev_flags & EVLIST_FINALIZING) {\n\t\t/* XXXX debug */\n\t\treturn;\n\t}\n\n\tswitch ((ev->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER))) {\n\tdefault:\n\tcase EVLIST_ACTIVE|EVLIST_ACTIVE_LATER:\n\t\tEVUTIL_ASSERT(0);\n\t\tbreak;\n\tcase EVLIST_ACTIVE:\n\t\t/* We get different kinds of events, add them together */\n\t\tev->ev_res |= res;\n\t\treturn;\n\tcase EVLIST_ACTIVE_LATER:\n\t\tev->ev_res |= res;\n\t\tbreak;\n\tcase 0:\n\t\tev->ev_res = res;\n\t\tbreak;\n\t}\n\n\tif (ev->ev_pri < base->event_running_priority)\n\t\tbase->event_continue = 1;\n\n\tif (ev->ev_events & EV_SIGNAL) {\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\t\tif (base->current_event == event_to_event_callback(ev) &&\n\t\t    !EVBASE_IN_THREAD(base)) {\n\t\t\t++base->current_event_waiters;\n\t\t\tEVTHREAD_COND_WAIT(base->current_event_cond, base->th_base_lock);\n\t\t}\n#endif\n\t\tev->ev_ncalls = ncalls;\n\t\tev->ev_pncalls = NULL;\n\t}\n\n\tevent_callback_activate_nolock_(base, event_to_event_callback(ev));\n}\n\nvoid\nevent_active_later_(struct event *ev, int res)\n{\n\tEVBASE_ACQUIRE_LOCK(ev->ev_base, th_base_lock);\n\tevent_active_later_nolock_(ev, res);\n\tEVBASE_RELEASE_LOCK(ev->ev_base, th_base_lock);\n}\n\nvoid\nevent_active_later_nolock_(struct event *ev, int res)\n{\n\tstruct event_base *base = ev->ev_base;\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (ev->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER)) {\n\t\t/* We get different kinds of events, add them together */\n\t\tev->ev_res |= res;\n\t\treturn;\n\t}\n\n\tev->ev_res = res;\n\n\tevent_callback_activate_later_nolock_(base, event_to_event_callback(ev));\n}\n\nint\nevent_callback_activate_(struct event_base *base,\n    struct event_callback *evcb)\n{\n\tint r;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tr = event_callback_activate_nolock_(base, evcb);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\nint\nevent_callback_activate_nolock_(struct event_base *base,\n    struct event_callback *evcb)\n{\n\tint r = 1;\n\n\tif (evcb->evcb_flags & EVLIST_FINALIZING)\n\t\treturn 0;\n\n\tswitch (evcb->evcb_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER)) {\n\tdefault:\n\t\tEVUTIL_ASSERT(0);\n\t\tEVUTIL_FALLTHROUGH;\n\tcase EVLIST_ACTIVE_LATER:\n\t\tevent_queue_remove_active_later(base, evcb);\n\t\tr = 0;\n\t\tbreak;\n\tcase EVLIST_ACTIVE:\n\t\treturn 0;\n\tcase 0:\n\t\tbreak;\n\t}\n\n\tevent_queue_insert_active(base, evcb);\n\n\tif (EVBASE_NEED_NOTIFY(base))\n\t\tevthread_notify_base(base);\n\n\treturn r;\n}\n\nint\nevent_callback_activate_later_nolock_(struct event_base *base,\n    struct event_callback *evcb)\n{\n\tif (evcb->evcb_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER))\n\t\treturn 0;\n\n\tevent_queue_insert_active_later(base, evcb);\n\tif (EVBASE_NEED_NOTIFY(base))\n\t\tevthread_notify_base(base);\n\treturn 1;\n}\n\nvoid\nevent_callback_init_(struct event_base *base,\n    struct event_callback *cb)\n{\n\tmemset(cb, 0, sizeof(*cb));\n\tcb->evcb_pri = base->nactivequeues - 1;\n}\n\nint\nevent_callback_cancel_(struct event_base *base,\n    struct event_callback *evcb)\n{\n\tint r;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tr = event_callback_cancel_nolock_(base, evcb, 0);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\nint\nevent_callback_cancel_nolock_(struct event_base *base,\n    struct event_callback *evcb, int even_if_finalizing)\n{\n\tif ((evcb->evcb_flags & EVLIST_FINALIZING) && !even_if_finalizing)\n\t\treturn 0;\n\n\tif (evcb->evcb_flags & EVLIST_INIT)\n\t\treturn event_del_nolock_(event_callback_to_event(evcb),\n\t\t    even_if_finalizing ? EVENT_DEL_EVEN_IF_FINALIZING : EVENT_DEL_AUTOBLOCK);\n\n\tswitch ((evcb->evcb_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER))) {\n\tdefault:\n\tcase EVLIST_ACTIVE|EVLIST_ACTIVE_LATER:\n\t\tEVUTIL_ASSERT(0);\n\t\tbreak;\n\tcase EVLIST_ACTIVE:\n\t\t/* We get different kinds of events, add them together */\n\t\tevent_queue_remove_active(base, evcb);\n\t\treturn 0;\n\tcase EVLIST_ACTIVE_LATER:\n\t\tevent_queue_remove_active_later(base, evcb);\n\t\tbreak;\n\tcase 0:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nvoid\nevent_deferred_cb_init_(struct event_callback *cb, ev_uint8_t priority, deferred_cb_fn fn, void *arg)\n{\n\tmemset(cb, 0, sizeof(*cb));\n\tcb->evcb_cb_union.evcb_selfcb = fn;\n\tcb->evcb_arg = arg;\n\tcb->evcb_pri = priority;\n\tcb->evcb_closure = EV_CLOSURE_CB_SELF;\n}\n\nvoid\nevent_deferred_cb_set_priority_(struct event_callback *cb, ev_uint8_t priority)\n{\n\tcb->evcb_pri = priority;\n}\n\nvoid\nevent_deferred_cb_cancel_(struct event_base *base, struct event_callback *cb)\n{\n\tif (!base)\n\t\tbase = current_base;\n\tevent_callback_cancel_(base, cb);\n}\n\n#define MAX_DEFERREDS_QUEUED 32\nint\nevent_deferred_cb_schedule_(struct event_base *base, struct event_callback *cb)\n{\n\tint r = 1;\n\tif (!base)\n\t\tbase = current_base;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tif (base->n_deferreds_queued > MAX_DEFERREDS_QUEUED) {\n\t\tr = event_callback_activate_later_nolock_(base, cb);\n\t} else {\n\t\tr = event_callback_activate_nolock_(base, cb);\n\t\tif (r) {\n\t\t\t++base->n_deferreds_queued;\n\t\t}\n\t}\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\nstatic int\ntimeout_next(struct event_base *base, struct timeval **tv_p)\n{\n\t/* Caller must hold th_base_lock */\n\tstruct timeval now;\n\tstruct event *ev;\n\tstruct timeval *tv = *tv_p;\n\tint res = 0;\n\n\tev = min_heap_top_(&base->timeheap);\n\n\tif (ev == NULL) {\n\t\t/* if no time-based events are active wait for I/O */\n\t\t*tv_p = NULL;\n\t\tgoto out;\n\t}\n\n\tif (gettime(base, &now) == -1) {\n\t\tres = -1;\n\t\tgoto out;\n\t}\n\n\tif (evutil_timercmp(&ev->ev_timeout, &now, <=)) {\n\t\tevutil_timerclear(tv);\n\t\tgoto out;\n\t}\n\n\tevutil_timersub(&ev->ev_timeout, &now, tv);\n\n\tEVUTIL_ASSERT(tv->tv_sec >= 0);\n\tEVUTIL_ASSERT(tv->tv_usec >= 0);\n\tevent_debug((\"timeout_next: event: %p, in %d seconds, %d useconds\", (void *)ev, (int)tv->tv_sec, (int)tv->tv_usec));\n\nout:\n\treturn (res);\n}\n\n/* Activate every event whose timeout has elapsed. */\nstatic void\ntimeout_process(struct event_base *base)\n{\n\t/* Caller must hold lock. */\n\tstruct timeval now;\n\tstruct event *ev;\n\n\tif (min_heap_empty_(&base->timeheap)) {\n\t\treturn;\n\t}\n\n\tgettime(base, &now);\n\n\twhile ((ev = min_heap_top_(&base->timeheap))) {\n\t\tint was_active = ev->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER);\n\n\t\tif (evutil_timercmp(&ev->ev_timeout, &now, >))\n\t\t\tbreak;\n\n\t\tif (!was_active)\n\t\t\tevent_del_nolock_(ev, EVENT_DEL_NOBLOCK);\n\t\telse\n\t\t\tevent_queue_remove_timeout(base, ev);\n\n\t\tevent_debug((\"timeout_process: event: %p, call %p (was active: %i)\",\n\t\t\t (void *)ev, (void *)ev->ev_callback, was_active));\n\t\tevent_active_nolock_(ev, EV_TIMEOUT, 1);\n\t}\n}\n\n#ifndef MAX\n#define MAX(a,b) (((a)>(b))?(a):(b))\n#endif\n\n#define MAX_EVENT_COUNT(var, v) var = MAX(var, v)\n\n/* These are a fancy way to spell\n     if (~flags & EVLIST_INTERNAL)\n         base->event_count--/++;\n*/\n#define DECR_EVENT_COUNT(base,flags) \\\n\t((base)->event_count -= !((flags) & EVLIST_INTERNAL))\n#define INCR_EVENT_COUNT(base,flags) do {\t\t\t\t\t\\\n\t((base)->event_count += !((flags) & EVLIST_INTERNAL));\t\t\t\\\n\tMAX_EVENT_COUNT((base)->event_count_max, (base)->event_count);\t\t\\\n} while (0)\n\nstatic void\nevent_queue_remove_inserted(struct event_base *base, struct event *ev)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (EVUTIL_FAILURE_CHECK(!(ev->ev_flags & EVLIST_INSERTED))) {\n\t\tevent_errx(1, \"%s: %p(fd \"EV_SOCK_FMT\") not on queue %x\", __func__,\n                   (void *)ev, EV_SOCK_ARG(ev->ev_fd), EVLIST_INSERTED);\n\t\treturn;\n\t}\n\tDECR_EVENT_COUNT(base, ev->ev_flags);\n\tev->ev_flags &= ~EVLIST_INSERTED;\n}\nstatic void\nevent_queue_remove_active(struct event_base *base, struct event_callback *evcb)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (EVUTIL_FAILURE_CHECK(!(evcb->evcb_flags & EVLIST_ACTIVE))) {\n\t\tevent_errx(1, \"%s: %p not on queue %x\", __func__,\n                          (void *)evcb, EVLIST_ACTIVE);\n\t\treturn;\n\t}\n\tDECR_EVENT_COUNT(base, evcb->evcb_flags);\n\tevcb->evcb_flags &= ~EVLIST_ACTIVE;\n\tbase->event_count_active--;\n\n\tTAILQ_REMOVE(&base->activequeues[evcb->evcb_pri],\n\t    evcb, evcb_active_next);\n}\nstatic void\nevent_queue_remove_active_later(struct event_base *base, struct event_callback *evcb)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (EVUTIL_FAILURE_CHECK(!(evcb->evcb_flags & EVLIST_ACTIVE_LATER))) {\n\t\tevent_errx(1, \"%s: %p not on queue %x\", __func__,\n                          (void *)evcb, EVLIST_ACTIVE_LATER);\n\t\treturn;\n\t}\n\tDECR_EVENT_COUNT(base, evcb->evcb_flags);\n\tevcb->evcb_flags &= ~EVLIST_ACTIVE_LATER;\n\tbase->event_count_active--;\n\n\tTAILQ_REMOVE(&base->active_later_queue, evcb, evcb_active_next);\n}\nstatic void\nevent_queue_remove_timeout(struct event_base *base, struct event *ev)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (EVUTIL_FAILURE_CHECK(!(ev->ev_flags & EVLIST_TIMEOUT))) {\n\t\tevent_errx(1, \"%s: %p(fd \"EV_SOCK_FMT\") not on queue %x\", __func__,\n                   (void *)ev, EV_SOCK_ARG(ev->ev_fd), EVLIST_TIMEOUT);\n\t\treturn;\n\t}\n\tDECR_EVENT_COUNT(base, ev->ev_flags);\n\tev->ev_flags &= ~EVLIST_TIMEOUT;\n\n\tif (is_common_timeout(&ev->ev_timeout, base)) {\n\t\tstruct common_timeout_list *ctl =\n\t\t    get_common_timeout_list(base, &ev->ev_timeout);\n\t\tTAILQ_REMOVE(&ctl->events, ev,\n\t\t    ev_timeout_pos.ev_next_with_common_timeout);\n\t} else {\n\t\tmin_heap_erase_(&base->timeheap, ev);\n\t}\n}\n\n#ifdef USE_REINSERT_TIMEOUT\n/* Remove and reinsert 'ev' into the timeout queue. */\nstatic void\nevent_queue_reinsert_timeout(struct event_base *base, struct event *ev,\n    int was_common, int is_common, int old_timeout_idx)\n{\n\tstruct common_timeout_list *ctl;\n\tif (!(ev->ev_flags & EVLIST_TIMEOUT)) {\n\t\tevent_queue_insert_timeout(base, ev);\n\t\treturn;\n\t}\n\n\tswitch ((was_common<<1) | is_common) {\n\tcase 3: /* Changing from one common timeout to another */\n\t\tctl = base->common_timeout_queues[old_timeout_idx];\n\t\tTAILQ_REMOVE(&ctl->events, ev,\n\t\t    ev_timeout_pos.ev_next_with_common_timeout);\n\t\tctl = get_common_timeout_list(base, &ev->ev_timeout);\n\t\tinsert_common_timeout_inorder(ctl, ev);\n\t\tbreak;\n\tcase 2: /* Was common; is no longer common */\n\t\tctl = base->common_timeout_queues[old_timeout_idx];\n\t\tTAILQ_REMOVE(&ctl->events, ev,\n\t\t    ev_timeout_pos.ev_next_with_common_timeout);\n\t\tmin_heap_push_(&base->timeheap, ev);\n\t\tbreak;\n\tcase 1: /* Wasn't common; has become common. */\n\t\tmin_heap_erase_(&base->timeheap, ev);\n\t\tctl = get_common_timeout_list(base, &ev->ev_timeout);\n\t\tinsert_common_timeout_inorder(ctl, ev);\n\t\tbreak;\n\tcase 0: /* was in heap; is still on heap. */\n\t\tmin_heap_adjust_(&base->timeheap, ev);\n\t\tbreak;\n\tdefault:\n\t\tEVUTIL_ASSERT(0); /* unreachable */\n\t\tbreak;\n\t}\n}\n#endif\n\n/* Add 'ev' to the common timeout list in 'ev'. */\nstatic void\ninsert_common_timeout_inorder(struct common_timeout_list *ctl,\n    struct event *ev)\n{\n\tstruct event *e;\n\t/* By all logic, we should just be able to append 'ev' to the end of\n\t * ctl->events, since the timeout on each 'ev' is set to {the common\n\t * timeout} + {the time when we add the event}, and so the events\n\t * should arrive in order of their timeouts.  But just in case\n\t * there's some wacky threading issue going on, we do a search from\n\t * the end of 'ev' to find the right insertion point.\n\t */\n\tTAILQ_FOREACH_REVERSE(e, &ctl->events,\n\t    event_list, ev_timeout_pos.ev_next_with_common_timeout) {\n\t\t/* This timercmp is a little sneaky, since both ev and e have\n\t\t * magic values in tv_usec.  Fortunately, they ought to have\n\t\t * the _same_ magic values in tv_usec.  Let's assert for that.\n\t\t */\n\t\tEVUTIL_ASSERT(\n\t\t\tis_same_common_timeout(&e->ev_timeout, &ev->ev_timeout));\n\t\tif (evutil_timercmp(&ev->ev_timeout, &e->ev_timeout, >=)) {\n\t\t\tTAILQ_INSERT_AFTER(&ctl->events, e, ev,\n\t\t\t    ev_timeout_pos.ev_next_with_common_timeout);\n\t\t\treturn;\n\t\t}\n\t}\n\tTAILQ_INSERT_HEAD(&ctl->events, ev,\n\t    ev_timeout_pos.ev_next_with_common_timeout);\n}\n\nstatic void\nevent_queue_insert_inserted(struct event_base *base, struct event *ev)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (EVUTIL_FAILURE_CHECK(ev->ev_flags & EVLIST_INSERTED)) {\n\t\tevent_errx(1, \"%s: %p(fd \"EV_SOCK_FMT\") already inserted\", __func__,\n                   (void *)ev, EV_SOCK_ARG(ev->ev_fd));\n\t\treturn;\n\t}\n\n\tINCR_EVENT_COUNT(base, ev->ev_flags);\n\n\tev->ev_flags |= EVLIST_INSERTED;\n}\n\nstatic void\nevent_queue_insert_active(struct event_base *base, struct event_callback *evcb)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (evcb->evcb_flags & EVLIST_ACTIVE) {\n\t\t/* Double insertion is possible for active events */\n\t\treturn;\n\t}\n\n\tINCR_EVENT_COUNT(base, evcb->evcb_flags);\n\n\tevcb->evcb_flags |= EVLIST_ACTIVE;\n\n\tbase->event_count_active++;\n\tMAX_EVENT_COUNT(base->event_count_active_max, base->event_count_active);\n\tEVUTIL_ASSERT(evcb->evcb_pri < base->nactivequeues);\n\tTAILQ_INSERT_TAIL(&base->activequeues[evcb->evcb_pri],\n\t    evcb, evcb_active_next);\n}\n\nstatic void\nevent_queue_insert_active_later(struct event_base *base, struct event_callback *evcb)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\tif (evcb->evcb_flags & (EVLIST_ACTIVE_LATER|EVLIST_ACTIVE)) {\n\t\t/* Double insertion is possible */\n\t\treturn;\n\t}\n\n\tINCR_EVENT_COUNT(base, evcb->evcb_flags);\n\tevcb->evcb_flags |= EVLIST_ACTIVE_LATER;\n\tbase->event_count_active++;\n\tMAX_EVENT_COUNT(base->event_count_active_max, base->event_count_active);\n\tEVUTIL_ASSERT(evcb->evcb_pri < base->nactivequeues);\n\tTAILQ_INSERT_TAIL(&base->active_later_queue, evcb, evcb_active_next);\n}\n\nstatic void\nevent_queue_insert_timeout(struct event_base *base, struct event *ev)\n{\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\tif (EVUTIL_FAILURE_CHECK(ev->ev_flags & EVLIST_TIMEOUT)) {\n\t\tevent_errx(1, \"%s: %p(fd \"EV_SOCK_FMT\") already on timeout\", __func__,\n                   (void *)ev, EV_SOCK_ARG(ev->ev_fd));\n\t\treturn;\n\t}\n\n\tINCR_EVENT_COUNT(base, ev->ev_flags);\n\n\tev->ev_flags |= EVLIST_TIMEOUT;\n\n\tif (is_common_timeout(&ev->ev_timeout, base)) {\n\t\tstruct common_timeout_list *ctl =\n\t\t    get_common_timeout_list(base, &ev->ev_timeout);\n\t\tinsert_common_timeout_inorder(ctl, ev);\n\t} else {\n\t\tmin_heap_push_(&base->timeheap, ev);\n\t}\n}\n\nstatic void\nevent_queue_make_later_events_active(struct event_base *base)\n{\n\tstruct event_callback *evcb;\n\tEVENT_BASE_ASSERT_LOCKED(base);\n\n\twhile ((evcb = TAILQ_FIRST(&base->active_later_queue))) {\n\t\tTAILQ_REMOVE(&base->active_later_queue, evcb, evcb_active_next);\n\t\tevcb->evcb_flags = (evcb->evcb_flags & ~EVLIST_ACTIVE_LATER) | EVLIST_ACTIVE;\n\t\tEVUTIL_ASSERT(evcb->evcb_pri < base->nactivequeues);\n\t\tTAILQ_INSERT_TAIL(&base->activequeues[evcb->evcb_pri], evcb, evcb_active_next);\n\t\tbase->n_deferreds_queued += (evcb->evcb_closure == EV_CLOSURE_CB_SELF);\n\t}\n}\n\n/* Functions for debugging */\n\nconst char *\nevent_get_version(void)\n{\n\treturn (EVENT__VERSION);\n}\n\nev_uint32_t\nevent_get_version_number(void)\n{\n\treturn (EVENT__NUMERIC_VERSION);\n}\n\n/*\n * No thread-safe interface needed - the information should be the same\n * for all threads.\n */\n\nconst char *\nevent_get_method(void)\n{\n\treturn (current_base->evsel->name);\n}\n\n#ifndef EVENT__DISABLE_MM_REPLACEMENT\nstatic void *(*mm_malloc_fn_)(size_t sz) = NULL;\nstatic void *(*mm_realloc_fn_)(void *p, size_t sz) = NULL;\nstatic void (*mm_free_fn_)(void *p) = NULL;\n\nvoid *\nevent_mm_malloc_(size_t sz)\n{\n\tif (sz == 0)\n\t\treturn NULL;\n\n\tif (mm_malloc_fn_)\n\t\treturn mm_malloc_fn_(sz);\n\telse\n\t\treturn malloc(sz);\n}\n\nvoid *\nevent_mm_calloc_(size_t count, size_t size)\n{\n\tif (count == 0 || size == 0)\n\t\treturn NULL;\n\n\tif (mm_malloc_fn_) {\n\t\tsize_t sz = count * size;\n\t\tvoid *p = NULL;\n\t\tif (count > EV_SIZE_MAX / size)\n\t\t\tgoto error;\n\t\tp = mm_malloc_fn_(sz);\n\t\tif (p)\n\t\t\treturn memset(p, 0, sz);\n\t} else {\n\t\tvoid *p = calloc(count, size);\n#ifdef _WIN32\n\t\t/* Windows calloc doesn't reliably set ENOMEM */\n\t\tif (p == NULL)\n\t\t\tgoto error;\n#endif\n\t\treturn p;\n\t}\n\nerror:\n\terrno = ENOMEM;\n\treturn NULL;\n}\n\nchar *\nevent_mm_strdup_(const char *str)\n{\n\tif (!str) {\n\t\terrno = EINVAL;\n\t\treturn NULL;\n\t}\n\n\tif (mm_malloc_fn_) {\n\t\tsize_t ln = strlen(str);\n\t\tvoid *p = NULL;\n\t\tif (ln == EV_SIZE_MAX)\n\t\t\tgoto error;\n\t\tp = mm_malloc_fn_(ln+1);\n\t\tif (p)\n\t\t\treturn memcpy(p, str, ln+1);\n\t} else\n#ifdef _WIN32\n\t\treturn _strdup(str);\n#else\n\t\treturn strdup(str);\n#endif\n\nerror:\n\terrno = ENOMEM;\n\treturn NULL;\n}\n\nvoid *\nevent_mm_realloc_(void *ptr, size_t sz)\n{\n\tif (mm_realloc_fn_)\n\t\treturn mm_realloc_fn_(ptr, sz);\n\telse\n\t\treturn realloc(ptr, sz);\n}\n\nvoid\nevent_mm_free_(void *ptr)\n{\n\tif (mm_free_fn_)\n\t\tmm_free_fn_(ptr);\n\telse\n\t\tfree(ptr);\n}\n\nvoid\nevent_set_mem_functions(void *(*malloc_fn)(size_t sz),\n\t\t\tvoid *(*realloc_fn)(void *ptr, size_t sz),\n\t\t\tvoid (*free_fn)(void *ptr))\n{\n\tmm_malloc_fn_ = malloc_fn;\n\tmm_realloc_fn_ = realloc_fn;\n\tmm_free_fn_ = free_fn;\n}\n#endif\n\n#ifdef EVENT__HAVE_EVENTFD\nstatic void\nevthread_notify_drain_eventfd(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct event_base *base = arg;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tbase->is_notify_pending = 0;\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n#endif\n\nstatic void\nevthread_notify_drain_default(evutil_socket_t fd, short what, void *arg)\n{\n\tunsigned char buf[1024];\n\tstruct event_base *base = arg;\n#ifdef _WIN32\n\twhile (recv(fd, (char*)buf, sizeof(buf), 0) > 0)\n\t\t;\n#else\n\twhile (read(fd, (char*)buf, sizeof(buf)) > 0)\n\t\t;\n#endif\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tbase->is_notify_pending = 0;\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nint\nevthread_make_base_notifiable(struct event_base *base)\n{\n\tint r;\n\tif (!base)\n\t\treturn -1;\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tr = evthread_make_base_notifiable_nolock_(base);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\nstatic int\nevthread_make_base_notifiable_nolock_(struct event_base *base)\n{\n\tvoid (*cb)(evutil_socket_t, short, void *);\n\tint (*notify)(struct event_base *);\n\n\tif (base->th_notify_fn != NULL) {\n\t\t/* The base is already notifiable: we're doing fine. */\n\t\treturn 0;\n\t}\n\n#if defined(EVENT__HAVE_WORKING_KQUEUE)\n\tif (base->evsel == &kqops && event_kq_add_notify_event_(base) == 0) {\n\t\tbase->th_notify_fn = event_kq_notify_base_;\n\t\t/* No need to add an event here; the backend can wake\n\t\t * itself up just fine. */\n\t\treturn 0;\n\t}\n#endif\n\n#ifdef EVENT__HAVE_EVENTFD\n\tbase->th_notify_fd[0] = evutil_eventfd_(0,\n\t    EVUTIL_EFD_CLOEXEC|EVUTIL_EFD_NONBLOCK);\n\tif (base->th_notify_fd[0] >= 0) {\n\t\tbase->th_notify_fd[1] = -1;\n\t\tnotify = evthread_notify_base_eventfd;\n\t\tcb = evthread_notify_drain_eventfd;\n\t} else\n#endif\n\tif (evutil_make_internal_pipe_(base->th_notify_fd) == 0) {\n\t\tnotify = evthread_notify_base_default;\n\t\tcb = evthread_notify_drain_default;\n\t} else {\n\t\treturn -1;\n\t}\n\n\tbase->th_notify_fn = notify;\n\n\t/* prepare an event that we can use for wakeup */\n\tevent_assign(&base->th_notify, base, base->th_notify_fd[0],\n\t\t\t\t EV_READ|EV_PERSIST|EV_ET, cb, base);\n\n\t/* we need to mark this as internal event */\n\tbase->th_notify.ev_flags |= EVLIST_INTERNAL;\n\tevent_priority_set(&base->th_notify, 0);\n\n\treturn event_add_nolock_(&base->th_notify, NULL, 0);\n}\n\nint\nevent_base_foreach_event_nolock_(struct event_base *base,\n    event_base_foreach_event_cb fn, void *arg)\n{\n\tint r, i;\n\tsize_t u;\n\tstruct event *ev;\n\n\t/* Start out with all the EVLIST_INSERTED events. */\n\tif ((r = evmap_foreach_event_(base, fn, arg)))\n\t\treturn r;\n\n\t/* Okay, now we deal with those events that have timeouts and are in\n\t * the min-heap. */\n\tfor (u = 0; u < base->timeheap.n; ++u) {\n\t\tev = base->timeheap.p[u];\n\t\tif (ev->ev_flags & EVLIST_INSERTED) {\n\t\t\t/* we already processed this one */\n\t\t\tcontinue;\n\t\t}\n\t\tif ((r = fn(base, ev, arg)))\n\t\t\treturn r;\n\t}\n\n\t/* Now for the events in one of the timeout queues.\n\t * the min-heap. */\n\tfor (i = 0; i < base->n_common_timeouts; ++i) {\n\t\tstruct common_timeout_list *ctl =\n\t\t    base->common_timeout_queues[i];\n\t\tTAILQ_FOREACH(ev, &ctl->events,\n\t\t    ev_timeout_pos.ev_next_with_common_timeout) {\n\t\t\tif (ev->ev_flags & EVLIST_INSERTED) {\n\t\t\t\t/* we already processed this one */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif ((r = fn(base, ev, arg)))\n\t\t\t\treturn r;\n\t\t}\n\t}\n\n\t/* Finally, we deal wit all the active events that we haven't touched\n\t * yet. */\n\tfor (i = 0; i < base->nactivequeues; ++i) {\n\t\tstruct event_callback *evcb;\n\t\tTAILQ_FOREACH(evcb, &base->activequeues[i], evcb_active_next) {\n\t\t\tif ((evcb->evcb_flags & (EVLIST_INIT|EVLIST_INSERTED|EVLIST_TIMEOUT)) != EVLIST_INIT) {\n\t\t\t\t/* This isn't an event (evlist_init clear), or\n\t\t\t\t * we already processed it. (inserted or\n\t\t\t\t * timeout set */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tev = event_callback_to_event(evcb);\n\t\t\tif ((r = fn(base, ev, arg)))\n\t\t\t\treturn r;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/* Helper for event_base_dump_events: called on each event in the event base;\n * dumps only the inserted events. */\nstatic int\ndump_inserted_event_fn(const struct event_base *base, const struct event *e, void *arg)\n{\n\tFILE *output = arg;\n\tconst char *gloss = (e->ev_events & EV_SIGNAL) ?\n\t    \"sig\" : \"fd \";\n\n\tif (! (e->ev_flags & (EVLIST_INSERTED|EVLIST_TIMEOUT)))\n\t\treturn 0;\n\n\tfprintf(output, \"  %p [%s \"EV_SOCK_FMT\"]%s%s%s%s%s%s%s\",\n\t    (void*)e, gloss, EV_SOCK_ARG(e->ev_fd),\n\t    (e->ev_events&EV_READ)?\" Read\":\"\",\n\t    (e->ev_events&EV_WRITE)?\" Write\":\"\",\n\t    (e->ev_events&EV_CLOSED)?\" EOF\":\"\",\n\t    (e->ev_events&EV_SIGNAL)?\" Signal\":\"\",\n\t    (e->ev_events&EV_PERSIST)?\" Persist\":\"\",\n\t    (e->ev_events&EV_ET)?\" ET\":\"\",\n\t    (e->ev_flags&EVLIST_INTERNAL)?\" Internal\":\"\");\n\tif (e->ev_flags & EVLIST_TIMEOUT) {\n\t\tstruct timeval tv;\n\t\ttv.tv_sec = e->ev_timeout.tv_sec;\n\t\ttv.tv_usec = e->ev_timeout.tv_usec & MICROSECONDS_MASK;\n\t\tevutil_timeradd(&tv, &base->tv_clock_diff, &tv);\n\t\tfprintf(output, \" Timeout=%ld.%06d\",\n\t\t    (long)tv.tv_sec, (int)(tv.tv_usec & MICROSECONDS_MASK));\n\t}\n\tfputc('\\n', output);\n\n\treturn 0;\n}\n\n/* Helper for event_base_dump_events: called on each event in the event base;\n * dumps only the active events. */\nstatic int\ndump_active_event_fn(const struct event_base *base, const struct event *e, void *arg)\n{\n\tFILE *output = arg;\n\tconst char *gloss = (e->ev_events & EV_SIGNAL) ?\n\t    \"sig\" : \"fd \";\n\n\tif (! (e->ev_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER)))\n\t\treturn 0;\n\n\tfprintf(output, \"  %p [%s \"EV_SOCK_FMT\", priority=%d]%s%s%s%s%s active%s%s\\n\",\n\t    (void*)e, gloss, EV_SOCK_ARG(e->ev_fd), e->ev_pri,\n\t    (e->ev_res&EV_READ)?\" Read\":\"\",\n\t    (e->ev_res&EV_WRITE)?\" Write\":\"\",\n\t    (e->ev_res&EV_CLOSED)?\" EOF\":\"\",\n\t    (e->ev_res&EV_SIGNAL)?\" Signal\":\"\",\n\t    (e->ev_res&EV_TIMEOUT)?\" Timeout\":\"\",\n\t    (e->ev_flags&EVLIST_INTERNAL)?\" [Internal]\":\"\",\n\t    (e->ev_flags&EVLIST_ACTIVE_LATER)?\" [NextTime]\":\"\");\n\n\treturn 0;\n}\n\nint\nevent_base_foreach_event(struct event_base *base,\n    event_base_foreach_event_cb fn, void *arg)\n{\n\tint r;\n\tif ((!fn) || (!base)) {\n\t\treturn -1;\n\t}\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tr = event_base_foreach_event_nolock_(base, fn, arg);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn r;\n}\n\n\nvoid\nevent_base_dump_events(struct event_base *base, FILE *output)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tfprintf(output, \"Inserted events:\\n\");\n\tevent_base_foreach_event_nolock_(base, dump_inserted_event_fn, output);\n\n\tfprintf(output, \"Active events:\\n\");\n\tevent_base_foreach_event_nolock_(base, dump_active_event_fn, output);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nvoid\nevent_base_active_by_fd(struct event_base *base, evutil_socket_t fd, short events)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\t/* Activate any non timer events */\n\tif (!(events & EV_TIMEOUT)) {\n\t\tevmap_io_active_(base, fd, events & (EV_READ|EV_WRITE|EV_CLOSED));\n\t} else {\n\t\t/* If we want to activate timer events, loop and activate each event with\n\t\t * the same fd in both the timeheap and common timeouts list */\n\t\tint i;\n\t\tsize_t u;\n\t\tstruct event *ev;\n\n\t\tfor (u = 0; u < base->timeheap.n; ++u) {\n\t\t\tev = base->timeheap.p[u];\n\t\t\tif (ev->ev_fd == fd) {\n\t\t\t\tevent_active_nolock_(ev, EV_TIMEOUT, 1);\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0; i < base->n_common_timeouts; ++i) {\n\t\t\tstruct common_timeout_list *ctl = base->common_timeout_queues[i];\n\t\t\tTAILQ_FOREACH(ev, &ctl->events,\n\t\t\t\tev_timeout_pos.ev_next_with_common_timeout) {\n\t\t\t\tif (ev->ev_fd == fd) {\n\t\t\t\t\tevent_active_nolock_(ev, EV_TIMEOUT, 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nvoid\nevent_base_active_by_signal(struct event_base *base, int sig)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tevmap_signal_active_(base, sig, 1);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\n\nvoid\nevent_base_add_virtual_(struct event_base *base)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tbase->virtual_event_count++;\n\tMAX_EVENT_COUNT(base->virtual_event_count_max, base->virtual_event_count);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nvoid\nevent_base_del_virtual_(struct event_base *base)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tEVUTIL_ASSERT(base->virtual_event_count > 0);\n\tbase->virtual_event_count--;\n\tif (base->virtual_event_count == 0 && EVBASE_NEED_NOTIFY(base))\n\t\tevthread_notify_base(base);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nstatic void\nevent_free_debug_globals_locks(void)\n{\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_map_lock_ != NULL) {\n\t\tEVTHREAD_FREE_LOCK(event_debug_map_lock_, 0);\n\t\tevent_debug_map_lock_ = NULL;\n\t\tevthreadimpl_disable_lock_debugging_();\n\t}\n#endif /* EVENT__DISABLE_DEBUG_MODE */\n#endif /* EVENT__DISABLE_THREAD_SUPPORT */\n\treturn;\n}\n\nstatic void\nevent_free_debug_globals(void)\n{\n\tevent_free_debug_globals_locks();\n}\n\nstatic void\nevent_free_evsig_globals(void)\n{\n\tevsig_free_globals_();\n}\n\nstatic void\nevent_free_evutil_globals(void)\n{\n\tevutil_free_globals_();\n}\n\nstatic void\nevent_free_globals(void)\n{\n\tevent_free_debug_globals();\n\tevent_free_evsig_globals();\n\tevent_free_evutil_globals();\n}\n\nvoid\nlibevent_global_shutdown(void)\n{\n\tevent_disable_debug_mode();\n\tevent_free_globals();\n}\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevent_global_setup_locks_(const int enable_locks)\n{\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tEVTHREAD_SETUP_GLOBAL_LOCK(event_debug_map_lock_, 0);\n#endif\n\tif (evsig_global_setup_locks_(enable_locks) < 0)\n\t\treturn -1;\n\tif (evutil_global_setup_locks_(enable_locks) < 0)\n\t\treturn -1;\n\tif (evutil_secure_rng_global_setup_locks_(enable_locks) < 0)\n\t\treturn -1;\n\treturn 0;\n}\n#endif\n\nvoid\nevent_base_assert_ok_(struct event_base *base)\n{\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tevent_base_assert_ok_nolock_(base);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nvoid\nevent_base_assert_ok_nolock_(struct event_base *base)\n{\n\tint i;\n\tsize_t u;\n\tint count;\n\n\t/* First do checks on the per-fd and per-signal lists */\n\tevmap_check_integrity_(base);\n\n\t/* Check the heap property */\n\tfor (u = 1; u < base->timeheap.n; ++u) {\n\t\tsize_t parent = (u - 1) / 2;\n\t\tstruct event *ev, *p_ev;\n\t\tev = base->timeheap.p[u];\n\t\tp_ev = base->timeheap.p[parent];\n\t\tEVUTIL_ASSERT(ev->ev_flags & EVLIST_TIMEOUT);\n\t\tEVUTIL_ASSERT(evutil_timercmp(&p_ev->ev_timeout, &ev->ev_timeout, <=));\n\t\tEVUTIL_ASSERT(ev->ev_timeout_pos.min_heap_idx == u);\n\t}\n\n\t/* Check that the common timeouts are fine */\n\tfor (i = 0; i < base->n_common_timeouts; ++i) {\n\t\tstruct common_timeout_list *ctl = base->common_timeout_queues[i];\n\t\tstruct event *last=NULL, *ev;\n\n\t\tEVUTIL_ASSERT_TAILQ_OK(&ctl->events, event, ev_timeout_pos.ev_next_with_common_timeout);\n\n\t\tTAILQ_FOREACH(ev, &ctl->events, ev_timeout_pos.ev_next_with_common_timeout) {\n\t\t\tif (last)\n\t\t\t\tEVUTIL_ASSERT(evutil_timercmp(&last->ev_timeout, &ev->ev_timeout, <=));\n\t\t\tEVUTIL_ASSERT(ev->ev_flags & EVLIST_TIMEOUT);\n\t\t\tEVUTIL_ASSERT(is_common_timeout(&ev->ev_timeout,base));\n\t\t\tEVUTIL_ASSERT(COMMON_TIMEOUT_IDX(&ev->ev_timeout) == i);\n\t\t\tlast = ev;\n\t\t}\n\t}\n\n\t/* Check the active queues. */\n\tcount = 0;\n\tfor (i = 0; i < base->nactivequeues; ++i) {\n\t\tstruct event_callback *evcb;\n\t\tEVUTIL_ASSERT_TAILQ_OK(&base->activequeues[i], event_callback, evcb_active_next);\n\t\tTAILQ_FOREACH(evcb, &base->activequeues[i], evcb_active_next) {\n\t\t\tEVUTIL_ASSERT((evcb->evcb_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER)) == EVLIST_ACTIVE);\n\t\t\tEVUTIL_ASSERT(evcb->evcb_pri == i);\n\t\t\t++count;\n\t\t}\n\t}\n\n\t{\n\t\tstruct event_callback *evcb;\n\t\tTAILQ_FOREACH(evcb, &base->active_later_queue, evcb_active_next) {\n\t\t\tEVUTIL_ASSERT((evcb->evcb_flags & (EVLIST_ACTIVE|EVLIST_ACTIVE_LATER)) == EVLIST_ACTIVE_LATER);\n\t\t\t++count;\n\t\t}\n\t}\n\tEVUTIL_ASSERT(count == base->event_count_active);\n}\n"
        },
        {
          "name": "event_iocp.c",
          "type": "blob",
          "size": 7.52734375,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifndef _WIN32_WINNT\n/* Minimum required for InitializeCriticalSectionAndSpinCount */\n#define _WIN32_WINNT 0x0403\n#endif\n\n#include \"evconfig-private.h\"\n\n#include <winsock2.h>\n#include <windows.h>\n#include <process.h>\n#include <stdio.h>\n#include <mswsock.h>\n\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"iocp-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"event-internal.h\"\n#include \"evthread-internal.h\"\n\n#define NOTIFICATION_KEY ((ULONG_PTR)-1)\n\nvoid\nevent_overlapped_init_(struct event_overlapped *o, iocp_callback cb)\n{\n\tmemset(o, 0, sizeof(struct event_overlapped));\n\to->cb = cb;\n}\n\nstatic void\nhandle_entry(OVERLAPPED *o, ULONG_PTR completion_key, DWORD nBytes, int ok)\n{\n\tstruct event_overlapped *eo =\n\t    EVUTIL_UPCAST(o, struct event_overlapped, overlapped);\n\teo->cb(eo, completion_key, nBytes, ok);\n}\n\nstatic void\nloop(void *port_)\n{\n\tstruct event_iocp_port *port = port_;\n\tlong ms = port->ms;\n\tHANDLE p = port->port;\n\n\tif (ms <= 0)\n\t\tms = INFINITE;\n\n\twhile (1) {\n\t\tOVERLAPPED *overlapped=NULL;\n\t\tULONG_PTR key=0;\n\t\tDWORD bytes=0;\n\t\tint ok = GetQueuedCompletionStatus(p, &bytes, &key,\n\t\t\t&overlapped, ms);\n\t\tEnterCriticalSection(&port->lock);\n\t\tif (port->shutdown) {\n\t\t\tif (--port->n_live_threads == 0)\n\t\t\t\tReleaseSemaphore(port->shutdownSemaphore, 1,\n\t\t\t\t\t\tNULL);\n\t\t\tLeaveCriticalSection(&port->lock);\n\t\t\treturn;\n\t\t}\n\t\tLeaveCriticalSection(&port->lock);\n\n\t\tif (key != NOTIFICATION_KEY && overlapped)\n\t\t\thandle_entry(overlapped, key, bytes, ok);\n\t\telse if (!overlapped)\n\t\t\tbreak;\n\t}\n\tevent_warnx(\"GetQueuedCompletionStatus exited with no event.\");\n\tEnterCriticalSection(&port->lock);\n\tif (--port->n_live_threads == 0)\n\t\tReleaseSemaphore(port->shutdownSemaphore, 1, NULL);\n\tLeaveCriticalSection(&port->lock);\n}\n\nint\nevent_iocp_port_associate_(struct event_iocp_port *port, evutil_socket_t fd,\n    ev_uintptr_t key)\n{\n\tHANDLE h;\n\th = CreateIoCompletionPort((HANDLE)fd, port->port, key, port->n_threads);\n\tif (!h)\n\t\treturn -1;\n\treturn 0;\n}\n\nstatic void *\nget_extension_function(SOCKET s, const GUID *which_fn)\n{\n\tvoid *ptr = NULL;\n\tDWORD bytes=0;\n\tWSAIoctl(s, SIO_GET_EXTENSION_FUNCTION_POINTER,\n\t    (GUID*)which_fn, sizeof(*which_fn),\n\t    &ptr, sizeof(ptr),\n\t    &bytes, NULL, NULL);\n\n\t/* No need to detect errors here: if ptr is set, then we have a good\n\t   function pointer.  Otherwise, we should behave as if we had no\n\t   function pointer.\n\t*/\n\treturn ptr;\n}\n\n/* Mingw doesn't have these in its mswsock.h.  The values are copied from\n   wine.h.   Perhaps if we copy them exactly, the cargo will come again.\n*/\n#ifndef WSAID_ACCEPTEX\n#define WSAID_ACCEPTEX \\\n\t{0xb5367df1,0xcbac,0x11cf,{0x95,0xca,0x00,0x80,0x5f,0x48,0xa1,0x92}}\n#endif\n#ifndef WSAID_CONNECTEX\n#define WSAID_CONNECTEX \\\n\t{0x25a207b9,0xddf3,0x4660,{0x8e,0xe9,0x76,0xe5,0x8c,0x74,0x06,0x3e}}\n#endif\n#ifndef WSAID_GETACCEPTEXSOCKADDRS\n#define WSAID_GETACCEPTEXSOCKADDRS \\\n\t{0xb5367df2,0xcbac,0x11cf,{0x95,0xca,0x00,0x80,0x5f,0x48,0xa1,0x92}}\n#endif\n\nstatic int extension_fns_initialized = 0;\n\nstatic void\ninit_extension_functions(struct win32_extension_fns *ext)\n{\n\tconst GUID acceptex = WSAID_ACCEPTEX;\n\tconst GUID connectex = WSAID_CONNECTEX;\n\tconst GUID getacceptexsockaddrs = WSAID_GETACCEPTEXSOCKADDRS;\n\tSOCKET s = socket(AF_INET, SOCK_STREAM, 0);\n\tif (s == EVUTIL_INVALID_SOCKET)\n\t\treturn;\n\text->AcceptEx = get_extension_function(s, &acceptex);\n\text->ConnectEx = get_extension_function(s, &connectex);\n\text->GetAcceptExSockaddrs = get_extension_function(s,\n\t    &getacceptexsockaddrs);\n\tclosesocket(s);\n\n\textension_fns_initialized = 1;\n}\n\nstatic struct win32_extension_fns the_extension_fns;\n\nconst struct win32_extension_fns *\nevent_get_win32_extension_fns_(void)\n{\n\treturn &the_extension_fns;\n}\n\n#define N_CPUS_DEFAULT 2\n\nstruct event_iocp_port *\nevent_iocp_port_launch_(int n_cpus)\n{\n\tstruct event_iocp_port *port;\n\tint i;\n\n\tif (!extension_fns_initialized)\n\t\tinit_extension_functions(&the_extension_fns);\n\n\tif (!(port = mm_calloc(1, sizeof(struct event_iocp_port))))\n\t\treturn NULL;\n\n\tif (n_cpus <= 0)\n\t\tn_cpus = N_CPUS_DEFAULT;\n\tport->n_threads = n_cpus * 2;\n\tport->threads = mm_calloc(port->n_threads, sizeof(HANDLE));\n\tif (!port->threads)\n\t\tgoto err;\n\n\tport->port = CreateIoCompletionPort(INVALID_HANDLE_VALUE, NULL, 0,\n\t\t\tn_cpus);\n\tport->ms = -1;\n\tif (!port->port)\n\t\tgoto err;\n\n\tport->shutdownSemaphore = CreateSemaphore(NULL, 0, 1, NULL);\n\tif (!port->shutdownSemaphore)\n\t\tgoto err;\n\n\tfor (i=0; i<port->n_threads; ++i) {\n\t\tev_uintptr_t th = _beginthread(loop, 0, port);\n\t\tif (th == (ev_uintptr_t)-1)\n\t\t\tgoto err;\n\t\tport->threads[i] = (HANDLE)th;\n\t\t++port->n_live_threads;\n\t}\n\n\tInitializeCriticalSectionAndSpinCount(&port->lock, 1000);\n\n\treturn port;\nerr:\n\tif (port->port)\n\t\tCloseHandle(port->port);\n\tif (port->threads)\n\t\tmm_free(port->threads);\n\tif (port->shutdownSemaphore)\n\t\tCloseHandle(port->shutdownSemaphore);\n\tmm_free(port);\n\treturn NULL;\n}\n\nstatic void\nevent_iocp_port_unlock_and_free_(struct event_iocp_port *port)\n{\n\tDeleteCriticalSection(&port->lock);\n\tCloseHandle(port->port);\n\tCloseHandle(port->shutdownSemaphore);\n\tmm_free(port->threads);\n\tmm_free(port);\n}\n\nstatic int\nevent_iocp_notify_all(struct event_iocp_port *port)\n{\n\tint i, r, ok=1;\n\tfor (i=0; i<port->n_threads; ++i) {\n\t\tr = PostQueuedCompletionStatus(port->port, 0, NOTIFICATION_KEY,\n\t\t    NULL);\n\t\tif (!r)\n\t\t\tok = 0;\n\t}\n\treturn ok ? 0 : -1;\n}\n\nint\nevent_iocp_shutdown_(struct event_iocp_port *port, long waitMsec)\n{\n\tDWORD ms = INFINITE;\n\tint n;\n\n\tEnterCriticalSection(&port->lock);\n\tport->shutdown = 1;\n\tLeaveCriticalSection(&port->lock);\n\tevent_iocp_notify_all(port);\n\n\tif (waitMsec >= 0)\n\t\tms = waitMsec;\n\n\tWaitForSingleObject(port->shutdownSemaphore, ms);\n\tEnterCriticalSection(&port->lock);\n\tn = port->n_live_threads;\n\tLeaveCriticalSection(&port->lock);\n\tif (n == 0) {\n\t\tevent_iocp_port_unlock_and_free_(port);\n\t\treturn 0;\n\t} else {\n\t\treturn -1;\n\t}\n}\n\nint\nevent_iocp_activate_overlapped_(\n    struct event_iocp_port *port, struct event_overlapped *o,\n    ev_uintptr_t key, ev_uint32_t n)\n{\n\tBOOL r;\n\n\tr = PostQueuedCompletionStatus(port->port, n, key, &o->overlapped);\n\treturn (r==0) ? -1 : 0;\n}\n\nstruct event_iocp_port *\nevent_base_get_iocp_(struct event_base *base)\n{\n#ifdef _WIN32\n\treturn base->iocp;\n#else\n\treturn NULL;\n#endif\n}\n"
        },
        {
          "name": "event_rpcgen.py",
          "type": "blob",
          "size": 53.650390625,
          "content": "#!/usr/bin/env python\n#\n# Copyright (c) 2005-2007 Niels Provos <provos@citi.umich.edu>\n# Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n# All rights reserved.\n#\n# Generates marshaling code based on libevent.\n\n# pylint: disable=too-many-lines\n# pylint: disable=too-many-branches\n# pylint: disable=too-many-public-methods\n# pylint: disable=too-many-statements\n# pylint: disable=global-statement\n\n# TODO:\n# 1) propagate the arguments/options parsed by argparse down to the\n#    instantiated factory objects.\n# 2) move the globals into a class that manages execution, including the\n#    progress outputs that go to stderr at the moment.\n# 3) emit other languages.\n\nimport argparse\nimport re\nimport sys\n\n_NAME = \"event_rpcgen.py\"\n_VERSION = \"0.1\"\n\n# Globals\nLINE_COUNT = 0\n\nCPPCOMMENT_RE = re.compile(r\"\\/\\/.*$\")\nNONIDENT_RE = re.compile(r\"\\W\")\nPREPROCESSOR_DEF_RE = re.compile(r\"^#define\")\nSTRUCT_REF_RE = re.compile(r\"^struct\\[(?P<name>[a-zA-Z_][a-zA-Z0-9_]*)\\]$\")\nSTRUCT_DEF_RE = re.compile(r\"^struct +[a-zA-Z_][a-zA-Z0-9_]* *{$\")\nWHITESPACE_RE = re.compile(r\"\\s+\")\n\nHEADER_DIRECT = []\nCPP_DIRECT = []\n\nQUIETLY = False\n\n\ndef declare(s):\n    if not QUIETLY:\n        print(s)\n\n\ndef TranslateList(mylist, mydict):\n    return [x % mydict for x in mylist]\n\n\nclass RpcGenError(Exception):\n    \"\"\"An Exception class for parse errors.\"\"\"\n\n    def __init__(self, why): # pylint: disable=super-init-not-called\n        self.why = why\n\n    def __str__(self):\n        return str(self.why)\n\n\n# Holds everything that makes a struct\nclass Struct(object):\n    def __init__(self, name):\n        self._name = name\n        self._entries = []\n        self._tags = {}\n        declare(\"  Created struct: %s\" % name)\n\n    def AddEntry(self, entry):\n        if entry.Tag() in self._tags:\n            raise RpcGenError(\n                'Entry \"%s\" duplicates tag number %d from \"%s\" '\n                \"around line %d\"\n                % (entry.Name(), entry.Tag(), self._tags[entry.Tag()], LINE_COUNT)\n            )\n        self._entries.append(entry)\n        self._tags[entry.Tag()] = entry.Name()\n        declare(\"    Added entry: %s\" % entry.Name())\n\n    def Name(self):\n        return self._name\n\n    def EntryTagName(self, entry):\n        \"\"\"Creates the name inside an enumeration for distinguishing data\n        types.\"\"\"\n        name = \"%s_%s\" % (self._name, entry.Name())\n        return name.upper()\n\n    @staticmethod\n    def PrintIndented(filep, ident, code):\n        \"\"\"Takes an array, add indentation to each entry and prints it.\"\"\"\n        for entry in code:\n            filep.write(\"%s%s\\n\" % (ident, entry))\n\n\nclass StructCCode(Struct):\n    \"\"\" Knows how to generate C code for a struct \"\"\"\n\n    def __init__(self, name):\n        Struct.__init__(self, name)\n\n    def PrintTags(self, filep):\n        \"\"\"Prints the tag definitions for a structure.\"\"\"\n        filep.write(\"/* Tag definition for %s */\\n\" % self._name)\n        filep.write(\"enum %s_ {\\n\" % self._name.lower())\n        for entry in self._entries:\n            filep.write(\"  %s=%d,\\n\" % (self.EntryTagName(entry), entry.Tag()))\n        filep.write(\"  %s_MAX_TAGS\\n\" % (self._name.upper()))\n        filep.write(\"};\\n\\n\")\n\n    def PrintForwardDeclaration(self, filep):\n        filep.write(\"struct %s;\\n\" % self._name)\n\n    def PrintDeclaration(self, filep):\n        filep.write(\"/* Structure declaration for %s */\\n\" % self._name)\n        filep.write(\"struct %s_access_ {\\n\" % self._name)\n        for entry in self._entries:\n            dcl = entry.AssignDeclaration(\"(*%s_assign)\" % entry.Name())\n            dcl.extend(entry.GetDeclaration(\"(*%s_get)\" % entry.Name()))\n            if entry.Array():\n                dcl.extend(entry.AddDeclaration(\"(*%s_add)\" % entry.Name()))\n            self.PrintIndented(filep, \"  \", dcl)\n        filep.write(\"};\\n\\n\")\n\n        filep.write(\"struct %s {\\n\" % self._name)\n        filep.write(\"  struct %s_access_ *base;\\n\\n\" % self._name)\n        for entry in self._entries:\n            dcl = entry.Declaration()\n            self.PrintIndented(filep, \"  \", dcl)\n        filep.write(\"\\n\")\n        for entry in self._entries:\n            filep.write(\"  ev_uint8_t %s_set;\\n\" % entry.Name())\n        filep.write(\"};\\n\\n\")\n\n        filep.write(\n            \"\"\"struct %(name)s *%(name)s_new(void);\nstruct %(name)s *%(name)s_new_with_arg(void *);\nvoid %(name)s_free(struct %(name)s *);\nvoid %(name)s_clear(struct %(name)s *);\nvoid %(name)s_marshal(struct evbuffer *, const struct %(name)s *);\nint %(name)s_unmarshal(struct %(name)s *, struct evbuffer *);\nint %(name)s_complete(struct %(name)s *);\nvoid evtag_marshal_%(name)s(struct evbuffer *, ev_uint32_t,\n    const struct %(name)s *);\nint evtag_unmarshal_%(name)s(struct evbuffer *, ev_uint32_t,\n    struct %(name)s *);\\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n        # Write a setting function of every variable\n        for entry in self._entries:\n            self.PrintIndented(\n                filep, \"\", entry.AssignDeclaration(entry.AssignFuncName())\n            )\n            self.PrintIndented(filep, \"\", entry.GetDeclaration(entry.GetFuncName()))\n            if entry.Array():\n                self.PrintIndented(filep, \"\", entry.AddDeclaration(entry.AddFuncName()))\n\n        filep.write(\"/* --- %s done --- */\\n\\n\" % self._name)\n\n    def PrintCode(self, filep):\n        filep.write(\n            \"\"\"/*\n * Implementation of %s\n */\n\"\"\"\n            % (self._name)\n        )\n\n        filep.write(\n            \"\"\"\nstatic struct %(name)s_access_ %(name)s_base__ = {\n\"\"\"\n            % {\"name\": self._name}\n        )\n        for entry in self._entries:\n            self.PrintIndented(filep, \"  \", entry.CodeBase())\n        filep.write(\"};\\n\\n\")\n\n        # Creation\n        filep.write(\n            \"\"\"struct %(name)s *\n%(name)s_new(void)\n{\n  return %(name)s_new_with_arg(NULL);\n}\n\nstruct %(name)s *\n%(name)s_new_with_arg(void *unused)\n{\n  struct %(name)s *tmp;\n  if ((tmp = malloc(sizeof(struct %(name)s))) == NULL) {\n    event_warn(\"%%s: malloc\", __func__);\n    return (NULL);\n  }\n  tmp->base = &%(name)s_base__;\n\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n        for entry in self._entries:\n            self.PrintIndented(filep, \"  \", entry.CodeInitialize(\"tmp\"))\n            filep.write(\"  tmp->%s_set = 0;\\n\\n\" % entry.Name())\n\n        filep.write(\n            \"\"\"  return (tmp);\n}\n\n\"\"\"\n        )\n\n        # Adding\n        for entry in self._entries:\n            if entry.Array():\n                self.PrintIndented(filep, \"\", entry.CodeAdd())\n            filep.write(\"\\n\")\n\n        # Assigning\n        for entry in self._entries:\n            self.PrintIndented(filep, \"\", entry.CodeAssign())\n            filep.write(\"\\n\")\n\n        # Getting\n        for entry in self._entries:\n            self.PrintIndented(filep, \"\", entry.CodeGet())\n            filep.write(\"\\n\")\n\n        # Clearing\n        filep.write(\n            \"\"\"void\n%(name)s_clear(struct %(name)s *tmp)\n{\n\"\"\"\n            % {\"name\": self._name}\n        )\n        for entry in self._entries:\n            self.PrintIndented(filep, \"  \", entry.CodeClear(\"tmp\"))\n\n        filep.write(\"}\\n\\n\")\n\n        # Freeing\n        filep.write(\n            \"\"\"void\n%(name)s_free(struct %(name)s *tmp)\n{\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n        for entry in self._entries:\n            self.PrintIndented(filep, \"  \", entry.CodeFree(\"tmp\"))\n\n        filep.write(\n            \"\"\"  free(tmp);\n}\n\n\"\"\"\n        )\n\n        # Marshaling\n        filep.write(\n            \"\"\"void\n%(name)s_marshal(struct evbuffer *evbuf, const struct %(name)s *tmp) {\n\"\"\"\n            % {\"name\": self._name}\n        )\n        for entry in self._entries:\n            indent = \"  \"\n            # Optional entries do not have to be set\n            if entry.Optional():\n                indent += \"  \"\n                filep.write(\"  if (tmp->%s_set) {\\n\" % entry.Name())\n            self.PrintIndented(\n                filep,\n                indent,\n                entry.CodeMarshal(\n                    \"evbuf\",\n                    self.EntryTagName(entry),\n                    entry.GetVarName(\"tmp\"),\n                    entry.GetVarLen(\"tmp\"),\n                ),\n            )\n            if entry.Optional():\n                filep.write(\"  }\\n\")\n\n        filep.write(\"}\\n\\n\")\n\n        # Unmarshaling\n        filep.write(\n            \"\"\"int\n%(name)s_unmarshal(struct %(name)s *tmp, struct evbuffer *evbuf)\n{\n  ev_uint32_t tag;\n  while (evbuffer_get_length(evbuf) > 0) {\n    if (evtag_peek(evbuf, &tag) == -1)\n      return (-1);\n    switch (tag) {\n\n\"\"\"\n            % {\"name\": self._name}\n        )\n        for entry in self._entries:\n            filep.write(\"      case %s:\\n\" % (self.EntryTagName(entry)))\n            if not entry.Array():\n                filep.write(\n                    \"\"\"        if (tmp->%s_set)\n          return (-1);\n\"\"\"\n                    % (entry.Name())\n                )\n\n            self.PrintIndented(\n                filep,\n                \"        \",\n                entry.CodeUnmarshal(\n                    \"evbuf\",\n                    self.EntryTagName(entry),\n                    entry.GetVarName(\"tmp\"),\n                    entry.GetVarLen(\"tmp\"),\n                ),\n            )\n\n            filep.write(\n                \"\"\"        tmp->%s_set = 1;\n        break;\n\"\"\"\n                % (entry.Name())\n            )\n        filep.write(\n            \"\"\"      default:\n        return -1;\n    }\n  }\n\n\"\"\"\n        )\n        # Check if it was decoded completely\n        filep.write(\n            \"\"\"  if (%(name)s_complete(tmp) == -1)\n    return (-1);\n  return (0);\n}\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n        # Checking if a structure has all the required data\n        filep.write(\n            \"\"\"\nint\n%(name)s_complete(struct %(name)s *msg)\n{\n\"\"\"\n            % {\"name\": self._name}\n        )\n        for entry in self._entries:\n            if not entry.Optional():\n                code = [\n                    \"\"\"if (!msg->%(name)s_set)\n    return (-1);\"\"\"\n                ]\n                code = TranslateList(code, entry.GetTranslation())\n                self.PrintIndented(filep, \"  \", code)\n\n            self.PrintIndented(\n                filep, \"  \", entry.CodeComplete(\"msg\", entry.GetVarName(\"msg\"))\n            )\n        filep.write(\n            \"\"\"  return (0);\n}\n\"\"\"\n        )\n\n        # Complete message unmarshaling\n        filep.write(\n            \"\"\"\nint\nevtag_unmarshal_%(name)s(struct evbuffer *evbuf, ev_uint32_t need_tag,\n  struct %(name)s *msg)\n{\n  ev_uint32_t tag;\n  int res = -1;\n\n  struct evbuffer *tmp = evbuffer_new();\n\n  if (evtag_unmarshal(evbuf, &tag, tmp) == -1 || tag != need_tag)\n    goto error;\n\n  if (%(name)s_unmarshal(msg, tmp) == -1)\n    goto error;\n\n  res = 0;\n\n error:\n  evbuffer_free(tmp);\n  return (res);\n}\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n        # Complete message marshaling\n        filep.write(\n            \"\"\"\nvoid\nevtag_marshal_%(name)s(struct evbuffer *evbuf, ev_uint32_t tag,\n    const struct %(name)s *msg)\n{\n  struct evbuffer *buf_ = evbuffer_new();\n  assert(buf_ != NULL);\n  %(name)s_marshal(buf_, msg);\n  evtag_marshal_buffer(evbuf, tag, buf_);\n  evbuffer_free(buf_);\n}\n\n\"\"\"\n            % {\"name\": self._name}\n        )\n\n\nclass Entry(object):\n    def __init__(self, ent_type, name, tag):\n        self._type = ent_type\n        self._name = name\n        self._tag = int(tag)\n        self._ctype = ent_type\n        self._optional = False\n        self._can_be_array = False\n        self._array = False\n        self._line_count = -1\n        self._struct = None\n        self._refname = None\n\n        self._optpointer = True\n        self._optaddarg = True\n\n    @staticmethod\n    def GetInitializer():\n        raise NotImplementedError(\"Entry does not provide an initializer\")\n\n    def SetStruct(self, struct):\n        self._struct = struct\n\n    def LineCount(self):\n        assert self._line_count != -1\n        return self._line_count\n\n    def SetLineCount(self, number):\n        self._line_count = number\n\n    def Array(self):\n        return self._array\n\n    def Optional(self):\n        return self._optional\n\n    def Tag(self):\n        return self._tag\n\n    def Name(self):\n        return self._name\n\n    def Type(self):\n        return self._type\n\n    def MakeArray(self):\n        self._array = True\n\n    def MakeOptional(self):\n        self._optional = True\n\n    def Verify(self):\n        if self.Array() and not self._can_be_array:\n            raise RpcGenError(\n                'Entry \"%s\" cannot be created as an array '\n                \"around line %d\" % (self._name, self.LineCount())\n            )\n        if not self._struct:\n            raise RpcGenError(\n                'Entry \"%s\" does not know which struct it belongs to '\n                \"around line %d\" % (self._name, self.LineCount())\n            )\n        if self._optional and self._array:\n            raise RpcGenError(\n                'Entry \"%s\" has illegal combination of optional and array '\n                \"around line %d\" % (self._name, self.LineCount())\n            )\n\n    def GetTranslation(self, extradict=None):\n        if extradict is None:\n            extradict = {}\n        mapping = {\n            \"parent_name\": self._struct.Name(),\n            \"name\": self._name,\n            \"ctype\": self._ctype,\n            \"refname\": self._refname,\n            \"optpointer\": self._optpointer and \"*\" or \"\",\n            \"optreference\": self._optpointer and \"&\" or \"\",\n            \"optaddarg\": self._optaddarg and \", const %s value\" % self._ctype or \"\",\n        }\n        for (k, v) in list(extradict.items()):\n            mapping[k] = v\n\n        return mapping\n\n    def GetVarName(self, var):\n        return \"%(var)s->%(name)s_data\" % self.GetTranslation({\"var\": var})\n\n    def GetVarLen(self, _var):\n        return \"sizeof(%s)\" % self._ctype\n\n    def GetFuncName(self):\n        return \"%s_%s_get\" % (self._struct.Name(), self._name)\n\n    def GetDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, %s *);\" % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def CodeGet(self):\n        code = \"\"\"int\n%(parent_name)s_%(name)s_get(struct %(parent_name)s *msg, %(ctype)s *value)\n{\n  if (msg->%(name)s_set != 1)\n    return (-1);\n  *value = msg->%(name)s_data;\n  return (0);\n}\"\"\"\n        code = code % self.GetTranslation()\n        return code.split(\"\\n\")\n\n    def AssignFuncName(self):\n        return \"%s_%s_assign\" % (self._struct.Name(), self._name)\n\n    def AddFuncName(self):\n        return \"%s_%s_add\" % (self._struct.Name(), self._name)\n\n    def AssignDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, const %s);\"\n            % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def CodeAssign(self):\n        code = [\n            \"int\",\n            \"%(parent_name)s_%(name)s_assign(struct %(parent_name)s *msg,\"\n            \" const %(ctype)s value)\",\n            \"{\",\n            \"  msg->%(name)s_set = 1;\",\n            \"  msg->%(name)s_data = value;\",\n            \"  return (0);\",\n            \"}\",\n        ]\n        code = \"\\n\".join(code)\n        code = code % self.GetTranslation()\n        return code.split(\"\\n\")\n\n    def CodeClear(self, structname):\n        code = [\"%s->%s_set = 0;\" % (structname, self.Name())]\n\n        return code\n\n    @staticmethod\n    def CodeComplete(_structname, _var_name):\n        return []\n\n    @staticmethod\n    def CodeFree(_name):\n        return []\n\n    def CodeBase(self):\n        code = [\"%(parent_name)s_%(name)s_assign,\", \"%(parent_name)s_%(name)s_get,\"]\n        if self.Array():\n            code.append(\"%(parent_name)s_%(name)s_add,\")\n\n        code = \"\\n\".join(code)\n        code = code % self.GetTranslation()\n        return code.split(\"\\n\")\n\n\nclass EntryBytes(Entry):\n    def __init__(self, ent_type, name, tag, length):\n        # Init base class\n        super(EntryBytes, self).__init__(ent_type, name, tag)\n\n        self._length = length\n        self._ctype = \"ev_uint8_t\"\n\n    @staticmethod\n    def GetInitializer():\n        return \"NULL\"\n\n    def GetVarLen(self, _var):\n        return \"(%s)\" % self._length\n\n    @staticmethod\n    def CodeArrayAdd(varname, _value):\n        # XXX: copy here\n        return [\"%(varname)s = NULL;\" % {\"varname\": varname}]\n\n    def GetDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, %s **);\" % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def AssignDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, const %s *);\"\n            % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def Declaration(self):\n        dcl = [\"ev_uint8_t %s_data[%s];\" % (self._name, self._length)]\n\n        return dcl\n\n    def CodeGet(self):\n        name = self._name\n        code = [\n            \"int\",\n            \"%s_%s_get(struct %s *msg, %s **value)\"\n            % (self._struct.Name(), name, self._struct.Name(), self._ctype),\n            \"{\",\n            \"  if (msg->%s_set != 1)\" % name,\n            \"    return (-1);\",\n            \"  *value = msg->%s_data;\" % name,\n            \"  return (0);\",\n            \"}\",\n        ]\n        return code\n\n    def CodeAssign(self):\n        name = self._name\n        code = [\n            \"int\",\n            \"%s_%s_assign(struct %s *msg, const %s *value)\"\n            % (self._struct.Name(), name, self._struct.Name(), self._ctype),\n            \"{\",\n            \"  msg->%s_set = 1;\" % name,\n            \"  memcpy(msg->%s_data, value, %s);\" % (name, self._length),\n            \"  return (0);\",\n            \"}\",\n        ]\n        return code\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, var_len):\n        code = [\n            \"if (evtag_unmarshal_fixed(%(buf)s, %(tag)s, \"\n            \"%(var)s, %(varlen)s) == -1) {\",\n            '  event_warnx(\"%%s: failed to unmarshal %(name)s\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n        return TranslateList(\n            code,\n            self.GetTranslation(\n                {\"var\": var_name, \"varlen\": var_len, \"buf\": buf, \"tag\": tag_name}\n            ),\n        )\n\n    @staticmethod\n    def CodeMarshal(buf, tag_name, var_name, var_len):\n        code = [\"evtag_marshal(%s, %s, %s, %s);\" % (buf, tag_name, var_name, var_len)]\n        return code\n\n    def CodeClear(self, structname):\n        code = [\n            \"%s->%s_set = 0;\" % (structname, self.Name()),\n            \"memset(%s->%s_data, 0, sizeof(%s->%s_data));\"\n            % (structname, self._name, structname, self._name),\n        ]\n\n        return code\n\n    def CodeInitialize(self, name):\n        code = [\n            \"memset(%s->%s_data, 0, sizeof(%s->%s_data));\"\n            % (name, self._name, name, self._name)\n        ]\n        return code\n\n    def Verify(self):\n        if not self._length:\n            raise RpcGenError(\n                'Entry \"%s\" needs a length '\n                \"around line %d\" % (self._name, self.LineCount())\n            )\n\n        super(EntryBytes, self).Verify()\n\n\nclass EntryInt(Entry):\n    def __init__(self, ent_type, name, tag, bits=32):\n        # Init base class\n        super(EntryInt, self).__init__(ent_type, name, tag)\n\n        self._can_be_array = True\n        if bits == 32:\n            self._ctype = \"ev_uint32_t\"\n            self._marshal_type = \"int\"\n        if bits == 64:\n            self._ctype = \"ev_uint64_t\"\n            self._marshal_type = \"int64\"\n\n    @staticmethod\n    def GetInitializer():\n        return \"0\"\n\n    @staticmethod\n    def CodeArrayFree(_var):\n        return []\n\n    @staticmethod\n    def CodeArrayAssign(varname, srcvar):\n        return [\"%(varname)s = %(srcvar)s;\" % {\"varname\": varname, \"srcvar\": srcvar}]\n\n    @staticmethod\n    def CodeArrayAdd(varname, value):\n        \"\"\"Returns a new entry of this type.\"\"\"\n        return [\"%(varname)s = %(value)s;\" % {\"varname\": varname, \"value\": value}]\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\n            \"if (evtag_unmarshal_%(ma)s(%(buf)s, %(tag)s, &%(var)s) == -1) {\",\n            '  event_warnx(\"%%s: failed to unmarshal %(name)s\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n        code = \"\\n\".join(code) % self.GetTranslation(\n            {\"ma\": self._marshal_type, \"buf\": buf, \"tag\": tag_name, \"var\": var_name}\n        )\n        return code.split(\"\\n\")\n\n    def CodeMarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\n            \"evtag_marshal_%s(%s, %s, %s);\"\n            % (self._marshal_type, buf, tag_name, var_name)\n        ]\n        return code\n\n    def Declaration(self):\n        dcl = [\"%s %s_data;\" % (self._ctype, self._name)]\n\n        return dcl\n\n    def CodeInitialize(self, name):\n        code = [\"%s->%s_data = 0;\" % (name, self._name)]\n        return code\n\n\nclass EntryString(Entry):\n    def __init__(self, ent_type, name, tag):\n        # Init base class\n        super(EntryString, self).__init__(ent_type, name, tag)\n\n        self._can_be_array = True\n        self._ctype = \"char *\"\n\n    @staticmethod\n    def GetInitializer():\n        return \"NULL\"\n\n    @staticmethod\n    def CodeArrayFree(varname):\n        code = [\"if (%(var)s != NULL) free(%(var)s);\"]\n\n        return TranslateList(code, {\"var\": varname})\n\n    @staticmethod\n    def CodeArrayAssign(varname, srcvar):\n        code = [\n            \"if (%(var)s != NULL)\",\n            \"  free(%(var)s);\",\n            \"%(var)s = strdup(%(srcvar)s);\",\n            \"if (%(var)s == NULL) {\",\n            '  event_warnx(\"%%s: strdup\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n\n        return TranslateList(code, {\"var\": varname, \"srcvar\": srcvar})\n\n    @staticmethod\n    def CodeArrayAdd(varname, value):\n        code = [\n            \"if (%(value)s != NULL) {\",\n            \"  %(var)s = strdup(%(value)s);\",\n            \"  if (%(var)s == NULL) {\",\n            \"    goto error;\",\n            \"  }\",\n            \"} else {\",\n            \"  %(var)s = NULL;\",\n            \"}\",\n        ]\n\n        return TranslateList(code, {\"var\": varname, \"value\": value})\n\n    def GetVarLen(self, var):\n        return \"strlen(%s)\" % self.GetVarName(var)\n\n    @staticmethod\n    def CodeMakeInitalize(varname):\n        return \"%(varname)s = NULL;\" % {\"varname\": varname}\n\n    def CodeAssign(self):\n        code = \"\"\"int\n%(parent_name)s_%(name)s_assign(struct %(parent_name)s *msg,\n    const %(ctype)s value)\n{\n  if (msg->%(name)s_data != NULL)\n    free(msg->%(name)s_data);\n  if ((msg->%(name)s_data = strdup(value)) == NULL)\n    return (-1);\n  msg->%(name)s_set = 1;\n  return (0);\n}\"\"\" % (\n            self.GetTranslation()\n        )\n\n        return code.split(\"\\n\")\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\n            \"if (evtag_unmarshal_string(%(buf)s, %(tag)s, &%(var)s) == -1) {\",\n            '  event_warnx(\"%%s: failed to unmarshal %(name)s\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n        code = \"\\n\".join(code) % self.GetTranslation(\n            {\"buf\": buf, \"tag\": tag_name, \"var\": var_name}\n        )\n        return code.split(\"\\n\")\n\n    @staticmethod\n    def CodeMarshal(buf, tag_name, var_name, _var_len):\n        code = [\"evtag_marshal_string(%s, %s, %s);\" % (buf, tag_name, var_name)]\n        return code\n\n    def CodeClear(self, structname):\n        code = [\n            \"if (%s->%s_set == 1) {\" % (structname, self.Name()),\n            \"  free(%s->%s_data);\" % (structname, self.Name()),\n            \"  %s->%s_data = NULL;\" % (structname, self.Name()),\n            \"  %s->%s_set = 0;\" % (structname, self.Name()),\n            \"}\",\n        ]\n\n        return code\n\n    def CodeInitialize(self, name):\n        code = [\"%s->%s_data = NULL;\" % (name, self._name)]\n        return code\n\n    def CodeFree(self, name):\n        code = [\n            \"if (%s->%s_data != NULL)\" % (name, self._name),\n            \"    free (%s->%s_data);\" % (name, self._name),\n        ]\n\n        return code\n\n    def Declaration(self):\n        dcl = [\"char *%s_data;\" % self._name]\n\n        return dcl\n\n\nclass EntryStruct(Entry):\n    def __init__(self, ent_type, name, tag, refname):\n        # Init base class\n        super(EntryStruct, self).__init__(ent_type, name, tag)\n\n        self._optpointer = False\n        self._can_be_array = True\n        self._refname = refname\n        self._ctype = \"struct %s*\" % refname\n        self._optaddarg = False\n\n    def GetInitializer(self):\n        return \"NULL\"\n\n    def GetVarLen(self, _var):\n        return \"-1\"\n\n    def CodeArrayAdd(self, varname, _value):\n        code = [\n            \"%(varname)s = %(refname)s_new();\",\n            \"if (%(varname)s == NULL)\",\n            \"  goto error;\",\n        ]\n\n        return TranslateList(code, self.GetTranslation({\"varname\": varname}))\n\n    def CodeArrayFree(self, var):\n        code = [\"%(refname)s_free(%(var)s);\" % self.GetTranslation({\"var\": var})]\n        return code\n\n    def CodeArrayAssign(self, var, srcvar):\n        code = [\n            \"int had_error = 0;\",\n            \"struct evbuffer *tmp = NULL;\",\n            \"%(refname)s_clear(%(var)s);\",\n            \"if ((tmp = evbuffer_new()) == NULL) {\",\n            '  event_warn(\"%%s: evbuffer_new()\", __func__);',\n            \"  had_error = 1;\",\n            \"  goto done;\",\n            \"}\",\n            \"%(refname)s_marshal(tmp, %(srcvar)s);\",\n            \"if (%(refname)s_unmarshal(%(var)s, tmp) == -1) {\",\n            '  event_warnx(\"%%s: %(refname)s_unmarshal\", __func__);',\n            \"  had_error = 1;\",\n            \"  goto done;\",\n            \"}\",\n            \"done:\",\n            \"if (tmp != NULL)\",\n            \"  evbuffer_free(tmp);\",\n            \"if (had_error) {\",\n            \"  %(refname)s_clear(%(var)s);\",\n            \"  return (-1);\",\n            \"}\",\n        ]\n\n        return TranslateList(code, self.GetTranslation({\"var\": var, \"srcvar\": srcvar}))\n\n    def CodeGet(self):\n        name = self._name\n        code = [\n            \"int\",\n            \"%s_%s_get(struct %s *msg, %s *value)\"\n            % (self._struct.Name(), name, self._struct.Name(), self._ctype),\n            \"{\",\n            \"  if (msg->%s_set != 1) {\" % name,\n            \"    msg->%s_data = %s_new();\" % (name, self._refname),\n            \"    if (msg->%s_data == NULL)\" % name,\n            \"      return (-1);\",\n            \"    msg->%s_set = 1;\" % name,\n            \"  }\",\n            \"  *value = msg->%s_data;\" % name,\n            \"  return (0);\",\n            \"}\",\n        ]\n        return code\n\n    def CodeAssign(self):\n        code = (\n            \"\"\"int\n%(parent_name)s_%(name)s_assign(struct %(parent_name)s *msg,\n    const %(ctype)s value)\n{\n   struct evbuffer *tmp = NULL;\n   if (msg->%(name)s_set) {\n     %(refname)s_clear(msg->%(name)s_data);\n     msg->%(name)s_set = 0;\n   } else {\n     msg->%(name)s_data = %(refname)s_new();\n     if (msg->%(name)s_data == NULL) {\n       event_warn(\"%%s: %(refname)s_new()\", __func__);\n       goto error;\n     }\n   }\n   if ((tmp = evbuffer_new()) == NULL) {\n     event_warn(\"%%s: evbuffer_new()\", __func__);\n     goto error;\n   }\n   %(refname)s_marshal(tmp, value);\n   if (%(refname)s_unmarshal(msg->%(name)s_data, tmp) == -1) {\n     event_warnx(\"%%s: %(refname)s_unmarshal\", __func__);\n     goto error;\n   }\n   msg->%(name)s_set = 1;\n   evbuffer_free(tmp);\n   return (0);\n error:\n   if (tmp != NULL)\n     evbuffer_free(tmp);\n   if (msg->%(name)s_data != NULL) {\n     %(refname)s_free(msg->%(name)s_data);\n     msg->%(name)s_data = NULL;\n   }\n   return (-1);\n}\"\"\"\n            % self.GetTranslation()\n        )\n        return code.split(\"\\n\")\n\n    def CodeComplete(self, structname, var_name):\n        code = [\n            \"if (%(structname)s->%(name)s_set && \"\n            \"%(refname)s_complete(%(var)s) == -1)\",\n            \"  return (-1);\",\n        ]\n\n        return TranslateList(\n            code, self.GetTranslation({\"structname\": structname, \"var\": var_name})\n        )\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\n            \"%(var)s = %(refname)s_new();\",\n            \"if (%(var)s == NULL)\",\n            \"  return (-1);\",\n            \"if (evtag_unmarshal_%(refname)s(%(buf)s, %(tag)s, \",\n            \"    %(var)s) == -1) {\",\n            '  event_warnx(\"%%s: failed to unmarshal %(name)s\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n        code = \"\\n\".join(code) % self.GetTranslation(\n            {\"buf\": buf, \"tag\": tag_name, \"var\": var_name}\n        )\n        return code.split(\"\\n\")\n\n    def CodeMarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\n            \"evtag_marshal_%s(%s, %s, %s);\" % (self._refname, buf, tag_name, var_name)\n        ]\n        return code\n\n    def CodeClear(self, structname):\n        code = [\n            \"if (%s->%s_set == 1) {\" % (structname, self.Name()),\n            \"  %s_free(%s->%s_data);\" % (self._refname, structname, self.Name()),\n            \"  %s->%s_data = NULL;\" % (structname, self.Name()),\n            \"  %s->%s_set = 0;\" % (structname, self.Name()),\n            \"}\",\n        ]\n\n        return code\n\n    def CodeInitialize(self, name):\n        code = [\"%s->%s_data = NULL;\" % (name, self._name)]\n        return code\n\n    def CodeFree(self, name):\n        code = [\n            \"if (%s->%s_data != NULL)\" % (name, self._name),\n            \"    %s_free(%s->%s_data);\" % (self._refname, name, self._name),\n        ]\n\n        return code\n\n    def Declaration(self):\n        dcl = [\"%s %s_data;\" % (self._ctype, self._name)]\n\n        return dcl\n\n\nclass EntryVarBytes(Entry):\n    def __init__(self, ent_type, name, tag):\n        # Init base class\n        super(EntryVarBytes, self).__init__(ent_type, name, tag)\n\n        self._ctype = \"ev_uint8_t *\"\n\n    @staticmethod\n    def GetInitializer():\n        return \"NULL\"\n\n    def GetVarLen(self, var):\n        return \"%(var)s->%(name)s_length\" % self.GetTranslation({\"var\": var})\n\n    @staticmethod\n    def CodeArrayAdd(varname, _value):\n        # xxx: copy\n        return [\"%(varname)s = NULL;\" % {\"varname\": varname}]\n\n    def GetDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, %s *, ev_uint32_t *);\"\n            % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def AssignDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, const %s, ev_uint32_t);\"\n            % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def CodeAssign(self):\n        name = self._name\n        code = [\n            \"int\",\n            \"%s_%s_assign(struct %s *msg, \"\n            \"const %s value, ev_uint32_t len)\"\n            % (self._struct.Name(), name, self._struct.Name(), self._ctype),\n            \"{\",\n            \"  if (msg->%s_data != NULL)\" % name,\n            \"    free (msg->%s_data);\" % name,\n            \"  msg->%s_data = malloc(len);\" % name,\n            \"  if (msg->%s_data == NULL)\" % name,\n            \"    return (-1);\",\n            \"  msg->%s_set = 1;\" % name,\n            \"  msg->%s_length = len;\" % name,\n            \"  memcpy(msg->%s_data, value, len);\" % name,\n            \"  return (0);\",\n            \"}\",\n        ]\n        return code\n\n    def CodeGet(self):\n        name = self._name\n        code = [\n            \"int\",\n            \"%s_%s_get(struct %s *msg, %s *value, ev_uint32_t *plen)\"\n            % (self._struct.Name(), name, self._struct.Name(), self._ctype),\n            \"{\",\n            \"  if (msg->%s_set != 1)\" % name,\n            \"    return (-1);\",\n            \"  *value = msg->%s_data;\" % name,\n            \"  *plen = msg->%s_length;\" % name,\n            \"  return (0);\",\n            \"}\",\n        ]\n        return code\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, var_len):\n        code = [\n            \"if (evtag_payload_length(%(buf)s, &%(varlen)s) == -1)\",\n            \"  return (-1);\",\n            # We do not want DoS opportunities\n            \"if (%(varlen)s > evbuffer_get_length(%(buf)s))\",\n            \"  return (-1);\",\n            \"if ((%(var)s = malloc(%(varlen)s)) == NULL)\",\n            \"  return (-1);\",\n            \"if (evtag_unmarshal_fixed(%(buf)s, %(tag)s, %(var)s, \"\n            \"%(varlen)s) == -1) {\",\n            '  event_warnx(\"%%s: failed to unmarshal %(name)s\", __func__);',\n            \"  return (-1);\",\n            \"}\",\n        ]\n        code = \"\\n\".join(code) % self.GetTranslation(\n            {\"buf\": buf, \"tag\": tag_name, \"var\": var_name, \"varlen\": var_len}\n        )\n        return code.split(\"\\n\")\n\n    @staticmethod\n    def CodeMarshal(buf, tag_name, var_name, var_len):\n        code = [\"evtag_marshal(%s, %s, %s, %s);\" % (buf, tag_name, var_name, var_len)]\n        return code\n\n    def CodeClear(self, structname):\n        code = [\n            \"if (%s->%s_set == 1) {\" % (structname, self.Name()),\n            \"  free (%s->%s_data);\" % (structname, self.Name()),\n            \"  %s->%s_data = NULL;\" % (structname, self.Name()),\n            \"  %s->%s_length = 0;\" % (structname, self.Name()),\n            \"  %s->%s_set = 0;\" % (structname, self.Name()),\n            \"}\",\n        ]\n\n        return code\n\n    def CodeInitialize(self, name):\n        code = [\n            \"%s->%s_data = NULL;\" % (name, self._name),\n            \"%s->%s_length = 0;\" % (name, self._name),\n        ]\n        return code\n\n    def CodeFree(self, name):\n        code = [\n            \"if (%s->%s_data != NULL)\" % (name, self._name),\n            \"    free(%s->%s_data);\" % (name, self._name),\n        ]\n\n        return code\n\n    def Declaration(self):\n        dcl = [\n            \"ev_uint8_t *%s_data;\" % self._name,\n            \"ev_uint32_t %s_length;\" % self._name,\n        ]\n\n        return dcl\n\n\nclass EntryArray(Entry):\n    _index = None\n\n    def __init__(self, entry):\n        # Init base class\n        super(EntryArray, self).__init__(entry._type, entry._name, entry._tag)\n\n        self._entry = entry\n        self._refname = entry._refname\n        self._ctype = self._entry._ctype\n        self._optional = True\n        self._optpointer = self._entry._optpointer\n        self._optaddarg = self._entry._optaddarg\n\n        # provide a new function for accessing the variable name\n        def GetVarName(var_name):\n            return \"%(var)s->%(name)s_data[%(index)s]\" % self._entry.GetTranslation(\n                {\"var\": var_name, \"index\": self._index}\n            )\n\n        self._entry.GetVarName = GetVarName\n\n    def GetInitializer(self):\n        return \"NULL\"\n\n    def GetVarName(self, var):\n        return var\n\n    def GetVarLen(self, _var_name):\n        return \"-1\"\n\n    def GetDeclaration(self, funcname):\n        \"\"\"Allows direct access to elements of the array.\"\"\"\n        code = [\n            \"int %(funcname)s(struct %(parent_name)s *, int, %(ctype)s *);\"\n            % self.GetTranslation({\"funcname\": funcname})\n        ]\n        return code\n\n    def AssignDeclaration(self, funcname):\n        code = [\n            \"int %s(struct %s *, int, const %s);\"\n            % (funcname, self._struct.Name(), self._ctype)\n        ]\n        return code\n\n    def AddDeclaration(self, funcname):\n        code = [\n            \"%(ctype)s %(optpointer)s \"\n            \"%(funcname)s(struct %(parent_name)s *msg%(optaddarg)s);\"\n            % self.GetTranslation({\"funcname\": funcname})\n        ]\n        return code\n\n    def CodeGet(self):\n        code = \"\"\"int\n%(parent_name)s_%(name)s_get(struct %(parent_name)s *msg, int offset,\n    %(ctype)s *value)\n{\n  if (!msg->%(name)s_set || offset < 0 || offset >= msg->%(name)s_length)\n    return (-1);\n  *value = msg->%(name)s_data[offset];\n  return (0);\n}\n\"\"\" % (\n            self.GetTranslation()\n        )\n\n        return code.splitlines()\n\n    def CodeAssign(self):\n        code = [\n            \"int\",\n            \"%(parent_name)s_%(name)s_assign(struct %(parent_name)s *msg, int off,\",\n            \"  const %(ctype)s value)\",\n            \"{\",\n            \"  if (!msg->%(name)s_set || off < 0 || off >= msg->%(name)s_length)\",\n            \"    return (-1);\",\n            \"\",\n            \"  {\",\n        ]\n        code = TranslateList(code, self.GetTranslation())\n\n        codearrayassign = self._entry.CodeArrayAssign(\n            \"msg->%(name)s_data[off]\" % self.GetTranslation(), \"value\"\n        )\n        code += [\"    \" + x for x in codearrayassign]\n\n        code += TranslateList([\"  }\", \"  return (0);\", \"}\"], self.GetTranslation())\n\n        return code\n\n    def CodeAdd(self):\n        codearrayadd = self._entry.CodeArrayAdd(\n            \"msg->%(name)s_data[msg->%(name)s_length - 1]\" % self.GetTranslation(),\n            \"value\",\n        )\n        code = [\n            \"static int\",\n            \"%(parent_name)s_%(name)s_expand_to_hold_more(\"\n            \"struct %(parent_name)s *msg)\",\n            \"{\",\n            \"  int tobe_allocated = msg->%(name)s_num_allocated;\",\n            \"  %(ctype)s* new_data = NULL;\",\n            \"  tobe_allocated = !tobe_allocated ? 1 : tobe_allocated << 1;\",\n            \"  new_data = (%(ctype)s*) realloc(msg->%(name)s_data,\",\n            \"      tobe_allocated * sizeof(%(ctype)s));\",\n            \"  if (new_data == NULL)\",\n            \"    return -1;\",\n            \"  msg->%(name)s_data = new_data;\",\n            \"  msg->%(name)s_num_allocated = tobe_allocated;\",\n            \"  return 0;\",\n            \"}\",\n            \"\",\n            \"%(ctype)s %(optpointer)s\",\n            \"%(parent_name)s_%(name)s_add(struct %(parent_name)s *msg%(optaddarg)s)\",\n            \"{\",\n            \"  if (++msg->%(name)s_length >= msg->%(name)s_num_allocated) {\",\n            \"    if (%(parent_name)s_%(name)s_expand_to_hold_more(msg)<0)\",\n            \"      goto error;\",\n            \"  }\",\n        ]\n\n        code = TranslateList(code, self.GetTranslation())\n\n        code += [\"  \" + x for x in codearrayadd]\n\n        code += TranslateList(\n            [\n                \"  msg->%(name)s_set = 1;\",\n                \"  return %(optreference)s(msg->%(name)s_data[\"\n                \"msg->%(name)s_length - 1]);\",\n                \"error:\",\n                \"  --msg->%(name)s_length;\",\n                \"  return (NULL);\",\n                \"}\",\n            ],\n            self.GetTranslation(),\n        )\n\n        return code\n\n    def CodeComplete(self, structname, var_name):\n        self._index = \"i\"\n        tmp = self._entry.CodeComplete(structname, self._entry.GetVarName(var_name))\n        # skip the whole loop if there is nothing to check\n        if not tmp:\n            return []\n\n        translate = self.GetTranslation({\"structname\": structname})\n        code = [\n            \"{\",\n            \"  int i;\",\n            \"  for (i = 0; i < %(structname)s->%(name)s_length; ++i) {\",\n        ]\n\n        code = TranslateList(code, translate)\n\n        code += [\"    \" + x for x in tmp]\n\n        code += [\"  }\", \"}\"]\n\n        return code\n\n    def CodeUnmarshal(self, buf, tag_name, var_name, _var_len):\n        translate = self.GetTranslation(\n            {\n                \"var\": var_name,\n                \"buf\": buf,\n                \"tag\": tag_name,\n                \"init\": self._entry.GetInitializer(),\n            }\n        )\n        code = [\n            \"if (%(var)s->%(name)s_length >= %(var)s->%(name)s_num_allocated &&\",\n            \"    %(parent_name)s_%(name)s_expand_to_hold_more(%(var)s) < 0) {\",\n            '  puts(\"HEY NOW\");',\n            \"  return (-1);\",\n            \"}\",\n        ]\n\n        # the unmarshal code directly returns\n        code = TranslateList(code, translate)\n\n        self._index = \"%(var)s->%(name)s_length\" % translate\n        code += self._entry.CodeUnmarshal(\n            buf,\n            tag_name,\n            self._entry.GetVarName(var_name),\n            self._entry.GetVarLen(var_name),\n        )\n\n        code += [\"++%(var)s->%(name)s_length;\" % translate]\n\n        return code\n\n    def CodeMarshal(self, buf, tag_name, var_name, _var_len):\n        code = [\"{\", \"  int i;\", \"  for (i = 0; i < %(var)s->%(name)s_length; ++i) {\"]\n\n        self._index = \"i\"\n        code += self._entry.CodeMarshal(\n            buf,\n            tag_name,\n            self._entry.GetVarName(var_name),\n            self._entry.GetVarLen(var_name),\n        )\n        code += [\"  }\", \"}\"]\n\n        code = \"\\n\".join(code) % self.GetTranslation({\"var\": var_name})\n\n        return code.split(\"\\n\")\n\n    def CodeClear(self, structname):\n        translate = self.GetTranslation({\"structname\": structname})\n        codearrayfree = self._entry.CodeArrayFree(\n            \"%(structname)s->%(name)s_data[i]\"\n            % self.GetTranslation({\"structname\": structname})\n        )\n\n        code = [\"if (%(structname)s->%(name)s_set == 1) {\"]\n\n        if codearrayfree:\n            code += [\n                \"  int i;\",\n                \"  for (i = 0; i < %(structname)s->%(name)s_length; ++i) {\",\n            ]\n\n        code = TranslateList(code, translate)\n\n        if codearrayfree:\n            code += [\"    \" + x for x in codearrayfree]\n            code += [\"  }\"]\n\n        code += TranslateList(\n            [\n                \"  free(%(structname)s->%(name)s_data);\",\n                \"  %(structname)s->%(name)s_data = NULL;\",\n                \"  %(structname)s->%(name)s_set = 0;\",\n                \"  %(structname)s->%(name)s_length = 0;\",\n                \"  %(structname)s->%(name)s_num_allocated = 0;\",\n                \"}\",\n            ],\n            translate,\n        )\n\n        return code\n\n    def CodeInitialize(self, name):\n        code = [\n            \"%s->%s_data = NULL;\" % (name, self._name),\n            \"%s->%s_length = 0;\" % (name, self._name),\n            \"%s->%s_num_allocated = 0;\" % (name, self._name),\n        ]\n        return code\n\n    def CodeFree(self, structname):\n        code = self.CodeClear(structname)\n\n        code += TranslateList(\n            [\"free(%(structname)s->%(name)s_data);\"],\n            self.GetTranslation({\"structname\": structname}),\n        )\n\n        return code\n\n    def Declaration(self):\n        dcl = [\n            \"%s *%s_data;\" % (self._ctype, self._name),\n            \"int %s_length;\" % self._name,\n            \"int %s_num_allocated;\" % self._name,\n        ]\n\n        return dcl\n\n\ndef NormalizeLine(line):\n\n    line = CPPCOMMENT_RE.sub(\"\", line)\n    line = line.strip()\n    line = WHITESPACE_RE.sub(\" \", line)\n\n    return line\n\n\nENTRY_NAME_RE = re.compile(r\"(?P<name>[^\\[\\]]+)(\\[(?P<fixed_length>.*)\\])?\")\nENTRY_TAG_NUMBER_RE = re.compile(r\"(0x)?\\d+\", re.I)\n\n\ndef ProcessOneEntry(factory, newstruct, entry):\n    optional = False\n    array = False\n    entry_type = \"\"\n    name = \"\"\n    tag = \"\"\n    tag_set = None\n    separator = \"\"\n    fixed_length = \"\"\n\n    for token in entry.split(\" \"):\n        if not entry_type:\n            if not optional and token == \"optional\":\n                optional = True\n                continue\n\n            if not array and token == \"array\":\n                array = True\n                continue\n\n        if not entry_type:\n            entry_type = token\n            continue\n\n        if not name:\n            res = ENTRY_NAME_RE.match(token)\n            if not res:\n                raise RpcGenError(\n                    r\"\"\"Cannot parse name: \"%s\" around line %d\"\"\" % (entry, LINE_COUNT)\n                )\n            name = res.group(\"name\")\n            fixed_length = res.group(\"fixed_length\")\n            continue\n\n        if not separator:\n            separator = token\n            if separator != \"=\":\n                raise RpcGenError(\n                    r'''Expected \"=\" after name \"%s\" got \"%s\"''' % (name, token)\n                )\n            continue\n\n        if not tag_set:\n            tag_set = 1\n            if not ENTRY_TAG_NUMBER_RE.match(token):\n                raise RpcGenError(r'''Expected tag number: \"%s\"''' % (entry))\n            tag = int(token, 0)\n            continue\n\n        raise RpcGenError(r'''Cannot parse \"%s\"''' % (entry))\n\n    if not tag_set:\n        raise RpcGenError(r'''Need tag number: \"%s\"''' % (entry))\n\n    # Create the right entry\n    if entry_type == \"bytes\":\n        if fixed_length:\n            newentry = factory.EntryBytes(entry_type, name, tag, fixed_length)\n        else:\n            newentry = factory.EntryVarBytes(entry_type, name, tag)\n    elif entry_type == \"int\" and not fixed_length:\n        newentry = factory.EntryInt(entry_type, name, tag)\n    elif entry_type == \"int64\" and not fixed_length:\n        newentry = factory.EntryInt(entry_type, name, tag, bits=64)\n    elif entry_type == \"string\" and not fixed_length:\n        newentry = factory.EntryString(entry_type, name, tag)\n    else:\n        res = STRUCT_REF_RE.match(entry_type)\n        if res:\n            # References another struct defined in our file\n            newentry = factory.EntryStruct(entry_type, name, tag, res.group(\"name\"))\n        else:\n            raise RpcGenError('Bad type: \"%s\" in \"%s\"' % (entry_type, entry))\n\n    structs = []\n\n    if optional:\n        newentry.MakeOptional()\n    if array:\n        newentry.MakeArray()\n\n    newentry.SetStruct(newstruct)\n    newentry.SetLineCount(LINE_COUNT)\n    newentry.Verify()\n\n    if array:\n        # We need to encapsulate this entry into a struct\n        newentry = factory.EntryArray(newentry)\n        newentry.SetStruct(newstruct)\n        newentry.SetLineCount(LINE_COUNT)\n        newentry.MakeArray()\n\n    newstruct.AddEntry(newentry)\n\n    return structs\n\n\ndef ProcessStruct(factory, data):\n    tokens = data.split(\" \")\n\n    # First three tokens are: 'struct' 'name' '{'\n    newstruct = factory.Struct(tokens[1])\n\n    inside = \" \".join(tokens[3:-1])\n\n    tokens = inside.split(\";\")\n\n    structs = []\n\n    for entry in tokens:\n        entry = NormalizeLine(entry)\n        if not entry:\n            continue\n\n        # It's possible that new structs get defined in here\n        structs.extend(ProcessOneEntry(factory, newstruct, entry))\n\n    structs.append(newstruct)\n    return structs\n\n\nC_COMMENT_START = \"/*\"\nC_COMMENT_END = \"*/\"\n\nC_COMMENT_START_RE = re.compile(re.escape(C_COMMENT_START))\nC_COMMENT_END_RE = re.compile(re.escape(C_COMMENT_END))\n\nC_COMMENT_START_SUB_RE = re.compile(r\"%s.*$\" % (re.escape(C_COMMENT_START)))\nC_COMMENT_END_SUB_RE = re.compile(r\"%s.*$\" % (re.escape(C_COMMENT_END)))\n\nC_MULTILINE_COMMENT_SUB_RE = re.compile(\n    r\"%s.*?%s\" % (re.escape(C_COMMENT_START), re.escape(C_COMMENT_END))\n)\nCPP_CONDITIONAL_BLOCK_RE = re.compile(r\"#(if( |def)|endif)\")\nINCLUDE_RE = re.compile(r'#include (\".+\"|<.+>)')\n\n\ndef GetNextStruct(filep):\n    global CPP_DIRECT\n    global LINE_COUNT\n\n    got_struct = False\n    have_c_comment = False\n\n    data = \"\"\n\n    while True:\n        line = filep.readline()\n        if not line:\n            break\n\n        LINE_COUNT += 1\n        line = line[:-1]\n\n        if not have_c_comment and C_COMMENT_START_RE.search(line):\n            if C_MULTILINE_COMMENT_SUB_RE.search(line):\n                line = C_MULTILINE_COMMENT_SUB_RE.sub(\"\", line)\n            else:\n                line = C_COMMENT_START_SUB_RE.sub(\"\", line)\n                have_c_comment = True\n\n        if have_c_comment:\n            if not C_COMMENT_END_RE.search(line):\n                continue\n            have_c_comment = False\n            line = C_COMMENT_END_SUB_RE.sub(\"\", line)\n\n        line = NormalizeLine(line)\n\n        if not line:\n            continue\n\n        if not got_struct:\n            if INCLUDE_RE.match(line):\n                CPP_DIRECT.append(line)\n            elif CPP_CONDITIONAL_BLOCK_RE.match(line):\n                CPP_DIRECT.append(line)\n            elif PREPROCESSOR_DEF_RE.match(line):\n                HEADER_DIRECT.append(line)\n            elif not STRUCT_DEF_RE.match(line):\n                raise RpcGenError(\"Missing struct on line %d: %s\" % (LINE_COUNT, line))\n            else:\n                got_struct = True\n                data += line\n            continue\n\n        # We are inside the struct\n        tokens = line.split(\"}\")\n        if len(tokens) == 1:\n            data += \" \" + line\n            continue\n\n        if tokens[1]:\n            raise RpcGenError(\"Trailing garbage after struct on line %d\" % LINE_COUNT)\n\n        # We found the end of the struct\n        data += \" %s}\" % tokens[0]\n        break\n\n    # Remove any comments, that might be in there\n    data = re.sub(r\"/\\*.*\\*/\", \"\", data)\n\n    return data\n\n\ndef Parse(factory, filep):\n    \"\"\"\n    Parses the input file and returns C code and corresponding header file.\n    \"\"\"\n\n    entities = []\n\n    while 1:\n        # Just gets the whole struct nicely formatted\n        data = GetNextStruct(filep)\n\n        if not data:\n            break\n\n        entities.extend(ProcessStruct(factory, data))\n\n    return entities\n\n\nclass CCodeGenerator(object):\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def GuardName(name):\n        # Use the complete provided path to the input file, with all\n        # non-identifier characters replaced with underscores, to\n        # reduce the chance of a collision between guard macros.\n        return \"EVENT_RPCOUT_%s_\" % (NONIDENT_RE.sub(\"_\", name).upper())\n\n    def HeaderPreamble(self, name):\n        guard = self.GuardName(name)\n        pre = \"\"\"\n/*\n * Automatically generated from %s\n */\n\n#ifndef %s\n#define %s\n\n\"\"\" % (\n            name,\n            guard,\n            guard,\n        )\n\n        if HEADER_DIRECT:\n            for statement in HEADER_DIRECT:\n                pre += \"%s\\n\" % statement\n            pre += \"\\n\"\n\n        pre += \"\"\"\n#include <event2/util.h> /* for ev_uint*_t */\n#include <event2/rpc.h>\n\"\"\"\n\n        return pre\n\n    def HeaderPostamble(self, name):\n        guard = self.GuardName(name)\n        return \"#endif  /* %s */\" % (guard)\n\n    @staticmethod\n    def BodyPreamble(name, header_file):\n        global _NAME\n        global _VERSION\n\n        slash = header_file.rfind(\"/\")\n        if slash != -1:\n            header_file = header_file[slash + 1 :]\n\n        pre = \"\"\"\n/*\n * Automatically generated from %(name)s\n * by %(script_name)s/%(script_version)s.  DO NOT EDIT THIS FILE.\n */\n\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <event2/event-config.h>\n#include <event2/event.h>\n#include <event2/buffer.h>\n#include <event2/tag.h>\n\n#if defined(EVENT__HAVE___func__)\n# ifndef __func__\n#  define __func__ __func__\n# endif\n#elif defined(EVENT__HAVE___FUNCTION__)\n# define __func__ __FUNCTION__\n#else\n# define __func__ __FILE__\n#endif\n\n\"\"\" % {\n            \"name\": name,\n            \"script_name\": _NAME,\n            \"script_version\": _VERSION,\n        }\n\n        for statement in CPP_DIRECT:\n            pre += \"%s\\n\" % statement\n\n        pre += '\\n#include \"%s\"\\n\\n' % header_file\n\n        pre += \"void event_warn(const char *fmt, ...);\\n\"\n        pre += \"void event_warnx(const char *fmt, ...);\\n\\n\"\n\n        return pre\n\n    @staticmethod\n    def HeaderFilename(filename):\n        return \".\".join(filename.split(\".\")[:-1]) + \".h\"\n\n    @staticmethod\n    def CodeFilename(filename):\n        return \".\".join(filename.split(\".\")[:-1]) + \".gen.c\"\n\n    @staticmethod\n    def Struct(name):\n        return StructCCode(name)\n\n    @staticmethod\n    def EntryBytes(entry_type, name, tag, fixed_length):\n        return EntryBytes(entry_type, name, tag, fixed_length)\n\n    @staticmethod\n    def EntryVarBytes(entry_type, name, tag):\n        return EntryVarBytes(entry_type, name, tag)\n\n    @staticmethod\n    def EntryInt(entry_type, name, tag, bits=32):\n        return EntryInt(entry_type, name, tag, bits)\n\n    @staticmethod\n    def EntryString(entry_type, name, tag):\n        return EntryString(entry_type, name, tag)\n\n    @staticmethod\n    def EntryStruct(entry_type, name, tag, struct_name):\n        return EntryStruct(entry_type, name, tag, struct_name)\n\n    @staticmethod\n    def EntryArray(entry):\n        return EntryArray(entry)\n\n\nclass CommandLine(object):\n    def __init__(self, argv=None):\n        \"\"\"Initialize a command-line to launch event_rpcgen, as if\n           from a command-line with CommandLine(sys.argv).  If you're\n           calling this directly, remember to provide a dummy value\n           for sys.argv[0]\n        \"\"\"\n        global QUIETLY\n\n        self.filename = None\n        self.header_file = None\n        self.impl_file = None\n        self.factory = CCodeGenerator()\n\n        parser = argparse.ArgumentParser(\n            usage=\"%(prog)s [options] rpc-file [[h-file] c-file]\"\n        )\n        parser.add_argument(\"--quiet\", action=\"store_true\", default=False)\n        parser.add_argument(\"rpc_file\", type=argparse.FileType(\"r\"))\n\n        args, extra_args = parser.parse_known_args(args=argv)\n\n        QUIETLY = args.quiet\n\n        if extra_args:\n            if len(extra_args) == 1:\n                self.impl_file = extra_args[0].replace(\"\\\\\", \"/\")\n            elif len(extra_args) == 2:\n                self.header_file = extra_args[0].replace(\"\\\\\", \"/\")\n                self.impl_file = extra_args[1].replace(\"\\\\\", \"/\")\n            else:\n                parser.error(\"Spurious arguments provided\")\n\n        self.rpc_file = args.rpc_file\n\n        if not self.impl_file:\n            self.impl_file = self.factory.CodeFilename(self.rpc_file.name)\n\n        if not self.header_file:\n            self.header_file = self.factory.HeaderFilename(self.impl_file)\n\n        if not self.impl_file.endswith(\".c\"):\n            parser.error(\"can only generate C implementation files\")\n        if not self.header_file.endswith(\".h\"):\n            parser.error(\"can only generate C header files\")\n\n    def run(self):\n        filename = self.rpc_file.name\n        header_file = self.header_file\n        impl_file = self.impl_file\n        factory = self.factory\n\n        declare('Reading \"%s\"' % filename)\n\n        with self.rpc_file:\n            entities = Parse(factory, self.rpc_file)\n\n        declare('... creating \"%s\"' % header_file)\n        with open(header_file, \"w\") as header_fp:\n            header_fp.write(factory.HeaderPreamble(filename))\n\n            # Create forward declarations: allows other structs to reference\n            # each other\n            for entry in entities:\n                entry.PrintForwardDeclaration(header_fp)\n            header_fp.write(\"\\n\")\n\n            for entry in entities:\n                entry.PrintTags(header_fp)\n                entry.PrintDeclaration(header_fp)\n            header_fp.write(factory.HeaderPostamble(filename))\n\n        declare('... creating \"%s\"' % impl_file)\n        with open(impl_file, \"w\") as impl_fp:\n            impl_fp.write(factory.BodyPreamble(filename, header_file))\n            for entry in entities:\n                entry.PrintCode(impl_fp)\n\n\ndef main(argv=None):\n    try:\n        CommandLine(argv=argv).run()\n        return 0\n    except RpcGenError as e:\n        sys.stderr.write(e)\n    except EnvironmentError as e:\n        if e.filename and e.strerror:\n            sys.stderr.write(\"%s: %s\" % (e.filename, e.strerror))\n        elif e.strerror:\n            sys.stderr.write(e.strerror)\n        else:\n            raise\n    return 1\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(argv=sys.argv[1:]))\n"
        },
        {
          "name": "event_tagging.c",
          "type": "blob",
          "size": 14.384765625,
          "content": "/*\n * Copyright (c) 2003-2009 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n#ifdef EVENT__HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n\n#ifdef _WIN32\n#define WIN32_LEAN_AND_MEAN\n#include <winsock2.h>\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n\n#ifdef EVENT__HAVE_SYS_IOCTL_H\n#include <sys/ioctl.h>\n#endif\n#include <sys/queue.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifndef _WIN32\n#include <syslog.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#include <limits.h>\n\n#include \"event2/event.h\"\n#include \"event2/tag.h\"\n#include \"event2/buffer.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n\n/*\n  Here's our wire format:\n\n  Stream = TaggedData*\n\n  TaggedData = Tag Length Data\n       where the integer value of 'Length' is the length of 'data'.\n\n  Tag = HByte* LByte\n       where HByte is a byte with the high bit set, and LByte is a byte\n       with the high bit clear. The integer value of the tag is taken\n       by concatenating the lower 7 bits from all the tags.  So for example,\n       the tag 0x66 is encoded as [66], whereas the tag 0x166 is encoded as\n       [82 66]\n\n  Length = Integer\n\n  Integer = NNibbles Nibble* Padding?\n       where NNibbles is a 4-bit value encoding the number of nibbles-1,\n       and each Nibble is 4 bits worth of encoded integer, in big-endian\n       order.  If the total encoded integer size is an odd number of nibbles,\n       a final padding nibble with value 0 is appended.\n*/\n\nEVENT2_EXPORT_SYMBOL\nint evtag_decode_int(ev_uint32_t *pnumber, struct evbuffer *evbuf);\nEVENT2_EXPORT_SYMBOL\nint evtag_decode_int64(ev_uint64_t *pnumber, struct evbuffer *evbuf);\nEVENT2_EXPORT_SYMBOL\nint evtag_encode_tag(struct evbuffer *evbuf, ev_uint32_t tag);\nEVENT2_EXPORT_SYMBOL\nint evtag_decode_tag(ev_uint32_t *ptag, struct evbuffer *evbuf);\n\nvoid\nevtag_init(void)\n{\n}\n\n/*\n * We encode integers by nibbles; the first nibble contains the number\n * of significant nibbles - 1;  this allows us to encode up to 64-bit\n * integers.  This function is byte-order independent.\n *\n * @param number a 32-bit unsigned integer to encode\n * @param data a pointer to where the data should be written.  Must\n *    have at least 5 bytes free.\n * @return the number of bytes written into data.\n */\n\n#define ENCODE_INT_INTERNAL(data, number) do {\t\t\t\t\\\n\tint off = 1, nibbles = 0;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tmemset(data, 0, sizeof(number)+1);\t\t\t\t\\\n\twhile (number) {\t\t\t\t\t\t\\\n\t\tif (off & 0x1)\t\t\t\t\t\t\\\n\t\t\tdata[off/2] = (data[off/2] & 0xf0) | (number & 0x0f); \\\n\t\telse\t\t\t\t\t\t\t\\\n\t\t\tdata[off/2] = (data[off/2] & 0x0f) |\t\t\\\n\t\t\t    ((number & 0x0f) << 4);\t\t\t\\\n\t\tnumber >>= 4;\t\t\t\t\t\t\\\n\t\toff++;\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (off > 2)\t\t\t\t\t\t\t\\\n\t\tnibbles = off - 2;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t/* Off - 1 is the number of encoded nibbles */\t\t\t\\\n\tdata[0] = (data[0] & 0x0f) | ((nibbles & 0x0f) << 4);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn ((off + 1) / 2);\t\t\t\t\t\t\\\n} while (0)\n\nstatic inline int\nencode_int_internal(ev_uint8_t *data, ev_uint32_t number)\n{\n\tENCODE_INT_INTERNAL(data, number);\n}\n\nstatic inline int\nencode_int64_internal(ev_uint8_t *data, ev_uint64_t number)\n{\n\tENCODE_INT_INTERNAL(data, number);\n}\n\nvoid\nevtag_encode_int(struct evbuffer *evbuf, ev_uint32_t number)\n{\n\tev_uint8_t data[5];\n\tint len = encode_int_internal(data, number);\n\tevbuffer_add(evbuf, data, len);\n}\n\nvoid\nevtag_encode_int64(struct evbuffer *evbuf, ev_uint64_t number)\n{\n\tev_uint8_t data[9];\n\tint len = encode_int64_internal(data, number);\n\tevbuffer_add(evbuf, data, len);\n}\n\n/*\n * Support variable length encoding of tags; we use the high bit in each\n * octet as a continuation signal.\n */\n\nint\nevtag_encode_tag(struct evbuffer *evbuf, ev_uint32_t tag)\n{\n\tint bytes = 0;\n\tev_uint8_t data[5];\n\n\tmemset(data, 0, sizeof(data));\n\tdo {\n\t\tev_uint8_t lower = tag & 0x7f;\n\t\ttag >>= 7;\n\n\t\tif (tag)\n\t\t\tlower |= 0x80;\n\n\t\tdata[bytes++] = lower;\n\t} while (tag);\n\n\tif (evbuf != NULL)\n\t\tevbuffer_add(evbuf, data, bytes);\n\n\treturn (bytes);\n}\n\nstatic int\ndecode_tag_internal(ev_uint32_t *ptag, struct evbuffer *evbuf, int dodrain)\n{\n\tev_uint32_t number = 0;\n\tsize_t len = evbuffer_get_length(evbuf);\n\tev_uint8_t *data;\n\tsize_t count = 0;\n\tint  shift = 0, done = 0;\n\n\t/*\n\t * the encoding of a number is at most one byte more than its\n\t * storage size.  however, it may also be much smaller.\n\t */\n\tdata = evbuffer_pullup(\n\t\tevbuf, len < sizeof(number) + 1 ? len : sizeof(number) + 1);\n\tif (!data)\n\t\treturn (-1);\n\n\twhile (count++ < len) {\n\t\tev_uint8_t lower = *data++;\n\t\tif (shift >= 28) {\n\t\t\t/* Make sure it fits into 32 bits */\n\t\t\tif (shift > 28)\n\t\t\t\treturn (-1);\n\t\t\tif ((lower & 0x7f) > 15)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tnumber |= (lower & (unsigned)0x7f) << shift;\n\t\tshift += 7;\n\n\t\tif (!(lower & 0x80)) {\n\t\t\tdone = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!done)\n\t\treturn (-1);\n\n\tif (dodrain)\n\t\tevbuffer_drain(evbuf, count);\n\n\tif (ptag != NULL)\n\t\t*ptag = number;\n\n\treturn count > INT_MAX ? INT_MAX : (int)(count);\n}\n\nint\nevtag_decode_tag(ev_uint32_t *ptag, struct evbuffer *evbuf)\n{\n\treturn (decode_tag_internal(ptag, evbuf, 1 /* dodrain */));\n}\n\n/*\n * Marshal a data type, the general format is as follows:\n *\n * tag number: one byte; length: var bytes; payload: var bytes\n */\n\nvoid\nevtag_marshal(struct evbuffer *evbuf, ev_uint32_t tag,\n    const void *data, ev_uint32_t len)\n{\n\tevtag_encode_tag(evbuf, tag);\n\tevtag_encode_int(evbuf, len);\n\tevbuffer_add(evbuf, (void *)data, len);\n}\n\nvoid\nevtag_marshal_buffer(struct evbuffer *evbuf, ev_uint32_t tag,\n    struct evbuffer *data)\n{\n\tevtag_encode_tag(evbuf, tag);\n\t/* XXX support more than UINT32_MAX data */\n\tevtag_encode_int(evbuf, (ev_uint32_t)evbuffer_get_length(data));\n\tevbuffer_add_buffer(evbuf, data);\n}\n\n/* Marshaling for integers */\nvoid\nevtag_marshal_int(struct evbuffer *evbuf, ev_uint32_t tag, ev_uint32_t integer)\n{\n\tev_uint8_t data[5];\n\tint len = encode_int_internal(data, integer);\n\n\tevtag_encode_tag(evbuf, tag);\n\tevtag_encode_int(evbuf, len);\n\tevbuffer_add(evbuf, data, len);\n}\n\nvoid\nevtag_marshal_int64(struct evbuffer *evbuf, ev_uint32_t tag,\n    ev_uint64_t integer)\n{\n\tev_uint8_t data[9];\n\tint len = encode_int64_internal(data, integer);\n\n\tevtag_encode_tag(evbuf, tag);\n\tevtag_encode_int(evbuf, len);\n\tevbuffer_add(evbuf, data, len);\n}\n\nvoid\nevtag_marshal_string(struct evbuffer *buf, ev_uint32_t tag, const char *string)\n{\n\t/* TODO support strings longer than UINT32_MAX ? */\n\tevtag_marshal(buf, tag, string, (ev_uint32_t)strlen(string));\n}\n\nvoid\nevtag_marshal_timeval(struct evbuffer *evbuf, ev_uint32_t tag, struct timeval *tv)\n{\n\tev_uint8_t data[10];\n\tint len = encode_int_internal(data, tv->tv_sec);\n\tlen += encode_int_internal(data + len, tv->tv_usec);\n\tevtag_marshal(evbuf, tag, data, len);\n}\n\n#define DECODE_INT_INTERNAL(number, maxnibbles, pnumber, evbuf, offset) \\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tev_uint8_t *data;\t\t\t\t\t\t\\\n\tev_ssize_t len = evbuffer_get_length(evbuf) - offset;\t\t\\\n\tint nibbles = 0;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (len <= 0)\t\t\t\t\t\t\t\\\n\t\treturn (-1);\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t/* XXX(niels): faster? */\t\t\t\t\t\\\n\tdata = evbuffer_pullup(evbuf, offset + 1) + offset;\t\t\\\n\tif (!data)\t\t\t\t\t\t\t\\\n\t\treturn (-1);\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tnibbles = ((data[0] & 0xf0) >> 4) + 1;\t\t\t\t\\\n\tif (nibbles > maxnibbles || (nibbles >> 1) + 1 > len)\t\t\\\n\t\treturn (-1);\t\t\t\t\t\t\\\n\tlen = (nibbles >> 1) + 1;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tdata = evbuffer_pullup(evbuf, offset + len) + offset;\t\t\\\n\tif (!data)\t\t\t\t\t\t\t\\\n\t\treturn (-1);\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\twhile (nibbles > 0) {\t\t\t\t\t\t\\\n\t\tnumber <<= 4;\t\t\t\t\t\t\\\n\t\tif (nibbles & 0x1)\t\t\t\t\t\\\n\t\t\tnumber |= data[nibbles >> 1] & 0x0f;\t\t\\\n\t\telse\t\t\t\t\t\t\t\\\n\t\t\tnumber |= (data[nibbles >> 1] & 0xf0) >> 4;\t\\\n\t\tnibbles--;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t*pnumber = number;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn (int)(len);\t\t\t\t\t\t\\\n} while (0)\n\n/* Internal: decode an integer from an evbuffer, without draining it.\n *  Only integers up to 32-bits are supported.\n *\n * @param evbuf the buffer to read from\n * @param offset an index into the buffer at which we should start reading.\n * @param pnumber a pointer to receive the integer.\n * @return The length of the number as encoded, or -1 on error.\n */\n\nstatic int\ndecode_int_internal(ev_uint32_t *pnumber, struct evbuffer *evbuf, int offset)\n{\n\tev_uint32_t number = 0;\n\tDECODE_INT_INTERNAL(number, 8, pnumber, evbuf, offset);\n}\n\nstatic int\ndecode_int64_internal(ev_uint64_t *pnumber, struct evbuffer *evbuf, int offset)\n{\n\tev_uint64_t number = 0;\n\tDECODE_INT_INTERNAL(number, 16, pnumber, evbuf, offset);\n}\n\nint\nevtag_decode_int(ev_uint32_t *pnumber, struct evbuffer *evbuf)\n{\n\tint res = decode_int_internal(pnumber, evbuf, 0);\n\tif (res != -1)\n\t\tevbuffer_drain(evbuf, res);\n\n\treturn (res == -1 ? -1 : 0);\n}\n\nint\nevtag_decode_int64(ev_uint64_t *pnumber, struct evbuffer *evbuf)\n{\n\tint res = decode_int64_internal(pnumber, evbuf, 0);\n\tif (res != -1)\n\t\tevbuffer_drain(evbuf, res);\n\n\treturn (res == -1 ? -1 : 0);\n}\n\nint\nevtag_peek(struct evbuffer *evbuf, ev_uint32_t *ptag)\n{\n\treturn (decode_tag_internal(ptag, evbuf, 0 /* dodrain */));\n}\n\nint\nevtag_peek_length(struct evbuffer *evbuf, ev_uint32_t *plength)\n{\n\tint res, len;\n\n\tlen = decode_tag_internal(NULL, evbuf, 0 /* dodrain */);\n\tif (len == -1)\n\t\treturn (-1);\n\n\tres = decode_int_internal(plength, evbuf, len);\n\tif (res == -1)\n\t\treturn (-1);\n\n\t*plength += res + len;\n\n\treturn (0);\n}\n\nint\nevtag_payload_length(struct evbuffer *evbuf, ev_uint32_t *plength)\n{\n\tint res, len;\n\n\tlen = decode_tag_internal(NULL, evbuf, 0 /* dodrain */);\n\tif (len == -1)\n\t\treturn (-1);\n\n\tres = decode_int_internal(plength, evbuf, len);\n\tif (res == -1)\n\t\treturn (-1);\n\n\treturn (0);\n}\n\n/* just unmarshals the header and returns the length of the remaining data */\n\nint\nevtag_unmarshal_header(struct evbuffer *evbuf, ev_uint32_t *ptag)\n{\n\tev_uint32_t len;\n\n\tif (decode_tag_internal(ptag, evbuf, 1 /* dodrain */) == -1)\n\t\treturn (-1);\n\tif (evtag_decode_int(&len, evbuf) == -1)\n\t\treturn (-1);\n\n\tif (evbuffer_get_length(evbuf) < len)\n\t\treturn (-1);\n\n\treturn (len);\n}\n\nint\nevtag_consume(struct evbuffer *evbuf)\n{\n\tint len;\n\tif ((len = evtag_unmarshal_header(evbuf, NULL)) == -1)\n\t\treturn (-1);\n\tevbuffer_drain(evbuf, len);\n\n\treturn (0);\n}\n\n/* Reads the data type from an event buffer */\n\nint\nevtag_unmarshal(struct evbuffer *src, ev_uint32_t *ptag, struct evbuffer *dst)\n{\n\tint len;\n\n\tif ((len = evtag_unmarshal_header(src, ptag)) == -1)\n\t\treturn (-1);\n\n\tif (evbuffer_add(dst, evbuffer_pullup(src, len), len) == -1)\n\t\treturn (-1);\n\n\tevbuffer_drain(src, len);\n\n\treturn (len);\n}\n\n/* Marshaling for integers */\n\nint\nevtag_unmarshal_int(struct evbuffer *evbuf, ev_uint32_t need_tag,\n    ev_uint32_t *pinteger)\n{\n\tev_uint32_t tag;\n\tev_uint32_t len;\n\tint result;\n\n\tif (decode_tag_internal(&tag, evbuf, 1 /* dodrain */) == -1)\n\t\treturn (-1);\n\tif (need_tag != tag)\n\t\treturn (-1);\n\tif (evtag_decode_int(&len, evbuf) == -1)\n\t\treturn (-1);\n\n\tif (evbuffer_get_length(evbuf) < len)\n\t\treturn (-1);\n\n\tresult = decode_int_internal(pinteger, evbuf, 0);\n\tevbuffer_drain(evbuf, len);\n\tif (result < 0 || (size_t)result > len) /* XXX Should this be != rather than > ?*/\n\t\treturn (-1);\n\telse\n\t\treturn result;\n}\n\nint\nevtag_unmarshal_int64(struct evbuffer *evbuf, ev_uint32_t need_tag,\n    ev_uint64_t *pinteger)\n{\n\tev_uint32_t tag;\n\tev_uint32_t len;\n\tint result;\n\n\tif (decode_tag_internal(&tag, evbuf, 1 /* dodrain */) == -1)\n\t\treturn (-1);\n\tif (need_tag != tag)\n\t\treturn (-1);\n\tif (evtag_decode_int(&len, evbuf) == -1)\n\t\treturn (-1);\n\n\tif (evbuffer_get_length(evbuf) < len)\n\t\treturn (-1);\n\n\tresult = decode_int64_internal(pinteger, evbuf, 0);\n\tevbuffer_drain(evbuf, len);\n\tif (result < 0 || (size_t)result > len) /* XXX Should this be != rather than > ?*/\n\t\treturn (-1);\n\telse\n\t\treturn result;\n}\n\n/* Unmarshal a fixed length tag */\n\nint\nevtag_unmarshal_fixed(struct evbuffer *src, ev_uint32_t need_tag, void *data,\n    size_t len)\n{\n\tev_uint32_t tag;\n\tint tag_len;\n\n\t/* Now unmarshal a tag and check that it matches the tag we want */\n\tif ((tag_len = evtag_unmarshal_header(src, &tag)) < 0 ||\n\t    tag != need_tag)\n\t\treturn (-1);\n\n\tif ((size_t)tag_len != len)\n\t\treturn (-1);\n\n\tevbuffer_remove(src, data, len);\n\treturn (0);\n}\n\nint\nevtag_unmarshal_string(struct evbuffer *evbuf, ev_uint32_t need_tag,\n    char **pstring)\n{\n\tev_uint32_t tag;\n\tint tag_len;\n\n\tif ((tag_len = evtag_unmarshal_header(evbuf, &tag)) == -1 ||\n\t    tag != need_tag)\n\t\treturn (-1);\n\n\t*pstring = mm_malloc(tag_len + 1);\n\tif (*pstring == NULL) {\n\t\tevent_warn(\"%s: malloc\", __func__);\n\t\treturn -1;\n\t}\n\tevbuffer_remove(evbuf, *pstring, tag_len);\n\t(*pstring)[tag_len] = '\\0';\n\n\treturn (0);\n}\n\nint\nevtag_unmarshal_timeval(struct evbuffer *evbuf, ev_uint32_t need_tag,\n    struct timeval *ptv)\n{\n\tev_uint32_t tag;\n\tev_uint32_t integer;\n\tint len, offset, offset2;\n\tint result = -1;\n\n\tif ((len = evtag_unmarshal_header(evbuf, &tag)) == -1)\n\t\treturn (-1);\n\tif (tag != need_tag)\n\t\tgoto done;\n\tif ((offset = decode_int_internal(&integer, evbuf, 0)) == -1)\n\t\tgoto done;\n\tptv->tv_sec = integer;\n\tif ((offset2 = decode_int_internal(&integer, evbuf, offset)) == -1)\n\t\tgoto done;\n\tptv->tv_usec = integer;\n\tif (offset + offset2 > len) /* XXX Should this be != instead of > ? */\n\t\tgoto done;\n\n\tresult = 0;\n done:\n\tevbuffer_drain(evbuf, len);\n\treturn result;\n}\n"
        },
        {
          "name": "evmap-internal.h",
          "type": "blob",
          "size": 4.7783203125,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVMAP_INTERNAL_H_INCLUDED_\n#define EVMAP_INTERNAL_H_INCLUDED_\n\n/** @file evmap-internal.h\n *\n * An event_map is a utility structure to map each fd or signal to zero or\n * more events.  Functions to manipulate event_maps should only be used from\n * inside libevent.  They generally need to hold the lock on the corresponding\n * event_base.\n **/\n\nstruct event_base;\nstruct event;\n\n/** Initialize an event_map for use.\n */\nvoid evmap_io_initmap_(struct event_io_map* ctx);\nvoid evmap_signal_initmap_(struct event_signal_map* ctx);\n\n/** Remove all entries from an event_map.\n\n\t@param ctx the map to clear.\n */\nvoid evmap_io_clear_(struct event_io_map* ctx);\nvoid evmap_signal_clear_(struct event_signal_map* ctx);\n\n/** Add an IO event (some combination of EV_READ or EV_WRITE) to an\n    event_base's list of events on a given file descriptor, and tell the\n    underlying eventops about the fd if its state has changed.\n\n    Requires that ev is not already added.\n\n    @param base the event_base to operate on.\n    @param fd the file descriptor corresponding to ev.\n    @param ev the event to add.\n*/\nint evmap_io_add_(struct event_base *base, evutil_socket_t fd, struct event *ev);\n/** Remove an IO event (some combination of EV_READ or EV_WRITE) to an\n    event_base's list of events on a given file descriptor, and tell the\n    underlying eventops about the fd if its state has changed.\n\n    @param base the event_base to operate on.\n    @param fd the file descriptor corresponding to ev.\n    @param ev the event to remove.\n */\nint evmap_io_del_(struct event_base *base, evutil_socket_t fd, struct event *ev);\n/** Active the set of events waiting on an event_base for a given fd.\n\n    @param base the event_base to operate on.\n    @param fd the file descriptor that has become active.\n    @param events a bitmask of EV_READ|EV_WRITE|EV_ET.\n*/\nvoid evmap_io_active_(struct event_base *base, evutil_socket_t fd, short events);\n\n\n/* These functions behave in the same way as evmap_io_*, except they work on\n * signals rather than fds.  signals use a linear map everywhere; fds use\n * either a linear map or a hashtable. */\nint evmap_signal_add_(struct event_base *base, int signum, struct event *ev);\nint evmap_signal_del_(struct event_base *base, int signum, struct event *ev);\nvoid evmap_signal_active_(struct event_base *base, evutil_socket_t signum, int ncalls);\n\n/* Return the fdinfo object associated with a given fd.  If the fd has no\n * events associated with it, the result may be NULL.\n */\nvoid *evmap_io_get_fdinfo_(struct event_io_map *ctx, evutil_socket_t fd);\n\n/* Helper for event_reinit(): Tell the backend to re-add every fd and signal\n * for which we have a pending event.\n */\nint evmap_reinit_(struct event_base *base);\n\n/* Helper for event_base_free(): Call event_del() on every pending fd and\n * signal event.\n */\nvoid evmap_delete_all_(struct event_base *base);\n\n/* Helper for event_base_assert_ok_(): Check referential integrity of the\n * evmaps.\n */\nvoid evmap_check_integrity_(struct event_base *base);\n\n/* Helper: Call fn on every fd or signal event, passing as its arguments the\n * provided event_base, the event, and arg.  If fn returns 0, process the next\n * event.  If it returns any other value, return that value and process no\n * more events.\n */\nint evmap_foreach_event_(struct event_base *base,\n    event_base_foreach_event_cb fn,\n    void *arg);\n\n#endif /* EVMAP_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "evmap.c",
          "type": "blob",
          "size": 28.3544921875,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#define WIN32_LEAN_AND_MEAN\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n#include <sys/types.h>\n#if !defined(_WIN32) && defined(EVENT__HAVE_SYS_TIME_H)\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <stdio.h>\n#include <stdlib.h>\n#ifndef _WIN32\n#include <unistd.h>\n#endif\n#include <errno.h>\n#include <limits.h>\n#include <signal.h>\n#include <string.h>\n#include <time.h>\n\n#include \"event-internal.h\"\n#include \"evmap-internal.h\"\n#include \"mm-internal.h\"\n#include \"changelist-internal.h\"\n\n/** An entry for an evmap_io list: notes all the events that want to read or\n\twrite on a given fd, and the number of each.\n  */\nstruct evmap_io {\n\tstruct event_dlist events;\n\tev_uint16_t nread;\n\tev_uint16_t nwrite;\n\tev_uint16_t nclose;\n};\n\n/* An entry for an evmap_signal list: notes all the events that want to know\n   when a signal triggers. */\nstruct evmap_signal {\n\tstruct event_dlist events;\n};\n\n/* On some platforms, fds start at 0 and increment by 1 as they are\n   allocated, and old numbers get used.  For these platforms, we\n   implement io maps just like signal maps: as an array of pointers to\n   struct evmap_io.  But on other platforms (windows), sockets are not\n   0-indexed, not necessarily consecutive, and not necessarily reused.\n   There, we use a hashtable to implement evmap_io.\n*/\n#ifdef EVMAP_USE_HT\nstruct event_map_entry {\n\tHT_ENTRY(event_map_entry) map_node;\n\tevutil_socket_t fd;\n\tunion { /* This is a union in case we need to make more things that can\n\t\t\t   be in the hashtable. */\n\t\tstruct evmap_io evmap_io;\n\t} ent;\n};\n\n/* Helper used by the event_io_map hashtable code; tries to return a good hash\n * of the fd in e->fd. */\nstatic inline unsigned\nhashsocket(struct event_map_entry *e)\n{\n\t/* On win32, in practice, the low 2-3 bits of a SOCKET seem not to\n\t * matter.  Our hashtable implementation really likes low-order bits,\n\t * though, so let's do the rotate-and-add trick. */\n\tunsigned h = (unsigned) e->fd;\n\th = (h >> 2) | (h << 30);\n\treturn h;\n}\n\n/* Helper used by the event_io_map hashtable code; returns true iff e1 and e2\n * have the same e->fd. */\nstatic inline int\neqsocket(struct event_map_entry *e1, struct event_map_entry *e2)\n{\n\treturn e1->fd == e2->fd;\n}\n\nHT_PROTOTYPE(event_io_map, event_map_entry, map_node, hashsocket, eqsocket)\nHT_GENERATE(event_io_map, event_map_entry, map_node, hashsocket, eqsocket,\n\t\t\t0.5, mm_malloc, mm_realloc, mm_free)\n\n#define GET_IO_SLOT(x, map, slot, type)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstruct event_map_entry key_, *ent_;\t\t\t\\\n\t\tkey_.fd = slot;\t\t\t\t\t\t\\\n\t\tent_ = HT_FIND(event_io_map, map, &key_);\t\t\\\n\t\t(x) = ent_ ? &ent_->ent.type : NULL;\t\t\t\\\n\t} while (0);\n\n#define GET_IO_SLOT_AND_CTOR(x, map, slot, type, ctor, fdinfo_len)\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstruct event_map_entry key_, *ent_;\t\t\t\\\n\t\tkey_.fd = slot;\t\t\t\t\t\t\\\n\t\tHT_FIND_OR_INSERT_(event_io_map, map_node, hashsocket, map, \\\n\t\t    event_map_entry, &key_, ptr,\t\t\t\\\n\t\t    {\t\t\t\t\t\t\t\\\n\t\t\t    ent_ = *ptr;\t\t\t\t\\\n\t\t    },\t\t\t\t\t\t\t\\\n\t\t    {\t\t\t\t\t\t\t\\\n\t\t\t    ent_ = mm_calloc(1,sizeof(struct event_map_entry)+fdinfo_len); \\\n\t\t\t    if (EVUTIL_UNLIKELY(ent_ == NULL))\t\t\\\n\t\t\t\t    return (-1);\t\t\t\\\n\t\t\t    ent_->fd = slot;\t\t\t\t\\\n\t\t\t    (ctor)(&ent_->ent.type);\t\t\t\\\n\t\t\t    HT_FOI_INSERT_(map_node, map, &key_, ent_, ptr) \\\n\t\t\t\t});\t\t\t\t\t\\\n\t\t(x) = &ent_->ent.type;\t\t\t\t\t\\\n\t} while (0)\n\nvoid evmap_io_initmap_(struct event_io_map *ctx)\n{\n\tHT_INIT(event_io_map, ctx);\n}\n\nvoid evmap_io_clear_(struct event_io_map *ctx)\n{\n\tstruct event_map_entry **ent, **next, *this;\n\tfor (ent = HT_START(event_io_map, ctx); ent; ent = next) {\n\t\tthis = *ent;\n\t\tnext = HT_NEXT_RMV(event_io_map, ctx, ent);\n\t\tmm_free(this);\n\t}\n\tHT_CLEAR(event_io_map, ctx); /* remove all storage held by the ctx. */\n}\n#endif\n\n/* Set the variable 'x' to the field in event_map 'map' with fields of type\n   'struct type *' corresponding to the fd or signal 'slot'.  Set 'x' to NULL\n   if there are no entries for 'slot'.  Does no bounds-checking. */\n#define GET_SIGNAL_SLOT(x, map, slot, type)\t\t\t\\\n\t(x) = (struct type *)((map)->entries[slot])\n/* As GET_SLOT, but construct the entry for 'slot' if it is not present,\n   by allocating enough memory for a 'struct type', and initializing the new\n   value by calling the function 'ctor' on it.  Makes the function\n   return -1 on allocation failure.\n */\n#define GET_SIGNAL_SLOT_AND_CTOR(x, map, slot, type, ctor, fdinfo_len)\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif ((map)->entries[slot] == NULL) {\t\t\t\\\n\t\t\t(map)->entries[slot] =\t\t\t\t\\\n\t\t\t    mm_calloc(1,sizeof(struct type)+fdinfo_len); \\\n\t\t\tif (EVUTIL_UNLIKELY((map)->entries[slot] == NULL)) \\\n\t\t\t\treturn (-1);\t\t\t\t\\\n\t\t\t(ctor)((struct type *)(map)->entries[slot]);\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\t(x) = (struct type *)((map)->entries[slot]);\t\t\\\n\t} while (0)\n\n/* If we aren't using hashtables, then define the IO_SLOT macros and functions\n   as thin aliases over the SIGNAL_SLOT versions. */\n#ifndef EVMAP_USE_HT\n#define GET_IO_SLOT(x,map,slot,type) GET_SIGNAL_SLOT(x,map,slot,type)\n#define GET_IO_SLOT_AND_CTOR(x,map,slot,type,ctor,fdinfo_len)\t\\\n\tGET_SIGNAL_SLOT_AND_CTOR(x,map,slot,type,ctor,fdinfo_len)\n#define FDINFO_OFFSET sizeof(struct evmap_io)\nvoid\nevmap_io_initmap_(struct event_io_map* ctx)\n{\n\tevmap_signal_initmap_(ctx);\n}\nvoid\nevmap_io_clear_(struct event_io_map* ctx)\n{\n\tevmap_signal_clear_(ctx);\n}\n#endif\n\n\n/** Expand 'map' with new entries of width 'msize' until it is big enough\n\tto store a value in 'slot'.\n */\nstatic int\nevmap_make_space(struct event_signal_map *map, int slot, int msize)\n{\n\tif (map->nentries <= slot) {\n\t\tint nentries = map->nentries ? map->nentries : 32;\n\t\tvoid **tmp;\n\n\t\tif (slot > INT_MAX / 2)\n\t\t\treturn (-1);\n\n\t\twhile (nentries <= slot)\n\t\t\tnentries <<= 1;\n\n\t\tif (nentries > INT_MAX / msize)\n\t\t\treturn (-1);\n\n\t\ttmp = (void **)mm_realloc(map->entries, nentries * msize);\n\t\tif (tmp == NULL)\n\t\t\treturn (-1);\n\n\t\tmemset(&tmp[map->nentries], 0,\n\t\t    (nentries - map->nentries) * msize);\n\n\t\tmap->nentries = nentries;\n\t\tmap->entries = tmp;\n\t}\n\n\treturn (0);\n}\n\nvoid\nevmap_signal_initmap_(struct event_signal_map *ctx)\n{\n\tctx->nentries = 0;\n\tctx->entries = NULL;\n}\n\nvoid\nevmap_signal_clear_(struct event_signal_map *ctx)\n{\n\tif (ctx->entries != NULL) {\n\t\tint i;\n\t\tfor (i = 0; i < ctx->nentries; ++i) {\n\t\t\tif (ctx->entries[i] != NULL)\n\t\t\t\tmm_free(ctx->entries[i]);\n\t\t}\n\t\tmm_free(ctx->entries);\n\t\tctx->entries = NULL;\n\t}\n\tctx->nentries = 0;\n}\n\n\n/* code specific to file descriptors */\n\n/** Constructor for struct evmap_io */\nstatic void\nevmap_io_init(struct evmap_io *entry)\n{\n\tLIST_INIT(&entry->events);\n\tentry->nread = 0;\n\tentry->nwrite = 0;\n\tentry->nclose = 0;\n}\n\n\n/* return -1 on error, 0 on success if nothing changed in the event backend,\n * and 1 on success if something did. */\nint\nevmap_io_add_(struct event_base *base, evutil_socket_t fd, struct event *ev)\n{\n\tconst struct eventop *evsel = base->evsel;\n\tstruct event_io_map *io = &base->io;\n\tstruct evmap_io *ctx = NULL;\n\tint nread, nwrite, nclose, retval = 0;\n\tshort res = 0, old = 0;\n\tstruct event *old_ev;\n\n\tEVUTIL_ASSERT(fd == ev->ev_fd);\n\n\tif (fd < 0)\n\t\treturn 0;\n\n#ifndef EVMAP_USE_HT\n\tif (fd >= io->nentries) {\n\t\tif (evmap_make_space(io, fd, sizeof(struct evmap_io *)) == -1)\n\t\t\treturn (-1);\n\t}\n#endif\n\tGET_IO_SLOT_AND_CTOR(ctx, io, fd, evmap_io, evmap_io_init,\n\t\t\t\t\t\t evsel->fdinfo_len);\n\n\tnread = ctx->nread;\n\tnwrite = ctx->nwrite;\n\tnclose = ctx->nclose;\n\n\tif (nread)\n\t\told |= EV_READ;\n\tif (nwrite)\n\t\told |= EV_WRITE;\n\tif (nclose)\n\t\told |= EV_CLOSED;\n\n\tif (ev->ev_events & EV_READ) {\n\t\tif (++nread == 1)\n\t\t\tres |= EV_READ;\n\t}\n\tif (ev->ev_events & EV_WRITE) {\n\t\tif (++nwrite == 1)\n\t\t\tres |= EV_WRITE;\n\t}\n\tif (ev->ev_events & EV_CLOSED) {\n\t\tif (++nclose == 1)\n\t\t\tres |= EV_CLOSED;\n\t}\n\tif (EVUTIL_UNLIKELY(nread > 0xffff || nwrite > 0xffff || nclose > 0xffff)) {\n\t\tevent_warnx(\"Too many events reading or writing on fd %d\",\n\t\t    (int)fd);\n\t\treturn -1;\n\t}\n\tif (EVENT_DEBUG_MODE_IS_ON() &&\n\t    (old_ev = LIST_FIRST(&ctx->events)) &&\n\t    (old_ev->ev_events&EV_ET) != (ev->ev_events&EV_ET)) {\n\t\tevent_warnx(\"Tried to mix edge-triggered and non-edge-triggered\"\n\t\t    \" events on fd %d\", (int)fd);\n\t\treturn -1;\n\t}\n\n\tif (res) {\n\t\tvoid *extra = ((char*)ctx) + sizeof(struct evmap_io);\n\t\t/* XXX(niels): we cannot mix edge-triggered and\n\t\t * level-triggered, we should probably assert on\n\t\t * this. */\n\t\tif (evsel->add(base, ev->ev_fd,\n\t\t\told, (ev->ev_events & EV_ET) | res, extra) == -1)\n\t\t\treturn (-1);\n\t\tretval = 1;\n\t}\n\n\tctx->nread = (ev_uint16_t) nread;\n\tctx->nwrite = (ev_uint16_t) nwrite;\n\tctx->nclose = (ev_uint16_t) nclose;\n\tLIST_INSERT_HEAD(&ctx->events, ev, ev_io_next);\n\n\treturn (retval);\n}\n\n/* return -1 on error, 0 on success if nothing changed in the event backend,\n * and 1 on success if something did. */\nint\nevmap_io_del_(struct event_base *base, evutil_socket_t fd, struct event *ev)\n{\n\tconst struct eventop *evsel = base->evsel;\n\tstruct event_io_map *io = &base->io;\n\tstruct evmap_io *ctx;\n\tint nread, nwrite, nclose, retval = 0;\n\tshort res = 0, old = 0;\n\n\tif (fd < 0)\n\t\treturn 0;\n\n\tEVUTIL_ASSERT(fd == ev->ev_fd);\n\n#ifndef EVMAP_USE_HT\n\tif (fd >= io->nentries)\n\t\treturn (-1);\n#endif\n\n\tGET_IO_SLOT(ctx, io, fd, evmap_io);\n\n\tnread = ctx->nread;\n\tnwrite = ctx->nwrite;\n\tnclose = ctx->nclose;\n\n\tif (nread)\n\t\told |= EV_READ;\n\tif (nwrite)\n\t\told |= EV_WRITE;\n\tif (nclose)\n\t\told |= EV_CLOSED;\n\n\tif (ev->ev_events & EV_READ) {\n\t\tif (--nread == 0)\n\t\t\tres |= EV_READ;\n\t\tEVUTIL_ASSERT(nread >= 0);\n\t}\n\tif (ev->ev_events & EV_WRITE) {\n\t\tif (--nwrite == 0)\n\t\t\tres |= EV_WRITE;\n\t\tEVUTIL_ASSERT(nwrite >= 0);\n\t}\n\tif (ev->ev_events & EV_CLOSED) {\n\t\tif (--nclose == 0)\n\t\t\tres |= EV_CLOSED;\n\t\tEVUTIL_ASSERT(nclose >= 0);\n\t}\n\n\tif (res) {\n\t\tvoid *extra = ((char*)ctx) + sizeof(struct evmap_io);\n\t\tif (evsel->del(base, ev->ev_fd,\n\t\t\told, (ev->ev_events & EV_ET) | res, extra) == -1) {\n\t\t\tretval = -1;\n\t\t} else {\n\t\t\tretval = 1;\n\t\t}\n\t}\n\n\tctx->nread = nread;\n\tctx->nwrite = nwrite;\n\tctx->nclose = nclose;\n\tLIST_REMOVE(ev, ev_io_next);\n\n\treturn (retval);\n}\n\nvoid\nevmap_io_active_(struct event_base *base, evutil_socket_t fd, short events)\n{\n\tstruct event_io_map *io = &base->io;\n\tstruct evmap_io *ctx;\n\tstruct event *ev;\n\n#ifndef EVMAP_USE_HT\n\tif (fd < 0 || fd >= io->nentries)\n\t\treturn;\n#endif\n\tGET_IO_SLOT(ctx, io, fd, evmap_io);\n\n\tif (NULL == ctx)\n\t\treturn;\n\tLIST_FOREACH(ev, &ctx->events, ev_io_next) {\n\t\tif (ev->ev_events & (events & ~EV_ET))\n\t\t\tevent_active_nolock_(ev, ev->ev_events & events, 1);\n\t}\n}\n\n/* code specific to signals */\n\nstatic void\nevmap_signal_init(struct evmap_signal *entry)\n{\n\tLIST_INIT(&entry->events);\n}\n\n\nint\nevmap_signal_add_(struct event_base *base, int sig, struct event *ev)\n{\n\tconst struct eventop *evsel = base->evsigsel;\n\tstruct event_signal_map *map = &base->sigmap;\n\tstruct evmap_signal *ctx = NULL;\n\n\tif (sig < 0 || sig >= NSIG)\n\t\treturn (-1);\n\n\tif (sig >= map->nentries) {\n\t\tif (evmap_make_space(\n\t\t\tmap, sig, sizeof(struct evmap_signal *)) == -1)\n\t\t\treturn (-1);\n\t}\n\tGET_SIGNAL_SLOT_AND_CTOR(ctx, map, sig, evmap_signal, evmap_signal_init,\n\t    base->evsigsel->fdinfo_len);\n\n\tif (LIST_EMPTY(&ctx->events)) {\n\t\tif (evsel->add(base, ev->ev_fd, 0, EV_SIGNAL, ev)\n\t\t    == -1)\n\t\t\treturn (-1);\n\t}\n\n\tLIST_INSERT_HEAD(&ctx->events, ev, ev_signal_next);\n\n\treturn (1);\n}\n\nint\nevmap_signal_del_(struct event_base *base, int sig, struct event *ev)\n{\n\tconst struct eventop *evsel = base->evsigsel;\n\tstruct event_signal_map *map = &base->sigmap;\n\tstruct evmap_signal *ctx;\n\n\tif (sig < 0 || sig >= map->nentries)\n\t\treturn (-1);\n\n\tGET_SIGNAL_SLOT(ctx, map, sig, evmap_signal);\n\n\tLIST_REMOVE(ev, ev_signal_next);\n\n\tif (LIST_FIRST(&ctx->events) == NULL) {\n\t\tif (evsel->del(base, ev->ev_fd, 0, EV_SIGNAL, NULL) == -1)\n\t\t\treturn (-1);\n\t}\n\n\treturn (1);\n}\n\nvoid\nevmap_signal_active_(struct event_base *base, evutil_socket_t sig, int ncalls)\n{\n\tstruct event_signal_map *map = &base->sigmap;\n\tstruct evmap_signal *ctx;\n\tstruct event *ev;\n\n\tif (sig < 0 || sig >= map->nentries)\n\t\treturn;\n\tGET_SIGNAL_SLOT(ctx, map, sig, evmap_signal);\n\n\tif (!ctx)\n\t\treturn;\n\tLIST_FOREACH(ev, &ctx->events, ev_signal_next)\n\t\tevent_active_nolock_(ev, EV_SIGNAL, ncalls);\n}\n\nvoid *\nevmap_io_get_fdinfo_(struct event_io_map *map, evutil_socket_t fd)\n{\n\tstruct evmap_io *ctx;\n\tGET_IO_SLOT(ctx, map, fd, evmap_io);\n\tif (ctx)\n\t\treturn ((char*)ctx) + sizeof(struct evmap_io);\n\telse\n\t\treturn NULL;\n}\n\n/* Callback type for evmap_io_foreach_fd */\ntypedef int (*evmap_io_foreach_fd_cb)(\n\tstruct event_base *, evutil_socket_t, struct evmap_io *, void *);\n\n/* Multipurpose helper function: Iterate over every file descriptor event_base\n * for which we could have EV_READ or EV_WRITE events.  For each such fd, call\n * fn(base, signum, evmap_io, arg), where fn is the user-provided\n * function, base is the event_base, signum is the signal number, evmap_io\n * is an evmap_io structure containing a list of events pending on the\n * file descriptor, and arg is the user-supplied argument.\n *\n * If fn returns 0, continue on to the next signal. Otherwise, return the same\n * value that fn returned.\n *\n * Note that there is no guarantee that the file descriptors will be processed\n * in any particular order.\n */\nstatic int\nevmap_io_foreach_fd(struct event_base *base,\n    evmap_io_foreach_fd_cb fn,\n    void *arg)\n{\n\tevutil_socket_t fd;\n\tstruct event_io_map *iomap = &base->io;\n\tint r = 0;\n#ifdef EVMAP_USE_HT\n\tstruct event_map_entry **mapent;\n\tHT_FOREACH(mapent, event_io_map, iomap) {\n\t\tstruct evmap_io *ctx = &(*mapent)->ent.evmap_io;\n\t\tfd = (*mapent)->fd;\n#else\n\tfor (fd = 0; fd < iomap->nentries; ++fd) {\n\t\tstruct evmap_io *ctx = iomap->entries[fd];\n\t\tif (!ctx)\n\t\t\tcontinue;\n#endif\n\t\tif ((r = fn(base, fd, ctx, arg)))\n\t\t\tbreak;\n\t}\n\treturn r;\n}\n\n/* Callback type for evmap_signal_foreach_signal */\ntypedef int (*evmap_signal_foreach_signal_cb)(\n\tstruct event_base *, int, struct evmap_signal *, void *);\n\n/* Multipurpose helper function: Iterate over every signal number in the\n * event_base for which we could have signal events.  For each such signal,\n * call fn(base, signum, evmap_signal, arg), where fn is the user-provided\n * function, base is the event_base, signum is the signal number, evmap_signal\n * is an evmap_signal structure containing a list of events pending on the\n * signal, and arg is the user-supplied argument.\n *\n * If fn returns 0, continue on to the next signal. Otherwise, return the same\n * value that fn returned.\n */\nstatic int\nevmap_signal_foreach_signal(struct event_base *base,\n    evmap_signal_foreach_signal_cb fn,\n    void *arg)\n{\n\tstruct event_signal_map *sigmap = &base->sigmap;\n\tint r = 0;\n\tint signum;\n\n\tfor (signum = 0; signum < sigmap->nentries; ++signum) {\n\t\tstruct evmap_signal *ctx = sigmap->entries[signum];\n\t\tif (!ctx)\n\t\t\tcontinue;\n\t\tif ((r = fn(base, signum, ctx, arg)))\n\t\t\tbreak;\n\t}\n\treturn r;\n}\n\n/* Helper for evmap_reinit_: tell the backend to add every fd for which we have\n * pending events, with the appropriate combination of EV_READ, EV_WRITE, and\n * EV_ET. */\nstatic int\nevmap_io_reinit_iter_fn(struct event_base *base, evutil_socket_t fd,\n    struct evmap_io *ctx, void *arg)\n{\n\tconst struct eventop *evsel = base->evsel;\n\tvoid *extra;\n\tint *result = arg;\n\tshort events = 0;\n\tstruct event *ev;\n\tEVUTIL_ASSERT(ctx);\n\n\textra = ((char*)ctx) + sizeof(struct evmap_io);\n\tif (ctx->nread)\n\t\tevents |= EV_READ;\n\tif (ctx->nwrite)\n\t\tevents |= EV_WRITE;\n\tif (ctx->nclose)\n\t\tevents |= EV_CLOSED;\n\tif (evsel->fdinfo_len)\n\t\tmemset(extra, 0, evsel->fdinfo_len);\n\tif (events &&\n\t    (ev = LIST_FIRST(&ctx->events)) &&\n\t    (ev->ev_events & EV_ET))\n\t\tevents |= EV_ET;\n\tif (evsel->add(base, fd, 0, events, extra) == -1)\n\t\t*result = -1;\n\n\treturn 0;\n}\n\n/* Helper for evmap_reinit_: tell the backend to add every signal for which we\n * have pending events.  */\nstatic int\nevmap_signal_reinit_iter_fn(struct event_base *base,\n    int signum, struct evmap_signal *ctx, void *arg)\n{\n\tconst struct eventop *evsel = base->evsigsel;\n\tint *result = arg;\n\n\tif (!LIST_EMPTY(&ctx->events)) {\n\t\tif (evsel->add(base, signum, 1, EV_SIGNAL,\n\t\t\t       LIST_FIRST(&ctx->events)) == -1)\n\t\t\t*result = -1;\n\t}\n\treturn 0;\n}\n\nint\nevmap_reinit_(struct event_base *base)\n{\n\tint result = 0;\n\n\tevmap_io_foreach_fd(base, evmap_io_reinit_iter_fn, &result);\n\tif (result < 0)\n\t\treturn -1;\n\tevmap_signal_foreach_signal(base, evmap_signal_reinit_iter_fn, &result);\n\tif (result < 0)\n\t\treturn -1;\n\treturn 0;\n}\n\n/* Helper for evmap_delete_all_: delete every event in an event_dlist. */\nstatic int\ndelete_all_in_dlist(struct event_dlist *dlist)\n{\n\tstruct event *ev;\n\twhile ((ev = LIST_FIRST(dlist)))\n\t\tevent_del(ev);\n\treturn 0;\n}\n\n/* Helper for evmap_delete_all_: delete every event pending on an fd. */\nstatic int\nevmap_io_delete_all_iter_fn(struct event_base *base, evutil_socket_t fd,\n    struct evmap_io *io_info, void *arg)\n{\n\treturn delete_all_in_dlist(&io_info->events);\n}\n\n/* Helper for evmap_delete_all_: delete every event pending on a signal. */\nstatic int\nevmap_signal_delete_all_iter_fn(struct event_base *base, int signum,\n    struct evmap_signal *sig_info, void *arg)\n{\n\treturn delete_all_in_dlist(&sig_info->events);\n}\n\nvoid\nevmap_delete_all_(struct event_base *base)\n{\n\tevmap_signal_foreach_signal(base, evmap_signal_delete_all_iter_fn, NULL);\n\tevmap_io_foreach_fd(base, evmap_io_delete_all_iter_fn, NULL);\n}\n\n/** Per-fd structure for use with changelists.  It keeps track, for each fd or\n * signal using the changelist, of where its entry in the changelist is.\n */\nstruct event_changelist_fdinfo {\n\tint idxplus1; /* this is the index +1, so that memset(0) will make it\n\t\t       * a no-such-element */\n};\n\nvoid\nevent_changelist_init_(struct event_changelist *changelist)\n{\n\tchangelist->changes = NULL;\n\tchangelist->changes_size = 0;\n\tchangelist->n_changes = 0;\n}\n\n/** Helper: return the changelist_fdinfo corresponding to a given change. */\nstatic inline struct event_changelist_fdinfo *\nevent_change_get_fdinfo(struct event_base *base,\n    const struct event_change *change)\n{\n\tchar *ptr;\n\tif (change->read_change & EV_CHANGE_SIGNAL) {\n\t\tstruct evmap_signal *ctx;\n\t\tGET_SIGNAL_SLOT(ctx, &base->sigmap, change->fd, evmap_signal);\n\t\tptr = ((char*)ctx) + sizeof(struct evmap_signal);\n\t} else {\n\t\tstruct evmap_io *ctx;\n\t\tGET_IO_SLOT(ctx, &base->io, change->fd, evmap_io);\n\t\tptr = ((char*)ctx) + sizeof(struct evmap_io);\n\t}\n\treturn (void*)ptr;\n}\n\n/** Callback helper for event_changelist_assert_ok */\nstatic int\nevent_changelist_assert_ok_foreach_iter_fn(\n\tstruct event_base *base,\n\tevutil_socket_t fd, struct evmap_io *io, void *arg)\n{\n\tstruct event_changelist *changelist = &base->changelist;\n\tstruct event_changelist_fdinfo *f;\n\tf = (void*)\n\t    ( ((char*)io) + sizeof(struct evmap_io) );\n\tif (f->idxplus1) {\n\t\tstruct event_change *c = &changelist->changes[f->idxplus1 - 1];\n\t\tEVUTIL_ASSERT(c->fd == fd);\n\t}\n\treturn 0;\n}\n\n/** Make sure that the changelist is consistent with the evmap structures. */\nstatic void\nevent_changelist_assert_ok(struct event_base *base)\n{\n\tint i;\n\tstruct event_changelist *changelist = &base->changelist;\n\n\tEVUTIL_ASSERT(changelist->changes_size >= changelist->n_changes);\n\tfor (i = 0; i < changelist->n_changes; ++i) {\n\t\tstruct event_change *c = &changelist->changes[i];\n\t\tstruct event_changelist_fdinfo *f;\n\t\tEVUTIL_ASSERT(c->fd >= 0);\n\t\tf = event_change_get_fdinfo(base, c);\n\t\tEVUTIL_ASSERT(f);\n\t\tEVUTIL_ASSERT(f->idxplus1 == i + 1);\n\t}\n\n\tevmap_io_foreach_fd(base,\n\t    event_changelist_assert_ok_foreach_iter_fn,\n\t    NULL);\n}\n\n#ifdef DEBUG_CHANGELIST\n#define event_changelist_check(base)  event_changelist_assert_ok((base))\n#else\n#define event_changelist_check(base)  ((void)0)\n#endif\n\nvoid\nevent_changelist_remove_all_(struct event_changelist *changelist,\n    struct event_base *base)\n{\n\tint i;\n\n\tevent_changelist_check(base);\n\n\tfor (i = 0; i < changelist->n_changes; ++i) {\n\t\tstruct event_change *ch = &changelist->changes[i];\n\t\tstruct event_changelist_fdinfo *fdinfo =\n\t\t    event_change_get_fdinfo(base, ch);\n\t\tEVUTIL_ASSERT(fdinfo->idxplus1 == i + 1);\n\t\tfdinfo->idxplus1 = 0;\n\t}\n\n\tchangelist->n_changes = 0;\n\n\tevent_changelist_check(base);\n}\n\nvoid\nevent_changelist_freemem_(struct event_changelist *changelist)\n{\n\tif (changelist->changes)\n\t\tmm_free(changelist->changes);\n\tevent_changelist_init_(changelist); /* zero it all out. */\n}\n\n/** Increase the size of 'changelist' to hold more changes. */\nstatic int\nevent_changelist_grow(struct event_changelist *changelist)\n{\n\tint new_size;\n\tstruct event_change *new_changes;\n\tif (changelist->changes_size < 64)\n\t\tnew_size = 64;\n\telse\n\t\tnew_size = changelist->changes_size * 2;\n\n\tnew_changes = mm_realloc(changelist->changes,\n\t    new_size * sizeof(struct event_change));\n\n\tif (EVUTIL_UNLIKELY(new_changes == NULL))\n\t\treturn (-1);\n\n\tchangelist->changes = new_changes;\n\tchangelist->changes_size = new_size;\n\n\treturn (0);\n}\n\n/** Return a pointer to the changelist entry for the file descriptor or signal\n * 'fd', whose fdinfo is 'fdinfo'.  If none exists, construct it, setting its\n * old_events field to old_events.\n */\nstatic struct event_change *\nevent_changelist_get_or_construct(struct event_changelist *changelist,\n    evutil_socket_t fd,\n    short old_events,\n    struct event_changelist_fdinfo *fdinfo)\n{\n\tstruct event_change *change;\n\n\tif (fdinfo->idxplus1 == 0) {\n\t\tint idx;\n\t\tEVUTIL_ASSERT(changelist->n_changes <= changelist->changes_size);\n\n\t\tif (changelist->n_changes == changelist->changes_size) {\n\t\t\tif (event_changelist_grow(changelist) < 0)\n\t\t\t\treturn NULL;\n\t\t}\n\n\t\tidx = changelist->n_changes++;\n\t\tchange = &changelist->changes[idx];\n\t\tfdinfo->idxplus1 = idx + 1;\n\n\t\tmemset(change, 0, sizeof(struct event_change));\n\t\tchange->fd = fd;\n\t\tchange->old_events = old_events;\n\t} else {\n\t\tchange = &changelist->changes[fdinfo->idxplus1 - 1];\n\t\tEVUTIL_ASSERT(change->fd == fd);\n\t}\n\treturn change;\n}\n\nint\nevent_changelist_add_(struct event_base *base, evutil_socket_t fd, short old, short events,\n    void *p)\n{\n\tstruct event_changelist *changelist = &base->changelist;\n\tstruct event_changelist_fdinfo *fdinfo = p;\n\tstruct event_change *change;\n\tev_uint8_t evchange = EV_CHANGE_ADD | (events & (EV_ET|EV_PERSIST|EV_SIGNAL));\n\n\tevent_changelist_check(base);\n\n\tchange = event_changelist_get_or_construct(changelist, fd, old, fdinfo);\n\tif (!change)\n\t\treturn -1;\n\n\t/* An add replaces any previous delete, but doesn't result in a no-op,\n\t * since the delete might fail (because the fd had been closed since\n\t * the last add, for instance. */\n\n\tif (events & (EV_READ|EV_SIGNAL))\n\t\tchange->read_change = evchange;\n\tif (events & EV_WRITE)\n\t\tchange->write_change = evchange;\n\tif (events & EV_CLOSED)\n\t\tchange->close_change = evchange;\n\n\tevent_changelist_check(base);\n\treturn (0);\n}\n\nint\nevent_changelist_del_(struct event_base *base, evutil_socket_t fd, short old, short events,\n    void *p)\n{\n\tstruct event_changelist *changelist = &base->changelist;\n\tstruct event_changelist_fdinfo *fdinfo = p;\n\tstruct event_change *change;\n\tev_uint8_t del = EV_CHANGE_DEL | (events & EV_ET);\n\n\tevent_changelist_check(base);\n\tchange = event_changelist_get_or_construct(changelist, fd, old, fdinfo);\n\tevent_changelist_check(base);\n\tif (!change)\n\t\treturn -1;\n\n\t/* A delete on an event set that doesn't contain the event to be\n\t   deleted produces a no-op.  This effectively emoves any previous\n\t   uncommitted add, rather than replacing it: on those platforms where\n\t   \"add, delete, dispatch\" is not the same as \"no-op, dispatch\", we\n\t   want the no-op behavior.\n\n\t   If we have a no-op item, we could remove it from the list\n\t   entirely, but really there's not much point: skipping the no-op\n\t   change when we do the dispatch later is far cheaper than rejuggling\n\t   the array now.\n\n\t   As this stands, it also lets through deletions of events that are\n\t   not currently set.\n\t */\n\n\tif (events & (EV_READ|EV_SIGNAL)) {\n\t\tif (!(change->old_events & (EV_READ | EV_SIGNAL)))\n\t\t\tchange->read_change = 0;\n\t\telse\n\t\t\tchange->read_change = del;\n\t}\n\tif (events & EV_WRITE) {\n\t\tif (!(change->old_events & EV_WRITE))\n\t\t\tchange->write_change = 0;\n\t\telse\n\t\t\tchange->write_change = del;\n\t}\n\tif (events & EV_CLOSED) {\n\t\tif (!(change->old_events & EV_CLOSED))\n\t\t\tchange->close_change = 0;\n\t\telse\n\t\t\tchange->close_change = del;\n\t}\n\n\tevent_changelist_check(base);\n\treturn (0);\n}\n\n/* Helper for evmap_check_integrity_: verify that all of the events pending on\n * given fd are set up correctly, and that the nread and nwrite counts on that\n * fd are correct. */\nstatic int\nevmap_io_check_integrity_fn(struct event_base *base, evutil_socket_t fd,\n    struct evmap_io *io_info, void *arg)\n{\n\tstruct event *ev;\n\tint n_read = 0, n_write = 0, n_close = 0;\n\n\t/* First, make sure the list itself isn't corrupt. Otherwise,\n\t * running LIST_FOREACH could be an exciting adventure. */\n\tEVUTIL_ASSERT_LIST_OK(&io_info->events, event, ev_io_next);\n\n\tLIST_FOREACH(ev, &io_info->events, ev_io_next) {\n\t\tEVUTIL_ASSERT(ev->ev_flags & EVLIST_INSERTED);\n\t\tEVUTIL_ASSERT(ev->ev_fd == fd);\n\t\tEVUTIL_ASSERT(!(ev->ev_events & EV_SIGNAL));\n\t\tEVUTIL_ASSERT((ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED)));\n\t\tif (ev->ev_events & EV_READ)\n\t\t\t++n_read;\n\t\tif (ev->ev_events & EV_WRITE)\n\t\t\t++n_write;\n\t\tif (ev->ev_events & EV_CLOSED)\n\t\t\t++n_close;\n\t}\n\n\tEVUTIL_ASSERT(n_read == io_info->nread);\n\tEVUTIL_ASSERT(n_write == io_info->nwrite);\n\tEVUTIL_ASSERT(n_close == io_info->nclose);\n\n\treturn 0;\n}\n\n/* Helper for evmap_check_integrity_: verify that all of the events pending\n * on given signal are set up correctly. */\nstatic int\nevmap_signal_check_integrity_fn(struct event_base *base,\n    int signum, struct evmap_signal *sig_info, void *arg)\n{\n\tstruct event *ev;\n\t/* First, make sure the list itself isn't corrupt. */\n\tEVUTIL_ASSERT_LIST_OK(&sig_info->events, event, ev_signal_next);\n\n\tLIST_FOREACH(ev, &sig_info->events, ev_io_next) {\n\t\tEVUTIL_ASSERT(ev->ev_flags & EVLIST_INSERTED);\n\t\tEVUTIL_ASSERT(ev->ev_fd == signum);\n\t\tEVUTIL_ASSERT((ev->ev_events & EV_SIGNAL));\n\t\tEVUTIL_ASSERT(!(ev->ev_events & (EV_READ|EV_WRITE|EV_CLOSED)));\n\t}\n\treturn 0;\n}\n\nvoid\nevmap_check_integrity_(struct event_base *base)\n{\n\tevmap_io_foreach_fd(base, evmap_io_check_integrity_fn, NULL);\n\tevmap_signal_foreach_signal(base, evmap_signal_check_integrity_fn, NULL);\n\n\tif (base->evsel->add == event_changelist_add_)\n\t\tevent_changelist_assert_ok(base);\n}\n\n/* Helper type for evmap_foreach_event_: Bundles a function to call on every\n * event, and the user-provided void* to use as its third argument. */\nstruct evmap_foreach_event_helper {\n\tevent_base_foreach_event_cb fn;\n\tvoid *arg;\n};\n\n/* Helper for evmap_foreach_event_: calls a provided function on every event\n * pending on a given fd.  */\nstatic int\nevmap_io_foreach_event_fn(struct event_base *base, evutil_socket_t fd,\n    struct evmap_io *io_info, void *arg)\n{\n\tstruct evmap_foreach_event_helper *h = arg;\n\tstruct event *ev;\n\tint r;\n\tLIST_FOREACH(ev, &io_info->events, ev_io_next) {\n\t\tif ((r = h->fn(base, ev, h->arg)))\n\t\t\treturn r;\n\t}\n\treturn 0;\n}\n\n/* Helper for evmap_foreach_event_: calls a provided function on every event\n * pending on a given signal.  */\nstatic int\nevmap_signal_foreach_event_fn(struct event_base *base, int signum,\n    struct evmap_signal *sig_info, void *arg)\n{\n\tstruct event *ev;\n\tstruct evmap_foreach_event_helper *h = arg;\n\tint r;\n\tLIST_FOREACH(ev, &sig_info->events, ev_signal_next) {\n\t\tif ((r = h->fn(base, ev, h->arg)))\n\t\t\treturn r;\n\t}\n\treturn 0;\n}\n\nint\nevmap_foreach_event_(struct event_base *base,\n    event_base_foreach_event_cb fn, void *arg)\n{\n\tstruct evmap_foreach_event_helper h;\n\tint r;\n\th.fn = fn;\n\th.arg = arg;\n\tif ((r = evmap_io_foreach_fd(base, evmap_io_foreach_event_fn, &h)))\n\t\treturn r;\n\treturn evmap_signal_foreach_signal(base, evmap_signal_foreach_event_fn, &h);\n}\n\n"
        },
        {
          "name": "evport.c",
          "type": "blob",
          "size": 11.7236328125,
          "content": "/*\n * Submitted by David Pacheco (dp.spambait@gmail.com)\n *\n * Copyright 2006-2007 Niels Provos\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY SUN MICROSYSTEMS, INC. ``AS IS'' AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL SUN MICROSYSTEMS, INC. BE LIABLE FOR ANY\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/*\n * Copyright (c) 2007 Sun Microsystems. All rights reserved.\n * Use is subject to license terms.\n */\n\n/*\n * evport.c: event backend using Solaris 10 event ports. See port_create(3C).\n * This implementation is loosely modeled after the one used for select(2) (in\n * select.c).\n *\n * The outstanding events are tracked in a data structure called evport_data.\n * Each entry in the ed_fds array corresponds to a file descriptor, and contains\n * pointers to the read and write events that correspond to that fd. (That is,\n * when the file is readable, the \"read\" event should handle it, etc.)\n *\n * evport_add and evport_del update this data structure. evport_dispatch uses it\n * to determine where to callback when an event occurs (which it gets from\n * port_getn).\n *\n * Helper functions are used: grow() grows the file descriptor array as\n * necessary when large fd's come in. reassociate() takes care of maintaining\n * the proper file-descriptor/event-port associations.\n *\n * As in the select(2) implementation, signals are handled by evsignal.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_EVENT_PORTS\n\n#include <sys/time.h>\n#include <sys/queue.h>\n#include <errno.h>\n#include <poll.h>\n#include <port.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n#include <unistd.h>\n\n#include \"event2/thread.h\"\n\n#include \"evthread-internal.h\"\n#include \"event-internal.h\"\n#include \"log-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"evmap-internal.h\"\n\n#define INITIAL_EVENTS_PER_GETN 8\n#define MAX_EVENTS_PER_GETN 4096\n\n/*\n * Per-file-descriptor information about what events we're subscribed to. These\n * fields are NULL if no event is subscribed to either of them.\n */\n\nstruct fd_info {\n\t/* combinations of EV_READ and EV_WRITE */\n\tshort fdi_what;\n\t/* Index of this fd within ed_pending, plus 1.  Zero if this fd is\n\t * not in ed_pending.  (The +1 is a hack so that memset(0) will set\n\t * it to a nil index. */\n\tint pending_idx_plus_1;\n};\n\n#define FDI_HAS_READ(fdi)  ((fdi)->fdi_what & EV_READ)\n#define FDI_HAS_WRITE(fdi) ((fdi)->fdi_what & EV_WRITE)\n#define FDI_HAS_EVENTS(fdi) (FDI_HAS_READ(fdi) || FDI_HAS_WRITE(fdi))\n#define FDI_TO_SYSEVENTS(fdi) (FDI_HAS_READ(fdi) ? POLLIN : 0) | \\\n    (FDI_HAS_WRITE(fdi) ? POLLOUT : 0)\n\nstruct evport_data {\n\tint\t\ted_port;\t/* event port for system events  */\n\t/* How many elements of ed_pending should we look at? */\n\tint ed_npending;\n\t/* How many elements are allocated in ed_pending and pevtlist? */\n\tint ed_maxevents;\n\t/* fdi's that we need to reassoc */\n\tint *ed_pending;\n\t/* storage space for incoming events. */ \n\tport_event_t *ed_pevtlist;\n\t\n};\n\nstatic void*\tevport_init(struct event_base *);\nstatic int evport_add(struct event_base *, int fd, short old, short events, void *);\nstatic int evport_del(struct event_base *, int fd, short old, short events, void *);\nstatic int\tevport_dispatch(struct event_base *, struct timeval *);\nstatic void\tevport_dealloc(struct event_base *);\nstatic int\tgrow(struct evport_data *, int min_events);\n\nconst struct eventop evportops = {\n\t\"evport\",\n\tevport_init,\n\tevport_add,\n\tevport_del,\n\tevport_dispatch,\n\tevport_dealloc,\n\t1, /* need reinit */\n\t0, /* features */\n\tsizeof(struct fd_info), /* fdinfo length */\n};\n\n/*\n * Initialize the event port implementation.\n */\n\nstatic void*\nevport_init(struct event_base *base)\n{\n\tstruct evport_data *evpd;\n\n\tif (!(evpd = mm_calloc(1, sizeof(struct evport_data))))\n\t\treturn (NULL);\n\n\tif ((evpd->ed_port = port_create()) == -1) {\n\t\tmm_free(evpd);\n\t\treturn (NULL);\n\t}\n\n\tif (grow(evpd, INITIAL_EVENTS_PER_GETN) < 0) {\n\t\tclose(evpd->ed_port);\n\t\tmm_free(evpd);\n\t\treturn NULL;\n\t}\n\t\t\n\tevpd->ed_npending = 0;\n\n\tevsig_init_(base);\n\n\treturn (evpd);\n}\n\nstatic int\ngrow(struct evport_data *data, int min_events)\n{\n\tint newsize;\n\tint *new_pending;\n\tport_event_t *new_pevtlist;\n\tif (data->ed_maxevents) {\n\t\tnewsize = data->ed_maxevents;\n\t\tdo {\n\t\t\tnewsize *= 2;\n\t\t} while (newsize < min_events);\n\t} else {\n\t\tnewsize = min_events;\n\t}\n\n\tnew_pending = mm_realloc(data->ed_pending, sizeof(int)*newsize);\n\tif (new_pending == NULL)\n\t\treturn -1;\n\tdata->ed_pending = new_pending;\n\tnew_pevtlist = mm_realloc(data->ed_pevtlist, sizeof(port_event_t)*newsize);\n\tif (new_pevtlist == NULL)\n\t\treturn -1;\n\tdata->ed_pevtlist = new_pevtlist; \n\n\tdata->ed_maxevents = newsize;\n\treturn 0;\n}\n\n#ifdef CHECK_INVARIANTS\n/*\n * Checks some basic properties about the evport_data structure. Because it\n * checks all file descriptors, this function can be expensive when the maximum\n * file descriptor ever used is rather large.\n */\n\nstatic void\ncheck_evportop(struct evport_data *evpd)\n{\n\tEVUTIL_ASSERT(evpd);\n\tEVUTIL_ASSERT(evpd->ed_port > 0);\n}\n\n/*\n * Verifies very basic integrity of a given port_event.\n */\nstatic void\ncheck_event(port_event_t* pevt)\n{\n\t/*\n\t * We've only registered for PORT_SOURCE_FD events. The only\n\t * other thing we can legitimately receive is PORT_SOURCE_ALERT,\n\t * but since we're not using port_alert either, we can assume\n\t * PORT_SOURCE_FD.\n\t */\n\tEVUTIL_ASSERT(pevt->portev_source == PORT_SOURCE_FD);\n}\n\n#else\n#define check_evportop(epop)\n#define check_event(pevt)\n#endif /* CHECK_INVARIANTS */\n\n/*\n * (Re)associates the given file descriptor with the event port. The OS events\n * are specified (implicitly) from the fd_info struct.\n */\nstatic int\nreassociate(struct evport_data *epdp, struct fd_info *fdip, int fd)\n{\n\tint sysevents = FDI_TO_SYSEVENTS(fdip);\n\n\tif (sysevents != 0) {\n\t\tif (port_associate(epdp->ed_port, PORT_SOURCE_FD,\n\t\t\t\t   fd, sysevents, fdip) == -1) {\n\t\t\tevent_warn(\"port_associate\");\n\t\t\treturn (-1);\n\t\t}\n\t}\n\n\tcheck_evportop(epdp);\n\n\treturn (0);\n}\n\n/*\n * Main event loop - polls port_getn for some number of events, and processes\n * them.\n */\n\nstatic int\nevport_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tint i, res;\n\tstruct evport_data *epdp = base->evbase;\n\tport_event_t *pevtlist = epdp->ed_pevtlist;\n\n\t/*\n\t * port_getn will block until it has at least nevents events. It will\n\t * also return how many it's given us (which may be more than we asked\n\t * for, as long as it's less than our maximum (ed_maxevents)) in\n\t * nevents.\n\t */\n\tint nevents = 1;\n\n\t/*\n\t * We have to convert a struct timeval to a struct timespec\n\t * (only difference is nanoseconds vs. microseconds). If no time-based\n\t * events are active, we should wait for I/O (and tv == NULL).\n\t */\n\tstruct timespec ts;\n\tstruct timespec *ts_p = NULL;\n\tif (tv != NULL) {\n\t\tts.tv_sec = tv->tv_sec;\n\t\tts.tv_nsec = tv->tv_usec * 1000;\n\t\tts_p = &ts;\n\t}\n\n\t/*\n\t * Before doing anything else, we need to reassociate the events we hit\n\t * last time which need reassociation. See comment at the end of the\n\t * loop below.\n\t */\n\tfor (i = 0; i < epdp->ed_npending; ++i) {\n\t\tstruct fd_info *fdi = NULL;\n\t\tconst int fd = epdp->ed_pending[i];\n\t\tif (fd != -1) {\n\t\t\t/* We might have cleared out this event; we need\n\t\t\t * to be sure that it's still set. */\n\t\t\tfdi = evmap_io_get_fdinfo_(&base->io, fd);\n\t\t}\n\n\t\tif (fdi != NULL && FDI_HAS_EVENTS(fdi)) {\n\t\t\treassociate(epdp, fdi, fd);\n\t\t\t/* epdp->ed_pending[i] = -1; */\n\t\t\tfdi->pending_idx_plus_1 = 0;\n\t\t}\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\tres = port_getn(epdp->ed_port, pevtlist, epdp->ed_maxevents,\n\t    (unsigned int *) &nevents, ts_p);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (res == -1) {\n\t\tif (errno == EINTR || errno == EAGAIN) {\n\t\t\treturn (0);\n\t\t} else if (errno == ETIME) {\n\t\t\tif (nevents == 0)\n\t\t\t\treturn (0);\n\t\t} else {\n\t\t\tevent_warn(\"port_getn\");\n\t\t\treturn (-1);\n\t\t}\n\t}\n\n\tevent_debug((\"%s: port_getn reports %d events\", __func__, nevents));\n\n\tfor (i = 0; i < nevents; ++i) {\n\t\tport_event_t *pevt = &pevtlist[i];\n\t\tint fd = (int) pevt->portev_object;\n\t\tstruct fd_info *fdi = pevt->portev_user;\n\t\t/*EVUTIL_ASSERT(evmap_io_get_fdinfo_(&base->io, fd) == fdi);*/\n\n\t\tcheck_evportop(epdp);\n\t\tcheck_event(pevt);\n\t\tepdp->ed_pending[i] = fd;\n\t\tfdi->pending_idx_plus_1 = i + 1;\n\n\t\t/*\n\t\t * Figure out what kind of event it was\n\t\t * (because we have to pass this to the callback)\n\t\t */\n\t\tres = 0;\n\t\tif (pevt->portev_events & (POLLERR|POLLHUP)) {\n\t\t\tres = EV_READ | EV_WRITE;\n\t\t} else {\n\t\t\tif (pevt->portev_events & POLLIN)\n\t\t\t\tres |= EV_READ;\n\t\t\tif (pevt->portev_events & POLLOUT)\n\t\t\t\tres |= EV_WRITE;\n\t\t}\n\n\t\t/*\n\t\t * Check for the error situations or a hangup situation\n\t\t */\n\t\tif (pevt->portev_events & (POLLERR|POLLHUP|POLLNVAL))\n\t\t\tres |= EV_READ|EV_WRITE;\n\n\t\tevmap_io_active_(base, fd, res);\n\t} /* end of all events gotten */\n\tepdp->ed_npending = nevents;\n\n\tif (nevents == epdp->ed_maxevents &&\n\t    epdp->ed_maxevents < MAX_EVENTS_PER_GETN) {\n\t\t/* we used all the space this time.  We should be ready\n\t\t * for more events next time around. */\n\t\tgrow(epdp, epdp->ed_maxevents * 2);\n\t}\n\n\tcheck_evportop(epdp);\n\n\treturn (0);\n}\n\n\n/*\n * Adds the given event (so that you will be notified when it happens via\n * the callback function).\n */\n\nstatic int\nevport_add(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct evport_data *evpd = base->evbase;\n\tstruct fd_info *fdi = p;\n\n\tcheck_evportop(evpd);\n\n\tfdi->fdi_what |= events;\n\n\treturn reassociate(evpd, fdi, fd);\n}\n\n/*\n * Removes the given event from the list of events to wait for.\n */\n\nstatic int\nevport_del(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct evport_data *evpd = base->evbase;\n\tstruct fd_info *fdi = p;\n\tint associated = ! fdi->pending_idx_plus_1;\n\n\tcheck_evportop(evpd);\n\n\tfdi->fdi_what &= ~(events &(EV_READ|EV_WRITE));\n\n\tif (associated) {\n\t\tif (!FDI_HAS_EVENTS(fdi) &&\n\t\t    port_dissociate(evpd->ed_port, PORT_SOURCE_FD, fd) == -1) {\n\t\t\t/*\n\t\t\t * Ignore EBADFD error the fd could have been closed\n\t\t\t * before event_del() was called.\n\t\t\t */\n\t\t\tif (errno != EBADFD) {\n\t\t\t\tevent_warn(\"port_dissociate\");\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t} else {\n\t\t\tif (FDI_HAS_EVENTS(fdi)) {\n\t\t\t\treturn (reassociate(evpd, fdi, fd));\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif ((fdi->fdi_what & (EV_READ|EV_WRITE)) == 0) {\n\t\t\tconst int i = fdi->pending_idx_plus_1 - 1;\n\t\t\tEVUTIL_ASSERT(evpd->ed_pending[i] == fd);\n\t\t\tevpd->ed_pending[i] = -1;\n\t\t\tfdi->pending_idx_plus_1 = 0;\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nstatic void\nevport_dealloc(struct event_base *base)\n{\n\tstruct evport_data *evpd = base->evbase;\n\n\tevsig_dealloc_(base);\n\n\tclose(evpd->ed_port);\n\n\tif (evpd->ed_pending)\n\t\tmm_free(evpd->ed_pending);\n\tif (evpd->ed_pevtlist)\n\t\tmm_free(evpd->ed_pevtlist);\n\n\tmm_free(evpd);\n}\n\n#endif /* EVENT__HAVE_EVENT_PORTS */\n"
        },
        {
          "name": "evrpc-internal.h",
          "type": "blob",
          "size": 5.5732421875,
          "content": "/*\n * Copyright (c) 2006-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVRPC_INTERNAL_H_INCLUDED_\n#define EVRPC_INTERNAL_H_INCLUDED_\n\n#include \"event2/http.h\"\n#include \"http-internal.h\"\n\nstruct evrpc;\nstruct evrpc_request_wrapper;\n\n#define EVRPC_URI_PREFIX \"/.rpc.\"\n\nstruct evrpc_hook {\n\tTAILQ_ENTRY(evrpc_hook) next;\n\n\t/* returns EVRPC_TERMINATE; if the rpc should be aborted.\n\t * a hook is allowed to rewrite the evbuffer\n\t */\n\tint (*process)(void *, struct evhttp_request *,\n\t    struct evbuffer *, void *);\n\tvoid *process_arg;\n};\n\nTAILQ_HEAD(evrpc_hook_list, evrpc_hook);\n\n/*\n * this is shared between the base and the pool, so that we can reuse\n * the hook adding functions; we alias both evrpc_pool and evrpc_base\n * to this common structure.\n */\n\nstruct evrpc_hook_ctx;\nTAILQ_HEAD(evrpc_pause_list, evrpc_hook_ctx);\n\nstruct evrpc_hooks_ {\n\t/* hooks for processing outbound and inbound rpcs */\n\tstruct evrpc_hook_list in_hooks;\n\tstruct evrpc_hook_list out_hooks;\n\n\tstruct evrpc_pause_list pause_requests;\n};\n\n#define input_hooks common.in_hooks\n#define output_hooks common.out_hooks\n#define paused_requests common.pause_requests\n\nstruct evrpc_base {\n\tstruct evrpc_hooks_ common;\n\n\t/* the HTTP server under which we register our RPC calls */\n\tstruct evhttp* http_server;\n\n\t/* a list of all RPCs registered with us */\n\tTAILQ_HEAD(evrpc_list, evrpc) registered_rpcs;\n};\n\nstruct evrpc_req_generic;\nvoid evrpc_reqstate_free_(struct evrpc_req_generic* rpc_state);\n\n/* A pool for holding evhttp_connection objects */\nstruct evrpc_pool {\n\tstruct evrpc_hooks_ common;\n\n\tstruct event_base *base;\n\n\tstruct evconq connections;\n\n\tint timeout;\n\n\tTAILQ_HEAD(evrpc_requestq, evrpc_request_wrapper) (requests);\n};\n\nstruct evrpc_hook_ctx {\n\tTAILQ_ENTRY(evrpc_hook_ctx) next;\n\n\tvoid *ctx;\n\tvoid (*cb)(void *, enum EVRPC_HOOK_RESULT);\n};\n\nstruct evrpc_meta {\n\tTAILQ_ENTRY(evrpc_meta) next;\n\tchar *key;\n\n\tvoid *data;\n\tsize_t data_size;\n};\n\nTAILQ_HEAD(evrpc_meta_list, evrpc_meta);\n\nstruct evrpc_hook_meta {\n\tstruct evrpc_meta_list meta_data;\n\tstruct evhttp_connection *evcon;\n};\n\n/* allows association of meta data with a request */\nstatic int evrpc_hook_associate_meta_(struct evrpc_hook_meta **pctx,\n    struct evhttp_connection *evcon);\n\n/* creates a new meta data store */\nstatic struct evrpc_hook_meta *evrpc_hook_meta_new_(void);\n\n/* frees the meta data associated with a request */\nstatic void evrpc_hook_context_free_(struct evrpc_hook_meta *ctx);\n\n/* the server side of an rpc */\n\n/* We alias the RPC specific structs to this voided one */\nstruct evrpc_req_generic {\n\t/*\n\t * allows association of meta data via hooks - needs to be\n\t * synchronized with evrpc_request_wrapper\n\t */\n\tstruct evrpc_hook_meta *hook_meta;\n\n\t/* the unmarshaled request object */\n\tvoid *request;\n\n\t/* the empty reply object that needs to be filled in */\n\tvoid *reply;\n\n\t/*\n\t * the static structure for this rpc; that can be used to\n\t * automatically unmarshal and marshal the http buffers.\n\t */\n\tstruct evrpc *rpc;\n\n\t/*\n\t * the http request structure on which we need to answer.\n\t */\n\tstruct evhttp_request* http_req;\n\n\t/*\n\t * Temporary data store for marshaled data\n\t */\n\tstruct evbuffer* rpc_data;\n};\n\n/* the client side of an rpc request */\nstruct evrpc_request_wrapper {\n\t/*\n\t * allows association of meta data via hooks - needs to be\n\t * synchronized with evrpc_req_generic.\n\t */\n\tstruct evrpc_hook_meta *hook_meta;\n\n\tTAILQ_ENTRY(evrpc_request_wrapper) next;\n\n\t/* pool on which this rpc request is being made */\n\tstruct evrpc_pool *pool;\n\n\t/* connection on which the request is being sent */\n\tstruct evhttp_connection *evcon;\n\n\t/* the actual  request */\n\tstruct evhttp_request *req;\n\n\t/* event for implementing request timeouts */\n\tstruct event ev_timeout;\n\n\t/* the name of the rpc */\n\tchar *name;\n\n\t/* callback */\n\tvoid (*cb)(struct evrpc_status*, void *request, void *reply, void *arg);\n\tvoid *cb_arg;\n\n\tvoid *request;\n\tvoid *reply;\n\n\t/* unmarshals the buffer into the proper request structure */\n\tvoid (*request_marshal)(struct evbuffer *, void *);\n\n\t/* removes all stored state in the reply */\n\tvoid (*reply_clear)(void *);\n\n\t/* marshals the reply into a buffer */\n\tint (*reply_unmarshal)(void *, struct evbuffer*);\n};\n\n#endif /* EVRPC_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "evrpc.c",
          "type": "blob",
          "size": 29.0576171875,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#define WIN32_LEAN_AND_MEAN\n#include <winsock2.h>\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n\n#include <sys/types.h>\n#ifndef _WIN32\n#include <sys/socket.h>\n#endif\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <stdio.h>\n#include <stdlib.h>\n#ifndef _WIN32\n#include <unistd.h>\n#endif\n#include <errno.h>\n#include <signal.h>\n#include <string.h>\n\n#include <sys/queue.h>\n\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/rpc.h\"\n#include \"event2/rpc_struct.h\"\n#include \"evrpc-internal.h\"\n#include \"event2/http.h\"\n#include \"event2/buffer.h\"\n#include \"event2/tag.h\"\n#include \"event2/http_struct.h\"\n#include \"event2/http_compat.h\"\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n\nstruct evrpc_base *\nevrpc_init(struct evhttp *http_server)\n{\n\tstruct evrpc_base* base = mm_calloc(1, sizeof(struct evrpc_base));\n\tif (base == NULL)\n\t\treturn (NULL);\n\n\t/* we rely on the tagging sub system */\n\tevtag_init();\n\n\tTAILQ_INIT(&base->registered_rpcs);\n\tTAILQ_INIT(&base->input_hooks);\n\tTAILQ_INIT(&base->output_hooks);\n\n\tTAILQ_INIT(&base->paused_requests);\n\n\tbase->http_server = http_server;\n\n\treturn (base);\n}\n\nvoid\nevrpc_free(struct evrpc_base *base)\n{\n\tstruct evrpc *rpc;\n\tstruct evrpc_hook *hook;\n\tstruct evrpc_hook_ctx *pause;\n\tint r;\n\n\twhile ((rpc = TAILQ_FIRST(&base->registered_rpcs)) != NULL) {\n\t\tr = evrpc_unregister_rpc(base, rpc->uri);\n\t\tEVUTIL_ASSERT(r == 0);\n\t}\n\twhile ((pause = TAILQ_FIRST(&base->paused_requests)) != NULL) {\n\t\tTAILQ_REMOVE(&base->paused_requests, pause, next);\n\t\tmm_free(pause);\n\t}\n\twhile ((hook = TAILQ_FIRST(&base->input_hooks)) != NULL) {\n\t\tr = evrpc_remove_hook(base, EVRPC_INPUT, hook);\n\t\tEVUTIL_ASSERT(r);\n\t}\n\twhile ((hook = TAILQ_FIRST(&base->output_hooks)) != NULL) {\n\t\tr = evrpc_remove_hook(base, EVRPC_OUTPUT, hook);\n\t\tEVUTIL_ASSERT(r);\n\t}\n\tmm_free(base);\n}\n\nvoid *\nevrpc_add_hook(void *vbase,\n    enum EVRPC_HOOK_TYPE hook_type,\n    int (*cb)(void *, struct evhttp_request *, struct evbuffer *, void *),\n    void *cb_arg)\n{\n\tstruct evrpc_hooks_ *base = vbase;\n\tstruct evrpc_hook_list *head = NULL;\n\tstruct evrpc_hook *hook = NULL;\n\tswitch (hook_type) {\n\tcase EVRPC_INPUT:\n\t\thead = &base->in_hooks;\n\t\tbreak;\n\tcase EVRPC_OUTPUT:\n\t\thead = &base->out_hooks;\n\t\tbreak;\n\tdefault:\n\t\tEVUTIL_ASSERT(hook_type == EVRPC_INPUT || hook_type == EVRPC_OUTPUT);\n\t\treturn NULL;\n\t}\n\n\thook = mm_calloc(1, sizeof(struct evrpc_hook));\n\tif (!hook)\n\t\treturn NULL;\n\n\thook->process = cb;\n\thook->process_arg = cb_arg;\n\tTAILQ_INSERT_TAIL(head, hook, next);\n\n\treturn (hook);\n}\n\nstatic int\nevrpc_remove_hook_internal(struct evrpc_hook_list *head, void *handle)\n{\n\tstruct evrpc_hook *hook = NULL;\n\tTAILQ_FOREACH(hook, head, next) {\n\t\tif (hook == handle) {\n\t\t\tTAILQ_REMOVE(head, hook, next);\n\t\t\tmm_free(hook);\n\t\t\treturn (1);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\n/*\n * remove the hook specified by the handle\n */\n\nint\nevrpc_remove_hook(void *vbase, enum EVRPC_HOOK_TYPE hook_type, void *handle)\n{\n\tstruct evrpc_hooks_ *base = vbase;\n\tstruct evrpc_hook_list *head = NULL;\n\tswitch (hook_type) {\n\tcase EVRPC_INPUT:\n\t\thead = &base->in_hooks;\n\t\tbreak;\n\tcase EVRPC_OUTPUT:\n\t\thead = &base->out_hooks;\n\t\tbreak;\n\tdefault:\n\t\tEVUTIL_ASSERT(hook_type == EVRPC_INPUT || hook_type == EVRPC_OUTPUT);\n\t}\n\n\treturn (evrpc_remove_hook_internal(head, handle));\n}\n\nstatic int\nevrpc_process_hooks(struct evrpc_hook_list *head, void *ctx,\n    struct evhttp_request *req, struct evbuffer *evbuf)\n{\n\tstruct evrpc_hook *hook;\n\tTAILQ_FOREACH(hook, head, next) {\n\t\tint res = hook->process(ctx, req, evbuf, hook->process_arg);\n\t\tif (res != EVRPC_CONTINUE)\n\t\t\treturn (res);\n\t}\n\n\treturn (EVRPC_CONTINUE);\n}\n\nstatic void evrpc_pool_schedule(struct evrpc_pool *pool);\nstatic void evrpc_request_cb(struct evhttp_request *, void *);\n\n/*\n * Registers a new RPC with the HTTP server.   The evrpc object is expected\n * to have been filled in via the EVRPC_REGISTER_OBJECT macro which in turn\n * calls this function.\n */\n\nstatic char *\nevrpc_construct_uri(const char *uri)\n{\n\tchar *constructed_uri;\n\tsize_t constructed_uri_len;\n\n\tconstructed_uri_len = strlen(EVRPC_URI_PREFIX) + strlen(uri) + 1;\n\tif ((constructed_uri = mm_malloc(constructed_uri_len)) == NULL)\n\t\tevent_err(1, \"%s: failed to register rpc at %s\",\n\t\t    __func__, uri);\n\tmemcpy(constructed_uri, EVRPC_URI_PREFIX, strlen(EVRPC_URI_PREFIX));\n\tmemcpy(constructed_uri + strlen(EVRPC_URI_PREFIX), uri, strlen(uri));\n\tconstructed_uri[constructed_uri_len - 1] = '\\0';\n\n\treturn (constructed_uri);\n}\n\nint\nevrpc_register_rpc(struct evrpc_base *base, struct evrpc *rpc,\n    void (*cb)(struct evrpc_req_generic *, void *), void *cb_arg)\n{\n\tchar *constructed_uri = evrpc_construct_uri(rpc->uri);\n\n\trpc->base = base;\n\trpc->cb = cb;\n\trpc->cb_arg = cb_arg;\n\n\tTAILQ_INSERT_TAIL(&base->registered_rpcs, rpc, next);\n\n\tevhttp_set_cb(base->http_server,\n\t    constructed_uri,\n\t    evrpc_request_cb,\n\t    rpc);\n\n\tmm_free(constructed_uri);\n\n\treturn (0);\n}\n\nint\nevrpc_unregister_rpc(struct evrpc_base *base, const char *name)\n{\n\tchar *registered_uri = NULL;\n\tstruct evrpc *rpc;\n\tint r;\n\n\t/* find the right rpc; linear search might be slow */\n\tTAILQ_FOREACH(rpc, &base->registered_rpcs, next) {\n\t\tif (strcmp(rpc->uri, name) == 0)\n\t\t\tbreak;\n\t}\n\tif (rpc == NULL) {\n\t\t/* We did not find an RPC with this name */\n\t\treturn (-1);\n\t}\n\tTAILQ_REMOVE(&base->registered_rpcs, rpc, next);\n\n\tregistered_uri = evrpc_construct_uri(name);\n\n\t/* remove the http server callback */\n\tr = evhttp_del_cb(base->http_server, registered_uri);\n\tEVUTIL_ASSERT(r == 0);\n\n\tmm_free(registered_uri);\n\n\tmm_free((char *)rpc->uri);\n\tmm_free(rpc);\n\treturn (0);\n}\n\nstatic int evrpc_pause_request(void *vbase, void *ctx,\n    void (*cb)(void *, enum EVRPC_HOOK_RESULT));\nstatic void evrpc_request_cb_closure(void *, enum EVRPC_HOOK_RESULT);\n\nstatic void\nevrpc_request_cb(struct evhttp_request *req, void *arg)\n{\n\tstruct evrpc *rpc = arg;\n\tstruct evrpc_req_generic *rpc_state = NULL;\n\n\t/* let's verify the outside parameters */\n\tif (req->type != EVHTTP_REQ_POST ||\n\t    evbuffer_get_length(req->input_buffer) <= 0)\n\t\tgoto error;\n\n\trpc_state = mm_calloc(1, sizeof(struct evrpc_req_generic));\n\tif (rpc_state == NULL)\n\t\tgoto error;\n\trpc_state->rpc = rpc;\n\trpc_state->http_req = req;\n\trpc_state->rpc_data = NULL;\n\n\tif (TAILQ_FIRST(&rpc->base->input_hooks) != NULL) {\n\t\tint hook_res;\n\n\t\tint err = evrpc_hook_associate_meta_(&rpc_state->hook_meta, req->evcon);\n\t\tif (err)\n\t\t\tgoto error;\n\n\t\t/*\n\t\t * allow hooks to modify the outgoing request\n\t\t */\n\t\thook_res = evrpc_process_hooks(&rpc->base->input_hooks,\n\t\t    rpc_state, req, req->input_buffer);\n\t\tswitch (hook_res) {\n\t\tcase EVRPC_TERMINATE:\n\t\t\tgoto error;\n\t\tcase EVRPC_PAUSE:\n\t\t\tevrpc_pause_request(rpc->base, rpc_state,\n\t\t\t    evrpc_request_cb_closure);\n\t\t\treturn;\n\t\tcase EVRPC_CONTINUE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tEVUTIL_ASSERT(hook_res == EVRPC_TERMINATE ||\n\t\t\t    hook_res == EVRPC_CONTINUE ||\n\t\t\t    hook_res == EVRPC_PAUSE);\n\t\t}\n\t}\n\n\tevrpc_request_cb_closure(rpc_state, EVRPC_CONTINUE);\n\treturn;\n\nerror:\n\tif (rpc_state)\n\t\tevrpc_reqstate_free_(rpc_state);\n\tevhttp_send_error(req, HTTP_SERVUNAVAIL, NULL);\n\treturn;\n}\n\nstatic void\nevrpc_request_cb_closure(void *arg, enum EVRPC_HOOK_RESULT hook_res)\n{\n\tstruct evrpc_req_generic *rpc_state = arg;\n\tstruct evrpc *rpc;\n\tstruct evhttp_request *req;\n\n\tEVUTIL_ASSERT(rpc_state);\n\trpc = rpc_state->rpc;\n\treq = rpc_state->http_req;\n\n\tif (hook_res == EVRPC_TERMINATE)\n\t\tgoto error;\n\n\t/* let's check that we can parse the request */\n\trpc_state->request = rpc->request_new(rpc->request_new_arg);\n\tif (rpc_state->request == NULL)\n\t\tgoto error;\n\n\tif (rpc->request_unmarshal(\n\t\t    rpc_state->request, req->input_buffer) == -1) {\n\t\t/* we failed to parse the request; that's a bummer */\n\t\tgoto error;\n\t}\n\n\t/* at this point, we have a well formed request, prepare the reply */\n\n\trpc_state->reply = rpc->reply_new(rpc->reply_new_arg);\n\tif (rpc_state->reply == NULL)\n\t\tgoto error;\n\n\t/* give the rpc to the user; they can deal with it */\n\trpc->cb(rpc_state, rpc->cb_arg);\n\n\treturn;\n\nerror:\n\tevrpc_reqstate_free_(rpc_state);\n\tevhttp_send_error(req, HTTP_SERVUNAVAIL, NULL);\n\treturn;\n}\n\n\nvoid\nevrpc_reqstate_free_(struct evrpc_req_generic* rpc_state)\n{\n\tstruct evrpc *rpc;\n\tEVUTIL_ASSERT(rpc_state != NULL);\n\trpc = rpc_state->rpc;\n\n\t/* clean up all memory */\n\tif (rpc_state->hook_meta != NULL)\n\t\tevrpc_hook_context_free_(rpc_state->hook_meta);\n\tif (rpc_state->request != NULL)\n\t\trpc->request_free(rpc_state->request);\n\tif (rpc_state->reply != NULL)\n\t\trpc->reply_free(rpc_state->reply);\n\tif (rpc_state->rpc_data != NULL)\n\t\tevbuffer_free(rpc_state->rpc_data);\n\tmm_free(rpc_state);\n}\n\nstatic void\nevrpc_request_done_closure(void *, enum EVRPC_HOOK_RESULT);\n\nvoid\nevrpc_request_done(struct evrpc_req_generic *rpc_state)\n{\n\tstruct evhttp_request *req;\n\tstruct evrpc *rpc;\n\n\tEVUTIL_ASSERT(rpc_state);\n\n\treq = rpc_state->http_req;\n\trpc = rpc_state->rpc;\n\n\tif (rpc->reply_complete(rpc_state->reply) == -1) {\n\t\t/* the reply was not completely filled in.  error out */\n\t\tgoto error;\n\t}\n\n\tif ((rpc_state->rpc_data = evbuffer_new()) == NULL) {\n\t\t/* out of memory */\n\t\tgoto error;\n\t}\n\n\t/* serialize the reply */\n\trpc->reply_marshal(rpc_state->rpc_data, rpc_state->reply);\n\n\tif (TAILQ_FIRST(&rpc->base->output_hooks) != NULL) {\n\t\tint hook_res;\n\n\t\tint err = evrpc_hook_associate_meta_(&rpc_state->hook_meta, req->evcon);\n\t\tif (err)\n\t\t\tgoto error;\n\n\t\t/* do hook based tweaks to the request */\n\t\thook_res = evrpc_process_hooks(&rpc->base->output_hooks,\n\t\t    rpc_state, req, rpc_state->rpc_data);\n\t\tswitch (hook_res) {\n\t\tcase EVRPC_TERMINATE:\n\t\t\tgoto error;\n\t\tcase EVRPC_PAUSE:\n\t\t\tif (evrpc_pause_request(rpc->base, rpc_state,\n\t\t\t\tevrpc_request_done_closure) == -1)\n\t\t\t\tgoto error;\n\t\t\treturn;\n\t\tcase EVRPC_CONTINUE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tEVUTIL_ASSERT(hook_res == EVRPC_TERMINATE ||\n\t\t\t    hook_res == EVRPC_CONTINUE ||\n\t\t\t    hook_res == EVRPC_PAUSE);\n\t\t}\n\t}\n\n\tevrpc_request_done_closure(rpc_state, EVRPC_CONTINUE);\n\treturn;\n\nerror:\n\tevrpc_reqstate_free_(rpc_state);\n\tevhttp_send_error(req, HTTP_SERVUNAVAIL, NULL);\n\treturn;\n}\n\nvoid *\nevrpc_get_request(struct evrpc_req_generic *req)\n{\n\treturn req->request;\n}\n\nvoid *\nevrpc_get_reply(struct evrpc_req_generic *req)\n{\n\treturn req->reply;\n}\n\nstatic void\nevrpc_request_done_closure(void *arg, enum EVRPC_HOOK_RESULT hook_res)\n{\n\tstruct evrpc_req_generic *rpc_state = arg;\n\tstruct evhttp_request *req;\n\tEVUTIL_ASSERT(rpc_state);\n\treq = rpc_state->http_req;\n\n\tif (hook_res == EVRPC_TERMINATE)\n\t\tgoto error;\n\n\t/* on success, we are going to transmit marshaled binary data */\n\tif (evhttp_find_header(req->output_headers, \"Content-Type\") == NULL) {\n\t\tevhttp_add_header(req->output_headers,\n\t\t    \"Content-Type\", \"application/octet-stream\");\n\t}\n\tevhttp_send_reply(req, HTTP_OK, \"OK\", rpc_state->rpc_data);\n\n\tevrpc_reqstate_free_(rpc_state);\n\n\treturn;\n\nerror:\n\tevrpc_reqstate_free_(rpc_state);\n\tevhttp_send_error(req, HTTP_SERVUNAVAIL, NULL);\n\treturn;\n}\n\n\n/* Client implementation of RPC site */\n\nstatic int evrpc_schedule_request(struct evhttp_connection *connection,\n    struct evrpc_request_wrapper *ctx);\n\nstruct evrpc_pool *\nevrpc_pool_new(struct event_base *base)\n{\n\tstruct evrpc_pool *pool = mm_calloc(1, sizeof(struct evrpc_pool));\n\tif (pool == NULL)\n\t\treturn (NULL);\n\n\tTAILQ_INIT(&pool->connections);\n\tTAILQ_INIT(&pool->requests);\n\n\tTAILQ_INIT(&pool->paused_requests);\n\n\tTAILQ_INIT(&pool->input_hooks);\n\tTAILQ_INIT(&pool->output_hooks);\n\n\tpool->base = base;\n\tpool->timeout = -1;\n\n\treturn (pool);\n}\n\nstatic void\nevrpc_request_wrapper_free(struct evrpc_request_wrapper *request)\n{\n\tif (request->hook_meta != NULL)\n\t\tevrpc_hook_context_free_(request->hook_meta);\n\tmm_free(request->name);\n\tmm_free(request);\n}\n\nvoid\nevrpc_pool_free(struct evrpc_pool *pool)\n{\n\tstruct evhttp_connection *connection;\n\tstruct evrpc_request_wrapper *request;\n\tstruct evrpc_hook_ctx *pause;\n\tstruct evrpc_hook *hook;\n\tint r;\n\n\twhile ((request = TAILQ_FIRST(&pool->requests)) != NULL) {\n\t\tTAILQ_REMOVE(&pool->requests, request, next);\n\t\tevrpc_request_wrapper_free(request);\n\t}\n\n\twhile ((pause = TAILQ_FIRST(&pool->paused_requests)) != NULL) {\n\t\tTAILQ_REMOVE(&pool->paused_requests, pause, next);\n\t\tmm_free(pause);\n\t}\n\n\twhile ((connection = TAILQ_FIRST(&pool->connections)) != NULL) {\n\t\tTAILQ_REMOVE(&pool->connections, connection, next);\n\t\tevhttp_connection_free(connection);\n\t}\n\n\twhile ((hook = TAILQ_FIRST(&pool->input_hooks)) != NULL) {\n\t\tr = evrpc_remove_hook(pool, EVRPC_INPUT, hook);\n\t\tEVUTIL_ASSERT(r);\n\t}\n\n\twhile ((hook = TAILQ_FIRST(&pool->output_hooks)) != NULL) {\n\t\tr = evrpc_remove_hook(pool, EVRPC_OUTPUT, hook);\n\t\tEVUTIL_ASSERT(r);\n\t}\n\n\tmm_free(pool);\n}\n\n/*\n * Add a connection to the RPC pool.   A request scheduled on the pool\n * may use any available connection.\n */\n\nvoid\nevrpc_pool_add_connection(struct evrpc_pool *pool,\n    struct evhttp_connection *connection)\n{\n\tEVUTIL_ASSERT(connection->http_server == NULL);\n\tTAILQ_INSERT_TAIL(&pool->connections, connection, next);\n\n\t/*\n\t * associate an event base with this connection\n\t */\n\tif (pool->base != NULL)\n\t\tevhttp_connection_set_base(connection, pool->base);\n\n\t/*\n\t * unless a timeout was specifically set for a connection,\n\t * the connection inherits the timeout from the pool.\n\t */\n\tif (!(connection->flags & EVHTTP_CON_TIMEOUT_ADJUSTED))\n\t\tevhttp_connection_set_timeout(connection, pool->timeout);\n\n\t/*\n\t * if we have any requests pending, schedule them with the new\n\t * connections.\n\t */\n\n\tif (TAILQ_FIRST(&pool->requests) != NULL) {\n\t\tstruct evrpc_request_wrapper *request =\n\t\t    TAILQ_FIRST(&pool->requests);\n\t\tTAILQ_REMOVE(&pool->requests, request, next);\n\t\tevrpc_schedule_request(connection, request);\n\t}\n}\n\nvoid\nevrpc_pool_remove_connection(struct evrpc_pool *pool,\n    struct evhttp_connection *connection)\n{\n\tTAILQ_REMOVE(&pool->connections, connection, next);\n}\n\nvoid\nevrpc_pool_set_timeout(struct evrpc_pool *pool, int timeout_in_secs)\n{\n\tstruct evhttp_connection *evcon;\n\tTAILQ_FOREACH(evcon, &pool->connections, next) {\n\t\tevhttp_connection_set_timeout(evcon, timeout_in_secs);\n\t}\n\tpool->timeout = timeout_in_secs;\n}\n\n\nstatic void evrpc_reply_done(struct evhttp_request *, void *);\nstatic void evrpc_request_timeout(evutil_socket_t, short, void *);\n\n/*\n * Finds a connection object associated with the pool that is currently\n * idle and can be used to make a request.\n */\nstatic struct evhttp_connection *\nevrpc_pool_find_connection(struct evrpc_pool *pool)\n{\n\tstruct evhttp_connection *connection;\n\tTAILQ_FOREACH(connection, &pool->connections, next) {\n\t\tif (TAILQ_FIRST(&connection->requests) == NULL)\n\t\t\treturn (connection);\n\t}\n\n\treturn (NULL);\n}\n\n/*\n * Prototypes responsible for evrpc scheduling and hooking\n */\n\nstatic void evrpc_schedule_request_closure(void *ctx, enum EVRPC_HOOK_RESULT);\n\n/*\n * We assume that the ctx is no longer queued on the pool.\n */\nstatic int\nevrpc_schedule_request(struct evhttp_connection *connection,\n    struct evrpc_request_wrapper *ctx)\n{\n\tstruct evhttp_request *req = NULL;\n\tstruct evrpc_pool *pool = ctx->pool;\n\tstruct evrpc_status status;\n\n\tif ((req = evhttp_request_new(evrpc_reply_done, ctx)) == NULL)\n\t\tgoto error;\n\n\t/* serialize the request data into the output buffer */\n\tctx->request_marshal(req->output_buffer, ctx->request);\n\n\t/* we need to know the connection that we might have to abort */\n\tctx->evcon = connection;\n\n\t/* if we get paused we also need to know the request */\n\tctx->req = req;\n\n\tif (TAILQ_FIRST(&pool->output_hooks) != NULL) {\n\t\tint hook_res;\n\n\t\tint err = evrpc_hook_associate_meta_(&ctx->hook_meta, connection);\n\t\tif (err)\n\t\t\tgoto error;\n\n\t\t/* apply hooks to the outgoing request */\n\t\thook_res = evrpc_process_hooks(&pool->output_hooks,\n\t\t    ctx, req, req->output_buffer);\n\n\t\tswitch (hook_res) {\n\t\tcase EVRPC_TERMINATE:\n\t\t\tgoto error;\n\t\tcase EVRPC_PAUSE:\n\t\t\t/* we need to be explicitly resumed */\n\t\t\tif (evrpc_pause_request(pool, ctx,\n\t\t\t\tevrpc_schedule_request_closure) == -1)\n\t\t\t\tgoto error;\n\t\t\treturn (0);\n\t\tcase EVRPC_CONTINUE:\n\t\t\t/* we can just continue */\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tEVUTIL_ASSERT(hook_res == EVRPC_TERMINATE ||\n\t\t\t    hook_res == EVRPC_CONTINUE ||\n\t\t\t    hook_res == EVRPC_PAUSE);\n\t\t}\n\t}\n\n\tevrpc_schedule_request_closure(ctx, EVRPC_CONTINUE);\n\treturn (0);\n\nerror:\n\tmemset(&status, 0, sizeof(status));\n\tstatus.error = EVRPC_STATUS_ERR_UNSTARTED;\n\t(*ctx->cb)(&status, ctx->request, ctx->reply, ctx->cb_arg);\n\tevrpc_request_wrapper_free(ctx);\n\treturn (-1);\n}\n\nstatic void\nevrpc_schedule_request_closure(void *arg, enum EVRPC_HOOK_RESULT hook_res)\n{\n\tstruct evrpc_request_wrapper *ctx = arg;\n\tstruct evhttp_connection *connection = ctx->evcon;\n\tstruct evhttp_request *req = ctx->req;\n\tstruct evrpc_pool *pool = ctx->pool;\n\tstruct evrpc_status status;\n\tchar *uri = NULL;\n\tint res = 0;\n\n\tif (hook_res == EVRPC_TERMINATE)\n\t\tgoto error;\n\n\turi = evrpc_construct_uri(ctx->name);\n\tif (uri == NULL)\n\t\tgoto error;\n\n\tif (pool->timeout > 0) {\n\t\t/*\n\t\t * a timeout after which the whole rpc is going to be aborted.\n\t\t */\n\t\tstruct timeval tv;\n\t\tevutil_timerclear(&tv);\n\t\ttv.tv_sec = pool->timeout;\n\t\tevtimer_add(&ctx->ev_timeout, &tv);\n\t}\n\n\t/* start the request over the connection */\n\tres = evhttp_make_request(connection, req, EVHTTP_REQ_POST, uri);\n\tmm_free(uri);\n\n\tif (res == -1)\n\t\tgoto error;\n\n\treturn;\n\nerror:\n\tmemset(&status, 0, sizeof(status));\n\tstatus.error = EVRPC_STATUS_ERR_UNSTARTED;\n\t(*ctx->cb)(&status, ctx->request, ctx->reply, ctx->cb_arg);\n\tevrpc_request_wrapper_free(ctx);\n}\n\n/* we just queue the paused request on the pool under the req object */\nstatic int\nevrpc_pause_request(void *vbase, void *ctx,\n    void (*cb)(void *, enum EVRPC_HOOK_RESULT))\n{\n\tstruct evrpc_hooks_ *base = vbase;\n\tstruct evrpc_hook_ctx *pause = mm_malloc(sizeof(*pause));\n\tif (pause == NULL)\n\t\treturn (-1);\n\n\tpause->ctx = ctx;\n\tpause->cb = cb;\n\n\tTAILQ_INSERT_TAIL(&base->pause_requests, pause, next);\n\treturn (0);\n}\n\nint\nevrpc_resume_request(void *vbase, void *ctx, enum EVRPC_HOOK_RESULT res)\n{\n\tstruct evrpc_hooks_ *base = vbase;\n\tstruct evrpc_pause_list *head = &base->pause_requests;\n\tstruct evrpc_hook_ctx *pause;\n\n\tTAILQ_FOREACH(pause, head, next) {\n\t\tif (pause->ctx == ctx)\n\t\t\tbreak;\n\t}\n\n\tif (pause == NULL)\n\t\treturn (-1);\n\n\t(*pause->cb)(pause->ctx, res);\n\tTAILQ_REMOVE(head, pause, next);\n\tmm_free(pause);\n\treturn (0);\n}\n\nint\nevrpc_make_request(struct evrpc_request_wrapper *ctx)\n{\n\tstruct evrpc_pool *pool = ctx->pool;\n\n\t/* initialize the event structure for this rpc */\n\tevtimer_assign(&ctx->ev_timeout, pool->base, evrpc_request_timeout, ctx);\n\n\t/* we better have some available connections on the pool */\n\tEVUTIL_ASSERT(TAILQ_FIRST(&pool->connections) != NULL);\n\n\t/*\n\t * if no connection is available, we queue the request on the pool,\n\t * the next time a connection is empty, the rpc will be send on that.\n\t */\n\tTAILQ_INSERT_TAIL(&pool->requests, ctx, next);\n\n\tevrpc_pool_schedule(pool);\n\n\treturn (0);\n}\n\n\nstruct evrpc_request_wrapper *\nevrpc_make_request_ctx(\n\tstruct evrpc_pool *pool, void *request, void *reply,\n\tconst char *rpcname,\n\tvoid (*req_marshal)(struct evbuffer*, void *),\n\tvoid (*rpl_clear)(void *),\n\tint (*rpl_unmarshal)(void *, struct evbuffer *),\n\tvoid (*cb)(struct evrpc_status *, void *, void *, void *),\n\tvoid *cbarg)\n{\n\tstruct evrpc_request_wrapper *ctx = (struct evrpc_request_wrapper *)\n\t    mm_malloc(sizeof(struct evrpc_request_wrapper));\n\tif (ctx == NULL)\n\t\treturn (NULL);\n\n\tctx->pool = pool;\n\tctx->hook_meta = NULL;\n\tctx->evcon = NULL;\n\tctx->name = mm_strdup(rpcname);\n\tif (ctx->name == NULL) {\n\t\tmm_free(ctx);\n\t\treturn (NULL);\n\t}\n\tctx->cb = cb;\n\tctx->cb_arg = cbarg;\n\tctx->request = request;\n\tctx->reply = reply;\n\tctx->request_marshal = req_marshal;\n\tctx->reply_clear = rpl_clear;\n\tctx->reply_unmarshal = rpl_unmarshal;\n\n\treturn (ctx);\n}\n\nstatic void\nevrpc_reply_done_closure(void *, enum EVRPC_HOOK_RESULT);\n\nstatic void\nevrpc_reply_done(struct evhttp_request *req, void *arg)\n{\n\tstruct evrpc_request_wrapper *ctx = arg;\n\tstruct evrpc_pool *pool = ctx->pool;\n\tint hook_res = EVRPC_CONTINUE;\n\n\t/* cancel any timeout we might have scheduled */\n\tevent_del(&ctx->ev_timeout);\n\n\tctx->req = req;\n\n\t/* we need to get the reply now */\n\tif (req == NULL) {\n\t\tevrpc_reply_done_closure(ctx, EVRPC_CONTINUE);\n\t\treturn;\n\t}\n\n\tif (TAILQ_FIRST(&pool->input_hooks) != NULL) {\n\t\tint err = evrpc_hook_associate_meta_(&ctx->hook_meta, ctx->evcon);\n\t\tif (err)\n\t\t\tgoto error;\n\n\t\t/* apply hooks to the incoming request */\n\t\thook_res = evrpc_process_hooks(&pool->input_hooks,\n\t\t    ctx, req, req->input_buffer);\n\n\t\tswitch (hook_res) {\n\t\tcase EVRPC_TERMINATE:\n\t\tcase EVRPC_CONTINUE:\n\t\t\tbreak;\n\t\tcase EVRPC_PAUSE:\n\t\t\t/*\n\t\t\t * if we get paused we also need to know the\n\t\t\t * request.  unfortunately, the underlying\n\t\t\t * layer is going to free it.  we need to\n\t\t\t * request ownership explicitly\n\t\t\t */\n\t\t\tevhttp_request_own(req);\n\n\t\t\tevrpc_pause_request(pool, ctx,\n\t\t\t    evrpc_reply_done_closure);\n\t\t\treturn;\n\t\tdefault:\n\t\t\tEVUTIL_ASSERT(hook_res == EVRPC_TERMINATE ||\n\t\t\t    hook_res == EVRPC_CONTINUE ||\n\t\t\t    hook_res == EVRPC_PAUSE);\n\t\t}\n\t}\n\n\tevrpc_reply_done_closure(ctx, hook_res);\n\treturn;\n\t/* http request is being freed by underlying layer */\n\nerror:\n\tevrpc_request_wrapper_free(ctx);\n}\n\nstatic void\nevrpc_reply_done_closure(void *arg, enum EVRPC_HOOK_RESULT hook_res)\n{\n\tstruct evrpc_request_wrapper *ctx = arg;\n\tstruct evhttp_request *req = ctx->req;\n\tstruct evrpc_pool *pool = ctx->pool;\n\tstruct evrpc_status status;\n\tint res = -1;\n\n\tmemset(&status, 0, sizeof(status));\n\tstatus.http_req = req;\n\n\t/* we need to get the reply now */\n\tif (req == NULL) {\n\t\tstatus.error = EVRPC_STATUS_ERR_TIMEOUT;\n\t} else if (hook_res == EVRPC_TERMINATE) {\n\t\tstatus.error = EVRPC_STATUS_ERR_HOOKABORTED;\n\t} else {\n\t\tres = ctx->reply_unmarshal(ctx->reply, req->input_buffer);\n\t\tif (res == -1)\n\t\t\tstatus.error = EVRPC_STATUS_ERR_BADPAYLOAD;\n\t}\n\n\tif (res == -1) {\n\t\t/* clear everything that we might have written previously */\n\t\tctx->reply_clear(ctx->reply);\n\t}\n\n\t(*ctx->cb)(&status, ctx->request, ctx->reply, ctx->cb_arg);\n\n\tevrpc_request_wrapper_free(ctx);\n\n\t/* the http layer owned the original request structure, but if we\n\t * got paused, we asked for ownership and need to free it here. */\n\tif (req != NULL && evhttp_request_is_owned(req))\n\t\tevhttp_request_free(req);\n\n\t/* see if we can schedule another request */\n\tevrpc_pool_schedule(pool);\n}\n\nstatic void\nevrpc_pool_schedule(struct evrpc_pool *pool)\n{\n\tstruct evrpc_request_wrapper *ctx = TAILQ_FIRST(&pool->requests);\n\tstruct evhttp_connection *evcon;\n\n\t/* if no requests are pending, we have no work */\n\tif (ctx == NULL)\n\t\treturn;\n\n\tif ((evcon = evrpc_pool_find_connection(pool)) != NULL) {\n\t\tTAILQ_REMOVE(&pool->requests, ctx, next);\n\t\tevrpc_schedule_request(evcon, ctx);\n\t}\n}\n\nstatic void\nevrpc_request_timeout(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct evrpc_request_wrapper *ctx = arg;\n\tstruct evhttp_connection *evcon = ctx->evcon;\n\tEVUTIL_ASSERT(evcon != NULL);\n\n\tevhttp_connection_fail_(evcon, EVREQ_HTTP_TIMEOUT);\n}\n\n/*\n * frees potential meta data associated with a request.\n */\n\nstatic void\nevrpc_meta_data_free(struct evrpc_meta_list *meta_data)\n{\n\tstruct evrpc_meta *entry;\n\n\tif (!meta_data)\n\t\treturn;\n\n\twhile ((entry = TAILQ_FIRST(meta_data)) != NULL) {\n\t\tTAILQ_REMOVE(meta_data, entry, next);\n\t\tmm_free(entry->key);\n\t\tmm_free(entry->data);\n\t\tmm_free(entry);\n\t}\n}\n\nstatic struct evrpc_hook_meta *\nevrpc_hook_meta_new_(void)\n{\n\tstruct evrpc_hook_meta *ctx;\n\tctx = mm_malloc(sizeof(struct evrpc_hook_meta));\n\tif (!ctx)\n\t\treturn NULL;\n\n\tTAILQ_INIT(&ctx->meta_data);\n\tctx->evcon = NULL;\n\n\treturn (ctx);\n}\n\nstatic int\nevrpc_hook_associate_meta_(struct evrpc_hook_meta **pctx,\n    struct evhttp_connection *evcon)\n{\n\tstruct evrpc_hook_meta *ctx = *pctx;\n\tif (ctx == NULL)\n\t\t*pctx = ctx = evrpc_hook_meta_new_();\n\tif (!ctx)\n\t\treturn 1;\n\tctx->evcon = evcon;\n\treturn 0;\n}\n\nstatic void\nevrpc_hook_context_free_(struct evrpc_hook_meta *ctx)\n{\n\tevrpc_meta_data_free(&ctx->meta_data);\n\tmm_free(ctx);\n}\n\n/* Adds meta data */\nint\nevrpc_hook_add_meta(void *ctx, const char *key,\n    const void *data, size_t data_size)\n{\n\tstruct evrpc_request_wrapper *req = ctx;\n\tstruct evrpc_hook_meta *store = NULL;\n\tstruct evrpc_meta *meta = NULL;\n\n\tif ((store = req->hook_meta) == NULL)\n\t\tstore = req->hook_meta = evrpc_hook_meta_new_();\n\n\tif (!store)\n\t\tgoto err;\n\n\tmeta = mm_malloc(sizeof(struct evrpc_meta));\n\tif (!meta)\n\t\tgoto err;\n\tmeta->key = mm_strdup(key);\n\tif (!meta->key)\n\t\tgoto err;\n\tmeta->data_size = data_size;\n\tmeta->data = mm_malloc(data_size);\n\tif (!meta->data)\n\t\tgoto err;\n\tmemcpy(meta->data, data, data_size);\n\n\tTAILQ_INSERT_TAIL(&store->meta_data, meta, next);\n\treturn 0;\n\nerr:\n\tevrpc_hook_context_free_(store);\n\tif (meta) {\n\t\tmm_free(meta->data);\n\t\tmm_free(meta->key);\n\t\tmm_free(meta);\n\t}\n\treturn 1;\n}\n\nint\nevrpc_hook_find_meta(void *ctx, const char *key, void **data, size_t *data_size)\n{\n\tstruct evrpc_request_wrapper *req = ctx;\n\tstruct evrpc_meta *meta = NULL;\n\n\tif (req->hook_meta == NULL)\n\t\treturn (-1);\n\n\tTAILQ_FOREACH(meta, &req->hook_meta->meta_data, next) {\n\t\tif (strcmp(meta->key, key) == 0) {\n\t\t\t*data = meta->data;\n\t\t\t*data_size = meta->data_size;\n\t\t\treturn (0);\n\t\t}\n\t}\n\n\treturn (-1);\n}\n\nstruct evhttp_connection *\nevrpc_hook_get_connection(void *ctx)\n{\n\tstruct evrpc_request_wrapper *req = ctx;\n\treturn (req->hook_meta != NULL ? req->hook_meta->evcon : NULL);\n}\n\nint\nevrpc_send_request_generic(struct evrpc_pool *pool,\n    void *request, void *reply,\n    void (*cb)(struct evrpc_status *, void *, void *, void *),\n    void *cb_arg,\n    const char *rpcname,\n    void (*req_marshal)(struct evbuffer *, void *),\n    void (*rpl_clear)(void *),\n    int (*rpl_unmarshal)(void *, struct evbuffer *))\n{\n\tstruct evrpc_status status;\n\tstruct evrpc_request_wrapper *ctx;\n\tctx = evrpc_make_request_ctx(pool, request, reply,\n\t    rpcname, req_marshal, rpl_clear, rpl_unmarshal, cb, cb_arg);\n\tif (ctx == NULL)\n\t\tgoto error;\n\treturn (evrpc_make_request(ctx));\nerror:\n\tmemset(&status, 0, sizeof(status));\n\tstatus.error = EVRPC_STATUS_ERR_UNSTARTED;\n\t(*(cb))(&status, request, reply, cb_arg);\n\treturn (-1);\n}\n\n/** Takes a request object and fills it in with the right magic */\nstatic struct evrpc *\nevrpc_register_object(const char *name,\n    void *(*req_new)(void*), void *req_new_arg, void (*req_free)(void *),\n    int (*req_unmarshal)(void *, struct evbuffer *),\n    void *(*rpl_new)(void*), void *rpl_new_arg, void (*rpl_free)(void *),\n    int (*rpl_complete)(void *),\n    void (*rpl_marshal)(struct evbuffer *, void *))\n{\n\tstruct evrpc* rpc = (struct evrpc *)mm_calloc(1, sizeof(struct evrpc));\n\tif (rpc == NULL)\n\t\treturn (NULL);\n\trpc->uri = mm_strdup(name);\n\tif (rpc->uri == NULL) {\n\t\tmm_free(rpc);\n\t\treturn (NULL);\n\t}\n\trpc->request_new = req_new;\n\trpc->request_new_arg = req_new_arg;\n\trpc->request_free = req_free;\n\trpc->request_unmarshal = req_unmarshal;\n\trpc->reply_new = rpl_new;\n\trpc->reply_new_arg = rpl_new_arg;\n\trpc->reply_free = rpl_free;\n\trpc->reply_complete = rpl_complete;\n\trpc->reply_marshal = rpl_marshal;\n\treturn (rpc);\n}\n\nint\nevrpc_register_generic(struct evrpc_base *base, const char *name,\n    void (*callback)(struct evrpc_req_generic *, void *), void *cbarg,\n    void *(*req_new)(void *), void *req_new_arg, void (*req_free)(void *),\n    int (*req_unmarshal)(void *, struct evbuffer *),\n    void *(*rpl_new)(void *), void *rpl_new_arg, void (*rpl_free)(void *),\n    int (*rpl_complete)(void *),\n    void (*rpl_marshal)(struct evbuffer *, void *))\n{\n\tstruct evrpc* rpc =\n\t    evrpc_register_object(name, req_new, req_new_arg, req_free, req_unmarshal,\n\t\trpl_new, rpl_new_arg, rpl_free, rpl_complete, rpl_marshal);\n\tif (rpc == NULL)\n\t\treturn (-1);\n\tevrpc_register_rpc(base, rpc,\n\t    (void (*)(struct evrpc_req_generic*, void *))callback, cbarg);\n\treturn (0);\n}\n\n/** accessors for obscure and undocumented functionality */\nstruct evrpc_pool *\nevrpc_request_get_pool(struct evrpc_request_wrapper *ctx)\n{\n\treturn (ctx->pool);\n}\n\nvoid\nevrpc_request_set_pool(struct evrpc_request_wrapper *ctx,\n    struct evrpc_pool *pool)\n{\n\tctx->pool = pool;\n}\n\nvoid\nevrpc_request_set_cb(struct evrpc_request_wrapper *ctx,\n    void (*cb)(struct evrpc_status*, void *request, void *reply, void *arg),\n    void *cb_arg)\n{\n\tctx->cb = cb;\n\tctx->cb_arg = cb_arg;\n}\n"
        },
        {
          "name": "evsignal-internal.h",
          "type": "blob",
          "size": 2.9833984375,
          "content": "/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVSIGNAL_INTERNAL_H_INCLUDED_\n#define EVSIGNAL_INTERNAL_H_INCLUDED_\n\n#ifndef evutil_socket_t\n#include \"event2/util.h\"\n#endif\n#include <signal.h>\n\ntypedef void (*ev_sighandler_t)(int);\n\n/* Data structure for the default signal-handling implementation in signal.c\n */\nstruct evsig_info {\n\t/* Event watching ev_signal_pair[1] */\n\tstruct event ev_signal;\n\t/* Socketpair used to send notifications from the signal handler */\n\tevutil_socket_t ev_signal_pair[2];\n\t/* True iff we've added the ev_signal event yet. */\n\tint ev_signal_added;\n\t/* Count of the number of signals we're currently watching. */\n\tint ev_n_signals_added;\n#ifdef EVENT__HAVE_SYS_SIGNALFD_H\n\t/* EV_READ events used to wakeup corresponding EV_SIGNAL ones. */\n\tstruct event *ev_sigevent[NSIG];\n#endif /* EVENT__HAVE_SYS_SIGNALFD_H */\n\n\t/* Array of previous signal handler objects before Libevent started\n\t * messing with them.  Used to restore old signal handlers. */\n#ifdef EVENT__HAVE_SIGACTION\n\tstruct sigaction **sh_old;\n#else\n\tev_sighandler_t **sh_old;\n#endif\n\t/* Size of sh_old. */\n\tint sh_old_max;\n};\n\n#ifdef EVENT__HAVE_SYS_SIGNALFD_H\nint sigfd_init_(struct event_base *);\n#else /* no signalfd() */\nstatic inline int\nsigfd_init_(struct event_base *base) { return -1; }\n#endif /* have signalfd() */\n\nint evsig_init_(struct event_base *);\nvoid evsig_dealloc_(struct event_base *);\nint evsig_ensure_saved_(struct evsig_info *, int);\n\nvoid evsig_set_base_(struct event_base *base);\nvoid evsig_free_globals_(void);\n\n#endif /* EVSIGNAL_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "evthread-internal.h",
          "type": "blob",
          "size": 14.30078125,
          "content": "/*\n * Copyright (c) 2008-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef EVTHREAD_INTERNAL_H_INCLUDED_\n#define EVTHREAD_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include \"event2/thread.h\"\n#include \"util-internal.h\"\n\nstruct event_base;\n\n#if !defined(_WIN32) && !defined(__CYGWIN__)\n/* On Windows, the way we currently make DLLs, it's not allowed for us to\n * have shared global structures.  Thus, we only do the direct-call-to-function\n * code path if we know that the local shared library system supports it.\n */\n#define EVTHREAD_EXPOSE_STRUCTS\n#endif\n\n#if ! defined(EVENT__DISABLE_THREAD_SUPPORT) && defined(EVTHREAD_EXPOSE_STRUCTS)\n/* Global function pointers to lock-related functions. NULL if locking isn't\n   enabled. */\nEVENT2_EXPORT_SYMBOL\nextern struct evthread_lock_callbacks evthread_lock_fns_;\nEVENT2_EXPORT_SYMBOL\nextern struct evthread_condition_callbacks evthread_cond_fns_;\nextern unsigned long (*evthread_id_fn_)(void);\nEVENT2_EXPORT_SYMBOL\nextern int evthread_lock_debugging_enabled_;\n\n/** Return the ID of the current thread, or 1 if threading isn't enabled. */\n#define EVTHREAD_GET_ID() \\\n\t(evthread_id_fn_ ? evthread_id_fn_() : 1)\n\n/** Return true iff we're in the thread that is currently (or most recently)\n * running a given event_base's loop. Requires lock. */\n#define EVBASE_IN_THREAD(base)\t\t\t\t \\\n\t(evthread_id_fn_ == NULL ||\t\t\t \\\n\t(base)->th_owner_id == evthread_id_fn_())\n\n/** Return true iff we need to notify the base's main thread about changes to\n * its state, because it's currently running the main loop in another\n * thread. Requires lock. */\n#define EVBASE_NEED_NOTIFY(base)\t\t\t \\\n\t(evthread_id_fn_ != NULL &&\t\t\t \\\n\t    (base)->running_loop &&\t\t\t \\\n\t    (base)->th_owner_id != evthread_id_fn_())\n\n/** Allocate a new lock, and store it in lockvar, a void*.  Sets lockvar to\n    NULL if locking is not enabled. */\n#define EVTHREAD_ALLOC_LOCK(lockvar, locktype)\t\t\\\n\t((lockvar) = evthread_lock_fns_.alloc ?\t\t\\\n\t    evthread_lock_fns_.alloc(locktype) : NULL)\n\n/** Free a given lock, if it is present and locking is enabled. */\n#define EVTHREAD_FREE_LOCK(lockvar, locktype)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tvoid *lock_tmp_ = (lockvar);\t\t\t\t\\\n\t\tif (lock_tmp_ && evthread_lock_fns_.free)\t\t\\\n\t\t\tevthread_lock_fns_.free(lock_tmp_, (locktype)); \\\n\t} while (0)\n\n/** Acquire a lock. */\n#define EVLOCK_LOCK(lockvar,mode)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar)\t\t\t\t\t\t\\\n\t\t\tevthread_lock_fns_.lock(mode, lockvar);\t\t\\\n\t} while (0)\n\n/** Release a lock */\n#define EVLOCK_UNLOCK(lockvar,mode)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar)\t\t\t\t\t\t\\\n\t\t\tevthread_lock_fns_.unlock(mode, lockvar);\t\\\n\t} while (0)\n\n/** Helper: put lockvar1 and lockvar2 into pointerwise ascending order. */\n#define EVLOCK_SORTLOCKS_(lockvar1, lockvar2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar1 && lockvar2 && lockvar1 > lockvar2) {\t\\\n\t\t\tvoid *tmp = lockvar1;\t\t\t\t\\\n\t\t\tlockvar1 = lockvar2;\t\t\t\t\\\n\t\t\tlockvar2 = tmp;\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n/** Lock an event_base, if it is set up for locking.  Acquires the lock\n    in the base structure whose field is named 'lockvar'. */\n#define EVBASE_ACQUIRE_LOCK(base, lockvar) do {\t\t\t\t\\\n\t\tEVLOCK_LOCK((base)->lockvar, 0);\t\t\t\\\n\t} while (0)\n\n/** Unlock an event_base, if it is set up for locking. */\n#define EVBASE_RELEASE_LOCK(base, lockvar) do {\t\t\t\t\\\n\t\tEVLOCK_UNLOCK((base)->lockvar, 0);\t\t\t\\\n\t} while (0)\n\n/** If lock debugging is enabled, and lock is non-null, assert that 'lock' is\n * locked and held by us. */\n#define EVLOCK_ASSERT_LOCKED(lock)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif ((lock) && evthread_lock_debugging_enabled_) {\t\\\n\t\t\tEVUTIL_ASSERT(evthread_is_debug_lock_held_(lock)); \\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n/** Try to grab the lock for 'lockvar' without blocking, and return 1 if we\n * manage to get it. */\nstatic inline int EVLOCK_TRY_LOCK_(void *lock);\nstatic inline int\nEVLOCK_TRY_LOCK_(void *lock)\n{\n\tif (lock && evthread_lock_fns_.lock) {\n\t\tint r = evthread_lock_fns_.lock(EVTHREAD_TRY, lock);\n\t\treturn !r;\n\t} else {\n\t\t/* Locking is disabled either globally or for this thing;\n\t\t * of course we count as having the lock. */\n\t\treturn 1;\n\t}\n}\n\n/** Allocate a new condition variable and store it in the void *, condvar */\n#define EVTHREAD_ALLOC_COND(condvar)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\t(condvar) = evthread_cond_fns_.alloc_condition ?\t\\\n\t\t    evthread_cond_fns_.alloc_condition(0) : NULL;\t\\\n\t} while (0)\n/** Deallocate and free a condition variable in condvar */\n#define EVTHREAD_FREE_COND(cond)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (cond)\t\t\t\t\t\t\\\n\t\t\tevthread_cond_fns_.free_condition((cond));\t\\\n\t} while (0)\n/** Signal one thread waiting on cond */\n#define EVTHREAD_COND_SIGNAL(cond)\t\t\t\t\t\\\n\t( (cond) ? evthread_cond_fns_.signal_condition((cond), 0) : 0 )\n/** Signal all threads waiting on cond */\n#define EVTHREAD_COND_BROADCAST(cond)\t\t\t\t\t\\\n\t( (cond) ? evthread_cond_fns_.signal_condition((cond), 1) : 0 )\n/** Wait until the condition 'cond' is signalled.  Must be called while\n * holding 'lock'.  The lock will be released until the condition is\n * signalled, at which point it will be acquired again.  Returns 0 for\n * success, -1 for failure. */\n#define EVTHREAD_COND_WAIT(cond, lock)\t\t\t\t\t\\\n\t( (cond) ? evthread_cond_fns_.wait_condition((cond), (lock), NULL) : 0 )\n/** As EVTHREAD_COND_WAIT, but gives up after 'tv' has elapsed.  Returns 1\n * on timeout. */\n#define EVTHREAD_COND_WAIT_TIMED(cond, lock, tv)\t\t\t\\\n\t( (cond) ? evthread_cond_fns_.wait_condition((cond), (lock), (tv)) : 0 )\n\n/** True iff locking functions have been configured. */\n#define EVTHREAD_LOCKING_ENABLED()\t\t\\\n\t(evthread_lock_fns_.lock != NULL)\n\n#elif ! defined(EVENT__DISABLE_THREAD_SUPPORT)\n\nunsigned long evthreadimpl_get_id_(void);\nEVENT2_EXPORT_SYMBOL\nint evthreadimpl_is_lock_debugging_enabled_(void);\nEVENT2_EXPORT_SYMBOL\nvoid *evthreadimpl_lock_alloc_(unsigned locktype);\nEVENT2_EXPORT_SYMBOL\nvoid evthreadimpl_lock_free_(void *lock, unsigned locktype);\nEVENT2_EXPORT_SYMBOL\nint evthreadimpl_lock_lock_(unsigned mode, void *lock);\nEVENT2_EXPORT_SYMBOL\nint evthreadimpl_lock_unlock_(unsigned mode, void *lock);\nEVENT2_EXPORT_SYMBOL\nvoid *evthreadimpl_cond_alloc_(unsigned condtype);\nEVENT2_EXPORT_SYMBOL\nvoid evthreadimpl_cond_free_(void *cond);\nEVENT2_EXPORT_SYMBOL\nint evthreadimpl_cond_signal_(void *cond, int broadcast);\nEVENT2_EXPORT_SYMBOL\nint evthreadimpl_cond_wait_(void *cond, void *lock, const struct timeval *tv);\nint evthreadimpl_locking_enabled_(void);\n\n#define EVTHREAD_GET_ID() evthreadimpl_get_id_()\n#define EVBASE_IN_THREAD(base)\t\t\t\t\\\n\t((base)->th_owner_id == evthreadimpl_get_id_())\n#define EVBASE_NEED_NOTIFY(base)\t\t\t \\\n\t((base)->running_loop &&\t\t\t \\\n\t    ((base)->th_owner_id != evthreadimpl_get_id_()))\n\n#define EVTHREAD_ALLOC_LOCK(lockvar, locktype)\t\t\\\n\t((lockvar) = evthreadimpl_lock_alloc_(locktype))\n\n#define EVTHREAD_FREE_LOCK(lockvar, locktype)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tvoid *lock_tmp_ = (lockvar);\t\t\t\t\\\n\t\tif (lock_tmp_)\t\t\t\t\t\t\\\n\t\t\tevthreadimpl_lock_free_(lock_tmp_, (locktype)); \\\n\t} while (0)\n\n/** Acquire a lock. */\n#define EVLOCK_LOCK(lockvar,mode)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar)\t\t\t\t\t\t\\\n\t\t\tevthreadimpl_lock_lock_(mode, lockvar);\t\t\\\n\t} while (0)\n\n/** Release a lock */\n#define EVLOCK_UNLOCK(lockvar,mode)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar)\t\t\t\t\t\t\\\n\t\t\tevthreadimpl_lock_unlock_(mode, lockvar);\t\\\n\t} while (0)\n\n/** Lock an event_base, if it is set up for locking.  Acquires the lock\n    in the base structure whose field is named 'lockvar'. */\n#define EVBASE_ACQUIRE_LOCK(base, lockvar) do {\t\t\t\t\\\n\t\tEVLOCK_LOCK((base)->lockvar, 0);\t\t\t\\\n\t} while (0)\n\n/** Unlock an event_base, if it is set up for locking. */\n#define EVBASE_RELEASE_LOCK(base, lockvar) do {\t\t\t\t\\\n\t\tEVLOCK_UNLOCK((base)->lockvar, 0);\t\t\t\\\n\t} while (0)\n\n/** If lock debugging is enabled, and lock is non-null, assert that 'lock' is\n * locked and held by us. */\n#define EVLOCK_ASSERT_LOCKED(lock)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif ((lock) && evthreadimpl_is_lock_debugging_enabled_()) { \\\n\t\t\tEVUTIL_ASSERT(evthread_is_debug_lock_held_(lock)); \\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n/** Try to grab the lock for 'lockvar' without blocking, and return 1 if we\n * manage to get it. */\nstatic inline int EVLOCK_TRY_LOCK_(void *lock);\nstatic inline int\nEVLOCK_TRY_LOCK_(void *lock)\n{\n\tif (lock) {\n\t\tint r = evthreadimpl_lock_lock_(EVTHREAD_TRY, lock);\n\t\treturn !r;\n\t} else {\n\t\t/* Locking is disabled either globally or for this thing;\n\t\t * of course we count as having the lock. */\n\t\treturn 1;\n\t}\n}\n\n/** Allocate a new condition variable and store it in the void *, condvar */\n#define EVTHREAD_ALLOC_COND(condvar)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\t(condvar) = evthreadimpl_cond_alloc_(0);\t\t\\\n\t} while (0)\n/** Deallocate and free a condition variable in condvar */\n#define EVTHREAD_FREE_COND(cond)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (cond)\t\t\t\t\t\t\\\n\t\t\tevthreadimpl_cond_free_((cond));\t\t\\\n\t} while (0)\n/** Signal one thread waiting on cond */\n#define EVTHREAD_COND_SIGNAL(cond)\t\t\t\t\t\\\n\t( (cond) ? evthreadimpl_cond_signal_((cond), 0) : 0 )\n/** Signal all threads waiting on cond */\n#define EVTHREAD_COND_BROADCAST(cond)\t\t\t\t\t\\\n\t( (cond) ? evthreadimpl_cond_signal_((cond), 1) : 0 )\n/** Wait until the condition 'cond' is signalled.  Must be called while\n * holding 'lock'.  The lock will be released until the condition is\n * signalled, at which point it will be acquired again.  Returns 0 for\n * success, -1 for failure. */\n#define EVTHREAD_COND_WAIT(cond, lock)\t\t\t\t\t\\\n\t( (cond) ? evthreadimpl_cond_wait_((cond), (lock), NULL) : 0 )\n/** As EVTHREAD_COND_WAIT, but gives up after 'tv' has elapsed.  Returns 1\n * on timeout. */\n#define EVTHREAD_COND_WAIT_TIMED(cond, lock, tv)\t\t\t\\\n\t( (cond) ? evthreadimpl_cond_wait_((cond), (lock), (tv)) : 0 )\n\n#define EVTHREAD_LOCKING_ENABLED()\t\t\\\n\t(evthreadimpl_locking_enabled_())\n\n#else /* EVENT__DISABLE_THREAD_SUPPORT */\n\n#define EVTHREAD_GET_ID()\t1\n#define EVTHREAD_ALLOC_LOCK(lockvar, locktype) EVUTIL_NIL_STMT_\n#define EVTHREAD_FREE_LOCK(lockvar, locktype) EVUTIL_NIL_STMT_\n\n#define EVLOCK_LOCK(lockvar, mode) EVUTIL_NIL_STMT_\n#define EVLOCK_UNLOCK(lockvar, mode) EVUTIL_NIL_STMT_\n#define EVLOCK_LOCK2(lock1,lock2,mode1,mode2) EVUTIL_NIL_STMT_\n#define EVLOCK_UNLOCK2(lock1,lock2,mode1,mode2) EVUTIL_NIL_STMT_\n\n#define EVBASE_IN_THREAD(base)\t1\n#define EVBASE_NEED_NOTIFY(base) 0\n#define EVBASE_ACQUIRE_LOCK(base, lock) (void)(base)\n#define EVBASE_RELEASE_LOCK(base, lock) (void)(base)\n#define EVLOCK_ASSERT_LOCKED(lock) EVUTIL_NIL_STMT_\n\n#define EVLOCK_TRY_LOCK_(lock) 1\n\n#define EVTHREAD_ALLOC_COND(condvar) EVUTIL_NIL_STMT_\n#define EVTHREAD_FREE_COND(cond) EVUTIL_NIL_STMT_\n#define EVTHREAD_COND_SIGNAL(cond) EVUTIL_NIL_STMT_\n#define EVTHREAD_COND_BROADCAST(cond) EVUTIL_NIL_STMT_\n#define EVTHREAD_COND_WAIT(cond, lock) EVUTIL_NIL_STMT_\n#define EVTHREAD_COND_WAIT_TIMED(cond, lock, howlong) EVUTIL_NIL_STMT_\n\n#define EVTHREAD_LOCKING_ENABLED() 0\n\n#endif\n\n/* This code is shared between both lock impls */\n#if ! defined(EVENT__DISABLE_THREAD_SUPPORT)\n/** Helper: put lockvar1 and lockvar2 into pointerwise ascending order. */\n#define EVLOCK_SORTLOCKS_(lockvar1, lockvar2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (lockvar1 && lockvar2 && lockvar1 > lockvar2) {\t\\\n\t\t\tvoid *tmp = lockvar1;\t\t\t\t\\\n\t\t\tlockvar1 = lockvar2;\t\t\t\t\\\n\t\t\tlockvar2 = tmp;\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n/** Acquire both lock1 and lock2.  Always allocates locks in the same order,\n * so that two threads locking two locks with LOCK2 will not deadlock. */\n#define EVLOCK_LOCK2(lock1,lock2,mode1,mode2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tvoid *lock1_tmplock_ = (lock1);\t\t\t\t\\\n\t\tvoid *lock2_tmplock_ = (lock2);\t\t\t\t\\\n\t\tEVLOCK_SORTLOCKS_(lock1_tmplock_,lock2_tmplock_);\t\\\n\t\tEVLOCK_LOCK(lock1_tmplock_,mode1);\t\t\t\\\n\t\tif (lock2_tmplock_ != lock1_tmplock_)\t\t\t\\\n\t\t\tEVLOCK_LOCK(lock2_tmplock_,mode2);\t\t\\\n\t} while (0)\n/** Release both lock1 and lock2.  */\n#define EVLOCK_UNLOCK2(lock1,lock2,mode1,mode2)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tvoid *lock1_tmplock_ = (lock1);\t\t\t\t\\\n\t\tvoid *lock2_tmplock_ = (lock2);\t\t\t\t\\\n\t\tEVLOCK_SORTLOCKS_(lock1_tmplock_,lock2_tmplock_);\t\\\n\t\tif (lock2_tmplock_ != lock1_tmplock_)\t\t\t\\\n\t\t\tEVLOCK_UNLOCK(lock2_tmplock_,mode2);\t\t\\\n\t\tEVLOCK_UNLOCK(lock1_tmplock_,mode1);\t\t\t\\\n\t} while (0)\n\nEVENT2_EXPORT_SYMBOL\nint evthread_is_debug_lock_held_(void *lock);\nvoid *evthread_debug_get_real_lock_(void *lock);\n\nvoid *evthread_setup_global_lock_(void *lock_, unsigned locktype,\n    int enable_locks);\n\n#define EVTHREAD_SETUP_GLOBAL_LOCK(lockvar, locktype)\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tlockvar = evthread_setup_global_lock_(lockvar,\t\t\\\n\t\t    (locktype), enable_locks);\t\t\t\t\\\n\t\tif (!lockvar) {\t\t\t\t\t\t\\\n\t\t\tevent_warn(\"Couldn't allocate %s\", #lockvar);\t\\\n\t\t\treturn -1;\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0);\n\nint event_global_setup_locks_(const int enable_locks);\nint evsig_global_setup_locks_(const int enable_locks);\nint evutil_global_setup_locks_(const int enable_locks);\nint evutil_secure_rng_global_setup_locks_(const int enable_locks);\n\n/** Return current evthread_lock_callbacks */\nEVENT2_EXPORT_SYMBOL\nstruct evthread_lock_callbacks *evthread_get_lock_callbacks(void);\n/** Return current evthread_condition_callbacks */\nstruct evthread_condition_callbacks *evthread_get_condition_callbacks(void);\n/** Disable locking for internal usage (like global shutdown) */\nvoid evthreadimpl_disable_lock_debugging_(void);\n\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* EVTHREAD_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "evthread.c",
          "type": "blob",
          "size": 13.41796875,
          "content": "/*\n * Copyright (c) 2008-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\n#include \"event2/thread.h\"\n\n#include <stdlib.h>\n#include <string.h>\n\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n#include \"evthread-internal.h\"\n\n#ifdef EVTHREAD_EXPOSE_STRUCTS\n#define GLOBAL\n#else\n#define GLOBAL static\n#endif\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\nextern int event_debug_created_threadable_ctx_;\nextern int event_debug_mode_on_;\n#endif\n\n/* globals */\nGLOBAL int evthread_lock_debugging_enabled_ = 0;\nGLOBAL struct evthread_lock_callbacks evthread_lock_fns_ = {\n\t0, 0, NULL, NULL, NULL, NULL\n};\nGLOBAL unsigned long (*evthread_id_fn_)(void) = NULL;\nGLOBAL struct evthread_condition_callbacks evthread_cond_fns_ = {\n\t0, NULL, NULL, NULL, NULL\n};\n\n/* Used for debugging */\nstatic struct evthread_lock_callbacks original_lock_fns_ = {\n\t0, 0, NULL, NULL, NULL, NULL\n};\nstatic struct evthread_condition_callbacks original_cond_fns_ = {\n\t0, NULL, NULL, NULL, NULL\n};\n\nvoid\nevthread_set_id_callback(unsigned long (*id_fn)(void))\n{\n\tevthread_id_fn_ = id_fn;\n}\n\nstruct evthread_lock_callbacks *evthread_get_lock_callbacks(void)\n{\n\treturn evthread_lock_debugging_enabled_\n\t    ? &original_lock_fns_ : &evthread_lock_fns_;\n}\nstruct evthread_condition_callbacks *evthread_get_condition_callbacks(void)\n{\n\treturn evthread_lock_debugging_enabled_\n\t    ? &original_cond_fns_ : &evthread_cond_fns_;\n}\nvoid evthreadimpl_disable_lock_debugging_(void)\n{\n\tevthread_lock_debugging_enabled_ = 0;\n}\n\nint\nevthread_set_lock_callbacks(const struct evthread_lock_callbacks *cbs)\n{\n\tstruct evthread_lock_callbacks *target = evthread_get_lock_callbacks();\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_mode_on_) {\n\t\tif (event_debug_created_threadable_ctx_) {\n\t\t    event_errx(1, \"evthread initialization must be called BEFORE anything else!\");\n\t\t}\n\t}\n#endif\n\n\tif (!cbs) {\n\t\tif (target->alloc)\n\t\t\tevent_warnx(\"Trying to disable lock functions after \"\n\t\t\t    \"they have been set up will probably not work.\");\n\t\tmemset(target, 0, sizeof(evthread_lock_fns_));\n\t\treturn 0;\n\t}\n\tif (target->alloc) {\n\t\t/* Uh oh; we already had locking callbacks set up.*/\n\t\tif (target->lock_api_version == cbs->lock_api_version &&\n\t\t\ttarget->supported_locktypes == cbs->supported_locktypes &&\n\t\t\ttarget->alloc == cbs->alloc &&\n\t\t\ttarget->free == cbs->free &&\n\t\t\ttarget->lock == cbs->lock &&\n\t\t\ttarget->unlock == cbs->unlock) {\n\t\t\t/* no change -- allow this. */\n\t\t\treturn 0;\n\t\t}\n\t\tevent_warnx(\"Can't change lock callbacks once they have been \"\n\t\t    \"initialized.\");\n\t\treturn -1;\n\t}\n\tif (cbs->alloc && cbs->free && cbs->lock && cbs->unlock) {\n\t\tmemcpy(target, cbs, sizeof(evthread_lock_fns_));\n\t\treturn event_global_setup_locks_(1);\n\t} else {\n\t\treturn -1;\n\t}\n}\n\nint\nevthread_set_condition_callbacks(const struct evthread_condition_callbacks *cbs)\n{\n\tstruct evthread_condition_callbacks *target = evthread_get_condition_callbacks();\n\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_mode_on_) {\n\t\tif (event_debug_created_threadable_ctx_) {\n\t\t    event_errx(1, \"evthread initialization must be called BEFORE anything else!\");\n\t\t}\n\t}\n#endif\n\n\tif (!cbs) {\n\t\tif (target->alloc_condition)\n\t\t\tevent_warnx(\"Trying to disable condition functions \"\n\t\t\t    \"after they have been set up will probably not \"\n\t\t\t    \"work.\");\n\t\tmemset(target, 0, sizeof(evthread_cond_fns_));\n\t\treturn 0;\n\t}\n\tif (target->alloc_condition) {\n\t\t/* Uh oh; we already had condition callbacks set up.*/\n\t\tif (target->condition_api_version == cbs->condition_api_version &&\n\t\t\ttarget->alloc_condition == cbs->alloc_condition &&\n\t\t\ttarget->free_condition == cbs->free_condition &&\n\t\t\ttarget->signal_condition == cbs->signal_condition &&\n\t\t\ttarget->wait_condition == cbs->wait_condition) {\n\t\t\t/* no change -- allow this. */\n\t\t\treturn 0;\n\t\t}\n\t\tevent_warnx(\"Can't change condition callbacks once they \"\n\t\t    \"have been initialized.\");\n\t\treturn -1;\n\t}\n\tif (cbs->alloc_condition && cbs->free_condition &&\n\t    cbs->signal_condition && cbs->wait_condition) {\n\t\tmemcpy(target, cbs, sizeof(evthread_cond_fns_));\n\t}\n\tif (evthread_lock_debugging_enabled_) {\n\t\tevthread_cond_fns_.alloc_condition = cbs->alloc_condition;\n\t\tevthread_cond_fns_.free_condition = cbs->free_condition;\n\t\tevthread_cond_fns_.signal_condition = cbs->signal_condition;\n\t}\n\treturn 0;\n}\n\n#define DEBUG_LOCK_SIG\t0xdeb0b10c\n\nstruct debug_lock {\n\tunsigned signature;\n\tunsigned locktype;\n\tunsigned long held_by;\n\t/* XXXX if we ever use read-write locks, we will need a separate\n\t * lock to protect count. */\n\tint count;\n\tvoid *lock;\n};\n\nstatic void *\ndebug_lock_alloc(unsigned locktype)\n{\n\tstruct debug_lock *result = mm_malloc(sizeof(struct debug_lock));\n\tif (!result)\n\t\treturn NULL;\n\tif (original_lock_fns_.alloc) {\n\t\tif (!(result->lock = original_lock_fns_.alloc(\n\t\t\t\tlocktype|EVTHREAD_LOCKTYPE_RECURSIVE))) {\n\t\t\tmm_free(result);\n\t\t\treturn NULL;\n\t\t}\n\t} else {\n\t\tresult->lock = NULL;\n\t}\n\tresult->signature = DEBUG_LOCK_SIG;\n\tresult->locktype = locktype;\n\tresult->count = 0;\n\tresult->held_by = 0;\n\treturn result;\n}\n\nstatic void\ndebug_lock_free(void *lock_, unsigned locktype)\n{\n\tstruct debug_lock *lock = lock_;\n\tEVUTIL_ASSERT(lock->count == 0);\n\tEVUTIL_ASSERT(locktype == lock->locktype);\n\tEVUTIL_ASSERT(DEBUG_LOCK_SIG == lock->signature);\n\tif (original_lock_fns_.free) {\n\t\toriginal_lock_fns_.free(lock->lock,\n\t\t    lock->locktype|EVTHREAD_LOCKTYPE_RECURSIVE);\n\t}\n\tlock->lock = NULL;\n\tlock->count = -100;\n\tlock->signature = 0x12300fda;\n\tmm_free(lock);\n}\n\nstatic void\nevthread_debug_lock_mark_locked(unsigned mode, struct debug_lock *lock)\n{\n\tEVUTIL_ASSERT(DEBUG_LOCK_SIG == lock->signature);\n\t++lock->count;\n\tif (!(lock->locktype & EVTHREAD_LOCKTYPE_RECURSIVE))\n\t\tEVUTIL_ASSERT(lock->count == 1);\n\tif (evthread_id_fn_) {\n\t\tunsigned long me;\n\t\tme = evthread_id_fn_();\n\t\tif (lock->count > 1)\n\t\t\tEVUTIL_ASSERT(lock->held_by == me);\n\t\tlock->held_by = me;\n\t}\n}\n\nstatic int\ndebug_lock_lock(unsigned mode, void *lock_)\n{\n\tstruct debug_lock *lock = lock_;\n\tint res = 0;\n\tif (lock->locktype & EVTHREAD_LOCKTYPE_READWRITE)\n\t\tEVUTIL_ASSERT(mode & (EVTHREAD_READ|EVTHREAD_WRITE));\n\telse\n\t\tEVUTIL_ASSERT((mode & (EVTHREAD_READ|EVTHREAD_WRITE)) == 0);\n\tif (original_lock_fns_.lock)\n\t\tres = original_lock_fns_.lock(mode, lock->lock);\n\tif (!res) {\n\t\tevthread_debug_lock_mark_locked(mode, lock);\n\t}\n\treturn res;\n}\n\nstatic void\nevthread_debug_lock_mark_unlocked(unsigned mode, struct debug_lock *lock)\n{\n\tEVUTIL_ASSERT(DEBUG_LOCK_SIG == lock->signature);\n\tif (lock->locktype & EVTHREAD_LOCKTYPE_READWRITE)\n\t\tEVUTIL_ASSERT(mode & (EVTHREAD_READ|EVTHREAD_WRITE));\n\telse\n\t\tEVUTIL_ASSERT((mode & (EVTHREAD_READ|EVTHREAD_WRITE)) == 0);\n\tif (evthread_id_fn_) {\n\t\tunsigned long me;\n\t\tme = evthread_id_fn_();\n\t\tEVUTIL_ASSERT(lock->held_by == me);\n\t\tif (lock->count == 1)\n\t\t\tlock->held_by = 0;\n\t}\n\t--lock->count;\n\tEVUTIL_ASSERT(lock->count >= 0);\n}\n\nstatic int\ndebug_lock_unlock(unsigned mode, void *lock_)\n{\n\tstruct debug_lock *lock = lock_;\n\tint res = 0;\n\tevthread_debug_lock_mark_unlocked(mode, lock);\n\tif (original_lock_fns_.unlock)\n\t\tres = original_lock_fns_.unlock(mode, lock->lock);\n\treturn res;\n}\n\nstatic int\ndebug_cond_wait(void *cond_, void *lock_, const struct timeval *tv)\n{\n\tint r;\n\tstruct debug_lock *lock = lock_;\n\tEVUTIL_ASSERT(lock);\n\tEVUTIL_ASSERT(DEBUG_LOCK_SIG == lock->signature);\n\tEVLOCK_ASSERT_LOCKED(lock_);\n\tevthread_debug_lock_mark_unlocked(0, lock);\n\tr = original_cond_fns_.wait_condition(cond_, lock->lock, tv);\n\tevthread_debug_lock_mark_locked(0, lock);\n\treturn r;\n}\n\n/* misspelled version for backward compatibility */\nvoid\nevthread_enable_lock_debuging(void)\n{\n\tevthread_enable_lock_debugging();\n}\n\nvoid\nevthread_enable_lock_debugging(void)\n{\n\tstruct evthread_lock_callbacks cbs = {\n\t\tEVTHREAD_LOCK_API_VERSION,\n\t\tEVTHREAD_LOCKTYPE_RECURSIVE,\n\t\tdebug_lock_alloc,\n\t\tdebug_lock_free,\n\t\tdebug_lock_lock,\n\t\tdebug_lock_unlock\n\t};\n\tif (evthread_lock_debugging_enabled_)\n\t\treturn;\n\tmemcpy(&original_lock_fns_, &evthread_lock_fns_,\n\t    sizeof(struct evthread_lock_callbacks));\n\tmemcpy(&evthread_lock_fns_, &cbs,\n\t    sizeof(struct evthread_lock_callbacks));\n\n\tmemcpy(&original_cond_fns_, &evthread_cond_fns_,\n\t    sizeof(struct evthread_condition_callbacks));\n\tevthread_cond_fns_.wait_condition = debug_cond_wait;\n\tevthread_lock_debugging_enabled_ = 1;\n\n\t/* XXX return value should get checked. */\n\tevent_global_setup_locks_(0);\n}\n\nint\nevthread_is_debug_lock_held_(void *lock_)\n{\n\tstruct debug_lock *lock = lock_;\n\tif (! lock->count)\n\t\treturn 0;\n\tif (evthread_id_fn_) {\n\t\tunsigned long me = evthread_id_fn_();\n\t\tif (lock->held_by != me)\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nvoid *\nevthread_debug_get_real_lock_(void *lock_)\n{\n\tstruct debug_lock *lock = lock_;\n\treturn lock->lock;\n}\n\nvoid *\nevthread_setup_global_lock_(void *lock_, unsigned locktype, int enable_locks)\n{\n\t/* there are four cases here:\n\t   1) we're turning on debugging; locking is not on.\n\t   2) we're turning on debugging; locking is on.\n\t   3) we're turning on locking; debugging is not on.\n\t   4) we're turning on locking; debugging is on. */\n\n\tif (!enable_locks && original_lock_fns_.alloc == NULL) {\n\t\t/* Case 1: allocate a debug lock. */\n\t\tEVUTIL_ASSERT(lock_ == NULL);\n\t\treturn debug_lock_alloc(locktype);\n\t} else if (!enable_locks && original_lock_fns_.alloc != NULL) {\n\t\t/* Case 2: wrap the lock in a debug lock. */\n\t\tstruct debug_lock *lock;\n\t\tEVUTIL_ASSERT(lock_ != NULL);\n\n\t\tif (!(locktype & EVTHREAD_LOCKTYPE_RECURSIVE)) {\n\t\t\t/* We can't wrap it: We need a recursive lock */\n\t\t\toriginal_lock_fns_.free(lock_, locktype);\n\t\t\treturn debug_lock_alloc(locktype);\n\t\t}\n\t\tlock = mm_malloc(sizeof(struct debug_lock));\n\t\tif (!lock) {\n\t\t\toriginal_lock_fns_.free(lock_, locktype);\n\t\t\treturn NULL;\n\t\t}\n\t\tlock->lock = lock_;\n\t\tlock->locktype = locktype;\n\t\tlock->count = 0;\n\t\tlock->held_by = 0;\n\t\treturn lock;\n\t} else if (enable_locks && ! evthread_lock_debugging_enabled_) {\n\t\t/* Case 3: allocate a regular lock */\n\t\tEVUTIL_ASSERT(lock_ == NULL);\n\t\treturn evthread_lock_fns_.alloc(locktype);\n\t} else {\n\t\t/* Case 4: Fill in a debug lock with a real lock */\n\t\tstruct debug_lock *lock = lock_ ? lock_ : debug_lock_alloc(locktype);\n\t\tif (!lock)\n\t\t\treturn NULL;\n\t\tEVUTIL_ASSERT(enable_locks && evthread_lock_debugging_enabled_);\n\t\tEVUTIL_ASSERT(lock->locktype == locktype);\n\t\tif (!lock->lock) {\n\t\t\tlock->lock = original_lock_fns_.alloc(\n\t\t\t\tlocktype|EVTHREAD_LOCKTYPE_RECURSIVE);\n\t\t\tif (!lock->lock) {\n\t\t\t\tlock->count = -200;\n\t\t\t\tmm_free(lock);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t\treturn lock;\n\t}\n}\n\n\n#ifndef EVTHREAD_EXPOSE_STRUCTS\nunsigned long\nevthreadimpl_get_id_()\n{\n\treturn evthread_id_fn_ ? evthread_id_fn_() : 1;\n}\nvoid *\nevthreadimpl_lock_alloc_(unsigned locktype)\n{\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_mode_on_) {\n\t\tevent_debug_created_threadable_ctx_ = 1;\n\t}\n#endif\n\n\treturn evthread_lock_fns_.alloc ?\n\t    evthread_lock_fns_.alloc(locktype) : NULL;\n}\nvoid\nevthreadimpl_lock_free_(void *lock, unsigned locktype)\n{\n\tif (evthread_lock_fns_.free)\n\t\tevthread_lock_fns_.free(lock, locktype);\n}\nint\nevthreadimpl_lock_lock_(unsigned mode, void *lock)\n{\n\tif (evthread_lock_fns_.lock)\n\t\treturn evthread_lock_fns_.lock(mode, lock);\n\telse\n\t\treturn 0;\n}\nint\nevthreadimpl_lock_unlock_(unsigned mode, void *lock)\n{\n\tif (evthread_lock_fns_.unlock)\n\t\treturn evthread_lock_fns_.unlock(mode, lock);\n\telse\n\t\treturn 0;\n}\nvoid *\nevthreadimpl_cond_alloc_(unsigned condtype)\n{\n#ifndef EVENT__DISABLE_DEBUG_MODE\n\tif (event_debug_mode_on_) {\n\t\tevent_debug_created_threadable_ctx_ = 1;\n\t}\n#endif\n\n\treturn evthread_cond_fns_.alloc_condition ?\n\t    evthread_cond_fns_.alloc_condition(condtype) : NULL;\n}\nvoid\nevthreadimpl_cond_free_(void *cond)\n{\n\tif (evthread_cond_fns_.free_condition)\n\t\tevthread_cond_fns_.free_condition(cond);\n}\nint\nevthreadimpl_cond_signal_(void *cond, int broadcast)\n{\n\tif (evthread_cond_fns_.signal_condition)\n\t\treturn evthread_cond_fns_.signal_condition(cond, broadcast);\n\telse\n\t\treturn 0;\n}\nint\nevthreadimpl_cond_wait_(void *cond, void *lock, const struct timeval *tv)\n{\n\tif (evthread_cond_fns_.wait_condition)\n\t\treturn evthread_cond_fns_.wait_condition(cond, lock, tv);\n\telse\n\t\treturn 0;\n}\nint\nevthreadimpl_is_lock_debugging_enabled_(void)\n{\n\treturn evthread_lock_debugging_enabled_;\n}\n\nint\nevthreadimpl_locking_enabled_(void)\n{\n\treturn evthread_lock_fns_.lock != NULL;\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "evthread_pthread.c",
          "type": "blob",
          "size": 5.701171875,
          "content": "/*\n * Copyright 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n/* With glibc we need to define _GNU_SOURCE to get PTHREAD_MUTEX_RECURSIVE.\n * This comes from evconfig-private.h\n */\n#include <pthread.h>\n\nstruct event_base;\n#include \"event2/thread.h\"\n\n#include <stdlib.h>\n#include <string.h>\n#include \"mm-internal.h\"\n#include \"evthread-internal.h\"\n\nstatic pthread_mutexattr_t attr_default;\nstatic pthread_mutexattr_t attr_recursive;\n\nstatic pthread_mutex_t once_init_lock = PTHREAD_MUTEX_INITIALIZER;\nstatic int once_init = 0;\n\nstatic void *\nevthread_posix_lock_alloc(unsigned locktype)\n{\n\tpthread_mutexattr_t *attr = &attr_default;\n\tpthread_mutex_t *lock = mm_malloc(sizeof(pthread_mutex_t));\n\tif (!lock)\n\t\treturn NULL;\n\tif (locktype & EVTHREAD_LOCKTYPE_RECURSIVE)\n\t\tattr = &attr_recursive;\n\tif (pthread_mutex_init(lock, attr)) {\n\t\tmm_free(lock);\n\t\treturn NULL;\n\t}\n\treturn lock;\n}\n\nstatic void\nevthread_posix_lock_free(void *lock_, unsigned locktype)\n{\n\tpthread_mutex_t *lock = lock_;\n\tpthread_mutex_destroy(lock);\n\tmm_free(lock);\n}\n\nstatic int\nevthread_posix_lock(unsigned mode, void *lock_)\n{\n\tpthread_mutex_t *lock = lock_;\n\tif (mode & EVTHREAD_TRY)\n\t\treturn pthread_mutex_trylock(lock);\n\telse\n\t\treturn pthread_mutex_lock(lock);\n}\n\nstatic int\nevthread_posix_unlock(unsigned mode, void *lock_)\n{\n\tpthread_mutex_t *lock = lock_;\n\treturn pthread_mutex_unlock(lock);\n}\n\nstatic unsigned long\nevthread_posix_get_id(void)\n{\n\tunion {\n\t\tpthread_t thr;\n#if EVENT__SIZEOF_PTHREAD_T > EVENT__SIZEOF_LONG\n\t\tev_uint64_t id;\n#else\n\t\tunsigned long id;\n#endif\n\t} r;\n#if EVENT__SIZEOF_PTHREAD_T < EVENT__SIZEOF_LONG\n\tmemset(&r, 0, sizeof(r));\n#endif\n\tr.thr = pthread_self();\n\treturn (unsigned long)r.id;\n}\n\nstatic void *\nevthread_posix_cond_alloc(unsigned condflags)\n{\n\tpthread_cond_t *cond = mm_malloc(sizeof(pthread_cond_t));\n\tif (!cond)\n\t\treturn NULL;\n\tif (pthread_cond_init(cond, NULL)) {\n\t\tmm_free(cond);\n\t\treturn NULL;\n\t}\n\treturn cond;\n}\n\nstatic void\nevthread_posix_cond_free(void *cond_)\n{\n\tpthread_cond_t *cond = cond_;\n\tpthread_cond_destroy(cond);\n\tmm_free(cond);\n}\n\nstatic int\nevthread_posix_cond_signal(void *cond_, int broadcast)\n{\n\tpthread_cond_t *cond = cond_;\n\tint r;\n\tif (broadcast)\n\t\tr = pthread_cond_broadcast(cond);\n\telse\n\t\tr = pthread_cond_signal(cond);\n\treturn r ? -1 : 0;\n}\n\nstatic int\nevthread_posix_cond_wait(void *cond_, void *lock_, const struct timeval *tv)\n{\n\tint r;\n\tpthread_cond_t *cond = cond_;\n\tpthread_mutex_t *lock = lock_;\n\n\tif (tv) {\n\t\tstruct timeval now, abstime;\n\t\tstruct timespec ts;\n\t\tevutil_gettimeofday(&now, NULL);\n\t\tevutil_timeradd(&now, tv, &abstime);\n\t\tts.tv_sec = abstime.tv_sec;\n\t\tts.tv_nsec = abstime.tv_usec*1000;\n\t\tr = pthread_cond_timedwait(cond, lock, &ts);\n\t\tif (r == ETIMEDOUT)\n\t\t\treturn 1;\n\t\telse if (r)\n\t\t\treturn -1;\n\t\telse\n\t\t\treturn 0;\n\t} else {\n\t\tr = pthread_cond_wait(cond, lock);\n\t\treturn r ? -1 : 0;\n\t}\n}\n\nint\nevthread_use_pthreads_with_flags(int flags)\n{\n\tstruct evthread_lock_callbacks cbs = {\n\t\tEVTHREAD_LOCK_API_VERSION,\n\t\tEVTHREAD_LOCKTYPE_RECURSIVE,\n\t\tevthread_posix_lock_alloc,\n\t\tevthread_posix_lock_free,\n\t\tevthread_posix_lock,\n\t\tevthread_posix_unlock\n\t};\n\tstruct evthread_condition_callbacks cond_cbs = {\n\t\tEVTHREAD_CONDITION_API_VERSION,\n\t\tevthread_posix_cond_alloc,\n\t\tevthread_posix_cond_free,\n\t\tevthread_posix_cond_signal,\n\t\tevthread_posix_cond_wait\n\t};\n\n\tpthread_mutex_lock(&once_init_lock);\n\tif (once_init == 1) {\n\t\tpthread_mutex_unlock(&once_init_lock);\n\t\treturn 0;\n\t}\n\n\tif (pthread_mutexattr_init(&attr_default)) \n\t\tgoto error;\n\n\t/* Set ourselves up to get recursive locks. */\n\tif (pthread_mutexattr_init(&attr_recursive))\n\t\tgoto error;\n\tif (pthread_mutexattr_settype(&attr_recursive, PTHREAD_MUTEX_RECURSIVE))\n\t\tgoto error;\n\n\tif (flags & EVTHREAD_PTHREAD_PRIO_INHERIT) {\n#ifdef EVENT__HAVE_PTHREAD_MUTEXATTR_SETPROTOCOL\n\t\t/* Set up priority inheritance */\n\t\tif (pthread_mutexattr_setprotocol(&attr_default, PTHREAD_PRIO_INHERIT))\n\t\t\tgoto error;\n\t\tif (pthread_mutexattr_setprotocol(&attr_recursive, PTHREAD_PRIO_INHERIT))\n\t\t\tgoto error;\n#else\n\t\tgoto error;\n#endif\n\t}\n\n\tevthread_set_lock_callbacks(&cbs);\n\tevthread_set_condition_callbacks(&cond_cbs);\n\tevthread_set_id_callback(evthread_posix_get_id);\n\tonce_init = 1;\n\n\tpthread_mutex_unlock(&once_init_lock);\n\treturn 0;\nerror:\n\tpthread_mutex_unlock(&once_init_lock);\n\treturn -1;\n}\n\nint\nevthread_use_pthreads(void)\n{\n\treturn evthread_use_pthreads_with_flags(0);\n}\n"
        },
        {
          "name": "evthread_win32.c",
          "type": "blob",
          "size": 8.3896484375,
          "content": "/*\n * Copyright 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifdef _WIN32\n#ifndef _WIN32_WINNT\n/* Minimum required for InitializeCriticalSectionAndSpinCount */\n#define _WIN32_WINNT 0x0403\n#endif\n#define WIN32_LEAN_AND_MEAN\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <windows.h>\n#include <sys/locking.h>\n#endif\n\nstruct event_base;\n#include \"event2/thread.h\"\n\n#include \"mm-internal.h\"\n#include \"evthread-internal.h\"\n#include \"time-internal.h\"\n\n#define SPIN_COUNT 2000\n\nstatic void *\nevthread_win32_lock_create(unsigned locktype)\n{\n\tCRITICAL_SECTION *lock = mm_malloc(sizeof(CRITICAL_SECTION));\n\tif (!lock)\n\t\treturn NULL;\n\tif (InitializeCriticalSectionAndSpinCount(lock, SPIN_COUNT) == 0) {\n\t\tmm_free(lock);\n\t\treturn NULL;\n\t}\n\treturn lock;\n}\n\nstatic void\nevthread_win32_lock_free(void *lock_, unsigned locktype)\n{\n\tCRITICAL_SECTION *lock = lock_;\n\tDeleteCriticalSection(lock);\n\tmm_free(lock);\n}\n\nstatic int\nevthread_win32_lock(unsigned mode, void *lock_)\n{\n\tCRITICAL_SECTION *lock = lock_;\n\tif ((mode & EVTHREAD_TRY)) {\n\t\treturn ! TryEnterCriticalSection(lock);\n\t} else {\n\t\tEnterCriticalSection(lock);\n\t\treturn 0;\n\t}\n}\n\nstatic int\nevthread_win32_unlock(unsigned mode, void *lock_)\n{\n\tCRITICAL_SECTION *lock = lock_;\n\tLeaveCriticalSection(lock);\n\treturn 0;\n}\n\nstatic unsigned long\nevthread_win32_get_id(void)\n{\n\treturn (unsigned long) GetCurrentThreadId();\n}\n\n#ifdef WIN32_HAVE_CONDITION_VARIABLES\nstatic void WINAPI (*InitializeConditionVariable_fn)(PCONDITION_VARIABLE)\n\t= NULL;\nstatic BOOL WINAPI (*SleepConditionVariableCS_fn)(\n\tPCONDITION_VARIABLE, PCRITICAL_SECTION, DWORD) = NULL;\nstatic void WINAPI (*WakeAllConditionVariable_fn)(PCONDITION_VARIABLE) = NULL;\nstatic void WINAPI (*WakeConditionVariable_fn)(PCONDITION_VARIABLE) = NULL;\n\nstatic int\nevthread_win32_condvar_init(void)\n{\n\tHANDLE lib;\n\n\tlib = GetModuleHandle(TEXT(\"kernel32.dll\"));\n\tif (lib == NULL)\n\t\treturn 0;\n\n#define LOAD(name)\t\t\t\t\\\n\tname##_fn = GetProcAddress(lib, #name)\n\tLOAD(InitializeConditionVariable);\n\tLOAD(SleepConditionVariableCS);\n\tLOAD(WakeAllConditionVariable);\n\tLOAD(WakeConditionVariable);\n\n\treturn InitializeConditionVariable_fn && SleepConditionVariableCS_fn &&\n\t    WakeAllConditionVariable_fn && WakeConditionVariable_fn;\n}\n\n/* XXXX Even if we can build this, we don't necessarily want to: the functions\n * in question didn't exist before Vista, so we'd better LoadProc them. */\nstatic void *\nevthread_win32_condvar_alloc(unsigned condflags)\n{\n\tCONDITION_VARIABLE *cond = mm_malloc(sizeof(CONDITION_VARIABLE));\n\tif (!cond)\n\t\treturn NULL;\n\tInitializeConditionVariable_fn(cond);\n\treturn cond;\n}\n\nstatic void\nevthread_win32_condvar_free(void *cond_)\n{\n\tCONDITION_VARIABLE *cond = cond_;\n\t/* There doesn't _seem_ to be a cleaup fn here... */\n\tmm_free(cond);\n}\n\nstatic int\nevthread_win32_condvar_signal(void *cond, int broadcast)\n{\n\tCONDITION_VARIABLE *cond = cond_;\n\tif (broadcast)\n\t\tWakeAllConditionVariable_fn(cond);\n\telse\n\t\tWakeConditionVariable_fn(cond);\n\treturn 0;\n}\n\nstatic int\nevthread_win32_condvar_wait(void *cond_, void *lock_, const struct timeval *tv)\n{\n\tCONDITION_VARIABLE *cond = cond_;\n\tCRITICAL_SECTION *lock = lock_;\n\tDWORD ms, err;\n\tBOOL result;\n\n\tif (tv)\n\t\tms = evutil_tv_to_msec_(tv);\n\telse\n\t\tms = INFINITE;\n\tresult = SleepConditionVariableCS_fn(cond, lock, ms);\n\tif (result) {\n\t\tif (GetLastError() == WAIT_TIMEOUT)\n\t\t\treturn 1;\n\t\telse\n\t\t\treturn -1;\n\t} else {\n\t\treturn 0;\n\t}\n}\n#endif\n\nstruct evthread_win32_cond {\n\tHANDLE event;\n\n\tCRITICAL_SECTION lock;\n\tint n_waiting;\n\tint n_to_wake;\n\tint generation;\n};\n\nstatic void *\nevthread_win32_cond_alloc(unsigned flags)\n{\n\tstruct evthread_win32_cond *cond;\n\tif (!(cond = mm_malloc(sizeof(struct evthread_win32_cond))))\n\t\treturn NULL;\n\tif (InitializeCriticalSectionAndSpinCount(&cond->lock, SPIN_COUNT)==0) {\n\t\tmm_free(cond);\n\t\treturn NULL;\n\t}\n\tif ((cond->event = CreateEvent(NULL,TRUE,FALSE,NULL)) == NULL) {\n\t\tDeleteCriticalSection(&cond->lock);\n\t\tmm_free(cond);\n\t\treturn NULL;\n\t}\n\tcond->n_waiting = cond->n_to_wake = cond->generation = 0;\n\treturn cond;\n}\n\nstatic void\nevthread_win32_cond_free(void *cond_)\n{\n\tstruct evthread_win32_cond *cond = cond_;\n\tDeleteCriticalSection(&cond->lock);\n\tCloseHandle(cond->event);\n\tmm_free(cond);\n}\n\nstatic int\nevthread_win32_cond_signal(void *cond_, int broadcast)\n{\n\tstruct evthread_win32_cond *cond = cond_;\n\tEnterCriticalSection(&cond->lock);\n\tif (broadcast)\n\t\tcond->n_to_wake = cond->n_waiting;\n\telse\n\t\t++cond->n_to_wake;\n\tcond->generation++;\n\tSetEvent(cond->event);\n\tLeaveCriticalSection(&cond->lock);\n\treturn 0;\n}\n\nstatic int\nevthread_win32_cond_wait(void *cond_, void *lock_, const struct timeval *tv)\n{\n\tstruct evthread_win32_cond *cond = cond_;\n\tCRITICAL_SECTION *lock = lock_;\n\tint generation_at_start;\n\tint waiting = 1;\n\tint result = -1;\n\tDWORD ms = INFINITE, ms_orig = INFINITE, startTime, endTime;\n\tif (tv)\n\t\tms_orig = ms = evutil_tv_to_msec_(tv);\n\n\tEnterCriticalSection(&cond->lock);\n\t++cond->n_waiting;\n\tgeneration_at_start = cond->generation;\n\tLeaveCriticalSection(&cond->lock);\n\n\tLeaveCriticalSection(lock);\n\n\tstartTime = GetTickCount();\n\tdo {\n\t\tDWORD res;\n\t\tres = WaitForSingleObject(cond->event, ms);\n\t\tEnterCriticalSection(&cond->lock);\n\t\tif (cond->n_to_wake &&\n\t\t    cond->generation != generation_at_start) {\n\t\t\t--cond->n_to_wake;\n\t\t\t--cond->n_waiting;\n\t\t\tresult = 0;\n\t\t\twaiting = 0;\n\t\t\tgoto out;\n\t\t} else if (res != WAIT_OBJECT_0) {\n\t\t\tresult = (res==WAIT_TIMEOUT) ? 1 : -1;\n\t\t\t--cond->n_waiting;\n\t\t\twaiting = 0;\n\t\t\tgoto out;\n\t\t} else if (ms != INFINITE) {\n\t\t\tendTime = GetTickCount();\n\t\t\tif (startTime + ms_orig <= endTime) {\n\t\t\t\tresult = 1; /* Timeout */\n\t\t\t\t--cond->n_waiting;\n\t\t\t\twaiting = 0;\n\t\t\t\tgoto out;\n\t\t\t} else {\n\t\t\t\tms = startTime + ms_orig - endTime;\n\t\t\t}\n\t\t}\n\t\t/* If we make it here, we are still waiting. */\n\t\tif (cond->n_to_wake == 0) {\n\t\t\t/* There is nobody else who should wake up; reset\n\t\t\t * the event. */\n\t\t\tResetEvent(cond->event);\n\t\t}\n\tout:\n\t\tLeaveCriticalSection(&cond->lock);\n\t} while (waiting);\n\n\tEnterCriticalSection(lock);\n\n\tEnterCriticalSection(&cond->lock);\n\tif (!cond->n_waiting)\n\t\tResetEvent(cond->event);\n\tLeaveCriticalSection(&cond->lock);\n\n\treturn result;\n}\n\nint\nevthread_use_windows_threads(void)\n{\n\tstruct evthread_lock_callbacks cbs = {\n\t\tEVTHREAD_LOCK_API_VERSION,\n\t\tEVTHREAD_LOCKTYPE_RECURSIVE,\n\t\tevthread_win32_lock_create,\n\t\tevthread_win32_lock_free,\n\t\tevthread_win32_lock,\n\t\tevthread_win32_unlock\n\t};\n\n\n\tstruct evthread_condition_callbacks cond_cbs = {\n\t\tEVTHREAD_CONDITION_API_VERSION,\n\t\tevthread_win32_cond_alloc,\n\t\tevthread_win32_cond_free,\n\t\tevthread_win32_cond_signal,\n\t\tevthread_win32_cond_wait\n\t};\n#ifdef WIN32_HAVE_CONDITION_VARIABLES\n\tstruct evthread_condition_callbacks condvar_cbs = {\n\t\tEVTHREAD_CONDITION_API_VERSION,\n\t\tevthread_win32_condvar_alloc,\n\t\tevthread_win32_condvar_free,\n\t\tevthread_win32_condvar_signal,\n\t\tevthread_win32_condvar_wait\n\t};\n#endif\n\n\tevthread_set_lock_callbacks(&cbs);\n\tevthread_set_id_callback(evthread_win32_get_id);\n#ifdef WIN32_HAVE_CONDITION_VARIABLES\n\tif (evthread_win32_condvar_init()) {\n\t\tevthread_set_condition_callbacks(&condvar_cbs);\n\t\treturn 0;\n\t}\n#endif\n\tevthread_set_condition_callbacks(&cond_cbs);\n\n\treturn 0;\n}\n\n"
        },
        {
          "name": "evutil.c",
          "type": "blob",
          "size": 88.224609375,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifdef _WIN32\n#ifndef _WIN32_WINNT\n/* For structs needed by GetAdaptersAddresses and AI_NUMERICSERV */\n#define _WIN32_WINNT 0x0600\n#endif\n#define WIN32_LEAN_AND_MEAN\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <winerror.h>\n#include <ws2tcpip.h>\n#ifdef _MSC_VER /* mstcpip.h is missing on MinGW */\n#include <mstcpip.h> /* for SIO_KEEPALIVE_VALS and tcp_keepalive struct */\n#endif\n#ifdef EVENT__HAVE_AFUNIX_H\n#include <afunix.h>\n#endif\n#include <windows.h>\n#include <io.h>\n#include <tchar.h>\n#include <process.h>\n#include <iphlpapi.h>\n#include <netioapi.h>\n#endif\n\n#ifdef EVENT__HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n#ifdef EVENT__HAVE_STDLIB_H\n#include <stdlib.h>\n#endif\n#include <errno.h>\n#include <limits.h>\n#include <stdio.h>\n#include <string.h>\n#ifdef EVENT__HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_TCP_H\n#include <netinet/tcp.h>\n#endif\n#ifdef EVENT__HAVE_ARPA_INET_H\n#include <arpa/inet.h>\n#endif\n#include <time.h>\n#include <sys/stat.h>\n#ifndef _WIN32\n#include <net/if.h>\n#endif\n#ifdef EVENT__HAVE_IFADDRS_H\n#include <ifaddrs.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n#include \"evthread-internal.h\"\n\n#include \"strlcpy-internal.h\"\n#include \"ipv6-internal.h\"\n\n#ifdef _WIN32\n#define HT_NO_CACHE_HASH_VALUES\n#include \"ht-internal.h\"\n#define open _open\n#define read _read\n#define close _close\n#ifndef fstat\n// i64 suffix is for 64-bit filesize support\n#define fstat _fstati64\n#endif\n#ifndef stat\n#define stat _stati64\n#endif\n#define mode_t int\n#endif\n\n#if defined(_WIN32) && !defined(SIO_KEEPALIVE_VALS)\n#define SIO_KEEPALIVE_VALS    _WSAIOW(IOC_VENDOR,4)\nstruct tcp_keepalive {\n  u_long onoff;\n  u_long keepalivetime;\n  u_long keepaliveinterval;\n};\n#endif\n\n#ifndef O_RDONLY\n#define O_RDONLY _O_RDONLY\n#endif\n\n#ifdef EVENT__HAVE_AFUNIX_H\nint have_working_afunix_ = -1;\n#endif\n\nint\nevutil_open_closeonexec_(const char *pathname, int flags, unsigned mode)\n{\n\tint fd;\n\n#ifdef O_CLOEXEC\n\tfd = open(pathname, flags|O_CLOEXEC, (mode_t)mode);\n\tif (fd >= 0 || errno == EINVAL)\n\t\treturn fd;\n\t/* If we got an EINVAL, fall through and try without O_CLOEXEC */\n#endif\n\tfd = open(pathname, flags, (mode_t)mode);\n\tif (fd < 0)\n\t\treturn -1;\n\n#if defined(FD_CLOEXEC)\n\tif (fcntl(fd, F_SETFD, FD_CLOEXEC) < 0) {\n\t\tclose(fd);\n\t\treturn -1;\n\t}\n#endif\n\n\treturn fd;\n}\n\nev_off_t evutil_fd_filesize(evutil_socket_t fd)\n{\n\tstruct stat st;\n\tif (fstat(fd, &st) < 0)\n\t\treturn -1;\n\treturn st.st_size;\n}\n\n/**\n   Read the contents of 'filename' into a newly allocated NUL-terminated\n   string.  Set *content_out to hold this string, and *len_out to hold its\n   length (not including the appended NUL).  If 'is_binary', open the file in\n   binary mode.\n\n   Returns 0 on success, -1 if the open fails, and -2 for all other failures.\n\n   Used internally only; may go away in a future version.\n */\nint\nevutil_read_file_(const char *filename, char **content_out, size_t *len_out,\n    int is_binary)\n{\n\tint fd;\n\tev_ssize_t r;\n\tev_off_t length;\n\tchar *mem;\n\tsize_t read_so_far = 0;\n\tint mode = O_RDONLY;\n\n\tEVUTIL_ASSERT(content_out);\n\tEVUTIL_ASSERT(len_out);\n\t*content_out = NULL;\n\t*len_out = 0;\n\n#ifdef O_BINARY\n\tif (is_binary)\n\t\tmode |= O_BINARY;\n#endif\n\n\tfd = evutil_open_closeonexec_(filename, mode, 0);\n\tif (fd < 0)\n\t\treturn -1;\n\tlength = evutil_fd_filesize(fd);\n\tif (length < 0 || length > EV_SSIZE_MAX-1) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tmem = mm_malloc(length + 1);\n\tif (!mem) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tread_so_far = 0;\n#ifdef _WIN32\n#define N_TO_READ(x) ((x) > INT_MAX) ? INT_MAX : ((int)(x))\n#else\n#define N_TO_READ(x) (x)\n#endif\n\twhile ((r = read(fd, mem+read_so_far, N_TO_READ(length - read_so_far))) > 0) {\n\t\tread_so_far += r;\n\t\tif (read_so_far >= (size_t)length)\n\t\t\tbreak;\n\t}\n\tclose(fd);\n\tif (r < 0) {\n\t\tmm_free(mem);\n\t\treturn -2;\n\t}\n\tmem[read_so_far] = 0;\n\n\t*len_out = read_so_far;\n\t*content_out = mem;\n\treturn 0;\n}\n\n#ifdef _WIN32\n\nstatic int\ncreate_tmpfile(WCHAR tmpfile[MAX_PATH])\n{\n\tWCHAR short_path[MAX_PATH] = {0};\n\tWCHAR long_path[MAX_PATH] = {0};\n\tWCHAR prefix[4] = {0};\n\t// GetTempFileNameW() uses up to the first three characters of the prefix\n\t// and windows filesystems are case-insensitive\n\tconst WCHAR *base32set = L\"abcdefghijklmnopqrstuvwxyz012345\";\n\tev_uint16_t rnd;\n\n\tevutil_secure_rng_get_bytes(&rnd, sizeof(rnd));\n\tprefix[0] = base32set[(rnd      ) & 31];\n\tprefix[1] = base32set[(rnd >>  5) & 31];\n\tprefix[2] = base32set[(rnd >> 10) & 31];\n\tprefix[3] = '\\0';\n\n\tGetTempPathW(MAX_PATH, short_path);\n\tGetLongPathNameW(short_path, long_path, MAX_PATH);\n\tif (!GetTempFileNameW(long_path, prefix, 0, tmpfile)) {\n\t\tevent_warnx(\"GetTempFileName failed: %d\", EVUTIL_SOCKET_ERROR());\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n#ifdef EVENT__HAVE_AFUNIX_H\n/* Test whether Unix domain socket works.\n * Return 1 if it works, otherwise 0 \t\t*/\nint\nevutil_check_working_afunix_()\n{\n\t/* Windows 10 began to support Unix domain socket. Let's just try\n\t * socket(AF_UNIX, , ) and fall back to socket(AF_INET, , ).\n\t * https://devblogs.microsoft.com/commandline/af_unix-comes-to-windows/\n\t */\n\tevutil_socket_t sd = -1;\n\tif (have_working_afunix_ < 0) {\n\t\tif ((sd = socket(AF_UNIX, SOCK_STREAM, 0)) < 0) {\n\t\t\thave_working_afunix_ = 0;\n\t\t} else {\n\t\t\thave_working_afunix_ = 1;\n\t\t\tevutil_closesocket(sd);\n\t\t}\n\t}\n\treturn have_working_afunix_;\n}\n\n/* XXX Copy from evutil_ersatz_socketpair_() */\nstatic int\nevutil_win_socketpair_afunix(int family, int type, int protocol,\n    evutil_socket_t fd[2])\n{\n#undef ERR\n#define ERR(e) WSA##e\n\tevutil_socket_t listener = -1;\n\tevutil_socket_t connector = -1;\n\tevutil_socket_t acceptor = -1;\n\n\tstruct sockaddr_un listen_addr;\n\tstruct sockaddr_un connect_addr;\n\tWCHAR tmp_file[MAX_PATH] = {0};\n\tchar tmp_file_utf8[MAX_PATH] = {0};\n\n\tev_socklen_t size;\n\tint saved_errno = -1;\n\n\tif (!fd) {\n\t\tEVUTIL_SET_SOCKET_ERROR(ERR(EINVAL));\n\t\treturn -1;\n\t}\n\n\tlistener = socket(family, type, 0);\n\tif (listener < 0)\n\t\treturn -1;\n\tmemset(&listen_addr, 0, sizeof(listen_addr));\n\n\tif (create_tmpfile(tmp_file)) {\n\t\tgoto tidy_up_and_fail;\n\t}\n\tDeleteFileW(tmp_file);\n\n\t/* Windows requires `sun_path` to be encoded by UTF-8 */\n\tWideCharToMultiByte(\n\t\tCP_UTF8, 0, tmp_file, MAX_PATH, tmp_file_utf8, MAX_PATH, NULL, NULL);\n\n\tlisten_addr.sun_family = AF_UNIX;\n\tif (strlcpy(listen_addr.sun_path, tmp_file_utf8, UNIX_PATH_MAX) >=\n\t\tUNIX_PATH_MAX) {\n\t\tevent_warnx(\"Temp file name is too long\");\n\t\tgoto tidy_up_and_fail;\n\t}\n\n\tif (bind(listener, (struct sockaddr *) &listen_addr, sizeof (listen_addr))\n\t\t== -1)\n\t\tgoto tidy_up_and_fail;\n\tif (listen(listener, 1) == -1)\n\t\tgoto tidy_up_and_fail;\n\n\tconnector = socket(family, type, 0);\n\tif (connector < 0)\n\t\tgoto tidy_up_and_fail;\n\n\tmemset(&connect_addr, 0, sizeof(connect_addr));\n\n\t/* We want to find out the port number to connect to.  */\n\tsize = sizeof(connect_addr);\n\tif (getsockname(listener, (struct sockaddr *) &connect_addr, &size) == -1)\n\t\tgoto tidy_up_and_fail;\n\n\tif (connect(connector, (struct sockaddr *) &connect_addr,\n\t\t\t\tsizeof(connect_addr)) == -1)\n\t\tgoto tidy_up_and_fail;\n\n\tsize = sizeof(listen_addr);\n\tacceptor = accept(listener, (struct sockaddr *) &listen_addr, &size);\n\tif (acceptor < 0)\n\t\tgoto tidy_up_and_fail;\n\tif (size != sizeof(listen_addr))\n\t\tgoto abort_tidy_up_and_fail;\n\t/* Now check we are talking to ourself by matching port and host on the\n\t   two sockets.\t */\n\tif (getsockname(connector, (struct sockaddr *) &connect_addr, &size) == -1)\n\t\tgoto tidy_up_and_fail;\n\n\tif (size != sizeof(connect_addr) ||\n\t    listen_addr.sun_family != connect_addr.sun_family ||\n\t    evutil_ascii_strcasecmp(listen_addr.sun_path, connect_addr.sun_path))\n\t\tgoto abort_tidy_up_and_fail;\n\n\tevutil_closesocket(listener);\n\tfd[0] = connector;\n\tfd[1] = acceptor;\n\n\treturn 0;\n\n abort_tidy_up_and_fail:\n\tsaved_errno = ERR(ECONNABORTED);\n tidy_up_and_fail:\n\tif (saved_errno < 0)\n\t\tsaved_errno = EVUTIL_SOCKET_ERROR();\n\tif (listener != -1)\n\t\tevutil_closesocket(listener);\n\tif (connector != -1)\n\t\tevutil_closesocket(connector);\n\tif (acceptor != -1)\n\t\tevutil_closesocket(acceptor);\n\tif (tmp_file[0])\n\t\tDeleteFileW(tmp_file);\n\n\tEVUTIL_SET_SOCKET_ERROR(saved_errno);\n\treturn -1;\n#undef ERR\n}\n#endif\n\nstatic int\nevutil_win_socketpair(int family, int type, int protocol,\n    evutil_socket_t fd[2])\n{\n#ifdef EVENT__HAVE_AFUNIX_H\n\t/* The family only support AF_UNIX and AF_INET */\n\tif (protocol || (family != AF_UNIX && family != AF_INET)) {\n\t\tEVUTIL_SET_SOCKET_ERROR(WSAEAFNOSUPPORT);\n\t\treturn -1;\n\t}\n\tif (evutil_check_working_afunix_()) {\n\t\t/* If the AF_UNIX socket works, we will change the family to\n\t\t * AF_UNIX forcely. */\n\t\tfamily = AF_UNIX;\n\t\tif (type != SOCK_STREAM) {\n\t\t\t/* Win10 does not support AF_UNIX socket of a type other\n\t\t\t * than SOCK_STREAM still now. */\n\t\t\tEVUTIL_SET_SOCKET_ERROR(WSAEAFNOSUPPORT);\n\t\t\treturn -1;\n\t\t}\n\t} else {\n\t\t/* If the AF_UNIX socket does not work, we will change the\n\t\t * family to AF_INET forcely. */\n\t\tfamily = AF_INET;\n\t}\n\tif (family == AF_UNIX)\n\t\treturn evutil_win_socketpair_afunix(family, type, protocol, fd);\n\n#endif\n\treturn evutil_ersatz_socketpair_(family, type, protocol, fd);\n}\n#endif\n\nint\nevutil_make_socket_nonblocking(evutil_socket_t fd)\n{\n#ifdef _WIN32\n\t{\n\t\tunsigned long nonblocking = 1;\n\t\tif (ioctlsocket(fd, FIONBIO, &nonblocking) == SOCKET_ERROR) {\n\t\t\tevent_sock_warn(fd, \"ioctlsocket(%d, FIONBIO, &%lu)\", (int)fd, (unsigned long)nonblocking);\n\t\t\treturn -1;\n\t\t}\n\t}\n#else\n\t{\n\t\tint flags;\n\t\tif ((flags = fcntl(fd, F_GETFL, NULL)) < 0) {\n\t\t\tevent_warn(\"fcntl(%d, F_GETFL)\", fd);\n\t\t\treturn -1;\n\t\t}\n\t\tif (!(flags & O_NONBLOCK)) {\n\t\t\tif (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) {\n\t\t\t\tevent_warn(\"fcntl(%d, F_SETFL)\", fd);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n#endif\n\treturn 0;\n}\n\n/* Faster version of evutil_make_socket_nonblocking for internal use.\n *\n * Requires that no F_SETFL flags were previously set on the fd.\n */\nstatic int\nevutil_fast_socket_nonblocking(evutil_socket_t fd)\n{\n#ifdef _WIN32\n\treturn evutil_make_socket_nonblocking(fd);\n#else\n\tif (fcntl(fd, F_SETFL, O_NONBLOCK) == -1) {\n\t\tevent_warn(\"fcntl(%d, F_SETFL)\", fd);\n\t\treturn -1;\n\t}\n\treturn 0;\n#endif\n}\n\nint\nevutil_make_listen_socket_reuseable(evutil_socket_t sock)\n{\n#if defined(SO_REUSEADDR) && !defined(_WIN32)\n\tint one = 1;\n\t/* REUSEADDR on Unix means, \"don't hang on to this address after the\n\t * listener is closed.\"  On Windows, though, it means \"don't keep other\n\t * processes from binding to this address while we're using it. */\n\treturn setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, (void*) &one,\n\t    (ev_socklen_t)sizeof(one));\n#else\n\treturn 0;\n#endif\n}\n\nint\nevutil_make_listen_socket_reuseable_port(evutil_socket_t sock)\n{\n#if defined(__FreeBSD__) && __FreeBSD__ >= 12 && defined(SO_REUSEPORT_LB)\n\t/* FreeBSD 12 introduced a new socket option named SO_REUSEPORT_LB\n\t * with the capability of load balancing, it's the equivalent of\n\t * the SO_REUSEPORTs on Linux and DragonFlyBSD. */\n\tint enabled = 1;\n\treturn setsockopt(sock, SOL_SOCKET, SO_REUSEPORT_LB, (void*)&enabled,\n\t    (ev_socklen_t)sizeof(enabled));\n#elif (defined(__linux__) || \\\n      defined(_AIX73) || \\\n      (defined(__DragonFly__) && __DragonFly_version >= 300600) || \\\n      (defined(EVENT__SOLARIS_11_4) && EVENT__SOLARIS_11_4)) && \\\n      defined(SO_REUSEPORT)\n\tint enabled = 1;\n\t/* SO_REUSEPORT on Linux 3.9+ means, \"Multiple servers (processes or\n\t * threads) can bind to the same port if they each set the option\".\n\t * In addition, the SO_REUSEPORT implementation distributes connections\n\t * or datagrams evenly across all of the threads (or processes).\n\t *\n\t * DragonFlyBSD 3.6.0 extended SO_REUSEPORT to distribute workload to\n\t * available sockets, which make it the same as Linux's SO_REUSEPORT.\n\t *\n\t * AIX 7.2.5 added the feature that would add the capability to distribute\n\t * incoming connections across all listening ports for SO_REUSEPORT.\n\t *\n\t * Solaris 11 supported SO_REUSEPORT, but it's implemented only for\n\t * binding to the same address and port, without load balancing.\n\t * Solaris 11.4 extended SO_REUSEPORT with the capability of load balancing.\n\t */\n\treturn setsockopt(sock, SOL_SOCKET, SO_REUSEPORT, (void*)&enabled,\n\t    (ev_socklen_t)sizeof(enabled));\n#else\n\t/* SO_REUSEPORTs on macOS and other BSDs only enable duplicate address and\n\t * port bindings, load balancing is not included. Therefore, only the last\n\t * socket that binds to a given address and port will receive all the traffic,\n\t * which means that incoming connections/datagrams will be shifted from the\n\t * old thread (or process) to the new one. That's not what we want, so we fail\n\t * this operation on these systems to indicate that SO_REUSEPORT without load\n\t * balancing is not supported. Otherwise, the callers would expected the load\n\t * balancing capability when they get 0 as the return value of this function.\n\t */\n\treturn -1;\n#endif\n}\n\nint\nevutil_make_listen_socket_ipv6only(evutil_socket_t sock)\n{\n#if defined(IPV6_V6ONLY)\n\tint one = 1;\n\treturn setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, (void*) &one,\n\t    (ev_socklen_t)sizeof(one));\n#endif\n\treturn 0;\n}\n\nint\nevutil_make_listen_socket_not_ipv6only(evutil_socket_t sock)\n{\n#if defined(IPV6_V6ONLY)\n\tint zero = 0;\n\treturn setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, (void *)&zero,\n\t\t(ev_socklen_t)sizeof(zero));\n#endif\n\treturn 0;\n}\n\nint\nevutil_make_tcp_listen_socket_deferred(evutil_socket_t sock)\n{\n#if defined(EVENT__HAVE_NETINET_TCP_H) && defined(TCP_DEFER_ACCEPT)\n\tint one = 1;\n\n\t/* TCP_DEFER_ACCEPT tells the kernel to call defer accept() only after data\n\t * has arrived and ready to read */\n\treturn setsockopt(sock, IPPROTO_TCP, TCP_DEFER_ACCEPT, &one,\n\t\t(ev_socklen_t)sizeof(one));\n#endif\n\treturn 0;\n}\n\nint\nevutil_make_socket_closeonexec(evutil_socket_t fd)\n{\n#if !defined(_WIN32) && defined(EVENT__HAVE_SETFD)\n\tint flags;\n\tif ((flags = fcntl(fd, F_GETFD, NULL)) < 0) {\n\t\tevent_warn(\"fcntl(%d, F_GETFD)\", fd);\n\t\treturn -1;\n\t}\n\tif (!(flags & FD_CLOEXEC)) {\n\t\tif (fcntl(fd, F_SETFD, flags | FD_CLOEXEC) == -1) {\n\t\t\tevent_warn(\"fcntl(%d, F_SETFD)\", fd);\n\t\t\treturn -1;\n\t\t}\n\t}\n#endif\n\treturn 0;\n}\n\n/* Faster version of evutil_make_socket_closeonexec for internal use.\n *\n * Requires that no F_SETFD flags were previously set on the fd.\n */\nstatic int\nevutil_fast_socket_closeonexec(evutil_socket_t fd)\n{\n#if !defined(_WIN32) && defined(EVENT__HAVE_SETFD)\n\tif (fcntl(fd, F_SETFD, FD_CLOEXEC) == -1) {\n\t\tevent_warn(\"fcntl(%d, F_SETFD)\", fd);\n\t\treturn -1;\n\t}\n#endif\n\treturn 0;\n}\n\nint\nevutil_closesocket(evutil_socket_t sock)\n{\n#ifndef _WIN32\n\treturn close(sock);\n#else\n\treturn closesocket(sock);\n#endif\n}\n\nev_int64_t\nevutil_strtoll(const char *s, char **endptr, int base)\n{\n#ifdef EVENT__HAVE_STRTOLL\n\treturn (ev_int64_t)strtoll(s, endptr, base);\n#elif EVENT__SIZEOF_LONG == 8\n\treturn (ev_int64_t)strtol(s, endptr, base);\n#elif defined(_WIN32) && defined(_MSC_VER) && _MSC_VER < 1300\n\t/* XXXX on old versions of MS APIs, we only support base\n\t * 10. */\n\tev_int64_t r;\n\tif (base != 10)\n\t\treturn 0;\n\tr = (ev_int64_t) _atoi64(s);\n\twhile (isspace(*s))\n\t\t++s;\n\tif (*s == '-')\n\t\t++s;\n\twhile (isdigit(*s))\n\t\t++s;\n\tif (endptr)\n\t\t*endptr = (char*) s;\n\treturn r;\n#elif defined(_WIN32)\n\treturn (ev_int64_t) _strtoi64(s, endptr, base);\n#elif defined(EVENT__SIZEOF_LONG_LONG) && EVENT__SIZEOF_LONG_LONG == 8\n\tlong long r;\n\tint n;\n\tif (base != 10 && base != 16)\n\t\treturn 0;\n\tif (base == 10) {\n\t\tn = sscanf(s, \"%lld\", &r);\n\t} else {\n\t\tunsigned long long ru=0;\n\t\tn = sscanf(s, \"%llx\", &ru);\n\t\tif (ru > EV_INT64_MAX)\n\t\t\treturn 0;\n\t\tr = (long long) ru;\n\t}\n\tif (n != 1)\n\t\treturn 0;\n\twhile (EVUTIL_ISSPACE_(*s))\n\t\t++s;\n\tif (*s == '-')\n\t\t++s;\n\tif (base == 10) {\n\t\twhile (EVUTIL_ISDIGIT_(*s))\n\t\t\t++s;\n\t} else {\n\t\twhile (EVUTIL_ISXDIGIT_(*s))\n\t\t\t++s;\n\t}\n\tif (endptr)\n\t\t*endptr = (char*) s;\n\treturn r;\n#else\n#error \"I don't know how to parse 64-bit integers.\"\n#endif\n}\n\n#ifdef _WIN32\nint\nevutil_socket_geterror(evutil_socket_t sock)\n{\n\tint optval, optvallen=sizeof(optval);\n\tint err = WSAGetLastError();\n\tif (err == WSAEWOULDBLOCK && sock >= 0) {\n\t\tif (getsockopt(sock, SOL_SOCKET, SO_ERROR, (void*)&optval,\n\t\t\t\t\t   &optvallen))\n\t\t\treturn err;\n\t\tif (optval)\n\t\t\treturn optval;\n\t}\n\treturn err;\n}\n#endif\n\n/* XXX we should use an enum here. */\n/* 2 for connection refused, 1 for connected, 0 for not yet, -1 for error. */\nint\nevutil_socket_connect_(evutil_socket_t *fd_ptr, const struct sockaddr *sa, int socklen)\n{\n\tint made_fd = 0;\n\n\tif (*fd_ptr < 0) {\n\t\tif ((*fd_ptr = socket(sa->sa_family, SOCK_STREAM, 0)) < 0)\n\t\t\tgoto err;\n\t\tmade_fd = 1;\n\t\tif (evutil_make_socket_nonblocking(*fd_ptr) < 0) {\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (connect(*fd_ptr, sa, socklen) < 0) {\n\t\tint e = evutil_socket_geterror(*fd_ptr);\n\t\tif (EVUTIL_ERR_CONNECT_RETRIABLE(e))\n\t\t\treturn 0;\n\t\tif (EVUTIL_ERR_CONNECT_REFUSED(e))\n\t\t\treturn 2;\n\t\tgoto err;\n\t} else {\n\t\treturn 1;\n\t}\n\nerr:\n\tif (made_fd) {\n\t\tevutil_closesocket(*fd_ptr);\n\t\t*fd_ptr = -1;\n\t}\n\treturn -1;\n}\n\n/* Check whether a socket on which we called connect() is done\n   connecting. Return 1 for connected, 0 for not yet, -1 for error.  In the\n   error case, set the current socket errno to the error that happened during\n   the connect operation. */\nint\nevutil_socket_finished_connecting_(evutil_socket_t fd)\n{\n\tint e;\n\tev_socklen_t elen = sizeof(e);\n\n\tif (getsockopt(fd, SOL_SOCKET, SO_ERROR, (void*)&e, &elen) < 0)\n\t\treturn -1;\n\n\tif (e) {\n\t\tif (EVUTIL_ERR_CONNECT_RETRIABLE(e))\n\t\t\treturn 0;\n\t\tEVUTIL_SET_SOCKET_ERROR(e);\n\t\treturn -1;\n\t}\n\n\treturn 1;\n}\n\n#if (EVUTIL_AI_PASSIVE|EVUTIL_AI_CANONNAME|EVUTIL_AI_NUMERICHOST| \\\n     EVUTIL_AI_NUMERICSERV|EVUTIL_AI_V4MAPPED|EVUTIL_AI_ALL| \\\n     EVUTIL_AI_ADDRCONFIG) != \\\n    (EVUTIL_AI_PASSIVE^EVUTIL_AI_CANONNAME^EVUTIL_AI_NUMERICHOST^ \\\n     EVUTIL_AI_NUMERICSERV^EVUTIL_AI_V4MAPPED^EVUTIL_AI_ALL^ \\\n     EVUTIL_AI_ADDRCONFIG)\n#error \"Some of our EVUTIL_AI_* flags seem to overlap with system AI_* flags\"\n#endif\n\n/* We sometimes need to know whether we have an ipv4 address and whether we\n   have an ipv6 address. If 'have_checked_interfaces', then we've already done\n   the test.  If 'had_ipv4_address', then it turns out we had an ipv4 address.\n   If 'had_ipv6_address', then it turns out we had an ipv6 address.   These are\n   set by evutil_check_interfaces. */\nstatic int have_checked_interfaces, had_ipv4_address, had_ipv6_address;\n\n/* True iff the IPv4 address 'addr', in host order, is in 127.0.0.0/8 */\nstatic inline int evutil_v4addr_is_localhost(ev_uint32_t addr)\n{ return addr>>24 == 127; }\n\n/* True iff the IPv4 address 'addr', in host order, is link-local\n * 169.254.0.0/16 (RFC3927) */\nstatic inline int evutil_v4addr_is_linklocal(ev_uint32_t addr)\n{ return ((addr & 0xffff0000U) == 0xa9fe0000U); }\n\n/* True iff the IPv4 address 'addr', in host order, is a class D\n * (multiclass) address.  */\nstatic inline int evutil_v4addr_is_classd(ev_uint32_t addr)\n{ return ((addr>>24) & 0xf0) == 0xe0; }\n\nint\nevutil_v4addr_is_local_(const struct in_addr *in)\n{\n\tconst ev_uint32_t addr = ntohl(in->s_addr);\n\treturn addr == INADDR_ANY ||\n\t\tevutil_v4addr_is_localhost(addr) ||\n\t\tevutil_v4addr_is_linklocal(addr) ||\n\t\tevutil_v4addr_is_classd(addr);\n}\nint\nevutil_v6addr_is_local_(const struct in6_addr *in)\n{\n\tstatic const char ZEROES[] =\n\t\t\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n\t\t\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\";\n\n\tconst unsigned char *addr = (const unsigned char *)in->s6_addr;\n\treturn !memcmp(addr, ZEROES, 8) ||\n\t\t((addr[0] & 0xfe) == 0xfc) ||\n\t\t(addr[0] == 0xfe && (addr[1] & 0xc0) == 0x80) ||\n\t\t(addr[0] == 0xfe && (addr[1] & 0xc0) == 0xc0) ||\n\t\t(addr[0] == 0xff);\n}\n\nstatic void\nevutil_found_ifaddr(const struct sockaddr *sa)\n{\n\tif (sa->sa_family == AF_INET) {\n\t\tconst struct sockaddr_in *sin = (struct sockaddr_in *)sa;\n\t\tif (!evutil_v4addr_is_local_(&sin->sin_addr)) {\n\t\t\tevent_debug((\"Detected an IPv4 interface\"));\n\t\t\thad_ipv4_address = 1;\n\t\t}\n\t} else if (sa->sa_family == AF_INET6) {\n\t\tconst struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)sa;\n\t\tif (!evutil_v6addr_is_local_(&sin6->sin6_addr)) {\n\t\t\tevent_debug((\"Detected an IPv6 interface\"));\n\t\t\thad_ipv6_address = 1;\n\t\t}\n\t}\n}\n\n#ifdef _WIN32\ntypedef ULONG (WINAPI *GetAdaptersAddresses_fn_t)(\n              ULONG, ULONG, PVOID, PIP_ADAPTER_ADDRESSES, PULONG);\n#endif\n\nstatic int\nevutil_check_ifaddrs(void)\n{\n#if defined(EVENT__HAVE_GETIFADDRS)\n\t/* Most free Unixy systems provide getifaddrs, which gives us a linked list\n\t * of struct ifaddrs. */\n\tstruct ifaddrs *ifa = NULL;\n\tconst struct ifaddrs *i;\n\tif (getifaddrs(&ifa) < 0) {\n\t\tevent_warn(\"Unable to call getifaddrs()\");\n\t\treturn -1;\n\t}\n\n\tfor (i = ifa; i; i = i->ifa_next) {\n\t\tif (!i->ifa_addr)\n\t\t\tcontinue;\n\t\tevutil_found_ifaddr(i->ifa_addr);\n\t}\n\n\tfreeifaddrs(ifa);\n\treturn 0;\n#elif defined(_WIN32)\n\t/* Windows XP began to provide GetAdaptersAddresses. Windows 2000 had a\n\t   \"GetAdaptersInfo\", but that's deprecated; let's just try\n\t   GetAdaptersAddresses and fall back to connect+getsockname.\n\t*/\n\tHMODULE lib = evutil_load_windows_system_library_(TEXT(\"iphlpapi.dll\"));\n\tGetAdaptersAddresses_fn_t fn;\n\tULONG size, res;\n\tIP_ADAPTER_ADDRESSES *addresses = NULL, *address;\n\tint result = -1;\n\n#define FLAGS (GAA_FLAG_SKIP_ANYCAST | \\\n               GAA_FLAG_SKIP_MULTICAST | \\\n               GAA_FLAG_SKIP_DNS_SERVER)\n\n\tif (!lib)\n\t\tgoto done;\n\n\tif (!(fn = (GetAdaptersAddresses_fn_t) GetProcAddress(lib, \"GetAdaptersAddresses\")))\n\t\tgoto done;\n\n\t/* Guess how much space we need. */\n\tsize = 15*1024;\n\taddresses = mm_malloc(size);\n\tif (!addresses)\n\t\tgoto done;\n\tres = fn(AF_UNSPEC, FLAGS, NULL, addresses, &size);\n\tif (res == ERROR_BUFFER_OVERFLOW) {\n\t\t/* we didn't guess that we needed enough space; try again */\n\t\tmm_free(addresses);\n\t\taddresses = mm_malloc(size);\n\t\tif (!addresses)\n\t\t\tgoto done;\n\t\tres = fn(AF_UNSPEC, FLAGS, NULL, addresses, &size);\n\t}\n\tif (res != NO_ERROR)\n\t\tgoto done;\n\n\tfor (address = addresses; address; address = address->Next) {\n\t\tIP_ADAPTER_UNICAST_ADDRESS *a;\n\t\tfor (a = address->FirstUnicastAddress; a; a = a->Next) {\n\t\t\t/* Yes, it's a linked list inside a linked list */\n\t\t\tstruct sockaddr *sa = a->Address.lpSockaddr;\n\t\t\tevutil_found_ifaddr(sa);\n\t\t}\n\t}\n\n\tresult = 0;\ndone:\n\tif (lib)\n\t\tFreeLibrary(lib);\n\tif (addresses)\n\t\tmm_free(addresses);\n\treturn result;\n#else\n\treturn -1;\n#endif\n}\n\n/* Test whether we have an ipv4 interface and an ipv6 interface.  Return 0 if\n * the test seemed successful. */\nstatic int\nevutil_check_interfaces(void)\n{\n\tevutil_socket_t fd = -1;\n\tstruct sockaddr_in sin, sin_out;\n\tstruct sockaddr_in6 sin6, sin6_out;\n\tev_socklen_t sin_out_len = sizeof(sin_out);\n\tev_socklen_t sin6_out_len = sizeof(sin6_out);\n\tint r;\n\tif (have_checked_interfaces)\n\t\treturn 0;\n\n\t/* From this point on we have done the ipv4/ipv6 interface check */\n\thave_checked_interfaces = 1;\n\n\tif (evutil_check_ifaddrs() == 0) {\n\t\t/* Use a nice sane interface, if this system has one. */\n\t\treturn 0;\n\t}\n\n\t/* Ugh. There was no nice sane interface.  So to check whether we have\n\t * an interface open for a given protocol, will try to make a UDP\n\t * 'connection' to a remote host on the internet.  We don't actually\n\t * use it, so the address doesn't matter, but we want to pick one that\n\t * keep us from using a host- or link-local interface. */\n\tmemset(&sin, 0, sizeof(sin));\n\tsin.sin_family = AF_INET;\n\tsin.sin_port = htons(53);\n\tr = evutil_inet_pton(AF_INET, \"18.244.0.188\", &sin.sin_addr);\n\tEVUTIL_ASSERT(r);\n\n\tmemset(&sin6, 0, sizeof(sin6));\n\tsin6.sin6_family = AF_INET6;\n\tsin6.sin6_port = htons(53);\n\tr = evutil_inet_pton(AF_INET6, \"2001:4860:b002::68\", &sin6.sin6_addr);\n\tEVUTIL_ASSERT(r);\n\n\tmemset(&sin_out, 0, sizeof(sin_out));\n\tmemset(&sin6_out, 0, sizeof(sin6_out));\n\n\t/* XXX some errnos mean 'no address'; some mean 'not enough sockets'. */\n\tif ((fd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP)) >= 0 &&\n\t    connect(fd, (struct sockaddr*)&sin, sizeof(sin)) == 0 &&\n\t    getsockname(fd, (struct sockaddr*)&sin_out, &sin_out_len) == 0) {\n\t\t/* We might have an IPv4 interface. */\n\t\tevutil_found_ifaddr((struct sockaddr*) &sin_out);\n\t}\n\tif (fd >= 0)\n\t\tevutil_closesocket(fd);\n\n\tif ((fd = socket(AF_INET6, SOCK_DGRAM, IPPROTO_UDP)) >= 0 &&\n\t    connect(fd, (struct sockaddr*)&sin6, sizeof(sin6)) == 0 &&\n\t    getsockname(fd, (struct sockaddr*)&sin6_out, &sin6_out_len) == 0) {\n\t\t/* We might have an IPv6 interface. */\n\t\tevutil_found_ifaddr((struct sockaddr*) &sin6_out);\n\t}\n\n\tif (fd >= 0)\n\t\tevutil_closesocket(fd);\n\n\treturn 0;\n}\n\n/* Internal addrinfo flag.  This one is set when we allocate the addrinfo from\n * inside libevent.  Otherwise, the built-in getaddrinfo() function allocated\n * it, and we should trust what they said.\n **/\n#define EVUTIL_AI_LIBEVENT_ALLOCATED 0x80000000\n\n/* Helper: construct a new addrinfo containing the socket address in\n * 'sa', which must be a sockaddr_in or a sockaddr_in6.  Take the\n * socktype and protocol info from hints.  If they weren't set, then\n * allocate both a TCP and a UDP addrinfo.\n */\nstruct evutil_addrinfo *\nevutil_new_addrinfo_(struct sockaddr *sa, ev_socklen_t socklen,\n    const struct evutil_addrinfo *hints)\n{\n\tstruct evutil_addrinfo *res;\n\tEVUTIL_ASSERT(hints);\n\n\tif (hints->ai_socktype == 0 && hints->ai_protocol == 0) {\n\t\t/* Indecisive user! Give them a UDP and a TCP. */\n\t\tstruct evutil_addrinfo *r1, *r2;\n\t\tstruct evutil_addrinfo tmp;\n\t\tmemcpy(&tmp, hints, sizeof(tmp));\n\t\ttmp.ai_socktype = SOCK_STREAM; tmp.ai_protocol = IPPROTO_TCP;\n\t\tr1 = evutil_new_addrinfo_(sa, socklen, &tmp);\n\t\tif (!r1)\n\t\t\treturn NULL;\n\t\ttmp.ai_socktype = SOCK_DGRAM; tmp.ai_protocol = IPPROTO_UDP;\n\t\tr2 = evutil_new_addrinfo_(sa, socklen, &tmp);\n\t\tif (!r2) {\n\t\t\tevutil_freeaddrinfo(r1);\n\t\t\treturn NULL;\n\t\t}\n\t\tr1->ai_next = r2;\n\t\treturn r1;\n\t}\n\n\t/* We're going to allocate extra space to hold the sockaddr. */\n\tres = mm_calloc(1,sizeof(struct evutil_addrinfo)+socklen);\n\tif (!res)\n\t\treturn NULL;\n\tres->ai_addr = (struct sockaddr*)\n\t    (((char*)res) + sizeof(struct evutil_addrinfo));\n\tmemcpy(res->ai_addr, sa, socklen);\n\tres->ai_addrlen = socklen;\n\tres->ai_family = sa->sa_family; /* Same or not? XXX */\n\tres->ai_flags = EVUTIL_AI_LIBEVENT_ALLOCATED;\n\tres->ai_socktype = hints->ai_socktype;\n\tres->ai_protocol = hints->ai_protocol;\n\n\treturn res;\n}\n\n/* Append the addrinfo 'append' to the end of 'first', and return the start of\n * the list.  Either element can be NULL, in which case we return the element\n * that is not NULL. */\nstruct evutil_addrinfo *\nevutil_addrinfo_append_(struct evutil_addrinfo *first,\n    struct evutil_addrinfo *append)\n{\n\tstruct evutil_addrinfo *ai = first;\n\tif (!ai)\n\t\treturn append;\n\twhile (ai->ai_next)\n\t\tai = ai->ai_next;\n\tai->ai_next = append;\n\n\treturn first;\n}\n\nstatic int\nparse_numeric_servname(const char *servname)\n{\n\tint n;\n\tchar *endptr=NULL;\n\tn = (int) strtol(servname, &endptr, 10);\n\tif (n>=0 && n <= 65535 && servname[0] && endptr && !endptr[0])\n\t\treturn n;\n\telse\n\t\treturn -1;\n}\n\n/** Parse a service name in 'servname', which can be a decimal port.\n * Return the port number, or -1 on error.\n */\nstatic int\nevutil_parse_servname(const char *servname, const char *protocol,\n    const struct evutil_addrinfo *hints)\n{\n\tint n = parse_numeric_servname(servname);\n\tif (n>=0)\n\t\treturn n;\n#if defined(EVENT__HAVE_GETSERVBYNAME) || defined(_WIN32)\n\tif (!(hints->ai_flags & EVUTIL_AI_NUMERICSERV)) {\n\t\tstruct servent *ent = getservbyname(servname, protocol);\n\t\tif (ent) {\n\t\t\treturn ntohs(ent->s_port);\n\t\t}\n\t}\n#endif\n\treturn -1;\n}\n\n/* Return a string corresponding to a protocol number that we can pass to\n * getservyname.  */\nstatic const char *\nevutil_unparse_protoname(int proto)\n{\n\tswitch (proto) {\n\tcase 0:\n\t\treturn NULL;\n\tcase IPPROTO_TCP:\n\t\treturn \"tcp\";\n\tcase IPPROTO_UDP:\n\t\treturn \"udp\";\n#ifdef IPPROTO_SCTP\n\tcase IPPROTO_SCTP:\n\t\treturn \"sctp\";\n#endif\n\tdefault:\n#ifdef EVENT__HAVE_GETPROTOBYNUMBER\n\t\t{\n\t\t\tstruct protoent *ent = getprotobynumber(proto);\n\t\t\tif (ent)\n\t\t\t\treturn ent->p_name;\n\t\t}\n#endif\n\t\treturn NULL;\n\t}\n}\n\nstatic void\nevutil_getaddrinfo_infer_protocols(struct evutil_addrinfo *hints)\n{\n\t/* If we can guess the protocol from the socktype, do so. */\n\tif (!hints->ai_protocol && hints->ai_socktype) {\n\t\tif (hints->ai_socktype == SOCK_DGRAM)\n\t\t\thints->ai_protocol = IPPROTO_UDP;\n\t\telse if (hints->ai_socktype == SOCK_STREAM)\n\t\t\thints->ai_protocol = IPPROTO_TCP;\n\t}\n\n\t/* Set the socktype if it isn't set. */\n\tif (!hints->ai_socktype && hints->ai_protocol) {\n\t\tif (hints->ai_protocol == IPPROTO_UDP)\n\t\t\thints->ai_socktype = SOCK_DGRAM;\n\t\telse if (hints->ai_protocol == IPPROTO_TCP)\n\t\t\thints->ai_socktype = SOCK_STREAM;\n#ifdef IPPROTO_SCTP\n\t\telse if (hints->ai_protocol == IPPROTO_SCTP)\n\t\t\thints->ai_socktype = SOCK_STREAM;\n#endif\n\t}\n}\n\n#if AF_UNSPEC != PF_UNSPEC\n#error \"I cannot build on a system where AF_UNSPEC != PF_UNSPEC\"\n#endif\n\n/** Implements the part of looking up hosts by name that's common to both\n * the blocking and nonblocking resolver:\n *   - Adjust 'hints' to have a reasonable socktype and protocol.\n *   - Look up the port based on 'servname', and store it in *portnum,\n *   - Handle the nodename==NULL case\n *   - Handle some invalid arguments cases.\n *   - Handle the cases where nodename is an IPv4 or IPv6 address.\n *\n * If we need the resolver to look up the hostname, we return\n * EVUTIL_EAI_NEED_RESOLVE.  Otherwise, we can completely implement\n * getaddrinfo: we return 0 or an appropriate EVUTIL_EAI_* error, and\n * set *res as getaddrinfo would.\n */\nint\nevutil_getaddrinfo_common_(const char *nodename, const char *servname,\n    struct evutil_addrinfo *hints, struct evutil_addrinfo **res, int *portnum)\n{\n\tint port = 0;\n\tunsigned int if_index;\n\tconst char *pname;\n\n\tif (nodename == NULL && servname == NULL)\n\t\treturn EVUTIL_EAI_NONAME;\n\n\t/* We only understand 3 families */\n\tif (hints->ai_family != PF_UNSPEC && hints->ai_family != PF_INET &&\n\t    hints->ai_family != PF_INET6)\n\t\treturn EVUTIL_EAI_FAMILY;\n\n\tevutil_getaddrinfo_infer_protocols(hints);\n\n\t/* Look up the port number and protocol, if possible. */\n\tpname = evutil_unparse_protoname(hints->ai_protocol);\n\tif (servname) {\n\t\t/* XXXX We could look at the protocol we got back from\n\t\t * getservbyname, but it doesn't seem too useful. */\n\t\tport = evutil_parse_servname(servname, pname, hints);\n\t\tif (port < 0) {\n\t\t\treturn EVUTIL_EAI_NONAME;\n\t\t}\n\t}\n\n\t/* If we have no node name, then we're supposed to bind to 'any' and\n\t * connect to localhost. */\n\tif (nodename == NULL) {\n\t\tstruct evutil_addrinfo *res4=NULL, *res6=NULL;\n\t\tif (hints->ai_family != PF_INET) { /* INET6 or UNSPEC. */\n\t\t\tstruct sockaddr_in6 sin6;\n\t\t\tmemset(&sin6, 0, sizeof(sin6));\n\t\t\tsin6.sin6_family = AF_INET6;\n\t\t\tsin6.sin6_port = htons(port);\n\t\t\tif (hints->ai_flags & EVUTIL_AI_PASSIVE) {\n\t\t\t\t/* Bind to :: */\n\t\t\t} else {\n\t\t\t\t/* connect to ::1 */\n\t\t\t\tsin6.sin6_addr.s6_addr[15] = 1;\n\t\t\t}\n\t\t\tres6 = evutil_new_addrinfo_((struct sockaddr*)&sin6,\n\t\t\t    sizeof(sin6), hints);\n\t\t\tif (!res6)\n\t\t\t\treturn EVUTIL_EAI_MEMORY;\n\t\t}\n\n\t\tif (hints->ai_family != PF_INET6) { /* INET or UNSPEC */\n\t\t\tstruct sockaddr_in sin;\n\t\t\tmemset(&sin, 0, sizeof(sin));\n\t\t\tsin.sin_family = AF_INET;\n\t\t\tsin.sin_port = htons(port);\n\t\t\tif (hints->ai_flags & EVUTIL_AI_PASSIVE) {\n\t\t\t\t/* Bind to 0.0.0.0 */\n\t\t\t} else {\n\t\t\t\t/* connect to 127.0.0.1 */\n\t\t\t\tsin.sin_addr.s_addr = htonl(0x7f000001);\n\t\t\t}\n\t\t\tres4 = evutil_new_addrinfo_((struct sockaddr*)&sin,\n\t\t\t    sizeof(sin), hints);\n\t\t\tif (!res4) {\n\t\t\t\tif (res6)\n\t\t\t\t\tevutil_freeaddrinfo(res6);\n\t\t\t\treturn EVUTIL_EAI_MEMORY;\n\t\t\t}\n\t\t}\n\t\t*res = evutil_addrinfo_append_(res4, res6);\n\t\treturn 0;\n\t}\n\n\t/* If we can, we should try to parse the hostname without resolving\n\t * it. */\n\t/* Try ipv6. */\n\tif (hints->ai_family == PF_INET6 || hints->ai_family == PF_UNSPEC) {\n\t\tstruct sockaddr_in6 sin6;\n\t\tmemset(&sin6, 0, sizeof(sin6));\n\t\tif (1 == evutil_inet_pton_scope(\n\t\t\tAF_INET6, nodename, &sin6.sin6_addr, &if_index)) {\n\t\t\t/* Got an ipv6 address. */\n\t\t\tsin6.sin6_family = AF_INET6;\n\t\t\tsin6.sin6_port = htons(port);\n\t\t\tsin6.sin6_scope_id = if_index;\n\t\t\t*res = evutil_new_addrinfo_((struct sockaddr*)&sin6,\n\t\t\t    sizeof(sin6), hints);\n\t\t\tif (!*res)\n\t\t\t\treturn EVUTIL_EAI_MEMORY;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* Try ipv4. */\n\tif (hints->ai_family == PF_INET || hints->ai_family == PF_UNSPEC) {\n\t\tstruct sockaddr_in sin;\n\t\tmemset(&sin, 0, sizeof(sin));\n\t\tif (1==evutil_inet_pton(AF_INET, nodename, &sin.sin_addr)) {\n\t\t\t/* Got an ipv4 address. */\n\t\t\tsin.sin_family = AF_INET;\n\t\t\tsin.sin_port = htons(port);\n\t\t\t*res = evutil_new_addrinfo_((struct sockaddr*)&sin,\n\t\t\t    sizeof(sin), hints);\n\t\t\tif (!*res)\n\t\t\t\treturn EVUTIL_EAI_MEMORY;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\n\t/* If we have reached this point, we definitely need to do a DNS\n\t * lookup. */\n\tif ((hints->ai_flags & EVUTIL_AI_NUMERICHOST)) {\n\t\t/* If we're not allowed to do one, then say so. */\n\t\treturn EVUTIL_EAI_NONAME;\n\t}\n\t*portnum = port;\n\treturn EVUTIL_EAI_NEED_RESOLVE;\n}\n\n#ifdef EVENT__HAVE_GETADDRINFO\n#define USE_NATIVE_GETADDRINFO\n#endif\n\n#ifdef USE_NATIVE_GETADDRINFO\n/* A mask of all the flags that we declare, so we can clear them before calling\n * the native getaddrinfo */\nstatic const unsigned int ALL_NONNATIVE_AI_FLAGS =\n#ifndef AI_PASSIVE\n    EVUTIL_AI_PASSIVE |\n#endif\n#ifndef AI_CANONNAME\n    EVUTIL_AI_CANONNAME |\n#endif\n#ifndef AI_NUMERICHOST\n    EVUTIL_AI_NUMERICHOST |\n#endif\n#ifndef AI_NUMERICSERV\n    EVUTIL_AI_NUMERICSERV |\n#endif\n#ifndef AI_ADDRCONFIG\n    EVUTIL_AI_ADDRCONFIG |\n#endif\n#ifndef AI_ALL\n    EVUTIL_AI_ALL |\n#endif\n#ifndef AI_V4MAPPED\n    EVUTIL_AI_V4MAPPED |\n#endif\n    EVUTIL_AI_LIBEVENT_ALLOCATED;\n\nstatic const unsigned int ALL_NATIVE_AI_FLAGS =\n#ifdef AI_PASSIVE\n    AI_PASSIVE |\n#endif\n#ifdef AI_CANONNAME\n    AI_CANONNAME |\n#endif\n#ifdef AI_NUMERICHOST\n    AI_NUMERICHOST |\n#endif\n#ifdef AI_NUMERICSERV\n    AI_NUMERICSERV |\n#endif\n#ifdef AI_ADDRCONFIG\n    AI_ADDRCONFIG |\n#endif\n#ifdef AI_ALL\n    AI_ALL |\n#endif\n#ifdef AI_V4MAPPED\n    AI_V4MAPPED |\n#endif\n    0;\n#endif\n\n#ifndef USE_NATIVE_GETADDRINFO\n/* Helper for systems with no getaddrinfo(): make one or more addrinfos out of\n * a struct hostent.\n */\nstatic struct evutil_addrinfo *\naddrinfo_from_hostent(const struct hostent *ent,\n    int port, const struct evutil_addrinfo *hints)\n{\n\tint i;\n\tstruct sockaddr_in sin;\n\tstruct sockaddr_in6 sin6;\n\tstruct sockaddr *sa;\n\tint socklen;\n\tstruct evutil_addrinfo *res=NULL, *ai;\n\tvoid *addrp;\n\n\tif (ent->h_addrtype == PF_INET) {\n\t\tmemset(&sin, 0, sizeof(sin));\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_port = htons(port);\n\t\tsa = (struct sockaddr *)&sin;\n\t\tsocklen = sizeof(struct sockaddr_in);\n\t\taddrp = &sin.sin_addr;\n\t\tif (ent->h_length != sizeof(sin.sin_addr)) {\n\t\t\tevent_warnx(\"Weird h_length from gethostbyname\");\n\t\t\treturn NULL;\n\t\t}\n\t} else if (ent->h_addrtype == PF_INET6) {\n\t\tmemset(&sin6, 0, sizeof(sin6));\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_port = htons(port);\n\t\tsa = (struct sockaddr *)&sin6;\n\t\tsocklen = sizeof(struct sockaddr_in6);\n\t\taddrp = &sin6.sin6_addr;\n\t\tif (ent->h_length != sizeof(sin6.sin6_addr)) {\n\t\t\tevent_warnx(\"Weird h_length from gethostbyname\");\n\t\t\treturn NULL;\n\t\t}\n\t} else\n\t\treturn NULL;\n\n\tfor (i = 0; ent->h_addr_list[i]; ++i) {\n\t\tmemcpy(addrp, ent->h_addr_list[i], ent->h_length);\n\t\tai = evutil_new_addrinfo_(sa, socklen, hints);\n\t\tif (!ai) {\n\t\t\tevutil_freeaddrinfo(res);\n\t\t\treturn NULL;\n\t\t}\n\t\tres = evutil_addrinfo_append_(res, ai);\n\t}\n\n\tif (res && ((hints->ai_flags & EVUTIL_AI_CANONNAME) && ent->h_name)) {\n\t\tres->ai_canonname = mm_strdup(ent->h_name);\n\t\tif (res->ai_canonname == NULL) {\n\t\t\tevutil_freeaddrinfo(res);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\treturn res;\n}\n#endif\n\n/* If the EVUTIL_AI_ADDRCONFIG flag is set on hints->ai_flags, and\n * hints->ai_family is PF_UNSPEC, then revise the value of hints->ai_family so\n * that we'll only get addresses we could maybe connect to.\n */\nvoid\nevutil_adjust_hints_for_addrconfig_(struct evutil_addrinfo *hints)\n{\n\tif (!(hints->ai_flags & EVUTIL_AI_ADDRCONFIG))\n\t\treturn;\n\tif (hints->ai_family != PF_UNSPEC)\n\t\treturn;\n\tevutil_check_interfaces();\n\tif (had_ipv4_address && !had_ipv6_address) {\n\t\thints->ai_family = PF_INET;\n\t} else if (!had_ipv4_address && had_ipv6_address) {\n\t\thints->ai_family = PF_INET6;\n\t}\n}\n\n#ifdef USE_NATIVE_GETADDRINFO\nstatic int need_numeric_port_hack_=0;\nstatic int need_socktype_protocol_hack_=0;\nstatic int tested_for_getaddrinfo_hacks=0;\n\n/* Some older BSDs (like OpenBSD up to 4.6) used to believe that\n   giving a numeric port without giving an ai_socktype was verboten.\n   We test for this so we can apply an appropriate workaround.  If it\n   turns out that the bug is present, then:\n\n    - If nodename==NULL and servname is numeric, we build an answer\n      ourselves using evutil_getaddrinfo_common_().\n\n    - If nodename!=NULL and servname is numeric, then we set\n      servname=NULL when calling getaddrinfo, and post-process the\n      result to set the ports on it.\n\n   We test for this bug at runtime, since otherwise we can't have the\n   same binary run on multiple BSD versions.\n\n   - Some versions of Solaris believe that it's nice to leave to protocol\n     field set to 0.  We test for this so we can apply an appropriate\n     workaround.\n*/\nstatic struct evutil_addrinfo *ai_find_protocol(struct evutil_addrinfo *ai)\n{\n\twhile (ai) {\n\t\tif (ai->ai_protocol)\n\t\t\treturn ai;\n\t\tai = ai->ai_next;\n\t}\n\treturn NULL;\n}\nstatic void\ntest_for_getaddrinfo_hacks(void)\n{\n\tint r, r2;\n\tstruct evutil_addrinfo *ai=NULL, *ai2=NULL, *ai3=NULL;\n\tstruct evutil_addrinfo hints;\n\n\tmemset(&hints,0,sizeof(hints));\n\thints.ai_family = PF_UNSPEC;\n\thints.ai_flags =\n#ifdef AI_NUMERICHOST\n\t    AI_NUMERICHOST |\n#endif\n#ifdef AI_NUMERICSERV\n\t    AI_NUMERICSERV |\n#endif\n\t    0;\n\tr = getaddrinfo(\"1.2.3.4\", \"80\", &hints, &ai);\n\tgetaddrinfo(\"1.2.3.4\", NULL, &hints, &ai3);\n\thints.ai_socktype = SOCK_STREAM;\n\tr2 = getaddrinfo(\"1.2.3.4\", \"80\", &hints, &ai2);\n\tif (r2 == 0 && r != 0) {\n\t\tneed_numeric_port_hack_=1;\n\t}\n\tif (!ai_find_protocol(ai2) || !ai_find_protocol(ai3)) {\n\t\tneed_socktype_protocol_hack_=1;\n\t}\n\n\tif (ai)\n\t\tfreeaddrinfo(ai);\n\tif (ai2)\n\t\tfreeaddrinfo(ai2);\n\tif (ai3)\n\t\tfreeaddrinfo(ai3);\n\ttested_for_getaddrinfo_hacks=1;\n}\n\nstatic inline int\nneed_numeric_port_hack(void)\n{\n\tif (!tested_for_getaddrinfo_hacks)\n\t\ttest_for_getaddrinfo_hacks();\n\treturn need_numeric_port_hack_;\n}\n\nstatic inline int\nneed_socktype_protocol_hack(void)\n{\n\tif (!tested_for_getaddrinfo_hacks)\n\t\ttest_for_getaddrinfo_hacks();\n\treturn need_socktype_protocol_hack_;\n}\n\nstatic void\napply_numeric_port_hack(int port, struct evutil_addrinfo **ai)\n{\n\t/* Now we run through the list and set the ports on all of the\n\t * results where ports would make sense. */\n\tfor ( ; *ai; ai = &(*ai)->ai_next) {\n\t\tstruct sockaddr *sa = (*ai)->ai_addr;\n\t\tif (sa && sa->sa_family == AF_INET) {\n\t\t\tstruct sockaddr_in *sin = (struct sockaddr_in*)sa;\n\t\t\tsin->sin_port = htons(port);\n\t\t} else if (sa && sa->sa_family == AF_INET6) {\n\t\t\tstruct sockaddr_in6 *sin6 = (struct sockaddr_in6*)sa;\n\t\t\tsin6->sin6_port = htons(port);\n\t\t} else {\n\t\t\t/* A numeric port makes no sense here; remove this one\n\t\t\t * from the list. */\n\t\t\tstruct evutil_addrinfo *victim = *ai;\n\t\t\t*ai = victim->ai_next;\n\t\t\tvictim->ai_next = NULL;\n\t\t\tfreeaddrinfo(victim);\n\t\t}\n\t}\n}\n\nstatic int\napply_socktype_protocol_hack(struct evutil_addrinfo *ai)\n{\n\tstruct evutil_addrinfo *ai_new;\n\tfor (; ai; ai = ai->ai_next) {\n\t\tevutil_getaddrinfo_infer_protocols(ai);\n\t\tif (ai->ai_socktype || ai->ai_protocol)\n\t\t\tcontinue;\n\t\tai_new = mm_malloc(sizeof(*ai_new));\n\t\tif (!ai_new)\n\t\t\treturn -1;\n\t\tmemcpy(ai_new, ai, sizeof(*ai_new));\n\t\tai->ai_socktype = SOCK_STREAM;\n\t\tai->ai_protocol = IPPROTO_TCP;\n\t\tai_new->ai_socktype = SOCK_DGRAM;\n\t\tai_new->ai_protocol = IPPROTO_UDP;\n\t\tai_new->ai_flags = EVUTIL_AI_LIBEVENT_ALLOCATED;\n\t\tif (ai_new->ai_canonname != NULL) {\n\t\t\tai_new->ai_canonname = mm_strdup(ai_new->ai_canonname);\n\t\t\tif (ai_new->ai_canonname == NULL) {\n\t\t\t\tmm_free(ai_new);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tai_new->ai_next = ai->ai_next;\n\t\tai->ai_next = ai_new;\n\t}\n\treturn 0;\n}\n#endif\n\nint\nevutil_getaddrinfo(const char *nodename, const char *servname,\n    const struct evutil_addrinfo *hints_in, struct evutil_addrinfo **res)\n{\n#ifdef USE_NATIVE_GETADDRINFO\n\tstruct evutil_addrinfo hints;\n\tint portnum=-1, need_np_hack, err;\n\n\tif (hints_in) {\n\t\tmemcpy(&hints, hints_in, sizeof(hints));\n\t} else {\n\t\tmemset(&hints, 0, sizeof(hints));\n\t\thints.ai_family = PF_UNSPEC;\n\t}\n\n#ifndef AI_ADDRCONFIG\n\t/* Not every system has AI_ADDRCONFIG, so fake it. */\n\tif (hints.ai_family == PF_UNSPEC &&\n\t    (hints.ai_flags & EVUTIL_AI_ADDRCONFIG)) {\n\t\tevutil_adjust_hints_for_addrconfig_(&hints);\n\t}\n#endif\n\n#ifndef AI_NUMERICSERV\n\t/* Not every system has AI_NUMERICSERV, so fake it. */\n\tif (hints.ai_flags & EVUTIL_AI_NUMERICSERV) {\n\t\tif (servname && parse_numeric_servname(servname)<0)\n\t\t\treturn EVUTIL_EAI_NONAME;\n\t}\n#endif\n\n\t/* Enough operating systems handle enough common non-resolve\n\t * cases here weirdly enough that we are better off just\n\t * overriding them.  For example:\n\t *\n\t * - Windows doesn't like to infer the protocol from the\n\t *   socket type, or fill in socket or protocol types much at\n\t *   all.  It also seems to do its own broken implicit\n\t *   always-on version of AI_ADDRCONFIG that keeps it from\n\t *   ever resolving even a literal IPv6 address when\n\t *   ai_addrtype is PF_UNSPEC.\n\t */\n#ifdef _WIN32\n\t{\n\t\tint tmp_port;\n\t\terr = evutil_getaddrinfo_common_(nodename,servname,&hints,\n\t\t    res, &tmp_port);\n\t\tif (err == 0 ||\n\t\t    err == EVUTIL_EAI_MEMORY ||\n\t\t    err == EVUTIL_EAI_NONAME)\n\t\t\treturn err;\n\t\t/* If we make it here, the system getaddrinfo can\n\t\t * have a crack at it. */\n\t}\n#endif\n\n\t/* See documentation for need_numeric_port_hack above.*/\n\tneed_np_hack = need_numeric_port_hack() && servname && !hints.ai_socktype\n\t    && ((portnum=parse_numeric_servname(servname)) >= 0);\n\tif (need_np_hack) {\n\t\tif (!nodename)\n\t\t\treturn evutil_getaddrinfo_common_(\n\t\t\t\tNULL,servname,&hints, res, &portnum);\n\t\tservname = NULL;\n\t}\n\n\tif (need_socktype_protocol_hack()) {\n\t\tevutil_getaddrinfo_infer_protocols(&hints);\n\t}\n\n\t/* Make sure that we didn't actually steal any AI_FLAGS values that\n\t * the system is using.  (This is a constant expression, and should ge\n\t * optimized out.)\n\t *\n\t * XXXX Turn this into a compile-time failure rather than a run-time\n\t * failure.\n\t */\n\tEVUTIL_ASSERT((ALL_NONNATIVE_AI_FLAGS & ALL_NATIVE_AI_FLAGS) == 0);\n\n\t/* Clear any flags that only libevent understands. */\n\thints.ai_flags &= ~ALL_NONNATIVE_AI_FLAGS;\n\n\terr = getaddrinfo(nodename, servname, &hints, res);\n\tif (need_np_hack)\n\t\tapply_numeric_port_hack(portnum, res);\n\n\tif (need_socktype_protocol_hack()) {\n\t\tif (apply_socktype_protocol_hack(*res) < 0) {\n\t\t\tevutil_freeaddrinfo(*res);\n\t\t\t*res = NULL;\n\t\t\treturn EVUTIL_EAI_MEMORY;\n\t\t}\n\t}\n\treturn err;\n#else\n\tint port=0, err;\n\tstruct hostent *ent = NULL;\n\tstruct evutil_addrinfo hints;\n\n\tif (hints_in) {\n\t\tmemcpy(&hints, hints_in, sizeof(hints));\n\t} else {\n\t\tmemset(&hints, 0, sizeof(hints));\n\t\thints.ai_family = PF_UNSPEC;\n\t}\n\n\tevutil_adjust_hints_for_addrconfig_(&hints);\n\n\terr = evutil_getaddrinfo_common_(nodename, servname, &hints, res, &port);\n\tif (err != EVUTIL_EAI_NEED_RESOLVE) {\n\t\t/* We either succeeded or failed.  No need to continue */\n\t\treturn err;\n\t}\n\n\terr = 0;\n\t/* Use any of the various gethostbyname_r variants as available. */\n\t{\n#ifdef EVENT__HAVE_GETHOSTBYNAME_R_6_ARG\n\t\t/* This one is what glibc provides. */\n\t\tchar buf[2048];\n\t\tstruct hostent hostent;\n\t\tint r;\n\t\tr = gethostbyname_r(nodename, &hostent, buf, sizeof(buf), &ent,\n\t\t    &err);\n#elif defined(EVENT__HAVE_GETHOSTBYNAME_R_5_ARG)\n\t\tchar buf[2048];\n\t\tstruct hostent hostent;\n\t\tent = gethostbyname_r(nodename, &hostent, buf, sizeof(buf),\n\t\t    &err);\n#elif defined(EVENT__HAVE_GETHOSTBYNAME_R_3_ARG)\n\t\tstruct hostent_data data;\n\t\tstruct hostent hostent;\n\t\tmemset(&data, 0, sizeof(data));\n\t\terr = gethostbyname_r(nodename, &hostent, &data);\n\t\tent = err ? NULL : &hostent;\n#else\n\t\t/* fall back to gethostbyname. */\n\t\t/* XXXX This needs a lock everywhere but Windows. */\n\t\tent = gethostbyname(nodename);\n#ifdef _WIN32\n\t\terr = WSAGetLastError();\n#else\n\t\terr = h_errno;\n#endif\n#endif\n\n\t\t/* Now we have either ent or err set. */\n\t\tif (!ent) {\n\t\t\t/* XXX is this right for windows ? */\n\t\t\tswitch (err) {\n\t\t\tcase TRY_AGAIN:\n\t\t\t\treturn EVUTIL_EAI_AGAIN;\n\t\t\tcase NO_RECOVERY:\n\t\t\tdefault:\n\t\t\t\treturn EVUTIL_EAI_FAIL;\n\t\t\tcase HOST_NOT_FOUND:\n\t\t\t\treturn EVUTIL_EAI_NONAME;\n\t\t\tcase NO_ADDRESS:\n#if NO_DATA != NO_ADDRESS\n\t\t\tcase NO_DATA:\n#endif\n\t\t\t\treturn EVUTIL_EAI_NODATA;\n\t\t\t}\n\t\t}\n\n\t\tif (ent->h_addrtype != hints.ai_family &&\n\t\t    hints.ai_family != PF_UNSPEC) {\n\t\t\t/* This wasn't the type we were hoping for.  Too bad\n\t\t\t * we never had a chance to ask gethostbyname for what\n\t\t\t * we wanted. */\n\t\t\treturn EVUTIL_EAI_NONAME;\n\t\t}\n\n\t\t/* Make sure we got _some_ answers. */\n\t\tif (ent->h_length == 0)\n\t\t\treturn EVUTIL_EAI_NODATA;\n\n\t\t/* If we got an address type we don't know how to make a\n\t\t   sockaddr for, give up. */\n\t\tif (ent->h_addrtype != PF_INET && ent->h_addrtype != PF_INET6)\n\t\t\treturn EVUTIL_EAI_FAMILY;\n\n\t\t*res = addrinfo_from_hostent(ent, port, &hints);\n\t\tif (! *res)\n\t\t\treturn EVUTIL_EAI_MEMORY;\n\t}\n\n\treturn 0;\n#endif\n}\n\nvoid\nevutil_freeaddrinfo(struct evutil_addrinfo *ai)\n{\n#ifdef EVENT__HAVE_GETADDRINFO\n\tstruct evutil_addrinfo *ai_prev = NULL;\n\tstruct evutil_addrinfo *ai_temp = ai;\n\t/* Linked list may be the result of a native getaddrinfo() call plus\n\t * locally allocated nodes, Before releasing it using freeaddrinfo(),\n\t * these custom structs need to be freed separately.\n\t */\n\twhile (ai_temp) {\n\t\tstruct evutil_addrinfo *next = ai_temp->ai_next;\n\t\tif (ai_temp->ai_flags & EVUTIL_AI_LIBEVENT_ALLOCATED) {\n\t\t\t/* Remove this node from the linked list */\n\t\t\tif (ai_temp->ai_canonname)\n\t\t\t\tmm_free(ai_temp->ai_canonname);\n\t\t\tmm_free(ai_temp);\n\t\t\tif (ai_prev == NULL) {\n\t\t\t\tai = next;\n\t\t\t} else {\n\t\t\t\tai_prev->ai_next = next;\n\t\t\t}\n\n\t\t} else {\n\t\t\tai_prev = ai_temp;\n\t\t}\n\t\tai_temp = next;\n\t}\n\tif (ai != NULL)\n\t\tfreeaddrinfo(ai);\n#else\n\twhile (ai) {\n\t\tstruct evutil_addrinfo *next = ai->ai_next;\n\t\tif (ai->ai_canonname)\n\t\t\tmm_free(ai->ai_canonname);\n\t\tmm_free(ai);\n\t\tai = next;\n\t}\n#endif\n}\n\nstruct evutil_addrinfo *\nevutil_dup_addrinfo_(struct evutil_addrinfo *ai)\n{\n\tstruct evutil_addrinfo *first = NULL;\n\tstruct evutil_addrinfo *prev = NULL;\n\tfor (; ai; ai = ai->ai_next) {\n\t\tint len = sizeof(struct evutil_addrinfo) + ai->ai_addrlen;\n\t\tstruct evutil_addrinfo *n = mm_calloc(1, len);\n\t\tmemcpy(n, ai, len);\n\t\tif (ai->ai_canonname) {\n\t\t\tn->ai_canonname = mm_strdup(ai->ai_canonname);\n\t\t}\n\t\tn->ai_addr = (struct sockaddr*)(((char*)n) + sizeof(struct evutil_addrinfo));\n\t\tif (!first) {\n\t\t\tfirst = n;\n\t\t} else {\n\t\t\tprev->ai_next = n;\n\t\t}\n\t\tprev = n;\n\t}\n\treturn first;\n}\n\nstatic evdns_getaddrinfo_fn evdns_getaddrinfo_impl = NULL;\nstatic evdns_getaddrinfo_cancel_fn evdns_getaddrinfo_cancel_impl = NULL;\n\nvoid\nevutil_set_evdns_getaddrinfo_fn_(evdns_getaddrinfo_fn fn)\n{\n\tif (!evdns_getaddrinfo_impl)\n\t\tevdns_getaddrinfo_impl = fn;\n}\nvoid\nevutil_set_evdns_getaddrinfo_cancel_fn_(evdns_getaddrinfo_cancel_fn fn)\n{\n\tif (!evdns_getaddrinfo_cancel_impl)\n\t\tevdns_getaddrinfo_cancel_impl = fn;\n}\n\nstatic const char *evutil_custom_resolvconf_filename = NULL;\n\nvoid\nevutil_set_resolvconf_filename_(const char *filename)\n{\n\tevutil_custom_resolvconf_filename = filename;\n}\n\nconst char *\nevutil_resolvconf_filename_(void)\n{\n\tif (evutil_custom_resolvconf_filename)\n\t\treturn evutil_custom_resolvconf_filename;\n\n\treturn \"/etc/resolv.conf\";\n}\n\n/* Internal helper function: act like evdns_getaddrinfo if dns_base is set;\n * otherwise do a blocking resolve and pass the result to the callback in the\n * way that evdns_getaddrinfo would.\n */\nstruct evdns_getaddrinfo_request *evutil_getaddrinfo_async_(\n    struct evdns_base *dns_base,\n    const char *nodename, const char *servname,\n    const struct evutil_addrinfo *hints_in,\n    void (*cb)(int, struct evutil_addrinfo *, void *), void *arg)\n{\n\tif (dns_base && evdns_getaddrinfo_impl) {\n\t\treturn evdns_getaddrinfo_impl(\n\t\t\tdns_base, nodename, servname, hints_in, cb, arg);\n\t} else {\n\t\tstruct evutil_addrinfo *ai=NULL;\n\t\tint err;\n\t\terr = evutil_getaddrinfo(nodename, servname, hints_in, &ai);\n\t\tcb(err, ai, arg);\n\t\treturn NULL;\n\t}\n}\n\nvoid evutil_getaddrinfo_cancel_async_(struct evdns_getaddrinfo_request *data)\n{\n\tif (evdns_getaddrinfo_cancel_impl && data) {\n\t\tevdns_getaddrinfo_cancel_impl(data);\n\t}\n}\n\nconst char *\nevutil_gai_strerror(int err)\n{\n\t/* As a sneaky side-benefit, this case statement will get most\n\t * compilers to tell us if any of the error codes we defined\n\t * conflict with the platform's native error codes. */\n\tswitch (err) {\n\tcase EVUTIL_EAI_CANCEL:\n\t\treturn \"Request canceled\";\n\tcase 0:\n\t\treturn \"No error\";\n\n\tcase EVUTIL_EAI_ADDRFAMILY:\n\t\treturn \"address family for nodename not supported\";\n\tcase EVUTIL_EAI_AGAIN:\n\t\treturn \"temporary failure in name resolution\";\n\tcase EVUTIL_EAI_BADFLAGS:\n\t\treturn \"invalid value for ai_flags\";\n\tcase EVUTIL_EAI_FAIL:\n\t\treturn \"non-recoverable failure in name resolution\";\n\tcase EVUTIL_EAI_FAMILY:\n\t\treturn \"ai_family not supported\";\n\tcase EVUTIL_EAI_MEMORY:\n\t\treturn \"memory allocation failure\";\n\tcase EVUTIL_EAI_NODATA:\n\t\treturn \"no address associated with nodename\";\n\tcase EVUTIL_EAI_NONAME:\n\t\treturn \"nodename nor servname provided, or not known\";\n\tcase EVUTIL_EAI_SERVICE:\n\t\treturn \"servname not supported for ai_socktype\";\n\tcase EVUTIL_EAI_SOCKTYPE:\n\t\treturn \"ai_socktype not supported\";\n\tcase EVUTIL_EAI_SYSTEM:\n\t\treturn \"system error\";\n\tdefault:\n#if defined(USE_NATIVE_GETADDRINFO) && defined(_WIN32)\n\t\treturn gai_strerrorA(err);\n#elif defined(USE_NATIVE_GETADDRINFO)\n\t\treturn gai_strerror(err);\n#else\n\t\treturn \"Unknown error code\";\n#endif\n\t}\n}\n\n#ifdef _WIN32\n/* destructively remove a trailing line terminator from s */\nstatic void\nchomp (char *s)\n{\n\tsize_t len;\n\tif (s && (len = strlen (s)) > 0 && s[len - 1] == '\\n') {\n\t\ts[--len] = 0;\n\t\tif (len > 0 && s[len - 1] == '\\r')\n\t\t\ts[--len] = 0;\n\t}\n}\n\n/* FormatMessage returns allocated strings, but evutil_socket_error_to_string\n * is supposed to return a string which is good indefinitely without having\n * to be freed.  To make this work without leaking memory, we cache the\n * string the first time FormatMessage is called on a particular error\n * code, and then return the cached string on subsequent calls with the\n * same code.  The strings aren't freed until libevent_global_shutdown\n * (or never).  We use a linked list to cache the errors, because we\n * only expect there to be a few dozen, and that should be fast enough.\n */\n\nstruct cached_sock_errs_entry {\n\tHT_ENTRY(cached_sock_errs_entry) node;\n\tDWORD code;\n\tchar *msg; /* allocated with LocalAlloc; free with LocalFree */\n};\n\nstatic inline unsigned\nhash_cached_sock_errs(const struct cached_sock_errs_entry *e)\n{\n\t/* Use Murmur3's 32-bit finalizer as an integer hash function */\n\tDWORD h = e->code;\n\th ^= h >> 16;\n\th *= 0x85ebca6b;\n\th ^= h >> 13;\n\th *= 0xc2b2ae35;\n\th ^= h >> 16;\n\treturn h;\n}\n\nstatic inline int\neq_cached_sock_errs(const struct cached_sock_errs_entry *a,\n\t\t    const struct cached_sock_errs_entry *b)\n{\n\treturn a->code == b->code;\n}\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nstatic void *windows_socket_errors_lock_ = NULL;\n#endif\n\nstatic HT_HEAD(cached_sock_errs_map, cached_sock_errs_entry)\n     windows_socket_errors = HT_INITIALIZER();\n\nHT_PROTOTYPE(cached_sock_errs_map,\n\t     cached_sock_errs_entry,\n\t     node,\n\t     hash_cached_sock_errs,\n\t     eq_cached_sock_errs);\n\nHT_GENERATE(cached_sock_errs_map,\n\t    cached_sock_errs_entry,\n\t    node,\n\t    hash_cached_sock_errs,\n\t    eq_cached_sock_errs,\n\t    0.5,\n\t    mm_malloc,\n\t    mm_realloc,\n\t    mm_free);\n\n/** Equivalent to strerror, but for windows socket errors. */\nconst char *\nevutil_socket_error_to_string(int errcode)\n{\n\tstruct cached_sock_errs_entry *errs, *newerr, find;\n\tchar *msg = NULL;\n\n\tEVLOCK_LOCK(windows_socket_errors_lock_, 0);\n\n\tfind.code = errcode;\n\terrs = HT_FIND(cached_sock_errs_map, &windows_socket_errors, &find);\n\tif (errs) {\n\t\tmsg = errs->msg;\n\t\tgoto done;\n\t}\n\n\tif (0 != FormatMessageA(FORMAT_MESSAGE_FROM_SYSTEM |\n\t\t\t       FORMAT_MESSAGE_IGNORE_INSERTS |\n\t\t\t       FORMAT_MESSAGE_ALLOCATE_BUFFER,\n\t\t\t       NULL, errcode, 0, (char *)&msg, 0, NULL))\n\t\tchomp (msg);\t/* because message has trailing newline */\n\telse {\n\t\tsize_t len = 50;\n\t\t/* use LocalAlloc because FormatMessage does */\n\t\tmsg = LocalAlloc(LMEM_FIXED, len);\n\t\tif (!msg) {\n\t\t\tmsg = (char *)\"LocalAlloc failed during Winsock error\";\n\t\t\tgoto done;\n\t\t}\n\t\tevutil_snprintf(msg, len, \"winsock error 0x%08x\", errcode);\n\t}\n\n\tnewerr = (struct cached_sock_errs_entry *)\n\t\tmm_malloc(sizeof (struct cached_sock_errs_entry));\n\n\tif (!newerr) {\n\t\tLocalFree(msg);\n\t\tmsg = (char *)\"malloc failed during Winsock error\";\n\t\tgoto done;\n\t}\n\n\tnewerr->code = errcode;\n\tnewerr->msg = msg;\n\tHT_INSERT(cached_sock_errs_map, &windows_socket_errors, newerr);\n\n done:\n\tEVLOCK_UNLOCK(windows_socket_errors_lock_, 0);\n\n\treturn msg;\n}\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevutil_global_setup_locks_(const int enable_locks)\n{\n\tEVTHREAD_SETUP_GLOBAL_LOCK(windows_socket_errors_lock_, 0);\n\treturn 0;\n}\n#endif\n\nstatic void\nevutil_free_sock_err_globals(void)\n{\n\tstruct cached_sock_errs_entry **errs, *tofree;\n\n\tfor (errs = HT_START(cached_sock_errs_map, &windows_socket_errors)\n\t\t     ; errs; ) {\n\t\ttofree = *errs;\n\t\terrs = HT_NEXT_RMV(cached_sock_errs_map,\n\t\t\t\t   &windows_socket_errors,\n\t\t\t\t   errs);\n\t\tLocalFree(tofree->msg);\n\t\tmm_free(tofree);\n\t}\n\n\tHT_CLEAR(cached_sock_errs_map, &windows_socket_errors);\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (windows_socket_errors_lock_ != NULL) {\n\t\tEVTHREAD_FREE_LOCK(windows_socket_errors_lock_, 0);\n\t\twindows_socket_errors_lock_ = NULL;\n\t}\n#endif\n}\n\n#else\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevutil_global_setup_locks_(const int enable_locks)\n{\n\treturn 0;\n}\n#endif\n\nstatic void\nevutil_free_sock_err_globals(void)\n{\n}\n\n#endif\n\nint\nevutil_snprintf(char *buf, size_t buflen, const char *format, ...)\n{\n\tint r;\n\tva_list ap;\n\tva_start(ap, format);\n\tr = evutil_vsnprintf(buf, buflen, format, ap);\n\tva_end(ap);\n\treturn r;\n}\n\nint\nevutil_vsnprintf(char *buf, size_t buflen, const char *format, va_list ap)\n{\n\tint r;\n\tif (!buflen)\n\t\treturn 0;\n#if defined(_MSC_VER) || defined(_WIN32)\n\tr = _vsnprintf(buf, buflen, format, ap);\n\tif (r < 0)\n\t\tr = _vscprintf(format, ap);\n#elif defined(sgi)\n\t/* Make sure we always use the correct vsnprintf on IRIX */\n\textern int      _xpg5_vsnprintf(char * __restrict,\n\t\t__SGI_LIBC_NAMESPACE_QUALIFIER size_t,\n\t\tconst char * __restrict, /* va_list */ char *);\n\n\tr = _xpg5_vsnprintf(buf, buflen, format, ap);\n#else\n\tr = vsnprintf(buf, buflen, format, ap);\n#endif\n\tbuf[buflen-1] = '\\0';\n\treturn r;\n}\n\n#define USE_INTERNAL_NTOP\n#define USE_INTERNAL_PTON\n\nconst char *\nevutil_inet_ntop(int af, const void *src, char *dst, size_t len)\n{\n#if defined(EVENT__HAVE_INET_NTOP) && !defined(USE_INTERNAL_NTOP)\n\treturn inet_ntop(af, src, dst, len);\n#else\n\tif (af == AF_INET) {\n\t\tconst struct in_addr *in = src;\n\t\tconst ev_uint32_t a = ntohl(in->s_addr);\n\t\tint r;\n\t\tr = evutil_snprintf(dst, len, \"%d.%d.%d.%d\",\n\t\t    (int)(ev_uint8_t)((a>>24)&0xff),\n\t\t    (int)(ev_uint8_t)((a>>16)&0xff),\n\t\t    (int)(ev_uint8_t)((a>>8 )&0xff),\n\t\t    (int)(ev_uint8_t)((a    )&0xff));\n\t\tif (r<0||(size_t)r>=len)\n\t\t\treturn NULL;\n\t\telse\n\t\t\treturn dst;\n#ifdef AF_INET6\n\t} else if (af == AF_INET6) {\n\t\tconst struct in6_addr *addr = src;\n\t\tchar buf[64], *cp;\n\t\tint longestGapLen = 0, longestGapPos = -1, i,\n\t\t\tcurGapPos = -1, curGapLen = 0;\n\t\tev_uint16_t words[8];\n\t\tfor (i = 0; i < 8; ++i) {\n\t\t\twords[i] =\n\t\t\t    (((ev_uint16_t)addr->s6_addr[2*i])<<8) + addr->s6_addr[2*i+1];\n\t\t}\n\t\tif (words[0] == 0 && words[1] == 0 && words[2] == 0 && words[3] == 0 &&\n\t\t    words[4] == 0 && ((words[5] == 0 && words[6] && words[7]) ||\n\t\t\t(words[5] == 0xffff))) {\n\t\t\t/* This is an IPv4 address. */\n\t\t\tif (words[5] == 0) {\n\t\t\t\tevutil_snprintf(buf, sizeof(buf), \"::%d.%d.%d.%d\",\n\t\t\t\t    addr->s6_addr[12], addr->s6_addr[13],\n\t\t\t\t    addr->s6_addr[14], addr->s6_addr[15]);\n\t\t\t} else {\n\t\t\t\tevutil_snprintf(buf, sizeof(buf), \"::%x:%d.%d.%d.%d\", words[5],\n\t\t\t\t    addr->s6_addr[12], addr->s6_addr[13],\n\t\t\t\t    addr->s6_addr[14], addr->s6_addr[15]);\n\t\t\t}\n\t\t\tif (strlen(buf) > len)\n\t\t\t\treturn NULL;\n\t\t\tstrlcpy(dst, buf, len);\n\t\t\treturn dst;\n\t\t}\n\t\ti = 0;\n\t\twhile (i < 8) {\n\t\t\tif (words[i] == 0) {\n\t\t\t\tcurGapPos = i++;\n\t\t\t\tcurGapLen = 1;\n\t\t\t\twhile (i<8 && words[i] == 0) {\n\t\t\t\t\t++i; ++curGapLen;\n\t\t\t\t}\n\t\t\t\tif (curGapLen > longestGapLen) {\n\t\t\t\t\tlongestGapPos = curGapPos;\n\t\t\t\t\tlongestGapLen = curGapLen;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t++i;\n\t\t\t}\n\t\t}\n\t\tif (longestGapLen<=1)\n\t\t\tlongestGapPos = -1;\n\n\t\tcp = buf;\n\t\tfor (i = 0; i < 8; ++i) {\n\t\t\tif (words[i] == 0 && longestGapPos == i) {\n\t\t\t\tif (i == 0)\n\t\t\t\t\t*cp++ = ':';\n\t\t\t\t*cp++ = ':';\n\t\t\t\twhile (i < 8 && words[i] == 0)\n\t\t\t\t\t++i;\n\t\t\t\t--i; /* to compensate for loop increment. */\n\t\t\t} else {\n\t\t\t\tevutil_snprintf(cp,\n\t\t\t\t\t\t\t\tsizeof(buf)-(cp-buf), \"%x\", (unsigned)words[i]);\n\t\t\t\tcp += strlen(cp);\n\t\t\t\tif (i != 7)\n\t\t\t\t\t*cp++ = ':';\n\t\t\t}\n\t\t}\n\t\t*cp = '\\0';\n\t\tif (strlen(buf) > len)\n\t\t\treturn NULL;\n\t\tstrlcpy(dst, buf, len);\n\t\treturn dst;\n#endif\n\t} else {\n\t\treturn NULL;\n\t}\n#endif\n}\n\nint\nevutil_inet_pton_scope(int af, const char *src, void *dst, unsigned *indexp)\n{\n\tint r;\n\tunsigned if_index;\n\tchar *check, *cp, *tmp_src;\n\n\t*indexp = 0; /* Reasonable default */\n\n\t/* Bail out if not IPv6 */\n\tif (af != AF_INET6)\n\t\treturn evutil_inet_pton(af, src, dst);\n\n\tcp = strchr(src, '%');\n\n\t/* Bail out if no zone ID */\n\tif (cp == NULL)\n\t\treturn evutil_inet_pton(af, src, dst);\n\n\tif_index = if_nametoindex(cp + 1);\n\tif (if_index == 0) {\n\t\t/* Could be numeric */\n\t\tif_index = strtoul(cp + 1, &check, 10);\n\t\tif (check[0] != '\\0')\n\t\t\treturn 0;\n\t}\n\t*indexp = if_index;\n\tif (!(tmp_src = mm_strdup(src))) {\n\t\treturn -1;\n\t}\n\tcp = strchr(tmp_src, '%');\n\t// The check had been already done above against original src\n\t*cp = '\\0';\n\tr = evutil_inet_pton(af, tmp_src, dst);\n\tmm_free(tmp_src);\n\treturn r;\n}\n\nint\nevutil_inet_pton(int af, const char *src, void *dst)\n{\n#if defined(EVENT__HAVE_INET_PTON) && !defined(USE_INTERNAL_PTON)\n\treturn inet_pton(af, src, dst);\n#else\n\tif (af == AF_INET) {\n\t\tunsigned a,b,c,d;\n\t\tchar more;\n\t\tstruct in_addr *addr = dst;\n\t\tif (sscanf(src, \"%u.%u.%u.%u%c\", &a,&b,&c,&d,&more) != 4)\n\t\t\treturn 0;\n\t\tif (a > 255) return 0;\n\t\tif (b > 255) return 0;\n\t\tif (c > 255) return 0;\n\t\tif (d > 255) return 0;\n\t\taddr->s_addr = htonl((a<<24) | (b<<16) | (c<<8) | d);\n\t\treturn 1;\n#ifdef AF_INET6\n\t} else if (af == AF_INET6) {\n\t\tstruct in6_addr *out = dst;\n\t\tev_uint16_t words[8];\n\t\tint gapPos = -1, i, setWords=0;\n\t\tconst char *dot = strchr(src, '.');\n\t\tconst char *eow; /* end of words. */\n\t\tif (dot == src)\n\t\t\treturn 0;\n\t\telse if (!dot)\n\t\t\teow = src+strlen(src);\n\t\telse {\n\t\t\tunsigned byte1,byte2,byte3,byte4;\n\t\t\tchar more;\n\t\t\tfor (eow = dot-1; eow >= src && EVUTIL_ISDIGIT_(*eow); --eow)\n\t\t\t\t;\n\t\t\t++eow;\n\n\t\t\t/* We use \"scanf\" because some platform inet_aton()s are too lax\n\t\t\t * about IPv4 addresses of the form \"1.2.3\" */\n\t\t\tif (sscanf(eow, \"%u.%u.%u.%u%c\",\n\t\t\t\t\t   &byte1,&byte2,&byte3,&byte4,&more) != 4)\n\t\t\t\treturn 0;\n\n\t\t\tif (byte1 > 255 ||\n\t\t\t    byte2 > 255 ||\n\t\t\t    byte3 > 255 ||\n\t\t\t    byte4 > 255)\n\t\t\t\treturn 0;\n\n\t\t\twords[6] = (byte1<<8) | byte2;\n\t\t\twords[7] = (byte3<<8) | byte4;\n\t\t\tsetWords += 2;\n\t\t}\n\n\t\ti = 0;\n\t\twhile (src < eow) {\n\t\t\tif (i > 7)\n\t\t\t\treturn 0;\n\t\t\tif (EVUTIL_ISXDIGIT_(*src)) {\n\t\t\t\tchar *next;\n\t\t\t\tlong r = strtol(src, &next, 16);\n\t\t\t\tif (next > 4+src)\n\t\t\t\t\treturn 0;\n\t\t\t\tif (next == src)\n\t\t\t\t\treturn 0;\n\t\t\t\tif (r<0 || r>65536)\n\t\t\t\t\treturn 0;\n\n\t\t\t\twords[i++] = (ev_uint16_t)r;\n\t\t\t\tsetWords++;\n\t\t\t\tsrc = next;\n\t\t\t\tif (*src != ':' && src != eow)\n\t\t\t\t\treturn 0;\n\t\t\t\t++src;\n\t\t\t} else if (*src == ':' && i > 0 && gapPos==-1) {\n\t\t\t\tgapPos = i;\n\t\t\t\t++src;\n\t\t\t} else if (*src == ':' && i == 0 && src[1] == ':' && gapPos==-1) {\n\t\t\t\tgapPos = i;\n\t\t\t\tsrc += 2;\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tif (setWords > 8 ||\n\t\t\t(setWords == 8 && gapPos != -1) ||\n\t\t\t(setWords < 8 && gapPos == -1))\n\t\t\treturn 0;\n\n\t\tif (gapPos >= 0) {\n\t\t\tint nToMove = setWords - (dot ? 2 : 0) - gapPos;\n\t\t\tint gapLen = 8 - setWords;\n\t\t\t/* assert(nToMove >= 0); */\n\t\t\tif (nToMove < 0)\n\t\t\t\treturn -1; /* should be impossible */\n\t\t\tmemmove(&words[gapPos+gapLen], &words[gapPos],\n\t\t\t\t\tsizeof(ev_uint16_t)*nToMove);\n\t\t\tmemset(&words[gapPos], 0, sizeof(ev_uint16_t)*gapLen);\n\t\t}\n\t\tfor (i = 0; i < 8; ++i) {\n\t\t\tout->s6_addr[2*i  ] = words[i] >> 8;\n\t\t\tout->s6_addr[2*i+1] = words[i] & 0xff;\n\t\t}\n\n\t\treturn 1;\n#endif\n\t} else {\n\t\treturn -1;\n\t}\n#endif\n}\n\nint\nevutil_parse_sockaddr_port(const char *ip_as_string, struct sockaddr *out, int *outlen)\n{\n\tint port;\n\tunsigned int if_index;\n\tchar buf[128];\n\tconst char *cp, *addr_part, *port_part;\n\tint is_ipv6;\n\t/* recognized formats are:\n\t * [ipv6]:port\n\t * ipv6\n\t * [ipv6]\n\t * ipv4:port\n\t * ipv4\n\t */\n\n\tcp = strchr(ip_as_string, ':');\n\tif (*ip_as_string == '[') {\n\t\tsize_t len;\n\t\tif (!(cp = strchr(ip_as_string, ']'))) {\n\t\t\treturn -1;\n\t\t}\n\t\tlen = ( cp-(ip_as_string + 1) );\n\t\tif (len > sizeof(buf)-1) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(buf, ip_as_string+1, len);\n\t\tbuf[len] = '\\0';\n\t\taddr_part = buf;\n\t\tif (cp[1] == ':')\n\t\t\tport_part = cp+2;\n\t\telse\n\t\t\tport_part = NULL;\n\t\tis_ipv6 = 1;\n\t} else if (cp && strchr(cp+1, ':')) {\n\t\tis_ipv6 = 1;\n\t\taddr_part = ip_as_string;\n\t\tport_part = NULL;\n\t} else if (cp) {\n\t\tis_ipv6 = 0;\n\t\tif (cp - ip_as_string > (int)sizeof(buf)-1) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(buf, ip_as_string, cp-ip_as_string);\n\t\tbuf[cp-ip_as_string] = '\\0';\n\t\taddr_part = buf;\n\t\tport_part = cp+1;\n\t} else {\n\t\taddr_part = ip_as_string;\n\t\tport_part = NULL;\n\t\tis_ipv6 = 0;\n\t}\n\n\tif (port_part == NULL) {\n\t\tport = 0;\n\t} else {\n\t\tport = atoi(port_part);\n\t\tif (port <= 0 || port > 65535) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (!addr_part)\n\t\treturn -1; /* Should be impossible. */\n#ifdef AF_INET6\n\tif (is_ipv6)\n\t{\n\t\tstruct sockaddr_in6 sin6;\n\t\tmemset(&sin6, 0, sizeof(sin6));\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN6_SIN6_LEN\n\t\tsin6.sin6_len = sizeof(sin6);\n#endif\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_port = htons(port);\n\t\tif (1 != evutil_inet_pton_scope(\n\t\t\tAF_INET6, addr_part, &sin6.sin6_addr, &if_index)) {\n\t\t\treturn -1;\n\t\t}\n\t\tif ((int)sizeof(sin6) > *outlen)\n\t\t\treturn -1;\n\t\tsin6.sin6_scope_id = if_index;\n\t\tmemcpy(out, &sin6, sizeof(sin6));\n\t\t*outlen = sizeof(sin6);\n\t\treturn 0;\n\t}\n\telse\n#endif\n\t{\n\t\tstruct sockaddr_in sin;\n\t\tmemset(&sin, 0, sizeof(sin));\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN\n\t\tsin.sin_len = sizeof(sin);\n#endif\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_port = htons(port);\n\t\tif (1 != evutil_inet_pton(AF_INET, addr_part, &sin.sin_addr))\n\t\t\treturn -1;\n\t\tif ((int)sizeof(sin) > *outlen)\n\t\t\treturn -1;\n\t\tmemcpy(out, &sin, sizeof(sin));\n\t\t*outlen = sizeof(sin);\n\t\treturn 0;\n\t}\n}\n\nconst char *\nevutil_format_sockaddr_port_(const struct sockaddr *sa, char *out, size_t outlen)\n{\n\tchar b[128];\n\tconst char *res=NULL;\n\tint port;\n\tif (sa->sa_family == AF_INET) {\n\t\tconst struct sockaddr_in *sin = (const struct sockaddr_in*)sa;\n\t\tres = evutil_inet_ntop(AF_INET, &sin->sin_addr,b,sizeof(b));\n\t\tport = ntohs(sin->sin_port);\n\t\tif (res) {\n\t\t\tevutil_snprintf(out, outlen, \"%s:%d\", b, port);\n\t\t\treturn out;\n\t\t}\n\t} else if (sa->sa_family == AF_INET6) {\n\t\tconst struct sockaddr_in6 *sin6 = (const struct sockaddr_in6*)sa;\n\t\tres = evutil_inet_ntop(AF_INET6, &sin6->sin6_addr,b,sizeof(b));\n\t\tport = ntohs(sin6->sin6_port);\n\t\tif (res) {\n\t\t\tevutil_snprintf(out, outlen, \"[%s]:%d\", b, port);\n\t\t\treturn out;\n\t\t}\n\t}\n\n\tevutil_snprintf(out, outlen, \"<addr with socktype %d>\",\n\t    (int)sa->sa_family);\n\treturn out;\n}\n\nint\nevutil_sockaddr_cmp(const struct sockaddr *sa1, const struct sockaddr *sa2,\n    int include_port)\n{\n\tint r;\n\tif (0 != (r = (sa1->sa_family - sa2->sa_family)))\n\t\treturn r;\n\n\tif (sa1->sa_family == AF_INET) {\n\t\tconst struct sockaddr_in *sin1, *sin2;\n\t\tsin1 = (const struct sockaddr_in *)sa1;\n\t\tsin2 = (const struct sockaddr_in *)sa2;\n\t\tif (sin1->sin_addr.s_addr < sin2->sin_addr.s_addr)\n\t\t\treturn -1;\n\t\telse if (sin1->sin_addr.s_addr > sin2->sin_addr.s_addr)\n\t\t\treturn 1;\n\t\telse if (include_port &&\n\t\t    (r = ((int)sin1->sin_port - (int)sin2->sin_port)))\n\t\t\treturn r;\n\t\telse\n\t\t\treturn 0;\n\t}\n#ifdef AF_INET6\n\telse if (sa1->sa_family == AF_INET6) {\n\t\tconst struct sockaddr_in6 *sin1, *sin2;\n\t\tsin1 = (const struct sockaddr_in6 *)sa1;\n\t\tsin2 = (const struct sockaddr_in6 *)sa2;\n\t\tif ((r = memcmp(sin1->sin6_addr.s6_addr, sin2->sin6_addr.s6_addr, 16)))\n\t\t\treturn r;\n\t\telse if (include_port &&\n\t\t    (r = ((int)sin1->sin6_port - (int)sin2->sin6_port)))\n\t\t\treturn r;\n\t\telse\n\t\t\treturn 0;\n\t}\n#endif\n\treturn 1;\n}\n\n/* Tables to implement ctypes-replacement EVUTIL_IS*() functions.  Each table\n * has 256 bits to look up whether a character is in some set or not.  This\n * fails on non-ASCII platforms, but so does every other place where we\n * take a char and write it onto the network.\n **/\nstatic const ev_uint32_t EVUTIL_ISALPHA_TABLE[8] =\n  { 0, 0, 0x7fffffe, 0x7fffffe, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISALNUM_TABLE[8] =\n  { 0, 0x3ff0000, 0x7fffffe, 0x7fffffe, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISSPACE_TABLE[8] = { 0x3e00, 0x1, 0, 0, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISXDIGIT_TABLE[8] =\n  { 0, 0x3ff0000, 0x7e, 0x7e, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISDIGIT_TABLE[8] = { 0, 0x3ff0000, 0, 0, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISPRINT_TABLE[8] =\n  { 0, 0xffffffff, 0xffffffff, 0x7fffffff, 0, 0, 0, 0x0 };\nstatic const ev_uint32_t EVUTIL_ISUPPER_TABLE[8] = { 0, 0, 0x7fffffe, 0, 0, 0, 0, 0 };\nstatic const ev_uint32_t EVUTIL_ISLOWER_TABLE[8] = { 0, 0, 0, 0x7fffffe, 0, 0, 0, 0 };\n/* Upper-casing and lowercasing tables to map characters to upper/lowercase\n * equivalents. */\nstatic const unsigned char EVUTIL_TOUPPER_TABLE[256] = {\n  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n  16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n  32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,\n  48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,\n  64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,\n  80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,\n  96,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,\n  80,81,82,83,84,85,86,87,88,89,90,123,124,125,126,127,\n  128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,\n  144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,\n  160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,\n  176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,\n  192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,\n  208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,\n  224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,\n  240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,\n};\nstatic const unsigned char EVUTIL_TOLOWER_TABLE[256] = {\n  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n  16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n  32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,\n  48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,\n  64,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,\n  112,113,114,115,116,117,118,119,120,121,122,91,92,93,94,95,\n  96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,\n  112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,\n  128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,\n  144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,\n  160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,\n  176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,\n  192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,\n  208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,\n  224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,\n  240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,\n};\n\n#define IMPL_CTYPE_FN(name)\t\t\t\t\t\t\\\n\tint EVUTIL_##name##_(char c) {\t\t\t\t\t\\\n\t\tev_uint8_t u = c;\t\t\t\t\t\\\n\t\treturn !!(EVUTIL_##name##_TABLE[(u >> 5) & 7] & (1U << (u & 31))); \\\n\t}\nIMPL_CTYPE_FN(ISALPHA)\nIMPL_CTYPE_FN(ISALNUM)\nIMPL_CTYPE_FN(ISSPACE)\nIMPL_CTYPE_FN(ISDIGIT)\nIMPL_CTYPE_FN(ISXDIGIT)\nIMPL_CTYPE_FN(ISPRINT)\nIMPL_CTYPE_FN(ISLOWER)\nIMPL_CTYPE_FN(ISUPPER)\n\nchar EVUTIL_TOLOWER_(char c)\n{\n\treturn ((char)EVUTIL_TOLOWER_TABLE[(ev_uint8_t)c]);\n}\nchar EVUTIL_TOUPPER_(char c)\n{\n\treturn ((char)EVUTIL_TOUPPER_TABLE[(ev_uint8_t)c]);\n}\nint\nevutil_ascii_strcasecmp(const char *s1, const char *s2)\n{\n\tchar c1, c2;\n\twhile (1) {\n\t\tc1 = EVUTIL_TOLOWER_(*s1++);\n\t\tc2 = EVUTIL_TOLOWER_(*s2++);\n\t\tif (c1 < c2)\n\t\t\treturn -1;\n\t\telse if (c1 > c2)\n\t\t\treturn 1;\n\t\telse if (c1 == 0)\n\t\t\treturn 0;\n\t}\n}\nint evutil_ascii_strncasecmp(const char *s1, const char *s2, size_t n)\n{\n\tchar c1, c2;\n\twhile (n--) {\n\t\tc1 = EVUTIL_TOLOWER_(*s1++);\n\t\tc2 = EVUTIL_TOLOWER_(*s2++);\n\t\tif (c1 < c2)\n\t\t\treturn -1;\n\t\telse if (c1 > c2)\n\t\t\treturn 1;\n\t\telse if (c1 == 0)\n\t\t\treturn 0;\n\t}\n\treturn 0;\n}\n\nconst char* evutil_ascii_strcasestr(const char* s, const char *find)\n{\n\tchar c, sc;\n\tsize_t len;\n\n\tif ((c = *find++) != 0) {\n\t\tc = EVUTIL_TOLOWER_(c);\n\t\tlen = strlen(find);\n\t\tdo {\n\t\t\tdo {\n\t\t\t\tif ((sc = *s++) == 0)\n\t\t\t\t\treturn (NULL);\n\t\t\t} while ((char)EVUTIL_TOLOWER_(sc) != c);\n\t\t} while (evutil_ascii_strncasecmp(s, find, len) != 0);\n\t\ts--;\n\t}\n\treturn s;\n}\n\nvoid\nevutil_rtrim_lws_(char *str)\n{\n\tchar *cp;\n\n\tif (str == NULL)\n\t\treturn;\n\n\tif ((cp = strchr(str, '\\0')) == NULL || (cp == str))\n\t\treturn;\n\n\t--cp;\n\n\twhile (*cp == ' ' || *cp == '\\t') {\n\t\t*cp = '\\0';\n\t\tif (cp == str)\n\t\t\tbreak;\n\t\t--cp;\n\t}\n}\n\nstatic int\nevutil_issetugid(void)\n{\n#ifdef EVENT__HAVE_ISSETUGID\n\treturn issetugid();\n#else\n\n#ifdef EVENT__HAVE_GETEUID\n\tif (getuid() != geteuid())\n\t\treturn 1;\n#endif\n#ifdef EVENT__HAVE_GETEGID\n\tif (getgid() != getegid())\n\t\treturn 1;\n#endif\n\treturn 0;\n#endif\n}\n\nconst char *\nevutil_getenv_(const char *varname)\n{\n\tif (evutil_issetugid())\n\t\treturn NULL;\n\n\treturn getenv(varname);\n}\n\nev_uint32_t\nevutil_weakrand_seed_(struct evutil_weakrand_state *state, ev_uint32_t seed)\n{\n\tif (seed == 0) {\n\t\tstruct timeval tv;\n\t\tevutil_gettimeofday(&tv, NULL);\n\t\tseed = (ev_uint32_t)tv.tv_sec + (ev_uint32_t)tv.tv_usec;\n#ifdef _WIN32\n\t\tseed += (ev_uint32_t) _getpid();\n#else\n\t\tseed += (ev_uint32_t) getpid();\n#endif\n\t}\n\tstate->seed = seed;\n\treturn seed;\n}\n\nev_int32_t\nevutil_weakrand_(struct evutil_weakrand_state *state)\n{\n\t/* This RNG implementation is a linear congruential generator, with\n\t * modulus 2^31, multiplier 1103515245, and addend 12345.  It's also\n\t * used by OpenBSD, and by Glibc's TYPE_0 RNG.\n\t *\n\t * The linear congruential generator is not an industrial-strength\n\t * RNG!  It's fast, but it can have higher-order patterns.  Notably,\n\t * the low bits tend to have periodicity.\n\t */\n\tstate->seed = ((state->seed) * 1103515245 + 12345) & 0x7fffffff;\n\treturn (ev_int32_t)(state->seed);\n}\n\nev_int32_t\nevutil_weakrand_range_(struct evutil_weakrand_state *state, ev_int32_t top)\n{\n\tev_int32_t divisor, result;\n\n\t/* We can't just do weakrand() % top, since the low bits of the LCG\n\t * are less random than the high ones.  (Specifically, since the LCG\n\t * modulus is 2^N, every 2^m for m<N will divide the modulus, and so\n\t * therefore the low m bits of the LCG will have period 2^m.) */\n\tdivisor = EVUTIL_WEAKRAND_MAX / top;\n\tdo {\n\t\tresult = evutil_weakrand_(state) / divisor;\n\t} while (result >= top);\n\treturn result;\n}\n\n/**\n * Volatile pointer to memset: we use this to keep the compiler from\n * eliminating our call to memset.\n */\nvoid * (*volatile evutil_memset_volatile_)(void *, int, size_t) = memset;\n\nvoid\nevutil_memclear_(void *mem, size_t len)\n{\n\tevutil_memset_volatile_(mem, 0, len);\n}\n\nint\nevutil_sockaddr_is_loopback_(const struct sockaddr *addr)\n{\n\tstatic const char LOOPBACK_S6[16] =\n\t    \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\1\";\n\tif (addr->sa_family == AF_INET) {\n\t\tstruct sockaddr_in *sin = (struct sockaddr_in *)addr;\n\t\treturn (ntohl(sin->sin_addr.s_addr) & 0xff000000) == 0x7f000000;\n\t} else if (addr->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)addr;\n\t\treturn !memcmp(sin6->sin6_addr.s6_addr, LOOPBACK_S6, 16);\n\t}\n\treturn 0;\n}\n\nint\nevutil_hex_char_to_int_(char c)\n{\n\tswitch(c)\n\t{\n\t\tcase '0': return 0;\n\t\tcase '1': return 1;\n\t\tcase '2': return 2;\n\t\tcase '3': return 3;\n\t\tcase '4': return 4;\n\t\tcase '5': return 5;\n\t\tcase '6': return 6;\n\t\tcase '7': return 7;\n\t\tcase '8': return 8;\n\t\tcase '9': return 9;\n\t\tcase 'A': case 'a': return 10;\n\t\tcase 'B': case 'b': return 11;\n\t\tcase 'C': case 'c': return 12;\n\t\tcase 'D': case 'd': return 13;\n\t\tcase 'E': case 'e': return 14;\n\t\tcase 'F': case 'f': return 15;\n\t}\n\treturn -1;\n}\n\n#ifdef _WIN32\nHMODULE\nevutil_load_windows_system_library_(const TCHAR *library_name)\n{\n  TCHAR path[MAX_PATH];\n  unsigned n;\n  n = GetSystemDirectory(path, MAX_PATH);\n  if (n == 0 || n + _tcslen(library_name) + 2 >= MAX_PATH)\n    return 0;\n  _tcscat(path, TEXT(\"\\\\\"));\n  _tcscat(path, library_name);\n  return LoadLibrary(path);\n}\n#endif\n\n/* Internal wrapper around 'socket' to provide Linux-style support for\n * syscall-saving methods where available.\n *\n * In addition to regular socket behavior, you can use a bitwise or to set the\n * flags EVUTIL_SOCK_NONBLOCK and EVUTIL_SOCK_CLOEXEC in the 'type' argument,\n * to make the socket nonblocking or close-on-exec with as few syscalls as\n * possible.\n */\nevutil_socket_t\nevutil_socket_(int domain, int type, int protocol)\n{\n\tevutil_socket_t r;\n#if defined(SOCK_NONBLOCK) && defined(SOCK_CLOEXEC)\n\tr = socket(domain, type, protocol);\n\tif (r >= 0)\n\t\treturn r;\n\telse if ((type & (SOCK_NONBLOCK|SOCK_CLOEXEC)) == 0)\n\t\treturn -1;\n#endif\n#define SOCKET_TYPE_MASK (~(EVUTIL_SOCK_NONBLOCK|EVUTIL_SOCK_CLOEXEC))\n\tr = socket(domain, type & SOCKET_TYPE_MASK, protocol);\n\tif (r < 0)\n\t\treturn -1;\n\tif (type & EVUTIL_SOCK_NONBLOCK) {\n\t\tif (evutil_fast_socket_nonblocking(r) < 0) {\n\t\t\tevutil_closesocket(r);\n\t\t\treturn -1;\n\t\t}\n\t}\n\tif (type & EVUTIL_SOCK_CLOEXEC) {\n\t\tif (evutil_fast_socket_closeonexec(r) < 0) {\n\t\t\tevutil_closesocket(r);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn r;\n}\n\nint\nevutil_socketpair(int family, int type, int protocol, evutil_socket_t fd[2])\n{\n\tint ret = 0;\n\tint sock_type = type;\n\t(void) sock_type;\n\t/* SOCK_NONBLOCK and SOCK_CLOEXEC are UNIX-specific. Therefore, the predefined and\n\t * platform-independent macros EVUTIL_SOCK_NONBLOCK and EVUTIL_SOCK_CLOEXEC are used\n\t * in type argument as combination while SOCK_NONBLOCK and SOCK_CLOEXEC are used for\n\t * distinguishing platforms.\n\t */\n#ifndef SOCK_NONBLOCK\n\ttype &= ~EVUTIL_SOCK_NONBLOCK;\n#endif\n#ifndef SOCK_CLOEXEC\n\ttype &= ~EVUTIL_SOCK_CLOEXEC;\n#endif\n#if defined(_WIN32)\n\tret = evutil_win_socketpair(family, type, protocol, fd);\n#elif defined(EVENT__HAVE_SOCKETPAIR)\n\tret = socketpair(family, type, protocol, fd);\n#else\n\tret = evutil_ersatz_socketpair_(family, type, protocol, fd);\n#endif\n\tif (ret)\n\t\treturn ret;\n#ifndef SOCK_NONBLOCK\n\tif (sock_type & EVUTIL_SOCK_NONBLOCK) {\n\t\tif ((ret = evutil_fast_socket_nonblocking(fd[0]))) {\n\t\t\tevutil_closesocket(fd[0]);\n\t\t\tevutil_closesocket(fd[1]);\n\t\t\treturn ret;\n\t\t}\n\t\tif ((ret = evutil_fast_socket_nonblocking(fd[1]))) {\n\t\t\tevutil_closesocket(fd[0]);\n\t\t\tevutil_closesocket(fd[1]);\n\t\t\treturn ret;\n\t\t}\n\t}\n#endif\n#ifndef SOCK_CLOEXEC\n\tif (sock_type & EVUTIL_SOCK_CLOEXEC) {\n\t\tif ((ret = evutil_fast_socket_closeonexec(fd[0]))) {\n\t\t\tevutil_closesocket(fd[0]);\n\t\t\tevutil_closesocket(fd[1]);\n\t\t\treturn ret;\n\t\t}\n\t\tif ((ret = evutil_fast_socket_closeonexec(fd[1]))) {\n\t\t\tevutil_closesocket(fd[0]);\n\t\t\tevutil_closesocket(fd[1]);\n\t\t\treturn ret;\n\t\t}\n\t}\n#endif\n\treturn ret;\n}\n\nint\nevutil_ersatz_socketpair_(int family, int type, int protocol,\n    evutil_socket_t fd[2])\n{\n\t/* This code is originally from Tor.  Used with permission. */\n\n\t/* This socketpair does not work when localhost is down. So\n\t * it's really not the same thing at all. But it's close enough\n\t * for now, and really, when localhost is down sometimes, we\n\t * have other problems too.\n\t */\n#undef ERR\n#ifdef _WIN32\n#define ERR(e) WSA##e\n#else\n#define ERR(e) e\n#endif\n\tevutil_socket_t listener = -1;\n\tevutil_socket_t connector = -1;\n\tevutil_socket_t acceptor = -1;\n\tstruct sockaddr_in listen_addr;\n\tstruct sockaddr_in connect_addr;\n\tev_socklen_t size;\n\tint saved_errno = -1;\n\tint family_test;\n\n\tfamily_test = family != AF_INET;\n#ifdef AF_UNIX\n\tfamily_test = family_test && (family != AF_UNIX);\n#endif\n\tif (protocol || family_test) {\n\t\tEVUTIL_SET_SOCKET_ERROR(ERR(EAFNOSUPPORT));\n\t\treturn -1;\n\t}\n\n\tif (!fd) {\n\t\tEVUTIL_SET_SOCKET_ERROR(ERR(EINVAL));\n\t\treturn -1;\n\t}\n\n\tlistener = socket(AF_INET, type, 0);\n\tif (listener < 0)\n\t\treturn -1;\n\tmemset(&listen_addr, 0, sizeof(listen_addr));\n\tlisten_addr.sin_family = AF_INET;\n\tlisten_addr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);\n\tlisten_addr.sin_port = 0;\t/* kernel chooses port.\t */\n\tif (bind(listener, (struct sockaddr *) &listen_addr, sizeof (listen_addr))\n\t\t== -1)\n\t\tgoto tidy_up_and_fail;\n\tif (listen(listener, 1) == -1)\n\t\tgoto tidy_up_and_fail;\n\n\tconnector = socket(AF_INET, type, 0);\n\tif (connector < 0)\n\t\tgoto tidy_up_and_fail;\n\n\tmemset(&connect_addr, 0, sizeof(connect_addr));\n\n\t/* We want to find out the port number to connect to.  */\n\tsize = sizeof(connect_addr);\n\tif (getsockname(listener, (struct sockaddr *) &connect_addr, &size) == -1)\n\t\tgoto tidy_up_and_fail;\n\tif (size != sizeof(connect_addr))\n\t\tgoto abort_tidy_up_and_fail;\n\tif (connect(connector, (struct sockaddr *) &connect_addr,\n\t\t\t\tsizeof(connect_addr)) == -1) {\n\t\t/* It's OK for a non-blocking socket to get an EINPROGRESS from connect(). */\n\t\tint err = evutil_socket_geterror(connector);\n\t\tif (!(EVUTIL_ERR_CONNECT_RETRIABLE(err) && type & EVUTIL_SOCK_NONBLOCK))\n\t\t\tgoto tidy_up_and_fail;\n\t}\n\n\tsize = sizeof(listen_addr);\n\tdo {\n\t\tacceptor = accept(listener, (struct sockaddr *) &listen_addr, &size);\n\t} while(acceptor < 0 && EVUTIL_ERR_ACCEPT_RETRIABLE(errno) && type & EVUTIL_SOCK_NONBLOCK);\n\tif (acceptor < 0)\n\t\tgoto tidy_up_and_fail;\n\tif (size != sizeof(listen_addr))\n\t\tgoto abort_tidy_up_and_fail;\n\t/* Now check we are talking to ourself by matching port and host on the\n\t   two sockets.\t */\n\tif (getsockname(connector, (struct sockaddr *) &connect_addr, &size) == -1)\n\t\tgoto tidy_up_and_fail;\n\tif (size != sizeof (connect_addr)\n\t\t|| listen_addr.sin_family != connect_addr.sin_family\n\t\t|| listen_addr.sin_addr.s_addr != connect_addr.sin_addr.s_addr\n\t\t|| listen_addr.sin_port != connect_addr.sin_port)\n\t\tgoto abort_tidy_up_and_fail;\n\tevutil_closesocket(listener);\n\tfd[0] = connector;\n\tfd[1] = acceptor;\n\n\treturn 0;\n\n abort_tidy_up_and_fail:\n\tsaved_errno = ERR(ECONNABORTED);\n tidy_up_and_fail:\n\tif (saved_errno < 0)\n\t\tsaved_errno = EVUTIL_SOCKET_ERROR();\n\tif (listener != -1)\n\t\tevutil_closesocket(listener);\n\tif (connector != -1)\n\t\tevutil_closesocket(connector);\n\tif (acceptor != -1)\n\t\tevutil_closesocket(acceptor);\n\n\tEVUTIL_SET_SOCKET_ERROR(saved_errno);\n\treturn -1;\n#undef ERR\n}\n\n/* Internal wrapper around 'accept' or 'accept4' to provide Linux-style\n * support for syscall-saving methods where available.\n *\n * In addition to regular accept behavior, you can set one or more of flags\n * EVUTIL_SOCK_NONBLOCK and EVUTIL_SOCK_CLOEXEC in the 'flags' argument, to\n * make the socket nonblocking or close-on-exec with as few syscalls as\n * possible.\n */\nevutil_socket_t\nevutil_accept4_(evutil_socket_t sockfd, struct sockaddr *addr,\n    ev_socklen_t *addrlen, int flags)\n{\n\tevutil_socket_t result;\n#if defined(EVENT__HAVE_ACCEPT4) && defined(SOCK_CLOEXEC) && defined(SOCK_NONBLOCK)\n\tresult = accept4(sockfd, addr, addrlen, flags);\n\tif (result >= 0 || (errno != EINVAL && errno != ENOSYS)) {\n\t\t/* A nonnegative result means that we succeeded, so return.\n\t\t * Failing with EINVAL means that an option wasn't supported,\n\t\t * and failing with ENOSYS means that the syscall wasn't\n\t\t * there: in those cases we want to fall back.  Otherwise, we\n\t\t * got a real error, and we should return. */\n\t\treturn result;\n\t}\n#endif\n\tresult = accept(sockfd, addr, addrlen);\n\tif (result < 0)\n\t\treturn result;\n\n\tif (flags & EVUTIL_SOCK_CLOEXEC) {\n\t\tif (evutil_fast_socket_closeonexec(result) < 0) {\n\t\t\tevutil_closesocket(result);\n\t\t\treturn -1;\n\t\t}\n\t}\n\tif (flags & EVUTIL_SOCK_NONBLOCK) {\n\t\tif (evutil_fast_socket_nonblocking(result) < 0) {\n\t\t\tevutil_closesocket(result);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn result;\n}\n\n/* Internal function: Set fd[0] and fd[1] to a pair of fds such that writes on\n * fd[1] get read from fd[0].  Make both fds nonblocking and close-on-exec.\n * Return 0 on success, -1 on failure.\n */\nint\nevutil_make_internal_pipe_(evutil_socket_t fd[2])\n{\n\t/*\n\t  Making the second socket nonblocking is a bit subtle, given that we\n\t  ignore any EAGAIN returns when writing to it, and you don't usually\n\t  do that for a nonblocking socket. But if the kernel gives us EAGAIN,\n\t  then there's no need to add any more data to the buffer, since\n\t  the main thread is already either about to wake up and drain it,\n\t  or woken up and in the process of draining it.\n\t*/\n\n#if defined(EVENT__HAVE_PIPE2)\n\tif (pipe2(fd, O_NONBLOCK|O_CLOEXEC) == 0)\n\t\treturn 0;\n#endif\n#if defined(EVENT__HAVE_PIPE)\n\tif (pipe(fd) == 0) {\n\t\tif (evutil_fast_socket_nonblocking(fd[0]) < 0 ||\n\t\t    evutil_fast_socket_nonblocking(fd[1]) < 0 ||\n\t\t    evutil_fast_socket_closeonexec(fd[0]) < 0 ||\n\t\t    evutil_fast_socket_closeonexec(fd[1]) < 0) {\n\t\t\tclose(fd[0]);\n\t\t\tclose(fd[1]);\n\t\t\tfd[0] = fd[1] = -1;\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t} else {\n\t\tevent_warn(\"%s: pipe\", __func__);\n\t}\n#endif\n\n#if defined(_WIN32) && !defined(EVENT__HAVE_AFUNIX_H)\n#define LOCAL_SOCKETPAIR_AF AF_INET\n#else\n#define LOCAL_SOCKETPAIR_AF AF_UNIX\n#endif\n\tif (evutil_socketpair(LOCAL_SOCKETPAIR_AF, SOCK_STREAM|EVUTIL_SOCK_CLOEXEC|EVUTIL_SOCK_NONBLOCK, 0, fd)) {\n\t\tfd[0] = fd[1] = -1;\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/* Wrapper around eventfd on systems that provide it.  Unlike the system\n * eventfd, it always supports EVUTIL_EFD_CLOEXEC and EVUTIL_EFD_NONBLOCK as\n * flags.  Returns -1 on error or if eventfd is not supported.\n */\nevutil_socket_t\nevutil_eventfd_(unsigned initval, int flags)\n{\n#if defined(EVENT__HAVE_EVENTFD) && defined(EVENT__HAVE_SYS_EVENTFD_H)\n\tint r;\n#if defined(EFD_CLOEXEC) && defined(EFD_NONBLOCK)\n\tr = eventfd(initval, flags);\n\tif (r >= 0 || flags == 0)\n\t\treturn r;\n#endif\n\tr = eventfd(initval, 0);\n\tif (r < 0)\n\t\treturn r;\n\tif (flags & EVUTIL_EFD_CLOEXEC) {\n\t\tif (evutil_fast_socket_closeonexec(r) < 0) {\n\t\t\tevutil_closesocket(r);\n\t\t\treturn -1;\n\t\t}\n\t}\n\tif (flags & EVUTIL_EFD_NONBLOCK) {\n\t\tif (evutil_fast_socket_nonblocking(r) < 0) {\n\t\t\tevutil_closesocket(r);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn r;\n#else\n\treturn -1;\n#endif\n}\n\nvoid\nevutil_free_globals_(void)\n{\n\tevutil_free_secure_rng_globals_();\n\tevutil_free_sock_err_globals();\n}\n\n#if (defined(EVENT__SOLARIS_11_4) && !EVENT__SOLARIS_11_4) || \\\n    (defined(__DragonFly__) && __DragonFly_version < 500702) || \\\n    (defined(_WIN32) && !defined(TCP_KEEPIDLE))\n/* DragonFlyBSD <500702, Solaris <11.4, and Windows <10.0.16299\n * require millisecond units for TCP keepalive options. */\n#define EVENT_KEEPALIVE_FACTOR(x) (x *= 1000)\n#else\n#define EVENT_KEEPALIVE_FACTOR(x)\n#endif\nint\nevutil_set_tcp_keepalive(evutil_socket_t fd, int on, int timeout)\n{\n\tint idle;\n\tint intvl;\n\tint cnt;\n\n\t/* Prevent compiler from complaining unused variables warnings. */\n\t(void) idle;\n\t(void) intvl;\n\t(void) cnt;\n\n\tif (timeout <= 0)\n\t\treturn 0;\n\n#ifdef _WIN32\n\tif (setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, (const char*)&on, sizeof(on)))\n#else\n\tif (setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &on, sizeof(on)))\n#endif\n\t\treturn -1;\n\tif (!on)\n\t\treturn 0;\n\n#ifdef _WIN32\n\tidle = timeout;\n\tintvl = idle/3;\n\tif (intvl == 0)\n\t\tintvl = 1;\n\n\tEVENT_KEEPALIVE_FACTOR(idle);\n\tEVENT_KEEPALIVE_FACTOR(intvl);\n\n\t/* The three options TCP_KEEPIDLE, TCP_KEEPINTVL and TCP_KEEPCNT are not available until\n\t * Windows 10 version 1709, but let's gamble here.\n\t */\n#if defined(TCP_KEEPIDLE) && defined(TCP_KEEPINTVL) && defined(TCP_KEEPCNT)\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, (const char*)&idle, sizeof(idle)))\n\t\treturn -1;\n\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, (const char*)&intvl, sizeof(intvl)))\n\t\treturn -1;\n\n\tcnt = 3;\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, (const char*)&cnt, sizeof(cnt)))\n\t\treturn -1;\n\n\t/* For those versions prior to Windows 10 version 1709, we fall back to SIO_KEEPALIVE_VALS.\n\t * The SIO_KEEPALIVE_VALS IOCTL is supported on Windows 2000 and later versions of the operating system. */\n#elif defined(SIO_KEEPALIVE_VALS)\n\tstruct tcp_keepalive keepalive;\n\tkeepalive.onoff = on;\n\tkeepalive.keepalivetime = idle;\n\tkeepalive.keepaliveinterval = intvl;\n\t/* On Windows Vista and later, the number of keep-alive probes (data retransmissions)\n\t * is set to 10 and cannot be changed.\n\t * On Windows Server 2003, Windows XP, and Windows 2000, the default setting for\n\t * number of keep-alive probes is 5 and cannot be changed programmatically.\n\t */\n\tDWORD dummy;\n\tif (WSAIoctl(fd, SIO_KEEPALIVE_VALS, (LPVOID) &keepalive, sizeof(keepalive), NULL, 0, &dummy, NULL, NULL))\n\t\treturn -1;\n#endif\n\n#else /* !_WIN32 */\n\n#ifdef __sun\n\t/* The implementation of TCP keep-alive on Solaris/SmartOS is a bit unusual\n\t * compared to other Unix-like systems.\n\t * Thus, we need to specialize it on Solaris.\n\t *\n\t * There are two keep-alive mechanisms on Solaris:\n\t * - By default, the first keep-alive probe is sent out after a TCP connection is idle for two hours.\n\t * If the peer does not respond to the probe within eight minutes, the TCP connection is aborted.\n\t * You can alter the interval for sending out the first probe using the socket option TCP_KEEPALIVE_THRESHOLD\n\t * in milliseconds or TCP_KEEPIDLE in seconds.\n\t * The system default is controlled by the TCP ndd parameter tcp_keepalive_interval. The minimum value is ten seconds.\n\t * The maximum is ten days, while the default is two hours. If you receive no response to the probe,\n\t * you can use the TCP_KEEPALIVE_ABORT_THRESHOLD socket option to change the time threshold for aborting a TCP connection.\n\t * The option value is an unsigned integer in milliseconds. The value zero indicates that TCP should never time out and\n\t * abort the connection when probing. The system default is controlled by the TCP ndd parameter tcp_keepalive_abort_interval.\n\t * The default is eight minutes.\n\t *\n\t * - The second implementation is activated if socket option TCP_KEEPINTVL and/or TCP_KEEPCNT are set.\n\t * The time between each consequent probes is set by TCP_KEEPINTVL in seconds.\n\t * The minimum value is ten seconds. The maximum is ten days, while the default is two hours.\n\t * The TCP connection will be aborted after certain amount of probes, which is set by TCP_KEEPCNT, without receiving response.\n\t */\n\n\tidle = timeout;\n\t/* Kernel expects at least 10 seconds. */\n\tif (idle < 10)\n\t\tidle = 10;\n\t/* Kernel expects at most 10 days. */\n\tif (idle > 10*24*60*60)\n\t\tidle = 10*24*60*60;\n\n\tEVENT_KEEPALIVE_FACTOR(idle);\n\n\t/* `TCP_KEEPIDLE`, `TCP_KEEPINTVL`, and `TCP_KEEPCNT` were not available on Solaris\n\t * until version 11.4, but let's gamble here.\n\t */\n#if defined(TCP_KEEPIDLE) && defined(TCP_KEEPINTVL) && defined(TCP_KEEPCNT)\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &idle, sizeof(idle)))\n\t\treturn -1;\n\n\tintvl = idle/3;\n\t/* Kernel expects at least 10 seconds. */\n\tif (intvl < 10)\n\t\tintvl = 10;\n\tEVENT_KEEPALIVE_FACTOR(intvl);\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &intvl, sizeof(intvl)))\n\t\treturn -1;\n\n\tcnt = 3;\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &cnt, sizeof(cnt)))\n\t\treturn -1;\n#else\n\t/* Fall back to the first implementation of tcp-alive mechanism for older Solaris,\n\t * simulate the tcp-alive mechanism on other platforms via `TCP_KEEPALIVE_THRESHOLD` + `TCP_KEEPALIVE_ABORT_THRESHOLD`.\n\t */\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPALIVE_THRESHOLD, &idle, sizeof(idle)))\n\t\treturn -1;\n\n\t/* Note that the consequent probes will not be sent at equal intervals on Solaris,\n\t * but will be sent using the exponential backoff algorithm.\n\t */\n\tint time_to_abort = idle;\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPALIVE_ABORT_THRESHOLD, &time_to_abort, sizeof(time_to_abort)))\n\t\treturn -1;\n#endif\n\n#else /* !__sun */\n\n\tidle = timeout;\n\tEVENT_KEEPALIVE_FACTOR(idle);\n#ifdef TCP_KEEPIDLE\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &idle, sizeof(idle)))\n\t\treturn -1;\n#elif defined(TCP_KEEPALIVE)\n\t/* Darwin/macOS uses TCP_KEEPALIVE in place of TCP_KEEPIDLE. */\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPALIVE, &idle, sizeof(idle)))\n\t\treturn -1;\n#endif\n\n#ifdef TCP_KEEPINTVL\n\t/* Set the interval between individual keep-alive probes as timeout / 3\n\t * and the maximum number of keepalive probes as 3 to make it double timeout\n\t * before aborting a dead connection.\n\t */\n\tintvl = timeout/3;\n\tif (intvl == 0)\n\t\tintvl = 1;\n\tEVENT_KEEPALIVE_FACTOR(intvl);\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &intvl, sizeof(intvl)))\n\t\treturn -1;\n#endif\n\n#ifdef TCP_KEEPCNT\n\t/* Set the maximum number of keepalive probes as 3 to collaborate with\n\t * TCP_KEEPINTVL, see the previous comment.\n\t */\n\tcnt = 3;\n\tif (setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &cnt, sizeof(cnt)))\n\t\treturn -1;\n#endif\n\n#endif /* !__sun */\n\n#endif /* !_WIN32 */\n\n\treturn 0;\n}\n\nconst char * evutil_strsignal(int sig)\n{\n#if !defined(EVENT__HAVE_STRSIGNAL)\n\tstatic char buf[10];\n\tevutil_snprintf(buf, 10, \"%d\", sig);\n\treturn buf;\n#else\n\treturn strsignal(sig);\n#endif\n}\n"
        },
        {
          "name": "evutil_rand.c",
          "type": "blob",
          "size": 5.23828125,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* This file has our secure PRNG code.  On platforms that have arc4random(),\n * we just use that.  Otherwise, we include arc4random.c as a bunch of static\n * functions, and wrap it lightly.  We don't expose the arc4random*() APIs\n * because A) they aren't in our namespace, and B) it's not nice to name your\n * APIs after their implementations.  We keep them in a separate file\n * so that other people can rip it out and use it for whatever.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <limits.h>\n\n#include \"util-internal.h\"\n#include \"evthread-internal.h\"\n\n#ifdef EVENT__HAVE_ARC4RANDOM\n#include <stdlib.h>\n#include <string.h>\nint\nevutil_secure_rng_set_urandom_device_file(char *fname)\n{\n\t(void) fname;\n\treturn -1;\n}\nint\nevutil_secure_rng_init(void)\n{\n\t/* call arc4random() now to force it to self-initialize */\n\t(void)! arc4random();\n\treturn 0;\n}\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevutil_secure_rng_global_setup_locks_(const int enable_locks)\n{\n\treturn 0;\n}\n#endif\nstatic void\nevutil_free_secure_rng_globals_locks(void)\n{\n}\n\nstatic void\nev_arc4random_buf(void *buf, size_t n)\n{\n#if defined(EVENT__HAVE_ARC4RANDOM_BUF) && !defined(__APPLE__)\n\tarc4random_buf(buf, n);\n\treturn;\n#else\n\tunsigned char *b = buf;\n\n#if defined(EVENT__HAVE_ARC4RANDOM_BUF)\n\t/* OSX 10.7 introduced arc4random_buf, so if you build your program\n\t * there, you'll get surprised when older versions of OSX fail to run.\n\t * To solve this, we can check whether the function pointer is set,\n\t * and fall back otherwise.  (OSX does this using some linker\n\t * trickery.)\n\t */\n\t{\n\t\tvoid (*tptr)(void *,size_t) =\n\t\t    (void (*)(void*,size_t))arc4random_buf;\n\t\tif (tptr != NULL) {\n\t\t\tarc4random_buf(buf, n);\n\t\t\treturn;\n\t\t}\n\t}\n#endif\n\t/* Make sure that we start out with b at a 4-byte alignment; plenty\n\t * of CPUs care about this for 32-bit access. */\n\tif (n >= 4 && ((ev_uintptr_t)b) & 3) {\n\t\tev_uint32_t u = arc4random();\n\t\tint n_bytes = 4 - (((ev_uintptr_t)b) & 3);\n\t\tmemcpy(b, &u, n_bytes);\n\t\tb += n_bytes;\n\t\tn -= n_bytes;\n\t}\n\twhile (n >= 4) {\n\t\t*(ev_uint32_t*)b = arc4random();\n\t\tb += 4;\n\t\tn -= 4;\n\t}\n\tif (n) {\n\t\tev_uint32_t u = arc4random();\n\t\tmemcpy(b, &u, n);\n\t}\n#endif\n}\n\n#else /* !EVENT__HAVE_ARC4RANDOM { */\n\n#ifdef EVENT__ssize_t\n#define ssize_t EVENT__ssize_t\n#endif\n#define ARC4RANDOM_EXPORT static\n#define ARC4_LOCK_() EVLOCK_LOCK(arc4rand_lock, 0)\n#define ARC4_UNLOCK_() EVLOCK_UNLOCK(arc4rand_lock, 0)\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nstatic void *arc4rand_lock;\n#endif\n\n#define ARC4RANDOM_UINT32 ev_uint32_t\n#define ARC4RANDOM_NOSTIR\n#define ARC4RANDOM_NORANDOM\n#define ARC4RANDOM_NOUNIFORM\n\n#include \"./arc4random.c\"\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevutil_secure_rng_global_setup_locks_(const int enable_locks)\n{\n\tEVTHREAD_SETUP_GLOBAL_LOCK(arc4rand_lock, 0);\n\treturn 0;\n}\n#endif\n\nstatic void\nevutil_free_secure_rng_globals_locks(void)\n{\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (arc4rand_lock != NULL) {\n\t\tEVTHREAD_FREE_LOCK(arc4rand_lock, 0);\n\t\tarc4rand_lock = NULL;\n\t}\n#endif\n\treturn;\n}\n\nint\nevutil_secure_rng_set_urandom_device_file(char *fname)\n{\n#ifdef TRY_SEED_URANDOM\n\tARC4_LOCK_();\n\tarc4random_urandom_filename = fname;\n\tARC4_UNLOCK_();\n#endif\n\treturn 0;\n}\n\nint\nevutil_secure_rng_init(void)\n{\n\tint val;\n\n\tARC4_LOCK_();\n\tval = (!arc4_stir()) ? 0 : -1;\n\tARC4_UNLOCK_();\n\treturn val;\n}\n\nstatic void\nev_arc4random_buf(void *buf, size_t n)\n{\n\tarc4random_buf(buf, n);\n}\n\n#endif /* } !EVENT__HAVE_ARC4RANDOM */\n\nvoid\nevutil_secure_rng_get_bytes(void *buf, size_t n)\n{\n\tev_arc4random_buf(buf, n);\n}\n\nvoid\nevutil_secure_rng_add_bytes(const char *buf, size_t n)\n{\n#if !defined(EVENT__HAVE_ARC4RANDOM)\n\tarc4random_addrandom((unsigned char*)buf,\n\t    n>(size_t)INT_MAX ? INT_MAX : (int)n);\n#elif defined(EVENT__HAVE_ARC4RANDOM_STIR)\n    arc4random_stir();\n#endif\n}\n\nvoid\nevutil_free_secure_rng_globals_(void)\n{\n    evutil_free_secure_rng_globals_locks();\n}\n"
        },
        {
          "name": "evutil_time.c",
          "type": "blob",
          "size": 17.8896484375,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#define WIN32_LEAN_AND_MEAN\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n\n#include <sys/types.h>\n#ifdef EVENT__HAVE_STDLIB_H\n#include <stdlib.h>\n#endif\n#include <errno.h>\n#include <limits.h>\n#ifndef EVENT__HAVE_GETTIMEOFDAY\n#include <sys/timeb.h>\n#endif\n#if !defined(EVENT__HAVE_NANOSLEEP) && !defined(EVENT__HAVE_USLEEP) && \\\n\t!defined(_WIN32)\n#include <sys/select.h>\n#endif\n#include <time.h>\n#include <sys/stat.h>\n#include <string.h>\n\n/** evutil_usleep_() */\n#if defined(_WIN32)\n#elif defined(EVENT__HAVE_NANOSLEEP)\n#elif defined(EVENT__HAVE_USLEEP)\n#include <unistd.h>\n#endif\n\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"log-internal.h\"\n#include \"mm-internal.h\"\n\n#ifndef EVENT__HAVE_GETTIMEOFDAY\n/* No gettimeofday; this must be windows. */\n\ntypedef void (WINAPI *GetSystemTimePreciseAsFileTime_fn_t) (LPFILETIME);\n\nint\nevutil_gettimeofday(struct timeval *tv, struct timezone *tz)\n{\n\tstatic GetSystemTimePreciseAsFileTime_fn_t GetSystemTimePreciseAsFileTime_fn = NULL;\n\tstatic int check_precise = 1;\n\n#ifdef _MSC_VER\n#define U64_LITERAL(n) n##ui64\n#else\n#define U64_LITERAL(n) n##llu\n#endif\n\n\t/* Conversion logic taken from Tor, which in turn took it\n\t * from Perl.  GetSystemTimeAsFileTime returns its value as\n\t * an unaligned (!) 64-bit value containing the number of\n\t * 100-nanosecond intervals since 1 January 1601 UTC. */\n#define EPOCH_BIAS U64_LITERAL(116444736000000000)\n#define UNITS_PER_SEC U64_LITERAL(10000000)\n#define USEC_PER_SEC U64_LITERAL(1000000)\n#define UNITS_PER_USEC U64_LITERAL(10)\n\tunion {\n\t\tFILETIME ft_ft;\n\t\tev_uint64_t ft_64;\n\t} ft;\n\n\tif (tv == NULL)\n\t\treturn -1;\n\n\tif (EVUTIL_UNLIKELY(check_precise)) {\n\t\tHMODULE h = evutil_load_windows_system_library_(TEXT(\"kernel32.dll\"));\n\t\tif (h != NULL)\n\t\t\tGetSystemTimePreciseAsFileTime_fn =\n\t\t\t\t(GetSystemTimePreciseAsFileTime_fn_t)\n\t\t\t\t\tGetProcAddress(h, \"GetSystemTimePreciseAsFileTime\");\n\t\tcheck_precise = 0;\n\t}\n\n\tif (GetSystemTimePreciseAsFileTime_fn != NULL)\n\t\tGetSystemTimePreciseAsFileTime_fn(&ft.ft_ft);\n\telse\n\t\tGetSystemTimeAsFileTime(&ft.ft_ft);\n\n\tif (EVUTIL_UNLIKELY(ft.ft_64 < EPOCH_BIAS)) {\n\t\t/* Time before the unix epoch. */\n\t\treturn -1;\n\t}\n\tft.ft_64 -= EPOCH_BIAS;\n\ttv->tv_sec = (long) (ft.ft_64 / UNITS_PER_SEC);\n\ttv->tv_usec = (long) ((ft.ft_64 / UNITS_PER_USEC) % USEC_PER_SEC);\n\treturn 0;\n}\n#endif\n\n#define MAX_SECONDS_IN_MSEC_LONG \\\n\t(((LONG_MAX) - 999) / 1000)\n\nlong\nevutil_tv_to_msec_(const struct timeval *tv)\n{\n\tif (tv->tv_usec > 1000000 || tv->tv_sec > MAX_SECONDS_IN_MSEC_LONG)\n\t\treturn -1;\n\n\treturn (tv->tv_sec * 1000) + ((tv->tv_usec + 999) / 1000);\n}\n\n/*\n  Replacement for usleep on platforms that don't have one.  Not guaranteed to\n  be any more finegrained than 1 msec.\n */\nvoid\nevutil_usleep_(const struct timeval *tv)\n{\n\tif (!tv)\n\t\treturn;\n#if defined(_WIN32)\n\t{\n\t\t__int64 usec;\n\t\tLARGE_INTEGER li;\n\t\tHANDLE timer;\n\n\t\tusec = tv->tv_sec * 1000000LL + tv->tv_usec;\n\t\tif (!usec)\n\t\t\treturn;\n\n\t\tli.QuadPart = -10LL * usec;\n\t\ttimer = CreateWaitableTimer(NULL, TRUE, NULL);\n\t\tif (!timer)\n\t\t\treturn;\n\n\t\tSetWaitableTimer(timer, &li, 0, NULL, NULL, 0);\n\t\tWaitForSingleObject(timer, INFINITE);\n\t\tCloseHandle(timer);\n\t}\n#elif defined(EVENT__HAVE_NANOSLEEP)\n\t{\n\t\tstruct timespec ts;\n\t\tts.tv_sec = tv->tv_sec;\n\t\tts.tv_nsec = tv->tv_usec*1000;\n\t\tnanosleep(&ts, NULL);\n\t}\n#elif defined(EVENT__HAVE_USLEEP)\n\t/* Some systems don't like to usleep more than 999999 usec */\n\tsleep(tv->tv_sec);\n\tusleep(tv->tv_usec);\n#else\n\t{\n\t\tstruct timeval tv2 = *tv;\n\t\tselect(0, NULL, NULL, NULL, &tv2);\n\t}\n#endif\n}\n\nint\nevutil_date_rfc1123(char *date, const size_t datelen, const struct tm *tm)\n{\n\tstatic const char *DAYS[] =\n\t\t{ \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\" };\n\tstatic const char *MONTHS[] =\n\t\t{ \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\" };\n\n\ttime_t t = time(NULL);\n\n#if defined(EVENT__HAVE__GMTIME64_S) || !defined(_WIN32)\n\tstruct tm sys;\n#endif\n\n\t/* If `tm` is null, set system's current time. */\n\tif (tm == NULL) {\n#if !defined(_WIN32)\n\t\tgmtime_r(&t, &sys);\n\t\ttm = &sys;\n\t\t/** detect _gmtime64()/_gmtime64_s() */\n#elif defined(EVENT__HAVE__GMTIME64_S)\n\t\terrno_t err;\n\t\terr = _gmtime64_s(&sys, &t);\n\t\tif (err) {\n\t\t\tevent_errx(1, \"Invalid argument to _gmtime64_s\");\n\t\t} else {\n\t\t\ttm = &sys;\n\t\t}\n#elif defined(EVENT__HAVE__GMTIME64)\n\t\ttm = _gmtime64(&t);\n#else\n\t\ttm = gmtime(&t);\n#endif\n\t}\n\n\treturn evutil_snprintf(\n\t\tdate, datelen, \"%s, %02d %s %4d %02d:%02d:%02d GMT\",\n\t\tDAYS[tm->tm_wday], tm->tm_mday, MONTHS[tm->tm_mon],\n\t\t1900 + tm->tm_year, tm->tm_hour, tm->tm_min, tm->tm_sec);\n}\n\n/*\n   This function assumes it's called repeatedly with a\n   not-actually-so-monotonic time source whose outputs are in 'tv'. It\n   implements a trivial ratcheting mechanism so that the values never go\n   backwards.\n */\nstatic void\nadjust_monotonic_time(struct evutil_monotonic_timer *base,\n    struct timeval *tv)\n{\n\tevutil_timeradd(tv, &base->adjust_monotonic_clock, tv);\n\n\tif (evutil_timercmp(tv, &base->last_time, <)) {\n\t\t/* Guess it wasn't monotonic after all. */\n\t\tstruct timeval adjust;\n\t\tevutil_timersub(&base->last_time, tv, &adjust);\n\t\tevutil_timeradd(&adjust, &base->adjust_monotonic_clock,\n\t\t    &base->adjust_monotonic_clock);\n\t\t*tv = base->last_time;\n\t}\n\tbase->last_time = *tv;\n}\n\n/*\n   Allocate a new struct evutil_monotonic_timer\n */\nstruct evutil_monotonic_timer *\nevutil_monotonic_timer_new(void)\n{\n  struct evutil_monotonic_timer *p = NULL;\n\n  p = mm_malloc(sizeof(*p));\n  if (!p) goto done;\n\n  memset(p, 0, sizeof(*p));\n\n done:\n  return p;\n}\n\n/*\n   Free a struct evutil_monotonic_timer\n */\nvoid\nevutil_monotonic_timer_free(struct evutil_monotonic_timer *timer)\n{\n  if (timer) {\n    mm_free(timer);\n  }\n}\n\n/*\n   Set up a struct evutil_monotonic_timer for initial use\n */\nint\nevutil_configure_monotonic_time(struct evutil_monotonic_timer *timer,\n                                int flags)\n{\n  return evutil_configure_monotonic_time_(timer, flags);\n}\n\n/*\n   Query the current monotonic time\n */\nint\nevutil_gettime_monotonic(struct evutil_monotonic_timer *timer,\n                         struct timeval *tp)\n{\n  return evutil_gettime_monotonic_(timer, tp);\n}\n\n\n#if defined(HAVE_POSIX_MONOTONIC)\n/* =====\n   The POSIX clock_gettime() interface provides a few ways to get at a\n   monotonic clock.  CLOCK_MONOTONIC is most widely supported.  Linux also\n   provides a CLOCK_MONOTONIC_COARSE with accuracy of about 1-4 msec.\n\n   On all platforms I'm aware of, CLOCK_MONOTONIC really is monotonic.\n   Platforms don't agree about whether it should jump on a sleep/resume.\n */\n\nint\nevutil_configure_monotonic_time_(struct evutil_monotonic_timer *base,\n    int flags)\n{\n\t/* CLOCK_MONOTONIC exists on FreeBSD, Linux, and Solaris.  You need to\n\t * check for it at runtime, because some older kernel versions won't\n\t * have it working. */\n#ifdef CLOCK_MONOTONIC_COARSE\n\tconst int precise = flags & EV_MONOT_PRECISE;\n#endif\n\tconst int fallback = flags & EV_MONOT_FALLBACK;\n\tstruct timespec\tts;\n\n\tmemset(base, 0, sizeof(*base));\n\n#ifdef CLOCK_MONOTONIC_COARSE\n\tif (CLOCK_MONOTONIC_COARSE < 0) {\n\t\t/* Technically speaking, nothing keeps CLOCK_* from being\n\t\t * negative (as far as I know). This check and the one below\n\t\t * make sure that it's safe for us to use -1 as an \"unset\"\n\t\t * value. */\n\t\tevent_errx(1,\"I didn't expect CLOCK_MONOTONIC_COARSE to be < 0\");\n\t}\n\tif (! precise && ! fallback) {\n\t\tif (clock_gettime(CLOCK_MONOTONIC_COARSE, &ts) == 0) {\n\t\t\tbase->monotonic_clock = CLOCK_MONOTONIC_COARSE;\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n\tif (!fallback && clock_gettime(CLOCK_MONOTONIC, &ts) == 0) {\n\t\tbase->monotonic_clock = CLOCK_MONOTONIC;\n\t\treturn 0;\n\t}\n\n\tif (CLOCK_MONOTONIC < 0) {\n\t\tevent_errx(1,\"I didn't expect CLOCK_MONOTONIC to be < 0\");\n\t}\n\n\tbase->monotonic_clock = -1;\n\treturn 0;\n}\n\nint\nevutil_gettime_monotonic_(struct evutil_monotonic_timer *base,\n    struct timeval *tp)\n{\n\tstruct timespec ts;\n\n\tif (base->monotonic_clock < 0) {\n\t\tif (evutil_gettimeofday(tp, NULL) < 0)\n\t\t\treturn -1;\n\t\tadjust_monotonic_time(base, tp);\n\t\treturn 0;\n\t}\n\n\tif (clock_gettime(base->monotonic_clock, &ts) == -1)\n\t\treturn -1;\n\ttp->tv_sec = ts.tv_sec;\n\ttp->tv_usec = ts.tv_nsec / 1000;\n\n\treturn 0;\n}\n#endif\n\n#if defined(HAVE_MACH_MONOTONIC)\n/* ======\n   Apple is a little late to the POSIX party.  And why not?  Instead of\n   clock_gettime(), they provide mach_absolute_time().  Its units are not\n   fixed; we need to use mach_timebase_info() to get the right functions to\n   convert its units into nanoseconds.\n\n   To all appearances, mach_absolute_time() seems to be honest-to-goodness\n   monotonic.  Whether it stops during sleep or not is unspecified in\n   principle, and dependent on CPU architecture in practice.\n */\n\nint\nevutil_configure_monotonic_time_(struct evutil_monotonic_timer *base,\n    int flags)\n{\n\tconst int fallback = flags & EV_MONOT_FALLBACK;\n\tstruct mach_timebase_info mi;\n\tmemset(base, 0, sizeof(*base));\n\t/* OSX has mach_absolute_time() */\n\tif (!fallback &&\n\t    mach_timebase_info(&mi) == 0 &&\n\t    mach_absolute_time() != 0) {\n\t\t/* mach_timebase_info tells us how to convert\n\t\t * mach_absolute_time() into nanoseconds, but we\n\t\t * want to use microseconds instead. */\n\t\tmi.denom *= 1000;\n\t\tmemcpy(&base->mach_timebase_units, &mi, sizeof(mi));\n\t} else {\n\t\tbase->mach_timebase_units.numer = 0;\n\t}\n\treturn 0;\n}\n\nint\nevutil_gettime_monotonic_(struct evutil_monotonic_timer *base,\n    struct timeval *tp)\n{\n\tev_uint64_t abstime, usec;\n\tif (base->mach_timebase_units.numer == 0) {\n\t\tif (evutil_gettimeofday(tp, NULL) < 0)\n\t\t\treturn -1;\n\t\tadjust_monotonic_time(base, tp);\n\t\treturn 0;\n\t}\n\n\tabstime = mach_absolute_time();\n\tusec = (abstime * base->mach_timebase_units.numer)\n\t    / (base->mach_timebase_units.denom);\n\ttp->tv_sec = usec / 1000000;\n\ttp->tv_usec = usec % 1000000;\n\n\treturn 0;\n}\n#endif\n\n#if defined(HAVE_WIN32_MONOTONIC)\n/* =====\n   Turn we now to Windows.  Want monontonic time on Windows?\n\n   Windows has QueryPerformanceCounter(), which gives time most high-\n   resolution time.  It's a pity it's not so monotonic in practice; it's\n   also got some fun bugs, especially: with older Windowses, under\n   virtualizations, with funny hardware, on multiprocessor systems, and so\n   on.  PEP418 [1] has a nice roundup of the issues here.\n\n   There's GetTickCount64() on Vista and later, which gives a number of 1-msec\n   ticks since startup.  The accuracy here might be as bad as 10-20 msec, I\n   hear.  There's an undocumented function (NtSetTimerResolution) that\n   allegedly increases the accuracy. Good luck!\n\n   There's also GetTickCount(), which is only 32 bits, but seems to be\n   supported on pre-Vista versions of Windows.  Apparently, you can coax\n   another 14 bits out of it, giving you 2231 years before rollover.\n\n   The less said about timeGetTime() the better.\n\n   \"We don't care.  We don't have to.  We're the Phone Company.\"\n            -- Lily Tomlin, SNL\n\n   Our strategy, if precise timers are turned off, is to just use the best\n   GetTickCount equivalent available.  If we've been asked for precise timing,\n   then we mostly[2] assume that GetTickCount is monotonic, and correct\n   GetPerformanceCounter to approximate it.\n\n   [1] http://www.python.org/dev/peps/pep-0418\n   [2] Of course, we feed the Windows stuff into adjust_monotonic_time()\n       anyway, just in case it isn't.\n\n */\n/*\n    Parts of our logic in the win32 timer code here are closely based on\n    BitTorrent's libUTP library.  That code is subject to the following\n    license:\n\n      Copyright (c) 2010 BitTorrent, Inc.\n\n      Permission is hereby granted, free of charge, to any person obtaining a\n      copy of this software and associated documentation files (the\n      \"Software\"), to deal in the Software without restriction, including\n      without limitation the rights to use, copy, modify, merge, publish,\n      distribute, sublicense, and/or sell copies of the Software, and to\n      permit persons to whom the Software is furnished to do so, subject to\n      the following conditions:\n\n      The above copyright notice and this permission notice shall be included\n      in all copies or substantial portions of the Software.\n\n      THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n      OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n      MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n      NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n      LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n      OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n      WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n\nstatic ev_uint64_t\nevutil_GetTickCount_(struct evutil_monotonic_timer *base)\n{\n\tif (base->GetTickCount64_fn) {\n\t\t/* Let's just use GetTickCount64 if we can. */\n\t\treturn base->GetTickCount64_fn();\n\t} else if (base->GetTickCount_fn) {\n\t\t/* Greg Hazel assures me that this works, that BitTorrent has\n\t\t * done it for years, and this it won't turn around and\n\t\t * bite us.  He says they found it on some game programmers'\n\t\t * forum some time around 2007.\n\t\t */\n\t\tev_uint64_t v = base->GetTickCount_fn();\n\t\treturn (DWORD)v | ((v >> 18) & 0xFFFFFFFF00000000);\n\t} else {\n\t\t/* Here's the fallback implementation. We have to use\n\t\t * GetTickCount() with its given signature, so we only get\n\t\t * 32 bits worth of milliseconds, which will roll ove every\n\t\t * 49 days or so.  */\n\t\tDWORD ticks = GetTickCount();\n\t\tif (ticks < base->last_tick_count) {\n\t\t\tbase->adjust_tick_count += ((ev_uint64_t)1) << 32;\n\t\t}\n\t\tbase->last_tick_count = ticks;\n\t\treturn ticks + base->adjust_tick_count;\n\t}\n}\n\nint\nevutil_configure_monotonic_time_(struct evutil_monotonic_timer *base,\n    int flags)\n{\n\tconst int precise = flags & EV_MONOT_PRECISE;\n\tconst int fallback = flags & EV_MONOT_FALLBACK;\n\tHANDLE h;\n\tmemset(base, 0, sizeof(*base));\n\n\th = evutil_load_windows_system_library_(TEXT(\"kernel32.dll\"));\n\tif (h != NULL && !fallback) {\n\t\tbase->GetTickCount64_fn = (ev_GetTickCount_func)GetProcAddress(h, \"GetTickCount64\");\n\t\tbase->GetTickCount_fn = (ev_GetTickCount_func)GetProcAddress(h, \"GetTickCount\");\n\t}\n\n\tbase->first_tick = base->last_tick_count = evutil_GetTickCount_(base);\n\tif (precise && !fallback) {\n\t\tLARGE_INTEGER freq;\n\t\tif (QueryPerformanceFrequency(&freq)) {\n\t\t\tLARGE_INTEGER counter;\n\t\t\tQueryPerformanceCounter(&counter);\n\t\t\tbase->first_counter = counter.QuadPart;\n\t\t\tbase->usec_per_count = 1.0e6 / freq.QuadPart;\n\t\t\tbase->use_performance_counter = 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic inline ev_int64_t\nabs64(ev_int64_t i)\n{\n\treturn i < 0 ? -i : i;\n}\n\n\nint\nevutil_gettime_monotonic_(struct evutil_monotonic_timer *base,\n    struct timeval *tp)\n{\n\tev_uint64_t ticks = evutil_GetTickCount_(base);\n\tif (base->use_performance_counter) {\n\t\t/* Here's a trick we took from BitTorrent's libutp, at Greg\n\t\t * Hazel's recommendation.  We use QueryPerformanceCounter for\n\t\t * our high-resolution timer, but use GetTickCount*() to keep\n\t\t * it sane, and adjust_monotonic_time() to keep it monotonic.\n\t\t */\n\t\tLARGE_INTEGER counter;\n\t\tev_int64_t counter_elapsed, counter_usec_elapsed, ticks_elapsed;\n\t\tQueryPerformanceCounter(&counter);\n\t\tcounter_elapsed = (ev_int64_t)\n\t\t    (counter.QuadPart - base->first_counter);\n\t\tticks_elapsed = ticks - base->first_tick;\n\t\t/* TODO: This may upset VC6. If you need this to work with\n\t\t * VC6, please supply an appropriate patch. */\n\t\tcounter_usec_elapsed = (ev_int64_t)\n\t\t    (counter_elapsed * base->usec_per_count);\n\n\t\tif (abs64(ticks_elapsed*1000 - counter_usec_elapsed) > 1000000) {\n\t\t\t/* It appears that the QueryPerformanceCounter()\n\t\t\t * result is more than 1 second away from\n\t\t\t * GetTickCount() result. Let's adjust it to be as\n\t\t\t * accurate as we can; adjust_monotonic_time() below\n\t\t\t * will keep it monotonic. */\n\t\t\tcounter_usec_elapsed = ticks_elapsed * 1000;\n\t\t\tbase->first_counter = (ev_uint64_t) (counter.QuadPart - counter_usec_elapsed / base->usec_per_count);\n\t\t}\n\t\ttp->tv_sec = (time_t) (counter_usec_elapsed / 1000000);\n\t\ttp->tv_usec = counter_usec_elapsed % 1000000;\n\n\t} else {\n\t\t/* We're just using GetTickCount(). */\n\t\ttp->tv_sec = (time_t) (ticks / 1000);\n\t\ttp->tv_usec = (ticks % 1000) * 1000;\n\t}\n\tadjust_monotonic_time(base, tp);\n\n\treturn 0;\n}\n#endif\n\n#if defined(HAVE_FALLBACK_MONOTONIC)\n/* =====\n   And if none of the other options work, let's just use gettimeofday(), and\n   ratchet it forward so that it acts like a monotonic timer, whether it\n   wants to or not.\n */\n\nint\nevutil_configure_monotonic_time_(struct evutil_monotonic_timer *base,\n    int precise)\n{\n\tmemset(base, 0, sizeof(*base));\n\treturn 0;\n}\n\nint\nevutil_gettime_monotonic_(struct evutil_monotonic_timer *base,\n    struct timeval *tp)\n{\n\tif (evutil_gettimeofday(tp, NULL) < 0)\n\t\treturn -1;\n\tadjust_monotonic_time(base, tp);\n\treturn 0;\n\n}\n#endif\n"
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "ht-internal.h",
          "type": "blob",
          "size": 28.5009765625,
          "content": "/* Copyright 2002 Christopher Clark */\n/* Copyright 2005-2012 Nick Mathewson */\n/* Copyright 2009-2012 Niels Provos and Nick Mathewson */\n/* See license at end. */\n\n/* Based on ideas by Christopher Clark and interfaces from Niels Provos. */\n\n#ifndef HT_INTERNAL_H_INCLUDED_\n#define HT_INTERNAL_H_INCLUDED_\n\n#define HT_HEAD(name, type)                                             \\\n  struct name {                                                         \\\n    /* The hash table itself. */                                        \\\n    struct type **hth_table;                                            \\\n    /* How long is the hash table? */                                   \\\n    unsigned hth_table_length;                                          \\\n    /* How many elements does the table contain? */                     \\\n    unsigned hth_n_entries;                                             \\\n    /* How many elements will we allow in the table before resizing it? */ \\\n    unsigned hth_load_limit;                                            \\\n    /* Position of hth_table_length in the primes table. */             \\\n    int hth_prime_idx;                                                  \\\n  }\n\n#define HT_INITIALIZER()                        \\\n  { NULL, 0, 0, 0, -1 }\n\n#ifdef HT_NO_CACHE_HASH_VALUES\n#define HT_ENTRY(type)                          \\\n  struct {                                      \\\n    struct type *hte_next;                      \\\n  }\n#else\n#define HT_ENTRY(type)                          \\\n  struct {                                      \\\n    struct type *hte_next;                      \\\n    unsigned hte_hash;                          \\\n  }\n#endif\n\n#define HT_EMPTY(head)                          \\\n  ((head)->hth_n_entries == 0)\n\n/* How many elements in 'head'? */\n#define HT_SIZE(head)                           \\\n  ((head)->hth_n_entries)\n\n/* Return memory usage for a hashtable (not counting the entries themselves) */\n#define HT_MEM_USAGE(head)                         \\\n  (sizeof(*head) + (head)->hth_table_length * sizeof(void*))\n\n#define HT_FIND(name, head, elm)     name##_HT_FIND((head), (elm))\n#define HT_INSERT(name, head, elm)   name##_HT_INSERT((head), (elm))\n#define HT_REPLACE(name, head, elm)  name##_HT_REPLACE((head), (elm))\n#define HT_REMOVE(name, head, elm)   name##_HT_REMOVE((head), (elm))\n#define HT_START(name, head)         name##_HT_START(head)\n#define HT_NEXT(name, head, elm)     name##_HT_NEXT((head), (elm))\n#define HT_NEXT_RMV(name, head, elm) name##_HT_NEXT_RMV((head), (elm))\n#define HT_CLEAR(name, head)         name##_HT_CLEAR(head)\n#define HT_INIT(name, head)          name##_HT_INIT(head)\n/* Helper: */\nstatic inline unsigned\nht_improve_hash_(unsigned h)\n{\n  /* Aim to protect against poor hash functions by adding logic here\n   * - logic taken from java 1.4 hashtable source */\n  h += ~(h << 9);\n  h ^=  ((h >> 14) | (h << 18)); /* >>> */\n  h +=  (h << 4);\n  h ^=  ((h >> 10) | (h << 22)); /* >>> */\n  return h;\n}\n\n#if 0\n/** Basic string hash function, from Java standard String.hashCode(). */\nstatic inline unsigned\nht_string_hash_(const char *s)\n{\n  unsigned h = 0;\n  int m = 1;\n  while (*s) {\n    h += ((signed char)*s++)*m;\n    m = (m<<5)-1; /* m *= 31 */\n  }\n  return h;\n}\n#endif\n\n/** Basic string hash function, from Python's str.__hash__() */\nstatic inline unsigned\nht_string_hash_(const char *s)\n{\n  unsigned h;\n  const unsigned char *cp = (const unsigned char *)s;\n  h = *cp << 7;\n  while (*cp) {\n    h = (1000003*h) ^ *cp++;\n  }\n  /* This conversion truncates the length of the string, but that's ok. */\n  h ^= (unsigned)(cp-(const unsigned char*)s);\n  return h;\n}\n\n#ifndef HT_NO_CACHE_HASH_VALUES\n#define HT_SET_HASH_(elm, field, hashfn)        \\\n\tdo { (elm)->field.hte_hash = hashfn(elm); } while (0)\n#define HT_SET_HASHVAL_(elm, field, val)\t\\\n\tdo { (elm)->field.hte_hash = (val); } while (0)\n#define HT_ELT_HASH_(elm, field, hashfn)\t\\\n\t((elm)->field.hte_hash)\n#else\n#define HT_SET_HASH_(elm, field, hashfn)\t\\\n\t((void)0)\n#define HT_ELT_HASH_(elm, field, hashfn)\t\\\n\t(hashfn(elm))\n#define HT_SET_HASHVAL_(elm, field, val)\t\\\n        ((void)0)\n#endif\n\n/* Helper: alias for the bucket containing 'elm'. */\n#define HT_BUCKET_(head, field, elm, hashfn)\t\t\t\t\\\n\t((head)->hth_table[HT_ELT_HASH_(elm,field,hashfn) % head->hth_table_length])\n\n#define HT_FOREACH(x, name, head)                 \\\n  for ((x) = HT_START(name, head);                \\\n       (x) != NULL;                               \\\n       (x) = HT_NEXT(name, head, x))\n\n#define HT_PROTOTYPE(name, type, field, hashfn, eqfn)                   \\\n  int name##_HT_GROW(struct name *ht, unsigned min_capacity);           \\\n  void name##_HT_CLEAR(struct name *ht);                                \\\n  int name##_HT_REP_IS_BAD_(const struct name *ht);\t\t\t\\\n  static inline void                                                    \\\n  name##_HT_INIT(struct name *head) {                                   \\\n    head->hth_table_length = 0;                                         \\\n    head->hth_table = NULL;                                             \\\n    head->hth_n_entries = 0;                                            \\\n    head->hth_load_limit = 0;                                           \\\n    head->hth_prime_idx = -1;                                           \\\n  }                                                                     \\\n  /* Helper: returns a pointer to the right location in the table       \\\n   * 'head' to find or insert the element 'elm'. */                     \\\n  static inline struct type **                                          \\\n  name##_HT_FIND_P_(struct name *head, struct type *elm)\t\t\\\n  {                                                                     \\\n    struct type **p;                                                    \\\n    if (!head->hth_table)                                               \\\n      return NULL;                                                      \\\n    p = &HT_BUCKET_(head, field, elm, hashfn);\t\t\t\t\\\n    while (*p) {                                                        \\\n      if (eqfn(*p, elm))                                                \\\n        return p;                                                       \\\n      p = &(*p)->field.hte_next;                                        \\\n    }                                                                   \\\n    return p;                                                           \\\n  }                                                                     \\\n  /* Return a pointer to the element in the table 'head' matching 'elm', \\\n   * or NULL if no such element exists */                               \\\n  static inline struct type *                                           \\\n  name##_HT_FIND(const struct name *head, struct type *elm)             \\\n  {                                                                     \\\n    struct type **p;                                                    \\\n    struct name *h = (struct name *) head;                              \\\n    HT_SET_HASH_(elm, field, hashfn);                                   \\\n    p = name##_HT_FIND_P_(h, elm);\t\t\t\t\t\\\n    return p ? *p : NULL;                                               \\\n  }                                                                     \\\n  /* Insert the element 'elm' into the table 'head'.  Do not call this  \\\n   * function if the table might already contain a matching element. */ \\\n  static inline void                                                    \\\n  name##_HT_INSERT(struct name *head, struct type *elm)                 \\\n  {                                                                     \\\n    struct type **p;                                                    \\\n    if (!head->hth_table || head->hth_n_entries >= head->hth_load_limit) \\\n      name##_HT_GROW(head, head->hth_n_entries+1);                      \\\n    ++head->hth_n_entries;                                              \\\n    HT_SET_HASH_(elm, field, hashfn);                                   \\\n    p = &HT_BUCKET_(head, field, elm, hashfn);\t\t\t\t\\\n    elm->field.hte_next = *p;                                           \\\n    *p = elm;                                                           \\\n  }                                                                     \\\n  /* Insert the element 'elm' into the table 'head'. If there already   \\\n   * a matching element in the table, replace that element and return   \\\n   * it. */                                                             \\\n  static inline struct type *                                           \\\n  name##_HT_REPLACE(struct name *head, struct type *elm)                \\\n  {                                                                     \\\n    struct type **p, *r;                                                \\\n    if (!head->hth_table || head->hth_n_entries >= head->hth_load_limit) \\\n      name##_HT_GROW(head, head->hth_n_entries+1);                      \\\n    HT_SET_HASH_(elm, field, hashfn);                                   \\\n    p = name##_HT_FIND_P_(head, elm);\t\t\t\t\t\\\n    r = *p;                                                             \\\n    *p = elm;                                                           \\\n    if (r && (r!=elm)) {                                                \\\n      elm->field.hte_next = r->field.hte_next;                          \\\n      r->field.hte_next = NULL;                                         \\\n      return r;                                                         \\\n    } else {                                                            \\\n      ++head->hth_n_entries;                                            \\\n      return NULL;                                                      \\\n    }                                                                   \\\n  }                                                                     \\\n  /* Remove any element matching 'elm' from the table 'head'.  If such  \\\n   * an element is found, return it; otherwise return NULL. */          \\\n  static inline struct type *                                           \\\n  name##_HT_REMOVE(struct name *head, struct type *elm)                 \\\n  {                                                                     \\\n    struct type **p, *r;                                                \\\n    HT_SET_HASH_(elm, field, hashfn);                                   \\\n    p = name##_HT_FIND_P_(head,elm);\t\t\t\t\t\\\n    if (!p || !*p)                                                      \\\n      return NULL;                                                      \\\n    r = *p;                                                             \\\n    *p = r->field.hte_next;                                             \\\n    r->field.hte_next = NULL;                                           \\\n    --head->hth_n_entries;                                              \\\n    return r;                                                           \\\n  }                                                                     \\\n  /* Invoke the function 'fn' on every element of the table 'head',     \\\n   * using 'data' as its second argument.  If the function returns      \\\n   * nonzero, remove the most recently examined element before invoking \\\n   * the function again. */                                             \\\n  static inline void                                                    \\\n  name##_HT_FOREACH_FN(struct name *head,                               \\\n                       int (*fn)(struct type *, void *),                \\\n                       void *data)                                      \\\n  {                                                                     \\\n    unsigned idx;                                                       \\\n    struct type **p, **nextp, *next;                                    \\\n    if (!head->hth_table)                                               \\\n      return;                                                           \\\n    for (idx=0; idx < head->hth_table_length; ++idx) {                  \\\n      p = &head->hth_table[idx];                                        \\\n      while (*p) {                                                      \\\n        nextp = &(*p)->field.hte_next;                                  \\\n        next = *nextp;                                                  \\\n        if (fn(*p, data)) {                                             \\\n          --head->hth_n_entries;                                        \\\n          *p = next;                                                    \\\n        } else {                                                        \\\n          p = nextp;                                                    \\\n        }                                                               \\\n      }                                                                 \\\n    }                                                                   \\\n  }                                                                     \\\n  /* Return a pointer to the first element in the table 'head', under   \\\n   * an arbitrary order.  This order is stable under remove operations, \\\n   * but not under others. If the table is empty, return NULL. */       \\\n  static inline struct type **                                          \\\n  name##_HT_START(struct name *head)                                    \\\n  {                                                                     \\\n    unsigned b = 0;                                                     \\\n    while (b < head->hth_table_length) {                                \\\n      if (head->hth_table[b])                                           \\\n        return &head->hth_table[b];                                     \\\n      ++b;                                                              \\\n    }                                                                   \\\n    return NULL;                                                        \\\n  }                                                                     \\\n  /* Return the next element in 'head' after 'elm', under the arbitrary \\\n   * order used by HT_START.  If there are no more elements, return     \\\n   * NULL.  If 'elm' is to be removed from the table, you must call     \\\n   * this function for the next value before you remove it.             \\\n   */                                                                   \\\n  static inline struct type **                                          \\\n  name##_HT_NEXT(struct name *head, struct type **elm)                  \\\n  {                                                                     \\\n    if ((*elm)->field.hte_next) {                                       \\\n      return &(*elm)->field.hte_next;                                   \\\n    } else {                                                            \\\n      unsigned b = (HT_ELT_HASH_(*elm, field, hashfn) % head->hth_table_length)+1; \\\n      while (b < head->hth_table_length) {                              \\\n        if (head->hth_table[b])                                         \\\n          return &head->hth_table[b];                                   \\\n        ++b;                                                            \\\n      }                                                                 \\\n      return NULL;                                                      \\\n    }                                                                   \\\n  }                                                                     \\\n  static inline struct type **                                          \\\n  name##_HT_NEXT_RMV(struct name *head, struct type **elm)              \\\n  {                                                                     \\\n    unsigned h = HT_ELT_HASH_(*elm, field, hashfn);\t\t        \\\n    *elm = (*elm)->field.hte_next;                                      \\\n    --head->hth_n_entries;                                              \\\n    if (*elm) {                                                         \\\n      return elm;                                                       \\\n    } else {                                                            \\\n      unsigned b = (h % head->hth_table_length)+1;                      \\\n      while (b < head->hth_table_length) {                              \\\n        if (head->hth_table[b])                                         \\\n          return &head->hth_table[b];                                   \\\n        ++b;                                                            \\\n      }                                                                 \\\n      return NULL;                                                      \\\n    }                                                                   \\\n  }\n\n#define HT_GENERATE(name, type, field, hashfn, eqfn, load, mallocfn,    \\\n                    reallocfn, freefn)                                  \\\n  static unsigned name##_PRIMES[] = {                                   \\\n    53, 97, 193, 389,                                                   \\\n    769, 1543, 3079, 6151,                                              \\\n    12289, 24593, 49157, 98317,                                         \\\n    196613, 393241, 786433, 1572869,                                    \\\n    3145739, 6291469, 12582917, 25165843,                               \\\n    50331653, 100663319, 201326611, 402653189,                          \\\n    805306457, 1610612741                                               \\\n  };                                                                    \\\n  static unsigned name##_N_PRIMES =                                     \\\n    (unsigned)(sizeof(name##_PRIMES)/sizeof(name##_PRIMES[0])) - 1;     \\\n  /* Expand the internal table of 'head' until it is large enough to    \\\n   * hold 'size' elements.  Return 0 on success, -1 on allocation       \\\n   * failure. */                                                        \\\n  int                                                                   \\\n  name##_HT_GROW(struct name *head, unsigned size)                      \\\n  {                                                                     \\\n    unsigned new_len, new_load_limit;                                   \\\n    int prime_idx;                                                      \\\n    struct type **new_table;                                            \\\n    if (head->hth_prime_idx == (int)name##_N_PRIMES)                    \\\n      return 0;                                                         \\\n    if (head->hth_load_limit > size)                                    \\\n      return 0;                                                         \\\n    prime_idx = head->hth_prime_idx;                                    \\\n    do {                                                                \\\n      new_len = name##_PRIMES[++prime_idx];                             \\\n      new_load_limit = (unsigned)(load*new_len);                        \\\n    } while (new_load_limit <= size &&                                  \\\n             prime_idx < (int)name##_N_PRIMES);                         \\\n    if ((new_table = mallocfn(new_len*sizeof(struct type*)))) {         \\\n      unsigned b;                                                       \\\n      memset(new_table, 0, new_len*sizeof(struct type*));               \\\n      for (b = 0; b < head->hth_table_length; ++b) {                    \\\n        struct type *elm, *next;                                        \\\n        unsigned b2;                                                    \\\n        elm = head->hth_table[b];                                       \\\n        while (elm) {                                                   \\\n          next = elm->field.hte_next;                                   \\\n          b2 = HT_ELT_HASH_(elm, field, hashfn) % new_len;              \\\n          elm->field.hte_next = new_table[b2];                          \\\n          new_table[b2] = elm;                                          \\\n          elm = next;                                                   \\\n        }                                                               \\\n      }                                                                 \\\n      if (head->hth_table)                                              \\\n        freefn(head->hth_table);                                        \\\n      head->hth_table = new_table;                                      \\\n    } else {                                                            \\\n      unsigned b, b2;                                                   \\\n      new_table = reallocfn(head->hth_table, new_len*sizeof(struct type*)); \\\n      if (!new_table) return -1;                                        \\\n      memset(new_table + head->hth_table_length, 0,                     \\\n             (new_len - head->hth_table_length)*sizeof(struct type*));  \\\n      for (b=0; b < head->hth_table_length; ++b) {                      \\\n        struct type *e, **pE;                                           \\\n        for (pE = &new_table[b], e = *pE; e != NULL; e = *pE) {         \\\n          b2 = HT_ELT_HASH_(e, field, hashfn) % new_len;                \\\n          if (b2 == b) {                                                \\\n            pE = &e->field.hte_next;                                    \\\n          } else {                                                      \\\n            *pE = e->field.hte_next;                                    \\\n            e->field.hte_next = new_table[b2];                          \\\n            new_table[b2] = e;                                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      head->hth_table = new_table;                                      \\\n    }                                                                   \\\n    head->hth_table_length = new_len;                                   \\\n    head->hth_prime_idx = prime_idx;                                    \\\n    head->hth_load_limit = new_load_limit;                              \\\n    return 0;                                                           \\\n  }                                                                     \\\n  /* Free all storage held by 'head'.  Does not free 'head' itself, or  \\\n   * individual elements. */                                            \\\n  void                                                                  \\\n  name##_HT_CLEAR(struct name *head)                                    \\\n  {                                                                     \\\n    if (head->hth_table)                                                \\\n      freefn(head->hth_table);                                          \\\n    name##_HT_INIT(head);                                               \\\n  }                                                                     \\\n  /* Debugging helper: return false iff the representation of 'head' is \\\n   * internally consistent. */                                          \\\n  int                                                                   \\\n  name##_HT_REP_IS_BAD_(const struct name *head)\t\t\t\\\n  {                                                                     \\\n    unsigned n, i;                                                      \\\n    struct type *elm;                                                   \\\n    if (!head->hth_table_length) {                                      \\\n      if (!head->hth_table && !head->hth_n_entries &&                   \\\n          !head->hth_load_limit && head->hth_prime_idx == -1)           \\\n        return 0;                                                       \\\n      else                                                              \\\n        return 1;                                                       \\\n    }                                                                   \\\n    if (!head->hth_table || head->hth_prime_idx < 0 ||                  \\\n        !head->hth_load_limit)                                          \\\n      return 2;                                                         \\\n    if (head->hth_n_entries > head->hth_load_limit)                     \\\n      return 3;                                                         \\\n    if (head->hth_table_length != name##_PRIMES[head->hth_prime_idx])   \\\n      return 4;                                                         \\\n    if (head->hth_load_limit != (unsigned)(load*head->hth_table_length)) \\\n      return 5;                                                         \\\n    for (n = i = 0; i < head->hth_table_length; ++i) {                  \\\n      for (elm = head->hth_table[i]; elm; elm = elm->field.hte_next) {  \\\n        if (HT_ELT_HASH_(elm, field, hashfn) != hashfn(elm))\t        \\\n          return 1000 + i;                                              \\\n        if ((HT_ELT_HASH_(elm, field, hashfn) % head->hth_table_length) != i) \\\n          return 10000 + i;                                             \\\n        ++n;                                                            \\\n      }                                                                 \\\n    }                                                                   \\\n    if (n != head->hth_n_entries)                                       \\\n      return 6;                                                         \\\n    return 0;                                                           \\\n  }\n\n/** Implements an over-optimized \"find and insert if absent\" block;\n * not meant for direct usage by typical code, or usage outside the critical\n * path.*/\n#define HT_FIND_OR_INSERT_(name, field, hashfn, head, eltype, elm, var, y, n) \\\n  {                                                                     \\\n    struct name *var##_head_ = head;                                    \\\n    struct eltype **var;                                                \\\n    if (!var##_head_->hth_table ||                                      \\\n        var##_head_->hth_n_entries >= var##_head_->hth_load_limit)      \\\n      name##_HT_GROW(var##_head_, var##_head_->hth_n_entries+1);        \\\n    HT_SET_HASH_((elm), field, hashfn);                                 \\\n    var = name##_HT_FIND_P_(var##_head_, (elm));                        \\\n    if (*var) {                                                         \\\n      y;                                                                \\\n    } else {                                                            \\\n      n;                                                                \\\n    }                                                                   \\\n  }\n#define HT_FOI_INSERT_(field, head, elm, newent, var)       \\\n  {                                                         \\\n    HT_SET_HASHVAL_(newent, field, (elm)->field.hte_hash);  \\\n    newent->field.hte_next = NULL;                          \\\n    *var = newent;                                          \\\n    ++((head)->hth_n_entries);                              \\\n  }\n\n/*\n * Copyright 2005, Nick Mathewson.  Implementation logic is adapted from code\n * by Christopher Clark, retrofit to allow drop-in memory management, and to\n * use the same interface as Niels Provos's tree.h.  This is probably still\n * a derived work, so the original license below still applies.\n *\n * Copyright (c) 2002, Christopher Clark\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * * Redistributions of source code must retain the above copyright\n * notice, this list of conditions and the following disclaimer.\n *\n * * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * * Neither the name of the original author; nor the names of any contributors\n * may be used to endorse or promote products derived from this software\n * without specific prior written permission.\n *\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER\n * OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n*/\n\n#endif\n\n"
        },
        {
          "name": "http-internal.h",
          "type": "blob",
          "size": 6.7763671875,
          "content": "/*\n * Copyright 2001-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * This header file contains definitions for dealing with HTTP requests\n * that are internal to libevent.  As user of the library, you should not\n * need to know about these.\n */\n\n#ifndef HTTP_INTERNAL_H_INCLUDED_\n#define HTTP_INTERNAL_H_INCLUDED_\n\n#include \"event2/event_struct.h\"\n#include \"util-internal.h\"\n#include \"defer-internal.h\"\n\n#define HTTP_CONNECT_TIMEOUT\t45\n#define HTTP_WRITE_TIMEOUT\t50\n#define HTTP_READ_TIMEOUT\t50\n#define HTTP_INITIAL_RETRY_TIMEOUT\t2\n\nenum message_read_status {\n\tALL_DATA_READ = 1,\n\tMORE_DATA_EXPECTED = 0,\n\tDATA_CORRUPTED = -1,\n\tREQUEST_CANCELED = -2,\n\tDATA_TOO_LONG = -3\n};\n\nstruct evbuffer;\nstruct addrinfo;\nstruct evhttp_request;\n\nenum evhttp_connection_state {\n\tEVCON_DISCONNECTED,\t/**< not currently connected not trying either*/\n\tEVCON_CONNECTING,\t/**< tries to currently connect */\n\tEVCON_IDLE,\t\t/**< connection is established */\n\tEVCON_READING_FIRSTLINE,/**< reading Request-Line (incoming conn) or\n\t\t\t\t **< Status-Line (outgoing conn) */\n\tEVCON_READING_HEADERS,\t/**< reading request/response headers */\n\tEVCON_READING_BODY,\t/**< reading request/response body */\n\tEVCON_READING_TRAILER,\t/**< reading request/response chunked trailer */\n\tEVCON_WRITING\t\t/**< writing request/response headers/body */\n};\n\nstruct event_base;\n\n/* A client or server connection. */\nstruct evhttp_connection {\n\t/* we use this tailq only if this connection was created for an http\n\t * server */\n\tTAILQ_ENTRY(evhttp_connection) next;\n\n\tstruct bufferevent *bufev;\n\n\tstruct event retry_ev;\t\t/* for retrying connects */\n\n\tchar *bind_address;\t\t/* address to use for binding the src */\n\tev_uint16_t bind_port;\t\t/* local port for binding the src */\n\n\tchar *address;\t\t\t/* address to connect to */\n\tev_uint16_t port;\n\n#ifndef _WIN32\n\tchar *unixsocket;\n#endif\n\tsize_t max_headers_size;\n\tev_uint64_t max_body_size;\n\n\tint flags;\n#define EVHTTP_CON_INCOMING\t0x0001       /* only one request on it ever */\n#define EVHTTP_CON_OUTGOING\t0x0002       /* multiple requests possible */\n#define EVHTTP_CON_CLOSEDETECT\t0x0004   /* detecting if persistent close */\n/* set when we want to auto free the connection */\n#define EVHTTP_CON_AUTOFREE\tEVHTTP_CON_PUBLIC_FLAGS_END\n/* Installed when attempt to read HTTP error after write failed, see\n * EVHTTP_CON_READ_ON_WRITE_ERROR */\n#define EVHTTP_CON_READING_ERROR\t(EVHTTP_CON_AUTOFREE << 1)\n/* Timeout is not default */\n#define EVHTTP_CON_TIMEOUT_ADJUSTED\t(EVHTTP_CON_READING_ERROR << 1)\n\n\tstruct timeval timeout_connect;\t\t/* timeout for connect phase */\n\tstruct timeval timeout_read;\t\t/* timeout for read */\n\tstruct timeval timeout_write;\t\t/* timeout for write */\n\n\tint retry_cnt;\t\t\t/* retry count */\n\tint retry_max;\t\t\t/* maximum number of retries */\n\tstruct timeval initial_retry_timeout; /* Timeout for low long to wait\n\t\t\t\t\t       * after first failing attempt\n\t\t\t\t\t       * before retry */\n\n\tenum evhttp_connection_state state;\n\n\t/* for server connections, the http server they are connected with */\n\tstruct evhttp *http_server;\n\n\tTAILQ_HEAD(evcon_requestq, evhttp_request) requests;\n\n\tvoid (*cb)(struct evhttp_connection *, void *);\n\tvoid *cb_arg;\n\n\tvoid (*closecb)(struct evhttp_connection *, void *);\n\tvoid *closecb_arg;\n\n\tstruct event_callback read_more_deferred_cb;\n\n\tstruct event_base *base;\n\tstruct evdns_base *dns_base;\n\tint ai_family;\n\n\tevhttp_ext_method_cb ext_method_cmp;\n};\n\n/* A callback for an http server */\nstruct evhttp_cb {\n\tTAILQ_ENTRY(evhttp_cb) next;\n\n\tchar *what;\n\n\tvoid (*cb)(struct evhttp_request *req, void *);\n\tvoid *cbarg;\n};\n\n/* both the http server as well as the rpc system need to queue connections */\nTAILQ_HEAD(evconq, evhttp_connection);\n\n/* WebSockets connections */\nTAILQ_HEAD(evwsq, evws_connection);\n\n/* each bound socket is stored in one of these */\nstruct evhttp_bound_socket {\n\tTAILQ_ENTRY(evhttp_bound_socket) next;\n\n\tstruct evhttp *http;\n\tstruct bufferevent* (*bevcb)(struct event_base *, void *);\n\tvoid *bevcbarg;\n\n\tstruct evconnlistener *listener;\n};\n\n/* server alias list item. */\nstruct evhttp_server_alias {\n\tTAILQ_ENTRY(evhttp_server_alias) next;\n\n\tchar *alias; /* the server alias. */\n};\n\nstruct evhttp {\n\t/* Next vhost, if this is a vhost. */\n\tTAILQ_ENTRY(evhttp) next_vhost;\n\n\t/* All listeners for this host */\n\tTAILQ_HEAD(boundq, evhttp_bound_socket) sockets;\n\n\tTAILQ_HEAD(httpcbq, evhttp_cb) callbacks;\n\n\t/* All live HTTP connections on this host. */\n\tstruct evconq connections;\n\t/* All live WebSockets sessions on this host. */\n\tstruct evwsq ws_sessions;\n\tint connection_max;\n\tint connection_cnt;\n\n\tTAILQ_HEAD(vhostsq, evhttp) virtualhosts;\n\n\tTAILQ_HEAD(aliasq, evhttp_server_alias) aliases;\n\n\t/* NULL if this server is not a vhost */\n\tchar *vhost_pattern;\n\n\tstruct timeval timeout_read;\t\t/* timeout for read */\n\tstruct timeval timeout_write;\t\t/* timeout for write */\n\n\tsize_t default_max_headers_size;\n\tev_uint64_t default_max_body_size;\n\tint flags;\n\tconst char *default_content_type;\n\n\t/* Bitmask of all HTTP methods that we accept and pass to user\n\t * callbacks. */\n\tev_uint32_t allowed_methods;\n\n\t/* Fallback callback if all the other callbacks for this connection\n\t   don't match. */\n\tvoid (*gencb)(struct evhttp_request *req, void *);\n\tvoid *gencbarg;\n\n\tstruct bufferevent* (*bevcb)(struct event_base *, void *);\n\tvoid *bevcbarg;\n\tint (*newreqcb)(struct evhttp_request *req, void *);\n\tvoid *newreqcbarg;\n\n\tint (*errorcb)(struct evhttp_request *, struct evbuffer *, int, const char *, void *);\n\tvoid *errorcbarg;\n\n\tstruct event_base *base;\n\n\tevhttp_ext_method_cb ext_method_cmp;\n};\n\n/* XXX most of these functions could be static. */\n\n/* resets the connection; can be reused for more requests */\nvoid evhttp_connection_reset_(struct evhttp_connection *, int);\n\n/* connects if necessary */\nint evhttp_connection_connect_(struct evhttp_connection *);\n\nenum evhttp_request_error;\n/* notifies the current request that it failed; resets connection */\nEVENT2_EXPORT_SYMBOL\nvoid evhttp_connection_fail_(struct evhttp_connection *,\n    enum evhttp_request_error error);\n\nenum message_read_status;\n\nEVENT2_EXPORT_SYMBOL\nenum message_read_status evhttp_parse_firstline_(struct evhttp_request *, struct evbuffer*);\nEVENT2_EXPORT_SYMBOL\nenum message_read_status evhttp_parse_headers_(struct evhttp_request *, struct evbuffer*);\n\nvoid evhttp_start_read_(struct evhttp_connection *);\nvoid evhttp_start_write_(struct evhttp_connection *);\n\n/* response sending HTML the data in the buffer */\nvoid evhttp_response_code_(struct evhttp_request *, int, const char *);\nvoid evhttp_send_page_(struct evhttp_request *, struct evbuffer *);\n\nstruct bufferevent * evhttp_start_ws_(struct evhttp_request *req);\n\n/* [] has been stripped */\n#define _EVHTTP_URI_HOST_HAS_BRACKETS 0x02\n\nEVENT2_EXPORT_SYMBOL\nint evhttp_decode_uri_internal(const char *uri, size_t length,\n    char *ret, int decode_plus);\n\n#endif /* HTTP_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "http.c",
          "type": "blob",
          "size": 137.373046875,
          "content": "/*\n * Copyright (c) 2002-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#define member_size(type, member) sizeof(((type *)0)->member)\n\n#ifdef EVENT__HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n#ifdef EVENT__HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n\n#ifdef HAVE_SYS_IOCCOM_H\n#include <sys/ioccom.h>\n#endif\n#ifdef EVENT__HAVE_SYS_RESOURCE_H\n#include <sys/resource.h>\n#endif\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#ifdef EVENT__HAVE_SYS_WAIT_H\n#include <sys/wait.h>\n#endif\n\n#ifndef _WIN32\n#include <sys/socket.h>\n#include <sys/stat.h>\n#else /* _WIN32 */\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#endif /* _WIN32 */\n\n#ifdef EVENT__HAVE_SYS_UN_H\n#include <sys/un.h>\n#endif\n#ifdef EVENT__HAVE_AFUNIX_H\n#include <afunix.h>\n#endif\n\n#include <sys/queue.h>\n\n#ifdef EVENT__HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef EVENT__HAVE_ARPA_INET_H\n#include <arpa/inet.h>\n#endif\n#ifdef EVENT__HAVE_NETDB_H\n#include <netdb.h>\n#endif\n\n#ifdef _WIN32\n#include <winsock2.h>\n#endif\n\n#include <ctype.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifndef _WIN32\n#include <syslog.h>\n#endif /* !_WIN32 */\n#include <signal.h>\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n\n#undef timeout_pending\n#undef timeout_initialized\n\n#include \"strlcpy-internal.h\"\n#include \"event2/http.h\"\n#include \"event2/event.h\"\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/http_struct.h\"\n#include \"event2/http_compat.h\"\n#include \"event2/util.h\"\n#include \"event2/ws.h\"\n#include \"event2/listener.h\"\n#include \"log-internal.h\"\n#include \"util-internal.h\"\n#include \"http-internal.h\"\n#include \"mm-internal.h\"\n#include \"bufferevent-internal.h\"\n\n#ifndef EVENT__HAVE_GETNAMEINFO\n#define NI_MAXSERV 32\n#define NI_MAXHOST 1025\n\n#ifndef NI_NUMERICHOST\n#define NI_NUMERICHOST 1\n#endif\n\n#ifndef NI_NUMERICSERV\n#define NI_NUMERICSERV 2\n#endif\n\nstatic int\nfake_getnameinfo(const struct sockaddr *sa, size_t salen, char *host,\n\tsize_t hostlen, char *serv, size_t servlen, int flags)\n{\n\tstruct sockaddr_in *sin = (struct sockaddr_in *)sa;\n\n\tif (serv != NULL) {\n\t\tchar tmpserv[16];\n\t\tevutil_snprintf(tmpserv, sizeof(tmpserv),\n\t\t    \"%d\", ntohs(sin->sin_port));\n\t\tif (strlcpy(serv, tmpserv, servlen) >= servlen)\n\t\t\treturn (-1);\n\t}\n\n\tif (host != NULL) {\n\t\tif (flags & NI_NUMERICHOST) {\n\t\t\tif (strlcpy(host, inet_ntoa(sin->sin_addr),\n\t\t\t    hostlen) >= hostlen)\n\t\t\t\treturn (-1);\n\t\t\telse\n\t\t\t\treturn (0);\n\t\t} else {\n\t\t\tstruct hostent *hp;\n\t\t\thp = gethostbyaddr((char *)&sin->sin_addr,\n\t\t\t    sizeof(struct in_addr), AF_INET);\n\t\t\tif (hp == NULL)\n\t\t\t\treturn (-2);\n\n\t\t\tif (strlcpy(host, hp->h_name, hostlen) >= hostlen)\n\t\t\t\treturn (-1);\n\t\t\telse\n\t\t\t\treturn (0);\n\t\t}\n\t}\n\treturn (0);\n}\n\n#endif\n\n#define REQ_VERSION_BEFORE(req, major_v, minor_v)\t\t\t\\\n\t((req)->major < (major_v) ||\t\t\t\t\t\\\n\t    ((req)->major == (major_v) && (req)->minor < (minor_v)))\n\n#define REQ_VERSION_ATLEAST(req, major_v, minor_v)\t\t\t\\\n\t((req)->major > (major_v) ||\t\t\t\t\t\\\n\t    ((req)->major == (major_v) && (req)->minor >= (minor_v)))\n\n#ifndef MIN\n#define MIN(a,b) (((a)<(b))?(a):(b))\n#endif\n\n/** The request obj owns the evhttp connection and needs to free it */\n#define EVHTTP_REQ_OWN_CONNECTION\t0x0001\n/** The request object is owned by the user; the user must free it */\n#define EVHTTP_USER_OWNED\t\t0x0004\n/** The request will be used again upstack; freeing must be deferred */\n#define EVHTTP_REQ_DEFER_FREE\t\t0x0008\n/** The request should be freed upstack */\n#define EVHTTP_REQ_NEEDS_FREE\t\t0x0010\n\nextern int debug;\n\nstatic evutil_socket_t create_bind_socket_nonblock(struct evutil_addrinfo *, int reuse);\nstatic evutil_socket_t bind_socket(const char *, ev_uint16_t, int reuse);\nstatic void name_from_addr(struct sockaddr *, ev_socklen_t, char **, char **);\nstatic struct evhttp_uri *evhttp_uri_parse_authority(char *source_uri, unsigned flags);\nstatic int evhttp_associate_new_request_with_connection(\n\tstruct evhttp_connection *evcon);\nstatic void evhttp_connection_start_detectclose(\n\tstruct evhttp_connection *evcon);\nstatic void evhttp_connection_stop_detectclose(\n\tstruct evhttp_connection *evcon);\nstatic void evhttp_request_dispatch(struct evhttp_connection* evcon);\nstatic void evhttp_read_firstline(struct evhttp_connection *evcon,\n\t\t\t\t  struct evhttp_request *req);\nstatic void evhttp_read_header(struct evhttp_connection *evcon,\n    struct evhttp_request *req);\nstatic int evhttp_add_header_internal(struct evkeyvalq *headers,\n    const char *key, const char *value);\nstatic const char *evhttp_response_phrase_internal(int code);\nstatic void evhttp_get_request(struct evhttp *, evutil_socket_t, struct sockaddr *, ev_socklen_t, struct bufferevent *bev);\nstatic void evhttp_write_buffer(struct evhttp_connection *,\n    void (*)(struct evhttp_connection *, void *), void *);\nstatic void evhttp_make_header(struct evhttp_connection *, struct evhttp_request *);\nstatic int evhttp_method_may_have_body_(struct evhttp_connection *, enum evhttp_cmd_type);\n\n/* callbacks for bufferevent */\nstatic void evhttp_read_cb(struct bufferevent *, void *);\nstatic void evhttp_write_cb(struct bufferevent *, void *);\nstatic void evhttp_error_cb(struct bufferevent *bufev, short what, void *arg);\nstatic int evhttp_find_vhost(struct evhttp *http, struct evhttp **outhttp, const char *hostname);\nstatic const char *evhttp_method_(struct evhttp_connection *evcon,\n\tenum evhttp_cmd_type type, ev_uint16_t *flags);\n\n#ifndef EVENT__HAVE_STRSEP\n/* strsep replacement for platforms that lack it.  Only works if\n * del is one character long. */\nstatic char *\nstrsep(char **s, const char *del)\n{\n\tchar *d, *tok;\n\tEVUTIL_ASSERT(strlen(del) == 1);\n\tif (!s || !*s)\n\t\treturn NULL;\n\ttok = *s;\n\td = strstr(tok, del);\n\tif (d) {\n\t\t*d = '\\0';\n\t\t*s = d + 1;\n\t} else\n\t\t*s = NULL;\n\treturn tok;\n}\n#endif\n\nstatic size_t\nhtml_replace(const char ch, const char **escaped)\n{\n\tswitch (ch) {\n\tcase '<':\n\t\t*escaped = \"&lt;\";\n\t\treturn 4;\n\tcase '>':\n\t\t*escaped = \"&gt;\";\n\t\treturn 4;\n\tcase '\"':\n\t\t*escaped = \"&quot;\";\n\t\treturn 6;\n\tcase '\\'':\n\t\t*escaped = \"&#039;\";\n\t\treturn 6;\n\tcase '&':\n\t\t*escaped = \"&amp;\";\n\t\treturn 5;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 1;\n}\n\n/*\n * Replaces <, >, \", ' and & with &lt;, &gt;, &quot;,\n * &#039; and &amp; correspondingly.\n *\n * The returned string needs to be freed by the caller.\n */\n\nchar *\nevhttp_htmlescape(const char *html)\n{\n\tsize_t i;\n\tsize_t new_size = 0, old_size = 0;\n\tchar *escaped_html, *p;\n\n\tif (html == NULL)\n\t\treturn (NULL);\n\n\told_size = strlen(html);\n\tfor (i = 0; i < old_size; ++i) {\n\t\tconst char *replaced = NULL;\n\t\tconst size_t replace_size = html_replace(html[i], &replaced);\n\t\tif (replace_size > EV_SIZE_MAX - new_size) {\n\t\t\tevent_warn(\"%s: html_replace overflow\", __func__);\n\t\t\treturn (NULL);\n\t\t}\n\t\tnew_size += replace_size;\n\t}\n\n\tif (new_size == EV_SIZE_MAX)\n\t\treturn (NULL);\n\tp = escaped_html = mm_malloc(new_size + 1);\n\tif (escaped_html == NULL) {\n\t\tevent_warn(\"%s: malloc(%lu)\", __func__,\n\t\t           (unsigned long)(new_size + 1));\n\t\treturn (NULL);\n\t}\n\tfor (i = 0; i < old_size; ++i) {\n\t\tconst char *replaced = &html[i];\n\t\tconst size_t len = html_replace(html[i], &replaced);\n\t\tmemcpy(p, replaced, len);\n\t\tp += len;\n\t}\n\n\t*p = '\\0';\n\n\treturn (escaped_html);\n}\n\n/** Given an evhttp_cmd_type, returns a constant string containing the\n * equivalent HTTP command, or NULL if the evhttp_cmd_type is\n * unrecognized. */\nstatic const char *\nevhttp_method_(struct evhttp_connection *evcon,\n              enum evhttp_cmd_type type, ev_uint16_t *flags)\n{\n\tstruct evhttp_ext_method ext_method;\n\tconst char *method    = NULL;\n\tev_uint16_t tmp_flags = EVHTTP_METHOD_HAS_BODY;\n\n\tswitch (type) {\n\tcase EVHTTP_REQ_GET:\n\t\tmethod = \"GET\";\n\t\tbreak;\n\tcase EVHTTP_REQ_POST:\n\t\tmethod = \"POST\";\n\t\tbreak;\n\tcase EVHTTP_REQ_HEAD:\n\t\tmethod = \"HEAD\";\n\t\ttmp_flags &= ~EVHTTP_METHOD_HAS_BODY;\n\t\tbreak;\n\tcase EVHTTP_REQ_PUT:\n\t\tmethod = \"PUT\";\n\t\tbreak;\n\tcase EVHTTP_REQ_DELETE:\n\t\tmethod = \"DELETE\";\n\t\tbreak;\n\tcase EVHTTP_REQ_OPTIONS:\n\t\tmethod = \"OPTIONS\";\n\t\tbreak;\n\tcase EVHTTP_REQ_TRACE:\n\t\tmethod = \"TRACE\";\n\t\ttmp_flags &= ~EVHTTP_METHOD_HAS_BODY;\n\t\tbreak;\n\tcase EVHTTP_REQ_CONNECT:\n\t\tmethod = \"CONNECT\";\n\t\tbreak;\n\tcase EVHTTP_REQ_PATCH:\n\t\tmethod = \"PATCH\";\n\t\tbreak;\n\tcase EVHTTP_REQ_PROPFIND:\n\t\tmethod = \"PROPFIND\";\n\t\tbreak;\n\tcase EVHTTP_REQ_PROPPATCH:\n\t\tmethod = \"PROPPATCH\";\n\t\tbreak;\n\tcase EVHTTP_REQ_MKCOL:\n\t\tmethod = \"MKCOL\";\n\t\tbreak;\n\tcase EVHTTP_REQ_LOCK:\n\t\tmethod = \"LOCK\";\n\t\tbreak;\n\tcase EVHTTP_REQ_UNLOCK:\n\t\tmethod = \"UNLOCK\";\n\t\tbreak;\n\tcase EVHTTP_REQ_COPY:\n\t\tmethod = \"COPY\";\n\t\tbreak;\n\tcase EVHTTP_REQ_MOVE:\n\t\tmethod = \"MOVE\";\n\t\tbreak;\n\tdefault:\n\t\t/* setup the structure to allow for the cmp.\n\t\t *\n\t\t * if the cmp function is set, it has the ability to\n\t\t * modify method and flags. Other fields will be\n\t\t * ignored.\n\t\t *\n\t\t * NOTE: the flags returned are OR'd with the current\n\t\t *       flags.\n\t\t */\n\t\ttmp_flags = 0;\n\t\text_method.method = NULL;\n\t\text_method.type   = type;\n\t\text_method.flags  = tmp_flags;\n\n\t\tif (evcon->ext_method_cmp != NULL &&\n\t\t\tevcon->ext_method_cmp(&ext_method) == 0) {\n\n\t\t\tif (ext_method.type != type) {\n\t\t\t\tevent_debug((\"%s: callback modified type from %u to %u, not allowed\",\n\t\t\t\t            __func__, type, ext_method.type));\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\tmethod     = ext_method.method;\n\t\t\ttmp_flags |= ext_method.flags;\n\t\t}\n\n\t\tbreak;\n\t}\n\n\tevent_debug((\"%s: type=%04x => '%s' flags=%04x\",\n\t             __func__, (int)type, method, tmp_flags));\n\n\tif (flags)\n\t\t*flags = tmp_flags;\n\treturn (method);\n}\n\n/**\n * Determines if a response should have a body.\n * Follows the rules in RFC 2616 section 4.3.\n * @return 1 if the response MUST have a body; 0 if the response MUST NOT have\n *     a body.\n */\nstatic int\nevhttp_response_needs_body(struct evhttp_request *req)\n{\n\treturn (req->response_code != HTTP_NOCONTENT &&\n\t\treq->response_code != HTTP_NOTMODIFIED &&\n\t\t(req->response_code < 100 || req->response_code >= 200) &&\n\t\treq->type != EVHTTP_REQ_CONNECT &&\n\t\treq->type != EVHTTP_REQ_HEAD);\n}\n\n/** Helper: called after we've added some data to an evcon's bufferevent's\n * output buffer.  Sets the evconn's writing-is-done callback, and puts\n * the bufferevent into writing mode.\n */\nstatic void\nevhttp_write_buffer(struct evhttp_connection *evcon,\n    void (*cb)(struct evhttp_connection *, void *), void *arg)\n{\n\tevent_debug((\"%s: preparing to write buffer\\n\", __func__));\n\n\t/* Set call back */\n\tevcon->cb = cb;\n\tevcon->cb_arg = arg;\n\n\t/* Disable the read callback: we don't actually care about data;\n\t * we only care about close detection. (We don't disable reading --\n\t * EV_READ, since we *do* want to learn about any close events.) */\n\tbufferevent_setcb(evcon->bufev,\n\t    NULL, /*read*/\n\t    evhttp_write_cb,\n\t    evhttp_error_cb,\n\t    evcon);\n\n\tbufferevent_enable(evcon->bufev, EV_READ|EV_WRITE);\n}\n\nstatic void\nevhttp_send_continue_done(struct evhttp_connection *evcon, void *arg)\n{\n\tbufferevent_disable(evcon->bufev, EV_WRITE);\n}\n\nstatic void\nevhttp_send_continue(struct evhttp_connection *evcon,\n\t\t\tstruct evhttp_request *req)\n{\n\tbufferevent_enable(evcon->bufev, EV_WRITE);\n\tevbuffer_add_printf(bufferevent_get_output(evcon->bufev),\n\t\t\t\"HTTP/%d.%d 100 Continue\\r\\n\\r\\n\",\n\t\t\treq->major, req->minor);\n\tevcon->cb = evhttp_send_continue_done;\n\tevcon->cb_arg = NULL;\n\tbufferevent_setcb(evcon->bufev,\n\t    evhttp_read_cb,\n\t    evhttp_write_cb,\n\t    evhttp_error_cb,\n\t    evcon);\n}\n\n/** Helper: returns true iff evconn is in any connected state. */\nstatic int\nevhttp_connected(struct evhttp_connection *evcon)\n{\n\tswitch (evcon->state) {\n\tcase EVCON_DISCONNECTED:\n\tcase EVCON_CONNECTING:\n\t\treturn (0);\n\tcase EVCON_IDLE:\n\tcase EVCON_READING_FIRSTLINE:\n\tcase EVCON_READING_HEADERS:\n\tcase EVCON_READING_BODY:\n\tcase EVCON_READING_TRAILER:\n\tcase EVCON_WRITING:\n\tdefault:\n\t\treturn (1);\n\t}\n}\n\n/* Create the headers needed for an outgoing HTTP request, adds them to\n * the request's header list, and writes the request line to the\n * connection's output buffer.\n */\nstatic void\nevhttp_make_header_request(struct evhttp_connection *evcon,\n    struct evhttp_request *req)\n{\n\tconst char *method;\n\t/* NOTE: some version of GCC reports a warning that flags may be uninitialized, hence assignment */\n\tev_uint16_t flags = 0;\n\n\t/* Generate request line */\n\tif (!(method = evhttp_method_(evcon, req->type, &flags))) {\n\t\tmethod = \"NULL\";\n\t}\n\n\tevbuffer_add_printf(bufferevent_get_output(evcon->bufev),\n\t    \"%s %s HTTP/%d.%d\\r\\n\",\n\t    method, req->uri, req->major, req->minor);\n\n\t/* Add the content length on a request if missing\n\t * Always add it for POST and PUT requests as clients expect it */\n\tif ((flags & EVHTTP_METHOD_HAS_BODY) &&\n\t    (evbuffer_get_length(req->output_buffer) > 0 ||\n\t     req->type == EVHTTP_REQ_POST || req->type == EVHTTP_REQ_PUT) &&\n\t    evhttp_find_header(req->output_headers, \"Content-Length\") == NULL) {\n\t\tchar size[22];\n\t\tevutil_snprintf(size, sizeof(size), EV_SIZE_FMT,\n\t\t    EV_SIZE_ARG(evbuffer_get_length(req->output_buffer)));\n\t\tevhttp_add_header(req->output_headers, \"Content-Length\", size);\n\t}\n}\n\n/** Return true if the list of headers in 'headers', intepreted with respect\n * to flags, means that we should send a \"connection: close\" when the request\n * is done. */\nstatic int\nevhttp_is_connection_close(int flags, struct evkeyvalq* headers)\n{\n\tconst char *connection = evhttp_find_header(headers, \"Connection\");\n\treturn (connection != NULL && evutil_ascii_strcasecmp(connection, \"close\") == 0);\n}\n\nstatic int\nevhttp_is_request_connection_close(struct evhttp_request *req)\n{\n\tif (req->type == EVHTTP_REQ_CONNECT)\n\t\treturn 0;\n\n\treturn\n\t\tevhttp_is_connection_close(req->flags, req->input_headers) ||\n\t\tevhttp_is_connection_close(req->flags, req->output_headers);\n}\n\n/* Return true iff 'headers' contains 'Connection: keep-alive' */\nstatic int\nevhttp_is_connection_keepalive(struct evkeyvalq* headers)\n{\n\tconst char *connection = evhttp_find_header(headers, \"Connection\");\n\treturn (connection != NULL\n\t    && evutil_ascii_strncasecmp(connection, \"keep-alive\", 10) == 0);\n}\n\n/* Add a correct \"Date\" header to headers, unless it already has one. */\nstatic void\nevhttp_maybe_add_date_header(struct evkeyvalq *headers)\n{\n\tif (evhttp_find_header(headers, \"Date\") == NULL) {\n\t\tchar date[50];\n\t\tif ((signed)sizeof(date) > evutil_date_rfc1123(date, sizeof(date), NULL)) {\n\t\t\tevhttp_add_header(headers, \"Date\", date);\n\t\t}\n\t}\n}\n\n/* Add a \"Content-Length\" header with value 'content_length' to headers,\n * unless it already has a content-length or transfer-encoding header. */\nstatic void\nevhttp_maybe_add_content_length_header(struct evkeyvalq *headers,\n    size_t content_length)\n{\n\tif (evhttp_find_header(headers, \"Transfer-Encoding\") == NULL &&\n\t    evhttp_find_header(headers, \"Content-Length\") == NULL) {\n\t\tchar len[22];\n\t\tevutil_snprintf(len, sizeof(len), EV_SIZE_FMT,\n\t\t    EV_SIZE_ARG(content_length));\n\t\tevhttp_add_header(headers, \"Content-Length\", len);\n\t}\n}\n\n/*\n * Create the headers needed for an HTTP reply in req->output_headers,\n * and write the first HTTP response for req line to evcon.\n */\nstatic void\nevhttp_make_header_response(struct evhttp_connection *evcon,\n    struct evhttp_request *req)\n{\n\tint is_keepalive = evhttp_is_connection_keepalive(req->input_headers);\n\tint need_body = evhttp_response_needs_body(req);\n\n\tevbuffer_add_printf(bufferevent_get_output(evcon->bufev),\n\t    \"HTTP/%d.%d %d %s\\r\\n\",\n\t    req->major, req->minor, req->response_code,\n\t    req->response_code_line);\n\n\tif (req->major == 1) {\n\t\tif (req->minor >= 1)\n\t\t\tevhttp_maybe_add_date_header(req->output_headers);\n\n\t\t/*\n\t\t * if the protocol is 1.0; and the connection was keep-alive\n\t\t * we need to add a keep-alive header, too.\n\t\t */\n\t\tif (req->minor == 0 && is_keepalive)\n\t\t\tevhttp_add_header(req->output_headers,\n\t\t\t    \"Connection\", \"keep-alive\");\n\n\t\tif ((req->minor >= 1 || is_keepalive) && need_body) {\n\t\t\t/*\n\t\t\t * we need to add the content length if the\n\t\t\t * user did not give it, this is required for\n\t\t\t * persistent connections to work.\n\t\t\t */\n\t\t\tevhttp_maybe_add_content_length_header(\n\t\t\t\treq->output_headers,\n\t\t\t\tevbuffer_get_length(req->output_buffer));\n\t\t}\n\t}\n\n\t/* Potentially add headers for unidentified content. */\n\tif (need_body) {\n\t\tif (evhttp_find_header(req->output_headers,\n\t\t\t\"Content-Type\") == NULL\n\t\t    && evcon->http_server->default_content_type) {\n\t\t\tevhttp_add_header(req->output_headers,\n\t\t\t    \"Content-Type\",\n\t\t\t    evcon->http_server->default_content_type);\n\t\t}\n\t}\n\n\t/* if the request asked for a close, we send a close, too */\n\tif (evhttp_is_connection_close(req->flags, req->input_headers)) {\n\t\tevhttp_remove_header(req->output_headers, \"Connection\");\n\t\tevhttp_add_header(req->output_headers, \"Connection\", \"close\");\n\t}\n}\n\nenum expect { NO, CONTINUE, OTHER };\nstatic enum expect evhttp_have_expect(struct evhttp_request *req, int input)\n{\n\tconst char *expect;\n\tstruct evkeyvalq *h = input ? req->input_headers : req->output_headers;\n\n\tif (!(req->kind == EVHTTP_REQUEST) || !REQ_VERSION_ATLEAST(req, 1, 1))\n\t\treturn NO;\n\n\texpect = evhttp_find_header(h, \"Expect\");\n\tif (!expect)\n\t\treturn NO;\n\n\treturn !evutil_ascii_strcasecmp(expect, \"100-continue\") ? CONTINUE : OTHER;\n}\n\n\n/** Generate all headers appropriate for sending the http request in req (or\n * the response, if we're sending a response), and write them to evcon's\n * bufferevent. Also writes all data from req->output_buffer */\nstatic void\nevhttp_make_header(struct evhttp_connection *evcon, struct evhttp_request *req)\n{\n\tstruct evkeyval *header;\n\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\n\t/*\n\t * Depending if this is a HTTP request or response, we might need to\n\t * add some new headers or remove existing headers.\n\t */\n\tif (req->kind == EVHTTP_REQUEST) {\n\t\tevhttp_make_header_request(evcon, req);\n\t} else {\n\t\tevhttp_make_header_response(evcon, req);\n\t}\n\n\tTAILQ_FOREACH(header, req->output_headers, next) {\n\t\tevbuffer_add_printf(output, \"%s: %s\\r\\n\",\n\t\t    header->key, header->value);\n\t}\n\tevbuffer_add(output, \"\\r\\n\", 2);\n\n\tif (evhttp_have_expect(req, 0) != CONTINUE &&\n\t\tevbuffer_get_length(req->output_buffer)) {\n\t\t/*\n\t\t * For a request, we add the POST data, for a reply, this\n\t\t * is the regular data.\n\t\t */\n\t\tevbuffer_add_buffer(output, req->output_buffer);\n\t}\n}\n\nvoid\nevhttp_connection_set_max_headers_size(struct evhttp_connection *evcon,\n    ev_ssize_t new_max_headers_size)\n{\n\tif (new_max_headers_size<0)\n\t\tevcon->max_headers_size = EV_SIZE_MAX;\n\telse\n\t\tevcon->max_headers_size = new_max_headers_size;\n}\nvoid\nevhttp_connection_set_max_body_size(struct evhttp_connection* evcon,\n    ev_ssize_t new_max_body_size)\n{\n\tif (new_max_body_size<0)\n\t\tevcon->max_body_size = EV_UINT64_MAX;\n\telse\n\t\tevcon->max_body_size = new_max_body_size;\n}\n\nstatic int\nevhttp_connection_incoming_fail(struct evhttp_request *req,\n    enum evhttp_request_error error)\n{\n\tswitch (error) {\n\t\tcase EVREQ_HTTP_DATA_TOO_LONG:\n\t\t\treq->response_code = HTTP_ENTITYTOOLARGE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treq->response_code = HTTP_BADREQUEST;\n\t}\n\n\tswitch (error) {\n\tcase EVREQ_HTTP_TIMEOUT:\n\tcase EVREQ_HTTP_EOF:\n\t\t/*\n\t\t * these are cases in which we probably should just\n\t\t * close the connection and not send a reply.  this\n\t\t * case may happen when a browser keeps a persistent\n\t\t * connection open and we timeout on the read.  when\n\t\t * the request is still being used for sending, we\n\t\t * need to disassociate it from the connection here.\n\t\t */\n\t\tif (!req->userdone) {\n\t\t\t/* remove it so that it will not be freed */\n\t\t\tTAILQ_REMOVE(&req->evcon->requests, req, next);\n\t\t\t/* indicate that this request no longer has a\n\t\t\t * connection object\n\t\t\t */\n\t\t\treq->evcon = NULL;\n\t\t}\n\t\treturn (-1);\n\tcase EVREQ_HTTP_INVALID_HEADER:\n\tcase EVREQ_HTTP_BUFFER_ERROR:\n\tcase EVREQ_HTTP_REQUEST_CANCEL:\n\tcase EVREQ_HTTP_DATA_TOO_LONG:\n\tdefault:\t/* xxx: probably should just error on default */\n\t\t/* the callback looks at the uri to determine errors */\n\t\tif (req->uri) {\n\t\t\tmm_free(req->uri);\n\t\t\treq->uri = NULL;\n\t\t}\n\t\tif (req->uri_elems) {\n\t\t\tevhttp_uri_free(req->uri_elems);\n\t\t\treq->uri_elems = NULL;\n\t\t}\n\n\t\t/*\n\t\t * the callback needs to send a reply, once the reply has\n\t\t * been send, the connection should get freed.\n\t\t */\n\t\t(*req->cb)(req, req->cb_arg);\n\t}\n\n\treturn (0);\n}\n\n/* Free connection ownership of which can be acquired by user using\n * evhttp_request_own(). */\nstatic inline void\nevhttp_request_free_auto(struct evhttp_request *req)\n{\n\tif (!(req->flags & EVHTTP_USER_OWNED))\n\t\tevhttp_request_free(req);\n}\n\nstatic void\nevhttp_request_free_(struct evhttp_connection *evcon, struct evhttp_request *req)\n{\n\tTAILQ_REMOVE(&evcon->requests, req, next);\n\tevhttp_request_free_auto(req);\n}\n\nstatic void\nevhttp_set_timeout_tv_(struct timeval *tv, const struct timeval *timeout, int def)\n{\n\tif (timeout == NULL && def != -1) {\n\t\ttv->tv_sec = def;\n\t\ttv->tv_usec = 0;\n\t\treturn;\n\t}\n\n\tif (timeout) {\n\t\t*tv = *timeout;\n\t} else {\n\t\tevutil_timerclear(tv);\n\t}\n}\nstatic void\nevhttp_set_timeout_(struct timeval *tv, int timeout, int def)\n{\n\tif (timeout == -1) {\n\t\ttimeout = def;\n\t}\n\n\tif (timeout == -1) {\n\t\tevutil_timerclear(tv);\n\t} else {\n\t\tstruct timeval timeout_tv;\n\t\ttimeout_tv.tv_sec = timeout;\n\t\ttimeout_tv.tv_usec = 0;\n\t\t*tv = timeout_tv;\n\t}\n}\n\n/* Called when evcon has experienced a (non-recoverable? -NM) error, as\n * given in error. If it's an outgoing connection, reset the connection,\n * retry any pending requests, and inform the user.  If it's incoming,\n * delegates to evhttp_connection_incoming_fail(). */\nvoid\nevhttp_connection_fail_(struct evhttp_connection *evcon,\n    enum evhttp_request_error error)\n{\n\tconst int errsave = EVUTIL_SOCKET_ERROR();\n\tstruct evhttp_request* req = TAILQ_FIRST(&evcon->requests);\n\tvoid (*cb)(struct evhttp_request *, void *);\n\tvoid *cb_arg;\n\tvoid (*error_cb)(enum evhttp_request_error, void *);\n\tvoid *error_cb_arg;\n\tEVUTIL_ASSERT(req != NULL);\n\n\tbufferevent_disable(evcon->bufev, EV_READ|EV_WRITE);\n\n\terror_cb = req->error_cb;\n\terror_cb_arg = req->cb_arg;\n\n\tif (evcon->flags & EVHTTP_CON_INCOMING) {\n\t\t/*\n\t\t * for incoming requests, there are two different\n\t\t * failure cases.  it's either a network level error\n\t\t * or an http layer error. for problems on the network\n\t\t * layer like timeouts we just drop the connections.\n\t\t * For HTTP problems, we might have to send back a\n\t\t * reply before the connection can be freed.\n\t\t */\n\t\tif (evhttp_connection_incoming_fail(req, error) == -1)\n\t\t\tevhttp_connection_free(evcon);\n\t\tif (error_cb != NULL)\n\t\t\terror_cb(error, error_cb_arg);\n\t\treturn;\n\t}\n\n\t/* when the request was canceled, the callback is not executed */\n\tif (error != EVREQ_HTTP_REQUEST_CANCEL) {\n\t\t/* save the callback for later; the cb might free our object */\n\t\tcb = req->cb;\n\t\tcb_arg = req->cb_arg;\n\t} else {\n\t\tcb = NULL;\n\t\tcb_arg = NULL;\n\t}\n\n\t/* do not fail all requests; the next request is going to get\n\t * send over a new connection.   when a user cancels a request,\n\t * all other pending requests should be processed as normal\n\t */\n\tevhttp_request_free_(evcon, req);\n\n\t/* reset the connection */\n\tevhttp_connection_reset_(evcon, 1);\n\n\t/* We are trying the next request that was queued on us */\n\tif (TAILQ_FIRST(&evcon->requests) != NULL)\n\t\tevhttp_connection_connect_(evcon);\n\telse\n\t\tif ((evcon->flags & EVHTTP_CON_OUTGOING) &&\n\t\t    (evcon->flags & EVHTTP_CON_AUTOFREE)) {\n\t\t\tevhttp_connection_free(evcon);\n\t\t}\n\n\t/* The call to evhttp_connection_reset_ overwrote errno.\n\t * Let's restore the original errno, so that the user's\n\t * callback can have a better idea of what the error was.\n\t */\n\tEVUTIL_SET_SOCKET_ERROR(errsave);\n\n\t/* inform the user */\n\tif (error_cb != NULL)\n\t\terror_cb(error, error_cb_arg);\n\tif (cb != NULL)\n\t\t(*cb)(NULL, cb_arg);\n}\n\n/* Bufferevent callback: invoked when any data has been written from an\n * http connection's bufferevent */\nstatic void\nevhttp_write_cb(struct bufferevent *bufev, void *arg)\n{\n\tstruct evhttp_connection *evcon = arg;\n\n\t/* Activate our call back */\n\tif (evcon->cb != NULL)\n\t\t(*evcon->cb)(evcon, evcon->cb_arg);\n}\n\n/**\n * Advance the connection state.\n * - If this is an outgoing connection, we've just processed the response;\n *   idle or close the connection.\n * - If this is an incoming connection, we've just processed the request;\n *   respond.\n */\nstatic void\nevhttp_connection_done(struct evhttp_connection *evcon)\n{\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\tint con_outgoing = evcon->flags & EVHTTP_CON_OUTGOING;\n\tint free_evcon = 0;\n\n\tif (con_outgoing) {\n\t\t/* idle or close the connection */\n\t\tint need_close = evhttp_is_request_connection_close(req);\n\t\tTAILQ_REMOVE(&evcon->requests, req, next);\n\t\treq->evcon = NULL;\n\n\t\tevcon->state = EVCON_IDLE;\n\n\t\t/* check if we got asked to close the connection */\n\t\tif (need_close)\n\t\t\tevhttp_connection_reset_(evcon, 1);\n\n\t\tif (TAILQ_FIRST(&evcon->requests) != NULL) {\n\t\t\t/*\n\t\t\t * We have more requests; reset the connection\n\t\t\t * and deal with the next request.\n\t\t\t */\n\t\t\tif (!evhttp_connected(evcon))\n\t\t\t\tevhttp_connection_connect_(evcon);\n\t\t\telse\n\t\t\t\tevhttp_request_dispatch(evcon);\n\t\t} else if (!need_close) {\n\t\t\t/*\n\t\t\t * The connection is going to be persistent, but we\n\t\t\t * need to detect if the other side closes it.\n\t\t\t */\n\t\t\tevhttp_connection_start_detectclose(evcon);\n\t\t} else if ((evcon->flags & EVHTTP_CON_AUTOFREE)) {\n\t\t\t/*\n\t\t\t * If we have no more requests that need completion\n\t\t\t * and we're not waiting for the connection to close\n\t\t\t */\n\t\t\t free_evcon = 1;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * incoming connection - we need to leave the request on the\n\t\t * connection so that we can reply to it.\n\t\t */\n\t\tevcon->state = EVCON_WRITING;\n\t}\n\n\t/* notify the user of the request */\n\t(*req->cb)(req, req->cb_arg);\n\n\t/* if this was an outgoing request, we own and it's done. so free it. */\n\tif (con_outgoing) {\n\t\tevhttp_request_free_auto(req);\n\t}\n\n\t/* If this was the last request of an outgoing connection and we're\n\t * not waiting to receive a connection close event and we want to\n\t * automatically free the connection. We check to ensure our request\n\t * list is empty one last time just in case our callback added a\n\t * new request.\n\t */\n\tif (free_evcon && TAILQ_FIRST(&evcon->requests) == NULL) {\n\t\tevhttp_connection_free(evcon);\n\t}\n}\n\n/*\n * Handles reading from a chunked request.\n *   return ALL_DATA_READ:\n *     all data has been read\n *   return MORE_DATA_EXPECTED:\n *     more data is expected\n *   return DATA_CORRUPTED:\n *     data is corrupted\n *   return REQUEST_CANCELED:\n *     request was canceled by the user calling evhttp_cancel_request\n *   return DATA_TOO_LONG:\n *     ran over the maximum limit\n */\n\nstatic enum message_read_status\nevhttp_handle_chunked_read(struct evhttp_request *req, struct evbuffer *buf)\n{\n\tif (req == NULL || buf == NULL) {\n\t    return DATA_CORRUPTED;\n\t}\n\n\twhile (1) {\n\t\tsize_t buflen;\n\n\t\tif ((buflen = evbuffer_get_length(buf)) == 0) {\n\t\t\tbreak;\n\t\t}\n\n\t\t/* evbuffer_get_length returns size_t, but len variable is ssize_t,\n\t\t * check for overflow conditions */\n\t\tif (buflen > EV_SSIZE_MAX) {\n\t\t\treturn DATA_CORRUPTED;\n\t\t}\n\n\t\tif (req->ntoread < 0) {\n\t\t\t/* Read chunk size */\n\t\t\tev_int64_t ntoread;\n\t\t\tchar *p = evbuffer_readln(buf, NULL, EVBUFFER_EOL_CRLF);\n\t\t\tchar *endp;\n\t\t\tint error;\n\t\t\tsize_t len_p;\n\t\t\tif (p == NULL)\n\t\t\t\tbreak;\n\t\t\tlen_p = strlen(p);\n\t\t\t/* the last chunk is on a new line? */\n\t\t\tif (len_p == 0) {\n\t\t\t\tmm_free(p);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* strtoll(,,16) lets through whitespace, 0x, +, and - prefixes, but HTTP doesn't. */\n\t\t\terror = isspace(p[0]) ||\n\t\t\t\tp[0] == '-' ||\n\t\t\t\tp[0] == '+' ||\n\t\t\t\t(len_p >= 2 && p[0] == '0' && (p[1] == 'x' || p[1] == 'X'));\n\t\t\tif (error) {\n\t\t\t\tmm_free(p);\n\t\t\t\treturn (DATA_CORRUPTED);\n\t\t\t}\n\t\t\tntoread = evutil_strtoll(p, &endp, 16);\n\t\t\terror = (*p == '\\0' ||\n\t\t\t    (*endp != '\\0' && *endp != ' ') ||\n\t\t\t    ntoread < 0);\n\t\t\tmm_free(p);\n\t\t\tif (error) {\n\t\t\t\t/* could not get chunk size */\n\t\t\t\treturn (DATA_CORRUPTED);\n\t\t\t}\n\n\t\t\t/* ntoread is signed int64, body_size is unsigned size_t, check for under/overflow conditions */\n\t\t\tif ((ev_uint64_t)ntoread > EV_SIZE_MAX - req->body_size) {\n\t\t\t    return DATA_CORRUPTED;\n\t\t\t}\n\n\t\t\tif (req->body_size + (size_t)ntoread > req->evcon->max_body_size) {\n\t\t\t\t/* failed body length test */\n\t\t\t\tevent_debug((\"Request body is too long\"));\n\t\t\t\treturn (DATA_TOO_LONG);\n\t\t\t}\n\n\t\t\treq->body_size += (size_t)ntoread;\n\t\t\treq->ntoread = ntoread;\n\t\t\tif (req->ntoread == 0) {\n\t\t\t\t/* Last chunk */\n\t\t\t\treturn (ALL_DATA_READ);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* req->ntoread is signed int64, len is ssize_t, based on arch,\n\t\t * ssize_t could only be 32b, check for these conditions */\n\t\tif (req->ntoread > EV_SSIZE_MAX) {\n\t\t\treturn DATA_CORRUPTED;\n\t\t}\n\n\t\t/* don't have enough to complete a chunk; wait for more */\n\t\tif (req->ntoread > 0 && buflen < (ev_uint64_t)req->ntoread)\n\t\t\treturn (MORE_DATA_EXPECTED);\n\n\t\t/* Completed chunk */\n\t\tevbuffer_remove_buffer(buf, req->input_buffer, (size_t)req->ntoread);\n\t\treq->ntoread = -1;\n\t\tif (req->chunk_cb != NULL) {\n\t\t\treq->flags |= EVHTTP_REQ_DEFER_FREE;\n\t\t\t(*req->chunk_cb)(req, req->cb_arg);\n\t\t\tevbuffer_drain(req->input_buffer,\n\t\t\t    evbuffer_get_length(req->input_buffer));\n\t\t\treq->flags &= ~EVHTTP_REQ_DEFER_FREE;\n\t\t\tif ((req->flags & EVHTTP_REQ_NEEDS_FREE) != 0) {\n\t\t\t\treturn (REQUEST_CANCELED);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn (MORE_DATA_EXPECTED);\n}\n\nstatic void\nevhttp_read_trailer(struct evhttp_connection *evcon, struct evhttp_request *req)\n{\n\tstruct evbuffer *buf = bufferevent_get_input(evcon->bufev);\n\n\tswitch (evhttp_parse_headers_(req, buf)) {\n\tcase DATA_CORRUPTED:\n\tcase DATA_TOO_LONG:\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_DATA_TOO_LONG);\n\t\tbreak;\n\tcase ALL_DATA_READ:\n\t\tbufferevent_disable(evcon->bufev, EV_READ);\n\t\tevhttp_connection_done(evcon);\n\t\tbreak;\n\tcase MORE_DATA_EXPECTED:\n\tcase REQUEST_CANCELED: /* ??? */\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void\nevhttp_lingering_close(struct evhttp_connection *evcon,\n\tstruct evhttp_request *req)\n{\n\tstruct evbuffer *buf = bufferevent_get_input(evcon->bufev);\n\n\tsize_t n = evbuffer_get_length(buf);\n\tif (n > (size_t) req->ntoread)\n\t\tn = (size_t) req->ntoread;\n\treq->ntoread -= n;\n\treq->body_size += n;\n\n\tevent_debug((\"Request body is too long, left \" EV_I64_FMT,\n\t\tEV_I64_ARG(req->ntoread)));\n\n\tevbuffer_drain(buf, n);\n\tif (!req->ntoread)\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_DATA_TOO_LONG);\n}\nstatic void\nevhttp_lingering_fail(struct evhttp_connection *evcon,\n\tstruct evhttp_request *req)\n{\n\tif (evcon->flags & EVHTTP_CON_LINGERING_CLOSE)\n\t\tevhttp_lingering_close(evcon, req);\n\telse\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_DATA_TOO_LONG);\n}\n\nstatic void\nevhttp_read_body(struct evhttp_connection *evcon, struct evhttp_request *req)\n{\n\tstruct evbuffer *buf = bufferevent_get_input(evcon->bufev);\n\n\tif (req->chunked) {\n\t\tswitch (evhttp_handle_chunked_read(req, buf)) {\n\t\tcase ALL_DATA_READ:\n\t\t\t/* finished last chunk */\n\t\t\tevcon->state = EVCON_READING_TRAILER;\n\t\t\tevhttp_read_trailer(evcon, req);\n\t\t\treturn;\n\t\tcase DATA_CORRUPTED:\n\t\t\t/* corrupted data */\n\t\t\tevhttp_connection_fail_(evcon,\n\t\t\t    EVREQ_HTTP_INVALID_HEADER);\n\t\t\treturn;\n\t\tcase DATA_TOO_LONG:\n\t\t\tevhttp_connection_fail_(evcon,\n\t\t\t    EVREQ_HTTP_DATA_TOO_LONG);\n\t\t\treturn;\n\t\tcase REQUEST_CANCELED:\n\t\t\t/* request canceled */\n\t\t\tevhttp_request_free_auto(req);\n\t\t\treturn;\n\t\tcase MORE_DATA_EXPECTED:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t} else if (req->ntoread < 0) {\n\t\t/* Read until connection close. */\n\t\tif ((size_t)(req->body_size + evbuffer_get_length(buf)) < req->body_size) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\t\treturn;\n\t\t}\n\n\t\treq->body_size += evbuffer_get_length(buf);\n\t\tevbuffer_add_buffer(req->input_buffer, buf);\n\t} else if (req->chunk_cb != NULL || evbuffer_get_length(buf) >= (size_t)req->ntoread) {\n\t\t/* XXX: the above get_length comparison has to be fixed for overflow conditions! */\n\t\t/* We've postponed moving the data until now, but we're\n\t\t * about to use it. */\n\t\tsize_t n = evbuffer_get_length(buf);\n\n\t\tif (n > (size_t) req->ntoread)\n\t\t\tn = (size_t) req->ntoread;\n\t\treq->ntoread -= n;\n\t\treq->body_size += n;\n\t\tevbuffer_remove_buffer(buf, req->input_buffer, n);\n\t}\n\n\tif (req->body_size > req->evcon->max_body_size ||\n\t    (!req->chunked && req->ntoread >= 0 &&\n\t\t(size_t)req->ntoread > req->evcon->max_body_size)) {\n\t\t/* XXX: The above casted comparison must checked for overflow */\n\t\t/* failed body length test */\n\n\t\tevhttp_lingering_fail(evcon, req);\n\t\treturn;\n\t}\n\n\tif (evbuffer_get_length(req->input_buffer) > 0 && req->chunk_cb != NULL) {\n\t\treq->flags |= EVHTTP_REQ_DEFER_FREE;\n\t\t(*req->chunk_cb)(req, req->cb_arg);\n\t\treq->flags &= ~EVHTTP_REQ_DEFER_FREE;\n\t\tevbuffer_drain(req->input_buffer,\n\t\t    evbuffer_get_length(req->input_buffer));\n\t\tif ((req->flags & EVHTTP_REQ_NEEDS_FREE) != 0) {\n\t\t\tevhttp_request_free_auto(req);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!req->ntoread) {\n\t\tbufferevent_disable(evcon->bufev, EV_READ);\n\t\t/* Completed content length */\n\t\tevhttp_connection_done(evcon);\n\t\treturn;\n\t}\n}\n\n#define get_deferred_queue(evcon)\t\t\\\n\t((evcon)->base)\n\n/*\n * Gets called when more data becomes available\n */\n\nstatic void\nevhttp_read_cb(struct bufferevent *bufev, void *arg)\n{\n\tstruct evhttp_connection *evcon = arg;\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\n\t/* Cancel if it's pending. */\n\tevent_deferred_cb_cancel_(get_deferred_queue(evcon),\n\t    &evcon->read_more_deferred_cb);\n\n\tswitch (evcon->state) {\n\tcase EVCON_READING_FIRSTLINE:\n\t\tevhttp_read_firstline(evcon, req);\n\t\t/* note the request may have been freed in\n\t\t * evhttp_read_body */\n\t\tbreak;\n\tcase EVCON_READING_HEADERS:\n\t\tevhttp_read_header(evcon, req);\n\t\t/* note the request may have been freed in\n\t\t * evhttp_read_body */\n\t\tbreak;\n\tcase EVCON_READING_BODY:\n\t\tevhttp_read_body(evcon, req);\n\t\t/* note the request may have been freed in\n\t\t * evhttp_read_body */\n\t\tbreak;\n\tcase EVCON_READING_TRAILER:\n\t\tevhttp_read_trailer(evcon, req);\n\t\tbreak;\n\tcase EVCON_IDLE:\n\t\t{\n#ifdef USE_DEBUG\n\t\t\tstruct evbuffer *input;\n\t\t\tsize_t total_len;\n\n\t\t\tinput = bufferevent_get_input(evcon->bufev);\n\t\t\ttotal_len = evbuffer_get_length(input);\n\t\t\tevent_debug((\"%s: read \"EV_SIZE_FMT\n\t\t\t\t\" bytes in EVCON_IDLE state,\"\n\t\t\t\t\" resetting connection\",\n\t\t\t\t__func__, EV_SIZE_ARG(total_len)));\n#endif\n\n\t\t\tevhttp_connection_reset_(evcon, 1);\n\t\t}\n\t\tbreak;\n\tcase EVCON_DISCONNECTED:\n\tcase EVCON_CONNECTING:\n\tcase EVCON_WRITING:\n\tdefault:\n\t\tevent_errx(1, \"%s: illegal connection state %d\",\n\t\t\t   __func__, evcon->state);\n\t}\n}\n\nstatic void\nevhttp_deferred_read_cb(struct event_callback *cb, void *data)\n{\n\tstruct evhttp_connection *evcon = data;\n\tstruct bufferevent *bev = evcon->bufev;\n\tif (bev->readcb)\n\t\t(bev->readcb)(evcon->bufev, evcon);\n}\n\nstatic void\nevhttp_write_connectioncb(struct evhttp_connection *evcon, void *arg)\n{\n\t/* This is after writing the request to the server */\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\tEVUTIL_ASSERT(req != NULL);\n\n\tEVUTIL_ASSERT(evcon->state == EVCON_WRITING);\n\n\t/* We need to wait until we've written all of our output data before we can\n\t * continue */\n\tif (evbuffer_get_length(output) > 0)\n\t\treturn;\n\n\t/* We are done writing our header and are now expecting the response */\n\treq->kind = EVHTTP_RESPONSE;\n\n\tevhttp_start_read_(evcon);\n}\n\n/*\n * Clean up a connection object\n */\n\nvoid\nevhttp_connection_free(struct evhttp_connection *evcon)\n{\n\tstruct evhttp_request *req;\n\n\t/* notify interested parties that this connection is going down */\n\tif (evhttp_connected(evcon) && evcon->closecb != NULL)\n\t\t(*evcon->closecb)(evcon, evcon->closecb_arg);\n\n\t/* remove all requests that might be queued on this\n\t * connection.  for server connections, this should be empty.\n\t * because it gets dequeued either in evhttp_connection_done or\n\t * evhttp_connection_fail_.\n\t */\n\twhile ((req = TAILQ_FIRST(&evcon->requests)) != NULL) {\n\t\tevhttp_request_free_(evcon, req);\n\t}\n\n\tif (evcon->http_server != NULL) {\n\t\tstruct evhttp *http = evcon->http_server;\n\t\tTAILQ_REMOVE(&http->connections, evcon, next);\n\t\thttp->connection_cnt--;\n\t}\n\n\tif (event_initialized(&evcon->retry_ev)) {\n\t\tevent_del(&evcon->retry_ev);\n\t\tevent_debug_unassign(&evcon->retry_ev);\n\t}\n\n\tevent_deferred_cb_cancel_(get_deferred_queue(evcon),\n\t    &evcon->read_more_deferred_cb);\n\n\tif (evcon->bufev != NULL) {\n\t\tbufferevent_free(evcon->bufev);\n\t}\n\n\tif (evcon->bind_address != NULL)\n\t\tmm_free(evcon->bind_address);\n\n\tif (evcon->address != NULL)\n\t\tmm_free(evcon->address);\n\n#ifndef _WIN32\n\tif (evcon->unixsocket != NULL)\n\t\tmm_free(evcon->unixsocket);\n#endif\n\n\tmm_free(evcon);\n}\n\nvoid\nevhttp_connection_free_on_completion(struct evhttp_connection *evcon) {\n\tevcon->flags |= EVHTTP_CON_AUTOFREE;\n}\n\nvoid\nevhttp_connection_set_local_address(struct evhttp_connection *evcon,\n    const char *address)\n{\n\tEVUTIL_ASSERT(evcon->state == EVCON_DISCONNECTED);\n\tif (evcon->bind_address)\n\t\tmm_free(evcon->bind_address);\n\tif ((evcon->bind_address = mm_strdup(address)) == NULL)\n\t\tevent_warn(\"%s: strdup\", __func__);\n}\n\nvoid\nevhttp_connection_set_local_port(struct evhttp_connection *evcon,\n    ev_uint16_t port)\n{\n\tEVUTIL_ASSERT(evcon->state == EVCON_DISCONNECTED);\n\tevcon->bind_port = port;\n}\n\nstatic void\nevhttp_request_dispatch(struct evhttp_connection* evcon)\n{\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\n\t/* this should not usually happy but it's possible */\n\tif (req == NULL)\n\t\treturn;\n\n\tEVUTIL_ASSERT(req->kind == EVHTTP_REQUEST);\n\n\t/* delete possible close detection events */\n\tevhttp_connection_stop_detectclose(evcon);\n\n\t/* we assume that the connection is connected already */\n\tEVUTIL_ASSERT(evcon->state == EVCON_IDLE);\n\n\tevcon->state = EVCON_WRITING;\n\n\t/* Create the header from the store arguments */\n\tevhttp_make_header(evcon, req);\n\n\tevhttp_write_buffer(evcon, evhttp_write_connectioncb, NULL);\n}\n\n/** Hard-reset our connection state\n *\n * This will:\n * - reset fd\n * - clears out buffers\n * - call closecb\n */\nstatic void\nevhttp_connection_reset_hard_(struct evhttp_connection *evcon)\n{\n\tstruct evbuffer *tmp;\n\tint err;\n\n\t/* XXXX This is not actually an optimal fix.  Instead we ought to have\n\t   an API for \"stop connecting\", or use bufferevent_replacefd to turn off\n\t   connecting.  But for Libevent 2.0, this seems like a minimal change\n\t   least likely to disrupt the rest of the bufferevent and http code.\n\n\t   Why is this here?  If the fd is set in the bufferevent, and the\n\t   bufferevent is connecting, then you can't actually stop the\n\t   bufferevent from trying to connect with bufferevent_disable().  The\n\t   connect will never trigger, since we close the fd, but the timeout\n\t   might.  That caused an assertion failure in evhttp_connection_fail_.\n\t*/\n\tbufferevent_disable_hard_(evcon->bufev, EV_READ|EV_WRITE);\n\n\t/* inform interested parties about connection close */\n\tif (evhttp_connected(evcon) && evcon->closecb != NULL)\n\t\t(*evcon->closecb)(evcon, evcon->closecb_arg);\n\n\t/** FIXME: manipulating with fd is unwanted */\n\terr = bufferevent_replacefd(evcon->bufev, -1);\n\tEVUTIL_ASSERT(!err && \"setfd\");\n\n\t/* we need to clean up any buffered data */\n\ttmp = bufferevent_get_output(evcon->bufev);\n\terr = evbuffer_drain(tmp, -1);\n\tEVUTIL_ASSERT(!err && \"drain output\");\n\ttmp = bufferevent_get_input(evcon->bufev);\n\terr = evbuffer_drain(tmp, -1);\n\tEVUTIL_ASSERT(!err && \"drain input\");\n}\n\n/** Reset our connection state\n *\n * This will:\n * - disables reading/writing\n * - puts us in DISCONNECTED state\n *\n * @param hard - hard reset will (@see evhttp_connection_reset_hard_())\n */\nvoid\nevhttp_connection_reset_(struct evhttp_connection *evcon, int hard)\n{\n\tbufferevent_setcb(evcon->bufev, NULL, NULL, NULL, NULL);\n\n\tif (hard) {\n\t\tevhttp_connection_reset_hard_(evcon);\n\t}\n\n\tevcon->flags &= ~EVHTTP_CON_READING_ERROR;\n\tevcon->state = EVCON_DISCONNECTED;\n}\n\nstatic void\nevhttp_connection_start_detectclose(struct evhttp_connection *evcon)\n{\n\tevcon->flags |= EVHTTP_CON_CLOSEDETECT;\n\tbufferevent_enable(evcon->bufev, EV_READ);\n}\n\nstatic void\nevhttp_connection_stop_detectclose(struct evhttp_connection *evcon)\n{\n\tevcon->flags &= ~EVHTTP_CON_CLOSEDETECT;\n\tbufferevent_disable(evcon->bufev, EV_READ);\n}\n\nstatic void\nevhttp_connection_retry(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct evhttp_connection *evcon = arg;\n\n\tevcon->state = EVCON_DISCONNECTED;\n\tevhttp_connection_connect_(evcon);\n}\n\nstatic void\nevhttp_connection_cb_cleanup(struct evhttp_connection *evcon)\n{\n\tstruct evcon_requestq requests;\n\tEVUTIL_ASSERT(evcon->flags & EVHTTP_CON_OUTGOING);\n\n\tevhttp_connection_reset_(evcon, 1);\n\n\tif (evcon->retry_max < 0 || evcon->retry_cnt < evcon->retry_max) {\n\t\tstruct timeval tv_retry = evcon->initial_retry_timeout;\n\t\tint i;\n\t\tevtimer_assign(&evcon->retry_ev, evcon->base, evhttp_connection_retry, evcon);\n\t\t/* XXXX handle failure from evhttp_add_event */\n\t\tfor (i=0; i < evcon->retry_cnt; ++i) {\n\t\t\ttv_retry.tv_usec *= 2;\n\t\t\tif (tv_retry.tv_usec > 1000000) {\n\t\t\t\ttv_retry.tv_usec -= 1000000;\n\t\t\t\ttv_retry.tv_sec += 1;\n\t\t\t}\n\t\t\ttv_retry.tv_sec *= 2;\n\t\t\tif (tv_retry.tv_sec > 3600) {\n\t\t\t\ttv_retry.tv_sec = 3600;\n\t\t\t\ttv_retry.tv_usec = 0;\n\t\t\t}\n\t\t}\n\t\tevent_add(&evcon->retry_ev, &tv_retry);\n\t\tevcon->retry_cnt++;\n\t\treturn;\n\t}\n\n\t/*\n\t * User callback can do evhttp_make_request() on the same\n\t * evcon so new request will be added to evcon->requests.  To\n\t * avoid freeing it prematurely we iterate over the copy of\n\t * the queue.\n\t */\n\tTAILQ_INIT(&requests);\n\twhile (TAILQ_FIRST(&evcon->requests) != NULL) {\n\t\tstruct evhttp_request *request = TAILQ_FIRST(&evcon->requests);\n\t\tTAILQ_REMOVE(&evcon->requests, request, next);\n\t\tTAILQ_INSERT_TAIL(&requests, request, next);\n\t}\n\n\t/* for now, we just signal all requests by executing their callbacks */\n\twhile (TAILQ_FIRST(&requests) != NULL) {\n\t\tstruct evhttp_request *request = TAILQ_FIRST(&requests);\n\t\tTAILQ_REMOVE(&requests, request, next);\n\t\trequest->evcon = NULL;\n\n\t\t/* we might want to set an error here */\n\t\trequest->cb(request, request->cb_arg);\n\t\tevhttp_request_free_auto(request);\n\t}\n\n\tif (TAILQ_FIRST(&evcon->requests) == NULL\n\t  && (evcon->flags & EVHTTP_CON_AUTOFREE)) {\n\t\tevhttp_connection_free(evcon);\n\t}\n\n}\n\nstatic void\nevhttp_connection_read_on_write_error(struct evhttp_connection *evcon,\n    struct evhttp_request *req)\n{\n\tstruct evbuffer *buf;\n\n\t/** Second time, we can't read anything */\n\tif (evcon->flags & EVHTTP_CON_READING_ERROR) {\n\t\tevcon->flags &= ~EVHTTP_CON_READING_ERROR;\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t\treturn;\n\t}\n\n\treq->kind = EVHTTP_RESPONSE;\n\n\tbuf = bufferevent_get_output(evcon->bufev);\n\tevbuffer_unfreeze(buf, 1);\n\tevbuffer_drain(buf, evbuffer_get_length(buf));\n\tevbuffer_freeze(buf, 1);\n\n\tevhttp_start_read_(evcon);\n\tevcon->flags |= EVHTTP_CON_READING_ERROR;\n}\n\nstatic void\nevhttp_error_cb(struct bufferevent *bufev, short what, void *arg)\n{\n\tstruct evhttp_connection *evcon = arg;\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\n\tswitch (evcon->state) {\n\tcase EVCON_CONNECTING:\n\t\tif (what & BEV_EVENT_TIMEOUT) {\n\t\t\tevent_debug((\"%s: connection timeout for \\\"%s:%d\\\" on \"\n\t\t\t\tEV_SOCK_FMT,\n\t\t\t\t__func__, evcon->address, evcon->port,\n\t\t\t\tEV_SOCK_ARG(bufferevent_getfd(bufev))));\n\t\t\tevhttp_connection_cb_cleanup(evcon);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase EVCON_READING_BODY:\n\t\tif (!req->chunked && req->ntoread < 0\n\t\t    && what == (BEV_EVENT_READING|BEV_EVENT_EOF)) {\n\t\t\t/* EOF on read can be benign */\n\t\t\tevhttp_connection_done(evcon);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase EVCON_DISCONNECTED:\n\tcase EVCON_IDLE:\n\tcase EVCON_READING_FIRSTLINE:\n\tcase EVCON_READING_HEADERS:\n\tcase EVCON_READING_TRAILER:\n\tcase EVCON_WRITING:\n\tdefault:\n\t\tbreak;\n\t}\n\n\t/* when we are in close detect mode, a read error means that\n\t * the other side closed their connection.\n\t */\n\tif (evcon->flags & EVHTTP_CON_CLOSEDETECT) {\n\t\tevcon->flags &= ~EVHTTP_CON_CLOSEDETECT;\n\t\tEVUTIL_ASSERT(evcon->http_server == NULL);\n\t\t/* For connections from the client, we just\n\t\t * reset the connection so that it becomes\n\t\t * disconnected.\n\t\t */\n\t\tEVUTIL_ASSERT(evcon->state == EVCON_IDLE);\n\t\tevhttp_connection_reset_(evcon, 1);\n\n\t\t/*\n\t\t * If we have no more requests that need completion\n\t\t * and we want to auto-free the connection when all\n\t\t * requests have been completed.\n\t\t */\n\t\tif (TAILQ_FIRST(&evcon->requests) == NULL\n\t\t  && (evcon->flags & EVHTTP_CON_OUTGOING)\n\t\t  && (evcon->flags & EVHTTP_CON_AUTOFREE)) {\n\t\t\tevhttp_connection_free(evcon);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (what & BEV_EVENT_TIMEOUT) {\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_TIMEOUT);\n\t} else if (what & (BEV_EVENT_EOF|BEV_EVENT_ERROR)) {\n\t\tif (what & BEV_EVENT_WRITING &&\n\t\t\tevcon->flags & EVHTTP_CON_READ_ON_WRITE_ERROR) {\n\t\t\tevhttp_connection_read_on_write_error(evcon, req);\n\t\t\treturn;\n\t\t}\n\n\t\tif (what & BEV_EVENT_READING &&\n\t\t\tevcon->flags & EVHTTP_CON_READ_ON_WRITE_ERROR &&\n\t\t\tevbuffer_get_length(bufferevent_get_input(bufev))) {\n\t\t\tevent_deferred_cb_schedule_(get_deferred_queue(evcon),\n\t\t\t    &evcon->read_more_deferred_cb);\n\t\t\treturn;\n\t\t}\n\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t} else if (what == BEV_EVENT_CONNECTED) {\n\t} else {\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_BUFFER_ERROR);\n\t}\n}\n\n/*\n * Event callback for asynchronous connection attempt.\n */\nstatic void\nevhttp_connection_cb(struct bufferevent *bufev, short what, void *arg)\n{\n\tstruct evhttp_connection *evcon = arg;\n\n\tif (!(what & BEV_EVENT_CONNECTED)) {\n\t\t/* some operating systems return ECONNREFUSED immediately\n\t\t * when connecting to a local address.  the cleanup is going\n\t\t * to reschedule this function call.\n\t\t */\n#ifndef _WIN32\n\t\tif (errno == ECONNREFUSED)\n\t\t\tgoto cleanup;\n#endif\n\t\tevhttp_error_cb(bufev, what, arg);\n\t\treturn;\n\t}\n\n\t/* We are connected to the server now */\n\tevent_debug((\"%s: connected to \\\"%s:%d\\\" on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, evcon->address, evcon->port,\n\t\t\tEV_SOCK_ARG(bufferevent_getfd(bufev))));\n\n\t/* Reset the retry count as we were successful in connecting */\n\tevcon->retry_cnt = 0;\n\tevcon->state = EVCON_IDLE;\n\n\t/* reset the bufferevent cbs */\n\tbufferevent_setcb(evcon->bufev,\n\t    evhttp_read_cb,\n\t    evhttp_write_cb,\n\t    evhttp_error_cb,\n\t    evcon);\n\n\tbufferevent_set_timeouts(evcon->bufev,\n\t    &evcon->timeout_read, &evcon->timeout_write);\n\n\t/* try to start requests that have queued up on this connection */\n\tevhttp_request_dispatch(evcon);\n\treturn;\n\n cleanup:\n\tevhttp_connection_cb_cleanup(evcon);\n}\n\n/*\n * Check if we got a valid response code.\n */\n\nstatic int\nevhttp_valid_response_code(int code)\n{\n\tif (code == 0)\n\t\treturn (0);\n\n\treturn (1);\n}\n\nstatic int\nevhttp_parse_http_version(const char *version, struct evhttp_request *req)\n{\n\tchar major, minor;\n\tchar ch;\n\tint n = sscanf(version, \"HTTP/%c.%c%c\", &major, &minor, &ch);\n\tif (n != 2 || major > '1' || major < '0' || minor > '9' || minor < '0') {\n\t\tevent_debug((\"%s: bad version %s on message %p from %s\",\n\t\t\t__func__, version, (void *)req, req->remote_host));\n\t\treturn (-1);\n\t}\n\treq->major = major - '0';\n\treq->minor = minor - '0';\n\treturn (0);\n}\n\n/* Parses the status line of a web server */\n\nstatic int\nevhttp_parse_response_line(struct evhttp_request *req, char *line)\n{\n\tchar *protocol;\n\tchar *number;\n\tconst char *readable = \"\";\n\n\tprotocol = strsep(&line, \" \");\n\tif (line == NULL)\n\t\treturn (-1);\n\tnumber = strsep(&line, \" \");\n\tif (line != NULL)\n\t\treadable = line;\n\n\tif (evhttp_parse_http_version(protocol, req) < 0)\n\t\treturn (-1);\n\n\treq->response_code = atoi(number);\n\tif (!evhttp_valid_response_code(req->response_code)) {\n\t\tevent_debug((\"%s: bad response code \\\"%s\\\"\",\n\t\t\t__func__, number));\n\t\treturn (-1);\n\t}\n\n\tif (req->response_code_line != NULL)\n\t\tmm_free(req->response_code_line);\n\tif ((req->response_code_line = mm_strdup(readable)) == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\treturn (-1);\n\t}\n\n\treturn (0);\n}\n\n/* Parse the first line of a HTTP request */\n\nstatic int\nevhttp_parse_request_line(struct evhttp_request *req, char *line, size_t len)\n{\n\tchar *eos = line + len;\n\tchar *method;\n\tchar *uri;\n\tchar *version;\n\tsize_t method_len;\n\tenum evhttp_cmd_type type = 0;\n\n\twhile (eos > line && *(eos-1) == ' ') {\n\t\t*(eos-1) = '\\0';\n\t\t--eos;\n\t\t--len;\n\t}\n\tif (len < strlen(\"GET / HTTP/1.0\"))\n\t\treturn -1;\n\n\t/* Parse the request line */\n\tmethod = strsep(&line, \" \");\n\tif (!line)\n\t\treturn -1;\n\turi = line;\n\tversion = strrchr(uri, ' ');\n\tif (!version || uri == version)\n\t\treturn -1;\n\t*version = '\\0';\n\tversion++;\n\n\tmethod_len = (uri - method) - 1;\n\n\t/* First line */\n\tswitch (method_len) {\n\t    case 3:\n\t\t/* The length of the method string is 3, meaning it can only be one of two methods: GET or PUT */\n            \n\t\t/* Since both GET and PUT share the same character 'T' at the end,\n\t\t * if the string doesn't have 'T', we can immediately determine this\n\t\t * is an invalid HTTP method */\n            \n\t\tif (method[2] != 'T') {\n\t\t    break;\n\t\t}\n            \n\t\tswitch (*method) {\n\t\t    case 'G':\n\t\t\t/* This first byte is 'G', so make sure the next byte is\n\t\t\t * 'E', if it isn't then this isn't a valid method */\n                    \n\t\t\tif (method[1] == 'E') {\n\t\t\t    type = EVHTTP_REQ_GET;\n\t\t\t}\n                    \n\t\t\tbreak;\n\t\t    case 'P':\n\t\t\t/* First byte is P, check second byte for 'U', if not,\n\t\t\t * we know it's an invalid method */\n\t\t\tif (method[1] == 'U') {\n\t\t\t    type = EVHTTP_REQ_PUT;\n\t\t\t}\n\t\t\tbreak;\n\t\t    default:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    case 4:\n\t\t/* The method length is 4 bytes, leaving only the methods POST, HEAD, LOCK, COPY and MOVE */\n\t\tswitch (*method) {\n\t\t    case 'P':\n\t\t\tif (method[3] == 'T' && method[2] == 'S' && method[1] == 'O') {\n\t\t\t    type = EVHTTP_REQ_POST;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'H':\n\t\t\tif (method[3] == 'D' && method[2] == 'A' && method[1] == 'E') {\n\t\t\t    type = EVHTTP_REQ_HEAD;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'L':\n\t\t\tif (method[3] == 'K' && method[2] == 'C' && method[1] == 'O') {\n\t\t\t    type = EVHTTP_REQ_LOCK;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'C':\n\t\t\tif (method[3] == 'Y' && method[2] == 'P' && method[1] == 'O') {\n\t\t\t    type = EVHTTP_REQ_COPY;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'M':\n\t\t\tif (method[3] == 'E' && method[2] == 'V' && method[1] == 'O') {\n\t\t\t    type = EVHTTP_REQ_MOVE;\n\t\t\t}\n\t\t\tbreak;\n\t\t    default:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    case 5:\n\t\t/* Method length is 5 bytes, which can only encompass PATCH, TRACE and MKCOL */\n\t\tswitch (*method) {\n\t\t    case 'P':\n\t\t\tif (method[4] == 'H' && method[3] == 'C' && method[2] == 'T' && method[1] == 'A') {\n\t\t\t    type = EVHTTP_REQ_PATCH;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'T':\n\t\t\tif (method[4] == 'E' && method[3] == 'C' && method[2] == 'A' && method[1] == 'R') {\n\t\t\t    type = EVHTTP_REQ_TRACE;\n\t\t\t}\n                    \n\t\t\tbreak;\n\t\t    case 'M':\n\t\t\tif (method[4] == 'L' && method[3] == 'O' && method[2] == 'C' && method[1] == 'K') {\n\t\t\t    type = EVHTTP_REQ_MKCOL;\n\t\t\t}\n\t\t\tbreak;\n\t\t    default:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    case 6:\n\t\t/* Method length is 6, only valid methods 6 bytes in length is DELETE and UNLOCK */\n\t\tswitch (*method) {\n\t\t    case 'D':\n\t\t\tif (method[5] == 'E' && method[4] == 'T' && method[3] == 'E' &&\n\t\t\t\tmethod[2] == 'L' && method[1] == 'E') {\n\t\t\t    type = EVHTTP_REQ_DELETE;\n\t\t\t}\n\t\t\tbreak;\n\t\t    case 'U':\n\t\t\tif (method[5] == 'K' && method[4] == 'C' && method[3] == 'O' &&\n\t\t\t\tmethod[2] == 'L' && method[1] == 'N') {\n\t\t\t    type = EVHTTP_REQ_UNLOCK;\n\t\t\t}\n\t\t\tbreak;\n\t\t    default:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    case 7:\n\t\t/* Method length is 7, only valid methods are \"OPTIONS\" and \"CONNECT\" */\n\t\tswitch (*method) {\n\t\t    case 'O':\n\t\t\tif (method[6] == 'S' && method[5] == 'N' && method[4] == 'O' &&\n\t\t\t\tmethod[3] == 'I' && method[2] == 'T' && method[1] == 'P') {\n\t\t\t    type = EVHTTP_REQ_OPTIONS;\n\t\t\t}\n                   \n\t\t       \tbreak;\n\t\t    case 'C':\n\t\t\tif (method[6] == 'T' && method[5] == 'C' && method[4] == 'E' &&\n\t\t\t\tmethod[3] == 'N' && method[2] == 'N' && method[1] == 'O') {\n\t\t\t    type = EVHTTP_REQ_CONNECT;\n\t\t\t}\n                    \n\t\t\tbreak;\n\t\t    default:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    case 8:\n\t\t/* Method length is 8, only valid method 8 bytes in length is PROPFIND */\n\n\t\t/* If the first byte isn't 'P' then it's invalid */\n\t\tif (*method != 'P') {\n\t\t    break;\n\t\t}\n\n\t\tif (method[7] == 'D' && method[6] == 'N' && method[5] == 'I' &&\n\t\t\tmethod[4] == 'F' && method[3] == 'P' && method[2] == 'O' &&\n\t\t\tmethod[1] == 'R') {\n\t\t    type = EVHTTP_REQ_PROPFIND;\n\t\t}\n\n\t\tbreak;\n\t    case 9:\n\t\t/* Method length is 9, only valid method 9 bytes in length is PROPPATCH */\n\n\t\t/* If the first byte isn't 'P' then it's invalid */\n\t\tif (*method != 'P') {\n\t\t    break;\n\t\t}\n\n\t\tif (method[8] == 'H' && method[7] == 'C' && method[6] == 'T' &&\n\t\t\tmethod[5] == 'A' && method[4] == 'P' && method[3] == 'P' &&\n\t\t\tmethod[2] == 'O' && method[1] == 'R') {\n\t\t    type = EVHTTP_REQ_PROPPATCH;\n\t\t}\n\n\t\tbreak;\n\t} /* switch */\n\n\tif (!type) {\n\t\t/* check extended methods, we only care about the\n\t\t * type set by the cmp function if the cmp function\n\t\t * returns a 0 value.\n\t\t */\n\t\tstruct evhttp_ext_method ext_method;\n\n\t\text_method.method = method;\n\t\text_method.type = 0;\n\t\text_method.flags = 0;\n\n\t\tif (req->evcon->ext_method_cmp &&\n\t\t    req->evcon->ext_method_cmp(&ext_method) == 0) {\n\t\t\t/* make sure the other fields in ext_method are\n\t\t\t * not changed by the callback.\n\t\t\t */\n\t\t\tif (strcmp(ext_method.method, method) != 0) {\n\t\t\t\tevent_warn(\"%s: modifying the 'method' field of ext_method_cmp's \"\n\t\t\t\t\t\"parameter is not allowed\", __func__);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (ext_method.flags != 0) {\n\t\t\t\tevent_warn(\"%s: modifying the 'flags' field of ext_method_cmp's \"\n\t\t\t\t\t\"parameter is not allowed\", __func__);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ttype = ext_method.type;\n\t\t}\n\t}\n\n\tif (!type) {\n\t\tevent_debug((\"%s: bad method %s on request %p from %s\",\n\t\t            __func__, method, (void *)req, req->remote_host));\n\t\t/* No error yet; we'll give a better error later when\n\t\t * we see that req->type is unsupported. */\n\t}\n\n\treq->type = type;\n\n\tif (evhttp_parse_http_version(version, req) < 0)\n\t\treturn -1;\n\n\tif ((req->uri = mm_strdup(uri)) == NULL) {\n\t\tevent_debug((\"%s: mm_strdup\", __func__));\n\t\treturn -1;\n\t}\n\n\tif (type == EVHTTP_REQ_CONNECT) {\n\t\tif ((req->uri_elems = evhttp_uri_parse_authority(req->uri, 0)) == NULL) {\n\t\t\treturn -1;\n\t\t}\n\t} else {\n\t\tif ((req->uri_elems = evhttp_uri_parse_with_flags(req->uri,\n\t\t\t    EVHTTP_URI_NONCONFORMANT)) == NULL) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nconst char *\nevhttp_find_header(const struct evkeyvalq *headers, const char *key)\n{\n\tstruct evkeyval *header;\n\n\tTAILQ_FOREACH(header, headers, next) {\n\t\tif (evutil_ascii_strcasecmp(header->key, key) == 0)\n\t\t\treturn (header->value);\n\t}\n\n\treturn (NULL);\n}\n\nvoid\nevhttp_clear_headers(struct evkeyvalq *headers)\n{\n\tstruct evkeyval *header;\n\n\tfor (header = TAILQ_FIRST(headers);\n\t    header != NULL;\n\t    header = TAILQ_FIRST(headers)) {\n\t\tTAILQ_REMOVE(headers, header, next);\n\t\tmm_free(header->key);\n\t\tmm_free(header->value);\n\t\tmm_free(header);\n\t}\n}\n\n/*\n * Returns 0,  if the header was successfully removed.\n * Returns -1, if the header could not be found.\n */\n\nint\nevhttp_remove_header(struct evkeyvalq *headers, const char *key)\n{\n\tstruct evkeyval *header;\n\n\tTAILQ_FOREACH(header, headers, next) {\n\t\tif (evutil_ascii_strcasecmp(header->key, key) == 0)\n\t\t\tbreak;\n\t}\n\n\tif (header == NULL)\n\t\treturn (-1);\n\n\t/* Free and remove the header that we found */\n\tTAILQ_REMOVE(headers, header, next);\n\tmm_free(header->key);\n\tmm_free(header->value);\n\tmm_free(header);\n\n\treturn (0);\n}\n\nstatic int\nevhttp_header_is_valid_value(const char *value)\n{\n\tconst char *p = value;\n\n\twhile ((p = strpbrk(p, \"\\r\\n\")) != NULL) {\n\t\t/* we really expect only one new line */\n\t\tp += strspn(p, \"\\r\\n\");\n\t\t/* we expect a space or tab for continuation */\n\t\tif (*p != ' ' && *p != '\\t')\n\t\t\treturn (0);\n\t}\n\treturn (1);\n}\n\nint\nevhttp_add_header(struct evkeyvalq *headers,\n    const char *key, const char *value)\n{\n\tevent_debug((\"%s: key: %s val: %s\\n\", __func__, key, value));\n\n\t/* RFC 9110 defines field-names as case-sensitive non-empty strings made of the following characters */\n\t// field-name     = 1*tchar\n\t// tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / 0-9 / A-Z / a-z\n\t/* For simplicity, we'll reject field-names containing the documented most dangerous characters */\n\t// \"Field values containing CR, LF, or NUL characters are invalid and dangerous, due to the varying ways that implementations might parse and interpret those characters; a recipient of CR, LF, or NUL within a field value MUST either reject the message or replace each of those characters with SP before further processing or forwarding of that message.\"\n\tif (strchr(key, '\\r') != NULL || strchr(key, '\\n') != NULL || key[0] == '\\0') {\n\t\t/* drop illegal headers */\n\t\tevent_debug((\"%s: dropping illegal header key\\n\", __func__));\n\t\treturn (-1);\n\t}\n\n\tif (!evhttp_header_is_valid_value(value)) {\n\t\tevent_debug((\"%s: dropping illegal header value\\n\", __func__));\n\t\treturn (-1);\n\t}\n\n\treturn (evhttp_add_header_internal(headers, key, value));\n}\n\nstatic int\nevhttp_add_header_internal(struct evkeyvalq *headers,\n    const char *key, const char *value)\n{\n\tstruct evkeyval *header = mm_calloc(1, sizeof(struct evkeyval));\n\tif (header == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\treturn (-1);\n\t}\n\tif ((header->key = mm_strdup(key)) == NULL) {\n\t\tmm_free(header);\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\treturn (-1);\n\t}\n\tif ((header->value = mm_strdup(value)) == NULL) {\n\t\tmm_free(header->key);\n\t\tmm_free(header);\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\treturn (-1);\n\t}\n\n\tTAILQ_INSERT_TAIL(headers, header, next);\n\n\treturn (0);\n}\n\n/*\n * Parses header lines from a request or a response into the specified\n * request object given an event buffer.\n *\n * Returns\n *   DATA_CORRUPTED      on error\n *   MORE_DATA_EXPECTED  when we need to read more headers\n *   ALL_DATA_READ       when all headers have been read.\n */\n\nenum message_read_status\nevhttp_parse_firstline_(struct evhttp_request *req, struct evbuffer *buffer)\n{\n\tchar *line;\n\tenum message_read_status status = ALL_DATA_READ;\n\n\tsize_t len;\n\t/* XXX try */\n\tline = evbuffer_readln(buffer, &len, EVBUFFER_EOL_CRLF);\n\tif (line == NULL) {\n\t\tif (req->evcon != NULL &&\n\t\t    evbuffer_get_length(buffer) > req->evcon->max_headers_size)\n\t\t\treturn (DATA_TOO_LONG);\n\t\telse\n\t\t\treturn (MORE_DATA_EXPECTED);\n\t}\n\n\tif (req->evcon != NULL && len > req->evcon->max_headers_size) {\n\t\tmm_free(line);\n\t\treturn (DATA_TOO_LONG);\n\t}\n\n\treq->headers_size = len;\n\n\tswitch (req->kind) {\n\tcase EVHTTP_REQUEST:\n\t\tif (evhttp_parse_request_line(req, line, len) == -1)\n\t\t\tstatus = DATA_CORRUPTED;\n\t\tbreak;\n\tcase EVHTTP_RESPONSE:\n\t\tif (evhttp_parse_response_line(req, line) == -1)\n\t\t\tstatus = DATA_CORRUPTED;\n\t\tbreak;\n\tdefault:\n\t\tstatus = DATA_CORRUPTED;\n\t}\n\n\tmm_free(line);\n\treturn (status);\n}\n\nstatic int\nevhttp_append_to_last_header(struct evkeyvalq *headers, char *line)\n{\n\tstruct evkeyval *header = TAILQ_LAST(headers, evkeyvalq);\n\tchar *newval;\n\tsize_t old_len, line_len;\n\n\tif (header == NULL)\n\t\treturn (-1);\n\n\told_len = strlen(header->value);\n\n\t/* Strip space from start and end of line. */\n\twhile (*line == ' ' || *line == '\\t')\n\t\t++line;\n\tevutil_rtrim_lws_(line);\n\n\tline_len = strlen(line);\n\n\tnewval = mm_realloc(header->value, old_len + line_len + 2);\n\tif (newval == NULL)\n\t\treturn (-1);\n\n\tnewval[old_len] = ' ';\n\tmemcpy(newval + old_len + 1, line, line_len + 1);\n\theader->value = newval;\n\n\treturn (0);\n}\n\nenum message_read_status\nevhttp_parse_headers_(struct evhttp_request *req, struct evbuffer* buffer)\n{\n\tenum message_read_status errcode = DATA_CORRUPTED;\n\tchar *line;\n\tenum message_read_status status = MORE_DATA_EXPECTED;\n\n\tstruct evkeyvalq* headers = req->input_headers;\n\tsize_t len;\n\twhile ((line = evbuffer_readln(buffer, &len, EVBUFFER_EOL_CRLF))\n\t       != NULL) {\n\t\tchar *skey, *svalue;\n\n\t\treq->headers_size += len;\n\n\t\tif (req->evcon != NULL &&\n\t\t    req->headers_size > req->evcon->max_headers_size) {\n\t\t\terrcode = DATA_TOO_LONG;\n\t\t\tgoto error;\n\t\t}\n\n\t\tif (*line == '\\0') { /* Last header - Done */\n\t\t\tstatus = ALL_DATA_READ;\n\t\t\tmm_free(line);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Check if this is a continuation line */\n\t\tif (*line == ' ' || *line == '\\t') {\n\t\t\tif (evhttp_append_to_last_header(headers, line) == -1)\n\t\t\t\tgoto error;\n\t\t\tmm_free(line);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Processing of header lines */\n\t\tsvalue = line;\n\t\tskey = strsep(&svalue, \":\");\n\t\tif (svalue == NULL)\n\t\t\tgoto error;\n\n\t\tsvalue += strspn(svalue, \" \");\n\t\tevutil_rtrim_lws_(svalue);\n\n\t\tif (evhttp_add_header(headers, skey, svalue) == -1)\n\t\t\tgoto error;\n\n\t\tmm_free(line);\n\t}\n\n\tif (status == MORE_DATA_EXPECTED) {\n\t\tif (req->evcon != NULL &&\n\t\treq->headers_size + evbuffer_get_length(buffer) > req->evcon->max_headers_size)\n\t\t\treturn (DATA_TOO_LONG);\n\t}\n\n\treturn (status);\n\n error:\n\tmm_free(line);\n\treturn (errcode);\n}\n\nstatic int\nevhttp_get_body_length(struct evhttp_request *req)\n{\n\tstruct evkeyvalq *headers = req->input_headers;\n\tconst char *content_length;\n\tconst char *connection;\n\n\tcontent_length = evhttp_find_header(headers, \"Content-Length\");\n\tconnection = evhttp_find_header(headers, \"Connection\");\n\n\tif (content_length == NULL && connection == NULL)\n\t\treq->ntoread = -1;\n\telse if (content_length == NULL &&\n\t    evutil_ascii_strcasecmp(connection, \"Close\") != 0) {\n\t\treq->ntoread = 0;\n\t} else if (content_length == NULL) {\n\t\treq->ntoread = -1;\n\t} else {\n\t\tchar *endp;\n\t\tev_int64_t ntoread = evutil_strtoll(content_length, &endp, 10);\n\t\tif (*content_length == '\\0' || *endp != '\\0' || ntoread < 0) {\n\t\t\tevent_debug((\"%s: illegal content length: %s\",\n\t\t\t\t__func__, content_length));\n\t\t\treturn (-1);\n\t\t}\n\t\treq->ntoread = ntoread;\n\t}\n\n\tevent_debug((\"%s: bytes to read: \"EV_I64_FMT\" (in buffer \"EV_SIZE_FMT\")\\n\",\n\t\t__func__, EV_I64_ARG(req->ntoread),\n\t\tEV_SIZE_ARG(evbuffer_get_length(bufferevent_get_input(req->evcon->bufev)))));\n\n\treturn (0);\n}\n\nstatic int\nevhttp_method_may_have_body_(struct evhttp_connection *evcon, enum evhttp_cmd_type type)\n{\n\t/* NOTE: some version of GCC reports a warning that flags may be uninitialized, hence assignment */\n\tev_uint16_t flags = 0;\n\tevhttp_method_(evcon, type, &flags);\n\treturn (flags & EVHTTP_METHOD_HAS_BODY) ? 1 : 0;\n}\n\nstatic void\nevhttp_get_body(struct evhttp_connection *evcon, struct evhttp_request *req)\n{\n\tconst char *xfer_enc;\n\n\t/* If this is a request without a body, then we are done */\n\tif (req->kind == EVHTTP_REQUEST &&\n\t    !evhttp_method_may_have_body_(evcon, req->type)) {\n\t\tevhttp_connection_done(evcon);\n\t\treturn;\n\t}\n\tevcon->state = EVCON_READING_BODY;\n\txfer_enc = evhttp_find_header(req->input_headers, \"Transfer-Encoding\");\n\tif (xfer_enc != NULL && evutil_ascii_strcasecmp(xfer_enc, \"chunked\") == 0) {\n\t\treq->chunked = 1;\n\t\treq->ntoread = -1;\n\t} else {\n\t\tif (evhttp_get_body_length(req) == -1) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\t\treturn;\n\t\t}\n\t\tif (req->kind == EVHTTP_REQUEST && req->ntoread < 1) {\n\t\t\t/* An incoming request with no content-length and no\n\t\t\t * transfer-encoding has no body. */\n\t\t\tevhttp_connection_done(evcon);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Should we send a 100 Continue status line? */\n\tswitch (evhttp_have_expect(req, 1)) {\n\t\tcase CONTINUE:\n\t\t\t\t/* XXX It would be nice to do some sanity\n\t\t\t\t   checking here. Does the resource exist?\n\t\t\t\t   Should the resource accept post requests? If\n\t\t\t\t   no, we should respond with an error. For\n\t\t\t\t   now, just optimistically tell the client to\n\t\t\t\t   send their message body. */\n\t\t\t\tif (req->ntoread > 0) {\n\t\t\t\t\t/* ntoread is ev_int64_t, max_body_size is ev_uint64_t */ \n\t\t\t\t\tif ((req->evcon->max_body_size <= EV_INT64_MAX) &&\n\t\t\t\t\t\t(ev_uint64_t)req->ntoread > req->evcon->max_body_size) {\n\t\t\t\t\t\tevhttp_lingering_fail(evcon, req);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!evbuffer_get_length(bufferevent_get_input(evcon->bufev)))\n\t\t\t\t\tevhttp_send_continue(evcon, req);\n\t\t\tbreak;\n\t\tcase OTHER:\n\t\t\tevhttp_send_error(req, HTTP_EXPECTATIONFAILED, NULL);\n\t\t\treturn;\n\t\tcase NO: break;\n\t}\n\n\tevhttp_read_body(evcon, req);\n\t/* note the request may have been freed in evhttp_read_body */\n}\n\nstatic void\nevhttp_read_firstline(struct evhttp_connection *evcon,\n\t\t      struct evhttp_request *req)\n{\n\tenum message_read_status res;\n\n\tres = evhttp_parse_firstline_(req, bufferevent_get_input(evcon->bufev));\n\tif (res == DATA_CORRUPTED || res == DATA_TOO_LONG) {\n\t\t/* Error while reading, terminate */\n\t\tevent_debug((\"%s: bad header lines on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(bufferevent_getfd(evcon->bufev))));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\treturn;\n\t} else if (res == MORE_DATA_EXPECTED) {\n\t\t/* Need more header lines */\n\t\treturn;\n\t}\n\n\tevcon->state = EVCON_READING_HEADERS;\n\tevhttp_read_header(evcon, req);\n}\n\nstatic void\nevhttp_read_header(struct evhttp_connection *evcon,\n\t\t   struct evhttp_request *req)\n{\n\tenum message_read_status res;\n\tevutil_socket_t fd = bufferevent_getfd(evcon->bufev);\n\n\tres = evhttp_parse_headers_(req, bufferevent_get_input(evcon->bufev));\n\tif (res == DATA_CORRUPTED || res == DATA_TOO_LONG) {\n\t\t/* Error while reading, terminate */\n\t\tevent_debug((\"%s: bad header lines on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\treturn;\n\t} else if (res == MORE_DATA_EXPECTED) {\n\t\t/* Need more header lines */\n\t\treturn;\n\t}\n\n\t/* Callback can shut down connection with negative return value */\n\tif (req->header_cb != NULL) {\n\t\tif ((*req->header_cb)(req, req->cb_arg) < 0) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Done reading headers, do the real work */\n\tswitch (req->kind) {\n\tcase EVHTTP_REQUEST:\n\t\tevent_debug((\"%s: checking for post data on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_get_body(evcon, req);\n\t\t/* note the request may have been freed in evhttp_get_body */\n\t\tbreak;\n\n\tcase EVHTTP_RESPONSE:\n\t\t/* Start over if we got a 100 Continue response. */\n\t\tif (req->response_code == 100) {\n\t\t\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\t\t\tevbuffer_add_buffer(output, req->output_buffer);\n\t\t\tevhttp_start_write_(evcon);\n\t\t\treturn;\n\t\t}\n\t\tif (!evhttp_response_needs_body(req)) {\n\t\t\tevent_debug((\"%s: skipping body for code %d\\n\",\n\t\t\t\t\t__func__, req->response_code));\n\t\t\tevhttp_connection_done(evcon);\n\t\t} else {\n\t\t\tevent_debug((\"%s: start of read body for %s on \"\n\t\t\t\tEV_SOCK_FMT\"\\n\",\n\t\t\t\t__func__, req->remote_host, EV_SOCK_ARG(fd)));\n\t\t\tevhttp_get_body(evcon, req);\n\t\t\t/* note the request may have been freed in\n\t\t\t * evhttp_get_body */\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tevent_warnx(\"%s: bad header on \"EV_SOCK_FMT, __func__,\n\t\t    EV_SOCK_ARG(fd));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\tbreak;\n\t}\n\t/* request may have been freed above */\n}\n\n/*\n * Creates a TCP connection to the specified port and executes a callback\n * when finished.  Failure or success is indicate by the passed connection\n * object.\n *\n * Although this interface accepts a hostname, it is intended to take\n * only numeric hostnames so that non-blocking DNS resolution can\n * happen elsewhere.\n */\n\nstruct evhttp_connection *\nevhttp_connection_new(const char *address, ev_uint16_t port)\n{\n\treturn (evhttp_connection_base_new(NULL, NULL, address, port));\n}\n\n/* We were passed a bev with file descriptor set.\n * Assume that this is an already-open connection that we\n * can start sending requests on.\n */\nstatic int\nevhttp_connection_set_existing_(struct evhttp_connection *evcon, struct bufferevent* bev)\n{\n\tevcon->state = EVCON_IDLE;\n\tevcon->flags |= EVHTTP_CON_OUTGOING;\n\treturn 0;\n}\n\nstatic struct evhttp_connection *\nevhttp_connection_new_(struct event_base *base, struct bufferevent* bev)\n{\n\tstruct evhttp_connection *evcon;\n\n\tif ((evcon = mm_calloc(1, sizeof(struct evhttp_connection))) == NULL) {\n\t\tevent_warn(\"%s: calloc failed\", __func__);\n\t\tgoto error;\n\t}\n\n\tevcon->max_headers_size = EV_SIZE_MAX;\n\tevcon->max_body_size = EV_SIZE_MAX;\n\n\tevcon->timeout_connect.tv_sec = HTTP_CONNECT_TIMEOUT;\n\tevcon->timeout_read.tv_sec    = HTTP_READ_TIMEOUT;\n\tevcon->timeout_write.tv_sec   = HTTP_WRITE_TIMEOUT;\n\tevcon->initial_retry_timeout.tv_sec = HTTP_INITIAL_RETRY_TIMEOUT;\n\n\tevcon->retry_cnt = evcon->retry_max = 0;\n\n\tif (bev == NULL) {\n\t\tif (!(bev = bufferevent_socket_new(base, -1, BEV_OPT_CLOSE_ON_FREE))) {\n\t\t\tevent_warn(\"%s: bufferevent_socket_new failed\", __func__);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\tbufferevent_setcb(bev, evhttp_read_cb, evhttp_write_cb, evhttp_error_cb, evcon);\n\tevcon->bufev = bev;\n\n\tevcon->state = EVCON_DISCONNECTED;\n\tTAILQ_INIT(&evcon->requests);\n\n\tif (base != NULL) {\n\t\tevcon->base = base;\n\t\tif (bufferevent_get_base(bev) != base)\n\t\t\tbufferevent_base_set(base, evcon->bufev);\n\t}\n\n\tevent_deferred_cb_init_(\n\t    &evcon->read_more_deferred_cb,\n\t    bufferevent_get_priority(bev),\n\t    evhttp_deferred_read_cb, evcon);\n\n\tevcon->ai_family = AF_UNSPEC;\n\n\treturn (evcon);\n\n error:\n\tif (evcon != NULL)\n\t\tevhttp_connection_free(evcon);\n\treturn (NULL);\n}\n\nstruct evhttp_connection *\nevhttp_connection_base_bufferevent_reuse_new(struct event_base *base, struct evdns_base *dnsbase, struct bufferevent* bev)\n{\n\tstruct evhttp_connection *evcon = NULL;\n\tif (bev == NULL)\n\t\tgoto error;\n\n\tevcon = evhttp_connection_new_(base, bev);\n\n\tif (evcon == NULL)\n\t\tgoto error;\n\n\tif (evhttp_connection_set_existing_(evcon, bev))\n\t\tgoto error;\n\n\tevcon->dns_base = dnsbase;\n\tevcon->address = NULL;\n\tevcon->port = 0;\n#ifndef _WIN32\n\tevcon->unixsocket = NULL;\n#endif\n\n\treturn (evcon);\n error:\n\tif (evcon != NULL)\n\t\tevhttp_connection_free(evcon);\n\treturn (NULL);\n}\n\n#ifndef _WIN32\nstruct evhttp_connection *\nevhttp_connection_base_bufferevent_unix_new(struct event_base *base, struct bufferevent* bev, const char *unixsocket)\n{\n\tstruct evhttp_connection *evcon;\n\n\tif (strlen(unixsocket) >= member_size(struct sockaddr_un, sun_path)) {\n\t\tevent_warn(\"%s: unix socket too long\", __func__);\n\t\treturn NULL;\n\t}\n\n\tevcon = evhttp_connection_new_(base, bev);\n\tif (evcon == NULL)\n\t\tgoto error;\n\n\tif ((evcon->unixsocket = mm_strdup(unixsocket)) == NULL) {\n\t\tevent_warn(\"%s: strdup failed\", __func__);\n\t\tgoto error;\n\t}\n\n\tevcon->ai_family = AF_UNIX;\n\n\treturn (evcon);\n error:\n\tif (evcon != NULL)\n\t\tevhttp_connection_free(evcon);\n\treturn (NULL);\n}\n#endif\n\nstruct evhttp_connection *\nevhttp_connection_base_bufferevent_new(struct event_base *base, struct evdns_base *dnsbase, struct bufferevent* bev,\n    const char *address, unsigned short port)\n{\n\tstruct evhttp_connection *evcon;\n\n\tevent_debug((\"Attempting connection to %s:%d\\n\", address, port));\n\n\tevcon = evhttp_connection_new_(base, bev);\n\tif (evcon == NULL)\n\t\tgoto error;\n\n\tif ((evcon->address = mm_strdup(address)) == NULL) {\n\t\tevent_warn(\"%s: strdup failed\", __func__);\n\t\tgoto error;\n\t}\n\tevcon->port = port;\n\tevcon->dns_base = dnsbase;\n\n\treturn (evcon);\nerror:\n\tif (evcon != NULL)\n\t\tevhttp_connection_free(evcon);\n\treturn (NULL);\n}\n\n\nstruct bufferevent* evhttp_connection_get_bufferevent(struct evhttp_connection *evcon)\n{\n\treturn evcon->bufev;\n}\n\nstruct evhttp *\nevhttp_connection_get_server(struct evhttp_connection *evcon)\n{\n\treturn evcon->http_server;\n}\n\nstruct evhttp_connection *\nevhttp_connection_base_new(struct event_base *base, struct evdns_base *dnsbase,\n    const char *address, ev_uint16_t port)\n{\n\treturn evhttp_connection_base_bufferevent_new(base, dnsbase, NULL, address, port);\n}\n\nvoid evhttp_connection_set_family(struct evhttp_connection *evcon,\n\tint family)\n{\n\tevcon->ai_family = family;\n}\n\nint evhttp_connection_set_flags(struct evhttp_connection *evcon,\n\tint flags)\n{\n\tint avail_flags = 0;\n\tavail_flags |= EVHTTP_CON_REUSE_CONNECTED_ADDR;\n\tavail_flags |= EVHTTP_CON_READ_ON_WRITE_ERROR;\n\n\tif (flags & ~avail_flags || flags > EVHTTP_CON_PUBLIC_FLAGS_END)\n\t\treturn 1;\n\tevcon->flags &= ~avail_flags;\n\n\tevcon->flags |= flags;\n\n\treturn 0;\n}\n\nvoid\nevhttp_connection_set_ext_method_cmp(struct evhttp_connection *evcon,\n\tevhttp_ext_method_cb cmp)\n{\n\tevcon->ext_method_cmp = cmp;\n}\n\nvoid\nevhttp_connection_set_base(struct evhttp_connection *evcon,\n    struct event_base *base)\n{\n\tEVUTIL_ASSERT(evcon->base == NULL);\n\tEVUTIL_ASSERT(evcon->state == EVCON_DISCONNECTED);\n\tevcon->base = base;\n\tbufferevent_base_set(base, evcon->bufev);\n}\n\nvoid\nevhttp_connection_set_timeout(struct evhttp_connection *evcon,\n    int timeout)\n{\n\tif (timeout != -1) {\n\t\tevcon->flags |= EVHTTP_CON_TIMEOUT_ADJUSTED;\n\t} else {\n\t\tevcon->flags &= ~EVHTTP_CON_TIMEOUT_ADJUSTED;\n\t}\n\tevhttp_set_timeout_(&evcon->timeout_read,  timeout, HTTP_READ_TIMEOUT);\n\tevhttp_set_timeout_(&evcon->timeout_write, timeout, HTTP_WRITE_TIMEOUT);\n\tbufferevent_set_timeouts(evcon->bufev,\n\t    &evcon->timeout_read, &evcon->timeout_write);\n}\nvoid\nevhttp_connection_set_timeout_tv(struct evhttp_connection *evcon,\n    const struct timeval* tv)\n{\n\tif (tv) {\n\t\tevcon->flags |= EVHTTP_CON_TIMEOUT_ADJUSTED;\n\t} else {\n\t\tevcon->flags &= ~EVHTTP_CON_TIMEOUT_ADJUSTED;\n\t}\n\tevhttp_set_timeout_tv_(&evcon->timeout_read,  tv, HTTP_READ_TIMEOUT);\n\tevhttp_set_timeout_tv_(&evcon->timeout_write, tv, HTTP_WRITE_TIMEOUT);\n\tbufferevent_set_timeouts(evcon->bufev,\n\t    &evcon->timeout_read, &evcon->timeout_write);\n}\nvoid evhttp_connection_set_connect_timeout_tv(struct evhttp_connection *evcon,\n    const struct timeval *tv)\n{\n\tevcon->flags |= EVHTTP_CON_TIMEOUT_ADJUSTED;\n\tevhttp_set_timeout_tv_(&evcon->timeout_connect, tv, -1);\n\tif (evcon->state == EVCON_CONNECTING)\n\t\tbufferevent_set_timeouts(evcon->bufev,\n\t\t    &evcon->timeout_connect, &evcon->timeout_connect);\n}\nvoid evhttp_connection_set_read_timeout_tv(struct evhttp_connection *evcon,\n    const struct timeval *tv)\n{\n\tevcon->flags |= EVHTTP_CON_TIMEOUT_ADJUSTED;\n\tevhttp_set_timeout_tv_(&evcon->timeout_read, tv, -1);\n\tif (evcon->state != EVCON_CONNECTING)\n\t\tbufferevent_set_timeouts(evcon->bufev,\n\t\t    &evcon->timeout_read, &evcon->timeout_write);\n}\nvoid evhttp_connection_set_write_timeout_tv(struct evhttp_connection *evcon,\n    const struct timeval *tv)\n{\n\tevcon->flags |= EVHTTP_CON_TIMEOUT_ADJUSTED;\n\tevhttp_set_timeout_tv_(&evcon->timeout_write, tv, -1);\n\tif (evcon->state != EVCON_CONNECTING)\n\t\tbufferevent_set_timeouts(evcon->bufev,\n\t\t    &evcon->timeout_read, &evcon->timeout_write);\n}\n\nvoid\nevhttp_connection_set_initial_retry_tv(struct evhttp_connection *evcon,\n    const struct timeval *tv)\n{\n\tif (tv) {\n\t\tevcon->initial_retry_timeout = *tv;\n\t} else {\n\t\tevutil_timerclear(&evcon->initial_retry_timeout);\n\t\tevcon->initial_retry_timeout.tv_sec = 2;\n\t}\n}\n\nvoid\nevhttp_connection_set_retries(struct evhttp_connection *evcon,\n    int retry_max)\n{\n\tevcon->retry_max = retry_max;\n}\n\nvoid\nevhttp_connection_set_closecb(struct evhttp_connection *evcon,\n    void (*cb)(struct evhttp_connection *, void *), void *cbarg)\n{\n\tevcon->closecb = cb;\n\tevcon->closecb_arg = cbarg;\n}\n\nvoid\nevhttp_connection_get_peer(struct evhttp_connection *evcon,\n    const char **address, ev_uint16_t *port)\n{\n\t*address = evcon->address;\n\t*port = evcon->port;\n}\n\nconst struct sockaddr*\nevhttp_connection_get_addr(struct evhttp_connection *evcon)\n{\n\treturn bufferevent_socket_get_conn_address_(evcon->bufev);\n}\n\nint\nevhttp_connection_connect_(struct evhttp_connection *evcon)\n{\n\tint old_state = evcon->state;\n\tconst char *address = evcon->address;\n\tconst struct sockaddr *sa = evhttp_connection_get_addr(evcon);\n\tint ret;\n\n\tif (evcon->state == EVCON_CONNECTING)\n\t\treturn (0);\n\n\t/* Do not do hard reset, since this will reset the fd, but someone may\n\t * change some options for it (i.e. setsockopt(), #875)\n\t *\n\t * However don't think that this options will be preserved for all\n\t * connection lifetime, they will be reseted in the following cases:\n\t * - evhttp_connection_set_local_address()\n\t * - evhttp_connection_set_local_port()\n\t * - evhttp_connection_set_retries()\n\t * */\n\tevhttp_connection_reset_(evcon, 0);\n\n\tEVUTIL_ASSERT(!(evcon->flags & EVHTTP_CON_INCOMING));\n\tevcon->flags |= EVHTTP_CON_OUTGOING;\n\n\tif (evcon->bind_address || evcon->bind_port) {\n\t\tint fd = bind_socket(evcon->bind_address, evcon->bind_port,\n\t\t\t0 /*reuse*/);\n\t\tif (fd == -1) {\n\t\t\tevent_debug((\"%s: failed to bind to \\\"%s\\\"\",\n\t\t\t\t__func__, evcon->bind_address));\n\t\t\treturn (-1);\n\t\t}\n\n\t\tif (bufferevent_replacefd(evcon->bufev, fd))\n\t\t\treturn (-1);\n\t}\n\n\t/* Set up a callback for successful connection setup */\n\tbufferevent_setcb(evcon->bufev,\n\t    NULL /* evhttp_read_cb */,\n\t    NULL /* evhttp_write_cb */,\n\t    evhttp_connection_cb,\n\t    evcon);\n\tbufferevent_set_timeouts(evcon->bufev,\n\t    &evcon->timeout_connect, &evcon->timeout_connect);\n\t/* make sure that we get a write callback */\n\tif (bufferevent_enable(evcon->bufev, EV_WRITE))\n\t\treturn (-1);\n\n\tevcon->state = EVCON_CONNECTING;\n\n\tif (evcon->flags & EVHTTP_CON_REUSE_CONNECTED_ADDR &&\n\t\tsa &&\n\t\t(sa->sa_family == AF_INET || sa->sa_family == AF_INET6)) {\n\t\tint socklen = sizeof(struct sockaddr_in);\n\t\tif (sa->sa_family == AF_INET6) {\n\t\t\tsocklen = sizeof(struct sockaddr_in6);\n\t\t}\n\t\tret = bufferevent_socket_connect(evcon->bufev, sa, socklen);\n\t}\n#ifndef _WIN32\n\telse if (evcon->unixsocket) {\n\t\tstruct sockaddr_un sockaddr;\n\t\tsockaddr.sun_family = AF_UNIX;\n\t\tstrcpy(sockaddr.sun_path, evcon->unixsocket);\n\t\tret = bufferevent_socket_connect(evcon->bufev, (const struct sockaddr*)&sockaddr, sizeof(sockaddr));\n\t}\n#endif\n\telse {\n\t\tret = bufferevent_socket_connect_hostname(evcon->bufev,\n\t\t\t\tevcon->dns_base, evcon->ai_family, address, evcon->port);\n\t}\n\n\tif (ret < 0) {\n\t\tevcon->state = old_state;\n\t\tevent_sock_warn(bufferevent_getfd(evcon->bufev), \"%s: connection to \\\"%s\\\" failed\",\n\t\t    __func__, evcon->address);\n\t\t/* some operating systems return ECONNREFUSED immediately\n\t\t * when connecting to a local address.  the cleanup is going\n\t\t * to reschedule this function call.\n\t\t */\n\t\tevhttp_connection_cb_cleanup(evcon);\n\t\treturn (0);\n\t}\n\n\treturn (0);\n}\n\n/*\n * Starts an HTTP request on the provided evhttp_connection object.\n * If the connection object is not connected to the web server already,\n * this will start the connection.\n */\n\nint\nevhttp_make_request(struct evhttp_connection *evcon,\n    struct evhttp_request *req,\n    enum evhttp_cmd_type type, const char *uri)\n{\n\t/* We are making a request */\n\treq->kind = EVHTTP_REQUEST;\n\treq->type = type;\n\tif (req->uri != NULL)\n\t\tmm_free(req->uri);\n\tif ((req->uri = mm_strdup(uri)) == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tevhttp_request_free_auto(req);\n\t\treturn (-1);\n\t}\n\n\t/* Set the protocol version if it is not supplied */\n\tif (!req->major && !req->minor) {\n\t\treq->major = 1;\n\t\treq->minor = 1;\n\t}\n\n\tEVUTIL_ASSERT(req->evcon == NULL);\n\treq->evcon = evcon;\n\tEVUTIL_ASSERT(!(req->flags & EVHTTP_REQ_OWN_CONNECTION));\n\n\tTAILQ_INSERT_TAIL(&evcon->requests, req, next);\n\n\t/* We do not want to conflict with retry_ev */\n\tif (evcon->retry_cnt)\n\t\treturn (0);\n\n\t/* If the connection object is not connected; make it so */\n\tif (!evhttp_connected(evcon)) {\n\t\tint res = evhttp_connection_connect_(evcon);\n\t\t/* evhttp_connection_fail_(), which is called through\n\t\t * evhttp_connection_connect_(), assumes that req lies in\n\t\t * evcon->requests.  Thus, enqueue the request in advance and\n\t\t * remove it in the error case. */\n\t\tif (res != 0)\n\t\t\tTAILQ_REMOVE(&evcon->requests, req, next);\n\n\t\treturn (res);\n\t}\n\n\t/*\n\t * If it's connected already and we are the first in the queue,\n\t * then we can dispatch this request immediately.  Otherwise, it\n\t * will be dispatched once the pending requests are completed.\n\t */\n\tif (TAILQ_FIRST(&evcon->requests) == req)\n\t\tevhttp_request_dispatch(evcon);\n\n\treturn (0);\n}\n\nvoid\nevhttp_cancel_request(struct evhttp_request *req)\n{\n\tstruct evhttp_connection *evcon = req->evcon;\n\tif (evcon != NULL) {\n\t\t/* We need to remove it from the connection */\n\t\tif (TAILQ_FIRST(&evcon->requests) == req) {\n\t\t\t/* it's currently being worked on, so reset\n\t\t\t * the connection.\n\t\t\t */\n\t\t\tevhttp_connection_fail_(evcon,\n\t\t\t    EVREQ_HTTP_REQUEST_CANCEL);\n\n\t\t\t/* connection fail freed the request */\n\t\t\treturn;\n\t\t} else {\n\t\t\t/* otherwise, we can just remove it from the\n\t\t\t * queue\n\t\t\t */\n\t\t\tTAILQ_REMOVE(&evcon->requests, req, next);\n\t\t}\n\t}\n\n\tevhttp_request_free_auto(req);\n}\n\n/*\n * Reads data from file descriptor into request structure\n * Request structure needs to be set up correctly.\n */\n\nvoid\nevhttp_start_read_(struct evhttp_connection *evcon)\n{\n\tbufferevent_disable(evcon->bufev, EV_WRITE);\n\tbufferevent_enable(evcon->bufev, EV_READ);\n\n\tevcon->state = EVCON_READING_FIRSTLINE;\n\t/* Reset the bufferevent callbacks */\n\tbufferevent_setcb(evcon->bufev,\n\t    evhttp_read_cb,\n\t    evhttp_write_cb,\n\t    evhttp_error_cb,\n\t    evcon);\n\n\t/* If there's still data pending, process it next time through the\n\t * loop.  Don't do it now; that could get recursive. */\n\tif (evbuffer_get_length(bufferevent_get_input(evcon->bufev))) {\n\t\tevent_deferred_cb_schedule_(get_deferred_queue(evcon),\n\t\t    &evcon->read_more_deferred_cb);\n\t}\n}\n\nvoid\nevhttp_start_write_(struct evhttp_connection *evcon)\n{\n\tbufferevent_disable(evcon->bufev, EV_WRITE);\n\tbufferevent_enable(evcon->bufev, EV_READ);\n\n\tevcon->state = EVCON_WRITING;\n\tevhttp_write_buffer(evcon, evhttp_write_connectioncb, NULL);\n}\n\nstatic void\nevhttp_send_done(struct evhttp_connection *evcon, void *arg)\n{\n\tint need_close;\n\tstruct evhttp_request *req = TAILQ_FIRST(&evcon->requests);\n\tTAILQ_REMOVE(&evcon->requests, req, next);\n\n\tif (req->on_complete_cb != NULL) {\n\t\treq->on_complete_cb(req, req->on_complete_cb_arg);\n\t}\n\n\tneed_close =\n\t    (REQ_VERSION_BEFORE(req, 1, 1) &&\n\t    !evhttp_is_connection_keepalive(req->input_headers)) ||\n\t    evhttp_is_request_connection_close(req);\n\n\tEVUTIL_ASSERT(req->flags & EVHTTP_REQ_OWN_CONNECTION);\n\tevhttp_request_free(req);\n\n\tif (need_close) {\n\t\tevhttp_connection_free(evcon);\n\t\treturn;\n\t}\n\n\t/* we have a persistent connection; try to accept another request. */\n\tif (evhttp_associate_new_request_with_connection(evcon) == -1) {\n\t\tevhttp_connection_free(evcon);\n\t}\n}\n\n/*\n * Returns an error page.\n */\nvoid\nevhttp_send_error(struct evhttp_request *req, int error, const char *reason)\n{\n#define ERR_FORMAT \"<html><head>\" \\\n\t\"<title>%d %s</title>\" \\\n\t\"</head><body>\" \\\n\t\"<h1>%d %s</h1>%s\" \\\n\t\"</body></html>\"\n\n\tstruct evbuffer *buf = evbuffer_new();\n\tstruct evhttp *http = req->evcon->http_server;\n\n\tif (buf == NULL) {\n\t\t/* if we cannot allocate memory; we just drop the connection */\n\t\tevhttp_connection_free(req->evcon);\n\t\treturn;\n\t}\n\n\tevhttp_response_code_(req, error, reason);\n\n\t/* Output error using callback for connection's evhttp, if available */\n\tif ((http->errorcb == NULL) ||\n\t    ((*http->errorcb)(req, buf, error, reason, http->errorcbarg) < 0))\n\t{\n\t\tconst char *heading = evhttp_response_phrase_internal(error);\n\n\t\tevbuffer_drain(buf, evbuffer_get_length(buf));\n\t\tevbuffer_add_printf(buf, ERR_FORMAT,\n\t\t   error, heading, error, heading,\n\t\t   (reason ? reason : \"\"));\n\t}\n\n\tevhttp_send_page_(req, buf);\n\n\tevbuffer_free(buf);\n#undef ERR_FORMAT\n}\nstatic void\nevhttp_send_notfound(struct evhttp_request *req, const char *url)\n{\n#define REASON_FORMAT \"<p>The requested URL %s was not found on this server.</p>\"\n\tchar   *escaped_url = NULL;\n\tchar   *reason = NULL;\n\tsize_t reason_len;\n\n\turl = (url != NULL ? url : req->uri);\n\tif (url != NULL)\n\t\tescaped_url = evhttp_htmlescape(url);\n\n\tif (escaped_url != NULL) {\n\t\treason_len = strlen(REASON_FORMAT)+strlen(escaped_url)+1;\n\t\treason = mm_malloc(reason_len);\n\t}\n\n\tif ((escaped_url != NULL) && (reason != NULL))\n\t\tevutil_snprintf(reason, reason_len, REASON_FORMAT, escaped_url);\n\n\tevhttp_send_error(req, HTTP_NOTFOUND, reason);\n\n\tif (reason != NULL)\n\t\tmm_free(reason);\n\tif (escaped_url != NULL)\n\t\tmm_free(escaped_url);\n#undef REASON_FORMAT\n}\n\n\n/* Requires that headers and response code are already set up */\n\nstatic inline void\nevhttp_send(struct evhttp_request *req, struct evbuffer *databuf)\n{\n\tstruct evhttp_connection *evcon = req->evcon;\n\n\tif (evcon == NULL) {\n\t\tevhttp_request_free(req);\n\t\treturn;\n\t}\n\n\tEVUTIL_ASSERT(TAILQ_FIRST(&evcon->requests) == req);\n\n\t/* we expect no more calls form the user on this request */\n\treq->userdone = 1;\n\n\t/* xxx: not sure if we really should expose the data buffer this way */\n\tif (databuf != NULL)\n\t\tevbuffer_add_buffer(req->output_buffer, databuf);\n\n\t/* Adds headers to the response */\n\tevhttp_make_header(evcon, req);\n\n\tevhttp_write_buffer(evcon, evhttp_send_done, NULL);\n}\n\nvoid\nevhttp_send_reply(struct evhttp_request *req, int code, const char *reason,\n    struct evbuffer *databuf)\n{\n\tevhttp_response_code_(req, code, reason);\n\n\tevhttp_send(req, databuf);\n}\n\nvoid\nevhttp_send_reply_start(struct evhttp_request *req, int code,\n    const char *reason)\n{\n\tevhttp_response_code_(req, code, reason);\n\n\tif (req->evcon == NULL)\n\t\treturn;\n\n\tif (evhttp_find_header(req->output_headers, \"Content-Length\") == NULL &&\n\t    REQ_VERSION_ATLEAST(req, 1, 1) &&\n\t    evhttp_response_needs_body(req)) {\n\t\t/*\n\t\t * prefer HTTP/1.1 chunked encoding to closing the connection;\n\t\t * note RFC 2616 section 4.4 forbids it with Content-Length:\n\t\t * and it's not necessary then anyway.\n\t\t */\n\t\tevhttp_add_header(req->output_headers, \"Transfer-Encoding\",\n\t\t    \"chunked\");\n\t\treq->chunked = 1;\n\t} else {\n\t\treq->chunked = 0;\n\t}\n\tevhttp_make_header(req->evcon, req);\n\tevhttp_write_buffer(req->evcon, NULL, NULL);\n}\n\nvoid\nevhttp_send_reply_chunk_with_cb(struct evhttp_request *req, struct evbuffer *databuf,\n    void (*cb)(struct evhttp_connection *, void *), void *arg)\n{\n\tstruct evhttp_connection *evcon = req->evcon;\n\tstruct evbuffer *output;\n\n\tif (evcon == NULL)\n\t\treturn;\n\n\toutput = bufferevent_get_output(evcon->bufev);\n\n\tif (evbuffer_get_length(databuf) == 0)\n\t\treturn;\n\tif (!evhttp_response_needs_body(req))\n\t\treturn;\n\tif (req->chunked) {\n\t\tevbuffer_add_printf(output, \"%x\\r\\n\",\n\t\t\t\t    (unsigned)evbuffer_get_length(databuf));\n\t}\n\tevbuffer_add_buffer(output, databuf);\n\tif (req->chunked) {\n\t\tevbuffer_add(output, \"\\r\\n\", 2);\n\t}\n\tevhttp_write_buffer(evcon, cb, arg);\n}\n\nstruct bufferevent *\nevhttp_start_ws_(struct evhttp_request *req)\n{\n\tstruct evhttp_connection *evcon = req->evcon;\n\tstruct bufferevent *bufev;\n\n\tevhttp_response_code_(req, HTTP_SWITCH_PROTOCOLS, \"Switching Protocols\");\n\n\tif (req->evcon == NULL)\n\t\treturn NULL;\n\n\tevhttp_make_header(req->evcon, req);\n\tevhttp_write_buffer(req->evcon, NULL, NULL);\n\n\tTAILQ_REMOVE(&evcon->requests, req, next);\n\n\tbufev = evcon->bufev;\n\tevcon->bufev = NULL;\n\tevcon->closecb = NULL;\n\n\tevhttp_request_free(req);\n\tevhttp_connection_free(evcon);\n\treturn bufev;\n}\n\nvoid\nevhttp_send_reply_chunk(struct evhttp_request *req, struct evbuffer *databuf)\n{\n\tevhttp_send_reply_chunk_with_cb(req, databuf, NULL, NULL);\n}\nvoid\nevhttp_send_reply_end(struct evhttp_request *req)\n{\n\tstruct evhttp_connection *evcon = req->evcon;\n\tstruct evbuffer *output;\n\n\tif (evcon == NULL) {\n\t\tevhttp_request_free(req);\n\t\treturn;\n\t}\n\n\toutput = bufferevent_get_output(evcon->bufev);\n\n\t/* we expect no more calls form the user on this request */\n\treq->userdone = 1;\n\n\tif (req->chunked) {\n\t\tevbuffer_add(output, \"0\\r\\n\\r\\n\", 5);\n\t\tevhttp_write_buffer(req->evcon, evhttp_send_done, NULL);\n\t\treq->chunked = 0;\n\t} else if (evbuffer_get_length(output) == 0) {\n\t\t/* let the connection know that we are done with the request */\n\t\tevhttp_send_done(evcon, NULL);\n\t} else {\n\t\t/* make the callback execute after all data has been written */\n\t\tevcon->cb = evhttp_send_done;\n\t\tevcon->cb_arg = NULL;\n\t}\n}\n\nstatic const char *informational_phrases[] = {\n\t/* 100 */ \"Continue\",\n\t/* 101 */ \"Switching Protocols\"\n};\n\nstatic const char *success_phrases[] = {\n\t/* 200 */ \"OK\",\n\t/* 201 */ \"Created\",\n\t/* 202 */ \"Accepted\",\n\t/* 203 */ \"Non-Authoritative Information\",\n\t/* 204 */ \"No Content\",\n\t/* 205 */ \"Reset Content\",\n\t/* 206 */ \"Partial Content\"\n};\n\nstatic const char *redirection_phrases[] = {\n\t/* 300 */ \"Multiple Choices\",\n\t/* 301 */ \"Moved Permanently\",\n\t/* 302 */ \"Found\",\n\t/* 303 */ \"See Other\",\n\t/* 304 */ \"Not Modified\",\n\t/* 305 */ \"Use Proxy\",\n\t/* 307 */ \"Temporary Redirect\"\n};\n\nstatic const char *client_error_phrases[] = {\n\t/* 400 */ \"Bad Request\",\n\t/* 401 */ \"Unauthorized\",\n\t/* 402 */ \"Payment Required\",\n\t/* 403 */ \"Forbidden\",\n\t/* 404 */ \"Not Found\",\n\t/* 405 */ \"Method Not Allowed\",\n\t/* 406 */ \"Not Acceptable\",\n\t/* 407 */ \"Proxy Authentication Required\",\n\t/* 408 */ \"Request Time-out\",\n\t/* 409 */ \"Conflict\",\n\t/* 410 */ \"Gone\",\n\t/* 411 */ \"Length Required\",\n\t/* 412 */ \"Precondition Failed\",\n\t/* 413 */ \"Request Entity Too Large\",\n\t/* 414 */ \"Request-URI Too Large\",\n\t/* 415 */ \"Unsupported Media Type\",\n\t/* 416 */ \"Requested range not satisfiable\",\n\t/* 417 */ \"Expectation Failed\"\n};\n\nstatic const char *server_error_phrases[] = {\n\t/* 500 */ \"Internal Server Error\",\n\t/* 501 */ \"Not Implemented\",\n\t/* 502 */ \"Bad Gateway\",\n\t/* 503 */ \"Service Unavailable\",\n\t/* 504 */ \"Gateway Time-out\",\n\t/* 505 */ \"HTTP Version not supported\"\n};\n\nstruct response_class {\n\tconst char *name;\n\tsize_t num_responses;\n\tconst char **responses;\n};\n\n#ifndef MEMBERSOF\n#define MEMBERSOF(x) (sizeof(x)/sizeof(x[0]))\n#endif\n\nstatic const struct response_class response_classes[] = {\n\t/* 1xx */ { \"Informational\", MEMBERSOF(informational_phrases), informational_phrases },\n\t/* 2xx */ { \"Success\", MEMBERSOF(success_phrases), success_phrases },\n\t/* 3xx */ { \"Redirection\", MEMBERSOF(redirection_phrases), redirection_phrases },\n\t/* 4xx */ { \"Client Error\", MEMBERSOF(client_error_phrases), client_error_phrases },\n\t/* 5xx */ { \"Server Error\", MEMBERSOF(server_error_phrases), server_error_phrases }\n};\n\nstatic const char *\nevhttp_response_phrase_internal(int code)\n{\n\tint klass = code / 100 - 1;\n\tint subcode = code % 100;\n\n\t/* Unknown class - can't do any better here */\n\tif (klass < 0 || klass >= (int) MEMBERSOF(response_classes))\n\t\treturn \"Unknown Status Class\";\n\n\t/* Unknown sub-code, return class name at least */\n\tif (subcode >= (int) response_classes[klass].num_responses)\n\t\treturn response_classes[klass].name;\n\n\treturn response_classes[klass].responses[subcode];\n}\n\nvoid\nevhttp_response_code_(struct evhttp_request *req, int code, const char *reason)\n{\n\treq->kind = EVHTTP_RESPONSE;\n\treq->response_code = code;\n\tif (req->response_code_line != NULL)\n\t\tmm_free(req->response_code_line);\n\tif (reason == NULL)\n\t\treason = evhttp_response_phrase_internal(code);\n\treq->response_code_line = mm_strdup(reason);\n\tif (req->response_code_line == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t/* XXX what else can we do? */\n\t}\n}\n\nvoid\nevhttp_send_page_(struct evhttp_request *req, struct evbuffer *databuf)\n{\n\tif (!req->major || !req->minor) {\n\t\treq->major = 1;\n\t\treq->minor = 1;\n\t}\n\n\tif (req->kind != EVHTTP_RESPONSE)\n\t\tevhttp_response_code_(req, 200, \"OK\");\n\n\tevhttp_clear_headers(req->output_headers);\n\tevhttp_add_header(req->output_headers, \"Content-Type\", \"text/html\");\n\tevhttp_add_header(req->output_headers, \"Connection\", \"close\");\n\n\tevhttp_send(req, databuf);\n}\n\nstatic const char uri_chars[256] = {\n\t/* 0 */\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 1, 1, 0,\n\t1, 1, 1, 1, 1, 1, 1, 1,   1, 1, 0, 0, 0, 0, 0, 0,\n\t/* 64 */\n\t0, 1, 1, 1, 1, 1, 1, 1,   1, 1, 1, 1, 1, 1, 1, 1,\n\t1, 1, 1, 1, 1, 1, 1, 1,   1, 1, 1, 0, 0, 0, 0, 1,\n\t0, 1, 1, 1, 1, 1, 1, 1,   1, 1, 1, 1, 1, 1, 1, 1,\n\t1, 1, 1, 1, 1, 1, 1, 1,   1, 1, 1, 0, 0, 0, 1, 0,\n\t/* 128 */\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t/* 192 */\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0,\n};\n\n#define CHAR_IS_UNRESERVED(c)\t\t\t\\\n\t(uri_chars[(unsigned char)(c)])\n\n/*\n * Helper functions to encode/decode a string for inclusion in a URI.\n * The returned string must be freed by the caller.\n */\nchar *\nevhttp_uriencode(const char *uri, ev_ssize_t len, int space_as_plus)\n{\n\tstruct evbuffer *buf = evbuffer_new();\n\tconst char *p, *end;\n\tchar *result = NULL;\n\n\tif (!buf) {\n\t\tgoto out;\n\t}\n\n\tif (len >= 0) {\n\t\tif (uri + len < uri) {\n\t\t\tgoto out;\n\t\t}\n\n\t\tend = uri + len;\n\t} else {\n\t\tsize_t slen = strlen(uri);\n\n\t\tif (slen >= EV_SSIZE_MAX) {\n\t\t\t/* we don't want to mix signed and unsigned */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (uri + slen < uri) {\n\t\t\tgoto out;\n\t\t}\n\n\t\tend = uri + slen;\n\t}\n\n\tfor (p = uri; p < end; p++) {\n\t\tif (CHAR_IS_UNRESERVED(*p)) {\n\t\t\tevbuffer_add(buf, p, 1);\n\t\t} else if (*p == ' ' && space_as_plus) {\n\t\t\tevbuffer_add(buf, \"+\", 1);\n\t\t} else {\n\t\t\tevbuffer_add_printf(buf, \"%%%02X\", (unsigned char)(*p));\n\t\t}\n\t}\n\n\tevbuffer_add(buf, \"\", 1); /* NUL-terminator. */\n\tresult = mm_malloc(evbuffer_get_length(buf));\n\n\tif (result)\n\t\tevbuffer_remove(buf, result, evbuffer_get_length(buf));\n\nout:\n\tif (buf)\n\t\tevbuffer_free(buf);\n\treturn result;\n}\n\nchar *\nevhttp_encode_uri(const char *str)\n{\n\treturn evhttp_uriencode(str, -1, 0);\n}\n\n/*\n * @param decode_plus_ctl: if 1, we decode plus into space.  If 0, we don't.\n *     If -1, when true we transform plus to space only after we've seen\n *     a ?.  -1 is deprecated.\n * @return the number of bytes written to 'ret'.\n */\nint\nevhttp_decode_uri_internal(\n\tconst char *uri, size_t length, char *ret, int decode_plus_ctl)\n{\n\tchar c;\n\tint j;\n\tint decode_plus = (decode_plus_ctl == 1) ? 1: 0;\n\tunsigned i;\n\n\tfor (i = j = 0; i < length; i++) {\n\t\tc = uri[i];\n\t\tif (c == '?') {\n\t\t\tif (decode_plus_ctl < 0)\n\t\t\t\tdecode_plus = 1;\n\t\t} else if (c == '+' && decode_plus) {\n\t\t\tc = ' ';\n\t\t} else if ((i + 2) < length && c == '%' &&\n\t\t\tEVUTIL_ISXDIGIT_(uri[i+1]) && EVUTIL_ISXDIGIT_(uri[i+2])) {\n\t\t\tchar tmp[3];\n\t\t\ttmp[0] = uri[i+1];\n\t\t\ttmp[1] = uri[i+2];\n\t\t\ttmp[2] = '\\0';\n\t\t\tc = (char)strtol(tmp, NULL, 16);\n\t\t\ti += 2;\n\t\t}\n\t\tret[j++] = c;\n\t}\n\tret[j] = '\\0';\n\n\treturn (j);\n}\n\n/* deprecated */\nchar *\nevhttp_decode_uri(const char *uri)\n{\n\tchar *ret;\n\n\tif ((ret = mm_malloc(strlen(uri) + 1)) == NULL) {\n\t\tevent_warn(\"%s: malloc(%lu)\", __func__,\n\t\t\t  (unsigned long)(strlen(uri) + 1));\n\t\treturn (NULL);\n\t}\n\n\tevhttp_decode_uri_internal(uri, strlen(uri),\n\t    ret, -1 /*always_decode_plus*/);\n\n\treturn (ret);\n}\n\nchar *\nevhttp_uridecode(const char *uri, int decode_plus, size_t *size_out)\n{\n\tchar *ret;\n\tint n;\n\n\tif ((ret = mm_malloc(strlen(uri) + 1)) == NULL) {\n\t\tevent_warn(\"%s: malloc(%lu)\", __func__,\n\t\t\t  (unsigned long)(strlen(uri) + 1));\n\t\treturn (NULL);\n\t}\n\n\tn = evhttp_decode_uri_internal(uri, strlen(uri),\n\t    ret, !!decode_plus/*always_decode_plus*/);\n\n\tif (size_out) {\n\t\tEVUTIL_ASSERT(n >= 0);\n\t\t*size_out = (size_t)n;\n\t}\n\n\treturn (ret);\n}\n\n/*\n * Helper function to parse out arguments in a query.\n * The arguments are separated by key and value.\n */\n\nstatic int\nevhttp_parse_query_impl(const char *str, struct evkeyvalq *headers,\n    int is_whole_uri, unsigned flags)\n{\n\tchar *line=NULL;\n\tchar *p;\n\tconst char *query_part;\n\tint result = -1;\n\tstruct evhttp_uri *uri=NULL;\n\n\tTAILQ_INIT(headers);\n\n\tif (is_whole_uri) {\n\t\turi = evhttp_uri_parse(str);\n\t\tif (!uri)\n\t\t\tgoto error;\n\t\tquery_part = evhttp_uri_get_query(uri);\n\t} else {\n\t\tquery_part = str;\n\t}\n\n\t/* No arguments - we are done */\n\tif (!query_part || !strlen(query_part)) {\n\t\tresult = 0;\n\t\tgoto done;\n\t}\n\n\tif ((line = mm_strdup(query_part)) == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tgoto error;\n\t}\n\n\tp = line;\n\twhile (p != NULL && *p != '\\0') {\n\t\tchar *key, *value, *decoded_value;\n\t\tint err;\n\n\t\tvalue = strsep(&p, \"&\");\n\t\tkey = strsep(&value, \"=\");\n\t\tif (flags & EVHTTP_URI_QUERY_NONCONFORMANT) {\n\t\t\tif (value == NULL)\n\t\t\t\tvalue = (char *)\"\";\n\t\t\tif (*key == '\\0')\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (value == NULL || *key == '\\0')\n\t\t\t\tgoto error;\n\t\t}\n\n\t\tif ((decoded_value = mm_malloc(strlen(value) + 1)) == NULL) {\n\t\t\tevent_warn(\"%s: mm_malloc\", __func__);\n\t\t\tgoto error;\n\t\t}\n\t\tevhttp_decode_uri_internal(value, strlen(value),\n\t\t    decoded_value, 1 /*always_decode_plus*/);\n\t\tevent_debug((\"Query Param: %s -> %s\\n\", key, decoded_value));\n\t\tif (flags & EVHTTP_URI_QUERY_LAST_VAL)\n\t\t\tevhttp_remove_header(headers, key);\n\t\terr = evhttp_add_header_internal(headers, key, decoded_value);\n\t\tmm_free(decoded_value);\n\t\tif (err)\n\t\t\tgoto error;\n\t}\n\n\tresult = 0;\n\tgoto done;\nerror:\n\tevhttp_clear_headers(headers);\ndone:\n\tif (line)\n\t\tmm_free(line);\n\tif (uri)\n\t\tevhttp_uri_free(uri);\n\treturn result;\n}\n\nint\nevhttp_parse_query(const char *uri, struct evkeyvalq *headers)\n{\n\treturn evhttp_parse_query_impl(uri, headers, 1, 0);\n}\nint\nevhttp_parse_query_str(const char *uri, struct evkeyvalq *headers)\n{\n\treturn evhttp_parse_query_impl(uri, headers, 0, 0);\n}\nint\nevhttp_parse_query_str_flags(const char *uri, struct evkeyvalq *headers, unsigned flags)\n{\n\treturn evhttp_parse_query_impl(uri, headers, 0, flags);\n}\n\nstatic struct evhttp_cb *\nevhttp_dispatch_callback(struct httpcbq *callbacks, struct evhttp_request *req)\n{\n\tstruct evhttp_cb *cb;\n\tsize_t offset = 0;\n\tchar *translated;\n\tconst char *path;\n\n\t/* Test for different URLs */\n\tpath = evhttp_uri_get_path(req->uri_elems);\n\toffset = strlen(path);\n\tif ((translated = mm_malloc(offset + 1)) == NULL)\n\t\treturn (NULL);\n\tevhttp_decode_uri_internal(path, offset, translated,\n\t    0 /* decode_plus */);\n\n\tTAILQ_FOREACH(cb, callbacks, next) {\n\t\tif (!strcmp(cb->what, translated)) {\n\t\t\tmm_free(translated);\n\t\t\treturn (cb);\n\t\t}\n\t}\n\n\tmm_free(translated);\n\treturn (NULL);\n}\n\n\nstatic int\nprefix_suffix_match(const char *pattern, const char *name, int ignorecase)\n{\n\tchar c;\n\n\twhile (1) {\n\t\tswitch (c = *pattern++) {\n\t\tcase '\\0':\n\t\t\treturn *name == '\\0';\n\n\t\tcase '*':\n\t\t\twhile (*name != '\\0') {\n\t\t\t\tif (prefix_suffix_match(pattern, name,\n\t\t\t\t\tignorecase))\n\t\t\t\t\treturn (1);\n\t\t\t\t++name;\n\t\t\t}\n\t\t\treturn (0);\n\t\tdefault:\n\t\t\tif (c != *name) {\n\t\t\t\tif (!ignorecase ||\n\t\t\t\t    EVUTIL_TOLOWER_(c) != EVUTIL_TOLOWER_(*name))\n\t\t\t\t\treturn (0);\n\t\t\t}\n\t\t\t++name;\n\t\t}\n\t}\n\t/* NOTREACHED */\n}\n\n/*\n   Search the vhost hierarchy beginning with http for a server alias\n   matching hostname.  If a match is found, and outhttp is non-null,\n   outhttp is set to the matching http object and 1 is returned.\n*/\n\nstatic int\nevhttp_find_alias(struct evhttp *http, struct evhttp **outhttp,\n\t\t  const char *hostname)\n{\n\tstruct evhttp_server_alias *alias;\n\tstruct evhttp *vhost;\n\n\tTAILQ_FOREACH(alias, &http->aliases, next) {\n\t\t/* XXX Do we need to handle IP addresses? */\n\t\tif (!evutil_ascii_strcasecmp(alias->alias, hostname)) {\n\t\t\tif (outhttp)\n\t\t\t\t*outhttp = http;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* XXX It might be good to avoid recursion here, but I don't\n\t   see a way to do that w/o a list. */\n\tTAILQ_FOREACH(vhost, &http->virtualhosts, next_vhost) {\n\t\tif (evhttp_find_alias(vhost, outhttp, hostname))\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n/*\n   Attempts to find the best http object to handle a request for a hostname.\n   All aliases for the root http object and vhosts are searched for an exact\n   match. Then, the vhost hierarchy is traversed again for a matching\n   pattern.\n\n   If an alias or vhost is matched, 1 is returned, and outhttp, if non-null,\n   is set with the best matching http object. If there are no matches, the\n   root http object is stored in outhttp and 0 is returned.\n*/\n\nstatic int\nevhttp_find_vhost(struct evhttp *http, struct evhttp **outhttp,\n\t\t  const char *hostname)\n{\n\tstruct evhttp *vhost;\n\tstruct evhttp *oldhttp;\n\tint match_found = 0;\n\n\tif (evhttp_find_alias(http, outhttp, hostname))\n\t\treturn 1;\n\n\tdo {\n\t\toldhttp = http;\n\t\tTAILQ_FOREACH(vhost, &http->virtualhosts, next_vhost) {\n\t\t\tif (prefix_suffix_match(vhost->vhost_pattern,\n\t\t\t\thostname, 1 /* ignorecase */)) {\n\t\t\t\thttp = vhost;\n\t\t\t\tmatch_found = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} while (oldhttp != http);\n\n\tif (outhttp)\n\t\t*outhttp = http;\n\n\treturn match_found;\n}\n\nstatic void\nevhttp_handle_request(struct evhttp_request *req, void *arg)\n{\n\tstruct evhttp *http = arg;\n\tstruct evhttp_cb *cb = NULL;\n\tconst char *hostname;\n\n\t/* we have a new request on which the user needs to take action */\n\treq->userdone = 0;\n\n\tbufferevent_disable(req->evcon->bufev, EV_READ);\n\n\tif (req->uri == NULL) {\n\t\tevhttp_send_error(req, req->response_code, NULL);\n\t\treturn;\n\t}\n\n\tif ((http->allowed_methods & req->type) == 0) {\n\t\tevent_debug((\"Rejecting disallowed method %x (allowed: %x)\\n\",\n\t\t\t(unsigned)req->type, (unsigned)http->allowed_methods));\n\t\tevhttp_send_error(req, HTTP_NOTIMPLEMENTED, NULL);\n\t\treturn;\n\t}\n\n\t/* handle potential virtual hosts */\n\thostname = evhttp_request_get_host(req);\n\tif (hostname != NULL) {\n\t\tevhttp_find_vhost(http, &http, hostname);\n\t}\n\n\tif ((cb = evhttp_dispatch_callback(&http->callbacks, req)) != NULL) {\n\t\t(*cb->cb)(req, cb->cbarg);\n\t\treturn;\n\t}\n\n\t/* Generic call back */\n\tif (http->gencb) {\n\t\t(*http->gencb)(req, http->gencbarg);\n\t\treturn;\n\t} else\n\t\tevhttp_send_notfound(req, NULL);\n}\n\n/* Listener callback when a connection arrives at a server. */\nstatic void\naccept_socket_cb(struct evconnlistener *listener, evutil_socket_t nfd, struct sockaddr *peer_sa, int peer_socklen, void *arg)\n{\n\tstruct evhttp_bound_socket *bound = arg;\n\n\tstruct evhttp *http = bound->http;\n\n\tstruct bufferevent *bev = NULL;\n\tif (bound->bevcb)\n\t\tbev = bound->bevcb(http->base, bound->bevcbarg);\n\n\tevhttp_get_request(http, nfd, peer_sa, peer_socklen, bev);\n}\n\nint\nevhttp_bind_socket(struct evhttp *http, const char *address, ev_uint16_t port)\n{\n\tstruct evhttp_bound_socket *bound =\n\t\tevhttp_bind_socket_with_handle(http, address, port);\n\tif (bound == NULL)\n\t\treturn (-1);\n\treturn (0);\n}\n\nstruct evhttp_bound_socket *\nevhttp_bind_socket_with_handle(struct evhttp *http, const char *address, ev_uint16_t port)\n{\n\tevutil_socket_t fd;\n\tstruct evhttp_bound_socket *bound;\n\tint serrno;\n\n\tif ((fd = bind_socket(address, port, 1 /*reuse*/)) == -1)\n\t\treturn (NULL);\n\n\tif (listen(fd, 128) == -1) {\n\t\tserrno = EVUTIL_SOCKET_ERROR();\n\t\tevent_sock_warn(fd, \"%s: listen\", __func__);\n\t\tevutil_closesocket(fd);\n\t\tEVUTIL_SET_SOCKET_ERROR(serrno);\n\t\treturn (NULL);\n\t}\n\n\tbound = evhttp_accept_socket_with_handle(http, fd);\n\n\tif (bound != NULL) {\n\t\tevent_debug((\"Bound to port %d - Awaiting connections ... \",\n\t\t\tport));\n\t\treturn (bound);\n\t}\n\n\treturn (NULL);\n}\n\nint\nevhttp_accept_socket(struct evhttp *http, evutil_socket_t fd)\n{\n\tstruct evhttp_bound_socket *bound =\n\t\tevhttp_accept_socket_with_handle(http, fd);\n\tif (bound == NULL)\n\t\treturn (-1);\n\treturn (0);\n}\n\nvoid\nevhttp_foreach_bound_socket(struct evhttp *http,\n                            evhttp_bound_socket_foreach_fn *function,\n                            void *argument)\n{\n\tstruct evhttp_bound_socket *bound;\n\n\tTAILQ_FOREACH(bound, &http->sockets, next)\n\t\tfunction(bound, argument);\n}\n\nstruct evhttp_bound_socket *\nevhttp_accept_socket_with_handle(struct evhttp *http, evutil_socket_t fd)\n{\n\tstruct evhttp_bound_socket *bound;\n\tstruct evconnlistener *listener;\n\tconst int flags =\n\t    LEV_OPT_REUSEABLE|LEV_OPT_CLOSE_ON_EXEC|LEV_OPT_CLOSE_ON_FREE;\n\n\tlistener = evconnlistener_new(http->base, NULL, NULL,\n\t    flags,\n\t    0, /* Backlog is '0' because we already said 'listen' */\n\t    fd);\n\tif (!listener)\n\t\treturn (NULL);\n\n\tbound = evhttp_bind_listener(http, listener);\n\tif (!bound) {\n\t\tevconnlistener_free(listener);\n\t\treturn (NULL);\n\t}\n\treturn (bound);\n}\n\nstruct evhttp_bound_socket *\nevhttp_bind_listener(struct evhttp *http, struct evconnlistener *listener)\n{\n\tstruct evhttp_bound_socket *bound;\n\n\tbound = mm_malloc(sizeof(struct evhttp_bound_socket));\n\tif (bound == NULL)\n\t\treturn (NULL);\n\n\tbound->listener = listener;\n\tbound->bevcb = NULL;\n\tbound->http = http;\n\tTAILQ_INSERT_TAIL(&http->sockets, bound, next);\n\n\tevconnlistener_set_cb(listener, accept_socket_cb, bound);\n\treturn bound;\n}\n\nevutil_socket_t\nevhttp_bound_socket_get_fd(struct evhttp_bound_socket *bound)\n{\n\treturn evconnlistener_get_fd(bound->listener);\n}\n\nstruct evconnlistener *\nevhttp_bound_socket_get_listener(struct evhttp_bound_socket *bound)\n{\n\treturn bound->listener;\n}\n\nvoid\nevhttp_bound_set_bevcb(struct evhttp_bound_socket *bound,\n    struct bufferevent* (*cb)(struct event_base *, void *), void *cbarg)\n{\n\tbound->bevcb = cb;\n\tbound->bevcbarg = cbarg;\n}\n\nvoid\nevhttp_del_accept_socket(struct evhttp *http, struct evhttp_bound_socket *bound)\n{\n\tTAILQ_REMOVE(&http->sockets, bound, next);\n\tevconnlistener_free(bound->listener);\n\tmm_free(bound);\n}\n\nstatic struct evhttp*\nevhttp_new_object(void)\n{\n\tstruct evhttp *http = NULL;\n\n\tif ((http = mm_calloc(1, sizeof(struct evhttp))) == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\treturn (NULL);\n\t}\n\n\tevutil_timerclear(&http->timeout_read);\n\tevutil_timerclear(&http->timeout_write);\n\n\tevhttp_set_max_headers_size(http, EV_SIZE_MAX);\n\tevhttp_set_max_body_size(http, EV_SIZE_MAX);\n\tevhttp_set_default_content_type(http, \"text/html; charset=ISO-8859-1\");\n\tevhttp_set_allowed_methods(http,\n\t    EVHTTP_REQ_GET |\n\t    EVHTTP_REQ_POST |\n\t    EVHTTP_REQ_HEAD |\n\t    EVHTTP_REQ_PUT |\n\t    EVHTTP_REQ_DELETE);\n\n\tTAILQ_INIT(&http->sockets);\n\tTAILQ_INIT(&http->callbacks);\n\tTAILQ_INIT(&http->connections);\n\tTAILQ_INIT(&http->ws_sessions);\n\tTAILQ_INIT(&http->virtualhosts);\n\tTAILQ_INIT(&http->aliases);\n\n\treturn (http);\n}\n\nstruct evhttp *\nevhttp_new(struct event_base *base)\n{\n\tstruct evhttp *http = NULL;\n\n\thttp = evhttp_new_object();\n\tif (http == NULL)\n\t\treturn (NULL);\n\thttp->base = base;\n\n\treturn (http);\n}\n\n/*\n * Start a web server on the specified address and port.\n */\n\nstruct evhttp *\nevhttp_start(const char *address, ev_uint16_t port)\n{\n\tstruct evhttp *http = NULL;\n\n\thttp = evhttp_new_object();\n\tif (http == NULL)\n\t\treturn (NULL);\n\tif (evhttp_bind_socket(http, address, port) == -1) {\n\t\tmm_free(http);\n\t\treturn (NULL);\n\t}\n\n\treturn (http);\n}\n\nvoid\nevhttp_free(struct evhttp* http)\n{\n\tstruct evhttp_cb *http_cb;\n\tstruct evhttp_connection *evcon;\n\tstruct evws_connection *evws;\n\tstruct evhttp_bound_socket *bound;\n\tstruct evhttp* vhost;\n\tstruct evhttp_server_alias *alias;\n\n\t/* Remove the accepting part */\n\twhile ((bound = TAILQ_FIRST(&http->sockets)) != NULL) {\n\t\tTAILQ_REMOVE(&http->sockets, bound, next);\n\n\t\tevconnlistener_free(bound->listener);\n\n\t\tmm_free(bound);\n\t}\n\n\twhile ((evcon = TAILQ_FIRST(&http->connections)) != NULL) {\n\t\t/* evhttp_connection_free removes the connection */\n\t\tevhttp_connection_free(evcon);\n\t}\n\n\twhile ((evws = TAILQ_FIRST(&http->ws_sessions)) != NULL) {\n\t\tevws_connection_free(evws);\n\t}\n\n\twhile ((http_cb = TAILQ_FIRST(&http->callbacks)) != NULL) {\n\t\tTAILQ_REMOVE(&http->callbacks, http_cb, next);\n\t\tmm_free(http_cb->what);\n\t\tmm_free(http_cb);\n\t}\n\n\twhile ((vhost = TAILQ_FIRST(&http->virtualhosts)) != NULL) {\n\t\tTAILQ_REMOVE(&http->virtualhosts, vhost, next_vhost);\n\n\t\tevhttp_free(vhost);\n\t}\n\n\tif (http->vhost_pattern != NULL)\n\t\tmm_free(http->vhost_pattern);\n\n\twhile ((alias = TAILQ_FIRST(&http->aliases)) != NULL) {\n\t\tTAILQ_REMOVE(&http->aliases, alias, next);\n\t\tmm_free(alias->alias);\n\t\tmm_free(alias);\n\t}\n\n\tmm_free(http);\n}\n\nint\nevhttp_add_virtual_host(struct evhttp* http, const char *pattern,\n    struct evhttp* vhost)\n{\n\t/* a vhost can only be a vhost once and should not have bound sockets */\n\tif (vhost->vhost_pattern != NULL ||\n\t    TAILQ_FIRST(&vhost->sockets) != NULL)\n\t\treturn (-1);\n\n\tvhost->vhost_pattern = mm_strdup(pattern);\n\tif (vhost->vhost_pattern == NULL)\n\t\treturn (-1);\n\n\tTAILQ_INSERT_TAIL(&http->virtualhosts, vhost, next_vhost);\n\n\treturn (0);\n}\n\nint\nevhttp_remove_virtual_host(struct evhttp* http, struct evhttp* vhost)\n{\n\tif (vhost->vhost_pattern == NULL)\n\t\treturn (-1);\n\n\tTAILQ_REMOVE(&http->virtualhosts, vhost, next_vhost);\n\n\tmm_free(vhost->vhost_pattern);\n\tvhost->vhost_pattern = NULL;\n\n\treturn (0);\n}\n\nint\nevhttp_add_server_alias(struct evhttp *http, const char *alias)\n{\n\tstruct evhttp_server_alias *evalias;\n\n\tevalias = mm_calloc(1, sizeof(*evalias));\n\tif (!evalias)\n\t\treturn -1;\n\n\tevalias->alias = mm_strdup(alias);\n\tif (!evalias->alias) {\n\t\tmm_free(evalias);\n\t\treturn -1;\n\t}\n\n\tTAILQ_INSERT_TAIL(&http->aliases, evalias, next);\n\n\treturn 0;\n}\n\nint\nevhttp_remove_server_alias(struct evhttp *http, const char *alias)\n{\n\tstruct evhttp_server_alias *evalias;\n\n\tTAILQ_FOREACH(evalias, &http->aliases, next) {\n\t\tif (evutil_ascii_strcasecmp(evalias->alias, alias) == 0) {\n\t\t\tTAILQ_REMOVE(&http->aliases, evalias, next);\n\t\t\tmm_free(evalias->alias);\n\t\t\tmm_free(evalias);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nvoid\nevhttp_set_timeout(struct evhttp* http, int timeout)\n{\n\tevhttp_set_timeout_(&http->timeout_read,  timeout, -1);\n\tevhttp_set_timeout_(&http->timeout_write, timeout, -1);\n}\nvoid\nevhttp_set_timeout_tv(struct evhttp* http, const struct timeval* tv)\n{\n\tevhttp_set_timeout_tv_(&http->timeout_read, tv, -1);\n\tevhttp_set_timeout_tv_(&http->timeout_write, tv, -1);\n}\nvoid\nevhttp_set_read_timeout_tv(struct evhttp* http, const struct timeval* tv)\n{\n\tevhttp_set_timeout_tv_(&http->timeout_read, tv, -1);\n}\nvoid\nevhttp_set_write_timeout_tv(struct evhttp* http, const struct timeval* tv)\n{\n\tevhttp_set_timeout_tv_(&http->timeout_write, tv, -1);\n}\n\nint evhttp_set_flags(struct evhttp *http, int flags)\n{\n\tint avail_flags = 0;\n\tavail_flags |= EVHTTP_SERVER_LINGERING_CLOSE;\n\n\tif (flags & ~avail_flags)\n\t\treturn 1;\n\thttp->flags &= ~avail_flags;\n\n\thttp->flags |= flags;\n\n\treturn 0;\n}\n\nvoid\nevhttp_set_max_headers_size(struct evhttp* http, ev_ssize_t max_headers_size)\n{\n\tif (max_headers_size < 0)\n\t\thttp->default_max_headers_size = EV_SIZE_MAX;\n\telse\n\t\thttp->default_max_headers_size = max_headers_size;\n}\n\nvoid\nevhttp_set_max_body_size(struct evhttp* http, ev_ssize_t max_body_size)\n{\n\tif (max_body_size < 0)\n\t\thttp->default_max_body_size = EV_UINT64_MAX;\n\telse\n\t\thttp->default_max_body_size = max_body_size;\n}\n\nvoid\nevhttp_set_max_connections(struct evhttp* http, int max_connections)\n{\n\tif (max_connections < 0)\n\t\thttp->connection_max = 0;\n\telse\n\t\thttp->connection_max = max_connections;\n}\n\nint\nevhttp_get_connection_count(struct evhttp* http)\n{\n\treturn http->connection_cnt;\n}\n\nvoid\nevhttp_set_default_content_type(struct evhttp *http,\n\tconst char *content_type) {\n\thttp->default_content_type = content_type;\n}\n\nvoid\nevhttp_set_allowed_methods(struct evhttp* http, ev_uint32_t methods)\n{\n\thttp->allowed_methods = methods;\n}\n\nvoid\nevhttp_set_ext_method_cmp(struct evhttp *http, evhttp_ext_method_cb cmp)\n{\n\thttp->ext_method_cmp = cmp;\n}\n\nint\nevhttp_set_cb(struct evhttp *http, const char *uri,\n    void (*cb)(struct evhttp_request *, void *), void *cbarg)\n{\n\tstruct evhttp_cb *http_cb;\n\n\tTAILQ_FOREACH(http_cb, &http->callbacks, next) {\n\t\tif (strcmp(http_cb->what, uri) == 0)\n\t\t\treturn (-1);\n\t}\n\n\tif ((http_cb = mm_calloc(1, sizeof(struct evhttp_cb))) == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\treturn (-2);\n\t}\n\n\thttp_cb->what = mm_strdup(uri);\n\tif (http_cb->what == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tmm_free(http_cb);\n\t\treturn (-3);\n\t}\n\thttp_cb->cb = cb;\n\thttp_cb->cbarg = cbarg;\n\n\tTAILQ_INSERT_TAIL(&http->callbacks, http_cb, next);\n\n\treturn (0);\n}\n\nint\nevhttp_del_cb(struct evhttp *http, const char *uri)\n{\n\tstruct evhttp_cb *http_cb;\n\n\tTAILQ_FOREACH(http_cb, &http->callbacks, next) {\n\t\tif (strcmp(http_cb->what, uri) == 0)\n\t\t\tbreak;\n\t}\n\tif (http_cb == NULL)\n\t\treturn (-1);\n\n\tTAILQ_REMOVE(&http->callbacks, http_cb, next);\n\tmm_free(http_cb->what);\n\tmm_free(http_cb);\n\n\treturn (0);\n}\n\nvoid\nevhttp_set_gencb(struct evhttp *http,\n    void (*cb)(struct evhttp_request *, void *), void *cbarg)\n{\n\thttp->gencb = cb;\n\thttp->gencbarg = cbarg;\n}\n\nvoid\nevhttp_set_bevcb(struct evhttp *http,\n    struct bufferevent* (*cb)(struct event_base *, void *), void *cbarg)\n{\n\thttp->bevcb = cb;\n\thttp->bevcbarg = cbarg;\n}\n\nvoid\nevhttp_set_newreqcb(struct evhttp *http,\n    int (*cb)(struct evhttp_request *, void *), void *cbarg)\n{\n\thttp->newreqcb = cb;\n\thttp->newreqcbarg = cbarg;\n}\nvoid\nevhttp_set_errorcb(struct evhttp *http,\n    int (*cb)(struct evhttp_request *, struct evbuffer *, int, const char *, void *),\n    void *cbarg)\n{\n\thttp->errorcb = cb;\n\thttp->errorcbarg = cbarg;\n}\n\n/*\n * Request related functions\n */\n\nstruct evhttp_request *\nevhttp_request_new(void (*cb)(struct evhttp_request *, void *), void *arg)\n{\n\tstruct evhttp_request *req = NULL;\n\n\t/* Allocate request structure */\n\tif ((req = mm_calloc(1, sizeof(struct evhttp_request))) == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto error;\n\t}\n\n\treq->headers_size = 0;\n\treq->body_size = 0;\n\n\treq->kind = EVHTTP_RESPONSE;\n\treq->input_headers = mm_calloc(1, sizeof(struct evkeyvalq));\n\tif (req->input_headers == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto error;\n\t}\n\tTAILQ_INIT(req->input_headers);\n\n\treq->output_headers = mm_calloc(1, sizeof(struct evkeyvalq));\n\tif (req->output_headers == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto error;\n\t}\n\tTAILQ_INIT(req->output_headers);\n\n\tif ((req->input_buffer = evbuffer_new()) == NULL) {\n\t\tevent_warn(\"%s: evbuffer_new\", __func__);\n\t\tgoto error;\n\t}\n\n\tif ((req->output_buffer = evbuffer_new()) == NULL) {\n\t\tevent_warn(\"%s: evbuffer_new\", __func__);\n\t\tgoto error;\n\t}\n\n\treq->cb = cb;\n\treq->cb_arg = arg;\n\n\treturn (req);\n\n error:\n\tif (req != NULL)\n\t\tevhttp_request_free(req);\n\treturn (NULL);\n}\n\nvoid\nevhttp_request_free(struct evhttp_request *req)\n{\n\tif ((req->flags & EVHTTP_REQ_DEFER_FREE) != 0) {\n\t\treq->flags |= EVHTTP_REQ_NEEDS_FREE;\n\t\treturn;\n\t}\n\n\tif (req->remote_host != NULL)\n\t\tmm_free(req->remote_host);\n\tif (req->uri != NULL)\n\t\tmm_free(req->uri);\n\tif (req->uri_elems != NULL)\n\t\tevhttp_uri_free(req->uri_elems);\n\tif (req->response_code_line != NULL)\n\t\tmm_free(req->response_code_line);\n\tif (req->host_cache != NULL)\n\t\tmm_free(req->host_cache);\n\n\tevhttp_clear_headers(req->input_headers);\n\tmm_free(req->input_headers);\n\n\tevhttp_clear_headers(req->output_headers);\n\tmm_free(req->output_headers);\n\n\tif (req->input_buffer != NULL)\n\t\tevbuffer_free(req->input_buffer);\n\n\tif (req->output_buffer != NULL)\n\t\tevbuffer_free(req->output_buffer);\n\n\tmm_free(req);\n}\n\nvoid\nevhttp_request_own(struct evhttp_request *req)\n{\n\treq->flags |= EVHTTP_USER_OWNED;\n}\n\nint\nevhttp_request_is_owned(struct evhttp_request *req)\n{\n\treturn (req->flags & EVHTTP_USER_OWNED) != 0;\n}\n\nstruct evhttp_connection *\nevhttp_request_get_connection(struct evhttp_request *req)\n{\n\treturn req->evcon;\n}\n\nstruct event_base *\nevhttp_connection_get_base(struct evhttp_connection *conn)\n{\n\treturn conn->base;\n}\n\nvoid\nevhttp_request_set_chunked_cb(struct evhttp_request *req,\n    void (*cb)(struct evhttp_request *, void *))\n{\n\treq->chunk_cb = cb;\n}\n\nvoid\nevhttp_request_set_header_cb(struct evhttp_request *req,\n    int (*cb)(struct evhttp_request *, void *))\n{\n\treq->header_cb = cb;\n}\n\nvoid\nevhttp_request_set_error_cb(struct evhttp_request *req,\n    void (*cb)(enum evhttp_request_error, void *))\n{\n\treq->error_cb = cb;\n}\n\nvoid\nevhttp_request_set_on_complete_cb(struct evhttp_request *req,\n    void (*cb)(struct evhttp_request *, void *), void *cb_arg)\n{\n\treq->on_complete_cb = cb;\n\treq->on_complete_cb_arg = cb_arg;\n}\n\n/*\n * Allows for inspection of the request URI\n */\n\nconst char *\nevhttp_request_get_uri(const struct evhttp_request *req) {\n\tif (req->uri == NULL)\n\t\tevent_debug((\"%s: request %p has no uri\\n\", __func__, (void *)req));\n\treturn (req->uri);\n}\n\nconst struct evhttp_uri *\nevhttp_request_get_evhttp_uri(const struct evhttp_request *req) {\n\tif (req->uri_elems == NULL)\n\t\tevent_debug((\"%s: request %p has no uri elems\\n\",\n\t\t\t    __func__, (void *)req));\n\treturn (req->uri_elems);\n}\n\nconst char *\nevhttp_request_get_host(struct evhttp_request *req)\n{\n\tconst char *host = NULL;\n\n\tif (req->host_cache)\n\t\treturn req->host_cache;\n\n\tif (req->uri_elems)\n\t\thost = evhttp_uri_get_host(req->uri_elems);\n\tif (!host && req->input_headers) {\n\t\tconst char *p;\n\t\tsize_t len;\n\n\t\thost = evhttp_find_header(req->input_headers, \"Host\");\n\t\t/* The Host: header may include a port. Remove it here\n\t\t   to be consistent with uri_elems case above. */\n\t\tif (host) {\n\t\t\tp = host + strlen(host) - 1;\n\t\t\twhile (p > host && EVUTIL_ISDIGIT_(*p))\n\t\t\t\t--p;\n\t\t\tif (p > host && *p == ':') {\n\t\t\t\tlen = p - host;\n\t\t\t\treq->host_cache = mm_malloc(len + 1);\n\t\t\t\tif (!req->host_cache) {\n\t\t\t\t\tevent_warn(\"%s: malloc\", __func__);\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\t\t\t\tmemcpy(req->host_cache, host, len);\n\t\t\t\treq->host_cache[len] = '\\0';\n\t\t\t\thost = req->host_cache;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn host;\n}\n\nenum evhttp_cmd_type\nevhttp_request_get_command(const struct evhttp_request *req) {\n\treturn (req->type);\n}\n\nint\nevhttp_request_get_response_code(const struct evhttp_request *req)\n{\n\treturn req->response_code;\n}\n\nconst char *\nevhttp_request_get_response_code_line(const struct evhttp_request *req)\n{\n\treturn req->response_code_line;\n}\n\n/** Returns the input headers */\nstruct evkeyvalq *evhttp_request_get_input_headers(struct evhttp_request *req)\n{\n\treturn (req->input_headers);\n}\n\n/** Returns the output headers */\nstruct evkeyvalq *evhttp_request_get_output_headers(struct evhttp_request *req)\n{\n\treturn (req->output_headers);\n}\n\n/** Returns the input buffer */\nstruct evbuffer *evhttp_request_get_input_buffer(struct evhttp_request *req)\n{\n\treturn (req->input_buffer);\n}\n\n/** Returns the output buffer */\nstruct evbuffer *evhttp_request_get_output_buffer(struct evhttp_request *req)\n{\n\treturn (req->output_buffer);\n}\n\n\n/*\n * Takes a file descriptor to read a request from.\n * The callback is executed once the whole request has been read.\n */\n\nstatic struct evhttp_connection*\nevhttp_get_request_connection(\n\tstruct evhttp* http,\n\tevutil_socket_t fd, struct sockaddr *sa, ev_socklen_t salen,\n\tstruct bufferevent* bev)\n{\n\tstruct evhttp_connection *evcon;\n\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_UN\n\tif (sa->sa_family == AF_UNIX) {\n\t\tstruct sockaddr_un *sa_un = (struct sockaddr_un *)sa;\n\t\tsa_un->sun_path[0] = '\\0';\n\t}\n#endif\n\n#ifndef _WIN32\n\tif (sa->sa_family == AF_UNIX) {\n\t\tstruct sockaddr_un *sockaddr = (struct sockaddr_un *)sa;\n\n\t\tevent_debug((\"%s: new request from unix socket on \"\n\t\t\tEV_SOCK_FMT\"\\n\", __func__, EV_SOCK_ARG(fd)));\n\n\t\t/* we need a connection object to put the http request on */\n\t\tif (!bev && http->bevcb != NULL) {\n\t\t\tbev = (*http->bevcb)(http->base, http->bevcbarg);\n\t\t}\n\n\t\tevcon = evhttp_connection_base_bufferevent_unix_new(http->base,\n\t\t\tbev, sockaddr->sun_path);\n\t}\n\telse\n#endif\n\t{\n\t\tchar *hostname = NULL, *portname = NULL;\n\n\t\tname_from_addr(sa, salen, &hostname, &portname);\n\t\tif (hostname == NULL || portname == NULL) {\n\t\t\tif (hostname) mm_free(hostname);\n\t\t\tif (portname) mm_free(portname);\n\t\t\treturn (NULL);\n\t\t}\n\n\t\tevent_debug((\"%s: new request from %s:%s on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, hostname, portname, EV_SOCK_ARG(fd)));\n\n\t\t/* we need a connection object to put the http request on */\n\t\tif (!bev && http->bevcb != NULL) {\n\t\t\tbev = (*http->bevcb)(http->base, http->bevcbarg);\n\t\t}\n\t\tevcon = evhttp_connection_base_bufferevent_new(\n\t\t\thttp->base, NULL, bev, hostname, atoi(portname));\n\t\tmm_free(hostname);\n\t\tmm_free(portname);\n\t}\n\tif (evcon == NULL)\n\t\treturn (NULL);\n\n\tevcon->max_headers_size = http->default_max_headers_size;\n\tevcon->max_body_size = http->default_max_body_size;\n\tif (http->flags & EVHTTP_SERVER_LINGERING_CLOSE)\n\t\tevcon->flags |= EVHTTP_CON_LINGERING_CLOSE;\n\n\tevcon->flags |= EVHTTP_CON_INCOMING;\n\tevcon->state = EVCON_READING_FIRSTLINE;\n\n\tif (bufferevent_replacefd(evcon->bufev, fd))\n\t\tgoto err;\n\tif (bufferevent_enable(evcon->bufev, EV_READ))\n\t\tgoto err;\n\tif (bufferevent_disable(evcon->bufev, EV_WRITE))\n\t\tgoto err;\n\tbufferevent_socket_set_conn_address_(evcon->bufev, sa, salen);\n\n\treturn (evcon);\n\nerr:\n\tevhttp_connection_free(evcon);\n\treturn (NULL);\n}\n\nstatic int\nevhttp_associate_new_request_with_connection(struct evhttp_connection *evcon)\n{\n\tstruct evhttp *http = evcon->http_server;\n\tstruct evhttp_request *req;\n\tif ((req = evhttp_request_new(evhttp_handle_request, http)) == NULL)\n\t\treturn (-1);\n\n\tif (evcon->address != NULL) {\n\t\tif ((req->remote_host = mm_strdup(evcon->address)) == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\tevhttp_request_free(req);\n\t\t\treturn (-1);\n\t\t}\n\t}\n\treq->remote_port = evcon->port;\n\n\treq->evcon = evcon;\t/* the request ends up owning the connection */\n\treq->flags |= EVHTTP_REQ_OWN_CONNECTION;\n\n\t/* We did not present the request to the user yet, so treat it\n\t * as if the user was done with the request.  This allows us\n\t * to free the request on a persistent connection if the\n\t * client drops it without sending a request.\n\t */\n\treq->userdone = 1;\n\treq->kind = EVHTTP_REQUEST;\n\n\tif (http->newreqcb && http->newreqcb(req, http->newreqcbarg) == -1) {\n\t\tevhttp_request_free(req);\n\t\treturn (-1);\n\t}\n\n\tTAILQ_INSERT_TAIL(&evcon->requests, req, next);\n\n\tevhttp_start_read_(evcon);\n\n\treturn (0);\n}\n\nstatic void\nevhttp_get_request(struct evhttp *http, evutil_socket_t fd,\n    struct sockaddr *sa, ev_socklen_t salen,\n    struct bufferevent *bev)\n{\n\tstruct evhttp_connection *evcon;\n\n\tevcon = evhttp_get_request_connection(http, fd, sa, salen, bev);\n\tif (evcon == NULL) {\n\t\tevent_sock_warn(fd, \"%s: cannot get connection on \"EV_SOCK_FMT,\n\t\t    __func__, EV_SOCK_ARG(fd));\n\t\tevutil_closesocket(fd);\n\t\treturn;\n\t}\n\n\t/* the timeout can be used by the server to close idle connections */\n\tif (evutil_timerisset(&http->timeout_read))\n\t\tevhttp_connection_set_read_timeout_tv(evcon,  &http->timeout_read);\n\tif (evutil_timerisset(&http->timeout_write))\n\t\tevhttp_connection_set_write_timeout_tv(evcon, &http->timeout_write);\n\n\t/*\n\t * if we want to accept more than one request on a connection,\n\t * we need to know which http server it belongs to.\n\t */\n\tevcon->http_server = http;\n\tevcon->ext_method_cmp = http->ext_method_cmp;\n\tTAILQ_INSERT_TAIL(&http->connections, evcon, next);\n\thttp->connection_cnt++;\n\n\t/* send \"service unavailable\" if we've reached the connection limit */\n\tif (http->connection_max && http->connection_max < http->connection_cnt) {\n\t\tstruct evhttp_request *req;\n\n\t\tif ((req = evhttp_request_new(evhttp_handle_request, http)) == NULL) {\n\t\t\tevhttp_connection_free(evcon);\n\t\t\treturn;\n\t\t}\n\n\t\treq->evcon = evcon;\t/* the request owns the connection */\n\t\treq->flags |= EVHTTP_REQ_OWN_CONNECTION;\n\t\treq->kind = EVHTTP_REQUEST;\n\t\t/* note, req->remote_host not needed since we don't read */\n\n\t\tTAILQ_INSERT_TAIL(&evcon->requests, req, next);\n\n\t\t/* send error to client */\n\t\tevcon->state = EVCON_WRITING;\n\t\tbufferevent_enable(evcon->bufev, EV_READ); /* enable close events */\n\t\tevhttp_send_error(req, HTTP_SERVUNAVAIL, NULL);\n\n\t} else if (evhttp_associate_new_request_with_connection(evcon) == -1)\n\t\tevhttp_connection_free(evcon);\n}\n\n\n/*\n * Network helper functions that we do not want to export to the rest of\n * the world.\n */\n\nstatic void\nname_from_addr(struct sockaddr *sa, ev_socklen_t salen,\n    char **phost, char **pport)\n{\n\tchar ntop[NI_MAXHOST];\n\tchar strport[NI_MAXSERV];\n\tint ni_result;\n\n#ifdef EVENT__HAVE_GETNAMEINFO\n\tni_result = getnameinfo(sa, salen,\n\t\tntop, sizeof(ntop), strport, sizeof(strport),\n\t\tNI_NUMERICHOST|NI_NUMERICSERV);\n\n\tif (ni_result != 0) {\n#ifdef EAI_SYSTEM\n\t\t/* Windows doesn't have an EAI_SYSTEM. */\n\t\tif (ni_result == EAI_SYSTEM)\n\t\t\tevent_err(1, \"getnameinfo failed\");\n\t\telse\n#endif\n\t\t\tevent_errx(1, \"getnameinfo failed: %s\", gai_strerror(ni_result));\n\t\treturn;\n\t}\n#else\n\tni_result = fake_getnameinfo(sa, salen,\n\t\tntop, sizeof(ntop), strport, sizeof(strport),\n\t\tNI_NUMERICHOST|NI_NUMERICSERV);\n\tif (ni_result != 0)\n\t\t\treturn;\n#endif\n\n\t*phost = mm_strdup(ntop);\n\t*pport = mm_strdup(strport);\n}\n\n/* Create a non-blocking socket and bind it */\nstatic evutil_socket_t\ncreate_bind_socket_nonblock(struct evutil_addrinfo *ai, int reuse)\n{\n\tevutil_socket_t fd;\n\n\tint r;\n\tint serrno;\n\n\t/* Create listen socket */\n\tfd = evutil_socket_(ai ? ai->ai_family : AF_INET,\n\t    SOCK_STREAM|EVUTIL_SOCK_NONBLOCK|EVUTIL_SOCK_CLOEXEC, 0);\n\tif (fd == -1) {\n\t\t\tevent_sock_warn(-1, \"socket\");\n\t\t\treturn (-1);\n\t}\n\n\t/* TODO(panjf2000): make this TCP keep-alive value configurable */\n\tif (evutil_set_tcp_keepalive(fd, 1, 300) < 0)\n\t\tgoto out;\n\tif (reuse) {\n\t\tif (evutil_make_listen_socket_reuseable(fd) < 0)\n\t\t\tgoto out;\n\t}\n\n\tif (ai != NULL) {\n\t\tr = bind(fd, ai->ai_addr, (ev_socklen_t)ai->ai_addrlen);\n\t\tif (r == -1)\n\t\t\tgoto out;\n\t}\n\n\treturn (fd);\n\n out:\n\tserrno = EVUTIL_SOCKET_ERROR();\n\tevutil_closesocket(fd);\n\tEVUTIL_SET_SOCKET_ERROR(serrno);\n\treturn (-1);\n}\n\nstatic struct evutil_addrinfo *\nmake_addrinfo(const char *address, ev_uint16_t port)\n{\n\tstruct evutil_addrinfo *ai = NULL;\n\n\tstruct evutil_addrinfo hints;\n\tchar strport[NI_MAXSERV];\n\tint ai_result;\n\n\tmemset(&hints, 0, sizeof(hints));\n\thints.ai_family = AF_UNSPEC;\n\thints.ai_socktype = SOCK_STREAM;\n\t/* turn NULL hostname into INADDR_ANY, and skip looking up any address\n\t * types we don't have an interface to connect to. */\n\thints.ai_flags = EVUTIL_AI_PASSIVE|EVUTIL_AI_ADDRCONFIG;\n\tevutil_snprintf(strport, sizeof(strport), \"%d\", port);\n\tif ((ai_result = evutil_getaddrinfo(address, strport, &hints, &ai))\n\t    != 0) {\n\t\tif (ai_result == EVUTIL_EAI_SYSTEM)\n\t\t\tevent_warn(\"getaddrinfo\");\n\t\telse\n\t\t\tevent_warnx(\"getaddrinfo: %s\",\n\t\t\t    evutil_gai_strerror(ai_result));\n\t\treturn (NULL);\n\t}\n\n\treturn (ai);\n}\n\nstatic evutil_socket_t\nbind_socket(const char *address, ev_uint16_t port, int reuse)\n{\n\tevutil_socket_t fd;\n\tstruct evutil_addrinfo *aitop = NULL;\n\n\t/* just create an unbound socket */\n\tif (address == NULL && port == 0)\n\t\treturn create_bind_socket_nonblock(NULL, 0);\n\n\taitop = make_addrinfo(address, port);\n\n\tif (aitop == NULL)\n\t\treturn (-1);\n\n\tfd = create_bind_socket_nonblock(aitop, reuse);\n\n\tevutil_freeaddrinfo(aitop);\n\n\treturn (fd);\n}\n\nstruct evhttp_uri {\n\tunsigned flags;\n\tchar *scheme; /* scheme; e.g http, ftp etc */\n\tchar *userinfo; /* userinfo (typically username:pass), or NULL */\n\tchar *host; /* hostname, IP address, or NULL */\n\tint port; /* port, or zero */\n#ifndef _WIN32\n\tchar *unixsocket; /* unix domain socket or NULL */\n#endif\n\tchar *path; /* path, or \"\". */\n\tchar *query; /* query, or NULL */\n\tchar *fragment; /* fragment or NULL */\n};\n\nstruct evhttp_uri *\nevhttp_uri_new(void)\n{\n\tstruct evhttp_uri *uri = mm_calloc(1, sizeof(struct evhttp_uri));\n\tif (uri)\n\t\turi->port = -1;\n\treturn uri;\n}\n\nvoid\nevhttp_uri_set_flags(struct evhttp_uri *uri, unsigned flags)\n{\n\turi->flags = flags;\n}\n\n/* Return true if the string starting at s and ending immediately before eos\n * is a valid URI scheme according to RFC3986\n */\nstatic int\nscheme_ok(const char *s, const char *eos)\n{\n\t/* scheme = ALPHA *( ALPHA / DIGIT / \"+\" / \"-\" / \".\" ) */\n\tEVUTIL_ASSERT(eos >= s);\n\tif (s == eos)\n\t\treturn 0;\n\tif (!EVUTIL_ISALPHA_(*s))\n\t\treturn 0;\n\twhile (++s < eos) {\n\t\tif (! EVUTIL_ISALNUM_(*s) &&\n\t\t    *s != '+' && *s != '-' && *s != '.')\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n#define SUBDELIMS \"!$&'()*+,;=\"\n\n/* Return true iff [s..eos) is a valid userinfo */\nstatic int\nuserinfo_ok(const char *s, const char *eos)\n{\n\twhile (s < eos) {\n\t\tif (CHAR_IS_UNRESERVED(*s) ||\n\t\t    strchr(SUBDELIMS, *s) ||\n\t\t    *s == ':')\n\t\t\t++s;\n\t\telse if (*s == '%' && s+2 < eos &&\n\t\t    EVUTIL_ISXDIGIT_(s[1]) &&\n\t\t    EVUTIL_ISXDIGIT_(s[2]))\n\t\t\ts += 3;\n\t\telse\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int\nregname_ok(const char *s, const char *eos)\n{\n\twhile (s && s<eos) {\n\t\tif (CHAR_IS_UNRESERVED(*s) ||\n\t\t    strchr(SUBDELIMS, *s))\n\t\t\t++s;\n\t\telse if (*s == '%' &&\n\t\t    EVUTIL_ISXDIGIT_(s[1]) &&\n\t\t    EVUTIL_ISXDIGIT_(s[2]))\n\t\t\ts += 3;\n\t\telse\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int\nparse_port(const char *s, const char *eos)\n{\n\tint portnum = 0;\n\twhile (s < eos) {\n\t\tif (! EVUTIL_ISDIGIT_(*s))\n\t\t\treturn -1;\n\t\tportnum = (portnum * 10) + (*s - '0');\n\t\tif (portnum < 0)\n\t\t\treturn -1;\n\t\tif (portnum > 65535)\n\t\t\treturn -1;\n\t\t++s;\n\t}\n\treturn portnum;\n}\n\n/* returns 0 for bad, 1 for ipv6, 2 for IPvFuture */\nstatic int\nbracket_addr_ok(const char *s, const char *eos)\n{\n\tif (s + 3 > eos || *s != '[' || *(eos-1) != ']')\n\t\treturn 0;\n\tif (s[1] == 'v') {\n\t\t/* IPvFuture, or junk.\n\t\t   \"v\" 1*HEXDIG \".\" 1*( unreserved / sub-delims / \":\" )\n\t\t */\n\t\ts += 2; /* skip [v */\n\t\t--eos;\n\t\tif (!EVUTIL_ISXDIGIT_(*s)) /*require at least one*/\n\t\t\treturn 0;\n\t\twhile (s < eos && *s != '.') {\n\t\t\tif (EVUTIL_ISXDIGIT_(*s))\n\t\t\t\t++s;\n\t\t\telse\n\t\t\t\treturn 0;\n\t\t}\n\t\tif (*s != '.')\n\t\t\treturn 0;\n\t\t++s;\n\t\twhile (s < eos) {\n\t\t\tif (CHAR_IS_UNRESERVED(*s) ||\n\t\t\t    strchr(SUBDELIMS, *s) ||\n\t\t\t    *s == ':')\n\t\t\t\t++s;\n\t\t\telse\n\t\t\t\treturn 0;\n\t\t}\n\t\treturn 2;\n\t} else {\n\t\t/* IPv6, or junk */\n\t\tchar buf[64];\n\t\tev_ssize_t n_chars = eos-s-2;\n\t\tstruct in6_addr in6;\n\t\tif (n_chars >= 64) /* way too long */\n\t\t\treturn 0;\n\t\tmemcpy(buf, s+1, n_chars);\n\t\tbuf[n_chars]='\\0';\n\t\treturn (evutil_inet_pton(AF_INET6,buf,&in6)==1) ? 1 : 0;\n\t}\n}\n\nstatic int\nparse_authority(struct evhttp_uri *uri, char *s, char *eos, unsigned *flags)\n{\n\tsize_t len;\n\tchar *cp, *port;\n\n\tEVUTIL_ASSERT(eos);\n\tif (eos == s) {\n\t\turi->host = mm_strdup(\"\");\n\t\tif (uri->host == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t/* Optionally, we start with \"userinfo@\" */\n\n\tcp = strchr(s, '@');\n\tif (cp && cp < eos) {\n\t\tif (! userinfo_ok(s,cp))\n\t\t\treturn -1;\n\t\t*cp++ = '\\0';\n\t\turi->userinfo = mm_strdup(s);\n\t\tif (uri->userinfo == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t} else {\n\t\tcp = s;\n\t}\n\n#ifndef _WIN32\n\tif (*flags & EVHTTP_URI_UNIX_SOCKET && !strncmp(cp, \"unix:\", 5)) {\n\t\tchar *e = strchr(cp + 5, ':');\n\t\tif (e) {\n\t\t\t*e = '\\0';\n\t\t\turi->unixsocket = mm_strdup(cp + 5);\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n#endif\n\n\t/* Optionally, we end with \":port\" */\n\tfor (port=eos-1; port >= cp && EVUTIL_ISDIGIT_(*port); --port)\n\t\t;\n\tif (port >= cp && *port == ':') {\n\t\tif (port+1 == eos) /* Leave port unspecified; the RFC allows a\n\t\t\t\t    * nil port */\n\t\t\turi->port = -1;\n\t\telse if ((uri->port = parse_port(port+1, eos))<0)\n\t\t\treturn -1;\n\t\teos = port;\n\t}\n\t/* Now, cp..eos holds the \"host\" port, which can be an IPv4Address,\n\t * an IP-Literal, or a reg-name */\n\tEVUTIL_ASSERT(eos >= cp);\n\tlen = eos-cp;\n\tif (*cp == '[' && eos >= cp+2 && *(eos-1) == ']') {\n\t\t/* IPv6address, IP-Literal, or junk. */\n\t\tif (! bracket_addr_ok(cp, eos))\n\t\t\treturn -1;\n\t\tif (*flags & EVHTTP_URI_HOST_STRIP_BRACKETS)\n\t\t\tlen = eos-cp-2;\n\t} else {\n\t\t/* Make sure the host part is ok. */\n\t\tif (! regname_ok(cp,eos)) /* Match IPv4Address or reg-name */\n\t\t\treturn -1;\n\t}\n\n\turi->host = mm_malloc(len+1);\n\tif (uri->host == NULL) {\n\t\tevent_warn(\"%s: malloc\", __func__);\n\t\treturn -1;\n\t}\n\tif (*cp == '[' && *flags & EVHTTP_URI_HOST_STRIP_BRACKETS) {\n\t\tmemcpy(uri->host, cp+1, len);\n\t\t*flags |= _EVHTTP_URI_HOST_HAS_BRACKETS;\n\t} else {\n\t\tmemcpy(uri->host, cp, len);\n\t}\n\turi->host[len] = '\\0';\n\treturn 0;\n\n}\n\nstatic char *\nend_of_authority(char *cp)\n{\n\twhile (*cp) {\n\t\tif (*cp == '?' || *cp == '#' || *cp == '/')\n\t\t\treturn cp;\n\t\t++cp;\n\t}\n\treturn cp;\n}\n\nenum uri_part {\n\tPART_PATH,\n\tPART_QUERY,\n\tPART_FRAGMENT\n};\n\n/* Return the character after the longest prefix of 'cp' that matches...\n *   *pchar / \"/\" if allow_qchars is false, or\n *   *(pchar / \"/\" / \"?\") if allow_qchars is true.\n */\nstatic char *\nend_of_path(char *cp, enum uri_part part, unsigned flags)\n{\n\tif (flags & EVHTTP_URI_NONCONFORMANT) {\n\t\t/* If NONCONFORMANT:\n\t\t *   Path is everything up to a # or ? or nul.\n\t\t *   Query is everything up a # or nul\n\t\t *   Fragment is everything up to a nul.\n\t\t */\n\t\tswitch (part) {\n\t\tcase PART_PATH:\n\t\t\twhile (*cp && *cp != '#' && *cp != '?')\n\t\t\t\t++cp;\n\t\t\tbreak;\n\t\tcase PART_QUERY:\n\t\t\twhile (*cp && *cp != '#')\n\t\t\t\t++cp;\n\t\t\tbreak;\n\t\tcase PART_FRAGMENT:\n\t\t\tcp += strlen(cp);\n\t\t\tbreak;\n\t\t};\n\t\treturn cp;\n\t}\n\n\twhile (*cp) {\n\t\tif (CHAR_IS_UNRESERVED(*cp) ||\n\t\t    strchr(SUBDELIMS, *cp) ||\n\t\t    *cp == ':' || *cp == '@' || *cp == '/')\n\t\t\t++cp;\n\t\telse if (*cp == '%' && EVUTIL_ISXDIGIT_(cp[1]) &&\n\t\t    EVUTIL_ISXDIGIT_(cp[2]))\n\t\t\tcp += 3;\n\t\telse if (*cp == '?' && part != PART_PATH)\n\t\t\t++cp;\n\t\telse\n\t\t\treturn cp;\n\t}\n\treturn cp;\n}\n\nstatic int\npath_matches_noscheme(const char *cp)\n{\n\twhile (*cp) {\n\t\tif (*cp == ':')\n\t\t\treturn 0;\n\t\telse if (*cp == '/')\n\t\t\treturn 1;\n\t\t++cp;\n\t}\n\treturn 1;\n}\n\nstruct evhttp_uri *\nevhttp_uri_parse(const char *source_uri)\n{\n\treturn evhttp_uri_parse_with_flags(source_uri, 0);\n}\n\nstruct evhttp_uri *\nevhttp_uri_parse_with_flags(const char *source_uri, unsigned flags)\n{\n\tchar *readbuf = NULL, *readp = NULL, *token = NULL, *query = NULL;\n\tchar *path = NULL, *fragment = NULL;\n\tint got_authority = 0;\n\n\tstruct evhttp_uri *uri = mm_calloc(1, sizeof(struct evhttp_uri));\n\tif (uri == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto err;\n\t}\n\turi->port = -1;\n\turi->flags = flags;\n\n\treadbuf = mm_strdup(source_uri);\n\tif (readbuf == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tgoto err;\n\t}\n\n\treadp = readbuf;\n\ttoken = NULL;\n\n\t/* We try to follow RFC3986 here as much as we can, and match\n\t   the productions\n\n\t      URI = scheme \":\" hier-part [ \"?\" query ] [ \"#\" fragment ]\n\n\t      relative-ref  = relative-part [ \"?\" query ] [ \"#\" fragment ]\n\t */\n\n\t/* 1. scheme: */\n\ttoken = strchr(readp, ':');\n\tif (token && scheme_ok(readp,token)) {\n\t\t*token = '\\0';\n\t\turi->scheme = mm_strdup(readp);\n\t\tif (uri->scheme == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\tgoto err;\n\t\t}\n\t\treadp = token+1; /* eat : */\n\t}\n\n\t/* 2. Optionally, \"//\" then an 'authority' part. */\n\tif (readp[0]=='/' && readp[1] == '/') {\n\t\tchar *authority;\n\t\treadp += 2;\n\t\tauthority = readp;\n\t\tpath = end_of_authority(readp);\n\t\tif (parse_authority(uri, authority, path, &uri->flags) < 0)\n\t\t\tgoto err;\n\t\treadp = path;\n\t\tgot_authority = 1;\n\t}\n\n\t/* 3. Query: path-abempty, path-absolute, path-rootless, or path-empty\n\t */\n\tpath = readp;\n\treadp = end_of_path(path, PART_PATH, flags);\n\n\t/* Query */\n\tif (*readp == '?') {\n\t\t*readp = '\\0';\n\t\t++readp;\n\t\tquery = readp;\n\t\treadp = end_of_path(readp, PART_QUERY, flags);\n\t}\n\t/* fragment */\n\tif (*readp == '#') {\n\t\t*readp = '\\0';\n\t\t++readp;\n\t\tfragment = readp;\n\t\treadp = end_of_path(readp, PART_FRAGMENT, flags);\n\t}\n\tif (*readp != '\\0') {\n\t\tgoto err;\n\t}\n\n\t/* These next two cases may be unreachable; I'm leaving them\n\t * in to be defensive. */\n\t/* If you didn't get an authority, the path can't begin with \"//\" */\n\tif (!got_authority && path[0]=='/' && path[1]=='/')\n\t\tgoto err;\n\t/* If you did get an authority, the path must begin with \"/\" or be\n\t * empty. */\n\tif (got_authority && path[0] != '/' && path[0] != '\\0')\n\t\tgoto err;\n\t/* (End of maybe-unreachable cases) */\n\n\t/* If there was no scheme, the first part of the path (if any) must\n\t * have no colon in it. */\n\tif (! uri->scheme && !path_matches_noscheme(path))\n\t\tgoto err;\n\n\tEVUTIL_ASSERT(path);\n\turi->path = mm_strdup(path);\n\tif (uri->path == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tgoto err;\n\t}\n\n\tif (query) {\n\t\turi->query = mm_strdup(query);\n\t\tif (uri->query == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\tgoto err;\n\t\t}\n\t}\n\tif (fragment) {\n\t\turi->fragment = mm_strdup(fragment);\n\t\tif (uri->fragment == NULL) {\n\t\t\tevent_warn(\"%s: strdup\", __func__);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tmm_free(readbuf);\n\n\treturn uri;\nerr:\n\tif (uri)\n\t\tevhttp_uri_free(uri);\n\tif (readbuf)\n\t\tmm_free(readbuf);\n\treturn NULL;\n}\n\nstatic struct evhttp_uri *\nevhttp_uri_parse_authority(char *source_uri, unsigned flags)\n{\n\tstruct evhttp_uri *uri = mm_calloc(1, sizeof(struct evhttp_uri));\n\tchar *end;\n\n\tif (uri == NULL) {\n\t\tevent_warn(\"%s: calloc\", __func__);\n\t\tgoto err;\n\t}\n\turi->port = -1;\n\turi->flags = flags;\n\n\tend = end_of_authority(source_uri);\n\tif (parse_authority(uri, source_uri, end, &uri->flags) < 0)\n\t\tgoto err;\n\n\turi->path = mm_strdup(\"\");\n\tif (uri->path == NULL) {\n\t\tevent_warn(\"%s: strdup\", __func__);\n\t\tgoto err;\n\t}\n\n\treturn uri;\nerr:\n\tif (uri)\n\t\tevhttp_uri_free(uri);\n\treturn NULL;\n}\n\nvoid\nevhttp_uri_free(struct evhttp_uri *uri)\n{\n#define URI_FREE_STR_(f)\t\t\\\n\tif (uri->f) {\t\t\t\\\n\t\tmm_free(uri->f);\t\t\\\n\t}\n\n\tURI_FREE_STR_(scheme);\n\tURI_FREE_STR_(userinfo);\n\tURI_FREE_STR_(host);\n#ifndef _WIN32\n\tURI_FREE_STR_(unixsocket);\n#endif\n\tURI_FREE_STR_(path);\n\tURI_FREE_STR_(query);\n\tURI_FREE_STR_(fragment);\n\n\tmm_free(uri);\n#undef URI_FREE_STR_\n}\n\nchar *\nevhttp_uri_join(const struct evhttp_uri *uri, char *buf, size_t limit)\n{\n\tstruct evbuffer *tmp = 0;\n\tsize_t joined_size = 0;\n\tchar *output = NULL;\n\n#define URI_ADD_(f)\tevbuffer_add(tmp, uri->f, strlen(uri->f))\n\n\tif (!uri || !buf || !limit)\n\t\treturn NULL;\n\n\ttmp = evbuffer_new();\n\tif (!tmp)\n\t\treturn NULL;\n\n\tif (uri->scheme) {\n\t\tURI_ADD_(scheme);\n\t\tevbuffer_add(tmp, \":\", 1);\n\t}\n#ifndef _WIN32\n\tif (uri->unixsocket) {\n\t\tevbuffer_add(tmp, \"//\", 2);\n\t\tif (uri->userinfo)\n\t\t\tevbuffer_add_printf(tmp, \"%s@\", uri->userinfo);\n\t\tevbuffer_add_printf(tmp, \"unix:%s:\", uri->unixsocket);\n\t}\n\telse\n#endif\n\tif (uri->host) {\n\t\tevbuffer_add(tmp, \"//\", 2);\n\t\tif (uri->userinfo)\n\t\t\tevbuffer_add_printf(tmp,\"%s@\", uri->userinfo);\n\t\tif (uri->flags & _EVHTTP_URI_HOST_HAS_BRACKETS) {\n\t\t\tevbuffer_add(tmp, \"[\", 1);\n\t\t\tURI_ADD_(host);\n\t\t\tevbuffer_add(tmp, \"]\", 1);\n\t\t} else {\n\t\t\tURI_ADD_(host);\n\t\t}\n\t\tif (uri->port >= 0)\n\t\t\tevbuffer_add_printf(tmp,\":%d\", uri->port);\n\n\t\tif (uri->path && uri->path[0] != '/' && uri->path[0] != '\\0')\n\t\t\tgoto err;\n\t}\n\n\tif (uri->path)\n\t\tURI_ADD_(path);\n\n\tif (uri->query) {\n\t\tevbuffer_add(tmp, \"?\", 1);\n\t\tURI_ADD_(query);\n\t}\n\n\tif (uri->fragment) {\n\t\tevbuffer_add(tmp, \"#\", 1);\n\t\tURI_ADD_(fragment);\n\t}\n\n\tevbuffer_add(tmp, \"\\0\", 1); /* NUL */\n\n\tjoined_size = evbuffer_get_length(tmp);\n\n\tif (joined_size > limit) {\n\t\t/* It doesn't fit. */\n\t\tevbuffer_free(tmp);\n\t\treturn NULL;\n\t}\n\tevbuffer_remove(tmp, buf, joined_size);\n\n\toutput = buf;\nerr:\n\tevbuffer_free(tmp);\n\n\treturn output;\n#undef URI_ADD_\n}\n\nconst char *\nevhttp_uri_get_scheme(const struct evhttp_uri *uri)\n{\n\treturn uri->scheme;\n}\nconst char *\nevhttp_uri_get_userinfo(const struct evhttp_uri *uri)\n{\n\treturn uri->userinfo;\n}\nconst char *\nevhttp_uri_get_host(const struct evhttp_uri *uri)\n{\n\treturn uri->host;\n}\n#ifndef _WIN32\nconst char *\nevhttp_uri_get_unixsocket(const struct evhttp_uri *uri)\n{\n\treturn uri->unixsocket;\n}\n#endif\nint\nevhttp_uri_get_port(const struct evhttp_uri *uri)\n{\n\treturn uri->port;\n}\nconst char *\nevhttp_uri_get_path(const struct evhttp_uri *uri)\n{\n\treturn uri->path;\n}\nconst char *\nevhttp_uri_get_query(const struct evhttp_uri *uri)\n{\n\treturn uri->query;\n}\nconst char *\nevhttp_uri_get_fragment(const struct evhttp_uri *uri)\n{\n\treturn uri->fragment;\n}\n\n#define URI_SET_STR_(f) do {\t\t\t\t\t\\\n\tif (uri->f)\t\t\t\t\t\t\\\n\t\tmm_free(uri->f);\t\t\t\t\\\n\tif (f) {\t\t\t\t\t\t\\\n\t\tif ((uri->f = mm_strdup(f)) == NULL) {\t\t\\\n\t\t\tevent_warn(\"%s: strdup()\", __func__);\t\\\n\t\t\treturn -1;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t} else {\t\t\t\t\t\t\\\n\t\turi->f = NULL;\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\t} while(0)\n\nint\nevhttp_uri_set_scheme(struct evhttp_uri *uri, const char *scheme)\n{\n\tif (scheme && !scheme_ok(scheme, scheme+strlen(scheme)))\n\t\treturn -1;\n\n\tURI_SET_STR_(scheme);\n\treturn 0;\n}\nint\nevhttp_uri_set_userinfo(struct evhttp_uri *uri, const char *userinfo)\n{\n\tif (userinfo && !userinfo_ok(userinfo, userinfo+strlen(userinfo)))\n\t\treturn -1;\n\tURI_SET_STR_(userinfo);\n\treturn 0;\n}\nint\nevhttp_uri_set_host(struct evhttp_uri *uri, const char *host)\n{\n\tsize_t len = 0;\n\n\tif (host) {\n\t\tlen = strlen(host);\n\n\t\tif (host[0] == '[') {\n\t\t\tif (! bracket_addr_ok(host, host+len))\n\t\t\t\treturn -1;\n\t\t} else {\n\t\t\tif (! regname_ok(host, host+len))\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (host && host[0] == '[' && uri->flags & EVHTTP_URI_HOST_STRIP_BRACKETS) {\n\t\tchar *new_host;\n\n\t\tlen -= 2;\n\t\tnew_host = mm_realloc(uri->host, len+1);\n\t\tif (!new_host) {\n\t\t\tfree(uri->host);\n\t\t\turi->host = NULL;\n\t\t} else {\n\t\t\tmemcpy(new_host, host+1, len);\n\t\t\tnew_host[len] = '\\0';\n\t\t\turi->host = new_host;\n\t\t}\n\t\turi->flags |= _EVHTTP_URI_HOST_HAS_BRACKETS;\n\t} else {\n\t\tURI_SET_STR_(host);\n\t\turi->flags &= ~_EVHTTP_URI_HOST_HAS_BRACKETS;\n\t}\n\n\treturn 0;\n}\n#ifndef _WIN32\nint\nevhttp_uri_set_unixsocket(struct evhttp_uri *uri, const char *unixsocket)\n{\n\tURI_SET_STR_(unixsocket);\n\treturn 0;\n}\n#endif\nint\nevhttp_uri_set_port(struct evhttp_uri *uri, int port)\n{\n\tif (port < -1)\n\t\treturn -1;\n\turi->port = port;\n\treturn 0;\n}\n#define end_of_cpath(cp,p,f) \\\n\t((const char*)(end_of_path(((char*)(cp)), (p), (f))))\n\nint\nevhttp_uri_set_path(struct evhttp_uri *uri, const char *path)\n{\n\tif (path && end_of_cpath(path, PART_PATH, uri->flags) != path+strlen(path))\n\t\treturn -1;\n\n\tURI_SET_STR_(path);\n\treturn 0;\n}\nint\nevhttp_uri_set_query(struct evhttp_uri *uri, const char *query)\n{\n\tif (query && end_of_cpath(query, PART_QUERY, uri->flags) != query+strlen(query))\n\t\treturn -1;\n\tURI_SET_STR_(query);\n\treturn 0;\n}\nint\nevhttp_uri_set_fragment(struct evhttp_uri *uri, const char *fragment)\n{\n\tif (fragment && end_of_cpath(fragment, PART_FRAGMENT, uri->flags) != fragment+strlen(fragment))\n\t\treturn -1;\n\tURI_SET_STR_(fragment);\n\treturn 0;\n}\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "iocp-internal.h",
          "type": "blob",
          "size": 7.8056640625,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifndef IOCP_INTERNAL_H_INCLUDED_\n#define IOCP_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nstruct event_overlapped;\nstruct event_iocp_port;\nstruct evbuffer;\ntypedef void (*iocp_callback)(struct event_overlapped *, ev_uintptr_t, ev_ssize_t, int success);\n\n/* This whole file is actually win32 only. We wrap the structures in a win32\n * ifdef so that we can test-compile code that uses these interfaces on\n * non-win32 platforms. */\n#ifdef _WIN32\n\n/**\n   Internal use only.  Wraps an OVERLAPPED that we're using for libevent\n   functionality.  Whenever an event_iocp_port gets an event for a given\n   OVERLAPPED*, it upcasts the pointer to an event_overlapped, and calls the\n   iocp_callback function with the event_overlapped, the iocp key, and the\n   number of bytes transferred as arguments.\n */\nstruct event_overlapped {\n\tOVERLAPPED overlapped;\n\tiocp_callback cb;\n};\n\n/* Mingw's headers don't define LPFN_ACCEPTEX. */\n\ntypedef BOOL (WINAPI *AcceptExPtr)(SOCKET, SOCKET, PVOID, DWORD, DWORD, DWORD, LPDWORD, LPOVERLAPPED);\ntypedef BOOL (WINAPI *ConnectExPtr)(SOCKET, const struct sockaddr *, int, PVOID, DWORD, LPDWORD, LPOVERLAPPED);\ntypedef void (WINAPI *GetAcceptExSockaddrsPtr)(PVOID, DWORD, DWORD, DWORD, LPSOCKADDR *, LPINT, LPSOCKADDR *, LPINT);\n\n/** Internal use only. Holds pointers to functions that only some versions of\n    Windows provide.\n */\nstruct win32_extension_fns {\n\tAcceptExPtr AcceptEx;\n\tConnectExPtr ConnectEx;\n\tGetAcceptExSockaddrsPtr GetAcceptExSockaddrs;\n};\n\n/**\n    Internal use only. Stores a Windows IO Completion port, along with\n    related data.\n */\nstruct event_iocp_port {\n\t/** The port itself */\n\tHANDLE port;\n\t/* A lock to cover internal structures. */\n\tCRITICAL_SECTION lock;\n\t/** Number of threads ever open on the port. */\n\tshort n_threads;\n\t/** True iff we're shutting down all the threads on this port */\n\tshort shutdown;\n\t/** How often the threads on this port check for shutdown and other\n\t * conditions */\n\tlong ms;\n\t/* The threads that are waiting for events. */\n\tHANDLE *threads;\n\t/** Number of threads currently open on this port. */\n\tshort n_live_threads;\n\t/** A semaphore to signal when we are done shutting down. */\n\tHANDLE *shutdownSemaphore;\n};\n\nEVENT2_EXPORT_SYMBOL\nconst struct win32_extension_fns *event_get_win32_extension_fns_(void);\n#else\n/* Dummy definition so we can test-compile more things on unix. */\nstruct event_overlapped {\n\tiocp_callback cb;\n};\n#endif\n\n/** Initialize the fields in an event_overlapped.\n\n    @param overlapped The struct event_overlapped to initialize\n    @param cb The callback that should be invoked once the IO operation has\n\tfinished.\n */\nEVENT2_EXPORT_SYMBOL\nvoid event_overlapped_init_(struct event_overlapped *, iocp_callback cb);\n\n/** Allocate and return a new evbuffer that supports overlapped IO on a given\n    socket.  The socket must be associated with an IO completion port using\n    event_iocp_port_associate_.\n*/\nEVENT2_EXPORT_SYMBOL\nstruct evbuffer *evbuffer_overlapped_new_(evutil_socket_t fd);\n\n/** XXXX Document (nickm) */\nevutil_socket_t evbuffer_overlapped_get_fd_(struct evbuffer *buf);\n\nvoid evbuffer_overlapped_set_fd_(struct evbuffer *buf, evutil_socket_t fd);\n\n/** Start reading data onto the end of an overlapped evbuffer.\n\n    An evbuffer can only have one read pending at a time.  While the read\n    is in progress, no other data may be added to the end of the buffer.\n    The buffer must be created with event_overlapped_init_().\n    evbuffer_commit_read_() must be called in the completion callback.\n\n    @param buf The buffer to read onto\n    @param n The number of bytes to try to read.\n    @param ol Overlapped object with associated completion callback.\n    @return 0 on success, -1 on error.\n */\nEVENT2_EXPORT_SYMBOL\nint evbuffer_launch_read_(struct evbuffer *buf, size_t n, struct event_overlapped *ol);\n\n/** Start writing data from the start of an evbuffer.\n\n    An evbuffer can only have one write pending at a time.  While the write is\n    in progress, no other data may be removed from the front of the buffer.\n    The buffer must be created with event_overlapped_init_().\n    evbuffer_commit_write_() must be called in the completion callback.\n\n    @param buf The buffer to read onto\n    @param n The number of bytes to try to read.\n    @param ol Overlapped object with associated completion callback.\n    @return 0 on success, -1 on error.\n */\nEVENT2_EXPORT_SYMBOL\nint evbuffer_launch_write_(struct evbuffer *buf, ev_ssize_t n, struct event_overlapped *ol);\n\n/** XXX document */\nEVENT2_EXPORT_SYMBOL\nvoid evbuffer_commit_read_(struct evbuffer *, ev_ssize_t);\nEVENT2_EXPORT_SYMBOL\nvoid evbuffer_commit_write_(struct evbuffer *, ev_ssize_t);\n\n/** Create an IOCP, and launch its worker threads.  Internal use only.\n\n    This interface is unstable, and will change.\n */\nEVENT2_EXPORT_SYMBOL\nstruct event_iocp_port *event_iocp_port_launch_(int n_cpus);\n\n/** Associate a file descriptor with an iocp, such that overlapped IO on the\n    fd will happen on one of the iocp's worker threads.\n*/\nEVENT2_EXPORT_SYMBOL\nint event_iocp_port_associate_(struct event_iocp_port *port, evutil_socket_t fd,\n    ev_uintptr_t key);\n\n/** Tell all threads serving an iocp to stop.  Wait for up to waitMsec for all\n    the threads to finish whatever they're doing.  If waitMsec is -1, wait\n    as long as required.  If all the threads are done, free the port and return\n    0. Otherwise, return -1.  If you get a -1 return value, it is safe to call\n    this function again.\n*/\nEVENT2_EXPORT_SYMBOL\nint event_iocp_shutdown_(struct event_iocp_port *port, long waitMsec);\n\n/* FIXME document. */\nEVENT2_EXPORT_SYMBOL\nint event_iocp_activate_overlapped_(struct event_iocp_port *port,\n    struct event_overlapped *o,\n    ev_uintptr_t key, ev_uint32_t n_bytes);\n\nstruct event_base;\n/* FIXME document. */\nEVENT2_EXPORT_SYMBOL\nstruct event_iocp_port *event_base_get_iocp_(struct event_base *base);\n\n/* FIXME document. */\nEVENT2_EXPORT_SYMBOL\nint event_base_start_iocp_(struct event_base *base, int n_cpus);\nvoid event_base_stop_iocp_(struct event_base *base);\n\n/* FIXME document. */\nEVENT2_EXPORT_SYMBOL\nstruct bufferevent *bufferevent_async_new_(struct event_base *base,\n    evutil_socket_t fd, int options);\n\n/* FIXME document. */\nvoid bufferevent_async_set_connected_(struct bufferevent *bev);\nint bufferevent_async_can_connect_(struct bufferevent *bev);\nint bufferevent_async_connect_(struct bufferevent *bev, evutil_socket_t fd,\n\tconst struct sockaddr *sa, int socklen);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "ipv6-internal.h",
          "type": "blob",
          "size": 2.455078125,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* Internal use only: Fake IPv6 structures and values on platforms that\n * do not have them */\n\n#ifndef IPV6_INTERNAL_H_INCLUDED_\n#define IPV6_INTERNAL_H_INCLUDED_\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#include \"event2/util.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/** @file ipv6-internal.h\n *\n * Replacement types and functions for platforms that don't support ipv6\n * properly.\n */\n\n#ifndef EVENT__HAVE_STRUCT_IN6_ADDR\nstruct in6_addr {\n\tev_uint8_t s6_addr[16];\n};\n#endif\n\n#ifndef EVENT__HAVE_SA_FAMILY_T\ntypedef int sa_family_t;\n#endif\n\n#ifndef EVENT__HAVE_STRUCT_SOCKADDR_IN6\nstruct sockaddr_in6 {\n\t/* This will fail if we find a struct sockaddr that doesn't have\n\t * sa_family as the first element. */\n\tsa_family_t sin6_family;\n\tev_uint16_t sin6_port;\n\tstruct in6_addr sin6_addr;\n};\n#endif\n\n#ifndef AF_INET6\n#define AF_INET6 3333\n#endif\n#ifndef PF_INET6\n#define PF_INET6 AF_INET6\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "kqueue-internal.h",
          "type": "blob",
          "size": 1.9443359375,
          "content": "/*\n * Copyright (c) 2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef KQUEUE_INTERNAL_H_INCLUDED_\n#define KQUEUE_INTERNAL_H_INCLUDED_\n\n/** Notification function, used to tell an event base to wake up from another\n * thread.  Only works when event_kq_add_notify_event_() has previously been\n * called successfully on that base. */\nint event_kq_notify_base_(struct event_base *base);\n\n/** Prepare a kqueue-using event base to receive notifications via an internal\n * EVFILT_USER event.  Return 0 on success, -1 on failure.\n */\nint event_kq_add_notify_event_(struct event_base *base);\n\n#endif\n"
        },
        {
          "name": "kqueue.c",
          "type": "blob",
          "size": 14.23046875,
          "content": "/*\t$OpenBSD: kqueue.c,v 1.5 2002/07/10 14:41:31 art Exp $\t*/\n\n/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_KQUEUE\n\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <sys/event.h>\n#include <limits.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <errno.h>\n#ifdef EVENT__HAVE_INTTYPES_H\n#include <inttypes.h>\n#endif\n\n/* Some platforms apparently define the udata field of struct kevent as\n * intptr_t, whereas others define it as void*.  There doesn't seem to be an\n * easy way to tell them apart via autoconf, so we need to use OS macros. */\n#if defined(__NetBSD__)\n#define PTR_TO_UDATA(x) ((typeof(((struct kevent *)0)->udata))(x))\n#define INT_TO_UDATA(x) ((typeof(((struct kevent *)0)->udata))(intptr_t)(x))\n#elif defined(EVENT__HAVE_INTTYPES_H) && !defined(__OpenBSD__) && !defined(__FreeBSD__) && !defined(__darwin__) && !defined(__APPLE__) && !defined(__CloudABI__)\n#define PTR_TO_UDATA(x)\t((intptr_t)(x))\n#define INT_TO_UDATA(x) ((intptr_t)(x))\n#else\n#define PTR_TO_UDATA(x)\t(x)\n#define INT_TO_UDATA(x) ((void*)(x))\n#endif\n\n#include \"event-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"event2/thread.h\"\n#include \"event2/util.h\"\n#include \"evthread-internal.h\"\n#include \"changelist-internal.h\"\n\n#include \"kqueue-internal.h\"\n\n#define NEVENT\t\t64\n\nstruct kqop {\n\tstruct kevent *events;\n\tint events_size;\n\tint kq;\n\tint notify_event_added;\n\tpid_t pid;\n};\n\nstatic void kqop_free(struct kqop *kqop);\n\nstatic void *kq_init(struct event_base *);\nstatic int kq_sig_add(struct event_base *, int, short, short, void *);\nstatic int kq_sig_del(struct event_base *, int, short, short, void *);\nstatic int kq_dispatch(struct event_base *, struct timeval *);\nstatic void kq_dealloc(struct event_base *);\n\nconst struct eventop kqops = {\n\t\"kqueue\",\n\tkq_init,\n\tevent_changelist_add_,\n\tevent_changelist_del_,\n\tkq_dispatch,\n\tkq_dealloc,\n\t1 /* need reinit */,\n    EV_FEATURE_ET|EV_FEATURE_O1|EV_FEATURE_FDS,\n\tEVENT_CHANGELIST_FDINFO_SIZE\n};\n\nstatic const struct eventop kqsigops = {\n\t\"kqueue_signal\",\n\tNULL,\n\tkq_sig_add,\n\tkq_sig_del,\n\tNULL,\n\tNULL,\n\t1 /* need reinit */,\n\t0,\n\t0\n};\n\nstatic void *\nkq_init(struct event_base *base)\n{\n\tint kq = -1;\n\tstruct kqop *kqueueop = NULL;\n\n\tif (!(kqueueop = mm_calloc(1, sizeof(struct kqop))))\n\t\treturn (NULL);\n\n/* Initialize the kernel queue */\n\n\tif ((kq = kqueue()) == -1) {\n\t\tevent_warn(\"kqueue\");\n\t\tgoto err;\n\t}\n\n\tkqueueop->kq = kq;\n\n\tkqueueop->pid = getpid();\n\n\t/* Initialize fields */\n\tkqueueop->events = mm_calloc(NEVENT, sizeof(struct kevent));\n\tif (kqueueop->events == NULL)\n\t\tgoto err;\n\tkqueueop->events_size = NEVENT;\n\n\t/* Check for Mac OS X kqueue bug. */\n\tmemset(&kqueueop->events[0], 0, sizeof kqueueop->events[0]);\n\tkqueueop->events[0].ident = -1;\n\tkqueueop->events[0].filter = EVFILT_READ;\n\tkqueueop->events[0].flags = EV_ADD;\n\t/*\n\t * If kqueue works, then kevent will succeed, and it will\n\t * stick an error in events[0].  If kqueue is broken, then\n\t * kevent will fail.\n\t */\n\tif (kevent(kq,\n\t\tkqueueop->events, 1, kqueueop->events, NEVENT, NULL) != 1 ||\n\t    (int)kqueueop->events[0].ident != -1 ||\n\t    !(kqueueop->events[0].flags & EV_ERROR)) {\n\t\tevent_warn(\"%s: detected broken kqueue; not using.\", __func__);\n\t\tgoto err;\n\t}\n\n\tbase->evsigsel = &kqsigops;\n\n\treturn (kqueueop);\nerr:\n\tif (kqueueop)\n\t\tkqop_free(kqueueop);\n\n\treturn (NULL);\n}\n\n#define ADD_UDATA 0x30303\n\nstatic void\nkq_setup_kevent(struct kevent *out, evutil_socket_t fd, int filter, short change)\n{\n\tmemset(out, 0, sizeof(struct kevent));\n\tout->ident = fd;\n\tout->filter = filter;\n\n\tif (change & EV_CHANGE_ADD) {\n\t\tout->flags = EV_ADD;\n\t\t/* We set a magic number here so that we can tell 'add'\n\t\t * errors from 'del' errors. */\n\t\tout->udata = INT_TO_UDATA(ADD_UDATA);\n\t\tif (change & EV_ET)\n\t\t\tout->flags |= EV_CLEAR;\n#ifdef NOTE_EOF\n\t\t/* Make it behave like select() and poll() */\n\t\tif (filter == EVFILT_READ)\n\t\t\tout->fflags = NOTE_EOF;\n#endif\n\t} else {\n\t\tEVUTIL_ASSERT(change & EV_CHANGE_DEL);\n\t\tout->flags = EV_DELETE;\n\t}\n}\n\nstatic int\nkq_grow_events(struct kqop *kqop)\n{\n\tsize_t new_size;\n\tstruct kevent *new_events;\n\n\tif (kqop->events_size > INT_MAX / 2 ||\n\t    (size_t)kqop->events_size * 2 > EV_SIZE_MAX / sizeof(struct kevent)) {\n\t\tevent_warnx(\"%s: int overflow\", __func__);\n\t\treturn -1;\n\t}\n\n\tnew_size = kqop->events_size * 2;\n\tnew_events = mm_realloc(kqop->events, new_size * sizeof(struct kevent));\n\tif (new_events == NULL) {\n\t\tevent_warn(\"%s: realloc\", __func__);\n\t\treturn -1;\n\t}\n\tkqop->events = new_events;\n\tkqop->events_size = new_size;\n\treturn 0;\n}\n\nstatic int\nkq_build_changes_list(const struct event_changelist *changelist,\n    struct kqop *kqop)\n{\n\tint i;\n\tint n_changes = 0;\n\n\tfor (i = 0; i < changelist->n_changes; ++i) {\n\t\tstruct event_change *in_ch = &changelist->changes[i];\n\t\tstruct kevent *out_ch;\n\t\tif (in_ch->read_change) {\n\t\t\tout_ch = &kqop->events[n_changes++];\n\t\t\tkq_setup_kevent(out_ch, in_ch->fd, EVFILT_READ,\n\t\t\t    in_ch->read_change);\n\t\t\tif (n_changes == kqop->events_size && kq_grow_events(kqop)) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tif (in_ch->write_change) {\n\t\t\tout_ch = &kqop->events[n_changes++];\n\t\t\tkq_setup_kevent(out_ch, in_ch->fd, EVFILT_WRITE,\n\t\t\t    in_ch->write_change);\n\t\t\tif (n_changes == kqop->events_size && kq_grow_events(kqop)) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\treturn n_changes;\n}\n\nstatic int\nkq_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tstruct kqop *kqop = base->evbase;\n\tstruct timespec ts, *ts_p = NULL;\n\tstruct kevent *events;\n\tint i, n_changes, res;\n\n\tif (tv != NULL) {\n\t\tts.tv_sec = tv->tv_sec;\n\t\tts.tv_nsec = tv->tv_usec * 1000;\n\t\tts_p = &ts;\n\t}\n\n\t/* Build the changelist of kevent() from \"base->changelist\" */\n\tEVUTIL_ASSERT(kqop->events);\n\tn_changes = kq_build_changes_list(&base->changelist, kqop);\n\tif (n_changes < 0)\n\t\treturn -1;\n\n\tevent_changelist_remove_all_(&base->changelist, base);\n\n\t/* Offload the events array before calling kevent() to register and\n\t * retrieve events in case some broken code tries to call dispatch\n\t * while there is already one on the fly. */\n\tevents = kqop->events;\n\tkqop->events = NULL;\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\tres = kevent(kqop->kq, events, n_changes, events, kqop->events_size, ts_p);\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tEVUTIL_ASSERT(kqop->events == NULL);\n\t/* Reinstate the events array to provision the next dispatch. */\n\tkqop->events = events;\n\n\tif (res == -1) {\n\t\tif (errno != EINTR) {\n\t\t\tevent_warn(\"kevent\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tevent_debug((\"%s: kevent reports %d\", __func__, res));\n\n\tfor (i = 0; i < res; i++) {\n\t\tint which = 0;\n\n\t\tif (events[i].flags & EV_ERROR) {\n\t\t\tswitch (events[i].data) {\n\n\t\t\t/* Can occur on delete if we are not currently\n\t\t\t * watching any events on this fd.  That can\n\t\t\t * happen when the fd was closed and another\n\t\t\t * file was opened with that fd. */\n\t\t\tcase ENOENT:\n\t\t\t/* Can occur for reasons not fully understood\n\t\t\t * on FreeBSD. */\n\t\t\tcase EINVAL:\n\t\t\t\tcontinue;\n#if defined(__FreeBSD__)\n\t\t\t/*\n\t\t\t * This currently occurs if an FD is closed\n\t\t\t * before the EV_DELETE makes it out via kevent().\n\t\t\t * The FreeBSD capabilities code sees the blank\n\t\t\t * capability set and rejects the request to\n\t\t\t * modify an event.\n\t\t\t *\n\t\t\t * To be strictly correct - when an FD is closed,\n\t\t\t * all the registered events are also removed.\n\t\t\t * Queuing EV_DELETE to a closed FD is wrong.\n\t\t\t * The event(s) should just be deleted from\n\t\t\t * the pending changelist.\n\t\t\t */\n\t\t\tcase ENOTCAPABLE:\n\t\t\t\tcontinue;\n#endif\n\n\t\t\t/* Can occur on a delete if the fd is closed. */\n\t\t\tcase EBADF:\n\t\t\t\t/* XXXX On NetBSD, we can also get EBADF if we\n\t\t\t\t * try to add the write side of a pipe, but\n\t\t\t\t * the read side has already been closed.\n\t\t\t\t * Other BSDs call this situation 'EPIPE'. It\n\t\t\t\t * would be good if we had a way to report\n\t\t\t\t * this situation. */\n\t\t\t\tcontinue;\n\t\t\t/* These two can occur on an add if the fd was one side\n\t\t\t * of a pipe, and the other side was closed. */\n\t\t\tcase EPERM:\n\t\t\tcase EPIPE:\n\t\t\t\t/* Report read events, if we're listening for\n\t\t\t\t * them, so that the user can learn about any\n\t\t\t\t * add errors.  (If the operation was a\n\t\t\t\t * delete, then udata should be cleared.) */\n\t\t\t\tif (events[i].udata) {\n\t\t\t\t\t/* The operation was an add:\n\t\t\t\t\t * report the error as a read. */\n\t\t\t\t\twhich |= EV_READ;\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t/* The operation was a del:\n\t\t\t\t\t * report nothing. */\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t/* Other errors shouldn't occur. */\n\t\t\tdefault:\n\t\t\t\terrno = events[i].data;\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t} else if (events[i].filter == EVFILT_READ) {\n\t\t\twhich |= EV_READ;\n\t\t} else if (events[i].filter == EVFILT_WRITE) {\n\t\t\twhich |= EV_WRITE;\n\t\t} else if (events[i].filter == EVFILT_SIGNAL) {\n\t\t\twhich |= EV_SIGNAL;\n#ifdef EVFILT_USER\n\t\t} else if (events[i].filter == EVFILT_USER) {\n\t\t\tbase->is_notify_pending = 0;\n#endif\n\t\t}\n\n\t\tif (!which)\n\t\t\tcontinue;\n\n\t\tif (events[i].filter == EVFILT_SIGNAL) {\n\t\t\tevmap_signal_active_(base, events[i].ident, 1);\n\t\t} else {\n\t\t\tevmap_io_active_(base, events[i].ident, which | EV_ET);\n\t\t}\n\t}\n\n\tif (res == kqop->events_size) {\n\t\t/* We've used up all the events space in this round.\n\t\t * Try to double the size of the eventlist for next round. */\n\t\tif (kq_grow_events(kqop) < 0)\n\t\t\treturn -1;\n\t}\n\n\treturn (0);\n}\n\nstatic void\nkqop_free(struct kqop *kqop)\n{\n\tif (kqop->events)\n\t\tmm_free(kqop->events);\n\tif (kqop->kq >= 0 && kqop->pid == getpid())\n\t\tclose(kqop->kq);\n\tmemset(kqop, 0, sizeof(struct kqop));\n\tmm_free(kqop);\n}\n\nstatic void\nkq_dealloc(struct event_base *base)\n{\n\tstruct kqop *kqop = base->evbase;\n\tevsig_dealloc_(base);\n\tkqop_free(kqop);\n}\n\n/* signal handling */\nstatic int\nkq_sig_add(struct event_base *base, int nsignal, short old, short events, void *p)\n{\n\tstruct kqop *kqop = base->evbase;\n\tstruct kevent kev;\n\tstruct timespec timeout = { 0, 0 };\n\t(void)p;\n\n\tEVUTIL_ASSERT(nsignal >= 0 && nsignal < NSIG);\n\n\tmemset(&kev, 0, sizeof(kev));\n\tkev.ident = nsignal;\n\tkev.filter = EVFILT_SIGNAL;\n\tkev.flags = EV_ADD;\n\n\t/* Be ready for the signal if it is sent any\n\t * time between now and the next call to\n\t * kq_dispatch. */\n\tif (kevent(kqop->kq, &kev, 1, NULL, 0, &timeout) == -1)\n\t\treturn (-1);\n\n        /* We can set the handler for most signals to SIG_IGN and\n         * still have them reported to us in the queue.  However,\n         * if the handler for SIGCHLD is SIG_IGN, the system reaps\n         * zombie processes for us, and we don't get any notification.\n         * This appears to be the only signal with this quirk. */\n\tif (evsig_set_handler_(base, nsignal,\n                               nsignal == SIGCHLD ? SIG_DFL : SIG_IGN) == -1)\n\t\treturn (-1);\n\n\treturn (0);\n}\n\nstatic int\nkq_sig_del(struct event_base *base, int nsignal, short old, short events, void *p)\n{\n\tstruct kqop *kqop = base->evbase;\n\tstruct kevent kev;\n\n\tstruct timespec timeout = { 0, 0 };\n\t(void)p;\n\n\tEVUTIL_ASSERT(nsignal >= 0 && nsignal < NSIG);\n\n\tmemset(&kev, 0, sizeof(kev));\n\tkev.ident = nsignal;\n\tkev.filter = EVFILT_SIGNAL;\n\tkev.flags = EV_DELETE;\n\n\t/* Because we insert signal events\n\t * immediately, we need to delete them\n\t * immediately, too */\n\tif (kevent(kqop->kq, &kev, 1, NULL, 0, &timeout) == -1)\n\t\treturn (-1);\n\n\tif (evsig_restore_handler_(base, nsignal) == -1)\n\t\treturn (-1);\n\n\treturn (0);\n}\n\n\n/* OSX 10.6, FreeBSD 8.1, DragonFlyBSD 4.0 and NetBSD 10.0 added support for EVFILT_USER,\n * which we can use to wake up the event loop from another thread. */\n\n/* Magic number we use for our filter ID.\n *\n * This is a made-up value, so it can be any integer within the range of type uintptr_t,\n * it's used in conjunction with filter as a (ident, filter) pair to identify a event entry.\n * We use 0 for consistency with other mainstream networking libraries.\n */\n#define NOTIFY_IDENT 0\n\nint\nevent_kq_add_notify_event_(struct event_base *base)\n{\n\tstruct kqop *kqop = base->evbase;\n#if defined(EVFILT_USER) && defined(NOTE_TRIGGER)\n\tstruct kevent kev;\n\tstruct timespec timeout = { 0, 0 };\n#endif\n\n\tif (kqop->notify_event_added)\n\t\treturn 0;\n\n#if defined(EVFILT_USER) && defined(NOTE_TRIGGER)\n\tmemset(&kev, 0, sizeof(kev));\n\tkev.ident = NOTIFY_IDENT;\n\tkev.filter = EVFILT_USER;\n\tkev.flags = EV_ADD | EV_CLEAR;\n\n\tif (kevent(kqop->kq, &kev, 1, NULL, 0, &timeout) == -1) {\n\t\tevent_warn(\"kevent: adding EVFILT_USER event\");\n\t\treturn -1;\n\t}\n\n\tkqop->notify_event_added = 1;\n\n\treturn 0;\n#else\n\treturn -1;\n#endif\n}\n\nint\nevent_kq_notify_base_(struct event_base *base)\n{\n\tstruct kqop *kqop = base->evbase;\n#if defined(EVFILT_USER) && defined(NOTE_TRIGGER)\n\tstruct kevent kev;\n\tstruct timespec timeout = { 0, 0 };\n#endif\n\tif (! kqop->notify_event_added)\n\t\treturn -1;\n\n#if defined(EVFILT_USER) && defined(NOTE_TRIGGER)\n\tmemset(&kev, 0, sizeof(kev));\n\tkev.ident = NOTIFY_IDENT;\n\tkev.filter = EVFILT_USER;\n\tkev.fflags = NOTE_TRIGGER;\n\n\tif (kevent(kqop->kq, &kev, 1, NULL, 0, &timeout) == -1) {\n\t\tevent_warn(\"kevent: triggering EVFILT_USER event\");\n\t\treturn -1;\n\t}\n\n\treturn 0;\n#else\n\treturn -1;\n#endif\n}\n\n#endif /* EVENT__HAVE_KQUEUE */\n"
        },
        {
          "name": "libevent.pc.in",
          "type": "blob",
          "size": 0.328125,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent\nDescription: libevent is an asynchronous notification event loop library\nVersion: @VERSION@\nRequires:\nConflicts:\nLibs: -L${libdir} -levent_core -levent_extra\nLibs.private: @LIBS@\nCflags: -I${includedir}\n\n"
        },
        {
          "name": "libevent_core.pc.in",
          "type": "blob",
          "size": 0.2734375,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent_core\nDescription: libevent_core\nVersion: @VERSION@\nLibs: -L${libdir} -levent_core@CMAKE_DEBUG_POSTFIX@\nLibs.private: @LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "libevent_extra.pc.in",
          "type": "blob",
          "size": 0.2998046875,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent_extra\nDescription: libevent_extra\nVersion: @VERSION@\nRequires: libevent_core\nLibs: -L${libdir} -levent_extra@CMAKE_DEBUG_POSTFIX@\nLibs.private: @LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "libevent_mbedtls.pc.in",
          "type": "blob",
          "size": 0.3681640625,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent_mbedtls\nDescription: libevent_mbedtls adds mbedtls-based TLS support to libevent\nVersion: @VERSION@\nRequires: libevent_core\nLibs: -L${libdir} -levent_mbedtls@CMAKE_DEBUG_POSTFIX@\nLibs.private: -lmbedtls -lmbedx509 @LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "libevent_openssl.pc.in",
          "type": "blob",
          "size": 0.3720703125,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent_openssl\nDescription: libevent_openssl adds openssl-based TLS support to libevent\nVersion: @VERSION@\nRequires: libevent_core\nRequires.private: libssl\nLibs: -L${libdir} -levent_openssl@CMAKE_DEBUG_POSTFIX@\nLibs.private: @LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "libevent_pthreads.pc.in",
          "type": "blob",
          "size": 0.3818359375,
          "content": "#libevent pkg-config source file\n\nprefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: libevent_pthreads\nDescription: libevent_pthreads adds pthreads-based threading support to libevent\nVersion: @VERSION@\nRequires: libevent_core\nLibs: -L${libdir} -levent_pthreads@CMAKE_DEBUG_POSTFIX@\nLibs.private: @CMAKE_THREAD_LIBS_INIT@ @LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "listener.c",
          "type": "blob",
          "size": 22.6025390625,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos, Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifdef _WIN32\n#ifndef _WIN32_WINNT\n/* Minimum required for InitializeCriticalSectionAndSpinCount */\n#define _WIN32_WINNT 0x0403\n#endif\n#endif\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifdef _WIN32\n#include <winsock2.h>\n#include <winerror.h>\n#include <ws2tcpip.h>\n#include <mswsock.h>\n#endif\n#ifdef EVENT__HAVE_AFUNIX_H\n#include <afunix.h>\n#endif\n#include <errno.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#include \"event2/listener.h\"\n#include \"event2/util.h\"\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"mm-internal.h\"\n#include \"util-internal.h\"\n#include \"log-internal.h\"\n#include \"evthread-internal.h\"\n#ifdef _WIN32\n#include \"iocp-internal.h\"\n#include \"defer-internal.h\"\n#include \"event-internal.h\"\n#endif\n\nstruct evconnlistener_ops {\n\tint (*enable)(struct evconnlistener *);\n\tint (*disable)(struct evconnlistener *);\n\tvoid (*destroy)(struct evconnlistener *);\n\tvoid (*shutdown)(struct evconnlistener *);\n\tevutil_socket_t (*getfd)(struct evconnlistener *);\n\tstruct event_base *(*getbase)(struct evconnlistener *);\n};\n\nstruct evconnlistener {\n\tconst struct evconnlistener_ops *ops;\n\tvoid *lock;\n\tevconnlistener_cb cb;\n\tevconnlistener_errorcb errorcb;\n\tvoid *user_data;\n\tunsigned flags;\n\tshort refcnt;\n\tint accept4_flags;\n\tunsigned enabled : 1;\n};\n\nstruct evconnlistener_event {\n\tstruct evconnlistener base;\n\tstruct event listener;\n};\n\n#ifdef _WIN32\nstruct evconnlistener_iocp {\n\tstruct evconnlistener base;\n\tevutil_socket_t fd;\n\tstruct event_base *event_base;\n\tstruct event_iocp_port *port;\n\tshort n_accepting;\n\tunsigned shutting_down : 1;\n\tunsigned event_added : 1;\n\tstruct accepting_socket **accepting;\n};\n#endif\n\n#define LOCK(listener) EVLOCK_LOCK((listener)->lock, 0)\n#define UNLOCK(listener) EVLOCK_UNLOCK((listener)->lock, 0)\n\nstruct evconnlistener *\nevconnlistener_new_async(struct event_base *base,\n    evconnlistener_cb cb, void *ptr, unsigned flags, int backlog,\n    evutil_socket_t fd); /* XXXX export this? */\n\nstatic int event_listener_enable(struct evconnlistener *);\nstatic int event_listener_disable(struct evconnlistener *);\nstatic void event_listener_destroy(struct evconnlistener *);\nstatic evutil_socket_t event_listener_getfd(struct evconnlistener *);\nstatic struct event_base *event_listener_getbase(struct evconnlistener *);\n\n#if 0\nstatic void\nlistener_incref_and_lock(struct evconnlistener *listener)\n{\n\tLOCK(listener);\n\t++listener->refcnt;\n}\n#endif\n\nstatic int\nlistener_decref_and_unlock(struct evconnlistener *listener)\n{\n\tint refcnt = --listener->refcnt;\n\tif (refcnt == 0) {\n\t\tlistener->ops->destroy(listener);\n\t\tUNLOCK(listener);\n\t\tEVTHREAD_FREE_LOCK(listener->lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\t\tmm_free(listener);\n\t\treturn 1;\n\t} else {\n\t\tUNLOCK(listener);\n\t\treturn 0;\n\t}\n}\n\nstatic const struct evconnlistener_ops evconnlistener_event_ops = {\n\tevent_listener_enable,\n\tevent_listener_disable,\n\tevent_listener_destroy,\n\tNULL, /* shutdown */\n\tevent_listener_getfd,\n\tevent_listener_getbase\n};\n\nstatic void listener_read_cb(evutil_socket_t, short, void *);\n\nstruct evconnlistener *\nevconnlistener_new(struct event_base *base,\n    evconnlistener_cb cb, void *ptr, unsigned flags, int backlog,\n    evutil_socket_t fd)\n{\n\tstruct evconnlistener_event *lev;\n\n#ifdef _WIN32\n\tif (base && event_base_get_iocp_(base)) {\n\t\tconst struct win32_extension_fns *ext =\n\t\t\tevent_get_win32_extension_fns_();\n\t\tif (ext->AcceptEx && ext->GetAcceptExSockaddrs)\n\t\t\treturn evconnlistener_new_async(base, cb, ptr, flags,\n\t\t\t\tbacklog, fd);\n\t}\n#endif\n\n\tif (backlog > 0) {\n\t\tif (listen(fd, backlog) < 0)\n\t\t\treturn NULL;\n\t} else if (backlog < 0) {\n\t\tif (listen(fd, 128) < 0)\n\t\t\treturn NULL;\n\t}\n\n\tlev = mm_calloc(1, sizeof(struct evconnlistener_event));\n\tif (!lev)\n\t\treturn NULL;\n\n\tlev->base.ops = &evconnlistener_event_ops;\n\tlev->base.cb = cb;\n\tlev->base.user_data = ptr;\n\tlev->base.flags = flags;\n\tlev->base.refcnt = 1;\n\n\tlev->base.accept4_flags = 0;\n\tif (!(flags & LEV_OPT_LEAVE_SOCKETS_BLOCKING))\n\t\tlev->base.accept4_flags |= EVUTIL_SOCK_NONBLOCK;\n\tif (flags & LEV_OPT_CLOSE_ON_EXEC)\n\t\tlev->base.accept4_flags |= EVUTIL_SOCK_CLOEXEC;\n\n\tif (flags & LEV_OPT_THREADSAFE) {\n\t\tEVTHREAD_ALLOC_LOCK(lev->base.lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\t}\n\n\tevent_assign(&lev->listener, base, fd, EV_READ|EV_PERSIST,\n\t    listener_read_cb, lev);\n\n\tif (!(flags & LEV_OPT_DISABLED))\n\t    evconnlistener_enable(&lev->base);\n\n\treturn &lev->base;\n}\n\nstruct evconnlistener *\nevconnlistener_new_bind(struct event_base *base, evconnlistener_cb cb,\n    void *ptr, unsigned flags, int backlog, const struct sockaddr *sa,\n    int socklen)\n{\n\tstruct evconnlistener *listener;\n\tevutil_socket_t fd;\n\tint family = sa ? sa->sa_family : AF_UNSPEC;\n\tint socktype = SOCK_STREAM | EVUTIL_SOCK_NONBLOCK;\n\n\tif (backlog == 0)\n\t\treturn NULL;\n\n\tif (flags & LEV_OPT_CLOSE_ON_EXEC)\n\t\tsocktype |= EVUTIL_SOCK_CLOEXEC;\n\n\tfd = evutil_socket_(family, socktype, 0);\n\tif (fd == -1)\n\t\treturn NULL;\n\n\t/*\n\t * We do not bother about TCP keep-alive on Unix sockets, because the\n\t * chances of a network failure here are only of theoretical nature.\n\t */\n\tif (family != AF_UNIX) {\n\t\t/* TODO(panjf2000): make this TCP keep-alive value configurable */\n\t\tif (evutil_set_tcp_keepalive(fd, 1, 300) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (flags & LEV_OPT_REUSEABLE) {\n\t\tif (family == AF_UNIX) {\n\t\t\t/* Despite the fact that SO_REUSEADDR can be set on a Unix domain socket\n\t\t\t * via setsockopt() without reporting an error, SO_REUSEADDR is actually\n\t\t\t * not supported for sockets of AF_UNIX.\n\t\t\t * Instead of confusing the callers by allowing this option to be set and\n\t\t\t * failing the subsequent bind() on the same socket, it's better to fail here.\n\t\t\t */\n\t\t\tevutil_closesocket(fd);\n\t\t\treturn NULL;\n\t\t}\n\t\tif (evutil_make_listen_socket_reuseable(fd) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (flags & LEV_OPT_REUSEABLE_PORT) {\n\t\tif (family == AF_UNIX) {\n\t\t\t/* Despite the fact that SO_REUSEPORT can be set on a Unix domain socket\n\t\t\t * via setsockopt() without reporting an error, SO_REUSEPORT is actually\n\t\t\t * not supported for sockets of AF_UNIX.\n\t\t\t * Instead of confusing the callers by allowing this option to be set and\n\t\t\t * failing the subsequent bind() on the same socket, it's better to fail here.\n\t\t\t */\n\t\t\tevutil_closesocket(fd);\n\t\t\treturn NULL;\n\t\t}\n\t\tif (evutil_make_listen_socket_reuseable_port(fd) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (flags & LEV_OPT_DEFERRED_ACCEPT) {\n\t\tif (evutil_make_tcp_listen_socket_deferred(fd) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (flags & LEV_OPT_BIND_IPV6ONLY) {\n\t\tif (evutil_make_listen_socket_ipv6only(fd) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (flags & LEV_OPT_BIND_IPV4_AND_IPV6) {\n\t\tif (evutil_make_listen_socket_not_ipv6only(fd) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (sa) {\n\t\tif (bind(fd, sa, socklen)<0)\n\t\t\tgoto err;\n\t}\n\n\tlistener = evconnlistener_new(base, cb, ptr, flags, backlog, fd);\n\tif (!listener)\n\t\tgoto err;\n\n\treturn listener;\nerr:\n\t{\n\t\tint saved_errno = EVUTIL_SOCKET_ERROR();\n\t\tevutil_closesocket(fd);\n\t\tif (saved_errno)\n\t\t\tEVUTIL_SET_SOCKET_ERROR(saved_errno);\n\t\treturn NULL;\n\t}\n}\n\nvoid\nevconnlistener_free(struct evconnlistener *lev)\n{\n\tLOCK(lev);\n\tlev->cb = NULL;\n\tlev->errorcb = NULL;\n\tif (lev->ops->shutdown)\n\t\tlev->ops->shutdown(lev);\n\tlistener_decref_and_unlock(lev);\n}\n\nstatic void\nevent_listener_destroy(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_event *lev_e =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_event, base);\n\n\tevent_del(&lev_e->listener);\n\tif (lev->flags & LEV_OPT_CLOSE_ON_FREE)\n\t\tevutil_closesocket(event_get_fd(&lev_e->listener));\n\tevent_debug_unassign(&lev_e->listener);\n}\n\nint\nevconnlistener_enable(struct evconnlistener *lev)\n{\n\tint r;\n\tLOCK(lev);\n\tlev->enabled = 1;\n\tif (lev->cb)\n\t\tr = lev->ops->enable(lev);\n\telse\n\t\tr = 0;\n\tUNLOCK(lev);\n\treturn r;\n}\n\nint\nevconnlistener_disable(struct evconnlistener *lev)\n{\n\tint r;\n\tLOCK(lev);\n\tlev->enabled = 0;\n\tr = lev->ops->disable(lev);\n\tUNLOCK(lev);\n\treturn r;\n}\n\nstatic int\nevent_listener_enable(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_event *lev_e =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_event, base);\n\treturn event_add(&lev_e->listener, NULL);\n}\n\nstatic int\nevent_listener_disable(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_event *lev_e =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_event, base);\n\treturn event_del(&lev_e->listener);\n}\n\nevutil_socket_t\nevconnlistener_get_fd(struct evconnlistener *lev)\n{\n\tevutil_socket_t fd;\n\tLOCK(lev);\n\tfd = lev->ops->getfd(lev);\n\tUNLOCK(lev);\n\treturn fd;\n}\n\nstatic evutil_socket_t\nevent_listener_getfd(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_event *lev_e =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_event, base);\n\treturn event_get_fd(&lev_e->listener);\n}\n\nstruct event_base *\nevconnlistener_get_base(struct evconnlistener *lev)\n{\n\tstruct event_base *base;\n\tLOCK(lev);\n\tbase = lev->ops->getbase(lev);\n\tUNLOCK(lev);\n\treturn base;\n}\n\nstatic struct event_base *\nevent_listener_getbase(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_event *lev_e =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_event, base);\n\treturn event_get_base(&lev_e->listener);\n}\n\nvoid\nevconnlistener_set_cb(struct evconnlistener *lev,\n    evconnlistener_cb cb, void *arg)\n{\n\tint enable = 0;\n\tLOCK(lev);\n\tif (lev->enabled && !lev->cb)\n\t\tenable = 1;\n\tlev->cb = cb;\n\tlev->user_data = arg;\n\tif (enable)\n\t\tevconnlistener_enable(lev);\n\tUNLOCK(lev);\n}\n\nvoid\nevconnlistener_set_error_cb(struct evconnlistener *lev,\n    evconnlistener_errorcb errorcb)\n{\n\tLOCK(lev);\n\tlev->errorcb = errorcb;\n\tUNLOCK(lev);\n}\n\nstatic void\nlistener_read_cb(evutil_socket_t fd, short what, void *p)\n{\n\tstruct evconnlistener *lev = p;\n\tint err;\n\tevconnlistener_cb cb;\n\tevconnlistener_errorcb errorcb;\n\tvoid *user_data;\n\tLOCK(lev);\n\twhile (1) {\n\t\tstruct sockaddr_storage ss;\n\t\tev_socklen_t socklen = sizeof(ss);\n\t\tevutil_socket_t new_fd = evutil_accept4_(fd, (struct sockaddr*)&ss, &socklen, lev->accept4_flags);\n\t\tif (new_fd < 0)\n\t\t\tbreak;\n\t\tif (socklen == 0) {\n\t\t\t/* This can happen with some older linux kernels in\n\t\t\t * response to nmap. */\n\t\t\tevutil_closesocket(new_fd);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (lev->cb == NULL) {\n\t\t\tevutil_closesocket(new_fd);\n\t\t\tUNLOCK(lev);\n\t\t\treturn;\n\t\t}\n\t\t++lev->refcnt;\n\t\tcb = lev->cb;\n\t\tuser_data = lev->user_data;\n\t\tcb(lev, new_fd, (struct sockaddr*)&ss, (int)socklen,\n\t\t    user_data);\n\t\tif (lev->refcnt == 1) {\n\t\t\tint freed = listener_decref_and_unlock(lev);\n\t\t\tEVUTIL_ASSERT(freed);\n\t\t\treturn;\n\t\t}\n\t\t--lev->refcnt;\n\t\tif (!lev->enabled) {\n\t\t\t/* the callback could have disabled the listener */\n\t\t\tUNLOCK(lev);\n\t\t\treturn;\n\t\t}\n\t}\n\terr = evutil_socket_geterror(fd);\n\tif (EVUTIL_ERR_ACCEPT_RETRIABLE(err)) {\n\t\tUNLOCK(lev);\n\t\treturn;\n\t}\n\tif (lev->errorcb != NULL) {\n\t\t++lev->refcnt;\n\t\terrorcb = lev->errorcb;\n\t\tuser_data = lev->user_data;\n\t\terrorcb(lev, user_data);\n\t\tlistener_decref_and_unlock(lev);\n\t} else {\n\t\tevent_sock_warn(fd, \"Error from accept() call\");\n\t\tUNLOCK(lev);\n\t}\n}\n\n#ifdef _WIN32\nstruct accepting_socket {\n\tCRITICAL_SECTION lock;\n\tstruct event_overlapped overlapped;\n\tSOCKET s;\n\tint error;\n\tstruct event_callback deferred;\n\tstruct evconnlistener_iocp *lev;\n\tev_uint8_t buflen;\n\tev_uint8_t family;\n\tunsigned free_on_cb:1;\n\tchar addrbuf[1];\n};\n\nstatic void accepted_socket_cb(struct event_overlapped *o, ev_uintptr_t key,\n    ev_ssize_t n, int ok);\nstatic void accepted_socket_invoke_user_cb(struct event_callback *cb, void *arg);\n\nstatic void\niocp_listener_event_add(struct evconnlistener_iocp *lev)\n{\n\tif (lev->event_added)\n\t\treturn;\n\n\tlev->event_added = 1;\n\tevent_base_add_virtual_(lev->event_base);\n}\n\nstatic void\niocp_listener_event_del(struct evconnlistener_iocp *lev)\n{\n\tif (!lev->event_added)\n\t\treturn;\n\n\tlev->event_added = 0;\n\tevent_base_del_virtual_(lev->event_base);\n}\n\nstatic struct accepting_socket *\nnew_accepting_socket(struct evconnlistener_iocp *lev, int family)\n{\n\tstruct accepting_socket *res;\n\tint addrlen;\n\tint buflen;\n\n\tif (family == AF_INET)\n\t\taddrlen = sizeof(struct sockaddr_in);\n\telse if (family == AF_INET6)\n\t\taddrlen = sizeof(struct sockaddr_in6);\n#ifdef EVENT__HAVE_AFUNIX_H\n\telse if (family == AF_UNIX && evutil_check_working_afunix_())\n\t\taddrlen = sizeof(struct sockaddr_un);\n#endif\n\telse\n\t\treturn NULL;\n\tbuflen = (addrlen+16)*2;\n\n\tres = mm_calloc(1,sizeof(struct accepting_socket)-1+buflen);\n\tif (!res)\n\t\treturn NULL;\n\n\tevent_overlapped_init_(&res->overlapped, accepted_socket_cb);\n\tres->s = EVUTIL_INVALID_SOCKET;\n\tres->lev = lev;\n\tres->buflen = buflen;\n\tres->family = family;\n\n\tevent_deferred_cb_init_(&res->deferred,\n\t    event_base_get_npriorities(lev->event_base) / 2,\n\t    accepted_socket_invoke_user_cb, res);\n\n\tInitializeCriticalSectionAndSpinCount(&res->lock, 1000);\n\n\treturn res;\n}\n\nstatic void\nfree_and_unlock_accepting_socket(struct accepting_socket *as)\n{\n\t/* requires lock. */\n\tif (as->s != EVUTIL_INVALID_SOCKET)\n\t\tclosesocket(as->s);\n\n\tLeaveCriticalSection(&as->lock);\n\tDeleteCriticalSection(&as->lock);\n\tmm_free(as);\n}\n\nstatic int\nstart_accepting(struct accepting_socket *as)\n{\n\t/* requires lock */\n\tconst struct win32_extension_fns *ext = event_get_win32_extension_fns_();\n\tDWORD pending = 0;\n\tSOCKET s = socket(as->family, SOCK_STREAM, 0);\n\tint error = 0;\n\n\tif (!as->lev->base.enabled)\n\t\treturn 0;\n\n\tif (s == EVUTIL_INVALID_SOCKET) {\n\t\terror = WSAGetLastError();\n\t\tgoto report_err;\n\t}\n\n\t/* XXXX It turns out we need to do this again later.  Does this call\n\t * have any effect? */\n\tsetsockopt(s, SOL_SOCKET, SO_UPDATE_ACCEPT_CONTEXT,\n\t    (char *)&as->lev->fd, sizeof(&as->lev->fd));\n\n\tif (!(as->lev->base.flags & LEV_OPT_LEAVE_SOCKETS_BLOCKING))\n\t\tevutil_make_socket_nonblocking(s);\n\n\tif (event_iocp_port_associate_(as->lev->port, s, 1) < 0) {\n\t\tclosesocket(s);\n\t\treturn -1;\n\t}\n\n\tas->s = s;\n\n\tif (ext->AcceptEx(as->lev->fd, s, as->addrbuf, 0,\n\t\tas->buflen/2, as->buflen/2, &pending, &as->overlapped.overlapped))\n\t{\n\t\t/* Immediate success! */\n\t\taccepted_socket_cb(&as->overlapped, 1, 0, 1);\n\t} else {\n\t\terror = WSAGetLastError();\n\t\tif (error != ERROR_IO_PENDING) {\n\t\t\tgoto report_err;\n\t\t}\n\t}\n\n\treturn 0;\n\nreport_err:\n\tas->error = error;\n\tevent_deferred_cb_schedule_(\n\t\tas->lev->event_base,\n\t\t&as->deferred);\n\treturn 0;\n}\n\nstatic void\nstop_accepting(struct accepting_socket *as)\n{\n\t/* requires lock. */\n\tSOCKET s = as->s;\n\tas->s = EVUTIL_INVALID_SOCKET;\n\tclosesocket(s);\n}\n\nstatic void\naccepted_socket_invoke_user_cb(struct event_callback *dcb, void *arg)\n{\n\tstruct accepting_socket *as = arg;\n\n\tstruct sockaddr *sa_local=NULL, *sa_remote=NULL;\n\tint socklen_local=0, socklen_remote=0;\n\tconst struct win32_extension_fns *ext = event_get_win32_extension_fns_();\n\tstruct evconnlistener *lev = &as->lev->base;\n\tevutil_socket_t sock=-1;\n\tvoid *data;\n\tevconnlistener_cb cb=NULL;\n\tevconnlistener_errorcb errorcb=NULL;\n\tint error;\n\n\tEVUTIL_ASSERT(ext->GetAcceptExSockaddrs);\n\n\tLOCK(lev);\n\tEnterCriticalSection(&as->lock);\n\tif (as->free_on_cb) {\n\t\tfree_and_unlock_accepting_socket(as);\n\t\tlistener_decref_and_unlock(lev);\n\t\treturn;\n\t}\n\n\t++lev->refcnt;\n\n\terror = as->error;\n\tif (error) {\n\t\tas->error = 0;\n\t\terrorcb = lev->errorcb;\n\t} else {\n\t\text->GetAcceptExSockaddrs(\n\t\t\tas->addrbuf, 0, as->buflen/2, as->buflen/2,\n\t\t\t&sa_local, &socklen_local, &sa_remote,\n\t\t\t&socklen_remote);\n\t\tsock = as->s;\n\t\tcb = lev->cb;\n\t\tas->s = EVUTIL_INVALID_SOCKET;\n\n\t\t/* We need to call this so getsockname, getpeername, and\n\t\t * shutdown work correctly on the accepted socket. */\n\t\t/* XXXX handle error? */\n\t\tsetsockopt(sock, SOL_SOCKET, SO_UPDATE_ACCEPT_CONTEXT,\n\t\t    (char *)&as->lev->fd, sizeof(&as->lev->fd));\n\t}\n\tdata = lev->user_data;\n\n\tLeaveCriticalSection(&as->lock);\n\tUNLOCK(lev);\n\n\tif (errorcb) {\n\t\tWSASetLastError(error);\n\t\terrorcb(lev, data);\n\t} else if (cb) {\n\t\tcb(lev, sock, sa_remote, socklen_remote, data);\n\t}\n\n\tLOCK(lev);\n\tif (listener_decref_and_unlock(lev))\n\t\treturn;\n\n\tEnterCriticalSection(&as->lock);\n\tstart_accepting(as);\n\tLeaveCriticalSection(&as->lock);\n}\n\nstatic void\naccepted_socket_cb(struct event_overlapped *o, ev_uintptr_t key, ev_ssize_t n, int ok)\n{\n\tstruct accepting_socket *as =\n\t    EVUTIL_UPCAST(o, struct accepting_socket, overlapped);\n\n\tLOCK(&as->lev->base);\n\tEnterCriticalSection(&as->lock);\n\tif (ok) {\n\t\t/* XXXX Don't do this if some EV_MT flag is set. */\n\t\tevent_deferred_cb_schedule_(\n\t\t\tas->lev->event_base,\n\t\t\t&as->deferred);\n\t\tLeaveCriticalSection(&as->lock);\n\t} else if (as->free_on_cb) {\n\t\tstruct evconnlistener *lev = &as->lev->base;\n\t\tfree_and_unlock_accepting_socket(as);\n\t\tlistener_decref_and_unlock(lev);\n\t\treturn;\n\t} else if (as->s == EVUTIL_INVALID_SOCKET) {\n\t\t/* This is okay; we were disabled by iocp_listener_disable. */\n\t\tLeaveCriticalSection(&as->lock);\n\t} else {\n\t\t/* Some error on accept that we couldn't actually handle. */\n\t\tBOOL ok;\n\t\tDWORD transfer = 0, flags=0;\n\t\tevent_sock_warn(as->s, \"Unexpected error on AcceptEx\");\n\t\tok = WSAGetOverlappedResult(as->s, &o->overlapped,\n\t\t    &transfer, FALSE, &flags);\n\t\tif (ok) {\n\t\t\t/* well, that was confusing! */\n\t\t\tas->error = 1;\n\t\t} else {\n\t\t\tas->error = WSAGetLastError();\n\t\t}\n\t\tevent_deferred_cb_schedule_(\n\t\t\tas->lev->event_base,\n\t\t\t&as->deferred);\n\t\tLeaveCriticalSection(&as->lock);\n\t}\n\tUNLOCK(&as->lev->base);\n}\n\nstatic int\niocp_listener_enable(struct evconnlistener *lev)\n{\n\tint i;\n\tstruct evconnlistener_iocp *lev_iocp =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_iocp, base);\n\n\tLOCK(lev);\n\tiocp_listener_event_add(lev_iocp);\n\tfor (i = 0; i < lev_iocp->n_accepting; ++i) {\n\t\tstruct accepting_socket *as = lev_iocp->accepting[i];\n\t\tif (!as)\n\t\t\tcontinue;\n\t\tEnterCriticalSection(&as->lock);\n\t\tif (!as->free_on_cb && as->s == EVUTIL_INVALID_SOCKET)\n\t\t\tstart_accepting(as);\n\t\tLeaveCriticalSection(&as->lock);\n\t}\n\tUNLOCK(lev);\n\treturn 0;\n}\n\nstatic int\niocp_listener_disable_impl(struct evconnlistener *lev, int shutdown)\n{\n\tint i;\n\tstruct evconnlistener_iocp *lev_iocp =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_iocp, base);\n\n\tLOCK(lev);\n\tiocp_listener_event_del(lev_iocp);\n\tfor (i = 0; i < lev_iocp->n_accepting; ++i) {\n\t\tstruct accepting_socket *as = lev_iocp->accepting[i];\n\t\tif (!as)\n\t\t\tcontinue;\n\t\tEnterCriticalSection(&as->lock);\n\t\tif (!as->free_on_cb && as->s != EVUTIL_INVALID_SOCKET) {\n\t\t\tif (shutdown)\n\t\t\t\tas->free_on_cb = 1;\n\t\t\tstop_accepting(as);\n\t\t}\n\t\tLeaveCriticalSection(&as->lock);\n\t}\n\n\tif (shutdown && lev->flags & LEV_OPT_CLOSE_ON_FREE)\n\t\tevutil_closesocket(lev_iocp->fd);\n\n\tUNLOCK(lev);\n\treturn 0;\n}\n\nstatic int\niocp_listener_disable(struct evconnlistener *lev)\n{\n\treturn iocp_listener_disable_impl(lev,0);\n}\n\nstatic void\niocp_listener_destroy(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_iocp *lev_iocp =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_iocp, base);\n\n\tif (! lev_iocp->shutting_down) {\n\t\tlev_iocp->shutting_down = 1;\n\t\tiocp_listener_disable_impl(lev,1);\n\t}\n\n}\n\nstatic evutil_socket_t\niocp_listener_getfd(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_iocp *lev_iocp =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_iocp, base);\n\treturn lev_iocp->fd;\n}\nstatic struct event_base *\niocp_listener_getbase(struct evconnlistener *lev)\n{\n\tstruct evconnlistener_iocp *lev_iocp =\n\t    EVUTIL_UPCAST(lev, struct evconnlistener_iocp, base);\n\treturn lev_iocp->event_base;\n}\n\nstatic const struct evconnlistener_ops evconnlistener_iocp_ops = {\n\tiocp_listener_enable,\n\tiocp_listener_disable,\n\tiocp_listener_destroy,\n\tiocp_listener_destroy, /* shutdown */\n\tiocp_listener_getfd,\n\tiocp_listener_getbase\n};\n\n/* XXX define some way to override this. */\n#define N_SOCKETS_PER_LISTENER 4\n\nstruct evconnlistener *\nevconnlistener_new_async(struct event_base *base,\n    evconnlistener_cb cb, void *ptr, unsigned flags, int backlog,\n    evutil_socket_t fd)\n{\n\tstruct sockaddr_storage ss;\n\tint socklen = sizeof(ss);\n\tstruct evconnlistener_iocp *lev;\n\tint i;\n\n\tflags |= LEV_OPT_THREADSAFE;\n\n\tif (!base || !event_base_get_iocp_(base))\n\t\tgoto err;\n\n\t/* XXXX duplicate code */\n\tif (backlog > 0) {\n\t\tif (listen(fd, backlog) < 0)\n\t\t\tgoto err;\n\t} else if (backlog < 0) {\n\t\tif (listen(fd, 128) < 0)\n\t\t\tgoto err;\n\t}\n\tif (getsockname(fd, (struct sockaddr*)&ss, &socklen)) {\n\t\tevent_sock_warn(fd, \"getsockname\");\n\t\tgoto err;\n\t}\n\tlev = mm_calloc(1, sizeof(struct evconnlistener_iocp));\n\tif (!lev) {\n\t\tevent_warn(\"calloc\");\n\t\tgoto err;\n\t}\n\tlev->base.ops = &evconnlistener_iocp_ops;\n\tlev->base.cb = cb;\n\tlev->base.user_data = ptr;\n\tlev->base.flags = flags;\n\tlev->base.refcnt = 1;\n\tlev->base.enabled = 1;\n\n\tlev->port = event_base_get_iocp_(base);\n\tlev->fd = fd;\n\tlev->event_base = base;\n\n\n\tif (event_iocp_port_associate_(lev->port, fd, 1) < 0)\n\t\tgoto err_free_lev;\n\n\tEVTHREAD_ALLOC_LOCK(lev->base.lock, EVTHREAD_LOCKTYPE_RECURSIVE);\n\n\tlev->n_accepting = N_SOCKETS_PER_LISTENER;\n\tlev->accepting = mm_calloc(lev->n_accepting,\n\t    sizeof(struct accepting_socket *));\n\tif (!lev->accepting) {\n\t\tevent_warn(\"calloc\");\n\t\tgoto err_delete_lock;\n\t}\n\tfor (i = 0; i < lev->n_accepting; ++i) {\n\t\tlev->accepting[i] = new_accepting_socket(lev, ss.ss_family);\n\t\tif (!lev->accepting[i]) {\n\t\t\tevent_warnx(\"Couldn't create accepting socket\");\n\t\t\tgoto err_free_accepting;\n\t\t}\n\t\tif (cb && start_accepting(lev->accepting[i]) < 0) {\n\t\t\tevent_warnx(\"Couldn't start accepting on socket\");\n\t\t\tEnterCriticalSection(&lev->accepting[i]->lock);\n\t\t\tfree_and_unlock_accepting_socket(lev->accepting[i]);\n\t\t\tgoto err_free_accepting;\n\t\t}\n\t\t++lev->base.refcnt;\n\t}\n\n\tiocp_listener_event_add(lev);\n\n\treturn &lev->base;\n\nerr_free_accepting:\n\tfor (i = 0; i < lev->n_accepting; ++i) {\n\t\tif (lev->accepting[i])\n\t\t\tfree_and_unlock_accepting_socket(lev->accepting[i]);\n\t}\n\tmm_free(lev->accepting);\nerr_delete_lock:\n\tEVTHREAD_FREE_LOCK(lev->base.lock, EVTHREAD_LOCKTYPE_RECURSIVE);\nerr_free_lev:\n\tmm_free(lev);\nerr:\n\t/* Don't close the fd, it is caller's responsibility. */\n\treturn NULL;\n}\n\n#endif\n"
        },
        {
          "name": "log-internal.h",
          "type": "blob",
          "size": 3.3115234375,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef LOG_INTERNAL_H_INCLUDED_\n#define LOG_INTERNAL_H_INCLUDED_\n\n#include \"event2/util.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#ifdef __GNUC__\n#define EV_CHECK_FMT(a,b) __attribute__((format(printf, a, b)))\n#define EV_NORETURN __attribute__((noreturn))\n#else\n#define EV_CHECK_FMT(a,b)\n#define EV_NORETURN\n#endif\n\n#define EVENT_ERR_ABORT_ ((int)0xdeaddead)\n\n#if !defined(EVENT__DISABLE_DEBUG_MODE) || defined(USE_DEBUG)\n#define EVENT_DEBUG_LOGGING_ENABLED\n#endif\n\n#ifdef EVENT_DEBUG_LOGGING_ENABLED\nEVENT2_CORE_EXPORT_SYMBOL extern ev_uint32_t event_debug_logging_mask_;\n#define event_debug_get_logging_mask_() (event_debug_logging_mask_)\n#else\n#define event_debug_get_logging_mask_() (0)\n#endif\n\nEVENT2_EXPORT_SYMBOL\nvoid event_err(int eval, const char *fmt, ...) EV_CHECK_FMT(2,3) EV_NORETURN;\nEVENT2_EXPORT_SYMBOL\nvoid event_warn(const char *fmt, ...) EV_CHECK_FMT(1,2);\nEVENT2_EXPORT_SYMBOL\nvoid event_sock_err(int eval, evutil_socket_t sock, const char *fmt, ...) EV_CHECK_FMT(3,4) EV_NORETURN;\nEVENT2_EXPORT_SYMBOL\nvoid event_sock_warn(evutil_socket_t sock, const char *fmt, ...) EV_CHECK_FMT(2,3);\nEVENT2_EXPORT_SYMBOL\nvoid event_errx(int eval, const char *fmt, ...) EV_CHECK_FMT(2,3) EV_NORETURN;\nEVENT2_EXPORT_SYMBOL\nvoid event_warnx(const char *fmt, ...) EV_CHECK_FMT(1,2);\nEVENT2_EXPORT_SYMBOL\nvoid event_msgx(const char *fmt, ...) EV_CHECK_FMT(1,2);\nEVENT2_EXPORT_SYMBOL\nvoid event_debugx_(const char *fmt, ...) EV_CHECK_FMT(1,2);\n\nEVENT2_EXPORT_SYMBOL\nvoid event_logv_(int severity, const char *errstr, const char *fmt, va_list ap)\n\tEV_CHECK_FMT(3,0);\n\n#ifdef EVENT_DEBUG_LOGGING_ENABLED\n#define event_debug(x) do {\t\t\t\\\n\tif (event_debug_get_logging_mask_()) {\t\\\n\t\tevent_debugx_ x;\t\t\\\n\t}\t\t\t\t\t\\\n\t} while (0)\n#else\n#define event_debug(x) ((void)0)\n#endif\n\n#undef EV_CHECK_FMT\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* LOG_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "log.c",
          "type": "blob",
          "size": 5.3369140625,
          "content": "/*\t$OpenBSD: err.c,v 1.2 2002/06/25 15:50:15 mickey Exp $\t*/\n\n/*\n * log.c\n *\n * Based on err.c, which was adapted from OpenBSD libc *err* *warn* code.\n *\n * Copyright (c) 2005-2012 Niels Provos and Nick Mathewson\n *\n * Copyright (c) 2000 Dug Song <dugsong@monkey.org>\n *\n * Copyright (c) 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#include <winsock2.h>\n#define WIN32_LEAN_AND_MEAN\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n#include <sys/types.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <errno.h>\n#include \"event2/event.h\"\n#include \"event2/util.h\"\n\n#include \"log-internal.h\"\n\nstatic void event_log(int severity, const char *msg);\nstatic void event_exit(int errcode) EV_NORETURN;\n\nstatic event_fatal_cb fatal_fn = NULL;\n\n#ifdef EVENT_DEBUG_LOGGING_ENABLED\n#ifdef USE_DEBUG\n#define DEFAULT_MASK EVENT_DBG_ALL\n#else\n#define DEFAULT_MASK 0\n#endif\n\nEVENT2_EXPORT_SYMBOL ev_uint32_t event_debug_logging_mask_ = DEFAULT_MASK;\n#endif /* EVENT_DEBUG_LOGGING_ENABLED */\n\nvoid\nevent_enable_debug_logging(ev_uint32_t which)\n{\n#ifdef EVENT_DEBUG_LOGGING_ENABLED\n\tevent_debug_logging_mask_ = which;\n#endif\n}\n\nvoid\nevent_set_fatal_callback(event_fatal_cb cb)\n{\n\tfatal_fn = cb;\n}\n\nstatic void\nevent_exit(int errcode)\n{\n\tif (fatal_fn) {\n\t\tfatal_fn(errcode);\n\t\texit(errcode); /* should never be reached */\n\t} else if (errcode == EVENT_ERR_ABORT_)\n\t\tabort();\n\telse\n\t\texit(errcode);\n}\n\nvoid\nevent_err(int eval, const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_ERR, strerror(errno), fmt, ap);\n\tva_end(ap);\n\tevent_exit(eval);\n}\n\nvoid\nevent_warn(const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_WARN, strerror(errno), fmt, ap);\n\tva_end(ap);\n}\n\nvoid\nevent_sock_err(int eval, evutil_socket_t sock, const char *fmt, ...)\n{\n\tva_list ap;\n\tint err = evutil_socket_geterror(sock);\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_ERR, evutil_socket_error_to_string(err), fmt, ap);\n\tva_end(ap);\n\tevent_exit(eval);\n}\n\nvoid\nevent_sock_warn(evutil_socket_t sock, const char *fmt, ...)\n{\n\tva_list ap;\n\tint err = evutil_socket_geterror(sock);\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_WARN, evutil_socket_error_to_string(err), fmt, ap);\n\tva_end(ap);\n}\n\nvoid\nevent_errx(int eval, const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_ERR, NULL, fmt, ap);\n\tva_end(ap);\n\tevent_exit(eval);\n}\n\nvoid\nevent_warnx(const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_WARN, NULL, fmt, ap);\n\tva_end(ap);\n}\n\nvoid\nevent_msgx(const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_MSG, NULL, fmt, ap);\n\tva_end(ap);\n}\n\nvoid\nevent_debugx_(const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tevent_logv_(EVENT_LOG_DEBUG, NULL, fmt, ap);\n\tva_end(ap);\n}\n\nvoid\nevent_logv_(int severity, const char *errstr, const char *fmt, va_list ap)\n{\n\tchar buf[1024];\n\tsize_t len;\n\n\tif (severity == EVENT_LOG_DEBUG && !event_debug_get_logging_mask_())\n\t\treturn;\n\n\tif (fmt != NULL)\n\t\tevutil_vsnprintf(buf, sizeof(buf), fmt, ap);\n\telse\n\t\tbuf[0] = '\\0';\n\n\tif (errstr) {\n\t\tlen = strlen(buf);\n\t\tif (len < sizeof(buf) - 3) {\n\t\t\tevutil_snprintf(buf + len, sizeof(buf) - len, \": %s\", errstr);\n\t\t}\n\t}\n\n\tevent_log(severity, buf);\n}\n\nstatic event_log_cb log_fn = NULL;\n\nvoid\nevent_set_log_callback(event_log_cb cb)\n{\n\tlog_fn = cb;\n}\n\nstatic void\nevent_log(int severity, const char *msg)\n{\n\tif (log_fn)\n\t\tlog_fn(severity, msg);\n\telse {\n\t\tconst char *severity_str;\n\t\tswitch (severity) {\n\t\tcase EVENT_LOG_DEBUG:\n\t\t\tseverity_str = \"debug\";\n\t\t\tbreak;\n\t\tcase EVENT_LOG_MSG:\n\t\t\tseverity_str = \"msg\";\n\t\t\tbreak;\n\t\tcase EVENT_LOG_WARN:\n\t\t\tseverity_str = \"warn\";\n\t\t\tbreak;\n\t\tcase EVENT_LOG_ERR:\n\t\t\tseverity_str = \"err\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tseverity_str = \"???\";\n\t\t\tbreak;\n\t\t}\n\t\t(void)fprintf(stderr, \"[%s] %s\\n\", severity_str, msg);\n\t}\n}\n"
        },
        {
          "name": "m4",
          "type": "tree",
          "content": null
        },
        {
          "name": "make-event-config.sed",
          "type": "blob",
          "size": 0.7138671875,
          "content": "# Sed script to postprocess config.h into event-config.h.\n\n1i\\\n/* event2/event-config.h\\\n *\\\n * This file was generated by autoconf when libevent was built, and post-\\\n * processed by Libevent so that its macros would have a uniform prefix.\\\n *\\\n * DO NOT EDIT THIS FILE.\\\n *\\\n * Do not rely on macros in this file existing in later versions.\\\n */\\\n\\\n#ifndef EVENT2_EVENT_CONFIG_H_INCLUDED_\\\n#define EVENT2_EVENT_CONFIG_H_INCLUDED_\\\n\n$a\\\n\\\n#endif /* event2/event-config.h */\n\n/#\\( *\\)undef STDC_HEADERS\\>/b\n/#\\( *\\)define STDC_HEADERS\\>/b\n\n# Only rewrite symbols starting with capitals\ns/#\\( *\\)define \\([A-Z]\\)/#\\1define EVENT__\\2/\ns/#\\( *\\)undef \\([A-Z]\\)/#\\1undef EVENT__\\2/\ns/#\\( *\\)if\\(n*\\)def \\([A-Z]\\)/#\\1if\\2def EVENT__\\2/\n"
        },
        {
          "name": "make_epoll_table.py",
          "type": "blob",
          "size": 1.7646484375,
          "content": "#!/usr/bin/python2\n\ndef get(old,wc,rc,cc):\n    if ('xxx' in (rc, wc, cc)):\n        return \"0\",255\n\n    if ('add' in (rc, wc, cc)):\n        events = []\n        if rc == 'add' or (rc != 'del' and 'r' in old):\n            events.append(\"EPOLLIN\")\n        if wc == 'add' or (wc != 'del' and 'w' in old):\n            events.append(\"EPOLLOUT\")\n        if cc == 'add' or (cc != 'del' and 'c' in old):\n            events.append(\"EPOLLRDHUP\")\n\n        if old == \"0\":\n            op = \"EPOLL_CTL_ADD\"\n        else:\n            op = \"EPOLL_CTL_MOD\"\n        return \"|\".join(events), op\n\n    if ('del' in (rc, wc, cc)):\n        delevents = []\n        modevents = []\n        op = \"EPOLL_CTL_DEL\"\n\n        if 'r' in old:\n            modevents.append(\"EPOLLIN\")\n        if 'w' in old:\n            modevents.append(\"EPOLLOUT\")\n        if 'c' in old:\n            modevents.append(\"EPOLLRDHUP\")\n\n        for item, event in [(rc,\"EPOLLIN\"),\n                            (wc,\"EPOLLOUT\"),\n                            (cc,\"EPOLLRDHUP\")]:\n            if item == 'del':\n                delevents.append(event)\n                if event in modevents:\n                    modevents.remove(event)\n\n        if modevents:\n            return \"|\".join(modevents), \"EPOLL_CTL_MOD\"\n        else:\n            return \"|\".join(delevents), \"EPOLL_CTL_DEL\"\n\n    return 0, 0\n\n\ndef fmt(op, ev, old, wc, rc, cc):\n    entry = \"{ %s, %s },\"%(op, ev)\n    print \"\\t/* old=%3s, write:%3s, read:%3s, close:%3s */\\n\\t%s\" % (\n        old, wc, rc, cc, entry)\n    return len(entry)\n\nfor old in ('0','r','w','rw','c','cr','cw','crw'):\n    for wc in ('0', 'add', 'del', 'xxx'):\n        for rc in ('0', 'add', 'del', 'xxx'):\n            for cc in ('0', 'add', 'del', 'xxx'):\n\n                op,ev = get(old,wc,rc,cc)\n\n                fmt(op, ev, old, wc, rc, cc)\n"
        },
        {
          "name": "mbedtls-compat.h",
          "type": "blob",
          "size": 0.689453125,
          "content": "#ifndef MBEDTLS_COMPAT_H\n#define MBEDTLS_COMPAT_H\n\n#include <mbedtls/version.h>\n\n#if MBEDTLS_VERSION_MAJOR >= 3\n# if defined(__clang__)\n#  pragma clang diagnostic push\n#  pragma clang diagnostic ignored \"-Wcpp\"\n# elif defined(__GNUC__)\n#  pragma GCC diagnostic push\n#  pragma GCC diagnostic ignored \"-Wcpp\"\n# endif\n\n# include <mbedtls/compat-2.x.h>\n\n# if defined(__clang__)\n#  pragma clang diagnostic pop\n# elif defined(__GNUC__)\n#  pragma GCC diagnostic pop\n# endif\n#endif // MBEDTLS_VERSION_MAJOR >= 3\n\n#if MBEDTLS_VERSION_MAJOR < 2 || (MBEDTLS_VERSION_MAJOR == 2 && MBEDTLS_VERSION_MINOR < 4)\n# include <mbedtls/net.h>\n#else\n# include <mbedtls/net_sockets.h>\n#endif\n\n#endif // LIBEVENT_MBEDTLS_COMPAT_H\n"
        },
        {
          "name": "minheap-internal.h",
          "type": "blob",
          "size": 6.7841796875,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Copyright (c) 2006 Maxim Yegorushkin <maxim.yegorushkin@gmail.com>\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef MINHEAP_INTERNAL_H_INCLUDED_\n#define MINHEAP_INTERNAL_H_INCLUDED_\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"mm-internal.h\"\n\ntypedef struct min_heap\n{\n\tstruct event** p;\n\tsize_t n, a;\n} min_heap_t;\n\nstatic inline void\t     min_heap_ctor_(min_heap_t* s);\nstatic inline void\t     min_heap_dtor_(min_heap_t* s);\nstatic inline void\t     min_heap_elem_init_(struct event* e);\nstatic inline int\t     min_heap_elt_is_top_(const struct event *e);\nstatic inline int\t     min_heap_empty_(min_heap_t* s);\nstatic inline size_t\t     min_heap_size_(min_heap_t* s);\nstatic inline struct event*  min_heap_top_(min_heap_t* s);\nstatic inline int\t     min_heap_reserve_(min_heap_t* s, size_t n);\nstatic inline int\t     min_heap_push_(min_heap_t* s, struct event* e);\nstatic inline struct event*  min_heap_pop_(min_heap_t* s);\nstatic inline int\t     min_heap_adjust_(min_heap_t *s, struct event* e);\nstatic inline int\t     min_heap_erase_(min_heap_t* s, struct event* e);\nstatic inline void\t     min_heap_shift_up_(min_heap_t* s, size_t hole_index, struct event* e);\nstatic inline void\t     min_heap_shift_up_unconditional_(min_heap_t* s, size_t hole_index, struct event* e);\nstatic inline void\t     min_heap_shift_down_(min_heap_t* s, size_t hole_index, struct event* e);\n\n#define min_heap_elem_greater(a, b) \\\n\t(evutil_timercmp(&(a)->ev_timeout, &(b)->ev_timeout, >))\n\nvoid min_heap_ctor_(min_heap_t* s) { s->p = 0; s->n = 0; s->a = 0; }\nvoid min_heap_dtor_(min_heap_t* s) { if (s->p) mm_free(s->p); }\nvoid min_heap_elem_init_(struct event* e) { e->ev_timeout_pos.min_heap_idx = EV_SIZE_MAX; }\nint min_heap_empty_(min_heap_t* s) { return 0 == s->n; }\nsize_t min_heap_size_(min_heap_t* s) { return s->n; }\nstruct event* min_heap_top_(min_heap_t* s) { return s->n ? *s->p : 0; }\n\nint min_heap_push_(min_heap_t* s, struct event* e)\n{\n\tif (min_heap_reserve_(s, s->n + 1))\n\t\treturn -1;\n\tmin_heap_shift_up_(s, s->n++, e);\n\treturn 0;\n}\n\nstruct event* min_heap_pop_(min_heap_t* s)\n{\n\tif (s->n)\n\t{\n\t\tstruct event* e = *s->p;\n\t\tmin_heap_shift_down_(s, 0, s->p[--s->n]);\n\t\te->ev_timeout_pos.min_heap_idx = EV_SIZE_MAX;\n\t\treturn e;\n\t}\n\treturn 0;\n}\n\nint min_heap_elt_is_top_(const struct event *e)\n{\n\treturn e->ev_timeout_pos.min_heap_idx == 0;\n}\n\nint min_heap_erase_(min_heap_t* s, struct event* e)\n{\n\tif (EV_SIZE_MAX != e->ev_timeout_pos.min_heap_idx)\n\t{\n\t\tstruct event *last = s->p[--s->n];\n\t\tsize_t parent = (e->ev_timeout_pos.min_heap_idx - 1) / 2;\n\t\t/* we replace e with the last element in the heap.  We might need to\n\t\t   shift it upward if it is less than its parent, or downward if it is\n\t\t   greater than one or both its children. Since the children are known\n\t\t   to be less than the parent, it can't need to shift both up and\n\t\t   down. */\n\t\tif (e->ev_timeout_pos.min_heap_idx > 0 && min_heap_elem_greater(s->p[parent], last))\n\t\t\tmin_heap_shift_up_unconditional_(s, e->ev_timeout_pos.min_heap_idx, last);\n\t\telse\n\t\t\tmin_heap_shift_down_(s, e->ev_timeout_pos.min_heap_idx, last);\n\t\te->ev_timeout_pos.min_heap_idx = EV_SIZE_MAX;\n\t\treturn 0;\n\t}\n\treturn -1;\n}\n\nint min_heap_adjust_(min_heap_t *s, struct event *e)\n{\n\tif (EV_SIZE_MAX == e->ev_timeout_pos.min_heap_idx) {\n\t\treturn min_heap_push_(s, e);\n\t} else {\n\t\tsize_t parent = (e->ev_timeout_pos.min_heap_idx - 1) / 2;\n\t\t/* The position of e has changed; we shift it up or down\n\t\t * as needed.  We can't need to do both. */\n\t\tif (e->ev_timeout_pos.min_heap_idx > 0 && min_heap_elem_greater(s->p[parent], e))\n\t\t\tmin_heap_shift_up_unconditional_(s, e->ev_timeout_pos.min_heap_idx, e);\n\t\telse\n\t\t\tmin_heap_shift_down_(s, e->ev_timeout_pos.min_heap_idx, e);\n\t\treturn 0;\n\t}\n}\n\nint min_heap_reserve_(min_heap_t* s, size_t n)\n{\n\tif (s->a < n)\n\t{\n\t\tstruct event** p;\n\t\tsize_t a = s->a ? s->a * 2 : 8;\n\t\tif (a < n)\n\t\t\ta = n;\n\t\tif (!(p = (struct event**)mm_realloc(s->p, a * sizeof *p)))\n\t\t\treturn -1;\n\t\ts->p = p;\n\t\ts->a = a;\n\t}\n\treturn 0;\n}\n\nvoid min_heap_shift_up_unconditional_(min_heap_t* s, size_t hole_index, struct event* e)\n{\n    size_t parent = (hole_index - 1) / 2;\n    do\n    {\n\t(s->p[hole_index] = s->p[parent])->ev_timeout_pos.min_heap_idx = hole_index;\n\thole_index = parent;\n\tparent = (hole_index - 1) / 2;\n    } while (hole_index && min_heap_elem_greater(s->p[parent], e));\n    (s->p[hole_index] = e)->ev_timeout_pos.min_heap_idx = hole_index;\n}\n\nvoid min_heap_shift_up_(min_heap_t* s, size_t hole_index, struct event* e)\n{\n    size_t parent = (hole_index - 1) / 2;\n    while (hole_index && min_heap_elem_greater(s->p[parent], e))\n    {\n\t(s->p[hole_index] = s->p[parent])->ev_timeout_pos.min_heap_idx = hole_index;\n\thole_index = parent;\n\tparent = (hole_index - 1) / 2;\n    }\n    (s->p[hole_index] = e)->ev_timeout_pos.min_heap_idx = hole_index;\n}\n\nvoid min_heap_shift_down_(min_heap_t* s, size_t hole_index, struct event* e)\n{\n    size_t min_child = 2 * (hole_index + 1);\n    while (min_child <= s->n)\n\t{\n\tmin_child -= min_child == s->n || min_heap_elem_greater(s->p[min_child], s->p[min_child - 1]);\n\tif (!(min_heap_elem_greater(e, s->p[min_child])))\n\t    break;\n\t(s->p[hole_index] = s->p[min_child])->ev_timeout_pos.min_heap_idx = hole_index;\n\thole_index = min_child;\n\tmin_child = 2 * (hole_index + 1);\n\t}\n    (s->p[hole_index] = e)->ev_timeout_pos.min_heap_idx = hole_index;\n}\n\n#endif /* MINHEAP_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "mm-internal.h",
          "type": "blob",
          "size": 3.4189453125,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef MM_INTERNAL_H_INCLUDED_\n#define MM_INTERNAL_H_INCLUDED_\n\n#include <sys/types.h>\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#ifndef EVENT__DISABLE_MM_REPLACEMENT\n/* Internal use only: Memory allocation functions. We give them nice short\n * mm_names for our own use, but make sure that the symbols have longer names\n * so they don't conflict with other libraries (like, say, libmm). */\n\n/** Allocate uninitialized memory.\n *\n * @return On success, return a pointer to sz newly allocated bytes.\n *     On failure, set errno to ENOMEM and return NULL.\n *     If the argument sz is 0, simply return NULL.\n */\nEVENT2_EXPORT_SYMBOL\nvoid *event_mm_malloc_(size_t sz);\n\n/** Allocate memory initialized to zero.\n *\n * @return On success, return a pointer to (count * size) newly allocated\n *     bytes, initialized to zero.\n *     On failure, or if the product would result in an integer overflow,\n *     set errno to ENOMEM and return NULL.\n *     If either arguments are 0, simply return NULL.\n */\nEVENT2_EXPORT_SYMBOL\nvoid *event_mm_calloc_(size_t count, size_t size);\n\n/** Duplicate a string.\n *\n * @return On success, return a pointer to a newly allocated duplicate\n *     of a string.\n *     Set errno to ENOMEM and return NULL if a memory allocation error\n *     occurs (or would occur) in the process.\n *     If the argument str is NULL, set errno to EINVAL and return NULL.\n */\nEVENT2_EXPORT_SYMBOL\nchar *event_mm_strdup_(const char *str);\n\nEVENT2_EXPORT_SYMBOL\nvoid *event_mm_realloc_(void *p, size_t sz);\nEVENT2_EXPORT_SYMBOL\nvoid event_mm_free_(void *p);\n#define mm_malloc(sz) event_mm_malloc_(sz)\n#define mm_calloc(count, size) event_mm_calloc_((count), (size))\n#define mm_strdup(s) event_mm_strdup_(s)\n#define mm_realloc(p, sz) event_mm_realloc_((p), (sz))\n#define mm_free(p) event_mm_free_(p)\n#else\n#define mm_malloc(sz) malloc(sz)\n#define mm_calloc(n, sz) calloc((n), (sz))\n#define mm_strdup(s) strdup(s)\n#define mm_realloc(p, sz) realloc((p), (sz))\n#define mm_free(p) free(p)\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "openssl-compat.h",
          "type": "blob",
          "size": 1.4189453125,
          "content": "#ifndef OPENSSL_COMPAT_H\n#define OPENSSL_COMPAT_H\n\n#include <openssl/bio.h>\n#include \"util-internal.h\"\n\n#if (OPENSSL_VERSION_NUMBER < 0x10100000L) || \\\n\t(defined(LIBRESSL_VERSION_NUMBER) && LIBRESSL_VERSION_NUMBER < 0x20700000L)\n\nstatic inline BIO_METHOD *BIO_meth_new(int type, const char *name)\n{\n\tBIO_METHOD *biom = calloc(1, sizeof(BIO_METHOD));\n\n\tif (biom != NULL) {\n\t\tbiom->type = type;\n\t\tbiom->name = name;\n\t}\n\treturn biom;\n}\n\n#define BIO_meth_set_write(b, f) (b)->bwrite = (f)\n#define BIO_meth_set_read(b, f) (b)->bread = (f)\n#define BIO_meth_set_puts(b, f) (b)->bputs = (f)\n#define BIO_meth_set_ctrl(b, f) (b)->ctrl = (f)\n#define BIO_meth_set_create(b, f) (b)->create = (f)\n#define BIO_meth_set_destroy(b, f) (b)->destroy = (f)\n\n#define BIO_set_init(b, val) (b)->init = (val)\n#define BIO_set_data(b, val) (b)->ptr = (val)\n#define BIO_set_shutdown(b, val) (b)->shutdown = (val)\n#define BIO_get_init(b) (b)->init\n#define BIO_get_data(b) (b)->ptr\n#define BIO_get_shutdown(b) (b)->shutdown\n\n#define TLS_method SSLv23_method\n\n#define X509_getm_notBefore X509_get_notBefore\n#define X509_getm_notAfter X509_get_notAfter\n\n#endif /* (OPENSSL_VERSION_NUMBER < 0x10100000L) || \\\n\t(defined(LIBRESSL_VERSION_NUMBER) && LIBRESSL_VERSION_NUMBER < 0x20700000L) */\n\n#if defined(LIBRESSL_VERSION_NUMBER) && LIBRESSL_VERSION_NUMBER >= 0x20700000L && \\\n\tLIBRESSL_VERSION_NUMBER < 0x30500000L\n#define BIO_get_init(b) (b)->init\n#endif\n\n#endif /* OPENSSL_COMPAT_H */\n"
        },
        {
          "name": "poll.c",
          "type": "blob",
          "size": 8.4765625,
          "content": "/*\t$OpenBSD: poll.c,v 1.2 2002/06/25 15:50:15 mickey Exp $\t*/\n\n/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_POLL\n\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#include <poll.h>\n#include <signal.h>\n#include <limits.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <errno.h>\n\n#include \"event-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"event2/thread.h\"\n#include \"evthread-internal.h\"\n#include \"time-internal.h\"\n\n/* Since Linux 2.6.17, poll is able to report about peer half-closed connection\n   using special POLLRDHUP flag on a read event.\n*/\n#if !defined(POLLRDHUP)\n#define POLLRDHUP 0\n#define EARLY_CLOSE_IF_HAVE_RDHUP 0\n#else\n#define EARLY_CLOSE_IF_HAVE_RDHUP EV_FEATURE_EARLY_CLOSE\n#endif\n\n\nstruct pollidx {\n\tint idxplus1;\n};\n\nstruct pollop {\n\tint event_count;\t\t/* Highest number alloc */\n\tint nfds;\t\t\t/* Highest number used */\n\tint realloc_copy;\t\t/* True iff we must realloc\n\t\t\t\t\t * event_set_copy */\n\tstruct pollfd *event_set;\n\tstruct pollfd *event_set_copy;\n};\n\nstatic void *poll_init(struct event_base *);\nstatic int poll_add(struct event_base *, int, short old, short events, void *idx);\nstatic int poll_del(struct event_base *, int, short old, short events, void *idx);\nstatic int poll_dispatch(struct event_base *, struct timeval *);\nstatic void poll_dealloc(struct event_base *);\n\nconst struct eventop pollops = {\n\t\"poll\",\n\tpoll_init,\n\tpoll_add,\n\tpoll_del,\n\tpoll_dispatch,\n\tpoll_dealloc,\n\t1, /* need_reinit */\n\tEV_FEATURE_FDS|EARLY_CLOSE_IF_HAVE_RDHUP,\n\tsizeof(struct pollidx),\n};\n\nstatic void *\npoll_init(struct event_base *base)\n{\n\tstruct pollop *pollop;\n\n\tif (!(pollop = mm_calloc(1, sizeof(struct pollop))))\n\t\treturn (NULL);\n\n\tif (sigfd_init_(base) < 0)\n\t\tevsig_init_(base);\n\n\tevutil_weakrand_seed_(&base->weakrand_seed, 0);\n\n\treturn (pollop);\n}\n\n#ifdef CHECK_INVARIANTS\nstatic void\npoll_check_ok(struct pollop *pop)\n{\n\tint i, idx;\n\tstruct event *ev;\n\n\tfor (i = 0; i < pop->fd_count; ++i) {\n\t\tidx = pop->idxplus1_by_fd[i]-1;\n\t\tif (idx < 0)\n\t\t\tcontinue;\n\t\tEVUTIL_ASSERT(pop->event_set[idx].fd == i);\n\t}\n\tfor (i = 0; i < pop->nfds; ++i) {\n\t\tstruct pollfd *pfd = &pop->event_set[i];\n\t\tEVUTIL_ASSERT(pop->idxplus1_by_fd[pfd->fd] == i+1);\n\t}\n}\n#else\n#define poll_check_ok(pop)\n#endif\n\nstatic int\npoll_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tint res, i, j, nfds;\n\tlong msec = -1;\n\tstruct pollop *pop = base->evbase;\n\tstruct pollfd *event_set;\n\n\tpoll_check_ok(pop);\n\n\tnfds = pop->nfds;\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (base->th_base_lock) {\n\t\t/* If we're using this backend in a multithreaded setting,\n\t\t * then we need to work on a copy of event_set, so that we can\n\t\t * let other threads modify the main event_set while we're\n\t\t * polling. If we're not multithreaded, then we'll skip the\n\t\t * copy step here to save memory and time. */\n\t\tif (pop->realloc_copy) {\n\t\t\tstruct pollfd *tmp = mm_realloc(pop->event_set_copy,\n\t\t\t    pop->event_count * sizeof(struct pollfd));\n\t\t\tif (tmp == NULL) {\n\t\t\t\tevent_warn(\"realloc\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tpop->event_set_copy = tmp;\n\t\t\tpop->realloc_copy = 0;\n\t\t}\n\t\tmemcpy(pop->event_set_copy, pop->event_set,\n\t\t    sizeof(struct pollfd)*nfds);\n\t\tevent_set = pop->event_set_copy;\n\t} else {\n\t\tevent_set = pop->event_set;\n\t}\n#else\n\tevent_set = pop->event_set;\n#endif\n\n\tif (tv != NULL) {\n\t\tmsec = evutil_tv_to_msec_(tv);\n\t\tif (msec < 0 || msec > INT_MAX)\n\t\t\tmsec = INT_MAX;\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\tres = poll(event_set, nfds, msec);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tif (res == -1) {\n\t\tif (errno != EINTR) {\n\t\t\tevent_warn(\"poll\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tevent_debug((\"%s: poll reports %d\", __func__, res));\n\n\tif (res == 0 || nfds == 0)\n\t\treturn (0);\n\n\ti = evutil_weakrand_range_(&base->weakrand_seed, nfds);\n\tfor (j = 0; j < nfds; j++) {\n\t\tint what;\n\t\tif (++i == nfds)\n\t\t\ti = 0;\n\t\twhat = event_set[i].revents;\n\t\tif (!what)\n\t\t\tcontinue;\n\n\t\tres = 0;\n\n\t\t/* If the file gets closed notify */\n\t\tif (what & (POLLHUP|POLLERR|POLLNVAL))\n\t\t\twhat |= POLLIN|POLLOUT;\n\t\tif (what & POLLIN)\n\t\t\tres |= EV_READ;\n\t\tif (what & POLLOUT)\n\t\t\tres |= EV_WRITE;\n\t\tif (what & POLLRDHUP)\n\t\t\tres |= EV_CLOSED;\n\t\tif (res == 0)\n\t\t\tcontinue;\n\n\t\tevmap_io_active_(base, event_set[i].fd, res);\n\t}\n\n\treturn (0);\n}\n\nstatic int\npoll_add(struct event_base *base, int fd, short old, short events, void *idx_)\n{\n\tstruct pollop *pop = base->evbase;\n\tstruct pollfd *pfd = NULL;\n\tstruct pollidx *idx = idx_;\n\tint i;\n\n\tEVUTIL_ASSERT((events & EV_SIGNAL) == 0);\n\tif (!(events & (EV_READ|EV_WRITE|EV_CLOSED)))\n\t\treturn (0);\n\n\tpoll_check_ok(pop);\n\tif (pop->nfds + 1 >= pop->event_count) {\n\t\tstruct pollfd *tmp_event_set;\n\t\tint tmp_event_count;\n\n\t\tif (pop->event_count < 32)\n\t\t\ttmp_event_count = 32;\n\t\telse\n\t\t\ttmp_event_count = pop->event_count * 2;\n\n\t\t/* We need more file descriptors */\n\t\ttmp_event_set = mm_realloc(pop->event_set,\n\t\t\t\t tmp_event_count * sizeof(struct pollfd));\n\t\tif (tmp_event_set == NULL) {\n\t\t\tevent_warn(\"realloc\");\n\t\t\treturn (-1);\n\t\t}\n\t\tpop->event_set = tmp_event_set;\n\n\t\tpop->event_count = tmp_event_count;\n\t\tpop->realloc_copy = 1;\n\t}\n\n\ti = idx->idxplus1 - 1;\n\n\tif (i >= 0) {\n\t\tpfd = &pop->event_set[i];\n\t} else {\n\t\ti = pop->nfds++;\n\t\tpfd = &pop->event_set[i];\n\t\tpfd->events = 0;\n\t\tpfd->fd = fd;\n\t\tidx->idxplus1 = i + 1;\n\t}\n\n\tpfd->revents = 0;\n\tif (events & EV_WRITE)\n\t\tpfd->events |= POLLOUT;\n\tif (events & EV_READ)\n\t\tpfd->events |= POLLIN;\n\tif (events & EV_CLOSED)\n\t\tpfd->events |= POLLRDHUP;\n\tpoll_check_ok(pop);\n\n\treturn (0);\n}\n\n/*\n * Nothing to be done here.\n */\n\nstatic int\npoll_del(struct event_base *base, int fd, short old, short events, void *idx_)\n{\n\tstruct pollop *pop = base->evbase;\n\tstruct pollfd *pfd = NULL;\n\tstruct pollidx *idx = idx_;\n\tint i;\n\n\tEVUTIL_ASSERT((events & EV_SIGNAL) == 0);\n\tif (!(events & (EV_READ|EV_WRITE|EV_CLOSED)))\n\t\treturn (0);\n\n\tpoll_check_ok(pop);\n\ti = idx->idxplus1 - 1;\n\tif (i < 0)\n\t\treturn (-1);\n\n\t/* Do we still want to read or write? */\n\tpfd = &pop->event_set[i];\n\tif (events & EV_READ)\n\t\tpfd->events &= ~POLLIN;\n\tif (events & EV_WRITE)\n\t\tpfd->events &= ~POLLOUT;\n\tif (events & EV_CLOSED)\n\t\tpfd->events &= ~POLLRDHUP;\n\tpoll_check_ok(pop);\n\tif (pfd->events)\n\t\t/* Another event cares about that fd. */\n\t\treturn (0);\n\n\t/* Okay, so we aren't interested in that fd anymore. */\n\tidx->idxplus1 = 0;\n\n\t--pop->nfds;\n\tif (i != pop->nfds) {\n\t\t/*\n\t\t * Shift the last pollfd down into the now-unoccupied\n\t\t * position.\n\t\t */\n\t\tmemcpy(&pop->event_set[i], &pop->event_set[pop->nfds],\n\t\t       sizeof(struct pollfd));\n\t\tidx = evmap_io_get_fdinfo_(&base->io, pop->event_set[i].fd);\n\t\tEVUTIL_ASSERT(idx);\n\t\tEVUTIL_ASSERT(idx->idxplus1 == pop->nfds + 1);\n\t\tidx->idxplus1 = i + 1;\n\t}\n\n\tpoll_check_ok(pop);\n\treturn (0);\n}\n\nstatic void\npoll_dealloc(struct event_base *base)\n{\n\tstruct pollop *pop = base->evbase;\n\n\tevsig_dealloc_(base);\n\tif (pop->event_set)\n\t\tmm_free(pop->event_set);\n\tif (pop->event_set_copy)\n\t\tmm_free(pop->event_set_copy);\n\n\tmemset(pop, 0, sizeof(struct pollop));\n\tmm_free(pop);\n}\n\n#endif /* EVENT__HAVE_POLL */\n"
        },
        {
          "name": "ratelim-internal.h",
          "type": "blob",
          "size": 3.99609375,
          "content": "/*\n * Copyright (c) 2009-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef RATELIM_INTERNAL_H_INCLUDED_\n#define RATELIM_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/util.h\"\n\n/** A token bucket is an internal structure that tracks how many bytes we are\n * currently willing to read or write on a given bufferevent or group of\n * bufferevents */\nstruct ev_token_bucket {\n\t/** How many bytes are we willing to read or write right now? These\n\t * values are signed so that we can do \"defecit spending\" */\n\tev_ssize_t read_limit, write_limit;\n\t/** When was this bucket last updated?  Measured in abstract 'ticks'\n\t * relative to the token bucket configuration. */\n\tev_uint32_t last_updated;\n};\n\n/** Configuration info for a token bucket or set of token buckets. */\nstruct ev_token_bucket_cfg {\n\t/** How many bytes are we willing to read on average per tick? */\n\tsize_t read_rate;\n\t/** How many bytes are we willing to read at most in any one tick? */\n\tsize_t read_maximum;\n\t/** How many bytes are we willing to write on average per tick? */\n\tsize_t write_rate;\n\t/** How many bytes are we willing to write at most in any one tick? */\n\tsize_t write_maximum;\n\n\t/* How long is a tick?  Note that fractions of a millisecond are\n\t * ignored. */\n\tstruct timeval tick_timeout;\n\n\t/* How long is a tick, in milliseconds?  Derived from tick_timeout. */\n\tunsigned msec_per_tick;\n};\n\n/** The current tick is 'current_tick': add bytes to 'bucket' as specified in\n * 'cfg'. */\nint ev_token_bucket_update_(struct ev_token_bucket *bucket,\n    const struct ev_token_bucket_cfg *cfg,\n    ev_uint32_t current_tick);\n\n/** In which tick does 'tv' fall according to 'cfg'?  Note that ticks can\n * overflow easily; your code needs to handle this. */\nev_uint32_t ev_token_bucket_get_tick_(const struct timeval *tv,\n    const struct ev_token_bucket_cfg *cfg);\n\n/** Adjust 'bucket' to respect 'cfg', and note that it was last updated in\n * 'current_tick'.  If 'reinitialize' is true, we are changing the\n * configuration of 'bucket'; otherwise, we are setting it up for the first\n * time.\n */\nint ev_token_bucket_init_(struct ev_token_bucket *bucket,\n    const struct ev_token_bucket_cfg *cfg,\n    ev_uint32_t current_tick,\n    int reinitialize);\n\nint bufferevent_remove_from_rate_limit_group_internal_(struct bufferevent *bev,\n    int unsuspend);\n\n/** Decrease the read limit of 'b' by 'n' bytes */\n#define ev_token_bucket_decrement_read(b,n)\t\\\n\tdo {\t\t\t\t\t\\\n\t\t(b)->read_limit -= (n);\t\t\\\n\t} while (0)\n/** Decrease the write limit of 'b' by 'n' bytes */\n#define ev_token_bucket_decrement_write(b,n)\t\\\n\tdo {\t\t\t\t\t\\\n\t\t(b)->write_limit -= (n);\t\\\n\t} while (0)\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "sample",
          "type": "tree",
          "content": null
        },
        {
          "name": "select.c",
          "type": "blob",
          "size": 8.5234375,
          "content": "/*\t$OpenBSD: select.c,v 1.2 2002/06/25 15:50:15 mickey Exp $\t*/\n\n/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_SELECT\n\n#ifdef __APPLE__\n/* Apple wants us to define this if we might ever pass more than\n * FD_SETSIZE bits to select(). */\n#define _DARWIN_UNLIMITED_SELECT\n#endif\n\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#ifdef EVENT__HAVE_SYS_SELECT_H\n#include <sys/select.h>\n#endif\n#include <sys/queue.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <errno.h>\n\n#include \"event-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"event2/thread.h\"\n#include \"evthread-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n\n#ifndef EVENT__HAVE_FD_MASK\n/* This type is mandatory, but Android doesn't define it. */\ntypedef unsigned long fd_mask;\n#endif\n\n#ifndef NFDBITS\n#define NFDBITS (sizeof(fd_mask)*8)\n#endif\n\n/* Divide positive x by y, rounding up. */\n#define DIV_ROUNDUP(x, y)   (((x)+((y)-1))/(y))\n\n/* How many bytes to allocate for N fds? */\n#define SELECT_ALLOC_SIZE(n) \\\n\t(DIV_ROUNDUP(n, NFDBITS) * sizeof(fd_mask))\n\nstruct selectop {\n\tint event_fds;\t\t/* Highest fd in fd set */\n\tint event_fdsz;\n\tint resize_out_sets;\n\tfd_set *event_readset_in;\n\tfd_set *event_writeset_in;\n\tfd_set *event_readset_out;\n\tfd_set *event_writeset_out;\n};\n\nstatic void *select_init(struct event_base *);\nstatic int select_add(struct event_base *, int, short old, short events, void*);\nstatic int select_del(struct event_base *, int, short old, short events, void*);\nstatic int select_dispatch(struct event_base *, struct timeval *);\nstatic void select_dealloc(struct event_base *);\n\nconst struct eventop selectops = {\n\t\"select\",\n\tselect_init,\n\tselect_add,\n\tselect_del,\n\tselect_dispatch,\n\tselect_dealloc,\n\t1, /* need_reinit. */\n\tEV_FEATURE_FDS,\n\t0,\n};\n\nstatic int select_resize(struct selectop *sop, int fdsz);\nstatic void select_free_selectop(struct selectop *sop);\n\nstatic void *\nselect_init(struct event_base *base)\n{\n\tstruct selectop *sop;\n\n\tif (!(sop = mm_calloc(1, sizeof(struct selectop))))\n\t\treturn (NULL);\n\n\tif (select_resize(sop, SELECT_ALLOC_SIZE(32 + 1))) {\n\t\tselect_free_selectop(sop);\n\t\treturn (NULL);\n\t}\n\n\tif (sigfd_init_(base) < 0)\n\t\tevsig_init_(base);\n\n\tevutil_weakrand_seed_(&base->weakrand_seed, 0);\n\n\treturn (sop);\n}\n\n#ifdef CHECK_INVARIANTS\nstatic void\ncheck_selectop(struct selectop *sop)\n{\n\t/* nothing to be done here */\n}\n#else\n#define check_selectop(sop) do { (void) sop; } while (0)\n#endif\n\nstatic int\nselect_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tint res=0, i, j, nfds;\n\tstruct selectop *sop = base->evbase;\n\n\tcheck_selectop(sop);\n\tif (sop->resize_out_sets) {\n\t\tfd_set *readset_out=NULL, *writeset_out=NULL;\n\t\tsize_t sz = sop->event_fdsz;\n\t\tif (!(readset_out = mm_realloc(sop->event_readset_out, sz)))\n\t\t\treturn (-1);\n\t\tsop->event_readset_out = readset_out;\n\t\tif (!(writeset_out = mm_realloc(sop->event_writeset_out, sz))) {\n\t\t\t/* We don't free readset_out here, since it was\n\t\t\t * already successfully reallocated. The next time\n\t\t\t * we call select_dispatch, the realloc will be a\n\t\t\t * no-op. */\n\t\t\treturn (-1);\n\t\t}\n\t\tsop->event_writeset_out = writeset_out;\n\t\tsop->resize_out_sets = 0;\n\t}\n\n\tmemcpy(sop->event_readset_out, sop->event_readset_in,\n\t       sop->event_fdsz);\n\tmemcpy(sop->event_writeset_out, sop->event_writeset_in,\n\t       sop->event_fdsz);\n\n\tnfds = sop->event_fds+1;\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\tres = select(nfds, sop->event_readset_out,\n\t    sop->event_writeset_out, NULL, tv);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tcheck_selectop(sop);\n\n\tif (res == -1) {\n\t\tif (errno != EINTR) {\n\t\t\tevent_warn(\"select\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tevent_debug((\"%s: select reports %d\", __func__, res));\n\n\tcheck_selectop(sop);\n\ti = evutil_weakrand_range_(&base->weakrand_seed, nfds);\n\tfor (j = 0; j < nfds; ++j) {\n\t\tif (++i >= nfds)\n\t\t\ti = 0;\n\t\tres = 0;\n\t\tif (FD_ISSET(i, sop->event_readset_out))\n\t\t\tres |= EV_READ;\n\t\tif (FD_ISSET(i, sop->event_writeset_out))\n\t\t\tres |= EV_WRITE;\n\n\t\tif (res == 0)\n\t\t\tcontinue;\n\n\t\tevmap_io_active_(base, i, res);\n\t}\n\tcheck_selectop(sop);\n\n\treturn (0);\n}\n\nstatic int\nselect_resize(struct selectop *sop, int fdsz)\n{\n\tfd_set *readset_in = NULL;\n\tfd_set *writeset_in = NULL;\n\n\tif (sop->event_readset_in)\n\t\tcheck_selectop(sop);\n\n\tif ((readset_in = mm_realloc(sop->event_readset_in, fdsz)) == NULL)\n\t\tgoto error;\n\tsop->event_readset_in = readset_in;\n\tif ((writeset_in = mm_realloc(sop->event_writeset_in, fdsz)) == NULL) {\n\t\t/* Note that this will leave event_readset_in expanded.\n\t\t * That's okay; we wouldn't want to free it, since that would\n\t\t * change the semantics of select_resize from \"expand the\n\t\t * readset_in and writeset_in, or return -1\" to \"expand the\n\t\t * *set_in members, or trash them and return -1.\"\n\t\t */\n\t\tgoto error;\n\t}\n\tsop->event_writeset_in = writeset_in;\n\tsop->resize_out_sets = 1;\n\n\tmemset((char *)sop->event_readset_in + sop->event_fdsz, 0,\n\t    fdsz - sop->event_fdsz);\n\tmemset((char *)sop->event_writeset_in + sop->event_fdsz, 0,\n\t    fdsz - sop->event_fdsz);\n\n\tsop->event_fdsz = fdsz;\n\tcheck_selectop(sop);\n\n\treturn (0);\n\n error:\n\tevent_warn(\"malloc\");\n\treturn (-1);\n}\n\n\nstatic int\nselect_add(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct selectop *sop = base->evbase;\n\t(void) p;\n\n\tEVUTIL_ASSERT((events & EV_SIGNAL) == 0);\n\tcheck_selectop(sop);\n\t/*\n\t * Keep track of the highest fd, so that we can calculate the size\n\t * of the fd_sets for select(2)\n\t */\n\tif (sop->event_fds < fd) {\n\t\tint fdsz = sop->event_fdsz;\n\n\t\tif (fdsz < (int)sizeof(fd_mask))\n\t\t\tfdsz = (int)sizeof(fd_mask);\n\n\t\t/* In theory we should worry about overflow here.  In\n\t\t * reality, though, the highest fd on a unixy system will\n\t\t * not overflow here. XXXX */\n\t\twhile (fdsz < (int) SELECT_ALLOC_SIZE(fd + 1))\n\t\t\tfdsz *= 2;\n\n\t\tif (fdsz != sop->event_fdsz) {\n\t\t\tif (select_resize(sop, fdsz)) {\n\t\t\t\tcheck_selectop(sop);\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t}\n\n\t\tsop->event_fds = fd;\n\t}\n\n\tif (events & EV_READ)\n\t\tFD_SET(fd, sop->event_readset_in);\n\tif (events & EV_WRITE)\n\t\tFD_SET(fd, sop->event_writeset_in);\n\tcheck_selectop(sop);\n\n\treturn (0);\n}\n\n/*\n * Nothing to be done here.\n */\n\nstatic int\nselect_del(struct event_base *base, int fd, short old, short events, void *p)\n{\n\tstruct selectop *sop = base->evbase;\n\t(void)p;\n\n\tEVUTIL_ASSERT((events & EV_SIGNAL) == 0);\n\tcheck_selectop(sop);\n\n\tif (sop->event_fds < fd) {\n\t\tcheck_selectop(sop);\n\t\treturn (0);\n\t}\n\n\tif (events & EV_READ)\n\t\tFD_CLR(fd, sop->event_readset_in);\n\n\tif (events & EV_WRITE)\n\t\tFD_CLR(fd, sop->event_writeset_in);\n\n\tcheck_selectop(sop);\n\treturn (0);\n}\n\nstatic void\nselect_free_selectop(struct selectop *sop)\n{\n\tif (sop->event_readset_in)\n\t\tmm_free(sop->event_readset_in);\n\tif (sop->event_writeset_in)\n\t\tmm_free(sop->event_writeset_in);\n\tif (sop->event_readset_out)\n\t\tmm_free(sop->event_readset_out);\n\tif (sop->event_writeset_out)\n\t\tmm_free(sop->event_writeset_out);\n\n\tmemset(sop, 0, sizeof(struct selectop));\n\tmm_free(sop);\n}\n\nstatic void\nselect_dealloc(struct event_base *base)\n{\n\tevsig_dealloc_(base);\n\n\tselect_free_selectop(base->evbase);\n}\n\n#endif /* EVENT__HAVE_SELECT */\n"
        },
        {
          "name": "sha1.c",
          "type": "blob",
          "size": 8.80078125,
          "content": "/*\nSHA-1 in C\nBy Steve Reid <steve@edmweb.com>\n100% Public Domain\n\nTest Vectors (from FIPS PUB 180-1)\n\"abc\"\n  A9993E36 4706816A BA3E2571 7850C26C 9CD0D89D\n\"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\"\n  84983E44 1C3BD26E BAAE4AA1 F95129E5 E54670F1\nA million repetitions of \"a\"\n  34AA973C D4C4DAA4 F61EEB2B DBAD2731 6534016F\n*/\n\n/* #define LITTLE_ENDIAN * This should be #define'd already, if true. */\n/* #define SHA1HANDSOFF * Copies data before messing with it. */\n\n#define SHA1HANDSOFF\n\n#if defined(__clang__)\n#elif defined(__GNUC__)\n#pragma GCC diagnostic push\n/* Ignore the case when SHA1Transform() called with 'char *', that code passed\n * buffer of 64 bytes anyway (at least now) */\n#pragma GCC diagnostic ignored \"-Wstringop-overread\"\n#endif\n\n#include <stdio.h>\n#include <string.h>\n\n/* for uint32_t */\n#include <stdint.h>\n\n#include \"sha1.h\"\n\n#define rol(value, bits) (((value) << (bits)) | ((value) >> (32 - (bits))))\n\n/* blk0() and blk() perform the initial expand. */\n/* I got the idea of expanding during the round function from SSLeay */\n#if defined(LITTLE_ENDIAN)\n#define blk0(i)                                                                \\\n    (block->l[i] = (rol(block->l[i], 24) & 0xFF00FF00) |                       \\\n                   (rol(block->l[i], 8) & 0x00FF00FF))\n#elif defined(BIG_ENDIAN)\n#define blk0(i) block->l[i]\n#else\n#error \"Endianness not defined!\"\n#endif\n#define blk(i)                                                                 \\\n    (block->l[i & 15] = rol(block->l[(i + 13) & 15] ^ block->l[(i + 8) & 15] ^ \\\n                                block->l[(i + 2) & 15] ^ block->l[i & 15],     \\\n                            1))\n\n/* (R0+R1), R2, R3, R4 are the different operations used in SHA1 */\n#define R0(v, w, x, y, z, i)                                                   \\\n    z += ((w & (x ^ y)) ^ y) + blk0(i) + 0x5A827999 + rol(v, 5);               \\\n    w = rol(w, 30);\n#define R1(v, w, x, y, z, i)                                                   \\\n    z += ((w & (x ^ y)) ^ y) + blk(i) + 0x5A827999 + rol(v, 5);                \\\n    w = rol(w, 30);\n#define R2(v, w, x, y, z, i)                                                   \\\n    z += (w ^ x ^ y) + blk(i) + 0x6ED9EBA1 + rol(v, 5);                        \\\n    w = rol(w, 30);\n#define R3(v, w, x, y, z, i)                                                   \\\n    z += (((w | x) & y) | (w & x)) + blk(i) + 0x8F1BBCDC + rol(v, 5);          \\\n    w = rol(w, 30);\n#define R4(v, w, x, y, z, i)                                                   \\\n    z += (w ^ x ^ y) + blk(i) + 0xCA62C1D6 + rol(v, 5);                        \\\n    w = rol(w, 30);\n\ntypedef struct {\n    uint32_t state[5];\n    uint32_t count[2];\n    unsigned char buffer[64];\n} SHA1_CTX;\n\nstatic void SHA1Transform(uint32_t state[5], const unsigned char buffer[64]);\n\nstatic void SHA1Init(SHA1_CTX *context);\n\nstatic void SHA1Update(SHA1_CTX *context, const unsigned char *data, uint32_t len);\n\nstatic void SHA1Final(unsigned char digest[20], SHA1_CTX *context);\n\n\n/* Hash a single 512-bit block. This is the core of the algorithm. */\n\nstatic void SHA1Transform(uint32_t state[5], const unsigned char buffer[64]) {\n    uint32_t a, b, c, d, e;\n\n    typedef union {\n        unsigned char c[64];\n        uint32_t l[16];\n    } CHAR64LONG16;\n\n#ifdef SHA1HANDSOFF\n    CHAR64LONG16 block[1]; /* use array to appear as a pointer */\n\n    memcpy(block, buffer, 64);\n#else\n    /* The following had better never be used because it causes the\n     * pointer-to-const buffer to be cast into a pointer to non-const.\n     * And the result is written through.  I threw a \"const\" in, hoping\n     * this will cause a diagnostic.\n     */\n    CHAR64LONG16 *block = (const CHAR64LONG16 *)buffer;\n#endif\n    /* Copy context->state[] to working vars */\n    a = state[0];\n    b = state[1];\n    c = state[2];\n    d = state[3];\n    e = state[4];\n    /* 4 rounds of 20 operations each. Loop unrolled. */\n    R0(a, b, c, d, e, 0);\n    R0(e, a, b, c, d, 1);\n    R0(d, e, a, b, c, 2);\n    R0(c, d, e, a, b, 3);\n    R0(b, c, d, e, a, 4);\n    R0(a, b, c, d, e, 5);\n    R0(e, a, b, c, d, 6);\n    R0(d, e, a, b, c, 7);\n    R0(c, d, e, a, b, 8);\n    R0(b, c, d, e, a, 9);\n    R0(a, b, c, d, e, 10);\n    R0(e, a, b, c, d, 11);\n    R0(d, e, a, b, c, 12);\n    R0(c, d, e, a, b, 13);\n    R0(b, c, d, e, a, 14);\n    R0(a, b, c, d, e, 15);\n    R1(e, a, b, c, d, 16);\n    R1(d, e, a, b, c, 17);\n    R1(c, d, e, a, b, 18);\n    R1(b, c, d, e, a, 19);\n    R2(a, b, c, d, e, 20);\n    R2(e, a, b, c, d, 21);\n    R2(d, e, a, b, c, 22);\n    R2(c, d, e, a, b, 23);\n    R2(b, c, d, e, a, 24);\n    R2(a, b, c, d, e, 25);\n    R2(e, a, b, c, d, 26);\n    R2(d, e, a, b, c, 27);\n    R2(c, d, e, a, b, 28);\n    R2(b, c, d, e, a, 29);\n    R2(a, b, c, d, e, 30);\n    R2(e, a, b, c, d, 31);\n    R2(d, e, a, b, c, 32);\n    R2(c, d, e, a, b, 33);\n    R2(b, c, d, e, a, 34);\n    R2(a, b, c, d, e, 35);\n    R2(e, a, b, c, d, 36);\n    R2(d, e, a, b, c, 37);\n    R2(c, d, e, a, b, 38);\n    R2(b, c, d, e, a, 39);\n    R3(a, b, c, d, e, 40);\n    R3(e, a, b, c, d, 41);\n    R3(d, e, a, b, c, 42);\n    R3(c, d, e, a, b, 43);\n    R3(b, c, d, e, a, 44);\n    R3(a, b, c, d, e, 45);\n    R3(e, a, b, c, d, 46);\n    R3(d, e, a, b, c, 47);\n    R3(c, d, e, a, b, 48);\n    R3(b, c, d, e, a, 49);\n    R3(a, b, c, d, e, 50);\n    R3(e, a, b, c, d, 51);\n    R3(d, e, a, b, c, 52);\n    R3(c, d, e, a, b, 53);\n    R3(b, c, d, e, a, 54);\n    R3(a, b, c, d, e, 55);\n    R3(e, a, b, c, d, 56);\n    R3(d, e, a, b, c, 57);\n    R3(c, d, e, a, b, 58);\n    R3(b, c, d, e, a, 59);\n    R4(a, b, c, d, e, 60);\n    R4(e, a, b, c, d, 61);\n    R4(d, e, a, b, c, 62);\n    R4(c, d, e, a, b, 63);\n    R4(b, c, d, e, a, 64);\n    R4(a, b, c, d, e, 65);\n    R4(e, a, b, c, d, 66);\n    R4(d, e, a, b, c, 67);\n    R4(c, d, e, a, b, 68);\n    R4(b, c, d, e, a, 69);\n    R4(a, b, c, d, e, 70);\n    R4(e, a, b, c, d, 71);\n    R4(d, e, a, b, c, 72);\n    R4(c, d, e, a, b, 73);\n    R4(b, c, d, e, a, 74);\n    R4(a, b, c, d, e, 75);\n    R4(e, a, b, c, d, 76);\n    R4(d, e, a, b, c, 77);\n    R4(c, d, e, a, b, 78);\n    R4(b, c, d, e, a, 79);\n    /* Add the working vars back into context.state[] */\n    state[0] += a;\n    state[1] += b;\n    state[2] += c;\n    state[3] += d;\n    state[4] += e;\n#ifdef SHA1HANDSOFF\n    memset(block, '\\0', sizeof(block));\n#endif\n}\n\n/* SHA1Init - Initialize new context */\n\nstatic void SHA1Init(SHA1_CTX *context) {\n    /* SHA1 initialization constants */\n    context->state[0] = 0x67452301;\n    context->state[1] = 0xEFCDAB89;\n    context->state[2] = 0x98BADCFE;\n    context->state[3] = 0x10325476;\n    context->state[4] = 0xC3D2E1F0;\n    context->count[0] = context->count[1] = 0;\n}\n\n/* Run your data through this. */\n\nstatic void SHA1Update(SHA1_CTX *context, const unsigned char *data, uint32_t len) {\n    uint32_t i;\n\n    uint32_t j;\n\n    j = context->count[0];\n    if ((context->count[0] += len << 3) < j)\n        context->count[1]++;\n    context->count[1] += (len >> 29);\n    j = (j >> 3) & 63;\n    if ((j + len) > 63) {\n        memcpy(&context->buffer[j], data, (i = 64 - j));\n        SHA1Transform(context->state, context->buffer);\n        for (; i + 63 < len; i += 64) {\n            SHA1Transform(context->state, &data[i]);\n        }\n        j = 0;\n    } else\n        i = 0;\n    memcpy(&context->buffer[j], &data[i], len - i);\n}\n\n/* Add padding and return the message digest. */\n\nstatic void SHA1Final(unsigned char digest[20], SHA1_CTX *context) {\n    unsigned i;\n\n    unsigned char finalcount[8];\n\n    unsigned char c;\n\n#if 0 /* untested \"improvement\" by DHR */\n    /* Convert context->count to a sequence of bytes\n     * in finalcount.  Second element first, but\n     * big-endian order within element.\n     * But we do it all backwards.\n     */\n    unsigned char *fcp = &finalcount[8];\n\n    for (i = 0; i < 2; i++)\n    {\n        uint32_t t = context->count[i];\n\n        int j;\n\n        for (j = 0; j < 4; t >>= 8, j++)\n            *--fcp = (unsigned char) t}\n#else\n    for (i = 0; i < 8; i++) {\n        finalcount[i] = (unsigned char)((context->count[(i >= 4 ? 0 : 1)] >>\n                                         ((3 - (i & 3)) * 8)) &\n                                        255); /* Endian independent */\n    }\n#endif\n    c = 0200;\n    SHA1Update(context, &c, 1);\n    while ((context->count[0] & 504) != 448) {\n        c = 0000;\n        SHA1Update(context, &c, 1);\n    }\n    SHA1Update(context, finalcount, 8); /* Should cause a SHA1Transform() */\n    for (i = 0; i < 20; i++) {\n        digest[i] =\n            (unsigned char)((context->state[i >> 2] >> ((3 - (i & 3)) * 8)) &\n                            255);\n    }\n    /* Wipe variables */\n    memset(context, '\\0', sizeof(*context));\n    memset(&finalcount, '\\0', sizeof(finalcount));\n}\n\nvoid builtin_SHA1(char *hash_out, const char *str, int len) {\n    SHA1_CTX ctx;\n    int ii;\n\n    SHA1Init(&ctx);\n    for (ii = 0; ii < len; ii += 1)\n        SHA1Update(&ctx, (const unsigned char *)str + ii, 1);\n    SHA1Final((unsigned char *)hash_out, &ctx);\n}\n"
        },
        {
          "name": "sha1.h",
          "type": "blob",
          "size": 0.208984375,
          "content": "#ifndef SHA1_H\n#define SHA1_H\n\n/*\n   SHA-1 in C\n   By Steve Reid <steve@edmweb.com>\n   100% Public Domain\n */\n\n#include \"stdint.h\"\n\nvoid builtin_SHA1(char *hash_out, const char *str, int len);\n\n#endif /* SHA1_H */\n"
        },
        {
          "name": "signal.c",
          "type": "blob",
          "size": 12.9931640625,
          "content": "/*\t$OpenBSD: select.c,v 1.2 2002/06/25 15:50:15 mickey Exp $\t*/\n\n/*\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n#define WIN32_LEAN_AND_MEAN\n#include <winsock2.h>\n#include <windows.h>\n#undef WIN32_LEAN_AND_MEAN\n#endif\n#include <sys/types.h>\n#ifdef EVENT__HAVE_SYS_TIME_H\n#include <sys/time.h>\n#endif\n#include <sys/queue.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#ifdef EVENT__HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#include <errno.h>\n#ifdef EVENT__HAVE_FCNTL_H\n#include <fcntl.h>\n#endif\n\n#include \"event2/event.h\"\n#include \"event2/event_struct.h\"\n#include \"event-internal.h\"\n#include \"event2/util.h\"\n#include \"evsignal-internal.h\"\n#include \"log-internal.h\"\n#include \"evmap-internal.h\"\n#include \"evthread-internal.h\"\n\n/*\n  signal.c\n\n  This is the signal-handling implementation we use for backends that don't\n  have a better way to do signal handling.  It uses sigaction() or signal()\n  to set a signal handler, and a socket pair to tell the event base when\n\n  Note that I said \"the event base\" : only one event base can be set up to use\n  this at a time.  For historical reasons and backward compatibility, if you\n  add an event for a signal to event_base A, then add an event for a signal\n  (any signal!) to event_base B, event_base B will get informed about the\n  signal, but event_base A won't.\n\n  It would be neat to change this behavior in some future version of Libevent.\n  kqueue already does something far more sensible.  We can make all backends\n  on Linux do a reasonable thing using signalfd.\n*/\n\n#ifndef _WIN32\n/* Windows wants us to call our signal handlers as __cdecl.  Nobody else\n * expects you to do anything crazy like this. */\n#ifndef __cdecl\n#define __cdecl\n#endif\n#endif\n\nstatic int evsig_add(struct event_base *, evutil_socket_t, short, short, void *);\nstatic int evsig_del(struct event_base *, evutil_socket_t, short, short, void *);\n\nstatic const struct eventop evsigops = {\n\t\"signal\",\n\tNULL,\n\tevsig_add,\n\tevsig_del,\n\tNULL,\n\tNULL,\n\t0, 0, 0\n};\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n/* Lock for evsig_base and evsig_base_n_signals_added fields. */\nstatic void *evsig_base_lock = NULL;\n#endif\n/* The event base that's currently getting informed about signals. */\nstatic struct event_base *evsig_base = NULL;\n/* A copy of evsig_base->sigev_n_signals_added. */\nstatic int evsig_base_n_signals_added = 0;\nstatic evutil_socket_t evsig_base_fd = -1;\n\nstatic void __cdecl evsig_handler(int sig);\n\n#define EVSIGBASE_LOCK() EVLOCK_LOCK(evsig_base_lock, 0)\n#define EVSIGBASE_UNLOCK() EVLOCK_UNLOCK(evsig_base_lock, 0)\n\nvoid\nevsig_set_base_(struct event_base *base)\n{\n\tEVSIGBASE_LOCK();\n\tevsig_base = base;\n\tevsig_base_n_signals_added = base->sig.ev_n_signals_added;\n\tevsig_base_fd = base->sig.ev_signal_pair[1];\n\tEVSIGBASE_UNLOCK();\n}\n\n/* Callback for when the signal handler write a byte to our signaling socket */\nstatic void\nevsig_cb(evutil_socket_t fd, short what, void *arg)\n{\n\tstatic char signals[1024];\n\tev_ssize_t n;\n\tint i;\n\tint ncaught[NSIG];\n\tstruct event_base *base;\n\n\tbase = arg;\n\n\tmemset(&ncaught, 0, sizeof(ncaught));\n\n\twhile (1) {\n#ifdef _WIN32\n\t\tn = recv(fd, signals, sizeof(signals), 0);\n#else\n\t\tn = read(fd, signals, sizeof(signals));\n#endif\n\t\tif (n == -1) {\n\t\t\tint err = evutil_socket_geterror(fd);\n\t\t\tif (! EVUTIL_ERR_RW_RETRIABLE(err))\n\t\t\t\tevent_sock_err(1, fd, \"%s: recv\", __func__);\n\t\t\tbreak;\n\t\t} else if (n == 0) {\n\t\t\t/* XXX warn? */\n\t\t\tbreak;\n\t\t}\n\t\tfor (i = 0; i < n; ++i) {\n\t\t\tev_uint8_t sig = signals[i];\n\t\t\tif (sig < NSIG)\n\t\t\t\tncaught[sig]++;\n\t\t}\n\t}\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tfor (i = 0; i < NSIG; ++i) {\n\t\tif (ncaught[i])\n\t\t\tevmap_signal_active_(base, i, ncaught[i]);\n\t}\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nint\nevsig_init_(struct event_base *base)\n{\n\t/*\n\t * Our signal handler is going to write to one end of the socket\n\t * pair to wake up our event loop.  The event loop then scans for\n\t * signals that got delivered.\n\t */\n\tif (evutil_make_internal_pipe_(base->sig.ev_signal_pair) == -1) {\n#ifdef _WIN32\n\t\t/* Make this nonfatal on win32, where sometimes people\n\t\t   have localhost firewalled. */\n\t\tevent_sock_warn(-1, \"%s: socketpair\", __func__);\n#else\n\t\tevent_sock_err(1, -1, \"%s: socketpair\", __func__);\n#endif\n\t\treturn -1;\n\t}\n\n\tif (base->sig.sh_old) {\n\t\tmm_free(base->sig.sh_old);\n\t}\n\tbase->sig.sh_old = NULL;\n\tbase->sig.sh_old_max = 0;\n\n\tevent_assign(&base->sig.ev_signal, base, base->sig.ev_signal_pair[0],\n\t\tEV_READ | EV_PERSIST, evsig_cb, base);\n\n\tbase->sig.ev_signal.ev_flags |= EVLIST_INTERNAL;\n\tevent_priority_set(&base->sig.ev_signal, 0);\n\n\tbase->evsigsel = &evsigops;\n\n\treturn 0;\n}\n\n/* Helper: resize saved signal handler array up to the highest signal\n   number. A dynamic array is used to keep footprint on the low side. */\nint\nevsig_ensure_saved_(struct evsig_info *sig, int evsignal)\n{\n\tif (evsignal >= sig->sh_old_max) {\n\t\tvoid *p;\n\t\tint new_max = evsignal + 1;\n\t\tevent_debug((\"%s: evsignal (%d) >= sh_old_max (%d), resizing\",\n\t\t\t    __func__, evsignal, sig->sh_old_max));\n\t\tp = mm_realloc(sig->sh_old, new_max * sizeof(*sig->sh_old));\n\t\tif (p == NULL) {\n\t\t\tevent_warn(\"realloc\");\n\t\t\treturn (-1);\n\t\t}\n\n\t\tmemset((char *)p + sig->sh_old_max * sizeof(*sig->sh_old),\n\t\t    0, (new_max - sig->sh_old_max) * sizeof(*sig->sh_old));\n\n\t\tsig->sh_old_max = new_max;\n\t\tsig->sh_old = p;\n\t}\n\treturn 0;\n}\n\n/* Helper: set the signal handler for evsignal to handler in base, so that\n * we can restore the original handler when we clear the current one. */\nint\nevsig_set_handler_(struct event_base *base,\n    int evsignal, void (__cdecl *handler)(int))\n{\n#ifdef EVENT__HAVE_SIGACTION\n\tstruct sigaction sa;\n#else\n\tev_sighandler_t sh;\n#endif\n\tstruct evsig_info *sig = &base->sig;\n\n\t/* ensure saved array is large enough */\n\tif (evsig_ensure_saved_(sig, evsignal) < 0)\n\t\treturn (-1);\n\n\t/* allocate space for previous handler out of dynamic array */\n\tsig->sh_old[evsignal] = mm_malloc(sizeof *sig->sh_old[evsignal]);\n\tif (sig->sh_old[evsignal] == NULL) {\n\t\tevent_warn(\"malloc\");\n\t\treturn (-1);\n\t}\n\n\t/* save previous handler and setup new handler */\n#ifdef EVENT__HAVE_SIGACTION\n\tmemset(&sa, 0, sizeof(sa));\n\tsa.sa_handler = handler;\n#ifdef SA_RESTART\n\tsa.sa_flags |= SA_RESTART;\n#endif\n\tsigfillset(&sa.sa_mask);\n\n\tif (sigaction(evsignal, &sa, sig->sh_old[evsignal]) == -1) {\n\t\tevent_warn(\"sigaction\");\n\t\tmm_free(sig->sh_old[evsignal]);\n\t\tsig->sh_old[evsignal] = NULL;\n\t\treturn (-1);\n\t}\n#else\n\tif ((sh = signal(evsignal, handler)) == SIG_ERR) {\n\t\tevent_warn(\"signal\");\n\t\tmm_free(sig->sh_old[evsignal]);\n\t\tsig->sh_old[evsignal] = NULL;\n\t\treturn (-1);\n\t}\n\t*sig->sh_old[evsignal] = sh;\n#endif\n\n\treturn (0);\n}\n\nstatic int\nevsig_add(struct event_base *base, evutil_socket_t evsignal, short old, short events, void *p)\n{\n\tstruct evsig_info *sig = &base->sig;\n\t(void)p;\n\n\tEVUTIL_ASSERT(evsignal >= 0 && evsignal < NSIG);\n\n\t/* catch signals if they happen quickly */\n\tEVSIGBASE_LOCK();\n\tif (evsig_base != base && evsig_base_n_signals_added) {\n\t\tevent_warnx(\"Added a signal to event base %p with signals \"\n\t\t    \"already added to event_base %p.  Only one can have \"\n\t\t    \"signals at a time with the %s backend.  The base with \"\n\t\t    \"the most recently added signal or the most recent \"\n\t\t    \"event_base_loop() call gets preference; do \"\n\t\t    \"not rely on this behavior in future Libevent versions.\",\n                   (void *)base, (void *)evsig_base, base->evsel->name);\n\t}\n\tevsig_base = base;\n\tevsig_base_n_signals_added = ++sig->ev_n_signals_added;\n\tevsig_base_fd = base->sig.ev_signal_pair[1];\n\tEVSIGBASE_UNLOCK();\n\n\tevent_debug((\"%s: %d: changing signal handler\", __func__, (int)evsignal));\n\tif (evsig_set_handler_(base, (int)evsignal, evsig_handler) == -1) {\n\t\tgoto err;\n\t}\n\n\n\tif (!sig->ev_signal_added) {\n\t\tif (event_add_nolock_(&sig->ev_signal, NULL, 0))\n\t\t\tgoto err;\n\t\tsig->ev_signal_added = 1;\n\t}\n\n\treturn (0);\n\nerr:\n\tEVSIGBASE_LOCK();\n\t--evsig_base_n_signals_added;\n\t--sig->ev_n_signals_added;\n\tEVSIGBASE_UNLOCK();\n\treturn (-1);\n}\n\nint\nevsig_restore_handler_(struct event_base *base, int evsignal)\n{\n\tint ret = 0;\n\tstruct evsig_info *sig = &base->sig;\n#ifdef EVENT__HAVE_SIGACTION\n\tstruct sigaction *sh;\n#else\n\tev_sighandler_t *sh;\n#endif\n\n\tif (evsignal >= sig->sh_old_max) {\n\t\t/* Can't actually restore. */\n\t\t/* XXXX.*/\n\t\treturn 0;\n\t}\n\n\t/* restore previous handler */\n\tsh = sig->sh_old[evsignal];\n\tsig->sh_old[evsignal] = NULL;\n#ifdef EVENT__HAVE_SIGACTION\n\tif (sigaction(evsignal, sh, NULL) == -1) {\n\t\tevent_warn(\"sigaction\");\n\t\tret = -1;\n\t}\n#else\n\tif (signal(evsignal, *sh) == SIG_ERR) {\n\t\tevent_warn(\"signal\");\n\t\tret = -1;\n\t}\n#endif\n\n\tmm_free(sh);\n\n\treturn ret;\n}\n\nstatic int\nevsig_del(struct event_base *base, evutil_socket_t evsignal, short old, short events, void *p)\n{\n\tEVUTIL_ASSERT(evsignal >= 0 && evsignal < NSIG);\n\n\tevent_debug((\"%s: \"EV_SOCK_FMT\": restoring signal handler\",\n\t\t__func__, EV_SOCK_ARG(evsignal)));\n\n\tEVSIGBASE_LOCK();\n\t--evsig_base_n_signals_added;\n\t--base->sig.ev_n_signals_added;\n\tEVSIGBASE_UNLOCK();\n\n\treturn (evsig_restore_handler_(base, (int)evsignal));\n}\n\nstatic void __cdecl\nevsig_handler(int sig)\n{\n\tint save_errno = errno;\n#ifdef _WIN32\n\tint socket_errno = EVUTIL_SOCKET_ERROR();\n#endif\n\tev_uint8_t msg;\n\n\tif (evsig_base == NULL) {\n\t\tevent_warnx(\n\t\t\t\"%s: received signal %d, but have no base configured\",\n\t\t\t__func__, sig);\n\t\treturn;\n\t}\n\n#ifndef EVENT__HAVE_SIGACTION\n\tsignal(sig, evsig_handler);\n#endif\n\n\t/* Wake up our notification mechanism */\n\tmsg = sig;\n#ifdef _WIN32\n\tsend(evsig_base_fd, (char*)&msg, 1, 0);\n#else\n\tfor (;;) {\n\t\t/*\n\t\t * errno is only set to provide a descriptive message for event_warnx\n\t\t * if write returns 0. Not setting it will result in \"No error\" message\n\t\t * because write does not set errno when returning 0.\n\t\t *\n\t\t * EAGAIN will print \"Try again\" message. Another idea is to use\n\t\t * ENOSPC, but since we use non blocking sockets EAGAIN is preferable.\n\t\t *\n\t\t * Other than setting this text of the logged warning, the value in\n\t\t * errno has no further effect.\n\t\t */\n\t\terrno = EAGAIN;\n\t\tif (0 >= write(evsig_base_fd, &msg, 1)) {\n\t\t\tif (errno == EINTR)\n\t\t\t\tcontinue;\n\t\t\tevent_warnx(\"%s: write: %s\", __func__, strerror(errno));\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\terrno = save_errno;\n#ifdef _WIN32\n\tEVUTIL_SET_SOCKET_ERROR(socket_errno);\n#endif\n}\n\nvoid\nevsig_dealloc_(struct event_base *base)\n{\n\tint i = 0;\n\tif (base->sig.ev_signal_added) {\n\t\tevent_del(&base->sig.ev_signal);\n\t\tbase->sig.ev_signal_added = 0;\n\t}\n\t/* debug event is created in evsig_init_/event_assign even when\n\t * ev_signal_added == 0, so unassign is required */\n\tevent_debug_unassign(&base->sig.ev_signal);\n\n\tfor (i = 0; i < NSIG; ++i) {\n\t\tif (i < base->sig.sh_old_max && base->sig.sh_old[i] != NULL)\n\t\t\tevsig_restore_handler_(base, i);\n\t}\n\tEVSIGBASE_LOCK();\n\tif (base == evsig_base) {\n\t\tevsig_base = NULL;\n\t\tevsig_base_n_signals_added = 0;\n\t\tevsig_base_fd = -1;\n\t}\n\tEVSIGBASE_UNLOCK();\n\n\tif (base->sig.ev_signal_pair[0] != -1) {\n\t\tevutil_closesocket(base->sig.ev_signal_pair[0]);\n\t\tbase->sig.ev_signal_pair[0] = -1;\n\t}\n\tif (base->sig.ev_signal_pair[1] != -1) {\n\t\tevutil_closesocket(base->sig.ev_signal_pair[1]);\n\t\tbase->sig.ev_signal_pair[1] = -1;\n\t}\n\tbase->sig.sh_old_max = 0;\n\n\t/* per index frees are handled in evsig_del() */\n\tif (base->sig.sh_old) {\n\t\tmm_free(base->sig.sh_old);\n\t\tbase->sig.sh_old = NULL;\n\t}\n}\n\nstatic void\nevsig_free_globals_locks(void)\n{\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\n\tif (evsig_base_lock != NULL) {\n\t\tEVTHREAD_FREE_LOCK(evsig_base_lock, 0);\n\t\tevsig_base_lock = NULL;\n\t}\n#endif\n\treturn;\n}\n\nvoid\nevsig_free_globals_(void)\n{\n\tevsig_free_globals_locks();\n}\n\n#ifndef EVENT__DISABLE_THREAD_SUPPORT\nint\nevsig_global_setup_locks_(const int enable_locks)\n{\n\tEVTHREAD_SETUP_GLOBAL_LOCK(evsig_base_lock, 0);\n\treturn 0;\n}\n\n#endif\n"
        },
        {
          "name": "signalfd.c",
          "type": "blob",
          "size": 6.0244140625,
          "content": "/*\n * Signal handling backend based on signalfd(2) system call\n * Written by Dmitry Antipov <dantipov@cloudlinux.com> 2022\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/event-config.h\"\n\n#include <unistd.h>\n#include <sys/signalfd.h>\n\n#include \"event2/event.h\"\n#include \"event-internal.h\"\n#include \"evmap-internal.h\"\n#include \"evsignal-internal.h\"\n#include \"evthread-internal.h\"\n\nstatic int sigfd_add(struct event_base *, evutil_socket_t, short, short, void *);\nstatic int sigfd_del(struct event_base *, evutil_socket_t, short, short, void *);\n\nstatic const struct eventop sigfdops = {\n\t\"signalfd_signal\",\n\tNULL,\n\tsigfd_add,\n\tsigfd_del,\n\tNULL,\n\tNULL,\n\t0, 0, 0\n};\n\nstatic void\nsigfd_cb(evutil_socket_t fd, short what, void *arg)\n{\n\tstruct signalfd_siginfo fdsi;\n\tstruct event_base *base = arg;\n\tssize_t ret = read(fd, &fdsi, sizeof(fdsi));\n\n\tEVUTIL_ASSERT(ret == sizeof(fdsi));\n\tEVUTIL_ASSERT(fdsi.ssi_signo > 0 && fdsi.ssi_signo < NSIG);\n\tEVUTIL_ASSERT(base->sig.ev_sigevent[fdsi.ssi_signo] != NULL);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tevmap_signal_active_(base, fdsi.ssi_signo, 1);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n}\n\nstatic void\nsigfd_free_sigevent(struct event_base *base, int signo)\n{\n\tint ret;\n\tstruct event* sigev = base->sig.ev_sigevent[signo];\n\n\tEVUTIL_ASSERT(sigev != NULL);\n\tevent_del_nolock_(sigev, EVENT_DEL_AUTOBLOCK);\n\tret = close(sigev->ev_fd);\n\tEVUTIL_ASSERT(ret == 0);\n\tmm_free(sigev);\n\tbase->sig.ev_sigevent[signo] = NULL;\n}\n\nstatic int\nsigfd_add(struct event_base *base, int signo, short old, short events, void *p)\n{\n\tint sigfd;\n\tsigset_t mask;\n\tstruct event* sigev;\n\tstruct evsig_info *sig = &base->sig;\n\n\t/* EV_SIGNAL event passed from evmap_signal_add_() when setting\n           up and from evmap_signal_reinit_iter_fn() during reinit. */\n\tEVUTIL_ASSERT(p != NULL);\n\n\tEVUTIL_ASSERT(signo > 0 && signo < NSIG);\n\tsigev = base->sig.ev_sigevent[signo];\n\n\tif (sigev != NULL) {\n\t\tif (old) {\n\t\t\t/* We're performing reinit after fork(). This is\n\t\t\t   required at least for epoll(2)-based backend\n\t\t\t   because if the process uses fork(2) to create\n\t\t\t   a child process, then the child will be able\n\t\t\t   to read(2) signals that are sent to it using the\n\t\t\t   signalfd(2) file descriptor, but epoll_wait(2)\n\t\t\t   will not indicate that the signalfd file\n\t\t\t   descriptor is ready. */\n\t\t\tsigfd_free_sigevent(base, signo);\n\t\t} else {\n\t\t\t/* We have an active signal fd\n\t\t\t   for this signal already. */\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* Save previous handler just like evsig_set_handler_() does. */\n\tif (evsig_ensure_saved_(sig, signo) < 0)\n\t\treturn -1;\n\n\tsig->sh_old[signo] = mm_malloc(sizeof *sig->sh_old[signo]);\n\tif (sig->sh_old[signo] == NULL) {\n\t\tevent_warn(\"malloc() failed\");\n\t\treturn -1;\n\t}\n\n\tif (sigaction(signo, NULL, sig->sh_old[signo]) == -1) {\n\t\tevent_warn(\"sigaction() failed\");\n\t\tmm_free(sig->sh_old[signo]);\n\t\tsig->sh_old[signo] = NULL;\n\t\treturn -1;\n\t}\n\n\t/* Block the signal from being handled according to its default\n\t   disposition so it may be received via the descriptor. */\n\tsigemptyset(&mask);\n\tsigaddset(&mask, signo);\n\tif (sigprocmask(SIG_BLOCK, &mask, NULL)) {\n\t\tevent_warn(\"sigprocmask() failed\");\n\t\treturn -1;\n\t}\n\n\tsigfd = signalfd(-1, &mask, SFD_NONBLOCK | SFD_CLOEXEC);\n\tif (sigfd < 0) {\n\t\tevent_warn(\"signalfd() failed\");\n\t\tgoto unblock;\n\t}\n\n\t/* EV_READ event used to wakeup corresponding EV_SIGNAL ones. */\n\tsigev = event_new(base, sigfd, EV_READ | EV_PERSIST, sigfd_cb, base);\n\tif (!sigev)\n\t\tgoto close_fd;\n\n\t/* This was blindly copied from evsig_init_(). */\n\tsigev->ev_flags |= EVLIST_INTERNAL;\n\tevent_priority_set(sigev, 0);\n\n\tif (event_add_nolock_(sigev, NULL, 0) < 0)\n\t\tgoto free_ev;\n\n\tbase->sig.ev_sigevent[signo] = sigev;\n\treturn 0;\nfree_ev:\n\tmm_free(sigev);\nclose_fd:\n\tclose(sigfd);\nunblock:\n\tsigprocmask(SIG_UNBLOCK, &mask, NULL);\n\treturn -1;\n}\n\nstatic int\nsigfd_del(struct event_base *base, int signo, short old, short events, void *p)\n{\n\tsigset_t mask;\n\tstruct event *sigev;\n\tstruct evsig_info *sig = &base->sig;\n\n\tEVUTIL_ASSERT(signo > 0 && signo < NSIG);\n\tsigev = base->sig.ev_sigevent[signo];\n\tEVUTIL_ASSERT(sigev != NULL);\n\n\tsigemptyset(&mask);\n\tsigaddset(&mask, signo);\n\tif (sigprocmask(SIG_UNBLOCK, &mask, NULL)) {\n\t\tevent_warn(\"sigprocmask() failed\");\n\t\treturn -1;\n\t}\n\n\t/* Restore previous handler, if any. */\n\tif (signo < sig->sh_old_max) {\n\t\tstruct sigaction *sa = sig->sh_old[signo];\n\t\tif (sa) {\n\t\t\tif (sigaction(signo, sa, NULL) == -1) {\n\t\t\t\tevent_warn(\"sigaction() failed\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmm_free(sa);\n\t\t\tsig->sh_old[signo] = NULL;\n\t\t}\n\t}\n\n\tsigfd_free_sigevent(base, signo);\n\treturn 0;\n}\n\nint sigfd_init_(struct event_base *base)\n{\n\tEVUTIL_ASSERT(base != NULL);\n\tif (!(base->flags & EVENT_BASE_FLAG_USE_SIGNALFD) &&\n\t    !getenv(\"EVENT_USE_SIGNALFD\"))\n\t\treturn -1;\n\tbase->evsigsel = &sigfdops;\n\treturn 0;\n}\n"
        },
        {
          "name": "ssl-compat.h",
          "type": "blob",
          "size": 3.509765625,
          "content": "#ifndef SSL_COMPACT_H\n#define SSL_COMPACT_H\n\n#include \"event.h\"\n#include \"bufferevent-internal.h\"\n#include \"event2/bufferevent_ssl.h\"\nstruct bufferevent_ssl;\n\nstruct le_ssl_ops {\n\tvoid *(*init)(void *ssl);\n\tvoid (*free)(void *ssl, int flags);\n\tvoid (*free_raw)(void *ssl);\n\tint (*renegotiate)(void *ssl);\n\tint (*write)(void *ssl, const unsigned char *buf, size_t len);\n\tint (*read)(void *ssl, unsigned char *buf, size_t len);\n\tsize_t (*pending)(void *ssl);\n\tint (*handshake)(void *ssl);\n\tint (*get_error)(void *ssl, int ret);\n\tvoid (*clear_error)(void);\n\tint (*clear)(void *ssl);\n\tvoid (*set_connect_state)(void *ssl);\n\tvoid (*set_accept_state)(void *ssl);\n\tint (*handshake_is_ok)(int err);\n\tint (*err_is_want_read)(int err);\n\tint (*err_is_want_write)(int err);\n\tevutil_socket_t (*get_fd)(void *ssl);\n\tint (*bio_set_fd)(struct bufferevent_ssl *ssl, evutil_socket_t fd);\n\tvoid (*init_bio_counts)(struct bufferevent_ssl *bev);\n\tvoid (*decrement_buckets)(struct bufferevent_ssl *bev);\n\tvoid (*conn_closed)(\n\t\tstruct bufferevent_ssl *bev, int when, int errcode, int ret);\n\tvoid (*print_err)(int err);\n};\n\nstruct bio_data_counts {\n\tunsigned long n_written;\n\tunsigned long n_read;\n};\n\nstruct bufferevent_ssl {\n\t/* Shared fields with common bufferevent implementation code.\n\t   If we were set up with an underlying bufferevent, we use the\n\t   events here as timers only.  If we have an SSL, then we use\n\t   the events as socket events.\n\t */\n\tstruct bufferevent_private bev;\n\t/* An underlying bufferevent that we're directing our output to.\n\t   If it's NULL, then we're connected to an fd, not an evbuffer. */\n\tstruct bufferevent *underlying;\n\t/* The SSL context doing our encryption. */\n\tvoid *ssl;\n\t/* The SSL operations doing on ssl. */\n\tstruct le_ssl_ops *ssl_ops;\n\n\t/* A callback that's invoked when data arrives on our outbuf so we\n\t   know to write data to the SSL. */\n\tstruct evbuffer_cb_entry *outbuf_cb;\n\n\t/* A count of how much data the bios have read/written total.  Used\n\t   for rate-limiting. */\n\tstruct bio_data_counts counts;\n\n\t/* If this value is greater than 0, then the last SSL_write blocked,\n\t * and we need to try it again with this many bytes. */\n\tev_ssize_t last_write;\n\n#define NUM_ERRORS 3\n\tev_uint32_t errors[NUM_ERRORS];\n\n\t/* When we next get available space, we should say \"read\" instead of\n\t   \"write\". This can happen if there's a renegotiation during a read\n\t   operation. */\n\tunsigned read_blocked_on_write : 1;\n\t/* When we next get data, we should say \"write\" instead of \"read\". */\n\tunsigned write_blocked_on_read : 1;\n\t/* XXX */\n\tunsigned n_errors : 2;\n\n\t/* Are we currently connecting, accepting, or doing IO? */\n\tunsigned state : 2;\n\t/* If we reset fd, we sould reset state too */\n\tunsigned old_state : 2;\n\n\tev_uint64_t flags;\n};\n\nstruct bufferevent *bufferevent_ssl_new_impl(struct event_base *base,\n\tstruct bufferevent *underlying, evutil_socket_t fd, void *ssl,\n\tenum bufferevent_ssl_state state, int options, struct le_ssl_ops *ssl_ops);\nstruct bufferevent_ssl *bufferevent_ssl_upcast(struct bufferevent *bev);\nvoid bufferevent_ssl_put_error(\n\tstruct bufferevent_ssl *bev_ssl, unsigned long err);\nvoid bufferevent_ssl_stop_reading(struct bufferevent_ssl *bev_ssl);\nvoid bufferevent_ssl_stop_writing(struct bufferevent_ssl *bev_ssl);\nint bufferevent_ssl_renegotiate_impl(struct bufferevent *bev);\nunsigned long bufferevent_get_ssl_error(struct bufferevent *bev);\nint bufferevent_ssl_get_allow_dirty_shutdown(struct bufferevent *bev);\nvoid bufferevent_ssl_set_allow_dirty_shutdown(\n\tstruct bufferevent *bev, int allow_dirty_shutdown);\n\n#endif /* SSL_COMPACT_H */\n"
        },
        {
          "name": "strlcpy-internal.h",
          "type": "blob",
          "size": 0.408203125,
          "content": "#ifndef STRLCPY_INTERNAL_H_INCLUDED_\n#define STRLCPY_INTERNAL_H_INCLUDED_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include \"event2/event-config.h\"\n#include \"event2/visibility.h\"\n#include \"evconfig-private.h\"\n\n#ifndef EVENT__HAVE_STRLCPY\n#include <string.h>\nEVENT2_EXPORT_SYMBOL\nsize_t event_strlcpy_(char *dst, const char *src, size_t siz);\n#define strlcpy event_strlcpy_\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n\n"
        },
        {
          "name": "strlcpy.c",
          "type": "blob",
          "size": 2.50390625,
          "content": "/*\t$OpenBSD: strlcpy.c,v 1.5 2001/05/13 15:40:16 deraadt Exp $\t*/\n\n/*\n * Copyright (c) 1998 Todd C. Miller <Todd.Miller@courtesan.com>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,\n * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY\n * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL\n * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\n * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#if defined(LIBC_SCCS) && !defined(lint)\nstatic char *rcsid = \"$OpenBSD: strlcpy.c,v 1.5 2001/05/13 15:40:16 deraadt Exp $\";\n#endif /* LIBC_SCCS and not lint */\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <sys/types.h>\n\n#ifndef EVENT__HAVE_STRLCPY\n#include \"strlcpy-internal.h\"\n\n/*\n * Copy src to string dst of size siz.  At most siz-1 characters\n * will be copied.  Always NUL terminates (unless siz == 0).\n * Returns strlen(src); if retval >= siz, truncation occurred.\n */\nsize_t event_strlcpy_(char *dst, const char *src, size_t siz)\n{\n\tregister char *d = dst;\n\tregister const char *s = src;\n\tregister size_t n = siz;\n\n\t/* Copy as many bytes as will fit */\n\tif (n != 0 && --n != 0) {\n\t\tdo {\n\t\t\tif ((*d++ = *s++) == 0)\n\t\t\t\tbreak;\n\t\t} while (--n != 0);\n\t}\n\n\t/* Not enough room in dst, add NUL and traverse rest of src */\n\tif (n == 0) {\n\t\tif (siz != 0)\n\t\t\t*d = '\\0';\t\t/* NUL-terminate dst */\n\t\twhile (*s++)\n\t\t\t;\n\t}\n\n\treturn (s - src - 1);\t/* count does not include NUL */\n}\n#endif\n"
        },
        {
          "name": "test-export",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "time-internal.h",
          "type": "blob",
          "size": 3.060546875,
          "content": "/*\n * Copyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef TIME_INTERNAL_H_INCLUDED_\n#define TIME_INTERNAL_H_INCLUDED_\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef EVENT__HAVE_MACH_MACH_TIME_H\n/* For mach_timebase_info */\n#include <mach/mach_time.h>\n#endif\n\n#include <time.h>\n\n#include \"event2/util.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#if defined(EVENT__HAVE_CLOCK_GETTIME) && defined(CLOCK_MONOTONIC)\n#define HAVE_POSIX_MONOTONIC\n#elif defined(EVENT__HAVE_MACH_ABSOLUTE_TIME)\n#define HAVE_MACH_MONOTONIC\n#elif defined(_WIN32)\n#define HAVE_WIN32_MONOTONIC\n#else\n#define HAVE_FALLBACK_MONOTONIC\n#endif\n\nlong evutil_tv_to_msec_(const struct timeval *tv);\nEVENT2_EXPORT_SYMBOL\nvoid evutil_usleep_(const struct timeval *tv);\n\n#ifdef _WIN32\ntypedef ULONGLONG (WINAPI *ev_GetTickCount_func)(void);\n#endif\n\nstruct evutil_monotonic_timer {\n\n#ifdef HAVE_MACH_MONOTONIC\n\tstruct mach_timebase_info mach_timebase_units;\n#endif\n\n#ifdef HAVE_POSIX_MONOTONIC\n\tint monotonic_clock;\n#endif\n\n#ifdef HAVE_WIN32_MONOTONIC\n\tev_GetTickCount_func GetTickCount64_fn;\n\tev_GetTickCount_func GetTickCount_fn;\n\tev_uint64_t last_tick_count;\n\tev_uint64_t adjust_tick_count;\n\n\tev_uint64_t first_tick;\n\tev_uint64_t first_counter;\n\tdouble usec_per_count;\n\tint use_performance_counter;\n#endif\n\n\tstruct timeval adjust_monotonic_clock;\n\tstruct timeval last_time;\n};\n\nEVENT2_EXPORT_SYMBOL\nint evutil_configure_monotonic_time_(struct evutil_monotonic_timer *mt,\n    int flags);\nEVENT2_EXPORT_SYMBOL\nint evutil_gettime_monotonic_(struct evutil_monotonic_timer *mt, struct timeval *tv);\n\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* EVENT_INTERNAL_H_INCLUDED_ */\n"
        },
        {
          "name": "util-internal.h",
          "type": "blob",
          "size": 18.2216796875,
          "content": "/*\n * Copyright (c) 2007-2012 Niels Provos and Nick Mathewson\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#ifndef UTIL_INTERNAL_H_INCLUDED_\n#define UTIL_INTERNAL_H_INCLUDED_\n\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include <errno.h>\n\n/* For EVUTIL_ASSERT */\n#include \"log-internal.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#ifdef EVENT__HAVE_SYS_SOCKET_H\n#include <sys/socket.h>\n#endif\n#ifdef EVENT__HAVE_SYS_EVENTFD_H\n#include <sys/eventfd.h>\n#endif\n#include \"event2/util.h\"\n\n#include \"time-internal.h\"\n#include \"ipv6-internal.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/* __has_attribute() wrapper */\n#ifdef __has_attribute\n# define EVUTIL_HAS_ATTRIBUTE __has_attribute\n#endif\n/** clang 3 __has_attribute misbehaves in some versions */\n#if defined(__clang__) && __clang__ == 1\n# if defined(__apple_build_version__)\n#  if __clang_major__ <= 6\n#   undef EVUTIL_HAS_ATTRIBUTE\n#  endif\n# else /* !__apple_build_version__ */\n#  if __clang_major__ == 3 && __clang_minor__ >= 2 && __clang_minor__ <= 5\n#   undef EVUTIL_HAS_ATTRIBUTE\n#  endif\n# endif /* __apple_build_version__ */\n#endif /*\\ defined(__clang__) && __clang__ == 1 */\n#ifndef EVUTIL_HAS_ATTRIBUTE\n# define EVUTIL_HAS_ATTRIBUTE(x) 0\n#endif\n\n/* If we need magic to say \"inline\", get it for free internally. */\n#ifdef EVENT__inline\n#define inline EVENT__inline\n#endif\n\n/* Define to appropriate substitute if compiler doesn't have __func__ */\n#if defined(EVENT__HAVE___func__)\n# ifndef __func__\n#  define __func__ __func__\n# endif\n#elif defined(EVENT__HAVE___FUNCTION__)\n# define __func__ __FUNCTION__\n#else\n# define __func__ __FILE__\n#endif\n\n/* A good no-op to use in macro definitions. */\n#define EVUTIL_NIL_STMT_ ((void)0)\n/* A no-op that tricks the compiler into thinking a condition is used while\n * definitely not making any code for it.  Used to compile out asserts while\n * avoiding \"unused variable\" warnings.  The \"!\" forces the compiler to\n * do the sizeof() on an int, in case \"condition\" is a bitfield value.\n */\n#define EVUTIL_NIL_CONDITION_(condition) do { \\\n\t(void)sizeof(!(condition));  \\\n} while(0)\n\n/* Internal use only: macros to match patterns of error codes in a\n   cross-platform way.  We need these macros because of two historical\n   reasons: first, nonblocking IO functions are generally written to give an\n   error on the \"blocked now, try later\" case, so sometimes an error from a\n   read, write, connect, or accept means \"no error; just wait for more\n   data,\" and we need to look at the error code.  Second, Windows defines\n   a different set of error codes for sockets. */\n\n#ifndef _WIN32\n\n#if EAGAIN == EWOULDBLOCK\n#define EVUTIL_ERR_IS_EAGAIN(e) \\\n\t((e) == EAGAIN)\n#else\n#define EVUTIL_ERR_IS_EAGAIN(e) \\\n\t((e) == EAGAIN || (e) == EWOULDBLOCK)\n#endif\n\n/* True iff e is an error that means a read/write operation can be retried. */\n#define EVUTIL_ERR_RW_RETRIABLE(e)\t\t\t\t\\\n\t((e) == EINTR || EVUTIL_ERR_IS_EAGAIN(e))\n/* True iff e is an error that means an connect can be retried. */\n#define EVUTIL_ERR_CONNECT_RETRIABLE(e)\t\t\t\\\n\t((e) == EINTR || (e) == EINPROGRESS)\n/* True iff e is an error that means a accept can be retried. */\n#define EVUTIL_ERR_ACCEPT_RETRIABLE(e)\t\t\t\\\n\t((e) == EINTR || EVUTIL_ERR_IS_EAGAIN(e) || (e) == ECONNABORTED)\n\n/* True iff e is an error that means the connection was refused */\n#define EVUTIL_ERR_CONNECT_REFUSED(e)\t\t\t\t\t\\\n\t((e) == ECONNREFUSED)\n\n#else\n/* Win32 */\n\n#define EVUTIL_ERR_IS_EAGAIN(e) \\\n\t((e) == WSAEWOULDBLOCK || (e) == EAGAIN)\n\n#define EVUTIL_ERR_RW_RETRIABLE(e)\t\t\t\t\t\\\n\t((e) == WSAEWOULDBLOCK ||\t\t\t\t\t\\\n\t    (e) == WSAEINTR)\n\n#define EVUTIL_ERR_CONNECT_RETRIABLE(e)\t\t\t\t\t\\\n\t((e) == WSAEWOULDBLOCK ||\t\t\t\t\t\\\n\t    (e) == WSAEINTR ||\t\t\t\t\t\t\\\n\t    (e) == WSAEINPROGRESS ||\t\t\t\t\t\\\n\t    (e) == WSAEINVAL)\n\n#define EVUTIL_ERR_ACCEPT_RETRIABLE(e)\t\t\t\\\n\tEVUTIL_ERR_RW_RETRIABLE(e)\n\n#define EVUTIL_ERR_CONNECT_REFUSED(e)\t\t\t\t\t\\\n\t((e) == WSAECONNREFUSED)\n\n#endif\n\n/* Arguments for shutdown() */\n#ifdef SHUT_RD\n#define EVUTIL_SHUT_RD SHUT_RD\n#else\n#define EVUTIL_SHUT_RD 0\n#endif\n#ifdef SHUT_WR\n#define EVUTIL_SHUT_WR SHUT_WR\n#else\n#define EVUTIL_SHUT_WR 1 /* SD_SEND */\n#endif\n#ifdef SHUT_BOTH\n#define EVUTIL_SHUT_BOTH SHUT_BOTH\n#else\n#define EVUTIL_SHUT_BOTH 2\n#endif\n\n/* Helper: Verify that all the elements in 'dlist' are internally consistent.\n * Checks for circular lists and bad prev/next pointers.\n *\n * Example usage:\n *    EVUTIL_ASSERT_LIST_OK(eventlist, event, ev_next);\n */\n#define EVUTIL_ASSERT_LIST_OK(dlist, type, field) do {\t\t\t\\\n\t\tstruct type *elm1, *elm2, **nextp;\t\t\t\\\n\t\tif (LIST_EMPTY((dlist)))\t\t\t\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t/* Check list for circularity using Floyd's */\t\t\\\n\t\t/* 'Tortoise and Hare' algorithm */\t\t\t\\\n\t\telm1 = LIST_FIRST((dlist));\t\t\t\t\\\n\t\telm2 = LIST_NEXT(elm1, field);\t\t\t\t\\\n\t\twhile (elm1 && elm2) {\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(elm1 != elm2);\t\t\t\\\n\t\t\telm1 = LIST_NEXT(elm1, field);\t\t\t\\\n\t\t\telm2 = LIST_NEXT(elm2, field);\t\t\t\\\n\t\t\tif (!elm2)\t\t\t\t\t\\\n\t\t\t\tbreak;\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(elm1 != elm2);\t\t\t\\\n\t\t\telm2 = LIST_NEXT(elm2, field);\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t/* Now check next and prev pointers for consistency. */ \\\n\t\tnextp = &LIST_FIRST((dlist));\t\t\t\t\\\n\t\telm1 = LIST_FIRST((dlist));\t\t\t\t\\\n\t\twhile (elm1) {\t\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(*nextp == elm1);\t\t\t\\\n\t\t\tEVUTIL_ASSERT(nextp == elm1->field.le_prev);\t\\\n\t\t\tnextp = &LIST_NEXT(elm1, field);\t\t\\\n\t\t\telm1 = *nextp;\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n/* Helper: Verify that all the elements in a TAILQ are internally consistent.\n * Checks for circular lists and bad prev/next pointers.\n *\n * Example usage:\n *    EVUTIL_ASSERT_TAILQ_OK(activelist, event, ev_active_next);\n */\n#define EVUTIL_ASSERT_TAILQ_OK(tailq, type, field) do {\t\t\t\\\n\t\tstruct type *elm1, *elm2, **nextp;\t\t\t\\\n\t\tif (TAILQ_EMPTY((tailq)))\t\t\t\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t/* Check list for circularity using Floyd's */\t\t\\\n\t\t/* 'Tortoise and Hare' algorithm */\t\t\t\\\n\t\telm1 = TAILQ_FIRST((tailq));\t\t\t\t\\\n\t\telm2 = TAILQ_NEXT(elm1, field);\t\t\t\t\\\n\t\twhile (elm1 && elm2) {\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(elm1 != elm2);\t\t\t\\\n\t\t\telm1 = TAILQ_NEXT(elm1, field);\t\t\t\\\n\t\t\telm2 = TAILQ_NEXT(elm2, field);\t\t\t\\\n\t\t\tif (!elm2)\t\t\t\t\t\\\n\t\t\t\tbreak;\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(elm1 != elm2);\t\t\t\\\n\t\t\telm2 = TAILQ_NEXT(elm2, field);\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t/* Now check next and prev pointers for consistency. */ \\\n\t\tnextp = &TAILQ_FIRST((tailq));\t\t\t\t\\\n\t\telm1 = TAILQ_FIRST((tailq));\t\t\t\t\\\n\t\twhile (elm1) {\t\t\t\t\t\t\\\n\t\t\tEVUTIL_ASSERT(*nextp == elm1);\t\t\t\\\n\t\t\tEVUTIL_ASSERT(nextp == elm1->field.tqe_prev);\t\\\n\t\t\tnextp = &TAILQ_NEXT(elm1, field);\t\t\\\n\t\t\telm1 = *nextp;\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\tEVUTIL_ASSERT(nextp == (tailq)->tqh_last);\t\t\\\n\t} while (0)\n\n/* Locale-independent replacements for some ctypes functions.  Use these\n * when you care about ASCII's notion of character types, because you are about\n * to send those types onto the wire.\n */\nEVENT2_EXPORT_SYMBOL\nint EVUTIL_ISALPHA_(char c);\nEVENT2_EXPORT_SYMBOL\nint EVUTIL_ISALNUM_(char c);\nint EVUTIL_ISSPACE_(char c);\nEVENT2_EXPORT_SYMBOL\nint EVUTIL_ISDIGIT_(char c);\nEVENT2_EXPORT_SYMBOL\nint EVUTIL_ISXDIGIT_(char c);\nint EVUTIL_ISPRINT_(char c);\nint EVUTIL_ISLOWER_(char c);\nint EVUTIL_ISUPPER_(char c);\nEVENT2_EXPORT_SYMBOL\nchar EVUTIL_TOUPPER_(char c);\nEVENT2_EXPORT_SYMBOL\nchar EVUTIL_TOLOWER_(char c);\n\n/** Remove all trailing horizontal whitespace (space or tab) from the end of a\n * string */\nEVENT2_EXPORT_SYMBOL\nvoid evutil_rtrim_lws_(char *);\n\n\n/** Helper macro.  If we know that a given pointer points to a field in a\n    structure, return a pointer to the structure itself.  Used to implement\n    our half-baked C OO.  Example:\n\n    struct subtype {\n\tint x;\n\tstruct supertype common;\n\tint y;\n    };\n    ...\n    void fn(struct supertype *super) {\n\tstruct subtype *sub = EVUTIL_UPCAST(super, struct subtype, common);\n\t...\n    }\n */\n#define EVUTIL_UPCAST(ptr, type, field)\t\t\t\t\\\n\t((type *)(((char*)(ptr)) - evutil_offsetof(type, field)))\n\n/* As open(pathname, flags, mode), except that the file is always opened with\n * the close-on-exec flag set. (And the mode argument is mandatory.)\n */\nint evutil_open_closeonexec_(const char *pathname, int flags, unsigned mode);\n\nev_off_t evutil_fd_filesize(evutil_socket_t fd);\n\nEVENT2_EXPORT_SYMBOL\nint evutil_read_file_(const char *filename, char **content_out, size_t *len_out,\n    int is_binary);\n\nEVENT2_EXPORT_SYMBOL\nint evutil_socket_connect_(evutil_socket_t *fd_ptr, const struct sockaddr *sa, int socklen);\n\nEVENT2_EXPORT_SYMBOL\nint evutil_socket_finished_connecting_(evutil_socket_t fd);\n\n#ifdef EVENT__HAVE_AFUNIX_H\nEVENT2_EXPORT_SYMBOL\nint evutil_check_working_afunix_(void);\n#endif\n\nEVENT2_EXPORT_SYMBOL\nint evutil_ersatz_socketpair_(int, int , int, evutil_socket_t[2]);\n\nint evutil_resolve_(int family, const char *hostname, struct sockaddr *sa,\n    ev_socklen_t *socklen, int port);\n\nconst char *evutil_getenv_(const char *name);\n\n/* Structure to hold the state of our weak random number generator.\n */\nstruct evutil_weakrand_state {\n\tev_uint32_t seed;\n};\n\n#define EVUTIL_WEAKRAND_MAX EV_INT32_MAX\n\n/* Initialize the state of a week random number generator based on 'seed'.  If\n * the seed is 0, construct a new seed based on not-very-strong platform\n * entropy, like the PID and the time of day.\n *\n * This function, and the other evutil_weakrand* functions, are meant for\n * speed, not security or statistical strength.  If you need a RNG which an\n * attacker can't predict, or which passes strong statistical tests, use the\n * evutil_secure_rng* functions instead.\n */\nEVENT2_EXPORT_SYMBOL\nev_uint32_t evutil_weakrand_seed_(struct evutil_weakrand_state *state, ev_uint32_t seed);\n/* Return a pseudorandom value between 0 and EVUTIL_WEAKRAND_MAX inclusive.\n * Updates the state in 'seed' as needed -- this value must be protected by a\n * lock.\n */\nEVENT2_EXPORT_SYMBOL\nev_int32_t evutil_weakrand_(struct evutil_weakrand_state *seed);\n/* Return a pseudorandom value x such that 0 <= x < top. top must be no more\n * than EVUTIL_WEAKRAND_MAX. Updates the state in 'seed' as needed -- this\n * value must be proteced by a lock */\nEVENT2_EXPORT_SYMBOL\nev_int32_t evutil_weakrand_range_(struct evutil_weakrand_state *seed, ev_int32_t top);\n\n/* Evaluates to the same boolean value as 'p', and hints to the compiler that\n * we expect this value to be false. */\n#if defined(__GNUC__) && __GNUC__ >= 3         /* gcc 3.0 or later */\n#define EVUTIL_UNLIKELY(p) __builtin_expect(!!(p),0)\n#else\n#define EVUTIL_UNLIKELY(p) (p)\n#endif\n\n#if EVUTIL_HAS_ATTRIBUTE(fallthrough)\n#define EVUTIL_FALLTHROUGH ; __attribute__((fallthrough))\n#else\n#define EVUTIL_FALLTHROUGH /* fallthrough */\n#endif\n\n/* Replacement for assert() that calls event_errx on failure. */\n#ifdef NDEBUG\n#define EVUTIL_ASSERT(cond) EVUTIL_NIL_CONDITION_(cond)\n#define EVUTIL_FAILURE_CHECK(cond) 0\n#else\n#define EVUTIL_ASSERT(cond)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (EVUTIL_UNLIKELY(!(cond))) {\t\t\t\t\\\n\t\t\tevent_errx(EVENT_ERR_ABORT_,\t\t\t\\\n\t\t\t    \"%s:%d: Assertion %s failed in %s\",\t\t\\\n\t\t\t    __FILE__,__LINE__,#cond,__func__);\t\t\\\n\t\t\t/* In case a user-supplied handler tries to */\t\\\n\t\t\t/* return control to us, log and abort here. */\t\\\n\t\t\t(void)fprintf(stderr,\t\t\t\t\\\n\t\t\t    \"%s:%d: Assertion %s failed in %s\",\t\t\\\n\t\t\t    __FILE__,__LINE__,#cond,__func__);\t\t\\\n\t\t\tabort();\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n#define EVUTIL_FAILURE_CHECK(cond) EVUTIL_UNLIKELY(cond)\n#endif\n\n#ifndef EVENT__HAVE_STRUCT_SOCKADDR_STORAGE\n/* Replacement for sockaddr storage that we can use internally on platforms\n * that lack it.  It is not space-efficient, but neither is sockaddr_storage.\n */\nstruct sockaddr_storage {\n\tunion {\n\t\tstruct sockaddr ss_sa;\n\t\tstruct sockaddr_in ss_sin;\n\t\tstruct sockaddr_in6 ss_sin6;\n\t\tchar ss_padding[128];\n\t} ss_union;\n};\n#define ss_family ss_union.ss_sa.sa_family\n#endif\n\n/* Internal addrinfo error code.  This one is returned from only from\n * evutil_getaddrinfo_common_, when we are sure that we'll have to hit a DNS\n * server. */\n#define EVUTIL_EAI_NEED_RESOLVE      -90002\n\nstruct evdns_base;\nstruct evdns_getaddrinfo_request;\ntypedef struct evdns_getaddrinfo_request* (*evdns_getaddrinfo_fn)(\n    struct evdns_base *base,\n    const char *nodename, const char *servname,\n    const struct evutil_addrinfo *hints_in,\n    void (*cb)(int, struct evutil_addrinfo *, void *), void *arg);\nEVENT2_EXPORT_SYMBOL\nvoid evutil_set_evdns_getaddrinfo_fn_(evdns_getaddrinfo_fn fn);\ntypedef void (*evdns_getaddrinfo_cancel_fn)(\n    struct evdns_getaddrinfo_request *req);\nEVENT2_EXPORT_SYMBOL\nvoid evutil_set_evdns_getaddrinfo_cancel_fn_(evdns_getaddrinfo_cancel_fn fn);\n\n/* Customization point to override \"/etc/resolv.conf\" */\nEVENT2_EXPORT_SYMBOL\nvoid evutil_set_resolvconf_filename_(const char *filename);\nEVENT2_EXPORT_SYMBOL\nconst char *evutil_resolvconf_filename_(void);\n\nEVENT2_EXPORT_SYMBOL\nstruct evutil_addrinfo *evutil_new_addrinfo_(struct sockaddr *sa,\n    ev_socklen_t socklen, const struct evutil_addrinfo *hints);\nEVENT2_EXPORT_SYMBOL\nstruct evutil_addrinfo *evutil_dup_addrinfo_(struct evutil_addrinfo *ai);\nEVENT2_EXPORT_SYMBOL\nstruct evutil_addrinfo *evutil_addrinfo_append_(struct evutil_addrinfo *first,\n    struct evutil_addrinfo *append);\nEVENT2_EXPORT_SYMBOL\nvoid evutil_adjust_hints_for_addrconfig_(struct evutil_addrinfo *hints);\nEVENT2_EXPORT_SYMBOL\nint evutil_getaddrinfo_common_(const char *nodename, const char *servname,\n    struct evutil_addrinfo *hints, struct evutil_addrinfo **res, int *portnum);\n\nstruct evdns_getaddrinfo_request *evutil_getaddrinfo_async_(\n    struct evdns_base *dns_base,\n    const char *nodename, const char *servname,\n    const struct evutil_addrinfo *hints_in,\n    void (*cb)(int, struct evutil_addrinfo *, void *), void *arg);\nvoid evutil_getaddrinfo_cancel_async_(struct evdns_getaddrinfo_request *data);\n\n/** Return true iff sa is a looback address. (That is, it is 127.0.0.1/8, or\n * ::1). */\nEVENT2_EXPORT_SYMBOL\nint evutil_sockaddr_is_loopback_(const struct sockaddr *sa);\n\n\n/**\n    Formats a sockaddr sa into a string buffer of size outlen stored in out.\n    Returns a pointer to out.  Always writes something into out, so it's safe\n    to use the output of this function without checking it for NULL.\n */\nEVENT2_EXPORT_SYMBOL\nconst char *evutil_format_sockaddr_port_(const struct sockaddr *sa, char *out, size_t outlen);\n\nint evutil_hex_char_to_int_(char c);\n\n\nvoid evutil_free_secure_rng_globals_(void);\nvoid evutil_free_globals_(void);\n\n#ifdef _WIN32\nEVENT2_EXPORT_SYMBOL\nHMODULE evutil_load_windows_system_library_(const TCHAR *library_name);\n#endif\n\n#if defined(_MSC_VER) || defined(__MINGW32__) || defined(__MINGW64__)\n#define EV_WINDOWS 1\n#else\n#define EV_WINDOWS 0\n#endif\n\n#ifndef EV_SIZE_FMT\n#if defined(_MSC_VER) && _MSC_VER < 1400\n#define EV_U64_FMT \"%I64u\"\n#define EV_I64_FMT \"%I64d\"\n#define EV_I64_ARG(x) ((__int64)(x))\n#define EV_U64_ARG(x) ((unsigned __int64)(x))\n#else\n#define EV_U64_FMT \"%llu\"\n#define EV_I64_FMT \"%lld\"\n#define EV_I64_ARG(x) ((long long)(x))\n#define EV_U64_ARG(x) ((unsigned long long)(x))\n#endif\n#endif\n\n#ifdef _WIN32\n#define EV_SOCK_FMT EV_I64_FMT\n#define EV_SOCK_ARG(x) EV_I64_ARG((x))\n#else\n#define EV_SOCK_FMT \"%d\"\n#define EV_SOCK_ARG(x) (x)\n#endif\n\n#if defined(__STDC__) && defined(__STDC_VERSION__) && !defined(__MINGW64_VERSION_MAJOR)\n#if (__STDC_VERSION__ >= 199901L)\n#define EV_SIZE_FMT \"%zu\"\n#define EV_SSIZE_FMT \"%zd\"\n#define EV_SIZE_ARG(x) (x)\n#define EV_SSIZE_ARG(x) (x)\n#endif\n#endif\n\n#ifndef EV_SIZE_FMT\n#if (EVENT__SIZEOF_SIZE_T <= EVENT__SIZEOF_LONG)\n#define EV_SIZE_FMT \"%lu\"\n#define EV_SSIZE_FMT \"%ld\"\n#define EV_SIZE_ARG(x) ((unsigned long)(x))\n#define EV_SSIZE_ARG(x) ((long)(x))\n#else\n#define EV_SIZE_FMT EV_U64_FMT\n#define EV_SSIZE_FMT EV_I64_FMT\n#define EV_SIZE_ARG(x) EV_U64_ARG(x)\n#define EV_SSIZE_ARG(x) EV_I64_ARG(x)\n#endif\n#endif\n\n/* Either a mapping for strsignal() or snprintf(\"%d\", sig)\n * NOTE: MT-Unsafe*/\nEVENT2_EXPORT_SYMBOL\nconst char * evutil_strsignal(int sig);\n\nEVENT2_EXPORT_SYMBOL\nevutil_socket_t evutil_socket_(int domain, int type, int protocol);\nevutil_socket_t evutil_accept4_(evutil_socket_t sockfd, struct sockaddr *addr,\n    ev_socklen_t *addrlen, int flags);\n\n    /* used by one of the test programs.. */\nEVENT2_EXPORT_SYMBOL\nint evutil_make_internal_pipe_(evutil_socket_t fd[2]);\nevutil_socket_t evutil_eventfd_(unsigned initval, int flags);\n\n#ifdef SOCK_NONBLOCK\n#define EVUTIL_SOCK_NONBLOCK SOCK_NONBLOCK\n#else\n#define EVUTIL_SOCK_NONBLOCK 0x4000000\n#endif\n#ifdef SOCK_CLOEXEC\n#define EVUTIL_SOCK_CLOEXEC SOCK_CLOEXEC\n#else\n#define EVUTIL_SOCK_CLOEXEC 0x80000000\n#endif\n#ifdef EFD_NONBLOCK\n#define EVUTIL_EFD_NONBLOCK EFD_NONBLOCK\n#else\n#define EVUTIL_EFD_NONBLOCK 0x4000\n#endif\n#ifdef EFD_CLOEXEC\n#define EVUTIL_EFD_CLOEXEC EFD_CLOEXEC\n#else\n#define EVUTIL_EFD_CLOEXEC 0x8000\n#endif\n\nvoid evutil_memclear_(void *mem, size_t len);\n\nstruct in_addr;\nstruct in6_addr;\n\n/* This is a any, loopback, link-local, multicast */\nEVENT2_EXPORT_SYMBOL\nint evutil_v4addr_is_local_(const struct in_addr *in);\n/* This is a reserved, ipv4compat, ipv4map, loopback,\n * link-local, multicast, or unspecified address. */\nEVENT2_EXPORT_SYMBOL\nint evutil_v6addr_is_local_(const struct in6_addr *in);\n\n/** As strcasestr, but always searching substring in locale-independent\n    ASCII.  That's useful if you're handling data in ASCII-based protocols.\n */\nEVENT2_EXPORT_SYMBOL\nconst char* evutil_ascii_strcasestr(const char* s, const char *find);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
        },
        {
          "name": "watch.c",
          "type": "blob",
          "size": 2.818359375,
          "content": "/*\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"event2/watch.h\"\n#include \"event-internal.h\"\n#include \"evthread-internal.h\"\n\nstatic inline struct evwatch *\nevwatch_new(struct event_base *base, union evwatch_cb callback, void *arg, unsigned type)\n{\n\tstruct evwatch *watcher = mm_malloc(sizeof(struct evwatch));\n\tif (!watcher)\n\t\treturn NULL;\n\twatcher->base = base;\n\twatcher->type = type;\n\twatcher->callback = callback;\n\twatcher->arg = arg;\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\tTAILQ_INSERT_TAIL(&base->watchers[type], watcher, next);\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\treturn watcher;\n}\n\nstruct evwatch *\nevwatch_prepare_new(struct event_base *base, evwatch_prepare_cb callback, void *arg)\n{\n\tunion evwatch_cb cb = { .prepare = callback };\n\treturn evwatch_new(base, cb, arg, EVWATCH_PREPARE);\n}\n\nstruct evwatch *\nevwatch_check_new(struct event_base *base, evwatch_check_cb callback, void *arg)\n{\n\tunion evwatch_cb cb = { .check = callback };\n\treturn evwatch_new(base, cb, arg, EVWATCH_CHECK);\n}\n\nstruct event_base *\nevwatch_base(struct evwatch *watcher)\n{\n\treturn watcher->base;\n}\n\nvoid\nevwatch_free(struct evwatch *watcher)\n{\n\tEVBASE_ACQUIRE_LOCK(watcher->base, th_base_lock);\n\tTAILQ_REMOVE(&watcher->base->watchers[watcher->type], watcher, next);\n\tEVBASE_RELEASE_LOCK(watcher->base, th_base_lock);\n\tmm_free(watcher);\n}\n\nint\nevwatch_prepare_get_timeout(const struct evwatch_prepare_cb_info *info, struct timeval *timeout)\n{\n\tif (info->timeout) {\n\t\t*timeout = *(info->timeout);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n"
        },
        {
          "name": "wepoll.c",
          "type": "blob",
          "size": 66.7734375,
          "content": "/*\n * wepoll - epoll for Windows\n * https://github.com/piscisaureus/wepoll\n *\n * Copyright 2012-2020, Bert Belder <bertbelder@gmail.com>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *   * Redistributions of source code must retain the above copyright\n *     notice, this list of conditions and the following disclaimer.\n *\n *   * Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#define WEPOLL_EXPORT\n\n#ifndef _WIN32_WINNT\n/* Minimum required for SetFileCompletionNotificationModes() */\n#define _WIN32_WINNT 0x0600\n#endif\n#define WIN32_LEAN_AND_MEAN\n\n#include <stdint.h>\n#include \"event-internal.h\"\n\nenum EPOLL_EVENTS {\n  EPOLLIN      = (int) (1U <<  0),\n  EPOLLPRI     = (int) (1U <<  1),\n  EPOLLOUT     = (int) (1U <<  2),\n  EPOLLERR     = (int) (1U <<  3),\n  EPOLLHUP     = (int) (1U <<  4),\n  EPOLLRDNORM  = (int) (1U <<  6),\n  EPOLLRDBAND  = (int) (1U <<  7),\n  EPOLLWRNORM  = (int) (1U <<  8),\n  EPOLLWRBAND  = (int) (1U <<  9),\n  EPOLLMSG     = (int) (1U << 10), /* Never reported. */\n  EPOLLRDHUP   = (int) (1U << 13),\n  EPOLLONESHOT = (int) (1U << 31)\n};\n\n#define EPOLLIN      (1U <<  0)\n#define EPOLLPRI     (1U <<  1)\n#define EPOLLOUT     (1U <<  2)\n#define EPOLLERR     (1U <<  3)\n#define EPOLLHUP     (1U <<  4)\n#define EPOLLRDNORM  (1U <<  6)\n#define EPOLLRDBAND  (1U <<  7)\n#define EPOLLWRNORM  (1U <<  8)\n#define EPOLLWRBAND  (1U <<  9)\n#define EPOLLMSG     (1U << 10)\n#define EPOLLRDHUP   (1U << 13)\n#define EPOLLONESHOT (1U << 31)\n\n#define EPOLL_CTL_ADD 1\n#define EPOLL_CTL_MOD 2\n#define EPOLL_CTL_DEL 3\n\ntypedef void* HANDLE;\ntypedef uintptr_t SOCKET;\n\ntypedef union epoll_data {\n  void* ptr;\n  int fd;\n  uint32_t u32;\n  uint64_t u64;\n  SOCKET sock; /* Windows specific */\n  HANDLE hnd;  /* Windows specific */\n} epoll_data_t;\n\nstruct epoll_event {\n  uint32_t events;   /* Epoll events and flags */\n  epoll_data_t data; /* User data variable */\n};\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nWEPOLL_EXPORT HANDLE epoll_create(int size);\nWEPOLL_EXPORT HANDLE epoll_create1(int flags);\n\nWEPOLL_EXPORT int epoll_close(HANDLE ephnd);\n\nWEPOLL_EXPORT int epoll_ctl(HANDLE ephnd,\n                            int op,\n                            SOCKET sock,\n                            struct epoll_event* event);\n\nWEPOLL_EXPORT int epoll_wait(HANDLE ephnd,\n                             struct epoll_event* events,\n                             int maxevents,\n                             int timeout);\n\n#ifdef __cplusplus\n} /* extern \"C\" */\n#endif\n\n#include <assert.h>\n\n#include <stdlib.h>\n\n#define WEPOLL_INTERNAL static\n#define WEPOLL_INTERNAL_VAR static\n\n#ifdef __clang__\n#pragma clang diagnostic push\n#pragma clang diagnostic ignored \"-Wreserved-id-macro\"\n#endif\n\n#ifdef __clang__\n#pragma clang diagnostic pop\n#endif\n\n#ifndef __GNUC__\n#pragma warning(push, 1)\n#endif\n\n#include <ws2tcpip.h>\n#include <winsock2.h>\n#include <windows.h>\n\n#ifndef __GNUC__\n#pragma warning(pop)\n#endif\n\nWEPOLL_INTERNAL int nt_global_init(void);\n\ntypedef LONG NTSTATUS;\ntypedef NTSTATUS* PNTSTATUS;\n\n#ifndef NT_SUCCESS\n#define NT_SUCCESS(status) (((NTSTATUS)(status)) >= 0)\n#endif\n\n#ifndef STATUS_SUCCESS\n#define STATUS_SUCCESS ((NTSTATUS) 0x00000000L)\n#endif\n\n#ifndef STATUS_PENDING\n#define STATUS_PENDING ((NTSTATUS) 0x00000103L)\n#endif\n\n#ifndef STATUS_CANCELLED\n#define STATUS_CANCELLED ((NTSTATUS) 0xC0000120L)\n#endif\n\n#ifndef STATUS_NOT_FOUND\n#define STATUS_NOT_FOUND ((NTSTATUS) 0xC0000225L)\n#endif\n\ntypedef struct _IO_STATUS_BLOCK {\n  NTSTATUS Status;\n  ULONG_PTR Information;\n} IO_STATUS_BLOCK, *PIO_STATUS_BLOCK;\n\ntypedef VOID(NTAPI* PIO_APC_ROUTINE)(PVOID ApcContext,\n                                     PIO_STATUS_BLOCK IoStatusBlock,\n                                     ULONG Reserved);\n\ntypedef struct _UNICODE_STRING {\n  USHORT Length;\n  USHORT MaximumLength;\n  PWSTR Buffer;\n} UNICODE_STRING, *PUNICODE_STRING;\n\n#define RTL_CONSTANT_STRING(s) \\\n  { sizeof(s) - sizeof((s)[0]), sizeof(s), s }\n\ntypedef struct _OBJECT_ATTRIBUTES {\n  ULONG Length;\n  HANDLE RootDirectory;\n  PUNICODE_STRING ObjectName;\n  ULONG Attributes;\n  PVOID SecurityDescriptor;\n  PVOID SecurityQualityOfService;\n} OBJECT_ATTRIBUTES, *POBJECT_ATTRIBUTES;\n\n#define RTL_CONSTANT_OBJECT_ATTRIBUTES(ObjectName, Attributes) \\\n  { sizeof(OBJECT_ATTRIBUTES), NULL, ObjectName, Attributes, NULL, NULL }\n\n#ifndef FILE_OPEN\n#define FILE_OPEN 0x00000001UL\n#endif\n\n#define KEYEDEVENT_WAIT 0x00000001UL\n#define KEYEDEVENT_WAKE 0x00000002UL\n#define KEYEDEVENT_ALL_ACCESS \\\n  (STANDARD_RIGHTS_REQUIRED | KEYEDEVENT_WAIT | KEYEDEVENT_WAKE)\n\n#define NT_NTDLL_IMPORT_LIST(X)           \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtCancelIoFileEx,                     \\\n    (HANDLE FileHandle,                   \\\n     PIO_STATUS_BLOCK IoRequestToCancel,  \\\n     PIO_STATUS_BLOCK IoStatusBlock))     \\\n                                          \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtCreateFile,                         \\\n    (PHANDLE FileHandle,                  \\\n     ACCESS_MASK DesiredAccess,           \\\n     POBJECT_ATTRIBUTES ObjectAttributes, \\\n     PIO_STATUS_BLOCK IoStatusBlock,      \\\n     PLARGE_INTEGER AllocationSize,       \\\n     ULONG FileAttributes,                \\\n     ULONG ShareAccess,                   \\\n     ULONG CreateDisposition,             \\\n     ULONG CreateOptions,                 \\\n     PVOID EaBuffer,                      \\\n     ULONG EaLength))                     \\\n                                          \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtCreateKeyedEvent,                   \\\n    (PHANDLE KeyedEventHandle,            \\\n     ACCESS_MASK DesiredAccess,           \\\n     POBJECT_ATTRIBUTES ObjectAttributes, \\\n     ULONG Flags))                        \\\n                                          \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtDeviceIoControlFile,                \\\n    (HANDLE FileHandle,                   \\\n     HANDLE Event,                        \\\n     PIO_APC_ROUTINE ApcRoutine,          \\\n     PVOID ApcContext,                    \\\n     PIO_STATUS_BLOCK IoStatusBlock,      \\\n     ULONG IoControlCode,                 \\\n     PVOID InputBuffer,                   \\\n     ULONG InputBufferLength,             \\\n     PVOID OutputBuffer,                  \\\n     ULONG OutputBufferLength))           \\\n                                          \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtReleaseKeyedEvent,                  \\\n    (HANDLE KeyedEventHandle,             \\\n     PVOID KeyValue,                      \\\n     BOOLEAN Alertable,                   \\\n     PLARGE_INTEGER Timeout))             \\\n                                          \\\n  X(NTSTATUS,                             \\\n    NTAPI,                                \\\n    NtWaitForKeyedEvent,                  \\\n    (HANDLE KeyedEventHandle,             \\\n     PVOID KeyValue,                      \\\n     BOOLEAN Alertable,                   \\\n     PLARGE_INTEGER Timeout))             \\\n                                          \\\n  X(ULONG, WINAPI, RtlNtStatusToDosError, (NTSTATUS Status))\n\n#define X(return_type, attributes, name, parameters) \\\n  WEPOLL_INTERNAL_VAR return_type(attributes* name) parameters;\nNT_NTDLL_IMPORT_LIST(X)\n#undef X\n\n#define AFD_POLL_RECEIVE           0x0001\n#define AFD_POLL_RECEIVE_EXPEDITED 0x0002\n#define AFD_POLL_SEND              0x0004\n#define AFD_POLL_DISCONNECT        0x0008\n#define AFD_POLL_ABORT             0x0010\n#define AFD_POLL_LOCAL_CLOSE       0x0020\n#define AFD_POLL_ACCEPT            0x0080\n#define AFD_POLL_CONNECT_FAIL      0x0100\n\ntypedef struct _AFD_POLL_HANDLE_INFO {\n  HANDLE Handle;\n  ULONG Events;\n  NTSTATUS Status;\n} AFD_POLL_HANDLE_INFO, *PAFD_POLL_HANDLE_INFO;\n\ntypedef struct _AFD_POLL_INFO {\n  LARGE_INTEGER Timeout;\n  ULONG NumberOfHandles;\n  ULONG Exclusive;\n  AFD_POLL_HANDLE_INFO Handles[1];\n} AFD_POLL_INFO, *PAFD_POLL_INFO;\n\nWEPOLL_INTERNAL int afd_create_helper_handle(HANDLE iocp_handle,\n                                             HANDLE* afd_helper_handle_out);\n\nWEPOLL_INTERNAL int afd_poll(HANDLE afd_helper_handle,\n                             AFD_POLL_INFO* poll_info,\n                             IO_STATUS_BLOCK* io_status_block);\nWEPOLL_INTERNAL int afd_cancel_poll(HANDLE afd_helper_handle,\n                                    IO_STATUS_BLOCK* io_status_block);\n\n#define return_map_error(value) \\\n  do {                          \\\n    err_map_win_error();        \\\n    return (value);             \\\n  } while (0)\n\n#define return_set_error(value, error) \\\n  do {                                 \\\n    err_set_win_error(error);          \\\n    return (value);                    \\\n  } while (0)\n\nWEPOLL_INTERNAL void err_map_win_error(void);\nWEPOLL_INTERNAL void err_set_win_error(DWORD error);\nWEPOLL_INTERNAL int err_check_handle(HANDLE handle);\n\n#define IOCTL_AFD_POLL 0x00012024\n\nstatic UNICODE_STRING afd__helper_name =\n    RTL_CONSTANT_STRING(L\"\\\\Device\\\\Afd\\\\Wepoll\");\n\nstatic OBJECT_ATTRIBUTES afd__helper_attributes =\n    RTL_CONSTANT_OBJECT_ATTRIBUTES(&afd__helper_name, 0);\n\nint afd_create_helper_handle(HANDLE iocp_handle,\n                             HANDLE* afd_helper_handle_out) {\n  HANDLE afd_helper_handle;\n  IO_STATUS_BLOCK iosb;\n  NTSTATUS status;\n\n  /* By opening \\Device\\Afd without specifying any extended attributes, we'll\n   * get a handle that lets us talk to the AFD driver, but that doesn't have an\n   * associated endpoint (so it's not a socket). */\n  status = NtCreateFile(&afd_helper_handle,\n                        SYNCHRONIZE,\n                        &afd__helper_attributes,\n                        &iosb,\n                        NULL,\n                        0,\n                        FILE_SHARE_READ | FILE_SHARE_WRITE,\n                        FILE_OPEN,\n                        0,\n                        NULL,\n                        0);\n  if (status != STATUS_SUCCESS)\n    return_set_error(-1, RtlNtStatusToDosError(status));\n\n  if (CreateIoCompletionPort(afd_helper_handle, iocp_handle, 0, 0) == NULL)\n    goto error;\n\n  if (!SetFileCompletionNotificationModes(afd_helper_handle,\n                                          FILE_SKIP_SET_EVENT_ON_HANDLE))\n    goto error;\n\n  *afd_helper_handle_out = afd_helper_handle;\n  return 0;\n\nerror:\n  CloseHandle(afd_helper_handle);\n  return_map_error(-1);\n}\n\nint afd_poll(HANDLE afd_helper_handle,\n             AFD_POLL_INFO* poll_info,\n             IO_STATUS_BLOCK* io_status_block) {\n  NTSTATUS status;\n\n  /* Blocking operation is not supported. */\n  assert(io_status_block != NULL);\n\n  io_status_block->Status = STATUS_PENDING;\n  status = NtDeviceIoControlFile(afd_helper_handle,\n                                 NULL,\n                                 NULL,\n                                 io_status_block,\n                                 io_status_block,\n                                 IOCTL_AFD_POLL,\n                                 poll_info,\n                                 sizeof *poll_info,\n                                 poll_info,\n                                 sizeof *poll_info);\n\n  if (status == STATUS_SUCCESS)\n    return 0;\n  else if (status == STATUS_PENDING)\n    return_set_error(-1, ERROR_IO_PENDING);\n  else\n    return_set_error(-1, RtlNtStatusToDosError(status));\n}\n\nint afd_cancel_poll(HANDLE afd_helper_handle,\n                    IO_STATUS_BLOCK* io_status_block) {\n  NTSTATUS cancel_status;\n  IO_STATUS_BLOCK cancel_iosb;\n\n  /* If the poll operation has already completed or has been cancelled earlier,\n   * there's nothing left for us to do. */\n  if (io_status_block->Status != STATUS_PENDING)\n    return 0;\n\n  cancel_status =\n      NtCancelIoFileEx(afd_helper_handle, io_status_block, &cancel_iosb);\n\n  /* NtCancelIoFileEx() may return STATUS_NOT_FOUND if the operation completed\n   * just before calling NtCancelIoFileEx(). This is not an error. */\n  if (cancel_status == STATUS_SUCCESS || cancel_status == STATUS_NOT_FOUND)\n    return 0;\n  else\n    return_set_error(-1, RtlNtStatusToDosError(cancel_status));\n}\n\nWEPOLL_INTERNAL int epoll_global_init(void);\n\nWEPOLL_INTERNAL int init(void);\n\ntypedef struct port_state port_state_t;\ntypedef struct queue queue_t;\ntypedef struct sock_state sock_state_t;\ntypedef struct ts_tree_node ts_tree_node_t;\n\nWEPOLL_INTERNAL port_state_t* port_new(HANDLE* iocp_handle_out);\nWEPOLL_INTERNAL int port_close(port_state_t* port_state);\nWEPOLL_INTERNAL int port_delete(port_state_t* port_state);\n\nWEPOLL_INTERNAL int port_wait(port_state_t* port_state,\n                              struct epoll_event* events,\n                              int maxevents,\n                              int timeout);\n\nWEPOLL_INTERNAL int port_ctl(port_state_t* port_state,\n                             int op,\n                             SOCKET sock,\n                             struct epoll_event* ev);\n\nWEPOLL_INTERNAL int port_register_socket_handle(port_state_t* port_state,\n                                                sock_state_t* sock_state,\n                                                SOCKET socket);\nWEPOLL_INTERNAL void port_unregister_socket_handle(port_state_t* port_state,\n                                                   sock_state_t* sock_state);\nWEPOLL_INTERNAL sock_state_t* port_find_socket(port_state_t* port_state,\n                                               SOCKET socket);\n\nWEPOLL_INTERNAL void port_request_socket_update(port_state_t* port_state,\n                                                sock_state_t* sock_state);\nWEPOLL_INTERNAL void port_cancel_socket_update(port_state_t* port_state,\n                                               sock_state_t* sock_state);\n\nWEPOLL_INTERNAL void port_add_deleted_socket(port_state_t* port_state,\n                                             sock_state_t* sock_state);\nWEPOLL_INTERNAL void port_remove_deleted_socket(port_state_t* port_state,\n                                                sock_state_t* sock_state);\n\nWEPOLL_INTERNAL HANDLE port_get_iocp_handle(port_state_t* port_state);\nWEPOLL_INTERNAL queue_t* port_get_poll_group_queue(port_state_t* port_state);\n\nWEPOLL_INTERNAL port_state_t* port_state_from_handle_tree_node(\n    ts_tree_node_t* tree_node);\nWEPOLL_INTERNAL ts_tree_node_t* port_state_to_handle_tree_node(\n    port_state_t* port_state);\n\n/* The reflock is a special kind of lock that normally prevents a chunk of\n * memory from being freed, but does allow the chunk of memory to eventually be\n * released in a coordinated fashion.\n *\n * Under normal operation, threads increase and decrease the reference count,\n * which are wait-free operations.\n *\n * Exactly once during the reflock's lifecycle, a thread holding a reference to\n * the lock may \"destroy\" the lock; this operation blocks until all other\n * threads holding a reference to the lock have dereferenced it. After\n * \"destroy\" returns, the calling thread may assume that no other threads have\n * a reference to the lock.\n *\n * Attempting to lock or destroy a lock after reflock_unref_and_destroy() has\n * been called is invalid and results in undefined behavior. Therefore the user\n * should use another lock to guarantee that this can't happen.\n */\n\ntypedef struct reflock {\n  volatile long state; /* 32-bit Interlocked APIs operate on `long` values. */\n} reflock_t;\n\nWEPOLL_INTERNAL int reflock_global_init(void);\n\nWEPOLL_INTERNAL void reflock_init(reflock_t* reflock);\nWEPOLL_INTERNAL void reflock_ref(reflock_t* reflock);\nWEPOLL_INTERNAL void reflock_unref(reflock_t* reflock);\nWEPOLL_INTERNAL void reflock_unref_and_destroy(reflock_t* reflock);\n\n#include <stdbool.h>\n\n/* N.b.: the tree functions do not set errno or LastError when they fail. Each\n * of the API functions has at most one failure mode. It is up to the caller to\n * set an appropriate error code when necessary. */\n\ntypedef struct tree tree_t;\ntypedef struct tree_node tree_node_t;\n\ntypedef struct tree {\n  tree_node_t* root;\n} tree_t;\n\ntypedef struct tree_node {\n  tree_node_t* left;\n  tree_node_t* right;\n  tree_node_t* parent;\n  uintptr_t key;\n  bool red;\n} tree_node_t;\n\nWEPOLL_INTERNAL void tree_init(tree_t* tree);\nWEPOLL_INTERNAL void tree_node_init(tree_node_t* node);\n\nWEPOLL_INTERNAL int tree_add(tree_t* tree, tree_node_t* node, uintptr_t key);\nWEPOLL_INTERNAL void tree_del(tree_t* tree, tree_node_t* node);\n\nWEPOLL_INTERNAL tree_node_t* tree_find(const tree_t* tree, uintptr_t key);\nWEPOLL_INTERNAL tree_node_t* tree_root(const tree_t* tree);\n\ntypedef struct ts_tree {\n  tree_t tree;\n  SRWLOCK lock;\n} ts_tree_t;\n\ntypedef struct ts_tree_node {\n  tree_node_t tree_node;\n  reflock_t reflock;\n} ts_tree_node_t;\n\nWEPOLL_INTERNAL void ts_tree_init(ts_tree_t* rtl);\nWEPOLL_INTERNAL void ts_tree_node_init(ts_tree_node_t* node);\n\nWEPOLL_INTERNAL int ts_tree_add(ts_tree_t* ts_tree,\n                                ts_tree_node_t* node,\n                                uintptr_t key);\n\nWEPOLL_INTERNAL ts_tree_node_t* ts_tree_del_and_ref(ts_tree_t* ts_tree,\n                                                    uintptr_t key);\nWEPOLL_INTERNAL ts_tree_node_t* ts_tree_find_and_ref(ts_tree_t* ts_tree,\n                                                     uintptr_t key);\n\nWEPOLL_INTERNAL void ts_tree_node_unref(ts_tree_node_t* node);\nWEPOLL_INTERNAL void ts_tree_node_unref_and_destroy(ts_tree_node_t* node);\n\nstatic ts_tree_t epoll__handle_tree;\n\nint epoll_global_init(void) {\n  ts_tree_init(&epoll__handle_tree);\n  return 0;\n}\n\nstatic HANDLE epoll__create(void) {\n  port_state_t* port_state;\n  HANDLE ephnd;\n  ts_tree_node_t* tree_node;\n\n  if (init() < 0)\n    return NULL;\n\n  port_state = port_new(&ephnd);\n  if (port_state == NULL)\n    return NULL;\n\n  tree_node = port_state_to_handle_tree_node(port_state);\n  if (ts_tree_add(&epoll__handle_tree, tree_node, (uintptr_t) ephnd) < 0) {\n    /* This should never happen. */\n    port_delete(port_state);\n    return_set_error(NULL, ERROR_ALREADY_EXISTS);\n  }\n\n  return ephnd;\n}\n\nHANDLE epoll_create(int size) {\n  if (size <= 0)\n    return_set_error(NULL, ERROR_INVALID_PARAMETER);\n\n  return epoll__create();\n}\n\nHANDLE epoll_create1(int flags) {\n  if (flags != 0)\n    return_set_error(NULL, ERROR_INVALID_PARAMETER);\n\n  return epoll__create();\n}\n\nint epoll_close(HANDLE ephnd) {\n  ts_tree_node_t* tree_node;\n  port_state_t* port_state;\n\n  if (init() < 0)\n    return -1;\n\n  tree_node = ts_tree_del_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n  if (tree_node == NULL) {\n    err_set_win_error(ERROR_INVALID_PARAMETER);\n    goto err;\n  }\n\n  port_state = port_state_from_handle_tree_node(tree_node);\n  port_close(port_state);\n\n  ts_tree_node_unref_and_destroy(tree_node);\n\n  return port_delete(port_state);\n\nerr:\n  err_check_handle(ephnd);\n  return -1;\n}\n\nint epoll_ctl(HANDLE ephnd, int op, SOCKET sock, struct epoll_event* ev) {\n  ts_tree_node_t* tree_node;\n  port_state_t* port_state;\n  int r;\n\n  if (init() < 0)\n    return -1;\n\n  tree_node = ts_tree_find_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n  if (tree_node == NULL) {\n    err_set_win_error(ERROR_INVALID_PARAMETER);\n    goto err;\n  }\n\n  port_state = port_state_from_handle_tree_node(tree_node);\n  r = port_ctl(port_state, op, sock, ev);\n\n  ts_tree_node_unref(tree_node);\n\n  if (r < 0)\n    goto err;\n\n  return 0;\n\nerr:\n  /* On Linux, in the case of epoll_ctl(), EBADF takes priority over other\n   * errors. Wepoll mimics this behavior. */\n  err_check_handle(ephnd);\n  err_check_handle((HANDLE) sock);\n  return -1;\n}\n\nint epoll_wait(HANDLE ephnd,\n               struct epoll_event* events,\n               int maxevents,\n               int timeout) {\n  ts_tree_node_t* tree_node;\n  port_state_t* port_state;\n  int num_events;\n\n  if (maxevents <= 0)\n    return_set_error(-1, ERROR_INVALID_PARAMETER);\n\n  if (init() < 0)\n    return -1;\n\n  tree_node = ts_tree_find_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n  if (tree_node == NULL) {\n    err_set_win_error(ERROR_INVALID_PARAMETER);\n    goto err;\n  }\n\n  port_state = port_state_from_handle_tree_node(tree_node);\n  num_events = port_wait(port_state, events, maxevents, timeout);\n\n  ts_tree_node_unref(tree_node);\n\n  if (num_events < 0)\n    goto err;\n\n  return num_events;\n\nerr:\n  err_check_handle(ephnd);\n  return -1;\n}\n\n#include <errno.h>\n\n#define ERR__ERRNO_MAPPINGS(X)               \\\n  X(ERROR_ACCESS_DENIED, EACCES)             \\\n  X(ERROR_ALREADY_EXISTS, EEXIST)            \\\n  X(ERROR_BAD_COMMAND, EACCES)               \\\n  X(ERROR_BAD_EXE_FORMAT, ENOEXEC)           \\\n  X(ERROR_BAD_LENGTH, EACCES)                \\\n  X(ERROR_BAD_NETPATH, ENOENT)               \\\n  X(ERROR_BAD_NET_NAME, ENOENT)              \\\n  X(ERROR_BAD_NET_RESP, ENETDOWN)            \\\n  X(ERROR_BAD_PATHNAME, ENOENT)              \\\n  X(ERROR_BROKEN_PIPE, EPIPE)                \\\n  X(ERROR_CANNOT_MAKE, EACCES)               \\\n  X(ERROR_COMMITMENT_LIMIT, ENOMEM)          \\\n  X(ERROR_CONNECTION_ABORTED, ECONNABORTED)  \\\n  X(ERROR_CONNECTION_ACTIVE, EISCONN)        \\\n  X(ERROR_CONNECTION_REFUSED, ECONNREFUSED)  \\\n  X(ERROR_CRC, EACCES)                       \\\n  X(ERROR_DIR_NOT_EMPTY, ENOTEMPTY)          \\\n  X(ERROR_DISK_FULL, ENOSPC)                 \\\n  X(ERROR_DUP_NAME, EADDRINUSE)              \\\n  X(ERROR_FILENAME_EXCED_RANGE, ENOENT)      \\\n  X(ERROR_FILE_NOT_FOUND, ENOENT)            \\\n  X(ERROR_GEN_FAILURE, EACCES)               \\\n  X(ERROR_GRACEFUL_DISCONNECT, EPIPE)        \\\n  X(ERROR_HOST_DOWN, EHOSTUNREACH)           \\\n  X(ERROR_HOST_UNREACHABLE, EHOSTUNREACH)    \\\n  X(ERROR_INSUFFICIENT_BUFFER, EFAULT)       \\\n  X(ERROR_INVALID_ADDRESS, EADDRNOTAVAIL)    \\\n  X(ERROR_INVALID_FUNCTION, EINVAL)          \\\n  X(ERROR_INVALID_HANDLE, EBADF)             \\\n  X(ERROR_INVALID_NETNAME, EADDRNOTAVAIL)    \\\n  X(ERROR_INVALID_PARAMETER, EINVAL)         \\\n  X(ERROR_INVALID_USER_BUFFER, EMSGSIZE)     \\\n  X(ERROR_IO_PENDING, EINPROGRESS)           \\\n  X(ERROR_LOCK_VIOLATION, EACCES)            \\\n  X(ERROR_MORE_DATA, EMSGSIZE)               \\\n  X(ERROR_NETNAME_DELETED, ECONNABORTED)     \\\n  X(ERROR_NETWORK_ACCESS_DENIED, EACCES)     \\\n  X(ERROR_NETWORK_BUSY, ENETDOWN)            \\\n  X(ERROR_NETWORK_UNREACHABLE, ENETUNREACH)  \\\n  X(ERROR_NOACCESS, EFAULT)                  \\\n  X(ERROR_NONPAGED_SYSTEM_RESOURCES, ENOMEM) \\\n  X(ERROR_NOT_ENOUGH_MEMORY, ENOMEM)         \\\n  X(ERROR_NOT_ENOUGH_QUOTA, ENOMEM)          \\\n  X(ERROR_NOT_FOUND, ENOENT)                 \\\n  X(ERROR_NOT_LOCKED, EACCES)                \\\n  X(ERROR_NOT_READY, EACCES)                 \\\n  X(ERROR_NOT_SAME_DEVICE, EXDEV)            \\\n  X(ERROR_NOT_SUPPORTED, ENOTSUP)            \\\n  X(ERROR_NO_MORE_FILES, ENOENT)             \\\n  X(ERROR_NO_SYSTEM_RESOURCES, ENOMEM)       \\\n  X(ERROR_OPERATION_ABORTED, EINTR)          \\\n  X(ERROR_OUT_OF_PAPER, EACCES)              \\\n  X(ERROR_PAGED_SYSTEM_RESOURCES, ENOMEM)    \\\n  X(ERROR_PAGEFILE_QUOTA, ENOMEM)            \\\n  X(ERROR_PATH_NOT_FOUND, ENOENT)            \\\n  X(ERROR_PIPE_NOT_CONNECTED, EPIPE)         \\\n  X(ERROR_PORT_UNREACHABLE, ECONNRESET)      \\\n  X(ERROR_PROTOCOL_UNREACHABLE, ENETUNREACH) \\\n  X(ERROR_REM_NOT_LIST, ECONNREFUSED)        \\\n  X(ERROR_REQUEST_ABORTED, EINTR)            \\\n  X(ERROR_REQ_NOT_ACCEP, EWOULDBLOCK)        \\\n  X(ERROR_SECTOR_NOT_FOUND, EACCES)          \\\n  X(ERROR_SEM_TIMEOUT, ETIMEDOUT)            \\\n  X(ERROR_SHARING_VIOLATION, EACCES)         \\\n  X(ERROR_TOO_MANY_NAMES, ENOMEM)            \\\n  X(ERROR_TOO_MANY_OPEN_FILES, EMFILE)       \\\n  X(ERROR_UNEXP_NET_ERR, ECONNABORTED)       \\\n  X(ERROR_WAIT_NO_CHILDREN, ECHILD)          \\\n  X(ERROR_WORKING_SET_QUOTA, ENOMEM)         \\\n  X(ERROR_WRITE_PROTECT, EACCES)             \\\n  X(ERROR_WRONG_DISK, EACCES)                \\\n  X(WSAEACCES, EACCES)                       \\\n  X(WSAEADDRINUSE, EADDRINUSE)               \\\n  X(WSAEADDRNOTAVAIL, EADDRNOTAVAIL)         \\\n  X(WSAEAFNOSUPPORT, EAFNOSUPPORT)           \\\n  X(WSAECONNABORTED, ECONNABORTED)           \\\n  X(WSAECONNREFUSED, ECONNREFUSED)           \\\n  X(WSAECONNRESET, ECONNRESET)               \\\n  X(WSAEDISCON, EPIPE)                       \\\n  X(WSAEFAULT, EFAULT)                       \\\n  X(WSAEHOSTDOWN, EHOSTUNREACH)              \\\n  X(WSAEHOSTUNREACH, EHOSTUNREACH)           \\\n  X(WSAEINPROGRESS, EBUSY)                   \\\n  X(WSAEINTR, EINTR)                         \\\n  X(WSAEINVAL, EINVAL)                       \\\n  X(WSAEISCONN, EISCONN)                     \\\n  X(WSAEMSGSIZE, EMSGSIZE)                   \\\n  X(WSAENETDOWN, ENETDOWN)                   \\\n  X(WSAENETRESET, EHOSTUNREACH)              \\\n  X(WSAENETUNREACH, ENETUNREACH)             \\\n  X(WSAENOBUFS, ENOMEM)                      \\\n  X(WSAENOTCONN, ENOTCONN)                   \\\n  X(WSAENOTSOCK, ENOTSOCK)                   \\\n  X(WSAEOPNOTSUPP, EOPNOTSUPP)               \\\n  X(WSAEPROCLIM, ENOMEM)                     \\\n  X(WSAESHUTDOWN, EPIPE)                     \\\n  X(WSAETIMEDOUT, ETIMEDOUT)                 \\\n  X(WSAEWOULDBLOCK, EWOULDBLOCK)             \\\n  X(WSANOTINITIALISED, ENETDOWN)             \\\n  X(WSASYSNOTREADY, ENETDOWN)                \\\n  X(WSAVERNOTSUPPORTED, ENOSYS)\n\nstatic errno_t err__map_win_error_to_errno(DWORD error) {\n  switch (error) {\n#define X(error_sym, errno_sym) \\\n  case error_sym:               \\\n    return errno_sym;\n    ERR__ERRNO_MAPPINGS(X)\n#undef X\n  }\n  return EINVAL;\n}\n\nvoid err_map_win_error(void) {\n  errno = err__map_win_error_to_errno(GetLastError());\n}\n\nvoid err_set_win_error(DWORD error) {\n  SetLastError(error);\n  errno = err__map_win_error_to_errno(error);\n}\n\nint err_check_handle(HANDLE handle) {\n  DWORD flags;\n\n  /* GetHandleInformation() succeeds when passed INVALID_HANDLE_VALUE, so check\n   * for this condition explicitly. */\n  if (handle == INVALID_HANDLE_VALUE)\n    return_set_error(-1, ERROR_INVALID_HANDLE);\n\n  if (!GetHandleInformation(handle, &flags))\n    return_map_error(-1);\n\n  return 0;\n}\n\n#include <stddef.h>\n\n#define array_count(a) (sizeof(a) / (sizeof((a)[0])))\n\n#define container_of(ptr, type, member) \\\n  ((type*) ((uintptr_t) (ptr) - offsetof(type, member)))\n\n#define unused_var(v) ((void) (v))\n\n/* Polyfill `inline` for older versions of msvc (up to Visual Studio 2013) */\n#if defined(_MSC_VER) && _MSC_VER < 1900\n#define inline __inline\n#endif\n\nWEPOLL_INTERNAL int ws_global_init(void);\nWEPOLL_INTERNAL SOCKET ws_get_base_socket(SOCKET socket);\n\nstatic bool init__done = false;\nstatic INIT_ONCE init__once = INIT_ONCE_STATIC_INIT;\n\nstatic BOOL CALLBACK init__once_callback(INIT_ONCE* once,\n                                         void* parameter,\n                                         void** context) {\n  unused_var(once);\n  unused_var(parameter);\n  unused_var(context);\n\n  /* N.b. that initialization order matters here. */\n  if (ws_global_init() < 0 || nt_global_init() < 0 ||\n      reflock_global_init() < 0 || epoll_global_init() < 0)\n    return FALSE;\n\n  init__done = true;\n  return TRUE;\n}\n\nint init(void) {\n  if (!init__done &&\n      !InitOnceExecuteOnce(&init__once, init__once_callback, NULL, NULL))\n    /* `InitOnceExecuteOnce()` itself is infallible, and it doesn't set any\n     * error code when the once-callback returns FALSE. We return -1 here to\n     * indicate that global initialization failed; the failing init function is\n     * resposible for setting `errno` and calling `SetLastError()`. */\n    return -1;\n\n  return 0;\n}\n\n/* Set up a workaround for the following problem:\n *   FARPROC addr = GetProcAddress(...);\n *   MY_FUNC func = (MY_FUNC) addr;          <-- GCC 8 warning/error.\n *   MY_FUNC func = (MY_FUNC) (void*) addr;  <-- MSVC  warning/error.\n * To compile cleanly with either compiler, do casts with this \"bridge\" type:\n *   MY_FUNC func = (MY_FUNC) (nt__fn_ptr_cast_t) addr; */\n#ifdef __GNUC__\ntypedef void* nt__fn_ptr_cast_t;\n#else\ntypedef FARPROC nt__fn_ptr_cast_t;\n#endif\n\n#define X(return_type, attributes, name, parameters) \\\n  WEPOLL_INTERNAL return_type(attributes* name) parameters = NULL;\nNT_NTDLL_IMPORT_LIST(X)\n#undef X\n\nint nt_global_init(void) {\n  HMODULE ntdll;\n  FARPROC fn_ptr;\n\n  ntdll = GetModuleHandleW(L\"ntdll.dll\");\n  if (ntdll == NULL)\n    return -1;\n\n#define X(return_type, attributes, name, parameters) \\\n  fn_ptr = GetProcAddress(ntdll, #name);             \\\n  if (fn_ptr == NULL)                                \\\n    return -1;                                       \\\n  name = (return_type(attributes*) parameters)(nt__fn_ptr_cast_t) fn_ptr;\n  NT_NTDLL_IMPORT_LIST(X)\n#undef X\n\n  return 0;\n}\n\n#include <string.h>\n\ntypedef struct poll_group poll_group_t;\n\ntypedef struct queue_node queue_node_t;\n\nWEPOLL_INTERNAL poll_group_t* poll_group_acquire(port_state_t* port);\nWEPOLL_INTERNAL void poll_group_release(poll_group_t* poll_group);\n\nWEPOLL_INTERNAL void poll_group_delete(poll_group_t* poll_group);\n\nWEPOLL_INTERNAL poll_group_t* poll_group_from_queue_node(\n    queue_node_t* queue_node);\nWEPOLL_INTERNAL HANDLE\n    poll_group_get_afd_helper_handle(poll_group_t* poll_group);\n\ntypedef struct queue_node {\n  queue_node_t* prev;\n  queue_node_t* next;\n} queue_node_t;\n\ntypedef struct queue {\n  queue_node_t head;\n} queue_t;\n\nWEPOLL_INTERNAL void queue_init(queue_t* queue);\nWEPOLL_INTERNAL void queue_node_init(queue_node_t* node);\n\nWEPOLL_INTERNAL queue_node_t* queue_first(const queue_t* queue);\nWEPOLL_INTERNAL queue_node_t* queue_last(const queue_t* queue);\n\nWEPOLL_INTERNAL void queue_prepend(queue_t* queue, queue_node_t* node);\nWEPOLL_INTERNAL void queue_append(queue_t* queue, queue_node_t* node);\nWEPOLL_INTERNAL void queue_move_first(queue_t* queue, queue_node_t* node);\nWEPOLL_INTERNAL void queue_move_last(queue_t* queue, queue_node_t* node);\nWEPOLL_INTERNAL void queue_remove(queue_node_t* node);\n\nWEPOLL_INTERNAL bool queue_empty(const queue_t* queue);\nWEPOLL_INTERNAL bool queue_enqueued(const queue_node_t* node);\n\nstatic const size_t POLL_GROUP__MAX_GROUP_SIZE = 32;\n\ntypedef struct poll_group {\n  port_state_t* port_state;\n  queue_node_t queue_node;\n  HANDLE afd_helper_handle;\n  size_t group_size;\n} poll_group_t;\n\nstatic poll_group_t* poll_group__new(port_state_t* port_state) {\n  HANDLE iocp_handle = port_get_iocp_handle(port_state);\n  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n\n  poll_group_t* poll_group = mm_malloc(sizeof *poll_group);\n  if (poll_group == NULL)\n    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n\n  memset(poll_group, 0, sizeof *poll_group);\n\n  queue_node_init(&poll_group->queue_node);\n  poll_group->port_state = port_state;\n\n  if (afd_create_helper_handle(iocp_handle, &poll_group->afd_helper_handle) <\n      0) {\n    mm_free(poll_group);\n    return NULL;\n  }\n\n  queue_append(poll_group_queue, &poll_group->queue_node);\n\n  return poll_group;\n}\n\nvoid poll_group_delete(poll_group_t* poll_group) {\n  assert(poll_group->group_size == 0);\n  CloseHandle(poll_group->afd_helper_handle);\n  queue_remove(&poll_group->queue_node);\n  mm_free(poll_group);\n}\n\npoll_group_t* poll_group_from_queue_node(queue_node_t* queue_node) {\n  return container_of(queue_node, poll_group_t, queue_node);\n}\n\nHANDLE poll_group_get_afd_helper_handle(poll_group_t* poll_group) {\n  return poll_group->afd_helper_handle;\n}\n\npoll_group_t* poll_group_acquire(port_state_t* port_state) {\n  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n  poll_group_t* poll_group =\n      !queue_empty(poll_group_queue)\n          ? container_of(\n                queue_last(poll_group_queue), poll_group_t, queue_node)\n          : NULL;\n\n  if (poll_group == NULL ||\n      poll_group->group_size >= POLL_GROUP__MAX_GROUP_SIZE)\n    poll_group = poll_group__new(port_state);\n  if (poll_group == NULL)\n    return NULL;\n\n  if (++poll_group->group_size == POLL_GROUP__MAX_GROUP_SIZE)\n    queue_move_first(poll_group_queue, &poll_group->queue_node);\n\n  return poll_group;\n}\n\nvoid poll_group_release(poll_group_t* poll_group) {\n  port_state_t* port_state = poll_group->port_state;\n  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n\n  poll_group->group_size--;\n  assert(poll_group->group_size < POLL_GROUP__MAX_GROUP_SIZE);\n\n  queue_move_last(poll_group_queue, &poll_group->queue_node);\n\n  /* Poll groups are currently only freed when the epoll port is closed. */\n}\n\nWEPOLL_INTERNAL sock_state_t* sock_new(port_state_t* port_state,\n                                       SOCKET socket);\nWEPOLL_INTERNAL void sock_delete(port_state_t* port_state,\n                                 sock_state_t* sock_state);\nWEPOLL_INTERNAL void sock_force_delete(port_state_t* port_state,\n                                       sock_state_t* sock_state);\n\nWEPOLL_INTERNAL int sock_set_event(port_state_t* port_state,\n                                   sock_state_t* sock_state,\n                                   const struct epoll_event* ev);\n\nWEPOLL_INTERNAL int sock_update(port_state_t* port_state,\n                                sock_state_t* sock_state);\nWEPOLL_INTERNAL int sock_feed_event(port_state_t* port_state,\n                                    IO_STATUS_BLOCK* io_status_block,\n                                    struct epoll_event* ev);\n\nWEPOLL_INTERNAL sock_state_t* sock_state_from_queue_node(\n    queue_node_t* queue_node);\nWEPOLL_INTERNAL queue_node_t* sock_state_to_queue_node(\n    sock_state_t* sock_state);\nWEPOLL_INTERNAL sock_state_t* sock_state_from_tree_node(\n    tree_node_t* tree_node);\nWEPOLL_INTERNAL tree_node_t* sock_state_to_tree_node(sock_state_t* sock_state);\n\n#define PORT__MAX_ON_STACK_COMPLETIONS 256\n\ntypedef struct port_state {\n  HANDLE iocp_handle;\n  tree_t sock_tree;\n  queue_t sock_update_queue;\n  queue_t sock_deleted_queue;\n  queue_t poll_group_queue;\n  ts_tree_node_t handle_tree_node;\n  CRITICAL_SECTION lock;\n  size_t active_poll_count;\n} port_state_t;\n\nstatic port_state_t* port__alloc(void) {\n  port_state_t* port_state = mm_malloc(sizeof *port_state);\n  if (port_state == NULL)\n    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n\n  return port_state;\n}\n\nstatic void port__free(port_state_t* port) {\n  assert(port != NULL);\n  mm_free(port);\n}\n\nstatic HANDLE port__create_iocp(void) {\n  HANDLE iocp_handle =\n      CreateIoCompletionPort(INVALID_HANDLE_VALUE, NULL, 0, 0);\n  if (iocp_handle == NULL)\n    return_map_error(NULL);\n\n  return iocp_handle;\n}\n\nport_state_t* port_new(HANDLE* iocp_handle_out) {\n  port_state_t* port_state;\n  HANDLE iocp_handle;\n\n  port_state = port__alloc();\n  if (port_state == NULL)\n    goto err1;\n\n  iocp_handle = port__create_iocp();\n  if (iocp_handle == NULL)\n    goto err2;\n\n  memset(port_state, 0, sizeof *port_state);\n\n  port_state->iocp_handle = iocp_handle;\n  tree_init(&port_state->sock_tree);\n  queue_init(&port_state->sock_update_queue);\n  queue_init(&port_state->sock_deleted_queue);\n  queue_init(&port_state->poll_group_queue);\n  ts_tree_node_init(&port_state->handle_tree_node);\n  InitializeCriticalSection(&port_state->lock);\n\n  *iocp_handle_out = iocp_handle;\n  return port_state;\n\nerr2:\n  port__free(port_state);\nerr1:\n  return NULL;\n}\n\nstatic int port__close_iocp(port_state_t* port_state) {\n  HANDLE iocp_handle = port_state->iocp_handle;\n  port_state->iocp_handle = NULL;\n\n  if (!CloseHandle(iocp_handle))\n    return_map_error(-1);\n\n  return 0;\n}\n\nint port_close(port_state_t* port_state) {\n  int result;\n\n  EnterCriticalSection(&port_state->lock);\n  result = port__close_iocp(port_state);\n  LeaveCriticalSection(&port_state->lock);\n\n  return result;\n}\n\nint port_delete(port_state_t* port_state) {\n  tree_node_t* tree_node;\n  queue_node_t* queue_node;\n\n  /* At this point the IOCP port should have been closed. */\n  assert(port_state->iocp_handle == NULL);\n\n  while ((tree_node = tree_root(&port_state->sock_tree)) != NULL) {\n    sock_state_t* sock_state = sock_state_from_tree_node(tree_node);\n    sock_force_delete(port_state, sock_state);\n  }\n\n  while ((queue_node = queue_first(&port_state->sock_deleted_queue)) != NULL) {\n    sock_state_t* sock_state = sock_state_from_queue_node(queue_node);\n    sock_force_delete(port_state, sock_state);\n  }\n\n  while ((queue_node = queue_first(&port_state->poll_group_queue)) != NULL) {\n    poll_group_t* poll_group = poll_group_from_queue_node(queue_node);\n    poll_group_delete(poll_group);\n  }\n\n  assert(queue_empty(&port_state->sock_update_queue));\n\n  DeleteCriticalSection(&port_state->lock);\n\n  port__free(port_state);\n\n  return 0;\n}\n\nstatic int port__update_events(port_state_t* port_state) {\n  queue_t* sock_update_queue = &port_state->sock_update_queue;\n\n  /* Walk the queue, submitting new poll requests for every socket that needs\n   * it. */\n  while (!queue_empty(sock_update_queue)) {\n    queue_node_t* queue_node = queue_first(sock_update_queue);\n    sock_state_t* sock_state = sock_state_from_queue_node(queue_node);\n\n    if (sock_update(port_state, sock_state) < 0)\n      return -1;\n\n    /* sock_update() removes the socket from the update queue. */\n  }\n\n  return 0;\n}\n\nstatic void port__update_events_if_polling(port_state_t* port_state) {\n  if (port_state->active_poll_count > 0)\n    port__update_events(port_state);\n}\n\nstatic int port__feed_events(port_state_t* port_state,\n                             struct epoll_event* epoll_events,\n                             OVERLAPPED_ENTRY* iocp_events,\n                             DWORD iocp_event_count) {\n  int epoll_event_count = 0;\n  DWORD i;\n\n  for (i = 0; i < iocp_event_count; i++) {\n    IO_STATUS_BLOCK* io_status_block =\n        (IO_STATUS_BLOCK*) iocp_events[i].lpOverlapped;\n    struct epoll_event* ev = &epoll_events[epoll_event_count];\n\n    epoll_event_count += sock_feed_event(port_state, io_status_block, ev);\n  }\n\n  return epoll_event_count;\n}\n\nstatic int port__poll(port_state_t* port_state,\n                      struct epoll_event* epoll_events,\n                      OVERLAPPED_ENTRY* iocp_events,\n                      DWORD maxevents,\n                      DWORD timeout) {\n  DWORD completion_count;\n\n  if (port__update_events(port_state) < 0)\n    return -1;\n\n  port_state->active_poll_count++;\n\n  LeaveCriticalSection(&port_state->lock);\n\n  BOOL r = GetQueuedCompletionStatusEx(port_state->iocp_handle,\n                                       iocp_events,\n                                       maxevents,\n                                       &completion_count,\n                                       timeout,\n                                       FALSE);\n\n  EnterCriticalSection(&port_state->lock);\n\n  port_state->active_poll_count--;\n\n  if (!r)\n    return_map_error(-1);\n\n  return port__feed_events(\n      port_state, epoll_events, iocp_events, completion_count);\n}\n\nint port_wait(port_state_t* port_state,\n              struct epoll_event* events,\n              int maxevents,\n              int timeout) {\n  OVERLAPPED_ENTRY stack_iocp_events[PORT__MAX_ON_STACK_COMPLETIONS];\n  OVERLAPPED_ENTRY* iocp_events;\n  uint64_t due = 0;\n  DWORD gqcs_timeout;\n  int result;\n\n  /* Check whether `maxevents` is in range. */\n  if (maxevents <= 0)\n    return_set_error(-1, ERROR_INVALID_PARAMETER);\n\n  /* Decide whether the IOCP completion list can live on the stack, or allocate\n   * memory for it on the heap. */\n  if ((size_t) maxevents <= array_count(stack_iocp_events)) {\n    iocp_events = stack_iocp_events;\n  } else if ((iocp_events =\n                  mm_malloc((size_t) maxevents * sizeof *iocp_events)) == NULL) {\n    iocp_events = stack_iocp_events;\n    maxevents = array_count(stack_iocp_events);\n  }\n\n  /* Compute the timeout for GetQueuedCompletionStatus, and the wait end\n   * time, if the user specified a timeout other than zero or infinite. */\n  if (timeout > 0) {\n    due = GetTickCount64() + (uint64_t) timeout;\n    gqcs_timeout = (DWORD) timeout;\n  } else if (timeout == 0) {\n    gqcs_timeout = 0;\n  } else {\n    gqcs_timeout = INFINITE;\n  }\n\n  EnterCriticalSection(&port_state->lock);\n\n  /* Dequeue completion packets until either at least one interesting event\n   * has been discovered, or the timeout is reached. */\n  for (;;) {\n    uint64_t now;\n\n    result = port__poll(\n        port_state, events, iocp_events, (DWORD) maxevents, gqcs_timeout);\n    if (result < 0 || result > 0)\n      break; /* Result, error, or time-out. */\n\n    if (timeout < 0)\n      continue; /* When timeout is negative, never time out. */\n\n    /* Update time. */\n    now = GetTickCount64();\n\n    /* Do not allow the due time to be in the past. */\n    if (now >= due) {\n      SetLastError(WAIT_TIMEOUT);\n      break;\n    }\n\n    /* Recompute time-out argument for GetQueuedCompletionStatus. */\n    gqcs_timeout = (DWORD)(due - now);\n  }\n\n  port__update_events_if_polling(port_state);\n\n  LeaveCriticalSection(&port_state->lock);\n\n  if (iocp_events != stack_iocp_events)\n    mm_free(iocp_events);\n\n  if (result >= 0)\n    return result;\n  else if (GetLastError() == WAIT_TIMEOUT)\n    return 0;\n  else\n    return -1;\n}\n\nstatic int port__ctl_add(port_state_t* port_state,\n                         SOCKET sock,\n                         struct epoll_event* ev) {\n  sock_state_t* sock_state = sock_new(port_state, sock);\n  if (sock_state == NULL)\n    return -1;\n\n  if (sock_set_event(port_state, sock_state, ev) < 0) {\n    sock_delete(port_state, sock_state);\n    return -1;\n  }\n\n  port__update_events_if_polling(port_state);\n\n  return 0;\n}\n\nstatic int port__ctl_mod(port_state_t* port_state,\n                         SOCKET sock,\n                         struct epoll_event* ev) {\n  sock_state_t* sock_state = port_find_socket(port_state, sock);\n  if (sock_state == NULL)\n    return -1;\n\n  if (sock_set_event(port_state, sock_state, ev) < 0)\n    return -1;\n\n  port__update_events_if_polling(port_state);\n\n  return 0;\n}\n\nstatic int port__ctl_del(port_state_t* port_state, SOCKET sock) {\n  sock_state_t* sock_state = port_find_socket(port_state, sock);\n  if (sock_state == NULL)\n    return -1;\n\n  sock_delete(port_state, sock_state);\n\n  return 0;\n}\n\nstatic int port__ctl_op(port_state_t* port_state,\n                        int op,\n                        SOCKET sock,\n                        struct epoll_event* ev) {\n  switch (op) {\n    case EPOLL_CTL_ADD:\n      return port__ctl_add(port_state, sock, ev);\n    case EPOLL_CTL_MOD:\n      return port__ctl_mod(port_state, sock, ev);\n    case EPOLL_CTL_DEL:\n      return port__ctl_del(port_state, sock);\n    default:\n      return_set_error(-1, ERROR_INVALID_PARAMETER);\n  }\n}\n\nint port_ctl(port_state_t* port_state,\n             int op,\n             SOCKET sock,\n             struct epoll_event* ev) {\n  int result;\n\n  EnterCriticalSection(&port_state->lock);\n  result = port__ctl_op(port_state, op, sock, ev);\n  LeaveCriticalSection(&port_state->lock);\n\n  return result;\n}\n\nint port_register_socket_handle(port_state_t* port_state,\n                                sock_state_t* sock_state,\n                                SOCKET socket) {\n  if (tree_add(&port_state->sock_tree,\n               sock_state_to_tree_node(sock_state),\n               socket) < 0)\n    return_set_error(-1, ERROR_ALREADY_EXISTS);\n  return 0;\n}\n\nvoid port_unregister_socket_handle(port_state_t* port_state,\n                                   sock_state_t* sock_state) {\n  tree_del(&port_state->sock_tree, sock_state_to_tree_node(sock_state));\n}\n\nsock_state_t* port_find_socket(port_state_t* port_state, SOCKET socket) {\n  tree_node_t* tree_node = tree_find(&port_state->sock_tree, socket);\n  if (tree_node == NULL)\n    return_set_error(NULL, ERROR_NOT_FOUND);\n  return sock_state_from_tree_node(tree_node);\n}\n\nvoid port_request_socket_update(port_state_t* port_state,\n                                sock_state_t* sock_state) {\n  if (queue_enqueued(sock_state_to_queue_node(sock_state)))\n    return;\n  queue_append(&port_state->sock_update_queue,\n               sock_state_to_queue_node(sock_state));\n}\n\nvoid port_cancel_socket_update(port_state_t* port_state,\n                               sock_state_t* sock_state) {\n  unused_var(port_state);\n  if (!queue_enqueued(sock_state_to_queue_node(sock_state)))\n    return;\n  queue_remove(sock_state_to_queue_node(sock_state));\n}\n\nvoid port_add_deleted_socket(port_state_t* port_state,\n                             sock_state_t* sock_state) {\n  if (queue_enqueued(sock_state_to_queue_node(sock_state)))\n    return;\n  queue_append(&port_state->sock_deleted_queue,\n               sock_state_to_queue_node(sock_state));\n}\n\nvoid port_remove_deleted_socket(port_state_t* port_state,\n                                sock_state_t* sock_state) {\n  unused_var(port_state);\n  if (!queue_enqueued(sock_state_to_queue_node(sock_state)))\n    return;\n  queue_remove(sock_state_to_queue_node(sock_state));\n}\n\nHANDLE port_get_iocp_handle(port_state_t* port_state) {\n  assert(port_state->iocp_handle != NULL);\n  return port_state->iocp_handle;\n}\n\nqueue_t* port_get_poll_group_queue(port_state_t* port_state) {\n  return &port_state->poll_group_queue;\n}\n\nport_state_t* port_state_from_handle_tree_node(ts_tree_node_t* tree_node) {\n  return container_of(tree_node, port_state_t, handle_tree_node);\n}\n\nts_tree_node_t* port_state_to_handle_tree_node(port_state_t* port_state) {\n  return &port_state->handle_tree_node;\n}\n\nvoid queue_init(queue_t* queue) {\n  queue_node_init(&queue->head);\n}\n\nvoid queue_node_init(queue_node_t* node) {\n  node->prev = node;\n  node->next = node;\n}\n\nstatic inline void queue__detach_node(queue_node_t* node) {\n  node->prev->next = node->next;\n  node->next->prev = node->prev;\n}\n\nqueue_node_t* queue_first(const queue_t* queue) {\n  return !queue_empty(queue) ? queue->head.next : NULL;\n}\n\nqueue_node_t* queue_last(const queue_t* queue) {\n  return !queue_empty(queue) ? queue->head.prev : NULL;\n}\n\nvoid queue_prepend(queue_t* queue, queue_node_t* node) {\n  node->next = queue->head.next;\n  node->prev = &queue->head;\n  node->next->prev = node;\n  queue->head.next = node;\n}\n\nvoid queue_append(queue_t* queue, queue_node_t* node) {\n  node->next = &queue->head;\n  node->prev = queue->head.prev;\n  node->prev->next = node;\n  queue->head.prev = node;\n}\n\nvoid queue_move_first(queue_t* queue, queue_node_t* node) {\n  queue__detach_node(node);\n  queue_prepend(queue, node);\n}\n\nvoid queue_move_last(queue_t* queue, queue_node_t* node) {\n  queue__detach_node(node);\n  queue_append(queue, node);\n}\n\nvoid queue_remove(queue_node_t* node) {\n  queue__detach_node(node);\n  queue_node_init(node);\n}\n\nbool queue_empty(const queue_t* queue) {\n  return !queue_enqueued(&queue->head);\n}\n\nbool queue_enqueued(const queue_node_t* node) {\n  return node->prev != node;\n}\n\nstatic const long REFLOCK__REF          = (long) 0x00000001;\nstatic const long REFLOCK__REF_MASK     = (long) 0x0fffffff;\nstatic const long REFLOCK__DESTROY      = (long) 0x10000000;\nstatic const long REFLOCK__DESTROY_MASK = (long) 0xf0000000;\nstatic const long REFLOCK__POISON       = (long) 0x300dead0;\n\nstatic HANDLE reflock__keyed_event = NULL;\n\nint reflock_global_init(void) {\n  NTSTATUS status = NtCreateKeyedEvent(\n      &reflock__keyed_event, KEYEDEVENT_ALL_ACCESS, NULL, 0);\n  if (status != STATUS_SUCCESS)\n    return_set_error(-1, RtlNtStatusToDosError(status));\n  return 0;\n}\n\nvoid reflock_init(reflock_t* reflock) {\n  reflock->state = 0;\n}\n\nstatic void reflock__signal_event(void* address) {\n  NTSTATUS status =\n      NtReleaseKeyedEvent(reflock__keyed_event, address, FALSE, NULL);\n  if (status != STATUS_SUCCESS)\n    abort();\n}\n\nstatic void reflock__await_event(void* address) {\n  NTSTATUS status =\n      NtWaitForKeyedEvent(reflock__keyed_event, address, FALSE, NULL);\n  if (status != STATUS_SUCCESS)\n    abort();\n}\n\nvoid reflock_ref(reflock_t* reflock) {\n  long state = InterlockedAdd(&reflock->state, REFLOCK__REF);\n\n  /* Verify that the counter didn't overflow and the lock isn't destroyed. */\n  assert((state & REFLOCK__DESTROY_MASK) == 0);\n  unused_var(state);\n}\n\nvoid reflock_unref(reflock_t* reflock) {\n  long state = InterlockedAdd(&reflock->state, -REFLOCK__REF);\n\n  /* Verify that the lock was referenced and not already destroyed. */\n  assert((state & REFLOCK__DESTROY_MASK & ~REFLOCK__DESTROY) == 0);\n\n  if (state == REFLOCK__DESTROY)\n    reflock__signal_event(reflock);\n}\n\nvoid reflock_unref_and_destroy(reflock_t* reflock) {\n  long state =\n      InterlockedAdd(&reflock->state, REFLOCK__DESTROY - REFLOCK__REF);\n  long ref_count = state & REFLOCK__REF_MASK;\n\n  /* Verify that the lock was referenced and not already destroyed. */\n  assert((state & REFLOCK__DESTROY_MASK) == REFLOCK__DESTROY);\n\n  if (ref_count != 0)\n    reflock__await_event(reflock);\n\n  state = InterlockedExchange(&reflock->state, REFLOCK__POISON);\n  assert(state == REFLOCK__DESTROY);\n}\n\nstatic const uint32_t SOCK__KNOWN_EPOLL_EVENTS =\n    EPOLLIN | EPOLLPRI | EPOLLOUT | EPOLLERR | EPOLLHUP | EPOLLRDNORM |\n    EPOLLRDBAND | EPOLLWRNORM | EPOLLWRBAND | EPOLLMSG | EPOLLRDHUP;\n\ntypedef enum sock__poll_status {\n  SOCK__POLL_IDLE = 0,\n  SOCK__POLL_PENDING,\n  SOCK__POLL_CANCELLED\n} sock__poll_status_t;\n\ntypedef struct sock_state {\n  IO_STATUS_BLOCK io_status_block;\n  AFD_POLL_INFO poll_info;\n  queue_node_t queue_node;\n  tree_node_t tree_node;\n  poll_group_t* poll_group;\n  SOCKET base_socket;\n  epoll_data_t user_data;\n  uint32_t user_events;\n  uint32_t pending_events;\n  sock__poll_status_t poll_status;\n  bool delete_pending;\n} sock_state_t;\n\nstatic inline sock_state_t* sock__alloc(void) {\n  sock_state_t* sock_state = mm_malloc(sizeof *sock_state);\n  if (sock_state == NULL)\n    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n  return sock_state;\n}\n\nstatic inline void sock__free(sock_state_t* sock_state) {\n  mm_free(sock_state);\n}\n\nstatic int sock__cancel_poll(sock_state_t* sock_state) {\n  assert(sock_state->poll_status == SOCK__POLL_PENDING);\n\n  if (afd_cancel_poll(poll_group_get_afd_helper_handle(sock_state->poll_group),\n                      &sock_state->io_status_block) < 0)\n    return -1;\n\n  sock_state->poll_status = SOCK__POLL_CANCELLED;\n  sock_state->pending_events = 0;\n  return 0;\n}\n\nsock_state_t* sock_new(port_state_t* port_state, SOCKET socket) {\n  SOCKET base_socket;\n  poll_group_t* poll_group;\n  sock_state_t* sock_state;\n\n  if (socket == 0 || socket == INVALID_SOCKET)\n    return_set_error(NULL, ERROR_INVALID_HANDLE);\n\n  base_socket = ws_get_base_socket(socket);\n  if (base_socket == INVALID_SOCKET)\n    return NULL;\n\n  poll_group = poll_group_acquire(port_state);\n  if (poll_group == NULL)\n    return NULL;\n\n  sock_state = sock__alloc();\n  if (sock_state == NULL)\n    goto err1;\n\n  memset(sock_state, 0, sizeof *sock_state);\n\n  sock_state->base_socket = base_socket;\n  sock_state->poll_group = poll_group;\n\n  tree_node_init(&sock_state->tree_node);\n  queue_node_init(&sock_state->queue_node);\n\n  if (port_register_socket_handle(port_state, sock_state, socket) < 0)\n    goto err2;\n\n  return sock_state;\n\nerr2:\n  sock__free(sock_state);\nerr1:\n  poll_group_release(poll_group);\n\n  return NULL;\n}\n\nstatic int sock__delete(port_state_t* port_state,\n                        sock_state_t* sock_state,\n                        bool force) {\n  if (!sock_state->delete_pending) {\n    if (sock_state->poll_status == SOCK__POLL_PENDING)\n      sock__cancel_poll(sock_state);\n\n    port_cancel_socket_update(port_state, sock_state);\n    port_unregister_socket_handle(port_state, sock_state);\n\n    sock_state->delete_pending = true;\n  }\n\n  /* If the poll request still needs to complete, the sock_state object can't\n   * be free()d yet. `sock_feed_event()` or `port_close()` will take care\n   * of this later. */\n  if (force || sock_state->poll_status == SOCK__POLL_IDLE) {\n    /* Free the sock_state now. */\n    port_remove_deleted_socket(port_state, sock_state);\n    poll_group_release(sock_state->poll_group);\n    sock__free(sock_state);\n  } else {\n    /* Free the socket later. */\n    port_add_deleted_socket(port_state, sock_state);\n  }\n\n  return 0;\n}\n\nvoid sock_delete(port_state_t* port_state, sock_state_t* sock_state) {\n  sock__delete(port_state, sock_state, false);\n}\n\nvoid sock_force_delete(port_state_t* port_state, sock_state_t* sock_state) {\n  sock__delete(port_state, sock_state, true);\n}\n\nint sock_set_event(port_state_t* port_state,\n                   sock_state_t* sock_state,\n                   const struct epoll_event* ev) {\n  /* EPOLLERR and EPOLLHUP are always reported, even when not requested by the\n   * caller. However they are disabled after a event has been reported for a\n   * socket for which the EPOLLONESHOT flag as set. */\n  uint32_t events = ev->events | EPOLLERR | EPOLLHUP;\n\n  sock_state->user_events = events;\n  sock_state->user_data = ev->data;\n\n  if ((events & SOCK__KNOWN_EPOLL_EVENTS & ~sock_state->pending_events) != 0)\n    port_request_socket_update(port_state, sock_state);\n\n  return 0;\n}\n\nstatic inline DWORD sock__epoll_events_to_afd_events(uint32_t epoll_events) {\n  /* Always monitor for AFD_POLL_LOCAL_CLOSE, which is triggered when the\n   * socket is closed with closesocket() or CloseHandle(). */\n  DWORD afd_events = AFD_POLL_LOCAL_CLOSE;\n\n  if (epoll_events & (EPOLLIN | EPOLLRDNORM))\n    afd_events |= AFD_POLL_RECEIVE | AFD_POLL_ACCEPT;\n  if (epoll_events & (EPOLLPRI | EPOLLRDBAND))\n    afd_events |= AFD_POLL_RECEIVE_EXPEDITED;\n  if (epoll_events & (EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND))\n    afd_events |= AFD_POLL_SEND;\n  if (epoll_events & (EPOLLIN | EPOLLRDNORM | EPOLLRDHUP))\n    afd_events |= AFD_POLL_DISCONNECT;\n  if (epoll_events & EPOLLHUP)\n    afd_events |= AFD_POLL_ABORT;\n  if (epoll_events & EPOLLERR)\n    afd_events |= AFD_POLL_CONNECT_FAIL;\n\n  return afd_events;\n}\n\nstatic inline uint32_t sock__afd_events_to_epoll_events(DWORD afd_events) {\n  uint32_t epoll_events = 0;\n\n  if (afd_events & (AFD_POLL_RECEIVE | AFD_POLL_ACCEPT))\n    epoll_events |= EPOLLIN | EPOLLRDNORM;\n  if (afd_events & AFD_POLL_RECEIVE_EXPEDITED)\n    epoll_events |= EPOLLPRI | EPOLLRDBAND;\n  if (afd_events & AFD_POLL_SEND)\n    epoll_events |= EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND;\n  if (afd_events & AFD_POLL_DISCONNECT)\n    epoll_events |= EPOLLIN | EPOLLRDNORM | EPOLLRDHUP;\n  if (afd_events & AFD_POLL_ABORT)\n    epoll_events |= EPOLLHUP;\n  if (afd_events & AFD_POLL_CONNECT_FAIL)\n    /* Linux reports all these events after connect() has failed. */\n    epoll_events |=\n        EPOLLIN | EPOLLOUT | EPOLLERR | EPOLLRDNORM | EPOLLWRNORM | EPOLLRDHUP;\n\n  return epoll_events;\n}\n\nint sock_update(port_state_t* port_state, sock_state_t* sock_state) {\n  assert(!sock_state->delete_pending);\n\n  if ((sock_state->poll_status == SOCK__POLL_PENDING) &&\n      (sock_state->user_events & SOCK__KNOWN_EPOLL_EVENTS &\n       ~sock_state->pending_events) == 0) {\n    /* All the events the user is interested in are already being monitored by\n     * the pending poll operation. It might spuriously complete because of an\n     * event that we're no longer interested in; when that happens we'll submit\n     * a new poll operation with the updated event mask. */\n\n  } else if (sock_state->poll_status == SOCK__POLL_PENDING) {\n    /* A poll operation is already pending, but it's not monitoring for all the\n     * events that the user is interested in. Therefore, cancel the pending\n     * poll operation; when we receive it's completion package, a new poll\n     * operation will be submitted with the correct event mask. */\n    if (sock__cancel_poll(sock_state) < 0)\n      return -1;\n\n  } else if (sock_state->poll_status == SOCK__POLL_CANCELLED) {\n    /* The poll operation has already been cancelled, we're still waiting for\n     * it to return. For now, there's nothing that needs to be done. */\n\n  } else if (sock_state->poll_status == SOCK__POLL_IDLE) {\n    /* No poll operation is pending; start one. */\n    sock_state->poll_info.Exclusive = FALSE;\n    sock_state->poll_info.NumberOfHandles = 1;\n    sock_state->poll_info.Timeout.QuadPart = INT64_MAX;\n    sock_state->poll_info.Handles[0].Handle = (HANDLE) sock_state->base_socket;\n    sock_state->poll_info.Handles[0].Status = 0;\n    sock_state->poll_info.Handles[0].Events =\n        sock__epoll_events_to_afd_events(sock_state->user_events);\n\n    if (afd_poll(poll_group_get_afd_helper_handle(sock_state->poll_group),\n                 &sock_state->poll_info,\n                 &sock_state->io_status_block) < 0) {\n      switch (GetLastError()) {\n        case ERROR_IO_PENDING:\n          /* Overlapped poll operation in progress; this is expected. */\n          break;\n        case ERROR_INVALID_HANDLE:\n          /* Socket closed; it'll be dropped from the epoll set. */\n          return sock__delete(port_state, sock_state, false);\n        default:\n          /* Other errors are propagated to the caller. */\n          return_map_error(-1);\n      }\n    }\n\n    /* The poll request was successfully submitted. */\n    sock_state->poll_status = SOCK__POLL_PENDING;\n    sock_state->pending_events = sock_state->user_events;\n\n  } else {\n    /* Unreachable. */\n    assert(false);\n  }\n\n  port_cancel_socket_update(port_state, sock_state);\n  return 0;\n}\n\nint sock_feed_event(port_state_t* port_state,\n                    IO_STATUS_BLOCK* io_status_block,\n                    struct epoll_event* ev) {\n  sock_state_t* sock_state =\n      container_of(io_status_block, sock_state_t, io_status_block);\n  AFD_POLL_INFO* poll_info = &sock_state->poll_info;\n  uint32_t epoll_events = 0;\n\n  sock_state->poll_status = SOCK__POLL_IDLE;\n  sock_state->pending_events = 0;\n\n  if (sock_state->delete_pending) {\n    /* Socket has been deleted earlier and can now be freed. */\n    return sock__delete(port_state, sock_state, false);\n\n  } else if (io_status_block->Status == STATUS_CANCELLED) {\n    /* The poll request was cancelled by CancelIoEx. */\n\n  } else if (!NT_SUCCESS(io_status_block->Status)) {\n    /* The overlapped request itself failed in an unexpected way. */\n    epoll_events = EPOLLERR;\n\n  } else if (poll_info->NumberOfHandles < 1) {\n    /* This poll operation succeeded but didn't report any socket events. */\n\n  } else if (poll_info->Handles[0].Events & AFD_POLL_LOCAL_CLOSE) {\n    /* The poll operation reported that the socket was closed. */\n    return sock__delete(port_state, sock_state, false);\n\n  } else {\n    /* Events related to our socket were reported. */\n    epoll_events =\n        sock__afd_events_to_epoll_events(poll_info->Handles[0].Events);\n  }\n\n  /* Requeue the socket so a new poll request will be submitted. */\n  port_request_socket_update(port_state, sock_state);\n\n  /* Filter out events that the user didn't ask for. */\n  epoll_events &= sock_state->user_events;\n\n  /* Return if there are no epoll events to report. */\n  if (epoll_events == 0)\n    return 0;\n\n  /* If the socket has the EPOLLONESHOT flag set, unmonitor all events,\n   * even EPOLLERR and EPOLLHUP. But always keep looking for closed sockets. */\n  if (sock_state->user_events & EPOLLONESHOT)\n    sock_state->user_events = 0;\n\n  ev->data = sock_state->user_data;\n  ev->events = epoll_events;\n  return 1;\n}\n\nsock_state_t* sock_state_from_queue_node(queue_node_t* queue_node) {\n  return container_of(queue_node, sock_state_t, queue_node);\n}\n\nqueue_node_t* sock_state_to_queue_node(sock_state_t* sock_state) {\n  return &sock_state->queue_node;\n}\n\nsock_state_t* sock_state_from_tree_node(tree_node_t* tree_node) {\n  return container_of(tree_node, sock_state_t, tree_node);\n}\n\ntree_node_t* sock_state_to_tree_node(sock_state_t* sock_state) {\n  return &sock_state->tree_node;\n}\n\nvoid ts_tree_init(ts_tree_t* ts_tree) {\n  tree_init(&ts_tree->tree);\n  InitializeSRWLock(&ts_tree->lock);\n}\n\nvoid ts_tree_node_init(ts_tree_node_t* node) {\n  tree_node_init(&node->tree_node);\n  reflock_init(&node->reflock);\n}\n\nint ts_tree_add(ts_tree_t* ts_tree, ts_tree_node_t* node, uintptr_t key) {\n  int r;\n\n  AcquireSRWLockExclusive(&ts_tree->lock);\n  r = tree_add(&ts_tree->tree, &node->tree_node, key);\n  ReleaseSRWLockExclusive(&ts_tree->lock);\n\n  return r;\n}\n\nstatic inline ts_tree_node_t* ts_tree__find_node(ts_tree_t* ts_tree,\n                                                 uintptr_t key) {\n  tree_node_t* tree_node = tree_find(&ts_tree->tree, key);\n  if (tree_node == NULL)\n    return NULL;\n\n  return container_of(tree_node, ts_tree_node_t, tree_node);\n}\n\nts_tree_node_t* ts_tree_del_and_ref(ts_tree_t* ts_tree, uintptr_t key) {\n  ts_tree_node_t* ts_tree_node;\n\n  AcquireSRWLockExclusive(&ts_tree->lock);\n\n  ts_tree_node = ts_tree__find_node(ts_tree, key);\n  if (ts_tree_node != NULL) {\n    tree_del(&ts_tree->tree, &ts_tree_node->tree_node);\n    reflock_ref(&ts_tree_node->reflock);\n  }\n\n  ReleaseSRWLockExclusive(&ts_tree->lock);\n\n  return ts_tree_node;\n}\n\nts_tree_node_t* ts_tree_find_and_ref(ts_tree_t* ts_tree, uintptr_t key) {\n  ts_tree_node_t* ts_tree_node;\n\n  AcquireSRWLockShared(&ts_tree->lock);\n\n  ts_tree_node = ts_tree__find_node(ts_tree, key);\n  if (ts_tree_node != NULL)\n    reflock_ref(&ts_tree_node->reflock);\n\n  ReleaseSRWLockShared(&ts_tree->lock);\n\n  return ts_tree_node;\n}\n\nvoid ts_tree_node_unref(ts_tree_node_t* node) {\n  reflock_unref(&node->reflock);\n}\n\nvoid ts_tree_node_unref_and_destroy(ts_tree_node_t* node) {\n  reflock_unref_and_destroy(&node->reflock);\n}\n\nvoid tree_init(tree_t* tree) {\n  memset(tree, 0, sizeof *tree);\n}\n\nvoid tree_node_init(tree_node_t* node) {\n  memset(node, 0, sizeof *node);\n}\n\n#define TREE__ROTATE(cis, trans)   \\\n  tree_node_t* p = node;           \\\n  tree_node_t* q = node->trans;    \\\n  tree_node_t* parent = p->parent; \\\n                                   \\\n  if (parent) {                    \\\n    if (parent->left == p)         \\\n      parent->left = q;            \\\n    else                           \\\n      parent->right = q;           \\\n  } else {                         \\\n    tree->root = q;                \\\n  }                                \\\n                                   \\\n  q->parent = parent;              \\\n  p->parent = q;                   \\\n  p->trans = q->cis;               \\\n  if (p->trans)                    \\\n    p->trans->parent = p;          \\\n  q->cis = p;\n\nstatic inline void tree__rotate_left(tree_t* tree, tree_node_t* node) {\n  TREE__ROTATE(left, right)\n}\n\nstatic inline void tree__rotate_right(tree_t* tree, tree_node_t* node) {\n  TREE__ROTATE(right, left)\n}\n\n#define TREE__INSERT_OR_DESCEND(side) \\\n  if (parent->side) {                 \\\n    parent = parent->side;            \\\n  } else {                            \\\n    parent->side = node;              \\\n    break;                            \\\n  }\n\n#define TREE__REBALANCE_AFTER_INSERT(cis, trans) \\\n  tree_node_t* grandparent = parent->parent;     \\\n  tree_node_t* uncle = grandparent->trans;       \\\n                                                 \\\n  if (uncle && uncle->red) {                     \\\n    parent->red = uncle->red = false;            \\\n    grandparent->red = true;                     \\\n    node = grandparent;                          \\\n  } else {                                       \\\n    if (node == parent->trans) {                 \\\n      tree__rotate_##cis(tree, parent);          \\\n      node = parent;                             \\\n      parent = node->parent;                     \\\n    }                                            \\\n    parent->red = false;                         \\\n    grandparent->red = true;                     \\\n    tree__rotate_##trans(tree, grandparent);     \\\n  }\n\nint tree_add(tree_t* tree, tree_node_t* node, uintptr_t key) {\n  tree_node_t* parent;\n\n  parent = tree->root;\n  if (parent) {\n    for (;;) {\n      if (key < parent->key) {\n        TREE__INSERT_OR_DESCEND(left)\n      } else if (key > parent->key) {\n        TREE__INSERT_OR_DESCEND(right)\n      } else {\n        return -1;\n      }\n    }\n  } else {\n    tree->root = node;\n  }\n\n  node->key = key;\n  node->left = node->right = NULL;\n  node->parent = parent;\n  node->red = true;\n\n  for (; parent && parent->red; parent = node->parent) {\n    if (parent == parent->parent->left) {\n      TREE__REBALANCE_AFTER_INSERT(left, right)\n    } else {\n      TREE__REBALANCE_AFTER_INSERT(right, left)\n    }\n  }\n  tree->root->red = false;\n\n  return 0;\n}\n\n#define TREE__REBALANCE_AFTER_REMOVE(cis, trans)   \\\n  tree_node_t* sibling = parent->trans;            \\\n                                                   \\\n  if (sibling->red) {                              \\\n    sibling->red = false;                          \\\n    parent->red = true;                            \\\n    tree__rotate_##cis(tree, parent);              \\\n    sibling = parent->trans;                       \\\n  }                                                \\\n  if ((sibling->left && sibling->left->red) ||     \\\n      (sibling->right && sibling->right->red)) {   \\\n    if (!sibling->trans || !sibling->trans->red) { \\\n      sibling->cis->red = false;                   \\\n      sibling->red = true;                         \\\n      tree__rotate_##trans(tree, sibling);         \\\n      sibling = parent->trans;                     \\\n    }                                              \\\n    sibling->red = parent->red;                    \\\n    parent->red = sibling->trans->red = false;     \\\n    tree__rotate_##cis(tree, parent);              \\\n    node = tree->root;                             \\\n    break;                                         \\\n  }                                                \\\n  sibling->red = true;\n\nvoid tree_del(tree_t* tree, tree_node_t* node) {\n  tree_node_t* parent = node->parent;\n  tree_node_t* left = node->left;\n  tree_node_t* right = node->right;\n  tree_node_t* next;\n  bool red;\n\n  if (!left) {\n    next = right;\n  } else if (!right) {\n    next = left;\n  } else {\n    next = right;\n    while (next->left)\n      next = next->left;\n  }\n\n  if (parent) {\n    if (parent->left == node)\n      parent->left = next;\n    else\n      parent->right = next;\n  } else {\n    tree->root = next;\n  }\n\n  if (left && right) {\n    red = next->red;\n    next->red = node->red;\n    next->left = left;\n    left->parent = next;\n    if (next != right) {\n      parent = next->parent;\n      next->parent = node->parent;\n      node = next->right;\n      parent->left = node;\n      next->right = right;\n      right->parent = next;\n    } else {\n      next->parent = parent;\n      parent = next;\n      node = next->right;\n    }\n  } else {\n    red = node->red;\n    node = next;\n  }\n\n  if (node)\n    node->parent = parent;\n  if (red)\n    return;\n  if (node && node->red) {\n    node->red = false;\n    return;\n  }\n\n  do {\n    if (node == tree->root)\n      break;\n    if (node == parent->left) {\n      TREE__REBALANCE_AFTER_REMOVE(left, right)\n    } else {\n      TREE__REBALANCE_AFTER_REMOVE(right, left)\n    }\n    node = parent;\n    parent = parent->parent;\n  } while (!node->red);\n\n  if (node)\n    node->red = false;\n}\n\ntree_node_t* tree_find(const tree_t* tree, uintptr_t key) {\n  tree_node_t* node = tree->root;\n  while (node) {\n    if (key < node->key)\n      node = node->left;\n    else if (key > node->key)\n      node = node->right;\n    else\n      return node;\n  }\n  return NULL;\n}\n\ntree_node_t* tree_root(const tree_t* tree) {\n  return tree->root;\n}\n\n#ifndef SIO_BASE_HANDLE\n#define SIO_BASE_HANDLE 0x48000022\n#endif\n\nint ws_global_init(void) {\n  int r;\n  WSADATA wsa_data;\n\n  r = WSAStartup(MAKEWORD(2, 2), &wsa_data);\n  if (r != 0)\n    return_set_error(-1, (DWORD) r);\n\n  return 0;\n}\n\nSOCKET ws_get_base_socket(SOCKET socket) {\n  SOCKET base_socket;\n  DWORD bytes;\n\n  if (WSAIoctl(socket,\n               SIO_BASE_HANDLE,\n               NULL,\n               0,\n               &base_socket,\n               sizeof base_socket,\n               &bytes,\n               NULL,\n               NULL) == SOCKET_ERROR)\n    return_map_error(INVALID_SOCKET);\n\n  return base_socket;\n}\n"
        },
        {
          "name": "wepoll.h",
          "type": "blob",
          "size": 3.361328125,
          "content": "/*\n * wepoll - epoll for Windows\n * https://github.com/piscisaureus/wepoll\n *\n * Copyright 2012-2020, Bert Belder <bertbelder@gmail.com>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *   * Redistributions of source code must retain the above copyright\n *     notice, this list of conditions and the following disclaimer.\n *\n *   * Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifndef WEPOLL_H_\n#define WEPOLL_H_\n\n#define WEPOLL_EXPORT\n\n#include <stdint.h>\n\nenum EPOLL_EVENTS {\n  EPOLLIN      = (int) (1U <<  0),\n  EPOLLPRI     = (int) (1U <<  1),\n  EPOLLOUT     = (int) (1U <<  2),\n  EPOLLERR     = (int) (1U <<  3),\n  EPOLLHUP     = (int) (1U <<  4),\n  EPOLLRDNORM  = (int) (1U <<  6),\n  EPOLLRDBAND  = (int) (1U <<  7),\n  EPOLLWRNORM  = (int) (1U <<  8),\n  EPOLLWRBAND  = (int) (1U <<  9),\n  EPOLLMSG     = (int) (1U << 10), /* Never reported. */\n  EPOLLRDHUP   = (int) (1U << 13),\n  EPOLLONESHOT = (int) (1U << 30)\n};\n\n#define EPOLLIN      (1U <<  0)\n#define EPOLLPRI     (1U <<  1)\n#define EPOLLOUT     (1U <<  2)\n#define EPOLLERR     (1U <<  3)\n#define EPOLLHUP     (1U <<  4)\n#define EPOLLRDNORM  (1U <<  6)\n#define EPOLLRDBAND  (1U <<  7)\n#define EPOLLWRNORM  (1U <<  8)\n#define EPOLLWRBAND  (1U <<  9)\n#define EPOLLMSG     (1U << 10)\n#define EPOLLRDHUP   (1U << 13)\n#define EPOLLONESHOT (1U << 30)\n\n#define EPOLL_CTL_ADD 1\n#define EPOLL_CTL_MOD 2\n#define EPOLL_CTL_DEL 3\n\ntypedef void* HANDLE;\ntypedef uintptr_t SOCKET;\n\ntypedef union epoll_data {\n  void* ptr;\n  int fd;\n  uint32_t u32;\n  uint64_t u64;\n  SOCKET sock; /* Windows specific */\n  HANDLE hnd;  /* Windows specific */\n} epoll_data_t;\n\nstruct epoll_event {\n  uint32_t events;   /* Epoll events and flags */\n  epoll_data_t data; /* User data variable */\n};\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nWEPOLL_EXPORT HANDLE epoll_create(int size);\nWEPOLL_EXPORT HANDLE epoll_create1(int flags);\n\nWEPOLL_EXPORT int epoll_close(HANDLE ephnd);\n\nWEPOLL_EXPORT int epoll_ctl(HANDLE ephnd,\n                            int op,\n                            SOCKET sock,\n                            struct epoll_event* event);\n\nWEPOLL_EXPORT int epoll_wait(HANDLE ephnd,\n                             struct epoll_event* events,\n                             int maxevents,\n                             int timeout);\n\n#ifdef __cplusplus\n} /* extern \"C\" */\n#endif\n\n#endif /* WEPOLL_H_ */\n"
        },
        {
          "name": "whatsnew-2.0.txt",
          "type": "blob",
          "size": 25.7265625,
          "content": "What's New In Libevent 2.0 so far:\n\n1. Meta-issues\n\n1.1. About this document\n\n  This document describes the key differences between Libevent 1.4 and\n  Libevent 2.0, from a user's point of view.  It was most recently\n  updated based on features in git master as of August 2010.\n\n  NOTE: I am very sure that I missed some thing on this list.  Caveat\n  haxxor.\n\n1.2. Better documentation\n\n  There is now a book-in-progress that explains how to use Libevent and its\n  growing pile of APIs.  As of this writing, it covers everything except the\n  http and rpc code.  Check out the latest draft at\n  http://www.wangafu.net/~nickm/libevent-book/ .\n\n2. New and Improved Event APIs\n\n  Many APIs are improved, refactored, or deprecated in Libevent 2.0.\n\n  COMPATIBILITY:\n\n  Nearly all existing code that worked with Libevent 1.4 should still\n  work correctly with Libevent 2.0.  However, if you are writing new code,\n  or if you want to port old code, we strongly recommend using the new APIs\n  and avoiding deprecated APIs as much as possible.\n\n  Binaries linked against Libevent 1.4 will need to be recompiled to link\n  against Libevent 2.0.  This is nothing new; we have never been good at\n  preserving binary compatibility between releases.  We'll try harder in the\n  future, though: see 2.1 below.\n\n2.1. New header layout for improved forward-compatibility\n\n  Libevent 2.0 has a new header layout to make it easier for programmers to\n  write good, well-supported libevent code.  The new headers are divided\n  into three types.\n\n  There are *regular headers*, like event2/event.h.  These headers contain\n  the functions that most programmers will want to use.\n\n  There are *backward compatibility headers*, like event2/event_compat.h.\n  These headers contain declarations for deprecated functions from older\n  versions of Libevent.  Documentation in these headers should suggest what's\n  wrong with the old functions, and what functions you want to start using\n  instead of the old ones.  Some of these functions might be removed in a\n  future release.  New programs should generally not include these headers.\n\n  Finally, there are *structure headers*, like event2/event_struct.h.\n  These headers contain definitions of some structures that Libevent has\n  historically exposed.  Exposing them caused problems in the past,\n  since programs that were compiled to work with one version of Libevent\n  would often stop working with another version that changed the size or\n  layout of some object.  We've moving them into separate headers so\n  that programmers can know that their code is not depending on any\n  unstable aspect of the Libvent ABI.  New programs should generally not\n  include these headers unless they really know what they are doing, are\n  willing to rebuild their software whenever they want to link it\n  against a new version of Libevent, and are willing to risk their code\n  breaking if and when data structures change.\n\n  Functionality that once was located in event.h is now more subdivided.\n  The core event logic is now in event2/event.h.  The \"evbuffer\" functions\n  for low-level buffer manipulation are in event2/buffer.h.  The\n  \"bufferevent\" functions for higher-level buffered IO are in\n  event2/bufferevent.h.\n\n  COMPATIBILITY:\n\n  All of the old headers (event.h, evdns.h, evhttp.h, evrpc.h, and\n  evutil.h) will continue to work by including the corresponding new\n  headers.  Old code should not be broken by this change.\n\n2.2. New thread-safe, binary-compatible, harder-to-mess-up APIs\n\n  Some aspects of the historical Libevent API have encouraged\n  non-threadsafe code, or forced code built against one version of Libevent\n  to no longer build with another.  The problems with now-deprecated APIs\n  fell into two categories:\n\n     1) Dependence on the \"current\" event_base.  In an application with\n        multiple event_bases, Libevent previously had a notion of the\n        \"current\" event_base.  New events were linked to this base, and\n        the caller needed to explicitly reattach them to another base.\n        This was horribly error-prone.\n\n        Functions like \"event_set\" that worked with the \"current\" event_base\n        are now deprecated but still available (see 2.1).  There are new\n        functions like \"event_assign\" that take an explicit event_base\n        argument when setting up a structure.  Using these functions will help\n        prevent errors in your applications, and to be more threadsafe.\n\n     2) Structure dependence.  Applications needed to allocate 'struct\n        event' themselves, since there was no function in Libevent to do it\n        for them.  But since the size and contents of struct event can\n        change between libevent versions, this created binary-compatibility\n        nightmares.  All structures of this kind are now isolated in\n        _struct.h header (see 2.1), and there are new allocate-and-\n        initialize functions you can use instead of the old initialize-only\n        functions.  For example, instead of malloc and event_set, you\n        can use event_new().\n\n        (For people who do really want to allocate a struct event on the\n        stack, or put one inside another structure, you can still use\n        event2/event_compat.h.)\n\n   So in the case where old code would look like this:\n\n      #include <event.h>\n      ...\n      struct event *ev = malloc(sizeof(struct event));\n      /* This call will cause a buffer overrun if you compile with one version\n         of Libevent and link dynamically against another. */\n      event_set(ev, fd, EV_READ, cb, NULL);\n      /* If you forget this call, your code will break in hard-to-diagnose\n         ways in the presence of multiple event bases. */\n      event_set_base(ev, base);\n\n   New code will look more like this:\n\n     #include <event2/event.h>\n     ...\n     struct event *ev;\n     ev = event_new(base, fd, EV_READ, cb, NULL);\n\n2.3. Overrideable allocation functions\n\n  If you want to override the allocation functions used by libevent\n  (for example, to use a specialized allocator, or debug memory\n  issues, or so on), you can replace them by calling\n  event_set_mem_functions.  It takes replacements for malloc(),\n  free(), and realloc().\n\n  If you're going to use this facility, you need to call it _before_\n  Libevent does any memory allocation; otherwise, Libevent may allocate some\n  memory with malloc(), and free it with the free() function you provide.\n\n  You can disable this feature when you are building Libevent by passing\n  the --disable-malloc-replacement argument to configure.\n\n2.4. Configurable event_base creation\n\n  Older versions of Libevent would always got the fastest backend\n  available, unless you reconfigured their behavior with the environment\n  variables EVENT_NOSELECT, EVENT_NOPOLL, and so forth.  This was annoying\n  to programmers who wanted to pick a backend explicitly without messing\n  with the environment.\n\n  Also, despite our best efforts, not every backend supports every\n  operation we might like.  Some features (like edge-triggered events, or\n  working with non-socket file descriptors) only work with some operating\n  systems' fast backends.  Previously, programmers who cared about this\n  needed to know which backends supported what.  This tended to get quite\n  ungainly.\n\n  There is now an API to choose backends, either by name or by feature.\n  Here is an example:\n\n      struct event_config_t *config;\n      struct event_base *base;\n\n      /* Create a new configuration object. */\n      config = event_config_new();\n      /* We don't want to use the \"select\" method. */\n      event_config_avoid_method(config, \"select\");\n      /* We want a method that can work with non-socket file descriptors */\n      event_config_require_features(config, EV_FEATURE_FDS);\n\n      base = event_base_new_with_config(config);\n      if (!base) {\n         /* There is no backend method that does what we want. */\n         exit(1);\n      }\n      event_config_free(config);\n\n  Supported features are documented in event2/event.h\n\n2.5. Socket is now an abstract type\n\n  All APIs that formerly accepted int as a socket type now accept\n  \"evutil_socket_t\".  On Unix, this is just an alias for \"int\" as\n  before.  On Windows, however, it's an alias for SOCKET, which can\n  be wider than int on 64-bit platforms.\n\n2.6. Timeouts and persistent events work together.\n\n  Previously, it wasn't useful to set a timeout on a persistent event:\n  the timeout would trigger once, and never again.  This is not what\n  applications tend to want.  Instead, applications tend to want every\n  triggering of the event to re-set the timeout.  So now, if you set\n  up an event like this:\n       struct event *ev;\n       struct timeval tv;\n       ev = event_new(base, fd, EV_READ|EV_PERSIST, cb, NULL);\n       tv.tv_sec = 1;\n       tv.tv_usec = 0;\n       event_add(ev, &tv);\n\n  The callback 'cb' will be invoked whenever fd is ready to read, OR whenever\n  a second has passed since the last invocation of cb.\n\n2.7. Multiple events allowed per fd\n\n  Older versions of Libevent allowed at most one EV_READ event and at most\n  one EV_WRITE event per socket, per event base.  This restriction is no\n  longer present.\n\n2.8. evthread_* functions for thread-safe structures.\n\n  Libevent structures can now be built with locking support.  This code\n  makes it safe to add, remove, and activate events on an event base from a\n  different thread.  (Previously, if you wanted to write multithreaded code\n  with Libevent, you could only an event_base or its events in one thread at\n  a time.)\n\n  If you want threading support and you're using pthreads, you can just\n  call evthread_use_pthreads().  (You'll need to link against the\n  libevent_pthreads library in addition to libevent_core.  These functions are\n  not in libevent_core.)\n\n  If you want threading support and you're using Windows, you can just\n  call evthread_use_windows_threads().\n\n  If you are using some locking system besides Windows and pthreads, You\n  can enable this on a per-event-base level by writing functions to\n  implement mutexes, conditions, and thread IDs, and passing them to\n  evthread_set_lock_callbacks and related functions in event2/thread.h.\n\n  Once locking functions are enabled, every new event_base is created with a\n  lock.  You can prevent a single event_base from being built with a lock\n  disabled by using the EVENT_BASE_FLAG_NOLOCK flag in its\n  event_config.  If an event_base is created with a lock, it is safe to call\n  event_del, event_add, and event_active on its events from any thread.  The\n  event callbacks themselves are still all executed from the thread running\n  the event loop.\n\n  To make an evbuffer or a bufferevent object threadsafe, call its\n  *_enable_locking() function.\n\n  The HTTP api is not currently threadsafe.\n\n  To build Libevent with threading support disabled, pass\n  --disable-thread-support to the configure script.\n\n2.9. Edge-triggered events on some backends.\n\n  With some backends, it's now possible to add the EV_ET flag to an event\n  in order to request that the event's semantics be edge-triggered.  Right\n  now, epoll and kqueue support this.\n\n  The corresponding event_config feature is EV_FEATURE_ET; see 2.4 for more\n  information.\n\n2.10. Better support for huge numbers of timeouts\n\n  The heap-based priority queue timer implementation for Libevent 1.4 is good\n  for randomly distributed timeouts, but suboptimal if you have huge numbers\n  of timeouts that all expire in the same amount of time after their\n  creation.  The new event_base_init_common_timeout() logic lets you signal\n  that a given timeout interval will be very common, and should use a linked\n  list implementation instead of a priority queue.\n\n2.11. Improved debugging support\n\n  It's been pretty easy to forget to delete all your events before you\n  re-initialize them, or otherwise put Libevent in an internally inconsistent\n  state.  You can tell libevent to catch these and other common errors with\n  the new event_enable_debug_mode() call.  Just invoke it before you do\n  any calls to other libevent functions, and it'll catch many common\n  event-level errors in your code.\n\n2.12. Functions to access all event fields\n\n  So that you don't have to access the struct event fields directly, Libevent\n  now provides accessor functions to retrieve everything from an event that\n  you set during event_new() or event_assign().\n\n3. Backend-specific and performance improvements.\n\n3.1. Change-minimization on O(1) backends\n\n  With previous versions of Libevent, if you called event_del() and\n  event_add() repeatedly on a single event between trips to the backend's\n  dispatch function, the backend might wind up making unnecessary calls or\n  passing unnecessary data to the kernel.  The new backend logic batches up\n  redundant adds and deletes, and performs no more operations than necessary\n  at the kernel level.\n\n  This logic is on for the kqueue backend, and available (but off by\n  default) for the epoll backend.  To turn it on for the epoll backend,\n  set the EVENT_BASE_FLAG_EPOLL_USE_CHANGELIST flag in the\n  event_base_cofig, or set the EVENT_EPOLL_USE_CHANGELIST environment\n  variable.  Doing this with epoll may result in weird bugs if you give\n  any fds closed by dup() or its variants.\n\n3.2. Improved notification on Linux\n\n  When we need to wake the event loop up from another thread, we use\n  an epollfd to do so, instead of a socketpair.  This is supposed to be\n  faster.\n\n3.3. Windows: better support for everything\n\n  Bufferevents on Windows can use a new mechanism (off-by-default; see below)\n  to send their data via Windows overlapped IO and get their notifications\n  via the IOCP API.  This should be much faster than using event-based\n  notification.\n\n  Other functions throughout the code have been fixed to work more\n  consistently with Windows.  Libevent now builds on Windows using either\n  mingw, or using MSVC (with nmake).  Libevent works fine with UNICODE\n  defined, or not.\n\n  Data structures are a little smarter: our lookups from socket to pending\n  event are now done with O(1) hash tables rather than O(lg n) red-black\n  trees.\n\n  Unfortunately, the main Windows backend is still select()-based: from\n  testing the IOCP backends on the mailing list, it seems that there isn't\n  actually a way to tell for certain whether a socket is writable with IOCP.\n  Libevent 2.1 may add a multithreaded WaitForMultipleEvents-based\n  backend for better performance with many inactive sockets and better\n  integration with Windows events.\n\n4. Improvements to evbuffers\n\n  Libevent has long had an \"evbuffer\" implementation to wrap access to an\n  input or output memory buffer.  In previous versions, the implementation\n  was very inefficient and lacked some desirable features.  We've made many\n  improvements in Libevent 2.0.\n\n4.1. Chunked-memory internal representation\n\n  Previously, each evbuffer was a huge chunk of memory.  When we ran out of\n  space in an evbuffer, we used realloc() to grow the chunk of memory.  When\n  data was misaligned, we used memmove to move the data back to the front\n  of the buffer.\n\n  Needless to say, this is a terrible interface for networked IO.\n\n  Now, evbuffers are implemented as a linked list of memory chunks, like\n  most Unix kernels use for network IO.  (See Linux's skbuf interfaces,\n  or *BSD's mbufs).  Data is added at the end of the linked list and\n  removed from the front, so that we don't ever need realloc huge chunks\n  or memmove the whole buffer contents.\n\n  To avoid excessive calls to read and write, we use the readv/writev\n  interfaces (or WSASend/WSARecv on Windows) to do IO on multiple chunks at\n  once with a single system call.\n\n  COMPATIBILITY NOTE:\n  The evbuffer struct is no longer exposed in a header.  The code here is\n  too volatile to expose an official evbuffer structure, and there was never\n  any means provided to create an evbuffer except via evbuffer_new which\n  heap-allocated the buffer.\n\n  If you need access to the whole buffer as a linear chunk of memory, the\n  EVBUFFER_DATA() function still works.  Watch out, though: it needs to copy\n  the buffer's contents in a linear chunk before you can use it.\n\n4.2. More flexible readline support\n\n  The old evbuffer_readline() function (which accepted any sequence of\n  CR and LF characters as a newline, and which couldn't handle lines\n  containing NUL characters), is now deprecated.  The preferred\n  function is evbuffer_readln(), which supports a variety of\n  line-ending styles, and which can return the number of characters in\n  the line returned.\n\n  You can also call evbuffer_search_eol() to find the end of a line\n  in an evbuffer without ever extracting the line.\n\n4.3. Support for file-based IO in evbuffers.\n\n  You can now add chunks of a file into a evbuffer, and Libevent will have\n  your OS use mapped-memory functionality, sendfile, or splice to transfer\n  the data without ever copying it to userspace.  On OSs where this is not\n  supported, Libevent just loads the data.\n\n  There are probably some bugs remaining in this code.  On some platforms\n  (like Windows), it just reads the relevant parts of the file into RAM.\n\n4.4. Support for zero-copy (\"scatter/gather\") writes in evbuffers.\n\n  You can add a piece of memory to an evbuffer without copying it.\n  Instead, Libevent adds a new element to the evbuffer's linked list of\n  chunks with a pointer to the memory you supplied.  You can do this\n  either with a reference-counted chunk (via evbuffer_add_reference), or\n  by asking Libevent for a pointer to its internal vectors (via\n  evbuffer_reserve_space or evbuffer_peek()).\n\n4.5. Multiple callbacks per evbuffer\n\n  Previously, you could only have one callback active on an evbuffer at a\n  time.  In practice, this meant that if one part of Libevent was using an\n  evbuffer callback to notice when an internal evbuffer was reading or\n  writing data, you couldn't have your own callback on that evbuffer.\n\n  Now, you can now use the evbuffer_add_cb() function to add a callback that\n  does not interfere with any other callbacks.\n\n  The evbuffer_setcb() function is now deprecated.\n\n4.6. New callback interface\n\n  Previously, evbuffer callbacks were invoked with the old size of the\n  buffer and the new size of the buffer.  This interface could not capture\n  operations that simultaneously filled _and_ drained a buffer, or handle\n  cases where we needed to postpone callbacks until multiple operations were\n  complete.\n\n  Callbacks that are set with evbuffer_setcb still use the old API.\n  Callbacks added with evbuffer_add_cb() use a new interface that takes a\n  pointer to a struct holding the total number of bytes drained read and the\n  total number of bytes written.  See event2/buffer.h for full details.\n\n4.7. Misc new evbuffer features\n\n   You can use evbuffer_remove() to move a given number of bytes from one\n   buffer to another.\n\n   The evbuffer_search() function lets you search for repeated instances of\n   a pattern inside an evbuffer.\n\n   You can use evbuffer_freeze() to temporarily suspend drains from or adds\n   to a given evbuffer.  This is useful for code that exposes an evbuffer as\n   part of its public API, but wants users to treat it as a pure source or\n   sink.\n\n   There's an evbuffer_copyout() that looks at the data at the start of an\n   evbuffer without doing a drain.\n\n   You can have an evbuffer defer all of its callbacks, so that rather than\n   being invoked immediately when the evbuffer's length changes, they are\n   invoked from within the event_loop.  This is useful when you have a\n   complex set of callbacks that can change the length of other evbuffers,\n   and you want to avoid having them recurse and overflow your stack.\n\n5. Bufferevents improvements\n\n   Libevent has long included a \"bufferevents\" structure and related\n   functions that were useful for generic buffered IO on a TCP connection.\n   This is what Libevent uses for its HTTP implementation.  In addition to\n   the improvements that they get for free from the underlying evbuffer\n   implementation above, there are many new features in Libevent 2.0's\n   evbuffers.\n\n5.1. New OO implementations\n\n   The \"bufferevent\" structure is now an abstract base type with multiple\n   implementations.  This should not break existing code, which always\n   allocated bufferevents with bufferevent_new().\n\n   Current implementations of the bufferevent interface are described below.\n\n5.2. bufferevent_socket_new() replaces bufferevent_new()\n\n   Since bufferevents that use a socket are not the only kind,\n   bufferevent_new() is now deprecated.  Use bufferevent_socket_new()\n   instead.\n\n5.3. Filtered bufferevent IO\n\n   You can use bufferevent_filter_new() to create a bufferevent that wraps\n   around another bufferevent and transforms data it is sending and\n   receiving.  See test/regress_zlib.c for a toy example that uses zlib to\n   compress data before sending it over a bufferevent.\n\n5.3. Linked pairs of bufferevents\n\n   You can use bufferevent_pair_new() to produce two linked\n   bufferevents.  This is like using socketpair, but doesn't require\n   system-calls.\n\n5.4. SSL support for bufferevents with OpenSSL\n\n   There is now a bufferevent type that supports SSL/TLS using the\n   OpenSSL library.  The code for this is build in a separate\n   library, libevent_openssl, so that your programs don't need to\n   link against OpenSSL unless they actually want SSL support.\n\n   There are two ways to construct one of these bufferevents, both\n   declared in <event2/bufferevent_ssl.h>.  If you want to wrap an\n   SSL layer around an existing bufferevent, you would call the\n   bufferevent_openssl_filter_new() function.  If you want to do SSL\n   on a socket directly, call bufferevent_openssl_socket_new().\n\n5.5. IOCP support for bufferevents on Windows\n\n   There is now a bufferevents backend that supports IOCP on Windows.\n   Supposedly, this will eventually make Windows IO much faster for\n   programs using bufferevents.  We'll have to see; the code is not\n   currently optimized at all.  To try it out, call the\n   event_base_start_iocp() method on an event_base before contructing\n   bufferevents.\n\n   This is tricky code; there are probably some bugs hiding here.\n\n5.6. Improved connect support for bufferevents.\n\n   You can now create a bufferevent that is not yet connected to any\n   host, and tell it to connect, either by address or by hostname.\n\n   The functions to do this are bufferevent_socket_connect and\n   bufferevent_socket_connect_hostname.\n\n5.7. Rate-limiting for bufferevents\n\n   If you need to limit the number of bytes read/written by a single\n   bufferevent, or by a group of them, you can do this with a new set of\n   bufferevent rate-limiting calls.\n\n6. Other improvements\n\n6.1. DNS improvements\n\n6.1.1. DNS: IPv6 nameservers\n\n   The evdns code now lets you have nameservers whose addresses are IPv6.\n\n6.1.2. DNS: Better security\n\n   Libevent 2.0 tries harder to resist DNS answer-sniping attacks than\n   earlier versions of evdns.  See comments in the code for full details.\n\n   Notably, evdns now supports the \"0x20 hack\" to make it harder to\n   impersonate a DNS server.  Additionally, Libevent now uses a strong\n   internal RNG to generate DNS transaction IDs, so you don't need to supply\n   your own.\n\n6.1.3. DNS: Getaddrinfo support\n\n   There's now an asynchronous getaddrinfo clone, evdns_getaddrinfo(),\n   to make the results of the evdns functions more usable.  It doesn't\n   support every feature of a typical platform getaddrinfo() yet, but it\n   is quite close.\n\n   There is also a blocking evutil_getaddrinfo() declared in\n   event2/util.h, to provide a getaddrinfo() implementation for\n   platforms that don't have one, and smooth over the differences in\n   various platforms implementations of RFC3493.\n\n   Bufferevents provide bufferevent_connect_hostname(), which combines\n   the name lookup and connect operations.\n\n6.1.4. DNS: No more evdns globals\n\n   Like an event base, evdns operations are now supposed to use an evdns_base\n   argument.  This makes them easier to wrap for other (more OO) languages,\n   and easier to control the lifetime of.  The old evdns functions will\n   still, of course, continue working.\n\n6.2. Listener support\n\n   You can now more easily automate setting up a bound socket to listen for\n   TCP connections.  Just use the evconnlistener_*() functions in the\n   event2/listener.h header.\n\n   The listener code supports IOCP on Windows if available.\n\n6.3. Secure RNG support\n\n   Network code very frequently needs a secure, hard-to-predict random number\n   generator.  Some operating systems provide a good C implementation of one;\n   others do not.  Libevent 2.0 now provides a consistent implementation\n   based on the arc4random code originally from OpenBSD.  Libevent (and you)\n   can use the evutil_secure_rng_*() functions to access a fairly secure\n   random stream of bytes.\n\n6.4. HTTP\n\n   The evhttp uriencoding and uridecoding APIs have updated versions\n   that behave more correctly, and can handle strings with internal NULs.\n\n   The evhttp query parsing and URI parsing logic can now detect errors\n   more usefully.  Moreover, we include an actual URI parsing function\n   (evhttp_uri_parse()) to correctly parse URIs, so as to discourage\n   people from rolling their own ad-hoc parsing functions.\n\n   There are now accessor functions for the useful fields of struct http\n   and friends; it shouldn't be necessary to access them directly any\n   more.\n\n   Libevent now lets you declare support for all specified HTTP methods,\n   including OPTIONS, PATCH, and so on.  The default list is unchanged.\n\n   Numerous evhttp bugs also got fixed.\n\n7. Infrastructure improvements\n\n7.1. Better unit test framework\n\n   We now use a unit test framework that Nick wrote called \"tinytest\".\n   The main benefit from Libevent's point of view is that tests which\n   might mess with global state can all run each in their own\n   subprocess.  This way, when there's a bug that makes one unit test\n   crash or mess up global state, it doesn't affect any others.\n\n7.2. Better unit tests\n\n   Despite all the code we've added, our unit tests are much better than\n   before.  Right now, iterating over the different backends on various\n   platforms, I'm getting between 78% and 81% test coverage, compared\n   with less than 45% test coverage in Libevent 1.4.\n\n"
        },
        {
          "name": "whatsnew-2.1.txt",
          "type": "blob",
          "size": 32.603515625,
          "content": "                         What's new in Libevent 2.1\n                             Nick Mathewson\n\n0. Before we start\n\n0.1. About this document\n\n  This document describes the key differences between Libevent 2.0 and\n  Libevent 2.1, from a user's point of view.  It's a work in progress.\n\n  For better documentation about libevent, see the links at\n  http://libevent.org/\n\n  Libevent 2.1 would not be possible without the generous help of\n  numerous volunteers.  For a list of who did what in Libevent 2.1,\n  please see the ChangeLog!\n\n  NOTE: I am very sure that I missed some thing on this list.  Caveat\n  haxxor.\n\n0.2. Where to get help\n\n  Try looking at the other documentation too.  All of the header files\n  have documentation in the doxygen format; this gets turned into nice\n  HTML and linked to from the libevent.org website.\n\n  There is a work-in-progress book with reference manual at\n  http://www.wangafu.net/~nickm/libevent-book/ .\n\n  You can ask questions on the #libevent IRC channel at irc.oftc.net or\n  on the mailing list at libevent-users@freehaven.net.  The mailing list\n  is subscribers-only, so you will need to subscribe before you post.\n\n0.3. Compatibility\n\n  Our source-compatibility policy is that correct code (that is to say,\n  code that uses public interfaces of Libevent and relies only on their\n  documented behavior) should have forward source compatibility: any\n  such code that worked with a previous version of Libevent should work\n  with this version too.\n\n  We don't try to do binary compatibility except within stable release\n  series, so binaries linked against any version of Libevent 2.0 will\n  probably need to be recompiled against Libevent 2.1.4-alpha if you\n  want to use it.  It is probable that we'll break binary compatibility\n  again before Libevent 2.1 is stable.\n\n1. New APIs and features\n\n1.1. New ways to build libevent\n\n  We now provide an --enable-gcc-hardening configure option to turn on\n  GCC features designed for increased code security.\n\n  There is also an --enable-silent-rules configure option to make\n  compilation run more quietly with automake 1.11 or later.\n\n  You no longer need to use the --enable-gcc-warnings option to turn on\n  all of the GCC warnings that Libevent uses.  The only change from\n  using that option now is to turn warnings into errors.\n\n  For IDE users, files that are not supposed to be built are now\n  surrounded with appropriate #ifdef lines to keep your IDE from getting\n  upset.\n\n  There is now an alternative cmake-based build process; cmake users\n  should see the relevant sections in the README.\n\n\n1.2. New functions for events and the event loop\n\n  If you're running Libevent with multiple event priorities, you might\n  want to make sure that Libevent checks for new events frequently, so\n  that time-consuming or numerous low-priority events don't keep it from\n  checking for new high-priority events.  You can now use the\n  event_config_set_max_dispatch_interval() interface to ensure that the\n  loop checks for new events either every N microseconds, every M\n  callbacks, or both.\n\n  When configuring an event base, you can now choose whether you want\n  timers to be more efficient, or more precise.  (This only has effect\n  on Linux for now.)  Timers are efficient by default: to select more\n  precise timers, use the EVENT_BASE_FLAG_PRECISE_TIMER flag when\n  constructing the event_config, or set the EVENT_PRECISE_TIMER\n  environment variable to a non-empty string.\n\n  There is an EVLOOP_NO_EXIT_ON_EMPTY flag that tells event_base_loop()\n  to keep looping even when there are no pending events.  (Ordinarily,\n  event_base_loop() will exit as soon as no events are pending.)\n\n  Past versions of Libevent have been annoying to use with some\n  memory-leak-checking tools, because Libevent allocated some global\n  singletons but provided no means to free them.  There is now a\n  function, libevent_global_shutdown(), that you can use to free all\n  globally held resources before exiting, so that your leak-check tools\n  don't complain.  (Note: this function doesn't free non-global things\n  like events, bufferevents, and so on; and it doesn't free anything\n  that wouldn't otherwise get cleaned up by the operating system when\n  your process exit()s.  If you aren't using a leak-checking tool, there\n  is not much reason to call libevent_global_shutdown().)\n\n  There is a new event_base_get_npriorities() function to return the\n  number of priorities set in the event base.\n\n  Libevent 2.0 added an event_new() function to construct a new struct\n  event on the heap.  Unfortunately, with event_new(), there was no\n  equivalent for:\n\n         struct event ev;\n         event_assign(&ev, base, fd, EV_READ, callback, &ev);\n\n  In other words, there was no easy way for event_new() to set up an\n  event so that the event itself would be its callback argument.\n  Libevent 2.1 lets you do this by passing \"event_self_cbarg()\" as the\n  callback argument:\n\n         struct event *evp;\n         evp = event_new(base, fd, EV_READ, callback,\n         event_self_cbarg());\n\n  There's also a new event_base_get_running_event() function you can\n  call from within a Libevent callback to get a pointer to the current\n  event.  This should never be strictly necessary, but it's sometimes\n  convenient.\n\n  The event_base_once() function used to leak some memory if the event\n  that it added was never actually triggered.  Now, its memory is\n  tracked in the event_base and freed when the event_base is freed.\n  Note however that Libevent doesn't know how to free any information\n  passed as the callback argument to event_base_once is still something\n  you'll might need a way to de-allocate yourself.\n\n  There is an event_get_priority() function to return an event's\n  priority.\n\n  By analogy to event_base_loopbreak(), there is now an\n  event_base_loopcontinue() that tells Libevent to stop processing\n  active event callbacks, and re-scan for new events right away.\n\n  There's a function, event_base_foreach_event(), that can iterate over\n  every event currently pending or active on an event base, and invoke a\n  user-supplied callback on each. The callback must not alter the events\n  or add or remove anything to the event base.\n\n  We now have an event_remove_timer() function to remove the timeout on\n  an event while leaving its socket and/or signal triggers unchanged.\n  (If we were designing the API from scratch, this would be the behavior\n  of \"event_add(ev, NULL)\" on an already-added event with a timeout. But\n  that's a no-op in past versions of Libevent, and we don't want to\n  break compatibility.)\n\n  You can use the new event_base_get_num_events() function to find the\n  number of events active or pending on an event_base. To find the\n  largest number of events that there have been since the last call, use\n  event_base_get_max_events().\n\n  You can now activate all the events waiting for a given fd or signal\n  using the event_base_active_by_fd() and event_base_active_by_signal()\n  APIs.\n\n  On backends that support it (currently epoll), there is now an\n  EV_CLOSED flag that programs can use to detect when a socket has\n  closed without having to read all the bytes until receiving an EOF.\n\n1.3. Event finalization\n\n1.3.1. Why event finalization?\n\n  Libevent 2.1 now supports an API for safely \"finalizing\" events that\n  might be running in multiple threads, and provides a way to slightly\n  change the semantics of event_del() to prevent deadlocks in\n  multithreaded programs.\n\n  To motivate this feature, consider the following code, in the context\n  of a mulithreaded Libevent application:\n\n        struct connection *conn = event_get_callback_arg(ev);\n        event_del(ev);\n        connection_free(conn);\n\n  Suppose that the event's callback might be running in another thread,\n  and using the value of \"conn\" concurrently.  We wouldn't want to\n  execute the connection_free() call until \"conn\" is no longer in use.\n  How can we make this code safe?\n\n  Libevent 2.0 answered that question by saying that the event_del()\n  call should block if the event's callback is running in another\n  thread.  That way, we can be sure that event_del() has canceled the\n  callback (if the callback hadn't started running yet), or has waited\n  for the callback to finish.\n\n  But now suppose that the data structure is protected by a lock, and we\n  have the following code:\n\n        void check_disable(struct connection *connection) {\n            lock(connection);\n            if (should_stop_reading(connection))\n                    event_del(connection->read_event);\n            unlock(connection);\n        }\n\n  What happens when we call check_disable() from a callback and from\n  another thread?  Let's say that the other thread gets the lock\n  first.  If it decides to call event_del(), it will wait for the\n  callback to finish.  But meanwhile, the callback will be waiting for\n  the lock on the connection.  Since each threads is waiting for the\n  other one to release a resource, the program will deadlock.\n\n  This bug showed up in multithreaded bufferevent programs in 2.1,\n  particularly when freeing bufferevents.  (For more information, see\n  the \"Deadlock when calling bufferevent_free from an other thread\"\n  thread on libevent-users starting on 6 August 2012 and running through\n  February of 2013.  You might also like to read my earlier writeup at\n  http://archives.seul.org/libevent/users/Feb-2012/msg00053.html and\n  the ensuing discussion.)\n\n1.3.2. The EV_FINALIZE flag and avoiding deadlock\n\n  To prevent the deadlock condition described above, Libevent\n  2.1.3-alpha adds a new flag, \"EV_FINALIZE\".  You can pass it to\n  event_new() and event_assign() along with EV_READ, EV_WRITE, and the\n  other event flags.\n\n  When an event is constructed with the EV_FINALIZE flag, event_del()\n  will not block on that event, even when the event's callback is\n  running in another thread.  By using EV_FINALIZE, you are therefore\n  promising not to use the \"event_del(ev); free(event_get_callback_arg(ev));\"\n  pattern, but rather to use one of the finalization functions below to\n  clean up the event.\n\n  EV_FINALIZE has no effect on a single-threaded program, or on a\n  program where events are only used from one thread.\n\n\n  There are also two new variants of event_del() that you can use for\n  more fine-grained control:\n     event_del_noblock(ev)\n     event_del_block(ev)\n  The event_del_noblock() function will never block, even if the event\n  callback is running in another thread and doesn't have the EV_FINALIZE\n  flag.  The event_del_block() function will _always_ block if the event\n  callback is running in another thread, even if the event _does_ have\n  the EV_FINALIZE flag.\n\n  [A future version of Libevent may have a way to make the EV_FINALIZE\n  flag the default.]\n\n1.3.3. Safely finalizing events\n\n  To safely tear down an event that may be running, Libevent 2.1.3-alpha\n  introduces event_finalize() and event_free_finalize(). You call them\n  on an event, and provide a finalizer callback to be run on the event\n  and its callback argument once the event is definitely no longer\n  running.\n\n  With event_free_finalize(), the event is also freed once the finalizer\n  callback has been invoked.\n\n  A finalized event cannot be re-added or activated.  The finalizer\n  callback must not add events, activate events, or attempt to\n  \"resucitate\" the event being finalized in any way.\n\n  If any finalizer callbacks are pending as the event_base is being\n  freed, they will be invoked.  You can override this behavior with the\n  new function event_base_free_nofinalize().\n\n1.4. New debugging features\n\n  You can now turn on debug logs at runtime using a new function,\n  event_enable_debug_logging().\n\n  The event_enable_lock_debugging() function is now spelled correctly.\n  You can still use the old \"event_enable_lock_debuging\" name, though,\n  so your old programs shouldn't break.\n\n  There's also been some work done to try to make the debugging logs\n  more generally useful.\n\n1.5. New evbuffer functions\n\n  In Libevent 2.0, we introduced evbuffer_add_file() to add an entire\n  file's contents to an evbuffer, and then send them using sendfile() or\n  mmap() as appropriate.  This API had some drawbacks, however.\n  Notably, it created one mapping or fd for every instance of the same\n  file added to any evbuffer.  Also, adding a file to an evbuffer could\n  make that buffer unusable with SSL bufferevents, filtering\n  bufferevents, and any code that tried to read the contents of the\n  evbuffer.\n\n  Libevent 2.1 adds a new evbuffer_file_segment API to solve these\n  problems.  Now, you can use evbuffer_file_segment_new() to construct a\n  file-segment object, and evbuffer_add_file_segment() to insert it (or\n  part of it) into an evbuffer.  These segments avoid creating redundant\n  maps or fds.  Better still, the code is smart enough (when the OS\n  supports sendfile) to map the file when that's necessary, and use\n  sendfile() otherwise.\n\n  File segments can receive callback functions that are invoked when the\n  file segments are freed.\n\n  The evbuffer_ptr interface has been extended so that an evbuffer_ptr\n  can now yield a point just after the end of the buffer.  This makes\n  many algorithms simpler to implement.\n\n  There's a new evbuffer_add_buffer() interface that you can use to add\n  one buffer to another nondestructively.  When you say\n  evbuffer_add_buffer_reference(outbuf, inbuf), outbuf now contains a\n  reference to the contents of inbuf.\n\n  To aid in adding data in bulk while minimizing evbuffer calls, there\n  is an evbuffer_add_iovec() function.\n\n  There's a new evbuffer_copyout_from() variant function to enable\n  copying data nondestructively from the middle of a buffer.\n\n  evbuffer_readln() now supports an EVBUFFER_EOL_NUL argument to fetch\n  NUL-terminated strings from buffers.\n\n  There's a new evbuffer_set_flags()/evbuffer_clear_flags() that you can use to\n  set EVBUFFER_FLAG_DRAINS_TO_FD.\n\n1.6. New functions and features: bufferevents\n\n  You can now use the bufferevent_getcb() function to find out a\n  bufferevent's callbacks.  Previously, there was no supported way to do\n  that.\n\n  The largest chunk readable or writeable in a single bufferevent\n  callback is no longer hardcoded; it's now configurable with\n  the new functions bufferevent_set_max_single_read() and\n  bufferevent_set_max_single_write().\n\n  For consistency, OpenSSL bufferevents now make sure to always set one\n  of BEV_EVENT_READING or BEV_EVENT_WRITING when invoking an event\n  callback.\n\n  Calling bufferevent_set_timeouts(bev, NULL, NULL) now removes the\n  timeouts from socket and ssl bufferevents correctly.\n\n  You can find the priority at which a bufferevent runs with\n  bufferevent_get_priority().\n\n  The function bufferevent_get_token_bucket_cfg() can retrieve the\n  rate-limit settings for a bufferevent; bufferevent_getwatermark() can\n  return a bufferevent's current watermark settings.\n\n  You can manually trigger a bufferevent's callbacks via\n  bufferevent_trigger() and bufferevent_trigger_event().\n\n  Also you can manually increment/decrement reference for bufferevent with\n  bufferevent_incref()/bufferevent_decref(), it is useful in situations where a\n  user may reference the bufferevent somewhere else.\n\n  Now bufferevent_openssl supports \"dirty\" shutdown (when the peer closes the\n  TCP connection before closing the SSL channel), see\n  bufferevent_openssl_get_allow_dirty_shutdown() and\n  bufferevent_openssl_set_allow_dirty_shutdown().\n\n  And also libevent supports openssl 1.1.\n\n1.7. New functions and features: evdns\n\n  The previous evdns interface used an \"open a test UDP socket\" trick in\n  order to detect IPv6 support.  This was a hack, since it would\n  sometimes badly confuse people's firewall software, even though no\n  packets were sent.  The current evdns interface-detection code uses\n  the appropriate OS functions to see which interfaces are configured.\n\n  The evdns_base_new() function now has multiple possible values for its\n  second (flags) argument.  Using 1 and 0 have their old meanings, though the\n  1 flag now has a symbolic name of EVDNS_BASE_INITIALIZE_NAMESERVERS.\n  A second flag is now supported too: the EVDNS_BASE_DISABLE_WHEN_INACTIVE\n  flag, which tells the evdns_base that it should not prevent Libevent from\n  exiting while it has no DNS requests in progress.\n\n  There is a new evdns_base_clear_host_addresses() function to remove\n  all the /etc/hosts addresses registered with an evdns instance.\n\n  Also there is evdns_base_get_nameserver_addr() for retrieve the address of\n  the 'idx'th configured nameserver.\n\n1.8. New functions and features: evconnlistener\n\n  Libevent 2.1 adds the following evconnlistener flags:\n\n    LEV_OPT_DEFERRED_ACCEPT -- Tells the OS that it doesn't need to\n    report sockets as having arrived until the initiator has sent some\n    data too.  This can greatly improve performance with protocols like\n    HTTP where the client always speaks first.  On operating systems\n    that don't support this functionality, this option has no effect.\n\n    LEV_OPT_REUSEABLE_PORT -- Indicates that we ask to allow multiple servers\n    to bind to the same port if they each set the option Ionly on Linux and\n    >=3.9)\n\n    LEV_OPT_DISABLED -- Creates an evconnlistener in the disabled (not\n    listening) state.\n\n  Libevent 2.1 changes the behavior of the LEV_OPT_CLOSE_ON_EXEC\n  flag.  Previously, it would apply to the listener sockets, but not to\n  the accepted sockets themselves.  That's almost never what you want.\n  Now, it applies both to the listener and the accepted sockets.\n\n1.9. New functions and features: evhttp\n\n  **********************************************************************\n  NOTE: The evhttp module will eventually be deprecated in favor of Mark\n  Ellzey's libevhtp library.  Don't worry -- this won't happen until\n  libevhtp provides every feature that evhttp does, and provides a\n  compatible interface that applications can use to migrate.\n  **********************************************************************\n\n  Previously, you could only set evhttp timeouts in increments of one\n  second.  Now, you can use evhttp_set_timeout_tv() and\n  evhttp_connection_set_timeout_tv() to configure\n  microsecond-granularity timeouts.\n\n  Also there is evhttp_connection_set_initial_retry_tv() to change initial\n  retry timeout.\n\n  There are a new pair of functions: evhttp_set_bevcb() and\n  evhttp_connection_base_bufferevent_new(), that you can use to\n  configure which bufferevents will be used for incoming and outgoing\n  http connections respectively.  These functions, combined with SSL\n  bufferevents, should enable HTTPS support.\n\n  There's a new evhttp_foreach_bound_socket() function to iterate over\n  every listener on an evhttp object.\n\n  Whitespace between lines in headers is now folded into a single space;\n  whitespace at the end of a header is now removed.\n\n  The socket errno value is now preserved when invoking an http error\n  callback.\n\n  There's a new kind of request callback for errors; you can set it with\n  evhttp_request_set_error_cb(). It gets called when there's a request error,\n  and actually reports the error code and lets you figure out which request\n  failed.\n\n  You can navigate from an evhttp_connection back to its evhttp with the\n  new evhttp_connection_get_server() function.\n\n  You can override the default HTTP Content-Type with the new\n  evhttp_set_default_content_type() function\n\n  There's a new evhttp_connection_get_addr() API to return the peer\n  address of an evhttp_connection.\n\n  The new evhttp_send_reply_chunk_with_cb() is a variant of\n  evhttp_send_reply_chunk() with a callback to be invoked when the\n  chunk is sent.\n\n  The evhttp_request_set_header_cb() facility adds a callback to be\n  invoked while parsing headers.\n\n  The evhttp_request_set_on_complete_cb() facility adds a callback to be\n  invoked on request completion.\n\n  You can add linger-close for http server by passing\n  EVHTTP_SERVER_LINGERING_CLOSE to evhttp_set_flags(), with this flag server\n  read all the clients body, and only after this respond with an error if the\n  clients body exceed max_body_size (since some clients cannot read response\n  otherwise).\n\n  The evhttp_connection_set_family() can bypass family hint to evdns.\n\n  There are some flags available for connections, which can be installed with\n  evhttp_connection_set_flags():\n  - EVHTTP_CON_REUSE_CONNECTED_ADDR -- reuse connection address on retry (avoid\n    extra DNS request).\n  - EVHTTP_CON_READ_ON_WRITE_ERROR - try read error, since server may already\n    close the connection.\n\n  The evhttp_connection_free_on_completion() can be used to tell libevent to\n  free the connection object after the last request has completed or failed.\n\n  There is evhttp_request_get_response_code_line() if\n  evhttp_request_get_response_code() is not enough for you.\n\n  There are *evhttp_uri_parse_with_flags() that accepts\n  EVHTTP_URI_NONCONFORMANT to tolerate URIs that do not conform to RFC3986.\n  The evhttp_uri_set_flags() can changes the flags on URI.\n\n1.10. New functions and features: evutil\n\n  There's a function \"evutil_secure_rng_set_urandom_device_file()\" that\n  you can use to override the default file that Libevent uses to seed\n  its (sort-of) secure RNG.\n\n  The evutil_date_rfc1123() returns date in RFC1123\n\n  There are new API to work with monotonic timer -- monotonic time is\n  guaranteed never to run in reverse, but is not necessarily epoch-based. Use\n  it to make reliable measurements of elapsed time between events even when the\n  system time may be changed:\n  - evutil_monotonic_timer_new()/evutil_monotonic_timer_free()\n  - evutil_configure_monotonic_time()\n  - evutil_gettime_monotonic()\n\n  Use evutil_make_listen_socket_reuseable_port() to set SO_REUSEPORT (linux >=\n  3.9)\n\n  The evutil_make_tcp_listen_socket_deferred() can make a tcp listener socket\n  defer accept()s until there is data to read (TCP_DEFER_ACCEPT).\n\n2. Cross-platform performance improvements\n\n2.1. Better data structures\n\n  We replaced several users of the sys/queue.h \"TAILQ\" data structure\n  with the \"LIST\" data structure.  Because this data type doesn't\n  require FIFO access, it requires fewer pointer checks and\n  manipulations to keep it in line.\n\n  All previous versions of Libevent have kept every pending (added)\n  event in an \"eventqueue\" data structure.  Starting in Libevent 2.0,\n  however, this structure became redundant: every pending timeout event\n  is stored in the timeout heap or in one of the common_timeout queues,\n  and every pending fd or signal event is stored in an evmap.  Libevent\n  2.1 removes this data structure, and thereby saves all of the code\n  that we'd been using to keep it updated.\n\n2.2. Faster activations and timeouts\n\n  It's a common pattern in older code to use event_base_once() with a\n  0-second timeout to ensure that a callback will get run 'as soon as\n  possible' in the current iteration of the Libevent loop.  We optimize\n  this case by calling event_active() directly, and bypassing the\n  timeout pool.  (People who are using this pattern should also consider\n  using event_active() themselves.)\n\n  Libevent 2.0 would wake up a polling event loop whenever the first\n  timeout in the event loop was adjusted--whether it had become earlier\n  or later.  We now only notify the event loop when a change causes the\n  expiration time to become _sooner_ than it would have been otherwise.\n\n  The timeout heap code is now optimized to perform fewer comparisons\n  and shifts when changing or removing a timeout.\n\n  Instead of checking for a wall-clock time jump every time we call\n  clock_gettime(), we now check only every 5 seconds.  This should save\n  a huge number of gettimeofday() calls.\n\n2.3. Microoptimizations\n\n  Internal event list maintainance no longer use the antipattern where\n  we have one function with multiple totally independent behaviors\n  depending on an argument:\n      #define OP1 1\n      #define OP2 2\n      #define OP3 3\n      void func(int operation, struct event *ev) {\n        switch (op) {\n          ...\n        }\n      }\n  Instead, these functions are now split into separate functions for\n  each operation:\n      void func_op1(struct event *ev) { ... }\n      void func_op2(struct event *ev) { ... }\n      void func_op3(struct event *ev) { ... }\n\n  This produces better code generation and inlining decisions on some\n  compilers, and makes the code easier to read and check.\n\n2.4. Evbuffer performance improvements\n\n  The EVBUFFER_EOL_CRLF line-ending type is now much faster, thanks to\n  smart optimizations.\n\n2.5. HTTP performance improvements\n\n   o Performance tweak to evhttp_parse_request_line. (aee1a97 Mark Ellzey)\n   o Add missing break to evhttp_parse_request_line (0fcc536)\n\n2.6. Coarse timers by default on Linux\n\n  Due to limitations of the epoll interface, Libevent programs using epoll\n  have not previously been able to wait for timeouts with accuracy smaller\n  than 1 millisecond.  But Libevent had been using CLOCK_MONOTONIC for\n  timekeeping on Linux, which is needlessly expensive: CLOCK_MONOTONIC_COARSE\n  has approximately the resolution corresponding to epoll, and is much faster\n  to invoke than CLOCK_MONOTONIC.\n\n  To disable coarse timers, and get a more plausible precision, use the\n  new EVENT_BASE_FLAG_PRECISE_TIMER flag when setting up your event base.\n\n3. Backend/OS-specific improvements\n\n3.1. Linux-specific improvements\n\n  The logic for deciding which arguments to use with epoll_ctl() is now\n  a table-driven lookup, rather than the previous pile of cascading\n  branches.  This should minimize epoll_ctl() calls and make the epoll\n  code run a little faster on change-heavy loads.\n\n  Libevent now takes advantage of Linux's support for enhanced APIs\n  (e.g., SOCK_CLOEXEC, SOCK_NONBLOCK, accept4, pipe2) that allow us to\n  simultaneously create a socket, make it nonblocking, and make it\n  close-on-exec.  This should save syscalls throughout our codebase, and\n  avoid race-conditions if an exec() occurs after a socket is socket is\n  created but before we can make it close-on-execute on it.\n\n3.2. Windows-specific improvements\n\n  We now use GetSystemTimeAsFileTime to implement gettimeofday.  It's\n  significantly faster and more accurate than our old ftime()-based approach.\n\n3.3. Improvements in the solaris evport backend.\n\n  The evport backend has been updated to use many of the infrastructure\n  improvements from Libevent 2.0.  Notably, it keeps track of per-fd\n  information using the evmap infrastructure, and removes a number of\n  linear scans over recently-added events.  This last change makes it\n  efficient to receive many more events per evport_getn() call, thereby\n  reducing evport overhead in general.\n\n3.4. OSX backend improvements\n\n  The OSX select backend doesn't like to have more than a certain number\n  of fds set unless an \"unlimited select\" option has been set.\n  Therefore, we now set it.\n\n3.5. Monotonic clocks on even more platforms\n\n  Libevent previously used a monotonic clock for its internal timekeeping\n  only on platforms supporting the POSIX clock_gettime() interface. Now,\n  Libevent has support for monotonic clocks on OSX and Windows too, and a\n  fallback implementation for systems without monotonic clocks that will at\n  least keep time running forwards.\n\n  Using monotonic timers makes Libevent more resilient to changes in the\n  system time, as can happen in small amounts due to clock adjustments from\n  NTP, or in large amounts due to users who move their system clocks all over\n  the timeline in order to keep nagware from nagging them.\n\n3.6. Faster cross-thread notification on kqueue\n\n  When a thread other than the one in which the main event loop is\n  running needs to wake the thread running the main event loop, Libevent\n  usually writes to a socketpair in order to force the main event loop\n  to wake up.  On Linux, we've been able to use eventfd() instead.  Now\n  on BSD and OSX systems (any anywhere else that has kqueue with the\n  EVFILT_USER extension), we can use EVFILT_USER to wake up the main\n  thread from kqueue.  This should be a tiny bit faster than the\n  previous approach.\n\n4. Infrastructure improvements\n\n4.1. Faster tests\n\n  I've spent some time to try to make the unit tests run faster in\n  Libevent 2.1.  Nearly all of this was a matter of searching slow tests\n  for unreasonably long timeouts, and cutting them down to reasonably\n  long delays, though on one or two cases I actually had to parallelize\n  an operation or improve an algorithm.\n\n  On my desktop, a full \"make verify\" run of Libevent 2.0.18-stable\n  requires about 218 seconds.  Libevent 2.1.1-alpha cuts this down to\n  about 78 seconds.\n\n  Faster unit tests are great, since they let programmers test their\n  changes without losing their train of thought.\n\n4.2. Finicky tests are now off-by-default\n\n  The Tinytest unit testing framework now supports optional tests, and\n  Libevent uses them.  By default, Libevent's unit testing framework\n  does not run tests that require a working network, and does not run\n  tests that tend to fail on heavily loaded systems because of timing\n  issues.  To re-enable all tests, run ./test/regress using the \"@all\"\n  alias.\n\n4.3. Modernized use of autotools\n\n  Our autotools-based build system has been updated to build without\n  warnings on recent autoconf/automake versions.\n\n  Libevent's autotools makefiles are no longer recursive.  This allows\n  make to use the maximum possible parallelism to do the minimally\n  necessary amount of work.  See Peter Miller's \"Recursive Make\n  Considered Harmful\" at http://miller.emu.id.au/pmiller/books/rmch/ for\n  more information here.\n\n  We now use the \"quiet build\" option to suppress distracting messages\n  about which commandlines are running.  You can get them back with\n  \"make V=1\".\n\n4.4. Portability\n\n  Libevent now uses large-file support internally on platforms where it\n  matters.  You shouldn't need to set _LARGEFILE or OFFSET_BITS or\n  anything magic before including the Libevent headers, either, since\n  Libevent now sets the size of ev_off_t to the size of off_t that it\n  received at compile time, not to some (possibly different) size based\n  on current macro definitions when your program is building.\n\n  We now also use the Autoconf AC_USE_SYSTEM_EXTENSIONS mechanism to\n  enable per-system macros needed to enable not-on-by-default features.\n  Unlike the rest of the autoconf macros, we output these to an\n  internal-use-only evconfig-private.h header, since their names need to\n  survive unmangled.  This lets us build correctly on more platforms,\n  and avoid inconsistencies when some files define _GNU_SOURCE and\n  others don't.\n\n  Libevent now tries to detect OpenSSL via pkg-config.\n\n4.5. Standards conformance\n\n  Previous Libevent versions had no consistent convention for internal\n  vs external identifiers, and used identifiers starting with the \"_\"\n  character throughout the codebase.  That's no good, since the C\n  standard says that identifiers beginning with _ are reserved.  I'm not\n  aware of having any collisions with system identifiers, but it's best\n  to fix these things before they cause trouble.\n\n  We now avoid all use of the _identifiers in the Libevent source code.\n  These changes were made *mainly* through the use of automated scripts,\n  so there shouldn't be any mistakes, but you never know.\n\n  As an exception, the names _EVENT_LOG_DEBUG, _EVENT_LOG_MSG_,\n  _EVENT_LOG_WARN, and _EVENT_LOG_ERR are still exposed in event.h: they\n  are now deprecated, but to support older code, they will need to stay\n  around for a while.  New code should use EVENT_LOG_DEBUG,\n  EVENT_LOG_MSG, EVENT_LOG_WARN, and EVENT_LOG_ERR instead.\n\n4.6. Event and callback refactoring\n\n  As a simplification and optimization to Libevent's \"deferred callback\"\n  logic (introduced in 2.0 to avoid callback recursion), Libevent now\n  treats all of its deferrable callback types using the same logic it\n  uses for active events.  Now deferred events no longer cause priority\n  inversion, no longer require special code to cancel them, and so on.\n\n  Regular events and deferred callbacks now both descend from an\n  internal light-weight event_callback supertype, and both support\n  priorities and take part in the other anti-priority-inversion\n  mechanisms in Libevent.\n\n  To avoid starvation from callback recursion (which was the reason we\n  introduced \"deferred callbacks\" in the first place) the implementation\n  now allows an event callback to be scheduled as \"active later\":\n  instead of running in the current iteration of the event loop, it runs\n  in the next one.\n\n5. Testing\n\n  Libevent's test coverage level is more or less unchanged since before:\n  we still have over 80% line coverage in our tests on Linux, FreeBSD, NetBSD,\n  Windows, OSX.\n  There are some under-tested modules, though: we need to fix those.\n\n  And now we have CI:\n  - https://travis-ci.org/libevent/libevent\n  - https://ci.appveyor.com/project/nmathewson/libevent\n\n  And code coverage:\n  - https://coveralls.io/github/libevent/libevent\n\n  Plus there is vagrant boxes if you what to test it on more OS'es then\n  travis-ci allows, and there is a wrapper (in python) that will parse logs and\n  provide report:\n  - https://github.com/libevent/libevent-extras/blob/master/tools/vagrant-tests.py\n\n6. Contributing\n\n  From now we have contributing guide and checkpatch.sh.\n"
        },
        {
          "name": "whatsnew-2.2.txt",
          "type": "blob",
          "size": 14.5517578125,
          "content": "                         What's new in Libevent 2.2\n                             Azat Khuzhin\n\n0. Before we start\n\n0.1. About this document\n\n  This document describes the key differences between Libevent 2.1 and\n  Libevent 2.2. It's a work in progress.\n\n  For better documentation about libevent, see the links at\n  http://libevent.org/\n\n  Libevent 2.2 would not be possible without the generous help of numerous\n  contributors.  For a list of who did what in Libevent 2.2, please see the\n  CONTRIBUTORS.md!\n\n0.2. Where to get help\n\n  Try looking at the other documentation too.  All of the header files have\n  documentation in the doxygen format; this gets turned into nice HTML and\n  linked to from the libevent.org website.\n\n  You can ask the questions by creating an issue on github.\n\n  Note, that the following communication channels had been deprecated:\n  - #libevent IRC channel at irc.oftc.net\n  - libevent-users@freehaven.net mailing list\n\n0.3. Compatibility\n\n  Our source-compatibility policy is that correct code (that is to say, code\n  that uses public interfaces of Libevent and relies only on their documented\n  behavior) should have forward source compatibility: any such code that worked\n  with a previous version of Libevent should work with this version too.\n\n  We don't try to do binary compatibility except within stable release series,\n  so binaries linked against any version of Libevent 2.1 will probably need to\n  be recompiled against Libevent 2.2 if you want to use it. It is probable that\n  we'll break binary compatibility again before Libevent 2.2 is stable.\n\n1. Core New APIs and features\n\n1.1. \"Prepare\" and \"check\" watchers\n\n  Libevent now has a new mechanism for hooking into the event loop: \"prepare\" and\n  \"check\" watchers.  A \"prepare\" watcher is a callback that fires immediately\n  before polling for I/O. A \"check\" watcher is a callback that fires immediately\n  after polling and before processing any active events. This may be useful for\n  embedding other libraries' event loops (e.g. UI toolkits) into libevent's. It's\n  also useful for monitoring server performance. For example, if you measure the\n  time between \"prepare\" and \"check,\" that is the polling duration; the difference\n  between the expected and actual polling duration provides an indication of\n  kernel scheduling delay. And if you measure the time between \"check\" and the\n  next \"prepare\" (in the next iteration of the event loop), that is a good\n  approximation of the amount of time handling events; this provides a convenient\n  way to monitor whether any event handlers are blocking or otherwise performing\n  heavy computation.\n\n  The watcher API is defined in <event2/watch.h>. A concrete example of how\n  watchers can help monitor server performance is available in\n  \"sample/watch-timing.c\".\n\n1.2. Ability to configure read/write buffer sizes for evbuffer/bufferevents\n\n  This allows to increase the IO throughtput.\n\n  Here is some numbers for the single max read in evbuffer impact:\n    function client() { becat \"$@\" | pv > /dev/null; }\n    function server() { cat /dev/zero | becat -l \"$@\"; }\n\n  Plain bufferevent:\n\n  - 40K\n    $ server -R $((40<<10)) & client -R $((40<<10))\n    700MiB/s\n\n  - 16K *default now*\n    $ server & client\n    1.81GiB/s\n\n  - 4K\n    $ server -R $((4<<10)) & client -R $((4<<10))\n    1.05GiB/s\n\n  With OpenSSL (-S):\n\n  - 40K *default now*\n    $ server -S -R $((40<<10)) & client -S -R $((40<<10))\n    900MiB/s\n\n  - 16K *default now*\n    $ server -S & client -S\n    745MiB/s\n\n  - 4K\n    $ server -S -R $((4<<10)) & client -S -R $((4<<10))\n    593MiB/s\n\n  So as you can see without openssl 16K is faster then 40K/4K, while for\n  openssl 40K is still faster then 16K (I guess that this is due to with\n  openssl SSL_read() more at time, while with plain we have some\n  allocations splits in evbuffer and maybe due to some buffer in openssl)\n\n1.3. New backend for windows - wepoll\n\n  wepoll is a epoll replacement on windows.\n\n  wepoll features, from the official project page [1]:\n  - Can poll 100000s of sockets efficiently.\n  - Fully thread-safe.\n  - Multiple threads can poll the same epoll port.\n  - Sockets can be added to multiple epoll sets.\n  - All epoll events (EPOLLIN, EPOLLOUT, EPOLLPRI, EPOLLRDHUP) are supported.\n  - Level-triggered and one-shot (EPOLLONESTHOT) modes are supported\n  - Trivial to embed: you need only two files.\n\n    [1]: https://github.com/piscisaureus/wepoll\n\n  The default backend on Windows is still select, just because it is well\n  tested, and there is no other reasons. That said, that there is no know\n  issues with wepoll, so please, use it and report any issues!\n\n1.4. Unix sockets under Windows\n\n  Since Windows 10 there is support for unix domain sockets, and Libevent also\n  supports this, via evutil_socketpair().\n\n1.5. Priority inheritance for pthreads\n\n  Now you can use\n  evthread_use_pthreads_with_flags(EVTHREAD_PTHREAD_PRIO_INHERIT) to use\n  priority inheritance.\n\n1.6. signalfd support\n\n  Linux-specific signal handling backend based on signalfd(2) system call, and\n  public function event_base_get_signal_method() to obtain an underlying kernel\n  signal handling mechanism.\n\n2. HTTP New APIs and features\n\n2.1. Support for custom HTTP methods\n\n  Libevent HTTP code now supports defining custom HTTP methods. It is done\n  through a callback:\n\n    #define EVHTTP_REQ_CUSTOM      ((EVHTTP_REQ_MAX) << 1)\n    static int ext_method_cb(struct evhttp_ext_method *p)\n    {\n      if (p == NULL)\n        return -1;\n      if (p->method) {\n        if (strcmp(p->method, \"CUSTOM\") == 0) {\n          p->type = EVHTTP_REQ_CUSTOM;\n          p->flags = 0;   /*EVHTTP_METHOD_HAS_BODY*/\n          return 0;\n        }\n      } else {\n        if (p->type == EVHTTP_REQ_CUSTOM) {\n          p->method = \"CUSTOM\";\n          return 0;\n        }\n      }\n    }\n\n  And to register this callback with http server you can use:\n    evhttp_set_ext_method_cmp(http, ext_method_cb);\n\n  Or registering callback with one client only:\n    evhttp_connection_set_ext_method_cmp(evcon, ext_method_cb);\n\n2.2. Separate timeouts for read/write/connect phase in HTTP\n\n  New API:\n\n  - client:\n    evhttp_connection_set_connect_timeout_tv() -- for connect\n    evhttp_connection_set_read_timeout_tv()    -- for read\n    evhttp_connection_set_write_timeout_tv()   -- for write\n\n  - server:\n    evhttp_set_read_timeout_tv()  -- for read\n    evhttp_set_write_timeout_tv() -- for write\n\n  It also changes a logic a little, before there was next fallbacks which\n  does not handled in new API:\n  - HTTP_CONNECT_TIMEOUT\n  - HTTP_WRITE_TIMEOUT\n  - HTTP_READ_TIMEOUT\n\n  And introduce another internal flag (EVHTTP_CON_TIMEOUT_ADJUSTED) that\n  will be used in evrpc, which adjust evhttp_connection timeout only if it\n  is not default.\n\n2.3. Add callback support for error pages\n\n  Now there is evhttp_set_errorcb(), that could be used to change error pages\n  of your http server.\n\n  This can be used for multi lingual support, or to overcome some browser\n  limitations (for example Microsoft Internet Explorer may display its own\n  error pages if ones sent by an HTTP server are smaller than certain sizes)\n\n2.4. Minimal WebSocket server implementation for evhttp\n\n  Adds few functions (for more details see event2/ws.h) to use evhttp-based\n  webserver to handle incoming WebSockets connections. We've tried to use both\n  libevent and libwebsockets in our application, but found that we need to have\n  different ports at the same time to handle standard HTTP and WebSockets\n  traffic. This change can help to stick only with libevent library.\n\n  Implementation was inspired by modified Libevent source code in ipush project\n  [1].\n\n    [1]: https://github.com/sqfasd/ipush/tree/master/deps/libevent-2.0.21-stable\n\n  Also, WebSocket-based chat server was added as a sample.\n\n2.5. evhttp_bound_set_bevcb()\n\n  Like evhttp_set_bevcb(), but for evhttp_bound_socket, and callback of\n  evhttp_set_bevcb() will not be called if evhttp_bound_set_bevcb() returns\n  bufferevent.\n\n2.6. evhttp max simultaneous connection limiting\n\n  When the max connection limit is enabled and the limit is reached, the server\n  will respond immediately with 503 Service Unavailable. This can be used to\n  prevent servers from running out of file descriptors. This is better than\n  request limiting because clients may make more than one request over a single\n  connection. Blocking a request does not necessarily close the connection and\n  free up a socket.\n\n  There are two new API:\n\n  - evhttp_set_max_connections()\n  - evhttp_get_connection_count()\n\n2.7. Support for Unix Domain Sockets in evhttp\n\n  This can be done using evhttp_connection_base_bufferevent_unix_new()\n\n  There are no standard for encoding a unix socket in an url. nginx uses:\n\n      http://unix:/path/to/unix/socket:/httppath\n\n  The second colon is needed to delimit where the unix path ends and where\n  the rest of the url continues.\n\n3. Bufferevents\n\n3.1. SSL layer\n\n  SSL layer has gained Mbed-TLS support, it is implemented in a different\n  library - event_mbedtls (remember that for OpenSSL, event_openssl should be\n  used).\n\n  LibreSSL is also supported, but you don't need separate library for this,\n  since LibreSSL is compatible with OpenSSL.\n\n  The library known to work with OpenSSL 3.0 as well, though the performance\n  with 3.0 is worser.\n\n  Some changes in API, the following had been deprecated:\n  - bufferevent_openssl_get_allow_dirty_shutdown()\n  - bufferevent_openssl_set_allow_dirty_shutdown()\n  - bufferevent_mbedtls_get_allow_dirty_shutdown()\n  - bufferevent_mbedtls_set_allow_dirty_shutdown()\n\n  And instead, the following should be used:\n  - bufferevent_ssl_set_flags()\n  - bufferevent_ssl_clear_flags()\n  - bufferevent_ssl_get_flags()\n\n  Also there is new flag BUFFEREVENT_SSL_BATCH_WRITE, that allows to avoid\n  Nagle effect in SSL.\n\n4. DNS layer\n\n4.1. TCP support\n\n  Libevent now has support for DNS requests via TCP.\n\n  By default, requests are done via UDP. In case truncated response is received\n  new attempt is done via TCP connection.\n\n  2 new macros DNS_QUERY_USEVC and DNS_QUERY_IGNTC had been added to force all\n  requests to be done via TCP and to disable switch to TCP in case of truncated\n  responses.\n\n  Possibility for DNS server to listen and receive requests on TCP port also\n  had been added.\n\n  Fallback to TCP in case of truncated DNS requests is done automatically.\n  To imitate the old behaviour macros DNS_QUERY_IGNTC should be used. To\n  force all DNS requests to be done via TCP one should use the flag\n  DNS_QUERY_USEVC. Names DNS_QUERY_IGNTC, DNS_QUERY_USEVC were chosen to\n  imitate similar flags in c-ares and glibc.\n\n4.2. New evdns options\n\n  - evdns-udp-size - allows to configure maximum allowed size of UDP DNS\n    messages\n\n  - probe-backoff-factor - backoff factor of probe timeout\n\n  - max-probe-timeout - maximum timeout between two probe packets will change\n    initial-probe-timeout when this value is smaller\n\n  And also evdns now can handle CNAME.\n\n4.3. evdns now has ability to not add default nameservers\n\n  By default evdns adds \"127.0.0.1\" if there is no other nameservers.\n\n  Two new options had been added:\n\n  - DNS_OPTION_NAMESERVERS_NO_DEFAULT\n\n    Do not \"default\" nameserver (i.e. \"127.0.0.1:53\") if there is no nameservers\n    in resolv.conf, (iff DNS_OPTION_NAMESERVERS is set)\n\n  - EVDNS_BASE_NAMESERVERS_NO_DEFAULT\n\n    If EVDNS_BASE_INITIALIZE_NAMESERVERS isset, do not add default\n    nameserver if there are no nameservers in resolv.conf (just set\n    DNS_OPTION_NAMESERVERS_NO_DEFAULT internally)\n\n5. Listeners new flags\n\n  - LEV_OPT_BIND_IPV6ONLY - bind only to IPv6\n\n  - LEV_OPT_BIND_IPV4_AND_IPV6 -- bind to both to IPv4 and IPv6\n\n10. Building\n\n10.1. autotools is deprecated, use cmake\n\n  Building with autotools/automake is considered as deprecated, instead, cmake\n  is recommended.\n\n  CMake is crossplatform so you don't need to support multiple files for\n  various operation systems, like before.\n\n  Libevent has find_package() support, and this is very flexible way of using\n  the library in your project, since it is very easy to use even local builds\n  (for more information read more about CMake User Registry).\n\n10.2. Building libevent as a sub-project using GNU Auto* tools\n\n  Some projects will choose to include libevent in their source distribution,\n  and build libevent as a sub-project.  This may be effected by putting the\n  line:\n\n   AC_CONFIG_SUBDIRS([path/to/libevent])\n\n  in the master configure.ac file for the master project.\n\n  There are cases where the master project will want to pass in additional\n  flags for CFLAGS, CPPFLAGS, or LDFLAGS.  Since these variables are reserved\n  for the user, and AM_CFLAGS, AM_CPPFLAGS, and AM_LDFLAGS are reserved for\n  each package, libevent offers the following variables for a master package\n  to tell libevent that there are additional compile/link values:\n\n   LIBEVENT_CFLAGS\n   LIBEVENT_CPPFLAGS\n   LIBEVENT_LDFLAGS\n\n  A master package can set these variables in its configure.ac file.\n\n  Here's an example:\n\n  configure.ac:\n  ...\n  EXTRA_CFLAGS=...\n  EXTRA_CPPFLAGS=...\n  EXTRA_LDFLAGS=...\n  ...\n  dnl ac_configure_args is undocumented but widely abused, as here,\n  dnl to modify the defaults of the libevent subpackage, by prefixing\n  dnl our changes to the child configure arguments already assembled.\n  dnl User-supplied contradictory choices should prevail thanks to\n  dnl \"last wins\".\n  ac_configure_args=\" --disable-openssl${ac_configure_args}\"\n  ac_configure_args=\" --disable-shared${ac_configure_args}\"\n  ac_configure_args=\" --disable-libevent-regress${ac_configure_args}\"\n  ac_configure_args=\" --disable-libevent-install${ac_configure_args}\"\n  ac_configure_args=\" --enable-silent-rules${ac_configure_args}\"\n  ac_configure_args=\" --enable-function-sections${ac_configure_args}\"\n  ac_configure_args=\" LIBEVENT_CFLAGS='${EXTRA_CFLAGS}'${ac_configure_args}\"\n  ac_configure_args=\" LIBEVENT_CPPFLAGS='${EXTRA_CPPFLAGS}'${ac_configure_args}\"\n  ac_configure_args=\" LIBEVENT_LDFLAGS='${EXTRA_LDFLAGS}'${ac_configure_args}\"\n  AC_CONFIG_SUBDIRS([libevent])\n  ...\n\n  The space after the initial '\"' is significant.\n\n11. Continuous Integration\n\n  Now Libevent uses github actions for CI, previously we had travis-ci for\n  linux/macos and appveyor for win32 (removed in #951), and also I used testing\n  vagrant for some time, but it had been moved into a separate repository\n  (8c1838be). But actually this is not required anymore since github actions\n  supports:\n  - linux\n  - freebsd\n  - windows\n  - osx\n  - openbsd\n  - and also tests under Thread/Address/Undefined sanitizers\n\n  So no need to test something locally before releases.\n\n  One thing that worth to mention, now, CI depends on public workers, and they\n  are pretty limited, so it take some time to run the whole CI.\n\n12. Documentation\n\n  Now documentation is automatically deployed to https://libevent.org/doc/\n"
        },
        {
          "name": "win32select.c",
          "type": "blob",
          "size": 10.376953125,
          "content": "/*\n * Copyright 2007-2012 Niels Provos and Nick Mathewson\n * Copyright 2000-2007 Niels Provos <provos@citi.umich.edu>\n * Copyright 2003 Michael A. Davis <mike@datanerds.net>\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#ifdef _WIN32\n\n#include <winsock2.h>\n#include <windows.h>\n#include <sys/types.h>\n#include <sys/queue.h>\n#include <limits.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n\n#include \"event2/util.h\"\n#include \"util-internal.h\"\n#include \"log-internal.h\"\n#include \"event2/event.h\"\n#include \"event-internal.h\"\n#include \"evmap-internal.h\"\n#include \"event2/thread.h\"\n#include \"evthread-internal.h\"\n#include \"time-internal.h\"\n\n#define XFREE(ptr) do { if (ptr) mm_free(ptr); } while (0)\n\nextern struct event_list timequeue;\nextern struct event_list addqueue;\n\nstruct win_fd_set {\n\tunsigned int fd_count;\n\tSOCKET fd_array[1];\n};\n\n/* MSDN says this is required to handle SIGFPE */\nvolatile double SIGFPE_REQ = 0.0f;\n\nstruct idx_info {\n\tint read_pos_plus1;\n\tint write_pos_plus1;\n};\n\nstruct win32op {\n\tunsigned num_fds_in_fd_sets;\n\tint resize_out_sets;\n\tstruct win_fd_set *readset_in;\n\tstruct win_fd_set *writeset_in;\n\tstruct win_fd_set *readset_out;\n\tstruct win_fd_set *writeset_out;\n\tstruct win_fd_set *exset_out;\n\tunsigned signals_are_broken : 1;\n};\n\nstatic void *win32_init(struct event_base *);\nstatic int win32_add(struct event_base *, evutil_socket_t, short old, short events, void *idx_);\nstatic int win32_del(struct event_base *, evutil_socket_t, short old, short events, void *idx_);\nstatic int win32_dispatch(struct event_base *base, struct timeval *);\nstatic void win32_dealloc(struct event_base *);\n\nstruct eventop win32ops = {\n\t\"win32\",\n\twin32_init,\n\twin32_add,\n\twin32_del,\n\twin32_dispatch,\n\twin32_dealloc,\n\t0, /* doesn't need reinit */\n\t0, /* No features supported. */\n\tsizeof(struct idx_info),\n};\n\n#define FD_SET_ALLOC_SIZE(n) ((sizeof(struct win_fd_set) + ((n)-1)*sizeof(SOCKET)))\n\nstatic int\ngrow_fd_sets(struct win32op *op, unsigned new_num_fds)\n{\n\tsize_t size;\n\n\tEVUTIL_ASSERT(new_num_fds >= op->readset_in->fd_count &&\n\t       new_num_fds >= op->writeset_in->fd_count);\n\tEVUTIL_ASSERT(new_num_fds >= 1);\n\n\tsize = FD_SET_ALLOC_SIZE(new_num_fds);\n\tif (!(op->readset_in = mm_realloc(op->readset_in, size)))\n\t\treturn (-1);\n\tif (!(op->writeset_in = mm_realloc(op->writeset_in, size)))\n\t\treturn (-1);\n\top->resize_out_sets = 1;\n\top->num_fds_in_fd_sets = new_num_fds;\n\treturn (0);\n}\n\nstatic int\ndo_fd_set(struct win32op *op, struct idx_info *ent, evutil_socket_t s, int read)\n{\n\tstruct win_fd_set *set = read ? op->readset_in : op->writeset_in;\n\tif (read) {\n\t\tif (ent->read_pos_plus1 > 0)\n\t\t\treturn (0);\n\t} else {\n\t\tif (ent->write_pos_plus1 > 0)\n\t\t\treturn (0);\n\t}\n\tif (set->fd_count == op->num_fds_in_fd_sets) {\n\t\tif (grow_fd_sets(op, op->num_fds_in_fd_sets*2))\n\t\t\treturn (-1);\n\t\t/* set pointer will have changed and needs reiniting! */\n\t\tset = read ? op->readset_in : op->writeset_in;\n\t}\n\tset->fd_array[set->fd_count] = s;\n\tif (read)\n\t\tent->read_pos_plus1 = set->fd_count+1;\n\telse\n\t\tent->write_pos_plus1 = set->fd_count+1;\n\treturn (set->fd_count++);\n}\n\nstatic int\ndo_fd_clear(struct event_base *base,\n\t\t\tstruct win32op *op, struct idx_info *ent, int read)\n{\n\tint i;\n\tstruct win_fd_set *set = read ? op->readset_in : op->writeset_in;\n\tif (read) {\n\t\ti = ent->read_pos_plus1 - 1;\n\t\tent->read_pos_plus1 = 0;\n\t} else {\n\t\ti = ent->write_pos_plus1 - 1;\n\t\tent->write_pos_plus1 = 0;\n\t}\n\tif (i < 0)\n\t\treturn (0);\n\tif (--set->fd_count != (unsigned)i) {\n\t\tstruct idx_info *ent2;\n\t\tSOCKET s2;\n\t\ts2 = set->fd_array[i] = set->fd_array[set->fd_count];\n\n\t\tent2 = evmap_io_get_fdinfo_(&base->io, s2);\n\n\t\tif (!ent2) /* This indicates a bug. */\n\t\t\treturn (0);\n\t\tif (read)\n\t\t\tent2->read_pos_plus1 = i+1;\n\t\telse\n\t\t\tent2->write_pos_plus1 = i+1;\n\t}\n\treturn (0);\n}\n\n#define NEVENT 32\nvoid *\nwin32_init(struct event_base *base)\n{\n\tstruct win32op *winop;\n\tsize_t size;\n\tif (!(winop = mm_calloc(1, sizeof(struct win32op))))\n\t\treturn NULL;\n\twinop->num_fds_in_fd_sets = NEVENT;\n\tsize = FD_SET_ALLOC_SIZE(NEVENT);\n\tif (!(winop->readset_in = mm_malloc(size)))\n\t\tgoto err;\n\tif (!(winop->writeset_in = mm_malloc(size)))\n\t\tgoto err;\n\tif (!(winop->readset_out = mm_malloc(size)))\n\t\tgoto err;\n\tif (!(winop->writeset_out = mm_malloc(size)))\n\t\tgoto err;\n\tif (!(winop->exset_out = mm_malloc(size)))\n\t\tgoto err;\n\twinop->readset_in->fd_count = winop->writeset_in->fd_count = 0;\n\twinop->readset_out->fd_count = winop->writeset_out->fd_count\n\t\t= winop->exset_out->fd_count = 0;\n\n\tif (evsig_init_(base) < 0)\n\t\twinop->signals_are_broken = 1;\n\n\tevutil_weakrand_seed_(&base->weakrand_seed, 0);\n\n\treturn (winop);\n err:\n\tXFREE(winop->readset_in);\n\tXFREE(winop->writeset_in);\n\tXFREE(winop->readset_out);\n\tXFREE(winop->writeset_out);\n\tXFREE(winop->exset_out);\n\tXFREE(winop);\n\treturn (NULL);\n}\n\nint\nwin32_add(struct event_base *base, evutil_socket_t fd,\n\t\t\t short old, short events, void *idx_)\n{\n\tstruct win32op *win32op = base->evbase;\n\tstruct idx_info *idx = idx_;\n\n\tif ((events & EV_SIGNAL) && win32op->signals_are_broken)\n\t\treturn (-1);\n\n\tif (!(events & (EV_READ|EV_WRITE)))\n\t\treturn (0);\n\n\tevent_debug((\"%s: adding event for %d\", __func__, (int)fd));\n\tif (events & EV_READ) {\n\t\tif (do_fd_set(win32op, idx, fd, 1)<0)\n\t\t\treturn (-1);\n\t}\n\tif (events & EV_WRITE) {\n\t\tif (do_fd_set(win32op, idx, fd, 0)<0)\n\t\t\treturn (-1);\n\t}\n\treturn (0);\n}\n\nint\nwin32_del(struct event_base *base, evutil_socket_t fd, short old, short events,\n\t\t  void *idx_)\n{\n\tstruct win32op *win32op = base->evbase;\n\tstruct idx_info *idx = idx_;\n\n\tevent_debug((\"%s: Removing event for \"EV_SOCK_FMT,\n\t\t__func__, EV_SOCK_ARG(fd)));\n\tif (events & EV_READ)\n\t\tdo_fd_clear(base, win32op, idx, 1);\n\tif (events & EV_WRITE)\n\t\tdo_fd_clear(base, win32op, idx, 0);\n\n\treturn 0;\n}\n\nstatic void\nfd_set_copy(struct win_fd_set *out, const struct win_fd_set *in)\n{\n\tout->fd_count = in->fd_count;\n\tmemcpy(out->fd_array, in->fd_array, in->fd_count * (sizeof(SOCKET)));\n}\n\n/*\n  static void dump_fd_set(struct win_fd_set *s)\n  {\n  unsigned int i;\n  printf(\"[ \");\n  for(i=0;i<s->fd_count;++i)\n  printf(\"%d \",(int)s->fd_array[i]);\n  printf(\"]\\n\");\n  }\n*/\n\nint\nwin32_dispatch(struct event_base *base, struct timeval *tv)\n{\n\tstruct win32op *win32op = base->evbase;\n\tint res = 0;\n\tunsigned j, i;\n\tint fd_count;\n\tSOCKET s;\n\n\tif (win32op->resize_out_sets) {\n\t\tsize_t size = FD_SET_ALLOC_SIZE(win32op->num_fds_in_fd_sets);\n\t\tif (!(win32op->readset_out = mm_realloc(win32op->readset_out, size)))\n\t\t\treturn (-1);\n\t\tif (!(win32op->exset_out = mm_realloc(win32op->exset_out, size)))\n\t\t\treturn (-1);\n\t\tif (!(win32op->writeset_out = mm_realloc(win32op->writeset_out, size)))\n\t\t\treturn (-1);\n\t\twin32op->resize_out_sets = 0;\n\t}\n\n\tfd_set_copy(win32op->readset_out, win32op->readset_in);\n\tfd_set_copy(win32op->exset_out, win32op->writeset_in);\n\tfd_set_copy(win32op->writeset_out, win32op->writeset_in);\n\n\tfd_count =\n\t    (win32op->readset_out->fd_count > win32op->writeset_out->fd_count) ?\n\t    win32op->readset_out->fd_count : win32op->writeset_out->fd_count;\n\n\tif (!fd_count) {\n\t\tlong msec = tv ? evutil_tv_to_msec_(tv) : LONG_MAX;\n\t\t/* Sleep's DWORD argument is unsigned long */\n\t\tif (msec < 0)\n\t\t\tmsec = LONG_MAX;\n\t\t/* Windows doesn't like you to call select() with no sockets */\n\t\tSleep(msec);\n\t\treturn (0);\n\t}\n\n\tEVBASE_RELEASE_LOCK(base, th_base_lock);\n\n\tres = select(fd_count,\n\t\t     (struct fd_set*)win32op->readset_out,\n\t\t     (struct fd_set*)win32op->writeset_out,\n\t\t     (struct fd_set*)win32op->exset_out, tv);\n\n\tEVBASE_ACQUIRE_LOCK(base, th_base_lock);\n\n\tevent_debug((\"%s: select returned %d\", __func__, res));\n\n\tif (res <= 0) {\n\t\tevent_debug((\"%s: %s\", __func__,\n\t\t    evutil_socket_error_to_string(EVUTIL_SOCKET_ERROR())));\n\t\treturn res;\n\t}\n\n\tif (win32op->readset_out->fd_count) {\n\t\ti = evutil_weakrand_range_(&base->weakrand_seed,\n\t\t    win32op->readset_out->fd_count);\n\t\tfor (j=0; j<win32op->readset_out->fd_count; ++j) {\n\t\t\tif (++i >= win32op->readset_out->fd_count)\n\t\t\t\ti = 0;\n\t\t\ts = win32op->readset_out->fd_array[i];\n\t\t\tevmap_io_active_(base, s, EV_READ);\n\t\t}\n\t}\n\tif (win32op->exset_out->fd_count) {\n\t\ti = evutil_weakrand_range_(&base->weakrand_seed,\n\t\t    win32op->exset_out->fd_count);\n\t\tfor (j=0; j<win32op->exset_out->fd_count; ++j) {\n\t\t\tif (++i >= win32op->exset_out->fd_count)\n\t\t\t\ti = 0;\n\t\t\ts = win32op->exset_out->fd_array[i];\n\t\t\tevmap_io_active_(base, s, EV_WRITE);\n\t\t}\n\t}\n\tif (win32op->writeset_out->fd_count) {\n\t\ti = evutil_weakrand_range_(&base->weakrand_seed,\n\t\t    win32op->writeset_out->fd_count);\n\t\tfor (j=0; j<win32op->writeset_out->fd_count; ++j) {\n\t\t\tif (++i >= win32op->writeset_out->fd_count)\n\t\t\t\ti = 0;\n\t\t\ts = win32op->writeset_out->fd_array[i];\n\t\t\tevmap_io_active_(base, s, EV_WRITE);\n\t\t}\n\t}\n\treturn (0);\n}\n\nvoid\nwin32_dealloc(struct event_base *base)\n{\n\tstruct win32op *win32op = base->evbase;\n\n\tevsig_dealloc_(base);\n\tif (win32op->readset_in)\n\t\tmm_free(win32op->readset_in);\n\tif (win32op->writeset_in)\n\t\tmm_free(win32op->writeset_in);\n\tif (win32op->readset_out)\n\t\tmm_free(win32op->readset_out);\n\tif (win32op->writeset_out)\n\t\tmm_free(win32op->writeset_out);\n\tif (win32op->exset_out)\n\t\tmm_free(win32op->exset_out);\n\t/* XXXXX free the tree. */\n\n\tmemset(win32op, 0, sizeof(*win32op));\n\tmm_free(win32op);\n}\n\n#endif\n"
        },
        {
          "name": "ws.c",
          "type": "blob",
          "size": 12.0986328125,
          "content": "#include \"event2/event-config.h\"\n#include \"evconfig-private.h\"\n\n#include \"event2/buffer.h\"\n#include \"event2/bufferevent.h\"\n#include \"event2/event.h\"\n#include \"event2/http.h\"\n#include \"event2/ws.h\"\n#include \"util-internal.h\"\n#include \"mm-internal.h\"\n#include \"sha1.h\"\n#include \"event2/bufferevent.h\"\n#include \"sys/queue.h\"\n#include \"http-internal.h\"\n#include \"bufferevent-internal.h\"\n\n#include <assert.h>\n#include <inttypes.h>\n#include <string.h>\n#include <stdbool.h>\n\n#ifndef _WIN32\n#include <sys/socket.h>\n#include <sys/stat.h>\n#else /* _WIN32 */\n#include <winsock2.h>\n#include <ws2tcpip.h>\n#endif /* _WIN32 */\n\n#ifdef EVENT__HAVE_ARPA_INET_H\n#include <arpa/inet.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN_H\n#include <netinet/in.h>\n#endif\n#ifdef EVENT__HAVE_NETINET_IN6_H\n#include <netinet/in6.h>\n#endif\n\n#define WS_UUID \"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\"\n/*\n * We limit the size of received WS frames to 10 MiB,\n * as a DoS prevention measure.\n */\nstatic const size_t WS_MAX_RECV_FRAME_SZ = 10485760;\n\nstruct evws_connection {\n\tTAILQ_ENTRY(evws_connection) next;\n\n\tstruct bufferevent *bufev;\n\n\tws_on_msg_cb cb;\n\tvoid *cb_arg;\n\n\tws_on_close_cb cbclose;\n\tvoid *cbclose_arg;\n\n\t/* for server connections, the http server they are connected with */\n\tstruct evhttp *http_server;\n\n\tstruct evbuffer *incomplete_frames;\n\tbool closed;\n};\n\nenum WebSocketFrameType {\n\tERROR_FRAME = 0xFF,\n\tINCOMPLETE_DATA = 0xFE,\n\n\tCLOSING_FRAME = 0x8,\n\n\tINCOMPLETE_FRAME = 0x81,\n\n\tTEXT_FRAME = 0x1,\n\tBINARY_FRAME = 0x2,\n\n\tPING_FRAME = 0x9,\n\tPONG_FRAME = 0xA\n};\n\n\nstatic void evws_send(struct evws_connection *evws,\n\tenum WebSocketFrameType frame_type, const char *packet_str, size_t str_len);\n\n/*\n * Clean up a WebSockets connection object\n */\n\nvoid\nevws_connection_free(struct evws_connection *evws)\n{\n\t/* notify interested parties that this connection is going down */\n\tif (evws->cbclose != NULL)\n\t\t(*evws->cbclose)(evws, evws->cbclose_arg);\n\n\tif (evws->http_server != NULL) {\n\t\tstruct evhttp *http = evws->http_server;\n\t\tTAILQ_REMOVE(&http->ws_sessions, evws, next);\n\t\thttp->connection_cnt--;\n\t}\n\n\tif (evws->bufev != NULL) {\n\t\tbufferevent_free(evws->bufev);\n\t}\n\tif (evws->incomplete_frames != NULL) {\n\t\tevbuffer_free(evws->incomplete_frames);\n\t}\n\n\tmm_free(evws);\n}\n\nstatic const char basis_64[] =\n\t\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\";\n\nstatic int\nBase64encode(char *encoded, const char *string, int len)\n{\n\tint i;\n\tchar *p;\n\n\tp = encoded;\n\tfor (i = 0; i < len - 2; i += 3) {\n\t\t*p++ = basis_64[(string[i] >> 2) & 0x3F];\n\t\t*p++ = basis_64[((string[i] & 0x3) << 4) |\n\t\t\t\t\t\t((int)(string[i + 1] & 0xF0) >> 4)];\n\t\t*p++ = basis_64[((string[i + 1] & 0xF) << 2) |\n\t\t\t\t\t\t((int)(string[i + 2] & 0xC0) >> 6)];\n\t\t*p++ = basis_64[string[i + 2] & 0x3F];\n\t}\n\tif (i < len) {\n\t\t*p++ = basis_64[(string[i] >> 2) & 0x3F];\n\t\tif (i == (len - 1)) {\n\t\t\t*p++ = basis_64[((string[i] & 0x3) << 4)];\n\t\t\t*p++ = '=';\n\t\t} else {\n\t\t\t*p++ = basis_64[((string[i] & 0x3) << 4) |\n\t\t\t\t\t\t\t((int)(string[i + 1] & 0xF0) >> 4)];\n\t\t\t*p++ = basis_64[((string[i + 1] & 0xF) << 2)];\n\t\t}\n\t\t*p++ = '=';\n\t}\n\n\t*p++ = '\\0';\n\treturn p - encoded;\n}\n\nstatic char *\nws_gen_accept_key(const char *ws_key, char out[32])\n{\n\tchar buf[1024];\n\tchar digest[20];\n\n\tsnprintf(buf, sizeof(buf), \"%s\" WS_UUID, ws_key);\n\n\tbuiltin_SHA1(digest, buf, strlen(buf));\n\tBase64encode(out, digest, sizeof(digest));\n\treturn out;\n}\n\nstatic void\nclose_after_write_cb(struct bufferevent *bev, void *ctx)\n{\n\tif (evbuffer_get_length(bufferevent_get_output(bev)) == 0) {\n\t\tevws_connection_free(ctx);\n\t}\n}\n\nstatic void\nclose_event_cb(struct bufferevent *bev, short what, void *ctx)\n{\n\tevws_connection_free(ctx);\n}\n\nvoid\nevws_close(struct evws_connection *evws, uint16_t reason)\n{\n\tuint8_t fr[4] = {0x8 | 0x80, 2, 0};\n\tstruct evbuffer *output;\n\tuint16_t *u16;\n\n\tif (evws->closed)\n\t\treturn;\n\tevws->closed = true;\n\n\tu16 = (uint16_t *)&fr[2];\n\t*u16 = htons((int16_t)reason);\n\toutput = bufferevent_get_output(evws->bufev);\n\tevbuffer_add(output, fr, 4);\n\n\t/* wait for close frame writing complete and close connection */\n\tbufferevent_setcb(\n\t\tevws->bufev, NULL, close_after_write_cb, close_event_cb, evws);\n}\n\nstatic void\nevws_force_disconnect_(struct evws_connection *evws)\n{\n\tevws_close(evws, WS_CR_NONE);\n}\n\n/* parse base frame according to\n * https://www.rfc-editor.org/rfc/rfc6455#section-5.2\n */\nstatic enum WebSocketFrameType\nget_ws_frame(unsigned char *in_buffer, size_t buf_len,\n\tunsigned char **payload_ptr, size_t *out_len)\n{\n\tunsigned char opcode;\n\tunsigned char fin;\n\tunsigned char masked;\n\tsize_t payload_len;\n\tsize_t pos;\n\tint length_field;\n\n\tif (buf_len < 2) {\n\t\treturn INCOMPLETE_DATA;\n\t}\n\n\topcode = in_buffer[0] & 0x0F;\n\tfin = (in_buffer[0] >> 7) & 0x01;\n\tmasked = (in_buffer[1] >> 7) & 0x01;\n\n\tpayload_len = 0;\n\tpos = 2;\n\tlength_field = in_buffer[1] & (~0x80);\n\n\tif (length_field <= 125) {\n\t\tpayload_len = length_field;\n\t} else if (length_field == 126) { /* msglen is 16bit */\n\t\tuint16_t tmp16;\n\t\tif (buf_len < 4)\n\t\t\treturn INCOMPLETE_DATA;\n\t\tmemcpy(&tmp16, in_buffer + pos, 2);\n\t\tpayload_len = ntohs(tmp16);\n\t\tpos += 2;\n\t} else if (length_field == 127) { /* msglen is 64bit */\n\t\tint i;\n\t\tuint64_t tmp64 = 0;\n\t\tif (buf_len < 10)\n\t\t\treturn INCOMPLETE_DATA;\n\t\t/* swap bytes from big endian to host byte order */\n\t\tfor (i = 56; i >= 0; i -= 8) {\n\t\t\ttmp64 |= (uint64_t)in_buffer[pos++] << i;\n\t\t}\n\t\tif (tmp64 > WS_MAX_RECV_FRAME_SZ) {\n\t\t\t/* Implementation limitation, we support up to 10 MiB\n\t\t\t * length, as a DoS prevention measure.\n\t\t\t */\n\t\t\tevent_warn(\"%s: frame length %\" PRIu64 \" exceeds %\" PRIu64 \"\\n\",\n\t\t\t\t__func__, tmp64, (uint64_t)WS_MAX_RECV_FRAME_SZ);\n\t\t\t/* Calling code needs these values; do the best we can here.\n\t\t\t * Caller will close the connection anyway.\n\t\t\t */\n\t\t\t*payload_ptr = in_buffer + pos;\n\t\t\t*out_len = 0;\n\t\t\treturn ERROR_FRAME;\n\t\t}\n\t\tpayload_len = (size_t)tmp64;\n\t}\n\tif (buf_len < payload_len + pos + (masked ? 4u : 0u)) {\n\t\treturn INCOMPLETE_DATA;\n\t}\n\n\t/* According to RFC it seems that unmasked data should be prohibited\n\t * but we support it for nonconformant clients\n\t */\n\tif (masked) {\n\t\tunsigned char *c, *mask;\n\t\tsize_t i;\n\n\t\tmask = in_buffer + pos; /* first 4 bytes are mask bytes */\n\t\tpos += 4;\n\n\t\t/* unmask data */\n\t\tc = in_buffer + pos;\n\t\tfor (i = 0; i < payload_len; i++) {\n\t\t\tc[i] = c[i] ^ mask[i % 4u];\n\t\t}\n\t}\n\n\t*payload_ptr = in_buffer + pos;\n\t*out_len = payload_len;\n\n\t/* are reserved for further frames */\n\tif ((opcode >= 3 && opcode <= 7) || (opcode >= 0xb))\n\t\treturn ERROR_FRAME;\n\n\tif (opcode <= 0x3 && !fin) {\n\t\treturn INCOMPLETE_FRAME;\n\t}\n\treturn opcode;\n}\n\n\nstatic void\nws_evhttp_read_cb(struct bufferevent *bufev, void *arg)\n{\n\tstruct evws_connection *evws = arg;\n\tunsigned char *payload;\n\tenum WebSocketFrameType type;\n\tsize_t msg_len, in_len, header_sz;\n\tstruct evbuffer *input = bufferevent_get_input(evws->bufev);\n\n\tbufferevent_incref_and_lock_(evws->bufev);\n\twhile ((in_len = evbuffer_get_length(input))) {\n\t\tunsigned char *data = evbuffer_pullup(input, in_len);\n\t\tif (data == NULL) {\n\t\t\tgoto bailout;\n\t\t}\n\n\t\ttype = get_ws_frame(data, in_len, &payload, &msg_len);\n\t\tif (type == INCOMPLETE_DATA) {\n\t\t\t/* incomplete data received, wait for next chunk */\n\t\t\tgoto bailout;\n\t\t}\n\t\theader_sz = payload - data;\n\t\tevbuffer_drain(input, header_sz);\n\t\tdata = evbuffer_pullup(input, -1);\n\n\t\tswitch (type) {\n\t\tcase TEXT_FRAME:\n\t\tcase BINARY_FRAME:\n\t\t\tif (evws->incomplete_frames != NULL) {\n\t\t\t\t/* we already have incomplete frames in internal buffer\n\t\t\t\t * and need to concatenate them with final one */\n\t\t\t\tevbuffer_add(evws->incomplete_frames, data, msg_len);\n\n\t\t\t\tdata = evbuffer_pullup(evws->incomplete_frames, -1);\n\n\t\t\t\tevws->cb(evws, type, data,\n\t\t\t\t\tevbuffer_get_length(evws->incomplete_frames), evws->cb_arg);\n\t\t\t\tevbuffer_free(evws->incomplete_frames);\n\t\t\t\tevws->incomplete_frames = NULL;\n\t\t\t} else {\n\t\t\t\tevws->cb(evws, type, data, msg_len, evws->cb_arg);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase INCOMPLETE_FRAME:\n\t\t\t/* we received full frame until get fin and need to\n\t\t\t * postpone callback until all data arrives */\n\t\t\tif (evws->incomplete_frames == NULL) {\n\t\t\t\tevws->incomplete_frames = evbuffer_new();\n\t\t\t}\n\t\t\tevbuffer_remove_buffer(input, evws->incomplete_frames, msg_len);\n\t\t\tcontinue;\n\t\tcase CLOSING_FRAME:\n\t\tcase ERROR_FRAME:\n\t\t\tevws_force_disconnect_(evws);\n\t\t\tbreak;\n\t\tcase PING_FRAME:\n\t\tcase PONG_FRAME:\n\t\t\t/* ping or pong frame */\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tevent_warn(\"%s: unexpected frame type %d\\n\", __func__, type);\n\t\t\tevws_force_disconnect_(evws);\n\t\t}\n\t\tevbuffer_drain(input, msg_len);\n\t}\n\nbailout:\n\tbufferevent_decref_and_unlock_(evws->bufev);\n}\n\nstatic void\nws_evhttp_error_cb(struct bufferevent *bufev, short what, void *arg)\n{\n\t/* when client just disappears after connection (wscat closed by Cmd+Q) */\n\tif (what & BEV_EVENT_EOF) {\n\t\tclose_after_write_cb(bufev, arg);\n\t}\n}\n\nstruct evws_connection *\nevws_new_session(\n\tstruct evhttp_request *req, ws_on_msg_cb cb, void *arg, int options)\n{\n\tstruct evws_connection *evws = NULL;\n\tstruct evkeyvalq *in_hdrs;\n\tconst char *upgrade, *connection, *ws_key, *ws_protocol;\n\tstruct evkeyvalq *out_hdrs;\n\tstruct evhttp_connection *evcon;\n\n\tin_hdrs = evhttp_request_get_input_headers(req);\n\tupgrade = evhttp_find_header(in_hdrs, \"Upgrade\");\n\tif (upgrade == NULL || evutil_ascii_strcasecmp(upgrade, \"websocket\"))\n\t\tgoto error;\n\n\tconnection = evhttp_find_header(in_hdrs, \"Connection\");\n\tif (connection == NULL || evutil_ascii_strcasestr(connection, \"Upgrade\") == NULL)\n\t\tgoto error;\n\n\tws_key = evhttp_find_header(in_hdrs, \"Sec-WebSocket-Key\");\n\tif (ws_key == NULL)\n\t\tgoto error;\n\n\tout_hdrs = evhttp_request_get_output_headers(req);\n\tevhttp_add_header(out_hdrs, \"Upgrade\", \"websocket\");\n\tevhttp_add_header(out_hdrs, \"Connection\", \"Upgrade\");\n\n\tevhttp_add_header(out_hdrs, \"Sec-WebSocket-Accept\",\n\t\tws_gen_accept_key(ws_key, (char[32]){0}));\n\n\tws_protocol = evhttp_find_header(in_hdrs, \"Sec-WebSocket-Protocol\");\n\tif (ws_protocol != NULL)\n\t\tevhttp_add_header(out_hdrs, \"Sec-WebSocket-Protocol\", ws_protocol);\n\n\tif ((evws = mm_calloc(1, sizeof(struct evws_connection))) == NULL) {\n\t\tevent_warn(\"%s: calloc failed\", __func__);\n\t\tgoto error;\n\t}\n\n\tevws->cb = cb;\n\tevws->cb_arg = arg;\n\n\tevcon = evhttp_request_get_connection(req);\n\tevws->http_server = evcon->http_server;\n\n\tevws->bufev = evhttp_start_ws_(req);\n\tif (evws->bufev == NULL) {\n\t\tgoto error;\n\t}\n\n\tif (options & BEV_OPT_THREADSAFE) {\n\t\tif (bufferevent_enable_locking_(evws->bufev, NULL) < 0)\n\t\t\tgoto error;\n\t}\n\n\tbufferevent_setcb(\n\t\tevws->bufev, ws_evhttp_read_cb, NULL, ws_evhttp_error_cb, evws);\n\n\tTAILQ_INSERT_TAIL(&evws->http_server->ws_sessions, evws, next);\n\tevws->http_server->connection_cnt++;\n\n\treturn evws;\n\nerror:\n\tif (evws)\n\t\tevws_connection_free(evws);\n\n\tevhttp_send_reply(req, HTTP_BADREQUEST, NULL, NULL);\n\treturn NULL;\n}\n\nstatic void\nmake_ws_frame(struct evbuffer *output, enum WebSocketFrameType frame_type,\n\tunsigned char *msg, size_t len)\n{\n\tsize_t pos = 0;\n\tunsigned char header[16] = {0};\n\n\theader[pos++] = (unsigned char)frame_type | 0x80; /* fin */\n\tif (len <= 125) {\n\t\theader[pos++] = len;\n\t} else if (len <= 65535) {\n\t\theader[pos++] = 126;\t\t\t   /* 16 bit length */\n\t\theader[pos++] = (len >> 8) & 0xFF; /* rightmost first */\n\t\theader[pos++] = len & 0xFF;\n\t} else {\t\t\t\t /* >2^16-1 */\n\t\tint i;\n\t\tconst uint64_t tmp64 = len;\n\t\theader[pos++] = 127;            /* 64 bit length */\n\t\t/* swap bytes from host byte order to big endian */\n\t\tfor (i = 56; i >= 0; i -= 8) {\n\t\t\theader[pos++] = tmp64 >> i & 0xFFu;\n\t\t}\n\t}\n\tevbuffer_add(output, header, pos);\n\tevbuffer_add(output, msg, len);\n}\n\nstatic void\nevws_send(struct evws_connection *evws, enum WebSocketFrameType frame_type,\n\tconst char *packet_str, size_t str_len)\n{\n\tstruct evbuffer *output;\n\n\tbufferevent_lock(evws->bufev);\n\toutput = bufferevent_get_output(evws->bufev);\n\tmake_ws_frame(output, frame_type, (unsigned char *)packet_str, str_len);\n\tbufferevent_unlock(evws->bufev);\n}\n\nvoid\nevws_send_text(struct evws_connection *evws, const char *packet_str)\n{\n\tevws_send(evws, TEXT_FRAME, packet_str, strlen(packet_str));\n}\n\nvoid\nevws_send_binary(\n\tstruct evws_connection *evws, const char *packet_data, size_t packet_len)\n{\n\tevws_send(evws, BINARY_FRAME, packet_data, packet_len);\n}\n\nvoid\nevws_connection_set_closecb(\n\tstruct evws_connection *evws, ws_on_close_cb cb, void *cbarg)\n{\n\tevws->cbclose = cb;\n\tevws->cbclose_arg = cbarg;\n}\n\nstruct bufferevent *\nevws_connection_get_bufferevent(struct evws_connection *evws)\n{\n\treturn evws->bufev;\n}\n"
        }
      ]
    }
  ]
}