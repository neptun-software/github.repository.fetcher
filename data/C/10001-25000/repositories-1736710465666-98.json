{
  "metadata": {
    "timestamp": 1736710465666,
    "page": 98,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "leandromoreira/ffmpeg-libav-tutorial",
      "stars": 10138,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1279296875,
          "content": "*pgm\nbuild/*\nbunny_1080p_60fps.mp4\nbunny_1s_gop.mp4\nbunny_1s_gop.mp4.ts\nbunny_1s_gop.mp4.webm\n.vscode\n.clangd\ncompile_commands.json"
        },
        {
          "name": "0_hello_world.c",
          "type": "blob",
          "size": 10.3857421875,
          "content": "/*\n * http://ffmpeg.org/doxygen/trunk/index.html\n *\n * Main components\n *\n * Format (Container) - a wrapper, providing sync, metadata and muxing for the streams.\n * Stream - a continuous stream (audio or video) of data over time.\n * Codec - defines how data are enCOded (from Frame to Packet)\n *        and DECoded (from Packet to Frame).\n * Packet - are the data (kind of slices of the stream data) to be decoded as raw frames.\n * Frame - a decoded raw frame (to be encoded or filtered).\n */\n\n#include <libavcodec/avcodec.h>\n#include <libavformat/avformat.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <stdlib.h>\n#include <string.h>\n#include <inttypes.h>\n\n// print out the steps and errors\nstatic void logging(const char *fmt, ...);\n// decode packets into frames\nstatic int decode_packet(AVPacket *pPacket, AVCodecContext *pCodecContext, AVFrame *pFrame);\n// save a frame into a .pgm file\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename);\n\nint main(int argc, const char *argv[])\n{\n  if (argc < 2) {\n    printf(\"You need to specify a media file.\\n\");\n    return -1;\n  }\n  \n  logging(\"initializing all the containers, codecs and protocols.\");\n\n  // AVFormatContext holds the header information from the format (Container)\n  // Allocating memory for this component\n  // http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html\n  AVFormatContext *pFormatContext = avformat_alloc_context();\n  if (!pFormatContext) {\n    logging(\"ERROR could not allocate memory for Format Context\");\n    return -1;\n  }\n\n  logging(\"opening the input file (%s) and loading format (container) header\", argv[1]);\n  // Open the file and read its header. The codecs are not opened.\n  // The function arguments are:\n  // AVFormatContext (the component we allocated memory for),\n  // url (filename),\n  // AVInputFormat (if you pass NULL it'll do the auto detect)\n  // and AVDictionary (which are options to the demuxer)\n  // http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49\n  if (avformat_open_input(&pFormatContext, argv[1], NULL, NULL) != 0) {\n    logging(\"ERROR could not open the file\");\n    return -1;\n  }\n\n  // now we have access to some information about our file\n  // since we read its header we can say what format (container) it's\n  // and some other information related to the format itself.\n  logging(\"format %s, duration %lld us, bit_rate %lld\", pFormatContext->iformat->name, pFormatContext->duration, pFormatContext->bit_rate);\n\n  logging(\"finding stream info from format\");\n  // read Packets from the Format to get stream information\n  // this function populates pFormatContext->streams\n  // (of size equals to pFormatContext->nb_streams)\n  // the arguments are:\n  // the AVFormatContext\n  // and options contains options for codec corresponding to i-th stream.\n  // On return each dictionary will be filled with options that were not found.\n  // https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb\n  if (avformat_find_stream_info(pFormatContext,  NULL) < 0) {\n    logging(\"ERROR could not get the stream info\");\n    return -1;\n  }\n\n  // the component that knows how to enCOde and DECode the stream\n  // it's the codec (audio or video)\n  // http://ffmpeg.org/doxygen/trunk/structAVCodec.html\n  AVCodec *pCodec = NULL;\n  // this component describes the properties of a codec used by the stream i\n  // https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html\n  AVCodecParameters *pCodecParameters =  NULL;\n  int video_stream_index = -1;\n\n  // loop though all the streams and print its main information\n  for (int i = 0; i < pFormatContext->nb_streams; i++)\n  {\n    AVCodecParameters *pLocalCodecParameters =  NULL;\n    pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n    logging(\"AVStream->time_base before open coded %d/%d\", pFormatContext->streams[i]->time_base.num, pFormatContext->streams[i]->time_base.den);\n    logging(\"AVStream->r_frame_rate before open coded %d/%d\", pFormatContext->streams[i]->r_frame_rate.num, pFormatContext->streams[i]->r_frame_rate.den);\n    logging(\"AVStream->start_time %\" PRId64, pFormatContext->streams[i]->start_time);\n    logging(\"AVStream->duration %\" PRId64, pFormatContext->streams[i]->duration);\n\n    logging(\"finding the proper decoder (CODEC)\");\n\n    AVCodec *pLocalCodec = NULL;\n\n    // finds the registered decoder for a codec ID\n    // https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca\n    pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n\n    if (pLocalCodec==NULL) {\n      logging(\"ERROR unsupported codec!\");\n      // In this example if the codec is not found we just skip it\n      continue;\n    }\n\n    // when the stream is a video we store its index, codec parameters and codec\n    if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n      if (video_stream_index == -1) {\n        video_stream_index = i;\n        pCodec = pLocalCodec;\n        pCodecParameters = pLocalCodecParameters;\n      }\n\n      logging(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n    } else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n      logging(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n    }\n\n    // print its name, id and bitrate\n    logging(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n  }\n\n  if (video_stream_index == -1) {\n    logging(\"File %s does not contain a video stream!\", argv[1]);\n    return -1;\n  }\n\n  // https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html\n  AVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\n  if (!pCodecContext)\n  {\n    logging(\"failed to allocated memory for AVCodecContext\");\n    return -1;\n  }\n\n  // Fill the codec context based on the values from the supplied codec parameters\n  // https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16\n  if (avcodec_parameters_to_context(pCodecContext, pCodecParameters) < 0)\n  {\n    logging(\"failed to copy codec params to codec context\");\n    return -1;\n  }\n\n  // Initialize the AVCodecContext to use the given AVCodec.\n  // https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d\n  if (avcodec_open2(pCodecContext, pCodec, NULL) < 0)\n  {\n    logging(\"failed to open codec through avcodec_open2\");\n    return -1;\n  }\n\n  // https://ffmpeg.org/doxygen/trunk/structAVFrame.html\n  AVFrame *pFrame = av_frame_alloc();\n  if (!pFrame)\n  {\n    logging(\"failed to allocate memory for AVFrame\");\n    return -1;\n  }\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html\n  AVPacket *pPacket = av_packet_alloc();\n  if (!pPacket)\n  {\n    logging(\"failed to allocate memory for AVPacket\");\n    return -1;\n  }\n\n  int response = 0;\n  int how_many_packets_to_process = 8;\n\n  // fill the Packet with data from the Stream\n  // https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61\n  while (av_read_frame(pFormatContext, pPacket) >= 0)\n  {\n    // if it's the video stream\n    if (pPacket->stream_index == video_stream_index) {\n    logging(\"AVPacket->pts %\" PRId64, pPacket->pts);\n      response = decode_packet(pPacket, pCodecContext, pFrame);\n      if (response < 0)\n        break;\n      // stop it, otherwise we'll be saving hundreds of frames\n      if (--how_many_packets_to_process <= 0) break;\n    }\n    // https://ffmpeg.org/doxygen/trunk/group__lavc__packet.html#ga63d5a489b419bd5d45cfd09091cbcbc2\n    av_packet_unref(pPacket);\n  }\n\n  logging(\"releasing all the resources\");\n\n  avformat_close_input(&pFormatContext);\n  av_packet_free(&pPacket);\n  av_frame_free(&pFrame);\n  avcodec_free_context(&pCodecContext);\n  return 0;\n}\n\nstatic void logging(const char *fmt, ...)\n{\n    va_list args;\n    fprintf( stderr, \"LOG: \" );\n    va_start( args, fmt );\n    vfprintf( stderr, fmt, args );\n    va_end( args );\n    fprintf( stderr, \"\\n\" );\n}\n\nstatic int decode_packet(AVPacket *pPacket, AVCodecContext *pCodecContext, AVFrame *pFrame)\n{\n  // Supply raw packet data as input to a decoder\n  // https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3\n  int response = avcodec_send_packet(pCodecContext, pPacket);\n\n  if (response < 0) {\n    logging(\"Error while sending a packet to the decoder: %s\", av_err2str(response));\n    return response;\n  }\n\n  while (response >= 0)\n  {\n    // Return decoded output data (into a frame) from a decoder\n    // https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c\n    response = avcodec_receive_frame(pCodecContext, pFrame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      logging(\"Error while receiving a frame from the decoder: %s\", av_err2str(response));\n      return response;\n    }\n\n    if (response >= 0) {\n      logging(\n          \"Frame %d (type=%c, size=%d bytes, format=%d) pts %d key_frame %d [DTS %d]\",\n          pCodecContext->frame_number,\n          av_get_picture_type_char(pFrame->pict_type),\n          pFrame->pkt_size,\n          pFrame->format,\n          pFrame->pts,\n          pFrame->key_frame,\n          pFrame->coded_picture_number\n      );\n\n      char frame_filename[1024];\n      snprintf(frame_filename, sizeof(frame_filename), \"%s-%d.pgm\", \"frame\", pCodecContext->frame_number);\n      // Check if the frame is a planar YUV 4:2:0, 12bpp\n      // That is the format of the provided .mp4 file\n      // RGB formats will definitely not give a gray image\n      // Other YUV image may do so, but untested, so give a warning\n      if (pFrame->format != AV_PIX_FMT_YUV420P)\n      {\n        logging(\"Warning: the generated file may not be a grayscale image, but could e.g. be just the R component if the video format is RGB\");\n      }\n      // save a grayscale frame into a .pgm file\n      save_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n    }\n  }\n  return 0;\n}\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    // writing the minimal required header for a pgm file format\n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // writing line by line\n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n"
        },
        {
          "name": "2_remuxing.c",
          "type": "blob",
          "size": 5.0966796875,
          "content": "// based on https://ffmpeg.org/doxygen/trunk/remuxing_8c-example.html\n#include <libavutil/timestamp.h>\n#include <libavformat/avformat.h>\n\nint main(int argc, char **argv)\n{\n  AVFormatContext *input_format_context = NULL, *output_format_context = NULL;\n  AVPacket packet;\n  const char *in_filename, *out_filename;\n  int ret, i;\n  int stream_index = 0;\n  int *streams_list = NULL;\n  int number_of_streams = 0;\n  int fragmented_mp4_options = 0;\n\n  if (argc < 3) {\n    printf(\"You need to pass at least two parameters.\\n\");\n    return -1;\n  } else if (argc == 4) {\n    fragmented_mp4_options = 1;\n  }\n\n  in_filename  = argv[1];\n  out_filename = argv[2];\n\n  if ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n    fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n    goto end;\n  }\n  if ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n    fprintf(stderr, \"Failed to retrieve input stream information\");\n    goto end;\n  }\n\n  avformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\n  if (!output_format_context) {\n    fprintf(stderr, \"Could not create output context\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n\n  number_of_streams = input_format_context->nb_streams;\n  streams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n\n  if (!streams_list) {\n    ret = AVERROR(ENOMEM);\n    goto end;\n  }\n\n  for (i = 0; i < input_format_context->nb_streams; i++) {\n    AVStream *out_stream;\n    AVStream *in_stream = input_format_context->streams[i];\n    AVCodecParameters *in_codecpar = in_stream->codecpar;\n    if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n        in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n        in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n      streams_list[i] = -1;\n      continue;\n    }\n    streams_list[i] = stream_index++;\n    out_stream = avformat_new_stream(output_format_context, NULL);\n    if (!out_stream) {\n      fprintf(stderr, \"Failed allocating output stream\\n\");\n      ret = AVERROR_UNKNOWN;\n      goto end;\n    }\n    ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n    if (ret < 0) {\n      fprintf(stderr, \"Failed to copy codec parameters\\n\");\n      goto end;\n    }\n  }\n  // https://ffmpeg.org/doxygen/trunk/group__lavf__misc.html#gae2645941f2dc779c307eb6314fd39f10\n  av_dump_format(output_format_context, 0, out_filename, 1);\n\n  // unless it's a no file (we'll talk later about that) write to the disk (FLAG_WRITE)\n  // but basically it's a way to save the file to a buffer so you can store it\n  // wherever you want.\n  if (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n    ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n    if (ret < 0) {\n      fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n      goto end;\n    }\n  }\n  AVDictionary* opts = NULL;\n\n  if (fragmented_mp4_options) {\n    // https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE\n    av_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\n  }\n  // https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga18b7b10bb5b94c4842de18166bc677cb\n  ret = avformat_write_header(output_format_context, &opts);\n  if (ret < 0) {\n    fprintf(stderr, \"Error occurred when opening output file\\n\");\n    goto end;\n  }\n  while (1) {\n    AVStream *in_stream, *out_stream;\n    ret = av_read_frame(input_format_context, &packet);\n    if (ret < 0)\n      break;\n    in_stream  = input_format_context->streams[packet.stream_index];\n    if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n      av_packet_unref(&packet);\n      continue;\n    }\n    packet.stream_index = streams_list[packet.stream_index];\n    out_stream = output_format_context->streams[packet.stream_index];\n    /* copy packet */\n    packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n    packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n    packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n    // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n    packet.pos = -1;\n\n    //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n    ret = av_interleaved_write_frame(output_format_context, &packet);\n    if (ret < 0) {\n      fprintf(stderr, \"Error muxing packet\\n\");\n      break;\n    }\n    av_packet_unref(&packet);\n  }\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13\n  av_write_trailer(output_format_context);\nend:\n  avformat_close_input(&input_format_context);\n  /* close output */\n  if (output_format_context && !(output_format_context->oformat->flags & AVFMT_NOFILE))\n    avio_closep(&output_format_context->pb);\n  avformat_free_context(output_format_context);\n  av_freep(&streams_list);\n  if (ret < 0 && ret != AVERROR_EOF) {\n    fprintf(stderr, \"Error occurred: %s\\n\", av_err2str(ret));\n    return 1;\n  }\n  return 0;\n}\n\n"
        },
        {
          "name": "3_transcoding.c",
          "type": "blob",
          "size": 14.826171875,
          "content": "#include <libavcodec/avcodec.h>\n#include <libavformat/avformat.h>\n#include <libavutil/timestamp.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <stdlib.h>\n#include <libavutil/opt.h>\n#include <string.h>\n#include <inttypes.h>\n#include \"video_debugging.h\"\n\ntypedef struct StreamingParams {\n  char copy_video;\n  char copy_audio;\n  char *output_extension;\n  char *muxer_opt_key;\n  char *muxer_opt_value;\n  char *video_codec;\n  char *audio_codec;\n  char *codec_priv_key;\n  char *codec_priv_value;\n} StreamingParams;\n\ntypedef struct StreamingContext {\n  AVFormatContext *avfc;\n  AVCodec *video_avc;\n  AVCodec *audio_avc;\n  AVStream *video_avs;\n  AVStream *audio_avs;\n  AVCodecContext *video_avcc;\n  AVCodecContext *audio_avcc;\n  int video_index;\n  int audio_index;\n  char *filename;\n} StreamingContext;\n\nint fill_stream_info(AVStream *avs, AVCodec **avc, AVCodecContext **avcc) {\n  *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  if (!*avc) {logging(\"failed to find the codec\"); return -1;}\n\n  *avcc = avcodec_alloc_context3(*avc);\n  if (!*avcc) {logging(\"failed to alloc memory for codec context\"); return -1;}\n\n  if (avcodec_parameters_to_context(*avcc, avs->codecpar) < 0) {logging(\"failed to fill codec context\"); return -1;}\n\n  if (avcodec_open2(*avcc, *avc, NULL) < 0) {logging(\"failed to open codec\"); return -1;}\n  return 0;\n}\n\nint open_media(const char *in_filename, AVFormatContext **avfc) {\n  *avfc = avformat_alloc_context();\n  if (!*avfc) {logging(\"failed to alloc memory for format\"); return -1;}\n\n  if (avformat_open_input(avfc, in_filename, NULL, NULL) != 0) {logging(\"failed to open input file %s\", in_filename); return -1;}\n\n  if (avformat_find_stream_info(*avfc, NULL) < 0) {logging(\"failed to get stream info\"); return -1;}\n  return 0;\n}\n\nint prepare_decoder(StreamingContext *sc) {\n  for (int i = 0; i < sc->avfc->nb_streams; i++) {\n    if (sc->avfc->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n      sc->video_avs = sc->avfc->streams[i];\n      sc->video_index = i;\n\n      if (fill_stream_info(sc->video_avs, &sc->video_avc, &sc->video_avcc)) {return -1;}\n    } else if (sc->avfc->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n      sc->audio_avs = sc->avfc->streams[i];\n      sc->audio_index = i;\n\n      if (fill_stream_info(sc->audio_avs, &sc->audio_avc, &sc->audio_avcc)) {return -1;}\n    } else {\n      logging(\"skipping streams other than audio and video\");\n    }\n  }\n\n  return 0;\n}\n\nint prepare_video_encoder(StreamingContext *sc, AVCodecContext *decoder_ctx, AVRational input_framerate, StreamingParams sp) {\n  sc->video_avs = avformat_new_stream(sc->avfc, NULL);\n\n  sc->video_avc = avcodec_find_encoder_by_name(sp.video_codec);\n  if (!sc->video_avc) {logging(\"could not find the proper codec\"); return -1;}\n\n  sc->video_avcc = avcodec_alloc_context3(sc->video_avc);\n  if (!sc->video_avcc) {logging(\"could not allocated memory for codec context\"); return -1;}\n\n  av_opt_set(sc->video_avcc->priv_data, \"preset\", \"fast\", 0);\n  if (sp.codec_priv_key && sp.codec_priv_value)\n    av_opt_set(sc->video_avcc->priv_data, sp.codec_priv_key, sp.codec_priv_value, 0);\n\n  sc->video_avcc->height = decoder_ctx->height;\n  sc->video_avcc->width = decoder_ctx->width;\n  sc->video_avcc->sample_aspect_ratio = decoder_ctx->sample_aspect_ratio;\n  if (sc->video_avc->pix_fmts)\n    sc->video_avcc->pix_fmt = sc->video_avc->pix_fmts[0];\n  else\n    sc->video_avcc->pix_fmt = decoder_ctx->pix_fmt;\n\n  sc->video_avcc->bit_rate = 2 * 1000 * 1000;\n  sc->video_avcc->rc_buffer_size = 4 * 1000 * 1000;\n  sc->video_avcc->rc_max_rate = 2 * 1000 * 1000;\n  sc->video_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n\n  sc->video_avcc->time_base = av_inv_q(input_framerate);\n  sc->video_avs->time_base = sc->video_avcc->time_base;\n\n  if (avcodec_open2(sc->video_avcc, sc->video_avc, NULL) < 0) {logging(\"could not open the codec\"); return -1;}\n  avcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n  return 0;\n}\n\nint prepare_audio_encoder(StreamingContext *sc, int sample_rate, StreamingParams sp){\n  sc->audio_avs = avformat_new_stream(sc->avfc, NULL);\n\n  sc->audio_avc = avcodec_find_encoder_by_name(sp.audio_codec);\n  if (!sc->audio_avc) {logging(\"could not find the proper codec\"); return -1;}\n\n  sc->audio_avcc = avcodec_alloc_context3(sc->audio_avc);\n  if (!sc->audio_avcc) {logging(\"could not allocated memory for codec context\"); return -1;}\n\n  int OUTPUT_CHANNELS = 2;\n  int OUTPUT_BIT_RATE = 196000;\n  sc->audio_avcc->channels       = OUTPUT_CHANNELS;\n  sc->audio_avcc->channel_layout = av_get_default_channel_layout(OUTPUT_CHANNELS);\n  sc->audio_avcc->sample_rate    = sample_rate;\n  sc->audio_avcc->sample_fmt     = sc->audio_avc->sample_fmts[0];\n  sc->audio_avcc->bit_rate       = OUTPUT_BIT_RATE;\n  sc->audio_avcc->time_base      = (AVRational){1, sample_rate};\n\n  sc->audio_avcc->strict_std_compliance = FF_COMPLIANCE_EXPERIMENTAL;\n\n  sc->audio_avs->time_base = sc->audio_avcc->time_base;\n\n  if (avcodec_open2(sc->audio_avcc, sc->audio_avc, NULL) < 0) {logging(\"could not open the codec\"); return -1;}\n  avcodec_parameters_from_context(sc->audio_avs->codecpar, sc->audio_avcc);\n  return 0;\n}\n\nint prepare_copy(AVFormatContext *avfc, AVStream **avs, AVCodecParameters *decoder_par) {\n  *avs = avformat_new_stream(avfc, NULL);\n  avcodec_parameters_copy((*avs)->codecpar, decoder_par);\n  return 0;\n}\n\nint remux(AVPacket **pkt, AVFormatContext **avfc, AVRational decoder_tb, AVRational encoder_tb) {\n  av_packet_rescale_ts(*pkt, decoder_tb, encoder_tb);\n  if (av_interleaved_write_frame(*avfc, *pkt) < 0) { logging(\"error while copying stream packet\"); return -1; }\n  return 0;\n}\n\nint encode_video(StreamingContext *decoder, StreamingContext *encoder, AVFrame *input_frame) {\n  if (input_frame) input_frame->pict_type = AV_PICTURE_TYPE_NONE;\n\n  AVPacket *output_packet = av_packet_alloc();\n  if (!output_packet) {logging(\"could not allocate memory for output packet\"); return -1;}\n\n  int response = avcodec_send_frame(encoder->video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(encoder->video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      logging(\"Error while receiving packet from encoder: %s\", av_err2str(response));\n      return -1;\n    }\n\n    output_packet->stream_index = decoder->video_index;\n    output_packet->duration = encoder->video_avs->time_base.den / encoder->video_avs->time_base.num / decoder->video_avs->avg_frame_rate.num * decoder->video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, decoder->video_avs->time_base, encoder->video_avs->time_base);\n    response = av_interleaved_write_frame(encoder->avfc, output_packet);\n    if (response != 0) { logging(\"Error %d while receiving packet from decoder: %s\", response, av_err2str(response)); return -1;}\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\nint encode_audio(StreamingContext *decoder, StreamingContext *encoder, AVFrame *input_frame) {\n  AVPacket *output_packet = av_packet_alloc();\n  if (!output_packet) {logging(\"could not allocate memory for output packet\"); return -1;}\n\n  int response = avcodec_send_frame(encoder->audio_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(encoder->audio_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      logging(\"Error while receiving packet from encoder: %s\", av_err2str(response));\n      return -1;\n    }\n\n    output_packet->stream_index = decoder->audio_index;\n\n    av_packet_rescale_ts(output_packet, decoder->audio_avs->time_base, encoder->audio_avs->time_base);\n    response = av_interleaved_write_frame(encoder->avfc, output_packet);\n    if (response != 0) { logging(\"Error %d while receiving packet from decoder: %s\", response, av_err2str(response)); return -1;}\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\nint transcode_audio(StreamingContext *decoder, StreamingContext *encoder, AVPacket *input_packet, AVFrame *input_frame) {\n  int response = avcodec_send_packet(decoder->audio_avcc, input_packet);\n  if (response < 0) {logging(\"Error while sending packet to decoder: %s\", av_err2str(response)); return response;}\n\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder->audio_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      logging(\"Error while receiving frame from decoder: %s\", av_err2str(response));\n      return response;\n    }\n\n    if (response >= 0) {\n      if (encode_audio(decoder, encoder, input_frame)) return -1;\n    }\n    av_frame_unref(input_frame);\n  }\n  return 0;\n}\n\nint transcode_video(StreamingContext *decoder, StreamingContext *encoder, AVPacket *input_packet, AVFrame *input_frame) {\n  int response = avcodec_send_packet(decoder->video_avcc, input_packet);\n  if (response < 0) {logging(\"Error while sending packet to decoder: %s\", av_err2str(response)); return response;}\n\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder->video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      logging(\"Error while receiving frame from decoder: %s\", av_err2str(response));\n      return response;\n    }\n\n    if (response >= 0) {\n      if (encode_video(decoder, encoder, input_frame)) return -1;\n    }\n    av_frame_unref(input_frame);\n  }\n  return 0;\n}\n\nint main(int argc, char *argv[])\n{\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 1;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libx264\";\n  //sp.codec_priv_key = \"x264-params\";\n  //sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 1;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libx264\";\n  //sp.codec_priv_key = \"x264-params\";\n  //sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  //sp.muxer_opt_key = \"movflags\";\n  //sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libx264\";\n  //sp.codec_priv_key = \"x264-params\";\n  //sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  //sp.audio_codec = \"aac\";\n  //sp.output_extension = \".ts\";\n\n  /*\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n\n  StreamingContext *decoder = (StreamingContext*) calloc(1, sizeof(StreamingContext));\n  decoder->filename = argv[1];\n\n  StreamingContext *encoder = (StreamingContext*) calloc(1, sizeof(StreamingContext));\n  encoder->filename = argv[2];\n\n  if (sp.output_extension)\n    strcat(encoder->filename, sp.output_extension);\n\n  if (open_media(decoder->filename, &decoder->avfc)) return -1;\n  if (prepare_decoder(decoder)) return -1;\n\n  avformat_alloc_output_context2(&encoder->avfc, NULL, NULL, encoder->filename);\n  if (!encoder->avfc) {logging(\"could not allocate memory for output format\");return -1;}\n\n  if (!sp.copy_video) {\n    AVRational input_framerate = av_guess_frame_rate(decoder->avfc, decoder->video_avs, NULL);\n    prepare_video_encoder(encoder, decoder->video_avcc, input_framerate, sp);\n  } else {\n    if (prepare_copy(encoder->avfc, &encoder->video_avs, decoder->video_avs->codecpar)) {return -1;}\n  }\n\n  if (!sp.copy_audio) {\n    if (prepare_audio_encoder(encoder, decoder->audio_avcc->sample_rate, sp)) {return -1;}\n  } else {\n    if (prepare_copy(encoder->avfc, &encoder->audio_avs, decoder->audio_avs->codecpar)) {return -1;}\n  }\n\n  if (encoder->avfc->oformat->flags & AVFMT_GLOBALHEADER)\n    encoder->avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\n  if (!(encoder->avfc->oformat->flags & AVFMT_NOFILE)) {\n    if (avio_open(&encoder->avfc->pb, encoder->filename, AVIO_FLAG_WRITE) < 0) {\n      logging(\"could not open the output file\");\n      return -1;\n    }\n  }\n\n  AVDictionary* muxer_opts = NULL;\n\n  if (sp.muxer_opt_key && sp.muxer_opt_value) {\n    av_dict_set(&muxer_opts, sp.muxer_opt_key, sp.muxer_opt_value, 0);\n  }\n\n  if (avformat_write_header(encoder->avfc, &muxer_opts) < 0) {logging(\"an error occurred when opening output file\"); return -1;}\n\n  AVFrame *input_frame = av_frame_alloc();\n  if (!input_frame) {logging(\"failed to allocated memory for AVFrame\"); return -1;}\n\n  AVPacket *input_packet = av_packet_alloc();\n  if (!input_packet) {logging(\"failed to allocated memory for AVPacket\"); return -1;}\n\n  while (av_read_frame(decoder->avfc, input_packet) >= 0)\n  {\n    if (decoder->avfc->streams[input_packet->stream_index]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n      if (!sp.copy_video) {\n        // TODO: refactor to be generic for audio and video (receiving a function pointer to the differences)\n        if (transcode_video(decoder, encoder, input_packet, input_frame)) return -1;\n        av_packet_unref(input_packet);\n      } else {\n        if (remux(&input_packet, &encoder->avfc, decoder->video_avs->time_base, encoder->video_avs->time_base)) return -1;\n      }\n    } else if (decoder->avfc->streams[input_packet->stream_index]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO)  {\n      if (!sp.copy_audio) {\n        if (transcode_audio(decoder, encoder, input_packet, input_frame)) return -1;\n        av_packet_unref(input_packet);\n      } else {\n        if (remux(&input_packet, &encoder->avfc, decoder->audio_avs->time_base, encoder->audio_avs->time_base)) return -1;\n      }\n    } else {\n      logging(\"ignoring all non video or audio packets\");\n    }\n  }\n  // TODO: should I also flush the audio encoder?\n  if (encode_video(decoder, encoder, NULL)) return -1;\n\n  av_write_trailer(encoder->avfc);\n\n  if (muxer_opts != NULL) {\n    av_dict_free(&muxer_opts);\n    muxer_opts = NULL;\n  }\n\n  if (input_frame != NULL) {\n    av_frame_free(&input_frame);\n    input_frame = NULL;\n  }\n\n  if (input_packet != NULL) {\n    av_packet_free(&input_packet);\n    input_packet = NULL;\n  }\n\n  avformat_close_input(&decoder->avfc);\n\n  avformat_free_context(decoder->avfc); decoder->avfc = NULL;\n  avformat_free_context(encoder->avfc); encoder->avfc = NULL;\n\n  avcodec_free_context(&decoder->video_avcc); decoder->video_avcc = NULL;\n  avcodec_free_context(&decoder->audio_avcc); decoder->audio_avcc = NULL;\n\n  free(decoder); decoder = NULL;\n  free(encoder); encoder = NULL;\n  return 0;\n}\n\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 1.2666015625,
          "content": "cmake_minimum_required(VERSION 3.17)\nproject(libav_tutorial)\n\n# set out directory\nset(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)\nset(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# set ffmpeg root directory\nif(NOT FFMPEG_DEV_ROOT)\n    message(FATAL_ERROR \"set FFMPEG_DEV_ROOT to use ffmpeg libraries\")\nendif()\n\n# set ffmpeg develop environment\ninclude_directories(${FFMPEG_DEV_ROOT}/include)\nlink_directories(${FFMPEG_DEV_ROOT}/lib)\nlink_libraries(\n    avcodec\n    avformat\n    avfilter\n    avdevice\n    swresample\n    swscale\n    avutil\n)\n\n# copy dlls \nfile(GLOB ffmpeg_shared_libries ${FFMPEG_DEV_ROOT}/bin/*dll)\nfile(COPY ${ffmpeg_shared_libries} DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY})\n\n# copy test file\nfile(COPY ${CMAKE_CURRENT_SOURCE_DIR}/small_bunny_1080p_60fps.mp4 DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY})\n\n\n# add library\nset(debug_src ${CMAKE_CURRENT_SOURCE_DIR}/video_debugging.c)\nadd_library(video_debug ${debug_src})\nlink_libraries(video_debug)\n\n# add project/executables\nfile(GLOB srcs *.c)\nlist(REMOVE_ITEM srcs ${debug_src})\nforeach(src  ${srcs})\n    get_filename_component(TARGET ${src} NAME)\n    add_executable(${TARGET} ${src})\n    message(STATUS \"${TARGET} added\")\nendforeach()\n\n\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 22.2080078125,
          "content": "# ffmpeg - http://ffmpeg.org/download.html\n#\n# From https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu\n#\n# https://hub.docker.com/r/jrottenberg/ffmpeg/\n#\n#\nFROM        ubuntu:20.04 AS base\n\nWORKDIR     /tmp/workdir\n\nRUN     apt-get -yqq update && \\\n        apt-get install -yq --no-install-recommends ca-certificates expat libgomp1 && \\\n        apt-get autoremove -y && \\\n        apt-get clean -y\n\nFROM base as build\n\nENV         FFMPEG_VERSION=4.4 \\\n            AOM_VERSION=v1.0.0 \\\n            FDKAAC_VERSION=0.1.5 \\\n            FONTCONFIG_VERSION=2.12.4 \\\n            FREETYPE_VERSION=2.10.4 \\\n            FRIBIDI_VERSION=0.19.7 \\\n            KVAZAAR_VERSION=2.0.0 \\\n            LAME_VERSION=3.100 \\\n            LIBASS_VERSION=0.13.7 \\\n            LIBPTHREAD_STUBS_VERSION=0.4 \\\n            LIBVIDSTAB_VERSION=1.1.0 \\\n            LIBXCB_VERSION=1.13.1 \\\n            XCBPROTO_VERSION=1.13 \\\n            OGG_VERSION=1.3.2 \\\n            OPENCOREAMR_VERSION=0.1.5 \\\n            OPUS_VERSION=1.2 \\\n            OPENJPEG_VERSION=2.1.2 \\\n            THEORA_VERSION=1.1.1 \\\n            VORBIS_VERSION=1.3.5 \\\n            VPX_VERSION=1.8.0 \\\n            WEBP_VERSION=1.0.2 \\\n            X264_VERSION=20170226-2245-stable \\\n            X265_VERSION=3.4 \\\n            XAU_VERSION=1.0.9 \\\n            XORG_MACROS_VERSION=1.19.2 \\\n            XPROTO_VERSION=7.0.31 \\\n            XVID_VERSION=1.3.4 \\\n            LIBXML2_VERSION=2.9.10 \\\n            LIBBLURAY_VERSION=1.1.2 \\\n            LIBZMQ_VERSION=4.3.2 \\\n            LIBSRT_VERSION=1.4.1 \\\n            LIBARIBB24_VERSION=1.0.3 \\\n            LIBPNG_VERSION=1.6.9 \\\n            LIBVMAF_VERSION=2.1.1 \\\n            SRC=/usr/local\n\nARG         FREETYPE_SHA256SUM=\"5eab795ebb23ac77001cfb68b7d4d50b5d6c7469247b0b01b2c953269f658dac freetype-2.10.4.tar.gz\"\nARG         FRIBIDI_SHA256SUM=\"3fc96fa9473bd31dcb5500bdf1aa78b337ba13eb8c301e7c28923fea982453a8 0.19.7.tar.gz\"\nARG         LIBASS_SHA256SUM=\"8fadf294bf701300d4605e6f1d92929304187fca4b8d8a47889315526adbafd7 0.13.7.tar.gz\"\nARG         LIBVIDSTAB_SHA256SUM=\"14d2a053e56edad4f397be0cb3ef8eb1ec3150404ce99a426c4eb641861dc0bb v1.1.0.tar.gz\"\nARG         OGG_SHA256SUM=\"e19ee34711d7af328cb26287f4137e70630e7261b17cbe3cd41011d73a654692 libogg-1.3.2.tar.gz\"\nARG         OPUS_SHA256SUM=\"77db45a87b51578fbc49555ef1b10926179861d854eb2613207dc79d9ec0a9a9 opus-1.2.tar.gz\"\nARG         THEORA_SHA256SUM=\"40952956c47811928d1e7922cda3bc1f427eb75680c3c37249c91e949054916b libtheora-1.1.1.tar.gz\"\nARG         VORBIS_SHA256SUM=\"6efbcecdd3e5dfbf090341b485da9d176eb250d893e3eb378c428a2db38301ce libvorbis-1.3.5.tar.gz\"\nARG         XVID_SHA256SUM=\"4e9fd62728885855bc5007fe1be58df42e5e274497591fec37249e1052ae316f xvidcore-1.3.4.tar.gz\"\nARG         LIBXML2_SHA256SUM=\"f07dab13bf42d2b8db80620cce7419b3b87827cc937c8bb20fe13b8571ee9501  libxml2-v2.9.10.tar.gz\"\nARG         LIBBLURAY_SHA256SUM=\"a3dd452239b100dc9da0d01b30e1692693e2a332a7d29917bf84bb10ea7c0b42 libbluray-1.1.2.tar.bz2\"\nARG         LIBZMQ_SHA256SUM=\"02ecc88466ae38cf2c8d79f09cfd2675ba299a439680b64ade733e26a349edeb v4.3.2.tar.gz\"\nARG         LIBARIBB24_SHA256SUM=\"f61560738926e57f9173510389634d8c06cabedfa857db4b28fb7704707ff128 v1.0.3.tar.gz\"\nARG         LIBVMAF_SHA256SUM=\"e7fc00ae1322a7eccfcf6d4f1cdf9c67eec8058709887c8c6c3795c617326f77 v2.1.1.tar.gz\"\n\n\nARG         LD_LIBRARY_PATH=/opt/ffmpeg/lib\nARG         MAKEFLAGS=\"-j2\"\nARG         PKG_CONFIG_PATH=\"/opt/ffmpeg/share/pkgconfig:/opt/ffmpeg/lib/pkgconfig:/opt/ffmpeg/lib64/pkgconfig\"\nARG         PREFIX=/opt/ffmpeg\nARG         LD_LIBRARY_PATH=\"/opt/ffmpeg/lib:/opt/ffmpeg/lib64\"\n\n\nARG DEBIAN_FRONTEND=noninteractive\n\nRUN      buildDeps=\"autoconf \\\n                    automake \\\n                    cmake \\\n                    curl \\\n                    bzip2 \\\n                    libexpat1-dev \\\n                    g++ \\\n                    gcc \\\n                    git \\\n                    gperf \\\n                    libtool \\\n                    make \\\n                    meson \\\n                    nasm \\\n                    perl \\\n                    pkg-config \\\n                    python \\\n                    libssl-dev \\\n                    yasm \\\n                    zlib1g-dev\" && \\\n        apt-get -yqq update && \\\n        apt-get install -yq --no-install-recommends ${buildDeps}\n## libvmaf https://github.com/Netflix/vmaf\nRUN \\\n        if which meson || false; then \\\n                echo \"Building VMAF.\" && \\\n                DIR=/tmp/vmaf && \\\n                mkdir -p ${DIR} && \\\n                cd ${DIR} && \\\n                curl -sLO https://github.com/Netflix/vmaf/archive/v${LIBVMAF_VERSION}.tar.gz && \\\n                tar -xz --strip-components=1 -f v${LIBVMAF_VERSION}.tar.gz && \\\n                cd /tmp/vmaf/libvmaf && \\\n                meson build --buildtype release --prefix=${PREFIX} && \\\n                ninja -vC build && \\\n                ninja -vC build install && \\\n                mkdir -p ${PREFIX}/share/model/ && \\\n                cp -r /tmp/vmaf/model/* ${PREFIX}/share/model/ && \\\n                rm -rf ${DIR}; \\\n        else \\\n                echo \"VMAF skipped.\"; \\\n        fi\n\n## opencore-amr https://sourceforge.net/projects/opencore-amr/\nRUN \\\n        DIR=/tmp/opencore-amr && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://versaweb.dl.sourceforge.net/project/opencore-amr/opencore-amr/opencore-amr-${OPENCOREAMR_VERSION}.tar.gz | \\\n        tar -zx --strip-components=1 && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared  && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## x264 http://www.videolan.org/developers/x264.html\nRUN \\\n        DIR=/tmp/x264 && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://download.videolan.org/pub/videolan/x264/snapshots/x264-snapshot-${X264_VERSION}.tar.bz2 | \\\n        tar -jx --strip-components=1 && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared --enable-pic --disable-cli && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### x265 http://x265.org/\nRUN \\\n        DIR=/tmp/x265 && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://github.com/videolan/x265/archive/refs/tags/${X265_VERSION}.tar.gz | \\\n        tar -zx && \\\n        cd x265-${X265_VERSION}/build/linux && \\\n        sed -i \"/-DEXTRA_LIB/ s/$/ -DCMAKE_INSTALL_PREFIX=\\${PREFIX}/\" multilib.sh && \\\n        sed -i \"/^cmake/ s/$/ -DENABLE_CLI=OFF/\" multilib.sh && \\\n        ./multilib.sh && \\\n        make -C 8bit install && \\\n        rm -rf ${DIR}\n### libogg https://www.xiph.org/ogg/\nRUN \\\n        DIR=/tmp/ogg && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO http://downloads.xiph.org/releases/ogg/libogg-${OGG_VERSION}.tar.gz && \\\n        echo ${OGG_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f libogg-${OGG_VERSION}.tar.gz && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared  && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libopus https://www.opus-codec.org/\nRUN \\\n        DIR=/tmp/opus && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://archive.mozilla.org/pub/opus/opus-${OPUS_VERSION}.tar.gz && \\\n        echo ${OPUS_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f opus-${OPUS_VERSION}.tar.gz && \\\n        autoreconf -fiv && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libvorbis https://xiph.org/vorbis/\nRUN \\\n        DIR=/tmp/vorbis && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO http://downloads.xiph.org/releases/vorbis/libvorbis-${VORBIS_VERSION}.tar.gz && \\\n        echo ${VORBIS_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f libvorbis-${VORBIS_VERSION}.tar.gz && \\\n        ./configure --prefix=\"${PREFIX}\" --with-ogg=\"${PREFIX}\" --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libtheora http://www.theora.org/\nRUN \\\n        DIR=/tmp/theora && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO http://downloads.xiph.org/releases/theora/libtheora-${THEORA_VERSION}.tar.gz && \\\n        echo ${THEORA_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f libtheora-${THEORA_VERSION}.tar.gz && \\\n        ./configure --prefix=\"${PREFIX}\" --with-ogg=\"${PREFIX}\" --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libvpx https://www.webmproject.org/code/\nRUN \\\n        DIR=/tmp/vpx && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://codeload.github.com/webmproject/libvpx/tar.gz/v${VPX_VERSION} | \\\n        tar -zx --strip-components=1 && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-vp8 --enable-vp9 --enable-vp9-highbitdepth --enable-pic --enable-shared \\\n        --disable-debug --disable-examples --disable-docs --disable-install-bins  && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libwebp https://developers.google.com/speed/webp/\nRUN \\\n        DIR=/tmp/vebp && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://storage.googleapis.com/downloads.webmproject.org/releases/webp/libwebp-${WEBP_VERSION}.tar.gz | \\\n        tar -zx --strip-components=1 && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared  && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### libmp3lame http://lame.sourceforge.net/\nRUN \\\n        DIR=/tmp/lame && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://versaweb.dl.sourceforge.net/project/lame/lame/$(echo ${LAME_VERSION} | sed -e 's/[^0-9]*\\([0-9]*\\)[.]\\([0-9]*\\)[.]\\([0-9]*\\)\\([0-9A-Za-z-]*\\)/\\1.\\2/')/lame-${LAME_VERSION}.tar.gz | \\\n        tar -zx --strip-components=1 && \\\n        ./configure --prefix=\"${PREFIX}\" --bindir=\"${PREFIX}/bin\" --enable-shared --enable-nasm --disable-frontend && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### xvid https://www.xvid.com/\nRUN \\\n        DIR=/tmp/xvid && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://xvid.com/downloads/xvidcore-${XVID_VERSION}.tar.gz && \\\n        echo ${XVID_SHA256SUM} | sha256sum --check && \\\n        tar -zx -f xvidcore-${XVID_VERSION}.tar.gz && \\\n        cd xvidcore/build/generic && \\\n        ./configure --prefix=\"${PREFIX}\" --bindir=\"${PREFIX}/bin\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n### fdk-aac https://github.com/mstorsjo/fdk-aac\nRUN \\\n        DIR=/tmp/fdk-aac && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://github.com/mstorsjo/fdk-aac/archive/v${FDKAAC_VERSION}.tar.gz | \\\n        tar -zx --strip-components=1 && \\\n        autoreconf -fiv && \\\n        ./configure --prefix=\"${PREFIX}\" --enable-shared --datadir=\"${DIR}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## openjpeg https://github.com/uclouvain/openjpeg\nRUN \\\n        DIR=/tmp/openjpeg && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sL https://github.com/uclouvain/openjpeg/archive/v${OPENJPEG_VERSION}.tar.gz | \\\n        tar -zx --strip-components=1 && \\\n        cmake -DBUILD_THIRDPARTY:BOOL=ON -DCMAKE_INSTALL_PREFIX=\"${PREFIX}\" . && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## freetype https://www.freetype.org/\nRUN  \\\n        DIR=/tmp/freetype && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://download.savannah.gnu.org/releases/freetype/freetype-${FREETYPE_VERSION}.tar.gz && \\\n        echo ${FREETYPE_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f freetype-${FREETYPE_VERSION}.tar.gz && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## libvstab https://github.com/georgmartius/vid.stab\nRUN  \\\n        DIR=/tmp/vid.stab && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/georgmartius/vid.stab/archive/v${LIBVIDSTAB_VERSION}.tar.gz && \\\n        echo ${LIBVIDSTAB_SHA256SUM} | sha256sum --check &&  \\\n        tar -zx --strip-components=1 -f v${LIBVIDSTAB_VERSION}.tar.gz && \\\n        cmake -DCMAKE_INSTALL_PREFIX=\"${PREFIX}\" . && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## fridibi https://www.fribidi.org/\nRUN  \\\n        DIR=/tmp/fribidi && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/fribidi/fribidi/archive/${FRIBIDI_VERSION}.tar.gz && \\\n        echo ${FRIBIDI_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f ${FRIBIDI_VERSION}.tar.gz && \\\n        sed -i 's/^SUBDIRS =.*/SUBDIRS=gen.tab charset lib bin/' Makefile.am && \\\n        ./bootstrap --no-config --auto && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make -j1 && \\\n        make install && \\\n        rm -rf ${DIR}\n## fontconfig https://www.freedesktop.org/wiki/Software/fontconfig/\nRUN  \\\n        DIR=/tmp/fontconfig && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://www.freedesktop.org/software/fontconfig/release/fontconfig-${FONTCONFIG_VERSION}.tar.bz2 && \\\n        tar -jx --strip-components=1 -f fontconfig-${FONTCONFIG_VERSION}.tar.bz2 && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## libass https://github.com/libass/libass\nRUN  \\\n        DIR=/tmp/libass && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/libass/libass/archive/${LIBASS_VERSION}.tar.gz && \\\n        echo ${LIBASS_SHA256SUM} | sha256sum --check && \\\n        tar -zx --strip-components=1 -f ${LIBASS_VERSION}.tar.gz && \\\n        ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n## kvazaar https://github.com/ultravideo/kvazaar\nRUN \\\n        DIR=/tmp/kvazaar && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/ultravideo/kvazaar/archive/v${KVAZAAR_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f v${KVAZAAR_VERSION}.tar.gz && \\\n        ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/aom && \\\n        git clone --branch ${AOM_VERSION} --depth 1 https://aomedia.googlesource.com/aom ${DIR} ; \\\n        cd ${DIR} ; \\\n        rm -rf CMakeCache.txt CMakeFiles ; \\\n        mkdir -p ./aom_build ; \\\n        cd ./aom_build ; \\\n        cmake -DCMAKE_INSTALL_PREFIX=\"${PREFIX}\" -DBUILD_SHARED_LIBS=1 ..; \\\n        make ; \\\n        make install ; \\\n        rm -rf ${DIR}\n\n## libxcb (and supporting libraries) for screen capture https://xcb.freedesktop.org/\nRUN \\\n        DIR=/tmp/xorg-macros && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://www.x.org/archive//individual/util/util-macros-${XORG_MACROS_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f util-macros-${XORG_MACROS_VERSION}.tar.gz && \\\n        ./configure --srcdir=${DIR} --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/xproto && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://www.x.org/archive/individual/proto/xproto-${XPROTO_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f xproto-${XPROTO_VERSION}.tar.gz && \\\n        ./configure --srcdir=${DIR} --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/libXau && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://www.x.org/archive/individual/lib/libXau-${XAU_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f libXau-${XAU_VERSION}.tar.gz && \\\n        ./configure --srcdir=${DIR} --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/libpthread-stubs && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://xcb.freedesktop.org/dist/libpthread-stubs-${LIBPTHREAD_STUBS_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f libpthread-stubs-${LIBPTHREAD_STUBS_VERSION}.tar.gz && \\\n        ./configure --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/libxcb-proto && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://xcb.freedesktop.org/dist/xcb-proto-${XCBPROTO_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f xcb-proto-${XCBPROTO_VERSION}.tar.gz && \\\n        ACLOCAL_PATH=\"${PREFIX}/share/aclocal\" ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\nRUN \\\n        DIR=/tmp/libxcb && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://xcb.freedesktop.org/dist/libxcb-${LIBXCB_VERSION}.tar.gz && \\\n        tar -zx --strip-components=1 -f libxcb-${LIBXCB_VERSION}.tar.gz && \\\n        ACLOCAL_PATH=\"${PREFIX}/share/aclocal\" ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libxml2 - for libbluray\nRUN \\\n        DIR=/tmp/libxml2 && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://gitlab.gnome.org/GNOME/libxml2/-/archive/v${LIBXML2_VERSION}/libxml2-v${LIBXML2_VERSION}.tar.gz && \\\n        echo ${LIBXML2_SHA256SUM} | sha256sum --check && \\\n        tar -xz --strip-components=1 -f libxml2-v${LIBXML2_VERSION}.tar.gz && \\\n        ./autogen.sh --prefix=\"${PREFIX}\" --with-ftp=no --with-http=no --with-python=no && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libbluray - Requires libxml, freetype, and fontconfig\nRUN \\\n        DIR=/tmp/libbluray && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://download.videolan.org/pub/videolan/libbluray/${LIBBLURAY_VERSION}/libbluray-${LIBBLURAY_VERSION}.tar.bz2 && \\\n        echo ${LIBBLURAY_SHA256SUM} | sha256sum --check && \\\n        tar -jx --strip-components=1 -f libbluray-${LIBBLURAY_VERSION}.tar.bz2 && \\\n        ./configure --prefix=\"${PREFIX}\" --disable-examples --disable-bdjava-jar --disable-static --enable-shared && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libzmq https://github.com/zeromq/libzmq/\nRUN \\\n        DIR=/tmp/libzmq && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/zeromq/libzmq/archive/v${LIBZMQ_VERSION}.tar.gz && \\\n        echo ${LIBZMQ_SHA256SUM} | sha256sum --check && \\\n        tar -xz --strip-components=1 -f v${LIBZMQ_VERSION}.tar.gz && \\\n        ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make check && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libsrt https://github.com/Haivision/srt\nRUN \\\n        DIR=/tmp/srt && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/Haivision/srt/archive/v${LIBSRT_VERSION}.tar.gz && \\\n        tar -xz --strip-components=1 -f v${LIBSRT_VERSION}.tar.gz && \\\n        cmake -DCMAKE_INSTALL_PREFIX=\"${PREFIX}\" . && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libpng\nRUN \\\n        DIR=/tmp/png && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        git clone https://git.code.sf.net/p/libpng/code ${DIR} -b v${LIBPNG_VERSION} --depth 1 && \\\n        ./autogen.sh && \\\n        ./configure --prefix=\"${PREFIX}\" && \\\n        make check && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## libaribb24\nRUN \\\n        DIR=/tmp/b24 && \\\n        mkdir -p ${DIR} && \\\n        cd ${DIR} && \\\n        curl -sLO https://github.com/nkoriyama/aribb24/archive/v${LIBARIBB24_VERSION}.tar.gz && \\\n        echo ${LIBARIBB24_SHA256SUM} | sha256sum --check && \\\n        tar -xz --strip-components=1 -f v${LIBARIBB24_VERSION}.tar.gz && \\\n        autoreconf -fiv && \\\n        ./configure CFLAGS=\"-I${PREFIX}/include -fPIC\" --prefix=\"${PREFIX}\" && \\\n        make && \\\n        make install && \\\n        rm -rf ${DIR}\n\n## ffmpeg https://ffmpeg.org/\nRUN  \\\n        DIR=/tmp/ffmpeg && mkdir -p ${DIR} && cd ${DIR} && \\\n        curl -sLO https://ffmpeg.org/releases/ffmpeg-${FFMPEG_VERSION}.tar.bz2 && \\\n        tar -jx --strip-components=1 -f ffmpeg-${FFMPEG_VERSION}.tar.bz2\n\n\n\nRUN \\\n        DIR=/tmp/ffmpeg && mkdir -p ${DIR} && cd ${DIR} && \\\n        ./configure \\\n        --disable-debug \\\n        --disable-doc \\\n        --disable-ffplay \\\n        --enable-shared \\\n        --enable-avresample \\\n        --enable-libopencore-amrnb \\\n        --enable-libopencore-amrwb \\\n        --enable-gpl \\\n        --enable-libass \\\n        --enable-fontconfig \\\n        --enable-libfreetype \\\n        --enable-libvidstab \\\n        --enable-libmp3lame \\\n        --enable-libopus \\\n        --enable-libtheora \\\n        --enable-libvorbis \\\n        --enable-libvpx \\\n        --enable-libwebp \\\n        --enable-libxcb \\\n        --enable-libx265 \\\n        --enable-libxvid \\\n        --enable-libx264 \\\n        --enable-nonfree \\\n        --enable-openssl \\\n        --enable-libfdk_aac \\\n        --enable-postproc \\\n        --enable-small \\\n        --enable-version3 \\\n        --enable-libbluray \\\n        --enable-libzmq \\\n        --extra-libs=-ldl \\\n        --prefix=\"${PREFIX}\" \\\n        --enable-libopenjpeg \\\n        --enable-libkvazaar \\\n        --enable-libaom \\\n        --extra-libs=-lpthread \\\n        --enable-libsrt \\\n        --enable-libaribb24 \\\n        --enable-libvmaf \\\n        --extra-cflags=\"-I${PREFIX}/include\" \\\n        --extra-ldflags=\"-L${PREFIX}/lib\" && \\\n        make && \\\n        make install && \\\n        make tools/zmqsend && cp tools/zmqsend ${PREFIX}/bin/ && \\\n        make distclean && \\\n        hash -r && \\\n        cd tools && \\\n        make qt-faststart && cp qt-faststart ${PREFIX}/bin/\n\n# Let's make sure the app built correctly\n# Convenient to verify on https://hub.docker.com/r/jrottenberg/ffmpeg/builds/ console output\n\nFROM        base AS release\nENV         LD_LIBRARY_PATH /opt/ffmpeg/lib:/usr/local/lib\nRUN     apt-get -yqq update && \\\n        apt-get install -yq --no-install-recommends build-essential && \\\n        apt-get autoremove -y && \\\n        apt-get clean -y\n\nCOPY --from=build /opt/ffmpeg /opt/ffmpeg\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4794921875,
          "content": "BSD 3-Clause License\n\nCopyright (c) 2017, Leandro Moreira\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.9130859375,
          "content": "usage:\n\techo \"make fetch_small_bunny_video && make run_hello\"\n\nall: clean fetch_bbb_video make_hello run_hello make_remuxing run_remuxing_ts run_remuxing_fragmented_mp4 make_transcoding\n.PHONY: all\n\nclean:\n\t@rm -rf ./build/*\n\nfetch_small_bunny_video:\n\t./fetch_bbb_video.sh\n\nmake_hello: clean\n\tdocker run -w /files --rm -it  -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 \\\n\t  gcc -L/opt/ffmpeg/lib -I/opt/ffmpeg/include/ /files/0_hello_world.c \\\n\t  -lavcodec -lavformat -lavfilter -lavdevice -lswresample -lswscale -lavutil \\\n\t  -o /files/build/hello\n\nrun_hello: make_hello\n\tdocker run -w /files --rm -it -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 /files/build/hello /files/small_bunny_1080p_60fps.mp4\n\nmake_remuxing: clean\n\tdocker run -w /files --rm -it  -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 \\\n\t  gcc -L/opt/ffmpeg/lib -I/opt/ffmpeg/include/ /files/2_remuxing.c \\\n\t  -lavcodec -lavformat -lavfilter -lavdevice -lswresample -lswscale -lavutil \\\n\t  -o /files/build/remuxing\n\nrun_remuxing_ts: make_remuxing\n\tdocker run -w /files --rm -it -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 /files/build/remuxing /files/small_bunny_1080p_60fps.mp4 /files/remuxed_small_bunny_1080p_60fps.ts\n\nrun_remuxing_fragmented_mp4: make_remuxing\n\tdocker run -w /files --rm -it -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 /files/build/remuxing /files/small_bunny_1080p_60fps.mp4 /files/fragmented_small_bunny_1080p_60fps.mp4 fragmented\n\nmake_transcoding: clean\n\tdocker run -w /files --rm -it  -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 \\\n\t  gcc -g -Wall -L/opt/ffmpeg/lib -I/opt/ffmpeg/include/ /files/3_transcoding.c /files/video_debugging.c \\\n\t  -lavcodec -lavformat -lavfilter -lavdevice -lswresample -lswscale -lavutil \\\n\t  -o /files/build/3_transcoding\n\nrun_transcoding: make_transcoding\n\tdocker run -w /files --rm -it -v `pwd`:/files leandromoreira/ffmpeg-devel:4.4 ./build/3_transcoding /files/small_bunny_1080p_60fps.mp4 /files/bunny_1s_gop.mp4\n"
        },
        {
          "name": "README-cn.md",
          "type": "blob",
          "size": 43.865234375,
          "content": "[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\nFFmpeg( libav)[\"1k\"](http://dranger.com/ffmpeg/)\n\nC****FFmpeg libav[python](https://pyav.org/)[go](https://github.com/imkira/go-libav)  `ffi`  [Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua) \n\n FFmpeg  [ FFmpeg libav](#-FFmpeg-libav) \n\n TV FFmpeg \n\n____\n\n* [](#)\n  * [ - ](#---)\n  * [ - ](#---)\n  * [ - ](#---)\n  * [ - ](#---)\n* [FFmpeg - ](#FFmpeg---)\n  * [FFmpeg  101](#FFmpeg--101)\n* [](#)\n  * [](#)\n  * [](#)\n  * [](#)\n  * [](#)\n  * [](#)\n  * [](#)\n* [ FFmpeg libav](#-FFmpeg-libav)\n  * [0 -  hello world](#0----hello-world)\n    * [FFmpeg libav ](#FFmpeg-libav-)\n  * [1 - ](#-1---)\n  * [2 - ](#-2---)\n  * [3 - ](#-3---)\n\n# \n\n##  - \n\n([24](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/))[](https://en.wikipedia.org/wiki/Persistence_of_vision)\n: **/**.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\n (1886)\n\n##  - \n\n\n\n\n\n> [PCM](https://en.wikipedia.org/wiki/Pulse-code_modulation)ADC\n\n![audio analog to digital](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analog to digital\")\n\n>[](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n##  - \n\n> CODEC/ /\n>\n> https://en.wikipedia.org/wiki/Video_codec\n\n\n\n `1080x1920` (x) `3 bytes` ( [24 bit](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29) ,  16,777,216 ) 24  30 \n\n```c\ntoppf = 1080 * 1920 // \ncpp = 3 // (bytes)\ntis = 30 * 60 // ()\nfps = 24 // \n\nrequired_storage = tis * fps * toppf * cpp\n```\n\n `250.28G`  `1.19Gbps`  [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work) \n\n##  - \n\n> \n> https://en.wikipedia.org/wiki/Digital_container_format\n\n********\n\n video.webm  [`webm`](https://www.webmproject.org/) \n\n![container](/img/container.png)\n\n# FFmpeg - \n\n> \n\n/ [FFmpeg](https://www.ffmpeg.org/)  [Chrome](https://www.chromium.org/developers/design-documents/video) \n\n`ffmpeg`  `mp4`  `avi` \n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\n\nFFmpeg \n\n## **FFmpeg  101**\n\nFFmpeg [](https://www.ffmpeg.org/ffmpeg.html)\n\nFFmpeg  `ffmpeg {1} {2} -i {3} {4} {5}`:\n\n1. \n2. \n3. \n4. \n5. \n\n 2345 \n\n``` bash\n#  300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ # \n-c:a libfdk_aac \\ # \n-i bunny_1080p_60fps.mp4 \\ # \n-c:v libvpx-vp9 -c:a libvorbis \\ # \nbunny_1080p_60fps_vp9.webm # \n```\n\n `mp4`  `aac` `h264`  `webm`\n\n FFmpeg  `ffmpeg -i input.avi output.mp4` FFmpeg / `output.mp4` \n\nWerner Robitza  [ ffmpeg ](https://slhck.info/ffmpeg-encoding-course/#/)\n\n# \n\n/\n\n## \n\n![transcoding](/img/transcoding.png)\n\n**?** \n\n**?** TV X  Y \n\n**?**  `H264`AVC `H265`HEVC\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n## \n\n![transmuxing](/img/transmuxing.png)\n\n**?** /\n\n**?** TV X  Y /\n\n**?**  `mp4`  `ts`\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ #  ffmpeg \nbunny_1080p_60fps.ts\n```\n\n## \n\n![transrating](/img/transrating.png)\n\n**?** \n\n**?**  `2G` (edge)  4K \n\n**?**  3856k  2000K \n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\nWerner Robitza  [FFmpeg ](https://slhck.info/posts/) \n\n## \n\n![transsizing](/img/transsizing.png)\n\n**?** \n\n**?** \n\n**?**  `1080p`   `480p` \n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## \n\n![adaptive streaming](/img/adaptive-streaming.png)\n\n**?** /http\n\n**?** 4K\n\n**?**  DASH  WebM\n\n```bash\n# \n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# \n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# DASH \n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPS:  [ DASH  WebM](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash)\n\n## \n\nFFmpeg [](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly) FFmpeg  iMovie  YouTube \n\n#  FFmpeg libav\n\n> Don't you wonder sometimes 'bout sound and vision?\n> **David Robert Jones**\n\n [FFmpeg](#ffmpeg---command-line) \n\nFFmpeg [lib](https://www.ffmpeg.org/doxygen/trunk/index.html)FFmpeg **FFmpeg libav**\n\n>  Zed Shaw [XX](https://learncodethehardway.org/)C\n\n## 0 -  hello world\n\n hello world  hello world :tongue:********\n\n\n### FFmpeg libav \n\n**FFmpeg libav **\n\n\n\n![ffmpeg libav architecture - decoding process](/img/decoding.png)\n\n [AVFormatContext](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) \n\n**** [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html) \n\n> \n\n [AAC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding)  [H264AVC](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC) [AVPacket](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) \n\n**** [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html)\n\n`AVCodec`  [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html)****\n\n### \n\n[](https://github.com/leandromoreira/ffmpeg-libav-tutorial/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+compiling) `Docker` / Big Buck Bunny  `make fetch_small_bunny_video` \n\n###  0 - \n\n> [](/0_hello_world.c)\n>\n> ```bash\n> $ make run_hello\n> ```\n\n[](https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/0_hello_world.c)Github\n\n [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) \n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\n `AVFormatContext` [`avformat_open_input`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49)  `AVFormatContext`[`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html)NULLFFmpeg[`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html)\n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\n\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\n [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb)`pFormatContext->nb_streams`   `pFormatContext->streams[i]`  `i` [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html))\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\n\n\n\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n  //\n}\n```\n\n [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html)\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\n\ncodec id [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca)  [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html) \n\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\n\n\n```c\n// \nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n  printf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n  printf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// \nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pCodecParameters->bit_rate);\n```\n\n `AVCodec`  [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html) /  [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16)(`AVCodecParameters`)  `AVCodecContext`\n\n [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) \n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\n  [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html)  [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html) \n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\n [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61) \n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n  //...\n}\n```\n\n [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3) ****\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\n [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c) \n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\n frame [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp)DTS[frame ](https://en.wikipedia.org/wiki/Video_compression_picture_types)\n\n```c\nprintf(\n    \"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n    av_get_picture_type_char(pFrame->pict_type),\n    pCodecContext->frame_number,\n    pFrame->pts,\n    pFrame->pkt_dts,\n    pFrame->key_frame,\n    pFrame->coded_picture_number,\n    pFrame->display_picture_number\n);\n```\n\n[](https://en.wikipedia.org/wiki/Netpbm#PGM_example) `pFrame->data` [Y, Cb  Cr ](https://en.wikipedia.org/wiki/YCbCr)  `0`Y \n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    //  pgm \n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // \n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n```\n\n2MB\n\n![saved frame](/img/generated_frame.png)\n\n##  1 - \n\n> **Be the player** -  JS  MSE \n\n [](#-2---) timing/\n\n\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\n****\n\n****PTS**timebase**FFmpeg**timescale**\n\n\n\n `fps=60/1`  `timebase=1/60000`PTS  `timescale / fps = 1000`  PTS 0:\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\n timebase  `1/60`\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\n `fps=25``timebase=1/75`PTS  `timescale / fps = 3`  PTS 0\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\n `pts_time`  `pts_time` FFmpeg libav \n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\n DTS (frames1,6,4,2,3,5) PTS (frames1,2,3,4,5)BPI\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n##  2 - \n\n FFmpeg  [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14)   [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream) \n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\n`-c copy` mp4  `mpegts`  `-f` ffmpeg \n\nFFmpeg  libav /\n\n* **[](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** -   `rtmp`  `http`\n* **[](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - \n* **[](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** -  <sup>**</sup>\n* **[](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** -  `filters`<sup>**</sup>\n* \n* **[](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - <sup>**</sup>\n* **[](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - \n* **[](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** -  ()\n\n![ffmpeg libav workflow](/img/ffmpeg_libav_workflow.jpeg)\n\n>  [Leixiaohua's](https://leixiaohua1020.github.io/#ffmpeg-development-examples)  [Slhck's](https://slhck.info/ffmpeg-encoding-course/#/9) \n\n libav :  `ffmpeg input.mp4 -c copy output.ts`\n\n`input_format_context`)`output_format_context`)\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\n\n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n  fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n  goto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n  fprintf(stderr, \"Failed to retrieve input stream information\");\n  goto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n  fprintf(stderr, \"Could not create output context\\n\");\n  ret = AVERROR_UNKNOWN;\n  goto end;\n}\n```\n\n\n\n```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n```\n\n [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827) \n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n  AVStream *out_stream;\n  AVStream *in_stream = input_format_context->streams[i];\n  AVCodecParameters *in_codecpar = in_stream->codecpar;\n  if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n    streams_list[i] = -1;\n    continue;\n  }\n  streams_list[i] = stream_index++;\n  out_stream = avformat_new_stream(output_format_context, NULL);\n  if (!out_stream) {\n    fprintf(stderr, \"Failed allocating output stream\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n  ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n  if (ret < 0) {\n    fprintf(stderr, \"Failed to copy codec parameters\\n\");\n    goto end;\n  }\n}\n```\n\n\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n  ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n  if (ret < 0) {\n    fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n    goto end;\n  }\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n  fprintf(stderr, \"Error occurred when opening output file\\n\");\n  goto end;\n}\n```\n\n`av_read_frame` PTS  DTS `av_interleaved_write_frame` \n\n```c\nwhile (1) {\n  AVStream *in_stream, *out_stream;\n  ret = av_read_frame(input_format_context, &packet);\n  if (ret < 0)\n    break;\n  in_stream  = input_format_context->streams[packet.stream_index];\n  if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n    av_packet_unref(&packet);\n    continue;\n  }\n  packet.stream_index = streams_list[packet.stream_index];\n  out_stream = output_format_context->streams[packet.stream_index];\n  /*  */\n  packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n  packet.pos = -1;\n\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n  ret = av_interleaved_write_frame(output_format_context, &packet);\n  if (ret < 0) {\n    fprintf(stderr, \"Error muxing packet\\n\");\n    break;\n  }\n  av_packet_unref(&packet);\n}\n```\n\n [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13) \n\n```c\nav_write_trailer(output_format_context);\n```\n\n MP4  MPEG-TS  libav  `ffmpeg input.mp4 -c copy output.ts `\n\n```bash\nmake run_remuxing_ts\n```\n\n ffprobe \n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n  Duration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n  Program 1\n    Metadata:\n      service_name    : Service01\n      service_provider: FFmpeg\n    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n    Stream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\n[libav](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture)\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\n   **** [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding)  [fragmented mp4](https://stackoverflow.com/a/35180327)fmp4 MPEG-TS  MPEG-4\n\n[](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting)\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\n libav \n\n```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n```\n\n fragmented mp4 \n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\n [gpac/mp4box.js](https://gpac.github.io/mp4box.js/) [http://mp4parser.com/](http://mp4parser.com/) mp4\n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\n`mdat` atom/box **** fragmented mp4 `mdat` \n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n##  3 - \n\n> #### \n>\n> ```bash\n> $ make run_transcoding\n> ```\n>\n> [](https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/3_transcoding.c) github\n\n C  **FFmpeg/libav**[libavcodec](https://ffmpeg.org/libavcodec.html)libavformat  libavutil H264  H265\n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html) MKVMP4WebmTS [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html)  [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html)  `AVStream`  [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html)av1h264vp9hevc [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html) \n\n### \n\n****\n\n```c\n//  AVFormatContext \navfc = avformat_alloc_context();\n// \navformat_open_input(avfc, in_filename, NULL, NULL);\n// \navformat_find_stream_info(avfc, NULL);\n```\n\n`AVFormatContext`  `AVStream`  `AVCodec`  `AVCodecContext`\n\n>  [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) \n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n  AVStream *avs = avfc->streams[i];\n  AVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  AVCodecContext *avcc = avcodec_alloc_context3(*avc);\n  avcodec_parameters_to_context(*avcc, avs->codecpar);\n  avcodec_open2(*avcc, *avc, NULL);\n}\n```\n\n `AVFormatContext` ************\n\n `AV_CODEC_FLAG_GLOBAL_HEADER` \n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n  encoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\n `AVPacket` `av_interleaved_write_frame`  \n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  av_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n  av_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n### \n\n `h264`  `h265`\n\n\n\n*  [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)  `AVStream`\n*  `libx265`  `AVCodec` [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37) \n*  [`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)  `AVCodecContext`\n* \n*  [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d)  [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe) \n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n//  x265 \n//  GOP  60 \nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// \nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// \nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// \nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\n\n\n-  [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)  `AVPacket` \n-  [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)  `AVFrame`\n- \n-  [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169) \n-  `AVPacket` [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decodinghtml#ga5b8eff59cf259747cf0b31563e38ded6) \n-  [`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n-  [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  int response = avcodec_send_packet(decoder_video_avcc, input_packet);\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder_video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return response;\n    }\n    if (response >= 0) {\n      encode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n    }\n    av_frame_unref(input_frame);\n  }\n  av_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// used function\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n  AVPacket *output_packet = av_packet_alloc();\n  int response = avcodec_send_frame(video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return -1;\n    }\n\n    output_packet->stream_index = index;\n    output_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n    response = av_interleaved_write_frame(avfc, output_packet);\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\n```\n\n `h264`  `h265``h265`  h264 [](/3_transcoding.c)\n\n```c\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.muxer_opt_key = \"movflags\";\n  sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 0;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.audio_codec = \"aac\";\n  sp.output_extension = \".ts\";\n\n  /* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n```\n\n> [](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54) [FFmpeg ](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749) `force-cfr`  h264  warning  `warning messages (forced frame type (5) at 80 was changed to frame type (3))`\n"
        },
        {
          "name": "README-es.md",
          "type": "blob",
          "size": 49.9033203125,
          "content": "[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\n\n\n\nEstaba buscando un tutorial/libro que pudiera ensearme como usar [FFmpeg](https://www.ffmpeg.org/) como una librera (alias libav) y encontr el tutorial de [\"How to write a video player in less than 1k lines\"](http://dranger.com/ffmpeg/). Desafortunadamente estaba obsoleto, as que decid escribir el siguiente tutorial.\n\n\n\nLa mayora del cdigo aqu estar en C, **pero no te preocupes**: tu podrs entenderlo fcilmente y aplicarlo a tu lenguaje preferido. FFmpeg libav tiene montones de bindings para muchos lenguajes como [python](https://pyav.org/), [go](https://github.com/imkira/go-libav) e incluso si tu lenguaje no lo tiene, an es posible darle soporte mediante `ffi` (aqu hay un ejemplo en [Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua)).\n\nEmpezaremos con una leccin rpida de lo que es video, audio, cdec y contenedor,  entonces iremos a un curso rpido en como usar el comando `FFmpeg` y finalmente, escribiremos algo de cdigo, sintete libre de saltar directamente[ ](http://newmediarockstars.com/wp-content/uploads/2015/11/nintendo-direct-iwata.jpg \"Secret Leandros Easter Egg\")a la seccin [Aprender FFmpeg libav de la manera difcil.](#learn-ffmpeg-libav-the-hard-way) \n\nAlgunas personas solan decir que la transmisin de video por internet era el futuro de la televisin tradicional, en cualquier caso, FFmpeg es algo que vale la pena estudiar.\n\n__Tabla de Contenido__\n\n* [Intro](#intro)\n  * [video - lo que ves!](#video---lo-que-ves!)\n  * [audio - lo que escuchas!](#audio---lo-que-escuchas!)\n  * [cdec - comprimiendo datos](#cdec---comprimiendo-datos)\n  * [Contenedor - un lugar cmodo para audio y video](#Contenedor---un-lugar-cmodo-para-audio-y-video)\n* [FFmpeg - lnea de comandos](#FFmpeg---lnea-de-comandos)\n  * [FFmpeg herramienta de lnea de comandos 101](#FFmpeg-herramienta-de-lnea-de-comandos-101)\n* [Operaciones de video comunes](#Operaciones-de-video-comunes)\n  * [Transcoding](#transcoding)\n  * [Transmuxing](#transmuxing)\n  * [Transrating](#transrating)\n  * [Transsizing](#transsizing)\n  * [Round Bonus:  Transmisin adaptativa](#Round-Bonus-Transmisin-adaptativa)\n  * [Ve ms all](#Ve-ms-all)\n* [Aprende FFmpeg libav de la manera difcil](#Aprende-FFmpeg-libav-de-la-manera-difcil)\n  * [Captulo 0 - El infame hola mundo](#Captulo-0---El-infame-hola-mundo)\n    * [Arquitectura de FFmpeg libav](#Arquitectura-de-FFmpeg-libav)\n  * [Captulo 1 - timing](#Captulo-1---sincronizando-audio-y-video)\n  * [Captulo 2 - remuxing](#Captulo-2---remuxing)\n  * [Captulo 3 - transcoding](#Captulo-3---transcoding)\n\n# Intro\n\n## Video - lo que ves!\n\nSi tu tienes una secuencia de imgenes en serie y las cambias a cierta frecuencia (digamos [24 imagenes por segundo](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/)), crearas una [ilusion de movimiento](https://en.wikipedia.org/wiki/Persistence_of_vision).\nEn resumen, esta es una muy bsica idea detrs de un video: **una serie de imgenes / cuadros, corriendo a una velocidad dada**.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\n\nIlustracin Zeitgenssische (1886)\n\n## Audio - lo que escuchas!\n\nAunque un video mudo puede expresar una variedad de sentimientos, el agregarle sonido lo vuelve una experiencia mas placentera.\n\nEl sonido es la vibracin que se propaga como una onda de presin, a travs del aire o de cualquier otro medio de transmisin, como un gas, lquido o slido.\n\n> En un sistema de audio digital, el micrfono convierte sonido a una seal elctrica analgica, despus un convertidor analgico-a-digital  (ADC)  tpicamente se usa [pulse-code modulation (PCM)](https://en.wikipedia.org/wiki/Pulse-code_modulation)  - que convierte la seal analgica en una seal digital.\n\n![audio analog to digital](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analogo a digital\")\n>[Fuente](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n## Cdec - comprimiendo datos\n\n> CODEC es un circuito electrnico o software que **comprime o descomprime audio/video digital.** \n\nConvierte audio/video digital en bruto (raw) a un formato comprimido o vice versa.\n\n> https://en.wikipedia.org/wiki/Video_codec\n\nPero si deseamos empaquetar millones de imgenes dentro de un solo archivo y generamos una pelcula, entonces terminaramos con un archivo enorme. Veamos las matemticas:\n\nSupongamos que creamos el video con una resolucin de `1080 x 1920` (altura x anchura) y que utilizaremos `3 bytes` por pxel (la unidad mnima en una pantalla) para codificar el color (o [un color de 24 bit](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29), que nos da 16,777,216 diferentes colores) y este video se reproduce a `24 cuadros por segundo` entonces sern  `30 minutos` de duracin.\n\n```c\ntoppf = 1080 * 1920 //total_de_pixeles_por_cuadro\ncpp = 3 //costo_por_pixel\ntis = 30 * 60 //tiempo_en_segundos\nfps = 24 //cuadros_por_segundo\n\nalmacenamiento_requerido = tis * fps * toppf * cpp\n```\n\nEste video requerira aproximadamente `250.28GB` de almacenamiento o `1.19 Gbps` de banda ancha! Es por esto que necesitamos hacer uso de un [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work).\n\n## Contenedor - un lugar cmodo para audio y video\n\n> Un contenedor o formato de envoltura es un formato de meta-archivos cuyas especificaciones describen que diferentes elementos de datos y metadatos coexisten en un mismo archivo de computadora.\n>\n>  https://en.wikipedia.org/wiki/Digital_container_format\n\nEs un **slo archivo que contiene todos los streams (en su mayora de audio y video) y tambin provee una sincronizacin y metadatos generales**, como un titulo, resolucin, etc.\n\nUsualmente, podemos inferir el formato de un archivo al ver su extensin: por ejemplo un `video.webm` es probablemente un video usando el contenedor [`webm`](https://www.webmproject.org/).\n\n![container](/img/container.png)\n\n# FFmpeg - lnea de comandos\n\n> Una completa solucin multi-plataforma para grabar, convertir y transmitir audio y video.\n\nPara trabajar con multimedia podemos hacer uso de esta MARAVILLOSA herramienta/librera llamada [FFmpeg](https://www.ffmpeg.org/). Existen posibilidades de que ya la conoces/usas, directa o indirectamente (usas [Chrome](https://www.chromium.org/developers/design-documents/video)?).\n\nste tiene una programa para lnea de comandos llamado `ffmpeg`,un binario muy simple y poderoso. Por ejemplo, puedes convertir desde un contenedor `mp4`a uno `avi` solo escribiendo el siguiente comando:\n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\nAcabamos de hacer **remuxing** (remultiplexacin) aqu, el cual consiste convertir de un contenedor a otro. Tcnicamente, FFmpeg puede tambin hacer un transcoding, pero hablaremos de eso despus. \n\n## FFmpeg herramienta de lnea de comandos 101\n\nFFmpeg posee [documentacin](https://www.ffmpeg.org/ffmpeg.html) que hace un gran trabajo explicando como funciona.\n\nPara ser breves, el comando de lnea para FFmpeg espera el siguiente formato de argumentos para realizar sus acciones `ffmpeg {1} {2} -i {3} {4} {5}`, donde:\n\n1. Opciones globales\n2. Opciones de archivo de entrada\n3. URL de entrada\n4. Opciones de archivo de salida\n5. URL de salida\n\nLas partes 2,3,4 y 5 pueden ser tantas como sean necesarias.\n\nEs mas fcil entender este formato de argumentos en accin:\n\n``` bash\n# ADVERTENCIA: este archivo pesa alrededor de 300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ # opciones globales\n-c:a libfdk_aac \\ # opciones de entrada\n-i bunny_1080p_60fps.mp4 \\ # url de entrada\n-c:v libvpx-vp9 -c:a libvorbis \\ # opciones de salida\nbunny_1080p_60fps_vp9.webm # url de salida\n```\n\nEste comando toma el archivo de entrada `mp4` que contiene 2 streams (un audio codificado con el CODEC `aac` y el video codificado usando el CODEC `h264`) y va a convertirlo a `webm`, cambiando tambin los CODECs de audio y video.\n\nPodramos simplificar el comando de arriba pero tenemos que saber que FFmpeg adoptar o supondr los valores predeterminados por ti.\n\nPor ejemplo, cuando tu introduces `ffmpeg -i input.avi output.mp4` qu CODEC para audio/video va a usar para producir `output.mp4`?\n\nWerner Robitza escribi un [tutorial acerca de codificacion y edicion con FFmpeg](http://slhck.info/ffmpeg-encoding-course/#/) que se tiene que leer/realizar para una mejor comprensin.\n\n# Operaciones de video comunes\n\nCuando trabajamos con audio/video nosotros usualmente hacemos una serie de tareas con archivos multimedia.\n\n## Transcoding\n\n![transcoding](/img/transcoding.png)\n\n**Qu?** el acto de convertir uno de los flujos de transmisin (audio o video) de un CODEC a otro.\n\n**Por qu?** en ocasiones algunos dispositivos (TVs, smartphones, consolas, etc.) no soportan X pero si Y y nuevos CODECs proveen mejor tasa de compresin. \n\n**Cmo?** convirtiendo un video `H264` (AVC) a un `H265` (HEVC).\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n## Transmuxing \n\n![transmuxing](/img/transmuxing.png)\n\n**Qu?** el acto de convertir un formato (contenedor) a otro.\n\n**Por qu?** en ocasiones algunos dispositivos (TVs, smartphones, consolas, etc.) no soportan X pero si Y y a veces nuevos contenedores proveen caractersticas modernas que son requeridas.\n\n**Cmo?** convirtiendo de `mp4` a `webm`.\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ # con esto se dice a ffmpeg que se salte la codificacin\nbunny_1080p_60fps.webm\n```\n\n## Transrating\n\n![transrating](/img/transrating.png)\n\n**Qu?** el acto de cambiar la tasa de bits, o produciendo otras presentaciones.\n\n**Por qu?** las personas intentaran ver tu video usando una conexin `2G` (edge) en un smartphone de baja gama o una conexin por `fibra` a Internet en los televisores a 4K, por lo tanto tu deberas ofrecer mas de una presentacin para el mismo video a diferente tasa de bits.\n\n**Cmo?** produciendo una presentacin con una tasa de bits entre 3856K y 2000K.\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\nUsualmente vamos a estar usando transrating con transsizing. Werner Robitza escribi otra [serie de posts acerca del control de tasa para FFmpeg](http://slhck.info/posts/) que debes leer/realizar.\n\n# Transsizing\n\n![transsizing](/img/transsizing.png)\n\n**Qu?** el acto de convertir desde una resolucin a otro. Como antes se dijo, transsizing es usualmente usado con transrating.\n\n**Por qu?** las razones serian las mismas que las de transrating.\n\n**Cmo?** convirtiendo de una resolucin de `1080p` a `480p`.\n\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## Round Bonus: Transmisin adaptativa\n\n![adaptive streaming](/img/adaptive-streaming.png)\n\n**Qu?** el acto de producir varias resoluciones (tasas de bits) y dividir el contenido en porciones y despus servirlos mediante http.\n\n**Por qu?** para proveer un contenido flexible que puede ser observado en un smartphone de baja gama o en una televisin en 4K, tambin es fcil de escalar y desplegar pero puede agregar latencia.\n\n**Cmo?** creando un WebM adaptativo usando DASH.\n```bash\n# emisiones de video\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# emisiones de audio\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# el manifiesto DASH\n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPD: Tom este ejemplo desde las [Instrucciones de la reproduccin de WebM adaptativo usando DASH](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash)\n\n## Ve ms all\n\nHay [muchos y bastantes mas usos para FFmpeg](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly).\nYo lo uso en conjunto con *iMovie* para producir/editar algunos videos de Youtube y tu ciertamente puedes usarle de manera profesional.\n\n# Aprende FFmpeg libav de la manera difcil\n\n> A veces no te preguntas acerca de el sonido y la visin?\n> **David Robert Jones**\n\nSabiendo que [FFmpeg]() es tan til como una herramienta de lnea de comandos para realizar tareas esenciales en archivos multimedia, pero cmo se pueden usar en nuestros programas?\n\nFFmpeg est [compuesto de multiples libreras](https://www.ffmpeg.org/doxygen/trunk/index.html) que pueden ser integradas en nuestros propios programas.\n\nUsualmente, cuando instalas FFmpeg, se instalan automticamente todas esas libreras. De aqu en adelante, me voy a referir a estas set de libreras como **FFmpeg libav**.\n\n> Este ttulo es un homenaje a las series de Zed Shaw [Aprende X de la manera difcil](https://learncodethehardway.org/), particularmente a su libro Aprende C de la manera difcil.\n\n## Captulo 0 - El infame hola mundo\n\nste hola mundo, de hecho, no enseara el mensaje de `\"hola mundo\"` en la terminal :tongue: En su lugar, vamos a **imprimir la informacin acerca del video**. cosas como su formato (contenedor), duracin, resolucin, canales de audio y, al final, vamos a **decodificar algunos cuadros y a guardarlos como archivos de imagen**.\n\n### Arquitectura de FFmpeg libav\n\nPero antes de que podamos empezar a codificar, vamos a aprender como la **Arquitectura de FFmpeg libav** funciona y como sus componentes se comunican con otros.\n\nAqu hay un diagrama del proceso de decodificacin de video:\n\n![ffmpeg libav architecture - decoding process](/img/decoding.png)\n\nPrimero, vas a necesitar cargar tu archivo multimedia dentro de un componente llamado [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html)(el contenedor de video es tambin conocido como formato). \n\nDe hecho, no se carga todo el archivo: usualmente solo lee el encabezado (header) del mismo.\n\nUna vez cargamos el **encabezado de nuestro contenedor** en su forma mnima, nosotros podemos acceder a sus streams (piensa de ellos como datos rudimentarios de audio y video).\n\nCada stream estar disponible en un componente llamado [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html).\n\n> Stream es un nombre elegante para un flujo continuo de datos.\n\nSupongamos que nuestro video tiene dos streams: un audio codificado con [AAC CODEC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding) y un video codificado con [H264 (AVC) CODEC](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC). Por cada stream, nosotros podemos extraer **piezas de datos** llamados paquetes, los que sern cargados en componentes llamados [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html).\n\nLos **datos dentro de los paquetes siguen codificados** (comprimidos) y para decodificar los paquetes, necesitamos pasarlos a un [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html) especfico.\n\nEl `AVCodec` va a decodificarlos dentro de un [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html) y finalmente, este componente nos da **el cuadro (frame) descomprimido**. Hay que poner atencin en que se usa la misma terminologa o mismo proceso es usado de igual manera por un stream de audio y video.\n\n### Requerimientos\n\nDebido a que algunas personas estuvieron [enfrentandose a varios problemas durante la compilacion o ejecucion de los ejemplos](https://github.com/leandromoreira/ffmpeg-libav-tutorial/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+compiling) **vamos a usar [`Docker`](https://docs.docker.com/install/) como nuestro entorno de desarrollo/ejecucin, tambin haremos uso del video: \"The Big Buck Bunny\", que en caso de no contar con l de manera local, solo ejecuta el comando `make fetch_small_bunny_video`.\n\n ### Captulo 0 - el cdigo, paso a paso\n\n> #### TLDR; ensname el [codigo](/0_hello_world.c) y ejecuta.\n> ```bash\n> $ make run_hello\n> ```\n\nVamos a saltarnos unos detalles, pero no te preocupes: el [cdigo fuente esta disponible en GitHub](/0_hello_world.c).\n\nVamos a acomodar (allocate) la memoria para el componente [`AVFormatContext`](http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html), el cual va a contener la informacin acerca del formato (contenedor).\n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\nAhora vamos a abrir el archivo y leer su encabezado para llenar el `AVFormatContext` con la informacin mnima acerca del formato (note que usualmente los cdecs no son abiertos).\n\nLa funcin usada para hacer esto es [`avformat_open_input`](http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49). ste espera un `AVFormatContext`, un archivo (`filename`) y dos argumentos opcionales: el [`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html) (si tu colocas un `NULL`, FFmpeg va a suponer el formato por ti) y el [`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html) (el cual son las opciones para el desmultiplexador).\n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\nPodemos imprimir el nombre del formato y la duracin media:\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\nPara acceder a los `streams`, necesitamos leer los datos del archivo. La funcin [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb) hace eso.\n\nAhora, el `pFormatContext->nb_streams` contendr el numero de streams y el `pFormatContext->streams[i]` nos dar el  stream `i`([`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)).\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\nAhora, navegaremos por todos los streams.\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n  //\n}\n```\nPor cada stream, vamos a mantener los [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html), los cuales describen las propiedades de un cdec usado por el stream `i`.\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\nYa con las propiedades del cdec, podremos ver el CODEC apropiado solicitndolo a la funcin [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca)  y encontrar el decodificador para un cdec id y regresar un [`AVCodec`](http://ffmpeg.org/doxygen/trunk/structAVCodec.html), el componente que conoce como **CO**dificar y **DEC**odificar el stream.\n\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\nAhora, vamos a imprimir la informacin acerca de los cdecs.\n\n```c\n// especifico para video y audio\nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n  printf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n  printf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// general\nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n```\n\nCon el cdec, podemos acomodar memoria para el [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html), el cual va a contener el contexto para nuestro proceso de decodificacin/codificacin, pero antes debemos llenar el contexto del cdec con los parmetros CODEC; esto lo hacemos con [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16).\n\nUna vez llenado el contexto del cdec, necesitamos abrirlo. Entonces tenemos que llamar a la funcin [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) y despus de ello,  lo podremos usar.\n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\nAhora, vamos a leer los paquetes desde el stream y decodificarlos dentro de cuadros, vamos a necesitar acomodar la memoria para ambos componentes, el [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) y [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\nHay que sustraer nuestros paquetes desde los streams con la funcin [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61) mientras contenga paquetes.\n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n  //...\n}\n```\n\nAhora, hay que **mandar los paquetes de datos en bruto** (cuadro comprimido) al decodificador, mediante el contexto del cdec, usando la funcin  [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3).\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\nY vamos a **recibir el cuadro de datos en bruto** (cuadro descomprimido) desde el decodificador, mediante el mismo contexto del cdec, usando la funcin [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c).\n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\nPodemos imprimir el numero de cuadro, el [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp), DTS, [frame type](https://en.wikipedia.org/wiki/Video_compression_picture_types), etc.\n\n```c\nprintf(\n    \"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n    av_get_picture_type_char(pFrame->pict_type),\n    pCodecContext->frame_number,\n    pFrame->pts,\n    pFrame->pkt_dts,\n    pFrame->key_frame,\n    pFrame->coded_picture_number,\n    pFrame->display_picture_number\n);\n```\n\nFinalmente, podemos guardar nuestro cuadro decodificado dentro de una [imagen gris simple](https://en.wikipedia.org/wiki/Netpbm_format#PGM_example). El proceso es muy sencillo, nosotros usaremos el `pFrame->data,`, donde el ndice esta relacionado con los [planos Y, Cb y Cr](https://en.wikipedia.org/wiki/YCbCr), nosotros solo seleccionamos  `0` (Y) para guardar nuestra imagen gris.\n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    // escribiendo el encabezado mnimo para un formato de un archivo pgm\n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // escribiendo linea por linea\n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n```\n\nY voil! Ahora nosotros tenemos una imagen gris a escala de 2MB:\n\n![saved frame](/img/generated_frame.png)\n\n## Captulo 1 - sincronizando audio y video\n\n> **S el jugador** - un joven desarrollador de JS escribiendo un nuevo reproductor de video MSE.\n\nAntes de que nos movamos a [codificar un ejemplo de transcoding](#capitulo2-transcoding) ahora vamos a hablar acerca de la **sincronizacin (timing)**, o como el reproductor de video lo conoce, el tiempo correcto para reproducir un cuadro.\n\nEn el ultimo ejemplo, hemos guardado algunos cuadros que pueden verse aqu:\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\nCuando nosotros estamos diseando un reproductor de video, nosotros necesitamos **reproducir cada cuadro a su debido tiempo**, de otra forma sera difcil ver un video de manera agradable, porque se estara reproduciendo demasiado rpido o lento.\n\nPor lo tanto, necesitamos introducir algo de lgica para reproducir sin complicaciones cada cuadro. Para ello, cada cuadro tiene un **Timestamp de presentacin** (PTS) el cual tiene un numero creciente factorizado en un **timebase (tiempo base)**, que es un numero racional (donde el denominador es conocido como **timescale**) divisible por el **frame rate (fps)**.\n\nEs fcil entender cuando vemos algunos ejemplos, vamos a simular varios escenarios.\n\nPara un `fps=60/1` y `timebase=1/60000` cada PTS se incrementar `timescale / fps = 1000`, por lo tanto el **PTS en tiempo real** por cada cuadro podra ser (suponiendo que empieza en 0):\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\nPara casi el mismo escenario pero con un timebase igual a `1/60`.\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\nPara un `fps=25/1` y `timebase=1/75` cada PTS se incrementar `timescale / fps = 3` y el tiempo PTS podra ser:\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\nAhora con el `pts_time` podemos encontrar una forma de renderizarlo, esto es sincronizndolo con el audio `pts_time` o con el reloj del sistema. El FFmpeg libav provee esa informacin a travs de su API:\n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\nPor pura curiosidad, observa que los cuadros fueron guardados en el orden DTS (cuadros: 1, 6, 4, 2, 3, 5) pero reproducidos en un orden PTS (cuadros: 1, 2, 3, 4, 5). Adems, nota que poco costo tienen los cuadros-B en comparacin con los cuadros-P o cuadros-I.\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n## Captulo 2 - remuxing\n\nRemuxing (remultiplexar) es el acto de cambiar de un formato (contenedor) a otro, por ejemplo, nosotros podemos cambiar un video [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14) a uno  [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream) sin muchos problemas usando FFmpeg:\n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\nEsto va a desmultiplexar (demux) el mp4 pero no lo va a decodificar o codificar (`-c copy`) y al final, esto lo multiplexa (mux) dentro de un archivo `mpegts`. Si tu no provees el formato `-f`, entonces FFmpeg va a tener que determinarlo en base de la extensin del archivo.\n\nEl uso general de FFmpeg o libav sigue un patrn/arquitectura o flujo de trabajo:\n\n* **[protocol layer](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - este acepta una entrada (`input`) (un archivo o `file`, o por ejemplo la entrada tambin podra ser  `rtmp` o `HTTP`)\n* **[format layer](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - este desmultiplexa (`demuxes`) su contenido, revelando, en mayor parte, los metadatos y sus streams\n* **[codec layer](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - esto decodifica (`decodes`) sus datos de stream comprimidos<sup>*opcional*</sup>\n* **[pixel layer](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** - aqu tambin se pueden aplicar filtros (`filters`) a los cuadros en bruto (como resizing)<sup>*optional*</sup>\n* y despus lo hace en el sentido contrario.\n* **[codec layer](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - esto codifica (`encodes`) (o re-encodifica (`re-encodes`) o incluso transcodifican o `transcodes`) los cuadros en bruto<sup>*opcional*</sup>\n* **[format layer](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - esto multiplexa (`muxes`) (o remultiplexa  (`remuxes`) los streams en bruto (los datos comprimidos)\n* **[protocol layer](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - y finalmente los datos multiplexados son enviados a una salida o `output` (otro archivo o quizs, un servidor remoto en la red)\n\n![ffmpeg libav workflow](/img/ffmpeg_libav_workflow.jpeg)\n\n> Esta imagen est fuertemente inspirada por los trabajos de [Leixiaohua](http://leixiaohua1020.github.io/#ffmpeg-development-examples) y [Slhck](https://slhck.info/ffmpeg-encoding-course/#/9).\n\nAhora vamos a codificar un ejemplo usando libav para proveer el mismo efecto que en `ffmpeg input.mp4 -c copy output.ts`.\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\nComo en los ejemplos anteriores, empezaremos por acomodar la memoria y abrir el formato de la entrada. Para este caso en especfico, vamos a abrir un archivo de entrada y acomodar memora para un archivo de salida.\n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n  fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n  goto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n  fprintf(stderr, \"Failed to retrieve input stream information\");\n  goto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n  fprintf(stderr, \"Could not create output context\\n\");\n  ret = AVERROR_UNKNOWN;\n  goto end;\n}\n```\n\nVamos a remultiplexar solamente los tipos de streams de video, audio y subttulos, as que vamos a obtener que streams vamos a estar usando dentro de un arreglo de ndices.\n\n ```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n ```\n\nDespus de haber acomodado la memoria requerida, vamos a navegar por todos los streams, por cada uno necesitaremos crear un nuevo stream dentro de nuestro contexto de formato de salida, usando la funcin [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827). Nota como estamos marcando todos los streams que no son video, audio o subtitulo, as que podemos saltarlos para luego.\n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n  AVStream *out_stream;\n  AVStream *in_stream = input_format_context->streams[i];\n  AVCodecParameters *in_codecpar = in_stream->codecpar;\n  if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n    streams_list[i] = -1;\n    continue;\n  }\n  streams_list[i] = stream_index++;\n  out_stream = avformat_new_stream(output_format_context, NULL);\n  if (!out_stream) {\n    fprintf(stderr, \"Failed allocating output stream\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n  ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n  if (ret < 0) {\n    fprintf(stderr, \"Failed to copy codec parameters\\n\");\n    goto end;\n  }\n}\n```\n\nAhora, podemos crear un archivo de salida.\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n  ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n  if (ret < 0) {\n    fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n    goto end;\n  }\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n  fprintf(stderr, \"Error occurred when opening output file\\n\");\n  goto end;\n}\n```\n\nDespus, podemos copiar los streams, paquete por paquete, desde nuestros streams de entrada a los de salida. Continuaremos navegando por los paquetes, mientras estos sigan llegando (`av_read_frame`), por cada paquete vamos a necesitar recalcular el PTS y el DTS, para finalmente escribirlo (`av_interleaved_write_frame`) a nuestro contexto de formato de salida.\n\n```c\nwhile (1) {\n  AVStream *in_stream, *out_stream;\n  ret = av_read_frame(input_format_context, &packet);\n  if (ret < 0)\n    break;\n  in_stream  = input_format_context->streams[packet.stream_index];\n  if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n    av_packet_unref(&packet);\n    continue;\n  }\n  packet.stream_index = streams_list[packet.stream_index];\n  out_stream = output_format_context->streams[packet.stream_index];\n  /* copiar paquete */\n  packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n  packet.pos = -1;\n\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n  ret = av_interleaved_write_frame(output_format_context, &packet);\n  if (ret < 0) {\n    fprintf(stderr, \"Error muxing packet\\n\");\n    break;\n  }\n  av_packet_unref(&packet);\n}\n```\n\nPara finalizar, necesitamos escribir el stream trailer a un archivo multimedia de salida con la funcin [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13).\n\n```c\nav_write_trailer(output_format_context);\n```\n\nAhora, estamos listos para probarlo y la primera prueba va a ser una conversin de formato (contenedor de video) de un video MP4 a un video MPEG-TS. Estamos bsicamente realizando la lnea de comando `ffmpeg input.mp4 -c copy output.ts` con libav.\n\n```bash\nmake run_remuxing_ts\n```\n\nFunciona! !No me crees?! no deberas, podemos checarlo con `ffprobe`:\n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n  Duration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n  Program 1\n    Metadata:\n      service_name    : Service01\n      service_provider: FFmpeg\n    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n    Stream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\nPara resumir todo lo que hicimos esto en una imagen, podemos revisitar nuestra [idea inicial acerca de cmo libav funciona](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture) pero observa que nos saltamos la parte del cdec.\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\nAntes de terminar este captulo, me gustara ensearte una parte importante del proceso de remultiplexacin, **tu puedes pasar esas opciones al multiplexor**. Digamos que se desea entregar un formato [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding), para eso, necesitamos usar [mp4 fragmentado](https://stackoverflow.com/a/35180327) (a veces es referido como `fmp4`) en lugar de MPEG-TS o MPEG-4 plano.\n\nCon la [lnea de comando, podemos hacer eso fcilmente](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting).\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\nCasi igual de fcil como en la lnea de comando, para su versin en libav, solamente debemos pasar las opciones y despus escribir el encabezado de salida, justo antes de copiar los paquetes.\n\n ```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n ```\n\nAhora podemos generar este archivo mp4 fragmentado:\n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\nPara asegurarte que no te estoy mintiendo. Puedes usar esta maravillosa pgina/herramienta [gpac/mp4box.js](http://download.tsi.telecom-paristech.fr/gpac/mp4box.js/filereader.html) o el sitio [http://mp4parser.com/](http://mp4parser.com/) para ver las diferencias, primero carga el mp4 \"comn\".\n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\nComo podrs ver, este tiene un solo atom (o caja) `mdat`, **este es el espacio donde se encuentran los cuadros de video y audio**. Ahora carga el mp4 fragmentado y ve lo que despliega de las cajas `mdat`.\n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n## Captulo 3 - transcoding\n\n> #### TLDR; ensame el [cdigo](/3_transcoding.c) y ejecuta.\n> ```bash\n> $ make run_transcoding\n> ```\n> Vamos a saltarnos unos detalles, pero no te preocupes: el [el codigo fuente est disponible en GitHub](/3_transcoding.c).\n\nEn este capitulo, vamos a crear un transcoder minimalista, escrito en C, que pueda convertir videos codificados en H264 a H265 usando la librera **FFmpeg/libav**, especficamente [libavcodec](https://ffmpeg.org/libavcodec.html), libavformat, y libavutil.\n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> _Solo una recapitulacin rpida:_ El [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html) es la abstraccin del formato para un archivo multimedia, alias contenedor (ej. MKV, MP4, Webm, TS). El [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html) representa cada tipo de datos para un formato dado (ej: audio, video, subtitulo, metadatos). El [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html) es una porcin de datos comprimidos, los cuales son adquiridos desde `AVStream` y que pueden ser decodificados por un [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html) (ej: av1, h264, vp9, hevc) generando datos en bruto, llamados [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n### Transmuxing \n\nVamos a empezar con una simple operacin de transmultiplexacin (transmuxing) y despus podemos construir sobre este cdigo, el primer paso es **cargar el archivo de entrada**.\n\n```c\n// Acomoda un AVFormatContext\navfc = avformat_alloc_context();\n// Abre un stream de entrada y lee el encabezado.\navformat_open_input(avfc, in_filename, NULL, NULL);\n// Lee los paquetes del archivo para obtener la informacion de streams.\navformat_find_stream_info(avfc, NULL);\n```\n\nAhora vamos a poner en pie el decodificador, el `AVFormatContext` nos va a dar acceso a todos los componentes `AVStream` y por cada uno de ellos, podremos obtener su `AVCodec` y crear su `AVCodecContext` en particular y finalmente podremos abrir el cdec dado, as entonces podremos proceder con el proceso de decodificacin.\n\n>  El [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) contiene datos acerca de la configuracin del archivo como la tasa de bits (bit rate), tasa de cuadros (frame rate), tasa de muestreo (sample rate), canales (channels), altura (height), as como muchos otros.\n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n  AVStream *avs = avfc->streams[i];\n  AVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  AVCodecContext *avcc = avcodec_alloc_context3(*avc);\n  avcodec_parameters_to_context(*avcc, avs->codecpar);\n  avcodec_open2(*avcc, *avc, NULL);\n}\n```\n\nNecesitamos preparar el archivo multimedia para transmultiplexacin tambin, primero debemos **acomodar memoria** para la salida `AVFormatContext`. Creamos **cada uno de los streams** en el formato de salida. Para poder empaquetar propiamente el stream, **copiamos los parmetros del cdec** desde el decodificador.\n\n**Establecemos la bandera** `AV_CODEC_FLAG_GLOBAL_HEADER` el cual le dice al encodificador que puede usar los encabezados globales y finalmente abrimos el **archivo de salida para vaciar los datos** y mantener los encabezados.\n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n  encoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\nNosotros conseguiremos los `AVPacket` desde el decodificador, ajustando los timestamps, y as poder escribir apropiadamente el paquete en el archivo de salida. Aunque la funcin `av_interleaved_write_frame` dice \"write frame\" (escribir cuadro), estamos guardando el paquete. Terminaremos el proceso de transmultiplexacin escribiendo el stream del trailer, que se encuentra dentro del archivo.\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  av_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n  av_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n### Transcoding\n\nLa seccin previa mostr un programa transmultiplexador, ahora vamos a agregar la capacidad para codificar los archivos, especficamente, vamos a habilitarlo para transcodificar videos desde `h264` a `h265`.\n\nDespus de que preparamos el decodificador, pero antes de acomodar el archivo de salida multimedia, vamos a configurar el encodificador.\n\n* Crea el video `AVStream` en el encodificador, [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)\n* Usa el `AVCodec` llamado `libx265`, [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37)\n* Crear el `AVCodecContext` basado en el cdec creado, [`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)\n* Configurar los atributos bsicos para la sesin de transcodificacin, y\n* Abre el cdec y copia los parmetros del contexto al stream. [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) y [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe) \n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n// vamos a usar las opciones internas para x265\n// esto deshabilita la deteccion de cambio de escena y despues fija\n// GOP en 60 cuadros.\nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// parametros de codec para el encoder \nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// control de tasa\nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// tiempo base\nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\nNecesitamos expandir nuestro ciclo decodificador para la transcodificacin del stream de video:\n\n* Enva el `AVPacket` vaco al decodificador, [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)\n* Recibir el `AVFrame` descomprimido, [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)\n* Empezar a transcodificar este cuadro en bruto,\n* Enviar este cuadro en bruto, [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169)\n* Recibe el contenido comprimido, basado en nuestro cdec, `AVPacket`, [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga5b8eff59cf259747cf0b31563e38ded6)\n* Establece el timestamp, y[`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n* Escrbelo a un archivo de salida. [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  int response = avcodec_send_packet(decoder_video_avcc, input_packet);\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder_video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return response;\n    }\n    if (response >= 0) {\n      encode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n    }\n    av_frame_unref(input_frame);\n  }\n  av_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// funcion usada\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n  AVPacket *output_packet = av_packet_alloc();\n  int response = avcodec_send_frame(video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return -1;\n    }\n\n    output_packet->stream_index = index;\n    output_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n    response = av_interleaved_write_frame(avfc, output_packet);\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\n```\n\nVamos a convertir el stream desde `h264` a `h265`, como se espera de la versin `h265`, el archivo es ms pequeo que el `h264` sin embargo el [programa creado](/3_transcoding.c) es capaz de:\n\n```c\n\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.muxer_opt_key = \"movflags\";\n  sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 0;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.audio_codec = \"aac\";\n  sp.output_extension = \".ts\";\n\n  /* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n\n```\n\n> Ahora, para ser honesto, esto fue [ms difcil de lo que pens](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54), voy a tener que y ya me he metido dentro de [el cdigo fuente de la linea de comandos FFmpeg](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749) y probarlo bastante, y tambin pienso que estoy olvidando algo, ya que cuando tengo que forzar `force-cfr` para que el `h264` funcione, me sigue arrojando algunos mensajes como `warning messages (forced frame type (5) at 80 was changed to frame type (3))`."
        },
        {
          "name": "README-ko.md",
          "type": "blob",
          "size": 52.462890625,
          "content": "[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\n[FFmpeg](https://www.ffmpeg.org/) (a.k.a. libav)     / .  [\"How to write a video player in less than 1k lines\"](http://dranger.com/ffmpeg/)   .\n          .\n\n    C . **  **:         .\nFFmpeg libav [python](https://pyav.org/), [go](https://github.com/imkira/go-libav)      bindings .      `ffi`    . ([Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua) )\n\n  , ,       `FFmpeg`         , [ FFmpeg libav ](#-FFmpeg-libav-)    .\n\n     TV   .   FFmpeg    .\n\n____\n\n* [](#intro)\n  * [ -   !](#-----!)\n  * [ -   !](#-----!)\n  * [ -  ](#----)\n  * [ -   ](#[-----)\n* [FFmpeg -  ](#FFmpeg----)\n  * [FFmpeg   101](#FFmpeg---101)\n* [  ](#--)\n  * [ (Transcoding)](#-(Transcoding))\n  * [ (Transmuxing)](#-(Transmuxing))\n  * [ (Transrating)](#-(Transrating))\n  * [ (Transsizing)](#-(Transsizing))\n  * [:   (Adaptive Streaming)](#:---(Adaptive-Streaming))\n  * [ ](#-)\n* [ FFmpeg libav ](#-FFmpeg-libav-)\n  * [ 0 -   hello world](#-0-----hello-world)\n    * [FFmpeg libav ](#FFmpeg-libav-)\n  * [ 1 -  (timing)](#-1-----)\n  * [ 2 -  (remuxing)](#-2----(remuxing))\n  * [ 3 -  (transcoding)](#-3----(transcoding))\n\n# \n\n##  -   !\n\n            ( [ 24 ](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/)), [ ](https://en.wikipedia.org/wiki/Persistence_of_vision)   .\n      : **      / **.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\nZeitgenssische Illustration (1886)\n\n##  -   !\n\n                .  \n\n   , ,          .\n\n>         , -  (ADC) -  [-  (PCM)](https://en.wikipedia.org/wiki/Pulse-code_modulation)  -     .\n\n![audio analog to digital](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analog to digital\")\n>[](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n##  -  \n\n> CODEC ** /  **  .  raw ()  /      .\n> https://en.wikipedia.org/wiki/Video_codec\n\n          ,         .  : \n\n .  `1080 x 1920` ( x )       `3 bytes` (  )  . ( [24 ](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29), 16,777,216   )    ` 24`  `30`  . \n\n```c\ntoppf = 1080 * 1920 //total_of_pixels_per_frame\ncpp = 3 //cost_per_pixel\ntis = 30 * 60 //time_in_seconds\nfps = 24 //frames_per_second\n\nrequired_storage = tis * fps * toppf * cpp\n```\n\n   `250.28GB`    `1.19Gbps`  !    [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work)  .\n\n##  -   \n\n>   (wrapper)               .\n> https://en.wikipedia.org/wiki/Digital_container_format\n\n**     ** (  )    ,      .\n\n        :  `video.webm`  [`webm`](https://www.webmproject.org/)   .\n\n![container](/img/container.png)\n\n# FFmpeg -  \n\n>         - .\n\n    [FFmpeg](https://www.ffmpeg.org/)    /   .     /   . ([Chrome](https://www.chromium.org/developers/design-documents/video) ?). \n\n `ffmpeg`        .\n,      `mp4` `avi`   :\n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\n\n        **remuxing** .\n FFmpeg (transcoding)        .\n\n## FFmpeg   101\n\nFFmpeg       [](https://www.ffmpeg.org/ffmpeg.html) . \n\n , FFmpeg          `ffmpeg {1} {2} -i {3} {4} {5}`, :\n\n1.  \n2.   \n3.  url\n4.   \n5.  url\n\n2, 3, 4, 5     .\n         :\n\n``` bash\n# WARNING: this file is around 300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ #  \n-c:a libfdk_aac \\ #   \n-i bunny_1080p_60fps.mp4 \\ #  url\n-c:v libvpx-vp9 -c:a libvorbis \\ #   \nbunny_1080p_60fps_vp9.webm #  url\n```\n   (`aac`    `h264`   )  `mp4`     `webm` ,        .\n\n       FFmpeg    .\n `ffmpeg -i input.avi output.mp4`    /  `output.mp4`   ?\n\nWerner Robitza   / [FFmpeg     ](http://slhck.info/ffmpeg-encoding-course/#/) .\n\n#   \n\n/         .\n\n##  (Transcoding)\n\n![transcoding](/img/transcoding.png)\n\n**?**  (  )        .\n\n**?**    (, ,  ) X   Y .         .\n\n**?** `H264` (AVC)  `H265` (HEVC) .\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n##  (Transmuxing)\n\n![transmuxing](/img/transmuxing.png)\n\n**?**   ()    .\n\n**?**    (, ,  ) X   Y .         .\n\n**?** `mp4` `webm` .\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ # just saying to ffmpeg to skip encoding\nbunny_1080p_60fps.webm\n```\n\n##  (Transrating)\n\n![transrating](/img/transrating.png)\n\n**?**    (renditions)  .\n\n**?**  `2G` (edge)    ``   4K     .          .\n\n**?** 3856K 2000K     .\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\n (transrating) (transsizing)  . Werner Robitza    / [FFmpeg rate    ](http://slhck.info/posts/) .\n\n##  (Transsizing)\n\n![transsizing](/img/transsizing.png)\n\n**?**      .    (transsizing)  (transrating)  .\n\n**?** (transrating)  .\n\n**?** `1080p`  `480p` .\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## :   (Adaptive Streaming)\n\n![adaptive streaming](/img/adaptive-streaming.png)\n\n**?**  ()       http   .\n\n**?**    4K TV       .      .     .\n\n**?** DASH   WebM .\n```bash\n# video streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# audio streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# the DASH manifest\n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPS:    [DASH  Adaptive WebM   ](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash) .\n\n##  \n\n[FFmpeg     ](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly) .\n  YouTube   / *iMovie*  .      .\n\n#  FFmpeg libav \n\n>  '   '  ?\n> **David Robert Jones**\n\n[FFmpeg](#ffmpeg---command-line)          .      ?\n\nFFmpeg      [  ](https://www.ffmpeg.org/doxygen/trunk/index.html).\n, FFmpeg      .    **FFmpeg libav** .\n\n>   Zed Shaw [Learn X the Hard Way](https://learncodethehardway.org/) ,    Learn C the Hard Way  .\n\n##  0 -   hello world\n hello world  `\"hello world\"`    . :tongue:\n  **  ** .   (), , ,     .   **     **.\n\n### FFmpeg libav \n\n   , **FFmpeg libav **        . \n\n       .\n\n![ffmpeg libav architecture - decoding process](/img/decoding.png)\n\n    [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) (   )     .\n     :   .\n\n  ** ** ,    (      )   .\n  [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)    .\n\n>      fancy .\n\n     :  [AAC CODEC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding)   [H264 (AVC) CODEC](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC) .   [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html)     ** **   .\n\n**    ** ().        [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html) .\n\n`AVCodec`  [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html)    **  ** .      /   .\n\n###  \n\n        ** /  [`Docker`](https://docs.docker.com/install/)  ,**   big buck bunny         `make fetch_small_bunny_video`   .\n\n###  0 -  \n\n> #### TLDR; [](/0_hello_world.c)  .\n> ```bash\n> $ make run_hello\n> ```\n>    .   : [  github ](/0_hello_world.c). \n\n ()     [`AVFormatContext`](http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html)   .\n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\n      `AVFormatContext`       (   ).\n    [`avformat_open_input`](http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49).   `AVFormatContext` `filename`    : [`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html) (`NULL`  FFmpeg  ) [`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html) (demuxer  )\n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\n      :\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\n`streams`  ,   . [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb)    .\n`pFormatContext->nb_streams`     `pFormatContext->streams[i]` `i`  ([`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)) .\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\n\n     .\n\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n  //\n}\n```\n\n  , `i`      [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html) .\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\n\n    [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca)       .  id       en**CO**de **DEC**ode   [`AVCodec`](http://ffmpeg.org/doxygen/trunk/structAVCodec.html)    .\n\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\n      .\n\n```c\n// specific for video and audio\nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n  printf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n  printf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// general\nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n```\n\n   /     [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html)    .       ; [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16) .\n\n        . [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) . \n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\n       .  , [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html)      .\n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\n     [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61)     . \n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n  //...\n}\n```\n\n  [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)    **raw   ( ) **.\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\n    [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)    **raw   (  ) **.\n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\n , [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp), DTS, [ ](https://en.wikipedia.org/wiki/Video_compression_picture_types)    .\n\n```c\nprintf(\n    \"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n    av_get_picture_type_char(pFrame->pict_type),\n    pCodecContext->frame_number,\n    pFrame->pts,\n    pFrame->pkt_dts,\n    pFrame->key_frame,\n    pFrame->coded_picture_number,\n    pFrame->display_picture_number\n);\n```\n\n   [  ](https://en.wikipedia.org/wiki/Netpbm_format#PGM_example)   .    ,  [planes Y, Cb, Cr](https://en.wikipedia.org/wiki/YCbCr)   `pFrame->data`  .      `0` (Y)  .\n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    // writing the minimal required header for a pgm file format\n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // writing line by line\n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n```\n\nvoil!   2MB   :\n\n![saved frame](/img/generated_frame.png)\n\n##  1 -   \n\n> ** ** -  MSE      JS \n\n[  ](#-3----(transcoding))   ****          .\n\n ,     .\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\n    **    **,             .\n\n          .   ,   ** ** (PTS)    **(fps)**   **(timebase)**   ( **(timescale)**  ) (factored)  .\n\n      ,   .\n\n`fps=60/1`  `timebase=1/60000`   PTS `timescale / fps = 1000`   .    **PTS  **   (0  ):\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\n   `1/60`.\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\n`fps=25/1` `timebase=1/75`   PTS `timescale / fps = 3`   PTS     :\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\n  `pts_time`  `pts_time`         . FFmpeg libav    API  .\n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\n ,    DTS  (frames: 1,6,4,2,3,5)   PTS  (frames: 1,2,3,4,5) . , B- P  I-      .\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n##  2 -  (remuxing)\n\nRemuxing   ()    .   FFmpeg     [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14)  [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream)   :\n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\n mp4 demux    . (`-c copy`)  `mpegts`  mux .    `-f`   ffmpeg     .\n\nFFmpeg  libav    /   : \n* **[ ](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - `input`  ( `file` `rtmp`  `HTTP`  ).\n* **[ ](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** -  `demuxes`,    \n* **[ ](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** -    `decodes` <sup>*optional*</sup>\n* **[ ](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** - raw   ( ) `filters`    <sup>*optional*</sup>\n* and then it does the reverse path\n* **[ ](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - raw  `encodes` ( `re-encodes`  `transcodes` ) <sup>*optional*</sup>\n* **[ ](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - raw  ( ) `muxes` ( `remuxes`)\n* **[ ](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** -   muxed  `output`  (       )\n\n![ffmpeg libav workflow](/img/ffmpeg_libav_workflow.jpeg)\n>   [Leixiaohua's](http://leixiaohua1020.github.io/#ffmpeg-development-examples) [Slhck's](https://slhck.info/ffmpeg-encoding-course/#/9)     .\n\n  `ffmpeg input.mp4 -c copy output.ts`      libav     .\n\n (`input_format_context`)     (`output_format_context`) .\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\n      .   ,        . \n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n  fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n  goto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n  fprintf(stderr, \"Failed to retrieve input stream information\");\n  goto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n  fprintf(stderr, \"Could not create output context\\n\");\n  ret = AVERROR_UNKNOWN;\n  goto end;\n}\n```\n\n, ,    remux       . \n\n```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n```\n\n   ,       [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)         . , ,            .\n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n  AVStream *out_stream;\n  AVStream *in_stream = input_format_context->streams[i];\n  AVCodecParameters *in_codecpar = in_stream->codecpar;\n  if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n    streams_list[i] = -1;\n    continue;\n  }\n  streams_list[i] = stream_index++;\n  out_stream = avformat_new_stream(output_format_context, NULL);\n  if (!out_stream) {\n    fprintf(stderr, \"Failed allocating output stream\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n  ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n  if (ret < 0) {\n    fprintf(stderr, \"Failed to copy codec parameters\\n\");\n    goto end;\n  }\n}\n```\n\n     .\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n  ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n  if (ret < 0) {\n    fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n    goto end;\n  }\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n  fprintf(stderr, \"Error occurred when opening output file\\n\");\n  goto end;\n}\n```\n\n ,       .    (`av_read_frame`),    PTS DTS      (`av_interleaved_write_frame`) .\n\n```c\nwhile (1) {\n  AVStream *in_stream, *out_stream;\n  ret = av_read_frame(input_format_context, &packet);\n  if (ret < 0)\n    break;\n  in_stream  = input_format_context->streams[packet.stream_index];\n  if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n    av_packet_unref(&packet);\n    continue;\n  }\n  packet.stream_index = streams_list[packet.stream_index];\n  out_stream = output_format_context->streams[packet.stream_index];\n  /* copy packet */\n  packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n  packet.pos = -1;\n\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n  ret = av_interleaved_write_frame(output_format_context, &packet);\n  if (ret < 0) {\n    fprintf(stderr, \"Error muxing packet\\n\");\n    break;\n  }\n  av_packet_unref(&packet);\n}\n```\n\n  [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13)    (trailer)    .\n\n```c\nav_write_trailer(output_format_context);\n```\n\n   .   MP4 MPEG-TS    ( ) .   `ffmpeg input.mp4 -c copy output.ts`  libav   .\n\n```bash\nmake run_remuxing_ts\n```\n\n!!!   ?!  , `ffprobe`  :\n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n  Duration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n  Program 1\n    Metadata:\n      service_name    : Service01\n      service_provider: FFmpeg\n    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n    Stream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\n     ,  [libav    ](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture)         .\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\n    (remuxing)     , **muxer    ** .   [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding)    MPEG-TS  MPEG-4  (`fmp4` ) [fragmented mp4](https://stackoverflow.com/a/35180327) .\n\n[     ](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting).\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\nlibav     .    ,        . \n\n```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n```\n\n fragmented mp4    :\n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\n     .     [gpac/mp4box.js](http://download.tsi.telecom-paristech.fr/gpac/mp4box.js/filereader.html)  [http://mp4parser.com/](http://mp4parser.com/)    /   .  \"common\" mp4  . \n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\n   `mdat` (atom) , **    **.  fragmented mp4  `mdat`    .\n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n##  3 -  (transcoding)\n\n> #### TLDR; [](/3_transcoding.c)  .\n> ```bash\n> $ make run_transcoding\n> ```\n>    ,   : [  github ](/3_transcoding.c). \n\n     , C  ,  H264   H265   . **FFmpeg/libav** ,  [libavcodec](https://ffmpeg.org/libavcodec.html), libavformat, libavutil . \n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> _ :_ [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html)  (ex: MKV, MP4, Webm, TS)       . [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html)   (ex: , , , )     . [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html) `AVStream`    .   [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html) (ex: av1, h264, vp9, hevc)   [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html)  raw  .\n\n###  (Transmuxing)\n\n   .       .   **  **.\n\n```c\n// Allocate an AVFormatContext\navfc = avformat_alloc_context();\n// Open an input stream and read the header.\navformat_open_input(avfc, in_filename, NULL, NULL);\n// Read packets of a media file to get stream information.\navformat_find_stream_info(avfc, NULL);\n```\n\n   , `AVFormatContext`  `AVStream`      .    , `AVCodec`   `AVCodecContext` .          .\n\n> [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) ,  , , ,         .\n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n  AVStream *avs = avfc->streams[i];\n  AVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  AVCodecContext *avcc = avcodec_alloc_context3(*avc);\n  avcodec_parameters_to_context(*avcc, avs->codecpar);\n  avcodec_open2(*avcc, *avc, NULL);\n}\n```\n\n     ,   `AVFormatContext`  ** **.    ** ** .      **  **.\n\n       `AV_CODEC_FLAG_GLOBAL_HEADER` ** **.   **  **   .\n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n  encoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\n `AVPacket` ,  ,     . `av_interleaved_write_frame`    \"write frame\"      .        . \n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  av_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n  av_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n###  (Transcoding)\n\n     ,     . , `h264` `h265`     .\n\n  ,         .\n\n*   `AVStream` , [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)\n* `libx265`  `AVCodec` , [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37)\n*    `AVCodecContext` ,[`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)\n*      , \n*      . [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d), [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe)\n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n// we're going to use internal options for the x265\n// it disables the scene change detection and fix then\n// GOP on 60 frames.\nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// encoder codec params\nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// control rate\nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// time base\nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\n      .\n\n*   `AVPacket` , [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)\n*   `AVFrame` , [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)\n*  raw   ,\n* raw  () , [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169)\n*    `AVPacket` , [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga5b8eff59cf259747cf0b31563e38ded6)\n*  , [`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n*    . [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  int response = avcodec_send_packet(decoder_video_avcc, input_packet);\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder_video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return response;\n    }\n    if (response >= 0) {\n      encode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n    }\n    av_frame_unref(input_frame);\n  }\n  av_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// used function\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n  AVPacket *output_packet = av_packet_alloc();\n  int response = avcodec_send_frame(video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return -1;\n    }\n\n    output_packet->stream_index = index;\n    output_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n    response = av_interleaved_write_frame(avfc, output_packet);\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\n```\n\n `h265`    `h264`      `h264` `h265` .  [ ](/3_transcoding.c)     :\n\n```c\n\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.muxer_opt_key = \"movflags\";\n  sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 0;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.audio_codec = \"aac\";\n  sp.output_extension = \".ts\";\n\n  /* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n\n```\n\n>   , [    ](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/53). [FFmpeg  ](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749)    .       ,  `force-cfr`   `h264`  `warning messages (forced frame type (5) at 80 was changed to frame type (3))`       .\n"
        },
        {
          "name": "README-pt.md",
          "type": "blob",
          "size": 48.6982421875,
          "content": "[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\nEu estava procurando por um tutorial/livro que me ensinasse a comear a usar o [FFmpeg](https://www.ffmpeg.org/) como biblioteca (tambm conhecida como libav) e ento encontrei o tutorial [\"Como escrever um player de vdeo em menos de 1k linhas\"](http://dranger.com/ffmpeg/).\nInfelizmente, ele foi descontinuado, ento decidi escrever este.\n\nA maior parte do cdigo aqui ser em C **mas no se preocupe**: voc pode facilmente entender e aplic-lo  sua linguagem preferida.\nO FFmpeg libav tem muitas ligaes para vrias linguagens, como [python](https://pyav.org/), [go](https://github.com/imkira/go-libav) e mesmo que sua linguagem no tenha, ainda  possvel suport-la atravs do `ffi` (aqui est um exemplo com [Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua)).\n\nComearemos com uma breve lio sobre o que  vdeo, udio, codec e continer e depois faremos um curso intensivo sobre como usar a linha de comando do `FFmpeg` e, finalmente, escreveremos cdigo. Sinta-se  vontade para pular diretamente para a seo [Aprenda o FFmpeg libav do jeito difcil.](#aprenda-o-ffmpeg-libav-do-modo-difcil)\n\nAlgumas pessoas costumavam dizer que o streaming de vdeo na internet  o futuro da TV tradicional, de qualquer forma, o FFmpeg  algo que vale a pena estudar.\n\n__ndice__\n\n* [Introduo](#introduo)\n\t* [Vdeo - O que voc v!](#vdeo---o-que-voc-v)\n\t* [udio - O que voc ouve!](#udio---o-que-voc-ouve)\n\t* [Codec - reduzindo dados](#codec---reduzindo-dados)\n\t* [Container - um lugar confortvel para udio e vdeo](#container---um-lugar-confortvel-para-udio-e-vdeo)\n* [FFmpeg - linha de comando](#ffmpeg---linha-de-comando)\n\t* [Ferramenta de linha de comando do FFmpeg 101](#ferramenta-de-linha-de-comando-do-ffmpeg-101)\n* [Operaes comuns de vdeo](#operaes-comuns-de-vdeo)\n\t* [Transcodificao](#transcodificao)\n\t* [Transmuxing](#transmuxing)\n\t* [Transcodificao de Taxa de Bits](#transcodificao-de-taxa-de-bits)\n\t* [Transdimensionamento](#transdimensionamento)\n\t* [Bnus: Streaming Adaptativo](#bnus-streaming-adaptativo)\n\t* [Indo alm](#indo-alm)\n* [Aprenda o FFmpeg libav do modo difcil](#aprenda-o-ffmpeg-libav-do-modo-difcil)\n  \t* [Captulo 0 - O famoso \"hello world\"](#captulo-0---o-famoso-hello-world)\n\t\t* [Arquitetura da biblioteca FFmpeg libav](#arquitetura-da-biblioteca-ffmpeg-libav)\n\t* [Captulo 1 - Sincronizao de udio e vdeo](#captulo-1---sincronizao-de-udio-e-vdeo)\n\t* [Captulo 2 - Remuxing](#captulo-2---remuxing)\n\t* [Captulo 3 - Transcoding](#captulo-3---transcoding)\n\n# Introduo\n\n## Vdeo - O que voc v!\n\nSe voc tem uma sequncia de imagens e as altera com uma determinada frequncia (digamos [24 imagens por segundo](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/)), voc criar uma [iluso de movimento](https://en.wikipedia.org/wiki/Persistence_of_vision).\nEm resumo, essa  a ideia bsica por trs de um vdeo: **uma srie de imagens/quadros sendo executados a uma determinada taxa**.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\nZeitgenssische Illustration (1886)\n\n## udio - O que voc ouve!\n\nEmbora um vdeo sem som possa expressar uma variedade de sentimentos, adicionar som a ele traz mais prazer  experincia.\n\nO som  a vibrao que se propaga como uma onda de presso, atravs do ar ou qualquer outro meio de transmisso, como um gs, lquido ou slido.\n\n> Em um sistema de udio digital, um microfone converte o som em um sinal eltrico analgico, em seguida, um conversor analgico-digital (ADC) - tipicamente usando [modulao por cdigo de pulso (PCM)](https://en.wikipedia.org/wiki/Pulse-code_modulation) - converte o sinal analgico em um sinal digital.\n\n![audio analog to digital](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analog to digital\")\n>[Fonte](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n## Codec - reduzindo dados\n\n> CODEC  um circuito eletrnico ou software que **comprime ou descomprime udio/vdeo digital.** Ele converte udio/vdeo digital bruto (no comprimido) para um formato comprimido ou vice-versa.\n> https://en.wikipedia.org/wiki/Video_codec\n\nMas se escolhermos empacotar milhes de imagens em um nico arquivo e cham-lo de filme, podemos acabar com um arquivo enorme. Vamos fazer as contas:\n\nSuponha que estamos criando um vdeo com resoluo `1080 x 1920` (altura x largura) e que gastaremos `3 bytes` por pixel (o ponto mnimo em uma tela) para codificar a cor (ou [cor de 24 bits](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29), o que nos d 16.777.216 cores diferentes) e este vdeo  executado a `24 quadros por segundo` e tem `30 minutos` de durao.\n\n```c\ntoppf = 1080 * 1920 // total_de_pixels_por_quadro\ncpp = 3 //custo_por_pixel\ntis = 30 * 60 //tempo_em_segundos\nfps = 24 //quadros_por_segundo\n\narmazenamento_necessrio = tis * fps * toppf * cpp\n```\n\nEste vdeo exigiria aproximadamente `250,28 GB` de armazenamento ou `1,19 Gbps` de largura de banda!  por isso que precisamos usar um [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work).\n\n## container - um lugar confortvel para udio e vdeo\n\n> Um formato de container ou envoltrio  um formato de metafile cuja especificao descreve como diferentes elementos de dados e metadados coexistem em um arquivo de computador.\n> https://en.wikipedia.org/wiki/Digital_container_format\n\nUm **nico arquivo que contm todos os fluxos** (principalmente udio e vdeo) e tambm fornece **sincronizao e metadados gerais**, como ttulo, resoluo, entre outros.\n\nNormalmente, podemos inferir o formato de um arquivo ao olhar para sua extenso: por exemplo, um `video.webm` provavelmente  um vdeo usando o container [`webm`](https://www.webmproject.org/).\n\n![container](/img/container.png)\n\n# FFmpeg - linha de comando\n\n> Uma soluo completa e multiplataforma para gravar, converter e transmitir udio e vdeo.\n\nPara trabalhar com multimdia, podemos usar a FERRAMENTA/BIBLIOTECA incrvel chamada [FFmpeg](https://www.ffmpeg.org/). Provavelmente, voc j a conhece/usa diretamente ou indiretamente (voc usa o [Chrome?](https://www.chromium.org/developers/design-documents/video)).\n\nEle tem um programa de linha de comando chamado `ffmpeg`, um binrio muito simples, porm poderoso.\nPor exemplo, voc pode converter de `mp4` para o continer `avi` apenas digitando o seguinte comando:\n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\n\nAcabamos de fazer um **remuxing** aqui, que  converter de um continer para outro.\nTecnicamente, o FFmpeg tambm poderia estar fazendo uma transcodificao, mas falaremos sobre isso mais tarde.\n\n## Ferramenta de linha de comando do FFmpeg 101\n\nO FFmpeg possui uma [documentao](https://www.ffmpeg.org/ffmpeg.html) que faz um timo trabalho explicando como ele funciona.\n\n```bash\n# voc tambm pode procurar a documentao usando a linha de comando\n\nffmpeg -h full | grep -A 10 -B 10 avoid_negative_ts\n```\n\nResumidamente, o programa de linha de comando do FFmpeg espera o seguinte formato de argumento para executar suas aes: `ffmpeg {1} {2} -i {3} {4} {5}`, onde:\n\n1. opes globais\n2. opes do arquivo de entrada\n3. URL de entrada\n4. opes do arquivo de sada\n5. URL de sada\n\nAs partes 2, 3, 4 e 5 podem ser quantas voc precisar.\n mais fcil entender esse formato de argumento na prtica:\n\n```bash\n# ATENO: este arquivo tem cerca de 300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ # opes globais\n-c:a libfdk_aac \\ # opes de entrada\n-i bunny_1080p_60fps.mp4 \\ # URL de entrada\n-c:v libvpx-vp9 -c:a libvorbis \\ # opes de sada\nbunny_1080p_60fps_vp9.webm # URL de sada\n```\nEste comando leva um arquivo de entrada `mp4` contendo dois fluxos (um udio codificado com `aac` CODEC e um vdeo codificado usando `h264` CODEC) e o converte para `webm`, mudando seus CODECs de udio e vdeo tambm.\n\nPodemos simplificar o comando acima, mas esteja ciente de que o FFmpeg adotar ou adivinhar os valores padro para voc.\nPor exemplo, quando voc apenas digita `ffmpeg -i input.avi output.mp4`, que CODEC de udio/vdeo ele usa para produzir o `output.mp4`?\n\nWerner Robitza escreveu um [tutorial obrigatrio para ler/executar sobre codificao e edio com FFmpeg](http://slhck.info/ffmpeg-encoding-course/#/).\n\n# Operaes comuns de vdeo\n\nAo trabalhar com udio/vdeo, geralmente realizamos um conjunto de tarefas com a mdia.\n\n## Transcodificao\n\n![transcodificao](/img/transcoding.png)\n\n**O que ?**  o ato de converter um dos fluxos (udio ou vdeo) de um CODEC para outro.\n\n**Por que?** s vezes, alguns dispositivos (TVs, smartphones, consoles etc.) no suportam X, mas sim Y, e os novos CODECs fornecem melhor taxa de compresso.\n\n**Como?** Convertendo um vdeo `H264` (AVC) para `H265` (HEVC).\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n## Transmuxing\n\n![transmuxing](/img/transmuxing.png)\n\n**O que ?**  o ato de converter de um formato (container) para outro.\n\n**Por que?** s vezes, alguns dispositivos (TVs, smartphones, consoles, etc.) no suportam o formato X, mas suportam o Y e, s vezes, os novos formatos (containers) fornecem recursos modernos necessrios.\n\n**Como?** Converter um arquivo `mp4` para `ts`.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ # just saying to ffmpeg to skip encoding\nbunny_1080p_60fps.ts\n```\n\n## Transcodificao de Taxa de Bits\n\n![transrating](/img/transrating.png)\n\n**O que ?**  a alterao da taxa de bits de um vdeo, ou a produo de outras verses do mesmo vdeo.\n\n**Por que fazer?** As pessoas podem tentar assistir ao seu vdeo em uma conexo de rede `2G` (edge) usando um smartphone menos potente ou em uma conexo de fibra ptica em suas TVs 4K. Portanto, voc deve oferecer mais de uma verso do mesmo vdeo com diferentes taxas de bits.\n\n**Como fazer?** Produzindo uma verso com taxa de bits entre 3856K e 2000K.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\nGeralmente, a transcodificao de taxa de bits  usada em conjunto com a transcodificao de tamanho de vdeo. Werner Robitza escreveu outra srie de posts que deve ser lida/executada sobre o controle de taxa do FFmpeg (http://slhck.info/posts/).\n\n## Transdimensionamento\n\n![transsizing](/img/transsizing.png)\n\n**O que ?** a ao de converter de uma resoluo para outra. Como mencionado antes, o transdimensionamento  frequentemente usado junto com o transrating.\n\n**Por qu?** as razes so as mesmas que para o transrating.\n\n**Como?** convertendo uma resoluo `1080p` para `480p`.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## Bnus: Streaming Adaptativo\n\n![Streaming adaptativo](/img/adaptive-streaming.png)\n\n**O que ?** A produo de vrias resolues (taxas de bits) e a diviso da mdia em pedaos para serem servidos por HTTP.\n\n**Por que?** Para fornecer uma mdia flexvel que possa ser assistida em um smartphone de baixo desempenho ou em uma TV 4K, alm de ser fcil de dimensionar e implantar, mas pode adicionar latncia.\n\n**Como?** Criando um WebM adaptativo usando o DASH.\n```bash\n# video streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# audio streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# the DASH manifest\n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPS: Eu roubei esse exemplo das [Instrues para reproduzir Adaptive WebM usando DASH](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash)\n\n## Indo alm\n\nExistem [muitos outros usos para o FFmpeg](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly).\nEu uso em conjunto com o *iMovie* para produzir/editar alguns vdeos para o YouTube e certamente voc pode us-lo profissionalmente.\n\n# Aprenda o FFmpeg libav do modo difcil\n\n> Voc nunca se perguntou sobre som e viso?\n> **David Robert Jones**\n\nJ que o [FFmpeg](#ffmpeg---linha-de-comando)  to til como uma ferramenta de linha de comando para realizar tarefas essenciais em arquivos de mdia, como podemos us-lo em nossos programas?\n\nO FFmpeg  [composto por diversas bibliotecas](https://www.ffmpeg.org/doxygen/trunk/index.html) que podem ser integradas em nossos prprios programas. Geralmente, quando voc instala o FFmpeg, ele instala automaticamente todas essas bibliotecas. Estarei me referindo a esse conjunto de bibliotecas como **FFmpeg libav**.\n\n> Este ttulo  uma homenagem  srie de Zed Shaw [Aprenda X do Modo Difcil](https://learncodethehardway.org/), em particular seu livro Aprenda C do Modo Difcil.\n\n## Captulo 0 - O famoso \"hello world\"\nEste \"hello world\" na verdade no mostrar a mensagem \"hello world\" no terminal :tongue:\nEm vez disso, vamos **imprimir informaes sobre o vdeo**, como seu formato (container), durao, resoluo, canais de udio e, no final, vamos **decodificar alguns quadros e salv-los como arquivos de imagem**.\n\n### Arquitetura da biblioteca FFmpeg libav\n\nMas antes de comearmos a programar, vamos aprender como funciona a **arquitetura da biblioteca FFmpeg libav** e como seus componentes se comunicam entre si.\n\nAqui est um diagrama do processo de decodificao de um vdeo:\n\n![ffmpeg libav architecture - processo de decodificao](/img/decoding.png)\n\nVoc primeiro precisar carregar seu arquivo de mdia em um componente chamado [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) (o continer de vdeo tambm  conhecido como formato).\nNa verdade, ele no carrega todo o arquivo: muitas vezes ele l apenas o cabealho.\n\nDepois de carregar o **cabealho mnimo do nosso continer**, podemos acessar suas streams (pense nelas como dados de udio e vdeo rudimentares).\nCada stream estar disponvel em um componente chamado [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html).\n\n> Stream  um nome elegante para um fluxo contnuo de dados.\n\nSuponha que nosso vdeo tenha duas streams: um udio codificado com [AAC CODEC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding) e um vdeo codificado com [H264 (AVC) CODEC](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC). De cada stream podemos extrair **pedaos (slices) de dados** chamados pacotes que sero carregados em componentes chamados [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html).\n\nOs **dados dentro dos pacotes ainda esto codificados** (comprimidos) e, para decodificar os pacotes, precisamos pass-los para um [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html) especfico.\n\nO `AVCodec` os decodificar em [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html) e, finalmente, este componente nos fornecer **o quadro no comprimido**. Observe que a mesma terminologia/processo  usada tanto para fluxo de udio quanto de vdeo.\n\n### Requisitos\n\nComo algumas pessoas estavam [enfrentando problemas ao compilar ou executar os exemplos](https://github.com/leandromoreira/ffmpeg-libav-tutorial/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+compiling), **vamos usar o [`Docker`](https://docs.docker.com/install/) como nosso ambiente de desenvolvimento/execuo**, tambm usaremos o vdeo Big Buck Bunny, ento se voc no o tiver localmente, basta executar o comando `make fetch_small_bunny_video`.\n\n### Captulo 0 - apresentao do cdigo\n\n> #### TLDR; mostre-me o [cdigo](/0_hello_world.c) e a execuo.\n> ```bash\n> $ make run_hello\n> ```\n\nVamos pular alguns detalhes, mas no se preocupe: o [cdigo-fonte est disponvel no GitHub](/0_hello_world.c).\n\nVamos alocar memria para o componente [`AVFormatContext`](http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) que conter informaes sobre o formato (container).\n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\nAgora vamos abrir o arquivo e ler seu cabealho e preencher o `AVFormatContext` com informaes mnimas sobre o formato (observe que geralmente os codecs no so abertos).\nA funo usada para isso  [`avformat_open_input`](http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49). Ele espera um `AVFormatContext`, um `filename` e dois argumentos opcionais: o [`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html) (se voc passar `NULL`, o FFmpeg adivinhar o formato) e o [`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html) (que so as opes para o demuxer).\n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\nPodemos imprimir o nome do formato e a durao da mdia:\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\nPara acessar as `streams`, precisamos ler os dados da mdia. A funo [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb) faz isso. Agora, o `pFormatContext->nb_streams` ir armazenar a quantidade de streams e o `pFormatContext->streams[i]` nos fornecer a `i`-sima stream (um [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)).\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\n\nAgora vamos iterar por todos os fluxos (streams).\n\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n\t//\n}\n```\n\nPara cada fluxo, vamos manter os [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html), que descreve as propriedades de um codec usado pelo fluxo `i`.\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\n\nCom as propriedades do codec, podemos procurar o CODEC apropriado consultando a funo [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca) e encontrar o decodificador registrado para o id do codec e retornar um [`AVCodec`](http://ffmpeg.org/doxygen/trunk/structAVCodec.html), o componente que sabe como en**CO**der e de**CO**der o fluxo.\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\nAgora podemos imprimir informaes sobre os codecs.\n\n```c\n// especifico para video e audio\nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n\tprintf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n\tprintf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// geral\nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n```\n\nCom o codec, podemos alocar memria para o [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html), que conter o contexto para nosso processo de decodificao/ codificao, mas precisamos preencher este contexto do codec com os parmetros do CODEC; fazemos isso com [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16).\n\nUma vez preenchido o contexto do codec, precisamos abrir o codec. Chamamos a funo [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) e, em seguida, podemos us-lo.\n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\nAgora vamos ler os pacotes do fluxo e decodific-los em quadros, mas antes disso, precisamos alocar memria para ambos os componentes, o [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) e [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\nVamos alimentar nossos pacotes das streams com a funo [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61) enquanto houver pacotes.\n\n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n\t//...\n}\n```\n\nVamos **enviar o pacote de dados bruto** (quadro comprimido) para o decodificador, por meio do contexto do codec, usando a funo [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3).\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\nE vamos **receber o quadro de dados bruto** (quadro descomprimido) do decodificador, atravs do mesmo contexto do codec, usando a funo [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c).\n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\nPodemos imprimir o nmero do quadro, o [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp), DTS, [tipo de quadro](https://en.wikipedia.org/wiki/Video_compression_picture_types) e etc.\n\n```c\nprintf(\n\t\t\"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n\t\tav_get_picture_type_char(pFrame->pict_type),\n\t\tpCodecContext->frame_number,\n\t\tpFrame->pts,\n\t\tpFrame->pkt_dts,\n\t\tpFrame->key_frame,\n\t\tpFrame->coded_picture_number,\n\t\tpFrame->display_picture_number\n);\n```\n\nFinalmente, podemos salvar nosso quadro decodificado em uma [imagem simples em tons de cinza](https://en.wikipedia.org/wiki/Netpbm_format#PGM_example). O processo  muito simples, usaremos `pFrame->data`, onde o ndice est relacionado aos [planos Y, Cb e Cr](https://en.wikipedia.org/wiki/YCbCr), escolhemos apenas `0` (Y) para salvar nossa imagem em tons de cinza.\n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n\t\tFILE *f;\n\t\tint i;\n\t\tf = fopen(filename,\"w\");\n\t\t// writing the minimal required header for a pgm file format\n\t\t// portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n\t\tfprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n\t\t// writing line by line\n\t\tfor (i = 0; i < ysize; i++)\n\t\t\t\tfwrite(buf + i * wrap, 1, xsize, f);\n\t\tfclose(f);\n}\n```\n\nE voil! Agora temos uma imagem em escala de cinza com 2MB:\n\n![saved frame](/img/generated_frame.png)\n\n## Captulo 1 - sincronizao de udio e vdeo\n\n> **Seja o player** - um jovem desenvolvedor de JS criando um novo player de vdeo MSE.\n\nAntes de avanarmos para [codificar um exemplo de transcodificao](#captulo-2---remuxing), vamos falar sobre **tempo**, ou como um player de vdeo sabe a hora certa de exibir um quadro.\n\nNo ltimo exemplo, salvamos alguns quadros que podem ser vistos aqui:\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\nQuando estamos projetando um player de vdeo, precisamos **reproduzir cada quadro em um ritmo definido**, caso contrrio, seria difcil visualizar o vdeo de forma agradvel, seja porque est reproduzindo muito rpido ou muito devagar.\n\nPortanto, precisamos introduzir alguma lgica para reproduzir cada quadro suavemente. Para esse fim, cada quadro tem um **carimbo de tempo de apresentao** (PTS), que  um nmero crescente multiplicado por uma **base de tempo** que  um nmero racional (onde o denominador  conhecido como **timescale**) divisvel pela **taxa de quadros (fps)**.\n\n mais fcil entender quando olhamos alguns exemplos, vamos simular alguns cenrios.\n\nPara um `fps=60/1` e `timebase=1/60000` cada PTS aumentar `timescale / fps = 1000` portanto, o **tempo real do PTS** para cada quadro poderia ser (supondo que comeou em 0):\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\nPara um cenrio quase idntico, mas com uma base de tempo igual a `1/60`.\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\nPara um `fps=25/1` e `timebase=1/75` cada PTS aumentar `timescale/fps = 3` e o tempo de PTS pode ser:\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\nAgora com o `pts_time` podemos encontrar uma maneira de renderizar isso sincronizado com o `pts_time` de udio ou com o relgio do sistema. O libav do FFmpeg fornece essas informaes por meio de sua API:\n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\nApenas por curiosidade, os quadros que salvamos foram enviados em uma ordem DTS (quadros: 1,6,4,2,3,5), mas tocados em uma ordem PTS (quadros: 1,2,3,4,5). Alm disso, observe como os quadros B so baratos em comparao com os quadros P ou I.\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n## Captulo 2 - Remuxing\n\nRemuxar  o ato de mudar de um formato (container) para outro, por exemplo, podemos mudar um vdeo [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14) para um [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream) sem muito esforo usando o FFmpeg:\n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\nEle ir demultiplexar o mp4, mas no o decodificar ou codificar (`-c copy`) e, no final, o multiplexar em um arquivo `mpegts`. Se voc no fornecer o formato `-f`, o ffmpeg tentar adivinh-lo com base na extenso do arquivo.\n\nO uso geral do FFmpeg ou do libav segue um padro/arquitetura ou fluxo de trabalho:\n\n* **[camada de protocolo](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - aceita uma entrada (`input`) (um arquivo, por exemplo, mas tambm pode ser uma entrada `rtmp` ou `HTTP`)\n* **[camada de formato](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - faz a desmultiplexao de seu contedo, revelando principalmente metadados e seus fluxos\n* **[camada de codec](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - decodifica os dados de fluxos comprimidos <sup>*opcional*</sup>\n* **[camada de pixel](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** - tambm pode aplicar alguns `filtros` aos quadros brutos (como redimensionamento)<sup>*opcional*</sup>\n* e ento ele segue o caminho inverso\n* **[camada de codec](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - codifica (ou re-codifica ou mesmo transcodifica) os quadros brutos<sup>*opcional*</sup>\n* **[camada de formato](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - multiplexa (ou remultiplexa) os fluxos brutos (os dados comprimidos)\n* **[camada de protocolo](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - e finalmente, os dados multiplexados so enviados para uma sada (outro arquivo ou talvez um servidor remoto de rede)\n\n![fluxo de trabalho do ffmpeg libav](/img/ffmpeg_libav_workflow.jpeg)\n> Este grfico  fortemente inspirado nos trabalhos de [Leixiaohua](http://leixiaohua1020.github.io/#ffmpeg-development-examples) e [Slhck](https://slhck.info/ffmpeg-encoding-course/#/9).\n\nAgora vamos codificar um exemplo usando o libav para fornecer o mesmo efeito de `ffmpeg input.mp4 -c copy output.ts`.\n\nVamos ler de uma entrada (`input_format_context`) e convert-la para outra sada (`output_format_context`).\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\nComeamos alocando a memria necessria e abrindo o formato de entrada. Para este caso especfico, vamos abrir um arquivo de entrada e alocar memria para um arquivo de sada.\n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n\tfprintf(stderr, \"Could not open input file '%s'\", in_filename);\n\tgoto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n\tfprintf(stderr, \"Failed to retrieve input stream information\");\n\tgoto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n\tfprintf(stderr, \"Could not create output context\\n\");\n\tret = AVERROR_UNKNOWN;\n\tgoto end;\n}\n```\n\nVamos remuxar apenas os tipos de fluxos de vdeo, udio e legenda, portanto, estamos armazenando em um array de ndices quais fluxos sero usados.\n\n```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n```\n\nLogo aps alocarmos a memria necessria, vamos fazer um loop em todos os fluxos e, para cada um, precisamos criar um novo fluxo de sada em nosso contexto de formato de sada, usando a funo [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827). Observe que estamos marcando todos os fluxos que no so de vdeo, udio ou legenda para que possamos ignor-los posteriormente.\n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n\tAVStream *out_stream;\n\tAVStream *in_stream = input_format_context->streams[i];\n\tAVCodecParameters *in_codecpar = in_stream->codecpar;\n\tif (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n\t\t\tin_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n\t\t\tin_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n\t\tstreams_list[i] = -1;\n\t\tcontinue;\n\t}\n\tstreams_list[i] = stream_index++;\n\tout_stream = avformat_new_stream(output_format_context, NULL);\n\tif (!out_stream) {\n\t\tfprintf(stderr, \"Failed allocating output stream\\n\");\n\t\tret = AVERROR_UNKNOWN;\n\t\tgoto end;\n\t}\n\tret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n\tif (ret < 0) {\n\t\tfprintf(stderr, \"Failed to copy codec parameters\\n\");\n\t\tgoto end;\n\t}\n}\n```\n\nAgora podemos criar o arquivo de sada.\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n\tret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n\tif (ret < 0) {\n\t\tfprintf(stderr, \"Could not open output file '%s'\", out_filename);\n\t\tgoto end;\n\t}\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n\tfprintf(stderr, \"Error occurred when opening output file\\n\");\n\tgoto end;\n}\n```\n\nDepois disso, podemos copiar os fluxos, pacote por pacote, dos nossos fluxos de entrada para os nossos fluxos de sada. Vamos fazer um loop enquanto tiver pacotes (`av_read_frame`), para cada pacote, precisamos recalcular o PTS e DTS para finalmente escrev-lo (`av_interleaved_write_frame`) no nosso contexto de formato de sada.\n\n```c\nwhile (1) {\n\tAVStream *in_stream, *out_stream;\n\tret = av_read_frame(input_format_context, &packet);\n\tif (ret < 0)\n\t\tbreak;\n\tin_stream  = input_format_context->streams[packet.stream_index];\n\tif (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n\t\tav_packet_unref(&packet);\n\t\tcontinue;\n\t}\n\tpacket.stream_index = streams_list[packet.stream_index];\n\tout_stream = output_format_context->streams[packet.stream_index];\n\t/* copy packet */\n\tpacket.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n\tpacket.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n\tpacket.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n\t// https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n\tpacket.pos = -1;\n\n\t//https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n\tret = av_interleaved_write_frame(output_format_context, &packet);\n\tif (ret < 0) {\n\t\tfprintf(stderr, \"Error muxing packet\\n\");\n\t\tbreak;\n\t}\n\tav_packet_unref(&packet);\n}\n```\n\nPara finalizar, precisamos escrever o trailer do fluxo em um arquivo de mdia de sada com a funo [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13).\n\n```c\nav_write_trailer(output_format_context);\n```\n\nAgora estamos prontos para testar e o primeiro teste ser a converso de formato (container de vdeo) de um arquivo MP4 para um arquivo de vdeo MPEG-TS. Basicamente, estamos executando a linha de comando `ffmpeg input.mp4 -c copy output.ts` com o libav.\n\n```bash\nmake run_remuxing_ts\n```\n\nEst funcionando!!! Voc no confia em mim?! Voc no deveria, podemos verificar com `ffprobe`:\n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n\tDuration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n\tProgram 1\n\t\tMetadata:\n\t\t\tservice_name    : Service01\n\t\t\tservice_provider: FFmpeg\n\t\tStream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n\t\tStream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\nPara resumir o que fizemos aqui em um grfico, podemos revisitar nossa [ideia inicial sobre como o libav funciona](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture) mostrando que pulamos a parte do codec.\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\nAntes de encerrarmos este captulo, gostaria de mostrar uma parte importante do processo de remuxing, voc pode passar opes para o muxer. Digamos que queremos entregar o formato [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding) para isso precisamos usar [fragmented mp4](https://stackoverflow.com/a/35180327) (s vezes referido como `fmp4`) em vez de MPEG-TS ou MPEG-4 simples.\n\nCom a [linha de comando, podemos fazer isso facilmente](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting).\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\nQuase to fcil quanto a linha de comando  a verso da biblioteca libav, s precisamos passar as opes ao escrever o cabealho de sada, logo antes da cpia dos pacotes.\n\n```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n```\n\nAgora podemos gerar este arquivo mp4 fragmentado:\n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\nMas para ter certeza de que no estou mentindo para voc, voc pode usar o incrvel site/ferramenta [gpac/mp4box.js](http://download.tsi.telecom-paristech.fr/gpac/mp4box.js/filereader.html) ou o site [http://mp4parser.com/](http://mp4parser.com/) para ver as diferenas. Primeiro carregue o mp4 \"comum\".\n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\nComo voc pode ver, ele tem apenas um tomo/box `mdat`, **este  o local onde esto os quadros de vdeo e udio**. Agora carregue o mp4 fragmentado para ver como ele espalha as caixas `mdat`.\n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n## Captulo 3 - Transcoding\n\n> #### TLDR; mostre-me o [cdigo](/3_transcoding.c) e a execuo.\n> ```bash\n> $ make run_transcoding\n> ```\n> Vamos pular alguns detalhes, mas no se preocupe: o [cdigo-fonte est disponvel no github](/3_transcoding.c).\n\n\nNeste captulo, vamos criar um transcodificador minimalista, escrito em C, que pode converter vdeos codificados em H264 para H265 usando a biblioteca **FFmpeg/libav**, especificamente [libavcodec](https://ffmpeg.org/libavcodec.html), libavformat e libavutil.\n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> _Apenas um rpido resumo:_ O [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html)  a abstrao para o formato do arquivo de mdia, tambm conhecido como continer (ex: MKV, MP4, Webm, TS). O [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html) representa cada tipo de dados para um determinado formato (ex: udio, vdeo, legenda, metadados). O [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html)  uma fatia de dados comprimidos obtidos do `AVStream` que pode ser decodificado por um [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html) (ex: av1, h264, vp9, hevc) gerando um dado bruto chamado [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n### Transmuxing\n\nVamos comear com a operao simples de transmuxing e depois podemos desenvolver este cdigo. O primeiro passo  **carregar o arquivo de entrada**.\n\n```c\n// Allocate an AVFormatContext\navfc = avformat_alloc_context();\n// Open an input stream and read the header.\navformat_open_input(avfc, in_filename, NULL, NULL);\n// Read packets of a media file to get stream information.\navformat_find_stream_info(avfc, NULL);\n```\n\nAgora vamos configurar o decodificador, o `AVFormatContext` nos dar acesso a todos os componentes do `AVStream` e, para cada um deles, podemos obter seu `AVCodec` e criar o `AVCodecContext` correspondente e, finalmente, podemos abrir o codec fornecido para que possamos prosseguir com o processo de decodificao.\n\n> O [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) contm dados sobre a configurao de mdia, como taxa de bits, taxa de quadros, taxa de amostragem, canais, altura e muitos outros.\n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n\tAVStream *avs = avfc->streams[i];\n\tAVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n\tAVCodecContext *avcc = avcodec_alloc_context3(*avc);\n\tavcodec_parameters_to_context(*avcc, avs->codecpar);\n\tavcodec_open2(*avcc, *avc, NULL);\n}\n```\n\nPrecisamos preparar o arquivo de mdia de sada para a transmuxao tambm, primeiro **alocamos memria** para o `AVFormatContext` de sada. Criamos **cada fluxo** no formato de sada. Para empacotar o fluxo adequadamente, **copiamos os parmetros do codec** do decodificador.\n\n**Definimos a flag** `AV_CODEC_FLAG_GLOBAL_HEADER`, que informa ao codificador que ele pode usar os cabealhos globais e, finalmente, abrimos o arquivo de sada para escrever e persistimos os cabealhos.\n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n\tencoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\nEstamos recebendo os `AVPacket` do decodificador, ajustando os timestamps e escrevendo o pacote corretamente no arquivo de sada. Embora a funo `av_interleaved_write_frame` diga \"escrever quadro\", estamos armazenando o pacote. Finalizamos o processo de transmuxing escrevendo o trailer do fluxo no arquivo.\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n\tav_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n\tav_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n### Transcodificao\n\nA seo anterior mostrou um programa de transmuxer simples, agora vamos adicionar a capacidade de codificar arquivos, especificamente, vamos habilit-lo para transcoded vdeos de `h264` para `h265`.\n\nAps prepararmos o decodificador, mas antes de organizarmos o arquivo de mdia de sada, vamos configurar o codificador.\n\n* Criar o `AVStream` de vdeo no codificador, [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)\n* Usar o `AVCodec` chamado `libx265`, [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37)\n* Criar o `AVCodecContext` com base no codec criado, [`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)\n* Configurar atributos bsicos para a sesso de transcodificao, e\n* Abrir o codec e copiar parmetros do contexto para o stream. [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) e [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe)\n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n// we're going to use internal options for the x265\n// it disables the scene change detection and fix then\n// GOP on 60 frames.\nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// encoder codec params\nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// control rate\nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// time base\nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\nPrecisamos expandir nosso loop de decodificao para a transcodificao do fluxo de vdeo:\n\n* Enviar o `AVPacket` vazio para o decodificador, [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)\n* Receber o `AVFrame` no comprimido, [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)\n* Comear a transcodificar este frame bruto,\n* Enviar o frame bruto, [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169)\n* Receber o `AVPacket` comprimido, com base no nosso codec, [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga5b8eff59cf259747cf0b31563e38ded6)\n* Configurar o timestamp e [`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n* Escrever no arquivo de sada. [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n\tint response = avcodec_send_packet(decoder_video_avcc, input_packet);\n\twhile (response >= 0) {\n\t\tresponse = avcodec_receive_frame(decoder_video_avcc, input_frame);\n\t\tif (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n\t\t\tbreak;\n\t\t} else if (response < 0) {\n\t\t\treturn response;\n\t\t}\n\t\tif (response >= 0) {\n\t\t\tencode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n\t\t}\n\t\tav_frame_unref(input_frame);\n\t}\n\tav_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// used function\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n\tAVPacket *output_packet = av_packet_alloc();\n\tint response = avcodec_send_frame(video_avcc, input_frame);\n\n\twhile (response >= 0) {\n\t\tresponse = avcodec_receive_packet(video_avcc, output_packet);\n\t\tif (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n\t\t\tbreak;\n\t\t} else if (response < 0) {\n\t\t\treturn -1;\n\t\t}\n\n\t\toutput_packet->stream_index = index;\n\t\toutput_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n\t\tav_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n\t\tresponse = av_interleaved_write_frame(avfc, output_packet);\n\t}\n\tav_packet_unref(output_packet);\n\tav_packet_free(&output_packet);\n\treturn 0;\n}\n\n```\n\nNs convertemos o fluxo de mdia de `h264` para `h265`, como esperado a verso `h265` do arquivo de mdia  menor que a verso `h264`, no entanto o [programa criado](/3_transcoding.c)  capaz de:\n\n```c\n\n\t/*\n\t * H264 -> H265\n\t * Audio -> remuxed (untouched)\n\t * MP4 - MP4\n\t */\n\tStreamingParams sp = {0};\n\tsp.copy_audio = 1;\n\tsp.copy_video = 0;\n\tsp.video_codec = \"libx265\";\n\tsp.codec_priv_key = \"x265-params\";\n\tsp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n\t/*\n\t * H264 -> H264 (fixed gop)\n\t * Audio -> remuxed (untouched)\n\t * MP4 - MP4\n\t */\n\tStreamingParams sp = {0};\n\tsp.copy_audio = 1;\n\tsp.copy_video = 0;\n\tsp.video_codec = \"libx264\";\n\tsp.codec_priv_key = \"x264-params\";\n\tsp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n\t/*\n\t * H264 -> H264 (fixed gop)\n\t * Audio -> remuxed (untouched)\n\t * MP4 - fragmented MP4\n\t */\n\tStreamingParams sp = {0};\n\tsp.copy_audio = 1;\n\tsp.copy_video = 0;\n\tsp.video_codec = \"libx264\";\n\tsp.codec_priv_key = \"x264-params\";\n\tsp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\tsp.muxer_opt_key = \"movflags\";\n\tsp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n\t/*\n\t * H264 -> H264 (fixed gop)\n\t * Audio -> AAC\n\t * MP4 - MPEG-TS\n\t */\n\tStreamingParams sp = {0};\n\tsp.copy_audio = 0;\n\tsp.copy_video = 0;\n\tsp.video_codec = \"libx264\";\n\tsp.codec_priv_key = \"x264-params\";\n\tsp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\tsp.audio_codec = \"aac\";\n\tsp.output_extension = \".ts\";\n\n\t/* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n\t * H264 -> VP9\n\t * Audio -> Vorbis\n\t * MP4 - WebM\n\t */\n\t//StreamingParams sp = {0};\n\t//sp.copy_audio = 0;\n\t//sp.copy_video = 0;\n\t//sp.video_codec = \"libvpx-vp9\";\n\t//sp.audio_codec = \"libvorbis\";\n\t//sp.output_extension = \".webm\";\n\n```\n\n> Para ser honesto, isso foi mais difcil do que eu pensava que seria (https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54) e tive que mergulhar no cdigo-fonte da linha de comando do FFmpeg (https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749) e testar muito, e acho que ainda estou perdendo alguma coisa, pois tive que forar `force-cfr` para o `h264` funcionar e ainda estou vendo algumas mensagens de aviso, como `warning messages (forced frame type (5) at 80 was changed to frame type (3))`."
        },
        {
          "name": "README-vn.md",
          "type": "blob",
          "size": 55.916015625,
          "content": "[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\nTi ang tm mt bi hng dn v cch s dng [FFmpeg](https://www.ffmpeg.org/) nh mt th vin (c bit n l libav) v sau  ti  tm thy bi vit [\"Cch vit video player t hn 1000 dng\"](http://dranger.com/ffmpeg/).\nTht khng may, n khng cn c dng na, v vy ti quyt nh vit bi hng dn ny.\n\nTt c dng code  y c vit bng ngn ng C, nhng ng lo lng: bn c th d dng hiu v p dng n vi ngn ng bn mong mun.\nTh vin FFmpeg libav c rt nhiu bin th cho cc ngn ng khc nhau nh [python](https://pyav.org/), [go](https://github.com/imkira/go-libav) v thm ch nu ngn ng bn s dng khng c th vin ny, bn vn c h tr qua `ffi` (y l mt v d vi [Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua)).\n\nChng ta s bt u vi mt tit hc nhanh v video, audio, codec v container; tip , chng ta i vo kho hc su hn v cch s dng cu lnh `FFmpeg` v cui cng chng ta s vit code. ng ngi b qua phn u v nhy thng n phn [Tm hiu th vin FFmpeg libav su hn.](#learn-ffmpeg-libav-the-hard-way).\n\nMt vi ngi thng ni pht trc tuyn video trn Internet l tng lai ca TV truyn thng, d bt c tnh hung g, FFmpeg l mt th ng  hc.\n\n__Mc lc__\n\n- [Gii thiu](#gii-thiu)\n  - [Video - iu bn thy!](#video---iu-bn-thy)\n  - [Audio - iu bn nghe!](#audio---iu-bn-nghe)\n  - [Codec - Nn d liu](#codec---nn-d-liu)\n  - [Container - nh dng tp lu tr chung video v audio](#container---nh-dng-tp-lu-tr-chung-video-v-audio)\n- [FFmpeg - B cng c di dng cu lnh](#ffmpeg---b-cng-c-di-dng-cu-lnh)\n  - [B cng c cu lnh FFmpeg 101](#b-cng-c-cu-lnh-ffmpeg-101)\n- [Nhng hnh ng x l video ph bin](#nhng-hnh-ng-x-l-video-ph-bin)\n  - [Chuyn i chun nn - Transcoding](#chuyn-i-chun-nn---transcoding)\n  - [Chuyn i nh dng tp - Transmuxing](#chuyn-i-nh-dng-tp---transmuxing)\n  - [Thay i tc  bit - Transrating](#thay-i-tc--bit---transrating)\n  - [Thay i  phn gii - Transsizing](#thay-i--phn-gii---transsizing)\n  - [M rng: pht trc tuyn thch ng (Adaptive-streaming)](#m-rng-pht-trc-tuyn-thch-ng-adaptive-streaming)\n  - [Hn th na](#hn-th-na)\n- [Tm hiu th vin FFmpeg libav su hn](#tm-hiu-th-vin-ffmpeg-libav-su-hn)\n  - [Chapter 0 - Hello world ni ting](#chapter-0---hello-world-ni-ting)\n    - [Kin trc th vin FFmpeg libav](#kin-trc-th-vin-ffmpeg-libav)\n    - [Cc yu cu](#cc-yu-cu)\n    - [Chng 0 - lt qua cc dng code](#chng-0---lt-qua-cc-dng-code)\n  - [Chapter 1 - ng b audio v video](#chapter-1---ng-b-audio-v-video)\n  - [Chapter 2 - Remuxing](#chapter-2---remuxing)\n  - [Chapter 3 - Transcoding](#chapter-3---transcoding)\n    - [Transmuxing](#transmuxing)\n    - [Transcoding](#transcoding)\n  \n# Gii thiu\n\n## Video - iu bn thy!\n\nNu bn c mt chui tun t cc hnh nh v thay i chng  mt tn s  bit (hy v d nh [24 hnh trn giy](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/)), bn s to ra [o gic v s chuyn ng](https://en.wikipedia.org/wiki/Persistence_of_vision).\nTm li, y l nguyn l c bn ng sau video: **mt chui cc hnh nh chy vi tc  cho trc**. \n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\nZeitgenssische Illustration (1886)\n\n## Audio - iu bn nghe!\n\nMc d video khng m thanh c th mang n rt nhiu cm xc, nhng vic b sung thm m thanh s mang li nhiu tri nghim hng khi hn.\n\nm thanh l s rung ng lan truyn nh sng p sut, thng qua khng kh hoc bt c phng tin truyn dn khc, nh kh gas, cht lng hoc t.\n\n> Trong mt h thng m thanh k thut s, microphone chuyn i m thanh thnh tn hiu in tng t, sau  qua b chuyn i tng t - s (analog-to-digital converter ADC) - tiu biu s dng [iu ch  rng xung (pulse-code modulation PCM)](https://en.wikipedia.org/wiki/Pulse-code_modulation) - chuyn i tn hiu tng t sang tn hiu s.\n\n![chuyn i tn hiu tng t m thnh sang tn hiu s](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analog to digital\")\n>[Ngun](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n## Codec - Nn d liu\n\n> CODEC l mt mch in t hoc phn mm dng  **nn hoc gii nn d liu video/audio k thut s.** N chuyn i d liu video/audio s ho nguyn thu (cha nn) sang nh dng nn hoc ngc li.\n> https://en.wikipedia.org/wiki/Video_codec\n\nNhng nu chng ta chn ng gi hng triu hnh nh vo trong tp ti liu v gi n l mt b phim, chng ta c th nhn c mt tp ti liu khng l. Hy th tnh ton mt cht:\n\nGi s chng ta ang to mt video vi  phn gii `1080 x 1920` (cao x rng) v chng ta dnh `3 bytes` cho mi im nh (pixel - n v nh nht ca mt mn hnh)  m ho mu sc (hoc [mu sc 24 bit](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29), n i din cho 16,777,216 mu sc khc nhau), v video ny chy  tc  `24 hnh trn giy`, ko di `30 pht`.\n\n```c\ntoppf = 1080 * 1920 //tong_so_diem_anh_tren_mot_hinh\ncpp = 3 //gia_tri_cho_moi_diem_anh\ntis = 30 * 60 //thoi_gian_tinh_bang_giay\nfps = 24 //so_hinh_tren_giay\n\nbo_nho_yeu_cau = tis * fps * toppf * cpp\n```\n\nVideo ny s yu cu xp x b nh `250.28GB` hoc bng thng `1.19Gbps`!  l l do ti sao chng ta cn dng [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work).\n\n## Container - nh dng tp lu tr chung video v audio\n\n> Mt container hay nh dng tp l mt nh dng tp tin m thng s ca n miu t nhng thnh phn khc nhau ca d liu v thng tin cng tn ti nh th no trong mt tp tin my tnh.\n> https://en.wikipedia.org/wiki/Digital_container_format\n\nMt **tp tin cha tt c cc lung d liu** (bao gm tt c audio v video) v n cng cung cp c ch ng b v thng tin chung, nh ta ,  phn gii,...\n\nThng thng chng ta c th suy lun nh dng ca tp d liu bng cch nhn vo phn m rng tn tp: v d nh mt tp c tn `video.webm` l mt video s dng nh dng container [`webm`](https://www.webmproject.org/).\n\n![container](/img/container.png)\n\n# FFmpeg - B cng c di dng cu lnh\n\n> Mt gii php hon thin, a nn tng  ghi li, chuyn i v pht trc tuyn lung audio v video.\n\n lm vic vi truyn thng a phng tin, chng ta c th s dng cng c/th vin hu ch gi l [FFmpeg](https://www.ffmpeg.org/). Rt c th bn  tng bit/s dng n mt cch trc tip hoc gin tip (bn c s dng [Chrome?](https://www.chromium.org/developers/design-documents/video)).\n\nN c mt chng trnh chy lnh gi l `ffmpeg`, mt chng trnh m nh phn n gin nhng v cng mnh m\nV d nh bn c th chuyn i t nh dng `mp4` sang nh dng container `avi` ch bng cch g cu lnh sau:\n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\n\nChng ta ch thc hin mt bc **nh dng li (remuxing)**  y, ngha l n ang chuyn i t nh dng container ny sang mt nh dng container khc.\nV mt k thut FFmpeg cng c th thc hin thm mt bc chuyn i chun nn (transcode) nhng chng ta s ni v n sau.\n\n## B cng c cu lnh FFmpeg 101\n\nFFmpeg c mt trang ch [ti liu](https://www.ffmpeg.org/ffmpeg.html)  gii thch r rng y  v nguyn l hot ng ca n. \n\nNgn gn m ni, chng trnh cu lnh FFmpeg cn nh dng i s sau  thc hin hnh ng ca n `ffmpeg {1} {2} -i {3} {4} {5}` trong :\n\n1. tu chn ton cc\n2. tu chn u vo\n3. ng dn u vo\n4. tu chn u ra\n5. ng dn u ra\n\nCc phn 2, 3, 4 v 5 c th l mt hoc nhiu theo nh yu cu ca bn.\nTht d dng  hiu nhng nh dng i s ny trong cu lnh di y:\n\n``` bash\n# WARNING: kch thc file xp x 300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ # la chn ton cc\n-c:a libfdk_aac \\ # tu chn u vo\n-i bunny_1080p_60fps.mp4 \\ # ng dn u vo\n-c:v libvpx-vp9 -c:a libvorbis \\ # tu chn u ra\nbunny_1080p_60fps_vp9.webm # ng dn u ra\n```\nCu lnh ny nhn tp u vo nh dng `mp4` cha 2 lung d liu (mt lung audio nn vi chun nn `aac` v mt lung video s dng chun nn `h264`) v chuyn i n sang nh dng tp `webm`, cng thay i chun nn audio v video ca n.\n\nChng ta c th n gin ho cc cu lnh trn nhng hy lu  rng FFmpeg s nhn hoc d on cc gi tr mc nh cho bn.\nV d, khi bn g `ffmpeg -i input.avi output.mp4`, chun nn audio/video s c s dng  xut `output.mp4` l g?\n\nWerner Robitza  vit mt bi hng dn nn c v [nn v chnh sa vi FFmpeg](http://slhck.info/ffmpeg-encoding-course/#/).\n\n# Nhng hnh ng x l video ph bin\n\nTrong khi lm vic vi audio/video, chng ta thng thc hin mt b cc tc v c th vi ni dung a phng tin.\n\n## Chuyn i chun nn - Transcoding\n\n![transcoding](/img/transcoding.png)\n\n**L g?** l hnh ng chuyn i mt lung d liu (c th l audio hoc video) t chun nn ny sang chun nn khc.\n\n**Ti sao?** thnh thong chng ta bt gp trng hp mt vi thit b (Tivi, in thoi thng minh, bng iu khin,...) khng h tr loi X nhng li h tr loi Y v nhng chun nn mi cung cp t l nn tt hn.\n\n**Nh th no?** chuyn i mt video t chun nn `H264` (AVC) sang chun nn `H265` (HEVC) bng cch sau:\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n## Chuyn i nh dng tp - Transmuxing\n\n![transmuxing](/img/transmuxing.png)\n\n**L g?** l hnh ng chuyn i t mt nh dng tp (container) ny sang mt nh dng tp khc.\n\n**Ti sao?** thng thong mt vi thit b (Tivi, in thoi thng minh, bng iu khin,...) khng h tr loi X nhng li h tr loi Y v thnh thong nhng nh dng mi cung cp nhng tnh nng hin i c yu cu.\n\n**Nh th no?** thc hin chuyn i t nh dng `mp4` sang nh dng `webm`.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ # dieu_khien_ffmpeg_bo_qua_buoc_giai_ma_va_ma_hoa\nbunny_1080p_60fps.webm\n```\n\n## Thay i tc  bit - Transrating\n\n![transrating](/img/transrating.png)\n\n**L g?** l hnh ng thay i tc  bit ca video/audio, hoc xut ra nhng bin th (renditions) khc.\n\n**Ti sao?** mi ngi c th th xem video ca bn vi kt ni mng `2G`(edge) bng cch s dng cc thit b in thoi thng minh hiu nng thp hoc bng kt ni Internet `cp quang` (fiber) trn thit b Tivi 4K ca h. Do , bn nn  xut nhiu hn mt bin th ca cng mt video vi tc  bit khc nhau.\n\n**Nh th no?** tin hnh xut mt bin th vi tc  bit gia 3856K v 2000K.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\nThng thng chng ta s cng s dng 2 tc v thay i tc  v thay i kch thc. Werner Robitza  vit mt chui cc bi vit nn c v [iu khin t l trong FFmpeg](http://slhck.info/posts/).\n\n## Thay i  phn gii - Transsizing\n\n![transsizing](/img/transsizing.png)\n\n**L g?** l hnh ng thay i cht lng video t  phn gii ny sang mt  phn gii khc. Nh  ni trc , tc v thay i kch thc thng i km vi tc v thay i tc .\n\n**Ti sao?** l do tng t nh vi tc v thay i tc .\n\n**Nh th no?** thay i t  phn gii t `1080p` thnh `480p`.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## M rng: pht trc tuyn thch ng (Adaptive-streaming)\n\n![adaptive streaming](/img/adaptive-streaming.png)\n\n**L g?** l hnh ng xut nhiu  phn gii (hoc tc  bit) v chia ni dung a phng tin thnh cc on v truyn ti chng thng qua giao thc http.\n\n**Ti sao?**  cung cp ni dung a phng tin linh hot  c th xem trn in thoi thng minh hiu nng thp hoc tivi 4K, n cng d dng m rng v trin khai nhng c th tng thm  tr.\n\n**Nh th no?** to ra mt ni dng nh dng WebM thch ng (adaptive) bng cch s dng giao thc DASH.\n```bash\n# lung video\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# lung audio\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# tp k khai DASH\n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPS: Ti  ly v d ny t bi [Gii thiu cch thc xem li WebM thch ng bng giao thc DASH](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash)\n\n## Hn th na\n\nCn [rt nhiu cch s dng khc na ca FFmpeg](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly).\nTi s dng n khi kt hp vi *iMovie*  xut ra/chnh sa mt vi video cho nn tng Youtube v bn chc chn c th s dng n mt cch chuyn nghip hn.\n\n# Tm hiu th vin FFmpeg libav su hn\n\n> Bn khng nn lo lng qu nhiu v m thanh v hnh nh?\n> **David Robert Jones**\n\nBi v [FFmpeg](#ffmpeg---command-line) l mt cu lnh rt hu dng  lm nhng tc v thit yu trn cc tp tin a phng tin, bng cch no chng ta c th s dng n trong chng trnh ca chng ta?\n\nFFmpeg c [kt hp bi mt vi th vin](https://www.ffmpeg.org/doxygen/trunk/index.html) m c th tch hp vo trong chng trnh ca chng ta.\nThng thng, khi bn ci t FFmpeg, n s t ng ci tt c cc th vin . Ti s tham chiu n tp cc th vin gi l **FFmpeg libav**.\n\n>> Ta  ny l trang ch ca chui cc bi vit ca Zed Shaw [\"Hc X chuyn su\"](https://learncodethehardway.org/), c bit l cun sch ca anh y \"Hc ngn ng C chuyn su\" (Learn C the Hard Way).\n\n## Chapter 0 - Hello world ni ting\n\nChng trnh Hello world ny thc cht s khng hin th tin nhn `\"hello world\"` trn mn hnh terminal :tongue: Thay vo , chng ta s in ra thng tin ca video, v d nh l nh dng tp (container) ca n, thi lng,  phn gii, cc knh audio v cui cng, chng ta s **gii nn mt s khung hnh (frames) v lu chng li nh tp tin hnh nh.**\n\n### Kin trc th vin FFmpeg libav\n\nTrc khi chng ta bt u vit chng trnh, hy hc cch **kin trc th vin FFmpeg libav** hot ng v cc thnh phn ca n giao tip vi nhau nh th no.\n\ny l s  tin trnh gii nn mt video:\n\n![kin trc th vin ffmpeg libav - tin trnh gii nn](/img/decoding.png)\n\nu tin bn s cn ti ln mt tp tin a phng tin ca bn vo thnh phn gi l [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) (Containter ca video cn c gi l nh dng).\nN thc cht khng ti ton b tp tin: n thng ch c phn u header ca tp tin.\n\nMt khi chng c c t nht **phn u (header) ca container**, chng ta c th truy cp vo cc lung d liu ca n (ngh chng nh l phn thng tin chung ca d liu audio v video).\nMi lung (stream) s c lu trong thnh phn gi l [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html).\n\n> Lung l mt ci tn a thch i in cho mt dng d liu lin tc.\n\nGi s chng ta c mt video cha hai lung d liu: mt lung l audio c nn vi [chun nn AAC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding) v lung cn li l video c nn vi [chun nn H264 (AVC)](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC). T mi lung, chng ta c th gii nn **tng mnh (slices) ca d liu** gi l gi (packet) m chng s c ti vo nhng phn t [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html).\n\nPhn **d liu trong cc gi vn c nn** v  gii nn cc gi, chng ta cn a chng vo [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html) c th.\n\nThnh phn `AVCodec` s gii m chng thnh phn t [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html) v cui cng, nhng phn t ny s cho chng ta nhng khung hnh gc khng nn. C th nhn ra rng thut ng/tin trnh u c s dng bi c lung audio v video.\n\n### Cc yu cu\n\nBi c mt s ngi  [gp vn  trong khi bin dch hoc chy cc v d mu](https://github.com/leandromoreira/ffmpeg-libav-tutorial/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+compiling) **chng ta s s dng [`Docker`](https://docs.docker.com/install/) nh l mt trng pht trin hay chy th,** chng ta cng s s dng video \"The big buck bunny\" v th nu bn khng c n  trn my tnh th hy chy lnh `make fetch_small_bunny_video`.\n\n### Chng 0 - lt qua cc dng code\n\n> #### TLDR; hy m [code](/0_hello_world.c) v thc thi n.\n> ```bash\n> $ make run_hello\n> ```\n\nChng ta s b qua mt s chi tit, nhng ng lo lng: [source code c sn trn github](/0_hello_world.c).\n\nChng ta s khi to vng nh cho thnh phn [`AVFormatContext`](http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html)  gi cc thng tin v nh dng tp (container).\n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\nBy gi chng ta s m tp tin v c phn u (header) ca n v in vo `AVFormatContext` vi thng tin ti thiu v nh dng (lu  rng cc chun nn vn cha c xc nh).\nHm c s dng  lm iu  l [`avformat_open_input`](http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49). N cn u vo l mt `AVFormatContext`, mt `tn file (filename)` v i s tu chn: [`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html) (nu bn a vo `NULL`, FFmpeg s d on nh dng) v [`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html) (l cc tu chn cho b demuxer).  \n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\nChng ta c th in tn nh dng v thi lng a phng tin:\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\n truy cp vo `cc lung`, chng ta cn c d liu t a phng tin. Hm [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb) thc hin iu .\nBy gi, thnh phn `pFormatContext->nb_streams` s gi s lng cc lung v `pFormatContext->streams[i]` s cho chng ta cc thng tin v lung `i` (tng ng vi mt [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)).\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\n\nBy gi chng ta s chy vng lp qua tt c cc lung.\n\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n  //\n}\n```\n\nVi mi lung, chng ta s cn [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html), n miu t cc thuc tnh ca chun nn c s dng vi lung `i`.\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\n\nvi thuc tnh ca chun nn, chng ta c th tm chun nn thch hp thng qua hm [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca) v tm b gii nn sn c vi m nh danh ca chun nn  (code id) v tr v mt [`AVCodec`](http://ffmpeg.org/doxygen/trunk/structAVCodec.html), thnh phn bit cch thc thc hin nn (en**CO**de) v gii nn (**DEC**ode) lung d liu.\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\nn gi chng ta c th in thng tin v chun nn\n\n```c\n// specific for video and audio\nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n  printf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n  printf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// general\nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n```\n\nVi thng tin chun nn, chng ta khi to vng nh cho [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html), n s gi ni dung ca tin trnh gii m/m ho, nhng sau  chng ta cn in ni dung chun nn vi cc thng s  xc nh; chng ta lm thc hin vi hm [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16).\n\nMt khi chng ta  in vo ni dung b m ho, chng ta c th m b m ho. Chng ta gi hm [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) v sau  chng ta c th s dng n.\n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\nBy gi, chng ta s c cc gi d liu t lung stream v gii m chng thnh cc khung hnh nhng trc tin, chng ta cn khi to b nh cho c hai thnh phn, [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) v [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\nHy ly cc gi d liu t lung stream vi hm [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61) trong khi n c d liu.\n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n  //...\n}\n```\n\n**a gi d liu th** (hnh  nn) vo b gii m, i qua b m ho, bng hm [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3).\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\nV **Nhn hnh nh th** (hnh  gii nn) t b gii m, thng qua b m ho tng t, bng hm [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c).\n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\nChng ta c th in ra s lng khung hnh, thng s [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp), DTS, [frame type](https://en.wikipedia.org/wiki/Video_compression_picture_types) v nhiu hn th.\n\n```c\nprintf(\n    \"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n    av_get_picture_type_char(pFrame->pict_type),\n    pCodecContext->frame_number,\n    pFrame->pts,\n    pFrame->pkt_dts,\n    pFrame->key_frame,\n    pFrame->coded_picture_number,\n    pFrame->display_picture_number\n);\n```\n\nCui cng chng ta c th lu li nhng khung hnh  c gii nn thnh mt nh xm n gin [simple gray image](https://en.wikipedia.org/wiki/Netpbm_format#PGM_example). Qu trnh ny rt n gin, chng ta s dng `pFrame->data` ni m index lin quan n khng gian mu [planes Y, Cb and Cr](https://en.wikipedia.org/wiki/YCbCr), chng ta ch cn ly phn t u tin vi ch mc `0` (Y)  lu thnh hnh nh.\n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    // writing the minimal required header for a pgm file format\n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // writing line by line\n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n```\n\nVy l cui cng chng ta c mt nh xm vi kch thc 2MB:\n\n![saved frame](/img/generated_frame.png)\n\n## Chapter 1 - ng b audio v video\n\n> **Player** - mt nh pht trin JS hon thnh mt trnh pht video mi.\n\nTrc khi chng ta n vi [v d v  transcoding](#chapter-2---transcoding) hy ni v **ng b thi gian** , hoc cch thc mt trnh pht video bit khi no cn hin th hnh nh.\n\nTrong v d cui cng, chng ta  lu mt s khung hnh c th xem c  y:\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\nKhi chng ta thit k trnh pht video, chng ta cn hin th tng khung hnh theo mt tc  nht nh, nu khng, s rt kh  xem video mt cch thoi mi bi v n pht rt nhanh hoc rt chm.\n\nDo , chng ta cn xc nh mt s logic  pht mi khung hnh mt cch mt m.  x l vn  ny, mi khung hnh c mt **mc thi gian hin th** (PTS) tng dn theo h s **timebase**, l mt s hu t (trong  mu s c bit n nh **timescale**), chia cho **tc  khung hnh (fps)** \n\nS d dng  hiu khi chng ta nhn vo mt s v d, hy thc hin mt s kch bn.\n\nVi `fps=60/1` v `timebase=1/60000`, mi PTS s tng ln `timescale / pts = 1000`, do  **PTS thi gian thc** cho mi khung hnh s l (gi nh bt u t 0):\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\nVi kch bn tng t nhng timebase bng `1/60`. \n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\nVi `fps=25/1` v `timebase=1/75`, mi PTS s tng mt khong `timescale / pts = 3` v mc thi gian PTS s l:\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\nBy gi vi `pts_time` chng ta c th tm c cch kt xut video ng b vi `pts_time` ca audio hoc vi nhp xung h thng. Th vin FFmpeg libav cung cp nhng thng tin ny thng qua API:  \n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\nXem xt su hn, nhng khung hnh chng ta lu c gi theo th t DTS (frames: 1,6,4,2,3,5) nhng pht theo th t PTS (frames: 1,2,3,4,5). Cng   xem hiu qu ca khung hnh loi B so vi khung hnh loi P hoc I.\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n## Chapter 2 - Remuxing\n\nRemuxing l hnh ng thay i t nh dang tp (container) ny sang nh dng tp khc, v d, chng ta thay i mt video nh dng [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14) sang nh dng [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream) m khng gp nhiu kh khn khi s dng FFmpeg: \n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\nN s bc tch nh dng mp4 nhng n s khng gii m hay m ho li (`-c copy`) v cui cng, n s sp xp li theo nh dng `mpegts`. Nu bn khng cung cp nh dng `-f`, ffmpeg s c gng on n bng tn m rng ca tp tin u ra.\n\nCch s dng thng thng ca FFmpeg hoc th vin libav theo kin trc/ mu hoc theo trnh t nh sau:\n* **[lp giao thc](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - n nhn `u vo`  (c th l mt `tp tin` hoc l giao thc `rtmp` hay `HTTP`)\n* **[lp nh dng](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - n `bc tch` ni dung trong , ly c hu ht siu d liu v cc lung ca n\n* **[lp m ho](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - n `gii m` d liu c nn trong cc lung <sup>*tu chn*</sup>\n* **[lp im nh](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** - n cng cung cp  `b lc` tng tc vi tng khung hnh gc (nh thay i kch thc)<sup>*tu chn*</sup>\n* v sau  thc hin ngc li cc bc\n* **[lp m ho](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - n `m ho` (hoc `m ho li` hoc `transcode`) nhng frame gc<sup>*tu chn*</sup>\n* **[lp nh dng](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - n `sp xp` (hoc `ti sp xp`) cc lung d liu (d liu nn)\n* **[lp giao thc](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - v cui cng nhng d liu c sp xp s c gi n `u ra` (tp tin khc hoc c th l mt my ch mng)\n\n![ffmpeg libav workflow](/img/ffmpeg_libav_workflow.jpeg)\n> S  ny c truyn cm hng t s n lc ca [Leixiaohua's](http://leixiaohua1020.github.io/#ffmpeg-development-examples) v [Slhck's](https://slhck.info/ffmpeg-encoding-course/#/9).\n\nBy gi hy xem v d s dng libav  a ra hiu ng tng t nh trong `ffmpeg input.mp4 -c copy output.ts`.\n\nChng ta c t u vo (`input_format_context`) v thay i n thnh u ra khc (`output_format_context`).\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\nChng ta bt u thc hin khi to vng nh v m nh dng u vo. Cho trng hp ny, chng ta cn m tp tin u vo v khi to vng nh cho tp tin u ra.\n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n  fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n  goto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n  fprintf(stderr, \"Failed to retrieve input stream information\");\n  goto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n  fprintf(stderr, \"Could not create output context\\n\");\n  ret = AVERROR_UNKNOWN;\n  goto end;\n}\n```\n\nChng ta cng cn sp xp li cc lung stream video, audio v subtitle, v  gi chng, chng ta s lu thng tin ca chng trong mng.\n\n```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n```\n\nSau , chng ta khi to vng nh yu cu, chng ta thc hin vng lp tt c cc lung stream v vi mi lung stream chng ta cn to mt lung stream u ra cho nh dng u ra, bng cch dng hm [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827). Ch  chng ta s nh u tt c cc lung stream k c khng phi video, audio hoc subtitle, v vy chng ta c th b qua chng.\n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n  AVStream *out_stream;\n  AVStream *in_stream = input_format_context->streams[i];\n  AVCodecParameters *in_codecpar = in_stream->codecpar;\n  if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n    streams_list[i] = -1;\n    continue;\n  }\n  streams_list[i] = stream_index++;\n  out_stream = avformat_new_stream(output_format_context, NULL);\n  if (!out_stream) {\n    fprintf(stderr, \"Failed allocating output stream\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n  ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n  if (ret < 0) {\n    fprintf(stderr, \"Failed to copy codec parameters\\n\");\n    goto end;\n  }\n}\n```\n\nBy gi chng ta c th to tp tin u ra.\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n  ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n  if (ret < 0) {\n    fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n    goto end;\n  }\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n  fprintf(stderr, \"Error occurred when opening output file\\n\");\n  goto end;\n}\n```\n\nSau , chng ta c th sao chp cc lung stream, tng gi d liu packet, t lung u vo n lung u ra. Thc hin vng lp khi c gi d liu (`av_read_frame`), vi mi gi d liu, chng ta cn tnh li PTS v DTS  kt thc ghi n li (`av_interleaved_write_frame`) ti b nh dng u ra.\n\n```c\nwhile (1) {\n  AVStream *in_stream, *out_stream;\n  ret = av_read_frame(input_format_context, &packet);\n  if (ret < 0)\n    break;\n  in_stream  = input_format_context->streams[packet.stream_index];\n  if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n    av_packet_unref(&packet);\n    continue;\n  }\n  packet.stream_index = streams_list[packet.stream_index];\n  out_stream = output_format_context->streams[packet.stream_index];\n  /* copy packet */\n  packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n  packet.pos = -1;\n\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n  ret = av_interleaved_write_frame(output_format_context, &packet);\n  if (ret < 0) {\n    fprintf(stderr, \"Error muxing packet\\n\");\n    break;\n  }\n  av_packet_unref(&packet);\n}\n```\n\n kt thc chng ta cn vit phn kt thc lung stream ti tp tin u ra vi hm [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13)\n\n```c\nav_write_trailer(output_format_context);\n```\n\nT gi chng ta  sn sng  kim tra n v bi kim tra u tin s l chuyn i nh dng video t MP4 sang MPEG-TS. Chng ta c bn thc hin lnh  `ffmpeg input.mp4 -c copy output.ts` vi th vin libav.\n\n```bash\nmake run_remuxing_ts\n```\n\nN  lm vic!!! Bn khng tin ti ?!  chc chn, chng ta c th kim tra n vi `ffprobe`\n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n  Duration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n  Program 1\n    Metadata:\n      service_name    : Service01\n      service_provider: FFmpeg\n    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n    Stream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\nTng hp li nhng g chng ta  lm theo s , chng ta xem li bi m u [ tng libav hot ng](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture) v nh  thy chng ta b qua phn m ho.\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\nTrc khi kt thc chng ny, ti mun ch ra phn quan trng nht ca tin trnh remuxing, **bn c th a cc tu chn vo b muxer**. Hy ni chng ta mun chuyn nh dng [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding),  gii quyt vn  ny, chng ta cn s dng nh dng [fragmented mp4](https://stackoverflow.com/a/35180327) (thnh thong c gii thiu nh `fmp4`) thay v MPEF-TS hoc thun MPEG-4.\n\nVi [vic thc hin d dng bng cu lnh](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting).\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\nDng libav cng d dng nh cu lnh, chng ta cn a cc tu chn khi ghi header u ra, trc khi sao chp cc gi d liu packet.\n\n```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n```\n\nChng ta c th to tp tin fragmented mp4:\n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\nNhng  chc chn rng ti khng ni di, bn c th s dng mt cng c tin ch [gpac/mp4box.js](http://download.tsi.telecom-paristech.fr/gpac/mp4box.js/filereader.html) hoc [http://mp4parser.com/](http://mp4parser.com/)  nhn s khc bit, u tin ti ln tp tin mp4 \"thng thng\"\n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\nNh bn thy, n ch c duy nht mt box `mdat`, **ni cha khung hnh video v audio**. Gi hy ti ln tp tin nh dng fragmented mp4  nhn chng c chia thnh nhiu box `mdat`\n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n## Chapter 3 - Transcoding\n\n> #### TLDR; ch ra b m ho [code](/3_transcoding.c) v thc thi.\n> ```bash\n> $ make run_transcoding\n> ```\n> Chng ta s b qua chi tit, nhng ng lo lng: [source code c sn trn github](/3_transcoding.c).\n\n\n chng ny, chng ta s to mt b chuyn i chun nn transcoder ti gin nht, vit bng ngn ng C, c th chuyn i video t chun nn H264 thnh H265 bng th vin **FFmpeg/libav**, c th l  [libavcodec](https://ffmpeg.org/libavcodec.html), libavformat, v libavutil.\n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> _Tm tt nhanh:_ [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html) l s tru tng cho cc nh dng tp tin a phng tin, hay cn gi l container (v d: MKV, MP4, Webm, TS). [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html) i din mi loi d liu ca nh dng  cho (v d: audio, video, subtitle, metadata). [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html) l mt phn ca d liu  nn cha trong `AVStream`, n c th c gii m bi [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html) (v d: av1, h264, vp9, hevc), to ra d liu gc gi l [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n### Transmuxing\n\nHy bt u vi s hot ng transmuxing n gin v sau  chng ta c th xy dng da trn code , bc u tin l **ti tp tin u vo**. \n\n```c\n// Allocate an AVFormatContext\navfc = avformat_alloc_context();\n// Open an input stream and read the header.\navformat_open_input(avfc, in_filename, NULL, NULL);\n// Read packets of a media file to get stream information.\navformat_find_stream_info(avfc, NULL);\n```\n\nChng ta s ci t mt b gii m, `AVFormatContext` s cho php chng ta truy cp tt c thnh phn `AVStream` v mi thnh phn trong s chng, chng ta c th nhn `AVCodec` v to `AVCodecContext` chi tit v cui cng chng ta c th m codec nhn c, do  chng ta c th thc hin qu trnh gii m.  \n\n>  Thnh phn [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) gi nhng d liu v cu hnh a phng tin nh tc  bit, tc  khung hnh, tc  mu, cc knh, chiu cao v rt nhiu th khc na.\n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n  AVStream *avs = avfc->streams[i];\n  AVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  AVCodecContext *avcc = avcodec_alloc_context3(*avc);\n  avcodec_parameters_to_context(*avcc, avs->codecpar);\n  avcodec_open2(*avcc, *avc, NULL);\n}\n```\n\nChng ta cn chun b tp tin u ra cho vic transmuxing, u tin chng ta **khi to vng nh** cho `AVFormatContext` u ra. Chng ta to **tng lung stream** cho nh dng u ra.  ng gi lung thch hp, chng ta **sao chp cc thng s codec** t b gii m.\n\nChng ta **bt c** `AV_CODEC_FLAG_GLOBAL_HEADER`  ni cho b m ho rng n c th s dng global header v cui cng chng ta m **tp tin  ghi** u ra v gi header.\n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n  encoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\nChng ta nhn `AVPacket` t b gii m, iu chnh timestamp, v ghi gi d liu packet thch hp vi tp tin u ra. Mc d hm `av_interleaved_write_frame` ni \"ghi khung hnh\", nhng chng ta ang lu cc gi packet. Chng ta kt thc qu trnh transmuxing bng cch ghi phn ui (trailer) vo tp tin.\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  av_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n  av_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n### Transcoding\n\nPhn trc  a ra chng trnh transmuxer n gin, by gi chng ta s thm vo kh nng cho tp tin m ho, c bit chng ta s thc hin transcode video t `h264` sang `h265`\n\nSau khi chng ta chun b b gii m, trc khi chng ta sp xp cc tp tin u ra, chng ta s ci t b m ho.\n\n* To video `AVStream` trong b m ho, [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)\n* S dng `AVCodec` l `libx265`, [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37)\n* To `AVCodecContext` da vo codec c to, [`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)\n* Ci t thuc tnh c s cho phin transcoding, v\n* M codec v sao chp thng s t context ti lung stream. [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) v [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe)\n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n// we're going to use internal options for the x265\n// it disables the scene change detection and fix then\n// GOP on 60 frames.\nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// encoder codec params\nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// control rate\nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// time base\nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\nChng ta cn m rng vng lp gii m cho vic trancoding lung video:\n\n* Gi `AVPacket` rng ti b gii m, [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)\n* Nhn `AVFrame`  gii nn, [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)\n* Bt u transcode khung hnh gc ny,\n* Gi khung hnh gc, [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169)\n* Nhn d liu nn li da trn codec, `AVPacket`, [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga5b8eff59cf259747cf0b31563e38ded6)\n* Ci t timestamp, v [`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n* Ghi n vo tp tin u ra. [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  int response = avcodec_send_packet(decoder_video_avcc, input_packet);\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder_video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return response;\n    }\n    if (response >= 0) {\n      encode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n    }\n    av_frame_unref(input_frame);\n  }\n  av_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// used function\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n  AVPacket *output_packet = av_packet_alloc();\n  int response = avcodec_send_frame(video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return -1;\n    }\n\n    output_packet->stream_index = index;\n    output_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n    response = av_interleaved_write_frame(avfc, output_packet);\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\n```\n\nChng ta chuyn i lung media t `h264` ti `h265`, nh phin bn `h265` mong i ca tp tin media s c kch thc nh hn `h264` tuy nhin [chng trnh c to](/3_transcoding.c) c kh nng:\n\n```c\n\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.muxer_opt_key = \"movflags\";\n  sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 0;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.audio_codec = \"aac\";\n  sp.output_extension = \".ts\";\n\n  /* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n\n```\n\n> By gi, thnh tht m ni, iu ny [kh hn ti ngh](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54) n l nh vy v ti phi o su hn [source code cu lnh FFmpeg](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749) v kim tra n rt nhiu v ti ngh ti ang b qun mt s th bi v ti phi thc hin `force-cfr` cho `h264`  lm vic v ti vn xem mt s tin nhn cnh bo nh `warning messages (forced frame type (5) at 80 was changed to frame type (3))`.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 46.4921875,
          "content": "[](/README-cn.md \"Simplified Chinese\")\n[](/README-ko.md \"Korean\")\n[](/README-es.md \"Spanish\")\n[](/README-vn.md \"Vietnamese\")\n[](/README-pt.md \"Portuguese\")\n\n[![license](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)\n\nI was looking for a tutorial/book that would teach me how to start to use [FFmpeg](https://www.ffmpeg.org/) as a library (a.k.a. libav) and then I found the [\"How to write a video player in less than 1k lines\"](http://dranger.com/ffmpeg/) tutorial.\nUnfortunately it was deprecated, so I decided to write this one.\n\nMost of the code in here will be in C **but don't worry**: you can easily understand and apply it to your preferred language.\nFFmpeg libav has lots of bindings for many languages like [python](https://pyav.org/), [go](https://github.com/imkira/go-libav) and even if your language doesn't have it, you can still support it through the `ffi` (here's an example with [Lua](https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua)).\n\nWe'll start with a quick lesson about what is video, audio, codec and container and then we'll go to a crash course on how to use `FFmpeg` command line and finally we'll write code, feel free to skip directly to[ ](http://newmediarockstars.com/wp-content/uploads/2015/11/nintendo-direct-iwata.jpg)the section [Learn FFmpeg libav the Hard Way.](#learn-ffmpeg-libav-the-hard-way)\n\nSome people used to say that the Internet video streaming is the future of the traditional TV, in any case, the FFmpeg is something that is worth studying.\n\n__Table of Contents__\n\n* [Intro](#intro)\n  * [video - what you see!](#video---what-you-see)\n  * [audio - what you listen!](#audio---what-you-listen)\n  * [codec - shrinking data](#codec---shrinking-data)\n  * [container - a comfy place for audio and video](#container---a-comfy-place-for-audio-and-video)\n* [FFmpeg - command line](#ffmpeg---command-line)\n  * [FFmpeg command line tool 101](#ffmpeg-command-line-tool-101)\n* [Common video operations](#common-video-operations)\n  * [Transcoding](#transcoding)\n  * [Transmuxing](#transmuxing)\n  * [Transrating](#transrating)\n  * [Transsizing](#transsizing)\n  * [Bonus Round: Adaptive Streaming](#bonus-round-adaptive-streaming)\n  * [Going beyond](#going-beyond)\n* [Learn FFmpeg libav the Hard Way](#learn-ffmpeg-libav-the-hard-way)\n  * [Chapter 0 - The infamous hello world](#chapter-0---the-infamous-hello-world)\n    * [FFmpeg libav architecture](#ffmpeg-libav-architecture)\n  * [Chapter 1 - timing](#chapter-1---syncing-audio-and-video)\n  * [Chapter 2 - remuxing](#chapter-2---remuxing)\n  * [Chapter 3 - transcoding](#chapter-3---transcoding)\n\n# Intro\n\n## video - what you see!\n\nIf you have a sequence series of images and change them at a given frequency (let's say [24 images per second](https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/)), you will create an [illusion of movement](https://en.wikipedia.org/wiki/Persistence_of_vision).\nIn summary this is the very basic idea behind a video: **a series of pictures / frames running at a given rate**.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg\" title=\"flip book\" height=\"280\"></img>\n\nZeitgenssische Illustration (1886)\n\n## audio - what you listen!\n\nAlthough a muted video can express a variety of feelings, adding sound to it brings more pleasure to the experience.\n\nSound is the vibration that propagates as a wave of pressure, through the air or any other transmission medium, such as a gas, liquid or solid.\n\n> In a digital audio system, a microphone converts sound to an analog electrical signal, then an analog-to-digital converter (ADC)  typically using [pulse-code modulation (PCM)](https://en.wikipedia.org/wiki/Pulse-code_modulation) - converts the analog signal into a digital signal.\n\n![audio analog to digital](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png \"audio analog to digital\")\n>[Source](https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg)\n\n## codec - shrinking data\n\n> CODEC is an electronic circuit or software that **compresses or decompresses digital audio/video.** It converts raw (uncompressed) digital audio/video to a compressed format or vice versa.\n> https://en.wikipedia.org/wiki/Video_codec\n\nBut if we chose to pack millions of images in a single file and called it a movie, we might end up with a huge file. Let's do the math:\n\nSuppose we are creating a video with a resolution of `1080 x 1920` (height x width) and that we'll spend `3 bytes` per pixel (the minimal point at a screen) to encode the color (or [24 bit color](https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29), what gives us 16,777,216 different colors) and this video runs at `24 frames per second` and it is `30 minutes` long.\n\n```c\ntoppf = 1080 * 1920 //total_of_pixels_per_frame\ncpp = 3 //cost_per_pixel\ntis = 30 * 60 //time_in_seconds\nfps = 24 //frames_per_second\n\nrequired_storage = tis * fps * toppf * cpp\n```\n\nThis video would require approximately `250.28GB` of storage or `1.19 Gbps` of bandwidth! That's why we need to use a [CODEC](https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work).\n\n## container - a comfy place for audio and video\n\n> A container or wrapper format is a metafile format whose specification describes how different elements of data and metadata coexist in a computer file.\n> https://en.wikipedia.org/wiki/Digital_container_format\n\nA **single file that contains all the streams** (mostly the audio and video) and it also provides **synchronization and general metadata**, such as title, resolution and etc.\n\nUsually we can infer the format of a file by looking at its extension: for instance a `video.webm` is probably a video using the container [`webm`](https://www.webmproject.org/).\n\n![container](/img/container.png)\n\n# FFmpeg - command line\n\n> A complete, cross-platform solution to record, convert and stream audio and video.\n\nTo work with multimedia we can use the AMAZING tool/library called [FFmpeg](https://www.ffmpeg.org/). Chances are you already know/use it directly or indirectly (do you use [Chrome?](https://www.chromium.org/developers/design-documents/video)).\n\nIt has a command line program called `ffmpeg`, a very simple yet powerful binary.\nFor instance, you can convert from `mp4` to the container `avi` just by typing the follow command:\n\n```bash\n$ ffmpeg -i input.mp4 output.avi\n```\n\nWe just made a **remuxing** here, which is converting from one container to another one.\nTechnically FFmpeg could also be doing a transcoding but we'll talk about that later.\n\n## FFmpeg command line tool 101\n\nFFmpeg does have a [documentation](https://www.ffmpeg.org/ffmpeg.html) that does a great job of explaining how it works.\n\n```bash\n# you can also look for the documentation using the command line\n\nffmpeg -h full | grep -A 10 -B 10 avoid_negative_ts\n```\n\nTo make things short, the FFmpeg command line program expects the following argument format to perform its actions `ffmpeg {1} {2} -i {3} {4} {5}`, where:\n\n1. global options\n2. input file options\n3. input url\n4. output file options\n5. output url\n\nThe parts 2, 3, 4 and 5 can be as many as you need.\nIt's easier to understand this argument format in action:\n\n``` bash\n# WARNING: this file is around 300MB\n$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n\n$ ffmpeg \\\n-y \\ # global options\n-c:a libfdk_aac \\ # input options\n-i bunny_1080p_60fps.mp4 \\ # input url\n-c:v libvpx-vp9 -c:a libvorbis \\ # output options\nbunny_1080p_60fps_vp9.webm # output url\n```\nThis command takes an input file `mp4` containing two streams (an audio encoded with `aac` CODEC and a video encoded using `h264` CODEC) and convert it to `webm`, changing its audio and video CODECs too.\n\nWe could simplify the command above but then be aware that FFmpeg will adopt or guess the default values for you.\nFor instance when you just type `ffmpeg -i input.avi output.mp4` what audio/video CODEC does it use to produce the `output.mp4`?\n\nWerner Robitza wrote a must read/execute [tutorial about encoding and editing with FFmpeg](http://slhck.info/ffmpeg-encoding-course/#/).\n\n# Common video operations\n\nWhile working with audio/video we usually do a set of tasks with the media.\n\n## Transcoding\n\n![transcoding](/img/transcoding.png)\n\n**What?** the act of converting one of the streams (audio or video) from one CODEC to another one.\n\n**Why?** sometimes some devices (TVs, smartphones, console and etc) doesn't support X but Y and newer CODECs provide better compression rate.\n\n**How?** converting an `H264` (AVC) video to an `H265` (HEVC).\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c:v libx265 \\\nbunny_1080p_60fps_h265.mp4\n```\n\n## Transmuxing\n\n![transmuxing](/img/transmuxing.png)\n\n**What?** the act of converting from one format (container) to another one.\n\n**Why?** sometimes some devices (TVs, smartphones, console and etc) doesn't support X but Y and sometimes newer containers provide modern required features.\n\n**How?** converting a `mp4` to a `ts`.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-c copy \\ # just saying to ffmpeg to skip encoding\nbunny_1080p_60fps.ts\n```\n\n## Transrating\n\n![transrating](/img/transrating.png)\n\n**What?** the act of changing the bit rate, or producing other renditions.\n\n**Why?** people will try to watch your video in a `2G` (edge) connection using a less powerful smartphone or in a `fiber` Internet connection on their 4K TVs therefore you should offer more than one rendition of the same video with different bit rate.\n\n**How?** producing a rendition with bit rate between 964K and 3856K.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-minrate 964K -maxrate 3856K -bufsize 2000K \\\nbunny_1080p_60fps_transrating_964_3856.mp4\n```\n\nUsually we'll be using transrating with transsizing. Werner Robitza wrote another must read/execute [series of posts about FFmpeg rate control](http://slhck.info/posts/).\n\n## Transsizing\n\n![transsizing](/img/transsizing.png)\n\n**What?** the act of converting from one resolution to another one. As said before transsizing is often used with transrating.\n\n**Why?** reasons are about the same as for the transrating.\n\n**How?** converting a `1080p` to a `480p` resolution.\n```bash\n$ ffmpeg \\\n-i bunny_1080p_60fps.mp4 \\\n-vf scale=480:-1 \\\nbunny_1080p_60fps_transsizing_480.mp4\n```\n\n## Bonus Round: Adaptive Streaming\n\n![adaptive streaming](/img/adaptive-streaming.png)\n\n**What?** the act of producing many resolutions (bit rates) and split the media into chunks and serve them via http.\n\n**Why?** to provide a flexible media that can be watched on a low end smartphone or on a 4K TV, it's also easy to scale and deploy but it can add latency.\n\n**How?** creating an adaptive WebM using DASH.\n```bash\n# video streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm\n\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm\n\n# audio streams\n$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm\n\n# the DASH manifest\n$ ffmpeg \\\n -f webm_dash_manifest -i video_160x90_250k.webm \\\n -f webm_dash_manifest -i video_320x180_500k.webm \\\n -f webm_dash_manifest -i video_640x360_750k.webm \\\n -f webm_dash_manifest -i video_640x360_1000k.webm \\\n -f webm_dash_manifest -i video_1280x720_500k.webm \\\n -f webm_dash_manifest -i audio_128k.webm \\\n -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \\\n -f webm_dash_manifest \\\n -adaptation_sets \"id=0,streams=0,1,2,3,4 id=1,streams=5\" \\\n manifest.mpd\n```\n\nPS: I stole this example from the [Instructions to playback Adaptive WebM using DASH](http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash)\n\n## Going beyond\n\nThere are [many and many other usages for FFmpeg](https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly).\nI use it in conjunction with *iMovie* to produce/edit some videos for YouTube and you can certainly use it professionally.\n\n# Learn FFmpeg libav the Hard Way\n\n> Don't you wonder sometimes 'bout sound and vision?\n> **David Robert Jones**\n\nSince the [FFmpeg](#ffmpeg---command-line) is so useful as a command line tool to do essential tasks over the media files, how can we use it in our programs?\n\nFFmpeg is [composed by several libraries](https://www.ffmpeg.org/doxygen/trunk/index.html) that can be integrated into our own programs.\nUsually, when you install FFmpeg, it installs automatically all these libraries. I'll be referring to the set of these libraries as **FFmpeg libav**.\n\n> This title is a homage to Zed Shaw's series [Learn X the Hard Way](https://learncodethehardway.org/), particularly his book Learn C the Hard Way.\n\n## Chapter 0 - The infamous hello world\nThis hello world actually won't show the message `\"hello world\"` in the terminal :tongue:\nInstead we're going to **print out information about the video**, things like its format (container), duration, resolution, audio channels and, in the end, we'll **decode some frames and save them as image files**.\n\n### FFmpeg libav architecture\n\nBut before we start to code, let's learn how **FFmpeg libav architecture** works and how its components communicate with others.\n\nHere's a diagram of the process of decoding a video:\n\n![ffmpeg libav architecture - decoding process](/img/decoding.png)\n\nYou'll first need to load your media file into a component called [`AVFormatContext`](https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) (the video container is also known as format).\nIt actually doesn't fully load the whole file: it often only reads the header.\n\nOnce we loaded the minimal **header of our container**, we can access its streams (think of them as a rudimentary audio and video data).\nEach stream will be available in a component called [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html).\n\n> Stream is a fancy name for a continuous flow of data.\n\nSuppose our video has two streams: an audio encoded with [AAC CODEC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding) and a video encoded with [H264 (AVC) CODEC](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC). From each stream we can extract **pieces (slices) of data** called packets that will be loaded into components named [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html).\n\nThe **data inside the packets are still coded** (compressed) and in order to decode the packets, we need to pass them to a specific [`AVCodec`](https://ffmpeg.org/doxygen/trunk/structAVCodec.html).\n\nThe `AVCodec` will decode them into [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html) and finally, this component gives us **the uncompressed frame**.  Noticed that the same terminology/process is used either by audio and video stream.\n\n### Requirements\n\nSince some people were [facing issues while compiling or running the examples](https://github.com/leandromoreira/ffmpeg-libav-tutorial/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+compiling) **we're going to use [`Docker`](https://docs.docker.com/install/) as our development/runner environment,** we'll also use the big buck bunny video so if you don't have it locally just run the command `make fetch_small_bunny_video`.\n\n### Chapter 0 - code walkthrough\n\n> #### TLDR; show me the [code](/0_hello_world.c) and execution.\n> ```bash\n> $ make run_hello\n> ```\n\nWe'll skip some details, but don't worry: the [source code is available at github](/0_hello_world.c).\n\nWe're going to allocate memory to the component [`AVFormatContext`](http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html) that will hold  information about the format (container).\n\n```c\nAVFormatContext *pFormatContext = avformat_alloc_context();\n```\n\nNow we're going to open the file and read its header and fill the `AVFormatContext` with minimal information about the format (notice that usually the codecs are not opened).\nThe function used to do this is [`avformat_open_input`](http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49). It expects an `AVFormatContext`, a `filename` and two optional arguments: the [`AVInputFormat`](https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html) (if you pass `NULL`, FFmpeg will guess the format) and the [`AVDictionary`](https://ffmpeg.org/doxygen/trunk/structAVDictionary.html) (which are the options to the demuxer).\n\n```c\navformat_open_input(&pFormatContext, filename, NULL, NULL);\n```\n\nWe can print the format name and the media duration:\n\n```c\nprintf(\"Format %s, duration %lld us\", pFormatContext->iformat->long_name, pFormatContext->duration);\n```\n\nTo access the `streams`, we need to read data from the media. The function [`avformat_find_stream_info`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb) does that.\nNow, the `pFormatContext->nb_streams` will hold the amount of streams and the `pFormatContext->streams[i]` will give us the `i` stream (an [`AVStream`](https://ffmpeg.org/doxygen/trunk/structAVStream.html)).\n\n```c\navformat_find_stream_info(pFormatContext,  NULL);\n```\n\nNow we'll loop through all the streams.\n\n```c\nfor (int i = 0; i < pFormatContext->nb_streams; i++)\n{\n  //\n}\n```\n\nFor each stream, we're going to keep the [`AVCodecParameters`](https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html), which describes the properties of a codec used by the stream `i`.\n\n```c\nAVCodecParameters *pLocalCodecParameters = pFormatContext->streams[i]->codecpar;\n```\n\nWith the codec properties we can look up the proper CODEC querying the function [`avcodec_find_decoder`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca) and find the registered decoder for the codec id and return an [`AVCodec`](http://ffmpeg.org/doxygen/trunk/structAVCodec.html), the component that knows how to en**CO**de and **DEC**ode the stream.\n```c\nAVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters->codec_id);\n```\n\nNow we can print information about the codecs.\n\n```c\n// specific for video and audio\nif (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_VIDEO) {\n  printf(\"Video Codec: resolution %d x %d\", pLocalCodecParameters->width, pLocalCodecParameters->height);\n} else if (pLocalCodecParameters->codec_type == AVMEDIA_TYPE_AUDIO) {\n  printf(\"Audio Codec: %d channels, sample rate %d\", pLocalCodecParameters->channels, pLocalCodecParameters->sample_rate);\n}\n// general\nprintf(\"\\tCodec %s ID %d bit_rate %lld\", pLocalCodec->long_name, pLocalCodec->id, pLocalCodecParameters->bit_rate);\n```\n\nWith the codec, we can allocate memory for the [`AVCodecContext`](https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html), which will hold the context for our decode/encode process, but then we need to fill this codec context with CODEC parameters; we do that with [`avcodec_parameters_to_context`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16).\n\nOnce we filled the codec context, we need to open the codec. We call the function [`avcodec_open2`](https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) and then we can use it.\n\n```c\nAVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);\navcodec_parameters_to_context(pCodecContext, pCodecParameters);\navcodec_open2(pCodecContext, pCodec, NULL);\n```\n\nNow we're going to read the packets from the stream and decode them into frames but first, we need to allocate memory for both components, the [`AVPacket`](https://ffmpeg.org/doxygen/trunk/structAVPacket.html) and [`AVFrame`](https://ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n```c\nAVPacket *pPacket = av_packet_alloc();\nAVFrame *pFrame = av_frame_alloc();\n```\n\nLet's feed our packets from the streams with the function [`av_read_frame`](https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61) while it has packets.\n\n```c\nwhile (av_read_frame(pFormatContext, pPacket) >= 0) {\n  //...\n}\n```\n\nLet's **send the raw data packet** (compressed frame) to the decoder, through the codec context, using the function [`avcodec_send_packet`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3).\n\n```c\navcodec_send_packet(pCodecContext, pPacket);\n```\n\nAnd let's **receive the raw data frame** (uncompressed frame) from the decoder, through the same codec context, using the function [`avcodec_receive_frame`](https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c).\n\n```c\navcodec_receive_frame(pCodecContext, pFrame);\n```\n\nWe can print the frame number, the [PTS](https://en.wikipedia.org/wiki/Presentation_timestamp), DTS, [frame type](https://en.wikipedia.org/wiki/Video_compression_picture_types) and etc.\n\n```c\nprintf(\n    \"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]\",\n    av_get_picture_type_char(pFrame->pict_type),\n    pCodecContext->frame_number,\n    pFrame->pts,\n    pFrame->pkt_dts,\n    pFrame->key_frame,\n    pFrame->coded_picture_number,\n    pFrame->display_picture_number\n);\n```\n\nFinally we can save our decoded frame into a [simple gray image](https://en.wikipedia.org/wiki/Netpbm_format#PGM_example). The process is very simple, we'll use the `pFrame->data` where the index is related to the [planes Y, Cb and Cr](https://en.wikipedia.org/wiki/YCbCr), we just picked `0` (Y) to save our gray image.\n\n```c\nsave_gray_frame(pFrame->data[0], pFrame->linesize[0], pFrame->width, pFrame->height, frame_filename);\n\nstatic void save_gray_frame(unsigned char *buf, int wrap, int xsize, int ysize, char *filename)\n{\n    FILE *f;\n    int i;\n    f = fopen(filename,\"w\");\n    // writing the minimal required header for a pgm file format\n    // portable graymap format -> https://en.wikipedia.org/wiki/Netpbm_format#PGM_example\n    fprintf(f, \"P5\\n%d %d\\n%d\\n\", xsize, ysize, 255);\n\n    // writing line by line\n    for (i = 0; i < ysize; i++)\n        fwrite(buf + i * wrap, 1, xsize, f);\n    fclose(f);\n}\n```\n\nAnd voil! Now we have a gray scale image with 2MB:\n\n![saved frame](/img/generated_frame.png)\n\n## Chapter 1 - syncing audio and video\n\n> **Be the player** - a young JS developer writing a new MSE video player.\n\nBefore we move to [code a transcoding example](#chapter-2---transcoding) let's talk about **timing**, or how a video player knows the right time to play a frame.\n\nIn the last example, we saved some frames that can be seen here:\n\n![frame 0](/img/hello_world_frames/frame0.png)\n![frame 1](/img/hello_world_frames/frame1.png)\n![frame 2](/img/hello_world_frames/frame2.png)\n![frame 3](/img/hello_world_frames/frame3.png)\n![frame 4](/img/hello_world_frames/frame4.png)\n![frame 5](/img/hello_world_frames/frame5.png)\n\nWhen we're designing a video player we need to **play each frame at a given pace**, otherwise it would be hard to pleasantly see the video either because it's playing so fast or so slow.\n\nTherefore we need to introduce some logic to play each frame smoothly. For that matter, each frame has a **presentation timestamp** (PTS) which is an increasing number factored in a **timebase** that is a rational number (where the denominator is known as **timescale**) divisible by the **frame rate (fps)**.\n\nIt's easier to understand when we look at some examples, let's simulate some scenarios.\n\nFor a `fps=60/1` and `timebase=1/60000` each PTS will increase `timescale / fps = 1000` therefore the **PTS real time** for each frame could be (supposing it started at 0):\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033`\n\nFor almost the same scenario but with a timebase equal to `1/60`.\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016`\n* `frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033`\n* `frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050`\n\nFor a `fps=25/1` and `timebase=1/75` each PTS will increase `timescale / fps = 3` and the PTS time could be:\n\n* `frame=0, PTS = 0, PTS_TIME = 0`\n* `frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04`\n* `frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08`\n* `frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12`\n* ...\n* `frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96`\n* ...\n* `frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56`\n\nNow with the `pts_time` we can find a way to render this synched with audio `pts_time` or with a system clock. The FFmpeg libav provides these info through its API:\n\n- fps = [`AVStream->avg_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a946e1e9b89eeeae4cab8a833b482c1ad)\n- tbr = [`AVStream->r_frame_rate`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#ad63fb11cc1415e278e09ddc676e8a1ad)\n- tbn = [`AVStream->time_base`](https://ffmpeg.org/doxygen/trunk/structAVStream.html#a9db755451f14e2bf590d4b85d82b32e6)\n\nJust out of curiosity, the frames we saved were sent in a DTS order (frames: 1,6,4,2,3,5) but played at a PTS order (frames: 1,2,3,4,5). Also, notice how cheap are B-Frames in comparison to P or I-Frames.\n\n```\nLOG: AVStream->r_frame_rate 60/1\nLOG: AVStream->time_base 1/60000\n...\nLOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]\nLOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]\nLOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]\nLOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]\nLOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]\nLOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]\n```\n\n## Chapter 2 - remuxing\n\nRemuxing is the act of changing from one format (container) to another, for instance, we can change a [MPEG-4](https://en.wikipedia.org/wiki/MPEG-4_Part_14) video to a [MPEG-TS](https://en.wikipedia.org/wiki/MPEG_transport_stream) one without much pain using FFmpeg:\n\n```bash\nffmpeg input.mp4 -c copy output.ts\n```\n\nIt'll demux the mp4 but it won't decode or encode it (`-c copy`) and in the end, it'll mux it into a `mpegts` file. If you don't provide the format `-f` the ffmpeg will try to guess it based on the file's extension.\n\nThe general usage of FFmpeg or the libav follows a pattern/architecture or workflow:\n* **[protocol layer](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - it accepts an `input` (a `file` for instance but it could be a `rtmp` or `HTTP` input as well)\n* **[format layer](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - it `demuxes` its content, revealing mostly metadata and its streams\n* **[codec layer](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - it `decodes` its compressed streams data <sup>*optional*</sup>\n* **[pixel layer](https://ffmpeg.org/doxygen/trunk/group__lavfi.html)** - it can also apply some `filters` to the raw frames (like resizing)<sup>*optional*</sup>\n* and then it does the reverse path\n* **[codec layer](https://ffmpeg.org/doxygen/trunk/group__libavc.html)** - it `encodes` (or `re-encodes` or even `transcodes`) the raw frames<sup>*optional*</sup>\n* **[format layer](https://ffmpeg.org/doxygen/trunk/group__libavf.html)** - it `muxes` (or `remuxes`) the raw streams (the compressed data)\n* **[protocol layer](https://ffmpeg.org/doxygen/trunk/protocols_8c.html)** - and finally the muxed data is sent to an `output` (another file or maybe a network remote server)\n\n![ffmpeg libav workflow](/img/ffmpeg_libav_workflow.jpeg)\n> This graph is strongly inspired by [Leixiaohua's](http://leixiaohua1020.github.io/#ffmpeg-development-examples) and [Slhck's](https://slhck.info/ffmpeg-encoding-course/#/9) works.\n\nNow let's code an example using libav to provide the same effect as in `ffmpeg input.mp4 -c copy output.ts`.\n\nWe're going to read from an input (`input_format_context`) and change it to another output (`output_format_context`).\n\n```c\nAVFormatContext *input_format_context = NULL;\nAVFormatContext *output_format_context = NULL;\n```\n\nWe start doing the usually allocate memory and open the input format. For this specific case, we're going to open an input file and allocate memory for an output file.\n\n```c\nif ((ret = avformat_open_input(&input_format_context, in_filename, NULL, NULL)) < 0) {\n  fprintf(stderr, \"Could not open input file '%s'\", in_filename);\n  goto end;\n}\nif ((ret = avformat_find_stream_info(input_format_context, NULL)) < 0) {\n  fprintf(stderr, \"Failed to retrieve input stream information\");\n  goto end;\n}\n\navformat_alloc_output_context2(&output_format_context, NULL, NULL, out_filename);\nif (!output_format_context) {\n  fprintf(stderr, \"Could not create output context\\n\");\n  ret = AVERROR_UNKNOWN;\n  goto end;\n}\n```\n\nWe're going to remux only the video, audio and subtitle types of streams so we're holding what streams we'll be using into an array of indexes.\n\n```c\nnumber_of_streams = input_format_context->nb_streams;\nstreams_list = av_mallocz_array(number_of_streams, sizeof(*streams_list));\n```\n\nJust after we allocated the required memory, we're going to loop throughout all the streams and for each one we need to create new out stream into our output format context, using the [avformat_new_stream](https://ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827) function. Notice that we're marking all the streams that aren't video, audio or subtitle so we can skip them after.\n\n```c\nfor (i = 0; i < input_format_context->nb_streams; i++) {\n  AVStream *out_stream;\n  AVStream *in_stream = input_format_context->streams[i];\n  AVCodecParameters *in_codecpar = in_stream->codecpar;\n  if (in_codecpar->codec_type != AVMEDIA_TYPE_AUDIO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_VIDEO &&\n      in_codecpar->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n    streams_list[i] = -1;\n    continue;\n  }\n  streams_list[i] = stream_index++;\n  out_stream = avformat_new_stream(output_format_context, NULL);\n  if (!out_stream) {\n    fprintf(stderr, \"Failed allocating output stream\\n\");\n    ret = AVERROR_UNKNOWN;\n    goto end;\n  }\n  ret = avcodec_parameters_copy(out_stream->codecpar, in_codecpar);\n  if (ret < 0) {\n    fprintf(stderr, \"Failed to copy codec parameters\\n\");\n    goto end;\n  }\n}\n```\n\nNow we can create the output file.\n\n```c\nif (!(output_format_context->oformat->flags & AVFMT_NOFILE)) {\n  ret = avio_open(&output_format_context->pb, out_filename, AVIO_FLAG_WRITE);\n  if (ret < 0) {\n    fprintf(stderr, \"Could not open output file '%s'\", out_filename);\n    goto end;\n  }\n}\n\nret = avformat_write_header(output_format_context, NULL);\nif (ret < 0) {\n  fprintf(stderr, \"Error occurred when opening output file\\n\");\n  goto end;\n}\n```\n\nAfter that, we can copy the streams, packet by packet, from our input to our output streams. We'll loop while it has packets (`av_read_frame`), for each packet we need to re-calculate the PTS and DTS to finally write it (`av_interleaved_write_frame`) to our output format context.\n\n```c\nwhile (1) {\n  AVStream *in_stream, *out_stream;\n  ret = av_read_frame(input_format_context, &packet);\n  if (ret < 0)\n    break;\n  in_stream  = input_format_context->streams[packet.stream_index];\n  if (packet.stream_index >= number_of_streams || streams_list[packet.stream_index] < 0) {\n    av_packet_unref(&packet);\n    continue;\n  }\n  packet.stream_index = streams_list[packet.stream_index];\n  out_stream = output_format_context->streams[packet.stream_index];\n  /* copy packet */\n  packet.pts = av_rescale_q_rnd(packet.pts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.dts = av_rescale_q_rnd(packet.dts, in_stream->time_base, out_stream->time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);\n  packet.duration = av_rescale_q(packet.duration, in_stream->time_base, out_stream->time_base);\n  // https://ffmpeg.org/doxygen/trunk/structAVPacket.html#ab5793d8195cf4789dfb3913b7a693903\n  packet.pos = -1;\n\n  //https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1\n  ret = av_interleaved_write_frame(output_format_context, &packet);\n  if (ret < 0) {\n    fprintf(stderr, \"Error muxing packet\\n\");\n    break;\n  }\n  av_packet_unref(&packet);\n}\n```\n\nTo finalize we need to write the stream trailer to an output media file with [av_write_trailer](https://ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga7f14007e7dc8f481f054b21614dfec13) function.\n\n```c\nav_write_trailer(output_format_context);\n```\n\nNow we're ready to test it and the first test will be a format (video container) conversion from a MP4 to a MPEG-TS video file. We're basically making the command line `ffmpeg input.mp4 -c copy output.ts` with libav.\n\n```bash\nmake run_remuxing_ts\n```\n\nIt's working!!! don't you trust me?! you shouldn't, we can check it with `ffprobe`:\n\n```bash\nffprobe -i remuxed_small_bunny_1080p_60fps.ts\n\nInput #0, mpegts, from 'remuxed_small_bunny_1080p_60fps.ts':\n  Duration: 00:00:10.03, start: 0.000000, bitrate: 2751 kb/s\n  Program 1\n    Metadata:\n      service_name    : Service01\n      service_provider: FFmpeg\n    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 60 fps, 60 tbr, 90k tbn, 120 tbc\n    Stream #0:1[0x101]: Audio: ac3 ([129][0][0][0] / 0x0081), 48000 Hz, 5.1(side), fltp, 320 kb/s\n```\n\nTo sum up what we did here in a graph, we can revisit our initial [idea about how libav works](https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg-libav-architecture) but showing that we skipped the codec part.\n\n![remuxing libav components](/img/remuxing_libav_components.png)\n\nBefore we end this chapter I'd like to show an important part of the remuxing process, **you can pass options to the muxer**. Let's say we want to delivery [MPEG-DASH](https://developer.mozilla.org/en-US/docs/Web/Apps/Fundamentals/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources#MPEG-DASH_Encoding) format for that matter we need to use [fragmented mp4](https://stackoverflow.com/a/35180327) (sometimes referred as `fmp4`) instead of MPEG-TS or plain MPEG-4.\n\nWith the [command line we can do that easily](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API/Transcoding_assets_for_MSE#Fragmenting).\n\n```\nffmpeg -i non_fragmented.mp4 -movflags frag_keyframe+empty_moov+default_base_moof fragmented.mp4\n```\n\nAlmost equally easy as the command line is the libav version of it, we just need to pass the options when write the output header, just before the packets copy.\n\n```c\nAVDictionary* opts = NULL;\nav_dict_set(&opts, \"movflags\", \"frag_keyframe+empty_moov+default_base_moof\", 0);\nret = avformat_write_header(output_format_context, &opts);\n```\n\nWe now can generate this fragmented mp4 file:\n\n```bash\nmake run_remuxing_fragmented_mp4\n```\n\nBut to make sure that I'm not lying to you. You can use the amazing site/tool [gpac/mp4box.js](http://download.tsi.telecom-paristech.fr/gpac/mp4box.js/filereader.html) or the site [http://mp4parser.com/](http://mp4parser.com/) to see the differences, first load up the \"common\" mp4.\n\n![mp4 boxes](/img/boxes_normal_mp4.png)\n\nAs you can see it has a single `mdat` atom/box, **this is place where the video and audio frames are**. Now load the fragmented mp4 to see which how it spreads the `mdat` boxes.\n\n![fragmented mp4 boxes](/img/boxes_fragmente_mp4.png)\n\n## Chapter 3 - transcoding\n\n> #### TLDR; show me the [code](/3_transcoding.c) and execution.\n> ```bash\n> $ make run_transcoding\n> ```\n> We'll skip some details, but don't worry: the [source code is available at github](/3_transcoding.c).\n\n\n\nIn this chapter, we're going to create a minimalist transcoder, written in C, that can convert videos coded in H264 to H265 using **FFmpeg/libav** library specifically [libavcodec](https://ffmpeg.org/libavcodec.html), libavformat, and libavutil.\n\n![media transcoding flow](/img/transcoding_flow.png)\n\n> _Just a quick recap:_ The [**AVFormatContext**](https://www.ffmpeg.org/doxygen/trunk/structAVFormatContext.html) is the abstraction for the format of the media file, aka container (ex: MKV, MP4, Webm, TS). The [**AVStream**](https://www.ffmpeg.org/doxygen/trunk/structAVStream.html) represents each type of data for a given format (ex: audio, video, subtitle, metadata). The [**AVPacket**](https://www.ffmpeg.org/doxygen/trunk/structAVPacket.html) is a slice of compressed data obtained from the `AVStream` that can be decoded by an [**AVCodec**](https://www.ffmpeg.org/doxygen/trunk/structAVCodec.html) (ex: av1, h264, vp9, hevc) generating a raw data called [**AVFrame**](https://www.ffmpeg.org/doxygen/trunk/structAVFrame.html).\n\n### Transmuxing\n\nLet's start with the simple transmuxing operation and then we can build upon this code, the first step is to **load the input file**.\n\n```c\n// Allocate an AVFormatContext\navfc = avformat_alloc_context();\n// Open an input stream and read the header.\navformat_open_input(avfc, in_filename, NULL, NULL);\n// Read packets of a media file to get stream information.\navformat_find_stream_info(avfc, NULL);\n```\n\nNow we're going to set up the decoder, the `AVFormatContext` will give us access to all the `AVStream` components and for each one of them, we can get their `AVCodec` and create the particular `AVCodecContext` and finally we can open the given codec so we can proceed to the decoding process.\n\n>  The [**AVCodecContext**](https://www.ffmpeg.org/doxygen/trunk/structAVCodecContext.html) holds data about media configuration such as bit rate, frame rate, sample rate, channels, height, and many others.\n\n```c\nfor (int i = 0; i < avfc->nb_streams; i++)\n{\n  AVStream *avs = avfc->streams[i];\n  AVCodec *avc = avcodec_find_decoder(avs->codecpar->codec_id);\n  AVCodecContext *avcc = avcodec_alloc_context3(*avc);\n  avcodec_parameters_to_context(*avcc, avs->codecpar);\n  avcodec_open2(*avcc, *avc, NULL);\n}\n```\n\nWe need to prepare the output media file for transmuxing as well, we first **allocate memory** for the output `AVFormatContext`. We create **each stream** in the output format. In order to pack the stream properly, we **copy the codec parameters** from the decoder.\n\nWe **set the flag** `AV_CODEC_FLAG_GLOBAL_HEADER` which tells the encoder that it can use the global headers and finally we open the output **file for write** and persist the headers.\n\n```c\navformat_alloc_output_context2(&encoder_avfc, NULL, NULL, out_filename);\n\nAVStream *avs = avformat_new_stream(encoder_avfc, NULL);\navcodec_parameters_copy(avs->codecpar, decoder_avs->codecpar);\n\nif (encoder_avfc->oformat->flags & AVFMT_GLOBALHEADER)\n  encoder_avfc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\navio_open(&encoder_avfc->pb, encoder->filename, AVIO_FLAG_WRITE);\navformat_write_header(encoder->avfc, &muxer_opts);\n\n```\n\nWe're getting the `AVPacket`'s from the decoder, adjusting the timestamps, and write the packet properly to the output file. Even though the function `av_interleaved_write_frame` says \"write frame\" we are storing the packet. We finish the transmuxing process by writing the stream trailer to the file.\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  av_packet_rescale_ts(input_packet, decoder_video_avs->time_base, encoder_video_avs->time_base);\n  av_interleaved_write_frame(*avfc, input_packet) < 0));\n}\n\nav_write_trailer(encoder_avfc);\n```\n\n### Transcoding\n\nThe previous section showed a simple transmuxer program, now we're going to add the capability to encode files, specifically we're going to enable it to transcode videos from `h264` to `h265`.\n\nAfter we prepared the decoder but before we arrange the output media file we're going to set up the encoder.\n\n* Create the video `AVStream` in the encoder, [`avformat_new_stream`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__core.html#gadcb0fd3e507d9b58fe78f61f8ad39827)\n* Use the `AVCodec` called `libx265`, [`avcodec_find_encoder_by_name`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__encoding.html#gaa614ffc38511c104bdff4a3afa086d37)\n* Create the `AVCodecContext` based in the created codec, [`avcodec_alloc_context3`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#gae80afec6f26df6607eaacf39b561c315)\n* Set up basic attributes for the transcoding session, and\n* Open the codec and copy parameters from the context to the stream. [`avcodec_open2`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d) and [`avcodec_parameters_from_context`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga0c7058f764778615e7978a1821ab3cfe)\n\n```c\nAVRational input_framerate = av_guess_frame_rate(decoder_avfc, decoder_video_avs, NULL);\nAVStream *video_avs = avformat_new_stream(encoder_avfc, NULL);\n\nchar *codec_name = \"libx265\";\nchar *codec_priv_key = \"x265-params\";\n// we're going to use internal options for the x265\n// it disables the scene change detection and fix then\n// GOP on 60 frames.\nchar *codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\nAVCodec *video_avc = avcodec_find_encoder_by_name(codec_name);\nAVCodecContext *video_avcc = avcodec_alloc_context3(video_avc);\n// encoder codec params\nav_opt_set(sc->video_avcc->priv_data, codec_priv_key, codec_priv_value, 0);\nvideo_avcc->height = decoder_ctx->height;\nvideo_avcc->width = decoder_ctx->width;\nvideo_avcc->pix_fmt = video_avc->pix_fmts[0];\n// control rate\nvideo_avcc->bit_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_buffer_size = 4 * 1000 * 1000;\nvideo_avcc->rc_max_rate = 2 * 1000 * 1000;\nvideo_avcc->rc_min_rate = 2.5 * 1000 * 1000;\n// time base\nvideo_avcc->time_base = av_inv_q(input_framerate);\nvideo_avs->time_base = sc->video_avcc->time_base;\n\navcodec_open2(sc->video_avcc, sc->video_avc, NULL);\navcodec_parameters_from_context(sc->video_avs->codecpar, sc->video_avcc);\n```\n\nWe need to expand our decoding loop for the video stream transcoding:\n\n* Send the empty `AVPacket` to the decoder, [`avcodec_send_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3)\n* Receive the uncompressed `AVFrame`, [`avcodec_receive_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c)\n* Start to transcode this raw frame,\n* Send the raw frame, [`avcodec_send_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga9395cb802a5febf1f00df31497779169)\n* Receive the compressed, based on our codec, `AVPacket`, [`avcodec_receive_packet`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga5b8eff59cf259747cf0b31563e38ded6)\n* Set up the timestamp, and [`av_packet_rescale_ts`](https://www.ffmpeg.org/doxygen/trunk/group__lavc__packet.html#gae5c86e4d93f6e7aa62ef2c60763ea67e)\n* Write it to the output file. [`av_interleaved_write_frame`](https://www.ffmpeg.org/doxygen/trunk/group__lavf__encoding.html#ga37352ed2c63493c38219d935e71db6c1)\n\n```c\nAVFrame *input_frame = av_frame_alloc();\nAVPacket *input_packet = av_packet_alloc();\n\nwhile (av_read_frame(decoder_avfc, input_packet) >= 0)\n{\n  int response = avcodec_send_packet(decoder_video_avcc, input_packet);\n  while (response >= 0) {\n    response = avcodec_receive_frame(decoder_video_avcc, input_frame);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return response;\n    }\n    if (response >= 0) {\n      encode(encoder_avfc, decoder_video_avs, encoder_video_avs, decoder_video_avcc, input_packet->stream_index);\n    }\n    av_frame_unref(input_frame);\n  }\n  av_packet_unref(input_packet);\n}\nav_write_trailer(encoder_avfc);\n\n// used function\nint encode(AVFormatContext *avfc, AVStream *dec_video_avs, AVStream *enc_video_avs, AVCodecContext video_avcc int index) {\n  AVPacket *output_packet = av_packet_alloc();\n  int response = avcodec_send_frame(video_avcc, input_frame);\n\n  while (response >= 0) {\n    response = avcodec_receive_packet(video_avcc, output_packet);\n    if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {\n      break;\n    } else if (response < 0) {\n      return -1;\n    }\n\n    output_packet->stream_index = index;\n    output_packet->duration = enc_video_avs->time_base.den / enc_video_avs->time_base.num / dec_video_avs->avg_frame_rate.num * dec_video_avs->avg_frame_rate.den;\n\n    av_packet_rescale_ts(output_packet, dec_video_avs->time_base, enc_video_avs->time_base);\n    response = av_interleaved_write_frame(avfc, output_packet);\n  }\n  av_packet_unref(output_packet);\n  av_packet_free(&output_packet);\n  return 0;\n}\n\n```\n\nWe converted the media stream from `h264` to `h265`, as expected the `h265` version of the media file is smaller than the `h264` however the [created program](/3_transcoding.c) is capable of:\n\n```c\n\n  /*\n   * H264 -> H265\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx265\";\n  sp.codec_priv_key = \"x265-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> remuxed (untouched)\n   * MP4 - fragmented MP4\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 1;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.muxer_opt_key = \"movflags\";\n  sp.muxer_opt_value = \"frag_keyframe+empty_moov+delay_moov+default_base_moof\";\n\n  /*\n   * H264 -> H264 (fixed gop)\n   * Audio -> AAC\n   * MP4 - MPEG-TS\n   */\n  StreamingParams sp = {0};\n  sp.copy_audio = 0;\n  sp.copy_video = 0;\n  sp.video_codec = \"libx264\";\n  sp.codec_priv_key = \"x264-params\";\n  sp.codec_priv_value = \"keyint=60:min-keyint=60:scenecut=0:force-cfr=1\";\n  sp.audio_codec = \"aac\";\n  sp.output_extension = \".ts\";\n\n  /* WIP :P  -> it's not playing on VLC, the final bit rate is huge\n   * H264 -> VP9\n   * Audio -> Vorbis\n   * MP4 - WebM\n   */\n  //StreamingParams sp = {0};\n  //sp.copy_audio = 0;\n  //sp.copy_video = 0;\n  //sp.video_codec = \"libvpx-vp9\";\n  //sp.audio_codec = \"libvorbis\";\n  //sp.output_extension = \".webm\";\n\n```\n\n> Now, to be honest, this was [harder than I thought](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54) it'd be and I had to dig into the [FFmpeg command line source code](https://github.com/leandromoreira/ffmpeg-libav-tutorial/pull/54#issuecomment-570746749) and test it a lot and I think I'm missing something because I had to enforce `force-cfr` for the `h264` to work and I'm still seeing some warning messages like `warning messages (forced frame type (5) at 80 was changed to frame type (3))`.\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "fetch_bbb_video.sh",
          "type": "blob",
          "size": 0.310546875,
          "content": "#!/bin/bash\n#  the link doesn't work anymore\n# wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4\n# ffmpeg -y -i bunny_1080p_60fps.mp4 -ss 00:01:24 -t 00:00:10 small_bunny_1080p_60fps.mp4\n\necho \"the small_bunny_1080p_60fps.mp4 is already provided\"\n"
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "remuxed_small_bunny_1080p_60fps.ts",
          "type": "blob",
          "size": 1320.0390625,
          "content": null
        },
        {
          "name": "small_bunny_1080p_60fps.mp4",
          "type": "blob",
          "size": 1267.0224609375,
          "content": null
        },
        {
          "name": "video_debugging.c",
          "type": "blob",
          "size": 2.6201171875,
          "content": "#include <libavcodec/avcodec.h>\n#include <libavformat/avformat.h>\n#include <libavutil/timestamp.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <stdlib.h>\n#include <libavutil/opt.h>\n#include <string.h>\n#include <inttypes.h>\n#include \"video_debugging.h\"\n\nvoid logging(const char *fmt, ...)\n{\n  va_list args;\n  fprintf( stderr, \"LOG: \" );\n  va_start( args, fmt );\n  vfprintf( stderr, fmt, args );\n  va_end( args );\n  fprintf( stderr, \"\\n\" );\n}\n\nvoid log_packet(const AVFormatContext *fmt_ctx, const AVPacket *pkt)\n{\n    AVRational *time_base = &fmt_ctx->streams[pkt->stream_index]->time_base;\n\n    logging(\"pts:%s pts_time:%s dts:%s dts_time:%s duration:%s duration_time:%s stream_index:%d\",\n           av_ts2str(pkt->pts), av_ts2timestr(pkt->pts, time_base),\n           av_ts2str(pkt->dts), av_ts2timestr(pkt->dts, time_base),\n           av_ts2str(pkt->duration), av_ts2timestr(pkt->duration, time_base),\n           pkt->stream_index);\n}\n\nvoid print_timing(char *name, AVFormatContext *avf, AVCodecContext *avc, AVStream *avs) {\n  logging(\"=================================================\");\n  logging(\"%s\", name);\n\n  logging(\"\\tAVFormatContext\");\n  if (avf != NULL) {\n    logging(\"\\t\\tstart_time=%d duration=%d bit_rate=%d start_time_realtime=%d\", avf->start_time, avf->duration, avf->bit_rate, avf->start_time_realtime);\n  } else {\n    logging(\"\\t\\t->NULL\");\n  }\n\n  logging(\"\\tAVCodecContext\");\n  if (avc != NULL) {\n    logging(\"\\t\\tbit_rate=%d ticks_per_frame=%d width=%d height=%d gop_size=%d keyint_min=%d sample_rate=%d profile=%d level=%d \",\n        avc->bit_rate, avc->ticks_per_frame, avc->width, avc->height, avc->gop_size, avc->keyint_min, avc->sample_rate, avc->profile, avc->level);\n    logging(\"\\t\\tavc->time_base=num/den %d/%d\", avc->time_base.num, avc->time_base.den);\n    logging(\"\\t\\tavc->framerate=num/den %d/%d\", avc->framerate.num, avc->framerate.den);\n    logging(\"\\t\\tavc->pkt_timebase=num/den %d/%d\", avc->pkt_timebase.num, avc->pkt_timebase.den);\n  } else {\n    logging(\"\\t\\t->NULL\");\n  }\n\n  logging(\"\\tAVStream\");\n  if (avs != NULL) {\n    logging(\"\\t\\tindex=%d start_time=%d duration=%d \", avs->index, avs->start_time, avs->duration);\n    logging(\"\\t\\tavs->time_base=num/den %d/%d\", avs->time_base.num, avs->time_base.den);\n    logging(\"\\t\\tavs->sample_aspect_ratio=num/den %d/%d\", avs->sample_aspect_ratio.num, avs->sample_aspect_ratio.den);\n    logging(\"\\t\\tavs->avg_frame_rate=num/den %d/%d\", avs->avg_frame_rate.num, avs->avg_frame_rate.den);\n    logging(\"\\t\\tavs->r_frame_rate=num/den %d/%d\", avs->r_frame_rate.num, avs->r_frame_rate.den);\n  } else {\n    logging(\"\\t\\t->NULL\");\n  }\n\n  logging(\"=================================================\");\n}\n"
        },
        {
          "name": "video_debugging.h",
          "type": "blob",
          "size": 0.4130859375,
          "content": "#include <libavcodec/avcodec.h>\n#include <libavformat/avformat.h>\n#include <libavutil/timestamp.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <stdlib.h>\n#include <libavutil/opt.h>\n#include <string.h>\n#include <inttypes.h>\n\nvoid logging(const char *fmt, ...);\nvoid log_packet(const AVFormatContext *fmt_ctx, const AVPacket *pkt);\nvoid print_timing(char *name, AVFormatContext *avf, AVCodecContext *avc, AVStream *avs);\n"
        }
      ]
    }
  ]
}