{
  "metadata": {
    "timestamp": 1736710391067,
    "page": 5,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebook/zstd",
      "stars": 24112,
      "defaultBranch": "dev",
      "files": [
        {
          "name": ".buckconfig",
          "type": "blob",
          "size": 0.3974609375,
          "content": "[cxx]\n  cppflags = -DXXH_NAMESPACE=ZSTD_ -DZSTD_LEGACY_SUPPORT=4\n  cflags = -Wall -Wextra -Wcast-qual -Wcast-align -Wshadow -Wstrict-aliasing=1 -Wswitch-enum -Wdeclaration-after-statement -Wstrict-prototypes -Wundef -Wpointer-arith\n  cxxppflags = -DXXH_NAMESPACE=ZSTD_ -DZSTD_LEGACY_SUPPORT=4\n  cxxflags = -std=c++11 -Wno-deprecated-declarations\n  gtest_dep = //contrib/pzstd:gtest\n\n[httpserver]\n  port = 0\n"
        },
        {
          "name": ".buckversion",
          "type": "blob",
          "size": 0.0400390625,
          "content": "c8dec2e8da52d483f6dd7c6cd2ad694e8e6fed2b\n"
        },
        {
          "name": ".cirrus.yml",
          "type": "blob",
          "size": 0.2099609375,
          "content": "task:\n  name: FreeBSD (shortest)\n  freebsd_instance:\n    matrix:\n      image_family: freebsd-14-1\n  install_script: pkg install -y gmake coreutils\n  script: |\n    MOREFLAGS=\"-Werror\" gmake -j all\n    gmake shortest\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.33984375,
          "content": "# Set the default behavior\n* text eol=lf\n\n# Explicitly declare source files\n*.c text eol=lf\n*.h text eol=lf\n\n# Denote files that should not be modified.\n*.odt binary\n*.png binary\n\n# Visual Studio\n*.sln text eol=crlf\n*.vcxproj* text eol=crlf\n*.vcproj* text eol=crlf\n*.suo binary\n*.rc text eol=crlf\n\n# Windows\n*.bat text eol=crlf\n*.cmd text eol=crlf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.552734375,
          "content": "# Object files\n*.o\n*.ko\n*.dSYM\n\n# Libraries\n*.lib\n*.a\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n/zstd\nzstdmt\n*.exe\n*.out\n*.app\n\n# Test artefacts\ntmp*\n*.zst\n*.zstd\ndictionary.\ndictionary\nNUL\ncmakebuild/\ninstall/\n\n# Build artefacts\ncontrib/linux-kernel/linux/\nprojects/\nbin/\n.buckd/\nbuck-out/\nbuild-*\n*.gcda\n\n# IDE\n.clang_complete\ncompile_flags.txt\n.clang-format\n\n# Other files\n.directory\n_codelite/\n_zstdbench/\n*.idea\n*.swp\n.DS_Store\ngoogletest/\n*.d\n*.vscode\n*.code-workspace\ncompile_commands.json\n.clangd\nperf.data\nperf.data.old\n"
        },
        {
          "name": "CHANGELOG",
          "type": "blob",
          "size": 48.384765625,
          "content": "V1.5.6 (Mar 2024)\napi: Promote `ZSTD_c_targetCBlockSize` to Stable API by @felixhandte\napi: new `ZSTD_d_maxBlockSize` experimental parameter, to reduce streaming decompression memory, by @terrelln\nperf: improve performance of param `ZSTD_c_targetCBlockSize`, by @Cyan4973\nperf: improved compression of arrays of integers at high compression, by @Cyan4973\nlib: reduce binary size with selective build-time exclusion, by @felixhandte\nlib: improved huffman speed on small data and linux kernel, by @terrelln\nlib: accept dictionaries with partial literal tables, by @terrelln\nlib: fix CCtx size estimation with external sequence producer, by @embg\nlib: fix corner case decoder behaviors, by @Cyan4973 and @aimuz\nlib: fix zdict prototype mismatch in static_only mode, by @ldv-alt\nlib: fix several bugs in magicless-format decoding, by @embg\ncli: add common compressed file types to `--exclude-compressed`` by @daniellerozenblit\ncli: fix mixing `-c` and `-o` commands with `--rm`, by @Cyan4973\ncli: fix erroneous exclusion of hidden files with `--output-dir-mirror` by @felixhandte\ncli: improved time accuracy on BSD, by @felixhandte\ncli: better errors on argument parsing, by @KapJI\ntests: better compatibility with older versions of `grep`, by @Cyan4973\ntests: lorem ipsum generator as default backup content, by @Cyan4973\nbuild: cmake improvements by @terrelln, @sighingnow, @gjasny, @JohanMabille, @Saverio976, @gruenich, @teo-tsirpanis\nbuild: bazel support, by @jondo2010\nbuild: fix cross-compiling for AArch64 with lld by @jcelerier\nbuild: fix Apple platform compatibility, by @nidhijaju\nbuild: fix Visual 2012 and lower compatibility, by @Cyan4973\nbuild: improve win32 support, by @DimitriPapadopoulos\nbuild: better C90 compliance for zlibWrapper, by @emaste\nport: make: fat binaries on macos, by @mredig\nport: ARM64EC compatibility for Windows, by @dunhor\nport: QNX support by @klausholstjacobsen\nport: MSYS2 and Cygwin makefile installation and test support, by @QBos07\nport: risc-v support validation in CI, by @Cyan4973\nport: sparc64 support validation in CI, by @Cyan4973\nport: AIX compatibility, by @likema\nport: HP-UX compatibility, by @likema\ndoc: Improved specification accuracy, by @elasota\nbug: Fix and deprecate ZSTD_generateSequences (#3981)\n\nv1.5.5 (Apr 2023)\nfix: fix rare corruption bug affecting the high compression mode, reported by @danlark1 (#3517, @terrelln)\nperf: improve mid-level compression speed (#3529, #3533, #3543, @yoniko and #3552, @terrelln)\nlib: deprecated bufferless block-level API (#3534) by @terrelln\ncli: mmap large dictionaries to save memory, by @daniellerozenblit\ncli: improve speed of --patch-from mode (~+50%) (#3545) by @daniellerozenblit\ncli: improve i/o speed (~+10%) when processing lots of small files (#3479) by @felixhandte\ncli: zstd no longer crashes when requested to write into write-protected directory (#3541) by @felixhandte\ncli: fix decompression into block device using -o, reported by @georgmu (#3583)\nbuild: fix zstd CLI compiled with lzma support but not zlib support (#3494) by @Hello71\nbuild: fix cmake does no longer require 3.18 as minimum version (#3510) by @kou\nbuild: fix MSVC+ClangCL linking issue (#3569) by @tru\nbuild: fix zstd-dll, version of zstd CLI that links to the dynamic library (#3496) by @yoniko\nbuild: fix MSVC warnings (#3495) by @embg\ndoc: updated zstd specification to clarify corner cases, by @Cyan4973\ndoc: document how to create fat binaries for macos (#3568) by @rickmark\nmisc: improve seekable format ingestion speed (~+100%) for very small chunk sizes (#3544) by @Cyan4973\nmisc: tests/fullbench can benchmark multiple files (#3516) by @dloidolt\n\nv1.5.4 (Feb 2023)\nperf: +20% faster huffman decompression for targets that can't compile x64 assembly (#3449, @terrelln)\nperf: up to +10% faster streaming compression at levels 1-2 (#3114, @embg)\nperf: +4-13% for levels 5-12 by optimizing function generation (#3295, @terrelln)\npref: +3-11% compression speed for `arm` target (#3199, #3164, #3145, #3141, #3138, @JunHe77 and #3139, #3160, @danlark1)\nperf: +5-30% faster dictionary compression at levels 1-4 (#3086, #3114, #3152, @embg)\nperf: +10-20% cold dict compression speed by prefetching CDict tables (#3177, @embg)\nperf: +1% faster compression by removing a branch in ZSTD_fast_noDict (#3129, @felixhandte)\nperf: Small compression ratio improvements in high compression mode (#2983, #3391, @Cyan4973 and #3285, #3302, @daniellerozenblit)\nperf: small speed improvement by better detecting `STATIC_BMI2` for `clang` (#3080, @TocarIP)\nperf: Improved streaming performance when `ZSTD_c_stableInBuffer` is set (#2974, @Cyan4973)\ncli: Asynchronous I/O for improved cli speed (#2975, #2985, #3021, #3022, @yoniko)\ncli: Change `zstdless` behavior to align with `zless` (#2909, @binhdvo)\ncli: Keep original file if `-c` or `--stdout` is given (#3052, @dirkmueller)\ncli: Keep original files when result is concatenated into a single output with `-o` (#3450, @Cyan4973)\ncli: Preserve Permissions and Ownership of regular files (#3432, @felixhandte)\ncli: Print zlib/lz4/lzma library versions with `-vv` (#3030, @terrelln)\ncli: Print checksum value for single frame files with `-lv`  (#3332, @Cyan4973)\ncli: Print `dictID` when present with `-lv` (#3184, @htnhan)\ncli: when `stderr` is *not* the console, disable status updates, but preserve final summary (#3458, @Cyan4973)\ncli: support `--best` and `--no-name` in `gzip` compatibility mode (#3059, @dirkmueller)\ncli: support for `posix` high resolution timer `clock_gettime()`, for improved benchmark accuracy (#3423, @Cyan4973)\ncli: improved help/usage (`-h`,  `-H`) formatting (#3094, @dirkmueller and #3385, @jonpalmisc)\ncli: Fix better handling of bogus numeric values (#3268, @ctkhanhly)\ncli: Fix input consists of multiple files _and_ `stdin` (#3222, @yoniko)\ncli: Fix tiny files passthrough (#3215, @cgbur)\ncli: Fix for `-r` on empty directory (#3027, @brailovich)\ncli: Fix empty string as argument for `--output-dir-*` (#3220, @embg)\ncli: Fix decompression memory usage reported by `-vv --long` (#3042, @u1f35c, and #3232, @zengyijing)\ncli: Fix infinite loop when empty input is passed to trainer (#3081, @terrelln)\ncli: Fix `--adapt` doesn't work when `--no-progress` is also set (#3354, @terrelln)\napi: Support for Block-Level Sequence Producer (#3333, @embg)\napi: Support for in-place decompression (#3432, @terrelln)\napi: New  `ZSTD_CCtx_setCParams()`  function, set all parameters defined in a  `ZSTD_compressionParameters`  structure (#3403, @Cyan4973)\napi: Streaming decompression detects incorrect header ID sooner (#3175, @Cyan4973)\napi: Window size resizing optimization for edge case (#3345, @daniellerozenblit)\napi: More accurate error codes for busy-loop scenarios (#3413, #3455, @Cyan4973)\napi: Fix limit overflow in `compressBound` and `decompressBound` (#3362, #3373, Cyan4973) reported by @nigeltao\napi: Deprecate several advanced experimental functions: streaming (#3408, @embg), copy (#3196, @mileshu)\nbug: Fix corruption that rarely occurs in 32-bit mode with wlog=25 (#3361, @terrelln)\nbug: Fix for block-splitter (#3033, @Cyan4973)\nbug: Fixes for Sequence Compression API (#3023, #3040, @Cyan4973)\nbug: Fix leaking thread handles on Windows (#3147, @animalize)\nbug: Fix timing issues with cmake/meson builds (#3166, #3167, #3170, @Cyan4973)\nbuild: Allow user to select legacy level for cmake (#3050, @shadchin)\nbuild: Enable legacy support by default in cmake (#3079, @niamster)\nbuild: Meson build script improvements (#3039, #3120, #3122, #3327, #3357, @eli-schwartz and #3276, @neheb)\nbuild: Add aarch64 to supported architectures for zstd_trace (#3054, @ooosssososos)\nbuild: support AIX architecture (#3219, @qiongsiwu)\nbuild: Fix `ZSTD_LIB_MINIFY` build macro, which now reduces static library size by half (#3366, @terrelln)\nbuild: Fix Windows issues with Multithreading translation layer (#3364, #3380, @yoniko) and ARM64 target (#3320, @cwoffenden)\nbuild: Fix `cmake` script (#3382, #3392, @terrelln and #3252 @Tachi107 and #3167 @Cyan4973)\ndoc: Updated man page, providing more details for `--train` mode (#3112, @Cyan4973)\ndoc: Add decompressor errata document (#3092, @terrelln)\nmisc: Enable Intel CET (#2992, #2994, @hjl-tools)\nmisc: Fix `contrib/` seekable format (#3058, @yhoogstrate and #3346, @daniellerozenblit)\nmisc: Improve speed of the one-file library generator (#3241, @wahern and #3005, @cwoffenden)\n\nv1.5.3 (dev version, unpublished)\n\nv1.5.2 (Jan, 2022)\nperf: Regain Minimal memset()-ing During Reuse of Compression Contexts (@Cyan4973, #2969)\nbuild: Build Zstd with `noexecstack` on All Architectures (@felixhandte, #2964)\ndoc: Clarify Licensing (@terrelln, #2981)\n\nv1.5.1 (Dec, 2021)\nperf: rebalanced compression levels, to better match the intended speed/level curve, by @senhuang42\nperf: faster huffman decoder, using x64 assembly, by @terrelln\nperf: slightly faster high speed modes (strategies fast & dfast), by @felixhandte\nperf: improved binary size and faster compilation times, by @terrelln\nperf: new row64 mode, used notably in level 12, by @senhuang42\nperf: faster mid-level compression speed in presence of highly repetitive patterns, by @senhuang42\nperf: minor compression ratio improvements for small data at high levels, by @cyan4973\nperf: reduced stack usage (mostly useful for Linux Kernel), by @terrelln\nperf: faster compression speed on incompressible data, by @bindhvo\nperf: on-demand reduced ZSTD_DCtx state size, using build macro ZSTD_DECODER_INTERNAL_BUFFER, at a small cost of performance, by @bindhvo\nbuild: allows hiding static symbols in the dynamic library, using build macro, by @skitt\nbuild: support for m68k (Motorola 68000's), by @cyan4973\nbuild: improved AIX support, by @Helflym\nbuild: improved meson unofficial build, by @eli-schwartz\ncli : custom memory limit when training dictionary (#2925), by @embg\ncli : report advanced parameters information when compressing in very verbose mode (`-vv`), by @Svetlitski-FB\n\nv1.5.0  (May 11, 2021)\napi: Various functions promoted from experimental to stable API: (#2579-2581, @senhuang42)\n  `ZSTD_defaultCLevel()`\n  `ZSTD_getDictID_fromCDict()`\napi: Several experimental functions have been deprecated and will emit a compiler warning (#2582, @senhuang42)\n  `ZSTD_compress_advanced()`\n  `ZSTD_compress_usingCDict_advanced()`\n  `ZSTD_compressBegin_advanced()`\n  `ZSTD_compressBegin_usingCDict_advanced()`\n  `ZSTD_initCStream_srcSize()`\n  `ZSTD_initCStream_usingDict()`\n  `ZSTD_initCStream_usingCDict()`\n  `ZSTD_initCStream_advanced()`\n  `ZSTD_initCStream_usingCDict_advanced()`\n  `ZSTD_resetCStream()`\napi: ZSTDMT_NBWORKERS_MAX reduced to 64 for 32-bit environments (@Cyan4973)\nperf: Significant speed improvements for middle compression levels (#2494, @senhuang42 @terrelln)\nperf: Block splitter to improve compression ratio, enabled by default for high compression levels (#2447, @senhuang42)\nperf: Decompression loop refactor, speed improvements on `clang` and for `--long` modes (#2614 #2630, @Cyan4973)\nperf: Reduced stack usage during compression and decompression entropy stage (#2522 #2524, @terrelln)\nbug: Improve setting permissions of created files (#2525, @felixhandte)\nbug: Fix large dictionary non-determinism (#2607, @terrelln)\nbug: Fix non-determinism test failures on Linux i686 (#2606, @terrelln)\nbug: Fix various dedicated dictionary search bugs (#2540 #2586, @senhuang42 @felixhandte)\nbug: Ensure `ZSTD_estimateCCtxSize*() `monotonically increases with compression level (#2538, @senhuang42)\nbug: Fix --patch-from mode parameter bound bug with small files (#2637, @occivink)\nbug: Fix UBSAN error in decompression (#2625, @terrelln)\nbug: Fix superblock compression divide by zero bug (#2592, @senhuang42)\nbug: Make the number of physical CPU cores detection more robust (#2517, @PaulBone)\ndoc: Improve `zdict.h` dictionary training API documentation (#2622, @terrelln)\ndoc: Note that public `ZSTD_free*()` functions accept NULL pointers (#2521, @animalize)\ndoc: Add style guide docs for open source contributors (#2626, @Cyan4973)\ntests: Better regression test coverage for different dictionary modes (#2559, @senhuang42)\ntests: Better test coverage of index reduction (#2603, @terrelln)\ntests: OSS-Fuzz coverage for seekable format (#2617, @senhuang42)\ntests: Test coverage for ZSTD threadpool API (#2604, @senhuang42)\nbuild: Dynamic library built multithreaded by default (#2584, @senhuang42)\nbuild: Move  `zstd_errors.h`  and  `zdict.h`  to  `lib/`  root (#2597, @terrelln)\nbuild: Allow `ZSTDMT_JOBSIZE_MIN` to be configured at compile-time, reduce default to 512KB (#2611, @Cyan4973)\nbuild: Single file library build script moved to `build/` directory (#2618, @felixhandte)\nbuild: `ZBUFF_*()` is no longer built by default (#2583, @senhuang42)\nbuild: Fixed Meson build (#2548, @SupervisedThinking @kloczek)\nbuild: Fix excessive compiler warnings with clang-cl and CMake (#2600, @nickhutchinson)\nbuild: Detect presence of `md5` on Darwin (#2609, @felixhandte)\nbuild: Avoid SIGBUS on armv6 (#2633, @bmwiedmann)\ncli: `--progress` flag added to always display progress bar (#2595, @senhuang42)\ncli: Allow reading from block devices with `--force` (#2613, @felixhandte)\ncli: Fix CLI filesize display bug (#2550, @Cyan4973)\ncli: Fix windows CLI `--filelist` end-of-line bug (#2620, @Cyan4973)\ncontrib: Various fixes for linux kernel patch (#2539, @terrelln)\ncontrib: Seekable format - Decompression hanging edge case fix (#2516, @senhuang42)\ncontrib: Seekable format - New seek table-only API  (#2113 #2518, @mdittmer @Cyan4973)\ncontrib: Seekable format - Fix seek table descriptor check when loading (#2534, @foxeng)\ncontrib: Seekable format - Decompression fix for large offsets, (#2594, @azat)\nmisc: Automatically published release tarballs available on Github (#2535, @felixhandte)\n\nv1.4.9  (Mar 1, 2021)\nbug: Use `umask()` to Constrain Created File Permissions (#2495, @felixhandte)\nbug: Make Simple Single-Pass Functions Ignore Advanced Parameters (#2498, @terrelln)\napi: Add (De)Compression Tracing Functionality (#2482, @terrelln)\napi: Support References to Multiple DDicts (#2446, @senhuang42)\napi: Add Function to Generate Skippable Frame (#2439, @senhuang42)\nperf: New Algorithms for the Long Distance Matcher (#2483, @mpu)\nperf: Performance Improvements for Long Distance Matcher (#2464, @mpu)\nperf: Don't Shrink Window Log when Streaming with a Dictionary (#2451, @terrelln)\ncli: Fix `--output-dir-mirror` rejection of `..` -containing paths (#2512, @felixhandte)\ncli: Allow Input From Console When `-f`/`--force` is Passed (#2466, @felixhandte)\ncli: Improve Help Message (#2500, @senhuang42)\ntests: Remove Flaky Tests (#2455, #2486, #2445, @Cyan4973)\ntests: Correctly Invoke md5 Utility on NetBSD (#2492, @niacat)\ntests: Avoid Using `stat -c` on NetBSD (#2513, @felixhandte)\nbuild: Zstd CLI Can Now be Linked to Dynamic `libzstd` (#2457, #2454 @Cyan4973)\nbuild: Hide and Avoid Using Static-Only Symbols (#2501, #2504, @skitt)\nbuild: CMake: Enable Only C for lib/ and programs/ Projects (#2498, @concatime)\nbuild: CMake: Use `configure_file()` to Create the `.pc` File (#2462, @lazka)\nbuild: Fix Fuzzer Compiler Detection & Update UBSAN Flags (#2503, @terrelln)\nbuild: Add Guards for `_LARGEFILE_SOURCE` and `_LARGEFILE64_SOURCE` (#2444, @indygreg)\nbuild: Improve `zlibwrapper` Makefile (#2437, @Cyan4973)\ncontrib: Add `recover_directory` Program (#2473, @terrelln)\ndoc: Change License Year to 2021 (#2452 & #2465, @terrelln & @senhuang42)\ndoc: Fix Typos (#2459, @ThomasWaldmann)\n\nv1.4.8  (Dec 18, 2020)\nhotfix: wrong alignment of an internal buffer\n\nv1.4.7  (Dec 16, 2020)\nperf: stronger --long mode at high compression levels, by @senhuang42\nperf: stronger --patch-from at high compression levels, thanks to --long improvements\nperf: faster dictionary compression at medium compression levels, by @felixhandte\nperf: small speed & memory usage improvements for ZSTD_compress2(), by @terrelln\nperf: improved fast compression speeds with Visual Studio, by @animalize\ncli : Set nb of threads with environment variable ZSTD_NBTHREADS, by @senhuang42\ncli : accept decompressing files with *.zstd suffix\ncli : provide a condensed summary by default when processing multiple files\ncli : fix : stdin input no longer confused as user prompt\ncli : improve accuracy of several error messages\napi : new sequence ingestion API, by @senhuang42\napi : shared thread pool: control total nb of threads used by multiple compression jobs, by @marxin\napi : new ZSTD_getDictID_fromCDict(), by @LuAPi\napi : zlibWrapper only uses public API, and is compatible with dynamic library, by @terrelln\napi : fix : multithreaded compression has predictable output even in special cases (see #2327) (issue not accessible from cli)\napi : fix : dictionary compression correctly respects dictionary compression level (see #2303) (issue not accessible from cli)\nbuild: fix cmake script when using path with spaces, by @terrelln\nbuild: improved compile-time detection of aarch64/neon platforms, by @bsdimp\nbuild: Fix building on AIX 5.1, by @likema\nbuild: compile paramgrill with cmake on Windows, requested by @mirh\ndoc : clarify repcode updates in format specification, by @felixhandte\n\nv1.4.6\nfix : Always return dstSize_tooSmall when that is the case\nfix : Fix ZSTD_initCStream_advanced() with static allocation and no dictionary\nperf: Improve small block decompression speed by 20%+, by @terrelln\nperf: Reduce compression stack usage by 1 KB, by @terrelln\nperf: Improve decompression speed by improving ZSTD_wildcopy, by @helloguo (#2252, #2256)\nperf: Improve histogram construction, by @cyan4973 (#2253)\ncli : Add --output-dir-mirror option, by @xxie24 (#2219)\ncli : Warn when (de)compressing multiple files into a single output, by @senhuang42 (#2279)\ncli : Improved progress bar and status summary when (de)compressing multiple files, by @senhuang42 (#2283)\ncli : Call stat less often, by @felixhandte (#2262)\ncli : Allow --patch-from XXX and --filelist XXX in addition to --patch-from=XXX and --filelist=XXX, by @cyan4973 (#2250)\ncli : Allow --patch-from to compress stdin with --stream-size, by @bimbashrestha (#2206)\napi : Do not install zbuff.h, since it has long been deprecated, by @cyan4973 (#2166).\napi : Fix ZSTD_CCtx_setParameter() with ZSTD_c_compressionLevel to make 0 mean default level, by @i-do-cpp (#2291)\napi : Rename ZSTDMT_NBTHREADS_MAX to ZSTDMT_NBWORKERS_MAX, by @marxin (#2228).\nbuild: Install pkg-config file with CMake and MinGW, by @tonytheodore (#2183)\nbuild: Install DLL with CMake on Windows, by @BioDataAnalysis (#2221)\nbuild: Fix DLL install location with CMake, by @xantares and @bimbashrestha (#2186)\nbuild: Add ZSTD_NO_UNUSED_FUNCTIONS macro to hide unused functions\nbuild: Add ZSTD_NO_INTRINSICS macro to avoid explicit intrinsics\nbuild: Add STATIC_BMI2 macro for compile time detection of BMI2 on MSVC, by @Niadb (#2258)\nbuild: Fix -Wcomma warnings, by @cwoffenden\nbuild: Remove distutils requirement for meson build, by @neheb (#2197)\nbuild: Fix cli compilation with uclibc\nbuild: Fix cli compilation without st_mtime, by @ffontaine (#2246)\nbuild: Fix shadowing warnings in library\nbuild: Fix single file library compilation with Enscripten, by @yoshihitoh (#2227)\nmisc: Improve single file library and include dictBuilder, by @cwoffenden\nmisc: Allow compression dictionaries with missing symbols\nmisc: Add freestanding translation script in contrib/freestanding_lib\nmisc: Collect all of zstd's libc dependencies into zstd_deps.h\ndoc : Add ZSTD_versionString() to manual, by @animalize\ndoc : Fix documentation for ZSTD_CCtxParams_setParameter(), by @felixhandte (#2270)\n\nv1.4.5  (May 22, 2020)\nfix : Compression ratio regression on huge files (> 3 GB) using high levels (--ultra) and multithreading, by @terrelln\nperf: Improved decompression speed: x64 : +10% (clang) / +5% (gcc); ARM : from +15% to +50%, depending on SoC, by @terrelln\nperf: Automatically downsizes ZSTD_DCtx when too large for too long (#2069, by @bimbashreshta)\nperf: Improved fast compression speed on aarch64 (#2040, ~+3%, by @caoyzh)\nperf: Small level 1 compression speed gains (depending on compiler)\ncli : New --patch-from command, create and apply patches from files, by @bimbashreshta\ncli : New --filelist= : Provide a list of files to operate upon from a file\ncli : -b -d command can now benchmark decompression on multiple files\ncli : New --no-content-size command\ncli : New --show-default-cparams information command\napi : ZDICT_finalizeDictionary() is promoted to stable (#2111)\napi : new experimental parameter ZSTD_d_stableOutBuffer (#2094)\nbuild: Generate a single-file libzstd library (#2065, by @cwoffenden)\nbuild: Relative includes no longer require -I compiler flags for zstd lib subdirs (#2103, by @felixhandte)\nbuild: zstd now compiles cleanly under -pedantic (#2099)\nbuild: zstd now compiles with make-4.3\nbuild: Support mingw cross-compilation from Linux, by @Ericson2314\nbuild: Meson multi-thread build fix on windows\nbuild: Some misc icc fixes backed by new ci test on travis\nmisc: bitflip analyzer tool, by @felixhandte\nmisc: Extend largeNbDicts benchmark to compression\nmisc: Edit-distance match finder in contrib/\ndoc : Improved beginner CONTRIBUTING.md docs\ndoc : New issue templates for zstd\n\nv1.4.4  (Nov 6, 2019)\nperf: Improved decompression speed, by > 10%, by @terrelln\nperf: Better compression speed when re-using a context, by @felixhandte\nperf: Fix compression ratio when compressing large files with small dictionary, by @senhuang42\nperf: zstd reference encoder can generate RLE blocks, by @bimbashrestha\nperf: minor generic speed optimization, by @davidbolvansky\napi: new ability to extract sequences from the parser for analysis, by @bimbashrestha\napi: fixed decoding of magic-less frames, by @terrelln\napi: fixed ZSTD_initCStream_advanced() performance with fast modes, reported by @QrczakMK\ncli: Named pipes support, by @bimbashrestha\ncli: short tar's extension support, by @stokito\ncli: command --output-dir-flat= , generates target files into requested directory, by @senhuang42\ncli: commands --stream-size=# and --size-hint=#, by @nmagerko\ncli: command --exclude-compressed, by @shashank0791\ncli: faster `-t` test mode\ncli: improved some error messages, by @vangyzen\ncli: fix command `-D dictionary` on Windows, reported by @artyompetrov\ncli: fix rare deadlock condition within dictionary builder, by @terrelln\nbuild: single-file decoder with emscripten compilation script, by @cwoffenden\nbuild: fixed zlibWrapper compilation on Visual Studio, reported by @bluenlive\nbuild: fixed deprecation warning for certain gcc version, reported by @jasonma163\nbuild: fix compilation on old gcc versions, by @cemeyer\nbuild: improved installation directories for cmake script, by Dmitri Shubin\npack: modified pkgconfig, for better integration into openwrt, requested by @neheb\nmisc: Improved documentation : ZSTD_CLEVEL, DYNAMIC_BMI2, ZSTD_CDict, function deprecation, zstd format\nmisc: fixed educational decoder : accept larger literals section, and removed UNALIGNED() macro\n\nv1.4.3  (Aug 20, 2019)\nbug: Fix Dictionary Compression Ratio Regression by @cyan4973 (#1709)\nbug: Fix Buffer Overflow in legacy v0.3 decompression by @felixhandte (#1722)\nbuild: Add support for IAR C/C++ Compiler for Arm by @joseph0918 (#1705)\n\nv1.4.2  (Jul 26, 2019)\nbug: Fix bug in zstd-0.5 decoder by @terrelln (#1696)\nbug: Fix seekable decompression in-memory API by @iburinoc (#1695)\nmisc: Validate blocks are smaller than size limit by @vivekmg (#1685)\nmisc: Restructure source files by @ephiepark (#1679)\n\nv1.4.1  (Jul 20, 2019)\nbug: Fix data corruption in niche use cases by @terrelln (#1659)\nbug: Fuzz legacy modes, fix uncovered bugs by @terrelln (#1593, #1594, #1595)\nbug: Fix out of bounds read by @terrelln (#1590)\nperf: Improve decode speed by ~7% @mgrice (#1668)\nperf: Slightly improved compression ratio of level 3 and 4 (ZSTD_dfast) by @cyan4973 (#1681)\nperf: Slightly faster compression speed when re-using a context by @cyan4973 (#1658)\nperf: Improve compression ratio for small windowLog by @cyan4973 (#1624)\nperf: Faster compression speed in high compression mode for repetitive data by @terrelln (#1635)\napi: Add parameter to generate smaller dictionaries by @tyler-tran (#1656)\ncli: Recognize symlinks when built in C99 mode by @felixhandte (#1640)\ncli: Expose cpu load indicator for each file on -vv mode by @ephiepark (#1631)\ncli: Restrict read permissions on destination files by @chungy (#1644)\ncli: zstdgrep: handle -f flag by @felixhandte (#1618)\ncli: zstdcat: follow symlinks by @vejnar (#1604)\ndoc: Remove extra size limit on compressed blocks by @felixhandte (#1689)\ndoc: Fix typo by @yk-tanigawa (#1633)\ndoc: Improve documentation on streaming buffer sizes by @cyan4973 (#1629)\nbuild: CMake: support building with LZ4 @leeyoung624 (#1626)\nbuild: CMake: install zstdless and zstdgrep by @leeyoung624 (#1647)\nbuild: CMake: respect existing uninstall target by @j301scott (#1619)\nbuild: Make: skip multithread tests when built without support by @michaelforney (#1620)\nbuild: Make: Fix examples/ test target by @sjnam (#1603)\nbuild: Meson: rename options out of deprecated namespace by @lzutao (#1665)\nbuild: Meson: fix build by @lzutao (#1602)\nbuild: Visual Studio: don't export symbols in static lib by @scharan (#1650)\nbuild: Visual Studio: fix linking by @absotively (#1639)\nbuild: Fix MinGW-W64 build by @myzhang1029 (#1600)\nmisc: Expand decodecorpus coverage by @ephiepark (#1664)\n\nv1.4.0  (Apr 17, 2019)\nperf: Improve level 1 compression speed in most scenarios by 6% by @gbtucker and @terrelln\napi: Move the advanced API, including all functions in the staging section, to the stable section\napi: Make ZSTD_e_flush and ZSTD_e_end block for maximum forward progress\napi: Rename ZSTD_CCtxParam_getParameter to ZSTD_CCtxParams_getParameter\napi: Rename ZSTD_CCtxParam_setParameter to ZSTD_CCtxParams_setParameter\napi: Don't export ZSTDMT functions from the shared library by default\napi: Require ZSTD_MULTITHREAD to be defined to use ZSTDMT\napi: Add ZSTD_decompressBound() to provide an upper bound on decompressed size by @shakeelrao\napi: Fix ZSTD_decompressDCtx() corner cases with a dictionary\napi: Move ZSTD_getDictID_*() functions to the stable section\napi: Add ZSTD_c_literalCompressionMode flag to enable or disable literal compression by @terrelln\napi: Allow compression parameters to be set when a dictionary is used\napi: Allow setting parameters before or after ZSTD_CCtx_loadDictionary() is called\napi: Fix ZSTD_estimateCStreamSize_usingCCtxParams()\napi: Setting ZSTD_d_maxWindowLog to 0 means use the default\ncli: Ensure that a dictionary is not used to compress itself by @shakeelrao\ncli: Add --[no-]compress-literals flag to enable or disable literal compression\ndoc: Update the examples to use the advanced API\ndoc: Explain how to transition from old streaming functions to the advanced API in the header\nbuild: Improve the Windows release packages\nbuild: Improve CMake build by @hjmjohnson\nbuild: Build fixes for FreeBSD by @lwhsu\nbuild: Remove redundant warnings by @thatsafunnyname\nbuild: Fix tests on OpenBSD by @bket\nbuild: Extend fuzzer build system to work with the new clang engine\nbuild: CMake now creates the libzstd.so.1 symlink\nbuild: Improve Menson build by @lzutao\nmisc: Fix symbolic link detection on FreeBSD\nmisc: Use physical core count for -T0 on FreeBSD by @cemeyer\nmisc: Fix zstd --list on truncated files by @kostmo\nmisc: Improve logging in debug mode by @felixhandte\nmisc: Add CirrusCI tests by @lwhsu\nmisc: Optimize dictionary memory usage in corner cases\nmisc: Improve the dictionary builder on small or homogeneous data\nmisc: Fix spelling across the repo by @jsoref\n\nv1.3.8  (Dec 28, 2018)\nperf: better decompression speed on large files (+7%) and cold dictionaries (+15%)\nperf: slightly better compression ratio at high compression modes\napi : finalized advanced API, last stage before \"stable\" status\napi : new --rsyncable mode, by @terrelln\napi : support decompression of empty frames into NULL (used to be an error) (#1385)\nbuild: new set of macros to build a minimal size decoder, by @felixhandte\nbuild: fix compilation on MIPS32, reported by @clbr (#1441)\nbuild: fix compilation with multiple -arch flags, by @ryandesign\nbuild: highly upgraded meson build, by @lzutao\nbuild: improved buck support, by @obelisk\nbuild: fix cmake script : can create debug build, by @pitrou\nbuild: Makefile : grep works on both colored consoles and systems without color support\nbuild: fixed zstd-pgo, by @bmwiedemann\ncli : support ZSTD_CLEVEL environment variable, by @yijinfb (#1423)\ncli : --no-progress flag, preserving final summary (#1371), by @terrelln\ncli : ensure destination file is not source file (#1422)\ncli : clearer error messages, especially when input file not present\ndoc : clarified zstd_compression_format.md, by @ulikunitz\nmisc: fixed zstdgrep, returns 1 on failure, by @lzutao\nmisc: NEWS renamed as CHANGELOG, in accordance with fboss\n\nv1.3.7  (Oct 20, 2018)\nperf: slightly better decompression speed on clang (depending on hardware target)\nfix : performance of dictionary compression for small input < 4 KB at levels 9 and 10\nbuild: no longer build backtrace by default in release mode; restrict further automatic mode\nbuild: control backtrace support through build macro BACKTRACE\nmisc: added man pages for zstdless and zstdgrep, by @samrussell\n\nv1.3.6  (Oct 6, 2018)\nperf: much faster dictionary builder, by @jenniferliu\nperf: faster dictionary compression on small data when using multiple contexts, by @felixhandte\nperf: faster dictionary decompression when using a very large number of dictionaries simultaneously\ncli : fix : does no longer overwrite destination when source does not exist (#1082)\ncli : new command --adapt, for automatic compression level adaptation\napi : fix : block api can be streamed with > 4 GB, reported by @catid\napi : reduced ZSTD_DDict size by 2 KB\napi : minimum negative compression level is defined, and can be queried using ZSTD_minCLevel().\nbuild: support Haiku target, by @korli\nbuild: Read Legacy format is limited to v0.5+ by default. Can be changed at compile time with macro ZSTD_LEGACY_SUPPORT.\ndoc : zstd_compression_format.md updated to match wording in IETF RFC 8478\nmisc: tests/paramgrill, a parameter optimizer, by @GeorgeLu97\n\nv1.3.5  (Jun 29, 2018)\nperf: much faster dictionary compression, by @felixhandte\nperf: small quality improvement for dictionary generation, by @terrelln\nperf: slightly improved high compression levels (notably level 19)\nmem : automatic memory release for long duration contexts\ncli : fix : overlapLog can be manually set\ncli : fix : decoding invalid lz4 frames\napi : fix : performance degradation for dictionary compression when using advanced API, by @terrelln\napi : change : clarify ZSTD_CCtx_reset() vs ZSTD_CCtx_resetParameters(), by @terrelln\nbuild: select custom libzstd scope through control macros, by @GeorgeLu97\nbuild: OpenBSD patch, by @bket\nbuild: make and make all are compatible with -j\ndoc : clarify zstd_compression_format.md, updated for IETF RFC process\nmisc: pzstd compatible with reproducible compilation, by @lamby\n\nv1.3.4  (Mar 27, 2018)\nperf: faster speed (especially decoding speed) on recent cpus (haswell+)\nperf: much better performance associating --long with multi-threading, by @terrelln\nperf: better compression at levels 13-15\ncli : asynchronous compression by default, for faster experience (use --single-thread for former behavior)\ncli : smoother status report in multi-threading mode\ncli : added command --fast=#, for faster compression modes\ncli : fix crash when not overwriting existing files, by Pádraig Brady (@pixelb)\napi : `nbThreads` becomes `nbWorkers` : 1 triggers asynchronous mode\napi : compression levels can be negative, for even more speed\napi : ZSTD_getFrameProgression() : get precise progress status of ZSTDMT anytime\napi : ZSTDMT can accept new compression parameters during compression\napi : implemented all advanced dictionary decompression prototypes\nbuild: improved meson recipe, by Shawn Landden (@shawnl)\nbuild: VS2017 scripts, by @HaydnTrigg\nmisc: all /contrib projects fixed\nmisc: added /contrib/docker script by @gyscos\n\nv1.3.3  (Dec 21, 2017)\nperf: faster zstd_opt strategy (levels 16-19)\nfix : bug #944 : multithreading with shared dictionary and large data, reported by @gsliepen\ncli : fix : content size written in header by default\ncli : fix : improved LZ4 format support, by @felixhandte\ncli : new : hidden command `-S`, to benchmark multiple files while generating one result per file\napi : fix : support large skippable frames, by @terrelln\napi : fix : streaming interface was adding a useless 3-bytes null block to small frames\napi : change : when setting `pledgedSrcSize`, use `ZSTD_CONTENTSIZE_UNKNOWN` macro value to mean \"unknown\"\nbuild: fix : compilation under rhel6 and centos6, reported by @pixelb\nbuild: added `check` target\n\nv1.3.2  (Oct 10, 2017)\nnew : long range mode, using --long command, by Stella Lau (@stellamplau)\nnew : ability to generate and decode magicless frames (#591)\nchanged : maximum nb of threads reduced to 200, to avoid address space exhaustion in 32-bits mode\nfix : multi-threading compression works with custom allocators\nfix : ZSTD_sizeof_CStream() was over-evaluating memory usage\nfix : a rare compression bug when compression generates very large distances and bunch of other conditions (only possible at --ultra -22)\nfix : 32-bits build can now decode large offsets (levels 21+)\ncli : added LZ4 frame support by default, by Felix Handte (@felixhandte)\ncli : improved --list output\ncli : new : can split input file for dictionary training, using command -B#\ncli : new : clean operation artefact on Ctrl-C interruption\ncli : fix : do not change /dev/null permissions when using command -t with root access, reported by @mike155 (#851)\ncli : fix : write file size in header in multiple-files mode\napi : added macro ZSTD_COMPRESSBOUND() for static allocation\napi : experimental : new advanced decompression API\napi : fix : sizeof_CCtx() used to over-estimate\nbuild: fix : no-multithread variant compiles without pool.c dependency, reported by Mitchell Blank Jr (@mitchblank) (#819)\nbuild: better compatibility with reproducible builds, by Bernhard M. Wiedemann (@bmwiedemann) (#818)\nexample : added streaming_memory_usage\nlicense : changed /examples license to BSD + GPLv2\nlicense : fix a few header files to reflect new license (#825)\n\nv1.3.1  (Aug 21, 2017)\nNew license : BSD + GPLv2\nperf: substantially decreased memory usage in Multi-threading mode, thanks to reports by Tino Reichardt (@mcmilk)\nperf: Multi-threading supports up to 256 threads. Cap at 256 when more are requested (#760)\ncli : improved and fixed --list command, by @ib (#772)\ncli : command -vV to list supported formats, by @ib (#771)\nbuild : fixed binary variants, reported by @svenha (#788)\nbuild : fix Visual compilation for non x86/x64 targets, reported by Greg Slazinski (@GregSlazinski) (#718)\nAPI exp : breaking change : ZSTD_getframeHeader() provides more information\nAPI exp : breaking change : pinned down values of error codes\ndoc : fixed huffman example, by Ulrich Kunitz (@ulikunitz)\nnew : contrib/adaptive-compression, I/O driven compression strength, by Paul Cruz (@paulcruz74)\nnew : contrib/long_distance_matching, statistics by Stella Lau (@stellamplau)\nupdated : contrib/linux-kernel, by Nick Terrell (@terrelln)\n\nv1.3.0  (Jul 6, 2017)\ncli : new : `--list` command, by Paul Cruz\ncli : changed : xz/lzma support enabled by default\ncli : changed : `-t *` continue processing list after a decompression error\nAPI : added : ZSTD_versionString()\nAPI : promoted to stable status : ZSTD_getFrameContentSize(), by Sean Purcell\nAPI exp : new advanced API : ZSTD_compress_generic(), ZSTD_CCtx_setParameter()\nAPI exp : new : API for static or external allocation : ZSTD_initStatic?Ctx()\nAPI exp : added : ZSTD_decompressBegin_usingDDict(), requested by Guy Riddle (#700)\nAPI exp : clarified memory estimation / measurement functions.\nAPI exp : changed : strongest strategy renamed ZSTD_btultra, fastest strategy ZSTD_fast set to 1\ntools : decodecorpus can generate random dictionary-compressed samples, by Paul Cruz\nnew : contrib/seekable_format, demo and API, by Sean Purcell\nchanged : contrib/linux-kernel, updated version and license, by Nick Terrell\n\nv1.2.0  (May 5, 2017)\ncli : changed : Multithreading enabled by default (use target zstd-nomt or HAVE_THREAD=0 to disable)\ncli : new : command -T0 means \"detect and use nb of cores\", by Sean Purcell\ncli : new : zstdmt symlink hardwired to `zstd -T0`\ncli : new : command --threads=# (#671)\ncli : changed : cover dictionary builder by default, for improved quality, by Nick Terrell\ncli : new : commands --train-cover and --train-legacy, to select dictionary algorithm and parameters\ncli : experimental targets `zstd4` and `xzstd4`, with support for lz4 format, by Sean Purcell\ncli : fix : does not output compressed data on console\ncli : fix : ignore symbolic links unless --force specified,\nAPI : breaking change : ZSTD_createCDict_advanced(), only use compressionParameters as argument\nAPI : added : prototypes ZSTD_*_usingCDict_advanced(), for direct control over frameParameters.\nAPI : improved: ZSTDMT_compressCCtx() reduced memory usage\nAPI : fix : ZSTDMT_compressCCtx() now provides srcSize in header (#634)\nAPI : fix : src size stored in frame header is controlled at end of frame\nAPI : fix : enforced consistent rules for pledgedSrcSize==0 (#641)\nAPI : fix : error code \"GENERIC\" replaced by \"dstSizeTooSmall\" when appropriate\nbuild: improved cmake script, by @Majlen\nbuild: enabled Multi-threading support for *BSD, by Baptiste Daroussin\ntools: updated Paramgrill. Command -O# provides best parameters for sample and speed target.\nnew : contrib/linux-kernel version, by Nick Terrell\n\nv1.1.4  (Mar 18, 2017)\ncli : new : can compress in *.gz format, using --format=gzip command, by Przemyslaw Skibinski\ncli : new : advanced benchmark command --priority=rt\ncli : fix : write on sparse-enabled file systems in 32-bits mode, by @ds77\ncli : fix : --rm remains silent when input is stdin\ncli : experimental : xzstd, with support for xz/lzma decoding, by Przemyslaw Skibinski\nspeed : improved decompression speed in streaming mode for single shot scenarios (+5%)\nmemory: DDict (decompression dictionary) memory usage down from 150 KB to 20 KB\narch: 32-bits variant able to generate and decode very long matches (>32 MB), by Sean Purcell\nAPI : new : ZSTD_findFrameCompressedSize(), ZSTD_getFrameContentSize(), ZSTD_findDecompressedSize()\nAPI : changed : dropped support of legacy versions <= v0.3 (can be changed by modifying ZSTD_LEGACY_SUPPORT value)\nbuild : new: meson build system in contrib/meson, by Dima Krasner\nbuild : improved cmake script, by @Majlen\nbuild : added -Wformat-security flag, as recommended by Padraig Brady\ndoc : new : educational decoder, by Sean Purcell\n\nv1.1.3  (Feb 7, 2017)\ncli : zstd can decompress .gz files (can be disabled with `make zstd-nogz` or `make HAVE_ZLIB=0`)\ncli : new : experimental target `make zstdmt`, with multi-threading support\ncli : new : improved dictionary builder \"cover\" (experimental), by Nick Terrell, based on prior work by Giuseppe Ottaviano.\ncli : new : advanced commands for detailed parameters, by Przemyslaw Skibinski\ncli : fix zstdless on Mac OS-X, by Andrew Janke\ncli : fix #232 \"compress non-files\"\ndictBuilder : improved dictionary generation quality, thanks to Nick Terrell\nAPI : new : lib/compress/ZSTDMT_compress.h multithreading API (experimental)\nAPI : new : ZSTD_create?Dict_byReference(), requested by Bartosz Taudul\nAPI : new : ZDICT_finalizeDictionary()\nAPI : fix : ZSTD_initCStream_usingCDict() properly writes dictID into frame header, by Gregory Szorc (#511)\nAPI : fix : all symbols properly exposed in libzstd, by Nick Terrell\nbuild : support for Solaris target, by Przemyslaw Skibinski\ndoc : clarified specification, by Sean Purcell\n\nv1.1.2  (Dec 15, 2016)\nAPI : streaming : decompression : changed : automatic implicit reset when chain-decoding new frames without init\nAPI : experimental : added : dictID retrieval functions, and ZSTD_initCStream_srcSize()\nAPI : zbuff : changed : prototypes now generate deprecation warnings\nlib : improved : faster decompression speed at ultra compression settings and 32-bits mode\nlib : changed : only public ZSTD_ symbols are now exposed\nlib : changed : reduced usage  of stack memory\nlib : fixed : several corner case bugs, by Nick Terrell\ncli : new : gzstd, experimental version able to decode .gz files, by Przemyslaw Skibinski\ncli : new : preserve file attributes\ncli : new : added zstdless and zstdgrep tools\ncli : fixed : status displays total amount decoded, even for file consisting of multiple frames (like pzstd)\ncli : fixed : zstdcat\nzlib_wrapper : added support for gz* functions, by Przemyslaw Skibinski\ninstall : better compatibility with FreeBSD, by Dimitry Andric\nsource tree : changed : zbuff source files moved to lib/deprecated\n\nv1.1.1  (Nov 2, 2016)\nNew : command -M#, --memory=, --memlimit=, --memlimit-decompress= to limit allowed memory consumption\nNew : doc/zstd_manual.html, by Przemyslaw Skibinski\nImproved : slightly better compression ratio at --ultra levels (>= 20)\nImproved : better memory usage when using streaming compression API, thanks to @Rogier-5 report\nAdded : API : ZSTD_initCStream_usingCDict(), ZSTD_initDStream_usingDDict() (experimental section)\nAdded : example/multiple_streaming_compression.c\nChanged : zstd_errors.h is now installed within /include (and replaces errors_public.h)\nUpdated man page\nFixed : zstd-small, zstd-compress and zstd-decompress compilation targets\n\nv1.1.0  (Sep 28, 2016)\nNew : contrib/pzstd, parallel version of zstd, by Nick Terrell\nadded : NetBSD install target (#338)\nImproved : speed for batches of small files\nImproved : speed of zlib wrapper, by Przemyslaw Skibinski\nChanged : libzstd on Windows supports legacy formats, by Christophe Chevalier\nFixed : CLI -d output to stdout by default when input is stdin (#322)\nFixed : CLI correctly detects console on Mac OS-X\nFixed : CLI supports recursive mode `-r` on Mac OS-X\nFixed : Legacy decoders use unified error codes, reported by benrg (#341), fixed by Przemyslaw Skibinski\nFixed : compatibility with OpenBSD, reported by Juan Francisco Cantero Hurtado (#319)\nFixed : compatibility with Hurd, by Przemyslaw Skibinski (#365)\nFixed : zstd-pgo, reported by octoploid (#329)\n\nv1.0.0  (Sep 1, 2016)\nChange Licensing, all project is now BSD, Copyright Facebook\nSmall decompression speed improvement\nAPI : Streaming API supports legacy format\nAPI : ZDICT_getDictID(), ZSTD_sizeof_{CCtx, DCtx, CStream, DStream}(), ZSTD_setDStreamParameter()\nCLI supports legacy formats v0.4+\nFixed : compression fails on certain huge files, reported by Jesse McGrew\nEnhanced documentation, by Przemyslaw Skibinski\n\nv0.8.1  (Aug 18, 2016)\nNew streaming API\nChanged : --ultra now enables levels beyond 19\nChanged : -i# now selects benchmark time in second\nFixed : ZSTD_compress* can now compress > 4 GB in a single pass, reported by Nick Terrell\nFixed : speed regression on specific patterns (#272)\nFixed : support for Z_SYNC_FLUSH, by Dmitry Krot (#291)\nFixed : ICC compilation, by Przemyslaw Skibinski\n\nv0.8.0  (Aug 2, 2016)\nImproved : better speed on clang and gcc -O2, thanks to Eric Biggers\nNew : Build on FreeBSD and DragonFly, thanks to JrMarino\nChanged : modified API : ZSTD_compressEnd()\nFixed : legacy mode with ZSTD_HEAPMODE=0, by Christopher Bergqvist\nFixed : premature end of frame when zero-sized raw block, reported by Eric Biggers\nFixed : large dictionaries (> 384 KB), reported by Ilona Papava\nFixed : checksum correctly checked in single-pass mode\nFixed : combined --test amd --rm, reported by Andreas M. Nilsson\nModified : minor compression level adaptations\nUpdated : compression format specification to v0.2.0\nchanged : zstd.h moved to /lib directory\n\nv0.7.5  (Aug 1, 2016)\nTransition version, supporting decoding of v0.8.x\n\nv0.7.4  (Jul 17, 2016)\nAdded : homebrew for Mac, by Daniel Cade\nAdded : more examples\nFixed : segfault when using small dictionaries, reported by Felix Handte\nModified : default compression level for CLI is now 3\nUpdated : specification, to v0.1.1\n\nv0.7.3  (Jul 9, 2016)\nNew : compression format specification\nNew : `--` separator, stating that all following arguments are file names. Suggested by Chip Turner.\nNew : `ZSTD_getDecompressedSize()`\nNew : OpenBSD target, by Juan Francisco Cantero Hurtado\nNew : `examples` directory\nfixed : dictBuilder using HC levels, reported by Bartosz Taudul\nfixed : legacy support from ZSTD_decompress_usingDDict(), reported by Felix Handte\nfixed : multi-blocks decoding with intermediate uncompressed blocks, reported by Greg Slazinski\nmodified : removed \"mem.h\" and \"error_public.h\" dependencies from \"zstd.h\" (experimental section)\nmodified : legacy functions no longer need magic number\n\nv0.7.2  (Jul 4, 2016)\nfixed : ZSTD_decompressBlock() using multiple consecutive blocks. Reported by Greg Slazinski.\nfixed : potential segfault on very large files (many gigabytes). Reported by Chip Turner.\nfixed : CLI displays system error message when destination file cannot be created (#231). Reported by Chip Turner.\n\nv0.7.1  (Jun 23, 2016)\nfixed : ZBUFF_compressEnd() called multiple times with too small `dst` buffer, reported by Christophe Chevalier\nfixed : dictBuilder fails if first sample is too small, reported by Руслан Ковалёв\nfixed : corruption issue, reported by cj\nmodified : checksum enabled by default in command line mode\n\nv0.7.0  (Jun 17, 2016)\nNew : Support for directory compression, using `-r`, thanks to Przemyslaw Skibinski\nNew : Command `--rm`, to remove source file after successful de/compression\nNew : Visual build scripts, by Christophe Chevalier\nNew : Support for Sparse File-systems (do not use space for zero-filled sectors)\nNew : Frame checksum support\nNew : Support pass-through mode (when using `-df`)\nAPI : more efficient Dictionary API : `ZSTD_compress_usingCDict()`, `ZSTD_decompress_usingDDict()`\nAPI : create dictionary files from custom content, by Giuseppe Ottaviano\nAPI : support for custom malloc/free functions\nNew : controllable Dictionary ID\nNew : Support for skippable frames\n\nv0.6.1  (May 13, 2016)\nNew : zlib wrapper API, thanks to Przemyslaw Skibinski\nNew : Ability to compile compressor / decompressor separately\nChanged : new lib directory structure\nFixed : Legacy codec v0.5 compatible with dictionary decompression\nFixed : Decoder corruption error (#173)\nFixed : null-string roundtrip (#176)\nNew : benchmark mode can select directory as input\nExperimental : midipix support, VMS support\n\nv0.6.0  (Apr 13, 2016)\nStronger high compression modes, thanks to Przemyslaw Skibinski\nAPI : ZSTD_getFrameParams() provides size of decompressed content\nNew : highest compression modes require `--ultra` command to fully unleash their capacity\nFixed : zstd cli return error code > 0 and removes dst file artifact when decompression fails, thanks to Chip Turner\n\nv0.5.1  (Feb 18, 2016)\nNew : Optimal parsing => Very high compression modes, thanks to Przemyslaw Skibinski\nChanged : Dictionary builder integrated into libzstd and zstd cli\nChanged (!) : zstd cli now uses \"multiple input files\" as default mode. See `zstd -h`.\nFix : high compression modes for big-endian platforms\nNew : zstd cli : `-t` | `--test` command\n\nv0.5.0  (Feb 5, 2016)\nNew : dictionary builder utility\nChanged : streaming & dictionary API\nImproved : better compression of small data\n\nv0.4.7  (Jan 22, 2016)\nImproved : small compression speed improvement in HC mode\nChanged : `zstd_decompress.c` has ZSTD_LEGACY_SUPPORT to 0 by default\nfix : bt search bug\n\nv0.4.6  (Jan 13, 2016)\nfix : fast compression mode on Windows\nNew : cmake configuration file, thanks to Artyom Dymchenko\nImproved : high compression mode on repetitive data\nNew : block-level API\nNew : ZSTD_duplicateCCtx()\n\nv0.4.5  (Dec 18, 2015)\nnew : -m/--multiple : compress/decompress multiple files\n\nv0.4.4  (Dec 14, 2015)\nFixed : high compression modes for Windows 32 bits\nnew : external dictionary API extended to buffered mode and accessible through command line\nnew : windows DLL project, thanks to Christophe Chevalier\n\nv0.4.3  (Dec 7, 2015)\nnew : external dictionary API\nnew : zstd-frugal\n\nv0.4.2  (Dec 2, 2015)\nGeneric minor improvements for small blocks\nFixed : big-endian compatibility, by Peter Harris (#85)\n\nv0.4.1  (Dec 1, 2015)\nFixed : ZSTD_LEGACY_SUPPORT=0 build mode (reported by Luben)\nremoved `zstd.c`\n\nv0.4.0  (Nov 29, 2015)\nCommand line utility compatible with high compression levels\nRemoved zstdhc => merged into zstd\nAdded : ZBUFF API (see zstd_buffered.h)\nRolling buffer support\n\nv0.3.6  (Nov 10, 2015)\nsmall blocks params\n\nv0.3.5  (Nov 9, 2015)\nminor generic compression improvements\n\nv0.3.4  (Nov 6, 2015)\nFaster fast cLevels\n\nv0.3.3  (Nov 5, 2015)\nSmall compression ratio improvement\n\nv0.3.2  (Nov 2, 2015)\nFixed Visual Studio\n\nv0.3.1  (Nov 2, 2015)\nSmall compression ratio improvement\n\nv0.3  (Oct 30, 2015)\nHC mode : compression levels 2-26\n\nv0.2.2  (Oct 28, 2015)\nFix : Visual Studio 2013 & 2015 release compilation, by Christophe Chevalier\n\nv0.2.1  (Oct 24, 2015)\nFix : Read errors, advanced fuzzer tests, by Hanno Böck\n\nv0.2.0  (Oct 22, 2015)\n**Breaking format change**\nFaster decompression speed\nCan still decode v0.1 format\n\nv0.1.3  (Oct 15, 2015)\nfix uninitialization warning, reported by Evan Nemerson\n\nv0.1.2  (Sep 11, 2015)\nframe concatenation support\n\nv0.1.1  (Aug 27, 2015)\nfix compression bug\ndetects write-flush errors\n\nv0.1.0  (Aug 25, 2015)\nfirst release\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.23828125,
          "content": "# Code of Conduct\n\nFacebook has adopted a Code of Conduct that we expect project participants to adhere to.\nPlease read the [full text](https://code.fb.com/codeofconduct/)\nso that you can understand what actions will and will not be tolerated.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 30.0625,
          "content": "# Contributing to Zstandard\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Our Development Process\nNew versions are being developed in the \"dev\" branch,\nor in their own feature branch.\nWhen they are deemed ready for a release, they are merged into \"release\".\n\nAs a consequence, all contributions must stage first through \"dev\"\nor their own feature branch.\n\n## Pull Requests\nWe actively welcome your pull requests.\n\n1. Fork the repo and create your branch from `dev`.\n2. If you've added code that should be tested, add tests.\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. Make sure your code lints.\n6. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Workflow\nZstd uses a branch-based workflow for making changes to the codebase. Typically, zstd\nwill use a new branch per sizable topic. For smaller changes, it is okay to lump multiple\nrelated changes into a branch.\n\nOur contribution process works in three main stages:\n1. Local development\n    * Update:\n        * Checkout your fork of zstd if you have not already\n        ```\n        git checkout https://github.com/<username>/zstd\n        cd zstd\n        ```\n        * Update your local dev branch\n        ```\n        git pull https://github.com/facebook/zstd dev\n        git push origin dev\n        ```\n    * Topic and development:\n        * Make a new branch on your fork about the topic you're developing for\n        ```\n        # branch names should be concise but sufficiently informative\n        git checkout -b <branch-name>\n        git push origin <branch-name>\n        ```\n        * Make commits and push\n        ```\n        # make some changes =\n        git add -u && git commit -m <message>\n        git push origin <branch-name>\n        ```\n        * Note: run local tests to ensure that your changes didn't break existing functionality\n            * Quick check\n            ```\n            make shortest\n            ```\n            * Longer check\n            ```\n            make test\n            ```\n2. Code Review and CI tests\n    * Ensure CI tests pass:\n        * Before sharing anything to the community, create a pull request in your own fork against the dev branch\n        and make sure that all GitHub Actions CI tests pass. See the Continuous Integration section below for more information.\n        * Ensure that static analysis passes on your development machine. See the Static Analysis section\n        below to see how to do this.\n    * Create a pull request:\n        * When you are ready to share you changes to the community, create a pull request from your branch\n        to facebook:dev. You can do this very easily by clicking 'Create Pull Request' on your fork's home\n        page.\n        * From there, select the branch where you made changes as your source branch and facebook:dev\n        as the destination.\n        * Examine the diff presented between the two branches to make sure there is nothing unexpected.\n    * Write a good pull request description:\n        * While there is no strict template that our contributors follow, we would like them to\n        sufficiently summarize and motivate the changes they are proposing. We recommend all pull requests,\n        at least indirectly, address the following points.\n            * Is this pull request important and why?\n            * Is it addressing an issue? If so, what issue? (provide links for convenience please)\n            * Is this a new feature? If so, why is it useful and/or necessary?\n            * Are there background references and documents that reviewers should be aware of to properly assess this change?\n        * Note: make sure to point out any design and architectural decisions that you made and the rationale behind them.\n        * Note: if you have been working with a specific user and would like them to review your work, make sure you mention them using (@<username>)\n    * Submit the pull request and iterate with feedback.\n3. Merge and Release\n    * Getting approval:\n        * You will have to iterate on your changes with feedback from other collaborators to reach a point\n        where your pull request can be safely merged.\n        * To avoid too many comments on style and convention, make sure that you have a\n        look at our style section below before creating a pull request.\n        * Eventually, someone from the zstd team will approve your pull request and not long after merge it into\n        the dev branch.\n    * Housekeeping:\n        * Most PRs are linked with one or more Github issues. If this is the case for your PR, make sure\n        the corresponding issue is mentioned. If your change 'fixes' or completely addresses the\n        issue at hand, then please indicate this by requesting that an issue be closed by commenting.\n        * Just because your changes have been merged does not mean the topic or larger issue is complete. Remember\n        that the change must make it to an official zstd release for it to be meaningful. We recommend\n        that contributors track the activity on their pull request and corresponding issue(s) page(s) until\n        their change makes it to the next release of zstd. Users will often discover bugs in your code or\n        suggest ways to refine and improve your initial changes even after the pull request is merged.\n\n## Static Analysis\nStatic analysis is a process for examining the correctness or validity of a program without actually\nexecuting it. It usually helps us find many simple bugs. Zstd uses clang's `scan-build` tool for\nstatic analysis. You can install it by following the instructions for your OS on https://clang-analyzer.llvm.org/scan-build.\n\nOnce installed, you can ensure that our static analysis tests pass on your local development machine\nby running:\n```\nmake staticAnalyze\n```\n\nIn general, you can use `scan-build` to static analyze any build script. For example, to static analyze\njust `contrib/largeNbDicts` and nothing else, you can run:\n\n```\nscan-build make -C contrib/largeNbDicts largeNbDicts\n```\n\n### Pitfalls of static analysis\n`scan-build` is part of our regular CI suite. Other static analyzers are not.\n\nIt can be useful to look at additional static analyzers once in a while (and we do), but it's not a good idea to multiply the nb of analyzers run continuously at each commit and PR. The reasons are :\n\n- Static analyzers are full of false positive. The signal to noise ratio is actually pretty low.\n- A good CI policy is \"zero-warning tolerance\". That means that all issues must be solved, including false positives. This quickly becomes a tedious workload.\n- Multiple static analyzers will feature multiple kind of false positives, sometimes applying to the same code but in different ways leading to :\n   + tortuous code, trying to please multiple constraints, hurting readability and therefore maintenance. Sometimes, such complexity introduce other more subtle bugs, that are just out of scope of the analyzers.\n   + sometimes, these constraints are mutually exclusive : if one try to solve one, the other static analyzer will complain, they can't be both happy at the same time.\n- As if that was not enough, the list of false positives change with each version. It's hard enough to follow one static analyzer, but multiple ones with their own update agenda, this quickly becomes a massive velocity reducer.\n\nThis is different from running a static analyzer once in a while, looking at the output, and __cherry picking__ a few warnings that seem helpful, either because they detected a genuine risk of bug, or because it helps expressing the code in a way which is more readable or more difficult to misuse. These kinds of reports can be useful, and are accepted.\n\n## Continuous Integration\nCI tests run every time a pull request (PR) is created or updated. The exact tests\nthat get run will depend on the destination branch you specify. Some tests take\nlonger to run than others. Currently, our CI is set up to run a short\nseries of tests when creating a PR to the dev branch and a longer series of tests\nwhen creating a PR to the release branch. You can look in the configuration files\nof the respective CI platform for more information on what gets run when.\n\nMost people will just want to create a PR with the destination set to their local dev\nbranch of zstd. You can then find the status of the tests on the PR's page. You can also\nre-run tests and cancel running tests from the PR page or from the respective CI's dashboard.\n\nAlmost all of zstd's CI runs on GitHub Actions (configured at `.github/workflows`), which will automatically run on PRs to your\nown fork. A small number of tests run on other services (e.g. Travis CI, Circle CI, Appveyor).\nThese require work to set up on your local fork, and (at least for Travis CI) cost money.\nTherefore, if the PR on your local fork passes GitHub Actions, feel free to submit a PR\nagainst the main repo.\n\n### Third-party CI\nA small number of tests cannot run on GitHub Actions, or have yet to be migrated.\nFor these, we use a variety of third-party services (listed below). It is not necessary to set\nthese up on your fork in order to contribute to zstd; however, we do link to instructions for those\nwho want earlier signal.\n\n| Service   | Purpose                                                                                                    | Setup Links                                                                                                                                            | Config Path            |\n|-----------|------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|\n| Travis CI | Used for testing on non-x86 architectures such as PowerPC                                                  | https://docs.travis-ci.com/user/tutorial/#to-get-started-with-travis-ci-using-github <br> https://github.com/marketplace/travis-ci                     | `.travis.yml`          |\n| AppVeyor  | Used for some Windows testing (e.g. cygwin, mingw)                                                         | https://www.appveyor.com/blog/2018/10/02/github-apps-integration/ <br> https://github.com/marketplace/appveyor                                         | `appveyor.yml`         |\n| Cirrus CI | Used for testing on FreeBSD                                                                                | https://github.com/marketplace/cirrus-ci/                                                                                                              | `.cirrus.yml`          |\n| Circle CI | Historically was used to provide faster signal,<br/> but we may be able to migrate these to Github Actions | https://circleci.com/docs/2.0/getting-started/#setting-up-circleci <br> https://youtu.be/Js3hMUsSZ2c <br> https://circleci.com/docs/2.0/enable-checks/ | `.circleci/config.yml` |\n\nNote: the instructions linked above mostly cover how to set up a repository with CI from scratch.\nThe general idea should be the same for setting up CI on your fork of zstd, but you may have to\nfollow slightly different steps. In particular, please ignore any instructions related to setting up\nconfig files (since zstd already has configs for each of these services).\n\n## Performance\nPerformance is extremely important for zstd and we only merge pull requests whose performance\nlandscape and corresponding trade-offs have been adequately analyzed, reproduced, and presented.\nThis high bar for performance means that every PR which has the potential to\nimpact performance takes a very long time for us to properly review. That being said, we\nalways welcome contributions to improve performance (or worsen performance for the trade-off of\nsomething else). Please keep the following in mind before submitting a performance related PR:\n\n1. Zstd isn't as old as gzip but it has been around for time now and its evolution is\nvery well documented via past Github issues and pull requests. It may be the case that your\nparticular performance optimization has already been considered in the past. Please take some\ntime to search through old issues and pull requests using keywords specific to your\nwould-be PR. Of course, just because a topic has already been discussed (and perhaps rejected\non some grounds) in the past, doesn't mean it isn't worth bringing up again. But even in that case,\nit will be helpful for you to have context from that topic's history before contributing.\n2. The distinction between noise and actual performance gains can unfortunately be very subtle\nespecially when microbenchmarking extremely small wins or losses. The only remedy to getting\nsomething subtle merged is extensive benchmarking. You will be doing us a great favor if you\ntake the time to run extensive, long-duration, and potentially cross-(os, platform, process, etc)\nbenchmarks on your end before submitting a PR. Of course, you will not be able to benchmark\nyour changes on every single processor and os out there (and neither will we) but do that best\nyou can:) We've added some things to think about when benchmarking below in the Benchmarking\nPerformance section which might be helpful for you.\n3. Optimizing performance for a certain OS, processor vendor, compiler, or network system is a perfectly\nlegitimate thing to do as long as it does not harm the overall performance health of Zstd.\nThis is a hard balance to strike but please keep in mind other aspects of Zstd when\nsubmitting changes that are clang-specific, windows-specific, etc.\n\n## Benchmarking Performance\nPerformance microbenchmarking is a tricky subject but also essential for Zstd. We value empirical\ntesting over theoretical speculation. This guide it not perfect but for most scenarios, it\nis a good place to start.\n\n### Stability\nUnfortunately, the most important aspect in being able to benchmark reliably is to have a stable\nbenchmarking machine. A virtual machine, a machine with shared resources, or your laptop\nwill typically not be stable enough to obtain reliable benchmark results. If you can get your\nhands on a desktop, this is usually a better scenario.\n\nOf course, benchmarking can be done on non-hyper-stable machines as well. You will just have to\ndo a little more work to ensure that you are in fact measuring the changes you've made and not\nnoise. Here are some things you can do to make your benchmarks more stable:\n\n1. The most simple thing you can do to drastically improve the stability of your benchmark is\nto run it multiple times and then aggregate the results of those runs. As a general rule of\nthumb, the smaller the change you are trying to measure, the more samples of benchmark runs\nyou will have to aggregate over to get reliable results. Here are some additional things to keep in\nmind when running multiple trials:\n    * How you aggregate your samples are important. You might be tempted to use the mean of your\n    results. While this is certainly going to be a more stable number than a raw single sample\n    benchmark number, you might have more luck by taking the median. The mean is not robust to\n    outliers whereas the median is. Better still, you could simply take the fastest speed your\n    benchmark achieved on each run since that is likely the fastest your process will be\n    capable of running your code. In our experience, this (aggregating by just taking the sample\n    with the fastest running time) has been the most stable approach.\n    * The more samples you have, the more stable your benchmarks should be. You can verify\n    your improved stability by looking at the size of your confidence intervals as you\n    increase your sample count. These should get smaller and smaller. Eventually hopefully\n    smaller than the performance win you are expecting.\n    * Most processors will take some time to get `hot` when running anything. The observations\n    you collect during that time period will very different from the true performance number. Having\n    a very large number of sample will help alleviate this problem slightly but you can also\n    address is directly by simply not including the first `n` iterations of your benchmark in\n    your aggregations. You can determine `n` by simply looking at the results from each iteration\n    and then hand picking a good threshold after which the variance in results seems to stabilize.\n2. You cannot really get reliable benchmarks if your host machine is simultaneously running\nanother cpu/memory-intensive application in the background. If you are running benchmarks on your\npersonal laptop for instance, you should close all applications (including your code editor and\nbrowser) before running your benchmarks. You might also have invisible background applications\nrunning. You can see what these are by looking at either Activity Monitor on Mac or Task Manager\non Windows. You will get more stable benchmark results of you end those processes as well.\n    * If you have multiple cores, you can even run your benchmark on a reserved core to prevent\n    pollution from other OS and user processes. There are a number of ways to do this depending\n    on your OS:\n        * On linux boxes, you have use https://github.com/lpechacek/cpuset.\n        * On Windows, you can \"Set Processor Affinity\" using https://www.thewindowsclub.com/processor-affinity-windows\n        * On Mac, you can try to use their dedicated affinity API https://developer.apple.com/library/archive/releasenotes/Performance/RN-AffinityAPI/#//apple_ref/doc/uid/TP40006635-CH1-DontLinkElementID_2\n3. To benchmark, you will likely end up writing a separate c/c++ program that will link libzstd.\nDynamically linking your library will introduce some added variation (not a large amount but\ndefinitely some). Statically linking libzstd will be more stable. Static libraries should\nbe enabled by default when building zstd.\n4. Use a profiler with a good high resolution timer. See the section below on profiling for\ndetails on this.\n5. Disable frequency scaling, turbo boost and address space randomization (this will vary by OS)\n6. Try to avoid storage. On some systems you can use tmpfs. Putting the program, inputs and outputs on\ntmpfs avoids touching a real storage system, which can have a pretty big variability.\n\nAlso check our LLVM's guide on benchmarking here: https://llvm.org/docs/Benchmarking.html\n\n### Zstd benchmark\nThe fastest signal you can get regarding your performance changes is via the in-build zstd cli\nbench option. You can run Zstd as you typically would for your scenario using some set of options\nand then additionally also specify the `-b#` option. Doing this will run our benchmarking pipeline\nfor that options you have just provided. If you want to look at the internals of how this\nbenchmarking script works, you can check out programs/benchzstd.c\n\nFor example: say you have made a change that you believe improves the speed of zstd level 1. The\nvery first thing you should use to assess whether you actually achieved any sort of improvement\nis `zstd -b`. You might try to do something like this. Note: you can use the `-i` option to\nspecify a running time for your benchmark in seconds (default is 3 seconds).\nUsually, the longer the running time, the more stable your results will be.\n\n```\n$ git checkout <commit-before-your-change>\n$ make && cp zstd zstd-old\n$ git checkout <commit-after-your-change>\n$ make && cp zstd zstd-new\n$ zstd-old -i5 -b1 <your-test-data>\n 1<your-test-data>         :      8990 ->      3992 (2.252), 302.6 MB/s , 626.4 MB/s\n$ zstd-new -i5 -b1 <your-test-data>\n 1<your-test-data>         :      8990 ->      3992 (2.252), 302.8 MB/s , 628.4 MB/s\n```\n\nUnless your performance win is large enough to be visible despite the intrinsic noise\non your computer, benchzstd alone will likely not be enough to validate the impact of your\nchanges. For example, the results of the example above indicate that effectively nothing\nchanged but there could be a small <3% improvement that the noise on the host machine\nobscured. So unless you see a large performance win (10-15% consistently) using just\nthis method of evaluation will not be sufficient.\n\n### Profiling\nThere are a number of great profilers out there. We're going to briefly mention how you can\nprofile your code using `instruments` on mac, `perf` on linux and `visual studio profiler`\non Windows.\n\nSay you have an idea for a change that you think will provide some good performance gains\nfor level 1 compression on Zstd. Typically this means, you have identified a section of\ncode that you think can be made to run faster.\n\nThe first thing you will want to do is make sure that the piece of code is actually taking up\na notable amount of time to run. It is usually not worth optimizing something which accounts for less than\n0.0001% of the total running time. Luckily, there are tools to help with this.\nProfilers will let you see how much time your code spends inside a particular function.\nIf your target code snippet is only part of a function, it might be worth trying to\nisolate that snippet by moving it to its own function (this is usually not necessary but\nmight be).\n\nMost profilers (including the profilers discussed below) will generate a call graph of\nfunctions for you. Your goal will be to find your function of interest in this call graph\nand then inspect the time spent inside of it. You might also want to look at the annotated\nassembly which most profilers will provide you with.\n\n#### Instruments\nWe will once again consider the scenario where you think you've identified a piece of code\nwhose performance can be improved upon. Follow these steps to profile your code using\nInstruments.\n\n1. Open Instruments\n2. Select `Time Profiler` from the list of standard templates\n3. Close all other applications except for your instruments window and your terminal\n4. Run your benchmarking script from your terminal window\n    * You will want a benchmark that runs for at least a few seconds (5 seconds will\n    usually be long enough). This way the profiler will have something to work with\n    and you will have ample time to attach your profiler to this process:)\n    * I will just use benchzstd as my benchmarmking script for this example:\n```\n$ zstd -b1 -i5 <my-data> # this will run for 5 seconds\n```\n5. Once you run your benchmarking script, switch back over to instruments and attach your\nprocess to the time profiler. You can do this by:\n    * Clicking on the `All Processes` drop down in the top left of the toolbar.\n    * Selecting your process from the dropdown. In my case, it is just going to be labeled\n    `zstd`\n    * Hitting the bright red record circle button on the top left of the toolbar\n6. You profiler will now start collecting metrics from your benchmarking script. Once\nyou think you have collected enough samples (usually this is the case after 3 seconds of\nrecording), stop your profiler.\n7. Make sure that in toolbar of the bottom window, `profile` is selected.\n8. You should be able to see your call graph.\n    * If you don't see the call graph or an incomplete call graph, make sure you have compiled\n    zstd and your benchmarking script using debug flags. On mac and linux, this just means\n    you will have to supply the `-g` flag alone with your build script. You might also\n    have to provide the `-fno-omit-frame-pointer` flag\n9. Dig down the graph to find your function call and then inspect it by double clicking\nthe list item. You will be able to see the annotated source code and the assembly side by\nside.\n\n#### Perf\n\nThis wiki has a pretty detailed tutorial on getting started working with perf so we'll\nleave you to check that out of you're getting started:\n\nhttps://perf.wiki.kernel.org/index.php/Tutorial\n\nSome general notes on perf:\n* Use `perf stat -r # <bench-program>` to quickly get some relevant timing and\ncounter statistics. Perf uses a high resolution timer and this is likely one\nof the first things your team will run when assessing your PR.\n* Perf has a long list of hardware counters that can be viewed with `perf --list`.\nWhen measuring optimizations, something worth trying is to make sure the hardware\ncounters you expect to be impacted by your change are in fact being so. For example,\nif you expect the L1 cache misses to decrease with your change, you can look at the\ncounter `L1-dcache-load-misses`\n* Perf hardware counters will not work on a virtual machine.\n\n#### Visual Studio\n\nTODO\n\n## Issues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## Coding Style\nIt's a pretty long topic, which is difficult to summarize in a single paragraph.\nAs a rule of thumbs, try to imitate the coding style of\nsimilar lines of codes around your contribution.\nThe following is a non-exhaustive list of rules employed in zstd code base:\n\n### C90\nThis code base is following strict C90 standard,\nwith 2 extensions : 64-bit `long long` types, and variadic macros.\nThis rule is applied strictly to code within `lib/` and `programs/`.\nSub-project in `contrib/` are allowed to use other conventions.\n\n### C++ direct compatibility : symbol mangling\nAll public symbol declarations must be wrapped in `extern “C” { … }`,\nso that this project can be compiled as C++98 code,\nand linked into C++ applications.\n\n### Minimal Frugal\nThis design requirement is fundamental to preserve the portability of the code base.\n#### Dependencies\n- Reduce dependencies to the minimum possible level.\n  Any dependency should be considered “bad” by default,\n  and only tolerated because it provides a service in a better way than can be achieved locally.\n  The only external dependencies this repository tolerates are\n  standard C libraries, and in rare cases, system level headers.\n- Within `lib/`, this policy is even more drastic.\n  The only external dependencies allowed are `<assert.h>`, `<stdlib.h>`, `<string.h>`,\n  and even then, not directly.\n  In particular, no function shall ever allocate on heap directly,\n  and must use instead `ZSTD_malloc()` and equivalent.\n  Other accepted non-symbol headers are `<stddef.h>` and `<limits.h>`.\n- Within the project, there is a strict hierarchy of dependencies that must be respected.\n  `programs/` is allowed to depend on `lib/`, but only its public API.\n  Within `lib/`, `lib/common` doesn't depend on any other directory.\n  `lib/compress` and `lib/decompress` shall not depend on each other.\n  `lib/dictBuilder` can depend on `lib/common` and `lib/compress`, but not `lib/decompress`.\n#### Resources\n- Functions in `lib/` must use very little stack space,\n  several dozens of bytes max.\n  Everything larger must use the heap allocator,\n  or require a scratch buffer to be emplaced manually.\n\n### Naming\n* All public symbols are prefixed with `ZSTD_`\n  + private symbols, with a scope limited to their own unit, are free of this restriction.\n    However, since `libzstd` source code can be amalgamated,\n    each symbol name must attempt to be (and remain) unique.\n    Avoid too generic names that could become ground for future collisions.\n    This generally implies usage of some form of prefix.\n* For symbols (functions and variables), naming convention is `PREFIX_camelCase`.\n  + In some advanced cases, one can also find :\n    - `PREFIX_prefix2_camelCase`\n    - `PREFIX_camelCase_extendedQualifier`\n* Multi-words names generally consist of an action followed by object:\n  - for example : `ZSTD_createCCtx()`\n* Prefer positive actions\n  - `goBackward` rather than `notGoForward`\n* Type names (`struct`, etc.) follow similar convention,\n  except that they are allowed and even invited to start by an Uppercase letter.\n  Example : `ZSTD_CCtx`, `ZSTD_CDict`\n* Macro names are all Capital letters.\n  The same composition rules (`PREFIX_NAME_QUALIFIER`) apply.\n* File names are all lowercase letters.\n  The convention is `snake_case`.\n  File names **must** be unique across the entire code base,\n  even when they stand in clearly separated directories.\n\n### Qualifiers\n* This code base is `const` friendly, if not `const` fanatical.\n  Any variable that can be `const` (aka. read-only) **must** be `const`.\n  Any pointer which content will not be modified must be `const`.\n  This property is then controlled at compiler level.\n  `const` variables are an important signal to readers that this variable isn't modified.\n  Conversely, non-const variables are a signal to readers to watch out for modifications later on in the function.\n* If a function must be inlined, mention it explicitly,\n  using project's own portable macros, such as `FORCE_INLINE_ATTR`,\n  defined in `lib/common/compiler.h`.\n\n### Debugging\n* **Assertions** are welcome, and should be used very liberally,\n  to control any condition the code expects for its correct execution.\n  These assertion checks will be run in debug builds, and disabled in production.\n* For traces, this project provides its own debug macros,\n  in particular `DEBUGLOG(level, ...)`, defined in `lib/common/debug.h`.\n\n### Code documentation\n* Avoid code documentation that merely repeats what the code is already stating.\n  Whenever applicable, prefer employing the code as the primary way to convey explanations.\n  Example 1 : `int nbTokens = n;` instead of `int i = n; /* i is a nb of tokens *./`.\n  Example 2 : `assert(size > 0);` instead of `/* here, size should be positive */`.\n* At declaration level, the documentation explains how to use the function or variable\n  and when applicable why it's needed, of the scenarios where it can be useful.\n* At implementation level, the documentation explains the general outline of the algorithm employed,\n  and when applicable why this specific choice was preferred.\n\n### General layout\n* 4 spaces for indentation rather than tabs\n* Code documentation shall directly precede function declaration or implementation\n* Function implementations and its code documentation should be preceded and followed by an empty line\n\n\n## License\nBy contributing to Zstandard, you agree that your contributions will be licensed\nunder both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 17.6669921875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Lesser General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n                            NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License along\n    with this program; if not, write to the Free Software Foundation, Inc.,\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License."
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.5126953125,
          "content": "BSD License\n\nFor Zstandard software\n\nCopyright (c) Meta Platforms, Inc. and affiliates. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name Facebook, nor Meta, nor the names of its contributors may\n   be used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 16.21875,
          "content": "# ################################################################\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under both the BSD-style license (found in the\n# LICENSE file in the root directory of this source tree) and the GPLv2 (found\n# in the COPYING file in the root directory of this source tree).\n# You may select, at your option, one of the above-listed licenses.\n# ################################################################\n\n# verbose mode (print commands) on V=1 or VERBOSE=1\nQ = $(if $(filter 1,$(V) $(VERBOSE)),,@)\n\nPRGDIR   = programs\nZSTDDIR  = lib\nBUILDIR  = build\nZWRAPDIR = zlibWrapper\nTESTDIR  = tests\nFUZZDIR  = $(TESTDIR)/fuzz\n\n# Define nul output\nVOID = /dev/null\n\n# When cross-compiling from linux to windows, you might\n# need to specify this as \"Windows.\" Fedora build fails\n# without it.\n#\n# Note: mingw-w64 build from linux to windows does not\n# fail on other tested distros (ubuntu, debian) even\n# without manually specifying the TARGET_SYSTEM.\nTARGET_SYSTEM ?= $(OS)\nCP ?= cp\n\nifneq (,$(filter Windows%,$(TARGET_SYSTEM)))\n  EXT =.exe\nelse\n  EXT =\nendif\n\n## default: Build lib-release and zstd-release\n.PHONY: default\ndefault: lib-release zstd-release\n\n.PHONY: all\nall: allmost examples manual contrib\n\n.PHONY: allmost\nallmost: allzstd zlibwrapper\n\n# skip zwrapper, can't build that on alternate architectures without the proper zlib installed\n.PHONY: allzstd\nallzstd: lib\n\t$(Q)$(MAKE) -C $(PRGDIR) all\n\t$(Q)$(MAKE) -C $(TESTDIR) all\n\n.PHONY: all32\nall32:\n\t$(MAKE) -C $(PRGDIR) zstd32\n\t$(MAKE) -C $(TESTDIR) all32\n\n.PHONY: lib lib-release lib-mt lib-nomt\nlib lib-release lib-mt lib-nomt:\n\t$(Q)$(MAKE) -C $(ZSTDDIR) $@\n\n.PHONY: zstd zstd-release\nzstd zstd-release:\n\t$(Q)$(MAKE) -C $(PRGDIR) $@\n\t$(Q)ln -sf $(PRGDIR)/zstd$(EXT) zstd$(EXT)\n\n.PHONY: zstdmt\nzstdmt:\n\t$(Q)$(MAKE) -C $(PRGDIR) $@\n\t$(Q)$(CP) $(PRGDIR)/zstd$(EXT) ./zstdmt$(EXT)\n\n.PHONY: zlibwrapper\nzlibwrapper: lib\n\t$(MAKE) -C $(ZWRAPDIR) all\n\n## test: run long-duration tests\n.PHONY: test\nDEBUGLEVEL ?= 1\ntest: MOREFLAGS += -g -Werror\ntest:\n\tDEBUGLEVEL=$(DEBUGLEVEL) MOREFLAGS=\"$(MOREFLAGS)\" $(MAKE) -j -C $(PRGDIR) allVariants\n\t$(MAKE) -C $(TESTDIR) $@\n\tZSTD=../../programs/zstd $(MAKE) -C doc/educational_decoder $@\n\n## shortest: same as `make check`\n.PHONY: shortest\nshortest:\n\t$(Q)$(MAKE) -C $(TESTDIR) $@\n\n## check: run basic tests for `zstd` cli\n.PHONY: check\ncheck: shortest\n\n.PHONY: automated_benchmarking\nautomated_benchmarking:\n\t$(MAKE) -C $(TESTDIR) $@\n\n.PHONY: benchmarking\nbenchmarking: automated_benchmarking\n\n## examples: build all examples in `examples/` directory\n.PHONY: examples\nexamples: lib\n\t$(MAKE) -C examples all\n\n## manual: generate API documentation in html format\n.PHONY: manual\nmanual:\n\t$(MAKE) -C contrib/gen_html $@\n\n## man: generate man page\n.PHONY: man\nman:\n\t$(MAKE) -C programs $@\n\n## contrib: build all supported projects in `/contrib` directory\n.PHONY: contrib\ncontrib: lib\n\t$(MAKE) -C contrib/pzstd all\n\t$(MAKE) -C contrib/seekable_format/examples all\n\t$(MAKE) -C contrib/seekable_format/tests test\n\t$(MAKE) -C contrib/largeNbDicts all\n\t$(MAKE) -C contrib/externalSequenceProducer all\n\tcd build/single_file_libs/ ; ./build_decoder_test.sh\n\tcd build/single_file_libs/ ; ./build_library_test.sh\n\n.PHONY: cleanTabs\ncleanTabs:\n\tcd contrib; ./cleanTabs\n\n.PHONY: clean\nclean:\n\t$(Q)$(MAKE) -C $(ZSTDDIR) $@ > $(VOID)\n\t$(Q)$(MAKE) -C $(PRGDIR) $@ > $(VOID)\n\t$(Q)$(MAKE) -C $(TESTDIR) $@ > $(VOID)\n\t$(Q)$(MAKE) -C $(ZWRAPDIR) $@ > $(VOID)\n\t$(Q)$(MAKE) -C examples/ $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/gen_html $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/pzstd $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/seekable_format/examples $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/seekable_format/tests $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/largeNbDicts $@ > $(VOID)\n\t$(Q)$(MAKE) -C contrib/externalSequenceProducer $@ > $(VOID)\n\t$(Q)$(RM) zstd$(EXT) zstdmt$(EXT) tmp*\n\t$(Q)$(RM) -r lz4 cmakebuild mesonbuild install\n\t@echo Cleaning completed\n\n#------------------------------------------------------------------------------\n# make install is validated only for Linux, macOS, Hurd and some BSD targets\n#------------------------------------------------------------------------------\nifneq (,$(filter Linux Darwin GNU/kFreeBSD GNU OpenBSD FreeBSD DragonFly NetBSD MSYS_NT% CYGWIN_NT% Haiku AIX,$(shell sh -c 'MSYSTEM=\"MSYS\" uname') ))\n\nHOST_OS = POSIX\n\nMKDIR ?= mkdir -p\n\nHAVE_COLORNEVER = $(shell echo a | egrep --color=never a > /dev/null 2> /dev/null && echo 1 || echo 0)\nEGREP_OPTIONS ?=\nifeq ($(HAVE_COLORNEVER), 1)\nEGREP_OPTIONS += --color=never\nendif\nEGREP = egrep $(EGREP_OPTIONS)\n\n# Print a two column output of targets and their description. To add a target description, put a\n# comment in the Makefile with the format \"## <TARGET>: <DESCRIPTION>\".  For example:\n#\n## list: Print all targets and their descriptions (if provided)\n.PHONY: list\nlist:\n\t$(Q)TARGETS=$$($(MAKE) -pRrq -f $(lastword $(MAKEFILE_LIST)) : 2>/dev/null \\\n\t\t| awk -v RS= -F: '/^# File/,/^# Finished Make data base/ {if ($$1 !~ \"^[#.]\") {print $$1}}' \\\n\t\t| $(EGREP) -v  -e '^[^[:alnum:]]' | sort); \\\n\t{ \\\n\t    printf \"Target Name\\tDescription\\n\"; \\\n\t    printf \"%0.s-\" {1..16}; printf \"\\t\"; printf \"%0.s-\" {1..40}; printf \"\\n\"; \\\n\t    for target in $$TARGETS; do \\\n\t        line=$$($(EGREP) \"^##[[:space:]]+$$target:\" $(lastword $(MAKEFILE_LIST))); \\\n\t        description=$$(echo $$line | awk '{i=index($$0,\":\"); print substr($$0,i+1)}' | xargs); \\\n\t        printf \"$$target\\t$$description\\n\"; \\\n\t    done \\\n\t} | column -t -s $$'\\t'\n\n.PHONY: install armtest usan asan uasan msan asan32\ninstall:\n\t$(Q)$(MAKE) -C $(ZSTDDIR) $@\n\t$(Q)$(MAKE) -C $(PRGDIR) $@\n\n.PHONY: uninstall\nuninstall:\n\t$(Q)$(MAKE) -C $(ZSTDDIR) $@\n\t$(Q)$(MAKE) -C $(PRGDIR) $@\n\n.PHONY: travis-install\ntravis-install:\n\t$(MAKE) install PREFIX=~/install_test_dir\n\n.PHONY: clangbuild-darwin-fat\nclangbuild-darwin-fat: clean\n\tclang -v\n\tCXX=clang++ CC=clang CFLAGS+=\"-Werror -Wconversion -Wno-sign-conversion -Wdocumentation -arch arm64\" $(MAKE) zstd-release\n\tmv programs/zstd programs/zstd_arm64\n\tCXX=clang++ CC=clang CFLAGS+=\"-Werror -Wconversion -Wno-sign-conversion -Wdocumentation -arch x86_64\" $(MAKE) zstd-release\n\tmv programs/zstd programs/zstd_x64\n\tlipo -create programs/zstd_x64 programs/zstd_arm64 -output programs/zstd\n\n.PHONY: gcc5build gcc6build gcc7build clangbuild m32build armbuild aarch64build ppcbuild ppc64build\ngcc5build: clean\n\tgcc-5 -v\n\tCC=gcc-5 $(MAKE) all MOREFLAGS=\"-Werror $(MOREFLAGS)\"\n\ngcc6build: clean\n\tgcc-6 -v\n\tCC=gcc-6 $(MAKE) all MOREFLAGS=\"-Werror $(MOREFLAGS)\"\n\ngcc7build: clean\n\tgcc-7 -v\n\tCC=gcc-7 $(MAKE) all MOREFLAGS=\"-Werror $(MOREFLAGS)\"\n\nclangbuild: clean\n\tclang -v\n\tCXX=clang++ CC=clang CFLAGS=\"-Werror -Wconversion -Wno-sign-conversion -Wdocumentation\" $(MAKE) all\n\nm32build: clean\n\tgcc -v\n\t$(MAKE) all32\n\narmbuild: clean\n\tCC=arm-linux-gnueabi-gcc CFLAGS=\"-Werror\" $(MAKE) allzstd\n\naarch64build: clean\n\tCC=aarch64-linux-gnu-gcc CFLAGS=\"-Werror -O0\" $(MAKE) allzstd\n\nppcbuild: clean\n\tCC=powerpc-linux-gnu-gcc CFLAGS=\"-m32 -Wno-attributes -Werror\" $(MAKE) -j allzstd\n\nppc64build: clean\n\tCC=powerpc-linux-gnu-gcc CFLAGS=\"-m64 -Werror\" $(MAKE) -j allzstd\n\n.PHONY: armfuzz aarch64fuzz ppcfuzz ppc64fuzz\narmfuzz: clean\n\tCC=arm-linux-gnueabi-gcc QEMU_SYS=qemu-arm-static MOREFLAGS=\"-static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\" $(MAKE) -C $(TESTDIR) fuzztest\n\naarch64fuzz: clean\n\tld -v\n\tCC=aarch64-linux-gnu-gcc QEMU_SYS=qemu-aarch64-static MOREFLAGS=\"-static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\" $(MAKE) -C $(TESTDIR) fuzztest\n\nppcfuzz: clean\n\tCC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc-static MOREFLAGS=\"-static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\" $(MAKE) -C $(TESTDIR) fuzztest\n\nppc64fuzz: clean\n\tCC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc64-static MOREFLAGS=\"-m64 -static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\" $(MAKE) -C $(TESTDIR) fuzztest\n\n.PHONY: cxxtest gcc5test gcc6test armtest aarch64test ppctest ppc64test\ncxxtest: CXXFLAGS += -Wall -Wextra -Wundef -Wshadow -Wcast-align -Werror\ncxxtest: clean\n\t$(MAKE) -C $(PRGDIR) all CC=\"$(CXX) -Wno-deprecated\" CFLAGS=\"$(CXXFLAGS)\"   # adding -Wno-deprecated to avoid clang++ warning on dealing with C files directly\n\ngcc5test: clean\n\tgcc-5 -v\n\t$(MAKE) all CC=gcc-5 MOREFLAGS=\"-Werror $(MOREFLAGS)\"\n\ngcc6test: clean\n\tgcc-6 -v\n\t$(MAKE) all CC=gcc-6 MOREFLAGS=\"-Werror $(MOREFLAGS)\"\n\narmtest: clean\n\t$(MAKE) -C $(TESTDIR) datagen   # use native, faster\n\t$(MAKE) -C $(TESTDIR) test CC=arm-linux-gnueabi-gcc QEMU_SYS=qemu-arm-static ZSTDRTTEST= MOREFLAGS=\"-Werror -static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\"\n\naarch64test:\n\t$(MAKE) -C $(TESTDIR) datagen   # use native, faster\n\t$(MAKE) -C $(TESTDIR) test CC=aarch64-linux-gnu-gcc QEMU_SYS=qemu-aarch64-static ZSTDRTTEST= MOREFLAGS=\"-Werror -static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\"\n\nppctest: clean\n\t$(MAKE) -C $(TESTDIR) datagen   # use native, faster\n\t$(MAKE) -C $(TESTDIR) test CC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc-static ZSTDRTTEST= MOREFLAGS=\"-Werror -Wno-attributes -static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\"\n\nppc64test: clean\n\t$(MAKE) -C $(TESTDIR) datagen   # use native, faster\n\t$(MAKE) -C $(TESTDIR) test CC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc64-static ZSTDRTTEST= MOREFLAGS=\"-m64 -static $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\"\n\n.PHONY: arm-ppc-compilation\narm-ppc-compilation:\n\t$(MAKE) -C $(PRGDIR) clean zstd CC=arm-linux-gnueabi-gcc QEMU_SYS=qemu-arm-static ZSTDRTTEST= MOREFLAGS=\"-Werror -static $(MOREFLAGS)\"\n\t$(MAKE) -C $(PRGDIR) clean zstd CC=aarch64-linux-gnu-gcc QEMU_SYS=qemu-aarch64-static ZSTDRTTEST= MOREFLAGS=\"-Werror -static $(MOREFLAGS)\"\n\t$(MAKE) -C $(PRGDIR) clean zstd CC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc-static ZSTDRTTEST= MOREFLAGS=\"-Werror -Wno-attributes -static $(MOREFLAGS)\"\n\t$(MAKE) -C $(PRGDIR) clean zstd CC=powerpc-linux-gnu-gcc QEMU_SYS=qemu-ppc64-static ZSTDRTTEST= MOREFLAGS=\"-m64 -static $(MOREFLAGS)\"\n\nregressiontest:\n\t$(MAKE) -C $(FUZZDIR) regressiontest\n\nuasanregressiontest:\n\t$(MAKE) -C $(FUZZDIR) regressiontest CC=clang CXX=clang++ CFLAGS=\"-O3 -fsanitize=address,undefined -Werror\" CXXFLAGS=\"-O3 -fsanitize=address,undefined -Werror\"\n\nmsanregressiontest:\n\t$(MAKE) -C $(FUZZDIR) regressiontest CC=clang CXX=clang++ CFLAGS=\"-O3 -fsanitize=memory -Werror\" CXXFLAGS=\"-O3 -fsanitize=memory -Werror\"\n\nupdate_regressionResults : REGRESS_RESULTS_DIR := /tmp/regress_results_dir/\nupdate_regressionResults:\n\t$(MAKE) -C programs zstd\n\t$(MAKE) -C tests/regression test\n\t$(RM) -rf $(REGRESS_RESULTS_DIR)\n\t$(MKDIR) $(REGRESS_RESULTS_DIR)\n\t./tests/regression/test                         \\\n        --cache  tests/regression/cache             \\\n        --output $(REGRESS_RESULTS_DIR)/results.csv \\\n        --zstd   programs/zstd\n\techo \"Showing results differences\"\n\t! diff tests/regression/results.csv $(REGRESS_RESULTS_DIR)/results.csv\n\techo \"Updating results.csv\"\n\t$(CP) $(REGRESS_RESULTS_DIR)/results.csv tests/regression/results.csv\n\n\n# run UBsan with -fsanitize-recover=pointer-overflow\n# this only works with recent compilers such as gcc 8+\nusan: clean\n\t$(MAKE) test CC=clang MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=undefined -Werror $(MOREFLAGS)\"\n\nasan: clean\n\t$(MAKE) test CC=clang MOREFLAGS=\"-g -fsanitize=address -Werror $(MOREFLAGS)\"\n\nasan-%: clean\n\tLDFLAGS=-fuse-ld=gold MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=address -Werror $(MOREFLAGS)\" $(MAKE) -C $(TESTDIR) $*\n\nmsan: clean\n\t$(MAKE) test CC=clang MOREFLAGS=\"-g -fsanitize=memory -fno-omit-frame-pointer -Werror $(MOREFLAGS)\" HAVE_LZMA=0   # datagen.c fails this test for no obvious reason\n\nmsan-%:\n\t$(MAKE) clean\n\tLDFLAGS=-fuse-ld=gold MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=memory -fno-omit-frame-pointer -Werror $(MOREFLAGS)\" FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\" $(MAKE) -j -C $(TESTDIR) HAVE_LZMA=0 $*\n\nasan32: clean\n\t$(MAKE) -C $(TESTDIR) test32 CC=clang MOREFLAGS=\"-g -fsanitize=address $(MOREFLAGS)\"\n\nuasan: clean\n\t$(MAKE) test CC=clang MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=address,undefined -Werror $(MOREFLAGS)\"\n\nuasan-%: clean\n\tLDFLAGS=-fuse-ld=gold MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=address,undefined -Werror $(MOREFLAGS)\" $(MAKE) -C $(TESTDIR) $*\n\ntsan-%: clean\n\tLDFLAGS=-fuse-ld=gold MOREFLAGS=\"-g -fno-sanitize-recover=all -fsanitize=thread -Werror $(MOREFLAGS)\" $(MAKE) -C $(TESTDIR) $* FUZZER_FLAGS=\"--no-big-tests $(FUZZER_FLAGS)\"\n\n.PHONY: apt-install\napt-install:\n\t# TODO: uncomment once issue 3011 is resolved and remove hack from Github Actions .yml\n\t# sudo apt-get update\n\tsudo apt-get -yq --no-install-suggests --no-install-recommends --force-yes install $(APT_PACKAGES)\n\n.PHONY: apt-add-repo\napt-add-repo:\n\tsudo add-apt-repository -y ppa:ubuntu-toolchain-r/test\n\tsudo apt-get update -y -qq\n\n.PHONY: ppcinstall arminstall valgrindinstall libc6install gcc6install gcc7install gcc8install gpp6install clang38install lz4install\nppcinstall:\n\tAPT_PACKAGES=\"qemu-system-ppc qemu-user-static gcc-powerpc-linux-gnu\" $(MAKE) apt-install\n\narminstall:\n\tAPT_PACKAGES=\"qemu-system-arm qemu-user-static gcc-arm-linux-gnueabi libc6-dev-armel-cross gcc-aarch64-linux-gnu libc6-dev-arm64-cross\" $(MAKE) apt-install\n\nvalgrindinstall:\n\tAPT_PACKAGES=\"valgrind\" $(MAKE) apt-install\n\nlibc6install:\n\tAPT_PACKAGES=\"libc6-dev-i386 gcc-multilib\" $(MAKE) apt-install\n\ngcc6install: apt-add-repo\n\tAPT_PACKAGES=\"libc6-dev-i386 gcc-multilib gcc-6 gcc-6-multilib\" $(MAKE) apt-install\n\ngcc7install: apt-add-repo\n\tAPT_PACKAGES=\"libc6-dev-i386 gcc-multilib gcc-7 gcc-7-multilib\" $(MAKE) apt-install\n\ngcc8install: apt-add-repo\n\tAPT_PACKAGES=\"libc6-dev-i386 gcc-multilib gcc-8 gcc-8-multilib\" $(MAKE) apt-install\n\ngpp6install: apt-add-repo\n\tAPT_PACKAGES=\"libc6-dev-i386 g++-multilib gcc-6 g++-6 g++-6-multilib\" $(MAKE) apt-install\n\nclang38install:\n\tAPT_PACKAGES=\"clang-3.8\" $(MAKE) apt-install\n\n# Ubuntu 14.04 ships a too-old lz4\nlz4install:\n\t[ -e lz4 ] || git clone https://github.com/lz4/lz4 && sudo $(MAKE) -C lz4 install\n\nendif\n\n\nifneq (,$(filter MSYS%,$(shell sh -c 'MSYSTEM=\"MSYS\" uname') ))\nHOST_OS = MSYS\nendif\n\n#------------------------------------------------------------------------\n# target specific tests\n#------------------------------------------------------------------------\nifneq (,$(filter MSYS POSIX,$(HOST_OS)))\n\nCMAKE ?= cmake\nCMAKE_PARAMS = -DZSTD_BUILD_CONTRIB:BOOL=ON -DZSTD_BUILD_STATIC:BOOL=ON -DZSTD_BUILD_TESTS:BOOL=ON -DZSTD_ZLIB_SUPPORT:BOOL=ON -DZSTD_LZMA_SUPPORT:BOOL=ON\n\nifneq (,$(filter MSYS%,$(shell sh -c 'MSYSTEM=\"MSYS\" uname')))\nCMAKE_PARAMS = -G\"MSYS Makefiles\" -DZSTD_MULTITHREAD_SUPPORT:BOOL=OFF -DZSTD_BUILD_STATIC:BOOL=ON -DZSTD_BUILD_TESTS:BOOL=ON\nendif\n\n.PHONY: cmakebuild\ncmakebuild:\n\t$(CMAKE) --version\n\t$(RM) -r cmakebuild install\n\t$(MKDIR) cmakebuild install\n\tcd cmakebuild; $(CMAKE) -Wdev -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_FLAGS=\"-Werror -O0\" -DCMAKE_INSTALL_PREFIX=install $(CMAKE_PARAMS) ../build/cmake\n\t$(CMAKE) --build cmakebuild --target install -- -j V=1\n\tcd cmakebuild; ctest -V -L Medium\n\nMESON ?= meson\nNINJA ?= ninja\n\n.PHONY: mesonbuild\nmesonbuild:\n\t$(MESON) setup \\\n\t\t--buildtype=debugoptimized \\\n\t\t-Db_lundef=false \\\n\t\t-Dauto_features=enabled \\\n\t\t-Dbin_programs=true \\\n\t\t-Dbin_tests=true \\\n\t\t-Dbin_contrib=true \\\n\t\t-Ddefault_library=both \\\n\t\tbuild/meson mesonbuild\n\t$(NINJA) -C mesonbuild/\n\t$(MESON) test -C mesonbuild/ --print-errorlogs\n\t$(MESON) install -C mesonbuild --destdir staging/\n\n.PHONY: c89build gnu90build c99build gnu99build c11build bmix64build bmix32build bmi32build staticAnalyze\nc89build: clean\n\t$(CC) -v\n\tCFLAGS=\"-std=c89 -Werror -Wno-attributes -Wpedantic -Wno-long-long -Wno-variadic-macros -O0\" $(MAKE) lib zstd\n\ngnu90build: clean\n\t$(CC) -v\n\tCFLAGS=\"-std=gnu90 -Werror -O0\" $(MAKE) allmost\n\nc99build: clean\n\t$(CC) -v\n\tCFLAGS=\"-std=c99 -Werror -O0\" $(MAKE) allmost\n\ngnu99build: clean\n\t$(CC) -v\n\tCFLAGS=\"-std=gnu99 -Werror -O0\" $(MAKE) allmost\n\nc11build: clean\n\t$(CC) -v\n\tCFLAGS=\"-std=c11 -Werror -O0\" $(MAKE) allmost\n\nbmix64build: clean\n\t$(CC) -v\n\tCFLAGS=\"-O3 -mbmi -Werror\" $(MAKE) -C $(TESTDIR) test\n\nbmix32build: clean\n\t$(CC) -v\n\tCFLAGS=\"-O3 -mbmi -mx32 -Werror\" $(MAKE) -C $(TESTDIR) test\n\nbmi32build: clean\n\t$(CC) -v\n\tCFLAGS=\"-O3 -mbmi -m32 -Werror\" $(MAKE) -C $(TESTDIR) test\n\n# static analyzer test uses clang's scan-build\n# does not analyze zlibWrapper, due to detected issues in zlib source code\nstaticAnalyze: SCANBUILD ?= scan-build\nstaticAnalyze:\n\t$(CC) -v\n\tCC=$(CC) CPPFLAGS=-g $(SCANBUILD) --status-bugs -v $(MAKE) zstd\nendif\n"
        },
        {
          "name": "Package.swift",
          "type": "blob",
          "size": 1.234375,
          "content": "// swift-tools-version:5.0\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"zstd\",\n    platforms: [\n        .macOS(.v10_10), .iOS(.v9), .tvOS(.v9)\n    ],\n    products: [\n        // Products define the executables and libraries a package produces, and make them visible to other packages.\n        .library(\n            name: \"libzstd\",\n            targets: [ \"libzstd\" ])\n    ],\n    dependencies: [\n        // Dependencies declare other packages that this package depends on.\n        // .package(url: /* package url */, from: \"1.0.0\"),\n    ],\n    targets: [\n        // Targets are the basic building blocks of a package. A target can define a module or a test suite.\n        // Targets can depend on other targets in this package, and on products in packages this package depends on.\n        .target(\n            name: \"libzstd\",\n            path: \"lib\",\n            sources: [ \"common\", \"compress\", \"decompress\", \"dictBuilder\" ],\n            publicHeadersPath: \".\",\n            cSettings: [\n                .headerSearchPath(\".\")\n            ])\n    ],\n    swiftLanguageVersions: [.v5],\n    cLanguageStandard: .gnu11,\n    cxxLanguageStandard: .gnucxx14\n)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.2177734375,
          "content": "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/facebook/zstd/dev/doc/images/zstd_logo86.png\" alt=\"Zstandard\"></p>\n\n__Zstandard__, or `zstd` as short version, is a fast lossless compression algorithm,\ntargeting real-time compression scenarios at zlib-level and better compression ratios.\nIt's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy).\n\nZstandard's format is stable and documented in [RFC8878](https://datatracker.ietf.org/doc/html/rfc8878). Multiple independent implementations are already available.\nThis repository represents the reference implementation, provided as an open-source dual [BSD](LICENSE) OR [GPLv2](COPYING) licensed **C** library,\nand a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.\nShould your project require another programming language,\na list of known ports and bindings is provided on [Zstandard homepage](https://facebook.github.io/zstd/#other-languages).\n\n**Development branch status:**\n\n[![Build Status][travisDevBadge]][travisLink]\n[![Build status][CircleDevBadge]][CircleLink]\n[![Build status][CirrusDevBadge]][CirrusLink]\n[![Fuzzing Status][OSSFuzzBadge]][OSSFuzzLink]\n\n[travisDevBadge]: https://api.travis-ci.com/facebook/zstd.svg?branch=dev \"Continuous Integration test suite\"\n[travisLink]: https://travis-ci.com/facebook/zstd\n[CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield \"Short test suite\"\n[CircleLink]: https://circleci.com/gh/facebook/zstd\n[CirrusDevBadge]: https://api.cirrus-ci.com/github/facebook/zstd.svg?branch=dev\n[CirrusLink]: https://cirrus-ci.com/github/facebook/zstd\n[OSSFuzzBadge]: https://oss-fuzz-build-logs.storage.googleapis.com/badges/zstd.svg\n[OSSFuzzLink]: https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:zstd\n\n## Benchmarks\n\nFor reference, several fast compression algorithms were tested and compared\non a desktop featuring a Core i7-9700K CPU @ 4.9GHz\nand running Ubuntu 20.04 (`Linux ubu20 5.15.0-101-generic`),\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 9.4.0,\non the [Silesia compression corpus].\n\n[lzbench]: https://github.com/inikep/lzbench\n[Silesia compression corpus]: https://sun.aei.polsl.pl//~sdeor/index.php?page=silesia\n[gcc]: https://gcc.gnu.org/\n\n| Compressor name         | Ratio | Compression| Decompress.|\n| ---------------         | ------| -----------| ---------- |\n| **zstd 1.5.6 -1**       | 2.887 |   510 MB/s |  1580 MB/s |\n| [zlib] 1.2.11 -1        | 2.743 |    95 MB/s |   400 MB/s |\n| brotli 1.0.9 -0         | 2.702 |   395 MB/s |   430 MB/s |\n| **zstd 1.5.6 --fast=1** | 2.437 |   545 MB/s |  1890 MB/s |\n| **zstd 1.5.6 --fast=3** | 2.239 |   650 MB/s |  2000 MB/s |\n| quicklz 1.5.0 -1        | 2.238 |   525 MB/s |   750 MB/s |\n| lzo1x 2.10 -1           | 2.106 |   650 MB/s |   825 MB/s |\n| [lz4] 1.9.4             | 2.101 |   700 MB/s |  4000 MB/s |\n| lzf 3.6 -1              | 2.077 |   420 MB/s |   830 MB/s |\n| snappy 1.1.9            | 2.073 |   530 MB/s |  1660 MB/s |\n\n[zlib]: https://www.zlib.net/\n[lz4]: https://lz4.github.io/lz4/\n\nThe negative compression levels, specified with `--fast=#`,\noffer faster compression and decompression speed\nat the cost of compression ratio.\n\nZstd can also offer stronger compression ratios at the cost of compression speed.\nSpeed vs Compression trade-off is configurable by small increments.\nDecompression speed is preserved and remains roughly the same at all settings,\na property shared by most LZ compression algorithms, such as [zlib] or lzma.\n\nThe following tests were run\non a server running Linux Debian (`Linux version 4.14.0-3-amd64`)\nwith a Core i7-6700K CPU @ 4.0GHz,\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 7.3.0,\non the [Silesia compression corpus].\n\nCompression Speed vs Ratio | Decompression Speed\n---------------------------|--------------------\n![Compression Speed vs Ratio](doc/images/CSpeed2.png \"Compression Speed vs Ratio\") | ![Decompression Speed](doc/images/DSpeed3.png \"Decompression Speed\")\n\nA few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.\nFor a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png).\n\n\n## The case for Small Data compression\n\nPrevious charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives.\n\nThe smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no \"past\" to build upon.\n\nTo solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.\nTraining Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called \"dictionary\", which must be loaded before compression and decompression.\nUsing this dictionary, the compression ratio achievable on small data improves dramatically.\n\nThe following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).\nIt consists of roughly 10K records weighing about 1KB each.\n\nCompression Ratio | Compression Speed | Decompression Speed\n------------------|-------------------|--------------------\n![Compression Ratio](doc/images/dict-cr.png \"Compression Ratio\") | ![Compression Speed](doc/images/dict-cs.png \"Compression Speed\") | ![Decompression Speed](doc/images/dict-ds.png \"Decompression Speed\")\n\n\nThese compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds.\n\nTraining works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).\nHence, deploying one dictionary per type of data will provide the greatest benefits.\nDictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file.\n\n### Dictionary compression How To:\n\n1. Create the dictionary\n\n   `zstd --train FullPathToTrainingSet/* -o dictionaryName`\n\n2. Compress with dictionary\n\n   `zstd -D dictionaryName FILE`\n\n3. Decompress with dictionary\n\n   `zstd -D dictionaryName --decompress FILE.zst`\n\n\n## Build instructions\n\n`make` is the officially maintained build system of this project.\nAll other build systems are \"compatible\" and 3rd-party maintained,\nthey may feature small differences in advanced options.\nWhen your system allows it, prefer using `make` to build `zstd` and `libzstd`.\n\n### Makefile\n\nIf your system is compatible with standard `make` (or `gmake`),\ninvoking `make` in root directory will generate `zstd` cli in root directory.\nIt will also create `libzstd` into `lib/`.\n\nOther available options include:\n- `make install` : create and install zstd cli, library and man pages\n- `make check` : create and run `zstd`, test its behavior on local platform\n\nThe `Makefile` follows the [GNU Standard Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html),\nallowing staged install, standard flags, directory variables and command variables.\n\nFor advanced use cases, specialized compilation flags which control binary generation\nare documented in [`lib/README.md`](lib/README.md#modular-build) for the `libzstd` library\nand in [`programs/README.md`](programs/README.md#compilation-variables) for the `zstd` CLI.\n\n### cmake\n\nA `cmake` project generator is provided within `build/cmake`.\nIt can generate Makefiles or other build scripts\nto create `zstd` binary, and `libzstd` dynamic and static libraries.\n\nBy default, `CMAKE_BUILD_TYPE` is set to `Release`.\n\n#### Support for Fat (Universal2) Output\n\n`zstd` can be built and installed with support for both Apple Silicon (M1/M2) as well as Intel by using CMake's Universal2 support.\nTo perform a Fat/Universal2 build and install use the following commands:\n\n```bash\ncmake -B build-cmake-debug -S build/cmake -G Ninja -DCMAKE_OSX_ARCHITECTURES=\"x86_64;x86_64h;arm64\"\ncd build-cmake-debug\nninja\nsudo ninja install\n```\n\n### Meson\n\nA Meson project is provided within [`build/meson`](build/meson). Follow\nbuild instructions in that directory.\n\nYou can also take a look at [`.travis.yml`](.travis.yml) file for an\nexample about how Meson is used to build this project.\n\nNote that default build type is **release**.\n\n### VCPKG\nYou can build and install zstd [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install zstd\n\nThe zstd port in vcpkg is kept up to date by Microsoft team members and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Conan\n\nYou can install pre-built binaries for zstd or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"zstd/[*]\" --build=missing\n```\n\nThe zstd Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n### Visual Studio (Windows)\n\nGoing into `build` directory, you will find additional possibilities:\n- Projects for Visual Studio 2005, 2008 and 2010.\n  + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.\n- Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,\n  which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution.\n\n### Buck\n\nYou can build the zstd binary via buck by executing: `buck build programs:zstd` from the root of the repo.\nThe output binary will be in `buck-out/gen/programs/`.\n\n### Bazel\n\nYou easily can integrate zstd into your Bazel project by using the module hosted on the [Bazel Central Repository](https://registry.bazel.build/modules/zstd).\n\n## Testing\n\nYou can run quick local smoke tests by running `make check`.\nIf you can't use `make`, execute the `playTest.sh` script from the `src/tests` directory.\nTwo env variables `$ZSTD_BIN` and `$DATAGEN_BIN` are needed for the test script to locate the `zstd` and `datagen` binary.\nFor information on CI testing, please refer to `TESTING.md`.\n\n## Status\n\nZstandard is currently deployed within Facebook and many other large cloud infrastructures.\nIt is run continuously to compress large amounts of data in multiple formats and use cases.\nZstandard is considered safe for production environments.\n\n## License\n\nZstandard is dual-licensed under [BSD](LICENSE) OR [GPLv2](COPYING).\n\n## Contributing\n\nThe `dev` branch is the one where all contributions are merged before reaching `release`.\nIf you plan to propose a patch, please commit into the `dev` branch, or its own feature branch.\nDirect commit to `release` are not permitted.\nFor more information, please read [CONTRIBUTING](CONTRIBUTING.md).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.9296875,
          "content": "# Reporting and Fixing Security Issues\n\nPlease do not open GitHub issues or pull requests - this makes the problem immediately visible to everyone, including malicious actors. Security issues in this open source project can be safely reported via the Meta Bug Bounty program:\n\nhttps://www.facebook.com/whitehat\n\nMeta's security team will triage your report and determine whether or not is it eligible for a bounty under our program.\n\n# Receiving Vulnerability Notifications\n\nIn the case that a significant security vulnerability is reported to us or discovered by us---without being publicly known---we will, at our discretion, notify high-profile, high-exposure users of Zstandard ahead of our public disclosure of the issue and associated fix.\n\nIf you believe your project would benefit from inclusion in this list, please reach out to one of the maintainers.\n\n<!-- Note to maintainers: this list is kept [here](https://fburl.com/wiki/cgc1l62x). -->\n"
        },
        {
          "name": "TESTING.md",
          "type": "blob",
          "size": 1.78125,
          "content": "Testing\n=======\n\nZstandard CI testing is split up into three sections:\nshort, medium, and long tests.\n\nShort Tests\n-----------\nShort tests run on CircleCI for new commits on every branch and pull request.\nThey consist of the following tests:\n- Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64)\n- Compilation on various versions of gcc, clang, and g++\n- `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests)\n- Small tests (`tests/legacy.c`, `tests/longmatch.c`) on x64_64\n\nMedium Tests\n------------\nMedium tests run on every commit and pull request to `dev` branch, on TravisCI.\nThey consist of the following tests:\n- The following tests run with UBsan and Asan on x86_64 and x86, as well as with\n  Msan on x86_64\n  - `tests/playTests.sh --test-large-data`\n  - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`\n- `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode)\n- Valgrind Test (`make -C tests test-valgrind`) (testing CLI and fuzzer under `valgrind`)\n- Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64\n\nLong Tests\n----------\nLong tests run on all commits to `release` branch,\nand once a day on the current version of `dev` branch,\non TravisCI.\nThey consist of the following tests:\n- Entire test suite (including fuzzers and some other specialized tests) on:\n  - x86_64 and x86 with UBsan and Asan\n  - x86_64 with Msan\n  - ARM, AArch64, PowerPC, and PowerPC64\n- Streaming mode fuzzer with Tsan (for the `zstdmt` testing)\n- ZlibWrapper tests, including under valgrind\n- Versions test (ensuring `zstd` can decode files from all previous versions)\n- `pzstd` with asan and tsan, as well as in 32-bits mode\n- Testing `zstd` with legacy mode off\n- Entire test suite and make install on macOS\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "programs",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "zlibWrapper",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}