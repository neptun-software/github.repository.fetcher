{
  "metadata": {
    "timestamp": 1736563718902,
    "page": 209,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "comet-ml/opik",
      "stars": 4136,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.09375,
          "content": "*.java linguist-detectable=false\n*.md linguist-detectable=false\n*.mdx linguist-detectable=false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.79296875,
          "content": "# Mac\n.DS_Store\n\n# IntelliJ\n.idea/\n*.iml\n\n# Maven\ntarget/\n**/dependency-reduced-pom.xml\n\n# BE related\n/apps/opik-backend/redoc/openapi.yaml\n\n# FE related\n/apps/opik-frontend/dist\n/apps/opik-frontend/build\n*.local\n\n# dependencies\n/apps/opik-frontend/node_modules\n/apps/opik-frontend/.pnp\n.pnp.js\n\n# testing\n/apps/opik-frontend/coverage\n\n# Vagrant\n**/.vagrant\n\n# debug\n/apps/opik-frontend/npm-debug.log*\n/apps/opik-frontend/yarn-debug.log*\n/apps/opik-frontend/yarn-error.log*\n\n# Python development\n*.egg\n*.egg-info\ndist\nbuild\nbuild/\neggs\nparts\nbin\nvar\nsdist\ndevelop-eggs\n.installed.cfg\n__pycache__\npip-log.txt\n.venv*\n.ipynb_checkpoints\n.python-version\n\n# VS Code\n.vscode\n\n# charts\ndeployment/helm_chart/opik/charts\ndeployment/helm_chart/opik/values-cloud-test.yaml\ndeployment/helm_chart/opik/values-test.yaml\ntemp\n"
        },
        {
          "name": ".hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": ".java-version",
          "type": "blob",
          "size": 0.0029296875,
          "content": "21\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.49609375,
          "content": "# 2024 Changelog\n\n### Release 1.0.3, 2024-10-29 [#](apps/opik-backend/data-migrations/1.0.3/README.md)\n\n#### Backward Incompatible Change\n\nThe structure of dataset items has changed to include new dynamic fields. Dataset items logged before version 1.0.3 will still show but would not be searchable. \nIf you would like to migrate previous dataset items to the new format, please see the instructions below: [dataset item migration](apps/opik-backend/data-migrations/1.0.3/README.md) for more information*.\n\n\n"
        },
        {
          "name": "CLA.md",
          "type": "blob",
          "size": 5.640625,
          "content": "Thank you for your interest in the OPIK project stewarded by Comet ML, Inc. (‚ÄúComet‚Äù). In order to clarify the intellectual property license granted with Contributions from any person or entity, Comet must have a Contributor License Agreement (CLA) on file that has been agreed to by each Contributor, indicating agreement to the license terms below. This license is for your protection as a Contributor as well as the protection of Comet and its users; it does not change your rights to use your own Contributions for any other purpose. This Agreement allows an individual to contribute to Comet on that individual‚Äôs own behalf, or an entity (the ‚ÄúCorporation‚Äù) to submit Contributions to Comet, to authorize Contributions submitted by its designated employees to Comet, and to grant copyright and patent licenses thereto.\nYou accept and agree to the following terms and conditions for Your present and future Contributions submitted to Comet. Except for the license granted herein to Comet and recipients of software distributed by Comet, You reserve all right, title, and interest in and to Your Contributions.\n1. Definitions. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) shall mean the copyright owner or legal entity authorized by the copyright owner that is making this Agreement with Comet. For legal entities, the entity making a Contribution and all other entities that control, are controlled by, or are under common control with that entity are considered to be a single Contributor. For the purposes of this definition, ‚Äúcontrol‚Äù means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ‚ÄúContribution‚Äù shall mean any work, as well as any modifications or additions to an existing work, that is intentionally submitted by You to Comet for inclusion in, or documentation of, any of the products owned or managed by Comet (the ‚ÄúWork‚Äù). For the purposes of this definition, ‚Äúsubmitted‚Äù means any form of electronic, verbal, or written communication sent to Comet or its representatives, including but not limited to communication on electronic mailing lists, source code control systems (such as GitHub), and issue tracking systems that are managed by, or on behalf of, Comet for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by You as ‚ÄúNot a Contribution.‚Äù\n2. Grant of Copyright License. Subject to the terms and conditions of this Agreement, You hereby grant to Comet and to recipients of software distributed by Comet a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute Your Contributions and such derivative works.\n3. Grant of Patent License. Subject to the terms and conditions of this Agreement, You hereby grant to Comet and to recipients of software distributed by Comet a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Work to which such Contribution(s) were submitted. If any entity institutes patent litigation against You or any other entity (including a cross-claim or counterclaim in a lawsuit) alleging that your Contribution, or the Work to which you have contributed, constitutes direct or contributory patent infringement, then any patent licenses granted to that entity under this Agreement for that Contribution or Work shall terminate as of the date such litigation is filed.\n4. You represent that You are legally entitled to grant the above license. If You are an individual, and if Your employer(s) has rights to intellectual property that you create that includes Your Contributions, you represent that You have received permission to make Contributions on behalf of that employer, or that Your employer has waived such rights for your Contributions to Comet. If You are a Corporation, any individual who makes a contribution from an account associated with You will be considered authorized to Contribute on Your behalf.\n5. You represent that each of Your Contributions is Your original creation (see section 7 for submissions on behalf of others).\n6. You agree that you will not receive any compensation for your contribution. Your contribution is made voluntarily and without expectation of payment.\n7. You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all. Unless required by applicable law or agreed to in writing, You provide Your Contributions on an ‚ÄúAS IS‚Äù BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE.\n8. Should You wish to submit work that is not Your original creation, You may submit it to Comet separately from any Contribution, identifying the complete details of its source and of any license or other restriction (including, but not limited to, related patents, trademarks, and license agreements) of which you are personally aware, and conspicuously marking the work as ‚ÄúSubmitted on behalf of a third-party: [named here]‚Äù.\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 13.68359375,
          "content": "# Contributing to Opik\n\nWe're excited that you're interested in contributing to Opik! There are many ways to contribute, from writing code to improving the documentation.\n\nThe easiest way to get started is to:\n\n* Submit [bug reports](https://github.com/comet-ml/opik/issues) and [feature requests](https://github.com/comet-ml/opik/issues)\n* Review the documentation and submit [Pull Requests](https://github.com/comet-ml/opik/pulls) to improve it\n* Speaking or writing about Opik and [letting us know](https://chat.comet.com)\n* Upvoting [popular feature requests](https://github.com/comet-ml/opik/issues?q=is%3Aissue+is%3Aopen+label%3A%22feature+request%22) to show your support\n* Review our [Contributor License Agreement](https://github.com/comet-ml/opik/blob/main/CLA.md)\n\n\n## Submitting a new issue or feature request\n\n### Submitting a new issue\n\nThanks for taking the time to submit an issue, it's the best way to help us improve Opik!\n\nBefore submitting a new issue, please check the [existing issues](https://github.com/comet-ml/opik/issues) to avoid duplicates.\n\nTo help us understand the issue you're experiencing, please provide steps to reproduce the issue included a minimal code snippet that reproduces the issue. This helps us diagnose the issue and fix it more quickly.\n\n### Submitting a new feature request\n\nFeature requests are welcome! To help us understand the feature you'd like to see, please provide:\n\n1. A short description of the motivation behind this request\n2. A detailed description of the feature you'd like to see, including any code snippets if applicable\n\nIf you are in a position to submit a PR for the feature, feel free to open a PR !\n\n## Project set up and Architecture\n\nThe Opik project is made up of five main sub-projects:\n\n* `apps/opik-documentation`: The Opik documentation website\n* `deployment/installer`: The Opik installer\n* `sdks/python`: The Opik Python SDK\n* `apps/opik-frontend`: The Opik frontend application\n* `apps/opik-backend`: The Opik backend server\n\n\nIn addition, Opik relies on:\n\n1. Clickhouse: Used to trace traces, spans and feedback scores\n2. MySQL: Used to store metadata associated with projects, datasets, experiments, etc.\n3. Redis: Used for caching\n\n### Configuring your development environment\n\n#### Pre-requisites\nIn order to run the development environment, you will need to have the following tools installed:\n\n* Docker - https://docs.docker.com/engine/install/\n\n* kubectl - https://kubernetes.io/docs/tasks/tools/#kubectl\n\n* Helm - https://helm.sh/docs/intro/install/\n\n* minikube - https://minikube.sigs.k8s.io/docs/start\n\n* More tools:\n    * **`bash`** completion / `zsh` completion\n    * `kubectx` and `kubens` - easy switch context/namespaces for kubectl -  https://github.com/ahmetb/kubectx\n\n#### Setting up the environment\n\nThe local development environment is based on minikube. Once you have minikube installed, you can run it using:\n\n```bash\nminikube start\n```\n\nYou can then run Opik and it's dependencies (Clickhouse, Redis, MySQL, etc) using:\n\n```bash\n./build_and_run.sh\n```\n\nThis script supports the following options:\n```\n--no-build          Skip the build process\n--no-fe-build       Skip the FE build process\n--no-helm-update    Skip helm repo update\n--local-fe          Run FE locally (For frontend developers)\n--help              Display help message\n```\n\n> [!NOTE]\n> The first time you run the `build_and_run` script, it can take a few minutes to install everything.\n\nTo check the application is running, you can access the FE using: `http://localhost:5173`\n\n#### Advanced usage\n\n*Connecting to Clickhouse*\nYou can run the `clickhouse-client` with:\n```bash\nkubectl exec -it chi-opik-clickhouse-cluster-0-0-0 clickhouse-client\n```\n\nAfter the client is connected, you can check the databases with \n```bash\nshow databases;\n```\n\n*Minikube commands*\n\nList the pods that are running\n```bash\nkubectl get pods\n```\nTo restart a pod just delete the pod, k8s will start a new one\n```bash\nkubectl delete pod <pod name>\n```\nThere is no clean way to delete the databases, so if you need to do that, it's better to delete the namespace and then install again.\nRun \n```bash\nkubectl delete namespace opik \n```\nand in parallel (in another terminal window/tab) run \n```bash\nkubectl patch chi opik-clickhouse --type json --patch='[ { \"op\": \"remove\", \"path\": \"/metadata/finalizers\" } ]'\n```\nafter the namespace is deleted, run \n```bash\n./build_and_run.sh --no-build\n```\nto install everything again\n\nStop minikube\n```bash\nminikube stop\n```\nNext time you will start the minikube, it will run everything with the same configuration and data you had before.\n\n### Contributing to the documentation\n\nThe documentation is made up of three main parts:\n\n1. `apps/opik-documentation/documentation`: The Opik documentation website\n2. `apps/opik-documentation/python-sdk-docs`: The Python reference documentation\n3. `apps/opik-documentation/rest-api-docs`: The REST API reference documentation\n\n#### Contributing to the documentation website\n\nThe documentation website is built using [Docusaurus](https://docusaurus.io/) and is located in `apps/opik-documentation/documentation`.\n\nIn order to run the documentation website locally, you need to have `npm` installed. Once installed, you can run the documentation locally using the following command:\n\n```bash\ncd apps/opik-documentation/documentation\n\n# Install dependencies - Only needs to be run once\nnpm install\n\n# Run the documentation website locally\nnpm run start\n```\n\nYou can then access the documentation website at `http://localhost:3000`. Any change you make to the documentation will be updated in real-time.\n\n#### Contributing to the Python SDK reference documentation\n\nThe Python SDK reference documentation is built using [Sphinx](https://www.sphinx-doc.org/en/master/) and is located in `apps/opik-documentation/python-sdk-docs`.\n\nIn order to run the Python SDK reference documentation locally, you need to have `python` and `pip` installed. Once installed, you can run the documentation locally using the following command:\n\n```bash\ncd apps/opik-documentation/python-sdk-docs\n\n# Install dependencies - Only needs to be run once\npip install -r requirements.txt\n\n# Run the python sdk reference documentation locally\nmake dev\n```\n\nThe Python SDK reference documentation will be built and available at `http://127.0.0.1:8000`. Any change you make to the documentation will be updated in real-time.\n\n### Contributing to the Python SDK\n\n**Setting up your development environment:**\n\nIn order to develop features in the Python SDK, you will need to have Opik running locally. You can follow the instructions in the [Configuring your development environment](#configuring-your-development-environment) section or by running Opik locally with Docker Compose:\n\n```bash\ncd deployment/docker-compose\n\n# Starting the Opik platform\ndocker compose up --detach\n\n# Configure the Python SDK to point to the local Opik deployment\nopik configure --use_local\n```\n\nThe Opik server will be running on `http://localhost:5173`.\n\n**Submitting a PR:**\n\nThe Python SDK is available under `sdks/python` and can be installed locally using `pip install -e sdks/python`.\n\nBefore submitting a PR, please ensure that your code passes the test suite:\n\n```bash\ncd sdks/python\n\npytest tests/\n```\n\nand the linter:\n\n```bash\ncd sdks/python\n\npre-commit run --all-files\n```\n\n> [!NOTE]\n> If you changes impact public facing methods or docstrings, please also update the documentation. You can find more information about updating the docs in the [documentation contribution guide](#contributing-to-the-documentation).\n\n### Contributing to the frontend\n\nThe Opik frontend is a React application that is located in `apps/opik-frontend`.\n\nIn order to run the frontend locally, you need to have `npm` installed. Once installed, you can run the frontend locally using the following command:\n\n```bash\n# Run the backend locally with the flag \"--local-fe\"\n./build_and_run.sh --local-fe\n\ncd apps/opik-frontend\n\n# Install dependencies - Only needs to be run once\nnpm install\n\n# Run the frontend locally\nnpm run start\n```\n\nYou can then access the development frontend at `http://localhost:5173/`. Any change you make to the frontend will be updated in real-time.\n\n> You will need to open the FE using `http://localhost:5173/` ignoring the output from the `npm run start` command which will recommend to open `http://localhost:5174/`. In case `http://localhost:5174/` is opened, the BE will not be accessible.\n\nBefore submitting a PR, please ensure that your code passes the test suite, the linter and the type checker:\n\n```bash\ncd apps/opik-frontend\n\nnpm run e2e\nnpm run lint\nnpm run typecheck\n```\n\n### Contributing to the backend\n\nIn order to run the external services (Clickhouse, MySQL, Redis), you can use the `build_and_run.sh` script or `docker-compose`:\n\n```bash\ncd deployment/docker-compose\n\ndocker compose up clickhouse redis mysql -d\n```\n\n#### Running the backend\n\nThe Opik backend is a Java application that is located in `apps/opik-backend`.\n\nIn order to run the backend locally, you need to have `java` and `maven` installed. Once installed, you can run the backend locally using the following command:\n\n```bash\ncd apps/opik-backend\n\n# Build the Opik application\nmvn clean install\n\n# Start the Opik application\njava -jar target/opik-backend-{project.pom.version}.jar server config.yml\n```\nReplace `{project.pom.version}` with the version of the project in the pom file.\n\nOnce the backend is running, you can access the Opik API at `http://localhost:8080`.\n\n#### Formatting the code\n\nBefore submitting a PR, please ensure that your code is formatted correctly.\nRun the following command to automatically format your code:\n\n```bash\nmvn spotless:apply\n```\n\nOur CI will check that the code is formatted correctly and will fail if it is not by running the following command:\n\n```bash\nmvn spotless:check\n```\n\n#### Testing the backend\n\nBefore submitting a PR, please ensure that your code passes the test suite:\n\n```bash\ncd apps/opik-backend\n\nmvn test\n```\n\nTests leverage the `testcontainers` library to run integration tests against a real instances of the external services. Ports are randomly assigned by the library to avoid conflicts.\n\n#### Advanced usage\n\n*Health Check*\nTo see your applications health enter url `http://localhost:8080/healthcheck`\n\n**Run migrations**\n\n*DDL migrations*\n\nThe project handles it using [liquibase](https://www.liquibase.com/). Such migrations are located at `apps/opik-backend/src/main/resources/liquibase/{{DB}}/migrations` and executed via `apps/opik-backend/run_db_migrations.sh`. This process is automated via Docker image and helm chart.\n\nIn order to run DB DDL migrations manually, you will need to run:\n* Check pending migrations `java -jar target/opik-backend-{project.pom.version}.jar {database} status config.yml`\n* Run migrations `java -jar target/opik-backend-{project.pom.version}.jar {database} migrate config.yml`\n* Create schema tag `java -jar target/opik-backend-{project.pom.version}.jar {database} tag config.yml {tag_name}`\n* Rollback migrations `java -jar target/opik-backend-{project.pom.version}.jar {database} rollback config.yml --count 1` OR `java -jar target/opik-backend-{project.pom.version}.jar {database} rollback config.yml --tag {tag_name}`\n\nReplace `{project.pom.version}` with the version of the project in the pom file. Replace `{database}` with db for MySQL migrations and with `dbAnalytics` for ClickHouse migrations.\n\nRequirements:\n* Such migrations have to be backward compatible, which means:\n    - New fields must be optional or have default values\n    - In order to remove a column, all references to it must be removed at least one release before the column is dropped at the DB level.\n    - Renaming the column is forbidden unless the table is not currently being used.\n    - Renaming the table is forbidden unless the table is not currently being used.\n    - For more complex migration, apply the transition phase. Refer to [Evolutionary Database Design](https://martinfowler.com/articles/evodb.html)\n* It has to be independent of the code. \n* It must not cause downtime\n* It must have a unique name\n* It must contain a rollback statement or, in the case of Liquibase, the word `empty` is not possible. Refer to [link](https://docs.liquibase.com/workflows/liquibase-community/using-rollback.html)\n\n*DML migrations*\n\nIn such cases, migrations will not run automatically. They have to be run manually by the system admin via the database client. These migrations are documented via `CHANGELOG.md` and placed at `apps/opik-backend/data-migrations` together with all instructions required to run them.\n\nRequirements:\n* Such migrations have to be backward compatible, which means:\n    - Data shouldn't be deleted unless 100% safe\n    - It must not prevent rollback to the previous version\n    - It must not degrade performance after running\n    - For more complex migration, apply the transition phase. Refer to [Evolutionary Database Design](https://martinfowler.com/articles/evodb.html)\n* It must contain detailed instructions on how to run it\n* It must be batched appropriately to avoid disrupting operations \n* It must not cause downtime\n* It must have a unique name\n* It must contain a rollback statement or, in the case of Liquibase, the word `empty` is not possible. Refer to [link](https://docs.liquibase.com/workflows/liquibase-community/using-rollback.html).\n\n*Accessing Clickhouse*\n\nYou can curl the ClickHouse REST endpoint with `echo 'SELECT version()' | curl -H 'X-ClickHouse-User: opik' -H 'X-ClickHouse-Key: opik' 'http://localhost:8123/' -d @-`.\n\n```\nSHOW DATABASES\n\nQuery id: a9faa739-5565-4fc5-8843-5dc0f72ff46d\n\n‚îå‚îÄname‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ INFORMATION_SCHEMA ‚îÇ\n‚îÇ opik               ‚îÇ\n‚îÇ default            ‚îÇ\n‚îÇ information_schema ‚îÇ\n‚îÇ system             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n5 rows in set. Elapsed: 0.004 sec. \n```\n\nSample result: `23.8.15.35`\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.1240234375,
          "content": "Copyright (c) Comet ML, Inc\n                   \n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2024 Comet ML, Inc\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 18.9326171875,
          "content": "<h1 align=\"center\" style=\"border-bottom: none\">\n    <div>\n        <a href=\"https://www.comet.com/site/products/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=header_img&utm_campaign=opik\"><picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"/apps/opik-documentation/documentation/static/img/logo-dark-mode.svg\">\n            <source media=\"(prefers-color-scheme: light)\" srcset=\"/apps/opik-documentation/documentation/static/img/opik-logo.svg\">\n            <img alt=\"Comet Opik logo\" src=\"/apps/opik-documentation/documentation/static/img/opik-logo.svg\" width=\"200\" />\n        </picture></a>\n        <br>\n        Opik\n    </div>\n    Open source LLM evaluation framework<br>\n</h1>\n\n<p align=\"center\">\nFrom RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards.\n</p>\n\n<div align=\"center\">\n\n[![Python SDK](https://img.shields.io/pypi/v/opik)](https://pypi.org/project/opik/)\n[![License](https://img.shields.io/github/license/comet-ml/opik)](https://github.com/comet-ml/opik/blob/main/LICENSE)\n[![Build](https://github.com/comet-ml/opik/actions/workflows/build_apps.yml/badge.svg)](https://github.com/comet-ml/opik/actions/workflows/build_apps.yml)\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb\">\n\n  <!-- <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open Quickstart In Colab\"/> -->\n</a>\n\n</div>\n\n<p align=\"center\">\n    <a href=\"https://www.comet.com/site/products/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=website_button&utm_campaign=opik\"><b>Website</b></a> ‚Ä¢\n    <a href=\"https://chat.comet.com\"><b>Slack community</b></a> ‚Ä¢\n    <a href=\"https://x.com/Cometml\"><b>Twitter</b></a> ‚Ä¢\n    <a href=\"https://www.comet.com/docs/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=docs_button&utm_campaign=opik\"><b>Documentation</b></a>\n</p>\n\n![Opik thumbnail](readme-thumbnail.png)\n\n## üöÄ What is Opik?\n\nOpik is an open-source platform for evaluating, testing and monitoring LLM applications. Built by [Comet](https://www.comet.com?from=llm&utm_source=opik&utm_medium=github&utm_content=what_is_opik_link&utm_campaign=opik).\n\n<br>\n\nYou can use Opik for:\n* **Development:**\n\n  * **Tracing:** Track all LLM calls and traces during development and production ([Quickstart](https://www.comet.com/docs/opik/quickstart/?from=llm&utm_source=opik&utm_medium=github&utm_content=quickstart_link&utm_campaign=opik), [Integrations](https://www.comet.com/docs/opik/tracing/integrations/overview/?from=llm&utm_source=opik&utm_medium=github&utm_content=integrations_link&utm_campaign=opik)\n\n  * **Annotations:** Annotate your LLM calls by logging feedback scores using the [Python SDK](https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-and-spans-using-the-sdk?from=llm&utm_source=opik&utm_medium=github&utm_content=sdk_link&utm_campaign=opik) or the [UI](https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-through-the-ui?from=llm&utm_source=opik&utm_medium=github&utm_content=ui_link&utm_campaign=opik).\n\n  * **Playground:**: Try out different prompts and models in the [prompt playground](https://www.comet.com/docs/opik/evaluation/playground/?from=llm&utm_source=opik&utm_medium=github&utm_content=playground_link&utm_campaign=opik)\n\n* **Evaluation**: Automate the evaluation process of your LLM application:\n\n    * **Datasets and Experiments**: Store test cases and run experiments ([Datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&utm_source=opik&utm_medium=github&utm_content=datasets_link&utm_campaign=opik), [Evaluate your LLM Application](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&utm_source=opik&utm_medium=github&utm_content=eval_link&utm_campaign=opik))\n\n    * **LLM as a judge metrics**: Use Opik's LLM as a judge metric for complex issues like [hallucination detection](https://www.comet.com/docs/opik/evaluation/metrics/hallucination/?from=llm&utm_source=opik&utm_medium=github&utm_content=hallucination_link&utm_campaign=opik), [moderation](https://www.comet.com/docs/opik/evaluation/metrics/moderation/?from=llm&utm_source=opik&utm_medium=github&utm_content=moderation_link&utm_campaign=opik) and RAG evaluation ([Answer Relevance](https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance/?from=llm&utm_source=opik&utm_medium=github&utm_content=alex_link&utm_campaign=opik), [Context Precision](https://www.comet.com/docs/opik/evaluation/metrics/context_precision/?from=llm&utm_source=opik&utm_medium=github&utm_content=context_link&utm_campaign=opik)\n\n    * **CI/CD integration**: Run evaluations as part of your CI/CD pipeline using our [PyTest integration](https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&utm_source=opik&utm_medium=github&utm_content=pytest_link&utm_campaign=opik)\n\n* **Production Monitoring**:\n    \n    * **Log all your production traces**: Opik has been designed to support high volumes of traces, making it easy to monitor your production applications.\n    \n    * **Monitoring dashboards**: Review your feedback scores, trace count and tokens over time in the [Opik Dashboard](https://www.comet.com/docs/opik/self-host/opik_dashboard/?from=llm&utm_source=opik&utm_medium=github&utm_content=dashboard_link&utm_campaign=opik).\n\n> [!TIP]  \n> If you are looking for features that Opik doesn't have today, please raise a new [Feature request](https://github.com/comet-ml/opik/issues/new/choose) üöÄ\n\n<br>\n\n## üõ†Ô∏è Installation\nOpik is available as a fully open source local installation or using Comet.com as a hosted solution.\nThe easiest way to get started with Opik is by creating a free Comet account at [comet.com](https://www.comet.com/signup?from=llm&utm_source=opik&utm_medium=github&utm_content=install&utm_campaign=opik).\n\nIf you'd like to self-host Opik, you can do so by cloning the repository and starting the platform using Docker Compose:\n\n```bash\n# Clone the Opik repository\ngit clone https://github.com/comet-ml/opik.git\n\n# Navigate to the opik/deployment/docker-compose directory\ncd opik/deployment/docker-compose\n\n# Start the Opik platform\ndocker compose up --detach\n\n# You can now visit http://localhost:5173 on your browser!\n```\n\nFor more information about the different deployment options, please see our deployment guides:\n\n| Installation methods | Docs link |\n| ------------------- | --------- |\n| Local instance | [![Local Deployment](https://img.shields.io/badge/Local%20Deployments-%232496ED?style=flat&logo=docker&logoColor=white)](https://www.comet.com/docs/opik/self-host/local_deployment?from=llm&utm_source=opik&utm_medium=github&utm_content=self_host_link&utm_campaign=opik)\n| Kubernetes | [![Kubernetes](https://img.shields.io/badge/Kubernetes-%23326ce5.svg?&logo=kubernetes&logoColor=white)](https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&utm_source=opik&utm_medium=github&utm_content=kubernetes_link&utm_campaign=opik)\n\n\n## üèÅ Get Started\n\nTo get started, you will need to first install the Python SDK:\n\n```bash\npip install opik\n```\n\nOnce the SDK is installed, you can configure it by running the `opik configure` command:\n\n```bash\nopik configure\n```\n\nThis will allow you to configure Opik locally by setting the correct local server address or if you're using the Cloud platform by setting the API Key\n\n> [!TIP]  \n> You can also call the `opik.configure(use_local=True)` method from your Python code to configure the SDK to run on the local installation.\n\nYou are now ready to start logging traces using the [Python SDK](https://www.comet.com/docs/opik/python-sdk-reference/?from=llm&utm_source=opik&utm_medium=github&utm_content=sdk_link2&utm_campaign=opik).\n\n### üìù Logging Traces\n\nThe easiest way to get started is to use one of our integrations. Opik supports:\n\n| Integration | Description                                                                  | Documentation                                                                                                                                                      | Try in Colab                                                                                                                                                                                                                      |\n| ----------- | ---------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| OpenAI      | Log traces for all OpenAI LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/openai/?utm_source=opik&utm_medium=github&utm_content=openai_link&utm_campaign=opik)          | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/openai.ipynb)      |\n| LiteLLM     | Call any LLM model using the OpenAI format                                   | [Documentation](/tracing/integrations/litellm.md)                                                                                                                  | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/litellm.ipynb)     |\n| LangChain   | Log traces for all LangChain LLM calls                                       | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/langchain/?utm_source=opik&utm_medium=github&utm_content=langchain_link&utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langchain.ipynb)   |\n| Haystack    | Log traces for all Haystack calls                                            | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/haystack/?utm_source=opik&utm_medium=github&utm_content=haystack_link&utm_campaign=opik)      | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/haystack.ipynb)    |\n| Anthropic   | Log traces for all Anthropic LLM calls                                       | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/anthropic?utm_source=opik&utm_medium=github&utm_content=anthropic_link&utm_campaign=opik)     | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/anthropic.ipynb)   |\n| Bedrock     | Log traces for all Bedrock LLM calls                                         | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/bedrock?utm_source=opik&utm_medium=github&utm_content=bedrock_link&utm_campaign=opik)         | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/bedrock.ipynb)     |\n| DSPy        | Log traces for all DSPy runs                                                 | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/dspy?utm_source=opik&utm_medium=github&utm_content=dspy_link&utm_campaign=opik)               | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/dspy.ipynb)        |\n| Gemini      | Log traces for all Gemini LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/gemini?utm_source=opik&utm_medium=github&utm_content=gemini_link&utm_campaign=opik)           | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/gemini.ipynb)      |\n| Groq        | Log traces for all Groq LLM calls                                            | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/groq?utm_source=opik&utm_medium=github&utm_content=groq_link&utm_campaign=opik)               | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/groq.ipynb)        |\n| LangGraph   | Log traces for all LangGraph executions                                      | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/langgraph/?utm_source=opik&utm_medium=github&utm_content=langchain_link&utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langgraph.ipynb)   |\n| LlamaIndex  | Log traces for all LlamaIndex LLM calls                                      | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/llama_index?utm_source=opik&utm_medium=github&utm_content=llama_index_link&utm_campaign=opik) | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/llama-index.ipynb) |\n| Ollama      | Log traces for all Ollama LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/ollama?utm_source=opik&utm_medium=github&utm_content=ollama_link&utm_campaign=opik)           | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ollama.ipynb)      |\n| Predibase   | Fine-tune and serve open-source Large Language Models                        | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&utm_medium=github&utm_content=predibase_link&utm_campaign=opik)     | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb)   |\n| Ragas       | Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/ragas?utm_source=opik&utm_medium=github&utm_content=ragas_link&utm_campaign=opik)             | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ragas.ipynb)       |\n| watsonx     | Log traces for all watsonx LLM calls                                         | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/watsonx?utm_source=opik&utm_medium=github&utm_content=watsonx_link&utm_campaign=opik)         | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/watsonx.ipynb)     |\n\n> [!TIP]  \n> If the framework you are using is not listed above, feel free to [open an issue](https://github.com/comet-ml/opik/issues) or submit a PR with the integration.\n\nIf you are not using any of the frameworks above, you can also use the `track` function decorator to [log traces](https://www.comet.com/docs/opik/tracing/log_traces/?from=llm&utm_source=opik&utm_medium=github&utm_content=traces_link&utm_campaign=opik):\n\n```python\nimport opik\n\nopik.configure(use_local=True) # Run locally\n\n@opik.track\ndef my_llm_function(user_question: str) -> str:\n    # Your LLM code here\n\n    return \"Hello\"\n```\n\n> [!TIP]  \n> The track decorator can be used in conjunction with any of our integrations and can also be used to track nested function calls.\n\n### üßë‚Äç‚öñÔ∏è LLM as a Judge metrics\n\nThe Python Opik SDK includes a number of LLM as a judge metrics to help you evaluate your LLM application. Learn more about it in the [metrics documentation](https://www.comet.com/docs/opik/evaluation/metrics/overview/?from=llm&utm_source=opik&utm_medium=github&utm_content=metrics_2_link&utm_campaign=opik).\n\nTo use them, simply import the relevant metric and use the `score` function:\n\n```python\nfrom opik.evaluation.metrics import Hallucination\n\nmetric = Hallucination()\nscore = metric.score(\n    input=\"What is the capital of France?\",\n    output=\"Paris\",\n    context=[\"France is a country in Europe.\"]\n)\nprint(score)\n```\n\nOpik also includes a number of pre-built heuristic metrics as well as the ability to create your own. Learn more about it in the [metrics documentation](https://www.comet.com/docs/opik/evaluation/metrics/overview?from=llm&utm_source=opik&utm_medium=github&utm_content=metrics_3_link&utm_campaign=opik).\n\n### üîç Evaluating your LLM Application\n\nOpik allows you to evaluate your LLM application during development through [Datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&utm_source=opik&utm_medium=github&utm_content=datasets_2_link&utm_campaign=opik) and [Experiments](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&utm_source=opik&utm_medium=github&utm_content=experiments_link&utm_campaign=opik).\n\nYou can also run evaluations as part of your CI/CD pipeline using our [PyTest integration](https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&utm_source=opik&utm_medium=github&utm_content=pytest_2_link&utm_campaign=opik).\n\n## ü§ù Contributing\n\nThere are many ways to contribute to Opik:\n\n* Submit [bug reports](https://github.com/comet-ml/opik/issues) and [feature requests](https://github.com/comet-ml/opik/issues)\n* Review the documentation and submit [Pull Requests](https://github.com/comet-ml/opik/pulls) to improve it\n* Speaking or writing about Opik and [letting us know](https://chat.comet.com)\n* Upvoting [popular feature requests](https://github.com/comet-ml/opik/issues?q=is%3Aissue+is%3Aopen+label%3A%22enhancement%22) to show your support\n\nTo learn more about how to contribute to Opik, please see our [contributing guidelines](CONTRIBUTING.md).\n"
        },
        {
          "name": "apps",
          "type": "tree",
          "content": null
        },
        {
          "name": "build_and_run.sh",
          "type": "blob",
          "size": 6.140625,
          "content": "#!/bin/bash\nset -e\n\nOPIK_BACKEND=\"opik-backend\"\nOPIK_FRONTEND=\"opik-frontend\"\nOPIK_CLICKHOUSE=\"clickhouse-opik-clickhouse\"\nOPIK_MYSQL=\"opik-mysql\"\nOPIK_FRONTEND_PORT=5173\nOPIK_BACKEND_PORT=8080\nOPIK_OPENAPI_PORT=3003\nOPIK_CLICKHOUSE_PORT=8123\nOPIK_MYSQL_PORT=3306\nDOCKER_REGISTRY_LOCAL=\"local\" \nBUILD=true\nFE_BUILD=true\nHELM_UPDATE=true\nLOCAL_FE=false\nLOCAL_FE_PORT=${LOCAL_FE_PORT:-5174}\nCLOUD_VERSION=false\n\nfunction show_help() {\n    echo \"Usage: ./build_and_run.sh [OPTIONS]\"\n    echo \"\"\n    echo \"Options:\"\n    echo \"  --no-build          Skip the build process.\"\n    echo \"  --no-fe-build       Skip the FE build process.\"\n    echo \"  --no-helm-update    Skip helm repo update.\"\n    echo \"  --local-fe          Run FE locally.\"\n    echo \"  --cloud             Run it inside the /opik/ path.\"\n    echo \"  --help              Display this help message.\"\n    echo \"\"\n    echo \"Example:\"\n    echo \"  ./build_and_run.sh --no-build\"\n}\n\n# Parse command line arguments\nwhile [[ \"$#\" -gt 0 ]]; do\n    case $1 in\n        --no-build) BUILD=false ;;\n        --no-fe-build) FE_BUILD=false ;;\n        --no-helm-update) HELM_UPDATE=false ;;\n        --local-fe) LOCAL_FE=true ;;\n        --cloud) CLOUD_VERSION=true ;;\n        --help) show_help; exit 0 ;;\n        *) echo \"Unknown parameter passed: $1\"; show_help; exit 1 ;;\n    esac\n    shift\ndone\n\n# Check if Minikube is running\nif minikube status | grep -q \"host: Running\"; then\n  echo \"Minikube is running.\"\nelse\n  echo \"Minikube is not running, starting minikube..\"\n  minikube start\nfi\n\n# Switch kubectl context to Minikube\nkubectl config use-context minikube\n\nif $BUILD; then\n    #### Building docker images\n    eval $(minikube docker-env)\n    echo \"### Build docker images\"\n\n    echo \"## Build Opik backend\"\n    cd apps/${OPIK_BACKEND}\n    DOCKER_IMAGE_NAME=${DOCKER_REGISTRY_LOCAL}/${OPIK_BACKEND}:latest\n    echo \"DOCKER_IMAGE_NAME is ${DOCKER_IMAGE_NAME}\"\n    DOCKER_BUILDKIT=1 docker build --build-arg OPIK_VERSION=latest -t ${DOCKER_IMAGE_NAME} .\n    cd -\n\n    if $FE_BUILD; then\n        echo \"## Build Opik frontend\"\n        cd apps/${OPIK_FRONTEND}\n        DOCKER_IMAGE_NAME=${DOCKER_REGISTRY_LOCAL}/${OPIK_FRONTEND}:latest\n        echo \"DOCKER_IMAGE_NAME is ${DOCKER_IMAGE_NAME}\"\n        DOCKER_FE_BUILD_ARGS=\"\"\n        if [[ \"${CLOUD_VERSION}\" == \"true\" ]]; then\n          DOCKER_FE_BUILD_ARGS=\"--build-arg BUILD_MODE=comet\"\n        fi\n\n        DOCKER_BUILDKIT=1 docker build \\\n            --build-arg OPIK_VERSION=latest \\\n            ${DOCKER_FE_BUILD_ARGS} \\\n            -t ${DOCKER_IMAGE_NAME} .\n        cd -\n    fi\nfi\n\n### Install/upgrade Opik on minikube\necho \necho \"### Install Opik using latest versions\"\ncd deployment/helm_chart/opik\nVERSION=latest\n\nif [[ \"${LOCAL_FE}\" == \"true\" ]]; then\n  LOCAL_FE_FLAGS=\"--set localFE=true\"\n  if [ -z \"${LOCAL_FE_HOST}\" ] ; then\n    if [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n      LOCAL_FE_HOST=$(ifconfig | grep 'inet ' | grep -vF '127.0.0.1' | awk '{print $2}' | head -n 1)\n    else\n      LOCAL_FE_HOST=$(hostname -I | awk '{print $1}')\n    fi\n  fi\n  LOCAL_FE_FLAGS=\"${LOCAL_FE_FLAGS} --set localFEAddress=${LOCAL_FE_HOST}:${LOCAL_FE_PORT}\";\nfi\n\nCLOUD_VERSION_FLAGS=\"\"\nif [[ \"${CLOUD_VERSION}\" == \"true\" ]]; then\n  CLOUD_VERSION_FLAGS=\"--set standalone=false\"\nfi\n\n\nif $HELM_UPDATE; then\n  helm repo add bitnami https://charts.bitnami.com/bitnami\n  helm repo add clickhouse-operator https://docs.altinity.com/clickhouse-operator\n  helm dependency build\nfi\nhelm upgrade --install opik -n opik --create-namespace -f values.yaml \\\n    --set registry=${DOCKER_REGISTRY_LOCAL} \\\n    --set component.backend.image.tag=$VERSION --set component.frontend.image.tag=$VERSION \\\n    ${LOCAL_FE_FLAGS} ${CLOUD_VERSION_FLAGS} .\n\ncd -\nkubectl config set-context --current --namespace=opik\necho \"Delete current pods\"\nkubectl delete po -l component=${OPIK_BACKEND}\nkubectl delete po -l component=${OPIK_FRONTEND}\n\necho\necho \"### Check if the pods are running\"\n\nTIMEOUT=180  # Timeout in seconds (e.g., 3 minutes)\nINTERVAL=5   # Interval in seconds between checks\nPOD_NAME=${OPIK_BACKEND}\n\nis_pod_running() {\n  kubectl get pods| grep $POD_NAME | grep Running &> /dev/null\n  return $?\n}\nSTART_TIME=$(date +%s)\nwhile true; do\n  if is_pod_running; then\n    echo \"Pod $POD_NAME is running \"\n    echo\n    break\n  else\n    echo \"Checking if pods are running...\"\n  fi\n  # Check if the timeout has been reached\n  CURRENT_TIME=$(date +%s)\n  ELAPSED_TIME=$((CURRENT_TIME - START_TIME))\n  if [ $ELAPSED_TIME -ge $TIMEOUT ]; then\n    echo \"Timeout reached: Pod $POD_NAME is not running\"\n    echo \"To check run 'kubectl get pods' and continue investigating from there\"\n    exit 1\n  fi\n  sleep $INTERVAL\ndone\n\necho \"### Waiting for pods\"\nkubectl wait --for=condition=ready pod --all\n\necho \"### Port-forward Opik Frontend to local host\"\n# remove the previous port-forward\nps -ef | grep \"svc/${OPIK_FRONTEND} ${OPIK_FRONTEND_PORT}\" | grep -v grep | awk '{print $2}' | xargs kill 2>/dev/null|| true\nkubectl port-forward svc/${OPIK_FRONTEND} ${OPIK_FRONTEND_PORT} > /dev/null 2>&1 &\n\necho \"### Port-forward Opik Backend to local host\"\n# remove the previous port-forward\nps -ef | grep \"svc/${OPIK_BACKEND} ${OPIK_BACKEND_PORT}\" | grep -v grep | awk '{print $2}' | xargs kill 2>/dev/null|| true\nkubectl port-forward svc/${OPIK_BACKEND} ${OPIK_BACKEND_PORT} > /dev/null 2>&1 &\n\necho \"### Port-forward Open API to local host\"\n# remove the previous port-forward\nps -ef | grep \"svc/${OPIK_BACKEND} ${OPIK_OPENAPI_PORT}\" | grep -v grep | awk '{print $2}' | xargs kill 2>/dev/null|| true\nkubectl port-forward svc/${OPIK_BACKEND} ${OPIK_OPENAPI_PORT} > /dev/null 2>&1 &\n\necho \"### Port-forward Clickhouse to local host\"\n# remove the previous port-forward\nps -ef | grep \"svc/${OPIK_CLICKHOUSE} ${OPIK_CLICKHOUSE_PORT}\" | grep -v grep | awk '{print $2}' | xargs kill 2>/dev/null|| true\nkubectl port-forward svc/${OPIK_CLICKHOUSE} ${OPIK_CLICKHOUSE_PORT} > /dev/null 2>&1 &\n\necho \"### Port-forward MySQL to local host\"\n# remove the previous port-forward\nps -ef | grep \"svc/${OPIK_MYSQL} ${OPIK_MYSQL_PORT}\" | grep -v grep | awk '{print $2}' | xargs kill 2>/dev/null|| true\nkubectl port-forward svc/${OPIK_MYSQL} ${OPIK_MYSQL_PORT} > /dev/null 2>&1 &\n\necho \"Now you can open your browser and connect http://localhost:${OPIK_FRONTEND_PORT}\"\n"
        },
        {
          "name": "deployment",
          "type": "tree",
          "content": null
        },
        {
          "name": "hooks-install.sh",
          "type": "blob",
          "size": 0.169921875,
          "content": "#!/bin/sh\n\n# Copy the pre-commit hook to the Git hooks directory\ncp .hooks/pre-commit .git/hooks/pre-commit\nchmod +x .git/hooks/pre-commit\n\necho \"Pre-commit hook installed.\"\n"
        },
        {
          "name": "hooks-remove.sh",
          "type": "blob",
          "size": 0.2060546875,
          "content": "#!/bin/sh\n\n# Remove the pre-commit hook from the Git hooks directory\nif [ -f .git/hooks/pre-commit ]; then\n  rm .git/hooks/pre-commit\n  echo \"Pre-commit hook removed.\"\nelse\n  echo \"No pre-commit hook found.\"\nfi\n"
        },
        {
          "name": "readme-thumbnail.png",
          "type": "blob",
          "size": 852.736328125,
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "sdks",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests_end_to_end",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.005859375,
          "content": "1.3.5\n"
        }
      ]
    }
  ]
}