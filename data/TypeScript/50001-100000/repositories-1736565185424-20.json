{
  "metadata": {
    "timestamp": 1736565185424,
    "page": 20,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/superset",
      "stars": 63749,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 2.8935546875,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# https://cwiki.apache.org/confluence/display/INFRA/.asf.yaml+features+for+git+repositories\n---\ngithub:\n  description: \"Apache Superset is a Data Visualization and Data Exploration Platform\"\n  homepage: https://superset.apache.org/\n  labels:\n    - superset\n    - apache\n    - apache-superset\n    - data-visualization\n    - data-viz\n    - analytics\n    - business-intelligence\n    - data-science\n    - data-engineering\n    - asf\n    - bi\n    - business-analytics\n    - data-analytics\n    - data-analysis\n    - data-science\n    - python\n    - react\n    - sql-editor\n    - flask\n  features:\n    # Enable issues management\n    issues: true\n    # Enable projects for project management boards\n    projects: true\n    # Enable wiki for documentation\n    wiki: true\n\n  enabled_merge_buttons:\n    squash: true\n    merge: false\n    rebase: false\n\n  ghp_branch:  gh-pages\n  ghp_path: /\n\n  protected_branches:\n    master:\n      required_status_checks:\n        # strict means \"Require branches to be up to date before merging\".\n        strict: false\n        # contexts are the names of checks that must pass\n        # unfortunately AFAICT for `matrix:` jobs, we have to itemize every\n        # combination here.\n        contexts:\n          - lint-check\n          - cypress-matrix (0, chrome)\n          - cypress-matrix (1, chrome)\n          - cypress-matrix (2, chrome)\n          - cypress-matrix (3, chrome)\n          - cypress-matrix (4, chrome)\n          - cypress-matrix (5, chrome)\n          - dependency-review\n          - frontend-build\n          - pre-commit (current)\n          - pre-commit (previous)\n          - test-mysql\n          - test-postgres (current)\n          - test-postgres-hive\n          - test-postgres-presto\n          - test-sqlite\n          - unit-tests (current)\n\n      required_pull_request_reviews:\n        dismiss_stale_reviews: false\n        require_code_owner_reviews: true\n        required_approving_review_count: 1\n\n      required_signatures: false\n    gh-pages:\n      required_pull_request_reviews:\n        dismiss_stale_reviews: false\n        require_code_owner_reviews: true\n        required_approving_review_count: 1\n\n      required_signatures: false\n"
        },
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 0.8896484375,
          "content": "codecov:\n    notify:\n        after_n_builds: 4\nignore:\n  - \"superset/migrations/versions/*.py\"\n  - \"superset-frontend/packages/superset-ui-demo/**/*\"\n  - \"**/*.stories.tsx\"\n  - \"**/*.stories.jsx\"\ncoverage:\n  status:\n    project:\n      default:\n        informational: true\n        # Commits pushed to master should not make the overall\n        # project coverage decrease:\n        target: auto\n        threshold: 0%\n      core-packages-ts:\n        target: 100%\n        paths:\n          - 'superset-frontend/packages'\n          - '!superset-frontend/packages/**/*.jsx'\n          - '!superset-frontend/packages/**/*.tsx'\n      core-packages-tsx:\n        target: 50%\n        paths:\n          - 'superset-frontend/packages/**/*.jsx'\n          - 'superset-frontend/packages/**/*.tsx'\n    patch:\n      default:\n        informational: true\n        threshold: 0%\nflag_management:\n  default_rules:\n    carryforward: true\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 1.2109375,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n**/__pycache__/\n**/.git\n**/.apache_superset.egg-info\n**/.github\n**/.mypy_cache\n**/.pytest_cache\n**/.tox\n**/.vscode\n**/.idea\n**/.coverage\n**/.DS_Store\n**/.eggs\n**/.python-version\n**/*.egg-info\n**/*.bak\n**/*.db\n**/*.pyc\n**/*.sqllite\n**/*.swp\n**/.terser-plugin-cache/\n**/node_modules/\n\ntests/\ndocs/\ninstall/\nsuperset-frontend/cypress-base/\nsuperset-frontend/coverage/\nsuperset-frontend/.temp_cache/\nsuperset/static/assets/\nsuperset-websocket/dist/\nvenv\n.venv\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 1.3330078125,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# EditorConfig is awesome: https://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n# Unix-style newlines with a newline ending every file\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\n\n# 4 space indentation for Python files\n[*.py]\nindent_style = space\nindent_size = 4\nmax_line_length=88\n\n# 2 space indentation for Frontend files\n[*.{js,jsx,ts,tsx,html,less,css}]\nindent_style = space\nindent_size = 2\n\n# 2 space indentation for json and yaml files\n[*.{json,yml}]\nindent_style = space\nindent_size = 2\n\n# Tab indentation\n[Makefile]\nindent_style = tab\n"
        },
        {
          "name": ".flaskenv",
          "type": "blob",
          "size": 0.8193359375,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nFLASK_APP=\"superset.app:create_app()\"\nFLASK_DEBUG=true\n"
        },
        {
          "name": ".fossa.yml",
          "type": "blob",
          "size": 1.1484375,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Generated by FOSSA CLI (https://github.com/fossas/fossa-cli)\n# Visit https://fossa.com to learn more\n\nversion: 2\ncli:\n  server: https://app.fossa.com\n  fetcher: custom\nanalyze:\n  modules:\n  - name: assets\n    type: npm\n    target: superset-frontend\n    path: superset-frontend\n  - name: base\n    type: pip\n    target: .\n    path: .\n    options:\n      requirements: ./requirements/base.txt\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0537109375,
          "content": "docker/**/*.sh text eol=lf\n*.svg binary\n*.ipynb binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.30859375,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n*.bak\n*.db\n*.pyc\n*.sqllite\n*.swp\n__pycache__\n\n.local\n.cache\n.bento*\n.cache-loader\n.coverage\ncover\n.DS_Store\n.eggs\n.env\n.envrc\n.idea\n.mypy_cache\n.python-version\n.tox\n.vscode\n_build\n_images\n_modules\n_static\nbuild\napp.db\napache_superset.egg-info/\nchangelog.sh\ndist\ndump.rdb\nenv\nvenv*\nenv_py3\nenvpy3\nenv36\nlocal_config.py\n/superset_config.py\n/superset_text.yml\nsuperset.egg-info/\nsuperset/bin/supersetc\ntmp\nrat-results.txt\nsuperset/app/\nsuperset-websocket/config.json\n\n# Node.js, webpack artifacts, storybook\n*.entry.js\n*.js.map\nnode_modules\nnpm-debug.log*\nsuperset/static/assets\nsuperset/static/version_info.json\nsuperset-frontend/**/esm/*\nsuperset-frontend/**/lib/*\nsuperset-frontend/**/storybook-static/*\nsuperset-frontend/migration-storybook.log\nyarn-error.log\n*.map\n*.min.js\ntest-changelog.md\n*.tsbuildinfo\n\n# Ignore package-lock in packages\nplugins/*/package-lock.json\npackages/*/package-lock.json\n\n# For country map geojson conversion script\n.ipynb_checkpoints/\nscripts/*.zip\n\n# IntelliJ\n*.iml\nvenv\n@eaDir/\n\n# PyCharm\n.run\n\n# Test data\ncelery_results.sqlite\ncelerybeat-schedule\ncelerydb.sqlite\ncelerybeat.pid\ngeckodriver.log\nghostdriver.log\ntestCSV.csv\n.terser-plugin-cache/\napache-superset-*.tar.gz*\nrelease.json\n\n# Translation-related files\n# these json files are generated by ./scripts/po2json.sh\nsuperset/translations/**/messages.json\n# these mo binary files are generated by `pybabel compile`\nsuperset/translations/**/messages.mo\n\ndocker/requirements-local.txt\n\ncache/\ndocker/*local*\n\n.temp_cache\n\n# Jest test report\ntest-report.html\nsuperset/static/stats/statistics.html\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.9384765625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n[submodule \".github/actions/latest-tag\"]\n\tpath = .github/actions/latest-tag\n\turl = https://github.com/EndBug/latest-tag\n[submodule \".github/actions/pr-lint-action\"]\n\tpath = .github/actions/pr-lint-action\n\turl = https://github.com/morrisoncole/pr-lint-action\n[submodule \".github/actions/file-changes-action\"]\n\tpath = .github/actions/file-changes-action\n\turl = https://github.com/trilom/file-changes-action\n[submodule \".github/actions/cached-dependencies\"]\n\tpath = .github/actions/cached-dependencies\n\turl = https://github.com/apache-superset/cached-dependencies\n[submodule \".github/actions/comment-on-pr\"]\n\tpath = .github/actions/comment-on-pr\n\turl = https://github.com/unsplash/comment-on-pr\n[submodule \".github/actions/chart-testing-action\"]\n\tpath = .github/actions/chart-testing-action\n\turl = https://github.com/helm/chart-testing-action\n[submodule \".github/actions/chart-releaser-action\"]\n\tpath = .github/actions/chart-releaser-action\n\turl = https://github.com/helm/chart-releaser-action\n[submodule \".github/actions/github-action-push-to-another-repository\"]\n\tpath = .github/actions/github-action-push-to-another-repository\n\turl = https://github.com/cpina/github-action-push-to-another-repository\n"
        },
        {
          "name": ".markdownlint.json",
          "type": "blob",
          "size": 0.05078125,
          "content": "{\n  \"no-bare-urls\": false,\n  \"line-length\": false\n}\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.798828125,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nrepos:\n  - repo: https://github.com/MarcoGorelli/auto-walrus\n    rev: 0.3.4\n    hooks:\n      - id: auto-walrus\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.13.0\n    hooks:\n      - id: mypy\n        args: [--check-untyped-defs]\n        additional_dependencies: [\n            types-simplejson,\n            types-python-dateutil,\n            types-requests,\n            # types-redis 4.6.0.5 is failing mypy\n            # because of https://github.com/python/typeshed/pull/10531\n            types-redis==4.6.0.4,\n            types-pytz,\n            types-croniter,\n            types-PyYAML,\n            types-setuptools,\n            types-paramiko,\n            types-Markdown,\n          ]\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-docstring-first\n      - id: check-added-large-files\n        exclude: ^.*\\.(geojson)$|^docs/static/img/screenshots/.*|^superset-frontend/CHANGELOG\\.md$\n      - id: check-yaml\n        exclude: ^helm/superset/templates/\n      - id: debug-statements\n      - id: end-of-file-fixer\n        exclude: .*/lerna\\.json$\n      - id: trailing-whitespace\n        exclude: ^.*\\.(snap)\n        args: [\"--markdown-linebreak-ext=md\"]\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v4.0.0-alpha.8 # Use the sha or tag you want to point at\n    hooks:\n      - id: prettier\n        additional_dependencies:\n          - prettier@3.3.3\n        args: [\"--ignore-path=./superset-frontend/.prettierignore\"]\n        files: \"superset-frontend\"\n  # blacklist unsafe functions like make_url (see #19526)\n  - repo: https://github.com/skorokithakis/blacklist-pre-commit-hook\n    rev: e2f070289d8eddcaec0b580d3bde29437e7c8221\n    hooks:\n      - id: blacklist\n        args: [\"--blacklisted-names=make_url\", \"--ignore=tests/\"]\n  - repo: https://github.com/norwoodj/helm-docs\n    rev: v1.14.2\n    hooks:\n      - id: helm-docs\n        files: helm\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.0\n    hooks:\n      - id: ruff\n        args: [ --fix ]\n      - id: ruff-format\n"
        },
        {
          "name": ".rat-excludes",
          "type": "blob",
          "size": 1.0712890625,
          "content": "# Note: these patterns are applied to single files or directories, not full paths\n.gitignore\n.gitattributes\n.gitkeep\n.coverage\n.coveragerc\n.codecov.yml\n.eslintrc\n.eslintignore\n.flake8\n.nvmrc\n.prettierrc\n.rat-excludes\n.*log\n.*pyc\n.*lock\n.*geojson\nDISCLAIMER\nlicenses/*\nnode_modules/*\nrat-results.txt\nbabel-node\ndist\nsuperset/static/*\nbuild\nsuperset.egg-info\napache_superset.egg-info\n.idea\n.*sql\n.*zip\n.*lock\n# json and csv in general cannot have comments\n.*json\n.*csv\n# Generated doc files\nenv/*\ndocs/.htaccess*\n.nojekyll\n_build/*\n_static/*\n.buildinfo\nsearchindex.js\n# auto generated\nrequirements/*\n# vendorized\nvendor/*\n# github configuration\n.github/*\n.*mdx\n\n# skip license check in superset-ui\ntmp/*\nlib/*\nesm/*\ntsconfig.tsbuildinfo\n.*ipynb\n.*yml\n.*iml\n.esprintrc\n.prettierignore\ngenerator-superset/*\ntemporary_superset_ui/*\n\n# skip license checks for auto-generated test snapshots\n.*snap\n\n# docs overrides for third party logos we don't have the rights to\ngoogle-big-query.svg\ngoogle-sheets.svg\nibm-db2.svg\npostgresql.svg\nsnowflake.svg\nydb.svg\n\n# docs-related\nerd.puml\nerd.svg\nintro_header.txt\n"
        },
        {
          "name": "ASF",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 1.54296875,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n## Change Log\n\n- [1.4.1](./CHANGELOG/1.4.1.md)\n- [1.4.2](./CHANGELOG/1.4.2.md)\n- [1.5.0](./CHANGELOG/1.5.0.md)\n- [1.5.1](./CHANGELOG/1.5.1.md)\n- [1.5.2](./CHANGELOG/1.5.2.md)\n- [1.5.3](./CHANGELOG/1.5.3.md)\n- [2.0.0](./CHANGELOG/2.0.0.md)\n- [2.0.1](./CHANGELOG/2.0.1.md)\n- [2.1.0](./CHANGELOG/2.1.0.md)\n- [2.1.1](./CHANGELOG/2.1.1.md)\n- [2.1.2](./CHANGELOG/2.1.2.md)\n- [2.1.3](./CHANGELOG/2.1.3.md)\n- [3.0.0](./CHANGELOG/3.0.0.md)\n- [3.0.1](./CHANGELOG/3.0.1.md)\n- [3.0.2](./CHANGELOG/3.0.2.md)\n- [3.0.3](./CHANGELOG/3.0.3.md)\n- [3.0.4](./CHANGELOG/3.0.4.md)\n- [3.1.0](./CHANGELOG/3.1.0.md)\n- [3.1.1](./CHANGELOG/3.1.1.md)\n- [3.1.2](./CHANGELOG/3.1.2.md)\n- [3.1.3](./CHANGELOG/3.1.3.md)\n- [4.0.0](./CHANGELOG/4.0.0.md)\n- [4.0.1](./CHANGELOG/4.0.1.md)\n- [4.0.2](./CHANGELOG/4.0.2.md)\n- [4.1.0](./CHANGELOG/4.1.0.md)\n"
        },
        {
          "name": "CHANGELOG",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 12.70703125,
          "content": "<!--\n    Licensed to the Apache Software Foundation (ASF) under one\n    or more contributor license agreements.  See the NOTICE file\n    distributed with this work for additional information\n    regarding copyright ownership.  The ASF licenses this file\n    to you under the Apache License, Version 2.0 (the\n    \"License\"); you may not use this file except in compliance\n    with the License.  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing,\n    software distributed under the License is distributed on an\n    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n    KIND, either express or implied.  See the License for the\n    specific language governing permissions and limitations\n    under the License.\n-->\n# CODE OF CONDUCT\n\n*The following is copied for your convenience from <https://www.apache.org/foundation/policies/conduct.html>. If there's a discrepancy between the two, let us know or submit a PR to fix it.*\n\n## INTRODUCTION\n\nThis code of conduct applies to all spaces managed by the Apache Software Foundation, including IRC, all public and private mailing lists, issue trackers, wikis, blogs, Twitter, and any other communication channel used by our communities. A code of conduct which is specific to in-person events (ie., conferences) is codified in the published ASF anti-harassment policy.\n\nWe expect this code of conduct to be honored by everyone who participates in the Apache community formally or informally, or claims any affiliation with the Foundation, in any Foundation-related activities and especially when representing the ASF, in any role.\n\nThis code is __not exhaustive or complete__. It serves to distill our common understanding of a collaborative, shared environment and goals. We expect it to be followed in spirit as much as in the letter, so that it can enrich all of us and the technical communities in which we participate.\n\n## SPECIFIC GUIDELINES\n\nWe strive to:\n\n1. **Be open.** We invite anyone to participate in our community. We preferably use public methods of communication for project-related messages, unless discussing something sensitive. This applies to messages for help or project-related support, too; not only is a public support request much more likely to result in an answer to a question, it also makes sure that any inadvertent mistakes made by people answering will be more easily detected and corrected.\n\n2. **Be empathetic, welcoming, friendly, and patient.** We work together to resolve conflict, assume good intentions, and do our best to act in an empathetic fashion. We may all experience some frustration from time to time, but we do not allow frustration to turn into a personal attack. A community where people feel uncomfortable or threatened is not a productive one. We should be respectful when dealing with other community members as well as with people outside our community.\n\n3. **Be collaborative.** Our work will be used by other people, and in turn we will depend on the work of others. When we make something for the benefit of the project, we are willing to explain to others how it works, so that they can build on the work to make it even better. Any decision we make will affect users and colleagues, and we take those consequences seriously when making decisions.\n\n4. **Be inquisitive.** Nobody knows everything! Asking questions early avoids many problems later, so questions are encouraged, though they may be directed to the appropriate forum. Those who are asked should be responsive and helpful, within the context of our shared goal of improving Apache project code.\n\n5. **Be careful in the words that we choose.** Whether we are participating as professionals or volunteers, we value professionalism in all interactions, and take responsibility for our own speech. Be kind to others. Do not insult or put down other participants. Harassment and other exclusionary behavior are not acceptable. This includes, but is not limited to:\n    * Violent threats or language directed against another person.\n    * Sexist, racist, or otherwise discriminatory jokes and language.\n    * Posting sexually explicit or violent material.\n    * Posting (or threatening to post) other people's personally identifying information (\"doxing\").\n    * Sharing private content, such as emails sent privately or non-publicly, or unlogged forums such as IRC channel history.\n    * Personal insults, especially those using racist or sexist terms.\n    * Unwelcome sexual attention.\n    * Excessive or unnecessary profanity.\n    * Repeated harassment of others. In general, if someone asks you to stop, then stop.\n    * Advocating for, or encouraging, any of the above behavior.\n\n6. **Be concise.** Keep in mind that what you write once will be read by hundreds of persons. Writing a short email means people can understand the conversation as efficiently as possible. Short emails should always strive to be empathetic, welcoming, friendly and patient. When a long explanation is necessary, consider adding a summary.\n\n    Try to bring new ideas to a conversation so that each mail adds something unique to the thread, keeping in mind that the rest of the thread still contains the other messages with arguments that have already been made.\n\n    Try to stay on topic, especially in discussions that are already fairly large.\n\n7. **Step down considerately.** Members of every project come and go. When somebody leaves or disengages from the project they should tell people they are leaving and take the proper steps to ensure that others can pick up where they left off. In doing so, they should remain respectful of those who continue to participate in the project and should not misrepresent the project's goals or achievements. Likewise, community members should respect any individual's choice to leave the project.\n\n## DIVERSITY STATEMENT\n\nApache welcomes and encourages participation by everyone. We are committed to being a community that everyone feels good about joining. Although we may not be able to satisfy everyone, we will always work to treat everyone well.\n\nNo matter how you identify yourself or how others perceive you: we welcome you. Though no list can hope to be comprehensive, we explicitly honour diversity in: age, culture, ethnicity, genotype, gender identity or expression, language, national origin, neurotype, phenotype, political beliefs, profession, race, religion, sexual orientation, socioeconomic status, subculture and technical ability.\n\nThough we welcome people fluent in all languages, Apache development is conducted in English.\n\nStandards for behaviour in the Apache community are detailed in the Code of Conduct above. We expect participants in our community to meet these standards in all their interactions and to help others to do so as well.\n\n## REPORTING GUIDELINES\n\nWhile this code of conduct should be adhered to by participants, we recognize that sometimes people may have a bad day, or be unaware of some of the guidelines in this code of conduct. When that happens, you may reply to them and point out this code of conduct. Such messages may be in public or in private, whatever is most appropriate. However, regardless of whether the message is public or not, it should still adhere to the relevant parts of this code of conduct; in particular, it should not be abusive or disrespectful.\n\nIf you believe someone is violating this code of conduct, you may reply to them and point out this code of conduct. Such messages may be in public or in private, whatever is most appropriate. Assume good faith; it is more likely that participants are unaware of their bad behaviour than that they intentionally try to degrade the quality of the discussion. Should there be difficulties in dealing with the situation, you may report your compliance issues in confidence to either:\n\n* President of the Apache Software Foundation: Sam Ruby (rubys at intertwingly dot net)\n\nOr one of our volunteers:\n\n* [Mark Thomas](https://www.linkedin.com/in/mark-thomas-b16751158/)\n* [Joan Touzet](https://www.apache.org/foundation/conduct-team/wohali.html)\n* [Sharan Foga](https://www.linkedin.com/in/sfoga/)\n\nIf the violation is in documentation or code, for example inappropriate pronoun usage or word choice within official documentation, we ask that people report these privately to the project in question at <private@project.apache.org>, and, if they have sufficient ability within the project, to resolve or remove the concerning material, being mindful of the perspective of the person originally reporting the issue.\n\n## ENDNOTES\n\nThis Code defines **empathy** as \"a vicarious participation in the emotions, ideas, or opinions of others; the ability to imagine oneself in the condition or predicament of another.\" **Empathetic** is the adjectival form of empathy.\n\nThis statement thanks the following, on which it draws for content and inspiration:\n\n* [CouchDB Project Code of conduct](http://couchdb.apache.org/conduct.html)\n* [Fedora Project Code of Conduct](http://fedoraproject.org/code-of-conduct)\n* [Speak Up! Code of Conduct](http://web.archive.org/web/20141109123859/http://speakup.io/coc.html)\n* [Django Code of Conduct](https://www.djangoproject.com/conduct/)\n* [Debian Code of Conduct](https://www.debian.org/vote/2014/vote_002)\n* [Twitter Open Source Code of Conduct](https://github.com/twitter/code-of-conduct/blob/master/code-of-conduct.md)\n* [Mozilla Code of Conduct/Draft](https://wiki.mozilla.org/Code_of_Conduct/Draft#Conflicts_of_Interest)\n* [Python Diversity Appendix](https://www.python.org/community/diversity/)\n* [Python Mentors Home Page](http://pythonmentors.com)\n\n\n# Slack Community Guidelines\n\nIf you decide to join the [Community Slack](http://bit.ly/join-superset-slack), please adhere to the following rules:\n\n**1. Treat everyone in the community with respect.**\n\n- We strive to make this community a warm place for people from all industries, use cases, geographies, and backgrounds. Harassment of any kind is not acceptable and won’t be tolerated.\n- Please follow the guidelines as outlined in the Superset Community [code of conduct here](https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.md).\n\n**2. Use the right channel.**\n\n- Channels are an effective way to organize and focus discussions while also empowering members to opt-in to the types of content they’re interested in. When questions are posted or discussions are started in the wrong channel, it dilutes the trust of the members in the channel and, more practically, makes it harder for your questions to be answered.\n\n**3. Ask thoughtful questions.**\n\n- We’re all here to help each other out. The best way to get help is by investing effort into your questions. First check and see if your question is answered in the [Superset documentation](https://superset.apache.org/faq.html) or on [StackOverflow](https://stackoverflow.com/questions/tagged/apache-superset). You can also check GitHub trackers to see if your inquiry has been submitted before: [GitHub discussions](https://github.com/apache/superset/discussions) for questions and feature requests and [GitHub issues](https://github.com/apache/superset/issues) for bug reports. Then, use Slack search to see if your question has already been asked and answered in the past.\n\nIf you still feel the need to ask a question, make sure you include:\n\n- The steps you’ve already taken.\n- Relevant details presented cleanly: text stacktraces, formatted markdown, or screenshots. Please don’t paste large blocks of code unformatted or post photos of your screen from your phone.\n- The specific question you have or the specific type of help you're seeking.\n\n**4. Avoid double posting**\n\n- This Slack community is not a customer support channel and all members are here voluntarily. If you aren’t getting a response to a question you have, make sure you look at rules 1, 2, and 3.  It’s also worth remembering that there may not be someone in the community who has the context to help you out.\n\n**5. Communicate openly**\n\n- Unless you have explicit permission from the person, please avoid sending direct messages to individuals. Communicating in public channels ensures that we’re all respecting each other’s attentions and we can scalably moderate our communication to mitigate harassment or discrimination. Do not use direct messages to pitch products and services. If you are receiving unwelcome direct messages, please notify an admin.\n\n**6. Practice good Slack hygiene by using threads for discussions and emojis for light reactions.**\n\n- The medium is the message. Slack can foster a warm, collaborative, and organized community when used effectively. We want to respect people’s attentions (thread notifications > channel notifications > DM notifications) and we want to improve information density (a member should be able to browse and explore many convo threads, not just see one thread discussed in a top level channel).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.1240234375,
          "content": "<!--\n Licensed to the Apache Software Foundation (ASF) under one\n or more contributor license agreements.  See the NOTICE file\n distributed with this work for additional information\n regarding copyright ownership.  The ASF licenses this file\n to you under the Apache License, Version 2.0 (the\n \"License\"); you may not use this file except in compliance\n with the License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing,\n software distributed under the License is distributed on an\n \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n KIND, either express or implied.  See the License for the\n specific language governing permissions and limitations\n under the License.\n-->\nContributions are welcome and are greatly appreciated! Every\nlittle bit helps, and credit will always be given.\n\nAll matters related to contributions have moved to [this section of\nthe official Superset documentation](https://superset.apache.org/docs/contributing/). Source for the documentation is\n[located here](https://github.com/apache/superset/tree/master/docs/docs).\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 9.2744140625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n######################################################################\n# Node stage to deal with static asset construction\n######################################################################\nARG PY_VER=3.10-slim-bookworm\n\n# If BUILDPLATFORM is null, set it to 'amd64' (or leave as is otherwise).\nARG BUILDPLATFORM=${BUILDPLATFORM:-amd64}\n\n######################################################################\n# superset-node-ci used as a base for building frontend assets and CI\n######################################################################\nFROM --platform=${BUILDPLATFORM} node:20-bullseye-slim AS superset-node-ci\nARG BUILD_TRANSLATIONS=\"false\" # Include translations in the final build\nENV BUILD_TRANSLATIONS=${BUILD_TRANSLATIONS}\nARG DEV_MODE=\"false\"           # Skip frontend build in dev mode\nENV DEV_MODE=${DEV_MODE}\n\nCOPY docker/ /app/docker/\n# Arguments for build configuration\nARG NPM_BUILD_CMD=\"build\"\n\n# Install system dependencies required for node-gyp\nRUN /app/docker/apt-install.sh build-essential python3 zstd\n\n# Define environment variables for frontend build\nENV BUILD_CMD=${NPM_BUILD_CMD} \\\n    PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true\n\n# Run the frontend memory monitoring script\nRUN /app/docker/frontend-mem-nag.sh\n\nWORKDIR /app/superset-frontend\n\n# Create necessary folders to avoid errors in subsequent steps\nRUN mkdir -p /app/superset/static/assets \\\n             /app/superset/translations\n\n# Mount package files and install dependencies if not in dev mode\n# NOTE: we mount packages and plugins as they are referenced in package.json as workspaces\n# ideally we'd COPY only their package.json. Here npm ci will be cached as long\n# as the full content of these folders don't change, yielding a decent cache reuse rate.\n# Note that's it's not possible selectively COPY of mount using blobs.\nRUN --mount=type=bind,source=./superset-frontend/package.json,target=./package.json \\\n    --mount=type=bind,source=./superset-frontend/package-lock.json,target=./package-lock.json \\\n    --mount=type=cache,target=/root/.cache \\\n    --mount=type=cache,target=/root/.npm \\\n    if [ \"$DEV_MODE\" = \"false\" ]; then \\\n        npm ci; \\\n    else \\\n        echo \"Skipping 'npm ci' in dev mode\"; \\\n    fi\n\n# Runs the webpack build process\nCOPY superset-frontend /app/superset-frontend\n\n######################################################################\n# superset-node used for compile frontend assets\n######################################################################\nFROM superset-node-ci AS superset-node\n\n# Build the frontend if not in dev mode\nRUN --mount=type=cache,target=/app/superset-frontend/.temp_cache \\\n    --mount=type=cache,target=/root/.npm \\\n    if [ \"$DEV_MODE\" = \"false\" ]; then \\\n        echo \"Running 'npm run ${BUILD_CMD}'\"; \\\n        npm run ${BUILD_CMD}; \\\n    else \\\n        echo \"Skipping 'npm run ${BUILD_CMD}' in dev mode\"; \\\n    fi;\n\n# Copy translation files\nCOPY superset/translations /app/superset/translations\n\n# Build the frontend if not in dev mode\nRUN if [ \"$BUILD_TRANSLATIONS\" = \"true\" ]; then \\\n        npm run build-translation; \\\n    fi; \\\n    rm -rf /app/superset/translations/*/*/*.po; \\\n    rm -rf /app/superset/translations/*/*/*.mo;\n\n\n######################################################################\n# Base python layer\n######################################################################\nFROM python:${PY_VER} AS python-base\nARG BUILD_TRANSLATIONS=\"false\" # Include translations in the final build\nENV BUILD_TRANSLATIONS=${BUILD_TRANSLATIONS}\nARG DEV_MODE=\"false\"           # Skip frontend build in dev mode\nENV DEV_MODE=${DEV_MODE}\n\nENV LANG=C.UTF-8 \\\n    LC_ALL=C.UTF-8 \\\n    SUPERSET_ENV=production \\\n    FLASK_APP=\"superset.app:create_app()\" \\\n    PYTHONPATH=\"/app/pythonpath\" \\\n    SUPERSET_HOME=\"/app/superset_home\" \\\n    SUPERSET_PORT=8088\n\n\nRUN useradd --user-group -d ${SUPERSET_HOME} -m --no-log-init --shell /bin/bash superset\n\n# Some bash scripts needed throughout the layers\nCOPY --chmod=755 docker/*.sh /app/docker/\n\nRUN pip install --no-cache-dir --upgrade uv\n\n# Using uv as it's faster/simpler than pip\nRUN uv venv /app/.venv\nENV PATH=\"/app/.venv/bin:${PATH}\"\n\n# Install Playwright and optionally setup headless browsers\nARG INCLUDE_CHROMIUM=\"true\"\nARG INCLUDE_FIREFOX=\"false\"\nRUN --mount=type=cache,target=/root/.cache/uv\\\n    if [ \"$INCLUDE_CHROMIUM\" = \"true\" ] || [ \"$INCLUDE_FIREFOX\" = \"true\" ]; then \\\n        uv pip install playwright && \\\n        playwright install-deps && \\\n        if [ \"$INCLUDE_CHROMIUM\" = \"true\" ]; then playwright install chromium; fi && \\\n        if [ \"$INCLUDE_FIREFOX\" = \"true\" ]; then playwright install firefox; fi; \\\n    else \\\n        echo \"Skipping browser installation\"; \\\n    fi\n\n######################################################################\n# Python translation compiler layer\n######################################################################\nFROM python-base AS python-translation-compiler\n\n# Install Python dependencies using docker/pip-install.sh\nCOPY requirements/translations.txt requirements/\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/translations.txt\n\nCOPY superset/translations/ /app/translations_mo/\nRUN if [ \"$BUILD_TRANSLATIONS\" = \"true\" ]; then \\\n        pybabel compile -d /app/translations_mo | true; \\\n    fi; \\\n    rm -f /app/translations_mo/*/*/*.po; \\\n    rm -f /app/translations_mo/*/*/*.json;\n\n######################################################################\n# Python APP common layer\n######################################################################\nFROM python-base AS python-common\n# Copy the entrypoints, make them executable in userspace\nCOPY --chmod=755 docker/entrypoints /app/docker/entrypoints\n\nWORKDIR /app\n# Set up necessary directories and user\nRUN mkdir -p \\\n      ${SUPERSET_HOME} \\\n      ${PYTHONPATH} \\\n      superset/static \\\n      requirements \\\n      superset-frontend \\\n      apache_superset.egg-info \\\n      requirements \\\n    && touch superset/static/version_info.json\n\n# Copy required files for Python build\nCOPY pyproject.toml setup.py MANIFEST.in README.md ./\nCOPY superset-frontend/package.json superset-frontend/\nCOPY scripts/check-env.py scripts/\n\n# keeping for backward compatibility\nCOPY --chmod=755 ./docker/entrypoints/run-server.sh /usr/bin/\n\n# Some debian libs\nRUN /app/docker/apt-install.sh \\\n      curl \\\n      libsasl2-dev \\\n      libsasl2-modules-gssapi-mit \\\n      libpq-dev \\\n      libecpg-dev \\\n      libldap2-dev\n\n# Copy compiled things from previous stages\nCOPY --from=superset-node /app/superset/static/assets superset/static/assets\n\n# TODO, when the next version comes out, use --exclude superset/translations\nCOPY superset superset\n# TODO in the meantime, remove the .po files\nRUN rm superset/translations/*/*/*.po\n\n# Merging translations from backend and frontend stages\nCOPY --from=superset-node /app/superset/translations superset/translations\nCOPY --from=python-translation-compiler /app/translations_mo superset/translations\n\nHEALTHCHECK CMD curl -f \"http://localhost:${SUPERSET_PORT}/health\"\nCMD [\"/app/docker/entrypoints/run-server.sh\"]\nEXPOSE ${SUPERSET_PORT}\n\n######################################################################\n# Final lean image...\n######################################################################\nFROM python-common AS lean\n\n# Install Python dependencies using docker/pip-install.sh\nCOPY requirements/base.txt requirements/\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/base.txt\n# Install the superset package\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install .\n\nRUN python -m compileall /app/superset\n\nUSER superset\n\n######################################################################\n# Dev image...\n######################################################################\nFROM python-common AS dev\n\n# Debian libs needed for dev\nRUN /app/docker/apt-install.sh \\\n    git \\\n    pkg-config \\\n    default-libmysqlclient-dev\n\n# Copy development requirements and install them\nCOPY requirements/*.txt requirements/\n# Install Python dependencies using docker/pip-install.sh\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/development.txt\n# Install the superset package\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install .\n\nRUN python -m compileall /app/superset\n\nUSER superset\n\n######################################################################\n# CI image...\n######################################################################\nFROM lean AS ci\n\nCMD [\"/app/docker/entrypoints/docker-ci.sh\"]\n"
        },
        {
          "name": "INSTALL.md",
          "type": "blob",
          "size": 0.955078125,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n# INSTALL / BUILD instructions for Apache Superset\n\nAt this time, the docker file at RELEASING/Dockerfile.from_local_tarball\nconstitutes the recipe on how to get to a working release from a source\nrelease tarball.\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 11.3134765625,
          "content": "                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n============================================================================\n   APACHE SUPERSET SUBCOMPONENTS:\n\n   The Apache Superset project contains subcomponents with separate copyright\n   notices and license terms. Your use of the source code for the these\n   subcomponents is subject to the terms and conditions of the following\n   licenses.\n\n========================================================================\nThird party SIL Open Font License v1.1 (OFL-1.1)\n========================================================================\n\n(SIL OPEN FONT LICENSE Version 1.1) The Inter font family (https://github.com/rsms/inter)\n(SIL OPEN FONT LICENSE Version 1.1) The Fira Code font family (https://github.com/tonsky/FiraCode)\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 1.0869140625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\ninclude NOTICE\ninclude LICENSE.txt\ngraft licenses/\ninclude README.md\ninclude superset-frontend/package.json\nrecursive-include superset/examples *\nrecursive-include superset/migrations *\nrecursive-include superset/templates *\nrecursive-include superset/translations *\nrecursive-include superset/static *\nrecursive-exclude tests *\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.15625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Python version installed; we need 3.10-3.11\nPYTHON=`command -v python3.11 || command -v python3.10`\n\n.PHONY: install superset venv pre-commit\n\ninstall: superset pre-commit\n\nsuperset:\n\t# Install external dependencies\n\tpip install -r requirements/development.txt\n\n\t# Install Superset in editable (development) mode\n\tpip install -e .\n\n\t# Create an admin user in your metadata database\n\tsuperset fab create-admin \\\n                    --username admin \\\n                    --firstname \"Admin I.\"\\\n                    --lastname Strator \\\n                    --email admin@superset.io \\\n                    --password general\n\n\t# Initialize the database\n\tsuperset db upgrade\n\n\t# Create default roles and permissions\n\tsuperset init\n\n\t# Load some data to play with\n\tsuperset load-examples\n\n\t# Install node packages\n\tcd superset-frontend; npm ci\n\nupdate: update-py update-js\n\nupdate-py:\n\t# Install external dependencies\n\tpip install -r requirements/development.txt\n\n\t# Install Superset in editable (development) mode\n\tpip install -e .\n\n\t# Initialize the database\n\tsuperset db upgrade\n\n\t# Create default roles and permissions\n\tsuperset init\n\nupdate-js:\n\t# Install js packages\n\tcd superset-frontend; npm ci\n\nvenv:\n\t# Create a virtual environment and activate it (recommended)\n\tif ! [ -x \"${PYTHON}\" ]; then echo \"You need Python 3.10 or 3.11 installed\"; exit 1; fi\n\ttest -d venv || ${PYTHON} -m venv venv # setup a python3 virtualenv\n\t. venv/bin/activate\n\nactivate:\n\t. venv/bin/activate\n\npre-commit:\n\t# setup pre commit dependencies\n\tpip3 install -r requirements/development.txt\n\tpre-commit install\n\nformat: py-format js-format\n\npy-format: pre-commit\n\tpre-commit run black --all-files\n\njs-format:\n\tcd superset-frontend; npm run prettier\n\nflask-app:\n\tflask run -p 8088 --with-threads --reload --debugger\n\nnode-app:\n\tcd superset-frontend; npm run dev-server\n\nbuild-cypress:\n\tcd superset-frontend; npm run build-instrumented\n\tcd superset-frontend/cypress-base; npm ci\n\nopen-cypress:\n\tif ! [ $(port) ]; then cd superset-frontend/cypress-base; CYPRESS_BASE_URL=http://localhost:9000 npm run cypress open; fi\n\tcd superset-frontend/cypress-base; CYPRESS_BASE_URL=http://localhost:$(port) npm run cypress open\n\nreport-celery-worker:\n\tcelery --app=superset.tasks.celery_app:app worker\n\nreport-celery-beat:\n\tcelery --app=superset.tasks.celery_app:app beat --pidfile /tmp/celerybeat.pid --schedule /tmp/celerybeat-schedulecd\n\nadmin-user:\n\tsuperset fab create-admin\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.1650390625,
          "content": "Apache Superset\nCopyright 2016-2024 The Apache Software Foundation\n\nThis product includes software developed at The Apache Software\nFoundation (http://www.apache.org/).\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.3056640625,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Superset\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/license/apache-2-0)\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/apache/superset?sort=semver)](https://github.com/apache/superset/tree/latest)\n[![Build Status](https://github.com/apache/superset/workflows/Python/badge.svg)](https://github.com/apache/superset/actions)\n[![PyPI version](https://badge.fury.io/py/apache-superset.svg)](https://badge.fury.io/py/apache-superset)\n[![Coverage Status](https://codecov.io/github/apache/superset/coverage.svg?branch=master)](https://codecov.io/github/apache/superset)\n[![PyPI](https://img.shields.io/pypi/pyversions/apache-superset.svg?maxAge=2592000)](https://pypi.python.org/pypi/apache-superset)\n[![Get on Slack](https://img.shields.io/badge/slack-join-orange.svg)](http://bit.ly/join-superset-slack)\n[![Documentation](https://img.shields.io/badge/docs-apache.org-blue.svg)](https://superset.apache.org)\n\n<picture width=\"500\">\n  <source\n    width=\"600\"\n    media=\"(prefers-color-scheme: dark)\"\n    src=\"https://superset.apache.org/img/superset-logo-horiz-dark.svg\"\n    alt=\"Superset logo (dark)\"\n  />\n  <img\n    width=\"600\"\n    src=\"https://superset.apache.org/img/superset-logo-horiz-apache.svg\"\n    alt=\"Superset logo (light)\"\n  />\n</picture>\n\nA modern, enterprise-ready business intelligence web application.\n\n[**Why Superset?**](#why-superset) |\n[**Supported Databases**](#supported-databases) |\n[**Installation and Configuration**](#installation-and-configuration) |\n[**Release Notes**](https://github.com/apache/superset/blob/master/RELEASING/README.md#release-notes-for-recent-releases) |\n[**Get Involved**](#get-involved) |\n[**Contributor Guide**](#contributor-guide) |\n[**Resources**](#resources) |\n[**Organizations Using Superset**](https://github.com/apache/superset/blob/master/RESOURCES/INTHEWILD.md)\n\n## Why Superset?\n\nSuperset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.\n\nSuperset provides:\n\n- A **no-code interface** for building charts quickly\n- A powerful, web-based **SQL Editor** for advanced querying\n- A **lightweight semantic layer** for quickly defining custom dimensions and metrics\n- Out of the box support for **nearly any SQL** database or data engine\n- A wide array of **beautiful visualizations** to showcase your data, ranging from simple bar charts to geospatial visualizations\n- Lightweight, configurable **caching layer** to help ease database load\n- Highly extensible **security roles and authentication** options\n- An **API** for programmatic customization\n- A **cloud-native architecture** designed from the ground up for scale\n\n## Screenshots & Gifs\n\n**Video Overview**\n<!-- File hosted here https://github.com/apache/superset-site/raw/lfs/superset-video-4k.mp4 -->\n[superset-video-4k.webm](https://github.com/apache/superset/assets/812905/da036bc2-150c-4ee7-80f9-75e63210ff76)\n\n<br/>\n\n**Large Gallery of Visualizations**\n\n<kbd><img title=\"Gallery\" src=\"https://superset.apache.org/img/screenshots/gallery.jpg\"/></kbd><br/>\n\n**Craft Beautiful, Dynamic Dashboards**\n\n<kbd><img title=\"View Dashboards\" src=\"https://superset.apache.org/img/screenshots/slack_dash.jpg\"/></kbd><br/>\n\n**No-Code Chart Builder**\n\n<kbd><img title=\"Slice & dice your data\" src=\"https://superset.apache.org/img/screenshots/explore.jpg\"/></kbd><br/>\n\n**Powerful SQL Editor**\n\n<kbd><img title=\"SQL Lab\" src=\"https://superset.apache.org/img/screenshots/sql_lab.jpg\"/></kbd><br/>\n\n## Supported Databases\n\nSuperset can query data from any SQL-speaking datastore or data engine (Presto, Trino, Athena, [and more](https://superset.apache.org/docs/configuration/databases)) that has a Python DB-API driver and a SQLAlchemy dialect.\n\nHere are some of the major database solutions that are supported:\n\n<p align=\"center\">\n  <img src=\"https://superset.apache.org/img/databases/redshift.png\" alt=\"redshift\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/google-biquery.png\" alt=\"google-biquery\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/snowflake.png\" alt=\"snowflake\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/trino.png\" alt=\"trino\" border=\"0\" width=\"150\" />\n  <img src=\"https://superset.apache.org/img/databases/presto.png\" alt=\"presto\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/databricks.png\" alt=\"databricks\" border=\"0\" width=\"160\" />\n  <img src=\"https://superset.apache.org/img/databases/druid.png\" alt=\"druid\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/firebolt.png\" alt=\"firebolt\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/timescale.png\" alt=\"timescale\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/rockset.png\" alt=\"rockset\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/postgresql.png\" alt=\"postgresql\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mysql.png\" alt=\"mysql\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mssql-server.png\" alt=\"mssql-server\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/ibm-db2.svg\" alt=\"db2\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/sqlite.png\" alt=\"sqlite\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/sybase.png\" alt=\"sybase\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mariadb.png\" alt=\"mariadb\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/vertica.png\" alt=\"vertica\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/oracle.png\" alt=\"oracle\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/firebird.png\" alt=\"firebird\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/greenplum.png\" alt=\"greenplum\" border=\"0\" width=\"200\"  />\n  <img src=\"https://superset.apache.org/img/databases/clickhouse.png\" alt=\"clickhouse\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/exasol.png\" alt=\"exasol\" border=\"0\" width=\"160\" />\n  <img src=\"https://superset.apache.org/img/databases/monet-db.png\" alt=\"monet-db\" border=\"0\" width=\"200\"  />\n  <img src=\"https://superset.apache.org/img/databases/apache-kylin.png\" alt=\"apache-kylin\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/hologres.png\" alt=\"hologres\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/netezza.png\" alt=\"netezza\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/pinot.png\" alt=\"pinot\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/teradata.png\" alt=\"teradata\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/yugabyte.png\" alt=\"yugabyte\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/databend.png\" alt=\"databend\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/starrocks.png\" alt=\"starrocks\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/doris.png\" alt=\"doris\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/oceanbase.svg\" alt=\"oceanbase\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/sap-hana.png\" alt=\"oceanbase\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/denodo.png\" alt=\"denodo\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/ydb.svg\" alt=\"ydb\" border=\"0\" width=\"200\" />\n</p>\n\n**A more comprehensive list of supported databases** along with the configuration instructions can be found [here](https://superset.apache.org/docs/configuration/databases).\n\nWant to add support for your datastore or data engine? Read more [here](https://superset.apache.org/docs/frequently-asked-questions#does-superset-work-with-insert-database-engine-here) about the technical requirements.\n\n## Installation and Configuration\n\n[Extended documentation for Superset](https://superset.apache.org/docs/installation/docker-compose)\n\n## Get Involved\n\n- Ask and answer questions on [StackOverflow](https://stackoverflow.com/questions/tagged/apache-superset) using the **apache-superset** tag\n- [Join our community's Slack](http://bit.ly/join-superset-slack)\n  and please read our [Slack Community Guidelines](https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.md#slack-community-guidelines)\n- [Join our dev@superset.apache.org Mailing list](https://lists.apache.org/list.html?dev@superset.apache.org). To join, simply send an email to [dev-subscribe@superset.apache.org](mailto:dev-subscribe@superset.apache.org)\n- If you want to help troubleshoot GitHub Issues involving the numerous database drivers that Superset supports, please consider adding your name and the databases you have access to on the [Superset Database Familiarity Rolodex](https://docs.google.com/spreadsheets/d/1U1qxiLvOX0kBTUGME1AHHi6Ywel6ECF8xk_Qy-V9R8c/edit#gid=0)\n- Join Superset's Town Hall and [Operational Model](https://preset.io/blog/the-superset-operational-model-wants-you/) recurring meetings.  Meeting info is available on the [Superset Community Calendar](https://superset.apache.org/community)\n\n## Contributor Guide\n\nInterested in contributing? Check out our\n[CONTRIBUTING.md](https://github.com/apache/superset/blob/master/CONTRIBUTING.md)\nto find resources around contributing along with a detailed guide on\nhow to set up a development environment.\n\n## Resources\n\n- [Superset \"In the Wild\"](https://github.com/apache/superset/blob/master/RESOURCES/INTHEWILD.md) - open a PR to add your org to the list!\n- [Feature Flags](https://github.com/apache/superset/blob/master/RESOURCES/FEATURE_FLAGS.md) - the status of Superset's Feature Flags.\n- [Standard Roles](https://github.com/apache/superset/blob/master/RESOURCES/STANDARD_ROLES.md) - How RBAC permissions map to roles.\n- [Superset Wiki](https://github.com/apache/superset/wiki) - Tons of additional community resources: best practices, community content and other information.\n- [Superset SIPs](https://github.com/orgs/apache/projects/170) - The status of Superset's SIPs (Superset Improvement Proposals) for both consensus and implementation status.\n\nUnderstanding the Superset Points of View\n\n- [The Case for Dataset-Centric Visualization](https://preset.io/blog/dataset-centric-visualization/)\n- [Understanding the Superset Semantic Layer](https://preset.io/blog/understanding-superset-semantic-layer/)\n\n- Getting Started with Superset\n  - [Superset in 2 Minutes using Docker Compose](https://superset.apache.org/docs/installation/docker-compose#installing-superset-locally-using-docker-compose)\n  - [Installing Database Drivers](https://superset.apache.org/docs/configuration/databases#installing-database-drivers)\n  - [Building New Database Connectors](https://preset.io/blog/building-database-connector/)\n  - [Create Your First Dashboard](https://superset.apache.org/docs/using-superset/creating-your-first-dashboard/)\n  - [Comprehensive Tutorial for Contributing Code to Apache Superset\n  ](https://preset.io/blog/tutorial-contributing-code-to-apache-superset/)\n- [Resources to master Superset by Preset](https://preset.io/resources/)\n\n- Deploying Superset\n  - [Official Docker image](https://hub.docker.com/r/apache/superset)\n  - [Helm Chart](https://github.com/apache/superset/tree/master/helm/superset)\n\n- Recordings of Past [Superset Community Events](https://preset.io/events)\n  - [Mixed Time Series Charts](https://preset.io/events/mixed-time-series-visualization-in-superset-workshop/)\n  - [How the Bing Team Customized Superset for the Internal Self-Serve Data & Analytics Platform](https://preset.io/events/how-the-bing-team-heavily-customized-superset-for-their-internal-data/)\n  - [Live Demo: Visualizing MongoDB and Pinot Data using Trino](https://preset.io/events/2021-04-13-visualizing-mongodb-and-pinot-data-using-trino/)\n  - [Introduction to the Superset API](https://preset.io/events/introduction-to-the-superset-api/)\n  - [Building a Database Connector for Superset](https://preset.io/events/2021-02-16-building-a-database-connector-for-superset/)\n\n- Visualizations\n  - [Creating Viz Plugins](https://superset.apache.org/docs/contributing/creating-viz-plugins/)\n  - [Managing and Deploying Custom Viz Plugins](https://medium.com/nmc-techblog/apache-superset-manage-custom-viz-plugins-in-production-9fde1a708e55)\n  - [Why Apache Superset is Betting on Apache ECharts](https://preset.io/blog/2021-4-1-why-echarts/)\n\n- [Superset API](https://superset.apache.org/docs/rest-api)\n\n## Repo Activity\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=39464018\" target=\"_blank\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\" />\n    <img alt=\"Performance Stats of apache/superset - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\" />\n  </picture>\n</a>\n\n<!-- Made with [OSS Insight](https://ossinsight.io/) -->\n\n<!-- telemetry/analytics pixel: -->\n<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=bc1c90cd-bc04-4e11-8c7b-289fb2839492\" />\n"
        },
        {
          "name": "RELEASING",
          "type": "tree",
          "content": null
        },
        {
          "name": "RESOURCES",
          "type": "tree",
          "content": null
        },
        {
          "name": "UPDATING.md",
          "type": "blob",
          "size": 70.2890625,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Updating Superset\n\nThis file documents any backwards-incompatible changes in Superset and\nassists people when migrating to a new version.\n\n## Next\n- [31774](https://github.com/apache/superset/pull/31774): Fixes the spelling of the `USE-ANALAGOUS-COLORS` feature flag. Please update any scripts/configuration item to use the new/corrected `USE-ANALOGOUS-COLORS` flag spelling.\n- [31582](https://github.com/apache/superset/pull/31582) Removed the legacy Area, Bar, Event Flow, Heatmap, Histogram, Line, Sankey, and Sankey Loop charts. They were all automatically migrated to their ECharts counterparts with the exception of the Event Flow and Sankey Loop charts which were removed as they were not actively maintained and not widely used. If you were using the Event Flow or Sankey Loop charts, you will need to find an alternative solution.\n- [31198](https://github.com/apache/superset/pull/31198) Disallows by default the use of the following ClickHouse functions: \"version\", \"currentDatabase\", \"hostName\".\n- [29798](https://github.com/apache/superset/pull/29798) Since 3.1.0, the intial schedule for an alert or report was mistakenly offset by the specified timezone's relation to UTC. The initial schedule should now begin at the correct time.\n- [30021](https://github.com/apache/superset/pull/30021) The `dev` layer in our Dockerfile no long includes firefox binaries, only Chromium to reduce bloat/docker-build-time.\n- [30099](https://github.com/apache/superset/pull/30099) Translations are no longer included in the default docker image builds. If your environment requires translations, you'll want to set the docker build arg `BUILD_TRANSACTION=true`.\n- [31262](https://github.com/apache/superset/pull/31262) NOTE: deprecated `pylint` in favor of `ruff` as our only python linter. Only affect development workflows positively (not the release itself). It should cover most important rules, be much faster, but some things linting rules that were enforced before may not be enforce in the exact same way as before.\n- [31173](https://github.com/apache/superset/pull/31173) Modified `fetch_csrf_token` to align with HTTP standards, particularly regarding how cookies are handled. If you encounter any issues related to CSRF functionality, please report them as a new issue and reference this PR for context.\n- [31385](https://github.com/apache/superset/pull/31385) Significant docker refactor, reducing access levels for the `superset` user, streamlining layer building, ...\n\n### Potential Downtime\n\n## 4.1.0\n\n- [29274](https://github.com/apache/superset/pull/29274): We made it easier to trigger CI on your\n  forks, whether they are public or private. Simply push to a branch that fits `[0-9].[0-9]*` and\n  should run on your fork, giving you flexibility on naming your release branches and triggering\n  CI\n- [27505](https://github.com/apache/superset/pull/27505): We simplified the files under\n  `requirements/` folder. If you use these files for your builds you may want to double\n  check that your builds are not affected. `base.txt` should be the same as before, though\n  `development.txt` becomes a bigger set, incorporating the now defunct local,testing,integration, and docker\n- [27434](https://github.com/apache/superset/pull/27434/files): DO NOT USE our docker compose.\\*\n  files for production use cases! While we never really supported\n  or should have tried to support docker compose for production use cases, we now actively\n  have taken a stance against supporting it. See the PR for details.\n- [24112](https://github.com/apache/superset/pull/24112): Python 3.10 is now the recommended python version to use, 3.9 still\n  supported but getting deprecated in the nearish future. CI/CD runs on py310 so you probably want to align. If you\n  use official dockers, upgrade should happen automatically.\n- [27697](https://github.com/apache/superset/pull/27697) [minor] flask-session bump leads to them\n  deprecating `SESSION_USE_SIGNER`, check your configs as this flag won't do anything moving\n  forward.\n- [27849](https://github.com/apache/superset/pull/27849/) More of an FYI, but we have a\n  new config `SLACK_ENABLE_AVATARS` (False by default) that works in conjunction with\n  set `SLACK_API_TOKEN` to fetch and serve Slack avatar links\n- [28134](https://github.com/apache/superset/pull/28134/) The default logging level was changed\n  from DEBUG to INFO - which is the normal/sane default logging level for most software.\n- [27777](https://github.com/apache/superset/pull/27777) Moves debug logging logic to config.py.\n  See `LOG_LEVEL` in `superset/config.py` for the recommended default.\n- [28205](https://github.com/apache/superset/pull/28205) The permission `all_database_access` now\n  more clearly provides access to all databases, as specified in its name. Before it only allowed\n  listing all databases in CRUD-view and dropdown and didn't provide access to data as it\n  seemed the name would imply.\n- [28483](https://github.com/apache/superset/pull/28483) Starting with this version we bundle\n  translations inside the python package. This includes the .mo files needed by pybabel on the\n  backend, as well as the .json files used by the frontend. If you were doing anything before\n  as part of your bundling to expose translation packages, it's probably not needed anymore.\n- [29264](https://github.com/apache/superset/pull/29264) Slack has updated its file upload api, and we are now supporting this new api in Superset, although the Slack api is not backward compatible. The original Slack integration is deprecated and we will require a new Slack scope `channels:read` to be added to Slack workspaces in order to use this new api. In an upcoming release, we will make this new Slack scope mandatory and remove the old Slack functionality.\n- [30274](https://github.com/apache/superset/pull/30274) Moved SLACK_ENABLE_AVATAR from config.py to the feature flag framework, please adapt your configs.\n\n### Potential Downtime\n\n- [27392](https://github.com/apache/superset/pull/27392): Adds an index to `query.sql_editor_id` to improve performance. This may cause downtime on large deployments.\n\n## 4.0.0\n\n- [27119](https://github.com/apache/superset/pull/27119): Updates various database columns to use the `MediumText` type, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n\n- [26450](https://github.com/apache/superset/pull/26450): Deprecates the `KV_STORE` feature flag and its related assets such as the API endpoint and `keyvalue` table. The main dependency of this feature is the `SHARE_QUERIES_VIA_KV_STORE` feature flag which allows sharing SQL Lab queries without the necessity of saving the query. Our intention is to use the permalink feature to implement this use case before 5.0 and that's why we are deprecating the feature flag now.\n\n### Breaking Changes\n\n- [27130](https://github.com/apache/superset/pull/27130): Fixes the DELETE `/database/{id}/ssh_tunnel/` endpoint to now correctly accept a database ID as a parameter, rather than an SSH tunnel ID.\n- [27117](https://github.com/apache/superset/pull/27117): Removes the following deprecated endpoints: `/superset/sqllab`, `/superset/sqllab/history`, `/sqllab/my_queries` use `/sqllab`, `/sqllab/history`, `/savedqueryview/list/?_flt_0_user={get_user_id()}` instead.\n- [26347](https://github.com/apache/superset/issues/26347): Removes the deprecated `VERSIONED_EXPORT` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26328](https://github.com/apache/superset/issues/26328): Removes the deprecated Filter Box code and it's associated dependencies `react-select` and `array-move`. It also removes the `DeprecatedSelect` and `AsyncSelect` components that were exclusively used by filter boxes. Existing filter boxes will be automatically migrated to native filters.\n- [26330](https://github.com/apache/superset/issues/26330): Removes the deprecated `DASHBOARD_FILTERS_EXPERIMENTAL` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26344](https://github.com/apache/superset/issues/26344): Removes the deprecated `ENABLE_EXPLORE_JSON_CSRF_PROTECTION` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26345](https://github.com/apache/superset/issues/26345): Removes the deprecated `ENABLE_TEMPLATE_REMOVE_FILTERS` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26346](https://github.com/apache/superset/issues/26346): Removes the deprecated `REMOVE_SLICE_LEVEL_LABEL_COLORS` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26348](https://github.com/apache/superset/issues/26348): Removes the deprecated `CLIENT_CACHE` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26349](https://github.com/apache/superset/issues/26349): Removes the deprecated `DASHBOARD_CACHE` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26369](https://github.com/apache/superset/issues/26369): Removes the Filter Sets feature including the deprecated `DASHBOARD_NATIVE_FILTERS_SET` feature flag and all related API endpoints. The feature is permanently removed as it was not being actively maintained, it was not widely used, and it was full of bugs. We also considered that if we were to provide a similar feature, it would be better to re-implement it from scratch given the amount of technical debt that the current implementation has. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26343](https://github.com/apache/superset/issues/26343): Removes the deprecated `ENABLE_EXPLORE_DRAG_AND_DROP` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26331](https://github.com/apache/superset/issues/26331): Removes the deprecated `DISABLE_DATASET_SOURCE_EDIT` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26636](https://github.com/apache/superset/issues/26636): Sets the `DASHBOARD_VIRTUALIZATION` feature flag to `True` by default. This feature was introduced by [21438](https://github.com/apache/superset/pull/21438) and will enable virtualization when rendering a dashboard's charts in an attempt to reduce the number of elements (DOM nodes) rendered at once. This is especially useful for large dashboards.\n- [26637](https://github.com/apache/superset/issues/26637): Sets the `DRILL_BY` feature flag to `True` by default given that the feature has been tested for a while and reached a stable state.\n- [26462](https://github.com/apache/superset/issues/26462): Removes the Profile feature given that it's not actively maintained and not widely used.\n- [26377](https://github.com/apache/superset/pull/26377): Removes the deprecated Redirect API that supported short URLs used before the permalink feature.\n- [26329](https://github.com/apache/superset/issues/26329): Removes the deprecated `DASHBOARD_NATIVE_FILTERS` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [25510](https://github.com/apache/superset/pull/25510): Reenforces that any newly defined Python data format (other than epoch) must adhere to the ISO 8601 standard (enforced by way of validation at the API and database level) after a previous relaxation to include slashes in addition to dashes. From now on when specifying new columns, dataset owners will need to use a SQL expression instead to convert their string columns of the form %Y/%m/%d etc. to a `DATE`, `DATETIME`, etc. type.\n- [26372](https://github.com/apache/superset/issues/26372): Removes the deprecated `GENERIC_CHART_AXES` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n\n### Potential Downtime\n\n- [26416](https://github.com/apache/superset/pull/26416): Adds two database indexes to the `report_execution_log` table and one database index to the `report_recipient` to improve performance. Scheduled downtime may be required for large deployments.\n- [28482](https://github.com/apache/superset/pull/28482): Potentially augments the `query.executed_sql` and `query.select_sql` columns for MySQL from `MEDIUMTEXT` to `LONGTEXT`. Potential downtime may be required for large deployments which previously ran [27119](https://github.com/apache/superset/pull/27119).\n\n## 3.1.0\n\n- [24657](https://github.com/apache/superset/pull/24657): Bumps the cryptography package to augment the OpenSSL security vulnerability.\n\n### Other\n\n- [24982](https://github.com/apache/superset/pull/24982): By default, physical datasets on Oracle-like dialects like Snowflake will now use denormalized column names. However, existing datasets won't be affected. To change this behavior, the \"Advanced\" section on the dataset modal has a \"Normalize column names\" flag which can be changed to change this behavior.\n\n## 3.0.3\n\n- [26034](https://github.com/apache/superset/issues/26034): Fixes a problem where numeric x-axes were being treated as categorical values. As a consequence of that, the way labels are displayed might change given that ECharts has a different treatment for numerical and categorical values. To revert to the old behavior, users need to manually convert numerical columns to text so that they are treated as categories. Check https://github.com/apache/superset/issues/26159 for more details.\n\n## 3.0.0\n\n- [25053](https://github.com/apache/superset/pull/25053): Extends the `ab_user.email` column from 64 to 320 characters which has an associated unique key constraint. This will be problematic for MySQL metadata databases which use the InnoDB storage engine with the `innodb_large_prefix` parameter disabled as the key prefix limit is 767 bytes. Enabling said parameter and ensuring that the table uses either the `DYNAMIC` or `COMPRESSED` row format should remedy the problem. See [here](https://dev.mysql.com/doc/refman/5.7/en/innodb-limits.html) for more details.\n- [24911](https://github.com/apache/superset/pull/24911): Changes the column type from `TEXT` to `MediumText` in table `logs`, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n- [24939](https://github.com/apache/superset/pull/24939): Augments the foreign key constraints for the `embedded_dashboards` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dashboard is deleted. Scheduled downtime may be advised.\n- [24938](https://github.com/apache/superset/pull/24938): Augments the foreign key constraints for the `dashboard_slices` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dashboard or slice is deleted. Scheduled downtime may be advised.\n- [24628](https://github.com/apache/superset/pull/24628): Augments the foreign key constraints for the `dashboard_owner`, `report_schedule_owner`, and `slice_owner` tables to include an explicit CASCADE ON DELETE to ensure the relevant ownership records are deleted when a dataset is deleted. Scheduled downtime may be advised.\n- [24488](https://github.com/apache/superset/pull/24488): Augments the foreign key constraints for the `sql_metrics`, `sqlatable_user`, and `table_columns` tables which reference the `tables` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dataset is deleted. Scheduled downtime may be advised.\n- [24232](https://github.com/apache/superset/pull/24232): Enables ENABLE_TEMPLATE_REMOVE_FILTERS, DRILL_TO_DETAIL, DASHBOARD_CROSS_FILTERS by default, marks VERSIONED_EXPORT and ENABLE_TEMPLATE_REMOVE_FILTERS as deprecated.\n- [23652](https://github.com/apache/superset/pull/23652): Enables GENERIC_CHART_AXES feature flag by default.\n- [23226](https://github.com/apache/superset/pull/23226): Migrated endpoint `/estimate_query_cost/<int:database_id>` to `/api/v1/sqllab/estimate/`. Corresponding permissions are can estimate query cost on SQLLab. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [23890](https://github.com/apache/superset/pull/23890): Removes Python 3.8 support.\n- [24404](https://github.com/apache/superset/pull/24404): FLASK_ENV is getting\n  deprecated, we recommend using SUPERSET_ENV and reviewing your\n  config for ENVIRONMENT_TAG_CONFIG, which enables adding a tag in the navbar to\n  make it more clear which environment your are in.\n  `SUPERSET_ENV=production` and `SUPERSET_ENV=development` are the two\n  supported switches based on the default config.\n- [19242](https://github.com/apache/superset/pull/19242): Adhoc subqueries are now disabled by default for security reasons. To enable them, set the feature flag `ALLOW_ADHOC_SUBQUERY` to `True`.\n\n### Breaking Changes\n\n- [24686](https://github.com/apache/superset/pull/24686): All dataset's custom explore_url are handled as relative URLs on the frontend, behaviour controlled by PREVENT_UNSAFE_DEFAULT_URLS_ON_DATASET.\n- [24262](https://github.com/apache/superset/pull/24262): Enabled `TALISMAN_ENABLED` flag by default and provided stricter default Content Security Policy\n- [24415](https://github.com/apache/superset/pull/24415): Removed the obsolete Druid NoSQL REGEX operator.\n- [24423](https://github.com/apache/superset/pull/24423): Removed deprecated APIs `/superset/slice_json/...`, `/superset/annotation_json/...`\n- [24400](https://github.com/apache/superset/pull/24400): Removed deprecated APIs `/superset/recent_activity/...`, `/superset/fave_dashboards_by_username/...`, `/superset/fave_dashboards/...`, `/superset/created_dashboards/...`, `/superset/user_slices/`, `/superset/created_slices/...`, `/superset/fave_slices/...`, `/superset/favstar/...`,\n- [24401](https://github.com/apache/superset/pull/24401): Removes the deprecated `metrics` column (which was blossomed in [20732](https://github.com/apache/superset/pull/20732)) from the `/api/v1/dataset/` API.\n- [24375](https://github.com/apache/superset/pull/24375): Removed deprecated API `/superset/get_or_create_table/...`, `/superset/sqllab_viz`\n- [24360](https://github.com/apache/superset/pull/24360): Removed deprecated APIs `/superset/stop_query/...`, `/superset/queries/...`, `/superset/search_queries`\n- [24353](https://github.com/apache/superset/pull/24353): Removed deprecated APIs `/copy_dash/int:dashboard_id/`, `/save_dash/int:dashboard_id/`, `/add_slices/int:dashboard_id/`.\n- [24198](https://github.com/apache/superset/pull/24198) The FAB views `User Registrations` and `User's Statistics` have been changed to Admin only. To re-enable them for non-admin users, please add the following perms to your custom role: `menu access on User's Statistics` and `menu access on User Registrations`.\n- [24354](https://github.com/apache/superset/pull/24354): Removed deprecated APIs `/superset/testconn`, `/superset/validate_sql_json/`, `/superset/schemas_access_for_file_upload`, `/superset/extra_table_metadata`\n- [24381](https://github.com/apache/superset/pull/24381): Removed deprecated API `/superset/available_domains/`\n- [24359](https://github.com/apache/superset/pull/24359): Removed deprecated APIs `/superset/estimate_query_cost/..`, `/superset/results/..`, `/superset/sql_json/..`, `/superset/csv/..`\n- [24345](https://github.com/apache/superset/pull/24345) Converts `ENABLE_BROAD_ACTIVITY_ACCESS` and `MENU_HIDE_USER_INFO` into feature flags and changes the value of `ENABLE_BROAD_ACTIVITY_ACCESS` to `False` as it's more secure.\n- [24342](https://github.com/apache/superset/pull/24342): Removed deprecated API `/superset/tables/<int:db_id>/<schema>/...`\n- [24335](https://github.com/apache/superset/pull/24335): Removed deprecated API `/superset/filter/<datasource_type>/<int:datasource_id>/<column>/`\n- [24333](https://github.com/apache/superset/pull/24333): Removed deprecated API `/superset/datasources`\n- [24266](https://github.com/apache/superset/pull/24266) Remove the `ENABLE_ACCESS_REQUEST` config parameter and the associated request/approval workflows.\n- [24330](https://github.com/apache/superset/pull/24330) Removes `getUiOverrideRegistry` from `ExtensionsRegistry`.\n- [23933](https://github.com/apache/superset/pull/23933) Removes the deprecated Multiple Line Charts.\n- [23741](https://github.com/apache/superset/pull/23741) Migrates the TreeMap chart and removes the legacy Treemap code.\n- [23712](https://github.com/apache/superset/pull/23712) Migrates the Pivot Table v1 chart to v2 and removes v1 code.\n- [24029](https://github.com/apache/superset/pull/24029) Removes the `user` and `username` arguments for the `QUERY_LOGGER` and `SQL_QUERY_MUTATOR` methods respectively. If the username for the current user is required, the `superset.utils.core.get_username` method should be used.\n- [24128](https://github.com/apache/superset/pull/24128) The `RLS_BASE_RELATED_FIELD_FILTERS` config parameter has been removed. Now the Tables dropdown will feature the same tables that the user is able to see elsewhere in the application using the standard `DatasourceFilter`, and the Roles dropdown will be filtered using the filter defined in `EXTRA_RELATED_QUERY_FILTERS[\"role\"]`.\n- [23785](https://github.com/apache/superset/pull/23785) Deprecated the following feature flags: `CLIENT_CACHE`, `DASHBOARD_CACHE`, `DASHBOARD_FILTERS_EXPERIMENTAL`, `DASHBOARD_NATIVE_FILTERS`, `DASHBOARD_NATIVE_FILTERS_SET`, `DISABLE_DATASET_SOURCE_EDIT`, `ENABLE_EXPLORE_JSON_CSRF_PROTECTION`, `REMOVE_SLICE_LEVEL_LABEL_COLORS`. It also removed `DASHBOARD_EDIT_CHART_IN_NEW_TAB` as the feature is supported without the need for a feature flag.\n- [22801](https://github.com/apache/superset/pull/22801): The Thumbnails feature has been changed to execute as the currently logged in user by default, falling back to the selenium user for anonymous users. To continue always using the selenium user, please add the following to your `superset_config.py`: `THUMBNAILS_EXECUTE_AS = [\"selenium\"]`\n- [22799](https://github.com/apache/superset/pull/22799): Alerts & Reports has been changed to execute as the owner of the alert/report by default, giving priority to the last modifier and then the creator if either is contained within the list of owners, otherwise the first owner will be used. To continue using the selenium user, please add the following to your `superset_config.py`: `ALERT_REPORTS_EXECUTE_AS = [\"selenium\"]`\n- [23651](https://github.com/apache/superset/pull/23651): Removes UX_BETA feature flag.\n- [23663](https://github.com/apache/superset/pull/23663): Removes deprecated feature flags `ALLOW_DASHBOARD_DOMAIN_SHARDING`, `DISPLAY_MARKDOWN_HTML`, and `FORCE_DATABASE_CONNECTIONS_SSL`.\n- [22325](https://github.com/apache/superset/pull/22325): \"RLS_FORM_QUERY_REL_FIELDS\" is replaced by \"RLS_BASE_RELATED_FIELD_FILTERS\" feature flag. Its value format stays same.\n\n## 2.1.1\n\n- [24185](https://github.com/apache/superset/pull/24185): `/api/v1/database/test_connection` and `api/v1/database/validate_parameters` permissions changed from `can_read` to `can_write`. Only Admin user's have access.\n\n### Other\n\n- [23888](https://github.com/apache/superset/pull/23888): Database Migration for json serialization instead of pickle should upgrade/downgrade correctly when bumping to/from this patch version\n\n## 2.1.0\n\n- [22809](https://github.com/apache/superset/pull/22809): Migrated endpoint `/superset/sql_json` and `/superset/results/` to `/api/v1/sqllab/execute/` and `/api/v1/sqllab/results/` respectively. Corresponding permissions are `can sql_json on Superset` to `can execute on SQLLab`, `can results on Superset` to `can results on SQLLab`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22931](https://github.com/apache/superset/pull/22931): Migrated endpoint `/superset/get_or_create_table/` to `/api/v1/dataset/get_or_create/`. Corresponding permissions are `can get or create table on Superset` to `can get or create dataset on Dataset`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22882](https://github.com/apache/superset/pull/22882): Migrated endpoint `/superset/filter/<datasource_type>/<int:datasource_id>/<column>/` to `/api/v1/datasource/<datasource_type>/<datasource_id>/column/<column_name>/values/`. Corresponding permissions are `can filter on Superset` to `can get column values on Datasource`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22789](https://github.com/apache/superset/pull/22789): Migrated endpoint `/superset/recent_activity/<user_id>/` to `/api/v1/log/recent_activity/<user_id>/`. Corresponding permissions are `can recent activity on Superset` to `can recent activity on Log`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22913](https://github.com/apache/superset/pull/22913): Migrated endpoint `/superset/csv` to `/api/v1/sqllab/export/`. Corresponding permissions are `can csv on Superset` to `can export csv on SQLLab`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22496](https://github.com/apache/superset/pull/22496): Migrated endpoint `/superset/slice_json/<int:layer_id>` to `/api/v1/chart/<int:id>/data/`. Corresponding permissions are `can slice json on Superset` to `can read on Chart`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22624](https://github.com/apache/superset/pull/22624): Migrated endpoint `/superset/stop_query/` to `/api/v1/query/stop`. Corresponding permissions are `can stop query on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22579](https://github.com/apache/superset/pull/22579): Migrated endpoint `/superset/search_queries/` to `/api/v1/query/`. Corresponding permissions are `can search queries on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22501](https://github.com/apache/superset/pull/22501): Migrated endpoint `/superset/tables/<int:db_id>/<schema>/` to `/api/v1/database/<int:id>/tables/`. Corresponding permissions are `can tables on Superset` to `can read on Database`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22611](https://github.com/apache/superset/pull/22611): Migrated endpoint `/superset/queries/` to `api/v1/query/updated_since`. Corresponding permissions are `can queries on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [23186](https://github.com/apache/superset/pull/23186): Superset will refuse to start if a default `SECRET_KEY` is detected on a non Flask debug setting.\n- [22022](https://github.com/apache/superset/pull/22022): HTTP API endpoints `/superset/approve` and `/superset/request_access` have been deprecated and their HTTP methods were changed from GET to POST\n- [20606](https://github.com/apache/superset/pull/20606): When user clicks on chart title or \"Edit chart\" button in Dashboard page, Explore opens in the same tab. Clicking while holding cmd/ctrl opens Explore in a new tab. To bring back the old behaviour (always opening Explore in a new tab), flip feature flag `DASHBOARD_EDIT_CHART_IN_NEW_TAB` to `True`.\n- [20799](https://github.com/apache/superset/pull/20799): Presto and Trino engine will now display tracking URL for running queries in SQL Lab. If for some reason you don't want to show the tracking URL (for example, when your data warehouse hasn't enabled access for to Presto or Trino UI), update `TRACKING_URL_TRANSFORMER` in `config.py` to return `None`.\n- [21002](https://github.com/apache/superset/pull/21002): Support Python 3.10 and bump pandas 1.4 and pyarrow 6.\n- [21163](https://github.com/apache/superset/pull/21163): The time grain will be decoupled from the time filter column and the time grain control will move below the X-Axis control when `GENERIC_CHART_AXES` feature flags set to `True`. The time grain will be applied on the time column in the column-like controls(x axis, dimensions) instead of the time column in the time section.\n- [21284](https://github.com/apache/superset/pull/21284): The non-functional `MAX_TABLE_NAMES` config key has been removed.\n- [21794](https://github.com/apache/superset/pull/21794): Deprecates the undocumented `PRESTO_SPLIT_VIEWS_FROM_TABLES` feature flag. Now for Presto, like other engines, only physical tables are treated as tables.\n- [22798](https://github.com/apache/superset/pull/22798): To make the welcome page more relevant in production environments, the last tab on the welcome page has been changed from to feature all charts/dashboards the user has access to (previously only examples were shown). To keep current behavior unchanged, add the following to your `superset_config.py`: `WELCOME_PAGE_LAST_TAB = \"examples\"`\n- [22328](https://github.com/apache/superset/pull/22328): For deployments that have enabled the \"THUMBNAILS\" feature flag, the function that calculates dashboard digests has been updated to consider additional properties to more accurately identify changes in the dashboard metadata. This change will invalidate all currently cached dashboard thumbnails.\n- [21765](https://github.com/apache/superset/pull/21765): For deployments that have enabled the \"ALERT_REPORTS\" feature flag, Gamma users will no longer have read and write access to Alerts & Reports by default. To give Gamma users the ability to schedule reports from the Dashboard and Explore view like before, create an additional role with \"can read on ReportSchedule\" and \"can write on ReportSchedule\" permissions. To further give Gamma users access to the \"Alerts & Reports\" menu and CRUD view, add \"menu access on Manage\" and \"menu access on Alerts & Report\" permissions to the role.\n\n### Potential Downtime\n\n- [21284](https://github.com/apache/superset/pull/21284): A change which drops the unused `dbs.allow_multi_schema_metadata_fetch` column via a (potentially locking) DDL operation.\n\n### Other\n\n- [23118](https://github.com/apache/superset/pull/23118): Previously the \"database access on <database>\" permission granted access to all datasets on the underlying database, but they didn't show up on the list views. Now all dashboards, charts and datasets that are accessible via this permission will also show up on their respective list views.\n\n## 2.0.1\n\n- [21895](https://github.com/apache/superset/pull/21895): Markdown components had their security increased by adhering to the same sanitization process enforced by GitHub. This means that some HTML elements found in markdowns are not allowed anymore due to the security risks they impose. If you're deploying Superset in a trusted environment and wish to use some of the blocked elements, then you can use the HTML_SANITIZATION_SCHEMA_EXTENSIONS configuration to extend the default sanitization schema. There's also the option to disable HTML sanitization using the HTML_SANITIZATION configuration but we do not recommend this approach because of the security risks. Given the provided configurations, we don't view the improved sanitization as a breaking change but as a security patch.\n\n## Breaking Changes\n\n## Potential Downtime\n\n## Other\n\n## 2.0.0\n\n- [19046](https://github.com/apache/superset/pull/19046): Enables the drag and drop interface in Explore control panel by default. Flips `ENABLE_EXPLORE_DRAG_AND_DROP` and `ENABLE_DND_WITH_CLICK_UX` feature flags to `True`.\n- [18936](https://github.com/apache/superset/pull/18936): Removes legacy SIP-15 interim logic/flags—specifically the `SIP_15_ENABLED`, `SIP_15_GRACE_PERIOD_END`, `SIP_15_DEFAULT_TIME_RANGE_ENDPOINTS`, and `SIP_15_TOAST_MESSAGE` flags. Time range endpoints are no longer configurable and strictly adhere to the `[start, end)` paradigm, i.e., inclusive of the start and exclusive of the end. Additionally this change removes the now obsolete `time_range_endpoints` from the form-data and resulting in the cache being busted.\n- [19570](https://github.com/apache/superset/pull/19570): makes [sqloxide](https://pypi.org/project/sqloxide/) optional so the SIP-68 migration can be run on aarch64. If the migration is taking too long installing sqloxide manually should improve the performance.\n- [20170](https://github.com/apache/superset/pull/20170): Introduced a new endpoint for getting datasets samples.\n\n### Breaking Changes\n\n- [19981](https://github.com/apache/superset/pull/19981): Per [SIP-81](https://github.com/apache/superset/issues/19953) the /explore/form_data api now requires a `datasource_type` in addition to a `datasource_id` for POST and PUT requests\n- [19770](https://github.com/apache/superset/pull/19770): Per [SIP-11](https://github.com/apache/superset/issues/6032) and [SIP-68](https://github.com/apache/superset/issues/14909), the native NoSQL Druid connector is deprecated and has been removed. Druid is still supported through SQLAlchemy via pydruid. The config keys `DRUID_IS_ACTIVE` and `DRUID_METADATA_LINKS_ENABLED` have also been removed.\n- [19274](https://github.com/apache/superset/pull/19274): The `PUBLIC_ROLE_LIKE_GAMMA` config key has been removed, set `PUBLIC_ROLE_LIKE = \"Gamma\"` to have the same functionality.\n- [19273](https://github.com/apache/superset/pull/19273): The `SUPERSET_CELERY_WORKERS` and `SUPERSET_WORKERS` config keys has been removed. Configure Celery directly using `CELERY_CONFIG` on Superset.\n- [19231](https://github.com/apache/superset/pull/19231): The `ENABLE_REACT_CRUD_VIEWS` feature flag has been removed (permanently enabled). Any deployments which had set this flag to false will need to verify that the React views support their use case.\n- [19230](https://github.com/apache/superset/pull/19230): The `ROW_LEVEL_SECURITY` feature flag has been removed (permanently enabled). Any deployments which had set this flag to false will need to verify that the presence of the Row Level Security feature does not interfere with their use case.\n- [19168](https://github.com/apache/superset/pull/19168): Celery upgrade to 5.X resulted in breaking changes to its command line invocation.\n  html#step-1-adjust-your-command-line-invocation) instructions for adjustments. Also consider migrating you Celery config per [here](https://docs.celeryq.dev/en/stable/userguide/configuration.html#conf-old-settings-map).\n- [19142](https://github.com/apache/superset/pull/19142): The `VERSIONED_EXPORT` config key is now `True` by default.\n- [19113](https://github.com/apache/superset/pull/19113): The `ENABLE_JAVASCRIPT_CONTROLS` config key has moved from an app config to a feature flag. Any deployments who overrode this setting will now need to override the feature flag from here onward.\n- [19107](https://github.com/apache/superset/pull/19107): The `SQLLAB_BACKEND_PERSISTENCE` feature flag is now `True` by default, which enables persisting SQL Lab tabs in the backend instead of the browser's `localStorage`.\n- [19083](https://github.com/apache/superset/pull/19083): Updates the mutator function in the config file to take a SQL argument and a list of kwargs. Any `SQL_QUERY_MUTATOR` config function overrides will need to be updated to match the new set of params. It is advised regardless of the dictionary args that you list in your function arguments, to keep `**kwargs` as the last argument to allow for any new kwargs to be passed in.\n- [19049](https://github.com/apache/superset/pull/19049): The `APP_ICON_WIDTH` config key has been removed. Superset should now be able to handle different logo sizes without having to explicitly set an `APP_ICON_WIDTH`. This might affect the size of existing custom logos as the UI will now resize them according to the specified space of maximum 148px and not according to the value of `APP_ICON_WIDTH`.\n- [19017](https://github.com/apache/superset/pull/19017): Removes Python 3.7 support.\n- [18970](https://github.com/apache/superset/pull/18970): The `DISABLE_LEGACY_DATASOURCE_EDITOR` feature flag is now `True` by default which disables the legacy datasource editor from being shown in the client.\n\n## 1.5.3\n\n### Other\n\n- [22022](https://github.com/apache/superset/pull/22022): HTTP API endpoints `/superset/approve` and `/superset/request_access` have been deprecated and their HTTP methods were changed from GET to POST\n- [21895](https://github.com/apache/superset/pull/21895): Markdown components had their security increased by adhering to the same sanitization process enforced by GitHub. This means that some HTML elements found in markdowns are not allowed anymore due to the security risks they impose. If you're deploying Superset in a trusted environment and wish to use some of the blocked elements, then you can use the HTML_SANITIZATION_SCHEMA_EXTENSIONS configuration to extend the default sanitization schema. There's also the option to disable HTML sanitization using the HTML_SANITIZATION configuration but we do not recommend this approach because of the security risks. Given the provided configurations, we don't view the improved sanitization as a breaking change but as a security patch.\n\n## 1.5.2\n\n### Other\n\n- [19570](https://github.com/apache/superset/pull/19570): makes [sqloxide](https://pypi.org/project/sqloxide/) optional so the SIP-68 migration can be run on aarch64. If the migration is taking too long installing sqloxide manually should improve the performance.\n\n## 1.5.0\n\n### Breaking Changes\n\n- [18976](https://github.com/apache/superset/pull/18976): When running the app in debug mode, the app will default to use `SimpleCache` for `FILTER_STATE_CACHE_CONFIG` and `EXPLORE_FORM_DATA_CACHE_CONFIG`. When running in non-debug mode, a cache backend will need to be defined, otherwise the application will fail to start. For installations using Redis or other caching backends, it is recommended to use the same backend for both cache configs.\n- [17881](https://github.com/apache/superset/pull/17881): Previously simple adhoc filter values on string columns were stripped of enclosing single and double quotes. To fully support literal quotes in filters, both single and double quotes will no longer be removed from filter values.\n- [17556](https://github.com/apache/superset/pull/17556): Bumps `mysqlclient` from v1 to v2.\n- [17539](https://github.com/apache/superset/pull/17539): All Superset CLI commands, e.g. `init`, `load_examples`, etc. require setting the `FLASK_APP` environment variable (which is set by default when `.flaskenv` is loaded).\n- [15254](https://github.com/apache/superset/pull/15254): The `QUERY_COST_FORMATTERS_BY_ENGINE`, `SQL_VALIDATORS_BY_ENGINE` and `SCHEDULED_QUERIES` feature flags are now defined as config keys given that feature flags are reserved for boolean only values.\n\n### Potential Downtime\n\n- [16756](https://github.com/apache/incubator-superset/pull/16756): a change which renames the `dbs.allow_csv_upload` column to `dbs.allow_file_upload` via a (potentially locking) DDL operation.\n- [17539](https://github.com/apache/superset/pull/17539): all Superset CLI commands\n  (init, load_examples and etc) require setting the FLASK_APP environment variable\n  (which is set by default when .flaskenv is loaded)\n- [17360](https://github.com/apache/superset/pull/17360): changes the column type from `VARCHAR(32)` to `TEXT` in table `table_columns`, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n- [17543](https://github.com/apache/superset/pull/17543): introduces new models from SIP-68. The database migration migrates the old models (`SqlaTable`, `TableColumn`, `SqlMetric`) to the new models (`Column`, `Table`, `Dataset`), and the PR introduces logic to keep the old models in sync with the new ones until they are fully removed. The migration might take considerable time depending on the number of datasets.\n\n### Deprecations\n\n- [18960](https://github.com/apache/superset/pull/18960): Persisting URL params in chart metadata is no longer supported. To set a default value for URL params in Jinja code, use the optional second argument: `url_param(\"my-param\", \"my-default-value\")`.\n\n### Other\n\n- [17589](https://github.com/apache/superset/pull/17589): It is now possible to limit access to users' recent activity data by setting the `ENABLE_BROAD_ACTIVITY_ACCESS` config flag to false, or customizing the `raise_for_user_activity_access` method in the security manager.\n- [17536](https://github.com/apache/superset/pull/17536): introduced a key-value endpoint to store dashboard filter state. This endpoint is backed by Flask-Caching and the default configuration assumes that the values will be stored in the file system. If you are already using another cache backend like Redis or Memcached, you'll probably want to change this setting in `superset_config.py`. The key is `FILTER_STATE_CACHE_CONFIG` and the available settings can be found in Flask-Caching [docs](https://flask-caching.readthedocs.io/en/latest/).\n- [17882](https://github.com/apache/superset/pull/17882): introduced a key-value endpoint to store Explore form data. This endpoint is backed by Flask-Caching and the default configuration assumes that the values will be stored in the file system. If you are already using another cache backend like Redis or Memcached, you'll probably want to change this setting in `superset_config.py`. The key is `EXPLORE_FORM_DATA_CACHE_CONFIG` and the available settings can be found in Flask-Caching [docs](https://flask-caching.readthedocs.io/en/latest/).\n\n## 1.4.1\n\n### Breaking Changes\n\n- [17984](https://github.com/apache/superset/pull/17984): Default Flask SECRET_KEY has changed for security reasons. You should always override with your own secret. Set `PREVIOUS_SECRET_KEY` (ex: PREVIOUS_SECRET_KEY = \"\\2\\1thisismyscretkey\\1\\2\\\\e\\\\y\\\\y\\\\h\") with your previous key and use `superset re-encrypt-secrets` to rotate you current secrets\n\n### Potential Downtime\n\n### Deprecations\n\n### Other\n\n## 1.4.0\n\n### Breaking Changes\n\n- [16660](https://github.com/apache/superset/pull/16660): The `columns` Jinja parameter has been renamed `table_columns` to make the `columns` query object parameter available in the Jinja context.\n- [16711](https://github.com/apache/superset/pull/16711): The `url_param` Jinja function will now by default escape the result. For instance, the value `O'Brien` will now be changed to `O''Brien`. To disable this behavior, call `url_param` with `escape_result` set to `False`: `url_param(\"my_key\", \"my default\", escape_result=False)`.\n\n### Potential Downtime\n\n### Deprecations\n\n### Other\n\n- [16809](https://github.com/apache/superset/pull/16809): When building the superset frontend assets manually, you should now use Node 16 (previously Node 14 was required/recommended). Node 14 will most likely still work for at least some time, but is no longer actively tested for on CI.\n\n## 1.3.0\n\n### Breaking Changes\n\n- [15909](https://github.com/apache/superset/pull/15909): a change which\n  drops a uniqueness criterion (which may or may not have existed) to the tables table. This constraint was obsolete as it is handled by the ORM due to differences in how MySQL, PostgreSQL, etc. handle uniqueness for NULL values.\n\n### Potential Downtime\n\n- [14234](https://github.com/apache/superset/pull/14234): Adds the `limiting_factor` column to the `query` table. Give the migration includes a DDL operation on a heavily trafficked table, potential service downtime may be required.\n- [16454](https://github.com/apache/superset/pull/16454): Adds the `extra` column to the `table_columns` table. Users using MySQL will either need to schedule downtime or use the percona toolkit (or similar) to perform the migration.\n\n## 1.2.0\n\n### Deprecations\n\n- [13440](https://github.com/apache/superset/pull/13440): Dashboard/Charts reports and old Alerts is deprecated. The following config keys are deprecated:\n  - ENABLE_ALERTS\n  - SCHEDULED_EMAIL_DEBUG_MODE\n  - EMAIL_REPORTS_CRON_RESOLUTION\n  - EMAIL_ASYNC_TIME_LIMIT_SEC\n  - EMAIL_REPORT_BCC_ADDRESS\n  - EMAIL_REPORTS_USER\n\n### Other\n\n- [13772](https://github.com/apache/superset/pull/13772): Row level security (RLS) is now enabled by default. To activate the feature, please run `superset init` to expose the RLS menus to Admin users.\n- [13980](https://github.com/apache/superset/pull/13980): Data health checks no longer use the metadata database as an interim cache. Though non-breaking, deployments which implement complex logic should likely memoize the callback function. Refer to documentation in the config.py file for more detail.\n- [14255](https://github.com/apache/superset/pull/14255): The default `CSV_TO_HIVE_UPLOAD_DIRECTORY_FUNC` callable logic has been updated to leverage the specified database and schema to ensure the upload S3 key prefix is unique. Previously tables generated via upload from CSV with the same name but differ schema and/or cluster would use the same S3 key prefix. Note this change does not impact previously imported tables.\n\n## 1.1.0\n\n### Breaking Changes\n\n- This is the first release since we adopted semantic versioning ([SIP-57](https://github.com/apache/superset/issues/12566)). There are no breaking changes in 1.1.0 since this is a minor release.\n\n### Potential Downtime\n\n- [13111](https://github.com/apache/superset/pull/13111) has a database migration that replaces `directed_force` charts with newer `graph_chart` charts based on Apache ECharts.\n- [13216](https://github.com/apache/superset/pull/13216) adds a UUID column to models that are missing it. The original migration script that added the column would incorrectly complete when the column couldn't be added, resulting in a broken schema. The script is optimized for MySQL and Postgres, so depending on the database and the number of objects this migration might take considerable time.\n- [12960](https://github.com/apache/superset/pull/12960) populates the granularity parameter in existing charts. Depending on the number of charts without a `granularity` or `granularity_sqla param` this might take considerable time.\n- [13052](https://github.com/apache/superset/pull/13052) updates the label in existing pie charts, setting `label_type` from `pie_label_type`. Depending on the number of pie charts this might take considerable time.\n- [12680](https://github.com/apache/superset/pull/12680) creates a new table, `dashboard_roles`, for role based dashboard level access.\n- [12552](https://github.com/apache/superset/pull/12552) updates charts that have the time range defined using \"until\" and \"since\". Depending on the number of charts this might take considerable time.\n\n### Deprecations\n\n- [12552](https://github.com/apache/superset/pull/12552) removes the use of unclear time offsets, eg, \"30 days\". An error message is displayed if the user doesn't specify \"ago\" or \"later\", instructing the user of the correct format.\n- [12627](https://github.com/apache/superset/pull/12627) deprecates the legacy alerts module.\n\n### Other\n\n- [shillelagh](https://github.com/betodealmeida/shillelagh/) is now the recommended module to connect Superset to Google Spreadsheets since it's more robust and has extensive test coverage. You should uninstall the `gsheetsdb` module and install the `shillelagh` module in its place. Shillelagh is a drop-in replacement, so no modifications are needed to be done on existing queries, datasets, or charts.\n\n## 1.0.0\n\n### Breaking Changes\n\n- [11509](https://github.com/apache/superset/pull/12491): Dataset metadata updates check user ownership, only owners or an Admin are allowed.\n- Security simplification (SIP-19), the following permission domains were simplified:\n\n  - [12072](https://github.com/apache/superset/pull/12072): `Query` with `can_read`, `can_write`\n  - [12036](https://github.com/apache/superset/pull/12036): `Database` with `can_read`, `can_write`.\n  - [12012](https://github.com/apache/superset/pull/12036): `Dashboard` with `can_read`, `can_write`.\n  - [12061](https://github.com/apache/superset/pull/12061): `Log` with `can_read`, `can_write`.\n  - [12000](https://github.com/apache/superset/pull/12000): `Dataset` with `can_read`, `can_write`.\n  - [12014](https://github.com/apache/superset/pull/12014): `Annotation` with `can_read`, `can_write`.\n  - [11981](https://github.com/apache/superset/pull/11981): `Chart` with `can_read`, `can_write`.\n  - [11853](https://github.com/apache/superset/pull/11853): `ReportSchedule` with `can_read`, `can_write`.\n  - [11856](https://github.com/apache/superset/pull/11856): `CssTemplate` with `can_read`, `can_write`.\n  - [11764](https://github.com/apache/superset/pull/11764): `SavedQuery` with `can_read`, `can_write`.\n    Old permissions will be automatically migrated to these new permissions and applied to all existing security Roles.\n\n- [11499](https://github.com/apache/superset/pull/11499): Breaking change: `STORE_CACHE_KEYS_IN_METADATA_DB` config flag added (default=`False`) to write `CacheKey` records to the metadata DB. `CacheKey` recording was enabled by default previously.\n\n- [11704](https://github.com/apache/superset/pull/11704) Breaking change: Jinja templating for SQL queries has been updated, removing default modules such as `datetime` and `random` and enforcing static template values. To restore or extend functionality, use `JINJA_CONTEXT_ADDONS` and `CUSTOM_TEMPLATE_PROCESSORS` in `superset_config.py`.\n\n- [11509](https://github.com/apache/superset/pull/11509): Config value `TABLE_NAMES_CACHE_CONFIG` has been renamed to `DATA_CACHE_CONFIG`, which will now also hold query results cache from connected datasources (previously held in `CACHE_CONFIG`), in addition to the table names. If you will set `DATA_CACHE_CONFIG` to a new cache backend different than your previous `CACHE_CONFIG`, plan for additional cache warmup to avoid degrading charting performance for the end users.\n\n- [11575](https://github.com/apache/superset/pull/11575) The Row Level Security (RLS) config flag has been moved to a feature flag. To migrate, add `ROW_LEVEL_SECURITY: True` to the `FEATURE_FLAGS` dict in `superset_config.py`.\n\n- [11259](https://github.com/apache/superset/pull/11259): config flag ENABLE_REACT_CRUD_VIEWS has been set to `True` by default, set to `False` if you prefer to the vintage look and feel. However, we may discontinue support on the vintage list view in the future.\n\n- [11244](https://github.com/apache/superset/pull/11244): The `REDUCE_DASHBOARD_BOOTSTRAP_PAYLOAD` feature flag has been removed after being set to True for multiple months.\n\n- [11172](https://github.com/apache/superset/pull/11172): Turning\n  off language selectors by default as i18n is incomplete in most languages\n  and requires more work. You can easily turn on the languages you want\n  to expose in your environment in superset_config.py\n\n- [11172](https://github.com/apache/superset/pull/11172): Breaking change: SQL templating is turned off by default. To turn it on set `ENABLE_TEMPLATE_PROCESSING` to True on `FEATURE_FLAGS`\n\n### Potential Downtime\n\n- [11920](https://github.com/apache/superset/pull/11920): Undoes the DB migration from [11714](https://github.com/apache/superset/pull/11714) to prevent adding new columns to the logs table. Deploying a sha between these two PRs may result in locking your DB.\n\n- [11714](https://github.com/apache/superset/pull/11714): Logs\n  significantly more analytics events (roughly double?), and when\n  using DBEventLogger (default) could result in stressing the metadata\n  database more.\n\n- [11098](https://github.com/apache/superset/pull/11098): includes a database migration that adds a `uuid` column to most models, and updates `Dashboard.position_json` to include chart UUIDs. Depending on number of objects, the migration may take up to 5 minutes, requiring planning for downtime.\n\n### Deprecations\n\n- [11155](https://github.com/apache/superset/pull/11155): The `FAB_UPDATE_PERMS` config parameter is no longer required as the Superset application correctly informs FAB under which context permissions should be updated.\n\n## 0.38.0\n\n- [10887](https://github.com/apache/superset/pull/10887): Breaking change: The custom cache backend changed in order to support the Flask-Caching factory method approach and thus must be registered as a custom type. See [here](https://flask-caching.readthedocs.io/en/latest/#custom-cache-backends) for specifics.\n\n- [10674](https://github.com/apache/superset/pull/10674): Breaking change: PUBLIC_ROLE_LIKE_GAMMA was removed is favour of the new PUBLIC_ROLE_LIKE so it can be set to whatever role you want.\n\n- [10590](https://github.com/apache/superset/pull/10590): Breaking change: this PR will convert iframe chart into dashboard markdown component, and remove all `iframe`, `separator`, and `markup` slices (and support) from Superset. If you have important data in those slices, please backup manually.\n\n- [10562](https://github.com/apache/superset/pull/10562): EMAIL_REPORTS_WEBDRIVER is deprecated use WEBDRIVER_TYPE instead.\n\n- [10567](https://github.com/apache/superset/pull/10567): Default WEBDRIVER_OPTION_ARGS are Chrome-specific. If you're using FF, should be `--headless` only\n\n- [10241](https://github.com/apache/superset/pull/10241): change on Alpha role, users started to have access to \"Annotation Layers\", \"Css Templates\" and \"Import Dashboards\".\n\n- [10324](https://github.com/apache/superset/pull/10324): Facebook Prophet has been introduced as an optional dependency to add support for timeseries forecasting in the chart data API. To enable this feature, install Superset with the optional dependency `prophet` or directly `pip install fbprophet`.\n\n- [10320](https://github.com/apache/superset/pull/10320): References to blacklist/whitelist language have been replaced with more appropriate alternatives. All configs referencing containing `WHITE`/`BLACK` have been replaced with `ALLOW`/`DENY`. Affected config variables that need to be updated: `TIME_GRAIN_BLACKLIST`, `VIZ_TYPE_BLACKLIST`, `DRUID_DATA_SOURCE_BLACKLIST`.\n\n## 0.37.1\n\n- [10794](https://github.com/apache/superset/pull/10794): Breaking change: `uuid` python package is not supported on Jinja2 anymore, only uuid functions are exposed eg: `uuid1`, `uuid3`, `uuid4`, `uuid5`.\n\n## 0.37.0\n\n- [9964](https://github.com/apache/superset/pull/9964): Breaking change on Flask-AppBuilder 3. If you're using OAuth, find out what needs to be changed [here](https://github.com/dpgaspar/Flask-AppBuilder/blob/master/README.rst#change-log).\n\n- [10233](https://github.com/apache/superset/pull/10233): a change which deprecates the `ENABLE_FLASK_COMPRESS` config option in favor of the Flask-Compress `COMPRESS_REGISTER` config option which serves the same purpose.\n\n- [10222](https://github.com/apache/superset/pull/10222): a change which changes how payloads are cached. Previous cached objects cannot be decoded and thus will be reloaded from source.\n\n- [10130](https://github.com/apache/superset/pull/10130): a change which deprecates the `dbs.perm` column in favor of SQLAlchemy [hybrid attributes](https://docs.sqlalchemy.org/en/13/orm/extensions/hybrid.html).\n\n- [10034](https://github.com/apache/superset/pull/10034): a change which deprecates the public security manager `assert_datasource_permission`, `assert_query_context_permission`, `assert_viz_permission`, and `rejected_tables` methods with the `raise_for_access` method which also handles assertion logic for SQL tables.\n\n- [10031](https://github.com/apache/superset/pull/10030): a change which renames the following public security manager methods: `can_access_datasource` to `can_access_table`, `all_datasource_access` to `can_access_all_datasources`, `all_database_access` to `can_access_all_databases`, `database_access` to `can_access_database`, `schema_access` to `can_access_schema`, and\n  `datasource_access` to `can_access_datasource`. Regrettably it is not viable to provide aliases for the deprecated methods as this would result in a name clash. Finally the `can_access_table` (previously `can_access_database`) method signature has changed, i.e., the optional `schema` argument no longer exists.\n\n- [10030](https://github.com/apache/superset/pull/10030): a change which renames the public security manager `schemas_accessible_by_user` method to `get_schemas_accessible_by_user`.\n\n- [9786](https://github.com/apache/superset/pull/9786): with the upgrade of `werkzeug` from version `0.16.0` to `1.0.1`, the `werkzeug.contrib.cache` module has been moved to a standalone package [cachelib](https://pypi.org/project/cachelib/). For example, to import the `RedisCache` class, please use the following import: `from cachelib.redis import RedisCache`.\n\n- [9794](https://github.com/apache/superset/pull/9794): introduces `create view as` functionality in the sqllab. This change will require the `query` table migration and potential service downtime as that table has quite some traffic.\n\n- [9572](https://github.com/apache/superset/pull/9572): a change which by default means that the Jinja `current_user_id`, `current_username`, and `url_param` context calls no longer need to be wrapped via `cache_key_wrapper` in order to be included in the cache key. The `cache_key_wrapper` function should only be required for Jinja add-ons.\n\n## 0.36.0\n\n- [8867](https://github.com/apache/superset/pull/8867): a change which adds the `tmp_schema_name` column to the `query` table which requires locking the table. Given the `query` table is heavily used performance may be degraded during the migration. Scheduled downtime may be advised.\n\n- [9238](https://github.com/apache/superset/pull/9238): the config option `TIME_GRAIN_FUNCTIONS` has been renamed to `TIME_GRAIN_EXPRESSIONS` to better reflect the content of the dictionary.\n\n- [9218](https://github.com/apache/superset/pull/9218): SQLite connections have been disabled by default\n  for analytics databases. You can optionally enable SQLite by setting `PREVENT_UNSAFE_DB_CONNECTIONS` to `False`.\n  It is not recommended to change this setting, as arbitrary SQLite connections can lead to security vulnerabilities.\n\n- [9133](https://github.com/apache/superset/pull/9133): Security list of permissions and list views has been\n  disable by default. You can optionally enable them back again by setting the following config keys:\n  `FAB_ADD_SECURITY_PERMISSION_VIEW`, `FAB_ADD_SECURITY_VIEW_MENU_VIEW`, `FAB_ADD_SECURITY_PERMISSION_VIEWS_VIEW` to `True`.\n\n- [9173](https://github.com/apache/superset/pull/9173): Changes the encoding of the query source from an int to an enum.\n\n- [9120](https://github.com/apache/superset/pull/9120): Changes the default behavior of ad-hoc sharing of\n  queries in SQLLab to one that links to the saved query rather than one that copies the query data into the KVStore\n  model and links to the record there. This is a security-related change that makes SQLLab query\n  sharing respect the existing role-based access controls. Should you wish to retain the existing behavior, set two feature flags:\n  `\"KV_STORE\": True` will re-enable the `/kv/` and `/kv/store/` endpoints, and `\"SHARE_QUERIES_VIA_KV_STORE\": True`\n  will tell the front-end to utilize them for query sharing.\n\n- [9109](https://github.com/apache/superset/pull/9109): Expire `filter_immune_slices` and\n  `filter_immune_filter_fields` to favor dashboard scoped filter metadata `filter_scopes`.\n\n- [9046](https://github.com/apache/superset/pull/9046): Replaces `can_only_access_owned_queries` by\n  `all_query_access` favoring a white list approach. Since a new permission is introduced use `superset init`\n  to create and associate it by default to the `Admin` role. Note that, by default, all non `Admin` users will\n  not be able to access queries they do not own.\n\n- [8901](https://github.com/apache/superset/pull/8901): The datasource's update\n  timestamp has been added to the query object's cache key to ensure updates to\n  datasources are always reflected in associated query results. As a consequence all\n  previously cached results will be invalidated when updating to the next version.\n\n- [8699](https://github.com/apache/superset/pull/8699): A `row_level_security_filters`\n  table has been added, which is many-to-many with `tables` and `ab_roles`. The applicable filters\n  are added to the sqla query, and the RLS ids are added to the query cache keys. If RLS is enabled in config.py (`ENABLE_ROW_LEVEL_SECURITY = True`; by default, it is disabled), they can be\n  accessed through the `Security` menu, or when editing a table.\n\n- [8732](https://github.com/apache/superset/pull/8732): Swagger user interface is now enabled by default.\n  A new permission `show on SwaggerView` is created by `superset init` and given to the `Admin` Role. To disable the UI,\n  set `FAB_API_SWAGGER_UI = False` on config.\n\n- [8721](https://github.com/apache/superset/pull/8721): When using the cache\n  warmup Celery task you should now specify the `SUPERSET_WEBSERVER_PROTOCOL` variable\n  in your configuration (probably either \"http\" or \"https\"). This defaults to \"http\".\n\n- [8512](https://github.com/apache/superset/pull/8512): `DRUID_IS_ACTIVE` now\n  defaults to False. To enable Druid-API-based functionality, override the\n  `DRUID_IS_ACTIVE` configuration variable by setting it to `True` for your deployment.\n\n- [8450](https://github.com/apache/superset/pull/8450): The time range picker\n  now uses UTC for the tooltips and default placeholder timestamps (sans timezone).\n\n- [8418](https://github.com/apache/superset/pull/8418): FLASK_APP / Worker App\n  have changed. FLASK_APP should be updated to `superset.app:create_app()` and Celery Workers\n  should be started with `--app=superset.tasks.celery_app:app`\n\n- [9017](https://github.com/apache/superset/pull/9017): `SIP_15_ENABLED` now\n  defaults to True which ensures that for all new SQL charts the time filter will behave\n  like [start, end). Existing deployments should either disable this feature to keep the\n  status quo or inform their users of this change prior to enabling the flag. The\n  `SIP_15_GRACE_PERIOD_END` option provides a mechanism for specifying how long chart\n  owners have to migrate their charts (the default is indefinite).\n\n## 0.35.0\n\n- [8370](https://github.com/apache/superset/pull/8370): Deprecates\n  the `HTTP_HEADERS` variable in favor of `DEFAULT_HTTP_HEADERS` and\n  `OVERRIDE_HTTP_HEADERS`. To retain the same behavior you should use\n  `OVERRIDE_HTTP_HEADERS` instead of `HTTP_HEADERS`. `HTTP_HEADERS` will still\n  work but may be removed in a future update.\n\n- We're deprecating the concept of \"restricted metric\", this feature\n  was not fully working anyhow.\n- [8117](https://github.com/apache/superset/pull/8117): If you are\n  using `ENABLE_PROXY_FIX = True`, review the newly-introduced variable,\n  `PROXY_FIX_CONFIG`, which changes the proxy behavior in accordance with\n  Werkzeug.\n\n- [8069](https://github.com/apache/superset/pull/8069): introduces\n  [MessagePack](https://github.com/msgpack/msgpack-python) and\n  [PyArrow](https://arrow.apache.org/docs/python/) for async query results\n  backend serialization. To disable set `RESULTS_BACKEND_USE_MSGPACK = False`\n  in your configuration.\n\n- [8371](https://github.com/apache/superset/pull/8371): makes\n  `tables.table_name`, `dbs.database_name`, `datasources.cluster_name`, and `clusters.cluster_name` non-nullable.\n  Depending on the integrity of the data, manual intervention may be required.\n\n## 0.34.0\n\n- [7848](https://github.com/apache/superset/pull/7848): If you are\n  running redis with celery, celery bump to 4.3.0 requires redis-py upgrade to\n  3.2.0 or later.\n\n- [7667](https://github.com/apache/superset/pull/7667): a change to\n  make all Unix timestamp (which by definition are in UTC) comparisons refer\n  to a timestamp in UTC as opposed to local time.\n\n- [7653](https://github.com/apache/superset/pull/7653): a change\n  which deprecates the table_columns.database_expression column. Expressions\n  should be handled by the DB engine spec conversion, Python date format, or\n  custom column expression/type.\n\n- The repo no longer contains translation binaries (`.mo`) files. If you\n  want translations in your build, you now have to run the command\n  `babel-compile --target superset/translations` as part of your builds\n- [5451](https://github.com/apache/superset/pull/5451): a change\n  which adds missing non-nullable fields to the `datasources` table. Depending on\n  the integrity of the data, manual intervention may be required.\n\n- [5452](https://github.com/apache/superset/pull/5452): a change\n  which adds missing non-nullable fields and uniqueness constraints (which may be\n  case insensitive depending on your database configuration) to the `columns`and\n  `table_columns` tables. Depending on the integrity of the data, manual\n  intervention may be required.\n- `fabmanager` command line is deprecated since Flask-AppBuilder 2.0.0, use\n  the new `flask fab <command>` integrated with _Flask cli_.\n- `SUPERSET_UPDATE_PERMS` environment variable was replaced by\n  `FAB_UPDATE_PERMS` config boolean key. To disable automatic\n  creation of permissions set `FAB_UPDATE_PERMS = False` on config.\n- [5453](https://github.com/apache/superset/pull/5453): a change\n  which adds missing non-nullable fields and uniqueness constraints (which may be\n  case insensitive depending on your database configuration) to the metrics\n  and sql_metrics tables. Depending on the integrity of the data, manual\n  intervention may be required.\n- [7616](https://github.com/apache/superset/pull/7616): this bug fix\n  changes time_compare deltas to correctly evaluate to the number of days prior\n  instead of number of days in the future. It will change the data for advanced\n  analytics time_compare so `1 year` from 5/1/2019 will be calculated as 365 days\n  instead of 366 days.\n\n## Superset 0.32.0\n\n- `npm run backend-sync` is deprecated and no longer needed, will fail if called\n- [5445](https://github.com/apache/superset/pull/5445): a change\n  which prevents encoding of empty string from form data in the database.\n  This involves a non-schema changing migration which does potentially impact\n  a large number of records. Scheduled downtime may be advised.\n\n## Superset 0.31.0\n\n- If you use `Hive` or `Presto`, we've moved some dependencies that were\n  in the main package as optional now. To get these packages,\n  run `pip install superset[presto]` and/or `pip install superset[hive]` as\n  required.\n\n- Similarly, if you use Celery's `flower`, `gsheetsdb`, `thrift` or\n  `thrift-sasl`, those dependencies have now been made optional in our\n  package, meaning you may have to install them in your environment post\n  0.31.0\n\n- boto3 / botocore was removed from the dependency list. If you use s3\n  as a place to store your SQL Lab result set or Hive uploads, you may\n  have to rely on an alternate requirements.txt file to install those\n  dependencies.\n- From 0.31.0 onwards, we recommend not using the npm package `yarn` in\n  favor of good old `npm install`. While yarn should still work just fine,\n  you should probably align to guarantee builds similar to the ones we\n  use in testing and across the community in general.\n\n## Superset 0.30.0\n\n- 0.30.0 includes a db_migration that removes allow_run_sync. This may\n  require downtime because during the migration if the db is migrated first,\n  superset will get 500 errors when the code can't find the field (until\n  the deploy finishes).\n\n## Superset 0.29.0\n\n- India was removed from the \"Country Map\" visualization as the geojson\n  file included in the package was very large\n\n- [5933](https://github.com/apache/superset/pull/5933)/[6078](https://github.com/apache/superset/pull/6078): changes which add schema and table metadata cache timeout logic at the database level. If left undefined caching of metadata is disabled.\n\n## Superset 0.28.0\n\n- Support for Python 2 is deprecated, we only support >=3.6 from\n  `0.28.0` onwards\n\n- Superset 0.28 deprecates the previous dashboard layout. While 0.27\n  offered a migration workflow to users and allowed them to validate and\n  publish their migrated dashboards individually, 0.28 forces\n  the migration of all\n  dashboards through an automated db migration script. We\n  do recommend that you take a backup prior to this migration.\n\n- Superset 0.28 deprecates the `median` cluster label aggregator for mapbox visualizations. This particular aggregation is not supported on mapbox visualizations going forward.\n\n- Superset 0.28 upgrades `flask-login` to `>=0.3`, which includes a\n  backwards-incompatible change: `g.user.is_authenticated`,\n  `g.user.is_anonymous`, and `g.user.is_active` are now properties\n  instead of methods.\n\n## Superset 0.27.0\n\n- Superset 0.27 start to use nested layout for dashboard builder, which is not\n  backward-compatible with earlier dashboard grid data. We provide migration script\n  to automatically convert dashboard grid to nested layout data. To be safe, please\n  take a database backup prior to this upgrade. It's the only way people could go\n  back to a previous state.\n\n## Superset 0.26.0\n\n- Superset 0.26.0 deprecates the `superset worker` CLI, which is a simple\n  wrapper around the `celery worker` command, forcing you into crafting\n  your own native `celery worker` command. Your command should look something\n  like `celery worker --app=superset.sql_lab:celery_app --pool=gevent -Ofair`\n\n## Superset 0.25.0\n\nSuperset 0.25.0 contains a backwards incompatible changes.\nIf you run a production system you should schedule downtime for this\nupgrade.\n\nThe PRs below have more information around the breaking changes:\n\n- [9825](https://github.com/apache/superset/pull/9825): Support for Excel sheet upload added. To enable support, install Superset with the optional dependency `excel`\n\n- [4587](https://github.com/apache/superset/pull/4587) : a backward\n  incompatible database migration that requires downtime. Once the\n  db migration succeeds, the web server needs to be restarted with the\n  new version. The previous version will fail\n- [4565](https://github.com/apache/superset/pull/4565) : we've\n  changed the security model a bit where in the past you would have to\n  define your authentication scheme by inheriting from Flask\n  App Builder's\n  `from flask_appbuilder.security.sqla.manager import SecurityManager`,\n  you now have to derive Superset's\n  own derivative `superset.security.SupersetSecurityManager`. This\n  can provide you with more hooks to define your own logic and/or defer\n  permissions to another system as needed. For all implementation, you\n  simply have to import and derive `SupersetSecurityManager` in place\n  of the `SecurityManager`\n- [4835](https://github.com/apache/superset/pull/4835) :\n  our `setup.py` now only pins versions where required, giving you\n  more latitude in using versions of libraries as needed. We do now\n  provide a `requirements.txt` with pinned versions if you want to run\n  the suggested versions that `Superset` builds and runs tests against.\n  Simply `pip install -r requirements.txt` in your build pipeline, likely\n  prior to `pip install superset==0.25.0`\n"
        },
        {
          "name": "docker-compose-image-tag.yml",
          "type": "blob",
          "size": 4.373046875,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-image: &superset-image apachesuperset.docker.scarf.sh/apache/superset:${TAG:-latest-dev}\nx-superset-volumes:\n  &superset-volumes # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - superset_home:/app/superset_home\n\nservices:\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: *superset-image\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app-gunicorn\"]\n    user: \"root\"\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-init:\n    image: *superset-image\n    container_name: superset_init\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker:\n    image: *superset-image\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\",\n        ]\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker-beat:\n    image: *superset-image\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker-compose-non-dev.yml",
          "type": "blob",
          "size": 4.4228515625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-volumes:\n  &superset-volumes # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - superset_home:/app/superset_home\n\nx-common-build: &common-build\n  context: .\n  target: dev\n  cache_from:\n    - apache/superset-cache:3.10-slim-bookworm\n\nservices:\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    build:\n      <<: *common-build\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app-gunicorn\"]\n    user: \"root\"\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-init:\n    container_name: superset_init\n    build:\n      <<: *common-build\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker:\n    build:\n      <<: *common-build\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\",\n        ]\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker-beat:\n    build:\n      <<: *common-build\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 8.5244140625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-user: &superset-user root\nx-superset-volumes: &superset-volumes\n  # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - ./superset:/app/superset\n  - ./superset-frontend:/app/superset-frontend\n  - superset_home:/app/superset_home\n  - ./tests:/app/tests\n\nx-common-build: &common-build\n  context: .\n  target: ${SUPERSET_BUILD_TARGET:-dev} # can use `dev` (default) or `lean`\n  cache_from:\n    - apache/superset-cache:3.10-slim-bookworm\n  args:\n    DEV_MODE: \"true\"\n    INCLUDE_CHROMIUM: ${INCLUDE_CHROMIUM:-false}\n    INCLUDE_FIREFOX: ${INCLUDE_FIREFOX:-false}\n    BUILD_TRANSLATIONS: ${BUILD_TRANSLATIONS:-false}\n\nservices:\n  nginx:\n    image: nginx:latest\n    container_name: superset_nginx\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    volumes:\n      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    ports:\n      - \"127.0.0.1:6379:6379\"\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    ports:\n      - \"127.0.0.1:5432:5432\"\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    build:\n      <<: *common-build\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app\"]\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    user: *superset-user\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-websocket:\n    container_name: superset_websocket\n    build: ./superset-websocket\n    ports:\n      - 8080:8080\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    depends_on:\n      - redis\n    # Mount everything in superset-websocket into container and\n    # then exclude node_modules and dist with bogus volume mount.\n    # This is necessary because host and container need to have\n    # their own, separate versions of these files. .dockerignore\n    # does not seem to work when starting the service through\n    # docker compose.\n    #\n    # For example, node_modules may contain libs with native bindings.\n    # Those bindings need to be compiled for each OS and the container\n    # OS is not necessarily the same as host OS.\n    volumes:\n      - ./superset-websocket:/home/superset-websocket\n      - /home/superset-websocket/node_modules\n      - /home/superset-websocket/dist\n\n      # Mounting a config file that contains a dummy secret required to boot up.\n      # do not use this docker compose in production\n      - ./docker/superset-websocket/config.json:/home/superset-websocket/config.json\n    environment:\n      - PORT=8080\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n      - REDIS_SSL=false\n\n  superset-init:\n    build:\n      <<: *common-build\n    container_name: superset_init\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: *superset-user\n    volumes: *superset-volumes\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    healthcheck:\n      disable: true\n\n  superset-node:\n    build:\n      context: .\n      target: superset-node\n      args:\n        # This prevents building the frontend bundle since we'll mount local folder\n        # and build it on startup while firing docker-frontend.sh in dev mode, where\n        # it'll mount and watch local files and rebuild as you update them\n        DEV_MODE: \"true\"\n        BUILD_TRANSLATIONS: ${BUILD_TRANSLATIONS:-false}\n    environment:\n      # set this to false if you have perf issues running the npm i; npm run dev in-docker\n      # if you do so, you have to run this manually on the host, which should perform better!\n      BUILD_SUPERSET_FRONTEND_IN_DOCKER: true\n      NPM_RUN_PRUNE: false\n      SCARF_ANALYTICS: \"${SCARF_ANALYTICS:-}\"\n    container_name: superset_node\n    command: [\"/app/docker/docker-frontend.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    volumes: *superset-volumes\n\n  superset-worker:\n    build:\n      <<: *common-build\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    environment:\n      CELERYD_CONCURRENCY: 2\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: *superset-user\n    volumes: *superset-volumes\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\"]\n    # Bump memory limit if processing selenium / thumbnails on superset-worker\n    # mem_limit: 2038m\n    # mem_reservation: 128M\n\n  superset-worker-beat:\n    build:\n      <<: *common-build\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      - superset-worker\n    user: *superset-user\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-tests-worker:\n    build:\n      <<: *common-build\n    container_name: superset_tests_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    profiles:\n      - optional\n    environment:\n      DATABASE_HOST: localhost\n      DATABASE_DB: test\n      REDIS_CELERY_DB: 2\n      REDIS_RESULTS_DB: 3\n      REDIS_HOST: localhost\n      CELERYD_CONCURRENCY: 8\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    network_mode: host\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: *superset-user\n    volumes: *superset-volumes\n    healthcheck:\n      test: [\"CMD-SHELL\", \"celery inspect ping -A superset.tasks.celery_app:app -d celery@$$HOSTNAME\"]\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "dockerize.Dockerfile",
          "type": "blob",
          "size": 1.2001953125,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nFROM alpine:latest\n\nARG DOCKERIZE_VERSION=v0.7.0\n\nRUN apk update --no-cache \\\n    && apk add --no-cache wget openssl \\\n    && case \"$(apk --print-arch)\" in \\\n        x86_64) ARCH=amd64 ;; \\\n        aarch64) ARCH=arm64 ;; \\\n       esac \\\n    && wget -O - https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-${ARCH}-${DOCKERIZE_VERSION}.tar.gz | tar xzf - -C /usr/local/bin \\\n    && apk del wget\n\nUSER 10001\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "helm",
          "type": "tree",
          "content": null
        },
        {
          "name": "lintconf.yaml",
          "type": "blob",
          "size": 1.7509765625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n---\nrules:\n  braces:\n    min-spaces-inside: 0\n    max-spaces-inside: 1\n    min-spaces-inside-empty: -1\n    max-spaces-inside-empty: -1\n  brackets:\n    min-spaces-inside: -1\n    max-spaces-inside: -1\n    min-spaces-inside-empty: -1\n    max-spaces-inside-empty: -1\n  colons:\n    max-spaces-before: 0\n    max-spaces-after: 1\n  commas:\n    max-spaces-before: 0\n    min-spaces-after: 1\n    max-spaces-after: 1\n  comments:\n    require-starting-space: false\n    min-spaces-from-content: -1\n  document-end: disable\n  document-start: disable # No --- to start a file\n  empty-lines:\n    max: 2\n    max-start: 0\n    max-end: 0\n  hyphens:\n    max-spaces-after: 1\n  indentation:\n    spaces: consistent\n    indent-sequences: whatever # - list indentation will handle both indentation and without\n    check-multi-line-strings: false\n  key-duplicates: enable\n  line-length: disable # Lines can be any length\n  new-line-at-end-of-file: enable\n  new-lines:\n    type: unix\n  trailing-spaces: enable\n  truthy:\n    level: warning\n"
        },
        {
          "name": "null_byte.csv",
          "type": "blob",
          "size": 0.005859375,
          "content": "A\n\"\u0000\"\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 11.0556640625,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n[build-system]\nrequires = [\"setuptools>=40.9.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"apache-superset\"\ndescription = \"A modern, enterprise-ready business intelligence web application\"\nreadme = \"README.md\"\ndynamic = [\"version\", \"scripts\", \"entry-points\"]\nrequires-python = \">=3.9\"\nlicense = { file=\"LICENSE.txt\" }\nauthors = [\n    { name = \"Apache Software Foundation\", email = \"dev@superset.apache.org\" },\n]\nclassifiers = [\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n]\ndependencies = [\n    \"backoff>=1.8.0\",\n    \"celery>=5.3.6, <6.0.0\",\n    \"click>=8.0.3\",\n    \"click-option-group\",\n    \"colorama\",\n    \"croniter>=0.3.28\",\n    \"cron-descriptor\",\n    \"cryptography>=42.0.4, <44.0.0\",\n    \"deprecation>=2.1.0, <2.2.0\",\n    \"flask>=2.2.5, <3.0.0\",\n    \"flask-appbuilder>=4.5.0, <5.0.0\",\n    \"flask-caching>=2.1.0, <3\",\n    \"flask-compress>=1.13, <2.0\",\n    \"flask-talisman>=1.0.0, <2.0\",\n    \"flask-login>=0.6.0, < 1.0\",\n    \"flask-migrate>=3.1.0, <4.0\",\n    \"flask-session>=0.4.0, <1.0\",\n    \"flask-wtf>=1.1.0, <2.0\",\n    \"geopy\",\n    \"greenlet>=3.0.3, <=3.1.1\",\n    \"gunicorn>=22.0.0; sys_platform != 'win32'\",\n    \"hashids>=1.3.1, <2\",\n    # known issue with holidays 0.26.0 and above related to prophet lib #25017\n    \"holidays>=0.25, <0.26\",\n    \"humanize\",\n    \"importlib_metadata\",\n    \"isodate\",\n    \"jsonpath-ng>=1.6.1, <2\",\n    \"Mako>=1.2.2\",\n    \"markdown>=3.0\",\n    \"msgpack>=1.0.0, <1.1\",\n    \"nh3>=0.2.11, <0.3\",\n    \"numpy==1.23.5\",\n    \"packaging\",\n    # --------------------------\n    # pandas and related (wanting pandas[performance] without numba as it's 100+MB and not needed)\n    \"pandas[excel]>=2.0.3, <2.1\",\n    \"bottleneck\",\n    # --------------------------\n    \"parsedatetime\",\n    \"paramiko>=3.4.0\",\n    \"pgsanity\",\n    \"polyline>=2.0.0, <3.0\",\n    \"pyparsing>=3.0.6, <4\",\n    \"python-dateutil\",\n    \"python-dotenv\",\n    \"python-geohash\",\n    \"pyarrow>=14.0.1, <15\",\n    \"pyyaml>=6.0.0, <7.0.0\",\n    \"PyJWT>=2.4.0, <3.0\",\n    \"redis>=4.6.0, <5.0\",\n    \"selenium>=3.141.0, <4.10.0\",\n    \"shillelagh[gsheetsapi]>=1.2.18, <2.0\",\n    \"shortid\",\n    \"sshtunnel>=0.4.0, <0.5\",\n    \"simplejson>=3.15.0\",\n    \"slack_sdk>=3.19.0, <4\",\n    \"sqlalchemy>=1.4, <2\",\n    \"sqlalchemy-utils>=0.38.3, <0.39\",\n    # known breaking changes in sqlglot 25.25.0\n    #https://github.com/tobymao/sqlglot/blob/main/CHANGELOG.md#v25250---2024-10-14\n    \"sqlglot>=25.24.0,<25.25.0\",\n    \"sqlparse>=0.5.0\",\n    \"tabulate>=0.8.9, <0.9\",\n    \"typing-extensions>=4, <5\",\n    \"waitress; sys_platform == 'win32'\",\n    \"wtforms>=2.3.3, <4\",\n    \"wtforms-json\",\n    \"xlsxwriter>=3.0.7, <3.1\",\n]\n\n[project.optional-dependencies]\n\nathena = [\"pyathena[pandas]>=2, <3\"]\naurora-data-api = [\"preset-sqlalchemy-aurora-data-api>=0.2.8,<0.3\"]\nbigquery = [\n    \"pandas-gbq>=0.19.1\",\n    \"sqlalchemy-bigquery>=1.6.1\",\n    \"google-cloud-bigquery>=3.10.0\",\n]\nclickhouse = [\"clickhouse-connect>=0.5.14, <1.0\"]\ncockroachdb = [\"cockroachdb>=0.3.5, <0.4\"]\ncors = [\"flask-cors>=2.0.0\"]\ncrate = [\"sqlalchemy-cratedb>=0.40.1, <1\"]\ndatabend = [\"databend-sqlalchemy>=0.3.2, <1.0\"]\ndatabricks = [\n    \"databricks-sql-connector>=2.0.2, <3\",\n    \"sqlalchemy-databricks>=0.2.0\",\n]\ndb2 = [\"ibm-db-sa>0.3.8, <=0.4.0\"]\ndenodo = [\"denodo-sqlalchemy~=1.0.6\"]\ndremio = [\"sqlalchemy-dremio>=1.2.1, <4\"]\ndrill = [\"sqlalchemy-drill>=1.1.4, <2\"]\ndruid = [\"pydruid>=0.6.5,<0.7\"]\nduckdb = [\"duckdb-engine>=0.9.5, <0.10\"]\ndynamodb = [\"pydynamodb>=0.4.2\"]\nsolr = [\"sqlalchemy-solr >= 0.2.0\"]\nelasticsearch = [\"elasticsearch-dbapi>=0.2.9, <0.3.0\"]\nexasol = [\"sqlalchemy-exasol >= 2.4.0, <3.0\"]\nexcel = [\"xlrd>=1.2.0, <1.3\"]\nfirebird = [\"sqlalchemy-firebird>=0.7.0, <0.8\"]\nfirebolt = [\"firebolt-sqlalchemy>=1.0.0, <2\"]\ngevent = [\"gevent>=23.9.1\"]\ngsheets = [\"shillelagh[gsheetsapi]>=1.2.18, <2\"]\nhana = [\"hdbcli==2.4.162\", \"sqlalchemy_hana==0.4.0\"]\nhive = [\n    \"pyhive[hive]>=0.6.5;python_version<'3.11'\",\n    \"pyhive[hive_pure_sasl]>=0.7.0\",\n    \"tableschema\",\n    \"thrift>=0.14.1, <1.0.0\",\n    \"thrift_sasl>=0.4.3, < 1.0.0\",\n]\nimpala = [\"impyla>0.16.2, <0.17\"]\nkusto = [\"sqlalchemy-kusto>=2.0.0, <3\"]\nkylin = [\"kylinpy>=2.8.1, <2.9\"]\nmssql = [\"pymssql>=2.2.8, <3\"]\nmysql = [\"mysqlclient>=2.1.0, <3\"]\nocient = [\n    \"sqlalchemy-ocient>=1.0.0\",\n    \"pyocient>=1.0.15, <2\",\n    \"shapely\",\n    \"geojson\",\n]\noracle = [\"cx-Oracle>8.0.0, <8.1\"]\npinot = [\"pinotdb>=5.0.0, <6.0.0\"]\nplaywright = [\"playwright>=1.37.0, <2\"]\npostgres = [\"psycopg2-binary==2.9.6\"]\npresto = [\"pyhive[presto]>=0.6.5\"]\ntrino = [\"trino>=0.328.0\"]\nprophet = [\"prophet>=1.1.5, <2\"]\nredshift = [\"sqlalchemy-redshift>=0.8.1, <0.9\"]\nrockset = [\"rockset-sqlalchemy>=0.0.1, <1\"]\nshillelagh = [\"shillelagh[all]>=1.2.18, <2\"]\nsnowflake = [\"snowflake-sqlalchemy>=1.2.4, <2\"]\nspark = [\n    \"pyhive[hive]>=0.6.5;python_version<'3.11'\",\n    \"pyhive[hive_pure_sasl]>=0.7\",\n    \"tableschema\",\n    \"thrift>=0.14.1, <1\",\n]\nteradata = [\"teradatasql>=16.20.0.23\"]\nthumbnails = [\"Pillow>=10.0.1, <11\"]\nvertica = [\"sqlalchemy-vertica-python>=0.5.9, < 0.6\"]\nnetezza = [\"nzalchemy>=11.0.2\"]\nstarrocks = [\"starrocks>=1.0.0\"]\ndoris = [\"pydoris>=1.0.0, <2.0.0\"]\noceanbase = [\"oceanbase_py>=0.0.1\"]\nydb = [\"ydb-sqlalchemy>=0.1.2\"]\ndevelopment = [\n    \"docker\",\n    \"flask-testing\",\n    \"freezegun\",\n    \"grpcio>=1.55.3\",\n    \"openapi-spec-validator\",\n    \"parameterized\",\n    \"pre-commit\",\n    \"progress>=1.5,<2\",\n    \"psutil\",\n    \"pyfakefs\",\n    \"pyinstrument>=4.0.2,<5\",\n    \"pytest<8.0.0\", # hairy issue with pytest >=8 where current_app proxies are not set in time\n    \"pytest-cov\",\n    \"pytest-mock\",\n    \"python-ldap>=3.4.4\",\n    \"ruff\",\n    \"sqloxide\",\n    \"statsd\",\n]\n\n[project.urls]\nhomepage = \"https://superset.apache.org/\"\ndocumentation = \"https://superset.apache.org/docs/intro\"\n\n\n[tool.isort]\ncombine_as_imports = true\ninclude_trailing_comma = true\nline_length = 88\nknown_first_party = \"superset\"\nknown_third_party = \"alembic, apispec, backoff, celery, click, colorama, cron_descriptor, croniter, cryptography, dateutil, deprecation, flask, flask_appbuilder, flask_babel, flask_caching, flask_compress, flask_jwt_extended, flask_login, flask_migrate, flask_sqlalchemy, flask_talisman, flask_testing, flask_wtf, freezegun, geohash, geopy, holidays, humanize, isodate, jinja2, jwt, markdown, markupsafe, marshmallow, msgpack, nh3, numpy, pandas, parameterized, parsedatetime, pgsanity, polyline, prison, progress, pyarrow, sqlalchemy_bigquery, pyhive, pyparsing, pytest, pytest_mock, pytz, redis, requests, selenium, setuptools, shillelagh, simplejson, slack, sqlalchemy, sqlalchemy_utils, sqlparse, typing_extensions, urllib3, werkzeug, wtforms, wtforms_json, yaml\"\nmulti_line_output = 3\norder_by_type = false\n\n[tool.mypy]\ncheck_untyped_defs = true\ndisallow_any_generics = true\ndisallow_untyped_calls = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\nno_implicit_optional = true\nwarn_unused_ignores = true\n\n[[tool.mypy.overrides]]\nmodule = \"superset.migrations.versions.*\"\nignore_errors = true\n\n[[tool.mypy.overrides]]\nmodule = \"tests.*\"\ncheck_untyped_defs = false\ndisallow_untyped_calls = false\ndisallow_untyped_defs = false\ndisable_error_code = \"annotation-unchecked\"\n\n[tool.ruff]\n# Exclude a variety of commonly ignored directories.\nexclude = [\n    \"**/*.ipynb\",\n    \".bzr\",\n    \".direnv\",\n    \".eggs\",\n    \".git\",\n    \".git-rewrite\",\n    \".hg\",\n    \".ipynb_checkpoints\",\n    \".mypy_cache\",\n    \".nox\",\n    \".pants.d\",\n    \".pyenv\",\n    \".pytest_cache\",\n    \".pytype\",\n    \".ruff_cache\",\n    \".svn\",\n    \".tox\",\n    \".venv\",\n    \".vscode\",\n    \"__pypackages__\",\n    \"_build\",\n    \"buck-out\",\n    \"build\",\n    \"dist\",\n    \"node_modules\",\n    \"site-packages\",\n    \"venv\",\n]\n\n\n# Same as Black.\nline-length = 88\nindent-width = 4\n\n# Assume Python 3.9\ntarget-version = \"py39\"\n\n[tool.ruff.lint]\n# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`)  codes by default.\n# Unlike Flake8, Ruff doesn't enable pycodestyle warnings (`W`) or\n# McCabe complexity (`C901`) by default.\nselect = [\n    \"B904\",\n    \"E4\",\n    \"E7\",\n    \"E9\",\n    \"PT009\",\n    \"TRY201\",\n    \"B\",\n    \"C\",\n    \"E\",\n    \"F\",\n    \"F\",\n    \"I\",\n    \"N\",\n    \"PT\",\n    \"Q\",\n    \"S\",\n    \"T\",\n    \"W\",\n]\nignore = [\n    \"S101\",\n    \"PT006\",\n    \"T201\",\n    \"N999\",\n]\n\nextend-select = [\"I\"]\n\n# Allow fix for all enabled rules (when `--fix`) is provided.\nfixable = [\"ALL\"]\nunfixable = []\n\n# Allow unused variables when underscore-prefixed.\ndummy-variable-rgx = \"^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\"\n\n[tool.ruff.lint.isort]\ncase-sensitive = false\ncombine-as-imports = true\nforce-sort-within-sections = false\nknown-first-party = []\nknown-third-party = []\nlines-after-imports = -1\norder-by-type = false\nsection-order = [\n    \"future\",\n    \"standard-library\",\n    \"third-party\",\n    \"first-party\",\n    \"local-folder\"\n]\n\n[tool.ruff.format]\n# Like Black, use double quotes for strings.\nquote-style = \"double\"\n\n# Like Black, indent with spaces, rather than tabs.\nindent-style = \"space\"\n\n# Like Black, respect magic trailing commas.\nskip-magic-trailing-comma = false\n\n# Like Black, automatically detect the appropriate line ending.\nline-ending = \"auto\"\n\n# Enable auto-formatting of code examples in docstrings. Markdown,\n# reStructuredText code/literal blocks and doctests are all supported.\n#\n# This is currently disabled by default, but it is planned for this\n# to be opt-out in the future.\ndocstring-code-format = false\n\n# Set the line length limit used when formatting code snippets in\n# docstrings.\n#\n# This only has an effect when the `docstring-code-format` setting is\n# enabled.\ndocstring-code-line-length = \"dynamic\"\n\n[tool.liccheck]\nrequirement_txt_file = \"requirements/base.txt\"\nauthorized_licenses = [\n    \"academic free license (afl)\",\n    \"apache license 2.0\",\n    \"apache software\",\n    \"apache software, bsd\",\n    \"bsd\",\n    \"isc license (iscl)\",\n    \"isc license\",\n    \"mit\",\n    \"mozilla public license 2.0 (mpl 2.0)\",\n    \"osi approved\",\n    \"osi approved\",\n    \"python software foundation\",\n    \"the unlicense (unlicense)\",\n    \"the unlicense\",\n]\n[tool.liccheck.authorized_packages]\n# --------------------------------------------------------------\n# These are ok, checked manually\n# Seems ok, might need legal review\n# https://github.com/urschrei/pypolyline/blob/master/LICENSE.md\npolyline = \"2\"\n# Apache 2.0 https://github.com/hkwi/python-geohash\npython-geohash = \"0\"\n# --------------------------------------------------------------\n\n# TODO REMOVE THESE DEPS FROM CODEBASE\nparamiko = \"3\"  # GPL\npyxlsb = \"1\"  # GPL\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.87890625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n[pytest]\ntestpaths =\n    tests\npython_files = *_test.py test_*.py *_tests.py *viz/utils.py\naddopts = -p no:warnings\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.6083984375,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\nimport json\nimport os\nimport subprocess\n\nfrom setuptools import find_packages, setup\n\nBASE_DIR = os.path.abspath(os.path.dirname(__file__))\nPACKAGE_JSON = os.path.join(BASE_DIR, \"superset-frontend\", \"package.json\")\n\n\nwith open(PACKAGE_JSON) as package_file:\n    version_string = json.load(package_file)[\"version\"]\n\n\ndef get_git_sha() -> str:\n    try:\n        output = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])  # noqa: S603, S607\n        return output.decode().strip()\n    except Exception:  # pylint: disable=broad-except\n        return \"\"\n\n\nGIT_SHA = get_git_sha()\nversion_info = {\"GIT_SHA\": GIT_SHA, \"version\": version_string}\nprint(\"-==-\" * 15)\nprint(\"VERSION: \" + version_string)\nprint(\"GIT SHA: \" + GIT_SHA)\nprint(\"-==-\" * 15)\n\nVERSION_INFO_FILE = os.path.join(BASE_DIR, \"superset\", \"static\", \"version_info.json\")\n\nwith open(VERSION_INFO_FILE, \"w\") as version_file:\n    json.dump(version_info, version_file)\n\n# translating 'no version' from npm to pypi to prevent warning msg\nversion_string = version_string.replace(\"-dev\", \".dev0\")\n\nsetup(\n    version=version_string,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    entry_points={\n        \"console_scripts\": [\"superset=superset.cli.main:superset\"],\n        # the `postgres` and `postgres+psycopg2://` schemes were removed in SQLAlchemy 1.4  # noqa: E501\n        # add an alias here to prevent breaking existing databases\n        \"sqlalchemy.dialects\": [\n            \"postgres.psycopg2 = sqlalchemy.dialects.postgresql:dialect\",\n            \"postgres = sqlalchemy.dialects.postgresql:dialect\",\n            \"superset = superset.extensions.metadb:SupersetAPSWDialect\",\n        ],\n        \"shillelagh.adapter\": [\n            \"superset=superset.extensions.metadb:SupersetShillelaghAdapter\"\n        ],\n    },\n    download_url=\"https://www.apache.org/dist/superset/\" + version_string,\n)\n"
        },
        {
          "name": "superset-embedded-sdk",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset-frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset-websocket",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset_text.yml",
          "type": "blob",
          "size": 1.1240234375,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\n# To set the images of your preferred database, you may create a mapping here with engine and locations of the relevant images. The image can be hosted locally inside your static/file directory or online (e.g. S3)\n\n# DB_IMAGES:\n#   postgresql: \"path/to/image/postgres.jpg\"\n#   bigquery: \"path/to/s3bucket/bigquery.jpg\"\n#   snowflake: \"path/to/image/snowflake.jpg\"\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}