{
  "metadata": {
    "timestamp": 1736564605026,
    "page": 253,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "weaviate/Verba",
      "stars": 6589,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2177734375,
          "content": ".env\n.env*\n__pycache__\n.DS_Store\n.pytest_cache\n.python-version\n*.egg-info\nvenv\nvenv*\ndist\nbuild\n~\n.local\n.cache\n.verba\n.vscode\nverba_config.json\ntext-generation-inference\ntest.py\ncache.txt\n.ruff_cache\n*_secrets.json\nollama\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 7.109375,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\n## [2.2.0] Investing in Testing (Suffering will never end)\n\n## [2.1.0] Fixing Bugs and Adding Friends\n\n## Added\n\n- Added Upstage: Reader, Embedder, Generator (https://www.upstage.ai/)\n- Added new deployment type: Custom\n- Added new port configuration (https://github.com/weaviate/Verba/issues/308)\n- Added Groq (https://github.com/weaviate/Verba/pull/278)\n- AssemblyAI Reader for audio files (https://github.com/weaviate/Verba/pull/283)\n- Language Detection for languages like chinese, english, french, german and dutch (https://github.com/weaviate/Verba/pull/302)\n- Improve Markdown Chunking (https://github.com/weaviate/Verba/pull/323)\n- Upgrade to latest Weaviate Client\n- Added Ollama to Docker Compose\n- Added Verba to Docker Hub\n- Added default deployment to skip login screen (https://github.com/weaviate/Verba/issues/305)\n\n## Fixed\n\n- Catch Exception when trying to access the OpenAI API Embedding endpoint to retrieve model names\n- Fixed reading empty string as environment variables (https://github.com/weaviate/Verba/pull/300)\n- Fixed default Unstructed URL (https://github.com/weaviate/Verba/pull/295)\n- Changed Collection names to prevent conflicts with other older Verba version generated collections\n- Ensure Ollama URL is parsed correctly (https://github.com/weaviate/Verba/pull/327)\n- Fixing typos (https://github.com/weaviate/Verba/pull/329)\n- System Message is now a textarea in the frontend (https://github.com/weaviate/Verba/issues/334)\n- Race Condition when multiple requests try to create same client (https://github.com/weaviate/Verba/issues/335)\n- Fix wrong data types when querying additional chunks\n- Remove legacy code (https://github.com/weaviate/Verba/issues/284)\n- Change Python version range below 3.13\n- Firecrawl Reader missing metadata (https://github.com/weaviate/Verba/issues/280)\n\n## [2.0.0] Importastic\n\n## Added\n\n- Async Ingestion with realtime logging\n- Migrated to Weaviate v4 Client\n- Added new File Selection Interface\n- Add Directory Upload\n- Control Settings per file/url individually\n- Import indivdual files or all\n- Overwrite existing files\n- Add multiple labels to documents\n- More configuration for readers, chunkers, and embedders\n- Improved Document Search UI\n- Add Config Validation\n- Add HTML Reader\n- Add Recursive Chunker\n- HTML Chunker\n- Markdown Chunker\n- Code Import\n- Code Chunking\n- Semantic Chunking\n- Label Filter\n- Document Filter (Add document to chat)\n- Add more themes\n- Reworked Admin Interface\n- Added Suggestion View\n- Reworked Suggestion logic\n- Added VoyageAI\n- Added custom metadata\n- Added DocumentExplorer with\n\n  - Content View\n  - Chunk View\n  - Vector View\n    - Visualize vectors of chunks of one or multiple documents\n    - PCA\n\n-\n\n## [1.0.3]\n\n## Added\n\n- Cancel Generation Button\n- Added .docx support\n- Added Documentation for JSON Files\n- Added GitLabReader (https://github.com/weaviate/Verba/pull/151)\n- Improved HuggingFace Embedding Models thanks to @tomaarsen\n- MixedBreadEmbedder\n- AllMPNetEmbedder\n\n## Fixed\n\n- Check error logs coming from Ollama and send it to the frontend\n- Check If Chunks Are NoneType\n\n## [1.0.2]\n\n## Added\n\n- Readme Variable: OPENAI_BASE_URL\n\n## Fixed\n\n- https://github.com/weaviate/Verba/pull/173\n- https://github.com/weaviate/Verba/pull/163\n- https://github.com/weaviate/Verba/pull/148\n\n## [1.0.0] - Beautiful Verba Update\n\n### Added\n\n- Added DaisyUI\n- Optimized frontend codebase\n- Fully Reworked Verba Design\n  - Fully Responsive, optimized for all screen sizes\n- Customization Capabilities\n  - Added Default, Darkmode, Weaviate themes\n  - Full text, color, image customization\n- Improve Chat Interface\n  - Better formatting of markdown + code\n  - Keep conversations saved in localBrowser storage\n  - Better Debugging by providing more information about current states\n- Improve Document Viewer Interface\n  - Add Pagination\n  - Add Sorting\n  - Use Aggregation for Filtering\n- Improve Status Overview\n  - Reworked Frontend + Optimize Code\n  - Sort status entries\n  - Improve Loading Speed by using Aggregation\n- Improve Component Selection for both Ingestion and RAG\n  - Added new configuraiton that will be passed between frontend and backend\n  - Cleaned codebase, merged interfaces and managers to single files\n  - Added clean endpoints for better code readability\n  - Reworked on interfaces\n- Added better console and logging for ingestion\n- More Configuration\n  - Enable/Disable Caching and Autocomplete Suggestions\n  - Improved verba_config.json\n- Ability to enable/disable caching + autosuggestions\n- Add Google Gemini as new Embedder and Generator\n- Added .CSV support (all file types available in Unstructured IO)\n- More test data\n- Add Ollama as Generator and Embedding Component\n- Add Support for Cohere R+\n- Improved WindowRetriever Context Generation\n- Show RAW Context in Frontend + Save in LocalStorage\n- Save Settings and Configuration in Weaviate\n\n### Changed\n\n- Changed to AppRouter framework\n- Changed frontend project structure\n- Changed backend project structure\n- Removed Llama Generator Component\n\n### Fixed\n\n- Using Accelerator Library\n\n## [0.4.0] - 11.04.2024\n\n### Added\n\n- Improved Docker Documentation\n- Improved Docker Settings\n- New Environment Variables for OpenAI proxies: OpenAI_BASE_URL (LiteLLM support) (https://github.com/weaviate/Verba/issues/56)\n- Increased version\n\n### Changed\n\n- Removed spaCy from project\n\n### Fixed\n\n- Python not working on version 3.12, 3.11, and 3.9\n- GitHub Links on README\n- Fix Docker Default Vectorizer (https://github.com/weaviate/Verba/issues/50)\n- Fix requirements.txt spelling error\n- Minor Bug fixes\n\n## [0.3.1] - 15.11.2023\n\n### Added\n\n- PDFReader powered by PyPDF2\n- TokenChunker powered by tiktoken\n- Ruff Linting (set as pre-commit)\n- Markdown Formatting for chat messages (https://github.com/weaviate/Verba/issues/48)\n\n### Fixed\n\n- Added missing dependencies\n- Fixed restart bug\n- Fixed MiniLM Cuda to_device bug (https://github.com/weaviate/Verba/issues/41)\n- Fixed Config Issues (https://github.com/weaviate/Verba/issues/51)\n- Fixed Weaviate Embedded Headers for Cohere\n\n## [0.3.0] - 12.09.2023\n\n### Added\n\n- Refactor modular architecture\n- Add ability to import data through the frontend, CLI, and script\n- Add Readers (SimpleReader, PathReader, GithubReader, PDFReader)\n- Add Chunkers (WordChunker, SentenceChunker)\n- Add Embedders (ADAEmbedder,SentenceTransformer, Cohere)\n- Add Generators (GPT3, GPT4, LLama, Cohere)\n- Status Page\n- Reset functionality\n- Streaming Token Generation\n- Lazy Document Loading\n- Add Copy and Cached Tag\n- Improved Semantic Cache\n- Added LLama 2 and Cohere support\n- Added new OpenAI models\n- Improved Documentation\n- Added technical docs and contribution guidelines\n\n### Fixed\n\n- Error handling for data ingestion (handling chunk size)\n- Schmea handling on startup\n\n### Changed\n\n- Removed Simple- and AdvancedEngine logic\n\n## [0.2.3] - 05.09.2023\n\n### Added\n\n- OpenAI API documentation example dataset\n\n## [0.2.2] - 31.08.2023\n\n### Release!\n\n- First version of Verba released! (many to come :)\n\n### Added\n\n- Verba favicon\n\n### Fixed\n\n- Add static files to package\n- Weaviate Embedded not shutting down\n\n## [0.1.0] - 29.08.2023\n\n### Added\n\n- Prepare Verba for first release\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.03125,
          "content": "# Verba Contribution Guidelines\n\nWelcome to the Verba community! We're thrilled that you're interested in contributing to the Verba project. Verba is a collaborative open-source project, and we believe that everyone has something unique to contribute. Below you'll find our guidelines which aim to make contributing to Verba a respectful and pleasant experience for everyone.\n\n## üåü Community and Open Source\n\nOpen source is at the heart of Verba. We appreciate feedback, ideas, and enhancements from the community. Whether you're looking to fix a bug, add a new feature, or simply improve the documentation, your contribution is important to us.\n\n## üìö Before You Begin\n\nBefore contributing, please take a moment to read through the [README](https://github.com/weaviate/Verba/README.md) and the [Technical Documentation](https://github.com/weaviate/Verba/TECHNICAL.md). These documents provide a comprehensive understanding of the project and are essential reading to ensure that we're all on the same page.\n\n## üêõ Reporting Issues\n\nIf you've identified a bug or have an idea for an enhancement, please begin by creating an Issue. Here's how:\n\n- Check the Issue tracker to ensure the bug or enhancement hasn't already been reported.\n- Clearly describe the issue including steps to reproduce when it is a bug.\n- Include as much relevant information as possible.\n\n## üí° Ideas and Feedback\n\nWe welcome all ideas and feedback. If you're not ready to open an Issue or if you're just looking for a place to discuss ideas, head over to our [GitHub Discussions](https://github.com/weaviate/Verba/discussions) or the [Weaviate Support Page](https://forum.weaviate.io/).\n\n## üìù Pull Requests\n\nIf you're ready to contribute code or documentation, please submit a Pull Request (PR) to the dev branch. Here's the process:\n\n- Fork the repository and create your branch from `main`.\n- Ensure that your code adheres to the existing code style. Use [Black](https://github.com/psf/black) for formatting Python code.\n- If you're adding a new feature, consider writing unit tests and documenting the feature.\n- Verify that your changes pass existing unit tests\n- Make sure your code lints (mypy compatibility is optional but encouraged).\n- Include a clear description of your changes in the PR.\n- Link to the Issue in your PR description.\n\n### üß™ Tests and Formatting\n\nTo maintain the quality of the codebase, we ask that all contributors:\n\n- Run unit tests to ensure that nothing is broken.\n- Use [Black](https://github.com/psf/black) to format your code before submitting.\n\n### üîÑ Pull Request Process\n\n- PRs are reviewed on a regular basis.\n- Engage in the conversation and make requested updates to your PR if needed.\n- Once approved, your PR will be merged into the main branch by a maintainer.\n\n## üó®Ô∏è Stay Connected\n\nWe encourage you to join our community channels. Stay connected, share ideas, and get to know fellow contributors.\n\nThank you for being a part of Verba. Your contributions not only help improve the project but also the wider community of users and developers.\n\nHappy contributing!\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.1328125,
          "content": "FROM python:3.11\nWORKDIR /Verba\nCOPY . /Verba\nRUN pip install '.'\nEXPOSE 8000\nCMD [\"verba\", \"start\",\"--port\",\"8000\",\"--host\",\"0.0.0.0\"]\n"
        },
        {
          "name": "FRONTEND.md",
          "type": "blob",
          "size": 1.2470703125,
          "content": "# Verba - Frontend Documentation\n\nVerba's Frontend is a [NextJS](https://nextjs.org/) application used together with [TailwindCSS](https://tailwindcss.com/) and [DaisyUI](https://daisyui.com/).\n\n## üöÄ Setting Up the Frontend\n\nTo get your local copy of the Verba frontend up and running, please follow these simple steps:\n\n1. Clone Repository\n\n```git\n\ngit clone https://github.com/weaviate/Verba.git\n\n```\n\n1. **Node.js Requirement**:\n\n   - Confirm that Node.js version `>=21.3.0` is installed on your system. If you need to install or update Node.js, visit the official [Node.js website](https://nodejs.org/).\n\n2. **Installation**:\n\n   - Navigate to the frontend directory: `cd frontend`\n   - Run `npm install` to install the dependencies required for the project.\n\n3. **Development Server**:\n   - Launch the application in development mode by executing `npm run dev`.\n   - Open your web browser and visit `http://localhost:3000` to view the application.\n\n## üì¶ Building Static Pages for FastAPI\n\nIf you wish to serve and update the frontend through FastAPI, you need to build static pages:\n\n1. **Build Process**:\n   - Execute `npm run build` to generate the static production build. The output will be directed to the FastAPI folder configured to serve the static content.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4677734375,
          "content": "Copyright (c) 2020-2023, Weaviate B.V.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0498046875,
          "content": "recursive-include goldenverba/server/frontend/out *"
        },
        {
          "name": "PYTHON_TUTORIAL.md",
          "type": "blob",
          "size": 2.130859375,
          "content": "# Installing Python and Setting Up a Virtual Environment\n\nBefore you can use Verba, you'll need to ensure that `Python >=3.10.0` is installed on your system and that you can create a virtual environment for a safer and cleaner project setup.\n\n## Installing Python\n\nPython is required to run Verba. If you don't have Python installed, follow these steps:\n\n### For Windows:\n\nDownload the latest Python installer from the official Python website.\nRun the installer and make sure to check the box that says `Add Python to PATH` during installation.\n\n### For macOS:\n\nYou can install Python using Homebrew, a package manager for macOS, with the following command in the terminal:\n\n```\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\nThen install Python:\n\n```\nbrew install python\n```\n\n### For Linux:\n\nPython usually comes pre-installed on most Linux distributions. If it's not, you can install it using your distribution's package manager. You can read more about it [here](https://opensource.com/article/20/4/install-python-linux)\n\n## Setting Up a Virtual Environment\n\nIt's recommended to use a virtual environment to avoid conflicts with other projects or system-wide Python packages.\n\n### Install the virtualenv package:\n\nFirst, ensure you have pip installed (it comes with Python if you're using version 3.4 and above).\nInstall virtualenv by running:\n\n```\npip install virtualenv\n```\n\n### Create a Virtual Environment:\n\nNavigate to your project's directory in the terminal.\nRun the following command to create a virtual environment named venv (you can name it anything you like):\n\n```\npython3 -m virtualenv venv\n```\n\n### Activate the Virtual Environment:\n\n- On Windows, activate the virtual environment by running:\n\n```\nvenv\\Scripts\\activate.bat\n```\n\n- On macOS and Linux, activate it with:\n\n```\nsource venv/bin/activate\n```\n\nOnce your virtual environment is activated, you'll see its name in the terminal prompt. Now you're ready to install Verba using the steps provided in the Quickstart sections.\n\n> Remember to deactivate the virtual environment when you're done working with Verba by simply running deactivate in the terminal.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 27.19140625,
          "content": "# Verba\n\n## The Golden RAGtriever - Community Edition ‚ú®\n\n[![Weaviate](https://img.shields.io/static/v1?label=powered%20by&message=Weaviate%20%E2%9D%A4&color=green&style=flat-square)](https://weaviate.io/)\n[![PyPi downloads](https://static.pepy.tech/personalized-badge/goldenverba?period=total&units=international_system&left_color=grey&right_color=orange&left_text=pip%20downloads)](https://pypi.org/project/goldenverba/) [![Docker support](https://img.shields.io/badge/Docker_support-%E2%9C%93-4c1?style=flat-square&logo=docker&logoColor=white)](https://docs.docker.com/get-started/) [![Demo](https://img.shields.io/badge/Check%20out%20the%20demo!-yellow?&style=flat-square&logo=react&logoColor=white)](https://verba.weaviate.io/)\n\nWelcome to Verba: The Golden RAGtriever, an community-driven open-source application designed to offer an end-to-end, streamlined, and user-friendly interface for Retrieval-Augmented Generation (RAG) out of the box. In just a few easy steps, explore your datasets and extract insights with ease, either locally with Ollama and Huggingface or through LLM providers such as Anthrophic, Cohere, and OpenAI. This project is built with and for the community, please be aware that it might not be maintained with the same urgency as other Weaviate production applications. Feel free to contribute to the project and help us make Verba even better! <3\n\n```\npip install goldenverba\n```\n\n![Demo of Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/verba.gif)\n\n- [Verba](#verba)\n  - [üéØ What Is Verba?](#what-is-verba)\n  - [‚ú® Features](#feature-lists)\n- [‚ú® Getting Started with Verba](#getting-started-with-verba)\n- [üîë API Keys](#api-keys)\n  - [Weaviate](#weaviate)\n  - [Ollama](#ollama)\n  - [Unstructured](#unstructured)\n  - [AssemblyAI](#assemblyai)\n  - [OpenAI](#openai)\n  - [HuggingFace](#huggingface)\n  - [Groq](#groq)\n- [Quickstart: Deploy with pip](#how-to-deploy-with-pip)\n- [Quickstart: Build from Source](#how-to-build-from-source)\n- [Quickstart: Deploy with Docker](#how-to-install-verba-with-docker)\n- [üíæ Verba Walkthrough](#Ô∏èverba-walkthrough)\n- [üíñ Open Source Contribution](#open-source-contribution)\n- [üö© Known Issues](#known-issues)\n- [‚ùîFAQ](#faq)\n\n## What Is Verba?\n\nVerba is a fully-customizable personal assistant utilizing [Retrieval Augmented Generation (RAG)](https://weaviate.io/rag#:~:text=RAG%20with%20Weaviate,accuracy%20of%20AI%2Dgenerated%20content.) for querying and interacting with your data, **either locally or deployed via cloud**. Resolve questions around your documents, cross-reference multiple data points or gain insights from existing knowledge bases. Verba combines state-of-the-art RAG techniques with Weaviate's context-aware database. Choose between different RAG frameworks, data types, chunking & retrieving techniques, and LLM providers based on your individual use-case.\n\n## Open Source Spirit\n\n**Weaviate** is proud to offer this open-source project for the community. While we strive to address issues as fast as we can, please understand that it may not be maintained with the same rigor as production software. We welcome and encourage community contributions to help keep it running smoothly. Your support in fixing open issues quickly is greatly appreciated.\n\n### Watch our newest Verba video here:\n\n[![VIDEO LINK](https://github.com/weaviate/Verba/blob/main/img/thumbnail.png)](https://www.youtube.com/watch?v=2VCy-YjRRhA&t=40s&ab_channel=Weaviate%E2%80%A2VectorDatabase)\n\n## Feature Lists\n\n| ü§ñ Model Support                  | Implemented | Description                                             |\n| --------------------------------- | ----------- | ------------------------------------------------------- |\n| Ollama (e.g. Llama3)              | ‚úÖ          | Local Embedding and Generation Models powered by Ollama |\n| HuggingFace (e.g. MiniLMEmbedder) | ‚úÖ          | Local Embedding Models powered by HuggingFace           |\n| Cohere (e.g. Command R+)          | ‚úÖ          | Embedding and Generation Models by Cohere               |\n| Anthrophic (e.g. Claude Sonnet)   | ‚úÖ          | Embedding and Generation Models by Anthrophic           |\n| OpenAI (e.g. GPT4)                | ‚úÖ          | Embedding and Generation Models by OpenAI               |\n| Groq (e.g. Llama3)                | ‚úÖ          | Generation Models by Groq (LPU inference)               |\n| Upstage (e.g. Solar)              | ‚úÖ          | Embedding and Generation Models by Upstage              |\n\n| ü§ñ Embedding Support | Implemented | Description                              |\n| -------------------- | ----------- | ---------------------------------------- |\n| Weaviate             | ‚úÖ          | Embedding Models powered by Weaviate     |\n| Ollama               | ‚úÖ          | Local Embedding Models powered by Ollama |\n| SentenceTransformers | ‚úÖ          | Embedding Models powered by HuggingFace  |\n| Cohere               | ‚úÖ          | Embedding Models by Cohere               |\n| VoyageAI             | ‚úÖ          | Embedding Models by VoyageAI             |\n| OpenAI               | ‚úÖ          | Embedding Models by OpenAI               |\n| Upstage              | ‚úÖ          | Embedding Models by Upstage              |\n\n| üìÅ Data Support                                          | Implemented | Description                                    |\n| -------------------------------------------------------- | ----------- | ---------------------------------------------- |\n| [UnstructuredIO](https://docs.unstructured.io/welcome)   | ‚úÖ          | Import Data through Unstructured               |\n| [Firecrawl](https://www.firecrawl.dev/)                  | ‚úÖ          | Scrape and Crawl URL through Firecrawl         |\n| [UpstageDocumentParse](https://upstage.ai/)              | ‚úÖ          | Parse Documents through Upstage Document AI    |\n| PDF Ingestion                                            | ‚úÖ          | Import PDF into Verba                          |\n| GitHub & GitLab                                          | ‚úÖ          | Import Files from Github and GitLab            |\n| CSV/XLSX Ingestion                                       | ‚úÖ          | Import Table Data into Verba                   |\n| .DOCX                                                    | ‚úÖ          | Import .docx files                             |\n| Multi-Modal (using [AssemblyAI](https://assemblyai.com)) | ‚úÖ          | Import and Transcribe Audio through AssemblyAI |\n\n| ‚ú® RAG Features         | Implemented     | Description                                                               |\n| ----------------------- | --------------- | ------------------------------------------------------------------------- |\n| Hybrid Search           | ‚úÖ              | Semantic Search combined with Keyword Search                              |\n| Autocomplete Suggestion | ‚úÖ              | Verba suggests autocompletion                                             |\n| Filtering               | ‚úÖ              | Apply Filters (e.g. documents, document types etc.) before performing RAG |\n| Customizable Metadata   | ‚úÖ              | Free control over Metadata                                                |\n| Async Ingestion         | ‚úÖ              | Ingest data asynchronously to speed up the process                        |\n| Advanced Querying       | planned ‚è±Ô∏è      | Task Delegation Based on LLM Evaluation                                   |\n| Reranking               | planned ‚è±Ô∏è      | Rerank results based on context for improved results                      |\n| RAG Evaluation          | planned ‚è±Ô∏è      | Interface for Evaluating RAG pipelines                                    |\n| Agentic RAG             | out of scope ‚ùå | Agentic RAG pipelines                                                     |\n| Graph RAG               | out of scope ‚ùå | Graph-based RAG pipelines                                                 |\n\n| üó°Ô∏è Chunking Techniques | Implemented | Description                                             |\n| ---------------------- | ----------- | ------------------------------------------------------- |\n| Token                  | ‚úÖ          | Chunk by Token powered by [spaCy](https://spacy.io/)    |\n| Sentence               | ‚úÖ          | Chunk by Sentence powered by [spaCy](https://spacy.io/) |\n| Semantic               | ‚úÖ          | Chunk and group by semantic sentence similarity         |\n| Recursive              | ‚úÖ          | Recursively chunk data based on rules                   |\n| HTML                   | ‚úÖ          | Chunk HTML files                                        |\n| Markdown               | ‚úÖ          | Chunk Markdown files                                    |\n| Code                   | ‚úÖ          | Chunk Code files                                        |\n| JSON                   | ‚úÖ          | Chunk JSON files                                        |\n\n| üÜí Cool Bonus            | Implemented     | Description                                             |\n| ------------------------ | --------------- | ------------------------------------------------------- |\n| Docker Support           | ‚úÖ              | Verba is deployable via Docker                          |\n| Customizable Frontend    | ‚úÖ              | Verba's frontend is fully-customizable via the frontend |\n| Vector Viewer            | ‚úÖ              | Visualize your data in 3D                               |\n| Multi-User Collaboration | out of scope ‚ùå | Multi-User Collaboration in Verba                       |\n\n| ü§ù RAG Libraries | Implemented | Description                        |\n| ---------------- | ----------- | ---------------------------------- |\n| LangChain        | ‚úÖ          | Implement LangChain RAG pipelines  |\n| Haystack         | planned ‚è±Ô∏è  | Implement Haystack RAG pipelines   |\n| LlamaIndex       | planned ‚è±Ô∏è  | Implement LlamaIndex RAG pipelines |\n\n> Something is missing? Feel free to create a new issue or discussion with your idea!\n\n![Showcase of Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/verba_screen.png)\n\n---\n\n# Getting Started with Verba\n\nYou have three deployment options for Verba:\n\n- Install via pip\n\n```\npip install goldenverba\n```\n\n- Build from Source\n\n```\ngit clone https://github.com/weaviate/Verba\n\npip install -e .\n```\n\n- Use Docker for Deployment\n\n**Prerequisites**: If you're not using Docker, ensure that you have `Python >=3.10.0,<3.13.0` installed on your system.\n\n```\ngit clone https://github.com/weaviate/Verba\n\ndocker compose --env-file <your-env-file> up -d --build\n```\n\nIf you're unfamiliar with Python and Virtual Environments, please read the [python tutorial guidelines](./PYTHON_TUTORIAL.md).\n\n# API Keys and Environment Variables\n\nYou can set all API keys in the Verba frontend, but to make your life easier, we can also prepare a `.env` file in which Verba will automatically look for the keys. Create a `.env` in the same directory you want to start Verba in. You can find an `.env.example` file in the [goldenverba](./goldenverba/.env.example) directory.\n\n> Make sure to only set environment variables you intend to use, environment variables with missing or incorrect values may lead to errors.\n\nBelow is a comprehensive list of the API keys and variables you may require:\n\n| Environment Variable   | Value                                                      | Description                                                                                                    |\n| ---------------------- | ---------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n| WEAVIATE_URL_VERBA     | URL to your hosted Weaviate Cluster                        | Connect to your [WCS](https://console.weaviate.cloud/) Cluster                                                 |\n| WEAVIATE_API_KEY_VERBA | API Credentials to your hosted Weaviate Cluster            | Connect to your [WCS](https://console.weaviate.cloud/) Cluster                                                 |\n| ANTHROPIC_API_KEY      | Your Anthropic API Key                                     | Get Access to [Anthropic](https://www.anthropic.com/) Models                                                   |\n| OPENAI_API_KEY         | Your OpenAI Key                                            | Get Access to [OpenAI](https://openai.com/) Models                                                             |\n| OPENAI_BASE_URL        | URL to OpenAI instance                                     | Models                                                                                                         |\n| COHERE_API_KEY         | Your API Key                                               | Get Access to [Cohere](https://cohere.com/) Models                                                             |\n| GROQ_API_KEY           | Your Groq API Key                                          | Get Access to [Groq](https://groq.com/) Models                                                                 |\n| OLLAMA_URL             | URL to your Ollama instance (e.g. http://localhost:11434 ) | Get Access to [Ollama](https://ollama.com/) Models                                                             |\n| UNSTRUCTURED_API_KEY   | Your API Key                                               | Get Access to [Unstructured](https://docs.unstructured.io/welcome) Data Ingestion                              |\n| UNSTRUCTURED_API_URL   | URL to Unstructured Instance                               | Get Access to [Unstructured](https://docs.unstructured.io/welcome) Data Ingestion                              |\n| ASSEMBLYAI_API_KEY     | Your API Key                                               | Get Access to [AssemblyAI](https://assemblyai.com) Data Ingestion                                              |\n| GITHUB_TOKEN           | Your GitHub Token                                          | Get Access to Data Ingestion via GitHub                                                                        |\n| GITLAB_TOKEN           | Your GitLab Token                                          | Get Access to Data Ingestion via GitLab                                                                        |\n| FIRECRAWL_API_KEY      | Your Firecrawl API Key                                     | Get Access to Data Ingestion via Firecrawl                                                                     |\n| VOYAGE_API_KEY         | Your VoyageAI API Key                                      | Get Access to Embedding Models via VoyageAI                                                                    |\n| EMBEDDING_SERVICE_URL  | URL to your Embedding Service Instance                     | Get Access to Embedding Models via [Weaviate Embedding Service](https://weaviate.io/developers/wcs/embeddings) |\n| EMBEDDING_SERVICE_KEY  | Your Embedding Service Key                                 | Get Access to Embedding Models via [Weaviate Embedding Service](https://weaviate.io/developers/wcs/embeddings) |\n| UPSTAGE_API_KEY        | Your Upstage API Key                                       | Get Access to [Upstage](https://upstage.ai/) Models                                                            |\n| UPSTAGE_BASE_URL       | URL to Upstage instance                                    | Models                                                                                                         |\n| DEFAULT_DEPLOYMENT     | Local, Weaviate, Custom, Docker                            | Set the default deployment mode                                                                                |\n\n![API Keys in Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/api_screen.png)\n\n## Weaviate\n\nVerba provides flexibility in connecting to Weaviate instances based on your needs. You have three options:\n\n1. **Local Deployment**: Use Weaviate Embedded which runs locally on your device (except Windows, choose the Docker/Cloud Deployment)\n2. **Docker Deployment**: Choose this option when you're running Verba's Dockerfile.\n3. **Cloud Deployment**: Use an existing Weaviate instance hosted on WCD to run Verba\n\n**üíª Weaviate Embedded**\nEmbedded Weaviate is a deployment model that runs a Weaviate instance from your application code rather than from a stand-alone Weaviate server installation. When you run Verba in `Local Deployment`, it will setup and manage Embedded Weaviate in the background. Please note that Weaviate Embedded is not supported on Windows and is in Experimental Mode which can bring unexpected errors. We recommend using the Docker Deployment or Cloud Deployment instead. You can read more about Weaviate Embedded [here](https://weaviate.io/developers/weaviate/installation/embedded).\n\n**üå©Ô∏è Weaviate Cloud Deployment (WCD)**\n\nIf you prefer a cloud-based solution, Weaviate Cloud (WCD) offers a scalable, managed environment. Learn how to set up a cloud cluster and get the API keys by following the [Weaviate Cluster Setup Guide](https://weaviate.io/developers/wcs/guides/create-instance).\n\n**üê≥ Docker Deployment**\nAnother local alternative is deploying Weaviate using Docker. For more details, follow the [How to install Verba with Docker](#how-to-install-verba-with-docker) section.\n\n![Deployment in Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/verba_deployment.png)\n\n**‚öôÔ∏è Custom Weaviate Deployment**\n\nIf you're hosting Weaviate yourself, you can use the `Custom` deployment option in Verba. This will allow you to specify the URL, PORT, and API key of your Weaviate instance.\n\n## Ollama\n\nVerba supports Ollama models. Download and Install Ollama on your device (https://ollama.com/download). Make sure to install your preferred LLM using `ollama run <model>`.\n\nTested with `llama3`, `llama3:70b` and `mistral`. The bigger models generally perform better, but need more computational power.\n\n> Make sure Ollama Server runs in the background and that you don't ingest documents with different ollama models since their vector dimension can vary that will lead to errors\n\nYou can verify that by running the following command\n\n```\nollama run llama3\n```\n\n## Unstructured\n\nVerba supports importing documents through Unstructured IO (e.g plain text, .pdf, .csv, and more). To use them you need the `UNSTRUCTURED_API_KEY` and `UNSTRUCTURED_API_URL` environment variable. You can get it from [Unstructured](https://unstructured.io/)\n\n> UNSTRUCTURED_API_URL is set to `https://api.unstructuredapp.io/general/v0/general` by default\n\n## AssemblyAI\n\nVerba supports importing documents through AssemblyAI (audio files or audio from video files). To use them you need the `ASSEMBLYAI_API_KEY` environment variable. You can get it from [AssemblyAI](https://assemblyai.com)\n\n## OpenAI\n\nVerba supports OpenAI Models such as Ada, GPT3, and GPT4. To use them, you need to specify the `OPENAI_API_KEY` environment variable. You can get it from [OpenAI](https://openai.com/)\n\nYou can also add a `OPENAI_BASE_URL` to use proxies such as LiteLLM (https://github.com/BerriAI/litellm)\n\n```\nOPENAI_BASE_URL=YOUR-OPENAI_BASE_URL\n```\n\n## HuggingFace\n\nIf you want to use the HuggingFace Features, make sure to install the correct Verba package. It will install required packages to use the local embedding models.\nPlease note that on startup, Verba will automatically download and install embedding models when used.\n\n```bash\npip install goldenverba[huggingface]\n\nor\n\npip install `.[huggingface]`\n```\n\n> If you're using Docker, modify the `Dockerfile` accordingly. It's not possible to install a custom Verba installation if you pull the Docker Image from the Docker Hub, as of now, you'd need to install the Docker deployment from the source code and modify the `Dockerfile` beforehand.\n\n## Groq\n\nTo use Groq LPUs as generation engine, you need to get an API key from [Groq](https://console.groq.com/keys).\n\n> Although you can provide it in the graphical interface when Verba is up, it is recommended to specify it as `GROQ_API_KEY` environment variable before you launch the application.  \n> It will allow you to choose the generation model in an up-to-date available models list.\n\n# How to deploy with pip\n\n`Python >=3.10.0`\n\n1. (Very Important) **Initialize a new Python Environment**\n\n```\npython3 -m virtualenv venv\nsource venv/bin/activate\n```\n\n2. **Install Verba**\n\n```\npip install goldenverba\n```\n\n3. **Launch Verba**\n\n```\nverba start\n```\n\n> You can specify the --port and --host via flags\n\n4. **Access Verba**\n\n```\nVisit localhost:8000\n```\n\n5. (Optional)**Create .env file and add environment variables**\n\n# How to build from Source\n\n1. **Clone the Verba repos**\n\n```\ngit clone https://github.com/weaviate/Verba.git\n```\n\n2. **Initialize a new Python Environment**\n\n```\npython3 -m virtualenv venv\nsource venv/bin/activate\n```\n\n3. **Install Verba**\n\n```\npip install -e .\n```\n\n4. **Launch Verba**\n\n```\nverba start\n```\n\n> You can specify the --port and --host via flags\n\n5. **Access Verba**\n\n```\nVisit localhost:8000\n```\n\n6. (Optional) **Create .env file and add environment variables**\n\n# How to install Verba with Docker\n\nDocker is a set of platform-as-a-service products that use OS-level virtualization to deliver software in packages called containers. To get started with deploying Verba using Docker, follow the steps below. If you need more detailed instructions on Docker usage, check out the [Docker Curriculum](https://docker-curriculum.com/).\n\nYou can use `docker pull semitechnologies/verba` to pull the latest Verba Docker Image. Please note, that by pulling directly from Docker Hub you're only able to install the vanilla Verba version that does not include packages e.g `HuggingFace`. If you want to use Docker and `HuggingFace` please follow the steps below.\n\nTo build the image yourself, you can clone the Verba repository and run `docker build -t verba .` inside the Verba directory.\n\n0. **Clone the Verba repos**\n   Ensure you have Git installed on your system. Then, open a terminal or command prompt and run the following command to clone the Verba repository:\n\n```\ngit clone https://github.com/weaviate/Verba.git\n```\n\n1. **Set necessary environment variables**\n   Make sure to set your required environment variables in the `.env` file. You can read more about how to set them up in the [API Keys Section](#api-keys)\n\n2. **Adjust the docker-compose file**\n   You can use the `docker-compose.yml` to add required environment variables under the `verba` service and can also adjust the Weaviate Docker settings to enable Authentification or change other settings of your database instance. You can read more about the Weaviate configuration in our [docker-compose documentation](https://weaviate.io/developers/weaviate/installation/docker-compose). You can also uncomment the `ollama` service to use Ollama within the same docker compose.\n\n> Please make sure to only add environment variables that you really need.\n\n2. **Deploy using Docker**\n   With Docker installed and the Verba repository cloned, navigate to the directory containing the Docker Compose file in your terminal or command prompt. Run the following command to start the Verba application in detached mode, which allows it to run in the background:\n\n```bash\n\ndocker compose up -d\n\n```\n\n```bash\n\ndocker compose --env-file goldenverba/.env up -d --build\n\n```\n\nThis command will download the necessary Docker images, create containers, and start Verba.\nRemember, Docker must be installed on your system to use this method. For installation instructions and more details about Docker, visit the official Docker documentation.\n\n4. **Access Verba**\n\n- You can access your local Weaviate instance at `localhost:8080`\n\n- You can access the Verba frontend at `localhost:8000`\n\nIf you want your Docker Instance to install a specific version of Verba you can edit the `Dockerfile` and change the installation line.\n\n```\nRUN pip install -e '.'\n```\n\n## Verba Walkthrough\n\n### Select your Deployment\n\nThe first screen you'll see is the deployment screen. Here you can select between `Local`, `Docker`, `Weaviate Cloud`, or `Custom` deployment. The `Local` deployment is using Weaviate Embedded under the hood, which initializes a Weaviate instance behind the scenes. The `Docker` deployment is using a separate Weaviate instance that is running inside the same Docker network. The `Weaviate Cloud` deployment is using a Weaviate instance that is hosted on Weaviate Cloud Services (WCS). The `Custom` deployment allows you to specify your own Weaviate instance URL, PORT, and API key.\n\nYou can skip this part by setting the `DEFAULT_DEPLOYMENT` environment variable to `Local`, `Docker`, `Weaviate`, or `Custom`.\n\n### Import Your Data\n\nFirst thing you need to do is to add your data. You can do this by clicking on `Import Data` and selecting either `Add Files`, `Add Directory`, or `Add URL` tab. Here you can add all your files that you want to ingest.\nYou can then configure every file individually by selecting the file and clicking on `Overview` or `Configure` tab.\n![Demo of Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/verba_data.png)\n\n### Query Your Data\n\nWith Data imported, you can use the `Chat` page to ask any related questions. You will receive relevant chunks that are semantically relevant to your question and an answer generated by your choosen model. You can configure the RAG pipeline under the `Config` tab.\n\n![Demo of Verba](https://github.com/weaviate/Verba/blob/2.0.0/img/verba_rag.png)\n\n## Open Source Contribution\n\nYour contributions are always welcome! Feel free to contribute ideas, feedback, or create issues and bug reports if you find any! Before contributing, please read the [Contribution Guide](./CONTRIBUTING.md). Visit our [Weaviate Community Forum](https://forum.weaviate.io/) if you need any help!\n\n### Project Architecture\n\nYou can learn more about Verba's architecture and implementation in its [technical documentation](./TECHNICAL.md) and [frontend documentation](./FRONTEND.md). It's recommended to have a look at them before making any contributions.\n\n## Known Issues\n\n- **Weaviate Embeeded** currently not working on Windows yet\n  - Will be fixed in future versions, until then please use the Docker or WCS Deployment\n\n## FAQ\n\n- **Can I use pre-existing data from my Weaviate instance?**\n\n  - No, unfortunatley not. Verba requires the data to be in a specific format to work. And as of now, this is only possible by importing data through the Verba UI.\n\n- **Is Verba Multi-Lingual?**\n\n  - This depends on your choosen Embedding and Generation Model whether they support multi-lingual data.\n\n- **Can I use my Ollama Server with the Verba Docker?**\n\n  - Yes, you can! Make sure the URL is set to: `OLLAMA_URL=http://host.docker.internal:11434`\n  - If you're running on Linux, you might need to get the IP Gateway of the Ollama server: `OLLAMA_URL=\"http://YOUR-IP-OF-OLLAMA:11434\"`\n\n- **How to clear Weaviate Embedded Storage?**\n\n  - You'll find the stored data here: `~/.local/share/weaviate`\n\n- **How can I specify the port?**\n\n  - You can use the port and host flag `verba start --port 9000 --host 0.0.0.0`\n\n- **Can multiple users use Verba at the same time? How about role based access?**\n\n  - Verba is designed and optimized for single user usage only. There are no plans on supporting multiple users or role based access in the near future.\n\n- **Does Verba offer a API endpoint to use externally?**\n  - No, right now Verba does not offer any useful API endpoints to interact with the application. The current FastAPI setup is optimized for the internal communication between the frontend and backend. It is not recommended to use it as a API endpoint. There are plans to add user-friendly\n"
        },
        {
          "name": "TECHNICAL.md",
          "type": "blob",
          "size": 1.2958984375,
          "content": "# Verba - Technical Documentation\n\nThis technical documentation is intended for developers who want to understand the inner workings of Verba. Please note that this document might be uncomplete and missing some parts. If you encounter any issues or have questions, please feel free to open an issue.\n\n## FastAPI Server\n\nVerba is served through a FastAPI server. The server is serving the static frontend files through the specified port. If you're modifying the frontend, you will need to rebuild the static files again. The frontend is sending API calls to itself which the FastAPI server handles. The server can handle multiple client connections which are handled by the `ClientManager` class.\n\n### ClientManager\n\n`TODO`\n\nFor handling large upload of files, the `BatchManager` class handles batches of data of a single file to merge it into a single file once all batches have been received.\n\n### BatchManager\n\n`TODO`\n\n### Websocket\n\n`TODO`\n\n## Automated Testing\n\n`TODO`\n\n## FAQ\n\n### How to control the position of context sent to the Generator to generate a response?\n\nEvery `generator` class has a `prepare_messages` method. This method is used to format the messages that are sent to the LLM. The position of the context in the messages is important because it determines where the context is placed in the conversation.\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 2.138671875,
          "content": "---\n\nservices:\n  verba:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    ports:\n      - 8000:8000\n    environment:\n      - WEAVIATE_URL_VERBA=http://weaviate:8080\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - COHERE_API_KEY=$COHERE_API_KEY\n      - OLLAMA_URL=http://host.docker.internal:11434\n      - OLLAMA_MODEL=$OLLAMA_MODEL\n      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL\n      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY\n      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL\n      - GITHUB_TOKEN=$GITHUB_TOKEN\n\n    volumes:\n      - ./data:/data/\n    depends_on:\n      weaviate:\n        condition: service_healthy\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    networks:\n      - ollama-docker\n\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image: semitechnologies/weaviate:1.25.10\n    ports:\n      - 8080:8080\n      - 3000:8080\n    volumes:\n      - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    healthcheck:\n      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1\n      interval: 5s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n    environment:\n      OPENAI_APIKEY: $OPENAI_API_KEY\n      COHERE_APIKEY: $COHERE_API_KEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'e'\n      CLUSTER_HOSTNAME: 'node1'\n    networks:\n      - ollama-docker\n\n  # Uncomment to use Ollama within the same docker compose\n\n  # ollama:\n  #     image: ollama/ollama:latest\n  #     ports:\n  #       - 7869:11434\n  #     volumes:\n  #       - .:/code\n  #       - ./ollama/ollama:/root/.ollama\n  #     container_name: ollama\n  #     pull_policy: always\n  #     tty: true\n  #     restart: always\n  #     environment:\n  #       - OLLAMA_KEEP_ALIVE=24h\n  #       - OLLAMA_HOST=0.0.0.0\n  #     networks:\n  #       - ollama-docker\n\nvolumes:\n  weaviate_data: {}\n\n\nnetworks:\n  ollama-docker:\n    external: false\n  \n..."
        },
        {
          "name": "frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "goldenverba",
          "type": "tree",
          "content": null
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "pypi_commands.sh",
          "type": "blob",
          "size": 0.052734375,
          "content": "python setup.py sdist bdist_wheel\n\ntwine upload dist/*"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.890625,
          "content": "from setuptools import find_packages, setup\n\nsetup(\n    name=\"goldenverba\",\n    version=\"2.1.0\",\n    packages=find_packages(),\n    python_requires=\">=3.10.0,<3.13.0\",\n    entry_points={\n        \"console_scripts\": [\n            \"verba=goldenverba.server.cli:cli\",\n        ],\n    },\n    author=\"Weaviate\",\n    author_email=\"edward@weaviate.io\",\n    description=\"Welcome to Verba: The Golden RAGtriever, an open-source initiative designed to offer a streamlined, user-friendly interface for Retrieval-Augmented Generation (RAG) applications. In just a few easy steps, dive into your data and make meaningful interactions!\",\n    long_description=open(\"README.md\", encoding=\"utf-8\").read(),\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/weaviate/Verba\",\n    classifiers=[\n        \"License :: OSI Approved :: BSD License\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n    ],\n    include_package_data=True,\n    install_requires=[\n        \"weaviate-client==4.9.6\",\n        \"python-dotenv==1.0.0\",\n        \"wasabi==1.1.2\",\n        \"fastapi==0.111.1\",\n        \"uvicorn[standard]==0.29.0\",\n        \"gunicorn==22.0.0\",\n        \"click==8.1.7\",\n        \"asyncio==3.4.3\",\n        \"tiktoken==0.6.0\",\n        \"requests==2.31.0\",\n        \"pypdf==4.3.1\",\n        \"python-docx==1.1.2\",\n        \"scikit-learn==1.5.1\",\n        \"langchain-text-splitters==0.2.2\",\n        \"spacy==3.7.5\",\n        \"aiohttp==3.9.5\",\n        \"markdownify==0.13.1\",\n        \"aiofiles==24.1.0\",\n        \"assemblyai==0.33.0\",\n        \"beautifulsoup4==4.12.3\",\n        \"langdetect==1.0.9\",\n    ],\n    extras_require={\n        \"dev\": [\"pytest\", \"wheel\", \"twine\", \"black>=23.7.0\", \"setuptools\"],\n        \"google\": [\n            \"vertexai==1.46.0\",\n        ],\n        \"huggingface\": [\n            \"sentence-transformers==3.0.1\",\n        ],\n    },\n)\n"
        }
      ]
    }
  ]
}