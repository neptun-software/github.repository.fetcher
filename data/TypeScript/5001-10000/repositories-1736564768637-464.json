{
  "metadata": {
    "timestamp": 1736564768637,
    "page": 464,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openchatai/copilot",
      "stars": 5109,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".all-contributorsrc",
          "type": "blob",
          "size": 0.5673828125,
          "content": "{\n  \"files\": [\n    \"README.md\"\n  ],\n  \"imageSize\": 100,\n  \"commit\": false,\n  \"commitType\": \"docs\",\n  \"commitConvention\": \"angular\",\n  \"contributors\": [\n    {\n      \"login\": \"yagarwal-allo\",\n      \"name\": \"yagarwal-allo\",\n      \"avatar_url\": \"https://avatars.githubusercontent.com/u/106862559?v=4\",\n      \"profile\": \"https://github.com/yagarwal-allo\",\n      \"contributions\": [\n        \"code\"\n      ]\n    }\n  ],\n  \"contributorsPerLine\": 7,\n  \"skipCi\": true,\n  \"repoType\": \"github\",\n  \"repoHost\": \"https://github.com\",\n  \"projectName\": \"OpenCopilot\",\n  \"projectOwner\": \"openchatai\"\n}\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2861328125,
          "content": "/.phpunit.cache\n/node_modules\n/public/build\n/public/hot\n/public/storage\n/storage/*.key\n/vendor\n.env\n.env.docker\n.env.backup\n.env.production\n.phpunit.result.cache\nHomestead.json\nHomestead.yaml\nauth.json\nnpm-debug.log\nyarn-error.log\n/.fleet\n/.idea\n/.vscode\n*.pyc\n.dmypy.*\n\ntest.html\n.aider*\nlogs"
        },
        {
          "name": ".gitpod.Dockerfile",
          "type": "blob",
          "size": 0.6357421875,
          "content": "# .gitpod.Dockerfile\n\nFROM gitpod/workspace-full\n\n# Install Miniconda\nRUN curl -o Miniconda.sh -LO https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \\\n    bash Miniconda.sh -b -p $HOME/miniconda && \\\n    rm Miniconda.sh\n\n# Install Fish shell\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\n# Add Miniconda to PATH\nENV PATH=$HOME/miniconda/bin:$PATH\n\n# Initialize Conda\nRUN conda init bash\n\n# Automatically activate the Conda environment on Gitpod workspace start\nENV CONDA_AUTO_ACTIVATE=true\nENV CONDA_DEFAULT_ENV=base\n\n# Set Fish as the default shell\nENV SHELL=/usr/bin/fish"
        },
        {
          "name": ".gitpod.yml",
          "type": "blob",
          "size": 0.4033203125,
          "content": "image:\n  file: .gitpod.Dockerfile\n  context: .\n\ntasks:\n  - init: |\n      mkdir -p ~/.ssh\n      echo \"Host github.com\" > ~/.ssh/config\n      echo \"  IdentityFile ~/.ssh/id_rsa\" >> ~/.ssh/config\n      chmod 600 ~/.ssh/config\n      echo \"$SSH_PRIVATE_KEY\" | base64 -d > ~/.ssh/id_rsa\n      chmod 600 ~/.ssh/id_rsa\n      \n      # Add the SSH key to the SSH agent\n      eval $(ssh-agent -s)\n      ssh-add ~/.ssh/id_rsa"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 1.0361328125,
          "content": "# Code of Conduct\n\n## Introduction\n\nWe are committed to providing a welcoming and inclusive environment for all participants, regardless of gender, sexual orientation, disability, ethnicity, religion, or any other personal characteristic. We value open and respectful communication and expect all contributors, maintainers, and users of this repository to abide by this Code of Conduct.\n\n## Expected Behavior\n\nWhen participating in this repository, we expect everyone to:\n\n- Be respectful and considerate of others' perspectives and experiences.\n- Use inclusive language and avoid derogatory or discriminatory comments or behavior.\n- Be open to constructive feedback and engage in healthy discussions.\n- Exercise empathy and understanding towards fellow contributors.\n- Be mindful of the impact of your words and actions on others.\n\n## Unacceptable Behavior\n\nThe following behaviors are considered unacceptable and will not be tolerated:\n\n- Harassment, discrimination, or intimidation in any form.\n- Offensive, derogatory, or inappropriate comments or content.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04296875,
          "content": "MIT License\n\nCopyright (c) 2023 OpenCopilot\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 4.2412109375,
          "content": "# Variables\nexport TARGET=production\nDOCKER_COMPOSE=docker-compose\n\n# Colors\nCOLOR_RESET=\\033[0m\nCOLOR_BOLD=\\033[1m\nCOLOR_GREEN=\\033[32m\nCOLOR_YELLOW=\\033[33m\n\n# Check if Docker is installed\nDOCKER_INSTALLED := $(shell command -v docker-compose 2> /dev/null)\nLLM_SERVER_ENV_EXISTS := $(shell [ -f llm-server/.env ] && echo \"true\" || echo \"false\")\n\nCOMMON_SETUP = \\\n\t@echo \"$(COLOR_BOLD)=== 🟢 Putting the services down (if already running) ===$(COLOR_RESET)\"; \\\n\t$(DOCKER_COMPOSE) down; \\\n\t@echo \"$(COLOR_BOLD)=== 🟢 Setting up Docker environment ===$(COLOR_RESET)\"; \\\n\tif [ \"$(LLM_SERVER_ENV_EXISTS)\" = \"false\" ]; then \\\n\t\techo \"Copying llm-server/.env.example to llm-server/.env\"; \\\n\t\tcp llm-server/.env.example llm-server/.env; \\\n\tfi; \\\n\t@echo \"$(COLOR_BOLD)=== 🟢 Copying .env files ===$(COLOR_RESET)\"; \\\n\tcp -n dashboard/.env.example dashboard/.env 2>/dev/null || true;\n\n# Targets\ninstall: \nifndef DOCKER_INSTALLED\n\t$(error Docker is not installed. Please visit https://www.docker.com/get-started to download and install Docker.)\nendif\n\t$(COMMON_SETUP)\n\t$(DOCKER_COMPOSE) build\n\t$(DOCKER_COMPOSE) up -d #--force-recreate\n\t@echo \"$(COLOR_BOLD)=== 🟢 Waiting for services to start (~30 seconds) ===$(COLOR_RESET)\"\n\t@sleep 30\n\t@echo \"$(COLOR_BOLD)=== 🟢 Running Alembic migrations ===$(COLOR_RESET)\"\n\t$(DOCKER_COMPOSE) exec -T llm-server sh -c \"cd models && python setup_alembic.py && alembic upgrade head\"\n\t@echo \"$(COLOR_BOLD)=== Installation completed ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== 🔥🔥 You can now access the dashboard at -> http://localhost:8888 ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== Enjoy! ===$(COLOR_RESET)\"\n\ninstall-arm: \nifndef DOCKER_INSTALLED\n\t$(error Docker is not installed. Please visit https://www.docker.com/get-started to download and install Docker.)\nendif\n\t$(COMMON_SETUP)\n\t$(DOCKER_COMPOSE) -f docker-compose.arm.yml up -d --build\n\t@echo \"$(COLOR_BOLD)=== 🟢 Waiting for services to start (~30 seconds) ===$(COLOR_RESET)\"\n\t@sleep 30\n\t@echo \"$(COLOR_BOLD)=== 🟢 Running Alembic migrations ===$(COLOR_RESET)\"\n\t$(DOCKER_COMPOSE) exec -T llm-server sh -c \"cd models && python setup_alembic.py && alembic upgrade head\"\n\t@echo \"$(COLOR_BOLD)=== Installation completed ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== 🔥🔥 You can now access the dashboard at -> http://localhost:8888 ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== Enjoy! ===$(COLOR_RESET)\"\n\nmigrate:\n\t@echo \"$(COLOR_BOLD)=== 🟢 Running Alembic migrations ===$(COLOR_RESET)\"\n\t$(DOCKER_COMPOSE) exec llm-server sh -c \"cd models && python setup_alembic.py && alembic upgrade head\"\n\ndown:\n\t$(DOCKER_COMPOSE) down --remove-orphans\n\nexec-dashboard:\n\t$(DOCKER_COMPOSE) exec dashboard /bin/sh\n\nexec-llm-server:\n\t$(DOCKER_COMPOSE) exec llm-server bash\n\nrestart:\n\t$(DOCKER_COMPOSE) restart\n\t@echo \"$(COLOR_BOLD)=== Restart completed ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== 🔥🔥 You can now access the dashboard at -> http://localhost:8888 ===$(COLOR_RESET)\"\n\t@echo \"$(COLOR_BOLD)=== Enjoy! ===$(COLOR_RESET)\"\n\nlogs:\n\t$(DOCKER_COMPOSE) logs -f\n\n# Define the help target\nhelp:\n\t@echo \"$(COLOR_BOLD)Usage: make [target]$(COLOR_RESET)\"\n\t@echo \"\"\n\t@echo \"$(COLOR_BOLD)Available Targets:$(COLOR_RESET)\"\n\t@echo \"\"\n\t@echo \"  $(COLOR_GREEN)install$(COLOR_RESET)            - Install and set up the Docker environment\"\n\t@echo \"  $(COLOR_GREEN)db-setup$(COLOR_RESET)           - Set up the database (fresh migration with seeding)\"\n\t@echo \"  $(COLOR_GREEN)down$(COLOR_RESET)               - Stop and remove all containers\"\n\t@echo \"  $(COLOR_GREEN)exec-dashboard$(COLOR_RESET)     - Access the dashboard container's shell\"\n\t@echo \"  $(COLOR_GREEN)exec-llm-server$(COLOR_RESET)    - Access the llm-server container's shell\"\n\t@echo \"  $(COLOR_GREEN)restart$(COLOR_RESET)            - Restart all containers\"\n\t@echo \"  $(COLOR_GREEN)logs$(COLOR_RESET)               - Show container logs\"\n\t@echo \"  $(COLOR_GREEN)purge$(COLOR_RESET)              - Full clean un-install (will remove containers, networks, volumes, .env) \"\n\t@echo \"\"\n\t@echo \"  $(COLOR_YELLOW)help$(COLOR_RESET)              - Display this help message\"\n\t@echo \"\"\n\n# Add the 'purge' target\npurge:\n\t@echo \"$(COLOR_BOLD)=== 🟥 Purging all containers, volumes, and network ===$(COLOR_RESET)\"\n\t$(DOCKER_COMPOSE) down -v --remove-orphans\n\trm -f llm-server/.env\n\n.PHONY: install down"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.7587890625,
          "content": "\nGet 1:1 support, Join the community (NEW!!)\n\n [![](https://dcbadge.vercel.app/api/server/yjEgCgvefr)](https://discord.gg/yjEgCgvefr)\n \n\n> [!TIP]\n> If you are looking for a managed version of OpenCopilot, [check out the cloud version ](https://cloud.opencopilot.so/) - it's production-ready with our latest planning engine that can handle and understand complex user requests. \n\n\n\n<img width=\"1445\" alt=\"image\" style=\"border-radius:20px\" src=\"https://github.com/openchatai/OpenCopilot/assets/32633162/340d174b-6ddd-452f-a66d-6c5567cc4583\">\n\n\n**Documentation [available here](https://docs.opencopilot.so)**\n\n------\n# 🔥 OpenCopilot\n\n---- \nOpenCopilot allows you to have your own product's AI copilot. It integrates with your underlying APIs and can execute API calls whenever needed. It uses LLMs to determine if the user's request requires calling an API endpoint. Then, it decides which endpoint to call and passes the appropriate payload based on the given API definition.\n\n## How does it work?\n- Provide your APIs/actions definition, including your public endpoints and how to call them. Currently, OpenCopilot supports Swagger OpenAPI 3.0 for bulk import.\n- OpenCopilot validates your schema to achieve the best results.\n- Finally, you can integrate our user-friendly chat bubble into your SaaS app.\n\n\n\n## 🚀 Getting Started\n\n- Make sure you have docker installed. \n\n- To begin, clone this Git repository:\n\n```\ngit clone git@github.com:openchatai/OpenCopilot.git\n```\n\nIn the `.env` file located in the `llm-server` directory, make sure to replace the placeholder value for the `OPENAI_API_KEY` variable with your actual token:\n\n```\nOPENAI_API_KEY=YOUR_TOKEN_HERE\n```\n\n### For Linux Machines\n\nTo install the necessary dependencies and set up the environment for OpenCopilot, use the following command:\n\n```bash\nmake install\n```\n\n### For ARM Machines (Mac Silicon)\n\nIf you are using an ARM machine, specifically Mac Silicon, use the following command to install dependencies and set up the environment:\n\n```bash\nmake install-arm\n```\n\nOnce the installation is complete, you can access the OpenCopilot console at [http://localhost:8888](http://localhost:8888).\n\n## Additional Commands\n\n- **make migrate**: Run Alembic migrations.\n- **make down**: Stop and remove all containers.\n- **make exec-dashboard**: Access the dashboard container's shell.\n- **make exec-llm-server**: Access the llm-server container's shell.\n- **make restart**: Restart all containers.\n- **make logs**: Show container logs.\n- **make purge**: Fully clean uninstall (remove containers, networks, volumes, .env).\n- **make help**: Display help message with available targets.\n\n\nThis will install the necessary dependencies and set up the environment for the OpenCopilot project.\n\nOnce the installation is complete, you can access the OpenCopilot console at http://localhost:8888\n\n\n\n## Try it out:\n**You can try it out on [opencopilot.so](http://opencopilot.so/)**\n\n\n\n[![IMAGE ALT TEXT](https://github.com/openchatai/OpenCopilot/assets/32633162/edebbaa6-eba5-4f72-b88d-cf0d690fffa8)](http://www.youtube.com/watch?v=HVvbY7A7lIQ \"Video Title\")\n\n\n(OpenCopilot is not affiliated with Shopify, and they do not use OpenCopilot, it's just a demo of what copilots are capable of)\n\n\n## AI Copilot: a growing trend\n\n- [Shopify is developing \"Shopify Sidekick.\"](https://www.youtube.com/watch?v=HVvbY7A7lIQ&ab_channel=Shopify)\n- [Microsoft is working on \"Windows Copilot.\"](https://www.youtube.com/watch?v=FCfwc-NNo30&ab_channel=MicrosoftDeveloper)\n- [GitHub is in the process of creating \"GitHub Copilot.\"](https://github.com/features/copilot)\n- [Microsoft is also developing \"Bing Copilot.\"](https://www.microsoft.com/en-us/bing?form=MA13FV)\n\n\nOur goal is to empower every SaaS product with the ability to have their own AI copilots tailored for their unique products.\n\n## 🏁 What OpenCopilot can and can't do now?\n\n- It is capable of calling your underlying APIs.\n- It can transform the response into meaningful text.\n- It can automatically populate certain request payload fields based on the context.\n  - For instance, you can request actions like: \"Initiate a new case about X problem,\" and the title field will be automatically filled with the appropriate name.\n- It is not suitable for handling large APIs (you will need to write JSON transformers to make it work, refer to the docs for more)\n\n\n\n## 🛣️ Teach the copilot via flows:\nMost of the time, the copilot can figure out what actions to execute when the user requests something, but in case there is a complex flow, you can define it to help the copilot:\n\n<img width=\"1453\" alt=\"image 2\" src=\"https://github.com/openchatai/OpenCopilot/assets/32633162/81cb899c-0200-40c6-bc2f-4fe49e112085\">\n\n\n\n## 🛣️ Embed on your app in a few lines of code\nLess than <10 lines of codes to implement on your web app or desktop app\n\n<img width=\"1445\" alt=\"image\" src=\"https://github.com/openchatai/OpenCopilot/assets/32633162/d2ad2597-9de2-4177-b894-7ce92dfd1fcd\">\n\n\n\n### Important links\n- The backend server (API) is reachable via http://localhost:8888/backend\n- The dashboard server is reachable via http://localhost:8888/ \n- You can also [use our SDK](https://github.com/openchatai/typescript-sdk)\n \n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind are welcome!\n\n\n\n## Contributors ✨\n\n- Learn how OpenCopilot codebase works and how you can contribute using Onbaord AI's tool: [learnthisrepo.com/opencopilot](https://learnthisrepo.com/opencopilot)\n- This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind are welcome!\n\n## Analytics\n\nThis product collects anonymous usage data to help improve your experience. You can opt out by setting `ENABLE_EXTERNAL_API_LOGGING=no` in your environment variables.\n\n\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 4.296875,
          "content": "# Security Policy\n\nThis document outlines the security policy for the OpenCopilot GitHub repository. It aims to establish guidelines and best practices to ensure the security and integrity of the project.\n\n## Reporting Security Issues\n\nIf you discover any security vulnerabilities or issues within the repository, we appreciate your cooperation in responsibly disclosing them. Please follow these steps:\n\n1. Submit a detailed report of the vulnerability or issue through our issue tracker or email [hey@openchat.so](mailto:hey@openchat.so).\n2. Include a description of the vulnerability or issue, along with any relevant details or steps to reproduce it.\n3. We will acknowledge receipt of your report and provide an estimated timeline for a response.\n4. We will investigate and validate the issue promptly, and if necessary, we will work towards resolving it.\n5. Once the vulnerability or issue is resolved, we will credit you for your contribution, unless you prefer to remain anonymous.\n\nPlease note that we appreciate your efforts to maintain responsible disclosure. We kindly request that you do not publicly disclose any vulnerabilities or issues until we have addressed them.\n\n## Supported Versions\n\nThe security policy applies to the latest stable version of the project. It is your responsibility to ensure that you are using an up-to-date version to benefit from security enhancements and bug fixes. Older versions might not receive immediate attention or support for reported vulnerabilities.\n\n## Vulnerability Response\n\nWe are committed to addressing security vulnerabilities promptly and efficiently. Once we receive a security report, we will follow these steps:\n\n1. Acknowledge receipt of the report within 1 business days.\n2. Investigate and validate the reported vulnerability or issue.\n3. Develop a plan to resolve the vulnerability or issue.\n4. Implement the necessary fixes and improvements.\n5. Release a patch or update that addresses the vulnerability or issue.\n6. Provide the reporter with feedback and credit (if requested) after the vulnerability is resolved.\n\nThe timeframe for the above steps may vary depending on the complexity of the issue and other factors. We will strive to keep you informed about the progress and any necessary actions.\n\n## Code of Conduct\n\nWe expect all contributors, maintainers, and users of this repository to adhere to our Code of Conduct. This ensures a respectful and inclusive environment for everyone involved. The Code of Conduct can be found in the [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md) file.\n\n## Dependencies\n\nThis repository may utilize third-party libraries and dependencies. While we strive to keep them updated, it is essential to be aware of potential vulnerabilities in these dependencies. We encourage contributors and users to regularly review and update dependencies to incorporate security patches and improvements.\n\n## Security Best Practices\n\nTo ensure the security and integrity of the repository, we recommend following these best practices:\n\n1. **Strong Authentication**: Enable two-factor authentication (2FA) for your GitHub account to add an extra layer of security.\n2. **Secure Credentials**: Avoid committing sensitive information, such as passwords, access tokens, or API keys, to the repository. Utilize environment variables or secure storage solutions for handling sensitive data.\n3. **Secure Coding**: Follow secure coding practices to prevent common vulnerabilities like SQL injection, cross-site scripting (XSS), and cross-site request forgery (CSRF).\n4. **Regular Updates**: Keep your local repository up to date by pulling the latest changes frequently.\n5. **Code Review**: Encourage peer code reviews to identify security vulnerabilities, logic flaws, or potential issues.\n6. **Secure Communications**: Use encrypted connections (HTTPS) when communicating with the repository and avoid using insecure or public networks.\n7. **Access Control**: Ensure appropriate access controls and permissions are set for collaborators or contributors.\n8. **Testing**: Implement a robust testing strategy to identify and fix security issues in the early stages of development.\n9. **Security Monitoring**: Continuously monitor the repository for any suspicious activity or unauthorized access attempts.\n\nThese practices aim to mitigate common security risks and maintain the overall security posture of the repository.\n"
        },
        {
          "name": "_swaggers",
          "type": "tree",
          "content": null
        },
        {
          "name": "container_config",
          "type": "tree",
          "content": null
        },
        {
          "name": "copilot-widget",
          "type": "tree",
          "content": null
        },
        {
          "name": "dashboard",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.arm.yml",
          "type": "blob",
          "size": 2.7421875,
          "content": "version: \"3.9\"\nservices:\n  llm-server:\n    restart: unless-stopped\n    build:\n      context: ./llm-server\n      dockerfile: Dockerfile\n      target: ${TARGET}\n    image: codebanesr/llm-server:latest\n    volumes:\n      - ./llm-server:/app\n      - shared_data:/app/shared_data\n    networks:\n      - opencopilot-net\n    env_file:\n      - llm-server/.env\n    ports:\n      - 8002:8002\n      - 5678:5678\n    depends_on:\n      mysql:\n        condition: service_healthy\n      qdrant:\n        condition: service_started\n\n  redis:\n    image: redis:latest\n    container_name: redis_cache\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - opencopilot-net\n\n  workers:\n    restart: unless-stopped\n    build:\n      context: ./llm-server\n      dockerfile: worker.Dockerfile\n    image: codebanesr/workers:latest  # Add this line\n    deploy:\n      replicas: 1\n    networks:\n      - opencopilot-net\n    volumes:\n      - shared_data:/app/shared_data\n    env_file:\n      - llm-server/.env\n    # worker will also check for some database tables, this is a hacky solution\n    command: sh -c \"celery -A celery_app worker --loglevel=info\"\n    depends_on:\n      mysql:\n        condition: service_healthy\n      qdrant:\n        condition: service_started\n\n  dashboard:\n    restart: unless-stopped\n    build:\n      context: ./dashboard\n      dockerfile: Dockerfile\n    image: codebanesr/dashboard:latest  # Add this line\n    ports:\n      - 8000:8000\n    volumes:\n      - shared_data:/app/shared_data\n    networks:\n      - opencopilot-net\n    depends_on:\n      - llm-server\n\n  mysql:\n    restart: unless-stopped\n    platform: linux/arm64\n    image: \"mysql:oraclelinux8\"\n    ports:\n      - \"3307:3306\"\n    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: opencopilot\n      MYSQL_USER: dbuser\n      MYSQL_PASSWORD: dbpass\n    volumes:\n      - database:/var/lib/mysql\n    networks:\n      - opencopilot-net\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  qdrant:\n    image: qdrant/qdrant\n    ports:\n      - 6333:6333\n      - 6334:6334\n    volumes:\n      - qdrant_storage:/qdrant/storage\n    networks:\n      - opencopilot-net\n\n\n  nginx:\n    image: nginx\n    restart: unless-stopped\n    ports:\n      - \"8888:80\"\n    volumes:\n      - ./container_config/nginx.conf:/etc/nginx/nginx.conf\n    networks:\n      - opencopilot-net\n    depends_on:\n      mysql:\n        condition: service_healthy\n      dashboard:\n        condition: service_started\n      llm-server:\n        condition: service_started\n\nnetworks:\n  opencopilot-net:\n    name: opencopilot-net\n\nvolumes:\n  shared_data:\n  database:\n  qdrant_storage:\n  redis_data:"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 2.6669921875,
          "content": "version: \"3.9\"\nservices:\n  llm-server:\n    restart: unless-stopped\n    build:\n      context: ./llm-server\n      dockerfile: Dockerfile\n      target: ${TARGET}\n    image: codebanesr/llm-server:latest\n\n    volumes:\n      - ./llm-server:/app\n      - shared_data:/app/shared_data\n    networks:\n      - opencopilot-net\n    env_file:\n      - llm-server/.env\n    ports:\n      - 8002:8002\n      - 5678:5678\n    depends_on:\n      mysql:\n        condition: service_healthy\n      qdrant:\n        condition: service_started\n\n  redis:\n    image: redis:latest\n    container_name: redis_cache\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - opencopilot-net\n\n  workers:\n    restart: unless-stopped\n    build:\n      context: ./llm-server\n      dockerfile: worker.Dockerfile\n    image: codebanesr/workers:latest  # Add this line\n    deploy:\n      replicas: 1\n      \n    networks:\n      - opencopilot-net\n    volumes:\n      - shared_data:/app/shared_data\n    env_file:\n      - llm-server/.env\n    \n    command: sh -c \"celery -A celery_app worker --loglevel=info\"\n    depends_on:\n      mysql:\n        condition: service_healthy\n      qdrant:\n        condition: service_started\n\n  dashboard:\n    restart: unless-stopped\n    build:\n      context: ./dashboard\n      dockerfile: Dockerfile\n    image: codebanesr/dashboard:latest  # Add this line\n    ports:\n      - 8000:8000\n    volumes:\n      - shared_data:/app/shared_data\n    networks:\n      - opencopilot-net\n    depends_on:\n      - llm-server\n\n  mysql:\n    restart: unless-stopped\n    platform: linux/x86_64\n    image: \"mysql:8\"\n    ports:\n      - \"3307:3306\"\n    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: opencopilot\n      MYSQL_USER: dbuser\n      MYSQL_PASSWORD: dbpass\n    volumes:\n      - database:/var/lib/mysql\n    networks:\n      - opencopilot-net\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  qdrant:\n    image: qdrant/qdrant\n    ports:\n      - 6333:6333\n      - 6334:6334\n    volumes:\n      - qdrant_storage:/qdrant/storage\n    networks:\n      - opencopilot-net\n\n  nginx:\n    image: nginx\n    restart: unless-stopped\n    ports:\n      - \"8888:80\"\n    volumes:\n      - ./container_config/nginx.conf:/etc/nginx/nginx.conf\n    networks:\n      - opencopilot-net\n    depends_on:\n      mysql:\n        condition: service_healthy\n      dashboard:\n        condition: service_started\n      llm-server:\n        condition: service_started\n\nnetworks:\n  opencopilot-net:\n    name: opencopilot-net\n\nvolumes:\n  shared_data:\n  database:\n  qdrant_storage:\n  redis_data:\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "llm-server",
          "type": "tree",
          "content": null
        },
        {
          "name": "session_summary",
          "type": "blob",
          "size": 0,
          "content": ""
        }
      ]
    }
  ]
}