{
  "metadata": {
    "timestamp": 1736564921089,
    "page": 148,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "arc53/DocsGPT",
      "stars": 15226,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".env-template",
          "type": "blob",
          "size": 0.232421875,
          "content": "API_KEY=<LLM api key (for example, open ai key)>\nLLM_NAME=docsgpt\nVITE_API_STREAMING=true\n\n#For Azure (you can delete it if you don't use Azure)\nOPENAI_API_BASE=\nOPENAI_API_VERSION=\nAZURE_DEPLOYMENT_NAME=\nAZURE_EMBEDDINGS_DEPLOYMENT_NAME="
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.36328125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n*.next\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n**/*.ipynb\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n.flaskenv\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n#pycharm\n.idea/\n\n# macOS\n.DS_Store\n\n#frontend\n# Logs\nfrontend/logs\nfrontend/*.log\nfrontend/npm-debug.log*\nfrontend/yarn-debug.log*\nfrontend/yarn-error.log*\nfrontend/pnpm-debug.log*\nfrontend/lerna-debug.log*\n\nfrontend/node_modules\nfrontend/dist\nfrontend/dist-ssr\nfrontend/*.local\n\n# Editor directories and files\nfrontend/.vscode/*\nfrontend/!.vscode/extensions.json\nfrontend/.idea\nfrontend/.DS_Store\nfrontend/*.suo\nfrontend/*.ntvs*\nfrontend/*.njsproj\nfrontend/*.sln\nfrontend/*.sw?\n\napplication/vectors/\n\n**/inputs\n\n**/indexes\n\n**/temp\n\n**/yarn.lock\n\nnode_modules/\n.vscode/settings.json\n/models/\nmodel/\n"
        },
        {
          "name": ".ruff.toml",
          "type": "blob",
          "size": 0.0625,
          "content": "# Allow lines to be as long as 120 characters.\nline-length = 120"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.1767578125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors and leaders pledge to make participation in our\ncommunity, a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive and a healthy community.\n\n## Our Standards\n\nExamples of behavior that contribute to a positive environment for our\ncommunity include:\n\n## Demonstrating empathy and kindness towards other people\n1. Being respectful and open to differing opinions, viewpoints, and experiences\n2. Giving and gracefully accepting constructive feedback\n3. Taking accountability and offering apologies to those who have been impacted by our errors,\n  while also gaining insights from the situation\n4. Focusing on what is best not just for us as individuals but for the\n  community as a whole\n\nExamples of unacceptable behavior include:\n\n1. The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n2. Trolling, insulting or derogatory comments, and personal or political attacks\n3. Public or private harassment\n4. Publishing other's private information, such as a physical or email\n  address, without their explicit permission\n5. Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\ncontact@arc53.com.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to be respectful towards the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action that they deem in violation of this Code of Conduct:\n\n### 1. Correction\n* **Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community space.\n\n* **Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n* **Community Impact**: A violation through a single incident or series\nof actions.\n\n* **Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n* **Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n* **Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n* **Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,harassment of an\nindividual or aggression towards or disparagement of classes of individuals.\n\n* **Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.31640625,
          "content": "# Welcome to DocsGPT Contributing Guidelines\n\nThank you for choosing to contribute to DocsGPT! We are all very grateful! \n\n# We accept different types of contributions\n\nüì£ **Discussions** - Engage in conversations, start new topics, or help answer questions.\n\nüêû **Issues** - This is where we keep track of tasks. It could be bugs, fixes or suggestions for new features.\n\nüõ†Ô∏è **Pull requests** - Suggest changes to our repository, either by working on existing issues or adding new features.\n\nüìö **Wiki** - This is where our documentation resides.\n\n\n## üêû Issues and Pull requests\n\n- We value contributions in the form of discussions or suggestions. We recommend taking a look at existing issues and our [roadmap](https://github.com/orgs/arc53/projects/2).\n\n\n- If you're interested in contributing code, here are some important things to know:\n\n- We have a frontend built on React (Vite) and a backend in Python.\n\n  \nBefore creating issues, please check out how the latest version of our app looks and works by launching it via [Quickstart](https://github.com/arc53/DocsGPT#quickstart) the version on our live demo is slightly modified with login. Your issues should relate to the version you can launch via [Quickstart](https://github.com/arc53/DocsGPT#quickstart).\n\n### üë®‚Äçüíª If you're interested in contributing code, here are some important things to know:\n\n\nTech Stack Overview:\n\n- üåê Frontend: Built with React (Vite) ‚öõÔ∏è,\n\n- üñ• Backend: Developed in Python üêç\n\n### üåê If you are looking to contribute to frontend (‚öõÔ∏èReact, Vite):\n\n- The current frontend is being migrated from [`/application`](https://github.com/arc53/DocsGPT/tree/main/application) to [`/frontend`](https://github.com/arc53/DocsGPT/tree/main/frontend) with a new design, so please contribute to the new one.\n- Check out this [milestone](https://github.com/arc53/DocsGPT/milestone/1) and its issues.\n- The updated Figma design can be found [here](https://www.figma.com/file/OXLtrl1EAy885to6S69554/DocsGPT?node-id=0%3A1&t=hjWVuxRg9yi5YkJ9-1).\n\nPlease try to follow the guidelines.\n\n### üñ• If you are looking to contribute to Backend (üêç Python):\n\n- Review our issues and contribute to [`/application`](https://github.com/arc53/DocsGPT/tree/main/application) or [`/scripts`](https://github.com/arc53/DocsGPT/tree/main/scripts) (please disregard old [`ingest_rst.py`](https://github.com/arc53/DocsGPT/blob/main/scripts/old/ingest_rst.py) [`ingest_rst_sphinx.py`](https://github.com/arc53/DocsGPT/blob/main/scripts/old/ingest_rst_sphinx.py) files; these will be deprecated soon).\n- All new code should be covered with unit tests ([pytest](https://github.com/pytest-dev/pytest)). Please find tests under [`/tests`](https://github.com/arc53/DocsGPT/tree/main/tests) folder.\n- Before submitting your Pull Request, ensure it can be queried after ingesting some test data.\n  \n### Testing\n\nTo run unit tests from the root of the repository, execute:\n```\npython -m pytest\n```\n\n## Workflow üìà\n\nHere's a step-by-step guide on how to contribute to DocsGPT:\n\n1. **Fork the Repository:**\n   - Click the \"Fork\" button at the top-right of this repository to create your fork.\n\n2. **Clone the Forked Repository:**\n   - Clone the repository using:\n      ``` shell\n      git clone https://github.com/<your-github-username>/DocsGPT.git\n      ```\n\n3. **Keep your Fork in Sync:**\n   - Before you make any changes, make sure that your fork is in sync to avoid merge conflicts using:\n     ```shell\n     git remote add upstream https://github.com/arc53/DocsGPT.git\n     git pull upstream main\n     ```\n\n4. **Create and Switch to a New Branch:**\n   - Create a new branch for your contribution using:\n     ```shell\n     git checkout -b your-branch-name\n     ```\n\n5. **Make Changes:**\n   - Make the required changes in your branch.\n\n6. **Add Changes to the Staging Area:**\n   - Add your changes to the staging area using:\n     ```shell\n     git add .\n     ```\n\n7. **Commit Your Changes:**\n   - Commit your changes with a descriptive commit message using:\n     ```shell\n     git commit -m \"Your descriptive commit message\"\n     ```\n\n8. **Push Your Changes to the Remote Repository:**\n   - Push your branch with changes to your fork on GitHub using:\n     ```shell\n     git push origin your-branch-name\n     ```\n\n9. **Submit a Pull Request (PR):**\n   - Create a Pull Request from your branch to the main repository. Make sure to include a detailed description of your changes and reference any related issues.\n\n10. **Collaborate:**\n   - Be responsive to comments and feedback on your PR.\n   - Make necessary updates as suggested.\n   - Once your PR is approved, it will be merged into the main repository.\n\n11. **Testing:**\n   - Before submitting a Pull Request, ensure your code passes all unit tests.\n   - To run unit tests from the root of the repository, execute:\n     ```shell\n     python -m pytest\n     ```\n\n*Note: You should run the unit test only after making the changes to the backend code.*\n\n12. **Questions and Collaboration:**\n    - Feel free to join our Discord. We're very friendly and welcoming to new contributors, so don't hesitate to reach out.\n\nThank you for considering contributing to DocsGPT! üôè\n\n## Questions/collaboration\nFeel free to join our [Discord](https://discord.gg/n5BX8dh8rU). We're very friendly and welcoming to new contributors, so don't hesitate to reach out.\n# Thank you so much for considering to contributing DocsGPT!üôè\n"
        },
        {
          "name": "HACKTOBERFEST.md",
          "type": "blob",
          "size": 2.5166015625,
          "content": "# **üéâ Join the Hacktoberfest with DocsGPT and win a Free T-shirt and other prizes! üéâ**\n\nWelcome, contributors! We're excited to announce that DocsGPT is participating in Hacktoberfest. Get involved by submitting meaningful pull requests.\n\nAll contributors with accepted PRs will receive a cool Holopin! ü§© (Watch out for a reply in your PR to collect it).\n\n### üèÜ Top 50 contributors will receive a special T-shirt\n\n### üèÜ [LLM Document analysis by LexEU competition](https://github.com/arc53/DocsGPT/blob/main/lexeu-competition.md): \nA separate competition is available for those who submit new retrieval / workflow method that will analyze a Document using EU laws.\nWith 200$, 100$, 50$ prize for 1st, 2nd and 3rd place respectively.\nYou can find more information [here](https://github.com/arc53/DocsGPT/blob/main/lexeu-competition.md)\n\n## üìú Here's How to Contribute:\n```text\nüõ†Ô∏è Code: This is the golden ticket! Make meaningful contributions through PRs.\n\nüß© API extension: Build an app utilising DocsGPT API. We prefer submissions that showcase original ideas and turn the API into an AI agent.\nThey can be a completely separate repos. \nFor example: \nhttps://github.com/arc53/tg-bot-docsgpt-extenstion or \nhttps://github.com/arc53/DocsGPT-cli\n\nNon-Code Contributions:\n\nüìö Wiki: Improve our documentation, create a guide or change existing documentation.\n\nüñ•Ô∏è Design: Improve the UI/UX or design a new feature.\n\nüìù Blogging or Content Creation: Write articles or create videos to showcase DocsGPT or highlight your contributions!\n```\n\n### üìù Guidelines for Pull Requests:\n- Familiarize yourself with the current contributions and our [Roadmap](https://github.com/orgs/arc53/projects/2).\n- Before contributing we highly advise that you check existing [issues](https://github.com/arc53/DocsGPT/issues) or [create](https://github.com/arc53/DocsGPT/issues/new/choose) an issue and wait to get assigned.\n- Once you are finished with your contribution, please fill in this [form](https://airtable.com/appikMaJwdHhC1SDP/pagoblCJ9W29wf6Hf/form).\n- Refer to the [Documentation](https://docs.docsgpt.cloud/).\n- Feel free to join our [Discord](https://discord.gg/n5BX8dh8rU) server. We're here to help newcomers, so don't hesitate to jump in! Join us [here](https://discord.gg/n5BX8dh8rU).\n  \nThank you very much for considering contributing to DocsGPT during Hacktoberfest! üôè Your contributions (not just simple typos) could earn you a stylish new t-shirt and other prizes as a token of our appreciation. üéÅ Join us, and let's code together! üöÄ\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.037109375,
          "content": "MIT License\n\nCopyright (c) 2023 arc53\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.4375,
          "content": "<h1 align=\"center\">\n  DocsGPT  ü¶ñ\n</h1>\n\n<p align=\"center\">\n  <strong>Open-Source Documentation Assistant</strong>\n</p>\n\n<p align=\"left\">\n  <strong><a href=\"https://www.docsgpt.cloud/\">DocsGPT</a></strong> is a cutting-edge open-source solution that streamlines the process of finding information in the project documentation. With its integration of the powerful <strong>GPT</strong> models, developers can easily ask questions about a project and receive accurate answers.\n  \nSay goodbye to time-consuming manual searches, and let <strong><a href=\"https://www.docsgpt.cloud/\">DocsGPT</a></strong> help you quickly find the information you need. Try it out and see how it revolutionizes your project documentation experience. Contribute to its development and be a part of the future of AI-powered assistance.\n</p>\n\n<div align=\"center\">\n  \n  <a href=\"https://github.com/arc53/DocsGPT\">![link to main GitHub showing Stars number](https://img.shields.io/github/stars/arc53/docsgpt?style=social)</a>\n  <a href=\"https://github.com/arc53/DocsGPT\">![link to main GitHub showing Forks number](https://img.shields.io/github/forks/arc53/docsgpt?style=social)</a>\n  <a href=\"https://github.com/arc53/DocsGPT/blob/main/LICENSE\">![link to license file](https://img.shields.io/github/license/arc53/docsgpt)</a>\n  <a href=\"https://discord.gg/n5BX8dh8rU\">![link to discord](https://img.shields.io/discord/1070046503302877216)</a>\n  <a href=\"https://twitter.com/docsgptai\">![X (formerly Twitter) URL](https://img.shields.io/twitter/follow/docsgptai)</a>\n\n \n</div>\n\n### Production Support / Help for Companies:\n\nWe're eager to provide personalized assistance when deploying your DocsGPT to a live environment.\n\n[Book a Meeting :wave:](https://cal.com/arc53/docsgpt-demo-b2b)‚Å†\n\n[Send Email :email:](mailto:contact@arc53.com?subject=DocsGPT%20support%2Fsolutions)\n\n\n<img src=\"https://github.com/user-attachments/assets/9a1f21de-7a15-4e42-9424-70d22ba5a913\" alt=\"video-example-of-docs-gpt\" width=\"1000\" height=\"500\">\n\n## Roadmap\n\nYou can find our roadmap [here](https://github.com/orgs/arc53/projects/2). Please don't hesitate to contribute or create issues, it helps us improve DocsGPT!\n\n## Our Open-Source Models Optimized for DocsGPT:\n\n| Name                                                                  | Base Model  | Requirements (or similar) |\n| --------------------------------------------------------------------- | ----------- | ------------------------- |\n| [Docsgpt-7b-mistral](https://huggingface.co/Arc53/docsgpt-7b-mistral)   | Mistral-7b   | 1xA10G gpu                |\n| [Docsgpt-14b](https://huggingface.co/Arc53/docsgpt-14b)               | llama-2-14b | 2xA10 gpu's               |\n| [Docsgpt-40b-falcon](https://huggingface.co/Arc53/docsgpt-40b-falcon) | falcon-40b  | 8xA10G gpu's              |\n\nIf you don't have enough resources to run it, you can use bitsnbytes to quantize.\n\n## End to End AI Framework for Information Retrieval\n\n![Architecture chart](https://github.com/user-attachments/assets/fc6a7841-ddfc-45e6-b5a0-d05fe648cbe2)\n\n## Useful Links\n\n- :mag: :fire: [Cloud Version](https://app.docsgpt.cloud/)\n\n- :speech_balloon: :tada: [Join our Discord](https://discord.gg/n5BX8dh8rU)\n\n- :books: :sunglasses: [Guides](https://docs.docsgpt.cloud/)\n\n- :couple: [Interested in contributing?](https://github.com/arc53/DocsGPT/blob/main/CONTRIBUTING.md)\n\n- :file_folder: :rocket: [How to use any other documentation](https://docs.docsgpt.cloud/Guides/How-to-train-on-other-documentation)\n\n- :house: :closed_lock_with_key: [How to host it locally (so all data will stay on-premises)](https://docs.docsgpt.cloud/Guides/How-to-use-different-LLM)\n\n## Project Structure\n\n- Application - Flask app (main application).\n\n- Extensions - Chrome extension.\n\n- Scripts - Script that creates similarity search index for other libraries.\n\n- Frontend - Frontend uses <a href=\"https://vitejs.dev/\">Vite</a> and <a href=\"https://react.dev/\">React</a>.\n\n## QuickStart\n\n> [!Note]\n> Make sure you have [Docker](https://docs.docker.com/engine/install/) installed\n\nOn Mac OS or Linux, write:\n\n`./setup.sh`\n\nIt will install all the dependencies and allow you to download the local model, use OpenAI or use our LLM API.\n\nOtherwise, refer to this Guide for Windows:\n\n1. Download and open this repository with `git clone https://github.com/arc53/DocsGPT.git`\n2. Create a `.env` file in your root directory and set the env variables and `VITE_API_STREAMING` to true or false, depending on whether you want streaming answers or not.\n   It should look like this inside:\n\n   ```\n   LLM_NAME=[docsgpt or openai or others] \n   VITE_API_STREAMING=true\n   API_KEY=[if LLM_NAME is openai]\n   ```\n\n   See optional environment variables in the [/.env-template](https://github.com/arc53/DocsGPT/blob/main/.env-template) and [/application/.env_sample](https://github.com/arc53/DocsGPT/blob/main/application/.env_sample) files.\n\n3. Run [./run-with-docker-compose.sh](https://github.com/arc53/DocsGPT/blob/main/run-with-docker-compose.sh).\n4. Navigate to http://localhost:5173/.\n\nTo stop, just run `Ctrl + C`.\n\n## Development Environments\n\n### Spin up Mongo and Redis\n\nFor development, only two containers are used from [docker-compose.yaml](https://github.com/arc53/DocsGPT/blob/main/docker-compose.yaml) (by deleting all services except for Redis and Mongo).\nSee file [docker-compose-dev.yaml](./docker-compose-dev.yaml).\n\nRun\n\n```\ndocker compose -f docker-compose-dev.yaml build\ndocker compose -f docker-compose-dev.yaml up -d\n```\n\n### Run the Backend\n\n> [!Note]\n> Make sure you have Python 3.12 installed.\n\n1. Export required environment variables or prepare a `.env` file in the project folder:\n   - Copy [.env-template](https://github.com/arc53/DocsGPT/blob/main/application/.env-template) and create `.env`.\n\n(check out [`application/core/settings.py`](application/core/settings.py) if you want to see more config options.)\n\n2. (optional) Create a Python virtual environment:\n   You can follow the [Python official documentation](https://docs.python.org/3/tutorial/venv.html) for virtual environments.\n\na) On Mac OS and Linux\n\n```commandline\npython -m venv venv\n. venv/bin/activate\n```\n\nb) On Windows\n\n```commandline\npython -m venv venv\n venv/Scripts/activate\n```\n\n3. Download embedding model and save it in the `model/` folder:\nYou can use the script below, or download it manually from [here](https://d3dg1063dc54p9.cloudfront.net/models/embeddings/mpnet-base-v2.zip), unzip it and save it in the `model/` folder.\n\n```commandline\nwget https://d3dg1063dc54p9.cloudfront.net/models/embeddings/mpnet-base-v2.zip\nunzip mpnet-base-v2.zip -d model\nrm mpnet-base-v2.zip\n```\n\n4. Install dependencies for the backend:\n\n```commandline\npip install -r application/requirements.txt\n```\n\n5. Run the app using `flask --app application/app.py run --host=0.0.0.0 --port=7091`.\n6. Start worker with `celery -A application.app.celery worker -l INFO`.\n\n### Start Frontend\n\n> [!Note]\n> Make sure you have Node version 16 or higher.\n\n1. Navigate to the [/frontend](https://github.com/arc53/DocsGPT/tree/main/frontend) folder.\n2. Install the required packages `husky` and `vite` (ignore if already installed).\n\n```commandline\nnpm install husky -g\nnpm install vite -g\n```\n\n3. Install dependencies by running `npm install --include=dev`.\n4. Run the app using `npm run dev`.\n\n## Contributing\n\nPlease refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file for information about how to get involved. We welcome issues, questions, and pull requests.\n\n## Code Of Conduct\n\nWe as members, contributors, and leaders, pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Please refer to the [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) file for more information about contributing.\n\n## Many Thanks To Our Contributors‚ö°\n\n<a href=\"https://github.com/arc53/DocsGPT/graphs/contributors\" alt=\"View Contributors\">\n  <img src=\"https://contrib.rocks/image?repo=arc53/DocsGPT\" alt=\"Contributors\" />\n</a>\n\n## License\n\nThe source code license is [MIT](https://opensource.org/license/mit/), as described in the [LICENSE](LICENSE) file.\n\n<p>This project is supported by:</p>\n<p>\n  <a href=\"https://www.digitalocean.com/?utm_medium=opensource&utm_source=DocsGPT\">\n    <img src=\"https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg\" width=\"201px\">\n  </a>\n</p>\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.2548828125,
          "content": "# Security Policy\n\n## Supported Versions\n\nSupported Versions:\n\nCurrently, we support security patches by committing changes and bumping the version published on Github.\n\n## Reporting a Vulnerability\n\nFound a vulnerability? Please email us:\n\nsecurity@arc53.com\n\n"
        },
        {
          "name": "application",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.0224609375,
          "content": "ignore:\n  - \"*/tests/*\""
        },
        {
          "name": "docker-compose-azure.yaml",
          "type": "blob",
          "size": 1.8369140625,
          "content": "services:\n  frontend:\n    build: ./frontend\n    environment:\n      - VITE_API_HOST=http://localhost:7091\n      - VITE_API_STREAMING=$VITE_API_STREAMING\n    ports:\n      - \"5173:5173\"\n    depends_on:\n      - backend\n\n  backend:\n    build: ./application\n    environment:\n      - API_KEY=$OPENAI_API_KEY\n      - EMBEDDINGS_KEY=$OPENAI_API_KEY\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/1\n      - MONGO_URI=mongodb://mongo:27017/docsgpt\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - OPENAI_API_BASE=$OPENAI_API_BASE\n      - OPENAI_API_VERSION=$OPENAI_API_VERSION\n      - AZURE_DEPLOYMENT_NAME=$AZURE_DEPLOYMENT_NAME\n      - AZURE_EMBEDDINGS_DEPLOYMENT_NAME=$AZURE_EMBEDDINGS_DEPLOYMENT_NAME\n    ports:\n      - \"7091:7091\"\n    volumes:\n      - ./application/indexes:/app/application/indexes\n      - ./application/inputs:/app/application/inputs\n      - ./application/vectors:/app/application/vectors\n    depends_on:\n        - redis\n        - mongo\n\n  worker:\n    build: ./application\n    command: celery -A application.app.celery worker -l INFO\n    environment:\n      - API_KEY=$OPENAI_API_KEY\n      - EMBEDDINGS_KEY=$OPENAI_API_KEY\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/1\n      - MONGO_URI=mongodb://mongo:27017/docsgpt\n      - API_URL=http://backend:7091\n      - OPENAI_API_KEY=$OPENAI_API_KEY\n      - OPENAI_API_BASE=$OPENAI_API_BASE\n      - OPENAI_API_VERSION=$OPENAI_API_VERSION\n      - AZURE_DEPLOYMENT_NAME=$AZURE_DEPLOYMENT_NAME\n      - AZURE_EMBEDDINGS_DEPLOYMENT_NAME=$AZURE_EMBEDDINGS_DEPLOYMENT_NAME\n    depends_on:\n        - redis\n        - mongo\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - 6379:6379\n\n  mongo:\n    image: mongo:6\n    ports:\n      - 27017:27017\n    volumes:\n      - mongodb_data_container:/data/db\n\n\n\nvolumes:\n  mongodb_data_container:"
        },
        {
          "name": "docker-compose-dev.yaml",
          "type": "blob",
          "size": 0.2197265625,
          "content": "services:\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - 6379:6379\n\n  mongo:\n    image: mongo:6\n    ports:\n      - 27017:27017\n    volumes:\n      - mongodb_data_container:/data/db\n\n\n\nvolumes:\n  mongodb_data_container:"
        },
        {
          "name": "docker-compose-local.yaml",
          "type": "blob",
          "size": 0.474609375,
          "content": "services:\n  frontend:\n    build: ./frontend\n    volumes:\n    - ./frontend/src:/app/src\n    environment:\n      - VITE_API_HOST=http://localhost:7091\n      - VITE_API_STREAMING=$VITE_API_STREAMING\n      - VITE_EMBEDDINGS_NAME=$EMBEDDINGS_NAME\n    ports:\n      - \"5173:5173\"\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - 6379:6379\n\n  mongo:\n    image: mongo:6\n    ports:\n      - 27017:27017\n    volumes:\n      - mongodb_data_container:/data/db\n\nvolumes:\n  mongodb_data_container:\n"
        },
        {
          "name": "docker-compose-mock.yaml",
          "type": "blob",
          "size": 0.3505859375,
          "content": "services:\n  frontend:\n    build: ./frontend\n    environment:\n      - VITE_API_HOST=http://localhost:7091\n      - VITE_API_STREAMING=$VITE_API_STREAMING\n    ports:\n      - \"5173:5173\"\n    depends_on:\n      - mock-backend\n\n  mock-backend:\n    build: ./mock-backend\n    ports:\n      - \"7091:7091\"\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - 6379:6379\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 1.490234375,
          "content": "services:\n  frontend:\n    build: ./frontend\n    volumes:\n      - ./frontend/src:/app/src\n    environment:\n      - VITE_API_HOST=http://localhost:7091\n      - VITE_API_STREAMING=$VITE_API_STREAMING\n    ports:\n      - \"5173:5173\"\n    depends_on:\n      - backend\n\n  backend:\n    build: ./application\n    environment:\n      - API_KEY=$API_KEY\n      - EMBEDDINGS_KEY=$API_KEY\n      - LLM_NAME=$LLM_NAME\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/1\n      - MONGO_URI=mongodb://mongo:27017/docsgpt\n      - CACHE_REDIS_URL=redis://redis:6379/2\n    ports:\n      - \"7091:7091\"\n    volumes:\n      - ./application/indexes:/app/application/indexes\n      - ./application/inputs:/app/application/inputs\n      - ./application/vectors:/app/application/vectors\n    depends_on:\n      - redis\n      - mongo\n\n  worker:\n    build: ./application\n    command: celery -A application.app.celery worker -l INFO -B\n    environment:\n      - API_KEY=$API_KEY\n      - EMBEDDINGS_KEY=$API_KEY\n      - LLM_NAME=$LLM_NAME\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/1\n      - MONGO_URI=mongodb://mongo:27017/docsgpt\n      - API_URL=http://backend:7091\n      - CACHE_REDIS_URL=redis://redis:6379/2\n    depends_on:\n      - redis\n      - mongo\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - 6379:6379\n\n  mongo:\n    image: mongo:6\n    ports:\n      - 27017:27017\n    volumes:\n      - mongodb_data_container:/data/db\n\nvolumes:\n  mongodb_data_container:\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "extensions",
          "type": "tree",
          "content": null
        },
        {
          "name": "frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "k8s",
          "type": "tree",
          "content": null
        },
        {
          "name": "run-with-docker-compose.sh",
          "type": "blob",
          "size": 0.3408203125,
          "content": "#!/bin/bash\n\nsource .env\n\nif [[ -n \"$OPENAI_API_BASE\" ]] && [[ -n \"$OPENAI_API_VERSION\" ]] && [[ -n \"$AZURE_DEPLOYMENT_NAME\" ]] && [[ -n \"$AZURE_EMBEDDINGS_DEPLOYMENT_NAME\" ]]; then\n  echo \"Running Azure Configuration\"\n  docker compose -f docker-compose-azure.yaml up --build\nelse\n  echo \"Running Plain Configuration\"\n  docker compose up --build\nfi\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.sh",
          "type": "blob",
          "size": 4.4111328125,
          "content": "#!/bin/bash\n\n# Function to prompt the user for their choice\nprompt_user() {\n    echo \"Do you want to:\"\n    echo \"1. Use DocsGPT public API (simple and free)\"\n    echo \"2. Download the language model locally (12GB)\"\n    echo \"3. Use the OpenAI API (requires an API key)\"\n    read -p \"Enter your choice (1, 2 or 3): \" choice\n}\n\ncheck_and_start_docker() {\n    # Check if Docker is running\n    if ! docker info > /dev/null 2>&1; then\n        echo \"Docker is not running. Starting Docker...\"\n\n        # Check the operating system\n        case \"$(uname -s)\" in\n            Darwin)\n                open -a Docker\n                ;;\n            Linux)\n                sudo systemctl start docker\n                ;;\n            *)\n                echo \"Unsupported platform. Please start Docker manually.\"\n                exit 1\n                ;;\n        esac\n\n        # Wait for Docker to be fully operational with animated dots\n        echo -n \"Waiting for Docker to start\"\n        while ! docker system info > /dev/null 2>&1; do\n            for i in {1..3}; do\n                echo -n \".\"\n                sleep 1\n            done\n            echo -ne \"\\rWaiting for Docker to start   \" # Reset to overwrite previous dots\n        done\n\n        echo -e \"\\nDocker has started!\"\n    fi\n}\n\n# Function to handle the choice to download the model locally\ndownload_locally() {\n    echo \"LLM_NAME=llama.cpp\" > .env\n    echo \"VITE_API_STREAMING=true\" >> .env\n    echo \"EMBEDDINGS_NAME=huggingface_sentence-transformers/all-mpnet-base-v2\" >> .env\n    echo \"The .env file has been created with LLM_NAME set to llama.cpp.\"\n\n    # Creating the directory if it does not exist\n    mkdir -p models\n    \n    # Downloading the model to the specific directory\n    echo \"Downloading the model...\"\n    # check if docsgpt-7b-f16.gguf does not exist\n    if [ ! -f models/docsgpt-7b-f16.gguf ]; then\n        echo \"Downloading the model...\"\n        wget -P models https://d3dg1063dc54p9.cloudfront.net/models/docsgpt-7b-f16.gguf\n        echo \"Model downloaded to models directory.\"\n    else\n        echo \"Model already exists.\"\n    fi\n   \n    # Call the function to check and start Docker if needed\n    check_and_start_docker\n\n    docker-compose -f docker-compose-local.yaml build && docker-compose -f docker-compose-local.yaml up -d\n    #python -m venv venv\n    #source venv/bin/activate\n    pip install -r application/requirements.txt\n    pip install llama-cpp-python\n    pip install sentence-transformers\n    export LLM_NAME=llama.cpp\n    export EMBEDDINGS_NAME=huggingface_sentence-transformers/all-mpnet-base-v2\n    export FLASK_APP=application/app.py\n    export FLASK_DEBUG=true\n    export CELERY_BROKER_URL=redis://localhost:6379/0\n    export CELERY_RESULT_BACKEND=redis://localhost:6379/1\n    echo \"The application is now running on http://localhost:5173\"\n    echo \"You can stop the application by running the following command:\"\n    echo \"Ctrl + C and then\"\n    echo \"Then pkill -f 'flask run' and then\"\n    echo \"docker-compose down\"\n    flask run --host=0.0.0.0 --port=7091 &\n    celery -A application.app.celery worker -l INFO\n}\n\n# Function to handle the choice to use the OpenAI API\nuse_openai() {\n    read -p \"Please enter your OpenAI API key: \" api_key\n    echo \"API_KEY=$api_key\" > .env\n    echo \"LLM_NAME=openai\" >> .env\n    echo \"VITE_API_STREAMING=true\" >> .env\n    echo \"The .env file has been created with API_KEY set to your provided key.\"\n\n    # Call the function to check and start Docker if needed\n    check_and_start_docker\n    \n    docker-compose build && docker-compose up -d\n\n    echo \"The application will run on http://localhost:5173\"\n    echo \"You can stop the application by running the following command:\"\n    echo \"docker-compose down\"\n}\n\nuse_docsgpt() {\n    echo \"LLM_NAME=docsgpt\" > .env\n    echo \"VITE_API_STREAMING=true\" >> .env\n    echo \"The .env file has been created with API_KEY set to your provided key.\"\n\n    # Call the function to check and start Docker if needed\n    check_and_start_docker\n\n    docker-compose build && docker-compose up -d\n\n    echo \"The application will run on http://localhost:5173\"\n    echo \"You can stop the application by running the following command:\"\n    echo \"docker-compose down\"\n}\n\n# Prompt the user for their choice\nprompt_user\n\n# Handle the user's choice\ncase $choice in\n    1)\n        use_docsgpt\n        ;;\n    2)\n        download_locally\n        ;;\n    3)\n        use_openai\n        ;;\n    *)\n        echo \"Invalid choice. Please choose either 1 or 2.\"\n        ;;\nesac\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}