{
  "metadata": {
    "timestamp": 1736567845028,
    "page": 1,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sirupsen/logrus",
      "stars": 24888,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.021484375,
          "content": "logrus\nvendor\n\n.idea/\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.951171875,
          "content": "run:\n  # do not run on test files yet\n  tests: false\n\n# all available settings of specific linters\nlinters-settings:\n  errcheck:\n    # report about not checking of errors in type assetions: `a := b.(MyStruct)`;\n    # default is false: such cases aren't reported by default.\n    check-type-assertions: false\n\n    # report about assignment of errors to blank identifier: `num, _ := strconv.Atoi(numStr)`;\n    # default is false: such cases aren't reported by default.\n    check-blank: false\n\n  lll:\n    line-length: 100\n    tab-width: 4\n\n  prealloc:\n    simple: false\n    range-loops: false\n    for-loops: false\n\n  whitespace:\n    multi-if: false   # Enforces newlines (or comments) after every multi-line if statement\n    multi-func: false # Enforces newlines (or comments) after every multi-line function signature\n\nlinters:\n  enable:\n    - megacheck\n    - govet\n  disable:\n    - maligned\n    - prealloc\n  disable-all: false\n  presets:\n    - bugs\n    - unused\n  fast: false\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.26953125,
          "content": "language: go\ngo_import_path: github.com/sirupsen/logrus\ngit:\n  depth: 1\nenv:\n  - GO111MODULE=on\ngo: 1.15.x\nos: linux\ninstall:\n  - ./travis/install.sh\nscript:\n  - cd ci\n  - go run mage.go -v -w ../ crossBuild\n  - go run mage.go -v -w ../ lint\n  - go run mage.go -v -w ../ test\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 7.294921875,
          "content": "# 1.8.1\nCode quality:\n  * move magefile in its own subdir/submodule to remove magefile dependency on logrus consumer\n  * improve timestamp format documentation\n\nFixes:\n  * fix race condition on logger hooks\n\n\n# 1.8.0\n\nCorrect versioning number replacing v1.7.1.\n\n# 1.7.1\n\nBeware this release has introduced a new public API and its semver is therefore incorrect.\n\nCode quality:\n  * use go 1.15 in travis\n  * use magefile as task runner\n\nFixes:\n  * small fixes about new go 1.13 error formatting system\n  * Fix for long time race condiction with mutating data hooks\n\nFeatures:\n  * build support for zos\n\n# 1.7.0\nFixes:\n  * the dependency toward a windows terminal library has been removed\n\nFeatures:\n  * a new buffer pool management API has been added\n  * a set of `<LogLevel>Fn()` functions have been added\n\n# 1.6.0\nFixes:\n  * end of line cleanup\n  * revert the entry concurrency bug fix whic leads to deadlock under some circumstances\n  * update dependency on go-windows-terminal-sequences to fix a crash with go 1.14\n\nFeatures:\n  * add an option to the `TextFormatter` to completely disable fields quoting\n\n# 1.5.0\nCode quality:\n  * add golangci linter run on travis\n\nFixes:\n  * add mutex for hooks concurrent access on `Entry` data\n  * caller function field for go1.14\n  * fix build issue for gopherjs target\n\nFeature:\n  * add an hooks/writer sub-package whose goal is to split output on different stream depending on the trace level\n  * add a `DisableHTMLEscape` option in the `JSONFormatter`\n  * add `ForceQuote` and `PadLevelText` options in the `TextFormatter`\n\n# 1.4.2\n  * Fixes build break for plan9, nacl, solaris\n# 1.4.1\nThis new release introduces:\n  * Enhance TextFormatter to not print caller information when they are empty (#944)\n  * Remove dependency on golang.org/x/crypto (#932, #943)\n\nFixes:\n  * Fix Entry.WithContext method to return a copy of the initial entry (#941)\n\n# 1.4.0\nThis new release introduces:\n  * Add `DeferExitHandler`, similar to `RegisterExitHandler` but prepending the handler to the list of handlers (semantically like `defer`) (#848).\n  * Add `CallerPrettyfier` to `JSONFormatter` and `TextFormatter` (#909, #911)\n  * Add `Entry.WithContext()` and `Entry.Context`, to set a context on entries to be used e.g. in hooks (#919).\n\nFixes:\n  * Fix wrong method calls `Logger.Print` and `Logger.Warningln` (#893).\n  * Update `Entry.Logf` to not do string formatting unless the log level is enabled (#903)\n  * Fix infinite recursion on unknown `Level.String()` (#907)\n  * Fix race condition in `getCaller` (#916).\n\n\n# 1.3.0\nThis new release introduces:\n  * Log, Logf, Logln functions for Logger and Entry that take a Level\n\nFixes:\n  * Building prometheus node_exporter on AIX (#840)\n  * Race condition in TextFormatter (#468)\n  * Travis CI import path (#868)\n  * Remove coloured output on Windows (#862)\n  * Pointer to func as field in JSONFormatter (#870)\n  * Properly marshal Levels (#873)\n\n# 1.2.0\nThis new release introduces:\n  * A new method `SetReportCaller` in the `Logger` to enable the file, line and calling function from which the trace has been issued\n  * A new trace level named `Trace` whose level is below `Debug`\n  * A configurable exit function to be called upon a Fatal trace\n  * The `Level` object now implements `encoding.TextUnmarshaler` interface\n\n# 1.1.1\nThis is a bug fix release.\n  * fix the build break on Solaris\n  * don't drop a whole trace in JSONFormatter when a field param is a function pointer which can not be serialized\n\n# 1.1.0\nThis new release introduces:\n  * several fixes:\n    * a fix for a race condition on entry formatting\n    * proper cleanup of previously used entries before putting them back in the pool\n    * the extra new line at the end of message in text formatter has been removed\n  * a new global public API to check if a level is activated: IsLevelEnabled\n  * the following methods have been added to the Logger object\n    * IsLevelEnabled\n    * SetFormatter\n    * SetOutput\n    * ReplaceHooks\n  * introduction of go module\n  * an indent configuration for the json formatter\n  * output colour support for windows\n  * the field sort function is now configurable for text formatter\n  * the CLICOLOR and CLICOLOR\\_FORCE environment variable support in text formater\n\n# 1.0.6\n\nThis new release introduces:\n  * a new api WithTime which allows to easily force the time of the log entry\n    which is mostly useful for logger wrapper\n  * a fix reverting the immutability of the entry given as parameter to the hooks\n    a new configuration field of the json formatter in order to put all the fields\n    in a nested dictionnary\n  * a new SetOutput method in the Logger\n  * a new configuration of the textformatter to configure the name of the default keys\n  * a new configuration of the text formatter to disable the level truncation\n\n# 1.0.5\n\n* Fix hooks race (#707)\n* Fix panic deadlock (#695)\n\n# 1.0.4\n\n* Fix race when adding hooks (#612)\n* Fix terminal check in AppEngine (#635)\n\n# 1.0.3\n\n* Replace example files with testable examples\n\n# 1.0.2\n\n* bug: quote non-string values in text formatter (#583)\n* Make (*Logger) SetLevel a public method\n\n# 1.0.1\n\n* bug: fix escaping in text formatter (#575)\n\n# 1.0.0\n\n* Officially changed name to lower-case\n* bug: colors on Windows 10 (#541)\n* bug: fix race in accessing level (#512)\n\n# 0.11.5\n\n* feature: add writer and writerlevel to entry (#372)\n\n# 0.11.4\n\n* bug: fix undefined variable on solaris (#493)\n\n# 0.11.3\n\n* formatter: configure quoting of empty values (#484)\n* formatter: configure quoting character (default is `\"`) (#484)\n* bug: fix not importing io correctly in non-linux environments (#481)\n\n# 0.11.2\n\n* bug: fix windows terminal detection (#476)\n\n# 0.11.1\n\n* bug: fix tty detection with custom out (#471)\n\n# 0.11.0\n\n* performance: Use bufferpool to allocate (#370)\n* terminal: terminal detection for app-engine (#343)\n* feature: exit handler (#375)\n\n# 0.10.0\n\n* feature: Add a test hook (#180)\n* feature: `ParseLevel` is now case-insensitive (#326)\n* feature: `FieldLogger` interface that generalizes `Logger` and `Entry` (#308)\n* performance: avoid re-allocations on `WithFields` (#335)\n\n# 0.9.0\n\n* logrus/text_formatter: don't emit empty msg\n* logrus/hooks/airbrake: move out of main repository\n* logrus/hooks/sentry: move out of main repository\n* logrus/hooks/papertrail: move out of main repository\n* logrus/hooks/bugsnag: move out of main repository\n* logrus/core: run tests with `-race`\n* logrus/core: detect TTY based on `stderr`\n* logrus/core: support `WithError` on logger\n* logrus/core: Solaris support\n\n# 0.8.7\n\n* logrus/core: fix possible race (#216)\n* logrus/doc: small typo fixes and doc improvements\n\n\n# 0.8.6\n\n* hooks/raven: allow passing an initialized client\n\n# 0.8.5\n\n* logrus/core: revert #208\n\n# 0.8.4\n\n* formatter/text: fix data race (#218)\n\n# 0.8.3\n\n* logrus/core: fix entry log level (#208)\n* logrus/core: improve performance of text formatter by 40%\n* logrus/core: expose `LevelHooks` type\n* logrus/core: add support for DragonflyBSD and NetBSD\n* formatter/text: print structs more verbosely\n\n# 0.8.2\n\n* logrus: fix more Fatal family functions\n\n# 0.8.1\n\n* logrus: fix not exiting on `Fatalf` and `Fatalln`\n\n# 0.8.0\n\n* logrus: defaults to stderr instead of stdout\n* hooks/sentry: add special field for `*http.Request`\n* formatter/text: ignore Windows for colors\n\n# 0.7.3\n\n* formatter/\\*: allow configuration of timestamp layout\n\n# 0.7.2\n\n* formatter/text: Add configuration option for time format (#158)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.056640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2014 Simon Eskildsen\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 19.126953125,
          "content": "# Logrus <img src=\"http://i.imgur.com/hTeVwmJ.png\" width=\"40\" height=\"40\" alt=\":walrus:\" class=\"emoji\" title=\":walrus:\"/> [![Build Status](https://github.com/sirupsen/logrus/workflows/CI/badge.svg)](https://github.com/sirupsen/logrus/actions?query=workflow%3ACI) [![Build Status](https://travis-ci.org/sirupsen/logrus.svg?branch=master)](https://travis-ci.org/sirupsen/logrus) [![Go Reference](https://pkg.go.dev/badge/github.com/sirupsen/logrus.svg)](https://pkg.go.dev/github.com/sirupsen/logrus)\n\nLogrus is a structured logger for Go (golang), completely API compatible with\nthe standard library logger.\n\n**Logrus is in maintenance-mode.** We will not be introducing new features. It's\nsimply too hard to do in a way that won't break many people's projects, which is\nthe last thing you want from your Logging library (again...).\n\nThis does not mean Logrus is dead. Logrus will continue to be maintained for\nsecurity, (backwards compatible) bug fixes, and performance (where we are\nlimited by the interface).\n\nI believe Logrus' biggest contribution is to have played a part in today's\nwidespread use of structured logging in Golang. There doesn't seem to be a\nreason to do a major, breaking iteration into Logrus V2, since the fantastic Go\ncommunity has built those independently. Many fantastic alternatives have sprung\nup. Logrus would look like those, had it been re-designed with what we know\nabout structured logging in Go today. Check out, for example,\n[Zerolog][zerolog], [Zap][zap], and [Apex][apex].\n\n[zerolog]: https://github.com/rs/zerolog\n[zap]: https://github.com/uber-go/zap\n[apex]: https://github.com/apex/log\n\n**Seeing weird case-sensitive problems?** It's in the past been possible to\nimport Logrus as both upper- and lower-case. Due to the Go package environment,\nthis caused issues in the community and we needed a standard. Some environments\nexperienced problems with the upper-case variant, so the lower-case was decided.\nEverything using `logrus` will need to use the lower-case:\n`github.com/sirupsen/logrus`. Any package that isn't, should be changed.\n\nTo fix Glide, see [these\ncomments](https://github.com/sirupsen/logrus/issues/553#issuecomment-306591437).\nFor an in-depth explanation of the casing issue, see [this\ncomment](https://github.com/sirupsen/logrus/issues/570#issuecomment-313933276).\n\nNicely color-coded in development (when a TTY is attached, otherwise just\nplain text):\n\n![Colored](http://i.imgur.com/PY7qMwd.png)\n\nWith `log.SetFormatter(&log.JSONFormatter{})`, for easy parsing by logstash\nor Splunk:\n\n```text\n{\"animal\":\"walrus\",\"level\":\"info\",\"msg\":\"A group of walrus emerges from the\nocean\",\"size\":10,\"time\":\"2014-03-10 19:57:38.562264131 -0400 EDT\"}\n\n{\"level\":\"warning\",\"msg\":\"The group's number increased tremendously!\",\n\"number\":122,\"omg\":true,\"time\":\"2014-03-10 19:57:38.562471297 -0400 EDT\"}\n\n{\"animal\":\"walrus\",\"level\":\"info\",\"msg\":\"A giant walrus appears!\",\n\"size\":10,\"time\":\"2014-03-10 19:57:38.562500591 -0400 EDT\"}\n\n{\"animal\":\"walrus\",\"level\":\"info\",\"msg\":\"Tremendously sized cow enters the ocean.\",\n\"size\":9,\"time\":\"2014-03-10 19:57:38.562527896 -0400 EDT\"}\n\n{\"level\":\"fatal\",\"msg\":\"The ice breaks!\",\"number\":100,\"omg\":true,\n\"time\":\"2014-03-10 19:57:38.562543128 -0400 EDT\"}\n```\n\nWith the default `log.SetFormatter(&log.TextFormatter{})` when a TTY is not\nattached, the output is compatible with the\n[logfmt](http://godoc.org/github.com/kr/logfmt) format:\n\n```text\ntime=\"2015-03-26T01:27:38-04:00\" level=debug msg=\"Started observing beach\" animal=walrus number=8\ntime=\"2015-03-26T01:27:38-04:00\" level=info msg=\"A group of walrus emerges from the ocean\" animal=walrus size=10\ntime=\"2015-03-26T01:27:38-04:00\" level=warning msg=\"The group's number increased tremendously!\" number=122 omg=true\ntime=\"2015-03-26T01:27:38-04:00\" level=debug msg=\"Temperature changes\" temperature=-4\ntime=\"2015-03-26T01:27:38-04:00\" level=panic msg=\"It's over 9000!\" animal=orca size=9009\ntime=\"2015-03-26T01:27:38-04:00\" level=fatal msg=\"The ice breaks!\" err=&{0x2082280c0 map[animal:orca size:9009] 2015-03-26 01:27:38.441574009 -0400 EDT panic It's over 9000!} number=100 omg=true\n```\nTo ensure this behaviour even if a TTY is attached, set your formatter as follows:\n\n```go\n\tlog.SetFormatter(&log.TextFormatter{\n\t\tDisableColors: true,\n\t\tFullTimestamp: true,\n\t})\n```\n\n#### Logging Method Name\n\nIf you wish to add the calling method as a field, instruct the logger via:\n```go\nlog.SetReportCaller(true)\n```\nThis adds the caller as 'method' like so:\n\n```json\n{\"animal\":\"penguin\",\"level\":\"fatal\",\"method\":\"github.com/sirupsen/arcticcreatures.migrate\",\"msg\":\"a penguin swims by\",\n\"time\":\"2014-03-10 19:57:38.562543129 -0400 EDT\"}\n```\n\n```text\ntime=\"2015-03-26T01:27:38-04:00\" level=fatal method=github.com/sirupsen/arcticcreatures.migrate msg=\"a penguin swims by\" animal=penguin\n```\nNote that this does add measurable overhead - the cost will depend on the version of Go, but is\nbetween 20 and 40% in recent tests with 1.6 and 1.7.  You can validate this in your\nenvironment via benchmarks:\n```\ngo test -bench=.*CallerTracing\n```\n\n\n#### Case-sensitivity\n\nThe organization's name was changed to lower-case--and this will not be changed\nback. If you are getting import conflicts due to case sensitivity, please use\nthe lower-case import: `github.com/sirupsen/logrus`.\n\n#### Example\n\nThe simplest way to use Logrus is simply the package-level exported logger:\n\n```go\npackage main\n\nimport (\n  log \"github.com/sirupsen/logrus\"\n)\n\nfunc main() {\n  log.WithFields(log.Fields{\n    \"animal\": \"walrus\",\n  }).Info(\"A walrus appears\")\n}\n```\n\nNote that it's completely api-compatible with the stdlib logger, so you can\nreplace your `log` imports everywhere with `log \"github.com/sirupsen/logrus\"`\nand you'll now have the flexibility of Logrus. You can customize it all you\nwant:\n\n```go\npackage main\n\nimport (\n  \"os\"\n  log \"github.com/sirupsen/logrus\"\n)\n\nfunc init() {\n  // Log as JSON instead of the default ASCII formatter.\n  log.SetFormatter(&log.JSONFormatter{})\n\n  // Output to stdout instead of the default stderr\n  // Can be any io.Writer, see below for File example\n  log.SetOutput(os.Stdout)\n\n  // Only log the warning severity or above.\n  log.SetLevel(log.WarnLevel)\n}\n\nfunc main() {\n  log.WithFields(log.Fields{\n    \"animal\": \"walrus\",\n    \"size\":   10,\n  }).Info(\"A group of walrus emerges from the ocean\")\n\n  log.WithFields(log.Fields{\n    \"omg\":    true,\n    \"number\": 122,\n  }).Warn(\"The group's number increased tremendously!\")\n\n  log.WithFields(log.Fields{\n    \"omg\":    true,\n    \"number\": 100,\n  }).Fatal(\"The ice breaks!\")\n\n  // A common pattern is to re-use fields between logging statements by re-using\n  // the logrus.Entry returned from WithFields()\n  contextLogger := log.WithFields(log.Fields{\n    \"common\": \"this is a common field\",\n    \"other\": \"I also should be logged always\",\n  })\n\n  contextLogger.Info(\"I'll be logged with common and other field\")\n  contextLogger.Info(\"Me too\")\n}\n```\n\nFor more advanced usage such as logging to multiple locations from the same\napplication, you can also create an instance of the `logrus` Logger:\n\n```go\npackage main\n\nimport (\n  \"os\"\n  \"github.com/sirupsen/logrus\"\n)\n\n// Create a new instance of the logger. You can have any number of instances.\nvar log = logrus.New()\n\nfunc main() {\n  // The API for setting attributes is a little different than the package level\n  // exported logger. See Godoc.\n  log.Out = os.Stdout\n\n  // You could set this to any `io.Writer` such as a file\n  // file, err := os.OpenFile(\"logrus.log\", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666)\n  // if err == nil {\n  //  log.Out = file\n  // } else {\n  //  log.Info(\"Failed to log to file, using default stderr\")\n  // }\n\n  log.WithFields(logrus.Fields{\n    \"animal\": \"walrus\",\n    \"size\":   10,\n  }).Info(\"A group of walrus emerges from the ocean\")\n}\n```\n\n#### Fields\n\nLogrus encourages careful, structured logging through logging fields instead of\nlong, unparseable error messages. For example, instead of: `log.Fatalf(\"Failed\nto send event %s to topic %s with key %d\")`, you should log the much more\ndiscoverable:\n\n```go\nlog.WithFields(log.Fields{\n  \"event\": event,\n  \"topic\": topic,\n  \"key\": key,\n}).Fatal(\"Failed to send event\")\n```\n\nWe've found this API forces you to think about logging in a way that produces\nmuch more useful logging messages. We've been in countless situations where just\na single added field to a log statement that was already there would've saved us\nhours. The `WithFields` call is optional.\n\nIn general, with Logrus using any of the `printf`-family functions should be\nseen as a hint you should add a field, however, you can still use the\n`printf`-family functions with Logrus.\n\n#### Default Fields\n\nOften it's helpful to have fields _always_ attached to log statements in an\napplication or parts of one. For example, you may want to always log the\n`request_id` and `user_ip` in the context of a request. Instead of writing\n`log.WithFields(log.Fields{\"request_id\": request_id, \"user_ip\": user_ip})` on\nevery line, you can create a `logrus.Entry` to pass around instead:\n\n```go\nrequestLogger := log.WithFields(log.Fields{\"request_id\": request_id, \"user_ip\": user_ip})\nrequestLogger.Info(\"something happened on that request\") # will log request_id and user_ip\nrequestLogger.Warn(\"something not great happened\")\n```\n\n#### Hooks\n\nYou can add hooks for logging levels. For example to send errors to an exception\ntracking service on `Error`, `Fatal` and `Panic`, info to StatsD or log to\nmultiple places simultaneously, e.g. syslog.\n\nLogrus comes with [built-in hooks](hooks/). Add those, or your custom hook, in\n`init`:\n\n```go\nimport (\n  log \"github.com/sirupsen/logrus\"\n  \"gopkg.in/gemnasium/logrus-airbrake-hook.v2\" // the package is named \"airbrake\"\n  logrus_syslog \"github.com/sirupsen/logrus/hooks/syslog\"\n  \"log/syslog\"\n)\n\nfunc init() {\n\n  // Use the Airbrake hook to report errors that have Error severity or above to\n  // an exception tracker. You can create custom hooks, see the Hooks section.\n  log.AddHook(airbrake.NewHook(123, \"xyz\", \"production\"))\n\n  hook, err := logrus_syslog.NewSyslogHook(\"udp\", \"localhost:514\", syslog.LOG_INFO, \"\")\n  if err != nil {\n    log.Error(\"Unable to connect to local syslog daemon\")\n  } else {\n    log.AddHook(hook)\n  }\n}\n```\nNote: Syslog hook also support connecting to local syslog (Ex. \"/dev/log\" or \"/var/run/syslog\" or \"/var/run/log\"). For the detail, please check the [syslog hook README](hooks/syslog/README.md).\n\nA list of currently known service hooks can be found in this wiki [page](https://github.com/sirupsen/logrus/wiki/Hooks)\n\n\n#### Level logging\n\nLogrus has seven logging levels: Trace, Debug, Info, Warning, Error, Fatal and Panic.\n\n```go\nlog.Trace(\"Something very low level.\")\nlog.Debug(\"Useful debugging information.\")\nlog.Info(\"Something noteworthy happened!\")\nlog.Warn(\"You should probably take a look at this.\")\nlog.Error(\"Something failed but I'm not quitting.\")\n// Calls os.Exit(1) after logging\nlog.Fatal(\"Bye.\")\n// Calls panic() after logging\nlog.Panic(\"I'm bailing.\")\n```\n\nYou can set the logging level on a `Logger`, then it will only log entries with\nthat severity or anything above it:\n\n```go\n// Will log anything that is info or above (warn, error, fatal, panic). Default.\nlog.SetLevel(log.InfoLevel)\n```\n\nIt may be useful to set `log.Level = logrus.DebugLevel` in a debug or verbose\nenvironment if your application has that.\n\nNote: If you want different log levels for global (`log.SetLevel(...)`) and syslog logging, please check the [syslog hook README](hooks/syslog/README.md#different-log-levels-for-local-and-remote-logging).\n\n#### Entries\n\nBesides the fields added with `WithField` or `WithFields` some fields are\nautomatically added to all logging events:\n\n1. `time`. The timestamp when the entry was created.\n2. `msg`. The logging message passed to `{Info,Warn,Error,Fatal,Panic}` after\n   the `AddFields` call. E.g. `Failed to send event.`\n3. `level`. The logging level. E.g. `info`.\n\n#### Environments\n\nLogrus has no notion of environment.\n\nIf you wish for hooks and formatters to only be used in specific environments,\nyou should handle that yourself. For example, if your application has a global\nvariable `Environment`, which is a string representation of the environment you\ncould do:\n\n```go\nimport (\n  log \"github.com/sirupsen/logrus\"\n)\n\nfunc init() {\n  // do something here to set environment depending on an environment variable\n  // or command-line flag\n  if Environment == \"production\" {\n    log.SetFormatter(&log.JSONFormatter{})\n  } else {\n    // The TextFormatter is default, you don't actually have to do this.\n    log.SetFormatter(&log.TextFormatter{})\n  }\n}\n```\n\nThis configuration is how `logrus` was intended to be used, but JSON in\nproduction is mostly only useful if you do log aggregation with tools like\nSplunk or Logstash.\n\n#### Formatters\n\nThe built-in logging formatters are:\n\n* `logrus.TextFormatter`. Logs the event in colors if stdout is a tty, otherwise\n  without colors.\n  * *Note:* to force colored output when there is no TTY, set the `ForceColors`\n    field to `true`.  To force no colored output even if there is a TTY  set the\n    `DisableColors` field to `true`. For Windows, see\n    [github.com/mattn/go-colorable](https://github.com/mattn/go-colorable).\n  * When colors are enabled, levels are truncated to 4 characters by default. To disable\n    truncation set the `DisableLevelTruncation` field to `true`.\n  * When outputting to a TTY, it's often helpful to visually scan down a column where all the levels are the same width. Setting the `PadLevelText` field to `true` enables this behavior, by adding padding to the level text.\n  * All options are listed in the [generated docs](https://godoc.org/github.com/sirupsen/logrus#TextFormatter).\n* `logrus.JSONFormatter`. Logs fields as JSON.\n  * All options are listed in the [generated docs](https://godoc.org/github.com/sirupsen/logrus#JSONFormatter).\n\nThird party logging formatters:\n\n* [`FluentdFormatter`](https://github.com/joonix/log). Formats entries that can be parsed by Kubernetes and Google Container Engine.\n* [`GELF`](https://github.com/fabienm/go-logrus-formatters). Formats entries so they comply to Graylog's [GELF 1.1 specification](http://docs.graylog.org/en/2.4/pages/gelf.html).\n* [`logstash`](https://github.com/bshuster-repo/logrus-logstash-hook). Logs fields as [Logstash](http://logstash.net) Events.\n* [`prefixed`](https://github.com/x-cray/logrus-prefixed-formatter). Displays log entry source along with alternative layout.\n* [`zalgo`](https://github.com/aybabtme/logzalgo). Invoking the Power of Zalgo.\n* [`nested-logrus-formatter`](https://github.com/antonfisher/nested-logrus-formatter). Converts logrus fields to a nested structure.\n* [`powerful-logrus-formatter`](https://github.com/zput/zxcTool). get fileName, log's line number and the latest function's name when print log; Save log to files.\n* [`caption-json-formatter`](https://github.com/nolleh/caption_json_formatter). logrus's message json formatter with human-readable caption added.\n\nYou can define your formatter by implementing the `Formatter` interface,\nrequiring a `Format` method. `Format` takes an `*Entry`. `entry.Data` is a\n`Fields` type (`map[string]interface{}`) with all your fields as well as the\ndefault ones (see Entries section above):\n\n```go\ntype MyJSONFormatter struct {\n}\n\nlog.SetFormatter(new(MyJSONFormatter))\n\nfunc (f *MyJSONFormatter) Format(entry *Entry) ([]byte, error) {\n  // Note this doesn't include Time, Level and Message which are available on\n  // the Entry. Consult `godoc` on information about those fields or read the\n  // source of the official loggers.\n  serialized, err := json.Marshal(entry.Data)\n    if err != nil {\n      return nil, fmt.Errorf(\"Failed to marshal fields to JSON, %w\", err)\n    }\n  return append(serialized, '\\n'), nil\n}\n```\n\n#### Logger as an `io.Writer`\n\nLogrus can be transformed into an `io.Writer`. That writer is the end of an `io.Pipe` and it is your responsibility to close it.\n\n```go\nw := logger.Writer()\ndefer w.Close()\n\nsrv := http.Server{\n    // create a stdlib log.Logger that writes to\n    // logrus.Logger.\n    ErrorLog: log.New(w, \"\", 0),\n}\n```\n\nEach line written to that writer will be printed the usual way, using formatters\nand hooks. The level for those entries is `info`.\n\nThis means that we can override the standard library logger easily:\n\n```go\nlogger := logrus.New()\nlogger.Formatter = &logrus.JSONFormatter{}\n\n// Use logrus for standard log output\n// Note that `log` here references stdlib's log\n// Not logrus imported under the name `log`.\nlog.SetOutput(logger.Writer())\n```\n\n#### Rotation\n\nLog rotation is not provided with Logrus. Log rotation should be done by an\nexternal program (like `logrotate(8)`) that can compress and delete old log\nentries. It should not be a feature of the application-level logger.\n\n#### Tools\n\n| Tool | Description |\n| ---- | ----------- |\n|[Logrus Mate](https://github.com/gogap/logrus_mate)|Logrus mate is a tool for Logrus to manage loggers, you can initial logger's level, hook and formatter by config file, the logger will be generated with different configs in different environments.|\n|[Logrus Viper Helper](https://github.com/heirko/go-contrib/tree/master/logrusHelper)|An Helper around Logrus to wrap with spf13/Viper to load configuration with fangs! And to simplify Logrus configuration use some behavior of [Logrus Mate](https://github.com/gogap/logrus_mate). [sample](https://github.com/heirko/iris-contrib/blob/master/middleware/logrus-logger/example) |\n\n#### Testing\n\nLogrus has a built in facility for asserting the presence of log messages. This is implemented through the `test` hook and provides:\n\n* decorators for existing logger (`test.NewLocal` and `test.NewGlobal`) which basically just adds the `test` hook\n* a test logger (`test.NewNullLogger`) that just records log messages (and does not output any):\n\n```go\nimport(\n  \"github.com/sirupsen/logrus\"\n  \"github.com/sirupsen/logrus/hooks/test\"\n  \"github.com/stretchr/testify/assert\"\n  \"testing\"\n)\n\nfunc TestSomething(t*testing.T){\n  logger, hook := test.NewNullLogger()\n  logger.Error(\"Helloerror\")\n\n  assert.Equal(t, 1, len(hook.Entries))\n  assert.Equal(t, logrus.ErrorLevel, hook.LastEntry().Level)\n  assert.Equal(t, \"Helloerror\", hook.LastEntry().Message)\n\n  hook.Reset()\n  assert.Nil(t, hook.LastEntry())\n}\n```\n\n#### Fatal handlers\n\nLogrus can register one or more functions that will be called when any `fatal`\nlevel message is logged. The registered handlers will be executed before\nlogrus performs an `os.Exit(1)`. This behavior may be helpful if callers need\nto gracefully shutdown. Unlike a `panic(\"Something went wrong...\")` call which can be intercepted with a deferred `recover` a call to `os.Exit(1)` can not be intercepted.\n\n```\n...\nhandler := func() {\n  // gracefully shutdown something...\n}\nlogrus.RegisterExitHandler(handler)\n...\n```\n\n#### Thread safety\n\nBy default, Logger is protected by a mutex for concurrent writes. The mutex is held when calling hooks and writing logs.\nIf you are sure such locking is not needed, you can call logger.SetNoLock() to disable the locking.\n\nSituation when locking is not needed includes:\n\n* You have no hooks registered, or hooks calling is already thread-safe.\n\n* Writing to logger.Out is already thread-safe, for example:\n\n  1) logger.Out is protected by locks.\n\n  2) logger.Out is an os.File handler opened with `O_APPEND` flag, and every write is smaller than 4k. (This allows multi-thread/multi-process writing)\n\n     (Refer to http://www.notthewizard.com/2014/06/17/are-files-appends-really-atomic/)\n"
        },
        {
          "name": "alt_exit.go",
          "type": "blob",
          "size": 2.736328125,
          "content": "package logrus\n\n// The following code was sourced and modified from the\n// https://github.com/tebeka/atexit package governed by the following license:\n//\n// Copyright (c) 2012 Miki Tebeka <miki.tebeka@gmail.com>.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n// the Software, and to permit persons to whom the Software is furnished to do so,\n// subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n// FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n// COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n// IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n// CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nimport (\n\t\"fmt\"\n\t\"os\"\n)\n\nvar handlers = []func(){}\n\nfunc runHandler(handler func()) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Fprintln(os.Stderr, \"Error: Logrus exit handler error:\", err)\n\t\t}\n\t}()\n\n\thandler()\n}\n\nfunc runHandlers() {\n\tfor _, handler := range handlers {\n\t\trunHandler(handler)\n\t}\n}\n\n// Exit runs all the Logrus atexit handlers and then terminates the program using os.Exit(code)\nfunc Exit(code int) {\n\trunHandlers()\n\tos.Exit(code)\n}\n\n// RegisterExitHandler appends a Logrus Exit handler to the list of handlers,\n// call logrus.Exit to invoke all handlers. The handlers will also be invoked when\n// any Fatal log entry is made.\n//\n// This method is useful when a caller wishes to use logrus to log a fatal\n// message but also needs to gracefully shutdown. An example usecase could be\n// closing database connections, or sending a alert that the application is\n// closing.\nfunc RegisterExitHandler(handler func()) {\n\thandlers = append(handlers, handler)\n}\n\n// DeferExitHandler prepends a Logrus Exit handler to the list of handlers,\n// call logrus.Exit to invoke all handlers. The handlers will also be invoked when\n// any Fatal log entry is made.\n//\n// This method is useful when a caller wishes to use logrus to log a fatal\n// message but also needs to gracefully shutdown. An example usecase could be\n// closing database connections, or sending a alert that the application is\n// closing.\nfunc DeferExitHandler(handler func()) {\n\thandlers = append([]func(){handler}, handlers...)\n}\n"
        },
        {
          "name": "alt_exit_test.go",
          "type": "blob",
          "size": 3.1337890625,
          "content": "package logrus\n\nimport (\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRegister(t *testing.T) {\n\tcurrent := len(handlers)\n\n\tvar results []string\n\n\th1 := func() { results = append(results, \"first\") }\n\th2 := func() { results = append(results, \"second\") }\n\n\tRegisterExitHandler(h1)\n\tRegisterExitHandler(h2)\n\n\tif len(handlers) != current+2 {\n\t\tt.Fatalf(\"expected %d handlers, got %d\", current+2, len(handlers))\n\t}\n\n\trunHandlers()\n\n\tif len(results) != 2 {\n\t\tt.Fatalf(\"expected 2 handlers to be run, ran %d\", len(results))\n\t}\n\n\tif results[0] != \"first\" {\n\t\tt.Fatal(\"expected handler h1 to be run first, but it wasn't\")\n\t}\n\n\tif results[1] != \"second\" {\n\t\tt.Fatal(\"expected handler h2 to be run second, but it wasn't\")\n\t}\n}\n\nfunc TestDefer(t *testing.T) {\n\tcurrent := len(handlers)\n\n\tvar results []string\n\n\th1 := func() { results = append(results, \"first\") }\n\th2 := func() { results = append(results, \"second\") }\n\n\tDeferExitHandler(h1)\n\tDeferExitHandler(h2)\n\n\tif len(handlers) != current+2 {\n\t\tt.Fatalf(\"expected %d handlers, got %d\", current+2, len(handlers))\n\t}\n\n\trunHandlers()\n\n\tif len(results) != 2 {\n\t\tt.Fatalf(\"expected 2 handlers to be run, ran %d\", len(results))\n\t}\n\n\tif results[0] != \"second\" {\n\t\tt.Fatal(\"expected handler h2 to be run first, but it wasn't\")\n\t}\n\n\tif results[1] != \"first\" {\n\t\tt.Fatal(\"expected handler h1 to be run second, but it wasn't\")\n\t}\n}\n\nfunc TestHandler(t *testing.T) {\n\ttestprog := testprogleader\n\ttestprog = append(testprog, getPackage()...)\n\ttestprog = append(testprog, testprogtrailer...)\n\ttempDir, err := ioutil.TempDir(\"\", \"test_handler\")\n\tif err != nil {\n\t\tlog.Fatalf(\"can't create temp dir. %q\", err)\n\t}\n\tdefer os.RemoveAll(tempDir)\n\n\tgofile := filepath.Join(tempDir, \"gofile.go\")\n\tif err := ioutil.WriteFile(gofile, testprog, 0666); err != nil {\n\t\tt.Fatalf(\"can't create go file. %q\", err)\n\t}\n\n\toutfile := filepath.Join(tempDir, \"outfile.out\")\n\targ := time.Now().UTC().String()\n\terr = exec.Command(\"go\", \"run\", gofile, outfile, arg).Run()\n\tif err == nil {\n\t\tt.Fatalf(\"completed normally, should have failed\")\n\t}\n\n\tdata, err := ioutil.ReadFile(outfile)\n\tif err != nil {\n\t\tt.Fatalf(\"can't read output file %s. %q\", outfile, err)\n\t}\n\n\tif string(data) != arg {\n\t\tt.Fatalf(\"bad data. Expected %q, got %q\", data, arg)\n\t}\n}\n\n// getPackage returns the name of the current package, which makes running this\n// test in a fork simpler\nfunc getPackage() []byte {\n\tpc, _, _, _ := runtime.Caller(0)\n\tfullFuncName := runtime.FuncForPC(pc).Name()\n\tidx := strings.LastIndex(fullFuncName, \".\")\n\treturn []byte(fullFuncName[:idx]) // trim off function details\n}\n\nvar testprogleader = []byte(`\n// Test program for atexit, gets output file and data as arguments and writes\n// data to output file in atexit handler.\npackage main\n\nimport (\n\t\"`)\nvar testprogtrailer = []byte(\n\t`\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n)\n\nvar outfile = \"\"\nvar data = \"\"\n\nfunc handler() {\n\tioutil.WriteFile(outfile, []byte(data), 0666)\n}\n\nfunc badHandler() {\n\tn := 0\n\tfmt.Println(1/n)\n}\n\nfunc main() {\n\tflag.Parse()\n\toutfile = flag.Arg(0)\n\tdata = flag.Arg(1)\n\n\tlogrus.RegisterExitHandler(handler)\n\tlogrus.RegisterExitHandler(badHandler)\n\tlogrus.Fatal(\"Bye bye\")\n}\n`)\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 0.2529296875,
          "content": "version: \"{build}\"\nplatform: x64\nclone_folder: c:\\gopath\\src\\github.com\\sirupsen\\logrus\nenvironment:\n  GOPATH: c:\\gopath\nbranches:\n  only:\n    - master\ninstall:\n  - set PATH=%GOPATH%\\bin;c:\\go\\bin;%PATH%\n  - go version\nbuild_script:\n  - go get -t\n  - go test\n"
        },
        {
          "name": "buffer_pool.go",
          "type": "blob",
          "size": 0.6474609375,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"sync\"\n)\n\nvar (\n\tbufferPool BufferPool\n)\n\ntype BufferPool interface {\n\tPut(*bytes.Buffer)\n\tGet() *bytes.Buffer\n}\n\ntype defaultPool struct {\n\tpool *sync.Pool\n}\n\nfunc (p *defaultPool) Put(buf *bytes.Buffer) {\n\tp.pool.Put(buf)\n}\n\nfunc (p *defaultPool) Get() *bytes.Buffer {\n\treturn p.pool.Get().(*bytes.Buffer)\n}\n\n// SetBufferPool allows to replace the default logrus buffer pool\n// to better meets the specific needs of an application.\nfunc SetBufferPool(bp BufferPool) {\n\tbufferPool = bp\n}\n\nfunc init() {\n\tSetBufferPool(&defaultPool{\n\t\tpool: &sync.Pool{\n\t\t\tNew: func() interface{} {\n\t\t\t\treturn new(bytes.Buffer)\n\t\t\t},\n\t\t},\n\t})\n}\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.572265625,
          "content": "/*\nPackage logrus is a structured logger for Go, completely API compatible with the standard library logger.\n\n\nThe simplest way to use Logrus is simply the package-level exported logger:\n\n  package main\n\n  import (\n    log \"github.com/sirupsen/logrus\"\n  )\n\n  func main() {\n    log.WithFields(log.Fields{\n      \"animal\": \"walrus\",\n      \"number\": 1,\n      \"size\":   10,\n    }).Info(\"A walrus appears\")\n  }\n\nOutput:\n  time=\"2015-09-07T08:48:33Z\" level=info msg=\"A walrus appears\" animal=walrus number=1 size=10\n\nFor a full guide visit https://github.com/sirupsen/logrus\n*/\npackage logrus\n"
        },
        {
          "name": "entry.go",
          "type": "blob",
          "size": 10.8642578125,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\n\t// qualified package name, cached at first use\n\tlogrusPackage string\n\n\t// Positions in the call stack when tracing to report the calling method\n\tminimumCallerDepth int\n\n\t// Used for caller information initialisation\n\tcallerInitOnce sync.Once\n)\n\nconst (\n\tmaximumCallerDepth int = 25\n\tknownLogrusFrames  int = 4\n)\n\nfunc init() {\n\t// start at the bottom of the stack before the package-name cache is primed\n\tminimumCallerDepth = 1\n}\n\n// Defines the key when adding errors using WithError.\nvar ErrorKey = \"error\"\n\n// An entry is the final or intermediate Logrus logging entry. It contains all\n// the fields passed with WithField{,s}. It's finally logged when Trace, Debug,\n// Info, Warn, Error, Fatal or Panic is called on it. These objects can be\n// reused and passed around as much as you wish to avoid field duplication.\ntype Entry struct {\n\tLogger *Logger\n\n\t// Contains all the fields set by the user.\n\tData Fields\n\n\t// Time at which the log entry was created\n\tTime time.Time\n\n\t// Level the log entry was logged at: Trace, Debug, Info, Warn, Error, Fatal or Panic\n\t// This field will be set on entry firing and the value will be equal to the one in Logger struct field.\n\tLevel Level\n\n\t// Calling method, with package name\n\tCaller *runtime.Frame\n\n\t// Message passed to Trace, Debug, Info, Warn, Error, Fatal or Panic\n\tMessage string\n\n\t// When formatter is called in entry.log(), a Buffer may be set to entry\n\tBuffer *bytes.Buffer\n\n\t// Contains the context set by the user. Useful for hook processing etc.\n\tContext context.Context\n\n\t// err may contain a field formatting error\n\terr string\n}\n\nfunc NewEntry(logger *Logger) *Entry {\n\treturn &Entry{\n\t\tLogger: logger,\n\t\t// Default is three fields, plus one optional.  Give a little extra room.\n\t\tData: make(Fields, 6),\n\t}\n}\n\nfunc (entry *Entry) Dup() *Entry {\n\tdata := make(Fields, len(entry.Data))\n\tfor k, v := range entry.Data {\n\t\tdata[k] = v\n\t}\n\treturn &Entry{Logger: entry.Logger, Data: data, Time: entry.Time, Context: entry.Context, err: entry.err}\n}\n\n// Returns the bytes representation of this entry from the formatter.\nfunc (entry *Entry) Bytes() ([]byte, error) {\n\treturn entry.Logger.Formatter.Format(entry)\n}\n\n// Returns the string representation from the reader and ultimately the\n// formatter.\nfunc (entry *Entry) String() (string, error) {\n\tserialized, err := entry.Bytes()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tstr := string(serialized)\n\treturn str, nil\n}\n\n// Add an error as single field (using the key defined in ErrorKey) to the Entry.\nfunc (entry *Entry) WithError(err error) *Entry {\n\treturn entry.WithField(ErrorKey, err)\n}\n\n// Add a context to the Entry.\nfunc (entry *Entry) WithContext(ctx context.Context) *Entry {\n\tdataCopy := make(Fields, len(entry.Data))\n\tfor k, v := range entry.Data {\n\t\tdataCopy[k] = v\n\t}\n\treturn &Entry{Logger: entry.Logger, Data: dataCopy, Time: entry.Time, err: entry.err, Context: ctx}\n}\n\n// Add a single field to the Entry.\nfunc (entry *Entry) WithField(key string, value interface{}) *Entry {\n\treturn entry.WithFields(Fields{key: value})\n}\n\n// Add a map of fields to the Entry.\nfunc (entry *Entry) WithFields(fields Fields) *Entry {\n\tdata := make(Fields, len(entry.Data)+len(fields))\n\tfor k, v := range entry.Data {\n\t\tdata[k] = v\n\t}\n\tfieldErr := entry.err\n\tfor k, v := range fields {\n\t\tisErrField := false\n\t\tif t := reflect.TypeOf(v); t != nil {\n\t\t\tswitch {\n\t\t\tcase t.Kind() == reflect.Func, t.Kind() == reflect.Ptr && t.Elem().Kind() == reflect.Func:\n\t\t\t\tisErrField = true\n\t\t\t}\n\t\t}\n\t\tif isErrField {\n\t\t\ttmp := fmt.Sprintf(\"can not add field %q\", k)\n\t\t\tif fieldErr != \"\" {\n\t\t\t\tfieldErr = entry.err + \", \" + tmp\n\t\t\t} else {\n\t\t\t\tfieldErr = tmp\n\t\t\t}\n\t\t} else {\n\t\t\tdata[k] = v\n\t\t}\n\t}\n\treturn &Entry{Logger: entry.Logger, Data: data, Time: entry.Time, err: fieldErr, Context: entry.Context}\n}\n\n// Overrides the time of the Entry.\nfunc (entry *Entry) WithTime(t time.Time) *Entry {\n\tdataCopy := make(Fields, len(entry.Data))\n\tfor k, v := range entry.Data {\n\t\tdataCopy[k] = v\n\t}\n\treturn &Entry{Logger: entry.Logger, Data: dataCopy, Time: t, err: entry.err, Context: entry.Context}\n}\n\n// getPackageName reduces a fully qualified function name to the package name\n// There really ought to be to be a better way...\nfunc getPackageName(f string) string {\n\tfor {\n\t\tlastPeriod := strings.LastIndex(f, \".\")\n\t\tlastSlash := strings.LastIndex(f, \"/\")\n\t\tif lastPeriod > lastSlash {\n\t\t\tf = f[:lastPeriod]\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn f\n}\n\n// getCaller retrieves the name of the first non-logrus calling function\nfunc getCaller() *runtime.Frame {\n\t// cache this package's fully-qualified name\n\tcallerInitOnce.Do(func() {\n\t\tpcs := make([]uintptr, maximumCallerDepth)\n\t\t_ = runtime.Callers(0, pcs)\n\n\t\t// dynamic get the package name and the minimum caller depth\n\t\tfor i := 0; i < maximumCallerDepth; i++ {\n\t\t\tfuncName := runtime.FuncForPC(pcs[i]).Name()\n\t\t\tif strings.Contains(funcName, \"getCaller\") {\n\t\t\t\tlogrusPackage = getPackageName(funcName)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tminimumCallerDepth = knownLogrusFrames\n\t})\n\n\t// Restrict the lookback frames to avoid runaway lookups\n\tpcs := make([]uintptr, maximumCallerDepth)\n\tdepth := runtime.Callers(minimumCallerDepth, pcs)\n\tframes := runtime.CallersFrames(pcs[:depth])\n\n\tfor f, again := frames.Next(); again; f, again = frames.Next() {\n\t\tpkg := getPackageName(f.Function)\n\n\t\t// If the caller isn't part of this package, we're done\n\t\tif pkg != logrusPackage {\n\t\t\treturn &f //nolint:scopelint\n\t\t}\n\t}\n\n\t// if we got here, we failed to find the caller's context\n\treturn nil\n}\n\nfunc (entry Entry) HasCaller() (has bool) {\n\treturn entry.Logger != nil &&\n\t\tentry.Logger.ReportCaller &&\n\t\tentry.Caller != nil\n}\n\nfunc (entry *Entry) log(level Level, msg string) {\n\tvar buffer *bytes.Buffer\n\n\tnewEntry := entry.Dup()\n\n\tif newEntry.Time.IsZero() {\n\t\tnewEntry.Time = time.Now()\n\t}\n\n\tnewEntry.Level = level\n\tnewEntry.Message = msg\n\n\tnewEntry.Logger.mu.Lock()\n\treportCaller := newEntry.Logger.ReportCaller\n\tbufPool := newEntry.getBufferPool()\n\tnewEntry.Logger.mu.Unlock()\n\n\tif reportCaller {\n\t\tnewEntry.Caller = getCaller()\n\t}\n\n\tnewEntry.fireHooks()\n\tbuffer = bufPool.Get()\n\tdefer func() {\n\t\tnewEntry.Buffer = nil\n\t\tbuffer.Reset()\n\t\tbufPool.Put(buffer)\n\t}()\n\tbuffer.Reset()\n\tnewEntry.Buffer = buffer\n\n\tnewEntry.write()\n\n\tnewEntry.Buffer = nil\n\n\t// To avoid Entry#log() returning a value that only would make sense for\n\t// panic() to use in Entry#Panic(), we avoid the allocation by checking\n\t// directly here.\n\tif level <= PanicLevel {\n\t\tpanic(newEntry)\n\t}\n}\n\nfunc (entry *Entry) getBufferPool() (pool BufferPool) {\n\tif entry.Logger.BufferPool != nil {\n\t\treturn entry.Logger.BufferPool\n\t}\n\treturn bufferPool\n}\n\nfunc (entry *Entry) fireHooks() {\n\tvar tmpHooks LevelHooks\n\tentry.Logger.mu.Lock()\n\ttmpHooks = make(LevelHooks, len(entry.Logger.Hooks))\n\tfor k, v := range entry.Logger.Hooks {\n\t\ttmpHooks[k] = v\n\t}\n\tentry.Logger.mu.Unlock()\n\n\terr := tmpHooks.Fire(entry.Level, entry)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to fire hook: %v\\n\", err)\n\t}\n}\n\nfunc (entry *Entry) write() {\n\tentry.Logger.mu.Lock()\n\tdefer entry.Logger.mu.Unlock()\n\tserialized, err := entry.Logger.Formatter.Format(entry)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to obtain reader, %v\\n\", err)\n\t\treturn\n\t}\n\tif _, err := entry.Logger.Out.Write(serialized); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to write to log, %v\\n\", err)\n\t}\n}\n\n// Log will log a message at the level given as parameter.\n// Warning: using Log at Panic or Fatal level will not respectively Panic nor Exit.\n// For this behaviour Entry.Panic or Entry.Fatal should be used instead.\nfunc (entry *Entry) Log(level Level, args ...interface{}) {\n\tif entry.Logger.IsLevelEnabled(level) {\n\t\tentry.log(level, fmt.Sprint(args...))\n\t}\n}\n\nfunc (entry *Entry) Trace(args ...interface{}) {\n\tentry.Log(TraceLevel, args...)\n}\n\nfunc (entry *Entry) Debug(args ...interface{}) {\n\tentry.Log(DebugLevel, args...)\n}\n\nfunc (entry *Entry) Print(args ...interface{}) {\n\tentry.Info(args...)\n}\n\nfunc (entry *Entry) Info(args ...interface{}) {\n\tentry.Log(InfoLevel, args...)\n}\n\nfunc (entry *Entry) Warn(args ...interface{}) {\n\tentry.Log(WarnLevel, args...)\n}\n\nfunc (entry *Entry) Warning(args ...interface{}) {\n\tentry.Warn(args...)\n}\n\nfunc (entry *Entry) Error(args ...interface{}) {\n\tentry.Log(ErrorLevel, args...)\n}\n\nfunc (entry *Entry) Fatal(args ...interface{}) {\n\tentry.Log(FatalLevel, args...)\n\tentry.Logger.Exit(1)\n}\n\nfunc (entry *Entry) Panic(args ...interface{}) {\n\tentry.Log(PanicLevel, args...)\n}\n\n// Entry Printf family functions\n\nfunc (entry *Entry) Logf(level Level, format string, args ...interface{}) {\n\tif entry.Logger.IsLevelEnabled(level) {\n\t\tentry.Log(level, fmt.Sprintf(format, args...))\n\t}\n}\n\nfunc (entry *Entry) Tracef(format string, args ...interface{}) {\n\tentry.Logf(TraceLevel, format, args...)\n}\n\nfunc (entry *Entry) Debugf(format string, args ...interface{}) {\n\tentry.Logf(DebugLevel, format, args...)\n}\n\nfunc (entry *Entry) Infof(format string, args ...interface{}) {\n\tentry.Logf(InfoLevel, format, args...)\n}\n\nfunc (entry *Entry) Printf(format string, args ...interface{}) {\n\tentry.Infof(format, args...)\n}\n\nfunc (entry *Entry) Warnf(format string, args ...interface{}) {\n\tentry.Logf(WarnLevel, format, args...)\n}\n\nfunc (entry *Entry) Warningf(format string, args ...interface{}) {\n\tentry.Warnf(format, args...)\n}\n\nfunc (entry *Entry) Errorf(format string, args ...interface{}) {\n\tentry.Logf(ErrorLevel, format, args...)\n}\n\nfunc (entry *Entry) Fatalf(format string, args ...interface{}) {\n\tentry.Logf(FatalLevel, format, args...)\n\tentry.Logger.Exit(1)\n}\n\nfunc (entry *Entry) Panicf(format string, args ...interface{}) {\n\tentry.Logf(PanicLevel, format, args...)\n}\n\n// Entry Println family functions\n\nfunc (entry *Entry) Logln(level Level, args ...interface{}) {\n\tif entry.Logger.IsLevelEnabled(level) {\n\t\tentry.Log(level, entry.sprintlnn(args...))\n\t}\n}\n\nfunc (entry *Entry) Traceln(args ...interface{}) {\n\tentry.Logln(TraceLevel, args...)\n}\n\nfunc (entry *Entry) Debugln(args ...interface{}) {\n\tentry.Logln(DebugLevel, args...)\n}\n\nfunc (entry *Entry) Infoln(args ...interface{}) {\n\tentry.Logln(InfoLevel, args...)\n}\n\nfunc (entry *Entry) Println(args ...interface{}) {\n\tentry.Infoln(args...)\n}\n\nfunc (entry *Entry) Warnln(args ...interface{}) {\n\tentry.Logln(WarnLevel, args...)\n}\n\nfunc (entry *Entry) Warningln(args ...interface{}) {\n\tentry.Warnln(args...)\n}\n\nfunc (entry *Entry) Errorln(args ...interface{}) {\n\tentry.Logln(ErrorLevel, args...)\n}\n\nfunc (entry *Entry) Fatalln(args ...interface{}) {\n\tentry.Logln(FatalLevel, args...)\n\tentry.Logger.Exit(1)\n}\n\nfunc (entry *Entry) Panicln(args ...interface{}) {\n\tentry.Logln(PanicLevel, args...)\n}\n\n// Sprintlnn => Sprint no newline. This is to get the behavior of how\n// fmt.Sprintln where spaces are always added between operands, regardless of\n// their type. Instead of vendoring the Sprintln implementation to spare a\n// string allocation, we do the simplest thing.\nfunc (entry *Entry) sprintlnn(args ...interface{}) string {\n\tmsg := fmt.Sprintln(args...)\n\treturn msg[:len(msg)-1]\n}\n"
        },
        {
          "name": "entry_test.go",
          "type": "blob",
          "size": 7.607421875,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\ntype contextKeyType string\n\nfunc TestEntryWithError(t *testing.T) {\n\n\tassert := assert.New(t)\n\n\tdefer func() {\n\t\tErrorKey = \"error\"\n\t}()\n\n\terr := fmt.Errorf(\"kaboom at layer %d\", 4711)\n\n\tassert.Equal(err, WithError(err).Data[\"error\"])\n\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tentry := NewEntry(logger)\n\n\tassert.Equal(err, entry.WithError(err).Data[\"error\"])\n\n\tErrorKey = \"err\"\n\n\tassert.Equal(err, entry.WithError(err).Data[\"err\"])\n\n}\n\nfunc TestEntryWithContext(t *testing.T) {\n\tassert := assert.New(t)\n\tvar contextKey contextKeyType = \"foo\"\n\tctx := context.WithValue(context.Background(), contextKey, \"bar\")\n\n\tassert.Equal(ctx, WithContext(ctx).Context)\n\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tentry := NewEntry(logger)\n\n\tassert.Equal(ctx, entry.WithContext(ctx).Context)\n}\n\nfunc TestEntryWithContextCopiesData(t *testing.T) {\n\tassert := assert.New(t)\n\n\t// Initialize a parent Entry object with a key/value set in its Data map\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tparentEntry := NewEntry(logger).WithField(\"parentKey\", \"parentValue\")\n\n\t// Create two children Entry objects from the parent in different contexts\n\tvar contextKey1 contextKeyType = \"foo\"\n\tctx1 := context.WithValue(context.Background(), contextKey1, \"bar\")\n\tchildEntry1 := parentEntry.WithContext(ctx1)\n\tassert.Equal(ctx1, childEntry1.Context)\n\n\tvar contextKey2 contextKeyType = \"bar\"\n\tctx2 := context.WithValue(context.Background(), contextKey2, \"baz\")\n\tchildEntry2 := parentEntry.WithContext(ctx2)\n\tassert.Equal(ctx2, childEntry2.Context)\n\tassert.NotEqual(ctx1, ctx2)\n\n\t// Ensure that data set in the parent Entry are preserved to both children\n\tassert.Equal(\"parentValue\", childEntry1.Data[\"parentKey\"])\n\tassert.Equal(\"parentValue\", childEntry2.Data[\"parentKey\"])\n\n\t// Modify data stored in the child entry\n\tchildEntry1.Data[\"childKey\"] = \"childValue\"\n\n\t// Verify that data is successfully stored in the child it was set on\n\tval, exists := childEntry1.Data[\"childKey\"]\n\tassert.True(exists)\n\tassert.Equal(\"childValue\", val)\n\n\t// Verify that the data change to child 1 has not affected its sibling\n\tval, exists = childEntry2.Data[\"childKey\"]\n\tassert.False(exists)\n\tassert.Empty(val)\n\n\t// Verify that the data change to child 1 has not affected its parent\n\tval, exists = parentEntry.Data[\"childKey\"]\n\tassert.False(exists)\n\tassert.Empty(val)\n}\n\nfunc TestEntryWithTimeCopiesData(t *testing.T) {\n\tassert := assert.New(t)\n\n\t// Initialize a parent Entry object with a key/value set in its Data map\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tparentEntry := NewEntry(logger).WithField(\"parentKey\", \"parentValue\")\n\n\t// Create two children Entry objects from the parent with two different times\n\tchildEntry1 := parentEntry.WithTime(time.Now().AddDate(0, 0, 1))\n\tchildEntry2 := parentEntry.WithTime(time.Now().AddDate(0, 0, 2))\n\n\t// Ensure that data set in the parent Entry are preserved to both children\n\tassert.Equal(\"parentValue\", childEntry1.Data[\"parentKey\"])\n\tassert.Equal(\"parentValue\", childEntry2.Data[\"parentKey\"])\n\n\t// Modify data stored in the child entry\n\tchildEntry1.Data[\"childKey\"] = \"childValue\"\n\n\t// Verify that data is successfully stored in the child it was set on\n\tval, exists := childEntry1.Data[\"childKey\"]\n\tassert.True(exists)\n\tassert.Equal(\"childValue\", val)\n\n\t// Verify that the data change to child 1 has not affected its sibling\n\tval, exists = childEntry2.Data[\"childKey\"]\n\tassert.False(exists)\n\tassert.Empty(val)\n\n\t// Verify that the data change to child 1 has not affected its parent\n\tval, exists = parentEntry.Data[\"childKey\"]\n\tassert.False(exists)\n\tassert.Empty(val)\n}\n\nfunc TestEntryPanicln(t *testing.T) {\n\terrBoom := fmt.Errorf(\"boom time\")\n\n\tdefer func() {\n\t\tp := recover()\n\t\tassert.NotNil(t, p)\n\n\t\tswitch pVal := p.(type) {\n\t\tcase *Entry:\n\t\t\tassert.Equal(t, \"kaboom\", pVal.Message)\n\t\t\tassert.Equal(t, errBoom, pVal.Data[\"err\"])\n\t\tdefault:\n\t\t\tt.Fatalf(\"want type *Entry, got %T: %#v\", pVal, pVal)\n\t\t}\n\t}()\n\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tentry := NewEntry(logger)\n\tentry.WithField(\"err\", errBoom).Panicln(\"kaboom\")\n}\n\nfunc TestEntryPanicf(t *testing.T) {\n\terrBoom := fmt.Errorf(\"boom again\")\n\n\tdefer func() {\n\t\tp := recover()\n\t\tassert.NotNil(t, p)\n\n\t\tswitch pVal := p.(type) {\n\t\tcase *Entry:\n\t\t\tassert.Equal(t, \"kaboom true\", pVal.Message)\n\t\t\tassert.Equal(t, errBoom, pVal.Data[\"err\"])\n\t\tdefault:\n\t\t\tt.Fatalf(\"want type *Entry, got %T: %#v\", pVal, pVal)\n\t\t}\n\t}()\n\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tentry := NewEntry(logger)\n\tentry.WithField(\"err\", errBoom).Panicf(\"kaboom %v\", true)\n}\n\nfunc TestEntryPanic(t *testing.T) {\n\terrBoom := fmt.Errorf(\"boom again\")\n\n\tdefer func() {\n\t\tp := recover()\n\t\tassert.NotNil(t, p)\n\n\t\tswitch pVal := p.(type) {\n\t\tcase *Entry:\n\t\t\tassert.Equal(t, \"kaboom\", pVal.Message)\n\t\t\tassert.Equal(t, errBoom, pVal.Data[\"err\"])\n\t\tdefault:\n\t\t\tt.Fatalf(\"want type *Entry, got %T: %#v\", pVal, pVal)\n\t\t}\n\t}()\n\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tentry := NewEntry(logger)\n\tentry.WithField(\"err\", errBoom).Panic(\"kaboom\")\n}\n\nconst (\n\tbadMessage   = \"this is going to panic\"\n\tpanicMessage = \"this is broken\"\n)\n\ntype panickyHook struct{}\n\nfunc (p *panickyHook) Levels() []Level {\n\treturn []Level{InfoLevel}\n}\n\nfunc (p *panickyHook) Fire(entry *Entry) error {\n\tif entry.Message == badMessage {\n\t\tpanic(panicMessage)\n\t}\n\n\treturn nil\n}\n\nfunc TestEntryHooksPanic(t *testing.T) {\n\tlogger := New()\n\tlogger.Out = &bytes.Buffer{}\n\tlogger.Level = InfoLevel\n\tlogger.Hooks.Add(&panickyHook{})\n\n\tdefer func() {\n\t\tp := recover()\n\t\tassert.NotNil(t, p)\n\t\tassert.Equal(t, panicMessage, p)\n\n\t\tentry := NewEntry(logger)\n\t\tentry.Info(\"another message\")\n\t}()\n\n\tentry := NewEntry(logger)\n\tentry.Info(badMessage)\n}\n\nfunc TestEntryWithIncorrectField(t *testing.T) {\n\tassert := assert.New(t)\n\n\tfn := func() {}\n\n\te := Entry{Logger: New()}\n\teWithFunc := e.WithFields(Fields{\"func\": fn})\n\teWithFuncPtr := e.WithFields(Fields{\"funcPtr\": &fn})\n\n\tassert.Equal(eWithFunc.err, `can not add field \"func\"`)\n\tassert.Equal(eWithFuncPtr.err, `can not add field \"funcPtr\"`)\n\n\teWithFunc = eWithFunc.WithField(\"not_a_func\", \"it is a string\")\n\teWithFuncPtr = eWithFuncPtr.WithField(\"not_a_func\", \"it is a string\")\n\n\tassert.Equal(eWithFunc.err, `can not add field \"func\"`)\n\tassert.Equal(eWithFuncPtr.err, `can not add field \"funcPtr\"`)\n\n\teWithFunc = eWithFunc.WithTime(time.Now())\n\teWithFuncPtr = eWithFuncPtr.WithTime(time.Now())\n\n\tassert.Equal(eWithFunc.err, `can not add field \"func\"`)\n\tassert.Equal(eWithFuncPtr.err, `can not add field \"funcPtr\"`)\n}\n\nfunc TestEntryLogfLevel(t *testing.T) {\n\tlogger := New()\n\tbuffer := &bytes.Buffer{}\n\tlogger.Out = buffer\n\tlogger.SetLevel(InfoLevel)\n\tentry := NewEntry(logger)\n\n\tentry.Logf(DebugLevel, \"%s\", \"debug\")\n\tassert.NotContains(t, buffer.String(), \"debug\")\n\n\tentry.Logf(WarnLevel, \"%s\", \"warn\")\n\tassert.Contains(t, buffer.String(), \"warn\")\n}\n\nfunc TestEntryReportCallerRace(t *testing.T) {\n\tlogger := New()\n\tentry := NewEntry(logger)\n\n\t// logging before SetReportCaller has the highest chance of causing a race condition\n\t// to be detected, but doing it twice just to increase the likelyhood of detecting the race\n\tgo func() {\n\t\tentry.Info(\"should not race\")\n\t}()\n\tgo func() {\n\t\tlogger.SetReportCaller(true)\n\t}()\n\tgo func() {\n\t\tentry.Info(\"should not race\")\n\t}()\n}\n\nfunc TestEntryFormatterRace(t *testing.T) {\n\tlogger := New()\n\tentry := NewEntry(logger)\n\n\t// logging before SetReportCaller has the highest chance of causing a race condition\n\t// to be detected, but doing it twice just to increase the likelyhood of detecting the race\n\tgo func() {\n\t\tentry.Info(\"should not race\")\n\t}()\n\tgo func() {\n\t\tlogger.SetFormatter(&TextFormatter{})\n\t}()\n\tgo func() {\n\t\tentry.Info(\"should not race\")\n\t}()\n}\n"
        },
        {
          "name": "example_basic_test.go",
          "type": "blob",
          "size": 2.232421875,
          "content": "package logrus_test\n\nimport (\n\t\"os\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc Example_basic() {\n\tvar log = logrus.New()\n\tlog.Formatter = new(logrus.JSONFormatter)\n\tlog.Formatter = new(logrus.TextFormatter)                     //default\n\tlog.Formatter.(*logrus.TextFormatter).DisableColors = true    // remove colors\n\tlog.Formatter.(*logrus.TextFormatter).DisableTimestamp = true // remove timestamp from test output\n\tlog.Level = logrus.TraceLevel\n\tlog.Out = os.Stdout\n\n\t// file, err := os.OpenFile(\"logrus.log\", os.O_CREATE|os.O_WRONLY, 0666)\n\t// if err == nil {\n\t// \tlog.Out = file\n\t// } else {\n\t// \tlog.Info(\"Failed to log to file, using default stderr\")\n\t// }\n\n\tdefer func() {\n\t\terr := recover()\n\t\tif err != nil {\n\t\t\tentry := err.(*logrus.Entry)\n\t\t\tlog.WithFields(logrus.Fields{\n\t\t\t\t\"omg\":         true,\n\t\t\t\t\"err_animal\":  entry.Data[\"animal\"],\n\t\t\t\t\"err_size\":    entry.Data[\"size\"],\n\t\t\t\t\"err_level\":   entry.Level,\n\t\t\t\t\"err_message\": entry.Message,\n\t\t\t\t\"number\":      100,\n\t\t\t}).Error(\"The ice breaks!\") // or use Fatal() to force the process to exit with a nonzero code\n\t\t}\n\t}()\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"animal\": \"walrus\",\n\t\t\"number\": 0,\n\t}).Trace(\"Went to the beach\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"animal\": \"walrus\",\n\t\t\"number\": 8,\n\t}).Debug(\"Started observing beach\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"animal\": \"walrus\",\n\t\t\"size\":   10,\n\t}).Info(\"A group of walrus emerges from the ocean\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"omg\":    true,\n\t\t\"number\": 122,\n\t}).Warn(\"The group's number increased tremendously!\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"temperature\": -4,\n\t}).Debug(\"Temperature changes\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"animal\": \"orca\",\n\t\t\"size\":   9009,\n\t}).Panic(\"It's over 9000!\")\n\n\t// Output:\n\t// level=trace msg=\"Went to the beach\" animal=walrus number=0\n\t// level=debug msg=\"Started observing beach\" animal=walrus number=8\n\t// level=info msg=\"A group of walrus emerges from the ocean\" animal=walrus size=10\n\t// level=warning msg=\"The group's number increased tremendously!\" number=122 omg=true\n\t// level=debug msg=\"Temperature changes\" temperature=-4\n\t// level=panic msg=\"It's over 9000!\" animal=orca size=9009\n\t// level=error msg=\"The ice breaks!\" err_animal=orca err_level=panic err_message=\"It's over 9000!\" err_size=9009 number=100 omg=true\n}\n"
        },
        {
          "name": "example_custom_caller_test.go",
          "type": "blob",
          "size": 0.6640625,
          "content": "package logrus_test\n\nimport (\n\t\"os\"\n\t\"path\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc ExampleJSONFormatter_CallerPrettyfier() {\n\tl := logrus.New()\n\tl.SetReportCaller(true)\n\tl.Out = os.Stdout\n\tl.Formatter = &logrus.JSONFormatter{\n\t\tDisableTimestamp: true,\n\t\tCallerPrettyfier: func(f *runtime.Frame) (string, string) {\n\t\t\ts := strings.Split(f.Function, \".\")\n\t\t\tfuncname := s[len(s)-1]\n\t\t\t_, filename := path.Split(f.File)\n\t\t\treturn funcname, filename\n\t\t},\n\t}\n\tl.Info(\"example of custom format caller\")\n\t// Output:\n\t// {\"file\":\"example_custom_caller_test.go\",\"func\":\"ExampleJSONFormatter_CallerPrettyfier\",\"level\":\"info\",\"msg\":\"example of custom format caller\"}\n}\n"
        },
        {
          "name": "example_default_field_value_test.go",
          "type": "blob",
          "size": 0.6552734375,
          "content": "package logrus_test\n\nimport (\n\t\"os\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\ntype DefaultFieldHook struct {\n\tGetValue func() string\n}\n\nfunc (h *DefaultFieldHook) Levels() []logrus.Level {\n\treturn logrus.AllLevels\n}\n\nfunc (h *DefaultFieldHook) Fire(e *logrus.Entry) error {\n\te.Data[\"aDefaultField\"] = h.GetValue()\n\treturn nil\n}\n\nfunc ExampleDefaultFieldHook() {\n\tl := logrus.New()\n\tl.Out = os.Stdout\n\tl.Formatter = &logrus.TextFormatter{DisableTimestamp: true, DisableColors: true}\n\n\tl.AddHook(&DefaultFieldHook{GetValue: func() string { return \"with its default value\" }})\n\tl.Info(\"first log\")\n\t// Output:\n\t// level=info msg=\"first log\" aDefaultField=\"with its default value\"\n}\n"
        },
        {
          "name": "example_function_test.go",
          "type": "blob",
          "size": 0.48828125,
          "content": "package logrus_test\n\nimport (\n\t\"testing\"\n\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestLogger_LogFn(t *testing.T) {\n\tlog.SetFormatter(&log.JSONFormatter{})\n\tlog.SetLevel(log.WarnLevel)\n\n\tnotCalled := 0\n\tlog.InfoFn(func() []interface{} {\n\t\tnotCalled++\n\t\treturn []interface{}{\n\t\t\t\"Hello\",\n\t\t}\n\t})\n\tassert.Equal(t, 0, notCalled)\n\n\tcalled := 0\n\tlog.ErrorFn(func() []interface{} {\n\t\tcalled++\n\t\treturn []interface{}{\n\t\t\t\"Oopsi\",\n\t\t}\n\t})\n\tassert.Equal(t, 1, called)\n}\n"
        },
        {
          "name": "example_global_hook_test.go",
          "type": "blob",
          "size": 0.6748046875,
          "content": "package logrus_test\n\nimport (\n\t\"os\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\nvar (\n\tmystring string\n)\n\ntype GlobalHook struct {\n}\n\nfunc (h *GlobalHook) Levels() []logrus.Level {\n\treturn logrus.AllLevels\n}\n\nfunc (h *GlobalHook) Fire(e *logrus.Entry) error {\n\te.Data[\"mystring\"] = mystring\n\treturn nil\n}\n\nfunc ExampleGlobalHook() {\n\tl := logrus.New()\n\tl.Out = os.Stdout\n\tl.Formatter = &logrus.TextFormatter{DisableTimestamp: true, DisableColors: true}\n\tl.AddHook(&GlobalHook{})\n\tmystring = \"first value\"\n\tl.Info(\"first log\")\n\tmystring = \"another value\"\n\tl.Info(\"second log\")\n\t// Output:\n\t// level=info msg=\"first log\" mystring=\"first value\"\n\t// level=info msg=\"second log\" mystring=\"another value\"\n}\n"
        },
        {
          "name": "example_hook_test.go",
          "type": "blob",
          "size": 1.1865234375,
          "content": "// +build !windows\n\npackage logrus_test\n\nimport (\n\t\"log/syslog\"\n\t\"os\"\n\n\t\"github.com/sirupsen/logrus\"\n\tslhooks \"github.com/sirupsen/logrus/hooks/syslog\"\n)\n\n// An example on how to use a hook\nfunc Example_hook() {\n\tvar log = logrus.New()\n\tlog.Formatter = new(logrus.TextFormatter)                     // default\n\tlog.Formatter.(*logrus.TextFormatter).DisableColors = true    // remove colors\n\tlog.Formatter.(*logrus.TextFormatter).DisableTimestamp = true // remove timestamp from test output\n\tif sl, err := slhooks.NewSyslogHook(\"udp\", \"localhost:514\", syslog.LOG_INFO, \"\"); err == nil {\n\t\tlog.Hooks.Add(sl)\n\t}\n\tlog.Out = os.Stdout\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"animal\": \"walrus\",\n\t\t\"size\":   10,\n\t}).Info(\"A group of walrus emerges from the ocean\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"omg\":    true,\n\t\t\"number\": 122,\n\t}).Warn(\"The group's number increased tremendously!\")\n\n\tlog.WithFields(logrus.Fields{\n\t\t\"omg\":    true,\n\t\t\"number\": 100,\n\t}).Error(\"The ice breaks!\")\n\n\t// Output:\n\t// level=info msg=\"A group of walrus emerges from the ocean\" animal=walrus size=10\n\t// level=warning msg=\"The group's number increased tremendously!\" number=122 omg=true\n\t// level=error msg=\"The ice breaks!\" number=100 omg=true\n}\n"
        },
        {
          "name": "exported.go",
          "type": "blob",
          "size": 7.0693359375,
          "content": "package logrus\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"time\"\n)\n\nvar (\n\t// std is the name of the standard logger in stdlib `log`\n\tstd = New()\n)\n\nfunc StandardLogger() *Logger {\n\treturn std\n}\n\n// SetOutput sets the standard logger output.\nfunc SetOutput(out io.Writer) {\n\tstd.SetOutput(out)\n}\n\n// SetFormatter sets the standard logger formatter.\nfunc SetFormatter(formatter Formatter) {\n\tstd.SetFormatter(formatter)\n}\n\n// SetReportCaller sets whether the standard logger will include the calling\n// method as a field.\nfunc SetReportCaller(include bool) {\n\tstd.SetReportCaller(include)\n}\n\n// SetLevel sets the standard logger level.\nfunc SetLevel(level Level) {\n\tstd.SetLevel(level)\n}\n\n// GetLevel returns the standard logger level.\nfunc GetLevel() Level {\n\treturn std.GetLevel()\n}\n\n// IsLevelEnabled checks if the log level of the standard logger is greater than the level param\nfunc IsLevelEnabled(level Level) bool {\n\treturn std.IsLevelEnabled(level)\n}\n\n// AddHook adds a hook to the standard logger hooks.\nfunc AddHook(hook Hook) {\n\tstd.AddHook(hook)\n}\n\n// WithError creates an entry from the standard logger and adds an error to it, using the value defined in ErrorKey as key.\nfunc WithError(err error) *Entry {\n\treturn std.WithField(ErrorKey, err)\n}\n\n// WithContext creates an entry from the standard logger and adds a context to it.\nfunc WithContext(ctx context.Context) *Entry {\n\treturn std.WithContext(ctx)\n}\n\n// WithField creates an entry from the standard logger and adds a field to\n// it. If you want multiple fields, use `WithFields`.\n//\n// Note that it doesn't log until you call Debug, Print, Info, Warn, Fatal\n// or Panic on the Entry it returns.\nfunc WithField(key string, value interface{}) *Entry {\n\treturn std.WithField(key, value)\n}\n\n// WithFields creates an entry from the standard logger and adds multiple\n// fields to it. This is simply a helper for `WithField`, invoking it\n// once for each field.\n//\n// Note that it doesn't log until you call Debug, Print, Info, Warn, Fatal\n// or Panic on the Entry it returns.\nfunc WithFields(fields Fields) *Entry {\n\treturn std.WithFields(fields)\n}\n\n// WithTime creates an entry from the standard logger and overrides the time of\n// logs generated with it.\n//\n// Note that it doesn't log until you call Debug, Print, Info, Warn, Fatal\n// or Panic on the Entry it returns.\nfunc WithTime(t time.Time) *Entry {\n\treturn std.WithTime(t)\n}\n\n// Trace logs a message at level Trace on the standard logger.\nfunc Trace(args ...interface{}) {\n\tstd.Trace(args...)\n}\n\n// Debug logs a message at level Debug on the standard logger.\nfunc Debug(args ...interface{}) {\n\tstd.Debug(args...)\n}\n\n// Print logs a message at level Info on the standard logger.\nfunc Print(args ...interface{}) {\n\tstd.Print(args...)\n}\n\n// Info logs a message at level Info on the standard logger.\nfunc Info(args ...interface{}) {\n\tstd.Info(args...)\n}\n\n// Warn logs a message at level Warn on the standard logger.\nfunc Warn(args ...interface{}) {\n\tstd.Warn(args...)\n}\n\n// Warning logs a message at level Warn on the standard logger.\nfunc Warning(args ...interface{}) {\n\tstd.Warning(args...)\n}\n\n// Error logs a message at level Error on the standard logger.\nfunc Error(args ...interface{}) {\n\tstd.Error(args...)\n}\n\n// Panic logs a message at level Panic on the standard logger.\nfunc Panic(args ...interface{}) {\n\tstd.Panic(args...)\n}\n\n// Fatal logs a message at level Fatal on the standard logger then the process will exit with status set to 1.\nfunc Fatal(args ...interface{}) {\n\tstd.Fatal(args...)\n}\n\n// TraceFn logs a message from a func at level Trace on the standard logger.\nfunc TraceFn(fn LogFunction) {\n\tstd.TraceFn(fn)\n}\n\n// DebugFn logs a message from a func at level Debug on the standard logger.\nfunc DebugFn(fn LogFunction) {\n\tstd.DebugFn(fn)\n}\n\n// PrintFn logs a message from a func at level Info on the standard logger.\nfunc PrintFn(fn LogFunction) {\n\tstd.PrintFn(fn)\n}\n\n// InfoFn logs a message from a func at level Info on the standard logger.\nfunc InfoFn(fn LogFunction) {\n\tstd.InfoFn(fn)\n}\n\n// WarnFn logs a message from a func at level Warn on the standard logger.\nfunc WarnFn(fn LogFunction) {\n\tstd.WarnFn(fn)\n}\n\n// WarningFn logs a message from a func at level Warn on the standard logger.\nfunc WarningFn(fn LogFunction) {\n\tstd.WarningFn(fn)\n}\n\n// ErrorFn logs a message from a func at level Error on the standard logger.\nfunc ErrorFn(fn LogFunction) {\n\tstd.ErrorFn(fn)\n}\n\n// PanicFn logs a message from a func at level Panic on the standard logger.\nfunc PanicFn(fn LogFunction) {\n\tstd.PanicFn(fn)\n}\n\n// FatalFn logs a message from a func at level Fatal on the standard logger then the process will exit with status set to 1.\nfunc FatalFn(fn LogFunction) {\n\tstd.FatalFn(fn)\n}\n\n// Tracef logs a message at level Trace on the standard logger.\nfunc Tracef(format string, args ...interface{}) {\n\tstd.Tracef(format, args...)\n}\n\n// Debugf logs a message at level Debug on the standard logger.\nfunc Debugf(format string, args ...interface{}) {\n\tstd.Debugf(format, args...)\n}\n\n// Printf logs a message at level Info on the standard logger.\nfunc Printf(format string, args ...interface{}) {\n\tstd.Printf(format, args...)\n}\n\n// Infof logs a message at level Info on the standard logger.\nfunc Infof(format string, args ...interface{}) {\n\tstd.Infof(format, args...)\n}\n\n// Warnf logs a message at level Warn on the standard logger.\nfunc Warnf(format string, args ...interface{}) {\n\tstd.Warnf(format, args...)\n}\n\n// Warningf logs a message at level Warn on the standard logger.\nfunc Warningf(format string, args ...interface{}) {\n\tstd.Warningf(format, args...)\n}\n\n// Errorf logs a message at level Error on the standard logger.\nfunc Errorf(format string, args ...interface{}) {\n\tstd.Errorf(format, args...)\n}\n\n// Panicf logs a message at level Panic on the standard logger.\nfunc Panicf(format string, args ...interface{}) {\n\tstd.Panicf(format, args...)\n}\n\n// Fatalf logs a message at level Fatal on the standard logger then the process will exit with status set to 1.\nfunc Fatalf(format string, args ...interface{}) {\n\tstd.Fatalf(format, args...)\n}\n\n// Traceln logs a message at level Trace on the standard logger.\nfunc Traceln(args ...interface{}) {\n\tstd.Traceln(args...)\n}\n\n// Debugln logs a message at level Debug on the standard logger.\nfunc Debugln(args ...interface{}) {\n\tstd.Debugln(args...)\n}\n\n// Println logs a message at level Info on the standard logger.\nfunc Println(args ...interface{}) {\n\tstd.Println(args...)\n}\n\n// Infoln logs a message at level Info on the standard logger.\nfunc Infoln(args ...interface{}) {\n\tstd.Infoln(args...)\n}\n\n// Warnln logs a message at level Warn on the standard logger.\nfunc Warnln(args ...interface{}) {\n\tstd.Warnln(args...)\n}\n\n// Warningln logs a message at level Warn on the standard logger.\nfunc Warningln(args ...interface{}) {\n\tstd.Warningln(args...)\n}\n\n// Errorln logs a message at level Error on the standard logger.\nfunc Errorln(args ...interface{}) {\n\tstd.Errorln(args...)\n}\n\n// Panicln logs a message at level Panic on the standard logger.\nfunc Panicln(args ...interface{}) {\n\tstd.Panicln(args...)\n}\n\n// Fatalln logs a message at level Fatal on the standard logger then the process will exit with status set to 1.\nfunc Fatalln(args ...interface{}) {\n\tstd.Fatalln(args...)\n}\n"
        },
        {
          "name": "formatter.go",
          "type": "blob",
          "size": 2.2978515625,
          "content": "package logrus\n\nimport \"time\"\n\n// Default key names for the default fields\nconst (\n\tdefaultTimestampFormat = time.RFC3339\n\tFieldKeyMsg            = \"msg\"\n\tFieldKeyLevel          = \"level\"\n\tFieldKeyTime           = \"time\"\n\tFieldKeyLogrusError    = \"logrus_error\"\n\tFieldKeyFunc           = \"func\"\n\tFieldKeyFile           = \"file\"\n)\n\n// The Formatter interface is used to implement a custom Formatter. It takes an\n// `Entry`. It exposes all the fields, including the default ones:\n//\n// * `entry.Data[\"msg\"]`. The message passed from Info, Warn, Error ..\n// * `entry.Data[\"time\"]`. The timestamp.\n// * `entry.Data[\"level\"]. The level the entry was logged at.\n//\n// Any additional fields added with `WithField` or `WithFields` are also in\n// `entry.Data`. Format is expected to return an array of bytes which are then\n// logged to `logger.Out`.\ntype Formatter interface {\n\tFormat(*Entry) ([]byte, error)\n}\n\n// This is to not silently overwrite `time`, `msg`, `func` and `level` fields when\n// dumping it. If this code wasn't there doing:\n//\n//  logrus.WithField(\"level\", 1).Info(\"hello\")\n//\n// Would just silently drop the user provided level. Instead with this code\n// it'll logged as:\n//\n//  {\"level\": \"info\", \"fields.level\": 1, \"msg\": \"hello\", \"time\": \"...\"}\n//\n// It's not exported because it's still using Data in an opinionated way. It's to\n// avoid code duplication between the two default formatters.\nfunc prefixFieldClashes(data Fields, fieldMap FieldMap, reportCaller bool) {\n\ttimeKey := fieldMap.resolve(FieldKeyTime)\n\tif t, ok := data[timeKey]; ok {\n\t\tdata[\"fields.\"+timeKey] = t\n\t\tdelete(data, timeKey)\n\t}\n\n\tmsgKey := fieldMap.resolve(FieldKeyMsg)\n\tif m, ok := data[msgKey]; ok {\n\t\tdata[\"fields.\"+msgKey] = m\n\t\tdelete(data, msgKey)\n\t}\n\n\tlevelKey := fieldMap.resolve(FieldKeyLevel)\n\tif l, ok := data[levelKey]; ok {\n\t\tdata[\"fields.\"+levelKey] = l\n\t\tdelete(data, levelKey)\n\t}\n\n\tlogrusErrKey := fieldMap.resolve(FieldKeyLogrusError)\n\tif l, ok := data[logrusErrKey]; ok {\n\t\tdata[\"fields.\"+logrusErrKey] = l\n\t\tdelete(data, logrusErrKey)\n\t}\n\n\t// If reportCaller is not set, 'func' will not conflict.\n\tif reportCaller {\n\t\tfuncKey := fieldMap.resolve(FieldKeyFunc)\n\t\tif l, ok := data[funcKey]; ok {\n\t\t\tdata[\"fields.\"+funcKey] = l\n\t\t}\n\t\tfileKey := fieldMap.resolve(FieldKeyFile)\n\t\tif l, ok := data[fileKey]; ok {\n\t\t\tdata[\"fields.\"+fileKey] = l\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "formatter_bench_test.go",
          "type": "blob",
          "size": 2.0927734375,
          "content": "package logrus\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n)\n\n// smallFields is a small size data set for benchmarking\nvar smallFields = Fields{\n\t\"foo\":   \"bar\",\n\t\"baz\":   \"qux\",\n\t\"one\":   \"two\",\n\t\"three\": \"four\",\n}\n\n// largeFields is a large size data set for benchmarking\nvar largeFields = Fields{\n\t\"foo\":       \"bar\",\n\t\"baz\":       \"qux\",\n\t\"one\":       \"two\",\n\t\"three\":     \"four\",\n\t\"five\":      \"six\",\n\t\"seven\":     \"eight\",\n\t\"nine\":      \"ten\",\n\t\"eleven\":    \"twelve\",\n\t\"thirteen\":  \"fourteen\",\n\t\"fifteen\":   \"sixteen\",\n\t\"seventeen\": \"eighteen\",\n\t\"nineteen\":  \"twenty\",\n\t\"a\":         \"b\",\n\t\"c\":         \"d\",\n\t\"e\":         \"f\",\n\t\"g\":         \"h\",\n\t\"i\":         \"j\",\n\t\"k\":         \"l\",\n\t\"m\":         \"n\",\n\t\"o\":         \"p\",\n\t\"q\":         \"r\",\n\t\"s\":         \"t\",\n\t\"u\":         \"v\",\n\t\"w\":         \"x\",\n\t\"y\":         \"z\",\n\t\"this\":      \"will\",\n\t\"make\":      \"thirty\",\n\t\"entries\":   \"yeah\",\n}\n\nvar errorFields = Fields{\n\t\"foo\": fmt.Errorf(\"bar\"),\n\t\"baz\": fmt.Errorf(\"qux\"),\n}\n\nfunc BenchmarkErrorTextFormatter(b *testing.B) {\n\tdoBenchmark(b, &TextFormatter{DisableColors: true}, errorFields)\n}\n\nfunc BenchmarkSmallTextFormatter(b *testing.B) {\n\tdoBenchmark(b, &TextFormatter{DisableColors: true}, smallFields)\n}\n\nfunc BenchmarkLargeTextFormatter(b *testing.B) {\n\tdoBenchmark(b, &TextFormatter{DisableColors: true}, largeFields)\n}\n\nfunc BenchmarkSmallColoredTextFormatter(b *testing.B) {\n\tdoBenchmark(b, &TextFormatter{ForceColors: true}, smallFields)\n}\n\nfunc BenchmarkLargeColoredTextFormatter(b *testing.B) {\n\tdoBenchmark(b, &TextFormatter{ForceColors: true}, largeFields)\n}\n\nfunc BenchmarkSmallJSONFormatter(b *testing.B) {\n\tdoBenchmark(b, &JSONFormatter{}, smallFields)\n}\n\nfunc BenchmarkLargeJSONFormatter(b *testing.B) {\n\tdoBenchmark(b, &JSONFormatter{}, largeFields)\n}\n\nfunc doBenchmark(b *testing.B, formatter Formatter, fields Fields) {\n\tlogger := New()\n\n\tentry := &Entry{\n\t\tTime:    time.Time{},\n\t\tLevel:   InfoLevel,\n\t\tMessage: \"message\",\n\t\tData:    fields,\n\t\tLogger:  logger,\n\t}\n\tvar d []byte\n\tvar err error\n\tfor i := 0; i < b.N; i++ {\n\t\td, err = formatter.Format(entry)\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tb.SetBytes(int64(len(d)))\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.1875,
          "content": "module github.com/sirupsen/logrus\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/stretchr/testify v1.7.0\n\tgolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8\n)\n\ngo 1.13\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.2890625,
          "content": "github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.7.0 h1:nwc3DEeHmmLAfoZucVR881uASk0Mfjw8xYJ99tb5CcY=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8 h1:0A+M6Uqn+Eje4kHMK80dtF3JCXC4ykBgQG4Fe06QRhQ=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c h1:dUUwHk2QECo/6vqA44rthZ8ie2QXMNeKRTHCNY2nXvo=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "hook_test.go",
          "type": "blob",
          "size": 4.38671875,
          "content": "package logrus_test\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"sync\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t. \"github.com/sirupsen/logrus\"\n\t\"github.com/sirupsen/logrus/hooks/test\"\n\t. \"github.com/sirupsen/logrus/internal/testutils\"\n)\n\ntype TestHook struct {\n\tFired bool\n}\n\nfunc (hook *TestHook) Fire(entry *Entry) error {\n\thook.Fired = true\n\treturn nil\n}\n\nfunc (hook *TestHook) Levels() []Level {\n\treturn []Level{\n\t\tTraceLevel,\n\t\tDebugLevel,\n\t\tInfoLevel,\n\t\tWarnLevel,\n\t\tErrorLevel,\n\t\tFatalLevel,\n\t\tPanicLevel,\n\t}\n}\n\nfunc TestHookFires(t *testing.T) {\n\thook := new(TestHook)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Hooks.Add(hook)\n\t\tassert.Equal(t, hook.Fired, false)\n\n\t\tlog.Print(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, hook.Fired, true)\n\t})\n}\n\ntype ModifyHook struct {\n}\n\nfunc (hook *ModifyHook) Fire(entry *Entry) error {\n\tentry.Data[\"wow\"] = \"whale\"\n\treturn nil\n}\n\nfunc (hook *ModifyHook) Levels() []Level {\n\treturn []Level{\n\t\tTraceLevel,\n\t\tDebugLevel,\n\t\tInfoLevel,\n\t\tWarnLevel,\n\t\tErrorLevel,\n\t\tFatalLevel,\n\t\tPanicLevel,\n\t}\n}\n\nfunc TestHookCanModifyEntry(t *testing.T) {\n\thook := new(ModifyHook)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Hooks.Add(hook)\n\t\tlog.WithField(\"wow\", \"elephant\").Print(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, fields[\"wow\"], \"whale\")\n\t})\n}\n\nfunc TestCanFireMultipleHooks(t *testing.T) {\n\thook1 := new(ModifyHook)\n\thook2 := new(TestHook)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Hooks.Add(hook1)\n\t\tlog.Hooks.Add(hook2)\n\n\t\tlog.WithField(\"wow\", \"elephant\").Print(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, fields[\"wow\"], \"whale\")\n\t\tassert.Equal(t, hook2.Fired, true)\n\t})\n}\n\ntype SingleLevelModifyHook struct {\n\tModifyHook\n}\n\nfunc (h *SingleLevelModifyHook) Levels() []Level {\n\treturn []Level{InfoLevel}\n}\n\nfunc TestHookEntryIsPristine(t *testing.T) {\n\tl := New()\n\tb := &bytes.Buffer{}\n\tl.Formatter = &JSONFormatter{}\n\tl.Out = b\n\tl.AddHook(&SingleLevelModifyHook{})\n\n\tl.Error(\"error message\")\n\tdata := map[string]string{}\n\terr := json.Unmarshal(b.Bytes(), &data)\n\trequire.NoError(t, err)\n\t_, ok := data[\"wow\"]\n\trequire.False(t, ok)\n\tb.Reset()\n\n\tl.Info(\"error message\")\n\tdata = map[string]string{}\n\terr = json.Unmarshal(b.Bytes(), &data)\n\trequire.NoError(t, err)\n\t_, ok = data[\"wow\"]\n\trequire.True(t, ok)\n\tb.Reset()\n\n\tl.Error(\"error message\")\n\tdata = map[string]string{}\n\terr = json.Unmarshal(b.Bytes(), &data)\n\trequire.NoError(t, err)\n\t_, ok = data[\"wow\"]\n\trequire.False(t, ok)\n\tb.Reset()\n}\n\ntype ErrorHook struct {\n\tFired bool\n}\n\nfunc (hook *ErrorHook) Fire(entry *Entry) error {\n\thook.Fired = true\n\treturn nil\n}\n\nfunc (hook *ErrorHook) Levels() []Level {\n\treturn []Level{\n\t\tErrorLevel,\n\t}\n}\n\nfunc TestErrorHookShouldntFireOnInfo(t *testing.T) {\n\thook := new(ErrorHook)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Hooks.Add(hook)\n\t\tlog.Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, hook.Fired, false)\n\t})\n}\n\nfunc TestErrorHookShouldFireOnError(t *testing.T) {\n\thook := new(ErrorHook)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Hooks.Add(hook)\n\t\tlog.Error(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, hook.Fired, true)\n\t})\n}\n\nfunc TestAddHookRace(t *testing.T) {\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\thook := new(ErrorHook)\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tlog.AddHook(hook)\n\t\t}()\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tlog.Error(\"test\")\n\t\t}()\n\t\twg.Wait()\n\t}, func(fields Fields) {\n\t\t// the line may have been logged\n\t\t// before the hook was added, so we can't\n\t\t// actually assert on the hook\n\t})\n}\n\nfunc TestAddHookRace2(t *testing.T) {\n\tt.Parallel()\n\n\tfor i := 0; i < 3; i++ {\n\t\ttestname := fmt.Sprintf(\"Test %d\", i)\n\t\tt.Run(testname, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\t_ = test.NewGlobal()\n\t\t\tInfo(testname)\n\t\t})\n\t}\n}\n\ntype HookCallFunc struct {\n\tF func()\n}\n\nfunc (h *HookCallFunc) Levels() []Level {\n\treturn AllLevels\n}\n\nfunc (h *HookCallFunc) Fire(e *Entry) error {\n\th.F()\n\treturn nil\n}\n\nfunc TestHookFireOrder(t *testing.T) {\n\tcheckers := []string{}\n\th := LevelHooks{}\n\th.Add(&HookCallFunc{F: func() { checkers = append(checkers, \"first hook\") }})\n\th.Add(&HookCallFunc{F: func() { checkers = append(checkers, \"second hook\") }})\n\th.Add(&HookCallFunc{F: func() { checkers = append(checkers, \"third hook\") }})\n\n\tif err := h.Fire(InfoLevel, &Entry{}); err != nil {\n\t\tt.Error(\"unexpected error:\", err)\n\t}\n\trequire.Equal(t, []string{\"first hook\", \"second hook\", \"third hook\"}, checkers)\n}\n"
        },
        {
          "name": "hooks.go",
          "type": "blob",
          "size": 1.0751953125,
          "content": "package logrus\n\n// A hook to be fired when logging on the logging levels returned from\n// `Levels()` on your implementation of the interface. Note that this is not\n// fired in a goroutine or a channel with workers, you should handle such\n// functionality yourself if your call is non-blocking and you don't wish for\n// the logging calls for levels returned from `Levels()` to block.\ntype Hook interface {\n\tLevels() []Level\n\tFire(*Entry) error\n}\n\n// Internal type for storing the hooks on a logger instance.\ntype LevelHooks map[Level][]Hook\n\n// Add a hook to an instance of logger. This is called with\n// `log.Hooks.Add(new(MyHook))` where `MyHook` implements the `Hook` interface.\nfunc (hooks LevelHooks) Add(hook Hook) {\n\tfor _, level := range hook.Levels() {\n\t\thooks[level] = append(hooks[level], hook)\n\t}\n}\n\n// Fire all the hooks for the passed level. Used by `entry.log` to fire\n// appropriate hooks for a log entry.\nfunc (hooks LevelHooks) Fire(level Level, entry *Entry) error {\n\tfor _, hook := range hooks[level] {\n\t\tif err := hook.Fire(entry); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "json_formatter.go",
          "type": "blob",
          "size": 3.3095703125,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"runtime\"\n)\n\ntype fieldKey string\n\n// FieldMap allows customization of the key names for default fields.\ntype FieldMap map[fieldKey]string\n\nfunc (f FieldMap) resolve(key fieldKey) string {\n\tif k, ok := f[key]; ok {\n\t\treturn k\n\t}\n\n\treturn string(key)\n}\n\n// JSONFormatter formats logs into parsable json\ntype JSONFormatter struct {\n\t// TimestampFormat sets the format used for marshaling timestamps.\n\t// The format to use is the same than for time.Format or time.Parse from the standard\n\t// library.\n\t// The standard Library already provides a set of predefined format.\n\tTimestampFormat string\n\n\t// DisableTimestamp allows disabling automatic timestamps in output\n\tDisableTimestamp bool\n\n\t// DisableHTMLEscape allows disabling html escaping in output\n\tDisableHTMLEscape bool\n\n\t// DataKey allows users to put all the log entry parameters into a nested dictionary at a given key.\n\tDataKey string\n\n\t// FieldMap allows users to customize the names of keys for default fields.\n\t// As an example:\n\t// formatter := &JSONFormatter{\n\t//   \tFieldMap: FieldMap{\n\t// \t\t FieldKeyTime:  \"@timestamp\",\n\t// \t\t FieldKeyLevel: \"@level\",\n\t// \t\t FieldKeyMsg:   \"@message\",\n\t// \t\t FieldKeyFunc:  \"@caller\",\n\t//    },\n\t// }\n\tFieldMap FieldMap\n\n\t// CallerPrettyfier can be set by the user to modify the content\n\t// of the function and file keys in the json data when ReportCaller is\n\t// activated. If any of the returned value is the empty string the\n\t// corresponding key will be removed from json fields.\n\tCallerPrettyfier func(*runtime.Frame) (function string, file string)\n\n\t// PrettyPrint will indent all json logs\n\tPrettyPrint bool\n}\n\n// Format renders a single log entry\nfunc (f *JSONFormatter) Format(entry *Entry) ([]byte, error) {\n\tdata := make(Fields, len(entry.Data)+4)\n\tfor k, v := range entry.Data {\n\t\tswitch v := v.(type) {\n\t\tcase error:\n\t\t\t// Otherwise errors are ignored by `encoding/json`\n\t\t\t// https://github.com/sirupsen/logrus/issues/137\n\t\t\tdata[k] = v.Error()\n\t\tdefault:\n\t\t\tdata[k] = v\n\t\t}\n\t}\n\n\tif f.DataKey != \"\" {\n\t\tnewData := make(Fields, 4)\n\t\tnewData[f.DataKey] = data\n\t\tdata = newData\n\t}\n\n\tprefixFieldClashes(data, f.FieldMap, entry.HasCaller())\n\n\ttimestampFormat := f.TimestampFormat\n\tif timestampFormat == \"\" {\n\t\ttimestampFormat = defaultTimestampFormat\n\t}\n\n\tif entry.err != \"\" {\n\t\tdata[f.FieldMap.resolve(FieldKeyLogrusError)] = entry.err\n\t}\n\tif !f.DisableTimestamp {\n\t\tdata[f.FieldMap.resolve(FieldKeyTime)] = entry.Time.Format(timestampFormat)\n\t}\n\tdata[f.FieldMap.resolve(FieldKeyMsg)] = entry.Message\n\tdata[f.FieldMap.resolve(FieldKeyLevel)] = entry.Level.String()\n\tif entry.HasCaller() {\n\t\tfuncVal := entry.Caller.Function\n\t\tfileVal := fmt.Sprintf(\"%s:%d\", entry.Caller.File, entry.Caller.Line)\n\t\tif f.CallerPrettyfier != nil {\n\t\t\tfuncVal, fileVal = f.CallerPrettyfier(entry.Caller)\n\t\t}\n\t\tif funcVal != \"\" {\n\t\t\tdata[f.FieldMap.resolve(FieldKeyFunc)] = funcVal\n\t\t}\n\t\tif fileVal != \"\" {\n\t\t\tdata[f.FieldMap.resolve(FieldKeyFile)] = fileVal\n\t\t}\n\t}\n\n\tvar b *bytes.Buffer\n\tif entry.Buffer != nil {\n\t\tb = entry.Buffer\n\t} else {\n\t\tb = &bytes.Buffer{}\n\t}\n\n\tencoder := json.NewEncoder(b)\n\tencoder.SetEscapeHTML(!f.DisableHTMLEscape)\n\tif f.PrettyPrint {\n\t\tencoder.SetIndent(\"\", \"  \")\n\t}\n\tif err := encoder.Encode(data); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to marshal fields to JSON, %w\", err)\n\t}\n\n\treturn b.Bytes(), nil\n}\n"
        },
        {
          "name": "json_formatter_test.go",
          "type": "blob",
          "size": 8.76953125,
          "content": "package logrus\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestErrorNotLost(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"error\", errors.New(\"wild walrus\")))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"error\"] != \"wild walrus\" {\n\t\tt.Fatal(\"Error field not set\")\n\t}\n}\n\nfunc TestErrorNotLostOnFieldNotNamedError(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"omg\", errors.New(\"wild walrus\")))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"omg\"] != \"wild walrus\" {\n\t\tt.Fatal(\"Error field not set\")\n\t}\n}\n\nfunc TestFieldClashWithTime(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"time\", \"right now!\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"fields.time\"] != \"right now!\" {\n\t\tt.Fatal(\"fields.time not set to original time field\")\n\t}\n\n\tif entry[\"time\"] != \"0001-01-01T00:00:00Z\" {\n\t\tt.Fatal(\"time field not set to current time, was: \", entry[\"time\"])\n\t}\n}\n\nfunc TestFieldClashWithMsg(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"msg\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"fields.msg\"] != \"something\" {\n\t\tt.Fatal(\"fields.msg not set to original msg field\")\n\t}\n}\n\nfunc TestFieldClashWithLevel(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"fields.level\"] != \"something\" {\n\t\tt.Fatal(\"fields.level not set to original level field\")\n\t}\n}\n\nfunc TestFieldClashWithRemappedFields(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tFieldMap: FieldMap{\n\t\t\tFieldKeyTime:  \"@timestamp\",\n\t\t\tFieldKeyLevel: \"@level\",\n\t\t\tFieldKeyMsg:   \"@message\",\n\t\t},\n\t}\n\n\tb, err := formatter.Format(WithFields(Fields{\n\t\t\"@timestamp\": \"@timestamp\",\n\t\t\"@level\":     \"@level\",\n\t\t\"@message\":   \"@message\",\n\t\t\"timestamp\":  \"timestamp\",\n\t\t\"level\":      \"level\",\n\t\t\"msg\":        \"msg\",\n\t}))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tfor _, field := range []string{\"timestamp\", \"level\", \"msg\"} {\n\t\tif entry[field] != field {\n\t\t\tt.Errorf(\"Expected field %v to be untouched; got %v\", field, entry[field])\n\t\t}\n\n\t\tremappedKey := fmt.Sprintf(\"fields.%s\", field)\n\t\tif remapped, ok := entry[remappedKey]; ok {\n\t\t\tt.Errorf(\"Expected %s to be empty; got %v\", remappedKey, remapped)\n\t\t}\n\t}\n\n\tfor _, field := range []string{\"@timestamp\", \"@level\", \"@message\"} {\n\t\tif entry[field] == field {\n\t\t\tt.Errorf(\"Expected field %v to be mapped to an Entry value\", field)\n\t\t}\n\n\t\tremappedKey := fmt.Sprintf(\"fields.%s\", field)\n\t\tif remapped, ok := entry[remappedKey]; ok {\n\t\t\tif remapped != field {\n\t\t\t\tt.Errorf(\"Expected field %v to be copied to %s; got %v\", field, remappedKey, remapped)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Errorf(\"Expected field %v to be copied to %s; was absent\", field, remappedKey)\n\t\t}\n\t}\n}\n\nfunc TestFieldsInNestedDictionary(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tDataKey: \"args\",\n\t}\n\n\tlogEntry := WithFields(Fields{\n\t\t\"level\": \"level\",\n\t\t\"test\":  \"test\",\n\t})\n\tlogEntry.Level = InfoLevel\n\n\tb, err := formatter.Format(logEntry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\targs := entry[\"args\"].(map[string]interface{})\n\n\tfor _, field := range []string{\"test\", \"level\"} {\n\t\tif value, present := args[field]; !present || value != field {\n\t\t\tt.Errorf(\"Expected field %v to be present under 'args'; untouched\", field)\n\t\t}\n\t}\n\n\tfor _, field := range []string{\"test\", \"fields.level\"} {\n\t\tif _, present := entry[field]; present {\n\t\t\tt.Errorf(\"Expected field %v not to be present at top level\", field)\n\t\t}\n\t}\n\n\t// with nested object, \"level\" shouldn't clash\n\tif entry[\"level\"] != \"info\" {\n\t\tt.Errorf(\"Expected 'level' field to contain 'info'\")\n\t}\n}\n\nfunc TestJSONEntryEndsWithNewline(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tif b[len(b)-1] != '\\n' {\n\t\tt.Fatal(\"Expected JSON log entry to end with a newline\")\n\t}\n}\n\nfunc TestJSONMessageKey(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tFieldMap: FieldMap{\n\t\t\tFieldKeyMsg: \"message\",\n\t\t},\n\t}\n\n\tb, err := formatter.Format(&Entry{Message: \"oh hai\"})\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !(strings.Contains(s, \"message\") && strings.Contains(s, \"oh hai\")) {\n\t\tt.Fatal(\"Expected JSON to format message key\")\n\t}\n}\n\nfunc TestJSONLevelKey(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tFieldMap: FieldMap{\n\t\t\tFieldKeyLevel: \"somelevel\",\n\t\t},\n\t}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !strings.Contains(s, \"somelevel\") {\n\t\tt.Fatal(\"Expected JSON to format level key\")\n\t}\n}\n\nfunc TestJSONTimeKey(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tFieldMap: FieldMap{\n\t\t\tFieldKeyTime: \"timeywimey\",\n\t\t},\n\t}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !strings.Contains(s, \"timeywimey\") {\n\t\tt.Fatal(\"Expected JSON to format time key\")\n\t}\n}\n\nfunc TestFieldDoesNotClashWithCaller(t *testing.T) {\n\tSetReportCaller(false)\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"func\", \"howdy pardner\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"func\"] != \"howdy pardner\" {\n\t\tt.Fatal(\"func field replaced when ReportCaller=false\")\n\t}\n}\n\nfunc TestFieldClashWithCaller(t *testing.T) {\n\tSetReportCaller(true)\n\tformatter := &JSONFormatter{}\n\te := WithField(\"func\", \"howdy pardner\")\n\te.Caller = &runtime.Frame{Function: \"somefunc\"}\n\tb, err := formatter.Format(e)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tentry := make(map[string]interface{})\n\terr = json.Unmarshal(b, &entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to unmarshal formatted entry: \", err)\n\t}\n\n\tif entry[\"fields.func\"] != \"howdy pardner\" {\n\t\tt.Fatalf(\"fields.func not set to original func field when ReportCaller=true (got '%s')\",\n\t\t\tentry[\"fields.func\"])\n\t}\n\n\tif entry[\"func\"] != \"somefunc\" {\n\t\tt.Fatalf(\"func not set as expected when ReportCaller=true (got '%s')\",\n\t\t\tentry[\"func\"])\n\t}\n\n\tSetReportCaller(false) // return to default value\n}\n\nfunc TestJSONDisableTimestamp(t *testing.T) {\n\tformatter := &JSONFormatter{\n\t\tDisableTimestamp: true,\n\t}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif strings.Contains(s, FieldKeyTime) {\n\t\tt.Error(\"Did not prevent timestamp\", s)\n\t}\n}\n\nfunc TestJSONEnableTimestamp(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(WithField(\"level\", \"something\"))\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !strings.Contains(s, FieldKeyTime) {\n\t\tt.Error(\"Timestamp not present\", s)\n\t}\n}\n\nfunc TestJSONDisableHTMLEscape(t *testing.T) {\n\tformatter := &JSONFormatter{DisableHTMLEscape: true}\n\n\tb, err := formatter.Format(&Entry{Message: \"& < >\"})\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !strings.Contains(s, \"& < >\") {\n\t\tt.Error(\"Message should not be HTML escaped\", s)\n\t}\n}\n\nfunc TestJSONEnableHTMLEscape(t *testing.T) {\n\tformatter := &JSONFormatter{}\n\n\tb, err := formatter.Format(&Entry{Message: \"& < >\"})\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\ts := string(b)\n\tif !(strings.Contains(s, \"u0026\") && strings.Contains(s, \"u003e\") && strings.Contains(s, \"u003c\")) {\n\t\tt.Error(\"Message should be HTML escaped\", s)\n\t}\n}\n"
        },
        {
          "name": "level_test.go",
          "type": "blob",
          "size": 1.2353515625,
          "content": "package logrus_test\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"testing\"\n\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestLevelJsonEncoding(t *testing.T) {\n\ttype X struct {\n\t\tLevel logrus.Level\n\t}\n\n\tvar x X\n\tx.Level = logrus.WarnLevel\n\tvar buf bytes.Buffer\n\tenc := json.NewEncoder(&buf)\n\trequire.NoError(t, enc.Encode(x))\n\tdec := json.NewDecoder(&buf)\n\tvar y X\n\trequire.NoError(t, dec.Decode(&y))\n}\n\nfunc TestLevelUnmarshalText(t *testing.T) {\n\tvar u logrus.Level\n\tfor _, level := range logrus.AllLevels {\n\t\tt.Run(level.String(), func(t *testing.T) {\n\t\t\trequire.NoError(t, u.UnmarshalText([]byte(level.String())))\n\t\t\trequire.Equal(t, level, u)\n\t\t})\n\t}\n\tt.Run(\"invalid\", func(t *testing.T) {\n\t\trequire.Error(t, u.UnmarshalText([]byte(\"invalid\")))\n\t})\n}\n\nfunc TestLevelMarshalText(t *testing.T) {\n\tlevelStrings := []string{\n\t\t\"panic\",\n\t\t\"fatal\",\n\t\t\"error\",\n\t\t\"warning\",\n\t\t\"info\",\n\t\t\"debug\",\n\t\t\"trace\",\n\t}\n\tfor idx, val := range logrus.AllLevels {\n\t\tlevel := val\n\t\tt.Run(level.String(), func(t *testing.T) {\n\t\t\tvar cmp logrus.Level\n\t\t\tb, err := level.MarshalText()\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Equal(t, levelStrings[idx], string(b))\n\t\t\terr = cmp.UnmarshalText(b)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Equal(t, level, cmp)\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "logger.go",
          "type": "blob",
          "size": 10.568359375,
          "content": "package logrus\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"os\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n// LogFunction For big messages, it can be more efficient to pass a function\n// and only call it if the log level is actually enables rather than\n// generating the log message and then checking if the level is enabled\ntype LogFunction func() []interface{}\n\ntype Logger struct {\n\t// The logs are `io.Copy`'d to this in a mutex. It's common to set this to a\n\t// file, or leave it default which is `os.Stderr`. You can also set this to\n\t// something more adventurous, such as logging to Kafka.\n\tOut io.Writer\n\t// Hooks for the logger instance. These allow firing events based on logging\n\t// levels and log entries. For example, to send errors to an error tracking\n\t// service, log to StatsD or dump the core on fatal errors.\n\tHooks LevelHooks\n\t// All log entries pass through the formatter before logged to Out. The\n\t// included formatters are `TextFormatter` and `JSONFormatter` for which\n\t// TextFormatter is the default. In development (when a TTY is attached) it\n\t// logs with colors, but to a file it wouldn't. You can easily implement your\n\t// own that implements the `Formatter` interface, see the `README` or included\n\t// formatters for examples.\n\tFormatter Formatter\n\n\t// Flag for whether to log caller info (off by default)\n\tReportCaller bool\n\n\t// The logging level the logger should log at. This is typically (and defaults\n\t// to) `logrus.Info`, which allows Info(), Warn(), Error() and Fatal() to be\n\t// logged.\n\tLevel Level\n\t// Used to sync writing to the log. Locking is enabled by Default\n\tmu MutexWrap\n\t// Reusable empty entry\n\tentryPool sync.Pool\n\t// Function to exit the application, defaults to `os.Exit()`\n\tExitFunc exitFunc\n\t// The buffer pool used to format the log. If it is nil, the default global\n\t// buffer pool will be used.\n\tBufferPool BufferPool\n}\n\ntype exitFunc func(int)\n\ntype MutexWrap struct {\n\tlock     sync.Mutex\n\tdisabled bool\n}\n\nfunc (mw *MutexWrap) Lock() {\n\tif !mw.disabled {\n\t\tmw.lock.Lock()\n\t}\n}\n\nfunc (mw *MutexWrap) Unlock() {\n\tif !mw.disabled {\n\t\tmw.lock.Unlock()\n\t}\n}\n\nfunc (mw *MutexWrap) Disable() {\n\tmw.disabled = true\n}\n\n// Creates a new logger. Configuration should be set by changing `Formatter`,\n// `Out` and `Hooks` directly on the default logger instance. You can also just\n// instantiate your own:\n//\n//    var log = &logrus.Logger{\n//      Out: os.Stderr,\n//      Formatter: new(logrus.TextFormatter),\n//      Hooks: make(logrus.LevelHooks),\n//      Level: logrus.DebugLevel,\n//    }\n//\n// It's recommended to make this a global instance called `log`.\nfunc New() *Logger {\n\treturn &Logger{\n\t\tOut:          os.Stderr,\n\t\tFormatter:    new(TextFormatter),\n\t\tHooks:        make(LevelHooks),\n\t\tLevel:        InfoLevel,\n\t\tExitFunc:     os.Exit,\n\t\tReportCaller: false,\n\t}\n}\n\nfunc (logger *Logger) newEntry() *Entry {\n\tentry, ok := logger.entryPool.Get().(*Entry)\n\tif ok {\n\t\treturn entry\n\t}\n\treturn NewEntry(logger)\n}\n\nfunc (logger *Logger) releaseEntry(entry *Entry) {\n\tentry.Data = map[string]interface{}{}\n\tlogger.entryPool.Put(entry)\n}\n\n// WithField allocates a new entry and adds a field to it.\n// Debug, Print, Info, Warn, Error, Fatal or Panic must be then applied to\n// this new returned entry.\n// If you want multiple fields, use `WithFields`.\nfunc (logger *Logger) WithField(key string, value interface{}) *Entry {\n\tentry := logger.newEntry()\n\tdefer logger.releaseEntry(entry)\n\treturn entry.WithField(key, value)\n}\n\n// Adds a struct of fields to the log entry. All it does is call `WithField` for\n// each `Field`.\nfunc (logger *Logger) WithFields(fields Fields) *Entry {\n\tentry := logger.newEntry()\n\tdefer logger.releaseEntry(entry)\n\treturn entry.WithFields(fields)\n}\n\n// Add an error as single field to the log entry.  All it does is call\n// `WithError` for the given `error`.\nfunc (logger *Logger) WithError(err error) *Entry {\n\tentry := logger.newEntry()\n\tdefer logger.releaseEntry(entry)\n\treturn entry.WithError(err)\n}\n\n// Add a context to the log entry.\nfunc (logger *Logger) WithContext(ctx context.Context) *Entry {\n\tentry := logger.newEntry()\n\tdefer logger.releaseEntry(entry)\n\treturn entry.WithContext(ctx)\n}\n\n// Overrides the time of the log entry.\nfunc (logger *Logger) WithTime(t time.Time) *Entry {\n\tentry := logger.newEntry()\n\tdefer logger.releaseEntry(entry)\n\treturn entry.WithTime(t)\n}\n\nfunc (logger *Logger) Logf(level Level, format string, args ...interface{}) {\n\tif logger.IsLevelEnabled(level) {\n\t\tentry := logger.newEntry()\n\t\tentry.Logf(level, format, args...)\n\t\tlogger.releaseEntry(entry)\n\t}\n}\n\nfunc (logger *Logger) Tracef(format string, args ...interface{}) {\n\tlogger.Logf(TraceLevel, format, args...)\n}\n\nfunc (logger *Logger) Debugf(format string, args ...interface{}) {\n\tlogger.Logf(DebugLevel, format, args...)\n}\n\nfunc (logger *Logger) Infof(format string, args ...interface{}) {\n\tlogger.Logf(InfoLevel, format, args...)\n}\n\nfunc (logger *Logger) Printf(format string, args ...interface{}) {\n\tentry := logger.newEntry()\n\tentry.Printf(format, args...)\n\tlogger.releaseEntry(entry)\n}\n\nfunc (logger *Logger) Warnf(format string, args ...interface{}) {\n\tlogger.Logf(WarnLevel, format, args...)\n}\n\nfunc (logger *Logger) Warningf(format string, args ...interface{}) {\n\tlogger.Warnf(format, args...)\n}\n\nfunc (logger *Logger) Errorf(format string, args ...interface{}) {\n\tlogger.Logf(ErrorLevel, format, args...)\n}\n\nfunc (logger *Logger) Fatalf(format string, args ...interface{}) {\n\tlogger.Logf(FatalLevel, format, args...)\n\tlogger.Exit(1)\n}\n\nfunc (logger *Logger) Panicf(format string, args ...interface{}) {\n\tlogger.Logf(PanicLevel, format, args...)\n}\n\n// Log will log a message at the level given as parameter.\n// Warning: using Log at Panic or Fatal level will not respectively Panic nor Exit.\n// For this behaviour Logger.Panic or Logger.Fatal should be used instead.\nfunc (logger *Logger) Log(level Level, args ...interface{}) {\n\tif logger.IsLevelEnabled(level) {\n\t\tentry := logger.newEntry()\n\t\tentry.Log(level, args...)\n\t\tlogger.releaseEntry(entry)\n\t}\n}\n\nfunc (logger *Logger) LogFn(level Level, fn LogFunction) {\n\tif logger.IsLevelEnabled(level) {\n\t\tentry := logger.newEntry()\n\t\tentry.Log(level, fn()...)\n\t\tlogger.releaseEntry(entry)\n\t}\n}\n\nfunc (logger *Logger) Trace(args ...interface{}) {\n\tlogger.Log(TraceLevel, args...)\n}\n\nfunc (logger *Logger) Debug(args ...interface{}) {\n\tlogger.Log(DebugLevel, args...)\n}\n\nfunc (logger *Logger) Info(args ...interface{}) {\n\tlogger.Log(InfoLevel, args...)\n}\n\nfunc (logger *Logger) Print(args ...interface{}) {\n\tentry := logger.newEntry()\n\tentry.Print(args...)\n\tlogger.releaseEntry(entry)\n}\n\nfunc (logger *Logger) Warn(args ...interface{}) {\n\tlogger.Log(WarnLevel, args...)\n}\n\nfunc (logger *Logger) Warning(args ...interface{}) {\n\tlogger.Warn(args...)\n}\n\nfunc (logger *Logger) Error(args ...interface{}) {\n\tlogger.Log(ErrorLevel, args...)\n}\n\nfunc (logger *Logger) Fatal(args ...interface{}) {\n\tlogger.Log(FatalLevel, args...)\n\tlogger.Exit(1)\n}\n\nfunc (logger *Logger) Panic(args ...interface{}) {\n\tlogger.Log(PanicLevel, args...)\n}\n\nfunc (logger *Logger) TraceFn(fn LogFunction) {\n\tlogger.LogFn(TraceLevel, fn)\n}\n\nfunc (logger *Logger) DebugFn(fn LogFunction) {\n\tlogger.LogFn(DebugLevel, fn)\n}\n\nfunc (logger *Logger) InfoFn(fn LogFunction) {\n\tlogger.LogFn(InfoLevel, fn)\n}\n\nfunc (logger *Logger) PrintFn(fn LogFunction) {\n\tentry := logger.newEntry()\n\tentry.Print(fn()...)\n\tlogger.releaseEntry(entry)\n}\n\nfunc (logger *Logger) WarnFn(fn LogFunction) {\n\tlogger.LogFn(WarnLevel, fn)\n}\n\nfunc (logger *Logger) WarningFn(fn LogFunction) {\n\tlogger.WarnFn(fn)\n}\n\nfunc (logger *Logger) ErrorFn(fn LogFunction) {\n\tlogger.LogFn(ErrorLevel, fn)\n}\n\nfunc (logger *Logger) FatalFn(fn LogFunction) {\n\tlogger.LogFn(FatalLevel, fn)\n\tlogger.Exit(1)\n}\n\nfunc (logger *Logger) PanicFn(fn LogFunction) {\n\tlogger.LogFn(PanicLevel, fn)\n}\n\nfunc (logger *Logger) Logln(level Level, args ...interface{}) {\n\tif logger.IsLevelEnabled(level) {\n\t\tentry := logger.newEntry()\n\t\tentry.Logln(level, args...)\n\t\tlogger.releaseEntry(entry)\n\t}\n}\n\nfunc (logger *Logger) Traceln(args ...interface{}) {\n\tlogger.Logln(TraceLevel, args...)\n}\n\nfunc (logger *Logger) Debugln(args ...interface{}) {\n\tlogger.Logln(DebugLevel, args...)\n}\n\nfunc (logger *Logger) Infoln(args ...interface{}) {\n\tlogger.Logln(InfoLevel, args...)\n}\n\nfunc (logger *Logger) Println(args ...interface{}) {\n\tentry := logger.newEntry()\n\tentry.Println(args...)\n\tlogger.releaseEntry(entry)\n}\n\nfunc (logger *Logger) Warnln(args ...interface{}) {\n\tlogger.Logln(WarnLevel, args...)\n}\n\nfunc (logger *Logger) Warningln(args ...interface{}) {\n\tlogger.Warnln(args...)\n}\n\nfunc (logger *Logger) Errorln(args ...interface{}) {\n\tlogger.Logln(ErrorLevel, args...)\n}\n\nfunc (logger *Logger) Fatalln(args ...interface{}) {\n\tlogger.Logln(FatalLevel, args...)\n\tlogger.Exit(1)\n}\n\nfunc (logger *Logger) Panicln(args ...interface{}) {\n\tlogger.Logln(PanicLevel, args...)\n}\n\nfunc (logger *Logger) Exit(code int) {\n\trunHandlers()\n\tif logger.ExitFunc == nil {\n\t\tlogger.ExitFunc = os.Exit\n\t}\n\tlogger.ExitFunc(code)\n}\n\n//When file is opened with appending mode, it's safe to\n//write concurrently to a file (within 4k message on Linux).\n//In these cases user can choose to disable the lock.\nfunc (logger *Logger) SetNoLock() {\n\tlogger.mu.Disable()\n}\n\nfunc (logger *Logger) level() Level {\n\treturn Level(atomic.LoadUint32((*uint32)(&logger.Level)))\n}\n\n// SetLevel sets the logger level.\nfunc (logger *Logger) SetLevel(level Level) {\n\tatomic.StoreUint32((*uint32)(&logger.Level), uint32(level))\n}\n\n// GetLevel returns the logger level.\nfunc (logger *Logger) GetLevel() Level {\n\treturn logger.level()\n}\n\n// AddHook adds a hook to the logger hooks.\nfunc (logger *Logger) AddHook(hook Hook) {\n\tlogger.mu.Lock()\n\tdefer logger.mu.Unlock()\n\tlogger.Hooks.Add(hook)\n}\n\n// IsLevelEnabled checks if the log level of the logger is greater than the level param\nfunc (logger *Logger) IsLevelEnabled(level Level) bool {\n\treturn logger.level() >= level\n}\n\n// SetFormatter sets the logger formatter.\nfunc (logger *Logger) SetFormatter(formatter Formatter) {\n\tlogger.mu.Lock()\n\tdefer logger.mu.Unlock()\n\tlogger.Formatter = formatter\n}\n\n// SetOutput sets the logger output.\nfunc (logger *Logger) SetOutput(output io.Writer) {\n\tlogger.mu.Lock()\n\tdefer logger.mu.Unlock()\n\tlogger.Out = output\n}\n\nfunc (logger *Logger) SetReportCaller(reportCaller bool) {\n\tlogger.mu.Lock()\n\tdefer logger.mu.Unlock()\n\tlogger.ReportCaller = reportCaller\n}\n\n// ReplaceHooks replaces the logger hooks and returns the old ones\nfunc (logger *Logger) ReplaceHooks(hooks LevelHooks) LevelHooks {\n\tlogger.mu.Lock()\n\toldHooks := logger.Hooks\n\tlogger.Hooks = hooks\n\tlogger.mu.Unlock()\n\treturn oldHooks\n}\n\n// SetBufferPool sets the logger buffer pool.\nfunc (logger *Logger) SetBufferPool(pool BufferPool) {\n\tlogger.mu.Lock()\n\tdefer logger.mu.Unlock()\n\tlogger.BufferPool = pool\n}\n"
        },
        {
          "name": "logger_bench_test.go",
          "type": "blob",
          "size": 1.6884765625,
          "content": "package logrus\n\nimport (\n\t\"io/ioutil\"\n\t\"os\"\n\t\"testing\"\n)\n\nfunc BenchmarkDummyLogger(b *testing.B) {\n\tnullf, err := os.OpenFile(\"/dev/null\", os.O_WRONLY, 0666)\n\tif err != nil {\n\t\tb.Fatalf(\"%v\", err)\n\t}\n\tdefer nullf.Close()\n\tdoLoggerBenchmark(b, nullf, &TextFormatter{DisableColors: true}, smallFields)\n}\n\nfunc BenchmarkDummyLoggerNoLock(b *testing.B) {\n\tnullf, err := os.OpenFile(\"/dev/null\", os.O_WRONLY|os.O_APPEND, 0666)\n\tif err != nil {\n\t\tb.Fatalf(\"%v\", err)\n\t}\n\tdefer nullf.Close()\n\tdoLoggerBenchmarkNoLock(b, nullf, &TextFormatter{DisableColors: true}, smallFields)\n}\n\nfunc doLoggerBenchmark(b *testing.B, out *os.File, formatter Formatter, fields Fields) {\n\tlogger := Logger{\n\t\tOut:       out,\n\t\tLevel:     InfoLevel,\n\t\tFormatter: formatter,\n\t}\n\tentry := logger.WithFields(fields)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tentry.Info(\"aaa\")\n\t\t}\n\t})\n}\n\nfunc doLoggerBenchmarkNoLock(b *testing.B, out *os.File, formatter Formatter, fields Fields) {\n\tlogger := Logger{\n\t\tOut:       out,\n\t\tLevel:     InfoLevel,\n\t\tFormatter: formatter,\n\t}\n\tlogger.SetNoLock()\n\tentry := logger.WithFields(fields)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tentry.Info(\"aaa\")\n\t\t}\n\t})\n}\n\nfunc BenchmarkLoggerJSONFormatter(b *testing.B) {\n\tdoLoggerBenchmarkWithFormatter(b, &JSONFormatter{})\n}\n\nfunc BenchmarkLoggerTextFormatter(b *testing.B) {\n\tdoLoggerBenchmarkWithFormatter(b, &TextFormatter{})\n}\n\nfunc doLoggerBenchmarkWithFormatter(b *testing.B, f Formatter) {\n\tb.SetParallelism(100)\n\tlog := New()\n\tlog.Formatter = f\n\tlog.Out = ioutil.Discard\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tlog.\n\t\t\t\tWithField(\"foo1\", \"bar1\").\n\t\t\t\tWithField(\"foo2\", \"bar2\").\n\t\t\t\tInfo(\"this is a dummy log\")\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "logger_test.go",
          "type": "blob",
          "size": 2.173828125,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestFieldValueError(t *testing.T) {\n\tbuf := &bytes.Buffer{}\n\tl := &Logger{\n\t\tOut:       buf,\n\t\tFormatter: new(JSONFormatter),\n\t\tHooks:     make(LevelHooks),\n\t\tLevel:     DebugLevel,\n\t}\n\tl.WithField(\"func\", func() {}).Info(\"test\")\n\tfmt.Println(buf.String())\n\tvar data map[string]interface{}\n\tif err := json.Unmarshal(buf.Bytes(), &data); err != nil {\n\t\tt.Error(\"unexpected error\", err)\n\t}\n\t_, ok := data[FieldKeyLogrusError]\n\trequire.True(t, ok, `cannot found expected \"logrus_error\" field: %v`, data)\n}\n\nfunc TestNoFieldValueError(t *testing.T) {\n\tbuf := &bytes.Buffer{}\n\tl := &Logger{\n\t\tOut:       buf,\n\t\tFormatter: new(JSONFormatter),\n\t\tHooks:     make(LevelHooks),\n\t\tLevel:     DebugLevel,\n\t}\n\tl.WithField(\"str\", \"str\").Info(\"test\")\n\tfmt.Println(buf.String())\n\tvar data map[string]interface{}\n\tif err := json.Unmarshal(buf.Bytes(), &data); err != nil {\n\t\tt.Error(\"unexpected error\", err)\n\t}\n\t_, ok := data[FieldKeyLogrusError]\n\trequire.False(t, ok)\n}\n\nfunc TestWarninglnNotEqualToWarning(t *testing.T) {\n\tbuf := &bytes.Buffer{}\n\tbufln := &bytes.Buffer{}\n\n\tformatter := new(TextFormatter)\n\tformatter.DisableTimestamp = true\n\tformatter.DisableLevelTruncation = true\n\n\tl := &Logger{\n\t\tOut:       buf,\n\t\tFormatter: formatter,\n\t\tHooks:     make(LevelHooks),\n\t\tLevel:     DebugLevel,\n\t}\n\tl.Warning(\"hello,\", \"world\")\n\n\tl.SetOutput(bufln)\n\tl.Warningln(\"hello,\", \"world\")\n\n\tassert.NotEqual(t, buf.String(), bufln.String(), \"Warning() and Wantingln() should not be equal\")\n}\n\ntype testBufferPool struct {\n\tbuffers []*bytes.Buffer\n\tget int\n}\n\nfunc (p *testBufferPool) Get() *bytes.Buffer {\n\tp.get++\n\treturn new(bytes.Buffer)\n}\n\nfunc (p *testBufferPool) Put(buf *bytes.Buffer) {\n\tp.buffers = append(p.buffers, buf)\n}\n\nfunc TestLogger_SetBufferPool(t *testing.T) {\n\tout := &bytes.Buffer{}\n\tl := New()\n\tl.SetOutput(out)\n\n\tpool := new(testBufferPool)\n\tl.SetBufferPool(pool)\n\n\tl.Info(\"test\")\n\n\tassert.Equal(t, pool.get, 1, \"Logger.SetBufferPool(): The BufferPool.Get() must be called\")\n\tassert.Len(t, pool.buffers, 1, \"Logger.SetBufferPool(): The BufferPool.Put() must be called\")\n}\n"
        },
        {
          "name": "logrus.go",
          "type": "blob",
          "size": 4.6875,
          "content": "package logrus\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n)\n\n// Fields type, used to pass to `WithFields`.\ntype Fields map[string]interface{}\n\n// Level type\ntype Level uint32\n\n// Convert the Level to a string. E.g. PanicLevel becomes \"panic\".\nfunc (level Level) String() string {\n\tif b, err := level.MarshalText(); err == nil {\n\t\treturn string(b)\n\t} else {\n\t\treturn \"unknown\"\n\t}\n}\n\n// ParseLevel takes a string level and returns the Logrus log level constant.\nfunc ParseLevel(lvl string) (Level, error) {\n\tswitch strings.ToLower(lvl) {\n\tcase \"panic\":\n\t\treturn PanicLevel, nil\n\tcase \"fatal\":\n\t\treturn FatalLevel, nil\n\tcase \"error\":\n\t\treturn ErrorLevel, nil\n\tcase \"warn\", \"warning\":\n\t\treturn WarnLevel, nil\n\tcase \"info\":\n\t\treturn InfoLevel, nil\n\tcase \"debug\":\n\t\treturn DebugLevel, nil\n\tcase \"trace\":\n\t\treturn TraceLevel, nil\n\t}\n\n\tvar l Level\n\treturn l, fmt.Errorf(\"not a valid logrus Level: %q\", lvl)\n}\n\n// UnmarshalText implements encoding.TextUnmarshaler.\nfunc (level *Level) UnmarshalText(text []byte) error {\n\tl, err := ParseLevel(string(text))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t*level = l\n\n\treturn nil\n}\n\nfunc (level Level) MarshalText() ([]byte, error) {\n\tswitch level {\n\tcase TraceLevel:\n\t\treturn []byte(\"trace\"), nil\n\tcase DebugLevel:\n\t\treturn []byte(\"debug\"), nil\n\tcase InfoLevel:\n\t\treturn []byte(\"info\"), nil\n\tcase WarnLevel:\n\t\treturn []byte(\"warning\"), nil\n\tcase ErrorLevel:\n\t\treturn []byte(\"error\"), nil\n\tcase FatalLevel:\n\t\treturn []byte(\"fatal\"), nil\n\tcase PanicLevel:\n\t\treturn []byte(\"panic\"), nil\n\t}\n\n\treturn nil, fmt.Errorf(\"not a valid logrus level %d\", level)\n}\n\n// A constant exposing all logging levels\nvar AllLevels = []Level{\n\tPanicLevel,\n\tFatalLevel,\n\tErrorLevel,\n\tWarnLevel,\n\tInfoLevel,\n\tDebugLevel,\n\tTraceLevel,\n}\n\n// These are the different logging levels. You can set the logging level to log\n// on your instance of logger, obtained with `logrus.New()`.\nconst (\n\t// PanicLevel level, highest level of severity. Logs and then calls panic with the\n\t// message passed to Debug, Info, ...\n\tPanicLevel Level = iota\n\t// FatalLevel level. Logs and then calls `logger.Exit(1)`. It will exit even if the\n\t// logging level is set to Panic.\n\tFatalLevel\n\t// ErrorLevel level. Logs. Used for errors that should definitely be noted.\n\t// Commonly used for hooks to send errors to an error tracking service.\n\tErrorLevel\n\t// WarnLevel level. Non-critical entries that deserve eyes.\n\tWarnLevel\n\t// InfoLevel level. General operational entries about what's going on inside the\n\t// application.\n\tInfoLevel\n\t// DebugLevel level. Usually only enabled when debugging. Very verbose logging.\n\tDebugLevel\n\t// TraceLevel level. Designates finer-grained informational events than the Debug.\n\tTraceLevel\n)\n\n// Won't compile if StdLogger can't be realized by a log.Logger\nvar (\n\t_ StdLogger = &log.Logger{}\n\t_ StdLogger = &Entry{}\n\t_ StdLogger = &Logger{}\n)\n\n// StdLogger is what your logrus-enabled library should take, that way\n// it'll accept a stdlib logger and a logrus logger. There's no standard\n// interface, this is the closest we get, unfortunately.\ntype StdLogger interface {\n\tPrint(...interface{})\n\tPrintf(string, ...interface{})\n\tPrintln(...interface{})\n\n\tFatal(...interface{})\n\tFatalf(string, ...interface{})\n\tFatalln(...interface{})\n\n\tPanic(...interface{})\n\tPanicf(string, ...interface{})\n\tPanicln(...interface{})\n}\n\n// The FieldLogger interface generalizes the Entry and Logger types\ntype FieldLogger interface {\n\tWithField(key string, value interface{}) *Entry\n\tWithFields(fields Fields) *Entry\n\tWithError(err error) *Entry\n\n\tDebugf(format string, args ...interface{})\n\tInfof(format string, args ...interface{})\n\tPrintf(format string, args ...interface{})\n\tWarnf(format string, args ...interface{})\n\tWarningf(format string, args ...interface{})\n\tErrorf(format string, args ...interface{})\n\tFatalf(format string, args ...interface{})\n\tPanicf(format string, args ...interface{})\n\n\tDebug(args ...interface{})\n\tInfo(args ...interface{})\n\tPrint(args ...interface{})\n\tWarn(args ...interface{})\n\tWarning(args ...interface{})\n\tError(args ...interface{})\n\tFatal(args ...interface{})\n\tPanic(args ...interface{})\n\n\tDebugln(args ...interface{})\n\tInfoln(args ...interface{})\n\tPrintln(args ...interface{})\n\tWarnln(args ...interface{})\n\tWarningln(args ...interface{})\n\tErrorln(args ...interface{})\n\tFatalln(args ...interface{})\n\tPanicln(args ...interface{})\n\n\t// IsDebugEnabled() bool\n\t// IsInfoEnabled() bool\n\t// IsWarnEnabled() bool\n\t// IsErrorEnabled() bool\n\t// IsFatalEnabled() bool\n\t// IsPanicEnabled() bool\n}\n\n// Ext1FieldLogger (the first extension to FieldLogger) is superfluous, it is\n// here for consistancy. Do not use. Use Logger or Entry instead.\ntype Ext1FieldLogger interface {\n\tFieldLogger\n\tTracef(format string, args ...interface{})\n\tTrace(args ...interface{})\n\tTraceln(args ...interface{})\n}\n"
        },
        {
          "name": "logrus_test.go",
          "type": "blob",
          "size": 21.44140625,
          "content": "package logrus_test\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t. \"github.com/sirupsen/logrus\"\n\t. \"github.com/sirupsen/logrus/internal/testutils\"\n)\n\n// TestReportCaller verifies that when ReportCaller is set, the 'func' field\n// is added, and when it is unset it is not set or modified\n// Verify that functions within the Logrus package aren't considered when\n// discovering the caller.\nfunc TestReportCallerWhenConfigured(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.ReportCaller = false\n\t\tlog.Print(\"testNoCaller\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"testNoCaller\", fields[\"msg\"])\n\t\tassert.Equal(t, \"info\", fields[\"level\"])\n\t\tassert.Equal(t, nil, fields[\"func\"])\n\t})\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.ReportCaller = true\n\t\tlog.Print(\"testWithCaller\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"testWithCaller\", fields[\"msg\"])\n\t\tassert.Equal(t, \"info\", fields[\"level\"])\n\t\tassert.Equal(t,\n\t\t\t\"github.com/sirupsen/logrus_test.TestReportCallerWhenConfigured.func3\", fields[FieldKeyFunc])\n\t})\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.ReportCaller = true\n\t\tlog.Formatter.(*JSONFormatter).CallerPrettyfier = func(f *runtime.Frame) (string, string) {\n\t\t\treturn \"somekindoffunc\", \"thisisafilename\"\n\t\t}\n\t\tlog.Print(\"testWithCallerPrettyfier\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"somekindoffunc\", fields[FieldKeyFunc])\n\t\tassert.Equal(t, \"thisisafilename\", fields[FieldKeyFile])\n\t})\n\n\tLogAndAssertText(t, func(log *Logger) {\n\t\tlog.ReportCaller = true\n\t\tlog.Formatter.(*TextFormatter).CallerPrettyfier = func(f *runtime.Frame) (string, string) {\n\t\t\treturn \"somekindoffunc\", \"thisisafilename\"\n\t\t}\n\t\tlog.Print(\"testWithCallerPrettyfier\")\n\t}, func(fields map[string]string) {\n\t\tassert.Equal(t, \"somekindoffunc\", fields[FieldKeyFunc])\n\t\tassert.Equal(t, \"thisisafilename\", fields[FieldKeyFile])\n\t})\n}\n\nfunc logSomething(t *testing.T, message string) Fields {\n\tvar buffer bytes.Buffer\n\tvar fields Fields\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tlogger.Formatter = new(JSONFormatter)\n\tlogger.ReportCaller = true\n\n\tentry := logger.WithFields(Fields{\n\t\t\"foo\": \"bar\",\n\t})\n\n\tentry.Info(message)\n\n\terr := json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.Nil(t, err)\n\n\treturn fields\n}\n\n// TestReportCallerHelperDirect - verify reference when logging from a regular function\nfunc TestReportCallerHelperDirect(t *testing.T) {\n\tfields := logSomething(t, \"direct\")\n\n\tassert.Equal(t, \"direct\", fields[\"msg\"])\n\tassert.Equal(t, \"info\", fields[\"level\"])\n\tassert.Regexp(t, \"github.com/.*/logrus_test.logSomething\", fields[\"func\"])\n}\n\n// TestReportCallerHelperDirect - verify reference when logging from a function called via pointer\nfunc TestReportCallerHelperViaPointer(t *testing.T) {\n\tfptr := logSomething\n\tfields := fptr(t, \"via pointer\")\n\n\tassert.Equal(t, \"via pointer\", fields[\"msg\"])\n\tassert.Equal(t, \"info\", fields[\"level\"])\n\tassert.Regexp(t, \"github.com/.*/logrus_test.logSomething\", fields[\"func\"])\n}\n\nfunc TestPrint(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Print(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t\tassert.Equal(t, \"info\", fields[\"level\"])\n\t})\n}\n\nfunc TestInfo(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t\tassert.Equal(t, \"info\", fields[\"level\"])\n\t})\n}\n\nfunc TestWarn(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Warn(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t\tassert.Equal(t, \"warning\", fields[\"level\"])\n\t})\n}\n\nfunc TestLog(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Log(WarnLevel, \"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t\tassert.Equal(t, \"warning\", fields[\"level\"])\n\t})\n}\n\nfunc TestInfolnShouldAddSpacesBetweenStrings(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Infoln(\"test\", \"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test test\", fields[\"msg\"])\n\t})\n}\n\nfunc TestInfolnShouldAddSpacesBetweenStringAndNonstring(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Infoln(\"test\", 10)\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test 10\", fields[\"msg\"])\n\t})\n}\n\nfunc TestInfolnShouldAddSpacesBetweenTwoNonStrings(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Infoln(10, 10)\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"10 10\", fields[\"msg\"])\n\t})\n}\n\nfunc TestInfoShouldAddSpacesBetweenTwoNonStrings(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Infoln(10, 10)\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"10 10\", fields[\"msg\"])\n\t})\n}\n\nfunc TestInfoShouldNotAddSpacesBetweenStringAndNonstring(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Info(\"test\", 10)\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test10\", fields[\"msg\"])\n\t})\n}\n\nfunc TestInfoShouldNotAddSpacesBetweenStrings(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.Info(\"test\", \"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"testtest\", fields[\"msg\"])\n\t})\n}\n\nfunc TestWithFieldsShouldAllowAssignments(t *testing.T) {\n\tvar buffer bytes.Buffer\n\tvar fields Fields\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tlogger.Formatter = new(JSONFormatter)\n\n\tlocalLog := logger.WithFields(Fields{\n\t\t\"key1\": \"value1\",\n\t})\n\n\tlocalLog.WithField(\"key2\", \"value2\").Info(\"test\")\n\terr := json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.Nil(t, err)\n\n\tassert.Equal(t, \"value2\", fields[\"key2\"])\n\tassert.Equal(t, \"value1\", fields[\"key1\"])\n\n\tbuffer = bytes.Buffer{}\n\tfields = Fields{}\n\tlocalLog.Info(\"test\")\n\terr = json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.Nil(t, err)\n\n\t_, ok := fields[\"key2\"]\n\tassert.Equal(t, false, ok)\n\tassert.Equal(t, \"value1\", fields[\"key1\"])\n}\n\nfunc TestUserSuppliedFieldDoesNotOverwriteDefaults(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithField(\"msg\", \"hello\").Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t})\n}\n\nfunc TestUserSuppliedMsgFieldHasPrefix(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithField(\"msg\", \"hello\").Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"test\", fields[\"msg\"])\n\t\tassert.Equal(t, \"hello\", fields[\"fields.msg\"])\n\t})\n}\n\nfunc TestUserSuppliedTimeFieldHasPrefix(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithField(\"time\", \"hello\").Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"hello\", fields[\"fields.time\"])\n\t})\n}\n\nfunc TestUserSuppliedLevelFieldHasPrefix(t *testing.T) {\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithField(\"level\", 1).Info(\"test\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, \"info\", fields[\"level\"])\n\t\tassert.Equal(t, 1.0, fields[\"fields.level\"]) // JSON has floats only\n\t})\n}\n\nfunc TestDefaultFieldsAreNotPrefixed(t *testing.T) {\n\tLogAndAssertText(t, func(log *Logger) {\n\t\tll := log.WithField(\"herp\", \"derp\")\n\t\tll.Info(\"hello\")\n\t\tll.Info(\"bye\")\n\t}, func(fields map[string]string) {\n\t\tfor _, fieldName := range []string{\"fields.level\", \"fields.time\", \"fields.msg\"} {\n\t\t\tif _, ok := fields[fieldName]; ok {\n\t\t\t\tt.Fatalf(\"should not have prefixed %q: %v\", fieldName, fields)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc TestWithTimeShouldOverrideTime(t *testing.T) {\n\tnow := time.Now().Add(24 * time.Hour)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithTime(now).Info(\"foobar\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, fields[\"time\"], now.Format(time.RFC3339))\n\t})\n}\n\nfunc TestWithTimeShouldNotOverrideFields(t *testing.T) {\n\tnow := time.Now().Add(24 * time.Hour)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithField(\"herp\", \"derp\").WithTime(now).Info(\"blah\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, fields[\"time\"], now.Format(time.RFC3339))\n\t\tassert.Equal(t, fields[\"herp\"], \"derp\")\n\t})\n}\n\nfunc TestWithFieldShouldNotOverrideTime(t *testing.T) {\n\tnow := time.Now().Add(24 * time.Hour)\n\n\tLogAndAssertJSON(t, func(log *Logger) {\n\t\tlog.WithTime(now).WithField(\"herp\", \"derp\").Info(\"blah\")\n\t}, func(fields Fields) {\n\t\tassert.Equal(t, fields[\"time\"], now.Format(time.RFC3339))\n\t\tassert.Equal(t, fields[\"herp\"], \"derp\")\n\t})\n}\n\nfunc TestTimeOverrideMultipleLogs(t *testing.T) {\n\tvar buffer bytes.Buffer\n\tvar firstFields, secondFields Fields\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tformatter := new(JSONFormatter)\n\tformatter.TimestampFormat = time.StampMilli\n\tlogger.Formatter = formatter\n\n\tllog := logger.WithField(\"herp\", \"derp\")\n\tllog.Info(\"foo\")\n\n\terr := json.Unmarshal(buffer.Bytes(), &firstFields)\n\tassert.NoError(t, err, \"should have decoded first message\")\n\n\tbuffer.Reset()\n\n\ttime.Sleep(10 * time.Millisecond)\n\tllog.Info(\"bar\")\n\n\terr = json.Unmarshal(buffer.Bytes(), &secondFields)\n\tassert.NoError(t, err, \"should have decoded second message\")\n\n\tassert.NotEqual(t, firstFields[\"time\"], secondFields[\"time\"], \"timestamps should not be equal\")\n}\n\nfunc TestDoubleLoggingDoesntPrefixPreviousFields(t *testing.T) {\n\n\tvar buffer bytes.Buffer\n\tvar fields Fields\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tlogger.Formatter = new(JSONFormatter)\n\n\tllog := logger.WithField(\"context\", \"eating raw fish\")\n\n\tllog.Info(\"looks delicious\")\n\n\terr := json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.NoError(t, err, \"should have decoded first message\")\n\tassert.Equal(t, len(fields), 4, \"should only have msg/time/level/context fields\")\n\tassert.Equal(t, fields[\"msg\"], \"looks delicious\")\n\tassert.Equal(t, fields[\"context\"], \"eating raw fish\")\n\n\tbuffer.Reset()\n\n\tllog.Warn(\"omg it is!\")\n\n\terr = json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.NoError(t, err, \"should have decoded second message\")\n\tassert.Equal(t, len(fields), 4, \"should only have msg/time/level/context fields\")\n\tassert.Equal(t, \"omg it is!\", fields[\"msg\"])\n\tassert.Equal(t, \"eating raw fish\", fields[\"context\"])\n\tassert.Nil(t, fields[\"fields.msg\"], \"should not have prefixed previous `msg` entry\")\n\n}\n\nfunc TestNestedLoggingReportsCorrectCaller(t *testing.T) {\n\tvar buffer bytes.Buffer\n\tvar fields Fields\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tlogger.Formatter = new(JSONFormatter)\n\tlogger.ReportCaller = true\n\n\tllog := logger.WithField(\"context\", \"eating raw fish\")\n\n\tllog.Info(\"looks delicious\")\n\t_, _, line, _ := runtime.Caller(0)\n\n\terr := json.Unmarshal(buffer.Bytes(), &fields)\n\trequire.NoError(t, err, \"should have decoded first message\")\n\tassert.Equal(t, 6, len(fields), \"should have msg/time/level/func/context fields\")\n\tassert.Equal(t, \"looks delicious\", fields[\"msg\"])\n\tassert.Equal(t, \"eating raw fish\", fields[\"context\"])\n\tassert.Equal(t,\n\t\t\"github.com/sirupsen/logrus_test.TestNestedLoggingReportsCorrectCaller\", fields[\"func\"])\n\tcwd, err := os.Getwd()\n\trequire.NoError(t, err)\n\tassert.Equal(t, filepath.ToSlash(fmt.Sprintf(\"%s/logrus_test.go:%d\", cwd, line-1)), filepath.ToSlash(fields[\"file\"].(string)))\n\n\tbuffer.Reset()\n\n\tlogger.WithFields(Fields{\n\t\t\"Clyde\": \"Stubblefield\",\n\t}).WithFields(Fields{\n\t\t\"Jab'o\": \"Starks\",\n\t}).WithFields(Fields{\n\t\t\"uri\": \"https://www.youtube.com/watch?v=V5DTznu-9v0\",\n\t}).WithFields(Fields{\n\t\t\"func\": \"y drummer\",\n\t}).WithFields(Fields{\n\t\t\"James\": \"Brown\",\n\t}).Print(\"The hardest workin' man in show business\")\n\t_, _, line, _ = runtime.Caller(0)\n\n\terr = json.Unmarshal(buffer.Bytes(), &fields)\n\tassert.NoError(t, err, \"should have decoded second message\")\n\tassert.Equal(t, 11, len(fields), \"should have all builtin fields plus foo,bar,baz,...\")\n\tassert.Equal(t, \"Stubblefield\", fields[\"Clyde\"])\n\tassert.Equal(t, \"Starks\", fields[\"Jab'o\"])\n\tassert.Equal(t, \"https://www.youtube.com/watch?v=V5DTznu-9v0\", fields[\"uri\"])\n\tassert.Equal(t, \"y drummer\", fields[\"fields.func\"])\n\tassert.Equal(t, \"Brown\", fields[\"James\"])\n\tassert.Equal(t, \"The hardest workin' man in show business\", fields[\"msg\"])\n\tassert.Nil(t, fields[\"fields.msg\"], \"should not have prefixed previous `msg` entry\")\n\tassert.Equal(t,\n\t\t\"github.com/sirupsen/logrus_test.TestNestedLoggingReportsCorrectCaller\", fields[\"func\"])\n\trequire.NoError(t, err)\n\tassert.Equal(t, filepath.ToSlash(fmt.Sprintf(\"%s/logrus_test.go:%d\", cwd, line-1)), filepath.ToSlash(fields[\"file\"].(string)))\n\n\tlogger.ReportCaller = false // return to default value\n}\n\nfunc logLoop(iterations int, reportCaller bool) {\n\tvar buffer bytes.Buffer\n\n\tlogger := New()\n\tlogger.Out = &buffer\n\tlogger.Formatter = new(JSONFormatter)\n\tlogger.ReportCaller = reportCaller\n\n\tfor i := 0; i < iterations; i++ {\n\t\tlogger.Infof(\"round %d of %d\", i, iterations)\n\t}\n}\n\n// Assertions for upper bounds to reporting overhead\nfunc TestCallerReportingOverhead(t *testing.T) {\n\titerations := 5000\n\tbefore := time.Now()\n\tlogLoop(iterations, false)\n\tduring := time.Now()\n\tlogLoop(iterations, true)\n\tafter := time.Now()\n\n\telapsedNotReporting := during.Sub(before).Nanoseconds()\n\telapsedReporting := after.Sub(during).Nanoseconds()\n\n\tmaxDelta := 1 * time.Second\n\tassert.WithinDuration(t, during, before, maxDelta,\n\t\t\"%d log calls without caller name lookup takes less than %d second(s) (was %d nanoseconds)\",\n\t\titerations, maxDelta.Seconds(), elapsedNotReporting)\n\tassert.WithinDuration(t, after, during, maxDelta,\n\t\t\"%d log calls without caller name lookup takes less than %d second(s) (was %d nanoseconds)\",\n\t\titerations, maxDelta.Seconds(), elapsedReporting)\n}\n\n// benchmarks for both with and without caller-function reporting\nfunc BenchmarkWithoutCallerTracing(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tlogLoop(1000, false)\n\t}\n}\n\nfunc BenchmarkWithCallerTracing(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tlogLoop(1000, true)\n\t}\n}\n\nfunc TestConvertLevelToString(t *testing.T) {\n\tassert.Equal(t, \"trace\", TraceLevel.String())\n\tassert.Equal(t, \"debug\", DebugLevel.String())\n\tassert.Equal(t, \"info\", InfoLevel.String())\n\tassert.Equal(t, \"warning\", WarnLevel.String())\n\tassert.Equal(t, \"error\", ErrorLevel.String())\n\tassert.Equal(t, \"fatal\", FatalLevel.String())\n\tassert.Equal(t, \"panic\", PanicLevel.String())\n}\n\nfunc TestParseLevel(t *testing.T) {\n\tl, err := ParseLevel(\"panic\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, PanicLevel, l)\n\n\tl, err = ParseLevel(\"PANIC\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, PanicLevel, l)\n\n\tl, err = ParseLevel(\"fatal\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, FatalLevel, l)\n\n\tl, err = ParseLevel(\"FATAL\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, FatalLevel, l)\n\n\tl, err = ParseLevel(\"error\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, ErrorLevel, l)\n\n\tl, err = ParseLevel(\"ERROR\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, ErrorLevel, l)\n\n\tl, err = ParseLevel(\"warn\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, WarnLevel, l)\n\n\tl, err = ParseLevel(\"WARN\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, WarnLevel, l)\n\n\tl, err = ParseLevel(\"warning\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, WarnLevel, l)\n\n\tl, err = ParseLevel(\"WARNING\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, WarnLevel, l)\n\n\tl, err = ParseLevel(\"info\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, InfoLevel, l)\n\n\tl, err = ParseLevel(\"INFO\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, InfoLevel, l)\n\n\tl, err = ParseLevel(\"debug\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, DebugLevel, l)\n\n\tl, err = ParseLevel(\"DEBUG\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, DebugLevel, l)\n\n\tl, err = ParseLevel(\"trace\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, TraceLevel, l)\n\n\tl, err = ParseLevel(\"TRACE\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, TraceLevel, l)\n\n\t_, err = ParseLevel(\"invalid\")\n\tassert.Equal(t, \"not a valid logrus Level: \\\"invalid\\\"\", err.Error())\n}\n\nfunc TestLevelString(t *testing.T) {\n\tvar loggerlevel Level = 32000\n\n\t_ = loggerlevel.String()\n}\n\nfunc TestGetSetLevelRace(t *testing.T) {\n\twg := sync.WaitGroup{}\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tif i%2 == 0 {\n\t\t\t\tSetLevel(InfoLevel)\n\t\t\t} else {\n\t\t\t\tGetLevel()\n\t\t\t}\n\t\t}(i)\n\n\t}\n\twg.Wait()\n}\n\nfunc TestLoggingRace(t *testing.T) {\n\tlogger := New()\n\n\tvar wg sync.WaitGroup\n\twg.Add(100)\n\n\tfor i := 0; i < 100; i++ {\n\t\tgo func() {\n\t\t\tlogger.Info(\"info\")\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n}\n\nfunc TestLoggingRaceWithHooksOnEntry(t *testing.T) {\n\tlogger := New()\n\thook := new(ModifyHook)\n\tlogger.AddHook(hook)\n\tentry := logger.WithField(\"context\", \"clue\")\n\n\tvar (\n\t\twg    sync.WaitGroup\n\t\tmtx   sync.Mutex\n\t\tstart bool\n\t)\n\n\tcond := sync.NewCond(&mtx)\n\n\twg.Add(100)\n\n\tfor i := 0; i < 50; i++ {\n\t\tgo func() {\n\t\t\tcond.L.Lock()\n\t\t\tfor !start {\n\t\t\t\tcond.Wait()\n\t\t\t}\n\t\t\tcond.L.Unlock()\n\t\t\tfor j := 0; j < 100; j++ {\n\t\t\t\tentry.Info(\"info\")\n\t\t\t}\n\t\t\twg.Done()\n\t\t}()\n\t}\n\n\tfor i := 0; i < 50; i++ {\n\t\tgo func() {\n\t\t\tcond.L.Lock()\n\t\t\tfor !start {\n\t\t\t\tcond.Wait()\n\t\t\t}\n\t\t\tcond.L.Unlock()\n\t\t\tfor j := 0; j < 100; j++ {\n\t\t\t\tentry.WithField(\"another field\", \"with some data\").Info(\"info\")\n\t\t\t}\n\t\t\twg.Done()\n\t\t}()\n\t}\n\n\tcond.L.Lock()\n\tstart = true\n\tcond.L.Unlock()\n\tcond.Broadcast()\n\twg.Wait()\n}\n\nfunc TestReplaceHooks(t *testing.T) {\n\told, cur := &TestHook{}, &TestHook{}\n\n\tlogger := New()\n\tlogger.SetOutput(ioutil.Discard)\n\tlogger.AddHook(old)\n\n\thooks := make(LevelHooks)\n\thooks.Add(cur)\n\treplaced := logger.ReplaceHooks(hooks)\n\n\tlogger.Info(\"test\")\n\n\tassert.Equal(t, old.Fired, false)\n\tassert.Equal(t, cur.Fired, true)\n\n\tlogger.ReplaceHooks(replaced)\n\tlogger.Info(\"test\")\n\tassert.Equal(t, old.Fired, true)\n}\n\n// Compile test\nfunc TestLogrusInterfaces(t *testing.T) {\n\tvar buffer bytes.Buffer\n\t// This verifies FieldLogger and Ext1FieldLogger work as designed.\n\t// Please don't use them. Use Logger and Entry directly.\n\tfn := func(xl Ext1FieldLogger) {\n\t\tvar l FieldLogger = xl\n\t\tb := l.WithField(\"key\", \"value\")\n\t\tb.Debug(\"Test\")\n\t}\n\t// test logger\n\tlogger := New()\n\tlogger.Out = &buffer\n\tfn(logger)\n\n\t// test Entry\n\te := logger.WithField(\"another\", \"value\")\n\tfn(e)\n}\n\n// Implements io.Writer using channels for synchronization, so we can wait on\n// the Entry.Writer goroutine to write in a non-racey way. This does assume that\n// there is a single call to Logger.Out for each message.\ntype channelWriter chan []byte\n\nfunc (cw channelWriter) Write(p []byte) (int, error) {\n\tcw <- p\n\treturn len(p), nil\n}\n\nfunc TestEntryWriter(t *testing.T) {\n\tcw := channelWriter(make(chan []byte, 1))\n\tlog := New()\n\tlog.Out = cw\n\tlog.Formatter = new(JSONFormatter)\n\t_, err := log.WithField(\"foo\", \"bar\").WriterLevel(WarnLevel).Write([]byte(\"hello\\n\"))\n\tif err != nil {\n\t\tt.Error(\"unexecpted error\", err)\n\t}\n\n\tbs := <-cw\n\tvar fields Fields\n\terr = json.Unmarshal(bs, &fields)\n\tassert.Nil(t, err)\n\tassert.Equal(t, fields[\"foo\"], \"bar\")\n\tassert.Equal(t, fields[\"level\"], \"warning\")\n}\n\nfunc TestLogLevelEnabled(t *testing.T) {\n\tlog := New()\n\tlog.SetLevel(PanicLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(FatalLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(ErrorLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(WarnLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(InfoLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(DebugLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, false, log.IsLevelEnabled(TraceLevel))\n\n\tlog.SetLevel(TraceLevel)\n\tassert.Equal(t, true, log.IsLevelEnabled(PanicLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(FatalLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(ErrorLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(WarnLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(InfoLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(DebugLevel))\n\tassert.Equal(t, true, log.IsLevelEnabled(TraceLevel))\n}\n\nfunc TestReportCallerOnTextFormatter(t *testing.T) {\n\tl := New()\n\n\tl.Formatter.(*TextFormatter).ForceColors = true\n\tl.Formatter.(*TextFormatter).DisableColors = false\n\tl.WithFields(Fields{\"func\": \"func\", \"file\": \"file\"}).Info(\"test\")\n\n\tl.Formatter.(*TextFormatter).ForceColors = false\n\tl.Formatter.(*TextFormatter).DisableColors = true\n\tl.WithFields(Fields{\"func\": \"func\", \"file\": \"file\"}).Info(\"test\")\n}\n\nfunc TestSetReportCallerRace(t *testing.T) {\n\tl := New()\n\tl.Out = ioutil.Discard\n\tl.SetReportCaller(true)\n\n\tvar wg sync.WaitGroup\n\twg.Add(100)\n\n\tfor i := 0; i < 100; i++ {\n\t\tgo func() {\n\t\t\tl.Error(\"Some Error\")\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n}\n"
        },
        {
          "name": "terminal_check_appengine.go",
          "type": "blob",
          "size": 0.1083984375,
          "content": "// +build appengine\n\npackage logrus\n\nimport (\n\t\"io\"\n)\n\nfunc checkIfTerminal(w io.Writer) bool {\n\treturn true\n}\n"
        },
        {
          "name": "terminal_check_bsd.go",
          "type": "blob",
          "size": 0.2578125,
          "content": "// +build darwin dragonfly freebsd netbsd openbsd hurd\n// +build !js\n\npackage logrus\n\nimport \"golang.org/x/sys/unix\"\n\nconst ioctlReadTermios = unix.TIOCGETA\n\nfunc isTerminal(fd int) bool {\n\t_, err := unix.IoctlGetTermios(fd, ioctlReadTermios)\n\treturn err == nil\n}\n"
        },
        {
          "name": "terminal_check_js.go",
          "type": "blob",
          "size": 0.0751953125,
          "content": "// +build js\n\npackage logrus\n\nfunc isTerminal(fd int) bool {\n\treturn false\n}\n"
        },
        {
          "name": "terminal_check_no_terminal.go",
          "type": "blob",
          "size": 0.11328125,
          "content": "// +build js nacl plan9\n\npackage logrus\n\nimport (\n\t\"io\"\n)\n\nfunc checkIfTerminal(w io.Writer) bool {\n\treturn false\n}\n"
        },
        {
          "name": "terminal_check_notappengine.go",
          "type": "blob",
          "size": 0.2265625,
          "content": "// +build !appengine,!js,!windows,!nacl,!plan9\n\npackage logrus\n\nimport (\n\t\"io\"\n\t\"os\"\n)\n\nfunc checkIfTerminal(w io.Writer) bool {\n\tswitch v := w.(type) {\n\tcase *os.File:\n\t\treturn isTerminal(int(v.Fd()))\n\tdefault:\n\t\treturn false\n\t}\n}\n"
        },
        {
          "name": "terminal_check_solaris.go",
          "type": "blob",
          "size": 0.21875,
          "content": "package logrus\n\nimport (\n\t\"golang.org/x/sys/unix\"\n)\n\n// IsTerminal returns true if the given file descriptor is a terminal.\nfunc isTerminal(fd int) bool {\n\t_, err := unix.IoctlGetTermio(fd, unix.TCGETA)\n\treturn err == nil\n}\n"
        },
        {
          "name": "terminal_check_unix.go",
          "type": "blob",
          "size": 0.2890625,
          "content": "//go:build (linux || aix || zos) && !js && !wasi\n// +build linux aix zos\n// +build !js\n// +build !wasi\n\npackage logrus\n\nimport \"golang.org/x/sys/unix\"\n\nconst ioctlReadTermios = unix.TCGETS\n\nfunc isTerminal(fd int) bool {\n\t_, err := unix.IoctlGetTermios(fd, ioctlReadTermios)\n\treturn err == nil\n}\n"
        },
        {
          "name": "terminal_check_wasi.go",
          "type": "blob",
          "size": 0.0927734375,
          "content": "//go:build wasi\n// +build wasi\n\npackage logrus\n\nfunc isTerminal(fd int) bool {\n\treturn false\n}\n"
        },
        {
          "name": "terminal_check_wasip1.go",
          "type": "blob",
          "size": 0.0966796875,
          "content": "//go:build wasip1\n// +build wasip1\n\npackage logrus\n\nfunc isTerminal(fd int) bool {\n\treturn false\n}\n"
        },
        {
          "name": "terminal_check_windows.go",
          "type": "blob",
          "size": 0.478515625,
          "content": "// +build !appengine,!js,windows\n\npackage logrus\n\nimport (\n\t\"io\"\n\t\"os\"\n\n\t\"golang.org/x/sys/windows\"\n)\n\nfunc checkIfTerminal(w io.Writer) bool {\n\tswitch v := w.(type) {\n\tcase *os.File:\n\t\thandle := windows.Handle(v.Fd())\n\t\tvar mode uint32\n\t\tif err := windows.GetConsoleMode(handle, &mode); err != nil {\n\t\t\treturn false\n\t\t}\n\t\tmode |= windows.ENABLE_VIRTUAL_TERMINAL_PROCESSING\n\t\tif err := windows.SetConsoleMode(handle, mode); err != nil {\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t}\n\treturn false\n}\n"
        },
        {
          "name": "text_formatter.go",
          "type": "blob",
          "size": 8.9541015625,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"os\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\t\"unicode/utf8\"\n)\n\nconst (\n\tred    = 31\n\tyellow = 33\n\tblue   = 36\n\tgray   = 37\n)\n\nvar baseTimestamp time.Time\n\nfunc init() {\n\tbaseTimestamp = time.Now()\n}\n\n// TextFormatter formats logs into text\ntype TextFormatter struct {\n\t// Set to true to bypass checking for a TTY before outputting colors.\n\tForceColors bool\n\n\t// Force disabling colors.\n\tDisableColors bool\n\n\t// Force quoting of all values\n\tForceQuote bool\n\n\t// DisableQuote disables quoting for all values.\n\t// DisableQuote will have a lower priority than ForceQuote.\n\t// If both of them are set to true, quote will be forced on all values.\n\tDisableQuote bool\n\n\t// Override coloring based on CLICOLOR and CLICOLOR_FORCE. - https://bixense.com/clicolors/\n\tEnvironmentOverrideColors bool\n\n\t// Disable timestamp logging. useful when output is redirected to logging\n\t// system that already adds timestamps.\n\tDisableTimestamp bool\n\n\t// Enable logging the full timestamp when a TTY is attached instead of just\n\t// the time passed since beginning of execution.\n\tFullTimestamp bool\n\n\t// TimestampFormat to use for display when a full timestamp is printed.\n\t// The format to use is the same than for time.Format or time.Parse from the standard\n\t// library.\n\t// The standard Library already provides a set of predefined format.\n\tTimestampFormat string\n\n\t// The fields are sorted by default for a consistent output. For applications\n\t// that log extremely frequently and don't use the JSON formatter this may not\n\t// be desired.\n\tDisableSorting bool\n\n\t// The keys sorting function, when uninitialized it uses sort.Strings.\n\tSortingFunc func([]string)\n\n\t// Disables the truncation of the level text to 4 characters.\n\tDisableLevelTruncation bool\n\n\t// PadLevelText Adds padding the level text so that all the levels output at the same length\n\t// PadLevelText is a superset of the DisableLevelTruncation option\n\tPadLevelText bool\n\n\t// QuoteEmptyFields will wrap empty fields in quotes if true\n\tQuoteEmptyFields bool\n\n\t// Whether the logger's out is to a terminal\n\tisTerminal bool\n\n\t// FieldMap allows users to customize the names of keys for default fields.\n\t// As an example:\n\t// formatter := &TextFormatter{\n\t//     FieldMap: FieldMap{\n\t//         FieldKeyTime:  \"@timestamp\",\n\t//         FieldKeyLevel: \"@level\",\n\t//         FieldKeyMsg:   \"@message\"}}\n\tFieldMap FieldMap\n\n\t// CallerPrettyfier can be set by the user to modify the content\n\t// of the function and file keys in the data when ReportCaller is\n\t// activated. If any of the returned value is the empty string the\n\t// corresponding key will be removed from fields.\n\tCallerPrettyfier func(*runtime.Frame) (function string, file string)\n\n\tterminalInitOnce sync.Once\n\n\t// The max length of the level text, generated dynamically on init\n\tlevelTextMaxLength int\n}\n\nfunc (f *TextFormatter) init(entry *Entry) {\n\tif entry.Logger != nil {\n\t\tf.isTerminal = checkIfTerminal(entry.Logger.Out)\n\t}\n\t// Get the max length of the level text\n\tfor _, level := range AllLevels {\n\t\tlevelTextLength := utf8.RuneCount([]byte(level.String()))\n\t\tif levelTextLength > f.levelTextMaxLength {\n\t\t\tf.levelTextMaxLength = levelTextLength\n\t\t}\n\t}\n}\n\nfunc (f *TextFormatter) isColored() bool {\n\tisColored := f.ForceColors || (f.isTerminal && (runtime.GOOS != \"windows\"))\n\n\tif f.EnvironmentOverrideColors {\n\t\tswitch force, ok := os.LookupEnv(\"CLICOLOR_FORCE\"); {\n\t\tcase ok && force != \"0\":\n\t\t\tisColored = true\n\t\tcase ok && force == \"0\", os.Getenv(\"CLICOLOR\") == \"0\":\n\t\t\tisColored = false\n\t\t}\n\t}\n\n\treturn isColored && !f.DisableColors\n}\n\n// Format renders a single log entry\nfunc (f *TextFormatter) Format(entry *Entry) ([]byte, error) {\n\tdata := make(Fields)\n\tfor k, v := range entry.Data {\n\t\tdata[k] = v\n\t}\n\tprefixFieldClashes(data, f.FieldMap, entry.HasCaller())\n\tkeys := make([]string, 0, len(data))\n\tfor k := range data {\n\t\tkeys = append(keys, k)\n\t}\n\n\tvar funcVal, fileVal string\n\n\tfixedKeys := make([]string, 0, 4+len(data))\n\tif !f.DisableTimestamp {\n\t\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyTime))\n\t}\n\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyLevel))\n\tif entry.Message != \"\" {\n\t\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyMsg))\n\t}\n\tif entry.err != \"\" {\n\t\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyLogrusError))\n\t}\n\tif entry.HasCaller() {\n\t\tif f.CallerPrettyfier != nil {\n\t\t\tfuncVal, fileVal = f.CallerPrettyfier(entry.Caller)\n\t\t} else {\n\t\t\tfuncVal = entry.Caller.Function\n\t\t\tfileVal = fmt.Sprintf(\"%s:%d\", entry.Caller.File, entry.Caller.Line)\n\t\t}\n\n\t\tif funcVal != \"\" {\n\t\t\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyFunc))\n\t\t}\n\t\tif fileVal != \"\" {\n\t\t\tfixedKeys = append(fixedKeys, f.FieldMap.resolve(FieldKeyFile))\n\t\t}\n\t}\n\n\tif !f.DisableSorting {\n\t\tif f.SortingFunc == nil {\n\t\t\tsort.Strings(keys)\n\t\t\tfixedKeys = append(fixedKeys, keys...)\n\t\t} else {\n\t\t\tif !f.isColored() {\n\t\t\t\tfixedKeys = append(fixedKeys, keys...)\n\t\t\t\tf.SortingFunc(fixedKeys)\n\t\t\t} else {\n\t\t\t\tf.SortingFunc(keys)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfixedKeys = append(fixedKeys, keys...)\n\t}\n\n\tvar b *bytes.Buffer\n\tif entry.Buffer != nil {\n\t\tb = entry.Buffer\n\t} else {\n\t\tb = &bytes.Buffer{}\n\t}\n\n\tf.terminalInitOnce.Do(func() { f.init(entry) })\n\n\ttimestampFormat := f.TimestampFormat\n\tif timestampFormat == \"\" {\n\t\ttimestampFormat = defaultTimestampFormat\n\t}\n\tif f.isColored() {\n\t\tf.printColored(b, entry, keys, data, timestampFormat)\n\t} else {\n\n\t\tfor _, key := range fixedKeys {\n\t\t\tvar value interface{}\n\t\t\tswitch {\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyTime):\n\t\t\t\tvalue = entry.Time.Format(timestampFormat)\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyLevel):\n\t\t\t\tvalue = entry.Level.String()\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyMsg):\n\t\t\t\tvalue = entry.Message\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyLogrusError):\n\t\t\t\tvalue = entry.err\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyFunc) && entry.HasCaller():\n\t\t\t\tvalue = funcVal\n\t\t\tcase key == f.FieldMap.resolve(FieldKeyFile) && entry.HasCaller():\n\t\t\t\tvalue = fileVal\n\t\t\tdefault:\n\t\t\t\tvalue = data[key]\n\t\t\t}\n\t\t\tf.appendKeyValue(b, key, value)\n\t\t}\n\t}\n\n\tb.WriteByte('\\n')\n\treturn b.Bytes(), nil\n}\n\nfunc (f *TextFormatter) printColored(b *bytes.Buffer, entry *Entry, keys []string, data Fields, timestampFormat string) {\n\tvar levelColor int\n\tswitch entry.Level {\n\tcase DebugLevel, TraceLevel:\n\t\tlevelColor = gray\n\tcase WarnLevel:\n\t\tlevelColor = yellow\n\tcase ErrorLevel, FatalLevel, PanicLevel:\n\t\tlevelColor = red\n\tcase InfoLevel:\n\t\tlevelColor = blue\n\tdefault:\n\t\tlevelColor = blue\n\t}\n\n\tlevelText := strings.ToUpper(entry.Level.String())\n\tif !f.DisableLevelTruncation && !f.PadLevelText {\n\t\tlevelText = levelText[0:4]\n\t}\n\tif f.PadLevelText {\n\t\t// Generates the format string used in the next line, for example \"%-6s\" or \"%-7s\".\n\t\t// Based on the max level text length.\n\t\tformatString := \"%-\" + strconv.Itoa(f.levelTextMaxLength) + \"s\"\n\t\t// Formats the level text by appending spaces up to the max length, for example:\n\t\t// \t- \"INFO   \"\n\t\t//\t- \"WARNING\"\n\t\tlevelText = fmt.Sprintf(formatString, levelText)\n\t}\n\n\t// Remove a single newline if it already exists in the message to keep\n\t// the behavior of logrus text_formatter the same as the stdlib log package\n\tentry.Message = strings.TrimSuffix(entry.Message, \"\\n\")\n\n\tcaller := \"\"\n\tif entry.HasCaller() {\n\t\tfuncVal := fmt.Sprintf(\"%s()\", entry.Caller.Function)\n\t\tfileVal := fmt.Sprintf(\"%s:%d\", entry.Caller.File, entry.Caller.Line)\n\n\t\tif f.CallerPrettyfier != nil {\n\t\t\tfuncVal, fileVal = f.CallerPrettyfier(entry.Caller)\n\t\t}\n\n\t\tif fileVal == \"\" {\n\t\t\tcaller = funcVal\n\t\t} else if funcVal == \"\" {\n\t\t\tcaller = fileVal\n\t\t} else {\n\t\t\tcaller = fileVal + \" \" + funcVal\n\t\t}\n\t}\n\n\tswitch {\n\tcase f.DisableTimestamp:\n\t\tfmt.Fprintf(b, \"\\x1b[%dm%s\\x1b[0m%s %-44s \", levelColor, levelText, caller, entry.Message)\n\tcase !f.FullTimestamp:\n\t\tfmt.Fprintf(b, \"\\x1b[%dm%s\\x1b[0m[%04d]%s %-44s \", levelColor, levelText, int(entry.Time.Sub(baseTimestamp)/time.Second), caller, entry.Message)\n\tdefault:\n\t\tfmt.Fprintf(b, \"\\x1b[%dm%s\\x1b[0m[%s]%s %-44s \", levelColor, levelText, entry.Time.Format(timestampFormat), caller, entry.Message)\n\t}\n\tfor _, k := range keys {\n\t\tv := data[k]\n\t\tfmt.Fprintf(b, \" \\x1b[%dm%s\\x1b[0m=\", levelColor, k)\n\t\tf.appendValue(b, v)\n\t}\n}\n\nfunc (f *TextFormatter) needsQuoting(text string) bool {\n\tif f.ForceQuote {\n\t\treturn true\n\t}\n\tif f.QuoteEmptyFields && len(text) == 0 {\n\t\treturn true\n\t}\n\tif f.DisableQuote {\n\t\treturn false\n\t}\n\tfor _, ch := range text {\n\t\tif !((ch >= 'a' && ch <= 'z') ||\n\t\t\t(ch >= 'A' && ch <= 'Z') ||\n\t\t\t(ch >= '0' && ch <= '9') ||\n\t\t\tch == '-' || ch == '.' || ch == '_' || ch == '/' || ch == '@' || ch == '^' || ch == '+') {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (f *TextFormatter) appendKeyValue(b *bytes.Buffer, key string, value interface{}) {\n\tif b.Len() > 0 {\n\t\tb.WriteByte(' ')\n\t}\n\tb.WriteString(key)\n\tb.WriteByte('=')\n\tf.appendValue(b, value)\n}\n\nfunc (f *TextFormatter) appendValue(b *bytes.Buffer, value interface{}) {\n\tstringVal, ok := value.(string)\n\tif !ok {\n\t\tstringVal = fmt.Sprint(value)\n\t}\n\n\tif !f.needsQuoting(stringVal) {\n\t\tb.WriteString(stringVal)\n\t} else {\n\t\tb.WriteString(fmt.Sprintf(\"%q\", stringVal))\n\t}\n}\n"
        },
        {
          "name": "text_formatter_test.go",
          "type": "blob",
          "size": 16.8779296875,
          "content": "package logrus\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestFormatting(t *testing.T) {\n\ttf := &TextFormatter{DisableColors: true}\n\n\ttestCases := []struct {\n\t\tvalue    string\n\t\texpected string\n\t}{\n\t\t{`foo`, \"time=\\\"0001-01-01T00:00:00Z\\\" level=panic test=foo\\n\"},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tb, _ := tf.Format(WithField(\"test\", tc.value))\n\n\t\tif string(b) != tc.expected {\n\t\t\tt.Errorf(\"formatting expected for %q (result was %q instead of %q)\", tc.value, string(b), tc.expected)\n\t\t}\n\t}\n}\n\nfunc TestQuoting(t *testing.T) {\n\ttf := &TextFormatter{DisableColors: true}\n\n\tcheckQuoting := func(q bool, value interface{}) {\n\t\tb, _ := tf.Format(WithField(\"test\", value))\n\t\tidx := bytes.Index(b, ([]byte)(\"test=\"))\n\t\tcont := bytes.Contains(b[idx+5:], []byte(\"\\\"\"))\n\t\tif cont != q {\n\t\t\tif q {\n\t\t\t\tt.Errorf(\"quoting expected for: %#v\", value)\n\t\t\t} else {\n\t\t\t\tt.Errorf(\"quoting not expected for: %#v\", value)\n\t\t\t}\n\t\t}\n\t}\n\n\tcheckQuoting(false, \"\")\n\tcheckQuoting(false, \"abcd\")\n\tcheckQuoting(false, \"v1.0\")\n\tcheckQuoting(false, \"1234567890\")\n\tcheckQuoting(false, \"/foobar\")\n\tcheckQuoting(false, \"foo_bar\")\n\tcheckQuoting(false, \"foo@bar\")\n\tcheckQuoting(false, \"foobar^\")\n\tcheckQuoting(false, \"+/-_^@f.oobar\")\n\tcheckQuoting(true, \"foo\\n\\rbar\")\n\tcheckQuoting(true, \"foobar$\")\n\tcheckQuoting(true, \"&foobar\")\n\tcheckQuoting(true, \"x y\")\n\tcheckQuoting(true, \"x,y\")\n\tcheckQuoting(false, errors.New(\"invalid\"))\n\tcheckQuoting(true, errors.New(\"invalid argument\"))\n\n\t// Test for quoting empty fields.\n\ttf.QuoteEmptyFields = true\n\tcheckQuoting(true, \"\")\n\tcheckQuoting(false, \"abcd\")\n\tcheckQuoting(true, \"foo\\n\\rbar\")\n\tcheckQuoting(true, errors.New(\"invalid argument\"))\n\n\t// Test forcing quotes.\n\ttf.ForceQuote = true\n\tcheckQuoting(true, \"\")\n\tcheckQuoting(true, \"abcd\")\n\tcheckQuoting(true, \"foo\\n\\rbar\")\n\tcheckQuoting(true, errors.New(\"invalid argument\"))\n\n\t// Test forcing quotes when also disabling them.\n\ttf.DisableQuote = true\n\tcheckQuoting(true, \"\")\n\tcheckQuoting(true, \"abcd\")\n\tcheckQuoting(true, \"foo\\n\\rbar\")\n\tcheckQuoting(true, errors.New(\"invalid argument\"))\n\n\t// Test disabling quotes\n\ttf.ForceQuote = false\n\ttf.QuoteEmptyFields = false\n\tcheckQuoting(false, \"\")\n\tcheckQuoting(false, \"abcd\")\n\tcheckQuoting(false, \"foo\\n\\rbar\")\n\tcheckQuoting(false, errors.New(\"invalid argument\"))\n}\n\nfunc TestEscaping(t *testing.T) {\n\ttf := &TextFormatter{DisableColors: true}\n\n\ttestCases := []struct {\n\t\tvalue    string\n\t\texpected string\n\t}{\n\t\t{`ba\"r`, `ba\\\"r`},\n\t\t{`ba'r`, `ba'r`},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tb, _ := tf.Format(WithField(\"test\", tc.value))\n\t\tif !bytes.Contains(b, []byte(tc.expected)) {\n\t\t\tt.Errorf(\"escaping expected for %q (result was %q instead of %q)\", tc.value, string(b), tc.expected)\n\t\t}\n\t}\n}\n\nfunc TestEscaping_Interface(t *testing.T) {\n\ttf := &TextFormatter{DisableColors: true}\n\n\tts := time.Now()\n\n\ttestCases := []struct {\n\t\tvalue    interface{}\n\t\texpected string\n\t}{\n\t\t{ts, fmt.Sprintf(\"\\\"%s\\\"\", ts.String())},\n\t\t{errors.New(\"error: something went wrong\"), \"\\\"error: something went wrong\\\"\"},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tb, _ := tf.Format(WithField(\"test\", tc.value))\n\t\tif !bytes.Contains(b, []byte(tc.expected)) {\n\t\t\tt.Errorf(\"escaping expected for %q (result was %q instead of %q)\", tc.value, string(b), tc.expected)\n\t\t}\n\t}\n}\n\nfunc TestTimestampFormat(t *testing.T) {\n\tcheckTimeStr := func(format string) {\n\t\tcustomFormatter := &TextFormatter{DisableColors: true, TimestampFormat: format}\n\t\tcustomStr, _ := customFormatter.Format(WithField(\"test\", \"test\"))\n\t\ttimeStart := bytes.Index(customStr, ([]byte)(\"time=\"))\n\t\ttimeEnd := bytes.Index(customStr, ([]byte)(\"level=\"))\n\t\ttimeStr := customStr[timeStart+5+len(\"\\\"\") : timeEnd-1-len(\"\\\"\")]\n\t\tif format == \"\" {\n\t\t\tformat = time.RFC3339\n\t\t}\n\t\t_, e := time.Parse(format, (string)(timeStr))\n\t\tif e != nil {\n\t\t\tt.Errorf(\"time string \\\"%s\\\" did not match provided time format \\\"%s\\\": %s\", timeStr, format, e)\n\t\t}\n\t}\n\n\tcheckTimeStr(\"2006-01-02T15:04:05.000000000Z07:00\")\n\tcheckTimeStr(\"Mon Jan _2 15:04:05 2006\")\n\tcheckTimeStr(\"\")\n}\n\nfunc TestDisableLevelTruncation(t *testing.T) {\n\tentry := &Entry{\n\t\tTime:    time.Now(),\n\t\tMessage: \"testing\",\n\t}\n\tkeys := []string{}\n\ttimestampFormat := \"Mon Jan 2 15:04:05 -0700 MST 2006\"\n\tcheckDisableTruncation := func(disabled bool, level Level) {\n\t\ttf := &TextFormatter{DisableLevelTruncation: disabled}\n\t\tvar b bytes.Buffer\n\t\tentry.Level = level\n\t\ttf.printColored(&b, entry, keys, nil, timestampFormat)\n\t\tlogLine := (&b).String()\n\t\tif disabled {\n\t\t\texpected := strings.ToUpper(level.String())\n\t\t\tif !strings.Contains(logLine, expected) {\n\t\t\t\tt.Errorf(\"level string expected to be %s when truncation disabled\", expected)\n\t\t\t}\n\t\t} else {\n\t\t\texpected := strings.ToUpper(level.String())\n\t\t\tif len(level.String()) > 4 {\n\t\t\t\tif strings.Contains(logLine, expected) {\n\t\t\t\t\tt.Errorf(\"level string %s expected to be truncated to %s when truncation is enabled\", expected, expected[0:4])\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif !strings.Contains(logLine, expected) {\n\t\t\t\t\tt.Errorf(\"level string expected to be %s when truncation is enabled and level string is below truncation threshold\", expected)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tcheckDisableTruncation(true, DebugLevel)\n\tcheckDisableTruncation(true, InfoLevel)\n\tcheckDisableTruncation(false, ErrorLevel)\n\tcheckDisableTruncation(false, InfoLevel)\n}\n\nfunc TestPadLevelText(t *testing.T) {\n\t// A note for future maintainers / committers:\n\t//\n\t// This test denormalizes the level text as a part of its assertions.\n\t// Because of that, its not really a \"unit test\" of the PadLevelText functionality.\n\t// So! Many apologies to the potential future person who has to rewrite this test\n\t// when they are changing some completely unrelated functionality.\n\tparams := []struct {\n\t\tname            string\n\t\tlevel           Level\n\t\tpaddedLevelText string\n\t}{\n\t\t{\n\t\t\tname:            \"PanicLevel\",\n\t\t\tlevel:           PanicLevel,\n\t\t\tpaddedLevelText: \"PANIC  \", // 2 extra spaces\n\t\t},\n\t\t{\n\t\t\tname:            \"FatalLevel\",\n\t\t\tlevel:           FatalLevel,\n\t\t\tpaddedLevelText: \"FATAL  \", // 2 extra spaces\n\t\t},\n\t\t{\n\t\t\tname:            \"ErrorLevel\",\n\t\t\tlevel:           ErrorLevel,\n\t\t\tpaddedLevelText: \"ERROR  \", // 2 extra spaces\n\t\t},\n\t\t{\n\t\t\tname:  \"WarnLevel\",\n\t\t\tlevel: WarnLevel,\n\t\t\t// WARNING is already the max length, so we don't need to assert a paddedLevelText\n\t\t},\n\t\t{\n\t\t\tname:            \"DebugLevel\",\n\t\t\tlevel:           DebugLevel,\n\t\t\tpaddedLevelText: \"DEBUG  \", // 2 extra spaces\n\t\t},\n\t\t{\n\t\t\tname:            \"TraceLevel\",\n\t\t\tlevel:           TraceLevel,\n\t\t\tpaddedLevelText: \"TRACE  \", // 2 extra spaces\n\t\t},\n\t\t{\n\t\t\tname:            \"InfoLevel\",\n\t\t\tlevel:           InfoLevel,\n\t\t\tpaddedLevelText: \"INFO   \", // 3 extra spaces\n\t\t},\n\t}\n\n\t// We create a \"default\" TextFormatter to do a control test.\n\t// We also create a TextFormatter with PadLevelText, which is the parameter we want to do our most relevant assertions against.\n\ttfDefault := TextFormatter{}\n\ttfWithPadding := TextFormatter{PadLevelText: true}\n\n\tfor _, val := range params {\n\t\tt.Run(val.name, func(t *testing.T) {\n\t\t\t// TextFormatter writes into these bytes.Buffers, and we make assertions about their contents later\n\t\t\tvar bytesDefault bytes.Buffer\n\t\t\tvar bytesWithPadding bytes.Buffer\n\n\t\t\t// The TextFormatter instance and the bytes.Buffer instance are different here\n\t\t\t// all the other arguments are the same. We also initialize them so that they\n\t\t\t// fill in the value of levelTextMaxLength.\n\t\t\ttfDefault.init(&Entry{})\n\t\t\ttfDefault.printColored(&bytesDefault, &Entry{Level: val.level}, []string{}, nil, \"\")\n\t\t\ttfWithPadding.init(&Entry{})\n\t\t\ttfWithPadding.printColored(&bytesWithPadding, &Entry{Level: val.level}, []string{}, nil, \"\")\n\n\t\t\t// turn the bytes back into a string so that we can actually work with the data\n\t\t\tlogLineDefault := (&bytesDefault).String()\n\t\t\tlogLineWithPadding := (&bytesWithPadding).String()\n\n\t\t\t// Control: the level text should not be padded by default\n\t\t\tif val.paddedLevelText != \"\" && strings.Contains(logLineDefault, val.paddedLevelText) {\n\t\t\t\tt.Errorf(\"log line %q should not contain the padded level text %q by default\", logLineDefault, val.paddedLevelText)\n\t\t\t}\n\n\t\t\t// Assertion: the level text should still contain the string representation of the level\n\t\t\tif !strings.Contains(strings.ToLower(logLineWithPadding), val.level.String()) {\n\t\t\t\tt.Errorf(\"log line %q should contain the level text %q when padding is enabled\", logLineWithPadding, val.level.String())\n\t\t\t}\n\n\t\t\t// Assertion: the level text should be in its padded form now\n\t\t\tif val.paddedLevelText != \"\" && !strings.Contains(logLineWithPadding, val.paddedLevelText) {\n\t\t\t\tt.Errorf(\"log line %q should contain the padded level text %q when padding is enabled\", logLineWithPadding, val.paddedLevelText)\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestDisableTimestampWithColoredOutput(t *testing.T) {\n\ttf := &TextFormatter{DisableTimestamp: true, ForceColors: true}\n\n\tb, _ := tf.Format(WithField(\"test\", \"test\"))\n\tif strings.Contains(string(b), \"[0000]\") {\n\t\tt.Error(\"timestamp not expected when DisableTimestamp is true\")\n\t}\n}\n\nfunc TestNewlineBehavior(t *testing.T) {\n\ttf := &TextFormatter{ForceColors: true}\n\n\t// Ensure a single new line is removed as per stdlib log\n\te := NewEntry(StandardLogger())\n\te.Message = \"test message\\n\"\n\tb, _ := tf.Format(e)\n\tif bytes.Contains(b, []byte(\"test message\\n\")) {\n\t\tt.Error(\"first newline at end of Entry.Message resulted in unexpected 2 newlines in output. Expected newline to be removed.\")\n\t}\n\n\t// Ensure a double new line is reduced to a single new line\n\te = NewEntry(StandardLogger())\n\te.Message = \"test message\\n\\n\"\n\tb, _ = tf.Format(e)\n\tif bytes.Contains(b, []byte(\"test message\\n\\n\")) {\n\t\tt.Error(\"Double newline at end of Entry.Message resulted in unexpected 2 newlines in output. Expected single newline\")\n\t}\n\tif !bytes.Contains(b, []byte(\"test message\\n\")) {\n\t\tt.Error(\"Double newline at end of Entry.Message did not result in a single newline after formatting\")\n\t}\n}\n\nfunc TestTextFormatterFieldMap(t *testing.T) {\n\tformatter := &TextFormatter{\n\t\tDisableColors: true,\n\t\tFieldMap: FieldMap{\n\t\t\tFieldKeyMsg:   \"message\",\n\t\t\tFieldKeyLevel: \"somelevel\",\n\t\t\tFieldKeyTime:  \"timeywimey\",\n\t\t},\n\t}\n\n\tentry := &Entry{\n\t\tMessage: \"oh hi\",\n\t\tLevel:   WarnLevel,\n\t\tTime:    time.Date(1981, time.February, 24, 4, 28, 3, 100, time.UTC),\n\t\tData: Fields{\n\t\t\t\"field1\":     \"f1\",\n\t\t\t\"message\":    \"messagefield\",\n\t\t\t\"somelevel\":  \"levelfield\",\n\t\t\t\"timeywimey\": \"timeywimeyfield\",\n\t\t},\n\t}\n\n\tb, err := formatter.Format(entry)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to format entry: \", err)\n\t}\n\n\tassert.Equal(t,\n\t\t`timeywimey=\"1981-02-24T04:28:03Z\" `+\n\t\t\t`somelevel=warning `+\n\t\t\t`message=\"oh hi\" `+\n\t\t\t`field1=f1 `+\n\t\t\t`fields.message=messagefield `+\n\t\t\t`fields.somelevel=levelfield `+\n\t\t\t`fields.timeywimey=timeywimeyfield`+\"\\n\",\n\t\tstring(b),\n\t\t\"Formatted output doesn't respect FieldMap\")\n}\n\nfunc TestTextFormatterIsColored(t *testing.T) {\n\tparams := []struct {\n\t\tname               string\n\t\texpectedResult     bool\n\t\tisTerminal         bool\n\t\tdisableColor       bool\n\t\tforceColor         bool\n\t\tenvColor           bool\n\t\tclicolorIsSet      bool\n\t\tclicolorForceIsSet bool\n\t\tclicolorVal        string\n\t\tclicolorForceVal   string\n\t}{\n\t\t// Default values\n\t\t{\n\t\t\tname:               \"testcase1\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           false,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: false,\n\t\t},\n\t\t// Output on terminal\n\t\t{\n\t\t\tname:               \"testcase2\",\n\t\t\texpectedResult:     true,\n\t\t\tisTerminal:         true,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           false,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: false,\n\t\t},\n\t\t// Output on terminal with color disabled\n\t\t{\n\t\t\tname:               \"testcase3\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         true,\n\t\t\tdisableColor:       true,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           false,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: false,\n\t\t},\n\t\t// Output not on terminal with color disabled\n\t\t{\n\t\t\tname:               \"testcase4\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       true,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           false,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: false,\n\t\t},\n\t\t// Output not on terminal with color forced\n\t\t{\n\t\t\tname:               \"testcase5\",\n\t\t\texpectedResult:     true,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         true,\n\t\t\tenvColor:           false,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: false,\n\t\t},\n\t\t// Output on terminal with clicolor set to \"0\"\n\t\t{\n\t\t\tname:               \"testcase6\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         true,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"0\",\n\t\t},\n\t\t// Output on terminal with clicolor set to \"1\"\n\t\t{\n\t\t\tname:               \"testcase7\",\n\t\t\texpectedResult:     true,\n\t\t\tisTerminal:         true,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"1\",\n\t\t},\n\t\t// Output not on terminal with clicolor set to \"0\"\n\t\t{\n\t\t\tname:               \"testcase8\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"0\",\n\t\t},\n\t\t// Output not on terminal with clicolor set to \"1\"\n\t\t{\n\t\t\tname:               \"testcase9\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"1\",\n\t\t},\n\t\t// Output not on terminal with clicolor set to \"1\" and force color\n\t\t{\n\t\t\tname:               \"testcase10\",\n\t\t\texpectedResult:     true,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         true,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"1\",\n\t\t},\n\t\t// Output not on terminal with clicolor set to \"0\" and force color\n\t\t{\n\t\t\tname:               \"testcase11\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         true,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      true,\n\t\t\tclicolorForceIsSet: false,\n\t\t\tclicolorVal:        \"0\",\n\t\t},\n\t\t// Output not on terminal with clicolor_force set to \"1\"\n\t\t{\n\t\t\tname:               \"testcase12\",\n\t\t\texpectedResult:     true,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: true,\n\t\t\tclicolorForceVal:   \"1\",\n\t\t},\n\t\t// Output not on terminal with clicolor_force set to \"0\"\n\t\t{\n\t\t\tname:               \"testcase13\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         false,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: true,\n\t\t\tclicolorForceVal:   \"0\",\n\t\t},\n\t\t// Output on terminal with clicolor_force set to \"0\"\n\t\t{\n\t\t\tname:               \"testcase14\",\n\t\t\texpectedResult:     false,\n\t\t\tisTerminal:         true,\n\t\t\tdisableColor:       false,\n\t\t\tforceColor:         false,\n\t\t\tenvColor:           true,\n\t\t\tclicolorIsSet:      false,\n\t\t\tclicolorForceIsSet: true,\n\t\t\tclicolorForceVal:   \"0\",\n\t\t},\n\t}\n\n\tcleanenv := func() {\n\t\tos.Unsetenv(\"CLICOLOR\")\n\t\tos.Unsetenv(\"CLICOLOR_FORCE\")\n\t}\n\n\tdefer cleanenv()\n\n\tfor _, val := range params {\n\t\tt.Run(\"textformatter_\"+val.name, func(subT *testing.T) {\n\t\t\ttf := TextFormatter{\n\t\t\t\tisTerminal:                val.isTerminal,\n\t\t\t\tDisableColors:             val.disableColor,\n\t\t\t\tForceColors:               val.forceColor,\n\t\t\t\tEnvironmentOverrideColors: val.envColor,\n\t\t\t}\n\t\t\tcleanenv()\n\t\t\tif val.clicolorIsSet {\n\t\t\t\tos.Setenv(\"CLICOLOR\", val.clicolorVal)\n\t\t\t}\n\t\t\tif val.clicolorForceIsSet {\n\t\t\t\tos.Setenv(\"CLICOLOR_FORCE\", val.clicolorForceVal)\n\t\t\t}\n\t\t\tres := tf.isColored()\n\t\t\tif runtime.GOOS == \"windows\" && !tf.ForceColors && !val.clicolorForceIsSet {\n\t\t\t\tassert.Equal(subT, false, res)\n\t\t\t} else {\n\t\t\t\tassert.Equal(subT, val.expectedResult, res)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCustomSorting(t *testing.T) {\n\tformatter := &TextFormatter{\n\t\tDisableColors: true,\n\t\tSortingFunc: func(keys []string) {\n\t\t\tsort.Slice(keys, func(i, j int) bool {\n\t\t\t\tif keys[j] == \"prefix\" {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif keys[i] == \"prefix\" {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\treturn strings.Compare(keys[i], keys[j]) == -1\n\t\t\t})\n\t\t},\n\t}\n\n\tentry := &Entry{\n\t\tMessage: \"Testing custom sort function\",\n\t\tTime:    time.Now(),\n\t\tLevel:   InfoLevel,\n\t\tData: Fields{\n\t\t\t\"test\":      \"testvalue\",\n\t\t\t\"prefix\":    \"the application prefix\",\n\t\t\t\"blablabla\": \"blablabla\",\n\t\t},\n\t}\n\tb, err := formatter.Format(entry)\n\trequire.NoError(t, err)\n\trequire.True(t, strings.HasPrefix(string(b), \"prefix=\"), \"format output is %q\", string(b))\n}\n"
        },
        {
          "name": "travis",
          "type": "tree",
          "content": null
        },
        {
          "name": "writer.go",
          "type": "blob",
          "size": 3.1220703125,
          "content": "package logrus\n\nimport (\n\t\"bufio\"\n\t\"io\"\n\t\"runtime\"\n\t\"strings\"\n)\n\n// Writer at INFO level. See WriterLevel for details.\nfunc (logger *Logger) Writer() *io.PipeWriter {\n\treturn logger.WriterLevel(InfoLevel)\n}\n\n// WriterLevel returns an io.Writer that can be used to write arbitrary text to\n// the logger at the given log level. Each line written to the writer will be\n// printed in the usual way using formatters and hooks. The writer is part of an\n// io.Pipe and it is the callers responsibility to close the writer when done.\n// This can be used to override the standard library logger easily.\nfunc (logger *Logger) WriterLevel(level Level) *io.PipeWriter {\n\treturn NewEntry(logger).WriterLevel(level)\n}\n\n// Writer returns an io.Writer that writes to the logger at the info log level\nfunc (entry *Entry) Writer() *io.PipeWriter {\n\treturn entry.WriterLevel(InfoLevel)\n}\n\n// WriterLevel returns an io.Writer that writes to the logger at the given log level\nfunc (entry *Entry) WriterLevel(level Level) *io.PipeWriter {\n\treader, writer := io.Pipe()\n\n\tvar printFunc func(args ...interface{})\n\n\t// Determine which log function to use based on the specified log level\n\tswitch level {\n\tcase TraceLevel:\n\t\tprintFunc = entry.Trace\n\tcase DebugLevel:\n\t\tprintFunc = entry.Debug\n\tcase InfoLevel:\n\t\tprintFunc = entry.Info\n\tcase WarnLevel:\n\t\tprintFunc = entry.Warn\n\tcase ErrorLevel:\n\t\tprintFunc = entry.Error\n\tcase FatalLevel:\n\t\tprintFunc = entry.Fatal\n\tcase PanicLevel:\n\t\tprintFunc = entry.Panic\n\tdefault:\n\t\tprintFunc = entry.Print\n\t}\n\n\t// Start a new goroutine to scan the input and write it to the logger using the specified print function.\n\t// It splits the input into chunks of up to 64KB to avoid buffer overflows.\n\tgo entry.writerScanner(reader, printFunc)\n\n\t// Set a finalizer function to close the writer when it is garbage collected\n\truntime.SetFinalizer(writer, writerFinalizer)\n\n\treturn writer\n}\n\n// writerScanner scans the input from the reader and writes it to the logger\nfunc (entry *Entry) writerScanner(reader *io.PipeReader, printFunc func(args ...interface{})) {\n\tscanner := bufio.NewScanner(reader)\n\n\t// Set the buffer size to the maximum token size to avoid buffer overflows\n\tscanner.Buffer(make([]byte, bufio.MaxScanTokenSize), bufio.MaxScanTokenSize)\n\n\t// Define a split function to split the input into chunks of up to 64KB\n\tchunkSize := bufio.MaxScanTokenSize // 64KB\n\tsplitFunc := func(data []byte, atEOF bool) (int, []byte, error) {\n\t\tif len(data) >= chunkSize {\n\t\t\treturn chunkSize, data[:chunkSize], nil\n\t\t}\n\n\t\treturn bufio.ScanLines(data, atEOF)\n\t}\n\n\t// Use the custom split function to split the input\n\tscanner.Split(splitFunc)\n\n\t// Scan the input and write it to the logger using the specified print function\n\tfor scanner.Scan() {\n\t\tprintFunc(strings.TrimRight(scanner.Text(), \"\\r\\n\"))\n\t}\n\n\t// If there was an error while scanning the input, log an error\n\tif err := scanner.Err(); err != nil {\n\t\tentry.Errorf(\"Error while reading from Writer: %s\", err)\n\t}\n\n\t// Close the reader when we are done\n\treader.Close()\n}\n\n// WriterFinalizer is a finalizer function that closes then given writer when it is garbage collected\nfunc writerFinalizer(writer *io.PipeWriter) {\n\twriter.Close()\n}\n"
        },
        {
          "name": "writer_test.go",
          "type": "blob",
          "size": 2.3984375,
          "content": "package logrus_test\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"log\"\n\t\"net/http\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc ExampleLogger_Writer_httpServer() {\n\tlogger := logrus.New()\n\tw := logger.Writer()\n\tdefer w.Close()\n\n\tsrv := http.Server{\n\t\t// create a stdlib log.Logger that writes to\n\t\t// logrus.Logger.\n\t\tErrorLog: log.New(w, \"\", 0),\n\t}\n\n\tif err := srv.ListenAndServe(); err != nil {\n\t\tlogger.Fatal(err)\n\t}\n}\n\nfunc ExampleLogger_Writer_stdlib() {\n\tlogger := logrus.New()\n\tlogger.Formatter = &logrus.JSONFormatter{}\n\n\t// Use logrus for standard log output\n\t// Note that `log` here references stdlib's log\n\t// Not logrus imported under the name `log`.\n\tlog.SetOutput(logger.Writer())\n}\n\nfunc TestWriterSplitNewlines(t *testing.T) {\n\tbuf := bytes.NewBuffer(nil)\n\tlogger := logrus.New()\n\tlogger.Formatter = &logrus.TextFormatter{\n\t\tDisableColors:    true,\n\t\tDisableTimestamp: true,\n\t}\n\tlogger.SetOutput(buf)\n\twriter := logger.Writer()\n\n\tconst logNum = 10\n\n\tfor i := 0; i < logNum; i++ {\n\t\t_, err := writer.Write([]byte(\"bar\\nfoo\\n\"))\n\t\tassert.NoError(t, err, \"writer.Write failed\")\n\t}\n\twriter.Close()\n\t// Test is flaky because it writes in another goroutine,\n\t// we need to make sure to wait a bit so all write are done.\n\ttime.Sleep(500 * time.Millisecond)\n\n\tlines := strings.Split(strings.TrimRight(buf.String(), \"\\n\"), \"\\n\")\n\tassert.Len(t, lines, logNum*2, \"logger printed incorrect number of lines\")\n}\n\nfunc TestWriterSplitsMax64KB(t *testing.T) {\n\tbuf := bytes.NewBuffer(nil)\n\tlogger := logrus.New()\n\tlogger.Formatter = &logrus.TextFormatter{\n\t\tDisableColors:    true,\n\t\tDisableTimestamp: true,\n\t}\n\tlogger.SetOutput(buf)\n\twriter := logger.Writer()\n\n\t// write more than 64KB\n\tconst bigWriteLen = bufio.MaxScanTokenSize + 100\n\toutput := make([]byte, bigWriteLen)\n\t// lets not write zero bytes\n\tfor i := 0; i < bigWriteLen; i++ {\n\t\toutput[i] = 'A'\n\t}\n\n\tfor i := 0; i < 3; i++ {\n\t\tlen, err := writer.Write(output)\n\t\tassert.NoError(t, err, \"writer.Write failed\")\n\t\tassert.Equal(t, bigWriteLen, len, \"bytes written\")\n\t}\n\twriter.Close()\n\t// Test is flaky because it writes in another goroutine,\n\t// we need to make sure to wait a bit so all write are done.\n\ttime.Sleep(500 * time.Millisecond)\n\n\tlines := strings.Split(strings.TrimRight(buf.String(), \"\\n\"), \"\\n\")\n\t// we should have 4 lines because we wrote more than 64 KB each time\n\tassert.Len(t, lines, 4, \"logger printed incorrect number of lines\")\n}\n"
        }
      ]
    }
  ]
}