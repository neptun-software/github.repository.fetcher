{
  "metadata": {
    "timestamp": 1736568010438,
    "page": 146,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "panjf2000/ants",
      "stars": 13164,
      "defaultBranch": "dev",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2802734375,
          "content": "# Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n\n# Test binary, built with `go test -c`\n*.test\n\n# Output of the go coverage tool, specifically when used with LiteIDE\n*.out\n\n# Dependency directories (remove the comment below to include it)\n# vendor/\n\n.idea\n\n.DS_Store\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2724609375,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at panjf2000@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.7958984375,
          "content": "# Contributing \n\n## With issues:\n  - Use the search tool before opening a new issue.\n  - Please provide source code and commit sha if you found a bug.\n  - Review existing issues and provide feedback or react to them.\n\n## With pull requests:\n  - Open your pull request against `dev`.\n  - Open one pull request for only one feature/proposal, if you have several those, please put them into different PRs, whereas you are allowed to open one pull request with several bug-fixs.\n  - Your pull request should have no more than two commits, if not, you should squash them.\n  - It should pass all tests in the available continuous integrations systems such as TravisCI.\n  - You should add/modify tests to cover your proposed code changes.\n  - If your pull request contains a new feature, please document it on the README.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0400390625,
          "content": "MIT License\n\nCopyright (c) 2018 Andy Pan\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 21.4443359375,
          "content": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/panjf2000/logos/master/ants/logo.png\" />\n<b>A goroutine pool for Go</b>\n<br/><br/>\n<a title=\"Build Status\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/actions?query=workflow%3ATests\"><img src=\"https://img.shields.io/github/actions/workflow/status/panjf2000/ants/test.yml?branch=master&style=flat-square&logo=github-actions\" /></a>\n<a title=\"Codecov\" target=\"_blank\" href=\"https://codecov.io/gh/panjf2000/ants\"><img src=\"https://img.shields.io/codecov/c/github/panjf2000/ants?style=flat-square&logo=codecov\" /></a>\n<a title=\"Release\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/releases\"><img src=\"https://img.shields.io/github/v/release/panjf2000/ants.svg?color=161823&style=flat-square&logo=smartthings\" /></a>\n<a title=\"Tag\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/tags\"><img src=\"https://img.shields.io/github/v/tag/panjf2000/ants?color=%23ff8936&logo=fitbit&style=flat-square\" /></a>\n<br/>\n<a title=\"Go Report Card\" target=\"_blank\" href=\"https://goreportcard.com/report/github.com/panjf2000/ants\"><img src=\"https://goreportcard.com/badge/github.com/panjf2000/ants?style=flat-square\" /></a>\n<a title=\"Doc for ants\" target=\"_blank\" href=\"https://pkg.go.dev/github.com/panjf2000/ants/v2?tab=doc\"><img src=\"https://img.shields.io/badge/go.dev-doc-007d9c?style=flat-square&logo=read-the-docs\" /></a>\n<a title=\"Mentioned in Awesome Go\" target=\"_blank\" href=\"https://github.com/avelino/awesome-go#goroutines\"><img src=\"https://awesome.re/mentioned-badge-flat.svg\" /></a>\n</p>\n\nEnglish | [中文](README_ZH.md)\n\n## 📖 Introduction\n\nLibrary `ants` implements a goroutine pool with fixed capacity, managing and recycling a massive number of goroutines, allowing developers to limit the number of goroutines in your concurrent programs.\n\n## 🚀 Features:\n\n- Managing and recycling a massive number of goroutines automatically\n- Purging overdue goroutines periodically\n- Abundant APIs: submitting tasks, getting the number of running goroutines, tuning the capacity of the pool dynamically, releasing the pool, rebooting the pool, etc.\n- Handle panic gracefully to prevent programs from crash\n- Efficient in memory usage and it may even achieve ***higher performance*** than unlimited goroutines in Golang\n- Nonblocking mechanism\n- Preallocated memory (ring buffer, optional)\n\n## 💡 How `ants` works\n\n### Flow Diagram\n\n<p align=\"center\">\n<img width=\"1011\" alt=\"ants-flowchart-en\" src=\"https://user-images.githubusercontent.com/7496278/66396509-7b42e700-ea0c-11e9-8612-b71a4b734683.png\">\n</p>\n\n### Activity Diagrams\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-1.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-2.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-3.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-4.png)\n\n## 🧰 How to install\n\n### For `ants` v1\n\n``` powershell\ngo get -u github.com/panjf2000/ants\n```\n\n### For `ants` v2 (with GO111MODULE=on)\n\n```powershell\ngo get -u github.com/panjf2000/ants/v2\n```\n\n## 🛠 How to use\nJust imagine that your program starts a massive number of goroutines, resulting in a huge consumption of memory. To mitigate that kind of situation, all you need to do is to import `ants` package and submit all your tasks to a default pool with fixed capacity, activated when package `ants` is imported:\n\n``` go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/panjf2000/ants/v2\"\n)\n\nvar sum int32\n\nfunc myFunc(i interface{}) {\n\tn := i.(int32)\n\tatomic.AddInt32(&sum, n)\n\tfmt.Printf(\"run with %d\\n\", n)\n}\n\nfunc demoFunc() {\n\ttime.Sleep(10 * time.Millisecond)\n\tfmt.Println(\"Hello World!\")\n}\n\nfunc main() {\n\tdefer ants.Release()\n\n\trunTimes := 1000\n\n\t// Use the common pool.\n\tvar wg sync.WaitGroup\n\tsyncCalculateSum := func() {\n\t\tdemoFunc()\n\t\twg.Done()\n\t}\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = ants.Submit(syncCalculateSum)\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", ants.Running())\n\tfmt.Printf(\"finish all tasks.\\n\")\n\n\t// Use the pool with a function,\n\t// set 10 to the capacity of goroutine pool and 1 second for expired duration.\n\tp, _ := ants.NewPoolWithFunc(10, func(i interface{}) {\n\t\tmyFunc(i)\n\t\twg.Done()\n\t})\n\tdefer p.Release()\n\t// Submit tasks one by one.\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Invoke(int32(i))\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", p.Running())\n\tfmt.Printf(\"finish all tasks, result is %d\\n\", sum)\n\tif sum != 499500 {\n\t\tpanic(\"the final result is wrong!!!\")\n\t}\n\n\t// Use the MultiPool and set the capacity of the 10 goroutine pools to unlimited.\n\t// If you use -1 as the pool size parameter, the size will be unlimited.\n\t// There are two load-balancing algorithms for pools: ants.RoundRobin and ants.LeastTasks.\n\tmp, _ := ants.NewMultiPool(10, -1, ants.RoundRobin)\n\tdefer mp.ReleaseTimeout(5 * time.Second)\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = mp.Submit(syncCalculateSum)\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", mp.Running())\n\tfmt.Printf(\"finish all tasks.\\n\")\n\n\t// Use the MultiPoolFunc and set the capacity of 10 goroutine pools to (runTimes/10).\n\tmpf, _ := ants.NewMultiPoolWithFunc(10, runTimes/10, func(i interface{}) {\n\t\tmyFunc(i)\n\t\twg.Done()\n\t}, ants.LeastTasks)\n\tdefer mpf.ReleaseTimeout(5 * time.Second)\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = mpf.Invoke(int32(i))\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", mpf.Running())\n\tfmt.Printf(\"finish all tasks, result is %d\\n\", sum)\n\tif sum != 499500*2 {\n\t\tpanic(\"the final result is wrong!!!\")\n\t}\n}\n```\n\n###  Functional options for ants pool\n\n```go\n// Option represents the optional function.\ntype Option func(opts *Options)\n\n// Options contains all options which will be applied when instantiating a ants pool.\ntype Options struct {\n\t// ExpiryDuration is a period for the scavenger goroutine to clean up those expired workers,\n\t// the scavenger scans all workers every `ExpiryDuration` and clean up those workers that haven't been\n\t// used for more than `ExpiryDuration`.\n\tExpiryDuration time.Duration\n\n\t// PreAlloc indicates whether to make memory pre-allocation when initializing Pool.\n\tPreAlloc bool\n\n\t// Max number of goroutine blocking on pool.Submit.\n\t// 0 (default value) means no such limit.\n\tMaxBlockingTasks int\n\n\t// When Nonblocking is true, Pool.Submit will never be blocked.\n\t// ErrPoolOverload will be returned when Pool.Submit cannot be done at once.\n\t// When Nonblocking is true, MaxBlockingTasks is inoperative.\n\tNonblocking bool\n\n\t// PanicHandler is used to handle panics from each worker goroutine.\n\t// if nil, panics will be thrown out again from worker goroutines.\n\tPanicHandler func(interface{})\n\n\t// Logger is the customized logger for logging info, if it is not set,\n\t// default standard logger from log package is used.\n\tLogger Logger\n}\n\n// WithOptions accepts the whole options config.\nfunc WithOptions(options Options) Option {\n\treturn func(opts *Options) {\n\t\t*opts = options\n\t}\n}\n\n// WithExpiryDuration sets up the interval time of cleaning up goroutines.\nfunc WithExpiryDuration(expiryDuration time.Duration) Option {\n\treturn func(opts *Options) {\n\t\topts.ExpiryDuration = expiryDuration\n\t}\n}\n\n// WithPreAlloc indicates whether it should malloc for workers.\nfunc WithPreAlloc(preAlloc bool) Option {\n\treturn func(opts *Options) {\n\t\topts.PreAlloc = preAlloc\n\t}\n}\n\n// WithMaxBlockingTasks sets up the maximum number of goroutines that are blocked when it reaches the capacity of pool.\nfunc WithMaxBlockingTasks(maxBlockingTasks int) Option {\n\treturn func(opts *Options) {\n\t\topts.MaxBlockingTasks = maxBlockingTasks\n\t}\n}\n\n// WithNonblocking indicates that pool will return nil when there is no available workers.\nfunc WithNonblocking(nonblocking bool) Option {\n\treturn func(opts *Options) {\n\t\topts.Nonblocking = nonblocking\n\t}\n}\n\n// WithPanicHandler sets up panic handler.\nfunc WithPanicHandler(panicHandler func(interface{})) Option {\n\treturn func(opts *Options) {\n\t\topts.PanicHandler = panicHandler\n\t}\n}\n\n// WithLogger sets up a customized logger.\nfunc WithLogger(logger Logger) Option {\n\treturn func(opts *Options) {\n\t\topts.Logger = logger\n\t}\n}\n```\n\n`ants.Options`contains all optional configurations of the ants pool, which allows you to customize the goroutine pool by invoking option functions to set up each configuration in `NewPool`/`NewPoolWithFunc`method.\n\n### Customize limited pool\n\n`ants` also supports customizing the capacity of the pool. You can invoke the `NewPool` method to instantiate a pool with a given capacity, as follows:\n\n``` go\np, _ := ants.NewPool(10000)\n```\n\n### Submit tasks\nTasks can be submitted by calling `ants.Submit(func())`\n```go\nants.Submit(func(){})\n```\n\n### Tune pool capacity in runtime\nYou can tune the capacity of  `ants` pool in runtime with `Tune(int)`:\n\n``` go\npool.Tune(1000) // Tune its capacity to 1000\npool.Tune(100000) // Tune its capacity to 100000\n```\n\nDon't worry about the contention problems in this case, the method here is thread-safe (or should be called goroutine-safe).\n\n### Pre-malloc goroutine queue in pool\n\n`ants` allows you to pre-allocate the memory of the goroutine queue in the pool, which may get a performance enhancement under some special certain circumstances such as the scenario that requires a pool with ultra-large capacity, meanwhile, each task in goroutine lasts for a long time, in this case, pre-mallocing will reduce a lot of memory allocation in goroutine queue.\n\n```go\n// ants will pre-malloc the whole capacity of pool when you invoke this method\np, _ := ants.NewPool(100000, ants.WithPreAlloc(true))\n```\n\n### Release Pool\n\n```go\npool.Release()\n```\n\nor\n\n```go\npool.ReleaseTimeout(time.Second * 3)\n```\n\n### Reboot Pool\n\n```go\n// A pool that has been released can be still used once you invoke the Reboot().\npool.Reboot()\n```\n\n## ⚙️ About sequence\n\nAll tasks submitted to `ants` pool will not be guaranteed to be addressed in order, because those tasks scatter among a series of concurrent workers, thus those tasks would be executed concurrently.\n\n## 👏 Contributors\n\nPlease read our [Contributing Guidelines](CONTRIBUTING.md) before opening a PR and thank you to all the developers who already made contributions to `ants`!\n\n<a href=\"https://github.com/panjf2000/ants/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=panjf2000/ants\" />\n</a>\n\n## 📄 License\n\nThe source code in `ants` is available under the [MIT License](/LICENSE).\n\n## 📚 Relevant Articles\n\n-  [Goroutine 并发调度模型深度解析之手撸一个高性能 goroutine 池](https://taohuawu.club/high-performance-implementation-of-goroutine-pool)\n-  [Visually Understanding Worker Pool](https://medium.com/coinmonks/visually-understanding-worker-pool-48a83b7fc1f5)\n-  [The Case For A Go Worker Pool](https://brandur.org/go-worker-pool)\n-  [Go Concurrency - GoRoutines, Worker Pools and Throttling Made Simple](https://twin.sh/articles/39/go-concurrency-goroutines-worker-pools-and-throttling-made-simple)\n\n## 🖥 Use cases\n\n### business corporations\n\nTrusted by the following corporations/organizations.\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.tencent.com/\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/tencent_logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.bytedance.com/en/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/ByteDance_Logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://tieba.baidu.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/baidu-tieba-logo.png\" width=\"300\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://weibo.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/weibo-logo.png\" width=\"300\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.tencentmusic.com/en-us/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/tencent-music-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.futuhk.com/en/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/futu-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.shopify.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/shopify-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.wechat.com/en/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/wechat-logo.png\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.baidu.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/baidu-mobile-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.360.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/360-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.huaweicloud.com/intl/en-us/\" target=\"_blank\">\n          <img src=\"https://res-static.hc-cdn.cn/cloudbu-site/china/zh-cn/%E7%BB%84%E4%BB%B6%E9%AA%8C%E8%AF%81/pep-common-header/logo-en.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.matrixorigin.io/\" target=\"_blank\">\n          <img src=\"https://www.matrixorigin.io/_next/static/media/logo-light-en.42553c69.svg\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://adguard-dns.io/\" target=\"_blank\">\n          <img src=\"https://cdn.adtidy.org/website/images/AdGuardDNS_black.svg\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://bk.tencent.com/\" target=\"_blank\">\n          <img src=\"https://static.apiseven.com/2022/11/14/6371adab14119.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.alibabacloud.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/aliyun-intl-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.zuoyebang.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/zuoyebang-logo.jpeg\" width=\"300\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.antgroup.com/en/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/ant-group-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://zilliz.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/zilliz-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://amap.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/amap-logo.png\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nIf you're also using `ants` in production, please help us enrich this list by opening a pull request.\n\n### open-source software\n\nThe open-source projects below do concurrent programming with the help of `ants`.\n\n- [gnet](https://github.com/panjf2000/gnet):  A high-performance, lightweight, non-blocking, event-driven networking framework written in pure Go.\n- [milvus](https://github.com/milvus-io/milvus): An open-source vector database for scalable similarity search and AI applications.\n- [nps](https://github.com/ehang-io/nps): A lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.\n- [TDengine](https://github.com/taosdata/TDengine): TDengine is an open source, high-performance, cloud native time-series database optimized for Internet of Things (IoT), Connected Cars, and Industrial IoT.\n- [siyuan](https://github.com/siyuan-note/siyuan): SiYuan is a local-first personal knowledge management system that supports complete offline use, as well as end-to-end encrypted synchronization.\n- [osmedeus](https://github.com/j3ssie/osmedeus): A Workflow Engine for Offensive Security.\n- [jitsu](https://github.com/jitsucom/jitsu/tree/master): An open-source Segment alternative. Fully-scriptable data ingestion engine for modern data teams. Set-up a real-time data pipeline in minutes, not days.\n- [triangula](https://github.com/RH12503/triangula): Generate high-quality triangulated and polygonal art from images.\n- [teler](https://github.com/kitabisa/teler): Real-time HTTP Intrusion Detection.\n- [bsc](https://github.com/binance-chain/bsc): A Binance Smart Chain client based on the go-ethereum fork.\n- [jaeles](https://github.com/jaeles-project/jaeles): The Swiss Army knife for automated Web Application Testing.\n- [devlake](https://github.com/apache/incubator-devlake): The open-source dev data platform & dashboard for your DevOps tools.\n- [matrixone](https://github.com/matrixorigin/matrixone): MatrixOne is a future-oriented hyper-converged cloud and edge native DBMS that supports transactional, analytical, and streaming workloads with a simplified and distributed database engine, across multiple data centers, clouds, edges and other heterogeneous infrastructures.\n- [bk-bcs](https://github.com/TencentBlueKing/bk-bcs): BlueKing Container Service (BCS, same below) is a container management and orchestration platform for the micro-services under the BlueKing ecosystem.\n- [trueblocks-core](https://github.com/TrueBlocks/trueblocks-core): TrueBlocks improves access to blockchain data for any EVM-compatible chain (particularly Ethereum mainnet) while remaining entirely local.\n- [openGemini](https://github.com/openGemini/openGemini): openGemini is an open-source,cloud-native time-series database(TSDB) that can be widely used in IoT, Internet of Vehicles(IoV), O&M monitoring, and industrial Internet scenarios.\n- [AdGuardDNS](https://github.com/AdguardTeam/AdGuardDNS): AdGuard DNS is an alternative solution for tracker blocking, privacy protection, and parental control.\n- [WatchAD2.0](https://github.com/Qihoo360/WatchAD2.0): WatchAD2.0 是 360 信息安全中心开发的一款针对域安全的日志分析与监控系统，它可以收集所有域控上的事件日志、网络流量，通过特征匹配、协议分析、历史行为、敏感操作和蜜罐账户等方式来检测各种已知与未知威胁，功能覆盖了大部分目前的常见内网域渗透手法。\n- [vanus](https://github.com/vanus-labs/vanus): Vanus is a Serverless, event streaming system with processing capabilities. It easily connects SaaS, Cloud Services, and Databases to help users build next-gen Event-driven Applications.\n- [trpc-go](https://github.com/trpc-group/trpc-go): A pluggable, high-performance RPC framework written in Golang.\n- [motan-go](https://github.com/weibocom/motan-go): Motan is a cross-language remote procedure call(RPC) framework for rapid development of high performance distributed services. motan-go is the golang implementation of Motan.\n\n#### All use cases:\n\n- [Repositories that depend on ants/v2](https://github.com/panjf2000/ants/network/dependents?package_id=UGFja2FnZS0yMjY2ODgxMjg2)\n\n- [Repositories that depend on ants/v1](https://github.com/panjf2000/ants/network/dependents?package_id=UGFja2FnZS0yMjY0ODMzNjEw)\n\nIf you have `ants` integrated into projects, feel free to open a pull request refreshing this list of use cases.\n\n## 🔋 JetBrains OS licenses\n\n`ants` has been being developed with GoLand under the **free JetBrains Open Source license(s)** granted by JetBrains s.r.o., hence I would like to express my thanks here.\n\n<a href=\"https://www.jetbrains.com/?from=ants\" target=\"_blank\"><img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo.\"></a>\n\n## 💰 Backers\n\nSupport us with a monthly donation and help us continue our activities.\n\n<a href=\"https://opencollective.com/ants#backers\" target=\"_blank\"><img src=\"https://opencollective.com/ants/backers.svg\"></a>\n\n## 💎 Sponsors\n\nBecome a bronze sponsor with a monthly donation of $10 and get your logo on our README on GitHub.\n\n<a href=\"https://opencollective.com/ants#sponsors\" target=\"_blank\"><img src=\"https://opencollective.com/ants/sponsors.svg\"></a>\n\n## ☕️ Buy me a coffee\n\n> Please be sure to leave your name, GitHub account, or other social media accounts when you donate by the following means so that I can add it to the list of donors as a token of my appreciation.\n\n<img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/WeChatPay.JPG\" width=\"250\" align=\"middle\"/>&nbsp;&nbsp;\n<img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/AliPay.JPG\" width=\"250\" align=\"middle\"/>&nbsp;&nbsp;\n<a href=\"https://www.paypal.me/R136a1X\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/PayPal.JPG\" width=\"250\" align=\"middle\"/></a>&nbsp;&nbsp;\n\n## 🔋 Sponsorship\n\n<p>\n  <a href=\"https://www.digitalocean.com/\">\n    <img src=\"https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/PoweredByDO/DO_Powered_by_Badge_blue.svg\" width=\"201px\">\n  </a>\n</p>\n"
        },
        {
          "name": "README_ZH.md",
          "type": "blob",
          "size": 21.5322265625,
          "content": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/panjf2000/logos/master/ants/logo.png\" />\n<b>Go 语言的 goroutine 池</b>\n<br/><br/>\n<a title=\"Build Status\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/actions?query=workflow%3ATests\"><img src=\"https://img.shields.io/github/actions/workflow/status/panjf2000/ants/test.yml?branch=master&style=flat-square&logo=github-actions\" /></a>\n<a title=\"Codecov\" target=\"_blank\" href=\"https://codecov.io/gh/panjf2000/ants\"><img src=\"https://img.shields.io/codecov/c/github/panjf2000/ants?style=flat-square&logo=codecov\" /></a>\n<a title=\"Release\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/releases\"><img src=\"https://img.shields.io/github/v/release/panjf2000/ants.svg?color=161823&style=flat-square&logo=smartthings\" /></a>\n<a title=\"Tag\" target=\"_blank\" href=\"https://github.com/panjf2000/ants/tags\"><img src=\"https://img.shields.io/github/v/tag/panjf2000/ants?color=%23ff8936&logo=fitbit&style=flat-square\" /></a>\n<br/>\n<a title=\"Go Report Card\" target=\"_blank\" href=\"https://goreportcard.com/report/github.com/panjf2000/ants\"><img src=\"https://goreportcard.com/badge/github.com/panjf2000/ants?style=flat-square\" /></a>\n<a title=\"Doc for ants\" target=\"_blank\" href=\"https://pkg.go.dev/github.com/panjf2000/ants/v2?tab=doc\"><img src=\"https://img.shields.io/badge/go.dev-doc-007d9c?style=flat-square&logo=read-the-docs\" /></a>\n<a title=\"Mentioned in Awesome Go\" target=\"_blank\" href=\"https://github.com/avelino/awesome-go#goroutines\"><img src=\"https://awesome.re/mentioned-badge-flat.svg\" /></a>\n</p>\n\n[英文](README.md) | 中文\n\n## 📖 简介\n\n`ants`是一个高性能的 goroutine 池，实现了对大规模 goroutine 的调度管理、goroutine 复用，允许使用者在开发并发程序的时候限制 goroutine 数量，复用资源，达到更高效执行任务的效果。\n\n## 🚀 功能：\n\n- 自动调度海量的 goroutines，复用 goroutines\n- 定期清理过期的 goroutines，进一步节省资源\n- 提供了大量实用的接口：任务提交、获取运行中的 goroutine 数量、动态调整 Pool 大小、释放 Pool、重启 Pool 等\n- 优雅处理 panic，防止程序崩溃\n- 资源复用，极大节省内存使用量；在大规模批量并发任务场景下甚至可能比原生 goroutine 并发具有***更高的性能***\n- 非阻塞机制\n- 预分配内存 (环形队列，可选)\n\n## 💡 `ants` 是如何运行的\n\n### 流程图\n\n<p align=\"center\">\n<img width=\"845\" alt=\"ants-flowchart-cn\" src=\"https://user-images.githubusercontent.com/7496278/66396519-7ed66e00-ea0c-11e9-9c1a-5ca54bbd61eb.png\">\n</p>\n\n### 动态图\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-1.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-2.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-3.png)\n\n![](https://raw.githubusercontent.com/panjf2000/illustrations/master/go/ants-pool-4.png)\n\n## 🧰 安装\n\n### 使用 `ants` v1 版本:\n\n``` powershell\ngo get -u github.com/panjf2000/ants\n```\n\n### 使用 `ants` v2 版本 (开启 GO111MODULE=on):\n\n```powershell\ngo get -u github.com/panjf2000/ants/v2\n```\n\n## 🛠 使用\n写 go 并发程序的时候如果程序会启动大量的 goroutine ，势必会消耗大量的系统资源（内存，CPU），通过使用 `ants`，可以实例化一个 goroutine 池，复用 goroutine ，节省资源，提升性能：\n\n``` go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/panjf2000/ants/v2\"\n)\n\nvar sum int32\n\nfunc myFunc(i interface{}) {\n\tn := i.(int32)\n\tatomic.AddInt32(&sum, n)\n\tfmt.Printf(\"run with %d\\n\", n)\n}\n\nfunc demoFunc() {\n\ttime.Sleep(10 * time.Millisecond)\n\tfmt.Println(\"Hello World!\")\n}\n\nfunc main() {\n\tdefer ants.Release()\n\n\trunTimes := 1000\n\n\t// Use the common pool.\n\tvar wg sync.WaitGroup\n\tsyncCalculateSum := func() {\n\t\tdemoFunc()\n\t\twg.Done()\n\t}\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = ants.Submit(syncCalculateSum)\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", ants.Running())\n\tfmt.Printf(\"finish all tasks.\\n\")\n\n\t// Use the pool with a function,\n\t// set 10 to the capacity of goroutine pool and 1 second for expired duration.\n\tp, _ := ants.NewPoolWithFunc(10, func(i interface{}) {\n\t\tmyFunc(i)\n\t\twg.Done()\n\t})\n\tdefer p.Release()\n\t// Submit tasks one by one.\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Invoke(int32(i))\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", p.Running())\n\tfmt.Printf(\"finish all tasks, result is %d\\n\", sum)\n\tif sum != 499500 {\n\t\tpanic(\"the final result is wrong!!!\")\n\t}\n\n\t// Use the MultiPool and set the capacity of the 10 goroutine pools to unlimited.\n\t// If you use -1 as the pool size parameter, the size will be unlimited.\n\t// There are two load-balancing algorithms for pools: ants.RoundRobin and ants.LeastTasks.\n\tmp, _ := ants.NewMultiPool(10, -1, ants.RoundRobin)\n\tdefer mp.ReleaseTimeout(5 * time.Second)\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = mp.Submit(syncCalculateSum)\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", mp.Running())\n\tfmt.Printf(\"finish all tasks.\\n\")\n\n\t// Use the MultiPoolFunc and set the capacity of 10 goroutine pools to (runTimes/10).\n\tmpf, _ := ants.NewMultiPoolWithFunc(10, runTimes/10, func(i interface{}) {\n\t\tmyFunc(i)\n\t\twg.Done()\n\t}, ants.LeastTasks)\n\tdefer mpf.ReleaseTimeout(5 * time.Second)\n\tfor i := 0; i < runTimes; i++ {\n\t\twg.Add(1)\n\t\t_ = mpf.Invoke(int32(i))\n\t}\n\twg.Wait()\n\tfmt.Printf(\"running goroutines: %d\\n\", mpf.Running())\n\tfmt.Printf(\"finish all tasks, result is %d\\n\", sum)\n\tif sum != 499500*2 {\n\t\tpanic(\"the final result is wrong!!!\")\n\t}\n}\n```\n\n### Pool 配置\n\n```go\n// Option represents the optional function.\ntype Option func(opts *Options)\n\n// Options contains all options which will be applied when instantiating a ants pool.\ntype Options struct {\n\t// ExpiryDuration is a period for the scavenger goroutine to clean up those expired workers,\n\t// the scavenger scans all workers every `ExpiryDuration` and clean up those workers that haven't been\n\t// used for more than `ExpiryDuration`.\n\tExpiryDuration time.Duration\n\n\t// PreAlloc indicates whether to make memory pre-allocation when initializing Pool.\n\tPreAlloc bool\n\n\t// Max number of goroutine blocking on pool.Submit.\n\t// 0 (default value) means no such limit.\n\tMaxBlockingTasks int\n\n\t// When Nonblocking is true, Pool.Submit will never be blocked.\n\t// ErrPoolOverload will be returned when Pool.Submit cannot be done at once.\n\t// When Nonblocking is true, MaxBlockingTasks is inoperative.\n\tNonblocking bool\n\n\t// PanicHandler is used to handle panics from each worker goroutine.\n\t// if nil, panics will be thrown out again from worker goroutines.\n\tPanicHandler func(interface{})\n\n\t// Logger is the customized logger for logging info, if it is not set,\n\t// default standard logger from log package is used.\n\tLogger Logger\n}\n\n// WithOptions accepts the whole options config.\nfunc WithOptions(options Options) Option {\n\treturn func(opts *Options) {\n\t\t*opts = options\n\t}\n}\n\n// WithExpiryDuration sets up the interval time of cleaning up goroutines.\nfunc WithExpiryDuration(expiryDuration time.Duration) Option {\n\treturn func(opts *Options) {\n\t\topts.ExpiryDuration = expiryDuration\n\t}\n}\n\n// WithPreAlloc indicates whether it should malloc for workers.\nfunc WithPreAlloc(preAlloc bool) Option {\n\treturn func(opts *Options) {\n\t\topts.PreAlloc = preAlloc\n\t}\n}\n\n// WithMaxBlockingTasks sets up the maximum number of goroutines that are blocked when it reaches the capacity of pool.\nfunc WithMaxBlockingTasks(maxBlockingTasks int) Option {\n\treturn func(opts *Options) {\n\t\topts.MaxBlockingTasks = maxBlockingTasks\n\t}\n}\n\n// WithNonblocking indicates that pool will return nil when there is no available workers.\nfunc WithNonblocking(nonblocking bool) Option {\n\treturn func(opts *Options) {\n\t\topts.Nonblocking = nonblocking\n\t}\n}\n\n// WithPanicHandler sets up panic handler.\nfunc WithPanicHandler(panicHandler func(interface{})) Option {\n\treturn func(opts *Options) {\n\t\topts.PanicHandler = panicHandler\n\t}\n}\n\n// WithLogger sets up a customized logger.\nfunc WithLogger(logger Logger) Option {\n\treturn func(opts *Options) {\n\t\topts.Logger = logger\n\t}\n}\n```\n\n通过在调用`NewPool`/`NewPoolWithFunc`之时使用各种 optional function，可以设置`ants.Options`中各个配置项的值，然后用它来定制化 goroutine pool.\n\n\n### 自定义池\n`ants`支持实例化使用者自己的一个 Pool ，指定具体的池容量；通过调用 `NewPool` 方法可以实例化一个新的带有指定容量的 Pool ，如下：\n\n``` go\np, _ := ants.NewPool(10000)\n```\n\n### 任务提交\n\n提交任务通过调用 `ants.Submit(func())`方法：\n```go\nants.Submit(func(){})\n```\n\n### 动态调整 goroutine 池容量\n需要动态调整 goroutine 池容量可以通过调用`Tune(int)`：\n\n``` go\npool.Tune(1000) // Tune its capacity to 1000\npool.Tune(100000) // Tune its capacity to 100000\n```\n\n该方法是线程安全的。\n\n### 预先分配 goroutine 队列内存\n\n`ants`允许你预先把整个池的容量分配内存， 这个功能可以在某些特定的场景下提高 goroutine 池的性能。比如， 有一个场景需要一个超大容量的池，而且每个 goroutine 里面的任务都是耗时任务，这种情况下，预先分配 goroutine 队列内存将会减少不必要的内存重新分配。\n\n```go\n// ants will pre-malloc the whole capacity of pool when you invoke this function\np, _ := ants.NewPool(100000, ants.WithPreAlloc(true))\n```\n\n### 释放 Pool\n\n```go\npool.Release()\n```\n\n或者\n\n```go\npool.ReleaseTimeout(time.Second * 3)\n```\n\n### 重启 Pool\n\n```go\n// 只要调用 Reboot() 方法，就可以重新激活一个之前已经被销毁掉的池，并且投入使用。\npool.Reboot()\n```\n\n## ⚙️ 关于任务执行顺序\n\n`ants` 并不保证提交的任务被执行的顺序，执行的顺序也不是和提交的顺序保持一致，因为在 `ants` 是并发地处理所有提交的任务，提交的任务会被分派到正在并发运行的 workers 上去，因此那些任务将会被并发且无序地被执行。\n\n## 👏 贡献者\n\n请在提 PR 之前仔细阅读 [Contributing Guidelines](CONTRIBUTING.md)，感谢那些为 `ants` 贡献过代码的开发者！\n\n<a href=\"https://github.com/panjf2000/ants/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=panjf2000/ants\" />\n</a>\n\n## 📄 证书\n\n`ants` 的源码允许用户在遵循 [MIT 开源证书](/LICENSE) 规则的前提下使用。\n\n## 📚 相关文章\n\n-  [Goroutine 并发调度模型深度解析之手撸一个高性能 goroutine 池](https://taohuawu.club/high-performance-implementation-of-goroutine-pool)\n-  [Visually Understanding Worker Pool](https://medium.com/coinmonks/visually-understanding-worker-pool-48a83b7fc1f5)\n-  [The Case For A Go Worker Pool](https://brandur.org/go-worker-pool)\n-  [Go Concurrency - GoRoutines, Worker Pools and Throttling Made Simple](https://twin.sh/articles/39/go-concurrency-goroutines-worker-pools-and-throttling-made-simple)\n\n## 🖥 用户案例\n\n### 商业公司\n\n以下公司/组织在生产环境上使用了 `ants`。\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.tencent.com/\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/tencent_logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.bytedance.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/ByteDance_Logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://tieba.baidu.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/baidu-tieba-logo.png\" width=\"300\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://weibo.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/weibo-logo.png\" width=\"300\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.tencentmusic.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/tencent-music-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.futuhk.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/futu-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.shopify.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/shopify-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://weixin.qq.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/wechat-logo.png\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.baidu.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/baidu-mobile-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.360.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/360-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.huaweicloud.com/\" target=\"_blank\">\n          <img src=\"https://res-static.hc-cdn.cn/cloudbu-site/china/zh-cn/wangxue/header/logo.svg\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://matrixorigin.cn/\" target=\"_blank\">\n          <img src=\"https://matrixorigin.cn/_next/static/media/logo-light-zh.a2a8f3c0.svg\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://adguard-dns.io/\" target=\"_blank\">\n          <img src=\"https://cdn.adtidy.org/website/images/AdGuardDNS_black.svg\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://bk.tencent.com/\" target=\"_blank\">\n          <img src=\"https://static.apiseven.com/2022/11/14/6371adab14119.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://cn.aliyun.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/aliyun-cn-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.zuoyebang.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/zuoyebang-logo.jpeg\" width=\"300\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.antgroup.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/ant-group-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://zilliz.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/zilliz-logo.png\" width=\"250\" />\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://amap.com/\" target=\"_blank\">\n          <img src=\"https://res.strikefreedom.top/static_res/logos/amap-logo.png\" width=\"250\" />\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n如果你也正在生产环境上使用 `ants`，欢迎提 PR 来丰富这份列表。\n\n### 开源软件\n\n这些开源项目借助 `ants` 进行并发编程。\n\n- [gnet](https://github.com/panjf2000/gnet):  gnet 是一个高性能、轻量级、非阻塞的事件驱动 Go 网络框架。\n- [milvus](https://github.com/milvus-io/milvus): 一个高度灵活、可靠且速度极快的云原生开源向量数据库。\n- [nps](https://github.com/ehang-io/nps): 一款轻量级、高性能、功能强大的内网穿透代理服务器。\n- [TDengine](https://github.com/taosdata/TDengine): TDengine 是一款开源、高性能、云原生的时序数据库 (Time-Series Database, TSDB)。TDengine 能被广泛运用于物联网、工业互联网、车联网、IT 运维、金融等领域。\n- [siyuan](https://github.com/siyuan-note/siyuan): 思源笔记是一款本地优先的个人知识管理系统，支持完全离线使用，同时也支持端到端加密同步。\n- [osmedeus](https://github.com/j3ssie/osmedeus): A Workflow Engine for Offensive Security.\n- [jitsu](https://github.com/jitsucom/jitsu/tree/master): An open-source Segment alternative. Fully-scriptable data ingestion engine for modern data teams. Set-up a real-time data pipeline in minutes, not days.\n- [triangula](https://github.com/RH12503/triangula): Generate high-quality triangulated and polygonal art from images.\n- [teler](https://github.com/kitabisa/teler): Real-time HTTP Intrusion Detection.\n- [bsc](https://github.com/binance-chain/bsc): A Binance Smart Chain client based on the go-ethereum fork.\n- [jaeles](https://github.com/jaeles-project/jaeles): The Swiss Army knife for automated Web Application Testing.\n- [devlake](https://github.com/apache/incubator-devlake): The open-source dev data platform & dashboard for your DevOps tools.\n- [matrixone](https://github.com/matrixorigin/matrixone): MatrixOne 是一款面向未来的超融合异构云原生数据库，通过超融合数据引擎支持事务/分析/流处理等混合工作负载，通过异构云原生架构支持跨机房协同/多地协同/云边协同。简化开发运维，消简数据碎片，打破数据的系统、位置和创新边界。\n- [bk-bcs](https://github.com/TencentBlueKing/bk-bcs): 蓝鲸容器管理平台（Blueking Container Service）定位于打造云原生技术和业务实际应用场景之间的桥梁；聚焦于复杂应用场景的容器化部署技术方案的研发、整合和产品化；致力于为游戏等复杂应用提供一站式、低门槛的容器编排和服务治理服务。\n- [trueblocks-core](https://github.com/TrueBlocks/trueblocks-core): TrueBlocks improves access to blockchain data for any EVM-compatible chain (particularly Ethereum mainnet) while remaining entirely local.\n- [openGemini](https://github.com/openGemini/openGemini): openGemini 是华为云开源的一款云原生分布式时序数据库，可广泛应用于物联网、车联网、运维监控、工业互联网等业务场景，具备卓越的读写性能和高效的数据分析能力，采用类SQL查询语言，无第三方软件依赖、安装简单、部署灵活、运维便捷。\n- [AdGuardDNS](https://github.com/AdguardTeam/AdGuardDNS): AdGuard DNS is an alternative solution for tracker blocking, privacy protection, and parental control.\n- [WatchAD2.0](https://github.com/Qihoo360/WatchAD2.0): WatchAD2.0 是 360 信息安全中心开发的一款针对域安全的日志分析与监控系统，它可以收集所有域控上的事件日志、网络流量，通过特征匹配、协议分析、历史行为、敏感操作和蜜罐账户等方式来检测各种已知与未知威胁，功能覆盖了大部分目前的常见内网域渗透手法。\n- [vanus](https://github.com/vanus-labs/vanus): Vanus is a Serverless, event streaming system with processing capabilities. It easily connects SaaS, Cloud Services, and Databases to help users build next-gen Event-driven Applications.\n- [trpc-go](https://github.com/trpc-group/trpc-go): 一个 Go 实现的可插拔的高性能 RPC 框架。\n- [motan-go](https://github.com/weibocom/motan-go): Motan 是一套高性能、易于使用的分布式远程服务调用 (RPC) 框架。motan-go 是 motan 的 Go 语言实现。\n\n#### 所有案例:\n\n- [Repositories that depend on ants/v2](https://github.com/panjf2000/ants/network/dependents?package_id=UGFja2FnZS0yMjY2ODgxMjg2)\n\n- [Repositories that depend on ants/v1](https://github.com/panjf2000/ants/network/dependents?package_id=UGFja2FnZS0yMjY0ODMzNjEw)\n\n如果你的项目也在使用 `ants`，欢迎给我提 Pull Request 来更新这份用户案例列表。\n\n## 🔋 JetBrains 开源证书支持\n\n`ants` 项目一直以来都是在 JetBrains 公司旗下的 GoLand 集成开发环境中进行开发，基于 **free JetBrains Open Source license(s)** 正版免费授权，在此表达我的谢意。\n\n<a href=\"https://www.jetbrains.com/?from=ants\" target=\"_blank\"><img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo.\"></a>\n\n## 💰 支持\n\n如果有意向，可以通过每个月定量的少许捐赠来支持这个项目。\n\n<a href=\"https://opencollective.com/ants#backers\" target=\"_blank\"><img src=\"https://opencollective.com/ants/backers.svg\"></a>\n\n## 💎 赞助\n\n每月定量捐赠 10 刀即可成为本项目的赞助者，届时您的 logo 或者 link 可以展示在本项目的 README 上。\n\n<a href=\"https://opencollective.com/ants#sponsors\" target=\"_blank\"><img src=\"https://opencollective.com/ants/sponsors.svg\"></a>\n\n## ☕️ 打赏\n\n> 当您通过以下方式进行捐赠时，请务必留下姓名、GitHub 账号或其他社交媒体账号，以便我将其添加到捐赠者名单中，以表谢意。\n\n<img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/WeChatPay.JPG\" width=\"250\" align=\"middle\"/>&nbsp;&nbsp;\n<img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/AliPay.JPG\" width=\"250\" align=\"middle\"/>&nbsp;&nbsp;\n<a href=\"https://www.paypal.me/R136a1X\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/panjf2000/illustrations/master/payments/PayPal.JPG\" width=\"250\" align=\"middle\"/></a>&nbsp;&nbsp;\n\n## 🔋 赞助商\n\n<p>\n  <a href=\"https://www.digitalocean.com/\">\n    <img src=\"https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/PoweredByDO/DO_Powered_by_Badge_blue.svg\" width=\"201px\">\n  </a>\n</p>\n"
        },
        {
          "name": "ants.go",
          "type": "blob",
          "size": 4.640625,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"errors\"\n\t\"log\"\n\t\"math\"\n\t\"os\"\n\t\"runtime\"\n\t\"time\"\n)\n\nconst (\n\t// DefaultAntsPoolSize is the default capacity for a default goroutine pool.\n\tDefaultAntsPoolSize = math.MaxInt32\n\n\t// DefaultCleanIntervalTime is the interval time to clean up goroutines.\n\tDefaultCleanIntervalTime = time.Second\n)\n\nconst (\n\t// OPENED represents that the pool is opened.\n\tOPENED = iota\n\n\t// CLOSED represents that the pool is closed.\n\tCLOSED\n)\n\nvar (\n\t// ErrLackPoolFunc will be returned when invokers don't provide function for pool.\n\tErrLackPoolFunc = errors.New(\"must provide function for pool\")\n\n\t// ErrInvalidPoolExpiry will be returned when setting a negative number as the periodic duration to purge goroutines.\n\tErrInvalidPoolExpiry = errors.New(\"invalid expiry for pool\")\n\n\t// ErrPoolClosed will be returned when submitting task to a closed pool.\n\tErrPoolClosed = errors.New(\"this pool has been closed\")\n\n\t// ErrPoolOverload will be returned when the pool is full and no workers available.\n\tErrPoolOverload = errors.New(\"too many goroutines blocked on submit or Nonblocking is set\")\n\n\t// ErrInvalidPreAllocSize will be returned when trying to set up a negative capacity under PreAlloc mode.\n\tErrInvalidPreAllocSize = errors.New(\"can not set up a negative capacity under PreAlloc mode\")\n\n\t// ErrTimeout will be returned after the operations timed out.\n\tErrTimeout = errors.New(\"operation timed out\")\n\n\t// ErrInvalidPoolIndex will be returned when trying to retrieve a pool with an invalid index.\n\tErrInvalidPoolIndex = errors.New(\"invalid pool index\")\n\n\t// ErrInvalidLoadBalancingStrategy will be returned when trying to create a MultiPool with an invalid load-balancing strategy.\n\tErrInvalidLoadBalancingStrategy = errors.New(\"invalid load-balancing strategy\")\n\n\t// workerChanCap determines whether the channel of a worker should be a buffered channel\n\t// to get the best performance. Inspired by fasthttp at\n\t// https://github.com/valyala/fasthttp/blob/master/workerpool.go#L139\n\tworkerChanCap = func() int {\n\t\t// Use blocking channel if GOMAXPROCS=1.\n\t\t// This switches context from sender to receiver immediately,\n\t\t// which results in higher performance (under go1.5 at least).\n\t\tif runtime.GOMAXPROCS(0) == 1 {\n\t\t\treturn 0\n\t\t}\n\n\t\t// Use non-blocking workerChan if GOMAXPROCS>1,\n\t\t// since otherwise the sender might be dragged down if the receiver is CPU-bound.\n\t\treturn 1\n\t}()\n\n\tdefaultLogger = Logger(log.New(os.Stderr, \"[ants]: \", log.LstdFlags|log.Lmsgprefix|log.Lmicroseconds))\n\n\t// Init an instance pool when importing ants.\n\tdefaultAntsPool, _ = NewPool(DefaultAntsPoolSize)\n)\n\nconst nowTimeUpdateInterval = 500 * time.Millisecond\n\n// Logger is used for logging formatted messages.\ntype Logger interface {\n\t// Printf must have the same semantics as log.Printf.\n\tPrintf(format string, args ...interface{})\n}\n\n// Submit submits a task to pool.\nfunc Submit(task func()) error {\n\treturn defaultAntsPool.Submit(task)\n}\n\n// Running returns the number of the currently running goroutines.\nfunc Running() int {\n\treturn defaultAntsPool.Running()\n}\n\n// Cap returns the capacity of this default pool.\nfunc Cap() int {\n\treturn defaultAntsPool.Cap()\n}\n\n// Free returns the available goroutines to work.\nfunc Free() int {\n\treturn defaultAntsPool.Free()\n}\n\n// Release Closes the default pool.\nfunc Release() {\n\tdefaultAntsPool.Release()\n}\n\n// ReleaseTimeout is like Release but with a timeout, it waits all workers to exit before timing out.\nfunc ReleaseTimeout(timeout time.Duration) error {\n\treturn defaultAntsPool.ReleaseTimeout(timeout)\n}\n\n// Reboot reboots the default pool.\nfunc Reboot() {\n\tdefaultAntsPool.Reboot()\n}\n"
        },
        {
          "name": "ants_benchmark_test.go",
          "type": "blob",
          "size": 4.8486328125,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n\n\t\"golang.org/x/sync/errgroup\"\n)\n\nconst (\n\tRunTimes           = 1e6\n\tPoolCap            = 5e4\n\tBenchParam         = 10\n\tDefaultExpiredTime = 10 * time.Second\n)\n\nfunc demoFunc() {\n\ttime.Sleep(time.Duration(BenchParam) * time.Millisecond)\n}\n\nfunc demoPoolFunc(args interface{}) {\n\tn := args.(int)\n\ttime.Sleep(time.Duration(n) * time.Millisecond)\n}\n\nvar stopLongRunningFunc int32\n\nfunc longRunningFunc() {\n\tfor atomic.LoadInt32(&stopLongRunningFunc) == 0 {\n\t\truntime.Gosched()\n\t}\n}\n\nvar stopLongRunningPoolFunc int32\n\nfunc longRunningPoolFunc(arg interface{}) {\n\tif ch, ok := arg.(chan struct{}); ok {\n\t\t<-ch\n\t\treturn\n\t}\n\tfor atomic.LoadInt32(&stopLongRunningPoolFunc) == 0 {\n\t\truntime.Gosched()\n\t}\n}\n\nfunc BenchmarkGoroutines(b *testing.B) {\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(RunTimes)\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\tgo func() {\n\t\t\t\tdemoFunc()\n\t\t\t\twg.Done()\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}\n}\n\nfunc BenchmarkChannel(b *testing.B) {\n\tvar wg sync.WaitGroup\n\tsema := make(chan struct{}, PoolCap)\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(RunTimes)\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\tsema <- struct{}{}\n\t\t\tgo func() {\n\t\t\t\tdemoFunc()\n\t\t\t\t<-sema\n\t\t\t\twg.Done()\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}\n}\n\nfunc BenchmarkErrGroup(b *testing.B) {\n\tvar wg sync.WaitGroup\n\tvar pool errgroup.Group\n\tpool.SetLimit(PoolCap)\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(RunTimes)\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\tpool.Go(func() error {\n\t\t\t\tdemoFunc()\n\t\t\t\twg.Done()\n\t\t\t\treturn nil\n\t\t\t})\n\t\t}\n\t\twg.Wait()\n\t}\n}\n\nfunc BenchmarkAntsPool(b *testing.B) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPool(PoolCap, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.Release()\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(RunTimes)\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\t_ = p.Submit(func() {\n\t\t\t\tdemoFunc()\n\t\t\t\twg.Done()\n\t\t\t})\n\t\t}\n\t\twg.Wait()\n\t}\n}\n\nfunc BenchmarkAntsMultiPool(b *testing.B) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewMultiPool(10, PoolCap/10, RoundRobin, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.ReleaseTimeout(DefaultExpiredTime) //nolint:errcheck\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(RunTimes)\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\t_ = p.Submit(func() {\n\t\t\t\tdemoFunc()\n\t\t\t\twg.Done()\n\t\t\t})\n\t\t}\n\t\twg.Wait()\n\t}\n}\n\nfunc BenchmarkGoroutinesThroughput(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\tgo demoFunc()\n\t\t}\n\t}\n}\n\nfunc BenchmarkSemaphoreThroughput(b *testing.B) {\n\tsema := make(chan struct{}, PoolCap)\n\tfor i := 0; i < b.N; i++ {\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\tsema <- struct{}{}\n\t\t\tgo func() {\n\t\t\t\tdemoFunc()\n\t\t\t\t<-sema\n\t\t\t}()\n\t\t}\n\t}\n}\n\nfunc BenchmarkAntsPoolThroughput(b *testing.B) {\n\tp, _ := NewPool(PoolCap, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.Release()\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\t_ = p.Submit(demoFunc)\n\t\t}\n\t}\n}\n\nfunc BenchmarkAntsMultiPoolThroughput(b *testing.B) {\n\tp, _ := NewMultiPool(10, PoolCap/10, RoundRobin, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.ReleaseTimeout(DefaultExpiredTime) //nolint:errcheck\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tfor j := 0; j < RunTimes; j++ {\n\t\t\t_ = p.Submit(demoFunc)\n\t\t}\n\t}\n}\n\nfunc BenchmarkParallelAntsPoolThroughput(b *testing.B) {\n\tp, _ := NewPool(PoolCap, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.Release()\n\n\tb.ResetTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\t_ = p.Submit(demoFunc)\n\t\t}\n\t})\n}\n\nfunc BenchmarkParallelAntsMultiPoolThroughput(b *testing.B) {\n\tp, _ := NewMultiPool(10, PoolCap/10, RoundRobin, WithExpiryDuration(DefaultExpiredTime))\n\tdefer p.ReleaseTimeout(DefaultExpiredTime) //nolint:errcheck\n\n\tb.ResetTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\t_ = p.Submit(demoFunc)\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "ants_test.go",
          "type": "blob",
          "size": 29.8583984375,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst (\n\t_   = 1 << (10 * iota)\n\tKiB // 1024\n\tMiB // 1048576\n)\n\nconst (\n\tParam    = 100\n\tAntsSize = 1000\n\tTestSize = 10000\n\tn        = 100000\n)\n\nvar curMem uint64\n\n// TestAntsPoolWaitToGetWorker is used to test waiting to get worker.\nfunc TestAntsPoolWaitToGetWorker(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPool(AntsSize)\n\tdefer p.Release()\n\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Submit(func() {\n\t\t\tdemoPoolFunc(Param)\n\t\t\twg.Done()\n\t\t})\n\t}\n\twg.Wait()\n\tt.Logf(\"pool, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\nfunc TestAntsPoolWaitToGetWorkerPreMalloc(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPool(AntsSize, WithPreAlloc(true))\n\tdefer p.Release()\n\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Submit(func() {\n\t\t\tdemoPoolFunc(Param)\n\t\t\twg.Done()\n\t\t})\n\t}\n\twg.Wait()\n\tt.Logf(\"pool, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\n// TestAntsPoolWithFuncWaitToGetWorker is used to test waiting to get worker.\nfunc TestAntsPoolWithFuncWaitToGetWorker(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPoolWithFunc(AntsSize, func(i interface{}) {\n\t\tdemoPoolFunc(i)\n\t\twg.Done()\n\t})\n\tdefer p.Release()\n\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Invoke(Param)\n\t}\n\twg.Wait()\n\tt.Logf(\"pool with func, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\nfunc TestAntsPoolWithFuncWaitToGetWorkerPreMalloc(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPoolWithFunc(AntsSize, func(i interface{}) {\n\t\tdemoPoolFunc(i)\n\t\twg.Done()\n\t}, WithPreAlloc(true))\n\tdefer p.Release()\n\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\t_ = p.Invoke(Param)\n\t}\n\twg.Wait()\n\tt.Logf(\"pool with func, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\n// TestAntsPoolGetWorkerFromCache is used to test getting worker from sync.Pool.\nfunc TestAntsPoolGetWorkerFromCache(t *testing.T) {\n\tp, _ := NewPool(TestSize)\n\tdefer p.Release()\n\n\tfor i := 0; i < AntsSize; i++ {\n\t\t_ = p.Submit(demoFunc)\n\t}\n\ttime.Sleep(2 * DefaultCleanIntervalTime)\n\t_ = p.Submit(demoFunc)\n\tt.Logf(\"pool, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\n// TestAntsPoolWithFuncGetWorkerFromCache is used to test getting worker from sync.Pool.\nfunc TestAntsPoolWithFuncGetWorkerFromCache(t *testing.T) {\n\tdur := 10\n\tp, _ := NewPoolWithFunc(TestSize, demoPoolFunc)\n\tdefer p.Release()\n\n\tfor i := 0; i < AntsSize; i++ {\n\t\t_ = p.Invoke(dur)\n\t}\n\ttime.Sleep(2 * DefaultCleanIntervalTime)\n\t_ = p.Invoke(dur)\n\tt.Logf(\"pool with func, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\nfunc TestAntsPoolWithFuncGetWorkerFromCachePreMalloc(t *testing.T) {\n\tdur := 10\n\tp, _ := NewPoolWithFunc(TestSize, demoPoolFunc, WithPreAlloc(true))\n\tdefer p.Release()\n\n\tfor i := 0; i < AntsSize; i++ {\n\t\t_ = p.Invoke(dur)\n\t}\n\ttime.Sleep(2 * DefaultCleanIntervalTime)\n\t_ = p.Invoke(dur)\n\tt.Logf(\"pool with func, running workers number:%d\", p.Running())\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\n// Contrast between goroutines without a pool and goroutines with ants pool.\n\nfunc TestNoPool(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdemoFunc()\n\t\t\twg.Done()\n\t\t}()\n\t}\n\n\twg.Wait()\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\nfunc TestAntsPool(t *testing.T) {\n\tdefer Release()\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < n; i++ {\n\t\twg.Add(1)\n\t\t_ = Submit(func() {\n\t\t\tdemoFunc()\n\t\t\twg.Done()\n\t\t})\n\t}\n\twg.Wait()\n\n\tt.Logf(\"pool, capacity:%d\", Cap())\n\tt.Logf(\"pool, running workers number:%d\", Running())\n\tt.Logf(\"pool, free workers number:%d\", Free())\n\n\tmem := runtime.MemStats{}\n\truntime.ReadMemStats(&mem)\n\tcurMem = mem.TotalAlloc/MiB - curMem\n\tt.Logf(\"memory usage:%d MB\", curMem)\n}\n\nfunc TestPanicHandler(t *testing.T) {\n\tvar panicCounter int64\n\tvar wg sync.WaitGroup\n\tp0, err := NewPool(10, WithPanicHandler(func(p interface{}) {\n\t\tdefer wg.Done()\n\t\tatomic.AddInt64(&panicCounter, 1)\n\t\tt.Logf(\"catch panic with PanicHandler: %v\", p)\n\t}))\n\tassert.NoErrorf(t, err, \"create new pool failed: %v\", err)\n\tdefer p0.Release()\n\twg.Add(1)\n\t_ = p0.Submit(func() {\n\t\tpanic(\"Oops!\")\n\t})\n\twg.Wait()\n\tc := atomic.LoadInt64(&panicCounter)\n\tassert.EqualValuesf(t, 1, c, \"panic handler didn't work, panicCounter: %d\", c)\n\tassert.EqualValues(t, 0, p0.Running(), \"pool should be empty after panic\")\n\tp1, err := NewPoolWithFunc(10, func(p interface{}) { panic(p) }, WithPanicHandler(func(_ interface{}) {\n\t\tdefer wg.Done()\n\t\tatomic.AddInt64(&panicCounter, 1)\n\t}))\n\tassert.NoErrorf(t, err, \"create new pool with func failed: %v\", err)\n\tdefer p1.Release()\n\twg.Add(1)\n\t_ = p1.Invoke(\"Oops!\")\n\twg.Wait()\n\tc = atomic.LoadInt64(&panicCounter)\n\tassert.EqualValuesf(t, 2, c, \"panic handler didn't work, panicCounter: %d\", c)\n\tassert.EqualValues(t, 0, p1.Running(), \"pool should be empty after panic\")\n}\n\nfunc TestPanicHandlerPreMalloc(t *testing.T) {\n\tvar panicCounter int64\n\tvar wg sync.WaitGroup\n\tp0, err := NewPool(10, WithPreAlloc(true), WithPanicHandler(func(p interface{}) {\n\t\tdefer wg.Done()\n\t\tatomic.AddInt64(&panicCounter, 1)\n\t\tt.Logf(\"catch panic with PanicHandler: %v\", p)\n\t}))\n\tassert.NoErrorf(t, err, \"create new pool failed: %v\", err)\n\tdefer p0.Release()\n\twg.Add(1)\n\t_ = p0.Submit(func() {\n\t\tpanic(\"Oops!\")\n\t})\n\twg.Wait()\n\tc := atomic.LoadInt64(&panicCounter)\n\tassert.EqualValuesf(t, 1, c, \"panic handler didn't work, panicCounter: %d\", c)\n\tassert.EqualValues(t, 0, p0.Running(), \"pool should be empty after panic\")\n\tp1, err := NewPoolWithFunc(10, func(p interface{}) { panic(p) }, WithPanicHandler(func(_ interface{}) {\n\t\tdefer wg.Done()\n\t\tatomic.AddInt64(&panicCounter, 1)\n\t}))\n\tassert.NoErrorf(t, err, \"create new pool with func failed: %v\", err)\n\tdefer p1.Release()\n\twg.Add(1)\n\t_ = p1.Invoke(\"Oops!\")\n\twg.Wait()\n\tc = atomic.LoadInt64(&panicCounter)\n\tassert.EqualValuesf(t, 2, c, \"panic handler didn't work, panicCounter: %d\", c)\n\tassert.EqualValues(t, 0, p1.Running(), \"pool should be empty after panic\")\n}\n\nfunc TestPoolPanicWithoutHandler(t *testing.T) {\n\tp0, err := NewPool(10)\n\tassert.NoErrorf(t, err, \"create new pool failed: %v\", err)\n\tdefer p0.Release()\n\t_ = p0.Submit(func() {\n\t\tpanic(\"Oops!\")\n\t})\n\n\tp1, err := NewPoolWithFunc(10, func(p interface{}) {\n\t\tpanic(p)\n\t})\n\tassert.NoErrorf(t, err, \"create new pool with func failed: %v\", err)\n\tdefer p1.Release()\n\t_ = p1.Invoke(\"Oops!\")\n}\n\nfunc TestPoolPanicWithoutHandlerPreMalloc(t *testing.T) {\n\tp0, err := NewPool(10, WithPreAlloc(true))\n\tassert.NoErrorf(t, err, \"create new pool failed: %v\", err)\n\tdefer p0.Release()\n\t_ = p0.Submit(func() {\n\t\tpanic(\"Oops!\")\n\t})\n\n\tp1, err := NewPoolWithFunc(10, func(p interface{}) {\n\t\tpanic(p)\n\t})\n\n\tassert.NoErrorf(t, err, \"create new pool with func failed: %v\", err)\n\n\tdefer p1.Release()\n\t_ = p1.Invoke(\"Oops!\")\n}\n\nfunc TestPurgePool(t *testing.T) {\n\tsize := 500\n\tch := make(chan struct{})\n\n\tp, err := NewPool(size)\n\tassert.NoErrorf(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\n\tfor i := 0; i < size; i++ {\n\t\tj := i + 1\n\t\t_ = p.Submit(func() {\n\t\t\t<-ch\n\t\t\td := j % 100\n\t\t\ttime.Sleep(time.Duration(d) * time.Millisecond)\n\t\t})\n\t}\n\tassert.Equalf(t, size, p.Running(), \"pool should be full, expected: %d, but got: %d\", size, p.Running())\n\n\tclose(ch)\n\ttime.Sleep(5 * DefaultCleanIntervalTime)\n\tassert.Equalf(t, 0, p.Running(), \"pool should be empty after purge, but got %d\", p.Running())\n\n\tch = make(chan struct{})\n\tf := func(i interface{}) {\n\t\t<-ch\n\t\td := i.(int) % 100\n\t\ttime.Sleep(time.Duration(d) * time.Millisecond)\n\t}\n\n\tp1, err := NewPoolWithFunc(size, f)\n\tassert.NoErrorf(t, err, \"create TimingPoolWithFunc failed: %v\", err)\n\tdefer p1.Release()\n\n\tfor i := 0; i < size; i++ {\n\t\t_ = p1.Invoke(i)\n\t}\n\tassert.Equalf(t, size, p1.Running(), \"pool should be full, expected: %d, but got: %d\", size, p1.Running())\n\n\tclose(ch)\n\ttime.Sleep(5 * DefaultCleanIntervalTime)\n\tassert.Equalf(t, 0, p1.Running(), \"pool should be empty after purge, but got %d\", p1.Running())\n}\n\nfunc TestPurgePreMallocPool(t *testing.T) {\n\tp, err := NewPool(10, WithPreAlloc(true))\n\tassert.NoErrorf(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\t_ = p.Submit(demoFunc)\n\ttime.Sleep(3 * DefaultCleanIntervalTime)\n\tassert.EqualValues(t, 0, p.Running(), \"all p should be purged\")\n\tp1, err := NewPoolWithFunc(10, demoPoolFunc)\n\tassert.NoErrorf(t, err, \"create TimingPoolWithFunc failed: %v\", err)\n\tdefer p1.Release()\n\t_ = p1.Invoke(1)\n\ttime.Sleep(3 * DefaultCleanIntervalTime)\n\tassert.EqualValues(t, 0, p.Running(), \"all p should be purged\")\n}\n\nfunc TestNonblockingSubmit(t *testing.T) {\n\tpoolSize := 10\n\tp, err := NewPool(poolSize, WithNonblocking(true))\n\tassert.NoErrorf(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\tfor i := 0; i < poolSize-1; i++ {\n\t\tassert.NoError(t, p.Submit(longRunningFunc), \"nonblocking submit when pool is not full shouldn't return error\")\n\t}\n\tch := make(chan struct{})\n\tch1 := make(chan struct{})\n\tf := func() {\n\t\t<-ch\n\t\tclose(ch1)\n\t}\n\t// p is full now.\n\tassert.NoError(t, p.Submit(f), \"nonblocking submit when pool is not full shouldn't return error\")\n\tassert.EqualError(t, p.Submit(demoFunc), ErrPoolOverload.Error(),\n\t\t\"nonblocking submit when pool is full should get an ErrPoolOverload\")\n\t// interrupt f to get an available worker\n\tclose(ch)\n\t<-ch1\n\tassert.NoError(t, p.Submit(demoFunc), \"nonblocking submit when pool is not full shouldn't return error\")\n}\n\nfunc TestMaxBlockingSubmit(t *testing.T) {\n\tpoolSize := 10\n\tp, err := NewPool(poolSize, WithMaxBlockingTasks(1))\n\tassert.NoErrorf(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\tfor i := 0; i < poolSize-1; i++ {\n\t\tassert.NoError(t, p.Submit(longRunningFunc), \"submit when pool is not full shouldn't return error\")\n\t}\n\tch := make(chan struct{})\n\tf := func() {\n\t\t<-ch\n\t}\n\t// p is full now.\n\tassert.NoError(t, p.Submit(f), \"submit when pool is not full shouldn't return error\")\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\t// should be blocked. blocking num == 1\n\t\tif err := p.Submit(demoFunc); err != nil {\n\t\t\terrCh <- err\n\t\t}\n\t\twg.Done()\n\t}()\n\ttime.Sleep(1 * time.Second)\n\t// already reached max blocking limit\n\tassert.EqualError(t, p.Submit(demoFunc), ErrPoolOverload.Error(),\n\t\t\"blocking submit when pool reach max blocking submit should return ErrPoolOverload\")\n\t// interrupt f to make blocking submit successful.\n\tclose(ch)\n\twg.Wait()\n\tselect {\n\tcase <-errCh:\n\t\tt.Fatalf(\"blocking submit when pool is full should not return error\")\n\tdefault:\n\t}\n}\n\nfunc TestNonblockingSubmitWithFunc(t *testing.T) {\n\tpoolSize := 10\n\tvar wg sync.WaitGroup\n\tp, err := NewPoolWithFunc(poolSize, func(i interface{}) {\n\t\tlongRunningPoolFunc(i)\n\t\twg.Done()\n\t}, WithNonblocking(true))\n\tassert.NoError(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\tch := make(chan struct{})\n\twg.Add(poolSize)\n\tfor i := 0; i < poolSize-1; i++ {\n\t\tassert.NoError(t, p.Invoke(ch), \"nonblocking submit when pool is not full shouldn't return error\")\n\t}\n\t// p is full now.\n\tassert.NoError(t, p.Invoke(ch), \"nonblocking submit when pool is not full shouldn't return error\")\n\tassert.EqualError(t, p.Invoke(nil), ErrPoolOverload.Error(),\n\t\t\"nonblocking submit when pool is full should get an ErrPoolOverload\")\n\t// interrupt f to get an available worker\n\tclose(ch)\n\twg.Wait()\n\tassert.NoError(t, p.Invoke(nil), \"nonblocking submit when pool is not full shouldn't return error\")\n}\n\nfunc TestMaxBlockingSubmitWithFunc(t *testing.T) {\n\tpoolSize := 10\n\tp, err := NewPoolWithFunc(poolSize, longRunningPoolFunc, WithMaxBlockingTasks(1))\n\tassert.NoError(t, err, \"create TimingPool failed: %v\", err)\n\tdefer p.Release()\n\tfor i := 0; i < poolSize-1; i++ {\n\t\tassert.NoError(t, p.Invoke(Param), \"submit when pool is not full shouldn't return error\")\n\t}\n\tch := make(chan struct{})\n\t// p is full now.\n\tassert.NoError(t, p.Invoke(ch), \"submit when pool is not full shouldn't return error\")\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\t// should be blocked. blocking num == 1\n\t\tif err := p.Invoke(Param); err != nil {\n\t\t\terrCh <- err\n\t\t}\n\t\twg.Done()\n\t}()\n\ttime.Sleep(1 * time.Second)\n\t// already reached max blocking limit\n\tassert.EqualErrorf(t, p.Invoke(Param), ErrPoolOverload.Error(),\n\t\t\"blocking submit when pool reach max blocking submit should return ErrPoolOverload: %v\", err)\n\t// interrupt one func to make blocking submit successful.\n\tclose(ch)\n\twg.Wait()\n\tselect {\n\tcase <-errCh:\n\t\tt.Fatalf(\"blocking submit when pool is full should not return error\")\n\tdefault:\n\t}\n}\n\nfunc TestRebootDefaultPool(t *testing.T) {\n\tdefer Release()\n\tReboot() // should do nothing inside\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\t_ = Submit(func() {\n\t\tdemoFunc()\n\t\twg.Done()\n\t})\n\twg.Wait()\n\tassert.NoError(t, ReleaseTimeout(time.Second))\n\tassert.EqualError(t, Submit(nil), ErrPoolClosed.Error(), \"pool should be closed\")\n\tReboot()\n\twg.Add(1)\n\tassert.NoError(t, Submit(func() { wg.Done() }), \"pool should be rebooted\")\n\twg.Wait()\n}\n\nfunc TestRebootNewPool(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, err := NewPool(10)\n\tassert.NoErrorf(t, err, \"create Pool failed: %v\", err)\n\tdefer p.Release()\n\twg.Add(1)\n\t_ = p.Submit(func() {\n\t\tdemoFunc()\n\t\twg.Done()\n\t})\n\twg.Wait()\n\tassert.NoError(t, p.ReleaseTimeout(time.Second))\n\tassert.EqualError(t, p.Submit(nil), ErrPoolClosed.Error(), \"pool should be closed\")\n\tp.Reboot()\n\twg.Add(1)\n\tassert.NoError(t, p.Submit(func() { wg.Done() }), \"pool should be rebooted\")\n\twg.Wait()\n\n\tp1, err := NewPoolWithFunc(10, func(i interface{}) {\n\t\tdemoPoolFunc(i)\n\t\twg.Done()\n\t})\n\tassert.NoErrorf(t, err, \"create TimingPoolWithFunc failed: %v\", err)\n\tdefer p1.Release()\n\twg.Add(1)\n\t_ = p1.Invoke(1)\n\twg.Wait()\n\tassert.NoError(t, p1.ReleaseTimeout(time.Second))\n\tassert.EqualError(t, p1.Invoke(nil), ErrPoolClosed.Error(), \"pool should be closed\")\n\tp1.Reboot()\n\twg.Add(1)\n\tassert.NoError(t, p1.Invoke(1), \"pool should be rebooted\")\n\twg.Wait()\n}\n\nfunc TestInfinitePool(t *testing.T) {\n\tc := make(chan struct{})\n\tp, _ := NewPool(-1)\n\t_ = p.Submit(func() {\n\t\t_ = p.Submit(func() {\n\t\t\t<-c\n\t\t})\n\t})\n\tc <- struct{}{}\n\tif n := p.Running(); n != 2 {\n\t\tt.Errorf(\"expect 2 workers running, but got %d\", n)\n\t}\n\tif n := p.Free(); n != -1 {\n\t\tt.Errorf(\"expect -1 of free workers by unlimited pool, but got %d\", n)\n\t}\n\tp.Tune(10)\n\tif capacity := p.Cap(); capacity != -1 {\n\t\tt.Fatalf(\"expect capacity: -1 but got %d\", capacity)\n\t}\n\tvar err error\n\t_, err = NewPool(-1, WithPreAlloc(true))\n\tassert.EqualErrorf(t, err, ErrInvalidPreAllocSize.Error(), \"\")\n}\n\nfunc testPoolWithDisablePurge(t *testing.T, p *Pool, numWorker int, waitForPurge time.Duration) {\n\tsig := make(chan struct{})\n\tvar wg1, wg2 sync.WaitGroup\n\twg1.Add(numWorker)\n\twg2.Add(numWorker)\n\tfor i := 0; i < numWorker; i++ {\n\t\t_ = p.Submit(func() {\n\t\t\twg1.Done()\n\t\t\t<-sig\n\t\t\twg2.Done()\n\t\t})\n\t}\n\twg1.Wait()\n\n\trunningCnt := p.Running()\n\tassert.EqualValuesf(t, numWorker, runningCnt, \"expect %d workers running, but got %d\", numWorker, runningCnt)\n\tfreeCnt := p.Free()\n\tassert.EqualValuesf(t, 0, freeCnt, \"expect %d free workers, but got %d\", 0, freeCnt)\n\n\t// Finish all tasks and sleep for a while to wait for purging, since we've disabled purge mechanism,\n\t// we should see that all workers are still running after the sleep.\n\tclose(sig)\n\twg2.Wait()\n\ttime.Sleep(waitForPurge + waitForPurge/2)\n\n\trunningCnt = p.Running()\n\tassert.EqualValuesf(t, numWorker, runningCnt, \"expect %d workers running, but got %d\", numWorker, runningCnt)\n\tfreeCnt = p.Free()\n\tassert.EqualValuesf(t, 0, freeCnt, \"expect %d free workers, but got %d\", 0, freeCnt)\n\n\terr := p.ReleaseTimeout(waitForPurge + waitForPurge/2)\n\tassert.NoErrorf(t, err, \"release pool failed: %v\", err)\n\n\trunningCnt = p.Running()\n\tassert.EqualValuesf(t, 0, runningCnt, \"expect %d workers running, but got %d\", 0, runningCnt)\n\tfreeCnt = p.Free()\n\tassert.EqualValuesf(t, numWorker, freeCnt, \"expect %d free workers, but got %d\", numWorker, freeCnt)\n}\n\nfunc TestWithDisablePurgePool(t *testing.T) {\n\tnumWorker := 10\n\tp, _ := NewPool(numWorker, WithDisablePurge(true))\n\ttestPoolWithDisablePurge(t, p, numWorker, DefaultCleanIntervalTime)\n}\n\nfunc TestWithDisablePurgeAndWithExpirationPool(t *testing.T) {\n\tnumWorker := 10\n\texpiredDuration := time.Millisecond * 100\n\tp, _ := NewPool(numWorker, WithDisablePurge(true), WithExpiryDuration(expiredDuration))\n\ttestPoolWithDisablePurge(t, p, numWorker, expiredDuration)\n}\n\nfunc testPoolFuncWithDisablePurge(t *testing.T, p *PoolWithFunc, numWorker int, wg1, wg2 *sync.WaitGroup, sig chan struct{}, waitForPurge time.Duration) {\n\tfor i := 0; i < numWorker; i++ {\n\t\t_ = p.Invoke(i)\n\t}\n\twg1.Wait()\n\n\trunningCnt := p.Running()\n\tassert.EqualValuesf(t, numWorker, runningCnt, \"expect %d workers running, but got %d\", numWorker, runningCnt)\n\tfreeCnt := p.Free()\n\tassert.EqualValuesf(t, 0, freeCnt, \"expect %d free workers, but got %d\", 0, freeCnt)\n\n\t// Finish all tasks and sleep for a while to wait for purging, since we've disabled purge mechanism,\n\t// we should see that all workers are still running after the sleep.\n\tclose(sig)\n\twg2.Wait()\n\ttime.Sleep(waitForPurge + waitForPurge/2)\n\n\trunningCnt = p.Running()\n\tassert.EqualValuesf(t, numWorker, runningCnt, \"expect %d workers running, but got %d\", numWorker, runningCnt)\n\tfreeCnt = p.Free()\n\tassert.EqualValuesf(t, 0, freeCnt, \"expect %d free workers, but got %d\", 0, freeCnt)\n\n\terr := p.ReleaseTimeout(waitForPurge + waitForPurge/2)\n\tassert.NoErrorf(t, err, \"release pool failed: %v\", err)\n\n\trunningCnt = p.Running()\n\tassert.EqualValuesf(t, 0, runningCnt, \"expect %d workers running, but got %d\", 0, runningCnt)\n\tfreeCnt = p.Free()\n\tassert.EqualValuesf(t, numWorker, freeCnt, \"expect %d free workers, but got %d\", numWorker, freeCnt)\n}\n\nfunc TestWithDisablePurgePoolFunc(t *testing.T) {\n\tnumWorker := 10\n\tsig := make(chan struct{})\n\tvar wg1, wg2 sync.WaitGroup\n\twg1.Add(numWorker)\n\twg2.Add(numWorker)\n\tp, _ := NewPoolWithFunc(numWorker, func(_ interface{}) {\n\t\twg1.Done()\n\t\t<-sig\n\t\twg2.Done()\n\t}, WithDisablePurge(true))\n\ttestPoolFuncWithDisablePurge(t, p, numWorker, &wg1, &wg2, sig, DefaultCleanIntervalTime)\n}\n\nfunc TestWithDisablePurgeAndWithExpirationPoolFunc(t *testing.T) {\n\tnumWorker := 2\n\tsig := make(chan struct{})\n\tvar wg1, wg2 sync.WaitGroup\n\twg1.Add(numWorker)\n\twg2.Add(numWorker)\n\texpiredDuration := time.Millisecond * 100\n\tp, _ := NewPoolWithFunc(numWorker, func(_ interface{}) {\n\t\twg1.Done()\n\t\t<-sig\n\t\twg2.Done()\n\t}, WithDisablePurge(true), WithExpiryDuration(expiredDuration))\n\ttestPoolFuncWithDisablePurge(t, p, numWorker, &wg1, &wg2, sig, expiredDuration)\n}\n\nfunc TestInfinitePoolWithFunc(t *testing.T) {\n\tc := make(chan struct{})\n\tp, _ := NewPoolWithFunc(-1, func(i interface{}) {\n\t\tdemoPoolFunc(i)\n\t\t<-c\n\t})\n\t_ = p.Invoke(10)\n\t_ = p.Invoke(10)\n\tc <- struct{}{}\n\tc <- struct{}{}\n\tif n := p.Running(); n != 2 {\n\t\tt.Errorf(\"expect 2 workers running, but got %d\", n)\n\t}\n\tif n := p.Free(); n != -1 {\n\t\tt.Errorf(\"expect -1 of free workers by unlimited pool, but got %d\", n)\n\t}\n\tp.Tune(10)\n\tif capacity := p.Cap(); capacity != -1 {\n\t\tt.Fatalf(\"expect capacity: -1 but got %d\", capacity)\n\t}\n\tvar err error\n\t_, err = NewPoolWithFunc(-1, demoPoolFunc, WithPreAlloc(true))\n\tif err != ErrInvalidPreAllocSize {\n\t\tt.Errorf(\"expect ErrInvalidPreAllocSize but got %v\", err)\n\t}\n}\n\nfunc TestReleaseWhenRunningPool(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPool(1)\n\twg.Add(2)\n\tgo func() {\n\t\tt.Log(\"start aaa\")\n\t\tdefer func() {\n\t\t\twg.Done()\n\t\t\tt.Log(\"stop aaa\")\n\t\t}()\n\t\tfor i := 0; i < 30; i++ {\n\t\t\tj := i\n\t\t\t_ = p.Submit(func() {\n\t\t\t\tt.Log(\"do task\", j)\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t})\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tt.Log(\"start bbb\")\n\t\tdefer func() {\n\t\t\twg.Done()\n\t\t\tt.Log(\"stop bbb\")\n\t\t}()\n\t\tfor i := 100; i < 130; i++ {\n\t\t\tj := i\n\t\t\t_ = p.Submit(func() {\n\t\t\t\tt.Log(\"do task\", j)\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t})\n\t\t}\n\t}()\n\n\ttime.Sleep(3 * time.Second)\n\tp.Release()\n\tt.Log(\"wait for all goroutines to exit...\")\n\twg.Wait()\n}\n\nfunc TestReleaseWhenRunningPoolWithFunc(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tp, _ := NewPoolWithFunc(1, func(i interface{}) {\n\t\tt.Log(\"do task\", i)\n\t\ttime.Sleep(1 * time.Second)\n\t})\n\twg.Add(2)\n\tgo func() {\n\t\tt.Log(\"start aaa\")\n\t\tdefer func() {\n\t\t\twg.Done()\n\t\t\tt.Log(\"stop aaa\")\n\t\t}()\n\t\tfor i := 0; i < 30; i++ {\n\t\t\t_ = p.Invoke(i)\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tt.Log(\"start bbb\")\n\t\tdefer func() {\n\t\t\twg.Done()\n\t\t\tt.Log(\"stop bbb\")\n\t\t}()\n\t\tfor i := 100; i < 130; i++ {\n\t\t\t_ = p.Invoke(i)\n\t\t}\n\t}()\n\n\ttime.Sleep(3 * time.Second)\n\tp.Release()\n\tt.Log(\"wait for all goroutines to exit...\")\n\twg.Wait()\n}\n\nfunc TestRestCodeCoverage(t *testing.T) {\n\t_, err := NewPool(-1, WithExpiryDuration(-1))\n\tt.Log(err)\n\t_, err = NewPool(1, WithExpiryDuration(-1))\n\tt.Log(err)\n\t_, err = NewPoolWithFunc(-1, demoPoolFunc, WithExpiryDuration(-1))\n\tt.Log(err)\n\t_, err = NewPoolWithFunc(1, demoPoolFunc, WithExpiryDuration(-1))\n\tt.Log(err)\n\n\toptions := Options{}\n\toptions.ExpiryDuration = time.Duration(10) * time.Second\n\toptions.Nonblocking = true\n\toptions.PreAlloc = true\n\tpoolOpts, _ := NewPool(1, WithOptions(options))\n\tt.Logf(\"Pool with options, capacity: %d\", poolOpts.Cap())\n\n\tp0, _ := NewPool(TestSize, WithLogger(log.New(os.Stderr, \"\", log.LstdFlags)))\n\tdefer func() {\n\t\t_ = p0.Submit(demoFunc)\n\t}()\n\tdefer p0.Release()\n\tfor i := 0; i < n; i++ {\n\t\t_ = p0.Submit(demoFunc)\n\t}\n\tt.Logf(\"pool, capacity:%d\", p0.Cap())\n\tt.Logf(\"pool, running workers number:%d\", p0.Running())\n\tt.Logf(\"pool, free workers number:%d\", p0.Free())\n\tp0.Tune(TestSize)\n\tp0.Tune(TestSize / 10)\n\tt.Logf(\"pool, after tuning capacity, capacity:%d, running:%d\", p0.Cap(), p0.Running())\n\n\tpprem, _ := NewPool(TestSize, WithPreAlloc(true))\n\tdefer func() {\n\t\t_ = pprem.Submit(demoFunc)\n\t}()\n\tdefer pprem.Release()\n\tfor i := 0; i < n; i++ {\n\t\t_ = pprem.Submit(demoFunc)\n\t}\n\tt.Logf(\"pre-malloc pool, capacity:%d\", pprem.Cap())\n\tt.Logf(\"pre-malloc pool, running workers number:%d\", pprem.Running())\n\tt.Logf(\"pre-malloc pool, free workers number:%d\", pprem.Free())\n\tpprem.Tune(TestSize)\n\tpprem.Tune(TestSize / 10)\n\tt.Logf(\"pre-malloc pool, after tuning capacity, capacity:%d, running:%d\", pprem.Cap(), pprem.Running())\n\n\tp, _ := NewPoolWithFunc(TestSize, demoPoolFunc)\n\tdefer func() {\n\t\t_ = p.Invoke(Param)\n\t}()\n\tdefer p.Release()\n\tfor i := 0; i < n; i++ {\n\t\t_ = p.Invoke(Param)\n\t}\n\ttime.Sleep(DefaultCleanIntervalTime)\n\tt.Logf(\"pool with func, capacity:%d\", p.Cap())\n\tt.Logf(\"pool with func, running workers number:%d\", p.Running())\n\tt.Logf(\"pool with func, free workers number:%d\", p.Free())\n\tp.Tune(TestSize)\n\tp.Tune(TestSize / 10)\n\tt.Logf(\"pool with func, after tuning capacity, capacity:%d, running:%d\", p.Cap(), p.Running())\n\n\tppremWithFunc, _ := NewPoolWithFunc(TestSize, demoPoolFunc, WithPreAlloc(true))\n\tdefer func() {\n\t\t_ = ppremWithFunc.Invoke(Param)\n\t}()\n\tdefer ppremWithFunc.Release()\n\tfor i := 0; i < n; i++ {\n\t\t_ = ppremWithFunc.Invoke(Param)\n\t}\n\ttime.Sleep(DefaultCleanIntervalTime)\n\tt.Logf(\"pre-malloc pool with func, capacity:%d\", ppremWithFunc.Cap())\n\tt.Logf(\"pre-malloc pool with func, running workers number:%d\", ppremWithFunc.Running())\n\tt.Logf(\"pre-malloc pool with func, free workers number:%d\", ppremWithFunc.Free())\n\tppremWithFunc.Tune(TestSize)\n\tppremWithFunc.Tune(TestSize / 10)\n\tt.Logf(\"pre-malloc pool with func, after tuning capacity, capacity:%d, running:%d\", ppremWithFunc.Cap(),\n\t\tppremWithFunc.Running())\n}\n\nfunc TestPoolTuneScaleUp(t *testing.T) {\n\tc := make(chan struct{})\n\tp, _ := NewPool(2)\n\tfor i := 0; i < 2; i++ {\n\t\t_ = p.Submit(func() {\n\t\t\t<-c\n\t\t})\n\t}\n\tif n := p.Running(); n != 2 {\n\t\tt.Errorf(\"expect 2 workers running, but got %d\", n)\n\t}\n\t// test pool tune scale up one\n\tp.Tune(3)\n\t_ = p.Submit(func() {\n\t\t<-c\n\t})\n\tif n := p.Running(); n != 3 {\n\t\tt.Errorf(\"expect 3 workers running, but got %d\", n)\n\t}\n\t// test pool tune scale up multiple\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = p.Submit(func() {\n\t\t\t\t<-c\n\t\t\t})\n\t\t}()\n\t}\n\tp.Tune(8)\n\twg.Wait()\n\tif n := p.Running(); n != 8 {\n\t\tt.Errorf(\"expect 8 workers running, but got %d\", n)\n\t}\n\tfor i := 0; i < 8; i++ {\n\t\tc <- struct{}{}\n\t}\n\tp.Release()\n\n\t// test PoolWithFunc\n\tpf, _ := NewPoolWithFunc(2, func(_ interface{}) {\n\t\t<-c\n\t})\n\tfor i := 0; i < 2; i++ {\n\t\t_ = pf.Invoke(1)\n\t}\n\tif n := pf.Running(); n != 2 {\n\t\tt.Errorf(\"expect 2 workers running, but got %d\", n)\n\t}\n\t// test pool tune scale up one\n\tpf.Tune(3)\n\t_ = pf.Invoke(1)\n\tif n := pf.Running(); n != 3 {\n\t\tt.Errorf(\"expect 3 workers running, but got %d\", n)\n\t}\n\t// test pool tune scale up multiple\n\tvar pfwg sync.WaitGroup\n\tfor i := 0; i < 5; i++ {\n\t\tpfwg.Add(1)\n\t\tgo func() {\n\t\t\tdefer pfwg.Done()\n\t\t\t_ = pf.Invoke(1)\n\t\t}()\n\t}\n\tpf.Tune(8)\n\tpfwg.Wait()\n\tif n := pf.Running(); n != 8 {\n\t\tt.Errorf(\"expect 8 workers running, but got %d\", n)\n\t}\n\tfor i := 0; i < 8; i++ {\n\t\tc <- struct{}{}\n\t}\n\tclose(c)\n\tpf.Release()\n}\n\nfunc TestReleaseTimeout(t *testing.T) {\n\tp, _ := NewPool(10)\n\tfor i := 0; i < 5; i++ {\n\t\t_ = p.Submit(func() {\n\t\t\ttime.Sleep(time.Second)\n\t\t})\n\t}\n\tassert.NotZero(t, p.Running())\n\terr := p.ReleaseTimeout(2 * time.Second)\n\tassert.NoError(t, err)\n\n\tvar pf *PoolWithFunc\n\tpf, _ = NewPoolWithFunc(10, func(i interface{}) {\n\t\tdur := i.(time.Duration)\n\t\ttime.Sleep(dur)\n\t})\n\tfor i := 0; i < 5; i++ {\n\t\t_ = pf.Invoke(time.Second)\n\t}\n\tassert.NotZero(t, pf.Running())\n\terr = pf.ReleaseTimeout(2 * time.Second)\n\tassert.NoError(t, err)\n}\n\nfunc TestDefaultPoolReleaseTimeout(t *testing.T) {\n\tReboot() // should do nothing inside\n\tfor i := 0; i < 5; i++ {\n\t\t_ = Submit(func() {\n\t\t\ttime.Sleep(time.Second)\n\t\t})\n\t}\n\tassert.NotZero(t, Running())\n\terr := ReleaseTimeout(2 * time.Second)\n\tassert.NoError(t, err)\n}\n\nfunc TestMultiPool(t *testing.T) {\n\t_, err := NewMultiPool(10, -1, 8)\n\tassert.ErrorIs(t, err, ErrInvalidLoadBalancingStrategy)\n\n\tmp, err := NewMultiPool(10, 5, RoundRobin)\n\ttestFn := func() {\n\t\tfor i := 0; i < 50; i++ {\n\t\t\terr = mp.Submit(longRunningFunc)\n\t\t\tassert.NoError(t, err)\n\t\t}\n\t\tassert.EqualValues(t, mp.Waiting(), 0)\n\t\t_, err = mp.WaitingByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.WaitingByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 50, mp.Running())\n\t\t_, err = mp.RunningByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.RunningByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 0, mp.Free())\n\t\t_, err = mp.FreeByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.FreeByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 50, mp.Cap())\n\t\tassert.False(t, mp.IsClosed())\n\t\tfor i := 0; i < 10; i++ {\n\t\t\tn, _ := mp.WaitingByIndex(i)\n\t\t\tassert.EqualValues(t, 0, n)\n\t\t\tn, _ = mp.RunningByIndex(i)\n\t\t\tassert.EqualValues(t, 5, n)\n\t\t\tn, _ = mp.FreeByIndex(i)\n\t\t\tassert.EqualValues(t, 0, n)\n\t\t}\n\t\tatomic.StoreInt32(&stopLongRunningFunc, 1)\n\t\tassert.NoError(t, mp.ReleaseTimeout(3*time.Second))\n\t\tassert.Zero(t, mp.Running())\n\t\tassert.True(t, mp.IsClosed())\n\t\tatomic.StoreInt32(&stopLongRunningFunc, 0)\n\t}\n\ttestFn()\n\n\tmp.Reboot()\n\ttestFn()\n\n\tmp, err = NewMultiPool(10, 5, LeastTasks)\n\ttestFn()\n\n\tmp.Reboot()\n\ttestFn()\n\n\tmp.Tune(10)\n}\n\nfunc TestMultiPoolWithFunc(t *testing.T) {\n\t_, err := NewMultiPoolWithFunc(10, -1, longRunningPoolFunc, 8)\n\tassert.ErrorIs(t, err, ErrInvalidLoadBalancingStrategy)\n\n\tmp, err := NewMultiPoolWithFunc(10, 5, longRunningPoolFunc, RoundRobin)\n\ttestFn := func() {\n\t\tfor i := 0; i < 50; i++ {\n\t\t\terr = mp.Invoke(i)\n\t\t\tassert.NoError(t, err)\n\t\t}\n\t\tassert.EqualValues(t, mp.Waiting(), 0)\n\t\t_, err = mp.WaitingByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.WaitingByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 50, mp.Running())\n\t\t_, err = mp.RunningByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.RunningByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 0, mp.Free())\n\t\t_, err = mp.FreeByIndex(-1)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\t_, err = mp.FreeByIndex(11)\n\t\tassert.ErrorIs(t, err, ErrInvalidPoolIndex)\n\t\tassert.EqualValues(t, 50, mp.Cap())\n\t\tassert.False(t, mp.IsClosed())\n\t\tfor i := 0; i < 10; i++ {\n\t\t\tn, _ := mp.WaitingByIndex(i)\n\t\t\tassert.EqualValues(t, 0, n)\n\t\t\tn, _ = mp.RunningByIndex(i)\n\t\t\tassert.EqualValues(t, 5, n)\n\t\t\tn, _ = mp.FreeByIndex(i)\n\t\t\tassert.EqualValues(t, 0, n)\n\t\t}\n\t\tatomic.StoreInt32(&stopLongRunningPoolFunc, 1)\n\t\tassert.NoError(t, mp.ReleaseTimeout(3*time.Second))\n\t\tassert.Zero(t, mp.Running())\n\t\tassert.True(t, mp.IsClosed())\n\t\tatomic.StoreInt32(&stopLongRunningPoolFunc, 0)\n\t}\n\ttestFn()\n\n\tmp.Reboot()\n\ttestFn()\n\n\tmp, err = NewMultiPoolWithFunc(10, 5, longRunningPoolFunc, LeastTasks)\n\ttestFn()\n\n\tmp.Reboot()\n\ttestFn()\n\n\tmp.Tune(10)\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.1171875,
          "content": "module github.com/panjf2000/ants/v2\n\ngo 1.16\n\nrequire (\n\tgithub.com/stretchr/testify v1.8.2\n\tgolang.org/x/sync v0.3.0\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.6318359375,
          "content": "github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.2 h1:+h33VjcLVPDHtOdpUCuF+7gSuG3yGIftsP1YvFihtJ8=\ngithub.com/stretchr/testify v1.8.2/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngolang.org/x/sync v0.3.0 h1:ftCYgMx6zT/asHUrPw8BLLscYtGznsLAnjq5RH9P66E=\ngolang.org/x/sync v0.3.0/go.mod h1:FU7BRWz2tNW+3quACPkgCx/L+uEAv1htQ0V83Z9Rj+Y=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "multipool.go",
          "type": "blob",
          "size": 6.0927734375,
          "content": "// MIT License\n\n// Copyright (c) 2023 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"golang.org/x/sync/errgroup\"\n)\n\n// LoadBalancingStrategy represents the type of load-balancing algorithm.\ntype LoadBalancingStrategy int\n\nconst (\n\t// RoundRobin distributes task to a list of pools in rotation.\n\tRoundRobin LoadBalancingStrategy = 1 << (iota + 1)\n\n\t// LeastTasks always selects the pool with the least number of pending tasks.\n\tLeastTasks\n)\n\n// MultiPool consists of multiple pools, from which you will benefit the\n// performance improvement on basis of the fine-grained locking that reduces\n// the lock contention.\n// MultiPool is a good fit for the scenario where you have a large number of\n// tasks to submit, and you don't want the single pool to be the bottleneck.\ntype MultiPool struct {\n\tpools []*Pool\n\tindex uint32\n\tstate int32\n\tlbs   LoadBalancingStrategy\n}\n\n// NewMultiPool instantiates a MultiPool with a size of the pool list and a size\n// per pool, and the load-balancing strategy.\nfunc NewMultiPool(size, sizePerPool int, lbs LoadBalancingStrategy, options ...Option) (*MultiPool, error) {\n\tif lbs != RoundRobin && lbs != LeastTasks {\n\t\treturn nil, ErrInvalidLoadBalancingStrategy\n\t}\n\tpools := make([]*Pool, size)\n\tfor i := 0; i < size; i++ {\n\t\tpool, err := NewPool(sizePerPool, options...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tpools[i] = pool\n\t}\n\treturn &MultiPool{pools: pools, lbs: lbs}, nil\n}\n\nfunc (mp *MultiPool) next(lbs LoadBalancingStrategy) (idx int) {\n\tswitch lbs {\n\tcase RoundRobin:\n\t\tif idx = int((atomic.AddUint32(&mp.index, 1) - 1) % uint32(len(mp.pools))); idx == -1 {\n\t\t\tidx = 0\n\t\t}\n\t\treturn\n\tcase LeastTasks:\n\t\tleastTasks := 1<<31 - 1\n\t\tfor i, pool := range mp.pools {\n\t\t\tif n := pool.Running(); n < leastTasks {\n\t\t\t\tleastTasks = n\n\t\t\t\tidx = i\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\treturn -1\n}\n\n// Submit submits a task to a pool selected by the load-balancing strategy.\nfunc (mp *MultiPool) Submit(task func()) (err error) {\n\tif mp.IsClosed() {\n\t\treturn ErrPoolClosed\n\t}\n\tif err = mp.pools[mp.next(mp.lbs)].Submit(task); err == nil {\n\t\treturn\n\t}\n\tif err == ErrPoolOverload && mp.lbs == RoundRobin {\n\t\treturn mp.pools[mp.next(LeastTasks)].Submit(task)\n\t}\n\treturn\n}\n\n// Running returns the number of the currently running workers across all pools.\nfunc (mp *MultiPool) Running() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Running()\n\t}\n\treturn\n}\n\n// RunningByIndex returns the number of the currently running workers in the specific pool.\nfunc (mp *MultiPool) RunningByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Running(), nil\n}\n\n// Free returns the number of available workers across all pools.\nfunc (mp *MultiPool) Free() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Free()\n\t}\n\treturn\n}\n\n// FreeByIndex returns the number of available workers in the specific pool.\nfunc (mp *MultiPool) FreeByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Free(), nil\n}\n\n// Waiting returns the number of the currently waiting tasks across all pools.\nfunc (mp *MultiPool) Waiting() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Waiting()\n\t}\n\treturn\n}\n\n// WaitingByIndex returns the number of the currently waiting tasks in the specific pool.\nfunc (mp *MultiPool) WaitingByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Waiting(), nil\n}\n\n// Cap returns the capacity of this multi-pool.\nfunc (mp *MultiPool) Cap() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Cap()\n\t}\n\treturn\n}\n\n// Tune resizes each pool in multi-pool.\n//\n// Note that this method doesn't resize the overall\n// capacity of multi-pool.\nfunc (mp *MultiPool) Tune(size int) {\n\tfor _, pool := range mp.pools {\n\t\tpool.Tune(size)\n\t}\n}\n\n// IsClosed indicates whether the multi-pool is closed.\nfunc (mp *MultiPool) IsClosed() bool {\n\treturn atomic.LoadInt32(&mp.state) == CLOSED\n}\n\n// ReleaseTimeout closes the multi-pool with a timeout,\n// it waits all pools to be closed before timing out.\nfunc (mp *MultiPool) ReleaseTimeout(timeout time.Duration) error {\n\tif !atomic.CompareAndSwapInt32(&mp.state, OPENED, CLOSED) {\n\t\treturn ErrPoolClosed\n\t}\n\n\terrCh := make(chan error, len(mp.pools))\n\tvar wg errgroup.Group\n\tfor i, pool := range mp.pools {\n\t\tfunc(p *Pool, idx int) {\n\t\t\twg.Go(func() error {\n\t\t\t\terr := p.ReleaseTimeout(timeout)\n\t\t\t\tif err != nil {\n\t\t\t\t\terr = fmt.Errorf(\"pool %d: %v\", idx, err)\n\t\t\t\t}\n\t\t\t\terrCh <- err\n\t\t\t\treturn err\n\t\t\t})\n\t\t}(pool, i)\n\t}\n\n\t_ = wg.Wait()\n\n\tvar errStr strings.Builder\n\tfor i := 0; i < len(mp.pools); i++ {\n\t\tif err := <-errCh; err != nil {\n\t\t\terrStr.WriteString(err.Error())\n\t\t\terrStr.WriteString(\" | \")\n\t\t}\n\t}\n\n\tif errStr.Len() == 0 {\n\t\treturn nil\n\t}\n\n\treturn errors.New(strings.TrimSuffix(errStr.String(), \" | \"))\n}\n\n// Reboot reboots a released multi-pool.\nfunc (mp *MultiPool) Reboot() {\n\tif atomic.CompareAndSwapInt32(&mp.state, CLOSED, OPENED) {\n\t\tatomic.StoreUint32(&mp.index, 0)\n\t\tfor _, pool := range mp.pools {\n\t\t\tpool.Reboot()\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "multipool_func.go",
          "type": "blob",
          "size": 6.001953125,
          "content": "// MIT License\n\n// Copyright (c) 2023 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"golang.org/x/sync/errgroup\"\n)\n\n// MultiPoolWithFunc consists of multiple pools, from which you will benefit the\n// performance improvement on basis of the fine-grained locking that reduces\n// the lock contention.\n// MultiPoolWithFunc is a good fit for the scenario where you have a large number of\n// tasks to submit, and you don't want the single pool to be the bottleneck.\ntype MultiPoolWithFunc struct {\n\tpools []*PoolWithFunc\n\tindex uint32\n\tstate int32\n\tlbs   LoadBalancingStrategy\n}\n\n// NewMultiPoolWithFunc instantiates a MultiPoolWithFunc with a size of the pool list and a size\n// per pool, and the load-balancing strategy.\nfunc NewMultiPoolWithFunc(size, sizePerPool int, fn func(interface{}), lbs LoadBalancingStrategy, options ...Option) (*MultiPoolWithFunc, error) {\n\tif lbs != RoundRobin && lbs != LeastTasks {\n\t\treturn nil, ErrInvalidLoadBalancingStrategy\n\t}\n\tpools := make([]*PoolWithFunc, size)\n\tfor i := 0; i < size; i++ {\n\t\tpool, err := NewPoolWithFunc(sizePerPool, fn, options...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tpools[i] = pool\n\t}\n\treturn &MultiPoolWithFunc{pools: pools, lbs: lbs}, nil\n}\n\nfunc (mp *MultiPoolWithFunc) next(lbs LoadBalancingStrategy) (idx int) {\n\tswitch lbs {\n\tcase RoundRobin:\n\t\tif idx = int((atomic.AddUint32(&mp.index, 1) - 1) % uint32(len(mp.pools))); idx == -1 {\n\t\t\tidx = 0\n\t\t}\n\t\treturn\n\tcase LeastTasks:\n\t\tleastTasks := 1<<31 - 1\n\t\tfor i, pool := range mp.pools {\n\t\t\tif n := pool.Running(); n < leastTasks {\n\t\t\t\tleastTasks = n\n\t\t\t\tidx = i\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\treturn -1\n}\n\n// Invoke submits a task to a pool selected by the load-balancing strategy.\nfunc (mp *MultiPoolWithFunc) Invoke(args interface{}) (err error) {\n\tif mp.IsClosed() {\n\t\treturn ErrPoolClosed\n\t}\n\n\tif err = mp.pools[mp.next(mp.lbs)].Invoke(args); err == nil {\n\t\treturn\n\t}\n\tif err == ErrPoolOverload && mp.lbs == RoundRobin {\n\t\treturn mp.pools[mp.next(LeastTasks)].Invoke(args)\n\t}\n\treturn\n}\n\n// Running returns the number of the currently running workers across all pools.\nfunc (mp *MultiPoolWithFunc) Running() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Running()\n\t}\n\treturn\n}\n\n// RunningByIndex returns the number of the currently running workers in the specific pool.\nfunc (mp *MultiPoolWithFunc) RunningByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Running(), nil\n}\n\n// Free returns the number of available workers across all pools.\nfunc (mp *MultiPoolWithFunc) Free() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Free()\n\t}\n\treturn\n}\n\n// FreeByIndex returns the number of available workers in the specific pool.\nfunc (mp *MultiPoolWithFunc) FreeByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Free(), nil\n}\n\n// Waiting returns the number of the currently waiting tasks across all pools.\nfunc (mp *MultiPoolWithFunc) Waiting() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Waiting()\n\t}\n\treturn\n}\n\n// WaitingByIndex returns the number of the currently waiting tasks in the specific pool.\nfunc (mp *MultiPoolWithFunc) WaitingByIndex(idx int) (int, error) {\n\tif idx < 0 || idx >= len(mp.pools) {\n\t\treturn -1, ErrInvalidPoolIndex\n\t}\n\treturn mp.pools[idx].Waiting(), nil\n}\n\n// Cap returns the capacity of this multi-pool.\nfunc (mp *MultiPoolWithFunc) Cap() (n int) {\n\tfor _, pool := range mp.pools {\n\t\tn += pool.Cap()\n\t}\n\treturn\n}\n\n// Tune resizes each pool in multi-pool.\n//\n// Note that this method doesn't resize the overall\n// capacity of multi-pool.\nfunc (mp *MultiPoolWithFunc) Tune(size int) {\n\tfor _, pool := range mp.pools {\n\t\tpool.Tune(size)\n\t}\n}\n\n// IsClosed indicates whether the multi-pool is closed.\nfunc (mp *MultiPoolWithFunc) IsClosed() bool {\n\treturn atomic.LoadInt32(&mp.state) == CLOSED\n}\n\n// ReleaseTimeout closes the multi-pool with a timeout,\n// it waits all pools to be closed before timing out.\nfunc (mp *MultiPoolWithFunc) ReleaseTimeout(timeout time.Duration) error {\n\tif !atomic.CompareAndSwapInt32(&mp.state, OPENED, CLOSED) {\n\t\treturn ErrPoolClosed\n\t}\n\n\terrCh := make(chan error, len(mp.pools))\n\tvar wg errgroup.Group\n\tfor i, pool := range mp.pools {\n\t\tfunc(p *PoolWithFunc, idx int) {\n\t\t\twg.Go(func() error {\n\t\t\t\terr := p.ReleaseTimeout(timeout)\n\t\t\t\tif err != nil {\n\t\t\t\t\terr = fmt.Errorf(\"pool %d: %v\", idx, err)\n\t\t\t\t}\n\t\t\t\terrCh <- err\n\t\t\t\treturn err\n\t\t\t})\n\t\t}(pool, i)\n\t}\n\n\t_ = wg.Wait()\n\n\tvar errStr strings.Builder\n\tfor i := 0; i < len(mp.pools); i++ {\n\t\tif err := <-errCh; err != nil {\n\t\t\terrStr.WriteString(err.Error())\n\t\t\terrStr.WriteString(\" | \")\n\t\t}\n\t}\n\n\tif errStr.Len() == 0 {\n\t\treturn nil\n\t}\n\n\treturn errors.New(strings.TrimSuffix(errStr.String(), \" | \"))\n}\n\n// Reboot reboots a released multi-pool.\nfunc (mp *MultiPoolWithFunc) Reboot() {\n\tif atomic.CompareAndSwapInt32(&mp.state, CLOSED, OPENED) {\n\t\tatomic.StoreUint32(&mp.index, 0)\n\t\tfor _, pool := range mp.pools {\n\t\t\tpool.Reboot()\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "options.go",
          "type": "blob",
          "size": 2.896484375,
          "content": "package ants\n\nimport \"time\"\n\n// Option represents the optional function.\ntype Option func(opts *Options)\n\nfunc loadOptions(options ...Option) *Options {\n\topts := new(Options)\n\tfor _, option := range options {\n\t\toption(opts)\n\t}\n\treturn opts\n}\n\n// Options contains all options which will be applied when instantiating an ants pool.\ntype Options struct {\n\t// ExpiryDuration is a period for the scavenger goroutine to clean up those expired workers,\n\t// the scavenger scans all workers every `ExpiryDuration` and clean up those workers that haven't been\n\t// used for more than `ExpiryDuration`.\n\tExpiryDuration time.Duration\n\n\t// PreAlloc indicates whether to make memory pre-allocation when initializing Pool.\n\tPreAlloc bool\n\n\t// Max number of goroutine blocking on pool.Submit.\n\t// 0 (default value) means no such limit.\n\tMaxBlockingTasks int\n\n\t// When Nonblocking is true, Pool.Submit will never be blocked.\n\t// ErrPoolOverload will be returned when Pool.Submit cannot be done at once.\n\t// When Nonblocking is true, MaxBlockingTasks is inoperative.\n\tNonblocking bool\n\n\t// PanicHandler is used to handle panics from each worker goroutine.\n\t// if nil, panics will be thrown out again from worker goroutines.\n\tPanicHandler func(interface{})\n\n\t// Logger is the customized logger for logging info, if it is not set,\n\t// default standard logger from log package is used.\n\tLogger Logger\n\n\t// When DisablePurge is true, workers are not purged and are resident.\n\tDisablePurge bool\n}\n\n// WithOptions accepts the whole options config.\nfunc WithOptions(options Options) Option {\n\treturn func(opts *Options) {\n\t\t*opts = options\n\t}\n}\n\n// WithExpiryDuration sets up the interval time of cleaning up goroutines.\nfunc WithExpiryDuration(expiryDuration time.Duration) Option {\n\treturn func(opts *Options) {\n\t\topts.ExpiryDuration = expiryDuration\n\t}\n}\n\n// WithPreAlloc indicates whether it should malloc for workers.\nfunc WithPreAlloc(preAlloc bool) Option {\n\treturn func(opts *Options) {\n\t\topts.PreAlloc = preAlloc\n\t}\n}\n\n// WithMaxBlockingTasks sets up the maximum number of goroutines that are blocked when it reaches the capacity of pool.\nfunc WithMaxBlockingTasks(maxBlockingTasks int) Option {\n\treturn func(opts *Options) {\n\t\topts.MaxBlockingTasks = maxBlockingTasks\n\t}\n}\n\n// WithNonblocking indicates that pool will return nil when there is no available workers.\nfunc WithNonblocking(nonblocking bool) Option {\n\treturn func(opts *Options) {\n\t\topts.Nonblocking = nonblocking\n\t}\n}\n\n// WithPanicHandler sets up panic handler.\nfunc WithPanicHandler(panicHandler func(interface{})) Option {\n\treturn func(opts *Options) {\n\t\topts.PanicHandler = panicHandler\n\t}\n}\n\n// WithLogger sets up a customized logger.\nfunc WithLogger(logger Logger) Option {\n\treturn func(opts *Options) {\n\t\topts.Logger = logger\n\t}\n}\n\n// WithDisablePurge indicates whether we turn off automatically purge.\nfunc WithDisablePurge(disable bool) Option {\n\treturn func(opts *Options) {\n\t\topts.DisablePurge = disable\n\t}\n}\n"
        },
        {
          "name": "pool.go",
          "type": "blob",
          "size": 10.8974609375,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tsyncx \"github.com/panjf2000/ants/v2/internal/sync\"\n)\n\ntype poolCommon struct {\n\t// capacity of the pool, a negative value means that the capacity of pool is limitless, an infinite pool is used to\n\t// avoid potential issue of endless blocking caused by nested usage of a pool: submitting a task to pool\n\t// which submits a new task to the same pool.\n\tcapacity int32\n\n\t// running is the number of the currently running goroutines.\n\trunning int32\n\n\t// lock for protecting the worker queue.\n\tlock sync.Locker\n\n\t// workers is a slice that store the available workers.\n\tworkers workerQueue\n\n\t// state is used to notice the pool to closed itself.\n\tstate int32\n\n\t// cond for waiting to get an idle worker.\n\tcond *sync.Cond\n\n\t// done is used to indicate that all workers are done.\n\tallDone chan struct{}\n\t// once is used to make sure the pool is closed just once.\n\tonce *sync.Once\n\n\t// workerCache speeds up the obtainment of a usable worker in function:retrieveWorker.\n\tworkerCache sync.Pool\n\n\t// waiting is the number of goroutines already been blocked on pool.Submit(), protected by pool.lock\n\twaiting int32\n\n\tpurgeDone int32\n\tpurgeCtx  context.Context\n\tstopPurge context.CancelFunc\n\n\tticktockDone int32\n\tticktockCtx  context.Context\n\tstopTicktock context.CancelFunc\n\n\tnow atomic.Value\n\n\toptions *Options\n}\n\n// Pool accepts the tasks and process them concurrently,\n// it limits the total of goroutines to a given number by recycling goroutines.\ntype Pool struct {\n\tpoolCommon\n}\n\n// purgeStaleWorkers clears stale workers periodically, it runs in an individual goroutine, as a scavenger.\nfunc (p *Pool) purgeStaleWorkers() {\n\tticker := time.NewTicker(p.options.ExpiryDuration)\n\n\tdefer func() {\n\t\tticker.Stop()\n\t\tatomic.StoreInt32(&p.purgeDone, 1)\n\t}()\n\n\tpurgeCtx := p.purgeCtx // copy to the local variable to avoid race from Reboot()\n\tfor {\n\t\tselect {\n\t\tcase <-purgeCtx.Done():\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t}\n\n\t\tif p.IsClosed() {\n\t\t\tbreak\n\t\t}\n\n\t\tvar isDormant bool\n\t\tp.lock.Lock()\n\t\tstaleWorkers := p.workers.refresh(p.options.ExpiryDuration)\n\t\tn := p.Running()\n\t\tisDormant = n == 0 || n == len(staleWorkers)\n\t\tp.lock.Unlock()\n\n\t\t// Clean up the stale workers.\n\t\tfor i := range staleWorkers {\n\t\t\tstaleWorkers[i].finish()\n\t\t\tstaleWorkers[i] = nil\n\t\t}\n\n\t\t// There might be a situation where all workers have been cleaned up (no worker is running),\n\t\t// while some invokers still are stuck in p.cond.Wait(), then we need to awake those invokers.\n\t\tif isDormant && p.Waiting() > 0 {\n\t\t\tp.cond.Broadcast()\n\t\t}\n\t}\n}\n\n// ticktock is a goroutine that updates the current time in the pool regularly.\nfunc (p *Pool) ticktock() {\n\tticker := time.NewTicker(nowTimeUpdateInterval)\n\tdefer func() {\n\t\tticker.Stop()\n\t\tatomic.StoreInt32(&p.ticktockDone, 1)\n\t}()\n\n\tticktockCtx := p.ticktockCtx // copy to the local variable to avoid race from Reboot()\n\tfor {\n\t\tselect {\n\t\tcase <-ticktockCtx.Done():\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t}\n\n\t\tif p.IsClosed() {\n\t\t\tbreak\n\t\t}\n\n\t\tp.now.Store(time.Now())\n\t}\n}\n\nfunc (p *Pool) goPurge() {\n\tif p.options.DisablePurge {\n\t\treturn\n\t}\n\n\t// Start a goroutine to clean up expired workers periodically.\n\tp.purgeCtx, p.stopPurge = context.WithCancel(context.Background())\n\tgo p.purgeStaleWorkers()\n}\n\nfunc (p *Pool) goTicktock() {\n\tp.now.Store(time.Now())\n\tp.ticktockCtx, p.stopTicktock = context.WithCancel(context.Background())\n\tgo p.ticktock()\n}\n\nfunc (p *Pool) nowTime() time.Time {\n\treturn p.now.Load().(time.Time)\n}\n\n// NewPool instantiates a Pool with customized options.\nfunc NewPool(size int, options ...Option) (*Pool, error) {\n\tif size <= 0 {\n\t\tsize = -1\n\t}\n\n\topts := loadOptions(options...)\n\n\tif !opts.DisablePurge {\n\t\tif expiry := opts.ExpiryDuration; expiry < 0 {\n\t\t\treturn nil, ErrInvalidPoolExpiry\n\t\t} else if expiry == 0 {\n\t\t\topts.ExpiryDuration = DefaultCleanIntervalTime\n\t\t}\n\t}\n\n\tif opts.Logger == nil {\n\t\topts.Logger = defaultLogger\n\t}\n\n\tp := &Pool{poolCommon: poolCommon{\n\t\tcapacity: int32(size),\n\t\tallDone:  make(chan struct{}),\n\t\tlock:     syncx.NewSpinLock(),\n\t\tonce:     &sync.Once{},\n\t\toptions:  opts,\n\t}}\n\tp.workerCache.New = func() interface{} {\n\t\treturn &goWorker{\n\t\t\tpool: p,\n\t\t\ttask: make(chan func(), workerChanCap),\n\t\t}\n\t}\n\tif p.options.PreAlloc {\n\t\tif size == -1 {\n\t\t\treturn nil, ErrInvalidPreAllocSize\n\t\t}\n\t\tp.workers = newWorkerQueue(queueTypeLoopQueue, size)\n\t} else {\n\t\tp.workers = newWorkerQueue(queueTypeStack, 0)\n\t}\n\n\tp.cond = sync.NewCond(p.lock)\n\n\tp.goPurge()\n\tp.goTicktock()\n\n\treturn p, nil\n}\n\n// Submit submits a task to this pool.\n//\n// Note that you are allowed to call Pool.Submit() from the current Pool.Submit(),\n// but what calls for special attention is that you will get blocked with the last\n// Pool.Submit() call once the current Pool runs out of its capacity, and to avoid this,\n// you should instantiate a Pool with ants.WithNonblocking(true).\nfunc (p *Pool) Submit(task func()) error {\n\tif p.IsClosed() {\n\t\treturn ErrPoolClosed\n\t}\n\n\tw, err := p.retrieveWorker()\n\tif w != nil {\n\t\tw.inputFunc(task)\n\t}\n\treturn err\n}\n\n// Running returns the number of workers currently running.\nfunc (p *Pool) Running() int {\n\treturn int(atomic.LoadInt32(&p.running))\n}\n\n// Free returns the number of available workers, -1 indicates this pool is unlimited.\nfunc (p *Pool) Free() int {\n\tc := p.Cap()\n\tif c < 0 {\n\t\treturn -1\n\t}\n\treturn c - p.Running()\n}\n\n// Waiting returns the number of tasks waiting to be executed.\nfunc (p *Pool) Waiting() int {\n\treturn int(atomic.LoadInt32(&p.waiting))\n}\n\n// Cap returns the capacity of this pool.\nfunc (p *Pool) Cap() int {\n\treturn int(atomic.LoadInt32(&p.capacity))\n}\n\n// Tune changes the capacity of this pool, note that it is noneffective to the infinite or pre-allocation pool.\nfunc (p *Pool) Tune(size int) {\n\tcapacity := p.Cap()\n\tif capacity == -1 || size <= 0 || size == capacity || p.options.PreAlloc {\n\t\treturn\n\t}\n\tatomic.StoreInt32(&p.capacity, int32(size))\n\tif size > capacity {\n\t\tif size-capacity == 1 {\n\t\t\tp.cond.Signal()\n\t\t\treturn\n\t\t}\n\t\tp.cond.Broadcast()\n\t}\n}\n\n// IsClosed indicates whether the pool is closed.\nfunc (p *Pool) IsClosed() bool {\n\treturn atomic.LoadInt32(&p.state) == CLOSED\n}\n\n// Release closes this pool and releases the worker queue.\nfunc (p *Pool) Release() {\n\tif !atomic.CompareAndSwapInt32(&p.state, OPENED, CLOSED) {\n\t\treturn\n\t}\n\n\tif p.stopPurge != nil {\n\t\tp.stopPurge()\n\t\tp.stopPurge = nil\n\t}\n\tif p.stopTicktock != nil {\n\t\tp.stopTicktock()\n\t\tp.stopTicktock = nil\n\t}\n\n\tp.lock.Lock()\n\tp.workers.reset()\n\tp.lock.Unlock()\n\t// There might be some callers waiting in retrieveWorker(), so we need to wake them up to prevent\n\t// those callers blocking infinitely.\n\tp.cond.Broadcast()\n}\n\n// ReleaseTimeout is like Release but with a timeout, it waits all workers to exit before timing out.\nfunc (p *Pool) ReleaseTimeout(timeout time.Duration) error {\n\tif p.IsClosed() || (!p.options.DisablePurge && p.stopPurge == nil) || p.stopTicktock == nil {\n\t\treturn ErrPoolClosed\n\t}\n\n\tp.Release()\n\n\tvar purgeCh <-chan struct{}\n\tif !p.options.DisablePurge {\n\t\tpurgeCh = p.purgeCtx.Done()\n\t} else {\n\t\tpurgeCh = p.allDone\n\t}\n\n\tif p.Running() == 0 {\n\t\tp.once.Do(func() {\n\t\t\tclose(p.allDone)\n\t\t})\n\t}\n\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\treturn ErrTimeout\n\t\tcase <-p.allDone:\n\t\t\t<-purgeCh\n\t\t\t<-p.ticktockCtx.Done()\n\t\t\tif p.Running() == 0 &&\n\t\t\t\t(p.options.DisablePurge || atomic.LoadInt32(&p.purgeDone) == 1) &&\n\t\t\t\tatomic.LoadInt32(&p.ticktockDone) == 1 {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Reboot reboots a closed pool, it does nothing if the pool is not closed.\n// If you intend to reboot a closed pool, use ReleaseTimeout() instead of\n// Release() to ensure that all workers are stopped and resource are released\n// before rebooting, otherwise you may run into data race.\nfunc (p *Pool) Reboot() {\n\tif atomic.CompareAndSwapInt32(&p.state, CLOSED, OPENED) {\n\t\tatomic.StoreInt32(&p.purgeDone, 0)\n\t\tp.goPurge()\n\t\tatomic.StoreInt32(&p.ticktockDone, 0)\n\t\tp.goTicktock()\n\t\tp.allDone = make(chan struct{})\n\t\tp.once = &sync.Once{}\n\t}\n}\n\nfunc (p *Pool) addRunning(delta int) int {\n\treturn int(atomic.AddInt32(&p.running, int32(delta)))\n}\n\nfunc (p *Pool) addWaiting(delta int) {\n\tatomic.AddInt32(&p.waiting, int32(delta))\n}\n\n// retrieveWorker returns an available worker to run the tasks.\nfunc (p *Pool) retrieveWorker() (w worker, err error) {\n\tp.lock.Lock()\n\nretry:\n\t// First try to fetch the worker from the queue.\n\tif w = p.workers.detach(); w != nil {\n\t\tp.lock.Unlock()\n\t\treturn\n\t}\n\n\t// If the worker queue is empty, and we don't run out of the pool capacity,\n\t// then just spawn a new worker goroutine.\n\tif capacity := p.Cap(); capacity == -1 || capacity > p.Running() {\n\t\tp.lock.Unlock()\n\t\tw = p.workerCache.Get().(*goWorker)\n\t\tw.run()\n\t\treturn\n\t}\n\n\t// Bail out early if it's in nonblocking mode or the number of pending callers reaches the maximum limit value.\n\tif p.options.Nonblocking || (p.options.MaxBlockingTasks != 0 && p.Waiting() >= p.options.MaxBlockingTasks) {\n\t\tp.lock.Unlock()\n\t\treturn nil, ErrPoolOverload\n\t}\n\n\t// Otherwise, we'll have to keep them blocked and wait for at least one worker to be put back into pool.\n\tp.addWaiting(1)\n\tp.cond.Wait() // block and wait for an available worker\n\tp.addWaiting(-1)\n\n\tif p.IsClosed() {\n\t\tp.lock.Unlock()\n\t\treturn nil, ErrPoolClosed\n\t}\n\n\tgoto retry\n}\n\n// revertWorker puts a worker back into free pool, recycling the goroutines.\nfunc (p *Pool) revertWorker(worker *goWorker) bool {\n\tif capacity := p.Cap(); (capacity > 0 && p.Running() > capacity) || p.IsClosed() {\n\t\tp.cond.Broadcast()\n\t\treturn false\n\t}\n\n\tworker.lastUsed = p.nowTime()\n\n\tp.lock.Lock()\n\t// To avoid memory leaks, add a double check in the lock scope.\n\t// Issue: https://github.com/panjf2000/ants/issues/113\n\tif p.IsClosed() {\n\t\tp.lock.Unlock()\n\t\treturn false\n\t}\n\tif err := p.workers.insert(worker); err != nil {\n\t\tp.lock.Unlock()\n\t\treturn false\n\t}\n\t// Notify the invoker stuck in 'retrieveWorker()' of there is an available worker in the worker queue.\n\tp.cond.Signal()\n\tp.lock.Unlock()\n\n\treturn true\n}\n"
        },
        {
          "name": "pool_func.go",
          "type": "blob",
          "size": 10.09375,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tsyncx \"github.com/panjf2000/ants/v2/internal/sync\"\n)\n\n// PoolWithFunc accepts the tasks and process them concurrently,\n// it limits the total of goroutines to a given number by recycling goroutines.\ntype PoolWithFunc struct {\n\tpoolCommon\n\n\t// poolFunc is the function for processing tasks.\n\tpoolFunc func(interface{})\n}\n\n// purgeStaleWorkers clears stale workers periodically, it runs in an individual goroutine, as a scavenger.\nfunc (p *PoolWithFunc) purgeStaleWorkers() {\n\tticker := time.NewTicker(p.options.ExpiryDuration)\n\tdefer func() {\n\t\tticker.Stop()\n\t\tatomic.StoreInt32(&p.purgeDone, 1)\n\t}()\n\n\tpurgeCtx := p.purgeCtx // copy to the local variable to avoid race from Reboot()\n\tfor {\n\t\tselect {\n\t\tcase <-purgeCtx.Done():\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t}\n\n\t\tif p.IsClosed() {\n\t\t\tbreak\n\t\t}\n\n\t\tvar isDormant bool\n\t\tp.lock.Lock()\n\t\tstaleWorkers := p.workers.refresh(p.options.ExpiryDuration)\n\t\tn := p.Running()\n\t\tisDormant = n == 0 || n == len(staleWorkers)\n\t\tp.lock.Unlock()\n\n\t\t// Clean up the stale workers.\n\t\tfor i := range staleWorkers {\n\t\t\tstaleWorkers[i].finish()\n\t\t\tstaleWorkers[i] = nil\n\t\t}\n\n\t\t// There might be a situation where all workers have been cleaned up (no worker is running),\n\t\t// while some invokers still are stuck in p.cond.Wait(), then we need to awake those invokers.\n\t\tif isDormant && p.Waiting() > 0 {\n\t\t\tp.cond.Broadcast()\n\t\t}\n\t}\n}\n\n// ticktock is a goroutine that updates the current time in the pool regularly.\nfunc (p *PoolWithFunc) ticktock() {\n\tticker := time.NewTicker(nowTimeUpdateInterval)\n\tdefer func() {\n\t\tticker.Stop()\n\t\tatomic.StoreInt32(&p.ticktockDone, 1)\n\t}()\n\n\tticktockCtx := p.ticktockCtx // copy to the local variable to avoid race from Reboot()\n\tfor {\n\t\tselect {\n\t\tcase <-ticktockCtx.Done():\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t}\n\n\t\tif p.IsClosed() {\n\t\t\tbreak\n\t\t}\n\n\t\tp.now.Store(time.Now())\n\t}\n}\n\nfunc (p *PoolWithFunc) goPurge() {\n\tif p.options.DisablePurge {\n\t\treturn\n\t}\n\n\t// Start a goroutine to clean up expired workers periodically.\n\tp.purgeCtx, p.stopPurge = context.WithCancel(context.Background())\n\tgo p.purgeStaleWorkers()\n}\n\nfunc (p *PoolWithFunc) goTicktock() {\n\tp.now.Store(time.Now())\n\tp.ticktockCtx, p.stopTicktock = context.WithCancel(context.Background())\n\tgo p.ticktock()\n}\n\nfunc (p *PoolWithFunc) nowTime() time.Time {\n\treturn p.now.Load().(time.Time)\n}\n\n// NewPoolWithFunc instantiates a PoolWithFunc with customized options.\nfunc NewPoolWithFunc(size int, pf func(interface{}), options ...Option) (*PoolWithFunc, error) {\n\tif size <= 0 {\n\t\tsize = -1\n\t}\n\n\tif pf == nil {\n\t\treturn nil, ErrLackPoolFunc\n\t}\n\n\topts := loadOptions(options...)\n\n\tif !opts.DisablePurge {\n\t\tif expiry := opts.ExpiryDuration; expiry < 0 {\n\t\t\treturn nil, ErrInvalidPoolExpiry\n\t\t} else if expiry == 0 {\n\t\t\topts.ExpiryDuration = DefaultCleanIntervalTime\n\t\t}\n\t}\n\n\tif opts.Logger == nil {\n\t\topts.Logger = defaultLogger\n\t}\n\n\tp := &PoolWithFunc{\n\t\tpoolCommon: poolCommon{\n\t\t\tcapacity: int32(size),\n\t\t\tallDone:  make(chan struct{}),\n\t\t\tlock:     syncx.NewSpinLock(),\n\t\t\tonce:     &sync.Once{},\n\t\t\toptions:  opts,\n\t\t},\n\t\tpoolFunc: pf,\n\t}\n\tp.workerCache.New = func() interface{} {\n\t\treturn &goWorkerWithFunc{\n\t\t\tpool: p,\n\t\t\targs: make(chan interface{}, workerChanCap),\n\t\t}\n\t}\n\tif p.options.PreAlloc {\n\t\tif size == -1 {\n\t\t\treturn nil, ErrInvalidPreAllocSize\n\t\t}\n\t\tp.workers = newWorkerQueue(queueTypeLoopQueue, size)\n\t} else {\n\t\tp.workers = newWorkerQueue(queueTypeStack, 0)\n\t}\n\n\tp.cond = sync.NewCond(p.lock)\n\n\tp.goPurge()\n\tp.goTicktock()\n\n\treturn p, nil\n}\n\n// Invoke submits a task to pool.\n//\n// Note that you are allowed to call Pool.Invoke() from the current Pool.Invoke(),\n// but what calls for special attention is that you will get blocked with the last\n// Pool.Invoke() call once the current Pool runs out of its capacity, and to avoid this,\n// you should instantiate a PoolWithFunc with ants.WithNonblocking(true).\nfunc (p *PoolWithFunc) Invoke(args interface{}) error {\n\tif p.IsClosed() {\n\t\treturn ErrPoolClosed\n\t}\n\n\tw, err := p.retrieveWorker()\n\tif w != nil {\n\t\tw.inputParam(args)\n\t}\n\treturn err\n}\n\n// Running returns the number of workers currently running.\nfunc (p *PoolWithFunc) Running() int {\n\treturn int(atomic.LoadInt32(&p.running))\n}\n\n// Free returns the number of available workers, -1 indicates this pool is unlimited.\nfunc (p *PoolWithFunc) Free() int {\n\tc := p.Cap()\n\tif c < 0 {\n\t\treturn -1\n\t}\n\treturn c - p.Running()\n}\n\n// Waiting returns the number of tasks waiting to be executed.\nfunc (p *PoolWithFunc) Waiting() int {\n\treturn int(atomic.LoadInt32(&p.waiting))\n}\n\n// Cap returns the capacity of this pool.\nfunc (p *PoolWithFunc) Cap() int {\n\treturn int(atomic.LoadInt32(&p.capacity))\n}\n\n// Tune changes the capacity of this pool, note that it is noneffective to the infinite or pre-allocation pool.\nfunc (p *PoolWithFunc) Tune(size int) {\n\tcapacity := p.Cap()\n\tif capacity == -1 || size <= 0 || size == capacity || p.options.PreAlloc {\n\t\treturn\n\t}\n\tatomic.StoreInt32(&p.capacity, int32(size))\n\tif size > capacity {\n\t\tif size-capacity == 1 {\n\t\t\tp.cond.Signal()\n\t\t\treturn\n\t\t}\n\t\tp.cond.Broadcast()\n\t}\n}\n\n// IsClosed indicates whether the pool is closed.\nfunc (p *PoolWithFunc) IsClosed() bool {\n\treturn atomic.LoadInt32(&p.state) == CLOSED\n}\n\n// Release closes this pool and releases the worker queue.\nfunc (p *PoolWithFunc) Release() {\n\tif !atomic.CompareAndSwapInt32(&p.state, OPENED, CLOSED) {\n\t\treturn\n\t}\n\n\tif p.stopPurge != nil {\n\t\tp.stopPurge()\n\t\tp.stopPurge = nil\n\t}\n\tif p.stopTicktock != nil {\n\t\tp.stopTicktock()\n\t\tp.stopTicktock = nil\n\t}\n\n\tp.lock.Lock()\n\tp.workers.reset()\n\tp.lock.Unlock()\n\t// There might be some callers waiting in retrieveWorker(), so we need to wake them up to prevent\n\t// those callers blocking infinitely.\n\tp.cond.Broadcast()\n}\n\n// ReleaseTimeout is like Release but with a timeout, it waits all workers to exit before timing out.\nfunc (p *PoolWithFunc) ReleaseTimeout(timeout time.Duration) error {\n\tif p.IsClosed() || (!p.options.DisablePurge && p.stopPurge == nil) || p.stopTicktock == nil {\n\t\treturn ErrPoolClosed\n\t}\n\n\tp.Release()\n\n\tvar purgeCh <-chan struct{}\n\tif !p.options.DisablePurge {\n\t\tpurgeCh = p.purgeCtx.Done()\n\t} else {\n\t\tpurgeCh = p.allDone\n\t}\n\n\tif p.Running() == 0 {\n\t\tp.once.Do(func() {\n\t\t\tclose(p.allDone)\n\t\t})\n\t}\n\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\treturn ErrTimeout\n\t\tcase <-p.allDone:\n\t\t\t<-purgeCh\n\t\t\t<-p.ticktockCtx.Done()\n\t\t\tif p.Running() == 0 &&\n\t\t\t\t(p.options.DisablePurge || atomic.LoadInt32(&p.purgeDone) == 1) &&\n\t\t\t\tatomic.LoadInt32(&p.ticktockDone) == 1 {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Reboot reboots a closed pool, it does nothing if the pool is not closed.\n// If you intend to reboot a closed pool, use ReleaseTimeout() instead of\n// Release() to ensure that all workers are stopped and resource are released\n// before rebooting, otherwise you may run into data race.\nfunc (p *PoolWithFunc) Reboot() {\n\tif atomic.CompareAndSwapInt32(&p.state, CLOSED, OPENED) {\n\t\tatomic.StoreInt32(&p.purgeDone, 0)\n\t\tp.goPurge()\n\t\tatomic.StoreInt32(&p.ticktockDone, 0)\n\t\tp.goTicktock()\n\t\tp.allDone = make(chan struct{})\n\t\tp.once = &sync.Once{}\n\t}\n}\n\nfunc (p *PoolWithFunc) addRunning(delta int) int {\n\treturn int(atomic.AddInt32(&p.running, int32(delta)))\n}\n\nfunc (p *PoolWithFunc) addWaiting(delta int) {\n\tatomic.AddInt32(&p.waiting, int32(delta))\n}\n\n// retrieveWorker returns an available worker to run the tasks.\nfunc (p *PoolWithFunc) retrieveWorker() (w worker, err error) {\n\tp.lock.Lock()\n\nretry:\n\t// First try to fetch the worker from the queue.\n\tif w = p.workers.detach(); w != nil {\n\t\tp.lock.Unlock()\n\t\treturn\n\t}\n\n\t// If the worker queue is empty, and we don't run out of the pool capacity,\n\t// then just spawn a new worker goroutine.\n\tif capacity := p.Cap(); capacity == -1 || capacity > p.Running() {\n\t\tp.lock.Unlock()\n\t\tw = p.workerCache.Get().(*goWorkerWithFunc)\n\t\tw.run()\n\t\treturn\n\t}\n\n\t// Bail out early if it's in nonblocking mode or the number of pending callers reaches the maximum limit value.\n\tif p.options.Nonblocking || (p.options.MaxBlockingTasks != 0 && p.Waiting() >= p.options.MaxBlockingTasks) {\n\t\tp.lock.Unlock()\n\t\treturn nil, ErrPoolOverload\n\t}\n\n\t// Otherwise, we'll have to keep them blocked and wait for at least one worker to be put back into pool.\n\tp.addWaiting(1)\n\tp.cond.Wait() // block and wait for an available worker\n\tp.addWaiting(-1)\n\n\tif p.IsClosed() {\n\t\tp.lock.Unlock()\n\t\treturn nil, ErrPoolClosed\n\t}\n\n\tgoto retry\n}\n\n// revertWorker puts a worker back into free pool, recycling the goroutines.\nfunc (p *PoolWithFunc) revertWorker(worker *goWorkerWithFunc) bool {\n\tif capacity := p.Cap(); (capacity > 0 && p.Running() > capacity) || p.IsClosed() {\n\t\tp.cond.Broadcast()\n\t\treturn false\n\t}\n\n\tworker.lastUsed = p.nowTime()\n\n\tp.lock.Lock()\n\t// To avoid memory leaks, add a double check in the lock scope.\n\t// Issue: https://github.com/panjf2000/ants/issues/113\n\tif p.IsClosed() {\n\t\tp.lock.Unlock()\n\t\treturn false\n\t}\n\tif err := p.workers.insert(worker); err != nil {\n\t\tp.lock.Unlock()\n\t\treturn false\n\t}\n\t// Notify the invoker stuck in 'retrieveWorker()' of there is an available worker in the worker queue.\n\tp.cond.Signal()\n\tp.lock.Unlock()\n\n\treturn true\n}\n"
        },
        {
          "name": "worker.go",
          "type": "blob",
          "size": 2.4775390625,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"runtime/debug\"\n\t\"time\"\n)\n\n// goWorker is the actual executor who runs the tasks,\n// it starts a goroutine that accepts tasks and\n// performs function calls.\ntype goWorker struct {\n\t// pool who owns this worker.\n\tpool *Pool\n\n\t// task is a job should be done.\n\ttask chan func()\n\n\t// lastUsed will be updated when putting a worker back into queue.\n\tlastUsed time.Time\n}\n\n// run starts a goroutine to repeat the process\n// that performs the function calls.\nfunc (w *goWorker) run() {\n\tw.pool.addRunning(1)\n\tgo func() {\n\t\tdefer func() {\n\t\t\tif w.pool.addRunning(-1) == 0 && w.pool.IsClosed() {\n\t\t\t\tw.pool.once.Do(func() {\n\t\t\t\t\tclose(w.pool.allDone)\n\t\t\t\t})\n\t\t\t}\n\t\t\tw.pool.workerCache.Put(w)\n\t\t\tif p := recover(); p != nil {\n\t\t\t\tif ph := w.pool.options.PanicHandler; ph != nil {\n\t\t\t\t\tph(p)\n\t\t\t\t} else {\n\t\t\t\t\tw.pool.options.Logger.Printf(\"worker exits from panic: %v\\n%s\\n\", p, debug.Stack())\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Call Signal() here in case there are goroutines waiting for available workers.\n\t\t\tw.pool.cond.Signal()\n\t\t}()\n\n\t\tfor f := range w.task {\n\t\t\tif f == nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tf()\n\t\t\tif ok := w.pool.revertWorker(w); !ok {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (w *goWorker) finish() {\n\tw.task <- nil\n}\n\nfunc (w *goWorker) lastUsedTime() time.Time {\n\treturn w.lastUsed\n}\n\nfunc (w *goWorker) inputFunc(fn func()) {\n\tw.task <- fn\n}\n\nfunc (w *goWorker) inputParam(interface{}) {\n\tpanic(\"unreachable\")\n}\n"
        },
        {
          "name": "worker_func.go",
          "type": "blob",
          "size": 2.5703125,
          "content": "// MIT License\n\n// Copyright (c) 2018 Andy Pan\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage ants\n\nimport (\n\t\"runtime/debug\"\n\t\"time\"\n)\n\n// goWorkerWithFunc is the actual executor who runs the tasks,\n// it starts a goroutine that accepts tasks and\n// performs function calls.\ntype goWorkerWithFunc struct {\n\t// pool who owns this worker.\n\tpool *PoolWithFunc\n\n\t// args is a job should be done.\n\targs chan interface{}\n\n\t// lastUsed will be updated when putting a worker back into queue.\n\tlastUsed time.Time\n}\n\n// run starts a goroutine to repeat the process\n// that performs the function calls.\nfunc (w *goWorkerWithFunc) run() {\n\tw.pool.addRunning(1)\n\tgo func() {\n\t\tdefer func() {\n\t\t\tif w.pool.addRunning(-1) == 0 && w.pool.IsClosed() {\n\t\t\t\tw.pool.once.Do(func() {\n\t\t\t\t\tclose(w.pool.allDone)\n\t\t\t\t})\n\t\t\t}\n\t\t\tw.pool.workerCache.Put(w)\n\t\t\tif p := recover(); p != nil {\n\t\t\t\tif ph := w.pool.options.PanicHandler; ph != nil {\n\t\t\t\t\tph(p)\n\t\t\t\t} else {\n\t\t\t\t\tw.pool.options.Logger.Printf(\"worker exits from panic: %v\\n%s\\n\", p, debug.Stack())\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Call Signal() here in case there are goroutines waiting for available workers.\n\t\t\tw.pool.cond.Signal()\n\t\t}()\n\n\t\tfor args := range w.args {\n\t\t\tif args == nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tw.pool.poolFunc(args)\n\t\t\tif ok := w.pool.revertWorker(w); !ok {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (w *goWorkerWithFunc) finish() {\n\tw.args <- nil\n}\n\nfunc (w *goWorkerWithFunc) lastUsedTime() time.Time {\n\treturn w.lastUsed\n}\n\nfunc (w *goWorkerWithFunc) inputFunc(func()) {\n\tpanic(\"unreachable\")\n}\n\nfunc (w *goWorkerWithFunc) inputParam(arg interface{}) {\n\tw.args <- arg\n}\n"
        },
        {
          "name": "worker_loop_queue.go",
          "type": "blob",
          "size": 2.9140625,
          "content": "package ants\n\nimport \"time\"\n\ntype loopQueue struct {\n\titems  []worker\n\texpiry []worker\n\thead   int\n\ttail   int\n\tsize   int\n\tisFull bool\n}\n\nfunc newWorkerLoopQueue(size int) *loopQueue {\n\treturn &loopQueue{\n\t\titems: make([]worker, size),\n\t\tsize:  size,\n\t}\n}\n\nfunc (wq *loopQueue) len() int {\n\tif wq.size == 0 || wq.isEmpty() {\n\t\treturn 0\n\t}\n\n\tif wq.head == wq.tail && wq.isFull {\n\t\treturn wq.size\n\t}\n\n\tif wq.tail > wq.head {\n\t\treturn wq.tail - wq.head\n\t}\n\n\treturn wq.size - wq.head + wq.tail\n}\n\nfunc (wq *loopQueue) isEmpty() bool {\n\treturn wq.head == wq.tail && !wq.isFull\n}\n\nfunc (wq *loopQueue) insert(w worker) error {\n\tif wq.size == 0 {\n\t\treturn errQueueIsReleased\n\t}\n\n\tif wq.isFull {\n\t\treturn errQueueIsFull\n\t}\n\twq.items[wq.tail] = w\n\twq.tail = (wq.tail + 1) % wq.size\n\n\tif wq.tail == wq.head {\n\t\twq.isFull = true\n\t}\n\n\treturn nil\n}\n\nfunc (wq *loopQueue) detach() worker {\n\tif wq.isEmpty() {\n\t\treturn nil\n\t}\n\n\tw := wq.items[wq.head]\n\twq.items[wq.head] = nil\n\twq.head = (wq.head + 1) % wq.size\n\n\twq.isFull = false\n\n\treturn w\n}\n\nfunc (wq *loopQueue) refresh(duration time.Duration) []worker {\n\texpiryTime := time.Now().Add(-duration)\n\tindex := wq.binarySearch(expiryTime)\n\tif index == -1 {\n\t\treturn nil\n\t}\n\twq.expiry = wq.expiry[:0]\n\n\tif wq.head <= index {\n\t\twq.expiry = append(wq.expiry, wq.items[wq.head:index+1]...)\n\t\tfor i := wq.head; i < index+1; i++ {\n\t\t\twq.items[i] = nil\n\t\t}\n\t} else {\n\t\twq.expiry = append(wq.expiry, wq.items[0:index+1]...)\n\t\twq.expiry = append(wq.expiry, wq.items[wq.head:]...)\n\t\tfor i := 0; i < index+1; i++ {\n\t\t\twq.items[i] = nil\n\t\t}\n\t\tfor i := wq.head; i < wq.size; i++ {\n\t\t\twq.items[i] = nil\n\t\t}\n\t}\n\thead := (index + 1) % wq.size\n\twq.head = head\n\tif len(wq.expiry) > 0 {\n\t\twq.isFull = false\n\t}\n\n\treturn wq.expiry\n}\n\nfunc (wq *loopQueue) binarySearch(expiryTime time.Time) int {\n\tvar mid, nlen, basel, tmid int\n\tnlen = len(wq.items)\n\n\t// if no need to remove work, return -1\n\tif wq.isEmpty() || expiryTime.Before(wq.items[wq.head].lastUsedTime()) {\n\t\treturn -1\n\t}\n\n\t// example\n\t// size = 8, head = 7, tail = 4\n\t// [ 2, 3, 4, 5, nil, nil, nil,  1]  true position\n\t//   0  1  2  3    4   5     6   7\n\t//              tail          head\n\t//\n\t//   1  2  3  4  nil nil   nil   0   mapped position\n\t//            r                  l\n\n\t// base algorithm is a copy from worker_stack\n\t// map head and tail to effective left and right\n\tr := (wq.tail - 1 - wq.head + nlen) % nlen\n\tbasel = wq.head\n\tl := 0\n\tfor l <= r {\n\t\tmid = l + ((r - l) >> 1) // avoid overflow when computing mid\n\t\t// calculate true mid position from mapped mid position\n\t\ttmid = (mid + basel + nlen) % nlen\n\t\tif expiryTime.Before(wq.items[tmid].lastUsedTime()) {\n\t\t\tr = mid - 1\n\t\t} else {\n\t\t\tl = mid + 1\n\t\t}\n\t}\n\t// return true position from mapped position\n\treturn (r + basel + nlen) % nlen\n}\n\nfunc (wq *loopQueue) reset() {\n\tif wq.isEmpty() {\n\t\treturn\n\t}\n\nretry:\n\tif w := wq.detach(); w != nil {\n\t\tw.finish()\n\t\tgoto retry\n\t}\n\twq.items = wq.items[:0]\n\twq.size = 0\n\twq.head = 0\n\twq.tail = 0\n}\n"
        },
        {
          "name": "worker_loop_queue_test.go",
          "type": "blob",
          "size": 4.474609375,
          "content": "//go:build !windows\n// +build !windows\n\npackage ants\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewLoopQueue(t *testing.T) {\n\tsize := 100\n\tq := newWorkerLoopQueue(size)\n\tassert.EqualValues(t, 0, q.len(), \"Len error\")\n\tassert.Equal(t, true, q.isEmpty(), \"IsEmpty error\")\n\tassert.Nil(t, q.detach(), \"Dequeue error\")\n}\n\nfunc TestLoopQueue(t *testing.T) {\n\tsize := 10\n\tq := newWorkerLoopQueue(size)\n\n\tfor i := 0; i < 5; i++ {\n\t\terr := q.insert(&goWorker{lastUsed: time.Now()})\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\tassert.EqualValues(t, 5, q.len(), \"Len error\")\n\t_ = q.detach()\n\tassert.EqualValues(t, 4, q.len(), \"Len error\")\n\n\ttime.Sleep(time.Second)\n\n\tfor i := 0; i < 6; i++ {\n\t\terr := q.insert(&goWorker{lastUsed: time.Now()})\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\tassert.EqualValues(t, 10, q.len(), \"Len error\")\n\n\terr := q.insert(&goWorker{lastUsed: time.Now()})\n\tassert.Error(t, err, \"Enqueue, error\")\n\n\tq.refresh(time.Second)\n\tassert.EqualValuesf(t, 6, q.len(), \"Len error: %d\", q.len())\n}\n\nfunc TestRotatedQueueSearch(t *testing.T) {\n\tsize := 10\n\tq := newWorkerLoopQueue(size)\n\n\t// 1\n\texpiry1 := time.Now()\n\n\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\n\tassert.EqualValues(t, 0, q.binarySearch(time.Now()), \"index should be 0\")\n\tassert.EqualValues(t, -1, q.binarySearch(expiry1), \"index should be -1\")\n\n\t// 2\n\texpiry2 := time.Now()\n\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\n\tassert.EqualValues(t, -1, q.binarySearch(expiry1), \"index should be -1\")\n\n\tassert.EqualValues(t, 0, q.binarySearch(expiry2), \"index should be 0\")\n\n\tassert.EqualValues(t, 1, q.binarySearch(time.Now()), \"index should be 1\")\n\n\t// more\n\tfor i := 0; i < 5; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\n\texpiry3 := time.Now()\n\t_ = q.insert(&goWorker{lastUsed: expiry3})\n\n\tvar err error\n\tfor err != errQueueIsFull {\n\t\terr = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\n\tassert.EqualValues(t, 7, q.binarySearch(expiry3), \"index should be 7\")\n\n\t// rotate\n\tfor i := 0; i < 6; i++ {\n\t\t_ = q.detach()\n\t}\n\n\texpiry4 := time.Now()\n\t_ = q.insert(&goWorker{lastUsed: expiry4})\n\n\tfor i := 0; i < 4; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\t//\thead = 6, tail = 5, insert direction ->\n\t// [expiry4, time, time, time,  time, nil/tail,  time/head, time, time, time]\n\tassert.EqualValues(t, 0, q.binarySearch(expiry4), \"index should be 0\")\n\n\tfor i := 0; i < 3; i++ {\n\t\t_ = q.detach()\n\t}\n\texpiry5 := time.Now()\n\t_ = q.insert(&goWorker{lastUsed: expiry5})\n\n\t//\thead = 6, tail = 5, insert direction ->\n\t// [expiry4, time, time, time,  time, expiry5,  nil/tail, nil, nil, time/head]\n\tassert.EqualValues(t, 5, q.binarySearch(expiry5), \"index should be 5\")\n\n\tfor i := 0; i < 3; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\t//\thead = 9, tail = 9, insert direction ->\n\t// [expiry4, time, time, time,  time, expiry5,  time, time, time, time/head/tail]\n\tassert.EqualValues(t, -1, q.binarySearch(expiry2), \"index should be -1\")\n\n\tassert.EqualValues(t, 9, q.binarySearch(q.items[9].lastUsedTime()), \"index should be 9\")\n\tassert.EqualValues(t, 8, q.binarySearch(time.Now()), \"index should be 8\")\n}\n\nfunc TestRetrieveExpiry(t *testing.T) {\n\tsize := 10\n\tq := newWorkerLoopQueue(size)\n\texpirew := make([]worker, 0)\n\tu, _ := time.ParseDuration(\"1s\")\n\n\t// test [ time+1s, time+1s, time+1s, time+1s, time+1s, time, time, time, time, time]\n\tfor i := 0; i < size/2; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\texpirew = append(expirew, q.items[:size/2]...)\n\ttime.Sleep(u)\n\n\tfor i := 0; i < size/2; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\tworkers := q.refresh(u)\n\n\tassert.EqualValues(t, expirew, workers, \"expired workers aren't right\")\n\n\t// test [ time, time, time, time, time, time+1s, time+1s, time+1s, time+1s, time+1s]\n\ttime.Sleep(u)\n\n\tfor i := 0; i < size/2; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\texpirew = expirew[:0]\n\texpirew = append(expirew, q.items[size/2:]...)\n\n\tworkers2 := q.refresh(u)\n\n\tassert.EqualValues(t, expirew, workers2, \"expired workers aren't right\")\n\n\t// test [ time+1s, time+1s, time+1s, nil, nil, time+1s, time+1s, time+1s, time+1s, time+1s]\n\tfor i := 0; i < size/2; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\tfor i := 0; i < size/2; i++ {\n\t\t_ = q.detach()\n\t}\n\tfor i := 0; i < 3; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\ttime.Sleep(u)\n\n\texpirew = expirew[:0]\n\texpirew = append(expirew, q.items[0:3]...)\n\texpirew = append(expirew, q.items[size/2:]...)\n\n\tworkers3 := q.refresh(u)\n\n\tassert.EqualValues(t, expirew, workers3, \"expired workers aren't right\")\n}\n"
        },
        {
          "name": "worker_queue.go",
          "type": "blob",
          "size": 0.9365234375,
          "content": "package ants\n\nimport (\n\t\"errors\"\n\t\"time\"\n)\n\nvar (\n\t// errQueueIsFull will be returned when the worker queue is full.\n\terrQueueIsFull = errors.New(\"the queue is full\")\n\n\t// errQueueIsReleased will be returned when trying to insert item to a released worker queue.\n\terrQueueIsReleased = errors.New(\"the queue length is zero\")\n)\n\ntype worker interface {\n\trun()\n\tfinish()\n\tlastUsedTime() time.Time\n\tinputFunc(func())\n\tinputParam(interface{})\n}\n\ntype workerQueue interface {\n\tlen() int\n\tisEmpty() bool\n\tinsert(worker) error\n\tdetach() worker\n\trefresh(duration time.Duration) []worker // clean up the stale workers and return them\n\treset()\n}\n\ntype queueType int\n\nconst (\n\tqueueTypeStack queueType = 1 << iota\n\tqueueTypeLoopQueue\n)\n\nfunc newWorkerQueue(qType queueType, size int) workerQueue {\n\tswitch qType {\n\tcase queueTypeStack:\n\t\treturn newWorkerStack(size)\n\tcase queueTypeLoopQueue:\n\t\treturn newWorkerLoopQueue(size)\n\tdefault:\n\t\treturn newWorkerStack(size)\n\t}\n}\n"
        },
        {
          "name": "worker_stack.go",
          "type": "blob",
          "size": 1.4306640625,
          "content": "package ants\n\nimport \"time\"\n\ntype workerStack struct {\n\titems  []worker\n\texpiry []worker\n}\n\nfunc newWorkerStack(size int) *workerStack {\n\treturn &workerStack{\n\t\titems: make([]worker, 0, size),\n\t}\n}\n\nfunc (wq *workerStack) len() int {\n\treturn len(wq.items)\n}\n\nfunc (wq *workerStack) isEmpty() bool {\n\treturn len(wq.items) == 0\n}\n\nfunc (wq *workerStack) insert(w worker) error {\n\twq.items = append(wq.items, w)\n\treturn nil\n}\n\nfunc (wq *workerStack) detach() worker {\n\tl := wq.len()\n\tif l == 0 {\n\t\treturn nil\n\t}\n\n\tw := wq.items[l-1]\n\twq.items[l-1] = nil // avoid memory leaks\n\twq.items = wq.items[:l-1]\n\n\treturn w\n}\n\nfunc (wq *workerStack) refresh(duration time.Duration) []worker {\n\tn := wq.len()\n\tif n == 0 {\n\t\treturn nil\n\t}\n\n\texpiryTime := time.Now().Add(-duration)\n\tindex := wq.binarySearch(0, n-1, expiryTime)\n\n\twq.expiry = wq.expiry[:0]\n\tif index != -1 {\n\t\twq.expiry = append(wq.expiry, wq.items[:index+1]...)\n\t\tm := copy(wq.items, wq.items[index+1:])\n\t\tfor i := m; i < n; i++ {\n\t\t\twq.items[i] = nil\n\t\t}\n\t\twq.items = wq.items[:m]\n\t}\n\treturn wq.expiry\n}\n\nfunc (wq *workerStack) binarySearch(l, r int, expiryTime time.Time) int {\n\tfor l <= r {\n\t\tmid := l + ((r - l) >> 1) // avoid overflow when computing mid\n\t\tif expiryTime.Before(wq.items[mid].lastUsedTime()) {\n\t\t\tr = mid - 1\n\t\t} else {\n\t\t\tl = mid + 1\n\t\t}\n\t}\n\treturn r\n}\n\nfunc (wq *workerStack) reset() {\n\tfor i := 0; i < wq.len(); i++ {\n\t\twq.items[i].finish()\n\t\twq.items[i] = nil\n\t}\n\twq.items = wq.items[:0]\n}\n"
        },
        {
          "name": "worker_stack_test.go",
          "type": "blob",
          "size": 2.078125,
          "content": "//go:build !windows\n// +build !windows\n\npackage ants\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewWorkerStack(t *testing.T) {\n\tsize := 100\n\tq := newWorkerStack(size)\n\tassert.EqualValues(t, 0, q.len(), \"Len error\")\n\tassert.Equal(t, true, q.isEmpty(), \"IsEmpty error\")\n\tassert.Nil(t, q.detach(), \"Dequeue error\")\n}\n\nfunc TestWorkerStack(t *testing.T) {\n\tq := newWorkerQueue(queueType(-1), 0)\n\n\tfor i := 0; i < 5; i++ {\n\t\terr := q.insert(&goWorker{lastUsed: time.Now()})\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\tassert.EqualValues(t, 5, q.len(), \"Len error\")\n\n\texpired := time.Now()\n\n\terr := q.insert(&goWorker{lastUsed: expired})\n\tif err != nil {\n\t\tt.Fatal(\"Enqueue error\")\n\t}\n\n\ttime.Sleep(time.Second)\n\n\tfor i := 0; i < 6; i++ {\n\t\terr := q.insert(&goWorker{lastUsed: time.Now()})\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Enqueue error\")\n\t\t}\n\t}\n\tassert.EqualValues(t, 12, q.len(), \"Len error\")\n\tq.refresh(time.Second)\n\tassert.EqualValues(t, 6, q.len(), \"Len error\")\n}\n\n// It seems that something wrong with time.Now() on Windows, not sure whether it is a bug on Windows,\n// so exclude this test from Windows platform temporarily.\nfunc TestSearch(t *testing.T) {\n\tq := newWorkerStack(0)\n\n\t// 1\n\texpiry1 := time.Now()\n\n\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\n\tassert.EqualValues(t, 0, q.binarySearch(0, q.len()-1, time.Now()), \"index should be 0\")\n\tassert.EqualValues(t, -1, q.binarySearch(0, q.len()-1, expiry1), \"index should be -1\")\n\n\t// 2\n\texpiry2 := time.Now()\n\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\n\tassert.EqualValues(t, -1, q.binarySearch(0, q.len()-1, expiry1), \"index should be -1\")\n\n\tassert.EqualValues(t, 0, q.binarySearch(0, q.len()-1, expiry2), \"index should be 0\")\n\n\tassert.EqualValues(t, 1, q.binarySearch(0, q.len()-1, time.Now()), \"index should be 1\")\n\n\t// more\n\tfor i := 0; i < 5; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\n\texpiry3 := time.Now()\n\n\t_ = q.insert(&goWorker{lastUsed: expiry3})\n\n\tfor i := 0; i < 10; i++ {\n\t\t_ = q.insert(&goWorker{lastUsed: time.Now()})\n\t}\n\n\tassert.EqualValues(t, 7, q.binarySearch(0, q.len()-1, expiry3), \"index should be 7\")\n}\n"
        }
      ]
    }
  ]
}