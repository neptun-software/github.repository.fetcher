{
  "metadata": {
    "timestamp": 1736567998001,
    "page": 132,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "tomnomnom/gron",
      "stars": 13939,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.046875,
          "content": "gron\n*.tgz\n*.zip\n*.swp\n*.exe\ncpu.out\ngron.test\n\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.0576171875,
          "content": "language: go\n\ngo:\n  - \"1.13\"\n  - \"1.14\"\n  - \"1.15\"\n  - tip\n"
        },
        {
          "name": "ADVANCED.mkd",
          "type": "blob",
          "size": 5.7666015625,
          "content": "# Advanced Usage\n\nAlthough gron's primary purpose is API discovery, when combined with other tools like `grep` it can do some interesting things.\n\nAs an exercise, let's try to mimick some of the examples from the [jq tutorial](https://stedolan.github.io/jq/tutorial/).\n\n> Disclaimer: munging data on the command line with gron can be useful, but using tools like `grep` and `sed` to manipulate the\n> data is error-prone and shouldn't be relied on in scripts.\n\nGet the last 5 commits from the gron repo:\n```\n▶ gron \"https://api.github.com/repos/tomnomnom/gron/commits?per_page=5\"\njson = [];\njson[0] = {};\njson[0].author = {};\njson[0].author.avatar_url = \"https://avatars.githubusercontent.com/u/58276?v=3\";\njson[0].author.events_url = \"https://api.github.com/users/tomnomnom/events{/privacy}\";\n...\njson[4].parents[0].html_url = \"https://github.com/tomnomnom/gron/commit/cbcad2299e55c28a9922776e58b2a0b5a0f05016\";\njson[4].parents[0].sha = \"cbcad2299e55c28a9922776e58b2a0b5a0f05016\";\njson[4].parents[0].url = \"https://api.github.com/repos/tomnomnom/gron/commits/cbcad2299e55c28a9922776e58b2a0b5a0f05016\";\njson[4].sha = \"91b204972e63a1166c9d148fbbfd839f8697f91b\";\njson[4].url = \"https://api.github.com/repos/tomnomnom/gron/commits/91b204972e63a1166c9d148fbbfd839f8697f91b\";\n```\n\nTo make the rest of this a little more readable, let's add an alias for that:\n\n```\n▶ alias ggh='gron \"https://api.github.com/repos/tomnomnom/gron/commits?per_page=5\"'\n```\n\nExtract just the first commit using `fgrep \"json[0]\"`:\n```\n▶ ggh | fgrep \"json[0]\"\njson[0] = {};\njson[0].author = {};\njson[0].author.avatar_url = \"https://avatars.githubusercontent.com/u/58276?v=3\";\njson[0].author.events_url = \"https://api.github.com/users/tomnomnom/events{/privacy}\";\njson[0].author.followers_url = \"https://api.github.com/users/tomnomnom/followers\";\n...\njson[0].parents[0].html_url = \"https://github.com/tomnomnom/gron/commit/48aba5325ece087ae24ab72684851cbe77ce8311\";\njson[0].parents[0].sha = \"48aba5325ece087ae24ab72684851cbe77ce8311\";\njson[0].parents[0].url = \"https://api.github.com/repos/tomnomnom/gron/commits/48aba5325ece087ae24ab72684851cbe77ce8311\";\njson[0].sha = \"7da81e29c27241c0a5c2e5d083ddebcfcc525908\";\njson[0].url = \"https://api.github.com/repos/tomnomnom/gron/commits/7da81e29c27241c0a5c2e5d083ddebcfcc525908\";\n```\n\nGet just the committer's name and the commit message using `egrep \"(committer.name|commit.message)\"`:\n```\n▶ ggh | fgrep \"json[0]\" | egrep \"(committer.name|commit.message)\"\njson[0].commit.committer.name = \"Tom Hudson\";\njson[0].commit.message = \"Adds 0.1.7 to changelog\";\n```\n\nTurn the result back into JSON using `gron --ungron`:\n```\n▶ ggh | fgrep \"json[0]\" | egrep \"(committer.name|commit.message)\" | gron --ungron\n[\n  {\n    \"commit\": {\n      \"committer\": {\n        \"name\": \"Tom Hudson\"\n      },\n      \"message\": \"Adds 0.1.7 to changelog\"\n    }\n  }\n]\n```\n\ngron preserves the location of values in the JSON, but you can use `sed` to remove keys from the path:\n```\n▶ ggh | fgrep \"json[0]\" | egrep \"(committer.name|commit.message)\" | sed -r \"s/(commit|committer)\\.//g\"\njson[0].name = \"Tom Hudson\";\njson[0].message = \"Adds 0.1.7 to changelog\"\n\n```\n\nWith those keys removed, the result is a 'flattened' object, which looks much cleaner when turned\nback into JSON with `gron --ungron`:\n\n```\n▶ ggh | fgrep \"json[0]\" | egrep \"(committer.name|commit.message)\" | sed -r \"s/(commit|committer)\\.//g\" | gron --ungron\n[\n  {\n    \"message\": \"Adds 0.1.7 to changelog\",\n    \"name\": \"Tom Hudson\"\n  }\n]\n```\n\nRemoving the `fgrep \"json[0]\"` from the pipeline means we do the same for all commits:\n```\n▶ ggh | egrep \"(committer.name|commit.message)\" | sed -r \"s/(commit|committer)\\.//g\" | gron --ungron\n[\n  {\n    \"message\": \"Adds 0.1.7 to changelog\",\n    \"name\": \"Tom Hudson\"\n  },\n  {\n    \"message\": \"Refactors natural sort to actualy work + be more readable\",\n    \"name\": \"Tom Hudson\"\n  },\n...\n```\n\nTo include the `html_url` key for each commit's parents, all we need to do is add `parents.*html_url` into our call to `egrep`:\n```\n▶ ggh | egrep \"(committer.name|commit.message|parents.*html_url)\" | sed -r \"s/(commit|committer)\\.//g\"\njson[0].name = \"Tom Hudson\";\njson[0].message = \"Adds 0.1.7 to changelog\";\njson[0].parents[0].html_url = \"https://github.com/tomnomnom/gron/commit/48aba5325ece087ae24ab72684851cbe77ce8311\";\njson[1].name = \"Tom Hudson\";\njson[1].message = \"Refactors natural sort to actualy work + be more readable\";\njson[1].parents[0].html_url = \"https://github.com/tomnomnom/gron/commit/3eca8bf5e07151f077cebf0d942c1fa8bc51e8f2\";\n...\n```\n\nTo make the structure more like that in the final example in the `jq` tutorial, we can use `sed -r \"s/\\.html_url//\"` to remove the `.html_url` part of the path:\n```\n▶ ggh | egrep \"(committer.name|commit.message|parents.*html_url)\" | sed -r \"s/(commit|committer)\\.//g\" | sed -r \"s/\\.html_url//\"\njson[0].name = \"Tom Hudson\";\njson[0].message = \"Adds 0.1.7 to changelog\";\njson[0].parents[0] = \"https://github.com/tomnomnom/gron/commit/48aba5325ece087ae24ab72684851cbe77ce8311\";\njson[1].name = \"Tom Hudson\";\njson[1].message = \"Refactors natural sort to actualy work + be more readable\";\njson[1].parents[0] = \"https://github.com/tomnomnom/gron/commit/3eca8bf5e07151f077cebf0d942c1fa8bc51e8f2\";\n...\n```\n\nAnd, of course, the statements can be turned back into JSON with `gron --ungron`:\n```\n▶ ggh | egrep \"(committer.name|commit.message|parents.*html_url)\" | sed -r \"s/(commit|committer)\\.//g\" | sed -r \"s/\\.html_url//\" | gron --ungron\n[\n  {\n    \"message\": \"Adds 0.1.7 to changelog\",\n    \"name\": \"Tom Hudson\",\n    \"parents\": [\n      \"https://github.com/tomnomnom/gron/commit/48aba5325ece087ae24ab72684851cbe77ce8311\"\n    ]\n  },\n  {\n    \"message\": \"Refactors natural sort to actualy work + be more readable\",\n    \"name\": \"Tom Hudson\",\n    \"parents\": [\n      \"https://github.com/tomnomnom/gron/commit/3eca8bf5e07151f077cebf0d942c1fa8bc51e8f2\"\n    ]\n  },\n...\n```\n"
        },
        {
          "name": "CHANGELOG.mkd",
          "type": "blob",
          "size": 2.6328125,
          "content": "# Changelog\n\n## 0.6.0\n- Adds `--json`/JSON stream output support (thanks @csabahenk!)\n- Removes trailing newline character for monochrome output (issue #43)\n\n## 0.5.2\n- Built with Go 1.10 to fix issue #32 - Thanks @VladimirAlexiev and @joekyo!\n\n## 0.5.1\n- Fixes bug where empty identifiers would be treated as bare words (thanks for the report, @waltertross!)\n\n## 0.5.0\n- Adds `-k`/`--insecure` to disable validation of certificates when fetching URLs (thanks @jagsta!)\n\n## 0.4.0\n- Adds `-c`/`--colorize` to force colorization of output (thanks @orivej!)\n- Adds `-s`/`--stream` option to read one JSON object per line\n- Native string quoting (performance improvement)\n- Fixes bug with strings ending in a double-slash (issue #25)\n\n## 0.3.7\n- HTML characters (`<`, `>` etc) are no-longer escaped in gron output (issue #22)\n\n## 0.3.6\n- Fixes bug where invalid statements were outputted\n\n## 0.3.5\n- General performance improvements; 5 to 17 times faster (see issue #21 for details)\n\n## 0.3.4\n- Speed improvements when using `--monochrome`\n- Adds `--no-sort` option\n\n## 0.3.3\n- Slightly improved error reporting when ungronning\n- 20 second timeout on HTTP(s) requests (thanks @gummiboll!)\n- Version information added at build time + `--version` option (issue #19)\n\n## 0.3.2\n- Adds handling of `--` lines produced by grep -A etc (issue #15)\n\n## 0.3.1\n- Built with Go 1.7!\n- Up to 25% faster\n- 40% smaller binaries\n\n## 0.3.0\n- Adds colorized gron output\n- Fixes formatting of large ints in ungron output (issue #12)\n\n## 0.2.9\n- Adds colorized ungron output (thanks @nwidger!)\n- Adds 32 bit binaries to releases\n\n## 0.2.8\n- Adds freebsd release binaries\n\n## 0.2.7\n- Fixes bad handling of escape sequences when ungronning - but properly this time (issue #7)\n\n## 0.2.5\n- Fixes bad handling of escape sequences when ungronning (issue #7)\n\n## 0.2.4\n- Fixes handling of large integers (issue #6)\n\n## 0.2.3\n- Switches Windows binary packaging to zip instead of tgz\n\n## 0.2.2\n- Tweaks release automation, no user-facing changes\n\n## 0.2.1\n- Adds windows binary\n\n## 0.2.0\n- Adds [ungronning](README.mkd#ungronning)!\n\n## 0.1.7\n- Fixes sorting of array keys; now uses natural sort\n\n## 0.1.6\n- Adds proper handling of key quoting using Unicode ranges\n- Adds basic benchmarks\n- Adds profiling script\n\n## 0.1.5\n- Adds scripted builds for darwin on amd64\n\n## 0.1.4\n- Minor changes to release script\n\n## 0.1.3\n- Releases are now tarballs\n\n## 0.1.2\n- Underscores no-longer cause keys to be quoted\n- HTTP requests are now done with `Accept: application/json`\n- HTTP requests are now done with `User-Agent: gron/0.1`\n\n## 0.1.1\n- Adds support for fetching URLs directly\n\n## 0.1.0\n- Support for files\n- Support for `stdin`\n\n"
        },
        {
          "name": "CONTRIBUTING.mkd",
          "type": "blob",
          "size": 0.44921875,
          "content": "# Contributing\n\n* Raise an issue if appropriate\n* Fork the repo\n* Make your changes\n* Use [gofmt](https://golang.org/cmd/gofmt/)\n* Make sure the tests pass (run `./script/test`)\n* Make sure the linters pass (run `./script/lint`)\n* Issue a pull request\n\n## Commit Messages\nI'd prefer it if commit messages describe what the *commit does*, not what *you did*.\n\nFor example, I'd prefer:\n\n```\nAdds lint; removes fluff\n```\n\nOver:\n\n```\nAdded lint; removed fluff\n```\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0419921875,
          "content": "MIT License\n\nCopyright (c) 2016 Tom Hudson\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.mkd",
          "type": "blob",
          "size": 6.6826171875,
          "content": "# gron\n[![Build Status](https://travis-ci.org/tomnomnom/gron.svg?branch=master)](https://travis-ci.org/tomnomnom/gron)\n\nMake JSON greppable!\n\ngron transforms JSON into discrete assignments to make it easier to `grep` for what you want and see the absolute 'path' to it.\nIt eases the exploration of APIs that return large blobs of JSON but have terrible documentation.\n\n<pre>\n▶ <b>gron</b> \"https://api.github.com/repos/tomnomnom/gron/commits?per_page=1\" | fgrep \"commit.author\"\njson[0].commit.author = {};\njson[0].commit.author.date = \"2016-07-02T10:51:21Z\";\njson[0].commit.author.email = \"mail@tomnomnom.com\";\njson[0].commit.author.name = \"Tom Hudson\";\n</pre>\n\ngron can work backwards too, enabling you to turn your filtered data back into JSON:\n<pre>\n▶ gron \"https://api.github.com/repos/tomnomnom/gron/commits?per_page=1\" | fgrep \"commit.author\" | <b>gron --ungron</b>\n[\n  {\n    \"commit\": {\n      \"author\": {\n        \"date\": \"2016-07-02T10:51:21Z\",\n        \"email\": \"mail@tomnomnom.com\",\n        \"name\": \"Tom Hudson\"\n      }\n    }\n  }\n]\n</pre>\n\n> Disclaimer: the GitHub API has fantastic documentation, but it makes for a good example.\n\n## Installation\n\ngron has no runtime dependencies. You can just [download a binary for Linux, Mac, Windows or FreeBSD and run it](https://github.com/tomnomnom/gron/releases).\nPut the binary in your `$PATH` (e.g. in `/usr/local/bin`) to make it easy to use:\n```\n▶ tar xzf gron-linux-amd64-0.1.5.tgz\n▶ sudo mv gron /usr/local/bin/\n```\n\nIf you're a Mac user you can also [install gron via brew](http://braumeister.org/formula/gron):\n```\n▶ brew install gron\n```\n\nOr if you're a Go user you can use `go install`:\n\n```\n▶ go install github.com/tomnomnom/gron@latest\n```\n\nIt's recommended that you alias `ungron` or `norg` (or both!) to `gron --ungron`. Put something like this in your shell profile (e.g. in `~/.bashrc`):\n```\nalias norg=\"gron --ungron\"\nalias ungron=\"gron --ungron\"\n```\nOr you could create a shell script in your $PATH named `ungron` or `norg` to affect all users:\n```\ngron --ungron \"$@\"\n```\n\n## Usage\n\nGet JSON from a file:\n\n```\n▶ gron testdata/two.json \njson = {};\njson.contact = {};\njson.contact.email = \"mail@tomnomnom.com\";\njson.contact.twitter = \"@TomNomNom\";\njson.github = \"https://github.com/tomnomnom/\";\njson.likes = [];\njson.likes[0] = \"code\";\njson.likes[1] = \"cheese\";\njson.likes[2] = \"meat\";\njson.name = \"Tom\";\n```\n\nFrom a URL:\n\n```\n▶ gron http://headers.jsontest.com/\njson = {};\njson.Host = \"headers.jsontest.com\";\njson[\"User-Agent\"] = \"gron/0.1\";\njson[\"X-Cloud-Trace-Context\"] = \"6917a823919477919dbc1523584ba25d/11970839830843610056\";\n```\n\nOr from `stdin`:\n\n```\n▶ curl -s http://headers.jsontest.com/ | gron\njson = {};\njson.Accept = \"*/*\";\njson.Host = \"headers.jsontest.com\";\njson[\"User-Agent\"] = \"curl/7.43.0\";\njson[\"X-Cloud-Trace-Context\"] = \"c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147\";\n```\n\nGrep for something and easily see the path to it:\n\n```\n▶ gron testdata/two.json | grep twitter\njson.contact.twitter = \"@TomNomNom\";\n```\n\ngron makes diffing JSON easy too:\n\n```\n▶ diff <(gron two.json) <(gron two-b.json)\n3c3\n< json.contact.email = \"mail@tomnomnom.com\";\n---\n> json.contact.email = \"contact@tomnomnom.com\";\n```\n\nThe output of `gron` is valid JavaScript:\n\n```\n▶ gron testdata/two.json > tmp.js\n▶ echo \"console.log(json);\" >> tmp.js\n▶ nodejs tmp.js\n{ contact: { email: 'mail@tomnomnom.com', twitter: '@TomNomNom' },\n  github: 'https://github.com/tomnomnom/',\n  likes: [ 'code', 'cheese', 'meat' ],\n  name: 'Tom' }\n```\n\nIt's also possible to obtain the `gron` output as JSON stream via\nthe `--json` switch:\n\n```\n▶ curl -s http://headers.jsontest.com/ | gron --json\n[[],{}]\n[[\"Accept\"],\"*/*\"]\n[[\"Host\"],\"headers.jsontest.com\"]\n[[\"User-Agent\"],\"curl/7.43.0\"]\n[[\"X-Cloud-Trace-Context\"],\"c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147\"]\n```\n\n## ungronning\ngron can also turn its output back into JSON:\n```\n▶ gron testdata/two.json | gron -u\n{\n  \"contact\": {\n    \"email\": \"mail@tomnomnom.com\",\n    \"twitter\": \"@TomNomNom\"\n  },\n  \"github\": \"https://github.com/tomnomnom/\",\n  \"likes\": [\n    \"code\",\n    \"cheese\",\n    \"meat\"\n  ],\n  \"name\": \"Tom\"\n}\n```\n\nThis means you use can use gron with `grep` and other tools to modify JSON:\n```\n▶ gron testdata/two.json | grep likes | gron --ungron\n{\n  \"likes\": [\n    \"code\",\n    \"cheese\",\n    \"meat\"\n  ]\n}\n```\n\nor\n\n\n```\n▶ gron --json testdata/two.json | grep likes | gron  --json --ungron\n{\n  \"likes\": [\n    \"code\",\n    \"cheese\",\n    \"meat\"\n  ]\n}\n```\n\nTo preserve array keys, arrays are padded with `null` when values are missing:\n```\n▶ gron testdata/two.json | grep likes | grep -v cheese\njson.likes = [];\njson.likes[0] = \"code\";\njson.likes[2] = \"meat\";\n▶ gron testdata/two.json | grep likes | grep -v cheese | gron --ungron\n{\n  \"likes\": [\n    \"code\",\n    null,\n    \"meat\"\n  ]\n}\n```\n\nIf you get creative you can do [some pretty neat tricks with gron](ADVANCED.mkd), and\nthen ungron the output back into JSON.\n\n## Get Help\n\n```\n▶ gron --help\nTransform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable\n\nUsage:\n  gron [OPTIONS] [FILE|URL|-]\n\nOptions:\n  -u, --ungron     Reverse the operation (turn assignments back into JSON)\n  -v, --values     Print just the values of provided assignments\n  -c, --colorize   Colorize output (default on tty)\n  -m, --monochrome Monochrome (don't colorize output)\n  -s, --stream     Treat each line of input as a separate JSON object\n  -k, --insecure   Disable certificate validation\n  -j, --json       Represent gron data as JSON stream\n      --no-sort    Don't sort output (faster)\n      --version    Print version information\n\nExit Codes:\n  0\tOK\n  1\tFailed to open file\n  2\tFailed to read input\n  3\tFailed to form statements\n  4\tFailed to fetch URL\n  5\tFailed to parse statements\n  6\tFailed to encode JSON\n\nExamples:\n  gron /tmp/apiresponse.json\n  gron http://jsonplaceholder.typicode.com/users/1 \n  curl -s http://jsonplaceholder.typicode.com/users/1 | gron\n  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron\n```\n\n## FAQ\n### Wasn't this written in PHP before?\nYes it was! The original version is [preserved here for posterity](https://github.com/tomnomnom/gron/blob/master/original-gron.php).\n\n### Why the change to Go?\nMostly to remove PHP as a dependency. There's a lot of people who work with JSON who don't have PHP installed.\n\n### Why shouldn't I just use jq?\n[jq](https://stedolan.github.io/jq/) is *awesome*, and a lot more powerful than gron, but with that power comes\ncomplexity. gron aims to make it easier to use the tools you already know, like `grep` and `sed`.\n\ngron's primary purpose is to make it easy to find the path to a value in a deeply nested JSON blob\nwhen you don't already know the structure; much of jq's power is unlocked only once you know that structure.\n"
        },
        {
          "name": "completions",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.28515625,
          "content": "module github.com/tomnomnom/gron\n\ngo 1.15\n\nrequire (\n\tgithub.com/fatih/color v1.18.0\n\tgithub.com/mattn/go-colorable v0.1.13\n\tgithub.com/nwidger/jsoncolor v0.3.2\n\tgithub.com/pkg/errors v0.9.1\n)\n\nrequire (\n\tgithub.com/mattn/go-isatty v0.0.20 // indirect\n\tgolang.org/x/sys v0.27.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.88671875,
          "content": "github.com/fatih/color v1.9.0/go.mod h1:eQcE1qtQxscV5RaZvpXrrb8Drkc3/DdQ+uUYCNjL+zU=\ngithub.com/fatih/color v1.18.0 h1:S8gINlzdQ840/4pfAwic/ZE0djQEH3wM94VfqLTZcOM=\ngithub.com/fatih/color v1.18.0/go.mod h1:4FelSpRwEGDpQ12mAdzqdOukCy4u8WUtOY6lkT/6HfU=\ngithub.com/mattn/go-colorable v0.1.4/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=\ngithub.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=\ngithub.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=\ngithub.com/mattn/go-isatty v0.0.8/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.11/go.mod h1:PhnuNfih5lzO57/f3n+odYbM4JtupLOxQOAqxQCu2WE=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/nwidger/jsoncolor v0.3.2 h1:rVJJlwAWDJShnbTYOQ5RM7yTA20INyKXlJ/fg4JMhHQ=\ngithub.com/nwidger/jsoncolor v0.3.2/go.mod h1:Cs34umxLbJvgBMnVNVqhji9BhoT/N/KinHqZptQ7cf4=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngolang.org/x/sys v0.0.0-20190222072716-a9d3bda3a223/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20191026070338-33540a1f6037/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.25.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.27.0 h1:wBqf8DvsY9Y/2P8gAfPDEYNuS30J4lPHJxXSb/nJZ+s=\ngolang.org/x/sys v0.27.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\n"
        },
        {
          "name": "identifier.go",
          "type": "blob",
          "size": 1.853515625,
          "content": "package main\n\nimport \"unicode\"\n\n// The javascript reserved words cannot be used as unquoted keys\nvar reservedWords = map[string]bool{\n\t\"break\":      true,\n\t\"case\":       true,\n\t\"catch\":      true,\n\t\"class\":      true,\n\t\"const\":      true,\n\t\"continue\":   true,\n\t\"debugger\":   true,\n\t\"default\":    true,\n\t\"delete\":     true,\n\t\"do\":         true,\n\t\"else\":       true,\n\t\"export\":     true,\n\t\"extends\":    true,\n\t\"false\":      true,\n\t\"finally\":    true,\n\t\"for\":        true,\n\t\"function\":   true,\n\t\"if\":         true,\n\t\"import\":     true,\n\t\"in\":         true,\n\t\"instanceof\": true,\n\t\"new\":        true,\n\t\"null\":       true,\n\t\"return\":     true,\n\t\"super\":      true,\n\t\"switch\":     true,\n\t\"this\":       true,\n\t\"throw\":      true,\n\t\"true\":       true,\n\t\"try\":        true,\n\t\"typeof\":     true,\n\t\"var\":        true,\n\t\"void\":       true,\n\t\"while\":      true,\n\t\"with\":       true,\n\t\"yield\":      true,\n}\n\n// validIdentifier checks to see if a string is a valid\n// JavaScript identifier\n// E.g:\n//     justLettersAndNumbers1 -> true\n//     a key with spaces      -> false\n//     1startsWithANumber\t  -> false\nfunc validIdentifier(s string) bool {\n\tif reservedWords[s] || s == \"\" {\n\t\treturn false\n\t}\n\n\tfor i, r := range s {\n\t\tif i == 0 && !validFirstRune(r) {\n\t\t\treturn false\n\t\t}\n\t\tif i != 0 && !validSecondaryRune(r) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\n// validFirstRune returns true for runes that are valid\n// as the first rune in an identifier.\n// E.g:\n//     'r' -> true\n//     '7' -> false\nfunc validFirstRune(r rune) bool {\n\treturn unicode.In(r,\n\t\tunicode.Lu,\n\t\tunicode.Ll,\n\t\tunicode.Lm,\n\t\tunicode.Lo,\n\t\tunicode.Nl,\n\t) || r == '$' || r == '_'\n}\n\n// validSecondaryRune returns true for runes that are valid\n// as anything other than the first rune in an identifier.\nfunc validSecondaryRune(r rune) bool {\n\treturn validFirstRune(r) ||\n\t\tunicode.In(r, unicode.Mn, unicode.Mc, unicode.Nd, unicode.Pc)\n}\n"
        },
        {
          "name": "identifier_test.go",
          "type": "blob",
          "size": 1.619140625,
          "content": "package main\n\nimport \"testing\"\n\nfunc TestValidIdentifier(t *testing.T) {\n\ttests := []struct {\n\t\tkey  string\n\t\twant bool\n\t}{\n\t\t// Valid Identifiers\n\t\t{\"dotted\", true},\n\t\t{\"dotted123\", true},\n\t\t{\"_under_scores\", true},\n\t\t{\"ಠ_ಠ\", true},\n\n\t\t// Invalid chars\n\t\t{\"is-quoted\", false},\n\t\t{\"Definitely quoted!\", false},\n\n\t\t// Reserved words\n\t\t{\"true\", false},\n\t\t{\"else\", false},\n\t\t{\"null\", false},\n\n\t\t// Empty string\n\t\t{\"\", false},\n\t}\n\n\tfor _, test := range tests {\n\t\thave := validIdentifier(test.key)\n\t\tif have != test.want {\n\t\t\tt.Errorf(\"Want %t for validIdentifier(%s); have %t\", test.want, test.key, have)\n\t\t}\n\t}\n}\n\nfunc TestValidFirstRune(t *testing.T) {\n\ttests := []struct {\n\t\tin   rune\n\t\twant bool\n\t}{\n\t\t{'r', true},\n\t\t{'ಠ', true},\n\t\t{'4', false},\n\t\t{'-', false},\n\t}\n\n\tfor _, test := range tests {\n\t\thave := validFirstRune(test.in)\n\t\tif have != test.want {\n\t\t\tt.Errorf(\"Want %t for validFirstRune(%#U); have %t\", test.want, test.in, have)\n\t\t}\n\t}\n}\n\nfunc TestValidSecondaryRune(t *testing.T) {\n\ttests := []struct {\n\t\tin   rune\n\t\twant bool\n\t}{\n\t\t{'r', true},\n\t\t{'ಠ', true},\n\t\t{'4', true},\n\t\t{'-', false},\n\t}\n\n\tfor _, test := range tests {\n\t\thave := validSecondaryRune(test.in)\n\t\tif have != test.want {\n\t\t\tt.Errorf(\"Want %t for validSecondaryRune(%#U); have %t\", test.want, test.in, have)\n\t\t}\n\t}\n}\n\nfunc BenchmarkValidIdentifier(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tvalidIdentifier(\"must-be-quoted\")\n\t}\n}\n\nfunc BenchmarkValidIdentifierUnquoted(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tvalidIdentifier(\"canbeunquoted\")\n\t}\n}\n\nfunc BenchmarkValidIdentifierReserved(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tvalidIdentifier(\"function\")\n\t}\n}\n"
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 11.318359375,
          "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/fatih/color\"\n\t\"github.com/mattn/go-colorable\"\n\t\"github.com/nwidger/jsoncolor\"\n\t\"github.com/pkg/errors\"\n)\n\n// Exit codes\nconst (\n\texitOK = iota\n\texitOpenFile\n\texitReadInput\n\texitFormStatements\n\texitFetchURL\n\texitParseStatements\n\texitJSONEncode\n)\n\n// Option bitfields\nconst (\n\toptMonochrome = 1 << iota\n\toptNoSort\n\toptJSON\n)\n\n// Output colors\nvar (\n\tstrColor   = color.New(color.FgYellow)\n\tbraceColor = color.New(color.FgMagenta)\n\tbareColor  = color.New(color.FgBlue, color.Bold)\n\tnumColor   = color.New(color.FgRed)\n\tboolColor  = color.New(color.FgCyan)\n)\n\n// gronVersion stores the current gron version, set at build\n// time with the ldflags -X option\nvar gronVersion = \"dev\"\n\nfunc init() {\n\tflag.Usage = func() {\n\t\th := \"Transform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable\\n\\n\"\n\n\t\th += \"Usage:\\n\"\n\t\th += \"  gron [OPTIONS] [FILE|URL|-]\\n\\n\"\n\n\t\th += \"Options:\\n\"\n\t\th += \"  -u, --ungron     Reverse the operation (turn assignments back into JSON)\\n\"\n\t\th += \"  -v, --values     Print just the values of provided assignments\\n\"\n\t\th += \"  -c, --colorize   Colorize output (default on tty)\\n\"\n\t\th += \"  -m, --monochrome Monochrome (don't colorize output)\\n\"\n\t\th += \"  -s, --stream     Treat each line of input as a separate JSON object\\n\"\n\t\th += \"  -k, --insecure   Disable certificate validation\\n\"\n\t\th += \"  -j, --json       Represent gron data as JSON stream\\n\"\n\t\th += \"      --no-sort    Don't sort output (faster)\\n\"\n\t\th += \"      --version    Print version information\\n\\n\"\n\n\t\th += \"Exit Codes:\\n\"\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitOK, \"OK\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitOpenFile, \"Failed to open file\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitReadInput, \"Failed to read input\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitFormStatements, \"Failed to form statements\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitFetchURL, \"Failed to fetch URL\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitParseStatements, \"Failed to parse statements\")\n\t\th += fmt.Sprintf(\"  %d\\t%s\\n\", exitJSONEncode, \"Failed to encode JSON\")\n\t\th += \"\\n\"\n\n\t\th += \"Examples:\\n\"\n\t\th += \"  gron /tmp/apiresponse.json\\n\"\n\t\th += \"  gron http://jsonplaceholder.typicode.com/users/1 \\n\"\n\t\th += \"  curl -s http://jsonplaceholder.typicode.com/users/1 | gron\\n\"\n\t\th += \"  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron\\n\"\n\n\t\tfmt.Fprintf(os.Stderr, h)\n\t}\n}\n\nfunc main() {\n\tvar (\n\t\tungronFlag     bool\n\t\tcolorizeFlag   bool\n\t\tmonochromeFlag bool\n\t\tstreamFlag     bool\n\t\tnoSortFlag     bool\n\t\tversionFlag    bool\n\t\tinsecureFlag   bool\n\t\tjsonFlag       bool\n\t\tvaluesFlag     bool\n\t)\n\n\tflag.BoolVar(&ungronFlag, \"ungron\", false, \"\")\n\tflag.BoolVar(&ungronFlag, \"u\", false, \"\")\n\tflag.BoolVar(&colorizeFlag, \"colorize\", false, \"\")\n\tflag.BoolVar(&colorizeFlag, \"c\", false, \"\")\n\tflag.BoolVar(&monochromeFlag, \"monochrome\", false, \"\")\n\tflag.BoolVar(&monochromeFlag, \"m\", false, \"\")\n\tflag.BoolVar(&streamFlag, \"s\", false, \"\")\n\tflag.BoolVar(&streamFlag, \"stream\", false, \"\")\n\tflag.BoolVar(&noSortFlag, \"no-sort\", false, \"\")\n\tflag.BoolVar(&versionFlag, \"version\", false, \"\")\n\tflag.BoolVar(&insecureFlag, \"k\", false, \"\")\n\tflag.BoolVar(&insecureFlag, \"insecure\", false, \"\")\n\tflag.BoolVar(&jsonFlag, \"j\", false, \"\")\n\tflag.BoolVar(&jsonFlag, \"json\", false, \"\")\n\tflag.BoolVar(&valuesFlag, \"values\", false, \"\")\n\tflag.BoolVar(&valuesFlag, \"value\", false, \"\")\n\tflag.BoolVar(&valuesFlag, \"v\", false, \"\")\n\n\tflag.Parse()\n\n\t// Print version information\n\tif versionFlag {\n\t\tfmt.Printf(\"gron version %s\\n\", gronVersion)\n\t\tos.Exit(exitOK)\n\t}\n\n\t// If executed as 'ungron' set the --ungron flag\n\tif strings.HasSuffix(os.Args[0], \"ungron\") {\n\t\tungronFlag = true\n\t}\n\n\t// Determine what the program's input should be:\n\t// file, HTTP URL or stdin\n\tvar rawInput io.Reader\n\tfilename := flag.Arg(0)\n\tif filename == \"\" || filename == \"-\" {\n\t\trawInput = os.Stdin\n\t} else if validURL(filename) {\n\t\tr, err := getURL(filename, insecureFlag)\n\t\tif err != nil {\n\t\t\tfatal(exitFetchURL, err)\n\t\t}\n\t\trawInput = r\n\t} else {\n\t\tr, err := os.Open(filename)\n\t\tif err != nil {\n\t\t\tfatal(exitOpenFile, err)\n\t\t}\n\t\trawInput = r\n\t}\n\n\tvar opts int\n\t// The monochrome option should be forced if the output isn't a terminal\n\t// to avoid doing unnecessary work calling the color functions\n\tswitch {\n\tcase colorizeFlag:\n\t\tcolor.NoColor = false\n\tcase monochromeFlag || color.NoColor:\n\t\topts = opts | optMonochrome\n\t}\n\tif noSortFlag {\n\t\topts = opts | optNoSort\n\t}\n\tif jsonFlag {\n\t\topts = opts | optJSON\n\t}\n\n\t// Pick the appropriate action: gron, ungron, gronValues, or gronStream\n\tvar a actionFn = gron\n\tif ungronFlag {\n\t\ta = ungron\n\t} else if valuesFlag {\n\t\ta = gronValues\n\t} else if streamFlag {\n\t\ta = gronStream\n\t}\n\texitCode, err := a(rawInput, colorable.NewColorableStdout(), opts)\n\n\tif exitCode != exitOK {\n\t\tfatal(exitCode, err)\n\t}\n\n\tos.Exit(exitOK)\n}\n\n// an actionFn represents a main action of the program, it accepts\n// an input, output and a bitfield of options; returning an exit\n// code and any error that occurred\ntype actionFn func(io.Reader, io.Writer, int) (int, error)\n\n// gron is the default action. Given JSON as the input it returns a list\n// of assignment statements. Possible options are optNoSort and optMonochrome\nfunc gron(r io.Reader, w io.Writer, opts int) (int, error) {\n\tvar err error\n\n\tvar conv statementconv\n\tif opts&optMonochrome > 0 {\n\t\tconv = statementToString\n\t} else {\n\t\tconv = statementToColorString\n\t}\n\n\tss, err := statementsFromJSON(r, statement{{\"json\", typBare}})\n\tif err != nil {\n\t\tgoto out\n\t}\n\n\t// Go's maps do not have well-defined ordering, but we want a consistent\n\t// output for a given input, so we must sort the statements\n\tif opts&optNoSort == 0 {\n\t\tsort.Sort(ss)\n\t}\n\n\tfor _, s := range ss {\n\t\tif opts&optJSON > 0 {\n\t\t\ts, err = s.jsonify()\n\t\t\tif err != nil {\n\t\t\t\tgoto out\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, conv(s))\n\t}\n\nout:\n\tif err != nil {\n\t\treturn exitFormStatements, fmt.Errorf(\"failed to form statements: %s\", err)\n\t}\n\treturn exitOK, nil\n}\n\n// gronStream is like the gron action, but it treats the input as one\n// JSON object per line. There's a bit of code duplication from the\n// gron action, but it'd be fairly messy to combine the two actions\nfunc gronStream(r io.Reader, w io.Writer, opts int) (int, error) {\n\tvar err error\n\terrstr := \"failed to form statements\"\n\tvar i int\n\tvar sc *bufio.Scanner\n\tvar buf []byte\n\n\tvar conv func(s statement) string\n\tif opts&optMonochrome > 0 {\n\t\tconv = statementToString\n\t} else {\n\t\tconv = statementToColorString\n\t}\n\n\t// Helper function to make the prefix statements for each line\n\tmakePrefix := func(index int) statement {\n\t\treturn statement{\n\t\t\t{\"json\", typBare},\n\t\t\t{\"[\", typLBrace},\n\t\t\t{fmt.Sprintf(\"%d\", index), typNumericKey},\n\t\t\t{\"]\", typRBrace},\n\t\t}\n\t}\n\n\t// The first line of output needs to establish that the top-level\n\t// thing is actually an array...\n\ttop := statement{\n\t\t{\"json\", typBare},\n\t\t{\"=\", typEquals},\n\t\t{\"[]\", typEmptyArray},\n\t\t{\";\", typSemi},\n\t}\n\n\tif opts&optJSON > 0 {\n\t\ttop, err = top.jsonify()\n\t\tif err != nil {\n\t\t\tgoto out\n\t\t}\n\t}\n\n\tfmt.Fprintln(w, conv(top))\n\n\t// Read the input line by line\n\tsc = bufio.NewScanner(r)\n\tbuf = make([]byte, 0, 64*1024)\n\tsc.Buffer(buf, 1024*1024)\n\ti = 0\n\tfor sc.Scan() {\n\n\t\tline := bytes.NewBuffer(sc.Bytes())\n\n\t\tvar ss statements\n\t\tss, err = statementsFromJSON(line, makePrefix(i))\n\t\ti++\n\t\tif err != nil {\n\t\t\tgoto out\n\t\t}\n\n\t\t// Go's maps do not have well-defined ordering, but we want a consistent\n\t\t// output for a given input, so we must sort the statements\n\t\tif opts&optNoSort == 0 {\n\t\t\tsort.Sort(ss)\n\t\t}\n\n\t\tfor _, s := range ss {\n\t\t\tif opts&optJSON > 0 {\n\t\t\t\ts, err = s.jsonify()\n\t\t\t\tif err != nil {\n\t\t\t\t\tgoto out\n\t\t\t\t}\n\n\t\t\t}\n\t\t\tfmt.Fprintln(w, conv(s))\n\t\t}\n\t}\n\tif err = sc.Err(); err != nil {\n\t\terrstr = \"error reading multiline input: %s\"\n\t}\n\nout:\n\tif err != nil {\n\t\treturn exitFormStatements, fmt.Errorf(errstr+\": %s\", err)\n\t}\n\treturn exitOK, nil\n\n}\n\n// ungron is the reverse of gron. Given assignment statements as input,\n// it returns JSON. The only option is optMonochrome\nfunc ungron(r io.Reader, w io.Writer, opts int) (int, error) {\n\tscanner := bufio.NewScanner(r)\n\tvar maker statementmaker\n\n\t// Allow larger internal buffer of the scanner (min: 64KiB ~ max: 1MiB)\n\tscanner.Buffer(make([]byte, 64*1024), 1024*1024)\n\n\tif opts&optJSON > 0 {\n\t\tmaker = statementFromJSONSpec\n\t} else {\n\t\tmaker = statementFromStringMaker\n\t}\n\n\t// Make a list of statements from the input\n\tvar ss statements\n\tfor scanner.Scan() {\n\t\ts, err := maker(scanner.Text())\n\t\tif err != nil {\n\t\t\treturn exitParseStatements, err\n\t\t}\n\t\tss.add(s)\n\t}\n\tif err := scanner.Err(); err != nil {\n\t\treturn exitReadInput, fmt.Errorf(\"failed to read input statements\")\n\t}\n\n\t// turn the statements into a single merged interface{} type\n\tmerged, err := ss.toInterface()\n\tif err != nil {\n\t\treturn exitParseStatements, err\n\t}\n\n\t// If there's only one top level key and it's \"json\", make that the top level thing\n\tmergedMap, ok := merged.(map[string]interface{})\n\tif ok {\n\t\tif len(mergedMap) == 1 {\n\t\t\tif _, exists := mergedMap[\"json\"]; exists {\n\t\t\t\tmerged = mergedMap[\"json\"]\n\t\t\t}\n\t\t}\n\t}\n\n\t// Marshal the output into JSON to display to the user\n\tout := &bytes.Buffer{}\n\tenc := json.NewEncoder(out)\n\tenc.SetIndent(\"\", \"  \")\n\tenc.SetEscapeHTML(false)\n\terr = enc.Encode(merged)\n\tif err != nil {\n\t\treturn exitJSONEncode, errors.Wrap(err, \"failed to convert statements to JSON\")\n\t}\n\tj := out.Bytes()\n\n\t// If the output isn't monochrome, add color to the JSON\n\tif opts&optMonochrome == 0 {\n\t\tc, err := colorizeJSON(j)\n\n\t\t// If we failed to colorize the JSON for whatever reason,\n\t\t// we'll just fall back to monochrome output, otherwise\n\t\t// replace the monochrome JSON with glorious technicolor\n\t\tif err == nil {\n\t\t\tj = c\n\t\t}\n\t}\n\n\t// For whatever reason, the monochrome version of the JSON\n\t// has a trailing newline character, but the colorized version\n\t// does not. Strip the whitespace so that neither has the newline\n\t// character on the end, and then we'll add a newline in the\n\t// Fprintf below\n\tj = bytes.TrimSpace(j)\n\n\tfmt.Fprintf(w, \"%s\\n\", j)\n\n\treturn exitOK, nil\n}\n\n// gronValues prints just the scalar values from some input gron statements\n// without any quotes or anything of that sort; a bit like jq -r\n// e.g. json[0].user.name = \"Sam\"; -> Sam\nfunc gronValues(r io.Reader, w io.Writer, opts int) (int, error) {\n\tscanner := bufio.NewScanner(os.Stdin)\n\n\tfor scanner.Scan() {\n\t\ts := statementFromString(scanner.Text())\n\n\t\t// strip off the leading 'json' bare key\n\t\tif s[0].typ == typBare && s[0].text == \"json\" {\n\t\t\ts = s[1:]\n\t\t}\n\n\t\t// strip off the leading dots\n\t\tif s[0].typ == typDot || s[0].typ == typLBrace {\n\t\t\ts = s[1:]\n\t\t}\n\n\t\tfor _, t := range s {\n\t\t\tswitch t.typ {\n\t\t\tcase typString:\n\t\t\t\tvar text string\n\t\t\t\terr := json.Unmarshal([]byte(t.text), &text)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// just swallow errors and try to continue\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfmt.Println(text)\n\n\t\t\tcase typNumber, typTrue, typFalse, typNull:\n\t\t\t\tfmt.Println(t.text)\n\n\t\t\tdefault:\n\t\t\t\t// Nothing\n\t\t\t}\n\t\t}\n\t}\n\n\treturn exitOK, nil\n}\n\nfunc colorizeJSON(src []byte) ([]byte, error) {\n\tout := &bytes.Buffer{}\n\tf := jsoncolor.NewFormatter()\n\n\tf.StringColor = strColor\n\tf.ObjectColor = braceColor\n\tf.ArrayColor = braceColor\n\tf.FieldColor = bareColor\n\tf.NumberColor = numColor\n\tf.TrueColor = boolColor\n\tf.FalseColor = boolColor\n\tf.NullColor = boolColor\n\n\terr := f.Format(out, src)\n\tif err != nil {\n\t\treturn out.Bytes(), err\n\t}\n\treturn out.Bytes(), nil\n}\n\nfunc fatal(code int, err error) {\n\tfmt.Fprintf(os.Stderr, \"%s\\n\", err)\n\tos.Exit(code)\n}\n"
        },
        {
          "name": "main_test.go",
          "type": "blob",
          "size": 7.3046875,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"reflect\"\n\t\"testing\"\n)\n\nfunc TestGron(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/one.json\", \"testdata/one.gron\"},\n\t\t{\"testdata/two.json\", \"testdata/two.gron\"},\n\t\t{\"testdata/three.json\", \"testdata/three.gron\"},\n\t\t{\"testdata/github.json\", \"testdata/github.gron\"},\n\t}\n\n\tfor _, c := range cases {\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\twant, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := gron(in, out, optMonochrome)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, out.Bytes()) {\n\t\t\tt.Logf(\"want: %s\", want)\n\t\t\tt.Logf(\"have: %s\", out.Bytes())\n\t\t\tt.Errorf(\"gronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\t}\n\n}\n\nfunc TestGronStream(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/stream.json\", \"testdata/stream.gron\"},\n\t\t{\"testdata/scalar-stream.json\", \"testdata/scalar-stream.gron\"},\n\t}\n\n\tfor _, c := range cases {\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\twant, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := gronStream(in, out, optMonochrome)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, out.Bytes()) {\n\t\t\tt.Logf(\"want: %s\", want)\n\t\t\tt.Logf(\"have: %s\", out.Bytes())\n\t\t\tt.Errorf(\"gronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\t}\n\n}\n\nfunc TestLargeGronStream(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/long-stream.json\", \"testdata/long-stream.gron\"},\n\t}\n\n\tfor _, c := range cases {\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\twant, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := gronStream(in, out, optMonochrome)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, out.Bytes()) {\n\t\t\tt.Logf(\"want: %s\", want)\n\t\t\tt.Logf(\"have: %s\", out.Bytes())\n\t\t\tt.Errorf(\"gronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\t}\n\n}\n\nfunc TestUngron(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/one.gron\", \"testdata/one.json\"},\n\t\t{\"testdata/two.gron\", \"testdata/two.json\"},\n\t\t{\"testdata/three.gron\", \"testdata/three.json\"},\n\t\t{\"testdata/grep-separators.gron\", \"testdata/grep-separators.json\"},\n\t\t{\"testdata/github.gron\", \"testdata/github.json\"},\n\t\t{\"testdata/large-line.gron\", \"testdata/large-line.json\"},\n\t}\n\n\tfor _, c := range cases {\n\t\twantF, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tvar want interface{}\n\t\terr = json.Unmarshal(wantF, &want)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to unmarshal JSON from want file: %s\", err)\n\t\t}\n\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := ungron(in, out, optMonochrome)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tvar have interface{}\n\t\terr = json.Unmarshal(out.Bytes(), &have)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to unmarshal JSON from ungron output: %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, have) {\n\t\t\tt.Logf(\"want: %#v\", want)\n\t\t\tt.Logf(\"have: %#v\", have)\n\t\t\tt.Errorf(\"ungronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\n\t}\n}\n\nfunc TestGronJ(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/one.json\", \"testdata/one.jgron\"},\n\t\t{\"testdata/two.json\", \"testdata/two.jgron\"},\n\t\t{\"testdata/three.json\", \"testdata/three.jgron\"},\n\t\t{\"testdata/github.json\", \"testdata/github.jgron\"},\n\t}\n\n\tfor _, c := range cases {\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\twant, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := gron(in, out, optMonochrome|optJSON)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, out.Bytes()) {\n\t\t\tt.Logf(\"want: %s\", want)\n\t\t\tt.Logf(\"have: %s\", out.Bytes())\n\t\t\tt.Errorf(\"gronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\t}\n\n}\n\nfunc TestGronStreamJ(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/stream.json\", \"testdata/stream.jgron\"},\n\t\t{\"testdata/scalar-stream.json\", \"testdata/scalar-stream.jgron\"},\n\t}\n\n\tfor _, c := range cases {\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\twant, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := gronStream(in, out, optMonochrome|optJSON)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, out.Bytes()) {\n\t\t\tt.Logf(\"want: %s\", want)\n\t\t\tt.Logf(\"have: %s\", out.Bytes())\n\t\t\tt.Errorf(\"gronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\t}\n\n}\n\nfunc TestUngronJ(t *testing.T) {\n\tcases := []struct {\n\t\tinFile  string\n\t\toutFile string\n\t}{\n\t\t{\"testdata/one.jgron\", \"testdata/one.json\"},\n\t\t{\"testdata/two.jgron\", \"testdata/two.json\"},\n\t\t{\"testdata/three.jgron\", \"testdata/three.json\"},\n\t\t{\"testdata/github.jgron\", \"testdata/github.json\"},\n\t}\n\n\tfor _, c := range cases {\n\t\twantF, err := ioutil.ReadFile(c.outFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open want file: %s\", err)\n\t\t}\n\n\t\tvar want interface{}\n\t\terr = json.Unmarshal(wantF, &want)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to unmarshal JSON from want file: %s\", err)\n\t\t}\n\n\t\tin, err := os.Open(c.inFile)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open input file: %s\", err)\n\t\t}\n\n\t\tout := &bytes.Buffer{}\n\t\tcode, err := ungron(in, out, optMonochrome|optJSON)\n\n\t\tif code != exitOK {\n\t\t\tt.Errorf(\"want exitOK; have %d\", code)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"want nil error; have %s\", err)\n\t\t}\n\n\t\tvar have interface{}\n\t\terr = json.Unmarshal(out.Bytes(), &have)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to unmarshal JSON from ungron output: %s\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(want, have) {\n\t\t\tt.Logf(\"want: %#v\", want)\n\t\t\tt.Logf(\"have: %#v\", have)\n\t\t\tt.Errorf(\"ungronned %s does not match %s\", c.inFile, c.outFile)\n\t\t}\n\n\t}\n}\n\nfunc BenchmarkBigJSON(b *testing.B) {\n\tin, err := os.Open(\"testdata/big.json\")\n\tif err != nil {\n\t\tb.Fatalf(\"failed to open test data file: %s\", err)\n\t}\n\n\tfor i := 0; i < b.N; i++ {\n\t\tout := &bytes.Buffer{}\n\t\t_, err = in.Seek(0, 0)\n\t\tif err != nil {\n\t\t\tb.Fatalf(\"failed to rewind input: %s\", err)\n\t\t}\n\n\t\t_, err := gron(in, out, optMonochrome|optNoSort)\n\t\tif err != nil {\n\t\t\tb.Fatalf(\"failed to gron: %s\", err)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "original-gron.php",
          "type": "blob",
          "size": 2.2294921875,
          "content": "#!/usr/bin/env php\n<?php\n//////////\n// Gron //\n//////////\n\n// Take valid JSON on stdin, or read it from a file or URL,\n// then output it as discrete assignments to make it grep-able.\n\n// Exit codes:\n//   0 - Success\n//   1 - Failed to decode JSON\n//   2 - Argument is not valid file or URL\n//   3 - Failed to fetch data from URL\n\n// Tom Hudson - 2012\n// https://github.com/TomNomNom/gron \n\n// Decide on stdin, a local file or URL\nif ($argc == 1){\n  $buffer = file_get_contents('php://stdin');\n\n} else {\n  $source = $argv[1];\n\n  // Check for a readable file or URL \n  if (is_readable($source)){\n    $buffer = file_get_contents($source);\n\n  } else if (filter_var($source, FILTER_VALIDATE_URL)){\n    $c = curl_init($source);\n    curl_setopt($c, CURLOPT_RETURNTRANSFER, true);\n    curl_setopt($c, CURLOPT_FOLLOWLOCATION, true);\n    curl_setopt($c, CURLOPT_TIMEOUT, 20);\n    curl_setopt($c, CURLOPT_HTTPHEADER, array(\n      'Accept: application/json'\n    ));\n\n    $buffer = curl_exec($c);\n    $err    = curl_errno($c);\n    curl_close($c);\n\n    if ($err != CURLE_OK){\n      fputs(STDERR, \"Data could not be fetched from [{$source}]\\n\");\n      exit(3);\n    }\n\n  } else {\n    fputs(STDERR, \"[{$source}] is not a valid file or URL.\\n\");\n    exit(2);\n  }\n}\n\n// Meat\n$struct = json_decode($buffer);\n$err = json_last_error();\n\nif ($err != JSON_ERROR_NONE){\n  // Attempt to read as multiple lines of JSON (sometimes found in streaming APIs etc)\n  $lines = explode(\"\\n\", trim($buffer));\n  for ($i = 0; $i < sizeOf($lines); $i++){\n\n    $line = $lines[$i];\n    $struct = json_decode($line);\n    $err = json_last_error();\n\n    // No dice; time to die\n    if ($err != JSON_ERROR_NONE){\n      fputs(STDERR, \"Failed to decode JSON\\n\");\n      exit(1);\n    }\n\n    printSruct($struct, \"json{$i}\");\n    echo PHP_EOL;\n  }\n} else {\n  // Buffer is all one JSON blob\n  printSruct($struct);\n}\n\nfunction printSruct($struct, $prefix = 'json'){\n  if (is_object($struct)){\n    echo \"{$prefix} = {};\\n\";\n  } elseif (is_array($struct)){\n    echo \"{$prefix} = [];\\n\";\n  } else {\n    echo \"{$prefix} = \". json_encode($struct) .\";\\n\";\n\n    // No need to iterate if we already have a scalar\n    return;\n  }\n\n  foreach ($struct as $k => $v){\n    $k = json_encode($k);\n    printSruct($v, \"{$prefix}[{$k}]\");\n  }\n}\n\nexit(0);\n"
        },
        {
          "name": "script",
          "type": "tree",
          "content": null
        },
        {
          "name": "statements.go",
          "type": "blob",
          "size": 10.009765625,
          "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/pkg/errors\"\n)\n\n// A statement is a slice of tokens representing an assignment statement.\n// An assignment statement is something like:\n//\n//   json.city = \"Leeds\";\n//\n// Where 'json', '.', 'city', '=', '\"Leeds\"' and ';' are discrete tokens.\n// Statements are stored as tokens to make sorting more efficient, and so\n// that the same type can easily be used when gronning and ungronning.\ntype statement []token\n\n// String returns the string form of a statement rather than the\n// underlying slice of tokens\nfunc (s statement) String() string {\n\tout := make([]string, 0, len(s)+2)\n\tfor _, t := range s {\n\t\tout = append(out, t.format())\n\t}\n\treturn strings.Join(out, \"\")\n}\n\n// colorString returns the string form of a statement with ASCII color codes\nfunc (s statement) colorString() string {\n\tout := make([]string, 0, len(s)+2)\n\tfor _, t := range s {\n\t\tout = append(out, t.formatColor())\n\t}\n\treturn strings.Join(out, \"\")\n}\n\n// a statementconv converts a statement to string\ntype statementconv func(s statement) string\n\n// statementconv variant of statement.String\nfunc statementToString(s statement) string {\n\treturn s.String()\n}\n\n// statementconv variant of statement.colorString\nfunc statementToColorString(s statement) string {\n\treturn s.colorString()\n}\n\n// withBare returns a copy of a statement with a new bare\n// word token appended to it\nfunc (s statement) withBare(k string) statement {\n\tnew := make(statement, len(s), len(s)+2)\n\tcopy(new, s)\n\treturn append(\n\t\tnew,\n\t\ttoken{\".\", typDot},\n\t\ttoken{k, typBare},\n\t)\n}\n\n// jsonify converts an assignment statement to a JSON representation\nfunc (s statement) jsonify() (statement, error) {\n\t// If m is the number of keys occurring in the left hand side\n\t// of s, then len(s) is in between 2*m+4 and 3*m+4. The resultant\n\t// statement j (carrying the JSON representation) is always 2*m+5\n\t// long. So len(s)+1 ≥ 2*m+5 = len(j). Therefore an initaial\n\t// allocation of j with capacity len(s)+1 will allow us to carry\n\t// through without reallocation.\n\tj := make(statement, 0, len(s)+1)\n\tif len(s) < 4 || s[0].typ != typBare || s[len(s)-3].typ != typEquals ||\n\t\ts[len(s)-1].typ != typSemi {\n\t\treturn nil, errors.New(\"non-assignment statement\")\n\t}\n\n\tj = append(j, token{\"[\", typLBrace})\n\tj = append(j, token{\"[\", typLBrace})\n\tfor _, t := range s[1 : len(s)-3] {\n\t\tswitch t.typ {\n\t\tcase typNumericKey, typQuotedKey:\n\t\t\tj = append(j, t)\n\t\t\tj = append(j, token{\",\", typComma})\n\t\tcase typBare:\n\t\t\tj = append(j, token{quoteString(t.text), typQuotedKey})\n\t\t\tj = append(j, token{\",\", typComma})\n\t\t}\n\t}\n\tif j[len(j)-1].typ == typComma {\n\t\tj = j[:len(j)-1]\n\t}\n\tj = append(j, token{\"]\", typLBrace})\n\tj = append(j, token{\",\", typComma})\n\tj = append(j, s[len(s)-2])\n\tj = append(j, token{\"]\", typLBrace})\n\n\treturn j, nil\n}\n\n// withQuotedKey returns a copy of a statement with a new\n// quoted key token appended to it\nfunc (s statement) withQuotedKey(k string) statement {\n\tnew := make(statement, len(s), len(s)+3)\n\tcopy(new, s)\n\treturn append(\n\t\tnew,\n\t\ttoken{\"[\", typLBrace},\n\t\ttoken{quoteString(k), typQuotedKey},\n\t\ttoken{\"]\", typRBrace},\n\t)\n}\n\n// withNumericKey returns a copy of a statement with a new\n// numeric key token appended to it\nfunc (s statement) withNumericKey(k int) statement {\n\tnew := make(statement, len(s), len(s)+3)\n\tcopy(new, s)\n\treturn append(\n\t\tnew,\n\t\ttoken{\"[\", typLBrace},\n\t\ttoken{strconv.Itoa(k), typNumericKey},\n\t\ttoken{\"]\", typRBrace},\n\t)\n}\n\n// statements is a list of assignment statements.\n// E.g statement: json.foo = \"bar\";\ntype statements []statement\n\n// addWithValue takes a statement representing a path, copies it,\n// adds a value token to the end of the statement and appends\n// the new statement to the list of statements\nfunc (ss *statements) addWithValue(path statement, value token) {\n\ts := make(statement, len(path), len(path)+3)\n\tcopy(s, path)\n\ts = append(s, token{\"=\", typEquals}, value, token{\";\", typSemi})\n\t*ss = append(*ss, s)\n}\n\n// add appends a new complete statement to list of statements\nfunc (ss *statements) add(s statement) {\n\t*ss = append(*ss, s)\n}\n\n// Len returns the number of statements for sort.Sort\nfunc (ss statements) Len() int {\n\treturn len(ss)\n}\n\n// Swap swaps two statements for sort.Sort\nfunc (ss statements) Swap(i, j int) {\n\tss[i], ss[j] = ss[j], ss[i]\n}\n\n// a statementmaker is a function that makes a statement\n// from string\ntype statementmaker func(str string) (statement, error)\n\n// statementFromString takes statement string, lexes it and returns\n// the corresponding statement\nfunc statementFromString(str string) statement {\n\tl := newLexer(str)\n\ts := l.lex()\n\treturn s\n}\n\n// statementmaker variant of statementFromString\nfunc statementFromStringMaker(str string) (statement, error) {\n\treturn statementFromString(str), nil\n}\n\n// statementFromJson returns statement encoded by\n// JSON specification\nfunc statementFromJSONSpec(str string) (statement, error) {\n\tvar a []interface{}\n\tvar ok bool\n\tvar v interface{}\n\tvar s statement\n\tvar t tokenTyp\n\tvar nstr string\n\tvar nbuf []byte\n\n\terr := json.Unmarshal([]byte(str), &a)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(a) != 2 {\n\t\tgoto out\n\t}\n\n\tv = a[1]\n\ta, ok = a[0].([]interface{})\n\tif !ok {\n\t\tgoto out\n\t}\n\n\t// We'll append one initial token, then 3 tokens for each element of a,\n\t// then 3 closing tokens, that's alltogether 3*len(a)+4.\n\ts = make(statement, 0, 3*len(a)+4)\n\ts = append(s, token{\"json\", typBare})\n\tfor _, e := range a {\n\t\ts = append(s, token{\"[\", typLBrace})\n\t\tswitch e := e.(type) {\n\t\tcase string:\n\t\t\ts = append(s, token{quoteString(e), typQuotedKey})\n\t\tcase float64:\n\t\t\tnbuf, err = json.Marshal(e)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"JSON internal error\")\n\t\t\t}\n\t\t\tnstr = fmt.Sprintf(\"%s\", nbuf)\n\t\t\ts = append(s, token{nstr, typNumericKey})\n\t\tdefault:\n\t\t\tok = false\n\t\t\tgoto out\n\t\t}\n\t\ts = append(s, token{\"]\", typRBrace})\n\t}\n\n\ts = append(s, token{\"=\", typEquals})\n\n\tswitch v := v.(type) {\n\tcase bool:\n\t\tif v {\n\t\t\tt = typTrue\n\t\t} else {\n\t\t\tt = typFalse\n\t\t}\n\tcase float64:\n\t\tt = typNumber\n\tcase string:\n\t\tt = typString\n\tcase []interface{}:\n\t\tok = (len(v) == 0)\n\t\tif !ok {\n\t\t\tgoto out\n\t\t}\n\t\tt = typEmptyArray\n\tcase map[string]interface{}:\n\t\tok = (len(v) == 0)\n\t\tif !ok {\n\t\t\tgoto out\n\t\t}\n\t\tt = typEmptyObject\n\tdefault:\n\t\tok = (v == nil)\n\t\tif !ok {\n\t\t\tgoto out\n\t\t}\n\t\tt = typNull\n\t}\n\n\tnbuf, err = json.Marshal(v)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"JSON internal error\")\n\t}\n\tnstr = fmt.Sprintf(\"%s\", nbuf)\n\ts = append(s, token{nstr, t})\n\n\ts = append(s, token{\";\", typSemi})\n\nout:\n\tif !ok {\n\t\treturn nil, errors.New(\"invalid JSON layout\")\n\t}\n\treturn s, nil\n}\n\n// ungron turns statements into a proper datastructure\nfunc (ss statements) toInterface() (interface{}, error) {\n\n\t// Get all the individually parsed statements\n\tvar parsed []interface{}\n\tfor _, s := range ss {\n\t\tu, err := ungronTokens(s)\n\n\t\tswitch err.(type) {\n\t\tcase nil:\n\t\t\t// no problem :)\n\t\tcase errRecoverable:\n\t\t\tcontinue\n\t\tdefault:\n\t\t\treturn nil, errors.Wrapf(err, \"ungron failed for `%s`\", s)\n\t\t}\n\n\t\tparsed = append(parsed, u)\n\t}\n\n\tif len(parsed) == 0 {\n\t\treturn nil, fmt.Errorf(\"no statements were parsed\")\n\t}\n\n\tmerged := parsed[0]\n\tfor _, p := range parsed[1:] {\n\t\tm, err := recursiveMerge(merged, p)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to merge statements\")\n\t\t}\n\t\tmerged = m\n\t}\n\treturn merged, nil\n\n}\n\n// Less compares two statements for sort.Sort\n// Implements a natural sort to keep array indexes in order\nfunc (ss statements) Less(a, b int) bool {\n\n\t// ss[a] and ss[b] are both slices of tokens. The first\n\t// thing we need to do is find the first token (if any)\n\t// that differs, then we can use that token to decide\n\t// if ss[a] or ss[b] should come first in the sort.\n\tdiffIndex := -1\n\tfor i := range ss[a] {\n\n\t\tif len(ss[b]) < i+1 {\n\t\t\t// b must be shorter than a, so it\n\t\t\t// should come first\n\t\t\treturn false\n\t\t}\n\n\t\t// The tokens match, so just carry on\n\t\tif ss[a][i] == ss[b][i] {\n\t\t\tcontinue\n\t\t}\n\n\t\t// We've found a difference\n\t\tdiffIndex = i\n\t\tbreak\n\t}\n\n\t// If diffIndex is still -1 then the only difference must be\n\t// that ss[b] is longer than ss[a], so ss[a] should come first\n\tif diffIndex == -1 {\n\t\treturn true\n\t}\n\n\t// Get the tokens that differ\n\tta := ss[a][diffIndex]\n\ttb := ss[b][diffIndex]\n\n\t// An equals always comes first\n\tif ta.typ == typEquals {\n\t\treturn true\n\t}\n\tif tb.typ == typEquals {\n\t\treturn false\n\t}\n\n\t// If both tokens are numeric keys do an integer comparison\n\tif ta.typ == typNumericKey && tb.typ == typNumericKey {\n\t\tia, _ := strconv.Atoi(ta.text)\n\t\tib, _ := strconv.Atoi(tb.text)\n\t\treturn ia < ib\n\t}\n\n\t// If neither token is a number, just do a string comparison\n\tif ta.typ != typNumber || tb.typ != typNumber {\n\t\treturn ta.text < tb.text\n\t}\n\n\t// We have two numbers to compare so turn them into json.Number\n\t// for comparison\n\tna, _ := json.Number(ta.text).Float64()\n\tnb, _ := json.Number(tb.text).Float64()\n\treturn na < nb\n\n}\n\n// Contains searches the statements for a given statement\n// Mostly to make testing things easier\nfunc (ss statements) Contains(search statement) bool {\n\tfor _, i := range ss {\n\t\tif reflect.DeepEqual(i, search) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// statementsFromJSON takes an io.Reader containing JSON\n// and returns statements or an error on failure\nfunc statementsFromJSON(r io.Reader, prefix statement) (statements, error) {\n\tvar top interface{}\n\td := json.NewDecoder(r)\n\td.UseNumber()\n\terr := d.Decode(&top)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tss := make(statements, 0, 32)\n\tss.fill(prefix, top)\n\treturn ss, nil\n}\n\n// fill takes a prefix statement and some value and recursively fills\n// the statement list using that value\nfunc (ss *statements) fill(prefix statement, v interface{}) {\n\n\t// Add a statement for the current prefix and value\n\tss.addWithValue(prefix, valueTokenFromInterface(v))\n\n\t// Recurse into objects and arrays\n\tswitch vv := v.(type) {\n\n\tcase map[string]interface{}:\n\t\t// It's an object\n\t\tfor k, sub := range vv {\n\t\t\tif validIdentifier(k) {\n\t\t\t\tss.fill(prefix.withBare(k), sub)\n\t\t\t} else {\n\t\t\t\tss.fill(prefix.withQuotedKey(k), sub)\n\t\t\t}\n\t\t}\n\n\tcase []interface{}:\n\t\t// It's an array\n\t\tfor k, sub := range vv {\n\t\t\tss.fill(prefix.withNumericKey(k), sub)\n\t\t}\n\t}\n\n}\n"
        },
        {
          "name": "statements_test.go",
          "type": "blob",
          "size": 4.09765625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"reflect\"\n\t\"sort\"\n\t\"testing\"\n)\n\nfunc statementsFromStringSlice(strs []string) statements {\n\tss := make(statements, len(strs))\n\tfor i, str := range strs {\n\t\tss[i] = statementFromString(str)\n\t}\n\treturn ss\n}\n\nfunc TestStatementsSimple(t *testing.T) {\n\n\tj := []byte(`{\n\t\t\"dotted\": \"A dotted value\",\n\t\t\"a quoted\": \"value\",\n\t\t\"bool1\": true,\n\t\t\"bool2\": false,\n\t\t\"anull\": null,\n\t\t\"anarr\": [1, 1.5],\n\t\t\"anob\": {\n\t\t\t\"foo\": \"bar\"\n\t\t},\n\t\t\"else\": 1,\n\t\t\"id\": 66912849,\n\t\t\"\": 2\n\t}`)\n\n\tss, err := statementsFromJSON(bytes.NewReader(j), statement{{\"json\", typBare}})\n\n\tif err != nil {\n\t\tt.Errorf(\"Want nil error from makeStatementsFromJSON() but got %s\", err)\n\t}\n\n\twants := statementsFromStringSlice([]string{\n\t\t`json = {};`,\n\t\t`json.dotted = \"A dotted value\";`,\n\t\t`json[\"a quoted\"] = \"value\";`,\n\t\t`json.bool1 = true;`,\n\t\t`json.bool2 = false;`,\n\t\t`json.anull = null;`,\n\t\t`json.anarr = [];`,\n\t\t`json.anarr[0] = 1;`,\n\t\t`json.anarr[1] = 1.5;`,\n\t\t`json.anob = {};`,\n\t\t`json.anob.foo = \"bar\";`,\n\t\t`json[\"else\"] = 1;`,\n\t\t`json.id = 66912849;`,\n\t\t`json[\"\"] = 2;`,\n\t})\n\n\tt.Logf(\"Have: %#v\", ss)\n\tfor _, want := range wants {\n\t\tif !ss.Contains(want) {\n\t\t\tt.Errorf(\"Statement group should contain `%s` but doesn't\", want)\n\t\t}\n\t}\n\n}\n\nfunc TestStatementsSorting(t *testing.T) {\n\twant := statementsFromStringSlice([]string{\n\t\t`json.a = true;`,\n\t\t`json.b = true;`,\n\t\t`json.c[0] = true;`,\n\t\t`json.c[2] = true;`,\n\t\t`json.c[10] = true;`,\n\t\t`json.c[11] = true;`,\n\t\t`json.c[21][2] = true;`,\n\t\t`json.c[21][11] = true;`,\n\t})\n\n\thave := statementsFromStringSlice([]string{\n\t\t`json.c[11] = true;`,\n\t\t`json.c[21][2] = true;`,\n\t\t`json.c[0] = true;`,\n\t\t`json.c[2] = true;`,\n\t\t`json.b = true;`,\n\t\t`json.c[10] = true;`,\n\t\t`json.c[21][11] = true;`,\n\t\t`json.a = true;`,\n\t})\n\n\tsort.Sort(have)\n\n\tfor i := range want {\n\t\tif !reflect.DeepEqual(have[i], want[i]) {\n\t\t\tt.Errorf(\"Statements sorted incorrectly; want `%s` at index %d, have `%s`\", want[i], i, have[i])\n\t\t}\n\t}\n}\n\nfunc BenchmarkStatementsLess(b *testing.B) {\n\tss := statementsFromStringSlice([]string{\n\t\t`json.c[21][2] = true;`,\n\t\t`json.c[21][11] = true;`,\n\t})\n\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = ss.Less(0, 1)\n\t}\n}\n\nfunc BenchmarkFill(b *testing.B) {\n\tj := []byte(`{\n\t\t\"dotted\": \"A dotted value\",\n\t\t\"a quoted\": \"value\",\n\t\t\"bool1\": true,\n\t\t\"bool2\": false,\n\t\t\"anull\": null,\n\t\t\"anarr\": [1, 1.5],\n\t\t\"anob\": {\n\t\t\t\"foo\": \"bar\"\n\t\t},\n\t\t\"else\": 1\n\t}`)\n\n\tvar top interface{}\n\terr := json.Unmarshal(j, &top)\n\tif err != nil {\n\t\tb.Fatalf(\"Failed to unmarshal test file: %s\", err)\n\t}\n\n\tfor i := 0; i < b.N; i++ {\n\t\tss := make(statements, 0)\n\t\tss.fill(statement{{\"json\", typBare}}, top)\n\t}\n}\n\nfunc TestUngronStatementsSimple(t *testing.T) {\n\tin := statementsFromStringSlice([]string{\n\t\t`json.contact = {};`,\n\t\t`json.contact[\"e-mail\"][0] = \"mail@tomnomnom.com\";`,\n\t\t`json.contact[\"e-mail\"][1] = \"test@tomnomnom.com\";`,\n\t\t`json.contact[\"e-mail\"][3] = \"foo@tomnomnom.com\";`,\n\t\t`json.contact.twitter = \"@TomNomNom\";`,\n\t})\n\n\twant := map[string]interface{}{\n\t\t\"json\": map[string]interface{}{\n\t\t\t\"contact\": map[string]interface{}{\n\t\t\t\t\"e-mail\": []interface{}{\n\t\t\t\t\t0: \"mail@tomnomnom.com\",\n\t\t\t\t\t1: \"test@tomnomnom.com\",\n\t\t\t\t\t3: \"foo@tomnomnom.com\",\n\t\t\t\t},\n\t\t\t\t\"twitter\": \"@TomNomNom\",\n\t\t\t},\n\t\t},\n\t}\n\n\thave, err := in.toInterface()\n\n\tif err != nil {\n\t\tt.Fatalf(\"want nil error but have: %s\", err)\n\t}\n\n\tt.Logf(\"Have: %#v\", have)\n\tt.Logf(\"Want: %#v\", want)\n\n\teq := reflect.DeepEqual(have, want)\n\tif !eq {\n\t\tt.Errorf(\"have and want are not equal\")\n\t}\n}\n\nfunc TestUngronStatementsInvalid(t *testing.T) {\n\tcases := []statements{\n\t\tstatementsFromStringSlice([]string{``}),\n\t\tstatementsFromStringSlice([]string{`this isn't a statement at all`}),\n\t\tstatementsFromStringSlice([]string{`json[0] = 1;`, `json.bar = 1;`}),\n\t}\n\n\tfor _, c := range cases {\n\t\t_, err := c.toInterface()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"want non-nil error; have nil\")\n\t\t}\n\t}\n}\n\nfunc TestStatement(t *testing.T) {\n\ts := statement{\n\t\ttoken{\"json\", typBare},\n\t\ttoken{\".\", typDot},\n\t\ttoken{\"foo\", typBare},\n\t\ttoken{\"=\", typEquals},\n\t\ttoken{\"2\", typNumber},\n\t\ttoken{\";\", typSemi},\n\t}\n\n\thave := s.String()\n\twant := \"json.foo = 2;\"\n\tif have != want {\n\t\tt.Errorf(\"have: `%s` want: `%s`\", have, want)\n\t}\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "token.go",
          "type": "blob",
          "size": 4.140625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"unicode\"\n)\n\n// A token is a chunk of text from a statement with a type\ntype token struct {\n\ttext string\n\ttyp  tokenTyp\n}\n\n// A tokenTyp identifies what kind of token something is\ntype tokenTyp int\n\nconst (\n\t// A bare word is a unquoted key; like 'foo' in json.foo = 1;\n\ttypBare tokenTyp = iota\n\n\t// Numeric key; like '2' in json[2] = \"foo\";\n\ttypNumericKey\n\n\t// A quoted key; like 'foo bar' in json[\"foo bar\"] = 2;\n\ttypQuotedKey\n\n\t// Punctuation types\n\ttypDot    // .\n\ttypLBrace // [\n\ttypRBrace // ]\n\ttypEquals // =\n\ttypSemi   // ;\n\ttypComma  // ,\n\n\t// Value types\n\ttypString      // \"foo\"\n\ttypNumber      // 4\n\ttypTrue        // true\n\ttypFalse       // false\n\ttypNull        // null\n\ttypEmptyArray  // []\n\ttypEmptyObject // {}\n\n\t// Ignored token\n\ttypIgnored\n\n\t// Error token\n\ttypError\n)\n\n// a sprintFn adds color to its input\ntype sprintFn func(...interface{}) string\n\n// mapping of token types to the appropriate color sprintFn\nvar sprintFns = map[tokenTyp]sprintFn{\n\ttypBare:        bareColor.SprintFunc(),\n\ttypNumericKey:  numColor.SprintFunc(),\n\ttypQuotedKey:   strColor.SprintFunc(),\n\ttypLBrace:      braceColor.SprintFunc(),\n\ttypRBrace:      braceColor.SprintFunc(),\n\ttypString:      strColor.SprintFunc(),\n\ttypNumber:      numColor.SprintFunc(),\n\ttypTrue:        boolColor.SprintFunc(),\n\ttypFalse:       boolColor.SprintFunc(),\n\ttypNull:        boolColor.SprintFunc(),\n\ttypEmptyArray:  braceColor.SprintFunc(),\n\ttypEmptyObject: braceColor.SprintFunc(),\n}\n\n// isValue returns true if the token is a valid value type\nfunc (t token) isValue() bool {\n\tswitch t.typ {\n\tcase typString, typNumber, typTrue, typFalse, typNull, typEmptyArray, typEmptyObject:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// isPunct returns true if the token is a punctuation type\nfunc (t token) isPunct() bool {\n\tswitch t.typ {\n\tcase typDot, typLBrace, typRBrace, typEquals, typSemi, typComma:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// format returns the formatted version of the token text\nfunc (t token) format() string {\n\tif t.typ == typEquals {\n\t\treturn \" \" + t.text + \" \"\n\t}\n\treturn t.text\n}\n\n// formatColor returns the colored formatted version of the token text\nfunc (t token) formatColor() string {\n\ttext := t.text\n\tif t.typ == typEquals {\n\t\ttext = \" \" + text + \" \"\n\t}\n\tfn, ok := sprintFns[t.typ]\n\tif ok {\n\t\treturn fn(text)\n\t}\n\treturn text\n\n}\n\n// valueTokenFromInterface takes any valid value and\n// returns a value token to represent it\nfunc valueTokenFromInterface(v interface{}) token {\n\tswitch vv := v.(type) {\n\n\tcase map[string]interface{}:\n\t\treturn token{\"{}\", typEmptyObject}\n\tcase []interface{}:\n\t\treturn token{\"[]\", typEmptyArray}\n\tcase json.Number:\n\t\treturn token{vv.String(), typNumber}\n\tcase string:\n\t\treturn token{quoteString(vv), typString}\n\tcase bool:\n\t\tif vv {\n\t\t\treturn token{\"true\", typTrue}\n\t\t}\n\t\treturn token{\"false\", typFalse}\n\tcase nil:\n\t\treturn token{\"null\", typNull}\n\tdefault:\n\t\treturn token{\"\", typError}\n\t}\n}\n\n// quoteString takes a string and returns a quoted and\n// escaped string valid for use in gron output\nfunc quoteString(s string) string {\n\n\tout := &bytes.Buffer{}\n\t// bytes.Buffer never returns errors on these methods.\n\t// errors are explicitly ignored to keep the linter\n\t// happy. A price worth paying so that the linter\n\t// remains useful.\n\t_ = out.WriteByte('\"')\n\n\tfor _, r := range s {\n\t\tswitch r {\n\t\tcase '\\\\':\n\t\t\t_, _ = out.WriteString(`\\\\`)\n\t\tcase '\"':\n\t\t\t_, _ = out.WriteString(`\\\"`)\n\t\tcase '\\b':\n\t\t\t_, _ = out.WriteString(`\\b`)\n\t\tcase '\\f':\n\t\t\t_, _ = out.WriteString(`\\f`)\n\t\tcase '\\n':\n\t\t\t_, _ = out.WriteString(`\\n`)\n\t\tcase '\\r':\n\t\t\t_, _ = out.WriteString(`\\r`)\n\t\tcase '\\t':\n\t\t\t_, _ = out.WriteString(`\\t`)\n\t\t// \\u2028 and \\u2029 are separator runes that are not valid\n\t\t// in javascript strings so they must be escaped.\n\t\t// See http://timelessrepo.com/json-isnt-a-javascript-subset\n\t\tcase '\\u2028':\n\t\t\t_, _ = out.WriteString(`\\u2028`)\n\t\tcase '\\u2029':\n\t\t\t_, _ = out.WriteString(`\\u2029`)\n\t\tdefault:\n\t\t\t// Any other control runes must be escaped\n\t\t\tif unicode.IsControl(r) {\n\t\t\t\t_, _ = fmt.Fprintf(out, `\\u%04X`, r)\n\t\t\t} else {\n\t\t\t\t// Unescaped rune\n\t\t\t\t_, _ = out.WriteRune(r)\n\t\t\t}\n\t\t}\n\t}\n\n\t_ = out.WriteByte('\"')\n\treturn out.String()\n\n}\n"
        },
        {
          "name": "token_test.go",
          "type": "blob",
          "size": 1.19921875,
          "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nvar cases = []struct {\n\tin   interface{}\n\twant token\n}{\n\t{make(map[string]interface{}), token{\"{}\", typEmptyObject}},\n\t{make([]interface{}, 0), token{\"[]\", typEmptyArray}},\n\t{json.Number(\"1.2\"), token{\"1.2\", typNumber}},\n\t{\"foo\", token{`\"foo\"`, typString}},\n\t{\"<3\", token{`\"<3\"`, typString}},\n\t{\"&\", token{`\"&\"`, typString}},\n\t{\"\\b\", token{`\"\\b\"`, typString}},\n\t{\"\\f\", token{`\"\\f\"`, typString}},\n\t{\"\\n\", token{`\"\\n\"`, typString}},\n\t{\"\\r\", token{`\"\\r\"`, typString}},\n\t{\"\\t\", token{`\"\\t\"`, typString}},\n\t{\"wat \\u001e\", token{`\"wat \\u001E\"`, typString}},\n\t{\"Hello, 世界\", token{`\"Hello, 世界\"`, typString}},\n\t{true, token{\"true\", typTrue}},\n\t{false, token{\"false\", typFalse}},\n\t{nil, token{\"null\", typNull}},\n\t{struct{}{}, token{\"\", typError}},\n}\n\nfunc TestValueTokenFromInterface(t *testing.T) {\n\n\tfor _, c := range cases {\n\t\thave := valueTokenFromInterface(c.in)\n\n\t\tif have != c.want {\n\t\t\tt.Logf(\"input: %#v\", have)\n\t\t\tt.Logf(\"have: %#v\", have)\n\t\t\tt.Logf(\"want: %#v\", c.want)\n\t\t\tt.Errorf(\"have != want\")\n\t\t}\n\t}\n}\n\nfunc BenchmarkValueTokenFromInterface(b *testing.B) {\n\n\tfor i := 0; i < b.N; i++ {\n\t\tfor _, c := range cases {\n\t\t\t_ = valueTokenFromInterface(c.in)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "ungron.go",
          "type": "blob",
          "size": 10.93359375,
          "content": "// Ungronning is the reverse of gronning: turn statements\n// back into JSON. The expected input grammar is:\n//\n//   Input ::= '--'* Statement (Statement | '--')*\n//   Statement ::= Path Space* \"=\" Space* Value \";\" \"\\n\"\n//   Path ::= (BareWord) (\".\" BareWord | (\"[\" Key \"]\"))*\n//   Value ::= String | Number | \"true\" | \"false\" | \"null\" | \"[]\" | \"{}\"\n//   BareWord ::= (UnicodeLu | UnicodeLl | UnicodeLm | UnicodeLo | UnicodeNl | '$' | '_') (UnicodeLu | UnicodeLl | UnicodeLm | UnicodeLo | UnicodeNl | UnicodeMn | UnicodeMc | UnicodeNd | UnicodePc | '$' | '_')*\n//   Key ::= [0-9]+ | String\n//   String ::= '\"' (UnescapedRune | (\"\\\" ([\"\\/bfnrt] | ('u' Hex))))* '\"'\n//   UnescapedRune ::= [^#x0-#x1f\"\\]\n\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n\t\"unicode\"\n\t\"unicode/utf8\"\n\n\t\"github.com/pkg/errors\"\n)\n\n// errRecoverable is an error type to represent errors that\n// can be recovered from; e.g. an empty line in the input\ntype errRecoverable struct {\n\tmsg string\n}\n\nfunc (e errRecoverable) Error() string {\n\treturn e.msg\n}\n\n// A lexer holds the state for lexing statements\ntype lexer struct {\n\ttext       string  // The raw input text\n\tpos        int     // The current byte offset in the text\n\twidth      int     // The width of the current rune in bytes\n\tcur        rune    // The rune at the current position\n\tprev       rune    // The rune at the previous position\n\ttokens     []token // The tokens that have been emitted\n\ttokenStart int     // The starting position of the current token\n}\n\n// newLexer returns a new lexer for the provided input string\nfunc newLexer(text string) *lexer {\n\treturn &lexer{\n\t\ttext:       text,\n\t\tpos:        0,\n\t\ttokenStart: 0,\n\t\ttokens:     make([]token, 0),\n\t}\n}\n\n// lex runs the lexer and returns the lexed statement\nfunc (l *lexer) lex() statement {\n\n\tfor lexfn := lexStatement; lexfn != nil; {\n\t\tlexfn = lexfn(l)\n\t}\n\treturn l.tokens\n}\n\n// next gets the next rune in the input and updates the lexer state\nfunc (l *lexer) next() rune {\n\tr, w := utf8.DecodeRuneInString(l.text[l.pos:])\n\n\tl.pos += w\n\tl.width = w\n\n\tl.prev = l.cur\n\tl.cur = r\n\n\treturn r\n}\n\n// backup moves the lexer back one rune\n// can only be used once per call of next()\nfunc (l *lexer) backup() {\n\tl.pos -= l.width\n}\n\n// peek returns the next rune in the input\n// without moving the internal pointer\nfunc (l *lexer) peek() rune {\n\tr := l.next()\n\tl.backup()\n\treturn r\n}\n\n// ignore skips the current token\nfunc (l *lexer) ignore() {\n\tl.tokenStart = l.pos\n}\n\n// emit adds the current token to the token slice and\n// moves the tokenStart pointer to the current position\nfunc (l *lexer) emit(typ tokenTyp) {\n\tt := token{\n\t\ttext: l.text[l.tokenStart:l.pos],\n\t\ttyp:  typ,\n\t}\n\tl.tokenStart = l.pos\n\n\tl.tokens = append(l.tokens, t)\n}\n\n// accept moves the pointer if the next rune is in\n// the set of valid runes\nfunc (l *lexer) accept(valid string) bool {\n\tif strings.ContainsRune(valid, l.next()) {\n\t\treturn true\n\t}\n\tl.backup()\n\treturn false\n}\n\n// acceptRun continually accepts runes from the\n// set of valid runes\nfunc (l *lexer) acceptRun(valid string) {\n\tfor strings.ContainsRune(valid, l.next()) {\n\t}\n\tl.backup()\n}\n\n// a runeCheck is a function that determines if a rune is valid\n// or not so that we can do complex checks against runes\ntype runeCheck func(rune) bool\n\n// acceptFunc accepts a rune if the provided runeCheck\n// function returns true\nfunc (l *lexer) acceptFunc(fn runeCheck) bool {\n\tif fn(l.next()) {\n\t\treturn true\n\t}\n\tl.backup()\n\treturn false\n}\n\n// acceptRunFunc continually accepts runes for as long\n// as the runeCheck function returns true\nfunc (l *lexer) acceptRunFunc(fn runeCheck) {\n\tfor fn(l.next()) {\n\t}\n\tl.backup()\n}\n\n// acceptUntil accepts runes until it hits a delimiter\n// rune contained in the provided string\nfunc (l *lexer) acceptUntil(delims string) {\n\tfor !strings.ContainsRune(delims, l.next()) {\n\t\tif l.cur == utf8.RuneError {\n\t\t\treturn\n\t\t}\n\t}\n\tl.backup()\n}\n\n// acceptUntilUnescaped accepts runes until it hits a delimiter\n// rune contained in the provided string, unless that rune was\n// escaped with a backslash\nfunc (l *lexer) acceptUntilUnescaped(delims string) {\n\n\t// Read until we hit an unescaped rune or the end of the input\n\tinEscape := false\n\tfor {\n\t\tr := l.next()\n\t\tif r == '\\\\' && !inEscape {\n\t\t\tinEscape = true\n\t\t\tcontinue\n\t\t}\n\t\tif strings.ContainsRune(delims, r) && !inEscape {\n\t\t\tl.backup()\n\t\t\treturn\n\t\t}\n\t\tif l.cur == utf8.RuneError {\n\t\t\treturn\n\t\t}\n\t\tinEscape = false\n\t}\n}\n\n// a lexFn accepts a lexer, performs some action on it and\n// then returns an appropriate lexFn for the next stage\ntype lexFn func(*lexer) lexFn\n\n// lexStatement is the highest level lexFn. Its only job\n// is to determine which more specific lexFn to use\nfunc lexStatement(l *lexer) lexFn {\n\tr := l.peek()\n\n\tswitch {\n\tcase r == '.' || validFirstRune(r):\n\t\treturn lexBareWord\n\tcase r == '[':\n\t\treturn lexBraces\n\tcase r == ' ', r == '=':\n\t\treturn lexValue\n\tcase r == '-':\n\t\t// grep -A etc can add '--' lines to output\n\t\t// we'll save the text but not actually do\n\t\t// anything with them\n\t\treturn lexIgnore\n\tcase r == utf8.RuneError:\n\t\treturn nil\n\tdefault:\n\t\tl.emit(typError)\n\t\treturn nil\n\t}\n\n}\n\n// lexBareWord lexes for bare identifiers.\n// E.g: the 'foo' in 'foo.bar' or 'foo[0]' is a bare identifier\nfunc lexBareWord(l *lexer) lexFn {\n\tif l.accept(\".\") {\n\t\tl.emit(typDot)\n\t}\n\n\tif !l.acceptFunc(validFirstRune) {\n\t\tl.emit(typError)\n\t\treturn nil\n\t}\n\tl.acceptRunFunc(validSecondaryRune)\n\tl.emit(typBare)\n\n\treturn lexStatement\n}\n\n// lexBraces lexes keys contained within square braces\nfunc lexBraces(l *lexer) lexFn {\n\tl.accept(\"[\")\n\tl.emit(typLBrace)\n\n\tswitch {\n\tcase unicode.IsNumber(l.peek()):\n\t\treturn lexNumericKey\n\tcase l.peek() == '\"':\n\t\treturn lexQuotedKey\n\tdefault:\n\t\tl.emit(typError)\n\t\treturn nil\n\t}\n}\n\n// lexNumericKey lexes numeric keys between square braces\nfunc lexNumericKey(l *lexer) lexFn {\n\tl.accept(\"[\")\n\tl.ignore()\n\n\tl.acceptRunFunc(unicode.IsNumber)\n\tl.emit(typNumericKey)\n\n\tif l.accept(\"]\") {\n\t\tl.emit(typRBrace)\n\t} else {\n\t\tl.emit(typError)\n\t\treturn nil\n\t}\n\tl.ignore()\n\treturn lexStatement\n}\n\n// lexQuotedKey lexes quoted keys between square braces\nfunc lexQuotedKey(l *lexer) lexFn {\n\tl.accept(\"[\")\n\tl.ignore()\n\n\tl.accept(`\"`)\n\n\tl.acceptUntilUnescaped(`\"`)\n\tl.accept(`\"`)\n\tl.emit(typQuotedKey)\n\n\tif l.accept(\"]\") {\n\t\tl.emit(typRBrace)\n\t} else {\n\t\tl.emit(typError)\n\t\treturn nil\n\t}\n\tl.ignore()\n\treturn lexStatement\n}\n\n// lexValue lexes a value at the end of a statement\nfunc lexValue(l *lexer) lexFn {\n\tl.acceptRun(\" \")\n\tl.ignore()\n\n\tif l.accept(\"=\") {\n\t\tl.emit(typEquals)\n\t} else {\n\t\treturn nil\n\t}\n\tl.acceptRun(\" \")\n\tl.ignore()\n\n\tswitch {\n\n\tcase l.accept(`\"`):\n\t\tl.acceptUntilUnescaped(`\"`)\n\t\tl.accept(`\"`)\n\t\tl.emit(typString)\n\n\tcase l.accept(\"t\"):\n\t\tl.acceptRun(\"rue\")\n\t\tl.emit(typTrue)\n\n\tcase l.accept(\"f\"):\n\t\tl.acceptRun(\"alse\")\n\t\tl.emit(typFalse)\n\n\tcase l.accept(\"n\"):\n\t\tl.acceptRun(\"ul\")\n\t\tl.emit(typNull)\n\n\tcase l.accept(\"[\"):\n\t\tl.accept(\"]\")\n\t\tl.emit(typEmptyArray)\n\n\tcase l.accept(\"{\"):\n\t\tl.accept(\"}\")\n\t\tl.emit(typEmptyObject)\n\n\tdefault:\n\t\t// Assume number\n\t\tl.acceptUntil(\";\")\n\t\tl.emit(typNumber)\n\t}\n\n\tl.acceptRun(\" \")\n\tl.ignore()\n\n\tif l.accept(\";\") {\n\t\tl.emit(typSemi)\n\t}\n\n\t// The value should always be the last thing\n\t// in the statement\n\treturn nil\n}\n\n// lexIgnore accepts runes until the end of the input\n// and emits them as a typIgnored token\nfunc lexIgnore(l *lexer) lexFn {\n\tl.acceptRunFunc(func(r rune) bool {\n\t\treturn r != utf8.RuneError\n\t})\n\tl.emit(typIgnored)\n\treturn nil\n}\n\n// ungronTokens turns a slice of tokens into an actual datastructure\nfunc ungronTokens(ts []token) (interface{}, error) {\n\tif len(ts) == 0 {\n\t\treturn nil, errRecoverable{\"empty input\"}\n\t}\n\n\tif ts[0].typ == typIgnored {\n\t\treturn nil, errRecoverable{\"ignored token\"}\n\t}\n\n\tif ts[len(ts)-1].typ == typError {\n\t\treturn nil, errors.New(\"invalid statement\")\n\t}\n\n\t// The last token should be typSemi so we need to check\n\t// the second to last token is a value rather than the\n\t// last one\n\tif len(ts) > 1 && !ts[len(ts)-2].isValue() {\n\t\treturn nil, errors.New(\"statement has no value\")\n\t}\n\n\tt := ts[0]\n\tswitch {\n\tcase t.isPunct():\n\t\t// Skip the token\n\t\tval, err := ungronTokens(ts[1:])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn val, nil\n\n\tcase t.isValue():\n\t\tvar val interface{}\n\t\td := json.NewDecoder(strings.NewReader(t.text))\n\t\td.UseNumber()\n\t\terr := d.Decode(&val)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid value `%s`\", t.text)\n\t\t}\n\t\treturn val, nil\n\n\tcase t.typ == typBare:\n\t\tval, err := ungronTokens(ts[1:])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tout := make(map[string]interface{})\n\t\tout[t.text] = val\n\t\treturn out, nil\n\n\tcase t.typ == typQuotedKey:\n\t\tval, err := ungronTokens(ts[1:])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tkey := \"\"\n\t\terr = json.Unmarshal([]byte(t.text), &key)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid quoted key `%s`\", t.text)\n\t\t}\n\n\t\tout := make(map[string]interface{})\n\t\tout[key] = val\n\t\treturn out, nil\n\n\tcase t.typ == typNumericKey:\n\t\tkey, err := strconv.Atoi(t.text)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid integer key `%s`\", t.text)\n\t\t}\n\n\t\tval, err := ungronTokens(ts[1:])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// There needs to be at least key + 1 space in the array\n\t\tout := make([]interface{}, key+1)\n\t\tout[key] = val\n\t\treturn out, nil\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unexpected token `%s`\", t.text)\n\t}\n}\n\n// recursiveMerge merges maps and slices, or returns b for scalars\nfunc recursiveMerge(a, b interface{}) (interface{}, error) {\n\tswitch a.(type) {\n\n\tcase map[string]interface{}:\n\t\tbMap, ok := b.(map[string]interface{})\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"cannot merge object with non-object\")\n\t\t}\n\t\treturn recursiveMapMerge(a.(map[string]interface{}), bMap)\n\n\tcase []interface{}:\n\t\tbSlice, ok := b.([]interface{})\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"cannot merge array with non-array\")\n\t\t}\n\t\treturn recursiveSliceMerge(a.([]interface{}), bSlice)\n\n\tcase string, int, float64, bool, nil:\n\t\t// Can't merge them, second one wins\n\t\treturn b, nil\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unexpected data type for merge\")\n\t}\n}\n\n// recursiveMapMerge recursively merges map[string]interface{} values\nfunc recursiveMapMerge(a, b map[string]interface{}) (map[string]interface{}, error) {\n\t// Merge keys from b into a\n\tfor k, v := range b {\n\t\t_, exists := a[k]\n\t\tif !exists {\n\t\t\t// Doesn't exist in a, just add it in\n\t\t\ta[k] = v\n\t\t} else {\n\t\t\t// Does exist, merge the values\n\t\t\tmerged, err := recursiveMerge(a[k], b[k])\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\ta[k] = merged\n\t\t}\n\t}\n\treturn a, nil\n}\n\n// recursiveSliceMerge recursively merged []interface{} values\nfunc recursiveSliceMerge(a, b []interface{}) ([]interface{}, error) {\n\t// We need a new slice with the capacity of whichever\n\t// slive is biggest\n\toutLen := len(a)\n\tif len(b) > outLen {\n\t\toutLen = len(b)\n\t}\n\tout := make([]interface{}, outLen)\n\n\t// Copy the values from 'a' into the output slice\n\tcopy(out, a)\n\n\t// Add the values from 'b'; merging existing keys\n\tfor k, v := range b {\n\t\tif out[k] == nil {\n\t\t\tout[k] = v\n\t\t} else if v != nil {\n\t\t\tmerged, err := recursiveMerge(out[k], b[k])\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tout[k] = merged\n\t\t}\n\t}\n\treturn out, nil\n}\n"
        },
        {
          "name": "ungron_test.go",
          "type": "blob",
          "size": 5.6005859375,
          "content": "package main\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n)\n\nfunc TestLex(t *testing.T) {\n\tcases := []struct {\n\t\tin   string\n\t\twant []token\n\t}{\n\t\t{`json.foo = 1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`foo`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`1`, typNumber},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json.foo = \"bar\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`foo`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"bar\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json.foo = \"ba;r\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`foo`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"ba;r\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json.foo = \"ba\\\"r ;\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`foo`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"ba\\\"r ;\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json = \"\\\\\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"\\\\\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json = \"\\\\\\\\\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"\\\\\\\\\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json = \"f\\oo\\\\\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"f\\oo\\\\\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json.value = \"\\u003c ;\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`value`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"\\u003c ;\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json[0] = \"bar\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`0`, typNumericKey},\n\t\t\t{`]`, typRBrace},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"bar\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json[\"foo\"] = \"bar\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`\"foo\"`, typQuotedKey},\n\t\t\t{`]`, typRBrace},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"bar\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json.foo[\"bar\"][0] = \"bar\";`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{`foo`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`\"bar\"`, typQuotedKey},\n\t\t\t{`]`, typRBrace},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`0`, typNumericKey},\n\t\t\t{`]`, typRBrace},\n\t\t\t{`=`, typEquals},\n\t\t\t{`\"bar\"`, typString},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`not an identifier at all`, []token{\n\t\t\t{`not`, typBare},\n\t\t}},\n\n\t\t{`alsonotanidentifier`, []token{\n\t\t\t{`alsonotanidentifier`, typBare},\n\t\t}},\n\n\t\t{`wat!`, []token{\n\t\t\t{`wat`, typBare},\n\t\t\t{``, typError},\n\t\t}},\n\n\t\t{`json[ = 1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{``, typError},\n\t\t}},\n\n\t\t{`json.[2] = 1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`.`, typDot},\n\t\t\t{``, typError},\n\t\t}},\n\n\t\t{`json[1 = 1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`1`, typNumericKey},\n\t\t\t{``, typError},\n\t\t}},\n\n\t\t{`json[\"foo] = 1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`[`, typLBrace},\n\t\t\t{`\"foo] = 1;`, typQuotedKey},\n\t\t\t{``, typError},\n\t\t}},\n\n\t\t{`--`, []token{\n\t\t\t{`--`, typIgnored},\n\t\t}},\n\n\t\t{`json  =  1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`1`, typNumber},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\n\t\t{`json=1;`, []token{\n\t\t\t{`json`, typBare},\n\t\t\t{`=`, typEquals},\n\t\t\t{`1`, typNumber},\n\t\t\t{`;`, typSemi},\n\t\t}},\n\t}\n\n\tfor _, c := range cases {\n\t\tl := newLexer(c.in)\n\t\thave := l.lex()\n\n\t\tif len(have) != len(c.want) {\n\t\t\tt.Logf(\"Input: %#v\", c.in)\n\t\t\tt.Logf(\"Want: %#v\", c.want)\n\t\t\tt.Logf(\"Have: %#v\", have)\n\t\t\tt.Fatalf(\"want %d tokens, have %d\", len(c.want), len(have))\n\t\t}\n\n\t\tfor i := range have {\n\t\t\tif have[i] != c.want[i] {\n\t\t\t\tt.Logf(\"Input: %#v\", c.in)\n\t\t\t\tt.Logf(\"Want: %#v\", c.want)\n\t\t\t\tt.Logf(\"Have: %#v\", have)\n\t\t\t\tt.Errorf(\"Want `%#v` in position %d, have `%#v`\", c.want[i], i, have[i])\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestUngronTokensSimple(t *testing.T) {\n\tin := `json.contact[\"e-mail\"][0] = \"mail@tomnomnom.com\";`\n\twant := map[string]interface{}{\n\t\t\"json\": map[string]interface{}{\n\t\t\t\"contact\": map[string]interface{}{\n\t\t\t\t\"e-mail\": []interface{}{\n\t\t\t\t\t\"mail@tomnomnom.com\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tl := newLexer(in)\n\ttokens := l.lex()\n\thave, err := ungronTokens(tokens)\n\n\tif err != nil {\n\t\tt.Fatalf(\"failed to ungron statement: %s\", err)\n\t}\n\n\tt.Logf(\"Have: %#v\", have)\n\tt.Logf(\"Want: %#v\", want)\n\n\teq := reflect.DeepEqual(have, want)\n\tif !eq {\n\t\tt.Errorf(\"Have and want datastructures are unequal\")\n\t}\n}\n\nfunc TestUngronTokensInvalid(t *testing.T) {\n\tcases := []struct {\n\t\tin []token\n\t}{\n\t\t{[]token{{``, typError}}},                           // Error token\n\t\t{[]token{{`foo`, typString}}},                       // Invalid value\n\t\t{[]token{{`\"foo`, typQuotedKey}, {\"1\", typNumber}}}, // Invalid quoted key\n\t\t{[]token{{`foo`, typNumericKey}, {\"1\", typNumber}}}, // Invalid numeric key\n\t\t{[]token{{``, -255}, {\"1\", typNumber}}},             // Invalid token type\n\t}\n\n\tfor _, c := range cases {\n\t\t_, err := ungronTokens(c.in)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"want non-nil error for %#v; have nil\", c.in)\n\t\t}\n\t}\n}\n\nfunc TestMerge(t *testing.T) {\n\ta := map[string]interface{}{\n\t\t\"json\": map[string]interface{}{\n\t\t\t\"contact\": map[string]interface{}{\n\t\t\t\t\"e-mail\": []interface{}{\n\t\t\t\t\t0: \"mail@tomnomnom.com\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tb := map[string]interface{}{\n\t\t\"json\": map[string]interface{}{\n\t\t\t\"contact\": map[string]interface{}{\n\t\t\t\t\"e-mail\": []interface{}{\n\t\t\t\t\t1: \"test@tomnomnom.com\",\n\t\t\t\t\t3: \"foo@tomnomnom.com\",\n\t\t\t\t},\n\t\t\t\t\"twitter\": \"@TomNomNom\",\n\t\t\t},\n\t\t},\n\t}\n\n\twant := map[string]interface{}{\n\t\t\"json\": map[string]interface{}{\n\t\t\t\"contact\": map[string]interface{}{\n\t\t\t\t\"e-mail\": []interface{}{\n\t\t\t\t\t0: \"mail@tomnomnom.com\",\n\t\t\t\t\t1: \"test@tomnomnom.com\",\n\t\t\t\t\t3: \"foo@tomnomnom.com\",\n\t\t\t\t},\n\t\t\t\t\"twitter\": \"@TomNomNom\",\n\t\t\t},\n\t\t},\n\t}\n\n\tt.Logf(\"A: %#v\", a)\n\tt.Logf(\"B: %#v\", b)\n\thave, err := recursiveMerge(a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to merge datastructures: %s\", err)\n\t}\n\n\tt.Logf(\"Have: %#v\", have)\n\tt.Logf(\"Want: %#v\", want)\n\teq := reflect.DeepEqual(have, want)\n\tif !eq {\n\t\tt.Errorf(\"Have and want datastructures are unequal\")\n\t}\n\n}\n"
        },
        {
          "name": "url.go",
          "type": "blob",
          "size": 0.71875,
          "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"time\"\n)\n\nfunc validURL(url string) bool {\n\tr := regexp.MustCompile(\"(?i)^http(?:s)?://\")\n\treturn r.MatchString(url)\n}\n\nfunc getURL(url string, insecure bool) (io.Reader, error) {\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: insecure},\n\t}\n\tclient := http.Client{\n\t\tTransport: tr,\n\t\tTimeout:   20 * time.Second,\n\t}\n\n\treq, err := http.NewRequest(\"GET\", url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treq.Header.Set(\"User-Agent\", fmt.Sprintf(\"gron/%s\", gronVersion))\n\treq.Header.Set(\"Accept\", \"application/json\")\n\n\tresp, err := client.Do(req)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn bufio.NewReader(resp.Body), err\n}\n"
        },
        {
          "name": "url_test.go",
          "type": "blob",
          "size": 0.41796875,
          "content": "package main\n\nimport (\n\t\"testing\"\n)\n\nfunc TestValidURL(t *testing.T) {\n\ttests := []struct {\n\t\turl  string\n\t\twant bool\n\t}{\n\t\t{\"http://test.com\", true},\n\t\t{\"https://test.com\", true},\n\t\t{\"HttPs://test.com\", true},\n\t\t{\"/test/test.com\", false},\n\t\t{\"\", false},\n\t}\n\n\tfor _, test := range tests {\n\t\thave := validURL(test.url)\n\t\tif have != test.want {\n\t\t\tt.Errorf(\"Want %t for validURL(%s); have %t\", test.want, test.url, have)\n\t\t}\n\t}\n}\n"
        }
      ]
    }
  ]
}