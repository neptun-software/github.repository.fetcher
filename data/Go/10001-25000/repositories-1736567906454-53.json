{
  "metadata": {
    "timestamp": 1736567906454,
    "page": 53,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "buger/goreplay",
      "stars": 18740,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clabot",
          "type": "blob",
          "size": 0.03125,
          "content": "{\n  \"contributors\": [\"buger\"]\n}\n"
        },
        {
          "name": ".deepsource.toml",
          "type": "blob",
          "size": 0.3447265625,
          "content": "version = 1\n\nexclude_patterns = [\n  \"vendor/**\"\n]\n\n[[analyzers]]\nname = \"go\"\nenabled = true\n\n  [analyzers.meta]\n  import_paths = [\"github.com/ankitdobhal/goreplay\"]\n\n[[analyzers]]\nname = \"docker\"\nenabled = true\n\n[[analyzers]]\nname = \"ruby\"\nenabled = true\n\n[[analyzers]]\nname = \"javascript\"\nenabled = true\n\n  [analyzers.meta]\n  environment = [\"nodejs\"]\n\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.021484375,
          "content": "*.tar.gz\ngor\ngor.test\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2060546875,
          "content": "vendor\n*.swp\n*.gor\n*.rpm\n*.dep\n*.deb\n*.pkg\n*.exe\n*.pprof\n*.out\nhey\n\n*.bin\nlib/\noutput/\n*.gz\n*.zip\n.aider*\n\n*.class\n\n*.test\n.idea\n*.iml\ngor\n\n*.mprof\n\n*.pcap\n\n.DS_Store\n\ngoreplay\ncorpus\ncrashers\nsuppressions\ndist\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": ".request",
          "type": "blob",
          "size": 0.0625,
          "content": "POST /post HTTP/1.1\nContent-Length: 7\nHost: www.w3.org\n\na=1&b=2\n"
        },
        {
          "name": "COMM-LICENSE",
          "type": "blob",
          "size": 17.826171875,
          "content": "END-USER LICENSE AGREEMENT\n\n------------------------------------------------------------------------------\n\nIMPORTANT: THIS SOFTWARE END-USER LICENSE AGREEMENT (\"EULA\") IS A LEGAL AGREEMENT (“Agreement”) BETWEEN YOU (THE CUSTOMER, EITHER AS AN INDIVIDUAL OR, IF PURCHASED OR OTHERWISE ACQUIRED BY OR FOR AN ENTITY, AS AN ENTITY), hereafter \"Customer\", AND Replay Software LLC (\"Licensor\"). READ IT CAREFULLY BEFORE COMPLETING THE INSTALLATION PROCESS AND USING GOREPLAY PRO AND RELATED SOFTWARE COMPONENTS (“SOFTWARE”). IT PROVIDES A LICENSE TO USE THE SOFTWARE AND CONTAINS WARRANTY INFORMATION AND LIABILITY DISCLAIMERS. BY INSTALLING AND USING THE SOFTWARE, YOU ARE CONFIRMING YOUR ACCEPTANCE OF THE SOFTWARE AND AGREEING TO BECOME BOUND BY THE TERMS OF THIS AGREEMENT.\n\n------------------------------------------------------------------------------\n\nIn order to use the Software under this Agreement, you must receive a “Source URL” at the time of purchase, in accordance with the scope of use and other terms specified for each type of Software and as set forth in this Section 1 of this Agreement. \n\n1. License Grant\n\n1.1 General Use. This Agreement grants you a non-exclusive, non-transferable, limited license to the use rights for the Software, without the right to grant sublicenses, subject to the terms and conditions in this Agreement. The Software is licensed, not sold.\n\n1.2 Unlimited Organization License. If you purchased an Organization License (included with the GoReplay Pro Software), you may install the Software on an unlimited number of Hosts. “Host” means any physical or virtual machine which is controlled by you. You may concurrently run the software on an unlimited number of Hosts.\n\n1.3 Appliance License. If you purchased an Appliance License, you may distribute the Software in any applications, frameworks, or elements (collectively referred to as an “Application” or “Applications”) that you develop using the Software in accordance with this EULA, provided that such distribution does not violate the restrictions set forth in section 3 of this EULA. You must not remove, obscure or interfere with any copyright, acknowledgment, attribution, trademark, warning or disclaimer statement affixed to, incorporated in or otherwise applied in connection with the Software. You are required to ensure that the Software is not reused by or with any applications other than those with which you distribute it as permitted herein. For example, if You install the Software on a customer’s server, that customer is not permitted to use the Software independently of your Application. You must inform Licensor of your knowledge of any infringing use of the Software by any of your customers. You are liable for compliance by those third parties with the terms and conditions of this EULA. You will not owe Licensor any royalties for your distribution of the Software in accordance with this EULA.\n\n1.4 Archive Copies. You are entitled to make a reasonable amount of copies of the Software for archival purposes. Each copy must reproduce all copyright and other proprietary rights notices on or in the Software Product.\n\n1.5 Electronic Delivery. All Software and license documentation shall be delivered by electronic means unless otherwise specified on the applicable invoice or at the time of purchase. Software shall be deemed delivered when it is made available for download by you (“Delivery”).        \n\n2. Modifications. Licensor shall provide you with source code so that you can create Modifications of the original software. “Modification” means: (a) any addition to or deletion from the contents of a file included in the original Software or previous Modifications created by You, or (b) any new file that contains any part of the original Software or previous Modifications. While you retain all rights to any original work authored by you as part of the Modifications, We continue to own all copyright and other intellectual property rights in the Software.\n\n3. Restricted Uses. \n\n3.1 You shall not (and shall not allow any third party to): (a) decompile, disassemble, or otherwise reverse engineer the Software or attempt to reconstruct or discover any source code, underlying ideas, algorithms, file formats or programming interfaces of the Software by any means whatsoever (except and only to the extent that applicable law prohibits or restricts reverse engineering restrictions); (b) distribute, sell, sublicense, rent, lease or use the Software for time sharing, hosting, service provider or like purposes, except as expressly permitted under this Agreement; (c) redistribute the Software or Modifications other than by including the Software or a portion thereof within your own product, which must have substantially different functionality than the Software or Modifications and must not allow any third party to use the Software or Modifications, or any portions thereof, for software development or application development purposes; (d) redistribute the Software as part of a product, \"appliance\" or \"virtual server\"; (e) redistribute the Software on any server which is not directly under your control; (f) remove any product identification, proprietary, copyright or other notices contained in the Software; (g) modify any part of the Software, create a derivative work of any part of the Software (except as permitted in Section 4), or incorporate the Software, except to the extent expressly authorized in writing by Licensor; (h) publicly disseminate performance information or analysis (including, without limitation, benchmarks) from any source relating to the Software; (i) utilize any equipment, device, software, or other means designed to circumvent or remove any form of Source URL or copy protection used by Licensor in connection with the Software, or use the Software together with any authorization code, Source URL, serial number, or other copy protection device not supplied by Licensor; (j) use the Software to develop a product which is competitive with any Licensor product offerings; or (k) use unauthorized Source URLS or keycode(s) or distribute or publish Source URLs or keycode(s), except as may be expressly permitted by Licensor in writing. If your unique Source URL is ever published, Licensor reserves the right to terminate your access without notice.\n\n3.2 UNDER NO CIRCUMSTANCES MAY YOU USE THE SOFTWARE AS PART OF A PRODUCT OR SERVICE THAT PROVIDES SIMILAR FUNCTIONALITY TO THE SOFTWARE ITSELF.\n\nThe Open Source version of the Software (“LGPL Version”) is licensed\nunder the terms of the GNU Lesser General Public License versions 3.0\n(“LGPL”) and not under this EULA. \n\n4. Ownership. Notwithstanding anything to the contrary contained herein, except for the limited license rights expressly provided herein, Licensor and its suppliers have and will retain all rights, title and interest (including, without limitation, all patent, copyright, trademark, trade secret and other intellectual property rights) in and to the Software and all copies, modifications and derivative works thereof (including any changes which incorporate any of your ideas, feedback or suggestions). You acknowledge that you are obtaining only a limited license right to the Software, and that irrespective of any use of the words “purchase”, “sale” or like terms hereunder no ownership rights are being conveyed to you under this Agreement or otherwise. \n\n5. Fees and Payment. The Software license fees will be due and payable in full as set forth in the applicable invoice or at the time of purchase. If the Software does not function properly within two weeks of purchase, please contact us within those two weeks for a refund. You shall be responsible for all taxes, withholdings, duties and levies arising from the order (excluding taxes based on the net income of Licensor). \n\n6. Support, Maintenance and Services. Subject to the terms and conditions of this Agreement, as set forth in your invoice, and as set forth on the GoReplay Pro support page (https://github.com/buger/goreplay/wiki/Pro-Support), support and maintenance services may be included with the purchase of your license subscription.\n\n7. Term of Agreement. \n\n7.1 Term. This Agreement is effective as of the Delivery of the Software and expires at such time as all license and service subscriptions hereunder have expired in accordance with their own terms (the “Term”). For clarification, the term of your license under this Agreement may be perpetual, limited for Evaluation Version, or designated as a fixed-term license in the Invoice, and shall be specified at your time of purchase. Either party may terminate this Agreement (including all related Invoices) if the other party: (a) fails to cure any material breach of this Agreement within thirty (30) days after written notice of such breach, provided that Licensor may terminate this Agreement immediately upon any breach of Section 3 or if you exceed any other restrictions contained in Section 1, unless otherwise specified in this agreement; (b) ceases operation without a successor; or (c) seeks protection under any bankruptcy, receivership, trust deed, creditors arrangement, composition or comparable proceeding, or if any such proceeding is instituted against such party (and not dismissed within sixty (60) days)). Termination is not an exclusive remedy and the exercise by either party of any remedy under this Agreement will be without prejudice to any other remedies it may have under this Agreement, by law, or otherwise.        \n\n7.2 Termination. Upon any termination of this Agreement, you shall cease any and all use of any Software and destroy all copies thereof. \n\n7.3 Expiration of License. Upon the expiration of any term under this Agreement, (a) all Software updates and services pursuant to the license shall cease, (b) you may only continue to run existing installations of the Software, (c) you may not install the Software on any additional Hosts, and (d) any new installation of the Software shall require the purchase of a new license subscription from Licensor.\n\n8. Disclaimer of Warranties. The Software is provided \"as is,\" with all faults, defects and errors, and without warranty of any kind. Licensor does not warrant that the Software will be free of bugs, errors, viruses or other defects, and Licensor shall have no liability of any kind for the use of or inability to use the Software, the Software content or any associated service, and you acknowledge that it is not technically practicable for Licensor to do so. \nTo the maximum extent permitted by applicable law, Licensor disclaims all warranties, express, implied, arising by law or otherwise, regarding the Software, the Software content and their respective performance or suitability for your intended use, including without limitation any implied warranty of merchantability, fitness for a particular purpose.\nNotwithstanding the foregoing, Licensor represents and warrants that it either owns the entire right to, title to, interest in, or has the right to license, the Software, and your proper use of the same will not violate any intellectual property or proprietary rights of another.\n\n9. Limitation of Liability. \n\nIn no event will either party be liable for any direct, indirect, consequential, incidental, special, exemplary, or punitive damages or liabilities whatsoever arising from or relating to the Software, the Software content or this Agreement, whether based on contract, tort (including negligence), strict liability or other theory, even if such party has been advised of the possibility of such damages. Except for indemnification obligations in Section 13.5, in no event will Licensor liability exceed the Software license price as indicated in the invoice. The existence of more than one claim will not enlarge or extend this limit.\n\n10. Remedies. Your exclusive remedy and Licensor’ entire liability for breach of this Agreement shall be limited, at Licensor’ sole and exclusive discretion, to (a) replacement of any defective software or documentation; or (b) refund of the license fee paid to Licensor, payable in accordance with Licensor' refund policy.\n\n11. Acknowledgements.\n\n11.1 Consent to the Use of Data. You agree that Licensor and its affiliates may collect and use technical information gathered as part of the product support services to be used in an anonymized manner. Licensor may use this information solely to improve products and services and will not disclose this information in a form that personally identifies you.\n\n11.2 Verification. We or a certified auditor acting on our behalf, may, upon its reasonable request and at its expense, audit you with respect to the use of the Software, subject to your reasonable information security and confidentiality protections. Such audit may be conducted by mail, electronic means or through an in-person visit to your place of business. Any such in-person audit shall be conducted during regular business hours at your facilities and shall not unreasonably interfere with your business activities. We shall not remove, copy, or redistribute any electronic material during the course of an audit. If an audit reveals that you are using the Software in a way that is in material violation of the terms of the EULA, then you shall pay our reasonable costs of conducting the audit. In the case of a material violation, you agree to pay Us any amounts owing that are attributable to the unauthorized use. In the alternative, We reserve the right, at our sole option, to terminate the licenses for the Software.\n\n11.3 Government End Users. If the Software and related documentation are supplied to or purchased by or on behalf of the United States Government, then the Software is deemed to be \"commercial software\" as that term is used in the Federal Acquisition Regulation system. Rights of the United States shall not exceed the minimum rights set forth in FAR 52.227-19 for \"restricted computer software\". All other terms and conditions of this Agreement apply.\n\n12. Third Party Software.  Examples included in Software may provide links to third party libraries or code (collectively “Third Party Software”) to implement various functions. Third Party Software does not comprise part of the Software. In some cases, access to Third Party Software may be included along with the Software delivery as a convenience for demonstration purposes. Such source code and libraries may be included in the “…/examples” source tree delivered with the Software and do not comprise the Software. Licensee acknowledges (1) that some part of Third Party Software may require additional licensing of copyright and patents from the owners of such, and (2) that distribution of any of the Software referencing or including any portion of a Third Party Software may require appropriate licensing from such third parties.\n\n\n13. Miscellaneous\n\n13.1 Entire Agreement. This Agreement sets forth our entire agreement with respect to the Software and the subject matter hereof and supersedes all prior and contemporaneous understandings and agreements whether written or oral.\n\n13.2 Amendment. Licensor reserves the right, in its sole discretion, to amend this Agreement from time. Amendments to this Agreement can be located at: https://github.com/buger/goreplay/blob/master/COMM-LICENSE.\n\n13.3 Assignment. You may not assign this Agreement or any of its rights under this Agreement without the prior written consent of Licensor and any attempted assignment without such consent shall be void.\n\n13.4 Export Compliance. Each party agrees to comply with all applicable laws and regulations, including laws, regulations, orders or other restrictions on export, re-export or redistribution of software.\n\n13.5 Indemnification. Licensor agrees to defend, indemnify, and hold harmless You from and against any lawsuits, claims, losses, damages, fines and expenses (including attorneys' fees and costs) arising out of a claim brought by a third-party alleging that the Software directly infringes such third-party’s intellectual property rights; provided that Licensor shall have no indemnity obligation for claims arising out of your modification to the Software. You agree to defend, indemnify, and hold harmless Licensor from and against any lawsuits, claims, losses, damages, fines and expenses (including attorneys' fees and costs) brought by a third-party arising out of your modifications to the Software or breach of this Agreement.\n\n13.6 Governing Law. This Agreement is governed by the laws of the State of Oregon and the United States without regard to conflicts of laws provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods or the Uniform Computer Information Transactions Act, as currently enacted by any jurisdiction or as may be codified or amended from time to time by any jurisdiction. The jurisdiction and venue for actions related to the subject matter hereof shall be the state of Oregon and United States federal courts located in Portland, Oregon, and both parties hereby submit to the personal jurisdiction of such courts. \n\n13.7 Attorneys’ Fees and Costs. The prevailing party in any action to enforce this Agreement will be entitled to recover its attorneys’ fees and costs in connection with such action. \n\n13.8 Severability. If any provision of this Agreement is held by a court of competent jurisdiction to be invalid, illegal, or unenforceable, the remainder of this Agreement will remain in full force and effect.\n\n13.9 Waiver. Failure or neglect by either party to enforce at any time any of the provisions of this licence Agreement shall not be construed or deemed to be a waiver of that party's rights under this Agreement.\n\n13.10 Headings. The headings of sections and paragraphs of this Agreement are for convenience of reference only and are not intended to restrict, affect or be of any weight in the interpretation or construction of the provisions of such sections or paragraphs.\n\n14. Contact Information. If you have any questions about this EULA, or if you want to contact Licensor for any reason, please direct correspondence to hello@goreplay.org\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.3720703125,
          "content": "FROM alpine:3.16 as builder\n\nARG RELEASE_VERSION\n\nRUN apk add --no-cache ca-certificates openssl\nRUN wget https://github.com/buger/goreplay/releases/download/${RELEASE_VERSION}/gor_${RELEASE_VERSION}_x64.tar.gz -O gor.tar.gz\nRUN tar xzf gor.tar.gz\n\nFROM scratch\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\nCOPY --from=builder /gor .\nENTRYPOINT [\"./gor\"]\n"
        },
        {
          "name": "Dockerfile.dev",
          "type": "blob",
          "size": 0.423828125,
          "content": "ARG BASE_IMAGE\nFROM ${BASE_IMAGE}\n\nRUN apk add --no-cache \\\n    gcc \\\n    g++ \\\n    make \\\n    linux-headers \\\n    bison \\\n    flex \\\n    git \\\n    wget\n\nRUN wget http://www.tcpdump.org/release/libpcap-1.10.0.tar.gz && tar xzf libpcap-1.10.0.tar.gz && cd libpcap-1.10.0 && ./configure && make install\n\nWORKDIR /go/src/github.com/buger/goreplay/\nADD . /go/src/github.com/buger/goreplay/\n\nRUN go get golang.org/x/lint/golint\nRUN go get\n"
        },
        {
          "name": "ELASTICSEARCH.md",
          "type": "blob",
          "size": 1.9150390625,
          "content": "gor & elasticsearch\n===================\n\nPrerequisites\n-------------\n\n- elasticsearch\n- kibana (Get it here: http://www.elasticsearch.org/overview/kibana/)\n- gor\n\n\nelasticsearch\n-------------\n\nThe default elasticsearch configuration is just fine for most workloads. You won't need clustering, sharding or something like that.\n\nIn this example we're installing it on our gor replay server which gives us the elasticsearch listener on _http://localhost:9200_\n\n\nkibana\n------\n\nKibana (elasticsearch analytics web-ui) is just as simple. \nDownload it, extract it and serve it via a simple webserver.\n(Could be nginx or apache)\n\nYou could also use a shell, ```cd``` into the kibana directory and start a little quick and dirty python webserver with:\n\n```\npython -m SimpleHTTPServer 8000\n```\n\nIn this example we're also choosing the gor replay server as our kibana host. If you choose a different server you'll have to point kibana to your elasticsearch host.\n\n\ngor\n---\n\nStart your gor replay server with elasticsearch option:\n\n```\n./gor --input-raw :8000 --output-http http://staging.com  --output-http-elasticsearch localhost:9200/gor\n```\n\n\n(You don't have to create the index upfront. That will be done for you automatically)\n\n\nNow visit your kibana url, load the predefined dashboard from the gist https://gist.github.com/gottwald/b2c875037f24719a9616 and watch the data rush in.\n\n\nTroubleshooting\n---------------\n\nThe replay process may complain about __too many open files__.\nThat's because your typical linux shell has a small open files soft limit at 1024.\nYou can easily raise that when you do this before starting your _gor replay_ process:\n\n```\nulimit -n 64000\n```\n\nPlease be aware, this is not a permanent setting. It's just valid for the following jobs you start from that shell.\n\nWe reached the 1024 limit in our tests with a ubuntu box replaying about 9000 requests per minute. (We had very slow responses there, should be way more with fast responses)\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.53125,
          "content": "Copyright (c) 2011-present Leonid Bugaev\n\nPortions of this software are licensed as follows:\n\n* All content residing under the \"doc/\" directory of this repository is licensed under \"Creative Commons: CC BY-SA 4.0 license\".\n* The file \"pro.go\" and all files ending with the \"_pro.go\" suffix are released under the commercial license specified in the \"COMM-LICENSE\" file.\n* Content outside of the above mentioned directories or restrictions above is available under the \"LGPLv3\" license as defined below.\n\n\nGoReplay is an Open Source project licensed under the terms of\nthe LGPLv3 license.  Please see <http://www.gnu.org/licenses/lgpl-3.0.html>\nfor license text.\n\nAs a special exception to the GNU Lesser General Public License version 3\n(\"LGPL3\"), the copyright holders of this Library give you permission to\nconvey to a third party a Combined Work that links statically or dynamically\nto this Library without providing any Minimal Corresponding Source or\nMinimal Application Code as set out in 4d or providing the installation\ninformation set out in section 4e, provided that you comply with the other\nprovisions of LGPL3 and provided that you meet, for the Application the\nterms and conditions of the license(s) which apply to the Application.\n\nTLDR: You are free to use Gor subpackages like `byteutils` or `proto` in your commercial projects.\n\n\nGoReplay Pro has a commercial-friendly license allowing private forks\nand modifications of GoReplay.  Please see https://goreplay.org/pro.html for\nmore detail.  You can find the commercial license terms in COMM-LICENSE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 6.3857421875,
          "content": "SOURCE = $(shell ls -1 *.go | grep -v _test.go)\nPROJECT_NAME := goreplay\nSOURCE_PATH = /go/src/github.com/buger/goreplay/\nPORT = 8000\nFADDR = :8000\nDIST_PATH = dist\nCONTAINER_AMD=gor-amd64\nCONTAINER_ARM=gor-arm64\nRUN = docker run --rm -v `pwd`:$(SOURCE_PATH) -e AWS_ACCESS_KEY_ID=$(AWS_ACCESS_KEY_ID) -e AWS_SECRET_ACCESS_KEY=$(AWS_SECRET_ACCESS_KEY) -p 0.0.0.0:$(PORT):$(PORT) -t -i $(CONTAINER_AMD)\nBENCHMARK = BenchmarkRAWInput\nTEST = TestRawListenerBench\nBIN_NAME = gor\nVERSION := DEV-$(shell date +%s)\nCUSTOM_TAGS := --tags \"ngo$(if $(CUSTOM_BUILD_TAGS), $(CUSTOM_BUILD_TAGS),)\"\nLDFLAGS = -ldflags \"-X main.VERSION=$(VERSION) -extldflags \\\"-static\\\" -X main.DEMO=$(DEMO)\"\nMAC_LDFLAGS = -ldflags \"-X main.VERSION=$(VERSION) -X main.DEMO=$(DEMO)\"\nDOCKER_FPM_CMD := docker run --rm -t -v `pwd`:/src -w /src fleetdm/fpm\n\nFPM_COMMON= \\\n\t\t\t\t--name $(PROJECT_NAME) \\\n\t\t\t\t--description \"GoReplay is an open-source network monitoring tool which can record your live traffic, and use it for shadowing, load testing, monitoring and detailed analysis.\" \\\n\t\t\t\t-v $(VERSION) \\\n\t\t\t\t--vendor \"Leonid Bugaev\" \\\n\t\t\t\t-m \"<support@goreplay.org>\" \\\n\t\t\t\t--url \"https://goreplay.org\" \\\n\t\t\t\t-s dir\n\nrelease: clean release-linux-amd64 release-linux-arm64 release-mac-amd64 release-mac-arm64 release-windows\n\n.PHONY: vendor\nvendor:\n\tgo mod vendor\n\nrelease-bin-linux-amd64: vendor\n\tdocker run --platform linux/amd64 --rm -v `pwd`:$(SOURCE_PATH) -t --env GOOS=linux --env GOARCH=amd64 -i $(CONTAINER_AMD) go build -mod=vendor -o $(BIN_NAME) $(CUSTOM_TAGS) $(LDFLAGS) ./cmd/gor/\n\nrelease-bin-linux-arm64: vendor\n\tdocker run --platform linux/arm64 --rm -v `pwd`:$(SOURCE_PATH) -t --env GOOS=linux --env GOARCH=arm64 -i $(CONTAINER_ARM) go build -mod=vendor -o $(BIN_NAME) $(CUSTOM_TAGS) $(LDFLAGS) ./cmd/gor/\n\nrelease-bin-mac-amd64: vendor\n\tGOOS=darwin go build -mod=vendor -o $(BIN_NAME) $(CUSTOM_TAGS) $(MAC_LDFLAGS) ./cmd/gor/\n\nrelease-bin-mac-arm64: vendor\n\tGOOS=darwin GOARCH=arm64 CGO_ENABLED=1 go build -mod=vendor -o $(BIN_NAME) $(CUSTOM_TAGS) $(MAC_LDFLAGS)\n\nrelease-bin-windows: vendor\n\tdocker run -it --rm -v `pwd`:$(SOURCE_PATH) -w $(SOURCE_PATH) -e CGO_ENABLED=1 docker.elastic.co/beats-dev/golang-crossbuild:1.19.2-main --build-cmd \"make VERSION=$(VERSION) CUSTOM_BUILD_TAGS=$(CUSTOM_BUILD_TAGS) build\" -p \"windows/amd64\" ./cmd/gor/\n\tmv $(BIN_NAME) \"$(BIN_NAME).exe\"\n\nrelease-linux-amd64: dist release-bin-linux-amd64\n\ttar -czf $(DIST_PATH)/gor_$(VERSION)_linux_amd64.tar.gz $(BIN_NAME)\n\t$(DOCKER_FPM_CMD) $(FPM_COMMON) -f -t deb -a arm64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\t$(DOCKER_FPM_CMD) $(FPM_COMMON) -f -t rpm -a arm64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\trm -rf $(BIN_NAME)\n\nrelease-linux-arm64: dist release-bin-linux-arm64\n\ttar -czf $(DIST_PATH)/gor_$(VERSION)_linux_arm64.tar.gz $(BIN_NAME)\n\t$(DOCKER_FPM_CMD) $(FPM_COMMON) -f -t deb -a arm64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\t$(DOCKER_FPM_CMD) $(FPM_COMMON) -f -t rpm -a arm64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\trm -rf $(BIN_NAME)\n\nrelease-mac-amd64: dist release-bin-mac-amd64\n\ttar -czf $(DIST_PATH)/gor_$(VERSION)_darwin_amd64.tar.gz $(BIN_NAME)\n\tfpm $(FPM_COMMON) -f -t osxpkg -a amd64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\tmv ./$(DIST_PATH)/$(PROJECT_NAME)-$(VERSION).pkg ./$(DIST_PATH)/$(PROJECT_NAME)-$(VERSION)-amd64.pkg\n\trm -rf $(BIN_NAME)\n\nrelease-mac-arm64: dist release-bin-mac-arm64\n\ttar -czf $(DIST_PATH)/gor_$(VERSION)_darwin_arm64.tar.gz $(BIN_NAME)\n\tfpm $(FPM_COMMON) -f -t osxpkg -a arm64 -p ./$(DIST_PATH) ./gor=/usr/local/bin\n\tmv ./$(DIST_PATH)/$(PROJECT_NAME)-$(VERSION).pkg ./$(DIST_PATH)/$(PROJECT_NAME)-$(VERSION)-arm64.pkg\n\trm -rf $(BIN_NAME)\n\nrelease-windows: dist release-bin-windows\n\tzip $(DIST_PATH)/gor-$(VERSION)_windows.zip \"$(BIN_NAME).exe\"\n\trm -rf \"$(BIN_NAME).exe\"\n\nclean:\n\trm -rf $(DIST_PATH)\n\nbuild:\n\tgo build -mod=vendor -o $(BIN_NAME) $(CUSTOM_TAGS) $(LDFLAGS)\n\ninstall:\n\tgo install $(CUSTOM_TAGS) $(MAC_LDFLAGS)\n\nbuild-env: build-amd64-env build-arm64-env\n\nbuild-amd64-env:\n\tdocker buildx build --build-arg BASE_IMAGE=golang:1.22-alpine --platform linux/amd64 -t $(CONTAINER_AMD) -f Dockerfile.dev --load .\n\nbuild-arm64-env:\n\tdocker buildx build --build-arg BASE_IMAGE=arm64v8/golang:1.22-alpine --platform linux/arm64 -t $(CONTAINER_ARM) -f Dockerfile.dev --load .\n\nbuild-docker:\n\tdocker build -t gor-dev -f Dockerfile .\n\nprofile:\n\tgo build && ./$(BIN_NAME) --output-http=\"http://localhost:9000\" --input-dummy 0 --input-raw :9000 --input-http :9000 --memprofile=./mem.out --cpuprofile=./cpu.out --stats --output-http-stats --output-http-timeout 100ms\n\nlint:\n\t$(RUN) golint $(PKG)\n\nrace:\n\t$(RUN) go test ./... $(ARGS) -v -race -timeout 15s\n\ntest:\n\t$(RUN) go test ./. -timeout 120s $(CUSTOM_TAGS) $(LDFLAGS) $(ARGS)  -v\n\ntest_all:\n\t$(RUN) go test ./... -timeout 120s $(CUSTOM_TAGS) $(LDFLAGS) $(ARGS) -v\n\ntestone:\n\t$(RUN) go test ./. -timeout 60s $(CUSTOM_TAGS) $(LDFLAGS) -run $(TEST) $(ARGS) -v\n\ncover:\n\t$(RUN) go test $(ARGS) -race -v -timeout 15s -coverprofile=coverage.out\n\tgo tool cover -html=coverage.out\n\nfmt:\n\t$(RUN) gofmt -w -s ./..\n\nvet:\n\t$(RUN) go vet\n\nbench:\n\t$(RUN) go test $(CUSTOM_TAGS) $(LDFLAGS) -v -run NOT_EXISTING -bench $(BENCHMARK) -benchtime 5s\n\nprofile_test:\n\t$(RUN) go test $(CUSTOM_TAGS) $(LDFLAGS) -run $(TEST) ./capture/. $(ARGS) -memprofile mem.mprof -cpuprofile cpu.out\n\t$(RUN) go test $(CUSTOM_TAGS) $(LDFLAGS) -run $(TEST) ./capture/. $(ARGS) -c\n\n# Used mainly for debugging, because docker container do not have access to parent machine ports\nrun:\n\t$(RUN) go run $(CUSTOM_TAGS) $(LDFLAGS) $(SOURCE) --input-dummy=0 --output-http=\"http://localhost:9000\" --input-raw-track-response --input-raw 127.0.0.1:9000 --verbose 0 --middleware \"./examples/middleware/echo.sh\" --output-file requests.gor\n\nrun-2:\n\t$(RUN) go run $(CUSTOM_TAGS) $(LDFLAGS) $(SOURCE) --input-raw :8000 --input-raw-bpf-filter \"dst port 8000\" --output-stdout --output-http \"http://localhost:8000\" --input-dummy=0\n\nrun-3:\n\tsudo -E go run $(CUSTOM_TAGS) $(SOURCE) --input-tcp :27001 --output-stdout\n\nrun-arg:\n\tsudo -E go run $(CUSTOM_TAGS) $(SOURCE) $(ARGS)\n\nfile-server:\n\tgo run $(CUSTOM_TAGS) $(SOURCE) file-server $(FADDR)\n\nreadpcap:\n\tgo run $(CUSTOM_TAGS) $(SOURCE) --input-raw $(FILE) --input-raw-track-response --input-raw-engine pcap_file --output-stdout\n\nrecord:\n\t$(RUN) go run $(CUSTOM_TAGS) $(SOURCE) --input-dummy=0 --output-file=requests.gor --verbose --debug\n\nreplay:\n\t$(RUN) go run $(CUSTOM_TAGS) $(SOURCE) --input-file=requests.bin --output-tcp=:9000 --verbose -h\n\nbash:\n\t$(RUN) /bin/bash\n\ndist:\n\tmkdir -p $(DIST_PATH)\n"
        },
        {
          "name": "Procfile",
          "type": "blob",
          "size": 0.2470703125,
          "content": "web: python -m SimpleHTTPServer 8000\nreplayed_web: python -m SimpleHTTPServer 8001\nlistener: sudo -E go run ./bin/gor.go --input-raw :8000 --output-tcp :8002 --verbose\nreplay: go run ./bin/gor.go --input-tcp :8002 --output-http localhost:8001 --verbose\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.015625,
          "content": "<a href=\"https://semgrep.dev/login?utm_source=github&utm_medium=badge&utm_campaign=growth-oss\"><img src=\"https://img.shields.io/badge/semgrep-security-green.svg\" /></a> [![GitHub release](https://img.shields.io/github/release/buger/gor.svg?maxAge=3600)](https://github.com/buger/goreplay/releases) [![codebeat](https://codebeat.co/badges/6427d589-a78e-416c-a546-d299b4089893)](https://codebeat.co/projects/github-com-buger-gor) [![Go Report Card](https://goreportcard.com/badge/github.com/buger/gor)](https://goreportcard.com/report/github.com/buger/gor) [![Join the chat at https://gitter.im/buger/gor](https://badges.gitter.im/buger/gor.svg)](https://gitter.im/buger/gor?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![Reviewed by Hound](https://img.shields.io/badge/Reviewed_by-Hound-8E64B0.svg)](https://houndci.com)\n\n![Go Replay](http://i.imgur.com/ZG2ki5n.png)\n\n## https://goreplay.org/\n\nGoReplay is an open-source network monitoring tool which can record your live traffic and use it for shadowing, load testing, monitoring and detailed analysis.\n\n## About\n\nAs your application grows, the effort required to test it also grows exponentially. GoReplay offers you the simple idea of reusing your existing traffic for testing, which makes it incredibly powerful. Our state of art technique allows you to analyze and record your application traffic without affecting it. This eliminates the risks that come with putting a third party component in the critical path. \n\nGoReplay increases your confidence in code deployments, configuration and infrastructure changes.\n\n\nGoReplay offers a unique approach for shadowing. Instead of being a proxy, GoReplay listens in the background for traffic on your network interfaces, requiring no changes in your production infrastructure, other than running GoReplay daemon on the same machine as your service.\n\n![Diagram](https://i.imgur.com/IN2xfDm.png)\n\nCheck [latest documentation](http://github.com/buger/goreplay/wiki).\n\n## Installation\nDownload the latest binary from https://github.com/buger/goreplay/releases or [compile by yourself](https://github.com/buger/goreplay/wiki/Compilation).\n\n## Getting started\n\nThe most basic setup will be `sudo ./gor --input-raw :8000 --output-stdout` which acts like tcpdump.\nIf you already have a test environment, you can start replaying by running: `sudo ./gor --input-raw :8000 --output-http http://staging.env`.\n\nSee our [documentation](https://github.com/buger/goreplay/wiki/) and the [Getting Started](https://github.com/buger/goreplay/wiki/Getting-Started) page for more info. \n\n## Newsletter\nSubscribe to our [newsletter](https://www.getdrip.com/forms/89690474/submissions/new) to stay informed about the latest features and changes to the Gor project.\n\n## Want to Upgrade?\n\nWe have created a [GoReplay PRO](https://goreplay.org/pro.html) extension which provides additional features such as support for binary protocols like Thrift or ProtocolBuffers, saving and replaying from cloud storage, TCP session replication, etc. The PRO version also includes a commercial-friendly license, dedicated support, and it also allows you to support high-quality open source development. \n\n\n## Problems?\nIf you have a problem, please review the [FAQ](https://github.com/buger/goreplay/wiki/FAQ) and [Troubleshooting](https://github.com/buger/goreplay/wiki/Troubleshooting) wiki pages. Searching the [issues](https://github.com/buger/goreplay/issues) for your problem is also a good idea.\n\nAll bug-reports and suggestions should go through Github Issues or our [Google Group](https://groups.google.com/forum/#!forum/gor-users) (you can just send email to gor-users@googlegroups.com).\nIf you have a private question feel free to send email to support@gortool.com.\n\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (git checkout -b my-new-feature)\n3. Commit your changes (git commit -am 'Added some feature')\n4. Push to the branch (git push origin my-new-feature)\n5. Create new Pull Request\n\n## Companies using Gor\n\n* [GOV.UK](https://www.gov.uk) - UK Government Digital Service\n* [theguardian.com](http://theguardian.com) - Most popular online newspaper in the UK\n* [TomTom](http://www.tomtom.com/) - Global leader in navigation, traffic and map products, GPS Sport Watches and fleet management solutions.\n* [3SCALE](http://www.3scale.net/) - API infrastructure to manage your APIs for internal or external users\n* [Optionlab](http://www.opinionlab.com) - Optimize customer experience and drive engagement across multiple channels\n* [TubeMogul](http://tubemogul.com) - Software for Brand Advertising\n* [Videology](http://www.videologygroup.com/) - Video advertising platform\n* [ForeksMobile](http://foreksmobile.com/) -  One of the leading financial application development company in Turkey\n* [Granify](http://granify.com) - AI backed SaaS solution that enables online retailers to maximise their sales\n* And many more!\n\nIf you are using Gor, we are happy to add you to the list and share your story, just write to: hello@goreplay.org\n\n## Author\n\nLeonid Bugaev, [@buger](https://twitter.com/buger), https://leonsbox.com\n"
        },
        {
          "name": "ce.go",
          "type": "blob",
          "size": 0.35546875,
          "content": "//go:build !pro\n\npackage goreplay\n\nimport (\n\t\"fmt\"\n)\n\n// PRO this value indicates if goreplay is running in PRO mode.\nvar PRO = false\n\nfunc SettingsHook(settings *AppSettings) {\n\tif settings.RecognizeTCPSessions {\n\t\tsettings.RecognizeTCPSessions = false\n\t\tfmt.Println(\"[ERROR] TCP session recognition is not supported in the open-source version of GoReplay\")\n\t}\n}\n"
        },
        {
          "name": "circle.yml",
          "type": "blob",
          "size": 0.2734375,
          "content": "dependencies:\n  pre:\n    - sudo apt-get install libpcap-dev -y\n\ntest:\n  override:\n    - sudo bash -l -c \"export GOPATH='/home/ubuntu/.go_workspace:/usr/local/go_workspace:/home/ubuntu/.go_project' && GORACE='halt_on_error=1' /usr/local/go/bin/go test ./... -v -timeout 120s -race\""
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "elasticsearch.go",
          "type": "blob",
          "size": 5.154296875,
          "content": "package goreplay\n\nimport (\n\t\"encoding/json\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"log\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\telastigo \"github.com/mattbaird/elastigo/lib\"\n)\n\ntype ESUriErorr struct{}\n\nfunc (e *ESUriErorr) Error() string {\n\treturn \"Wrong ElasticSearch URL format. Expected to be: scheme://host/index_name\"\n}\n\ntype ESPlugin struct {\n\tActive  bool\n\tApiPort string\n\teConn   *elastigo.Conn\n\tHost    string\n\tIndex   string\n\tindexor *elastigo.BulkIndexer\n\tdone    chan bool\n}\n\ntype ESRequestResponse struct {\n\tReqURL               string `json:\"Req_URL\"`\n\tReqMethod            string `json:\"Req_Method\"`\n\tReqUserAgent         string `json:\"Req_User-Agent\"`\n\tReqAcceptLanguage    string `json:\"Req_Accept-Language,omitempty\"`\n\tReqAccept            string `json:\"Req_Accept,omitempty\"`\n\tReqAcceptEncoding    string `json:\"Req_Accept-Encoding,omitempty\"`\n\tReqIfModifiedSince   string `json:\"Req_If-Modified-Since,omitempty\"`\n\tReqConnection        string `json:\"Req_Connection,omitempty\"`\n\tReqCookies           string `json:\"Req_Cookies,omitempty\"`\n\tRespStatus           string `json:\"Resp_Status\"`\n\tRespStatusCode       string `json:\"Resp_Status-Code\"`\n\tRespProto            string `json:\"Resp_Proto,omitempty\"`\n\tRespContentLength    string `json:\"Resp_Content-Length,omitempty\"`\n\tRespContentType      string `json:\"Resp_Content-Type,omitempty\"`\n\tRespTransferEncoding string `json:\"Resp_Transfer-Encoding,omitempty\"`\n\tRespContentEncoding  string `json:\"Resp_Content-Encoding,omitempty\"`\n\tRespExpires          string `json:\"Resp_Expires,omitempty\"`\n\tRespCacheControl     string `json:\"Resp_Cache-Control,omitempty\"`\n\tRespVary             string `json:\"Resp_Vary,omitempty\"`\n\tRespSetCookie        string `json:\"Resp_Set-Cookie,omitempty\"`\n\tRtt                  int64  `json:\"RTT\"`\n\tTimestamp            time.Time\n}\n\n// Parse ElasticSearch URI\n//\n// Proper format is: scheme://[userinfo@]host/index_name\n// userinfo is: user[:password]\n// net/url.Parse() does not fail if scheme is not provided but actually does not\n// handle URI properly.\n// So we must 'validate' URI format to match requirements to use net/url.Parse()\nfunc parseURI(URI string) (err error, index string) {\n\n\tparsedUrl, parseErr := url.Parse(URI)\n\n\tif parseErr != nil {\n\t\terr = new(ESUriErorr)\n\t\treturn\n\t}\n\n\t//\tcheck URL validity by extracting host and index values.\n\thost := parsedUrl.Host\n\turlPathParts := strings.Split(parsedUrl.Path, \"/\")\n\tindex = urlPathParts[len(urlPathParts)-1]\n\n\t// force index specification in uri : ie no implicit index\n\tif host == \"\" || index == \"\" {\n\t\terr = new(ESUriErorr)\n\t}\n\n\treturn\n}\n\nfunc (p *ESPlugin) Init(URI string) {\n\tvar err error\n\n\terr, p.Index = parseURI(URI)\n\n\tif err != nil {\n\t\tlog.Fatal(\"Can't initialize ElasticSearch plugin.\", err)\n\t}\n\n\tp.eConn = elastigo.NewConn()\n\n\tp.eConn.SetFromUrl(URI)\n\n\tp.indexor = p.eConn.NewBulkIndexerErrors(50, 60)\n\tp.done = make(chan bool)\n\tp.indexor.Start()\n\n\tgo p.ErrorHandler()\n\n\tDebug(1, \"Initialized Elasticsearch Plugin\")\n\treturn\n}\n\nfunc (p *ESPlugin) IndexerShutdown() {\n\tp.indexor.Stop()\n\treturn\n}\n\nfunc (p *ESPlugin) ErrorHandler() {\n\tfor {\n\t\terrBuf := <-p.indexor.ErrorChannel\n\t\tDebug(1, \"[ELASTICSEARCH]\", errBuf.Err)\n\t}\n}\n\nfunc (p *ESPlugin) RttDurationToMs(d time.Duration) int64 {\n\tsec := d / time.Second\n\tnsec := d % time.Second\n\tfl := float64(sec) + float64(nsec)*1e-6\n\treturn int64(fl)\n}\n\n// ResponseAnalyze send req and resp to ES\nfunc (p *ESPlugin) ResponseAnalyze(req, resp []byte, start, stop time.Time) {\n\tif len(resp) == 0 {\n\t\t// nil http response - skipped elasticsearch export for this request\n\t\treturn\n\t}\n\tt := time.Now()\n\trtt := p.RttDurationToMs(stop.Sub(start))\n\n\tesResp := ESRequestResponse{\n\t\tReqURL:               string(proto.Path(req)),\n\t\tReqMethod:            string(proto.Method(req)),\n\t\tReqUserAgent:         string(proto.Header(req, []byte(\"User-Agent\"))),\n\t\tReqAcceptLanguage:    string(proto.Header(req, []byte(\"Accept-Language\"))),\n\t\tReqAccept:            string(proto.Header(req, []byte(\"Accept\"))),\n\t\tReqAcceptEncoding:    string(proto.Header(req, []byte(\"Accept-Encoding\"))),\n\t\tReqIfModifiedSince:   string(proto.Header(req, []byte(\"If-Modified-Since\"))),\n\t\tReqConnection:        string(proto.Header(req, []byte(\"Connection\"))),\n\t\tReqCookies:           string(proto.Header(req, []byte(\"Cookie\"))),\n\t\tRespStatus:           string(proto.Status(resp)),\n\t\tRespStatusCode:       string(proto.Status(resp)),\n\t\tRespProto:            string(proto.Method(resp)),\n\t\tRespContentLength:    string(proto.Header(resp, []byte(\"Content-Length\"))),\n\t\tRespContentType:      string(proto.Header(resp, []byte(\"Content-Type\"))),\n\t\tRespTransferEncoding: string(proto.Header(resp, []byte(\"Transfer-Encoding\"))),\n\t\tRespContentEncoding:  string(proto.Header(resp, []byte(\"Content-Encoding\"))),\n\t\tRespExpires:          string(proto.Header(resp, []byte(\"Expires\"))),\n\t\tRespCacheControl:     string(proto.Header(resp, []byte(\"Cache-Control\"))),\n\t\tRespVary:             string(proto.Header(resp, []byte(\"Vary\"))),\n\t\tRespSetCookie:        string(proto.Header(resp, []byte(\"Set-Cookie\"))),\n\t\tRtt:                  rtt,\n\t\tTimestamp:            t,\n\t}\n\tj, err := json.Marshal(&esResp)\n\tif err != nil {\n\t\tDebug(0, \"[ELASTIC-RESPONSE]\", err)\n\t} else {\n\t\tp.indexor.Index(p.Index, \"RequestResponse\", \"\", \"\", \"\", &t, j)\n\t}\n\treturn\n}\n"
        },
        {
          "name": "elasticsearch_test.go",
          "type": "blob",
          "size": 3.4169921875,
          "content": "package goreplay\n\nimport (\n\t\"testing\"\n)\n\nconst expectedIndex = \"gor\"\n\nfunc assertExpectedGorIndex(index string, t *testing.T) {\n\tif expectedIndex != index {\n\t\tt.Fatalf(\"Expected index %s but got %s\", expectedIndex, index)\n\t}\n}\n\nfunc assertExpectedIndex(expectedIndex string, index string, t *testing.T) {\n\tif expectedIndex != index {\n\t\tt.Fatalf(\"Expected index %s but got %s\", expectedIndex, index)\n\t}\n}\n\nfunc assertExpectedError(returnedError error, t *testing.T) {\n\texpectedError := new(ESUriErorr)\n\n\tif expectedError != returnedError {\n\t\tt.Errorf(\"Expected err %s but got %s\", expectedError, returnedError)\n\t}\n}\n\nfunc assertNoError(returnedError error, t *testing.T) {\n\tif nil != returnedError {\n\t\tt.Errorf(\"Expected no err but got %s\", returnedError)\n\t}\n}\n\n// Argument host:port/index_name\n// i.e : localhost:9200/gor\n// Fail because scheme is mandatory\nfunc TestElasticConnectionBuildFailWithoutScheme(t *testing.T) {\n\turi := \"localhost:9200/\" + expectedIndex\n\n\terr, _ := parseURI(uri)\n\tassertExpectedError(err, t)\n}\n\n// Argument scheme://Host:port\n// i.e : http://localhost:9200\n// Fail : explicit index is required\nfunc TestElasticConnectionBuildFailWithoutIndex(t *testing.T) {\n\turi := \"http://localhost:9200\"\n\n\terr, index := parseURI(uri)\n\n\tassertExpectedIndex(\"\", index, t)\n\n\tassertExpectedError(err, t)\n}\n\n// Argument scheme://Host/index_name\n// i.e : http://localhost/gor\nfunc TestElasticConnectionBuildFailWithoutPort(t *testing.T) {\n\turi := \"http://localhost/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:port/index_name\n// i.e : http://localhost:9200/gor\nfunc TestElasticLocalConnectionBuild(t *testing.T) {\n\turi := \"http://localhost:9200/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:port/index_name\n// i.e : http://localhost.local:9200/gor or https://localhost.local:9200/gor\nfunc TestElasticSimpleLocalWithSchemeConnectionBuild(t *testing.T) {\n\turi := \"http://localhost.local:9200/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:port/index_name\n// i.e : http://localhost.local:9200/gor or https://localhost.local:9200/gor\nfunc TestElasticSimpleLocalWithHTTPSConnectionBuild(t *testing.T) {\n\turi := \"https://localhost.local:9200/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:port/index_name\n// i.e : localhost.local:9200/pathtoElastic/gor\nfunc TestElasticLongPathConnectionBuild(t *testing.T) {\n\turi := \"http://localhost.local:9200/pathtoElastic/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:userinfo@port/index_name\n// i.e : http://user:password@localhost.local:9200/gor\nfunc TestElasticBasicAuthConnectionBuild(t *testing.T) {\n\turi := \"http://user:password@localhost.local:9200/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n\n// Argument scheme://Host:port/path/index_name\n// i.e : http://localhost.local:9200/path/gor or https://localhost.local:9200/path/gor\nfunc TestElasticComplexPathConnectionBuild(t *testing.T) {\n\turi := \"http://localhost.local:9200/path/\" + expectedIndex\n\n\terr, index := parseURI(uri)\n\n\tassertNoError(err, t)\n\n\tassertExpectedGorIndex(index, t)\n}\n"
        },
        {
          "name": "emitter.go",
          "type": "blob",
          "size": 3.81640625,
          "content": "package goreplay\n\nimport (\n\t\"fmt\"\n\t\"github.com/buger/goreplay/internal/byteutils\"\n\t\"hash/fnv\"\n\t\"io\"\n\t\"log\"\n\t\"sync\"\n\n\t\"github.com/coocood/freecache\"\n)\n\n// Emitter represents an abject to manage plugins communication\ntype Emitter struct {\n\tsync.WaitGroup\n\tplugins *InOutPlugins\n}\n\n// NewEmitter creates and initializes new Emitter object.\nfunc NewEmitter() *Emitter {\n\treturn &Emitter{}\n}\n\n// Start initialize loop for sending data from inputs to outputs\nfunc (e *Emitter) Start(plugins *InOutPlugins, middlewareCmd string) {\n\tif Settings.CopyBufferSize < 1 {\n\t\tSettings.CopyBufferSize = 5 << 20\n\t}\n\te.plugins = plugins\n\n\tif middlewareCmd != \"\" {\n\t\tmiddleware := NewMiddleware(middlewareCmd)\n\n\t\tfor _, in := range plugins.Inputs {\n\t\t\tmiddleware.ReadFrom(in)\n\t\t}\n\n\t\te.plugins.Inputs = append(e.plugins.Inputs, middleware)\n\t\te.plugins.All = append(e.plugins.All, middleware)\n\t\te.Add(1)\n\t\tgo func() {\n\t\t\tdefer e.Done()\n\t\t\tif err := CopyMulty(middleware, plugins.Outputs...); err != nil {\n\t\t\t\tDebug(2, fmt.Sprintf(\"[EMITTER] error during copy: %q\", err))\n\t\t\t}\n\t\t}()\n\t} else {\n\t\tfor _, in := range plugins.Inputs {\n\t\t\te.Add(1)\n\t\t\tgo func(in PluginReader) {\n\t\t\t\tdefer e.Done()\n\t\t\t\tif err := CopyMulty(in, plugins.Outputs...); err != nil {\n\t\t\t\t\tDebug(2, fmt.Sprintf(\"[EMITTER] error during copy: %q\", err))\n\t\t\t\t}\n\t\t\t}(in)\n\t\t}\n\t}\n}\n\n// Close closes all the goroutine and waits for it to finish.\nfunc (e *Emitter) Close() {\n\tfor _, p := range e.plugins.All {\n\t\tif cp, ok := p.(io.Closer); ok {\n\t\t\tcp.Close()\n\t\t}\n\t}\n\tif len(e.plugins.All) > 0 {\n\t\t// wait for everything to stop\n\t\te.Wait()\n\t}\n\te.plugins.All = nil // avoid Close to make changes again\n}\n\n// CopyMulty copies from 1 reader to multiple writers\nfunc CopyMulty(src PluginReader, writers ...PluginWriter) error {\n\twIndex := 0\n\tmodifier := NewHTTPModifier(&Settings.ModifierConfig)\n\tfilteredRequests := freecache.NewCache(200 * 1024 * 1024) // 200M\n\n\tfor {\n\t\tmsg, err := src.PluginRead()\n\t\tif err != nil {\n\t\t\tif err == ErrorStopped || err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tif msg != nil && len(msg.Data) > 0 {\n\t\t\tif len(msg.Data) > int(Settings.CopyBufferSize) {\n\t\t\t\tmsg.Data = msg.Data[:Settings.CopyBufferSize]\n\t\t\t}\n\t\t\tmeta := payloadMeta(msg.Meta)\n\t\t\tif len(meta) < 3 {\n\t\t\t\tDebug(2, fmt.Sprintf(\"[EMITTER] Found malformed record %q from %q\", msg.Meta, src))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\trequestID := meta[1]\n\t\t\t// start a subroutine only when necessary\n\t\t\tif Settings.Verbose >= 3 {\n\t\t\t\tDebug(3, \"[EMITTER] input: \", byteutils.SliceToString(msg.Meta[:len(msg.Meta)-1]), \" from: \", src)\n\t\t\t}\n\t\t\tif modifier != nil {\n\t\t\t\tDebug(3, \"[EMITTER] modifier:\", requestID, \"from:\", src)\n\t\t\t\tif isRequestPayload(msg.Meta) {\n\t\t\t\t\tmsg.Data = modifier.Rewrite(msg.Data)\n\t\t\t\t\t// If modifier tells to skip request\n\t\t\t\t\tif len(msg.Data) == 0 {\n\t\t\t\t\t\tfilteredRequests.Set(requestID, []byte{}, 60) //\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tDebug(3, \"[EMITTER] Rewritten input:\", requestID, \"from:\", src)\n\n\t\t\t\t} else {\n\t\t\t\t\t_, err := filteredRequests.Get(requestID)\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tfilteredRequests.Del(requestID)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif Settings.PrettifyHTTP {\n\t\t\t\tmsg.Data = prettifyHTTP(msg.Data)\n\t\t\t\tif len(msg.Data) == 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif Settings.SplitOutput {\n\t\t\t\tif Settings.RecognizeTCPSessions {\n\t\t\t\t\tif !PRO {\n\t\t\t\t\t\tlog.Fatal(\"Detailed TCP sessions work only with PRO license\")\n\t\t\t\t\t}\n\t\t\t\t\thasher := fnv.New32a()\n\t\t\t\t\thasher.Write(meta[1])\n\n\t\t\t\t\twIndex = int(hasher.Sum32()) % len(writers)\n\t\t\t\t\tif _, err := writers[wIndex].PluginWrite(msg); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// Simple round robin\n\t\t\t\t\tif _, err := writers[wIndex].PluginWrite(msg); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\twIndex = (wIndex + 1) % len(writers)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor _, dst := range writers {\n\t\t\t\t\tif _, err := dst.PluginWrite(msg); err != nil && err != io.ErrClosedPipe {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "emitter_test.go",
          "type": "blob",
          "size": 5.205078125,
          "content": "package goreplay\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestMain(m *testing.M) {\n\tPRO = true\n\tcode := m.Run()\n\tos.Exit(code)\n}\n\nfunc TestEmitter(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 1000; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc TestEmitterFiltered(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\tinput.skipHeader = true\n\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\tmethods := HTTPMethods{[]byte(\"GET\")}\n\tSettings.ModifierConfig = HTTPModifierConfig{Methods: methods}\n\n\temitter := &Emitter{}\n\tgo emitter.Start(plugins, \"\")\n\n\twg.Add(2)\n\n\tid := uuid()\n\treqh := payloadHeader(RequestPayload, id, time.Now().UnixNano(), -1)\n\treqb := append(reqh, []byte(\"POST / HTTP/1.1\\r\\nHost: www.w3.org\\r\\nUser-Agent: Go 1.1 package http\\r\\nAccept-Encoding: gzip\\r\\n\\r\\n\")...)\n\n\tresh := payloadHeader(ResponsePayload, id, time.Now().UnixNano()+1, 1)\n\trespb := append(resh, []byte(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")...)\n\n\tinput.EmitBytes(reqb)\n\tinput.EmitBytes(respb)\n\n\tid = uuid()\n\treqh = payloadHeader(RequestPayload, id, time.Now().UnixNano(), -1)\n\treqb = append(reqh, []byte(\"GET / HTTP/1.1\\r\\nHost: www.w3.org\\r\\nUser-Agent: Go 1.1 package http\\r\\nAccept-Encoding: gzip\\r\\n\\r\\n\")...)\n\n\tresh = payloadHeader(ResponsePayload, id, time.Now().UnixNano()+1, 1)\n\trespb = append(resh, []byte(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")...)\n\n\tinput.EmitBytes(reqb)\n\tinput.EmitBytes(respb)\n\n\twg.Wait()\n\temitter.Close()\n\n\tSettings.ModifierConfig = HTTPModifierConfig{}\n}\n\nfunc TestEmitterSplitRoundRobin(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\n\tvar counter1, counter2 int32\n\n\toutput1 := NewTestOutput(func(*Message) {\n\t\tatomic.AddInt32(&counter1, 1)\n\t\twg.Done()\n\t})\n\n\toutput2 := NewTestOutput(func(*Message) {\n\t\tatomic.AddInt32(&counter2, 1)\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output1, output2},\n\t}\n\n\tSettings.SplitOutput = true\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 1000; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\n\temitter.Close()\n\n\tif counter1 == 0 || counter2 == 0 || counter1 != counter2 {\n\t\tt.Errorf(\"Round robin should split traffic equally: %d vs %d\", counter1, counter2)\n\t}\n\n\tSettings.SplitOutput = false\n}\n\nfunc TestEmitterRoundRobin(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\n\tvar counter1, counter2 int32\n\n\toutput1 := NewTestOutput(func(*Message) {\n\t\tcounter1++\n\t\twg.Done()\n\t})\n\n\toutput2 := NewTestOutput(func(*Message) {\n\t\tcounter2++\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output1, output2},\n\t}\n\tplugins.All = append(plugins.All, input, output1, output2)\n\n\tSettings.SplitOutput = true\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 1000; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n\n\tif counter1 == 0 || counter2 == 0 {\n\t\tt.Errorf(\"Round robin should split traffic equally: %d vs %d\", counter1, counter2)\n\t}\n\n\tSettings.SplitOutput = false\n}\n\nfunc TestEmitterSplitSession(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\twg.Add(200)\n\n\tinput := NewTestInput()\n\tinput.skipHeader = true\n\n\tvar counter1, counter2 int32\n\n\toutput1 := NewTestOutput(func(msg *Message) {\n\t\tif payloadID(msg.Meta)[0] == 'a' {\n\t\t\tcounter1++\n\t\t}\n\t\twg.Done()\n\t})\n\n\toutput2 := NewTestOutput(func(msg *Message) {\n\t\tif payloadID(msg.Meta)[0] == 'b' {\n\t\t\tcounter2++\n\t\t}\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output1, output2},\n\t}\n\n\tSettings.SplitOutput = true\n\tSettings.RecognizeTCPSessions = true\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 200; i++ {\n\t\t// Keep session but randomize\n\t\tid := make([]byte, 20)\n\t\tif i&1 == 0 { // for recognizeTCPSessions one should be odd and other will be even number\n\t\t\tid[0] = 'a'\n\t\t} else {\n\t\t\tid[0] = 'b'\n\t\t}\n\t\tinput.EmitBytes([]byte(fmt.Sprintf(\"1 %s 1 1\\nGET / HTTP/1.1\\r\\n\\r\\n\", id[:20])))\n\t}\n\n\twg.Wait()\n\n\tif counter1 != counter2 {\n\t\tt.Errorf(\"Round robin should split traffic equally: %d vs %d\", counter1, counter2)\n\t}\n\n\tSettings.SplitOutput = false\n\tSettings.RecognizeTCPSessions = false\n\temitter.Close()\n}\n\nfunc BenchmarkEmitter(b *testing.B) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 3.42578125,
          "content": "module github.com/buger/goreplay\n\ngo 1.21\n\nrequire (\n\tgithub.com/Shopify/sarama v1.38.1\n\tgithub.com/aws/aws-sdk-go v1.44.262\n\tgithub.com/coocood/freecache v1.2.3\n\tgithub.com/google/gopacket v1.1.20-0.20210429153827-3eaba0894325\n\tgithub.com/gorilla/websocket v1.5.0\n\tgithub.com/klauspost/compress v1.16.5 // indirect\n\tgithub.com/mattbaird/elastigo v0.0.0-20170123220020-2fe47fd29e4b\n\tgithub.com/stretchr/testify v1.8.2\n\tgithub.com/xdg-go/scram v1.1.2\n\tgolang.org/x/net v0.10.0\n\tgolang.org/x/sys v0.8.0\n\tk8s.io/apimachinery v0.27.1\n\tk8s.io/client-go v0.27.1\n)\n\nrequire (\n\tgithub.com/araddon/gou v0.0.0-20211019181548-e7d08105776c // indirect\n\tgithub.com/bitly/go-hostpool v0.1.0 // indirect\n\tgithub.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/eapache/go-resiliency v1.3.0 // indirect\n\tgithub.com/eapache/go-xerial-snappy v0.0.0-20230111030713-bf00bc1b83b6 // indirect\n\tgithub.com/eapache/queue v1.1.0 // indirect\n\tgithub.com/emicklei/go-restful/v3 v3.10.2 // indirect\n\tgithub.com/go-logr/logr v1.2.4 // indirect\n\tgithub.com/go-openapi/jsonpointer v0.19.6 // indirect\n\tgithub.com/go-openapi/jsonreference v0.20.2 // indirect\n\tgithub.com/go-openapi/swag v0.22.3 // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/golang/protobuf v1.5.3 // indirect\n\tgithub.com/golang/snappy v0.0.4 // indirect\n\tgithub.com/google/gnostic v0.6.9 // indirect\n\tgithub.com/google/go-cmp v0.5.9 // indirect\n\tgithub.com/google/gofuzz v1.2.0 // indirect\n\tgithub.com/google/uuid v1.3.0 // indirect\n\tgithub.com/hashicorp/errwrap v1.1.0 // indirect\n\tgithub.com/hashicorp/go-multierror v1.1.1 // indirect\n\tgithub.com/hashicorp/go-uuid v1.0.3 // indirect\n\tgithub.com/jcmturner/aescts/v2 v2.0.0 // indirect\n\tgithub.com/jcmturner/dnsutils/v2 v2.0.0 // indirect\n\tgithub.com/jcmturner/gofork v1.7.6 // indirect\n\tgithub.com/jcmturner/gokrb5/v8 v8.4.4 // indirect\n\tgithub.com/jcmturner/rpc/v2 v2.0.3 // indirect\n\tgithub.com/jmespath/go-jmespath v0.4.0 // indirect\n\tgithub.com/josharian/intern v1.0.0 // indirect\n\tgithub.com/json-iterator/go v1.1.12 // indirect\n\tgithub.com/mailru/easyjson v0.7.7 // indirect\n\tgithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect\n\tgithub.com/modern-go/reflect2 v1.0.2 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/pierrec/lz4/v4 v4.1.17 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 // indirect\n\tgithub.com/smartystreets/goconvey v1.7.2 // indirect\n\tgithub.com/xdg-go/pbkdf2 v1.0.0 // indirect\n\tgithub.com/xdg-go/stringprep v1.0.4 // indirect\n\tgolang.org/x/crypto v0.9.0 // indirect\n\tgolang.org/x/oauth2 v0.8.0 // indirect\n\tgolang.org/x/term v0.8.0 // indirect\n\tgolang.org/x/text v0.9.0 // indirect\n\tgolang.org/x/time v0.3.0 // indirect\n\tgoogle.golang.org/appengine v1.6.7 // indirect\n\tgoogle.golang.org/protobuf v1.30.0 // indirect\n\tgopkg.in/inf.v0 v0.9.1 // indirect\n\tgopkg.in/yaml.v2 v2.4.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n\tk8s.io/api v0.27.1 // indirect\n\tk8s.io/klog/v2 v2.100.1 // indirect\n\tk8s.io/kube-openapi v0.0.0-20230501164219-8b0f38b5fd1f // indirect\n\tk8s.io/utils v0.0.0-20230505201702-9f6742963106 // indirect\n\tsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd // indirect\n\tsigs.k8s.io/structured-merge-diff/v4 v4.2.3 // indirect\n\tsigs.k8s.io/yaml v1.3.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 35.486328125,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=\ngithub.com/Shopify/sarama v1.38.1 h1:lqqPUPQZ7zPqYlWpTh+LQ9bhYNu2xJL6k1SJN4WVe2A=\ngithub.com/Shopify/sarama v1.38.1/go.mod h1:iwv9a67Ha8VNa+TifujYoWGxWnu2kNVAQdSdZ4X2o5g=\ngithub.com/Shopify/toxiproxy/v2 v2.5.0 h1:i4LPT+qrSlKNtQf5QliVjdP08GyAH8+BUIc9gT0eahc=\ngithub.com/Shopify/toxiproxy/v2 v2.5.0/go.mod h1:yhM2epWtAmel9CB8r2+L+PCmhH6yH2pITaPAo7jxJl0=\ngithub.com/antihax/optional v1.0.0/go.mod h1:uupD/76wgC+ih3iEmQUL+0Ugr19nfwCT1kdvxnR2qWY=\ngithub.com/araddon/gou v0.0.0-20211019181548-e7d08105776c h1:XUqw//RExYoxW4Eie8MuKp8sEDAZI1gMHX/daUFgZww=\ngithub.com/araddon/gou v0.0.0-20211019181548-e7d08105776c/go.mod h1:ikc1XA58M+Rx7SEbf0bLJCfBkwayZ8T5jBo5FXK8Uz8=\ngithub.com/aws/aws-sdk-go v1.44.262 h1:gyXpcJptWoNkK+DiAiaBltlreoWKQXjAIh6FRh60F+I=\ngithub.com/aws/aws-sdk-go v1.44.262/go.mod h1:aVsgQcEevwlmQ7qHE9I3h+dtQgpqhFB+i8Phjh7fkwI=\ngithub.com/bitly/go-hostpool v0.1.0 h1:XKmsF6k5el6xHG3WPJ8U0Ku/ye7njX7W81Ng7O2ioR0=\ngithub.com/bitly/go-hostpool v0.1.0/go.mod h1:4gOCgp6+NZnVqlKyZ/iBZFTAJKembaVENUpMkpg42fw=\ngithub.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869 h1:DDGfHa7BWjL4YnC6+E63dPcxHo2sUxDIu8g3QgEJdRY=\ngithub.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869/go.mod h1:Ekp36dRnpXw/yCqJaO+ZrUyxD+3VXMFFr56k5XYrpB4=\ngithub.com/buger/jsonparser v1.1.1/go.mod h1:6RYKKt7H4d4+iWqouImQ9R2FZql3VbhNgx27UK13J/0=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=\ngithub.com/cespare/xxhash/v2 v2.1.2/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\ngithub.com/cncf/udpa/go v0.0.0-20201120205902-5459f2c99403/go.mod h1:WmhPx2Nbnhtbo57+VJT5O0JRkEi1Wbu0z5j0R8u5Hbk=\ngithub.com/cncf/xds/go v0.0.0-20210312221358-fbca930ec8ed/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/coocood/freecache v1.2.3 h1:lcBwpZrwBZRZyLk/8EMyQVXRiFl663cCuMOrjCALeto=\ngithub.com/coocood/freecache v1.2.3/go.mod h1:RBUWa/Cy+OHdfTGFEhEuE1pMCMX51Ncizj7rthiQ3vk=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/docopt/docopt-go v0.0.0-20180111231733-ee0de3bc6815/go.mod h1:WwZ+bS3ebgob9U8Nd0kOddGdZWjyMGR8Wziv+TBNwSE=\ngithub.com/eapache/go-resiliency v1.3.0 h1:RRL0nge+cWGlxXbUzJ7yMcq6w2XBEr19dCN6HECGaT0=\ngithub.com/eapache/go-resiliency v1.3.0/go.mod h1:5yPzW0MIvSe0JDsv0v+DvcjEv2FyD6iZYSs1ZI+iQho=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20230111030713-bf00bc1b83b6 h1:8yY/I9ndfrgrXUbOGObLHKBR4Fl3nZXwM2c7OYTT8hM=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20230111030713-bf00bc1b83b6/go.mod h1:YvSRo5mw33fLEx1+DlK6L2VV43tJt5Eyel9n9XBcR+0=\ngithub.com/eapache/queue v1.1.0 h1:YOEu7KNc61ntiQlcEeUIoDTJ2o8mQznoNvUhiigpIqc=\ngithub.com/eapache/queue v1.1.0/go.mod h1:6eCeP0CKFpHLu8blIFXhExK/dRa7WDZfr6jVFPTqq+I=\ngithub.com/emicklei/go-restful/v3 v3.10.2 h1:hIovbnmBTLjHXkqEBUz3HGpXZdM7ZrE9fJIZIqlJLqE=\ngithub.com/emicklei/go-restful/v3 v3.10.2/go.mod h1:6n3XBCmQQb25CM2LCACGz8ukIrRry+4bhvbpWn3mrbc=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.4/go.mod h1:6rpuAdCZL397s3pYoYcLgu1mIlRU8Am5FuJP05cCM98=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20201210154907-fd9021fe5dad/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210512163311-63b5d3c536b0/go.mod h1:hliV/p42l8fGbc6Y9bQ70uLwIvmJyVE5k4iMKlh8wCQ=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/flowstack/go-jsonschema v0.1.1/go.mod h1:yL7fNggx1o8rm9RlgXv7hTBWxdBM0rVwpMwimd3F3N0=\ngithub.com/fortytw2/leaktest v1.3.0 h1:u8491cBMTQ8ft8aeV+adlcytMZylmA5nnwwkRZjI8vw=\ngithub.com/fortytw2/leaktest v1.3.0/go.mod h1:jDsjWgpAGjm2CA7WthBh/CdZYEPF31XHquHwclZch5g=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/go-logr/logr v1.2.0/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.2.4 h1:g01GSCwiDw2xSZfjJ2/T9M+S6pFdcNtFYsp+Y43HYDQ=\ngithub.com/go-logr/logr v1.2.4/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-openapi/jsonpointer v0.19.6 h1:eCs3fxoIi3Wh6vtgmLTOjdhSpiqphQ+DaPn38N2ZdrE=\ngithub.com/go-openapi/jsonpointer v0.19.6/go.mod h1:osyAmYz/mB/C3I+WsTTSgw1ONzaLJoLCyoi6/zppojs=\ngithub.com/go-openapi/jsonreference v0.20.2 h1:3sVjiK66+uXK/6oQ8xgcRKcFgQ5KXa2KvnJRumpMGbE=\ngithub.com/go-openapi/jsonreference v0.20.2/go.mod h1:Bl1zwGIM8/wsvqjsOQLJ/SH+En5Ap4rVB5KVcIDZG2k=\ngithub.com/go-openapi/swag v0.22.3 h1:yMBqmnQ0gyZvEb/+KzuWZOXgllrXT4SADYbvDaXHv/g=\ngithub.com/go-openapi/swag v0.22.3/go.mod h1:UzaqsxGiab7freDnrUUra0MwWfN/q7tE4j+VcZ0yl14=\ngithub.com/go-task/slim-sprig v0.0.0-20210107165309-348f09dbbbc0 h1:p104kn46Q8WdvHunIJ9dAyjPVtrBPhSr3KT2yUst43I=\ngithub.com/go-task/slim-sprig v0.0.0-20210107165309-348f09dbbbc0/go.mod h1:fyg7847qk6SyHyPtNmDHnmrv/HOrqktSC+C9fM+CJOE=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.4.3/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/protobuf v1.5.3 h1:KhyjKVUg7Usr/dYsdSqoFveMYd5ko72D+zANwlG1mmg=\ngithub.com/golang/protobuf v1.5.3/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/gnostic v0.6.9 h1:ZK/5VhkoX835RikCHpSUJV9a+S3e1zLh59YnyWeBW+0=\ngithub.com/google/gnostic v0.6.9/go.mod h1:Nm8234We1lq6iB9OmlgNv3nH91XLLVZHCDayfA3xq+E=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.9 h1:O2Tfq5qg4qc4AmwVlvv0oLiVAGB7enBSJ2x2DqQFi38=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/gofuzz v1.2.0 h1:xRy4A+RhZaiKjJ1bPfwQ8sedCA+YS2YcCHW6ec7JMi0=\ngithub.com/google/gofuzz v1.2.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/gopacket v1.1.20-0.20210429153827-3eaba0894325 h1:YmIcZ5Var3BAQ64AW98Iiys5Ih4fiU0xK41+8isC5Ec=\ngithub.com/google/gopacket v1.1.20-0.20210429153827-3eaba0894325/go.mod h1:riddUzxTSBpJXk3qBHtYr4qOhFhT6k/1c0E3qkQjQpA=\ngithub.com/google/pprof v0.0.0-20210720184732-4bb14d4b1be1 h1:K6RDEckDVWvDI9JAJYCmNdQXq6neHJOYx3V6jnqNEec=\ngithub.com/google/pprof v0.0.0-20210720184732-4bb14d4b1be1/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/uuid v1.1.2/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.3.0 h1:t6JiXgmwXMjEs8VusXIJk2BXHsn+wx8BZdTaoZ5fu7I=\ngithub.com/google/uuid v1.3.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1 h1:EGx4pi6eqNxGaHF6qqu48+N2wcFQ5qg5FXgOdqsJ5d8=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gorilla/securecookie v1.1.1/go.mod h1:ra0sb63/xPlUeL+yeDciTfxMRAA+MP+HVt/4epWDjd4=\ngithub.com/gorilla/sessions v1.2.1/go.mod h1:dk2InVEVJ0sfLlnXv9EAgkf6ecYs/i80K/zI+bUmuGM=\ngithub.com/gorilla/websocket v1.5.0 h1:PPwGk2jz7EePpoHN/+ClbZu8SPxiqlu12wZP/3sWmnc=\ngithub.com/gorilla/websocket v1.5.0/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0/go.mod h1:BDjrQk3hbvj6Nolgz8mAMFbcEtjT1g+wF4CSlocrBnw=\ngithub.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=\ngithub.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/go-multierror v1.1.1 h1:H5DkEtf6CXdFp0N0Em5UCwQpXMWke8IA0+lD48awMYo=\ngithub.com/hashicorp/go-multierror v1.1.1/go.mod h1:iw975J/qwKPdAO1clOe2L8331t/9/fmwbPZ6JB6eMoM=\ngithub.com/hashicorp/go-uuid v1.0.2/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-uuid v1.0.3 h1:2gKiV6YVmrJ1i2CKKa9obLvRieoRGviZFL26PcT/Co8=\ngithub.com/hashicorp/go-uuid v1.0.3/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/jcmturner/aescts/v2 v2.0.0 h1:9YKLH6ey7H4eDBXW8khjYslgyqG2xZikXP0EQFKrle8=\ngithub.com/jcmturner/aescts/v2 v2.0.0/go.mod h1:AiaICIRyfYg35RUkr8yESTqvSy7csK90qZ5xfvvsoNs=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0 h1:lltnkeZGL0wILNvrNiVCR6Ro5PGU/SeBvVO/8c/iPbo=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0/go.mod h1:b0TnjGOvI/n42bZa+hmXL+kFJZsFT7G4t3HTlQ184QM=\ngithub.com/jcmturner/gofork v1.7.6 h1:QH0l3hzAU1tfT3rZCnW5zXl+orbkNMMRGJfdJjHVETg=\ngithub.com/jcmturner/gofork v1.7.6/go.mod h1:1622LH6i/EZqLloHfE7IeZ0uEJwMSUyQ/nDd82IeqRo=\ngithub.com/jcmturner/goidentity/v6 v6.0.1 h1:VKnZd2oEIMorCTsFBnJWbExfNN7yZr3EhJAxwOkZg6o=\ngithub.com/jcmturner/goidentity/v6 v6.0.1/go.mod h1:X1YW3bgtvwAXju7V3LCIMpY0Gbxyjn/mY9zx4tFonSg=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4 h1:x1Sv4HaTpepFkXbt2IkL29DXRf8sOfZXo8eRKh687T8=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4/go.mod h1:1btQEpgT6k+unzCwX1KdWMEwPPkkgBtP+F6aCACiMrs=\ngithub.com/jcmturner/rpc/v2 v2.0.3 h1:7FXXj8Ti1IaVFpSAziCZWNzbNuZmnvw/i6CqLNdWfZY=\ngithub.com/jcmturner/rpc/v2 v2.0.3/go.mod h1:VUJYCIDm3PVOEHw8sgt091/20OJjskO/YJki3ELg/Hc=\ngithub.com/jmespath/go-jmespath v0.4.0 h1:BEgLn5cpjn8UN1mAw4NjwDrS35OdebyEtFe+9YPoQUg=\ngithub.com/jmespath/go-jmespath v0.4.0/go.mod h1:T8mJZnbsbmF+m6zOOFylbeCJqk5+pHWvzYPziyZiYoo=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1 h1:shLQSRRSCCPj3f2gpwzGwWFoC7ycTf1rcQZHOlsJ6N8=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1/go.mod h1:L3OGu8Wl2/fWfCI6z80xFu9LTZmf1ZRjMHUOPmWr69U=\ngithub.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=\ngithub.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=\ngithub.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/jtolds/gls v4.20.0+incompatible h1:xdiiI2gbIgH/gLH7ADydsJ1uDOEzR8yvV7C0MuV77Wo=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/compress v1.16.5 h1:IFV2oUNUzZaz+XyusxpLzpzS8Pt5rh0Z16For/djlyI=\ngithub.com/klauspost/compress v1.16.5/go.mod h1:ntbaceVETuRiXiv4DpjP66DpAtAGkEQskQzEyD//IeE=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=\ngithub.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=\ngithub.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=\ngithub.com/mattbaird/elastigo v0.0.0-20170123220020-2fe47fd29e4b h1:v29yPGHhOqw7VHEnTeQFAth3SsBrmwc8JfuhNY0G34k=\ngithub.com/mattbaird/elastigo v0.0.0-20170123220020-2fe47fd29e4b/go.mod h1:5MWrJXKRQyhQdUCF+vu6U5c4nQpg70vW3eHaU0/AYbU=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/onsi/ginkgo/v2 v2.9.1 h1:zie5Ly042PD3bsCvsSOPvRnFwyo3rKe64TJlD6nu0mk=\ngithub.com/onsi/ginkgo/v2 v2.9.1/go.mod h1:FEcmzVcCHl+4o9bQZVab+4dC9+j+91t2FHSzmGAPfuo=\ngithub.com/onsi/gomega v1.27.4 h1:Z2AnStgsdSayCMDiCU42qIz+HLqEPcgiOCXjAU/w+8E=\ngithub.com/onsi/gomega v1.27.4/go.mod h1:riYq/GJKh8hhoM01HN6Vmuy93AarCXCBGpvFDK3q3fQ=\ngithub.com/pierrec/lz4/v4 v4.1.17 h1:kV4Ip+/hUBC+8T6+2EgburRtkE9ef4nbY3f4dFhGjMc=\ngithub.com/pierrec/lz4/v4 v4.1.17/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 h1:N/ElC8H3+5XpJzTSTfLsJV/mx9Q9g7kxmchpfZyxgzM=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=\ngithub.com/rogpeppe/fastuuid v1.2.0/go.mod h1:jVj6XXZzXRy/MSR5jhDC/2q6DgLz+nrA6LYCDYWNEvQ=\ngithub.com/rogpeppe/go-internal v1.10.0 h1:TMyTOH3F/DB16zRVcYyreMH6GnZZrwQVAoYjRBZyWFQ=\ngithub.com/rogpeppe/go-internal v1.10.0/go.mod h1:UQnix2H7Ngw/k4C5ijL5+65zddjncjaFoBhdsK/akog=\ngithub.com/smartystreets/assertions v1.2.0 h1:42S6lae5dvLc7BrLu/0ugRtcFVjoJNMC/N3yZFZkDFs=\ngithub.com/smartystreets/assertions v1.2.0/go.mod h1:tcbTF8ujkAEcZ8TElKY+i30BzYlVhC/LOxJk7iOWnoo=\ngithub.com/smartystreets/goconvey v1.7.2 h1:9RBaZCeXEQ3UselpuwUQHltGVXvdwm6cv1hgR6gDIPg=\ngithub.com/smartystreets/goconvey v1.7.2/go.mod h1:Vw0tHAZW6lzCRk3xgdin6fKYcG+G3Pg9vgXWeJpQFMM=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/stoewer/go-strcase v1.2.0/go.mod h1:IBiWB2sKIp3wVVQ3Y035++gc+knqhUQag1KpM8ahLw8=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.2 h1:+h33VjcLVPDHtOdpUCuF+7gSuG3yGIftsP1YvFihtJ8=\ngithub.com/stretchr/testify v1.8.2/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/vishvananda/netlink v1.1.0/go.mod h1:cTgwzPIzzgDAYoQrMm0EdrjRUBkTqKYppBueQtXaqoE=\ngithub.com/vishvananda/netns v0.0.0-20191106174202-0a2b9b5464df/go.mod h1:JP3t17pCcGlemwknint6hfoeCVQrEMVwxRLRjXpq+BU=\ngithub.com/vishvananda/netns v0.0.0-20210104183010-2eb08e3e575f/go.mod h1:DD4vA1DwXk04H54A1oHXtwZmA0grkVMdPxx/VGLCah0=\ngithub.com/xdg-go/pbkdf2 v1.0.0 h1:Su7DPu48wXMwC3bs7MCNG+z4FhcyEuz5dlvchbq0B0c=\ngithub.com/xdg-go/pbkdf2 v1.0.0/go.mod h1:jrpuAogTd400dnrH08LKmI/xc1MbPOebTwRqcT5RDeI=\ngithub.com/xdg-go/scram v1.1.2 h1:FHX5I5B4i4hKRVRBCFRxq1iQRej7WO3hhBuJf+UUySY=\ngithub.com/xdg-go/scram v1.1.2/go.mod h1:RT/sEzTbU5y00aCK8UOx6R7YryM0iF1N2MOmC3kKLN4=\ngithub.com/xdg-go/stringprep v1.0.4 h1:XLI/Ng3O1Atzq0oBs3TWm+5ZVgkq2aqdlvP9JtoZ6c8=\ngithub.com/xdg-go/stringprep v1.0.4/go.mod h1:mPGuuIYwz7CmR2bT9j4GbQqutWS1zV24gijq1dTyGkM=\ngithub.com/xeipuuv/gojsonpointer v0.0.0-20180127040702-4e3ac2762d5f/go.mod h1:N2zxlSyiKSe5eX1tZViRH5QA0qijqEDrYZiPEAiq3wU=\ngithub.com/xeipuuv/gojsonreference v0.0.0-20180127040603-bd5ef7bd5415/go.mod h1:GwrjFmJcFw6At/Gs6z4yjiIwzuJ1/+UwLxMQDVQXShQ=\ngithub.com/xeipuuv/gojsonschema v1.2.0/go.mod h1:anYRn/JVcOK2ZgGU+IjEV4nwlhoK5sQluxsYJ78Id3Y=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngo.opentelemetry.io/proto/otlp v0.7.0/go.mod h1:PqfVotwruBrMGOCsRd/89rSnXhoiJIqeYNgFYFoEGnI=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.6.0/go.mod h1:OFC/31mSvZgRz0V1QTNCzfAI1aIRzbiufJtkMIlEp58=\ngolang.org/x/crypto v0.9.0 h1:LF6fAI+IutBocDJ2OT0Q1g8plpYljMZ4+lty+dsqw3g=\ngolang.org/x/crypto v0.9.0/go.mod h1:yrmDGqONDYtNj3tH8X9dzUun2m2lzPa9ngI6/RUPGR0=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200114155413-6afb5195e5aa/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\ngolang.org/x/net v0.0.0-20210805182204-aaa1db679c0d/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.1.0/go.mod h1:Cx3nUiGt4eDBEyega/BKRp+/AlGL8hYe7U9odMt2Cco=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.7.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.10.0 h1:X2//UzNDwYmtCLn7To6G58Wr6f5ahEAQgKNzv9Y951M=\ngolang.org/x/net v0.10.0/go.mod h1:0qNGK6F8kojg2nk9dLZ2mShWaEBan6FAoqfSigmmuDg=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.8.0 h1:6dkIjl3j3LtZ/O3sTgZTMsLKSftL/B8Zgq4huOIIUu8=\ngolang.org/x/oauth2 v0.8.0/go.mod h1:yr7u4HXZRm1R1kBWqr/xKNqewf0plRYoB7sla+BCIXE=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0 h1:wsuoTGHzEhffawBOhz5CYhcrV4IdKZbEyZjBMuTp12o=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606203320-7fc4e5ec1444/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200217220822-9197077df867/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.1.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.8.0 h1:EBmGv8NaZBZTWvrbjNoL6HVt+IVy3QDQpJs7VRIw3tU=\ngolang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.1.0/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.8.0 h1:n5xxQn2i3PC0yLAbjTpNT85q/Kgzcr2gIoX9OrJUols=\ngolang.org/x/term v0.8.0/go.mod h1:xPskH00ivmX89bAKVGSKKtLOWNx2+17Eiy94tnKShWo=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.5/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.3.8/go.mod h1:E6s5w1FMmriuDzIBO73fBruAKo1PCIq6d2Q6DHfQ8WQ=\ngolang.org/x/text v0.4.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.9.0 h1:2sjJmO8cDvYveuX97RDLsxlyUxLl+GHoLxBiRdHllBE=\ngolang.org/x/text v0.9.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=\ngolang.org/x/time v0.3.0 h1:rg5rLMjNzMS1RkNLzCG38eapWhnYLFYXDXj2gOlr8j4=\ngolang.org/x/time v0.3.0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190328211700-ab21143f2384/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.7.0 h1:W4OVu8VVOaIO0yzWMNdepAulS7YfoS3Zabrm8DOXXU4=\ngolang.org/x/tools v0.7.0/go.mod h1:4pg6aUX35JBAogB10C9AtvVL+qowtN4pT3CGSQex14s=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.7 h1:FZR1q0exgwxzPzp/aF+VccGrSfxfPpkBqjIIEq3ru6c=\ngoogle.golang.org/appengine v1.6.7/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20200513103714-09dca8ec2884/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/genproto v0.0.0-20220107163113-42d7afdf6368/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.33.1/go.mod h1:fr5YgcSWrqhRRxogOsw7RzIpsmvOZ6IcH4kBYTpR3n0=\ngoogle.golang.org/grpc v1.36.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.40.0/go.mod h1:ogyxbiOoUXAkP+4+xa6PZSE9DZgIHtSpzjDTB9KAK34=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.27.1/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.30.0 h1:kPPoIgf3TsEvrm0PFe15JQ+570QVxYzEvvHqChK+cng=\ngoogle.golang.org/protobuf v1.30.0/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/inf.v0 v0.9.1 h1:73M5CoZyi3ZLMOyDlQh031Cx6N9NDJ2Vvfl76EDAgDc=\ngopkg.in/inf.v0 v0.9.1/go.mod h1:cWUDdTG/fYaXco+Dcufb5Vnc6Gp2YChqWtbxRZE0mXw=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20200615113413-eeeca48fe776/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nk8s.io/api v0.27.1 h1:Z6zUGQ1Vd10tJ+gHcNNNgkV5emCyW+v2XTmn+CLjSd0=\nk8s.io/api v0.27.1/go.mod h1:z5g/BpAiD+f6AArpqNjkY+cji8ueZDU/WV1jcj5Jk4E=\nk8s.io/apimachinery v0.27.1 h1:EGuZiLI95UQQcClhanryclaQE6xjg1Bts6/L3cD7zyc=\nk8s.io/apimachinery v0.27.1/go.mod h1:5ikh59fK3AJ287GUvpUsryoMFtH9zj/ARfWCo3AyXTM=\nk8s.io/client-go v0.27.1 h1:oXsfhW/qncM1wDmWBIuDzRHNS2tLhK3BZv512Nc59W8=\nk8s.io/client-go v0.27.1/go.mod h1:f8LHMUkVb3b9N8bWturc+EDtVVVwZ7ueTVquFAJb2vA=\nk8s.io/klog/v2 v2.100.1 h1:7WCHKK6K8fNhTqfBhISHQ97KrnJNFZMcQvKp7gP/tmg=\nk8s.io/klog/v2 v2.100.1/go.mod h1:y1WjHnz7Dj687irZUWR/WLkLc5N1YHtjLdmgWjndZn0=\nk8s.io/kube-openapi v0.0.0-20230501164219-8b0f38b5fd1f h1:2kWPakN3i/k81b0gvD5C5FJ2kxm1WrQFanWchyKuqGg=\nk8s.io/kube-openapi v0.0.0-20230501164219-8b0f38b5fd1f/go.mod h1:byini6yhqGC14c3ebc/QwanvYwhuMWF6yz2F8uwW8eg=\nk8s.io/utils v0.0.0-20230505201702-9f6742963106 h1:EObNQ3TW2D+WptiYXlApGNLVy0zm/JIBVY9i+M4wpAU=\nk8s.io/utils v0.0.0-20230505201702-9f6742963106/go.mod h1:OLgZIPagt7ERELqWJFomSt595RzquPNLL48iOWgYOg0=\nsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd h1:EDPBXCAspyGV4jQlpZSudPeMmr1bNJefnuqLsRAsHZo=\nsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd/go.mod h1:B8JuhiUyNFVKdsE8h686QcCxMaH6HrOAZj4vswFpcB0=\nsigs.k8s.io/structured-merge-diff/v4 v4.2.3 h1:PRbqxJClWWYMNV1dhaG4NsibJbArud9kFxnAMREiWFE=\nsigs.k8s.io/structured-merge-diff/v4 v4.2.3/go.mod h1:qjx8mGObPmV2aSZepjQjbmb2ihdVs8cGKBraizNC69E=\nsigs.k8s.io/yaml v1.3.0 h1:a2VclLzOGrwOHDiV8EfBGhvjHvP46CtW5j6POvhYGGo=\nsigs.k8s.io/yaml v1.3.0/go.mod h1:GeOyir5tyXNByN85N/dRIT9es5UQNerPYEKK56eTBm8=\n"
        },
        {
          "name": "gor_stat.go",
          "type": "blob",
          "size": 1.1630859375,
          "content": "package goreplay\n\nimport (\n\t\"runtime\"\n\t\"strconv\"\n\t\"time\"\n)\n\ntype GorStat struct {\n\tstatName string\n\trateMs   int\n\tlatest   int\n\tmean     int\n\tmax      int\n\tcount    int\n}\n\nfunc NewGorStat(statName string, rateMs int) (s *GorStat) {\n\ts = new(GorStat)\n\ts.statName = statName\n\ts.rateMs = rateMs\n\ts.latest = 0\n\ts.mean = 0\n\ts.max = 0\n\ts.count = 0\n\n\tif Settings.Stats {\n\t\tgo s.reportStats()\n\t}\n\treturn\n}\n\nfunc (s *GorStat) Write(latest int) {\n\tif Settings.Stats {\n\t\tif latest > s.max {\n\t\t\ts.max = latest\n\t\t}\n\t\tif latest != 0 {\n\t\t\ts.mean = ((s.mean * s.count) + latest) / (s.count + 1)\n\t\t}\n\t\ts.latest = latest\n\t\ts.count = s.count + 1\n\t}\n}\n\nfunc (s *GorStat) Reset() {\n\ts.latest = 0\n\ts.max = 0\n\ts.mean = 0\n\ts.count = 0\n}\n\nfunc (s *GorStat) String() string {\n\treturn s.statName + \":\" + strconv.Itoa(s.latest) + \",\" + strconv.Itoa(s.mean) + \",\" + strconv.Itoa(s.max) + \",\" + strconv.Itoa(s.count) + \",\" + strconv.Itoa(s.count/(s.rateMs/1000.0)) + \",\" + strconv.Itoa(runtime.NumGoroutine())\n}\n\nfunc (s *GorStat) reportStats() {\n\tDebug(0, \"\\n\", s.statName+\":latest,mean,max,count,count/second,gcount\")\n\tfor {\n\t\tDebug(0, \"\\n\", s)\n\t\ts.Reset()\n\t\ttime.Sleep(time.Duration(s.rateMs) * time.Millisecond)\n\t}\n}\n"
        },
        {
          "name": "homebrew",
          "type": "tree",
          "content": null
        },
        {
          "name": "http_modifier.go",
          "type": "blob",
          "size": 3.876953125,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"encoding/base64\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"hash/fnv\"\n\t\"strings\"\n)\n\ntype HTTPModifier struct {\n\tconfig *HTTPModifierConfig\n}\n\nfunc NewHTTPModifier(config *HTTPModifierConfig) *HTTPModifier {\n\t// Optimization to skip modifier completely if we do not need it\n\tif len(config.URLRegexp) == 0 &&\n\t\tlen(config.URLNegativeRegexp) == 0 &&\n\t\tlen(config.URLRewrite) == 0 &&\n\t\tlen(config.HeaderRewrite) == 0 &&\n\t\tlen(config.HeaderFilters) == 0 &&\n\t\tlen(config.HeaderNegativeFilters) == 0 &&\n\t\tlen(config.HeaderBasicAuthFilters) == 0 &&\n\t\tlen(config.HeaderHashFilters) == 0 &&\n\t\tlen(config.ParamHashFilters) == 0 &&\n\t\tlen(config.Params) == 0 &&\n\t\tlen(config.Headers) == 0 &&\n\t\tlen(config.Methods) == 0 {\n\t\treturn nil\n\t}\n\n\treturn &HTTPModifier{config: config}\n}\n\nfunc (m *HTTPModifier) Rewrite(payload []byte) (response []byte) {\n\tif !proto.HasRequestTitle(payload) {\n\t\treturn payload\n\t}\n\n\tif len(m.config.Methods) > 0 {\n\t\tmethod := proto.Method(payload)\n\n\t\tmatched := false\n\n\t\tfor _, m := range m.config.Methods {\n\t\t\tif bytes.Equal(method, m) {\n\t\t\t\tmatched = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !matched {\n\t\t\treturn\n\t\t}\n\t}\n\n\tif len(m.config.Headers) > 0 {\n\t\tfor _, header := range m.config.Headers {\n\t\t\tpayload = proto.SetHeader(payload, []byte(header.Name), []byte(header.Value))\n\t\t}\n\t}\n\n\tif len(m.config.Params) > 0 {\n\t\tfor _, param := range m.config.Params {\n\t\t\tpayload = proto.SetPathParam(payload, param.Name, param.Value)\n\t\t}\n\t}\n\n\tif len(m.config.URLRegexp) > 0 {\n\t\tpath := proto.Path(payload)\n\n\t\tmatched := false\n\n\t\tfor _, f := range m.config.URLRegexp {\n\t\t\tif f.regexp.Match(path) {\n\t\t\t\tmatched = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !matched {\n\t\t\treturn\n\t\t}\n\t}\n\n\tif len(m.config.URLNegativeRegexp) > 0 {\n\t\tpath := proto.Path(payload)\n\n\t\tfor _, f := range m.config.URLNegativeRegexp {\n\t\t\tif f.regexp.Match(path) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.HeaderFilters) > 0 {\n\t\tfor _, f := range m.config.HeaderFilters {\n\t\t\tvalue := proto.Header(payload, f.name)\n\n\t\t\tif len(value) == 0 {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !f.regexp.Match(value) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.HeaderNegativeFilters) > 0 {\n\t\tfor _, f := range m.config.HeaderNegativeFilters {\n\t\t\tvalue := proto.Header(payload, f.name)\n\n\t\t\tif len(value) > 0 && f.regexp.Match(value) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.HeaderBasicAuthFilters) > 0 {\n\t\tfor _, f := range m.config.HeaderBasicAuthFilters {\n\t\t\tvalue := proto.Header(payload, []byte(\"Authorization\"))\n\n\t\t\tif len(value) > 0 {\n\t\t\t\tvalueString := string(value)\n\t\t\t\ttrimmedBasicAuthEncoded := strings.TrimPrefix(valueString, \"Basic \")\n\t\t\t\tif strings.Compare(valueString, trimmedBasicAuthEncoded) != 0 {\n\t\t\t\t\tdecodedAuth, _ := base64.StdEncoding.DecodeString(trimmedBasicAuthEncoded)\n\t\t\t\t\tif !f.regexp.Match(decodedAuth) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.HeaderHashFilters) > 0 {\n\t\tfor _, f := range m.config.HeaderHashFilters {\n\t\t\tvalue := proto.Header(payload, f.name)\n\n\t\t\tif len(value) > 0 {\n\t\t\t\thasher := fnv.New32a()\n\t\t\t\thasher.Write(value)\n\n\t\t\t\tif (hasher.Sum32() % 100) >= f.percent {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.ParamHashFilters) > 0 {\n\t\tfor _, f := range m.config.ParamHashFilters {\n\t\t\tvalue, s, _ := proto.PathParam(payload, f.name)\n\n\t\t\tif s != -1 {\n\t\t\t\thasher := fnv.New32a()\n\t\t\t\thasher.Write(value)\n\n\t\t\t\tif (hasher.Sum32() % 100) >= f.percent {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.URLRewrite) > 0 {\n\t\tpath := proto.Path(payload)\n\n\t\tfor _, f := range m.config.URLRewrite {\n\t\t\tif f.src.Match(path) {\n\t\t\t\tpath = f.src.ReplaceAll(path, f.target)\n\t\t\t\tpayload = proto.SetPath(payload, path)\n\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(m.config.HeaderRewrite) > 0 {\n\t\tfor _, f := range m.config.HeaderRewrite {\n\t\t\tvalue := proto.Header(payload, f.header)\n\t\t\tif len(value) == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tif f.src.Match(value) {\n\t\t\t\tnewValue := f.src.ReplaceAll(value, f.target)\n\t\t\t\tpayload = proto.SetHeader(payload, f.header, newValue)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn payload\n}\n"
        },
        {
          "name": "http_modifier_settings.go",
          "type": "blob",
          "size": 6.888671875,
          "content": "package goreplay\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// HTTPModifierConfig holds configuration options for built-in traffic modifier\ntype HTTPModifierConfig struct {\n\tURLNegativeRegexp      HTTPURLRegexp              `json:\"http-disallow-url\"`\n\tURLRegexp              HTTPURLRegexp              `json:\"http-allow-url\"`\n\tURLRewrite             URLRewriteMap              `json:\"http-rewrite-url\"`\n\tHeaderRewrite          HeaderRewriteMap           `json:\"http-rewrite-header\"`\n\tHeaderFilters          HTTPHeaderFilters          `json:\"http-allow-header\"`\n\tHeaderNegativeFilters  HTTPHeaderFilters          `json:\"http-disallow-header\"`\n\tHeaderBasicAuthFilters HTTPHeaderBasicAuthFilters `json:\"http-basic-auth-filter\"`\n\tHeaderHashFilters      HTTPHashFilters            `json:\"http-header-limiter\"`\n\tParamHashFilters       HTTPHashFilters            `json:\"http-param-limiter\"`\n\tParams                 HTTPParams                 `json:\"http-set-param\"`\n\tHeaders                HTTPHeaders                `json:\"http-set-header\"`\n\tMethods                HTTPMethods                `json:\"http-allow-method\"`\n}\n\n// Handling of --http-allow-header, --http-disallow-header options\ntype headerFilter struct {\n\tname   []byte\n\tregexp *regexp.Regexp\n}\n\n// HTTPHeaderFilters holds list of headers and their regexps\ntype HTTPHeaderFilters []headerFilter\n\nfunc (h *HTTPHeaderFilters) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPHeaderFilters) Set(value string) error {\n\tvalArr := strings.SplitN(value, \":\", 2)\n\tif len(valArr) < 2 {\n\t\treturn errors.New(\"need both header and value, colon-delimited (ex. user_id:^169$)\")\n\t}\n\tval := strings.TrimSpace(valArr[1])\n\tr, err := regexp.Compile(val)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t*h = append(*h, headerFilter{name: []byte(valArr[0]), regexp: r})\n\n\treturn nil\n}\n\n// Handling of --http-basic-auth-filter option\ntype basicAuthFilter struct {\n\tregexp *regexp.Regexp\n}\n\n// HTTPHeaderBasicAuthFilters holds list of regxp to match basic Auth header values\ntype HTTPHeaderBasicAuthFilters []basicAuthFilter\n\nfunc (h *HTTPHeaderBasicAuthFilters) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPHeaderBasicAuthFilters) Set(value string) error {\n\tr, err := regexp.Compile(value)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t*h = append(*h, basicAuthFilter{regexp: r})\n\n\treturn nil\n}\n\n// Handling of --http-allow-header-hash and --http-allow-param-hash options\ntype hashFilter struct {\n\tname    []byte\n\tpercent uint32\n}\n\n// HTTPHashFilters represents a slice of header hash filters\ntype HTTPHashFilters []hashFilter\n\nfunc (h *HTTPHashFilters) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPHashFilters) Set(value string) error {\n\tvalArr := strings.SplitN(value, \":\", 2)\n\tif len(valArr) < 2 {\n\t\treturn errors.New(\"need both header and value, colon-delimited (ex. user_id:50%)\")\n\t}\n\n\tf := hashFilter{name: []byte(valArr[0])}\n\n\tval := strings.TrimSpace(valArr[1])\n\n\tif strings.Contains(val, \"%\") {\n\t\tp, _ := strconv.ParseInt(val[:len(val)-1], 0, 0)\n\t\tf.percent = uint32(p)\n\t} else if strings.Contains(val, \"/\") {\n\t\t// DEPRECATED format\n\t\tvar num, den uint64\n\n\t\tfracArr := strings.Split(val, \"/\")\n\t\tnum, _ = strconv.ParseUint(fracArr[0], 10, 64)\n\t\tden, _ = strconv.ParseUint(fracArr[1], 10, 64)\n\n\t\tf.percent = uint32((float64(num) / float64(den)) * 100)\n\t} else {\n\t\treturn errors.New(\"Value should be percent and contain '%'\")\n\t}\n\n\t*h = append(*h, f)\n\n\treturn nil\n}\n\n// Handling of --http-set-header option\ntype httpHeader struct {\n\tName  string\n\tValue string\n}\n\n// HTTPHeaders is a slice of headers that must appended\ntype HTTPHeaders []httpHeader\n\nfunc (h *HTTPHeaders) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPHeaders) Set(value string) error {\n\tv := strings.SplitN(value, \":\", 2)\n\tif len(v) != 2 {\n\t\treturn errors.New(\"Expected `Key: Value`\")\n\t}\n\n\theader := httpHeader{\n\t\tstrings.TrimSpace(v[0]),\n\t\tstrings.TrimSpace(v[1]),\n\t}\n\n\t*h = append(*h, header)\n\treturn nil\n}\n\n// Handling of --http-set-param option\ntype httpParam struct {\n\tName  []byte\n\tValue []byte\n}\n\n// HTTPParams filters for --http-set-param\ntype HTTPParams []httpParam\n\nfunc (h *HTTPParams) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPParams) Set(value string) error {\n\tv := strings.SplitN(value, \"=\", 2)\n\tif len(v) != 2 {\n\t\treturn errors.New(\"Expected `Key=Value`\")\n\t}\n\n\tparam := httpParam{\n\t\t[]byte(strings.TrimSpace(v[0])),\n\t\t[]byte(strings.TrimSpace(v[1])),\n\t}\n\n\t*h = append(*h, param)\n\treturn nil\n}\n\n//\n// Handling of --http-allow-method option\n//\n\n// HTTPMethods holds values for method allowed\ntype HTTPMethods [][]byte\n\nfunc (h *HTTPMethods) String() string {\n\treturn fmt.Sprint(*h)\n}\n\n// Set method to implement flags.Value\nfunc (h *HTTPMethods) Set(value string) error {\n\t*h = append(*h, []byte(value))\n\treturn nil\n}\n\n// Handling of --http-rewrite-url option\ntype urlRewrite struct {\n\tsrc    *regexp.Regexp\n\ttarget []byte\n}\n\n// URLRewriteMap holds regexp and data to modify URL\ntype URLRewriteMap []urlRewrite\n\nfunc (r *URLRewriteMap) String() string {\n\treturn fmt.Sprint(*r)\n}\n\n// Set method to implement flags.Value\nfunc (r *URLRewriteMap) Set(value string) error {\n\tvalArr := strings.SplitN(value, \":\", 2)\n\tif len(valArr) < 2 {\n\t\treturn errors.New(\"need both src and target, colon-delimited (ex. /a:/b)\")\n\t}\n\tregexp, err := regexp.Compile(valArr[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\t*r = append(*r, urlRewrite{src: regexp, target: []byte(valArr[1])})\n\treturn nil\n}\n\n// Handling of --http-rewrite-header option\ntype headerRewrite struct {\n\theader []byte\n\tsrc    *regexp.Regexp\n\ttarget []byte\n}\n\n// HeaderRewriteMap holds regexp and data to rewrite headers\ntype HeaderRewriteMap []headerRewrite\n\nfunc (r *HeaderRewriteMap) String() string {\n\treturn fmt.Sprint(*r)\n}\n\n// Set method to implement flags.Value\nfunc (r *HeaderRewriteMap) Set(value string) error {\n\theaderArr := strings.SplitN(value, \":\", 2)\n\tif len(headerArr) < 2 {\n\t\treturn errors.New(\"need both header, regexp and rewrite target, colon-delimited (ex. Header: regexp,target)\")\n\t}\n\n\theader := headerArr[0]\n\tvalArr := strings.SplitN(strings.TrimSpace(headerArr[1]), \",\", 2)\n\n\tif len(valArr) < 2 {\n\t\treturn errors.New(\"need both header, regexp and rewrite target, colon-delimited (ex. Header: regexp,target)\")\n\t}\n\n\tregexp, err := regexp.Compile(valArr[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\t*r = append(*r, headerRewrite{header: []byte(header), src: regexp, target: []byte(valArr[1])})\n\treturn nil\n}\n\n// Handling of --http-allow-url option\ntype urlRegexp struct {\n\tregexp *regexp.Regexp\n}\n\n// HTTPURLRegexp a slice of regexp to match URLs\ntype HTTPURLRegexp []urlRegexp\n\nfunc (r *HTTPURLRegexp) String() string {\n\treturn fmt.Sprint(*r)\n}\n\n// Set method to implement flags.Value\nfunc (r *HTTPURLRegexp) Set(value string) error {\n\tregexp, err := regexp.Compile(value)\n\n\t*r = append(*r, urlRegexp{regexp: regexp})\n\n\treturn err\n}\n"
        },
        {
          "name": "http_modifier_settings_test.go",
          "type": "blob",
          "size": 1.2509765625,
          "content": "package goreplay\n\nimport (\n\t\"testing\"\n)\n\nfunc TestHTTPHeaderFilters(t *testing.T) {\n\tfilters := HTTPHeaderFilters{}\n\n\terr := filters.Set(\"Header1:^$\")\n\tif err != nil {\n\t\tt.Error(\"Should not error on Header1:^$\")\n\t}\n\n\terr = filters.Set(\"Header2:^:$\")\n\tif err != nil {\n\t\tt.Error(\"Should not error on Header2:^:$\")\n\t}\n\n\t// Missing colon\n\terr = filters.Set(\"Header3-^$\")\n\tif err == nil {\n\t\tt.Error(\"Should error on Header2:^:$\")\n\t}\n}\n\nfunc TestHTTPHashFilters(t *testing.T) {\n\tfilters := HTTPHashFilters{}\n\n\terr := filters.Set(\"Header1:1/2\")\n\tif err != nil {\n\t\tt.Error(\"Should support old syntax\")\n\t}\n\n\tif filters[0].percent != 50 {\n\t\tt.Error(\"Wrong percentage\", filters[0].percent)\n\t}\n\n\terr = filters.Set(\"Header2:1\")\n\tif err == nil {\n\t\tt.Error(\"Should error on Header2 because no % symbol\")\n\t}\n\n\terr = filters.Set(\"Header2:10%\")\n\tif err != nil {\n\t\tt.Error(\"Should pass\")\n\t}\n\n\tif filters[1].percent != 10 {\n\t\tt.Error(\"Wrong percentage\", filters[1].percent)\n\t}\n}\n\nfunc TestUrlRewriteMap(t *testing.T) {\n\tvar err error\n\trewrites := URLRewriteMap{}\n\n\tif err = rewrites.Set(\"/v1/user/([^\\\\/]+)/ping:/v2/user/$1/ping\"); err != nil {\n\t\tt.Error(\"Should set mapping\", err)\n\t}\n\n\tif err = rewrites.Set(\"/v1/user/([^\\\\/]+)/ping\"); err == nil {\n\t\tt.Error(\"Should not set mapping without :\")\n\t}\n}\n"
        },
        {
          "name": "http_modifier_test.go",
          "type": "blob",
          "size": 8.9150390625,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"testing\"\n)\n\nfunc TestHTTPModifierWithoutConfig(t *testing.T) {\n\tif NewHTTPModifier(&HTTPModifierConfig{}) != nil {\n\t\tt.Error(\"If no config specified should not be initialized\")\n\t}\n}\n\nfunc TestHTTPModifierHeaderFilters(t *testing.T) {\n\tfilters := HTTPHeaderFilters{}\n\tfilters.Set(\"Host:^www.w3.org$\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderFilters: filters,\n\t})\n\n\tpayload := []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\n\tif len(modifier.Rewrite(payload)) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n\n\tfilters = HTTPHeaderFilters{}\n\t// Setting filter that not match our header\n\tfilters.Set(\"Host:^www.w4.org$\")\n\n\tmodifier = NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderFilters: filters,\n\t})\n\n\tif len(modifier.Rewrite(payload)) != 0 {\n\t\tt.Error(\"Request should not pass filters\")\n\t}\n}\n\nfunc TestHTTPModifierHeaderNegativeFilters(t *testing.T) {\n\tfilters := HTTPHeaderFilters{}\n\tfilters.Set(\"Host:^www.w3.org$\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderNegativeFilters: filters,\n\t})\n\n\tpayload := []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w4.org\\r\\n\\r\\na=1&b=2\")\n\n\tif len(modifier.Rewrite(payload)) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n\n\tfilters = HTTPHeaderFilters{}\n\t// Setting filter that not match our header\n\tfilters.Set(\"Host:^www.w4.org$\")\n\n\tmodifier = NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderNegativeFilters: filters,\n\t})\n\n\tif len(modifier.Rewrite(payload)) != 0 {\n\t\tt.Error(\"Request should not pass filters\")\n\t}\n\n\tfilters = HTTPHeaderFilters{}\n\t// Setting filter that not match our header\n\tfilters.Set(\"Host: www*\")\n\n\tmodifier = NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderNegativeFilters: filters,\n\t})\n\n\tif len(modifier.Rewrite(payload)) != 0 {\n\t\tt.Error(\"Request should not pass filters\")\n\t}\n}\n\nfunc TestHTTPHeaderBasicAuthFilters(t *testing.T) {\n\tfilters := HTTPHeaderBasicAuthFilters{}\n\tfilters.Set(\"^customer[0-9].*\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderBasicAuthFilters: filters,\n\t})\n\n\t//Encoded UserId:Password = customer3:welcome\n\tpayload := []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 7\\r\\nAuthorization: Basic Y3VzdG9tZXIzOndlbGNvbWU=\\r\\n\\r\\na=1&b=2\")\n\tif len(modifier.Rewrite(payload)) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n\n\t//customer6:rest@123^TEST\n\tpayload = []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 88\\r\\nAuthorization: Basic Y3VzdG9tZXI2OnJlc3RAMTIzXlRFU1Q==\\r\\n\\r\\na=1&b=2\")\n\tif len(modifier.Rewrite(payload)) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n\n\tfilters = HTTPHeaderBasicAuthFilters{}\n\t// Setting filter that not match our header\n\tfilters.Set(\"^(homer simpson|mickey mouse).*\")\n\n\tmodifier = NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderBasicAuthFilters: filters,\n\t})\n\n\tif len(modifier.Rewrite(payload)) != 0 {\n\t\tt.Error(\"Request should not pass filters\")\n\t}\n\n\t//mickey mouse:happy123\n\tpayload = []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 88\\r\\nAuthorization: Basic bWlja2V5IG1vdXNlOmhhcHB5MTIz\\r\\n\\r\\na=1&b=2\")\n\tif len(modifier.Rewrite(payload)) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n}\n\nfunc TestHTTPModifierURLRewrite(t *testing.T) {\n\tvar url, newURL []byte\n\n\trewrites := URLRewriteMap{}\n\n\tpayload := func(url []byte) []byte {\n\t\treturn []byte(\"POST \" + string(url) + \" HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\t}\n\n\terr := rewrites.Set(\"/v1/user/([^\\\\/]+)/ping:/v2/user/$1/ping\")\n\tif err != nil {\n\t\tt.Error(\"Should not error on /v1/user/([^\\\\/]+)/ping:/v2/user/$1/ping\")\n\t}\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tURLRewrite: rewrites,\n\t})\n\n\turl = []byte(\"/v1/user/joe/ping\")\n\tif newURL = proto.Path(modifier.Rewrite(payload(url))); bytes.Equal(newURL, url) {\n\t\tt.Error(\"Request url should have been rewritten, wasn't\", string(newURL))\n\t}\n\n\turl = []byte(\"/v1/user/ping\")\n\tif newURL = proto.Path(modifier.Rewrite(payload(url))); !bytes.Equal(newURL, url) {\n\t\tt.Error(\"Request url should have been rewritten, wasn't\", string(newURL))\n\t}\n}\n\nfunc TestHTTPModifierHeaderRewrite(t *testing.T) {\n\tvar header, newHeader []byte\n\n\trewrites := HeaderRewriteMap{}\n\tpayload := []byte(\"GET / HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\n\terr := rewrites.Set(\"Host: (.*).w3.org,$1.beta.w3.org\")\n\tif err != nil {\n\t\tt.Error(\"Should not error\", err)\n\t}\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderRewrite: rewrites,\n\t})\n\n\theader = []byte(\"www.beta.w3.org\")\n\tif newHeader = proto.Header(modifier.Rewrite(payload), []byte(\"Host\")); !bytes.Equal(newHeader, header) {\n\t\tt.Error(\"Request header should have been rewritten, wasn't\", string(newHeader), string(header))\n\t}\n}\n\nfunc TestHTTPModifierHeaderHashFilters(t *testing.T) {\n\tfilters := HTTPHashFilters{}\n\tfilters.Set(\"Header2:1/2\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaderHashFilters: filters,\n\t})\n\n\tpayload := func(header []byte) []byte {\n\t\treturn []byte(\"POST / HTTP/1.1\\r\\n\" + string(header) + \"Content-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"\"))); len(p) == 0 {\n\t\tt.Error(\"Request should pass filters if Header does not exist\")\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"Header2: 3\\r\\n\"))); len(p) > 0 {\n\t\tt.Error(\"Request should not pass filters, Header2 hash too high\")\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"Header2: 1\\r\\n\"))); len(p) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n}\n\nfunc TestHTTPModifierParamHashFilters(t *testing.T) {\n\tfilters := HTTPHashFilters{}\n\tfilters.Set(\"user_id:1/2\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tParamHashFilters: filters,\n\t})\n\n\tpayload := func(value []byte) []byte {\n\t\treturn []byte(\"POST /\" + string(value) + \" HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"\"))); len(p) == 0 {\n\t\tt.Error(\"Request should pass filters if param does not exist\")\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"?user_id=3\"))); len(p) > 0 {\n\t\tt.Error(\"Request should not pass filters\", string(p))\n\t}\n\n\tif p := modifier.Rewrite(payload([]byte(\"?user_id=1\"))); len(p) == 0 {\n\t\tt.Error(\"Request should pass filters\")\n\t}\n}\n\nfunc TestHTTPModifierHeaders(t *testing.T) {\n\theaders := HTTPHeaders{}\n\theaders.Set(\"Header1:1\")\n\theaders.Set(\"Host:localhost\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaders: headers,\n\t})\n\n\tpayload := []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\tnewPayload := []byte(\"POST /post HTTP/1.1\\r\\nHeader1: 1\\r\\nContent-Length: 7\\r\\nHost: localhost\\r\\n\\r\\na=1&b=2\")\n\n\tif payload = modifier.Rewrite(payload); !bytes.Equal(payload, newPayload) {\n\t\tt.Error(\"Should update request headers\", string(payload))\n\t}\n}\n\nfunc TestHTTPModifierURLRegexp(t *testing.T) {\n\tfilters := HTTPURLRegexp{}\n\tfilters.Set(\"/v1/app\")\n\tfilters.Set(\"/v1/api\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tURLRegexp: filters,\n\t})\n\n\tpayload := func(url string) []byte {\n\t\treturn []byte(\"POST \" + url + \" HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/v1/app/test\"))) == 0 {\n\t\tt.Error(\"Should pass url\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/v1/api/test\"))) == 0 {\n\t\tt.Error(\"Should pass url\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/other\"))) > 0 {\n\t\tt.Error(\"Should not pass url\")\n\t}\n}\n\nfunc TestHTTPModifierURLNegativeRegexp(t *testing.T) {\n\tfilters := HTTPURLRegexp{}\n\tfilters.Set(\"/restricted1\")\n\tfilters.Set(\"/some/restricted2\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tURLNegativeRegexp: filters,\n\t})\n\n\tpayload := func(url string) []byte {\n\t\treturn []byte(\"POST \" + url + \" HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/v1/app/test\"))) == 0 {\n\t\tt.Error(\"Should pass url\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/restricted1\"))) > 0 {\n\t\tt.Error(\"Should not pass url\")\n\t}\n\n\tif len(modifier.Rewrite(payload(\"/some/restricted2\"))) > 0 {\n\t\tt.Error(\"Should not pass url\")\n\t}\n}\n\nfunc TestHTTPModifierSetHeader(t *testing.T) {\n\tfilters := HTTPHeaders{}\n\tfilters.Set(\"User-Agent:Gor\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tHeaders: filters,\n\t})\n\n\tpayload := []byte(\"POST /post HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\tpayloadAfter := []byte(\"POST /post HTTP/1.1\\r\\nUser-Agent: Gor\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\n\tif payload = modifier.Rewrite(payload); !bytes.Equal(payloadAfter, payload) {\n\t\tt.Error(\"Should add new header\", string(payload))\n\t}\n}\n\nfunc TestHTTPModifierSetParam(t *testing.T) {\n\tfilters := HTTPParams{}\n\tfilters.Set(\"api_key=1\")\n\n\tmodifier := NewHTTPModifier(&HTTPModifierConfig{\n\t\tParams: filters,\n\t})\n\n\tpayload := []byte(\"POST /post?api_key=1234 HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\tpayloadAfter := []byte(\"POST /post?api_key=1 HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n\n\tif payload = modifier.Rewrite(payload); !bytes.Equal(payloadAfter, payload) {\n\t\tt.Error(\"Should override param\", string(payload))\n\t}\n}\n"
        },
        {
          "name": "http_prettifier.go",
          "type": "blob",
          "size": 1.3740234375,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"io/ioutil\"\n\t\"net/http/httputil\"\n\t\"strconv\"\n)\n\nfunc prettifyHTTP(p []byte) []byte {\n\n\ttEnc := bytes.Equal(proto.Header(p, []byte(\"Transfer-Encoding\")), []byte(\"chunked\"))\n\tcEnc := bytes.Equal(proto.Header(p, []byte(\"Content-Encoding\")), []byte(\"gzip\"))\n\n\tif !(tEnc || cEnc) {\n\t\treturn p\n\t}\n\n\theadersPos := proto.MIMEHeadersEndPos(p)\n\n\tif headersPos < 5 || headersPos > len(p) {\n\t\treturn p\n\t}\n\n\theaders := p[:headersPos]\n\tcontent := p[headersPos:]\n\n\tif tEnc {\n\t\tbuf := bytes.NewReader(content)\n\t\tr := httputil.NewChunkedReader(buf)\n\t\tcontent, _ = ioutil.ReadAll(r)\n\n\t\theaders = proto.DeleteHeader(headers, []byte(\"Transfer-Encoding\"))\n\n\t\tnewLen := strconv.Itoa(len(content))\n\t\theaders = proto.SetHeader(headers, []byte(\"Content-Length\"), []byte(newLen))\n\t}\n\n\tif cEnc {\n\t\tbuf := bytes.NewReader(content)\n\t\tg, err := gzip.NewReader(buf)\n\n\t\tif err != nil {\n\t\t\tDebug(1, \"[Prettifier] GZIP encoding error:\", err)\n\t\t\treturn []byte{}\n\t\t}\n\n\t\tcontent, err = ioutil.ReadAll(g)\n\t\tif err != nil {\n\t\t\tDebug(1, fmt.Sprintf(\"[HTTP-PRETTIFIER] %q\", err))\n\t\t\treturn p\n\t\t}\n\n\t\theaders = proto.DeleteHeader(headers, []byte(\"Content-Encoding\"))\n\n\t\tnewLen := strconv.Itoa(len(content))\n\t\theaders = proto.SetHeader(headers, []byte(\"Content-Length\"), []byte(newLen))\n\t}\n\n\tnewPayload := append(headers, content...)\n\n\treturn newPayload\n}\n"
        },
        {
          "name": "http_prettifier_test.go",
          "type": "blob",
          "size": 0.9599609375,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"strconv\"\n\t\"testing\"\n)\n\nfunc TestHTTPPrettifierGzip(t *testing.T) {\n\tb := bytes.NewBufferString(\"\")\n\tw := gzip.NewWriter(b)\n\tw.Write([]byte(\"test\"))\n\tw.Close()\n\n\tsize := strconv.Itoa(len(b.Bytes()))\n\n\tpayload := []byte(\"HTTP/1.1 200 OK\\r\\nContent-Length: \" + size + \"\\r\\nContent-Encoding: gzip\\r\\n\\r\\n\")\n\tpayload = append(payload, b.Bytes()...)\n\n\tnewPayload := prettifyHTTP(payload)\n\n\tif string(newPayload) != \"HTTP/1.1 200 OK\\r\\nContent-Length: 4\\r\\n\\r\\ntest\" {\n\t\tt.Errorf(\"Payload not match %q\", string(newPayload))\n\t}\n}\n\nfunc TestHTTPPrettifierChunked(t *testing.T) {\n\tpayload := []byte(\"POST / HTTP/1.1\\r\\nHost: www.w3.org\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n4\\r\\nWiki\\r\\n5\\r\\npedia\\r\\ne\\r\\n in\\r\\n\\r\\nchunks.\\r\\n0\\r\\n\\r\\n\")\n\n\tpayload = prettifyHTTP(payload)\n\tif string(proto.Header(payload, []byte(\"Content-Length\"))) != \"23\" {\n\t\tt.Errorf(\"payload should have content length of 23\")\n\t}\n}\n"
        },
        {
          "name": "input_dummy.go",
          "type": "blob",
          "size": 1.271484375,
          "content": "package goreplay\n\nimport (\n\t\"time\"\n)\n\n// DummyInput used for debugging. It generate 1 \"GET /\"\" request per second.\ntype DummyInput struct {\n\tdata chan []byte\n\tquit chan struct{}\n}\n\n// NewDummyInput constructor for DummyInput\nfunc NewDummyInput(options string) (di *DummyInput) {\n\tdi = new(DummyInput)\n\tdi.data = make(chan []byte)\n\tdi.quit = make(chan struct{})\n\n\tgo di.emit()\n\n\treturn\n}\n\n// PluginRead reads message from this plugin\nfunc (i *DummyInput) PluginRead() (*Message, error) {\n\tvar msg Message\n\tselect {\n\tcase <-i.quit:\n\t\treturn nil, ErrorStopped\n\tcase buf := <-i.data:\n\t\tmsg.Meta, msg.Data = payloadMetaWithBody(buf)\n\t\treturn &msg, nil\n\t}\n}\n\nfunc (i *DummyInput) emit() {\n\tticker := time.NewTicker(time.Second)\n\n\tfor range ticker.C {\n\t\tuuid := uuid()\n\t\treqh := payloadHeader(RequestPayload, uuid, time.Now().UnixNano(), -1)\n\t\ti.data <- append(reqh, []byte(\"GET / HTTP/1.1\\r\\nHost: www.w3.org\\r\\nUser-Agent: Go 1.1 package http\\r\\nAccept-Encoding: gzip\\r\\n\\r\\n\")...)\n\n\t\tresh := payloadHeader(ResponsePayload, uuid, time.Now().UnixNano()+1, 1)\n\t\ti.data <- append(resh, []byte(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\")...)\n\t}\n}\n\nfunc (i *DummyInput) String() string {\n\treturn \"Dummy Input\"\n}\n\n// Close closes this plugins\nfunc (i *DummyInput) Close() error {\n\tclose(i.quit)\n\treturn nil\n}\n"
        },
        {
          "name": "input_file.go",
          "type": "blob",
          "size": 8.5439453125,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"container/heap\"\n\t\"errors\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n)\n\ntype filePayload struct {\n\tdata      []byte\n\ttimestamp int64\n}\n\n// An IntHeap is a min-heap of ints.\ntype payloadQueue struct {\n\tsync.RWMutex\n\ts []*filePayload\n}\n\nfunc (h payloadQueue) Len() int           { return len(h.s) }\nfunc (h payloadQueue) Less(i, j int) bool { return h.s[i].timestamp < h.s[j].timestamp }\nfunc (h payloadQueue) Swap(i, j int)      { h.s[i], h.s[j] = h.s[j], h.s[i] }\n\nfunc (h *payloadQueue) Push(x interface{}) {\n\t// Push and Pop use pointer receivers because they modify the slice's length,\n\t// not just its contents.\n\th.s = append(h.s, x.(*filePayload))\n}\n\nfunc (h *payloadQueue) Pop() interface{} {\n\told := h.s\n\tn := len(old)\n\tx := old[n-1]\n\th.s = old[0 : n-1]\n\treturn x\n}\n\nfunc (h payloadQueue) Idx(i int) *filePayload {\n\treturn h.s[i]\n}\n\ntype fileInputReader struct {\n\treader    *bufio.Reader\n\tfile      io.ReadCloser\n\tclosed    int32 // Value of 0 indicates that the file is still open.\n\ts3        bool\n\tqueue     payloadQueue\n\treadDepth int\n\tdryRun    bool\n\tpath      string\n}\n\nfunc (f *fileInputReader) parse(init chan struct{}) error {\n\tpayloadSeparatorAsBytes := []byte(payloadSeparator)\n\tvar buffer bytes.Buffer\n\tvar initialized bool\n\n\tlineNum := 0\n\n\tfor {\n\t\tline, err := f.reader.ReadBytes('\\n')\n\t\tlineNum++\n\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\tDebug(1, err)\n\t\t\t}\n\n\t\t\tf.Close()\n\n\t\t\tif !initialized {\n\t\t\t\tclose(init)\n\t\t\t\tinitialized = true\n\t\t\t}\n\n\t\t\treturn err\n\t\t}\n\n\t\tif bytes.Equal(payloadSeparatorAsBytes[1:], line) {\n\t\t\tasBytes := buffer.Bytes()\n\t\t\tmeta := payloadMeta(asBytes)\n\n\t\t\tif len(meta) < 3 {\n\t\t\t\tDebug(1, fmt.Sprintf(\"Found malformed record, file: %s, line %d\", f.path, lineNum))\n\t\t\t\tbuffer = bytes.Buffer{}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\ttimestamp, _ := strconv.ParseInt(string(meta[2]), 10, 64)\n\t\t\tdata := asBytes[:len(asBytes)-1]\n\n\t\t\tf.queue.Lock()\n\t\t\theap.Push(&f.queue, &filePayload{\n\t\t\t\ttimestamp: timestamp,\n\t\t\t\tdata:      data,\n\t\t\t})\n\t\t\tf.queue.Unlock()\n\n\t\t\tfor {\n\t\t\t\tif f.queue.Len() < f.readDepth {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\tif !initialized {\n\t\t\t\t\tclose(init)\n\t\t\t\t\tinitialized = true\n\t\t\t\t}\n\n\t\t\t\tif !f.dryRun {\n\t\t\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbuffer = bytes.Buffer{}\n\t\t\tcontinue\n\t\t}\n\n\t\tbuffer.Write(line)\n\t}\n}\n\nfunc (f *fileInputReader) wait() {\n\tfor {\n\t\tif atomic.LoadInt32(&f.closed) == 1 {\n\t\t\treturn\n\t\t}\n\n\t\tif f.queue.Len() > 0 {\n\t\t\treturn\n\t\t}\n\n\t\tif !f.dryRun {\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t}\n\t}\n\n\treturn\n}\n\n// Close closes this plugin\nfunc (f *fileInputReader) Close() error {\n\tif atomic.LoadInt32(&f.closed) == 0 {\n\t\tatomic.StoreInt32(&f.closed, 1)\n\t\tf.file.Close()\n\t}\n\n\treturn nil\n}\n\nfunc newFileInputReader(path string, readDepth int, dryRun bool) *fileInputReader {\n\tvar file io.ReadCloser\n\tvar err error\n\n\tif strings.HasPrefix(path, \"s3://\") {\n\t\tfile = NewS3ReadCloser(path)\n\t} else {\n\t\tfile, err = os.Open(path)\n\t}\n\n\tif err != nil {\n\t\tDebug(0, fmt.Sprintf(\"[INPUT-FILE] err: %q\", err))\n\t\treturn nil\n\t}\n\n\tr := &fileInputReader{path: path, file: file, closed: 0, readDepth: readDepth, dryRun: dryRun}\n\tif strings.HasSuffix(path, \".gz\") {\n\t\tgzReader, err := gzip.NewReader(file)\n\t\tif err != nil {\n\t\t\tDebug(0, fmt.Sprintf(\"[INPUT-FILE] err: %q\", err))\n\t\t\treturn nil\n\t\t}\n\t\tr.reader = bufio.NewReader(gzReader)\n\t} else {\n\t\tr.reader = bufio.NewReader(file)\n\t}\n\n\theap.Init(&r.queue)\n\n\tinit := make(chan struct{})\n\tgo r.parse(init)\n\t<-init\n\n\treturn r\n}\n\n// FileInput can read requests generated by FileOutput\ntype FileInput struct {\n\tmu          sync.Mutex\n\tdata        chan []byte\n\texit        chan bool\n\tpath        string\n\treaders     []*fileInputReader\n\tspeedFactor float64\n\tloop        bool\n\treadDepth   int\n\tdryRun      bool\n\tmaxWait     time.Duration\n\n\tstats *expvar.Map\n}\n\n// NewFileInput constructor for FileInput. Accepts file path as argument.\nfunc NewFileInput(path string, loop bool, readDepth int, maxWait time.Duration, dryRun bool) (i *FileInput) {\n\ti = new(FileInput)\n\ti.data = make(chan []byte, 1000)\n\ti.exit = make(chan bool)\n\ti.path = path\n\ti.speedFactor = 1\n\ti.loop = loop\n\ti.readDepth = readDepth\n\ti.stats = expvar.NewMap(\"file-\" + path)\n\ti.dryRun = dryRun\n\ti.maxWait = maxWait\n\n\tif err := i.init(); err != nil {\n\t\treturn\n\t}\n\n\tgo i.emit()\n\n\treturn\n}\n\nfunc parseS3Url(path string) (bucket, key string) {\n\tpath = path[5:] // stripping `s3://`\n\tsep := strings.IndexByte(path, '/')\n\n\tbucket = path[:sep]\n\tkey = path[sep+1:]\n\n\treturn bucket, key\n}\n\nfunc (i *FileInput) init() (err error) {\n\tdefer i.mu.Unlock()\n\ti.mu.Lock()\n\n\tvar matches []string\n\n\tif strings.HasPrefix(i.path, \"s3://\") {\n\t\tsess := session.Must(session.NewSession(awsConfig()))\n\t\tsvc := s3.New(sess)\n\n\t\tbucket, key := parseS3Url(i.path)\n\n\t\tparams := &s3.ListObjectsInput{\n\t\t\tBucket: aws.String(bucket),\n\t\t\tPrefix: aws.String(key),\n\t\t}\n\n\t\tresp, err := svc.ListObjects(params)\n\t\tif err != nil {\n\t\t\tDebug(2, \"[INPUT-FILE] Error while retrieving list of files from S3\", i.path, err)\n\t\t\treturn err\n\t\t}\n\n\t\tfor _, c := range resp.Contents {\n\t\t\tmatches = append(matches, \"s3://\"+bucket+\"/\"+(*c.Key))\n\t\t}\n\t} else if matches, err = filepath.Glob(i.path); err != nil {\n\t\tDebug(2, \"[INPUT-FILE] Wrong file pattern\", i.path, err)\n\t\treturn\n\t}\n\n\tif len(matches) == 0 {\n\t\tDebug(2, \"[INPUT-FILE] No files match pattern: \", i.path)\n\t\treturn errors.New(\"no matching files\")\n\t}\n\n\ti.readers = make([]*fileInputReader, len(matches))\n\n\tfor idx, p := range matches {\n\t\ti.readers[idx] = newFileInputReader(p, i.readDepth, i.dryRun)\n\t}\n\n\ti.stats.Add(\"reader_count\", int64(len(matches)))\n\n\treturn nil\n}\n\n// PluginRead reads message from this plugin\nfunc (i *FileInput) PluginRead() (*Message, error) {\n\tvar msg Message\n\tselect {\n\tcase <-i.exit:\n\t\treturn nil, ErrorStopped\n\tcase buf := <-i.data:\n\t\ti.stats.Add(\"read_from\", 1)\n\t\tmsg.Meta, msg.Data = payloadMetaWithBody(buf)\n\t\treturn &msg, nil\n\t}\n}\n\nfunc (i *FileInput) String() string {\n\treturn \"File input: \" + i.path\n}\n\n// Find reader with smallest timestamp e.g next payload in row\nfunc (i *FileInput) nextReader() (next *fileInputReader) {\n\tfor _, r := range i.readers {\n\t\tif r == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tr.wait()\n\n\t\tif r.queue.Len() == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif next == nil || r.queue.Idx(0).timestamp < next.queue.Idx(0).timestamp {\n\t\t\tnext = r\n\t\t\tcontinue\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc (i *FileInput) emit() {\n\tvar lastTime int64 = -1\n\n\tvar maxWait, firstWait, minWait int64\n\tminWait = math.MaxInt64\n\n\ti.stats.Add(\"negative_wait\", 0)\n\n\tfor {\n\t\tselect {\n\t\tcase <-i.exit:\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\treader := i.nextReader()\n\n\t\tif reader == nil {\n\t\t\tif i.loop {\n\t\t\t\ti.init()\n\t\t\t\tlastTime = -1\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\treader.queue.RLock()\n\t\tpayload := heap.Pop(&reader.queue).(*filePayload)\n\t\ti.stats.Add(\"total_counter\", 1)\n\t\ti.stats.Add(\"total_bytes\", int64(len(payload.data)))\n\t\treader.queue.RUnlock()\n\n\t\tif lastTime != -1 {\n\t\t\tdiff := payload.timestamp - lastTime\n\n\t\t\tif firstWait == 0 {\n\t\t\t\tfirstWait = diff\n\t\t\t}\n\n\t\t\tif i.speedFactor != 1 {\n\t\t\t\tdiff = int64(float64(diff) / i.speedFactor)\n\t\t\t}\n\n\t\t\tif i.maxWait > 0 && diff > int64(i.maxWait) {\n\t\t\t\tdiff = int64(i.maxWait)\n\t\t\t}\n\n\t\t\tif diff >= 0 {\n\t\t\t\tlastTime = payload.timestamp\n\n\t\t\t\tif !i.dryRun {\n\t\t\t\t\ttime.Sleep(time.Duration(diff))\n\t\t\t\t}\n\n\t\t\t\ti.stats.Add(\"total_wait\", diff)\n\n\t\t\t\tif diff > maxWait {\n\t\t\t\t\tmaxWait = diff\n\t\t\t\t}\n\n\t\t\t\tif diff < minWait {\n\t\t\t\t\tminWait = diff\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti.stats.Add(\"negative_wait\", 1)\n\t\t\t}\n\t\t} else {\n\t\t\tlastTime = payload.timestamp\n\t\t}\n\n\t\t// Recheck if we have exited since last check.\n\t\tselect {\n\t\tcase <-i.exit:\n\t\t\treturn\n\t\tdefault:\n\t\t\tif !i.dryRun {\n\t\t\t\ti.data <- payload.data\n\t\t\t}\n\t\t}\n\t}\n\n\ti.stats.Set(\"first_wait\", time.Duration(firstWait))\n\ti.stats.Set(\"max_wait\", time.Duration(maxWait))\n\ti.stats.Set(\"min_wait\", time.Duration(minWait))\n\n\tDebug(2, fmt.Sprintf(\"[INPUT-FILE] FileInput: end of file '%s'\\n\", i.path))\n\n\tif i.dryRun {\n\t\tfmt.Printf(\"Records found: %v\\nFiles processed: %v\\nBytes processed: %v\\nMax wait: %v\\nMin wait: %v\\nFirst wait: %v\\nIt will take `%v` to replay at current speed.\\nFound %v records with out of order timestamp\\n\",\n\t\t\ti.stats.Get(\"total_counter\"),\n\t\t\ti.stats.Get(\"reader_count\"),\n\t\t\ti.stats.Get(\"total_bytes\"),\n\t\t\ti.stats.Get(\"max_wait\"),\n\t\t\ti.stats.Get(\"min_wait\"),\n\t\t\ti.stats.Get(\"first_wait\"),\n\t\t\ttime.Duration(i.stats.Get(\"total_wait\").(*expvar.Int).Value()),\n\t\t\ti.stats.Get(\"negative_wait\"),\n\t\t)\n\t}\n}\n\n// Close closes this plugin\nfunc (i *FileInput) Close() error {\n\tdefer i.mu.Unlock()\n\ti.mu.Lock()\n\n\tclose(i.exit)\n\tfor _, r := range i.readers {\n\t\tr.Close()\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "input_file_test.go",
          "type": "blob",
          "size": 9.2822265625,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math/rand\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestInputFileWithGET(t *testing.T) {\n\tinput := NewTestInput()\n\trg := NewRequestGenerator([]PluginReader{input}, func() { input.EmitGET() }, 1)\n\treadPayloads := []*Message{}\n\n\t// Given a capture file with a GET request\n\texpectedCaptureFile := CreateCaptureFile(rg)\n\tdefer expectedCaptureFile.TearDown()\n\n\t// When the request is read from the capture file\n\terr := ReadFromCaptureFile(expectedCaptureFile.file, 1, func(msg *Message) {\n\t\treadPayloads = append(readPayloads, msg)\n\t})\n\n\t// The read request should match the original request\n\tif err != nil {\n\t\tt.Error(err)\n\t} else if !expectedCaptureFile.PayloadsEqual(readPayloads) {\n\t\tt.Error(\"Request read back from file should match\")\n\n\t}\n}\n\nfunc TestInputFileWithPayloadLargerThan64Kb(t *testing.T) {\n\tinput := NewTestInput()\n\trg := NewRequestGenerator([]PluginReader{input}, func() { input.EmitSizedPOST(64 * 1024) }, 1)\n\treadPayloads := []*Message{}\n\n\t// Given a capture file with a request over 64Kb\n\texpectedCaptureFile := CreateCaptureFile(rg)\n\tdefer expectedCaptureFile.TearDown()\n\n\t// When the request is read from the capture file\n\terr := ReadFromCaptureFile(expectedCaptureFile.file, 1, func(msg *Message) {\n\t\treadPayloads = append(readPayloads, msg)\n\t})\n\n\t// The read request should match the original request\n\tif err != nil {\n\t\tt.Error(err)\n\t} else if !expectedCaptureFile.PayloadsEqual(readPayloads) {\n\t\tt.Error(\"Request read back from file should match\")\n\n\t}\n\n}\n\nfunc TestInputFileWithGETAndPOST(t *testing.T) {\n\n\tinput := NewTestInput()\n\trg := NewRequestGenerator([]PluginReader{input}, func() {\n\t\tinput.EmitGET()\n\t\tinput.EmitPOST()\n\t}, 2)\n\treadPayloads := []*Message{}\n\n\t// Given a capture file with a GET request\n\texpectedCaptureFile := CreateCaptureFile(rg)\n\tdefer expectedCaptureFile.TearDown()\n\n\t// When the requests are read from the capture file\n\terr := ReadFromCaptureFile(expectedCaptureFile.file, 2, func(msg *Message) {\n\t\treadPayloads = append(readPayloads, msg)\n\t})\n\n\t// The read requests should match the original request\n\tif err != nil {\n\t\tt.Error(err)\n\t} else if !expectedCaptureFile.PayloadsEqual(readPayloads) {\n\t\tt.Error(\"Request read back from file should match\")\n\n\t}\n\n}\n\nfunc TestInputFileMultipleFilesWithRequestsOnly(t *testing.T) {\n\trnd := rand.Int63()\n\n\tfile1, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d_0\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tfile1.Write([]byte(\"1 1 1\\ntest1\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Write([]byte(\"1 1 3\\ntest2\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Close()\n\n\tfile2, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d_1\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tfile2.Write([]byte(\"1 1 2\\ntest3\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Write([]byte(\"1 1 4\\ntest4\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Close()\n\n\tinput := NewFileInput(fmt.Sprintf(\"/tmp/%d*\", rnd), false, 100, 0, false)\n\n\tfor i := '1'; i <= '4'; i++ {\n\t\tmsg, _ := input.PluginRead()\n\t\tif msg.Meta[4] != byte(i) {\n\t\t\tt.Error(\"Should emit requests in right order\", string(msg.Meta))\n\t\t}\n\t}\n\n\tos.Remove(file1.Name())\n\tos.Remove(file2.Name())\n}\n\nfunc TestInputFileRequestsWithLatency(t *testing.T) {\n\trnd := rand.Int63()\n\n\tfile, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tdefer file.Close()\n\n\tfile.Write([]byte(\"1 1 100000000\\nrequest1\"))\n\tfile.Write([]byte(payloadSeparator))\n\tfile.Write([]byte(\"1 2 150000000\\nrequest2\"))\n\tfile.Write([]byte(payloadSeparator))\n\tfile.Write([]byte(\"1 3 250000000\\nrequest3\"))\n\tfile.Write([]byte(payloadSeparator))\n\n\tinput := NewFileInput(fmt.Sprintf(\"/tmp/%d\", rnd), false, 100, 0, false)\n\n\tstart := time.Now().UnixNano()\n\tfor i := 0; i < 3; i++ {\n\t\tinput.PluginRead()\n\t}\n\tend := time.Now().UnixNano()\n\n\tvar expectedLatency int64 = 300000000 - 100000000\n\trealLatency := end - start\n\tif realLatency > expectedLatency {\n\t\tt.Errorf(\"Should emit requests respecting latency. Expected: %v, real: %v\", expectedLatency, realLatency)\n\t}\n}\n\nfunc TestInputFileMultipleFilesWithRequestsAndResponses(t *testing.T) {\n\trnd := rand.Int63()\n\n\tfile1, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d_0\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tfile1.Write([]byte(\"1 1 1\\nrequest1\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Write([]byte(\"2 1 1\\nresponse1\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Write([]byte(\"1 2 3\\nrequest2\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Write([]byte(\"2 2 3\\nresponse2\"))\n\tfile1.Write([]byte(payloadSeparator))\n\tfile1.Close()\n\n\tfile2, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d_1\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tfile2.Write([]byte(\"1 3 2\\nrequest3\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Write([]byte(\"2 3 2\\nresponse3\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Write([]byte(\"1 4 4\\nrequest4\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Write([]byte(\"2 4 4\\nresponse4\"))\n\tfile2.Write([]byte(payloadSeparator))\n\tfile2.Close()\n\n\tinput := NewFileInput(fmt.Sprintf(\"/tmp/%d*\", rnd), false, 100, 0, false)\n\n\tfor i := '1'; i <= '4'; i++ {\n\t\tmsg, _ := input.PluginRead()\n\t\tif msg.Meta[0] != '1' && msg.Meta[4] != byte(i) {\n\t\t\tt.Error(\"Shound emit requests in right order\", string(msg.Meta))\n\t\t}\n\n\t\tmsg, _ = input.PluginRead()\n\t\tif msg.Meta[0] != '2' && msg.Meta[4] != byte(i) {\n\t\t\tt.Error(\"Shound emit responses in right order\", string(msg.Meta))\n\t\t}\n\t}\n\n\tos.Remove(file1.Name())\n\tos.Remove(file2.Name())\n}\n\nfunc TestInputFileLoop(t *testing.T) {\n\trnd := rand.Int63()\n\n\tfile, _ := os.OpenFile(fmt.Sprintf(\"/tmp/%d\", rnd), os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\tfile.Write([]byte(\"1 1 1\\ntest1\"))\n\tfile.Write([]byte(payloadSeparator))\n\tfile.Write([]byte(\"1 1 2\\ntest2\"))\n\tfile.Write([]byte(payloadSeparator))\n\tfile.Close()\n\n\tinput := NewFileInput(fmt.Sprintf(\"/tmp/%d\", rnd), true, 100, 0, false)\n\n\t// Even if we have just 2 requests in file, it should indifinitly loop\n\tfor i := 0; i < 1000; i++ {\n\t\tinput.PluginRead()\n\t}\n\n\tinput.Close()\n\tos.Remove(file.Name())\n}\n\nfunc TestInputFileCompressed(t *testing.T) {\n\trnd := rand.Int63()\n\n\toutput := NewFileOutput(fmt.Sprintf(\"/tmp/%d_0.gz\", rnd), &FileOutputConfig{FlushInterval: time.Minute, Append: true})\n\tfor i := 0; i < 1000; i++ {\n\t\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\t}\n\tname1 := output.file.Name()\n\toutput.Close()\n\n\toutput2 := NewFileOutput(fmt.Sprintf(\"/tmp/%d_1.gz\", rnd), &FileOutputConfig{FlushInterval: time.Minute, Append: true})\n\tfor i := 0; i < 1000; i++ {\n\t\toutput2.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\t}\n\tname2 := output2.file.Name()\n\toutput2.Close()\n\n\tinput := NewFileInput(fmt.Sprintf(\"/tmp/%d*\", rnd), false, 100, 0, false)\n\tfor i := 0; i < 2000; i++ {\n\t\tinput.PluginRead()\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name2)\n}\n\ntype CaptureFile struct {\n\tmsgs []*Message\n\tfile *os.File\n}\n\nfunc NewExpectedCaptureFile(msgs []*Message, file *os.File) *CaptureFile {\n\tecf := new(CaptureFile)\n\tecf.file = file\n\tecf.msgs = msgs\n\treturn ecf\n}\n\nfunc (expectedCaptureFile *CaptureFile) TearDown() {\n\tif expectedCaptureFile.file != nil {\n\t\tos.Remove(expectedCaptureFile.file.Name())\n\t}\n}\n\ntype RequestGenerator struct {\n\tinputs []PluginReader\n\temit   func()\n\twg     *sync.WaitGroup\n}\n\nfunc NewRequestGenerator(inputs []PluginReader, emit func(), count int) (rg *RequestGenerator) {\n\trg = new(RequestGenerator)\n\trg.inputs = inputs\n\trg.emit = emit\n\trg.wg = new(sync.WaitGroup)\n\trg.wg.Add(count)\n\treturn\n}\n\nfunc (expectedCaptureFile *CaptureFile) PayloadsEqual(other []*Message) bool {\n\n\tif len(expectedCaptureFile.msgs) != len(other) {\n\t\treturn false\n\t}\n\n\tfor i, payload := range other {\n\t\tif !bytes.Equal(expectedCaptureFile.msgs[i].Meta, payload.Meta) {\n\t\t\treturn false\n\t\t}\n\t\tif !bytes.Equal(expectedCaptureFile.msgs[i].Data, payload.Data) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n\n}\n\nfunc CreateCaptureFile(requestGenerator *RequestGenerator) *CaptureFile {\n\tf, err := ioutil.TempFile(\"\", \"testmainconf\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treadPayloads := []*Message{}\n\toutput := NewTestOutput(func(msg *Message) {\n\t\treadPayloads = append(readPayloads, msg)\n\t\trequestGenerator.wg.Done()\n\t})\n\n\toutputFile := NewFileOutput(f.Name(), &FileOutputConfig{FlushInterval: time.Second, Append: true})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  requestGenerator.inputs,\n\t\tOutputs: []PluginWriter{output, outputFile},\n\t}\n\tfor _, input := range requestGenerator.inputs {\n\t\tplugins.All = append(plugins.All, input)\n\t}\n\tplugins.All = append(plugins.All, output, outputFile)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\trequestGenerator.emit()\n\trequestGenerator.wg.Wait()\n\n\ttime.Sleep(100 * time.Millisecond)\n\temitter.Close()\n\n\treturn NewExpectedCaptureFile(readPayloads, f)\n\n}\n\nfunc ReadFromCaptureFile(captureFile *os.File, count int, callback writeCallback) (err error) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewFileInput(captureFile.Name(), false, 100, 0, false)\n\toutput := NewTestOutput(func(msg *Message) {\n\t\tcallback(msg)\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\twg.Add(count)\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tdone := make(chan int, 1)\n\tgo func() {\n\t\twg.Wait()\n\t\tdone <- 1\n\t}()\n\n\tselect {\n\tcase <-done:\n\t\tbreak\n\tcase <-time.After(2 * time.Second):\n\t\terr = errors.New(\"Timed out\")\n\t}\n\temitter.Close()\n\treturn\n\n}\n"
        },
        {
          "name": "input_http.go",
          "type": "blob",
          "size": 1.662109375,
          "content": "package goreplay\n\nimport (\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httputil\"\n\t\"time\"\n)\n\n// HTTPInput used for sending requests to Gor via http\ntype HTTPInput struct {\n\tdata     chan []byte\n\taddress  string\n\tlistener net.Listener\n\tstop     chan bool // Channel used only to indicate goroutine should shutdown\n}\n\n// NewHTTPInput constructor for HTTPInput. Accepts address with port which it will listen on.\nfunc NewHTTPInput(address string) (i *HTTPInput) {\n\ti = new(HTTPInput)\n\ti.data = make(chan []byte, 1000)\n\ti.stop = make(chan bool)\n\n\ti.listen(address)\n\n\treturn\n}\n\n// PluginRead reads message from this plugin\nfunc (i *HTTPInput) PluginRead() (*Message, error) {\n\tvar msg Message\n\tselect {\n\tcase <-i.stop:\n\t\treturn nil, ErrorStopped\n\tcase buf := <-i.data:\n\t\tmsg.Data = buf\n\t\tmsg.Meta = payloadHeader(RequestPayload, uuid(), time.Now().UnixNano(), -1)\n\t\treturn &msg, nil\n\t}\n}\n\n// Close closes this plugin\nfunc (i *HTTPInput) Close() error {\n\tclose(i.stop)\n\treturn nil\n}\n\nfunc (i *HTTPInput) handler(w http.ResponseWriter, r *http.Request) {\n\tr.URL.Scheme = \"http\"\n\tr.URL.Host = i.address\n\n\tbuf, _ := httputil.DumpRequestOut(r, true)\n\thttp.Error(w, http.StatusText(200), 200)\n\ti.data <- buf\n}\n\nfunc (i *HTTPInput) listen(address string) {\n\tvar err error\n\n\tmux := http.NewServeMux()\n\n\tmux.HandleFunc(\"/\", i.handler)\n\n\ti.listener, err = net.Listen(\"tcp\", address)\n\tif err != nil {\n\t\tlog.Fatal(\"HTTP input listener failure:\", err)\n\t}\n\ti.address = i.listener.Addr().String()\n\n\tgo func() {\n\t\terr = http.Serve(i.listener, mux)\n\t\tif err != nil && err != http.ErrServerClosed {\n\t\t\tlog.Fatal(\"HTTP input serve failure \", err)\n\t\t}\n\t}()\n}\n\nfunc (i *HTTPInput) String() string {\n\treturn \"HTTP input: \" + i.address\n}\n"
        },
        {
          "name": "input_http_test.go",
          "type": "blob",
          "size": 1.58984375,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"net/http\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestHTTPInput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewHTTPInput(\"127.0.0.1:0\")\n\ttime.Sleep(time.Millisecond)\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\taddress := strings.Replace(input.address, \"[::]\", \"127.0.0.1\", -1)\n\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(1)\n\t\thttp.Get(\"http://\" + address + \"/\")\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc TestInputHTTPLargePayload(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\tconst n = 10 << 20 // 10MB\n\tvar large [n]byte\n\tlarge[n-1] = '0'\n\n\tinput := NewHTTPInput(\"127.0.0.1:0\")\n\toutput := NewTestOutput(func(msg *Message) {\n\t\t_len := len(msg.Data)\n\t\tif _len >= n { // considering http body CRLF\n\t\t\tt.Errorf(\"expected body to be >= %d\", n)\n\t\t}\n\t\twg.Done()\n\t})\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tdefer emitter.Close()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\taddress := strings.Replace(input.address, \"[::]\", \"127.0.0.1\", -1)\n\tvar req *http.Request\n\tvar err error\n\treq, err = http.NewRequest(\"POST\", \"http://\"+address, bytes.NewBuffer(large[:]))\n\tif err != nil {\n\t\tt.Error(err)\n\t\treturn\n\t}\n\twg.Add(1)\n\t_, err = http.DefaultClient.Do(req)\n\tif err != nil {\n\t\tt.Error(err)\n\t\treturn\n\t}\n\twg.Wait()\n}\n"
        },
        {
          "name": "input_kafka.go",
          "type": "blob",
          "size": 4.0771484375,
          "content": "package goreplay\n\nimport (\n\t\"encoding/json\"\n\t\"log\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/Shopify/sarama\"\n\t\"github.com/Shopify/sarama/mocks\"\n)\n\n// KafkaInput is used for receiving Kafka messages and\n// transforming them into HTTP payloads.\ntype KafkaInput struct {\n\tconfig      *InputKafkaConfig\n\tconsumers   []sarama.PartitionConsumer\n\tmessages    chan *sarama.ConsumerMessage\n\tspeedFactor float64\n\tquit        chan struct{}\n\tkafkaTimer  *kafkaTimer\n}\n\nfunc getOffsetOfPartitions(offsetCfg string) int64 {\n\toffset, err := strconv.ParseInt(offsetCfg, 10, 64)\n\tif err != nil || offset < -2 {\n\t\tlog.Fatalln(\"Failed to parse offset: \"+offsetCfg, err)\n\t}\n\treturn offset\n}\n\n// NewKafkaInput creates instance of kafka consumer client with TLS config\nfunc NewKafkaInput(offsetCfg string, config *InputKafkaConfig, tlsConfig *KafkaTLSConfig) *KafkaInput {\n\tc := NewKafkaConfig(&config.SASLConfig, tlsConfig)\n\n\tvar con sarama.Consumer\n\n\tif mock, ok := config.consumer.(*mocks.Consumer); ok && mock != nil {\n\t\tcon = config.consumer\n\t} else {\n\t\tvar err error\n\t\tcon, err = sarama.NewConsumer(strings.Split(config.Host, \",\"), c)\n\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"Failed to start Sarama(Kafka) consumer:\", err)\n\t\t}\n\t}\n\n\tpartitions, err := con.Partitions(config.Topic)\n\tif err != nil {\n\t\tlog.Fatalln(\"Failed to collect Sarama(Kafka) partitions:\", err)\n\t}\n\n\ti := &KafkaInput{\n\t\tconfig:      config,\n\t\tconsumers:   make([]sarama.PartitionConsumer, len(partitions)),\n\t\tmessages:    make(chan *sarama.ConsumerMessage, 256),\n\t\tspeedFactor: 1,\n\t\tquit:        make(chan struct{}),\n\t\tkafkaTimer:  new(kafkaTimer),\n\t}\n\ti.config.Offset = offsetCfg\n\n\tfor index, partition := range partitions {\n\t\tconsumer, err := con.ConsumePartition(config.Topic, partition, getOffsetOfPartitions(offsetCfg))\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"Failed to start Sarama(Kafka) partition consumer:\", err)\n\t\t}\n\n\t\tgo func(consumer sarama.PartitionConsumer) {\n\t\t\tdefer consumer.Close()\n\n\t\t\tfor message := range consumer.Messages() {\n\t\t\t\ti.messages <- message\n\t\t\t}\n\t\t}(consumer)\n\n\t\tgo i.ErrorHandler(consumer)\n\n\t\ti.consumers[index] = consumer\n\t}\n\n\treturn i\n}\n\n// ErrorHandler should receive errors\nfunc (i *KafkaInput) ErrorHandler(consumer sarama.PartitionConsumer) {\n\tfor err := range consumer.Errors() {\n\t\tDebug(1, \"Failed to read access log entry:\", err)\n\t}\n}\n\n// PluginRead a reads message from this plugin\nfunc (i *KafkaInput) PluginRead() (*Message, error) {\n\tvar message *sarama.ConsumerMessage\n\tvar msg Message\n\tselect {\n\tcase <-i.quit:\n\t\treturn nil, ErrorStopped\n\tcase message = <-i.messages:\n\t}\n\n\tinputTs := \"\"\n\n\tmsg.Data = message.Value\n\tif i.config.UseJSON {\n\n\t\tvar kafkaMessage KafkaMessage\n\t\tjson.Unmarshal(message.Value, &kafkaMessage)\n\n\t\tinputTs = kafkaMessage.ReqTs\n\t\tvar err error\n\t\tmsg.Data, err = kafkaMessage.Dump()\n\t\tif err != nil {\n\t\t\tDebug(1, \"[INPUT-KAFKA] failed to decode access log entry:\", err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// does it have meta\n\tif isOriginPayload(msg.Data) {\n\t\tmsg.Meta, msg.Data = payloadMetaWithBody(msg.Data)\n\t\tinputTs = string(payloadMeta(msg.Meta)[2])\n\t}\n\n\ti.timeWait(inputTs)\n\n\treturn &msg, nil\n\n}\n\nfunc (i *KafkaInput) String() string {\n\treturn \"Kafka Input: \" + i.config.Host + \"/\" + i.config.Topic\n}\n\n// Close closes this plugin\nfunc (i *KafkaInput) Close() error {\n\tclose(i.quit)\n\treturn nil\n}\n\nfunc (i *KafkaInput) timeWait(curInputTs string) {\n\tif i.config.Offset == \"-1\" || curInputTs == \"\" {\n\t\treturn\n\t}\n\n\t// implement for Kafka input showdown or speedup emitting\n\ttimer := i.kafkaTimer\n\tcurTs := time.Now().UnixNano()\n\n\tcurInput, err := strconv.ParseInt(curInputTs, 10, 64)\n\n\tif timer.latestInputTs == 0 || timer.latestOutputTs == 0 {\n\t\ttimer.latestInputTs = curInput\n\t\ttimer.latestOutputTs = curTs\n\t\treturn\n\t}\n\n\tif err != nil {\n\t\tlog.Fatalln(\"Fatal to parse timestamp err: \", err)\n\t}\n\n\tdiffTs := curInput - timer.latestInputTs\n\tpastTs := curTs - timer.latestOutputTs\n\n\tdiff := diffTs - pastTs\n\tif i.speedFactor != 1 {\n\t\tdiff = int64(float64(diff) / i.speedFactor)\n\t}\n\n\tif diff > 0 {\n\t\ttime.Sleep(time.Duration(diff))\n\t}\n\n\ttimer.latestInputTs = curInput\n\ttimer.latestOutputTs = curTs\n}\n\ntype kafkaTimer struct {\n\tlatestInputTs  int64\n\tlatestOutputTs int64\n}\n"
        },
        {
          "name": "input_kafka_test.go",
          "type": "blob",
          "size": 1.4482421875,
          "content": "package goreplay\n\nimport (\n\t\"testing\"\n\n\t\"github.com/Shopify/sarama\"\n\t\"github.com/Shopify/sarama/mocks\"\n)\n\nfunc TestInputKafkaRAW(t *testing.T) {\n\tconsumer := mocks.NewConsumer(t, nil)\n\tdefer consumer.Close()\n\n\tconsumer.ExpectConsumePartition(\"test\", 0, mocks.AnyOffset).YieldMessage(&sarama.ConsumerMessage{Value: []byte(\"1 2 3\\nGET / HTTP1.1\\r\\nHeader: 1\\r\\n\\r\\n\")})\n\tconsumer.SetTopicMetadata(\n\t\tmap[string][]int32{\"test\": {0}},\n\t)\n\n\tinput := NewKafkaInput(\"-1\", &InputKafkaConfig{\n\t\tconsumer: consumer,\n\t\tTopic:    \"test\",\n\t\tUseJSON:  false,\n\t}, nil)\n\n\tmsg, err := input.PluginRead()\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif string(append(msg.Meta, msg.Data...)) != \"1 2 3\\nGET / HTTP1.1\\r\\nHeader: 1\\r\\n\\r\\n\" {\n\t\tt.Error(\"Message not properly decoded\")\n\t}\n}\n\nfunc TestInputKafkaJSON(t *testing.T) {\n\tconsumer := mocks.NewConsumer(t, nil)\n\tdefer consumer.Close()\n\n\tconsumer.ExpectConsumePartition(\"test\", 0, mocks.AnyOffset).YieldMessage(&sarama.ConsumerMessage{Value: []byte(`{\"Req_URL\":\"/\",\"Req_Type\":\"1\",\"Req_ID\":\"2\",\"Req_Ts\":\"3\",\"Req_Method\":\"GET\",\"Req_Headers\":{\"Header\":\"1\"}}`)})\n\tconsumer.SetTopicMetadata(\n\t\tmap[string][]int32{\"test\": {0}},\n\t)\n\n\tinput := NewKafkaInput(\"-1\", &InputKafkaConfig{\n\t\tconsumer: consumer,\n\t\tTopic:    \"test\",\n\t\tUseJSON:  true,\n\t}, nil)\n\n\tmsg, err := input.PluginRead()\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif string(append(msg.Meta, msg.Data...)) != \"1 2 3\\nGET / HTTP/1.1\\r\\nHeader: 1\\r\\n\\r\\n\" {\n\t\tt.Error(\"Message not properly decoded\")\n\t}\n}\n"
        },
        {
          "name": "input_raw.go",
          "type": "blob",
          "size": 3.9462890625,
          "content": "package goreplay\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/buger/goreplay/internal/capture\"\n\t\"github.com/buger/goreplay/internal/tcp\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"log\"\n\t\"net\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// RAWInputConfig represents configuration that can be applied on raw input\ntype RAWInputConfig = capture.PcapOptions\n\n// RAWInput used for intercepting traffic for given address\ntype RAWInput struct {\n\tsync.Mutex\n\tconfig         RAWInputConfig\n\tmessageStats   []tcp.Stats\n\tlistener       *capture.Listener\n\tmessageParser  *tcp.MessageParser\n\tcancelListener context.CancelFunc\n\tclosed         bool\n\n\tquit  chan bool // Channel used only to indicate goroutine should shutdown\n\thost  string\n\tports []uint16\n}\n\n// NewRAWInput constructor for RAWInput. Accepts raw input config as arguments.\nfunc NewRAWInput(address string, config RAWInputConfig) (i *RAWInput) {\n\ti = new(RAWInput)\n\ti.config = config\n\ti.quit = make(chan bool)\n\n\thost, _ports, err := net.SplitHostPort(address)\n\tif err != nil {\n\t\t// If we are reading pcap file, no port needed\n\t\tif strings.HasSuffix(address, \"pcap\") {\n\t\t\thost = address\n\t\t\t_ports = \"0\"\n\t\t\terr = nil\n\t\t} else if strings.HasPrefix(address, \"k8s://\") {\n\t\t\tportIndex := strings.LastIndex(address, \":\")\n\t\t\thost = address[:portIndex]\n\t\t\t_ports = address[portIndex+1:]\n\t\t} else {\n\t\t\tlog.Fatalf(\"input-raw: error while parsing address: %s\", err)\n\t\t}\n\t}\n\n\tif strings.HasSuffix(host, \"pcap\") {\n\t\ti.config.Engine = capture.EnginePcapFile\n\t}\n\n\tvar ports []uint16\n\tif _ports != \"\" {\n\t\tportsStr := strings.Split(_ports, \",\")\n\n\t\tfor _, portStr := range portsStr {\n\t\t\tport, err := strconv.Atoi(strings.TrimSpace(portStr))\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"parsing port error: %v\", err)\n\t\t\t}\n\t\t\tports = append(ports, uint16(port))\n\n\t\t}\n\t}\n\n\ti.host = host\n\ti.ports = ports\n\n\ti.listen(address)\n\n\treturn\n}\n\n// PluginRead reads meassage from this plugin\nfunc (i *RAWInput) PluginRead() (*Message, error) {\n\tvar msgTCP *tcp.Message\n\tvar msg Message\n\tselect {\n\tcase <-i.quit:\n\t\treturn nil, ErrorStopped\n\tcase msgTCP = <-i.listener.Messages():\n\t\tmsg.Data = msgTCP.Data()\n\t}\n\n\tvar msgType byte = ResponsePayload\n\tif msgTCP.Direction == tcp.DirIncoming {\n\t\tmsgType = RequestPayload\n\t\tif i.config.RealIPHeader != \"\" {\n\t\t\tmsg.Data = proto.SetHeader(msg.Data, []byte(i.config.RealIPHeader), []byte(msgTCP.SrcAddr))\n\t\t}\n\t}\n\tmsg.Meta = payloadHeader(msgType, msgTCP.UUID(), msgTCP.Start.UnixNano(), msgTCP.End.UnixNano()-msgTCP.Start.UnixNano())\n\n\t// to be removed....\n\tif msgTCP.Truncated {\n\t\tDebug(2, \"[INPUT-RAW] message truncated, increase copy-buffer-size\")\n\t}\n\t// to be removed...\n\tif msgTCP.TimedOut {\n\t\tDebug(2, \"[INPUT-RAW] message timeout reached, increase input-raw-expire\")\n\t}\n\tif i.config.Stats {\n\t\tstat := msgTCP.Stats\n\t\tgo i.addStats(stat)\n\t}\n\tmsgTCP = nil\n\treturn &msg, nil\n}\n\nfunc (i *RAWInput) listen(address string) {\n\tvar err error\n\ti.listener, err = capture.NewListener(i.host, i.ports, i.config)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\terr = i.listener.Activate()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tvar ctx context.Context\n\tctx, i.cancelListener = context.WithCancel(context.Background())\n\terrCh := i.listener.ListenBackground(ctx)\n\t<-i.listener.Reading\n\tDebug(1, i)\n\tgo func() {\n\t\t<-errCh // the listener closed voluntarily\n\t\ti.Close()\n\t}()\n}\n\nfunc (i *RAWInput) String() string {\n\treturn fmt.Sprintf(\"Intercepting traffic from: %s:%s\", i.host, strings.Join(strings.Fields(fmt.Sprint(i.ports)), \",\"))\n}\n\n// GetStats returns the stats so far and reset the stats\nfunc (i *RAWInput) GetStats() []tcp.Stats {\n\ti.Lock()\n\tdefer func() {\n\t\ti.messageStats = []tcp.Stats{}\n\t\ti.Unlock()\n\t}()\n\treturn i.messageStats\n}\n\n// Close closes the input raw listener\nfunc (i *RAWInput) Close() error {\n\ti.Lock()\n\tdefer i.Unlock()\n\tif i.closed {\n\t\treturn nil\n\t}\n\ti.cancelListener()\n\tclose(i.quit)\n\ti.closed = true\n\treturn nil\n}\n\nfunc (i *RAWInput) addStats(mStats tcp.Stats) {\n\ti.Lock()\n\tif len(i.messageStats) >= 10000 {\n\t\ti.messageStats = []tcp.Stats{}\n\t}\n\ti.messageStats = append(i.messageStats, mStats)\n\ti.Unlock()\n}\n"
        },
        {
          "name": "input_raw_test.go",
          "type": "blob",
          "size": 8.095703125,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"github.com/buger/goreplay/internal/capture\"\n\t\"github.com/buger/goreplay/internal/tcp\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"io/ioutil\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"net/http/httputil\"\n\t\"os/exec\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nconst testRawExpire = time.Millisecond * 200\n\nfunc TestRAWInputIPv4(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tlistener, err := net.Listen(\"tcp4\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tt.Error(err)\n\t\treturn\n\t}\n\torigin := &http.Server{\n\t\tHandler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.Write([]byte(\"ab\"))\n\t\t}),\n\t\tReadTimeout:  10 * time.Second,\n\t\tWriteTimeout: 10 * time.Second,\n\t}\n\tgo origin.Serve(listener)\n\tdefer listener.Close()\n\t_, port, _ := net.SplitHostPort(listener.Addr().String())\n\n\tvar respCounter, reqCounter int64\n\tconf := RAWInputConfig{\n\t\tEngine:        capture.EnginePcap,\n\t\tExpire:        0,\n\t\tProtocol:      tcp.ProtocolHTTP,\n\t\tTrackResponse: true,\n\t\tRealIPHeader:  \"X-Real-IP\",\n\t}\n\tinput := NewRAWInput(listener.Addr().String(), conf)\n\n\toutput := NewTestOutput(func(msg *Message) {\n\t\tif msg.Meta[0] == '1' {\n\t\t\tif len(proto.Header(msg.Data, []byte(\"X-Real-IP\"))) == 0 {\n\t\t\t\tt.Error(\"Should have X-Real-IP header\")\n\t\t\t}\n\t\t\treqCounter++\n\t\t} else {\n\t\t\trespCounter++\n\t\t}\n\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\taddr := \"http://127.0.0.1:\" + port\n\temitter := NewEmitter()\n\tdefer emitter.Close()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\t// time.Sleep(time.Second)\n\tfor i := 0; i < 1; i++ {\n\t\twg.Add(2)\n\t\t_, err = http.Get(addr)\n\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\t}\n\n\twg.Wait()\n\tconst want = 10\n\tif reqCounter != respCounter && reqCounter != want {\n\t\tt.Errorf(\"want %d requests and %d responses, got %d requests and %d responses\", want, want, reqCounter, respCounter)\n\t}\n}\n\nfunc TestRAWInputNoKeepAlive(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tlistener, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\torigin := &http.Server{\n\t\tHandler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.Write([]byte(\"ab\"))\n\t\t}),\n\t\tReadTimeout:  10 * time.Second,\n\t\tWriteTimeout: 10 * time.Second,\n\t}\n\torigin.SetKeepAlivesEnabled(false)\n\tgo origin.Serve(listener)\n\tdefer listener.Close()\n\t_, port, _ := net.SplitHostPort(listener.Addr().String())\n\n\tconf := RAWInputConfig{\n\t\tEngine:        capture.EnginePcap,\n\t\tExpire:        testRawExpire,\n\t\tProtocol:      tcp.ProtocolHTTP,\n\t\tTrackResponse: true,\n\t}\n\tinput := NewRAWInput(\":\"+port, conf)\n\tvar respCounter, reqCounter int64\n\toutput := NewTestOutput(func(msg *Message) {\n\t\tif msg.Meta[0] == '1' {\n\t\t\tatomic.AddInt64(&reqCounter, 1)\n\t\t\twg.Done()\n\t\t} else {\n\t\t\tatomic.AddInt64(&respCounter, 1)\n\t\t\twg.Done()\n\t\t}\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\taddr := \"http://127.0.0.1:\" + port\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 10; i++ {\n\t\t// request + response\n\t\twg.Add(2)\n\t\t_, err = http.Get(addr)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\t}\n\n\twg.Wait()\n\tconst want = 10\n\tif reqCounter != respCounter && reqCounter != want {\n\t\tt.Errorf(\"want %d requests and %d responses, got %d requests and %d responses\", want, want, reqCounter, respCounter)\n\t}\n\temitter.Close()\n}\n\nfunc TestRAWInputIPv6(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tlistener, err := net.Listen(\"tcp\", \"[::1]:0\")\n\tif err != nil {\n\t\treturn\n\t}\n\torigin := &http.Server{\n\t\tHandler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.Write([]byte(\"ab\"))\n\t\t}),\n\t\tReadTimeout:  10 * time.Second,\n\t\tWriteTimeout: 10 * time.Second,\n\t}\n\tgo origin.Serve(listener)\n\tdefer listener.Close()\n\t_, port, _ := net.SplitHostPort(listener.Addr().String())\n\toriginAddr := \"[::1]:\" + port\n\n\tvar respCounter, reqCounter int64\n\tconf := RAWInputConfig{\n\t\tEngine:        capture.EnginePcap,\n\t\tProtocol:      tcp.ProtocolHTTP,\n\t\tTrackResponse: true,\n\t}\n\tinput := NewRAWInput(originAddr, conf)\n\n\toutput := NewTestOutput(func(msg *Message) {\n\t\tif msg.Meta[0] == '1' {\n\t\t\tatomic.AddInt64(&reqCounter, 1)\n\t\t} else {\n\t\t\tatomic.AddInt64(&respCounter, 1)\n\t\t}\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\n\temitter := NewEmitter()\n\taddr := \"http://\" + originAddr\n\tgo emitter.Start(plugins, Settings.Middleware)\n\tfor i := 0; i < 10; i++ {\n\t\t// request + response\n\t\twg.Add(2)\n\t\t_, err = http.Get(addr)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\t}\n\n\twg.Wait()\n\tconst want = 10\n\tif reqCounter != respCounter && reqCounter != want {\n\t\tt.Errorf(\"want %d requests and %d responses, got %d requests and %d responses\", want, want, reqCounter, respCounter)\n\t}\n\temitter.Close()\n}\n\nfunc TestInputRAWChunkedEncoding(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tfileContent, _ := ioutil.ReadFile(\"README.md\")\n\n\t// Origing and Replay server initialization\n\torigin := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer r.Body.Close()\n\t\tioutil.ReadAll(r.Body)\n\n\t\twg.Done()\n\t}))\n\n\toriginAddr := strings.Replace(origin.Listener.Addr().String(), \"[::]\", \"127.0.0.1\", -1)\n\tconf := RAWInputConfig{\n\t\tEngine:          capture.EnginePcap,\n\t\tExpire:          time.Second,\n\t\tProtocol:        tcp.ProtocolHTTP,\n\t\tTrackResponse:   true,\n\t\tAllowIncomplete: true,\n\t}\n\tinput := NewRAWInput(originAddr, conf)\n\n\treplay := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer r.Body.Close()\n\t\tbody, _ := ioutil.ReadAll(r.Body)\n\n\t\tif !bytes.Equal(body, fileContent) {\n\t\t\tbuf, _ := httputil.DumpRequest(r, true)\n\t\t\tt.Error(\"Wrong POST body:\", string(buf))\n\t\t}\n\n\t\twg.Done()\n\t}))\n\tdefer replay.Close()\n\n\thttpOutput := NewHTTPOutput(replay.URL, &HTTPOutputConfig{})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{httpOutput},\n\t}\n\tplugins.All = append(plugins.All, input, httpOutput)\n\n\temitter := NewEmitter()\n\tdefer emitter.Close()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\twg.Add(2)\n\n\tcurl := exec.Command(\"curl\", \"http://\"+originAddr, \"--header\", \"Transfer-Encoding: chunked\", \"--header\", \"Expect:\", \"--data-binary\", \"@README.md\")\n\terr := curl.Run()\n\tif err != nil {\n\t\tt.Error(err)\n\t\treturn\n\t}\n\n\twg.Wait()\n}\n\nfunc BenchmarkRAWInputWithReplay(b *testing.B) {\n\tvar respCounter, reqCounter, replayCounter uint32\n\twg := &sync.WaitGroup{}\n\n\tlistener, err := net.Listen(\"tcp4\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tb.Error(err)\n\t\treturn\n\t}\n\tlistener0, err := net.Listen(\"tcp4\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tb.Error(err)\n\t\treturn\n\t}\n\n\torigin := http.Server{\n\t\tHandler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.Write([]byte(\"ab\"))\n\t\t}),\n\t}\n\tgo origin.Serve(listener)\n\tdefer origin.Close()\n\toriginAddr := listener.Addr().String()\n\n\treplay := http.Server{\n\t\tHandler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tatomic.AddUint32(&replayCounter, 1)\n\t\t\tw.Write(nil)\n\t\t\twg.Done()\n\t\t}),\n\t}\n\tgo replay.Serve(listener0)\n\tdefer replay.Close()\n\treplayAddr := listener0.Addr().String()\n\n\tconf := RAWInputConfig{\n\t\tEngine:        capture.EnginePcap,\n\t\tExpire:        testRawExpire,\n\t\tProtocol:      tcp.ProtocolHTTP,\n\t\tTrackResponse: true,\n\t}\n\tinput := NewRAWInput(originAddr, conf)\n\n\ttestOutput := NewTestOutput(func(msg *Message) {\n\t\tif msg.Meta[0] == '1' {\n\t\t\treqCounter++\n\t\t} else {\n\t\t\trespCounter++\n\t\t}\n\t\twg.Done()\n\t})\n\thttpOutput := NewHTTPOutput(\"http://\"+replayAddr, &HTTPOutputConfig{})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{testOutput, httpOutput},\n\t}\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\taddr := \"http://\" + originAddr\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(3) // reqCounter + replayCounter + respCounter\n\t\tresp, err := http.Get(addr)\n\t\tif err != nil {\n\t\t\twg.Add(-3)\n\t\t}\n\t\tresp.Body.Close()\n\t}\n\n\twg.Wait()\n\tb.ReportMetric(float64(reqCounter), \"requests\")\n\tb.ReportMetric(float64(respCounter), \"responses\")\n\tb.ReportMetric(float64(replayCounter), \"replayed\")\n\temitter.Close()\n}\n"
        },
        {
          "name": "input_tcp.go",
          "type": "blob",
          "size": 3.130859375,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n)\n\n// TCPInput used for internal communication\ntype TCPInput struct {\n\tdata     chan *Message\n\tlistener net.Listener\n\taddress  string\n\tconfig   *TCPInputConfig\n\tstop     chan bool // Channel used only to indicate goroutine should shutdown\n}\n\n// TCPInputConfig represents configuration of a TCP input plugin\ntype TCPInputConfig struct {\n\tSecure          bool   `json:\"input-tcp-secure\"`\n\tCertificatePath string `json:\"input-tcp-certificate\"`\n\tKeyPath         string `json:\"input-tcp-certificate-key\"`\n}\n\n// NewTCPInput constructor for TCPInput, accepts address with port\nfunc NewTCPInput(address string, config *TCPInputConfig) (i *TCPInput) {\n\ti = new(TCPInput)\n\ti.data = make(chan *Message, 1000)\n\ti.address = address\n\ti.config = config\n\ti.stop = make(chan bool)\n\n\ti.listen(address)\n\n\treturn\n}\n\n// PluginRead returns data and details read from plugin\nfunc (i *TCPInput) PluginRead() (msg *Message, err error) {\n\tselect {\n\tcase <-i.stop:\n\t\treturn nil, ErrorStopped\n\tcase msg = <-i.data:\n\t\treturn msg, nil\n\t}\n\n}\n\n// Close closes the plugin\nfunc (i *TCPInput) Close() error {\n\tclose(i.stop)\n\ti.listener.Close()\n\treturn nil\n}\n\nfunc (i *TCPInput) listen(address string) {\n\tif i.config.Secure {\n\t\tcer, err := tls.LoadX509KeyPair(i.config.CertificatePath, i.config.KeyPath)\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"error while loading --input-tcp TLS certificate:\", err)\n\t\t}\n\n\t\tconfig := &tls.Config{Certificates: []tls.Certificate{cer}}\n\t\tlistener, err := tls.Listen(\"tcp\", address, config)\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"[INPUT-TCP] failed to start INPUT-TCP listener:\", err)\n\t\t}\n\t\ti.listener = listener\n\t} else {\n\t\tlistener, err := net.Listen(\"tcp\", address)\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"failed to start INPUT-TCP listener:\", err)\n\t\t}\n\t\ti.listener = listener\n\t}\n\tgo func() {\n\t\tfor {\n\t\t\tconn, err := i.listener.Accept()\n\t\t\tif err == nil {\n\t\t\t\tgo i.handleConnection(conn)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif isTemporaryNetworkError(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif operr, ok := err.(*net.OpError); ok && operr.Err.Error() != \"use of closed network connection\" {\n\t\t\t\tDebug(0, fmt.Sprintf(\"[INPUT-TCP] listener closed, err: %q\", err))\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}()\n}\n\nvar payloadSeparatorAsBytes = []byte(payloadSeparator)\n\nfunc (i *TCPInput) handleConnection(conn net.Conn) {\n\tdefer conn.Close()\n\n\treader := bufio.NewReader(conn)\n\tvar buffer bytes.Buffer\n\n\tfor {\n\t\tline, err := reader.ReadBytes('\\n')\n\t\tif err != nil {\n\t\t\tif isTemporaryNetworkError(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err != io.EOF {\n\t\t\t\tDebug(0, fmt.Sprintf(\"[INPUT-TCP] connection error: %q\", err))\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\tif bytes.Equal(payloadSeparatorAsBytes[1:], line) {\n\t\t\t// unread the '\\n' before monkeys\n\t\t\tbuffer.UnreadByte()\n\t\t\tvar msg Message\n\t\t\tmsg.Meta, msg.Data = payloadMetaWithBody(buffer.Bytes())\n\t\t\ti.data <- &msg\n\t\t\tbuffer.Reset()\n\t\t} else {\n\t\t\tbuffer.Write(line)\n\t\t}\n\t}\n}\n\nfunc (i *TCPInput) String() string {\n\treturn \"TCP input: \" + i.address\n}\n\nfunc isTemporaryNetworkError(err error) bool {\n\tif nerr, ok := err.(net.Error); ok && nerr.Temporary() {\n\t\treturn true\n\t}\n\tif operr, ok := err.(*net.OpError); ok && operr.Temporary() {\n\t\treturn true\n\t}\n\treturn false\n}\n"
        },
        {
          "name": "input_tcp_test.go",
          "type": "blob",
          "size": 3.1298828125,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"crypto/rand\"\n\t\"crypto/rsa\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math/big\"\n\t\"net\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTCPInput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTCPInput(\"127.0.0.1:0\", &TCPInputConfig{})\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\ttcpAddr, err := net.ResolveTCPAddr(\"tcp\", input.listener.Addr().String())\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tconn, err := net.DialTCP(\"tcp\", nil, tcpAddr)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tmsg := []byte(\"1 1 1\\nGET / HTTP/1.1\\r\\n\\r\\n\")\n\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(1)\n\t\tif _, err = conn.Write(msg); err == nil {\n\t\t\t_, err = conn.Write(payloadSeparatorAsBytes)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\t}\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc genCertificate(template *x509.Certificate) ([]byte, []byte) {\n\tpriv, _ := rsa.GenerateKey(rand.Reader, 2048)\n\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, _ := rand.Int(rand.Reader, serialNumberLimit)\n\ttemplate.SerialNumber = serialNumber\n\ttemplate.BasicConstraintsValid = true\n\ttemplate.NotBefore = time.Now()\n\ttemplate.NotAfter = time.Now().Add(time.Hour)\n\n\tderBytes, _ := x509.CreateCertificate(rand.Reader, template, template, &priv.PublicKey, priv)\n\n\tvar certPem, keyPem bytes.Buffer\n\tpem.Encode(&certPem, &pem.Block{Type: \"CERTIFICATE\", Bytes: derBytes})\n\tpem.Encode(&keyPem, &pem.Block{Type: \"RSA PRIVATE KEY\", Bytes: x509.MarshalPKCS1PrivateKey(priv)})\n\n\treturn certPem.Bytes(), keyPem.Bytes()\n}\n\nfunc TestTCPInputSecure(t *testing.T) {\n\tserverCertPem, serverPrivPem := genCertificate(&x509.Certificate{\n\t\tDNSNames:    []string{\"localhost\"},\n\t\tIPAddresses: []net.IP{net.ParseIP(\"127.0.0.1\"), net.ParseIP(\"::\")},\n\t})\n\n\tserverCertPemFile, _ := ioutil.TempFile(\"\", \"server.crt\")\n\tserverCertPemFile.Write(serverCertPem)\n\tserverCertPemFile.Close()\n\n\tserverPrivPemFile, _ := ioutil.TempFile(\"\", \"server.key\")\n\tserverPrivPemFile.Write(serverPrivPem)\n\tserverPrivPemFile.Close()\n\n\tdefer func() {\n\t\tos.Remove(serverPrivPemFile.Name())\n\t\tos.Remove(serverCertPemFile.Name())\n\t}()\n\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTCPInput(\"127.0.0.1:0\", &TCPInputConfig{\n\t\tSecure:          true,\n\t\tCertificatePath: serverCertPemFile.Name(),\n\t\tKeyPath:         serverPrivPemFile.Name(),\n\t})\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tconf := &tls.Config{\n\t\tInsecureSkipVerify: true,\n\t}\n\n\tconn, err := tls.Dial(\"tcp\", input.listener.Addr().String(), conf)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer conn.Close()\n\n\tmsg := []byte(\"1 1 1\\nGET / HTTP/1.1\\r\\n\\r\\n\")\n\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(1)\n\t\tconn.Write(msg)\n\t\tconn.Write([]byte(payloadSeparator))\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "k8s",
          "type": "tree",
          "content": null
        },
        {
          "name": "kafka.go",
          "type": "blob",
          "size": 5.2109375,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"errors\"\n\t\"fmt\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"io/ioutil\"\n\t\"log\"\n\n\t\"github.com/Shopify/sarama\"\n\t\"github.com/xdg-go/scram\"\n)\n\n// SASLKafkaConfig SASL configuration\ntype SASLKafkaConfig struct {\n\tUseSASL   bool   `json:\"input-kafka-use-sasl\"`\n\tMechanism string `json:\"input-kafka-mechanism\"`\n\tUsername  string `json:\"input-kafka-username\"`\n\tPassword  string `json:\"input-kafka-password\"`\n}\n\n// InputKafkaConfig should contains required information to\n// build producers.\ntype InputKafkaConfig struct {\n\tconsumer   sarama.Consumer\n\tHost       string `json:\"input-kafka-host\"`\n\tTopic      string `json:\"input-kafka-topic\"`\n\tUseJSON    bool   `json:\"input-kafka-json-format\"`\n\tOffset     string  `json:\"input-kafka-offset\"`\n\tSASLConfig SASLKafkaConfig\n}\n\n// OutputKafkaConfig is the representation of kfka output configuration\ntype OutputKafkaConfig struct {\n\tproducer   sarama.AsyncProducer\n\tHost       string `json:\"output-kafka-host\"`\n\tTopic      string `json:\"output-kafka-topic\"`\n\tUseJSON    bool   `json:\"output-kafka-json-format\"`\n\tSASLConfig SASLKafkaConfig\n}\n\n// KafkaTLSConfig should contains TLS certificates for connecting to secured Kafka clusters\ntype KafkaTLSConfig struct {\n\tCACert     string `json:\"kafka-tls-ca-cert\"`\n\tClientCert string `json:\"kafka-tls-client-cert\"`\n\tClientKey  string `json:\"kafka-tls-client-key\"`\n}\n\n// KafkaMessage should contains catched request information that should be\n// passed as Json to Apache Kafka.\ntype KafkaMessage struct {\n\tReqURL     string            `json:\"Req_URL\"`\n\tReqType    string            `json:\"Req_Type\"`\n\tReqID      string            `json:\"Req_ID\"`\n\tReqTs      string            `json:\"Req_Ts\"`\n\tReqMethod  string            `json:\"Req_Method\"`\n\tReqBody    string            `json:\"Req_Body,omitempty\"`\n\tReqHeaders map[string]string `json:\"Req_Headers,omitempty\"`\n}\n\n// NewTLSConfig loads TLS certificates\nfunc NewTLSConfig(clientCertFile, clientKeyFile, caCertFile string) (*tls.Config, error) {\n\ttlsConfig := tls.Config{}\n\n\tif clientCertFile != \"\" && clientKeyFile == \"\" {\n\t\treturn &tlsConfig, errors.New(\"Missing key of client certificate in kafka\")\n\t}\n\tif clientCertFile == \"\" && clientKeyFile != \"\" {\n\t\treturn &tlsConfig, errors.New(\"missing TLS client certificate in kafka\")\n\t}\n\t// Load client cert\n\tif (clientCertFile != \"\") && (clientKeyFile != \"\") {\n\t\tcert, err := tls.LoadX509KeyPair(clientCertFile, clientKeyFile)\n\t\tif err != nil {\n\t\t\treturn &tlsConfig, err\n\t\t}\n\t\ttlsConfig.Certificates = []tls.Certificate{cert}\n\t}\n\t// Load CA cert\n\tif caCertFile != \"\" {\n\t\tcaCert, err := ioutil.ReadFile(caCertFile)\n\t\tif err != nil {\n\t\t\treturn &tlsConfig, err\n\t\t}\n\t\tcaCertPool := x509.NewCertPool()\n\t\tcaCertPool.AppendCertsFromPEM(caCert)\n\t\ttlsConfig.RootCAs = caCertPool\n\t}\n\treturn &tlsConfig, nil\n}\n\n// NewKafkaConfig returns Kafka config with or without TLS\nfunc NewKafkaConfig(saslConfig *SASLKafkaConfig, tlsConfig *KafkaTLSConfig) *sarama.Config {\n\tconfig := sarama.NewConfig()\n\t// Configuration options go here\n\tif tlsConfig != nil && (tlsConfig.ClientCert != \"\" || tlsConfig.CACert != \"\") {\n\t\tconfig.Net.TLS.Enable = true\n\t\ttlsConfig, err := NewTLSConfig(tlsConfig.ClientCert, tlsConfig.ClientKey, tlsConfig.CACert)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tconfig.Net.TLS.Config = tlsConfig\n\t}\n\tif saslConfig.UseSASL {\n\t\tmechanism := sarama.SASLMechanism(saslConfig.Mechanism)\n\t\tconfig.Net.SASL.Enable = saslConfig.UseSASL\n\t\tconfig.Net.SASL.Mechanism = mechanism\n\t\tconfig.Net.SASL.User = saslConfig.Username\n\t\tconfig.Net.SASL.Password = saslConfig.Password\n\t\tif mechanism == sarama.SASLTypeSCRAMSHA256 {\n\t\t\tconfig.Net.SASL.SCRAMClientGeneratorFunc = func() sarama.SCRAMClient { return &XDGSCRAMClient{HashGeneratorFcn: SHA256} }\n\t\t} else if mechanism == sarama.SASLTypeSCRAMSHA512 {\n\t\t\tconfig.Net.SASL.SCRAMClientGeneratorFunc = func() sarama.SCRAMClient { return &XDGSCRAMClient{HashGeneratorFcn: SHA512} }\n\t\t}\n\t}\n\treturn config\n}\n\n// Dump returns the given request in its HTTP/1.x wire\n// representation.\nfunc (m KafkaMessage) Dump() ([]byte, error) {\n\tvar b bytes.Buffer\n\n\tb.WriteString(fmt.Sprintf(\"%s %s %s\\n\", m.ReqType, m.ReqID, m.ReqTs))\n\tb.WriteString(fmt.Sprintf(\"%s %s HTTP/1.1\", m.ReqMethod, m.ReqURL))\n\tb.Write(proto.CRLF)\n\tfor key, value := range m.ReqHeaders {\n\t\tb.WriteString(fmt.Sprintf(\"%s: %s\", key, value))\n\t\tb.Write(proto.CRLF)\n\t}\n\n\tb.Write(proto.CRLF)\n\tb.WriteString(m.ReqBody)\n\n\treturn b.Bytes(), nil\n}\n\nvar (\n\t// SHA256 SASLMechanism\n\tSHA256 scram.HashGeneratorFcn = sha256.New\n\t// SHA512 SASLMechanism\n\tSHA512 scram.HashGeneratorFcn = sha512.New\n)\n\n// XDGSCRAMClient for SASL-Protocol\ntype XDGSCRAMClient struct {\n\t*scram.Client\n\t*scram.ClientConversation\n\tscram.HashGeneratorFcn\n}\n\n// Begin of XDGSCRAMClient\nfunc (x *XDGSCRAMClient) Begin(userName, password, authzID string) (err error) {\n\tx.Client, err = x.HashGeneratorFcn.NewClient(userName, password, authzID)\n\tif err != nil {\n\t\treturn err\n\t}\n\tx.ClientConversation = x.Client.NewConversation()\n\treturn nil\n}\n\n// Step of XDGSCRAMClient\nfunc (x *XDGSCRAMClient) Step(challenge string) (response string, err error) {\n\tresponse, err = x.ClientConversation.Step(challenge)\n\treturn\n}\n\n// Done of XDGSCRAMClient\nfunc (x *XDGSCRAMClient) Done() bool {\n\treturn x.ClientConversation.Done()\n}\n"
        },
        {
          "name": "limiter.go",
          "type": "blob",
          "size": 2.7216796875,
          "content": "package goreplay\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// Limiter is a wrapper for input or output plugin which adds rate limiting\ntype Limiter struct {\n\tplugin    interface{}\n\tlimit     int\n\tisPercent bool\n\n\tcurrentRPS  int\n\tcurrentTime int64\n}\n\nfunc parseLimitOptions(options string) (limit int, isPercent bool) {\n\tif n := strings.Index(options, \"%\"); n > 0 {\n\t\tlimit, _ = strconv.Atoi(options[:n])\n\t\tisPercent = true\n\t} else {\n\t\tlimit, _ = strconv.Atoi(options)\n\t\tisPercent = false\n\t}\n\n\treturn\n}\n\nfunc newLimiterExceptions(l *Limiter) {\n\n\tif !l.isPercent {\n\t\treturn\n\t}\n\tspeedFactor := float64(l.limit) / float64(100)\n\n\t// FileInput、KafkaInput have its own rate limiting. Unlike other inputs we not just dropping requests, we can slow down or speed up request emittion.\n\tswitch input := l.plugin.(type) {\n\tcase *FileInput:\n\t\tinput.speedFactor = speedFactor\n\tcase *KafkaInput:\n\t\tinput.speedFactor = speedFactor\n\t}\n}\n\n// NewLimiter constructor for Limiter, accepts plugin and options\n// `options` allow to sprcify relatve or absolute limiting\nfunc NewLimiter(plugin interface{}, options string) PluginReadWriter {\n\tl := new(Limiter)\n\tl.limit, l.isPercent = parseLimitOptions(options)\n\tl.plugin = plugin\n\tl.currentTime = time.Now().UnixNano()\n\n\tnewLimiterExceptions(l)\n\n\treturn l\n}\n\nfunc (l *Limiter) isLimitedExceptions() bool {\n\tif !l.isPercent {\n\t\treturn false\n\t}\n\t// Fileinput、Kafkainput have its own limiting algorithm\n\tswitch l.plugin.(type) {\n\tcase *FileInput:\n\t\treturn true\n\tcase *KafkaInput:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\nfunc (l *Limiter) isLimited() bool {\n\tif l.isLimitedExceptions() {\n\t\treturn false\n\t}\n\n\tif l.isPercent {\n\t\treturn l.limit <= rand.Intn(100)\n\t}\n\n\tif (time.Now().UnixNano() - l.currentTime) > time.Second.Nanoseconds() {\n\t\tl.currentTime = time.Now().UnixNano()\n\t\tl.currentRPS = 0\n\t}\n\n\tif l.currentRPS >= l.limit {\n\t\treturn true\n\t}\n\n\tl.currentRPS++\n\n\treturn false\n}\n\n// PluginWrite writes message to this plugin\nfunc (l *Limiter) PluginWrite(msg *Message) (n int, err error) {\n\tif l.isLimited() {\n\t\treturn 0, nil\n\t}\n\tif w, ok := l.plugin.(PluginWriter); ok {\n\t\treturn w.PluginWrite(msg)\n\t}\n\t// avoid further writing\n\treturn 0, io.ErrClosedPipe\n}\n\n// PluginRead reads message from this plugin\nfunc (l *Limiter) PluginRead() (msg *Message, err error) {\n\tif r, ok := l.plugin.(PluginReader); ok {\n\t\tmsg, err = r.PluginRead()\n\t} else {\n\t\t// avoid further reading\n\t\treturn nil, io.ErrClosedPipe\n\t}\n\n\tif l.isLimited() {\n\t\treturn nil, nil\n\t}\n\n\treturn\n}\n\nfunc (l *Limiter) String() string {\n\treturn fmt.Sprintf(\"Limiting %s to: %d (isPercent: %v)\", l.plugin, l.limit, l.isPercent)\n}\n\n// Close closes the resources.\nfunc (l *Limiter) Close() error {\n\tif fi, ok := l.plugin.(io.Closer); ok {\n\t\tfi.Close()\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "limiter_test.go",
          "type": "blob",
          "size": 2.0087890625,
          "content": "//go:build !race\n\npackage goreplay\n\nimport (\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestOutputLimiter(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\toutput := NewLimiter(NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t}), \"10\")\n\twg.Add(10)\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 100; i++ {\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc TestInputLimiter(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewLimiter(NewTestInput(), \"10\")\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\twg.Add(10)\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 100; i++ {\n\t\tinput.(*Limiter).plugin.(*TestInput).EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n\n// Should limit all requests\nfunc TestPercentLimiter1(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\toutput := NewLimiter(NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t}), \"0%\")\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 100; i++ {\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n}\n\n// Should not limit at all\nfunc TestPercentLimiter2(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\toutput := NewLimiter(NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t}), \"100%\")\n\twg.Add(100)\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 100; i++ {\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n}\n"
        },
        {
          "name": "middleware.go",
          "type": "blob",
          "size": 3.3388671875,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"encoding/hex\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n)\n\n// Middleware represents a middleware object\ntype Middleware struct {\n\tcommand       string\n\tdata          chan *Message\n\tStdin         io.Writer\n\tStdout        io.Reader\n\tcommandCancel context.CancelFunc\n\tstop          chan bool // Channel used only to indicate goroutine should shutdown\n\tclosed        bool\n\tmu            sync.RWMutex\n}\n\n// NewMiddleware returns new middleware\nfunc NewMiddleware(command string) *Middleware {\n\tm := new(Middleware)\n\tm.command = command\n\tm.data = make(chan *Message, 1000)\n\tm.stop = make(chan bool)\n\n\tcommands := strings.Split(command, \" \")\n\tctx, cancl := context.WithCancel(context.Background())\n\tm.commandCancel = cancl\n\tcmd := exec.CommandContext(ctx, commands[0], commands[1:]...)\n\n\tm.Stdout, _ = cmd.StdoutPipe()\n\tm.Stdin, _ = cmd.StdinPipe()\n\n\tcmd.Stderr = os.Stderr\n\n\tgo m.read(m.Stdout)\n\n\tgo func() {\n\t\tdefer m.Close()\n\t\tvar err error\n\t\tif err = cmd.Start(); err == nil {\n\t\t\terr = cmd.Wait()\n\t\t}\n\t\tif err != nil {\n\t\t\tif e, ok := err.(*exec.ExitError); ok {\n\t\t\t\tstatus := e.Sys().(syscall.WaitStatus)\n\t\t\t\tif status.Signal() == syscall.SIGKILL /*killed or context canceld */ {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t\tDebug(0, fmt.Sprintf(\"[MIDDLEWARE] command[%q] error: %q\", command, err.Error()))\n\t\t}\n\t}()\n\n\treturn m\n}\n\n// ReadFrom start a worker to read from this plugin\nfunc (m *Middleware) ReadFrom(plugin PluginReader) {\n\tDebug(2, fmt.Sprintf(\"[MIDDLEWARE] command[%q] Starting reading from %q\", m.command, plugin))\n\tgo m.copy(m.Stdin, plugin)\n}\n\nfunc (m *Middleware) copy(to io.Writer, from PluginReader) {\n\tvar buf, dst []byte\n\n\tfor {\n\t\tmsg, err := from.PluginRead()\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tif msg == nil || len(msg.Data) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tbuf = msg.Data\n\t\tif Settings.PrettifyHTTP {\n\t\t\tbuf = prettifyHTTP(msg.Data)\n\t\t}\n\t\tdstLen := (len(buf)+len(msg.Meta))*2 + 1\n\t\t// if enough space was previously allocated use it instead\n\t\tif dstLen > len(dst) {\n\t\t\tdst = make([]byte, dstLen)\n\t\t}\n\t\tn := hex.Encode(dst, msg.Meta)\n\t\tn += hex.Encode(dst[n:], buf)\n\t\tdst[n] = '\\n'\n\n\t\tn, err = to.Write(dst[:n+1])\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif m.isClosed() {\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (m *Middleware) read(from io.Reader) {\n\treader := bufio.NewReader(from)\n\tvar line []byte\n\tvar e error\n\tfor {\n\t\tif line, e = reader.ReadBytes('\\n'); e != nil {\n\t\t\tif m.isClosed() {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tbuf := make([]byte, (len(line)-1)/2)\n\t\tif _, err := hex.Decode(buf, line[:len(line)-1]); err != nil {\n\t\t\tDebug(0, fmt.Sprintf(\"[MIDDLEWARE] command[%q] failed to decode err: %q\", m.command, err))\n\t\t\tcontinue\n\t\t}\n\t\tvar msg Message\n\t\tmsg.Meta, msg.Data = payloadMetaWithBody(buf)\n\t\tselect {\n\t\tcase <-m.stop:\n\t\t\treturn\n\t\tcase m.data <- &msg:\n\t\t}\n\t}\n\n}\n\n// PluginRead reads message from this plugin\nfunc (m *Middleware) PluginRead() (msg *Message, err error) {\n\tselect {\n\tcase <-m.stop:\n\t\treturn nil, ErrorStopped\n\tcase msg = <-m.data:\n\t}\n\n\treturn\n}\n\nfunc (m *Middleware) String() string {\n\treturn fmt.Sprintf(\"Modifying traffic using %q command\", m.command)\n}\n\nfunc (m *Middleware) isClosed() bool {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\treturn m.closed\n}\n\n// Close closes this plugin\nfunc (m *Middleware) Close() error {\n\tif m.isClosed() {\n\t\treturn nil\n\t}\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tm.commandCancel()\n\tclose(m.stop)\n\tm.closed = true\n\treturn nil\n}\n"
        },
        {
          "name": "middleware",
          "type": "tree",
          "content": null
        },
        {
          "name": "middleware_test.go",
          "type": "blob",
          "size": 4.7919921875,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"syscall\"\n\t\"testing\"\n)\n\nconst echoSh = \"./examples/middleware/echo.sh\"\nconst tokenModifier = \"go run ./examples/middleware/token_modifier.go\"\n\nvar withDebug = append(syscall.Environ(), \"GOR_TEST=1\")\n\nfunc initMiddleware(cmd *exec.Cmd, cancl context.CancelFunc, l PluginReader, c func(error)) *Middleware {\n\tvar m Middleware\n\tm.data = make(chan *Message, 1000)\n\tm.stop = make(chan bool)\n\tm.commandCancel = cancl\n\tm.Stdout, _ = cmd.StdoutPipe()\n\tm.Stdin, _ = cmd.StdinPipe()\n\tcmd.Stderr = os.Stderr\n\tgo m.read(m.Stdout)\n\tgo func() {\n\t\tdefer m.Close()\n\t\tvar err error\n\t\tif err = cmd.Start(); err == nil {\n\t\t\terr = cmd.Wait()\n\t\t}\n\t\tif err != nil {\n\t\t\tc(err)\n\t\t}\n\t}()\n\tm.ReadFrom(l)\n\treturn &m\n}\n\nfunc initCmd(command string, env []string) (*exec.Cmd, context.CancelFunc) {\n\tcommands := strings.Split(command, \" \")\n\tctx, cancl := context.WithCancel(context.Background())\n\tcmd := exec.CommandContext(ctx, commands[0], commands[1:]...)\n\tcmd.Env = env\n\treturn cmd, cancl\n}\n\nfunc TestMiddlewareEarlyClose(t *testing.T) {\n\tquit := make(chan struct{})\n\tin := NewTestInput()\n\tcmd, cancl := initCmd(echoSh, withDebug)\n\tmidd := initMiddleware(cmd, cancl, in, func(err error) {\n\t\tif err != nil {\n\t\t\tif e, ok := err.(*exec.ExitError); ok {\n\t\t\t\tstatus := e.Sys().(syscall.WaitStatus)\n\t\t\t\tif status.Signal() != syscall.SIGKILL {\n\t\t\t\t\tt.Errorf(\"expected error to be signal killed. got %s\", status.Signal().String())\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tquit <- struct{}{}\n\t})\n\tvar body = []byte(\"OPTIONS / HTTP/1.1\\r\\nHost: example.org\\r\\n\\r\\n\")\n\tcount := uint32(0)\n\tout := NewTestOutput(func(msg *Message) {\n\t\tif !bytes.Equal(body, msg.Data) {\n\t\t\tt.Errorf(\"expected %q to equal %q\", body, msg.Data)\n\t\t}\n\t\tatomic.AddUint32(&count, 1)\n\t\tif atomic.LoadUint32(&count) == 5 {\n\t\t\tquit <- struct{}{}\n\t\t}\n\t})\n\tpl := &InOutPlugins{}\n\tpl.Inputs = []PluginReader{midd, in}\n\tpl.Outputs = []PluginWriter{out}\n\tpl.All = []interface{}{midd, out, in}\n\te := NewEmitter()\n\tgo e.Start(pl, \"\")\n\tfor i := 0; i < 5; i++ {\n\t\tin.EmitBytes(body)\n\t}\n\t<-quit\n\tmidd.Close()\n\t<-quit\n}\n\n//func TestTokenMiddleware(t *testing.T) {\n//\tquit := make(chan struct{})\n//\tin := NewTestInput()\n//\tin.skipHeader = true\n//\tcmd, cancl := initCmd(tokenModifier, withDebug)\n//\tmidd := initMiddleware(cmd, cancl, in, func(err error) {})\n//\treq := []byte(\"1 932079936fa4306fc308d67588178d17d823647c 1439818823587396305 200\\nGET /token HTTP/1.1\\r\\nHost: example.org\\r\\n\\r\\n\")\n//\tres := []byte(\"2 932079936fa4306fc308d67588178d17d823647c 1439818823587396305 200\\nHTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\\r\\n17d823647c\")\n//\trep := []byte(\"3 932079936fa4306fc308d67588178d17d823647c 1439818823587396305 200\\nHTTP/1.1 200 OK\\r\\nContent-Length: 15\\r\\nContent-Type: text/plain; charset=utf-8\\r\\n\\r\\n932079936fa4306\")\n//\tcount := uint32(0)\n//\tout := NewTestOutput(func(msg *Message) {\n//\t\tif msg.Meta[0] == '1' && !bytes.Equal(payloadID(msg.Meta), payloadID(req)) {\n//\t\t\ttoken, _, _ := proto.PathParam(msg.Data, []byte(\"token\"))\n//\t\t\tif !bytes.Equal(token, proto.Body(rep)) {\n//\t\t\t\tt.Errorf(\"expected the token %s to be equal to the replayed response's token %s\", token, proto.Body(rep))\n//\t\t\t}\n//\t\t}\n//\t\tatomic.AddUint32(&count, 1)\n//\t\tif atomic.LoadUint32(&count) == 2 {\n//\t\t\tquit <- struct{}{}\n//\t\t}\n//\t})\n//\tpl := &InOutPlugins{}\n//\tpl.Inputs = []PluginReader{midd, in}\n//\tpl.Outputs = []PluginWriter{out}\n//\tpl.All = []interface{}{midd, out, in}\n//\te := NewEmitter()\n//\tgo e.Start(pl, \"\")\n//\tin.EmitBytes(req) // emit original request\n//\tin.EmitBytes(res) // emit its response\n//\tin.EmitBytes(rep) // emit replayed response\n//\t// emit the request which should have modified token\n//\ttoken := []byte(\"1 8e091765ae902fef8a2b7d9dd96 14398188235873 100\\nGET /?token=17d823647c HTTP/1.1\\r\\nHost: example.org\\r\\n\\r\\n\")\n//\tin.EmitBytes(token)\n//\t<-quit\n//\tmidd.Close()\n//}\n\n//func TestMiddlewareWithPrettify(t *testing.T) {\n//\tSettings.PrettifyHTTP = true\n//\tquit := make(chan struct{})\n//\tin := NewTestInput()\n//\tcmd, cancl := initCmd(echoSh, withDebug)\n//\tmidd := initMiddleware(cmd, cancl, in, func(err error) {})\n//\tvar b1 = []byte(\"POST / HTTP/1.1\\r\\nHost: example.org\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n4\\r\\nWiki\\r\\n5\\r\\npedia\\r\\nE\\r\\n in\\r\\n\\r\\nchunks.\\r\\n0\\r\\n\\r\\n\")\n//\tvar b2 = []byte(\"POST / HTTP/1.1\\r\\nHost: example.org\\r\\nContent-Length: 25\\r\\n\\r\\nWikipedia in\\r\\n\\r\\nchunks.\")\n//\tout := NewTestOutput(func(msg *Message) {\n//\t\tif !bytes.Equal(proto.Body(b2), proto.Body(msg.Data)) {\n//\t\t\tt.Errorf(\"expected %q body to equal %q body\", b2, msg.Data)\n//\t\t}\n//\t\tquit <- struct{}{}\n//\t})\n//\tpl := &InOutPlugins{}\n//\tpl.Inputs = []PluginReader{midd, in}\n//\tpl.Outputs = []PluginWriter{out}\n//\tpl.All = []interface{}{midd, out, in}\n//\te := NewEmitter()\n//\tgo e.Start(pl, \"\")\n//\tin.EmitBytes(b1)\n//\t<-quit\n//\tmidd.Close()\n//\tSettings.PrettifyHTTP = false\n//}\n"
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 0.037109375,
          "content": "site_name: My Docs\ntheme: readthedocs\n"
        },
        {
          "name": "nfpm.yaml",
          "type": "blob",
          "size": 0.5166015625,
          "content": "# nfpm example config file\n#\n# check https://nfpm.goreleaser.com/configuration for detailed usage\n#\nname: \"GoReplay\"\narch: ${PLATFORM}\nplatform: \"linux\"\nversion: ${VERSION}\nsection: \"default\"\npriority: \"extra\"\nprovides:\n- goreplay\nmaintainer: \"Leonid Bugaev <hello@goreplay.org>\"\ndescription: |\n GoReplay is the simplest and safest way to test your app using real traffic before you put it into production. \nvendor: \"GoReplay\"\nhomepage: \"https://goreplay.org\"\nlicense: \"AGPL\"\ncontents:\n- src: ./${BIN_NAME}\n  dst: /usr/local/bin\n"
        },
        {
          "name": "output_binary.go",
          "type": "blob",
          "size": 1.5732421875,
          "content": "//go:build !pro\n\npackage goreplay\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/buger/goreplay/internal/size\"\n)\n\nvar _ PluginWriter = (*BinaryOutput)(nil)\n\n// BinaryOutputConfig struct for holding binary output configuration\ntype BinaryOutputConfig struct {\n\tWorkers        int           `json:\"output-binary-workers\"`\n\tTimeout        time.Duration `json:\"output-binary-timeout\"`\n\tBufferSize     size.Size     `json:\"output-tcp-response-buffer\"`\n\tDebug          bool          `json:\"output-binary-debug\"`\n\tTrackResponses bool          `json:\"output-binary-track-response\"`\n}\n\n// BinaryOutput plugin manage pool of workers which send request to replayed server\n// By default workers pool is dynamic and starts with 10 workers\n// You can specify fixed number of workers using `--output-tcp-workers`\ntype BinaryOutput struct {\n\taddress string\n}\n\n// NewBinaryOutput constructor for BinaryOutput\n// Initialize workers\nfunc NewBinaryOutput(address string, config *BinaryOutputConfig) PluginReadWriter {\n\treturn &BinaryOutput{address: address}\n}\n\n// PluginWrite writes a message to this plugin\nfunc (o *BinaryOutput) PluginWrite(msg *Message) (n int, err error) {\n\treturn 0, errors.New(\"binary output is only available in PRO version\")\n}\n\n// PluginRead reads a message from this plugin\nfunc (o *BinaryOutput) PluginRead() (*Message, error) {\n\treturn nil, errors.New(\"binary output is only available in PRO version\")\n}\n\nfunc (o *BinaryOutput) String() string {\n\treturn \"Binary output: \" + o.address + \" (PRO version required)\"\n}\n\n// Close closes this plugin for reading\nfunc (o *BinaryOutput) Close() error {\n\treturn nil\n}\n"
        },
        {
          "name": "output_binary_pro.go",
          "type": "blob",
          "size": 4.10546875,
          "content": "//go:build pro\n\npackage goreplay\n\nimport (\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/buger/goreplay/internal/size\"\n)\n\nvar _ PluginWriter = (*BinaryOutput)(nil)\n\n// BinaryOutputConfig struct for holding binary output configuration\ntype BinaryOutputConfig struct {\n\tWorkers        int           `json:\"output-binary-workers\"`\n\tTimeout        time.Duration `json:\"output-binary-timeout\"`\n\tBufferSize     size.Size     `json:\"output-tcp-response-buffer\"`\n\tDebug          bool          `json:\"output-binary-debug\"`\n\tTrackResponses bool          `json:\"output-binary-track-response\"`\n}\n\n// BinaryOutput plugin manage pool of workers which send request to replayed server\n// By default workers pool is dynamic and starts with 10 workers\n// You can specify fixed number of workers using `--output-tcp-workers`\ntype BinaryOutput struct {\n\t// Keep this as first element of struct because it guarantees 64bit\n\t// alignment. atomic.* functions crash on 32bit machines if operand is not\n\t// aligned at 64bit. See https://github.com/golang/go/issues/599\n\tactiveWorkers int64\n\taddress       string\n\tqueue         chan *Message\n\tresponses     chan response\n\tneedWorker    chan int\n\tquit          chan struct{}\n\tconfig        *BinaryOutputConfig\n\tqueueStats    *GorStat\n}\n\n// NewBinaryOutput constructor for BinaryOutput\n// Initialize workers\nfunc NewBinaryOutput(address string, config *BinaryOutputConfig) PluginReadWriter {\n\to := new(BinaryOutput)\n\n\to.address = address\n\to.config = config\n\n\to.queue = make(chan *Message, 1000)\n\to.responses = make(chan response, 1000)\n\to.needWorker = make(chan int, 1)\n\to.quit = make(chan struct{})\n\n\t// Initial workers count\n\tif o.config.Workers == 0 {\n\t\to.needWorker <- initialDynamicWorkers\n\t} else {\n\t\to.needWorker <- o.config.Workers\n\t}\n\n\tgo o.workerMaster()\n\n\treturn o\n}\n\nfunc (o *BinaryOutput) workerMaster() {\n\tfor {\n\t\tnewWorkers := <-o.needWorker\n\t\tfor i := 0; i < newWorkers; i++ {\n\t\t\tgo o.startWorker()\n\t\t}\n\n\t\t// Disable dynamic scaling if workers poll fixed size\n\t\tif o.config.Workers != 0 {\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (o *BinaryOutput) startWorker() {\n\tclient := NewTCPClient(o.address, &TCPClientConfig{\n\t\tDebug:              o.config.Debug,\n\t\tTimeout:            o.config.Timeout,\n\t\tResponseBufferSize: int(o.config.BufferSize),\n\t})\n\n\tdeathCount := 0\n\n\tatomic.AddInt64(&o.activeWorkers, 1)\n\n\tfor {\n\t\tselect {\n\t\tcase msg := <-o.queue:\n\t\t\to.sendRequest(client, msg)\n\t\t\tdeathCount = 0\n\t\tcase <-time.After(time.Millisecond * 100):\n\t\t\t// When dynamic scaling enabled workers die after 2s of inactivity\n\t\t\tif o.config.Workers == 0 {\n\t\t\t\tdeathCount++\n\t\t\t} else {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif deathCount > 20 {\n\t\t\t\tworkersCount := atomic.LoadInt64(&o.activeWorkers)\n\n\t\t\t\t// At least 1 startWorker should be alive\n\t\t\t\tif workersCount != 1 {\n\t\t\t\t\tatomic.AddInt64(&o.activeWorkers, -1)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// PluginWrite writes a message tothis plugin\nfunc (o *BinaryOutput) PluginWrite(msg *Message) (n int, err error) {\n\tif !isRequestPayload(msg.Meta) {\n\t\treturn len(msg.Data), nil\n\t}\n\n\to.queue <- msg\n\n\tif o.config.Workers == 0 {\n\t\tworkersCount := atomic.LoadInt64(&o.activeWorkers)\n\n\t\tif len(o.queue) > int(workersCount) {\n\t\t\to.needWorker <- len(o.queue)\n\t\t}\n\t}\n\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\n// PluginRead reads a message from this plugin\nfunc (o *BinaryOutput) PluginRead() (*Message, error) {\n\tvar resp response\n\tvar msg Message\n\tselect {\n\tcase <-o.quit:\n\t\treturn nil, ErrorStopped\n\tcase resp = <-o.responses:\n\t}\n\tmsg.Data = resp.payload\n\tmsg.Meta = payloadHeader(ReplayedResponsePayload, resp.uuid, resp.startedAt, resp.roundTripTime)\n\n\treturn &msg, nil\n}\n\nfunc (o *BinaryOutput) sendRequest(client *TCPClient, msg *Message) {\n\tif !isRequestPayload(msg.Meta) {\n\t\treturn\n\t}\n\n\tuuid := payloadID(msg.Meta)\n\n\tstart := time.Now()\n\tresp, err := client.Send(msg.Data)\n\tstop := time.Now()\n\n\tif err != nil {\n\t\tDebug(1, \"Request error:\", err)\n\t}\n\n\tif o.config.TrackResponses {\n\t\to.responses <- response{resp, uuid, start.UnixNano(), stop.UnixNano() - start.UnixNano()}\n\t}\n}\n\nfunc (o *BinaryOutput) String() string {\n\treturn \"Binary output: \" + o.address\n}\n\n// Close closes this plugin for reading\nfunc (o *BinaryOutput) Close() error {\n\tclose(o.quit)\n\treturn nil\n}\n"
        },
        {
          "name": "output_dummy.go",
          "type": "blob",
          "size": 0.6025390625,
          "content": "package goreplay\n\nimport (\n\t\"os\"\n)\n\n// DummyOutput used for debugging, prints all incoming requests\ntype DummyOutput struct {\n}\n\n// NewDummyOutput constructor for DummyOutput\nfunc NewDummyOutput() (di *DummyOutput) {\n\tdi = new(DummyOutput)\n\n\treturn\n}\n\n// PluginWrite writes message to this plugin\nfunc (i *DummyOutput) PluginWrite(msg *Message) (int, error) {\n\tvar n, nn int\n\tvar err error\n\tn, err = os.Stdout.Write(msg.Meta)\n\tnn, err = os.Stdout.Write(msg.Data)\n\tn += nn\n\tnn, err = os.Stdout.Write(payloadSeparatorAsBytes)\n\tn += nn\n\n\treturn n, err\n}\n\nfunc (i *DummyOutput) String() string {\n\treturn \"Dummy Output\"\n}\n"
        },
        {
          "name": "output_file.go",
          "type": "blob",
          "size": 6.95703125,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"compress/gzip\"\n\t\"errors\"\n\t\"fmt\"\n\t\"github.com/buger/goreplay/internal/size\"\n\t\"io\"\n\t\"log\"\n\t\"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime/debug\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar letters = []rune(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\nvar instanceID string\n\nfunc init() {\n\tinstanceID = randSeq(8)\n}\n\nfunc randSeq(n int) string {\n\tb := make([]rune, n)\n\tfor i := range b {\n\t\tb[i] = letters[rand.Intn(len(letters))]\n\t}\n\treturn string(b)\n}\n\nvar dateFileNameFuncs = map[string]func(*FileOutput) string{\n\t\"%Y\":  func(o *FileOutput) string { return time.Now().Format(\"2006\") },\n\t\"%m\":  func(o *FileOutput) string { return time.Now().Format(\"01\") },\n\t\"%d\":  func(o *FileOutput) string { return time.Now().Format(\"02\") },\n\t\"%H\":  func(o *FileOutput) string { return time.Now().Format(\"15\") },\n\t\"%M\":  func(o *FileOutput) string { return time.Now().Format(\"04\") },\n\t\"%S\":  func(o *FileOutput) string { return time.Now().Format(\"05\") },\n\t\"%NS\": func(o *FileOutput) string { return fmt.Sprint(time.Now().Nanosecond()) },\n\t\"%r\":  func(o *FileOutput) string { return string(o.currentID) },\n\t\"%t\":  func(o *FileOutput) string { return string(o.payloadType) },\n\t\"%i\":  func(o *FileOutput) string { return instanceID },\n}\n\n// FileOutputConfig ...\ntype FileOutputConfig struct {\n\tFlushInterval     time.Duration `json:\"output-file-flush-interval\"`\n\tSizeLimit         size.Size     `json:\"output-file-size-limit\"`\n\tOutputFileMaxSize size.Size     `json:\"output-file-max-size-limit\"`\n\tQueueLimit        int           `json:\"output-file-queue-limit\"`\n\tAppend            bool          `json:\"output-file-append\"`\n\tBufferPath        string        `json:\"output-file-buffer\"`\n\tonClose           func(string)\n}\n\n// FileOutput output plugin\ntype FileOutput struct {\n\tsync.RWMutex\n\tpathTemplate    string\n\tcurrentName     string\n\tfile            *os.File\n\tQueueLength     int\n\twriter          io.Writer\n\trequestPerFile  bool\n\tcurrentID       []byte\n\tpayloadType     []byte\n\tclosed          bool\n\tcurrentFileSize int\n\ttotalFileSize   size.Size\n\n\tconfig *FileOutputConfig\n}\n\n// NewFileOutput constructor for FileOutput, accepts path\nfunc NewFileOutput(pathTemplate string, config *FileOutputConfig) *FileOutput {\n\to := new(FileOutput)\n\to.pathTemplate = pathTemplate\n\to.config = config\n\n\tif strings.Contains(pathTemplate, \"%r\") {\n\t\to.requestPerFile = true\n\t}\n\n\tif config.FlushInterval == 0 {\n\t\tconfig.FlushInterval = 100 * time.Millisecond\n\t}\n\n\tgo func() {\n\t\tfor {\n\t\t\ttime.Sleep(config.FlushInterval)\n\t\t\tif o.IsClosed() {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\to.flush()\n\t\t}\n\t}()\n\n\treturn o\n}\n\nfunc getFileIndex(name string) int {\n\text := filepath.Ext(name)\n\twithoutExt := strings.TrimSuffix(name, ext)\n\n\tif idx := strings.LastIndex(withoutExt, \"_\"); idx != -1 {\n\t\tif i, err := strconv.Atoi(withoutExt[idx+1:]); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn -1\n}\n\nfunc setFileIndex(name string, idx int) string {\n\tidxS := strconv.Itoa(idx)\n\text := filepath.Ext(name)\n\twithoutExt := strings.TrimSuffix(name, ext)\n\n\tif i := strings.LastIndex(withoutExt, \"_\"); i != -1 {\n\t\tif _, err := strconv.Atoi(withoutExt[i+1:]); err == nil {\n\t\t\twithoutExt = withoutExt[:i]\n\t\t}\n\t}\n\n\treturn withoutExt + \"_\" + idxS + ext\n}\n\nfunc withoutIndex(s string) string {\n\tif i := strings.LastIndex(s, \"_\"); i != -1 {\n\t\treturn s[:i]\n\t}\n\n\treturn s\n}\n\ntype sortByFileIndex []string\n\nfunc (s sortByFileIndex) Len() int {\n\treturn len(s)\n}\n\nfunc (s sortByFileIndex) Swap(i, j int) {\n\ts[i], s[j] = s[j], s[i]\n}\n\nfunc (s sortByFileIndex) Less(i, j int) bool {\n\tif withoutIndex(s[i]) == withoutIndex(s[j]) {\n\t\treturn getFileIndex(s[i]) < getFileIndex(s[j])\n\t}\n\n\treturn s[i] < s[j]\n}\n\nfunc (o *FileOutput) filename() string {\n\to.RLock()\n\tdefer o.RUnlock()\n\n\tpath := o.pathTemplate\n\n\tfor name, fn := range dateFileNameFuncs {\n\t\tpath = strings.Replace(path, name, fn(o), -1)\n\t}\n\n\tif !o.config.Append {\n\t\tnextChunk := false\n\n\t\tif o.currentName == \"\" ||\n\t\t\t((o.config.QueueLimit > 0 && o.QueueLength >= o.config.QueueLimit) ||\n\t\t\t\t(o.config.SizeLimit > 0 && o.currentFileSize >= int(o.config.SizeLimit))) {\n\t\t\tnextChunk = true\n\t\t}\n\n\t\text := filepath.Ext(path)\n\t\twithoutExt := strings.TrimSuffix(path, ext)\n\n\t\tif matches, err := filepath.Glob(withoutExt + \"*\" + ext); err == nil {\n\t\t\tif len(matches) == 0 {\n\t\t\t\treturn setFileIndex(path, 0)\n\t\t\t}\n\t\t\tsort.Sort(sortByFileIndex(matches))\n\n\t\t\tlast := matches[len(matches)-1]\n\n\t\t\tfileIndex := 0\n\t\t\tif idx := getFileIndex(last); idx != -1 {\n\t\t\t\tfileIndex = idx\n\n\t\t\t\tif nextChunk {\n\t\t\t\t\tfileIndex++\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn setFileIndex(last, fileIndex)\n\t\t}\n\t}\n\n\treturn path\n}\n\nfunc (o *FileOutput) updateName() {\n\tname := filepath.Clean(o.filename())\n\to.Lock()\n\to.currentName = name\n\to.Unlock()\n}\n\n// PluginWrite writes message to this plugin\nfunc (o *FileOutput) PluginWrite(msg *Message) (n int, err error) {\n\tif o.requestPerFile {\n\t\to.Lock()\n\t\tmeta := payloadMeta(msg.Meta)\n\t\to.currentID = meta[1]\n\t\to.payloadType = meta[0]\n\t\to.Unlock()\n\t}\n\n\to.updateName()\n\to.Lock()\n\tdefer o.Unlock()\n\n\tif o.file == nil || o.currentName != o.file.Name() {\n\t\to.closeLocked()\n\n\t\to.file, err = os.OpenFile(o.currentName, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0660)\n\t\to.file.Sync()\n\n\t\tif strings.HasSuffix(o.currentName, \".gz\") {\n\t\t\to.writer = gzip.NewWriter(o.file)\n\t\t} else {\n\t\t\to.writer = bufio.NewWriter(o.file)\n\t\t}\n\n\t\tif err != nil {\n\t\t\tlog.Fatal(o, \"Cannot open file %q. Error: %s\", o.currentName, err)\n\t\t}\n\n\t\to.QueueLength = 0\n\t}\n\n\tvar nn int\n\tn, err = o.writer.Write(msg.Meta)\n\tnn, err = o.writer.Write(msg.Data)\n\tn += nn\n\tnn, err = o.writer.Write(payloadSeparatorAsBytes)\n\tn += nn\n\n\to.totalFileSize += size.Size(n)\n\to.currentFileSize += n\n\to.QueueLength++\n\n\tif Settings.OutputFileConfig.OutputFileMaxSize > 0 && o.totalFileSize >= Settings.OutputFileConfig.OutputFileMaxSize {\n\t\treturn n, errors.New(\"File output reached size limit\")\n\t}\n\n\treturn n, err\n}\n\nfunc (o *FileOutput) flush() {\n\t// Don't exit on panic\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tDebug(0, \"[OUTPUT-FILE] PANIC while file flush: \", r, o, string(debug.Stack()))\n\t\t}\n\t}()\n\n\to.Lock()\n\tdefer o.Unlock()\n\n\tif o.file != nil {\n\t\tif strings.HasSuffix(o.currentName, \".gz\") {\n\t\t\to.writer.(*gzip.Writer).Flush()\n\t\t} else {\n\t\t\to.writer.(*bufio.Writer).Flush()\n\t\t}\n\n\t\tif stat, err := o.file.Stat(); err == nil {\n\t\t\to.currentFileSize = int(stat.Size())\n\t\t} else {\n\t\t\tDebug(0, \"[OUTPUT-HTTP] error accessing file size\", err)\n\t\t}\n\t}\n}\n\nfunc (o *FileOutput) String() string {\n\treturn \"File output: \" + o.file.Name()\n}\n\nfunc (o *FileOutput) closeLocked() error {\n\tif o.file != nil {\n\t\tif strings.HasSuffix(o.currentName, \".gz\") {\n\t\t\to.writer.(*gzip.Writer).Close()\n\t\t} else {\n\t\t\to.writer.(*bufio.Writer).Flush()\n\t\t}\n\t\to.file.Close()\n\n\t\tif o.config.onClose != nil {\n\t\t\to.config.onClose(o.file.Name())\n\t\t}\n\t}\n\n\to.closed = true\n\to.currentFileSize = 0\n\n\treturn nil\n}\n\n// Close closes the output file that is being written to.\nfunc (o *FileOutput) Close() error {\n\to.Lock()\n\tdefer o.Unlock()\n\treturn o.closeLocked()\n}\n\n// IsClosed returns if the output file is closed or not.\nfunc (o *FileOutput) IsClosed() bool {\n\to.Lock()\n\tdefer o.Unlock()\n\treturn o.closed\n}\n"
        },
        {
          "name": "output_file_test.go",
          "type": "blob",
          "size": 8.869140625,
          "content": "package goreplay\n\nimport (\n\t\"fmt\"\n\t\"github.com/buger/goreplay/internal/size\"\n\t\"math/rand\"\n\t\"os\"\n\t\"reflect\"\n\t\"sort\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestFileOutput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\toutput := NewFileOutput(\"/tmp/test_requests.gor\", &FileOutputConfig{FlushInterval: time.Minute, Append: true})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(2)\n\t\tinput.EmitGET()\n\t\tinput.EmitPOST()\n\t}\n\ttime.Sleep(100 * time.Millisecond)\n\toutput.flush()\n\temitter.Close()\n\n\tvar counter int64\n\tinput2 := NewFileInput(\"/tmp/test_requests.gor\", false, 100, 0, false)\n\toutput2 := NewTestOutput(func(*Message) {\n\t\tatomic.AddInt64(&counter, 1)\n\t\twg.Done()\n\t})\n\n\tplugins2 := &InOutPlugins{\n\t\tInputs:  []PluginReader{input2},\n\t\tOutputs: []PluginWriter{output2},\n\t}\n\tplugins2.All = append(plugins2.All, input2, output2)\n\n\temitter2 := NewEmitter()\n\tgo emitter2.Start(plugins2, Settings.Middleware)\n\n\twg.Wait()\n\temitter2.Close()\n}\n\nfunc TestFileOutputWithNameCleaning(t *testing.T) {\n\toutput := &FileOutput{pathTemplate: \"./test_requests.gor\", config: &FileOutputConfig{FlushInterval: time.Minute, Append: false}}\n\texpectedFileName := \"test_requests_0.gor\"\n\toutput.updateName()\n\n\tif expectedFileName != output.currentName {\n\t\tt.Errorf(\"Expected path %s but got %s\", expectedFileName, output.currentName)\n\t}\n\n}\n\nfunc TestFileOutputPathTemplate(t *testing.T) {\n\toutput := &FileOutput{pathTemplate: \"/tmp/log-%Y-%m-%d-%S-%t\", config: &FileOutputConfig{FlushInterval: time.Minute, Append: true}}\n\tnow := time.Now()\n\toutput.payloadType = []byte(\"3\")\n\texpectedPath := fmt.Sprintf(\"/tmp/log-%s-%s-%s-%s-3\", now.Format(\"2006\"), now.Format(\"01\"), now.Format(\"02\"), now.Format(\"05\"))\n\tpath := output.filename()\n\n\tif expectedPath != path {\n\t\tt.Errorf(\"Expected path %s but got %s\", expectedPath, path)\n\t}\n}\n\nfunc TestFileOutputMultipleFiles(t *testing.T) {\n\toutput := NewFileOutput(\"/tmp/log-%Y-%m-%d-%S\", &FileOutputConfig{Append: true, FlushInterval: time.Minute})\n\n\tif output.file != nil {\n\t\tt.Error(\"Should not initialize file if no writes\")\n\t}\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\ttime.Sleep(time.Second)\n\toutput.updateName()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name2 != name1 {\n\t\tt.Error(\"Fast changes should happen in same file:\", name1, name2, name3)\n\t}\n\n\tif name3 == name1 {\n\t\tt.Error(\"File name should change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name3)\n}\n\nfunc TestFileOutputFilePerRequest(t *testing.T) {\n\toutput := NewFileOutput(\"/tmp/log-%Y-%m-%d-%S-%r\", &FileOutputConfig{Append: true})\n\n\tif output.file != nil {\n\t\tt.Error(\"Should not initialize file if no writes\")\n\t}\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 2 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\ttime.Sleep(time.Second)\n\toutput.updateName()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 3 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name3 == name2 || name2 == name1 || name3 == name1 {\n\t\tt.Error(\"File name should change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name2)\n\tos.Remove(name3)\n}\n\nfunc TestFileOutputCompression(t *testing.T) {\n\toutput := NewFileOutput(\"/tmp/log-%Y-%m-%d-%S.gz\", &FileOutputConfig{Append: true, FlushInterval: time.Minute})\n\n\tif output.file != nil {\n\t\tt.Error(\"Should not initialize file if no writes\")\n\t}\n\n\tfor i := 0; i < 1000; i++ {\n\t\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\t}\n\n\tname := output.file.Name()\n\toutput.Close()\n\n\ts, _ := os.Stat(name)\n\tif s.Size() == 12*1000 {\n\t\tt.Error(\"Should be compressed file:\", s.Size())\n\t}\n\n\tos.Remove(name)\n}\n\nfunc TestGetFileIndex(t *testing.T) {\n\tvar tests = []struct {\n\t\tpath  string\n\t\tindex int\n\t}{\n\t\t{\"/tmp/logs\", -1},\n\t\t{\"/tmp/logs_1\", 1},\n\t\t{\"/tmp/logs_2.gz\", 2},\n\t\t{\"/tmp/logs_0.gz\", 0},\n\t}\n\n\tfor _, c := range tests {\n\t\tif getFileIndex(c.path) != c.index {\n\t\t\tt.Error(c.path, \"should be\", c.index, \"instead\", getFileIndex(c.path))\n\t\t}\n\t}\n}\n\nfunc TestSetFileIndex(t *testing.T) {\n\tvar tests = []struct {\n\t\tpath    string\n\t\tindex   int\n\t\tnewPath string\n\t}{\n\t\t{\"/tmp/logs\", 0, \"/tmp/logs_0\"},\n\t\t{\"/tmp/logs.gz\", 1, \"/tmp/logs_1.gz\"},\n\t\t{\"/tmp/logs_1\", 0, \"/tmp/logs_0\"},\n\t\t{\"/tmp/logs_0\", 10, \"/tmp/logs_10\"},\n\t\t{\"/tmp/logs_0.gz\", 10, \"/tmp/logs_10.gz\"},\n\t\t{\"/tmp/logs_underscores.gz\", 10, \"/tmp/logs_underscores_10.gz\"},\n\t}\n\n\tfor _, c := range tests {\n\t\tif setFileIndex(c.path, c.index) != c.newPath {\n\t\t\tt.Error(c.path, \"should be\", c.newPath, \"instead\", setFileIndex(c.path, c.index))\n\t\t}\n\t}\n}\n\nfunc TestFileOutputAppendQueueLimitOverflow(t *testing.T) {\n\trnd := rand.Int63()\n\tname := fmt.Sprintf(\"/tmp/%d\", rnd)\n\n\toutput := NewFileOutput(name, &FileOutputConfig{Append: false, FlushInterval: time.Minute, QueueLimit: 2})\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\toutput.updateName()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name2 != name1 || name1 != fmt.Sprintf(\"/tmp/%d_0\", rnd) {\n\t\tt.Error(\"Fast changes should happen in same file:\", name1, name2, name3)\n\t}\n\n\tif name3 == name1 || name3 != fmt.Sprintf(\"/tmp/%d_1\", rnd) {\n\t\tt.Error(\"File name should change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name3)\n}\n\nfunc TestFileOutputAppendQueueLimitNoOverflow(t *testing.T) {\n\trnd := rand.Int63()\n\tname := fmt.Sprintf(\"/tmp/%d\", rnd)\n\n\toutput := NewFileOutput(name, &FileOutputConfig{Append: false, FlushInterval: time.Minute, QueueLimit: 3})\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\toutput.updateName()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name2 != name1 || name1 != fmt.Sprintf(\"/tmp/%d_0\", rnd) {\n\t\tt.Error(\"Fast changes should happen in same file:\", name1, name2, name3)\n\t}\n\n\tif name3 != name1 || name3 != fmt.Sprintf(\"/tmp/%d_0\", rnd) {\n\t\tt.Error(\"File name should not change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name3)\n}\n\nfunc TestFileOutputAppendQueueLimitGzips(t *testing.T) {\n\trnd := rand.Int63()\n\tname := fmt.Sprintf(\"/tmp/%d.gz\", rnd)\n\n\toutput := NewFileOutput(name, &FileOutputConfig{Append: false, FlushInterval: time.Minute, QueueLimit: 2})\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\toutput.updateName()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name2 != name1 || name1 != fmt.Sprintf(\"/tmp/%d_0.gz\", rnd) {\n\t\tt.Error(\"Fast changes should happen in same file:\", name1, name2, name3)\n\t}\n\n\tif name3 == name1 || name3 != fmt.Sprintf(\"/tmp/%d_1.gz\", rnd) {\n\t\tt.Error(\"File name should change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name3)\n}\n\nfunc TestFileOutputSort(t *testing.T) {\n\tvar files = []string{\"2016_0\", \"2014_10\", \"2015_0\", \"2015_10\", \"2015_2\"}\n\tvar expected = []string{\"2014_10\", \"2015_0\", \"2015_2\", \"2015_10\", \"2016_0\"}\n\tsort.Sort(sortByFileIndex(files))\n\n\tif !reflect.DeepEqual(files, expected) {\n\t\tt.Error(\"Should properly sort file names using indexes\", files, expected)\n\t}\n}\n\nfunc TestFileOutputAppendSizeLimitOverflow(t *testing.T) {\n\trnd := rand.Int63()\n\tname := fmt.Sprintf(\"/tmp/%d\", rnd)\n\n\tmessage := []byte(\"1 1 1\\r\\ntest\")\n\n\tmessageSize := len(message) + len(payloadSeparator)\n\n\toutput := NewFileOutput(name, &FileOutputConfig{Append: false, FlushInterval: time.Minute, SizeLimit: size.Size(2 * messageSize)})\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname1 := output.file.Name()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname2 := output.file.Name()\n\n\toutput.flush()\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 1 1\\r\\n\"), Data: []byte(\"test\")})\n\tname3 := output.file.Name()\n\n\tif name2 != name1 || name1 != fmt.Sprintf(\"/tmp/%d_0\", rnd) {\n\t\tt.Error(\"Fast changes should happen in same file:\", name1, name2, name3)\n\t}\n\n\tif name3 == name1 || name3 != fmt.Sprintf(\"/tmp/%d_1\", rnd) {\n\t\tt.Error(\"File name should change:\", name1, name2, name3)\n\t}\n\n\tos.Remove(name1)\n\tos.Remove(name3)\n}\n"
        },
        {
          "name": "output_http.go",
          "type": "blob",
          "size": 10.9287109375,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"log\"\n\t\"math\"\n\t\"net/http\"\n\t\"net/http/httputil\"\n\t\"net/url\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/buger/goreplay/internal/size\"\n)\n\nconst (\n\tinitialDynamicWorkers = 10\n\treadChunkSize         = 64 * 1024\n\tmaxResponseSize       = 1073741824\n)\n\ntype response struct {\n\tpayload       []byte\n\tuuid          []byte\n\tstartedAt     int64\n\troundTripTime int64\n}\n\n// HTTPOutputConfig struct for holding http output configuration\ntype HTTPOutputConfig struct {\n\tTrackResponses    bool          `json:\"output-http-track-response\"`\n\tStats             bool          `json:\"output-http-stats\"`\n\tOriginalHost      bool          `json:\"output-http-original-host\"`\n\tRedirectLimit     int           `json:\"output-http-redirect-limit\"`\n\tWorkersMin        int           `json:\"output-http-workers-min\"`\n\tWorkersMax        int           `json:\"output-http-workers\"`\n\tStatsMs           int           `json:\"output-http-stats-ms\"`\n\tQueueLen          int           `json:\"output-http-queue-len\"`\n\tElasticSearch     string        `json:\"output-http-elasticsearch\"`\n\tTimeout           time.Duration `json:\"output-http-timeout\"`\n\tWorkerTimeout     time.Duration `json:\"output-http-worker-timeout\"`\n\tBufferSize        size.Size     `json:\"output-http-response-buffer\"`\n\tSkipVerify        bool          `json:\"output-http-skip-verify\"`\n\tCompatibilityMode bool          `json:\"output-http-compatibility-mode\"`\n\tRequestGroup      string        `json:\"output-http-request-group\"`\n\tDebug             bool          `json:\"output-http-debug\"`\n\trawURL            string\n\turl               *url.URL\n}\n\nfunc (hoc *HTTPOutputConfig) Copy() *HTTPOutputConfig {\n\treturn &HTTPOutputConfig{\n\t\tTrackResponses:    hoc.TrackResponses,\n\t\tStats:             hoc.Stats,\n\t\tOriginalHost:      hoc.OriginalHost,\n\t\tRedirectLimit:     hoc.RedirectLimit,\n\t\tWorkersMin:        hoc.WorkersMin,\n\t\tWorkersMax:        hoc.WorkersMax,\n\t\tStatsMs:           hoc.StatsMs,\n\t\tQueueLen:          hoc.QueueLen,\n\t\tElasticSearch:     hoc.ElasticSearch,\n\t\tTimeout:           hoc.Timeout,\n\t\tWorkerTimeout:     hoc.WorkerTimeout,\n\t\tBufferSize:        hoc.BufferSize,\n\t\tSkipVerify:        hoc.SkipVerify,\n\t\tCompatibilityMode: hoc.CompatibilityMode,\n\t\tRequestGroup:      hoc.RequestGroup,\n\t\tDebug:             hoc.Debug,\n\t}\n}\n\n// HTTPOutput plugin manage pool of workers which send request to replayed server\n// By default workers pool is dynamic and starts with 1 worker or workerMin workers\n// You can specify maximum number of workers using `--output-http-workers`\ntype HTTPOutput struct {\n\tactiveWorkers  int64\n\tconfig         *HTTPOutputConfig\n\tqueueStats     *GorStat\n\telasticSearch  *ESPlugin\n\tclient         *HTTPClient\n\tstopWorker     chan struct{}\n\tqueue          chan *Message\n\tresponses      chan *response\n\tstop           chan bool // Channel used only to indicate goroutine should shutdown\n\tworkerSessions map[string]*httpWorker\n}\n\ntype httpWorker struct {\n\toutput       *HTTPOutput\n\tclient       *HTTPClient\n\tlastActivity time.Time\n\tqueue        chan *Message\n\tstop         chan bool\n}\n\nfunc newHTTPWorker(output *HTTPOutput, queue chan *Message) *httpWorker {\n\tclient := NewHTTPClient(output.config)\n\n\tw := &httpWorker{client: client, output: output}\n\tif queue == nil {\n\t\tw.queue = make(chan *Message, 100)\n\t} else {\n\t\tw.queue = queue\n\t}\n\tw.stop = make(chan bool)\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase msg := <-w.queue:\n\t\t\t\toutput.sendRequest(client, msg)\n\t\t\tcase <-w.stop:\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn w\n}\n\n// NewHTTPOutput constructor for HTTPOutput\n// Initialize workers\nfunc NewHTTPOutput(address string, config *HTTPOutputConfig) PluginReadWriter {\n\to := new(HTTPOutput)\n\tvar err error\n\tnewConfig := config.Copy()\n\tnewConfig.url, err = url.Parse(address)\n\tif err != nil {\n\t\tlog.Fatal(fmt.Sprintf(\"[OUTPUT-HTTP] parse HTTP output URL error[%q]\", err))\n\t}\n\tif newConfig.url.Scheme == \"\" {\n\t\tnewConfig.url.Scheme = \"http\"\n\t}\n\tnewConfig.rawURL = newConfig.url.String()\n\tif newConfig.Timeout < time.Millisecond*100 {\n\t\tnewConfig.Timeout = time.Second\n\t}\n\tif newConfig.BufferSize <= 0 {\n\t\tnewConfig.BufferSize = 100 * 1024 // 100kb\n\t}\n\tif newConfig.WorkersMin <= 0 {\n\t\tnewConfig.WorkersMin = 1\n\t}\n\tif newConfig.WorkersMin > 1000 {\n\t\tnewConfig.WorkersMin = 1000\n\t}\n\tif newConfig.WorkersMax <= 0 {\n\t\tnewConfig.WorkersMax = math.MaxInt32 // ideally so large\n\t}\n\tif newConfig.WorkersMax < newConfig.WorkersMin {\n\t\tnewConfig.WorkersMax = newConfig.WorkersMin\n\t}\n\tif newConfig.QueueLen <= 0 {\n\t\tnewConfig.QueueLen = 1000\n\t}\n\tif newConfig.RedirectLimit < 0 {\n\t\tnewConfig.RedirectLimit = 0\n\t}\n\tif newConfig.WorkerTimeout <= 0 {\n\t\tnewConfig.WorkerTimeout = time.Second * 2\n\t}\n\to.config = newConfig\n\to.stop = make(chan bool)\n\tif o.config.Stats {\n\t\to.queueStats = NewGorStat(\"output_http\", o.config.StatsMs)\n\t}\n\n\to.queue = make(chan *Message, o.config.QueueLen)\n\tif o.config.TrackResponses {\n\t\to.responses = make(chan *response, o.config.QueueLen)\n\t}\n\t// it should not be buffered to avoid races\n\to.stopWorker = make(chan struct{})\n\n\tif o.config.ElasticSearch != \"\" {\n\t\to.elasticSearch = new(ESPlugin)\n\t\to.elasticSearch.Init(o.config.ElasticSearch)\n\t}\n\to.client = NewHTTPClient(o.config)\n\n\tif Settings.RecognizeTCPSessions {\n\t\to.workerSessions = make(map[string]*httpWorker, 100)\n\t\tgo o.sessionWorkerMaster()\n\t} else {\n\t\to.activeWorkers += int64(o.config.WorkersMin)\n\t\tfor i := 0; i < o.config.WorkersMin; i++ {\n\t\t\tgo o.startWorker()\n\t\t}\n\t\tgo o.workerMaster()\n\t}\n\n\treturn o\n}\n\nfunc (o *HTTPOutput) workerMaster() {\n\tvar timer = time.NewTimer(o.config.WorkerTimeout)\n\tdefer func() {\n\t\t// recover from panics caused by trying to send in\n\t\t// a closed chan(o.stopWorker)\n\t\trecover()\n\t}()\n\tdefer timer.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-o.stop:\n\t\t\treturn\n\t\tdefault:\n\t\t\t<-timer.C\n\t\t}\n\t\t// rollback workers\n\trollback:\n\t\tif atomic.LoadInt64(&o.activeWorkers) > int64(o.config.WorkersMin) && len(o.queue) < 1 {\n\t\t\t// close one worker\n\t\t\to.stopWorker <- struct{}{}\n\t\t\tatomic.AddInt64(&o.activeWorkers, -1)\n\t\t\tgoto rollback\n\t\t}\n\t\ttimer.Reset(o.config.WorkerTimeout)\n\t}\n}\n\nfunc (o *HTTPOutput) sessionWorkerMaster() {\n\tgc := time.Tick(time.Second)\n\n\tfor {\n\t\tselect {\n\t\tcase msg := <-o.queue:\n\t\t\tid := payloadID(msg.Meta)\n\t\t\tsessionID := string(id[0:20])\n\t\t\tworker, ok := o.workerSessions[sessionID]\n\n\t\t\tif !ok {\n\t\t\t\tatomic.AddInt64(&o.activeWorkers, 1)\n\t\t\t\tworker = newHTTPWorker(o, nil)\n\t\t\t\to.workerSessions[sessionID] = worker\n\t\t\t}\n\n\t\t\tworker.queue <- msg\n\t\t\tworker.lastActivity = time.Now()\n\t\tcase <-gc:\n\t\t\tnow := time.Now()\n\n\t\t\tfor id, w := range o.workerSessions {\n\t\t\t\tif !w.lastActivity.IsZero() && now.Sub(w.lastActivity) >= 120*time.Second {\n\t\t\t\t\tw.stop <- true\n\t\t\t\t\tdelete(o.workerSessions, id)\n\t\t\t\t\tatomic.AddInt64(&o.activeWorkers, -1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (o *HTTPOutput) startWorker() {\n\tfor {\n\t\tselect {\n\t\tcase <-o.stopWorker:\n\t\t\treturn\n\t\tcase msg := <-o.queue:\n\t\t\to.sendRequest(o.client, msg)\n\t\t}\n\t}\n}\n\n// PluginWrite writes message to this plugin\nfunc (o *HTTPOutput) PluginWrite(msg *Message) (n int, err error) {\n\tif !isRequestPayload(msg.Meta) {\n\t\treturn len(msg.Data), nil\n\t}\n\n\tselect {\n\tcase <-o.stop:\n\t\treturn 0, ErrorStopped\n\tcase o.queue <- msg:\n\t}\n\n\tif o.config.Stats {\n\t\to.queueStats.Write(len(o.queue))\n\t}\n\n\tif !Settings.RecognizeTCPSessions && o.config.WorkersMax != o.config.WorkersMin {\n\t\tworkersCount := int(atomic.LoadInt64(&o.activeWorkers))\n\n\t\tif len(o.queue) > workersCount {\n\t\t\textraWorkersReq := len(o.queue) - workersCount + 1\n\t\t\tmaxWorkersAvailable := o.config.WorkersMax - workersCount\n\t\t\tif extraWorkersReq > maxWorkersAvailable {\n\t\t\t\textraWorkersReq = maxWorkersAvailable\n\t\t\t}\n\t\t\tif extraWorkersReq > 0 {\n\t\t\t\tfor i := 0; i < extraWorkersReq; i++ {\n\t\t\t\t\tgo o.startWorker()\n\t\t\t\t\tatomic.AddInt64(&o.activeWorkers, 1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\n// PluginRead reads message from this plugin\nfunc (o *HTTPOutput) PluginRead() (*Message, error) {\n\tif !o.config.TrackResponses {\n\t\treturn nil, ErrorStopped\n\t}\n\tvar resp *response\n\tvar msg Message\n\tselect {\n\tcase <-o.stop:\n\t\treturn nil, ErrorStopped\n\tcase resp = <-o.responses:\n\t\tmsg.Data = resp.payload\n\t}\n\n\tmsg.Meta = payloadHeader(ReplayedResponsePayload, resp.uuid, resp.startedAt, resp.roundTripTime)\n\n\treturn &msg, nil\n}\n\nfunc (o *HTTPOutput) sendRequest(client *HTTPClient, msg *Message) {\n\tif !isRequestPayload(msg.Meta) {\n\t\treturn\n\t}\n\n\tuuid := payloadID(msg.Meta)\n\tstart := time.Now()\n\tresp, err := client.Send(msg.Data)\n\tstop := time.Now()\n\n\tif err != nil {\n\t\tDebug(1, fmt.Sprintf(\"[HTTP-OUTPUT] error when sending: %q\", err))\n\t\treturn\n\t}\n\tif resp == nil {\n\t\treturn\n\t}\n\n\tif o.config.TrackResponses {\n\t\to.responses <- &response{resp, uuid, start.UnixNano(), stop.UnixNano() - start.UnixNano()}\n\t}\n\n\tif o.elasticSearch != nil {\n\t\to.elasticSearch.ResponseAnalyze(msg.Data, resp, start, stop)\n\t}\n}\n\nfunc (o *HTTPOutput) String() string {\n\treturn \"HTTP output: \" + o.config.rawURL\n}\n\n// Close closes the data channel so that data\nfunc (o *HTTPOutput) Close() error {\n\tclose(o.stop)\n\tclose(o.stopWorker)\n\treturn nil\n}\n\n// HTTPClient holds configurations for a single HTTP client\ntype HTTPClient struct {\n\tconfig *HTTPOutputConfig\n\tClient *http.Client\n}\n\n// NewHTTPClient returns new http client with check redirects policy\nfunc NewHTTPClient(config *HTTPOutputConfig) *HTTPClient {\n\tclient := new(HTTPClient)\n\tclient.config = config\n\tvar transport *http.Transport\n\tclient.Client = &http.Client{\n\t\tTimeout: client.config.Timeout,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\tif len(via) >= client.config.RedirectLimit {\n\t\t\t\tDebug(1, fmt.Sprintf(\"[HTTPCLIENT] maximum output-http-redirects[%d] reached!\", client.config.RedirectLimit))\n\t\t\t\treturn http.ErrUseLastResponse\n\t\t\t}\n\t\t\tlastReq := via[len(via)-1]\n\t\t\tresp := req.Response\n\t\t\tDebug(2, fmt.Sprintf(\"[HTTPCLIENT] HTTP redirects from %q to %q with %q\", lastReq.Host, req.Host, resp.Status))\n\t\t\treturn nil\n\t\t},\n\t}\n\tif config.SkipVerify {\n\t\t// clone to avoid modifying global default RoundTripper\n\t\ttransport = http.DefaultTransport.(*http.Transport).Clone()\n\t\ttransport.TLSClientConfig = &tls.Config{InsecureSkipVerify: true}\n\t\tclient.Client.Transport = transport\n\t}\n\n\treturn client\n}\n\n// Send sends an http request using client created by NewHTTPClient\nfunc (c *HTTPClient) Send(data []byte) ([]byte, error) {\n\tvar req *http.Request\n\tvar resp *http.Response\n\tvar err error\n\n\treq, err = http.ReadRequest(bufio.NewReader(bytes.NewReader(data)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// we don't send CONNECT or OPTIONS request\n\tif req.Method == http.MethodConnect {\n\t\treturn nil, nil\n\t}\n\n\tif !c.config.OriginalHost {\n\t\treq.Host = c.config.url.Host\n\t}\n\n\t// fix #862\n\tif c.config.url.Path == \"\" && c.config.url.RawQuery == \"\" {\n\t\treq.URL.Scheme = c.config.url.Scheme\n\t\treq.URL.Host = c.config.url.Host\n\t} else {\n\t\treq.URL = c.config.url\n\t}\n\n\t// force connection to not be closed, which can affect the global client\n\treq.Close = false\n\t// it's an error if this is not equal to empty string\n\treq.RequestURI = \"\"\n\n\tresp, err = c.Client.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif c.config.TrackResponses {\n\t\treturn httputil.DumpResponse(resp, true)\n\t}\n\t_ = resp.Body.Close()\n\treturn nil, nil\n}\n"
        },
        {
          "name": "output_http_test.go",
          "type": "blob",
          "size": 5.33984375,
          "content": "package goreplay\n\nimport (\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t_ \"net/http/httputil\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestHTTPOutput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\tif req.Header.Get(\"User-Agent\") != \"Gor\" {\n\t\t\tt.Error(\"Wrong header\")\n\t\t}\n\n\t\tif req.Method == \"OPTIONS\" {\n\t\t\tt.Error(\"Wrong method\")\n\t\t}\n\n\t\tif req.Method == \"POST\" {\n\t\t\tdefer req.Body.Close()\n\t\t\tbody, _ := ioutil.ReadAll(req.Body)\n\n\t\t\tif string(body) != \"a=1&b=2\" {\n\t\t\t\tt.Error(\"Wrong POST body:\", string(body))\n\t\t\t}\n\t\t}\n\n\t\twg.Done()\n\t}))\n\tdefer server.Close()\n\n\theaders := HTTPHeaders{httpHeader{\"User-Agent\", \"Gor\"}}\n\tmethods := HTTPMethods{[]byte(\"GET\"), []byte(\"PUT\"), []byte(\"POST\")}\n\tSettings.ModifierConfig = HTTPModifierConfig{Headers: headers, Methods: methods}\n\n\thttpOutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{TrackResponses: false})\n\toutput := NewTestOutput(func(*Message) {\n\t\twg.Done()\n\t})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{httpOutput, output},\n\t}\n\tplugins.All = append(plugins.All, input, output, httpOutput)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 10; i++ {\n\t\t// 2 http-output, 2 - test output request\n\t\twg.Add(4) // OPTIONS should be ignored\n\t\tinput.EmitPOST()\n\t\tinput.EmitOPTIONS()\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n\n\tSettings.ModifierConfig = HTTPModifierConfig{}\n}\n\nfunc TestHTTPOutputKeepOriginalHost(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\n\tserver := httptest.NewTLSServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\tif req.Host != \"custom-host.com\" {\n\t\t\tt.Error(\"Wrong header\", req.Host)\n\t\t}\n\n\t\twg.Done()\n\t}))\n\tdefer server.Close()\n\n\theaders := HTTPHeaders{httpHeader{\"Host\", \"custom-host.com\"}}\n\tSettings.ModifierConfig = HTTPModifierConfig{Headers: headers}\n\n\toutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{OriginalHost: true, SkipVerify: true})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\twg.Add(1)\n\tinput.EmitGET()\n\n\twg.Wait()\n\temitter.Close()\n\tSettings.ModifierConfig = HTTPModifierConfig{}\n}\n\nfunc TestHTTPOutputSSL(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\t// Origing and Replay server initialization\n\tserver := httptest.NewTLSServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\twg.Done()\n\t}))\n\n\tinput := NewTestInput()\n\toutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{SkipVerify: true})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\twg.Add(2)\n\n\tinput.EmitPOST()\n\tinput.EmitGET()\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc TestHTTPOutputSessions(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tinput := NewTestInput()\n\tinput.skipHeader = true\n\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\twg.Done()\n\t}))\n\tdefer server.Close()\n\n\tSettings.RecognizeTCPSessions = true\n\tSettings.SplitOutput = true\n\toutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tuuid1 := []byte(\"1234567890123456789a0000\")\n\tuuid2 := []byte(\"1234567890123456789d0000\")\n\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1) // OPTIONS should be ignored\n\t\tcopy(uuid1[20:], randByte(4))\n\t\tinput.EmitBytes([]byte(\"1 \" + string(uuid1) + \" 1\\n\" + \"GET / HTTP/1.1\\r\\n\\r\\n\"))\n\t}\n\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1) // OPTIONS should be ignored\n\t\tcopy(uuid2[20:], randByte(4))\n\t\tinput.EmitBytes([]byte(\"1 \" + string(uuid2) + \" 1\\n\" + \"GET / HTTP/1.1\\r\\n\\r\\n\"))\n\t}\n\n\twg.Wait()\n\n\temitter.Close()\n\n\tSettings.RecognizeTCPSessions = false\n\tSettings.SplitOutput = false\n}\n\nfunc BenchmarkHTTPOutput(b *testing.B) {\n\twg := new(sync.WaitGroup)\n\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\twg.Done()\n\t}))\n\tdefer server.Close()\n\n\tinput := NewTestInput()\n\toutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{WorkersMax: 1})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitPOST()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc BenchmarkHTTPOutputTLS(b *testing.B) {\n\twg := new(sync.WaitGroup)\n\n\tserver := httptest.NewTLSServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\twg.Done()\n\t}))\n\tdefer server.Close()\n\n\tinput := NewTestInput()\n\toutput := NewHTTPOutput(server.URL, &HTTPOutputConfig{SkipVerify: true, WorkersMax: 1})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\tplugins.All = append(plugins.All, input, output)\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < b.N; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitPOST()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n"
        },
        {
          "name": "output_kafka.go",
          "type": "blob",
          "size": 2.615234375,
          "content": "package goreplay\n\nimport (\n\t\"encoding/json\"\n\t\"github.com/buger/goreplay/internal/byteutils\"\n\t\"github.com/buger/goreplay/proto\"\n\t\"log\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/Shopify/sarama\"\n\t\"github.com/Shopify/sarama/mocks\"\n)\n\n// KafkaOutput is used for sending payloads to kafka in JSON format.\ntype KafkaOutput struct {\n\tconfig   *OutputKafkaConfig\n\tproducer sarama.AsyncProducer\n}\n\n// KafkaOutputFrequency in milliseconds\nconst KafkaOutputFrequency = 500\n\n// NewKafkaOutput creates instance of kafka producer client  with TLS config\nfunc NewKafkaOutput(_ string, config *OutputKafkaConfig, tlsConfig *KafkaTLSConfig) PluginWriter {\n\tc := NewKafkaConfig(&config.SASLConfig, tlsConfig)\n\n\tvar producer sarama.AsyncProducer\n\n\tif mock, ok := config.producer.(*mocks.AsyncProducer); ok && mock != nil {\n\t\tproducer = config.producer\n\t} else {\n\t\tc.Producer.RequiredAcks = sarama.WaitForLocal\n\t\tc.Producer.Compression = sarama.CompressionSnappy\n\t\tc.Producer.Flush.Frequency = KafkaOutputFrequency * time.Millisecond\n\n\t\tbrokerList := strings.Split(config.Host, \",\")\n\n\t\tvar err error\n\t\tproducer, err = sarama.NewAsyncProducer(brokerList, c)\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"Failed to start Sarama(Kafka) producer:\", err)\n\t\t}\n\t}\n\n\to := &KafkaOutput{\n\t\tconfig:   config,\n\t\tproducer: producer,\n\t}\n\n\t// Start infinite loop for tracking errors for kafka producer.\n\tgo o.ErrorHandler()\n\n\treturn o\n}\n\n// ErrorHandler should receive errors\nfunc (o *KafkaOutput) ErrorHandler() {\n\tfor err := range o.producer.Errors() {\n\t\tDebug(1, \"Failed to write access log entry:\", err)\n\t}\n}\n\n// PluginWrite writes a message to this plugin\nfunc (o *KafkaOutput) PluginWrite(msg *Message) (n int, err error) {\n\tvar message sarama.StringEncoder\n\n\tif !o.config.UseJSON {\n\t\tmessage = sarama.StringEncoder(byteutils.SliceToString(msg.Meta) + byteutils.SliceToString(msg.Data))\n\t} else {\n\t\tmimeHeader := proto.ParseHeaders(msg.Data)\n\t\theader := make(map[string]string)\n\t\tfor k, v := range mimeHeader {\n\t\t\theader[k] = strings.Join(v, \", \")\n\t\t}\n\n\t\tmeta := payloadMeta(msg.Meta)\n\t\treq := msg.Data\n\n\t\tkafkaMessage := KafkaMessage{\n\t\t\tReqURL:     byteutils.SliceToString(proto.Path(req)),\n\t\t\tReqType:    byteutils.SliceToString(meta[0]),\n\t\t\tReqID:      byteutils.SliceToString(meta[1]),\n\t\t\tReqTs:      byteutils.SliceToString(meta[2]),\n\t\t\tReqMethod:  byteutils.SliceToString(proto.Method(req)),\n\t\t\tReqBody:    byteutils.SliceToString(proto.Body(req)),\n\t\t\tReqHeaders: header,\n\t\t}\n\t\tjsonMessage, _ := json.Marshal(&kafkaMessage)\n\t\tmessage = sarama.StringEncoder(byteutils.SliceToString(jsonMessage))\n\t}\n\n\to.producer.Input() <- &sarama.ProducerMessage{\n\t\tTopic: o.config.Topic,\n\t\tValue: message,\n\t}\n\n\treturn len(message), nil\n}\n"
        },
        {
          "name": "output_kafka_test.go",
          "type": "blob",
          "size": 1.3369140625,
          "content": "package goreplay\n\nimport (\n\t\"testing\"\n\n\t\"github.com/Shopify/sarama\"\n\t\"github.com/Shopify/sarama/mocks\"\n)\n\nfunc TestOutputKafkaRAW(t *testing.T) {\n\tconfig := sarama.NewConfig()\n\tconfig.Producer.Return.Successes = true\n\tproducer := mocks.NewAsyncProducer(t, config)\n\tproducer.ExpectInputAndSucceed()\n\n\toutput := NewKafkaOutput(\"\", &OutputKafkaConfig{\n\t\tproducer: producer,\n\t\tTopic:    \"test\",\n\t\tUseJSON:  false,\n\t}, nil)\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 2 3\\n\"), Data: []byte(\"GET / HTTP1.1\\r\\nHeader: 1\\r\\n\\r\\n\")})\n\n\tresp := <-producer.Successes()\n\n\tdata, _ := resp.Value.Encode()\n\n\tif string(data) != \"1 2 3\\nGET / HTTP1.1\\r\\nHeader: 1\\r\\n\\r\\n\" {\n\t\tt.Errorf(\"Message not properly encoded: %q\", data)\n\t}\n}\n\nfunc TestOutputKafkaJSON(t *testing.T) {\n\tconfig := sarama.NewConfig()\n\tconfig.Producer.Return.Successes = true\n\tproducer := mocks.NewAsyncProducer(t, config)\n\tproducer.ExpectInputAndSucceed()\n\n\toutput := NewKafkaOutput(\"\", &OutputKafkaConfig{\n\t\tproducer: producer,\n\t\tTopic:    \"test\",\n\t\tUseJSON:  true,\n\t}, nil)\n\n\toutput.PluginWrite(&Message{Meta: []byte(\"1 2 3\\n\"), Data: []byte(\"GET / HTTP1.1\\r\\nHeader: 1\\r\\n\\r\\n\")})\n\n\tresp := <-producer.Successes()\n\n\tdata, _ := resp.Value.Encode()\n\n\tif string(data) != `{\"Req_URL\":\"\",\"Req_Type\":\"1\",\"Req_ID\":\"2\",\"Req_Ts\":\"3\",\"Req_Method\":\"GET\"}` {\n\t\tt.Error(\"Message not properly encoded: \", string(data))\n\t}\n}\n"
        },
        {
          "name": "output_null.go",
          "type": "blob",
          "size": 0.4111328125,
          "content": "package goreplay\n\n// NullOutput used for debugging, prints nothing\ntype NullOutput struct {\n}\n\n// NewNullOutput constructor for NullOutput\nfunc NewNullOutput() (o *NullOutput) {\n\treturn new(NullOutput)\n}\n\n// PluginWrite writes message to this plugin\nfunc (o *NullOutput) PluginWrite(msg *Message) (int, error) {\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\nfunc (o *NullOutput) String() string {\n\treturn \"Null Output\"\n}\n"
        },
        {
          "name": "output_s3.go",
          "type": "blob",
          "size": 0.642578125,
          "content": "//go:build !pro\n\npackage goreplay\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// S3Output output plugin\ntype S3Output struct{}\n\n// NewS3Output constructor for FileOutput, accepts path\nfunc NewS3Output(pathTemplate string, config *FileOutputConfig) *S3Output {\n\tfmt.Println(\"S3 output is only available in the pro version\")\n\treturn &S3Output{}\n}\n\nfunc (o *S3Output) PluginWrite(msg *Message) (n int, err error) {\n\treturn 0, errors.New(\"S3 output is only available in the pro version\")\n}\n\nfunc (o *S3Output) String() string {\n\treturn \"S3 output (pro version only)\"\n}\n\nfunc (o *S3Output) Close() error {\n\treturn errors.New(\"S3 output is only available in the pro version\")\n}\n"
        },
        {
          "name": "output_s3_pro.go",
          "type": "blob",
          "size": 2.3291015625,
          "content": "//go:build pro\n\npackage goreplay\n\nimport (\n\t_ \"bufio\"\n\t\"fmt\"\n\t_ \"io\"\n\t\"log\"\n\t\"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n\t_ \"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n)\n\nvar _ PluginWriter = (*S3Output)(nil)\n\n// S3Output output plugin\ntype S3Output struct {\n\tpathTemplate string\n\n\tbuffer  *FileOutput\n\tsession *session.Session\n\tconfig  *FileOutputConfig\n\tcloseC  chan struct{}\n}\n\n// NewS3Output constructor for FileOutput, accepts path\nfunc NewS3Output(pathTemplate string, config *FileOutputConfig) *S3Output {\n\to := new(S3Output)\n\to.pathTemplate = pathTemplate\n\to.config = config\n\to.config.onClose = o.onBufferUpdate\n\n\tif config.BufferPath == \"\" {\n\t\tconfig.BufferPath = \"/tmp\"\n\t}\n\n\trnd := rand.Int63()\n\tbuffer_name := fmt.Sprintf(\"gor_output_s3_%d_buf_\", rnd)\n\n\tpathParts := strings.Split(pathTemplate, \"/\")\n\tbuffer_name += pathParts[len(pathParts)-1]\n\n\tif strings.HasSuffix(o.pathTemplate, \".gz\") {\n\t\tbuffer_name += \".gz\"\n\t}\n\n\tbuffer_path := filepath.Join(config.BufferPath, buffer_name)\n\n\to.buffer = NewFileOutput(buffer_path, config)\n\to.connect()\n\n\treturn o\n}\n\nfunc (o *S3Output) connect() {\n\tif o.session == nil {\n\t\to.session = session.Must(session.NewSession(awsConfig()))\n\t\tlog.Println(\"[S3 Output] S3 connection succesfully initialized\")\n\t}\n}\n\nfunc (o *S3Output) PluginWrite(msg *Message) (n int, err error) {\n\treturn o.buffer.PluginWrite(msg)\n}\n\nfunc (o *S3Output) String() string {\n\treturn \"S3 output: \" + o.pathTemplate\n}\n\nfunc (o *S3Output) Close() error {\n\treturn o.buffer.Close()\n}\n\nfunc (o *S3Output) keyPath(idx int) (bucket, key string) {\n\tbucket, key = parseS3Url(o.pathTemplate)\n\n\tfor name, fn := range dateFileNameFuncs {\n\t\tkey = strings.Replace(key, name, fn(o.buffer), -1)\n\t}\n\n\tkey = setFileIndex(key, idx)\n\n\treturn\n}\n\nfunc (o *S3Output) onBufferUpdate(path string) {\n\tsvc := s3.New(o.session)\n\tidx := getFileIndex(path)\n\tbucket, key := o.keyPath(idx)\n\n\tfile, _ := os.Open(path)\n\t// reader := bufio.NewReader(file)\n\n\t_, err := svc.PutObject(&s3.PutObjectInput{\n\t\tBody:   file,\n\t\tBucket: aws.String(bucket),\n\t\tKey:    aws.String(key),\n\t})\n\tif err != nil {\n\t\tlog.Printf(\"[S3 Output] Failed to upload data to %s/%s, %s\\n\", bucket, key, err)\n\t\tos.Remove(path)\n\t\treturn\n\t}\n\n\tos.Remove(path)\n\n\tif o.closeC != nil {\n\t\to.closeC <- struct{}{}\n\t}\n}\n"
        },
        {
          "name": "output_tcp.go",
          "type": "blob",
          "size": 3.796875,
          "content": "package goreplay\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"hash/fnv\"\n\t\"net\"\n\t\"time\"\n)\n\n// TCPOutput used for sending raw tcp payloads\n// Currently used for internal communication between listener and replay server\n// Can be used for transferring binary payloads like protocol buffers\ntype TCPOutput struct {\n\taddress     string\n\tlimit       int\n\tbuf         []chan *Message\n\tbufStats    *GorStat\n\tconfig      *TCPOutputConfig\n\tworkerIndex uint32\n\n\tclose bool\n}\n\n// TCPOutputConfig tcp output configuration\ntype TCPOutputConfig struct {\n\tSecure     bool `json:\"output-tcp-secure\"`\n\tSticky     bool `json:\"output-tcp-sticky\"`\n\tSkipVerify bool `json:\"output-tcp-skip-verify\"`\n\tWorkers    int  `json:\"output-tcp-workers\"`\n\n\tGetInitMessage     func() *Message                         `json:\"-\"`\n\tWriteBeforeMessage func(conn net.Conn, msg *Message) error `json:\"-\"`\n}\n\n// NewTCPOutput constructor for TCPOutput\n// Initialize X workers which hold keep-alive connection\nfunc NewTCPOutput(address string, config *TCPOutputConfig) PluginWriter {\n\to := new(TCPOutput)\n\n\to.address = address\n\to.config = config\n\n\tif Settings.OutputTCPStats {\n\t\to.bufStats = NewGorStat(\"output_tcp\", 5000)\n\t}\n\n\t// create X buffers and send the buffer index to the worker\n\to.buf = make([]chan *Message, o.config.Workers)\n\tfor i := 0; i < o.config.Workers; i++ {\n\t\to.buf[i] = make(chan *Message, 100)\n\t\tgo o.worker(i)\n\t}\n\n\treturn o\n}\n\nfunc (o *TCPOutput) worker(bufferIndex int) {\n\tretries := 0\n\tconn, err := o.connect(o.address)\n\tfor {\n\t\tif o.close {\n\t\t\treturn\n\t\t}\n\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tDebug(1, fmt.Sprintf(\"Can't connect to aggregator instance, reconnecting in 1 second. Retries:%d\", retries))\n\t\ttime.Sleep(1 * time.Second)\n\n\t\tconn, err = o.connect(o.address)\n\t\tretries++\n\t}\n\n\tif retries > 0 {\n\t\tDebug(2, fmt.Sprintf(\"Connected to aggregator instance after %d retries\", retries))\n\t}\n\n\tdefer conn.Close()\n\n\tif o.config.GetInitMessage != nil {\n\t\tmsg := o.config.GetInitMessage()\n\t\t_ = o.writeToConnection(conn, msg)\n\t}\n\n\tfor {\n\t\tmsg := <-o.buf[bufferIndex]\n\t\terr = o.writeToConnection(conn, msg)\n\t\tif err != nil {\n\t\t\tDebug(2, \"INFO: TCP output connection closed, reconnecting\")\n\t\t\tgo o.worker(bufferIndex)\n\t\t\to.buf[bufferIndex] <- msg\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc (o *TCPOutput) writeToConnection(conn net.Conn, msg *Message) (err error) {\n\tif o.config.WriteBeforeMessage != nil {\n\t\terr = o.config.WriteBeforeMessage(conn, msg)\n\t}\n\n\tif err == nil {\n\t\tif _, err = conn.Write(msg.Meta); err == nil {\n\t\t\tif _, err = conn.Write(msg.Data); err == nil {\n\t\t\t\t_, err = conn.Write(payloadSeparatorAsBytes)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn err\n}\n\nfunc (o *TCPOutput) getBufferIndex(msg *Message) int {\n\tif !o.config.Sticky {\n\t\to.workerIndex++\n\t\treturn int(o.workerIndex) % o.config.Workers\n\t}\n\n\thasher := fnv.New32a()\n\thasher.Write(payloadID(msg.Meta))\n\treturn int(hasher.Sum32()) % o.config.Workers\n}\n\n// PluginWrite writes message to this plugin\nfunc (o *TCPOutput) PluginWrite(msg *Message) (n int, err error) {\n\tif !isOriginPayload(msg.Meta) {\n\t\treturn len(msg.Data), nil\n\t}\n\n\tbufferIndex := o.getBufferIndex(msg)\n\to.buf[bufferIndex] <- msg\n\n\tif Settings.OutputTCPStats {\n\t\to.bufStats.Write(len(o.buf[bufferIndex]))\n\t}\n\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\nfunc (o *TCPOutput) connect(address string) (conn net.Conn, err error) {\n\tif o.config.Secure {\n\t\tvar d tls.Dialer\n\t\td.Config = &tls.Config{InsecureSkipVerify: o.config.SkipVerify}\n\t\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\tconn, err = d.DialContext(ctx, \"tcp\", address)\n\t} else {\n\t\tvar d net.Dialer\n\t\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\tconn, err = d.DialContext(ctx, \"tcp\", address)\n\t}\n\n\treturn\n}\n\nfunc (o *TCPOutput) String() string {\n\treturn fmt.Sprintf(\"TCP output %s, limit: %d\", o.address, o.limit)\n}\n\nfunc (o *TCPOutput) Close() {\n\to.close = true\n}\n"
        },
        {
          "name": "output_tcp_test.go",
          "type": "blob",
          "size": 4.6025390625,
          "content": "package goreplay\n\nimport (\n\t\"bufio\"\n\t\"log\"\n\t\"net\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestTCPOutput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tlistener := startTCP(func(data []byte) {\n\t\twg.Done()\n\t})\n\toutput := NewTCPOutput(listener.Addr().String(), &TCPOutputConfig{Workers: 10})\n\trunTCPOutput(wg, output, 10, false)\n}\n\nfunc startTCP(cb func([]byte)) net.Listener {\n\tlistener, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\n\tif err != nil {\n\t\tlog.Fatal(\"Can't start:\", err)\n\t}\n\n\tgo func() {\n\t\tfor {\n\t\t\tconn, _ := listener.Accept()\n\n\t\t\tgo func(conn net.Conn) {\n\t\t\t\tdefer conn.Close()\n\t\t\t\treader := bufio.NewReader(conn)\n\t\t\t\tscanner := bufio.NewScanner(reader)\n\t\t\t\tscanner.Split(payloadScanner)\n\n\t\t\t\tfor scanner.Scan() {\n\t\t\t\t\tcb(scanner.Bytes())\n\t\t\t\t}\n\t\t\t}(conn)\n\t\t}\n\t}()\n\n\treturn listener\n}\n\nfunc BenchmarkTCPOutput(b *testing.B) {\n\twg := new(sync.WaitGroup)\n\n\tlistener := startTCP(func(data []byte) {\n\t\twg.Done()\n\t})\n\tinput := NewTestInput()\n\tinput.data = make(chan []byte, b.N)\n\tfor i := 0; i < b.N; i++ {\n\t\tinput.EmitGET()\n\t}\n\twg.Add(b.N)\n\toutput := NewTCPOutput(listener.Addr().String(), &TCPOutputConfig{Workers: 10})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\n\temitter := NewEmitter()\n\t// avoid counting above initialization\n\tb.ResetTimer()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\twg.Wait()\n\temitter.Close()\n}\n\nfunc TestStickyDisable(t *testing.T) {\n\ttcpOutput := TCPOutput{config: &TCPOutputConfig{Sticky: false, Workers: 10}}\n\n\tfor i := 0; i < 10; i++ {\n\t\tindex := tcpOutput.getBufferIndex(getTestBytes())\n\t\tif index != (i+1)%10 {\n\t\t\tt.Errorf(\"Sticky is disable. Got: %d want %d\", index, (i+1)%10)\n\t\t}\n\t}\n}\n\nfunc TestBufferDistribution(t *testing.T) {\n\tnumberOfWorkers := 10\n\tnumberOfMessages := 10000\n\tpercentDistributionErrorRange := 20\n\n\tbuffer := make([]int, numberOfWorkers)\n\ttcpOutput := TCPOutput{config: &TCPOutputConfig{Sticky: true, Workers: 10}}\n\tfor i := 0; i < numberOfMessages; i++ {\n\t\tbuffer[tcpOutput.getBufferIndex(getTestBytes())]++\n\t}\n\n\texpectedDistribution := numberOfMessages / numberOfWorkers\n\tlowerDistribution := expectedDistribution - (expectedDistribution * percentDistributionErrorRange / 100)\n\tupperDistribution := expectedDistribution + (expectedDistribution * percentDistributionErrorRange / 100)\n\tfor i := 0; i < numberOfWorkers; i++ {\n\t\tif buffer[i] < lowerDistribution {\n\t\t\tt.Errorf(\"Under expected distribution. Got %d expected lower distribution %d\", buffer[i], lowerDistribution)\n\t\t}\n\t\tif buffer[i] > upperDistribution {\n\t\t\tt.Errorf(\"Under expected distribution. Got %d expected upper distribution %d\", buffer[i], upperDistribution)\n\t\t}\n\t}\n}\n\nfunc getTestBytes() *Message {\n\treturn &Message{\n\t\tMeta: payloadHeader(RequestPayload, uuid(), time.Now().UnixNano(), -1),\n\t\tData: []byte(\"GET / HTTP/1.1\\r\\nHost: www.w3.org\\r\\nUser-Agent: Go 1.1 package http\\r\\nAccept-Encoding: gzip\\r\\n\\r\\n\"),\n\t}\n}\n\nfunc TestTCPOutputGetInitMessage(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tvar dataList [][]byte\n\tlistener := startTCP(func(data []byte) {\n\t\tdataList = append(dataList, data)\n\t\twg.Done()\n\t})\n\tgetInitMessage := func() *Message {\n\t\treturn &Message{\n\t\t\tMeta: []byte{},\n\t\t\tData: []byte(\"test1\"),\n\t\t}\n\t}\n\toutput := NewTCPOutput(listener.Addr().String(), &TCPOutputConfig{Workers: 1, GetInitMessage: getInitMessage})\n\n\trunTCPOutput(wg, output, 1, true)\n\n\tif assert.Equal(t, 2, len(dataList)) {\n\t\tassert.Equal(t, \"test1\", string(dataList[0]))\n\t}\n}\n\nfunc TestTCPOutputGetInitMessageAndWriteBeforeMessage(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tvar dataList [][]byte\n\tlistener := startTCP(func(data []byte) {\n\t\tdataList = append(dataList, data)\n\t\twg.Done()\n\t})\n\tgetInitMessage := func() *Message {\n\t\treturn &Message{\n\t\t\tMeta: []byte{},\n\t\t\tData: []byte(\"test2\"),\n\t\t}\n\t}\n\twriteBeforeMessage := func(conn net.Conn, _ *Message) error {\n\t\t_, err := conn.Write([]byte(\"before\"))\n\t\treturn err\n\t}\n\toutput := NewTCPOutput(listener.Addr().String(), &TCPOutputConfig{Workers: 1, GetInitMessage: getInitMessage, WriteBeforeMessage: writeBeforeMessage})\n\n\trunTCPOutput(wg, output, 1, true)\n\n\tif assert.Equal(t, 2, len(dataList)) {\n\t\tassert.Equal(t, \"beforetest2\", string(dataList[0]))\n\t\tassert.True(t, strings.HasPrefix(string(dataList[1]), \"before\"))\n\t}\n}\n\nfunc runTCPOutput(wg *sync.WaitGroup, output PluginWriter, repeat int, initMessage bool) {\n\tinput := NewTestInput()\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tif initMessage {\n\t\twg.Add(1)\n\t}\n\tfor i := 0; i < repeat; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n}\n"
        },
        {
          "name": "output_ws.go",
          "type": "blob",
          "size": 3.71484375,
          "content": "package goreplay\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"hash/fnv\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/gorilla/websocket\"\n)\n\n// WebSocketOutput used for sending raw tcp payloads\n// Can be used for transferring binary payloads like protocol buffers\ntype WebSocketOutput struct {\n\taddress     string\n\tlimit       int\n\tbuf         []chan *Message\n\tbufStats    *GorStat\n\tconfig      *WebSocketOutputConfig\n\tworkerIndex uint32\n\theaders     http.Header\n\n\tclose bool\n}\n\n// WebSocketOutputConfig WebSocket output configuration\ntype WebSocketOutputConfig struct {\n\tSticky     bool `json:\"output-ws-sticky\"`\n\tSkipVerify bool `json:\"output-ws-skip-verify\"`\n\tWorkers    int  `json:\"output-ws-workers\"`\n\n\tHeaders map[string][]string `json:\"output-ws-headers\"`\n}\n\n// NewWebSocketOutput constructor for WebSocketOutput\n// Initialize X workers which hold keep-alive connection\nfunc NewWebSocketOutput(address string, config *WebSocketOutputConfig) PluginWriter {\n\to := new(WebSocketOutput)\n\n\tu, err := url.Parse(address)\n\tif err != nil {\n\t\tlog.Fatal(fmt.Sprintf(\"[OUTPUT-WS] parse WS output URL error[%q]\", err))\n\t}\n\n\to.config = config\n\to.headers = http.Header{\n\t\t\"Authorization\": []string{\"Basic \" + base64.StdEncoding.EncodeToString([]byte(u.User.String()))},\n\t}\n\tfor k, values := range config.Headers {\n\t\tfor _, v := range values {\n\t\t\to.headers.Add(k, v)\n\t\t}\n\t}\n\n\tu.User = nil // must be after creating the headers\n\to.address = u.String()\n\n\tif Settings.OutputWebSocketStats {\n\t\to.bufStats = NewGorStat(\"output_ws\", 5000)\n\t}\n\n\t// create X buffers and send the buffer index to the worker\n\to.buf = make([]chan *Message, o.config.Workers)\n\tfor i := 0; i < o.config.Workers; i++ {\n\t\to.buf[i] = make(chan *Message, 100)\n\t\tgo o.worker(i)\n\t}\n\n\treturn o\n}\n\nfunc (o *WebSocketOutput) worker(bufferIndex int) {\n\tretries := 0\n\tconn, err := o.connect(o.address)\n\tfor {\n\t\tif o.close {\n\t\t\treturn\n\t\t}\n\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tDebug(1, fmt.Sprintf(\"Can't connect to aggregator instance, reconnecting in 1 second. Retries:%d\", retries))\n\t\ttime.Sleep(1 * time.Second)\n\n\t\tconn, err = o.connect(o.address)\n\t\tretries++\n\t}\n\n\tif retries > 0 {\n\t\tDebug(2, fmt.Sprintf(\"Connected to aggregator instance after %d retries\", retries))\n\t}\n\n\tdefer conn.Close()\n\n\tfor {\n\t\tmsg := <-o.buf[bufferIndex]\n\t\terr = conn.WriteMessage(websocket.BinaryMessage, append(msg.Meta, msg.Data...))\n\t\tif err != nil {\n\t\t\tDebug(2, \"INFO: WebSocket output connection closed, reconnecting \"+err.Error())\n\t\t\tgo o.worker(bufferIndex)\n\t\t\to.buf[bufferIndex] <- msg\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc (o *WebSocketOutput) getBufferIndex(msg *Message) int {\n\tif !o.config.Sticky {\n\t\to.workerIndex++\n\t\treturn int(o.workerIndex) % o.config.Workers\n\t}\n\n\thasher := fnv.New32a()\n\thasher.Write(payloadID(msg.Meta))\n\treturn int(hasher.Sum32()) % o.config.Workers\n}\n\n// PluginWrite writes message to this plugin\nfunc (o *WebSocketOutput) PluginWrite(msg *Message) (n int, err error) {\n\tif !isOriginPayload(msg.Meta) {\n\t\treturn len(msg.Data), nil\n\t}\n\n\tbufferIndex := o.getBufferIndex(msg)\n\to.buf[bufferIndex] <- msg\n\n\tif Settings.OutputTCPStats {\n\t\to.bufStats.Write(len(o.buf[bufferIndex]))\n\t}\n\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\nfunc (o *WebSocketOutput) connect(address string) (conn *websocket.Conn, err error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\n\td := websocket.DefaultDialer\n\tif strings.HasPrefix(address, \"wss://\") {\n\t\td.TLSClientConfig = &tls.Config{InsecureSkipVerify: o.config.SkipVerify}\n\t}\n\n\tconn, _, err = d.DialContext(ctx, address, o.headers)\n\treturn\n}\n\nfunc (o *WebSocketOutput) String() string {\n\treturn fmt.Sprintf(\"WebSocket output %s, limit: %d\", o.address, o.limit)\n}\n\n// Close closes the output\nfunc (o *WebSocketOutput) Close() {\n\to.close = true\n}\n"
        },
        {
          "name": "output_ws_test.go",
          "type": "blob",
          "size": 1.6083984375,
          "content": "package goreplay\n\nimport (\n\t\"log\"\n\t\"net/http\"\n\t\"sync\"\n\t\"testing\"\n\n\t\"github.com/gorilla/websocket\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestWebSocketOutput(t *testing.T) {\n\twg := new(sync.WaitGroup)\n\n\tvar gotHeader http.Header\n\twsAddr := startWebsocket(func(data []byte) {\n\t\twg.Done()\n\t}, func(header http.Header) {\n\t\tgotHeader = header\n\t})\n\tinput := NewTestInput()\n\theaders := map[string][]string{\n\t\t\"key1\": {\"value1\"},\n\t\t\"key2\": {\"value2\"},\n\t}\n\toutput := NewWebSocketOutput(wsAddr, &WebSocketOutputConfig{Workers: 1, Headers: headers})\n\n\tplugins := &InOutPlugins{\n\t\tInputs:  []PluginReader{input},\n\t\tOutputs: []PluginWriter{output},\n\t}\n\n\temitter := NewEmitter()\n\tgo emitter.Start(plugins, Settings.Middleware)\n\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tinput.EmitGET()\n\t}\n\n\twg.Wait()\n\temitter.Close()\n\n\tif assert.NotNil(t, gotHeader) {\n\t\tassert.Equal(t, \"Basic dXNlcjE=\", gotHeader.Get(\"Authorization\"))\n\t\tfor k, values := range headers {\n\t\t\tassert.Equal(t, 1, len(values))\n\t\t\tassert.Equal(t, values[0], gotHeader.Get(k))\n\t\t}\n\t}\n}\n\nfunc startWebsocket(cb func([]byte), headercb func(http.Header)) string {\n\tupgrader := websocket.Upgrader{}\n\n\thttp.HandleFunc(\"/test\", func(w http.ResponseWriter, r *http.Request) {\n\t\theadercb(r.Header)\n\t\tc, err := upgrader.Upgrade(w, r, nil)\n\t\tif err != nil {\n\t\t\tlog.Print(\"upgrade:\", err)\n\t\t\treturn\n\t\t}\n\n\t\tgo func(conn *websocket.Conn) {\n\t\t\tdefer conn.Close()\n\t\t\tfor {\n\t\t\t\t_, msg, _ := conn.ReadMessage()\n\t\t\t\tcb(msg)\n\t\t\t}\n\t\t}(c)\n\t})\n\n\tgo func() {\n\t\terr := http.ListenAndServe(\"localhost:8081\", nil)\n\t\tif err != nil {\n\t\t\tlog.Fatal(\"Can't start:\", err)\n\t\t}\n\t}()\n\n\treturn \"ws://user1@localhost:8081/test\"\n}\n"
        },
        {
          "name": "plugins.go",
          "type": "blob",
          "size": 4.5048828125,
          "content": "package goreplay\n\nimport (\n\t\"reflect\"\n\t\"strings\"\n)\n\n// Message represents data across plugins\ntype Message struct {\n\tMeta []byte // metadata\n\tData []byte // actual data\n}\n\n// PluginReader is an interface for input plugins\ntype PluginReader interface {\n\tPluginRead() (msg *Message, err error)\n}\n\n// PluginWriter is an interface for output plugins\ntype PluginWriter interface {\n\tPluginWrite(msg *Message) (n int, err error)\n}\n\n// PluginReadWriter is an interface for plugins that support reading and writing\ntype PluginReadWriter interface {\n\tPluginReader\n\tPluginWriter\n}\n\n// InOutPlugins struct for holding references to plugins\ntype InOutPlugins struct {\n\tInputs  []PluginReader\n\tOutputs []PluginWriter\n\tAll     []interface{}\n}\n\n// extractLimitOptions detects if plugin get called with limiter support\n// Returns address and limit\nfunc extractLimitOptions(options string) (string, string) {\n\tsplit := strings.Split(options, \"|\")\n\n\tif len(split) > 1 {\n\t\treturn split[0], split[1]\n\t}\n\n\treturn split[0], \"\"\n}\n\n// Automatically detects type of plugin and initialize it\n//\n// See this article if curious about reflect stuff below: http://blog.burntsushi.net/type-parametric-functions-golang\nfunc (plugins *InOutPlugins) registerPlugin(constructor interface{}, options ...interface{}) {\n\tvar path, limit string\n\tvc := reflect.ValueOf(constructor)\n\n\t// Pre-processing options to make it work with reflect\n\tvo := []reflect.Value{}\n\tfor _, oi := range options {\n\t\tvo = append(vo, reflect.ValueOf(oi))\n\t}\n\n\tif len(vo) > 0 {\n\t\t// Removing limit options from path\n\t\tpath, limit = extractLimitOptions(vo[0].String())\n\n\t\t// Writing value back without limiter \"|\" options\n\t\tvo[0] = reflect.ValueOf(path)\n\t}\n\n\t// Calling our constructor with list of given options\n\tplugin := vc.Call(vo)[0].Interface()\n\n\tif limit != \"\" {\n\t\tplugin = NewLimiter(plugin, limit)\n\t}\n\n\t// Some of the output can be Readers as well because return responses\n\tif r, ok := plugin.(PluginReader); ok {\n\t\tplugins.Inputs = append(plugins.Inputs, r)\n\t}\n\n\tif w, ok := plugin.(PluginWriter); ok {\n\t\tplugins.Outputs = append(plugins.Outputs, w)\n\t}\n\tplugins.All = append(plugins.All, plugin)\n}\n\n// NewPlugins specify and initialize all available plugins\nfunc NewPlugins() *InOutPlugins {\n\tplugins := new(InOutPlugins)\n\n\tfor _, options := range Settings.InputDummy {\n\t\tplugins.registerPlugin(NewDummyInput, options)\n\t}\n\n\tfor range Settings.OutputDummy {\n\t\tplugins.registerPlugin(NewDummyOutput)\n\t}\n\n\tif Settings.OutputStdout {\n\t\tplugins.registerPlugin(NewDummyOutput)\n\t}\n\n\tif Settings.OutputNull {\n\t\tplugins.registerPlugin(NewNullOutput)\n\t}\n\n\tfor _, options := range Settings.InputRAW {\n\t\tplugins.registerPlugin(NewRAWInput, options, Settings.InputRAWConfig)\n\t}\n\n\tfor _, options := range Settings.InputTCP {\n\t\tplugins.registerPlugin(NewTCPInput, options, &Settings.InputTCPConfig)\n\t}\n\n\tfor _, options := range Settings.OutputTCP {\n\t\tplugins.registerPlugin(NewTCPOutput, options, &Settings.OutputTCPConfig)\n\t}\n\n\tfor _, options := range Settings.OutputWebSocket {\n\t\tplugins.registerPlugin(NewWebSocketOutput, options, &Settings.OutputWebSocketConfig)\n\t}\n\n\tfor _, options := range Settings.InputFile {\n\t\tplugins.registerPlugin(NewFileInput, options, Settings.InputFileLoop, Settings.InputFileReadDepth, Settings.InputFileMaxWait, Settings.InputFileDryRun)\n\t}\n\n\tfor _, path := range Settings.OutputFile {\n\t\tif strings.HasPrefix(path, \"s3://\") {\n\t\t\tplugins.registerPlugin(NewS3Output, path, &Settings.OutputFileConfig)\n\t\t} else {\n\t\t\tplugins.registerPlugin(NewFileOutput, path, &Settings.OutputFileConfig)\n\t\t}\n\t}\n\n\tfor _, options := range Settings.InputHTTP {\n\t\tplugins.registerPlugin(NewHTTPInput, options)\n\t}\n\n\t// If we explicitly set Host header http output should not rewrite it\n\t// Fix: https://github.com/buger/gor/issues/174\n\tfor _, header := range Settings.ModifierConfig.Headers {\n\t\tif header.Name == \"Host\" {\n\t\t\tSettings.OutputHTTPConfig.OriginalHost = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tfor _, options := range Settings.OutputHTTP {\n\t\tplugins.registerPlugin(NewHTTPOutput, options, &Settings.OutputHTTPConfig)\n\t}\n\n\tfor _, options := range Settings.OutputBinary {\n\t\tplugins.registerPlugin(NewBinaryOutput, options, &Settings.OutputBinaryConfig)\n\t}\n\n\tif Settings.OutputKafkaConfig.Host != \"\" && Settings.OutputKafkaConfig.Topic != \"\" {\n\t\tplugins.registerPlugin(NewKafkaOutput, \"\", &Settings.OutputKafkaConfig, &Settings.KafkaTLSConfig)\n\t}\n\n\tif Settings.InputKafkaConfig.Host != \"\" && Settings.InputKafkaConfig.Topic != \"\" {\n\t\tplugins.registerPlugin(NewKafkaInput, Settings.InputKafkaConfig.Offset, &Settings.InputKafkaConfig, &Settings.KafkaTLSConfig)\n\t}\n\n\treturn plugins\n}\n"
        },
        {
          "name": "plugins_test.go",
          "type": "blob",
          "size": 0.98046875,
          "content": "package goreplay\n\nimport (\n\t\"testing\"\n)\n\nfunc TestPluginsRegistration(t *testing.T) {\n\tSettings.InputDummy = []string{\"[]\"}\n\tSettings.OutputDummy = []string{\"[]\"}\n\tSettings.OutputHTTP = []string{\"www.example.com|10\"}\n\tSettings.InputFile = []string{\"/dev/null\"}\n\n\tplugins := NewPlugins()\n\n\tif len(plugins.Inputs) != 3 {\n\t\tt.Errorf(\"Should be 3 inputs got %d\", len(plugins.Inputs))\n\t}\n\n\tif _, ok := plugins.Inputs[0].(*DummyInput); !ok {\n\t\tt.Errorf(\"First input should be DummyInput\")\n\t}\n\n\tif _, ok := plugins.Inputs[1].(*FileInput); !ok {\n\t\tt.Errorf(\"Second input should be FileInput\")\n\t}\n\n\tif len(plugins.Outputs) != 2 {\n\t\tt.Errorf(\"Should be 2 output %d\", len(plugins.Outputs))\n\t}\n\n\tif _, ok := plugins.Outputs[0].(*DummyOutput); !ok {\n\t\tt.Errorf(\"First output should be DummyOutput\")\n\t}\n\n\tif l, ok := plugins.Outputs[1].(*Limiter); ok {\n\t\tif _, ok := l.plugin.(*HTTPOutput); !ok {\n\t\t\tt.Errorf(\"HTTPOutput should be wrapped in limiter\")\n\t\t}\n\t} else {\n\t\tt.Errorf(\"Second output should be Limiter\")\n\t}\n\n}\n"
        },
        {
          "name": "pro.go",
          "type": "blob",
          "size": 0.2509765625,
          "content": "//go:build pro\n\npackage goreplay\n\n// PRO this value indicates if goreplay is running in PRO mode..\n// it must not be modified explicitly in production\nvar PRO = true\n\n// SettingsHook is intentionally left as a no-op\nvar SettingsHook = func(*AppSettings) {}\n"
        },
        {
          "name": "proto",
          "type": "tree",
          "content": null
        },
        {
          "name": "protocol.go",
          "type": "blob",
          "size": 2.0234375,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"crypto/rand\"\n\t\"encoding/hex\"\n\t\"fmt\"\n)\n\n// These constants help to indicate the type of payload\nconst (\n\tRequestPayload          = '1'\n\tResponsePayload         = '2'\n\tReplayedResponsePayload = '3'\n)\n\nfunc randByte(len int) []byte {\n\tb := make([]byte, len/2)\n\trand.Read(b)\n\n\th := make([]byte, len)\n\thex.Encode(h, b)\n\n\treturn h\n}\n\nfunc uuid() []byte {\n\treturn randByte(24)\n}\n\nvar payloadSeparator = \"\\n🐵🙈🙉\\n\"\n\nfunc payloadScanner(data []byte, atEOF bool) (advance int, token []byte, err error) {\n\tif atEOF && len(data) == 0 {\n\t\treturn 0, nil, nil\n\t}\n\n\tif i := bytes.Index(data, []byte(payloadSeparator)); i >= 0 {\n\t\t// We have a full newline-terminated line.\n\t\treturn i + len([]byte(payloadSeparator)), data[0:i], nil\n\t}\n\n\tif atEOF {\n\t\treturn len(data), data, nil\n\t}\n\treturn 0, nil, nil\n}\n\n// Timing is request start or round-trip time, depending on payloadType\nfunc payloadHeader(payloadType byte, uuid []byte, timing int64, latency int64) (header []byte) {\n\t//Example:\n\t//  3 f45590522cd1838b4a0d5c5aab80b77929dea3b3 13923489726487326 1231\\n\n\treturn []byte(fmt.Sprintf(\"%c %s %d %d\\n\", payloadType, uuid, timing, latency))\n}\n\nfunc payloadBody(payload []byte) []byte {\n\theaderSize := bytes.IndexByte(payload, '\\n')\n\treturn payload[headerSize+1:]\n}\n\nfunc payloadMeta(payload []byte) [][]byte {\n\theaderSize := bytes.IndexByte(payload, '\\n')\n\tif headerSize < 0 {\n\t\treturn nil\n\t}\n\treturn bytes.Split(payload[:headerSize], []byte{' '})\n}\n\nfunc payloadMetaWithBody(payload []byte) (meta, body []byte) {\n\tif i := bytes.IndexByte(payload, '\\n'); i > 0 && len(payload) > i+1 {\n\t\tmeta = payload[:i+1]\n\t\tbody = payload[i+1:]\n\t\treturn\n\t}\n\t// we assume the message did not have meta data\n\treturn nil, payload\n}\n\nfunc payloadID(payload []byte) (id []byte) {\n\tmeta := payloadMeta(payload)\n\n\tif len(meta) < 2 {\n\t\treturn\n\t}\n\treturn meta[1]\n}\n\nfunc isOriginPayload(payload []byte) bool {\n\treturn payload[0] == RequestPayload || payload[0] == ResponsePayload\n}\n\nfunc isRequestPayload(payload []byte) bool {\n\treturn payload[0] == RequestPayload\n}\n"
        },
        {
          "name": "s3",
          "type": "tree",
          "content": null
        },
        {
          "name": "s3_reader.go",
          "type": "blob",
          "size": 2.279296875,
          "content": "package goreplay\n\nimport (\n\t\"bytes\"\n\t\"log\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n)\n\n// S3ReadCloser ...\ntype S3ReadCloser struct {\n\tbucket    string\n\tkey       string\n\toffset    int\n\ttotalSize int\n\treadBytes int\n\tsess      *session.Session\n\tbuf       *bytes.Buffer\n}\n\nfunc awsConfig() *aws.Config {\n\tregion := os.Getenv(\"AWS_DEFAULT_REGION\")\n\tif region == \"\" {\n\t\tregion = os.Getenv(\"AWS_REGION\")\n\t\tif region == \"\" {\n\t\t\tregion = \"us-east-1\"\n\t\t}\n\t}\n\n\tconfig := &aws.Config{Region: aws.String(region)}\n\n\tif endpoint := os.Getenv(\"AWS_ENDPOINT_URL\"); endpoint != \"\" {\n\t\tconfig.Endpoint = aws.String(endpoint)\n\t\tlog.Println(\"Custom endpoint:\", endpoint)\n\t}\n\n\tlog.Println(\"Connecting to S3. Region: \" + region)\n\n\tconfig.CredentialsChainVerboseErrors = aws.Bool(true)\n\n\tif os.Getenv(\"AWS_DEBUG\") != \"\" {\n\t\tconfig.LogLevel = aws.LogLevel(aws.LogDebugWithHTTPBody)\n\t}\n\n\treturn config\n}\n\n// NewS3ReadCloser returns new instance of S3 read closer\nfunc NewS3ReadCloser(path string) *S3ReadCloser {\n\tif !PRO {\n\t\tlog.Fatal(\"Using S3 input and output require PRO license\")\n\t\treturn nil\n\t}\n\n\tbucket, key := parseS3Url(path)\n\tsess := session.Must(session.NewSession(awsConfig()))\n\n\tlog.Println(\"[S3 Input] S3 connection successfully initialized\", path)\n\n\treturn &S3ReadCloser{\n\t\tbucket: bucket,\n\t\tkey:    key,\n\t\tsess:   sess,\n\t\tbuf:    &bytes.Buffer{},\n\t}\n}\n\n// Read reads buffer from s3 session\nfunc (s *S3ReadCloser) Read(b []byte) (n int, e error) {\n\tif s.readBytes == 0 || s.readBytes+len(b) > s.offset {\n\t\tsvc := s3.New(s.sess)\n\n\t\tobjectRange := \"bytes=\" + strconv.Itoa(s.offset)\n\t\ts.offset += 1000000 // Reading in chunks of 1 mb\n\t\tobjectRange += \"-\" + strconv.Itoa(s.offset-1)\n\n\t\tparams := &s3.GetObjectInput{\n\t\t\tBucket: aws.String(s.bucket),\n\t\t\tKey:    aws.String(s.key),\n\t\t\tRange:  aws.String(objectRange),\n\t\t}\n\t\tresp, err := svc.GetObject(params)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"[S3 Input] Error during getting file\", s.bucket, s.key, err)\n\t\t} else {\n\t\t\ts.totalSize, _ = strconv.Atoi(strings.Split(*resp.ContentRange, \"/\")[1])\n\t\t\ts.buf.ReadFrom(resp.Body)\n\t\t}\n\t}\n\n\ts.readBytes += len(b)\n\n\treturn s.buf.Read(b)\n}\n\n// Close is here to make S3ReadCloser satisfy ReadCloser interface\nfunc (s *S3ReadCloser) Close() error {\n\treturn nil\n}\n"
        },
        {
          "name": "s3_test.go",
          "type": "blob",
          "size": 3.421875,
          "content": "//go:build pro\n\npackage goreplay\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n)\n\nfunc TestS3Output(t *testing.T) {\n\tbucket := aws.String(\"test-gor\")\n\trnd := rand.Int63()\n\tpath := fmt.Sprintf(\"s3://test-gor/%d/requests.gz\", rnd)\n\n\toutput := NewS3Output(path, &FileOutputConfig{queueLimit: 2})\n\n\tsvc := s3.New(output.session)\n\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\toutput.buffer.updateName()\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\toutput.buffer.updateName()\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\n\ttime.Sleep(time.Second)\n\n\tparams := &s3.ListObjectsInput{\n\t\tBucket: bucket,\n\t\tPrefix: aws.String(fmt.Sprintf(\"%d\", rnd)),\n\t}\n\n\tresp, _ := svc.ListObjects(params)\n\tif len(resp.Contents) != 2 {\n\t\tt.Error(\"Should create 2 objects\", len(resp.Contents))\n\t} else {\n\t\tif *resp.Contents[0].Key != fmt.Sprintf(\"%d/requests_0.gz\", rnd) ||\n\t\t\t*resp.Contents[1].Key != fmt.Sprintf(\"%d/requests_1.gz\", rnd) {\n\t\t\tt.Error(\"Should assign proper names\", resp.Contents)\n\t\t}\n\t}\n\n\tfor _, c := range resp.Contents {\n\t\tsvc.DeleteObject(&s3.DeleteObjectInput{Bucket: bucket, Key: c.Key})\n\t}\n\n\tmatches, _ := filepath.Glob(fmt.Sprintf(\"/tmp/gor_output_s3_*\"))\n\tfor _, m := range matches {\n\t\tos.Remove(m)\n\t}\n}\n\nfunc TestS3OutputQueueLimit(t *testing.T) {\n\tbucket := aws.String(\"test-gor\")\n\trnd := rand.Int63()\n\tpath := fmt.Sprintf(\"s3://test-gor/%d/requests.gz\", rnd)\n\n\toutput := NewS3Output(path, &FileOutputConfig{queueLimit: 100})\n\toutput.closeCh = make(chan struct{}, 3)\n\n\tsvc := s3.New(output.session)\n\n\tfor i := 0; i < 3; i++ {\n\t\tfor i := 0; i < 100; i++ {\n\t\t\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\t\t}\n\t\toutput.buffer.updateName()\n\t}\n\toutput.buffer.updateName()\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\n\tfor i := 0; i < 3; i++ {\n\t\t<-output.closeCh\n\t}\n\n\tparams := &s3.ListObjectsInput{\n\t\tBucket: bucket,\n\t\tPrefix: aws.String(fmt.Sprintf(\"%d\", rnd)),\n\t}\n\n\tresp, _ := svc.ListObjects(params)\n\tif len(resp.Contents) != 3 {\n\t\tt.Error(\"Should create 3 object\", len(resp.Contents))\n\t} else {\n\t\tif *resp.Contents[0].Key != fmt.Sprintf(\"%d/requests_0.gz\", rnd) ||\n\t\t\t*resp.Contents[1].Key != fmt.Sprintf(\"%d/requests_1.gz\", rnd) {\n\t\t\tt.Error(\"Should assign proper names\", resp.Contents)\n\t\t}\n\t}\n\n\tfor _, c := range resp.Contents {\n\t\tsvc.DeleteObject(&s3.DeleteObjectInput{Bucket: bucket, Key: c.Key})\n\t}\n\n\tmatches, _ := filepath.Glob(fmt.Sprintf(\"/tmp/gor_output_s3_*\"))\n\tfor _, m := range matches {\n\t\tos.Remove(m)\n\t}\n}\n\nfunc TestInputFileFromS3(t *testing.T) {\n\trnd := rand.Int63()\n\tpath := fmt.Sprintf(\"s3://test-gor-eu/%d/requests.gz\", rnd)\n\n\toutput := NewS3Output(path, &FileOutputConfig{queueLimit: 5000})\n\toutput.closeCh = make(chan struct{}, 10)\n\n\tfor i := 0; i <= 20000; i++ {\n\t\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\n\t\tif i%5000 == 0 {\n\t\t\toutput.buffer.updateName()\n\t\t}\n\t}\n\n\toutput.Write([]byte(\"1 1 1\\ntest\"))\n\n\tfor i := 0; i < 2; i++ {\n\t\t<-output.closeCh\n\t}\n\n\tinput := NewFileInput(fmt.Sprintf(\"s3://test-gor-eu/%d\", rnd), false, 100, 0, false)\n\n\tbuf := make([]byte, 1000)\n\tfor i := 0; i <= 19999; i++ {\n\t\tinput.Read(buf)\n\t}\n\n\t// Cleanup artifacts\n\tbucket := aws.String(\"test-gor\")\n\tsvc := s3.New(output.session)\n\tparams := &s3.ListObjectsInput{\n\t\tBucket: bucket,\n\t\tPrefix: aws.String(fmt.Sprintf(\"%d\", rnd)),\n\t}\n\n\tresp, _ := svc.ListObjects(params)\n\n\tfor _, c := range resp.Contents {\n\t\tsvc.DeleteObject(&s3.DeleteObjectInput{Bucket: bucket, Key: c.Key})\n\t}\n}\n"
        },
        {
          "name": "settings.go",
          "type": "blob",
          "size": 24.021484375,
          "content": "package goreplay\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/buger/goreplay/internal/size\"\n)\n\n// DEMO indicates that goreplay is running in demo mode\nvar DEMO string\n\n// MultiOption allows to specify multiple flags with same name and collects all values into array\ntype MultiOption struct {\n\ta *[]string\n}\n\nfunc (h *MultiOption) String() string {\n\tif h.a == nil {\n\t\treturn \"\"\n\t}\n\treturn fmt.Sprint(*h.a)\n}\n\n// Set gets called multiple times for each flag with same name\nfunc (h *MultiOption) Set(value string) error {\n\tif h.a == nil {\n\t\treturn nil\n\t}\n\n\t*h.a = append(*h.a, value)\n\treturn nil\n}\n\n// MultiOption allows to specify multiple flags with same name and collects all values into array\ntype MultiIntOption struct {\n\ta *[]int\n}\n\nfunc (h *MultiIntOption) String() string {\n\tif h.a == nil {\n\t\treturn \"\"\n\t}\n\n\treturn fmt.Sprint(*h.a)\n}\n\n// Set gets called multiple times for each flag with same name\nfunc (h *MultiIntOption) Set(value string) error {\n\tif h.a == nil {\n\t\treturn nil\n\t}\n\n\tval, _ := strconv.Atoi(value)\n\t*h.a = append(*h.a, val)\n\treturn nil\n}\n\n// AppSettings is the struct of main configuration\ntype AppSettings struct {\n\tVerbose   int           `json:\"verbose\"`\n\tStats     bool          `json:\"stats\"`\n\tExitAfter time.Duration `json:\"exit-after\"`\n\n\tSplitOutput          bool   `json:\"split-output\"`\n\tRecognizeTCPSessions bool   `json:\"recognize-tcp-sessions\"`\n\tPprof                string `json:\"http-pprof\"`\n\n\tCopyBufferSize size.Size `json:\"copy-buffer-size\"`\n\n\tInputDummy   []string `json:\"input-dummy\"`\n\tOutputDummy  []string\n\tOutputStdout bool `json:\"output-stdout\"`\n\tOutputNull   bool `json:\"output-null\"`\n\n\tInputTCP        []string `json:\"input-tcp\"`\n\tInputTCPConfig  TCPInputConfig\n\tOutputTCP       []string `json:\"output-tcp\"`\n\tOutputTCPConfig TCPOutputConfig\n\tOutputTCPStats  bool `json:\"output-tcp-stats\"`\n\n\tOutputWebSocket       []string `json:\"output-ws\"`\n\tOutputWebSocketConfig WebSocketOutputConfig\n\tOutputWebSocketStats  bool `json:\"output-ws-stats\"`\n\n\tInputFile          []string      `json:\"input-file\"`\n\tInputFileLoop      bool          `json:\"input-file-loop\"`\n\tInputFileReadDepth int           `json:\"input-file-read-depth\"`\n\tInputFileDryRun    bool          `json:\"input-file-dry-run\"`\n\tInputFileMaxWait   time.Duration `json:\"input-file-max-wait\"`\n\tOutputFile         []string      `json:\"output-file\"`\n\tOutputFileConfig   FileOutputConfig\n\n\tInputRAW       []string `json:\"input_raw\"`\n\tInputRAWConfig RAWInputConfig\n\n\tMiddleware string `json:\"middleware\"`\n\n\tInputHTTP    []string\n\tOutputHTTP   []string `json:\"output-http\"`\n\tPrettifyHTTP bool     `json:\"prettify-http\"`\n\n\tOutputHTTPConfig HTTPOutputConfig\n\n\tOutputBinary       []string `json:\"output-binary\"`\n\tOutputBinaryConfig BinaryOutputConfig\n\n\tModifierConfig HTTPModifierConfig\n\n\tInputKafkaConfig  InputKafkaConfig\n\tOutputKafkaConfig OutputKafkaConfig\n\tKafkaTLSConfig    KafkaTLSConfig\n}\n\n// Settings holds Gor configuration\nvar Settings AppSettings\n\nfunc usage() {\n\tfmt.Printf(\"Gor is a simple http traffic replication tool written in Go. Its main goal is to replay traffic from production servers to staging and dev environments.\\nProject page: https://github.com/buger/gor\\nAuthor: <Leonid Bugaev> leonsbox@gmail.com\\nCurrent Version: v%s\\n\\n\", VERSION)\n\tflag.PrintDefaults()\n\tos.Exit(2)\n}\n\nfunc init() {\n\tflag.Usage = usage\n\tflag.StringVar(&Settings.Pprof, \"http-pprof\", \"\", \"Enable profiling. Starts  http server on specified port, exposing special /debug/pprof endpoint. Example: `:8181`\")\n\tflag.IntVar(&Settings.Verbose, \"verbose\", 0, \"set the level of verbosity, if greater than zero then it will turn on debug output\")\n\tflag.BoolVar(&Settings.Stats, \"stats\", false, \"Turn on queue stats output\")\n\n\tif DEMO == \"\" {\n\t\tflag.DurationVar(&Settings.ExitAfter, \"exit-after\", 0, \"exit after specified duration\")\n\t} else {\n\t\tSettings.ExitAfter = 5 * time.Minute\n\t}\n\n\tflag.BoolVar(&Settings.SplitOutput, \"split-output\", false, \"By default each output gets same traffic. If set to `true` it splits traffic equally among all outputs.\")\n\tflag.BoolVar(&Settings.RecognizeTCPSessions, \"recognize-tcp-sessions\", false, \"[PRO] If turned on http output will create separate worker for each TCP session. Splitting output will session based as well.\")\n\n\tflag.Var(&MultiOption{&Settings.InputDummy}, \"input-dummy\", \"Used for testing outputs. Emits 'Get /' request every 1s\")\n\tflag.BoolVar(&Settings.OutputStdout, \"output-stdout\", false, \"Used for testing inputs. Just prints to console data coming from inputs.\")\n\tflag.BoolVar(&Settings.OutputNull, \"output-null\", false, \"Used for testing inputs. Drops all requests.\")\n\n\tflag.Var(&MultiOption{&Settings.InputTCP}, \"input-tcp\", \"Used for internal communication between Gor instances. Example: \\n\\t# Receive requests from other Gor instances on 28020 port, and redirect output to staging\\n\\tgor --input-tcp :28020 --output-http staging.com\")\n\tflag.BoolVar(&Settings.InputTCPConfig.Secure, \"input-tcp-secure\", false, \"Turn on TLS security. Do not forget to specify certificate and key files.\")\n\tflag.StringVar(&Settings.InputTCPConfig.CertificatePath, \"input-tcp-certificate\", \"\", \"Path to PEM encoded certificate file. Used when TLS turned on.\")\n\tflag.StringVar(&Settings.InputTCPConfig.KeyPath, \"input-tcp-certificate-key\", \"\", \"Path to PEM encoded certificate key file. Used when TLS turned on.\")\n\n\tflag.Var(&MultiOption{&Settings.OutputTCP}, \"output-tcp\", \"Used for internal communication between Gor instances. Example: \\n\\t# Listen for requests on 80 port and forward them to other Gor instance on 28020 port\\n\\tgor --input-raw :80 --output-tcp replay.local:28020\")\n\tflag.BoolVar(&Settings.OutputTCPConfig.Secure, \"output-tcp-secure\", false, \"Use TLS secure connection. --input-file on another end should have TLS turned on as well.\")\n\tflag.BoolVar(&Settings.OutputTCPConfig.SkipVerify, \"output-tcp-skip-verify\", false, \"Don't verify hostname on TLS secure connection.\")\n\tflag.BoolVar(&Settings.OutputTCPConfig.Sticky, \"output-tcp-sticky\", false, \"Use Sticky connection. Request/Response with same ID will be sent to the same connection.\")\n\tflag.IntVar(&Settings.OutputTCPConfig.Workers, \"output-tcp-workers\", 10, \"Number of parallel tcp connections, default is 10\")\n\tflag.BoolVar(&Settings.OutputTCPStats, \"output-tcp-stats\", false, \"Report TCP output queue stats to console every 5 seconds.\")\n\n\tflag.Var(&MultiOption{&Settings.OutputWebSocket}, \"output-ws\", \"Just like output tcp, just with WebSocket. Example: \\n\\t# Listen for requests on 80 port and forward them to other Gor instance on 28020 port\\n\\tgor --input-raw :80 --output-ws wss://replay.local:28020/endpoint\")\n\tflag.BoolVar(&Settings.OutputWebSocketConfig.SkipVerify, \"output-ws-skip-verify\", false, \"Don't verify hostname on TLS secure connection.\")\n\tflag.BoolVar(&Settings.OutputWebSocketConfig.Sticky, \"output-ws-sticky\", false, \"Use Sticky connection. Request/Response with same ID will be sent to the same connection.\")\n\tflag.IntVar(&Settings.OutputWebSocketConfig.Workers, \"output-ws-workers\", 10, \"Number of parallel ws connections, default is 10\")\n\tflag.BoolVar(&Settings.OutputWebSocketStats, \"output-ws-stats\", false, \"Report WebSocket output queue stats to console every 5 seconds.\")\n\n\tflag.Var(&MultiOption{&Settings.InputFile}, \"input-file\", \"Read requests from file: \\n\\tgor --input-file ./requests.gor --output-http staging.com\")\n\tflag.BoolVar(&Settings.InputFileLoop, \"input-file-loop\", false, \"Loop input files, useful for performance testing.\")\n\tflag.IntVar(&Settings.InputFileReadDepth, \"input-file-read-depth\", 100, \"GoReplay tries to read and cache multiple records, in advance. In parallel it also perform sorting of requests, if they came out of order. Since it needs hold this buffer in memory, bigger values can cause worse performance\")\n\tflag.BoolVar(&Settings.InputFileDryRun, \"input-file-dry-run\", false, \"Simulate reading from the data source without replaying it. You will get information about expected replay time, number of found records etc.\")\n\tflag.DurationVar(&Settings.InputFileMaxWait, \"input-file-max-wait\", 0, \"Set the maximum time between requests. Can help in situations when you have too long periods between request, and you want to skip them. Example: --input-raw-max-wait 1s\")\n\n\tflag.Var(&MultiOption{&Settings.OutputFile}, \"output-file\", \"Write incoming requests to file: \\n\\tgor --input-raw :80 --output-file ./requests.gor\")\n\tflag.DurationVar(&Settings.OutputFileConfig.FlushInterval, \"output-file-flush-interval\", time.Second, \"Interval for forcing buffer flush to the file, default: 1s.\")\n\tflag.BoolVar(&Settings.OutputFileConfig.Append, \"output-file-append\", false, \"The flushed chunk is appended to existence file or not. \")\n\tflag.Var(&Settings.OutputFileConfig.SizeLimit, \"output-file-size-limit\", \"Size of each chunk. Default: 32mb\")\n\tflag.IntVar(&Settings.OutputFileConfig.QueueLimit, \"output-file-queue-limit\", 256, \"The length of the chunk queue. Default: 256\")\n\tflag.Var(&Settings.OutputFileConfig.OutputFileMaxSize, \"output-file-max-size-limit\", \"Max size of output file, Default: 1TB\")\n\n\tflag.StringVar(&Settings.OutputFileConfig.BufferPath, \"output-file-buffer\", \"/tmp\", \"The path for temporary storing current buffer: \\n\\tgor --input-raw :80 --output-file s3://mybucket/logs/%Y-%m-%d.gz --output-file-buffer /mnt/logs\")\n\n\tflag.BoolVar(&Settings.PrettifyHTTP, \"prettify-http\", false, \"If enabled, will automatically decode requests and responses with: Content-Encoding: gzip and Transfer-Encoding: chunked. Useful for debugging, in conjunction with --output-stdout\")\n\n\tflag.Var(&Settings.CopyBufferSize, \"copy-buffer-size\", \"Set the buffer size for an individual request (default 5MB)\")\n\n\t// input raw flags\n\tflag.Var(&MultiOption{&Settings.InputRAW}, \"input-raw\", \"Capture traffic from given port (use RAW sockets and require *sudo* access):\\n\\t# Capture traffic from 8080 port\\n\\tgor --input-raw :8080 --output-http staging.com\")\n\tflag.BoolVar(&Settings.InputRAWConfig.TrackResponse, \"input-raw-track-response\", false, \"If turned on Gor will track responses in addition to requests, and they will be available to middleware and file output.\")\n\tflag.IntVar(&Settings.InputRAWConfig.VXLANPort, \"input-raw-vxlan-port\", 4789, \"VXLAN port. Can be used only when engine set to `vxlan`. Default: 4789\")\n\tflag.Var(&MultiIntOption{&Settings.InputRAWConfig.VXLANVNIs}, \"input-raw-vxlan-vni\", \"VXLAN VNI to capture. By default capture all VNIs. Ignore VNI by setting them with minus sign, example: `--input-raw-vxlan-vni -2`\")\n\tflag.BoolVar(&Settings.InputRAWConfig.VLAN, \"input-raw-vlan\", false, \"Enable VLAN (802.1Q) support\")\n\tflag.Var(&MultiIntOption{&Settings.InputRAWConfig.VLANVIDs}, \"input-raw-vlan-vid\", \"VLAN VID to capture. By default capture all VIDs\")\n\tflag.Var(&Settings.InputRAWConfig.Engine, \"input-raw-engine\", \"Intercept traffic using `libpcap` (default), `raw_socket`, `pcap_file`, `vxlan`\")\n\tflag.Var(&Settings.InputRAWConfig.Protocol, \"input-raw-protocol\", \"Specify application protocol of intercepted traffic. Possible values: http, binary\")\n\tflag.StringVar(&Settings.InputRAWConfig.RealIPHeader, \"input-raw-realip-header\", \"\", \"If not blank, injects header with given name and real IP value to the request payload. Usually this header should be named: X-Real-IP\")\n\tflag.DurationVar(&Settings.InputRAWConfig.Expire, \"input-raw-expire\", time.Second*2, \"How much it should wait for the last TCP packet, till consider that TCP message complete.\")\n\tflag.StringVar(&Settings.InputRAWConfig.BPFFilter, \"input-raw-bpf-filter\", \"\", \"BPF filter to write custom expressions. Can be useful in case of non standard network interfaces like tunneling or SPAN port. Example: --input-raw-bpf-filter 'dst port 80'\")\n\tflag.StringVar(&Settings.InputRAWConfig.TimestampType, \"input-raw-timestamp-type\", \"\", \"Possible values: PCAP_TSTAMP_HOST, PCAP_TSTAMP_HOST_LOWPREC, PCAP_TSTAMP_HOST_HIPREC, PCAP_TSTAMP_ADAPTER, PCAP_TSTAMP_ADAPTER_UNSYNCED. This values not supported on all systems, GoReplay will tell you available values of you put wrong one.\")\n\tflag.BoolVar(&Settings.InputRAWConfig.Snaplen, \"input-raw-override-snaplen\", false, \"Override the capture snaplen to be 64k. Required for some Virtualized environments\")\n\tflag.DurationVar(&Settings.InputRAWConfig.BufferTimeout, \"input-raw-buffer-timeout\", 0, \"set the pcap timeout. for immediate mode don't set this flag\")\n\tflag.Var(&Settings.InputRAWConfig.BufferSize, \"input-raw-buffer-size\", \"Controls size of the OS buffer which holds packets until they dispatched. Default value depends by system: in Linux around 2MB. If you see big package drop, increase this value.\")\n\tflag.BoolVar(&Settings.InputRAWConfig.Promiscuous, \"input-raw-promisc\", false, \"enable promiscuous mode\")\n\tflag.BoolVar(&Settings.InputRAWConfig.Monitor, \"input-raw-monitor\", false, \"enable RF monitor mode\")\n\tflag.BoolVar(&Settings.InputRAWConfig.Stats, \"input-raw-stats\", false, \"enable stats generator on raw TCP messages\")\n\tflag.BoolVar(&Settings.InputRAWConfig.AllowIncomplete, \"input-raw-allow-incomplete\", false, \"If turned on Gor will record HTTP messages with missing packets\")\n\tflag.Var(&MultiOption{&Settings.InputRAWConfig.IgnoreInterface}, \"input-raw-ignore-interface\", \"In case if you want listen for all interfaces except a few ones. Can be used in k8s environment. Example: --input-raw-ignore-interface cbr0 --input-raw-ignore-interface eth0 --input-raw-ignore-interface localhost\")\n\n\tflag.StringVar(&Settings.Middleware, \"middleware\", \"\", \"Used for modifying traffic using external command\")\n\n\tflag.Var(&MultiOption{&Settings.OutputHTTP}, \"output-http\", \"Forwards incoming requests to given http address.\\n\\t# Redirect all incoming requests to staging.com address \\n\\tgor --input-raw :80 --output-http http://staging.com\")\n\n\t/* outputHTTPConfig */\n\tflag.Var(&Settings.OutputHTTPConfig.BufferSize, \"output-http-response-buffer\", \"HTTP response buffer size, all data after this size will be discarded.\")\n\tflag.IntVar(&Settings.OutputHTTPConfig.WorkersMin, \"output-http-workers-min\", 0, \"Gor uses dynamic worker scaling. Enter a number to set a minimum number of workers. default = 1.\")\n\tflag.IntVar(&Settings.OutputHTTPConfig.WorkersMax, \"output-http-workers\", 0, \"Gor uses dynamic worker scaling. Enter a number to set a maximum number of workers. default = 0 = unlimited.\")\n\tflag.IntVar(&Settings.OutputHTTPConfig.QueueLen, \"output-http-queue-len\", 1000, \"Number of requests that can be queued for output, if all workers are busy. default = 1000\")\n\tflag.BoolVar(&Settings.OutputHTTPConfig.SkipVerify, \"output-http-skip-verify\", false, \"Don't verify hostname on TLS secure connection.\")\n\tflag.DurationVar(&Settings.OutputHTTPConfig.WorkerTimeout, \"output-http-worker-timeout\", 2*time.Second, \"Duration to rollback idle workers.\")\n\n\tflag.IntVar(&Settings.OutputHTTPConfig.RedirectLimit, \"output-http-redirects\", 0, \"Enable how often redirects should be followed.\")\n\tflag.DurationVar(&Settings.OutputHTTPConfig.Timeout, \"output-http-timeout\", 5*time.Second, \"Specify HTTP request/response timeout. By default 5s. Example: --output-http-timeout 30s\")\n\tflag.BoolVar(&Settings.OutputHTTPConfig.TrackResponses, \"output-http-track-response\", false, \"If turned on, HTTP output responses will be set to all outputs like stdout, file and etc.\")\n\n\tflag.BoolVar(&Settings.OutputHTTPConfig.Stats, \"output-http-stats\", false, \"Report http output queue stats to console every N milliseconds. See output-http-stats-ms\")\n\tflag.IntVar(&Settings.OutputHTTPConfig.StatsMs, \"output-http-stats-ms\", 5000, \"Report http output queue stats to console every N milliseconds. default: 5000\")\n\tflag.BoolVar(&Settings.OutputHTTPConfig.OriginalHost, \"http-original-host\", false, \"Normally gor replaces the Host http header with the host supplied with --output-http.  This option disables that behavior, preserving the original Host header.\")\n\tflag.StringVar(&Settings.OutputHTTPConfig.ElasticSearch, \"output-http-elasticsearch\", \"\", \"Send request and response stats to ElasticSearch:\\n\\tgor --input-raw :8080 --output-http staging.com --output-http-elasticsearch 'es_host:api_port/index_name'\")\n\t/* outputHTTPConfig */\n\n\tflag.Var(&MultiOption{&Settings.OutputBinary}, \"output-binary\", \"Forwards incoming binary payloads to given address.\\n\\t# Redirect all incoming requests to staging.com address \\n\\tgor --input-raw :80 --input-raw-protocol binary --output-binary staging.com:80\")\n\n\t/* outputBinaryConfig */\n\tflag.Var(&Settings.OutputBinaryConfig.BufferSize, \"output-tcp-response-buffer\", \"TCP response buffer size, all data after this size will be discarded.\")\n\tflag.IntVar(&Settings.OutputBinaryConfig.Workers, \"output-binary-workers\", 0, \"Gor uses dynamic worker scaling by default.  Enter a number to run a set number of workers.\")\n\tflag.DurationVar(&Settings.OutputBinaryConfig.Timeout, \"output-binary-timeout\", 0, \"Specify HTTP request/response timeout. By default 5s. Example: --output-binary-timeout 30s\")\n\tflag.BoolVar(&Settings.OutputBinaryConfig.TrackResponses, \"output-binary-track-response\", false, \"If turned on, Binary output responses will be set to all outputs like stdout, file and etc.\")\n\n\tflag.BoolVar(&Settings.OutputBinaryConfig.Debug, \"output-binary-debug\", false, \"Enables binary debug output.\")\n\t/* outputBinaryConfig */\n\n\tflag.StringVar(&Settings.OutputKafkaConfig.Host, \"output-kafka-host\", \"\", \"Read request and response stats from Kafka:\\n\\tgor --input-raw :8080 --output-kafka-host '192.168.0.1:9092,192.168.0.2:9092'\")\n\tflag.StringVar(&Settings.OutputKafkaConfig.Topic, \"output-kafka-topic\", \"\", \"Read request and response stats from Kafka:\\n\\tgor --input-raw :8080 --output-kafka-topic 'kafka-log'\")\n\tflag.BoolVar(&Settings.OutputKafkaConfig.UseJSON, \"output-kafka-json-format\", false, \"If turned on, it will serialize messages from GoReplay text format to JSON.\")\n\tflag.BoolVar(&Settings.OutputKafkaConfig.SASLConfig.UseSASL, \"output-kafka-use-sasl\", false, \"--output-kafka-use-sasl true\")\n\tflag.StringVar(&Settings.OutputKafkaConfig.SASLConfig.Mechanism, \"output-kafka-mechanism\", \"\", \"mechanism\\n\\tgor --input-raw :8080 --output-kafka-mechanism 'SCRAM-SHA-512'\")\n\tflag.StringVar(&Settings.OutputKafkaConfig.SASLConfig.Username, \"output-kafka-username\", \"\", \"username\\n\\tgor --input-raw :8080 --output-kafka-username 'username'\")\n\tflag.StringVar(&Settings.OutputKafkaConfig.SASLConfig.Password, \"output-kafka-password\", \"\", \"password\\n\\tgor --input-raw :8080 --output-kafka-password 'password'\")\n\n\tflag.StringVar(&Settings.InputKafkaConfig.Host, \"input-kafka-host\", \"\", \"Send request and response stats to Kafka:\\n\\tgor --output-stdout --input-kafka-host '192.168.0.1:9092,192.168.0.2:9092'\")\n\tflag.StringVar(&Settings.InputKafkaConfig.Topic, \"input-kafka-topic\", \"\", \"Send request and response stats to Kafka:\\n\\tgor --output-stdout --input-kafka-topic 'kafka-log'\")\n\tflag.BoolVar(&Settings.InputKafkaConfig.UseJSON, \"input-kafka-json-format\", false, \"If turned on, it will assume that messages coming in JSON format rather than  GoReplay text format.\")\n\tflag.BoolVar(&Settings.InputKafkaConfig.SASLConfig.UseSASL, \"input-kafka-use-sasl\", false, \"use-sasl\\n\\t--use-sasl true\")\n\tflag.StringVar(&Settings.InputKafkaConfig.SASLConfig.Mechanism, \"input-kafka-mechanism\", \"\", \"mechanism\\n\\tgor --input-raw :8080 --output-kafka-mechanism 'SCRAM-SHA-512'\")\n\tflag.StringVar(&Settings.InputKafkaConfig.SASLConfig.Username, \"input-kafka-username\", \"\", \"username\\n\\tgor --input-raw :8080 --output-kafka-username 'username'\")\n\tflag.StringVar(&Settings.InputKafkaConfig.SASLConfig.Password, \"input-kafka-password\", \"\", \"password\\n\\tgor --input-raw :8080 --output-kafka-password 'password'\")\n\tflag.StringVar(&Settings.InputKafkaConfig.Offset, \"input-kafka-offset\", \"-1\", \"Specify offset in Kafka partitions start to consume\\n\\t-1: Starts from newest, -2: Starts from oldest\\nAnd supported for showdown or speedup for emitting!\\n\\tgor --input-kafka-offset \\\"-2|200%\\\"\")\n\n\tflag.StringVar(&Settings.KafkaTLSConfig.CACert, \"kafka-tls-ca-cert\", \"\", \"CA certificate for Kafka TLS Config:\\n\\tgor  --input-raw :3000 --output-kafka-host '192.168.0.1:9092' --output-kafka-topic 'topic' --kafka-tls-ca-cert cacert.cer.pem --kafka-tls-client-cert client.cer.pem --kafka-tls-client-key client.key.pem\")\n\tflag.StringVar(&Settings.KafkaTLSConfig.ClientCert, \"kafka-tls-client-cert\", \"\", \"Client certificate for Kafka TLS Config (mandatory with to kafka-tls-ca-cert and kafka-tls-client-key)\")\n\tflag.StringVar(&Settings.KafkaTLSConfig.ClientKey, \"kafka-tls-client-key\", \"\", \"Client Key for Kafka TLS Config (mandatory with to kafka-tls-client-cert and kafka-tls-client-key)\")\n\n\tflag.Var(&Settings.ModifierConfig.Headers, \"http-set-header\", \"Inject additional headers to http request:\\n\\tgor --input-raw :8080 --output-http staging.com --http-set-header 'User-Agent: Gor'\")\n\tflag.Var(&Settings.ModifierConfig.HeaderRewrite, \"http-rewrite-header\", \"Rewrite the request header based on a mapping:\\n\\tgor --input-raw :8080 --output-http staging.com --http-rewrite-header Host: (.*).example.com,$1.beta.example.com\")\n\tflag.Var(&Settings.ModifierConfig.Params, \"http-set-param\", \"Set request url param, if param already exists it will be overwritten:\\n\\tgor --input-raw :8080 --output-http staging.com --http-set-param api_key=1\")\n\tflag.Var(&Settings.ModifierConfig.Methods, \"http-allow-method\", \"Whitelist of HTTP methods to replay. Anything else will be dropped:\\n\\tgor --input-raw :8080 --output-http staging.com --http-allow-method GET --http-allow-method OPTIONS\")\n\tflag.Var(&Settings.ModifierConfig.URLRegexp, \"http-allow-url\", \"A regexp to match requests against. Filter get matched against full url with domain. Anything else will be dropped:\\n\\t gor --input-raw :8080 --output-http staging.com --http-allow-url ^www.\")\n\tflag.Var(&Settings.ModifierConfig.URLNegativeRegexp, \"http-disallow-url\", \"A regexp to match requests against. Filter get matched against full url with domain. Anything else will be forwarded:\\n\\t gor --input-raw :8080 --output-http staging.com --http-disallow-url ^www.\")\n\tflag.Var(&Settings.ModifierConfig.URLRewrite, \"http-rewrite-url\", \"Rewrite the request url based on a mapping:\\n\\tgor --input-raw :8080 --output-http staging.com --http-rewrite-url /v1/user/([^\\\\/]+)/ping:/v2/user/$1/ping\")\n\tflag.Var(&Settings.ModifierConfig.HeaderFilters, \"http-allow-header\", \"A regexp to match a specific header against. Requests with non-matching headers will be dropped:\\n\\t gor --input-raw :8080 --output-http staging.com --http-allow-header api-version:^v1\")\n\tflag.Var(&Settings.ModifierConfig.HeaderNegativeFilters, \"http-disallow-header\", \"A regexp to match a specific header against. Requests with matching headers will be dropped:\\n\\t gor --input-raw :8080 --output-http staging.com --http-disallow-header \\\"User-Agent: Replayed by Gor\\\"\")\n\tflag.Var(&Settings.ModifierConfig.HeaderBasicAuthFilters, \"http-basic-auth-filter\", \"A regexp to match the decoded basic auth string against. Requests with non-matching headers will be dropped:\\n\\t gor --input-raw :8080 --output-http staging.com --http-basic-auth-filter \\\"^customer[0-9].*\\\"\")\n\tflag.Var(&Settings.ModifierConfig.HeaderHashFilters, \"http-header-limiter\", \"Takes a fraction of requests, consistently taking or rejecting a request based on the FNV32-1A hash of a specific header:\\n\\t gor --input-raw :8080 --output-http staging.com --http-header-limiter user-id:25%\")\n\tflag.Var(&Settings.ModifierConfig.ParamHashFilters, \"http-param-limiter\", \"Takes a fraction of requests, consistently taking or rejecting a request based on the FNV32-1A hash of a specific GET param:\\n\\t gor --input-raw :8080 --output-http staging.com --http-param-limiter user_id:25%\")\n\n\t// default values, using for tests\n\tSettings.OutputFileConfig.SizeLimit = 33554432\n\tSettings.OutputFileConfig.OutputFileMaxSize = 1099511627776\n\tSettings.CopyBufferSize = 5242880\n\n}\n\nfunc CheckSettings() {\n\tSettingsHook(&Settings)\n\n\tif Settings.OutputFileConfig.SizeLimit < 1 {\n\t\tSettings.OutputFileConfig.SizeLimit.Set(\"32mb\")\n\t}\n\tif Settings.OutputFileConfig.OutputFileMaxSize < 1 {\n\t\tSettings.OutputFileConfig.OutputFileMaxSize.Set(\"1tb\")\n\t}\n\tif Settings.CopyBufferSize < 1 {\n\t\tSettings.CopyBufferSize.Set(\"5mb\")\n\t}\n}\n\nvar previousDebugTime = time.Now()\nvar debugMutex sync.Mutex\n\n// Debug take an effect only if --verbose greater than 0 is specified\nfunc Debug(level int, args ...interface{}) {\n\tif Settings.Verbose >= level {\n\t\tdebugMutex.Lock()\n\t\tdefer debugMutex.Unlock()\n\t\tnow := time.Now()\n\t\tdiff := now.Sub(previousDebugTime)\n\t\tpreviousDebugTime = now\n\t\tfmt.Fprintf(os.Stderr, \"[DEBUG][elapsed %s]: \", diff)\n\t\tfmt.Fprintln(os.Stderr, args...)\n\t}\n}\n"
        },
        {
          "name": "settings_test.go",
          "type": "blob",
          "size": 0.17578125,
          "content": "package goreplay\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestAppSettings(t *testing.T) {\n\ta := AppSettings{}\n\t_, err := json.Marshal(&a)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n}\n"
        },
        {
          "name": "sidenav.css",
          "type": "blob",
          "size": 8.427734375,
          "content": ".wy-affix {\n  position: fixed;\n  top: 1.618em;\n}\n\n.wy-menu a:hover {\n  text-decoration: none;\n}\n\n.wy-menu-vertical header,\n.wy-menu-vertical p.caption {\n  height: 32px;\n  display: inline-block;\n  line-height: 32px;\n  padding: 0 1.618em;\n  margin-bottom: 0;\n  margin-top: 14px;\n  display: block;\n  font-weight: 700;\n  text-transform: uppercase;\n  font-size: 85%;\n  color: #ccc;\n  white-space: nowrap;\n}\n\n.wy-menu-vertical span {\n  color: #666;\n}\n\n.wy-menu-vertical ul {\n  margin-bottom: 0;\n}\n\n.wy-menu-vertical li.divide-top {\n  border-top: solid 1px #404040;\n}\n\n.wy-menu-vertical li.divide-bottom {\n  border-bottom: solid 1px #404040;\n}\n\n.wy-menu-vertical li.current {\n  background-color: #e5e5e5;\n}\n\n.wy-menu-vertical li.current a {\n  color: rgba(0, 93, 255, 0.7);\n  border-right: none;\n}\n\n.wy-menu-vertical li.current a:hover {\n  color: rgba(0, 93, 255, 0.9);\n}\n\n.wy-menu-vertical li code,\n.wy-menu-vertical li .rst-content tt,\n.rst-content .wy-menu-vertical li tt {\n  border: none;\n  background: inherit;\n  color: inherit;\n  padding-left: 0;\n  padding-right: 0\n}\n\n.wy-menu-vertical li span.toctree-expand {\n  display: block;\n  float: left;\n  margin-left: -1.2em;\n  font-size: .8em;\n  line-height: 1.6em;\n  color: #999;\n}\n\n.wy-menu-vertical li.on a,\n.wy-menu-vertical li.current>a {\n  color: rgba(0, 93, 255, 0.9);\n  font-weight: 700;\n  position: relative;\n  background: #fafafa;\n  border: none;\n}\n\n/*.wy-menu-vertical li.on a:hover span.toctree-expand,\n.wy-menu-vertical li.current>a:hover span.toctree-expand {\n  color: gray;\n}*/\n\n.wy-menu-vertical li.on a span.toctree-expand,\n.wy-menu-vertical li.current>a span.toctree-expand {\n  display: block;\n  font-size: .8em;\n  line-height: 1.6em;\n  color: #333;\n}\n\n.wy-menu-vertical li.toctree-l1.current li.toctree-l2>ul,\n.wy-menu-vertical li.toctree-l2.current li.toctree-l3>ul {\n  display: none;\n}\n\n.wy-menu-vertical li.toctree-l1.current li.toctree-l2.current>ul,\n.wy-menu-vertical li.toctree-l2.current li.toctree-l3.current>ul {\n  display: block;\n}\n\n.wy-menu-vertical li.toctree-l2.current li.toctree-l3>a {\n  display: block;\n  padding: .4045em 4.045em;\n}\n\n.wy-menu-vertical li.toctree-l2 a:hover span.toctree-expand {\n  color: #999;\n}\n\n.wy-menu-vertical li.toctree-l2 span.toctree-expand {\n  color: #999;\n}\n\n.wy-menu-vertical li.toctree-l3 {\n  background-color: #eee;\n  font-size: .9em;\n}\n\n.wy-menu-vertical li.toctree-l3.current>a {\n  padding: .4045em 4.045em;\n}\n\n.wy-menu-vertical li.toctree-l3.current li.toctree-l4>a {\n  display: block;\n  padding: .4045em 5.663em;\n  border-top: none;\n  border-bottom: none;\n}\n\n.wy-menu-vertical li.toctree-l3 a:hover span.toctree-expand {\n  color: rgba(0, 93, 255, 0.9);\n}\n\n.wy-menu-vertical li.toctree-l3 span.toctree-expand {\n  color: #999;\n}\n\n.wy-menu-vertical li.toctree-l4 {\n  font-size: .9em;\n}\n\n.wy-menu-vertical li.current ul {\n  display: block;\n}\n\n.wy-menu-vertical .local-toc li ul {\n  display: block;\n}\n\n.wy-menu-vertical li ul li a {\n  margin-bottom: 0;\n  color: rgba(0, 93, 255, 0.7);\n  font-weight: 400;\n}\n\n.wy-menu-vertical a {\n  display: inline-block;\n  line-height: 18px;\n  padding: .4045em 1.618em;\n  display: block;\n  position: relative;\n  font-size: 90%;\n  color: rgba(0, 93, 255, 0.7);\n}\n\n.wy-menu-vertical li.on a:hover,\n.wy-menu-vertical li.current>a:hover {\n  background-color: #fafafa;\n}\n\n.wy-menu-vertical a:hover {\n  color: rgba(0, 93, 255, 0.9);\n  cursor: pointer;\n  background-color: #fafafa;\n}\n\n.wy-menu-vertical a:hover span.toctree-expand {\n  color: rgba(0, 93, 255, 0.5);\n}\n\n.wy-menu-vertical a:active span.toctree-expand {\n  color: rgba(0, 93, 255, 0.7);\n}\n\n/* Search */\n\n.wy-side-nav-search {\n  z-index: 200;\n  background-color: #fafafa;\n  border-bottom: #333;\n  text-align: center;\n  padding: .809em;\n  display: block;\n  color: #333;\n  margin-bottom: .809em\n}\n\n.wy-side-nav-search input[type=text] {\n  width: 100%;\n  color: #333;\n  border-radius: 3px;\n  outline: 0;\n  padding: 10px;\n  background-color: #fff;\n  border: solid 1px #6d6d6d;\n  box-shadow: none\n}\n\n.wy-side-nav-search img {\n  display: block;\n  margin: auto auto .809em;\n  height: 45px;\n  width: 45px;\n  background-color: #2980B9;\n  padding: 5px;\n  border-radius: 100%\n}\n\n.wy-side-nav-search>a,\n.wy-side-nav-search .wy-dropdown>a {\n  color: #333;\n  font-size: 100%;\n  font-weight: 700;\n  display: inline-block;\n  padding: 4px 6px;\n  margin-bottom: .809em\n}\n\n.wy-side-nav-search>a:hover,\n.wy-side-nav-search .wy-dropdown>a:hover {\n  background: rgba(255,255,255,0.1)\n}\n\n.wy-side-nav-search>a img.logo,\n.wy-side-nav-search .wy-dropdown>a img.logo {\n  display: block;\n  margin: 0 auto;\n  height: auto;\n  width: auto;\n  border-radius: 0;\n  max-width: 100%;\n  background: transparent\n}\n\n.wy-side-nav-search>a.icon img.logo,\n.wy-side-nav-search .wy-dropdown>a.icon img.logo {\n  margin-top: .85em\n}\n\n.wy-nav .wy-menu-vertical header {\n  color: #2980B9\n}\n\n.wy-nav .wy-menu-vertical a {\n  color: #b3b3b3\n}\n\n.wy-nav .wy-menu-vertical a:hover {\n  background-color: #2980B9;\n  color: #fff\n}\n\n[data-menu-wrap] {\n  -webkit-transition: all .2s ease-in;\n  -moz-transition: all .2s ease-in;\n  transition: all .2s ease-in;\n  position: absolute;\n  opacity: 1;\n  width: 100%;\n  opacity: 0\n}\n\n[data-menu-wrap].move-center {\n  left: 0;\n  right: auto;\n  opacity: 1\n}\n\n[data-menu-wrap].move-left {\n  right: auto;\n  left: -100%;\n  opacity: 0\n}\n\n[data-menu-wrap].move-right {\n  right: -100%;\n  left: auto;\n  opacity: 0\n}\n\n.wy-body-for-nav {\n  background: left repeat-y #fcfcfc;\n  background-image: url(data:image/png;\n  base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAIAAACQd1PeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyRpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoTWFjaW50b3NoKSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDoxOERBMTRGRDBFMUUxMUUzODUwMkJCOThDMEVFNURFMCIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDoxOERBMTRGRTBFMUUxMUUzODUwMkJCOThDMEVFNURFMCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOjE4REExNEZCMEUxRTExRTM4NTAyQkI5OEMwRUU1REUwIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjE4REExNEZDMEUxRTExRTM4NTAyQkI5OEMwRUU1REUwIi8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+EwrlwAAAAA5JREFUeNpiMDU0BAgwAAE2AJgB9BnaAAAAAElFTkSuQmCC);\n  background-size: 300px 1px\n}\n\n.wy-grid-for-nav {\n  position: absolute;\n  width: 100%;\n  height: 100%\n}\n\n.wy-nav-side {\n  position: fixed;\n  top: 0;\n  bottom: 0;\n  left: 0;\n  padding-bottom: 2em;\n  width: 300px;\n  overflow-x: hidden;\n  overflow-y: scroll;\n  min-height: 100%;\n  background-color: #fafafa;\n  z-index: 200;\n  border-right: 2px solid #eee;\n}\n\n.wy-nav-top {\n  display: none;\n  background-color: #333;\n  color: #fff;\n  padding: .4045em .809em;\n  position: relative;\n  line-height: 50px;\n  text-align: center;\n  font-size: 100%;\n  *zoom: 1\n}\n\n.wy-nav-top:before,\n.wy-nav-top:after {\n  display: table;\n  content: \"\"\n}\n\n.wy-nav-top:after {\n  clear: both\n}\n\n.wy-nav-top a {\n  color: #fff;\n  font-weight: 700\n}\n\n.wy-nav-top img {\n  margin-right: 12px;\n  height: 45px;\n  width: 45px;\n  background-color: #2980B9;\n  padding: 5px;\n  border-radius: 100%\n}\n\n.wy-nav-top i {\n  font-size: 30px;\n  line-height: 50px;\n  float: left;\n  cursor: pointer\n}\n\n.wy-nav-content-wrap {\n  margin-left: 300px;\n  background: #fcfcfc;\n  min-height: 100%\n}\n\n.wy-nav-content {\n  padding: 1.618em 3.236em;\n  height: 100%;\n  max-width: 1100px;\n  margin: auto\n}\n\n.wy-body-mask {\n  position: fixed;\n  width: 100%;\n  height: 100%;\n  background: rgba(0,0,0,0.2);\n  display: none;\n  z-index: 499\n}\n\n.wy-body-mask.on {\n  display: block\n}\n\n@media screen and (max-width: 768px) {\n  .wy-body-for-nav {\n    background: #fcfcfc\n  }\n\n  .wy-nav-top {\n    display: block\n  }\n\n  .wy-nav-side {\n    left: -300px\n  }\n\n  .wy-nav-side.shift {\n    width: 85%;\n    left: 0\n  }\n\n  .wy-nav-content-wrap {\n    margin-left: 0\n  }\n\n  .wy-nav-content-wrap .wy-nav-content {\n    padding: 1.618em\n  }\n\n  .wy-nav-content-wrap.shift {\n    position: fixed;\n    min-width: 100%;\n    left: 85%;\n    top: 0;\n    height: 100%;\n    overflow: hidden\n  }\n\n}\n\n@media screen and (min-width: 1400px) {\n  .wy-nav-content {\n    margin: 0;\n    background: #fcfcfc\n  }\n}"
        },
        {
          "name": "site",
          "type": "tree",
          "content": null
        },
        {
          "name": "snapcraft.yaml",
          "type": "blob",
          "size": 0.9951171875,
          "content": "name: goreplay\nversion: '1.0'\nsummary: GoReplay is an open-source tool for capturing and replaying live HTTP traffic \ndescription: |\n  GoReplay is an open-source tool for capturing and replaying \n  live HTTP traffic into a test environment in order to continuously \n  test your system with real data. It can be used to increase confidence \n  in code deployments, configuration changes and infrastructure changes. \ngrade: stable\nconfinement: strict\nbase: core18\nparts:\n  goreplay:\n    plugin: go\n    source: https://github.com/buger/goreplay.git\n    go-importpath: github.com/buger/goreplay\n    build-packages:\n      - build-essential\n      - libpcap-dev\n    stage-packages:\n      - libpcap0.8\n\napps:\n  goreplay:\n    command: bin/goreplay\n    daemon: simple\n    restart-condition: on-abnormal\n    plugs:\n      - home\n      - network\n      - network-bind\n      - network-control\n      - network-observe\n      - netlink-connector\n      - netlink-audit\n      - bluetooth-control\n      - firewall-control\n      - x11\n      \n"
        },
        {
          "name": "tcp_client.go",
          "type": "blob",
          "size": 3.94921875,
          "content": "package goreplay\n\nimport (\n\t\"crypto/tls\"\n\t\"io\"\n\t\"net\"\n\t\"runtime/debug\"\n\t\"syscall\"\n\t\"time\"\n)\n\n// TCPClientConfig client configuration\ntype TCPClientConfig struct {\n\tDebug              bool\n\tConnectionTimeout  time.Duration\n\tTimeout            time.Duration\n\tResponseBufferSize int\n\tSecure             bool\n}\n\n// TCPClient client connection properties\ntype TCPClient struct {\n\tbaseURL        string\n\taddr           string\n\tconn           net.Conn\n\trespBuf        []byte\n\tconfig         *TCPClientConfig\n\tredirectsCount int\n}\n\n// NewTCPClient returns new TCPClient\nfunc NewTCPClient(addr string, config *TCPClientConfig) *TCPClient {\n\tif config.Timeout.Nanoseconds() == 0 {\n\t\tconfig.Timeout = 5 * time.Second\n\t}\n\n\tconfig.ConnectionTimeout = config.Timeout\n\n\tif config.ResponseBufferSize == 0 {\n\t\tconfig.ResponseBufferSize = 100 * 1024 // 100kb\n\t}\n\n\tclient := &TCPClient{config: config, addr: addr}\n\tclient.respBuf = make([]byte, config.ResponseBufferSize)\n\n\treturn client\n}\n\n// Connect creates a tcp connection of the client\nfunc (c *TCPClient) Connect() (err error) {\n\tc.Disconnect()\n\n\tc.conn, err = net.DialTimeout(\"tcp\", c.addr, c.config.ConnectionTimeout)\n\n\tif c.config.Secure {\n\t\ttlsConn := tls.Client(c.conn, &tls.Config{InsecureSkipVerify: true})\n\n\t\tif err = tlsConn.Handshake(); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tc.conn = tlsConn\n\t}\n\n\treturn\n}\n\n// Disconnect closes the client connection\nfunc (c *TCPClient) Disconnect() {\n\tif c.conn != nil {\n\t\tc.conn.Close()\n\t\tc.conn = nil\n\t\tDebug(1, \"[TCPClient] Disconnected: \", c.baseURL)\n\t}\n}\n\nfunc (c *TCPClient) isAlive() bool {\n\tone := make([]byte, 1)\n\n\t// Ready 1 byte from socket without timeout to check if it not closed\n\tc.conn.SetReadDeadline(time.Now().Add(time.Millisecond))\n\t_, err := c.conn.Read(one)\n\n\tif err == nil {\n\t\treturn true\n\t} else if err == io.EOF {\n\t\tDebug(1, \"[TCPClient] connection closed, reconnecting\")\n\t\treturn false\n\t} else if err == syscall.EPIPE {\n\t\tDebug(1, \"Detected broken pipe.\", err)\n\t\treturn false\n\t}\n\n\treturn true\n}\n\n// Send sends data over created tcp connection\nfunc (c *TCPClient) Send(data []byte) (response []byte, err error) {\n\t// Don't exit on panic\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tDebug(1, \"[TCPClient]\", r, string(data))\n\n\t\t\tif _, ok := r.(error); !ok {\n\t\t\t\tDebug(1, \"[TCPClient] Failed to send request: \", string(data))\n\t\t\t\tDebug(1, \"PANIC: pkg:\", r, debug.Stack())\n\t\t\t}\n\t\t}\n\t}()\n\n\tif c.conn == nil || !c.isAlive() {\n\t\tDebug(1, \"[TCPClient] Connecting:\", c.baseURL)\n\t\tif err = c.Connect(); err != nil {\n\t\t\tDebug(1, \"[TCPClient] Connection error:\", err)\n\t\t\treturn\n\t\t}\n\t}\n\n\ttimeout := time.Now().Add(c.config.Timeout)\n\n\tc.conn.SetWriteDeadline(timeout)\n\n\tif c.config.Debug {\n\t\tDebug(1, \"[TCPClient] Sending:\", string(data))\n\t}\n\n\tif _, err = c.conn.Write(data); err != nil {\n\t\tDebug(1, \"[TCPClient] Write error:\", err, c.baseURL)\n\t\treturn\n\t}\n\n\tvar readBytes, n int\n\tvar currentChunk []byte\n\ttimeout = time.Now().Add(c.config.Timeout)\n\n\tfor {\n\t\tc.conn.SetReadDeadline(timeout)\n\n\t\tif readBytes < len(c.respBuf) {\n\t\t\tn, err = c.conn.Read(c.respBuf[readBytes:])\n\t\t\treadBytes += n\n\n\t\t\tif err != nil {\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\terr = nil\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t} else {\n\t\t\tif currentChunk == nil {\n\t\t\t\tcurrentChunk = make([]byte, readChunkSize)\n\t\t\t}\n\n\t\t\tn, err = c.conn.Read(currentChunk)\n\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t} else if err != nil {\n\t\t\t\tDebug(1, \"[TCPClient] Read the whole body error:\", err, c.baseURL)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\treadBytes += int(n)\n\t\t}\n\n\t\tif readBytes >= maxResponseSize {\n\t\t\tDebug(1, \"[TCPClient] Body is more than the max size\", maxResponseSize,\n\t\t\t\tc.baseURL)\n\t\t\tbreak\n\t\t}\n\n\t\t// For following chunks expect less timeout\n\t\ttimeout = time.Now().Add(c.config.Timeout / 5)\n\t}\n\n\tif err != nil {\n\t\tDebug(1, \"[TCPClient] Response read error\", err, c.conn, readBytes)\n\t\treturn\n\t}\n\n\tif readBytes > len(c.respBuf) {\n\t\treadBytes = len(c.respBuf)\n\t}\n\n\tpayload := make([]byte, readBytes)\n\tcopy(payload, c.respBuf[:readBytes])\n\n\tif c.config.Debug {\n\t\tDebug(1, \"[TCPClient] Received:\", string(payload))\n\t}\n\n\treturn payload, err\n}\n"
        },
        {
          "name": "test_input.go",
          "type": "blob",
          "size": 2.5966796875,
          "content": "package goreplay\n\nimport (\n\t\"encoding/base64\"\n\t\"errors\"\n\t\"math/rand\"\n\t\"time\"\n)\n\n// ErrorStopped is the error returned when the go routines reading the input is stopped.\nvar ErrorStopped = errors.New(\"reading stopped\")\n\n// TestInput used for testing purpose, it allows emitting requests on demand\ntype TestInput struct {\n\tdata       chan []byte\n\tskipHeader bool\n\tstop       chan bool // Channel used only to indicate goroutine should shutdown\n}\n\n// NewTestInput constructor for TestInput\nfunc NewTestInput() (i *TestInput) {\n\ti = new(TestInput)\n\ti.data = make(chan []byte, 100)\n\ti.stop = make(chan bool)\n\treturn\n}\n\n// PluginRead reads message from this plugin\nfunc (i *TestInput) PluginRead() (*Message, error) {\n\tvar msg Message\n\tselect {\n\tcase buf := <-i.data:\n\t\tmsg.Data = buf\n\t\tif !i.skipHeader {\n\t\t\tmsg.Meta = payloadHeader(RequestPayload, uuid(), time.Now().UnixNano(), -1)\n\t\t} else {\n\t\t\tmsg.Meta, msg.Data = payloadMetaWithBody(msg.Data)\n\t\t}\n\n\t\treturn &msg, nil\n\tcase <-i.stop:\n\t\treturn nil, ErrorStopped\n\t}\n}\n\n// Close closes this plugin\nfunc (i *TestInput) Close() error {\n\tclose(i.stop)\n\treturn nil\n}\n\n// EmitBytes sends data\nfunc (i *TestInput) EmitBytes(data []byte) {\n\ti.data <- data\n}\n\n// EmitGET emits GET request without headers\nfunc (i *TestInput) EmitGET() {\n\ti.data <- []byte(\"GET / HTTP/1.1\\r\\n\\r\\n\")\n}\n\n// EmitPOST emits POST request with Content-Length\nfunc (i *TestInput) EmitPOST() {\n\ti.data <- []byte(\"POST /pub/WWW/ HTTP/1.1\\r\\nContent-Length: 7\\r\\nHost: www.w3.org\\r\\n\\r\\na=1&b=2\")\n}\n\n// EmitChunkedPOST emits POST request with `Transfer-Encoding: chunked` and chunked body\nfunc (i *TestInput) EmitChunkedPOST() {\n\ti.data <- []byte(\"POST /pub/WWW/ HTTP/1.1\\r\\nHost: www.w3.org\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n4\\r\\nWiki\\r\\n5\\r\\npedia\\r\\ne\\r\\n in\\r\\n\\r\\nchunks.\\r\\n0\\r\\n\\r\\n\")\n}\n\n// EmitLargePOST emits POST request with large payload (5mb)\nfunc (i *TestInput) EmitLargePOST() {\n\tsize := 5 * 1024 * 1024 // 5 MB\n\trb := make([]byte, size)\n\trand.Read(rb)\n\n\trs := base64.URLEncoding.EncodeToString(rb)\n\n\ti.data <- []byte(\"POST / HTTP/1.1\\r\\nHost: www.w3.org\\nContent-Length:5242880\\r\\n\\r\\n\" + rs)\n}\n\n// EmitSizedPOST emit a POST with a payload set to a supplied size\nfunc (i *TestInput) EmitSizedPOST(payloadSize int) {\n\trb := make([]byte, payloadSize)\n\trand.Read(rb)\n\n\trs := base64.URLEncoding.EncodeToString(rb)\n\n\ti.data <- []byte(\"POST / HTTP/1.1\\r\\nHost: www.w3.org\\nContent-Length:5242880\\r\\n\\r\\n\" + rs)\n}\n\n// EmitOPTIONS emits OPTIONS request, similar to GET\nfunc (i *TestInput) EmitOPTIONS() {\n\ti.data <- []byte(\"OPTIONS / HTTP/1.1\\r\\nHost: www.w3.org\\r\\n\\r\\n\")\n}\n\nfunc (i *TestInput) String() string {\n\treturn \"Test Input\"\n}\n"
        },
        {
          "name": "test_output.go",
          "type": "blob",
          "size": 0.5810546875,
          "content": "package goreplay\n\ntype writeCallback func(*Message)\n\n// TestOutput used in testing to intercept any output into callback\ntype TestOutput struct {\n\tcb writeCallback\n}\n\n// NewTestOutput constructor for TestOutput, accepts callback which get called on each incoming Write\nfunc NewTestOutput(cb writeCallback) PluginWriter {\n\ti := new(TestOutput)\n\ti.cb = cb\n\n\treturn i\n}\n\n// PluginWrite write message to this plugin\nfunc (i *TestOutput) PluginWrite(msg *Message) (int, error) {\n\ti.cb(msg)\n\n\treturn len(msg.Data) + len(msg.Meta), nil\n}\n\nfunc (i *TestOutput) String() string {\n\treturn \"Test Output\"\n}\n"
        },
        {
          "name": "version.go",
          "type": "blob",
          "size": 0.0810546875,
          "content": "package goreplay\n\n// VERSION the current version of goreplay\nvar VERSION = \"2.0.0\"\n"
        }
      ]
    }
  ]
}