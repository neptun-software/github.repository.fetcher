{
  "metadata": {
    "timestamp": 1736568073925,
    "page": 211,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "fullstorydev/grpcurl",
      "stars": 11093,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0263671875,
          "content": "dist/\n.idea/\nVERSION\n.tmp/\n"
        },
        {
          "name": ".goreleaser.yml",
          "type": "blob",
          "size": 1.4130859375,
          "content": "builds:\n  - binary: grpcurl\n    main: ./cmd/grpcurl\n    goos:\n      - linux\n      - darwin\n      - windows\n    goarch:\n      - amd64\n      - 386\n      - arm\n      - arm64\n      - s390x\n      - ppc64le\n    goarm:\n      - 5\n      - 6\n      - 7\n    ignore:\n      - goos: darwin\n        goarch: 386\n      - goos: windows\n        goarch: arm64\n      - goos: darwin\n        goarch: arm\n      - goos: windows\n        goarch: arm\n      - goos: darwin\n        goarch: s390x\n      - goos: windows\n        goarch: s390x\n      - goos: darwin\n        goarch: ppc64le\n      - goos: windows\n        goarch: ppc64le\n    ldflags:\n      - -s -w -X main.version=v{{.Version}}\n\narchives:\n  - format: tar.gz\n    name_template: >-\n      {{ .Binary }}_{{ .Version }}_\n      {{- if eq .Os \"darwin\" }}osx{{ else }}{{ .Os }}{{ end }}_\n      {{- if eq .Arch \"amd64\" }}x86_64\n      {{- else if eq .Arch \"386\" }}x86_32\n      {{- else }}{{ .Arch }}{{ end }}\n      {{- with .Arm }}v{{ . }}{{ end }}{{ with .Mips }}_{{ . }}{{ end }}{{ if not (eq .Amd64 \"v1\") }}{{ .Amd64 }}{{ end }}\n    format_overrides:\n      - goos: windows\n        format: zip\n    files:\n      - LICENSE\n\nnfpms:\n  - vendor: Fullstory\n    homepage: https://github.com/fullstorydev/grpcurl/\n    maintainer: Engineering at Fullstory  <fixme@fixme>\n    description: 'Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers'\n    license: MIT\n    id: nfpms\n    formats:\n      - deb\n      - rpm\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.109375,
          "content": "FROM golang:1.23-alpine as builder\nMAINTAINER Fullstory Engineering\n\n# create non-privileged group and user\nRUN addgroup -S grpcurl && adduser -S grpcurl -G grpcurl\n\nWORKDIR /tmp/fullstorydev/grpcurl\n# copy just the files/sources we need to build grpcurl\nCOPY VERSION *.go go.* /tmp/fullstorydev/grpcurl/\nCOPY cmd /tmp/fullstorydev/grpcurl/cmd\n# and build a completely static binary (so we can use\n# scratch as basis for the final image)\nENV CGO_ENABLED=0\nENV GO111MODULE=on\nRUN go build -o /grpcurl \\\n    -ldflags \"-w -extldflags \\\"-static\\\" -X \\\"main.version=$(cat VERSION)\\\"\" \\\n    ./cmd/grpcurl\n\nFROM alpine:3 as alpine\nWORKDIR /\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ca-certificates.crt\nCOPY --from=builder /etc/passwd /etc/passwd\nCOPY --from=builder /grpcurl /bin/grpcurl\nUSER grpcurl\n\nENTRYPOINT [\"/bin/grpcurl\"]\n\n# New FROM so we have a nice'n'tiny image\nFROM scratch\nWORKDIR /\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ca-certificates.crt\nCOPY --from=builder /etc/passwd /etc/passwd\nCOPY --from=builder /grpcurl /bin/grpcurl\nUSER grpcurl\n\nENTRYPOINT [\"/bin/grpcurl\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0556640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2017 Fullstory, Inc\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.609375,
          "content": "dev_build_version=$(shell git describe --tags --always --dirty)\n\nexport PATH := $(shell pwd)/.tmp/protoc/bin:$(PATH)\nexport PROTOC_VERSION := 22.0\n# Disable CGO for improved compatibility across distros\nexport CGO_ENABLED=0\n\n# TODO: run golint and errcheck, but only to catch *new* violations and\n# decide whether to change code or not (e.g. we need to be able to whitelist\n# violations already in the code). They can be useful to catch errors, but\n# they are just too noisy to be a requirement for a CI -- we don't even *want*\n# to fix some of the things they consider to be violations.\n.PHONY: ci\nci: deps checkgofmt checkgenerate vet staticcheck ineffassign predeclared test\n\n.PHONY: deps\ndeps:\n\tgo get -d -v -t ./...\n\tgo mod tidy\n\n.PHONY: updatedeps\nupdatedeps:\n\tgo get -d -v -t -u -f ./...\n\tgo mod tidy\n\n.PHONY: install\ninstall:\n\tgo install -ldflags '-X \"main.version=dev build $(dev_build_version)\"' ./...\n\n.PHONY: release\nrelease:\n\t@go install github.com/goreleaser/goreleaser@v1.21.0\n\tgoreleaser release --clean\n\n.PHONY: docker\ndocker:\n\t@echo $(dev_build_version) > VERSION\n\tdocker build -t fullstorydev/grpcurl:$(dev_build_version) .\n\t@rm VERSION\n\n.PHONY: generate\ngenerate: .tmp/protoc/bin/protoc\n\t@go install google.golang.org/protobuf/cmd/protoc-gen-go@a709e31e5d12\n\t@go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.1.0\n\t@go install github.com/jhump/protoreflect/desc/sourceinfo/cmd/protoc-gen-gosrcinfo@v1.14.1\n\tgo generate ./...\n\tgo mod tidy\n\n.PHONY: checkgenerate\ncheckgenerate: generate\n\tgit status --porcelain\n\t@if [ -n \"$$(git status --porcelain)\" ]; then \\\n\t\tgit diff; \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: checkgofmt\ncheckgofmt:\n\tgofmt -s -l .\n\t@if [ -n \"$$(gofmt -s -l .)\" ]; then \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: vet\nvet:\n\tgo vet ./...\n\n.PHONY: staticcheck\nstaticcheck:\n\t@go install honnef.co/go/tools/cmd/staticcheck@v0.5.1\n\tstaticcheck ./...\n\n.PHONY: ineffassign\nineffassign:\n\t@go install github.com/gordonklaus/ineffassign@7953dde2c7bf\n\tineffassign .\n\n.PHONY: predeclared\npredeclared:\n\t@go install github.com/nishanths/predeclared@245576f9a85c\n\tpredeclared ./...\n\n# Intentionally omitted from CI, but target here for ad-hoc reports.\n.PHONY: golint\ngolint:\n\t@go install golang.org/x/lint/golint@v0.0.0-20210508222113-6edffad5e616\n\tgolint -min_confidence 0.9 -set_exit_status ./...\n\n# Intentionally omitted from CI, but target here for ad-hoc reports.\n.PHONY: errcheck\nerrcheck:\n\t@go install github.com/kisielk/errcheck@v1.2.0\n\terrcheck ./...\n\n.PHONY: test\ntest:\n\t# The race detector requires CGO: https://github.com/golang/go/issues/6508\n\tCGO_ENABLED=1 go test -race ./...\n\n.tmp/protoc/bin/protoc: ./Makefile ./download_protoc.sh\n\t./download_protoc.sh\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.478515625,
          "content": "# gRPCurl\n[![Build Status](https://circleci.com/gh/fullstorydev/grpcurl/tree/master.svg?style=svg)](https://circleci.com/gh/fullstorydev/grpcurl/tree/master)\n[![Go Report Card](https://goreportcard.com/badge/github.com/fullstorydev/grpcurl)](https://goreportcard.com/report/github.com/fullstorydev/grpcurl)\n\n`grpcurl` is a command-line tool that lets you interact with gRPC servers. It's\nbasically `curl` for gRPC servers.\n\nThe main purpose for this tool is to invoke RPC methods on a gRPC server from the\ncommand-line. gRPC servers use a binary encoding on the wire\n([protocol buffers](https://developers.google.com/protocol-buffers/), or \"protobufs\"\nfor short). So they are basically impossible to interact with using regular `curl`\n(and older versions of `curl` that do not support HTTP/2 are of course non-starters).\nThis program accepts messages using JSON encoding, which is much more friendly for both\nhumans and scripts.\n\nWith this tool you can also browse the schema for gRPC services, either by querying\na server that supports [server reflection](https://github.com/grpc/grpc/blob/master/src/proto/grpc/reflection/v1/reflection.proto),\nby reading proto source files, or by loading in compiled \"protoset\" files (files that contain\nencoded file [descriptor protos](https://github.com/google/protobuf/blob/master/src/google/protobuf/descriptor.proto)).\nIn fact, the way the tool transforms JSON request data into a binary encoded protobuf\nis using that very same schema. So, if the server you interact with does not support\nreflection, you will either need the proto source files that define the service or need\nprotoset files that `grpcurl` can use.\n\nThis repo also provides a library package, `github.com/fullstorydev/grpcurl`, that has\nfunctions for simplifying the construction of other command-line tools that dynamically\ninvoke gRPC endpoints. This code is a great example of how to use the various packages of\nthe [protoreflect](https://godoc.org/github.com/jhump/protoreflect) library, and shows\noff what they can do.\n\nSee also the [`grpcurl` talk at GopherCon 2018](https://www.youtube.com/watch?v=dDr-8kbMnaw).\n\n## Features\n`grpcurl` supports all kinds of RPC methods, including streaming methods. You can even\noperate bi-directional streaming methods interactively by running `grpcurl` from an\ninteractive terminal and using stdin as the request body!\n\n`grpcurl` supports both secure/TLS servers _and_ plain-text servers (i.e. no TLS) and has\nnumerous options for TLS configuration. It also supports mutual TLS, where the client is\nrequired to present a client certificate.\n\nAs mentioned above, `grpcurl` works seamlessly if the server supports the reflection\nservice. If not, you can supply the `.proto` source files or you can supply protoset\nfiles (containing compiled descriptors, produced by `protoc`) to `grpcurl`.\n\n## Installation\n\n### Binaries\n\nDownload the binary from the [releases](https://github.com/fullstorydev/grpcurl/releases) page.\n\n### Homebrew (macOS)\n\nOn macOS, `grpcurl` is available via Homebrew:\n```shell\nbrew install grpcurl\n```\n\n### Docker\n\nFor platforms that support Docker, you can download an image that lets you run `grpcurl`:\n```shell\n# Download image\ndocker pull fullstorydev/grpcurl:latest\n# Run the tool\ndocker run fullstorydev/grpcurl api.grpc.me:443 list\n```\nNote that there are some pitfalls when using docker:\n- If you need to interact with a server listening on the host's loopback network, you must specify the host as `host.docker.internal` instead of `localhost` (for Mac or Windows) _OR_ have the container use the host network with `-network=\"host\"` (Linux only).\n- If you need to provide proto source files or descriptor sets, you must mount the folder containing the files as a volume (`-v $(pwd):/protos`) and adjust the import paths to container paths accordingly.\n- If you want to provide the request message via stdin, using the `-d @` option, you need to use the `-i` flag on the docker command.\n\n### Other Packages\n\nThere are numerous other ways to install `grpcurl`, thanks to support from third parties that\nhave created recipes/packages for it. These include other ways to install `grpcurl` on a variety\nof environments, including Windows and myriad Linux distributions.\n\nYou can see more details and the full list of other packages for `grpcurl` at _repology.org_:\nhttps://repology.org/project/grpcurl/information\n\n### From Source\nIf you already have the [Go SDK](https://golang.org/doc/install) installed, you can use the `go`\ntool to install `grpcurl`:\n```shell\ngo install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest\n```\n\nThis installs the command into the `bin` sub-folder of wherever your `$GOPATH`\nenvironment variable points. (If you have no `GOPATH` environment variable set,\nthe default install location is `$HOME/go/bin`). If this directory is already in\nyour `$PATH`, then you should be good to go.\n\nIf you have already pulled down this repo to a location that is not in your\n`$GOPATH` and want to build from the sources, you can `cd` into the repo and then\nrun `make install`.\n\nIf you encounter compile errors and are using a version of the Go SDK older than 1.13,\nyou could have out-dated versions of `grpcurl`'s dependencies. You can update the\ndependencies by running `make updatedeps`. Or, if you are using Go 1.11 or 1.12, you\ncan add `GO111MODULE=on` as a prefix to the commands above, which will also build using\nthe right versions of dependencies (vs. whatever you may already have in your `GOPATH`).\n\n## Usage\nThe usage doc for the tool explains the numerous options:\n```shell\ngrpcurl -help\n```\n\nIn the sections below, you will find numerous examples demonstrating how to use\n`grpcurl`.\n\n### Invoking RPCs\nInvoking an RPC on a trusted server (e.g. TLS without self-signed key or custom CA)\nthat requires no client certs and supports server reflection is the simplest thing to\ndo with `grpcurl`. This minimal invocation sends an empty request body:\n```shell\ngrpcurl grpc.server.com:443 my.custom.server.Service/Method\n\n# no TLS\ngrpcurl -plaintext grpc.server.com:80 my.custom.server.Service/Method\n```\n\nTo send a non-empty request, use the `-d` argument. Note that all arguments must come\n*before* the server address and method name:\n```shell\ngrpcurl -d '{\"id\": 1234, \"tags\": [\"foo\",\"bar\"]}' \\\n    grpc.server.com:443 my.custom.server.Service/Method\n```\n\nAs can be seen in the example, the supplied body must be in JSON format. The body will\nbe parsed and then transmitted to the server in the protobuf binary format.\n\nIf you want to include `grpcurl` in a command pipeline, such as when using `jq` to\ncreate a request body, you can use `-d @`, which tells `grpcurl` to read the actual\nrequest body from stdin:\n```shell\ngrpcurl -d @ grpc.server.com:443 my.custom.server.Service/Method <<EOM\n{\n  \"id\": 1234,\n  \"tags\": [\n    \"foor\",\n    \"bar\"\n  ]\n}\nEOM\n```\n### Adding Headers/Metadata to Request\nAdding of headers / metadata to a rpc request is possible via the `-H name:value` command line option. Multiple headers can be added in a similar fashion.\nExample :\n```shell\ngrpcurl -H header1:value1 -H header2:value2 -d '{\"id\": 1234, \"tags\": [\"foo\",\"bar\"]}' grpc.server.com:443 my.custom.server.Service/Method\n```\nFor more usage guide, check out the help docs via `grpcurl -help`\n\n### Listing Services\nTo list all services exposed by a server, use the \"list\" verb. When using `.proto` source\nor protoset files instead of server reflection, this lists all services defined in the\nsource or protoset files.\n```shell\n# Server supports reflection\ngrpcurl localhost:8787 list\n\n# Using compiled protoset files\ngrpcurl -protoset my-protos.bin list\n\n# Using proto sources\ngrpcurl -import-path ../protos -proto my-stuff.proto list\n\n# Export proto files (use -proto-out-dir to specify the output directory)\ngrpcurl -plaintext -proto-out-dir \"out_protos\" \"localhost:8787\" describe my.custom.server.Service\n\n# Export protoset file (use -protoset-out to specify the output file)\ngrpcurl -plaintext -protoset-out \"out.protoset\" \"localhost:8787\" describe my.custom.server.Service\n\n```\n\nThe \"list\" verb also lets you see all methods in a particular service:\n```shell\ngrpcurl localhost:8787 list my.custom.server.Service\n```\n\n### Describing Elements\nThe \"describe\" verb will print the type of any symbol that the server knows about\nor that is found in a given protoset file. It also prints a description of that\nsymbol, in the form of snippets of proto source. It won't necessarily be the\noriginal source that defined the element, but it will be equivalent.\n\n```shell\n# Server supports reflection\ngrpcurl localhost:8787 describe my.custom.server.Service.MethodOne\n\n# Using compiled protoset files\ngrpcurl -protoset my-protos.bin describe my.custom.server.Service.MethodOne\n\n# Using proto sources\ngrpcurl -import-path ../protos -proto my-stuff.proto describe my.custom.server.Service.MethodOne\n```\n\n## Descriptor Sources\nThe `grpcurl` tool can operate on a variety of sources for descriptors. The descriptors\nare required, in order for `grpcurl` to understand the RPC schema, translate inputs\ninto the protobuf binary format as well as translate responses from the binary format\ninto text. The sections below document the supported sources and what command-line flags\nare needed to use them.\n\n### Server Reflection\n\nWithout any additional command-line flags, `grpcurl` will try to use [server reflection](https://github.com/grpc/grpc/blob/master/src/proto/grpc/reflection/v1/reflection.proto).\n\nExamples for how to set up server reflection can be found [here](https://github.com/grpc/grpc/blob/master/doc/server-reflection.md#known-implementations).\n\nWhen using reflection, the server address (host:port or path to Unix socket) is required\neven for \"list\" and \"describe\" operations, so that `grpcurl` can connect to the server\nand ask it for its descriptors.\n\n### Proto Source Files\nTo use `grpcurl` on servers that do not support reflection, you can use `.proto` source\nfiles.\n\nIn addition to using `-proto` flags to point `grpcurl` at the relevant proto source file(s),\nyou may also need to supply `-import-path` flags to tell `grpcurl` the folders from which\ndependencies can be imported.\n\nJust like when compiling with `protoc`, you do *not* need to provide an import path for the\nlocation of the standard protos included with `protoc` (which contain various \"well-known\ntypes\" with a package definition of `google.protobuf`). These files are \"known\" by `grpcurl`\nas a snapshot of their descriptors is built into the `grpcurl` binary.\n\nWhen using proto sources, you can omit the server address (host:port or path to Unix socket)\nwhen using the \"list\" and \"describe\" operations since they only need to consult the proto\nsource files.\n\n### Protoset Files\nYou can also use compiled protoset files with `grpcurl`. If you are scripting `grpcurl` and\nneed to re-use the same proto sources for many invocations, you will see better performance\nby using protoset files (since it skips the parsing and compilation steps with each\ninvocation).\n\nProtoset files contain binary encoded `google.protobuf.FileDescriptorSet` protos. To create\na protoset file, invoke `protoc` with the `*.proto` files that define the service:\n```shell\nprotoc --proto_path=. \\\n    --descriptor_set_out=myservice.protoset \\\n    --include_imports \\\n    my/custom/server/service.proto\n```\n\nThe `--descriptor_set_out` argument is what tells `protoc` to produce a protoset,\nand the `--include_imports` argument is necessary for the protoset to contain\neverything that `grpcurl` needs to process and understand the schema.\n\nWhen using protosets, you can omit the server address (host:port or path to Unix socket)\nwhen using the \"list\" and \"describe\" operations since they only need to consult the\nprotoset files.\n\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "desc_source.go",
          "type": "blob",
          "size": 12.44921875,
          "content": "package grpcurl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sync\"\n\n\t\"github.com/golang/protobuf/proto\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"github.com/jhump/protoreflect/desc/protoparse\"\n\t\"github.com/jhump/protoreflect/desc/protoprint\"\n\t\"github.com/jhump/protoreflect/dynamic\"\n\t\"github.com/jhump/protoreflect/grpcreflect\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/status\"\n\t\"google.golang.org/protobuf/types/descriptorpb\"\n)\n\n// ErrReflectionNotSupported is returned by DescriptorSource operations that\n// rely on interacting with the reflection service when the source does not\n// actually expose the reflection service. When this occurs, an alternate source\n// (like file descriptor sets) must be used.\nvar ErrReflectionNotSupported = errors.New(\"server does not support the reflection API\")\n\n// DescriptorSource is a source of protobuf descriptor information. It can be backed by a FileDescriptorSet\n// proto (like a file generated by protoc) or a remote server that supports the reflection API.\ntype DescriptorSource interface {\n\t// ListServices returns a list of fully-qualified service names. It will be all services in a set of\n\t// descriptor files or the set of all services exposed by a gRPC server.\n\tListServices() ([]string, error)\n\t// FindSymbol returns a descriptor for the given fully-qualified symbol name.\n\tFindSymbol(fullyQualifiedName string) (desc.Descriptor, error)\n\t// AllExtensionsForType returns all known extension fields that extend the given message type name.\n\tAllExtensionsForType(typeName string) ([]*desc.FieldDescriptor, error)\n}\n\n// DescriptorSourceFromProtoSets creates a DescriptorSource that is backed by the named files, whose contents\n// are encoded FileDescriptorSet protos.\nfunc DescriptorSourceFromProtoSets(fileNames ...string) (DescriptorSource, error) {\n\tfiles := &descriptorpb.FileDescriptorSet{}\n\tfor _, fileName := range fileNames {\n\t\tb, err := os.ReadFile(fileName)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not load protoset file %q: %v\", fileName, err)\n\t\t}\n\t\tvar fs descriptorpb.FileDescriptorSet\n\t\terr = proto.Unmarshal(b, &fs)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not parse contents of protoset file %q: %v\", fileName, err)\n\t\t}\n\t\tfiles.File = append(files.File, fs.File...)\n\t}\n\treturn DescriptorSourceFromFileDescriptorSet(files)\n}\n\n// DescriptorSourceFromProtoFiles creates a DescriptorSource that is backed by the named files,\n// whose contents are Protocol Buffer source files. The given importPaths are used to locate\n// any imported files.\nfunc DescriptorSourceFromProtoFiles(importPaths []string, fileNames ...string) (DescriptorSource, error) {\n\tfileNames, err := protoparse.ResolveFilenames(importPaths, fileNames...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tp := protoparse.Parser{\n\t\tImportPaths:           importPaths,\n\t\tInferImportPaths:      len(importPaths) == 0,\n\t\tIncludeSourceCodeInfo: true,\n\t}\n\tfds, err := p.ParseFiles(fileNames...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"could not parse given files: %v\", err)\n\t}\n\treturn DescriptorSourceFromFileDescriptors(fds...)\n}\n\n// DescriptorSourceFromFileDescriptorSet creates a DescriptorSource that is backed by the FileDescriptorSet.\nfunc DescriptorSourceFromFileDescriptorSet(files *descriptorpb.FileDescriptorSet) (DescriptorSource, error) {\n\tunresolved := map[string]*descriptorpb.FileDescriptorProto{}\n\tfor _, fd := range files.File {\n\t\tunresolved[fd.GetName()] = fd\n\t}\n\tresolved := map[string]*desc.FileDescriptor{}\n\tfor _, fd := range files.File {\n\t\t_, err := resolveFileDescriptor(unresolved, resolved, fd.GetName())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn &fileSource{files: resolved}, nil\n}\n\nfunc resolveFileDescriptor(unresolved map[string]*descriptorpb.FileDescriptorProto, resolved map[string]*desc.FileDescriptor, filename string) (*desc.FileDescriptor, error) {\n\tif r, ok := resolved[filename]; ok {\n\t\treturn r, nil\n\t}\n\tfd, ok := unresolved[filename]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"no descriptor found for %q\", filename)\n\t}\n\tdeps := make([]*desc.FileDescriptor, 0, len(fd.GetDependency()))\n\tfor _, dep := range fd.GetDependency() {\n\t\tdepFd, err := resolveFileDescriptor(unresolved, resolved, dep)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdeps = append(deps, depFd)\n\t}\n\tresult, err := desc.CreateFileDescriptor(fd, deps...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresolved[filename] = result\n\treturn result, nil\n}\n\n// DescriptorSourceFromFileDescriptors creates a DescriptorSource that is backed by the given\n// file descriptors\nfunc DescriptorSourceFromFileDescriptors(files ...*desc.FileDescriptor) (DescriptorSource, error) {\n\tfds := map[string]*desc.FileDescriptor{}\n\tfor _, fd := range files {\n\t\tif err := addFile(fd, fds); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn &fileSource{files: fds}, nil\n}\n\nfunc addFile(fd *desc.FileDescriptor, fds map[string]*desc.FileDescriptor) error {\n\tname := fd.GetName()\n\tif existing, ok := fds[name]; ok {\n\t\t// already added this file\n\t\tif existing != fd {\n\t\t\t// doh! duplicate files provided\n\t\t\treturn fmt.Errorf(\"given files include multiple copies of %q\", name)\n\t\t}\n\t\treturn nil\n\t}\n\tfds[name] = fd\n\tfor _, dep := range fd.GetDependencies() {\n\t\tif err := addFile(dep, fds); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\ntype fileSource struct {\n\tfiles  map[string]*desc.FileDescriptor\n\ter     *dynamic.ExtensionRegistry\n\terInit sync.Once\n}\n\nfunc (fs *fileSource) ListServices() ([]string, error) {\n\tset := map[string]bool{}\n\tfor _, fd := range fs.files {\n\t\tfor _, svc := range fd.GetServices() {\n\t\t\tset[svc.GetFullyQualifiedName()] = true\n\t\t}\n\t}\n\tsl := make([]string, 0, len(set))\n\tfor svc := range set {\n\t\tsl = append(sl, svc)\n\t}\n\treturn sl, nil\n}\n\n// GetAllFiles returns all of the underlying file descriptors. This is\n// more thorough and more efficient than the fallback strategy used by\n// the GetAllFiles package method, for enumerating all files from a\n// descriptor source.\nfunc (fs *fileSource) GetAllFiles() ([]*desc.FileDescriptor, error) {\n\tfiles := make([]*desc.FileDescriptor, len(fs.files))\n\ti := 0\n\tfor _, fd := range fs.files {\n\t\tfiles[i] = fd\n\t\ti++\n\t}\n\treturn files, nil\n}\n\nfunc (fs *fileSource) FindSymbol(fullyQualifiedName string) (desc.Descriptor, error) {\n\tfor _, fd := range fs.files {\n\t\tif dsc := fd.FindSymbol(fullyQualifiedName); dsc != nil {\n\t\t\treturn dsc, nil\n\t\t}\n\t}\n\treturn nil, notFound(\"Symbol\", fullyQualifiedName)\n}\n\nfunc (fs *fileSource) AllExtensionsForType(typeName string) ([]*desc.FieldDescriptor, error) {\n\tfs.erInit.Do(func() {\n\t\tfs.er = &dynamic.ExtensionRegistry{}\n\t\tfor _, fd := range fs.files {\n\t\t\tfs.er.AddExtensionsFromFile(fd)\n\t\t}\n\t})\n\treturn fs.er.AllExtensionsForType(typeName), nil\n}\n\n// DescriptorSourceFromServer creates a DescriptorSource that uses the given gRPC reflection client\n// to interrogate a server for descriptor information. If the server does not support the reflection\n// API then the various DescriptorSource methods will return ErrReflectionNotSupported\nfunc DescriptorSourceFromServer(_ context.Context, refClient *grpcreflect.Client) DescriptorSource {\n\treturn serverSource{client: refClient}\n}\n\ntype serverSource struct {\n\tclient *grpcreflect.Client\n}\n\nfunc (ss serverSource) ListServices() ([]string, error) {\n\tsvcs, err := ss.client.ListServices()\n\treturn svcs, reflectionSupport(err)\n}\n\nfunc (ss serverSource) FindSymbol(fullyQualifiedName string) (desc.Descriptor, error) {\n\tfile, err := ss.client.FileContainingSymbol(fullyQualifiedName)\n\tif err != nil {\n\t\treturn nil, reflectionSupport(err)\n\t}\n\td := file.FindSymbol(fullyQualifiedName)\n\tif d == nil {\n\t\treturn nil, notFound(\"Symbol\", fullyQualifiedName)\n\t}\n\treturn d, nil\n}\n\nfunc (ss serverSource) AllExtensionsForType(typeName string) ([]*desc.FieldDescriptor, error) {\n\tvar exts []*desc.FieldDescriptor\n\tnums, err := ss.client.AllExtensionNumbersForType(typeName)\n\tif err != nil {\n\t\treturn nil, reflectionSupport(err)\n\t}\n\tfor _, fieldNum := range nums {\n\t\text, err := ss.client.ResolveExtension(typeName, fieldNum)\n\t\tif err != nil {\n\t\t\treturn nil, reflectionSupport(err)\n\t\t}\n\t\texts = append(exts, ext)\n\t}\n\treturn exts, nil\n}\n\nfunc reflectionSupport(err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\tif stat, ok := status.FromError(err); ok && stat.Code() == codes.Unimplemented {\n\t\treturn ErrReflectionNotSupported\n\t}\n\treturn err\n}\n\n// WriteProtoset will use the given descriptor source to resolve all of the given\n// symbols and write a proto file descriptor set with their definitions to the\n// given output. The output will include descriptors for all files in which the\n// symbols are defined as well as their transitive dependencies.\nfunc WriteProtoset(out io.Writer, descSource DescriptorSource, symbols ...string) error {\n\tfilenames, fds, err := getFileDescriptors(symbols, descSource)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// now expand that to include transitive dependencies in topologically sorted\n\t// order (such that file always appears after its dependencies)\n\texpandedFiles := make(map[string]struct{}, len(fds))\n\tallFilesSlice := make([]*descriptorpb.FileDescriptorProto, 0, len(fds))\n\tfor _, filename := range filenames {\n\t\tallFilesSlice = addFilesToSet(allFilesSlice, expandedFiles, fds[filename])\n\t}\n\t// now we can serialize to file\n\tb, err := proto.Marshal(&descriptorpb.FileDescriptorSet{File: allFilesSlice})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to serialize file descriptor set: %v\", err)\n\t}\n\tif _, err := out.Write(b); err != nil {\n\t\treturn fmt.Errorf(\"failed to write file descriptor set: %v\", err)\n\t}\n\treturn nil\n}\n\nfunc addFilesToSet(allFiles []*descriptorpb.FileDescriptorProto, expanded map[string]struct{}, fd *desc.FileDescriptor) []*descriptorpb.FileDescriptorProto {\n\tif _, ok := expanded[fd.GetName()]; ok {\n\t\t// already seen this one\n\t\treturn allFiles\n\t}\n\texpanded[fd.GetName()] = struct{}{}\n\t// add all dependencies first\n\tfor _, dep := range fd.GetDependencies() {\n\t\tallFiles = addFilesToSet(allFiles, expanded, dep)\n\t}\n\treturn append(allFiles, fd.AsFileDescriptorProto())\n}\n\n// WriteProtoFiles will use the given descriptor source to resolve all the given\n// symbols and write proto files with their definitions to the given output directory.\nfunc WriteProtoFiles(outProtoDirPath string, descSource DescriptorSource, symbols ...string) error {\n\tfilenames, fds, err := getFileDescriptors(symbols, descSource)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// now expand that to include transitive dependencies in topologically sorted\n\t// order (such that file always appears after its dependencies)\n\texpandedFiles := make(map[string]struct{}, len(fds))\n\tallFileDescriptors := make([]*desc.FileDescriptor, 0, len(fds))\n\tfor _, filename := range filenames {\n\t\tallFileDescriptors = addFilesToFileDescriptorList(allFileDescriptors, expandedFiles, fds[filename])\n\t}\n\tpr := protoprint.Printer{}\n\t// now we can serialize to files\n\tfor i := range allFileDescriptors {\n\t\tif err := writeProtoFile(outProtoDirPath, allFileDescriptors[i], &pr); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc writeProtoFile(outProtoDirPath string, fd *desc.FileDescriptor, pr *protoprint.Printer) error {\n\toutFile := filepath.Join(outProtoDirPath, fd.GetFullyQualifiedName())\n\toutDir := filepath.Dir(outFile)\n\tif err := os.MkdirAll(outDir, 0777); err != nil {\n\t\treturn fmt.Errorf(\"failed to create directory %q: %w\", outDir, err)\n\t}\n\n\tf, err := os.Create(outFile)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create proto file %q: %w\", outFile, err)\n\t}\n\tdefer f.Close()\n\tif err := pr.PrintProtoFile(fd, f); err != nil {\n\t\treturn fmt.Errorf(\"failed to write proto file %q: %w\", outFile, err)\n\t}\n\treturn nil\n}\n\nfunc getFileDescriptors(symbols []string, descSource DescriptorSource) ([]string, map[string]*desc.FileDescriptor, error) {\n\t// compute set of file descriptors\n\tfilenames := make([]string, 0, len(symbols))\n\tfds := make(map[string]*desc.FileDescriptor, len(symbols))\n\tfor _, sym := range symbols {\n\t\td, err := descSource.FindSymbol(sym)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"failed to find descriptor for %q: %v\", sym, err)\n\t\t}\n\t\tfd := d.GetFile()\n\t\tif _, ok := fds[fd.GetName()]; !ok {\n\t\t\tfds[fd.GetName()] = fd\n\t\t\tfilenames = append(filenames, fd.GetName())\n\t\t}\n\t}\n\treturn filenames, fds, nil\n}\n\nfunc addFilesToFileDescriptorList(allFiles []*desc.FileDescriptor, expanded map[string]struct{}, fd *desc.FileDescriptor) []*desc.FileDescriptor {\n\tif _, ok := expanded[fd.GetName()]; ok {\n\t\t// already seen this one\n\t\treturn allFiles\n\t}\n\texpanded[fd.GetName()] = struct{}{}\n\t// add all dependencies first\n\tfor _, dep := range fd.GetDependencies() {\n\t\tallFiles = addFilesToFileDescriptorList(allFiles, expanded, dep)\n\t}\n\treturn append(allFiles, fd)\n}\n"
        },
        {
          "name": "desc_source_test.go",
          "type": "blob",
          "size": 1.86328125,
          "content": "package grpcurl\n\nimport (\n\t\"bytes\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/golang/protobuf/proto\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"google.golang.org/protobuf/types/descriptorpb\"\n)\n\nfunc TestWriteProtoset(t *testing.T) {\n\texampleProtoset, err := loadProtoset(\"./internal/testing/example.protoset\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to load example.protoset: %v\", err)\n\t}\n\ttestProtoset, err := loadProtoset(\"./internal/testing/test.protoset\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to load test.protoset: %v\", err)\n\t}\n\n\tmergedProtoset := &descriptorpb.FileDescriptorSet{\n\t\tFile: append(exampleProtoset.File, testProtoset.File...),\n\t}\n\n\tdescSrc, err := DescriptorSourceFromFileDescriptorSet(mergedProtoset)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create descriptor source: %v\", err)\n\t}\n\n\tcheckWriteProtoset(t, descSrc, exampleProtoset, \"TestService\")\n\tcheckWriteProtoset(t, descSrc, testProtoset, \"testing.TestService\")\n\tcheckWriteProtoset(t, descSrc, mergedProtoset, \"TestService\", \"testing.TestService\")\n}\n\nfunc loadProtoset(path string) (*descriptorpb.FileDescriptorSet, error) {\n\tb, err := os.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar protoset descriptorpb.FileDescriptorSet\n\tif err := proto.Unmarshal(b, &protoset); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &protoset, nil\n}\n\nfunc checkWriteProtoset(t *testing.T, descSrc DescriptorSource, protoset *descriptorpb.FileDescriptorSet, symbols ...string) {\n\tvar buf bytes.Buffer\n\tif err := WriteProtoset(&buf, descSrc, symbols...); err != nil {\n\t\tt.Fatalf(\"failed to write protoset: %v\", err)\n\t}\n\n\tvar result descriptorpb.FileDescriptorSet\n\tif err := proto.Unmarshal(buf.Bytes(), &result); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal written protoset: %v\", err)\n\t}\n\n\tif !proto.Equal(protoset, &result) {\n\t\tt.Fatalf(\"written protoset not equal to input:\\nExpecting: %s\\nActual: %s\", protoset, &result)\n\t}\n}\n"
        },
        {
          "name": "download_protoc.sh",
          "type": "blob",
          "size": 1.05078125,
          "content": "#!/usr/bin/env bash\n\nset -e\n\ncd $(dirname $0)\n\nif [[ -z \"$PROTOC_VERSION\" ]]; then\n  echo \"Set PROTOC_VERSION env var to indicate the version to download\" >&2\n  exit 1\nfi\nPROTOC_OS=\"$(uname -s)\"\nPROTOC_ARCH=\"$(uname -m)\"\ncase \"${PROTOC_OS}\" in\n  Darwin) PROTOC_OS=\"osx\" ;;\n  Linux) PROTOC_OS=\"linux\" ;;\n  *)\n    echo \"Invalid value for uname -s: ${PROTOC_OS}\" >&2\n    exit 1\nesac\n\n# This is for macs with M1 chips. Precompiled binaries for osx/amd64 are not available for download, so for that case\n# we download the x86_64 version instead. This will work as long as rosetta2 is installed.\nif [ \"$PROTOC_OS\" = \"osx\" ] && [ \"$PROTOC_ARCH\" = \"arm64\" ]; then\n  PROTOC_ARCH=\"x86_64\"\nfi\n\nPROTOC=\"${PWD}/.tmp/protoc/bin/protoc\"\n\nif [[ \"$(${PROTOC} --version 2>/dev/null)\" != \"libprotoc 3.${PROTOC_VERSION}\" ]]; then\n  rm -rf ./.tmp/protoc\n  mkdir -p .tmp/protoc\n  curl -L \"https://github.com/google/protobuf/releases/download/v${PROTOC_VERSION}/protoc-${PROTOC_VERSION}-${PROTOC_OS}-${PROTOC_ARCH}.zip\" > .tmp/protoc/protoc.zip\n  pushd ./.tmp/protoc && unzip protoc.zip && popd\nfi\n\n"
        },
        {
          "name": "format.go",
          "type": "blob",
          "size": 17.7568359375,
          "content": "package grpcurl\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/golang/protobuf/jsonpb\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/golang/protobuf/proto\"  //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"github.com/jhump/protoreflect/dynamic\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n)\n\n// RequestParser processes input into messages.\ntype RequestParser interface {\n\t// Next parses input data into the given request message. If called after\n\t// input is exhausted, it returns io.EOF. If the caller re-uses the same\n\t// instance in multiple calls to Next, it should call msg.Reset() in between\n\t// each call.\n\tNext(msg proto.Message) error\n\t// NumRequests returns the number of messages that have been parsed and\n\t// returned by a call to Next.\n\tNumRequests() int\n}\n\ntype jsonRequestParser struct {\n\tdec          *json.Decoder\n\tunmarshaler  jsonpb.Unmarshaler\n\trequestCount int\n}\n\n// NewJSONRequestParser returns a RequestParser that reads data in JSON format\n// from the given reader. The given resolver is used to assist with decoding of\n// google.protobuf.Any messages.\n//\n// Input data that contains more than one message should just include all\n// messages concatenated (though whitespace is necessary to separate some kinds\n// of values in JSON).\n//\n// If the given reader has no data, the returned parser will return io.EOF on\n// the very first call.\nfunc NewJSONRequestParser(in io.Reader, resolver jsonpb.AnyResolver) RequestParser {\n\treturn &jsonRequestParser{\n\t\tdec:         json.NewDecoder(in),\n\t\tunmarshaler: jsonpb.Unmarshaler{AnyResolver: resolver},\n\t}\n}\n\n// NewJSONRequestParserWithUnmarshaler is like NewJSONRequestParser but\n// accepts a protobuf jsonpb.Unmarshaler instead of jsonpb.AnyResolver.\nfunc NewJSONRequestParserWithUnmarshaler(in io.Reader, unmarshaler jsonpb.Unmarshaler) RequestParser {\n\treturn &jsonRequestParser{\n\t\tdec:         json.NewDecoder(in),\n\t\tunmarshaler: unmarshaler,\n\t}\n}\n\nfunc (f *jsonRequestParser) Next(m proto.Message) error {\n\tvar msg json.RawMessage\n\tif err := f.dec.Decode(&msg); err != nil {\n\t\treturn err\n\t}\n\tf.requestCount++\n\treturn f.unmarshaler.Unmarshal(bytes.NewReader(msg), m)\n}\n\nfunc (f *jsonRequestParser) NumRequests() int {\n\treturn f.requestCount\n}\n\nconst (\n\ttextSeparatorChar = '\\x1e'\n)\n\ntype textRequestParser struct {\n\tr            *bufio.Reader\n\terr          error\n\trequestCount int\n}\n\n// NewTextRequestParser returns a RequestParser that reads data in the protobuf\n// text format from the given reader.\n//\n// Input data that contains more than one message should include an ASCII\n// 'Record Separator' character (0x1E) between each message.\n//\n// Empty text is a valid text format and represents an empty message. So if the\n// given reader has no data, the returned parser will yield an empty message\n// for the first call to Next and then return io.EOF thereafter. This also means\n// that if the input data ends with a record separator, then a final empty\n// message will be parsed *after* the separator.\nfunc NewTextRequestParser(in io.Reader) RequestParser {\n\treturn &textRequestParser{r: bufio.NewReader(in)}\n}\n\nfunc (f *textRequestParser) Next(m proto.Message) error {\n\tif f.err != nil {\n\t\treturn f.err\n\t}\n\n\tvar b []byte\n\tb, f.err = f.r.ReadBytes(textSeparatorChar)\n\tif f.err != nil && f.err != io.EOF {\n\t\treturn f.err\n\t}\n\t// remove delimiter\n\tif len(b) > 0 && b[len(b)-1] == textSeparatorChar {\n\t\tb = b[:len(b)-1]\n\t}\n\n\tf.requestCount++\n\n\treturn proto.UnmarshalText(string(b), m)\n}\n\nfunc (f *textRequestParser) NumRequests() int {\n\treturn f.requestCount\n}\n\n// Formatter translates messages into string representations.\ntype Formatter func(proto.Message) (string, error)\n\n// NewJSONFormatter returns a formatter that returns JSON strings. The JSON will\n// include empty/default values (instead of just omitted them) if emitDefaults\n// is true. The given resolver is used to assist with encoding of\n// google.protobuf.Any messages.\nfunc NewJSONFormatter(emitDefaults bool, resolver jsonpb.AnyResolver) Formatter {\n\tmarshaler := jsonpb.Marshaler{\n\t\tEmitDefaults: emitDefaults,\n\t\tAnyResolver:  resolver,\n\t}\n\t// Workaround for indentation issue in jsonpb with Any messages.\n\t// Bug was originally fixed in https://github.com/golang/protobuf/pull/834\n\t// but later re-introduced before the module was deprecated and frozen.\n\t// If jsonpb is ever replaced with google.golang.org/protobuf/encoding/protojson\n\t// this workaround will no longer be needed.\n\tformatter := func(message proto.Message) (string, error) {\n\t\toutput, err := marshaler.MarshalToString(message)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tvar buf bytes.Buffer\n\t\tif err := json.Indent(&buf, []byte(output), \"\", \"  \"); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn buf.String(), nil\n\t}\n\treturn formatter\n}\n\n// NewTextFormatter returns a formatter that returns strings in the protobuf\n// text format. If includeSeparator is true then, when invoked to format\n// multiple messages, all messages after the first one will be prefixed with the\n// ASCII 'Record Separator' character (0x1E).\nfunc NewTextFormatter(includeSeparator bool) Formatter {\n\ttf := textFormatter{useSeparator: includeSeparator}\n\treturn tf.format\n}\n\ntype textFormatter struct {\n\tuseSeparator bool\n\tnumFormatted int\n}\n\nvar protoTextMarshaler = proto.TextMarshaler{ExpandAny: true}\n\nfunc (tf *textFormatter) format(m proto.Message) (string, error) {\n\tvar buf bytes.Buffer\n\tif tf.useSeparator && tf.numFormatted > 0 {\n\t\tif err := buf.WriteByte(textSeparatorChar); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\n\t// If message implements MarshalText method (such as a *dynamic.Message),\n\t// it won't get details about whether or not to format to text compactly\n\t// or with indentation. So first see if the message also implements a\n\t// MarshalTextIndent method and use that instead if available.\n\ttype indentMarshaler interface {\n\t\tMarshalTextIndent() ([]byte, error)\n\t}\n\n\tif indenter, ok := m.(indentMarshaler); ok {\n\t\tb, err := indenter.MarshalTextIndent()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tif _, err := buf.Write(b); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t} else if err := protoTextMarshaler.Marshal(&buf, m); err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// no trailing newline needed\n\tstr := buf.String()\n\tif len(str) > 0 && str[len(str)-1] == '\\n' {\n\t\tstr = str[:len(str)-1]\n\t}\n\n\ttf.numFormatted++\n\n\treturn str, nil\n}\n\n// Format of request data. The allowed values are 'json' or 'text'.\ntype Format string\n\nconst (\n\t// FormatJSON specifies input data in JSON format. Multiple request values\n\t// may be concatenated (messages with a JSON representation other than\n\t// object must be separated by whitespace, such as a newline)\n\tFormatJSON = Format(\"json\")\n\n\t// FormatText specifies input data must be in the protobuf text format.\n\t// Multiple request values must be separated by the \"record separator\"\n\t// ASCII character: 0x1E. The stream should not end in a record separator.\n\t// If it does, it will be interpreted as a final, blank message after the\n\t// separator.\n\tFormatText = Format(\"text\")\n)\n\n// AnyResolverFromDescriptorSource returns an AnyResolver that will search for\n// types using the given descriptor source.\nfunc AnyResolverFromDescriptorSource(source DescriptorSource) jsonpb.AnyResolver {\n\treturn &anyResolver{source: source}\n}\n\n// AnyResolverFromDescriptorSourceWithFallback returns an AnyResolver that will\n// search for types using the given descriptor source and then fallback to a\n// special message if the type is not found. The fallback type will render to\n// JSON with a \"@type\" property, just like an Any message, but also with a\n// custom \"@value\" property that includes the binary encoded payload.\nfunc AnyResolverFromDescriptorSourceWithFallback(source DescriptorSource) jsonpb.AnyResolver {\n\tres := anyResolver{source: source}\n\treturn &anyResolverWithFallback{AnyResolver: &res}\n}\n\ntype anyResolver struct {\n\tsource DescriptorSource\n\n\ter dynamic.ExtensionRegistry\n\n\tmu       sync.RWMutex\n\tmf       *dynamic.MessageFactory\n\tresolved map[string]func() proto.Message\n}\n\nfunc (r *anyResolver) Resolve(typeUrl string) (proto.Message, error) {\n\tmname := typeUrl\n\tif slash := strings.LastIndex(mname, \"/\"); slash >= 0 {\n\t\tmname = mname[slash+1:]\n\t}\n\n\tr.mu.RLock()\n\tfactory := r.resolved[mname]\n\tr.mu.RUnlock()\n\n\t// already resolved?\n\tif factory != nil {\n\t\treturn factory(), nil\n\t}\n\n\tr.mu.Lock()\n\tdefer r.mu.Unlock()\n\n\t// double-check, in case we were racing with another goroutine\n\t// that resolved this one\n\tfactory = r.resolved[mname]\n\tif factory != nil {\n\t\treturn factory(), nil\n\t}\n\n\t// use descriptor source to resolve message type\n\td, err := r.source.FindSymbol(mname)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmd, ok := d.(*desc.MessageDescriptor)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unknown message: %s\", typeUrl)\n\t}\n\t// populate any extensions for this message, too (if there are any)\n\tif exts, err := r.source.AllExtensionsForType(mname); err == nil {\n\t\tif err := r.er.AddExtension(exts...); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif r.mf == nil {\n\t\tr.mf = dynamic.NewMessageFactoryWithExtensionRegistry(&r.er)\n\t}\n\n\tfactory = func() proto.Message {\n\t\treturn r.mf.NewMessage(md)\n\t}\n\tif r.resolved == nil {\n\t\tr.resolved = map[string]func() proto.Message{}\n\t}\n\tr.resolved[mname] = factory\n\treturn factory(), nil\n}\n\n// anyResolverWithFallback can provide a fallback value for unknown\n// messages that will format itself to JSON using an \"@value\" field\n// that has the base64-encoded data for the unknown message value.\ntype anyResolverWithFallback struct {\n\tjsonpb.AnyResolver\n}\n\nfunc (r anyResolverWithFallback) Resolve(typeUrl string) (proto.Message, error) {\n\tmsg, err := r.AnyResolver.Resolve(typeUrl)\n\tif err == nil {\n\t\treturn msg, err\n\t}\n\n\t// Try \"default\" resolution logic. This mirrors the default behavior\n\t// of jsonpb, which checks to see if the given message name is registered\n\t// in the proto package.\n\tmname := typeUrl\n\tif slash := strings.LastIndex(mname, \"/\"); slash >= 0 {\n\t\tmname = mname[slash+1:]\n\t}\n\t//lint:ignore SA1019 new non-deprecated API requires other code changes; deferring...\n\tmt := proto.MessageType(mname)\n\tif mt != nil {\n\t\treturn reflect.New(mt.Elem()).Interface().(proto.Message), nil\n\t}\n\n\t// finally, fallback to a special placeholder that can marshal itself\n\t// to JSON using a special \"@value\" property to show base64-encoded\n\t// data for the embedded message\n\treturn &unknownAny{TypeUrl: typeUrl, Error: fmt.Sprintf(\"%s is not recognized; see @value for raw binary message data\", mname)}, nil\n}\n\ntype unknownAny struct {\n\tTypeUrl string `json:\"@type\"`\n\tError   string `json:\"@error\"`\n\tValue   string `json:\"@value\"`\n}\n\nfunc (a *unknownAny) MarshalJSONPB(jsm *jsonpb.Marshaler) ([]byte, error) {\n\tif jsm.Indent != \"\" {\n\t\treturn json.MarshalIndent(a, \"\", jsm.Indent)\n\t}\n\treturn json.Marshal(a)\n}\n\nfunc (a *unknownAny) Unmarshal(b []byte) error {\n\ta.Value = base64.StdEncoding.EncodeToString(b)\n\treturn nil\n}\n\nfunc (a *unknownAny) Reset() {\n\ta.Value = \"\"\n}\n\nfunc (a *unknownAny) String() string {\n\tb, err := a.MarshalJSONPB(&jsonpb.Marshaler{})\n\tif err != nil {\n\t\treturn fmt.Sprintf(\"ERROR: %v\", err.Error())\n\t}\n\treturn string(b)\n}\n\nfunc (a *unknownAny) ProtoMessage() {\n}\n\nvar _ proto.Message = (*unknownAny)(nil)\n\n// FormatOptions is a set of flags that are passed to a JSON or text formatter.\ntype FormatOptions struct {\n\t// EmitJSONDefaultFields flag, when true, includes empty/default values in the output.\n\t// FormatJSON only flag.\n\tEmitJSONDefaultFields bool\n\n\t// AllowUnknownFields is an option for the parser. When true,\n\t// it accepts input which includes unknown fields. These unknown fields\n\t// are skipped instead of returning an error.\n\t// FormatJSON only flag.\n\tAllowUnknownFields bool\n\n\t// IncludeTextSeparator is true then, when invoked to format multiple messages,\n\t// all messages after the first one will be prefixed with the\n\t// ASCII 'Record Separator' character (0x1E).\n\t// It might be useful when the output is piped to another grpcurl process.\n\t// FormatText only flag.\n\tIncludeTextSeparator bool\n}\n\n// RequestParserAndFormatter returns a request parser and formatter for the\n// given format. The given descriptor source may be used for parsing message\n// data (if needed by the format).\n// It accepts a set of options. The field EmitJSONDefaultFields and IncludeTextSeparator\n// are options for JSON and protobuf text formats, respectively. The AllowUnknownFields field\n// is a JSON-only format flag.\n// Requests will be parsed from the given in.\nfunc RequestParserAndFormatter(format Format, descSource DescriptorSource, in io.Reader, opts FormatOptions) (RequestParser, Formatter, error) {\n\tswitch format {\n\tcase FormatJSON:\n\t\tresolver := AnyResolverFromDescriptorSource(descSource)\n\t\tunmarshaler := jsonpb.Unmarshaler{AnyResolver: resolver, AllowUnknownFields: opts.AllowUnknownFields}\n\t\treturn NewJSONRequestParserWithUnmarshaler(in, unmarshaler), NewJSONFormatter(opts.EmitJSONDefaultFields, anyResolverWithFallback{AnyResolver: resolver}), nil\n\tcase FormatText:\n\t\treturn NewTextRequestParser(in), NewTextFormatter(opts.IncludeTextSeparator), nil\n\tdefault:\n\t\treturn nil, nil, fmt.Errorf(\"unknown format: %s\", format)\n\t}\n}\n\n// RequestParserAndFormatterFor returns a request parser and formatter for the\n// given format. The given descriptor source may be used for parsing message\n// data (if needed by the format). The flags emitJSONDefaultFields and\n// includeTextSeparator are options for JSON and protobuf text formats,\n// respectively. Requests will be parsed from the given in.\n// This function is deprecated. Please use RequestParserAndFormatter instead.\n// DEPRECATED\nfunc RequestParserAndFormatterFor(format Format, descSource DescriptorSource, emitJSONDefaultFields, includeTextSeparator bool, in io.Reader) (RequestParser, Formatter, error) {\n\treturn RequestParserAndFormatter(format, descSource, in, FormatOptions{\n\t\tEmitJSONDefaultFields: emitJSONDefaultFields,\n\t\tIncludeTextSeparator:  includeTextSeparator,\n\t})\n}\n\n// DefaultEventHandler logs events to a writer. This is not thread-safe, but is\n// safe for use with InvokeRPC as long as NumResponses and Status are not read\n// until the call to InvokeRPC completes.\ntype DefaultEventHandler struct {\n\tOut       io.Writer\n\tFormatter Formatter\n\t// 0 = default\n\t// 1 = verbose\n\t// 2 = very verbose\n\tVerbosityLevel int\n\n\t// NumResponses is the number of responses that have been received.\n\tNumResponses int\n\t// Status is the status that was received at the end of an RPC. It is\n\t// nil if the RPC is still in progress.\n\tStatus *status.Status\n}\n\n// NewDefaultEventHandler returns an InvocationEventHandler that logs events to\n// the given output. If verbose is true, all events are logged. Otherwise, only\n// response messages are logged.\n//\n// Deprecated: NewDefaultEventHandler exists for compatibility.\n// It doesn't allow fine control over the `VerbosityLevel`\n// and provides only 0 and 1 options (which corresponds to the `verbose` argument).\n// Use DefaultEventHandler{} initializer directly.\nfunc NewDefaultEventHandler(out io.Writer, descSource DescriptorSource, formatter Formatter, verbose bool) *DefaultEventHandler {\n\tverbosityLevel := 0\n\tif verbose {\n\t\tverbosityLevel = 1\n\t}\n\treturn &DefaultEventHandler{\n\t\tOut:            out,\n\t\tFormatter:      formatter,\n\t\tVerbosityLevel: verbosityLevel,\n\t}\n}\n\nvar _ InvocationEventHandler = (*DefaultEventHandler)(nil)\n\nfunc (h *DefaultEventHandler) OnResolveMethod(md *desc.MethodDescriptor) {\n\tif h.VerbosityLevel > 0 {\n\t\ttxt, err := GetDescriptorText(md, nil)\n\t\tif err == nil {\n\t\t\tfmt.Fprintf(h.Out, \"\\nResolved method descriptor:\\n%s\\n\", txt)\n\t\t}\n\t}\n}\n\nfunc (h *DefaultEventHandler) OnSendHeaders(md metadata.MD) {\n\tif h.VerbosityLevel > 0 {\n\t\tfmt.Fprintf(h.Out, \"\\nRequest metadata to send:\\n%s\\n\", MetadataToString(md))\n\t}\n}\n\nfunc (h *DefaultEventHandler) OnReceiveHeaders(md metadata.MD) {\n\tif h.VerbosityLevel > 0 {\n\t\tfmt.Fprintf(h.Out, \"\\nResponse headers received:\\n%s\\n\", MetadataToString(md))\n\t}\n}\n\nfunc (h *DefaultEventHandler) OnReceiveResponse(resp proto.Message) {\n\th.NumResponses++\n\tif h.VerbosityLevel > 1 {\n\t\tfmt.Fprintf(h.Out, \"\\nEstimated response size: %d bytes\\n\", proto.Size(resp))\n\t}\n\tif h.VerbosityLevel > 0 {\n\t\tfmt.Fprint(h.Out, \"\\nResponse contents:\\n\")\n\t}\n\tif respStr, err := h.Formatter(resp); err != nil {\n\t\tfmt.Fprintf(h.Out, \"Failed to format response message %d: %v\\n\", h.NumResponses, err)\n\t} else {\n\t\tfmt.Fprintln(h.Out, respStr)\n\t}\n}\n\nfunc (h *DefaultEventHandler) OnReceiveTrailers(stat *status.Status, md metadata.MD) {\n\th.Status = stat\n\tif h.VerbosityLevel > 0 {\n\t\tfmt.Fprintf(h.Out, \"\\nResponse trailers received:\\n%s\\n\", MetadataToString(md))\n\t}\n}\n\n// PrintStatus prints details about the given status to the given writer. The given\n// formatter is used to print any detail messages that may be included in the status.\n// If the given status has a code of OK, \"OK\" is printed and that is all. Otherwise,\n// \"ERROR:\" is printed along with a line showing the code, one showing the message\n// string, and each detail message if any are present. The detail messages will be\n// printed as proto text format or JSON, depending on the given formatter.\nfunc PrintStatus(w io.Writer, stat *status.Status, formatter Formatter) {\n\tif stat.Code() == codes.OK {\n\t\tfmt.Fprintln(w, \"OK\")\n\t\treturn\n\t}\n\tfmt.Fprintf(w, \"ERROR:\\n  Code: %s\\n  Message: %s\\n\", stat.Code().String(), stat.Message())\n\n\tstatpb := stat.Proto()\n\tif len(statpb.Details) > 0 {\n\t\tfmt.Fprintf(w, \"  Details:\\n\")\n\t\tfor i, det := range statpb.Details {\n\t\t\tprefix := fmt.Sprintf(\"  %d)\", i+1)\n\t\t\tfmt.Fprintf(w, \"%s\\t\", prefix)\n\t\t\tprefix = strings.Repeat(\" \", len(prefix)) + \"\\t\"\n\n\t\t\toutput, err := formatter(det)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Fprintf(w, \"Error parsing detail message: %v\\n\", err)\n\t\t\t} else {\n\t\t\t\tlines := strings.Split(output, \"\\n\")\n\t\t\t\tfor i, line := range lines {\n\t\t\t\t\tif i == 0 {\n\t\t\t\t\t\t// first line is already indented\n\t\t\t\t\t\tfmt.Fprintf(w, \"%s\\n\", line)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfmt.Fprintf(w, \"%s%s\\n\", prefix, line)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "format_test.go",
          "type": "blob",
          "size": 7.41796875,
          "content": "package grpcurl\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/golang/protobuf/jsonpb\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/golang/protobuf/proto\"  //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/protobuf/types/known/structpb\"\n)\n\nfunc TestRequestParser(t *testing.T) {\n\tsource, err := DescriptorSourceFromProtoSets(\"internal/testing/example.protoset\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create descriptor source: %v\", err)\n\t}\n\n\tmsg, err := makeProto()\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create message: %v\", err)\n\t}\n\n\ttestCases := []struct {\n\t\tformat         Format\n\t\tinput          string\n\t\texpectedOutput []proto.Message\n\t}{\n\t\t{\n\t\t\tformat: FormatJSON,\n\t\t\tinput:  \"\",\n\t\t},\n\t\t{\n\t\t\tformat:         FormatJSON,\n\t\t\tinput:          messageAsJSON,\n\t\t\texpectedOutput: []proto.Message{msg},\n\t\t},\n\t\t{\n\t\t\tformat:         FormatJSON,\n\t\t\tinput:          messageAsJSON + messageAsJSON + messageAsJSON,\n\t\t\texpectedOutput: []proto.Message{msg, msg, msg},\n\t\t},\n\t\t{\n\t\t\t// unlike JSON, empty input yields one empty message (vs. zero messages)\n\t\t\tformat:         FormatText,\n\t\t\tinput:          \"\",\n\t\t\texpectedOutput: []proto.Message{&structpb.Value{}},\n\t\t},\n\t\t{\n\t\t\tformat:         FormatText,\n\t\t\tinput:          messageAsText,\n\t\t\texpectedOutput: []proto.Message{msg},\n\t\t},\n\t\t{\n\t\t\tformat:         FormatText,\n\t\t\tinput:          messageAsText + string(textSeparatorChar),\n\t\t\texpectedOutput: []proto.Message{msg, &structpb.Value{}},\n\t\t},\n\t\t{\n\t\t\tformat:         FormatText,\n\t\t\tinput:          messageAsText + string(textSeparatorChar) + messageAsText + string(textSeparatorChar) + messageAsText,\n\t\t\texpectedOutput: []proto.Message{msg, msg, msg},\n\t\t},\n\t}\n\n\tfor i, tc := range testCases {\n\t\tname := fmt.Sprintf(\"#%d, %s, %d message(s)\", i+1, tc.format, len(tc.expectedOutput))\n\t\trf, _, err := RequestParserAndFormatter(tc.format, source, strings.NewReader(tc.input), FormatOptions{})\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Failed to create parser and formatter: %v\", err)\n\t\t\tcontinue\n\t\t}\n\t\tnumReqs := 0\n\t\tfor {\n\t\t\tvar req structpb.Value\n\t\t\terr := rf.Next(&req)\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t} else if err != nil {\n\t\t\t\tt.Errorf(\"%s, msg %d: unexpected error: %v\", name, numReqs, err)\n\t\t\t}\n\t\t\tif !proto.Equal(&req, tc.expectedOutput[numReqs]) {\n\t\t\t\tt.Errorf(\"%s, msg %d: incorrect message;\\nexpecting:\\n%v\\ngot:\\n%v\", name, numReqs, tc.expectedOutput[numReqs], &req)\n\t\t\t}\n\t\t\tnumReqs++\n\t\t}\n\t\tif rf.NumRequests() != numReqs {\n\t\t\tt.Errorf(\"%s: factory reported wrong number of requests: expecting %d, got %d\", name, numReqs, rf.NumRequests())\n\t\t}\n\t}\n}\n\n// Handler prints response data (and headers/trailers in verbose mode).\n// This verifies that we get the right output in both JSON and proto text modes.\nfunc TestHandler(t *testing.T) {\n\tsource, err := DescriptorSourceFromProtoSets(\"internal/testing/example.protoset\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create descriptor source: %v\", err)\n\t}\n\td, err := source.FindSymbol(\"TestService.GetFiles\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to find method 'TestService.GetFiles': %v\", err)\n\t}\n\tmd, ok := d.(*desc.MethodDescriptor)\n\tif !ok {\n\t\tt.Fatalf(\"wrong kind of descriptor found: %T\", d)\n\t}\n\n\treqHeaders := metadata.Pairs(\"foo\", \"123\", \"bar\", \"456\")\n\trespHeaders := metadata.Pairs(\"foo\", \"abc\", \"bar\", \"def\", \"baz\", \"xyz\")\n\trespTrailers := metadata.Pairs(\"a\", \"1\", \"b\", \"2\", \"c\", \"3\")\n\trsp, err := makeProto()\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create response message: %v\", err)\n\t}\n\n\tfor _, format := range []Format{FormatJSON, FormatText} {\n\t\tfor _, numMessages := range []int{1, 3} {\n\t\t\tfor verbosityLevel := 0; verbosityLevel <= 2; verbosityLevel++ {\n\t\t\t\tname := fmt.Sprintf(\"%s, %d message(s)\", format, numMessages)\n\t\t\t\tif verbosityLevel > 0 {\n\t\t\t\t\tname += fmt.Sprintf(\", verbosityLevel=%d\", verbosityLevel)\n\t\t\t\t}\n\n\t\t\t\tverbose := verbosityLevel > 0\n\n\t\t\t\t_, formatter, err := RequestParserAndFormatter(format, source, nil, FormatOptions{IncludeTextSeparator: !verbose})\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"Failed to create parser and formatter: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\th := &DefaultEventHandler{\n\t\t\t\t\tOut:            &buf,\n\t\t\t\t\tFormatter:      formatter,\n\t\t\t\t\tVerbosityLevel: verbosityLevel,\n\t\t\t\t}\n\n\t\t\t\th.OnResolveMethod(md)\n\t\t\t\th.OnSendHeaders(reqHeaders)\n\t\t\t\th.OnReceiveHeaders(respHeaders)\n\t\t\t\tfor i := 0; i < numMessages; i++ {\n\t\t\t\t\th.OnReceiveResponse(rsp)\n\t\t\t\t}\n\t\t\t\th.OnReceiveTrailers(nil, respTrailers)\n\n\t\t\t\texpectedOutput := \"\"\n\t\t\t\tif verbose {\n\t\t\t\t\texpectedOutput += verbosePrefix\n\t\t\t\t}\n\t\t\t\tfor i := 0; i < numMessages; i++ {\n\t\t\t\t\tif verbosityLevel > 1 {\n\t\t\t\t\t\texpectedOutput += verboseResponseSize\n\t\t\t\t\t}\n\t\t\t\t\tif verbose {\n\t\t\t\t\t\texpectedOutput += verboseResponseHeader\n\t\t\t\t\t}\n\t\t\t\t\tif format == \"json\" {\n\t\t\t\t\t\texpectedOutput += messageAsJSON\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif i > 0 && !verbose {\n\t\t\t\t\t\t\texpectedOutput += string(textSeparatorChar)\n\t\t\t\t\t\t}\n\t\t\t\t\t\texpectedOutput += messageAsText\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif verbose {\n\t\t\t\t\texpectedOutput += verboseSuffix\n\t\t\t\t}\n\n\t\t\t\tout := buf.String()\n\t\t\t\tif !compare(out, expectedOutput) {\n\t\t\t\t\tt.Errorf(\"%s: Incorrect output. Expected:\\n%s\\nGot:\\n%s\", name, expectedOutput, out)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// compare checks that actual and expected are equal, returning true if so.\n// A simple equality check (==) does not suffice because jsonpb formats\n// structpb.Value strangely. So if that formatting gets fixed, we don't\n// want this test in grpcurl to suddenly start failing. So we check each\n// line and compare the lines after stripping whitespace (which removes\n// the jsonpb format anomalies).\nfunc compare(actual, expected string) bool {\n\tactualLines := strings.Split(actual, \"\\n\")\n\texpectedLines := strings.Split(expected, \"\\n\")\n\tif len(actualLines) != len(expectedLines) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(actualLines); i++ {\n\t\tif strings.TrimSpace(actualLines[i]) != strings.TrimSpace(expectedLines[i]) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc makeProto() (proto.Message, error) {\n\tvar rsp structpb.Value\n\terr := jsonpb.UnmarshalString(`{\n\t\t\"foo\": [\"abc\", \"def\", \"ghi\"],\n\t\t\"bar\": { \"a\": 1, \"b\": 2 },\n\t\t\"baz\": true,\n\t\t\"null\": null\n\t}`, &rsp)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &rsp, nil\n}\n\nvar (\n\tverbosePrefix = `\nResolved method descriptor:\nrpc GetFiles ( .TestRequest ) returns ( .TestResponse );\n\nRequest metadata to send:\nbar: 456\nfoo: 123\n\nResponse headers received:\nbar: def\nbaz: xyz\nfoo: abc\n`\n\tverboseSuffix = `\nResponse trailers received:\na: 1\nb: 2\nc: 3\n`\n\tverboseResponseSize = `\nEstimated response size: 100 bytes\n`\n\tverboseResponseHeader = `\nResponse contents:\n`\n\tmessageAsJSON = `{\n  \"bar\": {\n    \"a\": 1,\n    \"b\": 2\n  },\n  \"baz\": true,\n  \"foo\": [\n    \"abc\",\n    \"def\",\n    \"ghi\"\n  ],\n  \"null\": null\n}\n`\n\tmessageAsText = `struct_value: <\n  fields: <\n    key: \"bar\"\n    value: <\n      struct_value: <\n        fields: <\n          key: \"a\"\n          value: <\n            number_value: 1\n          >\n        >\n        fields: <\n          key: \"b\"\n          value: <\n            number_value: 2\n          >\n        >\n      >\n    >\n  >\n  fields: <\n    key: \"baz\"\n    value: <\n      bool_value: true\n    >\n  >\n  fields: <\n    key: \"foo\"\n    value: <\n      list_value: <\n        values: <\n          string_value: \"abc\"\n        >\n        values: <\n          string_value: \"def\"\n        >\n        values: <\n          string_value: \"ghi\"\n        >\n      >\n    >\n  >\n  fields: <\n    key: \"null\"\n    value: <\n      null_value: NULL_VALUE\n    >\n  >\n>\n`\n)\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.228515625,
          "content": "module github.com/fullstorydev/grpcurl\n\ngo 1.21\n\nrequire (\n\tgithub.com/golang/protobuf v1.5.4\n\tgithub.com/jhump/protoreflect v1.16.0\n\tgoogle.golang.org/grpc v1.61.0\n\tgoogle.golang.org/protobuf v1.34.2\n)\n\nrequire (\n\tcloud.google.com/go/compute v1.23.3 // indirect\n\tcloud.google.com/go/compute/metadata v0.2.3 // indirect\n\tgithub.com/bufbuild/protocompile v0.10.0 // indirect\n\tgithub.com/census-instrumentation/opencensus-proto v0.4.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/cncf/udpa/go v0.0.0-20220112060539-c52dc94e7fbe // indirect\n\tgithub.com/cncf/xds/go v0.0.0-20231109132714-523115ebc101 // indirect\n\tgithub.com/envoyproxy/go-control-plane v0.11.1 // indirect\n\tgithub.com/envoyproxy/protoc-gen-validate v1.0.2 // indirect\n\tgolang.org/x/net v0.23.0 // indirect\n\tgolang.org/x/oauth2 v0.14.0 // indirect\n\tgolang.org/x/sync v0.6.0 // indirect\n\tgolang.org/x/sys v0.18.0 // indirect\n\tgolang.org/x/text v0.14.0 // indirect\n\tgoogle.golang.org/appengine v1.6.8 // indirect\n\tgoogle.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17 // indirect\n\tgoogle.golang.org/genproto/googleapis/api v0.0.0-20231106174013-bbf56f31fb17 // indirect\n\tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 11.77734375,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go/compute v1.23.3 h1:6sVlXXBmbd7jNX0Ipq0trII3e4n1/MsADLK6a+aiVlk=\ncloud.google.com/go/compute v1.23.3/go.mod h1:VCgBUoMnIVIR0CscqQiPJLAG25E3ZRZMzcFZeQ+h8CI=\ncloud.google.com/go/compute/metadata v0.2.3 h1:mg4jlk7mCAj6xXp9UJ4fjI9VUI5rubuGBW5aJ7UnBMY=\ncloud.google.com/go/compute/metadata v0.2.3/go.mod h1:VAV5nSsACxMJvgaAuX6Pk2AawlZn8kiOGuCv6gTkwuA=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/bufbuild/protocompile v0.10.0 h1:+jW/wnLMLxaCEG8AX9lD0bQ5v9h1RUiMKOBOT5ll9dM=\ngithub.com/bufbuild/protocompile v0.10.0/go.mod h1:G9qQIQo0xZ6Uyj6CMNz0saGmx2so+KONo8/KrELABiY=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/census-instrumentation/opencensus-proto v0.4.1 h1:iKLQ0xPNFxR/2hzXZMrBo8f1j86j5WHzznCCQxV/b8g=\ngithub.com/census-instrumentation/opencensus-proto v0.4.1/go.mod h1:4T9NM4+4Vw91VeyqjLS6ao50K5bOcLKN6Q42XnYaRYw=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cncf/udpa/go v0.0.0-20220112060539-c52dc94e7fbe h1:QQ3GSy+MqSHxm/d8nCtnAiZdYFd45cYZPs8vOOIYKfk=\ngithub.com/cncf/udpa/go v0.0.0-20220112060539-c52dc94e7fbe/go.mod h1:6pvJx4me5XPnfI9Z40ddWsdw2W/uZgQLFXToKeRcDiI=\ngithub.com/cncf/xds/go v0.0.0-20210922020428-25de7278fc84/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cncf/xds/go v0.0.0-20231109132714-523115ebc101 h1:7To3pQ+pZo0i3dsWEbinPNFs5gPSBOsJtx3wTT94VBY=\ngithub.com/cncf/xds/go v0.0.0-20231109132714-523115ebc101/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.11.1 h1:wSUXTlLfiAQRWs2F+p+EKOY9rUyis1MyGqJ2DIk5HpM=\ngithub.com/envoyproxy/go-control-plane v0.11.1/go.mod h1:uhMcXKCQMEJHiAb0w+YGefQLaTEw+YhGluxZkrTmD0g=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/envoyproxy/protoc-gen-validate v1.0.2 h1:QkIBuU5k+x7/QXPvPPnWXWlCdaBFApVqftFV6k087DA=\ngithub.com/envoyproxy/protoc-gen-validate v1.0.2/go.mod h1:GpiZQP3dDbg4JouG/NNS7QWXpgx6x8QiMKdmN72jogE=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/uuid v1.4.0 h1:MtMxsa51/r9yyhkyLsVeVt0B+BGQZzpQiTQ4eHZ8bc4=\ngithub.com/google/uuid v1.4.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/jhump/protoreflect v1.16.0 h1:54fZg+49widqXYQ0b+usAFHbMkBGR4PpXrsHc8+TBDg=\ngithub.com/jhump/protoreflect v1.16.0/go.mod h1:oYPd7nPvcBw/5wlDfm/AVmU9zH9BgqGCI469pGxfj/8=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.23.0 h1:7EYJ93RZ9vYSZAIb2x3lnuvqO5zneoD6IvWjuhfxjTs=\ngolang.org/x/net v0.23.0/go.mod h1:JKghWKKOSdJwpW2GEx0Ja7fmaKnMsbu+MWVZTokSYmg=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.14.0 h1:P0Vrf/2538nmC0H+pEQ3MNFRRnVR7RlqyVw+bvm26z0=\ngolang.org/x/oauth2 v0.14.0/go.mod h1:lAtNWgaWfL4cm7j2OV8TxGi9Qb7ECORx8DktCY74OwM=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.6.0 h1:5BMeUDZ7vkXGfEr1x9B4bRcTH4lpkTkpdh0T/J+qjbQ=\ngolang.org/x/sync v0.6.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.18.0 h1:DBdB3niSjOA/O0blCZBqDefyWNYveAYMNF1Wum0DYQ4=\ngolang.org/x/sys v0.18.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.3.8/go.mod h1:E6s5w1FMmriuDzIBO73fBruAKo1PCIq6d2Q6DHfQ8WQ=\ngolang.org/x/text v0.14.0 h1:ScX5w1eTa3QqT8oi6+ziP7dTV1S2+ALU0bI+0zXKWiQ=\ngolang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.8 h1:IhEN5q69dyKagZPYMSdIjS2HqprW324FRQZJcGqPAsM=\ngoogle.golang.org/appengine v1.6.8/go.mod h1:1jJ3jBArFh5pcgW8gCtRJnepW8FzD1V44FJffLiz/Ds=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17 h1:wpZ8pe2x1Q3f2KyT5f8oP/fa9rHAKgFPr/HZdNuS+PQ=\ngoogle.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:J7XzRzVy1+IPwWHZUzoD0IccYZIrXILAQpc+Qy9CMhY=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20231106174013-bbf56f31fb17 h1:JpwMPBpFN3uKhdaekDpiNlImDdkUAyiJ6ez/uxGaUSo=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:0xJLfVdJqpAPl8tDg1ujOCGzx6LFLttXT5NhllGOXY4=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17 h1:Jyp0Hsi0bmHXG6k9eATXoYtjd6e2UzZ1SCn/wIupY14=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:oQ5rr10WTTMvP4A36n8JpR1OrO1BEiV4f78CneXZxkA=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.61.0 h1:TOvOcuXn30kRao+gfcvsebNEa5iZIiLkisYEkf7R7o0=\ngoogle.golang.org/grpc v1.61.0/go.mod h1:VUbo7IFqmF1QtCAstipjG0GIoq49KvMe9+h1jFLBNJs=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.34.2 h1:6xV6lTsCfpGD21XK49h7MhtcApnLqkfYgPcdHftf6hg=\ngoogle.golang.org/protobuf v1.34.2/go.mod h1:qYOHts0dSfpeUzUFpOMr/WGzszTmLH+DiWniOlNbLDw=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\n"
        },
        {
          "name": "grpcurl.go",
          "type": "blob",
          "size": 22.42578125,
          "content": "// Package grpcurl provides the core functionality exposed by the grpcurl command, for\n// dynamically connecting to a server, using the reflection service to inspect the server,\n// and invoking RPCs. The grpcurl command-line tool constructs a DescriptorSource, based\n// on the command-line parameters, and supplies an InvocationEventHandler to supply request\n// data (which can come from command-line args or the process's stdin) and to log the\n// events (to the process's stdout).\npackage grpcurl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/golang/protobuf/proto\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"github.com/jhump/protoreflect/desc/protoprint\"\n\t\"github.com/jhump/protoreflect/dynamic\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n\t\"google.golang.org/grpc/credentials/insecure\"\n\txdsCredentials \"google.golang.org/grpc/credentials/xds\"\n\t_ \"google.golang.org/grpc/health\" // import grpc/health to enable transparent client side checking\n\t\"google.golang.org/grpc/metadata\"\n\tprotov2 \"google.golang.org/protobuf/proto\"\n\t\"google.golang.org/protobuf/types/descriptorpb\"\n\t\"google.golang.org/protobuf/types/known/anypb\"\n\t\"google.golang.org/protobuf/types/known/emptypb\"\n\t\"google.golang.org/protobuf/types/known/structpb\"\n)\n\n// ListServices uses the given descriptor source to return a sorted list of fully-qualified\n// service names.\nfunc ListServices(source DescriptorSource) ([]string, error) {\n\tsvcs, err := source.ListServices()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsort.Strings(svcs)\n\treturn svcs, nil\n}\n\ntype sourceWithFiles interface {\n\tGetAllFiles() ([]*desc.FileDescriptor, error)\n}\n\nvar _ sourceWithFiles = (*fileSource)(nil)\n\n// GetAllFiles uses the given descriptor source to return a list of file descriptors.\nfunc GetAllFiles(source DescriptorSource) ([]*desc.FileDescriptor, error) {\n\tvar files []*desc.FileDescriptor\n\tsrcFiles, ok := source.(sourceWithFiles)\n\n\t// If an error occurs, we still try to load as many files as we can, so that\n\t// caller can decide whether to ignore error or not.\n\tvar firstError error\n\tif ok {\n\t\tfiles, firstError = srcFiles.GetAllFiles()\n\t} else {\n\t\t// Source does not implement GetAllFiles method, so use ListServices\n\t\t// and grab files from there.\n\t\tsvcNames, err := source.ListServices()\n\t\tif err != nil {\n\t\t\tfirstError = err\n\t\t} else {\n\t\t\tallFiles := map[string]*desc.FileDescriptor{}\n\t\t\tfor _, name := range svcNames {\n\t\t\t\td, err := source.FindSymbol(name)\n\t\t\t\tif err != nil {\n\t\t\t\t\tif firstError == nil {\n\t\t\t\t\t\tfirstError = err\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\taddAllFilesToSet(d.GetFile(), allFiles)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfiles = make([]*desc.FileDescriptor, len(allFiles))\n\t\t\ti := 0\n\t\t\tfor _, fd := range allFiles {\n\t\t\t\tfiles[i] = fd\n\t\t\t\ti++\n\t\t\t}\n\t\t}\n\t}\n\n\tsort.Sort(filesByName(files))\n\treturn files, firstError\n}\n\ntype filesByName []*desc.FileDescriptor\n\nfunc (f filesByName) Len() int {\n\treturn len(f)\n}\n\nfunc (f filesByName) Less(i, j int) bool {\n\treturn f[i].GetName() < f[j].GetName()\n}\n\nfunc (f filesByName) Swap(i, j int) {\n\tf[i], f[j] = f[j], f[i]\n}\n\nfunc addAllFilesToSet(fd *desc.FileDescriptor, all map[string]*desc.FileDescriptor) {\n\tif _, ok := all[fd.GetName()]; ok {\n\t\t// already added\n\t\treturn\n\t}\n\tall[fd.GetName()] = fd\n\tfor _, dep := range fd.GetDependencies() {\n\t\taddAllFilesToSet(dep, all)\n\t}\n}\n\n// ListMethods uses the given descriptor source to return a sorted list of method names\n// for the specified fully-qualified service name.\nfunc ListMethods(source DescriptorSource, serviceName string) ([]string, error) {\n\tdsc, err := source.FindSymbol(serviceName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif sd, ok := dsc.(*desc.ServiceDescriptor); !ok {\n\t\treturn nil, notFound(\"Service\", serviceName)\n\t} else {\n\t\tmethods := make([]string, 0, len(sd.GetMethods()))\n\t\tfor _, method := range sd.GetMethods() {\n\t\t\tmethods = append(methods, method.GetFullyQualifiedName())\n\t\t}\n\t\tsort.Strings(methods)\n\t\treturn methods, nil\n\t}\n}\n\n// MetadataFromHeaders converts a list of header strings (each string in\n// \"Header-Name: Header-Value\" form) into metadata. If a string has a header\n// name without a value (e.g. does not contain a colon), the value is assumed\n// to be blank. Binary headers (those whose names end in \"-bin\") should be\n// base64-encoded. But if they cannot be base64-decoded, they will be assumed to\n// be in raw form and used as is.\nfunc MetadataFromHeaders(headers []string) metadata.MD {\n\tmd := make(metadata.MD)\n\tfor _, part := range headers {\n\t\tif part != \"\" {\n\t\t\tpieces := strings.SplitN(part, \":\", 2)\n\t\t\tif len(pieces) == 1 {\n\t\t\t\tpieces = append(pieces, \"\") // if no value was specified, just make it \"\" (maybe the header value doesn't matter)\n\t\t\t}\n\t\t\theaderName := strings.ToLower(strings.TrimSpace(pieces[0]))\n\t\t\tval := strings.TrimSpace(pieces[1])\n\t\t\tif strings.HasSuffix(headerName, \"-bin\") {\n\t\t\t\tif v, err := decode(val); err == nil {\n\t\t\t\t\tval = v\n\t\t\t\t}\n\t\t\t}\n\t\t\tmd[headerName] = append(md[headerName], val)\n\t\t}\n\t}\n\treturn md\n}\n\nvar envVarRegex = regexp.MustCompile(`\\${\\w+}`)\n\n// ExpandHeaders expands environment variables contained in the header string.\n// If no corresponding environment variable is found an error is returned.\n// TODO: Add escaping for `${`\nfunc ExpandHeaders(headers []string) ([]string, error) {\n\texpandedHeaders := make([]string, len(headers))\n\tfor idx, header := range headers {\n\t\tif header == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tresults := envVarRegex.FindAllString(header, -1)\n\t\tif len(results) == 0 {\n\t\t\texpandedHeaders[idx] = headers[idx]\n\t\t\tcontinue\n\t\t}\n\t\texpandedHeader := header\n\t\tfor _, result := range results {\n\t\t\tenvVarName := result[2 : len(result)-1] // strip leading `${` and trailing `}`\n\t\t\tenvVarValue, ok := os.LookupEnv(envVarName)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"header %q refers to missing environment variable %q\", header, envVarName)\n\t\t\t}\n\t\t\texpandedHeader = strings.Replace(expandedHeader, result, envVarValue, -1)\n\t\t}\n\t\texpandedHeaders[idx] = expandedHeader\n\t}\n\treturn expandedHeaders, nil\n}\n\nvar base64Codecs = []*base64.Encoding{base64.StdEncoding, base64.URLEncoding, base64.RawStdEncoding, base64.RawURLEncoding}\n\nfunc decode(val string) (string, error) {\n\tvar firstErr error\n\tvar b []byte\n\t// we are lenient and can accept any of the flavors of base64 encoding\n\tfor _, d := range base64Codecs {\n\t\tvar err error\n\t\tb, err = d.DecodeString(val)\n\t\tif err != nil {\n\t\t\tif firstErr == nil {\n\t\t\t\tfirstErr = err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn string(b), nil\n\t}\n\treturn \"\", firstErr\n}\n\n// MetadataToString returns a string representation of the given metadata, for\n// displaying to users.\nfunc MetadataToString(md metadata.MD) string {\n\tif len(md) == 0 {\n\t\treturn \"(empty)\"\n\t}\n\n\tkeys := make([]string, 0, len(md))\n\tfor k := range md {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tvar b bytes.Buffer\n\tfirst := true\n\tfor _, k := range keys {\n\t\tvs := md[k]\n\t\tfor _, v := range vs {\n\t\t\tif first {\n\t\t\t\tfirst = false\n\t\t\t} else {\n\t\t\t\tb.WriteString(\"\\n\")\n\t\t\t}\n\t\t\tb.WriteString(k)\n\t\t\tb.WriteString(\": \")\n\t\t\tif strings.HasSuffix(k, \"-bin\") {\n\t\t\t\tv = base64.StdEncoding.EncodeToString([]byte(v))\n\t\t\t}\n\t\t\tb.WriteString(v)\n\t\t}\n\t}\n\treturn b.String()\n}\n\nvar printer = &protoprint.Printer{\n\tCompact:                  true,\n\tOmitComments:             protoprint.CommentsNonDoc,\n\tSortElements:             true,\n\tForceFullyQualifiedNames: true,\n}\n\n// GetDescriptorText returns a string representation of the given descriptor.\n// This returns a snippet of proto source that describes the given element.\nfunc GetDescriptorText(dsc desc.Descriptor, _ DescriptorSource) (string, error) {\n\t// Note: DescriptorSource is not used, but remains an argument for backwards\n\t// compatibility with previous implementation.\n\ttxt, err := printer.PrintProtoToString(dsc)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\t// callers don't expect trailing newlines\n\tif txt[len(txt)-1] == '\\n' {\n\t\ttxt = txt[:len(txt)-1]\n\t}\n\treturn txt, nil\n}\n\n// EnsureExtensions uses the given descriptor source to download extensions for\n// the given message. It returns a copy of the given message, but as a dynamic\n// message that knows about all extensions known to the given descriptor source.\nfunc EnsureExtensions(source DescriptorSource, msg proto.Message) proto.Message {\n\t// load any server extensions so we can properly describe custom options\n\tdsc, err := desc.LoadMessageDescriptorForMessage(msg)\n\tif err != nil {\n\t\treturn msg\n\t}\n\n\tvar ext dynamic.ExtensionRegistry\n\tif err = fetchAllExtensions(source, &ext, dsc, map[string]bool{}); err != nil {\n\t\treturn msg\n\t}\n\n\t// convert message into dynamic message that knows about applicable extensions\n\t// (that way we can show meaningful info for custom options instead of printing as unknown)\n\tmsgFactory := dynamic.NewMessageFactoryWithExtensionRegistry(&ext)\n\tdm, err := fullyConvertToDynamic(msgFactory, msg)\n\tif err != nil {\n\t\treturn msg\n\t}\n\treturn dm\n}\n\n// fetchAllExtensions recursively fetches from the server extensions for the given message type as well as\n// for all message types of nested fields. The extensions are added to the given dynamic registry of extensions\n// so that all server-known extensions can be correctly parsed by grpcurl.\nfunc fetchAllExtensions(source DescriptorSource, ext *dynamic.ExtensionRegistry, md *desc.MessageDescriptor, alreadyFetched map[string]bool) error {\n\tmsgTypeName := md.GetFullyQualifiedName()\n\tif alreadyFetched[msgTypeName] {\n\t\treturn nil\n\t}\n\talreadyFetched[msgTypeName] = true\n\tif len(md.GetExtensionRanges()) > 0 {\n\t\tfds, err := source.AllExtensionsForType(msgTypeName)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to query for extensions of type %s: %v\", msgTypeName, err)\n\t\t}\n\t\tfor _, fd := range fds {\n\t\t\tif err := ext.AddExtension(fd); err != nil {\n\t\t\t\treturn fmt.Errorf(\"could not register extension %s of type %s: %v\", fd.GetFullyQualifiedName(), msgTypeName, err)\n\t\t\t}\n\t\t}\n\t}\n\t// recursively fetch extensions for the types of any message fields\n\tfor _, fd := range md.GetFields() {\n\t\tif fd.GetMessageType() != nil {\n\t\t\terr := fetchAllExtensions(source, ext, fd.GetMessageType(), alreadyFetched)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// fullyConvertToDynamic attempts to convert the given message to a dynamic message as well\n// as any nested messages it may contain as field values. If the given message factory has\n// extensions registered that were not known when the given message was parsed, this effectively\n// allows re-parsing to identify those extensions.\nfunc fullyConvertToDynamic(msgFact *dynamic.MessageFactory, msg proto.Message) (proto.Message, error) {\n\tif _, ok := msg.(*dynamic.Message); ok {\n\t\treturn msg, nil // already a dynamic message\n\t}\n\tmd, err := desc.LoadMessageDescriptorForMessage(msg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnewMsg := msgFact.NewMessage(md)\n\tdm, ok := newMsg.(*dynamic.Message)\n\tif !ok {\n\t\t// if message factory didn't produce a dynamic message, then we should leave msg as is\n\t\treturn msg, nil\n\t}\n\n\tif err := dm.ConvertFrom(msg); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// recursively convert all field values, too\n\tfor _, fd := range md.GetFields() {\n\t\tif fd.IsMap() {\n\t\t\tif fd.GetMapValueType().GetMessageType() != nil {\n\t\t\t\tm := dm.GetField(fd).(map[interface{}]interface{})\n\t\t\t\tfor k, v := range m {\n\t\t\t\t\t// keys can't be nested messages; so we only need to recurse through map values, not keys\n\t\t\t\t\tnewVal, err := fullyConvertToDynamic(msgFact, v.(proto.Message))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tdm.PutMapField(fd, k, newVal)\n\t\t\t\t}\n\t\t\t}\n\t\t} else if fd.IsRepeated() {\n\t\t\tif fd.GetMessageType() != nil {\n\t\t\t\ts := dm.GetField(fd).([]interface{})\n\t\t\t\tfor i, e := range s {\n\t\t\t\t\tnewVal, err := fullyConvertToDynamic(msgFact, e.(proto.Message))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tdm.SetRepeatedField(fd, i, newVal)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif fd.GetMessageType() != nil {\n\t\t\t\tv := dm.GetField(fd)\n\t\t\t\tnewVal, err := fullyConvertToDynamic(msgFact, v.(proto.Message))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tdm.SetField(fd, newVal)\n\t\t\t}\n\t\t}\n\t}\n\treturn dm, nil\n}\n\n// MakeTemplate returns a message instance for the given descriptor that is a\n// suitable template for creating an instance of that message in JSON. In\n// particular, it ensures that any repeated fields (which include map fields)\n// are not empty, so they will render with a single element (to show the types\n// and optionally nested fields). It also ensures that nested messages are not\n// nil by setting them to a message that is also fleshed out as a template\n// message.\nfunc MakeTemplate(md *desc.MessageDescriptor) proto.Message {\n\treturn makeTemplate(md, nil)\n}\n\nfunc makeTemplate(md *desc.MessageDescriptor, path []*desc.MessageDescriptor) proto.Message {\n\tswitch md.GetFullyQualifiedName() {\n\tcase \"google.protobuf.Any\":\n\t\t// empty type URL is not allowed by JSON representation\n\t\t// so we must give it a dummy type\n\t\tvar anyVal anypb.Any\n\t\t_ = anypb.MarshalFrom(&anyVal, &emptypb.Empty{}, protov2.MarshalOptions{})\n\t\treturn &anyVal\n\tcase \"google.protobuf.Value\":\n\t\t// unset kind is not allowed by JSON representation\n\t\t// so we must give it something\n\t\treturn &structpb.Value{\n\t\t\tKind: &structpb.Value_StructValue{StructValue: &structpb.Struct{\n\t\t\t\tFields: map[string]*structpb.Value{\n\t\t\t\t\t\"google.protobuf.Value\": {Kind: &structpb.Value_StringValue{\n\t\t\t\t\t\tStringValue: \"supports arbitrary JSON\",\n\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t}},\n\t\t}\n\tcase \"google.protobuf.ListValue\":\n\t\treturn &structpb.ListValue{\n\t\t\tValues: []*structpb.Value{\n\t\t\t\t{\n\t\t\t\t\tKind: &structpb.Value_StructValue{StructValue: &structpb.Struct{\n\t\t\t\t\t\tFields: map[string]*structpb.Value{\n\t\t\t\t\t\t\t\"google.protobuf.ListValue\": {Kind: &structpb.Value_StringValue{\n\t\t\t\t\t\t\t\tStringValue: \"is an array of arbitrary JSON values\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\tcase \"google.protobuf.Struct\":\n\t\treturn &structpb.Struct{\n\t\t\tFields: map[string]*structpb.Value{\n\t\t\t\t\"google.protobuf.Struct\": {Kind: &structpb.Value_StringValue{\n\t\t\t\t\tStringValue: \"supports arbitrary JSON objects\",\n\t\t\t\t}},\n\t\t\t},\n\t\t}\n\t}\n\n\tdm := dynamic.NewMessage(md)\n\n\t// if the message is a recursive structure, we don't want to blow the stack\n\tfor _, seen := range path {\n\t\tif seen == md {\n\t\t\t// already visited this type; avoid infinite recursion\n\t\t\treturn dm\n\t\t}\n\t}\n\tpath = append(path, dm.GetMessageDescriptor())\n\n\t// for repeated fields, add a single element with default value\n\t// and for message fields, add a message with all default fields\n\t// that also has non-nil message and non-empty repeated fields\n\n\tfor _, fd := range dm.GetMessageDescriptor().GetFields() {\n\t\tif fd.IsRepeated() {\n\t\t\tswitch fd.GetType() {\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_FIXED32,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_UINT32:\n\t\t\t\tdm.AddRepeatedField(fd, uint32(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_SFIXED32,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_SINT32,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_INT32,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_ENUM:\n\t\t\t\tdm.AddRepeatedField(fd, int32(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_FIXED64,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_UINT64:\n\t\t\t\tdm.AddRepeatedField(fd, uint64(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_SFIXED64,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_SINT64,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_INT64:\n\t\t\t\tdm.AddRepeatedField(fd, int64(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_STRING:\n\t\t\t\tdm.AddRepeatedField(fd, \"\")\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_BYTES:\n\t\t\t\tdm.AddRepeatedField(fd, []byte{})\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_BOOL:\n\t\t\t\tdm.AddRepeatedField(fd, false)\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_FLOAT:\n\t\t\t\tdm.AddRepeatedField(fd, float32(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_DOUBLE:\n\t\t\t\tdm.AddRepeatedField(fd, float64(0))\n\n\t\t\tcase descriptorpb.FieldDescriptorProto_TYPE_MESSAGE,\n\t\t\t\tdescriptorpb.FieldDescriptorProto_TYPE_GROUP:\n\t\t\t\tdm.AddRepeatedField(fd, makeTemplate(fd.GetMessageType(), path))\n\t\t\t}\n\t\t} else if fd.GetMessageType() != nil {\n\t\t\tdm.SetField(fd, makeTemplate(fd.GetMessageType(), path))\n\t\t}\n\t}\n\treturn dm\n}\n\n// ClientTransportCredentials is a helper function that constructs a TLS config with\n// the given properties (see ClientTLSConfig) and then constructs and returns gRPC\n// transport credentials using that config.\n//\n// Deprecated: Use grpcurl.ClientTLSConfig and credentials.NewTLS instead.\nfunc ClientTransportCredentials(insecureSkipVerify bool, cacertFile, clientCertFile, clientKeyFile string) (credentials.TransportCredentials, error) {\n\ttlsConf, err := ClientTLSConfig(insecureSkipVerify, cacertFile, clientCertFile, clientKeyFile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn credentials.NewTLS(tlsConf), nil\n}\n\n// ClientTLSConfig builds transport-layer config for a gRPC client using the\n// given properties. If cacertFile is blank, only standard trusted certs are used to\n// verify the server certs. If clientCertFile is blank, the client will not use a client\n// certificate. If clientCertFile is not blank then clientKeyFile must not be blank.\nfunc ClientTLSConfig(insecureSkipVerify bool, cacertFile, clientCertFile, clientKeyFile string) (*tls.Config, error) {\n\tvar tlsConf tls.Config\n\n\tif clientCertFile != \"\" {\n\t\t// Load the client certificates from disk\n\t\tcertificate, err := tls.LoadX509KeyPair(clientCertFile, clientKeyFile)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not load client key pair: %v\", err)\n\t\t}\n\t\ttlsConf.Certificates = []tls.Certificate{certificate}\n\t}\n\n\tif insecureSkipVerify {\n\t\ttlsConf.InsecureSkipVerify = true\n\t} else if cacertFile != \"\" {\n\t\t// Create a certificate pool from the certificate authority\n\t\tcertPool := x509.NewCertPool()\n\t\tca, err := os.ReadFile(cacertFile)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not read ca certificate: %v\", err)\n\t\t}\n\n\t\t// Append the certificates from the CA\n\t\tif ok := certPool.AppendCertsFromPEM(ca); !ok {\n\t\t\treturn nil, errors.New(\"failed to append ca certs\")\n\t\t}\n\n\t\ttlsConf.RootCAs = certPool\n\t}\n\n\treturn &tlsConf, nil\n}\n\n// ServerTransportCredentials builds transport credentials for a gRPC server using the\n// given properties. If cacertFile is blank, the server will not request client certs\n// unless requireClientCerts is true. When requireClientCerts is false and cacertFile is\n// not blank, the server will verify client certs when presented, but will not require\n// client certs. The serverCertFile and serverKeyFile must both not be blank.\nfunc ServerTransportCredentials(cacertFile, serverCertFile, serverKeyFile string, requireClientCerts bool) (credentials.TransportCredentials, error) {\n\tvar tlsConf tls.Config\n\t// TODO(jh): Remove this line once https://github.com/golang/go/issues/28779 is fixed\n\t// in Go tip. Until then, the recently merged TLS 1.3 support breaks the TLS tests.\n\ttlsConf.MaxVersion = tls.VersionTLS12\n\n\t// Load the server certificates from disk\n\tcertificate, err := tls.LoadX509KeyPair(serverCertFile, serverKeyFile)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"could not load key pair: %v\", err)\n\t}\n\ttlsConf.Certificates = []tls.Certificate{certificate}\n\n\tif cacertFile != \"\" {\n\t\t// Create a certificate pool from the certificate authority\n\t\tcertPool := x509.NewCertPool()\n\t\tca, err := os.ReadFile(cacertFile)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not read ca certificate: %v\", err)\n\t\t}\n\n\t\t// Append the certificates from the CA\n\t\tif ok := certPool.AppendCertsFromPEM(ca); !ok {\n\t\t\treturn nil, errors.New(\"failed to append ca certs\")\n\t\t}\n\n\t\ttlsConf.ClientCAs = certPool\n\t}\n\n\tif requireClientCerts {\n\t\ttlsConf.ClientAuth = tls.RequireAndVerifyClientCert\n\t} else if cacertFile != \"\" {\n\t\ttlsConf.ClientAuth = tls.VerifyClientCertIfGiven\n\t} else {\n\t\ttlsConf.ClientAuth = tls.NoClientCert\n\t}\n\n\treturn credentials.NewTLS(&tlsConf), nil\n}\n\n// BlockingDial is a helper method to dial the given address, using optional TLS credentials,\n// and blocking until the returned connection is ready. If the given credentials are nil, the\n// connection will be insecure (plain-text).\nfunc BlockingDial(ctx context.Context, network, address string, creds credentials.TransportCredentials, opts ...grpc.DialOption) (*grpc.ClientConn, error) {\n\tif creds == nil {\n\t\tcreds = insecure.NewCredentials()\n\t}\n\n\tvar err error\n\tif strings.HasPrefix(address, \"xds:///\") {\n\t\t// The xds:/// prefix is used to signal to the gRPC client to use an xDS server to resolve the\n\t\t// target. The relevant credentials will be automatically pulled from the GRPC_XDS_BOOTSTRAP or\n\t\t// GRPC_XDS_BOOTSTRAP_CONFIG env vars.\n\t\tcreds, err = xdsCredentials.NewClientCredentials(xdsCredentials.ClientOptions{FallbackCreds: creds})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// grpc.Dial doesn't provide any information on permanent connection errors (like\n\t// TLS handshake failures). So in order to provide good error messages, we need a\n\t// custom dialer that can provide that info. That means we manage the TLS handshake.\n\tresult := make(chan interface{}, 1)\n\n\twriteResult := func(res interface{}) {\n\t\t// non-blocking write: we only need the first result\n\t\tselect {\n\t\tcase result <- res:\n\t\tdefault:\n\t\t}\n\t}\n\n\t// custom credentials and dialer will notify on error via the\n\t// writeResult function\n\tcreds = &errSignalingCreds{\n\t\tTransportCredentials: creds,\n\t\twriteResult:          writeResult,\n\t}\n\n\t// Even with grpc.FailOnNonTempDialError, this call will usually timeout in\n\t// the face of TLS handshake errors. So we can't rely on grpc.WithBlock() to\n\t// know when we're done. So we run it in a goroutine and then use result\n\t// channel to either get the connection or fail-fast.\n\tgo func() {\n\t\t// We put grpc.FailOnNonTempDialError *before* the explicitly provided\n\t\t// options so that it could be overridden.\n\t\topts = append([]grpc.DialOption{grpc.FailOnNonTempDialError(true)}, opts...)\n\t\t// But we don't want caller to be able to override these two, so we put\n\t\t// them *after* the explicitly provided options.\n\t\topts = append(opts, grpc.WithBlock(), grpc.WithTransportCredentials(creds))\n\n\t\tconn, err := grpc.DialContext(ctx, address, opts...)\n\t\tvar res interface{}\n\t\tif err != nil {\n\t\t\tres = err\n\t\t} else {\n\t\t\tres = conn\n\t\t}\n\t\twriteResult(res)\n\t}()\n\n\tselect {\n\tcase res := <-result:\n\t\tif conn, ok := res.(*grpc.ClientConn); ok {\n\t\t\treturn conn, nil\n\t\t}\n\t\treturn nil, res.(error)\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\t}\n}\n\n// errSignalingCreds is a wrapper around a TransportCredentials value, but\n// it will use the writeResult function to notify on error.\ntype errSignalingCreds struct {\n\tcredentials.TransportCredentials\n\twriteResult func(res interface{})\n}\n\nfunc (c *errSignalingCreds) ClientHandshake(ctx context.Context, addr string, rawConn net.Conn) (net.Conn, credentials.AuthInfo, error) {\n\tconn, auth, err := c.TransportCredentials.ClientHandshake(ctx, addr, rawConn)\n\tif err != nil {\n\t\tc.writeResult(err)\n\t}\n\treturn conn, auth, err\n}\n"
        },
        {
          "name": "grpcurl_test.go",
          "type": "blob",
          "size": 28.734375,
          "content": "package grpcurl_test\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/golang/protobuf/jsonpb\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/golang/protobuf/proto\"  //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"github.com/jhump/protoreflect/grpcreflect\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/credentials/insecure\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/reflection\"\n\t\"google.golang.org/grpc/status\"\n\n\t. \"github.com/fullstorydev/grpcurl\"\n\tgrpcurl_testing \"github.com/fullstorydev/grpcurl/internal/testing\"\n\tjsonpbtest \"github.com/fullstorydev/grpcurl/internal/testing/jsonpb_test_proto\"\n)\n\nvar (\n\tsourceProtoset   DescriptorSource\n\tsourceProtoFiles DescriptorSource\n\tccNoReflect      *grpc.ClientConn\n\n\tsourceReflect DescriptorSource\n\tccReflect     *grpc.ClientConn\n\n\tdescSources []descSourceCase\n)\n\ntype descSourceCase struct {\n\tname        string\n\tsource      DescriptorSource\n\tincludeRefl bool\n}\n\n// NB: These tests intentionally use the deprecated InvokeRpc since that\n// calls the other (non-deprecated InvokeRPC). That allows the tests to\n// easily exercise both functions.\n\nfunc TestMain(m *testing.M) {\n\tvar err error\n\tsourceProtoset, err = DescriptorSourceFromProtoSets(\"internal/testing/test.protoset\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tsourceProtoFiles, err = DescriptorSourceFromProtoFiles([]string{\"internal/testing\"}, \"test.proto\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Create a server that includes the reflection service\n\tsvrReflect := grpc.NewServer()\n\tgrpcurl_testing.RegisterTestServiceServer(svrReflect, grpcurl_testing.TestServer{})\n\treflection.Register(svrReflect)\n\tvar portReflect int\n\tif l, err := net.Listen(\"tcp\", \"127.0.0.1:0\"); err != nil {\n\t\tpanic(err)\n\t} else {\n\t\tportReflect = l.Addr().(*net.TCPAddr).Port\n\t\tgo svrReflect.Serve(l)\n\t}\n\tdefer svrReflect.Stop()\n\n\t// And a corresponding client\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\tif ccReflect, err = grpc.DialContext(ctx, fmt.Sprintf(\"127.0.0.1:%d\", portReflect),\n\t\tgrpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithBlock()); err != nil {\n\t\tpanic(err)\n\t}\n\tdefer ccReflect.Close()\n\trefClient := grpcreflect.NewClientAuto(context.Background(), ccReflect)\n\tdefer refClient.Reset()\n\n\tsourceReflect = DescriptorSourceFromServer(context.Background(), refClient)\n\n\t// Also create a server that does *not* include the reflection service\n\tsvrProtoset := grpc.NewServer()\n\tgrpcurl_testing.RegisterTestServiceServer(svrProtoset, grpcurl_testing.TestServer{})\n\tvar portProtoset int\n\tif l, err := net.Listen(\"tcp\", \"127.0.0.1:0\"); err != nil {\n\t\tpanic(err)\n\t} else {\n\t\tportProtoset = l.Addr().(*net.TCPAddr).Port\n\t\tgo svrProtoset.Serve(l)\n\t}\n\tdefer svrProtoset.Stop()\n\n\t// And a corresponding client\n\tctx, cancel = context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\tif ccNoReflect, err = grpc.DialContext(ctx, fmt.Sprintf(\"127.0.0.1:%d\", portProtoset),\n\t\tgrpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithBlock()); err != nil {\n\t\tpanic(err)\n\t}\n\tdefer ccNoReflect.Close()\n\n\tdescSources = []descSourceCase{\n\t\t{\"protoset\", sourceProtoset, false},\n\t\t{\"proto\", sourceProtoFiles, false},\n\t\t{\"reflect\", sourceReflect, true},\n\t}\n\n\tos.Exit(m.Run())\n}\n\nfunc TestServerDoesNotSupportReflection(t *testing.T) {\n\trefClient := grpcreflect.NewClientAuto(context.Background(), ccNoReflect)\n\tdefer refClient.Reset()\n\n\trefSource := DescriptorSourceFromServer(context.Background(), refClient)\n\n\t_, err := ListServices(refSource)\n\tif err != ErrReflectionNotSupported {\n\t\tt.Errorf(\"ListServices should have returned ErrReflectionNotSupported; instead got %v\", err)\n\t}\n\n\t_, err = ListMethods(refSource, \"SomeService\")\n\tif err != ErrReflectionNotSupported {\n\t\tt.Errorf(\"ListMethods should have returned ErrReflectionNotSupported; instead got %v\", err)\n\t}\n\n\terr = InvokeRpc(context.Background(), refSource, ccNoReflect, \"FooService/Method\", nil, nil, nil)\n\t// InvokeRpc wraps the error, so we just verify the returned error includes the right message\n\tif err == nil || !strings.Contains(err.Error(), ErrReflectionNotSupported.Error()) {\n\t\tt.Errorf(\"InvokeRpc should have returned ErrReflectionNotSupported; instead got %v\", err)\n\t}\n}\n\nfunc TestProtosetWithImports(t *testing.T) {\n\tsourceProtoset, err := DescriptorSourceFromProtoSets(\"internal/testing/example.protoset\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to load protoset: %v\", err)\n\t}\n\t// really shallow check of the loaded descriptors\n\tif sd, err := sourceProtoset.FindSymbol(\"TestService\"); err != nil {\n\t\tt.Errorf(\"failed to find TestService in protoset: %v\", err)\n\t} else if sd == nil {\n\t\tt.Errorf(\"FindSymbol returned nil for TestService\")\n\t} else if _, ok := sd.(*desc.ServiceDescriptor); !ok {\n\t\tt.Errorf(\"FindSymbol returned wrong kind of descriptor for TestService: %T\", sd)\n\t}\n\tif md, err := sourceProtoset.FindSymbol(\"TestRequest\"); err != nil {\n\t\tt.Errorf(\"failed to find TestRequest in protoset: %v\", err)\n\t} else if md == nil {\n\t\tt.Errorf(\"FindSymbol returned nil for TestRequest\")\n\t} else if _, ok := md.(*desc.MessageDescriptor); !ok {\n\t\tt.Errorf(\"FindSymbol returned wrong kind of descriptor for TestRequest: %T\", md)\n\t}\n}\n\nfunc TestListServices(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestListServices(t, ds.source, ds.includeRefl)\n\t\t})\n\t}\n}\n\nfunc doTestListServices(t *testing.T, source DescriptorSource, includeReflection bool) {\n\tnames, err := ListServices(source)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to list services: %v\", err)\n\t}\n\tvar expected []string\n\tif includeReflection {\n\t\t// when using server reflection, we see the TestService as well as the ServerReflection service\n\t\texpected = []string{\"grpc.reflection.v1.ServerReflection\", \"grpc.reflection.v1alpha.ServerReflection\", \"testing.TestService\"}\n\t} else {\n\t\t// without reflection, we see all services defined in the same test.proto file, which is the\n\t\t// TestService as well as UnimplementedService\n\t\texpected = []string{\"testing.TestService\", \"testing.UnimplementedService\"}\n\t}\n\tif !reflect.DeepEqual(expected, names) {\n\t\tt.Errorf(\"ListServices returned wrong results: wanted %v, got %v\", expected, names)\n\t}\n}\n\nfunc TestListMethods(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestListMethods(t, ds.source, ds.includeRefl)\n\t\t})\n\t}\n}\n\nfunc doTestListMethods(t *testing.T, source DescriptorSource, includeReflection bool) {\n\tnames, err := ListMethods(source, \"testing.TestService\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to list methods for TestService: %v\", err)\n\t}\n\texpected := []string{\n\t\t\"testing.TestService.EmptyCall\",\n\t\t\"testing.TestService.FullDuplexCall\",\n\t\t\"testing.TestService.HalfDuplexCall\",\n\t\t\"testing.TestService.StreamingInputCall\",\n\t\t\"testing.TestService.StreamingOutputCall\",\n\t\t\"testing.TestService.UnaryCall\",\n\t}\n\tif !reflect.DeepEqual(expected, names) {\n\t\tt.Errorf(\"ListMethods returned wrong results: wanted %v, got %v\", expected, names)\n\t}\n\n\tif includeReflection {\n\t\t// when using server reflection, we see the TestService as well as the ServerReflection service\n\t\tnames, err = ListMethods(source, \"grpc.reflection.v1.ServerReflection\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to list methods for ServerReflection: %v\", err)\n\t\t}\n\t\texpected = []string{\"grpc.reflection.v1.ServerReflection.ServerReflectionInfo\"}\n\t} else {\n\t\t// without reflection, we see all services defined in the same test.proto file, which is the\n\t\t// TestService as well as UnimplementedService\n\t\tnames, err = ListMethods(source, \"testing.UnimplementedService\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to list methods for ServerReflection: %v\", err)\n\t\t}\n\t\texpected = []string{\"testing.UnimplementedService.UnimplementedCall\"}\n\t}\n\tif !reflect.DeepEqual(expected, names) {\n\t\tt.Errorf(\"ListMethods returned wrong results: wanted %v, got %v\", expected, names)\n\t}\n\n\t// force an error\n\t_, err = ListMethods(source, \"FooService\")\n\tif err != nil && !strings.Contains(err.Error(), \"Symbol not found: FooService\") {\n\t\tt.Errorf(\"ListMethods should have returned 'not found' error but instead returned %v\", err)\n\t}\n}\n\nfunc TestGetAllFiles(t *testing.T) {\n\texpectedFiles := []string{\"test.proto\"}\n\texpectedFilesWithReflection := []string{\n\t\t\"grpc/reflection/v1/reflection.proto\", \"grpc/reflection/v1alpha/reflection.proto\", \"test.proto\",\n\t}\n\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tfiles, err := GetAllFiles(ds.source)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to get all files: %v\", err)\n\t\t\t}\n\t\t\tnames := fileNames(files)\n\t\t\tmatch := false\n\t\t\tvar expected []string\n\t\t\tif ds.includeRefl {\n\t\t\t\texpected = expectedFilesWithReflection\n\t\t\t} else {\n\t\t\t\texpected = expectedFiles\n\t\t\t}\n\t\t\tmatch = reflect.DeepEqual(expected, names)\n\t\t\tif !match {\n\t\t\t\tt.Errorf(\"GetAllFiles returned wrong results: wanted %v, got %v\", expected, names)\n\t\t\t}\n\t\t})\n\t}\n\n\t// try cases with more complicated set of files\n\totherSourceProtoset, err := DescriptorSourceFromProtoSets(\"internal/testing/test.protoset\", \"internal/testing/example.protoset\")\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\totherSourceProtoFiles, err := DescriptorSourceFromProtoFiles([]string{\"internal/testing\"}, \"test.proto\", \"example.proto\")\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\totherDescSources := []descSourceCase{\n\t\t{\"protoset[b]\", otherSourceProtoset, false},\n\t\t{\"proto[b]\", otherSourceProtoFiles, false},\n\t}\n\texpectedFiles = []string{\n\t\t\"example.proto\",\n\t\t\"example2.proto\",\n\t\t\"google/protobuf/any.proto\",\n\t\t\"google/protobuf/descriptor.proto\",\n\t\t\"google/protobuf/empty.proto\",\n\t\t\"google/protobuf/timestamp.proto\",\n\t\t\"test.proto\",\n\t}\n\tfor _, ds := range otherDescSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tfiles, err := GetAllFiles(ds.source)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to get all files: %v\", err)\n\t\t\t}\n\t\t\tnames := fileNames(files)\n\t\t\tif !reflect.DeepEqual(expectedFiles, names) {\n\t\t\t\tt.Errorf(\"GetAllFiles returned wrong results: wanted %v, got %v\", expectedFiles, names)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestExpandHeaders(t *testing.T) {\n\tinHeaders := []string{\"key1: ${value}\", \"key2: bar\", \"key3: ${woo\", \"key4: woo}\", \"key5: ${TEST}\",\n\t\t\"key6: ${TEST_VAR}\", \"${TEST}: ${TEST_VAR}\", \"key8: ${EMPTY}\"}\n\tos.Setenv(\"value\", \"value\")\n\tos.Setenv(\"TEST\", \"value5\")\n\tos.Setenv(\"TEST_VAR\", \"value6\")\n\tos.Setenv(\"EMPTY\", \"\")\n\texpectedHeaders := map[string]bool{\"key1: value\": true, \"key2: bar\": true, \"key3: ${woo\": true, \"key4: woo}\": true,\n\t\t\"key5: value5\": true, \"key6: value6\": true, \"value5: value6\": true, \"key8: \": true}\n\n\toutHeaders, err := ExpandHeaders(inHeaders)\n\tif err != nil {\n\t\tt.Errorf(\"The ExpandHeaders function generated an unexpected error %s\", err)\n\t}\n\tfor _, expandedHeader := range outHeaders {\n\t\tif _, ok := expectedHeaders[expandedHeader]; !ok {\n\t\t\tt.Errorf(\"The ExpandHeaders function has returned an unexpected header. Received unexpected header %s\", expandedHeader)\n\t\t}\n\t}\n\n\tbadHeaders := []string{\"key: ${DNE}\"}\n\t_, err = ExpandHeaders(badHeaders)\n\tif err == nil {\n\t\tt.Errorf(\"The ExpandHeaders function should return an error for missing environment variables %q\", badHeaders)\n\t}\n}\n\nfunc fileNames(files []*desc.FileDescriptor) []string {\n\tnames := make([]string, len(files))\n\tfor i, f := range files {\n\t\tnames[i] = f.GetName()\n\t}\n\treturn names\n}\n\nconst expectKnownType = `{\n  \"dur\": \"0s\",\n  \"ts\": \"1970-01-01T00:00:00Z\",\n  \"dbl\": 0,\n  \"flt\": 0,\n  \"i64\": \"0\",\n  \"u64\": \"0\",\n  \"i32\": 0,\n  \"u32\": 0,\n  \"bool\": false,\n  \"str\": \"\",\n  \"bytes\": null,\n  \"st\": {\"google.protobuf.Struct\": \"supports arbitrary JSON objects\"},\n  \"an\": {\"@type\": \"type.googleapis.com/google.protobuf.Empty\", \"value\": {}},\n  \"lv\": [{\"google.protobuf.ListValue\": \"is an array of arbitrary JSON values\"}],\n  \"val\": {\"google.protobuf.Value\": \"supports arbitrary JSON\"}\n}`\n\nfunc TestMakeTemplateKnownTypes(t *testing.T) {\n\tdescriptor, err := desc.LoadMessageDescriptorForMessage((*jsonpbtest.KnownTypes)(nil))\n\tif err != nil {\n\t\tt.Fatalf(\"failed to load descriptor: %v\", err)\n\t}\n\tmessage := MakeTemplate(descriptor)\n\n\tjsm := jsonpb.Marshaler{EmitDefaults: true}\n\tout, err := jsm.MarshalToString(message)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to marshal to JSON: %v\", err)\n\t}\n\n\t// make sure template JSON matches expected\n\tvar actual, expected interface{}\n\tif err := json.Unmarshal([]byte(out), &actual); err != nil {\n\t\tt.Fatalf(\"failed to parse actual JSON: %v\", err)\n\t}\n\tif err := json.Unmarshal([]byte(expectKnownType), &expected); err != nil {\n\t\tt.Fatalf(\"failed to parse expected JSON: %v\", err)\n\t}\n\n\tif !reflect.DeepEqual(actual, expected) {\n\t\tt.Errorf(\"template message is not as expected; want:\\n%s\\ngot:\\n%s\", expectKnownType, out)\n\t}\n}\n\nfunc TestDescribe(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestDescribe(t, ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestDescribe(t *testing.T, source DescriptorSource) {\n\tsym := \"testing.TestService.EmptyCall\"\n\tdsc, err := source.FindSymbol(sym)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to get descriptor for %q: %v\", sym, err)\n\t}\n\tif _, ok := dsc.(*desc.MethodDescriptor); !ok {\n\t\tt.Fatalf(\"descriptor for %q was a %T (expecting a MethodDescriptor)\", sym, dsc)\n\t}\n\ttxt := proto.MarshalTextString(dsc.AsProto())\n\texpected :=\n\t\t`name: \"EmptyCall\"\ninput_type: \".testing.Empty\"\noutput_type: \".testing.Empty\"\n`\n\tif expected != txt {\n\t\tt.Errorf(\"descriptor mismatch: expected %s, got %s\", expected, txt)\n\t}\n\n\tsym = \"testing.StreamingOutputCallResponse\"\n\tdsc, err = source.FindSymbol(sym)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to get descriptor for %q: %v\", sym, err)\n\t}\n\tif _, ok := dsc.(*desc.MessageDescriptor); !ok {\n\t\tt.Fatalf(\"descriptor for %q was a %T (expecting a MessageDescriptor)\", sym, dsc)\n\t}\n\ttxt = proto.MarshalTextString(dsc.AsProto())\n\texpected =\n\t\t`name: \"StreamingOutputCallResponse\"\nfield: <\n  name: \"payload\"\n  number: 1\n  label: LABEL_OPTIONAL\n  type: TYPE_MESSAGE\n  type_name: \".testing.Payload\"\n  json_name: \"payload\"\n>\n`\n\tif expected != txt {\n\t\tt.Errorf(\"descriptor mismatch: expected %s, got %s\", expected, txt)\n\t}\n\n\t_, err = source.FindSymbol(\"FooService\")\n\tif err != nil && !strings.Contains(err.Error(), \"Symbol not found: FooService\") {\n\t\tt.Errorf(\"FindSymbol should have returned 'not found' error but instead returned %v\", err)\n\t}\n}\n\nconst (\n\t// type == COMPRESSABLE, but that is default (since it has\n\t// numeric value == 0) and thus doesn't actually get included\n\t// on the wire\n\tpayload1 = `{\n  \"payload\": {\n    \"body\": \"SXQncyBCdXNpbmVzcyBUaW1l\"\n  }\n}`\n\tpayload2 = `{\n  \"payload\": {\n    \"type\": \"RANDOM\",\n    \"body\": \"Rm91eCBkdSBGYUZh\"\n  }\n}`\n\tpayload3 = `{\n  \"payload\": {\n    \"type\": \"UNCOMPRESSABLE\",\n    \"body\": \"SGlwaG9wb3BvdGFtdXMgdnMuIFJoeW1lbm9jZXJvcw==\"\n  }\n}`\n)\n\nfunc getCC(includeRefl bool) *grpc.ClientConn {\n\tif includeRefl {\n\t\treturn ccReflect\n\t} else {\n\t\treturn ccNoReflect\n\t}\n}\n\nfunc TestUnary(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestUnary(t, getCC(ds.includeRefl), ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestUnary(t *testing.T, cc *grpc.ClientConn, source DescriptorSource) {\n\t// Success\n\th := &handler{reqMessages: []string{payload1}}\n\terr := InvokeRpc(context.Background(), source, cc, \"testing.TestService/UnaryCall\", makeHeaders(codes.OK), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\tif h.check(t, \"testing.TestService.UnaryCall\", codes.OK, 1, 1) {\n\t\tif h.respMessages[0] != payload1 {\n\t\t\tt.Errorf(\"unexpected response from RPC: expecting %s; got %s\", payload1, h.respMessages[0])\n\t\t}\n\t}\n\n\t// Failure\n\th = &handler{reqMessages: []string{payload1}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/UnaryCall\", makeHeaders(codes.NotFound), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.UnaryCall\", codes.NotFound, 1, 0)\n}\n\nfunc TestClientStream(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestClientStream(t, getCC(ds.includeRefl), ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestClientStream(t *testing.T, cc *grpc.ClientConn, source DescriptorSource) {\n\t// Success\n\th := &handler{reqMessages: []string{payload1, payload2, payload3}}\n\terr := InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingInputCall\", makeHeaders(codes.OK), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\tif h.check(t, \"testing.TestService.StreamingInputCall\", codes.OK, 3, 1) {\n\t\texpected :=\n\t\t\t`{\n  \"aggregatedPayloadSize\": 61\n}`\n\t\tif h.respMessages[0] != expected {\n\t\t\tt.Errorf(\"unexpected response from RPC: expecting %s; got %s\", expected, h.respMessages[0])\n\t\t}\n\t}\n\n\t// Fail fast (server rejects as soon as possible)\n\th = &handler{reqMessages: []string{payload1, payload2, payload3}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingInputCall\", makeHeaders(codes.InvalidArgument), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.StreamingInputCall\", codes.InvalidArgument, -3, 0)\n\n\t// Fail late (server waits until stream is complete to reject)\n\th = &handler{reqMessages: []string{payload1, payload2, payload3}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingInputCall\", makeHeaders(codes.Internal, true), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.StreamingInputCall\", codes.Internal, 3, 0)\n}\n\nfunc TestServerStream(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestServerStream(t, getCC(ds.includeRefl), ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestServerStream(t *testing.T, cc *grpc.ClientConn, source DescriptorSource) {\n\treq := &grpcurl_testing.StreamingOutputCallRequest{\n\t\tResponseType: grpcurl_testing.PayloadType_COMPRESSABLE,\n\t\tResponseParameters: []*grpcurl_testing.ResponseParameters{\n\t\t\t{Size: 10}, {Size: 20}, {Size: 30}, {Size: 40}, {Size: 50},\n\t\t},\n\t}\n\tpayload, err := (&jsonpb.Marshaler{}).MarshalToString(req)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to construct request: %v\", err)\n\t}\n\n\t// Success\n\th := &handler{reqMessages: []string{payload}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingOutputCall\", makeHeaders(codes.OK), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\tif h.check(t, \"testing.TestService.StreamingOutputCall\", codes.OK, 1, 5) {\n\t\tresp := &grpcurl_testing.StreamingOutputCallResponse{}\n\t\tfor i, msg := range h.respMessages {\n\t\t\tif err := jsonpb.UnmarshalString(msg, resp); err != nil {\n\t\t\t\tt.Errorf(\"failed to parse response %d: %v\", i+1, err)\n\t\t\t}\n\t\t\tif resp.Payload.GetType() != grpcurl_testing.PayloadType_COMPRESSABLE {\n\t\t\t\tt.Errorf(\"response %d has wrong payload type; expecting %v, got %v\", i, grpcurl_testing.PayloadType_COMPRESSABLE, resp.Payload.Type)\n\t\t\t}\n\t\t\tif len(resp.Payload.Body) != (i+1)*10 {\n\t\t\t\tt.Errorf(\"response %d has wrong payload size; expecting %d, got %d\", i, (i+1)*10, len(resp.Payload.Body))\n\t\t\t}\n\t\t\tresp.Reset()\n\t\t}\n\t}\n\n\t// Fail fast (server rejects as soon as possible)\n\th = &handler{reqMessages: []string{payload}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingOutputCall\", makeHeaders(codes.Aborted), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.StreamingOutputCall\", codes.Aborted, 1, 0)\n\n\t// Fail late (server waits until stream is complete to reject)\n\th = &handler{reqMessages: []string{payload}}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/StreamingOutputCall\", makeHeaders(codes.AlreadyExists, true), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.StreamingOutputCall\", codes.AlreadyExists, 1, 5)\n}\n\nfunc TestHalfDuplexStream(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestHalfDuplexStream(t, getCC(ds.includeRefl), ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestHalfDuplexStream(t *testing.T, cc *grpc.ClientConn, source DescriptorSource) {\n\treqs := []string{payload1, payload2, payload3}\n\n\t// Success\n\th := &handler{reqMessages: reqs}\n\terr := InvokeRpc(context.Background(), source, cc, \"testing.TestService/HalfDuplexCall\", makeHeaders(codes.OK), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\tif h.check(t, \"testing.TestService.HalfDuplexCall\", codes.OK, 3, 3) {\n\t\tfor i, resp := range h.respMessages {\n\t\t\tif resp != reqs[i] {\n\t\t\t\tt.Errorf(\"unexpected response %d from RPC:\\nexpecting %q\\ngot %q\", i, reqs[i], resp)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Fail fast (server rejects as soon as possible)\n\th = &handler{reqMessages: reqs}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/HalfDuplexCall\", makeHeaders(codes.Canceled), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.HalfDuplexCall\", codes.Canceled, -3, 0)\n\n\t// Fail late (server waits until stream is complete to reject)\n\th = &handler{reqMessages: reqs}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/HalfDuplexCall\", makeHeaders(codes.DataLoss, true), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.HalfDuplexCall\", codes.DataLoss, 3, 3)\n}\n\nfunc TestFullDuplexStream(t *testing.T) {\n\tfor _, ds := range descSources {\n\t\tt.Run(ds.name, func(t *testing.T) {\n\t\t\tdoTestFullDuplexStream(t, getCC(ds.includeRefl), ds.source)\n\t\t})\n\t}\n}\n\nfunc doTestFullDuplexStream(t *testing.T, cc *grpc.ClientConn, source DescriptorSource) {\n\treqs := make([]string, 3)\n\treq := &grpcurl_testing.StreamingOutputCallRequest{\n\t\tResponseType: grpcurl_testing.PayloadType_RANDOM,\n\t}\n\tfor i := range reqs {\n\t\treq.ResponseParameters = append(req.ResponseParameters, &grpcurl_testing.ResponseParameters{Size: int32((i + 1) * 10)})\n\t\tpayload, err := (&jsonpb.Marshaler{}).MarshalToString(req)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to construct request %d: %v\", i, err)\n\t\t}\n\t\treqs[i] = payload\n\t}\n\n\t// Success\n\th := &handler{reqMessages: reqs}\n\terr := InvokeRpc(context.Background(), source, cc, \"testing.TestService/FullDuplexCall\", makeHeaders(codes.OK), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\tif h.check(t, \"testing.TestService.FullDuplexCall\", codes.OK, 3, 6) {\n\t\tresp := &grpcurl_testing.StreamingOutputCallResponse{}\n\t\ti := 0\n\t\tfor j := 1; j < 3; j++ {\n\t\t\t// three requests\n\t\t\tfor k := 0; k < j; k++ {\n\t\t\t\t// 1 response for first request, 2 for second, etc\n\t\t\t\tmsg := h.respMessages[i]\n\t\t\t\tif err := jsonpb.UnmarshalString(msg, resp); err != nil {\n\t\t\t\t\tt.Errorf(\"failed to parse response %d: %v\", i+1, err)\n\t\t\t\t}\n\t\t\t\tif resp.Payload.GetType() != grpcurl_testing.PayloadType_RANDOM {\n\t\t\t\t\tt.Errorf(\"response %d has wrong payload type; expecting %v, got %v\", i, grpcurl_testing.PayloadType_RANDOM, resp.Payload.Type)\n\t\t\t\t}\n\t\t\t\tif len(resp.Payload.Body) != (k+1)*10 {\n\t\t\t\t\tt.Errorf(\"response %d has wrong payload size; expecting %d, got %d\", i, (k+1)*10, len(resp.Payload.Body))\n\t\t\t\t}\n\t\t\t\tresp.Reset()\n\n\t\t\t\ti++\n\t\t\t}\n\t\t}\n\t}\n\n\t// Fail fast (server rejects as soon as possible)\n\th = &handler{reqMessages: reqs}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/FullDuplexCall\", makeHeaders(codes.PermissionDenied), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.FullDuplexCall\", codes.PermissionDenied, -3, 0)\n\n\t// Fail late (server waits until stream is complete to reject)\n\th = &handler{reqMessages: reqs}\n\terr = InvokeRpc(context.Background(), source, cc, \"testing.TestService/FullDuplexCall\", makeHeaders(codes.ResourceExhausted, true), h, h.getRequestData)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error during RPC: %v\", err)\n\t}\n\n\th.check(t, \"testing.TestService.FullDuplexCall\", codes.ResourceExhausted, 3, 6)\n}\n\ntype handler struct {\n\tmethod            *desc.MethodDescriptor\n\tmethodCount       int\n\treqHeaders        metadata.MD\n\treqHeadersCount   int\n\treqMessages       []string\n\treqMessagesCount  int\n\trespHeaders       metadata.MD\n\trespHeadersCount  int\n\trespMessages      []string\n\trespTrailers      metadata.MD\n\trespStatus        *status.Status\n\trespTrailersCount int\n}\n\nfunc (h *handler) getRequestData() ([]byte, error) {\n\t// we don't use a mutex, though this method will be called from different goroutine\n\t// than other methods for bidi calls, because this method does not share any state\n\t// with the other methods.\n\th.reqMessagesCount++\n\tif h.reqMessagesCount > len(h.reqMessages) {\n\t\treturn nil, io.EOF\n\t}\n\tif h.reqMessagesCount > 1 {\n\t\t// insert delay between messages in request stream\n\t\ttime.Sleep(time.Millisecond * 50)\n\t}\n\treturn []byte(h.reqMessages[h.reqMessagesCount-1]), nil\n}\n\nfunc (h *handler) OnResolveMethod(md *desc.MethodDescriptor) {\n\th.methodCount++\n\th.method = md\n}\n\nfunc (h *handler) OnSendHeaders(md metadata.MD) {\n\th.reqHeadersCount++\n\th.reqHeaders = md\n}\n\nfunc (h *handler) OnReceiveHeaders(md metadata.MD) {\n\th.respHeadersCount++\n\th.respHeaders = md\n}\n\nfunc (h *handler) OnReceiveResponse(msg proto.Message) {\n\tjsm := jsonpb.Marshaler{Indent: \"  \"}\n\trespStr, err := jsm.MarshalToString(msg)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"failed to generate JSON form of response message: %v\", err))\n\t}\n\th.respMessages = append(h.respMessages, respStr)\n}\n\nfunc (h *handler) OnReceiveTrailers(stat *status.Status, md metadata.MD) {\n\th.respTrailersCount++\n\th.respTrailers = md\n\th.respStatus = stat\n}\n\nfunc (h *handler) check(t *testing.T, expectedMethod string, expectedCode codes.Code, expectedRequestQueries, expectedResponses int) bool {\n\t// verify a few things were only ever called once\n\tif h.methodCount != 1 {\n\t\tt.Errorf(\"expected grpcurl to invoke OnResolveMethod once; was %d\", h.methodCount)\n\t}\n\tif h.reqHeadersCount != 1 {\n\t\tt.Errorf(\"expected grpcurl to invoke OnSendHeaders once; was %d\", h.reqHeadersCount)\n\t}\n\tif h.reqHeadersCount != 1 {\n\t\tt.Errorf(\"expected grpcurl to invoke OnSendHeaders once; was %d\", h.reqHeadersCount)\n\t}\n\tif h.respHeadersCount != 1 {\n\t\tt.Errorf(\"expected grpcurl to invoke OnReceiveHeaders once; was %d\", h.respHeadersCount)\n\t}\n\tif h.respTrailersCount != 1 {\n\t\tt.Errorf(\"expected grpcurl to invoke OnReceiveTrailers once; was %d\", h.respTrailersCount)\n\t}\n\n\t// check other stuff against given expectations\n\tif h.method.GetFullyQualifiedName() != expectedMethod {\n\t\tt.Errorf(\"wrong method: expecting %v, got %v\", expectedMethod, h.method.GetFullyQualifiedName())\n\t}\n\tif h.respStatus.Code() != expectedCode {\n\t\tt.Errorf(\"wrong code: expecting %v, got %v\", expectedCode, h.respStatus.Code())\n\t}\n\tif expectedRequestQueries < 0 {\n\t\t// negative expectation means \"negate and expect up to that number; could be fewer\"\n\t\tif h.reqMessagesCount > -expectedRequestQueries+1 {\n\t\t\t// the + 1 is because there will be an extra query that returns EOF\n\t\t\tt.Errorf(\"wrong number of messages queried: expecting no more than %v, got %v\", -expectedRequestQueries, h.reqMessagesCount-1)\n\t\t}\n\t} else {\n\t\tif h.reqMessagesCount != expectedRequestQueries+1 {\n\t\t\t// the + 1 is because there will be an extra query that returns EOF\n\t\t\tt.Errorf(\"wrong number of messages queried: expecting %v, got %v\", expectedRequestQueries, h.reqMessagesCount-1)\n\t\t}\n\t}\n\tif len(h.respMessages) != expectedResponses {\n\t\tt.Errorf(\"wrong number of messages received: expecting %v, got %v\", expectedResponses, len(h.respMessages))\n\t}\n\n\t// also check headers and trailers came through as expected\n\tv := h.respHeaders[\"some-fake-header-1\"]\n\tif len(v) != 1 || v[0] != \"val1\" {\n\t\tt.Errorf(\"wrong request header for %q: %v\", \"some-fake-header-1\", v)\n\t}\n\tv = h.respHeaders[\"some-fake-header-2\"]\n\tif len(v) != 1 || v[0] != \"val2\" {\n\t\tt.Errorf(\"wrong request header for %q: %v\", \"some-fake-header-2\", v)\n\t}\n\tv = h.respTrailers[\"some-fake-trailer-1\"]\n\tif len(v) != 1 || v[0] != \"valA\" {\n\t\tt.Errorf(\"wrong request header for %q: %v\", \"some-fake-trailer-1\", v)\n\t}\n\tv = h.respTrailers[\"some-fake-trailer-2\"]\n\tif len(v) != 1 || v[0] != \"valB\" {\n\t\tt.Errorf(\"wrong request header for %q: %v\", \"some-fake-trailer-2\", v)\n\t}\n\n\treturn len(h.respMessages) == expectedResponses\n}\n\nfunc makeHeaders(code codes.Code, failLate ...bool) []string {\n\tif len(failLate) > 1 {\n\t\tpanic(\"incorrect use of makeContext; should be at most one failLate flag\")\n\t}\n\n\thdrs := append(make([]string, 0, 5),\n\t\tfmt.Sprintf(\"%s: %s\", grpcurl_testing.MetadataReplyHeaders, \"some-fake-header-1: val1\"),\n\t\tfmt.Sprintf(\"%s: %s\", grpcurl_testing.MetadataReplyHeaders, \"some-fake-header-2: val2\"),\n\t\tfmt.Sprintf(\"%s: %s\", grpcurl_testing.MetadataReplyTrailers, \"some-fake-trailer-1: valA\"),\n\t\tfmt.Sprintf(\"%s: %s\", grpcurl_testing.MetadataReplyTrailers, \"some-fake-trailer-2: valB\"))\n\tif code != codes.OK {\n\t\tif len(failLate) > 0 && failLate[0] {\n\t\t\thdrs = append(hdrs, fmt.Sprintf(\"%s: %d\", grpcurl_testing.MetadataFailLate, code))\n\t\t} else {\n\t\t\thdrs = append(hdrs, fmt.Sprintf(\"%s: %d\", grpcurl_testing.MetadataFailEarly, code))\n\t\t}\n\t}\n\n\treturn hdrs\n}\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "invoke.go",
          "type": "blob",
          "size": 12.7529296875,
          "content": "package grpcurl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\t\"github.com/golang/protobuf/jsonpb\" //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/golang/protobuf/proto\"  //lint:ignore SA1019 we have to import this because it appears in exported API\n\t\"github.com/jhump/protoreflect/desc\"\n\t\"github.com/jhump/protoreflect/dynamic\"\n\t\"github.com/jhump/protoreflect/dynamic/grpcdynamic\"\n\t\"github.com/jhump/protoreflect/grpcreflect\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n)\n\n// InvocationEventHandler is a bag of callbacks for handling events that occur in the course\n// of invoking an RPC. The handler also provides request data that is sent. The callbacks are\n// generally called in the order they are listed below.\ntype InvocationEventHandler interface {\n\t// OnResolveMethod is called with a descriptor of the method that is being invoked.\n\tOnResolveMethod(*desc.MethodDescriptor)\n\t// OnSendHeaders is called with the request metadata that is being sent.\n\tOnSendHeaders(metadata.MD)\n\t// OnReceiveHeaders is called when response headers have been received.\n\tOnReceiveHeaders(metadata.MD)\n\t// OnReceiveResponse is called for each response message received.\n\tOnReceiveResponse(proto.Message)\n\t// OnReceiveTrailers is called when response trailers and final RPC status have been received.\n\tOnReceiveTrailers(*status.Status, metadata.MD)\n}\n\n// RequestMessageSupplier is a function that is called to retrieve request\n// messages for a GRPC operation. This type is deprecated and will be removed in\n// a future release.\n//\n// Deprecated: This is only used with the deprecated InvokeRpc. Instead, use\n// RequestSupplier with InvokeRPC.\ntype RequestMessageSupplier func() ([]byte, error)\n\n// InvokeRpc uses the given gRPC connection to invoke the given method. This function is deprecated\n// and will be removed in a future release. It just delegates to the similarly named InvokeRPC\n// method, whose signature is only slightly different.\n//\n// Deprecated: use InvokeRPC instead.\nfunc InvokeRpc(ctx context.Context, source DescriptorSource, cc *grpc.ClientConn, methodName string,\n\theaders []string, handler InvocationEventHandler, requestData RequestMessageSupplier) error {\n\n\treturn InvokeRPC(ctx, source, cc, methodName, headers, handler, func(m proto.Message) error {\n\t\t// New function is almost identical, but the request supplier function works differently.\n\t\t// So we adapt the logic here to maintain compatibility.\n\t\tdata, err := requestData()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn jsonpb.Unmarshal(bytes.NewReader(data), m)\n\t})\n}\n\n// RequestSupplier is a function that is called to populate messages for a gRPC operation. The\n// function should populate the given message or return a non-nil error. If the supplier has no\n// more messages, it should return io.EOF. When it returns io.EOF, it should not in any way\n// modify the given message argument.\ntype RequestSupplier func(proto.Message) error\n\n// InvokeRPC uses the given gRPC channel to invoke the given method. The given descriptor source\n// is used to determine the type of method and the type of request and response message. The given\n// headers are sent as request metadata. Methods on the given event handler are called as the\n// invocation proceeds.\n//\n// The given requestData function supplies the actual data to send. It should return io.EOF when\n// there is no more request data. If the method being invoked is a unary or server-streaming RPC\n// (e.g. exactly one request message) and there is no request data (e.g. the first invocation of\n// the function returns io.EOF), then an empty request message is sent.\n//\n// If the requestData function and the given event handler coordinate or share any state, they should\n// be thread-safe. This is because the requestData function may be called from a different goroutine\n// than the one invoking event callbacks. (This only happens for bi-directional streaming RPCs, where\n// one goroutine sends request messages and another consumes the response messages).\nfunc InvokeRPC(ctx context.Context, source DescriptorSource, ch grpcdynamic.Channel, methodName string,\n\theaders []string, handler InvocationEventHandler, requestData RequestSupplier) error {\n\n\tmd := MetadataFromHeaders(headers)\n\n\tsvc, mth := parseSymbol(methodName)\n\tif svc == \"\" || mth == \"\" {\n\t\treturn fmt.Errorf(\"given method name %q is not in expected format: 'service/method' or 'service.method'\", methodName)\n\t}\n\n\tdsc, err := source.FindSymbol(svc)\n\tif err != nil {\n\t\t// return a gRPC status error if hasStatus is true\n\t\terrStatus, hasStatus := status.FromError(err)\n\t\tswitch {\n\t\tcase hasStatus && isNotFoundError(err):\n\t\t\treturn status.Errorf(errStatus.Code(), \"target server does not expose service %q: %s\", svc, errStatus.Message())\n\t\tcase hasStatus:\n\t\t\treturn status.Errorf(errStatus.Code(), \"failed to query for service descriptor %q: %s\", svc, errStatus.Message())\n\t\tcase isNotFoundError(err):\n\t\t\treturn fmt.Errorf(\"target server does not expose service %q\", svc)\n\t\t}\n\t\treturn fmt.Errorf(\"failed to query for service descriptor %q: %v\", svc, err)\n\t}\n\tsd, ok := dsc.(*desc.ServiceDescriptor)\n\tif !ok {\n\t\treturn fmt.Errorf(\"target server does not expose service %q\", svc)\n\t}\n\tmtd := sd.FindMethodByName(mth)\n\tif mtd == nil {\n\t\treturn fmt.Errorf(\"service %q does not include a method named %q\", svc, mth)\n\t}\n\n\thandler.OnResolveMethod(mtd)\n\n\t// we also download any applicable extensions so we can provide full support for parsing user-provided data\n\tvar ext dynamic.ExtensionRegistry\n\talreadyFetched := map[string]bool{}\n\tif err = fetchAllExtensions(source, &ext, mtd.GetInputType(), alreadyFetched); err != nil {\n\t\treturn fmt.Errorf(\"error resolving server extensions for message %s: %v\", mtd.GetInputType().GetFullyQualifiedName(), err)\n\t}\n\tif err = fetchAllExtensions(source, &ext, mtd.GetOutputType(), alreadyFetched); err != nil {\n\t\treturn fmt.Errorf(\"error resolving server extensions for message %s: %v\", mtd.GetOutputType().GetFullyQualifiedName(), err)\n\t}\n\n\tmsgFactory := dynamic.NewMessageFactoryWithExtensionRegistry(&ext)\n\treq := msgFactory.NewMessage(mtd.GetInputType())\n\n\thandler.OnSendHeaders(md)\n\tctx = metadata.NewOutgoingContext(ctx, md)\n\n\tstub := grpcdynamic.NewStubWithMessageFactory(ch, msgFactory)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tif mtd.IsClientStreaming() && mtd.IsServerStreaming() {\n\t\treturn invokeBidi(ctx, stub, mtd, handler, requestData, req)\n\t} else if mtd.IsClientStreaming() {\n\t\treturn invokeClientStream(ctx, stub, mtd, handler, requestData, req)\n\t} else if mtd.IsServerStreaming() {\n\t\treturn invokeServerStream(ctx, stub, mtd, handler, requestData, req)\n\t} else {\n\t\treturn invokeUnary(ctx, stub, mtd, handler, requestData, req)\n\t}\n}\n\nfunc invokeUnary(ctx context.Context, stub grpcdynamic.Stub, md *desc.MethodDescriptor, handler InvocationEventHandler,\n\trequestData RequestSupplier, req proto.Message) error {\n\n\terr := requestData(req)\n\tif err != nil && err != io.EOF {\n\t\treturn fmt.Errorf(\"error getting request data: %v\", err)\n\t}\n\tif err != io.EOF {\n\t\t// verify there is no second message, which is a usage error\n\t\terr := requestData(req)\n\t\tif err == nil {\n\t\t\treturn fmt.Errorf(\"method %q is a unary RPC, but request data contained more than 1 message\", md.GetFullyQualifiedName())\n\t\t} else if err != io.EOF {\n\t\t\treturn fmt.Errorf(\"error getting request data: %v\", err)\n\t\t}\n\t}\n\n\t// Now we can actually invoke the RPC!\n\tvar respHeaders metadata.MD\n\tvar respTrailers metadata.MD\n\tresp, err := stub.InvokeRpc(ctx, md, req, grpc.Trailer(&respTrailers), grpc.Header(&respHeaders))\n\n\tstat, ok := status.FromError(err)\n\tif !ok {\n\t\t// Error codes sent from the server will get printed differently below.\n\t\t// So just bail for other kinds of errors here.\n\t\treturn fmt.Errorf(\"grpc call for %q failed: %v\", md.GetFullyQualifiedName(), err)\n\t}\n\n\thandler.OnReceiveHeaders(respHeaders)\n\n\tif stat.Code() == codes.OK {\n\t\thandler.OnReceiveResponse(resp)\n\t}\n\n\thandler.OnReceiveTrailers(stat, respTrailers)\n\n\treturn nil\n}\n\nfunc invokeClientStream(ctx context.Context, stub grpcdynamic.Stub, md *desc.MethodDescriptor, handler InvocationEventHandler,\n\trequestData RequestSupplier, req proto.Message) error {\n\n\t// invoke the RPC!\n\tstr, err := stub.InvokeRpcClientStream(ctx, md)\n\n\t// Upload each request message in the stream\n\tvar resp proto.Message\n\tfor err == nil {\n\t\terr = requestData(req)\n\t\tif err == io.EOF {\n\t\t\tresp, err = str.CloseAndReceive()\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error getting request data: %v\", err)\n\t\t}\n\n\t\terr = str.SendMsg(req)\n\t\tif err == io.EOF {\n\t\t\t// We get EOF on send if the server says \"go away\"\n\t\t\t// We have to use CloseAndReceive to get the actual code\n\t\t\tresp, err = str.CloseAndReceive()\n\t\t\tbreak\n\t\t}\n\n\t\treq.Reset()\n\t}\n\n\t// finally, process response data\n\tstat, ok := status.FromError(err)\n\tif !ok {\n\t\t// Error codes sent from the server will get printed differently below.\n\t\t// So just bail for other kinds of errors here.\n\t\treturn fmt.Errorf(\"grpc call for %q failed: %v\", md.GetFullyQualifiedName(), err)\n\t}\n\n\tif str != nil {\n\t\tif respHeaders, err := str.Header(); err == nil {\n\t\t\thandler.OnReceiveHeaders(respHeaders)\n\t\t}\n\t}\n\n\tif stat.Code() == codes.OK {\n\t\thandler.OnReceiveResponse(resp)\n\t}\n\n\tif str != nil {\n\t\thandler.OnReceiveTrailers(stat, str.Trailer())\n\t}\n\n\treturn nil\n}\n\nfunc invokeServerStream(ctx context.Context, stub grpcdynamic.Stub, md *desc.MethodDescriptor, handler InvocationEventHandler,\n\trequestData RequestSupplier, req proto.Message) error {\n\n\terr := requestData(req)\n\tif err != nil && err != io.EOF {\n\t\treturn fmt.Errorf(\"error getting request data: %v\", err)\n\t}\n\tif err != io.EOF {\n\t\t// verify there is no second message, which is a usage error\n\t\terr := requestData(req)\n\t\tif err == nil {\n\t\t\treturn fmt.Errorf(\"method %q is a server-streaming RPC, but request data contained more than 1 message\", md.GetFullyQualifiedName())\n\t\t} else if err != io.EOF {\n\t\t\treturn fmt.Errorf(\"error getting request data: %v\", err)\n\t\t}\n\t}\n\n\t// Now we can actually invoke the RPC!\n\tstr, err := stub.InvokeRpcServerStream(ctx, md, req)\n\n\tif str != nil {\n\t\tif respHeaders, err := str.Header(); err == nil {\n\t\t\thandler.OnReceiveHeaders(respHeaders)\n\t\t}\n\t}\n\n\t// Download each response message\n\tfor err == nil {\n\t\tvar resp proto.Message\n\t\tresp, err = str.RecvMsg()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\thandler.OnReceiveResponse(resp)\n\t}\n\n\tstat, ok := status.FromError(err)\n\tif !ok {\n\t\t// Error codes sent from the server will get printed differently below.\n\t\t// So just bail for other kinds of errors here.\n\t\treturn fmt.Errorf(\"grpc call for %q failed: %v\", md.GetFullyQualifiedName(), err)\n\t}\n\n\tif str != nil {\n\t\thandler.OnReceiveTrailers(stat, str.Trailer())\n\t}\n\n\treturn nil\n}\n\nfunc invokeBidi(ctx context.Context, stub grpcdynamic.Stub, md *desc.MethodDescriptor, handler InvocationEventHandler,\n\trequestData RequestSupplier, req proto.Message) error {\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\t// invoke the RPC!\n\tstr, err := stub.InvokeRpcBidiStream(ctx, md)\n\n\tvar wg sync.WaitGroup\n\tvar sendErr atomic.Value\n\n\tdefer wg.Wait()\n\n\tif err == nil {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\n\t\t\t// Concurrently upload each request message in the stream\n\t\t\tvar err error\n\t\t\tfor err == nil {\n\t\t\t\terr = requestData(req)\n\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\terr = str.CloseSend()\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\terr = fmt.Errorf(\"error getting request data: %v\", err)\n\t\t\t\t\tcancel()\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\terr = str.SendMsg(req)\n\n\t\t\t\treq.Reset()\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\tsendErr.Store(err)\n\t\t\t}\n\t\t}()\n\t}\n\n\tif str != nil {\n\t\tif respHeaders, err := str.Header(); err == nil {\n\t\t\thandler.OnReceiveHeaders(respHeaders)\n\t\t}\n\t}\n\n\t// Download each response message\n\tfor err == nil {\n\t\tvar resp proto.Message\n\t\tresp, err = str.RecvMsg()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\thandler.OnReceiveResponse(resp)\n\t}\n\n\tif se, ok := sendErr.Load().(error); ok && se != io.EOF {\n\t\terr = se\n\t}\n\n\tstat, ok := status.FromError(err)\n\tif !ok {\n\t\t// Error codes sent from the server will get printed differently below.\n\t\t// So just bail for other kinds of errors here.\n\t\treturn fmt.Errorf(\"grpc call for %q failed: %v\", md.GetFullyQualifiedName(), err)\n\t}\n\n\tif str != nil {\n\t\thandler.OnReceiveTrailers(stat, str.Trailer())\n\t}\n\n\treturn nil\n}\n\ntype notFoundError string\n\nfunc notFound(kind, name string) error {\n\treturn notFoundError(fmt.Sprintf(\"%s not found: %s\", kind, name))\n}\n\nfunc (e notFoundError) Error() string {\n\treturn string(e)\n}\n\nfunc isNotFoundError(err error) bool {\n\tif grpcreflect.IsElementNotFoundError(err) {\n\t\treturn true\n\t}\n\t_, ok := err.(notFoundError)\n\treturn ok\n}\n\nfunc parseSymbol(svcAndMethod string) (string, string) {\n\tpos := strings.LastIndex(svcAndMethod, \"/\")\n\tif pos < 0 {\n\t\tpos = strings.LastIndex(svcAndMethod, \".\")\n\t\tif pos < 0 {\n\t\t\treturn \"\", \"\"\n\t\t}\n\t}\n\treturn svcAndMethod[:pos], svcAndMethod[pos+1:]\n}\n"
        },
        {
          "name": "mk-test-files.sh",
          "type": "blob",
          "size": 1.4111328125,
          "content": "#!/bin/bash\n\nset -e\n\ncd \"$(dirname $0)\"\n\n# Run this script to generate files used by tests.\n\necho \"Creating protosets...\"\nprotoc testing/test.proto \\\n\t--include_imports \\\n\t--descriptor_set_out=testing/test.protoset\n\nprotoc testing/example.proto \\\n\t--include_imports \\\n\t--descriptor_set_out=testing/example.protoset\n\nprotoc testing/jsonpb_test_proto/test_objects.proto \\\n\t--go_out=paths=source_relative:.\n\necho \"Creating certs for TLS testing...\"\nif ! hash certstrap 2>/dev/null; then\n  # certstrap not found: try to install it\n  go get github.com/square/certstrap\n  go install github.com/square/certstrap\nfi\n\nfunction cs() {\n\tcertstrap --depot-path testing/tls \"$@\" --passphrase \"\"\n}\n\nrm -rf testing/tls\n\n# Create CA\ncs init --years 10 --common-name ca\n\n# Create client cert\ncs request-cert --common-name client\ncs sign client --years 10 --CA ca\n\n# Create server cert\ncs request-cert --common-name server --ip 127.0.0.1 --domain localhost\ncs sign server --years 10 --CA ca\n\n# Create another server cert for error testing\ncs request-cert --common-name other --ip 1.2.3.4 --domain foobar.com\ncs sign other --years 10 --CA ca\n\n# Create another CA and client cert for more\n# error testing\ncs init --years 10 --common-name wrong-ca\ncs request-cert --common-name wrong-client\ncs sign wrong-client --years 10 --CA wrong-ca\n\n# Create expired cert\ncs request-cert --common-name expired --ip 127.0.0.1 --domain localhost\ncs sign expired --years 0 --CA ca\n"
        },
        {
          "name": "releasing",
          "type": "tree",
          "content": null
        },
        {
          "name": "tls_settings_test.go",
          "type": "blob",
          "size": 11.494140625,
          "content": "package grpcurl_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n\n\t. \"github.com/fullstorydev/grpcurl\"\n\tgrpcurl_testing \"github.com/fullstorydev/grpcurl/internal/testing\"\n)\n\nfunc TestPlainText(t *testing.T) {\n\te, err := createTestServerAndClient(nil, nil)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t}\n\tdefer e.Close()\n\n\tsimpleTest(t, e.cc)\n}\n\nfunc TestBasicTLS(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t}\n\tdefer e.Close()\n\n\tsimpleTest(t, e.cc)\n}\n\nfunc TestInsecureClientTLS(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(true, \"\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t}\n\tdefer e.Close()\n\n\tsimpleTest(t, e.cc)\n}\n\nfunc TestClientCertTLS(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"internal/testing/tls/ca.crt\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"internal/testing/tls/client.crt\", \"internal/testing/tls/client.key\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t}\n\tdefer e.Close()\n\n\tsimpleTest(t, e.cc)\n}\n\nfunc TestRequireClientCertTLS(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"internal/testing/tls/ca.crt\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", true)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"internal/testing/tls/client.crt\", \"internal/testing/tls/client.key\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t}\n\tdefer e.Close()\n\n\tsimpleTest(t, e.cc)\n}\n\nfunc TestBrokenTLS_ClientPlainText(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\t// client connection (usually) succeeds since client is not waiting for TLS handshake\n\t// (we try several times, but if we never get a connection and the error message is\n\t// a known/expected possibility, we'll just bail)\n\tvar e testEnv\n\tfailCount := 0\n\tfor {\n\t\te, err = createTestServerAndClient(serverCreds, nil)\n\t\tif err == nil {\n\t\t\t// success!\n\t\t\tdefer e.Close()\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.Contains(err.Error(), \"deadline exceeded\") ||\n\t\t\tstrings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\t// It is possible that the connection never becomes healthy:\n\t\t\t//   1) grpc connects successfully\n\t\t\t//   2) grpc client tries to send HTTP/2 preface and settings frame\n\t\t\t//   3) server, expecting handshake, closes the connection\n\t\t\t//   4) in the client, the write fails, so the connection never\n\t\t\t//      becomes ready\n\t\t\t// The client will attempt to reconnect on transient errors, so\n\t\t\t// may eventually bump into the connect time limit. This used to\n\t\t\t// result in a \"deadline exceeded\" error, but more recent versions\n\t\t\t// of the grpc library report any underlying I/O error instead, so\n\t\t\t// we also check for \"use of closed network connection\".\n\t\t\tfailCount++\n\t\t\tif failCount > 5 {\n\t\t\t\treturn // bail...\n\t\t\t}\n\t\t\t// we'll try again\n\n\t\t} else {\n\t\t\t// some other error occurred, so we'll consider that a test failure\n\t\t\tt.Fatalf(\"failed to setup server and client: %v\", err)\n\t\t}\n\t}\n\n\t// but request fails because server closes connection upon seeing request\n\t// bytes that are not a TLS handshake\n\tcl := grpcurl_testing.NewTestServiceClient(e.cc)\n\t_, err = cl.UnaryCall(context.Background(), &grpcurl_testing.SimpleRequest{})\n\tif err == nil {\n\t\tt.Fatal(\"expecting failure\")\n\t}\n\t// various errors possible when server closes connection\n\tif !strings.Contains(err.Error(), \"transport is closing\") &&\n\t\t!strings.Contains(err.Error(), \"connection is unavailable\") &&\n\t\t!strings.Contains(err.Error(), \"use of closed network connection\") &&\n\t\t!strings.Contains(err.Error(), \"all SubConns are in TransientFailure\") {\n\n\t\tt.Fatalf(\"expecting transport failure, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ServerPlainText(t *testing.T) {\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(nil, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"first record does not look like a TLS handshake\") {\n\t\tt.Fatalf(\"expecting TLS handshake failure, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ServerUsesWrongCert(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/other.crt\", \"internal/testing/tls/other.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"certificate is valid for\") {\n\t\tt.Fatalf(\"expecting TLS certificate error, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ClientHasExpiredCert(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"internal/testing/tls/ca.crt\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"internal/testing/tls/expired.crt\", \"internal/testing/tls/expired.key\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"certificate\") {\n\t\tt.Fatalf(\"expecting TLS certificate error, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ServerHasExpiredCert(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/expired.crt\", \"internal/testing/tls/expired.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"certificate has expired or is not yet valid\") {\n\t\tt.Fatalf(\"expecting TLS certificate expired, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ClientNotTrusted(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"internal/testing/tls/ca.crt\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", true)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"internal/testing/tls/wrong-client.crt\", \"internal/testing/tls/wrong-client.key\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"bad certificate\") {\n\t\tt.Fatalf(\"expecting TLS certificate error, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_ServerNotTrusted(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"\", \"internal/testing/tls/client.crt\", \"internal/testing/tls/client.key\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"certificate\") {\n\t\tt.Fatalf(\"expecting TLS certificate error, got: %v\", err)\n\t}\n}\n\nfunc TestBrokenTLS_RequireClientCertButNonePresented(t *testing.T) {\n\tserverCreds, err := ServerTransportCredentials(\"internal/testing/tls/ca.crt\", \"internal/testing/tls/server.crt\", \"internal/testing/tls/server.key\", true)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\tclientCreds, err := ClientTransportCredentials(false, \"internal/testing/tls/ca.crt\", \"\", \"\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create server creds: %v\", err)\n\t}\n\n\te, err := createTestServerAndClient(serverCreds, clientCreds)\n\tif err == nil {\n\t\te.Close()\n\t\tt.Fatal(\"expecting TLS failure setting up server and client\")\n\t}\n\tif !strings.Contains(err.Error(), \"bad certificate\") {\n\t\tt.Fatalf(\"expecting TLS certificate error, got: %v\", err)\n\t}\n}\n\nfunc simpleTest(t *testing.T, cc *grpc.ClientConn) {\n\tcl := grpcurl_testing.NewTestServiceClient(cc)\n\tctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)\n\tdefer cancel()\n\t_, err := cl.UnaryCall(ctx, &grpcurl_testing.SimpleRequest{}, grpc.WaitForReady(true))\n\tif err != nil {\n\t\tt.Errorf(\"simple RPC failed: %v\", err)\n\t}\n}\n\nfunc createTestServerAndClient(serverCreds, clientCreds credentials.TransportCredentials) (testEnv, error) {\n\tvar e testEnv\n\tcompleted := false\n\tdefer func() {\n\t\tif !completed {\n\t\t\te.Close()\n\t\t}\n\t}()\n\n\tvar svrOpts []grpc.ServerOption\n\tif serverCreds != nil {\n\t\tsvrOpts = []grpc.ServerOption{grpc.Creds(serverCreds)}\n\t}\n\tsvr := grpc.NewServer(svrOpts...)\n\tgrpcurl_testing.RegisterTestServiceServer(svr, grpcurl_testing.TestServer{})\n\tl, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\treturn e, err\n\t}\n\tport := l.Addr().(*net.TCPAddr).Port\n\tgo svr.Serve(l)\n\n\tctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)\n\tdefer cancel()\n\n\tcc, err := BlockingDial(ctx, \"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", port), clientCreds)\n\tif err != nil {\n\t\treturn e, err\n\t}\n\n\te.svr = svr\n\te.cc = cc\n\tcompleted = true\n\treturn e, nil\n}\n\ntype testEnv struct {\n\tsvr *grpc.Server\n\tcc  *grpc.ClientConn\n}\n\nfunc (e *testEnv) Close() {\n\tif e.cc != nil {\n\t\te.cc.Close()\n\t\te.cc = nil\n\t}\n\tif e.svr != nil {\n\t\te.svr.GracefulStop()\n\t\te.svr = nil\n\t}\n}\n"
        }
      ]
    }
  ]
}