{
  "metadata": {
    "timestamp": 1736568002355,
    "page": 137,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "json-iterator/go",
      "stars": 13526,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 0.0322265625,
          "content": "ignore:\n    - \"output_tests/.*\"\n\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.041015625,
          "content": "/vendor\n/bug_test.go\n/coverage.txt\n/.idea\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.1552734375,
          "content": "language: go\n\ngo:\n  - 1.8.x\n  - 1.x\n\nbefore_install:\n  - go get -t -v ./...\n\nscript:\n  - ./test.sh\n\nafter_success:\n  - bash <(curl -s https://codecov.io/bash)\n"
        },
        {
          "name": "Gopkg.lock",
          "type": "blob",
          "size": 0.57421875,
          "content": "# This file is autogenerated, do not edit; changes may be undone by the next 'dep ensure'.\n\n\n[[projects]]\n  name = \"github.com/modern-go/concurrent\"\n  packages = [\".\"]\n  revision = \"e0a39a4cb4216ea8db28e22a69f4ec25610d513a\"\n  version = \"1.0.0\"\n\n[[projects]]\n  name = \"github.com/modern-go/reflect2\"\n  packages = [\".\"]\n  revision = \"4b7aa43c6742a2c18fdef89dd197aaae7dac7ccd\"\n  version = \"1.0.1\"\n\n[solve-meta]\n  analyzer-name = \"dep\"\n  analyzer-version = 1\n  inputs-digest = \"ea54a775e5a354cb015502d2e7aa4b74230fc77e894f34a838b268c25ec8eeb8\"\n  solver-name = \"gps-cdcl\"\n  solver-version = 1\n"
        },
        {
          "name": "Gopkg.toml",
          "type": "blob",
          "size": 0.6953125,
          "content": "# Gopkg.toml example\n#\n# Refer to https://github.com/golang/dep/blob/master/docs/Gopkg.toml.md\n# for detailed Gopkg.toml documentation.\n#\n# required = [\"github.com/user/thing/cmd/thing\"]\n# ignored = [\"github.com/user/project/pkgX\", \"bitbucket.org/user/project/pkgA/pkgY\"]\n#\n# [[constraint]]\n#   name = \"github.com/user/project\"\n#   version = \"1.0.0\"\n#\n# [[constraint]]\n#   name = \"github.com/user/project2\"\n#   branch = \"dev\"\n#   source = \"github.com/myfork/project2\"\n#\n# [[override]]\n#  name = \"github.com/x/y\"\n#  version = \"2.4.0\"\n\nignored = [\"github.com/davecgh/go-spew*\",\"github.com/google/gofuzz*\",\"github.com/stretchr/testify*\"]\n\n[[constraint]]\n  name = \"github.com/modern-go/reflect2\"\n  version = \"1.0.1\"\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.044921875,
          "content": "MIT License\n\nCopyright (c) 2016 json-iterator\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.8642578125,
          "content": "[![Sourcegraph](https://sourcegraph.com/github.com/json-iterator/go/-/badge.svg)](https://sourcegraph.com/github.com/json-iterator/go?badge)\n[![GoDoc](http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square)](https://pkg.go.dev/github.com/json-iterator/go)\n[![Build Status](https://travis-ci.org/json-iterator/go.svg?branch=master)](https://travis-ci.org/json-iterator/go)\n[![codecov](https://codecov.io/gh/json-iterator/go/branch/master/graph/badge.svg)](https://codecov.io/gh/json-iterator/go)\n[![rcard](https://goreportcard.com/badge/github.com/json-iterator/go)](https://goreportcard.com/report/github.com/json-iterator/go)\n[![License](http://img.shields.io/badge/license-mit-blue.svg?style=flat-square)](https://raw.githubusercontent.com/json-iterator/go/master/LICENSE)\n[![Gitter chat](https://badges.gitter.im/gitterHQ/gitter.png)](https://gitter.im/json-iterator/Lobby)\n\nA high-performance 100% compatible drop-in replacement of \"encoding/json\"\n\n# Benchmark\n\n![benchmark](http://jsoniter.com/benchmarks/go-benchmark.png)\n\nSource code: https://github.com/json-iterator/go-benchmark/blob/master/src/github.com/json-iterator/go-benchmark/benchmark_medium_payload_test.go\n\nRaw Result (easyjson requires static code generation)\n\n|                 | ns/op       | allocation bytes | allocation times |\n| --------------- | ----------- | ---------------- | ---------------- |\n| std decode      | 35510 ns/op | 1960 B/op        | 99 allocs/op     |\n| easyjson decode | 8499 ns/op  | 160 B/op         | 4 allocs/op      |\n| jsoniter decode | 5623 ns/op  | 160 B/op         | 3 allocs/op      |\n| std encode      | 2213 ns/op  | 712 B/op         | 5 allocs/op      |\n| easyjson encode | 883 ns/op   | 576 B/op         | 3 allocs/op      |\n| jsoniter encode | 837 ns/op   | 384 B/op         | 4 allocs/op      |\n\nAlways benchmark with your own workload.\nThe result depends heavily on the data input.\n\n# Usage\n\n100% compatibility with standard lib\n\nReplace\n\n```go\nimport \"encoding/json\"\njson.Marshal(&data)\n```\n\nwith\n\n```go\nimport jsoniter \"github.com/json-iterator/go\"\n\nvar json = jsoniter.ConfigCompatibleWithStandardLibrary\njson.Marshal(&data)\n```\n\nReplace\n\n```go\nimport \"encoding/json\"\njson.Unmarshal(input, &data)\n```\n\nwith\n\n```go\nimport jsoniter \"github.com/json-iterator/go\"\n\nvar json = jsoniter.ConfigCompatibleWithStandardLibrary\njson.Unmarshal(input, &data)\n```\n\n[More documentation](http://jsoniter.com/migrate-from-go-std.html)\n\n# How to get\n\n```\ngo get github.com/json-iterator/go\n```\n\n# Contribution Welcomed !\n\nContributors\n\n- [thockin](https://github.com/thockin)\n- [mattn](https://github.com/mattn)\n- [cch123](https://github.com/cch123)\n- [Oleg Shaldybin](https://github.com/olegshaldybin)\n- [Jason Toffaletti](https://github.com/toffaletti)\n\nReport issue or pull request, or email taowen@gmail.com, or [![Gitter chat](https://badges.gitter.im/gitterHQ/gitter.png)](https://gitter.im/json-iterator/Lobby)\n"
        },
        {
          "name": "adapter.go",
          "type": "blob",
          "size": 4.490234375,
          "content": "package jsoniter\n\nimport (\n\t\"bytes\"\n\t\"io\"\n)\n\n// RawMessage to make replace json with jsoniter\ntype RawMessage []byte\n\n// Unmarshal adapts to json/encoding Unmarshal API\n//\n// Unmarshal parses the JSON-encoded data and stores the result in the value pointed to by v.\n// Refer to https://godoc.org/encoding/json#Unmarshal for more information\nfunc Unmarshal(data []byte, v interface{}) error {\n\treturn ConfigDefault.Unmarshal(data, v)\n}\n\n// UnmarshalFromString is a convenient method to read from string instead of []byte\nfunc UnmarshalFromString(str string, v interface{}) error {\n\treturn ConfigDefault.UnmarshalFromString(str, v)\n}\n\n// Get quick method to get value from deeply nested JSON structure\nfunc Get(data []byte, path ...interface{}) Any {\n\treturn ConfigDefault.Get(data, path...)\n}\n\n// Marshal adapts to json/encoding Marshal API\n//\n// Marshal returns the JSON encoding of v, adapts to json/encoding Marshal API\n// Refer to https://godoc.org/encoding/json#Marshal for more information\nfunc Marshal(v interface{}) ([]byte, error) {\n\treturn ConfigDefault.Marshal(v)\n}\n\n// MarshalIndent same as json.MarshalIndent. Prefix is not supported.\nfunc MarshalIndent(v interface{}, prefix, indent string) ([]byte, error) {\n\treturn ConfigDefault.MarshalIndent(v, prefix, indent)\n}\n\n// MarshalToString convenient method to write as string instead of []byte\nfunc MarshalToString(v interface{}) (string, error) {\n\treturn ConfigDefault.MarshalToString(v)\n}\n\n// NewDecoder adapts to json/stream NewDecoder API.\n//\n// NewDecoder returns a new decoder that reads from r.\n//\n// Instead of a json/encoding Decoder, an Decoder is returned\n// Refer to https://godoc.org/encoding/json#NewDecoder for more information\nfunc NewDecoder(reader io.Reader) *Decoder {\n\treturn ConfigDefault.NewDecoder(reader)\n}\n\n// Decoder reads and decodes JSON values from an input stream.\n// Decoder provides identical APIs with json/stream Decoder (Token() and UseNumber() are in progress)\ntype Decoder struct {\n\titer *Iterator\n}\n\n// Decode decode JSON into interface{}\nfunc (adapter *Decoder) Decode(obj interface{}) error {\n\tif adapter.iter.head == adapter.iter.tail && adapter.iter.reader != nil {\n\t\tif !adapter.iter.loadMore() {\n\t\t\treturn io.EOF\n\t\t}\n\t}\n\tadapter.iter.ReadVal(obj)\n\terr := adapter.iter.Error\n\tif err == io.EOF {\n\t\treturn nil\n\t}\n\treturn adapter.iter.Error\n}\n\n// More is there more?\nfunc (adapter *Decoder) More() bool {\n\titer := adapter.iter\n\tif iter.Error != nil {\n\t\treturn false\n\t}\n\tc := iter.nextToken()\n\tif c == 0 {\n\t\treturn false\n\t}\n\titer.unreadByte()\n\treturn c != ']' && c != '}'\n}\n\n// Buffered remaining buffer\nfunc (adapter *Decoder) Buffered() io.Reader {\n\tremaining := adapter.iter.buf[adapter.iter.head:adapter.iter.tail]\n\treturn bytes.NewReader(remaining)\n}\n\n// UseNumber causes the Decoder to unmarshal a number into an interface{} as a\n// Number instead of as a float64.\nfunc (adapter *Decoder) UseNumber() {\n\tcfg := adapter.iter.cfg.configBeforeFrozen\n\tcfg.UseNumber = true\n\tadapter.iter.cfg = cfg.frozeWithCacheReuse(adapter.iter.cfg.extraExtensions)\n}\n\n// DisallowUnknownFields causes the Decoder to return an error when the destination\n// is a struct and the input contains object keys which do not match any\n// non-ignored, exported fields in the destination.\nfunc (adapter *Decoder) DisallowUnknownFields() {\n\tcfg := adapter.iter.cfg.configBeforeFrozen\n\tcfg.DisallowUnknownFields = true\n\tadapter.iter.cfg = cfg.frozeWithCacheReuse(adapter.iter.cfg.extraExtensions)\n}\n\n// NewEncoder same as json.NewEncoder\nfunc NewEncoder(writer io.Writer) *Encoder {\n\treturn ConfigDefault.NewEncoder(writer)\n}\n\n// Encoder same as json.Encoder\ntype Encoder struct {\n\tstream *Stream\n}\n\n// Encode encode interface{} as JSON to io.Writer\nfunc (adapter *Encoder) Encode(val interface{}) error {\n\tadapter.stream.WriteVal(val)\n\tadapter.stream.WriteRaw(\"\\n\")\n\tadapter.stream.Flush()\n\treturn adapter.stream.Error\n}\n\n// SetIndent set the indention. Prefix is not supported\nfunc (adapter *Encoder) SetIndent(prefix, indent string) {\n\tconfig := adapter.stream.cfg.configBeforeFrozen\n\tconfig.IndentionStep = len(indent)\n\tadapter.stream.cfg = config.frozeWithCacheReuse(adapter.stream.cfg.extraExtensions)\n}\n\n// SetEscapeHTML escape html by default, set to false to disable\nfunc (adapter *Encoder) SetEscapeHTML(escapeHTML bool) {\n\tconfig := adapter.stream.cfg.configBeforeFrozen\n\tconfig.EscapeHTML = escapeHTML\n\tadapter.stream.cfg = config.frozeWithCacheReuse(adapter.stream.cfg.extraExtensions)\n}\n\n// Valid reports whether data is a valid JSON encoding.\nfunc Valid(data []byte) bool {\n\treturn ConfigDefault.Valid(data)\n}\n"
        },
        {
          "name": "any.go",
          "type": "blob",
          "size": 7.0263671875,
          "content": "package jsoniter\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"github.com/modern-go/reflect2\"\n\t\"io\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"unsafe\"\n)\n\n// Any generic object representation.\n// The lazy json implementation holds []byte and parse lazily.\ntype Any interface {\n\tLastError() error\n\tValueType() ValueType\n\tMustBeValid() Any\n\tToBool() bool\n\tToInt() int\n\tToInt32() int32\n\tToInt64() int64\n\tToUint() uint\n\tToUint32() uint32\n\tToUint64() uint64\n\tToFloat32() float32\n\tToFloat64() float64\n\tToString() string\n\tToVal(val interface{})\n\tGet(path ...interface{}) Any\n\tSize() int\n\tKeys() []string\n\tGetInterface() interface{}\n\tWriteTo(stream *Stream)\n}\n\ntype baseAny struct{}\n\nfunc (any *baseAny) Get(path ...interface{}) Any {\n\treturn &invalidAny{baseAny{}, fmt.Errorf(\"GetIndex %v from simple value\", path)}\n}\n\nfunc (any *baseAny) Size() int {\n\treturn 0\n}\n\nfunc (any *baseAny) Keys() []string {\n\treturn []string{}\n}\n\nfunc (any *baseAny) ToVal(obj interface{}) {\n\tpanic(\"not implemented\")\n}\n\n// WrapInt32 turn int32 into Any interface\nfunc WrapInt32(val int32) Any {\n\treturn &int32Any{baseAny{}, val}\n}\n\n// WrapInt64 turn int64 into Any interface\nfunc WrapInt64(val int64) Any {\n\treturn &int64Any{baseAny{}, val}\n}\n\n// WrapUint32 turn uint32 into Any interface\nfunc WrapUint32(val uint32) Any {\n\treturn &uint32Any{baseAny{}, val}\n}\n\n// WrapUint64 turn uint64 into Any interface\nfunc WrapUint64(val uint64) Any {\n\treturn &uint64Any{baseAny{}, val}\n}\n\n// WrapFloat64 turn float64 into Any interface\nfunc WrapFloat64(val float64) Any {\n\treturn &floatAny{baseAny{}, val}\n}\n\n// WrapString turn string into Any interface\nfunc WrapString(val string) Any {\n\treturn &stringAny{baseAny{}, val}\n}\n\n// Wrap turn a go object into Any interface\nfunc Wrap(val interface{}) Any {\n\tif val == nil {\n\t\treturn &nilAny{}\n\t}\n\tasAny, isAny := val.(Any)\n\tif isAny {\n\t\treturn asAny\n\t}\n\ttyp := reflect2.TypeOf(val)\n\tswitch typ.Kind() {\n\tcase reflect.Slice:\n\t\treturn wrapArray(val)\n\tcase reflect.Struct:\n\t\treturn wrapStruct(val)\n\tcase reflect.Map:\n\t\treturn wrapMap(val)\n\tcase reflect.String:\n\t\treturn WrapString(val.(string))\n\tcase reflect.Int:\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn WrapInt32(int32(val.(int)))\n\t\t}\n\t\treturn WrapInt64(int64(val.(int)))\n\tcase reflect.Int8:\n\t\treturn WrapInt32(int32(val.(int8)))\n\tcase reflect.Int16:\n\t\treturn WrapInt32(int32(val.(int16)))\n\tcase reflect.Int32:\n\t\treturn WrapInt32(val.(int32))\n\tcase reflect.Int64:\n\t\treturn WrapInt64(val.(int64))\n\tcase reflect.Uint:\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn WrapUint32(uint32(val.(uint)))\n\t\t}\n\t\treturn WrapUint64(uint64(val.(uint)))\n\tcase reflect.Uintptr:\n\t\tif ptrSize == 32 {\n\t\t\treturn WrapUint32(uint32(val.(uintptr)))\n\t\t}\n\t\treturn WrapUint64(uint64(val.(uintptr)))\n\tcase reflect.Uint8:\n\t\treturn WrapUint32(uint32(val.(uint8)))\n\tcase reflect.Uint16:\n\t\treturn WrapUint32(uint32(val.(uint16)))\n\tcase reflect.Uint32:\n\t\treturn WrapUint32(uint32(val.(uint32)))\n\tcase reflect.Uint64:\n\t\treturn WrapUint64(val.(uint64))\n\tcase reflect.Float32:\n\t\treturn WrapFloat64(float64(val.(float32)))\n\tcase reflect.Float64:\n\t\treturn WrapFloat64(val.(float64))\n\tcase reflect.Bool:\n\t\tif val.(bool) == true {\n\t\t\treturn &trueAny{}\n\t\t}\n\t\treturn &falseAny{}\n\t}\n\treturn &invalidAny{baseAny{}, fmt.Errorf(\"unsupported type: %v\", typ)}\n}\n\n// ReadAny read next JSON element as an Any object. It is a better json.RawMessage.\nfunc (iter *Iterator) ReadAny() Any {\n\treturn iter.readAny()\n}\n\nfunc (iter *Iterator) readAny() Any {\n\tc := iter.nextToken()\n\tswitch c {\n\tcase '\"':\n\t\titer.unreadByte()\n\t\treturn &stringAny{baseAny{}, iter.ReadString()}\n\tcase 'n':\n\t\titer.skipThreeBytes('u', 'l', 'l') // null\n\t\treturn &nilAny{}\n\tcase 't':\n\t\titer.skipThreeBytes('r', 'u', 'e') // true\n\t\treturn &trueAny{}\n\tcase 'f':\n\t\titer.skipFourBytes('a', 'l', 's', 'e') // false\n\t\treturn &falseAny{}\n\tcase '{':\n\t\treturn iter.readObjectAny()\n\tcase '[':\n\t\treturn iter.readArrayAny()\n\tcase '-':\n\t\treturn iter.readNumberAny(false)\n\tcase 0:\n\t\treturn &invalidAny{baseAny{}, errors.New(\"input is empty\")}\n\tdefault:\n\t\treturn iter.readNumberAny(true)\n\t}\n}\n\nfunc (iter *Iterator) readNumberAny(positive bool) Any {\n\titer.startCapture(iter.head - 1)\n\titer.skipNumber()\n\tlazyBuf := iter.stopCapture()\n\treturn &numberLazyAny{baseAny{}, iter.cfg, lazyBuf, nil}\n}\n\nfunc (iter *Iterator) readObjectAny() Any {\n\titer.startCapture(iter.head - 1)\n\titer.skipObject()\n\tlazyBuf := iter.stopCapture()\n\treturn &objectLazyAny{baseAny{}, iter.cfg, lazyBuf, nil}\n}\n\nfunc (iter *Iterator) readArrayAny() Any {\n\titer.startCapture(iter.head - 1)\n\titer.skipArray()\n\tlazyBuf := iter.stopCapture()\n\treturn &arrayLazyAny{baseAny{}, iter.cfg, lazyBuf, nil}\n}\n\nfunc locateObjectField(iter *Iterator, target string) []byte {\n\tvar found []byte\n\titer.ReadObjectCB(func(iter *Iterator, field string) bool {\n\t\tif field == target {\n\t\t\tfound = iter.SkipAndReturnBytes()\n\t\t\treturn false\n\t\t}\n\t\titer.Skip()\n\t\treturn true\n\t})\n\treturn found\n}\n\nfunc locateArrayElement(iter *Iterator, target int) []byte {\n\tvar found []byte\n\tn := 0\n\titer.ReadArrayCB(func(iter *Iterator) bool {\n\t\tif n == target {\n\t\t\tfound = iter.SkipAndReturnBytes()\n\t\t\treturn false\n\t\t}\n\t\titer.Skip()\n\t\tn++\n\t\treturn true\n\t})\n\treturn found\n}\n\nfunc locatePath(iter *Iterator, path []interface{}) Any {\n\tfor i, pathKeyObj := range path {\n\t\tswitch pathKey := pathKeyObj.(type) {\n\t\tcase string:\n\t\t\tvalueBytes := locateObjectField(iter, pathKey)\n\t\t\tif valueBytes == nil {\n\t\t\t\treturn newInvalidAny(path[i:])\n\t\t\t}\n\t\t\titer.ResetBytes(valueBytes)\n\t\tcase int:\n\t\t\tvalueBytes := locateArrayElement(iter, pathKey)\n\t\t\tif valueBytes == nil {\n\t\t\t\treturn newInvalidAny(path[i:])\n\t\t\t}\n\t\t\titer.ResetBytes(valueBytes)\n\t\tcase int32:\n\t\t\tif '*' == pathKey {\n\t\t\t\treturn iter.readAny().Get(path[i:]...)\n\t\t\t}\n\t\t\treturn newInvalidAny(path[i:])\n\t\tdefault:\n\t\t\treturn newInvalidAny(path[i:])\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn &invalidAny{baseAny{}, iter.Error}\n\t}\n\treturn iter.readAny()\n}\n\nvar anyType = reflect2.TypeOfPtr((*Any)(nil)).Elem()\n\nfunc createDecoderOfAny(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tif typ == anyType {\n\t\treturn &directAnyCodec{}\n\t}\n\tif typ.Implements(anyType) {\n\t\treturn &anyCodec{\n\t\t\tvalType: typ,\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc createEncoderOfAny(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tif typ == anyType {\n\t\treturn &directAnyCodec{}\n\t}\n\tif typ.Implements(anyType) {\n\t\treturn &anyCodec{\n\t\t\tvalType: typ,\n\t\t}\n\t}\n\treturn nil\n}\n\ntype anyCodec struct {\n\tvalType reflect2.Type\n}\n\nfunc (codec *anyCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tpanic(\"not implemented\")\n}\n\nfunc (codec *anyCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tobj := codec.valType.UnsafeIndirect(ptr)\n\tany := obj.(Any)\n\tany.WriteTo(stream)\n}\n\nfunc (codec *anyCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\tobj := codec.valType.UnsafeIndirect(ptr)\n\tany := obj.(Any)\n\treturn any.Size() == 0\n}\n\ntype directAnyCodec struct {\n}\n\nfunc (codec *directAnyCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\t*(*Any)(ptr) = iter.readAny()\n}\n\nfunc (codec *directAnyCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tany := *(*Any)(ptr)\n\tif any == nil {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tany.WriteTo(stream)\n}\n\nfunc (codec *directAnyCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\tany := *(*Any)(ptr)\n\treturn any.Size() == 0\n}\n"
        },
        {
          "name": "any_array.go",
          "type": "blob",
          "size": 4.724609375,
          "content": "package jsoniter\n\nimport (\n\t\"reflect\"\n\t\"unsafe\"\n)\n\ntype arrayLazyAny struct {\n\tbaseAny\n\tcfg *frozenConfig\n\tbuf []byte\n\terr error\n}\n\nfunc (any *arrayLazyAny) ValueType() ValueType {\n\treturn ArrayValue\n}\n\nfunc (any *arrayLazyAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *arrayLazyAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *arrayLazyAny) ToBool() bool {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\treturn iter.ReadArray()\n}\n\nfunc (any *arrayLazyAny) ToInt() int {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToInt32() int32 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToInt64() int64 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToUint() uint {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToUint32() uint32 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToUint64() uint64 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToFloat32() float32 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToFloat64() float64 {\n\tif any.ToBool() {\n\t\treturn 1\n\t}\n\treturn 0\n}\n\nfunc (any *arrayLazyAny) ToString() string {\n\treturn *(*string)(unsafe.Pointer(&any.buf))\n}\n\nfunc (any *arrayLazyAny) ToVal(val interface{}) {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\titer.ReadVal(val)\n}\n\nfunc (any *arrayLazyAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\tswitch firstPath := path[0].(type) {\n\tcase int:\n\t\titer := any.cfg.BorrowIterator(any.buf)\n\t\tdefer any.cfg.ReturnIterator(iter)\n\t\tvalueBytes := locateArrayElement(iter, firstPath)\n\t\tif valueBytes == nil {\n\t\t\treturn newInvalidAny(path)\n\t\t}\n\t\titer.ResetBytes(valueBytes)\n\t\treturn locatePath(iter, path[1:])\n\tcase int32:\n\t\tif '*' == firstPath {\n\t\t\titer := any.cfg.BorrowIterator(any.buf)\n\t\t\tdefer any.cfg.ReturnIterator(iter)\n\t\t\tarr := make([]Any, 0)\n\t\t\titer.ReadArrayCB(func(iter *Iterator) bool {\n\t\t\t\tfound := iter.readAny().Get(path[1:]...)\n\t\t\t\tif found.ValueType() != InvalidValue {\n\t\t\t\t\tarr = append(arr, found)\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t})\n\t\t\treturn wrapArray(arr)\n\t\t}\n\t\treturn newInvalidAny(path)\n\tdefault:\n\t\treturn newInvalidAny(path)\n\t}\n}\n\nfunc (any *arrayLazyAny) Size() int {\n\tsize := 0\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\titer.ReadArrayCB(func(iter *Iterator) bool {\n\t\tsize++\n\t\titer.Skip()\n\t\treturn true\n\t})\n\treturn size\n}\n\nfunc (any *arrayLazyAny) WriteTo(stream *Stream) {\n\tstream.Write(any.buf)\n}\n\nfunc (any *arrayLazyAny) GetInterface() interface{} {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\treturn iter.Read()\n}\n\ntype arrayAny struct {\n\tbaseAny\n\tval reflect.Value\n}\n\nfunc wrapArray(val interface{}) *arrayAny {\n\treturn &arrayAny{baseAny{}, reflect.ValueOf(val)}\n}\n\nfunc (any *arrayAny) ValueType() ValueType {\n\treturn ArrayValue\n}\n\nfunc (any *arrayAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *arrayAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *arrayAny) ToBool() bool {\n\treturn any.val.Len() != 0\n}\n\nfunc (any *arrayAny) ToInt() int {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToInt32() int32 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToInt64() int64 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToUint() uint {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToUint32() uint32 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToUint64() uint64 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToFloat32() float32 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToFloat64() float64 {\n\tif any.val.Len() == 0 {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc (any *arrayAny) ToString() string {\n\tstr, _ := MarshalToString(any.val.Interface())\n\treturn str\n}\n\nfunc (any *arrayAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\tswitch firstPath := path[0].(type) {\n\tcase int:\n\t\tif firstPath < 0 || firstPath >= any.val.Len() {\n\t\t\treturn newInvalidAny(path)\n\t\t}\n\t\treturn Wrap(any.val.Index(firstPath).Interface())\n\tcase int32:\n\t\tif '*' == firstPath {\n\t\t\tmappedAll := make([]Any, 0)\n\t\t\tfor i := 0; i < any.val.Len(); i++ {\n\t\t\t\tmapped := Wrap(any.val.Index(i).Interface()).Get(path[1:]...)\n\t\t\t\tif mapped.ValueType() != InvalidValue {\n\t\t\t\t\tmappedAll = append(mappedAll, mapped)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn wrapArray(mappedAll)\n\t\t}\n\t\treturn newInvalidAny(path)\n\tdefault:\n\t\treturn newInvalidAny(path)\n\t}\n}\n\nfunc (any *arrayAny) Size() int {\n\treturn any.val.Len()\n}\n\nfunc (any *arrayAny) WriteTo(stream *Stream) {\n\tstream.WriteVal(any.val)\n}\n\nfunc (any *arrayAny) GetInterface() interface{} {\n\treturn any.val.Interface()\n}\n"
        },
        {
          "name": "any_bool.go",
          "type": "blob",
          "size": 1.837890625,
          "content": "package jsoniter\n\ntype trueAny struct {\n\tbaseAny\n}\n\nfunc (any *trueAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *trueAny) ToBool() bool {\n\treturn true\n}\n\nfunc (any *trueAny) ToInt() int {\n\treturn 1\n}\n\nfunc (any *trueAny) ToInt32() int32 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToInt64() int64 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToUint() uint {\n\treturn 1\n}\n\nfunc (any *trueAny) ToUint32() uint32 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToUint64() uint64 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToFloat32() float32 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToFloat64() float64 {\n\treturn 1\n}\n\nfunc (any *trueAny) ToString() string {\n\treturn \"true\"\n}\n\nfunc (any *trueAny) WriteTo(stream *Stream) {\n\tstream.WriteTrue()\n}\n\nfunc (any *trueAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *trueAny) GetInterface() interface{} {\n\treturn true\n}\n\nfunc (any *trueAny) ValueType() ValueType {\n\treturn BoolValue\n}\n\nfunc (any *trueAny) MustBeValid() Any {\n\treturn any\n}\n\ntype falseAny struct {\n\tbaseAny\n}\n\nfunc (any *falseAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *falseAny) ToBool() bool {\n\treturn false\n}\n\nfunc (any *falseAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *falseAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *falseAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *falseAny) ToString() string {\n\treturn \"false\"\n}\n\nfunc (any *falseAny) WriteTo(stream *Stream) {\n\tstream.WriteFalse()\n}\n\nfunc (any *falseAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *falseAny) GetInterface() interface{} {\n\treturn false\n}\n\nfunc (any *falseAny) ValueType() ValueType {\n\treturn BoolValue\n}\n\nfunc (any *falseAny) MustBeValid() Any {\n\treturn any\n}\n"
        },
        {
          "name": "any_float.go",
          "type": "blob",
          "size": 1.22265625,
          "content": "package jsoniter\n\nimport (\n\t\"strconv\"\n)\n\ntype floatAny struct {\n\tbaseAny\n\tval float64\n}\n\nfunc (any *floatAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *floatAny) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *floatAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *floatAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *floatAny) ToBool() bool {\n\treturn any.ToFloat64() != 0\n}\n\nfunc (any *floatAny) ToInt() int {\n\treturn int(any.val)\n}\n\nfunc (any *floatAny) ToInt32() int32 {\n\treturn int32(any.val)\n}\n\nfunc (any *floatAny) ToInt64() int64 {\n\treturn int64(any.val)\n}\n\nfunc (any *floatAny) ToUint() uint {\n\tif any.val > 0 {\n\t\treturn uint(any.val)\n\t}\n\treturn 0\n}\n\nfunc (any *floatAny) ToUint32() uint32 {\n\tif any.val > 0 {\n\t\treturn uint32(any.val)\n\t}\n\treturn 0\n}\n\nfunc (any *floatAny) ToUint64() uint64 {\n\tif any.val > 0 {\n\t\treturn uint64(any.val)\n\t}\n\treturn 0\n}\n\nfunc (any *floatAny) ToFloat32() float32 {\n\treturn float32(any.val)\n}\n\nfunc (any *floatAny) ToFloat64() float64 {\n\treturn any.val\n}\n\nfunc (any *floatAny) ToString() string {\n\treturn strconv.FormatFloat(any.val, 'E', -1, 64)\n}\n\nfunc (any *floatAny) WriteTo(stream *Stream) {\n\tstream.WriteFloat64(any.val)\n}\n\nfunc (any *floatAny) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "any_int32.go",
          "type": "blob",
          "size": 1.115234375,
          "content": "package jsoniter\n\nimport (\n\t\"strconv\"\n)\n\ntype int32Any struct {\n\tbaseAny\n\tval int32\n}\n\nfunc (any *int32Any) LastError() error {\n\treturn nil\n}\n\nfunc (any *int32Any) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *int32Any) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *int32Any) ToBool() bool {\n\treturn any.val != 0\n}\n\nfunc (any *int32Any) ToInt() int {\n\treturn int(any.val)\n}\n\nfunc (any *int32Any) ToInt32() int32 {\n\treturn any.val\n}\n\nfunc (any *int32Any) ToInt64() int64 {\n\treturn int64(any.val)\n}\n\nfunc (any *int32Any) ToUint() uint {\n\treturn uint(any.val)\n}\n\nfunc (any *int32Any) ToUint32() uint32 {\n\treturn uint32(any.val)\n}\n\nfunc (any *int32Any) ToUint64() uint64 {\n\treturn uint64(any.val)\n}\n\nfunc (any *int32Any) ToFloat32() float32 {\n\treturn float32(any.val)\n}\n\nfunc (any *int32Any) ToFloat64() float64 {\n\treturn float64(any.val)\n}\n\nfunc (any *int32Any) ToString() string {\n\treturn strconv.FormatInt(int64(any.val), 10)\n}\n\nfunc (any *int32Any) WriteTo(stream *Stream) {\n\tstream.WriteInt32(any.val)\n}\n\nfunc (any *int32Any) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *int32Any) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "any_int64.go",
          "type": "blob",
          "size": 1.1083984375,
          "content": "package jsoniter\n\nimport (\n\t\"strconv\"\n)\n\ntype int64Any struct {\n\tbaseAny\n\tval int64\n}\n\nfunc (any *int64Any) LastError() error {\n\treturn nil\n}\n\nfunc (any *int64Any) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *int64Any) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *int64Any) ToBool() bool {\n\treturn any.val != 0\n}\n\nfunc (any *int64Any) ToInt() int {\n\treturn int(any.val)\n}\n\nfunc (any *int64Any) ToInt32() int32 {\n\treturn int32(any.val)\n}\n\nfunc (any *int64Any) ToInt64() int64 {\n\treturn any.val\n}\n\nfunc (any *int64Any) ToUint() uint {\n\treturn uint(any.val)\n}\n\nfunc (any *int64Any) ToUint32() uint32 {\n\treturn uint32(any.val)\n}\n\nfunc (any *int64Any) ToUint64() uint64 {\n\treturn uint64(any.val)\n}\n\nfunc (any *int64Any) ToFloat32() float32 {\n\treturn float32(any.val)\n}\n\nfunc (any *int64Any) ToFloat64() float64 {\n\treturn float64(any.val)\n}\n\nfunc (any *int64Any) ToString() string {\n\treturn strconv.FormatInt(any.val, 10)\n}\n\nfunc (any *int64Any) WriteTo(stream *Stream) {\n\tstream.WriteInt64(any.val)\n}\n\nfunc (any *int64Any) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *int64Any) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "any_invalid.go",
          "type": "blob",
          "size": 1.330078125,
          "content": "package jsoniter\n\nimport \"fmt\"\n\ntype invalidAny struct {\n\tbaseAny\n\terr error\n}\n\nfunc newInvalidAny(path []interface{}) *invalidAny {\n\treturn &invalidAny{baseAny{}, fmt.Errorf(\"%v not found\", path)}\n}\n\nfunc (any *invalidAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *invalidAny) ValueType() ValueType {\n\treturn InvalidValue\n}\n\nfunc (any *invalidAny) MustBeValid() Any {\n\tpanic(any.err)\n}\n\nfunc (any *invalidAny) ToBool() bool {\n\treturn false\n}\n\nfunc (any *invalidAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *invalidAny) ToString() string {\n\treturn \"\"\n}\n\nfunc (any *invalidAny) WriteTo(stream *Stream) {\n}\n\nfunc (any *invalidAny) Get(path ...interface{}) Any {\n\tif any.err == nil {\n\t\treturn &invalidAny{baseAny{}, fmt.Errorf(\"get %v from invalid\", path)}\n\t}\n\treturn &invalidAny{baseAny{}, fmt.Errorf(\"%v, get %v from invalid\", any.err, path)}\n}\n\nfunc (any *invalidAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *invalidAny) GetInterface() interface{} {\n\treturn nil\n}\n"
        },
        {
          "name": "any_nil.go",
          "type": "blob",
          "size": 0.89453125,
          "content": "package jsoniter\n\ntype nilAny struct {\n\tbaseAny\n}\n\nfunc (any *nilAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *nilAny) ValueType() ValueType {\n\treturn NilValue\n}\n\nfunc (any *nilAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *nilAny) ToBool() bool {\n\treturn false\n}\n\nfunc (any *nilAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *nilAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *nilAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *nilAny) ToString() string {\n\treturn \"\"\n}\n\nfunc (any *nilAny) WriteTo(stream *Stream) {\n\tstream.WriteNil()\n}\n\nfunc (any *nilAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *nilAny) GetInterface() interface{} {\n\treturn nil\n}\n"
        },
        {
          "name": "any_number.go",
          "type": "blob",
          "size": 2.5546875,
          "content": "package jsoniter\n\nimport (\n\t\"io\"\n\t\"unsafe\"\n)\n\ntype numberLazyAny struct {\n\tbaseAny\n\tcfg *frozenConfig\n\tbuf []byte\n\terr error\n}\n\nfunc (any *numberLazyAny) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *numberLazyAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *numberLazyAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *numberLazyAny) ToBool() bool {\n\treturn any.ToFloat64() != 0\n}\n\nfunc (any *numberLazyAny) ToInt() int {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadInt()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToInt32() int32 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadInt32()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToInt64() int64 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadInt64()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToUint() uint {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadUint()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToUint32() uint32 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadUint32()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToUint64() uint64 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadUint64()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToFloat32() float32 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadFloat32()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToFloat64() float64 {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\tval := iter.ReadFloat64()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\tany.err = iter.Error\n\t}\n\treturn val\n}\n\nfunc (any *numberLazyAny) ToString() string {\n\treturn *(*string)(unsafe.Pointer(&any.buf))\n}\n\nfunc (any *numberLazyAny) WriteTo(stream *Stream) {\n\tstream.Write(any.buf)\n}\n\nfunc (any *numberLazyAny) GetInterface() interface{} {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\treturn iter.Read()\n}\n"
        },
        {
          "name": "any_object.go",
          "type": "blob",
          "size": 6.7744140625,
          "content": "package jsoniter\n\nimport (\n\t\"reflect\"\n\t\"unsafe\"\n)\n\ntype objectLazyAny struct {\n\tbaseAny\n\tcfg *frozenConfig\n\tbuf []byte\n\terr error\n}\n\nfunc (any *objectLazyAny) ValueType() ValueType {\n\treturn ObjectValue\n}\n\nfunc (any *objectLazyAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *objectLazyAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *objectLazyAny) ToBool() bool {\n\treturn true\n}\n\nfunc (any *objectLazyAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *objectLazyAny) ToString() string {\n\treturn *(*string)(unsafe.Pointer(&any.buf))\n}\n\nfunc (any *objectLazyAny) ToVal(obj interface{}) {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\titer.ReadVal(obj)\n}\n\nfunc (any *objectLazyAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\tswitch firstPath := path[0].(type) {\n\tcase string:\n\t\titer := any.cfg.BorrowIterator(any.buf)\n\t\tdefer any.cfg.ReturnIterator(iter)\n\t\tvalueBytes := locateObjectField(iter, firstPath)\n\t\tif valueBytes == nil {\n\t\t\treturn newInvalidAny(path)\n\t\t}\n\t\titer.ResetBytes(valueBytes)\n\t\treturn locatePath(iter, path[1:])\n\tcase int32:\n\t\tif '*' == firstPath {\n\t\t\tmappedAll := map[string]Any{}\n\t\t\titer := any.cfg.BorrowIterator(any.buf)\n\t\t\tdefer any.cfg.ReturnIterator(iter)\n\t\t\titer.ReadMapCB(func(iter *Iterator, field string) bool {\n\t\t\t\tmapped := locatePath(iter, path[1:])\n\t\t\t\tif mapped.ValueType() != InvalidValue {\n\t\t\t\t\tmappedAll[field] = mapped\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t})\n\t\t\treturn wrapMap(mappedAll)\n\t\t}\n\t\treturn newInvalidAny(path)\n\tdefault:\n\t\treturn newInvalidAny(path)\n\t}\n}\n\nfunc (any *objectLazyAny) Keys() []string {\n\tkeys := []string{}\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\titer.ReadMapCB(func(iter *Iterator, field string) bool {\n\t\titer.Skip()\n\t\tkeys = append(keys, field)\n\t\treturn true\n\t})\n\treturn keys\n}\n\nfunc (any *objectLazyAny) Size() int {\n\tsize := 0\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\titer.ReadObjectCB(func(iter *Iterator, field string) bool {\n\t\titer.Skip()\n\t\tsize++\n\t\treturn true\n\t})\n\treturn size\n}\n\nfunc (any *objectLazyAny) WriteTo(stream *Stream) {\n\tstream.Write(any.buf)\n}\n\nfunc (any *objectLazyAny) GetInterface() interface{} {\n\titer := any.cfg.BorrowIterator(any.buf)\n\tdefer any.cfg.ReturnIterator(iter)\n\treturn iter.Read()\n}\n\ntype objectAny struct {\n\tbaseAny\n\terr error\n\tval reflect.Value\n}\n\nfunc wrapStruct(val interface{}) *objectAny {\n\treturn &objectAny{baseAny{}, nil, reflect.ValueOf(val)}\n}\n\nfunc (any *objectAny) ValueType() ValueType {\n\treturn ObjectValue\n}\n\nfunc (any *objectAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *objectAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *objectAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *objectAny) ToBool() bool {\n\treturn any.val.NumField() != 0\n}\n\nfunc (any *objectAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *objectAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *objectAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *objectAny) ToString() string {\n\tstr, err := MarshalToString(any.val.Interface())\n\tany.err = err\n\treturn str\n}\n\nfunc (any *objectAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\tswitch firstPath := path[0].(type) {\n\tcase string:\n\t\tfield := any.val.FieldByName(firstPath)\n\t\tif !field.IsValid() {\n\t\t\treturn newInvalidAny(path)\n\t\t}\n\t\treturn Wrap(field.Interface())\n\tcase int32:\n\t\tif '*' == firstPath {\n\t\t\tmappedAll := map[string]Any{}\n\t\t\tfor i := 0; i < any.val.NumField(); i++ {\n\t\t\t\tfield := any.val.Field(i)\n\t\t\t\tif field.CanInterface() {\n\t\t\t\t\tmapped := Wrap(field.Interface()).Get(path[1:]...)\n\t\t\t\t\tif mapped.ValueType() != InvalidValue {\n\t\t\t\t\t\tmappedAll[any.val.Type().Field(i).Name] = mapped\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn wrapMap(mappedAll)\n\t\t}\n\t\treturn newInvalidAny(path)\n\tdefault:\n\t\treturn newInvalidAny(path)\n\t}\n}\n\nfunc (any *objectAny) Keys() []string {\n\tkeys := make([]string, 0, any.val.NumField())\n\tfor i := 0; i < any.val.NumField(); i++ {\n\t\tkeys = append(keys, any.val.Type().Field(i).Name)\n\t}\n\treturn keys\n}\n\nfunc (any *objectAny) Size() int {\n\treturn any.val.NumField()\n}\n\nfunc (any *objectAny) WriteTo(stream *Stream) {\n\tstream.WriteVal(any.val)\n}\n\nfunc (any *objectAny) GetInterface() interface{} {\n\treturn any.val.Interface()\n}\n\ntype mapAny struct {\n\tbaseAny\n\terr error\n\tval reflect.Value\n}\n\nfunc wrapMap(val interface{}) *mapAny {\n\treturn &mapAny{baseAny{}, nil, reflect.ValueOf(val)}\n}\n\nfunc (any *mapAny) ValueType() ValueType {\n\treturn ObjectValue\n}\n\nfunc (any *mapAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *mapAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *mapAny) LastError() error {\n\treturn any.err\n}\n\nfunc (any *mapAny) ToBool() bool {\n\treturn true\n}\n\nfunc (any *mapAny) ToInt() int {\n\treturn 0\n}\n\nfunc (any *mapAny) ToInt32() int32 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToInt64() int64 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToUint() uint {\n\treturn 0\n}\n\nfunc (any *mapAny) ToUint32() uint32 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToUint64() uint64 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToFloat32() float32 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToFloat64() float64 {\n\treturn 0\n}\n\nfunc (any *mapAny) ToString() string {\n\tstr, err := MarshalToString(any.val.Interface())\n\tany.err = err\n\treturn str\n}\n\nfunc (any *mapAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\tswitch firstPath := path[0].(type) {\n\tcase int32:\n\t\tif '*' == firstPath {\n\t\t\tmappedAll := map[string]Any{}\n\t\t\tfor _, key := range any.val.MapKeys() {\n\t\t\t\tkeyAsStr := key.String()\n\t\t\t\telement := Wrap(any.val.MapIndex(key).Interface())\n\t\t\t\tmapped := element.Get(path[1:]...)\n\t\t\t\tif mapped.ValueType() != InvalidValue {\n\t\t\t\t\tmappedAll[keyAsStr] = mapped\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn wrapMap(mappedAll)\n\t\t}\n\t\treturn newInvalidAny(path)\n\tdefault:\n\t\tvalue := any.val.MapIndex(reflect.ValueOf(firstPath))\n\t\tif !value.IsValid() {\n\t\t\treturn newInvalidAny(path)\n\t\t}\n\t\treturn Wrap(value.Interface())\n\t}\n}\n\nfunc (any *mapAny) Keys() []string {\n\tkeys := make([]string, 0, any.val.Len())\n\tfor _, key := range any.val.MapKeys() {\n\t\tkeys = append(keys, key.String())\n\t}\n\treturn keys\n}\n\nfunc (any *mapAny) Size() int {\n\treturn any.val.Len()\n}\n\nfunc (any *mapAny) WriteTo(stream *Stream) {\n\tstream.WriteVal(any.val)\n}\n\nfunc (any *mapAny) GetInterface() interface{} {\n\treturn any.val.Interface()\n}\n"
        },
        {
          "name": "any_str.go",
          "type": "blob",
          "size": 2.8251953125,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\ntype stringAny struct {\n\tbaseAny\n\tval string\n}\n\nfunc (any *stringAny) Get(path ...interface{}) Any {\n\tif len(path) == 0 {\n\t\treturn any\n\t}\n\treturn &invalidAny{baseAny{}, fmt.Errorf(\"GetIndex %v from simple value\", path)}\n}\n\nfunc (any *stringAny) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *stringAny) ValueType() ValueType {\n\treturn StringValue\n}\n\nfunc (any *stringAny) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *stringAny) LastError() error {\n\treturn nil\n}\n\nfunc (any *stringAny) ToBool() bool {\n\tstr := any.ToString()\n\tif str == \"0\" {\n\t\treturn false\n\t}\n\tfor _, c := range str {\n\t\tswitch c {\n\t\tcase ' ', '\\n', '\\r', '\\t':\n\t\tdefault:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (any *stringAny) ToInt() int {\n\treturn int(any.ToInt64())\n\n}\n\nfunc (any *stringAny) ToInt32() int32 {\n\treturn int32(any.ToInt64())\n}\n\nfunc (any *stringAny) ToInt64() int64 {\n\tif any.val == \"\" {\n\t\treturn 0\n\t}\n\n\tflag := 1\n\tstartPos := 0\n\tif any.val[0] == '+' || any.val[0] == '-' {\n\t\tstartPos = 1\n\t}\n\n\tif any.val[0] == '-' {\n\t\tflag = -1\n\t}\n\n\tendPos := startPos\n\tfor i := startPos; i < len(any.val); i++ {\n\t\tif any.val[i] >= '0' && any.val[i] <= '9' {\n\t\t\tendPos = i + 1\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\tparsed, _ := strconv.ParseInt(any.val[startPos:endPos], 10, 64)\n\treturn int64(flag) * parsed\n}\n\nfunc (any *stringAny) ToUint() uint {\n\treturn uint(any.ToUint64())\n}\n\nfunc (any *stringAny) ToUint32() uint32 {\n\treturn uint32(any.ToUint64())\n}\n\nfunc (any *stringAny) ToUint64() uint64 {\n\tif any.val == \"\" {\n\t\treturn 0\n\t}\n\n\tstartPos := 0\n\n\tif any.val[0] == '-' {\n\t\treturn 0\n\t}\n\tif any.val[0] == '+' {\n\t\tstartPos = 1\n\t}\n\n\tendPos := startPos\n\tfor i := startPos; i < len(any.val); i++ {\n\t\tif any.val[i] >= '0' && any.val[i] <= '9' {\n\t\t\tendPos = i + 1\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\tparsed, _ := strconv.ParseUint(any.val[startPos:endPos], 10, 64)\n\treturn parsed\n}\n\nfunc (any *stringAny) ToFloat32() float32 {\n\treturn float32(any.ToFloat64())\n}\n\nfunc (any *stringAny) ToFloat64() float64 {\n\tif len(any.val) == 0 {\n\t\treturn 0\n\t}\n\n\t// first char invalid\n\tif any.val[0] != '+' && any.val[0] != '-' && (any.val[0] > '9' || any.val[0] < '0') {\n\t\treturn 0\n\t}\n\n\t// extract valid num expression from string\n\t// eg 123true => 123, -12.12xxa => -12.12\n\tendPos := 1\n\tfor i := 1; i < len(any.val); i++ {\n\t\tif any.val[i] == '.' || any.val[i] == 'e' || any.val[i] == 'E' || any.val[i] == '+' || any.val[i] == '-' {\n\t\t\tendPos = i + 1\n\t\t\tcontinue\n\t\t}\n\n\t\t// end position is the first char which is not digit\n\t\tif any.val[i] >= '0' && any.val[i] <= '9' {\n\t\t\tendPos = i + 1\n\t\t} else {\n\t\t\tendPos = i\n\t\t\tbreak\n\t\t}\n\t}\n\tparsed, _ := strconv.ParseFloat(any.val[:endPos], 64)\n\treturn parsed\n}\n\nfunc (any *stringAny) ToString() string {\n\treturn any.val\n}\n\nfunc (any *stringAny) WriteTo(stream *Stream) {\n\tstream.WriteString(any.val)\n}\n\nfunc (any *stringAny) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "any_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "any_uint32.go",
          "type": "blob",
          "size": 1.1328125,
          "content": "package jsoniter\n\nimport (\n\t\"strconv\"\n)\n\ntype uint32Any struct {\n\tbaseAny\n\tval uint32\n}\n\nfunc (any *uint32Any) LastError() error {\n\treturn nil\n}\n\nfunc (any *uint32Any) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *uint32Any) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *uint32Any) ToBool() bool {\n\treturn any.val != 0\n}\n\nfunc (any *uint32Any) ToInt() int {\n\treturn int(any.val)\n}\n\nfunc (any *uint32Any) ToInt32() int32 {\n\treturn int32(any.val)\n}\n\nfunc (any *uint32Any) ToInt64() int64 {\n\treturn int64(any.val)\n}\n\nfunc (any *uint32Any) ToUint() uint {\n\treturn uint(any.val)\n}\n\nfunc (any *uint32Any) ToUint32() uint32 {\n\treturn any.val\n}\n\nfunc (any *uint32Any) ToUint64() uint64 {\n\treturn uint64(any.val)\n}\n\nfunc (any *uint32Any) ToFloat32() float32 {\n\treturn float32(any.val)\n}\n\nfunc (any *uint32Any) ToFloat64() float64 {\n\treturn float64(any.val)\n}\n\nfunc (any *uint32Any) ToString() string {\n\treturn strconv.FormatInt(int64(any.val), 10)\n}\n\nfunc (any *uint32Any) WriteTo(stream *Stream) {\n\tstream.WriteUint32(any.val)\n}\n\nfunc (any *uint32Any) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *uint32Any) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "any_uint64.go",
          "type": "blob",
          "size": 1.126953125,
          "content": "package jsoniter\n\nimport (\n\t\"strconv\"\n)\n\ntype uint64Any struct {\n\tbaseAny\n\tval uint64\n}\n\nfunc (any *uint64Any) LastError() error {\n\treturn nil\n}\n\nfunc (any *uint64Any) ValueType() ValueType {\n\treturn NumberValue\n}\n\nfunc (any *uint64Any) MustBeValid() Any {\n\treturn any\n}\n\nfunc (any *uint64Any) ToBool() bool {\n\treturn any.val != 0\n}\n\nfunc (any *uint64Any) ToInt() int {\n\treturn int(any.val)\n}\n\nfunc (any *uint64Any) ToInt32() int32 {\n\treturn int32(any.val)\n}\n\nfunc (any *uint64Any) ToInt64() int64 {\n\treturn int64(any.val)\n}\n\nfunc (any *uint64Any) ToUint() uint {\n\treturn uint(any.val)\n}\n\nfunc (any *uint64Any) ToUint32() uint32 {\n\treturn uint32(any.val)\n}\n\nfunc (any *uint64Any) ToUint64() uint64 {\n\treturn any.val\n}\n\nfunc (any *uint64Any) ToFloat32() float32 {\n\treturn float32(any.val)\n}\n\nfunc (any *uint64Any) ToFloat64() float64 {\n\treturn float64(any.val)\n}\n\nfunc (any *uint64Any) ToString() string {\n\treturn strconv.FormatUint(any.val, 10)\n}\n\nfunc (any *uint64Any) WriteTo(stream *Stream) {\n\tstream.WriteUint64(any.val)\n}\n\nfunc (any *uint64Any) Parse() *Iterator {\n\treturn nil\n}\n\nfunc (any *uint64Any) GetInterface() interface{} {\n\treturn any.val\n}\n"
        },
        {
          "name": "api_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.3720703125,
          "content": "#!/bin/bash\nset -e\nset -x\n\nif [ ! -d /tmp/build-golang/src/github.com/json-iterator ]; then\n    mkdir -p /tmp/build-golang/src/github.com/json-iterator\n    ln -s $PWD /tmp/build-golang/src/github.com/json-iterator/go\nfi\nexport GOPATH=/tmp/build-golang\ngo get -u github.com/golang/dep/cmd/dep\ncd /tmp/build-golang/src/github.com/json-iterator/go\nexec $GOPATH/bin/dep ensure -update\n"
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 10.2978515625,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/json\"\n\t\"io\"\n\t\"reflect\"\n\t\"sync\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/concurrent\"\n\t\"github.com/modern-go/reflect2\"\n)\n\n// Config customize how the API should behave.\n// The API is created from Config by Froze.\ntype Config struct {\n\tIndentionStep                 int\n\tMarshalFloatWith6Digits       bool\n\tEscapeHTML                    bool\n\tSortMapKeys                   bool\n\tUseNumber                     bool\n\tDisallowUnknownFields         bool\n\tTagKey                        string\n\tOnlyTaggedField               bool\n\tValidateJsonRawMessage        bool\n\tObjectFieldMustBeSimpleString bool\n\tCaseSensitive                 bool\n}\n\n// API the public interface of this package.\n// Primary Marshal and Unmarshal.\ntype API interface {\n\tIteratorPool\n\tStreamPool\n\tMarshalToString(v interface{}) (string, error)\n\tMarshal(v interface{}) ([]byte, error)\n\tMarshalIndent(v interface{}, prefix, indent string) ([]byte, error)\n\tUnmarshalFromString(str string, v interface{}) error\n\tUnmarshal(data []byte, v interface{}) error\n\tGet(data []byte, path ...interface{}) Any\n\tNewEncoder(writer io.Writer) *Encoder\n\tNewDecoder(reader io.Reader) *Decoder\n\tValid(data []byte) bool\n\tRegisterExtension(extension Extension)\n\tDecoderOf(typ reflect2.Type) ValDecoder\n\tEncoderOf(typ reflect2.Type) ValEncoder\n}\n\n// ConfigDefault the default API\nvar ConfigDefault = Config{\n\tEscapeHTML: true,\n}.Froze()\n\n// ConfigCompatibleWithStandardLibrary tries to be 100% compatible with standard library behavior\nvar ConfigCompatibleWithStandardLibrary = Config{\n\tEscapeHTML:             true,\n\tSortMapKeys:            true,\n\tValidateJsonRawMessage: true,\n}.Froze()\n\n// ConfigFastest marshals float with only 6 digits precision\nvar ConfigFastest = Config{\n\tEscapeHTML:                    false,\n\tMarshalFloatWith6Digits:       true, // will lose precession\n\tObjectFieldMustBeSimpleString: true, // do not unescape object field\n}.Froze()\n\ntype frozenConfig struct {\n\tconfigBeforeFrozen            Config\n\tsortMapKeys                   bool\n\tindentionStep                 int\n\tobjectFieldMustBeSimpleString bool\n\tonlyTaggedField               bool\n\tdisallowUnknownFields         bool\n\tdecoderCache                  *concurrent.Map\n\tencoderCache                  *concurrent.Map\n\tencoderExtension              Extension\n\tdecoderExtension              Extension\n\textraExtensions               []Extension\n\tstreamPool                    *sync.Pool\n\titeratorPool                  *sync.Pool\n\tcaseSensitive                 bool\n}\n\nfunc (cfg *frozenConfig) initCache() {\n\tcfg.decoderCache = concurrent.NewMap()\n\tcfg.encoderCache = concurrent.NewMap()\n}\n\nfunc (cfg *frozenConfig) addDecoderToCache(cacheKey uintptr, decoder ValDecoder) {\n\tcfg.decoderCache.Store(cacheKey, decoder)\n}\n\nfunc (cfg *frozenConfig) addEncoderToCache(cacheKey uintptr, encoder ValEncoder) {\n\tcfg.encoderCache.Store(cacheKey, encoder)\n}\n\nfunc (cfg *frozenConfig) getDecoderFromCache(cacheKey uintptr) ValDecoder {\n\tdecoder, found := cfg.decoderCache.Load(cacheKey)\n\tif found {\n\t\treturn decoder.(ValDecoder)\n\t}\n\treturn nil\n}\n\nfunc (cfg *frozenConfig) getEncoderFromCache(cacheKey uintptr) ValEncoder {\n\tencoder, found := cfg.encoderCache.Load(cacheKey)\n\tif found {\n\t\treturn encoder.(ValEncoder)\n\t}\n\treturn nil\n}\n\nvar cfgCache = concurrent.NewMap()\n\nfunc getFrozenConfigFromCache(cfg Config) *frozenConfig {\n\tobj, found := cfgCache.Load(cfg)\n\tif found {\n\t\treturn obj.(*frozenConfig)\n\t}\n\treturn nil\n}\n\nfunc addFrozenConfigToCache(cfg Config, frozenConfig *frozenConfig) {\n\tcfgCache.Store(cfg, frozenConfig)\n}\n\n// Froze forge API from config\nfunc (cfg Config) Froze() API {\n\tapi := &frozenConfig{\n\t\tsortMapKeys:                   cfg.SortMapKeys,\n\t\tindentionStep:                 cfg.IndentionStep,\n\t\tobjectFieldMustBeSimpleString: cfg.ObjectFieldMustBeSimpleString,\n\t\tonlyTaggedField:               cfg.OnlyTaggedField,\n\t\tdisallowUnknownFields:         cfg.DisallowUnknownFields,\n\t\tcaseSensitive:                 cfg.CaseSensitive,\n\t}\n\tapi.streamPool = &sync.Pool{\n\t\tNew: func() interface{} {\n\t\t\treturn NewStream(api, nil, 512)\n\t\t},\n\t}\n\tapi.iteratorPool = &sync.Pool{\n\t\tNew: func() interface{} {\n\t\t\treturn NewIterator(api)\n\t\t},\n\t}\n\tapi.initCache()\n\tencoderExtension := EncoderExtension{}\n\tdecoderExtension := DecoderExtension{}\n\tif cfg.MarshalFloatWith6Digits {\n\t\tapi.marshalFloatWith6Digits(encoderExtension)\n\t}\n\tif cfg.EscapeHTML {\n\t\tapi.escapeHTML(encoderExtension)\n\t}\n\tif cfg.UseNumber {\n\t\tapi.useNumber(decoderExtension)\n\t}\n\tif cfg.ValidateJsonRawMessage {\n\t\tapi.validateJsonRawMessage(encoderExtension)\n\t}\n\tapi.encoderExtension = encoderExtension\n\tapi.decoderExtension = decoderExtension\n\tapi.configBeforeFrozen = cfg\n\treturn api\n}\n\nfunc (cfg Config) frozeWithCacheReuse(extraExtensions []Extension) *frozenConfig {\n\tapi := getFrozenConfigFromCache(cfg)\n\tif api != nil {\n\t\treturn api\n\t}\n\tapi = cfg.Froze().(*frozenConfig)\n\tfor _, extension := range extraExtensions {\n\t\tapi.RegisterExtension(extension)\n\t}\n\taddFrozenConfigToCache(cfg, api)\n\treturn api\n}\n\nfunc (cfg *frozenConfig) validateJsonRawMessage(extension EncoderExtension) {\n\tencoder := &funcEncoder{func(ptr unsafe.Pointer, stream *Stream) {\n\t\trawMessage := *(*json.RawMessage)(ptr)\n\t\titer := cfg.BorrowIterator([]byte(rawMessage))\n\t\tdefer cfg.ReturnIterator(iter)\n\t\titer.Read()\n\t\tif iter.Error != nil && iter.Error != io.EOF {\n\t\t\tstream.WriteRaw(\"null\")\n\t\t} else {\n\t\t\tstream.WriteRaw(string(rawMessage))\n\t\t}\n\t}, func(ptr unsafe.Pointer) bool {\n\t\treturn len(*((*json.RawMessage)(ptr))) == 0\n\t}}\n\textension[reflect2.TypeOfPtr((*json.RawMessage)(nil)).Elem()] = encoder\n\textension[reflect2.TypeOfPtr((*RawMessage)(nil)).Elem()] = encoder\n}\n\nfunc (cfg *frozenConfig) useNumber(extension DecoderExtension) {\n\textension[reflect2.TypeOfPtr((*interface{})(nil)).Elem()] = &funcDecoder{func(ptr unsafe.Pointer, iter *Iterator) {\n\t\texitingValue := *((*interface{})(ptr))\n\t\tif exitingValue != nil && reflect.TypeOf(exitingValue).Kind() == reflect.Ptr {\n\t\t\titer.ReadVal(exitingValue)\n\t\t\treturn\n\t\t}\n\t\tif iter.WhatIsNext() == NumberValue {\n\t\t\t*((*interface{})(ptr)) = json.Number(iter.readNumberAsString())\n\t\t} else {\n\t\t\t*((*interface{})(ptr)) = iter.Read()\n\t\t}\n\t}}\n}\nfunc (cfg *frozenConfig) getTagKey() string {\n\ttagKey := cfg.configBeforeFrozen.TagKey\n\tif tagKey == \"\" {\n\t\treturn \"json\"\n\t}\n\treturn tagKey\n}\n\nfunc (cfg *frozenConfig) RegisterExtension(extension Extension) {\n\tcfg.extraExtensions = append(cfg.extraExtensions, extension)\n\tcopied := cfg.configBeforeFrozen\n\tcfg.configBeforeFrozen = copied\n}\n\ntype lossyFloat32Encoder struct {\n}\n\nfunc (encoder *lossyFloat32Encoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteFloat32Lossy(*((*float32)(ptr)))\n}\n\nfunc (encoder *lossyFloat32Encoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*float32)(ptr)) == 0\n}\n\ntype lossyFloat64Encoder struct {\n}\n\nfunc (encoder *lossyFloat64Encoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteFloat64Lossy(*((*float64)(ptr)))\n}\n\nfunc (encoder *lossyFloat64Encoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*float64)(ptr)) == 0\n}\n\n// EnableLossyFloatMarshalling keeps 10**(-6) precision\n// for float variables for better performance.\nfunc (cfg *frozenConfig) marshalFloatWith6Digits(extension EncoderExtension) {\n\t// for better performance\n\textension[reflect2.TypeOfPtr((*float32)(nil)).Elem()] = &lossyFloat32Encoder{}\n\textension[reflect2.TypeOfPtr((*float64)(nil)).Elem()] = &lossyFloat64Encoder{}\n}\n\ntype htmlEscapedStringEncoder struct {\n}\n\nfunc (encoder *htmlEscapedStringEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstr := *((*string)(ptr))\n\tstream.WriteStringWithHTMLEscaped(str)\n}\n\nfunc (encoder *htmlEscapedStringEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*string)(ptr)) == \"\"\n}\n\nfunc (cfg *frozenConfig) escapeHTML(encoderExtension EncoderExtension) {\n\tencoderExtension[reflect2.TypeOfPtr((*string)(nil)).Elem()] = &htmlEscapedStringEncoder{}\n}\n\nfunc (cfg *frozenConfig) cleanDecoders() {\n\ttypeDecoders = map[string]ValDecoder{}\n\tfieldDecoders = map[string]ValDecoder{}\n\t*cfg = *(cfg.configBeforeFrozen.Froze().(*frozenConfig))\n}\n\nfunc (cfg *frozenConfig) cleanEncoders() {\n\ttypeEncoders = map[string]ValEncoder{}\n\tfieldEncoders = map[string]ValEncoder{}\n\t*cfg = *(cfg.configBeforeFrozen.Froze().(*frozenConfig))\n}\n\nfunc (cfg *frozenConfig) MarshalToString(v interface{}) (string, error) {\n\tstream := cfg.BorrowStream(nil)\n\tdefer cfg.ReturnStream(stream)\n\tstream.WriteVal(v)\n\tif stream.Error != nil {\n\t\treturn \"\", stream.Error\n\t}\n\treturn string(stream.Buffer()), nil\n}\n\nfunc (cfg *frozenConfig) Marshal(v interface{}) ([]byte, error) {\n\tstream := cfg.BorrowStream(nil)\n\tdefer cfg.ReturnStream(stream)\n\tstream.WriteVal(v)\n\tif stream.Error != nil {\n\t\treturn nil, stream.Error\n\t}\n\tresult := stream.Buffer()\n\tcopied := make([]byte, len(result))\n\tcopy(copied, result)\n\treturn copied, nil\n}\n\nfunc (cfg *frozenConfig) MarshalIndent(v interface{}, prefix, indent string) ([]byte, error) {\n\tif prefix != \"\" {\n\t\tpanic(\"prefix is not supported\")\n\t}\n\tfor _, r := range indent {\n\t\tif r != ' ' {\n\t\t\tpanic(\"indent can only be space\")\n\t\t}\n\t}\n\tnewCfg := cfg.configBeforeFrozen\n\tnewCfg.IndentionStep = len(indent)\n\treturn newCfg.frozeWithCacheReuse(cfg.extraExtensions).Marshal(v)\n}\n\nfunc (cfg *frozenConfig) UnmarshalFromString(str string, v interface{}) error {\n\tdata := []byte(str)\n\titer := cfg.BorrowIterator(data)\n\tdefer cfg.ReturnIterator(iter)\n\titer.ReadVal(v)\n\tc := iter.nextToken()\n\tif c == 0 {\n\t\tif iter.Error == io.EOF {\n\t\t\treturn nil\n\t\t}\n\t\treturn iter.Error\n\t}\n\titer.ReportError(\"Unmarshal\", \"there are bytes left after unmarshal\")\n\treturn iter.Error\n}\n\nfunc (cfg *frozenConfig) Get(data []byte, path ...interface{}) Any {\n\titer := cfg.BorrowIterator(data)\n\tdefer cfg.ReturnIterator(iter)\n\treturn locatePath(iter, path)\n}\n\nfunc (cfg *frozenConfig) Unmarshal(data []byte, v interface{}) error {\n\titer := cfg.BorrowIterator(data)\n\tdefer cfg.ReturnIterator(iter)\n\titer.ReadVal(v)\n\tc := iter.nextToken()\n\tif c == 0 {\n\t\tif iter.Error == io.EOF {\n\t\t\treturn nil\n\t\t}\n\t\treturn iter.Error\n\t}\n\titer.ReportError(\"Unmarshal\", \"there are bytes left after unmarshal\")\n\treturn iter.Error\n}\n\nfunc (cfg *frozenConfig) NewEncoder(writer io.Writer) *Encoder {\n\tstream := NewStream(cfg, writer, 512)\n\treturn &Encoder{stream}\n}\n\nfunc (cfg *frozenConfig) NewDecoder(reader io.Reader) *Decoder {\n\titer := Parse(cfg, reader, 512)\n\treturn &Decoder{iter}\n}\n\nfunc (cfg *frozenConfig) Valid(data []byte) bool {\n\titer := cfg.BorrowIterator(data)\n\tdefer cfg.ReturnIterator(iter)\n\titer.Skip()\n\treturn iter.Error == nil\n}\n"
        },
        {
          "name": "example_test.go",
          "type": "blob",
          "size": 2.5654296875,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n)\n\nfunc ExampleMarshal() {\n\ttype ColorGroup struct {\n\t\tID     int\n\t\tName   string\n\t\tColors []string\n\t}\n\tgroup := ColorGroup{\n\t\tID:     1,\n\t\tName:   \"Reds\",\n\t\tColors: []string{\"Crimson\", \"Red\", \"Ruby\", \"Maroon\"},\n\t}\n\tb, err := Marshal(group)\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t}\n\tos.Stdout.Write(b)\n\t// Output:\n\t// {\"ID\":1,\"Name\":\"Reds\",\"Colors\":[\"Crimson\",\"Red\",\"Ruby\",\"Maroon\"]}\n}\n\nfunc ExampleUnmarshal() {\n\tvar jsonBlob = []byte(`[\n\t\t{\"Name\": \"Platypus\", \"Order\": \"Monotremata\"},\n\t\t{\"Name\": \"Quoll\",    \"Order\": \"Dasyuromorphia\"}\n\t]`)\n\ttype Animal struct {\n\t\tName  string\n\t\tOrder string\n\t}\n\tvar animals []Animal\n\terr := Unmarshal(jsonBlob, &animals)\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t}\n\tfmt.Printf(\"%+v\", animals)\n\t// Output:\n\t// [{Name:Platypus Order:Monotremata} {Name:Quoll Order:Dasyuromorphia}]\n}\n\nfunc ExampleConfigFastest_Marshal() {\n\ttype ColorGroup struct {\n\t\tID     int\n\t\tName   string\n\t\tColors []string\n\t}\n\tgroup := ColorGroup{\n\t\tID:     1,\n\t\tName:   \"Reds\",\n\t\tColors: []string{\"Crimson\", \"Red\", \"Ruby\", \"Maroon\"},\n\t}\n\tstream := ConfigFastest.BorrowStream(nil)\n\tdefer ConfigFastest.ReturnStream(stream)\n\tstream.WriteVal(group)\n\tif stream.Error != nil {\n\t\tfmt.Println(\"error:\", stream.Error)\n\t}\n\tos.Stdout.Write(stream.Buffer())\n\t// Output:\n\t// {\"ID\":1,\"Name\":\"Reds\",\"Colors\":[\"Crimson\",\"Red\",\"Ruby\",\"Maroon\"]}\n}\n\nfunc ExampleConfigFastest_Unmarshal() {\n\tvar jsonBlob = []byte(`[\n\t\t{\"Name\": \"Platypus\", \"Order\": \"Monotremata\"},\n\t\t{\"Name\": \"Quoll\",    \"Order\": \"Dasyuromorphia\"}\n\t]`)\n\ttype Animal struct {\n\t\tName  string\n\t\tOrder string\n\t}\n\tvar animals []Animal\n\titer := ConfigFastest.BorrowIterator(jsonBlob)\n\tdefer ConfigFastest.ReturnIterator(iter)\n\titer.ReadVal(&animals)\n\tif iter.Error != nil {\n\t\tfmt.Println(\"error:\", iter.Error)\n\t}\n\tfmt.Printf(\"%+v\", animals)\n\t// Output:\n\t// [{Name:Platypus Order:Monotremata} {Name:Quoll Order:Dasyuromorphia}]\n}\n\nfunc ExampleGet() {\n\tval := []byte(`{\"ID\":1,\"Name\":\"Reds\",\"Colors\":[\"Crimson\",\"Red\",\"Ruby\",\"Maroon\"]}`)\n\tfmt.Printf(Get(val, \"Colors\", 0).ToString())\n\t// Output:\n\t// Crimson\n}\n\nfunc ExampleMyKey() {\n\thello := MyKey(\"hello\")\n\toutput, _ := Marshal(map[*MyKey]string{&hello: \"world\"})\n\tfmt.Println(string(output))\n\tobj := map[*MyKey]string{}\n\tUnmarshal(output, &obj)\n\tfor k, v := range obj {\n\t\tfmt.Println(*k, v)\n\t}\n\t// Output:\n\t// {\"Hello\":\"world\"}\n\t// Hel world\n}\n\ntype MyKey string\n\nfunc (m *MyKey) MarshalText() ([]byte, error) {\n\treturn []byte(strings.Replace(string(*m), \"h\", \"H\", -1)), nil\n}\n\nfunc (m *MyKey) UnmarshalText(text []byte) error {\n\t*m = MyKey(text[:3])\n\treturn nil\n}\n"
        },
        {
          "name": "extension_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "fuzzy_mode_convert_table.md",
          "type": "blob",
          "size": 0.9052734375,
          "content": "| json type \\ dest type | bool | int | uint | float |string|\n| --- | --- | --- | --- |--|--|\n| number | positive => true <br/> negative => true <br/> zero => false| 23.2 => 23 <br/> -32.1 => -32| 12.1 => 12 <br/> -12.1 => 0|as normal|same as origin|\n| string | empty string => false <br/> string \"0\" => false <br/> other strings => true | \"123.32\" => 123 <br/> \"-123.4\" => -123 <br/> \"123.23xxxw\" => 123 <br/>  \"abcde12\" => 0 <br/> \"-32.1\" => -32| 13.2 => 13 <br/> -1.1 => 0 |12.1 => 12.1 <br/> -12.3 => -12.3<br/> 12.4xxa => 12.4 <br/> +1.1e2 =>110 |same as origin|\n| bool | true => true <br/> false => false| true => 1 <br/> false => 0 | true => 1 <br/> false => 0 |true => 1 <br/>false => 0|true => \"true\" <br/> false => \"false\"|\n| object | true | 0 | 0 |0|originnal json|\n| array | empty array => false <br/> nonempty array => true| [] => 0 <br/> [1,2] => 1 | [] => 0 <br/> [1,2] => 1 |[] => 0<br/>[1,2] => 1|original json|"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.2607421875,
          "content": "module github.com/json-iterator/go\n\ngo 1.12\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/google/gofuzz v1.0.0\n\tgithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421\n\tgithub.com/modern-go/reflect2 v1.0.2\n\tgithub.com/stretchr/testify v1.8.0\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.876953125,
          "content": "github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/google/gofuzz v1.0.0 h1:A8PeW59pxE9IoFRqBp37U+mSNaQoZ46F1f0f863XSXw=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421 h1:ZqeYNhU3OHLH3mGKHDcjJRFFRrJa6eAM5H+CtDdOsPc=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0 h1:pSgiaMZlXftHpm5L7V1+rVB+AZJydKsMxsQBIJw4PKk=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "iter.go",
          "type": "blob",
          "size": 7.7119140625,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n)\n\n// ValueType the type for JSON element\ntype ValueType int\n\nconst (\n\t// InvalidValue invalid JSON element\n\tInvalidValue ValueType = iota\n\t// StringValue JSON element \"string\"\n\tStringValue\n\t// NumberValue JSON element 100 or 0.10\n\tNumberValue\n\t// NilValue JSON element null\n\tNilValue\n\t// BoolValue JSON element true or false\n\tBoolValue\n\t// ArrayValue JSON element []\n\tArrayValue\n\t// ObjectValue JSON element {}\n\tObjectValue\n)\n\nvar hexDigits []byte\nvar valueTypes []ValueType\n\nfunc init() {\n\thexDigits = make([]byte, 256)\n\tfor i := 0; i < len(hexDigits); i++ {\n\t\thexDigits[i] = 255\n\t}\n\tfor i := '0'; i <= '9'; i++ {\n\t\thexDigits[i] = byte(i - '0')\n\t}\n\tfor i := 'a'; i <= 'f'; i++ {\n\t\thexDigits[i] = byte((i - 'a') + 10)\n\t}\n\tfor i := 'A'; i <= 'F'; i++ {\n\t\thexDigits[i] = byte((i - 'A') + 10)\n\t}\n\tvalueTypes = make([]ValueType, 256)\n\tfor i := 0; i < len(valueTypes); i++ {\n\t\tvalueTypes[i] = InvalidValue\n\t}\n\tvalueTypes['\"'] = StringValue\n\tvalueTypes['-'] = NumberValue\n\tvalueTypes['0'] = NumberValue\n\tvalueTypes['1'] = NumberValue\n\tvalueTypes['2'] = NumberValue\n\tvalueTypes['3'] = NumberValue\n\tvalueTypes['4'] = NumberValue\n\tvalueTypes['5'] = NumberValue\n\tvalueTypes['6'] = NumberValue\n\tvalueTypes['7'] = NumberValue\n\tvalueTypes['8'] = NumberValue\n\tvalueTypes['9'] = NumberValue\n\tvalueTypes['t'] = BoolValue\n\tvalueTypes['f'] = BoolValue\n\tvalueTypes['n'] = NilValue\n\tvalueTypes['['] = ArrayValue\n\tvalueTypes['{'] = ObjectValue\n}\n\n// Iterator is a io.Reader like object, with JSON specific read functions.\n// Error is not returned as return value, but stored as Error member on this iterator instance.\ntype Iterator struct {\n\tcfg              *frozenConfig\n\treader           io.Reader\n\tbuf              []byte\n\thead             int\n\ttail             int\n\tdepth            int\n\tcaptureStartedAt int\n\tcaptured         []byte\n\tError            error\n\tAttachment       interface{} // open for customized decoder\n}\n\n// NewIterator creates an empty Iterator instance\nfunc NewIterator(cfg API) *Iterator {\n\treturn &Iterator{\n\t\tcfg:    cfg.(*frozenConfig),\n\t\treader: nil,\n\t\tbuf:    nil,\n\t\thead:   0,\n\t\ttail:   0,\n\t\tdepth:  0,\n\t}\n}\n\n// Parse creates an Iterator instance from io.Reader\nfunc Parse(cfg API, reader io.Reader, bufSize int) *Iterator {\n\treturn &Iterator{\n\t\tcfg:    cfg.(*frozenConfig),\n\t\treader: reader,\n\t\tbuf:    make([]byte, bufSize),\n\t\thead:   0,\n\t\ttail:   0,\n\t\tdepth:  0,\n\t}\n}\n\n// ParseBytes creates an Iterator instance from byte array\nfunc ParseBytes(cfg API, input []byte) *Iterator {\n\treturn &Iterator{\n\t\tcfg:    cfg.(*frozenConfig),\n\t\treader: nil,\n\t\tbuf:    input,\n\t\thead:   0,\n\t\ttail:   len(input),\n\t\tdepth:  0,\n\t}\n}\n\n// ParseString creates an Iterator instance from string\nfunc ParseString(cfg API, input string) *Iterator {\n\treturn ParseBytes(cfg, []byte(input))\n}\n\n// Pool returns a pool can provide more iterator with same configuration\nfunc (iter *Iterator) Pool() IteratorPool {\n\treturn iter.cfg\n}\n\n// Reset reuse iterator instance by specifying another reader\nfunc (iter *Iterator) Reset(reader io.Reader) *Iterator {\n\titer.reader = reader\n\titer.head = 0\n\titer.tail = 0\n\titer.depth = 0\n\treturn iter\n}\n\n// ResetBytes reuse iterator instance by specifying another byte array as input\nfunc (iter *Iterator) ResetBytes(input []byte) *Iterator {\n\titer.reader = nil\n\titer.buf = input\n\titer.head = 0\n\titer.tail = len(input)\n\titer.depth = 0\n\treturn iter\n}\n\n// WhatIsNext gets ValueType of relatively next json element\nfunc (iter *Iterator) WhatIsNext() ValueType {\n\tvalueType := valueTypes[iter.nextToken()]\n\titer.unreadByte()\n\treturn valueType\n}\n\nfunc (iter *Iterator) skipWhitespacesWithoutLoadMore() bool {\n\tfor i := iter.head; i < iter.tail; i++ {\n\t\tc := iter.buf[i]\n\t\tswitch c {\n\t\tcase ' ', '\\n', '\\t', '\\r':\n\t\t\tcontinue\n\t\t}\n\t\titer.head = i\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (iter *Iterator) isObjectEnd() bool {\n\tc := iter.nextToken()\n\tif c == ',' {\n\t\treturn false\n\t}\n\tif c == '}' {\n\t\treturn true\n\t}\n\titer.ReportError(\"isObjectEnd\", \"object ended prematurely, unexpected char \"+string([]byte{c}))\n\treturn true\n}\n\nfunc (iter *Iterator) nextToken() byte {\n\t// a variation of skip whitespaces, returning the next non-whitespace token\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tc := iter.buf[i]\n\t\t\tswitch c {\n\t\t\tcase ' ', '\\n', '\\t', '\\r':\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\titer.head = i + 1\n\t\t\treturn c\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\treturn 0\n\t\t}\n\t}\n}\n\n// ReportError record a error in iterator instance with current position.\nfunc (iter *Iterator) ReportError(operation string, msg string) {\n\tif iter.Error != nil {\n\t\tif iter.Error != io.EOF {\n\t\t\treturn\n\t\t}\n\t}\n\tpeekStart := iter.head - 10\n\tif peekStart < 0 {\n\t\tpeekStart = 0\n\t}\n\tpeekEnd := iter.head + 10\n\tif peekEnd > iter.tail {\n\t\tpeekEnd = iter.tail\n\t}\n\tparsing := string(iter.buf[peekStart:peekEnd])\n\tcontextStart := iter.head - 50\n\tif contextStart < 0 {\n\t\tcontextStart = 0\n\t}\n\tcontextEnd := iter.head + 50\n\tif contextEnd > iter.tail {\n\t\tcontextEnd = iter.tail\n\t}\n\tcontext := string(iter.buf[contextStart:contextEnd])\n\titer.Error = fmt.Errorf(\"%s: %s, error found in #%v byte of ...|%s|..., bigger context ...|%s|...\",\n\t\toperation, msg, iter.head-peekStart, parsing, context)\n}\n\n// CurrentBuffer gets current buffer as string for debugging purpose\nfunc (iter *Iterator) CurrentBuffer() string {\n\tpeekStart := iter.head - 10\n\tif peekStart < 0 {\n\t\tpeekStart = 0\n\t}\n\treturn fmt.Sprintf(\"parsing #%v byte, around ...|%s|..., whole buffer ...|%s|...\", iter.head,\n\t\tstring(iter.buf[peekStart:iter.head]), string(iter.buf[0:iter.tail]))\n}\n\nfunc (iter *Iterator) readByte() (ret byte) {\n\tif iter.head == iter.tail {\n\t\tif iter.loadMore() {\n\t\t\tret = iter.buf[iter.head]\n\t\t\titer.head++\n\t\t\treturn ret\n\t\t}\n\t\treturn 0\n\t}\n\tret = iter.buf[iter.head]\n\titer.head++\n\treturn ret\n}\n\nfunc (iter *Iterator) loadMore() bool {\n\tif iter.reader == nil {\n\t\tif iter.Error == nil {\n\t\t\titer.head = iter.tail\n\t\t\titer.Error = io.EOF\n\t\t}\n\t\treturn false\n\t}\n\tif iter.captured != nil {\n\t\titer.captured = append(iter.captured,\n\t\t\titer.buf[iter.captureStartedAt:iter.tail]...)\n\t\titer.captureStartedAt = 0\n\t}\n\tfor {\n\t\tn, err := iter.reader.Read(iter.buf)\n\t\tif n == 0 {\n\t\t\tif err != nil {\n\t\t\t\tif iter.Error == nil {\n\t\t\t\t\titer.Error = err\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else {\n\t\t\titer.head = 0\n\t\t\titer.tail = n\n\t\t\treturn true\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) unreadByte() {\n\tif iter.Error != nil {\n\t\treturn\n\t}\n\titer.head--\n\treturn\n}\n\n// Read read the next JSON element as generic interface{}.\nfunc (iter *Iterator) Read() interface{} {\n\tvalueType := iter.WhatIsNext()\n\tswitch valueType {\n\tcase StringValue:\n\t\treturn iter.ReadString()\n\tcase NumberValue:\n\t\tif iter.cfg.configBeforeFrozen.UseNumber {\n\t\t\treturn json.Number(iter.readNumberAsString())\n\t\t}\n\t\treturn iter.ReadFloat64()\n\tcase NilValue:\n\t\titer.skipFourBytes('n', 'u', 'l', 'l')\n\t\treturn nil\n\tcase BoolValue:\n\t\treturn iter.ReadBool()\n\tcase ArrayValue:\n\t\tarr := []interface{}{}\n\t\titer.ReadArrayCB(func(iter *Iterator) bool {\n\t\t\tvar elem interface{}\n\t\t\titer.ReadVal(&elem)\n\t\t\tarr = append(arr, elem)\n\t\t\treturn true\n\t\t})\n\t\treturn arr\n\tcase ObjectValue:\n\t\tobj := map[string]interface{}{}\n\t\titer.ReadMapCB(func(Iter *Iterator, field string) bool {\n\t\t\tvar elem interface{}\n\t\t\titer.ReadVal(&elem)\n\t\t\tobj[field] = elem\n\t\t\treturn true\n\t\t})\n\t\treturn obj\n\tdefault:\n\t\titer.ReportError(\"Read\", fmt.Sprintf(\"unexpected value type: %v\", valueType))\n\t\treturn nil\n\t}\n}\n\n// limit maximum depth of nesting, as allowed by https://tools.ietf.org/html/rfc7159#section-9\nconst maxDepth = 10000\n\nfunc (iter *Iterator) incrementDepth() (success bool) {\n\titer.depth++\n\tif iter.depth <= maxDepth {\n\t\treturn true\n\t}\n\titer.ReportError(\"incrementDepth\", \"exceeded max depth\")\n\treturn false\n}\n\nfunc (iter *Iterator) decrementDepth() (success bool) {\n\titer.depth--\n\tif iter.depth >= 0 {\n\t\treturn true\n\t}\n\titer.ReportError(\"decrementDepth\", \"unexpected negative nesting\")\n\treturn false\n}\n"
        },
        {
          "name": "iter_array.go",
          "type": "blob",
          "size": 1.369140625,
          "content": "package jsoniter\n\n// ReadArray read array element, tells if the array has more element to read.\nfunc (iter *Iterator) ReadArray() (ret bool) {\n\tc := iter.nextToken()\n\tswitch c {\n\tcase 'n':\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn false // null\n\tcase '[':\n\t\tc = iter.nextToken()\n\t\tif c != ']' {\n\t\t\titer.unreadByte()\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\tcase ']':\n\t\treturn false\n\tcase ',':\n\t\treturn true\n\tdefault:\n\t\titer.ReportError(\"ReadArray\", \"expect [ or , or ] or n, but found \"+string([]byte{c}))\n\t\treturn\n\t}\n}\n\n// ReadArrayCB read array with callback\nfunc (iter *Iterator) ReadArrayCB(callback func(*Iterator) bool) (ret bool) {\n\tc := iter.nextToken()\n\tif c == '[' {\n\t\tif !iter.incrementDepth() {\n\t\t\treturn false\n\t\t}\n\t\tc = iter.nextToken()\n\t\tif c != ']' {\n\t\t\titer.unreadByte()\n\t\t\tif !callback(iter) {\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tc = iter.nextToken()\n\t\t\tfor c == ',' {\n\t\t\t\tif !callback(iter) {\n\t\t\t\t\titer.decrementDepth()\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tc = iter.nextToken()\n\t\t\t}\n\t\t\tif c != ']' {\n\t\t\t\titer.ReportError(\"ReadArrayCB\", \"expect ] in the end, but found \"+string([]byte{c}))\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn iter.decrementDepth()\n\t\t}\n\t\treturn iter.decrementDepth()\n\t}\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn true // null\n\t}\n\titer.ReportError(\"ReadArrayCB\", \"expect [ or n, but found \"+string([]byte{c}))\n\treturn false\n}\n"
        },
        {
          "name": "iter_float.go",
          "type": "blob",
          "size": 7.4619140625,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/json\"\n\t\"io\"\n\t\"math/big\"\n\t\"strconv\"\n\t\"strings\"\n\t\"unsafe\"\n)\n\nvar floatDigits []int8\n\nconst invalidCharForNumber = int8(-1)\nconst endOfNumber = int8(-2)\nconst dotInNumber = int8(-3)\n\nfunc init() {\n\tfloatDigits = make([]int8, 256)\n\tfor i := 0; i < len(floatDigits); i++ {\n\t\tfloatDigits[i] = invalidCharForNumber\n\t}\n\tfor i := int8('0'); i <= int8('9'); i++ {\n\t\tfloatDigits[i] = i - int8('0')\n\t}\n\tfloatDigits[','] = endOfNumber\n\tfloatDigits[']'] = endOfNumber\n\tfloatDigits['}'] = endOfNumber\n\tfloatDigits[' '] = endOfNumber\n\tfloatDigits['\\t'] = endOfNumber\n\tfloatDigits['\\n'] = endOfNumber\n\tfloatDigits['.'] = dotInNumber\n}\n\n// ReadBigFloat read big.Float\nfunc (iter *Iterator) ReadBigFloat() (ret *big.Float) {\n\tstr := iter.readNumberAsString()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn nil\n\t}\n\tprec := 64\n\tif len(str) > prec {\n\t\tprec = len(str)\n\t}\n\tval, _, err := big.ParseFloat(str, 10, uint(prec), big.ToZero)\n\tif err != nil {\n\t\titer.Error = err\n\t\treturn nil\n\t}\n\treturn val\n}\n\n// ReadBigInt read big.Int\nfunc (iter *Iterator) ReadBigInt() (ret *big.Int) {\n\tstr := iter.readNumberAsString()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn nil\n\t}\n\tret = big.NewInt(0)\n\tvar success bool\n\tret, success = ret.SetString(str, 10)\n\tif !success {\n\t\titer.ReportError(\"ReadBigInt\", \"invalid big int\")\n\t\treturn nil\n\t}\n\treturn ret\n}\n\n//ReadFloat32 read float32\nfunc (iter *Iterator) ReadFloat32() (ret float32) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\treturn -iter.readPositiveFloat32()\n\t}\n\titer.unreadByte()\n\treturn iter.readPositiveFloat32()\n}\n\nfunc (iter *Iterator) readPositiveFloat32() (ret float32) {\n\ti := iter.head\n\t// first char\n\tif i == iter.tail {\n\t\treturn iter.readFloat32SlowPath()\n\t}\n\tc := iter.buf[i]\n\ti++\n\tind := floatDigits[c]\n\tswitch ind {\n\tcase invalidCharForNumber:\n\t\treturn iter.readFloat32SlowPath()\n\tcase endOfNumber:\n\t\titer.ReportError(\"readFloat32\", \"empty number\")\n\t\treturn\n\tcase dotInNumber:\n\t\titer.ReportError(\"readFloat32\", \"leading dot is invalid\")\n\t\treturn\n\tcase 0:\n\t\tif i == iter.tail {\n\t\t\treturn iter.readFloat32SlowPath()\n\t\t}\n\t\tc = iter.buf[i]\n\t\tswitch c {\n\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\t\titer.ReportError(\"readFloat32\", \"leading zero is invalid\")\n\t\t\treturn\n\t\t}\n\t}\n\tvalue := uint64(ind)\n\t// chars before dot\nnon_decimal_loop:\n\tfor ; i < iter.tail; i++ {\n\t\tc = iter.buf[i]\n\t\tind := floatDigits[c]\n\t\tswitch ind {\n\t\tcase invalidCharForNumber:\n\t\t\treturn iter.readFloat32SlowPath()\n\t\tcase endOfNumber:\n\t\t\titer.head = i\n\t\t\treturn float32(value)\n\t\tcase dotInNumber:\n\t\t\tbreak non_decimal_loop\n\t\t}\n\t\tif value > uint64SafeToMultiple10 {\n\t\t\treturn iter.readFloat32SlowPath()\n\t\t}\n\t\tvalue = (value << 3) + (value << 1) + uint64(ind) // value = value * 10 + ind;\n\t}\n\t// chars after dot\n\tif c == '.' {\n\t\ti++\n\t\tdecimalPlaces := 0\n\t\tif i == iter.tail {\n\t\t\treturn iter.readFloat32SlowPath()\n\t\t}\n\t\tfor ; i < iter.tail; i++ {\n\t\t\tc = iter.buf[i]\n\t\t\tind := floatDigits[c]\n\t\t\tswitch ind {\n\t\t\tcase endOfNumber:\n\t\t\t\tif decimalPlaces > 0 && decimalPlaces < len(pow10) {\n\t\t\t\t\titer.head = i\n\t\t\t\t\treturn float32(float64(value) / float64(pow10[decimalPlaces]))\n\t\t\t\t}\n\t\t\t\t// too many decimal places\n\t\t\t\treturn iter.readFloat32SlowPath()\n\t\t\tcase invalidCharForNumber, dotInNumber:\n\t\t\t\treturn iter.readFloat32SlowPath()\n\t\t\t}\n\t\t\tdecimalPlaces++\n\t\t\tif value > uint64SafeToMultiple10 {\n\t\t\t\treturn iter.readFloat32SlowPath()\n\t\t\t}\n\t\t\tvalue = (value << 3) + (value << 1) + uint64(ind)\n\t\t}\n\t}\n\treturn iter.readFloat32SlowPath()\n}\n\nfunc (iter *Iterator) readNumberAsString() (ret string) {\n\tstrBuf := [16]byte{}\n\tstr := strBuf[0:0]\nload_loop:\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tc := iter.buf[i]\n\t\t\tswitch c {\n\t\t\tcase '+', '-', '.', 'e', 'E', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\t\t\tstr = append(str, c)\n\t\t\t\tcontinue\n\t\t\tdefault:\n\t\t\t\titer.head = i\n\t\t\t\tbreak load_loop\n\t\t\t}\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn\n\t}\n\tif len(str) == 0 {\n\t\titer.ReportError(\"readNumberAsString\", \"invalid number\")\n\t}\n\treturn *(*string)(unsafe.Pointer(&str))\n}\n\nfunc (iter *Iterator) readFloat32SlowPath() (ret float32) {\n\tstr := iter.readNumberAsString()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn\n\t}\n\terrMsg := validateFloat(str)\n\tif errMsg != \"\" {\n\t\titer.ReportError(\"readFloat32SlowPath\", errMsg)\n\t\treturn\n\t}\n\tval, err := strconv.ParseFloat(str, 32)\n\tif err != nil {\n\t\titer.Error = err\n\t\treturn\n\t}\n\treturn float32(val)\n}\n\n// ReadFloat64 read float64\nfunc (iter *Iterator) ReadFloat64() (ret float64) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\treturn -iter.readPositiveFloat64()\n\t}\n\titer.unreadByte()\n\treturn iter.readPositiveFloat64()\n}\n\nfunc (iter *Iterator) readPositiveFloat64() (ret float64) {\n\ti := iter.head\n\t// first char\n\tif i == iter.tail {\n\t\treturn iter.readFloat64SlowPath()\n\t}\n\tc := iter.buf[i]\n\ti++\n\tind := floatDigits[c]\n\tswitch ind {\n\tcase invalidCharForNumber:\n\t\treturn iter.readFloat64SlowPath()\n\tcase endOfNumber:\n\t\titer.ReportError(\"readFloat64\", \"empty number\")\n\t\treturn\n\tcase dotInNumber:\n\t\titer.ReportError(\"readFloat64\", \"leading dot is invalid\")\n\t\treturn\n\tcase 0:\n\t\tif i == iter.tail {\n\t\t\treturn iter.readFloat64SlowPath()\n\t\t}\n\t\tc = iter.buf[i]\n\t\tswitch c {\n\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\t\titer.ReportError(\"readFloat64\", \"leading zero is invalid\")\n\t\t\treturn\n\t\t}\n\t}\n\tvalue := uint64(ind)\n\t// chars before dot\nnon_decimal_loop:\n\tfor ; i < iter.tail; i++ {\n\t\tc = iter.buf[i]\n\t\tind := floatDigits[c]\n\t\tswitch ind {\n\t\tcase invalidCharForNumber:\n\t\t\treturn iter.readFloat64SlowPath()\n\t\tcase endOfNumber:\n\t\t\titer.head = i\n\t\t\treturn float64(value)\n\t\tcase dotInNumber:\n\t\t\tbreak non_decimal_loop\n\t\t}\n\t\tif value > uint64SafeToMultiple10 {\n\t\t\treturn iter.readFloat64SlowPath()\n\t\t}\n\t\tvalue = (value << 3) + (value << 1) + uint64(ind) // value = value * 10 + ind;\n\t}\n\t// chars after dot\n\tif c == '.' {\n\t\ti++\n\t\tdecimalPlaces := 0\n\t\tif i == iter.tail {\n\t\t\treturn iter.readFloat64SlowPath()\n\t\t}\n\t\tfor ; i < iter.tail; i++ {\n\t\t\tc = iter.buf[i]\n\t\t\tind := floatDigits[c]\n\t\t\tswitch ind {\n\t\t\tcase endOfNumber:\n\t\t\t\tif decimalPlaces > 0 && decimalPlaces < len(pow10) {\n\t\t\t\t\titer.head = i\n\t\t\t\t\treturn float64(value) / float64(pow10[decimalPlaces])\n\t\t\t\t}\n\t\t\t\t// too many decimal places\n\t\t\t\treturn iter.readFloat64SlowPath()\n\t\t\tcase invalidCharForNumber, dotInNumber:\n\t\t\t\treturn iter.readFloat64SlowPath()\n\t\t\t}\n\t\t\tdecimalPlaces++\n\t\t\tif value > uint64SafeToMultiple10 {\n\t\t\t\treturn iter.readFloat64SlowPath()\n\t\t\t}\n\t\t\tvalue = (value << 3) + (value << 1) + uint64(ind)\n\t\t\tif value > maxFloat64 {\n\t\t\t\treturn iter.readFloat64SlowPath()\n\t\t\t}\n\t\t}\n\t}\n\treturn iter.readFloat64SlowPath()\n}\n\nfunc (iter *Iterator) readFloat64SlowPath() (ret float64) {\n\tstr := iter.readNumberAsString()\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\treturn\n\t}\n\terrMsg := validateFloat(str)\n\tif errMsg != \"\" {\n\t\titer.ReportError(\"readFloat64SlowPath\", errMsg)\n\t\treturn\n\t}\n\tval, err := strconv.ParseFloat(str, 64)\n\tif err != nil {\n\t\titer.Error = err\n\t\treturn\n\t}\n\treturn val\n}\n\nfunc validateFloat(str string) string {\n\t// strconv.ParseFloat is not validating `1.` or `1.e1`\n\tif len(str) == 0 {\n\t\treturn \"empty number\"\n\t}\n\tif str[0] == '-' {\n\t\treturn \"-- is not valid\"\n\t}\n\tdotPos := strings.IndexByte(str, '.')\n\tif dotPos != -1 {\n\t\tif dotPos == len(str)-1 {\n\t\t\treturn \"dot can not be last character\"\n\t\t}\n\t\tswitch str[dotPos+1] {\n\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\tdefault:\n\t\t\treturn \"missing digit after dot\"\n\t\t}\n\t}\n\treturn \"\"\n}\n\n// ReadNumber read json.Number\nfunc (iter *Iterator) ReadNumber() (ret json.Number) {\n\treturn json.Number(iter.readNumberAsString())\n}\n"
        },
        {
          "name": "iter_int.go",
          "type": "blob",
          "size": 8.5634765625,
          "content": "package jsoniter\n\nimport (\n\t\"math\"\n\t\"strconv\"\n)\n\nvar intDigits []int8\n\nconst uint32SafeToMultiply10 = uint32(0xffffffff)/10 - 1\nconst uint64SafeToMultiple10 = uint64(0xffffffffffffffff)/10 - 1\nconst maxFloat64 = 1<<53 - 1\n\nfunc init() {\n\tintDigits = make([]int8, 256)\n\tfor i := 0; i < len(intDigits); i++ {\n\t\tintDigits[i] = invalidCharForNumber\n\t}\n\tfor i := int8('0'); i <= int8('9'); i++ {\n\t\tintDigits[i] = i - int8('0')\n\t}\n}\n\n// ReadUint read uint\nfunc (iter *Iterator) ReadUint() uint {\n\tif strconv.IntSize == 32 {\n\t\treturn uint(iter.ReadUint32())\n\t}\n\treturn uint(iter.ReadUint64())\n}\n\n// ReadInt read int\nfunc (iter *Iterator) ReadInt() int {\n\tif strconv.IntSize == 32 {\n\t\treturn int(iter.ReadInt32())\n\t}\n\treturn int(iter.ReadInt64())\n}\n\n// ReadInt8 read int8\nfunc (iter *Iterator) ReadInt8() (ret int8) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\tval := iter.readUint32(iter.readByte())\n\t\tif val > math.MaxInt8+1 {\n\t\t\titer.ReportError(\"ReadInt8\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\t\treturn\n\t\t}\n\t\treturn -int8(val)\n\t}\n\tval := iter.readUint32(c)\n\tif val > math.MaxInt8 {\n\t\titer.ReportError(\"ReadInt8\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\treturn\n\t}\n\treturn int8(val)\n}\n\n// ReadUint8 read uint8\nfunc (iter *Iterator) ReadUint8() (ret uint8) {\n\tval := iter.readUint32(iter.nextToken())\n\tif val > math.MaxUint8 {\n\t\titer.ReportError(\"ReadUint8\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\treturn\n\t}\n\treturn uint8(val)\n}\n\n// ReadInt16 read int16\nfunc (iter *Iterator) ReadInt16() (ret int16) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\tval := iter.readUint32(iter.readByte())\n\t\tif val > math.MaxInt16+1 {\n\t\t\titer.ReportError(\"ReadInt16\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\t\treturn\n\t\t}\n\t\treturn -int16(val)\n\t}\n\tval := iter.readUint32(c)\n\tif val > math.MaxInt16 {\n\t\titer.ReportError(\"ReadInt16\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\treturn\n\t}\n\treturn int16(val)\n}\n\n// ReadUint16 read uint16\nfunc (iter *Iterator) ReadUint16() (ret uint16) {\n\tval := iter.readUint32(iter.nextToken())\n\tif val > math.MaxUint16 {\n\t\titer.ReportError(\"ReadUint16\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\treturn\n\t}\n\treturn uint16(val)\n}\n\n// ReadInt32 read int32\nfunc (iter *Iterator) ReadInt32() (ret int32) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\tval := iter.readUint32(iter.readByte())\n\t\tif val > math.MaxInt32+1 {\n\t\t\titer.ReportError(\"ReadInt32\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\t\treturn\n\t\t}\n\t\treturn -int32(val)\n\t}\n\tval := iter.readUint32(c)\n\tif val > math.MaxInt32 {\n\t\titer.ReportError(\"ReadInt32\", \"overflow: \"+strconv.FormatInt(int64(val), 10))\n\t\treturn\n\t}\n\treturn int32(val)\n}\n\n// ReadUint32 read uint32\nfunc (iter *Iterator) ReadUint32() (ret uint32) {\n\treturn iter.readUint32(iter.nextToken())\n}\n\nfunc (iter *Iterator) readUint32(c byte) (ret uint32) {\n\tind := intDigits[c]\n\tif ind == 0 {\n\t\titer.assertInteger()\n\t\treturn 0 // single zero\n\t}\n\tif ind == invalidCharForNumber {\n\t\titer.ReportError(\"readUint32\", \"unexpected character: \"+string([]byte{byte(ind)}))\n\t\treturn\n\t}\n\tvalue := uint32(ind)\n\tif iter.tail-iter.head > 10 {\n\t\ti := iter.head\n\t\tind2 := intDigits[iter.buf[i]]\n\t\tif ind2 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t\ti++\n\t\tind3 := intDigits[iter.buf[i]]\n\t\tif ind3 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*10 + uint32(ind2)\n\t\t}\n\t\t//iter.head = i + 1\n\t\t//value = value * 100 + uint32(ind2) * 10 + uint32(ind3)\n\t\ti++\n\t\tind4 := intDigits[iter.buf[i]]\n\t\tif ind4 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*100 + uint32(ind2)*10 + uint32(ind3)\n\t\t}\n\t\ti++\n\t\tind5 := intDigits[iter.buf[i]]\n\t\tif ind5 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*1000 + uint32(ind2)*100 + uint32(ind3)*10 + uint32(ind4)\n\t\t}\n\t\ti++\n\t\tind6 := intDigits[iter.buf[i]]\n\t\tif ind6 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*10000 + uint32(ind2)*1000 + uint32(ind3)*100 + uint32(ind4)*10 + uint32(ind5)\n\t\t}\n\t\ti++\n\t\tind7 := intDigits[iter.buf[i]]\n\t\tif ind7 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*100000 + uint32(ind2)*10000 + uint32(ind3)*1000 + uint32(ind4)*100 + uint32(ind5)*10 + uint32(ind6)\n\t\t}\n\t\ti++\n\t\tind8 := intDigits[iter.buf[i]]\n\t\tif ind8 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*1000000 + uint32(ind2)*100000 + uint32(ind3)*10000 + uint32(ind4)*1000 + uint32(ind5)*100 + uint32(ind6)*10 + uint32(ind7)\n\t\t}\n\t\ti++\n\t\tind9 := intDigits[iter.buf[i]]\n\t\tvalue = value*10000000 + uint32(ind2)*1000000 + uint32(ind3)*100000 + uint32(ind4)*10000 + uint32(ind5)*1000 + uint32(ind6)*100 + uint32(ind7)*10 + uint32(ind8)\n\t\titer.head = i\n\t\tif ind9 == invalidCharForNumber {\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t}\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tind = intDigits[iter.buf[i]]\n\t\t\tif ind == invalidCharForNumber {\n\t\t\t\titer.head = i\n\t\t\t\titer.assertInteger()\n\t\t\t\treturn value\n\t\t\t}\n\t\t\tif value > uint32SafeToMultiply10 {\n\t\t\t\tvalue2 := (value << 3) + (value << 1) + uint32(ind)\n\t\t\t\tif value2 < value {\n\t\t\t\t\titer.ReportError(\"readUint32\", \"overflow\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tvalue = value2\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tvalue = (value << 3) + (value << 1) + uint32(ind)\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t}\n}\n\n// ReadInt64 read int64\nfunc (iter *Iterator) ReadInt64() (ret int64) {\n\tc := iter.nextToken()\n\tif c == '-' {\n\t\tval := iter.readUint64(iter.readByte())\n\t\tif val > math.MaxInt64+1 {\n\t\t\titer.ReportError(\"ReadInt64\", \"overflow: \"+strconv.FormatUint(uint64(val), 10))\n\t\t\treturn\n\t\t}\n\t\treturn -int64(val)\n\t}\n\tval := iter.readUint64(c)\n\tif val > math.MaxInt64 {\n\t\titer.ReportError(\"ReadInt64\", \"overflow: \"+strconv.FormatUint(uint64(val), 10))\n\t\treturn\n\t}\n\treturn int64(val)\n}\n\n// ReadUint64 read uint64\nfunc (iter *Iterator) ReadUint64() uint64 {\n\treturn iter.readUint64(iter.nextToken())\n}\n\nfunc (iter *Iterator) readUint64(c byte) (ret uint64) {\n\tind := intDigits[c]\n\tif ind == 0 {\n\t\titer.assertInteger()\n\t\treturn 0 // single zero\n\t}\n\tif ind == invalidCharForNumber {\n\t\titer.ReportError(\"readUint64\", \"unexpected character: \"+string([]byte{byte(ind)}))\n\t\treturn\n\t}\n\tvalue := uint64(ind)\n\tif iter.tail-iter.head > 10 {\n\t\ti := iter.head\n\t\tind2 := intDigits[iter.buf[i]]\n\t\tif ind2 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t\ti++\n\t\tind3 := intDigits[iter.buf[i]]\n\t\tif ind3 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*10 + uint64(ind2)\n\t\t}\n\t\t//iter.head = i + 1\n\t\t//value = value * 100 + uint32(ind2) * 10 + uint32(ind3)\n\t\ti++\n\t\tind4 := intDigits[iter.buf[i]]\n\t\tif ind4 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*100 + uint64(ind2)*10 + uint64(ind3)\n\t\t}\n\t\ti++\n\t\tind5 := intDigits[iter.buf[i]]\n\t\tif ind5 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*1000 + uint64(ind2)*100 + uint64(ind3)*10 + uint64(ind4)\n\t\t}\n\t\ti++\n\t\tind6 := intDigits[iter.buf[i]]\n\t\tif ind6 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*10000 + uint64(ind2)*1000 + uint64(ind3)*100 + uint64(ind4)*10 + uint64(ind5)\n\t\t}\n\t\ti++\n\t\tind7 := intDigits[iter.buf[i]]\n\t\tif ind7 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*100000 + uint64(ind2)*10000 + uint64(ind3)*1000 + uint64(ind4)*100 + uint64(ind5)*10 + uint64(ind6)\n\t\t}\n\t\ti++\n\t\tind8 := intDigits[iter.buf[i]]\n\t\tif ind8 == invalidCharForNumber {\n\t\t\titer.head = i\n\t\t\titer.assertInteger()\n\t\t\treturn value*1000000 + uint64(ind2)*100000 + uint64(ind3)*10000 + uint64(ind4)*1000 + uint64(ind5)*100 + uint64(ind6)*10 + uint64(ind7)\n\t\t}\n\t\ti++\n\t\tind9 := intDigits[iter.buf[i]]\n\t\tvalue = value*10000000 + uint64(ind2)*1000000 + uint64(ind3)*100000 + uint64(ind4)*10000 + uint64(ind5)*1000 + uint64(ind6)*100 + uint64(ind7)*10 + uint64(ind8)\n\t\titer.head = i\n\t\tif ind9 == invalidCharForNumber {\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t}\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tind = intDigits[iter.buf[i]]\n\t\t\tif ind == invalidCharForNumber {\n\t\t\t\titer.head = i\n\t\t\t\titer.assertInteger()\n\t\t\t\treturn value\n\t\t\t}\n\t\t\tif value > uint64SafeToMultiple10 {\n\t\t\t\tvalue2 := (value << 3) + (value << 1) + uint64(ind)\n\t\t\t\tif value2 < value {\n\t\t\t\t\titer.ReportError(\"readUint64\", \"overflow\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tvalue = value2\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tvalue = (value << 3) + (value << 1) + uint64(ind)\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\titer.assertInteger()\n\t\t\treturn value\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) assertInteger() {\n\tif iter.head < iter.tail && iter.buf[iter.head] == '.' {\n\t\titer.ReportError(\"assertInteger\", \"can not decode float as int\")\n\t}\n}\n"
        },
        {
          "name": "iter_object.go",
          "type": "blob",
          "size": 6.212890625,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// ReadObject read one field from object.\n// If object ended, returns empty string.\n// Otherwise, returns the field name.\nfunc (iter *Iterator) ReadObject() (ret string) {\n\tc := iter.nextToken()\n\tswitch c {\n\tcase 'n':\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn \"\" // null\n\tcase '{':\n\t\tc = iter.nextToken()\n\t\tif c == '\"' {\n\t\t\titer.unreadByte()\n\t\t\tfield := iter.ReadString()\n\t\t\tc = iter.nextToken()\n\t\t\tif c != ':' {\n\t\t\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\t}\n\t\t\treturn field\n\t\t}\n\t\tif c == '}' {\n\t\t\treturn \"\" // end of object\n\t\t}\n\t\titer.ReportError(\"ReadObject\", `expect \" after {, but found `+string([]byte{c}))\n\t\treturn\n\tcase ',':\n\t\tfield := iter.ReadString()\n\t\tc = iter.nextToken()\n\t\tif c != ':' {\n\t\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t}\n\t\treturn field\n\tcase '}':\n\t\treturn \"\" // end of object\n\tdefault:\n\t\titer.ReportError(\"ReadObject\", fmt.Sprintf(`expect { or , or } or n, but found %s`, string([]byte{c})))\n\t\treturn\n\t}\n}\n\n// CaseInsensitive\nfunc (iter *Iterator) readFieldHash() int64 {\n\thash := int64(0x811c9dc5)\n\tc := iter.nextToken()\n\tif c != '\"' {\n\t\titer.ReportError(\"readFieldHash\", `expect \", but found `+string([]byte{c}))\n\t\treturn 0\n\t}\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\t// require ascii string and no escape\n\t\t\tb := iter.buf[i]\n\t\t\tif b == '\\\\' {\n\t\t\t\titer.head = i\n\t\t\t\tfor _, b := range iter.readStringSlowPath() {\n\t\t\t\t\tif 'A' <= b && b <= 'Z' && !iter.cfg.caseSensitive {\n\t\t\t\t\t\tb += 'a' - 'A'\n\t\t\t\t\t}\n\t\t\t\t\thash ^= int64(b)\n\t\t\t\t\thash *= 0x1000193\n\t\t\t\t}\n\t\t\t\tc = iter.nextToken()\n\t\t\t\tif c != ':' {\n\t\t\t\t\titer.ReportError(\"readFieldHash\", `expect :, but found `+string([]byte{c}))\n\t\t\t\t\treturn 0\n\t\t\t\t}\n\t\t\t\treturn hash\n\t\t\t}\n\t\t\tif b == '\"' {\n\t\t\t\titer.head = i + 1\n\t\t\t\tc = iter.nextToken()\n\t\t\t\tif c != ':' {\n\t\t\t\t\titer.ReportError(\"readFieldHash\", `expect :, but found `+string([]byte{c}))\n\t\t\t\t\treturn 0\n\t\t\t\t}\n\t\t\t\treturn hash\n\t\t\t}\n\t\t\tif 'A' <= b && b <= 'Z' && !iter.cfg.caseSensitive {\n\t\t\t\tb += 'a' - 'A'\n\t\t\t}\n\t\t\thash ^= int64(b)\n\t\t\thash *= 0x1000193\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\titer.ReportError(\"readFieldHash\", `incomplete field name`)\n\t\t\treturn 0\n\t\t}\n\t}\n}\n\nfunc calcHash(str string, caseSensitive bool) int64 {\n\tif !caseSensitive {\n\t\tstr = strings.ToLower(str)\n\t}\n\thash := int64(0x811c9dc5)\n\tfor _, b := range []byte(str) {\n\t\thash ^= int64(b)\n\t\thash *= 0x1000193\n\t}\n\treturn int64(hash)\n}\n\n// ReadObjectCB read object with callback, the key is ascii only and field name not copied\nfunc (iter *Iterator) ReadObjectCB(callback func(*Iterator, string) bool) bool {\n\tc := iter.nextToken()\n\tvar field string\n\tif c == '{' {\n\t\tif !iter.incrementDepth() {\n\t\t\treturn false\n\t\t}\n\t\tc = iter.nextToken()\n\t\tif c == '\"' {\n\t\t\titer.unreadByte()\n\t\t\tfield = iter.ReadString()\n\t\t\tc = iter.nextToken()\n\t\t\tif c != ':' {\n\t\t\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\t}\n\t\t\tif !callback(iter, field) {\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tc = iter.nextToken()\n\t\t\tfor c == ',' {\n\t\t\t\tfield = iter.ReadString()\n\t\t\t\tc = iter.nextToken()\n\t\t\t\tif c != ':' {\n\t\t\t\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\t\t}\n\t\t\t\tif !callback(iter, field) {\n\t\t\t\t\titer.decrementDepth()\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tc = iter.nextToken()\n\t\t\t}\n\t\t\tif c != '}' {\n\t\t\t\titer.ReportError(\"ReadObjectCB\", `object not ended with }`)\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn iter.decrementDepth()\n\t\t}\n\t\tif c == '}' {\n\t\t\treturn iter.decrementDepth()\n\t\t}\n\t\titer.ReportError(\"ReadObjectCB\", `expect \" after {, but found `+string([]byte{c}))\n\t\titer.decrementDepth()\n\t\treturn false\n\t}\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn true // null\n\t}\n\titer.ReportError(\"ReadObjectCB\", `expect { or n, but found `+string([]byte{c}))\n\treturn false\n}\n\n// ReadMapCB read map with callback, the key can be any string\nfunc (iter *Iterator) ReadMapCB(callback func(*Iterator, string) bool) bool {\n\tc := iter.nextToken()\n\tif c == '{' {\n\t\tif !iter.incrementDepth() {\n\t\t\treturn false\n\t\t}\n\t\tc = iter.nextToken()\n\t\tif c == '\"' {\n\t\t\titer.unreadByte()\n\t\t\tfield := iter.ReadString()\n\t\t\tif iter.nextToken() != ':' {\n\t\t\t\titer.ReportError(\"ReadMapCB\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !callback(iter, field) {\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tc = iter.nextToken()\n\t\t\tfor c == ',' {\n\t\t\t\tfield = iter.ReadString()\n\t\t\t\tif iter.nextToken() != ':' {\n\t\t\t\t\titer.ReportError(\"ReadMapCB\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\t\t\titer.decrementDepth()\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif !callback(iter, field) {\n\t\t\t\t\titer.decrementDepth()\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tc = iter.nextToken()\n\t\t\t}\n\t\t\tif c != '}' {\n\t\t\t\titer.ReportError(\"ReadMapCB\", `object not ended with }`)\n\t\t\t\titer.decrementDepth()\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn iter.decrementDepth()\n\t\t}\n\t\tif c == '}' {\n\t\t\treturn iter.decrementDepth()\n\t\t}\n\t\titer.ReportError(\"ReadMapCB\", `expect \" after {, but found `+string([]byte{c}))\n\t\titer.decrementDepth()\n\t\treturn false\n\t}\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn true // null\n\t}\n\titer.ReportError(\"ReadMapCB\", `expect { or n, but found `+string([]byte{c}))\n\treturn false\n}\n\nfunc (iter *Iterator) readObjectStart() bool {\n\tc := iter.nextToken()\n\tif c == '{' {\n\t\tc = iter.nextToken()\n\t\tif c == '}' {\n\t\t\treturn false\n\t\t}\n\t\titer.unreadByte()\n\t\treturn true\n\t} else if c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn false\n\t}\n\titer.ReportError(\"readObjectStart\", \"expect { or n, but found \"+string([]byte{c}))\n\treturn false\n}\n\nfunc (iter *Iterator) readObjectFieldAsBytes() (ret []byte) {\n\tstr := iter.ReadStringAsSlice()\n\tif iter.skipWhitespacesWithoutLoadMore() {\n\t\tif ret == nil {\n\t\t\tret = make([]byte, len(str))\n\t\t\tcopy(ret, str)\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\treturn\n\t\t}\n\t}\n\tif iter.buf[iter.head] != ':' {\n\t\titer.ReportError(\"readObjectFieldAsBytes\", \"expect : after object field, but found \"+string([]byte{iter.buf[iter.head]}))\n\t\treturn\n\t}\n\titer.head++\n\tif iter.skipWhitespacesWithoutLoadMore() {\n\t\tif ret == nil {\n\t\t\tret = make([]byte, len(str))\n\t\t\tcopy(ret, str)\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\treturn\n\t\t}\n\t}\n\tif ret == nil {\n\t\treturn str\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "iter_skip.go",
          "type": "blob",
          "size": 3.3486328125,
          "content": "package jsoniter\n\nimport \"fmt\"\n\n// ReadNil reads a json object as nil and\n// returns whether it's a nil or not\nfunc (iter *Iterator) ReadNil() (ret bool) {\n\tc := iter.nextToken()\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l') // null\n\t\treturn true\n\t}\n\titer.unreadByte()\n\treturn false\n}\n\n// ReadBool reads a json object as BoolValue\nfunc (iter *Iterator) ReadBool() (ret bool) {\n\tc := iter.nextToken()\n\tif c == 't' {\n\t\titer.skipThreeBytes('r', 'u', 'e')\n\t\treturn true\n\t}\n\tif c == 'f' {\n\t\titer.skipFourBytes('a', 'l', 's', 'e')\n\t\treturn false\n\t}\n\titer.ReportError(\"ReadBool\", \"expect t or f, but found \"+string([]byte{c}))\n\treturn\n}\n\n// SkipAndReturnBytes skip next JSON element, and return its content as []byte.\n// The []byte can be kept, it is a copy of data.\nfunc (iter *Iterator) SkipAndReturnBytes() []byte {\n\titer.startCapture(iter.head)\n\titer.Skip()\n\treturn iter.stopCapture()\n}\n\n// SkipAndAppendBytes skips next JSON element and appends its content to\n// buffer, returning the result.\nfunc (iter *Iterator) SkipAndAppendBytes(buf []byte) []byte {\n\titer.startCaptureTo(buf, iter.head)\n\titer.Skip()\n\treturn iter.stopCapture()\n}\n\nfunc (iter *Iterator) startCaptureTo(buf []byte, captureStartedAt int) {\n\tif iter.captured != nil {\n\t\tpanic(\"already in capture mode\")\n\t}\n\titer.captureStartedAt = captureStartedAt\n\titer.captured = buf\n}\n\nfunc (iter *Iterator) startCapture(captureStartedAt int) {\n\titer.startCaptureTo(make([]byte, 0, 32), captureStartedAt)\n}\n\nfunc (iter *Iterator) stopCapture() []byte {\n\tif iter.captured == nil {\n\t\tpanic(\"not in capture mode\")\n\t}\n\tcaptured := iter.captured\n\tremaining := iter.buf[iter.captureStartedAt:iter.head]\n\titer.captureStartedAt = -1\n\titer.captured = nil\n\treturn append(captured, remaining...)\n}\n\n// Skip skips a json object and positions to relatively the next json object\nfunc (iter *Iterator) Skip() {\n\tc := iter.nextToken()\n\tswitch c {\n\tcase '\"':\n\t\titer.skipString()\n\tcase 'n':\n\t\titer.skipThreeBytes('u', 'l', 'l') // null\n\tcase 't':\n\t\titer.skipThreeBytes('r', 'u', 'e') // true\n\tcase 'f':\n\t\titer.skipFourBytes('a', 'l', 's', 'e') // false\n\tcase '0':\n\t\titer.unreadByte()\n\t\titer.ReadFloat32()\n\tcase '-', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\titer.skipNumber()\n\tcase '[':\n\t\titer.skipArray()\n\tcase '{':\n\t\titer.skipObject()\n\tdefault:\n\t\titer.ReportError(\"Skip\", fmt.Sprintf(\"do not know how to skip: %v\", c))\n\t\treturn\n\t}\n}\n\nfunc (iter *Iterator) skipFourBytes(b1, b2, b3, b4 byte) {\n\tif iter.readByte() != b1 {\n\t\titer.ReportError(\"skipFourBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3, b4})))\n\t\treturn\n\t}\n\tif iter.readByte() != b2 {\n\t\titer.ReportError(\"skipFourBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3, b4})))\n\t\treturn\n\t}\n\tif iter.readByte() != b3 {\n\t\titer.ReportError(\"skipFourBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3, b4})))\n\t\treturn\n\t}\n\tif iter.readByte() != b4 {\n\t\titer.ReportError(\"skipFourBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3, b4})))\n\t\treturn\n\t}\n}\n\nfunc (iter *Iterator) skipThreeBytes(b1, b2, b3 byte) {\n\tif iter.readByte() != b1 {\n\t\titer.ReportError(\"skipThreeBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3})))\n\t\treturn\n\t}\n\tif iter.readByte() != b2 {\n\t\titer.ReportError(\"skipThreeBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3})))\n\t\treturn\n\t}\n\tif iter.readByte() != b3 {\n\t\titer.ReportError(\"skipThreeBytes\", fmt.Sprintf(\"expect %s\", string([]byte{b1, b2, b3})))\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "iter_skip_sloppy.go",
          "type": "blob",
          "size": 3.1787109375,
          "content": "//+build jsoniter_sloppy\n\npackage jsoniter\n\n// sloppy but faster implementation, do not validate the input json\n\nfunc (iter *Iterator) skipNumber() {\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tc := iter.buf[i]\n\t\t\tswitch c {\n\t\t\tcase ' ', '\\n', '\\r', '\\t', ',', '}', ']':\n\t\t\t\titer.head = i\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) skipArray() {\n\tlevel := 1\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tswitch iter.buf[i] {\n\t\t\tcase '\"': // If inside string, skip it\n\t\t\t\titer.head = i + 1\n\t\t\t\titer.skipString()\n\t\t\t\ti = iter.head - 1 // it will be i++ soon\n\t\t\tcase '[': // If open symbol, increase level\n\t\t\t\tlevel++\n\t\t\t\tif !iter.incrementDepth() {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase ']': // If close symbol, increase level\n\t\t\t\tlevel--\n\t\t\t\tif !iter.decrementDepth() {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// If we have returned to the original level, we're done\n\t\t\t\tif level == 0 {\n\t\t\t\t\titer.head = i + 1\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\titer.ReportError(\"skipObject\", \"incomplete array\")\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) skipObject() {\n\tlevel := 1\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\n\tfor {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tswitch iter.buf[i] {\n\t\t\tcase '\"': // If inside string, skip it\n\t\t\t\titer.head = i + 1\n\t\t\t\titer.skipString()\n\t\t\t\ti = iter.head - 1 // it will be i++ soon\n\t\t\tcase '{': // If open symbol, increase level\n\t\t\t\tlevel++\n\t\t\t\tif !iter.incrementDepth() {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase '}': // If close symbol, increase level\n\t\t\t\tlevel--\n\t\t\t\tif !iter.decrementDepth() {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// If we have returned to the original level, we're done\n\t\t\t\tif level == 0 {\n\t\t\t\t\titer.head = i + 1\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !iter.loadMore() {\n\t\t\titer.ReportError(\"skipObject\", \"incomplete object\")\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) skipString() {\n\tfor {\n\t\tend, escaped := iter.findStringEnd()\n\t\tif end == -1 {\n\t\t\tif !iter.loadMore() {\n\t\t\t\titer.ReportError(\"skipString\", \"incomplete string\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif escaped {\n\t\t\t\titer.head = 1 // skip the first char as last char read is \\\n\t\t\t}\n\t\t} else {\n\t\t\titer.head = end\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// adapted from: https://github.com/buger/jsonparser/blob/master/parser.go\n// Tries to find the end of string\n// Support if string contains escaped quote symbols.\nfunc (iter *Iterator) findStringEnd() (int, bool) {\n\tescaped := false\n\tfor i := iter.head; i < iter.tail; i++ {\n\t\tc := iter.buf[i]\n\t\tif c == '\"' {\n\t\t\tif !escaped {\n\t\t\t\treturn i + 1, false\n\t\t\t}\n\t\t\tj := i - 1\n\t\t\tfor {\n\t\t\t\tif j < iter.head || iter.buf[j] != '\\\\' {\n\t\t\t\t\t// even number of backslashes\n\t\t\t\t\t// either end of buffer, or \" found\n\t\t\t\t\treturn i + 1, true\n\t\t\t\t}\n\t\t\t\tj--\n\t\t\t\tif j < iter.head || iter.buf[j] != '\\\\' {\n\t\t\t\t\t// odd number of backslashes\n\t\t\t\t\t// it is \\\" or \\\\\\\"\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tj--\n\t\t\t}\n\t\t} else if c == '\\\\' {\n\t\t\tescaped = true\n\t\t}\n\t}\n\tj := iter.tail - 1\n\tfor {\n\t\tif j < iter.head || iter.buf[j] != '\\\\' {\n\t\t\t// even number of backslashes\n\t\t\t// either end of buffer, or \" found\n\t\t\treturn -1, false // do not end with \\\n\t\t}\n\t\tj--\n\t\tif j < iter.head || iter.buf[j] != '\\\\' {\n\t\t\t// odd number of backslashes\n\t\t\t// it is \\\" or \\\\\\\"\n\t\t\tbreak\n\t\t}\n\t\tj--\n\n\t}\n\treturn -1, true // end with \\\n}\n"
        },
        {
          "name": "iter_skip_sloppy_test.go",
          "type": "blob",
          "size": 3.091796875,
          "content": "//+build jsoniter_sloppy\n\npackage jsoniter\n\nimport (\n\t\"github.com/stretchr/testify/require\"\n\t\"io\"\n\t\"testing\"\n)\n\nfunc Test_string_end(t *testing.T) {\n\tend, escaped := ParseString(ConfigDefault, `abc\"`).findStringEnd()\n\tif end != 4 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != false {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `abc\\\\\"`).findStringEnd()\n\tif end != 6 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != true {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `abc\\\\\\\\\"`).findStringEnd()\n\tif end != 8 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != true {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `abc\\\"`).findStringEnd()\n\tif end != -1 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != false {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `abc\\`).findStringEnd()\n\tif end != -1 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != true {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `abc\\\\`).findStringEnd()\n\tif end != -1 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != false {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `\\\\`).findStringEnd()\n\tif end != -1 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != false {\n\t\tt.Fatal(escaped)\n\t}\n\tend, escaped = ParseString(ConfigDefault, `\\`).findStringEnd()\n\tif end != -1 {\n\t\tt.Fatal(end)\n\t}\n\tif escaped != true {\n\t\tt.Fatal(escaped)\n\t}\n}\n\ntype StagedReader struct {\n\tr1 string\n\tr2 string\n\tr3 string\n\tr  int\n}\n\nfunc (reader *StagedReader) Read(p []byte) (n int, err error) {\n\treader.r++\n\tswitch reader.r {\n\tcase 1:\n\t\tcopy(p, []byte(reader.r1))\n\t\treturn len(reader.r1), nil\n\tcase 2:\n\t\tcopy(p, []byte(reader.r2))\n\t\treturn len(reader.r2), nil\n\tcase 3:\n\t\tcopy(p, []byte(reader.r3))\n\t\treturn len(reader.r3), nil\n\tdefault:\n\t\treturn 0, io.EOF\n\t}\n}\n\nfunc Test_skip_string(t *testing.T) {\n\tshould := require.New(t)\n\titer := ParseString(ConfigDefault, `\"abc`)\n\titer.skipString()\n\tshould.Equal(1, iter.head)\n\titer = ParseString(ConfigDefault, `\\\"\"abc`)\n\titer.skipString()\n\tshould.Equal(3, iter.head)\n\treader := &StagedReader{\n\t\tr1: `abc`,\n\t\tr2: `\"`,\n\t}\n\titer = Parse(ConfigDefault, reader, 4096)\n\titer.skipString()\n\tshould.Equal(1, iter.head)\n\treader = &StagedReader{\n\t\tr1: `abc`,\n\t\tr2: `1\"`,\n\t}\n\titer = Parse(ConfigDefault, reader, 4096)\n\titer.skipString()\n\tshould.Equal(2, iter.head)\n\treader = &StagedReader{\n\t\tr1: `abc\\`,\n\t\tr2: `\"`,\n\t}\n\titer = Parse(ConfigDefault, reader, 4096)\n\titer.skipString()\n\tshould.NotNil(iter.Error)\n\treader = &StagedReader{\n\t\tr1: `abc\\`,\n\t\tr2: `\"\"`,\n\t}\n\titer = Parse(ConfigDefault, reader, 4096)\n\titer.skipString()\n\tshould.Equal(2, iter.head)\n}\n\nfunc Test_skip_object(t *testing.T) {\n\titer := ParseString(ConfigDefault, `}`)\n\titer.skipObject()\n\tif iter.head != 1 {\n\t\tt.Fatal(iter.head)\n\t}\n\titer = ParseString(ConfigDefault, `a}`)\n\titer.skipObject()\n\tif iter.head != 2 {\n\t\tt.Fatal(iter.head)\n\t}\n\titer = ParseString(ConfigDefault, `{}}a`)\n\titer.skipObject()\n\tif iter.head != 3 {\n\t\tt.Fatal(iter.head)\n\t}\n\treader := &StagedReader{\n\t\tr1: `{`,\n\t\tr2: `}}a`,\n\t}\n\titer = Parse(ConfigDefault, reader, 4096)\n\titer.skipObject()\n\tif iter.head != 2 {\n\t\tt.Fatal(iter.head)\n\t}\n\titer = ParseString(ConfigDefault, `\"}\"}a`)\n\titer.skipObject()\n\tif iter.head != 4 {\n\t\tt.Fatal(iter.head)\n\t}\n}\n"
        },
        {
          "name": "iter_skip_strict.go",
          "type": "blob",
          "size": 1.955078125,
          "content": "//+build !jsoniter_sloppy\n\npackage jsoniter\n\nimport (\n\t\"fmt\"\n\t\"io\"\n)\n\nfunc (iter *Iterator) skipNumber() {\n\tif !iter.trySkipNumber() {\n\t\titer.unreadByte()\n\t\tif iter.Error != nil && iter.Error != io.EOF {\n\t\t\treturn\n\t\t}\n\t\titer.ReadFloat64()\n\t\tif iter.Error != nil && iter.Error != io.EOF {\n\t\t\titer.Error = nil\n\t\t\titer.ReadBigFloat()\n\t\t}\n\t}\n}\n\nfunc (iter *Iterator) trySkipNumber() bool {\n\tdotFound := false\n\tfor i := iter.head; i < iter.tail; i++ {\n\t\tc := iter.buf[i]\n\t\tswitch c {\n\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\tcase '.':\n\t\t\tif dotFound {\n\t\t\t\titer.ReportError(\"validateNumber\", `more than one dot found in number`)\n\t\t\t\treturn true // already failed\n\t\t\t}\n\t\t\tif i+1 == iter.tail {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tc = iter.buf[i+1]\n\t\t\tswitch c {\n\t\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\t\tdefault:\n\t\t\t\titer.ReportError(\"validateNumber\", `missing digit after dot`)\n\t\t\t\treturn true // already failed\n\t\t\t}\n\t\t\tdotFound = true\n\t\tdefault:\n\t\t\tswitch c {\n\t\t\tcase ',', ']', '}', ' ', '\\t', '\\n', '\\r':\n\t\t\t\tif iter.head == i {\n\t\t\t\t\treturn false // if - without following digits\n\t\t\t\t}\n\t\t\t\titer.head = i\n\t\t\t\treturn true // must be valid\n\t\t\t}\n\t\t\treturn false // may be invalid\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (iter *Iterator) skipString() {\n\tif !iter.trySkipString() {\n\t\titer.unreadByte()\n\t\titer.ReadString()\n\t}\n}\n\nfunc (iter *Iterator) trySkipString() bool {\n\tfor i := iter.head; i < iter.tail; i++ {\n\t\tc := iter.buf[i]\n\t\tif c == '\"' {\n\t\t\titer.head = i + 1\n\t\t\treturn true // valid\n\t\t} else if c == '\\\\' {\n\t\t\treturn false\n\t\t} else if c < ' ' {\n\t\t\titer.ReportError(\"trySkipString\",\n\t\t\t\tfmt.Sprintf(`invalid control character found: %d`, c))\n\t\t\treturn true // already failed\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (iter *Iterator) skipObject() {\n\titer.unreadByte()\n\titer.ReadObjectCB(func(iter *Iterator, field string) bool {\n\t\titer.Skip()\n\t\treturn true\n\t})\n}\n\nfunc (iter *Iterator) skipArray() {\n\titer.unreadByte()\n\titer.ReadArrayCB(func(iter *Iterator) bool {\n\t\titer.Skip()\n\t\treturn true\n\t})\n}\n"
        },
        {
          "name": "iter_str.go",
          "type": "blob",
          "size": 4.7080078125,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"unicode/utf16\"\n)\n\n// ReadString read string from iterator\nfunc (iter *Iterator) ReadString() (ret string) {\n\tc := iter.nextToken()\n\tif c == '\"' {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\tc := iter.buf[i]\n\t\t\tif c == '\"' {\n\t\t\t\tret = string(iter.buf[iter.head:i])\n\t\t\t\titer.head = i + 1\n\t\t\t\treturn ret\n\t\t\t} else if c == '\\\\' {\n\t\t\t\tbreak\n\t\t\t} else if c < ' ' {\n\t\t\t\titer.ReportError(\"ReadString\",\n\t\t\t\t\tfmt.Sprintf(`invalid control character found: %d`, c))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\treturn iter.readStringSlowPath()\n\t} else if c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn \"\"\n\t}\n\titer.ReportError(\"ReadString\", `expects \" or n, but found `+string([]byte{c}))\n\treturn\n}\n\nfunc (iter *Iterator) readStringSlowPath() (ret string) {\n\tvar str []byte\n\tvar c byte\n\tfor iter.Error == nil {\n\t\tc = iter.readByte()\n\t\tif c == '\"' {\n\t\t\treturn string(str)\n\t\t}\n\t\tif c == '\\\\' {\n\t\t\tc = iter.readByte()\n\t\t\tstr = iter.readEscapedChar(c, str)\n\t\t} else {\n\t\t\tstr = append(str, c)\n\t\t}\n\t}\n\titer.ReportError(\"readStringSlowPath\", \"unexpected end of input\")\n\treturn\n}\n\nfunc (iter *Iterator) readEscapedChar(c byte, str []byte) []byte {\n\tswitch c {\n\tcase 'u':\n\t\tr := iter.readU4()\n\t\tif utf16.IsSurrogate(r) {\n\t\t\tc = iter.readByte()\n\t\t\tif iter.Error != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif c != '\\\\' {\n\t\t\t\titer.unreadByte()\n\t\t\t\tstr = appendRune(str, r)\n\t\t\t\treturn str\n\t\t\t}\n\t\t\tc = iter.readByte()\n\t\t\tif iter.Error != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif c != 'u' {\n\t\t\t\tstr = appendRune(str, r)\n\t\t\t\treturn iter.readEscapedChar(c, str)\n\t\t\t}\n\t\t\tr2 := iter.readU4()\n\t\t\tif iter.Error != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tcombined := utf16.DecodeRune(r, r2)\n\t\t\tif combined == '\\uFFFD' {\n\t\t\t\tstr = appendRune(str, r)\n\t\t\t\tstr = appendRune(str, r2)\n\t\t\t} else {\n\t\t\t\tstr = appendRune(str, combined)\n\t\t\t}\n\t\t} else {\n\t\t\tstr = appendRune(str, r)\n\t\t}\n\tcase '\"':\n\t\tstr = append(str, '\"')\n\tcase '\\\\':\n\t\tstr = append(str, '\\\\')\n\tcase '/':\n\t\tstr = append(str, '/')\n\tcase 'b':\n\t\tstr = append(str, '\\b')\n\tcase 'f':\n\t\tstr = append(str, '\\f')\n\tcase 'n':\n\t\tstr = append(str, '\\n')\n\tcase 'r':\n\t\tstr = append(str, '\\r')\n\tcase 't':\n\t\tstr = append(str, '\\t')\n\tdefault:\n\t\titer.ReportError(\"readEscapedChar\",\n\t\t\t`invalid escape char after \\`)\n\t\treturn nil\n\t}\n\treturn str\n}\n\n// ReadStringAsSlice read string from iterator without copying into string form.\n// The []byte can not be kept, as it will change after next iterator call.\nfunc (iter *Iterator) ReadStringAsSlice() (ret []byte) {\n\tc := iter.nextToken()\n\tif c == '\"' {\n\t\tfor i := iter.head; i < iter.tail; i++ {\n\t\t\t// require ascii string and no escape\n\t\t\t// for: field name, base64, number\n\t\t\tif iter.buf[i] == '\"' {\n\t\t\t\t// fast path: reuse the underlying buffer\n\t\t\t\tret = iter.buf[iter.head:i]\n\t\t\t\titer.head = i + 1\n\t\t\t\treturn ret\n\t\t\t}\n\t\t}\n\t\treadLen := iter.tail - iter.head\n\t\tcopied := make([]byte, readLen, readLen*2)\n\t\tcopy(copied, iter.buf[iter.head:iter.tail])\n\t\titer.head = iter.tail\n\t\tfor iter.Error == nil {\n\t\t\tc := iter.readByte()\n\t\t\tif c == '\"' {\n\t\t\t\treturn copied\n\t\t\t}\n\t\t\tcopied = append(copied, c)\n\t\t}\n\t\treturn copied\n\t}\n\titer.ReportError(\"ReadStringAsSlice\", `expects \" or n, but found `+string([]byte{c}))\n\treturn\n}\n\nfunc (iter *Iterator) readU4() (ret rune) {\n\tfor i := 0; i < 4; i++ {\n\t\tc := iter.readByte()\n\t\tif iter.Error != nil {\n\t\t\treturn\n\t\t}\n\t\tif c >= '0' && c <= '9' {\n\t\t\tret = ret*16 + rune(c-'0')\n\t\t} else if c >= 'a' && c <= 'f' {\n\t\t\tret = ret*16 + rune(c-'a'+10)\n\t\t} else if c >= 'A' && c <= 'F' {\n\t\t\tret = ret*16 + rune(c-'A'+10)\n\t\t} else {\n\t\t\titer.ReportError(\"readU4\", \"expects 0~9 or a~f, but found \"+string([]byte{c}))\n\t\t\treturn\n\t\t}\n\t}\n\treturn ret\n}\n\nconst (\n\tt1 = 0x00 // 0000 0000\n\ttx = 0x80 // 1000 0000\n\tt2 = 0xC0 // 1100 0000\n\tt3 = 0xE0 // 1110 0000\n\tt4 = 0xF0 // 1111 0000\n\tt5 = 0xF8 // 1111 1000\n\n\tmaskx = 0x3F // 0011 1111\n\tmask2 = 0x1F // 0001 1111\n\tmask3 = 0x0F // 0000 1111\n\tmask4 = 0x07 // 0000 0111\n\n\trune1Max = 1<<7 - 1\n\trune2Max = 1<<11 - 1\n\trune3Max = 1<<16 - 1\n\n\tsurrogateMin = 0xD800\n\tsurrogateMax = 0xDFFF\n\n\tmaxRune   = '\\U0010FFFF' // Maximum valid Unicode code point.\n\truneError = '\\uFFFD'     // the \"error\" Rune or \"Unicode replacement character\"\n)\n\nfunc appendRune(p []byte, r rune) []byte {\n\t// Negative values are erroneous. Making it unsigned addresses the problem.\n\tswitch i := uint32(r); {\n\tcase i <= rune1Max:\n\t\tp = append(p, byte(r))\n\t\treturn p\n\tcase i <= rune2Max:\n\t\tp = append(p, t2|byte(r>>6))\n\t\tp = append(p, tx|byte(r)&maskx)\n\t\treturn p\n\tcase i > maxRune, surrogateMin <= i && i <= surrogateMax:\n\t\tr = runeError\n\t\tfallthrough\n\tcase i <= rune3Max:\n\t\tp = append(p, t3|byte(r>>12))\n\t\tp = append(p, tx|byte(r>>6)&maskx)\n\t\tp = append(p, tx|byte(r)&maskx)\n\t\treturn p\n\tdefault:\n\t\tp = append(p, t4|byte(r>>18))\n\t\tp = append(p, tx|byte(r>>12)&maskx)\n\t\tp = append(p, tx|byte(r>>6)&maskx)\n\t\tp = append(p, tx|byte(r)&maskx)\n\t\treturn p\n\t}\n}\n"
        },
        {
          "name": "jsoniter.go",
          "type": "blob",
          "size": 0.86328125,
          "content": "// Package jsoniter implements encoding and decoding of JSON as defined in\n// RFC 4627 and provides interfaces with identical syntax of standard lib encoding/json.\n// Converting from encoding/json to jsoniter is no more than replacing the package with jsoniter\n// and variable type declarations (if any).\n// jsoniter interfaces gives 100% compatibility with code using standard lib.\n//\n// \"JSON and Go\"\n// (https://golang.org/doc/articles/json_and_go.html)\n// gives a description of how Marshal/Unmarshal operate\n// between arbitrary or predefined json objects and bytes,\n// and it applies to jsoniter.Marshal/Unmarshal as well.\n//\n// Besides, jsoniter.Iterator provides a different set of interfaces\n// iterating given bytes/string/reader\n// and yielding parsed elements one by one.\n// This set of interfaces reads input as required and gives\n// better performance.\npackage jsoniter\n"
        },
        {
          "name": "misc_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "pool.go",
          "type": "blob",
          "size": 0.93359375,
          "content": "package jsoniter\n\nimport (\n\t\"io\"\n)\n\n// IteratorPool a thread safe pool of iterators with same configuration\ntype IteratorPool interface {\n\tBorrowIterator(data []byte) *Iterator\n\tReturnIterator(iter *Iterator)\n}\n\n// StreamPool a thread safe pool of streams with same configuration\ntype StreamPool interface {\n\tBorrowStream(writer io.Writer) *Stream\n\tReturnStream(stream *Stream)\n}\n\nfunc (cfg *frozenConfig) BorrowStream(writer io.Writer) *Stream {\n\tstream := cfg.streamPool.Get().(*Stream)\n\tstream.Reset(writer)\n\treturn stream\n}\n\nfunc (cfg *frozenConfig) ReturnStream(stream *Stream) {\n\tstream.out = nil\n\tstream.Error = nil\n\tstream.Attachment = nil\n\tcfg.streamPool.Put(stream)\n}\n\nfunc (cfg *frozenConfig) BorrowIterator(data []byte) *Iterator {\n\titer := cfg.iteratorPool.Get().(*Iterator)\n\titer.ResetBytes(data)\n\treturn iter\n}\n\nfunc (cfg *frozenConfig) ReturnIterator(iter *Iterator) {\n\titer.Error = nil\n\titer.Attachment = nil\n\tcfg.iteratorPool.Put(iter)\n}\n"
        },
        {
          "name": "reflect.go",
          "type": "blob",
          "size": 8.5322265625,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/reflect2\"\n)\n\n// ValDecoder is an internal type registered to cache as needed.\n// Don't confuse jsoniter.ValDecoder with json.Decoder.\n// For json.Decoder's adapter, refer to jsoniter.AdapterDecoder(todo link).\n//\n// Reflection on type to create decoders, which is then cached\n// Reflection on value is avoided as we can, as the reflect.Value itself will allocate, with following exceptions\n// 1. create instance of new value, for example *int will need a int to be allocated\n// 2. append to slice, if the existing cap is not enough, allocate will be done using Reflect.New\n// 3. assignment to map, both key and value will be reflect.Value\n// For a simple struct binding, it will be reflect.Value free and allocation free\ntype ValDecoder interface {\n\tDecode(ptr unsafe.Pointer, iter *Iterator)\n}\n\n// ValEncoder is an internal type registered to cache as needed.\n// Don't confuse jsoniter.ValEncoder with json.Encoder.\n// For json.Encoder's adapter, refer to jsoniter.AdapterEncoder(todo godoc link).\ntype ValEncoder interface {\n\tIsEmpty(ptr unsafe.Pointer) bool\n\tEncode(ptr unsafe.Pointer, stream *Stream)\n}\n\ntype checkIsEmpty interface {\n\tIsEmpty(ptr unsafe.Pointer) bool\n}\n\ntype ctx struct {\n\t*frozenConfig\n\tprefix   string\n\tencoders map[reflect2.Type]ValEncoder\n\tdecoders map[reflect2.Type]ValDecoder\n}\n\nfunc (b *ctx) caseSensitive() bool {\n\tif b.frozenConfig == nil {\n\t\t// default is case-insensitive\n\t\treturn false\n\t}\n\treturn b.frozenConfig.caseSensitive\n}\n\nfunc (b *ctx) append(prefix string) *ctx {\n\treturn &ctx{\n\t\tfrozenConfig: b.frozenConfig,\n\t\tprefix:       b.prefix + \" \" + prefix,\n\t\tencoders:     b.encoders,\n\t\tdecoders:     b.decoders,\n\t}\n}\n\n// ReadVal copy the underlying JSON into go interface, same as json.Unmarshal\nfunc (iter *Iterator) ReadVal(obj interface{}) {\n\tdepth := iter.depth\n\tcacheKey := reflect2.RTypeOf(obj)\n\tdecoder := iter.cfg.getDecoderFromCache(cacheKey)\n\tif decoder == nil {\n\t\ttyp := reflect2.TypeOf(obj)\n\t\tif typ == nil || typ.Kind() != reflect.Ptr {\n\t\t\titer.ReportError(\"ReadVal\", \"can only unmarshal into pointer\")\n\t\t\treturn\n\t\t}\n\t\tdecoder = iter.cfg.DecoderOf(typ)\n\t}\n\tptr := reflect2.PtrOf(obj)\n\tif ptr == nil {\n\t\titer.ReportError(\"ReadVal\", \"can not read into nil pointer\")\n\t\treturn\n\t}\n\tdecoder.Decode(ptr, iter)\n\tif iter.depth != depth {\n\t\titer.ReportError(\"ReadVal\", \"unexpected mismatched nesting\")\n\t\treturn\n\t}\n}\n\n// WriteVal copy the go interface into underlying JSON, same as json.Marshal\nfunc (stream *Stream) WriteVal(val interface{}) {\n\tif nil == val {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tcacheKey := reflect2.RTypeOf(val)\n\tencoder := stream.cfg.getEncoderFromCache(cacheKey)\n\tif encoder == nil {\n\t\ttyp := reflect2.TypeOf(val)\n\t\tencoder = stream.cfg.EncoderOf(typ)\n\t}\n\tencoder.Encode(reflect2.PtrOf(val), stream)\n}\n\nfunc (cfg *frozenConfig) DecoderOf(typ reflect2.Type) ValDecoder {\n\tcacheKey := typ.RType()\n\tdecoder := cfg.getDecoderFromCache(cacheKey)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tctx := &ctx{\n\t\tfrozenConfig: cfg,\n\t\tprefix:       \"\",\n\t\tdecoders:     map[reflect2.Type]ValDecoder{},\n\t\tencoders:     map[reflect2.Type]ValEncoder{},\n\t}\n\tptrType := typ.(*reflect2.UnsafePtrType)\n\tdecoder = decoderOfType(ctx, ptrType.Elem())\n\tcfg.addDecoderToCache(cacheKey, decoder)\n\treturn decoder\n}\n\nfunc decoderOfType(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tdecoder := getTypeDecoderFromExtension(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tdecoder = createDecoderOfType(ctx, typ)\n\tfor _, extension := range extensions {\n\t\tdecoder = extension.DecorateDecoder(typ, decoder)\n\t}\n\tdecoder = ctx.decoderExtension.DecorateDecoder(typ, decoder)\n\tfor _, extension := range ctx.extraExtensions {\n\t\tdecoder = extension.DecorateDecoder(typ, decoder)\n\t}\n\treturn decoder\n}\n\nfunc createDecoderOfType(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tdecoder := ctx.decoders[typ]\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tplaceholder := &placeholderDecoder{}\n\tctx.decoders[typ] = placeholder\n\tdecoder = _createDecoderOfType(ctx, typ)\n\tplaceholder.decoder = decoder\n\treturn decoder\n}\n\nfunc _createDecoderOfType(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tdecoder := createDecoderOfJsonRawMessage(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tdecoder = createDecoderOfJsonNumber(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tdecoder = createDecoderOfMarshaler(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tdecoder = createDecoderOfAny(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tdecoder = createDecoderOfNative(ctx, typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tswitch typ.Kind() {\n\tcase reflect.Interface:\n\t\tifaceType, isIFace := typ.(*reflect2.UnsafeIFaceType)\n\t\tif isIFace {\n\t\t\treturn &ifaceDecoder{valType: ifaceType}\n\t\t}\n\t\treturn &efaceDecoder{}\n\tcase reflect.Struct:\n\t\treturn decoderOfStruct(ctx, typ)\n\tcase reflect.Array:\n\t\treturn decoderOfArray(ctx, typ)\n\tcase reflect.Slice:\n\t\treturn decoderOfSlice(ctx, typ)\n\tcase reflect.Map:\n\t\treturn decoderOfMap(ctx, typ)\n\tcase reflect.Ptr:\n\t\treturn decoderOfOptional(ctx, typ)\n\tdefault:\n\t\treturn &lazyErrorDecoder{err: fmt.Errorf(\"%s%s is unsupported type\", ctx.prefix, typ.String())}\n\t}\n}\n\nfunc (cfg *frozenConfig) EncoderOf(typ reflect2.Type) ValEncoder {\n\tcacheKey := typ.RType()\n\tencoder := cfg.getEncoderFromCache(cacheKey)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tctx := &ctx{\n\t\tfrozenConfig: cfg,\n\t\tprefix:       \"\",\n\t\tdecoders:     map[reflect2.Type]ValDecoder{},\n\t\tencoders:     map[reflect2.Type]ValEncoder{},\n\t}\n\tencoder = encoderOfType(ctx, typ)\n\tif typ.LikePtr() {\n\t\tencoder = &onePtrEncoder{encoder}\n\t}\n\tcfg.addEncoderToCache(cacheKey, encoder)\n\treturn encoder\n}\n\ntype onePtrEncoder struct {\n\tencoder ValEncoder\n}\n\nfunc (encoder *onePtrEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.encoder.IsEmpty(unsafe.Pointer(&ptr))\n}\n\nfunc (encoder *onePtrEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tencoder.encoder.Encode(unsafe.Pointer(&ptr), stream)\n}\n\nfunc encoderOfType(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tencoder := getTypeEncoderFromExtension(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tencoder = createEncoderOfType(ctx, typ)\n\tfor _, extension := range extensions {\n\t\tencoder = extension.DecorateEncoder(typ, encoder)\n\t}\n\tencoder = ctx.encoderExtension.DecorateEncoder(typ, encoder)\n\tfor _, extension := range ctx.extraExtensions {\n\t\tencoder = extension.DecorateEncoder(typ, encoder)\n\t}\n\treturn encoder\n}\n\nfunc createEncoderOfType(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tencoder := ctx.encoders[typ]\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tplaceholder := &placeholderEncoder{}\n\tctx.encoders[typ] = placeholder\n\tencoder = _createEncoderOfType(ctx, typ)\n\tplaceholder.encoder = encoder\n\treturn encoder\n}\nfunc _createEncoderOfType(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tencoder := createEncoderOfJsonRawMessage(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tencoder = createEncoderOfJsonNumber(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tencoder = createEncoderOfMarshaler(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tencoder = createEncoderOfAny(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tencoder = createEncoderOfNative(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tkind := typ.Kind()\n\tswitch kind {\n\tcase reflect.Interface:\n\t\treturn &dynamicEncoder{typ}\n\tcase reflect.Struct:\n\t\treturn encoderOfStruct(ctx, typ)\n\tcase reflect.Array:\n\t\treturn encoderOfArray(ctx, typ)\n\tcase reflect.Slice:\n\t\treturn encoderOfSlice(ctx, typ)\n\tcase reflect.Map:\n\t\treturn encoderOfMap(ctx, typ)\n\tcase reflect.Ptr:\n\t\treturn encoderOfOptional(ctx, typ)\n\tdefault:\n\t\treturn &lazyErrorEncoder{err: fmt.Errorf(\"%s%s is unsupported type\", ctx.prefix, typ.String())}\n\t}\n}\n\ntype lazyErrorDecoder struct {\n\terr error\n}\n\nfunc (decoder *lazyErrorDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.WhatIsNext() != NilValue {\n\t\tif iter.Error == nil {\n\t\t\titer.Error = decoder.err\n\t\t}\n\t} else {\n\t\titer.Skip()\n\t}\n}\n\ntype lazyErrorEncoder struct {\n\terr error\n}\n\nfunc (encoder *lazyErrorEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif ptr == nil {\n\t\tstream.WriteNil()\n\t} else if stream.Error == nil {\n\t\tstream.Error = encoder.err\n\t}\n}\n\nfunc (encoder *lazyErrorEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn false\n}\n\ntype placeholderDecoder struct {\n\tdecoder ValDecoder\n}\n\nfunc (decoder *placeholderDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.decoder.Decode(ptr, iter)\n}\n\ntype placeholderEncoder struct {\n\tencoder ValEncoder\n}\n\nfunc (encoder *placeholderEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tencoder.encoder.Encode(ptr, stream)\n}\n\nfunc (encoder *placeholderEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.encoder.IsEmpty(ptr)\n}\n"
        },
        {
          "name": "reflect_array.go",
          "type": "blob",
          "size": 2.58984375,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"github.com/modern-go/reflect2\"\n\t\"io\"\n\t\"unsafe\"\n)\n\nfunc decoderOfArray(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tarrayType := typ.(*reflect2.UnsafeArrayType)\n\tdecoder := decoderOfType(ctx.append(\"[arrayElem]\"), arrayType.Elem())\n\treturn &arrayDecoder{arrayType, decoder}\n}\n\nfunc encoderOfArray(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tarrayType := typ.(*reflect2.UnsafeArrayType)\n\tif arrayType.Len() == 0 {\n\t\treturn emptyArrayEncoder{}\n\t}\n\tencoder := encoderOfType(ctx.append(\"[arrayElem]\"), arrayType.Elem())\n\treturn &arrayEncoder{arrayType, encoder}\n}\n\ntype emptyArrayEncoder struct{}\n\nfunc (encoder emptyArrayEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteEmptyArray()\n}\n\nfunc (encoder emptyArrayEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn true\n}\n\ntype arrayEncoder struct {\n\tarrayType   *reflect2.UnsafeArrayType\n\telemEncoder ValEncoder\n}\n\nfunc (encoder *arrayEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteArrayStart()\n\telemPtr := unsafe.Pointer(ptr)\n\tencoder.elemEncoder.Encode(elemPtr, stream)\n\tfor i := 1; i < encoder.arrayType.Len(); i++ {\n\t\tstream.WriteMore()\n\t\telemPtr = encoder.arrayType.UnsafeGetIndex(ptr, i)\n\t\tencoder.elemEncoder.Encode(elemPtr, stream)\n\t}\n\tstream.WriteArrayEnd()\n\tif stream.Error != nil && stream.Error != io.EOF {\n\t\tstream.Error = fmt.Errorf(\"%v: %s\", encoder.arrayType, stream.Error.Error())\n\t}\n}\n\nfunc (encoder *arrayEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn false\n}\n\ntype arrayDecoder struct {\n\tarrayType   *reflect2.UnsafeArrayType\n\telemDecoder ValDecoder\n}\n\nfunc (decoder *arrayDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.doDecode(ptr, iter)\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\titer.Error = fmt.Errorf(\"%v: %s\", decoder.arrayType, iter.Error.Error())\n\t}\n}\n\nfunc (decoder *arrayDecoder) doDecode(ptr unsafe.Pointer, iter *Iterator) {\n\tc := iter.nextToken()\n\tarrayType := decoder.arrayType\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\treturn\n\t}\n\tif c != '[' {\n\t\titer.ReportError(\"decode array\", \"expect [ or n, but found \"+string([]byte{c}))\n\t\treturn\n\t}\n\tc = iter.nextToken()\n\tif c == ']' {\n\t\treturn\n\t}\n\titer.unreadByte()\n\telemPtr := arrayType.UnsafeGetIndex(ptr, 0)\n\tdecoder.elemDecoder.Decode(elemPtr, iter)\n\tlength := 1\n\tfor c = iter.nextToken(); c == ','; c = iter.nextToken() {\n\t\tif length >= arrayType.Len() {\n\t\t\titer.Skip()\n\t\t\tcontinue\n\t\t}\n\t\tidx := length\n\t\tlength += 1\n\t\telemPtr = arrayType.UnsafeGetIndex(ptr, idx)\n\t\tdecoder.elemDecoder.Decode(elemPtr, iter)\n\t}\n\tif c != ']' {\n\t\titer.ReportError(\"decode array\", \"expect ], but found \"+string([]byte{c}))\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "reflect_dynamic.go",
          "type": "blob",
          "size": 1.423828125,
          "content": "package jsoniter\n\nimport (\n\t\"github.com/modern-go/reflect2\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\ntype dynamicEncoder struct {\n\tvalType reflect2.Type\n}\n\nfunc (encoder *dynamicEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tobj := encoder.valType.UnsafeIndirect(ptr)\n\tstream.WriteVal(obj)\n}\n\nfunc (encoder *dynamicEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.valType.UnsafeIndirect(ptr) == nil\n}\n\ntype efaceDecoder struct {\n}\n\nfunc (decoder *efaceDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tpObj := (*interface{})(ptr)\n\tobj := *pObj\n\tif obj == nil {\n\t\t*pObj = iter.Read()\n\t\treturn\n\t}\n\ttyp := reflect2.TypeOf(obj)\n\tif typ.Kind() != reflect.Ptr {\n\t\t*pObj = iter.Read()\n\t\treturn\n\t}\n\tptrType := typ.(*reflect2.UnsafePtrType)\n\tptrElemType := ptrType.Elem()\n\tif iter.WhatIsNext() == NilValue {\n\t\tif ptrElemType.Kind() != reflect.Ptr {\n\t\t\titer.skipFourBytes('n', 'u', 'l', 'l')\n\t\t\t*pObj = nil\n\t\t\treturn\n\t\t}\n\t}\n\tif reflect2.IsNil(obj) {\n\t\tobj := ptrElemType.New()\n\t\titer.ReadVal(obj)\n\t\t*pObj = obj\n\t\treturn\n\t}\n\titer.ReadVal(obj)\n}\n\ntype ifaceDecoder struct {\n\tvalType *reflect2.UnsafeIFaceType\n}\n\nfunc (decoder *ifaceDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.ReadNil() {\n\t\tdecoder.valType.UnsafeSet(ptr, decoder.valType.UnsafeNew())\n\t\treturn\n\t}\n\tobj := decoder.valType.UnsafeIndirect(ptr)\n\tif reflect2.IsNil(obj) {\n\t\titer.ReportError(\"decode non empty interface\", \"can not unmarshal into nil\")\n\t\treturn\n\t}\n\titer.ReadVal(obj)\n}\n"
        },
        {
          "name": "reflect_extension.go",
          "type": "blob",
          "size": 14.2421875,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"github.com/modern-go/reflect2\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"unicode\"\n\t\"unsafe\"\n)\n\nvar typeDecoders = map[string]ValDecoder{}\nvar fieldDecoders = map[string]ValDecoder{}\nvar typeEncoders = map[string]ValEncoder{}\nvar fieldEncoders = map[string]ValEncoder{}\nvar extensions = []Extension{}\n\n// StructDescriptor describe how should we encode/decode the struct\ntype StructDescriptor struct {\n\tType   reflect2.Type\n\tFields []*Binding\n}\n\n// GetField get one field from the descriptor by its name.\n// Can not use map here to keep field orders.\nfunc (structDescriptor *StructDescriptor) GetField(fieldName string) *Binding {\n\tfor _, binding := range structDescriptor.Fields {\n\t\tif binding.Field.Name() == fieldName {\n\t\t\treturn binding\n\t\t}\n\t}\n\treturn nil\n}\n\n// Binding describe how should we encode/decode the struct field\ntype Binding struct {\n\tlevels    []int\n\tField     reflect2.StructField\n\tFromNames []string\n\tToNames   []string\n\tEncoder   ValEncoder\n\tDecoder   ValDecoder\n}\n\n// Extension the one for all SPI. Customize encoding/decoding by specifying alternate encoder/decoder.\n// Can also rename fields by UpdateStructDescriptor.\ntype Extension interface {\n\tUpdateStructDescriptor(structDescriptor *StructDescriptor)\n\tCreateMapKeyDecoder(typ reflect2.Type) ValDecoder\n\tCreateMapKeyEncoder(typ reflect2.Type) ValEncoder\n\tCreateDecoder(typ reflect2.Type) ValDecoder\n\tCreateEncoder(typ reflect2.Type) ValEncoder\n\tDecorateDecoder(typ reflect2.Type, decoder ValDecoder) ValDecoder\n\tDecorateEncoder(typ reflect2.Type, encoder ValEncoder) ValEncoder\n}\n\n// DummyExtension embed this type get dummy implementation for all methods of Extension\ntype DummyExtension struct {\n}\n\n// UpdateStructDescriptor No-op\nfunc (extension *DummyExtension) UpdateStructDescriptor(structDescriptor *StructDescriptor) {\n}\n\n// CreateMapKeyDecoder No-op\nfunc (extension *DummyExtension) CreateMapKeyDecoder(typ reflect2.Type) ValDecoder {\n\treturn nil\n}\n\n// CreateMapKeyEncoder No-op\nfunc (extension *DummyExtension) CreateMapKeyEncoder(typ reflect2.Type) ValEncoder {\n\treturn nil\n}\n\n// CreateDecoder No-op\nfunc (extension *DummyExtension) CreateDecoder(typ reflect2.Type) ValDecoder {\n\treturn nil\n}\n\n// CreateEncoder No-op\nfunc (extension *DummyExtension) CreateEncoder(typ reflect2.Type) ValEncoder {\n\treturn nil\n}\n\n// DecorateDecoder No-op\nfunc (extension *DummyExtension) DecorateDecoder(typ reflect2.Type, decoder ValDecoder) ValDecoder {\n\treturn decoder\n}\n\n// DecorateEncoder No-op\nfunc (extension *DummyExtension) DecorateEncoder(typ reflect2.Type, encoder ValEncoder) ValEncoder {\n\treturn encoder\n}\n\ntype EncoderExtension map[reflect2.Type]ValEncoder\n\n// UpdateStructDescriptor No-op\nfunc (extension EncoderExtension) UpdateStructDescriptor(structDescriptor *StructDescriptor) {\n}\n\n// CreateDecoder No-op\nfunc (extension EncoderExtension) CreateDecoder(typ reflect2.Type) ValDecoder {\n\treturn nil\n}\n\n// CreateEncoder get encoder from map\nfunc (extension EncoderExtension) CreateEncoder(typ reflect2.Type) ValEncoder {\n\treturn extension[typ]\n}\n\n// CreateMapKeyDecoder No-op\nfunc (extension EncoderExtension) CreateMapKeyDecoder(typ reflect2.Type) ValDecoder {\n\treturn nil\n}\n\n// CreateMapKeyEncoder No-op\nfunc (extension EncoderExtension) CreateMapKeyEncoder(typ reflect2.Type) ValEncoder {\n\treturn nil\n}\n\n// DecorateDecoder No-op\nfunc (extension EncoderExtension) DecorateDecoder(typ reflect2.Type, decoder ValDecoder) ValDecoder {\n\treturn decoder\n}\n\n// DecorateEncoder No-op\nfunc (extension EncoderExtension) DecorateEncoder(typ reflect2.Type, encoder ValEncoder) ValEncoder {\n\treturn encoder\n}\n\ntype DecoderExtension map[reflect2.Type]ValDecoder\n\n// UpdateStructDescriptor No-op\nfunc (extension DecoderExtension) UpdateStructDescriptor(structDescriptor *StructDescriptor) {\n}\n\n// CreateMapKeyDecoder No-op\nfunc (extension DecoderExtension) CreateMapKeyDecoder(typ reflect2.Type) ValDecoder {\n\treturn nil\n}\n\n// CreateMapKeyEncoder No-op\nfunc (extension DecoderExtension) CreateMapKeyEncoder(typ reflect2.Type) ValEncoder {\n\treturn nil\n}\n\n// CreateDecoder get decoder from map\nfunc (extension DecoderExtension) CreateDecoder(typ reflect2.Type) ValDecoder {\n\treturn extension[typ]\n}\n\n// CreateEncoder No-op\nfunc (extension DecoderExtension) CreateEncoder(typ reflect2.Type) ValEncoder {\n\treturn nil\n}\n\n// DecorateDecoder No-op\nfunc (extension DecoderExtension) DecorateDecoder(typ reflect2.Type, decoder ValDecoder) ValDecoder {\n\treturn decoder\n}\n\n// DecorateEncoder No-op\nfunc (extension DecoderExtension) DecorateEncoder(typ reflect2.Type, encoder ValEncoder) ValEncoder {\n\treturn encoder\n}\n\ntype funcDecoder struct {\n\tfun DecoderFunc\n}\n\nfunc (decoder *funcDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.fun(ptr, iter)\n}\n\ntype funcEncoder struct {\n\tfun         EncoderFunc\n\tisEmptyFunc func(ptr unsafe.Pointer) bool\n}\n\nfunc (encoder *funcEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tencoder.fun(ptr, stream)\n}\n\nfunc (encoder *funcEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\tif encoder.isEmptyFunc == nil {\n\t\treturn false\n\t}\n\treturn encoder.isEmptyFunc(ptr)\n}\n\n// DecoderFunc the function form of TypeDecoder\ntype DecoderFunc func(ptr unsafe.Pointer, iter *Iterator)\n\n// EncoderFunc the function form of TypeEncoder\ntype EncoderFunc func(ptr unsafe.Pointer, stream *Stream)\n\n// RegisterTypeDecoderFunc register TypeDecoder for a type with function\nfunc RegisterTypeDecoderFunc(typ string, fun DecoderFunc) {\n\ttypeDecoders[typ] = &funcDecoder{fun}\n}\n\n// RegisterTypeDecoder register TypeDecoder for a typ\nfunc RegisterTypeDecoder(typ string, decoder ValDecoder) {\n\ttypeDecoders[typ] = decoder\n}\n\n// RegisterFieldDecoderFunc register TypeDecoder for a struct field with function\nfunc RegisterFieldDecoderFunc(typ string, field string, fun DecoderFunc) {\n\tRegisterFieldDecoder(typ, field, &funcDecoder{fun})\n}\n\n// RegisterFieldDecoder register TypeDecoder for a struct field\nfunc RegisterFieldDecoder(typ string, field string, decoder ValDecoder) {\n\tfieldDecoders[fmt.Sprintf(\"%s/%s\", typ, field)] = decoder\n}\n\n// RegisterTypeEncoderFunc register TypeEncoder for a type with encode/isEmpty function\nfunc RegisterTypeEncoderFunc(typ string, fun EncoderFunc, isEmptyFunc func(unsafe.Pointer) bool) {\n\ttypeEncoders[typ] = &funcEncoder{fun, isEmptyFunc}\n}\n\n// RegisterTypeEncoder register TypeEncoder for a type\nfunc RegisterTypeEncoder(typ string, encoder ValEncoder) {\n\ttypeEncoders[typ] = encoder\n}\n\n// RegisterFieldEncoderFunc register TypeEncoder for a struct field with encode/isEmpty function\nfunc RegisterFieldEncoderFunc(typ string, field string, fun EncoderFunc, isEmptyFunc func(unsafe.Pointer) bool) {\n\tRegisterFieldEncoder(typ, field, &funcEncoder{fun, isEmptyFunc})\n}\n\n// RegisterFieldEncoder register TypeEncoder for a struct field\nfunc RegisterFieldEncoder(typ string, field string, encoder ValEncoder) {\n\tfieldEncoders[fmt.Sprintf(\"%s/%s\", typ, field)] = encoder\n}\n\n// RegisterExtension register extension\nfunc RegisterExtension(extension Extension) {\n\textensions = append(extensions, extension)\n}\n\nfunc getTypeDecoderFromExtension(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tdecoder := _getTypeDecoderFromExtension(ctx, typ)\n\tif decoder != nil {\n\t\tfor _, extension := range extensions {\n\t\t\tdecoder = extension.DecorateDecoder(typ, decoder)\n\t\t}\n\t\tdecoder = ctx.decoderExtension.DecorateDecoder(typ, decoder)\n\t\tfor _, extension := range ctx.extraExtensions {\n\t\t\tdecoder = extension.DecorateDecoder(typ, decoder)\n\t\t}\n\t}\n\treturn decoder\n}\nfunc _getTypeDecoderFromExtension(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tfor _, extension := range extensions {\n\t\tdecoder := extension.CreateDecoder(typ)\n\t\tif decoder != nil {\n\t\t\treturn decoder\n\t\t}\n\t}\n\tdecoder := ctx.decoderExtension.CreateDecoder(typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tfor _, extension := range ctx.extraExtensions {\n\t\tdecoder := extension.CreateDecoder(typ)\n\t\tif decoder != nil {\n\t\t\treturn decoder\n\t\t}\n\t}\n\ttypeName := typ.String()\n\tdecoder = typeDecoders[typeName]\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tif typ.Kind() == reflect.Ptr {\n\t\tptrType := typ.(*reflect2.UnsafePtrType)\n\t\tdecoder := typeDecoders[ptrType.Elem().String()]\n\t\tif decoder != nil {\n\t\t\treturn &OptionalDecoder{ptrType.Elem(), decoder}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc getTypeEncoderFromExtension(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tencoder := _getTypeEncoderFromExtension(ctx, typ)\n\tif encoder != nil {\n\t\tfor _, extension := range extensions {\n\t\t\tencoder = extension.DecorateEncoder(typ, encoder)\n\t\t}\n\t\tencoder = ctx.encoderExtension.DecorateEncoder(typ, encoder)\n\t\tfor _, extension := range ctx.extraExtensions {\n\t\t\tencoder = extension.DecorateEncoder(typ, encoder)\n\t\t}\n\t}\n\treturn encoder\n}\n\nfunc _getTypeEncoderFromExtension(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tfor _, extension := range extensions {\n\t\tencoder := extension.CreateEncoder(typ)\n\t\tif encoder != nil {\n\t\t\treturn encoder\n\t\t}\n\t}\n\tencoder := ctx.encoderExtension.CreateEncoder(typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tfor _, extension := range ctx.extraExtensions {\n\t\tencoder := extension.CreateEncoder(typ)\n\t\tif encoder != nil {\n\t\t\treturn encoder\n\t\t}\n\t}\n\ttypeName := typ.String()\n\tencoder = typeEncoders[typeName]\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tif typ.Kind() == reflect.Ptr {\n\t\ttypePtr := typ.(*reflect2.UnsafePtrType)\n\t\tencoder := typeEncoders[typePtr.Elem().String()]\n\t\tif encoder != nil {\n\t\t\treturn &OptionalEncoder{encoder}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc describeStruct(ctx *ctx, typ reflect2.Type) *StructDescriptor {\n\tstructType := typ.(*reflect2.UnsafeStructType)\n\tembeddedBindings := []*Binding{}\n\tbindings := []*Binding{}\n\tfor i := 0; i < structType.NumField(); i++ {\n\t\tfield := structType.Field(i)\n\t\ttag, hastag := field.Tag().Lookup(ctx.getTagKey())\n\t\tif ctx.onlyTaggedField && !hastag && !field.Anonymous() {\n\t\t\tcontinue\n\t\t}\n\t\tif tag == \"-\" || field.Name() == \"_\" {\n\t\t\tcontinue\n\t\t}\n\t\ttagParts := strings.Split(tag, \",\")\n\t\tif field.Anonymous() && (tag == \"\" || tagParts[0] == \"\") {\n\t\t\tif field.Type().Kind() == reflect.Struct {\n\t\t\t\tstructDescriptor := describeStruct(ctx, field.Type())\n\t\t\t\tfor _, binding := range structDescriptor.Fields {\n\t\t\t\t\tbinding.levels = append([]int{i}, binding.levels...)\n\t\t\t\t\tomitempty := binding.Encoder.(*structFieldEncoder).omitempty\n\t\t\t\t\tbinding.Encoder = &structFieldEncoder{field, binding.Encoder, omitempty}\n\t\t\t\t\tbinding.Decoder = &structFieldDecoder{field, binding.Decoder}\n\t\t\t\t\tembeddedBindings = append(embeddedBindings, binding)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t} else if field.Type().Kind() == reflect.Ptr {\n\t\t\t\tptrType := field.Type().(*reflect2.UnsafePtrType)\n\t\t\t\tif ptrType.Elem().Kind() == reflect.Struct {\n\t\t\t\t\tstructDescriptor := describeStruct(ctx, ptrType.Elem())\n\t\t\t\t\tfor _, binding := range structDescriptor.Fields {\n\t\t\t\t\t\tbinding.levels = append([]int{i}, binding.levels...)\n\t\t\t\t\t\tomitempty := binding.Encoder.(*structFieldEncoder).omitempty\n\t\t\t\t\t\tbinding.Encoder = &dereferenceEncoder{binding.Encoder}\n\t\t\t\t\t\tbinding.Encoder = &structFieldEncoder{field, binding.Encoder, omitempty}\n\t\t\t\t\t\tbinding.Decoder = &dereferenceDecoder{ptrType.Elem(), binding.Decoder}\n\t\t\t\t\t\tbinding.Decoder = &structFieldDecoder{field, binding.Decoder}\n\t\t\t\t\t\tembeddedBindings = append(embeddedBindings, binding)\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfieldNames := calcFieldNames(field.Name(), tagParts[0], tag)\n\t\tfieldCacheKey := fmt.Sprintf(\"%s/%s\", typ.String(), field.Name())\n\t\tdecoder := fieldDecoders[fieldCacheKey]\n\t\tif decoder == nil {\n\t\t\tdecoder = decoderOfType(ctx.append(field.Name()), field.Type())\n\t\t}\n\t\tencoder := fieldEncoders[fieldCacheKey]\n\t\tif encoder == nil {\n\t\t\tencoder = encoderOfType(ctx.append(field.Name()), field.Type())\n\t\t}\n\t\tbinding := &Binding{\n\t\t\tField:     field,\n\t\t\tFromNames: fieldNames,\n\t\t\tToNames:   fieldNames,\n\t\t\tDecoder:   decoder,\n\t\t\tEncoder:   encoder,\n\t\t}\n\t\tbinding.levels = []int{i}\n\t\tbindings = append(bindings, binding)\n\t}\n\treturn createStructDescriptor(ctx, typ, bindings, embeddedBindings)\n}\nfunc createStructDescriptor(ctx *ctx, typ reflect2.Type, bindings []*Binding, embeddedBindings []*Binding) *StructDescriptor {\n\tstructDescriptor := &StructDescriptor{\n\t\tType:   typ,\n\t\tFields: bindings,\n\t}\n\tfor _, extension := range extensions {\n\t\textension.UpdateStructDescriptor(structDescriptor)\n\t}\n\tctx.encoderExtension.UpdateStructDescriptor(structDescriptor)\n\tctx.decoderExtension.UpdateStructDescriptor(structDescriptor)\n\tfor _, extension := range ctx.extraExtensions {\n\t\textension.UpdateStructDescriptor(structDescriptor)\n\t}\n\tprocessTags(structDescriptor, ctx.frozenConfig)\n\t// merge normal & embedded bindings & sort with original order\n\tallBindings := sortableBindings(append(embeddedBindings, structDescriptor.Fields...))\n\tsort.Sort(allBindings)\n\tstructDescriptor.Fields = allBindings\n\treturn structDescriptor\n}\n\ntype sortableBindings []*Binding\n\nfunc (bindings sortableBindings) Len() int {\n\treturn len(bindings)\n}\n\nfunc (bindings sortableBindings) Less(i, j int) bool {\n\tleft := bindings[i].levels\n\tright := bindings[j].levels\n\tk := 0\n\tfor {\n\t\tif left[k] < right[k] {\n\t\t\treturn true\n\t\t} else if left[k] > right[k] {\n\t\t\treturn false\n\t\t}\n\t\tk++\n\t}\n}\n\nfunc (bindings sortableBindings) Swap(i, j int) {\n\tbindings[i], bindings[j] = bindings[j], bindings[i]\n}\n\nfunc processTags(structDescriptor *StructDescriptor, cfg *frozenConfig) {\n\tfor _, binding := range structDescriptor.Fields {\n\t\tshouldOmitEmpty := false\n\t\ttagParts := strings.Split(binding.Field.Tag().Get(cfg.getTagKey()), \",\")\n\t\tfor _, tagPart := range tagParts[1:] {\n\t\t\tif tagPart == \"omitempty\" {\n\t\t\t\tshouldOmitEmpty = true\n\t\t\t} else if tagPart == \"string\" {\n\t\t\t\tif binding.Field.Type().Kind() == reflect.String {\n\t\t\t\t\tbinding.Decoder = &stringModeStringDecoder{binding.Decoder, cfg}\n\t\t\t\t\tbinding.Encoder = &stringModeStringEncoder{binding.Encoder, cfg}\n\t\t\t\t} else {\n\t\t\t\t\tbinding.Decoder = &stringModeNumberDecoder{binding.Decoder}\n\t\t\t\t\tbinding.Encoder = &stringModeNumberEncoder{binding.Encoder}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tbinding.Decoder = &structFieldDecoder{binding.Field, binding.Decoder}\n\t\tbinding.Encoder = &structFieldEncoder{binding.Field, binding.Encoder, shouldOmitEmpty}\n\t}\n}\n\nfunc calcFieldNames(originalFieldName string, tagProvidedFieldName string, wholeTag string) []string {\n\t// ignore?\n\tif wholeTag == \"-\" {\n\t\treturn []string{}\n\t}\n\t// rename?\n\tvar fieldNames []string\n\tif tagProvidedFieldName == \"\" {\n\t\tfieldNames = []string{originalFieldName}\n\t} else {\n\t\tfieldNames = []string{tagProvidedFieldName}\n\t}\n\t// private?\n\tisNotExported := unicode.IsLower(rune(originalFieldName[0])) || originalFieldName[0] == '_'\n\tif isNotExported {\n\t\tfieldNames = []string{}\n\t}\n\treturn fieldNames\n}\n"
        },
        {
          "name": "reflect_json_number.go",
          "type": "blob",
          "size": 2.630859375,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/json\"\n\t\"github.com/modern-go/reflect2\"\n\t\"strconv\"\n\t\"unsafe\"\n)\n\ntype Number string\n\n// String returns the literal text of the number.\nfunc (n Number) String() string { return string(n) }\n\n// Float64 returns the number as a float64.\nfunc (n Number) Float64() (float64, error) {\n\treturn strconv.ParseFloat(string(n), 64)\n}\n\n// Int64 returns the number as an int64.\nfunc (n Number) Int64() (int64, error) {\n\treturn strconv.ParseInt(string(n), 10, 64)\n}\n\nfunc CastJsonNumber(val interface{}) (string, bool) {\n\tswitch typedVal := val.(type) {\n\tcase json.Number:\n\t\treturn string(typedVal), true\n\tcase Number:\n\t\treturn string(typedVal), true\n\t}\n\treturn \"\", false\n}\n\nvar jsonNumberType = reflect2.TypeOfPtr((*json.Number)(nil)).Elem()\nvar jsoniterNumberType = reflect2.TypeOfPtr((*Number)(nil)).Elem()\n\nfunc createDecoderOfJsonNumber(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tif typ.AssignableTo(jsonNumberType) {\n\t\treturn &jsonNumberCodec{}\n\t}\n\tif typ.AssignableTo(jsoniterNumberType) {\n\t\treturn &jsoniterNumberCodec{}\n\t}\n\treturn nil\n}\n\nfunc createEncoderOfJsonNumber(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tif typ.AssignableTo(jsonNumberType) {\n\t\treturn &jsonNumberCodec{}\n\t}\n\tif typ.AssignableTo(jsoniterNumberType) {\n\t\treturn &jsoniterNumberCodec{}\n\t}\n\treturn nil\n}\n\ntype jsonNumberCodec struct {\n}\n\nfunc (codec *jsonNumberCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tswitch iter.WhatIsNext() {\n\tcase StringValue:\n\t\t*((*json.Number)(ptr)) = json.Number(iter.ReadString())\n\tcase NilValue:\n\t\titer.skipFourBytes('n', 'u', 'l', 'l')\n\t\t*((*json.Number)(ptr)) = \"\"\n\tdefault:\n\t\t*((*json.Number)(ptr)) = json.Number([]byte(iter.readNumberAsString()))\n\t}\n}\n\nfunc (codec *jsonNumberCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tnumber := *((*json.Number)(ptr))\n\tif len(number) == 0 {\n\t\tstream.writeByte('0')\n\t} else {\n\t\tstream.WriteRaw(string(number))\n\t}\n}\n\nfunc (codec *jsonNumberCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn len(*((*json.Number)(ptr))) == 0\n}\n\ntype jsoniterNumberCodec struct {\n}\n\nfunc (codec *jsoniterNumberCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tswitch iter.WhatIsNext() {\n\tcase StringValue:\n\t\t*((*Number)(ptr)) = Number(iter.ReadString())\n\tcase NilValue:\n\t\titer.skipFourBytes('n', 'u', 'l', 'l')\n\t\t*((*Number)(ptr)) = \"\"\n\tdefault:\n\t\t*((*Number)(ptr)) = Number([]byte(iter.readNumberAsString()))\n\t}\n}\n\nfunc (codec *jsoniterNumberCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tnumber := *((*Number)(ptr))\n\tif len(number) == 0 {\n\t\tstream.writeByte('0')\n\t} else {\n\t\tstream.WriteRaw(string(number))\n\t}\n}\n\nfunc (codec *jsoniterNumberCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn len(*((*Number)(ptr))) == 0\n}\n"
        },
        {
          "name": "reflect_json_raw_message.go",
          "type": "blob",
          "size": 1.798828125,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/json\"\n\t\"github.com/modern-go/reflect2\"\n\t\"unsafe\"\n)\n\nvar jsonRawMessageType = reflect2.TypeOfPtr((*json.RawMessage)(nil)).Elem()\nvar jsoniterRawMessageType = reflect2.TypeOfPtr((*RawMessage)(nil)).Elem()\n\nfunc createEncoderOfJsonRawMessage(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tif typ == jsonRawMessageType {\n\t\treturn &jsonRawMessageCodec{}\n\t}\n\tif typ == jsoniterRawMessageType {\n\t\treturn &jsoniterRawMessageCodec{}\n\t}\n\treturn nil\n}\n\nfunc createDecoderOfJsonRawMessage(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tif typ == jsonRawMessageType {\n\t\treturn &jsonRawMessageCodec{}\n\t}\n\tif typ == jsoniterRawMessageType {\n\t\treturn &jsoniterRawMessageCodec{}\n\t}\n\treturn nil\n}\n\ntype jsonRawMessageCodec struct {\n}\n\nfunc (codec *jsonRawMessageCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.ReadNil() {\n\t\t*((*json.RawMessage)(ptr)) = nil\n\t} else {\n\t\t*((*json.RawMessage)(ptr)) = iter.SkipAndReturnBytes()\n\t}\n}\n\nfunc (codec *jsonRawMessageCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *((*json.RawMessage)(ptr)) == nil {\n\t\tstream.WriteNil()\n\t} else {\n\t\tstream.WriteRaw(string(*((*json.RawMessage)(ptr))))\n\t}\n}\n\nfunc (codec *jsonRawMessageCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn len(*((*json.RawMessage)(ptr))) == 0\n}\n\ntype jsoniterRawMessageCodec struct {\n}\n\nfunc (codec *jsoniterRawMessageCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.ReadNil() {\n\t\t*((*RawMessage)(ptr)) = nil\n\t} else {\n\t\t*((*RawMessage)(ptr)) = iter.SkipAndReturnBytes()\n\t}\n}\n\nfunc (codec *jsoniterRawMessageCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *((*RawMessage)(ptr)) == nil {\n\t\tstream.WriteNil()\n\t} else {\n\t\tstream.WriteRaw(string(*((*RawMessage)(ptr))))\n\t}\n}\n\nfunc (codec *jsoniterRawMessageCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn len(*((*RawMessage)(ptr))) == 0\n}\n"
        },
        {
          "name": "reflect_map.go",
          "type": "blob",
          "size": 8.99609375,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"sort\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/reflect2\"\n)\n\nfunc decoderOfMap(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tmapType := typ.(*reflect2.UnsafeMapType)\n\tkeyDecoder := decoderOfMapKey(ctx.append(\"[mapKey]\"), mapType.Key())\n\telemDecoder := decoderOfType(ctx.append(\"[mapElem]\"), mapType.Elem())\n\treturn &mapDecoder{\n\t\tmapType:     mapType,\n\t\tkeyType:     mapType.Key(),\n\t\telemType:    mapType.Elem(),\n\t\tkeyDecoder:  keyDecoder,\n\t\telemDecoder: elemDecoder,\n\t}\n}\n\nfunc encoderOfMap(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tmapType := typ.(*reflect2.UnsafeMapType)\n\tif ctx.sortMapKeys {\n\t\treturn &sortKeysMapEncoder{\n\t\t\tmapType:     mapType,\n\t\t\tkeyEncoder:  encoderOfMapKey(ctx.append(\"[mapKey]\"), mapType.Key()),\n\t\t\telemEncoder: encoderOfType(ctx.append(\"[mapElem]\"), mapType.Elem()),\n\t\t}\n\t}\n\treturn &mapEncoder{\n\t\tmapType:     mapType,\n\t\tkeyEncoder:  encoderOfMapKey(ctx.append(\"[mapKey]\"), mapType.Key()),\n\t\telemEncoder: encoderOfType(ctx.append(\"[mapElem]\"), mapType.Elem()),\n\t}\n}\n\nfunc decoderOfMapKey(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tdecoder := ctx.decoderExtension.CreateMapKeyDecoder(typ)\n\tif decoder != nil {\n\t\treturn decoder\n\t}\n\tfor _, extension := range ctx.extraExtensions {\n\t\tdecoder := extension.CreateMapKeyDecoder(typ)\n\t\tif decoder != nil {\n\t\t\treturn decoder\n\t\t}\n\t}\n\n\tptrType := reflect2.PtrTo(typ)\n\tif ptrType.Implements(unmarshalerType) {\n\t\treturn &referenceDecoder{\n\t\t\t&unmarshalerDecoder{\n\t\t\t\tvalType: ptrType,\n\t\t\t},\n\t\t}\n\t}\n\tif typ.Implements(unmarshalerType) {\n\t\treturn &unmarshalerDecoder{\n\t\t\tvalType: typ,\n\t\t}\n\t}\n\tif ptrType.Implements(textUnmarshalerType) {\n\t\treturn &referenceDecoder{\n\t\t\t&textUnmarshalerDecoder{\n\t\t\t\tvalType: ptrType,\n\t\t\t},\n\t\t}\n\t}\n\tif typ.Implements(textUnmarshalerType) {\n\t\treturn &textUnmarshalerDecoder{\n\t\t\tvalType: typ,\n\t\t}\n\t}\n\n\tswitch typ.Kind() {\n\tcase reflect.String:\n\t\treturn decoderOfType(ctx, reflect2.DefaultTypeOfKind(reflect.String))\n\tcase reflect.Bool,\n\t\treflect.Uint8, reflect.Int8,\n\t\treflect.Uint16, reflect.Int16,\n\t\treflect.Uint32, reflect.Int32,\n\t\treflect.Uint64, reflect.Int64,\n\t\treflect.Uint, reflect.Int,\n\t\treflect.Float32, reflect.Float64,\n\t\treflect.Uintptr:\n\t\ttyp = reflect2.DefaultTypeOfKind(typ.Kind())\n\t\treturn &numericMapKeyDecoder{decoderOfType(ctx, typ)}\n\tdefault:\n\t\treturn &lazyErrorDecoder{err: fmt.Errorf(\"unsupported map key type: %v\", typ)}\n\t}\n}\n\nfunc encoderOfMapKey(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tencoder := ctx.encoderExtension.CreateMapKeyEncoder(typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tfor _, extension := range ctx.extraExtensions {\n\t\tencoder := extension.CreateMapKeyEncoder(typ)\n\t\tif encoder != nil {\n\t\t\treturn encoder\n\t\t}\n\t}\n\n\tif typ.Kind() != reflect.String {\n\t\tif typ == textMarshalerType {\n\t\t\treturn &directTextMarshalerEncoder{\n\t\t\t\tstringEncoder: ctx.EncoderOf(reflect2.TypeOf(\"\")),\n\t\t\t}\n\t\t}\n\t\tif typ.Implements(textMarshalerType) {\n\t\t\treturn &textMarshalerEncoder{\n\t\t\t\tvalType:       typ,\n\t\t\t\tstringEncoder: ctx.EncoderOf(reflect2.TypeOf(\"\")),\n\t\t\t}\n\t\t}\n\t}\n\n\tswitch typ.Kind() {\n\tcase reflect.String:\n\t\treturn encoderOfType(ctx, reflect2.DefaultTypeOfKind(reflect.String))\n\tcase reflect.Bool,\n\t\treflect.Uint8, reflect.Int8,\n\t\treflect.Uint16, reflect.Int16,\n\t\treflect.Uint32, reflect.Int32,\n\t\treflect.Uint64, reflect.Int64,\n\t\treflect.Uint, reflect.Int,\n\t\treflect.Float32, reflect.Float64,\n\t\treflect.Uintptr:\n\t\ttyp = reflect2.DefaultTypeOfKind(typ.Kind())\n\t\treturn &numericMapKeyEncoder{encoderOfType(ctx, typ)}\n\tdefault:\n\t\tif typ.Kind() == reflect.Interface {\n\t\t\treturn &dynamicMapKeyEncoder{ctx, typ}\n\t\t}\n\t\treturn &lazyErrorEncoder{err: fmt.Errorf(\"unsupported map key type: %v\", typ)}\n\t}\n}\n\ntype mapDecoder struct {\n\tmapType     *reflect2.UnsafeMapType\n\tkeyType     reflect2.Type\n\telemType    reflect2.Type\n\tkeyDecoder  ValDecoder\n\telemDecoder ValDecoder\n}\n\nfunc (decoder *mapDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tmapType := decoder.mapType\n\tc := iter.nextToken()\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\t*(*unsafe.Pointer)(ptr) = nil\n\t\tmapType.UnsafeSet(ptr, mapType.UnsafeNew())\n\t\treturn\n\t}\n\tif mapType.UnsafeIsNil(ptr) {\n\t\tmapType.UnsafeSet(ptr, mapType.UnsafeMakeMap(0))\n\t}\n\tif c != '{' {\n\t\titer.ReportError(\"ReadMapCB\", `expect { or n, but found `+string([]byte{c}))\n\t\treturn\n\t}\n\tc = iter.nextToken()\n\tif c == '}' {\n\t\treturn\n\t}\n\titer.unreadByte()\n\tkey := decoder.keyType.UnsafeNew()\n\tdecoder.keyDecoder.Decode(key, iter)\n\tc = iter.nextToken()\n\tif c != ':' {\n\t\titer.ReportError(\"ReadMapCB\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\treturn\n\t}\n\telem := decoder.elemType.UnsafeNew()\n\tdecoder.elemDecoder.Decode(elem, iter)\n\tdecoder.mapType.UnsafeSetIndex(ptr, key, elem)\n\tfor c = iter.nextToken(); c == ','; c = iter.nextToken() {\n\t\tkey := decoder.keyType.UnsafeNew()\n\t\tdecoder.keyDecoder.Decode(key, iter)\n\t\tc = iter.nextToken()\n\t\tif c != ':' {\n\t\t\titer.ReportError(\"ReadMapCB\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t\treturn\n\t\t}\n\t\telem := decoder.elemType.UnsafeNew()\n\t\tdecoder.elemDecoder.Decode(elem, iter)\n\t\tdecoder.mapType.UnsafeSetIndex(ptr, key, elem)\n\t}\n\tif c != '}' {\n\t\titer.ReportError(\"ReadMapCB\", `expect }, but found `+string([]byte{c}))\n\t}\n}\n\ntype numericMapKeyDecoder struct {\n\tdecoder ValDecoder\n}\n\nfunc (decoder *numericMapKeyDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tc := iter.nextToken()\n\tif c != '\"' {\n\t\titer.ReportError(\"ReadMapCB\", `expect \", but found `+string([]byte{c}))\n\t\treturn\n\t}\n\tdecoder.decoder.Decode(ptr, iter)\n\tc = iter.nextToken()\n\tif c != '\"' {\n\t\titer.ReportError(\"ReadMapCB\", `expect \", but found `+string([]byte{c}))\n\t\treturn\n\t}\n}\n\ntype numericMapKeyEncoder struct {\n\tencoder ValEncoder\n}\n\nfunc (encoder *numericMapKeyEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.writeByte('\"')\n\tencoder.encoder.Encode(ptr, stream)\n\tstream.writeByte('\"')\n}\n\nfunc (encoder *numericMapKeyEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn false\n}\n\ntype dynamicMapKeyEncoder struct {\n\tctx     *ctx\n\tvalType reflect2.Type\n}\n\nfunc (encoder *dynamicMapKeyEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tobj := encoder.valType.UnsafeIndirect(ptr)\n\tencoderOfMapKey(encoder.ctx, reflect2.TypeOf(obj)).Encode(reflect2.PtrOf(obj), stream)\n}\n\nfunc (encoder *dynamicMapKeyEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\tobj := encoder.valType.UnsafeIndirect(ptr)\n\treturn encoderOfMapKey(encoder.ctx, reflect2.TypeOf(obj)).IsEmpty(reflect2.PtrOf(obj))\n}\n\ntype mapEncoder struct {\n\tmapType     *reflect2.UnsafeMapType\n\tkeyEncoder  ValEncoder\n\telemEncoder ValEncoder\n}\n\nfunc (encoder *mapEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *(*unsafe.Pointer)(ptr) == nil {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tstream.WriteObjectStart()\n\titer := encoder.mapType.UnsafeIterate(ptr)\n\tfor i := 0; iter.HasNext(); i++ {\n\t\tif i != 0 {\n\t\t\tstream.WriteMore()\n\t\t}\n\t\tkey, elem := iter.UnsafeNext()\n\t\tencoder.keyEncoder.Encode(key, stream)\n\t\tif stream.indention > 0 {\n\t\t\tstream.writeTwoBytes(byte(':'), byte(' '))\n\t\t} else {\n\t\t\tstream.writeByte(':')\n\t\t}\n\t\tencoder.elemEncoder.Encode(elem, stream)\n\t}\n\tstream.WriteObjectEnd()\n}\n\nfunc (encoder *mapEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\titer := encoder.mapType.UnsafeIterate(ptr)\n\treturn !iter.HasNext()\n}\n\ntype sortKeysMapEncoder struct {\n\tmapType     *reflect2.UnsafeMapType\n\tkeyEncoder  ValEncoder\n\telemEncoder ValEncoder\n}\n\nfunc (encoder *sortKeysMapEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *(*unsafe.Pointer)(ptr) == nil {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tstream.WriteObjectStart()\n\tmapIter := encoder.mapType.UnsafeIterate(ptr)\n\tsubStream := stream.cfg.BorrowStream(nil)\n\tsubStream.Attachment = stream.Attachment\n\tsubIter := stream.cfg.BorrowIterator(nil)\n\tkeyValues := encodedKeyValues{}\n\tfor mapIter.HasNext() {\n\t\tkey, elem := mapIter.UnsafeNext()\n\t\tsubStreamIndex := subStream.Buffered()\n\t\tencoder.keyEncoder.Encode(key, subStream)\n\t\tif subStream.Error != nil && subStream.Error != io.EOF && stream.Error == nil {\n\t\t\tstream.Error = subStream.Error\n\t\t}\n\t\tencodedKey := subStream.Buffer()[subStreamIndex:]\n\t\tsubIter.ResetBytes(encodedKey)\n\t\tdecodedKey := subIter.ReadString()\n\t\tif stream.indention > 0 {\n\t\t\tsubStream.writeTwoBytes(byte(':'), byte(' '))\n\t\t} else {\n\t\t\tsubStream.writeByte(':')\n\t\t}\n\t\tencoder.elemEncoder.Encode(elem, subStream)\n\t\tkeyValues = append(keyValues, encodedKV{\n\t\t\tkey:      decodedKey,\n\t\t\tkeyValue: subStream.Buffer()[subStreamIndex:],\n\t\t})\n\t}\n\tsort.Sort(keyValues)\n\tfor i, keyValue := range keyValues {\n\t\tif i != 0 {\n\t\t\tstream.WriteMore()\n\t\t}\n\t\tstream.Write(keyValue.keyValue)\n\t}\n\tif subStream.Error != nil && stream.Error == nil {\n\t\tstream.Error = subStream.Error\n\t}\n\tstream.WriteObjectEnd()\n\tstream.cfg.ReturnStream(subStream)\n\tstream.cfg.ReturnIterator(subIter)\n}\n\nfunc (encoder *sortKeysMapEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\titer := encoder.mapType.UnsafeIterate(ptr)\n\treturn !iter.HasNext()\n}\n\ntype encodedKeyValues []encodedKV\n\ntype encodedKV struct {\n\tkey      string\n\tkeyValue []byte\n}\n\nfunc (sv encodedKeyValues) Len() int           { return len(sv) }\nfunc (sv encodedKeyValues) Swap(i, j int)      { sv[i], sv[j] = sv[j], sv[i] }\nfunc (sv encodedKeyValues) Less(i, j int) bool { return sv[i].key < sv[j].key }\n"
        },
        {
          "name": "reflect_marshaler.go",
          "type": "blob",
          "size": 5.82421875,
          "content": "package jsoniter\n\nimport (\n\t\"encoding\"\n\t\"encoding/json\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/reflect2\"\n)\n\nvar marshalerType = reflect2.TypeOfPtr((*json.Marshaler)(nil)).Elem()\nvar unmarshalerType = reflect2.TypeOfPtr((*json.Unmarshaler)(nil)).Elem()\nvar textMarshalerType = reflect2.TypeOfPtr((*encoding.TextMarshaler)(nil)).Elem()\nvar textUnmarshalerType = reflect2.TypeOfPtr((*encoding.TextUnmarshaler)(nil)).Elem()\n\nfunc createDecoderOfMarshaler(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tptrType := reflect2.PtrTo(typ)\n\tif ptrType.Implements(unmarshalerType) {\n\t\treturn &referenceDecoder{\n\t\t\t&unmarshalerDecoder{ptrType},\n\t\t}\n\t}\n\tif ptrType.Implements(textUnmarshalerType) {\n\t\treturn &referenceDecoder{\n\t\t\t&textUnmarshalerDecoder{ptrType},\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc createEncoderOfMarshaler(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tif typ == marshalerType {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, typ)\n\t\tvar encoder ValEncoder = &directMarshalerEncoder{\n\t\t\tcheckIsEmpty: checkIsEmpty,\n\t\t}\n\t\treturn encoder\n\t}\n\tif typ.Implements(marshalerType) {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, typ)\n\t\tvar encoder ValEncoder = &marshalerEncoder{\n\t\t\tvalType:      typ,\n\t\t\tcheckIsEmpty: checkIsEmpty,\n\t\t}\n\t\treturn encoder\n\t}\n\tptrType := reflect2.PtrTo(typ)\n\tif ctx.prefix != \"\" && ptrType.Implements(marshalerType) {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, ptrType)\n\t\tvar encoder ValEncoder = &marshalerEncoder{\n\t\t\tvalType:      ptrType,\n\t\t\tcheckIsEmpty: checkIsEmpty,\n\t\t}\n\t\treturn &referenceEncoder{encoder}\n\t}\n\tif typ == textMarshalerType {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, typ)\n\t\tvar encoder ValEncoder = &directTextMarshalerEncoder{\n\t\t\tcheckIsEmpty:  checkIsEmpty,\n\t\t\tstringEncoder: ctx.EncoderOf(reflect2.TypeOf(\"\")),\n\t\t}\n\t\treturn encoder\n\t}\n\tif typ.Implements(textMarshalerType) {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, typ)\n\t\tvar encoder ValEncoder = &textMarshalerEncoder{\n\t\t\tvalType:       typ,\n\t\t\tstringEncoder: ctx.EncoderOf(reflect2.TypeOf(\"\")),\n\t\t\tcheckIsEmpty:  checkIsEmpty,\n\t\t}\n\t\treturn encoder\n\t}\n\t// if prefix is empty, the type is the root type\n\tif ctx.prefix != \"\" && ptrType.Implements(textMarshalerType) {\n\t\tcheckIsEmpty := createCheckIsEmpty(ctx, ptrType)\n\t\tvar encoder ValEncoder = &textMarshalerEncoder{\n\t\t\tvalType:       ptrType,\n\t\t\tstringEncoder: ctx.EncoderOf(reflect2.TypeOf(\"\")),\n\t\t\tcheckIsEmpty:  checkIsEmpty,\n\t\t}\n\t\treturn &referenceEncoder{encoder}\n\t}\n\treturn nil\n}\n\ntype marshalerEncoder struct {\n\tcheckIsEmpty checkIsEmpty\n\tvalType      reflect2.Type\n}\n\nfunc (encoder *marshalerEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tobj := encoder.valType.UnsafeIndirect(ptr)\n\tif encoder.valType.IsNullable() && reflect2.IsNil(obj) {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tmarshaler := obj.(json.Marshaler)\n\tbytes, err := marshaler.MarshalJSON()\n\tif err != nil {\n\t\tstream.Error = err\n\t} else {\n\t\t// html escape was already done by jsoniter\n\t\t// but the extra '\\n' should be trimed\n\t\tl := len(bytes)\n\t\tif l > 0 && bytes[l-1] == '\\n' {\n\t\t\tbytes = bytes[:l-1]\n\t\t}\n\t\tstream.Write(bytes)\n\t}\n}\n\nfunc (encoder *marshalerEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.checkIsEmpty.IsEmpty(ptr)\n}\n\ntype directMarshalerEncoder struct {\n\tcheckIsEmpty checkIsEmpty\n}\n\nfunc (encoder *directMarshalerEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tmarshaler := *(*json.Marshaler)(ptr)\n\tif marshaler == nil {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tbytes, err := marshaler.MarshalJSON()\n\tif err != nil {\n\t\tstream.Error = err\n\t} else {\n\t\tstream.Write(bytes)\n\t}\n}\n\nfunc (encoder *directMarshalerEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.checkIsEmpty.IsEmpty(ptr)\n}\n\ntype textMarshalerEncoder struct {\n\tvalType       reflect2.Type\n\tstringEncoder ValEncoder\n\tcheckIsEmpty  checkIsEmpty\n}\n\nfunc (encoder *textMarshalerEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tobj := encoder.valType.UnsafeIndirect(ptr)\n\tif encoder.valType.IsNullable() && reflect2.IsNil(obj) {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tmarshaler := (obj).(encoding.TextMarshaler)\n\tbytes, err := marshaler.MarshalText()\n\tif err != nil {\n\t\tstream.Error = err\n\t} else {\n\t\tstr := string(bytes)\n\t\tencoder.stringEncoder.Encode(unsafe.Pointer(&str), stream)\n\t}\n}\n\nfunc (encoder *textMarshalerEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.checkIsEmpty.IsEmpty(ptr)\n}\n\ntype directTextMarshalerEncoder struct {\n\tstringEncoder ValEncoder\n\tcheckIsEmpty  checkIsEmpty\n}\n\nfunc (encoder *directTextMarshalerEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tmarshaler := *(*encoding.TextMarshaler)(ptr)\n\tif marshaler == nil {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tbytes, err := marshaler.MarshalText()\n\tif err != nil {\n\t\tstream.Error = err\n\t} else {\n\t\tstr := string(bytes)\n\t\tencoder.stringEncoder.Encode(unsafe.Pointer(&str), stream)\n\t}\n}\n\nfunc (encoder *directTextMarshalerEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.checkIsEmpty.IsEmpty(ptr)\n}\n\ntype unmarshalerDecoder struct {\n\tvalType reflect2.Type\n}\n\nfunc (decoder *unmarshalerDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tvalType := decoder.valType\n\tobj := valType.UnsafeIndirect(ptr)\n\tunmarshaler := obj.(json.Unmarshaler)\n\titer.nextToken()\n\titer.unreadByte() // skip spaces\n\tbytes := iter.SkipAndReturnBytes()\n\terr := unmarshaler.UnmarshalJSON(bytes)\n\tif err != nil {\n\t\titer.ReportError(\"unmarshalerDecoder\", err.Error())\n\t}\n}\n\ntype textUnmarshalerDecoder struct {\n\tvalType reflect2.Type\n}\n\nfunc (decoder *textUnmarshalerDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tvalType := decoder.valType\n\tobj := valType.UnsafeIndirect(ptr)\n\tif reflect2.IsNil(obj) {\n\t\tptrType := valType.(*reflect2.UnsafePtrType)\n\t\telemType := ptrType.Elem()\n\t\telem := elemType.UnsafeNew()\n\t\tptrType.UnsafeSet(ptr, unsafe.Pointer(&elem))\n\t\tobj = valType.UnsafeIndirect(ptr)\n\t}\n\tunmarshaler := (obj).(encoding.TextUnmarshaler)\n\tstr := iter.ReadString()\n\terr := unmarshaler.UnmarshalText([]byte(str))\n\tif err != nil {\n\t\titer.ReportError(\"textUnmarshalerDecoder\", err.Error())\n\t}\n}\n"
        },
        {
          "name": "reflect_native.go",
          "type": "blob",
          "size": 10.8916015625,
          "content": "package jsoniter\n\nimport (\n\t\"encoding/base64\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/reflect2\"\n)\n\nconst ptrSize = 32 << uintptr(^uintptr(0)>>63)\n\nfunc createEncoderOfNative(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tif typ.Kind() == reflect.Slice && typ.(reflect2.SliceType).Elem().Kind() == reflect.Uint8 {\n\t\tsliceDecoder := decoderOfSlice(ctx, typ)\n\t\treturn &base64Codec{sliceDecoder: sliceDecoder}\n\t}\n\ttypeName := typ.String()\n\tkind := typ.Kind()\n\tswitch kind {\n\tcase reflect.String:\n\t\tif typeName != \"string\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*string)(nil)).Elem())\n\t\t}\n\t\treturn &stringCodec{}\n\tcase reflect.Int:\n\t\tif typeName != \"int\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*int)(nil)).Elem())\n\t\t}\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn &int32Codec{}\n\t\t}\n\t\treturn &int64Codec{}\n\tcase reflect.Int8:\n\t\tif typeName != \"int8\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*int8)(nil)).Elem())\n\t\t}\n\t\treturn &int8Codec{}\n\tcase reflect.Int16:\n\t\tif typeName != \"int16\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*int16)(nil)).Elem())\n\t\t}\n\t\treturn &int16Codec{}\n\tcase reflect.Int32:\n\t\tif typeName != \"int32\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*int32)(nil)).Elem())\n\t\t}\n\t\treturn &int32Codec{}\n\tcase reflect.Int64:\n\t\tif typeName != \"int64\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*int64)(nil)).Elem())\n\t\t}\n\t\treturn &int64Codec{}\n\tcase reflect.Uint:\n\t\tif typeName != \"uint\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uint)(nil)).Elem())\n\t\t}\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn &uint32Codec{}\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Uint8:\n\t\tif typeName != \"uint8\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uint8)(nil)).Elem())\n\t\t}\n\t\treturn &uint8Codec{}\n\tcase reflect.Uint16:\n\t\tif typeName != \"uint16\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uint16)(nil)).Elem())\n\t\t}\n\t\treturn &uint16Codec{}\n\tcase reflect.Uint32:\n\t\tif typeName != \"uint32\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uint32)(nil)).Elem())\n\t\t}\n\t\treturn &uint32Codec{}\n\tcase reflect.Uintptr:\n\t\tif typeName != \"uintptr\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uintptr)(nil)).Elem())\n\t\t}\n\t\tif ptrSize == 32 {\n\t\t\treturn &uint32Codec{}\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Uint64:\n\t\tif typeName != \"uint64\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*uint64)(nil)).Elem())\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Float32:\n\t\tif typeName != \"float32\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*float32)(nil)).Elem())\n\t\t}\n\t\treturn &float32Codec{}\n\tcase reflect.Float64:\n\t\tif typeName != \"float64\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*float64)(nil)).Elem())\n\t\t}\n\t\treturn &float64Codec{}\n\tcase reflect.Bool:\n\t\tif typeName != \"bool\" {\n\t\t\treturn encoderOfType(ctx, reflect2.TypeOfPtr((*bool)(nil)).Elem())\n\t\t}\n\t\treturn &boolCodec{}\n\t}\n\treturn nil\n}\n\nfunc createDecoderOfNative(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tif typ.Kind() == reflect.Slice && typ.(reflect2.SliceType).Elem().Kind() == reflect.Uint8 {\n\t\tsliceDecoder := decoderOfSlice(ctx, typ)\n\t\treturn &base64Codec{sliceDecoder: sliceDecoder}\n\t}\n\ttypeName := typ.String()\n\tswitch typ.Kind() {\n\tcase reflect.String:\n\t\tif typeName != \"string\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*string)(nil)).Elem())\n\t\t}\n\t\treturn &stringCodec{}\n\tcase reflect.Int:\n\t\tif typeName != \"int\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*int)(nil)).Elem())\n\t\t}\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn &int32Codec{}\n\t\t}\n\t\treturn &int64Codec{}\n\tcase reflect.Int8:\n\t\tif typeName != \"int8\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*int8)(nil)).Elem())\n\t\t}\n\t\treturn &int8Codec{}\n\tcase reflect.Int16:\n\t\tif typeName != \"int16\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*int16)(nil)).Elem())\n\t\t}\n\t\treturn &int16Codec{}\n\tcase reflect.Int32:\n\t\tif typeName != \"int32\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*int32)(nil)).Elem())\n\t\t}\n\t\treturn &int32Codec{}\n\tcase reflect.Int64:\n\t\tif typeName != \"int64\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*int64)(nil)).Elem())\n\t\t}\n\t\treturn &int64Codec{}\n\tcase reflect.Uint:\n\t\tif typeName != \"uint\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uint)(nil)).Elem())\n\t\t}\n\t\tif strconv.IntSize == 32 {\n\t\t\treturn &uint32Codec{}\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Uint8:\n\t\tif typeName != \"uint8\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uint8)(nil)).Elem())\n\t\t}\n\t\treturn &uint8Codec{}\n\tcase reflect.Uint16:\n\t\tif typeName != \"uint16\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uint16)(nil)).Elem())\n\t\t}\n\t\treturn &uint16Codec{}\n\tcase reflect.Uint32:\n\t\tif typeName != \"uint32\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uint32)(nil)).Elem())\n\t\t}\n\t\treturn &uint32Codec{}\n\tcase reflect.Uintptr:\n\t\tif typeName != \"uintptr\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uintptr)(nil)).Elem())\n\t\t}\n\t\tif ptrSize == 32 {\n\t\t\treturn &uint32Codec{}\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Uint64:\n\t\tif typeName != \"uint64\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*uint64)(nil)).Elem())\n\t\t}\n\t\treturn &uint64Codec{}\n\tcase reflect.Float32:\n\t\tif typeName != \"float32\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*float32)(nil)).Elem())\n\t\t}\n\t\treturn &float32Codec{}\n\tcase reflect.Float64:\n\t\tif typeName != \"float64\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*float64)(nil)).Elem())\n\t\t}\n\t\treturn &float64Codec{}\n\tcase reflect.Bool:\n\t\tif typeName != \"bool\" {\n\t\t\treturn decoderOfType(ctx, reflect2.TypeOfPtr((*bool)(nil)).Elem())\n\t\t}\n\t\treturn &boolCodec{}\n\t}\n\treturn nil\n}\n\ntype stringCodec struct {\n}\n\nfunc (codec *stringCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\t*((*string)(ptr)) = iter.ReadString()\n}\n\nfunc (codec *stringCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstr := *((*string)(ptr))\n\tstream.WriteString(str)\n}\n\nfunc (codec *stringCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*string)(ptr)) == \"\"\n}\n\ntype int8Codec struct {\n}\n\nfunc (codec *int8Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*int8)(ptr)) = iter.ReadInt8()\n\t}\n}\n\nfunc (codec *int8Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteInt8(*((*int8)(ptr)))\n}\n\nfunc (codec *int8Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*int8)(ptr)) == 0\n}\n\ntype int16Codec struct {\n}\n\nfunc (codec *int16Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*int16)(ptr)) = iter.ReadInt16()\n\t}\n}\n\nfunc (codec *int16Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteInt16(*((*int16)(ptr)))\n}\n\nfunc (codec *int16Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*int16)(ptr)) == 0\n}\n\ntype int32Codec struct {\n}\n\nfunc (codec *int32Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*int32)(ptr)) = iter.ReadInt32()\n\t}\n}\n\nfunc (codec *int32Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteInt32(*((*int32)(ptr)))\n}\n\nfunc (codec *int32Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*int32)(ptr)) == 0\n}\n\ntype int64Codec struct {\n}\n\nfunc (codec *int64Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*int64)(ptr)) = iter.ReadInt64()\n\t}\n}\n\nfunc (codec *int64Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteInt64(*((*int64)(ptr)))\n}\n\nfunc (codec *int64Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*int64)(ptr)) == 0\n}\n\ntype uint8Codec struct {\n}\n\nfunc (codec *uint8Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*uint8)(ptr)) = iter.ReadUint8()\n\t}\n}\n\nfunc (codec *uint8Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteUint8(*((*uint8)(ptr)))\n}\n\nfunc (codec *uint8Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*uint8)(ptr)) == 0\n}\n\ntype uint16Codec struct {\n}\n\nfunc (codec *uint16Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*uint16)(ptr)) = iter.ReadUint16()\n\t}\n}\n\nfunc (codec *uint16Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteUint16(*((*uint16)(ptr)))\n}\n\nfunc (codec *uint16Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*uint16)(ptr)) == 0\n}\n\ntype uint32Codec struct {\n}\n\nfunc (codec *uint32Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*uint32)(ptr)) = iter.ReadUint32()\n\t}\n}\n\nfunc (codec *uint32Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteUint32(*((*uint32)(ptr)))\n}\n\nfunc (codec *uint32Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*uint32)(ptr)) == 0\n}\n\ntype uint64Codec struct {\n}\n\nfunc (codec *uint64Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*uint64)(ptr)) = iter.ReadUint64()\n\t}\n}\n\nfunc (codec *uint64Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteUint64(*((*uint64)(ptr)))\n}\n\nfunc (codec *uint64Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*uint64)(ptr)) == 0\n}\n\ntype float32Codec struct {\n}\n\nfunc (codec *float32Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*float32)(ptr)) = iter.ReadFloat32()\n\t}\n}\n\nfunc (codec *float32Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteFloat32(*((*float32)(ptr)))\n}\n\nfunc (codec *float32Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*float32)(ptr)) == 0\n}\n\ntype float64Codec struct {\n}\n\nfunc (codec *float64Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*float64)(ptr)) = iter.ReadFloat64()\n\t}\n}\n\nfunc (codec *float64Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteFloat64(*((*float64)(ptr)))\n}\n\nfunc (codec *float64Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*float64)(ptr)) == 0\n}\n\ntype boolCodec struct {\n}\n\nfunc (codec *boolCodec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.ReadNil() {\n\t\t*((*bool)(ptr)) = iter.ReadBool()\n\t}\n}\n\nfunc (codec *boolCodec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteBool(*((*bool)(ptr)))\n}\n\nfunc (codec *boolCodec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn !(*((*bool)(ptr)))\n}\n\ntype base64Codec struct {\n\tsliceType    *reflect2.UnsafeSliceType\n\tsliceDecoder ValDecoder\n}\n\nfunc (codec *base64Codec) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.ReadNil() {\n\t\tcodec.sliceType.UnsafeSetNil(ptr)\n\t\treturn\n\t}\n\tswitch iter.WhatIsNext() {\n\tcase StringValue:\n\t\tsrc := iter.ReadString()\n\t\tdst, err := base64.StdEncoding.DecodeString(src)\n\t\tif err != nil {\n\t\t\titer.ReportError(\"decode base64\", err.Error())\n\t\t} else {\n\t\t\tcodec.sliceType.UnsafeSet(ptr, unsafe.Pointer(&dst))\n\t\t}\n\tcase ArrayValue:\n\t\tcodec.sliceDecoder.Decode(ptr, iter)\n\tdefault:\n\t\titer.ReportError(\"base64Codec\", \"invalid input\")\n\t}\n}\n\nfunc (codec *base64Codec) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif codec.sliceType.UnsafeIsNil(ptr) {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tsrc := *((*[]byte)(ptr))\n\tencoding := base64.StdEncoding\n\tstream.writeByte('\"')\n\tif len(src) != 0 {\n\t\tsize := encoding.EncodedLen(len(src))\n\t\tbuf := make([]byte, size)\n\t\tencoding.Encode(buf, src)\n\t\tstream.buf = append(stream.buf, buf...)\n\t}\n\tstream.writeByte('\"')\n}\n\nfunc (codec *base64Codec) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn len(*((*[]byte)(ptr))) == 0\n}\n"
        },
        {
          "name": "reflect_optional.go",
          "type": "blob",
          "size": 3.2939453125,
          "content": "package jsoniter\n\nimport (\n\t\"github.com/modern-go/reflect2\"\n\t\"unsafe\"\n)\n\nfunc decoderOfOptional(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tptrType := typ.(*reflect2.UnsafePtrType)\n\telemType := ptrType.Elem()\n\tdecoder := decoderOfType(ctx, elemType)\n\treturn &OptionalDecoder{elemType, decoder}\n}\n\nfunc encoderOfOptional(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tptrType := typ.(*reflect2.UnsafePtrType)\n\telemType := ptrType.Elem()\n\telemEncoder := encoderOfType(ctx, elemType)\n\tencoder := &OptionalEncoder{elemEncoder}\n\treturn encoder\n}\n\ntype OptionalDecoder struct {\n\tValueType    reflect2.Type\n\tValueDecoder ValDecoder\n}\n\nfunc (decoder *OptionalDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.ReadNil() {\n\t\t*((*unsafe.Pointer)(ptr)) = nil\n\t} else {\n\t\tif *((*unsafe.Pointer)(ptr)) == nil {\n\t\t\t//pointer to null, we have to allocate memory to hold the value\n\t\t\tnewPtr := decoder.ValueType.UnsafeNew()\n\t\t\tdecoder.ValueDecoder.Decode(newPtr, iter)\n\t\t\t*((*unsafe.Pointer)(ptr)) = newPtr\n\t\t} else {\n\t\t\t//reuse existing instance\n\t\t\tdecoder.ValueDecoder.Decode(*((*unsafe.Pointer)(ptr)), iter)\n\t\t}\n\t}\n}\n\ntype dereferenceDecoder struct {\n\t// only to deference a pointer\n\tvalueType    reflect2.Type\n\tvalueDecoder ValDecoder\n}\n\nfunc (decoder *dereferenceDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif *((*unsafe.Pointer)(ptr)) == nil {\n\t\t//pointer to null, we have to allocate memory to hold the value\n\t\tnewPtr := decoder.valueType.UnsafeNew()\n\t\tdecoder.valueDecoder.Decode(newPtr, iter)\n\t\t*((*unsafe.Pointer)(ptr)) = newPtr\n\t} else {\n\t\t//reuse existing instance\n\t\tdecoder.valueDecoder.Decode(*((*unsafe.Pointer)(ptr)), iter)\n\t}\n}\n\ntype OptionalEncoder struct {\n\tValueEncoder ValEncoder\n}\n\nfunc (encoder *OptionalEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *((*unsafe.Pointer)(ptr)) == nil {\n\t\tstream.WriteNil()\n\t} else {\n\t\tencoder.ValueEncoder.Encode(*((*unsafe.Pointer)(ptr)), stream)\n\t}\n}\n\nfunc (encoder *OptionalEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn *((*unsafe.Pointer)(ptr)) == nil\n}\n\ntype dereferenceEncoder struct {\n\tValueEncoder ValEncoder\n}\n\nfunc (encoder *dereferenceEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif *((*unsafe.Pointer)(ptr)) == nil {\n\t\tstream.WriteNil()\n\t} else {\n\t\tencoder.ValueEncoder.Encode(*((*unsafe.Pointer)(ptr)), stream)\n\t}\n}\n\nfunc (encoder *dereferenceEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\tdePtr := *((*unsafe.Pointer)(ptr))\n\tif dePtr == nil {\n\t\treturn true\n\t}\n\treturn encoder.ValueEncoder.IsEmpty(dePtr)\n}\n\nfunc (encoder *dereferenceEncoder) IsEmbeddedPtrNil(ptr unsafe.Pointer) bool {\n\tdeReferenced := *((*unsafe.Pointer)(ptr))\n\tif deReferenced == nil {\n\t\treturn true\n\t}\n\tisEmbeddedPtrNil, converted := encoder.ValueEncoder.(IsEmbeddedPtrNil)\n\tif !converted {\n\t\treturn false\n\t}\n\tfieldPtr := unsafe.Pointer(deReferenced)\n\treturn isEmbeddedPtrNil.IsEmbeddedPtrNil(fieldPtr)\n}\n\ntype referenceEncoder struct {\n\tencoder ValEncoder\n}\n\nfunc (encoder *referenceEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tencoder.encoder.Encode(unsafe.Pointer(&ptr), stream)\n}\n\nfunc (encoder *referenceEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.encoder.IsEmpty(unsafe.Pointer(&ptr))\n}\n\ntype referenceDecoder struct {\n\tdecoder ValDecoder\n}\n\nfunc (decoder *referenceDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.decoder.Decode(unsafe.Pointer(&ptr), iter)\n}\n"
        },
        {
          "name": "reflect_slice.go",
          "type": "blob",
          "size": 2.599609375,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"github.com/modern-go/reflect2\"\n\t\"io\"\n\t\"unsafe\"\n)\n\nfunc decoderOfSlice(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tsliceType := typ.(*reflect2.UnsafeSliceType)\n\tdecoder := decoderOfType(ctx.append(\"[sliceElem]\"), sliceType.Elem())\n\treturn &sliceDecoder{sliceType, decoder}\n}\n\nfunc encoderOfSlice(ctx *ctx, typ reflect2.Type) ValEncoder {\n\tsliceType := typ.(*reflect2.UnsafeSliceType)\n\tencoder := encoderOfType(ctx.append(\"[sliceElem]\"), sliceType.Elem())\n\treturn &sliceEncoder{sliceType, encoder}\n}\n\ntype sliceEncoder struct {\n\tsliceType   *reflect2.UnsafeSliceType\n\telemEncoder ValEncoder\n}\n\nfunc (encoder *sliceEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tif encoder.sliceType.UnsafeIsNil(ptr) {\n\t\tstream.WriteNil()\n\t\treturn\n\t}\n\tlength := encoder.sliceType.UnsafeLengthOf(ptr)\n\tif length == 0 {\n\t\tstream.WriteEmptyArray()\n\t\treturn\n\t}\n\tstream.WriteArrayStart()\n\tencoder.elemEncoder.Encode(encoder.sliceType.UnsafeGetIndex(ptr, 0), stream)\n\tfor i := 1; i < length; i++ {\n\t\tstream.WriteMore()\n\t\telemPtr := encoder.sliceType.UnsafeGetIndex(ptr, i)\n\t\tencoder.elemEncoder.Encode(elemPtr, stream)\n\t}\n\tstream.WriteArrayEnd()\n\tif stream.Error != nil && stream.Error != io.EOF {\n\t\tstream.Error = fmt.Errorf(\"%v: %s\", encoder.sliceType, stream.Error.Error())\n\t}\n}\n\nfunc (encoder *sliceEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.sliceType.UnsafeLengthOf(ptr) == 0\n}\n\ntype sliceDecoder struct {\n\tsliceType   *reflect2.UnsafeSliceType\n\telemDecoder ValDecoder\n}\n\nfunc (decoder *sliceDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.doDecode(ptr, iter)\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\titer.Error = fmt.Errorf(\"%v: %s\", decoder.sliceType, iter.Error.Error())\n\t}\n}\n\nfunc (decoder *sliceDecoder) doDecode(ptr unsafe.Pointer, iter *Iterator) {\n\tc := iter.nextToken()\n\tsliceType := decoder.sliceType\n\tif c == 'n' {\n\t\titer.skipThreeBytes('u', 'l', 'l')\n\t\tsliceType.UnsafeSetNil(ptr)\n\t\treturn\n\t}\n\tif c != '[' {\n\t\titer.ReportError(\"decode slice\", \"expect [ or n, but found \"+string([]byte{c}))\n\t\treturn\n\t}\n\tc = iter.nextToken()\n\tif c == ']' {\n\t\tsliceType.UnsafeSet(ptr, sliceType.UnsafeMakeSlice(0, 0))\n\t\treturn\n\t}\n\titer.unreadByte()\n\tsliceType.UnsafeGrow(ptr, 1)\n\telemPtr := sliceType.UnsafeGetIndex(ptr, 0)\n\tdecoder.elemDecoder.Decode(elemPtr, iter)\n\tlength := 1\n\tfor c = iter.nextToken(); c == ','; c = iter.nextToken() {\n\t\tidx := length\n\t\tlength += 1\n\t\tsliceType.UnsafeGrow(ptr, length)\n\t\telemPtr = sliceType.UnsafeGetIndex(ptr, idx)\n\t\tdecoder.elemDecoder.Decode(elemPtr, iter)\n\t}\n\tif c != ']' {\n\t\titer.ReportError(\"decode slice\", \"expect ], but found \"+string([]byte{c}))\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "reflect_struct_decoder.go",
          "type": "blob",
          "size": 29.2841796875,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"unsafe\"\n\n\t\"github.com/modern-go/reflect2\"\n)\n\nfunc decoderOfStruct(ctx *ctx, typ reflect2.Type) ValDecoder {\n\tbindings := map[string]*Binding{}\n\tstructDescriptor := describeStruct(ctx, typ)\n\tfor _, binding := range structDescriptor.Fields {\n\t\tfor _, fromName := range binding.FromNames {\n\t\t\told := bindings[fromName]\n\t\t\tif old == nil {\n\t\t\t\tbindings[fromName] = binding\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tignoreOld, ignoreNew := resolveConflictBinding(ctx.frozenConfig, old, binding)\n\t\t\tif ignoreOld {\n\t\t\t\tdelete(bindings, fromName)\n\t\t\t}\n\t\t\tif !ignoreNew {\n\t\t\t\tbindings[fromName] = binding\n\t\t\t}\n\t\t}\n\t}\n\tfields := map[string]*structFieldDecoder{}\n\tfor k, binding := range bindings {\n\t\tfields[k] = binding.Decoder.(*structFieldDecoder)\n\t}\n\n\tif !ctx.caseSensitive() {\n\t\tfor k, binding := range bindings {\n\t\t\tif _, found := fields[strings.ToLower(k)]; !found {\n\t\t\t\tfields[strings.ToLower(k)] = binding.Decoder.(*structFieldDecoder)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn createStructDecoder(ctx, typ, fields)\n}\n\nfunc createStructDecoder(ctx *ctx, typ reflect2.Type, fields map[string]*structFieldDecoder) ValDecoder {\n\tif ctx.disallowUnknownFields {\n\t\treturn &generalStructDecoder{typ: typ, fields: fields, disallowUnknownFields: true}\n\t}\n\tknownHash := map[int64]struct{}{\n\t\t0: {},\n\t}\n\n\tswitch len(fields) {\n\tcase 0:\n\t\treturn &skipObjectDecoder{typ}\n\tcase 1:\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\treturn &oneFieldStructDecoder{typ, fieldHash, fieldDecoder}\n\t\t}\n\tcase 2:\n\t\tvar fieldHash1 int64\n\t\tvar fieldHash2 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldHash1 == 0 {\n\t\t\t\tfieldHash1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldHash2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &twoFieldsStructDecoder{typ, fieldHash1, fieldDecoder1, fieldHash2, fieldDecoder2}\n\tcase 3:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &threeFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3}\n\tcase 4:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &fourFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4}\n\tcase 5:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &fiveFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5}\n\tcase 6:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldName6 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tvar fieldDecoder6 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else if fieldName5 == 0 {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName6 = fieldHash\n\t\t\t\tfieldDecoder6 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &sixFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5,\n\t\t\tfieldName6, fieldDecoder6}\n\tcase 7:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldName6 int64\n\t\tvar fieldName7 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tvar fieldDecoder6 *structFieldDecoder\n\t\tvar fieldDecoder7 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else if fieldName5 == 0 {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t} else if fieldName6 == 0 {\n\t\t\t\tfieldName6 = fieldHash\n\t\t\t\tfieldDecoder6 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName7 = fieldHash\n\t\t\t\tfieldDecoder7 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &sevenFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5,\n\t\t\tfieldName6, fieldDecoder6,\n\t\t\tfieldName7, fieldDecoder7}\n\tcase 8:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldName6 int64\n\t\tvar fieldName7 int64\n\t\tvar fieldName8 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tvar fieldDecoder6 *structFieldDecoder\n\t\tvar fieldDecoder7 *structFieldDecoder\n\t\tvar fieldDecoder8 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else if fieldName5 == 0 {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t} else if fieldName6 == 0 {\n\t\t\t\tfieldName6 = fieldHash\n\t\t\t\tfieldDecoder6 = fieldDecoder\n\t\t\t} else if fieldName7 == 0 {\n\t\t\t\tfieldName7 = fieldHash\n\t\t\t\tfieldDecoder7 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName8 = fieldHash\n\t\t\t\tfieldDecoder8 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &eightFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5,\n\t\t\tfieldName6, fieldDecoder6,\n\t\t\tfieldName7, fieldDecoder7,\n\t\t\tfieldName8, fieldDecoder8}\n\tcase 9:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldName6 int64\n\t\tvar fieldName7 int64\n\t\tvar fieldName8 int64\n\t\tvar fieldName9 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tvar fieldDecoder6 *structFieldDecoder\n\t\tvar fieldDecoder7 *structFieldDecoder\n\t\tvar fieldDecoder8 *structFieldDecoder\n\t\tvar fieldDecoder9 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else if fieldName5 == 0 {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t} else if fieldName6 == 0 {\n\t\t\t\tfieldName6 = fieldHash\n\t\t\t\tfieldDecoder6 = fieldDecoder\n\t\t\t} else if fieldName7 == 0 {\n\t\t\t\tfieldName7 = fieldHash\n\t\t\t\tfieldDecoder7 = fieldDecoder\n\t\t\t} else if fieldName8 == 0 {\n\t\t\t\tfieldName8 = fieldHash\n\t\t\t\tfieldDecoder8 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName9 = fieldHash\n\t\t\t\tfieldDecoder9 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &nineFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5,\n\t\t\tfieldName6, fieldDecoder6,\n\t\t\tfieldName7, fieldDecoder7,\n\t\t\tfieldName8, fieldDecoder8,\n\t\t\tfieldName9, fieldDecoder9}\n\tcase 10:\n\t\tvar fieldName1 int64\n\t\tvar fieldName2 int64\n\t\tvar fieldName3 int64\n\t\tvar fieldName4 int64\n\t\tvar fieldName5 int64\n\t\tvar fieldName6 int64\n\t\tvar fieldName7 int64\n\t\tvar fieldName8 int64\n\t\tvar fieldName9 int64\n\t\tvar fieldName10 int64\n\t\tvar fieldDecoder1 *structFieldDecoder\n\t\tvar fieldDecoder2 *structFieldDecoder\n\t\tvar fieldDecoder3 *structFieldDecoder\n\t\tvar fieldDecoder4 *structFieldDecoder\n\t\tvar fieldDecoder5 *structFieldDecoder\n\t\tvar fieldDecoder6 *structFieldDecoder\n\t\tvar fieldDecoder7 *structFieldDecoder\n\t\tvar fieldDecoder8 *structFieldDecoder\n\t\tvar fieldDecoder9 *structFieldDecoder\n\t\tvar fieldDecoder10 *structFieldDecoder\n\t\tfor fieldName, fieldDecoder := range fields {\n\t\t\tfieldHash := calcHash(fieldName, ctx.caseSensitive())\n\t\t\t_, known := knownHash[fieldHash]\n\t\t\tif known {\n\t\t\t\treturn &generalStructDecoder{typ, fields, false}\n\t\t\t}\n\t\t\tknownHash[fieldHash] = struct{}{}\n\t\t\tif fieldName1 == 0 {\n\t\t\t\tfieldName1 = fieldHash\n\t\t\t\tfieldDecoder1 = fieldDecoder\n\t\t\t} else if fieldName2 == 0 {\n\t\t\t\tfieldName2 = fieldHash\n\t\t\t\tfieldDecoder2 = fieldDecoder\n\t\t\t} else if fieldName3 == 0 {\n\t\t\t\tfieldName3 = fieldHash\n\t\t\t\tfieldDecoder3 = fieldDecoder\n\t\t\t} else if fieldName4 == 0 {\n\t\t\t\tfieldName4 = fieldHash\n\t\t\t\tfieldDecoder4 = fieldDecoder\n\t\t\t} else if fieldName5 == 0 {\n\t\t\t\tfieldName5 = fieldHash\n\t\t\t\tfieldDecoder5 = fieldDecoder\n\t\t\t} else if fieldName6 == 0 {\n\t\t\t\tfieldName6 = fieldHash\n\t\t\t\tfieldDecoder6 = fieldDecoder\n\t\t\t} else if fieldName7 == 0 {\n\t\t\t\tfieldName7 = fieldHash\n\t\t\t\tfieldDecoder7 = fieldDecoder\n\t\t\t} else if fieldName8 == 0 {\n\t\t\t\tfieldName8 = fieldHash\n\t\t\t\tfieldDecoder8 = fieldDecoder\n\t\t\t} else if fieldName9 == 0 {\n\t\t\t\tfieldName9 = fieldHash\n\t\t\t\tfieldDecoder9 = fieldDecoder\n\t\t\t} else {\n\t\t\t\tfieldName10 = fieldHash\n\t\t\t\tfieldDecoder10 = fieldDecoder\n\t\t\t}\n\t\t}\n\t\treturn &tenFieldsStructDecoder{typ,\n\t\t\tfieldName1, fieldDecoder1,\n\t\t\tfieldName2, fieldDecoder2,\n\t\t\tfieldName3, fieldDecoder3,\n\t\t\tfieldName4, fieldDecoder4,\n\t\t\tfieldName5, fieldDecoder5,\n\t\t\tfieldName6, fieldDecoder6,\n\t\t\tfieldName7, fieldDecoder7,\n\t\t\tfieldName8, fieldDecoder8,\n\t\t\tfieldName9, fieldDecoder9,\n\t\t\tfieldName10, fieldDecoder10}\n\t}\n\treturn &generalStructDecoder{typ, fields, false}\n}\n\ntype generalStructDecoder struct {\n\ttyp                   reflect2.Type\n\tfields                map[string]*structFieldDecoder\n\tdisallowUnknownFields bool\n}\n\nfunc (decoder *generalStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tvar c byte\n\tfor c = ','; c == ','; c = iter.nextToken() {\n\t\tdecoder.decodeOneField(ptr, iter)\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\tif c != '}' {\n\t\titer.ReportError(\"struct Decode\", `expect }, but found `+string([]byte{c}))\n\t}\n\titer.decrementDepth()\n}\n\nfunc (decoder *generalStructDecoder) decodeOneField(ptr unsafe.Pointer, iter *Iterator) {\n\tvar field string\n\tvar fieldDecoder *structFieldDecoder\n\tif iter.cfg.objectFieldMustBeSimpleString {\n\t\tfieldBytes := iter.ReadStringAsSlice()\n\t\tfield = *(*string)(unsafe.Pointer(&fieldBytes))\n\t\tfieldDecoder = decoder.fields[field]\n\t\tif fieldDecoder == nil && !iter.cfg.caseSensitive {\n\t\t\tfieldDecoder = decoder.fields[strings.ToLower(field)]\n\t\t}\n\t} else {\n\t\tfield = iter.ReadString()\n\t\tfieldDecoder = decoder.fields[field]\n\t\tif fieldDecoder == nil && !iter.cfg.caseSensitive {\n\t\t\tfieldDecoder = decoder.fields[strings.ToLower(field)]\n\t\t}\n\t}\n\tif fieldDecoder == nil {\n\t\tif decoder.disallowUnknownFields {\n\t\t\tmsg := \"found unknown field: \" + field\n\t\t\titer.ReportError(\"ReadObject\", msg)\n\t\t}\n\t\tc := iter.nextToken()\n\t\tif c != ':' {\n\t\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t\t}\n\t\titer.Skip()\n\t\treturn\n\t}\n\tc := iter.nextToken()\n\tif c != ':' {\n\t\titer.ReportError(\"ReadObject\", \"expect : after object field, but found \"+string([]byte{c}))\n\t}\n\tfieldDecoder.Decode(ptr, iter)\n}\n\ntype skipObjectDecoder struct {\n\ttyp reflect2.Type\n}\n\nfunc (decoder *skipObjectDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tvalueType := iter.WhatIsNext()\n\tif valueType != ObjectValue && valueType != NilValue {\n\t\titer.ReportError(\"skipObjectDecoder\", \"expect object or null\")\n\t\treturn\n\t}\n\titer.Skip()\n}\n\ntype oneFieldStructDecoder struct {\n\ttyp          reflect2.Type\n\tfieldHash    int64\n\tfieldDecoder *structFieldDecoder\n}\n\nfunc (decoder *oneFieldStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tif iter.readFieldHash() == decoder.fieldHash {\n\t\t\tdecoder.fieldDecoder.Decode(ptr, iter)\n\t\t} else {\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype twoFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n}\n\nfunc (decoder *twoFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype threeFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n}\n\nfunc (decoder *threeFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype fourFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n}\n\nfunc (decoder *fourFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype fiveFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n\tfieldHash5    int64\n\tfieldDecoder5 *structFieldDecoder\n}\n\nfunc (decoder *fiveFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype sixFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n\tfieldHash5    int64\n\tfieldDecoder5 *structFieldDecoder\n\tfieldHash6    int64\n\tfieldDecoder6 *structFieldDecoder\n}\n\nfunc (decoder *sixFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tcase decoder.fieldHash6:\n\t\t\tdecoder.fieldDecoder6.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype sevenFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n\tfieldHash5    int64\n\tfieldDecoder5 *structFieldDecoder\n\tfieldHash6    int64\n\tfieldDecoder6 *structFieldDecoder\n\tfieldHash7    int64\n\tfieldDecoder7 *structFieldDecoder\n}\n\nfunc (decoder *sevenFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tcase decoder.fieldHash6:\n\t\t\tdecoder.fieldDecoder6.Decode(ptr, iter)\n\t\tcase decoder.fieldHash7:\n\t\t\tdecoder.fieldDecoder7.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype eightFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n\tfieldHash5    int64\n\tfieldDecoder5 *structFieldDecoder\n\tfieldHash6    int64\n\tfieldDecoder6 *structFieldDecoder\n\tfieldHash7    int64\n\tfieldDecoder7 *structFieldDecoder\n\tfieldHash8    int64\n\tfieldDecoder8 *structFieldDecoder\n}\n\nfunc (decoder *eightFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tcase decoder.fieldHash6:\n\t\t\tdecoder.fieldDecoder6.Decode(ptr, iter)\n\t\tcase decoder.fieldHash7:\n\t\t\tdecoder.fieldDecoder7.Decode(ptr, iter)\n\t\tcase decoder.fieldHash8:\n\t\t\tdecoder.fieldDecoder8.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype nineFieldsStructDecoder struct {\n\ttyp           reflect2.Type\n\tfieldHash1    int64\n\tfieldDecoder1 *structFieldDecoder\n\tfieldHash2    int64\n\tfieldDecoder2 *structFieldDecoder\n\tfieldHash3    int64\n\tfieldDecoder3 *structFieldDecoder\n\tfieldHash4    int64\n\tfieldDecoder4 *structFieldDecoder\n\tfieldHash5    int64\n\tfieldDecoder5 *structFieldDecoder\n\tfieldHash6    int64\n\tfieldDecoder6 *structFieldDecoder\n\tfieldHash7    int64\n\tfieldDecoder7 *structFieldDecoder\n\tfieldHash8    int64\n\tfieldDecoder8 *structFieldDecoder\n\tfieldHash9    int64\n\tfieldDecoder9 *structFieldDecoder\n}\n\nfunc (decoder *nineFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tcase decoder.fieldHash6:\n\t\t\tdecoder.fieldDecoder6.Decode(ptr, iter)\n\t\tcase decoder.fieldHash7:\n\t\t\tdecoder.fieldDecoder7.Decode(ptr, iter)\n\t\tcase decoder.fieldHash8:\n\t\t\tdecoder.fieldDecoder8.Decode(ptr, iter)\n\t\tcase decoder.fieldHash9:\n\t\t\tdecoder.fieldDecoder9.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype tenFieldsStructDecoder struct {\n\ttyp            reflect2.Type\n\tfieldHash1     int64\n\tfieldDecoder1  *structFieldDecoder\n\tfieldHash2     int64\n\tfieldDecoder2  *structFieldDecoder\n\tfieldHash3     int64\n\tfieldDecoder3  *structFieldDecoder\n\tfieldHash4     int64\n\tfieldDecoder4  *structFieldDecoder\n\tfieldHash5     int64\n\tfieldDecoder5  *structFieldDecoder\n\tfieldHash6     int64\n\tfieldDecoder6  *structFieldDecoder\n\tfieldHash7     int64\n\tfieldDecoder7  *structFieldDecoder\n\tfieldHash8     int64\n\tfieldDecoder8  *structFieldDecoder\n\tfieldHash9     int64\n\tfieldDecoder9  *structFieldDecoder\n\tfieldHash10    int64\n\tfieldDecoder10 *structFieldDecoder\n}\n\nfunc (decoder *tenFieldsStructDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif !iter.readObjectStart() {\n\t\treturn\n\t}\n\tif !iter.incrementDepth() {\n\t\treturn\n\t}\n\tfor {\n\t\tswitch iter.readFieldHash() {\n\t\tcase decoder.fieldHash1:\n\t\t\tdecoder.fieldDecoder1.Decode(ptr, iter)\n\t\tcase decoder.fieldHash2:\n\t\t\tdecoder.fieldDecoder2.Decode(ptr, iter)\n\t\tcase decoder.fieldHash3:\n\t\t\tdecoder.fieldDecoder3.Decode(ptr, iter)\n\t\tcase decoder.fieldHash4:\n\t\t\tdecoder.fieldDecoder4.Decode(ptr, iter)\n\t\tcase decoder.fieldHash5:\n\t\t\tdecoder.fieldDecoder5.Decode(ptr, iter)\n\t\tcase decoder.fieldHash6:\n\t\t\tdecoder.fieldDecoder6.Decode(ptr, iter)\n\t\tcase decoder.fieldHash7:\n\t\t\tdecoder.fieldDecoder7.Decode(ptr, iter)\n\t\tcase decoder.fieldHash8:\n\t\t\tdecoder.fieldDecoder8.Decode(ptr, iter)\n\t\tcase decoder.fieldHash9:\n\t\t\tdecoder.fieldDecoder9.Decode(ptr, iter)\n\t\tcase decoder.fieldHash10:\n\t\t\tdecoder.fieldDecoder10.Decode(ptr, iter)\n\t\tdefault:\n\t\t\titer.Skip()\n\t\t}\n\t\tif iter.isObjectEnd() {\n\t\t\tbreak\n\t\t}\n\t}\n\tif iter.Error != nil && iter.Error != io.EOF && len(decoder.typ.Type1().Name()) != 0 {\n\t\titer.Error = fmt.Errorf(\"%v.%s\", decoder.typ, iter.Error.Error())\n\t}\n\titer.decrementDepth()\n}\n\ntype structFieldDecoder struct {\n\tfield        reflect2.StructField\n\tfieldDecoder ValDecoder\n}\n\nfunc (decoder *structFieldDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tfieldPtr := decoder.field.UnsafeGet(ptr)\n\tdecoder.fieldDecoder.Decode(fieldPtr, iter)\n\tif iter.Error != nil && iter.Error != io.EOF {\n\t\titer.Error = fmt.Errorf(\"%s: %s\", decoder.field.Name(), iter.Error.Error())\n\t}\n}\n\ntype stringModeStringDecoder struct {\n\telemDecoder ValDecoder\n\tcfg         *frozenConfig\n}\n\nfunc (decoder *stringModeStringDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tdecoder.elemDecoder.Decode(ptr, iter)\n\tstr := *((*string)(ptr))\n\ttempIter := decoder.cfg.BorrowIterator([]byte(str))\n\tdefer decoder.cfg.ReturnIterator(tempIter)\n\t*((*string)(ptr)) = tempIter.ReadString()\n}\n\ntype stringModeNumberDecoder struct {\n\telemDecoder ValDecoder\n}\n\nfunc (decoder *stringModeNumberDecoder) Decode(ptr unsafe.Pointer, iter *Iterator) {\n\tif iter.WhatIsNext() == NilValue {\n\t\tdecoder.elemDecoder.Decode(ptr, iter)\n\t\treturn\n\t}\n\n\tc := iter.nextToken()\n\tif c != '\"' {\n\t\titer.ReportError(\"stringModeNumberDecoder\", `expect \", but found `+string([]byte{c}))\n\t\treturn\n\t}\n\tdecoder.elemDecoder.Decode(ptr, iter)\n\tif iter.Error != nil {\n\t\treturn\n\t}\n\tc = iter.readByte()\n\tif c != '\"' {\n\t\titer.ReportError(\"stringModeNumberDecoder\", `expect \", but found `+string([]byte{c}))\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "reflect_struct_encoder.go",
          "type": "blob",
          "size": 5.1708984375,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"github.com/modern-go/reflect2\"\n\t\"io\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\nfunc encoderOfStruct(ctx *ctx, typ reflect2.Type) ValEncoder {\n\ttype bindingTo struct {\n\t\tbinding *Binding\n\t\ttoName  string\n\t\tignored bool\n\t}\n\torderedBindings := []*bindingTo{}\n\tstructDescriptor := describeStruct(ctx, typ)\n\tfor _, binding := range structDescriptor.Fields {\n\t\tfor _, toName := range binding.ToNames {\n\t\t\tnew := &bindingTo{\n\t\t\t\tbinding: binding,\n\t\t\t\ttoName:  toName,\n\t\t\t}\n\t\t\tfor _, old := range orderedBindings {\n\t\t\t\tif old.toName != toName {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\told.ignored, new.ignored = resolveConflictBinding(ctx.frozenConfig, old.binding, new.binding)\n\t\t\t}\n\t\t\torderedBindings = append(orderedBindings, new)\n\t\t}\n\t}\n\tif len(orderedBindings) == 0 {\n\t\treturn &emptyStructEncoder{}\n\t}\n\tfinalOrderedFields := []structFieldTo{}\n\tfor _, bindingTo := range orderedBindings {\n\t\tif !bindingTo.ignored {\n\t\t\tfinalOrderedFields = append(finalOrderedFields, structFieldTo{\n\t\t\t\tencoder: bindingTo.binding.Encoder.(*structFieldEncoder),\n\t\t\t\ttoName:  bindingTo.toName,\n\t\t\t})\n\t\t}\n\t}\n\treturn &structEncoder{typ, finalOrderedFields}\n}\n\nfunc createCheckIsEmpty(ctx *ctx, typ reflect2.Type) checkIsEmpty {\n\tencoder := createEncoderOfNative(ctx, typ)\n\tif encoder != nil {\n\t\treturn encoder\n\t}\n\tkind := typ.Kind()\n\tswitch kind {\n\tcase reflect.Interface:\n\t\treturn &dynamicEncoder{typ}\n\tcase reflect.Struct:\n\t\treturn &structEncoder{typ: typ}\n\tcase reflect.Array:\n\t\treturn &arrayEncoder{}\n\tcase reflect.Slice:\n\t\treturn &sliceEncoder{}\n\tcase reflect.Map:\n\t\treturn encoderOfMap(ctx, typ)\n\tcase reflect.Ptr:\n\t\treturn &OptionalEncoder{}\n\tdefault:\n\t\treturn &lazyErrorEncoder{err: fmt.Errorf(\"unsupported type: %v\", typ)}\n\t}\n}\n\nfunc resolveConflictBinding(cfg *frozenConfig, old, new *Binding) (ignoreOld, ignoreNew bool) {\n\tnewTagged := new.Field.Tag().Get(cfg.getTagKey()) != \"\"\n\toldTagged := old.Field.Tag().Get(cfg.getTagKey()) != \"\"\n\tif newTagged {\n\t\tif oldTagged {\n\t\t\tif len(old.levels) > len(new.levels) {\n\t\t\t\treturn true, false\n\t\t\t} else if len(new.levels) > len(old.levels) {\n\t\t\t\treturn false, true\n\t\t\t} else {\n\t\t\t\treturn true, true\n\t\t\t}\n\t\t} else {\n\t\t\treturn true, false\n\t\t}\n\t} else {\n\t\tif oldTagged {\n\t\t\treturn true, false\n\t\t}\n\t\tif len(old.levels) > len(new.levels) {\n\t\t\treturn true, false\n\t\t} else if len(new.levels) > len(old.levels) {\n\t\t\treturn false, true\n\t\t} else {\n\t\t\treturn true, true\n\t\t}\n\t}\n}\n\ntype structFieldEncoder struct {\n\tfield        reflect2.StructField\n\tfieldEncoder ValEncoder\n\tomitempty    bool\n}\n\nfunc (encoder *structFieldEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tfieldPtr := encoder.field.UnsafeGet(ptr)\n\tencoder.fieldEncoder.Encode(fieldPtr, stream)\n\tif stream.Error != nil && stream.Error != io.EOF {\n\t\tstream.Error = fmt.Errorf(\"%s: %s\", encoder.field.Name(), stream.Error.Error())\n\t}\n}\n\nfunc (encoder *structFieldEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\tfieldPtr := encoder.field.UnsafeGet(ptr)\n\treturn encoder.fieldEncoder.IsEmpty(fieldPtr)\n}\n\nfunc (encoder *structFieldEncoder) IsEmbeddedPtrNil(ptr unsafe.Pointer) bool {\n\tisEmbeddedPtrNil, converted := encoder.fieldEncoder.(IsEmbeddedPtrNil)\n\tif !converted {\n\t\treturn false\n\t}\n\tfieldPtr := encoder.field.UnsafeGet(ptr)\n\treturn isEmbeddedPtrNil.IsEmbeddedPtrNil(fieldPtr)\n}\n\ntype IsEmbeddedPtrNil interface {\n\tIsEmbeddedPtrNil(ptr unsafe.Pointer) bool\n}\n\ntype structEncoder struct {\n\ttyp    reflect2.Type\n\tfields []structFieldTo\n}\n\ntype structFieldTo struct {\n\tencoder *structFieldEncoder\n\ttoName  string\n}\n\nfunc (encoder *structEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteObjectStart()\n\tisNotFirst := false\n\tfor _, field := range encoder.fields {\n\t\tif field.encoder.omitempty && field.encoder.IsEmpty(ptr) {\n\t\t\tcontinue\n\t\t}\n\t\tif field.encoder.IsEmbeddedPtrNil(ptr) {\n\t\t\tcontinue\n\t\t}\n\t\tif isNotFirst {\n\t\t\tstream.WriteMore()\n\t\t}\n\t\tstream.WriteObjectField(field.toName)\n\t\tfield.encoder.Encode(ptr, stream)\n\t\tisNotFirst = true\n\t}\n\tstream.WriteObjectEnd()\n\tif stream.Error != nil && stream.Error != io.EOF {\n\t\tstream.Error = fmt.Errorf(\"%v.%s\", encoder.typ, stream.Error.Error())\n\t}\n}\n\nfunc (encoder *structEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn false\n}\n\ntype emptyStructEncoder struct {\n}\n\nfunc (encoder *emptyStructEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.WriteEmptyObject()\n}\n\nfunc (encoder *emptyStructEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn false\n}\n\ntype stringModeNumberEncoder struct {\n\telemEncoder ValEncoder\n}\n\nfunc (encoder *stringModeNumberEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\tstream.writeByte('\"')\n\tencoder.elemEncoder.Encode(ptr, stream)\n\tstream.writeByte('\"')\n}\n\nfunc (encoder *stringModeNumberEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.elemEncoder.IsEmpty(ptr)\n}\n\ntype stringModeStringEncoder struct {\n\telemEncoder ValEncoder\n\tcfg         *frozenConfig\n}\n\nfunc (encoder *stringModeStringEncoder) Encode(ptr unsafe.Pointer, stream *Stream) {\n\ttempStream := encoder.cfg.BorrowStream(nil)\n\ttempStream.Attachment = stream.Attachment\n\tdefer encoder.cfg.ReturnStream(tempStream)\n\tencoder.elemEncoder.Encode(ptr, tempStream)\n\tstream.WriteString(string(tempStream.Buffer()))\n}\n\nfunc (encoder *stringModeStringEncoder) IsEmpty(ptr unsafe.Pointer) bool {\n\treturn encoder.elemEncoder.IsEmpty(ptr)\n}\n"
        },
        {
          "name": "skip_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "stream.go",
          "type": "blob",
          "size": 5.1630859375,
          "content": "package jsoniter\n\nimport (\n\t\"io\"\n)\n\n// stream is a io.Writer like object, with JSON specific write functions.\n// Error is not returned as return value, but stored as Error member on this stream instance.\ntype Stream struct {\n\tcfg        *frozenConfig\n\tout        io.Writer\n\tbuf        []byte\n\tError      error\n\tindention  int\n\tAttachment interface{} // open for customized encoder\n}\n\n// NewStream create new stream instance.\n// cfg can be jsoniter.ConfigDefault.\n// out can be nil if write to internal buffer.\n// bufSize is the initial size for the internal buffer in bytes.\nfunc NewStream(cfg API, out io.Writer, bufSize int) *Stream {\n\treturn &Stream{\n\t\tcfg:       cfg.(*frozenConfig),\n\t\tout:       out,\n\t\tbuf:       make([]byte, 0, bufSize),\n\t\tError:     nil,\n\t\tindention: 0,\n\t}\n}\n\n// Pool returns a pool can provide more stream with same configuration\nfunc (stream *Stream) Pool() StreamPool {\n\treturn stream.cfg\n}\n\n// Reset reuse this stream instance by assign a new writer\nfunc (stream *Stream) Reset(out io.Writer) {\n\tstream.out = out\n\tstream.buf = stream.buf[:0]\n}\n\n// Available returns how many bytes are unused in the buffer.\nfunc (stream *Stream) Available() int {\n\treturn cap(stream.buf) - len(stream.buf)\n}\n\n// Buffered returns the number of bytes that have been written into the current buffer.\nfunc (stream *Stream) Buffered() int {\n\treturn len(stream.buf)\n}\n\n// Buffer if writer is nil, use this method to take the result\nfunc (stream *Stream) Buffer() []byte {\n\treturn stream.buf\n}\n\n// SetBuffer allows to append to the internal buffer directly\nfunc (stream *Stream) SetBuffer(buf []byte) {\n\tstream.buf = buf\n}\n\n// Write writes the contents of p into the buffer.\n// It returns the number of bytes written.\n// If nn < len(p), it also returns an error explaining\n// why the write is short.\nfunc (stream *Stream) Write(p []byte) (nn int, err error) {\n\tstream.buf = append(stream.buf, p...)\n\tif stream.out != nil {\n\t\tnn, err = stream.out.Write(stream.buf)\n\t\tstream.buf = stream.buf[nn:]\n\t\treturn\n\t}\n\treturn len(p), nil\n}\n\n// WriteByte writes a single byte.\nfunc (stream *Stream) writeByte(c byte) {\n\tstream.buf = append(stream.buf, c)\n}\n\nfunc (stream *Stream) writeTwoBytes(c1 byte, c2 byte) {\n\tstream.buf = append(stream.buf, c1, c2)\n}\n\nfunc (stream *Stream) writeThreeBytes(c1 byte, c2 byte, c3 byte) {\n\tstream.buf = append(stream.buf, c1, c2, c3)\n}\n\nfunc (stream *Stream) writeFourBytes(c1 byte, c2 byte, c3 byte, c4 byte) {\n\tstream.buf = append(stream.buf, c1, c2, c3, c4)\n}\n\nfunc (stream *Stream) writeFiveBytes(c1 byte, c2 byte, c3 byte, c4 byte, c5 byte) {\n\tstream.buf = append(stream.buf, c1, c2, c3, c4, c5)\n}\n\n// Flush writes any buffered data to the underlying io.Writer.\nfunc (stream *Stream) Flush() error {\n\tif stream.out == nil {\n\t\treturn nil\n\t}\n\tif stream.Error != nil {\n\t\treturn stream.Error\n\t}\n\t_, err := stream.out.Write(stream.buf)\n\tif err != nil {\n\t\tif stream.Error == nil {\n\t\t\tstream.Error = err\n\t\t}\n\t\treturn err\n\t}\n\tstream.buf = stream.buf[:0]\n\treturn nil\n}\n\n// WriteRaw write string out without quotes, just like []byte\nfunc (stream *Stream) WriteRaw(s string) {\n\tstream.buf = append(stream.buf, s...)\n}\n\n// WriteNil write null to stream\nfunc (stream *Stream) WriteNil() {\n\tstream.writeFourBytes('n', 'u', 'l', 'l')\n}\n\n// WriteTrue write true to stream\nfunc (stream *Stream) WriteTrue() {\n\tstream.writeFourBytes('t', 'r', 'u', 'e')\n}\n\n// WriteFalse write false to stream\nfunc (stream *Stream) WriteFalse() {\n\tstream.writeFiveBytes('f', 'a', 'l', 's', 'e')\n}\n\n// WriteBool write true or false into stream\nfunc (stream *Stream) WriteBool(val bool) {\n\tif val {\n\t\tstream.WriteTrue()\n\t} else {\n\t\tstream.WriteFalse()\n\t}\n}\n\n// WriteObjectStart write { with possible indention\nfunc (stream *Stream) WriteObjectStart() {\n\tstream.indention += stream.cfg.indentionStep\n\tstream.writeByte('{')\n\tstream.writeIndention(0)\n}\n\n// WriteObjectField write \"field\": with possible indention\nfunc (stream *Stream) WriteObjectField(field string) {\n\tstream.WriteString(field)\n\tif stream.indention > 0 {\n\t\tstream.writeTwoBytes(':', ' ')\n\t} else {\n\t\tstream.writeByte(':')\n\t}\n}\n\n// WriteObjectEnd write } with possible indention\nfunc (stream *Stream) WriteObjectEnd() {\n\tstream.writeIndention(stream.cfg.indentionStep)\n\tstream.indention -= stream.cfg.indentionStep\n\tstream.writeByte('}')\n}\n\n// WriteEmptyObject write {}\nfunc (stream *Stream) WriteEmptyObject() {\n\tstream.writeByte('{')\n\tstream.writeByte('}')\n}\n\n// WriteMore write , with possible indention\nfunc (stream *Stream) WriteMore() {\n\tstream.writeByte(',')\n\tstream.writeIndention(0)\n}\n\n// WriteArrayStart write [ with possible indention\nfunc (stream *Stream) WriteArrayStart() {\n\tstream.indention += stream.cfg.indentionStep\n\tstream.writeByte('[')\n\tstream.writeIndention(0)\n}\n\n// WriteEmptyArray write []\nfunc (stream *Stream) WriteEmptyArray() {\n\tstream.writeTwoBytes('[', ']')\n}\n\n// WriteArrayEnd write ] with possible indention\nfunc (stream *Stream) WriteArrayEnd() {\n\tstream.writeIndention(stream.cfg.indentionStep)\n\tstream.indention -= stream.cfg.indentionStep\n\tstream.writeByte(']')\n}\n\nfunc (stream *Stream) writeIndention(delta int) {\n\tif stream.indention == 0 {\n\t\treturn\n\t}\n\tstream.writeByte('\\n')\n\ttoWrite := stream.indention - delta\n\tfor i := 0; i < toWrite; i++ {\n\t\tstream.buf = append(stream.buf, ' ')\n\t}\n}\n"
        },
        {
          "name": "stream_float.go",
          "type": "blob",
          "size": 3.146484375,
          "content": "package jsoniter\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"strconv\"\n)\n\nvar pow10 []uint64\n\nfunc init() {\n\tpow10 = []uint64{1, 10, 100, 1000, 10000, 100000, 1000000}\n}\n\n// WriteFloat32 write float32 to stream\nfunc (stream *Stream) WriteFloat32(val float32) {\n\tif math.IsInf(float64(val), 0) || math.IsNaN(float64(val)) {\n\t\tstream.Error = fmt.Errorf(\"unsupported value: %f\", val)\n\t\treturn\n\t}\n\tabs := math.Abs(float64(val))\n\tfmt := byte('f')\n\t// Note: Must use float32 comparisons for underlying float32 value to get precise cutoffs right.\n\tif abs != 0 {\n\t\tif float32(abs) < 1e-6 || float32(abs) >= 1e21 {\n\t\t\tfmt = 'e'\n\t\t}\n\t}\n\tstream.buf = strconv.AppendFloat(stream.buf, float64(val), fmt, -1, 32)\n\tif fmt == 'e' {\n\t\t// clean up e-09 to e-9\n\t\tn := len(stream.buf)\n\t\tif n >= 4 && stream.buf[n-4] == 'e' && stream.buf[n-3] == '-' && stream.buf[n-2] == '0' {\n\t\t\tstream.buf[n-2] = stream.buf[n-1]\n\t\t\tstream.buf = stream.buf[:n-1]\n\t\t}\n\t}\n}\n\n// WriteFloat32Lossy write float32 to stream with ONLY 6 digits precision although much much faster\nfunc (stream *Stream) WriteFloat32Lossy(val float32) {\n\tif math.IsInf(float64(val), 0) || math.IsNaN(float64(val)) {\n\t\tstream.Error = fmt.Errorf(\"unsupported value: %f\", val)\n\t\treturn\n\t}\n\tif val < 0 {\n\t\tstream.writeByte('-')\n\t\tval = -val\n\t}\n\tif val > 0x4ffffff {\n\t\tstream.WriteFloat32(val)\n\t\treturn\n\t}\n\tprecision := 6\n\texp := uint64(1000000) // 6\n\tlval := uint64(float64(val)*float64(exp) + 0.5)\n\tstream.WriteUint64(lval / exp)\n\tfval := lval % exp\n\tif fval == 0 {\n\t\treturn\n\t}\n\tstream.writeByte('.')\n\tfor p := precision - 1; p > 0 && fval < pow10[p]; p-- {\n\t\tstream.writeByte('0')\n\t}\n\tstream.WriteUint64(fval)\n\tfor stream.buf[len(stream.buf)-1] == '0' {\n\t\tstream.buf = stream.buf[:len(stream.buf)-1]\n\t}\n}\n\n// WriteFloat64 write float64 to stream\nfunc (stream *Stream) WriteFloat64(val float64) {\n\tif math.IsInf(val, 0) || math.IsNaN(val) {\n\t\tstream.Error = fmt.Errorf(\"unsupported value: %f\", val)\n\t\treturn\n\t}\n\tabs := math.Abs(val)\n\tfmt := byte('f')\n\t// Note: Must use float32 comparisons for underlying float32 value to get precise cutoffs right.\n\tif abs != 0 {\n\t\tif abs < 1e-6 || abs >= 1e21 {\n\t\t\tfmt = 'e'\n\t\t}\n\t}\n\tstream.buf = strconv.AppendFloat(stream.buf, float64(val), fmt, -1, 64)\n\tif fmt == 'e' {\n\t\t// clean up e-09 to e-9\n\t\tn := len(stream.buf)\n\t\tif n >= 4 && stream.buf[n-4] == 'e' && stream.buf[n-3] == '-' && stream.buf[n-2] == '0' {\n\t\t\tstream.buf[n-2] = stream.buf[n-1]\n\t\t\tstream.buf = stream.buf[:n-1]\n\t\t}\n\t}\n}\n\n// WriteFloat64Lossy write float64 to stream with ONLY 6 digits precision although much much faster\nfunc (stream *Stream) WriteFloat64Lossy(val float64) {\n\tif math.IsInf(val, 0) || math.IsNaN(val) {\n\t\tstream.Error = fmt.Errorf(\"unsupported value: %f\", val)\n\t\treturn\n\t}\n\tif val < 0 {\n\t\tstream.writeByte('-')\n\t\tval = -val\n\t}\n\tif val > 0x4ffffff {\n\t\tstream.WriteFloat64(val)\n\t\treturn\n\t}\n\tprecision := 6\n\texp := uint64(1000000) // 6\n\tlval := uint64(val*float64(exp) + 0.5)\n\tstream.WriteUint64(lval / exp)\n\tfval := lval % exp\n\tif fval == 0 {\n\t\treturn\n\t}\n\tstream.writeByte('.')\n\tfor p := precision - 1; p > 0 && fval < pow10[p]; p-- {\n\t\tstream.writeByte('0')\n\t}\n\tstream.WriteUint64(fval)\n\tfor stream.buf[len(stream.buf)-1] == '0' {\n\t\tstream.buf = stream.buf[:len(stream.buf)-1]\n\t}\n}\n"
        },
        {
          "name": "stream_int.go",
          "type": "blob",
          "size": 4.47265625,
          "content": "package jsoniter\n\nvar digits []uint32\n\nfunc init() {\n\tdigits = make([]uint32, 1000)\n\tfor i := uint32(0); i < 1000; i++ {\n\t\tdigits[i] = (((i / 100) + '0') << 16) + ((((i / 10) % 10) + '0') << 8) + i%10 + '0'\n\t\tif i < 10 {\n\t\t\tdigits[i] += 2 << 24\n\t\t} else if i < 100 {\n\t\t\tdigits[i] += 1 << 24\n\t\t}\n\t}\n}\n\nfunc writeFirstBuf(space []byte, v uint32) []byte {\n\tstart := v >> 24\n\tif start == 0 {\n\t\tspace = append(space, byte(v>>16), byte(v>>8))\n\t} else if start == 1 {\n\t\tspace = append(space, byte(v>>8))\n\t}\n\tspace = append(space, byte(v))\n\treturn space\n}\n\nfunc writeBuf(buf []byte, v uint32) []byte {\n\treturn append(buf, byte(v>>16), byte(v>>8), byte(v))\n}\n\n// WriteUint8 write uint8 to stream\nfunc (stream *Stream) WriteUint8(val uint8) {\n\tstream.buf = writeFirstBuf(stream.buf, digits[val])\n}\n\n// WriteInt8 write int8 to stream\nfunc (stream *Stream) WriteInt8(nval int8) {\n\tvar val uint8\n\tif nval < 0 {\n\t\tval = uint8(-nval)\n\t\tstream.buf = append(stream.buf, '-')\n\t} else {\n\t\tval = uint8(nval)\n\t}\n\tstream.buf = writeFirstBuf(stream.buf, digits[val])\n}\n\n// WriteUint16 write uint16 to stream\nfunc (stream *Stream) WriteUint16(val uint16) {\n\tq1 := val / 1000\n\tif q1 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[val])\n\t\treturn\n\t}\n\tr1 := val - q1*1000\n\tstream.buf = writeFirstBuf(stream.buf, digits[q1])\n\tstream.buf = writeBuf(stream.buf, digits[r1])\n\treturn\n}\n\n// WriteInt16 write int16 to stream\nfunc (stream *Stream) WriteInt16(nval int16) {\n\tvar val uint16\n\tif nval < 0 {\n\t\tval = uint16(-nval)\n\t\tstream.buf = append(stream.buf, '-')\n\t} else {\n\t\tval = uint16(nval)\n\t}\n\tstream.WriteUint16(val)\n}\n\n// WriteUint32 write uint32 to stream\nfunc (stream *Stream) WriteUint32(val uint32) {\n\tq1 := val / 1000\n\tif q1 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[val])\n\t\treturn\n\t}\n\tr1 := val - q1*1000\n\tq2 := q1 / 1000\n\tif q2 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q1])\n\t\tstream.buf = writeBuf(stream.buf, digits[r1])\n\t\treturn\n\t}\n\tr2 := q1 - q2*1000\n\tq3 := q2 / 1000\n\tif q3 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q2])\n\t} else {\n\t\tr3 := q2 - q3*1000\n\t\tstream.buf = append(stream.buf, byte(q3+'0'))\n\t\tstream.buf = writeBuf(stream.buf, digits[r3])\n\t}\n\tstream.buf = writeBuf(stream.buf, digits[r2])\n\tstream.buf = writeBuf(stream.buf, digits[r1])\n}\n\n// WriteInt32 write int32 to stream\nfunc (stream *Stream) WriteInt32(nval int32) {\n\tvar val uint32\n\tif nval < 0 {\n\t\tval = uint32(-nval)\n\t\tstream.buf = append(stream.buf, '-')\n\t} else {\n\t\tval = uint32(nval)\n\t}\n\tstream.WriteUint32(val)\n}\n\n// WriteUint64 write uint64 to stream\nfunc (stream *Stream) WriteUint64(val uint64) {\n\tq1 := val / 1000\n\tif q1 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[val])\n\t\treturn\n\t}\n\tr1 := val - q1*1000\n\tq2 := q1 / 1000\n\tif q2 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q1])\n\t\tstream.buf = writeBuf(stream.buf, digits[r1])\n\t\treturn\n\t}\n\tr2 := q1 - q2*1000\n\tq3 := q2 / 1000\n\tif q3 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q2])\n\t\tstream.buf = writeBuf(stream.buf, digits[r2])\n\t\tstream.buf = writeBuf(stream.buf, digits[r1])\n\t\treturn\n\t}\n\tr3 := q2 - q3*1000\n\tq4 := q3 / 1000\n\tif q4 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q3])\n\t\tstream.buf = writeBuf(stream.buf, digits[r3])\n\t\tstream.buf = writeBuf(stream.buf, digits[r2])\n\t\tstream.buf = writeBuf(stream.buf, digits[r1])\n\t\treturn\n\t}\n\tr4 := q3 - q4*1000\n\tq5 := q4 / 1000\n\tif q5 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q4])\n\t\tstream.buf = writeBuf(stream.buf, digits[r4])\n\t\tstream.buf = writeBuf(stream.buf, digits[r3])\n\t\tstream.buf = writeBuf(stream.buf, digits[r2])\n\t\tstream.buf = writeBuf(stream.buf, digits[r1])\n\t\treturn\n\t}\n\tr5 := q4 - q5*1000\n\tq6 := q5 / 1000\n\tif q6 == 0 {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q5])\n\t} else {\n\t\tstream.buf = writeFirstBuf(stream.buf, digits[q6])\n\t\tr6 := q5 - q6*1000\n\t\tstream.buf = writeBuf(stream.buf, digits[r6])\n\t}\n\tstream.buf = writeBuf(stream.buf, digits[r5])\n\tstream.buf = writeBuf(stream.buf, digits[r4])\n\tstream.buf = writeBuf(stream.buf, digits[r3])\n\tstream.buf = writeBuf(stream.buf, digits[r2])\n\tstream.buf = writeBuf(stream.buf, digits[r1])\n}\n\n// WriteInt64 write int64 to stream\nfunc (stream *Stream) WriteInt64(nval int64) {\n\tvar val uint64\n\tif nval < 0 {\n\t\tval = uint64(-nval)\n\t\tstream.buf = append(stream.buf, '-')\n\t} else {\n\t\tval = uint64(nval)\n\t}\n\tstream.WriteUint64(val)\n}\n\n// WriteInt write int to stream\nfunc (stream *Stream) WriteInt(val int) {\n\tstream.WriteInt64(int64(val))\n}\n\n// WriteUint write uint to stream\nfunc (stream *Stream) WriteUint(val uint) {\n\tstream.WriteUint64(uint64(val))\n}\n"
        },
        {
          "name": "stream_str.go",
          "type": "blob",
          "size": 7.798828125,
          "content": "package jsoniter\n\nimport (\n\t\"unicode/utf8\"\n)\n\n// htmlSafeSet holds the value true if the ASCII character with the given\n// array position can be safely represented inside a JSON string, embedded\n// inside of HTML <script> tags, without any additional escaping.\n//\n// All values are true except for the ASCII control characters (0-31), the\n// double quote (\"), the backslash character (\"\\\"), HTML opening and closing\n// tags (\"<\" and \">\"), and the ampersand (\"&\").\nvar htmlSafeSet = [utf8.RuneSelf]bool{\n\t' ':      true,\n\t'!':      true,\n\t'\"':      false,\n\t'#':      true,\n\t'$':      true,\n\t'%':      true,\n\t'&':      false,\n\t'\\'':     true,\n\t'(':      true,\n\t')':      true,\n\t'*':      true,\n\t'+':      true,\n\t',':      true,\n\t'-':      true,\n\t'.':      true,\n\t'/':      true,\n\t'0':      true,\n\t'1':      true,\n\t'2':      true,\n\t'3':      true,\n\t'4':      true,\n\t'5':      true,\n\t'6':      true,\n\t'7':      true,\n\t'8':      true,\n\t'9':      true,\n\t':':      true,\n\t';':      true,\n\t'<':      false,\n\t'=':      true,\n\t'>':      false,\n\t'?':      true,\n\t'@':      true,\n\t'A':      true,\n\t'B':      true,\n\t'C':      true,\n\t'D':      true,\n\t'E':      true,\n\t'F':      true,\n\t'G':      true,\n\t'H':      true,\n\t'I':      true,\n\t'J':      true,\n\t'K':      true,\n\t'L':      true,\n\t'M':      true,\n\t'N':      true,\n\t'O':      true,\n\t'P':      true,\n\t'Q':      true,\n\t'R':      true,\n\t'S':      true,\n\t'T':      true,\n\t'U':      true,\n\t'V':      true,\n\t'W':      true,\n\t'X':      true,\n\t'Y':      true,\n\t'Z':      true,\n\t'[':      true,\n\t'\\\\':     false,\n\t']':      true,\n\t'^':      true,\n\t'_':      true,\n\t'`':      true,\n\t'a':      true,\n\t'b':      true,\n\t'c':      true,\n\t'd':      true,\n\t'e':      true,\n\t'f':      true,\n\t'g':      true,\n\t'h':      true,\n\t'i':      true,\n\t'j':      true,\n\t'k':      true,\n\t'l':      true,\n\t'm':      true,\n\t'n':      true,\n\t'o':      true,\n\t'p':      true,\n\t'q':      true,\n\t'r':      true,\n\t's':      true,\n\t't':      true,\n\t'u':      true,\n\t'v':      true,\n\t'w':      true,\n\t'x':      true,\n\t'y':      true,\n\t'z':      true,\n\t'{':      true,\n\t'|':      true,\n\t'}':      true,\n\t'~':      true,\n\t'\\u007f': true,\n}\n\n// safeSet holds the value true if the ASCII character with the given array\n// position can be represented inside a JSON string without any further\n// escaping.\n//\n// All values are true except for the ASCII control characters (0-31), the\n// double quote (\"), and the backslash character (\"\\\").\nvar safeSet = [utf8.RuneSelf]bool{\n\t' ':      true,\n\t'!':      true,\n\t'\"':      false,\n\t'#':      true,\n\t'$':      true,\n\t'%':      true,\n\t'&':      true,\n\t'\\'':     true,\n\t'(':      true,\n\t')':      true,\n\t'*':      true,\n\t'+':      true,\n\t',':      true,\n\t'-':      true,\n\t'.':      true,\n\t'/':      true,\n\t'0':      true,\n\t'1':      true,\n\t'2':      true,\n\t'3':      true,\n\t'4':      true,\n\t'5':      true,\n\t'6':      true,\n\t'7':      true,\n\t'8':      true,\n\t'9':      true,\n\t':':      true,\n\t';':      true,\n\t'<':      true,\n\t'=':      true,\n\t'>':      true,\n\t'?':      true,\n\t'@':      true,\n\t'A':      true,\n\t'B':      true,\n\t'C':      true,\n\t'D':      true,\n\t'E':      true,\n\t'F':      true,\n\t'G':      true,\n\t'H':      true,\n\t'I':      true,\n\t'J':      true,\n\t'K':      true,\n\t'L':      true,\n\t'M':      true,\n\t'N':      true,\n\t'O':      true,\n\t'P':      true,\n\t'Q':      true,\n\t'R':      true,\n\t'S':      true,\n\t'T':      true,\n\t'U':      true,\n\t'V':      true,\n\t'W':      true,\n\t'X':      true,\n\t'Y':      true,\n\t'Z':      true,\n\t'[':      true,\n\t'\\\\':     false,\n\t']':      true,\n\t'^':      true,\n\t'_':      true,\n\t'`':      true,\n\t'a':      true,\n\t'b':      true,\n\t'c':      true,\n\t'd':      true,\n\t'e':      true,\n\t'f':      true,\n\t'g':      true,\n\t'h':      true,\n\t'i':      true,\n\t'j':      true,\n\t'k':      true,\n\t'l':      true,\n\t'm':      true,\n\t'n':      true,\n\t'o':      true,\n\t'p':      true,\n\t'q':      true,\n\t'r':      true,\n\t's':      true,\n\t't':      true,\n\t'u':      true,\n\t'v':      true,\n\t'w':      true,\n\t'x':      true,\n\t'y':      true,\n\t'z':      true,\n\t'{':      true,\n\t'|':      true,\n\t'}':      true,\n\t'~':      true,\n\t'\\u007f': true,\n}\n\nvar hex = \"0123456789abcdef\"\n\n// WriteStringWithHTMLEscaped write string to stream with html special characters escaped\nfunc (stream *Stream) WriteStringWithHTMLEscaped(s string) {\n\tvalLen := len(s)\n\tstream.buf = append(stream.buf, '\"')\n\t// write string, the fast path, without utf8 and escape support\n\ti := 0\n\tfor ; i < valLen; i++ {\n\t\tc := s[i]\n\t\tif c < utf8.RuneSelf && htmlSafeSet[c] {\n\t\t\tstream.buf = append(stream.buf, c)\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\tif i == valLen {\n\t\tstream.buf = append(stream.buf, '\"')\n\t\treturn\n\t}\n\twriteStringSlowPathWithHTMLEscaped(stream, i, s, valLen)\n}\n\nfunc writeStringSlowPathWithHTMLEscaped(stream *Stream, i int, s string, valLen int) {\n\tstart := i\n\t// for the remaining parts, we process them char by char\n\tfor i < valLen {\n\t\tif b := s[i]; b < utf8.RuneSelf {\n\t\t\tif htmlSafeSet[b] {\n\t\t\t\ti++\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif start < i {\n\t\t\t\tstream.WriteRaw(s[start:i])\n\t\t\t}\n\t\t\tswitch b {\n\t\t\tcase '\\\\', '\"':\n\t\t\t\tstream.writeTwoBytes('\\\\', b)\n\t\t\tcase '\\n':\n\t\t\t\tstream.writeTwoBytes('\\\\', 'n')\n\t\t\tcase '\\r':\n\t\t\t\tstream.writeTwoBytes('\\\\', 'r')\n\t\t\tcase '\\t':\n\t\t\t\tstream.writeTwoBytes('\\\\', 't')\n\t\t\tdefault:\n\t\t\t\t// This encodes bytes < 0x20 except for \\t, \\n and \\r.\n\t\t\t\t// If escapeHTML is set, it also escapes <, >, and &\n\t\t\t\t// because they can lead to security holes when\n\t\t\t\t// user-controlled strings are rendered into JSON\n\t\t\t\t// and served to some browsers.\n\t\t\t\tstream.WriteRaw(`\\u00`)\n\t\t\t\tstream.writeTwoBytes(hex[b>>4], hex[b&0xF])\n\t\t\t}\n\t\t\ti++\n\t\t\tstart = i\n\t\t\tcontinue\n\t\t}\n\t\tc, size := utf8.DecodeRuneInString(s[i:])\n\t\tif c == utf8.RuneError && size == 1 {\n\t\t\tif start < i {\n\t\t\t\tstream.WriteRaw(s[start:i])\n\t\t\t}\n\t\t\tstream.WriteRaw(`\\ufffd`)\n\t\t\ti++\n\t\t\tstart = i\n\t\t\tcontinue\n\t\t}\n\t\t// U+2028 is LINE SEPARATOR.\n\t\t// U+2029 is PARAGRAPH SEPARATOR.\n\t\t// They are both technically valid characters in JSON strings,\n\t\t// but don't work in JSONP, which has to be evaluated as JavaScript,\n\t\t// and can lead to security holes there. It is valid JSON to\n\t\t// escape them, so we do so unconditionally.\n\t\t// See http://timelessrepo.com/json-isnt-a-javascript-subset for discussion.\n\t\tif c == '\\u2028' || c == '\\u2029' {\n\t\t\tif start < i {\n\t\t\t\tstream.WriteRaw(s[start:i])\n\t\t\t}\n\t\t\tstream.WriteRaw(`\\u202`)\n\t\t\tstream.writeByte(hex[c&0xF])\n\t\t\ti += size\n\t\t\tstart = i\n\t\t\tcontinue\n\t\t}\n\t\ti += size\n\t}\n\tif start < len(s) {\n\t\tstream.WriteRaw(s[start:])\n\t}\n\tstream.writeByte('\"')\n}\n\n// WriteString write string to stream without html escape\nfunc (stream *Stream) WriteString(s string) {\n\tvalLen := len(s)\n\tstream.buf = append(stream.buf, '\"')\n\t// write string, the fast path, without utf8 and escape support\n\ti := 0\n\tfor ; i < valLen; i++ {\n\t\tc := s[i]\n\t\tif c > 31 && c != '\"' && c != '\\\\' {\n\t\t\tstream.buf = append(stream.buf, c)\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\tif i == valLen {\n\t\tstream.buf = append(stream.buf, '\"')\n\t\treturn\n\t}\n\twriteStringSlowPath(stream, i, s, valLen)\n}\n\nfunc writeStringSlowPath(stream *Stream, i int, s string, valLen int) {\n\tstart := i\n\t// for the remaining parts, we process them char by char\n\tfor i < valLen {\n\t\tif b := s[i]; b < utf8.RuneSelf {\n\t\t\tif safeSet[b] {\n\t\t\t\ti++\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif start < i {\n\t\t\t\tstream.WriteRaw(s[start:i])\n\t\t\t}\n\t\t\tswitch b {\n\t\t\tcase '\\\\', '\"':\n\t\t\t\tstream.writeTwoBytes('\\\\', b)\n\t\t\tcase '\\n':\n\t\t\t\tstream.writeTwoBytes('\\\\', 'n')\n\t\t\tcase '\\r':\n\t\t\t\tstream.writeTwoBytes('\\\\', 'r')\n\t\t\tcase '\\t':\n\t\t\t\tstream.writeTwoBytes('\\\\', 't')\n\t\t\tdefault:\n\t\t\t\t// This encodes bytes < 0x20 except for \\t, \\n and \\r.\n\t\t\t\t// If escapeHTML is set, it also escapes <, >, and &\n\t\t\t\t// because they can lead to security holes when\n\t\t\t\t// user-controlled strings are rendered into JSON\n\t\t\t\t// and served to some browsers.\n\t\t\t\tstream.WriteRaw(`\\u00`)\n\t\t\t\tstream.writeTwoBytes(hex[b>>4], hex[b&0xF])\n\t\t\t}\n\t\t\ti++\n\t\t\tstart = i\n\t\t\tcontinue\n\t\t}\n\t\ti++\n\t\tcontinue\n\t}\n\tif start < len(s) {\n\t\tstream.WriteRaw(s[start:])\n\t}\n\tstream.writeByte('\"')\n}\n"
        },
        {
          "name": "stream_test.go",
          "type": "blob",
          "size": 2.3251953125,
          "content": "package jsoniter\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc Test_writeByte_should_grow_buffer(t *testing.T) {\n\tshould := require.New(t)\n\tstream := NewStream(ConfigDefault, nil, 1)\n\tstream.writeByte('1')\n\tshould.Equal(\"1\", string(stream.Buffer()))\n\tshould.Equal(1, len(stream.buf))\n\tstream.writeByte('2')\n\tshould.Equal(\"12\", string(stream.Buffer()))\n\tshould.Equal(2, len(stream.buf))\n\tstream.writeThreeBytes('3', '4', '5')\n\tshould.Equal(\"12345\", string(stream.Buffer()))\n}\n\nfunc Test_writeBytes_should_grow_buffer(t *testing.T) {\n\tshould := require.New(t)\n\tstream := NewStream(ConfigDefault, nil, 1)\n\tstream.Write([]byte{'1', '2'})\n\tshould.Equal(\"12\", string(stream.Buffer()))\n\tshould.Equal(2, len(stream.buf))\n\tstream.Write([]byte{'3', '4', '5', '6', '7'})\n\tshould.Equal(\"1234567\", string(stream.Buffer()))\n\tshould.Equal(7, len(stream.buf))\n}\n\nfunc Test_writeIndention_should_grow_buffer(t *testing.T) {\n\tshould := require.New(t)\n\tstream := NewStream(Config{IndentionStep: 2}.Froze(), nil, 1)\n\tstream.WriteVal([]int{1, 2, 3})\n\tshould.Equal(\"[\\n  1,\\n  2,\\n  3\\n]\", string(stream.Buffer()))\n}\n\nfunc Test_writeRaw_should_grow_buffer(t *testing.T) {\n\tshould := require.New(t)\n\tstream := NewStream(ConfigDefault, nil, 1)\n\tstream.WriteRaw(\"123\")\n\tshould.Nil(stream.Error)\n\tshould.Equal(\"123\", string(stream.Buffer()))\n}\n\nfunc Test_writeString_should_grow_buffer(t *testing.T) {\n\tshould := require.New(t)\n\tstream := NewStream(ConfigDefault, nil, 0)\n\tstream.WriteString(\"123\")\n\tshould.Nil(stream.Error)\n\tshould.Equal(`\"123\"`, string(stream.Buffer()))\n}\n\ntype NopWriter struct {\n\tbufferSize int\n}\n\nfunc (w *NopWriter) Write(p []byte) (n int, err error) {\n\tw.bufferSize = cap(p)\n\treturn len(p), nil\n}\n\nfunc Test_flush_buffer_should_stop_grow_buffer(t *testing.T) {\n\t// Stream an array of a zillion zeros.\n\twriter := new(NopWriter)\n\tstream := NewStream(ConfigDefault, writer, 512)\n\tstream.WriteArrayStart()\n\tfor i := 0; i < 10000000; i++ {\n\t\tstream.WriteInt(0)\n\t\tstream.WriteMore()\n\t\tstream.Flush()\n\t}\n\tstream.WriteInt(0)\n\tstream.WriteArrayEnd()\n\n\t// Confirm that the buffer didn't have to grow.\n\tshould := require.New(t)\n\n\t// 512 is the internal buffer size set in NewEncoder\n\t//\n\t// Flush is called after each array element, so only the first 8 bytes of it\n\t// is ever used, and it is never extended. Capacity remains 512.\n\tshould.Equal(512, writer.bufferSize)\n}\n"
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 0.2783203125,
          "content": "#!/usr/bin/env bash\n\nset -e\necho \"\" > coverage.txt\n\nfor d in $(go list ./... | grep -v vendor); do\n    go test -coverprofile=profile.out -coverpkg=github.com/json-iterator/go $d\n    if [ -f profile.out ]; then\n        cat profile.out >> coverage.txt\n        rm profile.out\n    fi\ndone\n"
        },
        {
          "name": "type_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "value_tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}