{
  "metadata": {
    "timestamp": 1736567842251,
    "page": 425,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjQyOA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nsf/gocode",
      "stars": 5012,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.09375,
          "content": "*.8\n*.a\n*.out\ngocode\ngocode.exe\ngoremote\ngocodetest\n*.swp\nlistidents\nshowcursor\nshowsmap\nrename\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0478515625,
          "content": "Copyright (C) 2010 nsf <no.smile.face@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.5439453125,
          "content": "## An autocompletion daemon for the Go programming language\n\n**IMPORTANT: This project is not maintained anymore, consider using https://pkg.go.dev/golang.org/x/tools/gopls, a tool which provides similar functionality and more, created and maintained by Go team.**\n\nGocode is a helper tool which is intended to be integrated with your source code editor, like vim, neovim and emacs. It provides several advanced capabilities, which currently includes:\n\n - Context-sensitive autocompletion\n\nIt is called *daemon*, because it uses client/server architecture for caching purposes. In particular, it makes autocompletions very fast. Typical autocompletion time with warm cache is 30ms, which is barely noticeable.\n\nAlso watch the [demo screencast](https://nosmileface.dev/images/gocode-demo.swf).\n\n![Gocode in vim](https://nosmileface.dev/images/gocode-screenshot.png)\n\n![Gocode in emacs](https://nosmileface.dev/images/emacs-gocode.png)\n\n### Setup\n\n 1. You should have a correctly installed Go compiler environment and your personal workspace ($GOPATH). If you have no idea what **$GOPATH** is, take a look [here](http://golang.org/doc/code.html). Please make sure that your **$GOPATH/bin** is available in your **$PATH**. This is important, because most editors assume that **gocode** binary is available in one of the directories, specified by your **$PATH** environment variable. Otherwise manually copy the **gocode** binary from **$GOPATH/bin** to a location which is part of your **$PATH** after getting it in step 2.\n\n    Do these steps only if you understand why you need to do them:\n\n    `export GOPATH=$HOME/goprojects`\n\n    `export PATH=$PATH:$GOPATH/bin`\n\n 2. Then you need to get the appropriate version of the gocode, for 6g/8g/5g compiler you can do this:\n\n    `go get -u github.com/nsf/gocode` (-u flag for \"update\")\n\n    Windows users should consider doing this instead:\n\n    `go get -u -ldflags -H=windowsgui github.com/nsf/gocode`\n\n    That way on the Windows OS gocode will be built as a GUI application and doing so solves hanging window issues with some of the editors.\n\n 3. Next steps are editor specific. See below.\n\n### Vim setup\n\n#### Vim manual installation\n\nNote: As of go 1.5 there is no $GOROOT/misc/vim script. Suggested installation is via [vim-go plugin](https://github.com/fatih/vim-go).\n\nIn order to install vim scripts, you need to fulfill the following steps:\n\n 1. Install official Go vim scripts from **$GOROOT/misc/vim**. If you did that already, proceed to the step 2.\n\n 2. Install gocode vim scripts. Usually it's enough to do the following:\n\n    2.1. `vim/update.sh`\n\n    **update.sh** script does the following:\n\n\t\t#!/bin/sh\n\t\tmkdir -p \"$HOME/.vim/autoload\"\n\t\tmkdir -p \"$HOME/.vim/ftplugin/go\"\n\t\tcp \"${0%/*}/autoload/gocomplete.vim\" \"$HOME/.vim/autoload\"\n\t\tcp \"${0%/*}/ftplugin/go/gocomplete.vim\" \"$HOME/.vim/ftplugin/go\"\n\n    2.2. Alternatively, you can create symlinks using symlink.sh script in order to avoid running update.sh after every gocode update.\n\n    **symlink.sh** script does the following:\n\n\t\t#!/bin/sh\n\t\tcd \"${0%/*}\"\n\t\tROOTDIR=`pwd`\n\t\tmkdir -p \"$HOME/.vim/autoload\"\n\t\tmkdir -p \"$HOME/.vim/ftplugin/go\"\n\t\tln -s \"$ROOTDIR/autoload/gocomplete.vim\" \"$HOME/.vim/autoload/\"\n\t\tln -s \"$ROOTDIR/ftplugin/go/gocomplete.vim\" \"$HOME/.vim/ftplugin/go/\"\n\n 3. Make sure vim has filetype plugin enabled. Simply add that to your **.vimrc**:\n\n    `filetype plugin on`\n\n 4. Autocompletion should work now. Use `<C-x><C-o>` for autocompletion (omnifunc autocompletion).\n\n#### Using Vundle in Vim\n\nAdd the following line to your **.vimrc**:\n\n`Plugin 'nsf/gocode', {'rtp': 'vim/'}`\n\nAnd then update your packages by running `:PluginInstall`.\n\n#### Using vim-plug in Vim\n\nAdd the following line to your **.vimrc**:\n\n`Plug 'nsf/gocode', { 'rtp': 'vim', 'do': '~/.vim/plugged/gocode/vim/symlink.sh' }`\n\nAnd then update your packages by running `:PlugInstall`.\n\n#### Other\n\nAlternatively take a look at the vundle/pathogen friendly repo: https://github.com/Blackrush/vim-gocode.\n\n### Neovim setup\n#### Neovim manual installation\n\n Neovim users should also follow `Vim manual installation`, except that you should goto `gocode/nvim` in step 2, and remember that, the Neovim configuration file is `~/.config/nvim/init.vim`.\n\n#### Using Vundle in Neovim\n\nAdd the following line to your **init.vim**:\n\n`Plugin 'nsf/gocode', {'rtp': 'nvim/'}`\n\nAnd then update your packages by running `:PluginInstall`.\n\n#### Using vim-plug in Neovim\n\nAdd the following line to your **init.vim**:\n\n`Plug 'nsf/gocode', { 'rtp': 'nvim', 'do': '~/.config/nvim/plugged/gocode/nvim/symlink.sh' }`\n\nAnd then update your packages by running `:PlugInstall`.\n\n### Emacs setup\n\nIn order to install emacs script, you need to fulfill the following steps:\n\n 1. Install [auto-complete-mode](http://www.emacswiki.org/emacs/AutoComplete)\n\n 2. Copy **emacs/go-autocomplete.el** file from the gocode source distribution to a directory which is in your 'load-path' in emacs.\n\n 3. Add these lines to your **.emacs**:\n\n \t\t(require 'go-autocomplete)\n\t\t(require 'auto-complete-config)\n\t\t(ac-config-default)\n\nAlso, there is an alternative plugin for emacs using company-mode. See `emacs-company/README` for installation instructions.\n\nIf you're a MacOSX user, you may find that script useful: https://github.com/purcell/exec-path-from-shell. It helps you with setting up the right environment variables as Go and gocode require it. By default it pulls the PATH, but don't forget to add the GOPATH as well, e.g.:\n\n```\n(when (memq window-system '(mac ns))\n  (exec-path-from-shell-initialize)\n  (exec-path-from-shell-copy-env \"GOPATH\"))\n```\n\n### Options\n\nYou can change all available options using `gocode set` command. The config file uses json format and is usually stored somewhere in **~/.config/gocode** directory. On windows it's stored in the appropriate AppData folder. It's suggested to avoid modifying config file manually, do that using the `gocode set` command.\n\n`gocode set` lists all options and their values.\n\n`gocode set <option>` shows the value of that *option*.\n\n`gocode set <option> <value>` sets the new *value* for that *option*.\n\n - *propose-builtins*\n\n   A boolean option. If **true**, gocode will add built-in types, functions and constants to autocompletion proposals. Default: **false**.\n\n - *lib-path*\n\n   A string option. Allows you to add search paths for packages. By default, gocode only searches **$GOPATH/pkg/$GOOS_$GOARCH** and **$GOROOT/pkg/$GOOS_$GOARCH** in terms of previously existed environment variables. Also you can specify multiple paths using ':' (colon) as a separator (on Windows use semicolon ';'). The paths specified by *lib-path* are prepended to the default ones.\n\n - *autobuild*\n\n   A boolean option. If **true**, gocode will try to automatically build out-of-date packages when their source files are modified, in order to obtain the freshest autocomplete results for them. This feature is experimental. Default: **false**.\n\n - *force-debug-output*\n\n   A string option. If is not empty, gocode will forcefully redirect the logging into that file. Also forces enabling of the debug mode on the server side. Default: \"\" (empty).\n\n - *package-lookup-mode*\n\n   A string option. If **go**, use standard Go package lookup rules. If **gb**, use gb-specific lookup rules. See https://github.com/constabulary/gb for details. Default: **go**.\n\n - *close-timeout*\n\n   An integer option. If there have been no completion requests after this number of seconds, the gocode process will terminate. Defaults to 1800 (30 minutes).\n\n - *unimported-packages*\n\n   A boolean option. If set to true, gocode will try to import certain known packages automatically for identifiers which cannot be resolved otherwise. Currently only a limited set of standard library packages are supported. Default: **false**.\n\n - *partials*\n\n   A boolean option. If set to false, gocode will not filter autocompletion results based on entered prefix before the cursor. Instead it will return all available autocompletion results viable for a given context. Whether this option is set to true or false, gocode will return a valid prefix length for output formats which support it. Setting this option to a non-default value may result in editor misbehaviour. Default: **true**.\n\n - *ignore-case*\n\n   A boolean option. If set to true, gocode will perform case-insensitive matching when doing prefix-based filtering. Default: **false**.\n\n - *class-filtering*\n\n   A boolean option. Enables or disables gocode's feature where it performs class-based filtering if partial input matches corresponding class keyword: const, var, type, func, package. Default: **true**.\n\n### Debugging\n\nIf something went wrong, the first thing you may want to do is manually start the gocode daemon with a debug mode enabled and in a separate terminal window. It will show you all the stack traces, panics if any and additional info about autocompletion requests. Shutdown the daemon if it was already started and run a new one explicitly with a debug mode enabled:\n\n`gocode close`\n\n`gocode -s -debug`\n\nPlease, report bugs, feature suggestions and other rants to the [github issue tracker](http://github.com/nsf/gocode/issues) of this project.\n\n### Developing\n\nThere is [Guide for IDE/editor plugin developers](docs/IDE_integration.md).\n\nIf you have troubles, please, contact me and I will try to do my best answering your questions. You can contact me via <a href=\"mailto:no.smile.face@gmail.com\">email</a>. Or for short question find me on IRC: #go-nuts @ freenode.\n\n### Misc\n\n - It's a good idea to use the latest git version always. I'm trying to keep it in a working state.\n - Use `go install` (not `go build`) for building a local source tree. The objects in `pkg/` are needed for Gocode to work.\n"
        },
        {
          "name": "_gccgo",
          "type": "tree",
          "content": null
        },
        {
          "name": "_goremote",
          "type": "tree",
          "content": null
        },
        {
          "name": "_testing",
          "type": "tree",
          "content": null
        },
        {
          "name": "autocompletecontext.go",
          "type": "blob",
          "size": 20.3798828125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/parser\"\n\t\"go/token\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n)\n\n//-------------------------------------------------------------------------\n// out_buffers\n//\n// Temporary structure for writing autocomplete response.\n//-------------------------------------------------------------------------\n\n// fields must be exported for RPC\ntype candidate struct {\n\tName    string\n\tType    string\n\tClass   decl_class\n\tPackage string\n}\n\ntype out_buffers struct {\n\ttmpbuf            *bytes.Buffer\n\tcandidates        []candidate\n\tcanonical_aliases map[string]string\n\tctx               *auto_complete_context\n\ttmpns             map[string]bool\n\tignorecase        bool\n}\n\nfunc new_out_buffers(ctx *auto_complete_context) *out_buffers {\n\tb := new(out_buffers)\n\tb.tmpbuf = bytes.NewBuffer(make([]byte, 0, 1024))\n\tb.candidates = make([]candidate, 0, 64)\n\tb.ctx = ctx\n\tb.canonical_aliases = make(map[string]string)\n\tfor _, imp := range b.ctx.current.packages {\n\t\tb.canonical_aliases[imp.abspath] = imp.alias\n\t}\n\treturn b\n}\n\nfunc (b *out_buffers) Len() int {\n\treturn len(b.candidates)\n}\n\nfunc (b *out_buffers) Less(i, j int) bool {\n\tx := b.candidates[i]\n\ty := b.candidates[j]\n\tif x.Class == y.Class {\n\t\treturn x.Name < y.Name\n\t}\n\treturn x.Class < y.Class\n}\n\nfunc (b *out_buffers) Swap(i, j int) {\n\tb.candidates[i], b.candidates[j] = b.candidates[j], b.candidates[i]\n}\n\nfunc (b *out_buffers) append_decl(p, name, pkg string, decl *decl, class decl_class) {\n\tc1 := !g_config.ProposeBuiltins && decl.scope == g_universe_scope && decl.name != \"Error\"\n\tc2 := class != decl_invalid && decl.class != class\n\tc3 := class == decl_invalid && !has_prefix(name, p, b.ignorecase)\n\tc4 := !decl.matches()\n\tc5 := !check_type_expr(decl.typ)\n\n\tif c1 || c2 || c3 || c4 || c5 {\n\t\treturn\n\t}\n\n\tdecl.pretty_print_type(b.tmpbuf, b.canonical_aliases)\n\tb.candidates = append(b.candidates, candidate{\n\t\tName:    name,\n\t\tType:    b.tmpbuf.String(),\n\t\tClass:   decl.class,\n\t\tPackage: pkg,\n\t})\n\tb.tmpbuf.Reset()\n}\n\nfunc (b *out_buffers) append_embedded(p string, decl *decl, pkg string, class decl_class) {\n\tif decl.embedded == nil {\n\t\treturn\n\t}\n\n\tfirst_level := false\n\tif b.tmpns == nil {\n\t\t// first level, create tmp namespace\n\t\tb.tmpns = make(map[string]bool)\n\t\tfirst_level = true\n\n\t\t// add all children of the current decl to the namespace\n\t\tfor _, c := range decl.children {\n\t\t\tb.tmpns[c.name] = true\n\t\t}\n\t}\n\n\tfor _, emb := range decl.embedded {\n\t\ttypedecl := type_to_decl(emb, decl.scope)\n\t\tif typedecl == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// could be type alias\n\t\tif typedecl.is_alias() {\n\t\t\ttypedecl = typedecl.type_dealias()\n\t\t}\n\n\t\t// prevent infinite recursion here\n\t\tif typedecl.is_visited() {\n\t\t\tcontinue\n\t\t}\n\t\ttypedecl.set_visited()\n\t\tdefer typedecl.clear_visited()\n\n\t\tfor _, c := range typedecl.children {\n\t\t\tif _, has := b.tmpns[c.name]; has {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tb.append_decl(p, c.name, pkg, c, class)\n\t\t\tb.tmpns[c.name] = true\n\t\t}\n\t\tb.append_embedded(p, typedecl, pkg, class)\n\t}\n\n\tif first_level {\n\t\t// remove tmp namespace\n\t\tb.tmpns = nil\n\t}\n}\n\n//-------------------------------------------------------------------------\n// auto_complete_context\n//\n// Context that holds cache structures for autocompletion needs. It\n// includes cache for packages and for main package files.\n//-------------------------------------------------------------------------\n\ntype auto_complete_context struct {\n\tcurrent *auto_complete_file // currently edited file\n\tothers  []*decl_file_cache  // other files of the current package\n\tpkg     *scope\n\n\tpcache    package_cache // packages cache\n\tdeclcache *decl_cache   // top-level declarations cache\n}\n\nfunc new_auto_complete_context(pcache package_cache, declcache *decl_cache) *auto_complete_context {\n\tc := new(auto_complete_context)\n\tc.current = new_auto_complete_file(\"\", declcache.context)\n\tc.pcache = pcache\n\tc.declcache = declcache\n\treturn c\n}\n\nfunc (c *auto_complete_context) update_caches() {\n\t// temporary map for packages that we need to check for a cache expiration\n\t// map is used as a set of unique items to prevent double checks\n\tps := make(map[string]*package_file_cache)\n\n\t// collect import information from all of the files\n\tc.pcache.append_packages(ps, c.current.packages)\n\tc.others = get_other_package_files(c.current.name, c.current.package_name, c.declcache)\n\tfor _, other := range c.others {\n\t\tc.pcache.append_packages(ps, other.packages)\n\t}\n\n\tupdate_packages(ps)\n\n\t// fix imports for all files\n\tfixup_packages(c.current.filescope, c.current.packages, c.pcache)\n\tfor _, f := range c.others {\n\t\tfixup_packages(f.filescope, f.packages, c.pcache)\n\t}\n\n\t// At this point we have collected all top level declarations, now we need to\n\t// merge them in the common package block.\n\tc.merge_decls()\n}\n\nfunc (c *auto_complete_context) merge_decls() {\n\tc.pkg = new_scope(g_universe_scope)\n\tmerge_decls(c.current.filescope, c.pkg, c.current.decls)\n\tmerge_decls_from_packages(c.pkg, c.current.packages, c.pcache)\n\tfor _, f := range c.others {\n\t\tmerge_decls(f.filescope, c.pkg, f.decls)\n\t\tmerge_decls_from_packages(c.pkg, f.packages, c.pcache)\n\t}\n\n\t// special pass for type aliases which also have methods, while this is\n\t// valid code, it shouldn't happen a lot in practice, so, whatever\n\t// let's move all type alias methods to their first non-alias type down in\n\t// the chain\n\tpropagate_type_alias_methods(c.pkg)\n}\n\nfunc (c *auto_complete_context) make_decl_set(scope *scope) map[string]*decl {\n\tset := make(map[string]*decl, len(c.pkg.entities)*2)\n\tmake_decl_set_recursive(set, scope)\n\treturn set\n}\n\nfunc (c *auto_complete_context) get_candidates_from_set(set map[string]*decl, partial string, class decl_class, b *out_buffers) {\n\tfor key, value := range set {\n\t\tif value == nil {\n\t\t\tcontinue\n\t\t}\n\t\tvalue.infer_type()\n\t\tpkgname := \"\"\n\t\tif pkg, ok := c.pcache[value.name]; ok {\n\t\t\tpkgname = pkg.import_name\n\t\t}\n\t\tb.append_decl(partial, key, pkgname, value, class)\n\t}\n}\n\nfunc (c *auto_complete_context) get_candidates_from_decl_alias(cc cursor_context, class decl_class, b *out_buffers) {\n\tif cc.decl.is_visited() {\n\t\treturn\n\t}\n\n\tcc.decl = cc.decl.type_dealias()\n\tif cc.decl == nil {\n\t\treturn\n\t}\n\n\tcc.decl.set_visited()\n\tdefer cc.decl.clear_visited()\n\n\tc.get_candidates_from_decl(cc, class, b)\n\treturn\n}\n\nfunc (c *auto_complete_context) decl_package_import_path(decl *decl) string {\n\tif decl == nil || decl.scope == nil {\n\t\treturn \"\"\n\t}\n\tif pkg, ok := c.pcache[decl.scope.pkgname]; ok {\n\t\treturn pkg.import_name\n\t}\n\treturn \"\"\n}\n\nfunc (c *auto_complete_context) get_candidates_from_decl(cc cursor_context, class decl_class, b *out_buffers) {\n\tif cc.decl.is_alias() {\n\t\tc.get_candidates_from_decl_alias(cc, class, b)\n\t\treturn\n\t}\n\n\t// propose all children of a subject declaration and\n\tfor _, decl := range cc.decl.children {\n\t\tif cc.decl.class == decl_package && !ast.IsExported(decl.name) {\n\t\t\tcontinue\n\t\t}\n\t\tif cc.struct_field {\n\t\t\t// if we're autocompleting struct field init, skip all methods\n\t\t\tif _, ok := decl.typ.(*ast.FuncType); ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tb.append_decl(cc.partial, decl.name, c.decl_package_import_path(decl), decl, class)\n\t}\n\t// propose all children of an underlying struct/interface type\n\tadecl := advance_to_struct_or_interface(cc.decl)\n\tif adecl != nil && adecl != cc.decl {\n\t\tfor _, decl := range adecl.children {\n\t\t\tif decl.class == decl_var {\n\t\t\t\tb.append_decl(cc.partial, decl.name, c.decl_package_import_path(decl), decl, class)\n\t\t\t}\n\t\t}\n\t}\n\t// propose all children of its embedded types\n\tb.append_embedded(cc.partial, cc.decl, c.decl_package_import_path(cc.decl), class)\n}\n\nfunc (c *auto_complete_context) get_import_candidates(partial string, b *out_buffers) {\n\tcurrentPackagePath, pkgdirs := g_daemon.context.pkg_dirs()\n\tresultSet := map[string]struct{}{}\n\tfor _, pkgdir := range pkgdirs {\n\t\t// convert srcpath to pkgpath and get candidates\n\t\tget_import_candidates_dir(pkgdir, filepath.FromSlash(partial), b.ignorecase, currentPackagePath, resultSet)\n\t}\n\tfor k := range resultSet {\n\t\tb.candidates = append(b.candidates, candidate{Name: k, Class: decl_import})\n\t}\n}\n\nfunc get_import_candidates_dir(root, partial string, ignorecase bool, currentPackagePath string, r map[string]struct{}) {\n\tvar fpath string\n\tvar match bool\n\tif strings.HasSuffix(partial, \"/\") {\n\t\tfpath = filepath.Join(root, partial)\n\t} else {\n\t\tfpath = filepath.Join(root, filepath.Dir(partial))\n\t\tmatch = true\n\t}\n\tfi := readdir(fpath)\n\tfor i := range fi {\n\t\tname := fi[i].Name()\n\t\trel, err := filepath.Rel(root, filepath.Join(fpath, name))\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif match && !has_prefix(rel, partial, ignorecase) {\n\t\t\tcontinue\n\t\t} else if fi[i].IsDir() {\n\t\t\tget_import_candidates_dir(root, rel+string(filepath.Separator), ignorecase, currentPackagePath, r)\n\t\t} else {\n\t\t\text := filepath.Ext(name)\n\t\t\tif ext != \".a\" {\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\trel = rel[0 : len(rel)-2]\n\t\t\t}\n\t\t\tif ipath, ok := vendorlessImportPath(filepath.ToSlash(rel), currentPackagePath); ok {\n\t\t\t\tr[ipath] = struct{}{}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// returns three slices of the same length containing:\n// 1. apropos names\n// 2. apropos types (pretty-printed)\n// 3. apropos classes\n// and length of the part that should be replaced (if any)\nfunc (c *auto_complete_context) apropos(file []byte, filename string, cursor int) ([]candidate, int) {\n\tc.current.cursor = cursor\n\tc.current.name = filename\n\n\t// Update caches and parse the current file.\n\t// This process is quite complicated, because I was trying to design it in a\n\t// concurrent fashion. Apparently I'm not really good at that. Hopefully\n\t// will be better in future.\n\n\t// Ugly hack, but it actually may help in some cases. Insert a\n\t// semicolon right at the cursor location.\n\tfilesemi := make([]byte, len(file)+1)\n\tcopy(filesemi, file[:cursor])\n\tfilesemi[cursor] = ';'\n\tcopy(filesemi[cursor+1:], file[cursor:])\n\n\t// Does full processing of the currently edited file (top-level declarations plus\n\t// active function).\n\tc.current.process_data(filesemi)\n\n\t// Updates cache of other files and packages. See the function for details of\n\t// the process. At the end merges all the top-level declarations into the package\n\t// block.\n\tc.update_caches()\n\n\t// And we're ready to Go. ;)\n\n\tb := new_out_buffers(c)\n\tif g_config.IgnoreCase {\n\t\tif *g_debug {\n\t\t\tlog.Printf(\"ignoring case sensitivity\")\n\t\t}\n\t\tb.ignorecase = true\n\t}\n\n\tcc, ok := c.deduce_cursor_context(file, cursor)\n\tpartial := len(cc.partial)\n\tif !g_config.Partials {\n\t\tif *g_debug {\n\t\t\tlog.Printf(\"not performing partial prefix matching\")\n\t\t}\n\t\tcc.partial = \"\"\n\t}\n\tif !ok {\n\t\tvar d *decl\n\t\tif ident, ok := cc.expr.(*ast.Ident); ok && g_config.UnimportedPackages {\n\t\t\tp := resolveKnownPackageIdent(ident.Name, c.current.name, c.current.context)\n\t\t\tif p != nil {\n\t\t\t\tc.pcache[p.name] = p\n\t\t\t\td = p.main\n\t\t\t}\n\t\t}\n\t\tif d == nil {\n\t\t\treturn nil, 0\n\t\t}\n\t\tcc.decl = d\n\t}\n\n\tclass := decl_invalid\n\tif g_config.ClassFiltering {\n\t\tswitch cc.partial {\n\t\tcase \"const\":\n\t\t\tclass = decl_const\n\t\tcase \"var\":\n\t\t\tclass = decl_var\n\t\tcase \"type\":\n\t\t\tclass = decl_type\n\t\tcase \"func\":\n\t\t\tclass = decl_func\n\t\tcase \"package\":\n\t\t\tclass = decl_package\n\t\t}\n\t}\n\n\tif cc.decl_import {\n\t\tc.get_import_candidates(cc.partial, b)\n\t\tif cc.partial != \"\" && len(b.candidates) == 0 {\n\t\t\t// as a fallback, try case insensitive approach\n\t\t\tb.ignorecase = true\n\t\t\tc.get_import_candidates(cc.partial, b)\n\t\t}\n\t} else if cc.decl == nil {\n\t\t// In case if no declaraion is a subject of completion, propose all:\n\t\tset := c.make_decl_set(c.current.scope)\n\t\tc.get_candidates_from_set(set, cc.partial, class, b)\n\t\tif cc.partial != \"\" && len(b.candidates) == 0 {\n\t\t\t// as a fallback, try case insensitive approach\n\t\t\tb.ignorecase = true\n\t\t\tc.get_candidates_from_set(set, cc.partial, class, b)\n\t\t}\n\t} else {\n\t\tc.get_candidates_from_decl(cc, class, b)\n\t\tif cc.partial != \"\" && len(b.candidates) == 0 {\n\t\t\t// as a fallback, try case insensitive approach\n\t\t\tb.ignorecase = true\n\t\t\tc.get_candidates_from_decl(cc, class, b)\n\t\t}\n\t}\n\n\tif len(b.candidates) == 0 {\n\t\treturn nil, 0\n\t}\n\n\tsort.Sort(b)\n\treturn b.candidates, partial\n}\n\nfunc update_packages(ps map[string]*package_file_cache) {\n\t// initiate package cache update\n\tdone := make(chan bool)\n\tfor _, p := range ps {\n\t\tgo func(p *package_file_cache) {\n\t\t\tdefer func() {\n\t\t\t\tif err := recover(); err != nil {\n\t\t\t\t\tprint_backtrace(err)\n\t\t\t\t\tdone <- false\n\t\t\t\t}\n\t\t\t}()\n\t\t\tp.update_cache()\n\t\t\tdone <- true\n\t\t}(p)\n\t}\n\n\t// wait for its completion\n\tfor _ = range ps {\n\t\tif !<-done {\n\t\t\tpanic(\"One of the package cache updaters panicked\")\n\t\t}\n\t}\n}\n\nfunc collect_type_alias_methods(d *decl) map[string]*decl {\n\tif d == nil || d.is_visited() || !d.is_alias() {\n\t\treturn nil\n\t}\n\td.set_visited()\n\tdefer d.clear_visited()\n\n\t// add own methods\n\tm := map[string]*decl{}\n\tfor k, v := range d.children {\n\t\tm[k] = v\n\t}\n\n\t// recurse into more aliases\n\tdd := type_to_decl(d.typ, d.scope)\n\tfor k, v := range collect_type_alias_methods(dd) {\n\t\tm[k] = v\n\t}\n\n\treturn m\n}\n\nfunc propagate_type_alias_methods(s *scope) {\n\tfor _, e := range s.entities {\n\t\tif !e.is_alias() {\n\t\t\tcontinue\n\t\t}\n\n\t\tmethods := collect_type_alias_methods(e)\n\t\tif len(methods) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tdd := e.type_dealias()\n\t\tif dd == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tdecl := dd.deep_copy()\n\t\tfor _, v := range methods {\n\t\t\tdecl.add_child(v)\n\t\t}\n\t\ts.entities[decl.name] = decl\n\t}\n}\n\nfunc merge_decls(filescope *scope, pkg *scope, decls map[string]*decl) {\n\tfor _, d := range decls {\n\t\tpkg.merge_decl(d)\n\t}\n\tfilescope.parent = pkg\n}\n\nfunc merge_decls_from_packages(pkgscope *scope, pkgs []package_import, pcache package_cache) {\n\tfor _, p := range pkgs {\n\t\tpath, alias := p.abspath, p.alias\n\t\tif alias != \".\" {\n\t\t\tcontinue\n\t\t}\n\t\tp := pcache[path].main\n\t\tif p == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, d := range p.children {\n\t\t\tif ast.IsExported(d.name) {\n\t\t\t\tpkgscope.merge_decl(d)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc fixup_packages(filescope *scope, pkgs []package_import, pcache package_cache) {\n\tfor _, p := range pkgs {\n\t\tpath, alias := p.abspath, p.alias\n\t\tif alias == \"\" {\n\t\t\talias = pcache[path].defalias\n\t\t}\n\t\t// skip packages that will be merged to the package scope\n\t\tif alias == \".\" {\n\t\t\tcontinue\n\t\t}\n\t\tfilescope.replace_decl(alias, pcache[path].main)\n\t}\n}\n\nfunc get_other_package_files(filename, packageName string, declcache *decl_cache) []*decl_file_cache {\n\tothers := find_other_package_files(filename, packageName)\n\n\tret := make([]*decl_file_cache, len(others))\n\tdone := make(chan *decl_file_cache)\n\n\tfor _, nm := range others {\n\t\tgo func(name string) {\n\t\t\tdefer func() {\n\t\t\t\tif err := recover(); err != nil {\n\t\t\t\t\tprint_backtrace(err)\n\t\t\t\t\tdone <- nil\n\t\t\t\t}\n\t\t\t}()\n\t\t\tdone <- declcache.get_and_update(name)\n\t\t}(nm)\n\t}\n\n\tfor i := range others {\n\t\tret[i] = <-done\n\t\tif ret[i] == nil {\n\t\t\tpanic(\"One of the decl cache updaters panicked\")\n\t\t}\n\t}\n\n\treturn ret\n}\n\nfunc find_other_package_files(filename, package_name string) []string {\n\tif filename == \"\" {\n\t\treturn nil\n\t}\n\n\tdir, file := filepath.Split(filename)\n\tfiles_in_dir, err := readdir_lstat(dir)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tcount := 0\n\tfor _, stat := range files_in_dir {\n\t\tok, _ := filepath.Match(\"*.go\", stat.Name())\n\t\tif !ok || stat.Name() == file {\n\t\t\tcontinue\n\t\t}\n\t\tcount++\n\t}\n\n\tout := make([]string, 0, count)\n\tfor _, stat := range files_in_dir {\n\t\tconst non_regular = os.ModeDir | os.ModeSymlink |\n\t\t\tos.ModeDevice | os.ModeNamedPipe | os.ModeSocket\n\n\t\tok, _ := filepath.Match(\"*.go\", stat.Name())\n\t\tif !ok || stat.Name() == file || stat.Mode()&non_regular != 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tabspath := filepath.Join(dir, stat.Name())\n\t\tif file_package_name(abspath) == package_name {\n\t\t\tn := len(out)\n\t\t\tout = out[:n+1]\n\t\t\tout[n] = abspath\n\t\t}\n\t}\n\n\treturn out\n}\n\nfunc file_package_name(filename string) string {\n\tfile, _ := parser.ParseFile(token.NewFileSet(), filename, nil, parser.PackageClauseOnly)\n\treturn file.Name.Name\n}\n\nfunc make_decl_set_recursive(set map[string]*decl, scope *scope) {\n\tfor name, ent := range scope.entities {\n\t\tif _, ok := set[name]; !ok {\n\t\t\tset[name] = ent\n\t\t}\n\t}\n\tif scope.parent != nil {\n\t\tmake_decl_set_recursive(set, scope.parent)\n\t}\n}\n\nfunc check_func_field_list(f *ast.FieldList) bool {\n\tif f == nil {\n\t\treturn true\n\t}\n\n\tfor _, field := range f.List {\n\t\tif !check_type_expr(field.Type) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// checks for a type expression correctness, it the type expression has\n// ast.BadExpr somewhere, returns false, otherwise true\nfunc check_type_expr(e ast.Expr) bool {\n\tswitch t := e.(type) {\n\tcase *ast.StarExpr:\n\t\treturn check_type_expr(t.X)\n\tcase *ast.ArrayType:\n\t\treturn check_type_expr(t.Elt)\n\tcase *ast.SelectorExpr:\n\t\treturn check_type_expr(t.X)\n\tcase *ast.FuncType:\n\t\ta := check_func_field_list(t.Params)\n\t\tb := check_func_field_list(t.Results)\n\t\treturn a && b\n\tcase *ast.MapType:\n\t\ta := check_type_expr(t.Key)\n\t\tb := check_type_expr(t.Value)\n\t\treturn a && b\n\tcase *ast.Ellipsis:\n\t\treturn check_type_expr(t.Elt)\n\tcase *ast.ChanType:\n\t\treturn check_type_expr(t.Value)\n\tcase *ast.BadExpr:\n\t\treturn false\n\tdefault:\n\t\treturn true\n\t}\n}\n\n//-------------------------------------------------------------------------\n// Status output\n//-------------------------------------------------------------------------\n\ntype decl_slice []*decl\n\nfunc (s decl_slice) Less(i, j int) bool {\n\tif s[i].class != s[j].class {\n\t\treturn s[i].name < s[j].name\n\t}\n\treturn s[i].class < s[j].class\n}\nfunc (s decl_slice) Len() int      { return len(s) }\nfunc (s decl_slice) Swap(i, j int) { s[i], s[j] = s[j], s[i] }\n\nconst (\n\tcolor_red          = \"\\033[0;31m\"\n\tcolor_red_bold     = \"\\033[1;31m\"\n\tcolor_green        = \"\\033[0;32m\"\n\tcolor_green_bold   = \"\\033[1;32m\"\n\tcolor_yellow       = \"\\033[0;33m\"\n\tcolor_yellow_bold  = \"\\033[1;33m\"\n\tcolor_blue         = \"\\033[0;34m\"\n\tcolor_blue_bold    = \"\\033[1;34m\"\n\tcolor_magenta      = \"\\033[0;35m\"\n\tcolor_magenta_bold = \"\\033[1;35m\"\n\tcolor_cyan         = \"\\033[0;36m\"\n\tcolor_cyan_bold    = \"\\033[1;36m\"\n\tcolor_white        = \"\\033[0;37m\"\n\tcolor_white_bold   = \"\\033[1;37m\"\n\tcolor_none         = \"\\033[0m\"\n)\n\nvar g_decl_class_to_color = [...]string{\n\tdecl_const:        color_white_bold,\n\tdecl_var:          color_magenta,\n\tdecl_type:         color_cyan,\n\tdecl_func:         color_green,\n\tdecl_package:      color_red,\n\tdecl_methods_stub: color_red,\n}\n\nvar g_decl_class_to_string_status = [...]string{\n\tdecl_const:        \"  const\",\n\tdecl_var:          \"    var\",\n\tdecl_type:         \"   type\",\n\tdecl_func:         \"   func\",\n\tdecl_package:      \"package\",\n\tdecl_methods_stub: \"   stub\",\n}\n\nfunc (c *auto_complete_context) status() string {\n\n\tbuf := bytes.NewBuffer(make([]byte, 0, 4096))\n\tfmt.Fprintf(buf, \"Server's GOMAXPROCS == %d\\n\", runtime.GOMAXPROCS(0))\n\tfmt.Fprintf(buf, \"\\nPackage cache contains %d entries\\n\", len(c.pcache))\n\tfmt.Fprintf(buf, \"\\nListing these entries:\\n\")\n\tfor _, mod := range c.pcache {\n\t\tfmt.Fprintf(buf, \"\\tname: %s (default alias: %s)\\n\", mod.name, mod.defalias)\n\t\tfmt.Fprintf(buf, \"\\timports %d declarations and %d packages\\n\", len(mod.main.children), len(mod.others))\n\t\tif mod.mtime == -1 {\n\t\t\tfmt.Fprintf(buf, \"\\tthis package stays in cache forever (built-in package)\\n\")\n\t\t} else {\n\t\t\tmtime := time.Unix(0, mod.mtime)\n\t\t\tfmt.Fprintf(buf, \"\\tlast modification time: %s\\n\", mtime)\n\t\t}\n\t\tfmt.Fprintf(buf, \"\\n\")\n\t}\n\tif c.current.name != \"\" {\n\t\tfmt.Fprintf(buf, \"Last edited file: %s (package: %s)\\n\", c.current.name, c.current.package_name)\n\t\tif len(c.others) > 0 {\n\t\t\tfmt.Fprintf(buf, \"\\nOther files from the current package:\\n\")\n\t\t}\n\t\tfor _, f := range c.others {\n\t\t\tfmt.Fprintf(buf, \"\\t%s\\n\", f.name)\n\t\t}\n\t\tfmt.Fprintf(buf, \"\\nListing declarations from files:\\n\")\n\n\t\tconst status_decls = \"\\t%s%s\" + color_none + \" \" + color_yellow + \"%s\" + color_none + \"\\n\"\n\t\tconst status_decls_children = \"\\t%s%s\" + color_none + \" \" + color_yellow + \"%s\" + color_none + \" (%d)\\n\"\n\n\t\tfmt.Fprintf(buf, \"\\n%s:\\n\", c.current.name)\n\t\tds := make(decl_slice, len(c.current.decls))\n\t\ti := 0\n\t\tfor _, d := range c.current.decls {\n\t\t\tds[i] = d\n\t\t\ti++\n\t\t}\n\t\tsort.Sort(ds)\n\t\tfor _, d := range ds {\n\t\t\tif len(d.children) > 0 {\n\t\t\t\tfmt.Fprintf(buf, status_decls_children,\n\t\t\t\t\tg_decl_class_to_color[d.class],\n\t\t\t\t\tg_decl_class_to_string_status[d.class],\n\t\t\t\t\td.name, len(d.children))\n\t\t\t} else {\n\t\t\t\tfmt.Fprintf(buf, status_decls,\n\t\t\t\t\tg_decl_class_to_color[d.class],\n\t\t\t\t\tg_decl_class_to_string_status[d.class],\n\t\t\t\t\td.name)\n\t\t\t}\n\t\t}\n\n\t\tfor _, f := range c.others {\n\t\t\tfmt.Fprintf(buf, \"\\n%s:\\n\", f.name)\n\t\t\tds = make(decl_slice, len(f.decls))\n\t\t\ti = 0\n\t\t\tfor _, d := range f.decls {\n\t\t\t\tds[i] = d\n\t\t\t\ti++\n\t\t\t}\n\t\t\tsort.Sort(ds)\n\t\t\tfor _, d := range ds {\n\t\t\t\tif len(d.children) > 0 {\n\t\t\t\t\tfmt.Fprintf(buf, status_decls_children,\n\t\t\t\t\t\tg_decl_class_to_color[d.class],\n\t\t\t\t\t\tg_decl_class_to_string_status[d.class],\n\t\t\t\t\t\td.name, len(d.children))\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Fprintf(buf, status_decls,\n\t\t\t\t\t\tg_decl_class_to_color[d.class],\n\t\t\t\t\t\tg_decl_class_to_string_status[d.class],\n\t\t\t\t\t\td.name)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn buf.String()\n}\n"
        },
        {
          "name": "autocompletefile.go",
          "type": "blob",
          "size": 9.6640625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"go/ast\"\n\t\"go/parser\"\n\t\"go/scanner\"\n\t\"go/token\"\n\t\"log\"\n)\n\nfunc parse_decl_list(fset *token.FileSet, data []byte) ([]ast.Decl, error) {\n\tvar buf bytes.Buffer\n\tbuf.WriteString(\"package p;\")\n\tbuf.Write(data)\n\tfile, err := parser.ParseFile(fset, \"\", buf.Bytes(), parser.AllErrors)\n\tif err != nil {\n\t\treturn file.Decls, err\n\t}\n\treturn file.Decls, nil\n}\n\nfunc log_parse_error(intro string, err error) {\n\tif el, ok := err.(scanner.ErrorList); ok {\n\t\tlog.Printf(\"%s:\", intro)\n\t\tfor _, er := range el {\n\t\t\tlog.Printf(\" %s\", er)\n\t\t}\n\t} else {\n\t\tlog.Printf(\"%s: %s\", intro, err)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// auto_complete_file\n//-------------------------------------------------------------------------\n\ntype auto_complete_file struct {\n\tname         string\n\tpackage_name string\n\n\tdecls     map[string]*decl\n\tpackages  []package_import\n\tfilescope *scope\n\tscope     *scope\n\n\tcursor  int // for current file buffer only\n\tfset    *token.FileSet\n\tcontext *package_lookup_context\n}\n\nfunc new_auto_complete_file(name string, context *package_lookup_context) *auto_complete_file {\n\tp := new(auto_complete_file)\n\tp.name = name\n\tp.cursor = -1\n\tp.fset = token.NewFileSet()\n\tp.context = context\n\treturn p\n}\n\nfunc (f *auto_complete_file) offset(p token.Pos) int {\n\tconst fixlen = len(\"package p;\")\n\treturn f.fset.Position(p).Offset - fixlen\n}\n\n// this one is used for current file buffer exclusively\nfunc (f *auto_complete_file) process_data(data []byte) {\n\tcur, filedata, block := rip_off_decl(data, f.cursor)\n\tfile, err := parser.ParseFile(f.fset, \"\", filedata, parser.AllErrors)\n\tif err != nil && *g_debug {\n\t\tlog_parse_error(\"Error parsing input file (outer block)\", err)\n\t}\n\tf.package_name = package_name(file)\n\n\tf.decls = make(map[string]*decl)\n\tf.packages = collect_package_imports(f.name, file.Decls, f.context)\n\tf.filescope = new_scope(nil)\n\tf.scope = f.filescope\n\n\tfor _, d := range file.Decls {\n\t\tanonymify_ast(d, 0, f.filescope)\n\t}\n\n\t// process all top-level declarations\n\tfor _, decl := range file.Decls {\n\t\tappend_to_top_decls(f.decls, decl, f.scope)\n\t}\n\tif block != nil {\n\t\t// process local function as top-level declaration\n\t\tdecls, err := parse_decl_list(f.fset, block)\n\t\tif err != nil && *g_debug {\n\t\t\tlog_parse_error(\"Error parsing input file (inner block)\", err)\n\t\t}\n\n\t\tfor _, d := range decls {\n\t\t\tanonymify_ast(d, 0, f.filescope)\n\t\t}\n\n\t\tfor _, decl := range decls {\n\t\t\tappend_to_top_decls(f.decls, decl, f.scope)\n\t\t}\n\n\t\t// process function internals\n\t\tf.cursor = cur\n\t\tfor _, decl := range decls {\n\t\t\tf.process_decl_locals(decl)\n\t\t}\n\t}\n\n}\n\nfunc (f *auto_complete_file) process_decl_locals(decl ast.Decl) {\n\tswitch t := decl.(type) {\n\tcase *ast.FuncDecl:\n\t\tif f.cursor_in(t.Body) {\n\t\t\ts := f.scope\n\t\t\tf.scope = new_scope(f.scope)\n\n\t\t\tf.process_field_list(t.Recv, s)\n\t\t\tf.process_field_list(t.Type.Params, s)\n\t\t\tf.process_field_list(t.Type.Results, s)\n\t\t\tf.process_block_stmt(t.Body)\n\t\t}\n\tdefault:\n\t\tv := new(func_lit_visitor)\n\t\tv.ctx = f\n\t\tast.Walk(v, decl)\n\t}\n}\n\nfunc (f *auto_complete_file) process_decl(decl ast.Decl) {\n\tif t, ok := decl.(*ast.GenDecl); ok && f.offset(t.TokPos) > f.cursor {\n\t\treturn\n\t}\n\tprevscope := f.scope\n\tforeach_decl(decl, func(data *foreach_decl_struct) {\n\t\tclass := ast_decl_class(data.decl)\n\t\tif class != decl_type {\n\t\t\tf.scope, prevscope = advance_scope(f.scope)\n\t\t}\n\t\tfor i, name := range data.names {\n\t\t\ttyp, v, vi := data.type_value_index(i)\n\n\t\t\td := new_decl_full(name.Name, class, ast_decl_flags(data.decl), typ, v, vi, prevscope)\n\t\t\tif d == nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tf.scope.add_named_decl(d)\n\t\t}\n\t})\n}\n\nfunc (f *auto_complete_file) process_block_stmt(block *ast.BlockStmt) {\n\tif block != nil && f.cursor_in(block) {\n\t\tf.scope, _ = advance_scope(f.scope)\n\n\t\tfor _, stmt := range block.List {\n\t\t\tf.process_stmt(stmt)\n\t\t}\n\n\t\t// hack to process all func literals\n\t\tv := new(func_lit_visitor)\n\t\tv.ctx = f\n\t\tast.Walk(v, block)\n\t}\n}\n\ntype func_lit_visitor struct {\n\tctx *auto_complete_file\n}\n\nfunc (v *func_lit_visitor) Visit(node ast.Node) ast.Visitor {\n\tif t, ok := node.(*ast.FuncLit); ok && v.ctx.cursor_in(t.Body) {\n\t\ts := v.ctx.scope\n\t\tv.ctx.scope = new_scope(v.ctx.scope)\n\n\t\tv.ctx.process_field_list(t.Type.Params, s)\n\t\tv.ctx.process_field_list(t.Type.Results, s)\n\t\tv.ctx.process_block_stmt(t.Body)\n\n\t\treturn nil\n\t}\n\treturn v\n}\n\nfunc (f *auto_complete_file) process_stmt(stmt ast.Stmt) {\n\tswitch t := stmt.(type) {\n\tcase *ast.DeclStmt:\n\t\tf.process_decl(t.Decl)\n\tcase *ast.AssignStmt:\n\t\tf.process_assign_stmt(t)\n\tcase *ast.IfStmt:\n\t\tif f.cursor_in_if_head(t) {\n\t\t\tf.process_stmt(t.Init)\n\t\t} else if f.cursor_in_if_stmt(t) {\n\t\t\tf.scope, _ = advance_scope(f.scope)\n\t\t\tf.process_stmt(t.Init)\n\t\t\tf.process_block_stmt(t.Body)\n\t\t\tf.process_stmt(t.Else)\n\t\t}\n\tcase *ast.BlockStmt:\n\t\tf.process_block_stmt(t)\n\tcase *ast.RangeStmt:\n\t\tf.process_range_stmt(t)\n\tcase *ast.ForStmt:\n\t\tif f.cursor_in_for_head(t) {\n\t\t\tf.process_stmt(t.Init)\n\t\t} else if f.cursor_in(t.Body) {\n\t\t\tf.scope, _ = advance_scope(f.scope)\n\n\t\t\tf.process_stmt(t.Init)\n\t\t\tf.process_block_stmt(t.Body)\n\t\t}\n\tcase *ast.SwitchStmt:\n\t\tf.process_switch_stmt(t)\n\tcase *ast.TypeSwitchStmt:\n\t\tf.process_type_switch_stmt(t)\n\tcase *ast.SelectStmt:\n\t\tf.process_select_stmt(t)\n\tcase *ast.LabeledStmt:\n\t\tf.process_stmt(t.Stmt)\n\t}\n}\n\nfunc (f *auto_complete_file) process_select_stmt(a *ast.SelectStmt) {\n\tif !f.cursor_in(a.Body) {\n\t\treturn\n\t}\n\tvar prevscope *scope\n\tf.scope, prevscope = advance_scope(f.scope)\n\n\tvar last_cursor_after *ast.CommClause\n\tfor _, s := range a.Body.List {\n\t\tif cc := s.(*ast.CommClause); f.cursor > f.offset(cc.Colon) {\n\t\t\tlast_cursor_after = cc\n\t\t}\n\t}\n\n\tif last_cursor_after != nil {\n\t\tif last_cursor_after.Comm != nil {\n\t\t\t//if lastCursorAfter.Lhs != nil && lastCursorAfter.Tok == token.DEFINE {\n\t\t\tif astmt, ok := last_cursor_after.Comm.(*ast.AssignStmt); ok && astmt.Tok == token.DEFINE {\n\t\t\t\tvname := astmt.Lhs[0].(*ast.Ident).Name\n\t\t\t\tv := new_decl_var(vname, nil, astmt.Rhs[0], -1, prevscope)\n\t\t\t\tif v != nil {\n\t\t\t\t\tf.scope.add_named_decl(v)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, s := range last_cursor_after.Body {\n\t\t\tf.process_stmt(s)\n\t\t}\n\t}\n}\n\nfunc (f *auto_complete_file) process_type_switch_stmt(a *ast.TypeSwitchStmt) {\n\tif !f.cursor_in(a.Body) {\n\t\treturn\n\t}\n\tvar prevscope *scope\n\tf.scope, prevscope = advance_scope(f.scope)\n\n\tf.process_stmt(a.Init)\n\t// type var\n\tvar tv *decl\n\tif a, ok := a.Assign.(*ast.AssignStmt); ok {\n\t\tlhs := a.Lhs\n\t\trhs := a.Rhs\n\t\tif lhs != nil && len(lhs) == 1 {\n\t\t\ttvname := lhs[0].(*ast.Ident).Name\n\t\t\ttv = new_decl_var(tvname, nil, rhs[0], -1, prevscope)\n\t\t}\n\t}\n\n\tvar last_cursor_after *ast.CaseClause\n\tfor _, s := range a.Body.List {\n\t\tif cc := s.(*ast.CaseClause); f.cursor > f.offset(cc.Colon) {\n\t\t\tlast_cursor_after = cc\n\t\t}\n\t}\n\n\tif last_cursor_after != nil {\n\t\tif tv != nil {\n\t\t\tif last_cursor_after.List != nil && len(last_cursor_after.List) == 1 {\n\t\t\t\ttv.typ = last_cursor_after.List[0]\n\t\t\t\ttv.value = nil\n\t\t\t}\n\t\t\tf.scope.add_named_decl(tv)\n\t\t}\n\t\tfor _, s := range last_cursor_after.Body {\n\t\t\tf.process_stmt(s)\n\t\t}\n\t}\n}\n\nfunc (f *auto_complete_file) process_switch_stmt(a *ast.SwitchStmt) {\n\tif !f.cursor_in(a.Body) {\n\t\treturn\n\t}\n\tf.scope, _ = advance_scope(f.scope)\n\n\tf.process_stmt(a.Init)\n\tvar last_cursor_after *ast.CaseClause\n\tfor _, s := range a.Body.List {\n\t\tif cc := s.(*ast.CaseClause); f.cursor > f.offset(cc.Colon) {\n\t\t\tlast_cursor_after = cc\n\t\t}\n\t}\n\tif last_cursor_after != nil {\n\t\tfor _, s := range last_cursor_after.Body {\n\t\t\tf.process_stmt(s)\n\t\t}\n\t}\n}\n\nfunc (f *auto_complete_file) process_range_stmt(a *ast.RangeStmt) {\n\tif !f.cursor_in(a.Body) {\n\t\treturn\n\t}\n\tvar prevscope *scope\n\tf.scope, prevscope = advance_scope(f.scope)\n\n\tif a.Tok == token.DEFINE {\n\t\tif t, ok := a.Key.(*ast.Ident); ok {\n\t\t\td := new_decl_var(t.Name, nil, a.X, 0, prevscope)\n\t\t\tif d != nil {\n\t\t\t\td.flags |= decl_rangevar\n\t\t\t\tf.scope.add_named_decl(d)\n\t\t\t}\n\t\t}\n\n\t\tif a.Value != nil {\n\t\t\tif t, ok := a.Value.(*ast.Ident); ok {\n\t\t\t\td := new_decl_var(t.Name, nil, a.X, 1, prevscope)\n\t\t\t\tif d != nil {\n\t\t\t\t\td.flags |= decl_rangevar\n\t\t\t\t\tf.scope.add_named_decl(d)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tf.process_block_stmt(a.Body)\n}\n\nfunc (f *auto_complete_file) process_assign_stmt(a *ast.AssignStmt) {\n\tif a.Tok != token.DEFINE || f.offset(a.TokPos) > f.cursor {\n\t\treturn\n\t}\n\n\tnames := make([]*ast.Ident, len(a.Lhs))\n\tfor i, name := range a.Lhs {\n\t\tid, ok := name.(*ast.Ident)\n\t\tif !ok {\n\t\t\t// something is wrong, just ignore the whole stmt\n\t\t\treturn\n\t\t}\n\t\tnames[i] = id\n\t}\n\n\tvar prevscope *scope\n\tf.scope, prevscope = advance_scope(f.scope)\n\n\tpack := decl_pack{names, nil, a.Rhs}\n\tfor i, name := range pack.names {\n\t\ttyp, v, vi := pack.type_value_index(i)\n\t\td := new_decl_var(name.Name, typ, v, vi, prevscope)\n\t\tif d == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tf.scope.add_named_decl(d)\n\t}\n}\n\nfunc (f *auto_complete_file) process_field_list(field_list *ast.FieldList, s *scope) {\n\tif field_list != nil {\n\t\tdecls := ast_field_list_to_decls(field_list, decl_var, 0, s, false)\n\t\tfor _, d := range decls {\n\t\t\tf.scope.add_named_decl(d)\n\t\t}\n\t}\n}\n\nfunc (f *auto_complete_file) cursor_in_if_head(s *ast.IfStmt) bool {\n\tif f.cursor > f.offset(s.If) && f.cursor <= f.offset(s.Body.Lbrace) {\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (f *auto_complete_file) cursor_in_if_stmt(s *ast.IfStmt) bool {\n\tif f.cursor > f.offset(s.If) {\n\t\t// magic -10 comes from auto_complete_file.offset method, see\n\t\t// len() expr in there\n\t\tif f.offset(s.End()) == -10 || f.cursor < f.offset(s.End()) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (f *auto_complete_file) cursor_in_for_head(s *ast.ForStmt) bool {\n\tif f.cursor > f.offset(s.For) && f.cursor <= f.offset(s.Body.Lbrace) {\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (f *auto_complete_file) cursor_in(block *ast.BlockStmt) bool {\n\tif f.cursor == -1 || block == nil {\n\t\treturn false\n\t}\n\n\tif f.cursor > f.offset(block.Lbrace) && f.cursor <= f.offset(block.Rbrace) {\n\t\treturn true\n\t}\n\treturn false\n}\n"
        },
        {
          "name": "client.go",
          "type": "blob",
          "size": 3.5966796875,
          "content": "package main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"go/build\"\n\t\"io/ioutil\"\n\t\"net/rpc\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"time\"\n)\n\nfunc do_client() int {\n\taddr := *g_addr\n\tif *g_sock == \"unix\" {\n\t\taddr = get_socket_filename()\n\t}\n\n\t// client\n\tclient, err := rpc.Dial(*g_sock, addr)\n\tif err != nil {\n\t\tif *g_sock == \"unix\" && file_exists(addr) {\n\t\t\tos.Remove(addr)\n\t\t}\n\n\t\terr = try_run_server()\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"%s\\n\", err.Error())\n\t\t\treturn 1\n\t\t}\n\t\tclient, err = try_to_connect(*g_sock, addr)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"%s\\n\", err.Error())\n\t\t\treturn 1\n\t\t}\n\t}\n\tdefer client.Close()\n\n\tif flag.NArg() > 0 {\n\t\tswitch flag.Arg(0) {\n\t\tcase \"autocomplete\":\n\t\t\tcmd_auto_complete(client)\n\t\tcase \"close\":\n\t\t\tcmd_close(client)\n\t\tcase \"status\":\n\t\t\tcmd_status(client)\n\t\tcase \"drop-cache\":\n\t\t\tcmd_drop_cache(client)\n\t\tcase \"set\":\n\t\t\tcmd_set(client)\n\t\tcase \"options\":\n\t\t\tcmd_options(client)\n\t\tdefault:\n\t\t\tfmt.Printf(\"unknown argument: %q, try running \\\"gocode -h\\\"\\n\", flag.Arg(0))\n\t\t\treturn 1\n\t\t}\n\t}\n\treturn 0\n}\n\nfunc try_run_server() error {\n\tpath := get_executable_filename()\n\targs := []string{os.Args[0], \"-s\", \"-sock\", *g_sock, \"-addr\", *g_addr}\n\tcwd, _ := os.Getwd()\n\n\tvar err error\n\tstdin, err := os.Open(os.DevNull)\n\tif err != nil {\n\t\treturn err\n\t}\n\tstdout, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0)\n\tif err != nil {\n\t\treturn err\n\t}\n\tstderr, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprocattr := os.ProcAttr{Dir: cwd, Env: os.Environ(), Files: []*os.File{stdin, stdout, stderr}}\n\tp, err := os.StartProcess(path, args, &procattr)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn p.Release()\n}\n\nfunc try_to_connect(network, address string) (client *rpc.Client, err error) {\n\tt := 0\n\tfor {\n\t\tclient, err = rpc.Dial(network, address)\n\t\tif err != nil && t < 1000 {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tt += 10\n\t\t\tcontinue\n\t\t}\n\t\tbreak\n\t}\n\n\treturn\n}\n\nfunc prepare_file_filename_cursor() ([]byte, string, int) {\n\tvar file []byte\n\tvar err error\n\n\tif *g_input != \"\" {\n\t\tfile, err = ioutil.ReadFile(*g_input)\n\t} else {\n\t\tfile, err = ioutil.ReadAll(os.Stdin)\n\t}\n\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n\tvar skipped int\n\tfile, skipped = filter_out_shebang(file)\n\n\tfilename := *g_input\n\tcursor := -1\n\n\toffset := \"\"\n\tswitch flag.NArg() {\n\tcase 2:\n\t\toffset = flag.Arg(1)\n\tcase 3:\n\t\tfilename = flag.Arg(1) // Override default filename\n\t\toffset = flag.Arg(2)\n\t}\n\n\tif offset != \"\" {\n\t\tif offset[0] == 'c' || offset[0] == 'C' {\n\t\t\tcursor, _ = strconv.Atoi(offset[1:])\n\t\t\tcursor = char_to_byte_offset(file, cursor)\n\t\t} else {\n\t\t\tcursor, _ = strconv.Atoi(offset)\n\t\t}\n\t}\n\n\tcursor -= skipped\n\tif filename != \"\" && !filepath.IsAbs(filename) {\n\t\tcwd, _ := os.Getwd()\n\t\tfilename = filepath.Join(cwd, filename)\n\t}\n\treturn file, filename, cursor\n}\n\n//-------------------------------------------------------------------------\n// commands\n//-------------------------------------------------------------------------\n\nfunc cmd_status(c *rpc.Client) {\n\tfmt.Printf(\"%s\\n\", client_status(c, 0))\n}\n\nfunc cmd_auto_complete(c *rpc.Client) {\n\tcontext := pack_build_context(&build.Default)\n\tfile, filename, cursor := prepare_file_filename_cursor()\n\tf := get_formatter(*g_format)\n\tf.write_candidates(client_auto_complete(c, file, filename, cursor, context))\n}\n\nfunc cmd_close(c *rpc.Client) {\n\tclient_close(c, 0)\n}\n\nfunc cmd_drop_cache(c *rpc.Client) {\n\tclient_drop_cache(c, 0)\n}\n\nfunc cmd_set(c *rpc.Client) {\n\tswitch flag.NArg() {\n\tcase 1:\n\t\tfmt.Print(client_set(c, \"\\x00\", \"\\x00\"))\n\tcase 2:\n\t\tfmt.Print(client_set(c, flag.Arg(1), \"\\x00\"))\n\tcase 3:\n\t\tfmt.Print(client_set(c, flag.Arg(1), flag.Arg(2)))\n\t}\n}\n\nfunc cmd_options(c *rpc.Client) {\n\tfmt.Print(client_options(c, 0))\n}\n"
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 7.6240234375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"strconv\"\n)\n\n//-------------------------------------------------------------------------\n// config\n//\n// Structure represents persistent config storage of the gocode daemon. Usually\n// the config is located somewhere in ~/.config/gocode directory.\n//-------------------------------------------------------------------------\n\ntype config struct {\n\tProposeBuiltins    bool   `json:\"propose-builtins\"`\n\tLibPath            string `json:\"lib-path\"`\n\tCustomPkgPrefix    string `json:\"custom-pkg-prefix\"`\n\tCustomVendorDir    string `json:\"custom-vendor-dir\"`\n\tAutobuild          bool   `json:\"autobuild\"`\n\tForceDebugOutput   string `json:\"force-debug-output\"`\n\tPackageLookupMode  string `json:\"package-lookup-mode\"`\n\tCloseTimeout       int    `json:\"close-timeout\"`\n\tUnimportedPackages bool   `json:\"unimported-packages\"`\n\tPartials           bool   `json:\"partials\"`\n\tIgnoreCase         bool   `json:\"ignore-case\"`\n\tClassFiltering     bool   `json:\"class-filtering\"`\n}\n\nvar g_config_desc = map[string]string{\n\t\"propose-builtins\":    \"If set to {true}, gocode will add built-in types, functions and constants to autocompletion proposals.\",\n\t\"lib-path\":            \"A string option. Allows you to add search paths for packages. By default, gocode only searches {$GOPATH/pkg/$GOOS_$GOARCH} and {$GOROOT/pkg/$GOOS_$GOARCH} in terms of previously existed environment variables. Also you can specify multiple paths using ':' (colon) as a separator (on Windows use semicolon ';'). The paths specified by {lib-path} are prepended to the default ones.\",\n\t\"custom-pkg-prefix\":   \"\",\n\t\"custom-vendor-dir\":   \"\",\n\t\"autobuild\":           \"If set to {true}, gocode will try to automatically build out-of-date packages when their source files are modified, in order to obtain the freshest autocomplete results for them. This feature is experimental.\",\n\t\"force-debug-output\":  \"If is not empty, gocode will forcefully redirect the logging into that file. Also forces enabling of the debug mode on the server side.\",\n\t\"package-lookup-mode\": \"If set to {go}, use standard Go package lookup rules. If set to {gb}, use gb-specific lookup rules. See {https://github.com/constabulary/gb} for details.\",\n\t\"close-timeout\":       \"If there have been no completion requests after this number of seconds, the gocode process will terminate. Default is 30 minutes.\",\n\t\"unimported-packages\": \"If set to {true}, gocode will try to import certain known packages automatically for identifiers which cannot be resolved otherwise. Currently only a limited set of standard library packages is supported.\",\n\t\"partials\":            \"If set to {false}, gocode will not filter autocompletion results based on entered prefix before the cursor. Instead it will return all available autocompletion results viable for a given context. Whether this option is set to {true} or {false}, gocode will return a valid prefix length for output formats which support it. Setting this option to a non-default value may result in editor misbehaviour.\",\n\t\"ignore-case\":         \"If set to {true}, gocode will perform case-insensitive matching when doing prefix-based filtering.\",\n\t\"class-filtering\":     \"Enables or disables gocode's feature where it performs class-based filtering if partial input matches corresponding class keyword: const, var, type, func, package.\",\n}\n\nvar g_default_config = config{\n\tProposeBuiltins:    false,\n\tLibPath:            \"\",\n\tCustomPkgPrefix:    \"\",\n\tAutobuild:          false,\n\tForceDebugOutput:   \"\",\n\tPackageLookupMode:  \"go\",\n\tCloseTimeout:       1800,\n\tUnimportedPackages: false,\n\tPartials:           true,\n\tIgnoreCase:         false,\n\tClassFiltering:     true,\n}\nvar g_config = g_default_config\n\nvar g_string_to_bool = map[string]bool{\n\t\"t\":     true,\n\t\"true\":  true,\n\t\"y\":     true,\n\t\"yes\":   true,\n\t\"on\":    true,\n\t\"1\":     true,\n\t\"f\":     false,\n\t\"false\": false,\n\t\"n\":     false,\n\t\"no\":    false,\n\t\"off\":   false,\n\t\"0\":     false,\n}\n\nfunc set_value(v reflect.Value, value string) {\n\tswitch t := v; t.Kind() {\n\tcase reflect.Bool:\n\t\tv, ok := g_string_to_bool[value]\n\t\tif ok {\n\t\t\tt.SetBool(v)\n\t\t}\n\tcase reflect.String:\n\t\tt.SetString(value)\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\tv, err := strconv.ParseInt(value, 10, 64)\n\t\tif err == nil {\n\t\t\tt.SetInt(v)\n\t\t}\n\tcase reflect.Float32, reflect.Float64:\n\t\tv, err := strconv.ParseFloat(value, 64)\n\t\tif err == nil {\n\t\t\tt.SetFloat(v)\n\t\t}\n\t}\n}\n\nfunc list_value(v reflect.Value, name string, w io.Writer) {\n\tswitch t := v; t.Kind() {\n\tcase reflect.Bool:\n\t\tfmt.Fprintf(w, \"%s %v\\n\", name, t.Bool())\n\tcase reflect.String:\n\t\tfmt.Fprintf(w, \"%s \\\"%v\\\"\\n\", name, t.String())\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\tfmt.Fprintf(w, \"%s %v\\n\", name, t.Int())\n\tcase reflect.Float32, reflect.Float64:\n\t\tfmt.Fprintf(w, \"%s %v\\n\", name, t.Float())\n\t}\n}\n\nfunc (this *config) list() string {\n\tstr, typ := this.value_and_type()\n\tbuf := bytes.NewBuffer(make([]byte, 0, 256))\n\tfor i := 0; i < str.NumField(); i++ {\n\t\tv := str.Field(i)\n\t\tname := typ.Field(i).Tag.Get(\"json\")\n\t\tlist_value(v, name, buf)\n\t}\n\treturn buf.String()\n}\n\nfunc (this *config) list_option(name string) string {\n\tstr, typ := this.value_and_type()\n\tbuf := bytes.NewBuffer(make([]byte, 0, 256))\n\tfor i := 0; i < str.NumField(); i++ {\n\t\tv := str.Field(i)\n\t\tnm := typ.Field(i).Tag.Get(\"json\")\n\t\tif nm == name {\n\t\t\tlist_value(v, name, buf)\n\t\t}\n\t}\n\treturn buf.String()\n}\n\nfunc (this *config) set_option(name, value string) string {\n\tstr, typ := this.value_and_type()\n\tbuf := bytes.NewBuffer(make([]byte, 0, 256))\n\tfor i := 0; i < str.NumField(); i++ {\n\t\tv := str.Field(i)\n\t\tnm := typ.Field(i).Tag.Get(\"json\")\n\t\tif nm == name {\n\t\t\tset_value(v, value)\n\t\t\tlist_value(v, name, buf)\n\t\t}\n\t}\n\tthis.write()\n\treturn buf.String()\n\n}\n\nfunc (this *config) value_and_type() (reflect.Value, reflect.Type) {\n\tv := reflect.ValueOf(this).Elem()\n\treturn v, v.Type()\n}\n\nfunc (this *config) write() error {\n\tdata, err := json.Marshal(this)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// make sure config dir exists\n\tdir := config_dir()\n\tif !file_exists(dir) {\n\t\tos.MkdirAll(dir, 0755)\n\t}\n\n\tf, err := os.Create(config_file())\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer f.Close()\n\n\t_, err = f.Write(data)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc (this *config) read() error {\n\tdata, err := ioutil.ReadFile(config_file())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = json.Unmarshal(data, this)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc quoted(v interface{}) string {\n\tswitch v.(type) {\n\tcase string:\n\t\treturn fmt.Sprintf(\"%q\", v)\n\tcase int:\n\t\treturn fmt.Sprint(v)\n\tcase bool:\n\t\treturn fmt.Sprint(v)\n\tdefault:\n\t\tpanic(\"unreachable\")\n\t}\n}\n\nvar descRE = regexp.MustCompile(`{[^}]+}`)\n\nfunc preprocess_desc(v string) string {\n\treturn descRE.ReplaceAllStringFunc(v, func(v string) string {\n\t\treturn color_cyan + v[1:len(v)-1] + color_none\n\t})\n}\n\nfunc (this *config) options() string {\n\tvar buf bytes.Buffer\n\tfmt.Fprintf(&buf, \"%sConfig file location%s: %s\\n\", color_white_bold, color_none, config_file())\n\tdv := reflect.ValueOf(g_default_config)\n\tv, t := this.value_and_type()\n\tfor i, n := 0, t.NumField(); i < n; i++ {\n\t\tf := t.Field(i)\n\t\tindex := f.Index\n\t\ttag := f.Tag.Get(\"json\")\n\t\tfmt.Fprintf(&buf, \"\\n%s%s%s\\n\", color_yellow_bold, tag, color_none)\n\t\tfmt.Fprintf(&buf, \"%stype%s: %s\\n\", color_yellow, color_none, f.Type)\n\t\tfmt.Fprintf(&buf, \"%svalue%s: %s\\n\", color_yellow, color_none, quoted(v.FieldByIndex(index).Interface()))\n\t\tfmt.Fprintf(&buf, \"%sdefault%s: %s\\n\", color_yellow, color_none, quoted(dv.FieldByIndex(index).Interface()))\n\t\tfmt.Fprintf(&buf, \"%sdescription%s: %s\\n\", color_yellow, color_none, preprocess_desc(g_config_desc[tag]))\n\t}\n\n\treturn buf.String()\n}\n"
        },
        {
          "name": "cursorcontext.go",
          "type": "blob",
          "size": 16.5263671875,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"go/ast\"\n\t\"go/parser\"\n\t\"go/scanner\"\n\t\"go/token\"\n\t\"log\"\n)\n\ntype cursor_context struct {\n\tdecl         *decl\n\tpartial      string\n\tstruct_field bool\n\tdecl_import  bool\n\n\t// store expression that was supposed to be deduced to \"decl\", however\n\t// if decl is nil, then deduction failed, we could try to resolve it to\n\t// unimported package instead\n\texpr ast.Expr\n}\n\ntype token_iterator struct {\n\ttokens      []token_item\n\ttoken_index int\n}\n\ntype token_item struct {\n\toff int\n\ttok token.Token\n\tlit string\n}\n\nfunc (i token_item) literal() string {\n\tif i.tok.IsLiteral() {\n\t\treturn i.lit\n\t}\n\treturn i.tok.String()\n}\n\nfunc new_token_iterator(src []byte, cursor int) token_iterator {\n\ttokens := make([]token_item, 0, 1000)\n\tvar s scanner.Scanner\n\tfset := token.NewFileSet()\n\tfile := fset.AddFile(\"\", fset.Base(), len(src))\n\ts.Init(file, src, nil, 0)\n\tfor {\n\t\tpos, tok, lit := s.Scan()\n\t\toff := fset.Position(pos).Offset\n\t\tif tok == token.EOF || cursor <= off {\n\t\t\tbreak\n\t\t}\n\t\ttokens = append(tokens, token_item{\n\t\t\toff: off,\n\t\t\ttok: tok,\n\t\t\tlit: lit,\n\t\t})\n\t}\n\treturn token_iterator{\n\t\ttokens:      tokens,\n\t\ttoken_index: len(tokens) - 1,\n\t}\n}\n\nfunc (this *token_iterator) token() token_item {\n\treturn this.tokens[this.token_index]\n}\n\nfunc (this *token_iterator) go_back() bool {\n\tif this.token_index <= 0 {\n\t\treturn false\n\t}\n\tthis.token_index--\n\treturn true\n}\n\nvar bracket_pairs_map = map[token.Token]token.Token{\n\ttoken.RPAREN: token.LPAREN,\n\ttoken.RBRACK: token.LBRACK,\n\ttoken.RBRACE: token.LBRACE,\n}\n\nfunc (ti *token_iterator) skip_to_left(left, right token.Token) bool {\n\tif ti.token().tok == left {\n\t\treturn true\n\t}\n\tbalance := 1\n\tfor balance != 0 {\n\t\tif !ti.go_back() {\n\t\t\treturn false\n\t\t}\n\t\tswitch ti.token().tok {\n\t\tcase right:\n\t\t\tbalance++\n\t\tcase left:\n\t\t\tbalance--\n\t\t}\n\t}\n\treturn true\n}\n\n// when the cursor is at the ')' or ']' or '}', move the cursor to an opposite\n// bracket pair, this functions takes nested bracket pairs into account\nfunc (this *token_iterator) skip_to_balanced_pair() bool {\n\tright := this.token().tok\n\tleft := bracket_pairs_map[right]\n\treturn this.skip_to_left(left, right)\n}\n\n// Move the cursor to the open brace of the current block, taking nested blocks\n// into account.\nfunc (this *token_iterator) skip_to_left_curly() bool {\n\treturn this.skip_to_left(token.LBRACE, token.RBRACE)\n}\n\nfunc (ti *token_iterator) extract_type_alike() string {\n\tif ti.token().tok != token.IDENT { // not Foo, return nothing\n\t\treturn \"\"\n\t}\n\tb := ti.token().literal()\n\tif !ti.go_back() { // just Foo\n\t\treturn b\n\t}\n\tif ti.token().tok != token.PERIOD { // not .Foo, return Foo\n\t\treturn b\n\t}\n\tif !ti.go_back() { // just .Foo, return Foo (best choice recovery)\n\t\treturn b\n\t}\n\tif ti.token().tok != token.IDENT { // not lib.Foo, return Foo\n\t\treturn b\n\t}\n\tout := ti.token().literal() + \".\" + b // lib.Foo\n\tti.go_back()\n\treturn out\n}\n\n// Extract the type expression right before the enclosing curly bracket block.\n// Examples (# - the cursor):\n//   &lib.Struct{Whatever: 1, Hel#} // returns \"lib.Struct\"\n//   X{#}                           // returns X\n// The idea is that we check if this type expression is a type and it is, we\n// can apply special filtering for autocompletion results.\n// Sadly, this doesn't cover anonymous structs.\nfunc (ti *token_iterator) extract_struct_type() string {\n\tif !ti.skip_to_left_curly() {\n\t\treturn \"\"\n\t}\n\tif !ti.go_back() {\n\t\treturn \"\"\n\t}\n\tif ti.token().tok == token.LBRACE { // Foo{#{}}\n\t\tif !ti.go_back() {\n\t\t\treturn \"\"\n\t\t}\n\t} else if ti.token().tok == token.COMMA { // Foo{abc,#{}}\n\t\treturn ti.extract_struct_type()\n\t}\n\ttyp := ti.extract_type_alike()\n\tif typ == \"\" {\n\t\treturn \"\"\n\t}\n\tif ti.token().tok == token.RPAREN || ti.token().tok == token.MUL {\n\t\treturn \"\"\n\t}\n\treturn typ\n}\n\n// Starting from the token under the cursor move back and extract something\n// that resembles a valid Go primary expression. Examples of primary expressions\n// from Go spec:\n//   x\n//   2\n//   (s + \".txt\")\n//   f(3.1415, true)\n//   Point{1, 2}\n//   m[\"foo\"]\n//   s[i : j + 1]\n//   obj.color\n//   f.p[i].x()\n//\n// As you can see we can move through all of them using balanced bracket\n// matching and applying simple rules\n// E.g.\n//   Point{1, 2}.m[\"foo\"].s[i : j + 1].MethodCall(a, func(a, b int) int { return a + b }).\n// Can be seen as:\n//   Point{    }.m[     ].s[         ].MethodCall(                                      ).\n// Which boils the rules down to these connected via dots:\n//   ident\n//   ident[]\n//   ident{}\n//   ident()\n// Of course there are also slightly more complicated rules for brackets:\n//   ident{}.ident()[5][4](), etc.\nfunc (this *token_iterator) extract_go_expr() string {\n\torig := this.token_index\n\n\t// Contains the type of the previously scanned token (initialized with\n\t// the token right under the cursor). This is the token to the *right* of\n\t// the current one.\n\tprev := this.token().tok\nloop:\n\tfor {\n\t\tif !this.go_back() {\n\t\t\treturn token_items_to_string(this.tokens[:orig])\n\t\t}\n\t\tswitch this.token().tok {\n\t\tcase token.PERIOD:\n\t\t\t// If the '.' is not followed by IDENT, it's invalid.\n\t\t\tif prev != token.IDENT {\n\t\t\t\tbreak loop\n\t\t\t}\n\t\tcase token.IDENT:\n\t\t\t// Valid tokens after IDENT are '.', '[', '{' and '('.\n\t\t\tswitch prev {\n\t\t\tcase token.PERIOD, token.LBRACK, token.LBRACE, token.LPAREN:\n\t\t\t\t// all ok\n\t\t\tdefault:\n\t\t\t\tbreak loop\n\t\t\t}\n\t\tcase token.RBRACE:\n\t\t\t// This one can only be a part of type initialization, like:\n\t\t\t//   Dummy{}.Hello()\n\t\t\t// It is valid Go if Hello method is defined on a non-pointer receiver.\n\t\t\tif prev != token.PERIOD {\n\t\t\t\tbreak loop\n\t\t\t}\n\t\t\tthis.skip_to_balanced_pair()\n\t\tcase token.RPAREN, token.RBRACK:\n\t\t\t// After ']' and ')' their opening counterparts are valid '[', '(',\n\t\t\t// as well as the dot.\n\t\t\tswitch prev {\n\t\t\tcase token.PERIOD, token.LBRACK, token.LPAREN:\n\t\t\t\t// all ok\n\t\t\tdefault:\n\t\t\t\tbreak loop\n\t\t\t}\n\t\t\tthis.skip_to_balanced_pair()\n\t\tdefault:\n\t\t\tbreak loop\n\t\t}\n\t\tprev = this.token().tok\n\t}\n\texpr := token_items_to_string(this.tokens[this.token_index+1 : orig])\n\tif *g_debug {\n\t\tlog.Printf(\"extracted expression tokens: %s\", expr)\n\t}\n\treturn expr\n}\n\n// Given a slice of token_item, reassembles them into the original literal\n// expression.\nfunc token_items_to_string(tokens []token_item) string {\n\tvar buf bytes.Buffer\n\tfor _, t := range tokens {\n\t\tbuf.WriteString(t.literal())\n\t}\n\treturn buf.String()\n}\n\n// this function is called when the cursor is at the '.' and you need to get the\n// declaration before that dot\nfunc (c *auto_complete_context) deduce_cursor_decl(iter *token_iterator) (*decl, ast.Expr) {\n\texpr, err := parser.ParseExpr(iter.extract_go_expr())\n\tif err != nil {\n\t\treturn nil, nil\n\t}\n\treturn expr_to_decl(expr, c.current.scope), expr\n}\n\n// try to find and extract the surrounding struct literal type\nfunc (c *auto_complete_context) deduce_struct_type_decl(iter *token_iterator) *decl {\n\ttyp := iter.extract_struct_type()\n\tif typ == \"\" {\n\t\treturn nil\n\t}\n\n\texpr, err := parser.ParseExpr(typ)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tdecl := type_to_decl(expr, c.current.scope)\n\tif decl == nil {\n\t\treturn nil\n\t}\n\n\t// we allow only struct types here, but also support type aliases\n\tif decl.is_alias() {\n\t\tdd := decl.type_dealias()\n\t\tif _, ok := dd.typ.(*ast.StructType); !ok {\n\t\t\treturn nil\n\t\t}\n\t} else if _, ok := decl.typ.(*ast.StructType); !ok {\n\t\treturn nil\n\t}\n\treturn decl\n}\n\n// Entry point from autocompletion, the function looks at text before the cursor\n// and figures out the declaration the cursor is on. This declaration is\n// used in filtering the resulting set of autocompletion suggestions.\nfunc (c *auto_complete_context) deduce_cursor_context(file []byte, cursor int) (cursor_context, bool) {\n\tif cursor <= 0 {\n\t\treturn cursor_context{}, true\n\t}\n\n\titer := new_token_iterator(file, cursor)\n\tif len(iter.tokens) == 0 {\n\t\treturn cursor_context{}, false\n\t}\n\n\t// figure out what is just before the cursor\n\tswitch tok := iter.token(); tok.tok {\n\tcase token.STRING:\n\t\t// make sure cursor is inside the string\n\t\ts := tok.literal()\n\t\tif len(s) > 1 && s[len(s)-1] == '\"' && tok.off+len(s) <= cursor {\n\t\t\treturn cursor_context{}, true\n\t\t}\n\t\t// now figure out if inside an import declaration\n\t\tvar ptok = token.STRING\n\t\tfor iter.go_back() {\n\t\t\titok := iter.token().tok\n\t\t\tswitch itok {\n\t\t\tcase token.STRING:\n\t\t\t\tswitch ptok {\n\t\t\t\tcase token.SEMICOLON, token.IDENT, token.PERIOD:\n\t\t\t\tdefault:\n\t\t\t\t\treturn cursor_context{}, true\n\t\t\t\t}\n\t\t\tcase token.LPAREN, token.SEMICOLON:\n\t\t\t\tswitch ptok {\n\t\t\t\tcase token.STRING, token.IDENT, token.PERIOD:\n\t\t\t\tdefault:\n\t\t\t\t\treturn cursor_context{}, true\n\t\t\t\t}\n\t\t\tcase token.IDENT, token.PERIOD:\n\t\t\t\tswitch ptok {\n\t\t\t\tcase token.STRING:\n\t\t\t\tdefault:\n\t\t\t\t\treturn cursor_context{}, true\n\t\t\t\t}\n\t\t\tcase token.IMPORT:\n\t\t\t\tswitch ptok {\n\t\t\t\tcase token.STRING, token.IDENT, token.PERIOD, token.LPAREN:\n\t\t\t\t\tpath_len := cursor - tok.off\n\t\t\t\t\tpath := s[1:path_len]\n\t\t\t\t\treturn cursor_context{decl_import: true, partial: path}, true\n\t\t\t\tdefault:\n\t\t\t\t\treturn cursor_context{}, true\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn cursor_context{}, true\n\t\t\t}\n\t\t\tptok = itok\n\t\t}\n\tcase token.PERIOD:\n\t\t// we're '<whatever>.'\n\t\t// figure out decl, Partial is \"\"\n\t\tdecl, expr := c.deduce_cursor_decl(&iter)\n\t\treturn cursor_context{decl: decl, expr: expr}, decl != nil\n\tcase token.IDENT, token.TYPE, token.CONST, token.VAR, token.FUNC, token.PACKAGE:\n\t\t// we're '<whatever>.<ident>'\n\t\t// parse <ident> as Partial and figure out decl\n\t\tvar partial string\n\t\tif tok.tok == token.IDENT {\n\t\t\t// Calculate the offset of the cursor position within the identifier.\n\t\t\t// For instance, if we are 'ab#c', we want partial_len = 2 and partial = ab.\n\t\t\tpartial_len := cursor - tok.off\n\n\t\t\t// If it happens that the cursor is past the end of the literal,\n\t\t\t// means there is a space between the literal and the cursor, think\n\t\t\t// of it as no context, because that's what it really is.\n\t\t\tif partial_len > len(tok.literal()) {\n\t\t\t\treturn cursor_context{}, true\n\t\t\t}\n\t\t\tpartial = tok.literal()[0:partial_len]\n\t\t} else {\n\t\t\t// Do not try to truncate if it is not an identifier.\n\t\t\tpartial = tok.literal()\n\t\t}\n\n\t\titer.go_back()\n\t\tswitch iter.token().tok {\n\t\tcase token.PERIOD:\n\t\t\tdecl, expr := c.deduce_cursor_decl(&iter)\n\t\t\treturn cursor_context{decl: decl, partial: partial, expr: expr}, decl != nil\n\t\tcase token.COMMA, token.LBRACE:\n\t\t\t// This can happen for struct fields:\n\t\t\t// &Struct{Hello: 1, Wor#} // (# - the cursor)\n\t\t\t// Let's try to find the struct type\n\t\t\tdecl := c.deduce_struct_type_decl(&iter)\n\t\t\treturn cursor_context{\n\t\t\t\tdecl:         decl,\n\t\t\t\tpartial:      partial,\n\t\t\t\tstruct_field: decl != nil,\n\t\t\t}, true\n\t\tdefault:\n\t\t\treturn cursor_context{partial: partial}, true\n\t\t}\n\tcase token.COMMA, token.LBRACE:\n\t\t// Try to parse the current expression as a structure initialization.\n\t\tdecl := c.deduce_struct_type_decl(&iter)\n\t\treturn cursor_context{\n\t\t\tdecl:         decl,\n\t\t\tpartial:      \"\",\n\t\t\tstruct_field: decl != nil,\n\t\t}, true\n\t}\n\n\treturn cursor_context{}, true\n}\n\n// Decl deduction failed, but we're on \"<ident>.\", this ident can be an\n// unexported package, let's try to match the ident against a set of known\n// packages and if it matches try to import it.\n// TODO: Right now I've made a static list of built-in packages, but in theory\n// we could scan all GOPATH packages as well. Now, don't forget that default\n// package name has nothing to do with package file name, that's why we need to\n// scan the packages. And many of them will have conflicts. Can we make a smart\n// prediction algorithm which will prefer certain packages over another ones?\nfunc resolveKnownPackageIdent(ident string, filename string, context *package_lookup_context) *package_file_cache {\n\timportPath, ok := knownPackageIdents[ident]\n\tif !ok {\n\t\treturn nil\n\t}\n\n\tpath, ok := abs_path_for_package(filename, importPath, context)\n\tif !ok {\n\t\treturn nil\n\t}\n\n\tp := new_package_file_cache(path, importPath)\n\tp.update_cache()\n\treturn p\n}\n\nvar knownPackageIdents = map[string]string{\n\t\"adler32\":         \"hash/adler32\",\n\t\"aes\":             \"crypto/aes\",\n\t\"ascii85\":         \"encoding/ascii85\",\n\t\"asn1\":            \"encoding/asn1\",\n\t\"ast\":             \"go/ast\",\n\t\"atomic\":          \"sync/atomic\",\n\t\"base32\":          \"encoding/base32\",\n\t\"base64\":          \"encoding/base64\",\n\t\"big\":             \"math/big\",\n\t\"binary\":          \"encoding/binary\",\n\t\"bufio\":           \"bufio\",\n\t\"build\":           \"go/build\",\n\t\"bytes\":           \"bytes\",\n\t\"bzip2\":           \"compress/bzip2\",\n\t\"cgi\":             \"net/http/cgi\",\n\t\"cgo\":             \"runtime/cgo\",\n\t\"cipher\":          \"crypto/cipher\",\n\t\"cmplx\":           \"math/cmplx\",\n\t\"color\":           \"image/color\",\n\t\"constant\":        \"go/constant\",\n\t\"context\":         \"context\",\n\t\"cookiejar\":       \"net/http/cookiejar\",\n\t\"crc32\":           \"hash/crc32\",\n\t\"crc64\":           \"hash/crc64\",\n\t\"crypto\":          \"crypto\",\n\t\"csv\":             \"encoding/csv\",\n\t\"debug\":           \"runtime/debug\",\n\t\"des\":             \"crypto/des\",\n\t\"doc\":             \"go/doc\",\n\t\"draw\":            \"image/draw\",\n\t\"driver\":          \"database/sql/driver\",\n\t\"dsa\":             \"crypto/dsa\",\n\t\"dwarf\":           \"debug/dwarf\",\n\t\"ecdsa\":           \"crypto/ecdsa\",\n\t\"elf\":             \"debug/elf\",\n\t\"elliptic\":        \"crypto/elliptic\",\n\t\"encoding\":        \"encoding\",\n\t\"errors\":          \"errors\",\n\t\"exec\":            \"os/exec\",\n\t\"expvar\":          \"expvar\",\n\t\"fcgi\":            \"net/http/fcgi\",\n\t\"filepath\":        \"path/filepath\",\n\t\"flag\":            \"flag\",\n\t\"flate\":           \"compress/flate\",\n\t\"fmt\":             \"fmt\",\n\t\"fnv\":             \"hash/fnv\",\n\t\"format\":          \"go/format\",\n\t\"gif\":             \"image/gif\",\n\t\"gob\":             \"encoding/gob\",\n\t\"gosym\":           \"debug/gosym\",\n\t\"gzip\":            \"compress/gzip\",\n\t\"hash\":            \"hash\",\n\t\"heap\":            \"container/heap\",\n\t\"hex\":             \"encoding/hex\",\n\t\"hmac\":            \"crypto/hmac\",\n\t\"hpack\":           \"vendor/golang_org/x/net/http2/hpack\",\n\t\"html\":            \"html\",\n\t\"http\":            \"net/http\",\n\t\"httplex\":         \"vendor/golang_org/x/net/lex/httplex\",\n\t\"httptest\":        \"net/http/httptest\",\n\t\"httptrace\":       \"net/http/httptrace\",\n\t\"httputil\":        \"net/http/httputil\",\n\t\"image\":           \"image\",\n\t\"importer\":        \"go/importer\",\n\t\"io\":              \"io\",\n\t\"iotest\":          \"testing/iotest\",\n\t\"ioutil\":          \"io/ioutil\",\n\t\"jpeg\":            \"image/jpeg\",\n\t\"json\":            \"encoding/json\",\n\t\"jsonrpc\":         \"net/rpc/jsonrpc\",\n\t\"list\":            \"container/list\",\n\t\"log\":             \"log\",\n\t\"lzw\":             \"compress/lzw\",\n\t\"macho\":           \"debug/macho\",\n\t\"mail\":            \"net/mail\",\n\t\"math\":            \"math\",\n\t\"md5\":             \"crypto/md5\",\n\t\"mime\":            \"mime\",\n\t\"multipart\":       \"mime/multipart\",\n\t\"net\":             \"net\",\n\t\"os\":              \"os\",\n\t\"palette\":         \"image/color/palette\",\n\t\"parse\":           \"text/template/parse\",\n\t\"parser\":          \"go/parser\",\n\t\"path\":            \"path\",\n\t\"pe\":              \"debug/pe\",\n\t\"pem\":             \"encoding/pem\",\n\t\"pkix\":            \"crypto/x509/pkix\",\n\t\"plan9obj\":        \"debug/plan9obj\",\n\t\"png\":             \"image/png\",\n\t\"pprof\":           \"net/http/pprof\",\n\t\"printer\":         \"go/printer\",\n\t\"quick\":           \"testing/quick\",\n\t\"quotedprintable\": \"mime/quotedprintable\",\n\t\"race\":            \"runtime/race\",\n\t\"rand\":            \"math/rand\",\n\t\"rc4\":             \"crypto/rc4\",\n\t\"reflect\":         \"reflect\",\n\t\"regexp\":          \"regexp\",\n\t\"ring\":            \"container/ring\",\n\t\"rpc\":             \"net/rpc\",\n\t\"rsa\":             \"crypto/rsa\",\n\t\"runtime\":         \"runtime\",\n\t\"scanner\":         \"text/scanner\",\n\t\"sha1\":            \"crypto/sha1\",\n\t\"sha256\":          \"crypto/sha256\",\n\t\"sha512\":          \"crypto/sha512\",\n\t\"signal\":          \"os/signal\",\n\t\"smtp\":            \"net/smtp\",\n\t\"sort\":            \"sort\",\n\t\"sql\":             \"database/sql\",\n\t\"strconv\":         \"strconv\",\n\t\"strings\":         \"strings\",\n\t\"subtle\":          \"crypto/subtle\",\n\t\"suffixarray\":     \"index/suffixarray\",\n\t\"sync\":            \"sync\",\n\t\"syntax\":          \"regexp/syntax\",\n\t\"syscall\":         \"syscall\",\n\t\"syslog\":          \"log/syslog\",\n\t\"tabwriter\":       \"text/tabwriter\",\n\t\"tar\":             \"archive/tar\",\n\t\"template\":        \"html/template\",\n\t\"testing\":         \"testing\",\n\t\"textproto\":       \"net/textproto\",\n\t\"time\":            \"time\",\n\t\"tls\":             \"crypto/tls\",\n\t\"token\":           \"go/token\",\n\t\"trace\":           \"runtime/trace\",\n\t\"types\":           \"go/types\",\n\t\"unicode\":         \"unicode\",\n\t\"url\":             \"net/url\",\n\t\"user\":            \"os/user\",\n\t\"utf16\":           \"unicode/utf16\",\n\t\"utf8\":            \"unicode/utf8\",\n\t\"x509\":            \"crypto/x509\",\n\t\"xml\":             \"encoding/xml\",\n\t\"zip\":             \"archive/zip\",\n\t\"zlib\":            \"compress/zlib\",\n\t//\"scanner\": \"go/scanner\", // DUP: prefer text/scanner\n\t//\"template\": \"text/template\", // DUP: prefer html/template\n\t//\"pprof\": \"runtime/pprof\", // DUP: prefer net/http/pprof\n\t//\"rand\": \"crypto/rand\", // DUP: prefer math/rand\n}\n"
        },
        {
          "name": "debian",
          "type": "tree",
          "content": null
        },
        {
          "name": "decl.go",
          "type": "blob",
          "size": 32.8974609375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/token\"\n\t\"io\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// decl.class\ntype decl_class int16\n\nconst (\n\tdecl_invalid = decl_class(-1 + iota)\n\n\t// these are in a sorted order\n\tdecl_const\n\tdecl_func\n\tdecl_import\n\tdecl_package\n\tdecl_type\n\tdecl_var\n\n\t// this one serves as a temporary type for those methods that were\n\t// declared before their actual owner\n\tdecl_methods_stub\n)\n\nfunc (this decl_class) String() string {\n\tswitch this {\n\tcase decl_invalid:\n\t\treturn \"PANIC\"\n\tcase decl_const:\n\t\treturn \"const\"\n\tcase decl_func:\n\t\treturn \"func\"\n\tcase decl_import:\n\t\treturn \"import\"\n\tcase decl_package:\n\t\treturn \"package\"\n\tcase decl_type:\n\t\treturn \"type\"\n\tcase decl_var:\n\t\treturn \"var\"\n\tcase decl_methods_stub:\n\t\treturn \"IF YOU SEE THIS, REPORT A BUG\" // :D\n\t}\n\tpanic(\"unreachable\")\n}\n\n// decl.flags\ntype decl_flags int16\n\nconst (\n\tdecl_foreign decl_flags = 1 << iota // imported from another package\n\n\t// means that the decl is a part of the range statement\n\t// its type is inferred in a special way\n\tdecl_rangevar\n\n\t// decl of decl_type class is a type alias\n\tdecl_alias\n\n\t// for preventing infinite recursions and loops in type inference code\n\tdecl_visited\n)\n\n//-------------------------------------------------------------------------\n// decl\n//\n// The most important data structure of the whole gocode project. It\n// describes a single declaration and its children.\n//-------------------------------------------------------------------------\n\ntype decl struct {\n\t// Name starts with '$' if the declaration describes an anonymous type.\n\t// '$s_%d' for anonymous struct types\n\t// '$i_%d' for anonymous interface types\n\tname  string\n\ttyp   ast.Expr\n\tclass decl_class\n\tflags decl_flags\n\n\t// functions for interface type, fields+methods for struct type\n\tchildren map[string]*decl\n\n\t// embedded types\n\tembedded []ast.Expr\n\n\t// if the type is unknown at AST building time, I'm using these\n\tvalue ast.Expr\n\n\t// if it's a multiassignment and the Value is a CallExpr, it is being set\n\t// to an index into the return value tuple, otherwise it's a -1\n\tvalue_index int\n\n\t// scope where this Decl was declared in (not its visibilty scope!)\n\t// Decl uses it for type inference\n\tscope *scope\n}\n\nfunc ast_decl_type(d ast.Decl) ast.Expr {\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.CONST, token.VAR:\n\t\t\tc := t.Specs[0].(*ast.ValueSpec)\n\t\t\treturn c.Type\n\t\tcase token.TYPE:\n\t\t\tt := t.Specs[0].(*ast.TypeSpec)\n\t\t\treturn t.Type\n\t\t}\n\tcase *ast.FuncDecl:\n\t\treturn t.Type\n\t}\n\tpanic(\"unreachable\")\n}\n\nfunc ast_decl_flags(d ast.Decl) decl_flags {\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.TYPE:\n\t\t\tif isAliasTypeSpec(t.Specs[0].(*ast.TypeSpec)) {\n\t\t\t\treturn decl_alias\n\t\t\t}\n\t\t}\n\t}\n\treturn 0\n}\n\nfunc ast_decl_class(d ast.Decl) decl_class {\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.VAR:\n\t\t\treturn decl_var\n\t\tcase token.CONST:\n\t\t\treturn decl_const\n\t\tcase token.TYPE:\n\t\t\treturn decl_type\n\t\t}\n\tcase *ast.FuncDecl:\n\t\treturn decl_func\n\t}\n\tpanic(\"unreachable\")\n}\n\nfunc ast_decl_convertable(d ast.Decl) bool {\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.VAR, token.CONST, token.TYPE:\n\t\t\treturn true\n\t\t}\n\tcase *ast.FuncDecl:\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc ast_field_list_to_decls(f *ast.FieldList, class decl_class, flags decl_flags, scope *scope, add_anonymous bool) map[string]*decl {\n\tcount := 0\n\tfor _, field := range f.List {\n\t\tcount += len(field.Names)\n\t}\n\n\tdecls := make(map[string]*decl, count)\n\tfor _, field := range f.List {\n\t\tfor _, name := range field.Names {\n\t\t\tif flags&decl_foreign != 0 && !ast.IsExported(name.Name) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\td := &decl{\n\t\t\t\tname:        name.Name,\n\t\t\t\ttyp:         field.Type,\n\t\t\t\tclass:       class,\n\t\t\t\tflags:       flags,\n\t\t\t\tscope:       scope,\n\t\t\t\tvalue_index: -1,\n\t\t\t}\n\t\t\tdecls[d.name] = d\n\t\t}\n\n\t\t// add anonymous field as a child (type embedding)\n\t\tif class == decl_var && field.Names == nil && add_anonymous {\n\t\t\ttp := get_type_path(field.Type)\n\t\t\tif flags&decl_foreign != 0 && !ast.IsExported(tp.name) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\td := &decl{\n\t\t\t\tname:        tp.name,\n\t\t\t\ttyp:         field.Type,\n\t\t\t\tclass:       class,\n\t\t\t\tflags:       flags,\n\t\t\t\tscope:       scope,\n\t\t\t\tvalue_index: -1,\n\t\t\t}\n\t\t\tdecls[d.name] = d\n\t\t}\n\t}\n\treturn decls\n}\n\nfunc ast_field_list_to_embedded(f *ast.FieldList) []ast.Expr {\n\tcount := 0\n\tfor _, field := range f.List {\n\t\tif field.Names == nil || field.Names[0].Name == \"?\" {\n\t\t\tcount++\n\t\t}\n\t}\n\n\tif count == 0 {\n\t\treturn nil\n\t}\n\n\tembedded := make([]ast.Expr, count)\n\ti := 0\n\tfor _, field := range f.List {\n\t\tif field.Names == nil || field.Names[0].Name == \"?\" {\n\t\t\tembedded[i] = field.Type\n\t\t\ti++\n\t\t}\n\t}\n\n\treturn embedded\n}\n\nfunc ast_type_to_embedded(ty ast.Expr) []ast.Expr {\n\tswitch t := ty.(type) {\n\tcase *ast.StructType:\n\t\treturn ast_field_list_to_embedded(t.Fields)\n\tcase *ast.InterfaceType:\n\t\treturn ast_field_list_to_embedded(t.Methods)\n\t}\n\treturn nil\n}\n\nfunc ast_type_to_children(ty ast.Expr, flags decl_flags, scope *scope) map[string]*decl {\n\tswitch t := ty.(type) {\n\tcase *ast.StructType:\n\t\treturn ast_field_list_to_decls(t.Fields, decl_var, flags, scope, true)\n\tcase *ast.InterfaceType:\n\t\treturn ast_field_list_to_decls(t.Methods, decl_func, flags, scope, false)\n\t}\n\treturn nil\n}\n\n//-------------------------------------------------------------------------\n// anonymous_id_gen\n//\n// ID generator for anonymous types (thread-safe)\n//-------------------------------------------------------------------------\n\ntype anonymous_id_gen struct {\n\tsync.Mutex\n\ti int\n}\n\nfunc (a *anonymous_id_gen) gen() (id int) {\n\ta.Lock()\n\tdefer a.Unlock()\n\tid = a.i\n\ta.i++\n\treturn\n}\n\nvar g_anon_gen anonymous_id_gen\n\n//-------------------------------------------------------------------------\n\nfunc check_for_anon_type(t ast.Expr, flags decl_flags, s *scope) ast.Expr {\n\tif t == nil {\n\t\treturn nil\n\t}\n\tvar name string\n\n\tswitch t.(type) {\n\tcase *ast.StructType:\n\t\tname = fmt.Sprintf(\"$s_%d\", g_anon_gen.gen())\n\tcase *ast.InterfaceType:\n\t\tname = fmt.Sprintf(\"$i_%d\", g_anon_gen.gen())\n\t}\n\n\tif name != \"\" {\n\t\tanonymify_ast(t, flags, s)\n\t\td := new_decl_full(name, decl_type, flags, t, nil, -1, s)\n\t\ts.add_named_decl(d)\n\t\treturn ast.NewIdent(name)\n\t}\n\treturn t\n}\n\n//-------------------------------------------------------------------------\n\nfunc new_decl_full(name string, class decl_class, flags decl_flags, typ, v ast.Expr, vi int, s *scope) *decl {\n\tif name == \"_\" {\n\t\treturn nil\n\t}\n\td := new(decl)\n\td.name = name\n\td.class = class\n\td.flags = flags\n\td.typ = typ\n\td.value = v\n\td.value_index = vi\n\td.scope = s\n\td.children = ast_type_to_children(d.typ, flags, s)\n\td.embedded = ast_type_to_embedded(d.typ)\n\treturn d\n}\n\nfunc new_decl(name string, class decl_class, scope *scope) *decl {\n\tdecl := new(decl)\n\tdecl.name = name\n\tdecl.class = class\n\tdecl.value_index = -1\n\tdecl.scope = scope\n\treturn decl\n}\n\nfunc new_decl_var(name string, typ ast.Expr, value ast.Expr, vindex int, scope *scope) *decl {\n\tif name == \"_\" {\n\t\treturn nil\n\t}\n\tdecl := new(decl)\n\tdecl.name = name\n\tdecl.class = decl_var\n\tdecl.typ = typ\n\tdecl.value = value\n\tdecl.value_index = vindex\n\tdecl.scope = scope\n\treturn decl\n}\n\nfunc method_of(d ast.Decl) string {\n\tif t, ok := d.(*ast.FuncDecl); ok {\n\t\tif t.Recv != nil && len(t.Recv.List) != 0 {\n\t\t\tswitch t := t.Recv.List[0].Type.(type) {\n\t\t\tcase *ast.StarExpr:\n\t\t\t\tif se, ok := t.X.(*ast.SelectorExpr); ok {\n\t\t\t\t\treturn se.Sel.Name\n\t\t\t\t}\n\t\t\t\tif ident, ok := t.X.(*ast.Ident); ok {\n\t\t\t\t\treturn ident.Name\n\t\t\t\t}\n\t\t\t\treturn \"\"\n\t\t\tcase *ast.Ident:\n\t\t\t\treturn t.Name\n\t\t\tdefault:\n\t\t\t\treturn \"\"\n\t\t\t}\n\t\t}\n\t}\n\treturn \"\"\n}\n\nfunc (other *decl) deep_copy() *decl {\n\td := new(decl)\n\td.name = other.name\n\td.class = other.class\n\td.flags = other.flags\n\td.typ = other.typ\n\td.value = other.value\n\td.value_index = other.value_index\n\td.children = make(map[string]*decl, len(other.children))\n\tfor key, value := range other.children {\n\t\td.children[key] = value\n\t}\n\tif other.embedded != nil {\n\t\td.embedded = make([]ast.Expr, len(other.embedded))\n\t\tcopy(d.embedded, other.embedded)\n\t}\n\td.scope = other.scope\n\treturn d\n}\n\nfunc (d *decl) is_rangevar() bool {\n\treturn d.flags&decl_rangevar != 0\n}\n\nfunc (d *decl) is_alias() bool {\n\treturn d.flags&decl_alias != 0\n}\n\nfunc (d *decl) is_visited() bool {\n\treturn d.flags&decl_visited != 0\n}\n\nfunc (d *decl) set_visited() {\n\td.flags |= decl_visited\n}\n\nfunc (d *decl) clear_visited() {\n\td.flags &^= decl_visited\n}\n\nfunc (d *decl) expand_or_replace(other *decl) {\n\t// expand only if it's a methods stub, otherwise simply keep it as is\n\tif d.class != decl_methods_stub && other.class != decl_methods_stub {\n\t\treturn\n\t}\n\n\tif d.class == decl_methods_stub {\n\t\td.typ = other.typ\n\t\td.class = other.class\n\t\td.flags = other.flags\n\t}\n\n\tif other.children != nil {\n\t\tfor _, c := range other.children {\n\t\t\td.add_child(c)\n\t\t}\n\t}\n\n\tif other.embedded != nil {\n\t\td.embedded = other.embedded\n\t\td.scope = other.scope\n\t}\n}\n\nfunc (d *decl) matches() bool {\n\tif strings.HasPrefix(d.name, \"$\") || d.class == decl_methods_stub {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (d *decl) pretty_print_type(out io.Writer, canonical_aliases map[string]string) {\n\tswitch d.class {\n\tcase decl_type:\n\t\tswitch d.typ.(type) {\n\t\tcase *ast.StructType:\n\t\t\t// TODO: not used due to anonymify?\n\t\t\tfmt.Fprintf(out, \"struct\")\n\t\tcase *ast.InterfaceType:\n\t\t\t// TODO: not used due to anonymify?\n\t\t\tfmt.Fprintf(out, \"interface\")\n\t\tdefault:\n\t\t\tif d.typ != nil {\n\t\t\t\tpretty_print_type_expr(out, d.typ, canonical_aliases)\n\t\t\t}\n\t\t}\n\tcase decl_var:\n\t\tif d.typ != nil {\n\t\t\tpretty_print_type_expr(out, d.typ, canonical_aliases)\n\t\t}\n\tcase decl_func:\n\t\tpretty_print_type_expr(out, d.typ, canonical_aliases)\n\t}\n}\n\nfunc (d *decl) add_child(cd *decl) {\n\tif d.children == nil {\n\t\td.children = make(map[string]*decl)\n\t}\n\td.children[cd.name] = cd\n}\n\nfunc check_for_builtin_funcs(typ *ast.Ident, c *ast.CallExpr, scope *scope) (ast.Expr, *scope) {\n\tif strings.HasPrefix(typ.Name, \"func(\") {\n\t\tif t, ok := c.Fun.(*ast.Ident); ok {\n\t\t\tswitch t.Name {\n\t\t\tcase \"new\":\n\t\t\t\tif len(c.Args) > 0 {\n\t\t\t\t\te := new(ast.StarExpr)\n\t\t\t\t\te.X = c.Args[0]\n\t\t\t\t\treturn e, scope\n\t\t\t\t}\n\t\t\tcase \"make\":\n\t\t\t\tif len(c.Args) > 0 {\n\t\t\t\t\treturn c.Args[0], scope\n\t\t\t\t}\n\t\t\tcase \"append\":\n\t\t\t\tif len(c.Args) > 0 {\n\t\t\t\t\tt, scope, _ := infer_type(c.Args[0], scope, -1)\n\t\t\t\t\treturn t, scope\n\t\t\t\t}\n\t\t\tcase \"complex\":\n\t\t\t\t// TODO: fix it\n\t\t\t\treturn ast.NewIdent(\"complex\"), g_universe_scope\n\t\t\tcase \"closed\":\n\t\t\t\treturn ast.NewIdent(\"bool\"), g_universe_scope\n\t\t\tcase \"cap\":\n\t\t\t\treturn ast.NewIdent(\"int\"), g_universe_scope\n\t\t\tcase \"copy\":\n\t\t\t\treturn ast.NewIdent(\"int\"), g_universe_scope\n\t\t\tcase \"len\":\n\t\t\t\treturn ast.NewIdent(\"int\"), g_universe_scope\n\t\t\t}\n\t\t\t// TODO:\n\t\t\t// func recover() interface{}\n\t\t\t// func imag(c ComplexType) FloatType\n\t\t\t// func real(c ComplexType) FloatType\n\t\t}\n\t}\n\treturn nil, nil\n}\n\nfunc func_return_type(f *ast.FuncType, index int) ast.Expr {\n\tif f.Results == nil {\n\t\treturn nil\n\t}\n\n\tif index == -1 {\n\t\treturn f.Results.List[0].Type\n\t}\n\n\ti := 0\n\tvar field *ast.Field\n\tfor _, field = range f.Results.List {\n\t\tn := 1\n\t\tif field.Names != nil {\n\t\t\tn = len(field.Names)\n\t\t}\n\t\tif i <= index && index < i+n {\n\t\t\treturn field.Type\n\t\t}\n\t\ti += n\n\t}\n\treturn nil\n}\n\ntype type_path struct {\n\tpkg  string\n\tname string\n}\n\nfunc (tp *type_path) is_nil() bool {\n\treturn tp.pkg == \"\" && tp.name == \"\"\n}\n\n// converts type expressions like:\n// ast.Expr\n// *ast.Expr\n// $ast$go/ast.Expr\n// to a path that can be used to lookup a type related Decl\nfunc get_type_path(e ast.Expr) (r type_path) {\n\tif e == nil {\n\t\treturn type_path{\"\", \"\"}\n\t}\n\n\tswitch t := e.(type) {\n\tcase *ast.Ident:\n\t\tr.name = t.Name\n\tcase *ast.StarExpr:\n\t\tr = get_type_path(t.X)\n\tcase *ast.SelectorExpr:\n\t\tif ident, ok := t.X.(*ast.Ident); ok {\n\t\t\tr.pkg = ident.Name\n\t\t}\n\t\tr.name = t.Sel.Name\n\t}\n\treturn\n}\n\nfunc lookup_path(tp type_path, scope *scope) *decl {\n\tif tp.is_nil() {\n\t\treturn nil\n\t}\n\tvar decl *decl\n\tif tp.pkg != \"\" {\n\t\tdecl = scope.lookup(tp.pkg)\n\t\t// return nil early if the package wasn't found but it's part\n\t\t// of the type specification\n\t\tif decl == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tif decl != nil {\n\t\tif tp.name != \"\" {\n\t\t\treturn decl.find_child(tp.name)\n\t\t} else {\n\t\t\treturn decl\n\t\t}\n\t}\n\n\treturn scope.lookup(tp.name)\n}\n\nfunc lookup_pkg(tp type_path, scope *scope) string {\n\tif tp.is_nil() {\n\t\treturn \"\"\n\t}\n\tif tp.pkg == \"\" {\n\t\treturn \"\"\n\t}\n\tdecl := scope.lookup(tp.pkg)\n\tif decl == nil {\n\t\treturn \"\"\n\t}\n\treturn decl.name\n}\n\nfunc type_to_decl(t ast.Expr, scope *scope) *decl {\n\ttp := get_type_path(t)\n\td := lookup_path(tp, scope)\n\tif d != nil && d.class == decl_var {\n\t\t// weird variable declaration pointing to itself\n\t\treturn nil\n\t}\n\treturn d\n}\n\nfunc expr_to_decl(e ast.Expr, scope *scope) *decl {\n\tt, scope, _ := infer_type(e, scope, -1)\n\treturn type_to_decl(t, scope)\n}\n\n//-------------------------------------------------------------------------\n// Type inference\n//-------------------------------------------------------------------------\n\ntype type_predicate func(ast.Expr) bool\n\nfunc advance_to_type(pred type_predicate, v ast.Expr, scope *scope) (ast.Expr, *scope) {\n\tif pred(v) {\n\t\treturn v, scope\n\t}\n\n\tdecl := type_to_decl(v, scope)\n\tif decl == nil {\n\t\treturn nil, nil\n\t}\n\n\tif decl.is_visited() {\n\t\treturn nil, nil\n\t}\n\tdecl.set_visited()\n\tdefer decl.clear_visited()\n\n\treturn advance_to_type(pred, decl.typ, decl.scope)\n}\n\nfunc advance_to_struct_or_interface(decl *decl) *decl {\n\tif decl.is_visited() {\n\t\treturn nil\n\t}\n\tdecl.set_visited()\n\tdefer decl.clear_visited()\n\n\tif struct_interface_predicate(decl.typ) {\n\t\treturn decl\n\t}\n\n\tdecl = type_to_decl(decl.typ, decl.scope)\n\tif decl == nil {\n\t\treturn nil\n\t}\n\treturn advance_to_struct_or_interface(decl)\n}\n\nfunc struct_interface_predicate(v ast.Expr) bool {\n\tswitch v.(type) {\n\tcase *ast.StructType, *ast.InterfaceType:\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc chan_predicate(v ast.Expr) bool {\n\t_, ok := v.(*ast.ChanType)\n\treturn ok\n}\n\nfunc index_predicate(v ast.Expr) bool {\n\tswitch v.(type) {\n\tcase *ast.ArrayType, *ast.MapType, *ast.Ellipsis:\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc star_predicate(v ast.Expr) bool {\n\t_, ok := v.(*ast.StarExpr)\n\treturn ok\n}\n\nfunc func_predicate(v ast.Expr) bool {\n\t_, ok := v.(*ast.FuncType)\n\treturn ok\n}\n\nfunc range_predicate(v ast.Expr) bool {\n\tswitch t := v.(type) {\n\tcase *ast.Ident:\n\t\tif t.Name == \"string\" {\n\t\t\treturn true\n\t\t}\n\tcase *ast.ArrayType, *ast.MapType, *ast.ChanType, *ast.Ellipsis:\n\t\treturn true\n\t}\n\treturn false\n}\n\ntype anonymous_typer struct {\n\tflags decl_flags\n\tscope *scope\n}\n\nfunc (a *anonymous_typer) Visit(node ast.Node) ast.Visitor {\n\tswitch t := node.(type) {\n\tcase *ast.CompositeLit:\n\t\tt.Type = check_for_anon_type(t.Type, a.flags, a.scope)\n\tcase *ast.MapType:\n\t\tt.Key = check_for_anon_type(t.Key, a.flags, a.scope)\n\t\tt.Value = check_for_anon_type(t.Value, a.flags, a.scope)\n\tcase *ast.ArrayType:\n\t\tt.Elt = check_for_anon_type(t.Elt, a.flags, a.scope)\n\tcase *ast.Ellipsis:\n\t\tt.Elt = check_for_anon_type(t.Elt, a.flags, a.scope)\n\tcase *ast.ChanType:\n\t\tt.Value = check_for_anon_type(t.Value, a.flags, a.scope)\n\tcase *ast.Field:\n\t\tt.Type = check_for_anon_type(t.Type, a.flags, a.scope)\n\tcase *ast.CallExpr:\n\t\tt.Fun = check_for_anon_type(t.Fun, a.flags, a.scope)\n\tcase *ast.ParenExpr:\n\t\tt.X = check_for_anon_type(t.X, a.flags, a.scope)\n\tcase *ast.StarExpr:\n\t\tt.X = check_for_anon_type(t.X, a.flags, a.scope)\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.VAR:\n\t\t\tfor _, s := range t.Specs {\n\t\t\t\tvs := s.(*ast.ValueSpec)\n\t\t\t\tvs.Type = check_for_anon_type(vs.Type, a.flags, a.scope)\n\t\t\t}\n\t\tcase token.TYPE:\n\t\t\tfor _, s := range t.Specs {\n\t\t\t\tts := s.(*ast.TypeSpec)\n\t\t\t\tif isAliasTypeSpec(ts) {\n\t\t\t\t\tts.Type = check_for_anon_type(ts.Type, a.flags, a.scope)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn a\n}\n\nfunc anonymify_ast(node ast.Node, flags decl_flags, scope *scope) {\n\tv := anonymous_typer{flags, scope}\n\tast.Walk(&v, node)\n}\n\n// RETURNS:\n// \t- type expression which represents a full name of a type\n//\t- bool whether a type expression is actually a type (used internally)\n//\t- scope in which type makes sense\nfunc infer_type(v ast.Expr, scope *scope, index int) (ast.Expr, *scope, bool) {\n\tswitch t := v.(type) {\n\tcase *ast.CompositeLit:\n\t\treturn t.Type, scope, true\n\tcase *ast.Ident:\n\t\tif d := scope.lookup(t.Name); d != nil {\n\t\t\tif d.class == decl_package {\n\t\t\t\treturn ast.NewIdent(t.Name), scope, false\n\t\t\t}\n\t\t\ttyp, scope := d.infer_type()\n\t\t\treturn typ, scope, d.class == decl_type\n\t\t}\n\tcase *ast.UnaryExpr:\n\t\tswitch t.Op {\n\t\tcase token.AND:\n\t\t\t// &a makes sense only with values, don't even check for type\n\t\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\t\tif it == nil {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\te := new(ast.StarExpr)\n\t\t\te.X = it\n\t\t\treturn e, s, false\n\t\tcase token.ARROW:\n\t\t\t// <-a makes sense only with values\n\t\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\t\tif it == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tswitch index {\n\t\t\tcase -1, 0:\n\t\t\t\tit, s = advance_to_type(chan_predicate, it, s)\n\t\t\t\treturn it.(*ast.ChanType).Value, s, false\n\t\t\tcase 1:\n\t\t\t\t// technically it's a value, but in case of index == 1\n\t\t\t\t// it is always the last infer operation\n\t\t\t\treturn ast.NewIdent(\"bool\"), g_universe_scope, false\n\t\t\t}\n\t\tcase token.ADD, token.NOT, token.SUB, token.XOR:\n\t\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\t\tif it == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn it, s, false\n\t\t}\n\tcase *ast.BinaryExpr:\n\t\tswitch t.Op {\n\t\tcase token.EQL, token.NEQ, token.LSS, token.LEQ,\n\t\t\ttoken.GTR, token.GEQ, token.LOR, token.LAND:\n\t\t\t// logic operations, the result is a bool, always\n\t\t\treturn ast.NewIdent(\"bool\"), g_universe_scope, false\n\t\tcase token.ADD, token.SUB, token.MUL, token.QUO, token.OR,\n\t\t\ttoken.XOR, token.REM, token.AND, token.AND_NOT:\n\t\t\t// try X, then Y, they should be the same anyway\n\t\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\t\tif it == nil {\n\t\t\t\tit, s, _ = infer_type(t.Y, scope, -1)\n\t\t\t\tif it == nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn it, s, false\n\t\tcase token.SHL, token.SHR:\n\t\t\t// try only X for shifts, Y is always uint\n\t\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\t\tif it == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn it, s, false\n\t\t}\n\tcase *ast.IndexExpr:\n\t\t// something[another] always returns a value and it works on a value too\n\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\t\tit, s = advance_to_type(index_predicate, it, s)\n\t\tswitch t := it.(type) {\n\t\tcase *ast.ArrayType:\n\t\t\treturn t.Elt, s, false\n\t\tcase *ast.Ellipsis:\n\t\t\treturn t.Elt, s, false\n\t\tcase *ast.MapType:\n\t\t\tswitch index {\n\t\t\tcase -1, 0:\n\t\t\t\treturn t.Value, s, false\n\t\t\tcase 1:\n\t\t\t\treturn ast.NewIdent(\"bool\"), g_universe_scope, false\n\t\t\t}\n\t\t}\n\tcase *ast.SliceExpr:\n\t\t// something[start : end] always returns a value\n\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\t\tit, s = advance_to_type(index_predicate, it, s)\n\t\tswitch t := it.(type) {\n\t\tcase *ast.ArrayType:\n\t\t\te := new(ast.ArrayType)\n\t\t\te.Elt = t.Elt\n\t\t\treturn e, s, false\n\t\t}\n\tcase *ast.StarExpr:\n\t\tit, s, is_type := infer_type(t.X, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\t\tif is_type {\n\t\t\t// if it's a type, add * modifier, make it a 'pointer of' type\n\t\t\te := new(ast.StarExpr)\n\t\t\te.X = it\n\t\t\treturn e, s, true\n\t\t} else {\n\t\t\tit, s := advance_to_type(star_predicate, it, s)\n\t\t\tif se, ok := it.(*ast.StarExpr); ok {\n\t\t\t\treturn se.X, s, false\n\t\t\t}\n\t\t}\n\tcase *ast.CallExpr:\n\t\t// this is a function call or a type cast:\n\t\t// myFunc(1,2,3) or int16(myvar)\n\t\tit, s, is_type := infer_type(t.Fun, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tif is_type {\n\t\t\t// a type cast\n\t\t\treturn it, scope, false\n\t\t} else {\n\t\t\t// it must be a function call or a built-in function\n\t\t\t// first check for built-in\n\t\t\tif ct, ok := it.(*ast.Ident); ok {\n\t\t\t\tty, s := check_for_builtin_funcs(ct, t, scope)\n\t\t\t\tif ty != nil {\n\t\t\t\t\treturn ty, s, false\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// then check for an ordinary function call\n\t\t\tit, scope = advance_to_type(func_predicate, it, s)\n\t\t\tif ct, ok := it.(*ast.FuncType); ok {\n\t\t\t\treturn func_return_type(ct, index), s, false\n\t\t\t}\n\t\t}\n\tcase *ast.ParenExpr:\n\t\tit, s, is_type := infer_type(t.X, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\t\treturn it, s, is_type\n\tcase *ast.SelectorExpr:\n\t\tit, s, _ := infer_type(t.X, scope, -1)\n\t\tif it == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tif d := type_to_decl(it, s); d != nil {\n\t\t\tc := d.find_child_and_in_embedded(t.Sel.Name)\n\t\t\tif c != nil {\n\t\t\t\tif c.class == decl_type {\n\t\t\t\t\treturn t, scope, true\n\t\t\t\t} else {\n\t\t\t\t\ttyp, s := c.infer_type()\n\t\t\t\t\treturn typ, s, false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase *ast.FuncLit:\n\t\t// it's a value, but I think most likely we don't even care, cause we can only\n\t\t// call it, and CallExpr uses the type itself to figure out\n\t\treturn t.Type, scope, false\n\tcase *ast.TypeAssertExpr:\n\t\tif t.Type == nil {\n\t\t\treturn infer_type(t.X, scope, -1)\n\t\t}\n\t\tswitch index {\n\t\tcase -1, 0:\n\t\t\t// converting a value to a different type, but return thing is a value\n\t\t\tit, _, _ := infer_type(t.Type, scope, -1)\n\t\t\treturn it, scope, false\n\t\tcase 1:\n\t\t\treturn ast.NewIdent(\"bool\"), g_universe_scope, false\n\t\t}\n\tcase *ast.ArrayType, *ast.MapType, *ast.ChanType, *ast.Ellipsis,\n\t\t*ast.FuncType, *ast.StructType, *ast.InterfaceType:\n\t\treturn t, scope, true\n\tdefault:\n\t\t_ = reflect.TypeOf(v)\n\t\t//fmt.Println(ty)\n\t}\n\treturn nil, nil, false\n}\n\n// Uses Value, ValueIndex and Scope to infer the type of this\n// declaration. Returns the type itself and the scope where this type\n// makes sense.\nfunc (d *decl) infer_type() (ast.Expr, *scope) {\n\t// special case for range vars\n\tif d.is_rangevar() {\n\t\tvar scope *scope\n\t\td.typ, scope = infer_range_type(d.value, d.scope, d.value_index)\n\t\treturn d.typ, scope\n\t}\n\n\tswitch d.class {\n\tcase decl_package:\n\t\t// package is handled specially in inferType\n\t\treturn nil, nil\n\tcase decl_type:\n\t\treturn ast.NewIdent(d.name), d.scope\n\t}\n\n\t// shortcut\n\tif d.typ != nil && d.value == nil {\n\t\treturn d.typ, d.scope\n\t}\n\n\t// prevent loops\n\tif d.is_visited() {\n\t\treturn nil, nil\n\t}\n\td.set_visited()\n\tdefer d.clear_visited()\n\n\tvar scope *scope\n\td.typ, scope, _ = infer_type(d.value, d.scope, d.value_index)\n\treturn d.typ, scope\n}\n\nfunc (d *decl) type_dealias() *decl {\n\tif d.is_visited() {\n\t\treturn nil\n\t}\n\td.set_visited()\n\tdefer d.clear_visited()\n\n\tdd := type_to_decl(d.typ, d.scope)\n\tif dd != nil && dd.is_alias() {\n\t\treturn dd.type_dealias()\n\t}\n\treturn dd\n}\n\nfunc (d *decl) find_child(name string) *decl {\n\t// type aliases don't really have any children on their own, but they\n\t// point to a different type, let's try to find one\n\tif d.is_alias() {\n\t\tdd := d.type_dealias()\n\t\tif dd != nil {\n\t\t\treturn dd.find_child(name)\n\t\t}\n\n\t\t// note that type alias can also point to a type literal, something like\n\t\t// type A = struct { A int }\n\t\t// in this case we rely on \"advance_to_struct_or_interface\" below\n\t}\n\n\tif d.children != nil {\n\t\tif c, ok := d.children[name]; ok {\n\t\t\treturn c\n\t\t}\n\t}\n\n\tdecl := advance_to_struct_or_interface(d)\n\tif decl != nil && decl != d {\n\t\tif d.is_visited() {\n\t\t\treturn nil\n\t\t}\n\t\td.set_visited()\n\t\tdefer d.clear_visited()\n\n\t\treturn decl.find_child(name)\n\t}\n\treturn nil\n}\n\nfunc (d *decl) find_child_and_in_embedded(name string) *decl {\n\tif d == nil {\n\t\treturn nil\n\t}\n\n\tif d.is_alias() {\n\t\tdd := d.type_dealias()\n\t\tif dd != nil {\n\t\t\treturn dd.find_child_and_in_embedded(name)\n\t\t}\n\t}\n\n\tif d.is_visited() {\n\t\treturn nil\n\t}\n\td.set_visited()\n\tdefer d.clear_visited()\n\n\tc := d.find_child(name)\n\tif c == nil {\n\t\tfor _, e := range d.embedded {\n\t\t\ttypedecl := type_to_decl(e, d.scope)\n\t\t\tc = typedecl.find_child_and_in_embedded(name)\n\t\t\tif c != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn c\n}\n\n// Special type inference for range statements.\n// [int], [int] := range [string]\n// [int], [value] := range [slice or array]\n// [key], [value] := range [map]\n// [value], [nil] := range [chan]\nfunc infer_range_type(e ast.Expr, sc *scope, valueindex int) (ast.Expr, *scope) {\n\tt, s, _ := infer_type(e, sc, -1)\n\tt, s = advance_to_type(range_predicate, t, s)\n\tif t != nil {\n\t\tvar t1, t2 ast.Expr\n\t\tvar s1, s2 *scope\n\t\ts1 = s\n\t\ts2 = s\n\n\t\tswitch t := t.(type) {\n\t\tcase *ast.Ident:\n\t\t\t// string\n\t\t\tif t.Name == \"string\" {\n\t\t\t\tt1 = ast.NewIdent(\"int\")\n\t\t\t\tt2 = ast.NewIdent(\"rune\")\n\t\t\t\ts1 = g_universe_scope\n\t\t\t\ts2 = g_universe_scope\n\t\t\t} else {\n\t\t\t\tt1, t2 = nil, nil\n\t\t\t}\n\t\tcase *ast.ArrayType:\n\t\t\tt1 = ast.NewIdent(\"int\")\n\t\t\ts1 = g_universe_scope\n\t\t\tt2 = t.Elt\n\t\tcase *ast.Ellipsis:\n\t\t\tt1 = ast.NewIdent(\"int\")\n\t\t\ts1 = g_universe_scope\n\t\t\tt2 = t.Elt\n\t\tcase *ast.MapType:\n\t\t\tt1 = t.Key\n\t\t\tt2 = t.Value\n\t\tcase *ast.ChanType:\n\t\t\tt1 = t.Value\n\t\t\tt2 = nil\n\t\tdefault:\n\t\t\tt1, t2 = nil, nil\n\t\t}\n\n\t\tswitch valueindex {\n\t\tcase 0:\n\t\t\treturn t1, s1\n\t\tcase 1:\n\t\t\treturn t2, s2\n\t\t}\n\t}\n\treturn nil, nil\n}\n\n//-------------------------------------------------------------------------\n// Pretty printing\n//-------------------------------------------------------------------------\n\nfunc get_array_len(e ast.Expr) string {\n\tswitch t := e.(type) {\n\tcase *ast.BasicLit:\n\t\treturn string(t.Value)\n\tcase *ast.Ellipsis:\n\t\treturn \"...\"\n\t}\n\treturn \"\"\n}\n\nfunc pretty_print_type_expr(out io.Writer, e ast.Expr, canonical_aliases map[string]string) {\n\tswitch t := e.(type) {\n\tcase *ast.StarExpr:\n\t\tfmt.Fprintf(out, \"*\")\n\t\tpretty_print_type_expr(out, t.X, canonical_aliases)\n\tcase *ast.Ident:\n\t\tif strings.HasPrefix(t.Name, \"$\") {\n\t\t\t// beautify anonymous types\n\t\t\tswitch t.Name[1] {\n\t\t\tcase 's':\n\t\t\t\tfmt.Fprintf(out, \"struct\")\n\t\t\tcase 'i':\n\t\t\t\t// ok, in most cases anonymous interface is an\n\t\t\t\t// empty interface, I'll just pretend that\n\t\t\t\t// it's always true\n\t\t\t\tfmt.Fprintf(out, \"interface{}\")\n\t\t\t}\n\t\t} else if !*g_debug && strings.HasPrefix(t.Name, \"!\") {\n\t\t\t// these are full package names for disambiguating and pretty\n\t\t\t// printing packages within packages, e.g.\n\t\t\t// !go/ast!ast vs. !github.com/nsf/my/ast!ast\n\t\t\t// another ugly hack, if people are punished in hell for ugly hacks\n\t\t\t// I'm screwed...\n\t\t\temarkIdx := strings.LastIndex(t.Name, \"!\")\n\t\t\tpath := t.Name[1:emarkIdx]\n\t\t\talias := canonical_aliases[path]\n\t\t\tif alias == \"\" {\n\t\t\t\talias = t.Name[emarkIdx+1:]\n\t\t\t}\n\t\t\tfmt.Fprintf(out, alias)\n\t\t} else {\n\t\t\tfmt.Fprintf(out, t.Name)\n\t\t}\n\tcase *ast.ArrayType:\n\t\tal := \"\"\n\t\tif t.Len != nil {\n\t\t\tal = get_array_len(t.Len)\n\t\t}\n\t\tif al != \"\" {\n\t\t\tfmt.Fprintf(out, \"[%s]\", al)\n\t\t} else {\n\t\t\tfmt.Fprintf(out, \"[]\")\n\t\t}\n\t\tpretty_print_type_expr(out, t.Elt, canonical_aliases)\n\tcase *ast.SelectorExpr:\n\t\tpretty_print_type_expr(out, t.X, canonical_aliases)\n\t\tfmt.Fprintf(out, \".%s\", t.Sel.Name)\n\tcase *ast.FuncType:\n\t\tfmt.Fprintf(out, \"func(\")\n\t\tpretty_print_func_field_list(out, t.Params, canonical_aliases)\n\t\tfmt.Fprintf(out, \")\")\n\n\t\tbuf := bytes.NewBuffer(make([]byte, 0, 256))\n\t\tnresults := pretty_print_func_field_list(buf, t.Results, canonical_aliases)\n\t\tif nresults > 0 {\n\t\t\tresults := buf.String()\n\t\t\tif strings.IndexAny(results, \", \") != -1 {\n\t\t\t\tresults = \"(\" + results + \")\"\n\t\t\t}\n\t\t\tfmt.Fprintf(out, \" %s\", results)\n\t\t}\n\tcase *ast.MapType:\n\t\tfmt.Fprintf(out, \"map[\")\n\t\tpretty_print_type_expr(out, t.Key, canonical_aliases)\n\t\tfmt.Fprintf(out, \"]\")\n\t\tpretty_print_type_expr(out, t.Value, canonical_aliases)\n\tcase *ast.InterfaceType:\n\t\tfmt.Fprintf(out, \"interface{}\")\n\tcase *ast.Ellipsis:\n\t\tfmt.Fprintf(out, \"...\")\n\t\tpretty_print_type_expr(out, t.Elt, canonical_aliases)\n\tcase *ast.StructType:\n\t\tfmt.Fprintf(out, \"struct\")\n\tcase *ast.ChanType:\n\t\tswitch t.Dir {\n\t\tcase ast.RECV:\n\t\t\tfmt.Fprintf(out, \"<-chan \")\n\t\tcase ast.SEND:\n\t\t\tfmt.Fprintf(out, \"chan<- \")\n\t\tcase ast.SEND | ast.RECV:\n\t\t\tfmt.Fprintf(out, \"chan \")\n\t\t}\n\t\tpretty_print_type_expr(out, t.Value, canonical_aliases)\n\tcase *ast.ParenExpr:\n\t\tfmt.Fprintf(out, \"(\")\n\t\tpretty_print_type_expr(out, t.X, canonical_aliases)\n\t\tfmt.Fprintf(out, \")\")\n\tcase *ast.BadExpr:\n\t\t// TODO: probably I should check that in a separate function\n\t\t// and simply discard declarations with BadExpr as a part of their\n\t\t// type\n\tdefault:\n\t\t// the element has some weird type, just ignore it\n\t}\n}\n\nfunc pretty_print_func_field_list(out io.Writer, f *ast.FieldList, canonical_aliases map[string]string) int {\n\tcount := 0\n\tif f == nil {\n\t\treturn count\n\t}\n\tfor i, field := range f.List {\n\t\t// names\n\t\tif field.Names != nil {\n\t\t\thasNonblank := false\n\t\t\tfor j, name := range field.Names {\n\t\t\t\tif name.Name != \"?\" {\n\t\t\t\t\thasNonblank = true\n\t\t\t\t\tfmt.Fprintf(out, \"%s\", name.Name)\n\t\t\t\t\tif j != len(field.Names)-1 {\n\t\t\t\t\t\tfmt.Fprintf(out, \", \")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcount++\n\t\t\t}\n\t\t\tif hasNonblank {\n\t\t\t\tfmt.Fprintf(out, \" \")\n\t\t\t}\n\t\t} else {\n\t\t\tcount++\n\t\t}\n\n\t\t// type\n\t\tpretty_print_type_expr(out, field.Type, canonical_aliases)\n\n\t\t// ,\n\t\tif i != len(f.List)-1 {\n\t\t\tfmt.Fprintf(out, \", \")\n\t\t}\n\t}\n\treturn count\n}\n\nfunc ast_decl_names(d ast.Decl) []*ast.Ident {\n\tvar names []*ast.Ident\n\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.CONST:\n\t\t\tc := t.Specs[0].(*ast.ValueSpec)\n\t\t\tnames = make([]*ast.Ident, len(c.Names))\n\t\t\tfor i, name := range c.Names {\n\t\t\t\tnames[i] = name\n\t\t\t}\n\t\tcase token.TYPE:\n\t\t\tt := t.Specs[0].(*ast.TypeSpec)\n\t\t\tnames = make([]*ast.Ident, 1)\n\t\t\tnames[0] = t.Name\n\t\tcase token.VAR:\n\t\t\tv := t.Specs[0].(*ast.ValueSpec)\n\t\t\tnames = make([]*ast.Ident, len(v.Names))\n\t\t\tfor i, name := range v.Names {\n\t\t\t\tnames[i] = name\n\t\t\t}\n\t\t}\n\tcase *ast.FuncDecl:\n\t\tnames = make([]*ast.Ident, 1)\n\t\tnames[0] = t.Name\n\t}\n\n\treturn names\n}\n\nfunc ast_decl_values(d ast.Decl) []ast.Expr {\n\t// TODO: CONST values here too\n\tswitch t := d.(type) {\n\tcase *ast.GenDecl:\n\t\tswitch t.Tok {\n\t\tcase token.VAR:\n\t\t\tv := t.Specs[0].(*ast.ValueSpec)\n\t\t\tif v.Values != nil {\n\t\t\t\treturn v.Values\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc ast_decl_split(d ast.Decl) []ast.Decl {\n\tvar decls []ast.Decl\n\tif t, ok := d.(*ast.GenDecl); ok {\n\t\tdecls = make([]ast.Decl, len(t.Specs))\n\t\tfor i, s := range t.Specs {\n\t\t\tdecl := new(ast.GenDecl)\n\t\t\t*decl = *t\n\t\t\tdecl.Specs = make([]ast.Spec, 1)\n\t\t\tdecl.Specs[0] = s\n\t\t\tdecls[i] = decl\n\t\t}\n\t} else {\n\t\tdecls = make([]ast.Decl, 1)\n\t\tdecls[0] = d\n\t}\n\treturn decls\n}\n\n//-------------------------------------------------------------------------\n// decl_pack\n//-------------------------------------------------------------------------\n\ntype decl_pack struct {\n\tnames  []*ast.Ident\n\ttyp    ast.Expr\n\tvalues []ast.Expr\n}\n\ntype foreach_decl_struct struct {\n\tdecl_pack\n\tdecl ast.Decl\n}\n\nfunc (f *decl_pack) value(i int) ast.Expr {\n\tif f.values == nil {\n\t\treturn nil\n\t}\n\tif len(f.values) > 1 {\n\t\treturn f.values[i]\n\t}\n\treturn f.values[0]\n}\n\nfunc (f *decl_pack) value_index(i int) (v ast.Expr, vi int) {\n\t// default: nil value\n\tv = nil\n\tvi = -1\n\n\tif f.values != nil {\n\t\t// A = B, if there is only one name, the value is solo too\n\t\tif len(f.names) == 1 {\n\t\t\treturn f.values[0], -1\n\t\t}\n\n\t\tif len(f.values) > 1 {\n\t\t\t// in case if there are multiple values, it's a usual\n\t\t\t// multiassignment\n\t\t\tif i >= len(f.values) {\n\t\t\t\ti = len(f.values) - 1\n\t\t\t}\n\t\t\tv = f.values[i]\n\t\t} else {\n\t\t\t// in case if there is one value, but many names, it's\n\t\t\t// a tuple unpack.. use index here\n\t\t\tv = f.values[0]\n\t\t\tvi = i\n\t\t}\n\t}\n\treturn\n}\n\nfunc (f *decl_pack) type_value_index(i int) (ast.Expr, ast.Expr, int) {\n\tif f.typ != nil {\n\t\t// If there is a type, we don't care about value, just return the type\n\t\t// and zero value.\n\t\treturn f.typ, nil, -1\n\t}\n\n\t// And otherwise we simply return nil type and a valid value for later inferring.\n\tv, vi := f.value_index(i)\n\treturn nil, v, vi\n}\n\ntype foreach_decl_func func(data *foreach_decl_struct)\n\nfunc foreach_decl(decl ast.Decl, do foreach_decl_func) {\n\tdecls := ast_decl_split(decl)\n\tvar data foreach_decl_struct\n\tfor _, decl := range decls {\n\t\tif !ast_decl_convertable(decl) {\n\t\t\tcontinue\n\t\t}\n\t\tdata.names = ast_decl_names(decl)\n\t\tdata.typ = ast_decl_type(decl)\n\t\tdata.values = ast_decl_values(decl)\n\t\tdata.decl = decl\n\n\t\tdo(&data)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// Built-in declarations\n//-------------------------------------------------------------------------\n\nvar g_universe_scope = new_scope(nil)\n\nfunc init() {\n\tbuiltin := ast.NewIdent(\"built-in\")\n\n\tadd_type := func(name string) {\n\t\td := new_decl(name, decl_type, g_universe_scope)\n\t\td.typ = builtin\n\t\tg_universe_scope.add_named_decl(d)\n\t}\n\tadd_type(\"bool\")\n\tadd_type(\"byte\")\n\tadd_type(\"complex64\")\n\tadd_type(\"complex128\")\n\tadd_type(\"float32\")\n\tadd_type(\"float64\")\n\tadd_type(\"int8\")\n\tadd_type(\"int16\")\n\tadd_type(\"int32\")\n\tadd_type(\"int64\")\n\tadd_type(\"string\")\n\tadd_type(\"uint8\")\n\tadd_type(\"uint16\")\n\tadd_type(\"uint32\")\n\tadd_type(\"uint64\")\n\tadd_type(\"int\")\n\tadd_type(\"uint\")\n\tadd_type(\"uintptr\")\n\tadd_type(\"rune\")\n\n\tadd_const := func(name string) {\n\t\td := new_decl(name, decl_const, g_universe_scope)\n\t\td.typ = builtin\n\t\tg_universe_scope.add_named_decl(d)\n\t}\n\tadd_const(\"true\")\n\tadd_const(\"false\")\n\tadd_const(\"iota\")\n\tadd_const(\"nil\")\n\n\tadd_func := func(name, typ string) {\n\t\td := new_decl(name, decl_func, g_universe_scope)\n\t\td.typ = ast.NewIdent(typ)\n\t\tg_universe_scope.add_named_decl(d)\n\t}\n\tadd_func(\"append\", \"func([]type, ...type) []type\")\n\tadd_func(\"cap\", \"func(container) int\")\n\tadd_func(\"close\", \"func(channel)\")\n\tadd_func(\"complex\", \"func(real, imag) complex\")\n\tadd_func(\"copy\", \"func(dst, src)\")\n\tadd_func(\"delete\", \"func(map[typeA]typeB, typeA)\")\n\tadd_func(\"imag\", \"func(complex)\")\n\tadd_func(\"len\", \"func(container) int\")\n\tadd_func(\"make\", \"func(type, len[, cap]) type\")\n\tadd_func(\"new\", \"func(type) *type\")\n\tadd_func(\"panic\", \"func(interface{})\")\n\tadd_func(\"print\", \"func(...interface{})\")\n\tadd_func(\"println\", \"func(...interface{})\")\n\tadd_func(\"real\", \"func(complex)\")\n\tadd_func(\"recover\", \"func() interface{}\")\n\n\t// built-in error interface\n\td := new_decl(\"error\", decl_type, g_universe_scope)\n\td.typ = &ast.InterfaceType{}\n\td.children = make(map[string]*decl)\n\td.children[\"Error\"] = new_decl(\"Error\", decl_func, g_universe_scope)\n\td.children[\"Error\"].typ = &ast.FuncType{\n\t\tResults: &ast.FieldList{\n\t\t\tList: []*ast.Field{\n\t\t\t\t{\n\t\t\t\t\tType: ast.NewIdent(\"string\"),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tg_universe_scope.add_named_decl(d)\n}\n"
        },
        {
          "name": "declcache.go",
          "type": "blob",
          "size": 14.521484375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/build\"\n\t\"go/parser\"\n\t\"go/token\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"sync\"\n)\n\n//-------------------------------------------------------------------------\n// []package_import\n//-------------------------------------------------------------------------\n\ntype package_import struct {\n\talias   string\n\tabspath string\n\tpath    string\n}\n\n// Parses import declarations until the first non-import declaration and fills\n// `packages` array with import information.\nfunc collect_package_imports(filename string, decls []ast.Decl, context *package_lookup_context) []package_import {\n\tpi := make([]package_import, 0, 16)\n\tfor _, decl := range decls {\n\t\tif gd, ok := decl.(*ast.GenDecl); ok && gd.Tok == token.IMPORT {\n\t\t\tfor _, spec := range gd.Specs {\n\t\t\t\timp := spec.(*ast.ImportSpec)\n\t\t\t\tpath, alias := path_and_alias(imp)\n\t\t\t\tabspath, ok := abs_path_for_package(filename, path, context)\n\t\t\t\tif ok && alias != \"_\" {\n\t\t\t\t\tpi = append(pi, package_import{alias, abspath, path})\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\treturn pi\n}\n\n//-------------------------------------------------------------------------\n// decl_file_cache\n//\n// Contains cache for top-level declarations of a file as well as its\n// contents, AST and import information.\n//-------------------------------------------------------------------------\n\ntype decl_file_cache struct {\n\tname  string // file name\n\tmtime int64  // last modification time\n\n\tdecls     map[string]*decl // top-level declarations\n\terror     error            // last error\n\tpackages  []package_import // import information\n\tfilescope *scope\n\n\tfset    *token.FileSet\n\tcontext *package_lookup_context\n}\n\nfunc new_decl_file_cache(name string, context *package_lookup_context) *decl_file_cache {\n\treturn &decl_file_cache{\n\t\tname:    name,\n\t\tcontext: context,\n\t}\n}\n\nfunc (f *decl_file_cache) update() {\n\tstat, err := os.Stat(f.name)\n\tif err != nil {\n\t\tf.decls = nil\n\t\tf.error = err\n\t\tf.fset = nil\n\t\treturn\n\t}\n\n\tstatmtime := stat.ModTime().UnixNano()\n\tif f.mtime == statmtime {\n\t\treturn\n\t}\n\n\tf.mtime = statmtime\n\tf.read_file()\n}\n\nfunc (f *decl_file_cache) read_file() {\n\tvar data []byte\n\tdata, f.error = file_reader.read_file(f.name)\n\tif f.error != nil {\n\t\treturn\n\t}\n\tdata, _ = filter_out_shebang(data)\n\n\tf.process_data(data)\n}\n\nfunc (f *decl_file_cache) process_data(data []byte) {\n\tvar file *ast.File\n\tf.fset = token.NewFileSet()\n\tfile, f.error = parser.ParseFile(f.fset, \"\", data, 0)\n\tf.filescope = new_scope(nil)\n\tfor _, d := range file.Decls {\n\t\tanonymify_ast(d, 0, f.filescope)\n\t}\n\tf.packages = collect_package_imports(f.name, file.Decls, f.context)\n\tf.decls = make(map[string]*decl, len(file.Decls))\n\tfor _, decl := range file.Decls {\n\t\tappend_to_top_decls(f.decls, decl, f.filescope)\n\t}\n}\n\nfunc append_to_top_decls(decls map[string]*decl, decl ast.Decl, scope *scope) {\n\tforeach_decl(decl, func(data *foreach_decl_struct) {\n\t\tclass := ast_decl_class(data.decl)\n\t\tfor i, name := range data.names {\n\t\t\ttyp, v, vi := data.type_value_index(i)\n\n\t\t\td := new_decl_full(name.Name, class, ast_decl_flags(data.decl), typ, v, vi, scope)\n\t\t\tif d == nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmethodof := method_of(decl)\n\t\t\tif methodof != \"\" {\n\t\t\t\tdecl, ok := decls[methodof]\n\t\t\t\tif ok {\n\t\t\t\t\tdecl.add_child(d)\n\t\t\t\t} else {\n\t\t\t\t\tdecl = new_decl(methodof, decl_methods_stub, scope)\n\t\t\t\t\tdecls[methodof] = decl\n\t\t\t\t\tdecl.add_child(d)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdecl, ok := decls[d.name]\n\t\t\t\tif ok {\n\t\t\t\t\tdecl.expand_or_replace(d)\n\t\t\t\t} else {\n\t\t\t\t\tdecls[d.name] = d\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc abs_path_for_package(filename, p string, context *package_lookup_context) (string, bool) {\n\tdir, _ := filepath.Split(filename)\n\tif len(p) == 0 {\n\t\treturn \"\", false\n\t}\n\tif p[0] == '.' {\n\t\treturn fmt.Sprintf(\"%s.a\", filepath.Join(dir, p)), true\n\t}\n\tpkg, ok := find_go_dag_package(p, dir)\n\tif ok {\n\t\treturn pkg, true\n\t}\n\treturn find_global_file(p, context)\n}\n\nfunc path_and_alias(imp *ast.ImportSpec) (string, string) {\n\tpath := \"\"\n\tif imp.Path != nil && len(imp.Path.Value) > 0 {\n\t\tpath = string(imp.Path.Value)\n\t\tpath = path[1 : len(path)-1]\n\t}\n\talias := \"\"\n\tif imp.Name != nil {\n\t\talias = imp.Name.Name\n\t}\n\treturn path, alias\n}\n\nfunc find_go_dag_package(imp, filedir string) (string, bool) {\n\t// Support godag directory structure\n\tdir, pkg := filepath.Split(imp)\n\tgodag_pkg := filepath.Join(filedir, \"..\", dir, \"_obj\", pkg+\".a\")\n\tif file_exists(godag_pkg) {\n\t\treturn godag_pkg, true\n\t}\n\treturn \"\", false\n}\n\n// autobuild compares the mod time of the source files of the package, and if any of them is newer\n// than the package object file will rebuild it.\nfunc autobuild(p *build.Package) error {\n\tif p.Dir == \"\" {\n\t\treturn fmt.Errorf(\"no files to build\")\n\t}\n\tps, err := os.Stat(p.PkgObj)\n\tif err != nil {\n\t\t// Assume package file does not exist and build for the first time.\n\t\treturn build_package(p)\n\t}\n\tpt := ps.ModTime()\n\tfs, err := readdir_lstat(p.Dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, f := range fs {\n\t\tif f.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tif f.ModTime().After(pt) {\n\t\t\t// Source file is newer than package file; rebuild.\n\t\t\treturn build_package(p)\n\t\t}\n\t}\n\treturn nil\n}\n\n// build_package builds the package by calling `go install package/import`. If everything compiles\n// correctly, the newly compiled package should then be in the usual place in the `$GOPATH/pkg`\n// directory, and gocode will pick it up from there.\nfunc build_package(p *build.Package) error {\n\tif *g_debug {\n\t\tlog.Printf(\"-------------------\")\n\t\tlog.Printf(\"rebuilding package %s\", p.Name)\n\t\tlog.Printf(\"package import: %s\", p.ImportPath)\n\t\tlog.Printf(\"package object: %s\", p.PkgObj)\n\t\tlog.Printf(\"package source dir: %s\", p.Dir)\n\t\tlog.Printf(\"package source files: %v\", p.GoFiles)\n\t\tlog.Printf(\"GOPATH: %v\", g_daemon.context.GOPATH)\n\t\tlog.Printf(\"GOROOT: %v\", g_daemon.context.GOROOT)\n\t}\n\tenv := os.Environ()\n\tfor i, v := range env {\n\t\tif strings.HasPrefix(v, \"GOPATH=\") {\n\t\t\tenv[i] = \"GOPATH=\" + g_daemon.context.GOPATH\n\t\t} else if strings.HasPrefix(v, \"GOROOT=\") {\n\t\t\tenv[i] = \"GOROOT=\" + g_daemon.context.GOROOT\n\t\t}\n\t}\n\n\tcmd := exec.Command(\"go\", \"install\", p.ImportPath)\n\tcmd.Env = env\n\n\t// TODO: Should read STDERR rather than STDOUT.\n\tout, err := cmd.CombinedOutput()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif *g_debug {\n\t\tlog.Printf(\"build out: %s\\n\", string(out))\n\t}\n\treturn nil\n}\n\n// executes autobuild function if autobuild option is enabled, logs error and\n// ignores it\nfunc try_autobuild(p *build.Package) {\n\tif g_config.Autobuild {\n\t\terr := autobuild(p)\n\t\tif err != nil && *g_debug {\n\t\t\tlog.Printf(\"Autobuild error: %s\\n\", err)\n\t\t}\n\t}\n}\n\nfunc log_found_package_maybe(imp, pkgpath string) {\n\tif *g_debug {\n\t\tlog.Printf(\"Found %q at %q\\n\", imp, pkgpath)\n\t}\n}\n\nfunc log_build_context(context *package_lookup_context) {\n\tlog.Printf(\" GOROOT: %s\\n\", context.GOROOT)\n\tlog.Printf(\" GOPATH: %s\\n\", context.GOPATH)\n\tlog.Printf(\" GOOS: %s\\n\", context.GOOS)\n\tlog.Printf(\" GOARCH: %s\\n\", context.GOARCH)\n\tlog.Printf(\" BzlProjectRoot: %q\\n\", context.BzlProjectRoot)\n\tlog.Printf(\" GBProjectRoot: %q\\n\", context.GBProjectRoot)\n\tlog.Printf(\" lib-path: %q\\n\", g_config.LibPath)\n}\n\n// find_global_file returns the file path of the compiled package corresponding to the specified\n// import, and a boolean stating whether such path is valid.\n// TODO: Return only one value, possibly empty string if not found.\nfunc find_global_file(imp string, context *package_lookup_context) (string, bool) {\n\t// gocode synthetically generates the builtin package\n\t// \"unsafe\", since the \"unsafe.a\" package doesn't really exist.\n\t// Thus, when the user request for the package \"unsafe\" we\n\t// would return synthetic global file that would be used\n\t// just as a key name to find this synthetic package\n\tif imp == \"unsafe\" {\n\t\treturn \"unsafe\", true\n\t}\n\n\tpkgfile := fmt.Sprintf(\"%s.a\", imp)\n\n\t// if lib-path is defined, use it\n\tif g_config.LibPath != \"\" {\n\t\tfor _, p := range filepath.SplitList(g_config.LibPath) {\n\t\t\tpkg_path := filepath.Join(p, pkgfile)\n\t\t\tif file_exists(pkg_path) {\n\t\t\t\tlog_found_package_maybe(imp, pkg_path)\n\t\t\t\treturn pkg_path, true\n\t\t\t}\n\t\t\t// Also check the relevant pkg/OS_ARCH dir for the libpath, if provided.\n\t\t\tpkgdir := fmt.Sprintf(\"%s_%s\", context.GOOS, context.GOARCH)\n\t\t\tpkg_path = filepath.Join(p, \"pkg\", pkgdir, pkgfile)\n\t\t\tif file_exists(pkg_path) {\n\t\t\t\tlog_found_package_maybe(imp, pkg_path)\n\t\t\t\treturn pkg_path, true\n\t\t\t}\n\t\t}\n\t}\n\n\t// gb-specific lookup mode, only if the root dir was found\n\tif g_config.PackageLookupMode == \"gb\" && context.GBProjectRoot != \"\" {\n\t\troot := context.GBProjectRoot\n\t\tpkgdir := filepath.Join(root, \"pkg\", context.GOOS+\"-\"+context.GOARCH)\n\t\tif !is_dir(pkgdir) {\n\t\t\tpkgdir = filepath.Join(root, \"pkg\", context.GOOS+\"-\"+context.GOARCH+\"-race\")\n\t\t}\n\t\tpkg_path := filepath.Join(pkgdir, pkgfile)\n\t\tif file_exists(pkg_path) {\n\t\t\tlog_found_package_maybe(imp, pkg_path)\n\t\t\treturn pkg_path, true\n\t\t}\n\t}\n\n\t// bzl-specific lookup mode, only if the root dir was found\n\tif g_config.PackageLookupMode == \"bzl\" && context.BzlProjectRoot != \"\" {\n\t\tvar root, impath string\n\t\tif strings.HasPrefix(imp, g_config.CustomPkgPrefix+\"/\") {\n\t\t\troot = filepath.Join(context.BzlProjectRoot, \"bazel-bin\")\n\t\t\timpath = imp[len(g_config.CustomPkgPrefix)+1:]\n\t\t} else if g_config.CustomVendorDir != \"\" {\n\t\t\t// Try custom vendor dir.\n\t\t\troot = filepath.Join(context.BzlProjectRoot, \"bazel-bin\", g_config.CustomVendorDir)\n\t\t\timpath = imp\n\t\t}\n\n\t\tif root != \"\" && impath != \"\" {\n\t\t\t// There might be more than one \".a\" files in the pkg path with bazel.\n\t\t\t// But the best practice is to keep one go_library build target in each\n\t\t\t// pakcage directory so that it follows the standard Go package\n\t\t\t// structure. Thus here we assume there is at most one \".a\" file existing\n\t\t\t// in the pkg path.\n\t\t\tif d, err := os.Open(filepath.Join(root, impath)); err == nil {\n\t\t\t\tdefer d.Close()\n\n\t\t\t\tif fis, err := d.Readdir(-1); err == nil {\n\t\t\t\t\tfor _, fi := range fis {\n\t\t\t\t\t\tif !fi.IsDir() && filepath.Ext(fi.Name()) == \".a\" {\n\t\t\t\t\t\t\tpkg_path := filepath.Join(root, impath, fi.Name())\n\t\t\t\t\t\t\tlog_found_package_maybe(imp, pkg_path)\n\t\t\t\t\t\t\treturn pkg_path, true\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif context.CurrentPackagePath != \"\" {\n\t\t// Try vendor path first, see GO15VENDOREXPERIMENT.\n\t\t// We don't check this environment variable however, seems like there is\n\t\t// almost no harm in doing so (well.. if you experiment with vendoring,\n\t\t// gocode will fail after enabling/disabling the flag, and you'll be\n\t\t// forced to get rid of vendor binaries). But asking users to set this\n\t\t// env var is up will bring more trouble. Because we also need to pass\n\t\t// it from client to server, make sure their editors set it, etc.\n\t\t// So, whatever, let's just pretend it's always on.\n\t\tpackage_path := context.CurrentPackagePath\n\t\tfor {\n\t\t\tlimp := filepath.Join(package_path, \"vendor\", imp)\n\t\t\tif p, err := context.Import(limp, \"\", build.AllowBinary|build.FindOnly); err == nil {\n\t\t\t\ttry_autobuild(p)\n\t\t\t\tif file_exists(p.PkgObj) {\n\t\t\t\t\tlog_found_package_maybe(imp, p.PkgObj)\n\t\t\t\t\treturn p.PkgObj, true\n\t\t\t\t}\n\t\t\t}\n\t\t\tif package_path == \"\" {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnext_path := filepath.Dir(package_path)\n\t\t\t// let's protect ourselves from inf recursion here\n\t\t\tif next_path == package_path {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpackage_path = next_path\n\t\t}\n\t}\n\n\tif p, err := context.Import(imp, \"\", build.AllowBinary|build.FindOnly); err == nil {\n\t\ttry_autobuild(p)\n\t\tif file_exists(p.PkgObj) {\n\t\t\tlog_found_package_maybe(imp, p.PkgObj)\n\t\t\treturn p.PkgObj, true\n\t\t}\n\t}\n\n\tif *g_debug {\n\t\tlog.Printf(\"Import path %q was not resolved\\n\", imp)\n\t\tlog.Println(\"Gocode's build context is:\")\n\t\tlog_build_context(context)\n\t}\n\treturn \"\", false\n}\n\nfunc package_name(file *ast.File) string {\n\tif file.Name != nil {\n\t\treturn file.Name.Name\n\t}\n\treturn \"\"\n}\n\n//-------------------------------------------------------------------------\n// decl_cache\n//\n// Thread-safe collection of DeclFileCache entities.\n//-------------------------------------------------------------------------\n\ntype package_lookup_context struct {\n\tbuild.Context\n\tBzlProjectRoot     string\n\tGBProjectRoot      string\n\tCurrentPackagePath string\n}\n\n// gopath returns the list of Go path directories.\nfunc (ctxt *package_lookup_context) gopath() []string {\n\tvar all []string\n\tfor _, p := range filepath.SplitList(ctxt.GOPATH) {\n\t\tif p == \"\" || p == ctxt.GOROOT {\n\t\t\t// Empty paths are uninteresting.\n\t\t\t// If the path is the GOROOT, ignore it.\n\t\t\t// People sometimes set GOPATH=$GOROOT.\n\t\t\t// Do not get confused by this common mistake.\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(p, \"~\") {\n\t\t\t// Path segments starting with ~ on Unix are almost always\n\t\t\t// users who have incorrectly quoted ~ while setting GOPATH,\n\t\t\t// preventing it from expanding to $HOME.\n\t\t\t// The situation is made more confusing by the fact that\n\t\t\t// bash allows quoted ~ in $PATH (most shells do not).\n\t\t\t// Do not get confused by this, and do not try to use the path.\n\t\t\t// It does not exist, and printing errors about it confuses\n\t\t\t// those users even more, because they think \"sure ~ exists!\".\n\t\t\t// The go command diagnoses this situation and prints a\n\t\t\t// useful error.\n\t\t\t// On Windows, ~ is used in short names, such as c:\\progra~1\n\t\t\t// for c:\\program files.\n\t\t\tcontinue\n\t\t}\n\t\tall = append(all, p)\n\t}\n\treturn all\n}\n\nfunc (ctxt *package_lookup_context) pkg_dirs() (string, []string) {\n\tpkgdir := fmt.Sprintf(\"%s_%s\", ctxt.GOOS, ctxt.GOARCH)\n\n\tvar currentPackagePath string\n\tvar all []string\n\tif ctxt.GOROOT != \"\" {\n\t\tdir := filepath.Join(ctxt.GOROOT, \"pkg\", pkgdir)\n\t\tif is_dir(dir) {\n\t\t\tall = append(all, dir)\n\t\t}\n\t}\n\n\tswitch g_config.PackageLookupMode {\n\tcase \"go\":\n\t\tcurrentPackagePath = ctxt.CurrentPackagePath\n\t\tfor _, p := range ctxt.gopath() {\n\t\t\tdir := filepath.Join(p, \"pkg\", pkgdir)\n\t\t\tif is_dir(dir) {\n\t\t\t\tall = append(all, dir)\n\t\t\t}\n\t\t\tdir = filepath.Join(dir, currentPackagePath, \"vendor\")\n\t\t\tif is_dir(dir) {\n\t\t\t\tall = append(all, dir)\n\t\t\t}\n\t\t}\n\tcase \"gb\":\n\t\tif ctxt.GBProjectRoot != \"\" {\n\t\t\tpkgdir := fmt.Sprintf(\"%s-%s\", ctxt.GOOS, ctxt.GOARCH)\n\t\t\tif !is_dir(pkgdir) {\n\t\t\t\tpkgdir = fmt.Sprintf(\"%s-%s-race\", ctxt.GOOS, ctxt.GOARCH)\n\t\t\t}\n\t\t\tdir := filepath.Join(ctxt.GBProjectRoot, \"pkg\", pkgdir)\n\t\t\tif is_dir(dir) {\n\t\t\t\tall = append(all, dir)\n\t\t\t}\n\t\t}\n\tcase \"bzl\":\n\t\t// TODO: Support bazel mode\n\t}\n\treturn currentPackagePath, all\n}\n\ntype decl_cache struct {\n\tcache   map[string]*decl_file_cache\n\tcontext *package_lookup_context\n\tsync.Mutex\n}\n\nfunc new_decl_cache(context *package_lookup_context) *decl_cache {\n\treturn &decl_cache{\n\t\tcache:   make(map[string]*decl_file_cache),\n\t\tcontext: context,\n\t}\n}\n\nfunc (c *decl_cache) get(filename string) *decl_file_cache {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tf, ok := c.cache[filename]\n\tif !ok {\n\t\tf = new_decl_file_cache(filename, c.context)\n\t\tc.cache[filename] = f\n\t}\n\treturn f\n}\n\nfunc (c *decl_cache) get_and_update(filename string) *decl_file_cache {\n\tf := c.get(filename)\n\tf.update()\n\treturn f\n}\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "emacs-company",
          "type": "tree",
          "content": null
        },
        {
          "name": "emacs",
          "type": "tree",
          "content": null
        },
        {
          "name": "formatters.go",
          "type": "blob",
          "size": 4.7900390625,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n//-------------------------------------------------------------------------\n// formatter interfaces\n//-------------------------------------------------------------------------\n\ntype formatter interface {\n\twrite_candidates(candidates []candidate, num int)\n}\n\n//-------------------------------------------------------------------------\n// nice_formatter (just for testing, simple textual output)\n//-------------------------------------------------------------------------\n\ntype nice_formatter struct{}\n\nfunc (*nice_formatter) write_candidates(candidates []candidate, num int) {\n\tif candidates == nil {\n\t\tfmt.Printf(\"Nothing to complete.\\n\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"Found %d candidates:\\n\", len(candidates))\n\tfor _, c := range candidates {\n\t\tabbr := fmt.Sprintf(\"%s %s %s\", c.Class, c.Name, c.Type)\n\t\tif c.Class == decl_func {\n\t\t\tabbr = fmt.Sprintf(\"%s %s%s\", c.Class, c.Name, c.Type[len(\"func\"):])\n\t\t}\n\t\tfmt.Printf(\"  %s\\n\", abbr)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// vim_formatter\n//-------------------------------------------------------------------------\n\ntype vim_formatter struct{}\n\nfunc (*vim_formatter) write_candidates(candidates []candidate, num int) {\n\tif candidates == nil {\n\t\tfmt.Print(\"[0, []]\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"[%d, [\", num)\n\tfor i, c := range candidates {\n\t\tif i != 0 {\n\t\t\tfmt.Printf(\", \")\n\t\t}\n\n\t\tword := c.Name\n\t\tif c.Class == decl_func {\n\t\t\tword += \"(\"\n\t\t\tif strings.HasPrefix(c.Type, \"func()\") {\n\t\t\t\tword += \")\"\n\t\t\t}\n\t\t}\n\n\t\tabbr := fmt.Sprintf(\"%s %s %s\", c.Class, c.Name, c.Type)\n\t\tif c.Class == decl_func {\n\t\t\tabbr = fmt.Sprintf(\"%s %s%s\", c.Class, c.Name, c.Type[len(\"func\"):])\n\t\t}\n\t\tfmt.Printf(\"{'word': '%s', 'abbr': '%s', 'info': '%s'}\", word, abbr, abbr)\n\t}\n\tfmt.Printf(\"]]\")\n}\n\n//-------------------------------------------------------------------------\n// godit_formatter\n//-------------------------------------------------------------------------\n\ntype godit_formatter struct{}\n\nfunc (*godit_formatter) write_candidates(candidates []candidate, num int) {\n\tfmt.Printf(\"%d,,%d\\n\", num, len(candidates))\n\tfor _, c := range candidates {\n\t\tcontents := c.Name\n\t\tif c.Class == decl_func {\n\t\t\tcontents += \"(\"\n\t\t\tif strings.HasPrefix(c.Type, \"func()\") {\n\t\t\t\tcontents += \")\"\n\t\t\t}\n\t\t}\n\n\t\tdisplay := fmt.Sprintf(\"%s %s %s\", c.Class, c.Name, c.Type)\n\t\tif c.Class == decl_func {\n\t\t\tdisplay = fmt.Sprintf(\"%s %s%s\", c.Class, c.Name, c.Type[len(\"func\"):])\n\t\t}\n\t\tfmt.Printf(\"%s,,%s\\n\", display, contents)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// emacs_formatter\n//-------------------------------------------------------------------------\n\ntype emacs_formatter struct{}\n\nfunc (*emacs_formatter) write_candidates(candidates []candidate, num int) {\n\tfor _, c := range candidates {\n\t\tvar hint string\n\t\tswitch {\n\t\tcase c.Class == decl_func:\n\t\t\thint = c.Type\n\t\tcase c.Type == \"\":\n\t\t\thint = c.Class.String()\n\t\tdefault:\n\t\t\thint = c.Class.String() + \" \" + c.Type\n\t\t}\n\t\tfmt.Printf(\"%s,,%s\\n\", c.Name, hint)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// csv_formatter\n//-------------------------------------------------------------------------\n\ntype csv_formatter struct{}\n\nfunc (*csv_formatter) write_candidates(candidates []candidate, num int) {\n\tfor _, c := range candidates {\n\t\tfmt.Printf(\"%s,,%s,,%s\\n\", c.Class, c.Name, c.Type)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// csv_with_package_formatter\n//-------------------------------------------------------------------------\n\ntype csv_with_package_formatter struct{}\n\nfunc (*csv_with_package_formatter) write_candidates(candidates []candidate, num int) {\n\tfor _, c := range candidates {\n\t\tfmt.Printf(\"%s,,%s,,%s,,%s\\n\", c.Class, c.Name, c.Type, c.Package)\n\t}\n}\n\n//-------------------------------------------------------------------------\n// json_formatter\n//-------------------------------------------------------------------------\n\ntype json_formatter struct{}\n\nfunc (*json_formatter) write_candidates(candidates []candidate, num int) {\n\tif candidates == nil {\n\t\tfmt.Print(\"[]\")\n\t\treturn\n\t}\n\n\tfmt.Printf(`[%d, [`, num)\n\tfor i, c := range candidates {\n\t\tif i != 0 {\n\t\t\tfmt.Printf(\", \")\n\t\t}\n\t\tfmt.Printf(`{\"class\": \"%s\", \"name\": \"%s\", \"type\": \"%s\", \"package\": \"%s\"}`,\n\t\t\tc.Class, c.Name, c.Type, c.Package)\n\t}\n\tfmt.Print(\"]]\")\n}\n\n//-------------------------------------------------------------------------\n\nfunc get_formatter(name string) formatter {\n\tswitch name {\n\tcase \"vim\":\n\t\treturn new(vim_formatter)\n\tcase \"emacs\":\n\t\treturn new(emacs_formatter)\n\tcase \"nice\":\n\t\treturn new(nice_formatter)\n\tcase \"csv\":\n\t\treturn new(csv_formatter)\n\tcase \"csv-with-package\":\n\t\treturn new(csv_with_package_formatter)\n\tcase \"json\":\n\t\treturn new(json_formatter)\n\tcase \"godit\":\n\t\treturn new(godit_formatter)\n\t}\n\treturn new(nice_formatter)\n}\n"
        },
        {
          "name": "gocode.go",
          "type": "blob",
          "size": 2.3134765625,
          "content": "package main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t_ \"net/http/pprof\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\nvar (\n\tg_is_server = flag.Bool(\"s\", false, \"run a server instead of a client\")\n\tg_format    = flag.String(\"f\", \"nice\", \"output format (vim | emacs | nice | csv | csv-with-package | json)\")\n\tg_input     = flag.String(\"in\", \"\", \"use this file instead of stdin input\")\n\tg_sock      = create_sock_flag(\"sock\", \"socket type (unix | tcp)\")\n\tg_addr      = flag.String(\"addr\", \"127.0.0.1:37373\", \"address for tcp socket\")\n\tg_debug     = flag.Bool(\"debug\", false, \"enable server-side debug mode\")\n\tg_profile   = flag.Int(\"profile\", 0, \"port on which to expose profiling information for pprof; 0 to disable profiling\")\n)\n\nfunc get_socket_filename() string {\n\tuser := os.Getenv(\"USER\")\n\tif user == \"\" {\n\t\tuser = \"all\"\n\t}\n\treturn filepath.Join(os.TempDir(), fmt.Sprintf(\"gocode-daemon.%s\", user))\n}\n\nfunc show_usage() {\n\tfmt.Fprintf(os.Stderr,\n\t\t\"Usage: %s [-s] [-f=<format>] [-in=<path>] [-sock=<type>] [-addr=<addr>]\\n\"+\n\t\t\t\"       <command> [<args>]\\n\\n\",\n\t\tos.Args[0])\n\tfmt.Fprintf(os.Stderr,\n\t\t\"Flags:\\n\")\n\tflag.PrintDefaults()\n\tfmt.Fprintf(os.Stderr,\n\t\t\"\\nCommands:\\n\"+\n\t\t\t\"  autocomplete [<path>] <offset>     main autocompletion command\\n\"+\n\t\t\t\"  close                              close the gocode daemon\\n\"+\n\t\t\t\"  drop-cache                         drop gocode daemon's cache\\n\"+\n\t\t\t\"  options                            list config options (extended)\\n\"+\n\t\t\t\"  set [<name> [<value>]]             list or set config options\\n\"+\n\t\t\t\"  status                             gocode daemon status report\\n\"+\n\t\t\t\"\")\n}\n\nfunc main() {\n\tflag.Usage = show_usage\n\tflag.Parse()\n\n\tvar retval int\n\tif *g_is_server {\n\t\tgo func() {\n\t\t\tif *g_profile <= 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\taddr := fmt.Sprintf(\"localhost:%d\", *g_profile)\n\t\t\t// Use the following commands to profile the binary:\n\t\t\t// go tool pprof http://localhost:6060/debug/pprof/profile   # 30-second CPU profile\n\t\t\t// go tool pprof http://localhost:6060/debug/pprof/heap      # heap profile\n\t\t\t// go tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile\n\t\t\t// See http://blog.golang.org/profiling-go-programs for more info.\n\t\t\tlog.Printf(\"enabling  profiler on %s\", addr)\n\t\t\tlog.Print(http.ListenAndServe(addr, nil))\n\t\t}()\n\t\tretval = do_server()\n\t} else {\n\t\tretval = do_client()\n\t}\n\tos.Exit(retval)\n}\n"
        },
        {
          "name": "nvim",
          "type": "tree",
          "content": null
        },
        {
          "name": "os_posix.go",
          "type": "blob",
          "size": 0.8427734375,
          "content": "// +build !windows\n\npackage main\n\nimport (\n\t\"flag\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n)\n\nfunc create_sock_flag(name, desc string) *string {\n\treturn flag.String(name, \"unix\", desc)\n}\n\n// Full path of the current executable\nfunc get_executable_filename() string {\n\t// try readlink first\n\tpath, err := os.Readlink(\"/proc/self/exe\")\n\tif err == nil {\n\t\treturn path\n\t}\n\t// use argv[0]\n\tpath = os.Args[0]\n\tif !filepath.IsAbs(path) {\n\t\tcwd, _ := os.Getwd()\n\t\tpath = filepath.Join(cwd, path)\n\t}\n\tif file_exists(path) {\n\t\treturn path\n\t}\n\t// Fallback : use \"gocode\" and assume we are in the PATH...\n\tpath, err = exec.LookPath(\"gocode\")\n\tif err == nil {\n\t\treturn path\n\t}\n\treturn \"\"\n}\n\n// config location\n\nfunc config_dir() string {\n\treturn filepath.Join(xdg_home_dir(), \"gocode\")\n}\n\nfunc config_file() string {\n\treturn filepath.Join(xdg_home_dir(), \"gocode\", \"config.json\")\n}\n"
        },
        {
          "name": "os_windows.go",
          "type": "blob",
          "size": 1.2998046875,
          "content": "package main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"path/filepath\"\n\t\"syscall\"\n\t\"unsafe\"\n)\n\nvar (\n\tshell32  = syscall.NewLazyDLL(\"shell32.dll\")\n\tkernel32 = syscall.NewLazyDLL(\"kernel32.dll\")\n)\n\nvar (\n\tproc_sh_get_folder_path   = shell32.NewProc(\"SHGetFolderPathW\")\n\tproc_get_module_file_name = kernel32.NewProc(\"GetModuleFileNameW\")\n)\n\nfunc create_sock_flag(name, desc string) *string {\n\treturn flag.String(name, \"tcp\", desc)\n}\n\n// Full path of the current executable\nfunc get_executable_filename() string {\n\tb := make([]uint16, syscall.MAX_PATH)\n\tret, _, err := syscall.Syscall(proc_get_module_file_name.Addr(), 3,\n\t\t0, uintptr(unsafe.Pointer(&b[0])), uintptr(len(b)))\n\tif int(ret) == 0 {\n\t\tpanic(fmt.Sprintf(\"GetModuleFileNameW : err %d\", int(err)))\n\t}\n\treturn syscall.UTF16ToString(b)\n}\n\nconst (\n\tcsidl_appdata = 0x1a\n)\n\nfunc get_appdata_folder_path() string {\n\tb := make([]uint16, syscall.MAX_PATH)\n\tret, _, err := syscall.Syscall6(proc_sh_get_folder_path.Addr(), 5,\n\t\t0, csidl_appdata, 0, 0, uintptr(unsafe.Pointer(&b[0])), 0)\n\tif int(ret) != 0 {\n\t\tpanic(fmt.Sprintf(\"SHGetFolderPathW : err %d\", int(err)))\n\t}\n\treturn syscall.UTF16ToString(b)\n}\n\nfunc config_dir() string {\n\treturn filepath.Join(get_appdata_folder_path(), \"gocode\")\n}\n\nfunc config_file() string {\n\treturn filepath.Join(get_appdata_folder_path(), \"gocode\", \"config.json\")\n}\n"
        },
        {
          "name": "package.go",
          "type": "blob",
          "size": 5.8125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"os\"\n\t\"strings\"\n)\n\ntype package_parser interface {\n\tparse_export(callback func(pkg string, decl ast.Decl))\n}\n\n//-------------------------------------------------------------------------\n// package_file_cache\n//\n// Structure that represents a cache for an imported pacakge. In other words\n// these are the contents of an archive (*.a) file.\n//-------------------------------------------------------------------------\n\ntype package_file_cache struct {\n\tname        string // file name\n\timport_name string\n\tmtime       int64\n\tdefalias    string\n\n\tscope  *scope\n\tmain   *decl // package declaration\n\tothers map[string]*decl\n}\n\nfunc new_package_file_cache(absname, name string) *package_file_cache {\n\tm := new(package_file_cache)\n\tm.name = absname\n\tm.import_name = name\n\tm.mtime = 0\n\tm.defalias = \"\"\n\treturn m\n}\n\n// Creates a cache that stays in cache forever. Useful for built-in packages.\nfunc new_package_file_cache_forever(name, defalias string) *package_file_cache {\n\tm := new(package_file_cache)\n\tm.name = name\n\tm.mtime = -1\n\tm.defalias = defalias\n\treturn m\n}\n\nfunc (m *package_file_cache) find_file() string {\n\tif file_exists(m.name) {\n\t\treturn m.name\n\t}\n\n\tn := len(m.name)\n\tfilename := m.name[:n-1] + \"6\"\n\tif file_exists(filename) {\n\t\treturn filename\n\t}\n\n\tfilename = m.name[:n-1] + \"8\"\n\tif file_exists(filename) {\n\t\treturn filename\n\t}\n\n\tfilename = m.name[:n-1] + \"5\"\n\tif file_exists(filename) {\n\t\treturn filename\n\t}\n\treturn m.name\n}\n\nfunc (m *package_file_cache) update_cache() {\n\tif m.mtime == -1 {\n\t\treturn\n\t}\n\tfname := m.find_file()\n\tstat, err := os.Stat(fname)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tstatmtime := stat.ModTime().UnixNano()\n\tif m.mtime != statmtime {\n\t\tm.mtime = statmtime\n\n\t\tdata, err := file_reader.read_file(fname)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tm.process_package_data(data)\n\t}\n}\n\nfunc (m *package_file_cache) process_package_data(data []byte) {\n\tm.scope = new_named_scope(g_universe_scope, m.name)\n\n\t// find import section\n\ti := bytes.Index(data, []byte{'\\n', '$', '$'})\n\tif i == -1 {\n\t\tpanic(fmt.Sprintf(\"Can't find the import section in the package file %s\", m.name))\n\t}\n\tdata = data[i+len(\"\\n$$\"):]\n\n\t// main package\n\tm.main = new_decl(m.name, decl_package, nil)\n\t// create map for other packages\n\tm.others = make(map[string]*decl)\n\n\tvar pp package_parser\n\tif data[0] == 'B' {\n\t\t// binary format, skip 'B\\n'\n\t\tdata = data[2:]\n\t\tif len(data) > 0 && data[0] == 'i' {\n\t\t\tvar p gc_ibin_parser\n\t\t\tp.init(data[1:], m)\n\t\t\tpp = &p\n\t\t} else {\n\t\t\tvar p gc_bin_parser\n\t\t\tp.init(data, m)\n\t\t\tpp = &p\n\t\t}\n\t} else {\n\t\t// textual format, find the beginning of the package clause\n\t\ti = bytes.Index(data, []byte{'p', 'a', 'c', 'k', 'a', 'g', 'e'})\n\t\tif i == -1 {\n\t\t\tpanic(\"Can't find the package clause\")\n\t\t}\n\t\tdata = data[i:]\n\n\t\tvar p gc_parser\n\t\tp.init(data, m)\n\t\tpp = &p\n\t}\n\n\tprefix := \"!\" + m.name + \"!\"\n\tpp.parse_export(func(pkg string, decl ast.Decl) {\n\t\tanonymify_ast(decl, decl_foreign, m.scope)\n\t\tif pkg == \"\" || strings.HasPrefix(pkg, prefix) {\n\t\t\t// main package\n\t\t\tadd_ast_decl_to_package(m.main, decl, m.scope)\n\t\t} else {\n\t\t\t// others\n\t\t\tif _, ok := m.others[pkg]; !ok {\n\t\t\t\tm.others[pkg] = new_decl(pkg, decl_package, nil)\n\t\t\t}\n\t\t\tadd_ast_decl_to_package(m.others[pkg], decl, m.scope)\n\t\t}\n\t})\n\n\t// hack, add ourselves to the package scope\n\tmainName := \"!\" + m.name + \"!\" + m.defalias\n\tm.add_package_to_scope(mainName, m.name)\n\n\t// replace dummy package decls in package scope to actual packages\n\tfor key := range m.scope.entities {\n\t\tif !strings.HasPrefix(key, \"!\") {\n\t\t\tcontinue\n\t\t}\n\t\tpkg, ok := m.others[key]\n\t\tif !ok && key == mainName {\n\t\t\tpkg = m.main\n\t\t}\n\t\tm.scope.replace_decl(key, pkg)\n\t}\n}\n\nfunc (m *package_file_cache) add_package_to_scope(alias, realname string) {\n\td := new_decl(realname, decl_package, nil)\n\tm.scope.add_decl(alias, d)\n}\n\nfunc add_ast_decl_to_package(pkg *decl, decl ast.Decl, scope *scope) {\n\tforeach_decl(decl, func(data *foreach_decl_struct) {\n\t\tclass := ast_decl_class(data.decl)\n\t\tfor i, name := range data.names {\n\t\t\ttyp, v, vi := data.type_value_index(i)\n\n\t\t\td := new_decl_full(name.Name, class, decl_foreign|ast_decl_flags(data.decl), typ, v, vi, scope)\n\t\t\tif d == nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !name.IsExported() && d.class != decl_type {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmethodof := method_of(data.decl)\n\t\t\tif methodof != \"\" {\n\t\t\t\tdecl := pkg.find_child(methodof)\n\t\t\t\tif decl != nil {\n\t\t\t\t\tdecl.add_child(d)\n\t\t\t\t} else {\n\t\t\t\t\tdecl = new_decl(methodof, decl_methods_stub, scope)\n\t\t\t\t\tdecl.add_child(d)\n\t\t\t\t\tpkg.add_child(decl)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdecl := pkg.find_child(d.name)\n\t\t\t\tif decl != nil {\n\t\t\t\t\tdecl.expand_or_replace(d)\n\t\t\t\t} else {\n\t\t\t\t\tpkg.add_child(d)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\n//-------------------------------------------------------------------------\n// package_cache\n//-------------------------------------------------------------------------\n\ntype package_cache map[string]*package_file_cache\n\nfunc new_package_cache() package_cache {\n\tm := make(package_cache)\n\n\t// add built-in \"unsafe\" package\n\tm.add_builtin_unsafe_package()\n\n\treturn m\n}\n\n// Function fills 'ps' set with packages from 'packages' import information.\n// In case if package is not in the cache, it creates one and adds one to the cache.\nfunc (c package_cache) append_packages(ps map[string]*package_file_cache, pkgs []package_import) {\n\tfor _, m := range pkgs {\n\t\tif _, ok := ps[m.abspath]; ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tif mod, ok := c[m.abspath]; ok {\n\t\t\tps[m.abspath] = mod\n\t\t} else {\n\t\t\tmod = new_package_file_cache(m.abspath, m.path)\n\t\t\tps[m.abspath] = mod\n\t\t\tc[m.abspath] = mod\n\t\t}\n\t}\n}\n\nvar g_builtin_unsafe_package = []byte(`\nimport\n$$\npackage unsafe\n\ttype @\"\".Pointer uintptr\n\tfunc @\"\".Offsetof (? any) uintptr\n\tfunc @\"\".Sizeof (? any) uintptr\n\tfunc @\"\".Alignof (? any) uintptr\n\n$$\n`)\n\nfunc (c package_cache) add_builtin_unsafe_package() {\n\tpkg := new_package_file_cache_forever(\"unsafe\", \"unsafe\")\n\tpkg.process_package_data(g_builtin_unsafe_package)\n\tc[\"unsafe\"] = pkg\n}\n"
        },
        {
          "name": "package_bin.go",
          "type": "blob",
          "size": 19.240234375,
          "content": "package main\n\nimport (\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/token\"\n\t\"strconv\"\n\t\"strings\"\n\t\"unicode\"\n\t\"unicode/utf8\"\n)\n\n//-------------------------------------------------------------------------\n// gc_bin_parser\n//\n// The following part of the code may contain portions of the code from the Go\n// standard library, which tells me to retain their copyright notice:\n//\n// Copyright (c) 2012 The Go Authors. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//-------------------------------------------------------------------------\n\ntype gc_bin_parser struct {\n\tdata    []byte\n\tbuf     []byte // for reading strings\n\tversion int    // export format version\n\n\t// object lists\n\tstrList       []string   // in order of appearance\n\tpathList      []string   // in order of appearance\n\tpkgList       []string   // in order of appearance\n\ttypList       []ast.Expr // in order of appearance\n\tcallback      func(pkg string, decl ast.Decl)\n\tpfc           *package_file_cache\n\ttrackAllTypes bool\n\n\t// position encoding\n\tposInfoFormat bool\n\tprevFile      string\n\tprevLine      int\n\n\t// debugging support\n\tdebugFormat bool\n\tread        int // bytes read\n\n}\n\nfunc (p *gc_bin_parser) init(data []byte, pfc *package_file_cache) {\n\tp.data = data\n\tp.version = -1            // unknown version\n\tp.strList = []string{\"\"}  // empty string is mapped to 0\n\tp.pathList = []string{\"\"} // empty string is mapped to 0\n\tp.pfc = pfc\n}\n\nfunc (p *gc_bin_parser) parse_export(callback func(string, ast.Decl)) {\n\tp.callback = callback\n\n\t// read version info\n\tvar versionstr string\n\tif b := p.rawByte(); b == 'c' || b == 'd' {\n\t\t// Go1.7 encoding; first byte encodes low-level\n\t\t// encoding format (compact vs debug).\n\t\t// For backward-compatibility only (avoid problems with\n\t\t// old installed packages). Newly compiled packages use\n\t\t// the extensible format string.\n\t\t// TODO(gri) Remove this support eventually; after Go1.8.\n\t\tif b == 'd' {\n\t\t\tp.debugFormat = true\n\t\t}\n\t\tp.trackAllTypes = p.rawByte() == 'a'\n\t\tp.posInfoFormat = p.int() != 0\n\t\tversionstr = p.string()\n\t\tif versionstr == \"v1\" {\n\t\t\tp.version = 0\n\t\t}\n\t} else {\n\t\t// Go1.8 extensible encoding\n\t\t// read version string and extract version number (ignore anything after the version number)\n\t\tversionstr = p.rawStringln(b)\n\t\tif s := strings.SplitN(versionstr, \" \", 3); len(s) >= 2 && s[0] == \"version\" {\n\t\t\tif v, err := strconv.Atoi(s[1]); err == nil && v > 0 {\n\t\t\t\tp.version = v\n\t\t\t}\n\t\t}\n\t}\n\n\t// read version specific flags - extend as necessary\n\tswitch p.version {\n\tcase 6, 5, 4, 3, 2, 1:\n\t\tp.debugFormat = p.rawStringln(p.rawByte()) == \"debug\"\n\t\tp.trackAllTypes = p.int() != 0\n\t\tp.posInfoFormat = p.int() != 0\n\tcase 0:\n\t\t// Go1.7 encoding format - nothing to do here\n\tdefault:\n\t\tpanic(fmt.Errorf(\"unknown export format version %d (%q)\", p.version, versionstr))\n\t}\n\n\t// --- generic export data ---\n\n\t// populate typList with predeclared \"known\" types\n\tp.typList = append(p.typList, predeclared...)\n\n\t// read package data\n\tpkgName := p.pkg()\n\tp.pfc.defalias = pkgName[strings.LastIndex(pkgName, \"!\")+1:]\n\n\t// read objects of phase 1 only (see cmd/compiler/internal/gc/bexport.go)\n\tobjcount := 0\n\tfor {\n\t\ttag := p.tagOrIndex()\n\t\tif tag == endTag {\n\t\t\tbreak\n\t\t}\n\t\tp.obj(tag)\n\t\tobjcount++\n\t}\n\n\t// self-verification\n\tif count := p.int(); count != objcount {\n\t\tpanic(fmt.Sprintf(\"got %d objects; want %d\", objcount, count))\n\t}\n}\n\nfunc (p *gc_bin_parser) pkg() string {\n\t// if the package was seen before, i is its index (>= 0)\n\ti := p.tagOrIndex()\n\tif i >= 0 {\n\t\treturn p.pkgList[i]\n\t}\n\n\t// otherwise, i is the package tag (< 0)\n\tif i != packageTag {\n\t\tpanic(fmt.Sprintf(\"unexpected package tag %d version %d\", i, p.version))\n\t}\n\n\t// read package data\n\tname := p.string()\n\tvar path string\n\tif p.version >= 5 {\n\t\tpath = p.path()\n\t} else {\n\t\tpath = p.string()\n\t}\n\tif p.version >= 6 {\n\t\tp.int() // package height; unused by go/types\n\t}\n\n\t// we should never see an empty package name\n\tif name == \"\" {\n\t\tpanic(\"empty package name in import\")\n\t}\n\n\t// an empty path denotes the package we are currently importing;\n\t// it must be the first package we see\n\tif (path == \"\") != (len(p.pkgList) == 0) {\n\t\tpanic(fmt.Sprintf(\"package path %q for pkg index %d\", path, len(p.pkgList)))\n\t}\n\n\tvar fullName string\n\tif path != \"\" {\n\t\tfullName = \"!\" + path + \"!\" + name\n\t\tp.pfc.add_package_to_scope(fullName, path)\n\t} else {\n\t\tfullName = \"!\" + p.pfc.name + \"!\" + name\n\t}\n\n\t// if the package was imported before, use that one; otherwise create a new one\n\tp.pkgList = append(p.pkgList, fullName)\n\treturn p.pkgList[len(p.pkgList)-1]\n}\n\nfunc (p *gc_bin_parser) obj(tag int) {\n\tswitch tag {\n\tcase constTag:\n\t\tp.pos()\n\t\tpkg, name := p.qualifiedName()\n\t\ttyp := p.typ(\"\")\n\t\tp.skipValue() // ignore const value, gocode's not interested\n\t\tp.callback(pkg, &ast.GenDecl{\n\t\t\tTok: token.CONST,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.ValueSpec{\n\t\t\t\t\tNames:  []*ast.Ident{ast.NewIdent(name)},\n\t\t\t\t\tType:   typ,\n\t\t\t\t\tValues: []ast.Expr{&ast.BasicLit{Kind: token.INT, Value: \"0\"}},\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\tcase aliasTag:\n\t\t// TODO(gri) verify type alias hookup is correct\n\t\tp.pos()\n\t\tpkg, name := p.qualifiedName()\n\t\ttyp := p.typ(\"\")\n\t\tp.callback(pkg, &ast.GenDecl{\n\t\t\tTok:   token.TYPE,\n\t\t\tSpecs: []ast.Spec{typeAliasSpec(name, typ)},\n\t\t})\n\n\tcase typeTag:\n\t\t_ = p.typ(\"\")\n\n\tcase varTag:\n\t\tp.pos()\n\t\tpkg, name := p.qualifiedName()\n\t\ttyp := p.typ(\"\")\n\t\tp.callback(pkg, &ast.GenDecl{\n\t\t\tTok: token.VAR,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.ValueSpec{\n\t\t\t\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\t\t\t\tType:  typ,\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\tcase funcTag:\n\t\tp.pos()\n\t\tpkg, name := p.qualifiedName()\n\t\tparams := p.paramList()\n\t\tresults := p.paramList()\n\t\tp.callback(pkg, &ast.FuncDecl{\n\t\t\tName: ast.NewIdent(name),\n\t\t\tType: &ast.FuncType{Params: params, Results: results},\n\t\t})\n\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected object tag %d\", tag))\n\t}\n}\n\nconst deltaNewFile = -64 // see cmd/compile/internal/gc/bexport.go\n\nfunc (p *gc_bin_parser) pos() {\n\tif !p.posInfoFormat {\n\t\treturn\n\t}\n\n\tfile := p.prevFile\n\tline := p.prevLine\n\tdelta := p.int()\n\tline += delta\n\tif p.version >= 5 {\n\t\tif delta == deltaNewFile {\n\t\t\tif n := p.int(); n >= 0 {\n\t\t\t\t// file changed\n\t\t\t\tfile = p.path()\n\t\t\t\tline = n\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif delta == 0 {\n\t\t\tif n := p.int(); n >= 0 {\n\t\t\t\t// file changed\n\t\t\t\tfile = p.prevFile[:n] + p.string()\n\t\t\t\tline = p.int()\n\t\t\t}\n\t\t}\n\t}\n\tp.prevFile = file\n\tp.prevLine = line\n\n\t// TODO(gri) register new position\n}\n\nfunc (p *gc_bin_parser) qualifiedName() (pkg string, name string) {\n\tname = p.string()\n\tpkg = p.pkg()\n\treturn pkg, name\n}\n\nfunc (p *gc_bin_parser) reserveMaybe() int {\n\tif p.trackAllTypes {\n\t\tp.typList = append(p.typList, nil)\n\t\treturn len(p.typList) - 1\n\t} else {\n\t\treturn -1\n\t}\n}\n\nfunc (p *gc_bin_parser) recordMaybe(idx int, t ast.Expr) ast.Expr {\n\tif idx == -1 {\n\t\treturn t\n\t}\n\tp.typList[idx] = t\n\treturn t\n}\n\nfunc (p *gc_bin_parser) record(t ast.Expr) {\n\tp.typList = append(p.typList, t)\n}\n\n// parent is the package which declared the type; parent == nil means\n// the package currently imported. The parent package is needed for\n// exported struct fields and interface methods which don't contain\n// explicit package information in the export data.\nfunc (p *gc_bin_parser) typ(parent string) ast.Expr {\n\t// if the type was seen before, i is its index (>= 0)\n\ti := p.tagOrIndex()\n\tif i >= 0 {\n\t\treturn p.typList[i]\n\t}\n\n\t// otherwise, i is the type tag (< 0)\n\tswitch i {\n\tcase namedTag:\n\t\t// read type object\n\t\tp.pos()\n\t\tparent, name := p.qualifiedName()\n\t\ttdecl := &ast.GenDecl{\n\t\t\tTok: token.TYPE,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.TypeSpec{\n\t\t\t\t\tName: ast.NewIdent(name),\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\t// record it right away (underlying type can contain refs to t)\n\t\tt := &ast.SelectorExpr{X: ast.NewIdent(parent), Sel: ast.NewIdent(name)}\n\t\tp.record(t)\n\n\t\t// parse underlying type\n\t\tt0 := p.typ(parent)\n\t\ttdecl.Specs[0].(*ast.TypeSpec).Type = t0\n\n\t\tp.callback(parent, tdecl)\n\n\t\t// interfaces have no methods\n\t\tif _, ok := t0.(*ast.InterfaceType); ok {\n\t\t\treturn t\n\t\t}\n\n\t\t// read associated methods\n\t\tfor i := p.int(); i > 0; i-- {\n\t\t\t// TODO(gri) replace this with something closer to fieldName\n\t\t\tp.pos()\n\t\t\tname := p.string()\n\t\t\tif !exported(name) {\n\t\t\t\tp.pkg()\n\t\t\t}\n\n\t\t\trecv := p.paramList()\n\t\t\tparams := p.paramList()\n\t\t\tresults := p.paramList()\n\t\t\tp.int() // go:nointerface pragma - discarded\n\n\t\t\tstrip_method_receiver(recv)\n\t\t\tp.callback(parent, &ast.FuncDecl{\n\t\t\t\tRecv: recv,\n\t\t\t\tName: ast.NewIdent(name),\n\t\t\t\tType: &ast.FuncType{Params: params, Results: results},\n\t\t\t})\n\t\t}\n\t\treturn t\n\tcase arrayTag:\n\t\ti := p.reserveMaybe()\n\t\tn := p.int64()\n\t\telt := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.ArrayType{\n\t\t\tLen: &ast.BasicLit{Kind: token.INT, Value: fmt.Sprint(n)},\n\t\t\tElt: elt,\n\t\t})\n\n\tcase sliceTag:\n\t\ti := p.reserveMaybe()\n\t\telt := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.ArrayType{Len: nil, Elt: elt})\n\n\tcase dddTag:\n\t\ti := p.reserveMaybe()\n\t\telt := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.Ellipsis{Elt: elt})\n\n\tcase structTag:\n\t\ti := p.reserveMaybe()\n\t\treturn p.recordMaybe(i, p.structType(parent))\n\n\tcase pointerTag:\n\t\ti := p.reserveMaybe()\n\t\telt := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.StarExpr{X: elt})\n\n\tcase signatureTag:\n\t\ti := p.reserveMaybe()\n\t\tparams := p.paramList()\n\t\tresults := p.paramList()\n\t\treturn p.recordMaybe(i, &ast.FuncType{Params: params, Results: results})\n\n\tcase interfaceTag:\n\t\ti := p.reserveMaybe()\n\t\tvar embeddeds []*ast.SelectorExpr\n\t\tfor n := p.int(); n > 0; n-- {\n\t\t\tp.pos()\n\t\t\tif named, ok := p.typ(parent).(*ast.SelectorExpr); ok {\n\t\t\t\tembeddeds = append(embeddeds, named)\n\t\t\t}\n\t\t}\n\t\tmethods := p.methodList(parent)\n\t\tfor _, field := range embeddeds {\n\t\t\tmethods = append(methods, &ast.Field{Type: field})\n\t\t}\n\t\treturn p.recordMaybe(i, &ast.InterfaceType{Methods: &ast.FieldList{List: methods}})\n\n\tcase mapTag:\n\t\ti := p.reserveMaybe()\n\t\tkey := p.typ(parent)\n\t\tval := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.MapType{Key: key, Value: val})\n\n\tcase chanTag:\n\t\ti := p.reserveMaybe()\n\t\tdir := ast.SEND | ast.RECV\n\t\tswitch d := p.int(); d {\n\t\tcase 1:\n\t\t\tdir = ast.RECV\n\t\tcase 2:\n\t\t\tdir = ast.SEND\n\t\tcase 3:\n\t\t\t// already set\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unexpected channel dir %d\", d))\n\t\t}\n\t\telt := p.typ(parent)\n\t\treturn p.recordMaybe(i, &ast.ChanType{Dir: dir, Value: elt})\n\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected type tag %d\", i))\n\t}\n}\n\nfunc (p *gc_bin_parser) structType(parent string) *ast.StructType {\n\tvar fields []*ast.Field\n\tif n := p.int(); n > 0 {\n\t\tfields = make([]*ast.Field, n)\n\t\tfor i := range fields {\n\t\t\tfields[i], _ = p.field(parent) // (*ast.Field, tag), not interested in tags\n\t\t}\n\t}\n\treturn &ast.StructType{Fields: &ast.FieldList{List: fields}}\n}\n\nfunc (p *gc_bin_parser) field(parent string) (*ast.Field, string) {\n\tp.pos()\n\t_, name, _ := p.fieldName(parent)\n\ttyp := p.typ(parent)\n\ttag := p.string()\n\n\tvar names []*ast.Ident\n\tif name != \"\" {\n\t\tnames = []*ast.Ident{ast.NewIdent(name)}\n\t}\n\treturn &ast.Field{\n\t\tNames: names,\n\t\tType:  typ,\n\t}, tag\n}\n\nfunc (p *gc_bin_parser) methodList(parent string) (methods []*ast.Field) {\n\tif n := p.int(); n > 0 {\n\t\tmethods = make([]*ast.Field, n)\n\t\tfor i := range methods {\n\t\t\tmethods[i] = p.method(parent)\n\t\t}\n\t}\n\treturn\n}\n\nfunc (p *gc_bin_parser) method(parent string) *ast.Field {\n\tp.pos()\n\t_, name, _ := p.fieldName(parent)\n\tparams := p.paramList()\n\tresults := p.paramList()\n\treturn &ast.Field{\n\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\tType:  &ast.FuncType{Params: params, Results: results},\n\t}\n}\n\nfunc (p *gc_bin_parser) fieldName(parent string) (string, string, bool) {\n\tname := p.string()\n\tpkg := parent\n\tif p.version == 0 && name == \"_\" {\n\t\t// version 0 didn't export a package for _ fields\n\t\treturn pkg, name, false\n\t}\n\tvar alias bool\n\tswitch name {\n\tcase \"\":\n\t\t// 1) field name matches base type name and is exported: nothing to do\n\tcase \"?\":\n\t\t// 2) field name matches base type name and is not exported: need package\n\t\tname = \"\"\n\t\tpkg = p.pkg()\n\tcase \"@\":\n\t\t// 3) field name doesn't match type name (alias)\n\t\tname = p.string()\n\t\talias = true\n\t\tfallthrough\n\tdefault:\n\t\tif !exported(name) {\n\t\t\tpkg = p.pkg()\n\t\t}\n\t}\n\treturn pkg, name, alias\n}\n\nfunc (p *gc_bin_parser) paramList() *ast.FieldList {\n\tn := p.int()\n\tif n == 0 {\n\t\treturn nil\n\t}\n\t// negative length indicates unnamed parameters\n\tnamed := true\n\tif n < 0 {\n\t\tn = -n\n\t\tnamed = false\n\t}\n\t// n > 0\n\tflds := make([]*ast.Field, n)\n\tfor i := range flds {\n\t\tflds[i] = p.param(named)\n\t}\n\treturn &ast.FieldList{List: flds}\n}\n\nfunc (p *gc_bin_parser) param(named bool) *ast.Field {\n\tt := p.typ(\"\")\n\n\tname := \"?\"\n\tif named {\n\t\tname = p.string()\n\t\tif name == \"\" {\n\t\t\tpanic(\"expected named parameter\")\n\t\t}\n\t\tif name != \"_\" {\n\t\t\tp.pkg()\n\t\t}\n\t\tif i := strings.Index(name, \"\"); i > 0 {\n\t\t\tname = name[:i] // cut off gc-specific parameter numbering\n\t\t}\n\t}\n\n\t// read and discard compiler-specific info\n\tp.string()\n\n\treturn &ast.Field{\n\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\tType:  t,\n\t}\n}\n\nfunc exported(name string) bool {\n\tch, _ := utf8.DecodeRuneInString(name)\n\treturn unicode.IsUpper(ch)\n}\n\nfunc (p *gc_bin_parser) skipValue() {\n\tswitch tag := p.tagOrIndex(); tag {\n\tcase falseTag, trueTag:\n\tcase int64Tag:\n\t\tp.int64()\n\tcase floatTag:\n\t\tp.float()\n\tcase complexTag:\n\t\tp.float()\n\t\tp.float()\n\tcase stringTag:\n\t\tp.string()\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected value tag %d\", tag))\n\t}\n}\n\nfunc (p *gc_bin_parser) float() {\n\tsign := p.int()\n\tif sign == 0 {\n\t\treturn\n\t}\n\n\tp.int()    // exp\n\tp.string() // mant\n}\n\n// ----------------------------------------------------------------------------\n// Low-level decoders\n\nfunc (p *gc_bin_parser) tagOrIndex() int {\n\tif p.debugFormat {\n\t\tp.marker('t')\n\t}\n\n\treturn int(p.rawInt64())\n}\n\nfunc (p *gc_bin_parser) int() int {\n\tx := p.int64()\n\tif int64(int(x)) != x {\n\t\tpanic(\"exported integer too large\")\n\t}\n\treturn int(x)\n}\n\nfunc (p *gc_bin_parser) int64() int64 {\n\tif p.debugFormat {\n\t\tp.marker('i')\n\t}\n\n\treturn p.rawInt64()\n}\n\nfunc (p *gc_bin_parser) path() string {\n\tif p.debugFormat {\n\t\tp.marker('p')\n\t}\n\t// if the path was seen before, i is its index (>= 0)\n\t// (the empty string is at index 0)\n\ti := p.rawInt64()\n\tif i >= 0 {\n\t\treturn p.pathList[i]\n\t}\n\t// otherwise, i is the negative path length (< 0)\n\ta := make([]string, -i)\n\tfor n := range a {\n\t\ta[n] = p.string()\n\t}\n\ts := strings.Join(a, \"/\")\n\tp.pathList = append(p.pathList, s)\n\treturn s\n}\n\nfunc (p *gc_bin_parser) string() string {\n\tif p.debugFormat {\n\t\tp.marker('s')\n\t}\n\t// if the string was seen before, i is its index (>= 0)\n\t// (the empty string is at index 0)\n\ti := p.rawInt64()\n\tif i >= 0 {\n\t\treturn p.strList[i]\n\t}\n\t// otherwise, i is the negative string length (< 0)\n\tif n := int(-i); n <= cap(p.buf) {\n\t\tp.buf = p.buf[:n]\n\t} else {\n\t\tp.buf = make([]byte, n)\n\t}\n\tfor i := range p.buf {\n\t\tp.buf[i] = p.rawByte()\n\t}\n\ts := string(p.buf)\n\tp.strList = append(p.strList, s)\n\treturn s\n}\n\nfunc (p *gc_bin_parser) marker(want byte) {\n\tif got := p.rawByte(); got != want {\n\t\tpanic(fmt.Sprintf(\"incorrect marker: got %c; want %c (pos = %d)\", got, want, p.read))\n\t}\n\n\tpos := p.read\n\tif n := int(p.rawInt64()); n != pos {\n\t\tpanic(fmt.Sprintf(\"incorrect position: got %d; want %d\", n, pos))\n\t}\n}\n\n// rawInt64 should only be used by low-level decoders.\nfunc (p *gc_bin_parser) rawInt64() int64 {\n\ti, err := binary.ReadVarint(p)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"read error: %v\", err))\n\t}\n\treturn i\n}\n\n// rawStringln should only be used to read the initial version string.\nfunc (p *gc_bin_parser) rawStringln(b byte) string {\n\tp.buf = p.buf[:0]\n\tfor b != '\\n' {\n\t\tp.buf = append(p.buf, b)\n\t\tb = p.rawByte()\n\t}\n\treturn string(p.buf)\n}\n\n// needed for binary.ReadVarint in rawInt64\nfunc (p *gc_bin_parser) ReadByte() (byte, error) {\n\treturn p.rawByte(), nil\n}\n\n// byte is the bottleneck interface for reading p.data.\n// It unescapes '|' 'S' to '$' and '|' '|' to '|'.\n// rawByte should only be used by low-level decoders.\nfunc (p *gc_bin_parser) rawByte() byte {\n\tb := p.data[0]\n\tr := 1\n\tif b == '|' {\n\t\tb = p.data[1]\n\t\tr = 2\n\t\tswitch b {\n\t\tcase 'S':\n\t\t\tb = '$'\n\t\tcase '|':\n\t\t\t// nothing to do\n\t\tdefault:\n\t\t\tpanic(\"unexpected escape sequence in export data\")\n\t\t}\n\t}\n\tp.data = p.data[r:]\n\tp.read += r\n\treturn b\n\n}\n\n// ----------------------------------------------------------------------------\n// Export format\n\n// Tags. Must be < 0.\nconst (\n\t// Objects\n\tpackageTag = -(iota + 1)\n\tconstTag\n\ttypeTag\n\tvarTag\n\tfuncTag\n\tendTag\n\n\t// Types\n\tnamedTag\n\tarrayTag\n\tsliceTag\n\tdddTag\n\tstructTag\n\tpointerTag\n\tsignatureTag\n\tinterfaceTag\n\tmapTag\n\tchanTag\n\n\t// Values\n\tfalseTag\n\ttrueTag\n\tint64Tag\n\tfloatTag\n\tfractionTag // not used by gc\n\tcomplexTag\n\tstringTag\n\tnilTag     // only used by gc (appears in exported inlined function bodies)\n\tunknownTag // not used by gc (only appears in packages with errors)\n\n\t// Type aliases\n\taliasTag\n)\n\nvar predeclared = []ast.Expr{\n\t// basic types\n\tast.NewIdent(\"bool\"),\n\tast.NewIdent(\"int\"),\n\tast.NewIdent(\"int8\"),\n\tast.NewIdent(\"int16\"),\n\tast.NewIdent(\"int32\"),\n\tast.NewIdent(\"int64\"),\n\tast.NewIdent(\"uint\"),\n\tast.NewIdent(\"uint8\"),\n\tast.NewIdent(\"uint16\"),\n\tast.NewIdent(\"uint32\"),\n\tast.NewIdent(\"uint64\"),\n\tast.NewIdent(\"uintptr\"),\n\tast.NewIdent(\"float32\"),\n\tast.NewIdent(\"float64\"),\n\tast.NewIdent(\"complex64\"),\n\tast.NewIdent(\"complex128\"),\n\tast.NewIdent(\"string\"),\n\n\t// basic type aliases\n\tast.NewIdent(\"byte\"),\n\tast.NewIdent(\"rune\"),\n\n\t// error\n\tast.NewIdent(\"error\"),\n\n\t// TODO(nsf): don't think those are used in just package type info,\n\t// maybe for consts, but we are not interested in that\n\t// untyped types\n\tast.NewIdent(\"&untypedBool&\"),    // TODO: types.Typ[types.UntypedBool],\n\tast.NewIdent(\"&untypedInt&\"),     // TODO: types.Typ[types.UntypedInt],\n\tast.NewIdent(\"&untypedRune&\"),    // TODO: types.Typ[types.UntypedRune],\n\tast.NewIdent(\"&untypedFloat&\"),   // TODO: types.Typ[types.UntypedFloat],\n\tast.NewIdent(\"&untypedComplex&\"), // TODO: types.Typ[types.UntypedComplex],\n\tast.NewIdent(\"&untypedString&\"),  // TODO: types.Typ[types.UntypedString],\n\tast.NewIdent(\"&untypedNil&\"),     // TODO: types.Typ[types.UntypedNil],\n\n\t// package unsafe\n\t&ast.SelectorExpr{X: ast.NewIdent(\"unsafe\"), Sel: ast.NewIdent(\"Pointer\")},\n\n\t// invalid type\n\tast.NewIdent(\">_<\"), // TODO: types.Typ[types.Invalid], // only appears in packages with errors\n\n\t// used internally by gc; never used by this package or in .a files\n\tast.NewIdent(\"any\"),\n}\n"
        },
        {
          "name": "package_ibin.go",
          "type": "blob",
          "size": 14.556640625,
          "content": "package main\n\n//-------------------------------------------------------------------------\n// gc_ibin_parser\n//\n// The following part of the code may contain portions of the code from the Go\n// standard library, which tells me to retain their copyright notice:\n//\n// Copyright (c) 2012 The Go Authors. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//-------------------------------------------------------------------------\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/constant\"\n\t\"go/token\"\n\t\"io\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype intReader struct {\n\t*bytes.Reader\n}\n\nfunc (r *intReader) int64() int64 {\n\ti, err := binary.ReadVarint(r.Reader)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"read varint error: %v\", err))\n\t}\n\treturn i\n}\n\nfunc (r *intReader) uint64() uint64 {\n\ti, err := binary.ReadUvarint(r.Reader)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"read varint error: %v\", err))\n\t}\n\treturn i\n}\n\ntype gc_ibin_parser struct {\n\tdata     []byte\n\tversion  int\n\tcallback func(pkg string, decl ast.Decl)\n\tpfc      *package_file_cache\n\n\tstringData  []byte\n\tstringCache map[uint64]string\n\tdeclData    []byte\n\ttypCache    map[uint64]*ibinType\n\tpkgCache    map[uint64]ibinPackage\n}\n\ntype ibinPackage struct {\n\tfullName string\n\tindex    map[string]uint64\n\tdeclTyp  map[string]*ibinType\n}\n\nfunc (p *gc_ibin_parser) typAt(off uint64) *ibinType {\n\tif t, ok := p.typCache[off]; ok {\n\t\treturn t\n\t}\n\n\tif off < predeclReserved {\n\t\tpanic(fmt.Sprintf(\"predeclared type missing from cache: %v\", off))\n\t}\n\n\tr := &importReader{p: p}\n\tr.declReader.Reset(p.declData[off-predeclReserved:])\n\tt := r.doType()\n\tp.typCache[off] = t\n\treturn t\n}\n\nfunc (p *gc_ibin_parser) stringAt(off uint64) string {\n\tif s, ok := p.stringCache[off]; ok {\n\t\treturn s\n\t}\n\n\tslen, n := binary.Uvarint(p.stringData[off:])\n\tif n <= 0 {\n\t\tpanic(fmt.Sprintf(\"varint failed\"))\n\t}\n\tspos := off + uint64(n)\n\ts := string(p.stringData[spos : spos+slen])\n\tp.stringCache[off] = s\n\treturn s\n}\n\nfunc (p *gc_ibin_parser) pkgAt(off uint64) ibinPackage {\n\tif pkg, ok := p.pkgCache[off]; ok {\n\t\treturn pkg\n\t}\n\tpath := p.stringAt(off)\n\tpanic(fmt.Sprintf(\"missing package %q\", path))\n}\n\nfunc (p *gc_ibin_parser) init(data []byte, pfc *package_file_cache) {\n\tp.data = data\n\tp.version = -1\n\tp.pfc = pfc\n\tp.stringCache = make(map[uint64]string)\n\tp.pkgCache = make(map[uint64]ibinPackage)\n}\n\nfunc (p *gc_ibin_parser) parse_export(callback func(string, ast.Decl)) {\n\tconst currentVersion = 0\n\tp.callback = callback\n\n\tr := &intReader{bytes.NewReader(p.data)}\n\tp.version = int(r.uint64())\n\tif p.version != currentVersion {\n\t\tpanic(fmt.Errorf(\"unknown export format version %d\", p.version))\n\t}\n\n\tsLen := int64(r.uint64())\n\tdLen := int64(r.uint64())\n\twhence, _ := r.Seek(0, io.SeekCurrent)\n\tp.stringData = p.data[whence : whence+sLen]\n\n\tp.declData = p.data[whence+sLen : whence+sLen+dLen]\n\tr.Seek(sLen+dLen, io.SeekCurrent)\n\n\t// built-in types\n\tp.typCache = make(map[uint64]*ibinType)\n\tfor i, pt := range predeclared {\n\t\tp.typCache[uint64(i)] = &ibinType{typ: pt}\n\t}\n\n\tpkgs := make([]ibinPackage, r.uint64())\n\tfor i := range pkgs {\n\t\tpkgPathOff := r.uint64()\n\t\tpkgPath := p.stringAt(pkgPathOff)\n\t\tpkgName := p.stringAt(r.uint64())\n\t\t_ = r.uint64() // package height; unused here\n\n\t\tvar fullName string\n\t\tif pkgPath == \"\" {\n\t\t\t// imported package\n\t\t\tfullName = \"!\" + p.pfc.name + \"!\" + pkgName\n\t\t\tp.pfc.defalias = fullName[strings.LastIndex(fullName, \"!\")+1:]\n\t\t} else {\n\t\t\t// third party import\n\t\t\tfullName = \"!\" + pkgPath + \"!\" + pkgName\n\t\t\tp.pfc.add_package_to_scope(fullName, pkgPath)\n\t\t}\n\n\t\t// list of package entities pointing at decl data by name\n\t\tindex := map[string]uint64{}\n\t\tnSyms := int(r.uint64())\n\t\tfor i := 0; i < nSyms; i++ {\n\t\t\tname := p.stringAt(r.uint64())\n\t\t\tindex[name] = r.uint64()\n\t\t}\n\n\t\tpkg := ibinPackage{fullName, index, make(map[string]*ibinType)}\n\t\tp.pkgCache[pkgPathOff] = pkg\n\t\tpkgs[i] = pkg\n\t}\n\n\tfor _, pkg := range pkgs {\n\t\tnames := make([]string, 0, len(pkg.index))\n\t\tfor name := range pkg.index {\n\t\t\tnames = append(names, name)\n\t\t}\n\t\tsort.Strings(names)\n\t\tfor _, name := range names {\n\t\t\tp.doDecl(pkg, name)\n\t\t}\n\t}\n}\n\nfunc (p *gc_ibin_parser) doDecl(pkg ibinPackage, name string) *ibinType {\n\tif t, ok := pkg.declTyp[name]; ok { // already processed\n\t\treturn t\n\t}\n\n\toff, ok := pkg.index[name]\n\tif !ok {\n\t\tpanic(fmt.Sprintf(\"%q not in %q\", name, pkg.fullName))\n\t}\n\n\tr := &importReader{p: p, currPkg: pkg}\n\tr.declReader.Reset(p.declData[off:])\n\tt := r.obj(name)\n\tpkg.declTyp[name] = t\n\treturn t\n}\n\ntype ibinType struct {\n\ttyp ast.Expr\n\tund *ibinType\n}\n\nfunc (t *ibinType) underlying() ast.Expr {\n\tfor t.und != nil {\n\t\tt = t.und\n\t}\n\treturn t.typ\n}\n\ntype importReader struct {\n\tp          *gc_ibin_parser\n\tdeclReader bytes.Reader\n\tcurrPkg    ibinPackage\n}\n\nfunc (r *importReader) obj(name string) *ibinType {\n\ttag := r.byte()\n\tr.pos()\n\n\tswitch tag {\n\tcase 'A':\n\t\ttyp := r.typ()\n\t\tr.p.callback(r.currPkg.fullName, &ast.GenDecl{\n\t\t\tTok:   token.TYPE,\n\t\t\tSpecs: []ast.Spec{typeAliasSpec(name, typ.typ)},\n\t\t})\n\t\treturn typ\n\tcase 'C':\n\t\ttyp := r.value()\n\t\tr.p.callback(r.currPkg.fullName, &ast.GenDecl{\n\t\t\tTok: token.CONST,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.ValueSpec{\n\t\t\t\t\tNames:  []*ast.Ident{ast.NewIdent(name)},\n\t\t\t\t\tType:   typ.typ,\n\t\t\t\t\tValues: []ast.Expr{&ast.BasicLit{Kind: token.INT, Value: \"0\"}},\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\treturn typ\n\tcase 'F':\n\t\tsig := r.signature()\n\t\tr.p.callback(r.currPkg.fullName, &ast.FuncDecl{\n\t\t\tName: ast.NewIdent(name),\n\t\t\tType: sig,\n\t\t})\n\t\treturn &ibinType{typ: sig}\n\tcase 'T':\n\t\t// Types can be recursive. We need to setup a stub\n\t\t// declaration before recursing.\n\t\tt := &ibinType{typ: &ast.SelectorExpr{X: ast.NewIdent(r.currPkg.fullName), Sel: ast.NewIdent(name)}}\n\t\tr.currPkg.declTyp[name] = t\n\t\tt.und = r.p.typAt(r.uint64())\n\t\tr.p.callback(r.currPkg.fullName, &ast.GenDecl{\n\t\t\tTok: token.TYPE,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.TypeSpec{\n\t\t\t\t\tName: ast.NewIdent(name),\n\t\t\t\t\tType: t.und.typ,\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\t\tif _, ok := t.und.typ.(*ast.InterfaceType); ok { // interfaces cannot have methods\n\t\t\treturn t\n\t\t}\n\n\t\t// read associated methods\n\t\tfor n := r.uint64(); n > 0; n-- {\n\t\t\tr.pos()\n\t\t\tmname := r.ident()\n\t\t\trecv := &ast.FieldList{List: []*ast.Field{r.param()}}\n\t\t\tmsig := r.signature()\n\t\t\tstrip_method_receiver(recv)\n\t\t\tr.p.callback(r.currPkg.fullName, &ast.FuncDecl{\n\t\t\t\tRecv: recv,\n\t\t\t\tName: ast.NewIdent(mname),\n\t\t\t\tType: msig,\n\t\t\t})\n\t\t}\n\t\treturn t\n\n\tcase 'V':\n\t\ttyp := r.typ()\n\t\tr.p.callback(r.currPkg.fullName, &ast.GenDecl{\n\t\t\tTok: token.VAR,\n\t\t\tSpecs: []ast.Spec{\n\t\t\t\t&ast.ValueSpec{\n\t\t\t\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\t\t\t\tType:  typ.typ,\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\treturn typ\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected tag: %v\", tag))\n\t}\n}\n\nconst predeclReserved = 32\n\ntype itag uint64\n\nconst (\n\t// Types\n\tdefinedType itag = iota\n\tpointerType\n\tsliceType\n\tarrayType\n\tchanType\n\tmapType\n\tsignatureType\n\tstructType\n\tinterfaceType\n)\n\n// we don't care about that, let's just skip it\nfunc (r *importReader) pos() {\n\tif r.int64() != deltaNewFile {\n\t} else if l := r.int64(); l == -1 {\n\t} else {\n\t\tr.string()\n\t}\n}\n\nfunc (r *importReader) value() *ibinType {\n\tt := r.typ()\n\ttyp := t.underlying()\n\tident, ok := typ.(*ast.Ident)\n\tif !ok {\n\t\tpanic(fmt.Sprintf(\"unexpected type: %v\", typ))\n\t}\n\n\tswitch ident.Name {\n\tcase \"bool\", \"&untypedBool&\":\n\t\tr.bool()\n\tcase \"int\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint\", \"uint8\", \"uint16\",\n\t\t\"uint32\", \"uint64\", \"uintptr\", \"byte\", \"rune\", \"&untypedInt&\", \"&untypedRune&\":\n\t\tr.mpint(ident)\n\tcase \"float32\", \"float64\", \"&untypedFloat&\":\n\t\tr.mpfloat(ident)\n\tcase \"complex64\", \"complex128\", \"&untypedComplex&\":\n\t\tr.mpfloat(ident)\n\t\tr.mpfloat(ident)\n\tcase \"string\", \"&untypedString&\":\n\t\tr.string()\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected type: %v\", typ))\n\t}\n\treturn t\n}\n\nfunc intSize(typ *ast.Ident) (signed bool, maxBytes uint) {\n\tif typ.Name[0] == '&' { // untyped\n\t\treturn true, 64\n\t}\n\n\tswitch typ.Name {\n\tcase \"float32\", \"complex64\":\n\t\treturn true, 3\n\tcase \"float64\", \"complex128\":\n\t\treturn true, 7\n\tcase \"int8\":\n\t\treturn true, 1\n\tcase \"int16\":\n\t\treturn true, 2\n\tcase \"int32\", \"rune\":\n\t\treturn true, 4\n\tcase \"int64\", \"int\":\n\t\treturn true, 8\n\tcase \"uint8\", \"byte\":\n\t\treturn false, 1\n\tcase \"uint16\":\n\t\treturn false, 2\n\tcase \"uint32\":\n\t\treturn false, 4\n\tcase \"uint64\", \"uint\", \"uintptr\":\n\t\treturn false, 8\n\t}\n\tpanic(fmt.Sprintf(\"unexpected type: %v\", typ))\n}\n\nfunc (r *importReader) mpint(typ *ast.Ident) constant.Value {\n\tsigned, maxBytes := intSize(typ)\n\n\tmaxSmall := 256 - maxBytes\n\tif signed {\n\t\tmaxSmall = 256 - 2*maxBytes\n\t}\n\tif maxBytes == 1 {\n\t\tmaxSmall = 256\n\t}\n\n\tn, _ := r.declReader.ReadByte()\n\tif uint(n) < maxSmall {\n\t\tv := int64(n)\n\t\tif signed {\n\t\t\tv >>= 1\n\t\t\tif n&1 != 0 {\n\t\t\t\tv = ^v\n\t\t\t}\n\t\t}\n\t\treturn constant.MakeInt64(v)\n\t}\n\n\tv := -n\n\tif signed {\n\t\tv = -(n &^ 1) >> 1\n\t}\n\tif v < 1 || uint(v) > maxBytes {\n\t\tpanic(fmt.Sprintf(\"weird decoding: %v, %v => %v\", n, signed, v))\n\t}\n\n\tbuf := make([]byte, v)\n\tio.ReadFull(&r.declReader, buf)\n\n\t// convert to little endian\n\t// TODO(gri) go/constant should have a more direct conversion function\n\t//           (e.g., once it supports a big.Float based implementation)\n\tfor i, j := 0, len(buf)-1; i < j; i, j = i+1, j-1 {\n\t\tbuf[i], buf[j] = buf[j], buf[i]\n\t}\n\n\tx := constant.MakeFromBytes(buf)\n\tif signed && n&1 != 0 {\n\t\tx = constant.UnaryOp(token.SUB, x, 0)\n\t}\n\treturn x\n}\n\nfunc (r *importReader) mpfloat(typ *ast.Ident) {\n\tx := r.mpint(typ)\n\tif constant.Sign(x) == 0 {\n\t\treturn\n\t}\n\tr.int64()\n}\n\nfunc (r *importReader) doType() *ibinType {\n\tk := r.kind()\n\tswitch k {\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unexpected kind tag: %v\", k))\n\tcase definedType:\n\t\tpkg, name := r.qualifiedIdent()\n\t\tr.p.doDecl(pkg, name)\n\t\treturn pkg.declTyp[name]\n\tcase pointerType:\n\t\telt := r.typ()\n\t\treturn &ibinType{typ: &ast.StarExpr{X: elt.typ}}\n\tcase sliceType:\n\t\telt := r.typ()\n\t\treturn &ibinType{typ: &ast.ArrayType{Len: nil, Elt: elt.typ}}\n\tcase arrayType:\n\t\tn := r.uint64()\n\t\telt := r.typ()\n\t\treturn &ibinType{typ: &ast.ArrayType{\n\t\t\tLen: &ast.BasicLit{Kind: token.INT, Value: fmt.Sprint(n)},\n\t\t\tElt: elt.typ,\n\t\t}}\n\tcase chanType:\n\t\tdir := ast.SEND | ast.RECV\n\t\tswitch d := r.uint64(); d {\n\t\tcase 1:\n\t\t\tdir = ast.RECV\n\t\tcase 2:\n\t\t\tdir = ast.SEND\n\t\tcase 3:\n\t\t\t// already set\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unexpected channel dir %d\", d))\n\t\t}\n\t\telt := r.typ()\n\t\treturn &ibinType{typ: &ast.ChanType{Dir: dir, Value: elt.typ}}\n\tcase mapType:\n\t\tkey := r.typ()\n\t\tval := r.typ()\n\t\treturn &ibinType{typ: &ast.MapType{Key: key.typ, Value: val.typ}}\n\tcase signatureType:\n\t\tr.currPkg = r.pkg()\n\t\treturn &ibinType{typ: r.signature()}\n\n\tcase structType:\n\t\tr.currPkg = r.pkg()\n\n\t\tfields := make([]*ast.Field, r.uint64())\n\t\tfor i := range fields {\n\t\t\tr.pos()\n\t\t\tfname := r.ident()\n\t\t\tftyp := r.typ()\n\t\t\temb := r.bool()\n\t\t\tr.string()\n\t\t\tvar names []*ast.Ident\n\t\t\tif fname != \"\" && !emb {\n\t\t\t\tnames = []*ast.Ident{ast.NewIdent(fname)}\n\t\t\t}\n\t\t\tfields[i] = &ast.Field{Names: names, Type: ftyp.typ}\n\t\t}\n\t\treturn &ibinType{typ: &ast.StructType{Fields: &ast.FieldList{List: fields}}}\n\n\tcase interfaceType:\n\t\tr.currPkg = r.pkg()\n\n\t\tnumEmbeds := int(r.uint64())\n\t\tembeddeds := make([]*ast.SelectorExpr, 0, numEmbeds)\n\t\tfor i := 0; i < numEmbeds; i++ {\n\t\t\tr.pos()\n\t\t\tt := r.typ()\n\t\t\tif named, ok := t.typ.(*ast.SelectorExpr); ok {\n\t\t\t\tembeddeds = append(embeddeds, named)\n\t\t\t}\n\t\t}\n\n\t\tmethods := make([]*ast.Field, r.uint64())\n\t\tfor i := range methods {\n\t\t\tr.pos()\n\t\t\tmname := r.ident()\n\t\t\tmsig := r.signature()\n\t\t\tmethods[i] = &ast.Field{\n\t\t\t\tNames: []*ast.Ident{ast.NewIdent(mname)},\n\t\t\t\tType:  msig,\n\t\t\t}\n\t\t}\n\t\tfor _, field := range embeddeds {\n\t\t\tmethods = append(methods, &ast.Field{Type: field})\n\t\t}\n\n\t\treturn &ibinType{typ: &ast.InterfaceType{Methods: &ast.FieldList{List: methods}}}\n\t}\n}\n\nfunc (r *importReader) signature() *ast.FuncType {\n\tparams := r.paramList()\n\tresults := r.paramList()\n\tif params != nil && len(params.List) > 0 {\n\t\tif r.bool() { // variadic flag\n\t\t\tlast := params.List[len(params.List)-1]\n\t\t\tlast.Type = &ast.Ellipsis{Elt: last.Type.(*ast.ArrayType).Elt}\n\t\t}\n\t}\n\treturn &ast.FuncType{Params: params, Results: results}\n}\n\nfunc (r *importReader) paramList() *ast.FieldList {\n\txs := make([]*ast.Field, r.uint64())\n\tfor i := range xs {\n\t\txs[i] = r.param()\n\t}\n\treturn &ast.FieldList{List: xs}\n}\n\nfunc (r *importReader) param() *ast.Field {\n\tr.pos()\n\tname := r.ident()\n\tif name == \"\" { // gocode specific hack for unnamed parameters\n\t\tname = \"?\"\n\t}\n\tt := r.typ()\n\treturn &ast.Field{\n\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\tType:  t.typ,\n\t}\n}\n\nfunc (r *importReader) typ() *ibinType   { return r.p.typAt(r.uint64()) }\nfunc (r *importReader) kind() itag       { return itag(r.uint64()) }\nfunc (r *importReader) pkg() ibinPackage { return r.p.pkgAt(r.uint64()) }\nfunc (r *importReader) string() string   { return r.p.stringAt(r.uint64()) }\nfunc (r *importReader) bool() bool       { return r.uint64() != 0 }\nfunc (r *importReader) ident() string    { return r.string() }\n\nfunc (r *importReader) qualifiedIdent() (ibinPackage, string) {\n\tname := r.string()\n\tpkg := r.pkg()\n\treturn pkg, name\n}\n\nfunc (r *importReader) int64() int64 {\n\tn, err := binary.ReadVarint(&r.declReader)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"readVarint: %v\", err))\n\t}\n\treturn n\n}\n\nfunc (r *importReader) uint64() uint64 {\n\tn, err := binary.ReadUvarint(&r.declReader)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"readUvarint: %v\", err))\n\t}\n\treturn n\n}\n\nfunc (r *importReader) byte() byte {\n\tx, err := r.declReader.ReadByte()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"declReader.ReadByte: %v\", err))\n\t}\n\treturn x\n}\n"
        },
        {
          "name": "package_text.go",
          "type": "blob",
          "size": 16.0390625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/token\"\n\t\"strconv\"\n\t\"text/scanner\"\n)\n\n//-------------------------------------------------------------------------\n// gc_parser\n//\n// The following part of the code may contain portions of the code from the Go\n// standard library, which tells me to retain their copyright notice:\n//\n// Copyright (c) 2009 The Go Authors. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//-------------------------------------------------------------------------\n\ntype gc_parser struct {\n\tscanner      scanner.Scanner\n\ttok          rune\n\tlit          string\n\tpath_to_name map[string]string\n\tbeautify     bool\n\tpfc          *package_file_cache\n}\n\nfunc (p *gc_parser) init(data []byte, pfc *package_file_cache) {\n\tp.scanner.Init(bytes.NewReader(data))\n\tp.scanner.Error = func(_ *scanner.Scanner, msg string) { p.error(msg) }\n\tp.scanner.Mode = scanner.ScanIdents | scanner.ScanInts | scanner.ScanStrings |\n\t\tscanner.ScanComments | scanner.ScanChars | scanner.SkipComments\n\tp.scanner.Whitespace = 1<<'\\t' | 1<<' ' | 1<<'\\r' | 1<<'\\v' | 1<<'\\f'\n\tp.scanner.Filename = \"package.go\"\n\tp.next()\n\t// and the built-in \"unsafe\" package to the path_to_name map\n\tp.path_to_name = map[string]string{\"unsafe\": \"unsafe\"}\n\tp.pfc = pfc\n}\n\nfunc (p *gc_parser) next() {\n\tp.tok = p.scanner.Scan()\n\tswitch p.tok {\n\tcase scanner.Ident, scanner.Int, scanner.String:\n\t\tp.lit = p.scanner.TokenText()\n\tdefault:\n\t\tp.lit = \"\"\n\t}\n}\n\nfunc (p *gc_parser) error(msg string) {\n\tpanic(errors.New(msg))\n}\n\nfunc (p *gc_parser) errorf(format string, args ...interface{}) {\n\tp.error(fmt.Sprintf(format, args...))\n}\n\nfunc (p *gc_parser) expect(tok rune) string {\n\tlit := p.lit\n\tif p.tok != tok {\n\t\tp.errorf(\"expected %s, got %s (%q)\", scanner.TokenString(tok),\n\t\t\tscanner.TokenString(p.tok), lit)\n\t}\n\tp.next()\n\treturn lit\n}\n\nfunc (p *gc_parser) expect_keyword(keyword string) {\n\tlit := p.expect(scanner.Ident)\n\tif lit != keyword {\n\t\tp.errorf(\"expected keyword: %s, got: %q\", keyword, lit)\n\t}\n}\n\nfunc (p *gc_parser) expect_special(what string) {\n\ti := 0\n\tfor i < len(what) {\n\t\tif p.tok != rune(what[i]) {\n\t\t\tbreak\n\t\t}\n\n\t\tnc := p.scanner.Peek()\n\t\tif i != len(what)-1 && nc <= ' ' {\n\t\t\tbreak\n\t\t}\n\n\t\tp.next()\n\t\ti++\n\t}\n\n\tif i < len(what) {\n\t\tp.errorf(\"expected: %q, got: %q\", what, what[0:i])\n\t}\n}\n\n// dotIdentifier = \"?\" | ( ident | '' ) { ident | int | '' } .\n// we're doing lexer job here, kind of\nfunc (p *gc_parser) parse_dot_ident() string {\n\tif p.tok == '?' {\n\t\tp.next()\n\t\treturn \"?\"\n\t}\n\n\tident := \"\"\n\tsep := 'x'\n\ti, j := 0, -1\n\tfor (p.tok == scanner.Ident || p.tok == scanner.Int || p.tok == '') && sep > ' ' {\n\t\tident += p.lit\n\t\tif p.tok == '' {\n\t\t\tident += \"\"\n\t\t\tj = i\n\t\t\ti++\n\t\t}\n\t\ti += len(p.lit)\n\t\tsep = p.scanner.Peek()\n\t\tp.next()\n\t}\n\t// middot = \\xc2\\xb7\n\tif j != -1 && i > j+1 {\n\t\tc := ident[j+2]\n\t\tif c >= '0' && c <= '9' {\n\t\t\tident = ident[0:j]\n\t\t}\n\t}\n\treturn ident\n}\n\n// ImportPath = string_lit .\n// quoted name of the path, but we return it as an identifier, taking an alias\n// from 'pathToAlias' map, it is filled by import statements\nfunc (p *gc_parser) parse_package() *ast.Ident {\n\tpath, err := strconv.Unquote(p.expect(scanner.String))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn ast.NewIdent(path)\n}\n\n// ExportedName = \"@\" ImportPath \".\" dotIdentifier .\nfunc (p *gc_parser) parse_exported_name() *ast.SelectorExpr {\n\tp.expect('@')\n\tpkg := p.parse_package()\n\tif pkg.Name == \"\" {\n\t\tpkg.Name = \"!\" + p.pfc.name + \"!\" + p.pfc.defalias\n\t} else {\n\t\tpkg.Name = p.path_to_name[pkg.Name]\n\t}\n\tp.expect('.')\n\tname := ast.NewIdent(p.parse_dot_ident())\n\treturn &ast.SelectorExpr{X: pkg, Sel: name}\n}\n\n// Name = identifier | \"?\" | ExportedName .\nfunc (p *gc_parser) parse_name() (string, ast.Expr) {\n\tswitch p.tok {\n\tcase scanner.Ident:\n\t\tname := p.lit\n\t\tp.next()\n\t\treturn name, ast.NewIdent(name)\n\tcase '?':\n\t\tp.next()\n\t\treturn \"?\", ast.NewIdent(\"?\")\n\tcase '@':\n\t\ten := p.parse_exported_name()\n\t\treturn en.Sel.Name, en\n\t}\n\tp.error(\"name expected\")\n\treturn \"\", nil\n}\n\n// Field = Name Type [ string_lit ] .\nfunc (p *gc_parser) parse_field() *ast.Field {\n\tvar tag string\n\tname, _ := p.parse_name()\n\ttyp := p.parse_type()\n\tif p.tok == scanner.String {\n\t\ttag = p.expect(scanner.String)\n\t}\n\n\tvar names []*ast.Ident\n\tif name != \"?\" {\n\t\tnames = []*ast.Ident{ast.NewIdent(name)}\n\t}\n\n\treturn &ast.Field{\n\t\tNames: names,\n\t\tType:  typ,\n\t\tTag:   &ast.BasicLit{Kind: token.STRING, Value: tag},\n\t}\n}\n\n// Parameter = ( identifier | \"?\" ) [ \"...\" ] Type [ string_lit ] .\nfunc (p *gc_parser) parse_parameter() *ast.Field {\n\t// name\n\tname, _ := p.parse_name()\n\n\t// type\n\tvar typ ast.Expr\n\tif p.tok == '.' {\n\t\tp.expect_special(\"...\")\n\t\ttyp = &ast.Ellipsis{Elt: p.parse_type()}\n\t} else {\n\t\ttyp = p.parse_type()\n\t}\n\n\tvar tag string\n\tif p.tok == scanner.String {\n\t\ttag = p.expect(scanner.String)\n\t}\n\n\treturn &ast.Field{\n\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\tType:  typ,\n\t\tTag:   &ast.BasicLit{Kind: token.STRING, Value: tag},\n\t}\n}\n\n// Parameters = \"(\" [ ParameterList ] \")\" .\n// ParameterList = { Parameter \",\" } Parameter .\nfunc (p *gc_parser) parse_parameters() *ast.FieldList {\n\tflds := []*ast.Field{}\n\tparse_parameter := func() {\n\t\tpar := p.parse_parameter()\n\t\tflds = append(flds, par)\n\t}\n\n\tp.expect('(')\n\tif p.tok != ')' {\n\t\tparse_parameter()\n\t\tfor p.tok == ',' {\n\t\t\tp.next()\n\t\t\tparse_parameter()\n\t\t}\n\t}\n\tp.expect(')')\n\treturn &ast.FieldList{List: flds}\n}\n\n// Signature = Parameters [ Result ] .\n// Result = Type | Parameters .\nfunc (p *gc_parser) parse_signature() *ast.FuncType {\n\tvar params *ast.FieldList\n\tvar results *ast.FieldList\n\n\tparams = p.parse_parameters()\n\tswitch p.tok {\n\tcase scanner.Ident, '[', '*', '<', '@':\n\t\tfld := &ast.Field{Type: p.parse_type()}\n\t\tresults = &ast.FieldList{List: []*ast.Field{fld}}\n\tcase '(':\n\t\tresults = p.parse_parameters()\n\t}\n\treturn &ast.FuncType{Params: params, Results: results}\n}\n\n// MethodOrEmbedSpec = Name [ Signature ] .\nfunc (p *gc_parser) parse_method_or_embed_spec() *ast.Field {\n\tname, nameexpr := p.parse_name()\n\tif p.tok == '(' {\n\t\ttyp := p.parse_signature()\n\t\treturn &ast.Field{\n\t\t\tNames: []*ast.Ident{ast.NewIdent(name)},\n\t\t\tType:  typ,\n\t\t}\n\t}\n\n\treturn &ast.Field{\n\t\tType: nameexpr,\n\t}\n}\n\n// int_lit = [ \"-\" | \"+\" ] { \"0\" ... \"9\" } .\nfunc (p *gc_parser) parse_int() {\n\tswitch p.tok {\n\tcase '-', '+':\n\t\tp.next()\n\t}\n\tp.expect(scanner.Int)\n}\n\n// number = int_lit [ \"p\" int_lit ] .\nfunc (p *gc_parser) parse_number() {\n\tp.parse_int()\n\tif p.lit == \"p\" {\n\t\tp.next()\n\t\tp.parse_int()\n\t}\n}\n\n//-------------------------------------------------------------------------------\n// gc_parser.types\n//-------------------------------------------------------------------------------\n\n// InterfaceType = \"interface\" \"{\" [ MethodOrEmbedList ] \"}\" .\n// MethodOrEmbedList = MethodOrEmbedSpec { \";\" MethodOrEmbedSpec } .\nfunc (p *gc_parser) parse_interface_type() ast.Expr {\n\tvar methods []*ast.Field\n\tparse_method := func() {\n\t\tmeth := p.parse_method_or_embed_spec()\n\t\tmethods = append(methods, meth)\n\t}\n\n\tp.expect_keyword(\"interface\")\n\tp.expect('{')\n\tif p.tok != '}' {\n\t\tparse_method()\n\t\tfor p.tok == ';' {\n\t\t\tp.next()\n\t\t\tparse_method()\n\t\t}\n\t}\n\tp.expect('}')\n\treturn &ast.InterfaceType{Methods: &ast.FieldList{List: methods}}\n}\n\n// StructType = \"struct\" \"{\" [ FieldList ] \"}\" .\n// FieldList = Field { \";\" Field } .\nfunc (p *gc_parser) parse_struct_type() ast.Expr {\n\tvar fields []*ast.Field\n\tparse_field := func() {\n\t\tfld := p.parse_field()\n\t\tfields = append(fields, fld)\n\t}\n\n\tp.expect_keyword(\"struct\")\n\tp.expect('{')\n\tif p.tok != '}' {\n\t\tparse_field()\n\t\tfor p.tok == ';' {\n\t\t\tp.next()\n\t\t\tparse_field()\n\t\t}\n\t}\n\tp.expect('}')\n\treturn &ast.StructType{Fields: &ast.FieldList{List: fields}}\n}\n\n// MapType = \"map\" \"[\" Type \"]\" Type .\nfunc (p *gc_parser) parse_map_type() ast.Expr {\n\tp.expect_keyword(\"map\")\n\tp.expect('[')\n\tkey := p.parse_type()\n\tp.expect(']')\n\telt := p.parse_type()\n\treturn &ast.MapType{Key: key, Value: elt}\n}\n\n// ChanType = ( \"chan\" [ \"<-\" ] | \"<-\" \"chan\" ) Type .\nfunc (p *gc_parser) parse_chan_type() ast.Expr {\n\tdir := ast.SEND | ast.RECV\n\tif p.tok == scanner.Ident {\n\t\tp.expect_keyword(\"chan\")\n\t\tif p.tok == '<' {\n\t\t\tp.expect_special(\"<-\")\n\t\t\tdir = ast.SEND\n\t\t}\n\t} else {\n\t\tp.expect_special(\"<-\")\n\t\tp.expect_keyword(\"chan\")\n\t\tdir = ast.RECV\n\t}\n\n\telt := p.parse_type()\n\treturn &ast.ChanType{Dir: dir, Value: elt}\n}\n\n// ArrayOrSliceType = ArrayType | SliceType .\n// ArrayType = \"[\" int_lit \"]\" Type .\n// SliceType = \"[\" \"]\" Type .\nfunc (p *gc_parser) parse_array_or_slice_type() ast.Expr {\n\tp.expect('[')\n\tif p.tok == ']' {\n\t\t// SliceType\n\t\tp.next() // skip ']'\n\t\treturn &ast.ArrayType{Len: nil, Elt: p.parse_type()}\n\t}\n\n\t// ArrayType\n\tlit := p.expect(scanner.Int)\n\tp.expect(']')\n\treturn &ast.ArrayType{\n\t\tLen: &ast.BasicLit{Kind: token.INT, Value: lit},\n\t\tElt: p.parse_type(),\n\t}\n}\n\n// Type =\n//\tBasicType | TypeName | ArrayType | SliceType | StructType |\n//      PointerType | FuncType | InterfaceType | MapType | ChanType |\n//      \"(\" Type \")\" .\n// BasicType = ident .\n// TypeName = ExportedName .\n// SliceType = \"[\" \"]\" Type .\n// PointerType = \"*\" Type .\n// FuncType = \"func\" Signature .\nfunc (p *gc_parser) parse_type() ast.Expr {\n\tswitch p.tok {\n\tcase scanner.Ident:\n\t\tswitch p.lit {\n\t\tcase \"struct\":\n\t\t\treturn p.parse_struct_type()\n\t\tcase \"func\":\n\t\t\tp.next()\n\t\t\treturn p.parse_signature()\n\t\tcase \"interface\":\n\t\t\treturn p.parse_interface_type()\n\t\tcase \"map\":\n\t\t\treturn p.parse_map_type()\n\t\tcase \"chan\":\n\t\t\treturn p.parse_chan_type()\n\t\tdefault:\n\t\t\tlit := p.lit\n\t\t\tp.next()\n\t\t\treturn ast.NewIdent(lit)\n\t\t}\n\tcase '@':\n\t\treturn p.parse_exported_name()\n\tcase '[':\n\t\treturn p.parse_array_or_slice_type()\n\tcase '*':\n\t\tp.next()\n\t\treturn &ast.StarExpr{X: p.parse_type()}\n\tcase '<':\n\t\treturn p.parse_chan_type()\n\tcase '(':\n\t\tp.next()\n\t\ttyp := p.parse_type()\n\t\tp.expect(')')\n\t\treturn typ\n\t}\n\tp.errorf(\"unexpected token: %s\", scanner.TokenString(p.tok))\n\treturn nil\n}\n\n//-------------------------------------------------------------------------------\n// gc_parser.declarations\n//-------------------------------------------------------------------------------\n\n// ImportDecl = \"import\" identifier string_lit .\nfunc (p *gc_parser) parse_import_decl() {\n\tp.expect_keyword(\"import\")\n\talias := p.expect(scanner.Ident)\n\tpath := p.parse_package()\n\tfullName := \"!\" + path.Name + \"!\" + alias\n\tp.path_to_name[path.Name] = fullName\n\tp.pfc.add_package_to_scope(fullName, path.Name)\n}\n\n// ConstDecl   = \"const\" ExportedName [ Type ] \"=\" Literal .\n// Literal     = bool_lit | int_lit | float_lit | complex_lit | string_lit .\n// bool_lit    = \"true\" | \"false\" .\n// complex_lit = \"(\" float_lit \"+\" float_lit \")\" .\n// rune_lit    = \"(\" int_lit \"+\" int_lit \")\" .\n// string_lit  = `\"` { unicode_char } `\"` .\nfunc (p *gc_parser) parse_const_decl() (string, *ast.GenDecl) {\n\t// TODO: do we really need actual const value? gocode doesn't use this\n\tp.expect_keyword(\"const\")\n\tname := p.parse_exported_name()\n\n\tvar typ ast.Expr\n\tif p.tok != '=' {\n\t\ttyp = p.parse_type()\n\t}\n\n\tp.expect('=')\n\n\t// skip the value\n\tswitch p.tok {\n\tcase scanner.Ident:\n\t\t// must be bool, true or false\n\t\tp.next()\n\tcase '-', '+', scanner.Int:\n\t\t// number\n\t\tp.parse_number()\n\tcase '(':\n\t\t// complex_lit or rune_lit\n\t\tp.next() // skip '('\n\t\tif p.tok == scanner.Char {\n\t\t\tp.next()\n\t\t} else {\n\t\t\tp.parse_number()\n\t\t}\n\t\tp.expect('+')\n\t\tp.parse_number()\n\t\tp.expect(')')\n\tcase scanner.Char:\n\t\tp.next()\n\tcase scanner.String:\n\t\tp.next()\n\tdefault:\n\t\tp.error(\"expected literal\")\n\t}\n\n\treturn name.X.(*ast.Ident).Name, &ast.GenDecl{\n\t\tTok: token.CONST,\n\t\tSpecs: []ast.Spec{\n\t\t\t&ast.ValueSpec{\n\t\t\t\tNames:  []*ast.Ident{name.Sel},\n\t\t\t\tType:   typ,\n\t\t\t\tValues: []ast.Expr{&ast.BasicLit{Kind: token.INT, Value: \"0\"}},\n\t\t\t},\n\t\t},\n\t}\n}\n\n// TypeDecl = \"type\" ExportedName Type .\nfunc (p *gc_parser) parse_type_decl() (string, *ast.GenDecl) {\n\tp.expect_keyword(\"type\")\n\tname := p.parse_exported_name()\n\ttyp := p.parse_type()\n\treturn name.X.(*ast.Ident).Name, &ast.GenDecl{\n\t\tTok: token.TYPE,\n\t\tSpecs: []ast.Spec{\n\t\t\t&ast.TypeSpec{\n\t\t\t\tName: name.Sel,\n\t\t\t\tType: typ,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// VarDecl = \"var\" ExportedName Type .\nfunc (p *gc_parser) parse_var_decl() (string, *ast.GenDecl) {\n\tp.expect_keyword(\"var\")\n\tname := p.parse_exported_name()\n\ttyp := p.parse_type()\n\treturn name.X.(*ast.Ident).Name, &ast.GenDecl{\n\t\tTok: token.VAR,\n\t\tSpecs: []ast.Spec{\n\t\t\t&ast.ValueSpec{\n\t\t\t\tNames: []*ast.Ident{name.Sel},\n\t\t\t\tType:  typ,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// FuncBody = \"{\" ... \"}\" .\nfunc (p *gc_parser) parse_func_body() {\n\tp.expect('{')\n\tfor i := 1; i > 0; p.next() {\n\t\tswitch p.tok {\n\t\tcase '{':\n\t\t\ti++\n\t\tcase '}':\n\t\t\ti--\n\t\t}\n\t}\n}\n\n// FuncDecl = \"func\" ExportedName Signature [ FuncBody ] .\nfunc (p *gc_parser) parse_func_decl() (string, *ast.FuncDecl) {\n\t// \"func\" was already consumed by lookahead\n\tname := p.parse_exported_name()\n\ttyp := p.parse_signature()\n\tif p.tok == '{' {\n\t\tp.parse_func_body()\n\t}\n\treturn name.X.(*ast.Ident).Name, &ast.FuncDecl{\n\t\tName: name.Sel,\n\t\tType: typ,\n\t}\n}\n\nfunc strip_method_receiver(recv *ast.FieldList) string {\n\tvar sel *ast.SelectorExpr\n\n\t// find selector expression\n\ttyp := recv.List[0].Type\n\tswitch t := typ.(type) {\n\tcase *ast.StarExpr:\n\t\tsel, _ = t.X.(*ast.SelectorExpr)\n\tcase *ast.SelectorExpr:\n\t\tsel = t\n\t}\n\n\t// extract package path\n\tif sel != nil {\n\t\tpkg := sel.X.(*ast.Ident).Name\n\n\t\t// write back stripped type\n\t\tswitch typ.(type) {\n\t\tcase *ast.StarExpr:\n\t\t\t*recv = ast.FieldList{\n\t\t\t\tList: []*ast.Field{{Names: recv.List[0].Names, Type: &ast.StarExpr{X: sel.Sel}}},\n\t\t\t}\n\t\tcase *ast.SelectorExpr:\n\t\t\t*recv = ast.FieldList{\n\t\t\t\tList: []*ast.Field{{Names: recv.List[0].Names, Type: sel.Sel}},\n\t\t\t}\n\t\t}\n\t\treturn pkg\n\t} else {\n\t\treturn \"\"\n\t}\n}\n\n// MethodDecl = \"func\" Receiver Name Signature .\n// Receiver = \"(\" ( identifier | \"?\" ) [ \"*\" ] ExportedName \")\" [ FuncBody ] .\nfunc (p *gc_parser) parse_method_decl() (string, *ast.FuncDecl) {\n\trecv := p.parse_parameters()\n\tpkg := strip_method_receiver(recv)\n\tname, _ := p.parse_name()\n\ttyp := p.parse_signature()\n\tif p.tok == '{' {\n\t\tp.parse_func_body()\n\t}\n\treturn pkg, &ast.FuncDecl{\n\t\tRecv: recv,\n\t\tName: ast.NewIdent(name),\n\t\tType: typ,\n\t}\n}\n\n// Decl = [ ImportDecl | ConstDecl | TypeDecl | VarDecl | FuncDecl | MethodDecl ] \"\\n\" .\nfunc (p *gc_parser) parse_decl() (pkg string, decl ast.Decl) {\n\tswitch p.lit {\n\tcase \"import\":\n\t\tp.parse_import_decl()\n\tcase \"const\":\n\t\tpkg, decl = p.parse_const_decl()\n\tcase \"type\":\n\t\tpkg, decl = p.parse_type_decl()\n\tcase \"var\":\n\t\tpkg, decl = p.parse_var_decl()\n\tcase \"func\":\n\t\tp.next()\n\t\tif p.tok == '(' {\n\t\t\tpkg, decl = p.parse_method_decl()\n\t\t} else {\n\t\t\tpkg, decl = p.parse_func_decl()\n\t\t}\n\t}\n\tp.expect('\\n')\n\treturn\n}\n\n// Export = PackageClause { Decl } \"$$\" .\n// PackageClause = \"package\" identifier [ \"safe\" ] \"\\n\" .\nfunc (p *gc_parser) parse_export(callback func(string, ast.Decl)) {\n\tp.expect_keyword(\"package\")\n\tp.pfc.defalias = p.expect(scanner.Ident)\n\tif p.tok != '\\n' {\n\t\tp.expect_keyword(\"safe\")\n\t}\n\tp.expect('\\n')\n\n\tfor p.tok != '$' && p.tok != scanner.EOF {\n\t\tpkg, decl := p.parse_decl()\n\t\tif decl != nil {\n\t\t\tcallback(pkg, decl)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "pre_go17.go",
          "type": "blob",
          "size": 0.1123046875,
          "content": "// +build !go1.7,!go1.8\n\npackage main\n\nfunc init() {\n\tknownPackageIdents[\"context\"] = \"golang.org/x/net/context\"\n}\n"
        },
        {
          "name": "ripper.go",
          "type": "blob",
          "size": 2.7822265625,
          "content": "package main\n\nimport (\n\t\"go/scanner\"\n\t\"go/token\"\n)\n\n// All the code in this file serves single purpose:\n// It separates a function with the cursor inside and the rest of the code. I'm\n// doing that, because sometimes parser is not able to recover itself from an\n// error and the autocompletion results become less complete.\n\ntype tok_pos_pair struct {\n\ttok token.Token\n\tpos token.Pos\n}\n\ntype tok_collection struct {\n\ttokens []tok_pos_pair\n\tfset   *token.FileSet\n}\n\nfunc (this *tok_collection) next(s *scanner.Scanner) bool {\n\tpos, tok, _ := s.Scan()\n\tif tok == token.EOF {\n\t\treturn false\n\t}\n\n\tthis.tokens = append(this.tokens, tok_pos_pair{tok, pos})\n\treturn true\n}\n\nfunc (this *tok_collection) find_decl_beg(pos int) int {\n\tlowest := 0\n\tlowpos := -1\n\tlowi := -1\n\tcur := 0\n\tfor i := pos; i >= 0; i-- {\n\t\tt := this.tokens[i]\n\t\tswitch t.tok {\n\t\tcase token.RBRACE:\n\t\t\tcur++\n\t\tcase token.LBRACE:\n\t\t\tcur--\n\t\t}\n\n\t\tif cur < lowest {\n\t\t\tlowest = cur\n\t\t\tlowpos = this.fset.Position(t.pos).Offset\n\t\t\tlowi = i\n\t\t}\n\t}\n\n\tcur = lowest\n\tfor i := lowi - 1; i >= 0; i-- {\n\t\tt := this.tokens[i]\n\t\tswitch t.tok {\n\t\tcase token.RBRACE:\n\t\t\tcur++\n\t\tcase token.LBRACE:\n\t\t\tcur--\n\t\t}\n\t\tif t.tok == token.SEMICOLON && cur == lowest {\n\t\t\tlowpos = this.fset.Position(t.pos).Offset\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn lowpos\n}\n\nfunc (this *tok_collection) find_decl_end(pos int) int {\n\thighest := 0\n\thighpos := -1\n\tcur := 0\n\n\tif this.tokens[pos].tok == token.LBRACE {\n\t\tpos++\n\t}\n\n\tfor i := pos; i < len(this.tokens); i++ {\n\t\tt := this.tokens[i]\n\t\tswitch t.tok {\n\t\tcase token.RBRACE:\n\t\t\tcur++\n\t\tcase token.LBRACE:\n\t\t\tcur--\n\t\t}\n\n\t\tif cur > highest {\n\t\t\thighest = cur\n\t\t\thighpos = this.fset.Position(t.pos).Offset\n\t\t}\n\t}\n\n\treturn highpos\n}\n\nfunc (this *tok_collection) find_outermost_scope(cursor int) (int, int) {\n\tpos := 0\n\n\tfor i, t := range this.tokens {\n\t\tif cursor <= this.fset.Position(t.pos).Offset {\n\t\t\tbreak\n\t\t}\n\t\tpos = i\n\t}\n\n\treturn this.find_decl_beg(pos), this.find_decl_end(pos)\n}\n\n// return new cursor position, file without ripped part and the ripped part itself\n// variants:\n//   new-cursor, file-without-ripped-part, ripped-part\n//   old-cursor, file, nil\nfunc (this *tok_collection) rip_off_decl(file []byte, cursor int) (int, []byte, []byte) {\n\tthis.fset = token.NewFileSet()\n\tvar s scanner.Scanner\n\ts.Init(this.fset.AddFile(\"\", this.fset.Base(), len(file)), file, nil, scanner.ScanComments)\n\tfor this.next(&s) {\n\t}\n\n\tbeg, end := this.find_outermost_scope(cursor)\n\tif beg == -1 || end == -1 {\n\t\treturn cursor, file, nil\n\t}\n\n\tripped := make([]byte, end+1-beg)\n\tcopy(ripped, file[beg:end+1])\n\n\tnewfile := make([]byte, len(file)-len(ripped))\n\tcopy(newfile, file[:beg])\n\tcopy(newfile[beg:], file[end+1:])\n\n\treturn cursor - beg, newfile, ripped\n}\n\nfunc rip_off_decl(file []byte, cursor int) (int, []byte, []byte) {\n\tvar tc tok_collection\n\treturn tc.rip_off_decl(file, cursor)\n}\n"
        },
        {
          "name": "rpc.go",
          "type": "blob",
          "size": 3.1689453125,
          "content": "// WARNING! Autogenerated by goremote, don't touch.\n\npackage main\n\nimport (\n\t\"net/rpc\"\n)\n\ntype RPC struct {\n}\n\n// wrapper for: server_auto_complete\n\ntype Args_auto_complete struct {\n\tArg0 []byte\n\tArg1 string\n\tArg2 int\n\tArg3 go_build_context\n}\ntype Reply_auto_complete struct {\n\tArg0 []candidate\n\tArg1 int\n}\n\nfunc (r *RPC) RPC_auto_complete(args *Args_auto_complete, reply *Reply_auto_complete) error {\n\treply.Arg0, reply.Arg1 = server_auto_complete(args.Arg0, args.Arg1, args.Arg2, args.Arg3)\n\treturn nil\n}\nfunc client_auto_complete(cli *rpc.Client, Arg0 []byte, Arg1 string, Arg2 int, Arg3 go_build_context) (c []candidate, d int) {\n\tvar args Args_auto_complete\n\tvar reply Reply_auto_complete\n\targs.Arg0 = Arg0\n\targs.Arg1 = Arg1\n\targs.Arg2 = Arg2\n\targs.Arg3 = Arg3\n\terr := cli.Call(\"RPC.RPC_auto_complete\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0, reply.Arg1\n}\n\n// wrapper for: server_close\n\ntype Args_close struct {\n\tArg0 int\n}\ntype Reply_close struct {\n\tArg0 int\n}\n\nfunc (r *RPC) RPC_close(args *Args_close, reply *Reply_close) error {\n\treply.Arg0 = server_close(args.Arg0)\n\treturn nil\n}\nfunc client_close(cli *rpc.Client, Arg0 int) int {\n\tvar args Args_close\n\tvar reply Reply_close\n\targs.Arg0 = Arg0\n\terr := cli.Call(\"RPC.RPC_close\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0\n}\n\n// wrapper for: server_status\n\ntype Args_status struct {\n\tArg0 int\n}\ntype Reply_status struct {\n\tArg0 string\n}\n\nfunc (r *RPC) RPC_status(args *Args_status, reply *Reply_status) error {\n\treply.Arg0 = server_status(args.Arg0)\n\treturn nil\n}\nfunc client_status(cli *rpc.Client, Arg0 int) string {\n\tvar args Args_status\n\tvar reply Reply_status\n\targs.Arg0 = Arg0\n\terr := cli.Call(\"RPC.RPC_status\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0\n}\n\n// wrapper for: server_drop_cache\n\ntype Args_drop_cache struct {\n\tArg0 int\n}\ntype Reply_drop_cache struct {\n\tArg0 int\n}\n\nfunc (r *RPC) RPC_drop_cache(args *Args_drop_cache, reply *Reply_drop_cache) error {\n\treply.Arg0 = server_drop_cache(args.Arg0)\n\treturn nil\n}\nfunc client_drop_cache(cli *rpc.Client, Arg0 int) int {\n\tvar args Args_drop_cache\n\tvar reply Reply_drop_cache\n\targs.Arg0 = Arg0\n\terr := cli.Call(\"RPC.RPC_drop_cache\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0\n}\n\n// wrapper for: server_set\n\ntype Args_set struct {\n\tArg0, Arg1 string\n}\ntype Reply_set struct {\n\tArg0 string\n}\n\nfunc (r *RPC) RPC_set(args *Args_set, reply *Reply_set) error {\n\treply.Arg0 = server_set(args.Arg0, args.Arg1)\n\treturn nil\n}\nfunc client_set(cli *rpc.Client, Arg0, Arg1 string) string {\n\tvar args Args_set\n\tvar reply Reply_set\n\targs.Arg0 = Arg0\n\targs.Arg1 = Arg1\n\terr := cli.Call(\"RPC.RPC_set\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0\n}\n\n// wrapper for: server_options\n\ntype Args_options struct {\n\tArg0 int\n}\ntype Reply_options struct {\n\tArg0 string\n}\n\nfunc (r *RPC) RPC_options(args *Args_options, reply *Reply_options) error {\n\treply.Arg0 = server_options(args.Arg0)\n\treturn nil\n}\nfunc client_options(cli *rpc.Client, Arg0 int) string {\n\tvar args Args_options\n\tvar reply Reply_options\n\targs.Arg0 = Arg0\n\terr := cli.Call(\"RPC.RPC_options\", &args, &reply)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn reply.Arg0\n}\n"
        },
        {
          "name": "scope.go",
          "type": "blob",
          "size": 1.474609375,
          "content": "package main\n\n//-------------------------------------------------------------------------\n// scope\n//-------------------------------------------------------------------------\n\ntype scope struct {\n\t// the package name that this scope resides in\n\tpkgname  string\n\tparent   *scope // nil for universe scope\n\tentities map[string]*decl\n}\n\nfunc new_named_scope(outer *scope, name string) *scope {\n\ts := new_scope(outer)\n\ts.pkgname = name\n\treturn s\n}\n\nfunc new_scope(outer *scope) *scope {\n\ts := new(scope)\n\tif outer != nil {\n\t\ts.pkgname = outer.pkgname\n\t}\n\ts.parent = outer\n\ts.entities = make(map[string]*decl)\n\treturn s\n}\n\n// returns: new, prev\nfunc advance_scope(s *scope) (*scope, *scope) {\n\tif len(s.entities) == 0 {\n\t\treturn s, s.parent\n\t}\n\treturn new_scope(s), s\n}\n\n// adds declaration or returns an existing one\nfunc (s *scope) add_named_decl(d *decl) *decl {\n\treturn s.add_decl(d.name, d)\n}\n\nfunc (s *scope) add_decl(name string, d *decl) *decl {\n\tdecl, ok := s.entities[name]\n\tif !ok {\n\t\ts.entities[name] = d\n\t\treturn d\n\t}\n\treturn decl\n}\n\nfunc (s *scope) replace_decl(name string, d *decl) {\n\ts.entities[name] = d\n}\n\nfunc (s *scope) merge_decl(d *decl) {\n\tdecl, ok := s.entities[d.name]\n\tif !ok {\n\t\ts.entities[d.name] = d\n\t} else {\n\t\tdecl := decl.deep_copy()\n\t\tdecl.expand_or_replace(d)\n\t\ts.entities[d.name] = decl\n\t}\n}\n\nfunc (s *scope) lookup(name string) *decl {\n\tdecl, ok := s.entities[name]\n\tif !ok {\n\t\tif s.parent != nil {\n\t\t\treturn s.parent.lookup(name)\n\t\t} else {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn decl\n}\n"
        },
        {
          "name": "server.go",
          "type": "blob",
          "size": 6.0498046875,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"go/build\"\n\t\"log\"\n\t\"net\"\n\t\"net/rpc\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"time\"\n)\n\nfunc do_server() int {\n\tg_config.read()\n\tif g_config.ForceDebugOutput != \"\" {\n\t\t// forcefully enable debugging and redirect logging into the\n\t\t// specified file\n\t\t*g_debug = true\n\t\tf, err := os.Create(g_config.ForceDebugOutput)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tlog.SetOutput(f)\n\t}\n\n\taddr := *g_addr\n\tif *g_sock == \"unix\" {\n\t\taddr = get_socket_filename()\n\t\tif file_exists(addr) {\n\t\t\tlog.Printf(\"unix socket: '%s' already exists\\n\", addr)\n\t\t\treturn 1\n\t\t}\n\t}\n\tg_daemon = new_daemon(*g_sock, addr)\n\tif *g_sock == \"unix\" {\n\t\t// cleanup unix socket file\n\t\tdefer os.Remove(addr)\n\t}\n\n\trpc.Register(new(RPC))\n\n\tg_daemon.loop()\n\treturn 0\n}\n\n//-------------------------------------------------------------------------\n// daemon\n//-------------------------------------------------------------------------\n\ntype daemon struct {\n\tlistener     net.Listener\n\tcmd_in       chan int\n\tautocomplete *auto_complete_context\n\tpkgcache     package_cache\n\tdeclcache    *decl_cache\n\tcontext      package_lookup_context\n}\n\nfunc new_daemon(network, address string) *daemon {\n\tvar err error\n\n\td := new(daemon)\n\td.listener, err = net.Listen(network, address)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\td.cmd_in = make(chan int, 1)\n\td.pkgcache = new_package_cache()\n\td.declcache = new_decl_cache(&d.context)\n\td.autocomplete = new_auto_complete_context(d.pkgcache, d.declcache)\n\treturn d\n}\n\nfunc (this *daemon) drop_cache() {\n\tthis.pkgcache = new_package_cache()\n\tthis.declcache = new_decl_cache(&this.context)\n\tthis.autocomplete = new_auto_complete_context(this.pkgcache, this.declcache)\n}\n\nconst (\n\tdaemon_close = iota\n)\n\nfunc (this *daemon) loop() {\n\tconn_in := make(chan net.Conn)\n\tgo func() {\n\t\tfor {\n\t\t\tc, err := this.listener.Accept()\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t\tconn_in <- c\n\t\t}\n\t}()\n\n\ttimeout := time.Duration(g_config.CloseTimeout) * time.Second\n\tcountdown := time.NewTimer(timeout)\n\n\tfor {\n\t\t// handle connections or server CMDs (currently one CMD)\n\t\tselect {\n\t\tcase c := <-conn_in:\n\t\t\trpc.ServeConn(c)\n\t\t\tcountdown.Reset(timeout)\n\t\t\truntime.GC()\n\t\tcase cmd := <-this.cmd_in:\n\t\t\tswitch cmd {\n\t\t\tcase daemon_close:\n\t\t\t\treturn\n\t\t\t}\n\t\tcase <-countdown.C:\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (this *daemon) close() {\n\tthis.cmd_in <- daemon_close\n}\n\nvar g_daemon *daemon\n\n//-------------------------------------------------------------------------\n// server_* functions\n//\n// Corresponding client_* functions are autogenerated by goremote.\n//-------------------------------------------------------------------------\n\nfunc server_auto_complete(file []byte, filename string, cursor int, context_packed go_build_context) (c []candidate, d int) {\n\tcontext := unpack_build_context(&context_packed)\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tprint_backtrace(err)\n\t\t\tc = []candidate{\n\t\t\t\t{\"PANIC\", \"PANIC\", decl_invalid, \"panic\"},\n\t\t\t}\n\n\t\t\t// drop cache\n\t\t\tg_daemon.drop_cache()\n\t\t}\n\t}()\n\t// TODO: Probably we don't care about comparing all the fields, checking GOROOT and GOPATH\n\t// should be enough.\n\tif !reflect.DeepEqual(g_daemon.context.Context, context.Context) {\n\t\tg_daemon.context = context\n\t\tg_daemon.drop_cache()\n\t}\n\tswitch g_config.PackageLookupMode {\n\tcase \"bzl\":\n\t\t// when package lookup mode is bzl, we set GOPATH to \"\" explicitly and\n\t\t// BzlProjectRoot becomes valid (or empty)\n\t\tvar err error\n\t\tg_daemon.context.GOPATH = \"\"\n\t\tg_daemon.context.BzlProjectRoot, err = find_bzl_project_root(g_config.LibPath, filename)\n\t\tif *g_debug && err != nil {\n\t\t\tlog.Printf(\"Bzl project root not found: %s\", err)\n\t\t}\n\tcase \"gb\":\n\t\t// when package lookup mode is gb, we set GOPATH to \"\" explicitly and\n\t\t// GBProjectRoot becomes valid (or empty)\n\t\tvar err error\n\t\tg_daemon.context.GOPATH = \"\"\n\t\tg_daemon.context.GBProjectRoot, err = find_gb_project_root(filename)\n\t\tif *g_debug && err != nil {\n\t\t\tlog.Printf(\"Gb project root not found: %s\", err)\n\t\t}\n\tcase \"go\":\n\t\t// get current package path for GO15VENDOREXPERIMENT hack\n\t\tg_daemon.context.CurrentPackagePath = \"\"\n\t\tpkg, err := g_daemon.context.ImportDir(filepath.Dir(filename), build.FindOnly)\n\t\tif err == nil {\n\t\t\tif *g_debug {\n\t\t\t\tlog.Printf(\"Go project path: %s\", pkg.ImportPath)\n\t\t\t}\n\t\t\tg_daemon.context.CurrentPackagePath = pkg.ImportPath\n\t\t} else if *g_debug {\n\t\t\tlog.Printf(\"Go project path not found: %s\", err)\n\t\t}\n\t}\n\tif *g_debug {\n\t\tvar buf bytes.Buffer\n\t\tlog.Printf(\"Got autocompletion request for '%s'\\n\", filename)\n\t\tlog.Printf(\"Cursor at: %d\\n\", cursor)\n\t\tif cursor > len(file) || cursor < 0 {\n\t\t\tlog.Println(\"ERROR! Cursor is outside of the boundaries of the buffer, \" +\n\t\t\t\t\"this is most likely a text editor plugin bug. Text editor is responsible \" +\n\t\t\t\t\"for passing the correct cursor position to gocode.\")\n\t\t} else {\n\t\t\tbuf.WriteString(\"-------------------------------------------------------\\n\")\n\t\t\tbuf.Write(file[:cursor])\n\t\t\tbuf.WriteString(\"#\")\n\t\t\tbuf.Write(file[cursor:])\n\t\t\tlog.Print(buf.String())\n\t\t\tlog.Println(\"-------------------------------------------------------\")\n\t\t}\n\t}\n\tcandidates, d := g_daemon.autocomplete.apropos(file, filename, cursor)\n\tif *g_debug {\n\t\tlog.Printf(\"Offset: %d\\n\", d)\n\t\tlog.Printf(\"Number of candidates found: %d\\n\", len(candidates))\n\t\tlog.Printf(\"Candidates are:\\n\")\n\t\tfor _, c := range candidates {\n\t\t\tabbr := fmt.Sprintf(\"%s %s %s\", c.Class, c.Name, c.Type)\n\t\t\tif c.Class == decl_func {\n\t\t\t\tabbr = fmt.Sprintf(\"%s %s%s\", c.Class, c.Name, c.Type[len(\"func\"):])\n\t\t\t}\n\t\t\tlog.Printf(\"  %s\\n\", abbr)\n\t\t}\n\t\tlog.Println(\"=======================================================\")\n\t}\n\treturn candidates, d\n}\n\nfunc server_close(notused int) int {\n\tg_daemon.close()\n\treturn 0\n}\n\nfunc server_status(notused int) string {\n\treturn g_daemon.autocomplete.status()\n}\n\nfunc server_drop_cache(notused int) int {\n\t// drop cache\n\tg_daemon.drop_cache()\n\treturn 0\n}\n\nfunc server_set(key, value string) string {\n\tif key == \"\\x00\" {\n\t\treturn g_config.list()\n\t} else if value == \"\\x00\" {\n\t\treturn g_config.list_option(key)\n\t}\n\t// drop cache on settings changes\n\tg_daemon.drop_cache()\n\treturn g_config.set_option(key, value)\n}\n\nfunc server_options(notused int) string {\n\treturn g_config.options()\n}\n"
        },
        {
          "name": "subl3",
          "type": "tree",
          "content": null
        },
        {
          "name": "type_alias_build_hack_18.go",
          "type": "blob",
          "size": 0.2578125,
          "content": "// +build !go1.9,!go1.8.typealias\n\npackage main\n\nimport (\n\t\"go/ast\"\n)\n\nfunc typeAliasSpec(name string, typ ast.Expr) *ast.TypeSpec {\n\treturn &ast.TypeSpec{\n\t\tName: ast.NewIdent(name),\n\t\tType: typ,\n\t}\n}\n\nfunc isAliasTypeSpec(t *ast.TypeSpec) bool {\n\treturn false\n}\n"
        },
        {
          "name": "type_alias_build_hack_19.go",
          "type": "blob",
          "size": 0.2802734375,
          "content": "// +build go1.9 go1.8.typealias\n\npackage main\n\nimport (\n\t\"go/ast\"\n)\n\nfunc typeAliasSpec(name string, typ ast.Expr) *ast.TypeSpec {\n\treturn &ast.TypeSpec{\n\t\tName:   ast.NewIdent(name),\n\t\tAssign: 1,\n\t\tType:   typ,\n\t}\n}\n\nfunc isAliasTypeSpec(t *ast.TypeSpec) bool {\n\treturn t.Assign != 0\n}\n"
        },
        {
          "name": "utils.go",
          "type": "blob",
          "size": 6.8212890625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"go/build\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"unicode/utf8\"\n)\n\n// our own readdir, which skips the files it cannot lstat\nfunc readdir_lstat(name string) ([]os.FileInfo, error) {\n\tf, err := os.Open(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\n\tnames, err := f.Readdirnames(-1)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := make([]os.FileInfo, 0, len(names))\n\tfor _, lname := range names {\n\t\ts, err := os.Lstat(filepath.Join(name, lname))\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = append(out, s)\n\t}\n\treturn out, nil\n}\n\n// our other readdir function, only opens and reads\nfunc readdir(dirname string) []os.FileInfo {\n\tf, err := os.Open(dirname)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tfi, err := f.Readdir(-1)\n\tf.Close()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn fi\n}\n\n// returns truncated 'data' and amount of bytes skipped (for cursor pos adjustment)\nfunc filter_out_shebang(data []byte) ([]byte, int) {\n\tif len(data) > 2 && data[0] == '#' && data[1] == '!' {\n\t\tnewline := bytes.Index(data, []byte(\"\\n\"))\n\t\tif newline != -1 && len(data) > newline+1 {\n\t\t\treturn data[newline+1:], newline + 1\n\t\t}\n\t}\n\treturn data, 0\n}\n\nfunc file_exists(filename string) bool {\n\t_, err := os.Stat(filename)\n\tif err != nil {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc is_dir(path string) bool {\n\tfi, err := os.Stat(path)\n\treturn err == nil && fi.IsDir()\n}\n\nfunc char_to_byte_offset(s []byte, offset_c int) (offset_b int) {\n\tfor offset_b = 0; offset_c > 0 && offset_b < len(s); offset_b++ {\n\t\tif utf8.RuneStart(s[offset_b]) {\n\t\t\toffset_c--\n\t\t}\n\t}\n\treturn offset_b\n}\n\nfunc xdg_home_dir() string {\n\txdghome := os.Getenv(\"XDG_CONFIG_HOME\")\n\tif xdghome == \"\" {\n\t\txdghome = filepath.Join(os.Getenv(\"HOME\"), \".config\")\n\t}\n\treturn xdghome\n}\n\nfunc has_prefix(s, prefix string, ignorecase bool) bool {\n\tif ignorecase {\n\t\ts = strings.ToLower(s)\n\t\tprefix = strings.ToLower(prefix)\n\t}\n\treturn strings.HasPrefix(s, prefix)\n}\n\nfunc find_bzl_project_root(libpath, path string) (string, error) {\n\tif libpath == \"\" {\n\t\treturn \"\", fmt.Errorf(\"could not find project root, libpath is empty\")\n\t}\n\n\tpathMap := map[string]struct{}{}\n\tfor _, lp := range strings.Split(libpath, \":\") {\n\t\tlp := strings.TrimSpace(lp)\n\t\tpathMap[filepath.Clean(lp)] = struct{}{}\n\t}\n\n\tpath = filepath.Dir(path)\n\tif path == \"\" {\n\t\treturn \"\", fmt.Errorf(\"project root is blank\")\n\t}\n\n\tstart := path\n\tfor path != \"/\" {\n\t\tif _, ok := pathMap[filepath.Clean(path)]; ok {\n\t\t\treturn path, nil\n\t\t}\n\t\tpath = filepath.Dir(path)\n\t}\n\treturn \"\", fmt.Errorf(\"could not find project root in %q or its parents\", start)\n}\n\n// Code taken directly from `gb`, I hope author doesn't mind.\nfunc find_gb_project_root(path string) (string, error) {\n\tpath = filepath.Dir(path)\n\tif path == \"\" {\n\t\treturn \"\", fmt.Errorf(\"project root is blank\")\n\t}\n\tstart := path\n\tfor path != \"/\" {\n\t\troot := filepath.Join(path, \"src\")\n\t\tif _, err := os.Stat(root); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\tpath = filepath.Dir(path)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn \"\", err\n\t\t}\n\t\tpath, err := filepath.EvalSymlinks(path)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn path, nil\n\t}\n\treturn \"\", fmt.Errorf(\"could not find project root in %q or its parents\", start)\n}\n\n// vendorlessImportPath returns the devendorized version of the provided import path.\n// e.g. \"foo/bar/vendor/a/b\" => \"a/b\"\nfunc vendorlessImportPath(ipath string, currentPackagePath string) (string, bool) {\n\tsplit := strings.Split(ipath, \"vendor/\")\n\t// no vendor in path\n\tif len(split) == 1 {\n\t\treturn ipath, true\n\t}\n\t// this import path does not belong to the current package\n\tif currentPackagePath != \"\" && !strings.Contains(currentPackagePath, split[0]) {\n\t\treturn \"\", false\n\t}\n\t// Devendorize for use in import statement.\n\tif i := strings.LastIndex(ipath, \"/vendor/\"); i >= 0 {\n\t\treturn ipath[i+len(\"/vendor/\"):], true\n\t}\n\tif strings.HasPrefix(ipath, \"vendor/\") {\n\t\treturn ipath[len(\"vendor/\"):], true\n\t}\n\treturn ipath, true\n}\n\n//-------------------------------------------------------------------------\n// print_backtrace\n//\n// a nicer backtrace printer than the default one\n//-------------------------------------------------------------------------\n\nvar g_backtrace_mutex sync.Mutex\n\nfunc print_backtrace(err interface{}) {\n\tg_backtrace_mutex.Lock()\n\tdefer g_backtrace_mutex.Unlock()\n\tfmt.Printf(\"panic: %v\\n\", err)\n\ti := 2\n\tfor {\n\t\tpc, file, line, ok := runtime.Caller(i)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tf := runtime.FuncForPC(pc)\n\t\tfmt.Printf(\"%d(%s): %s:%d\\n\", i-1, f.Name(), file, line)\n\t\ti++\n\t}\n\tfmt.Println(\"\")\n}\n\n//-------------------------------------------------------------------------\n// File reader goroutine\n//\n// It's a bad idea to block multiple goroutines on file I/O. Creates many\n// threads which fight for HDD. Therefore only single goroutine should read HDD\n// at the same time.\n//-------------------------------------------------------------------------\n\ntype file_read_request struct {\n\tfilename string\n\tout      chan file_read_response\n}\n\ntype file_read_response struct {\n\tdata  []byte\n\terror error\n}\n\ntype file_reader_type struct {\n\tin chan file_read_request\n}\n\nfunc new_file_reader() *file_reader_type {\n\tthis := new(file_reader_type)\n\tthis.in = make(chan file_read_request)\n\tgo func() {\n\t\tvar rsp file_read_response\n\t\tfor {\n\t\t\treq := <-this.in\n\t\t\trsp.data, rsp.error = ioutil.ReadFile(req.filename)\n\t\t\treq.out <- rsp\n\t\t}\n\t}()\n\treturn this\n}\n\nfunc (this *file_reader_type) read_file(filename string) ([]byte, error) {\n\treq := file_read_request{\n\t\tfilename,\n\t\tmake(chan file_read_response),\n\t}\n\tthis.in <- req\n\trsp := <-req.out\n\treturn rsp.data, rsp.error\n}\n\nvar file_reader = new_file_reader()\n\n//-------------------------------------------------------------------------\n// copy of the build.Context without func fields\n//-------------------------------------------------------------------------\n\ntype go_build_context struct {\n\tGOARCH        string\n\tGOOS          string\n\tGOROOT        string\n\tGOPATH        string\n\tCgoEnabled    bool\n\tUseAllFiles   bool\n\tCompiler      string\n\tBuildTags     []string\n\tReleaseTags   []string\n\tInstallSuffix string\n}\n\nfunc pack_build_context(ctx *build.Context) go_build_context {\n\treturn go_build_context{\n\t\tGOARCH:        ctx.GOARCH,\n\t\tGOOS:          ctx.GOOS,\n\t\tGOROOT:        ctx.GOROOT,\n\t\tGOPATH:        ctx.GOPATH,\n\t\tCgoEnabled:    ctx.CgoEnabled,\n\t\tUseAllFiles:   ctx.UseAllFiles,\n\t\tCompiler:      ctx.Compiler,\n\t\tBuildTags:     ctx.BuildTags,\n\t\tReleaseTags:   ctx.ReleaseTags,\n\t\tInstallSuffix: ctx.InstallSuffix,\n\t}\n}\n\nfunc unpack_build_context(ctx *go_build_context) package_lookup_context {\n\treturn package_lookup_context{\n\t\tContext: build.Context{\n\t\t\tGOARCH:        ctx.GOARCH,\n\t\t\tGOOS:          ctx.GOOS,\n\t\t\tGOROOT:        ctx.GOROOT,\n\t\t\tGOPATH:        ctx.GOPATH,\n\t\t\tCgoEnabled:    ctx.CgoEnabled,\n\t\t\tUseAllFiles:   ctx.UseAllFiles,\n\t\t\tCompiler:      ctx.Compiler,\n\t\t\tBuildTags:     ctx.BuildTags,\n\t\t\tReleaseTags:   ctx.ReleaseTags,\n\t\t\tInstallSuffix: ctx.InstallSuffix,\n\t\t},\n\t}\n}\n"
        },
        {
          "name": "vim",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}