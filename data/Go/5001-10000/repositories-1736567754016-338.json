{
  "metadata": {
    "timestamp": 1736567754016,
    "page": 338,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "anacrolix/torrent",
      "stars": 5630,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".deepsource.toml",
          "type": "blob",
          "size": 0.197265625,
          "content": "version = 1\n\ntest_patterns = [\"**/*_test.go\"]\n\n[[analyzers]]\nname = \"go\"\nenabled = true\n\n  [analyzers.meta]\n  import_root = \"github.com/anacrolix/torrent\"\n\n[[transformers]]\nname = \"gofmt\"\nenabled = true"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0478515625,
          "content": ".idea\n*-run.gob\n.envrc*\n.DS_Store\ngo.work*\n/.env\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.1171875,
          "content": "linters-settings:\n  staticcheck:\n    go: \"1.16\"\n    checks: [\"all\", \"-U1000\"]\n\n  govet:\n    disable:\n      - composites\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.9521484375,
          "content": "# On macOS, docker does not support IPv6.\n\nFROM alpine\n\nRUN apk add go fuse bash rustup git gcc musl-dev g++\nRUN rustup-init -y --profile minimal\nENV PATH=\"/root/.cargo/bin:$PATH\"\n\nWORKDIR /src\n\nCOPY . .\nRUN git clone https://github.com/anacrolix/possum\n\nWORKDIR possum\n\nRUN git submodule update --init --recursive\nRUN --mount=type=cache,target=/root/.cargo/registry \\\n\t--mount=type=cache,target=/root/.cargo/git \\\n\t--mount=type=cache,target=/src/possum/target \\\n\tcargo build\n\nWORKDIR ..\n\nARG GOCACHE=/root/.cache/go-build\nARG GOMODCACHE=/root/go/pkg/mod\n\nRUN --mount=type=cache,target=$GOCACHE \\\n\t--mount=type=cache,target=$GOMODCACHE \\\n\tCGO_LDFLAGS=possum/target/debug/libpossum.a \\\n\tgo test -failfast ./...\n\n# # Can't use fuse inside Docker? Asks for modprobe fuse.\n\n# RUN go install github.com/anacrolix/godo@v1\n# RUN echo \"$HOME\"\n# ENV PATH=\"/root/go/bin:$PATH\"\n# # RUN --mount=type=cache,target=$GOCACHE \\\n# # \t--mount=type=cache,target=$GOMODCACHE \\\n# # \t./fs/test.sh\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 16.3330078125,
          "content": "Mozilla Public License Version 2.0\n==================================\n\n1. Definitions\n--------------\n\n1.1. \"Contributor\"\n    means each individual or legal entity that creates, contributes to\n    the creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n    means the combination of the Contributions of others (if any) used\n    by a Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n    means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n    means Source Code Form to which the initial Contributor has attached\n    the notice in Exhibit A, the Executable Form of such Source Code\n    Form, and Modifications of such Source Code Form, in each case\n    including portions thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n    means\n\n    (a) that the initial Contributor has attached the notice described\n        in Exhibit B to the Covered Software; or\n\n    (b) that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the\n        terms of a Secondary License.\n\n1.6. \"Executable Form\"\n    means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n    means a work that combines Covered Software with other material, in\n    a separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n    means this document.\n\n1.9. \"Licensable\"\n    means having the right to grant, to the maximum extent possible,\n    whether at the time of the initial grant or subsequently, any and\n    all of the rights conveyed by this License.\n\n1.10. \"Modifications\"\n    means any of the following:\n\n    (a) any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered\n        Software; or\n\n    (b) any new file in Source Code Form that contains any Covered\n        Software.\n\n1.11. \"Patent Claims\" of a Contributor\n    means any patent claim(s), including without limitation, method,\n    process, and apparatus claims, in any patent Licensable by such\n    Contributor that would be infringed, but for the grant of the\n    License, by the making, using, selling, offering for sale, having\n    made, import, or transfer of either its Contributions or its\n    Contributor Version.\n\n1.12. \"Secondary License\"\n    means either the GNU General Public License, Version 2.0, the GNU\n    Lesser General Public License, Version 2.1, the GNU Affero General\n    Public License, Version 3.0, or any later versions of those\n    licenses.\n\n1.13. \"Source Code Form\"\n    means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n    means an individual or a legal entity exercising rights under this\n    License. For legal entities, \"You\" includes any entity that\n    controls, is controlled by, or is under common control with You. For\n    purposes of this definition, \"control\" means (a) the power, direct\n    or indirect, to cause the direction or management of such entity,\n    whether by contract or otherwise, or (b) ownership of more than\n    fifty percent (50%) of the outstanding shares or beneficial\n    ownership of such entity.\n\n2. License Grants and Conditions\n--------------------------------\n\n2.1. Grants\n\nEach Contributor hereby grants You a world-wide, royalty-free,\nnon-exclusive license:\n\n(a) under intellectual property rights (other than patent or trademark)\n    Licensable by such Contributor to use, reproduce, make available,\n    modify, display, perform, distribute, and otherwise exploit its\n    Contributions, either on an unmodified basis, with Modifications, or\n    as part of a Larger Work; and\n\n(b) under Patent Claims of such Contributor to make, use, sell, offer\n    for sale, have made, import, and otherwise transfer either its\n    Contributions or its Contributor Version.\n\n2.2. Effective Date\n\nThe licenses granted in Section 2.1 with respect to any Contribution\nbecome effective for each Contribution on the date the Contributor first\ndistributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\nThe licenses granted in this Section 2 are the only rights granted under\nthis License. No additional rights or licenses will be implied from the\ndistribution or licensing of Covered Software under this License.\nNotwithstanding Section 2.1(b) above, no patent license is granted by a\nContributor:\n\n(a) for any code that a Contributor has removed from Covered Software;\n    or\n\n(b) for infringements caused by: (i) Your and any other third party's\n    modifications of Covered Software, or (ii) the combination of its\n    Contributions with other software (except as part of its Contributor\n    Version); or\n\n(c) under Patent Claims infringed by Covered Software in the absence of\n    its Contributions.\n\nThis License does not grant any rights in the trademarks, service marks,\nor logos of any Contributor (except as may be necessary to comply with\nthe notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\nNo Contributor makes additional grants as a result of Your choice to\ndistribute the Covered Software under a subsequent version of this\nLicense (see Section 10.2) or under the terms of a Secondary License (if\npermitted under the terms of Section 3.3).\n\n2.5. Representation\n\nEach Contributor represents that the Contributor believes its\nContributions are its original creation(s) or it has sufficient rights\nto grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\nThis License is not intended to limit any rights You have under\napplicable copyright doctrines of fair use, fair dealing, or other\nequivalents.\n\n2.7. Conditions\n\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted\nin Section 2.1.\n\n3. Responsibilities\n-------------------\n\n3.1. Distribution of Source Form\n\nAll distribution of Covered Software in Source Code Form, including any\nModifications that You create or to which You contribute, must be under\nthe terms of this License. You must inform recipients that the Source\nCode Form of the Covered Software is governed by the terms of this\nLicense, and how they can obtain a copy of this License. You may not\nattempt to alter or restrict the recipients' rights in the Source Code\nForm.\n\n3.2. Distribution of Executable Form\n\nIf You distribute Covered Software in Executable Form then:\n\n(a) such Covered Software must also be made available in Source Code\n    Form, as described in Section 3.1, and You must inform recipients of\n    the Executable Form how they can obtain a copy of such Source Code\n    Form by reasonable means in a timely manner, at a charge no more\n    than the cost of distribution to the recipient; and\n\n(b) You may distribute such Executable Form under the terms of this\n    License, or sublicense it under different terms, provided that the\n    license for the Executable Form does not attempt to limit or alter\n    the recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\nYou may create and distribute a Larger Work under terms of Your choice,\nprovided that You also comply with the requirements of this License for\nthe Covered Software. If the Larger Work is a combination of Covered\nSoftware with a work governed by one or more Secondary Licenses, and the\nCovered Software is not Incompatible With Secondary Licenses, this\nLicense permits You to additionally distribute such Covered Software\nunder the terms of such Secondary License(s), so that the recipient of\nthe Larger Work may, at their option, further distribute the Covered\nSoftware under the terms of either this License or such Secondary\nLicense(s).\n\n3.4. Notices\n\nYou may not remove or alter the substance of any license notices\n(including copyright notices, patent notices, disclaimers of warranty,\nor limitations of liability) contained within the Source Code Form of\nthe Covered Software, except that You may alter any license notices to\nthe extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\nYou may choose to offer, and to charge a fee for, warranty, support,\nindemnity or liability obligations to one or more recipients of Covered\nSoftware. However, You may do so only on Your own behalf, and not on\nbehalf of any Contributor. You must make it absolutely clear that any\nsuch warranty, support, indemnity, or liability obligation is offered by\nYou alone, and You hereby agree to indemnify every Contributor for any\nliability incurred by such Contributor as a result of warranty, support,\nindemnity or liability terms You offer. You may include additional\ndisclaimers of warranty and limitations of liability specific to any\njurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n---------------------------------------------------\n\nIf it is impossible for You to comply with any of the terms of this\nLicense with respect to some or all of the Covered Software due to\nstatute, judicial order, or regulation then You must: (a) comply with\nthe terms of this License to the maximum extent possible; and (b)\ndescribe the limitations and the code they affect. Such description must\nbe placed in a text file included with all distributions of the Covered\nSoftware under this License. Except to the extent prohibited by statute\nor regulation, such description must be sufficiently detailed for a\nrecipient of ordinary skill to be able to understand it.\n\n5. Termination\n--------------\n\n5.1. The rights granted under this License will terminate automatically\nif You fail to comply with any of its terms. However, if You become\ncompliant, then the rights granted under this License from a particular\nContributor are reinstated (a) provisionally, unless and until such\nContributor explicitly and finally terminates Your grants, and (b) on an\nongoing basis, if such Contributor fails to notify You of the\nnon-compliance by some reasonable means prior to 60 days after You have\ncome back into compliance. Moreover, Your grants from a particular\nContributor are reinstated on an ongoing basis if such Contributor\nnotifies You of the non-compliance by some reasonable means, this is the\nfirst time You have received notice of non-compliance with this License\nfrom such Contributor, and You become compliant prior to 30 days after\nYour receipt of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\ninfringement claim (excluding declaratory judgment actions,\ncounter-claims, and cross-claims) alleging that a Contributor Version\ndirectly or indirectly infringes any patent, then the rights granted to\nYou by any and all Contributors for the Covered Software under Section\n2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all\nend user license agreements (excluding distributors and resellers) which\nhave been validly granted by You or Your distributors under this License\nprior to termination shall survive termination.\n\n************************************************************************\n*                                                                      *\n*  6. Disclaimer of Warranty                                           *\n*  -------------------------                                           *\n*                                                                      *\n*  Covered Software is provided under this License on an \"as is\"       *\n*  basis, without warranty of any kind, either expressed, implied, or  *\n*  statutory, including, without limitation, warranties that the       *\n*  Covered Software is free of defects, merchantable, fit for a        *\n*  particular purpose or non-infringing. The entire risk as to the     *\n*  quality and performance of the Covered Software is with You.        *\n*  Should any Covered Software prove defective in any respect, You     *\n*  (not any Contributor) assume the cost of any necessary servicing,   *\n*  repair, or correction. This disclaimer of warranty constitutes an   *\n*  essential part of this License. No use of any Covered Software is   *\n*  authorized under this License except under this disclaimer.         *\n*                                                                      *\n************************************************************************\n\n************************************************************************\n*                                                                      *\n*  7. Limitation of Liability                                          *\n*  --------------------------                                          *\n*                                                                      *\n*  Under no circumstances and under no legal theory, whether tort      *\n*  (including negligence), contract, or otherwise, shall any           *\n*  Contributor, or anyone who distributes Covered Software as          *\n*  permitted above, be liable to You for any direct, indirect,         *\n*  special, incidental, or consequential damages of any character      *\n*  including, without limitation, damages for lost profits, loss of    *\n*  goodwill, work stoppage, computer failure or malfunction, or any    *\n*  and all other commercial damages or losses, even if such party      *\n*  shall have been informed of the possibility of such damages. This   *\n*  limitation of liability shall not apply to liability for death or   *\n*  personal injury resulting from such party's negligence to the       *\n*  extent applicable law prohibits such limitation. Some               *\n*  jurisdictions do not allow the exclusion or limitation of           *\n*  incidental or consequential damages, so this exclusion and          *\n*  limitation may not apply to You.                                    *\n*                                                                      *\n************************************************************************\n\n8. Litigation\n-------------\n\nAny litigation relating to this License may be brought only in the\ncourts of a jurisdiction where the defendant maintains its principal\nplace of business and such litigation shall be governed by laws of that\njurisdiction, without reference to its conflict-of-law provisions.\nNothing in this Section shall prevent a party's ability to bring\ncross-claims or counter-claims.\n\n9. Miscellaneous\n----------------\n\nThis License represents the complete agreement concerning the subject\nmatter hereof. If any provision of this License is held to be\nunenforceable, such provision shall be reformed only to the extent\nnecessary to make it enforceable. Any law or regulation which provides\nthat the language of a contract shall be construed against the drafter\nshall not be used to construe this License against a Contributor.\n\n10. Versions of the License\n---------------------------\n\n10.1. New Versions\n\nMozilla Foundation is the license steward. Except as provided in Section\n10.3, no one other than the license steward has the right to modify or\npublish new versions of this License. Each version will be given a\ndistinguishing version number.\n\n10.2. Effect of New Versions\n\nYou may distribute the Covered Software under the terms of the version\nof the License under which You originally received the Covered Software,\nor under the terms of any subsequent version published by the license\nsteward.\n\n10.3. Modified Versions\n\nIf you create software not governed by this License, and you want to\ncreate a new license for such software, you may create and use a\nmodified version of this License if you rename the license and remove\nany references to the name of the license steward (except to note that\nsuch modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\nLicenses\n\nIf You choose to distribute Source Code Form that is Incompatible With\nSecondary Licenses under the terms of this version of the License, the\nnotice described in Exhibit B of this License must be attached.\n\nExhibit A - Source Code Form License Notice\n-------------------------------------------\n\n  This Source Code Form is subject to the terms of the Mozilla Public\n  License, v. 2.0. If a copy of the MPL was not distributed with this\n  file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular\nfile, then You may include the notice in a location (such as a LICENSE\nfile in a relevant directory) where a recipient would be likely to look\nfor such a notice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n---------------------------------------------------------\n\n  This Source Code Form is \"Incompatible With Secondary Licenses\", as\n  defined by the Mozilla Public License, v. 2.0.\n"
        },
        {
          "name": "NOTES.md",
          "type": "blob",
          "size": 3.7275390625,
          "content": "### Literature\n\n* [arvid on writing a fast piece picker](https://blog.libtorrent.org/2011/11/writing-a-fast-piece-picker/)\n\n    Uses C++ for examples.\n\n* [On Piece Selection for Streaming BitTorrent](https://www.diva-portal.org/smash/get/diva2:835742/FULLTEXT01.pdf)\n \n  Some simulations by some Swedes on piece selection.\n\n* [A South American paper on peer-selection strategies for uploading](https://arxiv.org/pdf/1402.2187.pdf)\n\n  Has some useful overviews of piece-selection.\n\n### Hole-punching\n\nHolepunching is tracked in Torrent, rather than in Client because if we send a rendezvous message, and subsequently receive a connect message, we do not know if a peer sent a rendezvous message to our relay and we're receiving the connect message for their rendezvous or ours. Relays are not required to respond to rendezvous, so we can't enforce a timeout. If we don't know if who sent the rendezvous that triggered a connect, then we don't know what infohash to use in the handshake. Once we send a rendezvous, and never receive a reply, we would have to always perform handshakes with our original infohash, or always copy the infohash the remote sends. Handling connects by always being the passive side in the handshake won't work since the other side might use the same behaviour and neither will initiate.\n\nIf we only perform rendezvous through relays for the same torrent as the relay, then all the handshake can be done actively for all connect messages. All connect messages received from a peer can only be for the same torrent for which we are connected to the peer.\n\nIn 2006, approximately 70% of clients were behind NAT (https://web.archive.org/web/20100724011252/http://illuminati.coralcdn.org/stats/). According to https://fosdem.org/2023/schedule/event/network_hole_punching_in_the_wild/,  hole punching (in libp2p) 70% of NAT can be defeated by relay mechanisms.\n\nIf either or both peers in a potential peer do not have NAT, or are full cone NAT, then NAT doesn't matter at least for BitTorrent, as both parties are trying to connect to each other and connections will always work in one direction.\n\nThe chance that 2 peers can connect to each other would be 1-(badnat)^2, and 1-unrelayable*(badnat)^2 where unrelayable is the chance they can't work even with a relay, and badnat is the chance a peer has a bad NAT (not full cone). For example if unrelayable is 0.3 per the libp2p study, and badnat is 0.5 (i made this up), 92.5% of peers can connect with each other if they use \"relay mechanisms\", and 75% if they don't. as long as any peers in the swarm are not badnat, they can relay those that are, and and act as super nodes for peers that can't or don't implement hole punching.\n\nThe DHT is a bit different: you can't be an active node if you are a badnat, but you can still query the network to get what you need, you just don't contribute to it. It also doesn't matter what the swarm looks like for a given torrent on the DHT, because you don't have to be in the swarm to host its data. all that matters is that there are some peers that aren't badnat that are in the DHT, of which there are millions (for BitTorrent).\n\n- https://blog.ipfs.tech/2022-01-20-libp2p-hole-punching/\n- https://www.bittorrent.org/beps/bep_0055.html\n- https://github.com/anacrolix/torrent/issues/685\n- https://stackoverflow.com/questions/38786438/libutp-%C2%B5tp-and-nat-traversal-udp-hole-punching\n\n### BitTorrent v2\n\n- https://www.bittorrent.org/beps/bep_0052.html\n\nThe canonical infohash to use for a torrent will be the v1 infohash, or the short form of the v2 infohash if v1 is not supported. This will apply everywhere that both infohashes are present. If only one 20 byte hash is present, it is always the v1 hash (except in code that interfaces with things that only work with 20 byte hashes, like the DHT)."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.8720703125,
          "content": "# torrent\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/anacrolix/torrent)](https://pkg.go.dev/github.com/anacrolix/torrent)\n\nThis repository implements BitTorrent-related packages and command-line utilities in Go. The emphasis is on use as a library from other projects. It's been used 24/7 in production by downstream services since late 2014. The implementation was specifically created to explore Go's concurrency capabilities, and to include the ability to stream data directly from the BitTorrent network. To this end it [supports seeking, readaheads and other features](https://godoc.org/github.com/anacrolix/torrent#Reader) exposing torrents and their files with the various Go idiomatic `io` package interfaces. This is also demonstrated through [torrentfs](#torrentfs).\n\nThere is [support for protocol encryption, DHT, PEX, uTP, and various extensions](https://godoc.org/github.com/anacrolix/torrent). There are [several data storage backends provided](https://godoc.org/github.com/anacrolix/torrent/storage): blob, file, bolt, mmap, and sqlite, to name a few. You can [write your own](https://godoc.org/github.com/anacrolix/torrent/storage#ClientImpl) to store data for example on S3, or in a database. \n\nSome noteworthy package dependencies that can be used for other purposes include:\n\n * [go-libutp](https://github.com/anacrolix/go-libutp)\n * [dht](https://github.com/anacrolix/dht)\n * [bencode](https://godoc.org/github.com/anacrolix/torrent/bencode)\n * [tracker](https://godoc.org/github.com/anacrolix/torrent/tracker)\n\n## Installation\n\nInstall the library package with `go get github.com/anacrolix/torrent`, or the provided cmds with `go install github.com/anacrolix/torrent/cmd/...@latest`.\n\n## Library examples\n\nThere are some small [examples](https://godoc.org/github.com/anacrolix/torrent#pkg-examples) in the package documentation.\n\n## Mentions\n\n * [@anacrolix](https://github.com/anacrolix) is interviewed about this repo in [Console 32](https://console.substack.com/p/console-32).\n\n### Downstream projects\n\nThere are several web-frontends, sites, Android clients, storage backends and supporting services among the known public projects:\n\n * [cove](https://coveapp.info): Personal torrent browser with streaming, DHT search, video transcoding and casting.\n * [confluence](https://github.com/anacrolix/confluence): torrent client as a HTTP service <!-- Well of course I know him... He's me -->\n * [Gopeed](https://github.com/GopeedLab/gopeed): Gopeed (full name Go Speed), a high-speed downloader developed by Golang + Flutter, supports (HTTP, BitTorrent, Magnet) protocol, and supports all platforms. <!-- 7.7k stars --> \n * [Erigon](https://github.com/ledgerwatch/erigon): an implementation of Ethereum (execution layer with embeddable consensus layer), on the efficiency frontier. <!-- 2.7k stars -->\n * [exatorrent](https://github.com/varbhat/exatorrent): Elegant self-hostable torrent client <!-- 1.5k stars -->\n * [bitmagnet](https://github.com/bitmagnet-io/bitmagnet): A self-hosted BitTorrent indexer, DHT crawler, content classifier and torrent search engine with web UI, GraphQL API and Servarr stack integration. <!-- 1.1k stars --> \n * [TorrServer](https://github.com/YouROK/TorrServer): Torrent streaming server over http <!-- 984 stars -->\n * [distribyted](https://github.com/distribyted/distribyted): Distribyted is an alternative torrent client. It can expose torrent files as a standard FUSE, webDAV or HTTP endpoint and download them on demand, allowing random reads using a fixed amount of disk space. <!-- 982 stars -->\n * [Mangayomi](https://github.com/kodjodevf/mangayomi): Cross-platform app that allows users to read manga and stream anime from a variety of sources including BitTorrent. <!-- 940 stars -->\n * [Simple Torrent](https://github.com/boypt/simple-torrent): self-hosted HTTP remote torrent client <!-- 876 stars -->\n * [autobrr](https://github.com/autobrr/autobrr): autobrr redefines download automation for torrents and Usenet, drawing inspiration from tools like trackarr, autodl-irssi, and flexget. <!-- 855 stars -->\n * [mabel](https://github.com/smmr-software/mabel): Fancy BitTorrent client for the terminal <!-- 421 stars -->\n * [Toru](https://github.com/sweetbbak/toru): Stream anime from the the terminal! <!-- 216 stars -->\n * [webtor.io](https://webtor.io/): free cloud BitTorrent-client <!-- not exclusively anacrolix/torrent maybe? 40-200 stars? -->\n * [Android Torrent Client](https://gitlab.com/axet/android-torrent-client): Android torrent client <!-- 29 stars -->\n * [libtorrent](https://gitlab.com/axet/libtorrent): gomobile wrapper <!-- 15 stars -->\n * [Go-PeersToHTTP](https://github.com/WinPooh32/peerstohttp): Simple torrent proxy to http stream controlled over REST-like api <!-- 28 stars -->\n * [CortexFoundation/torrentfs](https://github.com/CortexFoundation/torrentfs): Independent HTTP service for file seeding and P2P file system of cortex full node <!-- 21 stars -->\n * [Torrent WebDAV Client](https://github.com/Jipok/torrent-webdav): Automatic torrent download, streaming, WebDAV server and client. <!-- 1 star, https://github.com/anacrolix/torrent/issues/917 --> \n * [goTorrent](https://github.com/deranjer/goTorrent): torrenting server with a React web frontend <!-- 156 stars, inactive since 2020 -->\n * [Go Peerflix](https://github.com/Sioro-Neoku/go-peerflix): Start watching the movie while your torrent is still downloading! <!-- 449 stars, inactive since 2019 -->\n * [hTorrent](https://github.com/pojntfx/htorrent): HTTP to BitTorrent gateway with seeking support. <!-- 102 stars -->\n * [Remote-Torrent](https://github.com/BruceWangNo1/remote-torrent): Download Remotely and Retrieve Files Over HTTP <!-- 57 stars, inactive since 2019 -->\n * [Trickl](https://github.com/arranlomas/Trickl): torrent client for android <!-- 48 stars, inactive since 2018 -->\n * [ANT-Downloader](https://github.com/anatasluo/ant): ANT Downloader is a BitTorrent Client developed by golang, angular 7, and electron <!-- archived -->\n * [Elementum](http://elementum.surge.sh/) (up to version 0.0.71)\n\n## Help\n\nCommunication about the project is primarily through [Discussions](https://github.com/anacrolix/torrent/discussions) and the [issue tracker](https://github.com/anacrolix/torrent/issues).\n\n## Command packages\n\nHere I'll describe what some of the packages in `./cmd` do. See [installation](#installation) to make them available.\n\n### `torrent`\n\n#### `torrent download`\n\nDownloads torrents from the command-line.\n\n    $ torrent download 'magnet:?xt=urn:btih:KRWPCX3SJUM4IMM4YF5RPHL6ANPYTQPU'\n    ... lots of jibber jabber ...\n    downloading \"ubuntu-14.04.2-desktop-amd64.iso\": 1.0 GB/1.0 GB, 1989/1992 pieces completed (1 partial)\n    2015/04/01 02:08:20 main.go:137: downloaded ALL the torrents\n    $ md5sum ubuntu-14.04.2-desktop-amd64.iso\n    1b305d585b1918f297164add46784116  ubuntu-14.04.2-desktop-amd64.iso\n    $ echo such amaze\n    wow\n\n#### `torrent metainfo magnet`\n\nCreates a magnet link from a torrent file. Note the extracted trackers, display name, and info hash.\n\n    $ torrent metainfo testdata/debian-10.8.0-amd64-netinst.iso.torrent magnet\n    magnet:?xt=urn:btih:4090c3c2a394a49974dfbbf2ce7ad0db3cdeddd7&dn=debian-10.8.0-amd64-netinst.iso&tr=http%3A%2F%2Fbttracker.debian.org%3A6969%2Fannounce\n\nSee `torrent metainfo --help` for other metainfo related commands.\n\n### `torrentfs`\n\ntorrentfs mounts a FUSE filesystem at `-mountDir`. The contents are the torrents described by the torrent files and magnet links at `-metainfoDir`. Data for read requests is fetched only as required from the torrent network, and stored at `-downloadDir`.\n\n    $ mkdir mnt torrents\n    $ torrentfs -mountDir=mnt -metainfoDir=torrents &\n    $ cd torrents\n    $ wget http://releases.ubuntu.com/14.04.2/ubuntu-14.04.2-desktop-amd64.iso.torrent\n    $ cd ..\n    $ ls mnt\n    ubuntu-14.04.2-desktop-amd64.iso\n    $ pv mnt/ubuntu-14.04.2-desktop-amd64.iso | md5sum\n    996MB 0:04:40 [3.55MB/s] [========================================>] 100%\n    1b305d585b1918f297164add46784116  -\n\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.5185546875,
          "content": "# Security Policy\n\n## Supported Versions\n\nThe two most recent minor releases are supported, with older versions receiving updates subject to contributor discretion.\nPlease also report issues in master, but there are no guarantees of stability there.\n\n## Reporting a Vulnerability\n\nAll vulnerability reports are welcomed. Use your discretion in providing information to Discussions, an Issue, or message a maintainer directly.\nFor a non-trivial issue, you should receive a response within a week, but more than likely a day or two.\n"
        },
        {
          "name": "TODO",
          "type": "blob",
          "size": 0.5126953125,
          "content": " * Make use of sparse file regions in download data for faster hashing. This is available as whence 3 and 4 on some OSs?\n * When we're choked and interested, are we not interested if there's no longer anything that we want?\n * dht: Randomize triedAddrs bloom filter to allow different Addr sets on each Announce.\n * data/blob: Deleting incomplete data triggers io.ErrUnexpectedEOF that isn't recovered from.\n * Handle wanted pieces more efficiently, it's slow in in fillRequests, since the prioritization system was changed.\n"
        },
        {
          "name": "analysis",
          "type": "tree",
          "content": null
        },
        {
          "name": "bad_storage.go",
          "type": "blob",
          "size": 1.279296875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"math/rand\"\n\t\"strings\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\ntype badStorage struct{}\n\nvar _ storage.ClientImpl = badStorage{}\n\nfunc (bs badStorage) OpenTorrent(\n\tcontext.Context,\n\t*metainfo.Info,\n\tmetainfo.Hash,\n) (storage.TorrentImpl, error) {\n\treturn storage.TorrentImpl{\n\t\tPiece: bs.Piece,\n\t}, nil\n}\n\nfunc (bs badStorage) Piece(p metainfo.Piece) storage.PieceImpl {\n\treturn badStoragePiece{p}\n}\n\ntype badStoragePiece struct {\n\tp metainfo.Piece\n}\n\nvar _ storage.PieceImpl = badStoragePiece{}\n\nfunc (p badStoragePiece) WriteAt(b []byte, off int64) (int, error) {\n\treturn 0, nil\n}\n\nfunc (p badStoragePiece) Completion() storage.Completion {\n\treturn storage.Completion{Complete: true, Ok: true}\n}\n\nfunc (p badStoragePiece) MarkComplete() error {\n\treturn errors.New(\"psyyyyyyyche\")\n}\n\nfunc (p badStoragePiece) MarkNotComplete() error {\n\treturn errors.New(\"psyyyyyyyche\")\n}\n\nfunc (p badStoragePiece) randomlyTruncatedDataString() string {\n\treturn testutil.GreetingFileContents[:rand.Intn(14)]\n}\n\nfunc (p badStoragePiece) ReadAt(b []byte, off int64) (n int, err error) {\n\tr := strings.NewReader(p.randomlyTruncatedDataString())\n\treturn r.ReadAt(b, off+p.p.Offset())\n}\n"
        },
        {
          "name": "bencode",
          "type": "tree",
          "content": null
        },
        {
          "name": "bep40.go",
          "type": "blob",
          "size": 1.7841796875,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"hash/crc32\"\n\t\"net\"\n)\n\nvar table = crc32.MakeTable(crc32.Castagnoli)\n\ntype peerPriority = uint32\n\nfunc sameSubnet(ones, bits int, a, b net.IP) bool {\n\tmask := net.CIDRMask(ones, bits)\n\treturn a.Mask(mask).Equal(b.Mask(mask))\n}\n\nfunc ipv4Mask(a, b net.IP) net.IPMask {\n\tif !sameSubnet(16, 32, a, b) {\n\t\treturn net.IPv4Mask(0xff, 0xff, 0x55, 0x55)\n\t}\n\tif !sameSubnet(24, 32, a, b) {\n\t\treturn net.IPv4Mask(0xff, 0xff, 0xff, 0x55)\n\t}\n\treturn net.IPv4Mask(0xff, 0xff, 0xff, 0xff)\n}\n\nfunc mask(prefix, bytes int) net.IPMask {\n\tret := make(net.IPMask, bytes)\n\tfor i := range ret {\n\t\tret[i] = 0x55\n\t}\n\tfor i := 0; i < prefix; i++ {\n\t\tret[i] = 0xff\n\t}\n\treturn ret\n}\n\nfunc ipv6Mask(a, b net.IP) net.IPMask {\n\tfor i := 6; i <= 16; i++ {\n\t\tif !sameSubnet(i*8, 128, a, b) {\n\t\t\treturn mask(i, 16)\n\t\t}\n\t}\n\tpanic(fmt.Sprintf(\"%s %s\", a, b))\n}\n\nfunc bep40PriorityBytes(a, b IpPort) ([]byte, error) {\n\tif a.IP.Equal(b.IP) {\n\t\tvar ret [4]byte\n\t\tbinary.BigEndian.PutUint16(ret[0:2], a.Port)\n\t\tbinary.BigEndian.PutUint16(ret[2:4], b.Port)\n\t\treturn ret[:], nil\n\t}\n\tif a4, b4 := a.IP.To4(), b.IP.To4(); a4 != nil && b4 != nil {\n\t\tm := ipv4Mask(a.IP, b.IP)\n\t\treturn append(a4.Mask(m), b4.Mask(m)...), nil\n\t}\n\tif a6, b6 := a.IP.To16(), b.IP.To16(); a6 != nil && b6 != nil {\n\t\tm := ipv6Mask(a.IP, b.IP)\n\t\treturn append(a6.Mask(m), b6.Mask(m)...), nil\n\t}\n\treturn nil, errors.New(\"incomparable IPs\")\n}\n\nfunc bep40Priority(a, b IpPort) (peerPriority, error) {\n\tbs, err := bep40PriorityBytes(a, b)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\ti := len(bs) / 2\n\t_a, _b := bs[:i], bs[i:]\n\tif bytes.Compare(_a, _b) > 0 {\n\t\tbs = append(_b, _a...)\n\t}\n\treturn crc32.Checksum(bs, table), nil\n}\n\nfunc bep40PriorityIgnoreError(a, b IpPort) peerPriority {\n\tprio, _ := bep40Priority(a, b)\n\treturn prio\n}\n"
        },
        {
          "name": "bep40_test.go",
          "type": "blob",
          "size": 1.048828125,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestBep40Priority(t *testing.T) {\n\tassert.EqualValues(t, peerPriority(0xec2d7224), bep40PriorityIgnoreError(\n\t\tIpPort{IP: net.ParseIP(\"123.213.32.10\"), Port: 0},\n\t\tIpPort{IP: net.ParseIP(\"98.76.54.32\"), Port: 0},\n\t))\n\tassert.EqualValues(t, peerPriority(0xec2d7224), bep40PriorityIgnoreError(\n\t\tIpPort{IP: net.ParseIP(\"98.76.54.32\"), Port: 0},\n\t\tIpPort{IP: net.ParseIP(\"123.213.32.10\"), Port: 0},\n\t))\n\tassert.Equal(t, peerPriority(0x99568189), bep40PriorityIgnoreError(\n\t\tIpPort{IP: net.ParseIP(\"123.213.32.10\"), Port: 0},\n\t\tIpPort{IP: net.ParseIP(\"123.213.32.234\"), Port: 0},\n\t))\n\tassert.Equal(t, peerPriority(0x2b41d456), bep40PriorityIgnoreError(\n\t\tIpPort{IP: net.ParseIP(\"206.248.98.111\"), Port: 0},\n\t\tIpPort{IP: net.ParseIP(\"142.147.89.224\"), Port: 0},\n\t))\n\tassert.EqualValues(t, \"\\x00\\x00\\x00\\x00\", func() []byte {\n\t\tb, _ := bep40PriorityBytes(\n\t\t\tIpPort{IP: net.ParseIP(\"123.213.32.234\"), Port: 0},\n\t\t\tIpPort{IP: net.ParseIP(\"123.213.32.234\"), Port: 0},\n\t\t)\n\t\treturn b\n\t}())\n}\n"
        },
        {
          "name": "callbacks.go",
          "type": "blob",
          "size": 1.9658203125,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/torrent/mse\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\n// These are called synchronously, and do not pass ownership of arguments (do not expect to retain\n// data after returning from the callback). The Client and other locks may still be held. nil\n// functions are not called.\ntype Callbacks struct {\n\t// Called after a peer connection completes the BitTorrent handshake. The Client lock is not\n\t// held.\n\tCompletedHandshake func(*PeerConn, InfoHash)\n\tReadMessage        func(*PeerConn, *pp.Message)\n\t// This can be folded into the general case below.\n\tReadExtendedHandshake func(*PeerConn, *pp.ExtendedHandshakeMessage)\n\tPeerConnClosed        func(*PeerConn)\n\t// BEP 10 message. Not sure if I should call this Ltep universally. Each handler here is called\n\t// in order.\n\tPeerConnReadExtensionMessage []func(PeerConnReadExtensionMessageEvent)\n\n\t// Provides secret keys to be tried against incoming encrypted connections.\n\tReceiveEncryptedHandshakeSkeys mse.SecretKeyIter\n\n\tReceivedUsefulData []func(ReceivedUsefulDataEvent)\n\tReceivedRequested  []func(PeerMessageEvent)\n\tDeletedRequest     []func(PeerRequestEvent)\n\tSentRequest        []func(PeerRequestEvent)\n\tPeerClosed         []func(*Peer)\n\tNewPeer            []func(*Peer)\n\t// Called when a PeerConn has been added to a Torrent. It's finished all BitTorrent protocol\n\t// handshakes, and is about to start sending and receiving BitTorrent messages. The extended\n\t// handshake has not yet occurred. This is a good time to alter the supported extension\n\t// protocols.\n\tPeerConnAdded []func(*PeerConn)\n}\n\ntype ReceivedUsefulDataEvent = PeerMessageEvent\n\ntype PeerMessageEvent struct {\n\tPeer    *Peer\n\tMessage *pp.Message\n}\n\ntype PeerRequestEvent struct {\n\tPeer *Peer\n\tRequest\n}\n\ntype PeerConnReadExtensionMessageEvent struct {\n\tPeerConn *PeerConn\n\t// You can look up what protocol this corresponds to using the PeerConn.LocalLtepProtocolMap.\n\tExtensionNumber pp.ExtensionNumber\n\tPayload         []byte\n}\n"
        },
        {
          "name": "client-nowasm_test.go",
          "type": "blob",
          "size": 1.796875,
          "content": "//go:build !wasm\n// +build !wasm\n\npackage torrent\n\nimport (\n\t\"os\"\n\t\"testing\"\n\n\tqt \"github.com/frankban/quicktest\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc TestBoltPieceCompletionClosedWhenClientClosed(t *testing.T) {\n\tc := qt.New(t)\n\tcfg := TestingConfig(t)\n\tpc, err := storage.NewBoltPieceCompletion(cfg.DataDir)\n\trequire.NoError(t, err)\n\tci := storage.NewFileWithCompletion(cfg.DataDir, pc)\n\tdefer ci.Close()\n\tcfg.DefaultStorage = ci\n\tcl, err := NewClient(cfg)\n\tc.Assert(err, qt.IsNil, qt.Commentf(\"%#v\", err))\n\tcl.Close()\n\t// And again, https://github.com/anacrolix/torrent/issues/158\n\tcl, err = NewClient(cfg)\n\trequire.NoError(t, err)\n\tcl.Close()\n}\n\nfunc TestIssue335(t *testing.T) {\n\tdir, mi := testutil.GreetingTestTorrent()\n\tdefer func() {\n\t\terr := os.RemoveAll(dir)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"removing torrent dummy data dir: %v\", err)\n\t\t}\n\t}()\n\tlogErr := func(f func() error, msg string) {\n\t\terr := f()\n\t\tt.Logf(\"%s: %v\", msg, err)\n\t\tif err != nil {\n\t\t\tt.Fail()\n\t\t}\n\t}\n\tcfg := TestingConfig(t)\n\tcfg.Seed = false\n\tcfg.Debug = true\n\tcfg.DataDir = dir\n\tcomp, err := storage.NewBoltPieceCompletion(dir)\n\tc := qt.New(t)\n\tc.Assert(err, qt.IsNil)\n\tdefer logErr(comp.Close, \"closing bolt piece completion\")\n\tmmapStorage := storage.NewMMapWithCompletion(dir, comp)\n\tdefer logErr(mmapStorage.Close, \"closing mmap storage\")\n\tcfg.DefaultStorage = mmapStorage\n\tcl, err := NewClient(cfg)\n\tc.Assert(err, qt.IsNil)\n\tdefer cl.Close()\n\ttor, new, err := cl.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tc.Assert(err, qt.IsNil)\n\tc.Assert(new, qt.IsTrue)\n\tc.Assert(cl.WaitAll(), qt.IsTrue)\n\ttor.Drop()\n\t_, new, err = cl.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tc.Assert(err, qt.IsNil)\n\tc.Assert(new, qt.IsTrue)\n\tc.Assert(cl.WaitAll(), qt.IsTrue)\n}\n"
        },
        {
          "name": "client-stats.go",
          "type": "blob",
          "size": 2.251953125,
          "content": "package torrent\n\nimport (\n\t\"net/netip\"\n\n\tg \"github.com/anacrolix/generics\"\n)\n\nfunc setAdd[K comparable](m *map[K]struct{}, elem K) {\n\tg.MakeMapIfNilAndSet(m, elem, struct{}{})\n}\n\ntype clientHolepunchAddrSets struct {\n\tundialableWithoutHolepunch                            map[netip.AddrPort]struct{}\n\tundialableWithoutHolepunchDialedAfterHolepunchConnect map[netip.AddrPort]struct{}\n\tdialableOnlyAfterHolepunch                            map[netip.AddrPort]struct{}\n\tdialedSuccessfullyAfterHolepunchConnect               map[netip.AddrPort]struct{}\n\tprobablyOnlyConnectedDueToHolepunch                   map[netip.AddrPort]struct{}\n\taccepted                                              map[netip.AddrPort]struct{}\n}\n\ntype ClientStats struct {\n\tConnStats\n\n\t// Ongoing outgoing dial attempts. There may be more than one dial going on per peer address due\n\t// to hole-punch connect requests. The total may not match the sum of attempts for all Torrents\n\t// if a Torrent is dropped while there are outstanding dials.\n\tActiveHalfOpenAttempts int\n\n\tNumPeersUndialableWithoutHolepunch int\n\t// Number of unique peer addresses that were dialed after receiving a holepunch connect message,\n\t// that have previously been undialable without any hole-punching attempts.\n\tNumPeersUndialableWithoutHolepunchDialedAfterHolepunchConnect int\n\t// Number of unique peer addresses that were successfully dialed and connected after a holepunch\n\t// connect message and previously failing to connect without holepunching.\n\tNumPeersDialableOnlyAfterHolepunch              int\n\tNumPeersDialedSuccessfullyAfterHolepunchConnect int\n\tNumPeersProbablyOnlyConnectedDueToHolepunch     int\n}\n\nfunc (cl *Client) statsLocked() (stats ClientStats) {\n\tstats.ConnStats = cl.connStats.Copy()\n\tstats.ActiveHalfOpenAttempts = cl.numHalfOpen\n\n\tstats.NumPeersUndialableWithoutHolepunch = len(cl.undialableWithoutHolepunch)\n\tstats.NumPeersUndialableWithoutHolepunchDialedAfterHolepunchConnect = len(cl.undialableWithoutHolepunchDialedAfterHolepunchConnect)\n\tstats.NumPeersDialableOnlyAfterHolepunch = len(cl.dialableOnlyAfterHolepunch)\n\tstats.NumPeersDialedSuccessfullyAfterHolepunchConnect = len(cl.dialedSuccessfullyAfterHolepunchConnect)\n\tstats.NumPeersProbablyOnlyConnectedDueToHolepunch = len(cl.probablyOnlyConnectedDueToHolepunch)\n\n\treturn\n}\n"
        },
        {
          "name": "client.go",
          "type": "blob",
          "size": 48.9765625,
          "content": "package torrent\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/binary\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/netip\"\n\t\"sort\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/anacrolix/chansync\"\n\t\"github.com/anacrolix/chansync/events\"\n\t\"github.com/anacrolix/dht/v2\"\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\t. \"github.com/anacrolix/generics\"\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\t\"github.com/anacrolix/missinggo/v2/pproffd\"\n\t\"github.com/anacrolix/sync\"\n\t\"github.com/cespare/xxhash\"\n\t\"github.com/davecgh/go-spew/spew\"\n\t\"github.com/dustin/go-humanize\"\n\tgbtree \"github.com/google/btree\"\n\t\"github.com/pion/webrtc/v4\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/internal/check\"\n\t\"github.com/anacrolix/torrent/internal/limiter\"\n\t\"github.com/anacrolix/torrent/iplist\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\t\"github.com/anacrolix/torrent/mse\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n\t\"github.com/anacrolix/torrent/storage\"\n\t\"github.com/anacrolix/torrent/tracker\"\n\t\"github.com/anacrolix/torrent/types/infohash\"\n\tinfohash_v2 \"github.com/anacrolix/torrent/types/infohash-v2\"\n\t\"github.com/anacrolix/torrent/webtorrent\"\n)\n\n// Clients contain zero or more Torrents. A Client manages a blocklist, the\n// TCP/UDP protocol ports, and DHT as desired.\ntype Client struct {\n\t// An aggregate of stats over all connections. First in struct to ensure 64-bit alignment of\n\t// fields. See #262.\n\tconnStats ConnStats\n\n\t_mu    lockWithDeferreds\n\tevent  sync.Cond\n\tclosed chansync.SetOnce\n\n\tconfig *ClientConfig\n\tlogger log.Logger\n\n\tpeerID         PeerID\n\tdefaultStorage *storage.Client\n\tonClose        []func()\n\tdialers        []Dialer\n\tlisteners      []Listener\n\tdhtServers     []DhtServer\n\tipBlockList    iplist.Ranger\n\n\t// Set of addresses that have our client ID. This intentionally will\n\t// include ourselves if we end up trying to connect to our own address\n\t// through legitimate channels.\n\tdopplegangerAddrs map[string]struct{}\n\tbadPeerIPs        map[netip.Addr]struct{}\n\t// All Torrents once.\n\ttorrents map[*Torrent]struct{}\n\t// All Torrents by their short infohashes (v1 if valid, and truncated v2 if valid). Unless the\n\t// info has been obtained, there's no knowing if an infohash belongs to v1 or v2.\n\ttorrentsByShortHash map[InfoHash]*Torrent\n\n\tpieceRequestOrder map[interface{}]*request_strategy.PieceRequestOrder\n\n\tacceptLimiter map[ipStr]int\n\tnumHalfOpen   int\n\n\twebsocketTrackers websocketTrackers\n\n\tactiveAnnounceLimiter limiter.Instance\n\thttpClient            *http.Client\n\n\tclientHolepunchAddrSets\n\n\tdefaultLocalLtepProtocolMap LocalLtepProtocolMap\n\n\tupnpMappings []*upnpMapping\n}\n\ntype ipStr string\n\nfunc (cl *Client) BadPeerIPs() (ips []string) {\n\tcl.rLock()\n\tips = cl.badPeerIPsLocked()\n\tcl.rUnlock()\n\treturn\n}\n\nfunc (cl *Client) badPeerIPsLocked() (ips []string) {\n\tips = make([]string, len(cl.badPeerIPs))\n\ti := 0\n\tfor k := range cl.badPeerIPs {\n\t\tips[i] = k.String()\n\t\ti += 1\n\t}\n\treturn\n}\n\nfunc (cl *Client) PeerID() PeerID {\n\treturn cl.peerID\n}\n\n// Returns the port number for the first listener that has one. No longer assumes that all port\n// numbers are the same, due to support for custom listeners. Returns zero if no port number is\n// found.\nfunc (cl *Client) LocalPort() (port int) {\n\tfor i := 0; i < len(cl.listeners); i += 1 {\n\t\tif port = addrPortOrZero(cl.listeners[i].Addr()); port != 0 {\n\t\t\treturn\n\t\t}\n\t}\n\treturn\n}\n\nfunc writeDhtServerStatus(w io.Writer, s DhtServer) {\n\tdhtStats := s.Stats()\n\tfmt.Fprintf(w, \" ID: %x\\n\", s.ID())\n\tspew.Fdump(w, dhtStats)\n}\n\n// Writes out a human readable status of the client, such as for writing to a\n// HTTP status page.\nfunc (cl *Client) WriteStatus(_w io.Writer) {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\tw := bufio.NewWriter(_w)\n\tdefer w.Flush()\n\tfmt.Fprintf(w, \"Listen port: %d\\n\", cl.LocalPort())\n\tfmt.Fprintf(w, \"Peer ID: %+q\\n\", cl.PeerID())\n\tfmt.Fprintf(w, \"Extension bits: %v\\n\", cl.config.Extensions)\n\tfmt.Fprintf(w, \"Announce key: %x\\n\", cl.announceKey())\n\tfmt.Fprintf(w, \"Banned IPs: %d\\n\", len(cl.badPeerIPsLocked()))\n\tcl.eachDhtServer(func(s DhtServer) {\n\t\tfmt.Fprintf(w, \"%s DHT server at %s:\\n\", s.Addr().Network(), s.Addr().String())\n\t\twriteDhtServerStatus(w, s)\n\t})\n\tdumpStats(w, cl.statsLocked())\n\ttorrentsSlice := cl.torrentsAsSlice()\n\tfmt.Fprintf(w, \"# Torrents: %d\\n\", len(torrentsSlice))\n\tfmt.Fprintln(w)\n\tsort.Slice(torrentsSlice, func(l, r int) bool {\n\t\treturn torrentsSlice[l].canonicalShortInfohash().AsString() < torrentsSlice[r].canonicalShortInfohash().AsString()\n\t})\n\tfor _, t := range torrentsSlice {\n\t\tif t.name() == \"\" {\n\t\t\tfmt.Fprint(w, \"<unknown name>\")\n\t\t} else {\n\t\t\tfmt.Fprint(w, t.name())\n\t\t}\n\t\tfmt.Fprint(w, \"\\n\")\n\t\tif t.info != nil {\n\t\t\tfmt.Fprintf(\n\t\t\t\tw,\n\t\t\t\t\"%f%% of %d bytes (%s)\",\n\t\t\t\t100*(1-float64(t.bytesMissingLocked())/float64(t.info.TotalLength())),\n\t\t\t\tt.length(),\n\t\t\t\thumanize.Bytes(uint64(t.length())))\n\t\t} else {\n\t\t\tw.WriteString(\"<missing metainfo>\")\n\t\t}\n\t\tfmt.Fprint(w, \"\\n\")\n\t\tt.writeStatus(w)\n\t\tfmt.Fprintln(w)\n\t}\n}\n\nfunc (cl *Client) initLogger() {\n\tlogger := cl.config.Logger\n\tif logger.IsZero() {\n\t\tlogger = log.Default\n\t}\n\tif cl.config.Debug {\n\t\tlogger = logger.WithFilterLevel(log.Debug)\n\t}\n\tcl.logger = logger.WithValues(cl)\n}\n\nfunc (cl *Client) announceKey() int32 {\n\treturn int32(binary.BigEndian.Uint32(cl.peerID[16:20]))\n}\n\n// Initializes a bare minimum Client. *Client and *ClientConfig must not be nil.\nfunc (cl *Client) init(cfg *ClientConfig) {\n\tcl.config = cfg\n\tg.MakeMap(&cl.dopplegangerAddrs)\n\tg.MakeMap(&cl.torrentsByShortHash)\n\tg.MakeMap(&cl.torrents)\n\tcl.torrentsByShortHash = make(map[metainfo.Hash]*Torrent)\n\tcl.activeAnnounceLimiter.SlotsPerKey = 2\n\tcl.event.L = cl.locker()\n\tcl.ipBlockList = cfg.IPBlocklist\n\tcl.httpClient = &http.Client{\n\t\tTransport: cfg.WebTransport,\n\t}\n\tif cl.httpClient.Transport == nil {\n\t\tcl.httpClient.Transport = &http.Transport{\n\t\t\tProxy:       cfg.HTTPProxy,\n\t\t\tDialContext: cfg.HTTPDialContext,\n\t\t\t// I think this value was observed from some webseeds. It seems reasonable to extend it\n\t\t\t// to other uses of HTTP from the client.\n\t\t\tMaxConnsPerHost: 10,\n\t\t}\n\t}\n\tcl.defaultLocalLtepProtocolMap = makeBuiltinLtepProtocols(!cfg.DisablePEX)\n}\n\nfunc NewClient(cfg *ClientConfig) (cl *Client, err error) {\n\tif cfg == nil {\n\t\tcfg = NewDefaultClientConfig()\n\t\tcfg.ListenPort = 0\n\t}\n\tcl = &Client{}\n\tcl.init(cfg)\n\tgo cl.acceptLimitClearer()\n\tcl.initLogger()\n\t//cl.logger.Levelf(log.Critical, \"test after init\")\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tcl.Close()\n\t\t\tcl = nil\n\t\t}\n\t}()\n\n\tstorageImpl := cfg.DefaultStorage\n\tif storageImpl == nil {\n\t\t// We'd use mmap by default but HFS+ doesn't support sparse files.\n\t\tstorageImplCloser := storage.NewFile(cfg.DataDir)\n\t\tcl.onClose = append(cl.onClose, func() {\n\t\t\tif err := storageImplCloser.Close(); err != nil {\n\t\t\t\tcl.logger.Printf(\"error closing default storage: %s\", err)\n\t\t\t}\n\t\t})\n\t\tstorageImpl = storageImplCloser\n\t}\n\tcl.defaultStorage = storage.NewClient(storageImpl)\n\n\tif cfg.PeerID != \"\" {\n\t\tmissinggo.CopyExact(&cl.peerID, cfg.PeerID)\n\t} else {\n\t\to := copy(cl.peerID[:], cfg.Bep20)\n\t\t_, err = rand.Read(cl.peerID[o:])\n\t\tif err != nil {\n\t\t\tpanic(\"error generating peer id\")\n\t\t}\n\t}\n\n\tbuiltinListenNetworks := cl.listenNetworks()\n\tsockets, err := listenAll(\n\t\tbuiltinListenNetworks,\n\t\tcl.config.ListenHost,\n\t\tcl.config.ListenPort,\n\t\tcl.firewallCallback,\n\t\tcl.logger,\n\t)\n\tif err != nil {\n\t\treturn\n\t}\n\tif len(sockets) == 0 && len(builtinListenNetworks) != 0 {\n\t\terr = fmt.Errorf(\"no sockets created for networks %v\", builtinListenNetworks)\n\t\treturn\n\t}\n\n\t// Check for panics.\n\tcl.LocalPort()\n\n\tfor _, _s := range sockets {\n\t\ts := _s // Go is fucking retarded.\n\t\tcl.onClose = append(cl.onClose, func() { go s.Close() })\n\t\tif peerNetworkEnabled(parseNetworkString(s.Addr().Network()), cl.config) {\n\t\t\tcl.dialers = append(cl.dialers, s)\n\t\t\tcl.listeners = append(cl.listeners, s)\n\t\t\tif cl.config.AcceptPeerConnections {\n\t\t\t\tgo cl.acceptConnections(s)\n\t\t\t}\n\t\t}\n\t}\n\n\tgo cl.forwardPort()\n\tif !cfg.NoDHT {\n\t\tfor _, s := range sockets {\n\t\t\tif pc, ok := s.(net.PacketConn); ok {\n\t\t\t\tds, err := cl.NewAnacrolixDhtServer(pc)\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t\tcl.dhtServers = append(cl.dhtServers, AnacrolixDhtServerWrapper{ds})\n\t\t\t\tcl.onClose = append(cl.onClose, func() { ds.Close() })\n\t\t\t}\n\t\t}\n\t}\n\n\tcl.websocketTrackers = websocketTrackers{\n\t\tPeerId: cl.peerID,\n\t\tLogger: cl.logger.WithNames(\"websocketTrackers\"),\n\t\tGetAnnounceRequest: func(\n\t\t\tevent tracker.AnnounceEvent, infoHash [20]byte,\n\t\t) (\n\t\t\ttracker.AnnounceRequest, error,\n\t\t) {\n\t\t\tcl.lock()\n\t\t\tdefer cl.unlock()\n\t\t\tt, ok := cl.torrentsByShortHash[infoHash]\n\t\t\tif !ok {\n\t\t\t\treturn tracker.AnnounceRequest{}, errors.New(\"torrent not tracked by client\")\n\t\t\t}\n\t\t\treturn t.announceRequest(event, infoHash), nil\n\t\t},\n\t\tProxy:                      cl.config.HTTPProxy,\n\t\tWebsocketTrackerHttpHeader: cl.config.WebsocketTrackerHttpHeader,\n\t\tICEServers:                 cl.ICEServers(),\n\t\tDialContext:                cl.config.TrackerDialContext,\n\t\tOnConn: func(dc webtorrent.DataChannelConn, dcc webtorrent.DataChannelContext) {\n\t\t\tcl.lock()\n\t\t\tdefer cl.unlock()\n\t\t\tt, ok := cl.torrentsByShortHash[dcc.InfoHash]\n\t\t\tif !ok {\n\t\t\t\tcl.logger.WithDefaultLevel(log.Warning).Printf(\n\t\t\t\t\t\"got webrtc conn for unloaded torrent with infohash %x\",\n\t\t\t\t\tdcc.InfoHash,\n\t\t\t\t)\n\t\t\t\tdc.Close()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tgo t.onWebRtcConn(dc, dcc)\n\t\t},\n\t}\n\n\treturn\n}\n\nfunc (cl *Client) AddDhtServer(d DhtServer) {\n\tcl.dhtServers = append(cl.dhtServers, d)\n}\n\n// Adds a Dialer for outgoing connections. All Dialers are used when attempting to connect to a\n// given address for any Torrent.\nfunc (cl *Client) AddDialer(d Dialer) {\n\tcl.lock()\n\tdefer cl.unlock()\n\tcl.dialers = append(cl.dialers, d)\n\tfor t := range cl.torrents {\n\t\tt.openNewConns()\n\t}\n}\n\nfunc (cl *Client) Listeners() []Listener {\n\treturn cl.listeners\n}\n\n// Registers a Listener, and starts Accepting on it. You must Close Listeners provided this way\n// yourself.\nfunc (cl *Client) AddListener(l Listener) {\n\tcl.listeners = append(cl.listeners, l)\n\tif cl.config.AcceptPeerConnections {\n\t\tgo cl.acceptConnections(l)\n\t}\n}\n\nfunc (cl *Client) firewallCallback(net.Addr) bool {\n\tcl.rLock()\n\tblock := !cl.wantConns() || !cl.config.AcceptPeerConnections\n\tcl.rUnlock()\n\tif block {\n\t\ttorrent.Add(\"connections firewalled\", 1)\n\t} else {\n\t\ttorrent.Add(\"connections not firewalled\", 1)\n\t}\n\treturn block\n}\n\nfunc (cl *Client) listenOnNetwork(n network) bool {\n\tif n.Ipv4 && cl.config.DisableIPv4 {\n\t\treturn false\n\t}\n\tif n.Ipv6 && cl.config.DisableIPv6 {\n\t\treturn false\n\t}\n\tif n.Tcp && cl.config.DisableTCP {\n\t\treturn false\n\t}\n\tif n.Udp && cl.config.DisableUTP && cl.config.NoDHT {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (cl *Client) listenNetworks() (ns []network) {\n\tfor _, n := range allPeerNetworks {\n\t\tif cl.listenOnNetwork(n) {\n\t\t\tns = append(ns, n)\n\t\t}\n\t}\n\treturn\n}\n\n// Creates an anacrolix/dht Server, as would be done internally in NewClient, for the given conn.\nfunc (cl *Client) NewAnacrolixDhtServer(conn net.PacketConn) (s *dht.Server, err error) {\n\tlogger := cl.logger.WithNames(\"dht\", conn.LocalAddr().String())\n\tcfg := dht.ServerConfig{\n\t\tIPBlocklist:    cl.ipBlockList,\n\t\tConn:           conn,\n\t\tOnAnnouncePeer: cl.onDHTAnnouncePeer,\n\t\tPublicIP: func() net.IP {\n\t\t\tif connIsIpv6(conn) && cl.config.PublicIp6 != nil {\n\t\t\t\treturn cl.config.PublicIp6\n\t\t\t}\n\t\t\treturn cl.config.PublicIp4\n\t\t}(),\n\t\tStartingNodes: cl.config.DhtStartingNodes(conn.LocalAddr().Network()),\n\t\tOnQuery:       cl.config.DHTOnQuery,\n\t\tLogger:        logger,\n\t}\n\tif f := cl.config.ConfigureAnacrolixDhtServer; f != nil {\n\t\tf(&cfg)\n\t}\n\ts, err = dht.NewServer(&cfg)\n\tif err == nil {\n\t\tgo s.TableMaintainer()\n\t}\n\treturn\n}\n\nfunc (cl *Client) Closed() events.Done {\n\treturn cl.closed.Done()\n}\n\nfunc (cl *Client) eachDhtServer(f func(DhtServer)) {\n\tfor _, ds := range cl.dhtServers {\n\t\tf(ds)\n\t}\n}\n\n// Stops the client. All connections to peers are closed and all activity will come to a halt.\nfunc (cl *Client) Close() (errs []error) {\n\tvar closeGroup sync.WaitGroup // For concurrent cleanup to complete before returning\n\tcl.lock()\n\tfor t := range cl.torrents {\n\t\terr := t.close(&closeGroup)\n\t\tif err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\tcl.clearPortMappings()\n\tfor i := range cl.onClose {\n\t\tcl.onClose[len(cl.onClose)-1-i]()\n\t}\n\tcl.closed.Set()\n\tcl.unlock()\n\tcl.event.Broadcast()\n\tcloseGroup.Wait() // defer is LIFO. We want to Wait() after cl.unlock()\n\treturn\n}\n\nfunc (cl *Client) ipBlockRange(ip net.IP) (r iplist.Range, blocked bool) {\n\tif cl.ipBlockList == nil {\n\t\treturn\n\t}\n\treturn cl.ipBlockList.Lookup(ip)\n}\n\nfunc (cl *Client) ipIsBlocked(ip net.IP) bool {\n\t_, blocked := cl.ipBlockRange(ip)\n\treturn blocked\n}\n\nfunc (cl *Client) wantConns() bool {\n\tif cl.config.AlwaysWantConns {\n\t\treturn true\n\t}\n\tfor t := range cl.torrents {\n\t\tif t.wantIncomingConns() {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// TODO: Apply filters for non-standard networks, particularly rate-limiting.\nfunc (cl *Client) rejectAccepted(conn net.Conn) error {\n\tif !cl.wantConns() {\n\t\treturn errors.New(\"don't want conns right now\")\n\t}\n\tra := conn.RemoteAddr()\n\tif rip := addrIpOrNil(ra); rip != nil {\n\t\tif cl.config.DisableIPv4Peers && rip.To4() != nil {\n\t\t\treturn errors.New(\"ipv4 peers disabled\")\n\t\t}\n\t\tif cl.config.DisableIPv4 && len(rip) == net.IPv4len {\n\t\t\treturn errors.New(\"ipv4 disabled\")\n\t\t}\n\t\tif cl.config.DisableIPv6 && len(rip) == net.IPv6len && rip.To4() == nil {\n\t\t\treturn errors.New(\"ipv6 disabled\")\n\t\t}\n\t\tif cl.rateLimitAccept(rip) {\n\t\t\treturn errors.New(\"source IP accepted rate limited\")\n\t\t}\n\t\tif cl.badPeerIPPort(rip, missinggo.AddrPort(ra)) {\n\t\t\treturn errors.New(\"bad source addr\")\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (cl *Client) acceptConnections(l Listener) {\n\tfor {\n\t\tconn, err := l.Accept()\n\t\ttorrent.Add(\"client listener accepts\", 1)\n\t\tif err == nil {\n\t\t\tholepunchAddr, holepunchErr := addrPortFromPeerRemoteAddr(conn.RemoteAddr())\n\t\t\tif holepunchErr == nil {\n\t\t\t\tcl.lock()\n\t\t\t\tif g.MapContains(cl.undialableWithoutHolepunch, holepunchAddr) {\n\t\t\t\t\tsetAdd(&cl.accepted, holepunchAddr)\n\t\t\t\t}\n\t\t\t\tif g.MapContains(\n\t\t\t\t\tcl.undialableWithoutHolepunchDialedAfterHolepunchConnect,\n\t\t\t\t\tholepunchAddr,\n\t\t\t\t) {\n\t\t\t\t\tsetAdd(&cl.probablyOnlyConnectedDueToHolepunch, holepunchAddr)\n\t\t\t\t}\n\t\t\t\tcl.unlock()\n\t\t\t}\n\t\t}\n\t\tconn = pproffd.WrapNetConn(conn)\n\t\tcl.rLock()\n\t\tclosed := cl.closed.IsSet()\n\t\tvar reject error\n\t\tif !closed && conn != nil {\n\t\t\treject = cl.rejectAccepted(conn)\n\t\t}\n\t\tcl.rUnlock()\n\t\tif closed {\n\t\t\tif conn != nil {\n\t\t\t\tconn.Close()\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tlog.Fmsg(\"error accepting connection: %s\", err).LogLevel(log.Debug, cl.logger)\n\t\t\tcontinue\n\t\t}\n\t\tgo func() {\n\t\t\tif reject != nil {\n\t\t\t\ttorrent.Add(\"rejected accepted connections\", 1)\n\t\t\t\tcl.logger.LazyLog(log.Debug, func() log.Msg {\n\t\t\t\t\treturn log.Fmsg(\"rejecting accepted conn: %v\", reject)\n\t\t\t\t})\n\t\t\t\tconn.Close()\n\t\t\t} else {\n\t\t\t\tgo cl.incomingConnection(conn)\n\t\t\t}\n\t\t\tcl.logger.LazyLog(log.Debug, func() log.Msg {\n\t\t\t\treturn log.Fmsg(\"accepted %q connection at %q from %q\",\n\t\t\t\t\tl.Addr().Network(),\n\t\t\t\t\tconn.LocalAddr(),\n\t\t\t\t\tconn.RemoteAddr(),\n\t\t\t\t)\n\t\t\t})\n\t\t\ttorrent.Add(fmt.Sprintf(\"accepted conn remote IP len=%d\", len(addrIpOrNil(conn.RemoteAddr()))), 1)\n\t\t\ttorrent.Add(fmt.Sprintf(\"accepted conn network=%s\", conn.RemoteAddr().Network()), 1)\n\t\t\ttorrent.Add(fmt.Sprintf(\"accepted on %s listener\", l.Addr().Network()), 1)\n\t\t}()\n\t}\n}\n\n// Creates the PeerConn.connString for a regular net.Conn PeerConn.\nfunc regularNetConnPeerConnConnString(nc net.Conn) string {\n\treturn fmt.Sprintf(\"%s-%s\", nc.LocalAddr(), nc.RemoteAddr())\n}\n\nfunc (cl *Client) incomingConnection(nc net.Conn) {\n\tdefer nc.Close()\n\tif tc, ok := nc.(*net.TCPConn); ok {\n\t\ttc.SetLinger(0)\n\t}\n\tremoteAddr, _ := tryIpPortFromNetAddr(nc.RemoteAddr())\n\tc := cl.newConnection(\n\t\tnc,\n\t\tnewConnectionOpts{\n\t\t\toutgoing:        false,\n\t\t\tremoteAddr:      nc.RemoteAddr(),\n\t\t\tlocalPublicAddr: cl.publicAddr(remoteAddr.IP),\n\t\t\tnetwork:         nc.RemoteAddr().Network(),\n\t\t\tconnString:      regularNetConnPeerConnConnString(nc),\n\t\t})\n\tc.Discovery = PeerSourceIncoming\n\tcl.runReceivedConn(c)\n\n\tcl.lock()\n\tc.close()\n\tcl.unlock()\n}\n\n// Returns a handle to the given torrent, if it's present in the client.\nfunc (cl *Client) Torrent(ih metainfo.Hash) (t *Torrent, ok bool) {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\tt, ok = cl.torrentsByShortHash[ih]\n\treturn\n}\n\ntype DialResult struct {\n\tConn   net.Conn\n\tDialer Dialer\n}\n\nfunc countDialResult(err error) {\n\tif err == nil {\n\t\ttorrent.Add(\"successful dials\", 1)\n\t} else {\n\t\ttorrent.Add(\"unsuccessful dials\", 1)\n\t}\n}\n\nfunc reducedDialTimeout(minDialTimeout, max time.Duration, halfOpenLimit, pendingPeers int) (ret time.Duration) {\n\tret = max / time.Duration((pendingPeers+halfOpenLimit)/halfOpenLimit)\n\tif ret < minDialTimeout {\n\t\tret = minDialTimeout\n\t}\n\treturn\n}\n\n// Returns whether an address is known to connect to a client with our own ID.\nfunc (cl *Client) dopplegangerAddr(addr string) bool {\n\t_, ok := cl.dopplegangerAddrs[addr]\n\treturn ok\n}\n\n// Returns a connection over UTP or TCP, whichever is first to connect.\nfunc (cl *Client) dialFirst(ctx context.Context, addr string) (res DialResult) {\n\treturn DialFirst(ctx, addr, cl.dialers)\n}\n\n// Returns a connection over UTP or TCP, whichever is first to connect.\nfunc DialFirst(ctx context.Context, addr string, dialers []Dialer) (res DialResult) {\n\tpool := dialPool{\n\t\taddr: addr,\n\t}\n\tdefer pool.startDrainer()\n\tfor _, _s := range dialers {\n\t\tpool.add(ctx, _s)\n\t}\n\treturn pool.getFirst()\n}\n\nfunc dialFromSocket(ctx context.Context, s Dialer, addr string) net.Conn {\n\tc, err := s.Dial(ctx, addr)\n\tif err != nil {\n\t\tlog.ContextLogger(ctx).Levelf(log.Debug, \"error dialing %q: %v\", addr, err)\n\t}\n\t// This is a bit optimistic, but it looks non-trivial to thread this through the proxy code. Set\n\t// it now in case we close the connection forthwith. Note this is also done in the TCP dialer\n\t// code to increase the chance it's done.\n\tif tc, ok := c.(*net.TCPConn); ok {\n\t\ttc.SetLinger(0)\n\t}\n\tcountDialResult(err)\n\treturn c\n}\n\nfunc (cl *Client) noLongerHalfOpen(t *Torrent, addr string, attemptKey outgoingConnAttemptKey) {\n\tpath := t.getHalfOpenPath(addr, attemptKey)\n\tif !path.Exists() {\n\t\tpanic(\"should exist\")\n\t}\n\tpath.Delete()\n\tcl.numHalfOpen--\n\tif cl.numHalfOpen < 0 {\n\t\tpanic(\"should not be possible\")\n\t}\n\tfor t := range cl.torrents {\n\t\tt.openNewConns()\n\t}\n}\n\nfunc (cl *Client) countHalfOpenFromTorrents() (count int) {\n\tfor t := range cl.torrents {\n\t\tcount += t.numHalfOpenAttempts()\n\t}\n\treturn\n}\n\n// Performs initiator handshakes and returns a connection. Returns nil *PeerConn if no connection\n// for valid reasons.\nfunc (cl *Client) initiateProtocolHandshakes(\n\tctx context.Context,\n\tnc net.Conn,\n\tt *Torrent,\n\tencryptHeader bool,\n\tnewConnOpts newConnectionOpts,\n) (\n\tc *PeerConn, err error,\n) {\n\tc = cl.newConnection(nc, newConnOpts)\n\tc.headerEncrypted = encryptHeader\n\tctx, cancel := context.WithTimeout(ctx, cl.config.HandshakesTimeout)\n\tdefer cancel()\n\tdl, ok := ctx.Deadline()\n\tif !ok {\n\t\tpanic(ctx)\n\t}\n\terr = nc.SetDeadline(dl)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = cl.initiateHandshakes(ctx, c, t)\n\treturn\n}\n\nfunc doProtocolHandshakeOnDialResult(\n\tt *Torrent,\n\tobfuscatedHeader bool,\n\taddr PeerRemoteAddr,\n\tdr DialResult,\n) (\n\tc *PeerConn, err error,\n) {\n\tcl := t.cl\n\tnc := dr.Conn\n\taddrIpPort, _ := tryIpPortFromNetAddr(addr)\n\tc, err = cl.initiateProtocolHandshakes(\n\t\tcontext.Background(), nc, t, obfuscatedHeader,\n\t\tnewConnectionOpts{\n\t\t\toutgoing:   true,\n\t\t\tremoteAddr: addr,\n\t\t\t// It would be possible to retrieve a public IP from the dialer used here?\n\t\t\tlocalPublicAddr: cl.publicAddr(addrIpPort.IP),\n\t\t\tnetwork:         dr.Dialer.DialerNetwork(),\n\t\t\tconnString:      regularNetConnPeerConnConnString(nc),\n\t\t})\n\tif err != nil {\n\t\tnc.Close()\n\t}\n\treturn c, err\n}\n\n// Returns nil connection and nil error if no connection could be established for valid reasons.\nfunc (cl *Client) dialAndCompleteHandshake(opts outgoingConnOpts) (c *PeerConn, err error) {\n\t// It would be better if dial rate limiting could be tested when considering to open connections\n\t// instead. Doing it here means if the limit is low, and the half-open limit is high, we could\n\t// end up with lots of outgoing connection attempts pending that were initiated on stale data.\n\t{\n\t\tdialReservation := cl.config.DialRateLimiter.Reserve()\n\t\tif !opts.receivedHolepunchConnect {\n\t\t\tif !dialReservation.OK() {\n\t\t\t\terr = errors.New(\"can't make dial limit reservation\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\ttime.Sleep(dialReservation.Delay())\n\t\t}\n\t}\n\ttorrent.Add(\"establish outgoing connection\", 1)\n\taddr := opts.peerInfo.Addr\n\tdialPool := dialPool{\n\t\tresCh: make(chan DialResult),\n\t\taddr:  addr.String(),\n\t}\n\tdefer dialPool.startDrainer()\n\tdialTimeout := opts.t.getDialTimeoutUnlocked()\n\t{\n\t\tctx, cancel := context.WithTimeout(context.Background(), dialTimeout)\n\t\tdefer cancel()\n\t\tfor _, d := range cl.dialers {\n\t\t\tdialPool.add(ctx, d)\n\t\t}\n\t}\n\tholepunchAddr, holepunchAddrErr := addrPortFromPeerRemoteAddr(addr)\n\theaderObfuscationPolicy := opts.HeaderObfuscationPolicy\n\tobfuscatedHeaderFirst := headerObfuscationPolicy.Preferred\n\tfirstDialResult := dialPool.getFirst()\n\tif firstDialResult.Conn == nil {\n\t\t// No dialers worked. Try to initiate a holepunching rendezvous.\n\t\tif holepunchAddrErr == nil {\n\t\t\tcl.lock()\n\t\t\tif !opts.receivedHolepunchConnect {\n\t\t\t\tg.MakeMapIfNilAndSet(&cl.undialableWithoutHolepunch, holepunchAddr, struct{}{})\n\t\t\t}\n\t\t\tif !opts.skipHolepunchRendezvous {\n\t\t\t\topts.t.trySendHolepunchRendezvous(holepunchAddr)\n\t\t\t}\n\t\t\tcl.unlock()\n\t\t}\n\t\terr = fmt.Errorf(\"all initial dials failed\")\n\t\treturn\n\t}\n\tif opts.receivedHolepunchConnect && holepunchAddrErr == nil {\n\t\tcl.lock()\n\t\tif g.MapContains(cl.undialableWithoutHolepunch, holepunchAddr) {\n\t\t\tg.MakeMapIfNilAndSet(&cl.dialableOnlyAfterHolepunch, holepunchAddr, struct{}{})\n\t\t}\n\t\tg.MakeMapIfNil(&cl.dialedSuccessfullyAfterHolepunchConnect)\n\t\tg.MapInsert(cl.dialedSuccessfullyAfterHolepunchConnect, holepunchAddr, struct{}{})\n\t\tcl.unlock()\n\t}\n\tc, err = doProtocolHandshakeOnDialResult(\n\t\topts.t,\n\t\tobfuscatedHeaderFirst,\n\t\taddr,\n\t\tfirstDialResult,\n\t)\n\tif err == nil {\n\t\ttorrent.Add(\"initiated conn with preferred header obfuscation\", 1)\n\t\treturn\n\t}\n\tc.logger.Levelf(\n\t\tlog.Debug,\n\t\t\"error doing protocol handshake with header obfuscation %v\",\n\t\tobfuscatedHeaderFirst,\n\t)\n\tfirstDialResult.Conn.Close()\n\t// We should have just tried with the preferred header obfuscation. If it was required, there's nothing else to try.\n\tif headerObfuscationPolicy.RequirePreferred {\n\t\treturn\n\t}\n\t// Reuse the dialer that returned already but failed to handshake.\n\t{\n\t\tctx, cancel := context.WithTimeout(context.Background(), dialTimeout)\n\t\tdefer cancel()\n\t\tdialPool.add(ctx, firstDialResult.Dialer)\n\t}\n\tsecondDialResult := dialPool.getFirst()\n\tif secondDialResult.Conn == nil {\n\t\treturn\n\t}\n\tc, err = doProtocolHandshakeOnDialResult(\n\t\topts.t,\n\t\t!obfuscatedHeaderFirst,\n\t\taddr,\n\t\tsecondDialResult,\n\t)\n\tif err == nil {\n\t\ttorrent.Add(\"initiated conn with fallback header obfuscation\", 1)\n\t\treturn\n\t}\n\tc.logger.Levelf(\n\t\tlog.Debug,\n\t\t\"error doing protocol handshake with header obfuscation %v\",\n\t\t!obfuscatedHeaderFirst,\n\t)\n\tsecondDialResult.Conn.Close()\n\treturn\n}\n\ntype outgoingConnOpts struct {\n\tpeerInfo PeerInfo\n\tt        *Torrent\n\t// Don't attempt to connect unless a connect message is received after initiating a rendezvous.\n\trequireRendezvous bool\n\t// Don't send rendezvous requests to eligible relays.\n\tskipHolepunchRendezvous bool\n\t// Outgoing connection attempt is in response to holepunch connect message.\n\treceivedHolepunchConnect bool\n\tHeaderObfuscationPolicy  HeaderObfuscationPolicy\n}\n\n// Called to dial out and run a connection. The addr we're given is already\n// considered half-open.\nfunc (cl *Client) outgoingConnection(\n\topts outgoingConnOpts,\n\tattemptKey outgoingConnAttemptKey,\n) {\n\tc, err := cl.dialAndCompleteHandshake(opts)\n\tif err == nil {\n\t\tc.conn.SetWriteDeadline(time.Time{})\n\t}\n\tcl.lock()\n\tdefer cl.unlock()\n\t// Don't release lock between here and addPeerConn, unless it's for failure.\n\tcl.noLongerHalfOpen(opts.t, opts.peerInfo.Addr.String(), attemptKey)\n\tif err != nil {\n\t\tif cl.config.Debug {\n\t\t\tcl.logger.Levelf(\n\t\t\t\tlog.Debug,\n\t\t\t\t\"error establishing outgoing connection to %v: %v\",\n\t\t\t\topts.peerInfo.Addr,\n\t\t\t\terr,\n\t\t\t)\n\t\t}\n\t\treturn\n\t}\n\tdefer c.close()\n\tc.Discovery = opts.peerInfo.Source\n\tc.trusted = opts.peerInfo.Trusted\n\topts.t.runHandshookConnLoggingErr(c)\n}\n\n// The port number for incoming peer connections. 0 if the client isn't listening.\nfunc (cl *Client) incomingPeerPort() int {\n\treturn cl.LocalPort()\n}\n\nfunc (cl *Client) initiateHandshakes(ctx context.Context, c *PeerConn, t *Torrent) (err error) {\n\tif c.headerEncrypted {\n\t\tvar rw io.ReadWriter\n\t\trw, c.cryptoMethod, err = mse.InitiateHandshakeContext(\n\t\t\tctx,\n\t\t\tstruct {\n\t\t\t\tio.Reader\n\t\t\t\tio.Writer\n\t\t\t}{c.r, c.w},\n\t\t\tt.canonicalShortInfohash().Bytes(),\n\t\t\tnil,\n\t\t\tcl.config.CryptoProvides,\n\t\t)\n\t\tc.setRW(rw)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"header obfuscation handshake: %w\", err)\n\t\t}\n\t}\n\tlocalReservedBits := cl.config.Extensions\n\thandshakeIh := *t.canonicalShortInfohash()\n\t// If we're sending the v1 infohash, and we know the v2 infohash, set the v2 upgrade bit. This\n\t// means the peer can send the v2 infohash in the handshake to upgrade the connection.\n\tlocalReservedBits.SetBit(pp.ExtensionBitV2Upgrade, g.Some(handshakeIh) == t.infoHash && t.infoHashV2.Ok)\n\tih, err := cl.connBtHandshake(context.TODO(), c, &handshakeIh, localReservedBits)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"bittorrent protocol handshake: %w\", err)\n\t}\n\tif g.Some(ih) == t.infoHash {\n\t\treturn nil\n\t}\n\tif t.infoHashV2.Ok && *t.infoHashV2.Value.ToShort() == ih {\n\t\ttorrent.Add(\"initiated handshakes upgraded to v2\", 1)\n\t\tc.v2 = true\n\t\treturn nil\n\t}\n\terr = errors.New(\"bittorrent protocol handshake: peer infohash didn't match\")\n\treturn\n}\n\n// Calls f with any secret keys. Note that it takes the Client lock, and so must be used from code\n// that won't also try to take the lock. This saves us copying all the infohashes everytime.\nfunc (cl *Client) forSkeys(f func([]byte) bool) {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\tif false { // Emulate the bug from #114\n\t\tvar firstIh InfoHash\n\t\tfor ih := range cl.torrentsByShortHash {\n\t\t\tfirstIh = ih\n\t\t\tbreak\n\t\t}\n\t\tfor range cl.torrentsByShortHash {\n\t\t\tif !f(firstIh[:]) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\tfor ih := range cl.torrentsByShortHash {\n\t\tif !f(ih[:]) {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc (cl *Client) handshakeReceiverSecretKeys() mse.SecretKeyIter {\n\tif ret := cl.config.Callbacks.ReceiveEncryptedHandshakeSkeys; ret != nil {\n\t\treturn ret\n\t}\n\treturn cl.forSkeys\n}\n\n// Do encryption and bittorrent handshakes as receiver.\nfunc (cl *Client) receiveHandshakes(c *PeerConn) (t *Torrent, err error) {\n\tvar rw io.ReadWriter\n\trw, c.headerEncrypted, c.cryptoMethod, err = handleEncryption(\n\t\tc.rw(),\n\t\tcl.handshakeReceiverSecretKeys(),\n\t\tcl.config.HeaderObfuscationPolicy,\n\t\tcl.config.CryptoSelector,\n\t)\n\tc.setRW(rw)\n\tif err == nil || err == mse.ErrNoSecretKeyMatch {\n\t\tif c.headerEncrypted {\n\t\t\ttorrent.Add(\"handshakes received encrypted\", 1)\n\t\t} else {\n\t\t\ttorrent.Add(\"handshakes received unencrypted\", 1)\n\t\t}\n\t} else {\n\t\ttorrent.Add(\"handshakes received with error while handling encryption\", 1)\n\t}\n\tif err != nil {\n\t\tif err == mse.ErrNoSecretKeyMatch {\n\t\t\terr = nil\n\t\t}\n\t\treturn\n\t}\n\tif cl.config.HeaderObfuscationPolicy.RequirePreferred && c.headerEncrypted != cl.config.HeaderObfuscationPolicy.Preferred {\n\t\terr = errors.New(\"connection does not have required header obfuscation\")\n\t\treturn\n\t}\n\tih, err := cl.connBtHandshake(context.TODO(), c, nil, cl.config.Extensions)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"during bt handshake: %w\", err)\n\t}\n\n\tcl.lock()\n\tt = cl.torrentsByShortHash[ih]\n\tif t != nil && t.infoHashV2.Ok && *t.infoHashV2.Value.ToShort() == ih {\n\t\ttorrent.Add(\"v2 handshakes received\", 1)\n\t\tc.v2 = true\n\t}\n\tcl.unlock()\n\n\treturn\n}\n\nvar successfulPeerWireProtocolHandshakePeerReservedBytes expvar.Map\n\nfunc init() {\n\ttorrent.Set(\n\t\t\"successful_peer_wire_protocol_handshake_peer_reserved_bytes\",\n\t\t&successfulPeerWireProtocolHandshakePeerReservedBytes)\n}\n\nfunc (cl *Client) connBtHandshake(ctx context.Context, c *PeerConn, ih *metainfo.Hash, reservedBits PeerExtensionBits) (ret metainfo.Hash, err error) {\n\tres, err := pp.Handshake(ctx, c.rw(), ih, cl.peerID, reservedBits)\n\tif err != nil {\n\t\treturn\n\t}\n\tsuccessfulPeerWireProtocolHandshakePeerReservedBytes.Add(\n\t\thex.EncodeToString(res.PeerExtensionBits[:]), 1)\n\tret = res.Hash\n\tc.PeerExtensionBytes = res.PeerExtensionBits\n\tc.PeerID = res.PeerID\n\tc.completedHandshake = time.Now()\n\tif cb := cl.config.Callbacks.CompletedHandshake; cb != nil {\n\t\tcb(c, res.Hash)\n\t}\n\treturn\n}\n\nfunc (cl *Client) runReceivedConn(c *PeerConn) {\n\terr := c.conn.SetDeadline(time.Now().Add(cl.config.HandshakesTimeout))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tt, err := cl.receiveHandshakes(c)\n\tif err != nil {\n\t\tcl.logger.LazyLog(log.Debug, func() log.Msg {\n\t\t\treturn log.Fmsg(\n\t\t\t\t\"error receiving handshakes on %v: %s\", c, err,\n\t\t\t).Add(\n\t\t\t\t\"network\", c.Network,\n\t\t\t)\n\t\t})\n\t\ttorrent.Add(\"error receiving handshake\", 1)\n\t\tcl.lock()\n\t\tcl.onBadAccept(c.RemoteAddr)\n\t\tcl.unlock()\n\t\treturn\n\t}\n\tif t == nil {\n\t\ttorrent.Add(\"received handshake for unloaded torrent\", 1)\n\t\tcl.logger.LazyLog(log.Debug, func() log.Msg {\n\t\t\treturn log.Fmsg(\"received handshake for unloaded torrent\")\n\t\t})\n\t\tcl.lock()\n\t\tcl.onBadAccept(c.RemoteAddr)\n\t\tcl.unlock()\n\t\treturn\n\t}\n\ttorrent.Add(\"received handshake for loaded torrent\", 1)\n\tc.conn.SetWriteDeadline(time.Time{})\n\tcl.lock()\n\tdefer cl.unlock()\n\tt.runHandshookConnLoggingErr(c)\n}\n\n// Client lock must be held before entering this.\nfunc (t *Torrent) runHandshookConn(pc *PeerConn) error {\n\tpc.setTorrent(t)\n\tcl := t.cl\n\tfor i, b := range cl.config.MinPeerExtensions {\n\t\tif pc.PeerExtensionBytes[i]&b != b {\n\t\t\treturn fmt.Errorf(\"peer did not meet minimum peer extensions: %x\", pc.PeerExtensionBytes[:])\n\t\t}\n\t}\n\tif pc.PeerID == cl.peerID {\n\t\tif pc.outgoing {\n\t\t\tconnsToSelf.Add(1)\n\t\t\taddr := pc.RemoteAddr.String()\n\t\t\tcl.dopplegangerAddrs[addr] = struct{}{}\n\t\t} /* else {\n\t\t\t// Because the remote address is not necessarily the same as its client's torrent listen\n\t\t\t// address, we won't record the remote address as a doppleganger. Instead, the initiator\n\t\t\t// can record *us* as the doppleganger.\n\t\t} */\n\t\tt.logger.Levelf(log.Debug, \"local and remote peer ids are the same\")\n\t\treturn nil\n\t}\n\tpc.r = deadlineReader{pc.conn, pc.r}\n\tcompletedHandshakeConnectionFlags.Add(pc.connectionFlags(), 1)\n\tif connIsIpv6(pc.conn) {\n\t\ttorrent.Add(\"completed handshake over ipv6\", 1)\n\t}\n\tif err := t.addPeerConn(pc); err != nil {\n\t\treturn fmt.Errorf(\"adding connection: %w\", err)\n\t}\n\tdefer t.dropConnection(pc)\n\tpc.addBuiltinLtepProtocols(!cl.config.DisablePEX)\n\tfor _, cb := range pc.callbacks.PeerConnAdded {\n\t\tcb(pc)\n\t}\n\tpc.startMessageWriter()\n\tpc.sendInitialMessages()\n\tpc.initUpdateRequestsTimer()\n\terr := pc.mainReadLoop()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"main read loop: %w\", err)\n\t}\n\treturn nil\n}\n\nfunc (p *Peer) initUpdateRequestsTimer() {\n\tif check.Enabled {\n\t\tif p.updateRequestsTimer != nil {\n\t\t\tpanic(p.updateRequestsTimer)\n\t\t}\n\t}\n\tif enableUpdateRequestsTimer {\n\t\tp.updateRequestsTimer = time.AfterFunc(math.MaxInt64, p.updateRequestsTimerFunc)\n\t}\n}\n\nconst peerUpdateRequestsTimerReason = \"updateRequestsTimer\"\n\nfunc (c *Peer) updateRequestsTimerFunc() {\n\tc.locker().Lock()\n\tdefer c.locker().Unlock()\n\tif c.closed.IsSet() {\n\t\treturn\n\t}\n\tif c.isLowOnRequests() {\n\t\t// If there are no outstanding requests, then a request update should have already run.\n\t\treturn\n\t}\n\tif d := time.Since(c.lastRequestUpdate); d < updateRequestsTimerDuration {\n\t\t// These should be benign, Timer.Stop doesn't guarantee that its function won't run if it's\n\t\t// already been fired.\n\t\ttorrent.Add(\"spurious timer requests updates\", 1)\n\t\treturn\n\t}\n\tc.updateRequests(peerUpdateRequestsTimerReason)\n}\n\n// Maximum pending requests we allow peers to send us. If peer requests are buffered on read, this\n// instructs the amount of memory that might be used to cache pending writes. Assuming 512KiB\n// (1<<19) cached for sending, for 16KiB (1<<14) chunks.\nconst localClientReqq = 1024\n\n// See the order given in Transmission's tr_peerMsgsNew.\nfunc (pc *PeerConn) sendInitialMessages() {\n\tt := pc.t\n\tcl := t.cl\n\tif pc.PeerExtensionBytes.SupportsExtended() && cl.config.Extensions.SupportsExtended() {\n\t\tpc.write(pp.Message{\n\t\t\tType:       pp.Extended,\n\t\t\tExtendedID: pp.HandshakeExtendedID,\n\t\t\tExtendedPayload: func() []byte {\n\t\t\t\tmsg := pp.ExtendedHandshakeMessage{\n\t\t\t\t\tV:            cl.config.ExtendedHandshakeClientVersion,\n\t\t\t\t\tReqq:         localClientReqq,\n\t\t\t\t\tYourIp:       pp.CompactIp(pc.remoteIp()),\n\t\t\t\t\tEncryption:   cl.config.HeaderObfuscationPolicy.Preferred || !cl.config.HeaderObfuscationPolicy.RequirePreferred,\n\t\t\t\t\tPort:         cl.incomingPeerPort(),\n\t\t\t\t\tMetadataSize: t.metadataSize(),\n\t\t\t\t\t// TODO: We can figure these out specific to the socket used.\n\t\t\t\t\tIpv4: pp.CompactIp(cl.config.PublicIp4.To4()),\n\t\t\t\t\tIpv6: cl.config.PublicIp6.To16(),\n\t\t\t\t}\n\t\t\t\tmsg.M = pc.LocalLtepProtocolMap.toSupportedExtensionDict()\n\t\t\t\treturn bencode.MustMarshal(msg)\n\t\t\t}(),\n\t\t})\n\t}\n\tfunc() {\n\t\tif pc.fastEnabled() {\n\t\t\tif t.haveAllPieces() {\n\t\t\t\tpc.write(pp.Message{Type: pp.HaveAll})\n\t\t\t\tpc.sentHaves.AddRange(0, bitmap.BitRange(pc.t.NumPieces()))\n\t\t\t\treturn\n\t\t\t} else if !t.haveAnyPieces() {\n\t\t\t\tpc.write(pp.Message{Type: pp.HaveNone})\n\t\t\t\tpc.sentHaves.Clear()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tpc.postBitfield()\n\t}()\n\tif pc.PeerExtensionBytes.SupportsDHT() && cl.config.Extensions.SupportsDHT() && cl.haveDhtServer() {\n\t\tpc.write(pp.Message{\n\t\t\tType: pp.Port,\n\t\t\tPort: cl.dhtPort(),\n\t\t})\n\t}\n}\n\nfunc (cl *Client) dhtPort() (ret uint16) {\n\tif len(cl.dhtServers) == 0 {\n\t\treturn\n\t}\n\treturn uint16(missinggo.AddrPort(cl.dhtServers[len(cl.dhtServers)-1].Addr()))\n}\n\nfunc (cl *Client) haveDhtServer() bool {\n\treturn len(cl.dhtServers) > 0\n}\n\n// Process incoming ut_metadata message.\nfunc (cl *Client) gotMetadataExtensionMsg(payload []byte, t *Torrent, c *PeerConn) error {\n\tvar d pp.ExtendedMetadataRequestMsg\n\terr := bencode.Unmarshal(payload, &d)\n\tif _, ok := err.(bencode.ErrUnusedTrailingBytes); ok {\n\t} else if err != nil {\n\t\treturn fmt.Errorf(\"error unmarshalling bencode: %s\", err)\n\t}\n\tpiece := d.Piece\n\tswitch d.Type {\n\tcase pp.DataMetadataExtensionMsgType:\n\t\tc.allStats(add(1, func(cs *ConnStats) *Count { return &cs.MetadataChunksRead }))\n\t\tif !c.requestedMetadataPiece(piece) {\n\t\t\treturn fmt.Errorf(\"got unexpected piece %d\", piece)\n\t\t}\n\t\tc.metadataRequests[piece] = false\n\t\tbegin := len(payload) - d.PieceSize()\n\t\tif begin < 0 || begin >= len(payload) {\n\t\t\treturn fmt.Errorf(\"data has bad offset in payload: %d\", begin)\n\t\t}\n\t\tt.saveMetadataPiece(piece, payload[begin:])\n\t\tc.lastUsefulChunkReceived = time.Now()\n\t\terr = t.maybeCompleteMetadata()\n\t\tif err != nil {\n\t\t\t// Log this at the Torrent-level, as we don't partition metadata by Peer yet, so we\n\t\t\t// don't know who to blame. TODO: Also errors can be returned here that aren't related\n\t\t\t// to verifying metadata, which should be fixed. This should be tagged with metadata, so\n\t\t\t// log consumers can filter for this message.\n\t\t\tt.logger.WithDefaultLevel(log.Warning).Printf(\"error completing metadata: %v\", err)\n\t\t}\n\t\treturn err\n\tcase pp.RequestMetadataExtensionMsgType:\n\t\tif !t.haveMetadataPiece(piece) {\n\t\t\tc.write(t.newMetadataExtensionMessage(c, pp.RejectMetadataExtensionMsgType, d.Piece, nil))\n\t\t\treturn nil\n\t\t}\n\t\tstart := (1 << 14) * piece\n\t\tc.protocolLogger.WithDefaultLevel(log.Debug).Printf(\"sending metadata piece %d\", piece)\n\t\tc.write(t.newMetadataExtensionMessage(c, pp.DataMetadataExtensionMsgType, piece, t.metadataBytes[start:start+t.metadataPieceSize(piece)]))\n\t\treturn nil\n\tcase pp.RejectMetadataExtensionMsgType:\n\t\treturn nil\n\tdefault:\n\t\treturn errors.New(\"unknown msg_type value\")\n\t}\n}\n\nfunc (cl *Client) badPeerAddr(addr PeerRemoteAddr) bool {\n\tif ipa, ok := tryIpPortFromNetAddr(addr); ok {\n\t\treturn cl.badPeerIPPort(ipa.IP, ipa.Port)\n\t}\n\treturn false\n}\n\n// Returns whether the IP address and port are considered \"bad\".\nfunc (cl *Client) badPeerIPPort(ip net.IP, port int) bool {\n\tif port == 0 || ip == nil {\n\t\treturn true\n\t}\n\tif cl.dopplegangerAddr(net.JoinHostPort(ip.String(), strconv.FormatInt(int64(port), 10))) {\n\t\treturn true\n\t}\n\tif _, ok := cl.ipBlockRange(ip); ok {\n\t\treturn true\n\t}\n\tipAddr, ok := netip.AddrFromSlice(ip)\n\tif !ok {\n\t\tpanic(ip)\n\t}\n\tif _, ok := cl.badPeerIPs[ipAddr]; ok {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Return a Torrent ready for insertion into a Client.\nfunc (cl *Client) newTorrent(ih metainfo.Hash, specStorage storage.ClientImpl) (t *Torrent) {\n\treturn cl.newTorrentOpt(AddTorrentOpts{\n\t\tInfoHash: ih,\n\t\tStorage:  specStorage,\n\t})\n}\n\n// Return a Torrent ready for insertion into a Client.\nfunc (cl *Client) newTorrentOpt(opts AddTorrentOpts) (t *Torrent) {\n\tvar v1InfoHash g.Option[infohash.T]\n\tif !opts.InfoHash.IsZero() {\n\t\tv1InfoHash.Set(opts.InfoHash)\n\t}\n\tif !v1InfoHash.Ok && !opts.InfoHashV2.Ok {\n\t\tpanic(\"v1 infohash must be nonzero or v2 infohash must be set\")\n\t}\n\t// use provided storage, if provided\n\tstorageClient := cl.defaultStorage\n\tif opts.Storage != nil {\n\t\tstorageClient = storage.NewClient(opts.Storage)\n\t}\n\n\tt = &Torrent{\n\t\tcl:         cl,\n\t\tinfoHash:   v1InfoHash,\n\t\tinfoHashV2: opts.InfoHashV2,\n\t\tpeers: prioritizedPeers{\n\t\t\tom: gbtree.New(32),\n\t\t\tgetPrio: func(p PeerInfo) peerPriority {\n\t\t\t\tipPort := p.addr()\n\t\t\t\treturn bep40PriorityIgnoreError(cl.publicAddr(ipPort.IP), ipPort)\n\t\t\t},\n\t\t},\n\t\tconns: make(map[*PeerConn]struct{}, 2*cl.config.EstablishedConnsPerTorrent),\n\n\t\tstorageOpener:       storageClient,\n\t\tmaxEstablishedConns: cl.config.EstablishedConnsPerTorrent,\n\n\t\tmetadataChanged: sync.Cond{\n\t\t\tL: cl.locker(),\n\t\t},\n\t\twebSeeds:     make(map[string]*Peer),\n\t\tgotMetainfoC: make(chan struct{}),\n\t}\n\tvar salt [8]byte\n\trand.Read(salt[:])\n\tt.smartBanCache.Hash = func(b []byte) uint64 {\n\t\th := xxhash.New()\n\t\th.Write(salt[:])\n\t\th.Write(b)\n\t\treturn h.Sum64()\n\t}\n\tt.smartBanCache.Init()\n\tt.networkingEnabled.Set()\n\tt.logger = cl.logger.WithDefaultLevel(log.Debug)\n\tt.sourcesLogger = t.logger.WithNames(\"sources\")\n\tif opts.ChunkSize == 0 {\n\t\topts.ChunkSize = defaultChunkSize\n\t}\n\tt.setChunkSize(opts.ChunkSize)\n\treturn\n}\n\n// A file-like handle to some torrent data resource.\ntype Handle interface {\n\tio.Reader\n\tio.Seeker\n\tio.Closer\n\tio.ReaderAt\n}\n\nfunc (cl *Client) AddTorrentInfoHash(infoHash metainfo.Hash) (t *Torrent, new bool) {\n\treturn cl.AddTorrentInfoHashWithStorage(infoHash, nil)\n}\n\n// Deprecated. Adds a torrent by InfoHash with a custom Storage implementation.\n// If the torrent already exists then this Storage is ignored and the\n// existing torrent returned with `new` set to `false`\nfunc (cl *Client) AddTorrentInfoHashWithStorage(\n\tinfoHash metainfo.Hash,\n\tspecStorage storage.ClientImpl,\n) (t *Torrent, new bool) {\n\tcl.lock()\n\tdefer cl.unlock()\n\tt, ok := cl.torrentsByShortHash[infoHash]\n\tif ok {\n\t\treturn\n\t}\n\tnew = true\n\n\tt = cl.newTorrent(infoHash, specStorage)\n\tcl.eachDhtServer(func(s DhtServer) {\n\t\tif cl.config.PeriodicallyAnnounceTorrentsToDht {\n\t\t\tgo t.dhtAnnouncer(s)\n\t\t}\n\t})\n\tcl.torrentsByShortHash[infoHash] = t\n\tcl.torrents[t] = struct{}{}\n\tcl.clearAcceptLimits()\n\tt.updateWantPeersEvent()\n\t// Tickle Client.waitAccept, new torrent may want conns.\n\tcl.event.Broadcast()\n\treturn\n}\n\n// Adds a torrent by InfoHash with a custom Storage implementation. If the torrent already exists\n// then this Storage is ignored and the existing torrent returned with `new` set to `false`.\nfunc (cl *Client) AddTorrentOpt(opts AddTorrentOpts) (t *Torrent, new bool) {\n\tinfoHash := opts.InfoHash\n\tcl.lock()\n\tdefer cl.unlock()\n\tt, ok := cl.torrentsByShortHash[infoHash]\n\tif ok {\n\t\treturn\n\t}\n\tif opts.InfoHashV2.Ok {\n\t\tt, ok = cl.torrentsByShortHash[*opts.InfoHashV2.Value.ToShort()]\n\t\tif ok {\n\t\t\treturn\n\t\t}\n\t}\n\tnew = true\n\n\tt = cl.newTorrentOpt(opts)\n\tcl.eachDhtServer(func(s DhtServer) {\n\t\tif cl.config.PeriodicallyAnnounceTorrentsToDht {\n\t\t\tgo t.dhtAnnouncer(s)\n\t\t}\n\t})\n\tcl.torrentsByShortHash[infoHash] = t\n\tcl.torrents[t] = struct{}{}\n\tt.setInfoBytesLocked(opts.InfoBytes)\n\tcl.clearAcceptLimits()\n\tt.updateWantPeersEvent()\n\t// Tickle Client.waitAccept, new torrent may want conns.\n\tcl.event.Broadcast()\n\treturn\n}\n\ntype AddTorrentOpts struct {\n\tInfoHash   infohash.T\n\tInfoHashV2 g.Option[infohash_v2.T]\n\tStorage    storage.ClientImpl\n\tChunkSize  pp.Integer\n\tInfoBytes  []byte\n}\n\n// Add or merge a torrent spec. Returns new if the torrent wasn't already in the client. See also\n// Torrent.MergeSpec.\nfunc (cl *Client) AddTorrentSpec(spec *TorrentSpec) (t *Torrent, new bool, err error) {\n\tt, new = cl.AddTorrentOpt(AddTorrentOpts{\n\t\tInfoHash:   spec.InfoHash,\n\t\tInfoHashV2: spec.InfoHashV2,\n\t\tStorage:    spec.Storage,\n\t\tChunkSize:  spec.ChunkSize,\n\t})\n\tmodSpec := *spec\n\tif new {\n\t\t// ChunkSize was already applied by adding a new Torrent, and MergeSpec disallows changing\n\t\t// it.\n\t\tmodSpec.ChunkSize = 0\n\t}\n\terr = t.MergeSpec(&modSpec)\n\tif err != nil && new {\n\t\tt.Drop()\n\t}\n\treturn\n}\n\n// The trackers will be merged with the existing ones. If the Info isn't yet known, it will be set.\n// spec.DisallowDataDownload/Upload will be read and applied\n// The display name is replaced if the new spec provides one. Note that any `Storage` is ignored.\nfunc (t *Torrent) MergeSpec(spec *TorrentSpec) error {\n\tif spec.DisplayName != \"\" {\n\t\tt.SetDisplayName(spec.DisplayName)\n\t}\n\tif spec.InfoBytes != nil {\n\t\terr := t.SetInfoBytes(spec.InfoBytes)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tcl := t.cl\n\tcl.AddDhtNodes(spec.DhtNodes)\n\tt.UseSources(spec.Sources)\n\tcl.lock()\n\tdefer cl.unlock()\n\tt.initialPieceCheckDisabled = spec.DisableInitialPieceCheck\n\tfor _, url := range spec.Webseeds {\n\t\tt.addWebSeed(url)\n\t}\n\tfor _, peerAddr := range spec.PeerAddrs {\n\t\tt.addPeer(PeerInfo{\n\t\t\tAddr:    StringAddr(peerAddr),\n\t\t\tSource:  PeerSourceDirect,\n\t\t\tTrusted: true,\n\t\t})\n\t}\n\tif spec.ChunkSize != 0 {\n\t\tpanic(\"chunk size cannot be changed for existing Torrent\")\n\t}\n\tt.addTrackers(spec.Trackers)\n\tt.maybeNewConns()\n\tt.dataDownloadDisallowed.SetBool(spec.DisallowDataDownload)\n\tt.dataUploadDisallowed = spec.DisallowDataUpload\n\treturn errors.Join(t.addPieceLayersLocked(spec.PieceLayers)...)\n}\n\nfunc (cl *Client) dropTorrent(t *Torrent, wg *sync.WaitGroup) (err error) {\n\tt.eachShortInfohash(func(short [20]byte) {\n\t\tdelete(cl.torrentsByShortHash, short)\n\t})\n\terr = t.close(wg)\n\tdelete(cl.torrents, t)\n\treturn\n}\n\nfunc (cl *Client) allTorrentsCompleted() bool {\n\tfor t := range cl.torrents {\n\t\tif !t.haveInfo() {\n\t\t\treturn false\n\t\t}\n\t\tif !t.haveAllPieces() {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// Returns true when all torrents are completely downloaded and false if the\n// client is stopped before that.\nfunc (cl *Client) WaitAll() bool {\n\tcl.lock()\n\tdefer cl.unlock()\n\tfor !cl.allTorrentsCompleted() {\n\t\tif cl.closed.IsSet() {\n\t\t\treturn false\n\t\t}\n\t\tcl.event.Wait()\n\t}\n\treturn true\n}\n\n// Returns handles to all the torrents loaded in the Client.\nfunc (cl *Client) Torrents() []*Torrent {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\treturn cl.torrentsAsSlice()\n}\n\nfunc (cl *Client) torrentsAsSlice() (ret []*Torrent) {\n\tfor t := range cl.torrents {\n\t\tret = append(ret, t)\n\t}\n\treturn\n}\n\nfunc (cl *Client) AddMagnet(uri string) (T *Torrent, err error) {\n\tspec, err := TorrentSpecFromMagnetUri(uri)\n\tif err != nil {\n\t\treturn\n\t}\n\tT, _, err = cl.AddTorrentSpec(spec)\n\treturn\n}\n\nfunc (cl *Client) AddTorrent(mi *metainfo.MetaInfo) (T *Torrent, err error) {\n\tts, err := TorrentSpecFromMetaInfoErr(mi)\n\tif err != nil {\n\t\treturn\n\t}\n\tT, _, err = cl.AddTorrentSpec(ts)\n\treturn\n}\n\nfunc (cl *Client) AddTorrentFromFile(filename string) (T *Torrent, err error) {\n\tmi, err := metainfo.LoadFromFile(filename)\n\tif err != nil {\n\t\treturn\n\t}\n\treturn cl.AddTorrent(mi)\n}\n\nfunc (cl *Client) DhtServers() []DhtServer {\n\treturn cl.dhtServers\n}\n\nfunc (cl *Client) AddDhtNodes(nodes []string) {\n\tfor _, n := range nodes {\n\t\thmp := missinggo.SplitHostMaybePort(n)\n\t\tip := net.ParseIP(hmp.Host)\n\t\tif ip == nil {\n\t\t\tcl.logger.Printf(\"won't add DHT node with bad IP: %q\", hmp.Host)\n\t\t\tcontinue\n\t\t}\n\t\tni := krpc.NodeInfo{\n\t\t\tAddr: krpc.NodeAddr{\n\t\t\t\tIP:   ip,\n\t\t\t\tPort: hmp.Port,\n\t\t\t},\n\t\t}\n\t\tcl.eachDhtServer(func(s DhtServer) {\n\t\t\ts.AddNode(ni)\n\t\t})\n\t}\n}\n\nfunc (cl *Client) banPeerIP(ip net.IP) {\n\t// We can't take this from string, because it will lose netip's v4on6. net.ParseIP parses v4\n\t// addresses directly to v4on6, which doesn't compare equal with v4.\n\tipAddr, ok := netip.AddrFromSlice(ip)\n\tif !ok {\n\t\tpanic(ip)\n\t}\n\tg.MakeMapIfNilAndSet(&cl.badPeerIPs, ipAddr, struct{}{})\n\tfor t := range cl.torrents {\n\t\tt.iterPeers(func(p *Peer) {\n\t\t\tif p.remoteIp().Equal(ip) {\n\t\t\t\tt.logger.Levelf(log.Warning, \"dropping peer %v with banned ip %v\", p, ip)\n\t\t\t\t// Should this be a close?\n\t\t\t\tp.drop()\n\t\t\t}\n\t\t})\n\t}\n}\n\ntype newConnectionOpts struct {\n\toutgoing        bool\n\tremoteAddr      PeerRemoteAddr\n\tlocalPublicAddr peerLocalPublicAddr\n\tnetwork         string\n\tconnString      string\n}\n\nfunc (cl *Client) newConnection(nc net.Conn, opts newConnectionOpts) (c *PeerConn) {\n\tif opts.network == \"\" {\n\t\tpanic(opts.remoteAddr)\n\t}\n\tc = &PeerConn{\n\t\tPeer: Peer{\n\t\t\toutgoing:        opts.outgoing,\n\t\t\tchoking:         true,\n\t\t\tpeerChoking:     true,\n\t\t\tPeerMaxRequests: 250,\n\n\t\t\tRemoteAddr:      opts.remoteAddr,\n\t\t\tlocalPublicAddr: opts.localPublicAddr,\n\t\t\tNetwork:         opts.network,\n\t\t\tcallbacks:       &cl.config.Callbacks,\n\t\t},\n\t\tconnString: opts.connString,\n\t\tconn:       nc,\n\t}\n\tc.peerRequestDataAllocLimiter.Max = cl.config.MaxAllocPeerRequestDataPerConn\n\tc.initRequestState()\n\t// TODO: Need to be much more explicit about this, including allowing non-IP bannable addresses.\n\tif opts.remoteAddr != nil {\n\t\tnetipAddrPort, err := netip.ParseAddrPort(opts.remoteAddr.String())\n\t\tif err == nil {\n\t\t\tc.bannableAddr = Some(netipAddrPort.Addr())\n\t\t}\n\t}\n\tc.peerImpl = c\n\tc.logger = cl.logger.WithDefaultLevel(log.Warning).WithContextText(fmt.Sprintf(\"%T %p\", c, c))\n\tc.protocolLogger = c.logger.WithNames(protocolLoggingName)\n\tc.setRW(connStatsReadWriter{nc, c})\n\tc.r = &rateLimitedReader{\n\t\tl: cl.config.DownloadRateLimiter,\n\t\tr: c.r,\n\t}\n\tc.logger.Levelf(\n\t\tlog.Debug,\n\t\t\"inited with remoteAddr %v network %v outgoing %t\",\n\t\topts.remoteAddr, opts.network, opts.outgoing,\n\t)\n\tfor _, f := range cl.config.Callbacks.NewPeer {\n\t\tf(&c.Peer)\n\t}\n\treturn\n}\n\nfunc (cl *Client) onDHTAnnouncePeer(ih metainfo.Hash, ip net.IP, port int, portOk bool) {\n\tcl.lock()\n\tdefer cl.unlock()\n\tt := cl.torrentsByShortHash[ih]\n\tif t == nil {\n\t\treturn\n\t}\n\tt.addPeers([]PeerInfo{{\n\t\tAddr:   ipPortAddr{ip, port},\n\t\tSource: PeerSourceDhtAnnouncePeer,\n\t}})\n}\n\nfunc firstNotNil(ips ...net.IP) net.IP {\n\tfor _, ip := range ips {\n\t\tif ip != nil {\n\t\t\treturn ip\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (cl *Client) eachListener(f func(Listener) bool) {\n\tfor _, s := range cl.listeners {\n\t\tif !f(s) {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc (cl *Client) findListener(f func(Listener) bool) (ret Listener) {\n\tfor i := 0; i < len(cl.listeners); i += 1 {\n\t\tif ret = cl.listeners[i]; f(ret) {\n\t\t\treturn\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (cl *Client) publicIp(peer net.IP) net.IP {\n\t// TODO: Use BEP 10 to determine how peers are seeing us.\n\tif peer.To4() != nil {\n\t\treturn firstNotNil(\n\t\t\tcl.config.PublicIp4,\n\t\t\tcl.findListenerIp(func(ip net.IP) bool { return ip.To4() != nil }),\n\t\t)\n\t}\n\n\treturn firstNotNil(\n\t\tcl.config.PublicIp6,\n\t\tcl.findListenerIp(func(ip net.IP) bool { return ip.To4() == nil }),\n\t)\n}\n\nfunc (cl *Client) findListenerIp(f func(net.IP) bool) net.IP {\n\tl := cl.findListener(\n\t\tfunc(l Listener) bool {\n\t\t\treturn f(addrIpOrNil(l.Addr()))\n\t\t},\n\t)\n\tif l == nil {\n\t\treturn nil\n\t}\n\treturn addrIpOrNil(l.Addr())\n}\n\n// Our IP as a peer should see it.\nfunc (cl *Client) publicAddr(peer net.IP) IpPort {\n\treturn IpPort{IP: cl.publicIp(peer), Port: uint16(cl.incomingPeerPort())}\n}\n\n// ListenAddrs addresses currently being listened to.\nfunc (cl *Client) ListenAddrs() (ret []net.Addr) {\n\tcl.lock()\n\tret = make([]net.Addr, len(cl.listeners))\n\tfor i := 0; i < len(cl.listeners); i += 1 {\n\t\tret[i] = cl.listeners[i].Addr()\n\t}\n\tcl.unlock()\n\treturn\n}\n\nfunc (cl *Client) PublicIPs() (ips []net.IP) {\n\tif ip := cl.config.PublicIp4; ip != nil {\n\t\tips = append(ips, ip)\n\t}\n\tif ip := cl.config.PublicIp6; ip != nil {\n\t\tips = append(ips, ip)\n\t}\n\treturn\n}\n\nfunc (cl *Client) onBadAccept(addr PeerRemoteAddr) {\n\tipa, ok := tryIpPortFromNetAddr(addr)\n\tif !ok {\n\t\treturn\n\t}\n\tip := maskIpForAcceptLimiting(ipa.IP)\n\tif cl.acceptLimiter == nil {\n\t\tcl.acceptLimiter = make(map[ipStr]int)\n\t}\n\tcl.acceptLimiter[ipStr(ip.String())]++\n}\n\nfunc maskIpForAcceptLimiting(ip net.IP) net.IP {\n\tif ip4 := ip.To4(); ip4 != nil {\n\t\treturn ip4.Mask(net.CIDRMask(24, 32))\n\t}\n\treturn ip\n}\n\nfunc (cl *Client) clearAcceptLimits() {\n\tcl.acceptLimiter = nil\n}\n\nfunc (cl *Client) acceptLimitClearer() {\n\tfor {\n\t\tselect {\n\t\tcase <-cl.closed.Done():\n\t\t\treturn\n\t\tcase <-time.After(15 * time.Minute):\n\t\t\tcl.lock()\n\t\t\tcl.clearAcceptLimits()\n\t\t\tcl.unlock()\n\t\t}\n\t}\n}\n\nfunc (cl *Client) rateLimitAccept(ip net.IP) bool {\n\tif cl.config.DisableAcceptRateLimiting {\n\t\treturn false\n\t}\n\treturn cl.acceptLimiter[ipStr(maskIpForAcceptLimiting(ip).String())] > 0\n}\n\nfunc (cl *Client) rLock() {\n\tcl._mu.RLock()\n}\n\nfunc (cl *Client) rUnlock() {\n\tcl._mu.RUnlock()\n}\n\nfunc (cl *Client) lock() {\n\tcl._mu.Lock()\n}\n\nfunc (cl *Client) unlock() {\n\tcl._mu.Unlock()\n}\n\nfunc (cl *Client) locker() *lockWithDeferreds {\n\treturn &cl._mu\n}\n\nfunc (cl *Client) String() string {\n\treturn fmt.Sprintf(\"<%[1]T %[1]p>\", cl)\n}\n\nfunc (cl *Client) ICEServers() []webrtc.ICEServer {\n\tvar ICEServers []webrtc.ICEServer\n\tif cl.config.ICEServerList != nil {\n\t\tICEServers = cl.config.ICEServerList\n\t} else if cl.config.ICEServers != nil {\n\t\tICEServers = []webrtc.ICEServer{{URLs: cl.config.ICEServers}}\n\t}\n\treturn ICEServers\n}\n\n// Returns connection-level aggregate connStats at the Client level. See the comment on\n// TorrentStats.ConnStats.\nfunc (cl *Client) ConnStats() ConnStats {\n\treturn cl.connStats.Copy()\n}\n\nfunc (cl *Client) Stats() ClientStats {\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\treturn cl.statsLocked()\n}\n"
        },
        {
          "name": "client_test.go",
          "type": "blob",
          "size": 24.9404296875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/netip\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"testing\"\n\t\"testing/iotest\"\n\t\"time\"\n\n\t\"github.com/anacrolix/dht/v2\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/anacrolix/missinggo/v2/filecache\"\n\t\"github.com/frankban/quicktest\"\n\tqt \"github.com/frankban/quicktest\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/iplist\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc TestClientDefault(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\trequire.Empty(t, cl.Close())\n}\n\nfunc TestClientNilConfig(t *testing.T) {\n\t// The default config will put crap in the working directory.\n\torigDir, _ := os.Getwd()\n\tdefer os.Chdir(origDir)\n\tos.Chdir(t.TempDir())\n\tcl, err := NewClient(nil)\n\trequire.NoError(t, err)\n\trequire.Empty(t, cl.Close())\n}\n\nfunc TestAddDropTorrent(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tdir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(dir)\n\ttt, new, err := cl.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\trequire.NoError(t, err)\n\tassert.True(t, new)\n\ttt.SetMaxEstablishedConns(0)\n\ttt.SetMaxEstablishedConns(1)\n\ttt.Drop()\n}\n\nfunc TestAddTorrentNoSupportedTrackerSchemes(t *testing.T) {\n\t// TODO?\n\tt.SkipNow()\n}\n\nfunc TestAddTorrentNoUsableURLs(t *testing.T) {\n\t// TODO?\n\tt.SkipNow()\n}\n\nfunc TestAddPeersToUnknownTorrent(t *testing.T) {\n\t// TODO?\n\tt.SkipNow()\n}\n\nfunc TestPieceHashSize(t *testing.T) {\n\tassert.Equal(t, 20, pieceHash.Size())\n}\n\nfunc TestTorrentInitialState(t *testing.T) {\n\tdir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(dir)\n\tvar cl Client\n\tcl.init(TestingConfig(t))\n\tcl.initLogger()\n\ttor := cl.newTorrent(\n\t\tmi.HashInfoBytes(),\n\t\tstorage.NewFileWithCompletion(t.TempDir(), storage.NewMapPieceCompletion()),\n\t)\n\ttor.setChunkSize(2)\n\ttor.cl.lock()\n\terr := tor.setInfoBytesLocked(mi.InfoBytes)\n\ttor.cl.unlock()\n\trequire.NoError(t, err)\n\trequire.Len(t, tor.pieces, 3)\n\ttor.pendAllChunkSpecs(0)\n\ttor.cl.lock()\n\tassert.EqualValues(t, 3, tor.pieceNumPendingChunks(0))\n\ttor.cl.unlock()\n\tassert.EqualValues(t, ChunkSpec{4, 1}, chunkIndexSpec(2, tor.pieceLength(0), tor.chunkSize))\n}\n\nfunc TestReducedDialTimeout(t *testing.T) {\n\tcfg := NewDefaultClientConfig()\n\tfor _, _case := range []struct {\n\t\tMax             time.Duration\n\t\tHalfOpenLimit   int\n\t\tPendingPeers    int\n\t\tExpectedReduced time.Duration\n\t}{\n\t\t{cfg.NominalDialTimeout, 40, 0, cfg.NominalDialTimeout},\n\t\t{cfg.NominalDialTimeout, 40, 1, cfg.NominalDialTimeout},\n\t\t{cfg.NominalDialTimeout, 40, 39, cfg.NominalDialTimeout},\n\t\t{cfg.NominalDialTimeout, 40, 40, cfg.NominalDialTimeout / 2},\n\t\t{cfg.NominalDialTimeout, 40, 80, cfg.NominalDialTimeout / 3},\n\t\t{cfg.NominalDialTimeout, 40, 4000, cfg.NominalDialTimeout / 101},\n\t} {\n\t\treduced := reducedDialTimeout(cfg.MinDialTimeout, _case.Max, _case.HalfOpenLimit, _case.PendingPeers)\n\t\texpected := _case.ExpectedReduced\n\t\tif expected < cfg.MinDialTimeout {\n\t\t\texpected = cfg.MinDialTimeout\n\t\t}\n\t\tif reduced != expected {\n\t\t\tt.Fatalf(\"expected %s, got %s\", _case.ExpectedReduced, reduced)\n\t\t}\n\t}\n}\n\nfunc TestAddDropManyTorrents(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tfor i := range 1000 {\n\t\tvar spec TorrentSpec\n\t\tbinary.PutVarint(spec.InfoHash[:], int64(i+1))\n\t\ttt, new, err := cl.AddTorrentSpec(&spec)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, new)\n\t\tdefer tt.Drop()\n\t}\n}\n\nfunc fileCachePieceResourceStorage(fc *filecache.Cache) storage.ClientImpl {\n\treturn storage.NewResourcePiecesOpts(\n\t\tfc.AsResourceProvider(),\n\t\tstorage.ResourcePiecesOpts{\n\t\t\tLeaveIncompleteChunks: true,\n\t\t},\n\t)\n}\n\nfunc TestMergingTrackersByAddingSpecs(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tspec := TorrentSpec{}\n\trand.Read(spec.InfoHash[:])\n\tT, new, _ := cl.AddTorrentSpec(&spec)\n\tif !new {\n\t\tt.FailNow()\n\t}\n\tspec.Trackers = [][]string{{\"http://a\"}, {\"udp://b\"}}\n\t_, new, _ = cl.AddTorrentSpec(&spec)\n\tassert.False(t, new)\n\tassert.EqualValues(t, [][]string{{\"http://a\"}, {\"udp://b\"}}, T.metainfo.AnnounceList)\n\t// Because trackers are disabled in TestingConfig.\n\tassert.EqualValues(t, 0, len(T.trackerAnnouncers))\n}\n\n// We read from a piece which is marked completed, but is missing data.\nfunc TestCompletedPieceWrongSize(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.DefaultStorage = badStorage{}\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tinfo := metainfo.Info{\n\t\tPieceLength: 15,\n\t\tPieces:      make([]byte, 20),\n\t\tFiles: []metainfo.FileInfo{\n\t\t\t{Path: []string{\"greeting\"}, Length: 13},\n\t\t},\n\t}\n\tb, err := bencode.Marshal(info)\n\trequire.NoError(t, err)\n\ttt, new, err := cl.AddTorrentSpec(&TorrentSpec{\n\t\tInfoBytes: b,\n\t\tInfoHash:  metainfo.HashBytes(b),\n\t})\n\trequire.NoError(t, err)\n\tdefer tt.Drop()\n\tassert.True(t, new)\n\tr := tt.NewReader()\n\tdefer r.Close()\n\tqt.Check(t, iotest.TestReader(r, []byte(testutil.GreetingFileContents)), qt.IsNil)\n}\n\nfunc BenchmarkAddLargeTorrent(b *testing.B) {\n\tcfg := TestingConfig(b)\n\tcfg.DisableTCP = true\n\tcfg.DisableUTP = true\n\tcl, err := NewClient(cfg)\n\trequire.NoError(b, err)\n\tdefer cl.Close()\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i += 1 {\n\t\tt, err := cl.AddTorrentFromFile(\"testdata/bootstrap.dat.torrent\")\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tt.Drop()\n\t}\n}\n\nfunc TestResponsive(t *testing.T) {\n\tseederDataDir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(seederDataDir)\n\tcfg := TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.DataDir = seederDataDir\n\tseeder, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer seeder.Close()\n\tseederTorrent, _, _ := seeder.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tseederTorrent.VerifyData()\n\tleecherDataDir := t.TempDir()\n\tcfg = TestingConfig(t)\n\tcfg.DataDir = leecherDataDir\n\tleecher, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer leecher.Close()\n\tleecherTorrent, _, _ := leecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 2\n\t\treturn\n\t}())\n\tleecherTorrent.AddClientPeer(seeder)\n\treader := leecherTorrent.NewReader()\n\tdefer reader.Close()\n\treader.SetReadahead(0)\n\treader.SetResponsive()\n\tb := make([]byte, 2)\n\t_, err = reader.Seek(3, io.SeekStart)\n\trequire.NoError(t, err)\n\t_, err = io.ReadFull(reader, b)\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, \"lo\", string(b))\n\t_, err = reader.Seek(11, io.SeekStart)\n\trequire.NoError(t, err)\n\tn, err := io.ReadFull(reader, b)\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, 2, n)\n\tassert.EqualValues(t, \"d\\n\", string(b))\n}\n\n// TestResponsive was the first test to fail if uTP is disabled and TCP sockets dial from the\n// listening port.\nfunc TestResponsiveTcpOnly(t *testing.T) {\n\tseederDataDir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(seederDataDir)\n\tcfg := TestingConfig(t)\n\tcfg.DisableUTP = true\n\tcfg.Seed = true\n\tcfg.DataDir = seederDataDir\n\tseeder, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer seeder.Close()\n\tseederTorrent, _, _ := seeder.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tseederTorrent.VerifyData()\n\tleecherDataDir := t.TempDir()\n\tcfg = TestingConfig(t)\n\tcfg.DataDir = leecherDataDir\n\tleecher, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer leecher.Close()\n\tleecherTorrent, _, _ := leecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 2\n\t\treturn\n\t}())\n\tleecherTorrent.AddClientPeer(seeder)\n\treader := leecherTorrent.NewReader()\n\tdefer reader.Close()\n\treader.SetReadahead(0)\n\treader.SetResponsive()\n\tb := make([]byte, 2)\n\t_, err = reader.Seek(3, io.SeekStart)\n\trequire.NoError(t, err)\n\t_, err = io.ReadFull(reader, b)\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, \"lo\", string(b))\n\t_, err = reader.Seek(11, io.SeekStart)\n\trequire.NoError(t, err)\n\tn, err := io.ReadFull(reader, b)\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, 2, n)\n\tassert.EqualValues(t, \"d\\n\", string(b))\n}\n\nfunc TestTorrentDroppedDuringResponsiveRead(t *testing.T) {\n\tseederDataDir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(seederDataDir)\n\tcfg := TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.DataDir = seederDataDir\n\tseeder, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer seeder.Close()\n\tseederTorrent, _, _ := seeder.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tseederTorrent.VerifyData()\n\tleecherDataDir := t.TempDir()\n\tcfg = TestingConfig(t)\n\tcfg.DataDir = leecherDataDir\n\tleecher, err := NewClient(cfg)\n\trequire.Nil(t, err)\n\tdefer leecher.Close()\n\tleecherTorrent, _, _ := leecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 2\n\t\treturn\n\t}())\n\tleecherTorrent.AddClientPeer(seeder)\n\treader := leecherTorrent.NewReader()\n\tdefer reader.Close()\n\treader.SetReadahead(0)\n\treader.SetResponsive()\n\tb := make([]byte, 2)\n\t_, err = reader.Seek(3, io.SeekStart)\n\trequire.NoError(t, err)\n\t_, err = io.ReadFull(reader, b)\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, \"lo\", string(b))\n\t_, err = reader.Seek(11, io.SeekStart)\n\trequire.NoError(t, err)\n\tleecherTorrent.Drop()\n\tn, err := reader.Read(b)\n\tassert.EqualError(t, err, \"torrent closed\")\n\tassert.EqualValues(t, 0, n)\n}\n\nfunc TestDhtInheritBlocklist(t *testing.T) {\n\tc := qt.New(t)\n\tipl := iplist.New(nil)\n\trequire.NotNil(t, ipl)\n\tcfg := TestingConfig(t)\n\tcfg.IPBlocklist = ipl\n\tcfg.NoDHT = false\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tnumServers := 0\n\tcl.eachDhtServer(func(s DhtServer) {\n\t\tt.Log(s)\n\t\tassert.Equal(t, ipl, s.(AnacrolixDhtServerWrapper).Server.IPBlocklist())\n\t\tnumServers++\n\t})\n\tc.Assert(numServers, qt.Not(qt.Equals), 0)\n}\n\n// Check that stuff is merged in subsequent AddTorrentSpec for the same\n// infohash.\nfunc TestAddTorrentSpecMerging(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tdir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(dir)\n\ttt, new, err := cl.AddTorrentSpec(&TorrentSpec{\n\t\tInfoHash: mi.HashInfoBytes(),\n\t})\n\trequire.NoError(t, err)\n\trequire.True(t, new)\n\trequire.Nil(t, tt.Info())\n\t_, new, err = cl.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\trequire.NoError(t, err)\n\trequire.False(t, new)\n\trequire.NotNil(t, tt.Info())\n}\n\nfunc TestTorrentDroppedBeforeGotInfo(t *testing.T) {\n\tdir, mi := testutil.GreetingTestTorrent()\n\tos.RemoveAll(dir)\n\tcl, _ := NewClient(TestingConfig(t))\n\tdefer cl.Close()\n\ttt, _, _ := cl.AddTorrentSpec(&TorrentSpec{\n\t\tInfoHash: mi.HashInfoBytes(),\n\t})\n\ttt.Drop()\n\tassert.EqualValues(t, 0, len(cl.Torrents()))\n\tselect {\n\tcase <-tt.GotInfo():\n\t\tt.FailNow()\n\tdefault:\n\t}\n}\n\nfunc writeTorrentData(ts *storage.Torrent, info metainfo.Info, b []byte) {\n\tfor i := 0; i < info.NumPieces(); i += 1 {\n\t\tp := info.Piece(i)\n\t\tts.Piece(p).WriteAt(b[p.Offset():p.Offset()+p.Length()], 0)\n\t}\n}\n\nfunc testAddTorrentPriorPieceCompletion(t *testing.T, alreadyCompleted bool, csf func(*filecache.Cache) storage.ClientImpl) {\n\tfileCacheDir := t.TempDir()\n\tfileCache, err := filecache.NewCache(fileCacheDir)\n\trequire.NoError(t, err)\n\tgreetingDataTempDir, greetingMetainfo := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(greetingDataTempDir)\n\tfilePieceStore := csf(fileCache)\n\tinfo, err := greetingMetainfo.UnmarshalInfo()\n\trequire.NoError(t, err)\n\tih := greetingMetainfo.HashInfoBytes()\n\tgreetingData, err := storage.NewClient(filePieceStore).OpenTorrent(context.Background(), &info, ih)\n\trequire.NoError(t, err)\n\twriteTorrentData(greetingData, info, []byte(testutil.GreetingFileContents))\n\t// require.Equal(t, len(testutil.GreetingFileContents), written)\n\t// require.NoError(t, err)\n\tfor i := 0; i < info.NumPieces(); i++ {\n\t\tp := info.Piece(i)\n\t\tif alreadyCompleted {\n\t\t\trequire.NoError(t, greetingData.Piece(p).MarkComplete())\n\t\t}\n\t}\n\tcfg := TestingConfig(t)\n\t// TODO: Disable network option?\n\tcfg.DisableTCP = true\n\tcfg.DisableUTP = true\n\tcfg.DefaultStorage = filePieceStore\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\ttt, err := cl.AddTorrent(greetingMetainfo)\n\trequire.NoError(t, err)\n\tpsrs := tt.PieceStateRuns()\n\tassert.Len(t, psrs, 1)\n\tassert.EqualValues(t, 3, psrs[0].Length)\n\tassert.Equal(t, alreadyCompleted, psrs[0].Complete)\n\tif alreadyCompleted {\n\t\tr := tt.NewReader()\n\t\tquicktest.Check(t, iotest.TestReader(r, []byte(testutil.GreetingFileContents)), quicktest.IsNil)\n\t}\n}\n\nfunc TestAddTorrentPiecesAlreadyCompleted(t *testing.T) {\n\ttestAddTorrentPriorPieceCompletion(t, true, fileCachePieceResourceStorage)\n}\n\nfunc TestAddTorrentPiecesNotAlreadyCompleted(t *testing.T) {\n\ttestAddTorrentPriorPieceCompletion(t, false, fileCachePieceResourceStorage)\n}\n\nfunc TestAddMetainfoWithNodes(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.ListenHost = func(string) string { return \"\" }\n\tcfg.NoDHT = false\n\tcfg.DhtStartingNodes = func(string) dht.StartingNodesGetter { return func() ([]dht.Addr, error) { return nil, nil } }\n\t// For now, we want to just jam the nodes into the table, without verifying them first. Also the\n\t// DHT code doesn't support mixing secure and insecure nodes if security is enabled (yet).\n\t// cfg.DHTConfig.NoSecurity = true\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tsum := func() (ret int64) {\n\t\tcl.eachDhtServer(func(s DhtServer) {\n\t\t\tret += s.Stats().(dht.ServerStats).OutboundQueriesAttempted\n\t\t})\n\t\treturn\n\t}\n\tassert.EqualValues(t, 0, sum())\n\ttt, err := cl.AddTorrentFromFile(\"metainfo/testdata/issue_65a.torrent\")\n\trequire.NoError(t, err)\n\t// Nodes are not added or exposed in Torrent's metainfo. We just randomly\n\t// check if the announce-list is here instead. TODO: Add nodes.\n\tassert.Len(t, tt.metainfo.AnnounceList, 5)\n\t// There are 6 nodes in the torrent file.\n\tfor sum() != int64(6*len(cl.dhtServers)) {\n\t\ttime.Sleep(time.Millisecond)\n\t}\n}\n\ntype testDownloadCancelParams struct {\n\tSetLeecherStorageCapacity bool\n\tLeecherStorageCapacity    int64\n\tCancel                    bool\n}\n\nfunc testDownloadCancel(t *testing.T, ps testDownloadCancelParams) {\n\tgreetingTempDir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(greetingTempDir)\n\tcfg := TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.DataDir = greetingTempDir\n\tseeder, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer seeder.Close()\n\tdefer testutil.ExportStatusWriter(seeder, \"s\", t)()\n\tseederTorrent, _, _ := seeder.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\tseederTorrent.VerifyData()\n\tleecherDataDir := t.TempDir()\n\tfc, err := filecache.NewCache(leecherDataDir)\n\trequire.NoError(t, err)\n\tif ps.SetLeecherStorageCapacity {\n\t\tfc.SetCapacity(ps.LeecherStorageCapacity)\n\t}\n\tcfg.DefaultStorage = storage.NewResourcePieces(fc.AsResourceProvider())\n\tcfg.DataDir = leecherDataDir\n\tleecher, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer leecher.Close()\n\tdefer testutil.ExportStatusWriter(leecher, \"l\", t)()\n\tleecherGreeting, new, err := leecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 2\n\t\treturn\n\t}())\n\trequire.NoError(t, err)\n\tassert.True(t, new)\n\tpsc := leecherGreeting.SubscribePieceStateChanges()\n\tdefer psc.Close()\n\n\tleecherGreeting.cl.lock()\n\tleecherGreeting.downloadPiecesLocked(0, leecherGreeting.numPieces())\n\tif ps.Cancel {\n\t\tleecherGreeting.cancelPiecesLocked(0, leecherGreeting.NumPieces(), \"\")\n\t}\n\tleecherGreeting.cl.unlock()\n\tdone := make(chan struct{})\n\tdefer close(done)\n\tgo leecherGreeting.AddClientPeer(seeder)\n\tcompletes := make(map[int]bool, 3)\n\texpected := func() map[int]bool {\n\t\tif ps.Cancel {\n\t\t\treturn map[int]bool{0: false, 1: false, 2: false}\n\t\t} else {\n\t\t\treturn map[int]bool{0: true, 1: true, 2: true}\n\t\t}\n\t}()\n\tfor !reflect.DeepEqual(completes, expected) {\n\t\tv := <-psc.Values\n\t\tcompletes[v.Index] = v.Complete\n\t}\n}\n\nfunc TestTorrentDownloadAll(t *testing.T) {\n\ttestDownloadCancel(t, testDownloadCancelParams{})\n}\n\nfunc TestTorrentDownloadAllThenCancel(t *testing.T) {\n\ttestDownloadCancel(t, testDownloadCancelParams{\n\t\tCancel: true,\n\t})\n}\n\n// Ensure that it's an error for a peer to send an invalid have message.\nfunc TestPeerInvalidHave(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.DropMutuallyCompletePeers = false\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tinfo := metainfo.Info{\n\t\tPieceLength: 1,\n\t\tPieces:      make([]byte, 20),\n\t\tFiles:       []metainfo.FileInfo{{Length: 1}},\n\t}\n\tinfoBytes, err := bencode.Marshal(info)\n\trequire.NoError(t, err)\n\ttt, _new, err := cl.AddTorrentSpec(&TorrentSpec{\n\t\tInfoBytes: infoBytes,\n\t\tInfoHash:  metainfo.HashBytes(infoBytes),\n\t\tStorage:   badStorage{},\n\t})\n\trequire.NoError(t, err)\n\tassert.True(t, _new)\n\tdefer tt.Drop()\n\tcn := &PeerConn{Peer: Peer{\n\t\tt:         tt,\n\t\tcallbacks: &cfg.Callbacks,\n\t}}\n\ttt.conns[cn] = struct{}{}\n\tcn.peerImpl = cn\n\tcl.lock()\n\tdefer cl.unlock()\n\tassert.NoError(t, cn.peerSentHave(0))\n\tassert.Error(t, cn.peerSentHave(1))\n}\n\nfunc TestPieceCompletedInStorageButNotClient(t *testing.T) {\n\tc := qt.New(t)\n\tgreetingTempDir, greetingMetainfo := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(greetingTempDir)\n\tcfg := TestingConfig(t)\n\tcfg.DataDir = greetingTempDir\n\tseeder, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer seeder.Close()\n\t_, new, err := seeder.AddTorrentSpec(&TorrentSpec{\n\t\tInfoBytes: greetingMetainfo.InfoBytes,\n\t\tInfoHash:  greetingMetainfo.HashInfoBytes(),\n\t})\n\tc.Check(err, qt.IsNil)\n\tc.Check(new, qt.IsTrue)\n}\n\n// Check that when the listen port is 0, all the protocols listened on have\n// the same port, and it isn't zero.\nfunc TestClientDynamicListenPortAllProtocols(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tport := cl.LocalPort()\n\tassert.NotEqual(t, 0, port)\n\tcl.eachListener(func(s Listener) bool {\n\t\tassert.Equal(t, port, missinggo.AddrPort(s.Addr()))\n\t\treturn true\n\t})\n}\n\nfunc TestClientDynamicListenTCPOnly(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.DisableUTP = true\n\tcfg.DisableTCP = false\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tassert.NotEqual(t, 0, cl.LocalPort())\n}\n\nfunc TestClientDynamicListenUTPOnly(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.DisableTCP = true\n\tcfg.DisableUTP = false\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tassert.NotEqual(t, 0, cl.LocalPort())\n}\n\nfunc totalConns(tts []*Torrent) (ret int) {\n\tfor _, tt := range tts {\n\t\ttt.cl.lock()\n\t\tret += len(tt.conns)\n\t\ttt.cl.unlock()\n\t}\n\treturn\n}\n\nfunc TestSetMaxEstablishedConn(t *testing.T) {\n\tvar tts []*Torrent\n\tih := testutil.GreetingMetaInfo().HashInfoBytes()\n\tcfg := TestingConfig(t)\n\tcfg.DisableAcceptRateLimiting = true\n\tcfg.DropDuplicatePeerIds = true\n\tfor i := 0; i < 3; i += 1 {\n\t\tcl, err := NewClient(cfg)\n\t\trequire.NoError(t, err)\n\t\tdefer cl.Close()\n\t\ttt, _ := cl.AddTorrentInfoHash(ih)\n\t\ttt.SetMaxEstablishedConns(2)\n\t\tdefer testutil.ExportStatusWriter(cl, fmt.Sprintf(\"%d\", i), t)()\n\t\ttts = append(tts, tt)\n\t}\n\taddPeers := func() {\n\t\tfor _, tt := range tts {\n\t\t\tfor _, _tt := range tts {\n\t\t\t\t// if tt != _tt {\n\t\t\t\ttt.AddClientPeer(_tt.cl)\n\t\t\t\t// }\n\t\t\t}\n\t\t}\n\t}\n\twaitTotalConns := func(num int) {\n\t\tfor totalConns(tts) != num {\n\t\t\taddPeers()\n\t\t\ttime.Sleep(time.Millisecond)\n\t\t}\n\t}\n\taddPeers()\n\twaitTotalConns(6)\n\ttts[0].SetMaxEstablishedConns(1)\n\twaitTotalConns(4)\n\ttts[0].SetMaxEstablishedConns(0)\n\twaitTotalConns(2)\n\ttts[0].SetMaxEstablishedConns(1)\n\taddPeers()\n\twaitTotalConns(4)\n\ttts[0].SetMaxEstablishedConns(2)\n\taddPeers()\n\twaitTotalConns(6)\n}\n\n// Creates a file containing its own name as data. Make a metainfo from that, adds it to the given\n// client, and returns a magnet link.\nfunc makeMagnet(t *testing.T, cl *Client, dir, name string) string {\n\tos.MkdirAll(dir, 0o770)\n\tfile, err := os.Create(filepath.Join(dir, name))\n\trequire.NoError(t, err)\n\tfile.Write([]byte(name))\n\tfile.Close()\n\tmi := metainfo.MetaInfo{}\n\tmi.SetDefaults()\n\tinfo := metainfo.Info{PieceLength: 256 * 1024}\n\terr = info.BuildFromFilePath(filepath.Join(dir, name))\n\trequire.NoError(t, err)\n\tmi.InfoBytes, err = bencode.Marshal(info)\n\trequire.NoError(t, err)\n\tmagnet := mi.Magnet(nil, &info).String()\n\ttr, err := cl.AddTorrent(&mi)\n\trequire.NoError(t, err)\n\trequire.True(t, tr.Seeding())\n\ttr.VerifyData()\n\treturn magnet\n}\n\n// https://github.com/anacrolix/torrent/issues/114\nfunc TestMultipleTorrentsWithEncryption(t *testing.T) {\n\ttestSeederLeecherPair(\n\t\tt,\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.Preferred = true\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = true\n\t\t},\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = false\n\t\t},\n\t)\n}\n\n// Test that the leecher can download a torrent in its entirety from the seeder. Note that the\n// seeder config is done first.\nfunc testSeederLeecherPair(t *testing.T, seeder, leecher func(*ClientConfig)) {\n\tcfg := TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.DataDir = filepath.Join(cfg.DataDir, \"server\")\n\tos.Mkdir(cfg.DataDir, 0o755)\n\tseeder(cfg)\n\tserver, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer server.Close()\n\tdefer testutil.ExportStatusWriter(server, \"s\", t)()\n\tmagnet1 := makeMagnet(t, server, cfg.DataDir, \"test1\")\n\t// Extra torrents are added to test the seeder having to match incoming obfuscated headers\n\t// against more than one torrent. See issue #114\n\tmakeMagnet(t, server, cfg.DataDir, \"test2\")\n\tfor i := 0; i < 100; i++ {\n\t\tmakeMagnet(t, server, cfg.DataDir, fmt.Sprintf(\"test%d\", i+2))\n\t}\n\tcfg = TestingConfig(t)\n\tcfg.DataDir = filepath.Join(cfg.DataDir, \"client\")\n\tleecher(cfg)\n\tclient, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer client.Close()\n\tdefer testutil.ExportStatusWriter(client, \"c\", t)()\n\ttr, err := client.AddMagnet(magnet1)\n\trequire.NoError(t, err)\n\ttr.AddClientPeer(server)\n\t<-tr.GotInfo()\n\ttr.DownloadAll()\n\tclient.WaitAll()\n}\n\n// This appears to be the situation with the S3 BitTorrent client.\nfunc TestObfuscatedHeaderFallbackSeederDisallowsLeecherPrefers(t *testing.T) {\n\t// Leecher prefers obfuscation, but the seeder does not allow it.\n\ttestSeederLeecherPair(\n\t\tt,\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.Preferred = false\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = true\n\t\t},\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.Preferred = true\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = false\n\t\t},\n\t)\n}\n\nfunc TestObfuscatedHeaderFallbackSeederRequiresLeecherPrefersNot(t *testing.T) {\n\t// Leecher prefers no obfuscation, but the seeder enforces it.\n\ttestSeederLeecherPair(\n\t\tt,\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.Preferred = true\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = true\n\t\t},\n\t\tfunc(cfg *ClientConfig) {\n\t\t\tcfg.HeaderObfuscationPolicy.Preferred = false\n\t\t\tcfg.HeaderObfuscationPolicy.RequirePreferred = false\n\t\t},\n\t)\n}\n\nfunc TestClientAddressInUse(t *testing.T) {\n\ts, _ := NewUtpSocket(\"udp\", \"localhost:50007\", nil, log.Default)\n\tif s != nil {\n\t\tdefer s.Close()\n\t}\n\tcfg := TestingConfig(t).SetListenAddr(\"localhost:50007\")\n\tcfg.DisableUTP = false\n\tcl, err := NewClient(cfg)\n\tif err == nil {\n\t\tassert.Nil(t, cl.Close())\n\t}\n\trequire.Error(t, err)\n\trequire.Nil(t, cl)\n}\n\nfunc TestClientHasDhtServersWhenUtpDisabled(t *testing.T) {\n\tcc := TestingConfig(t)\n\tcc.DisableUTP = true\n\tcc.NoDHT = false\n\tcl, err := NewClient(cc)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tassert.NotEmpty(t, cl.DhtServers())\n}\n\nfunc TestClientDisabledImplicitNetworksButDhtEnabled(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.DisableTCP = true\n\tcfg.DisableUTP = true\n\tcfg.NoDHT = false\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tassert.Empty(t, cl.listeners)\n\tassert.NotEmpty(t, cl.DhtServers())\n}\n\nfunc TestBadPeerIpPort(t *testing.T) {\n\tfor _, tc := range []struct {\n\t\ttitle      string\n\t\tip         net.IP\n\t\tport       int\n\t\texpectedOk bool\n\t\tsetup      func(*Client)\n\t}{\n\t\t{\"empty both\", nil, 0, true, func(*Client) {}},\n\t\t{\"empty/nil ip\", nil, 6666, true, func(*Client) {}},\n\t\t{\n\t\t\t\"empty port\",\n\t\t\tnet.ParseIP(\"127.0.0.1/32\"),\n\t\t\t0, true,\n\t\t\tfunc(*Client) {},\n\t\t},\n\t\t{\n\t\t\t\"in doppleganger addresses\",\n\t\t\tnet.ParseIP(\"127.0.0.1/32\"),\n\t\t\t2322,\n\t\t\ttrue,\n\t\t\tfunc(cl *Client) {\n\t\t\t\tcl.dopplegangerAddrs[\"10.0.0.1:2322\"] = struct{}{}\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"in IP block list\",\n\t\t\tnet.ParseIP(\"10.0.0.1\"),\n\t\t\t2322,\n\t\t\ttrue,\n\t\t\tfunc(cl *Client) {\n\t\t\t\tcl.ipBlockList = iplist.New([]iplist.Range{\n\t\t\t\t\t{First: net.ParseIP(\"10.0.0.1\"), Last: net.ParseIP(\"10.0.0.255\")},\n\t\t\t\t})\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"in bad peer IPs\",\n\t\t\tnet.ParseIP(\"10.0.0.1\"),\n\t\t\t2322,\n\t\t\ttrue,\n\t\t\tfunc(cl *Client) {\n\t\t\t\tipAddr, ok := netip.AddrFromSlice(net.ParseIP(\"10.0.0.1\"))\n\t\t\t\trequire.True(t, ok)\n\t\t\t\tcl.badPeerIPs = map[netip.Addr]struct{}{}\n\t\t\t\tcl.badPeerIPs[ipAddr] = struct{}{}\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"good\",\n\t\t\tnet.ParseIP(\"10.0.0.1\"),\n\t\t\t2322,\n\t\t\tfalse,\n\t\t\tfunc(cl *Client) {},\n\t\t},\n\t} {\n\t\tt.Run(tc.title, func(t *testing.T) {\n\t\t\tcfg := TestingConfig(t)\n\t\t\tcfg.DisableTCP = true\n\t\t\tcfg.DisableUTP = true\n\t\t\tcfg.NoDHT = false\n\t\t\tcl, err := NewClient(cfg)\n\t\t\trequire.NoError(t, err)\n\t\t\tdefer cl.Close()\n\n\t\t\ttc.setup(cl)\n\t\t\trequire.Equal(t, tc.expectedOk, cl.badPeerIPPort(tc.ip, tc.port))\n\t\t})\n\t}\n}\n\n// https://github.com/anacrolix/torrent/issues/837\nfunc TestClientConfigSetHandlerNotIgnored(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.Logger.SetHandlers(log.DiscardHandler)\n\tc := qt.New(t)\n\tcl, err := NewClient(cfg)\n\tc.Assert(err, qt.IsNil)\n\tdefer cl.Close()\n\tc.Assert(cl.logger.Handlers, qt.HasLen, 1)\n\th := cl.logger.Handlers[0].(log.StreamHandler)\n\tc.Check(h.W, qt.Equals, io.Discard)\n}\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 10.2890625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"time\"\n\n\t\"github.com/anacrolix/dht/v2\"\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/pion/webrtc/v4\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/iplist\"\n\t\"github.com/anacrolix/torrent/mse\"\n\t\"github.com/anacrolix/torrent/storage\"\n\t\"github.com/anacrolix/torrent/version\"\n)\n\n// Contains config elements that are exclusive to tracker handling. There may be other fields in\n// ClientConfig that are also relevant.\ntype ClientTrackerConfig struct {\n\t// Don't announce to trackers. This only leaves DHT to discover peers.\n\tDisableTrackers bool `long:\"disable-trackers\"`\n\t// Defines DialContext func to use for HTTP tracker announcements\n\tTrackerDialContext func(ctx context.Context, network, addr string) (net.Conn, error)\n\t// Defines ListenPacket func to use for UDP tracker announcements\n\tTrackerListenPacket func(network, addr string) (net.PacketConn, error)\n\t// Takes a tracker's hostname and requests DNS A and AAAA records.\n\t// Used in case DNS lookups require a special setup (i.e., dns-over-https)\n\tLookupTrackerIp func(*url.URL) ([]net.IP, error)\n}\n\ntype ClientDhtConfig struct {\n\t// Don't create a DHT.\n\tNoDHT            bool `long:\"disable-dht\"`\n\tDhtStartingNodes func(network string) dht.StartingNodesGetter\n\t// Called for each anacrolix/dht Server created for the Client.\n\tConfigureAnacrolixDhtServer       func(*dht.ServerConfig)\n\tPeriodicallyAnnounceTorrentsToDht bool\n\t// OnQuery hook func\n\tDHTOnQuery func(query *krpc.Msg, source net.Addr) (propagate bool)\n}\n\n// Probably not safe to modify this after it's given to a Client.\ntype ClientConfig struct {\n\tClientTrackerConfig\n\tClientDhtConfig\n\n\t// Store torrent file data in this directory unless .DefaultStorage is\n\t// specified.\n\tDataDir string `long:\"data-dir\" description:\"directory to store downloaded torrent data\"`\n\t// The address to listen for new uTP and TCP BitTorrent protocol connections. DHT shares a UDP\n\t// socket with uTP unless configured otherwise.\n\tListenHost              func(network string) string\n\tListenPort              int\n\tNoDefaultPortForwarding bool\n\tUpnpID                  string\n\tDisablePEX              bool `long:\"disable-pex\"`\n\n\t// Never send chunks to peers.\n\tNoUpload bool `long:\"no-upload\"`\n\t// Disable uploading even when it isn't fair.\n\tDisableAggressiveUpload bool `long:\"disable-aggressive-upload\"`\n\t// Upload even after there's nothing in it for us. By default uploading is\n\t// not altruistic, we'll only upload to encourage the peer to reciprocate.\n\tSeed bool `long:\"seed\"`\n\t// Only applies to chunks uploaded to peers, to maintain responsiveness\n\t// communicating local Client state to peers. Each limiter token\n\t// represents one byte. The Limiter's burst must be large enough to fit a\n\t// whole chunk, which is usually 16 KiB (see TorrentSpec.ChunkSize).\n\tUploadRateLimiter *rate.Limiter\n\t// Rate limits all reads from connections to peers. Each limiter token\n\t// represents one byte. The Limiter's burst must be bigger than the\n\t// largest Read performed on a the underlying rate-limiting io.Reader\n\t// minus one. This is likely to be the larger of the main read loop buffer\n\t// (~4096), and the requested chunk size (~16KiB, see\n\t// TorrentSpec.ChunkSize).\n\tDownloadRateLimiter *rate.Limiter\n\t// Maximum unverified bytes across all torrents. Not used if zero.\n\tMaxUnverifiedBytes int64\n\n\t// User-provided Client peer ID. If not present, one is generated automatically.\n\tPeerID string\n\t// For the bittorrent protocol.\n\tDisableUTP bool\n\t// For the bittorrent protocol.\n\tDisableTCP bool `long:\"disable-tcp\"`\n\t// Called to instantiate storage for each added torrent. Builtin backends\n\t// are in the storage package. If not set, the \"file\" implementation is\n\t// used (and Closed when the Client is Closed).\n\tDefaultStorage storage.ClientImpl\n\n\tHeaderObfuscationPolicy HeaderObfuscationPolicy\n\t// The crypto methods to offer when initiating connections with header obfuscation.\n\tCryptoProvides mse.CryptoMethod\n\t// Chooses the crypto method to use when receiving connections with header obfuscation.\n\tCryptoSelector mse.CryptoSelector\n\n\tIPBlocklist      iplist.Ranger\n\tDisableIPv6      bool `long:\"disable-ipv6\"`\n\tDisableIPv4      bool\n\tDisableIPv4Peers bool\n\t// Perform logging and any other behaviour that will help debug.\n\tDebug  bool `help:\"enable debugging\"`\n\tLogger log.Logger\n\n\t// Used for torrent sources and webseeding if set.\n\tWebTransport http.RoundTripper\n\t// Defines proxy for HTTP requests, such as for trackers. It's commonly set from the result of\n\t// \"net/http\".ProxyURL(HTTPProxy).\n\tHTTPProxy func(*http.Request) (*url.URL, error)\n\t// Defines DialContext func to use for HTTP requests, such as for fetching metainfo and webtorrent seeds\n\tHTTPDialContext func(ctx context.Context, network, addr string) (net.Conn, error)\n\t// HTTPUserAgent changes default UserAgent for HTTP requests\n\tHTTPUserAgent string\n\t// HttpRequestDirector modifies the request before it's sent.\n\t// Useful for adding authentication headers, for example\n\tHttpRequestDirector func(*http.Request) error\n\t// WebsocketTrackerHttpHeader returns a custom header to be used when dialing a websocket connection\n\t// to the tracker. Useful for adding authentication headers\n\tWebsocketTrackerHttpHeader func() http.Header\n\t// Updated occasionally to when there's been some changes to client\n\t// behaviour in case other clients are assuming anything of us. See also\n\t// `bep20`.\n\tExtendedHandshakeClientVersion string\n\t// Peer ID client identifier prefix. We'll update this occasionally to\n\t// reflect changes to client behaviour that other clients may depend on.\n\t// Also see `extendedHandshakeClientVersion`.\n\tBep20 string\n\n\t// Peer dial timeout to use when there are limited peers.\n\tNominalDialTimeout time.Duration\n\t// Minimum peer dial timeout to use (even if we have lots of peers).\n\tMinDialTimeout             time.Duration\n\tEstablishedConnsPerTorrent int\n\tHalfOpenConnsPerTorrent    int\n\tTotalHalfOpenConns         int\n\t// Maximum number of peer addresses in reserve.\n\tTorrentPeersHighWater int\n\t// Minumum number of peers before effort is made to obtain more peers.\n\tTorrentPeersLowWater int\n\n\t// Limit how long handshake can take. This is to reduce the lingering\n\t// impact of a few bad apples. 4s loses 1% of successful handshakes that\n\t// are obtained with 60s timeout, and 5% of unsuccessful handshakes.\n\tHandshakesTimeout time.Duration\n\t// How long between writes before sending a keep alive message on a peer connection that we want\n\t// to maintain.\n\tKeepAliveTimeout time.Duration\n\t// Maximum bytes to buffer per peer connection for peer request data before it is sent.\n\tMaxAllocPeerRequestDataPerConn int64\n\n\t// The IP addresses as our peers should see them. May differ from the\n\t// local interfaces due to NAT or other network configurations.\n\tPublicIp4 net.IP\n\tPublicIp6 net.IP\n\n\t// Accept rate limiting affects excessive connection attempts from IPs that fail during\n\t// handshakes or request torrents that we don't have.\n\tDisableAcceptRateLimiting bool\n\t// Don't add connections that have the same peer ID as an existing\n\t// connection for a given Torrent.\n\tDropDuplicatePeerIds bool\n\t// Drop peers that are complete if we are also complete and have no use for the peer. This is a\n\t// bit of a special case, since a peer could also be useless if they're just not interested, or\n\t// we don't intend to obtain all of a torrent's data.\n\tDropMutuallyCompletePeers bool\n\t// Whether to accept peer connections at all.\n\tAcceptPeerConnections bool\n\t// Whether a Client should want conns without delegating to any attached Torrents. This is\n\t// useful when torrents might be added dynamically in callbacks for example.\n\tAlwaysWantConns bool\n\n\tExtensions PeerExtensionBits\n\t// Bits that peers must have set to proceed past handshakes.\n\tMinPeerExtensions PeerExtensionBits\n\n\tDisableWebtorrent bool\n\tDisableWebseeds   bool\n\n\tCallbacks Callbacks\n\n\t// ICEServerList defines a slice describing servers available to be used by\n\t// ICE, such as STUN and TURN servers.\n\tICEServerList []webrtc.ICEServer\n\n\t// Deprecated. ICEServers does not support server authentication and therefore\n\t// it cannot be used with most TURN servers. Use ICEServerList instead.\n\t// ICEServers is kept for legacy support.\n\tICEServers []string\n\n\tDialRateLimiter *rate.Limiter\n\n\tPieceHashersPerTorrent int // default: 2\n}\n\nfunc (cfg *ClientConfig) SetListenAddr(addr string) *ClientConfig {\n\thost, port, err := missinggo.ParseHostPort(addr)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcfg.ListenHost = func(string) string { return host }\n\tcfg.ListenPort = port\n\treturn cfg\n}\n\nfunc NewDefaultClientConfig() *ClientConfig {\n\tcc := &ClientConfig{\n\t\tHTTPUserAgent:                  version.DefaultHttpUserAgent,\n\t\tExtendedHandshakeClientVersion: version.DefaultExtendedHandshakeClientVersion,\n\t\tBep20:                          version.DefaultBep20Prefix,\n\t\tUpnpID:                         version.DefaultUpnpId,\n\t\tNominalDialTimeout:             20 * time.Second,\n\t\tMinDialTimeout:                 3 * time.Second,\n\t\tEstablishedConnsPerTorrent:     50,\n\t\tHalfOpenConnsPerTorrent:        25,\n\t\tTotalHalfOpenConns:             100,\n\t\tTorrentPeersHighWater:          500,\n\t\tTorrentPeersLowWater:           50,\n\t\tHandshakesTimeout:              4 * time.Second,\n\t\tKeepAliveTimeout:               time.Minute,\n\t\tMaxAllocPeerRequestDataPerConn: 1 << 20,\n\t\tListenHost:                     func(string) string { return \"\" },\n\t\tUploadRateLimiter:              unlimited,\n\t\tDownloadRateLimiter:            unlimited,\n\t\tDisableAcceptRateLimiting:      true,\n\t\tDropMutuallyCompletePeers:      true,\n\t\tHeaderObfuscationPolicy: HeaderObfuscationPolicy{\n\t\t\tPreferred:        true,\n\t\t\tRequirePreferred: false,\n\t\t},\n\t\tCryptoSelector:         mse.DefaultCryptoSelector,\n\t\tCryptoProvides:         mse.AllSupportedCrypto,\n\t\tListenPort:             42069,\n\t\tExtensions:             defaultPeerExtensionBytes(),\n\t\tAcceptPeerConnections:  true,\n\t\tMaxUnverifiedBytes:     64 << 20,\n\t\tDialRateLimiter:        rate.NewLimiter(10, 10),\n\t\tPieceHashersPerTorrent: 2,\n\t}\n\tcc.DhtStartingNodes = func(network string) dht.StartingNodesGetter {\n\t\treturn func() ([]dht.Addr, error) { return dht.GlobalBootstrapAddrs(network) }\n\t}\n\tcc.PeriodicallyAnnounceTorrentsToDht = true\n\treturn cc\n}\n\ntype HeaderObfuscationPolicy struct {\n\tRequirePreferred bool // Whether the value of Preferred is a strict requirement.\n\tPreferred        bool // Whether header obfuscation is preferred.\n}\n"
        },
        {
          "name": "conn_stats.go",
          "type": "blob",
          "size": 2.8037109375,
          "content": "package torrent\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"sync/atomic\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\n// Various connection-level metrics. At the Torrent level these are aggregates. Chunks are messages\n// with data payloads. Data is actual torrent content without any overhead. Useful is something we\n// needed locally. Unwanted is something we didn't ask for (but may still be useful). Written is\n// things sent to the peer, and Read is stuff received from them. Due to the implementation of\n// Count, must be aligned on some platforms: See https://github.com/anacrolix/torrent/issues/262.\ntype ConnStats struct {\n\t// Total bytes on the wire. Includes handshakes and encryption.\n\tBytesWritten     Count\n\tBytesWrittenData Count\n\n\tBytesRead                   Count\n\tBytesReadData               Count\n\tBytesReadUsefulData         Count\n\tBytesReadUsefulIntendedData Count\n\n\tChunksWritten Count\n\n\tChunksRead       Count\n\tChunksReadUseful Count\n\tChunksReadWasted Count\n\n\tMetadataChunksRead Count\n\n\t// Number of pieces data was written to, that subsequently passed verification.\n\tPiecesDirtiedGood Count\n\t// Number of pieces data was written to, that subsequently failed verification. Note that a\n\t// connection may not have been the sole dirtier of a piece.\n\tPiecesDirtiedBad Count\n}\n\nfunc (me *ConnStats) Copy() (ret ConnStats) {\n\tfor i := 0; i < reflect.TypeOf(ConnStats{}).NumField(); i++ {\n\t\tn := reflect.ValueOf(me).Elem().Field(i).Addr().Interface().(*Count).Int64()\n\t\treflect.ValueOf(&ret).Elem().Field(i).Addr().Interface().(*Count).Add(n)\n\t}\n\treturn\n}\n\ntype Count struct {\n\tn int64\n}\n\nvar _ fmt.Stringer = (*Count)(nil)\n\nfunc (me *Count) Add(n int64) {\n\tatomic.AddInt64(&me.n, n)\n}\n\nfunc (me *Count) Int64() int64 {\n\treturn atomic.LoadInt64(&me.n)\n}\n\nfunc (me *Count) String() string {\n\treturn fmt.Sprintf(\"%v\", me.Int64())\n}\n\nfunc (me *Count) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(me.n)\n}\n\nfunc (cs *ConnStats) wroteMsg(msg *pp.Message) {\n\t// TODO: Track messages and not just chunks.\n\tswitch msg.Type {\n\tcase pp.Piece:\n\t\tcs.ChunksWritten.Add(1)\n\t\tcs.BytesWrittenData.Add(int64(len(msg.Piece)))\n\t}\n}\n\nfunc (cs *ConnStats) receivedChunk(size int64) {\n\tcs.ChunksRead.Add(1)\n\tcs.BytesReadData.Add(size)\n}\n\nfunc (cs *ConnStats) incrementPiecesDirtiedGood() {\n\tcs.PiecesDirtiedGood.Add(1)\n}\n\nfunc (cs *ConnStats) incrementPiecesDirtiedBad() {\n\tcs.PiecesDirtiedBad.Add(1)\n}\n\nfunc add(n int64, f func(*ConnStats) *Count) func(*ConnStats) {\n\treturn func(cs *ConnStats) {\n\t\tp := f(cs)\n\t\tp.Add(n)\n\t}\n}\n\ntype connStatsReadWriter struct {\n\trw io.ReadWriter\n\tc  *PeerConn\n}\n\nfunc (me connStatsReadWriter) Write(b []byte) (n int, err error) {\n\tn, err = me.rw.Write(b)\n\tme.c.wroteBytes(int64(n))\n\treturn\n}\n\nfunc (me connStatsReadWriter) Read(b []byte) (n int, err error) {\n\tn, err = me.rw.Read(b)\n\tme.c.readBytes(int64(n))\n\treturn\n}\n"
        },
        {
          "name": "deferrwl.go",
          "type": "blob",
          "size": 0.8642578125,
          "content": "package torrent\n\nimport \"github.com/anacrolix/sync\"\n\n// Runs deferred actions on Unlock. Note that actions are assumed to be the results of changes that\n// would only occur with a write lock at present. The race detector should catch instances of defers\n// without the write lock being held.\ntype lockWithDeferreds struct {\n\tinternal      sync.RWMutex\n\tunlockActions []func()\n}\n\nfunc (me *lockWithDeferreds) Lock() {\n\tme.internal.Lock()\n}\n\nfunc (me *lockWithDeferreds) Unlock() {\n\tunlockActions := me.unlockActions\n\tfor i := 0; i < len(unlockActions); i += 1 {\n\t\tunlockActions[i]()\n\t}\n\tme.unlockActions = unlockActions[:0]\n\tme.internal.Unlock()\n}\n\nfunc (me *lockWithDeferreds) RLock() {\n\tme.internal.RLock()\n}\n\nfunc (me *lockWithDeferreds) RUnlock() {\n\tme.internal.RUnlock()\n}\n\nfunc (me *lockWithDeferreds) Defer(action func()) {\n\tme.unlockActions = append(me.unlockActions, action)\n}\n"
        },
        {
          "name": "dht.go",
          "type": "blob",
          "size": 1.568359375,
          "content": "package torrent\n\nimport (\n\t\"io\"\n\t\"net\"\n\n\t\"github.com/anacrolix/dht/v2\"\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\tpeer_store \"github.com/anacrolix/dht/v2/peer-store\"\n)\n\n// DHT server interface for use by a Torrent or Client. It's reasonable for this to make assumptions\n// for torrent-use that might not be the default behaviour for the DHT server.\ntype DhtServer interface {\n\tStats() interface{}\n\tID() [20]byte\n\tAddr() net.Addr\n\tAddNode(ni krpc.NodeInfo) error\n\t// This is called asynchronously when receiving PORT messages.\n\tPing(addr *net.UDPAddr)\n\tAnnounce(hash [20]byte, port int, impliedPort bool) (DhtAnnounce, error)\n\tWriteStatus(io.Writer)\n}\n\n// Optional interface for DhtServer's that can expose their peer store (if any).\ntype PeerStorer interface {\n\tPeerStore() peer_store.Interface\n}\n\ntype DhtAnnounce interface {\n\tClose()\n\tPeers() <-chan dht.PeersValues\n}\n\ntype AnacrolixDhtServerWrapper struct {\n\t*dht.Server\n}\n\nfunc (me AnacrolixDhtServerWrapper) Stats() interface{} {\n\treturn me.Server.Stats()\n}\n\ntype anacrolixDhtAnnounceWrapper struct {\n\t*dht.Announce\n}\n\nfunc (me anacrolixDhtAnnounceWrapper) Peers() <-chan dht.PeersValues {\n\treturn me.Announce.Peers\n}\n\nfunc (me AnacrolixDhtServerWrapper) Announce(hash [20]byte, port int, impliedPort bool) (DhtAnnounce, error) {\n\tann, err := me.Server.Announce(hash, port, impliedPort)\n\treturn anacrolixDhtAnnounceWrapper{ann}, err\n}\n\nfunc (me AnacrolixDhtServerWrapper) Ping(addr *net.UDPAddr) {\n\tme.Server.PingQueryInput(addr, dht.QueryInput{\n\t\tRateLimiting: dht.QueryRateLimiting{NoWaitFirst: true},\n\t})\n}\n\nvar _ DhtServer = AnacrolixDhtServerWrapper{}\n"
        },
        {
          "name": "dial-pool.go",
          "type": "blob",
          "size": 0.6396484375,
          "content": "package torrent\n\nimport (\n\t\"context\"\n)\n\ntype dialPool struct {\n\tresCh chan DialResult\n\taddr  string\n\tleft  int\n}\n\nfunc (me *dialPool) getFirst() (res DialResult) {\n\tfor me.left > 0 && res.Conn == nil {\n\t\tres = <-me.resCh\n\t\tme.left--\n\t}\n\treturn\n}\n\nfunc (me *dialPool) add(ctx context.Context, dialer Dialer) {\n\tme.left++\n\tgo func() {\n\t\tme.resCh <- DialResult{\n\t\t\tdialFromSocket(ctx, dialer, me.addr),\n\t\t\tdialer,\n\t\t}\n\t}()\n}\n\nfunc (me *dialPool) startDrainer() {\n\tgo me.drainAndCloseRemainingDials()\n}\n\nfunc (me *dialPool) drainAndCloseRemainingDials() {\n\tfor me.left > 0 {\n\t\tconn := (<-me.resCh).Conn\n\t\tme.left--\n\t\tif conn != nil {\n\t\t\tconn.Close()\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "dialer.go",
          "type": "blob",
          "size": 0.1748046875,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/torrent/dialer\"\n)\n\ntype (\n\tDialer        = dialer.T\n\tNetworkDialer = dialer.WithNetwork\n)\n\nvar DefaultNetDialer = &dialer.Default\n"
        },
        {
          "name": "dialer",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.9326171875,
          "content": "/*\nPackage torrent implements a torrent client. Goals include:\n  - Configurable data storage, such as file, mmap, and piece-based.\n  - Downloading on demand: torrent.Reader will request only the data required to\n    satisfy Reads, which is ideal for streaming and torrentfs.\n\nBitTorrent features implemented include:\n  - Protocol obfuscation\n  - DHT\n  - uTP\n  - PEX\n  - Magnet links\n  - IP Blocklists\n  - Some IPv6\n  - HTTP and UDP tracker clients\n  - BEPs:\n  - 3: Basic BitTorrent protocol\n  - 5: DHT\n  - 6: Fast Extension (have all/none only)\n  - 7: IPv6 Tracker Extension\n  - 9: ut_metadata\n  - 10: Extension protocol\n  - 11: PEX\n  - 12: Multitracker metadata extension\n  - 15: UDP Tracker Protocol\n  - 19: WebSeed\n  - 20: Peer ID convention (\"-GTnnnn-\")\n  - 23: Tracker Returns Compact Peer Lists\n  - 29: uTorrent transport protocol\n  - 41: UDP Tracker Protocol Extensions\n  - 42: DHT Security extension\n  - 43: Read-only DHT Nodes\n*/\npackage torrent\n"
        },
        {
          "name": "example_test.go",
          "type": "blob",
          "size": 0.5244140625,
          "content": "package torrent_test\n\nimport (\n\t\"log\"\n\n\t\"github.com/anacrolix/torrent\"\n)\n\nfunc Example() {\n\tc, _ := torrent.NewClient(nil)\n\tdefer c.Close()\n\tt, _ := c.AddMagnet(\"magnet:?xt=urn:btih:ZOCMZQIPFFW7OLLMIC5HUB6BPCSDEOQU\")\n\t<-t.GotInfo()\n\tt.DownloadAll()\n\tc.WaitAll()\n\tlog.Print(\"ermahgerd, torrent downloaded\")\n}\n\nfunc Example_fileReader() {\n\tvar f torrent.File\n\t// Accesses the parts of the torrent pertaining to f. Data will be\n\t// downloaded as required, per the configuration of the torrent.Reader.\n\tr := f.NewReader()\n\tdefer r.Close()\n}\n"
        },
        {
          "name": "file.go",
          "type": "blob",
          "size": 5.6474609375,
          "content": "package torrent\n\nimport (\n\t\"crypto/sha256\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\n// Provides access to regions of torrent data that correspond to its files.\ntype File struct {\n\tt           *Torrent\n\tpath        string\n\toffset      int64\n\tlength      int64\n\tfi          metainfo.FileInfo\n\tdisplayPath string\n\tprio        PiecePriority\n\tpiecesRoot  g.Option[[sha256.Size]byte]\n}\n\nfunc (f *File) String() string {\n\treturn f.Path()\n}\n\nfunc (f *File) Torrent() *Torrent {\n\treturn f.t\n}\n\n// Data for this file begins this many bytes into the Torrent.\nfunc (f *File) Offset() int64 {\n\treturn f.offset\n}\n\n// The FileInfo from the metainfo.Info to which this file corresponds.\nfunc (f *File) FileInfo() metainfo.FileInfo {\n\treturn f.fi\n}\n\n// The file's path components joined by '/'.\nfunc (f *File) Path() string {\n\treturn f.path\n}\n\n// The file's length in bytes.\nfunc (f *File) Length() int64 {\n\treturn f.length\n}\n\n// Number of bytes of the entire file we have completed. This is the sum of\n// completed pieces, and dirtied chunks of incomplete pieces.\nfunc (f *File) BytesCompleted() (n int64) {\n\tf.t.cl.rLock()\n\tn = f.bytesCompletedLocked()\n\tf.t.cl.rUnlock()\n\treturn\n}\n\nfunc (f *File) bytesCompletedLocked() int64 {\n\treturn f.length - f.bytesLeft()\n}\n\nfunc fileBytesLeft(\n\ttorrentUsualPieceSize int64,\n\tfileFirstPieceIndex int,\n\tfileEndPieceIndex int,\n\tfileTorrentOffset int64,\n\tfileLength int64,\n\ttorrentCompletedPieces *roaring.Bitmap,\n\tpieceSizeCompletedFn func(pieceIndex int) int64,\n) (left int64) {\n\tif fileLength == 0 {\n\t\treturn\n\t}\n\n\tnoCompletedMiddlePieces := roaring.New()\n\tnoCompletedMiddlePieces.AddRange(bitmap.BitRange(fileFirstPieceIndex), bitmap.BitRange(fileEndPieceIndex))\n\tnoCompletedMiddlePieces.AndNot(torrentCompletedPieces)\n\tnoCompletedMiddlePieces.Iterate(func(pieceIndex uint32) bool {\n\t\ti := int(pieceIndex)\n\t\tpieceSizeCompleted := pieceSizeCompletedFn(i)\n\t\tif i == fileFirstPieceIndex {\n\t\t\tbeginOffset := fileTorrentOffset % torrentUsualPieceSize\n\t\t\tbeginSize := torrentUsualPieceSize - beginOffset\n\t\t\tbeginDownLoaded := pieceSizeCompleted - beginOffset\n\t\t\tif beginDownLoaded < 0 {\n\t\t\t\tbeginDownLoaded = 0\n\t\t\t}\n\t\t\tleft += beginSize - beginDownLoaded\n\t\t} else if i == fileEndPieceIndex-1 {\n\t\t\tendSize := (fileTorrentOffset + fileLength) % torrentUsualPieceSize\n\t\t\tif endSize == 0 {\n\t\t\t\tendSize = torrentUsualPieceSize\n\t\t\t}\n\t\t\tendDownloaded := pieceSizeCompleted\n\t\t\tif endDownloaded > endSize {\n\t\t\t\tendDownloaded = endSize\n\t\t\t}\n\t\t\tleft += endSize - endDownloaded\n\t\t} else {\n\t\t\tleft += torrentUsualPieceSize - pieceSizeCompleted\n\t\t}\n\t\treturn true\n\t})\n\n\tif left > fileLength {\n\t\tleft = fileLength\n\t}\n\t//\n\t//numPiecesSpanned := f.EndPieceIndex() - f.BeginPieceIndex()\n\t//completedMiddlePieces := f.t._completedPieces.Clone()\n\t//completedMiddlePieces.RemoveRange(0, bitmap.BitRange(f.BeginPieceIndex()+1))\n\t//completedMiddlePieces.RemoveRange(bitmap.BitRange(f.EndPieceIndex()-1), bitmap.ToEnd)\n\t//left += int64(numPiecesSpanned-2-pieceIndex(completedMiddlePieces.GetCardinality())) * torrentUsualPieceSize\n\treturn\n}\n\nfunc (f *File) bytesLeft() (left int64) {\n\treturn fileBytesLeft(int64(f.t.usualPieceSize()), f.BeginPieceIndex(), f.EndPieceIndex(), f.offset, f.length, &f.t._completedPieces, func(pieceIndex int) int64 {\n\t\treturn int64(f.t.piece(pieceIndex).numDirtyBytes())\n\t})\n}\n\n// The relative file path for a multi-file torrent, and the torrent name for a\n// single-file torrent. Dir separators are '/'.\nfunc (f *File) DisplayPath() string {\n\treturn f.displayPath\n}\n\n// The download status of a piece that comprises part of a File.\ntype FilePieceState struct {\n\tBytes int64 // Bytes within the piece that are part of this File.\n\tPieceState\n}\n\n// Returns the state of pieces in this file.\nfunc (f *File) State() (ret []FilePieceState) {\n\tf.t.cl.rLock()\n\tdefer f.t.cl.rUnlock()\n\tpieceSize := int64(f.t.usualPieceSize())\n\toff := f.offset % pieceSize\n\tremaining := f.length\n\tfor i := pieceIndex(f.offset / pieceSize); ; i++ {\n\t\tif remaining == 0 {\n\t\t\tbreak\n\t\t}\n\t\tlen1 := pieceSize - off\n\t\tif len1 > remaining {\n\t\t\tlen1 = remaining\n\t\t}\n\t\tps := f.t.pieceState(i)\n\t\tret = append(ret, FilePieceState{len1, ps})\n\t\toff = 0\n\t\tremaining -= len1\n\t}\n\treturn\n}\n\n// Requests that all pieces containing data in the file be downloaded.\nfunc (f *File) Download() {\n\tf.SetPriority(PiecePriorityNormal)\n}\n\nfunc byteRegionExclusivePieces(off, size, pieceSize int64) (begin, end int) {\n\tbegin = int((off + pieceSize - 1) / pieceSize)\n\tend = int((off + size) / pieceSize)\n\treturn\n}\n\n// Deprecated: Use File.SetPriority.\nfunc (f *File) Cancel() {\n\tf.SetPriority(PiecePriorityNone)\n}\n\nfunc (f *File) NewReader() Reader {\n\treturn f.t.newReader(f.Offset(), f.Length())\n}\n\n// Sets the minimum priority for pieces in the File.\nfunc (f *File) SetPriority(prio PiecePriority) {\n\tf.t.cl.lock()\n\tif prio != f.prio {\n\t\tf.prio = prio\n\t\tf.t.updatePiecePriorities(f.BeginPieceIndex(), f.EndPieceIndex(), \"File.SetPriority\")\n\t}\n\tf.t.cl.unlock()\n}\n\n// Returns the priority per File.SetPriority.\nfunc (f *File) Priority() (prio PiecePriority) {\n\tf.t.cl.rLock()\n\tprio = f.prio\n\tf.t.cl.rUnlock()\n\treturn\n}\n\n// Returns the index of the first piece containing data for the file.\nfunc (f *File) BeginPieceIndex() int {\n\tif f.t.usualPieceSize() == 0 {\n\t\treturn 0\n\t}\n\treturn pieceIndex(f.offset / int64(f.t.usualPieceSize()))\n}\n\n// Returns the index of the piece after the last one containing data for the file.\nfunc (f *File) EndPieceIndex() int {\n\tif f.t.usualPieceSize() == 0 {\n\t\treturn 0\n\t}\n\treturn pieceIndex((f.offset + f.length + int64(f.t.usualPieceSize()) - 1) / int64(f.t.usualPieceSize()))\n}\n\nfunc (f *File) numPieces() int {\n\treturn f.EndPieceIndex() - f.BeginPieceIndex()\n}\n"
        },
        {
          "name": "file_test.go",
          "type": "blob",
          "size": 2.4697265625,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestFileExclusivePieces(t *testing.T) {\n\tfor _, _case := range []struct {\n\t\toff, size, pieceSize int64\n\t\tbegin, end           int\n\t}{\n\t\t{0, 2, 2, 0, 1},\n\t\t{1, 2, 2, 1, 1},\n\t\t{1, 4, 2, 1, 2},\n\t} {\n\t\tbegin, end := byteRegionExclusivePieces(_case.off, _case.size, _case.pieceSize)\n\t\tassert.EqualValues(t, _case.begin, begin)\n\t\tassert.EqualValues(t, _case.end, end)\n\t}\n}\n\ntype testFileBytesLeft struct {\n\tusualPieceSize  int64\n\tfirstPieceIndex int\n\tendPieceIndex   int\n\tfileOffset      int64\n\tfileLength      int64\n\tcompletedPieces roaring.Bitmap\n\texpected        int64\n\tname            string\n}\n\nfunc (me testFileBytesLeft) Run(t *testing.T) {\n\tt.Run(me.name, func(t *testing.T) {\n\t\tassert.EqualValues(t, me.expected, fileBytesLeft(me.usualPieceSize, me.firstPieceIndex, me.endPieceIndex, me.fileOffset, me.fileLength, &me.completedPieces, func(pieceIndex int) int64 {\n\t\t\treturn 0\n\t\t}))\n\t})\n}\n\nfunc TestFileBytesLeft(t *testing.T) {\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 1,\n\t\tendPieceIndex:   1,\n\t\tfileOffset:      1,\n\t\tfileLength:      0,\n\t\texpected:        0,\n\t\tname:            \"ZeroLengthFile\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  2,\n\t\tfirstPieceIndex: 1,\n\t\tendPieceIndex:   2,\n\t\tfileOffset:      1,\n\t\tfileLength:      1,\n\t\texpected:        1,\n\t\tname:            \"EndOfSecondPiece\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 0,\n\t\tendPieceIndex:   1,\n\t\tfileOffset:      1,\n\t\tfileLength:      1,\n\t\texpected:        1,\n\t\tname:            \"FileInFirstPiece\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 0,\n\t\tendPieceIndex:   1,\n\t\tfileOffset:      1,\n\t\tfileLength:      1,\n\t\texpected:        1,\n\t\tname:            \"LandLocked\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 1,\n\t\tendPieceIndex:   3,\n\t\tfileOffset:      4,\n\t\tfileLength:      4,\n\t\texpected:        4,\n\t\tname:            \"TwoPieces\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 1,\n\t\tendPieceIndex:   4,\n\t\tfileOffset:      5,\n\t\tfileLength:      7,\n\t\texpected:        7,\n\t\tname:            \"ThreePieces\",\n\t}.Run(t)\n\n\ttestFileBytesLeft{\n\t\tusualPieceSize:  3,\n\t\tfirstPieceIndex: 1,\n\t\tendPieceIndex:   4,\n\t\tfileOffset:      5,\n\t\tfileLength:      7,\n\t\texpected:        0,\n\t\tcompletedPieces: func() (ret roaring.Bitmap) {\n\t\t\tret.AddRange(0, 5)\n\t\t\treturn\n\t\t}(),\n\t\tname: \"ThreePiecesCompletedAll\",\n\t}.Run(t)\n}\n"
        },
        {
          "name": "fs",
          "type": "tree",
          "content": null
        },
        {
          "name": "global.go",
          "type": "blob",
          "size": 2.173828125,
          "content": "package torrent\n\nimport (\n\t\"crypto\"\n\t\"expvar\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nconst (\n\tpieceHash        = crypto.SHA1\n\tdefaultChunkSize = 0x4000 // 16KiB\n\n\t// Arbitrary maximum of \"metadata_size\" (see https://www.bittorrent.org/beps/bep_0009.html)\n\t// libtorrent-rasterbar uses 4MiB at last check. TODO: Add links to values used by other\n\t// implementations here. I saw 14143527 in the metainfo for\n\t// 3597f16e239aeb8f8524a1a1c4e4725a0a96b470. Large values for legitimate torrents should be\n\t// recorded here for consideration.\n\tmaxMetadataSize uint32 = 16 * 1024 * 1024\n)\n\nfunc defaultPeerExtensionBytes() PeerExtensionBits {\n\treturn pp.NewPeerExtensionBytes(pp.ExtensionBitDht, pp.ExtensionBitLtep, pp.ExtensionBitFast)\n}\n\nfunc init() {\n\ttorrent.Set(\"peers supporting extension\", &peersSupportingExtension)\n\ttorrent.Set(\"chunks received\", &ChunksReceived)\n}\n\n// I could move a lot of these counters to their own file, but I suspect they\n// may be attached to a Client someday.\nvar (\n\ttorrent                  = expvar.NewMap(\"torrent\")\n\tpeersSupportingExtension expvar.Map\n\t// This could move at any time. It contains counts of chunks received and the conditions they\n\t// were received.\n\tChunksReceived expvar.Map\n\n\tpieceHashedCorrect    = expvar.NewInt(\"pieceHashedCorrect\")\n\tpieceHashedNotCorrect = expvar.NewInt(\"pieceHashedNotCorrect\")\n\n\tcompletedHandshakeConnectionFlags = expvar.NewMap(\"completedHandshakeConnectionFlags\")\n\t// Count of connections to peer with same client ID.\n\tconnsToSelf        = expvar.NewInt(\"connsToSelf\")\n\treceivedKeepalives = expvar.NewInt(\"receivedKeepalives\")\n\t// Requests received for pieces we don't have.\n\trequestsReceivedForMissingPieces = expvar.NewInt(\"requestsReceivedForMissingPieces\")\n\trequestedChunkLengths            = expvar.NewMap(\"requestedChunkLengths\")\n\n\tmessageTypesReceived = expvar.NewMap(\"messageTypesReceived\")\n\n\t// Track the effectiveness of Torrent.connPieceInclinationPool.\n\tpieceInclinationsReused = expvar.NewInt(\"pieceInclinationsReused\")\n\tpieceInclinationsNew    = expvar.NewInt(\"pieceInclinationsNew\")\n\tpieceInclinationsPut    = expvar.NewInt(\"pieceInclinationsPut\")\n\n\tconcurrentChunkWrites = expvar.NewInt(\"torrentConcurrentChunkWrites\")\n)\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 7.3544921875,
          "content": "module github.com/anacrolix/torrent\n\ngo 1.23\n\nrequire (\n\tgithub.com/RoaringBitmap/roaring v1.2.3\n\tgithub.com/ajwerner/btree v0.0.0-20211221152037-f427b3e689c0\n\tgithub.com/alexflint/go-arg v1.4.3\n\tgithub.com/anacrolix/bargle v0.0.0-20221014000746-4f2739072e9d\n\tgithub.com/anacrolix/chansync v0.4.1-0.20240627045151-1aa1ac392fe8\n\tgithub.com/anacrolix/dht/v2 v2.19.2-0.20221121215055-066ad8494444\n\tgithub.com/anacrolix/envpprof v1.3.0\n\tgithub.com/anacrolix/fuse v0.2.0\n\tgithub.com/anacrolix/generics v0.0.3-0.20240902042256-7fb2702ef0ca\n\tgithub.com/anacrolix/go-libutp v1.3.1\n\tgithub.com/anacrolix/gostdapp v0.1.0\n\tgithub.com/anacrolix/log v0.15.3-0.20240627045001-cd912c641d83\n\tgithub.com/anacrolix/missinggo v1.3.0\n\tgithub.com/anacrolix/missinggo/v2 v2.7.4\n\tgithub.com/anacrolix/multiless v0.4.0\n\tgithub.com/anacrolix/possum/go v0.1.1-0.20240321122240-a01f3a22f2d1\n\tgithub.com/anacrolix/squirrel v0.6.4\n\tgithub.com/anacrolix/sync v0.5.1\n\tgithub.com/anacrolix/tagflag v1.3.0\n\tgithub.com/anacrolix/upnp v0.1.4\n\tgithub.com/anacrolix/utp v0.1.0\n\tgithub.com/bahlo/generic-list-go v0.2.0\n\tgithub.com/bradfitz/iter v0.0.0-20191230175014-e8f45d346db8\n\tgithub.com/cespare/xxhash v1.1.0\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/dustin/go-humanize v1.0.0\n\tgithub.com/edsrzf/mmap-go v1.1.0\n\tgithub.com/elliotchance/orderedmap v1.4.0\n\tgithub.com/frankban/quicktest v1.14.6\n\tgithub.com/fsnotify/fsnotify v1.5.4\n\tgithub.com/go-llsqlite/adapter v0.0.0-20230927005056-7f5ce7f0c916\n\tgithub.com/go-quicktest/qt v1.101.0\n\tgithub.com/google/btree v1.1.2\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/gorilla/websocket v1.5.0\n\tgithub.com/jessevdk/go-flags v1.5.0\n\tgithub.com/multiformats/go-multihash v0.2.3\n\tgithub.com/pion/datachannel v1.5.9\n\tgithub.com/pion/logging v0.2.2\n\tgithub.com/pion/webrtc/v4 v4.0.0\n\tgithub.com/pkg/errors v0.9.1\n\tgithub.com/prometheus/client_golang v1.12.2\n\tgithub.com/protolambda/ctxlock v0.1.0\n\tgithub.com/stretchr/testify v1.9.0\n\tgithub.com/tidwall/btree v1.6.0\n\tgo.etcd.io/bbolt v1.3.6\n\tgo.opentelemetry.io/otel v1.11.1\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.11.1\n\tgo.opentelemetry.io/otel/sdk v1.11.1\n\tgo.opentelemetry.io/otel/trace v1.11.1\n\tgolang.org/x/sync v0.8.0\n\tgolang.org/x/sys v0.26.0\n\tgolang.org/x/time v0.0.0-20220609170525-579cf78fd858\n)\n\nrequire (\n\tgithub.com/alecthomas/atomic v0.1.0-alpha2 // indirect\n\tgithub.com/alexflint/go-scalar v1.1.0 // indirect\n\tgithub.com/anacrolix/backtrace v0.0.0-20221205112523-22a61db8f82e // indirect\n\tgithub.com/anacrolix/missinggo/perf v1.0.0 // indirect\n\tgithub.com/anacrolix/mmsg v1.0.0 // indirect\n\tgithub.com/anacrolix/stm v0.4.0 // indirect\n\tgithub.com/benbjohnson/immutable v0.3.0 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/bits-and-blooms/bitset v1.2.2 // indirect\n\tgithub.com/cenkalti/backoff/v4 v4.1.3 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/go-llsqlite/crawshaw v0.5.2-0.20240425034140-f30eb7704568 // indirect\n\tgithub.com/go-logr/logr v1.2.3 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/go-ole/go-ole v1.2.6 // indirect\n\tgithub.com/golang/protobuf v1.5.3 // indirect\n\tgithub.com/google/uuid v1.6.0 // indirect\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2 v2.12.0 // indirect\n\tgithub.com/honeycombio/honeycomb-opentelemetry-go v0.3.0 // indirect\n\tgithub.com/honeycombio/opentelemetry-go-contrib/launcher v0.0.0-20221031150637-a3c60ed98d54 // indirect\n\tgithub.com/huandu/xstrings v1.3.2 // indirect\n\tgithub.com/klauspost/cpuid/v2 v2.2.3 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/lufia/plan9stats v0.0.0-20220913051719-115f729f3c8c // indirect\n\tgithub.com/mattn/go-isatty v0.0.16 // indirect\n\tgithub.com/matttproud/golang_protobuf_extensions v1.0.1 // indirect\n\tgithub.com/minio/sha256-simd v1.0.0 // indirect\n\tgithub.com/mr-tron/base58 v1.2.0 // indirect\n\tgithub.com/mschoch/smat v0.2.0 // indirect\n\tgithub.com/multiformats/go-varint v0.0.6 // indirect\n\tgithub.com/pion/dtls/v3 v3.0.3 // indirect\n\tgithub.com/pion/ice/v4 v4.0.2 // indirect\n\tgithub.com/pion/interceptor v0.1.37 // indirect\n\tgithub.com/pion/mdns/v2 v2.0.7 // indirect\n\tgithub.com/pion/randutil v0.1.0 // indirect\n\tgithub.com/pion/rtcp v1.2.14 // indirect\n\tgithub.com/pion/rtp v1.8.9 // indirect\n\tgithub.com/pion/sctp v1.8.33 // indirect\n\tgithub.com/pion/sdp/v3 v3.0.9 // indirect\n\tgithub.com/pion/srtp/v3 v3.0.4 // indirect\n\tgithub.com/pion/stun/v3 v3.0.0 // indirect\n\tgithub.com/pion/transport/v3 v3.0.7 // indirect\n\tgithub.com/pion/turn/v4 v4.0.0 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/power-devops/perfstat v0.0.0-20220216144756-c35f1ee13d7c // indirect\n\tgithub.com/prometheus/client_model v0.2.0 // indirect\n\tgithub.com/prometheus/common v0.35.0 // indirect\n\tgithub.com/prometheus/procfs v0.7.3 // indirect\n\tgithub.com/remyoudompheng/bigfft v0.0.0-20230129092748-24d4a6f8daec // indirect\n\tgithub.com/rogpeppe/go-internal v1.11.0 // indirect\n\tgithub.com/rs/dnscache v0.0.0-20211102005908-e0241e321417 // indirect\n\tgithub.com/ryszard/goskiplist v0.0.0-20150312221310-2dfbae5fcf46 // indirect\n\tgithub.com/sethvargo/go-envconfig v0.8.2 // indirect\n\tgithub.com/shirou/gopsutil/v3 v3.22.9 // indirect\n\tgithub.com/spaolacci/murmur3 v1.1.0 // indirect\n\tgithub.com/tklauser/go-sysconf v0.3.10 // indirect\n\tgithub.com/tklauser/numcpus v0.5.0 // indirect\n\tgithub.com/wlynxg/anet v0.0.3 // indirect\n\tgithub.com/yusufpapurcu/wmi v1.2.2 // indirect\n\tgo.opentelemetry.io/contrib/instrumentation/host v0.36.4 // indirect\n\tgo.opentelemetry.io/contrib/instrumentation/runtime v0.36.4 // indirect\n\tgo.opentelemetry.io/contrib/propagators/b3 v1.11.1 // indirect\n\tgo.opentelemetry.io/contrib/propagators/ot v1.11.1 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/internal/retry v1.11.1 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlpmetric v0.33.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v0.33.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v0.33.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.11.1 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.11.1 // indirect\n\tgo.opentelemetry.io/otel/exporters/stdout/stdouttrace v1.11.1 // indirect\n\tgo.opentelemetry.io/otel/metric v0.33.0 // indirect\n\tgo.opentelemetry.io/otel/sdk/metric v0.33.0 // indirect\n\tgo.opentelemetry.io/proto/otlp v0.19.0 // indirect\n\tgo.uber.org/atomic v1.10.0 // indirect\n\tgo.uber.org/multierr v1.8.0 // indirect\n\tgolang.org/x/crypto v0.28.0 // indirect\n\tgolang.org/x/exp v0.0.0-20240823005443-9b4947da3948 // indirect\n\tgolang.org/x/net v0.29.0 // indirect\n\tgolang.org/x/text v0.19.0 // indirect\n\tgolang.org/x/xerrors v0.0.0-20220609144429-65e65417b02f // indirect\n\tgoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1 // indirect\n\tgoogle.golang.org/grpc v1.56.3 // indirect\n\tgoogle.golang.org/protobuf v1.33.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n\tlukechampine.com/blake3 v1.1.6 // indirect\n\tmodernc.org/libc v1.22.3 // indirect\n\tmodernc.org/mathutil v1.5.0 // indirect\n\tmodernc.org/memory v1.5.0 // indirect\n\tmodernc.org/sqlite v1.21.1 // indirect\n\tzombiezen.com/go/sqlite v0.13.1 // indirect\n)\n\nretract (\n\t// Doesn't signal interest to peers if choked when piece priorities change.\n\tv1.39.0\n\t// peer-requesting doesn't scale\n\t[v1.34.0, v1.38.1]\n\t// Indefinite outgoing requests on storage write errors. https://github.com/anacrolix/torrent/issues/889\n\t[v1.29.0, v1.53.2]\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 92.1142578125,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.38.0/go.mod h1:990N+gfupTy94rShfmMCWGDn0LpTmnzTp2qbd1dvSRU=\ncloud.google.com/go v0.44.1/go.mod h1:iSa0KzasP4Uvy3f1mN/7PiObzGgflwredwwASm/v6AU=\ncloud.google.com/go v0.44.2/go.mod h1:60680Gw3Yr4ikxnPRS/oxxkBccT6SA1yMk63TGekxKY=\ncloud.google.com/go v0.45.1/go.mod h1:RpBamKRgapWJb87xiFSdk4g1CME7QZg3uwTez+TSTjc=\ncloud.google.com/go v0.46.3/go.mod h1:a6bKKbmY7er1mI7TEI4lsAkts/mkhTSZK8w33B4RAg0=\ncloud.google.com/go v0.50.0/go.mod h1:r9sluTvynVuxRIOHXQEHMFffphuXHOMZMycpNR5e6To=\ncloud.google.com/go v0.52.0/go.mod h1:pXajvRH/6o3+F9jDHZWQ5PbGhn+o8w9qiu/CffaVdO4=\ncloud.google.com/go v0.53.0/go.mod h1:fp/UouUEsRkN6ryDKNW/Upv/JBKnv6WDthjR6+vze6M=\ncloud.google.com/go v0.54.0/go.mod h1:1rq2OEkV3YMf6n/9ZvGWI3GWw0VoqH/1x2nd8Is/bPc=\ncloud.google.com/go v0.56.0/go.mod h1:jr7tqZxxKOVYizybht9+26Z/gUq7tiRzu+ACVAMbKVk=\ncloud.google.com/go v0.57.0/go.mod h1:oXiQ6Rzq3RAkkY7N6t3TcE6jE+CIBBbA36lwQ1JyzZs=\ncloud.google.com/go v0.62.0/go.mod h1:jmCYTdRCQuc1PHIIJ/maLInMho30T/Y0M4hTdTShOYc=\ncloud.google.com/go v0.65.0/go.mod h1:O5N8zS7uWy9vkA9vayVHs65eM1ubvY4h553ofrNHObY=\ncloud.google.com/go/bigquery v1.0.1/go.mod h1:i/xbL2UlR5RvWAURpBYZTtm/cXjCha9lbfbpx4poX+o=\ncloud.google.com/go/bigquery v1.3.0/go.mod h1:PjpwJnslEMmckchkHFfq+HTD2DmtT67aNFKH1/VBDHE=\ncloud.google.com/go/bigquery v1.4.0/go.mod h1:S8dzgnTigyfTmLBfrtrhyYhwRxG72rYxvftPBK2Dvzc=\ncloud.google.com/go/bigquery v1.5.0/go.mod h1:snEHRnqQbz117VIFhE8bmtwIDY80NLUZUMb4Nv6dBIg=\ncloud.google.com/go/bigquery v1.7.0/go.mod h1://okPTzCYNXSlb24MZs83e2Do+h+VXtc4gLoIoXIAPc=\ncloud.google.com/go/bigquery v1.8.0/go.mod h1:J5hqkt3O0uAFnINi6JXValWIb1v0goeZM77hZzJN/fQ=\ncloud.google.com/go/datastore v1.0.0/go.mod h1:LXYbyblFSglQ5pkeyhO+Qmw7ukd3C+pD7TKLgZqpHYE=\ncloud.google.com/go/datastore v1.1.0/go.mod h1:umbIZjpQpHh4hmRpGhH4tLFup+FVzqBi1b3c64qFpCk=\ncloud.google.com/go/pubsub v1.0.1/go.mod h1:R0Gpsv3s54REJCy4fxDixWD93lHJMoZTyQ2kNxGRt3I=\ncloud.google.com/go/pubsub v1.1.0/go.mod h1:EwwdRX2sKPjnvnqCa270oGRyludottCI76h+R3AArQw=\ncloud.google.com/go/pubsub v1.2.0/go.mod h1:jhfEVHT8odbXTkndysNHCcx0awwzvfOlguIAii9o8iA=\ncloud.google.com/go/pubsub v1.3.1/go.mod h1:i+ucay31+CNRpDW4Lu78I4xXG+O1r/MAHgjpRVR+TSU=\ncloud.google.com/go/storage v1.0.0/go.mod h1:IhtSnM/ZTZV8YYJWCY8RULGVqBDmpoyjwiyrjsg+URw=\ncloud.google.com/go/storage v1.5.0/go.mod h1:tpKbwo567HUNpVclU5sGELwQWBDZ8gh0ZeosJ0Rtdos=\ncloud.google.com/go/storage v1.6.0/go.mod h1:N7U0C8pVQ/+NIKOBQyamJIeKQKkZ+mxpohlUTyfDhBk=\ncloud.google.com/go/storage v1.8.0/go.mod h1:Wv1Oy7z6Yz3DshWRJFhqM/UCfaWIRTdp0RXyy7KQOVs=\ncloud.google.com/go/storage v1.10.0/go.mod h1:FLPqc6j+Ki4BU591ie1oL6qBQGu2Bl/tZ9ullr3+Kg0=\ncrawshaw.io/iox v0.0.0-20181124134642-c51c3df30797/go.mod h1:sXBiorCo8c46JlQV3oXPKINnZ8mcqnye1EkVkqsectk=\ncrawshaw.io/sqlite v0.3.2/go.mod h1:igAO5JulrQ1DbdZdtVq48mnZUBAPOeFzer7VhDWNtW4=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\nfilippo.io/edwards25519 v1.0.0-rc.1 h1:m0VOOB23frXZvAOK44usCgLWvtsxIoMCTBGJZlpmGfU=\nfilippo.io/edwards25519 v1.0.0-rc.1/go.mod h1:N1IkdkCkiLB6tki+MYJoSx2JTY9NUlxZE7eHn5EwJns=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\ngithub.com/Julusian/godocdown v0.0.0-20170816220326-6d19f8ff2df8/go.mod h1:INZr5t32rG59/5xeltqoCJoNY7e5x/3xoY9WSWVWg74=\ngithub.com/OneOfOne/xxhash v1.2.2 h1:KMrpdQIwFcEqXDklaen+P1axHaj9BSKzvpUUfnHldSE=\ngithub.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=\ngithub.com/RoaringBitmap/roaring v0.4.7/go.mod h1:8khRDP4HmeXns4xIj9oGrKSz7XTQiJx2zgh7AcNke4w=\ngithub.com/RoaringBitmap/roaring v0.4.17/go.mod h1:D3qVegWTmfCaX4Bl5CrBE9hfrSrrXIr8KVNvRsDi1NI=\ngithub.com/RoaringBitmap/roaring v0.4.23/go.mod h1:D0gp8kJQgE1A4LQ5wFLggQEyvDi06Mq5mKs52e1TwOo=\ngithub.com/RoaringBitmap/roaring v1.2.3 h1:yqreLINqIrX22ErkKI0vY47/ivtJr6n+kMhVOVmhWBY=\ngithub.com/RoaringBitmap/roaring v1.2.3/go.mod h1:plvDsJQpxOC5bw8LRteu/MLWHsHez/3y6cubLI4/1yE=\ngithub.com/Shopify/sarama v1.19.0/go.mod h1:FVkBWblsNy7DGZRfXLU0O9RCGt5g3g3yEuWXgklEdEo=\ngithub.com/Shopify/toxiproxy v2.1.4+incompatible/go.mod h1:OXgGpZ6Cli1/URJOF1DMxUHB2q5Ap20/P/eIdh4G0pI=\ngithub.com/ajwerner/btree v0.0.0-20211221152037-f427b3e689c0 h1:byYvvbfSo3+9efR4IeReh77gVs4PnNDR3AMOE9NJ7a0=\ngithub.com/ajwerner/btree v0.0.0-20211221152037-f427b3e689c0/go.mod h1:q37NoqncT41qKc048STsifIt69LfUJ8SrWWcz/yam5k=\ngithub.com/alecthomas/assert/v2 v2.0.0-alpha3 h1:pcHeMvQ3OMstAWgaeaXIAL8uzB9xMm2zlxt+/4ml8lk=\ngithub.com/alecthomas/assert/v2 v2.0.0-alpha3/go.mod h1:+zD0lmDXTeQj7TgDgCt0ePWxb0hMC1G+PGTsTCv1B9o=\ngithub.com/alecthomas/atomic v0.1.0-alpha2 h1:dqwXmax66gXvHhsOS4pGPZKqYOlTkapELkLb3MNdlH8=\ngithub.com/alecthomas/atomic v0.1.0-alpha2/go.mod h1:zD6QGEyw49HIq19caJDc2NMXAy8rNi9ROrxtMXATfyI=\ngithub.com/alecthomas/repr v0.0.0-20210801044451-80ca428c5142 h1:8Uy0oSf5co/NZXje7U1z8Mpep++QJOldL2hs/sBQf48=\ngithub.com/alecthomas/repr v0.0.0-20210801044451-80ca428c5142/go.mod h1:2kn6fqh/zIyPLmm3ugklbEi5hg5wS435eygvNfaDQL8=\ngithub.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190717042225-c3de453c63f4/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190924025748-f65c72e2690d/go.mod h1:rBZYJk541a8SKzHPHnH3zbiI+7dagKZ0cgpgrD7Fyho=\ngithub.com/alexflint/go-arg v1.4.3 h1:9rwwEBpMXfKQKceuZfYcwuc/7YY7tWJbFsgG5cAU/uo=\ngithub.com/alexflint/go-arg v1.4.3/go.mod h1:3PZ/wp/8HuqRZMUUgu7I+e1qcpUbvmS258mRXkFH4IA=\ngithub.com/alexflint/go-scalar v1.1.0 h1:aaAouLLzI9TChcPXotr6gUhq+Scr8rl0P9P4PnltbhM=\ngithub.com/alexflint/go-scalar v1.1.0/go.mod h1:LoFvNMqS1CPrMVltza4LvnGKhaSpc3oyLEBUZVhhS2o=\ngithub.com/anacrolix/backtrace v0.0.0-20221205112523-22a61db8f82e h1:A0Ty9UeyBDIo29ZMnk0AvPqWDIa4HVvCaJqWNlCrMXA=\ngithub.com/anacrolix/backtrace v0.0.0-20221205112523-22a61db8f82e/go.mod h1:4YFqy+788tLJWtin2jNliYVJi+8aDejG9zcu/2/pONw=\ngithub.com/anacrolix/bargle v0.0.0-20221014000746-4f2739072e9d h1:ypNOsIwvdumNRlqWj/hsnLs5TyQWQOylwi+T9Qs454A=\ngithub.com/anacrolix/bargle v0.0.0-20221014000746-4f2739072e9d/go.mod h1:9xUiZbkh+94FbiIAL1HXpAIBa832f3Mp07rRPl5c5RQ=\ngithub.com/anacrolix/chansync v0.4.1-0.20240627045151-1aa1ac392fe8 h1:eyb0bBaQKMOh5Se/Qg54shijc8K4zpQiOjEhKFADkQM=\ngithub.com/anacrolix/chansync v0.4.1-0.20240627045151-1aa1ac392fe8/go.mod h1:DZsatdsdXxD0WiwcGl0nJVwyjCKMDv+knl1q2iBjA2k=\ngithub.com/anacrolix/dht/v2 v2.19.2-0.20221121215055-066ad8494444 h1:8V0K09lrGoeT2KRJNOtspA7q+OMxGwQqK/Ug0IiaaRE=\ngithub.com/anacrolix/dht/v2 v2.19.2-0.20221121215055-066ad8494444/go.mod h1:MctKM1HS5YYDb3F30NGJxLE+QPuqWoT5ReW/4jt8xew=\ngithub.com/anacrolix/envpprof v0.0.0-20180404065416-323002cec2fa/go.mod h1:KgHhUaQMc8cC0+cEflSgCFNFbKwi5h54gqtVn8yhP7c=\ngithub.com/anacrolix/envpprof v1.0.0/go.mod h1:KgHhUaQMc8cC0+cEflSgCFNFbKwi5h54gqtVn8yhP7c=\ngithub.com/anacrolix/envpprof v1.1.0/go.mod h1:My7T5oSqVfEn4MD4Meczkw/f5lSIndGAKu/0SM/rkf4=\ngithub.com/anacrolix/envpprof v1.3.0 h1:WJt9bpuT7A/CDCxPOv/eeZqHWlle/Y0keJUvc6tcJDk=\ngithub.com/anacrolix/envpprof v1.3.0/go.mod h1:7QIG4CaX1uexQ3tqd5+BRa/9e2D02Wcertl6Yh0jCB0=\ngithub.com/anacrolix/fuse v0.2.0 h1:pc+To78kI2d/WUjIyrsdqeJQAesuwpGxlI3h1nAv3Do=\ngithub.com/anacrolix/fuse v0.2.0/go.mod h1:Kfu02xBwnySDpH3N23BmrP3MDfwAQGRLUCj6XyeOvBQ=\ngithub.com/anacrolix/generics v0.0.0-20230113004304-d6428d516633/go.mod h1:ff2rHB/joTV03aMSSn/AZNnaIpUw0h3njetGsaXcMy8=\ngithub.com/anacrolix/generics v0.0.3-0.20240902042256-7fb2702ef0ca h1:aiiGqSQWjtVNdi8zUMfA//IrM8fPkv2bWwZVPbDe0wg=\ngithub.com/anacrolix/generics v0.0.3-0.20240902042256-7fb2702ef0ca/go.mod h1:MN3ve08Z3zSV/rTuX/ouI4lNdlfTxgdafQJiLzyNRB8=\ngithub.com/anacrolix/go-libutp v1.3.1 h1:idJzreNLl+hNjGC3ZnUOjujEaryeOGgkwHLqSGoige0=\ngithub.com/anacrolix/go-libutp v1.3.1/go.mod h1:heF41EC8kN0qCLMokLBVkB8NXiLwx3t8R8810MTNI5o=\ngithub.com/anacrolix/gostdapp v0.1.0 h1:sZC+gSLhA7Hdalak5rPCkhO0YSEl0tt/lsovxh6qka4=\ngithub.com/anacrolix/gostdapp v0.1.0/go.mod h1:2pstbgWcpBCY3rFUldM0NbDCrP86vWsh61wj8yY517E=\ngithub.com/anacrolix/log v0.3.0/go.mod h1:lWvLTqzAnCWPJA08T2HCstZi0L1y2Wyvm3FJgwU9jwU=\ngithub.com/anacrolix/log v0.6.0/go.mod h1:lWvLTqzAnCWPJA08T2HCstZi0L1y2Wyvm3FJgwU9jwU=\ngithub.com/anacrolix/log v0.13.1/go.mod h1:D4+CvN8SnruK6zIFS/xPoRJmtvtnxs+CSfDQ+BFxZ68=\ngithub.com/anacrolix/log v0.14.2/go.mod h1:1OmJESOtxQGNMlUO5rcv96Vpp9mfMqXXbe2RdinFLdY=\ngithub.com/anacrolix/log v0.15.3-0.20240627045001-cd912c641d83 h1:9o/yVzzLzYaBDFx8B27yhkvBLhNnRAuSTK7Y+yZKVtU=\ngithub.com/anacrolix/log v0.15.3-0.20240627045001-cd912c641d83/go.mod h1:xvHjsYWWP7yO8PZwtuIp/k0DBlu07pSJqH4SEC78Vwc=\ngithub.com/anacrolix/lsan v0.0.0-20211126052245-807000409a62 h1:P04VG6Td13FHMgS5ZBcJX23NPC/fiC4cp9bXwYujdYM=\ngithub.com/anacrolix/lsan v0.0.0-20211126052245-807000409a62/go.mod h1:66cFKPCO7Sl4vbFnAaSq7e4OXtdMhRSBagJGWgmpJbM=\ngithub.com/anacrolix/missinggo v0.0.0-20180725070939-60ef2fbf63df/go.mod h1:kwGiTUTZ0+p4vAz3VbAI5a30t2YbvemcmspjKwrAz5s=\ngithub.com/anacrolix/missinggo v1.1.0/go.mod h1:MBJu3Sk/k3ZfGYcS7z18gwfu72Ey/xopPFJJbTi5yIo=\ngithub.com/anacrolix/missinggo v1.1.2-0.20190815015349-b888af804467/go.mod h1:MBJu3Sk/k3ZfGYcS7z18gwfu72Ey/xopPFJJbTi5yIo=\ngithub.com/anacrolix/missinggo v1.2.1/go.mod h1:J5cMhif8jPmFoC3+Uvob3OXXNIhOUikzMt+uUjeM21Y=\ngithub.com/anacrolix/missinggo v1.3.0 h1:06HlMsudotL7BAELRZs0yDZ4yVXsHXGi323QBjAVASw=\ngithub.com/anacrolix/missinggo v1.3.0/go.mod h1:bqHm8cE8xr+15uVfMG3BFui/TxyB6//H5fwlq/TeqMc=\ngithub.com/anacrolix/missinggo/perf v1.0.0 h1:7ZOGYziGEBytW49+KmYGTaNfnwUqP1HBsy6BqESAJVw=\ngithub.com/anacrolix/missinggo/perf v1.0.0/go.mod h1:ljAFWkBuzkO12MQclXzZrosP5urunoLS0Cbvb4V0uMQ=\ngithub.com/anacrolix/missinggo/v2 v2.2.0/go.mod h1:o0jgJoYOyaoYQ4E2ZMISVa9c88BbUBVQQW4QeRkNCGY=\ngithub.com/anacrolix/missinggo/v2 v2.5.1/go.mod h1:WEjqh2rmKECd0t1VhQkLGTdIWXO6f6NLjp5GlMZ+6FA=\ngithub.com/anacrolix/missinggo/v2 v2.7.4 h1:47h5OXoPV8JbA/ACA+FLwKdYbAinuDO8osc2Cu9xkxg=\ngithub.com/anacrolix/missinggo/v2 v2.7.4/go.mod h1:vVO5FEziQm+NFmJesc7StpkquZk+WJFCaL0Wp//2sa0=\ngithub.com/anacrolix/mmsg v0.0.0-20180515031531-a4a3ba1fc8bb/go.mod h1:x2/ErsYUmT77kezS63+wzZp8E3byYB0gzirM/WMBLfw=\ngithub.com/anacrolix/mmsg v1.0.0 h1:btC7YLjOn29aTUAExJiVUhQOuf/8rhm+/nWCMAnL3Hg=\ngithub.com/anacrolix/mmsg v1.0.0/go.mod h1:x8kRaJY/dCrY9Al0PEcj1mb/uFHwP6GCJ9fLl4thEPc=\ngithub.com/anacrolix/multiless v0.4.0 h1:lqSszHkliMsZd2hsyrDvHOw4AbYWa+ijQ66LzbjqWjM=\ngithub.com/anacrolix/multiless v0.4.0/go.mod h1:zJv1JF9AqdZiHwxqPgjuOZDGWER6nyE48WBCi/OOrMM=\ngithub.com/anacrolix/possum/go v0.1.1-0.20240321122240-a01f3a22f2d1 h1:lINi1HW+PExnMJkECx30AZSt0XT0cng9dVo3Zz5rSRM=\ngithub.com/anacrolix/possum/go v0.1.1-0.20240321122240-a01f3a22f2d1/go.mod h1:pw5HEMBSiL+otYzHe4q5jGaVuy5unl+Mt4Bx6SDemW8=\ngithub.com/anacrolix/squirrel v0.6.4 h1:K6ABRMCms0xwpEIdY3kAaDBUqiUeUYCKLKI0yHTr9IQ=\ngithub.com/anacrolix/squirrel v0.6.4/go.mod h1:0kFVjOLMOKVOet6ja2ac1vTOrqVbLj2zy2Fjp7+dkE8=\ngithub.com/anacrolix/stm v0.2.0/go.mod h1:zoVQRvSiGjGoTmbM0vSLIiaKjWtNPeTvXUSdJQA4hsg=\ngithub.com/anacrolix/stm v0.4.0 h1:tOGvuFwaBjeu1u9X1eIh9TX8OEedEiEQ1se1FjhFnXY=\ngithub.com/anacrolix/stm v0.4.0/go.mod h1:GCkwqWoAsP7RfLW+jw+Z0ovrt2OO7wRzcTtFYMYY5t8=\ngithub.com/anacrolix/sync v0.0.0-20180808010631-44578de4e778/go.mod h1:s735Etp3joe/voe2sdaXLcqDdJSay1O0OPnM0ystjqk=\ngithub.com/anacrolix/sync v0.3.0/go.mod h1:BbecHL6jDSExojhNtgTFSBcdGerzNc64tz3DCOj/I0g=\ngithub.com/anacrolix/sync v0.5.1 h1:FbGju6GqSjzVoTgcXTUKkF041lnZkG5P0C3T5RL3SGc=\ngithub.com/anacrolix/sync v0.5.1/go.mod h1:BbecHL6jDSExojhNtgTFSBcdGerzNc64tz3DCOj/I0g=\ngithub.com/anacrolix/tagflag v0.0.0-20180109131632-2146c8d41bf0/go.mod h1:1m2U/K6ZT+JZG0+bdMK6qauP49QT4wE5pmhJXOKKCHw=\ngithub.com/anacrolix/tagflag v1.0.0/go.mod h1:1m2U/K6ZT+JZG0+bdMK6qauP49QT4wE5pmhJXOKKCHw=\ngithub.com/anacrolix/tagflag v1.1.0/go.mod h1:Scxs9CV10NQatSmbyjqmqmeQNwGzlNe0CMUMIxqHIG8=\ngithub.com/anacrolix/tagflag v1.3.0 h1:5NI+9CniDnEH0BWA4UcQbERyFPjKJqZnVkItGVIDy/s=\ngithub.com/anacrolix/tagflag v1.3.0/go.mod h1:Scxs9CV10NQatSmbyjqmqmeQNwGzlNe0CMUMIxqHIG8=\ngithub.com/anacrolix/upnp v0.1.4 h1:+2t2KA6QOhm/49zeNyeVwDu1ZYS9dB9wfxyVvh/wk7U=\ngithub.com/anacrolix/upnp v0.1.4/go.mod h1:Qyhbqo69gwNWvEk1xNTXsS5j7hMHef9hdr984+9fIic=\ngithub.com/anacrolix/utp v0.1.0 h1:FOpQOmIwYsnENnz7tAGohA+r6iXpRjrq8ssKSre2Cp4=\ngithub.com/anacrolix/utp v0.1.0/go.mod h1:MDwc+vsGEq7RMw6lr2GKOEqjWny5hO5OZXRVNaBJ2Dk=\ngithub.com/antihax/optional v1.0.0/go.mod h1:uupD/76wgC+ih3iEmQUL+0Ugr19nfwCT1kdvxnR2qWY=\ngithub.com/apache/thrift v0.12.0/go.mod h1:cp2SuWMxlEZw2r+iP2GNCdIi4C1qmUzdZFSVb+bacwQ=\ngithub.com/bahlo/generic-list-go v0.2.0 h1:5sz/EEAK+ls5wF+NeqDpk5+iNdMDXrh3z3nPnH1Wvgk=\ngithub.com/bahlo/generic-list-go v0.2.0/go.mod h1:2KvAjgMlE5NNynlg/5iLrrCCZ2+5xWbdbCW3pNTGyYg=\ngithub.com/benbjohnson/immutable v0.2.0/go.mod h1:uc6OHo6PN2++n98KHLxW8ef4W42ylHiQSENghE1ezxI=\ngithub.com/benbjohnson/immutable v0.3.0 h1:TVRhuZx2wG9SZ0LRdqlbs9S5BZ6Y24hJEHTCgWHZEIw=\ngithub.com/benbjohnson/immutable v0.3.0/go.mod h1:uc6OHo6PN2++n98KHLxW8ef4W42ylHiQSENghE1ezxI=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/bits-and-blooms/bitset v1.2.0/go.mod h1:gIdJ4wp64HaoK2YrL1Q5/N7Y16edYb8uY+O0FJTyyDA=\ngithub.com/bits-and-blooms/bitset v1.2.2 h1:J5gbX05GpMdBjCvQ9MteIg2KKDExr7DrgK+Yc15FvIk=\ngithub.com/bits-and-blooms/bitset v1.2.2/go.mod h1:gIdJ4wp64HaoK2YrL1Q5/N7Y16edYb8uY+O0FJTyyDA=\ngithub.com/bradfitz/iter v0.0.0-20140124041915-454541ec3da2/go.mod h1:PyRFw1Lt2wKX4ZVSQ2mk+PeDa1rxyObEDlApuIsUKuo=\ngithub.com/bradfitz/iter v0.0.0-20190303215204-33e6a9893b0c/go.mod h1:PyRFw1Lt2wKX4ZVSQ2mk+PeDa1rxyObEDlApuIsUKuo=\ngithub.com/bradfitz/iter v0.0.0-20191230175014-e8f45d346db8 h1:GKTyiRCL6zVf5wWaqKnf+7Qs6GbEPfd4iMOitWzXJx8=\ngithub.com/bradfitz/iter v0.0.0-20191230175014-e8f45d346db8/go.mod h1:spo1JLcs67NmW1aVLEgtA8Yy1elc+X8y5SRW1sFW4Og=\ngithub.com/cenkalti/backoff/v4 v4.1.3 h1:cFAlzYUlVYDysBEH2T5hyJZMh3+5+WCBvSnK6Q8UtC4=\ngithub.com/cenkalti/backoff/v4 v4.1.3/go.mod h1:scbssz8iZGpm3xbr14ovlUdkxfGXNInqkPWOWmG2CLw=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash v1.1.0 h1:a6HrQnmkObjyL+Gs60czilIUGqrzKutQD6XZog3p+ko=\ngithub.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=\ngithub.com/cespare/xxhash/v2 v2.1.1/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cespare/xxhash/v2 v2.1.2/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\ngithub.com/cncf/udpa/go v0.0.0-20201120205902-5459f2c99403/go.mod h1:WmhPx2Nbnhtbo57+VJT5O0JRkEi1Wbu0z5j0R8u5Hbk=\ngithub.com/cncf/udpa/go v0.0.0-20210930031921-04548b0d99d4/go.mod h1:6pvJx4me5XPnfI9Z40ddWsdw2W/uZgQLFXToKeRcDiI=\ngithub.com/cncf/xds/go v0.0.0-20210312221358-fbca930ec8ed/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cncf/xds/go v0.0.0-20210805033703-aa0b78936158/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cncf/xds/go v0.0.0-20210922020428-25de7278fc84/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cncf/xds/go v0.0.0-20211011173535-cb28da3451f1/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/docopt/docopt-go v0.0.0-20180111231733-ee0de3bc6815/go.mod h1:WwZ+bS3ebgob9U8Nd0kOddGdZWjyMGR8Wziv+TBNwSE=\ngithub.com/dustin/go-humanize v0.0.0-20180421182945-02af3965c54e/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/dustin/go-humanize v1.0.0 h1:VSnTsYCnlFHaM2/igO1h6X3HA71jcobQuxemgkq4zYo=\ngithub.com/dustin/go-humanize v1.0.0/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/dvyukov/go-fuzz v0.0.0-20200318091601-be3528f3a813/go.mod h1:11Gm+ccJnvAhCNLlf5+cS9KjtbaD5I5zaZpFMsTHWTw=\ngithub.com/eapache/go-resiliency v1.1.0/go.mod h1:kFI+JgMyC7bLPUVY133qvEBtVayf5mFgVsvEsIPBvNs=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20180814174437-776d5712da21/go.mod h1:+020luEh2TKB4/GOp8oxxtq0Daoen/Cii55CzbTV6DU=\ngithub.com/eapache/queue v1.1.0/go.mod h1:6eCeP0CKFpHLu8blIFXhExK/dRa7WDZfr6jVFPTqq+I=\ngithub.com/edsrzf/mmap-go v1.1.0 h1:6EUwBLQ/Mcr1EYLE4Tn1VdW1A4ckqCQWZBw8Hr0kjpQ=\ngithub.com/edsrzf/mmap-go v1.1.0/go.mod h1:19H/e8pUPLicwkyNgOykDXkJ9F0MHE+Z52B8EIth78Q=\ngithub.com/elazarl/go-bindata-assetfs v1.0.0/go.mod h1:v+YaWX3bdea5J/mo8dSETolEo7R71Vk1u8bnjau5yw4=\ngithub.com/elliotchance/orderedmap v1.4.0 h1:wZtfeEONCbx6in1CZyE6bELEt/vFayMvsxqI5SgsR+A=\ngithub.com/elliotchance/orderedmap v1.4.0/go.mod h1:wsDwEaX5jEoyhbs7x93zk2H/qv0zwuhg4inXhDkYqys=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.4/go.mod h1:6rpuAdCZL397s3pYoYcLgu1mIlRU8Am5FuJP05cCM98=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20201210154907-fd9021fe5dad/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210512163311-63b5d3c536b0/go.mod h1:hliV/p42l8fGbc6Y9bQ70uLwIvmJyVE5k4iMKlh8wCQ=\ngithub.com/envoyproxy/go-control-plane v0.9.10-0.20210907150352-cf90f659a021/go.mod h1:AFq3mo9L8Lqqiid3OhADV3RfLJnjiw63cSpi+fDTRC0=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/frankban/quicktest v1.9.0/go.mod h1:ui7WezCLWMWxVWr1GETZY3smRy0G4KWq9vcPtJmFl7Y=\ngithub.com/frankban/quicktest v1.14.4/go.mod h1:4ptaffx2x8+WTWXmUCuVU6aPUX1/Mz7zb5vbUoiM6w0=\ngithub.com/frankban/quicktest v1.14.6 h1:7Xjx+VpznH+oBnejlPUj8oUpdxnVs4f8XU8WnHkI4W8=\ngithub.com/frankban/quicktest v1.14.6/go.mod h1:4ptaffx2x8+WTWXmUCuVU6aPUX1/Mz7zb5vbUoiM6w0=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.5.4 h1:jRbGcIw6P2Meqdwuo0H1p6JVLbL5DHKAKlYndzMwVZI=\ngithub.com/fsnotify/fsnotify v1.5.4/go.mod h1:OVB6XrOHzAwXMpEM7uPOzcehqUV2UqJxmVXmkdnm1bU=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20180323001048-9f0cb55181dd/go.mod h1:/20jfyN9Y5QPEAprSgKAUr+glWDY39ZiUEAYOEv5dsE=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20181221182339-f9677308dec2/go.mod h1:/20jfyN9Y5QPEAprSgKAUr+glWDY39ZiUEAYOEv5dsE=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20190901134440-81cf024a9e0a/go.mod h1:/20jfyN9Y5QPEAprSgKAUr+glWDY39ZiUEAYOEv5dsE=\ngithub.com/glycerine/goconvey v0.0.0-20180728074245-46e3a41ad493/go.mod h1:Ogl1Tioa0aV7gstGFO7KhffUsb9M4ydbEbbxpcEDc24=\ngithub.com/glycerine/goconvey v0.0.0-20190315024820-982ee783a72e/go.mod h1:Ogl1Tioa0aV7gstGFO7KhffUsb9M4ydbEbbxpcEDc24=\ngithub.com/glycerine/goconvey v0.0.0-20190410193231-58a59202ab31/go.mod h1:Ogl1Tioa0aV7gstGFO7KhffUsb9M4ydbEbbxpcEDc24=\ngithub.com/go-gl/glfw v0.0.0-20190409004039-e6da0acd62b1/go.mod h1:vR7hzQXu2zJy9AVAgeJqvqgH9Q5CA+iKCZ2gyEVpxRU=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20191125211704-12ad95a8df72/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20200222043503-6f7a984d4dc4/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.9.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/log v0.1.0/go.mod h1:zbhenjAZHb184qTLMA9ZjW7ThYL0H2mk7Q6pNt4vbaY=\ngithub.com/go-kit/log v0.2.0/go.mod h1:NwTd00d/i8cPZ3xOwwiv2PO5MOcx78fFErGNcVmBjv0=\ngithub.com/go-llsqlite/adapter v0.0.0-20230927005056-7f5ce7f0c916 h1:OyQmpAN302wAopDgwVjgs2HkFawP9ahIEqkUYz7V7CA=\ngithub.com/go-llsqlite/adapter v0.0.0-20230927005056-7f5ce7f0c916/go.mod h1:DADrR88ONKPPeSGjFp5iEN55Arx3fi2qXZeKCYDpbmU=\ngithub.com/go-llsqlite/crawshaw v0.5.2-0.20240425034140-f30eb7704568 h1:3EpZo8LxIzF4q3BT+vttQQlRfA6uTtTb/cxVisWa5HM=\ngithub.com/go-llsqlite/crawshaw v0.5.2-0.20240425034140-f30eb7704568/go.mod h1:/YJdV7uBQaYDE0fwe4z3wwJIZBJxdYzd38ICggWqtaE=\ngithub.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=\ngithub.com/go-logfmt/logfmt v0.4.0/go.mod h1:3RMwSq7FuexP4Kalkev3ejPJsZTpXXBr9+V4qmtdjCk=\ngithub.com/go-logfmt/logfmt v0.5.0/go.mod h1:wCYkCAKZfumFQihp8CzCvQ3paCTfi41vtzG1KdI/P7A=\ngithub.com/go-logfmt/logfmt v0.5.1/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.2.3 h1:2DntVwHkVopvECVRSlL5PSo9eG+cAkDCuckLubN+rq0=\ngithub.com/go-logr/logr v1.2.3/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-ole/go-ole v1.2.6 h1:/Fpf6oFPoeFik9ty7siob0G6Ke8QvQEuVcuChpwXzpY=\ngithub.com/go-ole/go-ole v1.2.6/go.mod h1:pprOEPIfldk/42T2oK7lQ4v4JSDwmV0As9GaiUsvbm0=\ngithub.com/go-quicktest/qt v1.101.0 h1:O1K29Txy5P2OK0dGo59b7b0LR6wKfIhttaAhHUyn7eI=\ngithub.com/go-quicktest/qt v1.101.0/go.mod h1:14Bz/f7NwaXPtdYEgzsx46kqSxVwTbzVZsDC26tQJow=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/gogo/protobuf v1.2.0/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/glog v1.0.0/go.mod h1:EWib/APOK0SL3dFbYqvxE3UYd8E6s1ouQ7iEp/0LWV4=\ngithub.com/golang/glog v1.1.0 h1:/d3pCKDPWNnvIWe0vVUpNP32qc8U3PDVxySP/y360qE=\ngithub.com/golang/glog v1.1.0/go.mod h1:pfYeQZ3JWZoXTV5sFc986z3HTpwQs9At6P4ImfuP3NQ=\ngithub.com/golang/groupcache v0.0.0-20190702054246-869f871628b6/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.3.1/go.mod h1:sBzyDLLjw3U8JLTeZvSv8jJB+tU5PVekmnlKIyFUx0Y=\ngithub.com/golang/mock v1.4.0/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.1/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.3/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.4/go.mod h1:l3mdAwkq5BuhzHwde/uurv3sEJeZMXNpwsxVWU71h+4=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.4/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.5/go.mod h1:6O5/vntMXwX2lRkT1hjjk0nAC1IDOTvTlVgjlRvqsdk=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.4.3/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/protobuf v1.5.3 h1:KhyjKVUg7Usr/dYsdSqoFveMYd5ko72D+zANwlG1mmg=\ngithub.com/golang/protobuf v1.5.3/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/snappy v0.0.0-20180518054509-2e65f85255db/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.1/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/btree v0.0.0-20180124185431-e89373fe6b4a/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.1.2 h1:xf4v41cLI2Z6FxbKm+8Bu+m8ifhj15JuZ9sa0jZCMUU=\ngithub.com/google/btree v1.1.2/go.mod h1:qOPhT0dTNdNzV6Z/lhRX0YXUafgPLFUh+gZMl761Gm4=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.4.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.4/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.6/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/martian/v3 v3.0.0/go.mod h1:y5Zk1BBys9G+gd6Jrk0W3cC1+ELVxBWuIGO+w/tUAp0=\ngithub.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20190515194954-54271f7e092f/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20191218002539-d4f498aebedc/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200212024743-f11f1df84d12/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200229191704-1ebb73c60ed3/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200430221834-fc25d7d30c6d/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200708004538-1a94d8640e99/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=\ngithub.com/google/uuid v1.1.2/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/googleapis/gax-go/v2 v2.0.4/go.mod h1:0Wqv26UfaUD9n4G6kQubkQ+KchISgw+vpHVxEJEs9eg=\ngithub.com/googleapis/gax-go/v2 v2.0.5/go.mod h1:DWXyrwAJ9X0FpwwEdw+IPEYBICEFu5mhpdKc/us6bOk=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gopherjs/gopherjs v0.0.0-20181103185306-d547d1d9531e/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gopherjs/gopherjs v0.0.0-20190309154008-847fc94819f9/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gopherjs/gopherjs v0.0.0-20190910122728-9d188e94fb99/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gorilla/context v1.1.1/go.mod h1:kBGZzfjB9CEq2AlWe17Uuf7NDRt0dE0s8S51q0aT7Yg=\ngithub.com/gorilla/mux v1.6.2/go.mod h1:1lud6UwP+6orDFRuTfBEV8e9/aOM/c4fVVCaMa2zaAs=\ngithub.com/gorilla/websocket v1.5.0 h1:PPwGk2jz7EePpoHN/+ClbZu8SPxiqlu12wZP/3sWmnc=\ngithub.com/gorilla/websocket v1.5.0/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0/go.mod h1:BDjrQk3hbvj6Nolgz8mAMFbcEtjT1g+wF4CSlocrBnw=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.7.0/go.mod h1:hgWBS7lorOAVIJEQMi4ZsPv9hVvWI6+ch50m39Pf2Ks=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.12.0 h1:kr3j8iIMR4ywO/O0rvksXaJvauGGCMg2zAZIiNZ9uIQ=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.12.0/go.mod h1:ummNFgdgLhhX7aIiy35vVmQNS0rWXknfPE0qe6fmFXg=\ngithub.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.1/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hexops/gotextdiff v1.0.3 h1:gitA9+qJrrTCsiCl7+kh75nPqQt1cx4ZkudSTLoUqJM=\ngithub.com/hexops/gotextdiff v1.0.3/go.mod h1:pSWU5MAI3yDq+fZBTazCSJysOMbxWL1BSow5/V2vxeg=\ngithub.com/honeycombio/honeycomb-opentelemetry-go v0.3.0 h1:3qotL5cFNAiuLk/YZsUGNmz9ywnXqGP9hGFQoNo5PdA=\ngithub.com/honeycombio/honeycomb-opentelemetry-go v0.3.0/go.mod h1:qzzIv/RAGWhyRgyRwwRaxmn5tZMkc/bbTX3zit4sBGI=\ngithub.com/honeycombio/opentelemetry-go-contrib/launcher v0.0.0-20221031150637-a3c60ed98d54 h1:CFyJMKF0jR2dv+3Cpj/GuRa5XBXKnJqiqmWMYifTzok=\ngithub.com/honeycombio/opentelemetry-go-contrib/launcher v0.0.0-20221031150637-a3c60ed98d54/go.mod h1:30UdGSqrIP+QzOGVyFiK6konkG1bQzs342GvLicmmnY=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/huandu/xstrings v1.0.0/go.mod h1:4qWG/gcEcfX4z/mBDHJ++3ReCw9ibxbsNJbcucJdbSo=\ngithub.com/huandu/xstrings v1.2.0/go.mod h1:DvyZB1rfVYsBIigL8HwpZgxHwXozlTgGqn63UyNX5k4=\ngithub.com/huandu/xstrings v1.3.0/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/huandu/xstrings v1.3.1/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/huandu/xstrings v1.3.2 h1:L18LIDzqlW6xN2rEkpdV8+oL/IXWJ1APd+vsdYy4Wdw=\ngithub.com/huandu/xstrings v1.3.2/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/ianlancetaylor/demangle v0.0.0-20181102032728-5e5cf60278f6/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/jessevdk/go-flags v1.5.0 h1:1jKYvbxEjfUl0fmqTCOfonvskHHXMjBySTLW4y9LFvc=\ngithub.com/jessevdk/go-flags v1.5.0/go.mod h1:Fw0T6WPc1dYxT4mKEZRfG5kJhaTDP9pj1c2EWnYs/m4=\ngithub.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=\ngithub.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=\ngithub.com/json-iterator/go v1.1.9/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.10/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.11/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=\ngithub.com/jstemmer/go-junit-report v0.9.1/go.mod h1:Brl9GWCQeLvo8nXZwPNNblvFj/XSXhF0NWZEnDohbsk=\ngithub.com/jtolds/gls v4.2.1+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/julienschmidt/httprouter v1.3.0/go.mod h1:JR6WtHb+2LUe8TCKY3cZOxFyyO8IZAc4RVcycCCAKdM=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/cpuid/v2 v2.0.4/go.mod h1:FInQzS24/EEf25PyTYn52gqo7WaD8xa0213Md/qVLRg=\ngithub.com/klauspost/cpuid/v2 v2.0.9/go.mod h1:FInQzS24/EEf25PyTYn52gqo7WaD8xa0213Md/qVLRg=\ngithub.com/klauspost/cpuid/v2 v2.2.3 h1:sxCkb+qR91z4vsqw4vGGZlDgPz3G7gjaLyK3V8y70BU=\ngithub.com/klauspost/cpuid/v2 v2.2.3/go.mod h1:RVVoqg1df56z8g3pUjL/3lE5UfnlrJX8tyFgg4nqhuY=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.3/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/lufia/plan9stats v0.0.0-20211012122336-39d0f177ccd0/go.mod h1:zJYVVT2jmtg6P3p1VtQj7WsuWi/y4VnjVBn7F8KPB3I=\ngithub.com/lufia/plan9stats v0.0.0-20220913051719-115f729f3c8c h1:VtwQ41oftZwlMnOEbMWQtSEUgU64U4s+GHk7hZK+jtY=\ngithub.com/lufia/plan9stats v0.0.0-20220913051719-115f729f3c8c/go.mod h1:JKx41uQRwqlTZabZc+kILPrO/3jlKnQ2Z8b7YiVw5cE=\ngithub.com/mattn/go-isatty v0.0.16 h1:bq3VjFmv/sOjHtdEhmkEV4x1AJtvUvOJ2PFAZ5+peKQ=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1 h1:4hp9jkHxhMHkqkrB3Ix0jegS5sx/RkqARlsWZ6pIwiU=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/minio/sha256-simd v1.0.0 h1:v1ta+49hkWZyvaKwrQB8elexRqm6Y0aMLjCNsrYxo6g=\ngithub.com/minio/sha256-simd v1.0.0/go.mod h1:OuYzVNI5vcoYIAmbIvHPl3N3jUzVedXbKy5RFepssQM=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v0.0.0-20180701023420-4b7aa43c6742/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/mr-tron/base58 v1.2.0 h1:T/HDJBh4ZCPbU39/+c3rRvE0uKBQlU27+QI8LJ4t64o=\ngithub.com/mr-tron/base58 v1.2.0/go.mod h1:BinMc/sQntlIE1frQmRFPUoPA1Zkr8VRgBdjWI2mNwc=\ngithub.com/mschoch/smat v0.0.0-20160514031455-90eadee771ae/go.mod h1:qAyveg+e4CE+eKJXWVjKXM4ck2QobLqTDytGJbLLhJg=\ngithub.com/mschoch/smat v0.2.0 h1:8imxQsjDm8yFEAVBe7azKmKSgzSkZXDuKkSq9374khM=\ngithub.com/mschoch/smat v0.2.0/go.mod h1:kc9mz7DoBKqDyiRL7VZN8KvXQMWeTaVnttLRXOlotKw=\ngithub.com/multiformats/go-multihash v0.2.3 h1:7Lyc8XfX/IY2jWb/gI7JP+o7JEq9hOa7BFvVU9RSh+U=\ngithub.com/multiformats/go-multihash v0.2.3/go.mod h1:dXgKXCXjBzdscBLk9JkjINiEsCKRVch90MdaGiKsvSM=\ngithub.com/multiformats/go-varint v0.0.6 h1:gk85QWKxh3TazbLxED/NlDVv8+q+ReFJk7Y2W/KhfNY=\ngithub.com/multiformats/go-varint v0.0.6/go.mod h1:3Ls8CIEsrijN6+B7PbrXRPxHRPuXSrVKRY101jdMZYE=\ngithub.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.7.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/gomega v1.4.3/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/openzipkin/zipkin-go v0.1.6/go.mod h1:QgAqvLzwWbR/WpD4A3cGpPtJrZXNIiJc5AZX7/PBEpw=\ngithub.com/philhofer/fwd v1.0.0/go.mod h1:gk3iGcWd9+svBvR0sR+KPcfE+RNWozjowpeBVG3ZVNU=\ngithub.com/pierrec/lz4 v2.0.5+incompatible/go.mod h1:pdkljMzZIN41W+lC3N2tnIh5sFi+IEE17M5jbnwPHcY=\ngithub.com/pion/datachannel v1.5.9 h1:LpIWAOYPyDrXtU+BW7X0Yt/vGtYxtXQ8ql7dFfYUVZA=\ngithub.com/pion/datachannel v1.5.9/go.mod h1:kDUuk4CU4Uxp82NH4LQZbISULkX/HtzKa4P7ldf9izE=\ngithub.com/pion/dtls/v3 v3.0.3 h1:j5ajZbQwff7Z8k3pE3S+rQ4STvKvXUdKsi/07ka+OWM=\ngithub.com/pion/dtls/v3 v3.0.3/go.mod h1:weOTUyIV4z0bQaVzKe8kpaP17+us3yAuiQsEAG1STMU=\ngithub.com/pion/ice/v4 v4.0.2 h1:1JhBRX8iQLi0+TfcavTjPjI6GO41MFn4CeTBX+Y9h5s=\ngithub.com/pion/ice/v4 v4.0.2/go.mod h1:DCdqyzgtsDNYN6/3U8044j3U7qsJ9KFJC92VnOWHvXg=\ngithub.com/pion/interceptor v0.1.37 h1:aRA8Zpab/wE7/c0O3fh1PqY0AJI3fCSEM5lRWJVorwI=\ngithub.com/pion/interceptor v0.1.37/go.mod h1:JzxbJ4umVTlZAf+/utHzNesY8tmRkM2lVmkS82TTj8Y=\ngithub.com/pion/logging v0.2.2 h1:M9+AIj/+pxNsDfAT64+MAVgJO0rsyLnoJKCqf//DoeY=\ngithub.com/pion/logging v0.2.2/go.mod h1:k0/tDVsRCX2Mb2ZEmTqNa7CWsQPc+YYCB7Q+5pahoms=\ngithub.com/pion/mdns/v2 v2.0.7 h1:c9kM8ewCgjslaAmicYMFQIde2H9/lrZpjBkN8VwoVtM=\ngithub.com/pion/mdns/v2 v2.0.7/go.mod h1:vAdSYNAT0Jy3Ru0zl2YiW3Rm/fJCwIeM0nToenfOJKA=\ngithub.com/pion/randutil v0.1.0 h1:CFG1UdESneORglEsnimhUjf33Rwjubwj6xfiOXBa3mA=\ngithub.com/pion/randutil v0.1.0/go.mod h1:XcJrSMMbbMRhASFVOlj/5hQial/Y8oH/HVo7TBZq+j8=\ngithub.com/pion/rtcp v1.2.14 h1:KCkGV3vJ+4DAJmvP0vaQShsb0xkRfWkO540Gy102KyE=\ngithub.com/pion/rtcp v1.2.14/go.mod h1:sn6qjxvnwyAkkPzPULIbVqSKI5Dv54Rv7VG0kNxh9L4=\ngithub.com/pion/rtp v1.8.9 h1:E2HX740TZKaqdcPmf4pw6ZZuG8u5RlMMt+l3dxeu6Wk=\ngithub.com/pion/rtp v1.8.9/go.mod h1:pBGHaFt/yW7bf1jjWAoUjpSNoDnw98KTMg+jWWvziqU=\ngithub.com/pion/sctp v1.8.33 h1:dSE4wX6uTJBcNm8+YlMg7lw1wqyKHggsP5uKbdj+NZw=\ngithub.com/pion/sctp v1.8.33/go.mod h1:beTnqSzewI53KWoG3nqB282oDMGrhNxBdb+JZnkCwRM=\ngithub.com/pion/sdp/v3 v3.0.9 h1:pX++dCHoHUwq43kuwf3PyJfHlwIj4hXA7Vrifiq0IJY=\ngithub.com/pion/sdp/v3 v3.0.9/go.mod h1:B5xmvENq5IXJimIO4zfp6LAe1fD9N+kFv+V/1lOdz8M=\ngithub.com/pion/srtp/v3 v3.0.4 h1:2Z6vDVxzrX3UHEgrUyIGM4rRouoC7v+NiF1IHtp9B5M=\ngithub.com/pion/srtp/v3 v3.0.4/go.mod h1:1Jx3FwDoxpRaTh1oRV8A/6G1BnFL+QI82eK4ms8EEJQ=\ngithub.com/pion/stun/v3 v3.0.0 h1:4h1gwhWLWuZWOJIJR9s2ferRO+W3zA/b6ijOI6mKzUw=\ngithub.com/pion/stun/v3 v3.0.0/go.mod h1:HvCN8txt8mwi4FBvS3EmDghW6aQJ24T+y+1TKjB5jyU=\ngithub.com/pion/transport/v3 v3.0.7 h1:iRbMH05BzSNwhILHoBoAPxoB9xQgOaJk+591KC9P1o0=\ngithub.com/pion/transport/v3 v3.0.7/go.mod h1:YleKiTZ4vqNxVwh77Z0zytYi7rXHl7j6uPLGhhz9rwo=\ngithub.com/pion/turn/v4 v4.0.0 h1:qxplo3Rxa9Yg1xXDxxH8xaqcyGUtbHYw4QSCvmFWvhM=\ngithub.com/pion/turn/v4 v4.0.0/go.mod h1:MuPDkm15nYSklKpN8vWJ9W2M0PlyQZqYt1McGuxG7mA=\ngithub.com/pion/webrtc/v4 v4.0.0 h1:x8ec7uJQPP3D1iI8ojPAiTOylPI7Fa7QgqZrhpLyqZ8=\ngithub.com/pion/webrtc/v4 v4.0.0/go.mod h1:SfNn8CcFxR6OUVjLXVslAQ3a3994JhyE3Hw1jAuqEto=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/power-devops/perfstat v0.0.0-20210106213030-5aafc221ea8c/go.mod h1:OmDBASR4679mdNQnz2pUhc2G8CO2JrUAVFDRBDP/hJE=\ngithub.com/power-devops/perfstat v0.0.0-20220216144756-c35f1ee13d7c h1:NRoLoZvkBTKvR5gQLgA3e0hqjkY9u1wm+iOL45VN/qI=\ngithub.com/power-devops/perfstat v0.0.0-20220216144756-c35f1ee13d7c/go.mod h1:OmDBASR4679mdNQnz2pUhc2G8CO2JrUAVFDRBDP/hJE=\ngithub.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v0.9.3-0.20190127221311-3c4408c8b829/go.mod h1:p2iRAGwDERtqlqzRXnrOVns+ignqQo//hLXqYxZYVNs=\ngithub.com/prometheus/client_golang v1.0.0/go.mod h1:db9x61etRT2tGnBNRi70OPL5FsnadC4Ky3P0J6CfImo=\ngithub.com/prometheus/client_golang v1.5.1/go.mod h1:e9GMxYsXl05ICDXkRhurwBS4Q3OK1iX/F2sw+iXX5zU=\ngithub.com/prometheus/client_golang v1.7.1/go.mod h1:PY5Wy2awLA44sXw4AOSfFBetzPP4j5+D6mVACh+pe2M=\ngithub.com/prometheus/client_golang v1.11.0/go.mod h1:Z6t4BnS23TR94PD6BsDNk8yVqroYurpAkEiz0P2BEV0=\ngithub.com/prometheus/client_golang v1.12.1/go.mod h1:3Z9XVyYiZYEO+YQWt3RD2R3jrbd179Rt297l4aS6nDY=\ngithub.com/prometheus/client_golang v1.12.2 h1:51L9cDoUHVrXx4zWYlcLQIZ+d+VXHgqnYKkIuq4g/34=\ngithub.com/prometheus/client_golang v1.12.2/go.mod h1:3Z9XVyYiZYEO+YQWt3RD2R3jrbd179Rt297l4aS6nDY=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190115171406-56726106282f/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.2.0 h1:uq5h0d+GuxiXLJLNABMgp2qUWDPiLvgCzz2dUR+/W/M=\ngithub.com/prometheus/client_model v0.2.0/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/common v0.2.0/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.4.1/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.9.1/go.mod h1:yhUN8i9wzaXS3w1O07YhxHEBxD+W35wd8bs7vj7HSQ4=\ngithub.com/prometheus/common v0.10.0/go.mod h1:Tlit/dnDKsSWFlCLTWaA1cyBgKHSMdTB80sz/V91rCo=\ngithub.com/prometheus/common v0.26.0/go.mod h1:M7rCNAaPfAosfx8veZJCuw84e35h3Cfd9VFqTh1DIvc=\ngithub.com/prometheus/common v0.32.1/go.mod h1:vu+V0TpY+O6vW9J44gczi3Ap/oXXR10b+M/gUGO4Hls=\ngithub.com/prometheus/common v0.35.0 h1:Eyr+Pw2VymWejHqCugNaQXkAi6KayVNxaHeu6khmFBE=\ngithub.com/prometheus/common v0.35.0/go.mod h1:phzohg0JFMnBEFGxTDbfu3QyL5GI8gTQJFhYO5B3mfA=\ngithub.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.0-20190117184657-bf6a532e95b1/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.2/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.0.8/go.mod h1:7Qr8sr6344vo1JqZ6HhLceV9o3AJ1Ff+GxbHq6oeK9A=\ngithub.com/prometheus/procfs v0.0.11/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=\ngithub.com/prometheus/procfs v0.1.3/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=\ngithub.com/prometheus/procfs v0.6.0/go.mod h1:cz+aTbrPOrUb4q7XlbU9ygM+/jj0fzG6c1xBZuNvfVA=\ngithub.com/prometheus/procfs v0.7.3 h1:4jVXhlkAyzOScmCkXBTOLRLTz8EeU+eyjrwB/EPq0VU=\ngithub.com/prometheus/procfs v0.7.3/go.mod h1:cz+aTbrPOrUb4q7XlbU9ygM+/jj0fzG6c1xBZuNvfVA=\ngithub.com/protolambda/ctxlock v0.1.0 h1:rCUY3+vRdcdZXqT07iXgyr744J2DU2LCBIXowYAjBCE=\ngithub.com/protolambda/ctxlock v0.1.0/go.mod h1:vefhX6rIZH8rsg5ZpOJfEDYQOppZi19SfPiGOFrNnwM=\ngithub.com/rcrowley/go-metrics v0.0.0-20181016184325-3113b8401b8a/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=\ngithub.com/remyoudompheng/bigfft v0.0.0-20200410134404-eec4a21b6bb0/go.mod h1:qqbHyh8v60DhA7CoWK5oRCqLrMHRGoxYCSS9EjAz6Eo=\ngithub.com/remyoudompheng/bigfft v0.0.0-20230129092748-24d4a6f8daec h1:W09IVJc94icq4NjY3clb7Lk8O1qJ8BdBEF8z0ibU0rE=\ngithub.com/remyoudompheng/bigfft v0.0.0-20230129092748-24d4a6f8daec/go.mod h1:qqbHyh8v60DhA7CoWK5oRCqLrMHRGoxYCSS9EjAz6Eo=\ngithub.com/robertkrimen/godocdown v0.0.0-20130622164427-0bfa04905481/go.mod h1:C9WhFzY47SzYBIvzFqSvHIR6ROgDo4TtdTuRaOMjF/s=\ngithub.com/rogpeppe/fastuuid v1.2.0/go.mod h1:jVj6XXZzXRy/MSR5jhDC/2q6DgLz+nrA6LYCDYWNEvQ=\ngithub.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.6.1/go.mod h1:xXDCJY+GAPziupqXw64V24skbSoqbTEfhy4qGm1nDQc=\ngithub.com/rogpeppe/go-internal v1.8.0/go.mod h1:WmiCO8CzOY8rg0OYDC4/i/2WRWAB6poM+XZ2dLUbcbE=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/rogpeppe/go-internal v1.11.0 h1:cWPaGQEPrBb5/AsnsZesgZZ9yb1OQ+GOISoDNXVBh4M=\ngithub.com/rogpeppe/go-internal v1.11.0/go.mod h1:ddIwULY96R17DhadqLgMfk9H9tvdUzkipdSkR5nkCZA=\ngithub.com/rs/dnscache v0.0.0-20211102005908-e0241e321417 h1:Lt9DzQALzHoDwMBGJ6v8ObDPR0dzr2a6sXTB1Fq7IHs=\ngithub.com/rs/dnscache v0.0.0-20211102005908-e0241e321417/go.mod h1:qe5TWALJ8/a1Lqznoc5BDHpYX/8HU60Hm2AwRmqzxqA=\ngithub.com/ryszard/goskiplist v0.0.0-20150312221310-2dfbae5fcf46 h1:GHRpF1pTW19a8tTFrMLUcfWwyC0pnifVo2ClaLq+hP8=\ngithub.com/ryszard/goskiplist v0.0.0-20150312221310-2dfbae5fcf46/go.mod h1:uAQ5PCi+MFsC7HjREoAz1BU+Mq60+05gifQSsHSDG/8=\ngithub.com/sethvargo/go-envconfig v0.8.2 h1:DDUVuG21RMgeB/bn4leclUI/837y6cQCD4w8hb5797k=\ngithub.com/sethvargo/go-envconfig v0.8.2/go.mod h1:Iz1Gy1Sf3T64TQlJSvee81qDhf7YIlt8GMUX6yyNFs0=\ngithub.com/shirou/gopsutil/v3 v3.22.9 h1:yibtJhIVEMcdw+tCTbOPiF1VcsuDeTE4utJ8Dm4c5eA=\ngithub.com/shirou/gopsutil/v3 v3.22.9/go.mod h1:bBYl1kjgEJpWpxeHmLI+dVHWtyAwfcmSBLDsp2TNT8A=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\ngithub.com/sirupsen/logrus v1.6.0/go.mod h1:7uNnSEd1DgxDLC74fIahvMZmmYsHGZGEOFrfsX/uA88=\ngithub.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\ngithub.com/smartystreets/assertions v0.0.0-20190215210624-980c5ac6f3ac/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\ngithub.com/smartystreets/goconvey v0.0.0-20181108003508-044398e4856c/go.mod h1:XDJAKZRPZ1CvBcN2aX5YOUTYGHki24fSF0Iv48Ibg0s=\ngithub.com/smartystreets/goconvey v0.0.0-20190306220146-200a235640ff/go.mod h1:KSQcGKpxUMHk3nbYzs/tIBAM2iDooCn0BmttHOJEbLs=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spaolacci/murmur3 v1.1.0 h1:7c1g84S4BPRrfL5Xrdp6fOJ206sU9y293DDHaoy0bLI=\ngithub.com/spaolacci/murmur3 v1.1.0/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/stephens2424/writerset v1.0.2/go.mod h1:aS2JhsMn6eA7e82oNmW4rfsgAOp9COBTTl8mzkwADnc=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.2.1/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/tidwall/btree v1.6.0 h1:LDZfKfQIBHGHWSwckhXI0RPSXzlo+KYdjK7FWSqOzzg=\ngithub.com/tidwall/btree v1.6.0/go.mod h1:twD9XRA5jj9VUQGELzDO4HPQTNJsoWWfYEL+EUQ2cKY=\ngithub.com/tinylib/msgp v1.0.2/go.mod h1:+d+yLhGm8mzTaHzB+wgMYrodPfmZrzkirds8fDWklFE=\ngithub.com/tinylib/msgp v1.1.0/go.mod h1:+d+yLhGm8mzTaHzB+wgMYrodPfmZrzkirds8fDWklFE=\ngithub.com/tinylib/msgp v1.1.2/go.mod h1:+d+yLhGm8mzTaHzB+wgMYrodPfmZrzkirds8fDWklFE=\ngithub.com/tklauser/go-sysconf v0.3.10 h1:IJ1AZGZRWbY8T5Vfk04D9WOA5WSejdflXxP03OUqALw=\ngithub.com/tklauser/go-sysconf v0.3.10/go.mod h1:C8XykCvCb+Gn0oNCWPIlcb0RuglQTYaQ2hGm7jmxEFk=\ngithub.com/tklauser/numcpus v0.4.0/go.mod h1:1+UI3pD8NW14VMwdgJNJ1ESk2UnwhAnz5hMwiKKqXCQ=\ngithub.com/tklauser/numcpus v0.5.0 h1:ooe7gN0fg6myJ0EKoTAf5hebTZrH52px3New/D9iJ+A=\ngithub.com/tklauser/numcpus v0.5.0/go.mod h1:OGzpTxpcIMNGYQdit2BYL1pvk/dSOaJWjKoflh+RQjo=\ngithub.com/tv42/httpunix v0.0.0-20191220191345-2ba4b9c3382c h1:u6SKchux2yDvFQnDHS3lPnIRmfVJ5Sxy3ao2SIdysLQ=\ngithub.com/tv42/httpunix v0.0.0-20191220191345-2ba4b9c3382c/go.mod h1:hzIxponao9Kjc7aWznkXaL4U4TWaDSs8zcsY4Ka08nM=\ngithub.com/willf/bitset v1.1.9/go.mod h1:RjeCKbqT1RxIR/KWY6phxZiaY1IyutSBfGjNPySAYV4=\ngithub.com/willf/bitset v1.1.10/go.mod h1:RjeCKbqT1RxIR/KWY6phxZiaY1IyutSBfGjNPySAYV4=\ngithub.com/wlynxg/anet v0.0.3 h1:PvR53psxFXstc12jelG6f1Lv4MWqE0tI76/hHGjh9rg=\ngithub.com/wlynxg/anet v0.0.3/go.mod h1:eay5PRQr7fIVAMbTbchTnO9gG65Hg/uYGdc7mguHxoA=\ngithub.com/yuin/goldmark v1.1.25/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.32/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.4.1/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngithub.com/yusufpapurcu/wmi v1.2.2 h1:KBNDSne4vP5mbSWnJbO+51IMOXJB67QiYCSBrubbPRg=\ngithub.com/yusufpapurcu/wmi v1.2.2/go.mod h1:SBZ9tNy3G9/m5Oi98Zks0QjeHVDvuK0qfxQmPyzfmi0=\ngo.etcd.io/bbolt v1.3.6 h1:/ecaJf0sk1l4l6V4awd65v2C3ILy7MSj+s/x1ADCIMU=\ngo.etcd.io/bbolt v1.3.6/go.mod h1:qXsaaIqmgQH0T+OPdb99Bf+PKfBBQVAdyD6TY9G8XM4=\ngo.opencensus.io v0.20.1/go.mod h1:6WKK9ahsWS3RSO+PY9ZHZUfv2irvY6gN279GOPZjmmk=\ngo.opencensus.io v0.20.2/go.mod h1:6WKK9ahsWS3RSO+PY9ZHZUfv2irvY6gN279GOPZjmmk=\ngo.opencensus.io v0.21.0/go.mod h1:mSImk1erAIZhrmZN+AvHh14ztQfjbGwt4TtuofqLduU=\ngo.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\ngo.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.4/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opentelemetry.io/contrib/instrumentation/host v0.36.4 h1:2D0q/69KewnkCkOI9I9uXgi1XQXvwQIfMebMcPft0no=\ngo.opentelemetry.io/contrib/instrumentation/host v0.36.4/go.mod h1:IQdse+GFHec/g2M4wtj6cE4uA5PJGQjjXP/602LjHBQ=\ngo.opentelemetry.io/contrib/instrumentation/runtime v0.36.4 h1:7AY5NdRzyU5s1ek3E4VK3FBnPtQ6La1i7sIn9hNgjsk=\ngo.opentelemetry.io/contrib/instrumentation/runtime v0.36.4/go.mod h1:yFSLOnffweT7Es+IzY1DF5KP0xa2Wl15SJfKqAyDXq8=\ngo.opentelemetry.io/contrib/propagators/b3 v1.11.1 h1:icQ6ttRV+r/2fnU46BIo/g/mPu6Rs5Ug8Rtohe3KqzI=\ngo.opentelemetry.io/contrib/propagators/b3 v1.11.1/go.mod h1:ECIveyMXgnl4gorxFcA7RYjJY/Ql9n20ubhbfDc3QfA=\ngo.opentelemetry.io/contrib/propagators/ot v1.11.1 h1:iezQwYW2sAaXwbXXA6Zg+PLjNnzc+M4hLKvOR6Q/CvI=\ngo.opentelemetry.io/contrib/propagators/ot v1.11.1/go.mod h1:oBced35DewKV7xvvIWC/oCaCFvthvTa6zjyvP2JhPAY=\ngo.opentelemetry.io/otel v1.11.1 h1:4WLLAmcfkmDk2ukNXJyq3/kiz/3UzCaYq6PskJsaou4=\ngo.opentelemetry.io/otel v1.11.1/go.mod h1:1nNhXBbWSD0nsL38H6btgnFN2k4i0sNLHNNMZMSbUGE=\ngo.opentelemetry.io/otel/exporters/otlp/internal/retry v1.11.1 h1:X2GndnMCsUPh6CiY2a+frAbNsXaPLbB0soHRYhAZ5Ig=\ngo.opentelemetry.io/otel/exporters/otlp/internal/retry v1.11.1/go.mod h1:i8vjiSzbiUC7wOQplijSXMYUpNM93DtlS5CbUT+C6oQ=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric v0.33.0 h1:OT/UjHcjog4A1s1UMCtyehIKS+vpjM5Du0r7KGsH6TE=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric v0.33.0/go.mod h1:0XctNDHEWmiSDIU8NPbJElrK05gBJFcYlGP4FMGo4g4=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v0.33.0 h1:1SVtGtRsNyGgv1fRfNXfh+sJowIwzF0gkf+61lvTgdg=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v0.33.0/go.mod h1:ryB27ubOBXsiqfh6MwtSdx5knzbSZtjvPnMMmt3AykQ=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v0.33.0 h1:NoG4v01cdLZfOeNGBQmSe4f4SeP+fx8I/0qzRgTKsGI=\ngo.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v0.33.0/go.mod h1:6anbDXBcTp3Qit87pfFmT0paxTJ8sWRccTNYVywN/H8=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.11.1 h1:MEQNafcNCB0uQIti/oHgU7CZpUMYQ7qigBwMVKycHvc=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.11.1/go.mod h1:19O5I2U5iys38SsmT2uDJja/300woyzE1KPIQxEUBUc=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.11.1 h1:LYyG/f1W/jzAix16jbksJfMQFpOH/Ma6T639pVPMgfI=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.11.1/go.mod h1:QrRRQiY3kzAoYPNLP0W/Ikg0gR6V3LMc+ODSxr7yyvg=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.11.1 h1:tFl63cpAAcD9TOU6U8kZU7KyXuSRYAZlbx1C61aaB74=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.11.1/go.mod h1:X620Jww3RajCJXw/unA+8IRTgxkdS7pi+ZwK9b7KUJk=\ngo.opentelemetry.io/otel/exporters/stdout/stdouttrace v1.11.1 h1:3Yvzs7lgOw8MmbxmLRsQGwYdCubFmUHSooKaEhQunFQ=\ngo.opentelemetry.io/otel/exporters/stdout/stdouttrace v1.11.1/go.mod h1:pyHDt0YlyuENkD2VwHsiRDf+5DfI3EH7pfhUYW6sQUE=\ngo.opentelemetry.io/otel/metric v0.33.0 h1:xQAyl7uGEYvrLAiV/09iTJlp1pZnQ9Wl793qbVvED1E=\ngo.opentelemetry.io/otel/metric v0.33.0/go.mod h1:QlTYc+EnYNq/M2mNk1qDDMRLpqCOj2f/r5c7Fd5FYaI=\ngo.opentelemetry.io/otel/sdk v1.11.1 h1:F7KmQgoHljhUuJyA+9BiU+EkJfyX5nVVF4wyzWZpKxs=\ngo.opentelemetry.io/otel/sdk v1.11.1/go.mod h1:/l3FE4SupHJ12TduVjUkZtlfFqDCQJlOlithYrdktys=\ngo.opentelemetry.io/otel/sdk/metric v0.33.0 h1:oTqyWfksgKoJmbrs2q7O7ahkJzt+Ipekihf8vhpa9qo=\ngo.opentelemetry.io/otel/sdk/metric v0.33.0/go.mod h1:xdypMeA21JBOvjjzDUtD0kzIcHO/SPez+a8HOzJPGp0=\ngo.opentelemetry.io/otel/trace v1.11.1 h1:ofxdnzsNrGBYXbP7t7zpUK281+go5rF7dvdIZXF8gdQ=\ngo.opentelemetry.io/otel/trace v1.11.1/go.mod h1:f/Q9G7vzk5u91PhbmKbg1Qn0rzH1LJ4vbPHFGkTPtOk=\ngo.opentelemetry.io/proto/otlp v0.7.0/go.mod h1:PqfVotwruBrMGOCsRd/89rSnXhoiJIqeYNgFYFoEGnI=\ngo.opentelemetry.io/proto/otlp v0.19.0 h1:IVN6GR+mhC4s5yfcTbmzHYODqvWAp3ZedA2SJPI1Nnw=\ngo.opentelemetry.io/proto/otlp v0.19.0/go.mod h1:H7XAot3MsfNsj7EXtrA2q5xSNQ10UqI405h3+duxN4U=\ngo.uber.org/atomic v1.7.0/go.mod h1:fEN4uk6kAWBTFdckzkM89CLk9XfWZrxpCo0nPH17wJc=\ngo.uber.org/atomic v1.10.0 h1:9qC72Qh0+3MqyJbAn8YU5xVq1frD8bn3JtD2oXtafVQ=\ngo.uber.org/atomic v1.10.0/go.mod h1:LUxbIzbOniOlMKjJjyPfpl4v+PKK2cNJn91OQbhoJI0=\ngo.uber.org/goleak v1.2.0 h1:xqgm/S+aQvhWFTtR0XK3Jvg7z8kGV8P4X14IzwN3Eqk=\ngo.uber.org/goleak v1.2.0/go.mod h1:XJYK+MuIchqpmGmUSAzotztawfKvYLUIgg7guXrwVUo=\ngo.uber.org/multierr v1.8.0 h1:dg6GjLku4EH+249NNmoIciG9N/jURbDG+pFlTkhzIC8=\ngo.uber.org/multierr v1.8.0/go.mod h1:7EAYxJLBy9rStEaz58O2t4Uvip6FSURkq8/ppBp95ak=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.28.0 h1:GBDwsMXVQi34v5CCYUm2jkJvu4cbtru2U4TN2PSyQnw=\ngolang.org/x/crypto v0.28.0/go.mod h1:rmgy+3RHxRZMyY0jjAJShp2zgEdOqj2AO7U0pYmeQ7U=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\ngolang.org/x/exp v0.0.0-20190829153037-c13cbed26979/go.mod h1:86+5VVa7VpoJ4kLfm080zCjGlMRFzhUhsZKEZO7MGek=\ngolang.org/x/exp v0.0.0-20191030013958-a1ab85dbe136/go.mod h1:JXzH8nQsPlswgeRAPE3MuO9GYsAcnJvJ4vnMwN/5qkY=\ngolang.org/x/exp v0.0.0-20191129062945-2f5052295587/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20191227195350-da58074b4299/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200119233911-0405dc783f0a/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200207192155-f17229e696bd/go.mod h1:J/WKrq2StrnmMY6+EHIKF9dgMWnmCNThgcyBT1FY9mM=\ngolang.org/x/exp v0.0.0-20200224162631-6cc2880d07d6/go.mod h1:3jZMyOhIsHpP37uCMkUooju7aAi5cS1Q23tOzKc+0MU=\ngolang.org/x/exp v0.0.0-20220428152302-39d4317da171/go.mod h1:lgLbSvA5ygNOMpwM/9anMpWVlVJ7Z+cHWq/eFuinpGE=\ngolang.org/x/exp v0.0.0-20240823005443-9b4947da3948 h1:kx6Ds3MlpiUHKj7syVnbp57++8WpuKPcR5yjLBjvLEA=\ngolang.org/x/exp v0.0.0-20240823005443-9b4947da3948/go.mod h1:akd2r19cwCdwSwWeIdzYQGa/EZZyqcOdwWiwj5L5eKQ=\ngolang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\ngolang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190409202823-959b441ac422/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190909230951-414d861bb4ac/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f/go.mod h1:5qLYkcX4OjUUV8bRuDixDT3tpyyb+LUpUlRWLxfhWrs=\ngolang.org/x/lint v0.0.0-20200130185559-910be7a94367/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6/go.mod h1:z+o9i4GpDbdi3rU15maQ/Ox0txvL9dWGYEHz965HBQE=\ngolang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=\ngolang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=\ngolang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.1.1-0.20191107180719-034126e5016b/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.5.1/go.mod h1:5OXOZSfqPIIbmVBIIKWRFfZjPR0E5r58TLhUjH0a2Ro=\ngolang.org/x/mod v0.6.0-dev.0.20211013180041-c96bc1413d57/go.mod h1:3p9vT2HGsQu2K1YbXdKPJLVgG5VJdoTa1poYQBtP1AY=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190125091013-d26f9f9a57f3/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190501004415-9ce7a6920f09/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190503192946-f4e77d36d62c/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190613194153-d28f0bde5980/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191209160850-c0dbc17a3553/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200114155413-6afb5195e5aa/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200202094626-16171245cfb2/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200222125558-5a598a2470a0/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200301022130-244492dfa37a/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200324143707-d3edc9973b7e/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200501053045-e0ff5e5a1de5/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200506145744-7e3656a0809f/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200513185701-a91f0712d120/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200520182314-0ba52f642ac2/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\ngolang.org/x/net v0.0.0-20210525063256-abc453219eb5/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20211015210444-4f30a5c0130f/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20220127200216-cd36cc0744dd/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=\ngolang.org/x/net v0.0.0-20220225172249-27dd8689420f/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.7.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.29.0 h1:5ORfpBpCs4HzDYoodCDBbwHzdR5UrLBZ3sOnUJmFoHo=\ngolang.org/x/net v0.29.0/go.mod h1:gLkgy8jTGERgjzMic6DS9+SP0ajcu6Xu3Orq/SpETg0=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20210514164344-f6687ab2804c/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20211104180415-d3ed0bb246c8/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20220223155221-ee480838109b/go.mod h1:DAh4E804XQdzx2j+YRIaUnCqCV2RuMz24cGBJ5QYIrc=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201207232520-09787c993a3a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.8.0 h1:3NFvSEYkUoMifnESzZl15y791HH1qU2xm6eCJU5ZPXQ=\ngolang.org/x/sync v0.8.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181122145206-62eef0e2fa9b/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190916202348-b4ddaad3f8a3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191001151750-bb3f8db39f24/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191210023423-ac6580df4449/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200106162015-b016eb3dc98e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200113162924-86b910548bc1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200122134326-e047566fdf82/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200212091648-12a6c2dcc1e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200302150141-5c8b2ff67527/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200331124033-c3d80250170d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200413165638-669c56c373c4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200501052902-10377860bb8e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200511232937-7e40ca221e25/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200515095857-1151b9dac4a9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200615200032-f1bc736245b1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200625212154-ddb9806d33ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200923182605-d9f96fdee20d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201204225414-ed752295db88/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210124154548-22da62e12c0c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210320140829-1e4c9ba3b0c4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210603081109-ebe580a85c40/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211019181941-9d821ace8654/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211216021012-1d35b9e2eb4e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220114195835-da31bd327af9/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220128215802-99c3d69c2c27/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220412211240-33da011f77ad/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220503163025-988cb79eb6c6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220704084225-05e143d24a9e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.26.0 h1:KHjCJyddX0LoSTb3J+vWpupP9p0oznkqVk/IfjymZbo=\ngolang.org/x/sys v0.26.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.5/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.19.0 h1:kTxAhCbGbxhK0IwgSKiMO5awPoDQ0RpfiVYBfK860YM=\ngolang.org/x/text v0.19.0/go.mod h1:BuEKDfySbSR4drPmRPG/7iBdf8hvFMuRexcpahXilzY=\ngolang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20220609170525-579cf78fd858 h1:Dpdu/EMxGMFgq0CeYMh4fazTD2vtlZRYE7wyynxJb9U=\ngolang.org/x/time v0.0.0-20220609170525-579cf78fd858/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180828015842-6cd1fcedba52/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191130070609-6e064ea0cf2d/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191216173652-a0e659d51361/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200117161641-43d50277825c/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200122220014-bf1340f18c4a/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200204074204-1cc6d1ef6c74/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200207183749-b753a1ba74fa/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200212150539-ea181f53ac56/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200224181240-023911ca70b2/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200227222343-706bc42d1f0d/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200304193943-95d2e580d8eb/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200312045724-11d5b4c81c7d/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200331025713-a30bf2db82d4/go.mod h1:Sl4aGygMT6LrqrWclx+PTx3U+LnKx/seiNR+3G19Ar8=\ngolang.org/x/tools v0.0.0-20200423201157-2723c5de0d66/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200501065659-ab2804fb9c9d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200512131952-2bc93b1c0c88/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200515010526-7d3b6ebf133d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.1.8-0.20211029000441-d6a9af8af023/go.mod h1:nABZi5QlRsZVlzPpHl034qft6wpY4eDcsTt5AaioBiU=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20220609144429-65e65417b02f h1:uF6paiQQebLeSXkrTqHqz0MXhXXS1KgF41eUdBNvxK0=\ngolang.org/x/xerrors v0.0.0-20220609144429-65e65417b02f/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=\ngoogle.golang.org/api v0.3.1/go.mod h1:6wY9I6uQWHQ8EM57III9mq/AjF+i8G65rmVagqKMtkk=\ngoogle.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=\ngoogle.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=\ngoogle.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.13.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.14.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.17.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.18.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.19.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.20.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.22.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.24.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.28.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.29.0/go.mod h1:Lcubydp8VUV7KeIHD9z2Bys/sm/vGKnG1UHuDBSrHWM=\ngoogle.golang.org/api v0.30.0/go.mod h1:QGmEvQ87FHZNiUVJkT14jQNYJ4ZJjdRF23ZXz5138Fc=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=\ngoogle.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/appengine v1.6.6/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=\ngoogle.golang.org/genproto v0.0.0-20191108220845-16a3f7862a1a/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191115194625-c23dd37a84c9/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191216164720-4f79533eabd1/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200115191322-ca5a22157cba/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200122232147-0452cf42e150/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200204135345-fa8e72b47b90/go.mod h1:GmwEX6Z4W5gMy59cAlVYjN9JhxgbQH6Gn+gFDQe2lzA=\ngoogle.golang.org/genproto v0.0.0-20200212174721-66ed5ce911ce/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200224152610-e50cd9704f63/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200228133532-8c2c7df3a383/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200305110556-506484158171/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200312145019-da6875a35672/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200331122359-1ee6d9798940/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200430143042-b979b6f78d84/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200511104702-f5ebc3bea380/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200513103714-09dca8ec2884/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200515170657-fc4c6c6a6587/go.mod h1:YsZOwe1myG/8QRHRsmBRE1LrgQY60beZKjly0O1fX9U=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/genproto v0.0.0-20200618031413-b414f8b61790/go.mod h1:jDfRM7FcilCzHH/e9qn6dsT145K34l5v+OpcnNgKAAA=\ngoogle.golang.org/genproto v0.0.0-20200729003335-053ba62fc06f/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200804131852-c06518451d9c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200825200019-8632dd797987/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20211118181313-81c1377c94b1/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=\ngoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1 h1:KpwkzHKEF7B9Zxg18WzOa7djJ+Ha5DzthMyZYQfEn2A=\ngoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1/go.mod h1:nKE/iIaLqn2bQwXBg8f1g2Ylh6r5MN5CmZvuzZCgsCU=\ngoogle.golang.org/grpc v1.17.0/go.mod h1:6QZJwpn2B+Zp71q/5VxRsJ6NXXVCE5NRUHRo+f3cWCs=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=\ngoogle.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.1/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.28.0/go.mod h1:rpkK4SK4GF4Ach/+MFLZUBavHOvF2JJB5uozKKal+60=\ngoogle.golang.org/grpc v1.29.1/go.mod h1:itym6AZVZYACWQqET3MqgPpjcuV5QH3BxFS3IjizoKk=\ngoogle.golang.org/grpc v1.30.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.31.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.33.1/go.mod h1:fr5YgcSWrqhRRxogOsw7RzIpsmvOZ6IcH4kBYTpR3n0=\ngoogle.golang.org/grpc v1.36.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.40.0/go.mod h1:ogyxbiOoUXAkP+4+xa6PZSE9DZgIHtSpzjDTB9KAK34=\ngoogle.golang.org/grpc v1.42.0/go.mod h1:k+4IHHFw41K8+bbowsex27ge2rCb65oeWqe4jJ590SU=\ngoogle.golang.org/grpc v1.56.3 h1:8I4C0Yq1EjstUzUJzpcRVbuYA2mODtEmpWiQoN/b2nc=\ngoogle.golang.org/grpc v1.56.3/go.mod h1:I9bI3vqKfayGqPUAwGdOSu7kt6oIJLixfffKrpXqQ9s=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=\ngoogle.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.27.1/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.33.0 h1:uNO2rsAINq/JlFpSdYEKIZ0uKD/R9cpdv0T+yoGwGmI=\ngoogle.golang.org/protobuf v1.33.0/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15 h1:YR8cESwS4TdDjEe65xsg0ogRM/Nc3DYOhEAlW+xobZo=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.5/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20210107192922-496545a6307b/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.0.0-20180728063816-88497007e858/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=\nhonnef.co/go/tools v0.0.1-2020.1.3/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nhonnef.co/go/tools v0.0.1-2020.1.4/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nlukechampine.com/blake3 v1.1.6 h1:H3cROdztr7RCfoaTpGZFQsrqvweFLrqS73j7L7cmR5c=\nlukechampine.com/blake3 v1.1.6/go.mod h1:tkKEOtDkNtklkXtLNEOGNq5tcV90tJiA1vAA12R78LA=\nmodernc.org/libc v1.22.3 h1:D/g6O5ftAfavceqlLOFwaZuA5KYafKwmr30A6iSqoyY=\nmodernc.org/libc v1.22.3/go.mod h1:MQrloYP209xa2zHome2a8HLiLm6k0UT8CoHpV74tOFw=\nmodernc.org/mathutil v1.5.0 h1:rV0Ko/6SfM+8G+yKiyI830l3Wuz1zRutdslNoQ0kfiQ=\nmodernc.org/mathutil v1.5.0/go.mod h1:mZW8CKdRPY1v87qxC/wUdX5O1qDzXMP5TH3wjfpga6E=\nmodernc.org/memory v1.5.0 h1:N+/8c5rE6EqugZwHii4IFsaJ7MUhoWX07J5tC/iI5Ds=\nmodernc.org/memory v1.5.0/go.mod h1:PkUhL0Mugw21sHPeskwZW4D6VscE/GQJOnIpCnW6pSU=\nmodernc.org/sqlite v1.21.1 h1:GyDFqNnESLOhwwDRaHGdp2jKLDzpyT/rNLglX3ZkMSU=\nmodernc.org/sqlite v1.21.1/go.mod h1:XwQ0wZPIh1iKb5mkvCJ3szzbhk+tykC8ZWqTRTgYRwI=\nrsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=\nrsc.io/quote/v3 v3.1.0/go.mod h1:yEA65RcK8LyAZtP9Kv3t0HmxON59tX3rD+tICJqUlj0=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\nzombiezen.com/go/sqlite v0.13.1 h1:qDzxyWWmMtSSEH5qxamqBFmqA2BLSSbtODi3ojaE02o=\nzombiezen.com/go/sqlite v0.13.1/go.mod h1:Ht/5Rg3Ae2hoyh1I7gbWtWAl89CNocfqeb/aAMTkJr4=\n"
        },
        {
          "name": "handshake.go",
          "type": "blob",
          "size": 1.6669921875,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"time\"\n\n\t\"github.com/anacrolix/torrent/mse\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\n// Wraps a raw connection and provides the interface we want for using the\n// connection in the message loop.\ntype deadlineReader struct {\n\tnc net.Conn\n\tr  io.Reader\n}\n\nfunc (r deadlineReader) Read(b []byte) (int, error) {\n\t// Keep-alives should be received every 2 mins. Give a bit of gracetime.\n\terr := r.nc.SetReadDeadline(time.Now().Add(150 * time.Second))\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"error setting read deadline: %s\", err)\n\t}\n\treturn r.r.Read(b)\n}\n\n// Handles stream encryption for inbound connections.\nfunc handleEncryption(\n\trw io.ReadWriter,\n\tskeys mse.SecretKeyIter,\n\tpolicy HeaderObfuscationPolicy,\n\tselector mse.CryptoSelector,\n) (\n\tret io.ReadWriter,\n\theaderEncrypted bool,\n\tcryptoMethod mse.CryptoMethod,\n\terr error,\n) {\n\t// Tries to start an unencrypted stream.\n\tif !policy.RequirePreferred || !policy.Preferred {\n\t\tvar protocol [len(pp.Protocol)]byte\n\t\t_, err = io.ReadFull(rw, protocol[:])\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\t// Put the protocol back into the stream.\n\t\trw = struct {\n\t\t\tio.Reader\n\t\t\tio.Writer\n\t\t}{\n\t\t\tio.MultiReader(bytes.NewReader(protocol[:]), rw),\n\t\t\trw,\n\t\t}\n\t\tif string(protocol[:]) == pp.Protocol {\n\t\t\tret = rw\n\t\t\treturn\n\t\t}\n\t\tif policy.RequirePreferred {\n\t\t\t// We are here because we require unencrypted connections.\n\t\t\terr = fmt.Errorf(\"unexpected protocol string %q and header obfuscation disabled\", protocol)\n\t\t\treturn\n\t\t}\n\t}\n\theaderEncrypted = true\n\tret, cryptoMethod, err = mse.ReceiveHandshake(context.TODO(), rw, skeys, selector)\n\treturn\n}\n\ntype PeerExtensionBits = pp.PeerExtensionBits\n"
        },
        {
          "name": "handshake_test.go",
          "type": "blob",
          "size": 0.3095703125,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestDefaultExtensionBytes(t *testing.T) {\n\tpex := defaultPeerExtensionBytes()\n\tassert.True(t, pex.SupportsDHT())\n\tassert.True(t, pex.SupportsExtended())\n\tassert.False(t, pex.GetBit(63))\n\tassert.Panics(t, func() { pex.GetBit(64) })\n}\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "iplist",
          "type": "tree",
          "content": null
        },
        {
          "name": "ipport.go",
          "type": "blob",
          "size": 1.322265625,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"strconv\"\n)\n\n// Extracts the port as an integer from an address string.\nfunc addrPortOrZero(addr net.Addr) int {\n\tswitch raw := addr.(type) {\n\tcase *net.UDPAddr:\n\t\treturn raw.Port\n\tcase *net.TCPAddr:\n\t\treturn raw.Port\n\tdefault:\n\t\t// Consider a unix socket on Windows with a name like \"C:notanint\".\n\t\t_, port, err := net.SplitHostPort(addr.String())\n\t\tif err != nil {\n\t\t\treturn 0\n\t\t}\n\t\ti64, err := strconv.ParseUint(port, 0, 16)\n\t\tif err != nil {\n\t\t\treturn 0\n\t\t}\n\t\treturn int(i64)\n\t}\n}\n\nfunc addrIpOrNil(addr net.Addr) net.IP {\n\tif addr == nil {\n\t\treturn nil\n\t}\n\tswitch raw := addr.(type) {\n\tcase *net.UDPAddr:\n\t\treturn raw.IP\n\tcase *net.TCPAddr:\n\t\treturn raw.IP\n\tdefault:\n\t\thost, _, err := net.SplitHostPort(addr.String())\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\treturn net.ParseIP(host)\n\t}\n}\n\ntype ipPortAddr struct {\n\tIP   net.IP\n\tPort int\n}\n\nfunc (ipPortAddr) Network() string {\n\treturn \"\"\n}\n\nfunc (me ipPortAddr) String() string {\n\treturn net.JoinHostPort(me.IP.String(), strconv.FormatInt(int64(me.Port), 10))\n}\n\nfunc tryIpPortFromNetAddr(addr PeerRemoteAddr) (ipPortAddr, bool) {\n\tok := true\n\thost, port, err := net.SplitHostPort(addr.String())\n\tif err != nil {\n\t\tok = false\n\t}\n\tportI64, err := strconv.ParseInt(port, 10, 0)\n\tif err != nil {\n\t\tok = false\n\t}\n\treturn ipPortAddr{net.ParseIP(host), int(portI64)}, ok\n}\n"
        },
        {
          "name": "issue-949_test.go",
          "type": "blob",
          "size": 0.80859375,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\tqt \"github.com/frankban/quicktest\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\nfunc TestIssue949LastPieceZeroPadding(t *testing.T) {\n\t// This torrent has a padding file after the last file listed in the v2 info file tree.\n\tmi, err := metainfo.LoadFromFile(\"testdata/issue-949.torrent\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tinfo, err := mi.UnmarshalInfo()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tlastPiece := info.Piece(info.NumPieces() - 1)\n\tc := qt.New(t)\n\tc.Assert(info.FilesArePieceAligned(), qt.IsTrue)\n\t// Check the v1 piece length includes the trailing padding file.\n\tc.Check(lastPiece.V1Length(), qt.Equals, info.PieceLength)\n\t// The v2 piece should only include the file data, which fits inside the piece length for this\n\t// file.\n\tc.Check(lastPiece.Length(), qt.Equals, int64(3677645))\n}\n"
        },
        {
          "name": "issue211_test.go",
          "type": "blob",
          "size": 0.904296875,
          "content": "//go:build !wasm\n// +build !wasm\n\npackage torrent\n\nimport (\n\t\"io\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc TestDropTorrentWithMmapStorageWhileHashing(t *testing.T) {\n\tcfg := TestingConfig(t)\n\t// Ensure the data is present when the torrent is added, and not obtained\n\t// over the network as the test runs.\n\tcfg.DownloadRateLimiter = rate.NewLimiter(0, 0)\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\n\ttd, mi := testutil.GreetingTestTorrent()\n\tmms := storage.NewMMap(td)\n\tdefer mms.Close()\n\ttt, new, err := cl.AddTorrentSpec(&TorrentSpec{\n\t\tStorage:   mms,\n\t\tInfoHash:  mi.HashInfoBytes(),\n\t\tInfoBytes: mi.InfoBytes,\n\t})\n\trequire.NoError(t, err)\n\tassert.True(t, new)\n\n\tr := tt.NewReader()\n\tgo tt.Drop()\n\tio.Copy(io.Discard, r)\n}\n"
        },
        {
          "name": "issue97_test.go",
          "type": "blob",
          "size": 0.6650390625,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc TestHashPieceAfterStorageClosed(t *testing.T) {\n\ttd := t.TempDir()\n\tcs := storage.NewFile(td)\n\tdefer cs.Close()\n\ttt := &Torrent{\n\t\tstorageOpener: storage.NewClient(cs),\n\t\tlogger:        log.Default,\n\t\tchunkSize:     defaultChunkSize,\n\t}\n\ttt.infoHash.Ok = true\n\ttt.infoHash.Value[0] = 1\n\tmi := testutil.GreetingMetaInfo()\n\tinfo, err := mi.UnmarshalInfo()\n\trequire.NoError(t, err)\n\trequire.NoError(t, tt.setInfo(&info))\n\trequire.NoError(t, tt.storage.Close())\n\ttt.hashPiece(0)\n}\n"
        },
        {
          "name": "justfile",
          "type": "blob",
          "size": 0.052734375,
          "content": "check:\n    go test -run @ -failfast ./... > /dev/null\n"
        },
        {
          "name": "listen.go",
          "type": "blob",
          "size": 0.1748046875,
          "content": "package torrent\n\nimport \"strings\"\n\nfunc LoopbackListenHost(network string) string {\n\tif strings.IndexByte(network, '4') != -1 {\n\t\treturn \"127.0.0.1\"\n\t} else {\n\t\treturn \"::1\"\n\t}\n}\n"
        },
        {
          "name": "logging.go",
          "type": "blob",
          "size": 0.0927734375,
          "content": "package torrent\n\nconst (\n\tprotocolLoggingName = \"protocol\"\n\tv2HashesLogName     = \"v2hashes\"\n)\n"
        },
        {
          "name": "logonce",
          "type": "tree",
          "content": null
        },
        {
          "name": "ltep.go",
          "type": "blob",
          "size": 2.2412109375,
          "content": "package torrent\n\nimport (\n\t\"fmt\"\n\t\"slices\"\n\n\tg \"github.com/anacrolix/generics\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\ntype LocalLtepProtocolMap struct {\n\t// 1-based mapping from extension number to extension name (subtract one from the extension ID\n\t// to find the corresponding protocol name). The first LocalLtepProtocolBuiltinCount of these\n\t// are use builtin handlers. If you want to handle builtin protocols yourself, you would move\n\t// them above the threshold. You can disable them by removing them entirely, and add your own.\n\t// These changes should be done in the PeerConnAdded callback.\n\tIndex []pp.ExtensionName\n\t// How many of the protocols are using the builtin handlers.\n\tNumBuiltin int\n}\n\nfunc (me *LocalLtepProtocolMap) toSupportedExtensionDict() (m map[pp.ExtensionName]pp.ExtensionNumber) {\n\tg.MakeMapWithCap(&m, len(me.Index))\n\tfor i, name := range me.Index {\n\t\told := g.MapInsert(m, name, pp.ExtensionNumber(i+1))\n\t\tif old.Ok {\n\t\t\tpanic(fmt.Sprintf(\"extension %q already defined with id %v\", name, old.Value))\n\t\t}\n\t}\n\treturn\n}\n\n// Returns the local extension name for the given ID. If builtin is true, the implementation intends\n// to handle it itself. For incoming messages with extension ID 0, the message is a handshake, and\n// should be treated specially.\nfunc (me *LocalLtepProtocolMap) LookupId(id pp.ExtensionNumber) (name pp.ExtensionName, builtin bool, err error) {\n\tif id == 0 {\n\t\terr = fmt.Errorf(\"extension ID 0 is handshake\")\n\t\tbuiltin = true\n\t\treturn\n\t}\n\tprotocolIndex := int(id - 1)\n\tif protocolIndex >= len(me.Index) {\n\t\terr = fmt.Errorf(\"unexpected extended message ID: %v\", id)\n\t\treturn\n\t}\n\tbuiltin = protocolIndex < me.NumBuiltin\n\tname = me.Index[protocolIndex]\n\treturn\n}\n\nfunc (me *LocalLtepProtocolMap) builtin() []pp.ExtensionName {\n\treturn me.Index[:me.NumBuiltin]\n}\n\nfunc (me *LocalLtepProtocolMap) user() []pp.ExtensionName {\n\treturn me.Index[me.NumBuiltin:]\n}\n\nfunc (me *LocalLtepProtocolMap) AddUserProtocol(name pp.ExtensionName) {\n\tbuiltin := slices.DeleteFunc(me.builtin(), func(delName pp.ExtensionName) bool {\n\t\treturn delName == name\n\t})\n\tuser := slices.DeleteFunc(me.user(), func(delName pp.ExtensionName) bool {\n\t\treturn delName == name\n\t})\n\tme.Index = append(append(builtin, user...), name)\n\tme.NumBuiltin = len(builtin)\n}\n"
        },
        {
          "name": "ltep_test.go",
          "type": "blob",
          "size": 4.009765625,
          "content": "package torrent_test\n\nimport (\n\t\"math/rand\"\n\t\"strconv\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/sync\"\n\tqt \"github.com/frankban/quicktest\"\n\n\t. \"github.com/anacrolix/torrent\"\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nconst (\n\ttestRepliesToOddsExtensionName  = \"pm_me_odds\"\n\ttestRepliesToEvensExtensionName = \"pm_me_evens\"\n)\n\nfunc countHandler(\n\tc *qt.C,\n\twg *sync.WaitGroup,\n\t// Name of the endpoint that this handler is for, for logging.\n\thandlerName string,\n\t// Whether we expect evens or odds\n\texpectedMod2 uint,\n\t// Extension name of messages we expect to handle.\n\tanswerToName pp.ExtensionName,\n\t// Extension name of messages we expect to send.\n\treplyToName pp.ExtensionName,\n\t// Signal done when this value is seen.\n\tdoneValue uint,\n) func(event PeerConnReadExtensionMessageEvent) {\n\treturn func(event PeerConnReadExtensionMessageEvent) {\n\t\t// Read handshake, don't look it up.\n\t\tif event.ExtensionNumber == 0 {\n\t\t\treturn\n\t\t}\n\t\tname, builtin, err := event.PeerConn.LocalLtepProtocolMap.LookupId(event.ExtensionNumber)\n\t\tc.Assert(err, qt.IsNil)\n\t\t// Not a user protocol.\n\t\tif builtin {\n\t\t\treturn\n\t\t}\n\t\tswitch name {\n\t\tcase answerToName:\n\t\t\tu64, err := strconv.ParseUint(string(event.Payload), 10, 0)\n\t\t\tc.Assert(err, qt.IsNil)\n\t\t\ti := uint(u64)\n\t\t\tc.Logf(\"%v got %d\", handlerName, i)\n\t\t\tif i == doneValue {\n\t\t\t\twg.Done()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tc.Assert(i%2, qt.Equals, expectedMod2)\n\t\t\tgo func() {\n\t\t\t\tc.Assert(\n\t\t\t\t\tevent.PeerConn.WriteExtendedMessage(\n\t\t\t\t\t\treplyToName,\n\t\t\t\t\t\t[]byte(strconv.FormatUint(uint64(i+1), 10))),\n\t\t\t\t\tqt.IsNil)\n\t\t\t}()\n\t\tdefault:\n\t\t\tc.Fatalf(\"got unexpected extension name %q\", name)\n\t\t}\n\t}\n}\n\nfunc TestUserLtep(t *testing.T) {\n\tc := qt.New(t)\n\tvar wg sync.WaitGroup\n\n\tmakeCfg := func() *ClientConfig {\n\t\tcfg := TestingConfig(t)\n\t\t// Only want a single connection to between the clients.\n\t\tcfg.DisableUTP = true\n\t\tcfg.DisableIPv6 = true\n\t\treturn cfg\n\t}\n\n\tevensCfg := makeCfg()\n\tevensCfg.Callbacks.ReadExtendedHandshake = func(pc *PeerConn, msg *pp.ExtendedHandshakeMessage) {\n\t\t// The client lock is held while handling this event, so we have to do synchronous work in a\n\t\t// separate goroutine.\n\t\tgo func() {\n\t\t\t// Check sending an extended message for a protocol the peer doesn't support is an error.\n\t\t\tc.Check(pc.WriteExtendedMessage(\"pm_me_floats\", []byte(\"3.142\")), qt.IsNotNil)\n\t\t\t// Kick things off by sending a 1.\n\t\t\tc.Check(pc.WriteExtendedMessage(testRepliesToOddsExtensionName, []byte(\"1\")), qt.IsNil)\n\t\t}()\n\t}\n\tevensCfg.Callbacks.PeerConnReadExtensionMessage = append(\n\t\tevensCfg.Callbacks.PeerConnReadExtensionMessage,\n\t\tcountHandler(c, &wg, \"evens\", 0, testRepliesToEvensExtensionName, testRepliesToOddsExtensionName, 100))\n\tevensCfg.Callbacks.PeerConnAdded = append(evensCfg.Callbacks.PeerConnAdded, func(conn *PeerConn) {\n\t\tconn.LocalLtepProtocolMap.AddUserProtocol(testRepliesToEvensExtensionName)\n\t\tc.Assert(conn.LocalLtepProtocolMap.Index[conn.LocalLtepProtocolMap.NumBuiltin:], qt.HasLen, 1)\n\t})\n\n\toddsCfg := makeCfg()\n\toddsCfg.Callbacks.PeerConnAdded = append(oddsCfg.Callbacks.PeerConnAdded, func(conn *PeerConn) {\n\t\tconn.LocalLtepProtocolMap.AddUserProtocol(testRepliesToOddsExtensionName)\n\t\tc.Assert(conn.LocalLtepProtocolMap.Index[conn.LocalLtepProtocolMap.NumBuiltin:], qt.HasLen, 1)\n\t})\n\toddsCfg.Callbacks.PeerConnReadExtensionMessage = append(\n\t\toddsCfg.Callbacks.PeerConnReadExtensionMessage,\n\t\tcountHandler(c, &wg, \"odds\", 1, testRepliesToOddsExtensionName, testRepliesToEvensExtensionName, 100))\n\n\tcl1, err := NewClient(oddsCfg)\n\tc.Assert(err, qt.IsNil)\n\tdefer cl1.Close()\n\tcl2, err := NewClient(evensCfg)\n\tc.Assert(err, qt.IsNil)\n\tdefer cl2.Close()\n\taddOpts := AddTorrentOpts{}\n\trand.Read(addOpts.InfoHash[:])\n\tt1, _ := cl1.AddTorrentOpt(addOpts)\n\tt2, _ := cl2.AddTorrentOpt(addOpts)\n\tdefer testutil.ExportStatusWriter(cl1, \"cl1\", t)()\n\tdefer testutil.ExportStatusWriter(cl2, \"cl2\", t)()\n\t// Expect one PeerConn to see the value.\n\twg.Add(1)\n\tadded := t1.AddClientPeer(cl2)\n\t// Ensure some addresses for the other client were added.\n\tc.Assert(added, qt.Not(qt.Equals), 0)\n\twg.Wait()\n\t_ = t2\n}\n"
        },
        {
          "name": "main_test.go",
          "type": "blob",
          "size": 0.322265625,
          "content": "package torrent\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"testing\"\n\n\t_ \"github.com/anacrolix/envpprof\"\n\tanalog \"github.com/anacrolix/log\"\n)\n\nfunc init() {\n\tlog.SetFlags(log.LstdFlags | log.Lshortfile)\n\tanalog.DefaultTimeFormatter = analog.TimeFormatSecondsSinceInit\n}\n\nfunc TestMain(m *testing.M) {\n\tcode := m.Run()\n\t// select {}\n\tos.Exit(code)\n}\n"
        },
        {
          "name": "merkle",
          "type": "tree",
          "content": null
        },
        {
          "name": "metainfo",
          "type": "tree",
          "content": null
        },
        {
          "name": "misc.go",
          "type": "blob",
          "size": 4.021484375,
          "content": "package torrent\n\nimport (\n\t\"errors\"\n\t\"net\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/types\"\n\t\"github.com/anacrolix/torrent/types/infohash\"\n)\n\ntype (\n\tRequest       = types.Request\n\tChunkSpec     = types.ChunkSpec\n\tPiecePriority = types.PiecePriority\n)\n\nconst (\n\tPiecePriorityNormal    = types.PiecePriorityNormal\n\tPiecePriorityNone      = types.PiecePriorityNone\n\tPiecePriorityNow       = types.PiecePriorityNow\n\tPiecePriorityReadahead = types.PiecePriorityReadahead\n\tPiecePriorityNext      = types.PiecePriorityNext\n\tPiecePriorityHigh      = types.PiecePriorityHigh\n)\n\nfunc newRequest(index, begin, length pp.Integer) Request {\n\treturn Request{index, ChunkSpec{begin, length}}\n}\n\nfunc newRequestFromMessage(msg *pp.Message) Request {\n\tswitch msg.Type {\n\tcase pp.Request, pp.Cancel, pp.Reject:\n\t\treturn newRequest(msg.Index, msg.Begin, msg.Length)\n\tcase pp.Piece:\n\t\treturn newRequest(msg.Index, msg.Begin, pp.Integer(len(msg.Piece)))\n\tdefault:\n\t\tpanic(msg.Type)\n\t}\n}\n\n// The size in bytes of a metadata extension piece.\nfunc metadataPieceSize(totalSize, piece int) int {\n\tret := totalSize - piece*(1<<14)\n\tif ret > 1<<14 {\n\t\tret = 1 << 14\n\t}\n\treturn ret\n}\n\n// Return the request that would include the given offset into the torrent data.\nfunc torrentOffsetRequest(\n\ttorrentLength, pieceSize, chunkSize, offset int64,\n) (\n\tr Request, ok bool,\n) {\n\tif offset < 0 || offset >= torrentLength {\n\t\treturn\n\t}\n\tr.Index = pp.Integer(offset / pieceSize)\n\tr.Begin = pp.Integer(offset % pieceSize / chunkSize * chunkSize)\n\tr.Length = pp.Integer(chunkSize)\n\tpieceLeft := pp.Integer(pieceSize - int64(r.Begin))\n\tif r.Length > pieceLeft {\n\t\tr.Length = pieceLeft\n\t}\n\ttorrentLeft := torrentLength - int64(r.Index)*pieceSize - int64(r.Begin)\n\tif int64(r.Length) > torrentLeft {\n\t\tr.Length = pp.Integer(torrentLeft)\n\t}\n\tok = true\n\treturn\n}\n\nfunc torrentRequestOffset(torrentLength, pieceSize int64, r Request) (off int64) {\n\toff = int64(r.Index)*pieceSize + int64(r.Begin)\n\tif off < 0 || off >= torrentLength {\n\t\tpanic(\"invalid Request\")\n\t}\n\treturn\n}\n\nfunc validateInfo(info *metainfo.Info) error {\n\tif len(info.Pieces)%20 != 0 {\n\t\treturn errors.New(\"pieces has invalid length\")\n\t}\n\tif info.PieceLength == 0 {\n\t\tif info.TotalLength() != 0 {\n\t\t\treturn errors.New(\"zero piece length\")\n\t\t}\n\t} else if !info.HasV2() {\n\t\t// TotalLength returns different values for V1 and V2 depending on whether v1 pad files are\n\t\t// counted. Split the interface into several methods?\n\t\tif int((info.TotalLength()+info.PieceLength-1)/info.PieceLength) != info.NumPieces() {\n\t\t\treturn errors.New(\"piece count and file lengths are at odds\")\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc chunkIndexSpec(index, pieceLength, chunkSize pp.Integer) ChunkSpec {\n\tret := ChunkSpec{pp.Integer(index) * chunkSize, chunkSize}\n\tif ret.Begin+ret.Length > pieceLength {\n\t\tret.Length = pieceLength - ret.Begin\n\t}\n\treturn ret\n}\n\nfunc comparePeerTrust(l, r *Peer) int {\n\treturn l.trust().Cmp(r.trust())\n}\n\nfunc connIsIpv6(nc interface {\n\tLocalAddr() net.Addr\n},\n) bool {\n\tra := nc.LocalAddr()\n\trip := addrIpOrNil(ra)\n\treturn rip.To4() == nil && rip.To16() != nil\n}\n\nfunc clamp(min, value, max int64) int64 {\n\tif min > max {\n\t\tpanic(\"harumph\")\n\t}\n\tif value < min {\n\t\tvalue = min\n\t}\n\tif value > max {\n\t\tvalue = max\n\t}\n\treturn value\n}\n\nfunc max(as ...int64) int64 {\n\tret := as[0]\n\tfor _, a := range as[1:] {\n\t\tif a > ret {\n\t\t\tret = a\n\t\t}\n\t}\n\treturn ret\n}\n\nfunc maxInt(as ...int) int {\n\tret := as[0]\n\tfor _, a := range as[1:] {\n\t\tif a > ret {\n\t\t\tret = a\n\t\t}\n\t}\n\treturn ret\n}\n\nfunc minInt(as ...int) int {\n\tret := as[0]\n\tfor _, a := range as[1:] {\n\t\tif a < ret {\n\t\t\tret = a\n\t\t}\n\t}\n\treturn ret\n}\n\nvar unlimited = rate.NewLimiter(rate.Inf, 0)\n\ntype (\n\tpieceIndex = int\n\t// Deprecated: Use infohash.T directly to avoid unnecessary imports.\n\tInfoHash = infohash.T\n\tIpPort   = missinggo.IpPort\n)\n\nfunc boolSliceToBitmap(slice []bool) (rb roaring.Bitmap) {\n\tfor i, b := range slice {\n\t\tif b {\n\t\t\trb.AddInt(i)\n\t\t}\n\t}\n\treturn\n}\n"
        },
        {
          "name": "misc_test.go",
          "type": "blob",
          "size": 1.240234375,
          "content": "package torrent\n\nimport (\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/missinggo/iter\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\t\"github.com/davecgh/go-spew/spew\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestTorrentOffsetRequest(t *testing.T) {\n\tcheck := func(tl, ps, off int64, expected Request, ok bool) {\n\t\treq, _ok := torrentOffsetRequest(tl, ps, defaultChunkSize, off)\n\t\tassert.Equal(t, _ok, ok)\n\t\tassert.Equal(t, req, expected)\n\t}\n\tcheck(13, 5, 0, newRequest(0, 0, 5), true)\n\tcheck(13, 5, 3, newRequest(0, 0, 5), true)\n\tcheck(13, 5, 11, newRequest(2, 0, 3), true)\n\tcheck(13, 5, 13, Request{}, false)\n}\n\nfunc BenchmarkIterBitmapsDistinct(t *testing.B) {\n\tt.ReportAllocs()\n\tfor i := 0; i < t.N; i += 1 {\n\t\tvar skip, first, second bitmap.Bitmap\n\t\tskip.Add(1)\n\t\tfirst.Add(1, 0, 3)\n\t\tsecond.Add(1, 2, 0)\n\t\tskipCopy := skip.Copy()\n\t\tt.StartTimer()\n\t\toutput := iter.ToSlice(iterBitmapsDistinct(&skipCopy, first, second))\n\t\tt.StopTimer()\n\t\tassert.Equal(t, []interface{}{0, 3, 2}, output)\n\t\tassert.Equal(t, []bitmap.BitIndex{1}, skip.ToSortedSlice())\n\t}\n}\n\nfunc TestSpewConnStats(t *testing.T) {\n\ts := spew.Sdump(ConnStats{})\n\tt.Logf(\"\\n%s\", s)\n\tlines := strings.Count(s, \"\\n\")\n\tassert.EqualValues(t, 2+reflect.ValueOf(ConnStats{}).NumField(), lines)\n}\n"
        },
        {
          "name": "mmap_span",
          "type": "tree",
          "content": null
        },
        {
          "name": "mse",
          "type": "tree",
          "content": null
        },
        {
          "name": "netip-addrport.go",
          "type": "blob",
          "size": 1.1474609375,
          "content": "package torrent\n\nimport (\n\t\"fmt\"\n\t\"net/netip\"\n\n\t\"github.com/anacrolix/dht/v2/krpc\"\n)\n\ntype addrPorter interface {\n\tAddrPort() netip.AddrPort\n}\n\nfunc ipv4AddrPortFromKrpcNodeAddr(na krpc.NodeAddr) (_ netip.AddrPort, err error) {\n\tip4 := na.IP.To4()\n\tif ip4 == nil {\n\t\terr = fmt.Errorf(\"not an ipv4 address: %v\", na.IP)\n\t\treturn\n\t}\n\taddr := netip.AddrFrom4(*(*[4]byte)(ip4))\n\taddrPort := netip.AddrPortFrom(addr, uint16(na.Port))\n\treturn addrPort, nil\n}\n\nfunc ipv6AddrPortFromKrpcNodeAddr(na krpc.NodeAddr) (_ netip.AddrPort, err error) {\n\tip6 := na.IP.To16()\n\tif ip6 == nil {\n\t\terr = fmt.Errorf(\"not an ipv4 address: %v\", na.IP)\n\t\treturn\n\t}\n\taddr := netip.AddrFrom16(*(*[16]byte)(ip6))\n\taddrPort := netip.AddrPortFrom(addr, uint16(na.Port))\n\treturn addrPort, nil\n}\n\nfunc addrPortFromPeerRemoteAddr(pra PeerRemoteAddr) (netip.AddrPort, error) {\n\tswitch v := pra.(type) {\n\tcase addrPorter:\n\t\treturn v.AddrPort(), nil\n\tcase netip.AddrPort:\n\t\treturn v, nil\n\tdefault:\n\t\treturn netip.ParseAddrPort(pra.String())\n\t}\n}\n\nfunc krpcNodeAddrFromAddrPort(addrPort netip.AddrPort) krpc.NodeAddr {\n\treturn krpc.NodeAddr{\n\t\tIP:   addrPort.Addr().AsSlice(),\n\t\tPort: int(addrPort.Port()),\n\t}\n}\n"
        },
        {
          "name": "network_test.go",
          "type": "blob",
          "size": 2.2236328125,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc testListenerNetwork(\n\tt *testing.T,\n\tlistenFunc func(net, addr string) (net.Listener, error),\n\texpectedNet, givenNet, addr string, validIp4 bool,\n) {\n\tl, err := listenFunc(givenNet, addr)\n\tif isUnsupportedNetworkError(err) {\n\t\treturn\n\t}\n\trequire.NoError(t, err)\n\tdefer l.Close()\n\tassert.EqualValues(t, expectedNet, l.Addr().Network())\n\tip := missinggo.AddrIP(l.Addr())\n\tassert.Equal(t, validIp4, ip.To4() != nil, ip)\n}\n\nfunc listenUtpListener(net, addr string) (l net.Listener, err error) {\n\tl, err = NewUtpSocket(net, addr, nil, log.Default)\n\treturn\n}\n\nfunc testAcceptedConnAddr(\n\tt *testing.T,\n\tnetwork string, valid4 bool,\n\tdial func(addr string) (net.Conn, error),\n\tlisten func() (net.Listener, error),\n) {\n\tl, err := listen()\n\trequire.NoError(t, err)\n\tdefer l.Close()\n\tdone := make(chan struct{})\n\tdefer close(done)\n\tgo func() {\n\t\tc, err := dial(l.Addr().String())\n\t\trequire.NoError(t, err)\n\t\t<-done\n\t\tc.Close()\n\t}()\n\tc, err := l.Accept()\n\trequire.NoError(t, err)\n\tdefer c.Close()\n\tassert.EqualValues(t, network, c.RemoteAddr().Network())\n\tassert.Equal(t, valid4, missinggo.AddrIP(c.RemoteAddr()).To4() == nil)\n}\n\nfunc listenClosure(\n\trawListenFunc func(string, string) (net.Listener, error),\n\tnetwork, addr string,\n) func() (net.Listener, error) {\n\treturn func() (net.Listener, error) {\n\t\treturn rawListenFunc(network, addr)\n\t}\n}\n\nfunc dialClosure(f func(net, addr string) (net.Conn, error), network string) func(addr string) (net.Conn, error) {\n\treturn func(addr string) (net.Conn, error) {\n\t\treturn f(network, addr)\n\t}\n}\n\nfunc TestListenLocalhostNetwork(t *testing.T) {\n\ttestListenerNetwork(t, net.Listen, \"tcp\", \"tcp\", \"0.0.0.0:0\", false)\n\ttestListenerNetwork(t, net.Listen, \"tcp\", \"tcp\", \"[::1]:0\", false)\n\ttestListenerNetwork(t, listenUtpListener, \"udp\", \"udp6\", \"[::1]:0\", false)\n\ttestListenerNetwork(t, listenUtpListener, \"udp\", \"udp6\", \"[::]:0\", false)\n\ttestListenerNetwork(t, listenUtpListener, \"udp\", \"udp4\", \"localhost:0\", true)\n\n\ttestAcceptedConnAddr(\n\t\tt,\n\t\t\"tcp\",\n\t\tfalse,\n\t\tdialClosure(net.Dial, \"tcp\"),\n\t\tlistenClosure(net.Listen, \"tcp4\", \"localhost:0\"),\n\t)\n}\n"
        },
        {
          "name": "networks.go",
          "type": "blob",
          "size": 0.9130859375,
          "content": "package torrent\n\nimport \"strings\"\n\nvar allPeerNetworks = func() (ret []network) {\n\tfor _, s := range []string{\"tcp4\", \"tcp6\", \"udp4\", \"udp6\"} {\n\t\tret = append(ret, parseNetworkString(s))\n\t}\n\treturn\n}()\n\ntype network struct {\n\tIpv4 bool\n\tIpv6 bool\n\tUdp  bool\n\tTcp  bool\n}\n\nfunc (n network) String() (ret string) {\n\ta := func(b bool, s string) {\n\t\tif b {\n\t\t\tret += s\n\t\t}\n\t}\n\ta(n.Udp, \"udp\")\n\ta(n.Tcp, \"tcp\")\n\ta(n.Ipv4, \"4\")\n\ta(n.Ipv6, \"6\")\n\treturn\n}\n\nfunc parseNetworkString(network string) (ret network) {\n\tc := func(s string) bool {\n\t\treturn strings.Contains(network, s)\n\t}\n\tret.Ipv4 = c(\"4\")\n\tret.Ipv6 = c(\"6\")\n\tret.Udp = c(\"udp\")\n\tret.Tcp = c(\"tcp\")\n\treturn\n}\n\nfunc peerNetworkEnabled(n network, cfg *ClientConfig) bool {\n\tif cfg.DisableUTP && n.Udp {\n\t\treturn false\n\t}\n\tif cfg.DisableTCP && n.Tcp {\n\t\treturn false\n\t}\n\tif cfg.DisableIPv6 && n.Ipv6 {\n\t\treturn false\n\t}\n\tif cfg.DisableIPv4 && n.Ipv4 {\n\t\treturn false\n\t}\n\treturn true\n}\n"
        },
        {
          "name": "ordered-bitmap.go",
          "type": "blob",
          "size": 1.4814453125,
          "content": "package torrent\n\nimport (\n\t\"iter\"\n\n\tg \"github.com/anacrolix/generics\"\n\tlist \"github.com/bahlo/generic-list-go\"\n\n\t\"github.com/anacrolix/torrent/typed-roaring\"\n)\n\ntype orderedBitmap[T typedRoaring.BitConstraint] struct {\n\tbitmap typedRoaring.Bitmap[T]\n\t// There should be way more efficient ways to do this.\n\torder    list.List[T]\n\telements map[T]*list.Element[T]\n}\n\nfunc (o *orderedBitmap[T]) IterateSnapshot(f func(T) bool) {\n\to.bitmap.Clone().Iterate(f)\n}\n\nfunc (o *orderedBitmap[T]) IsEmpty() bool {\n\treturn o.bitmap.IsEmpty()\n}\n\nfunc (o *orderedBitmap[T]) GetCardinality() uint64 {\n\treturn uint64(o.order.Len())\n}\n\nfunc (o *orderedBitmap[T]) Contains(index T) bool {\n\treturn o.bitmap.Contains(index)\n}\n\nfunc (o *orderedBitmap[T]) Add(index T) {\n\to.bitmap.Add(index)\n\tif _, ok := o.elements[index]; !ok {\n\t\tg.MakeMapIfNilAndSet(&o.elements, index, o.order.PushBack(index))\n\t}\n}\n\nfunc (o *orderedBitmap[T]) Rank(index T) uint64 {\n\treturn o.bitmap.Rank(index)\n}\n\nfunc (o *orderedBitmap[T]) Iterate(f func(T) bool) (all bool) {\n\tfor e := o.order.Front(); e != nil; e = e.Next() {\n\t\tif !f(e.Value) {\n\t\t\treturn\n\t\t}\n\t}\n\tall = true\n\treturn\n}\n\nfunc (o *orderedBitmap[T]) Iterator() iter.Seq[T] {\n\treturn func(yield func(T) bool) {\n\t\tfor e := o.order.Front(); e != nil; e = e.Next() {\n\t\t\tif !yield(e.Value) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (o *orderedBitmap[T]) CheckedRemove(index T) bool {\n\tif !o.bitmap.CheckedRemove(index) {\n\t\treturn false\n\t}\n\to.order.Remove(o.elements[index])\n\tdelete(o.elements, index)\n\treturn true\n}\n"
        },
        {
          "name": "otel.go",
          "type": "blob",
          "size": 0.0546875,
          "content": "package torrent\n\nconst tracerName = \"anacrolix.torrent\"\n"
        },
        {
          "name": "peer-conn-msg-writer.go",
          "type": "blob",
          "size": 3.3359375,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"io\"\n\t\"time\"\n\n\t\"github.com/anacrolix/chansync\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/sync\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc (pc *PeerConn) initMessageWriter() {\n\tw := &pc.messageWriter\n\t*w = peerConnMsgWriter{\n\t\tfillWriteBuffer: func() {\n\t\t\tpc.locker().Lock()\n\t\t\tdefer pc.locker().Unlock()\n\t\t\tif pc.closed.IsSet() {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpc.fillWriteBuffer()\n\t\t},\n\t\tclosed: &pc.closed,\n\t\tlogger: pc.logger,\n\t\tw:      pc.w,\n\t\tkeepAlive: func() bool {\n\t\t\tpc.locker().RLock()\n\t\t\tdefer pc.locker().RUnlock()\n\t\t\treturn pc.useful()\n\t\t},\n\t\twriteBuffer: new(bytes.Buffer),\n\t}\n}\n\nfunc (pc *PeerConn) startMessageWriter() {\n\tpc.initMessageWriter()\n\tgo pc.messageWriterRunner()\n}\n\nfunc (pc *PeerConn) messageWriterRunner() {\n\tdefer pc.locker().Unlock()\n\tdefer pc.close()\n\tdefer pc.locker().Lock()\n\tpc.messageWriter.run(pc.t.cl.config.KeepAliveTimeout)\n}\n\ntype peerConnMsgWriter struct {\n\t// Must not be called with the local mutex held, as it will call back into the write method.\n\tfillWriteBuffer func()\n\tclosed          *chansync.SetOnce\n\tlogger          log.Logger\n\tw               io.Writer\n\tkeepAlive       func() bool\n\n\tmu        sync.Mutex\n\twriteCond chansync.BroadcastCond\n\t// Pointer so we can swap with the \"front buffer\".\n\twriteBuffer *bytes.Buffer\n}\n\n// Routine that writes to the peer. Some of what to write is buffered by\n// activity elsewhere in the Client, and some is determined locally when the\n// connection is writable.\nfunc (cn *peerConnMsgWriter) run(keepAliveTimeout time.Duration) {\n\tlastWrite := time.Now()\n\tkeepAliveTimer := time.NewTimer(keepAliveTimeout)\n\tfrontBuf := new(bytes.Buffer)\n\tfor {\n\t\tif cn.closed.IsSet() {\n\t\t\treturn\n\t\t}\n\t\tcn.fillWriteBuffer()\n\t\tkeepAlive := cn.keepAlive()\n\t\tcn.mu.Lock()\n\t\tif cn.writeBuffer.Len() == 0 && time.Since(lastWrite) >= keepAliveTimeout && keepAlive {\n\t\t\tcn.writeBuffer.Write(pp.Message{Keepalive: true}.MustMarshalBinary())\n\t\t\ttorrent.Add(\"written keepalives\", 1)\n\t\t}\n\t\tif cn.writeBuffer.Len() == 0 {\n\t\t\twriteCond := cn.writeCond.Signaled()\n\t\t\tcn.mu.Unlock()\n\t\t\tselect {\n\t\t\tcase <-cn.closed.Done():\n\t\t\tcase <-writeCond:\n\t\t\tcase <-keepAliveTimer.C:\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// Flip the buffers.\n\t\tfrontBuf, cn.writeBuffer = cn.writeBuffer, frontBuf\n\t\tcn.mu.Unlock()\n\t\tif frontBuf.Len() == 0 {\n\t\t\tpanic(\"expected non-empty front buffer\")\n\t\t}\n\t\tvar err error\n\t\tfor frontBuf.Len() != 0 {\n\t\t\tnext := frontBuf.Bytes()\n\t\t\tvar n int\n\t\t\tn, err = cn.w.Write(next)\n\t\t\tfrontBuf.Next(n)\n\t\t\tif err == nil && n != len(next) {\n\t\t\t\tpanic(\"expected full write\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\tcn.logger.WithDefaultLevel(log.Debug).Printf(\"error writing: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tlastWrite = time.Now()\n\t\tkeepAliveTimer.Reset(keepAliveTimeout)\n\t}\n}\n\nfunc (cn *peerConnMsgWriter) writeToBuffer(msg pp.Message) (err error) {\n\toriginalLen := cn.writeBuffer.Len()\n\tdefer func() {\n\t\tif err != nil {\n\t\t\t// Since an error occurred during buffer write, revert buffer to its original state before the write.\n\t\t\tcn.writeBuffer.Truncate(originalLen)\n\t\t}\n\t}()\n\treturn msg.WriteTo(cn.writeBuffer)\n}\n\nfunc (cn *peerConnMsgWriter) write(msg pp.Message) bool {\n\tcn.mu.Lock()\n\tdefer cn.mu.Unlock()\n\tcn.writeToBuffer(msg)\n\tcn.writeCond.Broadcast()\n\treturn !cn.writeBufferFull()\n}\n\nfunc (cn *peerConnMsgWriter) writeBufferFull() bool {\n\treturn cn.writeBuffer.Len() >= writeBufferHighWaterLen\n}\n"
        },
        {
          "name": "peer-conn-msg-writer_test.go",
          "type": "blob",
          "size": 1.4287109375,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"testing\"\n\n\t\"github.com/dustin/go-humanize\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc PieceMsg(length int64) pp.Message {\n\treturn pp.Message{\n\t\tType:  pp.Piece,\n\t\tIndex: pp.Integer(0),\n\t\tBegin: pp.Integer(0),\n\t\tPiece: make([]byte, length),\n\t}\n}\n\nvar benchmarkPieceLengths = []int{defaultChunkSize, 1 << 20, 4 << 20, 8 << 20}\n\nfunc runBenchmarkWriteToBuffer(b *testing.B, length int64) {\n\twriter := &peerConnMsgWriter{\n\t\twriteBuffer: &bytes.Buffer{},\n\t}\n\tmsg := PieceMsg(length)\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t//b.StopTimer()\n\t\twriter.writeBuffer.Reset()\n\t\t//b.StartTimer()\n\t\twriter.writeToBuffer(msg)\n\t}\n}\n\nfunc BenchmarkWritePieceMsg(b *testing.B) {\n\tfor _, length := range benchmarkPieceLengths {\n\t\tb.Run(humanize.IBytes(uint64(length)), func(b *testing.B) {\n\t\t\tb.Run(\"ToBuffer\", func(b *testing.B) {\n\t\t\t\tb.SetBytes(int64(length))\n\t\t\t\trunBenchmarkWriteToBuffer(b, int64(length))\n\t\t\t})\n\t\t\tb.Run(\"MarshalBinary\", func(b *testing.B) {\n\t\t\t\tb.SetBytes(int64(length))\n\t\t\t\trunBenchmarkMarshalBinaryWrite(b, int64(length))\n\t\t\t})\n\t\t})\n\t}\n}\n\nfunc runBenchmarkMarshalBinaryWrite(b *testing.B, length int64) {\n\twriter := &peerConnMsgWriter{\n\t\twriteBuffer: &bytes.Buffer{},\n\t}\n\tmsg := PieceMsg(length)\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t//b.StopTimer()\n\t\twriter.writeBuffer.Reset()\n\t\t//b.StartTimer()\n\t\twriter.writeBuffer.Write(msg.MustMarshalBinary())\n\t}\n}\n"
        },
        {
          "name": "peer-impl.go",
          "type": "blob",
          "size": 1.2412109375,
          "content": "package torrent\n\nimport (\n\t\"github.com/RoaringBitmap/roaring\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\n// Contains implementation details that differ between peer types, like Webseeds and regular\n// BitTorrent protocol connections. Some methods are underlined so as to avoid collisions with\n// legacy PeerConn methods.\ntype peerImpl interface {\n\t// Trigger the actual request state to get updated\n\thandleUpdateRequests()\n\twriteInterested(interested bool) bool\n\n\t// _cancel initiates cancellation of a request and returns acked if it expects the cancel to be\n\t// handled by a follow-up event.\n\t_cancel(RequestIndex) (acked bool)\n\t_request(Request) bool\n\tconnectionFlags() string\n\tonClose()\n\tonGotInfo(*metainfo.Info)\n\t// Drop connection. This may be a no-op if there is no connection.\n\tdrop()\n\t// Rebuke the peer\n\tban()\n\tString() string\n\tpeerImplStatusLines() []string\n\n\t// All if the peer should have everything, known if we know that for a fact. For example, we can\n\t// guess at how many pieces are in a torrent, and assume they have all pieces based on them\n\t// having sent haves for everything, but we don't know for sure. But if they send a have-all\n\t// message, then it's clear that they do.\n\tpeerHasAllPieces() (all, known bool)\n\tpeerPieces() *roaring.Bitmap\n}\n"
        },
        {
          "name": "peer.go",
          "type": "blob",
          "size": 25.33203125,
          "content": "package torrent\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/anacrolix/chansync\"\n\t. \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/iter\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\t\"github.com/anacrolix/multiless\"\n\n\t\"github.com/anacrolix/torrent/internal/alloclim\"\n\t\"github.com/anacrolix/torrent/mse\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n\ttypedRoaring \"github.com/anacrolix/torrent/typed-roaring\"\n)\n\ntype (\n\tPeer struct {\n\t\t// First to ensure 64-bit alignment for atomics. See #262.\n\t\t_stats ConnStats\n\n\t\tt *Torrent\n\n\t\tpeerImpl\n\t\tcallbacks *Callbacks\n\n\t\toutgoing   bool\n\t\tNetwork    string\n\t\tRemoteAddr PeerRemoteAddr\n\t\t// The local address as observed by the remote peer. WebRTC seems to get this right without needing hints from the\n\t\t// config.\n\t\tlocalPublicAddr peerLocalPublicAddr\n\t\tbannableAddr    Option[bannableAddr]\n\t\t// True if the connection is operating over MSE obfuscation.\n\t\theaderEncrypted bool\n\t\tcryptoMethod    mse.CryptoMethod\n\t\tDiscovery       PeerSource\n\t\ttrusted         bool\n\t\tclosed          chansync.SetOnce\n\t\t// Set true after we've added our ConnStats generated during handshake to\n\t\t// other ConnStat instances as determined when the *Torrent became known.\n\t\treconciledHandshakeStats bool\n\n\t\tlastMessageReceived     time.Time\n\t\tcompletedHandshake      time.Time\n\t\tlastUsefulChunkReceived time.Time\n\t\tlastChunkSent           time.Time\n\n\t\t// Stuff controlled by the local peer.\n\t\tneedRequestUpdate    updateRequestReason\n\t\trequestState         request_strategy.PeerRequestState\n\t\tupdateRequestsTimer  *time.Timer\n\t\tlastRequestUpdate    time.Time\n\t\tpeakRequests         maxRequests\n\t\tlastBecameInterested time.Time\n\t\tpriorInterest        time.Duration\n\n\t\tlastStartedExpectingToReceiveChunks time.Time\n\t\tcumulativeExpectedToReceiveChunks   time.Duration\n\t\t_chunksReceivedWhileExpecting       int64\n\n\t\tchoking                                bool\n\t\tpiecesReceivedSinceLastRequestUpdate   maxRequests\n\t\tmaxPiecesReceivedBetweenRequestUpdates maxRequests\n\t\t// Chunks that we might reasonably expect to receive from the peer. Due to latency, buffering,\n\t\t// and implementation differences, we may receive chunks that are no longer in the set of\n\t\t// requests actually want. This could use a roaring.BSI if the memory use becomes noticeable.\n\t\tvalidReceiveChunks map[RequestIndex]int\n\t\t// Indexed by metadata piece, set to true if posted and pending a\n\t\t// response.\n\t\tmetadataRequests []bool\n\t\tsentHaves        bitmap.Bitmap\n\n\t\t// Stuff controlled by the remote peer.\n\t\tpeerInterested        bool\n\t\tpeerChoking           bool\n\t\tpeerRequests          map[Request]*peerRequestState\n\t\tPeerPrefersEncryption bool // as indicated by 'e' field in extension handshake\n\t\t// The highest possible number of pieces the torrent could have based on\n\t\t// communication with the peer. Generally only useful until we have the\n\t\t// torrent info.\n\t\tpeerMinPieces pieceIndex\n\t\t// Pieces we've accepted chunks for from the peer.\n\t\tpeerTouchedPieces map[pieceIndex]struct{}\n\t\tpeerAllowedFast   typedRoaring.Bitmap[pieceIndex]\n\n\t\tPeerMaxRequests maxRequests // Maximum pending requests the peer allows.\n\n\t\tlogger log.Logger\n\t}\n\n\tPeerSource string\n\n\tpeerRequestState struct {\n\t\tdata             []byte\n\t\tallocReservation *alloclim.Reservation\n\t}\n\n\tPeerRemoteAddr interface {\n\t\tString() string\n\t}\n\n\tpeerRequests = orderedBitmap[RequestIndex]\n\n\tupdateRequestReason string\n)\n\nconst (\n\tPeerSourceUtHolepunch     = \"C\"\n\tPeerSourceTracker         = \"Tr\"\n\tPeerSourceIncoming        = \"I\"\n\tPeerSourceDhtGetPeers     = \"Hg\" // Peers we found by searching a DHT.\n\tPeerSourceDhtAnnouncePeer = \"Ha\" // Peers that were announced to us by a DHT.\n\tPeerSourcePex             = \"X\"\n\t// The peer was given directly, such as through a magnet link.\n\tPeerSourceDirect = \"M\"\n)\n\n// These are grouped because we might vary update request behaviour depending on the reason. I'm not\n// sure about the fact that multiple reasons can be triggered before an update runs, and only the\n// first will count. Possibly we should be signalling what behaviours are appropriate in the next\n// update instead.\nconst (\n\tpeerUpdateRequestsPeerCancelReason   updateRequestReason = \"Peer.cancel\"\n\tpeerUpdateRequestsRemoteRejectReason updateRequestReason = \"Peer.remoteRejectedRequest\"\n)\n\n// Returns the Torrent a Peer belongs to. Shouldn't change for the lifetime of the Peer. May be nil\n// if we are the receiving end of a connection and the handshake hasn't been received or accepted\n// yet.\nfunc (p *Peer) Torrent() *Torrent {\n\treturn p.t\n}\n\nfunc (p *Peer) initRequestState() {\n\tp.requestState.Requests = &peerRequests{}\n}\n\nfunc (cn *Peer) updateExpectingChunks() {\n\tif cn.expectingChunks() {\n\t\tif cn.lastStartedExpectingToReceiveChunks.IsZero() {\n\t\t\tcn.lastStartedExpectingToReceiveChunks = time.Now()\n\t\t}\n\t} else {\n\t\tif !cn.lastStartedExpectingToReceiveChunks.IsZero() {\n\t\t\tcn.cumulativeExpectedToReceiveChunks += time.Since(cn.lastStartedExpectingToReceiveChunks)\n\t\t\tcn.lastStartedExpectingToReceiveChunks = time.Time{}\n\t\t}\n\t}\n}\n\nfunc (cn *Peer) expectingChunks() bool {\n\tif cn.requestState.Requests.IsEmpty() {\n\t\treturn false\n\t}\n\tif !cn.requestState.Interested {\n\t\treturn false\n\t}\n\tif !cn.peerChoking {\n\t\treturn true\n\t}\n\thaveAllowedFastRequests := false\n\tcn.peerAllowedFast.Iterate(func(i pieceIndex) bool {\n\t\thaveAllowedFastRequests = roaringBitmapRangeCardinality[RequestIndex](\n\t\t\tcn.requestState.Requests,\n\t\t\tcn.t.pieceRequestIndexOffset(i),\n\t\t\tcn.t.pieceRequestIndexOffset(i+1),\n\t\t) == 0\n\t\treturn !haveAllowedFastRequests\n\t})\n\treturn haveAllowedFastRequests\n}\n\nfunc (cn *Peer) remoteChokingPiece(piece pieceIndex) bool {\n\treturn cn.peerChoking && !cn.peerAllowedFast.Contains(piece)\n}\n\nfunc (cn *Peer) cumInterest() time.Duration {\n\tret := cn.priorInterest\n\tif cn.requestState.Interested {\n\t\tret += time.Since(cn.lastBecameInterested)\n\t}\n\treturn ret\n}\n\nfunc (cn *Peer) locker() *lockWithDeferreds {\n\treturn cn.t.cl.locker()\n}\n\nfunc (cn *PeerConn) supportsExtension(ext pp.ExtensionName) bool {\n\t_, ok := cn.PeerExtensionIDs[ext]\n\treturn ok\n}\n\n// The best guess at number of pieces in the torrent for this peer.\nfunc (cn *Peer) bestPeerNumPieces() pieceIndex {\n\tif cn.t.haveInfo() {\n\t\treturn cn.t.numPieces()\n\t}\n\treturn cn.peerMinPieces\n}\n\nfunc (cn *Peer) completedString() string {\n\thave := pieceIndex(cn.peerPieces().GetCardinality())\n\tif all, _ := cn.peerHasAllPieces(); all {\n\t\thave = cn.bestPeerNumPieces()\n\t}\n\treturn fmt.Sprintf(\"%d/%d\", have, cn.bestPeerNumPieces())\n}\n\nfunc eventAgeString(t time.Time) string {\n\tif t.IsZero() {\n\t\treturn \"never\"\n\t}\n\treturn fmt.Sprintf(\"%.2fs ago\", time.Since(t).Seconds())\n}\n\n// Inspired by https://github.com/transmission/transmission/wiki/Peer-Status-Text.\nfunc (cn *Peer) statusFlags() (ret string) {\n\tc := func(b byte) {\n\t\tret += string([]byte{b})\n\t}\n\tif cn.requestState.Interested {\n\t\tc('i')\n\t}\n\tif cn.choking {\n\t\tc('c')\n\t}\n\tc(':')\n\tret += cn.connectionFlags()\n\tc(':')\n\tif cn.peerInterested {\n\t\tc('i')\n\t}\n\tif cn.peerChoking {\n\t\tc('c')\n\t}\n\treturn\n}\n\nfunc (cn *Peer) downloadRate() float64 {\n\tnum := cn._stats.BytesReadUsefulData.Int64()\n\tif num == 0 {\n\t\treturn 0\n\t}\n\treturn float64(num) / cn.totalExpectingTime().Seconds()\n}\n\nfunc (p *Peer) DownloadRate() float64 {\n\tp.locker().RLock()\n\tdefer p.locker().RUnlock()\n\n\treturn p.downloadRate()\n}\n\nfunc (cn *Peer) iterContiguousPieceRequests(f func(piece pieceIndex, count int)) {\n\tvar last Option[pieceIndex]\n\tvar count int\n\tnext := func(item Option[pieceIndex]) {\n\t\tif item == last {\n\t\t\tcount++\n\t\t} else {\n\t\t\tif count != 0 {\n\t\t\t\tf(last.Value, count)\n\t\t\t}\n\t\t\tlast = item\n\t\t\tcount = 1\n\t\t}\n\t}\n\tcn.requestState.Requests.Iterate(func(requestIndex request_strategy.RequestIndex) bool {\n\t\tnext(Some(cn.t.pieceIndexOfRequestIndex(requestIndex)))\n\t\treturn true\n\t})\n\tnext(None[pieceIndex]())\n}\n\nfunc (cn *Peer) writeStatus(w io.Writer) {\n\t// \\t isn't preserved in <pre> blocks?\n\tif cn.closed.IsSet() {\n\t\tfmt.Fprint(w, \"CLOSED: \")\n\t}\n\tfmt.Fprintln(w, strings.Join(cn.peerImplStatusLines(), \"\\n\"))\n\tprio, err := cn.peerPriority()\n\tprioStr := fmt.Sprintf(\"%08x\", prio)\n\tif err != nil {\n\t\tprioStr += \": \" + err.Error()\n\t}\n\tfmt.Fprintf(w, \"bep40-prio: %v\\n\", prioStr)\n\tfmt.Fprintf(w, \"last msg: %s, connected: %s, last helpful: %s, itime: %s, etime: %s\\n\",\n\t\teventAgeString(cn.lastMessageReceived),\n\t\teventAgeString(cn.completedHandshake),\n\t\teventAgeString(cn.lastHelpful()),\n\t\tcn.cumInterest(),\n\t\tcn.totalExpectingTime(),\n\t)\n\tfmt.Fprintf(w,\n\t\t\"%s completed, %d pieces touched, good chunks: %v/%v:%v reqq: %d+%v/(%d/%d):%d/%d, flags: %s, dr: %.1f KiB/s\\n\",\n\t\tcn.completedString(),\n\t\tlen(cn.peerTouchedPieces),\n\t\t&cn._stats.ChunksReadUseful,\n\t\t&cn._stats.ChunksRead,\n\t\t&cn._stats.ChunksWritten,\n\t\tcn.requestState.Requests.GetCardinality(),\n\t\tcn.requestState.Cancelled.GetCardinality(),\n\t\tcn.nominalMaxRequests(),\n\t\tcn.PeerMaxRequests,\n\t\tlen(cn.peerRequests),\n\t\tlocalClientReqq,\n\t\tcn.statusFlags(),\n\t\tcn.downloadRate()/(1<<10),\n\t)\n\tfmt.Fprintf(w, \"requested pieces:\")\n\tcn.iterContiguousPieceRequests(func(piece pieceIndex, count int) {\n\t\tfmt.Fprintf(w, \" %v(%v)\", piece, count)\n\t})\n\tfmt.Fprintf(w, \"\\n\")\n}\n\nfunc (p *Peer) close() {\n\tif !p.closed.Set() {\n\t\treturn\n\t}\n\tif p.updateRequestsTimer != nil {\n\t\tp.updateRequestsTimer.Stop()\n\t}\n\tfor _, prs := range p.peerRequests {\n\t\tprs.allocReservation.Drop()\n\t}\n\tp.peerImpl.onClose()\n\tif p.t != nil {\n\t\tp.t.decPeerPieceAvailability(p)\n\t}\n\tfor _, f := range p.callbacks.PeerClosed {\n\t\tf(p)\n\t}\n}\n\nfunc (p *Peer) Close() error {\n\tp.locker().Lock()\n\tdefer p.locker().Unlock()\n\tp.close()\n\treturn nil\n}\n\n// Peer definitely has a piece, for purposes of requesting. So it's not sufficient that we think\n// they do (known=true).\nfunc (cn *Peer) peerHasPiece(piece pieceIndex) bool {\n\tif all, known := cn.peerHasAllPieces(); all && known {\n\t\treturn true\n\t}\n\treturn cn.peerPieces().ContainsInt(piece)\n}\n\n// 64KiB, but temporarily less to work around an issue with WebRTC. TODO: Update when\n// https://github.com/pion/datachannel/issues/59 is fixed.\nconst (\n\twriteBufferHighWaterLen = 1 << 15\n\twriteBufferLowWaterLen  = writeBufferHighWaterLen / 2\n)\n\nvar (\n\tinterestedMsgLen = len(pp.Message{Type: pp.Interested}.MustMarshalBinary())\n\trequestMsgLen    = len(pp.Message{Type: pp.Request}.MustMarshalBinary())\n\t// This is the maximum request count that could fit in the write buffer if it's at or below the\n\t// low water mark when we run maybeUpdateActualRequestState.\n\tmaxLocalToRemoteRequests = (writeBufferHighWaterLen - writeBufferLowWaterLen - interestedMsgLen) / requestMsgLen\n)\n\n// The actual value to use as the maximum outbound requests.\nfunc (cn *Peer) nominalMaxRequests() maxRequests {\n\treturn maxInt(1, minInt(cn.PeerMaxRequests, cn.peakRequests*2, maxLocalToRemoteRequests))\n}\n\nfunc (cn *Peer) totalExpectingTime() (ret time.Duration) {\n\tret = cn.cumulativeExpectedToReceiveChunks\n\tif !cn.lastStartedExpectingToReceiveChunks.IsZero() {\n\t\tret += time.Since(cn.lastStartedExpectingToReceiveChunks)\n\t}\n\treturn\n}\n\nfunc (cn *Peer) setInterested(interested bool) bool {\n\tif cn.requestState.Interested == interested {\n\t\treturn true\n\t}\n\tcn.requestState.Interested = interested\n\tif interested {\n\t\tcn.lastBecameInterested = time.Now()\n\t} else if !cn.lastBecameInterested.IsZero() {\n\t\tcn.priorInterest += time.Since(cn.lastBecameInterested)\n\t}\n\tcn.updateExpectingChunks()\n\t// log.Printf(\"%p: setting interest: %v\", cn, interested)\n\treturn cn.writeInterested(interested)\n}\n\n// The function takes a message to be sent, and returns true if more messages\n// are okay.\ntype messageWriter func(pp.Message) bool\n\n// This function seems to only used by Peer.request. It's all logic checks, so maybe we can no-op it\n// when we want to go fast.\nfunc (cn *Peer) shouldRequest(r RequestIndex) error {\n\terr := cn.t.checkValidReceiveChunk(cn.t.requestIndexToRequest(r))\n\tif err != nil {\n\t\treturn err\n\t}\n\tpi := cn.t.pieceIndexOfRequestIndex(r)\n\tif cn.requestState.Cancelled.Contains(r) {\n\t\treturn errors.New(\"request is cancelled and waiting acknowledgement\")\n\t}\n\tif !cn.peerHasPiece(pi) {\n\t\treturn errors.New(\"requesting piece peer doesn't have\")\n\t}\n\tif !cn.t.peerIsActive(cn) {\n\t\tpanic(\"requesting but not in active conns\")\n\t}\n\tif cn.closed.IsSet() {\n\t\tpanic(\"requesting when connection is closed\")\n\t}\n\tif cn.t.hashingPiece(pi) {\n\t\tpanic(\"piece is being hashed\")\n\t}\n\tif cn.t.pieceQueuedForHash(pi) {\n\t\tpanic(\"piece is queued for hash\")\n\t}\n\tif cn.peerChoking && !cn.peerAllowedFast.Contains(pi) {\n\t\t// This could occur if we made a request with the fast extension, and then got choked and\n\t\t// haven't had the request rejected yet.\n\t\tif !cn.requestState.Requests.Contains(r) {\n\t\t\tpanic(\"peer choking and piece not allowed fast\")\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (cn *Peer) mustRequest(r RequestIndex) bool {\n\tmore, err := cn.request(r)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn more\n}\n\nfunc (cn *Peer) request(r RequestIndex) (more bool, err error) {\n\tif err := cn.shouldRequest(r); err != nil {\n\t\tpanic(err)\n\t}\n\tif cn.requestState.Requests.Contains(r) {\n\t\treturn true, nil\n\t}\n\tif maxRequests(cn.requestState.Requests.GetCardinality()) >= cn.nominalMaxRequests() {\n\t\treturn true, errors.New(\"too many outstanding requests\")\n\t}\n\tcn.requestState.Requests.Add(r)\n\tif cn.validReceiveChunks == nil {\n\t\tcn.validReceiveChunks = make(map[RequestIndex]int)\n\t}\n\tcn.validReceiveChunks[r]++\n\tcn.t.requestState[r] = requestState{\n\t\tpeer: cn,\n\t\twhen: time.Now(),\n\t}\n\tcn.updateExpectingChunks()\n\tppReq := cn.t.requestIndexToRequest(r)\n\tfor _, f := range cn.callbacks.SentRequest {\n\t\tf(PeerRequestEvent{cn, ppReq})\n\t}\n\treturn cn.peerImpl._request(ppReq), nil\n}\n\nfunc (me *Peer) cancel(r RequestIndex) {\n\tif !me.deleteRequest(r) {\n\t\tpanic(\"request not existing should have been guarded\")\n\t}\n\tif me._cancel(r) {\n\t\t// Record that we expect to get a cancel ack.\n\t\tif !me.requestState.Cancelled.CheckedAdd(r) {\n\t\t\tpanic(\"request already cancelled\")\n\t\t}\n\t}\n\tme.decPeakRequests()\n\tif me.isLowOnRequests() {\n\t\tme.updateRequests(peerUpdateRequestsPeerCancelReason)\n\t}\n}\n\n// Sets a reason to update requests, and if there wasn't already one, handle it.\nfunc (cn *Peer) updateRequests(reason updateRequestReason) {\n\tif cn.needRequestUpdate != \"\" {\n\t\treturn\n\t}\n\tcn.needRequestUpdate = reason\n\tcn.handleUpdateRequests()\n}\n\n// Emits the indices in the Bitmaps bms in order, never repeating any index.\n// skip is mutated during execution, and its initial values will never be\n// emitted.\nfunc iterBitmapsDistinct(skip *bitmap.Bitmap, bms ...bitmap.Bitmap) iter.Func {\n\treturn func(cb iter.Callback) {\n\t\tfor _, bm := range bms {\n\t\t\tif !iter.All(\n\t\t\t\tfunc(_i interface{}) bool {\n\t\t\t\t\ti := _i.(int)\n\t\t\t\t\tif skip.Contains(bitmap.BitIndex(i)) {\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t\tskip.Add(bitmap.BitIndex(i))\n\t\t\t\t\treturn cb(i)\n\t\t\t\t},\n\t\t\t\tbm.Iter,\n\t\t\t) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\n// After handshake, we know what Torrent and Client stats to include for a\n// connection.\nfunc (cn *Peer) postHandshakeStats(f func(*ConnStats)) {\n\tt := cn.t\n\tf(&t.stats)\n\tf(&t.cl.connStats)\n}\n\n// All ConnStats that include this connection. Some objects are not known\n// until the handshake is complete, after which it's expected to reconcile the\n// differences.\nfunc (cn *Peer) allStats(f func(*ConnStats)) {\n\tf(&cn._stats)\n\tif cn.reconciledHandshakeStats {\n\t\tcn.postHandshakeStats(f)\n\t}\n}\n\nfunc (cn *Peer) readBytes(n int64) {\n\tcn.allStats(add(n, func(cs *ConnStats) *Count { return &cs.BytesRead }))\n}\n\nfunc (c *Peer) lastHelpful() (ret time.Time) {\n\tret = c.lastUsefulChunkReceived\n\tif c.t.seeding() && c.lastChunkSent.After(ret) {\n\t\tret = c.lastChunkSent\n\t}\n\treturn\n}\n\n// Returns whether any part of the chunk would lie outside a piece of the given length.\nfunc chunkOverflowsPiece(cs ChunkSpec, pieceLength pp.Integer) bool {\n\tswitch {\n\tdefault:\n\t\treturn false\n\tcase cs.Begin+cs.Length > pieceLength:\n\t// Check for integer overflow\n\tcase cs.Begin > pp.IntegerMax-cs.Length:\n\t}\n\treturn true\n}\n\nfunc runSafeExtraneous(f func()) {\n\tif true {\n\t\tgo f()\n\t} else {\n\t\tf()\n\t}\n}\n\n// Returns true if it was valid to reject the request.\nfunc (c *Peer) remoteRejectedRequest(r RequestIndex) bool {\n\tif c.deleteRequest(r) {\n\t\tc.decPeakRequests()\n\t} else if !c.requestState.Cancelled.CheckedRemove(r) {\n\t\treturn false\n\t}\n\tif c.isLowOnRequests() {\n\t\tc.updateRequests(peerUpdateRequestsRemoteRejectReason)\n\t}\n\tc.decExpectedChunkReceive(r)\n\treturn true\n}\n\nfunc (c *Peer) decExpectedChunkReceive(r RequestIndex) {\n\tcount := c.validReceiveChunks[r]\n\tif count == 1 {\n\t\tdelete(c.validReceiveChunks, r)\n\t} else if count > 1 {\n\t\tc.validReceiveChunks[r] = count - 1\n\t} else {\n\t\tpanic(r)\n\t}\n}\n\nfunc (c *Peer) doChunkReadStats(size int64) {\n\tc.allStats(func(cs *ConnStats) { cs.receivedChunk(size) })\n}\n\n// Handle a received chunk from a peer.\nfunc (c *Peer) receiveChunk(msg *pp.Message) error {\n\tChunksReceived.Add(\"total\", 1)\n\n\tppReq := newRequestFromMessage(msg)\n\tt := c.t\n\terr := t.checkValidReceiveChunk(ppReq)\n\tif err != nil {\n\t\terr = log.WithLevel(log.Warning, err)\n\t\treturn err\n\t}\n\treq := c.t.requestIndexFromRequest(ppReq)\n\n\trecordBlockForSmartBan := sync.OnceFunc(func() {\n\t\tc.recordBlockForSmartBan(req, msg.Piece)\n\t})\n\t// This needs to occur before we return, but we try to do it when the client is unlocked. It\n\t// can't be done before checking if chunks are valid because they won't be deallocated by piece\n\t// hashing if they're out of bounds.\n\tdefer recordBlockForSmartBan()\n\n\tif c.peerChoking {\n\t\tChunksReceived.Add(\"while choked\", 1)\n\t}\n\n\tif c.validReceiveChunks[req] <= 0 {\n\t\tChunksReceived.Add(\"unexpected\", 1)\n\t\treturn errors.New(\"received unexpected chunk\")\n\t}\n\tc.decExpectedChunkReceive(req)\n\n\tif c.peerChoking && c.peerAllowedFast.Contains(pieceIndex(ppReq.Index)) {\n\t\tChunksReceived.Add(\"due to allowed fast\", 1)\n\t}\n\n\t// The request needs to be deleted immediately to prevent cancels occurring asynchronously when\n\t// have actually already received the piece, while we have the Client unlocked to write the data\n\t// out.\n\tintended := false\n\t{\n\t\tif c.requestState.Requests.Contains(req) {\n\t\t\tfor _, f := range c.callbacks.ReceivedRequested {\n\t\t\t\tf(PeerMessageEvent{c, msg})\n\t\t\t}\n\t\t}\n\t\t// Request has been satisfied.\n\t\tif c.deleteRequest(req) || c.requestState.Cancelled.CheckedRemove(req) {\n\t\t\tintended = true\n\t\t\tif !c.peerChoking {\n\t\t\t\tc._chunksReceivedWhileExpecting++\n\t\t\t}\n\t\t\tif c.isLowOnRequests() {\n\t\t\t\tc.updateRequests(\"Peer.receiveChunk deleted request\")\n\t\t\t}\n\t\t} else {\n\t\t\tChunksReceived.Add(\"unintended\", 1)\n\t\t}\n\t}\n\n\tcl := t.cl\n\n\t// Do we actually want this chunk?\n\tif t.haveChunk(ppReq) {\n\t\t// panic(fmt.Sprintf(\"%+v\", ppReq))\n\t\tChunksReceived.Add(\"redundant\", 1)\n\t\tc.allStats(add(1, func(cs *ConnStats) *Count { return &cs.ChunksReadWasted }))\n\t\treturn nil\n\t}\n\n\tpiece := &t.pieces[ppReq.Index]\n\n\tc.allStats(add(1, func(cs *ConnStats) *Count { return &cs.ChunksReadUseful }))\n\tc.allStats(add(int64(len(msg.Piece)), func(cs *ConnStats) *Count { return &cs.BytesReadUsefulData }))\n\tif intended {\n\t\tc.piecesReceivedSinceLastRequestUpdate++\n\t\tc.allStats(add(int64(len(msg.Piece)), func(cs *ConnStats) *Count { return &cs.BytesReadUsefulIntendedData }))\n\t}\n\tfor _, f := range c.t.cl.config.Callbacks.ReceivedUsefulData {\n\t\tf(ReceivedUsefulDataEvent{c, msg})\n\t}\n\tc.lastUsefulChunkReceived = time.Now()\n\n\t// Need to record that it hasn't been written yet, before we attempt to do\n\t// anything with it.\n\tpiece.incrementPendingWrites()\n\t// Record that we have the chunk, so we aren't trying to download it while\n\t// waiting for it to be written to storage.\n\tpiece.unpendChunkIndex(chunkIndexFromChunkSpec(ppReq.ChunkSpec, t.chunkSize))\n\n\t// Cancel pending requests for this chunk from *other* peers.\n\tif p := t.requestingPeer(req); p != nil {\n\t\tif p == c {\n\t\t\tpanic(\"should not be pending request from conn that just received it\")\n\t\t}\n\t\tp.cancel(req)\n\t}\n\n\terr = func() error {\n\t\tcl.unlock()\n\t\tdefer cl.lock()\n\t\t// Opportunistically do this here while we aren't holding the client lock.\n\t\trecordBlockForSmartBan()\n\t\tconcurrentChunkWrites.Add(1)\n\t\tdefer concurrentChunkWrites.Add(-1)\n\t\t// Write the chunk out. Note that the upper bound on chunk writing concurrency will be the\n\t\t// number of connections. We write inline with receiving the chunk (with this lock dance),\n\t\t// because we want to handle errors synchronously and I haven't thought of a nice way to\n\t\t// defer any concurrency to the storage and have that notify the client of errors. TODO: Do\n\t\t// that instead.\n\t\treturn t.writeChunk(int(msg.Index), int64(msg.Begin), msg.Piece)\n\t}()\n\n\tpiece.decrementPendingWrites()\n\n\tif err != nil {\n\t\tc.logger.WithDefaultLevel(log.Error).Printf(\"writing received chunk %v: %v\", req, err)\n\t\tt.pendRequest(req)\n\t\t// Necessary to pass TestReceiveChunkStorageFailureSeederFastExtensionDisabled. I think a\n\t\t// request update runs while we're writing the chunk that just failed. Then we never do a\n\t\t// fresh update after pending the failed request.\n\t\tc.updateRequests(\"Peer.receiveChunk error writing chunk\")\n\t\tt.onWriteChunkErr(err)\n\t\treturn nil\n\t}\n\n\tc.onDirtiedPiece(pieceIndex(ppReq.Index))\n\n\t// We need to ensure the piece is only queued once, so only the last chunk writer gets this job.\n\tif t.pieceAllDirty(pieceIndex(ppReq.Index)) && piece.pendingWrites == 0 {\n\t\tt.queuePieceCheck(pieceIndex(ppReq.Index))\n\t\t// We don't pend all chunks here anymore because we don't want code dependent on the dirty\n\t\t// chunk status (such as the haveChunk call above) to have to check all the various other\n\t\t// piece states like queued for hash, hashing etc. This does mean that we need to be sure\n\t\t// that chunk pieces are pended at an appropriate time later however.\n\t}\n\n\tcl.event.Broadcast()\n\t// We do this because we've written a chunk, and may change PieceState.Partial.\n\tt.publishPieceStateChange(pieceIndex(ppReq.Index))\n\n\treturn nil\n}\n\nfunc (c *Peer) onDirtiedPiece(piece pieceIndex) {\n\tif c.peerTouchedPieces == nil {\n\t\tc.peerTouchedPieces = make(map[pieceIndex]struct{})\n\t}\n\tc.peerTouchedPieces[piece] = struct{}{}\n\tds := &c.t.pieces[piece].dirtiers\n\tif *ds == nil {\n\t\t*ds = make(map[*Peer]struct{})\n\t}\n\t(*ds)[c] = struct{}{}\n}\n\nfunc (cn *Peer) netGoodPiecesDirtied() int64 {\n\treturn cn._stats.PiecesDirtiedGood.Int64() - cn._stats.PiecesDirtiedBad.Int64()\n}\n\nfunc (c *Peer) peerHasWantedPieces() bool {\n\tif all, _ := c.peerHasAllPieces(); all {\n\t\treturn !c.t.haveAllPieces() && !c.t._pendingPieces.IsEmpty()\n\t}\n\tif !c.t.haveInfo() {\n\t\treturn !c.peerPieces().IsEmpty()\n\t}\n\treturn c.peerPieces().Intersects(&c.t._pendingPieces)\n}\n\n// Returns true if an outstanding request is removed. Cancelled requests should be handled\n// separately.\nfunc (c *Peer) deleteRequest(r RequestIndex) bool {\n\tif !c.requestState.Requests.CheckedRemove(r) {\n\t\treturn false\n\t}\n\tfor _, f := range c.callbacks.DeletedRequest {\n\t\tf(PeerRequestEvent{c, c.t.requestIndexToRequest(r)})\n\t}\n\tc.updateExpectingChunks()\n\tif c.t.requestingPeer(r) != c {\n\t\tpanic(\"only one peer should have a given request at a time\")\n\t}\n\tdelete(c.t.requestState, r)\n\t// c.t.iterPeers(func(p *Peer) {\n\t// \tif p.isLowOnRequests() {\n\t// \t\tp.updateRequests(\"Peer.deleteRequest\")\n\t// \t}\n\t// })\n\treturn true\n}\n\nfunc (c *Peer) deleteAllRequests(reason updateRequestReason) {\n\tif c.requestState.Requests.IsEmpty() {\n\t\treturn\n\t}\n\tc.requestState.Requests.IterateSnapshot(func(x RequestIndex) bool {\n\t\tif !c.deleteRequest(x) {\n\t\t\tpanic(\"request should exist\")\n\t\t}\n\t\treturn true\n\t})\n\tc.assertNoRequests()\n\tc.t.iterPeers(func(p *Peer) {\n\t\tif p.isLowOnRequests() {\n\t\t\tp.updateRequests(reason)\n\t\t}\n\t})\n\treturn\n}\n\nfunc (c *Peer) assertNoRequests() {\n\tif !c.requestState.Requests.IsEmpty() {\n\t\tpanic(c.requestState.Requests.GetCardinality())\n\t}\n}\n\nfunc (c *Peer) cancelAllRequests() {\n\tc.requestState.Requests.IterateSnapshot(func(x RequestIndex) bool {\n\t\tc.cancel(x)\n\t\treturn true\n\t})\n\tc.assertNoRequests()\n\treturn\n}\n\nfunc (c *Peer) peerPriority() (peerPriority, error) {\n\treturn bep40Priority(c.remoteIpPort(), c.localPublicAddr)\n}\n\nfunc (c *Peer) remoteIp() net.IP {\n\thost, _, _ := net.SplitHostPort(c.RemoteAddr.String())\n\treturn net.ParseIP(host)\n}\n\nfunc (c *Peer) remoteIpPort() IpPort {\n\tipa, _ := tryIpPortFromNetAddr(c.RemoteAddr)\n\treturn IpPort{ipa.IP, uint16(ipa.Port)}\n}\n\nfunc (c *Peer) trust() connectionTrust {\n\treturn connectionTrust{c.trusted, c.netGoodPiecesDirtied()}\n}\n\ntype connectionTrust struct {\n\tImplicit            bool\n\tNetGoodPiecesDirted int64\n}\n\nfunc (l connectionTrust) Cmp(r connectionTrust) int {\n\treturn multiless.New().Bool(l.Implicit, r.Implicit).Int64(l.NetGoodPiecesDirted, r.NetGoodPiecesDirted).OrderingInt()\n}\n\n// Returns a new Bitmap that includes bits for all pieces the peer could have based on their claims.\nfunc (cn *Peer) newPeerPieces() *roaring.Bitmap {\n\t// TODO: Can we use copy on write?\n\tret := cn.peerPieces().Clone()\n\tif all, _ := cn.peerHasAllPieces(); all {\n\t\tif cn.t.haveInfo() {\n\t\t\tret.AddRange(0, bitmap.BitRange(cn.t.numPieces()))\n\t\t} else {\n\t\t\tret.AddRange(0, bitmap.ToEnd)\n\t\t}\n\t}\n\treturn ret\n}\n\nfunc (cn *Peer) stats() *ConnStats {\n\treturn &cn._stats\n}\n\nfunc (p *Peer) TryAsPeerConn() (*PeerConn, bool) {\n\tpc, ok := p.peerImpl.(*PeerConn)\n\treturn pc, ok\n}\n\nfunc (p *Peer) uncancelledRequests() uint64 {\n\treturn p.requestState.Requests.GetCardinality()\n}\n\ntype peerLocalPublicAddr = IpPort\n\nfunc (p *Peer) isLowOnRequests() bool {\n\treturn p.requestState.Requests.IsEmpty() && p.requestState.Cancelled.IsEmpty()\n}\n\nfunc (p *Peer) decPeakRequests() {\n\t// // This can occur when peak requests are altered by the update request timer to be lower than\n\t// // the actual number of outstanding requests. Let's let it go negative and see what happens. I\n\t// // wonder what happens if maxRequests is not signed.\n\t// if p.peakRequests < 1 {\n\t// \tpanic(p.peakRequests)\n\t// }\n\tp.peakRequests--\n}\n\nfunc (p *Peer) recordBlockForSmartBan(req RequestIndex, blockData []byte) {\n\tif p.bannableAddr.Ok {\n\t\tp.t.smartBanCache.RecordBlock(p.bannableAddr.Value, req, blockData)\n\t}\n}\n"
        },
        {
          "name": "peer_info.go",
          "type": "blob",
          "size": 1.1689453125,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\n\t\"github.com/anacrolix/torrent/peer_protocol\"\n)\n\n// Peer connection info, handed about publicly.\ntype PeerInfo struct {\n\tId     [20]byte\n\tAddr   PeerRemoteAddr\n\tSource PeerSource\n\t// Peer is known to support encryption.\n\tSupportsEncryption bool\n\tpeer_protocol.PexPeerFlags\n\t// Whether we can ignore poor or bad behaviour from the peer.\n\tTrusted bool\n}\n\nfunc (me PeerInfo) equal(other PeerInfo) bool {\n\treturn me.Id == other.Id &&\n\t\tme.Addr.String() == other.Addr.String() &&\n\t\tme.Source == other.Source &&\n\t\tme.SupportsEncryption == other.SupportsEncryption &&\n\t\tme.PexPeerFlags == other.PexPeerFlags &&\n\t\tme.Trusted == other.Trusted\n}\n\n// Generate PeerInfo from peer exchange\nfunc (me *PeerInfo) FromPex(na krpc.NodeAddr, fs peer_protocol.PexPeerFlags) {\n\tme.Addr = ipPortAddr{append([]byte(nil), na.IP...), na.Port}\n\tme.Source = PeerSourcePex\n\t// If they prefer encryption, they must support it.\n\tif fs.Get(peer_protocol.PexPrefersEncryption) {\n\t\tme.SupportsEncryption = true\n\t}\n\tme.PexPeerFlags = fs\n}\n\nfunc (me PeerInfo) addr() IpPort {\n\tipPort, _ := tryIpPortFromNetAddr(me.Addr)\n\treturn IpPort{ipPort.IP, uint16(ipPort.Port)}\n}\n"
        },
        {
          "name": "peer_infos.go",
          "type": "blob",
          "size": 0.7080078125,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\n\t\"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/tracker\"\n)\n\n// Helper-type used to bulk-manage PeerInfos.\ntype peerInfos []PeerInfo\n\nfunc (me *peerInfos) AppendFromPex(nas []krpc.NodeAddr, fs []peer_protocol.PexPeerFlags) {\n\tfor i, na := range nas {\n\t\tvar p PeerInfo\n\t\tvar f peer_protocol.PexPeerFlags\n\t\tif i < len(fs) {\n\t\t\tf = fs[i]\n\t\t}\n\t\tp.FromPex(na, f)\n\t\t*me = append(*me, p)\n\t}\n}\n\nfunc (ret peerInfos) AppendFromTracker(ps []tracker.Peer) peerInfos {\n\tfor _, p := range ps {\n\t\t_p := PeerInfo{\n\t\t\tAddr:   ipPortAddr{p.IP, p.Port},\n\t\t\tSource: PeerSourceTracker,\n\t\t}\n\t\tcopy(_p.Id[:], p.ID)\n\t\tret = append(ret, _p)\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "peer_protocol",
          "type": "tree",
          "content": null
        },
        {
          "name": "peerconn.go",
          "type": "blob",
          "size": 40.34375,
          "content": "package torrent\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/netip\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/anacrolix/generics\"\n\t. \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\t\"github.com/anacrolix/multiless\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/internal/alloclim\"\n\t\"github.com/anacrolix/torrent/merkle\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\t\"github.com/anacrolix/torrent/mse\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\tutHolepunch \"github.com/anacrolix/torrent/peer_protocol/ut-holepunch\"\n)\n\n// Maintains the state of a BitTorrent-protocol based connection with a peer.\ntype PeerConn struct {\n\tPeer\n\n\t// Move to PeerConn?\n\tprotocolLogger log.Logger\n\n\t// BEP 52\n\tv2 bool\n\n\t// A string that should identify the PeerConn's net.Conn endpoints. The net.Conn could\n\t// be wrapping WebRTC, uTP, or TCP etc. Used in writing the conn status for peers.\n\tconnString string\n\n\t// See BEP 3 etc.\n\tPeerID             PeerID\n\tPeerExtensionBytes pp.PeerExtensionBits\n\tPeerListenPort     int\n\n\t// The local extended protocols to advertise in the extended handshake, and to support receiving\n\t// from the peer. This will point to the Client default when the PeerConnAdded callback is\n\t// invoked. Do not modify this, point it to your own instance. Do not modify the destination\n\t// after returning from the callback.\n\tLocalLtepProtocolMap *LocalLtepProtocolMap\n\n\t// The actual Conn, used for closing, and setting socket options. Do not use methods on this\n\t// while holding any mutexes.\n\tconn net.Conn\n\t// The Reader and Writer for this Conn, with hooks installed for stats,\n\t// limiting, deadlines etc.\n\tw io.Writer\n\tr io.Reader\n\n\tmessageWriter peerConnMsgWriter\n\n\t// The peer's extension map, as sent in their extended handshake.\n\tPeerExtensionIDs map[pp.ExtensionName]pp.ExtensionNumber\n\tPeerClientName   atomic.Value\n\tuploadTimer      *time.Timer\n\tpex              pexConnState\n\n\t// The pieces the peer has claimed to have.\n\t_peerPieces roaring.Bitmap\n\t// The peer has everything. This can occur due to a special message, when\n\t// we may not even know the number of pieces in the torrent yet.\n\tpeerSentHaveAll bool\n\n\tpeerRequestDataAllocLimiter alloclim.Limiter\n\n\toutstandingHolepunchingRendezvous map[netip.AddrPort]struct{}\n\n\t// Hash requests sent to the peer. If there's an issue we probably don't want to reissue these,\n\t// because I haven't implemented it smart enough yet.\n\tsentHashRequests map[hashRequest]struct{}\n\t// Hash pieces received from the peer, mapped from pieces root to piece layer hashes. This way\n\t// we can verify all the pieces for a file when they're all arrived before submitting them to\n\t// the torrent.\n\treceivedHashPieces map[[32]byte][][32]byte\n}\n\nfunc (cn *PeerConn) pexStatus() string {\n\tif !cn.bitExtensionEnabled(pp.ExtensionBitLtep) {\n\t\treturn \"extended protocol disabled\"\n\t}\n\tif cn.PeerExtensionIDs == nil {\n\t\treturn \"pending extended handshake\"\n\t}\n\tif !cn.supportsExtension(pp.ExtensionNamePex) {\n\t\treturn \"unsupported\"\n\t}\n\treturn fmt.Sprintf(\n\t\t\"%v conns, %v unsent events\",\n\t\tlen(cn.pex.remoteLiveConns),\n\t\tcn.pex.numPending(),\n\t)\n}\n\nfunc (cn *PeerConn) peerImplStatusLines() []string {\n\treturn []string{\n\t\tcn.connString,\n\t\tfmt.Sprintf(\"peer id: %+q\", cn.PeerID),\n\t\tfmt.Sprintf(\"extensions: %v\", cn.PeerExtensionBytes),\n\t\tfmt.Sprintf(\"ltep extensions: %v\", cn.PeerExtensionIDs),\n\t\tfmt.Sprintf(\"pex: %s\", cn.pexStatus()),\n\t}\n}\n\n// Returns true if the connection is over IPv6.\nfunc (cn *PeerConn) ipv6() bool {\n\tip := cn.remoteIp()\n\tif ip.To4() != nil {\n\t\treturn false\n\t}\n\treturn len(ip) == net.IPv6len\n}\n\n// Returns true the if the dialer/initiator has the higher client peer ID. See\n// https://github.com/arvidn/libtorrent/blame/272828e1cc37b042dfbbafa539222d8533e99755/src/bt_peer_connection.cpp#L3536-L3557.\n// As far as I can tell, Transmission just keeps the oldest connection.\nfunc (cn *PeerConn) isPreferredDirection() bool {\n\t// True if our client peer ID is higher than the remote's peer ID.\n\treturn bytes.Compare(cn.PeerID[:], cn.t.cl.peerID[:]) < 0 == cn.outgoing\n}\n\n// Returns whether the left connection should be preferred over the right one,\n// considering only their networking properties. If ok is false, we can't\n// decide.\nfunc (l *PeerConn) hasPreferredNetworkOver(r *PeerConn) bool {\n\tvar ml multiless.Computation\n\tml = ml.Bool(r.isPreferredDirection(), l.isPreferredDirection())\n\tml = ml.Bool(l.utp(), r.utp())\n\tml = ml.Bool(r.ipv6(), l.ipv6())\n\treturn ml.Less()\n}\n\nfunc (cn *PeerConn) peerHasAllPieces() (all, known bool) {\n\tif cn.peerSentHaveAll {\n\t\treturn true, true\n\t}\n\tif !cn.t.haveInfo() {\n\t\treturn false, false\n\t}\n\treturn cn._peerPieces.GetCardinality() == uint64(cn.t.numPieces()), true\n}\n\nfunc (cn *PeerConn) onGotInfo(info *metainfo.Info) {\n\tcn.setNumPieces(info.NumPieces())\n}\n\n// Correct the PeerPieces slice length. Return false if the existing slice is invalid, such as by\n// receiving badly sized BITFIELD, or invalid HAVE messages.\nfunc (cn *PeerConn) setNumPieces(num pieceIndex) {\n\tcn._peerPieces.RemoveRange(bitmap.BitRange(num), bitmap.ToEnd)\n\tcn.peerPiecesChanged()\n}\n\nfunc (cn *PeerConn) peerPieces() *roaring.Bitmap {\n\treturn &cn._peerPieces\n}\n\nfunc (cn *PeerConn) connectionFlags() string {\n\tvar sb strings.Builder\n\tadd := func(s string) {\n\t\tif sb.Len() > 0 {\n\t\t\tsb.WriteByte(',')\n\t\t}\n\t\tsb.WriteString(s)\n\t}\n\t// From first relevant to last.\n\tadd(string(cn.Discovery))\n\tif cn.utp() {\n\t\tadd(\"U\")\n\t}\n\tif cn.cryptoMethod == mse.CryptoMethodRC4 {\n\t\tadd(\"E\")\n\t} else if cn.headerEncrypted {\n\t\tadd(\"e\")\n\t}\n\tif cn.v2 {\n\t\tadd(\"v2\")\n\t} else {\n\t\tadd(\"v1\")\n\t}\n\treturn sb.String()\n}\n\nfunc (cn *PeerConn) utp() bool {\n\treturn parseNetworkString(cn.Network).Udp\n}\n\nfunc (cn *PeerConn) onClose() {\n\tif cn.pex.IsEnabled() {\n\t\tcn.pex.Close()\n\t}\n\tcn.tickleWriter()\n\tif cn.conn != nil {\n\t\tgo cn.conn.Close()\n\t}\n\tif cb := cn.callbacks.PeerConnClosed; cb != nil {\n\t\tcb(cn)\n\t}\n}\n\n// Writes a message into the write buffer. Returns whether it's okay to keep writing. Writing is\n// done asynchronously, so it may be that we're not able to honour backpressure from this method.\nfunc (cn *PeerConn) write(msg pp.Message) bool {\n\ttorrent.Add(fmt.Sprintf(\"messages written of type %s\", msg.Type.String()), 1)\n\t// We don't need to track bytes here because the connection's Writer has that behaviour injected\n\t// (although there's some delay between us buffering the message, and the connection writer\n\t// flushing it out.).\n\tnotFull := cn.messageWriter.write(msg)\n\t// Last I checked only Piece messages affect stats, and we don't write those.\n\tcn.wroteMsg(&msg)\n\tcn.tickleWriter()\n\treturn notFull\n}\n\nfunc (cn *PeerConn) requestMetadataPiece(index int) {\n\teID := cn.PeerExtensionIDs[pp.ExtensionNameMetadata]\n\tif eID == pp.ExtensionDeleteNumber {\n\t\treturn\n\t}\n\tif index < len(cn.metadataRequests) && cn.metadataRequests[index] {\n\t\treturn\n\t}\n\tcn.protocolLogger.WithDefaultLevel(log.Debug).Printf(\"requesting metadata piece %d\", index)\n\tcn.write(pp.MetadataExtensionRequestMsg(eID, index))\n\tfor index >= len(cn.metadataRequests) {\n\t\tcn.metadataRequests = append(cn.metadataRequests, false)\n\t}\n\tcn.metadataRequests[index] = true\n}\n\nfunc (cn *PeerConn) requestedMetadataPiece(index int) bool {\n\treturn index < len(cn.metadataRequests) && cn.metadataRequests[index]\n}\n\nfunc (cn *PeerConn) onPeerSentCancel(r Request) {\n\tif _, ok := cn.peerRequests[r]; !ok {\n\t\ttorrent.Add(\"unexpected cancels received\", 1)\n\t\treturn\n\t}\n\tif cn.fastEnabled() {\n\t\tcn.reject(r)\n\t} else {\n\t\tdelete(cn.peerRequests, r)\n\t}\n}\n\nfunc (cn *PeerConn) choke(msg messageWriter) (more bool) {\n\tif cn.choking {\n\t\treturn true\n\t}\n\tcn.choking = true\n\tmore = msg(pp.Message{\n\t\tType: pp.Choke,\n\t})\n\tif !cn.fastEnabled() {\n\t\tcn.deleteAllPeerRequests()\n\t}\n\treturn\n}\n\nfunc (cn *PeerConn) deleteAllPeerRequests() {\n\tfor _, state := range cn.peerRequests {\n\t\tstate.allocReservation.Drop()\n\t}\n\tcn.peerRequests = nil\n}\n\nfunc (cn *PeerConn) unchoke(msg func(pp.Message) bool) bool {\n\tif !cn.choking {\n\t\treturn true\n\t}\n\tcn.choking = false\n\treturn msg(pp.Message{\n\t\tType: pp.Unchoke,\n\t})\n}\n\nfunc (pc *PeerConn) writeInterested(interested bool) bool {\n\treturn pc.write(pp.Message{\n\t\tType: func() pp.MessageType {\n\t\t\tif interested {\n\t\t\t\treturn pp.Interested\n\t\t\t} else {\n\t\t\t\treturn pp.NotInterested\n\t\t\t}\n\t\t}(),\n\t})\n}\n\nfunc (me *PeerConn) _request(r Request) bool {\n\treturn me.write(pp.Message{\n\t\tType:   pp.Request,\n\t\tIndex:  r.Index,\n\t\tBegin:  r.Begin,\n\t\tLength: r.Length,\n\t})\n}\n\nfunc (me *PeerConn) _cancel(r RequestIndex) bool {\n\tme.write(makeCancelMessage(me.t.requestIndexToRequest(r)))\n\treturn me.remoteRejectsCancels()\n}\n\n// Whether we should expect a reject message after sending a cancel.\nfunc (me *PeerConn) remoteRejectsCancels() bool {\n\tif !me.fastEnabled() {\n\t\treturn false\n\t}\n\tif me.remoteIsTransmission() {\n\t\t// Transmission did not send rejects for received cancels. See\n\t\t// https://github.com/transmission/transmission/pull/2275. Fixed in 4.0.0-beta.1 onward in\n\t\t// https://github.com/transmission/transmission/commit/76719bf34c255da4fca991c2ad3fa4b65d2154b1.\n\t\t// Peer ID prefix scheme described\n\t\t// https://github.com/transmission/transmission/blob/7ec7607bbcf0fa99bd4b157b9b0f0c411d59f45d/CMakeLists.txt#L128-L149.\n\t\treturn me.PeerID[3] >= '4'\n\t}\n\treturn true\n}\n\nfunc (cn *PeerConn) fillWriteBuffer() {\n\tif cn.messageWriter.writeBuffer.Len() > writeBufferLowWaterLen {\n\t\t// Fully committing to our max requests requires sufficient space (see\n\t\t// maxLocalToRemoteRequests). Flush what we have instead. We also prefer always to make\n\t\t// requests than to do PEX or upload, so we short-circuit before handling those. Any update\n\t\t// request reason will not be cleared, so we'll come right back here when there's space. We\n\t\t// can't do this in maybeUpdateActualRequestState because it's a method on Peer and has no\n\t\t// knowledge of write buffers.\n\t\treturn\n\t}\n\tcn.requestMissingHashes()\n\tcn.maybeUpdateActualRequestState()\n\tif cn.pex.IsEnabled() {\n\t\tif flow := cn.pex.Share(cn.write); !flow {\n\t\t\treturn\n\t\t}\n\t}\n\tcn.upload(cn.write)\n}\n\nfunc (cn *PeerConn) have(piece pieceIndex) {\n\tif cn.sentHaves.Get(bitmap.BitIndex(piece)) {\n\t\treturn\n\t}\n\tcn.write(pp.Message{\n\t\tType:  pp.Have,\n\t\tIndex: pp.Integer(piece),\n\t})\n\tcn.sentHaves.Add(bitmap.BitIndex(piece))\n}\n\nfunc (cn *PeerConn) postBitfield() {\n\tif cn.sentHaves.Len() != 0 {\n\t\tpanic(\"bitfield must be first have-related message sent\")\n\t}\n\tif !cn.t.haveAnyPieces() {\n\t\treturn\n\t}\n\tcn.write(pp.Message{\n\t\tType:     pp.Bitfield,\n\t\tBitfield: cn.t.bitfield(),\n\t})\n\tcn.sentHaves = bitmap.Bitmap{cn.t._completedPieces.Clone()}\n}\n\nfunc (cn *PeerConn) handleUpdateRequests() {\n\t// The writer determines the request state as needed when it can write.\n\tcn.tickleWriter()\n}\n\nfunc (cn *PeerConn) raisePeerMinPieces(newMin pieceIndex) {\n\tif newMin > cn.peerMinPieces {\n\t\tcn.peerMinPieces = newMin\n\t}\n}\n\nfunc (cn *PeerConn) peerSentHave(piece pieceIndex) error {\n\tif cn.t.haveInfo() && piece >= cn.t.numPieces() || piece < 0 {\n\t\treturn errors.New(\"invalid piece\")\n\t}\n\tif cn.peerHasPiece(piece) {\n\t\treturn nil\n\t}\n\tcn.raisePeerMinPieces(piece + 1)\n\tif !cn.peerHasPiece(piece) {\n\t\tcn.t.incPieceAvailability(piece)\n\t}\n\tcn._peerPieces.Add(uint32(piece))\n\tif cn.t.wantPieceIndex(piece) {\n\t\tcn.updateRequests(\"have\")\n\t}\n\tcn.peerPiecesChanged()\n\treturn nil\n}\n\nfunc (cn *PeerConn) peerSentBitfield(bf []bool) error {\n\tif len(bf)%8 != 0 {\n\t\tpanic(\"expected bitfield length divisible by 8\")\n\t}\n\t// We know that the last byte means that at most the last 7 bits are wasted.\n\tcn.raisePeerMinPieces(pieceIndex(len(bf) - 7))\n\tif cn.t.haveInfo() && len(bf) > int(cn.t.numPieces()) {\n\t\t// Ignore known excess pieces.\n\t\tbf = bf[:cn.t.numPieces()]\n\t}\n\tbm := boolSliceToBitmap(bf)\n\tif cn.t.haveInfo() && pieceIndex(bm.GetCardinality()) == cn.t.numPieces() {\n\t\tcn.onPeerHasAllPieces()\n\t\treturn nil\n\t}\n\tif !bm.IsEmpty() {\n\t\tcn.raisePeerMinPieces(pieceIndex(bm.Maximum()) + 1)\n\t}\n\tshouldUpdateRequests := false\n\tif cn.peerSentHaveAll {\n\t\tif !cn.t.deleteConnWithAllPieces(&cn.Peer) {\n\t\t\tpanic(cn)\n\t\t}\n\t\tcn.peerSentHaveAll = false\n\t\tif !cn._peerPieces.IsEmpty() {\n\t\t\tpanic(\"if peer has all, we expect no individual peer pieces to be set\")\n\t\t}\n\t} else {\n\t\tbm.Xor(&cn._peerPieces)\n\t}\n\tcn.peerSentHaveAll = false\n\t// bm is now 'on' for pieces that are changing\n\tbm.Iterate(func(x uint32) bool {\n\t\tpi := pieceIndex(x)\n\t\tif cn._peerPieces.Contains(x) {\n\t\t\t// Then we must be losing this piece\n\t\t\tcn.t.decPieceAvailability(pi)\n\t\t} else {\n\t\t\tif !shouldUpdateRequests && cn.t.wantPieceIndex(pieceIndex(x)) {\n\t\t\t\tshouldUpdateRequests = true\n\t\t\t}\n\t\t\t// We must be gaining this piece\n\t\t\tcn.t.incPieceAvailability(pieceIndex(x))\n\t\t}\n\t\treturn true\n\t})\n\t// Apply the changes. If we had everything previously, this should be empty, so xor is the same\n\t// as or.\n\tcn._peerPieces.Xor(&bm)\n\tif shouldUpdateRequests {\n\t\tcn.updateRequests(\"bitfield\")\n\t}\n\t// We didn't guard this before, I see no reason to do it now.\n\tcn.peerPiecesChanged()\n\treturn nil\n}\n\nfunc (cn *PeerConn) onPeerHasAllPiecesNoTriggers() {\n\tt := cn.t\n\tif t.haveInfo() {\n\t\tcn._peerPieces.Iterate(func(x uint32) bool {\n\t\t\tt.decPieceAvailability(pieceIndex(x))\n\t\t\treturn true\n\t\t})\n\t}\n\tt.addConnWithAllPieces(&cn.Peer)\n\tcn.peerSentHaveAll = true\n\tcn._peerPieces.Clear()\n}\n\nfunc (cn *PeerConn) onPeerHasAllPieces() {\n\tcn.onPeerHasAllPiecesNoTriggers()\n\tcn.peerHasAllPiecesTriggers()\n}\n\nfunc (cn *PeerConn) peerHasAllPiecesTriggers() {\n\tif !cn.t._pendingPieces.IsEmpty() {\n\t\tcn.updateRequests(\"Peer.onPeerHasAllPieces\")\n\t}\n\tcn.peerPiecesChanged()\n}\n\nfunc (cn *PeerConn) onPeerSentHaveAll() error {\n\tcn.onPeerHasAllPieces()\n\treturn nil\n}\n\nfunc (cn *PeerConn) peerSentHaveNone() error {\n\tif !cn.peerSentHaveAll {\n\t\tcn.t.decPeerPieceAvailability(&cn.Peer)\n\t}\n\tcn._peerPieces.Clear()\n\tcn.peerSentHaveAll = false\n\tcn.peerPiecesChanged()\n\treturn nil\n}\n\nfunc (c *PeerConn) requestPendingMetadata() {\n\tif c.t.haveInfo() {\n\t\treturn\n\t}\n\tif c.PeerExtensionIDs[pp.ExtensionNameMetadata] == 0 {\n\t\t// Peer doesn't support this.\n\t\treturn\n\t}\n\t// Request metadata pieces that we don't have in a random order.\n\tvar pending []int\n\tfor index := 0; index < c.t.metadataPieceCount(); index++ {\n\t\tif !c.t.haveMetadataPiece(index) && !c.requestedMetadataPiece(index) {\n\t\t\tpending = append(pending, index)\n\t\t}\n\t}\n\trand.Shuffle(len(pending), func(i, j int) { pending[i], pending[j] = pending[j], pending[i] })\n\tfor _, i := range pending {\n\t\tc.requestMetadataPiece(i)\n\t}\n}\n\nfunc (cn *PeerConn) wroteMsg(msg *pp.Message) {\n\ttorrent.Add(fmt.Sprintf(\"messages written of type %s\", msg.Type.String()), 1)\n\tif msg.Type == pp.Extended {\n\t\tfor name, id := range cn.PeerExtensionIDs {\n\t\t\tif id != msg.ExtendedID {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ttorrent.Add(fmt.Sprintf(\"Extended messages written for protocol %q\", name), 1)\n\t\t}\n\t}\n\tcn.allStats(func(cs *ConnStats) { cs.wroteMsg(msg) })\n}\n\nfunc (cn *PeerConn) wroteBytes(n int64) {\n\tcn.allStats(add(n, func(cs *ConnStats) *Count { return &cs.BytesWritten }))\n}\n\nfunc (c *PeerConn) fastEnabled() bool {\n\treturn c.PeerExtensionBytes.SupportsFast() && c.t.cl.config.Extensions.SupportsFast()\n}\n\nfunc (c *PeerConn) reject(r Request) {\n\tif !c.fastEnabled() {\n\t\tpanic(\"fast not enabled\")\n\t}\n\tc.write(r.ToMsg(pp.Reject))\n\t// It is possible to reject a request before it is added to peer requests due to being invalid.\n\tif state, ok := c.peerRequests[r]; ok {\n\t\tstate.allocReservation.Drop()\n\t\tdelete(c.peerRequests, r)\n\t}\n}\n\nfunc (c *PeerConn) maximumPeerRequestChunkLength() (_ Option[int]) {\n\tuploadRateLimiter := c.t.cl.config.UploadRateLimiter\n\tif uploadRateLimiter.Limit() == rate.Inf {\n\t\treturn\n\t}\n\treturn Some(uploadRateLimiter.Burst())\n}\n\n// startFetch is for testing purposes currently.\nfunc (c *PeerConn) onReadRequest(r Request, startFetch bool) error {\n\trequestedChunkLengths.Add(strconv.FormatUint(r.Length.Uint64(), 10), 1)\n\tif _, ok := c.peerRequests[r]; ok {\n\t\ttorrent.Add(\"duplicate requests received\", 1)\n\t\tif c.fastEnabled() {\n\t\t\treturn errors.New(\"received duplicate request with fast enabled\")\n\t\t}\n\t\treturn nil\n\t}\n\tif c.choking {\n\t\ttorrent.Add(\"requests received while choking\", 1)\n\t\tif c.fastEnabled() {\n\t\t\ttorrent.Add(\"requests rejected while choking\", 1)\n\t\t\tc.reject(r)\n\t\t}\n\t\treturn nil\n\t}\n\t// TODO: What if they've already requested this?\n\tif len(c.peerRequests) >= localClientReqq {\n\t\ttorrent.Add(\"requests received while queue full\", 1)\n\t\tif c.fastEnabled() {\n\t\t\tc.reject(r)\n\t\t}\n\t\t// BEP 6 says we may close here if we choose.\n\t\treturn nil\n\t}\n\tif opt := c.maximumPeerRequestChunkLength(); opt.Ok && int(r.Length) > opt.Value {\n\t\terr := fmt.Errorf(\"peer requested chunk too long (%v)\", r.Length)\n\t\tc.protocolLogger.Levelf(log.Warning, err.Error())\n\t\tif c.fastEnabled() {\n\t\t\tc.reject(r)\n\t\t\treturn nil\n\t\t} else {\n\t\t\treturn err\n\t\t}\n\t}\n\tif !c.t.havePiece(pieceIndex(r.Index)) {\n\t\t// TODO: Tell the peer we don't have the piece, and reject this request.\n\t\trequestsReceivedForMissingPieces.Add(1)\n\t\treturn fmt.Errorf(\"peer requested piece we don't have: %v\", r.Index.Int())\n\t}\n\tpieceLength := c.t.pieceLength(pieceIndex(r.Index))\n\t// Check this after we know we have the piece, so that the piece length will be known.\n\tif chunkOverflowsPiece(r.ChunkSpec, pieceLength) {\n\t\ttorrent.Add(\"bad requests received\", 1)\n\t\treturn errors.New(\"chunk overflows piece\")\n\t}\n\tif c.peerRequests == nil {\n\t\tc.peerRequests = make(map[Request]*peerRequestState, localClientReqq)\n\t}\n\tvalue := &peerRequestState{\n\t\tallocReservation: c.peerRequestDataAllocLimiter.Reserve(int64(r.Length)),\n\t}\n\tc.peerRequests[r] = value\n\tif startFetch {\n\t\t// TODO: Limit peer request data read concurrency.\n\t\tgo c.peerRequestDataReader(r, value)\n\t}\n\treturn nil\n}\n\nfunc (c *PeerConn) peerRequestDataReader(r Request, prs *peerRequestState) {\n\t// Should we depend on Torrent closure here? I think it's okay to get cancelled from elsewhere,\n\t// or fail to read and then cleanup. Also, we used to hang here if the reservation was never\n\t// dropped, that was fixed.\n\tctx := context.Background()\n\terr := prs.allocReservation.Wait(ctx)\n\tif err != nil {\n\t\tc.logger.WithDefaultLevel(log.Debug).Levelf(log.ErrorLevel(err), \"waiting for alloc limit reservation: %v\", err)\n\t\treturn\n\t}\n\tb, err := c.readPeerRequestData(r)\n\tc.locker().Lock()\n\tdefer c.locker().Unlock()\n\tif err != nil {\n\t\tc.peerRequestDataReadFailed(err, r)\n\t} else {\n\t\tif b == nil {\n\t\t\tpanic(\"data must be non-nil to trigger send\")\n\t\t}\n\t\ttorrent.Add(\"peer request data read successes\", 1)\n\t\tprs.data = b\n\t\t// This might be required for the error case too (#752 and #753).\n\t\tc.tickleWriter()\n\t}\n}\n\n// If this is maintained correctly, we might be able to support optional synchronous reading for\n// chunk sending, the way it used to work.\nfunc (c *PeerConn) peerRequestDataReadFailed(err error, r Request) {\n\ttorrent.Add(\"peer request data read failures\", 1)\n\tlogLevel := log.Warning\n\tif c.t.hasStorageCap() {\n\t\t// It's expected that pieces might drop. See\n\t\t// https://github.com/anacrolix/torrent/issues/702#issuecomment-1000953313.\n\t\tlogLevel = log.Debug\n\t}\n\tc.logger.Levelf(logLevel, \"error reading chunk for peer Request %v: %v\", r, err)\n\tif c.t.closed.IsSet() {\n\t\treturn\n\t}\n\ti := pieceIndex(r.Index)\n\tif c.t.pieceComplete(i) {\n\t\t// There used to be more code here that just duplicated the following break. Piece\n\t\t// completions are currently cached, so I'm not sure how helpful this update is, except to\n\t\t// pull any completion changes pushed to the storage backend in failed reads that got us\n\t\t// here.\n\t\tc.t.updatePieceCompletion(i)\n\t}\n\t// We've probably dropped a piece from storage, but there's no way to communicate this to the\n\t// peer. If they ask for it again, we kick them allowing us to send them updated piece states if\n\t// we reconnect. TODO: Instead, we could just try to update them with Bitfield or HaveNone and\n\t// if they kick us for breaking protocol, on reconnect we will be compliant again (at least\n\t// initially).\n\tif c.fastEnabled() {\n\t\tc.reject(r)\n\t} else {\n\t\tif c.choking {\n\t\t\t// If fast isn't enabled, I think we would have wiped all peer requests when we last\n\t\t\t// choked, and requests while we're choking would be ignored. It could be possible that\n\t\t\t// a peer request data read completed concurrently to it being deleted elsewhere.\n\t\t\tc.protocolLogger.WithDefaultLevel(log.Warning).Printf(\"already choking peer, requests might not be rejected correctly\")\n\t\t}\n\t\t// Choking a non-fast peer should cause them to flush all their requests.\n\t\tc.choke(c.write)\n\t}\n}\n\nfunc (c *PeerConn) readPeerRequestData(r Request) ([]byte, error) {\n\tb := make([]byte, r.Length)\n\tp := c.t.info.Piece(int(r.Index))\n\tn, err := c.t.readAt(b, p.Offset()+int64(r.Begin))\n\tif n == len(b) {\n\t\tif err == io.EOF {\n\t\t\terr = nil\n\t\t}\n\t} else {\n\t\tif err == nil {\n\t\t\tpanic(\"expected error\")\n\t\t}\n\t}\n\treturn b, err\n}\n\nfunc (c *PeerConn) logProtocolBehaviour(level log.Level, format string, arg ...interface{}) {\n\tc.protocolLogger.WithContextText(fmt.Sprintf(\n\t\t\"peer id %q, ext v %q\", c.PeerID, c.PeerClientName.Load(),\n\t)).SkipCallers(1).Levelf(level, format, arg...)\n}\n\n// Processes incoming BitTorrent wire-protocol messages. The client lock is held upon entry and\n// exit. Returning will end the connection.\nfunc (c *PeerConn) mainReadLoop() (err error) {\n\tdefer func() {\n\t\tif err != nil {\n\t\t\ttorrent.Add(\"connection.mainReadLoop returned with error\", 1)\n\t\t} else {\n\t\t\ttorrent.Add(\"connection.mainReadLoop returned with no error\", 1)\n\t\t}\n\t}()\n\tt := c.t\n\tcl := t.cl\n\n\tdecoder := pp.Decoder{\n\t\tR:         bufio.NewReaderSize(c.r, 1<<17),\n\t\tMaxLength: 4 * pp.Integer(max(int64(t.chunkSize), defaultChunkSize)),\n\t\tPool:      &t.chunkPool,\n\t}\n\tfor {\n\t\tvar msg pp.Message\n\t\tfunc() {\n\t\t\tcl.unlock()\n\t\t\tdefer cl.lock()\n\t\t\terr = decoder.Decode(&msg)\n\t\t\tif err != nil {\n\t\t\t\terr = fmt.Errorf(\"decoding message: %w\", err)\n\t\t\t}\n\t\t}()\n\t\t// Do this before checking closed.\n\t\tif cb := c.callbacks.ReadMessage; cb != nil && err == nil {\n\t\t\tcb(c, &msg)\n\t\t}\n\t\tif t.closed.IsSet() || c.closed.IsSet() {\n\t\t\treturn nil\n\t\t}\n\t\tif err != nil {\n\t\t\terr = log.WithLevel(log.Info, err)\n\t\t\treturn err\n\t\t}\n\t\tc.lastMessageReceived = time.Now()\n\t\tif msg.Keepalive {\n\t\t\treceivedKeepalives.Add(1)\n\t\t\tcontinue\n\t\t}\n\t\tmessageTypesReceived.Add(msg.Type.String(), 1)\n\t\tif msg.Type.FastExtension() && !c.fastEnabled() {\n\t\t\trunSafeExtraneous(func() { torrent.Add(\"fast messages received when extension is disabled\", 1) })\n\t\t\treturn fmt.Errorf(\"received fast extension message (type=%v) but extension is disabled\", msg.Type)\n\t\t}\n\t\tswitch msg.Type {\n\t\tcase pp.Choke:\n\t\t\tif c.peerChoking {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif !c.fastEnabled() {\n\t\t\t\tc.deleteAllRequests(\"choked by non-fast PeerConn\")\n\t\t\t} else {\n\t\t\t\t// We don't decrement pending requests here, let's wait for the peer to either\n\t\t\t\t// reject or satisfy the outstanding requests. Additionally, some peers may unchoke\n\t\t\t\t// us and resume where they left off, we don't want to have piled on to those chunks\n\t\t\t\t// in the meanwhile. I think a peer's ability to abuse this should be limited: they\n\t\t\t\t// could let us request a lot of stuff, then choke us and never reject, but they're\n\t\t\t\t// only a single peer, our chunk balancing should smooth over this abuse.\n\t\t\t}\n\t\t\tc.peerChoking = true\n\t\t\tc.updateExpectingChunks()\n\t\tcase pp.Unchoke:\n\t\t\tif !c.peerChoking {\n\t\t\t\t// Some clients do this for some reason. Transmission doesn't error on this, so we\n\t\t\t\t// won't for consistency.\n\t\t\t\tc.logProtocolBehaviour(log.Debug, \"received unchoke when already unchoked\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tc.peerChoking = false\n\t\t\tpreservedCount := 0\n\t\t\tc.requestState.Requests.Iterate(func(x RequestIndex) bool {\n\t\t\t\tif !c.peerAllowedFast.Contains(c.t.pieceIndexOfRequestIndex(x)) {\n\t\t\t\t\tpreservedCount++\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t})\n\t\t\tif preservedCount != 0 {\n\t\t\t\t// TODO: Yes this is a debug log but I'm not happy with the state of the logging lib\n\t\t\t\t// right now.\n\t\t\t\tc.protocolLogger.Levelf(log.Debug,\n\t\t\t\t\t\"%v requests were preserved while being choked (fast=%v)\",\n\t\t\t\t\tpreservedCount,\n\t\t\t\t\tc.fastEnabled())\n\n\t\t\t\ttorrent.Add(\"requestsPreservedThroughChoking\", int64(preservedCount))\n\t\t\t}\n\t\t\tif !c.t._pendingPieces.IsEmpty() {\n\t\t\t\tc.updateRequests(\"unchoked\")\n\t\t\t}\n\t\t\tc.updateExpectingChunks()\n\t\tcase pp.Interested:\n\t\t\tc.peerInterested = true\n\t\t\tc.tickleWriter()\n\t\tcase pp.NotInterested:\n\t\t\tc.peerInterested = false\n\t\t\t// We don't clear their requests since it isn't clear in the spec.\n\t\t\t// We'll probably choke them for this, which will clear them if\n\t\t\t// appropriate, and is clearly specified.\n\t\tcase pp.Have:\n\t\t\terr = c.peerSentHave(pieceIndex(msg.Index))\n\t\tcase pp.Bitfield:\n\t\t\terr = c.peerSentBitfield(msg.Bitfield)\n\t\tcase pp.Request:\n\t\t\tr := newRequestFromMessage(&msg)\n\t\t\terr = c.onReadRequest(r, true)\n\t\t\tif err != nil {\n\t\t\t\terr = fmt.Errorf(\"on reading request %v: %w\", r, err)\n\t\t\t}\n\t\tcase pp.Piece:\n\t\t\tc.doChunkReadStats(int64(len(msg.Piece)))\n\t\t\terr = c.receiveChunk(&msg)\n\t\t\tif len(msg.Piece) == int(t.chunkSize) {\n\t\t\t\tt.chunkPool.Put(&msg.Piece)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\terr = fmt.Errorf(\"receiving chunk: %w\", err)\n\t\t\t}\n\t\tcase pp.Cancel:\n\t\t\treq := newRequestFromMessage(&msg)\n\t\t\tc.onPeerSentCancel(req)\n\t\tcase pp.Port:\n\t\t\tipa, ok := tryIpPortFromNetAddr(c.RemoteAddr)\n\t\t\tif !ok {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpingAddr := net.UDPAddr{\n\t\t\t\tIP:   ipa.IP,\n\t\t\t\tPort: ipa.Port,\n\t\t\t}\n\t\t\tif msg.Port != 0 {\n\t\t\t\tpingAddr.Port = int(msg.Port)\n\t\t\t}\n\t\t\tcl.eachDhtServer(func(s DhtServer) {\n\t\t\t\tgo s.Ping(&pingAddr)\n\t\t\t})\n\t\tcase pp.Suggest:\n\t\t\ttorrent.Add(\"suggests received\", 1)\n\t\t\tlog.Fmsg(\"peer suggested piece %d\", msg.Index).AddValues(c, msg.Index).LogLevel(log.Debug, c.t.logger)\n\t\t\tc.updateRequests(\"suggested\")\n\t\tcase pp.HaveAll:\n\t\t\terr = c.onPeerSentHaveAll()\n\t\tcase pp.HaveNone:\n\t\t\terr = c.peerSentHaveNone()\n\t\tcase pp.Reject:\n\t\t\treq := newRequestFromMessage(&msg)\n\t\t\tif !c.remoteRejectedRequest(c.t.requestIndexFromRequest(req)) {\n\t\t\t\terr = fmt.Errorf(\"received invalid reject for request %v\", req)\n\t\t\t\tc.protocolLogger.Levelf(log.Debug, \"%v\", err)\n\t\t\t}\n\t\tcase pp.AllowedFast:\n\t\t\ttorrent.Add(\"allowed fasts received\", 1)\n\t\t\tlog.Fmsg(\"peer allowed fast: %d\", msg.Index).AddValues(c).LogLevel(log.Debug, c.t.logger)\n\t\t\tc.updateRequests(\"PeerConn.mainReadLoop allowed fast\")\n\t\tcase pp.Extended:\n\t\t\terr = c.onReadExtendedMsg(msg.ExtendedID, msg.ExtendedPayload)\n\t\tcase pp.Hashes:\n\t\t\terr = c.onReadHashes(&msg)\n\t\tcase pp.HashRequest:\n\t\t\terr = c.onHashRequest(&msg)\n\t\tcase pp.HashReject:\n\t\t\tc.protocolLogger.Levelf(log.Info, \"received unimplemented BitTorrent v2 message: %v\", msg.Type)\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"received unknown message type: %#v\", msg.Type)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\nfunc (c *PeerConn) onReadExtendedMsg(id pp.ExtensionNumber, payload []byte) (err error) {\n\tdefer func() {\n\t\t// TODO: Should we still do this?\n\t\tif err != nil {\n\t\t\t// These clients use their own extension IDs for outgoing message\n\t\t\t// types, which is incorrect.\n\t\t\tif bytes.HasPrefix(c.PeerID[:], []byte(\"-SD0100-\")) || strings.HasPrefix(string(c.PeerID[:]), \"-XL0012-\") {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t}\n\t}()\n\tt := c.t\n\tcl := t.cl\n\t{\n\t\tevent := PeerConnReadExtensionMessageEvent{\n\t\t\tPeerConn:        c,\n\t\t\tExtensionNumber: id,\n\t\t\tPayload:         payload,\n\t\t}\n\t\tfor _, cb := range c.callbacks.PeerConnReadExtensionMessage {\n\t\t\tcb(event)\n\t\t}\n\t}\n\tif id == pp.HandshakeExtendedID {\n\t\tvar d pp.ExtendedHandshakeMessage\n\t\tif err := bencode.Unmarshal(payload, &d); err != nil {\n\t\t\tc.protocolLogger.Printf(\"error parsing extended handshake message %q: %s\", payload, err)\n\t\t\treturn fmt.Errorf(\"unmarshalling extended handshake payload: %w\", err)\n\t\t}\n\t\t// Trigger this callback after it's been processed. If you want to handle it yourself, you\n\t\t// should hook PeerConnReadExtensionMessage.\n\t\tif cb := c.callbacks.ReadExtendedHandshake; cb != nil {\n\t\t\tcb(c, &d)\n\t\t}\n\t\tif d.Reqq != 0 {\n\t\t\tc.PeerMaxRequests = d.Reqq\n\t\t}\n\t\tc.PeerClientName.Store(d.V)\n\t\tif c.PeerExtensionIDs == nil {\n\t\t\tc.PeerExtensionIDs = make(map[pp.ExtensionName]pp.ExtensionNumber, len(d.M))\n\t\t}\n\t\tc.PeerListenPort = d.Port\n\t\tc.PeerPrefersEncryption = d.Encryption\n\t\tfor name, id := range d.M {\n\t\t\tif _, ok := c.PeerExtensionIDs[name]; !ok {\n\t\t\t\tpeersSupportingExtension.Add(\n\t\t\t\t\t// expvar.Var.String must produce valid JSON. \"ut_payme\\xeet_address\" was being\n\t\t\t\t\t// entered here which caused problems later when unmarshalling.\n\t\t\t\t\tstrconv.Quote(string(name)),\n\t\t\t\t\t1)\n\t\t\t}\n\t\t\tc.PeerExtensionIDs[name] = id\n\t\t}\n\t\tif d.MetadataSize != 0 {\n\t\t\tif err = t.setMetadataSize(d.MetadataSize); err != nil {\n\t\t\t\treturn fmt.Errorf(\"setting metadata size to %d: %w\", d.MetadataSize, err)\n\t\t\t}\n\t\t}\n\t\tc.requestPendingMetadata()\n\t\tif !t.cl.config.DisablePEX {\n\t\t\tt.pex.Add(c) // we learnt enough now\n\t\t\t// This checks the extension is supported internally.\n\t\t\tc.pex.Init(c)\n\t\t}\n\t\treturn nil\n\t}\n\textensionName, builtin, err := c.LocalLtepProtocolMap.LookupId(id)\n\tif err != nil {\n\t\treturn\n\t}\n\tif !builtin {\n\t\t// User should have taken care of this in PeerConnReadExtensionMessage callback.\n\t\treturn nil\n\t}\n\tswitch extensionName {\n\tcase pp.ExtensionNameMetadata:\n\t\terr := cl.gotMetadataExtensionMsg(payload, t, c)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"handling metadata extension message: %w\", err)\n\t\t}\n\t\treturn nil\n\tcase pp.ExtensionNamePex:\n\t\tif !c.pex.IsEnabled() {\n\t\t\treturn nil // or hang-up maybe?\n\t\t}\n\t\terr = c.pex.Recv(payload)\n\t\tif err != nil {\n\t\t\terr = fmt.Errorf(\"receiving pex message: %w\", err)\n\t\t}\n\t\treturn\n\tcase utHolepunch.ExtensionName:\n\t\tvar msg utHolepunch.Msg\n\t\terr = msg.UnmarshalBinary(payload)\n\t\tif err != nil {\n\t\t\terr = fmt.Errorf(\"unmarshalling ut_holepunch message: %w\", err)\n\t\t\treturn\n\t\t}\n\t\terr = c.t.handleReceivedUtHolepunchMsg(msg, c)\n\t\treturn\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unhandled builtin extension protocol %q\", extensionName))\n\t}\n}\n\n// Set both the Reader and Writer for the connection from a single ReadWriter.\nfunc (cn *PeerConn) setRW(rw io.ReadWriter) {\n\tcn.r = rw\n\tcn.w = rw\n}\n\n// Returns the Reader and Writer as a combined ReadWriter.\nfunc (cn *PeerConn) rw() io.ReadWriter {\n\treturn struct {\n\t\tio.Reader\n\t\tio.Writer\n\t}{cn.r, cn.w}\n}\n\nfunc (c *PeerConn) uploadAllowed() bool {\n\tif c.t.cl.config.NoUpload {\n\t\treturn false\n\t}\n\tif c.t.dataUploadDisallowed {\n\t\treturn false\n\t}\n\tif c.t.seeding() {\n\t\treturn true\n\t}\n\tif !c.peerHasWantedPieces() {\n\t\treturn false\n\t}\n\t// Don't upload more than 100 KiB more than we download.\n\tif c._stats.BytesWrittenData.Int64() >= c._stats.BytesReadData.Int64()+100<<10 {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (c *PeerConn) setRetryUploadTimer(delay time.Duration) {\n\tif c.uploadTimer == nil {\n\t\tc.uploadTimer = time.AfterFunc(delay, c.tickleWriter)\n\t} else {\n\t\tc.uploadTimer.Reset(delay)\n\t}\n}\n\n// Also handles choking and unchoking of the remote peer.\nfunc (c *PeerConn) upload(msg func(pp.Message) bool) bool {\n\t// Breaking or completing this loop means we don't want to upload to the peer anymore, and we\n\t// choke them.\nanother:\n\tfor c.uploadAllowed() {\n\t\t// We want to upload to the peer.\n\t\tif !c.unchoke(msg) {\n\t\t\treturn false\n\t\t}\n\t\tfor r, state := range c.peerRequests {\n\t\t\tif state.data == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tres := c.t.cl.config.UploadRateLimiter.ReserveN(time.Now(), int(r.Length))\n\t\t\tif !res.OK() {\n\t\t\t\tpanic(fmt.Sprintf(\"upload rate limiter burst size < %d\", r.Length))\n\t\t\t}\n\t\t\tdelay := res.Delay()\n\t\t\tif delay > 0 {\n\t\t\t\tres.Cancel()\n\t\t\t\tc.setRetryUploadTimer(delay)\n\t\t\t\t// Hard to say what to return here.\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tmore := c.sendChunk(r, msg, state)\n\t\t\tdelete(c.peerRequests, r)\n\t\t\tif !more {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tgoto another\n\t\t}\n\t\treturn true\n\t}\n\treturn c.choke(msg)\n}\n\nfunc (cn *PeerConn) drop() {\n\tcn.t.dropConnection(cn)\n}\n\nfunc (cn *PeerConn) ban() {\n\tcn.t.cl.banPeerIP(cn.remoteIp())\n}\n\n// This is called when something has changed that should wake the writer, such as putting stuff into\n// the writeBuffer, or changing some state that the writer can act on.\nfunc (c *PeerConn) tickleWriter() {\n\tc.messageWriter.writeCond.Broadcast()\n}\n\nfunc (c *PeerConn) sendChunk(r Request, msg func(pp.Message) bool, state *peerRequestState) (more bool) {\n\tc.lastChunkSent = time.Now()\n\tstate.allocReservation.Release()\n\treturn msg(pp.Message{\n\t\tType:  pp.Piece,\n\t\tIndex: r.Index,\n\t\tBegin: r.Begin,\n\t\tPiece: state.data,\n\t})\n}\n\nfunc (c *Peer) setTorrent(t *Torrent) {\n\tif c.t != nil {\n\t\tpanic(\"connection already associated with a torrent\")\n\t}\n\tc.t = t\n\tc.logger.WithDefaultLevel(log.Debug).Printf(\"set torrent=%v\", t)\n\tt.reconcileHandshakeStats(c)\n}\n\nfunc (c *PeerConn) pexPeerFlags() pp.PexPeerFlags {\n\tf := pp.PexPeerFlags(0)\n\tif c.PeerPrefersEncryption {\n\t\tf |= pp.PexPrefersEncryption\n\t}\n\tif c.outgoing {\n\t\tf |= pp.PexOutgoingConn\n\t}\n\tif c.utp() {\n\t\tf |= pp.PexSupportsUtp\n\t}\n\treturn f\n}\n\n// This returns the address to use if we want to dial the peer again. It incorporates the peer's\n// advertised listen port.\nfunc (c *PeerConn) dialAddr() PeerRemoteAddr {\n\tif c.outgoing || c.PeerListenPort == 0 {\n\t\treturn c.RemoteAddr\n\t}\n\taddrPort, err := addrPortFromPeerRemoteAddr(c.RemoteAddr)\n\tif err != nil {\n\t\tc.logger.Levelf(\n\t\t\tlog.Warning,\n\t\t\t\"error parsing %q for alternate dial port: %v\",\n\t\t\tc.RemoteAddr,\n\t\t\terr,\n\t\t)\n\t\treturn c.RemoteAddr\n\t}\n\treturn netip.AddrPortFrom(addrPort.Addr(), uint16(c.PeerListenPort))\n}\n\nfunc (c *PeerConn) pexEvent(t pexEventType) (_ pexEvent, err error) {\n\tf := c.pexPeerFlags()\n\tdialAddr := c.dialAddr()\n\taddr, err := addrPortFromPeerRemoteAddr(dialAddr)\n\tif err != nil || !addr.IsValid() {\n\t\terr = fmt.Errorf(\"parsing dial addr %q: %w\", dialAddr, err)\n\t\treturn\n\t}\n\treturn pexEvent{t, addr, f, nil}, nil\n}\n\nfunc (pc *PeerConn) String() string {\n\treturn fmt.Sprintf(\n\t\t\"%T %p [flags=%v id=%+q, exts=%v, v=%q]\",\n\t\tpc,\n\t\tpc,\n\t\tpc.connectionFlags(),\n\t\tpc.PeerID,\n\t\tpc.PeerExtensionBytes,\n\t\tpc.PeerClientName.Load(),\n\t)\n}\n\n// Returns the pieces the peer could have based on their claims. If we don't know how many pieces\n// are in the torrent, it could be a very large range if the peer has sent HaveAll.\nfunc (pc *PeerConn) PeerPieces() *roaring.Bitmap {\n\tpc.locker().RLock()\n\tdefer pc.locker().RUnlock()\n\treturn pc.newPeerPieces()\n}\n\nfunc (pc *PeerConn) remoteIsTransmission() bool {\n\treturn bytes.HasPrefix(pc.PeerID[:], []byte(\"-TR\")) && pc.PeerID[7] == '-'\n}\n\nfunc (pc *PeerConn) remoteDialAddrPort() (netip.AddrPort, error) {\n\tdialAddr := pc.dialAddr()\n\treturn addrPortFromPeerRemoteAddr(dialAddr)\n}\n\nfunc (pc *PeerConn) bitExtensionEnabled(bit pp.ExtensionBit) bool {\n\treturn pc.t.cl.config.Extensions.GetBit(bit) && pc.PeerExtensionBytes.GetBit(bit)\n}\n\nfunc (cn *PeerConn) peerPiecesChanged() {\n\tcn.t.maybeDropMutuallyCompletePeer(cn)\n}\n\n// Returns whether the connection could be useful to us. We're seeding and\n// they want data, we don't have metainfo and they can provide it, etc.\nfunc (c *PeerConn) useful() bool {\n\tt := c.t\n\tif c.closed.IsSet() {\n\t\treturn false\n\t}\n\tif !t.haveInfo() {\n\t\treturn c.supportsExtension(\"ut_metadata\")\n\t}\n\tif t.seeding() && c.peerInterested {\n\t\treturn true\n\t}\n\tif c.peerHasWantedPieces() {\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc makeBuiltinLtepProtocols(pex bool) LocalLtepProtocolMap {\n\tps := []pp.ExtensionName{pp.ExtensionNameMetadata, utHolepunch.ExtensionName}\n\tif pex {\n\t\tps = append(ps, pp.ExtensionNamePex)\n\t}\n\treturn LocalLtepProtocolMap{\n\t\tIndex:      ps,\n\t\tNumBuiltin: len(ps),\n\t}\n}\n\nfunc (c *PeerConn) addBuiltinLtepProtocols(pex bool) {\n\tc.LocalLtepProtocolMap = &c.t.cl.defaultLocalLtepProtocolMap\n}\n\nfunc (pc *PeerConn) WriteExtendedMessage(extName pp.ExtensionName, payload []byte) error {\n\tpc.locker().Lock()\n\tdefer pc.locker().Unlock()\n\tid := pc.PeerExtensionIDs[extName]\n\tif id == 0 {\n\t\treturn fmt.Errorf(\"peer does not support or has disabled extension %q\", extName)\n\t}\n\tpc.write(pp.Message{\n\t\tType:            pp.Extended,\n\t\tExtendedID:      id,\n\t\tExtendedPayload: payload,\n\t})\n\treturn nil\n}\n\nfunc (pc *PeerConn) shouldRequestHashes() bool {\n\treturn pc.t.haveInfo() && pc.v2 && pc.t.info.HasV2()\n}\n\nfunc (pc *PeerConn) requestMissingHashes() {\n\tif !pc.shouldRequestHashes() {\n\t\treturn\n\t}\n\tinfo := pc.t.info\n\tbaseLayer := pp.Integer(merkle.Log2RoundingUp(merkle.RoundUpToPowerOfTwo(\n\t\tuint((pc.t.usualPieceSize() + merkle.BlockSize - 1) / merkle.BlockSize)),\n\t))\n\tnextFileBeginPiece := 0\nfile:\n\tfor _, file := range info.UpvertedFiles() {\n\t\tfileNumPieces := int((file.Length + info.PieceLength - 1) / info.PieceLength)\n\t\t// We would be requesting the leaves, the file must be short enough that we can just do with\n\t\t// the pieces root as the piece hash.\n\t\tif fileNumPieces <= 1 {\n\t\t\tcontinue\n\t\t}\n\t\tcurFileBeginPiece := nextFileBeginPiece\n\t\tnextFileBeginPiece += fileNumPieces\n\t\thaveAllHashes := true\n\t\tfor i := range fileNumPieces {\n\t\t\ttorrentPieceIndex := curFileBeginPiece + i\n\t\t\tif !pc.peerHasPiece(torrentPieceIndex) {\n\t\t\t\tcontinue file\n\t\t\t}\n\t\t\tif !pc.t.piece(torrentPieceIndex).hashV2.Ok {\n\t\t\t\thaveAllHashes = false\n\t\t\t}\n\t\t}\n\t\tif haveAllHashes {\n\t\t\tcontinue\n\t\t}\n\t\tpiecesRoot := file.PiecesRoot.Unwrap()\n\t\tproofLayers := pp.Integer(0)\n\t\tfor index := 0; index < fileNumPieces; index += 512 {\n\t\t\t// Minimizing to the number of pieces in a file conflicts with the BEP.\n\t\t\tlength := merkle.RoundUpToPowerOfTwo(uint(min(512, fileNumPieces-index)))\n\t\t\tif length < 2 {\n\t\t\t\t// This should have been filtered out by baseLayer and pieces root as piece hash\n\t\t\t\t// checks.\n\t\t\t\tpanic(length)\n\t\t\t}\n\t\t\tif length%2 != 0 {\n\t\t\t\tpc.protocolLogger.Levelf(log.Warning, \"requesting odd hashes length %d\", length)\n\t\t\t}\n\t\t\tmsg := pp.Message{\n\t\t\t\tType:        pp.HashRequest,\n\t\t\t\tPiecesRoot:  piecesRoot,\n\t\t\t\tBaseLayer:   baseLayer,\n\t\t\t\tIndex:       pp.Integer(index),\n\t\t\t\tLength:      pp.Integer(length),\n\t\t\t\tProofLayers: proofLayers,\n\t\t\t}\n\t\t\thr := hashRequestFromMessage(msg)\n\t\t\tif generics.MapContains(pc.sentHashRequests, hr) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tpc.write(msg)\n\t\t\tgenerics.MakeMapIfNil(&pc.sentHashRequests)\n\t\t\tpc.sentHashRequests[hr] = struct{}{}\n\t\t}\n\t}\n}\n\nfunc (pc *PeerConn) onReadHashes(msg *pp.Message) (err error) {\n\tfile := pc.t.getFileByPiecesRoot(msg.PiecesRoot)\n\tfilePieceHashes := pc.receivedHashPieces[msg.PiecesRoot]\n\tif filePieceHashes == nil {\n\t\tfilePieceHashes = make([][32]byte, file.numPieces())\n\t\tgenerics.MakeMapIfNil(&pc.receivedHashPieces)\n\t\tpc.receivedHashPieces[msg.PiecesRoot] = filePieceHashes\n\t}\n\tif msg.ProofLayers != 0 {\n\t\t// This isn't handled yet.\n\t\tpanic(msg.ProofLayers)\n\t}\n\tcopy(filePieceHashes[msg.Index:], msg.Hashes)\n\troot := merkle.RootWithPadHash(\n\t\tfilePieceHashes,\n\t\tmetainfo.HashForPiecePad(int64(pc.t.usualPieceSize())))\n\texpectedPiecesRoot := file.piecesRoot.Unwrap()\n\tif root == expectedPiecesRoot {\n\t\tpc.protocolLogger.WithNames(v2HashesLogName).Levelf(\n\t\t\tlog.Info,\n\t\t\t\"got piece hashes for file %v (num pieces %v)\",\n\t\t\tfile, file.numPieces())\n\t\tfor filePieceIndex, peerHash := range filePieceHashes {\n\t\t\ttorrentPieceIndex := file.BeginPieceIndex() + filePieceIndex\n\t\t\tpc.t.piece(torrentPieceIndex).setV2Hash(peerHash)\n\t\t}\n\t} else {\n\t\tpc.protocolLogger.WithNames(v2HashesLogName).Levelf(\n\t\t\tlog.Debug,\n\t\t\t\"peer file piece hashes root mismatch: %x != %x\",\n\t\t\troot, expectedPiecesRoot)\n\t}\n\treturn nil\n}\n\nfunc (pc *PeerConn) getHashes(msg *pp.Message) ([][32]byte, error) {\n\tif msg.ProofLayers != 0 {\n\t\treturn nil, errors.New(\"proof layers not supported\")\n\t}\n\tif msg.Length > 8192 {\n\t\treturn nil, fmt.Errorf(\"requested too many hashes: %d\", msg.Length)\n\t}\n\tfile := pc.t.getFileByPiecesRoot(msg.PiecesRoot)\n\tif file == nil {\n\t\treturn nil, fmt.Errorf(\"no file for pieces root %x\", msg.PiecesRoot)\n\t}\n\tbeginPieceIndex := file.BeginPieceIndex()\n\tendPieceIndex := file.EndPieceIndex()\n\tlength := merkle.RoundUpToPowerOfTwo(uint(endPieceIndex - beginPieceIndex))\n\tif uint(msg.Index+msg.Length) > length {\n\t\treturn nil, errors.New(\"invalid hash range\")\n\t}\n\n\thashes := make([][32]byte, msg.Length)\n\tpadHash := metainfo.HashForPiecePad(int64(pc.t.usualPieceSize()))\n\tfor i := range hashes {\n\t\ttorrentPieceIndex := beginPieceIndex + int(msg.Index) + i\n\t\tif torrentPieceIndex >= endPieceIndex {\n\t\t\thashes[i] = padHash\n\t\t\tcontinue\n\t\t}\n\t\tpiece := pc.t.piece(torrentPieceIndex)\n\t\thash, err := piece.obtainHashV2()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"can't get hash for piece %d: %w\", torrentPieceIndex, err)\n\t\t}\n\t\thashes[i] = hash\n\t}\n\treturn hashes, nil\n}\n\nfunc (pc *PeerConn) onHashRequest(msg *pp.Message) error {\n\tif !pc.t.info.HasV2() {\n\t\treturn errors.New(\"torrent has no v2 metadata\")\n\t}\n\n\tresp := pp.Message{\n\t\tPiecesRoot:  msg.PiecesRoot,\n\t\tBaseLayer:   msg.BaseLayer,\n\t\tIndex:       msg.Index,\n\t\tLength:      msg.Length,\n\t\tProofLayers: msg.ProofLayers,\n\t}\n\n\thashes, err := pc.getHashes(msg)\n\tif err != nil {\n\t\tpc.protocolLogger.WithNames(v2HashesLogName).Levelf(log.Debug, \"error getting hashes: %v\", err)\n\t\tresp.Type = pp.HashReject\n\t\tpc.write(resp)\n\t\treturn nil\n\t}\n\n\tresp.Type = pp.Hashes\n\tresp.Hashes = hashes\n\tpc.write(resp)\n\treturn nil\n}\n\ntype hashRequest struct {\n\tpiecesRoot                            [32]byte\n\tbaseLayer, index, length, proofLayers pp.Integer\n}\n\nfunc (hr hashRequest) toMessage() pp.Message {\n\treturn pp.Message{\n\t\tType:        pp.HashRequest,\n\t\tPiecesRoot:  hr.piecesRoot,\n\t\tBaseLayer:   hr.baseLayer,\n\t\tIndex:       hr.index,\n\t\tLength:      hr.length,\n\t\tProofLayers: hr.proofLayers,\n\t}\n}\n\nfunc hashRequestFromMessage(m pp.Message) hashRequest {\n\treturn hashRequest{\n\t\tpiecesRoot:  m.PiecesRoot,\n\t\tbaseLayer:   m.BaseLayer,\n\t\tindex:       m.Index,\n\t\tlength:      m.Length,\n\t\tproofLayers: m.ProofLayers,\n\t}\n}\n"
        },
        {
          "name": "peerconn_test.go",
          "type": "blob",
          "size": 11.4375,
          "content": "package torrent\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/netip\"\n\t\"sync\"\n\t\"testing\"\n\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/frankban/quicktest\"\n\tqt \"github.com/frankban/quicktest\"\n\t\"github.com/stretchr/testify/require\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\n// Ensure that no race exists between sending a bitfield, and a subsequent\n// Have that would potentially alter it.\nfunc TestSendBitfieldThenHave(t *testing.T) {\n\tvar cl Client\n\tcl.init(TestingConfig(t))\n\tcl.initLogger()\n\tqtc := qt.New(t)\n\tc := cl.newConnection(nil, newConnectionOpts{network: \"io.Pipe\"})\n\tc.setTorrent(cl.newTorrentForTesting())\n\terr := c.t.setInfo(&metainfo.Info{Pieces: make([]byte, metainfo.HashSize*3)})\n\tqtc.Assert(err, qt.IsNil)\n\tr, w := io.Pipe()\n\t// c.r = r\n\tc.w = w\n\tc.startMessageWriter()\n\tc.locker().Lock()\n\tc.t._completedPieces.Add(1)\n\tc.postBitfield( /*[]bool{false, true, false}*/ )\n\tc.locker().Unlock()\n\tc.locker().Lock()\n\tc.have(2)\n\tc.locker().Unlock()\n\tb := make([]byte, 15)\n\tn, err := io.ReadFull(r, b)\n\tc.locker().Lock()\n\t// This will cause connection.writer to terminate.\n\tc.closed.Set()\n\tc.locker().Unlock()\n\trequire.NoError(t, err)\n\trequire.EqualValues(t, 15, n)\n\t// Here we see that the bitfield doesn't have piece 2 set, as that should\n\t// arrive in the following Have message.\n\trequire.EqualValues(t, \"\\x00\\x00\\x00\\x02\\x05@\\x00\\x00\\x00\\x05\\x04\\x00\\x00\\x00\\x02\", string(b))\n}\n\ntype torrentStorage struct {\n\tallChunksWritten sync.WaitGroup\n}\n\nfunc (me *torrentStorage) Close() error { return nil }\n\nfunc (me *torrentStorage) Piece(mp metainfo.Piece) storage.PieceImpl {\n\treturn me\n}\n\nfunc (me *torrentStorage) Completion() storage.Completion {\n\treturn storage.Completion{}\n}\n\nfunc (me *torrentStorage) MarkComplete() error {\n\treturn nil\n}\n\nfunc (me *torrentStorage) MarkNotComplete() error {\n\treturn nil\n}\n\nfunc (me *torrentStorage) ReadAt([]byte, int64) (int, error) {\n\tpanic(\"shouldn't be called\")\n}\n\nfunc (me *torrentStorage) WriteAt(b []byte, _ int64) (int, error) {\n\tif len(b) != defaultChunkSize {\n\t\tpanic(len(b))\n\t}\n\tme.allChunksWritten.Done()\n\treturn len(b), nil\n}\n\nfunc BenchmarkConnectionMainReadLoop(b *testing.B) {\n\tc := quicktest.New(b)\n\tvar cl Client\n\tcl.init(&ClientConfig{\n\t\tDownloadRateLimiter: unlimited,\n\t})\n\tcl.initLogger()\n\tts := &torrentStorage{}\n\tt := cl.newTorrentForTesting()\n\tt.initialPieceCheckDisabled = true\n\trequire.NoError(b, t.setInfo(&metainfo.Info{\n\t\tPieces:      make([]byte, 20),\n\t\tLength:      1 << 20,\n\t\tPieceLength: 1 << 20,\n\t}))\n\tt.storage = &storage.Torrent{TorrentImpl: storage.TorrentImpl{Piece: ts.Piece, Close: ts.Close}}\n\tt.onSetInfo()\n\tt._pendingPieces.Add(0)\n\tr, w := net.Pipe()\n\tc.Logf(\"pipe reader remote addr: %v\", r.RemoteAddr())\n\tcn := cl.newConnection(r, newConnectionOpts{\n\t\toutgoing: true,\n\t\t// TODO: This is a hack to give the pipe a bannable remote address.\n\t\tremoteAddr: netip.AddrPortFrom(netip.AddrFrom4([4]byte{1, 2, 3, 4}), 1234),\n\t\tnetwork:    r.RemoteAddr().Network(),\n\t\tconnString: regularNetConnPeerConnConnString(r),\n\t})\n\tc.Assert(cn.bannableAddr.Ok, qt.IsTrue)\n\tcn.setTorrent(t)\n\trequestIndexBegin := t.pieceRequestIndexOffset(0)\n\trequestIndexEnd := t.pieceRequestIndexOffset(1)\n\teachRequestIndex := func(f func(ri RequestIndex)) {\n\t\tfor ri := requestIndexBegin; ri < requestIndexEnd; ri++ {\n\t\t\tf(ri)\n\t\t}\n\t}\n\tconst chunkSize = defaultChunkSize\n\tnumRequests := requestIndexEnd - requestIndexBegin\n\tmsgBufs := make([][]byte, 0, numRequests)\n\teachRequestIndex(func(ri RequestIndex) {\n\t\tmsgBufs = append(msgBufs, pp.Message{\n\t\t\tType:  pp.Piece,\n\t\t\tPiece: make([]byte, chunkSize),\n\t\t\tBegin: pp.Integer(chunkSize) * pp.Integer(ri),\n\t\t}.MustMarshalBinary())\n\t})\n\t// errgroup can't handle this pattern...\n\tallErrors := make(chan error, 2)\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tcl.lock()\n\t\terr := cn.mainReadLoop()\n\t\tif errors.Is(err, io.EOF) {\n\t\t\terr = nil\n\t\t}\n\t\tallErrors <- err\n\t}()\n\tb.SetBytes(chunkSize * int64(numRequests))\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tfor i := 0; i < b.N; i += 1 {\n\t\t\tcl.lock()\n\t\t\t// The chunk must be written to storage everytime, to ensure the\n\t\t\t// writeSem is unlocked.\n\t\t\tt.pendAllChunkSpecs(0)\n\t\t\tg.MakeMapIfNil(&cn.validReceiveChunks)\n\t\t\teachRequestIndex(func(ri RequestIndex) {\n\t\t\t\tcn.validReceiveChunks[ri] = 1\n\t\t\t})\n\t\t\tcl.unlock()\n\t\t\tts.allChunksWritten.Add(int(numRequests))\n\t\t\tfor _, wb := range msgBufs {\n\t\t\t\tn, err := w.Write(wb)\n\t\t\t\trequire.NoError(b, err)\n\t\t\t\trequire.EqualValues(b, len(wb), n)\n\t\t\t}\n\t\t\t// This is unlocked by a successful write to storage. So this unblocks when that is\n\t\t\t// done.\n\t\t\tts.allChunksWritten.Wait()\n\t\t}\n\t\tif err := w.Close(); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}()\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(allErrors)\n\t}()\n\tvar err error\n\tfor err = range allErrors {\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\tc.Assert(err, qt.IsNil)\n\tc.Assert(cn._stats.ChunksReadUseful.Int64(), quicktest.Equals, int64(b.N)*int64(numRequests))\n\tc.Assert(t.smartBanCache.HasBlocks(), qt.IsTrue)\n}\n\nfunc TestConnPexPeerFlags(t *testing.T) {\n\tvar (\n\t\ttcpAddr = &net.TCPAddr{IP: net.IPv6loopback, Port: 4848}\n\t\tudpAddr = &net.UDPAddr{IP: net.IPv6loopback, Port: 4848}\n\t)\n\ttestcases := []struct {\n\t\tconn *PeerConn\n\t\tf    pp.PexPeerFlags\n\t}{\n\t\t{&PeerConn{Peer: Peer{outgoing: false, PeerPrefersEncryption: false}}, 0},\n\t\t{&PeerConn{Peer: Peer{outgoing: false, PeerPrefersEncryption: true}}, pp.PexPrefersEncryption},\n\t\t{&PeerConn{Peer: Peer{outgoing: true, PeerPrefersEncryption: false}}, pp.PexOutgoingConn},\n\t\t{&PeerConn{Peer: Peer{outgoing: true, PeerPrefersEncryption: true}}, pp.PexOutgoingConn | pp.PexPrefersEncryption},\n\t\t{&PeerConn{Peer: Peer{RemoteAddr: udpAddr, Network: udpAddr.Network()}}, pp.PexSupportsUtp},\n\t\t{&PeerConn{Peer: Peer{RemoteAddr: udpAddr, Network: udpAddr.Network(), outgoing: true}}, pp.PexOutgoingConn | pp.PexSupportsUtp},\n\t\t{&PeerConn{Peer: Peer{RemoteAddr: tcpAddr, Network: tcpAddr.Network(), outgoing: true}}, pp.PexOutgoingConn},\n\t\t{&PeerConn{Peer: Peer{RemoteAddr: tcpAddr, Network: tcpAddr.Network()}}, 0},\n\t}\n\tfor i, tc := range testcases {\n\t\tf := tc.conn.pexPeerFlags()\n\t\trequire.EqualValues(t, tc.f, f, i)\n\t}\n}\n\nfunc TestConnPexEvent(t *testing.T) {\n\tc := qt.New(t)\n\tvar (\n\t\tudpAddr     = &net.UDPAddr{IP: net.IPv6loopback, Port: 4848}\n\t\ttcpAddr     = &net.TCPAddr{IP: net.IPv6loopback, Port: 4848}\n\t\tdialTcpAddr = &net.TCPAddr{IP: net.IPv6loopback, Port: 4747}\n\t\tdialUdpAddr = &net.UDPAddr{IP: net.IPv6loopback, Port: 4747}\n\t)\n\ttestcases := []struct {\n\t\tt pexEventType\n\t\tc *PeerConn\n\t\te pexEvent\n\t}{\n\t\t{\n\t\t\tpexAdd,\n\t\t\t&PeerConn{Peer: Peer{RemoteAddr: udpAddr, Network: udpAddr.Network()}},\n\t\t\tpexEvent{pexAdd, udpAddr.AddrPort(), pp.PexSupportsUtp, nil},\n\t\t},\n\t\t{\n\t\t\tpexDrop,\n\t\t\t&PeerConn{\n\t\t\t\tPeer:           Peer{RemoteAddr: tcpAddr, Network: tcpAddr.Network(), outgoing: true},\n\t\t\t\tPeerListenPort: dialTcpAddr.Port,\n\t\t\t},\n\t\t\tpexEvent{pexDrop, tcpAddr.AddrPort(), pp.PexOutgoingConn, nil},\n\t\t},\n\t\t{\n\t\t\tpexAdd,\n\t\t\t&PeerConn{\n\t\t\t\tPeer:           Peer{RemoteAddr: tcpAddr, Network: tcpAddr.Network()},\n\t\t\t\tPeerListenPort: dialTcpAddr.Port,\n\t\t\t},\n\t\t\tpexEvent{pexAdd, dialTcpAddr.AddrPort(), 0, nil},\n\t\t},\n\t\t{\n\t\t\tpexDrop,\n\t\t\t&PeerConn{\n\t\t\t\tPeer:           Peer{RemoteAddr: udpAddr, Network: udpAddr.Network()},\n\t\t\t\tPeerListenPort: dialUdpAddr.Port,\n\t\t\t},\n\t\t\tpexEvent{pexDrop, dialUdpAddr.AddrPort(), pp.PexSupportsUtp, nil},\n\t\t},\n\t}\n\tfor i, tc := range testcases {\n\t\tc.Run(fmt.Sprintf(\"%v\", i), func(c *qt.C) {\n\t\t\te, err := tc.c.pexEvent(tc.t)\n\t\t\tc.Assert(err, qt.IsNil)\n\t\t\tc.Check(e, qt.Equals, tc.e)\n\t\t})\n\t}\n}\n\nfunc TestHaveAllThenBitfield(t *testing.T) {\n\tc := qt.New(t)\n\tcl := newTestingClient(t)\n\ttt := cl.newTorrentForTesting()\n\t// cl.newConnection()\n\tpc := PeerConn{\n\t\tPeer: Peer{t: tt},\n\t}\n\tpc.initRequestState()\n\tpc.peerImpl = &pc\n\ttt.conns[&pc] = struct{}{}\n\tc.Assert(pc.onPeerSentHaveAll(), qt.IsNil)\n\tc.Check(pc.t.connsWithAllPieces, qt.DeepEquals, map[*Peer]struct{}{&pc.Peer: {}})\n\tpc.peerSentBitfield([]bool{false, false, true, false, true, true, false, false})\n\tc.Check(pc.peerMinPieces, qt.Equals, 6)\n\tc.Check(pc.t.connsWithAllPieces, qt.HasLen, 0)\n\tc.Assert(pc.t.setInfo(&metainfo.Info{\n\t\tPieceLength: 0,\n\t\tPieces:      make([]byte, pieceHash.Size()*7),\n\t}), qt.IsNil)\n\tpc.t.onSetInfo()\n\tc.Check(tt.numPieces(), qt.Equals, 7)\n\tc.Check(tt.pieceAvailabilityRuns(), qt.DeepEquals, []pieceAvailabilityRun{\n\t\t// The last element of the bitfield is irrelevant, as the Torrent actually only has 7\n\t\t// pieces.\n\t\t{2, 0}, {1, 1}, {1, 0}, {2, 1}, {1, 0},\n\t})\n}\n\nfunc TestApplyRequestStateWriteBufferConstraints(t *testing.T) {\n\tc := qt.New(t)\n\tc.Check(interestedMsgLen, qt.Equals, 5)\n\tc.Check(requestMsgLen, qt.Equals, 17)\n\tc.Check(maxLocalToRemoteRequests >= 8, qt.IsTrue)\n\tc.Logf(\"max local to remote requests: %v\", maxLocalToRemoteRequests)\n}\n\nfunc peerConnForPreferredNetworkDirection(\n\tlocalPeerId, remotePeerId int,\n\toutgoing, utp, ipv6 bool,\n) *PeerConn {\n\tpc := PeerConn{}\n\tpc.outgoing = outgoing\n\tif utp {\n\t\tpc.Network = \"udp\"\n\t}\n\tif ipv6 {\n\t\tpc.RemoteAddr = &net.TCPAddr{IP: net.ParseIP(\"::420\")}\n\t} else {\n\t\tpc.RemoteAddr = &net.TCPAddr{IP: net.IPv4(1, 2, 3, 4)}\n\t}\n\tbinary.BigEndian.PutUint64(pc.PeerID[:], uint64(remotePeerId))\n\tcl := Client{}\n\tbinary.BigEndian.PutUint64(cl.peerID[:], uint64(localPeerId))\n\tpc.t = &Torrent{cl: &cl}\n\treturn &pc\n}\n\nfunc TestPreferredNetworkDirection(t *testing.T) {\n\tpc := peerConnForPreferredNetworkDirection\n\tc := qt.New(t)\n\n\t// Prefer outgoing to lower peer ID\n\n\tc.Check(\n\t\tpc(1, 2, true, false, false).hasPreferredNetworkOver(pc(1, 2, false, false, false)),\n\t\tqt.IsFalse,\n\t)\n\tc.Check(\n\t\tpc(1, 2, false, false, false).hasPreferredNetworkOver(pc(1, 2, true, false, false)),\n\t\tqt.IsTrue,\n\t)\n\tc.Check(\n\t\tpc(2, 1, false, false, false).hasPreferredNetworkOver(pc(2, 1, true, false, false)),\n\t\tqt.IsFalse,\n\t)\n\n\t// Don't prefer uTP\n\tc.Check(\n\t\tpc(1, 2, false, true, false).hasPreferredNetworkOver(pc(1, 2, false, false, false)),\n\t\tqt.IsFalse,\n\t)\n\t// Prefer IPv6\n\tc.Check(\n\t\tpc(1, 2, false, false, false).hasPreferredNetworkOver(pc(1, 2, false, false, true)),\n\t\tqt.IsFalse,\n\t)\n\t// No difference\n\tc.Check(\n\t\tpc(1, 2, false, false, false).hasPreferredNetworkOver(pc(1, 2, false, false, false)),\n\t\tqt.IsFalse,\n\t)\n}\n\nfunc TestReceiveLargeRequest(t *testing.T) {\n\tc := qt.New(t)\n\tcl := newTestingClient(t)\n\tpc := cl.newConnection(nil, newConnectionOpts{network: \"test\"})\n\ttor := cl.newTorrentForTesting()\n\ttor.info = &metainfo.Info{PieceLength: 3 << 20}\n\tpc.setTorrent(tor)\n\ttor._completedPieces.Add(0)\n\tpc.PeerExtensionBytes.SetBit(pp.ExtensionBitFast, true)\n\tpc.choking = false\n\tpc.initMessageWriter()\n\treq := Request{}\n\treq.Length = defaultChunkSize\n\tc.Assert(pc.fastEnabled(), qt.IsTrue)\n\tc.Check(pc.onReadRequest(req, false), qt.IsNil)\n\tc.Check(pc.peerRequests, qt.HasLen, 1)\n\treq.Length = 2 << 20\n\tc.Check(pc.onReadRequest(req, false), qt.IsNil)\n\tc.Check(pc.peerRequests, qt.HasLen, 2)\n\tpc.peerRequests = nil\n\tpc.t.cl.config.UploadRateLimiter = rate.NewLimiter(1, defaultChunkSize)\n\treq.Length = defaultChunkSize\n\tc.Check(pc.onReadRequest(req, false), qt.IsNil)\n\tc.Check(pc.peerRequests, qt.HasLen, 1)\n\treq.Length = 2 << 20\n\tc.Check(pc.onReadRequest(req, false), qt.IsNil)\n\tc.Check(pc.messageWriter.writeBuffer.Len(), qt.Equals, 17)\n}\n\nfunc TestChunkOverflowsPiece(t *testing.T) {\n\tc := qt.New(t)\n\tcheck := func(begin, length, limit pp.Integer, expected bool) {\n\t\tc.Check(chunkOverflowsPiece(ChunkSpec{begin, length}, limit), qt.Equals, expected)\n\t}\n\tcheck(2, 3, 1, true)\n\tcheck(2, pp.IntegerMax, 1, true)\n\tcheck(2, pp.IntegerMax, 3, true)\n\tcheck(2, pp.IntegerMax, pp.IntegerMax, true)\n\tcheck(2, pp.IntegerMax-2, pp.IntegerMax, false)\n}\n"
        },
        {
          "name": "peerid.go",
          "type": "blob",
          "size": 0.0869140625,
          "content": "package torrent\n\nimport \"github.com/anacrolix/torrent/types\"\n\ntype PeerID = types.PeerID\n"
        },
        {
          "name": "peerid_test.go",
          "type": "blob",
          "size": 0.5126953125,
          "content": "package torrent\n\n// func TestPeerIdString(t *testing.T) {\n// \tfor _, _case := range []struct {\n// \t\tid string\n// \t\ts  string\n// \t}{\n// \t\t{\"\\x1cNJ}\\x9c\\xc7\\xc4o\\x94<\\x9b\\x8c\\xc2!I\\x1c\\a\\xec\\x98n\", \"\\\"\\x1cNJ}\\x9c\\xc7\\xc4o\\x94<\\x9b\\x8c\\xc2!I\\x1c\\a\\xec\\x98n\\\"\"},\n// \t\t{\"-FD51W\\xe4-LaZMk0N8ZLA7\", \"-FD51W\\xe4-LaZMk0N8ZLA7\"},\n// \t} {\n// \t\tvar pi PeerID\n// \t\tmissinggo.CopyExact(&pi, _case.id)\n// \t\tassert.EqualValues(t, _case.s, pi.String())\n// \t\tassert.EqualValues(t, fmt.Sprintf(\"%q\", _case.s), fmt.Sprintf(\"%q\", pi))\n// \t}\n// }\n"
        },
        {
          "name": "pex.go",
          "type": "blob",
          "size": 5.5126953125,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"net/netip\"\n\t\"sync\"\n\t\"time\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\ntype pexEventType int\n\nconst (\n\tpexAdd pexEventType = iota\n\tpexDrop\n)\n\n// internal, based on BEP11\nconst (\n\tpexTargAdded = 25 // put drops on hold when the number of alive connections is lower than this\n\tpexMaxHold   = 25 // length of the drop hold-back buffer\n\tpexMaxDelta  = 50 // upper bound on added+added6 and dropped+dropped6 in a single PEX message\n)\n\n// represents a single connection (t=pexAdd) or disconnection (t=pexDrop) event\ntype pexEvent struct {\n\tt    pexEventType\n\taddr netip.AddrPort\n\tf    pp.PexPeerFlags\n\tnext *pexEvent // event feed list\n}\n\n// facilitates efficient de-duplication while generating PEX messages\ntype pexMsgFactory struct {\n\tmsg     pp.PexMsg\n\tadded   map[netip.AddrPort]struct{}\n\tdropped map[netip.AddrPort]struct{}\n}\n\nfunc (me *pexMsgFactory) DeltaLen() int {\n\treturn int(max(\n\t\tint64(len(me.added)),\n\t\tint64(len(me.dropped))))\n}\n\ntype addrKey = netip.AddrPort\n\n// Returns the key to use to identify a given addr in the factory.\nfunc (me *pexMsgFactory) addrKey(addr netip.AddrPort) addrKey {\n\treturn addr\n}\n\n// Returns whether the entry was added (we can check if we're cancelling out another entry and so\n// won't hit the limit consuming this event).\nfunc (me *pexMsgFactory) add(e pexEvent) {\n\tkey := me.addrKey(e.addr)\n\tif _, ok := me.added[key]; ok {\n\t\treturn\n\t}\n\tif me.added == nil {\n\t\tme.added = make(map[addrKey]struct{}, pexMaxDelta)\n\t}\n\taddr := krpcNodeAddrFromAddrPort(e.addr)\n\tm := &me.msg\n\tswitch {\n\tcase addr.IP.To4() != nil:\n\t\tif _, ok := me.dropped[key]; ok {\n\t\t\tif i := m.Dropped.Index(addr); i >= 0 {\n\t\t\t\tm.Dropped = append(m.Dropped[:i], m.Dropped[i+1:]...)\n\t\t\t}\n\t\t\tdelete(me.dropped, key)\n\t\t\treturn\n\t\t}\n\t\tm.Added = append(m.Added, addr)\n\t\tm.AddedFlags = append(m.AddedFlags, e.f)\n\tcase len(addr.IP) == net.IPv6len:\n\t\tif _, ok := me.dropped[key]; ok {\n\t\t\tif i := m.Dropped6.Index(addr); i >= 0 {\n\t\t\t\tm.Dropped6 = append(m.Dropped6[:i], m.Dropped6[i+1:]...)\n\t\t\t}\n\t\t\tdelete(me.dropped, key)\n\t\t\treturn\n\t\t}\n\t\tm.Added6 = append(m.Added6, addr)\n\t\tm.Added6Flags = append(m.Added6Flags, e.f)\n\tdefault:\n\t\tpanic(addr)\n\t}\n\tme.added[key] = struct{}{}\n}\n\n// Returns whether the entry was added (we can check if we're cancelling out another entry and so\n// won't hit the limit consuming this event).\nfunc (me *pexMsgFactory) drop(e pexEvent) {\n\taddr := krpcNodeAddrFromAddrPort(e.addr)\n\tkey := me.addrKey(e.addr)\n\tif me.dropped == nil {\n\t\tme.dropped = make(map[addrKey]struct{}, pexMaxDelta)\n\t}\n\tif _, ok := me.dropped[key]; ok {\n\t\treturn\n\t}\n\tm := &me.msg\n\tswitch {\n\tcase addr.IP.To4() != nil:\n\t\tif _, ok := me.added[key]; ok {\n\t\t\tif i := m.Added.Index(addr); i >= 0 {\n\t\t\t\tm.Added = append(m.Added[:i], m.Added[i+1:]...)\n\t\t\t\tm.AddedFlags = append(m.AddedFlags[:i], m.AddedFlags[i+1:]...)\n\t\t\t}\n\t\t\tdelete(me.added, key)\n\t\t\treturn\n\t\t}\n\t\tm.Dropped = append(m.Dropped, addr)\n\tcase len(addr.IP) == net.IPv6len:\n\t\tif _, ok := me.added[key]; ok {\n\t\t\tif i := m.Added6.Index(addr); i >= 0 {\n\t\t\t\tm.Added6 = append(m.Added6[:i], m.Added6[i+1:]...)\n\t\t\t\tm.Added6Flags = append(m.Added6Flags[:i], m.Added6Flags[i+1:]...)\n\t\t\t}\n\t\t\tdelete(me.added, key)\n\t\t\treturn\n\t\t}\n\t\tm.Dropped6 = append(m.Dropped6, addr)\n\t}\n\tme.dropped[key] = struct{}{}\n}\n\nfunc (me *pexMsgFactory) append(event pexEvent) {\n\tswitch event.t {\n\tcase pexAdd:\n\t\tme.add(event)\n\tcase pexDrop:\n\t\tme.drop(event)\n\tdefault:\n\t\tpanic(event.t)\n\t}\n}\n\nfunc (me *pexMsgFactory) PexMsg() *pp.PexMsg {\n\treturn &me.msg\n}\n\n// Per-torrent PEX state\ntype pexState struct {\n\tsync.RWMutex\n\ttail *pexEvent  // event feed list\n\thold []pexEvent // delayed drops\n\t// Torrent-wide cooldown deadline on inbound. This exists to prevent PEX from drowning out other\n\t// peer address sources, until that is fixed.\n\trest time.Time\n\tnc   int           // net number of alive conns\n\tmsg0 pexMsgFactory // initial message\n}\n\n// Reset wipes the state clean, releasing resources. Called from Torrent.Close().\nfunc (s *pexState) Reset() {\n\ts.Lock()\n\tdefer s.Unlock()\n\ts.tail = nil\n\ts.hold = nil\n\ts.nc = 0\n\ts.rest = time.Time{}\n\ts.msg0 = pexMsgFactory{}\n}\n\nfunc (s *pexState) append(e *pexEvent) {\n\tif s.tail != nil {\n\t\ts.tail.next = e\n\t}\n\ts.tail = e\n\ts.msg0.append(*e)\n}\n\nfunc (s *pexState) Add(c *PeerConn) {\n\te, err := c.pexEvent(pexAdd)\n\tif err != nil {\n\t\treturn\n\t}\n\ts.Lock()\n\tdefer s.Unlock()\n\ts.nc++\n\tif s.nc >= pexTargAdded {\n\t\tfor _, e := range s.hold {\n\t\t\tne := e\n\t\t\ts.append(&ne)\n\t\t}\n\t\ts.hold = s.hold[:0]\n\t}\n\tc.pex.Listed = true\n\ts.append(&e)\n}\n\nfunc (s *pexState) Drop(c *PeerConn) {\n\tif !c.pex.Listed {\n\t\t// skip connections which were not previously Added\n\t\treturn\n\t}\n\te, err := c.pexEvent(pexDrop)\n\tif err != nil {\n\t\treturn\n\t}\n\ts.Lock()\n\tdefer s.Unlock()\n\ts.nc--\n\tif s.nc < pexTargAdded && len(s.hold) < pexMaxHold {\n\t\ts.hold = append(s.hold, e)\n\t} else {\n\t\ts.append(&e)\n\t}\n}\n\n// Generate a PEX message based on the event feed.\n// Also returns a pointer to pass to the subsequent calls\n// to produce incremental deltas.\nfunc (s *pexState) Genmsg(start *pexEvent) (pp.PexMsg, *pexEvent) {\n\ts.RLock()\n\tdefer s.RUnlock()\n\tif start == nil {\n\t\treturn *s.msg0.PexMsg(), s.tail\n\t}\n\tvar msg pexMsgFactory\n\tlast := start\n\tfor e := start.next; e != nil; e = e.next {\n\t\tif msg.DeltaLen() >= pexMaxDelta {\n\t\t\tbreak\n\t\t}\n\t\tmsg.append(*e)\n\t\tlast = e\n\t}\n\treturn *msg.PexMsg(), last\n}\n\n// The same as Genmsg but just counts up the distinct events that haven't been sent.\nfunc (s *pexState) numPending(start *pexEvent) (num int) {\n\ts.RLock()\n\tdefer s.RUnlock()\n\tif start == nil {\n\t\treturn s.msg0.PexMsg().Len()\n\t}\n\tfor e := start.next; e != nil; e = e.next {\n\t\tnum++\n\t}\n\treturn\n}\n"
        },
        {
          "name": "pex_test.go",
          "type": "blob",
          "size": 8.36328125,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nvar (\n\taddrs6 = []net.Addr{\n\t\t&net.TCPAddr{IP: net.IPv6loopback, Port: 4747},\n\t\t&net.TCPAddr{IP: net.IPv6loopback, Port: 4748},\n\t\t&net.TCPAddr{IP: net.IPv6loopback, Port: 4749},\n\t\t&net.TCPAddr{IP: net.IPv6loopback, Port: 4750},\n\t}\n\taddrs4 = []net.Addr{\n\t\t&net.TCPAddr{IP: net.IPv4(127, 0, 0, 1), Port: 4747},\n\t\t&net.TCPAddr{IP: net.IPv4(127, 0, 0, 1), Port: 4748},\n\t\t&net.TCPAddr{IP: net.IPv4(127, 0, 0, 1), Port: 4749},\n\t\t&net.TCPAddr{IP: net.IPv4(127, 0, 0, 1), Port: 4750},\n\t}\n\taddrs = []net.Addr{\n\t\taddrs6[0],\n\t\taddrs6[1],\n\t\taddrs4[0],\n\t\taddrs4[1],\n\t}\n)\n\nfunc TestPexReset(t *testing.T) {\n\ts := &pexState{}\n\tconns := []PeerConn{\n\t\t{Peer: Peer{RemoteAddr: addrs[0]}},\n\t\t{Peer: Peer{RemoteAddr: addrs[1]}},\n\t\t{Peer: Peer{RemoteAddr: addrs[2]}},\n\t}\n\ts.Add(&conns[0])\n\ts.Add(&conns[1])\n\ts.Drop(&conns[0])\n\ts.Reset()\n\ttarg := new(pexState)\n\trequire.EqualValues(t, targ, s)\n}\n\nfunc krpcNodeAddrFromNetAddr(addr net.Addr) krpc.NodeAddr {\n\taddrPort, err := addrPortFromPeerRemoteAddr(addr)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn krpcNodeAddrFromAddrPort(addrPort)\n}\n\nvar testcases = []struct {\n\tname   string\n\tin     *pexState\n\ttarg   pp.PexMsg\n\tupdate func(*pexState)\n\ttarg1  pp.PexMsg\n}{\n\t{\n\t\tname: \"empty\",\n\t\tin:   &pexState{},\n\t\ttarg: pp.PexMsg{},\n\t},\n\t{\n\t\tname: \"add0\",\n\t\tin: func() *pexState {\n\t\t\ts := new(pexState)\n\t\t\tnullAddr := &net.TCPAddr{}\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: nullAddr}})\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{},\n\t},\n\t{\n\t\tname: \"drop0\",\n\t\tin: func() *pexState {\n\t\t\tnullAddr := &net.TCPAddr{}\n\t\t\ts := new(pexState)\n\t\t\ts.Drop(&PeerConn{Peer: Peer{RemoteAddr: nullAddr}, pex: pexConnState{Listed: true}})\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{},\n\t},\n\t{\n\t\tname: \"add4\",\n\t\tin: func() *pexState {\n\t\t\ts := new(pexState)\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[0]}})\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[1], outgoing: true}})\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[2], outgoing: true}})\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[3]}})\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tAdded: krpc.CompactIPv4NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[2]),\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[3]),\n\t\t\t},\n\t\t\tAddedFlags: []pp.PexPeerFlags{pp.PexOutgoingConn, 0},\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[0]),\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[1]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0, pp.PexOutgoingConn},\n\t\t},\n\t},\n\t{\n\t\tname: \"drop2\",\n\t\tin: func() *pexState {\n\t\t\ts := &pexState{nc: pexTargAdded + 2}\n\t\t\ts.Drop(&PeerConn{Peer: Peer{RemoteAddr: addrs[0]}, pex: pexConnState{Listed: true}})\n\t\t\ts.Drop(&PeerConn{Peer: Peer{RemoteAddr: addrs[2]}, pex: pexConnState{Listed: true}})\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tDropped: krpc.CompactIPv4NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[2]),\n\t\t\t},\n\t\t\tDropped6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[0]),\n\t\t\t},\n\t\t},\n\t},\n\t{\n\t\tname: \"add2drop1\",\n\t\tin: func() *pexState {\n\t\t\tconns := []PeerConn{\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[0]}},\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[1]}},\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[2]}},\n\t\t\t}\n\t\t\ts := &pexState{nc: pexTargAdded}\n\t\t\ts.Add(&conns[0])\n\t\t\ts.Add(&conns[1])\n\t\t\ts.Drop(&conns[0])\n\t\t\ts.Drop(&conns[2]) // to be ignored: it wasn't added\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[1]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0},\n\t\t},\n\t},\n\t{\n\t\tname: \"delayed\",\n\t\tin: func() *pexState {\n\t\t\tconns := []PeerConn{\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[0]}},\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[1]}},\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[2]}},\n\t\t\t}\n\t\t\ts := new(pexState)\n\t\t\ts.Add(&conns[0])\n\t\t\ts.Add(&conns[1])\n\t\t\ts.Add(&conns[2])\n\t\t\ts.Drop(&conns[0]) // on hold: s.nc < pexTargAdded\n\t\t\ts.Drop(&conns[2])\n\t\t\ts.Drop(&conns[1])\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tAdded: krpc.CompactIPv4NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[2]),\n\t\t\t},\n\t\t\tAddedFlags: []pp.PexPeerFlags{0},\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[0]),\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[1]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0, 0},\n\t\t},\n\t},\n\t{\n\t\tname: \"unheld\",\n\t\tin: func() *pexState {\n\t\t\tconns := []PeerConn{\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[0]}},\n\t\t\t\t{Peer: Peer{RemoteAddr: addrs[1]}},\n\t\t\t}\n\t\t\ts := &pexState{nc: pexTargAdded - 1}\n\t\t\ts.Add(&conns[0])\n\t\t\ts.Drop(&conns[0]) // on hold: s.nc < pexTargAdded\n\t\t\ts.Add(&conns[1])  // unholds the above\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[1]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0},\n\t\t},\n\t},\n\t{\n\t\tname: \"followup\",\n\t\tin: func() *pexState {\n\t\t\ts := new(pexState)\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[0]}})\n\t\t\treturn s\n\t\t}(),\n\t\ttarg: pp.PexMsg{\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[0]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0},\n\t\t},\n\t\tupdate: func(s *pexState) {\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addrs[1]}})\n\t\t},\n\t\ttarg1: pp.PexMsg{\n\t\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\t\tkrpcNodeAddrFromNetAddr(addrs[1]),\n\t\t\t},\n\t\t\tAdded6Flags: []pp.PexPeerFlags{0},\n\t\t},\n\t},\n}\n\n// Represents the contents of a PexMsg in a way that supports equivalence checking in tests. This is\n// necessary because pexMsgFactory uses maps and so ordering of the resultant PexMsg isn't\n// deterministic. Because the flags are in a different array, we can't just use testify's\n// ElementsMatch because the ordering *does* still matter between an added addr and its flags.\ntype comparablePexMsg struct {\n\tadded, added6           []krpc.NodeAddr\n\taddedFlags, added6Flags []pp.PexPeerFlags\n\tdropped, dropped6       []krpc.NodeAddr\n}\n\n// Such Rust-inspired.\nfunc (me *comparablePexMsg) From(f pp.PexMsg) {\n\tme.added = f.Added\n\tme.addedFlags = f.AddedFlags\n\tme.added6 = f.Added6\n\tme.added6Flags = f.Added6Flags\n\tme.dropped = f.Dropped\n\tme.dropped6 = f.Dropped6\n}\n\n// For PexMsg created by pexMsgFactory, this is as good as it can get without using data structures\n// in pexMsgFactory that preserve insert ordering.\nfunc (actual comparablePexMsg) AssertEqual(t *testing.T, expected comparablePexMsg) {\n\tassert.ElementsMatch(t, expected.added, actual.added)\n\tassert.ElementsMatch(t, expected.addedFlags, actual.addedFlags)\n\tassert.ElementsMatch(t, expected.added6, actual.added6)\n\tassert.ElementsMatch(t, expected.added6Flags, actual.added6Flags)\n\tassert.ElementsMatch(t, expected.dropped, actual.dropped)\n\tassert.ElementsMatch(t, expected.dropped6, actual.dropped6)\n}\n\nfunc assertPexMsgsEqual(t *testing.T, expected, actual pp.PexMsg) {\n\tvar ec, ac comparablePexMsg\n\tec.From(expected)\n\tac.From(actual)\n\tac.AssertEqual(t, ec)\n}\n\nfunc TestPexGenmsg0(t *testing.T) {\n\tfor _, tc := range testcases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\ts := *tc.in\n\t\t\tm, last := s.Genmsg(nil)\n\t\t\tassertPexMsgsEqual(t, tc.targ, m)\n\t\t\tif tc.update != nil {\n\t\t\t\ttc.update(&s)\n\t\t\t\tm1, last := s.Genmsg(last)\n\t\t\t\tassertPexMsgsEqual(t, tc.targ1, m1)\n\t\t\t\tassert.NotNil(t, last)\n\t\t\t}\n\t\t})\n\t}\n}\n\n// generate 𝑛 distinct values of net.Addr\nfunc addrgen(n int) chan net.Addr {\n\tc := make(chan net.Addr)\n\tgo func() {\n\t\tdefer close(c)\n\t\tfor i := 4747; i < 65535 && n > 0; i++ {\n\t\t\tc <- &net.TCPAddr{IP: net.IPv4(127, 0, 0, 1), Port: i}\n\t\t\tn--\n\t\t}\n\t}()\n\treturn c\n}\n\nfunc TestPexInitialNoCutoff(t *testing.T) {\n\tconst n = 2 * pexMaxDelta\n\tvar s pexState\n\n\tc := addrgen(n)\n\tfor addr := range c {\n\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addr}})\n\t}\n\tm, _ := s.Genmsg(nil)\n\n\trequire.EqualValues(t, n, len(m.Added))\n\trequire.EqualValues(t, n, len(m.AddedFlags))\n\trequire.EqualValues(t, 0, len(m.Added6))\n\trequire.EqualValues(t, 0, len(m.Added6Flags))\n\trequire.EqualValues(t, 0, len(m.Dropped))\n\trequire.EqualValues(t, 0, len(m.Dropped6))\n}\n\nfunc benchmarkPexInitialN(b *testing.B, npeers int) {\n\tfor i := 0; i < b.N; i++ {\n\t\tvar s pexState\n\t\tc := addrgen(npeers)\n\t\tfor addr := range c {\n\t\t\ts.Add(&PeerConn{Peer: Peer{RemoteAddr: addr}})\n\t\t\ts.Genmsg(nil)\n\t\t}\n\t}\n}\n\n// obtain at least 5 points, e.g. to plot a graph\nfunc BenchmarkPexInitial4(b *testing.B)   { benchmarkPexInitialN(b, 4) }\nfunc BenchmarkPexInitial50(b *testing.B)  { benchmarkPexInitialN(b, 50) }\nfunc BenchmarkPexInitial100(b *testing.B) { benchmarkPexInitialN(b, 100) }\nfunc BenchmarkPexInitial200(b *testing.B) { benchmarkPexInitialN(b, 200) }\nfunc BenchmarkPexInitial400(b *testing.B) { benchmarkPexInitialN(b, 400) }\n"
        },
        {
          "name": "pexconn.go",
          "type": "blob",
          "size": 4.287109375,
          "content": "package torrent\n\nimport (\n\t\"fmt\"\n\t\"net/netip\"\n\t\"time\"\n\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nconst (\n\tpexRetryDelay = 10 * time.Second\n\tpexInterval   = 1 * time.Minute\n)\n\n// per-connection PEX state\ntype pexConnState struct {\n\tenabled bool\n\txid     pp.ExtensionNumber\n\tlast    *pexEvent\n\ttimer   *time.Timer\n\tgate    chan struct{}\n\treadyfn func()\n\ttorrent *Torrent\n\tListed  bool\n\tlogger  log.Logger\n\t// Running record of live connections the remote end of the connection purports to have.\n\tremoteLiveConns map[netip.AddrPort]g.Option[pp.PexPeerFlags]\n\tlastRecv        time.Time\n}\n\nfunc (s *pexConnState) IsEnabled() bool {\n\treturn s.enabled\n}\n\n// Init is called from the reader goroutine upon the extended handshake completion\nfunc (s *pexConnState) Init(c *PeerConn) {\n\txid, ok := c.PeerExtensionIDs[pp.ExtensionNamePex]\n\tif !ok || xid == 0 || c.t.cl.config.DisablePEX {\n\t\treturn\n\t}\n\ts.xid = xid\n\ts.last = nil\n\ts.torrent = c.t\n\ts.logger = c.logger.WithDefaultLevel(log.Debug).WithNames(\"pex\")\n\ts.readyfn = c.tickleWriter\n\ts.gate = make(chan struct{}, 1)\n\ts.timer = time.AfterFunc(0, func() {\n\t\ts.gate <- struct{}{}\n\t\ts.readyfn() // wake up the writer\n\t})\n\ts.enabled = true\n}\n\n// schedule next PEX message\nfunc (s *pexConnState) sched(delay time.Duration) {\n\ts.timer.Reset(delay)\n}\n\n// generate next PEX message for the peer; returns nil if nothing yet to send\nfunc (s *pexConnState) genmsg() *pp.PexMsg {\n\ttx, last := s.torrent.pex.Genmsg(s.last)\n\tif tx.Len() == 0 {\n\t\treturn nil\n\t}\n\ts.last = last\n\treturn &tx\n}\n\nfunc (s *pexConnState) numPending() int {\n\tif s.torrent == nil {\n\t\treturn 0\n\t}\n\treturn s.torrent.pex.numPending(s.last)\n}\n\n// Share is called from the writer goroutine if when it is woken up with the write buffers empty\n// Returns whether there's more room on the send buffer to write to.\nfunc (s *pexConnState) Share(postfn messageWriter) bool {\n\tselect {\n\tcase <-s.gate:\n\t\tif tx := s.genmsg(); tx != nil {\n\t\t\ts.logger.Print(\"sending PEX message: \", tx)\n\t\t\tflow := postfn(tx.Message(s.xid))\n\t\t\ts.sched(pexInterval)\n\t\t\treturn flow\n\t\t} else {\n\t\t\t// no PEX to send this time - try again shortly\n\t\t\ts.sched(pexRetryDelay)\n\t\t}\n\tdefault:\n\t}\n\treturn true\n}\n\nfunc (s *pexConnState) updateRemoteLiveConns(rx pp.PexMsg) (errs []error) {\n\tfor _, dropped := range rx.Dropped {\n\t\taddrPort, _ := ipv4AddrPortFromKrpcNodeAddr(dropped)\n\t\tdelete(s.remoteLiveConns, addrPort)\n\t}\n\tfor _, dropped := range rx.Dropped6 {\n\t\taddrPort, _ := ipv6AddrPortFromKrpcNodeAddr(dropped)\n\t\tdelete(s.remoteLiveConns, addrPort)\n\t}\n\tfor i, added := range rx.Added {\n\t\taddr := netip.AddrFrom4(*(*[4]byte)(added.IP.To4()))\n\t\taddrPort := netip.AddrPortFrom(addr, uint16(added.Port))\n\t\tflags := g.SliceGet(rx.AddedFlags, i)\n\t\tg.MakeMapIfNilAndSet(&s.remoteLiveConns, addrPort, flags)\n\t}\n\tfor i, added := range rx.Added6 {\n\t\taddr := netip.AddrFrom16(*(*[16]byte)(added.IP.To16()))\n\t\taddrPort := netip.AddrPortFrom(addr, uint16(added.Port))\n\t\tflags := g.SliceGet(rx.Added6Flags, i)\n\t\tg.MakeMapIfNilAndSet(&s.remoteLiveConns, addrPort, flags)\n\t}\n\treturn\n}\n\n// Recv is called from the reader goroutine\nfunc (s *pexConnState) Recv(payload []byte) error {\n\trx, err := pp.LoadPexMsg(payload)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unmarshalling pex message: %w\", err)\n\t}\n\ts.logger.Printf(\"received pex message: %v\", rx)\n\ttorrent.Add(\"pex added peers received\", int64(len(rx.Added)))\n\ttorrent.Add(\"pex added6 peers received\", int64(len(rx.Added6)))\n\n\t// \"Clients must batch updates to send no more than 1 PEX message per minute.\"\n\ttimeSinceLastRecv := time.Since(s.lastRecv)\n\tif timeSinceLastRecv < 45*time.Second {\n\t\treturn fmt.Errorf(\"last received only %v ago\", timeSinceLastRecv)\n\t}\n\ts.lastRecv = time.Now()\n\ts.updateRemoteLiveConns(rx)\n\n\tvar peers peerInfos\n\tpeers.AppendFromPex(rx.Added6, rx.Added6Flags)\n\tpeers.AppendFromPex(rx.Added, rx.AddedFlags)\n\tif time.Now().Before(s.torrent.pex.rest) {\n\t\ts.logger.Printf(\"in cooldown period, incoming PEX discarded\")\n\t\treturn nil\n\t}\n\tadded := s.torrent.addPeers(peers)\n\ts.logger.Printf(\"got %v peers over pex, added %v\", len(peers), added)\n\n\tif len(peers) > 0 {\n\t\ts.torrent.pex.rest = time.Now().Add(pexInterval)\n\t}\n\n\t// one day we may also want to:\n\t// - handle drops somehow\n\t// - detect malicious peers\n\n\treturn nil\n}\n\nfunc (s *pexConnState) Close() {\n\tif s.timer != nil {\n\t\ts.timer.Stop()\n\t}\n}\n"
        },
        {
          "name": "pexconn_test.go",
          "type": "blob",
          "size": 1.5126953125,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\t\"github.com/stretchr/testify/require\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc TestPexConnState(t *testing.T) {\n\tvar cl Client\n\tcl.init(TestingConfig(t))\n\tcl.initLogger()\n\ttorrent := cl.newTorrentForTesting()\n\taddr := &net.TCPAddr{IP: net.IPv6loopback, Port: 4747}\n\tc := cl.newConnection(nil, newConnectionOpts{\n\t\tremoteAddr: addr,\n\t\tnetwork:    addr.Network(),\n\t})\n\tc.PeerExtensionIDs = make(map[pp.ExtensionName]pp.ExtensionNumber)\n\tc.PeerExtensionIDs[pp.ExtensionNamePex] = 1\n\tc.messageWriter.mu.Lock()\n\tc.setTorrent(torrent)\n\tif err := torrent.addPeerConn(c); err != nil {\n\t\tt.Log(err)\n\t}\n\n\tconnWriteCond := c.messageWriter.writeCond.Signaled()\n\tc.pex.Init(c)\n\trequire.True(t, c.pex.IsEnabled(), \"should get enabled\")\n\tdefer c.pex.Close()\n\n\tvar out pp.Message\n\twriterCalled := false\n\ttestWriter := func(m pp.Message) bool {\n\t\twriterCalled = true\n\t\tout = m\n\t\treturn true\n\t}\n\t<-connWriteCond\n\tc.pex.Share(testWriter)\n\trequire.True(t, writerCalled)\n\trequire.EqualValues(t, pp.Extended, out.Type)\n\trequire.NotEqualValues(t, out.ExtendedID, 0)\n\trequire.EqualValues(t, c.PeerExtensionIDs[pp.ExtensionNamePex], out.ExtendedID)\n\n\tx, err := pp.LoadPexMsg(out.ExtendedPayload)\n\trequire.NoError(t, err)\n\ttargx := pp.PexMsg{\n\t\tAdded:      krpc.CompactIPv4NodeAddrs(nil),\n\t\tAddedFlags: []pp.PexPeerFlags{},\n\t\tAdded6: krpc.CompactIPv6NodeAddrs{\n\t\t\tkrpcNodeAddrFromNetAddr(addr),\n\t\t},\n\t\tAdded6Flags: []pp.PexPeerFlags{0},\n\t}\n\trequire.EqualValues(t, targx, x)\n}\n"
        },
        {
          "name": "piece.go",
          "type": "blob",
          "size": 8.2861328125,
          "content": "package torrent\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n\n\t\"github.com/anacrolix/chansync\"\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\n\t\"github.com/anacrolix/torrent/merkle\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\ntype Piece struct {\n\t// The completed piece SHA1 hash, from the metainfo \"pieces\" field. Nil if the info is not V1\n\t// compatible.\n\thash   *metainfo.Hash\n\thashV2 g.Option[[32]byte]\n\tt      *Torrent\n\tindex  pieceIndex\n\tfiles  []*File\n\n\treaderCond chansync.BroadcastCond\n\n\tnumVerifies         int64\n\thashing             bool\n\tmarking             bool\n\tstorageCompletionOk bool\n\n\tpublicPieceState PieceState\n\tpriority         PiecePriority\n\t// Availability adjustment for this piece relative to len(Torrent.connsWithAllPieces). This is\n\t// incremented for any piece a peer has when a peer has a piece, Torrent.haveInfo is true, and\n\t// the Peer isn't recorded in Torrent.connsWithAllPieces.\n\trelativeAvailability int\n\n\t// This can be locked when the Client lock is taken, but probably not vice versa.\n\tpendingWritesMutex sync.Mutex\n\tpendingWrites      int\n\tnoPendingWrites    sync.Cond\n\n\t// Connections that have written data to this piece since its last check.\n\t// This can include connections that have closed.\n\tdirtiers map[*Peer]struct{}\n}\n\nfunc (p *Piece) String() string {\n\treturn fmt.Sprintf(\"%s/%d\", p.t.canonicalShortInfohash().HexString(), p.index)\n}\n\nfunc (p *Piece) Info() metainfo.Piece {\n\treturn p.t.info.Piece(p.index)\n}\n\nfunc (p *Piece) Storage() storage.Piece {\n\tvar pieceHash g.Option[[]byte]\n\tif p.hash != nil {\n\t\tpieceHash.Set(p.hash.Bytes())\n\t} else if !p.hasPieceLayer() {\n\t\tpieceHash.Set(p.mustGetOnlyFile().piecesRoot.UnwrapPtr()[:])\n\t} else if p.hashV2.Ok {\n\t\tpieceHash.Set(p.hashV2.Value[:])\n\t}\n\treturn p.t.storage.PieceWithHash(p.Info(), pieceHash)\n}\n\nfunc (p *Piece) Flush() {\n\tif p.t.storage.Flush != nil {\n\t\t_ = p.t.storage.Flush()\n\t}\n}\n\nfunc (p *Piece) pendingChunkIndex(chunkIndex chunkIndexType) bool {\n\treturn !p.chunkIndexDirty(chunkIndex)\n}\n\nfunc (p *Piece) pendingChunk(cs ChunkSpec, chunkSize pp.Integer) bool {\n\treturn p.pendingChunkIndex(chunkIndexFromChunkSpec(cs, chunkSize))\n}\n\nfunc (p *Piece) hasDirtyChunks() bool {\n\treturn p.numDirtyChunks() != 0\n}\n\nfunc (p *Piece) numDirtyChunks() chunkIndexType {\n\treturn chunkIndexType(roaringBitmapRangeCardinality[RequestIndex](\n\t\t&p.t.dirtyChunks,\n\t\tp.requestIndexOffset(),\n\t\tp.t.pieceRequestIndexOffset(p.index+1)))\n}\n\nfunc (p *Piece) unpendChunkIndex(i chunkIndexType) {\n\tp.t.dirtyChunks.Add(p.requestIndexOffset() + i)\n\tp.t.updatePieceRequestOrderPiece(p.index)\n\tp.readerCond.Broadcast()\n}\n\nfunc (p *Piece) pendChunkIndex(i RequestIndex) {\n\tp.t.dirtyChunks.Remove(p.requestIndexOffset() + i)\n\tp.t.updatePieceRequestOrderPiece(p.index)\n}\n\nfunc (p *Piece) numChunks() chunkIndexType {\n\treturn p.t.pieceNumChunks(p.index)\n}\n\nfunc (p *Piece) incrementPendingWrites() {\n\tp.pendingWritesMutex.Lock()\n\tp.pendingWrites++\n\tp.pendingWritesMutex.Unlock()\n}\n\nfunc (p *Piece) decrementPendingWrites() {\n\tp.pendingWritesMutex.Lock()\n\tif p.pendingWrites == 0 {\n\t\tpanic(\"assertion\")\n\t}\n\tp.pendingWrites--\n\tif p.pendingWrites == 0 {\n\t\tp.noPendingWrites.Broadcast()\n\t}\n\tp.pendingWritesMutex.Unlock()\n}\n\nfunc (p *Piece) waitNoPendingWrites() {\n\tp.pendingWritesMutex.Lock()\n\tfor p.pendingWrites != 0 {\n\t\tp.noPendingWrites.Wait()\n\t}\n\tp.pendingWritesMutex.Unlock()\n}\n\nfunc (p *Piece) chunkIndexDirty(chunk chunkIndexType) bool {\n\treturn p.t.dirtyChunks.Contains(p.requestIndexOffset() + chunk)\n}\n\nfunc (p *Piece) chunkIndexSpec(chunk chunkIndexType) ChunkSpec {\n\treturn chunkIndexSpec(pp.Integer(chunk), p.length(), p.chunkSize())\n}\n\nfunc (p *Piece) numDirtyBytes() (ret pp.Integer) {\n\t// defer func() {\n\t// \tif ret > p.length() {\n\t// \t\tpanic(\"too many dirty bytes\")\n\t// \t}\n\t// }()\n\tnumRegularDirtyChunks := p.numDirtyChunks()\n\tif p.chunkIndexDirty(p.numChunks() - 1) {\n\t\tnumRegularDirtyChunks--\n\t\tret += p.chunkIndexSpec(p.lastChunkIndex()).Length\n\t}\n\tret += pp.Integer(numRegularDirtyChunks) * p.chunkSize()\n\treturn\n}\n\nfunc (p *Piece) length() pp.Integer {\n\treturn p.t.pieceLength(p.index)\n}\n\nfunc (p *Piece) chunkSize() pp.Integer {\n\treturn p.t.chunkSize\n}\n\nfunc (p *Piece) lastChunkIndex() chunkIndexType {\n\treturn p.numChunks() - 1\n}\n\nfunc (p *Piece) bytesLeft() (ret pp.Integer) {\n\tif p.t.pieceComplete(p.index) {\n\t\treturn 0\n\t}\n\treturn p.length() - p.numDirtyBytes()\n}\n\n// Forces the piece data to be rehashed.\nfunc (p *Piece) VerifyData() {\n\tp.t.cl.lock()\n\tdefer p.t.cl.unlock()\n\ttarget := p.numVerifies + 1\n\tif p.hashing {\n\t\ttarget++\n\t}\n\t// log.Printf(\"target: %d\", target)\n\tp.t.queuePieceCheck(p.index)\n\tfor {\n\t\t// log.Printf(\"got %d verifies\", p.numVerifies)\n\t\tif p.numVerifies >= target {\n\t\t\tbreak\n\t\t}\n\t\tp.t.cl.event.Wait()\n\t}\n\t// log.Print(\"done\")\n}\n\nfunc (p *Piece) queuedForHash() bool {\n\treturn p.t.piecesQueuedForHash.Get(bitmap.BitIndex(p.index))\n}\n\nfunc (p *Piece) torrentBeginOffset() int64 {\n\treturn int64(p.index) * p.t.info.PieceLength\n}\n\nfunc (p *Piece) torrentEndOffset() int64 {\n\treturn p.torrentBeginOffset() + int64(p.t.usualPieceSize())\n}\n\nfunc (p *Piece) SetPriority(prio PiecePriority) {\n\tp.t.cl.lock()\n\tdefer p.t.cl.unlock()\n\tp.priority = prio\n\tp.t.updatePiecePriority(p.index, \"Piece.SetPriority\")\n}\n\n// This is priority based only on piece, file and reader priorities.\nfunc (p *Piece) purePriority() (ret PiecePriority) {\n\tfor _, f := range p.files {\n\t\tret.Raise(f.prio)\n\t}\n\tif p.t.readerNowPieces().Contains(bitmap.BitIndex(p.index)) {\n\t\tret.Raise(PiecePriorityNow)\n\t}\n\t// if t._readerNowPieces.Contains(piece - 1) {\n\t// \treturn PiecePriorityNext\n\t// }\n\tif p.t.readerReadaheadPieces().Contains(bitmap.BitIndex(p.index)) {\n\t\tret.Raise(PiecePriorityReadahead)\n\t}\n\tret.Raise(p.priority)\n\treturn\n}\n\nfunc (p *Piece) ignoreForRequests() bool {\n\treturn p.hashing || p.marking || !p.haveHash() || p.t.pieceComplete(p.index) || p.queuedForHash()\n}\n\n// This is the priority adjusted for piece state like completion, hashing etc.\nfunc (p *Piece) effectivePriority() (ret PiecePriority) {\n\tif p.ignoreForRequests() {\n\t\treturn PiecePriorityNone\n\t}\n\treturn p.purePriority()\n}\n\n// Tells the Client to refetch the completion status from storage, updating priority etc. if\n// necessary. Might be useful if you know the state of the piece data has changed externally.\nfunc (p *Piece) UpdateCompletion() {\n\tp.t.cl.lock()\n\tdefer p.t.cl.unlock()\n\tp.t.updatePieceCompletion(p.index)\n}\n\nfunc (p *Piece) completion() (ret storage.Completion) {\n\tret.Complete = p.t.pieceComplete(p.index)\n\tret.Ok = p.storageCompletionOk\n\treturn\n}\n\nfunc (p *Piece) allChunksDirty() bool {\n\treturn p.numDirtyChunks() == p.numChunks()\n}\n\nfunc (p *Piece) State() PieceState {\n\treturn p.t.PieceState(p.index)\n}\n\nfunc (p *Piece) requestIndexOffset() RequestIndex {\n\treturn p.t.pieceRequestIndexOffset(p.index)\n}\n\nfunc (p *Piece) availability() int {\n\treturn len(p.t.connsWithAllPieces) + p.relativeAvailability\n}\n\n// For v2 torrents, files are aligned to pieces so there should always only be a single file for a\n// given piece.\nfunc (p *Piece) mustGetOnlyFile() *File {\n\tif len(p.files) != 1 {\n\t\tpanic(len(p.files))\n\t}\n\treturn p.files[0]\n}\n\n// Sets the v2 piece hash, queuing initial piece checks if appropriate.\nfunc (p *Piece) setV2Hash(v2h [32]byte) {\n\t// See Torrent.onSetInfo. We want to trigger an initial check if appropriate, if we didn't yet\n\t// have a piece hash (can occur with v2 when we don't start with piece layers).\n\tp.t.storageLock.Lock()\n\toldV2Hash := p.hashV2.Set(v2h)\n\tp.t.storageLock.Unlock()\n\tif !oldV2Hash.Ok && p.hash == nil {\n\t\tp.t.updatePieceCompletion(p.index)\n\t\tp.t.queueInitialPieceCheck(p.index)\n\t}\n}\n\n// Can't do certain things if we don't know the piece hash.\nfunc (p *Piece) haveHash() bool {\n\tif p.hash != nil {\n\t\treturn true\n\t}\n\tif !p.hasPieceLayer() {\n\t\treturn true\n\t}\n\treturn p.hashV2.Ok\n}\n\nfunc (p *Piece) hasPieceLayer() bool {\n\treturn len(p.files) == 1 && p.files[0].length > p.t.info.PieceLength\n}\n\nfunc (p *Piece) obtainHashV2() (hash [32]byte, err error) {\n\tif p.hashV2.Ok {\n\t\thash = p.hashV2.Value\n\t\treturn\n\t}\n\tif !p.hasPieceLayer() {\n\t\thash = p.mustGetOnlyFile().piecesRoot.Unwrap()\n\t\treturn\n\t}\n\tstorage := p.Storage()\n\tif !storage.Completion().Complete {\n\t\terr = errors.New(\"piece incomplete\")\n\t\treturn\n\t}\n\n\th := merkle.NewHash()\n\tif _, err = storage.WriteTo(h); err != nil {\n\t\treturn\n\t}\n\th.SumMinLength(hash[:0], int(p.t.info.PieceLength))\n\treturn\n}\n"
        },
        {
          "name": "piecestate.go",
          "type": "blob",
          "size": 0.6728515625,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\n// The current state of a piece.\ntype PieceState struct {\n\tPriority PiecePriority\n\tstorage.Completion\n\t// The piece is being hashed, or is queued for hash. Deprecated: Use those fields instead.\n\tChecking bool\n\n\tHashing       bool\n\tQueuedForHash bool\n\t// The piece state is being marked in the storage.\n\tMarking bool\n\n\t// Some of the piece has been obtained.\n\tPartial bool\n\n\t// The v2 hash for the piece layer is missing.\n\tMissingPieceLayerHash bool\n}\n\n// Represents a series of consecutive pieces with the same state.\ntype PieceStateRun struct {\n\tPieceState\n\tLength int // How many consecutive pieces have this state.\n}\n"
        },
        {
          "name": "portfwd.go",
          "type": "blob",
          "size": 2.103515625,
          "content": "package torrent\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/upnp\"\n)\n\nconst UpnpDiscoverLogTag = \"upnp-discover\"\n\ntype upnpMapping struct {\n\td            upnp.Device\n\tproto        upnp.Protocol\n\texternalPort int\n}\n\nfunc (cl *Client) addPortMapping(d upnp.Device, proto upnp.Protocol, internalPort int, upnpID string) {\n\tlogger := cl.logger.WithContextText(fmt.Sprintf(\"UPnP device at %v: mapping internal %v port %v\", d.GetLocalIPAddress(), proto, internalPort))\n\texternalPort, err := d.AddPortMapping(proto, internalPort, internalPort, upnpID, 0)\n\tif err != nil {\n\t\tlogger.WithDefaultLevel(log.Warning).Printf(\"error: %v\", err)\n\t\treturn\n\t}\n\tcl.lock()\n\tcl.upnpMappings = append(cl.upnpMappings, &upnpMapping{d, proto, externalPort})\n\tcl.unlock()\n\tlevel := log.Info\n\tif externalPort != internalPort {\n\t\tlevel = log.Warning\n\t}\n\tlogger.WithDefaultLevel(level).Printf(\"success: external port %v\", externalPort)\n}\n\nfunc (cl *Client) forwardPort() {\n\tcl.lock()\n\tdefer cl.unlock()\n\tif cl.config.NoDefaultPortForwarding {\n\t\treturn\n\t}\n\tcl.unlock()\n\tds := upnp.Discover(0, 2*time.Second, cl.logger.WithValues(UpnpDiscoverLogTag))\n\tcl.lock()\n\tcl.logger.WithDefaultLevel(log.Debug).Printf(\"discovered %d upnp devices\", len(ds))\n\tport := cl.incomingPeerPort()\n\tid := cl.config.UpnpID\n\tcl.unlock()\n\tfor _, d := range ds {\n\t\tgo cl.addPortMapping(d, upnp.TCP, port, id)\n\t\tgo cl.addPortMapping(d, upnp.UDP, port, id)\n\t}\n\tcl.lock()\n}\n\nfunc (cl *Client) deletePortMapping(d upnp.Device, proto upnp.Protocol, externalPort int) {\n\tlogger := cl.logger.WithContextText(fmt.Sprintf(\"UPnP device at %v: delete mapping internal %v port %v\", d.GetLocalIPAddress(), proto, externalPort))\n\terr := d.DeletePortMapping(proto, externalPort)\n\tif err != nil {\n\t\tlogger.WithDefaultLevel(log.Warning).Printf(\"error: %v\", err)\n\t\treturn\n\t}\n}\n\nfunc (cl *Client) clearPortMappings() {\n\tmLen := len(cl.upnpMappings)\n\tif mLen == 0 {\n\t\treturn\n\t}\n\n\tvar wg sync.WaitGroup\n\twg.Add(mLen)\n\tfor _, m := range cl.upnpMappings {\n\t\tgo func(m *upnpMapping) {\n\t\t\tdefer wg.Done()\n\t\t\tcl.deletePortMapping(m.d, m.proto, m.externalPort)\n\t\t}(m)\n\t}\n\tcl.upnpMappings = nil\n}\n"
        },
        {
          "name": "prioritized-peers.go",
          "type": "blob",
          "size": 1.806640625,
          "content": "package torrent\n\nimport (\n\t\"hash/maphash\"\n\n\t\"github.com/anacrolix/multiless\"\n\t\"github.com/google/btree\"\n)\n\n// Peers are stored with their priority at insertion. Their priority may\n// change if our apparent IP changes, we don't currently handle that.\ntype prioritizedPeersItem struct {\n\tprio peerPriority\n\tp    PeerInfo\n}\n\nvar hashSeed = maphash.MakeSeed()\n\nfunc (me prioritizedPeersItem) addrHash() int64 {\n\tvar h maphash.Hash\n\th.SetSeed(hashSeed)\n\th.WriteString(me.p.Addr.String())\n\treturn int64(h.Sum64())\n}\n\nfunc (me prioritizedPeersItem) Less(than btree.Item) bool {\n\tother := than.(prioritizedPeersItem)\n\treturn multiless.New().Bool(\n\t\tme.p.Trusted, other.p.Trusted).Uint32(\n\t\tme.prio, other.prio).Int64(\n\t\tme.addrHash(), other.addrHash(),\n\t).Less()\n}\n\ntype prioritizedPeers struct {\n\tom      *btree.BTree\n\tgetPrio func(PeerInfo) peerPriority\n}\n\nfunc (me *prioritizedPeers) Each(f func(PeerInfo)) {\n\tme.om.Ascend(func(i btree.Item) bool {\n\t\tf(i.(prioritizedPeersItem).p)\n\t\treturn true\n\t})\n}\n\nfunc (me *prioritizedPeers) Len() int {\n\tif me == nil || me.om == nil {\n\t\treturn 0\n\t}\n\treturn me.om.Len()\n}\n\n// Returns true if a peer is replaced.\nfunc (me *prioritizedPeers) Add(p PeerInfo) bool {\n\treturn me.om.ReplaceOrInsert(prioritizedPeersItem{me.getPrio(p), p}) != nil\n}\n\n// Returns true if a peer is replaced.\nfunc (me *prioritizedPeers) AddReturningReplacedPeer(p PeerInfo) (ret PeerInfo, ok bool) {\n\titem := me.om.ReplaceOrInsert(prioritizedPeersItem{me.getPrio(p), p})\n\tif item == nil {\n\t\treturn\n\t}\n\tret = item.(prioritizedPeersItem).p\n\tok = true\n\treturn\n}\n\nfunc (me *prioritizedPeers) DeleteMin() (ret prioritizedPeersItem, ok bool) {\n\ti := me.om.DeleteMin()\n\tif i == nil {\n\t\treturn\n\t}\n\tret = i.(prioritizedPeersItem)\n\tok = true\n\treturn\n}\n\nfunc (me *prioritizedPeers) PopMax() PeerInfo {\n\treturn me.om.DeleteMax().(prioritizedPeersItem).p\n}\n"
        },
        {
          "name": "prioritized-peers_test.go",
          "type": "blob",
          "size": 1.224609375,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"testing\"\n\n\t\"github.com/google/btree\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestPrioritizedPeers(t *testing.T) {\n\tpp := prioritizedPeers{\n\t\tom: btree.New(3),\n\t\tgetPrio: func(p PeerInfo) peerPriority {\n\t\t\treturn bep40PriorityIgnoreError(p.addr(), IpPort{IP: net.ParseIP(\"0.0.0.0\")})\n\t\t},\n\t}\n\t_, ok := pp.DeleteMin()\n\tassert.Panics(t, func() { pp.PopMax() })\n\tassert.False(t, ok)\n\tps := []PeerInfo{\n\t\t{Addr: ipPortAddr{IP: net.ParseIP(\"1.2.3.4\")}},\n\t\t{Addr: ipPortAddr{IP: net.ParseIP(\"1::2\")}},\n\t\t{Addr: ipPortAddr{IP: net.ParseIP(\"\")}},\n\t\t{Addr: ipPortAddr{IP: net.ParseIP(\"\")}, Trusted: true},\n\t}\n\tfor i, p := range ps {\n\t\tt.Logf(\"peer %d priority: %08x trusted: %t\\n\", i, pp.getPrio(p), p.Trusted)\n\t\tassert.False(t, pp.Add(p))\n\t\tassert.True(t, pp.Add(p))\n\t\tassert.Equal(t, i+1, pp.Len())\n\t}\n\tpop := func(expected *PeerInfo) {\n\t\tif expected == nil {\n\t\t\tassert.Panics(t, func() { pp.PopMax() })\n\t\t} else {\n\t\t\tassert.Equal(t, *expected, pp.PopMax())\n\t\t}\n\t}\n\tmin := func(expected *PeerInfo) {\n\t\ti, ok := pp.DeleteMin()\n\t\tif expected == nil {\n\t\t\tassert.False(t, ok)\n\t\t} else {\n\t\t\tassert.True(t, ok)\n\t\t\tassert.Equal(t, *expected, i.p)\n\t\t}\n\t}\n\tpop(&ps[3])\n\tpop(&ps[1])\n\tmin(&ps[2])\n\tpop(&ps[0])\n\tmin(nil)\n\tpop(nil)\n}\n"
        },
        {
          "name": "protocol.go",
          "type": "blob",
          "size": 0.1796875,
          "content": "package torrent\n\nimport (\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc makeCancelMessage(r Request) pp.Message {\n\treturn pp.MakeCancelMessage(r.Index, r.Begin, r.Length)\n}\n"
        },
        {
          "name": "ratelimitreader.go",
          "type": "blob",
          "size": 1.0537109375,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\ntype rateLimitedReader struct {\n\tl *rate.Limiter\n\tr io.Reader\n\n\t// This is the time of the last Read's reservation.\n\tlastRead time.Time\n}\n\nfunc (me *rateLimitedReader) Read(b []byte) (n int, err error) {\n\tconst oldStyle = false // Retained for future reference.\n\tif oldStyle {\n\t\t// Wait until we can read at all.\n\t\tif err := me.l.WaitN(context.Background(), 1); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\t// Limit the read to within the burst.\n\t\tif me.l.Limit() != rate.Inf && len(b) > me.l.Burst() {\n\t\t\tb = b[:me.l.Burst()]\n\t\t}\n\t\tn, err = me.r.Read(b)\n\t\t// Pay the piper.\n\t\tnow := time.Now()\n\t\tme.lastRead = now\n\t\tif !me.l.ReserveN(now, n-1).OK() {\n\t\t\tpanic(fmt.Sprintf(\"burst exceeded?: %d\", n-1))\n\t\t}\n\t} else {\n\t\t// Limit the read to within the burst.\n\t\tif me.l.Limit() != rate.Inf && len(b) > me.l.Burst() {\n\t\t\tb = b[:me.l.Burst()]\n\t\t}\n\t\tn, err = me.r.Read(b)\n\t\tnow := time.Now()\n\t\tr := me.l.ReserveN(now, n)\n\t\tif !r.OK() {\n\t\t\tpanic(n)\n\t\t}\n\t\tme.lastRead = now\n\t\ttime.Sleep(r.Delay())\n\t}\n\treturn\n}\n"
        },
        {
          "name": "reader.go",
          "type": "blob",
          "size": 8.451171875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"sync\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n)\n\n// Accesses Torrent data via a Client. Reads block until the data is available. Seeks and readahead\n// also drive Client behaviour. Not safe for concurrent use.\ntype Reader interface {\n\tio.ReadSeekCloser\n\tmissinggo.ReadContexter\n\t// Configure the number of bytes ahead of a read that should also be prioritized in preparation\n\t// for further reads. Overridden by non-nil readahead func, see SetReadaheadFunc.\n\tSetReadahead(int64)\n\t// If non-nil, the provided function is called when the implementation needs to know the\n\t// readahead for the current reader. Calls occur during Reads and Seeks, and while the Client is\n\t// locked.\n\tSetReadaheadFunc(ReadaheadFunc)\n\t// Don't wait for pieces to complete and be verified. Read calls return as soon as they can when\n\t// the underlying chunks become available.\n\tSetResponsive()\n}\n\n// Piece range by piece index, [begin, end).\ntype pieceRange struct {\n\tbegin, end pieceIndex\n}\n\ntype ReadaheadContext struct {\n\tContiguousReadStartPos int64\n\tCurrentPos             int64\n}\n\n// Returns the desired readahead for a Reader.\ntype ReadaheadFunc func(ReadaheadContext) int64\n\ntype reader struct {\n\tt *Torrent\n\t// Adjust the read/seek window to handle Readers locked to File extents and the like.\n\toffset, length int64\n\n\t// Function to dynamically calculate readahead. If nil, readahead is static.\n\treadaheadFunc ReadaheadFunc\n\n\t// Required when modifying pos and readahead.\n\tmu sync.Locker\n\n\treadahead, pos int64\n\t// Position that reads have continued contiguously from.\n\tcontiguousReadStartPos int64\n\t// The cached piece range this reader wants downloaded. The zero value corresponds to nothing.\n\t// We cache this so that changes can be detected, and bubbled up to the Torrent only as\n\t// required.\n\tpieces pieceRange\n\n\t// Reads have been initiated since the last seek. This is used to prevent readaheads occurring\n\t// after a seek or with a new reader at the starting position.\n\treading    bool\n\tresponsive bool\n}\n\nvar _ io.ReadSeekCloser = (*reader)(nil)\n\nfunc (r *reader) SetResponsive() {\n\tr.responsive = true\n\tr.t.cl.event.Broadcast()\n}\n\n// Disable responsive mode. TODO: Remove?\nfunc (r *reader) SetNonResponsive() {\n\tr.responsive = false\n\tr.t.cl.event.Broadcast()\n}\n\nfunc (r *reader) SetReadahead(readahead int64) {\n\tr.mu.Lock()\n\tr.readahead = readahead\n\tr.readaheadFunc = nil\n\tr.posChanged()\n\tr.mu.Unlock()\n}\n\nfunc (r *reader) SetReadaheadFunc(f ReadaheadFunc) {\n\tr.mu.Lock()\n\tr.readaheadFunc = f\n\tr.posChanged()\n\tr.mu.Unlock()\n}\n\n// How many bytes are available to read. Max is the most we could require.\nfunc (r *reader) available(off, max int64) (ret int64) {\n\toff += r.offset\n\tfor max > 0 {\n\t\treq, ok := r.t.offsetRequest(off)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tif !r.responsive && !r.t.pieceComplete(pieceIndex(req.Index)) {\n\t\t\tbreak\n\t\t}\n\t\tif !r.t.haveChunk(req) {\n\t\t\tbreak\n\t\t}\n\t\tlen1 := int64(req.Length) - (off - r.t.requestOffset(req))\n\t\tmax -= len1\n\t\tret += len1\n\t\toff += len1\n\t}\n\t// Ensure that ret hasn't exceeded our original max.\n\tif max < 0 {\n\t\tret += max\n\t}\n\treturn\n}\n\n// Calculates the pieces this reader wants downloaded, ignoring the cached value at r.pieces.\nfunc (r *reader) piecesUncached() (ret pieceRange) {\n\tra := r.readahead\n\tif r.readaheadFunc != nil {\n\t\tra = r.readaheadFunc(ReadaheadContext{\n\t\t\tContiguousReadStartPos: r.contiguousReadStartPos,\n\t\t\tCurrentPos:             r.pos,\n\t\t})\n\t}\n\tif ra < 1 {\n\t\t// Needs to be at least 1, because [x, x) means we don't want\n\t\t// anything.\n\t\tra = 1\n\t}\n\tif !r.reading {\n\t\tra = 0\n\t}\n\tif ra > r.length-r.pos {\n\t\tra = r.length - r.pos\n\t}\n\tret.begin, ret.end = r.t.byteRegionPieces(r.torrentOffset(r.pos), ra)\n\treturn\n}\n\nfunc (r *reader) Read(b []byte) (n int, err error) {\n\treturn r.ReadContext(context.Background(), b)\n}\n\nfunc (r *reader) ReadContext(ctx context.Context, b []byte) (n int, err error) {\n\tif len(b) > 0 {\n\t\tr.reading = true\n\t\t// TODO: Rework reader piece priorities so we don't have to push updates in to the Client\n\t\t// and take the lock here.\n\t\tr.mu.Lock()\n\t\tr.posChanged()\n\t\tr.mu.Unlock()\n\t}\n\tn, err = r.readOnceAt(ctx, b, r.pos)\n\tif n == 0 {\n\t\tif err == nil && len(b) > 0 {\n\t\t\tpanic(\"expected error\")\n\t\t} else {\n\t\t\treturn\n\t\t}\n\t}\n\n\tr.mu.Lock()\n\tr.pos += int64(n)\n\tr.posChanged()\n\tr.mu.Unlock()\n\tif r.pos >= r.length {\n\t\terr = io.EOF\n\t} else if err == io.EOF {\n\t\terr = io.ErrUnexpectedEOF\n\t}\n\treturn\n}\n\nvar closedChan = make(chan struct{})\n\nfunc init() {\n\tclose(closedChan)\n}\n\n// Wait until some data should be available to read. Tickles the client if it isn't. Returns how\n// much should be readable without blocking.\nfunc (r *reader) waitAvailable(ctx context.Context, pos, wanted int64, wait bool) (avail int64, err error) {\n\tt := r.t\n\tfor {\n\t\tr.t.cl.rLock()\n\t\tavail = r.available(pos, wanted)\n\t\treaderCond := t.piece(int((r.offset + pos) / t.info.PieceLength)).readerCond.Signaled()\n\t\tr.t.cl.rUnlock()\n\t\tif avail != 0 {\n\t\t\treturn\n\t\t}\n\t\tvar dontWait <-chan struct{}\n\t\tif !wait || wanted == 0 {\n\t\t\tdontWait = closedChan\n\t\t}\n\t\tselect {\n\t\tcase <-r.t.closed.Done():\n\t\t\terr = errors.New(\"torrent closed\")\n\t\t\treturn\n\t\tcase <-ctx.Done():\n\t\t\terr = ctx.Err()\n\t\t\treturn\n\t\tcase <-r.t.dataDownloadDisallowed.On():\n\t\t\terr = errors.New(\"torrent data downloading disabled\")\n\t\tcase <-r.t.networkingEnabled.Off():\n\t\t\terr = errors.New(\"torrent networking disabled\")\n\t\t\treturn\n\t\tcase <-dontWait:\n\t\t\treturn\n\t\tcase <-readerCond:\n\t\t}\n\t}\n}\n\n// Adds the reader's torrent offset to the reader object offset (for example the reader might be\n// constrainted to a particular file within the torrent).\nfunc (r *reader) torrentOffset(readerPos int64) int64 {\n\treturn r.offset + readerPos\n}\n\n// Performs at most one successful read to torrent storage.\nfunc (r *reader) readOnceAt(ctx context.Context, b []byte, pos int64) (n int, err error) {\n\tif pos >= r.length {\n\t\terr = io.EOF\n\t\treturn\n\t}\n\tfor {\n\t\tvar avail int64\n\t\tavail, err = r.waitAvailable(ctx, pos, int64(len(b)), n == 0)\n\t\tif avail == 0 {\n\t\t\treturn\n\t\t}\n\t\tfirstPieceIndex := pieceIndex(r.torrentOffset(pos) / r.t.info.PieceLength)\n\t\tfirstPieceOffset := r.torrentOffset(pos) % r.t.info.PieceLength\n\t\tb1 := missinggo.LimitLen(b, avail)\n\t\tn, err = r.t.readAt(b1, r.torrentOffset(pos))\n\t\tif n != 0 {\n\t\t\terr = nil\n\t\t\treturn\n\t\t}\n\t\tif r.t.closed.IsSet() {\n\t\t\terr = fmt.Errorf(\"reading from closed torrent: %w\", err)\n\t\t\treturn\n\t\t}\n\t\tr.t.cl.lock()\n\t\t// I think there's a panic here caused by the Client being closed before obtaining this\n\t\t// lock. TestDropTorrentWithMmapStorageWhileHashing seems to tickle occasionally in CI.\n\t\tfunc() {\n\t\t\t// Just add exceptions already.\n\t\t\tdefer r.t.cl.unlock()\n\t\t\tif r.t.closed.IsSet() {\n\t\t\t\t// Can't update because Torrent's piece order is removed from Client.\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// TODO: Just reset pieces in the readahead window. This might help\n\t\t\t// prevent thrashing with small caches and file and piece priorities.\n\t\t\tr.log(log.Fstr(\"error reading piece %d offset %d, %d bytes: %v\",\n\t\t\t\tfirstPieceIndex, firstPieceOffset, len(b1), err))\n\t\t\tif !r.t.updatePieceCompletion(firstPieceIndex) {\n\t\t\t\tr.log(log.Fstr(\"piece %d completion unchanged\", firstPieceIndex))\n\t\t\t}\n\t\t\t// Update the rest of the piece completions in the readahead window, without alerting to\n\t\t\t// changes (since only the first piece, the one above, could have generated the read error\n\t\t\t// we're currently handling).\n\t\t\tif r.pieces.begin != firstPieceIndex {\n\t\t\t\tpanic(fmt.Sprint(r.pieces.begin, firstPieceIndex))\n\t\t\t}\n\t\t\tfor index := r.pieces.begin + 1; index < r.pieces.end; index++ {\n\t\t\t\tr.t.updatePieceCompletion(index)\n\t\t\t}\n\t\t}()\n\t}\n}\n\n// Hodor\nfunc (r *reader) Close() error {\n\tr.t.cl.lock()\n\tr.t.deleteReader(r)\n\tr.t.cl.unlock()\n\treturn nil\n}\n\nfunc (r *reader) posChanged() {\n\tto := r.piecesUncached()\n\tfrom := r.pieces\n\tif to == from {\n\t\treturn\n\t}\n\tr.pieces = to\n\t// log.Printf(\"reader pos changed %v->%v\", from, to)\n\tr.t.readerPosChanged(from, to)\n}\n\nfunc (r *reader) Seek(off int64, whence int) (newPos int64, err error) {\n\tswitch whence {\n\tcase io.SeekStart:\n\t\tnewPos = off\n\t\tr.mu.Lock()\n\tcase io.SeekCurrent:\n\t\tr.mu.Lock()\n\t\tnewPos = r.pos + off\n\tcase io.SeekEnd:\n\t\tnewPos = r.length + off\n\t\tr.mu.Lock()\n\tdefault:\n\t\treturn 0, errors.New(\"bad whence\")\n\t}\n\tif newPos != r.pos {\n\t\tr.reading = false\n\t\tr.pos = newPos\n\t\tr.contiguousReadStartPos = newPos\n\t\tr.posChanged()\n\t}\n\tr.mu.Unlock()\n\treturn\n}\n\nfunc (r *reader) log(m log.Msg) {\n\tr.t.logger.LogLevel(log.Debug, m.Skip(1))\n}\n\n// Implementation inspired by https://news.ycombinator.com/item?id=27019613.\nfunc defaultReadaheadFunc(r ReadaheadContext) int64 {\n\treturn r.CurrentPos - r.ContiguousReadStartPos\n}\n"
        },
        {
          "name": "reader_test.go",
          "type": "blob",
          "size": 0.619140625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n)\n\nfunc TestReaderReadContext(t *testing.T) {\n\tcl, err := NewClient(TestingConfig(t))\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\ttt, err := cl.AddTorrent(testutil.GreetingMetaInfo())\n\trequire.NoError(t, err)\n\tdefer tt.Drop()\n\tctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Millisecond))\n\tdefer cancel()\n\tr := tt.Files()[0].NewReader()\n\tdefer r.Close()\n\t_, err = r.ReadContext(ctx, make([]byte, 1))\n\trequire.EqualValues(t, context.DeadlineExceeded, err)\n}\n"
        },
        {
          "name": "request-strategy-impls.go",
          "type": "blob",
          "size": 2.6796875,
          "content": "package torrent\n\nimport (\n\tg \"github.com/anacrolix/generics\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\ntype requestStrategyInputCommon struct {\n\tmaxUnverifiedBytes int64\n}\n\nfunc (r requestStrategyInputCommon) MaxUnverifiedBytes() int64 {\n\treturn r.maxUnverifiedBytes\n}\n\ntype requestStrategyInputMultiTorrent struct {\n\trequestStrategyInputCommon\n\ttorrents map[metainfo.Hash]*Torrent\n\tcapFunc  storage.TorrentCapacity\n}\n\nfunc (r requestStrategyInputMultiTorrent) Torrent(ih metainfo.Hash) request_strategy.Torrent {\n\treturn requestStrategyTorrent{g.MapMustGet(r.torrents, ih)}\n}\n\nfunc (r requestStrategyInputMultiTorrent) Capacity() (int64, bool) {\n\treturn (*r.capFunc)()\n}\n\ntype requestStrategyInputSingleTorrent struct {\n\trequestStrategyInputCommon\n\tt *Torrent\n}\n\nfunc (r requestStrategyInputSingleTorrent) Torrent(_ metainfo.Hash) request_strategy.Torrent {\n\treturn requestStrategyTorrent{r.t}\n}\n\nfunc (r requestStrategyInputSingleTorrent) Capacity() (cap int64, capped bool) {\n\treturn 0, false\n}\n\nvar _ request_strategy.Input = requestStrategyInputSingleTorrent{}\n\nfunc (cl *Client) getRequestStrategyInputCommon() requestStrategyInputCommon {\n\treturn requestStrategyInputCommon{cl.config.MaxUnverifiedBytes}\n}\n\n// Returns what is necessary to run request_strategy.GetRequestablePieces for primaryTorrent.\nfunc (cl *Client) getRequestStrategyInput(primaryTorrent *Torrent) (input request_strategy.Input) {\n\tif !primaryTorrent.hasStorageCap() {\n\t\treturn requestStrategyInputSingleTorrent{\n\t\t\trequestStrategyInputCommon: cl.getRequestStrategyInputCommon(),\n\t\t\tt:                          primaryTorrent,\n\t\t}\n\t} else {\n\t\treturn requestStrategyInputMultiTorrent{\n\t\t\trequestStrategyInputCommon: cl.getRequestStrategyInputCommon(),\n\t\t\t// TODO: Check this is an appropriate key\n\t\t\ttorrents: cl.torrentsByShortHash,\n\t\t\tcapFunc:  primaryTorrent.storage.Capacity,\n\t\t}\n\t}\n}\n\nfunc (t *Torrent) getRequestStrategyInput() request_strategy.Input {\n\treturn t.cl.getRequestStrategyInput(t)\n}\n\ntype requestStrategyTorrent struct {\n\tt *Torrent\n}\n\nfunc (r requestStrategyTorrent) Piece(i int) request_strategy.Piece {\n\treturn requestStrategyPiece{r.t.piece(i)}\n}\n\nfunc (r requestStrategyTorrent) PieceLength() int64 {\n\treturn r.t.info.PieceLength\n}\n\nvar _ request_strategy.Torrent = requestStrategyTorrent{}\n\ntype requestStrategyPiece struct {\n\tp *Piece\n}\n\nfunc (r requestStrategyPiece) CountUnverified() bool {\n\treturn r.p.hashing || r.p.marking || r.p.queuedForHash()\n}\n\nfunc (r requestStrategyPiece) Request() bool {\n\treturn !r.p.ignoreForRequests() && r.p.purePriority() != PiecePriorityNone\n}\n\nvar _ request_strategy.Piece = requestStrategyPiece{}\n"
        },
        {
          "name": "request-strategy-impls_test.go",
          "type": "blob",
          "size": 3.6728515625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"runtime\"\n\t\"testing\"\n\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/missinggo/v2/iter\"\n\t\"github.com/davecgh/go-spew/spew\"\n\tqt \"github.com/frankban/quicktest\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n\t\"github.com/anacrolix/torrent/storage\"\n\tinfohash_v2 \"github.com/anacrolix/torrent/types/infohash-v2\"\n)\n\nfunc makeRequestStrategyPiece(t request_strategy.Torrent) request_strategy.Piece {\n\treturn t.Piece(0)\n}\n\nfunc TestRequestStrategyPieceDoesntAlloc(t *testing.T) {\n\tc := qt.New(t)\n\takshalTorrent := &Torrent{pieces: make([]Piece, 1)}\n\trst := requestStrategyTorrent{akshalTorrent}\n\tvar before, after runtime.MemStats\n\truntime.ReadMemStats(&before)\n\tp := makeRequestStrategyPiece(rst)\n\truntime.ReadMemStats(&after)\n\tc.Assert(before.HeapAlloc, qt.Equals, after.HeapAlloc)\n\t// We have to use p, or it gets optimized away.\n\tspew.Fdump(io.Discard, p)\n}\n\ntype storagePiece struct {\n\tcomplete bool\n}\n\nfunc (s storagePiece) ReadAt(p []byte, off int64) (n int, err error) {\n\t//TODO implement me\n\tpanic(\"implement me\")\n}\n\nfunc (s storagePiece) WriteAt(p []byte, off int64) (n int, err error) {\n\t//TODO implement me\n\tpanic(\"implement me\")\n}\n\nfunc (s storagePiece) MarkComplete() error {\n\t//TODO implement me\n\tpanic(\"implement me\")\n}\n\nfunc (s storagePiece) MarkNotComplete() error {\n\t//TODO implement me\n\tpanic(\"implement me\")\n}\n\nfunc (s storagePiece) Completion() storage.Completion {\n\treturn storage.Completion{Ok: true, Complete: s.complete}\n}\n\nvar _ storage.PieceImpl = storagePiece{}\n\ntype storageClient struct {\n\tcompleted int\n}\n\nfunc (s *storageClient) OpenTorrent(\n\t_ context.Context,\n\tinfo *metainfo.Info,\n\tinfoHash metainfo.Hash,\n) (storage.TorrentImpl, error) {\n\treturn storage.TorrentImpl{\n\t\tPiece: func(p metainfo.Piece) storage.PieceImpl {\n\t\t\treturn storagePiece{complete: p.Index() < s.completed}\n\t\t},\n\t}, nil\n}\n\nfunc BenchmarkRequestStrategy(b *testing.B) {\n\tc := qt.New(b)\n\tcl := newTestingClient(b)\n\tstorageClient := storageClient{}\n\ttor, new := cl.AddTorrentOpt(AddTorrentOpts{\n\t\tInfoHashV2: g.Some(infohash_v2.FromHexString(\"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef\")),\n\t\tStorage:    &storageClient,\n\t})\n\ttor.disableTriggers = true\n\tc.Assert(new, qt.IsTrue)\n\tconst pieceLength = 1 << 8 << 10\n\tconst numPieces = 30_000\n\terr := tor.setInfo(&metainfo.Info{\n\t\tPieces:      make([]byte, numPieces*metainfo.HashSize),\n\t\tPieceLength: pieceLength,\n\t\tLength:      pieceLength * numPieces,\n\t})\n\tc.Assert(err, qt.IsNil)\n\ttor.onSetInfo()\n\tpeer := cl.newConnection(nil, newConnectionOpts{\n\t\tnetwork: \"test\",\n\t})\n\tpeer.setTorrent(tor)\n\tc.Assert(tor.storage, qt.IsNotNil)\n\tconst chunkSize = defaultChunkSize\n\tpeer.onPeerHasAllPiecesNoTriggers()\n\tfor i := 0; i < tor.numPieces(); i++ {\n\t\ttor.pieces[i].priority.Raise(PiecePriorityNormal)\n\t\ttor.updatePiecePriorityNoTriggers(i)\n\t}\n\tpeer.peerChoking = false\n\t//b.StopTimer()\n\tb.ResetTimer()\n\t//b.ReportAllocs()\n\tfor _ = range iter.N(b.N) {\n\t\tstorageClient.completed = 0\n\t\tfor pieceIndex := range iter.N(numPieces) {\n\t\t\ttor.updatePieceCompletion(pieceIndex)\n\t\t}\n\t\tfor completed := 0; completed <= numPieces; completed += 1 {\n\t\t\tstorageClient.completed = completed\n\t\t\tif completed > 0 {\n\t\t\t\ttor.updatePieceCompletion(completed - 1)\n\t\t\t}\n\t\t\t// Starting and stopping timers around this part causes lots of GC overhead.\n\t\t\trs := peer.getDesiredRequestState()\n\t\t\ttor.cacheNextRequestIndexesForReuse(rs.Requests.requestIndexes)\n\t\t\t// End of part that should be timed.\n\t\t\tremainingChunks := (numPieces - completed) * (pieceLength / chunkSize)\n\t\t\tc.Assert(rs.Requests.requestIndexes, qt.HasLen, minInt(\n\t\t\t\tremainingChunks,\n\t\t\t\tint(cl.config.MaxUnverifiedBytes/chunkSize)))\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "request-strategy",
          "type": "tree",
          "content": null
        },
        {
          "name": "requesting.go",
          "type": "blob",
          "size": 11.7490234375,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"encoding/gob\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"runtime/pprof\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/generics/heap\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/multiless\"\n\n\trequestStrategy \"github.com/anacrolix/torrent/request-strategy\"\n\ttypedRoaring \"github.com/anacrolix/torrent/typed-roaring\"\n)\n\ntype (\n\t// Since we have to store all the requests in memory, we can't reasonably exceed what could be\n\t// indexed with the memory space available.\n\tmaxRequests = int\n)\n\nfunc (t *Torrent) requestStrategyPieceOrderState(i int) requestStrategy.PieceRequestOrderState {\n\treturn requestStrategy.PieceRequestOrderState{\n\t\tPriority:     t.piece(i).purePriority(),\n\t\tPartial:      t.piecePartiallyDownloaded(i),\n\t\tAvailability: t.piece(i).availability(),\n\t}\n}\n\nfunc init() {\n\tgob.Register(peerId{})\n}\n\ntype peerId struct {\n\t*Peer\n\tptr uintptr\n}\n\nfunc (p peerId) Uintptr() uintptr {\n\treturn p.ptr\n}\n\nfunc (p peerId) GobEncode() (b []byte, _ error) {\n\t*(*reflect.SliceHeader)(unsafe.Pointer(&b)) = reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(&p.ptr)),\n\t\tLen:  int(unsafe.Sizeof(p.ptr)),\n\t\tCap:  int(unsafe.Sizeof(p.ptr)),\n\t}\n\treturn\n}\n\nfunc (p *peerId) GobDecode(b []byte) error {\n\tif uintptr(len(b)) != unsafe.Sizeof(p.ptr) {\n\t\tpanic(len(b))\n\t}\n\tptr := unsafe.Pointer(&b[0])\n\tp.ptr = *(*uintptr)(ptr)\n\tlog.Printf(\"%p\", ptr)\n\tdst := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(&p.Peer)),\n\t\tLen:  int(unsafe.Sizeof(p.Peer)),\n\t\tCap:  int(unsafe.Sizeof(p.Peer)),\n\t}\n\tcopy(*(*[]byte)(unsafe.Pointer(&dst)), b)\n\treturn nil\n}\n\ntype (\n\tRequestIndex   = requestStrategy.RequestIndex\n\tchunkIndexType = requestStrategy.ChunkIndex\n)\n\ntype desiredPeerRequests struct {\n\trequestIndexes []RequestIndex\n\tpeer           *Peer\n\tpieceStates    []g.Option[requestStrategy.PieceRequestOrderState]\n}\n\nfunc (p *desiredPeerRequests) lessByValue(leftRequest, rightRequest RequestIndex) bool {\n\tt := p.peer.t\n\tleftPieceIndex := t.pieceIndexOfRequestIndex(leftRequest)\n\trightPieceIndex := t.pieceIndexOfRequestIndex(rightRequest)\n\tml := multiless.New()\n\t// Push requests that can't be served right now to the end. But we don't throw them away unless\n\t// there's a better alternative. This is for when we're using the fast extension and get choked\n\t// but our requests could still be good when we get unchoked.\n\tif p.peer.peerChoking {\n\t\tml = ml.Bool(\n\t\t\t!p.peer.peerAllowedFast.Contains(leftPieceIndex),\n\t\t\t!p.peer.peerAllowedFast.Contains(rightPieceIndex),\n\t\t)\n\t}\n\tleftPiece := p.pieceStates[leftPieceIndex].UnwrapPtr()\n\trightPiece := p.pieceStates[rightPieceIndex].UnwrapPtr()\n\t// Putting this first means we can steal requests from lesser-performing peers for our first few\n\t// new requests.\n\tpriority := func() PiecePriority {\n\t\t// Technically we would be happy with the cached priority here, except we don't actually\n\t\t// cache it anymore, and Torrent.PiecePriority just does another lookup of *Piece to resolve\n\t\t// the priority through Piece.purePriority, which is probably slower.\n\t\tleftPriority := leftPiece.Priority\n\t\trightPriority := rightPiece.Priority\n\t\tml = ml.Int(\n\t\t\t-int(leftPriority),\n\t\t\t-int(rightPriority),\n\t\t)\n\t\tif !ml.Ok() {\n\t\t\tif leftPriority != rightPriority {\n\t\t\t\tpanic(\"expected equal\")\n\t\t\t}\n\t\t}\n\t\treturn leftPriority\n\t}()\n\tif ml.Ok() {\n\t\treturn ml.MustLess()\n\t}\n\tleftRequestState := t.requestState[leftRequest]\n\trightRequestState := t.requestState[rightRequest]\n\tleftPeer := leftRequestState.peer\n\trightPeer := rightRequestState.peer\n\t// Prefer chunks already requested from this peer.\n\tml = ml.Bool(rightPeer == p.peer, leftPeer == p.peer)\n\t// Prefer unrequested chunks.\n\tml = ml.Bool(rightPeer == nil, leftPeer == nil)\n\tif ml.Ok() {\n\t\treturn ml.MustLess()\n\t}\n\tif leftPeer != nil {\n\t\t// The right peer should also be set, or we'd have resolved the computation by now.\n\t\tml = ml.Uint64(\n\t\t\trightPeer.requestState.Requests.GetCardinality(),\n\t\t\tleftPeer.requestState.Requests.GetCardinality(),\n\t\t)\n\t\t// Could either of the lastRequested be Zero? That's what checking an existing peer is for.\n\t\tleftLast := leftRequestState.when\n\t\trightLast := rightRequestState.when\n\t\tif leftLast.IsZero() || rightLast.IsZero() {\n\t\t\tpanic(\"expected non-zero last requested times\")\n\t\t}\n\t\t// We want the most-recently requested on the left. Clients like Transmission serve requests\n\t\t// in received order, so the most recently-requested is the one that has the longest until\n\t\t// it will be served and therefore is the best candidate to cancel.\n\t\tml = ml.CmpInt64(rightLast.Sub(leftLast).Nanoseconds())\n\t}\n\tml = ml.Int(\n\t\tleftPiece.Availability,\n\t\trightPiece.Availability)\n\tif priority == PiecePriorityReadahead {\n\t\t// TODO: For readahead in particular, it would be even better to consider distance from the\n\t\t// reader position so that reads earlier in a torrent don't starve reads later in the\n\t\t// torrent. This would probably require reconsideration of how readahead priority works.\n\t\tml = ml.Int(leftPieceIndex, rightPieceIndex)\n\t} else {\n\t\tml = ml.Int(t.pieceRequestOrder[leftPieceIndex], t.pieceRequestOrder[rightPieceIndex])\n\t}\n\treturn ml.Less()\n}\n\ntype desiredRequestState struct {\n\tRequests   desiredPeerRequests\n\tInterested bool\n}\n\nfunc (p *Peer) getDesiredRequestState() (desired desiredRequestState) {\n\tt := p.t\n\tif !t.haveInfo() {\n\t\treturn\n\t}\n\tif t.closed.IsSet() {\n\t\treturn\n\t}\n\tif t.dataDownloadDisallowed.Bool() {\n\t\treturn\n\t}\n\tinput := t.getRequestStrategyInput()\n\trequestHeap := desiredPeerRequests{\n\t\tpeer:           p,\n\t\tpieceStates:    t.requestPieceStates,\n\t\trequestIndexes: t.requestIndexes,\n\t}\n\tclear(requestHeap.pieceStates)\n\t// Caller-provided allocation for roaring bitmap iteration.\n\tvar it typedRoaring.Iterator[RequestIndex]\n\trequestStrategy.GetRequestablePieces(\n\t\tinput,\n\t\tt.getPieceRequestOrder(),\n\t\tfunc(ih InfoHash, pieceIndex int, pieceExtra requestStrategy.PieceRequestOrderState) bool {\n\t\t\tif ih != *t.canonicalShortInfohash() {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !p.peerHasPiece(pieceIndex) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\trequestHeap.pieceStates[pieceIndex].Set(pieceExtra)\n\t\t\tallowedFast := p.peerAllowedFast.Contains(pieceIndex)\n\t\t\tt.iterUndirtiedRequestIndexesInPiece(&it, pieceIndex, func(r requestStrategy.RequestIndex) {\n\t\t\t\tif !allowedFast {\n\t\t\t\t\t// We must signal interest to request this. TODO: We could set interested if the\n\t\t\t\t\t// peers pieces (minus the allowed fast set) overlap with our missing pieces if\n\t\t\t\t\t// there are any readers, or any pending pieces.\n\t\t\t\t\tdesired.Interested = true\n\t\t\t\t\t// We can make or will allow sustaining a request here if we're not choked, or\n\t\t\t\t\t// have made the request previously (presumably while unchoked), and haven't had\n\t\t\t\t\t// the peer respond yet (and the request was retained because we are using the\n\t\t\t\t\t// fast extension).\n\t\t\t\t\tif p.peerChoking && !p.requestState.Requests.Contains(r) {\n\t\t\t\t\t\t// We can't request this right now.\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcancelled := &p.requestState.Cancelled\n\t\t\t\tif !cancelled.IsEmpty() && cancelled.Contains(r) {\n\t\t\t\t\t// Can't re-request while awaiting acknowledgement.\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\trequestHeap.requestIndexes = append(requestHeap.requestIndexes, r)\n\t\t\t})\n\t\t\treturn true\n\t\t},\n\t)\n\tt.assertPendingRequests()\n\tdesired.Requests = requestHeap\n\treturn\n}\n\nfunc (p *Peer) maybeUpdateActualRequestState() {\n\tif p.closed.IsSet() {\n\t\treturn\n\t}\n\tif p.needRequestUpdate == \"\" {\n\t\treturn\n\t}\n\tif p.needRequestUpdate == peerUpdateRequestsTimerReason {\n\t\tsince := time.Since(p.lastRequestUpdate)\n\t\tif since < updateRequestsTimerDuration {\n\t\t\tpanic(since)\n\t\t}\n\t}\n\tpprof.Do(\n\t\tcontext.Background(),\n\t\tpprof.Labels(\"update request\", string(p.needRequestUpdate)),\n\t\tfunc(_ context.Context) {\n\t\t\tnext := p.getDesiredRequestState()\n\t\t\tp.applyRequestState(next)\n\t\t\tp.t.cacheNextRequestIndexesForReuse(next.Requests.requestIndexes)\n\t\t},\n\t)\n}\n\nfunc (t *Torrent) cacheNextRequestIndexesForReuse(slice []RequestIndex) {\n\t// The incoming slice can be smaller when getDesiredRequestState short circuits on some\n\t// conditions.\n\tif cap(slice) > cap(t.requestIndexes) {\n\t\tt.requestIndexes = slice[:0]\n\t}\n}\n\n// Whether we should allow sending not interested (\"losing interest\") to the peer. I noticed\n// qBitTorrent seems to punish us for sending not interested when we're streaming and don't\n// currently need anything.\nfunc (p *Peer) allowSendNotInterested() bool {\n\t// Except for caching, we're not likely to lose pieces very soon.\n\tif p.t.haveAllPieces() {\n\t\treturn true\n\t}\n\tall, known := p.peerHasAllPieces()\n\tif all || !known {\n\t\treturn false\n\t}\n\t// Allow losing interest if we have all the pieces the peer has.\n\treturn roaring.AndNot(p.peerPieces(), &p.t._completedPieces).IsEmpty()\n}\n\n// Transmit/action the request state to the peer.\nfunc (p *Peer) applyRequestState(next desiredRequestState) {\n\tcurrent := &p.requestState\n\t// Make interest sticky\n\tif !next.Interested && p.requestState.Interested {\n\t\tif !p.allowSendNotInterested() {\n\t\t\tnext.Interested = true\n\t\t}\n\t}\n\tif !p.setInterested(next.Interested) {\n\t\treturn\n\t}\n\tmore := true\n\torig := next.Requests.requestIndexes\n\trequestHeap := heap.InterfaceForSlice(\n\t\t&next.Requests.requestIndexes,\n\t\tnext.Requests.lessByValue,\n\t)\n\theap.Init(requestHeap)\n\n\tt := p.t\n\toriginalRequestCount := current.Requests.GetCardinality()\n\tfor {\n\t\tif requestHeap.Len() == 0 {\n\t\t\tbreak\n\t\t}\n\t\tnumPending := maxRequests(current.Requests.GetCardinality() + current.Cancelled.GetCardinality())\n\t\tif numPending >= p.nominalMaxRequests() {\n\t\t\tbreak\n\t\t}\n\t\treq := heap.Pop(requestHeap)\n\t\tif cap(next.Requests.requestIndexes) != cap(orig) {\n\t\t\tpanic(\"changed\")\n\t\t}\n\n\t\t// don't add requests on reciept of a reject - because this causes request back\n\t\t// to potentially permanently unresponive peers - which just adds network noise.  If\n\t\t// the peer can handle more requests it will send an \"unchoked\" message - which\n\t\t// will cause it to get added back to the request queue\n\t\tif p.needRequestUpdate == peerUpdateRequestsRemoteRejectReason {\n\t\t\tcontinue\n\t\t}\n\n\t\texisting := t.requestingPeer(req)\n\t\tif existing != nil && existing != p {\n\t\t\t// don't steal on cancel - because this is triggered by t.cancelRequest below\n\t\t\t// which means that the cancelled can immediately try to steal back a request\n\t\t\t// it has lost which can lead to circular cancel/add processing\n\t\t\tif p.needRequestUpdate == peerUpdateRequestsPeerCancelReason {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Don't steal from the poor.\n\t\t\tdiff := int64(current.Requests.GetCardinality()) + 1 - (int64(existing.uncancelledRequests()) - 1)\n\t\t\t// Steal a request that leaves us with one more request than the existing peer\n\t\t\t// connection if the stealer more recently received a chunk.\n\t\t\tif diff > 1 || (diff == 1 && !p.lastUsefulChunkReceived.After(existing.lastUsefulChunkReceived)) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tt.cancelRequest(req)\n\t\t}\n\t\tmore = p.mustRequest(req)\n\t\tif !more {\n\t\t\tbreak\n\t\t}\n\t}\n\tif !more {\n\t\t// This might fail if we incorrectly determine that we can fit up to the maximum allowed\n\t\t// requests into the available write buffer space. We don't want that to happen because it\n\t\t// makes our peak requests dependent on how much was already in the buffer.\n\t\tpanic(fmt.Sprintf(\n\t\t\t\"couldn't fill apply entire request state [newRequests=%v]\",\n\t\t\tcurrent.Requests.GetCardinality()-originalRequestCount))\n\t}\n\tnewPeakRequests := maxRequests(current.Requests.GetCardinality() - originalRequestCount)\n\t// log.Printf(\n\t// \t\"requests %v->%v (peak %v->%v) reason %q (peer %v)\",\n\t// \toriginalRequestCount, current.Requests.GetCardinality(), p.peakRequests, newPeakRequests, p.needRequestUpdate, p)\n\tp.peakRequests = newPeakRequests\n\tp.needRequestUpdate = \"\"\n\tp.lastRequestUpdate = time.Now()\n\tif enableUpdateRequestsTimer {\n\t\tp.updateRequestsTimer.Reset(updateRequestsTimerDuration)\n\t}\n}\n\n// This could be set to 10s to match the unchoke/request update interval recommended by some\n// specifications. I've set it shorter to trigger it more often for testing for now.\nconst (\n\tupdateRequestsTimerDuration = 3 * time.Second\n\tenableUpdateRequestsTimer   = false\n)\n"
        },
        {
          "name": "requesting_test.go",
          "type": "blob",
          "size": 1.9580078125,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/bradfitz/iter\"\n\tqt \"github.com/frankban/quicktest\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc keysAsSlice(m map[Request]struct{}) (sl []Request) {\n\tfor k := range m {\n\t\tsl = append(sl, k)\n\t}\n\treturn\n}\n\nfunc makeTypicalRequests() map[Request]struct{} {\n\tm := make(map[Request]struct{})\n\tfor p := pp.Integer(0); p < 4; p++ {\n\t\tfor c := pp.Integer(0); c < 16; c++ {\n\t\t\tm[Request{p, ChunkSpec{c * defaultChunkSize, defaultChunkSize}}] = struct{}{}\n\t\t}\n\t}\n\treturn m\n}\n\nfunc TestLogExampleRequestMapOrdering(t *testing.T) {\n\tfor k := range makeTypicalRequests() {\n\t\tt.Log(k)\n\t}\n}\n\nfunc TestRequestMapOrderingPersistent(t *testing.T) {\n\tm := makeTypicalRequests()\n\t// Shows that map order is persistent across separate range statements.\n\tqt.Assert(t, keysAsSlice(m), qt.ContentEquals, keysAsSlice(m))\n}\n\nfunc TestRequestMapOrderAcrossInstances(t *testing.T) {\n\t// This shows that different map instances with the same contents can have the same range order.\n\tqt.Assert(t, keysAsSlice(makeTypicalRequests()), qt.ContentEquals, keysAsSlice(makeTypicalRequests()))\n}\n\n// Added for testing repeating loop iteration after shuffling in Peer.applyRequestState.\nfunc TestForLoopRepeatItem(t *testing.T) {\n\tt.Run(\"ExplicitLoopVar\", func(t *testing.T) {\n\t\tonce := false\n\t\tvar seen []int\n\t\tfor i := 0; i < 4; i++ {\n\t\t\tseen = append(seen, i)\n\t\t\tif !once && i == 2 {\n\t\t\t\tonce = true\n\t\t\t\ti--\n\t\t\t\t// Will i++ still run?\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// We can mutate i and it's observed by the loop. No special treatment of the loop var.\n\t\tqt.Assert(t, seen, qt.DeepEquals, []int{0, 1, 2, 2, 3})\n\t})\n\tt.Run(\"Range\", func(t *testing.T) {\n\t\tonce := false\n\t\tvar seen []int\n\t\tfor i := range iter.N(4) {\n\t\t\tseen = append(seen, i)\n\t\t\tif !once && i == 2 {\n\t\t\t\tonce = true\n\t\t\t\t// Can we actually modify the next value of i produced by the range?\n\t\t\t\ti--\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// Range ignores any mutation to i.\n\t\tqt.Assert(t, seen, qt.DeepEquals, []int{0, 1, 2, 3})\n\t})\n}\n"
        },
        {
          "name": "reuse_test.go",
          "type": "blob",
          "size": 2.380859375,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"net\"\n\t\"sync/atomic\"\n\t\"syscall\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/log\"\n\tqt \"github.com/frankban/quicktest\"\n)\n\n// Show that multiple connections from the same local TCP port to the same remote port will fail.\nfunc TestTcpPortReuseIsABadIdea(t *testing.T) {\n\tremote, err := net.Listen(\"tcp\", \"localhost:0\")\n\tc := qt.New(t)\n\tc.Assert(err, qt.IsNil)\n\tdefer remote.Close()\n\tdialer := net.Dialer{}\n\t// Show that we can't duplicate an existing connection even with various socket options.\n\tdialer.Control = func(network, address string, c syscall.RawConn) (err error) {\n\t\treturn c.Control(func(fd uintptr) {\n\t\t\terr = setReusePortSockOpts(fd)\n\t\t})\n\t}\n\t// Tie up a local port to the remote.\n\tfirst, err := dialer.Dial(\"tcp\", remote.Addr().String())\n\tc.Assert(err, qt.IsNil)\n\tdefer first.Close()\n\t// Show that dialling the remote with the same local port fails.\n\tdialer.LocalAddr = first.LocalAddr()\n\t_, err = dialer.Dial(\"tcp\", remote.Addr().String())\n\tc.Assert(err, qt.IsNotNil)\n\t// Show that not fixing the local port again allows connections to succeed.\n\tdialer.LocalAddr = nil\n\tsecond, err := dialer.Dial(\"tcp\", remote.Addr().String())\n\tc.Assert(err, qt.IsNil)\n\tsecond.Close()\n}\n\n// Show that multiple connections from the same local utp socket to the same remote port will\n// succeed. This is necessary for ut_holepunch to work.\nfunc TestUtpLocalPortIsReusable(t *testing.T) {\n\tconst network = \"udp\"\n\tc := qt.New(t)\n\tremote, err := NewUtpSocket(network, \"localhost:0\", nil, log.Default)\n\tc.Assert(err, qt.IsNil)\n\tdefer remote.Close()\n\tvar remoteAccepts int32\n\tdoneAccepting := make(chan struct{})\n\tgo func() {\n\t\tdefer close(doneAccepting)\n\t\tfor {\n\t\t\tc, err := remote.Accept()\n\t\t\tif err != nil {\n\t\t\t\tif atomic.LoadInt32(&remoteAccepts) != 2 {\n\t\t\t\t\tt.Logf(\"error accepting on remote: %v\", err)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// This is not a leak, bugger off.\n\t\t\tdefer c.Close()\n\t\t\tatomic.AddInt32(&remoteAccepts, 1)\n\t\t}\n\t}()\n\tlocal, err := NewUtpSocket(network, \"localhost:0\", nil, log.Default)\n\tc.Assert(err, qt.IsNil)\n\tdefer local.Close()\n\tfirst, err := local.DialContext(context.Background(), network, remote.Addr().String())\n\tc.Assert(err, qt.IsNil)\n\tdefer first.Close()\n\tsecond, err := local.DialContext(context.Background(), network, remote.Addr().String())\n\tc.Assert(err, qt.IsNil)\n\tdefer second.Close()\n\tremote.Close()\n\t<-doneAccepting\n\tc.Assert(atomic.LoadInt32(&remoteAccepts), qt.Equals, int32(2))\n}\n"
        },
        {
          "name": "rlreader_test.go",
          "type": "blob",
          "size": 2.2685546875,
          "content": "package torrent\n\nimport (\n\t\"io\"\n\t\"log\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\t\"golang.org/x/time/rate\"\n)\n\nfunc writeN(ws []io.Writer, n int) error {\n\tb := make([]byte, n)\n\tfor _, w := range ws[1:] {\n\t\tn1 := rand.Intn(n)\n\t\twn, err := w.Write(b[:n1])\n\t\tif wn != n1 {\n\t\t\tif err == nil {\n\t\t\t\tpanic(n1)\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tn -= n1\n\t}\n\twn, err := ws[0].Write(b[:n])\n\tif wn != n {\n\t\tif err == nil {\n\t\t\tpanic(n)\n\t\t}\n\t}\n\treturn err\n}\n\nfunc TestRateLimitReaders(t *testing.T) {\n\tconst (\n\t\tnumReaders     = 2\n\t\tbytesPerSecond = 100\n\t\tburst          = 5\n\t\treadSize       = 6\n\t\twriteRounds    = 10\n\t\tbytesPerRound  = 12\n\t)\n\tcontrol := rate.NewLimiter(bytesPerSecond, burst)\n\tshared := rate.NewLimiter(bytesPerSecond, burst)\n\tvar (\n\t\tws []io.Writer\n\t\tcs []io.Closer\n\t)\n\twg := sync.WaitGroup{}\n\ttype read struct {\n\t\tN int\n\t\t// When the read was allowed.\n\t\tAt time.Time\n\t}\n\treads := make(chan read)\n\tdone := make(chan struct{})\n\tfor i := 0; i < numReaders; i += 1 {\n\t\tr, w := io.Pipe()\n\t\tws = append(ws, w)\n\t\tcs = append(cs, w)\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tr := rateLimitedReader{\n\t\t\t\tl: shared,\n\t\t\t\tr: r,\n\t\t\t}\n\t\t\tb := make([]byte, readSize)\n\t\t\tfor {\n\t\t\t\tn, err := r.Read(b)\n\t\t\t\tselect {\n\t\t\t\tcase reads <- read{n, r.lastRead}:\n\t\t\t\tcase <-done:\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\tcloseAll := func() {\n\t\tfor _, c := range cs {\n\t\t\tc.Close()\n\t\t}\n\t}\n\tdefer func() {\n\t\tclose(done)\n\t\tcloseAll()\n\t\twg.Wait()\n\t}()\n\twritten := 0\n\tgo func() {\n\t\tfor i := 0; i < writeRounds; i += 1 {\n\t\t\terr := writeN(ws, bytesPerRound)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"error writing: %s\", err)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\twritten += bytesPerRound\n\t\t}\n\t\tcloseAll()\n\t\twg.Wait()\n\t\tclose(reads)\n\t}()\n\ttotalBytesRead := 0\n\tstarted := time.Now()\n\tfor r := range reads {\n\t\ttotalBytesRead += r.N\n\t\trequire.False(t, r.At.IsZero())\n\t\t// Copy what the reader should have done with its reservation.\n\t\tres := control.ReserveN(r.At, r.N)\n\t\t// If we don't have to wait with the control, the reader has gone too\n\t\t// fast.\n\t\tif res.Delay() > 0 {\n\t\t\tlog.Printf(\"%d bytes not allowed at %s\", r.N, time.Since(started))\n\t\t\tt.FailNow()\n\t\t}\n\t}\n\tassert.EqualValues(t, writeRounds*bytesPerRound, totalBytesRead)\n}\n"
        },
        {
          "name": "roaring.go",
          "type": "blob",
          "size": 0.5146484375,
          "content": "package torrent\n\nimport (\n\t\"github.com/anacrolix/torrent/typed-roaring\"\n)\n\n// Return the number of bits set in the range. To do this we need the rank of the item before the\n// first, and the rank of the last item. An off-by-one minefield. Hopefully I haven't missed\n// something in roaring's API that provides this.\nfunc roaringBitmapRangeCardinality[T typedRoaring.BitConstraint](bm interface{ Rank(T) uint64 }, start, end T) (card uint64) {\n\tcard = bm.Rank(end - 1)\n\tif start != 0 {\n\t\tcard -= bm.Rank(start - 1)\n\t}\n\treturn\n}\n"
        },
        {
          "name": "segments",
          "type": "tree",
          "content": null
        },
        {
          "name": "smartban.go",
          "type": "blob",
          "size": 1.2451171875,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"net/netip\"\n\n\tg \"github.com/anacrolix/generics\"\n\n\t\"github.com/anacrolix/torrent/smartban\"\n)\n\ntype bannableAddr = netip.Addr\n\ntype smartBanCache = smartban.Cache[bannableAddr, RequestIndex, uint64]\n\ntype blockCheckingWriter struct {\n\tcache        *smartBanCache\n\trequestIndex RequestIndex\n\t// Peers that didn't match blocks written now.\n\tbadPeers    map[bannableAddr]struct{}\n\tblockBuffer bytes.Buffer\n\tchunkSize   int\n}\n\nfunc (me *blockCheckingWriter) checkBlock() {\n\tb := me.blockBuffer.Next(me.chunkSize)\n\tfor _, peer := range me.cache.CheckBlock(me.requestIndex, b) {\n\t\tg.MakeMapIfNilAndSet(&me.badPeers, peer, struct{}{})\n\t}\n\tme.requestIndex++\n}\n\nfunc (me *blockCheckingWriter) checkFullBlocks() {\n\tfor me.blockBuffer.Len() >= me.chunkSize {\n\t\tme.checkBlock()\n\t}\n}\n\nfunc (me *blockCheckingWriter) Write(b []byte) (int, error) {\n\tn, err := me.blockBuffer.Write(b)\n\tif err != nil {\n\t\t// bytes.Buffer.Write should never fail.\n\t\tpanic(err)\n\t}\n\tme.checkFullBlocks()\n\treturn n, err\n}\n\n// Check any remaining block data. Terminal pieces or piece sizes that don't divide into the chunk\n// size cleanly may leave fragments that should be checked.\nfunc (me *blockCheckingWriter) Flush() {\n\tfor me.blockBuffer.Len() != 0 {\n\t\tme.checkBlock()\n\t}\n}\n"
        },
        {
          "name": "smartban",
          "type": "tree",
          "content": null
        },
        {
          "name": "smartban_test.go",
          "type": "blob",
          "size": 0.9853515625,
          "content": "package torrent\n\nimport (\n\t\"crypto/sha1\"\n\t\"net/netip\"\n\t\"testing\"\n\n\t\"github.com/anacrolix/missinggo/v2/iter\"\n\t\"github.com/cespare/xxhash\"\n\n\t\"github.com/anacrolix/torrent/smartban\"\n)\n\nfunc benchmarkSmartBanRecordBlock[Sum comparable](b *testing.B, hash func([]byte) Sum) {\n\tvar cache smartban.Cache[bannableAddr, RequestIndex, Sum]\n\tcache.Hash = hash\n\tcache.Init()\n\tvar data [defaultChunkSize]byte\n\tvar addr netip.Addr\n\tb.SetBytes(int64(len(data)))\n\tfor i := range iter.N(b.N) {\n\t\tcache.RecordBlock(addr, RequestIndex(i), data[:])\n\t}\n}\n\nfunc BenchmarkSmartBanRecordBlock(b *testing.B) {\n\tb.Run(\"xxHash\", func(b *testing.B) {\n\t\tvar salt [8]byte\n\t\tbenchmarkSmartBanRecordBlock(b, func(block []byte) uint64 {\n\t\t\th := xxhash.New()\n\t\t\t// xxHash is not cryptographic, and so we're salting it so attackers can't know a priori\n\t\t\t// where block data collisions are.\n\t\t\th.Write(salt[:])\n\t\t\th.Write(block)\n\t\t\treturn h.Sum64()\n\t\t})\n\t})\n\tb.Run(\"Sha1\", func(b *testing.B) {\n\t\tbenchmarkSmartBanRecordBlock(b, sha1.Sum)\n\t})\n}\n"
        },
        {
          "name": "socket.go",
          "type": "blob",
          "size": 5.28515625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n\t\"strconv\"\n\t\"syscall\"\n\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n)\n\ntype Listener interface {\n\t// Accept waits for and returns the next connection to the listener.\n\tAccept() (net.Conn, error)\n\n\t// Addr returns the listener's network address.\n\tAddr() net.Addr\n}\n\ntype socket interface {\n\tListener\n\tDialer\n\tClose() error\n}\n\nfunc listen(n network, addr string, f firewallCallback, logger log.Logger) (socket, error) {\n\tswitch {\n\tcase n.Tcp:\n\t\treturn listenTcp(n.String(), addr)\n\tcase n.Udp:\n\t\treturn listenUtp(n.String(), addr, f, logger)\n\tdefault:\n\t\tpanic(n)\n\t}\n}\n\n// Dialing TCP from a local port limits us to a single outgoing TCP connection to each remote\n// client. Instead, this should be a last resort if we need to use holepunching, and only then to\n// connect to other clients that actually try to holepunch TCP.\nconst dialTcpFromListenPort = false\n\nvar tcpListenConfig = net.ListenConfig{\n\tControl: func(network, address string, c syscall.RawConn) (err error) {\n\t\tcontrolErr := c.Control(func(fd uintptr) {\n\t\t\tif dialTcpFromListenPort {\n\t\t\t\terr = setReusePortSockOpts(fd)\n\t\t\t}\n\t\t})\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\terr = controlErr\n\t\treturn\n\t},\n\t// BitTorrent connections manage their own keep-alives.\n\tKeepAlive: -1,\n}\n\nfunc listenTcp(network, address string) (s socket, err error) {\n\tl, err := tcpListenConfig.Listen(context.Background(), network, address)\n\tif err != nil {\n\t\treturn\n\t}\n\tnetDialer := net.Dialer{\n\t\t// We don't want fallback, as we explicitly manage the IPv4/IPv6 distinction ourselves,\n\t\t// although it's probably not triggered as I think the network is already constrained to\n\t\t// tcp4 or tcp6 at this point.\n\t\tFallbackDelay: -1,\n\t\t// BitTorrent connections manage their own keepalives.\n\t\tKeepAlive: tcpListenConfig.KeepAlive,\n\t\tControl: func(network, address string, c syscall.RawConn) (err error) {\n\t\t\tcontrolErr := c.Control(func(fd uintptr) {\n\t\t\t\terr = setSockNoLinger(fd)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// Failing to disable linger is undesirable, but not fatal.\n\t\t\t\t\tlog.Levelf(log.Debug, \"error setting linger socket option on tcp socket: %v\", err)\n\t\t\t\t\terr = nil\n\t\t\t\t}\n\t\t\t\t// This is no longer required I think, see\n\t\t\t\t// https://github.com/anacrolix/torrent/discussions/856. I added this originally to\n\t\t\t\t// allow dialling out from the client's listen port, but that doesn't really work. I\n\t\t\t\t// think Linux older than ~2013 doesn't support SO_REUSEPORT.\n\t\t\t\tif dialTcpFromListenPort {\n\t\t\t\t\terr = setReusePortSockOpts(fd)\n\t\t\t\t}\n\t\t\t})\n\t\t\tif err == nil {\n\t\t\t\terr = controlErr\n\t\t\t}\n\t\t\treturn\n\t\t},\n\t}\n\tif dialTcpFromListenPort {\n\t\tnetDialer.LocalAddr = l.Addr()\n\t}\n\ts = tcpSocket{\n\t\tListener: l,\n\t\tNetworkDialer: NetworkDialer{\n\t\t\tNetwork: network,\n\t\t\tDialer:  &netDialer,\n\t\t},\n\t}\n\treturn\n}\n\ntype tcpSocket struct {\n\tnet.Listener\n\tNetworkDialer\n}\n\nfunc listenAll(\n\tnetworks []network,\n\tgetHost func(string) string,\n\tport int,\n\tf firewallCallback,\n\tlogger log.Logger,\n) ([]socket, error) {\n\tif len(networks) == 0 {\n\t\treturn nil, nil\n\t}\n\tvar nahs []networkAndHost\n\tfor _, n := range networks {\n\t\tnahs = append(nahs, networkAndHost{n, getHost(n.String())})\n\t}\n\tfor {\n\t\tss, retry, err := listenAllRetry(nahs, port, f, logger)\n\t\tif !retry {\n\t\t\treturn ss, err\n\t\t}\n\t}\n}\n\ntype networkAndHost struct {\n\tNetwork network\n\tHost    string\n}\n\nfunc isUnsupportedNetworkError(err error) bool {\n\tvar sysErr *os.SyscallError\n\t//spewCfg := spew.NewDefaultConfig()\n\t//spewCfg.ContinueOnMethod = true\n\t//spewCfg.Dump(err)\n\tif !errors.As(err, &sysErr) {\n\t\treturn false\n\t}\n\t//spewCfg.Dump(sysErr)\n\t//spewCfg.Dump(sysErr.Err.Error())\n\t// This might only be Linux specific.\n\treturn sysErr.Syscall == \"bind\" && sysErr.Err.Error() == \"cannot assign requested address\"\n}\n\nfunc listenAllRetry(\n\tnahs []networkAndHost,\n\tport int,\n\tf firewallCallback,\n\tlogger log.Logger,\n) (ss []socket, retry bool, err error) {\n\t// Close all sockets on error or retry.\n\tdefer func() {\n\t\tif err != nil || retry {\n\t\t\tfor _, s := range ss {\n\t\t\t\ts.Close()\n\t\t\t}\n\t\t\tss = nil\n\t\t}\n\t}()\n\tg.MakeSliceWithCap(&ss, len(nahs))\n\tportStr := strconv.FormatInt(int64(port), 10)\n\tfor _, nah := range nahs {\n\t\tvar s socket\n\t\ts, err = listen(nah.Network, net.JoinHostPort(nah.Host, portStr), f, logger)\n\t\tif err != nil {\n\t\t\tif isUnsupportedNetworkError(err) {\n\t\t\t\terr = nil\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif len(ss) == 0 {\n\t\t\t\t// First relative to a possibly dynamic port (0).\n\t\t\t\terr = fmt.Errorf(\"first listen: %w\", err)\n\t\t\t} else {\n\t\t\t\terr = fmt.Errorf(\"subsequent listen: %w\", err)\n\t\t\t}\n\t\t\tretry = missinggo.IsAddrInUse(err) && port == 0\n\t\t\treturn\n\t\t}\n\t\tss = append(ss, s)\n\t\tportStr = strconv.FormatInt(int64(missinggo.AddrPort(ss[0].Addr())), 10)\n\t}\n\treturn\n}\n\n// This isn't aliased from go-libutp since that assumes CGO.\ntype firewallCallback func(net.Addr) bool\n\nfunc listenUtp(network, addr string, fc firewallCallback, logger log.Logger) (socket, error) {\n\tus, err := NewUtpSocket(network, addr, fc, logger)\n\treturn utpSocketSocket{us, network}, err\n}\n\n// utpSocket wrapper, additionally wrapped for the torrent package's socket interface.\ntype utpSocketSocket struct {\n\tutpSocket\n\tnetwork string\n}\n\nfunc (me utpSocketSocket) DialerNetwork() string {\n\treturn me.network\n}\n\nfunc (me utpSocketSocket) Dial(ctx context.Context, addr string) (conn net.Conn, err error) {\n\treturn me.utpSocket.DialContext(ctx, me.network, addr)\n}\n"
        },
        {
          "name": "sockopts.go",
          "type": "blob",
          "size": 0.111328125,
          "content": "//go:build !wasm\n\npackage torrent\n\nimport \"syscall\"\n\nvar lingerOffVal = syscall.Linger{\n\tOnoff:  0,\n\tLinger: 0,\n}\n"
        },
        {
          "name": "sockopts_unix.go",
          "type": "blob",
          "size": 0.71875,
          "content": "//go:build !windows && !wasm\n\npackage torrent\n\nimport (\n\t\"syscall\"\n\n\t\"golang.org/x/sys/unix\"\n)\n\nfunc setReusePortSockOpts(fd uintptr) (err error) {\n\t// I would use libp2p/go-reuseport to do this here, but no surprise it's\n\t// implemented incorrectly.\n\n\t// Looks like we can get away with just REUSEPORT at least on Darwin, and probably by\n\t// extension BSDs and Linux.\n\tif false {\n\t\terr = syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\terr = syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, unix.SO_REUSEPORT, 1)\n\treturn\n}\n\nfunc setSockNoLinger(fd uintptr) (err error) {\n\treturn syscall.SetsockoptLinger(int(fd), syscall.SOL_SOCKET, syscall.SO_LINGER, &lingerOffVal)\n}\n"
        },
        {
          "name": "sockopts_wasm.go",
          "type": "blob",
          "size": 0.388671875,
          "content": "package torrent\n\n// It's possible that we either need to use JS-specific way to allow port reuse, or to fall back to\n// dialling TCP without forcing the local address to match the listener. If the fallback is\n// implemented, then this should probably return an error to trigger it.\nfunc setReusePortSockOpts(fd uintptr) error {\n\treturn nil\n}\n\nfunc setSockNoLinger(fd uintptr) error {\n\treturn nil\n}\n"
        },
        {
          "name": "sockopts_windows.go",
          "type": "blob",
          "size": 0.3662109375,
          "content": "package torrent\n\nimport (\n\t\"syscall\"\n\n\t\"golang.org/x/sys/windows\"\n)\n\nfunc setReusePortSockOpts(fd uintptr) (err error) {\n\treturn windows.SetsockoptInt(windows.Handle(fd), windows.SOL_SOCKET, windows.SO_REUSEADDR, 1)\n}\n\nfunc setSockNoLinger(fd uintptr) (err error) {\n\treturn syscall.SetsockoptLinger(syscall.Handle(fd), syscall.SOL_SOCKET, syscall.SO_LINGER, &lingerOffVal)\n}\n"
        },
        {
          "name": "sources.go",
          "type": "blob",
          "size": 1.7685546875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/anacrolix/log\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\n// Add HTTP endpoints that serve the metainfo. They will be used if the torrent info isn't obtained\n// yet. The Client HTTP client is used.\nfunc (t *Torrent) UseSources(sources []string) {\n\tselect {\n\tcase <-t.Closed():\n\t\treturn\n\tcase <-t.GotInfo():\n\t\treturn\n\tdefault:\n\t}\n\tfor _, s := range sources {\n\t\t_, loaded := t.activeSources.LoadOrStore(s, struct{}{})\n\t\tif loaded {\n\t\t\tcontinue\n\t\t}\n\t\ts := s\n\t\tgo func() {\n\t\t\terr := t.useActiveTorrentSource(s)\n\t\t\t_, loaded := t.activeSources.LoadAndDelete(s)\n\t\t\tif !loaded {\n\t\t\t\tpanic(s)\n\t\t\t}\n\t\t\tlevel := log.Debug\n\t\t\tif err != nil && !errors.Is(err, context.Canceled) {\n\t\t\t\tlevel = log.Info\n\t\t\t}\n\t\t\tt.logger.Levelf(level, \"used torrent source %q [err=%v]\", s, err)\n\t\t}()\n\t}\n}\n\nfunc (t *Torrent) useActiveTorrentSource(source string) error {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tgo func() {\n\t\tselect {\n\t\tcase <-t.GotInfo():\n\t\tcase <-t.Closed():\n\t\tcase <-ctx.Done():\n\t\t}\n\t\tcancel()\n\t}()\n\tmi, err := getTorrentSource(ctx, source, t.cl.httpClient)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn t.MergeSpec(TorrentSpecFromMetaInfo(&mi))\n}\n\nfunc getTorrentSource(ctx context.Context, source string, hc *http.Client) (mi metainfo.MetaInfo, err error) {\n\tvar req *http.Request\n\tif req, err = http.NewRequestWithContext(ctx, http.MethodGet, source, nil); err != nil {\n\t\treturn\n\t}\n\tvar resp *http.Response\n\tif resp, err = hc.Do(req); err != nil {\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode != http.StatusOK {\n\t\terr = fmt.Errorf(\"unexpected response status code: %v\", resp.StatusCode)\n\t\treturn\n\t}\n\terr = bencode.NewDecoder(resp.Body).Decode(&mi)\n\treturn\n}\n"
        },
        {
          "name": "spec.go",
          "type": "blob",
          "size": 3.1123046875,
          "content": "package torrent\n\nimport (\n\t\"fmt\"\n\n\tg \"github.com/anacrolix/generics\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/storage\"\n\tinfohash_v2 \"github.com/anacrolix/torrent/types/infohash-v2\"\n)\n\n// Specifies a new torrent for adding to a client, or additions to an existing Torrent. There are\n// constructor functions for magnet URIs and torrent metainfo files. TODO: This type should be\n// dismantled into a new Torrent option type, and separate Torrent mutate method(s).\ntype TorrentSpec struct {\n\t// The tiered tracker URIs.\n\tTrackers [][]string\n\t// TODO: Move into a \"new\" Torrent opt type.\n\tInfoHash   metainfo.Hash\n\tInfoHashV2 g.Option[infohash_v2.T]\n\tInfoBytes  []byte\n\t// The name to use if the Name field from the Info isn't available.\n\tDisplayName string\n\t// WebSeed URLs. For additional options add the URLs separately with Torrent.AddWebSeeds\n\t// instead.\n\tWebseeds  []string\n\tDhtNodes  []string\n\tPeerAddrs []string\n\t// The combination of the \"xs\" and \"as\" fields in magnet links, for now.\n\tSources []string\n\t// BEP 52 \"piece layers\" from metainfo\n\tPieceLayers map[string]string\n\n\t// The chunk size to use for outbound requests. Defaults to 16KiB if not set. Can only be set\n\t// for new Torrents. TODO: Move into a \"new\" Torrent opt type.\n\tChunkSize pp.Integer\n\t// TODO: Move into a \"new\" Torrent opt type.\n\tStorage storage.ClientImpl\n\n\tDisableInitialPieceCheck bool\n\n\t// Whether to allow data download or upload\n\tDisallowDataUpload   bool\n\tDisallowDataDownload bool\n}\n\nfunc TorrentSpecFromMagnetUri(uri string) (spec *TorrentSpec, err error) {\n\tm, err := metainfo.ParseMagnetV2Uri(uri)\n\tif err != nil {\n\t\treturn\n\t}\n\tspec = &TorrentSpec{\n\t\tTrackers:    [][]string{m.Trackers},\n\t\tDisplayName: m.DisplayName,\n\t\tInfoHash:    m.InfoHash.UnwrapOrZeroValue(),\n\t\tInfoHashV2:  m.V2InfoHash,\n\t\tWebseeds:    m.Params[\"ws\"],\n\t\tSources:     append(m.Params[\"xs\"], m.Params[\"as\"]...),\n\t\tPeerAddrs:   m.Params[\"x.pe\"], // BEP 9\n\t\t// TODO: What's the parameter for DHT nodes?\n\t}\n\treturn\n}\n\n// The error will be from unmarshalling the info bytes. The TorrentSpec is still filled out as much\n// as possible in this case.\nfunc TorrentSpecFromMetaInfoErr(mi *metainfo.MetaInfo) (*TorrentSpec, error) {\n\tinfo, err := mi.UnmarshalInfo()\n\tif err != nil {\n\t\terr = fmt.Errorf(\"unmarshalling info: %w\", err)\n\t}\n\tvar v1Ih metainfo.Hash\n\tif info.HasV1() {\n\t\tv1Ih = mi.HashInfoBytes()\n\t}\n\tvar v2Infohash g.Option[infohash_v2.T]\n\tif info.HasV2() {\n\t\tv2Infohash.Set(infohash_v2.HashBytes(mi.InfoBytes))\n\t}\n\n\treturn &TorrentSpec{\n\t\tTrackers:    mi.UpvertedAnnounceList(),\n\t\tInfoHash:    v1Ih,\n\t\tInfoHashV2:  v2Infohash,\n\t\tPieceLayers: mi.PieceLayers,\n\t\tInfoBytes:   mi.InfoBytes,\n\t\tDisplayName: info.BestName(),\n\t\tWebseeds:    mi.UrlList,\n\t\tDhtNodes: func() (ret []string) {\n\t\t\tret = make([]string, 0, len(mi.Nodes))\n\t\t\tfor _, node := range mi.Nodes {\n\t\t\t\tret = append(ret, string(node))\n\t\t\t}\n\t\t\treturn\n\t\t}(),\n\t}, err\n}\n\n// Panics if there was anything missing from the metainfo.\nfunc TorrentSpecFromMetaInfo(mi *metainfo.MetaInfo) *TorrentSpec {\n\tts, err := TorrentSpecFromMetaInfoErr(mi)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn ts\n}\n"
        },
        {
          "name": "stats.go",
          "type": "blob",
          "size": 0.162109375,
          "content": "package torrent\n\nimport (\n\t\"io\"\n\n\t\"github.com/davecgh/go-spew/spew\"\n)\n\nfunc dumpStats[T any](w io.Writer, stats T) {\n\tspew.NewDefaultConfig()\n\tspew.Fdump(w, stats)\n}\n"
        },
        {
          "name": "storage",
          "type": "tree",
          "content": null
        },
        {
          "name": "string-addr.go",
          "type": "blob",
          "size": 0.275390625,
          "content": "package torrent\n\nimport \"net\"\n\n// This adds a net.Addr interface to a string address that has no presumed Network.\ntype StringAddr string\n\nvar _ net.Addr = StringAddr(\"\")\n\nfunc (StringAddr) Network() string   { return \"\" }\nfunc (me StringAddr) String() string { return string(me) }\n"
        },
        {
          "name": "struct_test.go",
          "type": "blob",
          "size": 0.2392578125,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\t\"unsafe\"\n)\n\nfunc TestStructSizes(t *testing.T) {\n\tt.Log(\"[]*File\", unsafe.Sizeof([]*File(nil)))\n\tt.Log(\"Piece\", unsafe.Sizeof(Piece{}))\n\tt.Log(\"map[*peer]struct{}\", unsafe.Sizeof(map[*Peer]struct{}(nil)))\n}\n"
        },
        {
          "name": "t.go",
          "type": "blob",
          "size": 7.4267578125,
          "content": "package torrent\n\nimport (\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/anacrolix/chansync/events\"\n\t\"github.com/anacrolix/missinggo/v2/pubsub\"\n\t\"github.com/anacrolix/sync\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\n// The Torrent's infohash. This is fixed and cannot change. It uniquely identifies a torrent.\nfunc (t *Torrent) InfoHash() metainfo.Hash {\n\treturn *t.canonicalShortInfohash()\n}\n\n// Returns a channel that is closed when the info (.Info()) for the torrent has become available.\nfunc (t *Torrent) GotInfo() events.Done {\n\treturn t.gotMetainfoC\n}\n\n// Returns the metainfo info dictionary, or nil if it's not yet available.\nfunc (t *Torrent) Info() (info *metainfo.Info) {\n\tt.nameMu.RLock()\n\tinfo = t.info\n\tt.nameMu.RUnlock()\n\treturn\n}\n\n// Returns a Reader bound to the torrent's data. All read calls block until the data requested is\n// actually available. Note that you probably want to ensure the Torrent Info is available first.\nfunc (t *Torrent) NewReader() Reader {\n\treturn t.newReader(0, t.length())\n}\n\nfunc (t *Torrent) newReader(offset, length int64) Reader {\n\tr := reader{\n\t\tmu:     t.cl.locker(),\n\t\tt:      t,\n\t\toffset: offset,\n\t\tlength: length,\n\t}\n\tr.readaheadFunc = defaultReadaheadFunc\n\tt.addReader(&r)\n\treturn &r\n}\n\ntype PieceStateRuns []PieceStateRun\n\nfunc (me PieceStateRuns) String() (s string) {\n\tif len(me) > 0 {\n\t\tvar sb strings.Builder\n\t\tsb.WriteString(me[0].String())\n\t\tfor i := 1; i < len(me); i += 1 {\n\t\t\tsb.WriteByte(' ')\n\t\t\tsb.WriteString(me[i].String())\n\t\t}\n\t\treturn sb.String()\n\t}\n\treturn\n}\n\n// Returns the state of pieces of the torrent. They are grouped into runs of same state. The sum of\n// the state run-lengths is the number of pieces in the torrent.\nfunc (t *Torrent) PieceStateRuns() (runs PieceStateRuns) {\n\tt.cl.rLock()\n\truns = t.pieceStateRuns()\n\tt.cl.rUnlock()\n\treturn\n}\n\nfunc (t *Torrent) PieceState(piece pieceIndex) (ps PieceState) {\n\tt.cl.rLock()\n\tps = t.pieceState(piece)\n\tt.cl.rUnlock()\n\treturn\n}\n\n// The number of pieces in the torrent. This requires that the info has been\n// obtained first.\nfunc (t *Torrent) NumPieces() pieceIndex {\n\treturn t.numPieces()\n}\n\n// Get missing bytes count for specific piece.\nfunc (t *Torrent) PieceBytesMissing(piece int) int64 {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\n\treturn int64(t.pieces[piece].bytesLeft())\n}\n\n// Drop the torrent from the client, and close it. It's always safe to do\n// this. No data corruption can, or should occur to either the torrent's data,\n// or connected peers.\nfunc (t *Torrent) Drop() {\n\tvar wg sync.WaitGroup\n\tdefer wg.Wait()\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\terr := t.cl.dropTorrent(t, &wg)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// Number of bytes of the entire torrent we have completed. This is the sum of\n// completed pieces, and dirtied chunks of incomplete pieces. Do not use this\n// for download rate, as it can go down when pieces are lost or fail checks.\n// Sample Torrent.Stats.DataBytesRead for actual file data download rate.\nfunc (t *Torrent) BytesCompleted() int64 {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\treturn t.bytesCompleted()\n}\n\n// The subscription emits as (int) the index of pieces as their state changes.\n// A state change is when the PieceState for a piece alters in value.\nfunc (t *Torrent) SubscribePieceStateChanges() *pubsub.Subscription[PieceStateChange] {\n\treturn t.pieceStateChanges.Subscribe()\n}\n\n// Returns true if the torrent is currently being seeded. This occurs when the\n// client is willing to upload without wanting anything in return.\nfunc (t *Torrent) Seeding() (ret bool) {\n\tt.cl.rLock()\n\tret = t.seeding()\n\tt.cl.rUnlock()\n\treturn\n}\n\n// Clobbers the torrent display name if metainfo is unavailable.\n// The display name is used as the torrent name while the metainfo is unavailable.\nfunc (t *Torrent) SetDisplayName(dn string) {\n\tt.nameMu.Lock()\n\tif !t.haveInfo() {\n\t\tt.displayName = dn\n\t}\n\tt.nameMu.Unlock()\n}\n\n// The current working name for the torrent. Either the name in the info dict,\n// or a display name given such as by the dn value in a magnet link, or \"\".\nfunc (t *Torrent) Name() string {\n\treturn t.name()\n}\n\n// The completed length of all the torrent data, in all its files. This is\n// derived from the torrent info, when it is available.\nfunc (t *Torrent) Length() int64 {\n\treturn t._length.Value\n}\n\n// Returns a run-time generated metainfo for the torrent that includes the\n// info bytes and announce-list as currently known to the client.\nfunc (t *Torrent) Metainfo() metainfo.MetaInfo {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\treturn t.newMetaInfo()\n}\n\nfunc (t *Torrent) addReader(r *reader) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tif t.readers == nil {\n\t\tt.readers = make(map[*reader]struct{})\n\t}\n\tt.readers[r] = struct{}{}\n\tr.posChanged()\n}\n\nfunc (t *Torrent) deleteReader(r *reader) {\n\tdelete(t.readers, r)\n\tt.readersChanged()\n}\n\n// Raise the priorities of pieces in the range [begin, end) to at least Normal\n// priority. Piece indexes are not the same as bytes. Requires that the info\n// has been obtained, see Torrent.Info and Torrent.GotInfo.\nfunc (t *Torrent) DownloadPieces(begin, end pieceIndex) {\n\tt.cl.lock()\n\tt.downloadPiecesLocked(begin, end)\n\tt.cl.unlock()\n}\n\nfunc (t *Torrent) downloadPiecesLocked(begin, end pieceIndex) {\n\tfor i := begin; i < end; i++ {\n\t\tif t.pieces[i].priority.Raise(PiecePriorityNormal) {\n\t\t\tt.updatePiecePriority(i, \"Torrent.DownloadPieces\")\n\t\t}\n\t}\n}\n\nfunc (t *Torrent) CancelPieces(begin, end pieceIndex) {\n\tt.cl.lock()\n\tt.cancelPiecesLocked(begin, end, \"Torrent.CancelPieces\")\n\tt.cl.unlock()\n}\n\nfunc (t *Torrent) cancelPiecesLocked(begin, end pieceIndex, reason updateRequestReason) {\n\tfor i := begin; i < end; i++ {\n\t\tp := &t.pieces[i]\n\t\tif p.priority == PiecePriorityNone {\n\t\t\tcontinue\n\t\t}\n\t\tp.priority = PiecePriorityNone\n\t\tt.updatePiecePriority(i, reason)\n\t}\n}\n\nfunc (t *Torrent) initFiles() {\n\tinfo := t.info\n\tvar offset int64\n\tt.files = new([]*File)\n\tfor _, fi := range t.info.UpvertedFiles() {\n\t\t*t.files = append(*t.files, &File{\n\t\t\tt,\n\t\t\tstrings.Join(append([]string{info.BestName()}, fi.BestPath()...), \"/\"),\n\t\t\toffset,\n\t\t\tfi.Length,\n\t\t\tfi,\n\t\t\tfi.DisplayPath(info),\n\t\t\tPiecePriorityNone,\n\t\t\tfi.PiecesRoot,\n\t\t})\n\t\toffset += fi.Length\n\t\tif info.FilesArePieceAligned() {\n\t\t\toffset = (offset + info.PieceLength - 1) / info.PieceLength * info.PieceLength\n\t\t}\n\t}\n}\n\n// Returns handles to the files in the torrent. This requires that the Info is\n// available first.\nfunc (t *Torrent) Files() []*File {\n\treturn *t.files\n}\n\nfunc (t *Torrent) AddPeers(pp []PeerInfo) (n int) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tn = t.addPeers(pp)\n\treturn\n}\n\n// Marks the entire torrent for download. Requires the info first, see\n// GotInfo. Sets piece priorities for historical reasons.\nfunc (t *Torrent) DownloadAll() {\n\tt.DownloadPieces(0, t.numPieces())\n}\n\nfunc (t *Torrent) String() string {\n\ts := t.name()\n\tif s == \"\" {\n\t\treturn t.canonicalShortInfohash().HexString()\n\t} else {\n\t\treturn strconv.Quote(s)\n\t}\n}\n\nfunc (t *Torrent) AddTrackers(announceList [][]string) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.addTrackers(announceList)\n}\n\nfunc (t *Torrent) ModifyTrackers(announceList [][]string) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.modifyTrackers(announceList)\n}\n\nfunc (t *Torrent) Piece(i pieceIndex) *Piece {\n\treturn t.piece(i)\n}\n\nfunc (t *Torrent) PeerConns() []*PeerConn {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\tret := make([]*PeerConn, 0, len(t.conns))\n\tfor c := range t.conns {\n\t\tret = append(ret, c)\n\t}\n\treturn ret\n}\n\nfunc (t *Torrent) WebseedPeerConns() []*Peer {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\tret := make([]*Peer, 0, len(t.conns))\n\tfor _, c := range t.webSeeds {\n\t\tret = append(ret, c)\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "test_test.go",
          "type": "blob",
          "size": 0.3564453125,
          "content": "package torrent\n\n// Helpers for testing\n\nimport (\n\t\"testing\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n)\n\nfunc newTestingClient(t testing.TB) *Client {\n\tcl := new(Client)\n\tcl.init(TestingConfig(t))\n\tt.Cleanup(func() {\n\t\tcl.Close()\n\t})\n\tcl.initLogger()\n\treturn cl\n}\n\nfunc (cl *Client) newTorrentForTesting() *Torrent {\n\treturn cl.newTorrent(metainfo.Hash{1}, nil)\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "testing.go",
          "type": "blob",
          "size": 1,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/anacrolix/log\"\n\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n)\n\nfunc TestingConfig(t testing.TB) *ClientConfig {\n\tcfg := NewDefaultClientConfig()\n\tcfg.ListenHost = LoopbackListenHost\n\tcfg.NoDHT = true\n\tcfg.DataDir = t.TempDir()\n\tcfg.DisableTrackers = true\n\tcfg.NoDefaultPortForwarding = true\n\tcfg.DisableAcceptRateLimiting = true\n\tcfg.ListenPort = 0\n\tcfg.KeepAliveTimeout = time.Millisecond\n\tcfg.MinPeerExtensions.SetBit(pp.ExtensionBitFast, true)\n\tcfg.Logger = log.Default.WithNames(t.Name())\n\t// 2 would suffice for the greeting test, but 5 is needed for a few other tests. This should be\n\t// something slightly higher than the usual chunk size, so it gets tickled in some tests.\n\tcfg.MaxAllocPeerRequestDataPerConn = 5\n\t//cfg.Debug = true\n\t//cfg.Logger = cfg.Logger.WithText(func(m log.Msg) string {\n\t//\tt := m.Text()\n\t//\tm.Values(func(i interface{}) bool {\n\t//\t\tt += fmt.Sprintf(\"\\n%[1]T: %[1]v\", i)\n\t//\t\treturn true\n\t//\t})\n\t//\treturn t\n\t//})\n\treturn cfg\n}\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "torrent-piece-request-order.go",
          "type": "blob",
          "size": 1.740234375,
          "content": "package torrent\n\nimport (\n\tg \"github.com/anacrolix/generics\"\n\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n)\n\nfunc (t *Torrent) updatePieceRequestOrderPiece(pieceIndex int) {\n\tif t.storage == nil {\n\t\treturn\n\t}\n\tpro, ok := t.cl.pieceRequestOrder[t.clientPieceRequestOrderKey()]\n\tif !ok {\n\t\treturn\n\t}\n\tkey := t.pieceRequestOrderKey(pieceIndex)\n\tif t.hasStorageCap() {\n\t\tpro.Update(key, t.requestStrategyPieceOrderState(pieceIndex))\n\t\treturn\n\t}\n\tpending := !t.ignorePieceForRequests(pieceIndex)\n\tif pending {\n\t\tpro.Add(key, t.requestStrategyPieceOrderState(pieceIndex))\n\t} else {\n\t\tpro.Delete(key)\n\t}\n}\n\nfunc (t *Torrent) clientPieceRequestOrderKey() interface{} {\n\tif t.storage.Capacity == nil {\n\t\treturn t\n\t}\n\treturn t.storage.Capacity\n}\n\nfunc (t *Torrent) deletePieceRequestOrder() {\n\tif t.storage == nil {\n\t\treturn\n\t}\n\tcpro := t.cl.pieceRequestOrder\n\tkey := t.clientPieceRequestOrderKey()\n\tpro := cpro[key]\n\tfor i := 0; i < t.numPieces(); i++ {\n\t\tpro.Delete(t.pieceRequestOrderKey(i))\n\t}\n\tif pro.Len() == 0 {\n\t\tdelete(cpro, key)\n\t}\n}\n\nfunc (t *Torrent) initPieceRequestOrder() {\n\tif t.storage == nil {\n\t\treturn\n\t}\n\tg.MakeMapIfNil(&t.cl.pieceRequestOrder)\n\tkey := t.clientPieceRequestOrderKey()\n\tcpro := t.cl.pieceRequestOrder\n\tif cpro[key] == nil {\n\t\tcpro[key] = request_strategy.NewPieceOrder(request_strategy.NewAjwernerBtree(), t.numPieces())\n\t}\n}\n\nfunc (t *Torrent) addRequestOrderPiece(i int) {\n\tif t.storage == nil {\n\t\treturn\n\t}\n\tpro := t.getPieceRequestOrder()\n\tkey := t.pieceRequestOrderKey(i)\n\tif t.hasStorageCap() || !t.ignorePieceForRequests(i) {\n\t\tpro.Add(key, t.requestStrategyPieceOrderState(i))\n\t}\n}\n\nfunc (t *Torrent) getPieceRequestOrder() *request_strategy.PieceRequestOrder {\n\treturn t.cl.pieceRequestOrder[t.clientPieceRequestOrderKey()]\n}\n"
        },
        {
          "name": "torrent-stats.go",
          "type": "blob",
          "size": 0.49609375,
          "content": "package torrent\n\n// Due to ConnStats, may require special alignment on some platforms. See\n// https://github.com/anacrolix/torrent/issues/383.\ntype TorrentStats struct {\n\t// Aggregates stats over all connections past and present. Some values may not have much meaning\n\t// in the aggregate context.\n\tConnStats\n\n\t// Ordered by expected descending quantities (if all is well).\n\tTotalPeers       int\n\tPendingPeers     int\n\tActivePeers      int\n\tConnectedSeeders int\n\tHalfOpenPeers    int\n\tPiecesComplete   int\n}\n"
        },
        {
          "name": "torrent.go",
          "type": "blob",
          "size": 85.2392578125,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"container/heap\"\n\t\"context\"\n\t\"crypto/sha1\"\n\t\"errors\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"iter\"\n\t\"maps\"\n\t\"math/rand\"\n\t\"net/netip\"\n\t\"net/url\"\n\t\"slices\"\n\t\"strings\"\n\t\"text/tabwriter\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/anacrolix/chansync\"\n\t\"github.com/anacrolix/chansync/events\"\n\t\"github.com/anacrolix/dht/v2\"\n\t. \"github.com/anacrolix/generics\"\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\t\"github.com/anacrolix/missinggo/v2/pubsub\"\n\t\"github.com/anacrolix/multiless\"\n\t\"github.com/anacrolix/sync\"\n\t\"github.com/pion/webrtc/v4\"\n\t\"golang.org/x/sync/errgroup\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/internal/check\"\n\t\"github.com/anacrolix/torrent/internal/nestedmaps\"\n\t\"github.com/anacrolix/torrent/merkle\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\tutHolepunch \"github.com/anacrolix/torrent/peer_protocol/ut-holepunch\"\n\trequest_strategy \"github.com/anacrolix/torrent/request-strategy\"\n\t\"github.com/anacrolix/torrent/storage\"\n\t\"github.com/anacrolix/torrent/tracker\"\n\ttypedRoaring \"github.com/anacrolix/torrent/typed-roaring\"\n\t\"github.com/anacrolix/torrent/types/infohash\"\n\tinfohash_v2 \"github.com/anacrolix/torrent/types/infohash-v2\"\n\t\"github.com/anacrolix/torrent/webseed\"\n\t\"github.com/anacrolix/torrent/webtorrent\"\n)\n\n// Maintains state of torrent within a Client. Many methods should not be called before the info is\n// available, see .Info and .GotInfo.\ntype Torrent struct {\n\t// Torrent-level aggregate statistics. First in struct to ensure 64-bit\n\t// alignment. See #262.\n\tstats  ConnStats\n\tcl     *Client\n\tlogger log.Logger\n\n\tnetworkingEnabled      chansync.Flag\n\tdataDownloadDisallowed chansync.Flag\n\tdataUploadDisallowed   bool\n\tuserOnWriteChunkErr    func(error)\n\n\tclosed  chansync.SetOnce\n\tonClose []func()\n\n\tinfoHash   g.Option[metainfo.Hash]\n\tinfoHashV2 g.Option[infohash_v2.T]\n\n\tpieces []Piece\n\n\t// The order pieces are requested if there's no stronger reason like availability or priority.\n\tpieceRequestOrder []int\n\t// Values are the piece indices that changed.\n\tpieceStateChanges pubsub.PubSub[PieceStateChange]\n\t// The size of chunks to request from peers over the wire. This is\n\t// normally 16KiB by convention these days.\n\tchunkSize pp.Integer\n\tchunkPool sync.Pool\n\t// Total length of the torrent in bytes. Stored because it's not O(1) to\n\t// get this from the info dict.\n\t_length Option[int64]\n\n\t// The storage to open when the info dict becomes available.\n\tstorageOpener *storage.Client\n\t// Storage for torrent data.\n\tstorage *storage.Torrent\n\t// Read-locked for using storage, and write-locked for Closing.\n\tstorageLock sync.RWMutex\n\n\t// TODO: Only announce stuff is used?\n\tmetainfo metainfo.MetaInfo\n\n\t// The info dict. nil if we don't have it (yet).\n\tinfo  *metainfo.Info\n\tfiles *[]*File\n\n\t_chunksPerRegularPiece chunkIndexType\n\n\twebSeeds map[string]*Peer\n\t// Active peer connections, running message stream loops. TODO: Make this\n\t// open (not-closed) connections only.\n\tconns               map[*PeerConn]struct{}\n\tmaxEstablishedConns int\n\t// Set of addrs to which we're attempting to connect. Connections are\n\t// half-open until all handshakes are completed.\n\thalfOpen map[string]map[outgoingConnAttemptKey]*PeerInfo\n\n\t// Reserve of peers to connect to. A peer can be both here and in the\n\t// active connections if were told about the peer after connecting with\n\t// them. That encourages us to reconnect to peers that are well known in\n\t// the swarm.\n\tpeers prioritizedPeers\n\t// Whether we want to know more peers.\n\twantPeersEvent missinggo.Event\n\t// An announcer for each tracker URL.\n\ttrackerAnnouncers map[torrentTrackerAnnouncerKey]torrentTrackerAnnouncer\n\t// How many times we've initiated a DHT announce. TODO: Move into stats.\n\tnumDHTAnnounces int\n\n\t// Name used if the info name isn't available. Should be cleared when the\n\t// Info does become available.\n\tnameMu      sync.RWMutex\n\tdisplayName string\n\n\t// The bencoded bytes of the info dict. This is actively manipulated if\n\t// the info bytes aren't initially available, and we try to fetch them\n\t// from peers.\n\tmetadataBytes []byte\n\t// Each element corresponds to the 16KiB metadata pieces. If true, we have\n\t// received that piece.\n\tmetadataCompletedChunks []bool\n\tmetadataChanged         sync.Cond\n\n\t// Closed when .Info is obtained.\n\tgotMetainfoC chan struct{}\n\n\treaders                map[*reader]struct{}\n\t_readerNowPieces       bitmap.Bitmap\n\t_readerReadaheadPieces bitmap.Bitmap\n\n\t// A cache of pieces we need to get. Calculated from various piece and file priorities and\n\t// completion states elsewhere. Includes piece data and piece v2 hashes.\n\t_pendingPieces roaring.Bitmap\n\t// A cache of completed piece indices.\n\t_completedPieces roaring.Bitmap\n\t// Pieces that need to be hashed.\n\tpiecesQueuedForHash       bitmap.Bitmap\n\tactivePieceHashes         int\n\tinitialPieceCheckDisabled bool\n\n\tconnsWithAllPieces map[*Peer]struct{}\n\n\trequestState map[RequestIndex]requestState\n\t// Chunks we've written to since the corresponding piece was last checked.\n\tdirtyChunks typedRoaring.Bitmap[RequestIndex]\n\n\tpex pexState\n\n\t// Is On when all pieces are complete.\n\tcomplete chansync.Flag\n\n\t// Torrent sources in use keyed by the source string.\n\tactiveSources sync.Map\n\tsourcesLogger log.Logger\n\n\tsmartBanCache smartBanCache\n\n\t// Large allocations reused between request state updates.\n\trequestPieceStates []g.Option[request_strategy.PieceRequestOrderState]\n\trequestIndexes     []RequestIndex\n\n\tdisableTriggers bool\n}\n\ntype torrentTrackerAnnouncerKey struct {\n\tshortInfohash [20]byte\n\turl           string\n}\n\ntype outgoingConnAttemptKey = *PeerInfo\n\nfunc (t *Torrent) length() int64 {\n\treturn t._length.Value\n}\n\nfunc (t *Torrent) selectivePieceAvailabilityFromPeers(i pieceIndex) (count int) {\n\t// This could be done with roaring.BitSliceIndexing.\n\tt.iterPeers(func(peer *Peer) {\n\t\tif _, ok := t.connsWithAllPieces[peer]; ok {\n\t\t\treturn\n\t\t}\n\t\tif peer.peerHasPiece(i) {\n\t\t\tcount++\n\t\t}\n\t})\n\treturn\n}\n\nfunc (t *Torrent) decPieceAvailability(i pieceIndex) {\n\tif !t.haveInfo() {\n\t\treturn\n\t}\n\tp := t.piece(i)\n\tif p.relativeAvailability <= 0 {\n\t\tpanic(p.relativeAvailability)\n\t}\n\tp.relativeAvailability--\n\tt.updatePieceRequestOrderPiece(i)\n}\n\nfunc (t *Torrent) incPieceAvailability(i pieceIndex) {\n\t// If we don't the info, this should be reconciled when we do.\n\tif t.haveInfo() {\n\t\tp := t.piece(i)\n\t\tp.relativeAvailability++\n\t\tt.updatePieceRequestOrderPiece(i)\n\t}\n}\n\nfunc (t *Torrent) readerNowPieces() bitmap.Bitmap {\n\treturn t._readerNowPieces\n}\n\nfunc (t *Torrent) readerReadaheadPieces() bitmap.Bitmap {\n\treturn t._readerReadaheadPieces\n}\n\nfunc (t *Torrent) ignorePieceForRequests(i pieceIndex) bool {\n\treturn t.piece(i).ignoreForRequests()\n}\n\n// Returns a channel that is closed when the Torrent is closed.\nfunc (t *Torrent) Closed() events.Done {\n\treturn t.closed.Done()\n}\n\n// KnownSwarm returns the known subset of the peers in the Torrent's swarm, including active,\n// pending, and half-open peers.\nfunc (t *Torrent) KnownSwarm() (ks []PeerInfo) {\n\t// Add pending peers to the list\n\tt.peers.Each(func(peer PeerInfo) {\n\t\tks = append(ks, peer)\n\t})\n\n\t// Add half-open peers to the list\n\tfor _, attempts := range t.halfOpen {\n\t\tfor _, peer := range attempts {\n\t\t\tks = append(ks, *peer)\n\t\t}\n\t}\n\n\t// Add active peers to the list\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\tfor conn := range t.conns {\n\t\tks = append(ks, PeerInfo{\n\t\t\tId:     conn.PeerID,\n\t\t\tAddr:   conn.RemoteAddr,\n\t\t\tSource: conn.Discovery,\n\t\t\t// > If the connection is encrypted, that's certainly enough to set SupportsEncryption.\n\t\t\t// > But if we're not connected to them with an encrypted connection, I couldn't say\n\t\t\t// > what's appropriate. We can carry forward the SupportsEncryption value as we\n\t\t\t// > received it from trackers/DHT/PEX, or just use the encryption state for the\n\t\t\t// > connection. It's probably easiest to do the latter for now.\n\t\t\t// https://github.com/anacrolix/torrent/pull/188\n\t\t\tSupportsEncryption: conn.headerEncrypted,\n\t\t})\n\t}\n\n\treturn\n}\n\nfunc (t *Torrent) setChunkSize(size pp.Integer) {\n\tt.chunkSize = size\n\tt.chunkPool = sync.Pool{\n\t\tNew: func() interface{} {\n\t\t\tb := make([]byte, size)\n\t\t\treturn &b\n\t\t},\n\t}\n}\n\nfunc (t *Torrent) pieceComplete(piece pieceIndex) bool {\n\treturn t._completedPieces.Contains(bitmap.BitIndex(piece))\n}\n\nfunc (t *Torrent) pieceCompleteUncached(piece pieceIndex) storage.Completion {\n\tif t.storage == nil {\n\t\treturn storage.Completion{Complete: false, Ok: true}\n\t}\n\treturn t.pieces[piece].Storage().Completion()\n}\n\n// There's a connection to that address already.\nfunc (t *Torrent) addrActive(addr string) bool {\n\tif _, ok := t.halfOpen[addr]; ok {\n\t\treturn true\n\t}\n\tfor c := range t.conns {\n\t\tra := c.RemoteAddr\n\t\tif ra.String() == addr {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (t *Torrent) appendUnclosedConns(ret []*PeerConn) []*PeerConn {\n\treturn t.appendConns(ret, func(conn *PeerConn) bool {\n\t\treturn !conn.closed.IsSet()\n\t})\n}\n\nfunc (t *Torrent) appendConns(ret []*PeerConn, f func(*PeerConn) bool) []*PeerConn {\n\tfor c := range t.conns {\n\t\tif f(c) {\n\t\t\tret = append(ret, c)\n\t\t}\n\t}\n\treturn ret\n}\n\nfunc (t *Torrent) addPeer(p PeerInfo) (added bool) {\n\tcl := t.cl\n\ttorrent.Add(fmt.Sprintf(\"peers added by source %q\", p.Source), 1)\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif ipAddr, ok := tryIpPortFromNetAddr(p.Addr); ok {\n\t\tif cl.badPeerIPPort(ipAddr.IP, ipAddr.Port) {\n\t\t\ttorrent.Add(\"peers not added because of bad addr\", 1)\n\t\t\t// cl.logger.Printf(\"peers not added because of bad addr: %v\", p)\n\t\t\treturn false\n\t\t}\n\t}\n\tif replaced, ok := t.peers.AddReturningReplacedPeer(p); ok {\n\t\ttorrent.Add(\"peers replaced\", 1)\n\t\tif !replaced.equal(p) {\n\t\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\"added %v replacing %v\", p, replaced)\n\t\t\tadded = true\n\t\t}\n\t} else {\n\t\tadded = true\n\t}\n\tt.openNewConns()\n\tfor t.peers.Len() > cl.config.TorrentPeersHighWater {\n\t\t_, ok := t.peers.DeleteMin()\n\t\tif ok {\n\t\t\ttorrent.Add(\"excess reserve peers discarded\", 1)\n\t\t}\n\t}\n\treturn\n}\n\nfunc (t *Torrent) invalidateMetadata() {\n\tfor i := 0; i < len(t.metadataCompletedChunks); i++ {\n\t\tt.metadataCompletedChunks[i] = false\n\t}\n\tt.nameMu.Lock()\n\tt.info = nil\n\tt.nameMu.Unlock()\n}\n\nfunc (t *Torrent) saveMetadataPiece(index int, data []byte) {\n\tif t.haveInfo() {\n\t\treturn\n\t}\n\tif index >= len(t.metadataCompletedChunks) {\n\t\tt.logger.Printf(\"%s: ignoring metadata piece %d\", t, index)\n\t\treturn\n\t}\n\tcopy(t.metadataBytes[(1<<14)*index:], data)\n\tt.metadataCompletedChunks[index] = true\n}\n\nfunc (t *Torrent) metadataPieceCount() int {\n\treturn (len(t.metadataBytes) + (1 << 14) - 1) / (1 << 14)\n}\n\nfunc (t *Torrent) haveMetadataPiece(piece int) bool {\n\tif t.haveInfo() {\n\t\treturn (1<<14)*piece < len(t.metadataBytes)\n\t} else {\n\t\treturn piece < len(t.metadataCompletedChunks) && t.metadataCompletedChunks[piece]\n\t}\n}\n\nfunc (t *Torrent) metadataSize() int {\n\treturn len(t.metadataBytes)\n}\n\nfunc (t *Torrent) makePieces() {\n\tt.pieces = make([]Piece, t.info.NumPieces())\n\tfor i := range t.pieces {\n\t\tpiece := &t.pieces[i]\n\t\tpiece.t = t\n\t\tpiece.index = i\n\t\tpiece.noPendingWrites.L = &piece.pendingWritesMutex\n\t\tif t.info.HasV1() {\n\t\t\tpiece.hash = (*metainfo.Hash)(unsafe.Pointer(\n\t\t\t\tunsafe.SliceData(t.info.Pieces[i*sha1.Size : (i+1)*sha1.Size])))\n\t\t}\n\t\tfiles := *t.files\n\t\tbeginFile := pieceFirstFileIndex(piece.torrentBeginOffset(), files)\n\t\tendFile := pieceEndFileIndex(piece.torrentEndOffset(), files)\n\t\tpiece.files = files[beginFile:endFile]\n\t}\n}\n\nfunc (t *Torrent) addPieceLayersLocked(layers map[string]string) (errs []error) {\n\tif layers == nil {\n\t\treturn\n\t}\nfiles:\n\tfor _, f := range *t.files {\n\t\tif f.numPieces() <= 1 {\n\t\t\tcontinue\n\t\t}\n\t\tif !f.piecesRoot.Ok {\n\t\t\terr := fmt.Errorf(\"no piece root set for file %v\", f)\n\t\t\terrs = append(errs, err)\n\t\t\tcontinue files\n\t\t}\n\t\tcompactLayer, ok := layers[string(f.piecesRoot.Value[:])]\n\t\tvar hashes [][32]byte\n\t\tif ok {\n\t\t\tvar err error\n\t\t\thashes, err = merkle.CompactLayerToSliceHashes(compactLayer)\n\t\t\tif err != nil {\n\t\t\t\terr = fmt.Errorf(\"bad piece layers for file %q: %w\", f, err)\n\t\t\t\terrs = append(errs, err)\n\t\t\t\tcontinue files\n\t\t\t}\n\t\t} else {\n\t\t\tif f.length > t.info.PieceLength {\n\t\t\t\t// BEP 52 is pretty strongly worded about this, even though we should be able to\n\t\t\t\t// recover: If a v2 torrent is added by magnet link or infohash, we need to fetch\n\t\t\t\t// piece layers ourselves anyway, and that's how we can recover from this.\n\t\t\t\tt.logger.Levelf(log.Warning, \"no piece layers for file %q\", f)\n\t\t\t}\n\t\t\tcontinue files\n\t\t}\n\t\tif len(hashes) != f.numPieces() {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\tfmt.Errorf(\"file %q: got %v hashes expected %v\", f, len(hashes), f.numPieces()),\n\t\t\t)\n\t\t\tcontinue files\n\t\t}\n\t\troot := merkle.RootWithPadHash(hashes, metainfo.HashForPiecePad(t.info.PieceLength))\n\t\tif root != f.piecesRoot.Value {\n\t\t\terrs = append(errs, fmt.Errorf(\"%v: expected hash %x got %x\", f, f.piecesRoot.Value, root))\n\t\t\tcontinue files\n\t\t}\n\t\tfor i := range f.numPieces() {\n\t\t\tpi := f.BeginPieceIndex() + i\n\t\t\tp := t.piece(pi)\n\t\t\tp.setV2Hash(hashes[i])\n\t\t}\n\t}\n\treturn\n}\n\nfunc (t *Torrent) AddPieceLayers(layers map[string]string) (errs []error) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\treturn t.addPieceLayersLocked(layers)\n}\n\n// Returns the index of the first file containing the piece. files must be\n// ordered by offset.\nfunc pieceFirstFileIndex(pieceOffset int64, files []*File) int {\n\tfor i, f := range files {\n\t\tif f.offset+f.length > pieceOffset {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn 0\n}\n\n// Returns the index after the last file containing the piece. files must be\n// ordered by offset.\nfunc pieceEndFileIndex(pieceEndOffset int64, files []*File) int {\n\tfor i, f := range files {\n\t\tif f.offset >= pieceEndOffset {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn len(files)\n}\n\nfunc (t *Torrent) cacheLength() {\n\tvar l int64\n\tfor _, f := range t.info.UpvertedFiles() {\n\t\tl += f.Length\n\t}\n\tt._length = Some(l)\n}\n\n// TODO: This shouldn't fail for storage reasons. Instead we should handle storage failure\n// separately.\nfunc (t *Torrent) setInfo(info *metainfo.Info) error {\n\tif err := validateInfo(info); err != nil {\n\t\treturn fmt.Errorf(\"bad info: %s\", err)\n\t}\n\tif t.storageOpener != nil {\n\t\tvar err error\n\t\tctx := log.ContextWithLogger(context.Background(), t.logger)\n\t\tt.storage, err = t.storageOpener.OpenTorrent(ctx, info, *t.canonicalShortInfohash())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error opening torrent storage: %s\", err)\n\t\t}\n\t}\n\tt.nameMu.Lock()\n\tt.info = info\n\tt.nameMu.Unlock()\n\tt._chunksPerRegularPiece = chunkIndexType(\n\t\t(pp.Integer(t.usualPieceSize()) + t.chunkSize - 1) / t.chunkSize)\n\tt.updateComplete()\n\tt.displayName = \"\" // Save a few bytes lol.\n\tt.initFiles()\n\tt.cacheLength()\n\tt.makePieces()\n\treturn nil\n}\n\nfunc (t *Torrent) pieceRequestOrderKey(i int) request_strategy.PieceRequestOrderKey {\n\treturn request_strategy.PieceRequestOrderKey{\n\t\tInfoHash: *t.canonicalShortInfohash(),\n\t\tIndex:    i,\n\t}\n}\n\n// This seems to be all the follow-up tasks after info is set, that can't fail.\nfunc (t *Torrent) onSetInfo() {\n\tt.pieceRequestOrder = rand.Perm(t.numPieces())\n\tt.initPieceRequestOrder()\n\tMakeSliceWithLength(&t.requestPieceStates, t.numPieces())\n\tfor i := range t.pieces {\n\t\tp := &t.pieces[i]\n\t\t// Need to add relativeAvailability before updating piece completion, as that may result in conns\n\t\t// being dropped.\n\t\tif p.relativeAvailability != 0 {\n\t\t\tpanic(p.relativeAvailability)\n\t\t}\n\t\tp.relativeAvailability = t.selectivePieceAvailabilityFromPeers(i)\n\t\tt.addRequestOrderPiece(i)\n\t\tt.updatePieceCompletion(i)\n\t\tt.queueInitialPieceCheck(i)\n\t}\n\tt.cl.event.Broadcast()\n\tclose(t.gotMetainfoC)\n\tt.updateWantPeersEvent()\n\tt.requestState = make(map[RequestIndex]requestState)\n\tt.tryCreateMorePieceHashers()\n\tt.iterPeers(func(p *Peer) {\n\t\tp.onGotInfo(t.info)\n\t\tp.updateRequests(\"onSetInfo\")\n\t})\n}\n\n// Checks the info bytes hash to expected values. Fills in any missing infohashes.\nfunc (t *Torrent) hashInfoBytes(b []byte, info *metainfo.Info) error {\n\tv1Hash := infohash.HashBytes(b)\n\tv2Hash := infohash_v2.HashBytes(b)\n\tcl := t.cl\n\tif t.infoHash.Ok && !t.infoHashV2.Ok {\n\t\tif v1Hash == t.infoHash.Value {\n\t\t\tif info.HasV2() {\n\t\t\t\tt.infoHashV2.Set(v2Hash)\n\t\t\t\tcl.torrentsByShortHash[*v2Hash.ToShort()] = t\n\t\t\t}\n\t\t} else if *v2Hash.ToShort() == t.infoHash.Value {\n\t\t\tif !info.HasV2() {\n\t\t\t\treturn errors.New(\"invalid v2 info\")\n\t\t\t}\n\t\t\tt.infoHashV2.Set(v2Hash)\n\t\t\tt.infoHash.SetNone()\n\t\t\tif info.HasV1() {\n\t\t\t\tcl.torrentsByShortHash[v1Hash] = t\n\t\t\t\tt.infoHash.Set(v1Hash)\n\t\t\t}\n\t\t}\n\t} else if t.infoHash.Ok && t.infoHashV2.Ok {\n\t\tif v1Hash != t.infoHash.Value {\n\t\t\treturn errors.New(\"incorrect v1 infohash\")\n\t\t}\n\t\tif v2Hash != t.infoHashV2.Value {\n\t\t\treturn errors.New(\"incorrect v2 infohash\")\n\t\t}\n\t} else if !t.infoHash.Ok && t.infoHashV2.Ok {\n\t\tif v2Hash != t.infoHashV2.Value {\n\t\t\treturn errors.New(\"incorrect v2 infohash\")\n\t\t}\n\t\tif info.HasV1() {\n\t\t\tt.infoHash.Set(v1Hash)\n\t\t\tcl.torrentsByShortHash[v1Hash] = t\n\t\t}\n\t} else {\n\t\tpanic(\"no expected infohashes\")\n\t}\n\treturn nil\n}\n\n// Called when metadata for a torrent becomes available.\nfunc (t *Torrent) setInfoBytesLocked(b []byte) (err error) {\n\tvar info metainfo.Info\n\terr = bencode.Unmarshal(b, &info)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"unmarshalling info bytes: %w\", err)\n\t\treturn\n\t}\n\terr = t.hashInfoBytes(b, &info)\n\tif err != nil {\n\t\treturn\n\t}\n\tt.metadataBytes = b\n\tt.metadataCompletedChunks = nil\n\tif t.info != nil {\n\t\treturn nil\n\t}\n\tif err := t.setInfo(&info); err != nil {\n\t\treturn err\n\t}\n\tt.onSetInfo()\n\treturn nil\n}\n\nfunc (t *Torrent) haveAllMetadataPieces() bool {\n\tif t.haveInfo() {\n\t\treturn true\n\t}\n\tif t.metadataCompletedChunks == nil {\n\t\treturn false\n\t}\n\tfor _, have := range t.metadataCompletedChunks {\n\t\tif !have {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// TODO: Propagate errors to disconnect peer.\nfunc (t *Torrent) setMetadataSize(size int) (err error) {\n\tif t.haveInfo() {\n\t\t// We already know the correct metadata size.\n\t\treturn\n\t}\n\tif uint32(size) > maxMetadataSize {\n\t\treturn log.WithLevel(log.Warning, errors.New(\"bad size\"))\n\t}\n\tif len(t.metadataBytes) == size {\n\t\treturn\n\t}\n\tt.metadataBytes = make([]byte, size)\n\tt.metadataCompletedChunks = make([]bool, (size+(1<<14)-1)/(1<<14))\n\tt.metadataChanged.Broadcast()\n\tfor c := range t.conns {\n\t\tc.requestPendingMetadata()\n\t}\n\treturn\n}\n\n// The current working name for the torrent. Either the name in the info dict,\n// or a display name given such as by the dn value in a magnet link, or \"\".\nfunc (t *Torrent) name() string {\n\tt.nameMu.RLock()\n\tdefer t.nameMu.RUnlock()\n\tif t.haveInfo() {\n\t\treturn t.info.BestName()\n\t}\n\tif t.displayName != \"\" {\n\t\treturn t.displayName\n\t}\n\treturn \"infohash:\" + t.canonicalShortInfohash().HexString()\n}\n\nfunc (t *Torrent) pieceState(index pieceIndex) (ret PieceState) {\n\tp := &t.pieces[index]\n\tret.Priority = p.effectivePriority()\n\tret.Completion = p.completion()\n\tret.QueuedForHash = p.queuedForHash()\n\tret.Hashing = p.hashing\n\tret.Checking = ret.QueuedForHash || ret.Hashing\n\tret.Marking = p.marking\n\tif !ret.Complete && t.piecePartiallyDownloaded(index) {\n\t\tret.Partial = true\n\t}\n\tif t.info.HasV2() && !p.hashV2.Ok && p.hasPieceLayer() {\n\t\tret.MissingPieceLayerHash = true\n\t}\n\treturn\n}\n\nfunc (t *Torrent) metadataPieceSize(piece int) int {\n\treturn metadataPieceSize(len(t.metadataBytes), piece)\n}\n\nfunc (t *Torrent) newMetadataExtensionMessage(c *PeerConn, msgType pp.ExtendedMetadataRequestMsgType, piece int, data []byte) pp.Message {\n\treturn pp.Message{\n\t\tType:       pp.Extended,\n\t\tExtendedID: c.PeerExtensionIDs[pp.ExtensionNameMetadata],\n\t\tExtendedPayload: append(bencode.MustMarshal(pp.ExtendedMetadataRequestMsg{\n\t\t\tPiece:     piece,\n\t\t\tTotalSize: len(t.metadataBytes),\n\t\t\tType:      msgType,\n\t\t}), data...),\n\t}\n}\n\ntype pieceAvailabilityRun struct {\n\tCount        pieceIndex\n\tAvailability int\n}\n\nfunc (me pieceAvailabilityRun) String() string {\n\treturn fmt.Sprintf(\"%v(%v)\", me.Count, me.Availability)\n}\n\nfunc (t *Torrent) pieceAvailabilityRuns() (ret []pieceAvailabilityRun) {\n\trle := missinggo.NewRunLengthEncoder(func(el interface{}, count uint64) {\n\t\tret = append(ret, pieceAvailabilityRun{Availability: el.(int), Count: int(count)})\n\t})\n\tfor i := range t.pieces {\n\t\trle.Append(t.pieces[i].availability(), 1)\n\t}\n\trle.Flush()\n\treturn\n}\n\nfunc (t *Torrent) pieceAvailabilityFrequencies() (freqs []int) {\n\tfreqs = make([]int, t.numActivePeers()+1)\n\tfor i := range t.pieces {\n\t\tfreqs[t.piece(i).availability()]++\n\t}\n\treturn\n}\n\nfunc (t *Torrent) pieceStateRuns() (ret PieceStateRuns) {\n\trle := missinggo.NewRunLengthEncoder(func(el interface{}, count uint64) {\n\t\tret = append(ret, PieceStateRun{\n\t\t\tPieceState: el.(PieceState),\n\t\t\tLength:     int(count),\n\t\t})\n\t})\n\tfor index := range t.pieces {\n\t\trle.Append(t.pieceState(index), 1)\n\t}\n\trle.Flush()\n\treturn\n}\n\n// Produces a small string representing a PieceStateRun.\nfunc (psr PieceStateRun) String() (ret string) {\n\tret = fmt.Sprintf(\"%d\", psr.Length)\n\tret += func() string {\n\t\tswitch psr.Priority {\n\t\tcase PiecePriorityNext:\n\t\t\treturn \"N\"\n\t\tcase PiecePriorityNormal:\n\t\t\treturn \".\"\n\t\tcase PiecePriorityReadahead:\n\t\t\treturn \"R\"\n\t\tcase PiecePriorityNow:\n\t\t\treturn \"!\"\n\t\tcase PiecePriorityHigh:\n\t\t\treturn \"H\"\n\t\tdefault:\n\t\t\treturn \"\"\n\t\t}\n\t}()\n\tif psr.Hashing {\n\t\tret += \"H\"\n\t}\n\tif psr.QueuedForHash {\n\t\tret += \"Q\"\n\t}\n\tif psr.Marking {\n\t\tret += \"M\"\n\t}\n\tif psr.Partial {\n\t\tret += \"P\"\n\t}\n\tif psr.Complete {\n\t\tret += \"C\"\n\t}\n\tif !psr.Ok {\n\t\tret += \"?\"\n\t}\n\tif psr.MissingPieceLayerHash {\n\t\tret += \"h\"\n\t}\n\treturn\n}\n\nfunc (t *Torrent) writeStatus(w io.Writer) {\n\tif t.infoHash.Ok {\n\t\tfmt.Fprintf(w, \"Infohash: %s\\n\", t.infoHash.Value.HexString())\n\t}\n\tif t.infoHashV2.Ok {\n\t\tfmt.Fprintf(w, \"Infohash v2: %s\\n\", t.infoHashV2.Value.HexString())\n\t}\n\tfmt.Fprintf(w, \"Metadata length: %d\\n\", t.metadataSize())\n\tif !t.haveInfo() {\n\t\tfmt.Fprintf(w, \"Metadata have: \")\n\t\tfor _, h := range t.metadataCompletedChunks {\n\t\t\tfmt.Fprintf(w, \"%c\", func() rune {\n\t\t\t\tif h {\n\t\t\t\t\treturn 'H'\n\t\t\t\t} else {\n\t\t\t\t\treturn '.'\n\t\t\t\t}\n\t\t\t}())\n\t\t}\n\t\tfmt.Fprintln(w)\n\t}\n\tfmt.Fprintf(w, \"Piece length: %s\\n\",\n\t\tfunc() string {\n\t\t\tif t.haveInfo() {\n\t\t\t\treturn fmt.Sprintf(\"%v (%v chunks)\",\n\t\t\t\t\tt.usualPieceSize(),\n\t\t\t\t\tfloat64(t.usualPieceSize())/float64(t.chunkSize))\n\t\t\t} else {\n\t\t\t\treturn \"no info\"\n\t\t\t}\n\t\t}(),\n\t)\n\tif t.info != nil {\n\t\tfmt.Fprintf(w, \"Num Pieces: %d (%d completed)\\n\", t.numPieces(), t.numPiecesCompleted())\n\t\tfmt.Fprintf(w, \"Piece States: %s\\n\", t.pieceStateRuns())\n\t\t// Generates a huge, unhelpful listing when piece availability is very scattered. Prefer\n\t\t// availability frequencies instead.\n\t\tif false {\n\t\t\tfmt.Fprintf(w, \"Piece availability: %v\\n\", strings.Join(func() (ret []string) {\n\t\t\t\tfor _, run := range t.pieceAvailabilityRuns() {\n\t\t\t\t\tret = append(ret, run.String())\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}(), \" \"))\n\t\t}\n\t\tfmt.Fprintf(w, \"Piece availability frequency: %v\\n\", strings.Join(\n\t\t\tfunc() (ret []string) {\n\t\t\t\tfor avail, freq := range t.pieceAvailabilityFrequencies() {\n\t\t\t\t\tif freq == 0 {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tret = append(ret, fmt.Sprintf(\"%v: %v\", avail, freq))\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}(),\n\t\t\t\", \"))\n\t}\n\tfmt.Fprintf(w, \"Reader Pieces:\")\n\tt.forReaderOffsetPieces(func(begin, end pieceIndex) (again bool) {\n\t\tfmt.Fprintf(w, \" %d:%d\", begin, end)\n\t\treturn true\n\t})\n\tfmt.Fprintln(w)\n\n\tfmt.Fprintf(w, \"Enabled trackers:\\n\")\n\t{\n\t\ttw := tabwriter.NewWriter(w, 0, 0, 2, ' ', 0)\n\t\tfmt.Fprintf(tw, \"    URL\\tExtra\\n\")\n\t\tsortedTrackerAnnouncers := slices.SortedFunc(\n\t\t\tmaps.Values(t.trackerAnnouncers),\n\t\t\tfunc(l, r torrentTrackerAnnouncer) int {\n\t\t\t\tlu := l.URL()\n\t\t\t\tru := r.URL()\n\t\t\t\tvar luns, runs url.URL = *lu, *ru\n\t\t\t\tluns.Scheme = \"\"\n\t\t\t\truns.Scheme = \"\"\n\t\t\t\tvar ml multiless.Computation\n\t\t\t\tml = multiless.EagerOrdered(ml, luns.String(), runs.String())\n\t\t\t\tml = multiless.EagerOrdered(ml, lu.String(), ru.String())\n\t\t\t\treturn ml.OrderingInt()\n\t\t\t},\n\t\t)\n\t\tfor _, ta := range sortedTrackerAnnouncers {\n\t\t\tfmt.Fprintf(tw, \"    %q\\t%v\\n\", ta.URL(), ta.statusLine())\n\t\t}\n\t\ttw.Flush()\n\t}\n\n\tfmt.Fprintf(w, \"DHT Announces: %d\\n\", t.numDHTAnnounces)\n\n\tdumpStats(w, t.statsLocked())\n\n\tfmt.Fprintf(w, \"webseeds:\\n\")\n\tt.writePeerStatuses(w, maps.Values(t.webSeeds))\n\n\t// Peers without priorities first, then those with. I'm undecided about how to order peers\n\t// without priorities.\n\tpeerConns := slices.SortedFunc(maps.Keys(t.conns), func(l, r *PeerConn) int {\n\t\tml := multiless.New()\n\t\tlpp := g.ResultFromTuple(l.peerPriority()).ToOption()\n\t\trpp := g.ResultFromTuple(r.peerPriority()).ToOption()\n\t\tml = ml.Bool(lpp.Ok, rpp.Ok)\n\t\tml = ml.Uint32(rpp.Value, lpp.Value)\n\t\treturn ml.OrderingInt()\n\t})\n\n\tfmt.Fprintf(w, \"%v peer conns:\\n\", len(peerConns))\n\tvar peerIter iter.Seq[*Peer] = func(yield func(*Peer) bool) {\n\t\tfor _, pc := range peerConns {\n\t\t\tif !yield(&pc.Peer) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\tt.writePeerStatuses(w, peerIter)\n}\n\nfunc (t *Torrent) writePeerStatuses(w io.Writer, peers iter.Seq[*Peer]) {\n\tvar buf bytes.Buffer\n\tfor c := range peers {\n\t\tfmt.Fprintf(w, \"- \")\n\t\tbuf.Reset()\n\t\tc.writeStatus(&buf)\n\t\tw.Write(bytes.TrimRight(\n\t\t\tbytes.ReplaceAll(buf.Bytes(), []byte(\"\\n\"), []byte(\"\\n  \")),\n\t\t\t\" \"))\n\t}\n}\n\nfunc (t *Torrent) haveInfo() bool {\n\treturn t.info != nil\n}\n\n// Returns a run-time generated MetaInfo that includes the info bytes and\n// announce-list as currently known to the client.\nfunc (t *Torrent) newMetaInfo() metainfo.MetaInfo {\n\treturn metainfo.MetaInfo{\n\t\tCreationDate: time.Now().Unix(),\n\t\tComment:      \"dynamic metainfo from client\",\n\t\tCreatedBy:    \"https://github.com/anacrolix/torrent\",\n\t\tAnnounceList: t.metainfo.UpvertedAnnounceList().Clone(),\n\t\tInfoBytes: func() []byte {\n\t\t\tif t.haveInfo() {\n\t\t\t\treturn t.metadataBytes\n\t\t\t} else {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}(),\n\t\tUrlList: func() []string {\n\t\t\tret := make([]string, 0, len(t.webSeeds))\n\t\t\tfor url := range t.webSeeds {\n\t\t\t\tret = append(ret, url)\n\t\t\t}\n\t\t\treturn ret\n\t\t}(),\n\t\tPieceLayers: t.pieceLayers(),\n\t}\n}\n\n// Returns a count of bytes that are not complete in storage, and not pending being written to\n// storage. This value is from the perspective of the download manager, and may not agree with the\n// actual state in storage. If you want read data synchronously you should use a Reader. See\n// https://github.com/anacrolix/torrent/issues/828.\nfunc (t *Torrent) BytesMissing() (n int64) {\n\tt.cl.rLock()\n\tn = t.bytesMissingLocked()\n\tt.cl.rUnlock()\n\treturn\n}\n\nfunc (t *Torrent) bytesMissingLocked() int64 {\n\treturn t.bytesLeft()\n}\n\nfunc iterFlipped(b *roaring.Bitmap, end uint64, cb func(uint32) bool) {\n\troaring.Flip(b, 0, end).Iterate(cb)\n}\n\nfunc (t *Torrent) bytesLeft() (left int64) {\n\titerFlipped(&t._completedPieces, uint64(t.numPieces()), func(x uint32) bool {\n\t\tp := t.piece(pieceIndex(x))\n\t\tleft += int64(p.length() - p.numDirtyBytes())\n\t\treturn true\n\t})\n\treturn\n}\n\n// Bytes left to give in tracker announces.\nfunc (t *Torrent) bytesLeftAnnounce() int64 {\n\tif t.haveInfo() {\n\t\treturn t.bytesLeft()\n\t} else {\n\t\treturn -1\n\t}\n}\n\nfunc (t *Torrent) piecePartiallyDownloaded(piece pieceIndex) bool {\n\tif t.pieceComplete(piece) {\n\t\treturn false\n\t}\n\tif t.pieceAllDirty(piece) {\n\t\treturn false\n\t}\n\treturn t.pieces[piece].hasDirtyChunks()\n}\n\nfunc (t *Torrent) usualPieceSize() int {\n\treturn int(t.info.PieceLength)\n}\n\nfunc (t *Torrent) numPieces() pieceIndex {\n\treturn t.info.NumPieces()\n}\n\nfunc (t *Torrent) numPiecesCompleted() (num pieceIndex) {\n\treturn pieceIndex(t._completedPieces.GetCardinality())\n}\n\nfunc (t *Torrent) close(wg *sync.WaitGroup) (err error) {\n\tif !t.closed.Set() {\n\t\terr = errors.New(\"already closed\")\n\t\treturn\n\t}\n\tfor _, f := range t.onClose {\n\t\tf()\n\t}\n\tif t.storage != nil {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tt.storageLock.Lock()\n\t\t\tdefer t.storageLock.Unlock()\n\t\t\tif f := t.storage.Close; f != nil {\n\t\t\t\terr1 := f()\n\t\t\t\tif err1 != nil {\n\t\t\t\t\tt.logger.WithDefaultLevel(log.Warning).Printf(\"error closing storage: %v\", err1)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\tt.iterPeers(func(p *Peer) {\n\t\tp.close()\n\t})\n\tif t.storage != nil {\n\t\tt.deletePieceRequestOrder()\n\t}\n\tt.assertAllPiecesRelativeAvailabilityZero()\n\tt.pex.Reset()\n\tt.cl.event.Broadcast()\n\tt.pieceStateChanges.Close()\n\tt.updateWantPeersEvent()\n\treturn\n}\n\nfunc (t *Torrent) assertAllPiecesRelativeAvailabilityZero() {\n\tfor i := range t.pieces {\n\t\tp := t.piece(i)\n\t\tif p.relativeAvailability != 0 {\n\t\t\tpanic(fmt.Sprintf(\"piece %v has relative availability %v\", i, p.relativeAvailability))\n\t\t}\n\t}\n}\n\nfunc (t *Torrent) requestOffset(r Request) int64 {\n\treturn torrentRequestOffset(t.length(), int64(t.usualPieceSize()), r)\n}\n\n// Return the request that would include the given offset into the torrent data. Returns !ok if\n// there is no such request.\nfunc (t *Torrent) offsetRequest(off int64) (req Request, ok bool) {\n\treturn torrentOffsetRequest(t.length(), t.info.PieceLength, int64(t.chunkSize), off)\n}\n\nfunc (t *Torrent) writeChunk(piece int, begin int64, data []byte) (err error) {\n\tn, err := t.pieces[piece].Storage().WriteAt(data, begin)\n\tif err == nil && n != len(data) {\n\t\terr = io.ErrShortWrite\n\t}\n\treturn err\n}\n\nfunc (t *Torrent) bitfield() (bf []bool) {\n\tbf = make([]bool, t.numPieces())\n\tt._completedPieces.Iterate(func(piece uint32) (again bool) {\n\t\tbf[piece] = true\n\t\treturn true\n\t})\n\treturn\n}\n\nfunc (t *Torrent) pieceNumChunks(piece pieceIndex) chunkIndexType {\n\treturn chunkIndexType((t.pieceLength(piece) + t.chunkSize - 1) / t.chunkSize)\n}\n\nfunc (t *Torrent) chunksPerRegularPiece() chunkIndexType {\n\treturn t._chunksPerRegularPiece\n}\n\nfunc (t *Torrent) numChunks() RequestIndex {\n\tif t.numPieces() == 0 {\n\t\treturn 0\n\t}\n\treturn RequestIndex(t.numPieces()-1)*t.chunksPerRegularPiece() + t.pieceNumChunks(t.numPieces()-1)\n}\n\nfunc (t *Torrent) pendAllChunkSpecs(pieceIndex pieceIndex) {\n\tt.dirtyChunks.RemoveRange(\n\t\tuint64(t.pieceRequestIndexOffset(pieceIndex)),\n\t\tuint64(t.pieceRequestIndexOffset(pieceIndex+1)))\n}\n\nfunc (t *Torrent) pieceLength(piece pieceIndex) pp.Integer {\n\tif t.info.PieceLength == 0 {\n\t\t// There will be no variance amongst pieces. Only pain.\n\t\treturn 0\n\t}\n\tif t.info.FilesArePieceAligned() {\n\t\tp := t.piece(piece)\n\t\tfile := p.mustGetOnlyFile()\n\t\tif piece == file.EndPieceIndex()-1 {\n\t\t\treturn pp.Integer(file.length - (p.torrentBeginOffset() - file.offset))\n\t\t}\n\t\treturn pp.Integer(t.usualPieceSize())\n\t}\n\tif piece == t.numPieces()-1 {\n\t\tret := pp.Integer(t.length() % t.info.PieceLength)\n\t\tif ret != 0 {\n\t\t\treturn ret\n\t\t}\n\t}\n\treturn pp.Integer(t.info.PieceLength)\n}\n\nfunc (t *Torrent) smartBanBlockCheckingWriter(piece pieceIndex) *blockCheckingWriter {\n\treturn &blockCheckingWriter{\n\t\tcache:        &t.smartBanCache,\n\t\trequestIndex: t.pieceRequestIndexOffset(piece),\n\t\tchunkSize:    t.chunkSize.Int(),\n\t}\n}\n\nfunc (t *Torrent) hashPiece(piece pieceIndex) (\n\tcorrect bool,\n\t// These are peers that sent us blocks that differ from what we hash here.\n\tdifferingPeers map[bannableAddr]struct{},\n\terr error,\n) {\n\tp := t.piece(piece)\n\tp.waitNoPendingWrites()\n\tstoragePiece := p.Storage()\n\n\tif p.hash != nil {\n\t\t// Does the backend want to do its own hashing?\n\t\tif i, ok := storagePiece.PieceImpl.(storage.SelfHashing); ok {\n\t\t\tvar sum metainfo.Hash\n\t\t\t// log.Printf(\"A piece decided to self-hash: %d\", piece)\n\t\t\tsum, err = i.SelfHash()\n\t\t\tcorrect = sum == *p.hash\n\t\t\t// Can't do smart banning without reading the piece. The smartBanCache is still cleared\n\t\t\t// in pieceHasher regardless.\n\t\t\treturn\n\t\t}\n\t\th := pieceHash.New()\n\t\tdifferingPeers, err = t.hashPieceWithSpecificHash(piece, h)\n\t\t// For a hybrid torrent, we work with the v2 files, but if we use a v1 hash, we can assume\n\t\t// that the pieces are padded with zeroes.\n\t\tif t.info.FilesArePieceAligned() {\n\t\t\tpaddingLen := p.Info().V1Length() - p.Info().Length()\n\t\t\twritten, err := io.CopyN(h, zeroReader, paddingLen)\n\t\t\tif written != paddingLen {\n\t\t\t\tpanic(fmt.Sprintf(\n\t\t\t\t\t\"piece %v: wrote %v bytes of padding, expected %v, error: %v\",\n\t\t\t\t\tpiece,\n\t\t\t\t\twritten,\n\t\t\t\t\tpaddingLen,\n\t\t\t\t\terr,\n\t\t\t\t))\n\t\t\t}\n\t\t}\n\t\tvar sum [20]byte\n\t\tsumExactly(sum[:], h.Sum)\n\t\tcorrect = sum == *p.hash\n\t} else if p.hashV2.Ok {\n\t\th := merkle.NewHash()\n\t\tdifferingPeers, err = t.hashPieceWithSpecificHash(piece, h)\n\t\tvar sum [32]byte\n\t\t// What about the final piece in a torrent? From BEP 52: \"The layer is chosen so that one\n\t\t// hash covers piece length bytes.\". Note that if a piece doesn't have a hash in piece\n\t\t// layers it's because it's not larger than the piece length.\n\t\tsumExactly(sum[:], func(b []byte) []byte {\n\t\t\treturn h.SumMinLength(b, int(t.info.PieceLength))\n\t\t})\n\t\tcorrect = sum == p.hashV2.Value\n\t} else {\n\t\texpected := p.mustGetOnlyFile().piecesRoot.Unwrap()\n\t\th := merkle.NewHash()\n\t\tdifferingPeers, err = t.hashPieceWithSpecificHash(piece, h)\n\t\tvar sum [32]byte\n\t\t// This is *not* padded to piece length.\n\t\tsumExactly(sum[:], h.Sum)\n\t\tcorrect = sum == expected\n\t}\n\treturn\n}\n\nfunc sumExactly(dst []byte, sum func(b []byte) []byte) {\n\tn := len(sum(dst[:0]))\n\tif n != len(dst) {\n\t\tpanic(n)\n\t}\n}\n\nfunc (t *Torrent) hashPieceWithSpecificHash(piece pieceIndex, h hash.Hash) (\n\t// These are peers that sent us blocks that differ from what we hash here.\n\tdifferingPeers map[bannableAddr]struct{},\n\terr error,\n) {\n\tp := t.piece(piece)\n\tstoragePiece := p.Storage()\n\n\tsmartBanWriter := t.smartBanBlockCheckingWriter(piece)\n\tmultiWriter := io.MultiWriter(h, smartBanWriter)\n\t{\n\t\tvar written int64\n\t\twritten, err = storagePiece.WriteTo(multiWriter)\n\t\tif err == nil && written != int64(p.length()) {\n\t\t\terr = fmt.Errorf(\"wrote %v bytes from storage, piece has length %v\", written, p.length())\n\t\t\t// Skip smart banning since we can't blame them for storage issues. A short write would\n\t\t\t// ban peers for all recorded blocks that weren't just written.\n\t\t\treturn\n\t\t}\n\t}\n\t// Flush before writing padding, since we would not have recorded the padding blocks.\n\tsmartBanWriter.Flush()\n\tdifferingPeers = smartBanWriter.badPeers\n\treturn\n}\n\nfunc (t *Torrent) haveAnyPieces() bool {\n\treturn !t._completedPieces.IsEmpty()\n}\n\nfunc (t *Torrent) haveAllPieces() bool {\n\tif !t.haveInfo() {\n\t\treturn false\n\t}\n\treturn t._completedPieces.GetCardinality() == bitmap.BitRange(t.numPieces())\n}\n\nfunc (t *Torrent) havePiece(index pieceIndex) bool {\n\treturn t.haveInfo() && t.pieceComplete(index)\n}\n\nfunc (t *Torrent) maybeDropMutuallyCompletePeer(\n\t// I'm not sure about taking peer here, not all peer implementations actually drop. Maybe that's\n\t// okay?\n\tp *PeerConn,\n) {\n\tif !t.cl.config.DropMutuallyCompletePeers {\n\t\treturn\n\t}\n\tif !t.haveAllPieces() {\n\t\treturn\n\t}\n\tif all, known := p.peerHasAllPieces(); !(known && all) {\n\t\treturn\n\t}\n\tif p.useful() {\n\t\treturn\n\t}\n\tp.logger.Levelf(log.Debug, \"is mutually complete; dropping\")\n\tp.drop()\n}\n\nfunc (t *Torrent) haveChunk(r Request) (ret bool) {\n\t// defer func() {\n\t// \tlog.Println(\"have chunk\", r, ret)\n\t// }()\n\tif !t.haveInfo() {\n\t\treturn false\n\t}\n\tif t.pieceComplete(pieceIndex(r.Index)) {\n\t\treturn true\n\t}\n\tp := &t.pieces[r.Index]\n\treturn !p.pendingChunk(r.ChunkSpec, t.chunkSize)\n}\n\nfunc chunkIndexFromChunkSpec(cs ChunkSpec, chunkSize pp.Integer) chunkIndexType {\n\treturn chunkIndexType(cs.Begin / chunkSize)\n}\n\nfunc (t *Torrent) wantPieceIndex(index pieceIndex) bool {\n\treturn !t._pendingPieces.IsEmpty() && t._pendingPieces.Contains(uint32(index))\n}\n\n// A pool of []*PeerConn, to reduce allocations in functions that need to index or sort Torrent\n// conns (which is a map).\nvar peerConnSlices sync.Pool\n\nfunc getPeerConnSlice(cap int) []*PeerConn {\n\tgetInterface := peerConnSlices.Get()\n\tif getInterface == nil {\n\t\treturn make([]*PeerConn, 0, cap)\n\t} else {\n\t\treturn getInterface.([]*PeerConn)[:0]\n\t}\n}\n\n// Calls the given function with a slice of unclosed conns. It uses a pool to reduce allocations as\n// this is a frequent occurrence.\nfunc (t *Torrent) withUnclosedConns(f func([]*PeerConn)) {\n\tsl := t.appendUnclosedConns(getPeerConnSlice(len(t.conns)))\n\tf(sl)\n\tpeerConnSlices.Put(sl)\n}\n\nfunc (t *Torrent) worstBadConnFromSlice(opts worseConnLensOpts, sl []*PeerConn) *PeerConn {\n\twcs := worseConnSlice{conns: sl}\n\twcs.initKeys(opts)\n\theap.Init(&wcs)\n\tfor wcs.Len() != 0 {\n\t\tc := heap.Pop(&wcs).(*PeerConn)\n\t\tif opts.incomingIsBad && !c.outgoing {\n\t\t\treturn c\n\t\t}\n\t\tif opts.outgoingIsBad && c.outgoing {\n\t\t\treturn c\n\t\t}\n\t\tif c._stats.ChunksReadWasted.Int64() >= 6 && c._stats.ChunksReadWasted.Int64() > c._stats.ChunksReadUseful.Int64() {\n\t\t\treturn c\n\t\t}\n\t\t// If the connection is in the worst half of the established\n\t\t// connection quota and is older than a minute.\n\t\tif wcs.Len() >= (t.maxEstablishedConns+1)/2 {\n\t\t\t// Give connections 1 minute to prove themselves.\n\t\t\tif time.Since(c.completedHandshake) > time.Minute {\n\t\t\t\treturn c\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// The worst connection is one that hasn't been sent, or sent anything useful for the longest. A bad\n// connection is one that usually sends us unwanted pieces, or has been in the worse half of the\n// established connections for more than a minute. This is O(n log n). If there was a way to not\n// consider the position of a conn relative to the total number, it could be reduced to O(n).\nfunc (t *Torrent) worstBadConn(opts worseConnLensOpts) (ret *PeerConn) {\n\tt.withUnclosedConns(func(ucs []*PeerConn) {\n\t\tret = t.worstBadConnFromSlice(opts, ucs)\n\t})\n\treturn\n}\n\ntype PieceStateChange struct {\n\tIndex int\n\tPieceState\n}\n\nfunc (t *Torrent) publishPieceStateChange(piece pieceIndex) {\n\tt.cl._mu.Defer(func() {\n\t\tcur := t.pieceState(piece)\n\t\tp := &t.pieces[piece]\n\t\tif cur != p.publicPieceState {\n\t\t\tp.publicPieceState = cur\n\t\t\tt.pieceStateChanges.Publish(PieceStateChange{\n\t\t\t\tint(piece),\n\t\t\t\tcur,\n\t\t\t})\n\t\t}\n\t})\n}\n\nfunc (t *Torrent) pieceNumPendingChunks(piece pieceIndex) pp.Integer {\n\tif t.pieceComplete(piece) {\n\t\treturn 0\n\t}\n\treturn pp.Integer(t.pieceNumChunks(piece) - t.pieces[piece].numDirtyChunks())\n}\n\nfunc (t *Torrent) pieceAllDirty(piece pieceIndex) bool {\n\treturn t.pieces[piece].allChunksDirty()\n}\n\nfunc (t *Torrent) readersChanged() {\n\tt.updateReaderPieces()\n\tt.updateAllPiecePriorities(\"Torrent.readersChanged\")\n}\n\nfunc (t *Torrent) updateReaderPieces() {\n\tt._readerNowPieces, t._readerReadaheadPieces = t.readerPiecePriorities()\n}\n\nfunc (t *Torrent) readerPosChanged(from, to pieceRange) {\n\tif from == to {\n\t\treturn\n\t}\n\tt.updateReaderPieces()\n\t// Order the ranges, high and low.\n\tl, h := from, to\n\tif l.begin > h.begin {\n\t\tl, h = h, l\n\t}\n\tif l.end < h.begin {\n\t\t// Two distinct ranges.\n\t\tt.updatePiecePriorities(l.begin, l.end, \"Torrent.readerPosChanged\")\n\t\tt.updatePiecePriorities(h.begin, h.end, \"Torrent.readerPosChanged\")\n\t} else {\n\t\t// Ranges overlap.\n\t\tend := l.end\n\t\tif h.end > end {\n\t\t\tend = h.end\n\t\t}\n\t\tt.updatePiecePriorities(l.begin, end, \"Torrent.readerPosChanged\")\n\t}\n}\n\nfunc (t *Torrent) maybeNewConns() {\n\t// Tickle the accept routine.\n\tt.cl.event.Broadcast()\n\tt.openNewConns()\n}\n\nfunc (t *Torrent) onPiecePendingTriggers(piece pieceIndex, reason updateRequestReason) {\n\tif t._pendingPieces.Contains(uint32(piece)) {\n\t\tt.iterPeers(func(c *Peer) {\n\t\t\t// if c.requestState.Interested {\n\t\t\t// \treturn\n\t\t\t// }\n\t\t\tif !c.isLowOnRequests() {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !c.peerHasPiece(piece) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif c.requestState.Interested && c.peerChoking && !c.peerAllowedFast.Contains(piece) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tc.updateRequests(reason)\n\t\t})\n\t}\n\tt.maybeNewConns()\n\tt.publishPieceStateChange(piece)\n}\n\nfunc (t *Torrent) updatePiecePriorityNoTriggers(piece pieceIndex) (pendingChanged bool) {\n\tif !t.closed.IsSet() {\n\t\t// It would be possible to filter on pure-priority changes here to avoid churning the piece\n\t\t// request order.\n\t\tt.updatePieceRequestOrderPiece(piece)\n\t}\n\tp := t.piece(piece)\n\tnewPrio := p.effectivePriority()\n\t// t.logger.Printf(\"torrent %p: piece %d: uncached priority: %v\", t, piece, newPrio)\n\tif newPrio == PiecePriorityNone && p.haveHash() {\n\t\treturn t._pendingPieces.CheckedRemove(uint32(piece))\n\t} else {\n\t\treturn t._pendingPieces.CheckedAdd(uint32(piece))\n\t}\n}\n\nfunc (t *Torrent) updatePiecePriority(piece pieceIndex, reason updateRequestReason) {\n\tif t.updatePiecePriorityNoTriggers(piece) && !t.disableTriggers {\n\t\tt.onPiecePendingTriggers(piece, reason)\n\t}\n\tt.updatePieceRequestOrderPiece(piece)\n}\n\nfunc (t *Torrent) updateAllPiecePriorities(reason updateRequestReason) {\n\tt.updatePiecePriorities(0, t.numPieces(), reason)\n}\n\n// Update all piece priorities in one hit. This function should have the same\n// output as updatePiecePriority, but across all pieces.\nfunc (t *Torrent) updatePiecePriorities(begin, end pieceIndex, reason updateRequestReason) {\n\tfor i := begin; i < end; i++ {\n\t\tt.updatePiecePriority(i, reason)\n\t}\n}\n\n// Returns the range of pieces [begin, end) that contains the extent of bytes.\nfunc (t *Torrent) byteRegionPieces(off, size int64) (begin, end pieceIndex) {\n\tif off >= t.length() {\n\t\treturn\n\t}\n\tif off < 0 {\n\t\tsize += off\n\t\toff = 0\n\t}\n\tif size <= 0 {\n\t\treturn\n\t}\n\tbegin = pieceIndex(off / t.info.PieceLength)\n\tend = pieceIndex((off + size + t.info.PieceLength - 1) / t.info.PieceLength)\n\tif end > pieceIndex(t.info.NumPieces()) {\n\t\tend = pieceIndex(t.info.NumPieces())\n\t}\n\treturn\n}\n\n// Returns true if all iterations complete without breaking. Returns the read regions for all\n// readers. The reader regions should not be merged as some callers depend on this method to\n// enumerate readers.\nfunc (t *Torrent) forReaderOffsetPieces(f func(begin, end pieceIndex) (more bool)) (all bool) {\n\tfor r := range t.readers {\n\t\tp := r.pieces\n\t\tif p.begin >= p.end {\n\t\t\tcontinue\n\t\t}\n\t\tif !f(p.begin, p.end) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (t *Torrent) pendRequest(req RequestIndex) {\n\tt.piece(t.pieceIndexOfRequestIndex(req)).pendChunkIndex(req % t.chunksPerRegularPiece())\n}\n\nfunc (t *Torrent) pieceCompletionChanged(piece pieceIndex, reason updateRequestReason) {\n\tt.cl.event.Broadcast()\n\tif t.pieceComplete(piece) {\n\t\tt.onPieceCompleted(piece)\n\t} else {\n\t\tt.onIncompletePiece(piece)\n\t}\n\tt.updatePiecePriority(piece, reason)\n}\n\nfunc (t *Torrent) numReceivedConns() (ret int) {\n\tfor c := range t.conns {\n\t\tif c.Discovery == PeerSourceIncoming {\n\t\t\tret++\n\t\t}\n\t}\n\treturn\n}\n\nfunc (t *Torrent) numOutgoingConns() (ret int) {\n\tfor c := range t.conns {\n\t\tif c.outgoing {\n\t\t\tret++\n\t\t}\n\t}\n\treturn\n}\n\nfunc (t *Torrent) maxHalfOpen() int {\n\t// Note that if we somehow exceed the maximum established conns, we want\n\t// the negative value to have an effect.\n\testablishedHeadroom := int64(t.maxEstablishedConns - len(t.conns))\n\textraIncoming := int64(t.numReceivedConns() - t.maxEstablishedConns/2)\n\t// We want to allow some experimentation with new peers, and to try to\n\t// upset an oversupply of received connections.\n\treturn int(min(\n\t\tmax(5, extraIncoming)+establishedHeadroom,\n\t\tint64(t.cl.config.HalfOpenConnsPerTorrent),\n\t))\n}\n\nfunc (t *Torrent) openNewConns() (initiated int) {\n\tdefer t.updateWantPeersEvent()\n\tfor t.peers.Len() != 0 {\n\t\tif !t.wantOutgoingConns() {\n\t\t\treturn\n\t\t}\n\t\tif len(t.halfOpen) >= t.maxHalfOpen() {\n\t\t\treturn\n\t\t}\n\t\tif len(t.cl.dialers) == 0 {\n\t\t\treturn\n\t\t}\n\t\tif t.cl.numHalfOpen >= t.cl.config.TotalHalfOpenConns {\n\t\t\treturn\n\t\t}\n\t\tp := t.peers.PopMax()\n\t\topts := outgoingConnOpts{\n\t\t\tpeerInfo:                 p,\n\t\t\tt:                        t,\n\t\t\trequireRendezvous:        false,\n\t\t\tskipHolepunchRendezvous:  false,\n\t\t\treceivedHolepunchConnect: false,\n\t\t\tHeaderObfuscationPolicy:  t.cl.config.HeaderObfuscationPolicy,\n\t\t}\n\t\tinitiateConn(opts, false)\n\t\tinitiated++\n\t}\n\treturn\n}\n\nfunc (t *Torrent) updatePieceCompletion(piece pieceIndex) bool {\n\tp := t.piece(piece)\n\tuncached := t.pieceCompleteUncached(piece)\n\tcached := p.completion()\n\tchanged := cached != uncached\n\tcomplete := uncached.Complete\n\tp.storageCompletionOk = uncached.Ok\n\tx := uint32(piece)\n\tif complete {\n\t\tt._completedPieces.Add(x)\n\t\tt.openNewConns()\n\t} else {\n\t\tt._completedPieces.Remove(x)\n\t}\n\tp.t.updatePieceRequestOrderPiece(piece)\n\tt.updateComplete()\n\tif complete && len(p.dirtiers) != 0 {\n\t\tt.logger.Printf(\"marked piece %v complete but still has dirtiers\", piece)\n\t}\n\tif changed {\n\t\t//slog.Debug(\n\t\t//\t\"piece completion changed\",\n\t\t//\tslog.Int(\"piece\", piece),\n\t\t//\tslog.Any(\"from\", cached),\n\t\t//\tslog.Any(\"to\", uncached))\n\t\tt.pieceCompletionChanged(piece, \"Torrent.updatePieceCompletion\")\n\t}\n\treturn changed\n}\n\n// Non-blocking read. Client lock is not required.\nfunc (t *Torrent) readAt(b []byte, off int64) (n int, err error) {\n\tfor len(b) != 0 {\n\t\tp := &t.pieces[off/t.info.PieceLength]\n\t\tp.waitNoPendingWrites()\n\t\tvar n1 int\n\t\tn1, err = p.Storage().ReadAt(b, off-p.Info().Offset())\n\t\tif n1 == 0 {\n\t\t\tbreak\n\t\t}\n\t\toff += int64(n1)\n\t\tn += n1\n\t\tb = b[n1:]\n\t}\n\treturn\n}\n\n// Returns an error if the metadata was completed, but couldn't be set for some reason. Blame it on\n// the last peer to contribute. TODO: Actually we shouldn't blame peers for failure to open storage\n// etc. Also we should probably cached metadata pieces per-Peer, to isolate failure appropriately.\nfunc (t *Torrent) maybeCompleteMetadata() error {\n\tif t.haveInfo() {\n\t\t// Nothing to do.\n\t\treturn nil\n\t}\n\tif !t.haveAllMetadataPieces() {\n\t\t// Don't have enough metadata pieces.\n\t\treturn nil\n\t}\n\terr := t.setInfoBytesLocked(t.metadataBytes)\n\tif err != nil {\n\t\tt.invalidateMetadata()\n\t\treturn fmt.Errorf(\"error setting info bytes: %s\", err)\n\t}\n\tif t.cl.config.Debug {\n\t\tt.logger.Printf(\"%s: got metadata from peers\", t)\n\t}\n\treturn nil\n}\n\nfunc (t *Torrent) readerPiecePriorities() (now, readahead bitmap.Bitmap) {\n\tt.forReaderOffsetPieces(func(begin, end pieceIndex) bool {\n\t\tif end > begin {\n\t\t\tnow.Add(bitmap.BitIndex(begin))\n\t\t\treadahead.AddRange(bitmap.BitRange(begin)+1, bitmap.BitRange(end))\n\t\t}\n\t\treturn true\n\t})\n\treturn\n}\n\nfunc (t *Torrent) needData() bool {\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif !t.haveInfo() {\n\t\treturn true\n\t}\n\treturn !t._pendingPieces.IsEmpty()\n}\n\nfunc appendMissingStrings(old, new []string) (ret []string) {\n\tret = old\nnew:\n\tfor _, n := range new {\n\t\tfor _, o := range old {\n\t\t\tif o == n {\n\t\t\t\tcontinue new\n\t\t\t}\n\t\t}\n\t\tret = append(ret, n)\n\t}\n\treturn\n}\n\nfunc appendMissingTrackerTiers(existing [][]string, minNumTiers int) (ret [][]string) {\n\tret = existing\n\tfor minNumTiers > len(ret) {\n\t\tret = append(ret, nil)\n\t}\n\treturn\n}\n\nfunc (t *Torrent) addTrackers(announceList [][]string) {\n\tfullAnnounceList := &t.metainfo.AnnounceList\n\tt.metainfo.AnnounceList = appendMissingTrackerTiers(*fullAnnounceList, len(announceList))\n\tfor tierIndex, trackerURLs := range announceList {\n\t\t(*fullAnnounceList)[tierIndex] = appendMissingStrings((*fullAnnounceList)[tierIndex], trackerURLs)\n\t}\n\tt.startMissingTrackerScrapers()\n\tt.updateWantPeersEvent()\n}\n\nfunc (t *Torrent) modifyTrackers(announceList [][]string) {\n\tvar workers errgroup.Group\n\tfor _, v := range t.trackerAnnouncers {\n\t\tworkers.Go(func() error {\n\t\t\tv.Stop()\n\t\t\treturn nil\n\t\t})\n\t}\n\tworkers.Wait()\n\n\tclear(t.metainfo.AnnounceList)\n\tt.addTrackers(announceList)\n}\n\n// Don't call this before the info is available.\nfunc (t *Torrent) bytesCompleted() int64 {\n\tif !t.haveInfo() {\n\t\treturn 0\n\t}\n\treturn t.length() - t.bytesLeft()\n}\n\nfunc (t *Torrent) SetInfoBytes(b []byte) (err error) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\treturn t.setInfoBytesLocked(b)\n}\n\n// Returns true if connection is removed from torrent.Conns.\nfunc (t *Torrent) deletePeerConn(c *PeerConn) (ret bool) {\n\tif !c.closed.IsSet() {\n\t\tpanic(\"connection is not closed\")\n\t\t// There are behaviours prevented by the closed state that will fail\n\t\t// if the connection has been deleted.\n\t}\n\t_, ret = t.conns[c]\n\tdelete(t.conns, c)\n\t// Avoid adding a drop event more than once. Probably we should track whether we've generated\n\t// the drop event against the PexConnState instead.\n\tif ret {\n\t\tif !t.cl.config.DisablePEX {\n\t\t\tt.pex.Drop(c)\n\t\t}\n\t}\n\ttorrent.Add(\"deleted connections\", 1)\n\tc.deleteAllRequests(\"Torrent.deletePeerConn\")\n\tt.assertPendingRequests()\n\tif t.numActivePeers() == 0 && len(t.connsWithAllPieces) != 0 {\n\t\tpanic(t.connsWithAllPieces)\n\t}\n\treturn\n}\n\nfunc (t *Torrent) decPeerPieceAvailability(p *Peer) {\n\tif t.deleteConnWithAllPieces(p) {\n\t\treturn\n\t}\n\tif !t.haveInfo() {\n\t\treturn\n\t}\n\tp.peerPieces().Iterate(func(i uint32) bool {\n\t\tp.t.decPieceAvailability(pieceIndex(i))\n\t\treturn true\n\t})\n}\n\nfunc (t *Torrent) assertPendingRequests() {\n\tif !check.Enabled {\n\t\treturn\n\t}\n\t// var actual pendingRequests\n\t// if t.haveInfo() {\n\t// \tactual.m = make([]int, t.numChunks())\n\t// }\n\t// t.iterPeers(func(p *Peer) {\n\t// \tp.requestState.Requests.Iterate(func(x uint32) bool {\n\t// \t\tactual.Inc(x)\n\t// \t\treturn true\n\t// \t})\n\t// })\n\t// diff := cmp.Diff(actual.m, t.pendingRequests.m)\n\t// if diff != \"\" {\n\t// \tpanic(diff)\n\t// }\n}\n\nfunc (t *Torrent) dropConnection(c *PeerConn) {\n\tt.cl.event.Broadcast()\n\tc.close()\n\tif t.deletePeerConn(c) {\n\t\tt.openNewConns()\n\t}\n}\n\n// Peers as in contact information for dialing out.\nfunc (t *Torrent) wantPeers() bool {\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif t.peers.Len() > t.cl.config.TorrentPeersLowWater {\n\t\treturn false\n\t}\n\treturn t.wantOutgoingConns()\n}\n\nfunc (t *Torrent) updateWantPeersEvent() {\n\tif t.wantPeers() {\n\t\tt.wantPeersEvent.Set()\n\t} else {\n\t\tt.wantPeersEvent.Clear()\n\t}\n}\n\n// Returns whether the client should make effort to seed the torrent.\nfunc (t *Torrent) seeding() bool {\n\tcl := t.cl\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif t.dataUploadDisallowed {\n\t\treturn false\n\t}\n\tif cl.config.NoUpload {\n\t\treturn false\n\t}\n\tif !cl.config.Seed {\n\t\treturn false\n\t}\n\tif cl.config.DisableAggressiveUpload && t.needData() {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (t *Torrent) onWebRtcConn(\n\tc webtorrent.DataChannelConn,\n\tdcc webtorrent.DataChannelContext,\n) {\n\tdefer c.Close()\n\tnetConn := webrtcNetConn{\n\t\tReadWriteCloser:    c,\n\t\tDataChannelContext: dcc,\n\t}\n\tpeerRemoteAddr := netConn.RemoteAddr()\n\t//t.logger.Levelf(log.Critical, \"onWebRtcConn remote addr: %v\", peerRemoteAddr)\n\tif t.cl.badPeerAddr(peerRemoteAddr) {\n\t\treturn\n\t}\n\tlocalAddrIpPort := missinggo.IpPortFromNetAddr(netConn.LocalAddr())\n\tpc, err := t.cl.initiateProtocolHandshakes(\n\t\tcontext.Background(),\n\t\tnetConn,\n\t\tt,\n\t\tfalse,\n\t\tnewConnectionOpts{\n\t\t\toutgoing:        dcc.LocalOffered,\n\t\t\tremoteAddr:      peerRemoteAddr,\n\t\t\tlocalPublicAddr: localAddrIpPort,\n\t\t\tnetwork:         webrtcNetwork,\n\t\t\tconnString:      fmt.Sprintf(\"webrtc offer_id %x: %v\", dcc.OfferId, regularNetConnPeerConnConnString(netConn)),\n\t\t},\n\t)\n\tif err != nil {\n\t\tt.logger.WithDefaultLevel(log.Error).Printf(\"error in handshaking webrtc connection: %v\", err)\n\t\treturn\n\t}\n\tif dcc.LocalOffered {\n\t\tpc.Discovery = PeerSourceTracker\n\t} else {\n\t\tpc.Discovery = PeerSourceIncoming\n\t}\n\tpc.conn.SetWriteDeadline(time.Time{})\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\terr = t.runHandshookConn(pc)\n\tif err != nil {\n\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\"error running handshook webrtc conn: %v\", err)\n\t}\n}\n\nfunc (t *Torrent) logRunHandshookConn(pc *PeerConn, logAll bool, level log.Level) {\n\terr := t.runHandshookConn(pc)\n\tif err != nil || logAll {\n\t\tt.logger.WithDefaultLevel(level).Levelf(log.ErrorLevel(err), \"error running handshook conn: %v\", err)\n\t}\n}\n\nfunc (t *Torrent) runHandshookConnLoggingErr(pc *PeerConn) {\n\tt.logRunHandshookConn(pc, false, log.Debug)\n}\n\nfunc (t *Torrent) startWebsocketAnnouncer(u url.URL, shortInfohash [20]byte) torrentTrackerAnnouncer {\n\twtc, release := t.cl.websocketTrackers.Get(u.String(), shortInfohash)\n\t// This needs to run before the Torrent is dropped from the Client, to prevent a new\n\t// webtorrent.TrackerClient for the same info hash before the old one is cleaned up.\n\tt.onClose = append(t.onClose, release)\n\twst := websocketTrackerStatus{u, wtc}\n\tgo func() {\n\t\terr := wtc.Announce(tracker.Started, shortInfohash)\n\t\tif err != nil {\n\t\t\tlevel := log.Warning\n\t\t\tif t.closed.IsSet() {\n\t\t\t\tlevel = log.Debug\n\t\t\t}\n\t\t\tt.logger.Levelf(level, \"error doing initial announce to %q: %v\", u.String(), err)\n\t\t}\n\t}()\n\treturn wst\n}\n\nfunc (t *Torrent) startScrapingTracker(_url string) {\n\tif _url == \"\" {\n\t\treturn\n\t}\n\tu, err := url.Parse(_url)\n\tif err != nil {\n\t\t// URLs with a leading '*' appear to be a uTorrent convention to disable trackers.\n\t\tif _url[0] != '*' {\n\t\t\tt.logger.Levelf(log.Warning, \"error parsing tracker url: %v\", err)\n\t\t}\n\t\treturn\n\t}\n\tif u.Scheme == \"udp\" {\n\t\tu.Scheme = \"udp4\"\n\t\tt.startScrapingTracker(u.String())\n\t\tu.Scheme = \"udp6\"\n\t\tt.startScrapingTracker(u.String())\n\t\treturn\n\t}\n\tif t.infoHash.Ok {\n\t\tt.startScrapingTrackerWithInfohash(u, _url, t.infoHash.Value)\n\t}\n\tif t.infoHashV2.Ok {\n\t\tt.startScrapingTrackerWithInfohash(u, _url, *t.infoHashV2.Value.ToShort())\n\t}\n}\n\nfunc (t *Torrent) startScrapingTrackerWithInfohash(u *url.URL, urlStr string, shortInfohash [20]byte) {\n\tannouncerKey := torrentTrackerAnnouncerKey{\n\t\tshortInfohash: shortInfohash,\n\t\turl:           urlStr,\n\t}\n\tif _, ok := t.trackerAnnouncers[announcerKey]; ok {\n\t\treturn\n\t}\n\tsl := func() torrentTrackerAnnouncer {\n\t\tswitch u.Scheme {\n\t\tcase \"ws\", \"wss\":\n\t\t\tif t.cl.config.DisableWebtorrent {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn t.startWebsocketAnnouncer(*u, shortInfohash)\n\t\tcase \"udp4\":\n\t\t\tif t.cl.config.DisableIPv4Peers || t.cl.config.DisableIPv4 {\n\t\t\t\treturn nil\n\t\t\t}\n\t\tcase \"udp6\":\n\t\t\tif t.cl.config.DisableIPv6 {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tnewAnnouncer := &trackerScraper{\n\t\t\tshortInfohash:   shortInfohash,\n\t\t\tu:               *u,\n\t\t\tt:               t,\n\t\t\tlookupTrackerIp: t.cl.config.LookupTrackerIp,\n\t\t\tstopCh:          make(chan struct{}),\n\t\t}\n\t\tgo newAnnouncer.Run()\n\t\treturn newAnnouncer\n\t}()\n\tif sl == nil {\n\t\treturn\n\t}\n\tg.MakeMapIfNil(&t.trackerAnnouncers)\n\tif g.MapInsert(t.trackerAnnouncers, announcerKey, sl).Ok {\n\t\tpanic(\"tracker announcer already exists\")\n\t}\n}\n\n// Adds and starts tracker scrapers for tracker URLs that aren't already\n// running.\nfunc (t *Torrent) startMissingTrackerScrapers() {\n\tif t.cl.config.DisableTrackers {\n\t\treturn\n\t}\n\tt.startScrapingTracker(t.metainfo.Announce)\n\tfor _, tier := range t.metainfo.AnnounceList {\n\t\tfor _, url := range tier {\n\t\t\tt.startScrapingTracker(url)\n\t\t}\n\t}\n}\n\n// Returns an AnnounceRequest with fields filled out to defaults and current\n// values.\nfunc (t *Torrent) announceRequest(\n\tevent tracker.AnnounceEvent,\n\tshortInfohash [20]byte,\n) tracker.AnnounceRequest {\n\t// Note that IPAddress is not set. It's set for UDP inside the tracker code, since it's\n\t// dependent on the network in use.\n\treturn tracker.AnnounceRequest{\n\t\tEvent: event,\n\t\tNumWant: func() int32 {\n\t\t\tif t.wantPeers() && len(t.cl.dialers) > 0 {\n\t\t\t\t// Windozer has UDP packet limit. See:\n\t\t\t\t// https://github.com/anacrolix/torrent/issues/764\n\t\t\t\treturn 200\n\t\t\t} else {\n\t\t\t\treturn 0\n\t\t\t}\n\t\t}(),\n\t\tPort:     uint16(t.cl.incomingPeerPort()),\n\t\tPeerId:   t.cl.peerID,\n\t\tInfoHash: shortInfohash,\n\t\tKey:      t.cl.announceKey(),\n\n\t\t// The following are vaguely described in BEP 3.\n\n\t\tLeft:     t.bytesLeftAnnounce(),\n\t\tUploaded: t.stats.BytesWrittenData.Int64(),\n\t\t// There's no mention of wasted or unwanted download in the BEP.\n\t\tDownloaded: t.stats.BytesReadUsefulData.Int64(),\n\t}\n}\n\n// Adds peers revealed in an announce until the announce ends, or we have\n// enough peers.\nfunc (t *Torrent) consumeDhtAnnouncePeers(pvs <-chan dht.PeersValues) {\n\tcl := t.cl\n\tfor v := range pvs {\n\t\tcl.lock()\n\t\tadded := 0\n\t\tfor _, cp := range v.Peers {\n\t\t\tif cp.Port == 0 {\n\t\t\t\t// Can't do anything with this.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif t.addPeer(PeerInfo{\n\t\t\t\tAddr:   ipPortAddr{cp.IP, cp.Port},\n\t\t\t\tSource: PeerSourceDhtGetPeers,\n\t\t\t}) {\n\t\t\t\tadded++\n\t\t\t}\n\t\t}\n\t\tcl.unlock()\n\t\t// if added != 0 {\n\t\t// \tlog.Printf(\"added %v peers from dht for %v\", added, t.InfoHash().HexString())\n\t\t// }\n\t}\n}\n\n// Announce using the provided DHT server. Peers are consumed automatically. done is closed when the\n// announce ends. stop will force the announce to end. This interface is really old-school, and\n// calls a private one that is much more modern. Both v1 and v2 info hashes are announced if they\n// exist.\nfunc (t *Torrent) AnnounceToDht(s DhtServer) (done <-chan struct{}, stop func(), err error) {\n\tvar ihs [][20]byte\n\tt.cl.lock()\n\tt.eachShortInfohash(func(short [20]byte) {\n\t\tihs = append(ihs, short)\n\t})\n\tt.cl.unlock()\n\tctx, stop := context.WithCancel(context.Background())\n\teg, ctx := errgroup.WithContext(ctx)\n\tfor _, ih := range ihs {\n\t\tvar ann DhtAnnounce\n\t\tann, err = s.Announce(ih, t.cl.incomingPeerPort(), true)\n\t\tif err != nil {\n\t\t\tstop()\n\t\t\treturn\n\t\t}\n\t\teg.Go(func() error {\n\t\t\treturn t.dhtAnnounceConsumer(ctx, ann)\n\t\t})\n\t}\n\t_done := make(chan struct{})\n\tdone = _done\n\tgo func() {\n\t\tdefer stop()\n\t\tdefer close(_done)\n\t\teg.Wait()\n\t}()\n\treturn\n}\n\n// Announce using the provided DHT server. Peers are consumed automatically. done is closed when the\n// announce ends. stop will force the announce to end.\nfunc (t *Torrent) dhtAnnounceConsumer(\n\tctx context.Context,\n\tps DhtAnnounce,\n) (\n\terr error,\n) {\n\tdefer ps.Close()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tt.consumeDhtAnnouncePeers(ps.Peers())\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn context.Cause(ctx)\n\tcase <-done:\n\t\treturn nil\n\t}\n}\n\nfunc (t *Torrent) timeboxedAnnounceToDht(s DhtServer) error {\n\t_, stop, err := t.AnnounceToDht(s)\n\tif err != nil {\n\t\treturn err\n\t}\n\tselect {\n\tcase <-t.closed.Done():\n\tcase <-time.After(5 * time.Minute):\n\t}\n\tstop()\n\treturn nil\n}\n\nfunc (t *Torrent) dhtAnnouncer(s DhtServer) {\n\tcl := t.cl\n\tcl.lock()\n\tdefer cl.unlock()\n\tfor {\n\t\tfor {\n\t\t\tif t.closed.IsSet() {\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// We're also announcing ourselves as a listener, so we don't just want peer addresses.\n\t\t\t// TODO: We can include the announce_peer step depending on whether we can receive\n\t\t\t// inbound connections. We should probably only announce once every 15 mins too.\n\t\t\tif !t.wantAnyConns() {\n\t\t\t\tgoto wait\n\t\t\t}\n\t\t\t// TODO: Determine if there's a listener on the port we're announcing.\n\t\t\tif len(cl.dialers) == 0 && len(cl.listeners) == 0 {\n\t\t\t\tgoto wait\n\t\t\t}\n\t\t\tbreak\n\t\twait:\n\t\t\tcl.event.Wait()\n\t\t}\n\t\tfunc() {\n\t\t\tt.numDHTAnnounces++\n\t\t\tcl.unlock()\n\t\t\tdefer cl.lock()\n\t\t\terr := t.timeboxedAnnounceToDht(s)\n\t\t\tif err != nil {\n\t\t\t\tt.logger.WithDefaultLevel(log.Warning).Printf(\"error announcing %q to DHT: %s\", t, err)\n\t\t\t}\n\t\t}()\n\t}\n}\n\nfunc (t *Torrent) addPeers(peers []PeerInfo) (added int) {\n\tfor _, p := range peers {\n\t\tif t.addPeer(p) {\n\t\t\tadded++\n\t\t}\n\t}\n\treturn\n}\n\n// The returned TorrentStats may require alignment in memory. See\n// https://github.com/anacrolix/torrent/issues/383.\nfunc (t *Torrent) Stats() TorrentStats {\n\tt.cl.rLock()\n\tdefer t.cl.rUnlock()\n\treturn t.statsLocked()\n}\n\nfunc (t *Torrent) statsLocked() (ret TorrentStats) {\n\tret.ActivePeers = len(t.conns)\n\tret.HalfOpenPeers = len(t.halfOpen)\n\tret.PendingPeers = t.peers.Len()\n\tret.TotalPeers = t.numTotalPeers()\n\tret.ConnectedSeeders = 0\n\tfor c := range t.conns {\n\t\tif all, ok := c.peerHasAllPieces(); all && ok {\n\t\t\tret.ConnectedSeeders++\n\t\t}\n\t}\n\tret.ConnStats = t.stats.Copy()\n\tret.PiecesComplete = t.numPiecesCompleted()\n\treturn\n}\n\n// The total number of peers in the torrent.\nfunc (t *Torrent) numTotalPeers() int {\n\tpeers := make(map[string]struct{})\n\tfor conn := range t.conns {\n\t\tra := conn.RemoteAddr\n\t\tif ra == nil {\n\t\t\t// It's been closed and doesn't support RemoteAddr.\n\t\t\tcontinue\n\t\t}\n\t\tpeers[ra.String()] = struct{}{}\n\t}\n\tfor addr := range t.halfOpen {\n\t\tpeers[addr] = struct{}{}\n\t}\n\tt.peers.Each(func(peer PeerInfo) {\n\t\tpeers[peer.Addr.String()] = struct{}{}\n\t})\n\treturn len(peers)\n}\n\n// Reconcile bytes transferred before connection was associated with a\n// torrent.\nfunc (t *Torrent) reconcileHandshakeStats(c *Peer) {\n\tif c._stats != (ConnStats{\n\t\t// Handshakes should only increment these fields:\n\t\tBytesWritten: c._stats.BytesWritten,\n\t\tBytesRead:    c._stats.BytesRead,\n\t}) {\n\t\tpanic(\"bad stats\")\n\t}\n\tc.postHandshakeStats(func(cs *ConnStats) {\n\t\tcs.BytesRead.Add(c._stats.BytesRead.Int64())\n\t\tcs.BytesWritten.Add(c._stats.BytesWritten.Int64())\n\t})\n\tc.reconciledHandshakeStats = true\n}\n\n// Returns true if the connection is added.\nfunc (t *Torrent) addPeerConn(c *PeerConn) (err error) {\n\tdefer func() {\n\t\tif err == nil {\n\t\t\ttorrent.Add(\"added connections\", 1)\n\t\t}\n\t}()\n\tif t.closed.IsSet() {\n\t\treturn errors.New(\"torrent closed\")\n\t}\n\tfor c0 := range t.conns {\n\t\tif c.PeerID != c0.PeerID {\n\t\t\tcontinue\n\t\t}\n\t\tif !t.cl.config.DropDuplicatePeerIds {\n\t\t\tcontinue\n\t\t}\n\t\tif c.hasPreferredNetworkOver(c0) {\n\t\t\tc0.close()\n\t\t\tt.deletePeerConn(c0)\n\t\t} else {\n\t\t\treturn errors.New(\"existing connection preferred\")\n\t\t}\n\t}\n\tif len(t.conns) >= t.maxEstablishedConns {\n\t\tnumOutgoing := t.numOutgoingConns()\n\t\tnumIncoming := len(t.conns) - numOutgoing\n\t\tc := t.worstBadConn(worseConnLensOpts{\n\t\t\t// We've already established that we have too many connections at this point, so we just\n\t\t\t// need to match what kind we have too many of vs. what we're trying to add now.\n\t\t\tincomingIsBad: (numIncoming-numOutgoing > 1) && c.outgoing,\n\t\t\toutgoingIsBad: (numOutgoing-numIncoming > 1) && !c.outgoing,\n\t\t})\n\t\tif c == nil {\n\t\t\treturn errors.New(\"don't want conn\")\n\t\t}\n\t\tc.close()\n\t\tt.deletePeerConn(c)\n\t}\n\tif len(t.conns) >= t.maxEstablishedConns {\n\t\tpanic(len(t.conns))\n\t}\n\tt.conns[c] = struct{}{}\n\tt.cl.event.Broadcast()\n\t// We'll never receive the \"p\" extended handshake parameter.\n\tif !t.cl.config.DisablePEX && !c.PeerExtensionBytes.SupportsExtended() {\n\t\tt.pex.Add(c)\n\t}\n\treturn nil\n}\n\nfunc (t *Torrent) newConnsAllowed() bool {\n\tif !t.networkingEnabled.Bool() {\n\t\treturn false\n\t}\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif !t.needData() && (!t.seeding() || !t.haveAnyPieces()) {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (t *Torrent) wantAnyConns() bool {\n\tif !t.networkingEnabled.Bool() {\n\t\treturn false\n\t}\n\tif t.closed.IsSet() {\n\t\treturn false\n\t}\n\tif !t.needData() && (!t.seeding() || !t.haveAnyPieces()) {\n\t\treturn false\n\t}\n\treturn len(t.conns) < t.maxEstablishedConns\n}\n\nfunc (t *Torrent) wantOutgoingConns() bool {\n\tif !t.newConnsAllowed() {\n\t\treturn false\n\t}\n\tif len(t.conns) < t.maxEstablishedConns {\n\t\treturn true\n\t}\n\tnumIncomingConns := len(t.conns) - t.numOutgoingConns()\n\treturn t.worstBadConn(worseConnLensOpts{\n\t\tincomingIsBad: numIncomingConns-t.numOutgoingConns() > 1,\n\t\toutgoingIsBad: false,\n\t}) != nil\n}\n\nfunc (t *Torrent) wantIncomingConns() bool {\n\tif !t.newConnsAllowed() {\n\t\treturn false\n\t}\n\tif len(t.conns) < t.maxEstablishedConns {\n\t\treturn true\n\t}\n\tnumIncomingConns := len(t.conns) - t.numOutgoingConns()\n\treturn t.worstBadConn(worseConnLensOpts{\n\t\tincomingIsBad: false,\n\t\toutgoingIsBad: t.numOutgoingConns()-numIncomingConns > 1,\n\t}) != nil\n}\n\nfunc (t *Torrent) SetMaxEstablishedConns(max int) (oldMax int) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\toldMax = t.maxEstablishedConns\n\tt.maxEstablishedConns = max\n\twcs := worseConnSlice{\n\t\tconns: t.appendConns(nil, func(*PeerConn) bool {\n\t\t\treturn true\n\t\t}),\n\t}\n\twcs.initKeys(worseConnLensOpts{})\n\theap.Init(&wcs)\n\tfor len(t.conns) > t.maxEstablishedConns && wcs.Len() > 0 {\n\t\tt.dropConnection(heap.Pop(&wcs).(*PeerConn))\n\t}\n\tt.openNewConns()\n\treturn oldMax\n}\n\nfunc (t *Torrent) pieceHashed(piece pieceIndex, passed bool, hashIoErr error) {\n\tt.logger.LazyLog(log.Debug, func() log.Msg {\n\t\treturn log.Fstr(\"hashed piece %d (passed=%t)\", piece, passed)\n\t})\n\tp := t.piece(piece)\n\tp.numVerifies++\n\tt.cl.event.Broadcast()\n\tif t.closed.IsSet() {\n\t\treturn\n\t}\n\n\t// Don't score the first time a piece is hashed, it could be an initial check.\n\tif p.storageCompletionOk {\n\t\tif passed {\n\t\t\tpieceHashedCorrect.Add(1)\n\t\t} else {\n\t\t\tlog.Fmsg(\n\t\t\t\t\"piece %d failed hash: %d connections contributed\", piece, len(p.dirtiers),\n\t\t\t).AddValues(t, p).LogLevel(log.Info, t.logger)\n\t\t\tpieceHashedNotCorrect.Add(1)\n\t\t}\n\t}\n\n\tp.marking = true\n\tt.publishPieceStateChange(piece)\n\tdefer func() {\n\t\tp.marking = false\n\t\tt.publishPieceStateChange(piece)\n\t}()\n\n\tif passed {\n\t\tif len(p.dirtiers) != 0 {\n\t\t\t// Don't increment stats above connection-level for every involved connection.\n\t\t\tt.allStats((*ConnStats).incrementPiecesDirtiedGood)\n\t\t}\n\t\tfor c := range p.dirtiers {\n\t\t\tc._stats.incrementPiecesDirtiedGood()\n\t\t}\n\t\tt.clearPieceTouchers(piece)\n\t\thasDirty := p.hasDirtyChunks()\n\t\tt.cl.unlock()\n\t\tif hasDirty {\n\t\t\tp.Flush() // You can be synchronous here!\n\t\t}\n\t\terr := p.Storage().MarkComplete()\n\t\tif err != nil {\n\t\t\tt.logger.Levelf(log.Warning, \"%T: error marking piece complete %d: %s\", t.storage, piece, err)\n\t\t}\n\t\tt.cl.lock()\n\n\t\tif t.closed.IsSet() {\n\t\t\treturn\n\t\t}\n\t\tt.pendAllChunkSpecs(piece)\n\t} else {\n\t\tif len(p.dirtiers) != 0 && p.allChunksDirty() && hashIoErr == nil {\n\t\t\t// Peers contributed to all the data for this piece hash failure, and the failure was\n\t\t\t// not due to errors in the storage (such as data being dropped in a cache).\n\n\t\t\t// Increment Torrent and above stats, and then specific connections.\n\t\t\tt.allStats((*ConnStats).incrementPiecesDirtiedBad)\n\t\t\tfor c := range p.dirtiers {\n\t\t\t\t// Y u do dis peer?!\n\t\t\t\tc.stats().incrementPiecesDirtiedBad()\n\t\t\t}\n\n\t\t\tbannableTouchers := make([]*Peer, 0, len(p.dirtiers))\n\t\t\tfor c := range p.dirtiers {\n\t\t\t\tif !c.trusted {\n\t\t\t\t\tbannableTouchers = append(bannableTouchers, c)\n\t\t\t\t}\n\t\t\t}\n\t\t\tt.clearPieceTouchers(piece)\n\t\t\tslices.SortFunc(bannableTouchers, comparePeerTrust)\n\n\t\t\tif t.cl.config.Debug {\n\t\t\t\tt.logger.Printf(\n\t\t\t\t\t\"bannable conns by trust for piece %d: %v\",\n\t\t\t\t\tpiece,\n\t\t\t\t\tfunc() (ret []connectionTrust) {\n\t\t\t\t\t\tfor _, c := range bannableTouchers {\n\t\t\t\t\t\t\tret = append(ret, c.trust())\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}(),\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tif len(bannableTouchers) >= 1 {\n\t\t\t\tc := bannableTouchers[0]\n\t\t\t\tif len(bannableTouchers) != 1 {\n\t\t\t\t\tt.logger.Levelf(log.Debug, \"would have banned %v for touching piece %v after failed piece check\", c.remoteIp(), piece)\n\t\t\t\t} else {\n\t\t\t\t\t// Turns out it's still useful to ban peers like this because if there's only a\n\t\t\t\t\t// single peer for a piece, and we never progress that piece to completion, we\n\t\t\t\t\t// will never smart-ban them. Discovered in\n\t\t\t\t\t// https://github.com/anacrolix/torrent/issues/715.\n\t\t\t\t\tt.logger.Levelf(\n\t\t\t\t\t\tlog.Warning,\n\t\t\t\t\t\t\"banning %v for being sole dirtier of piece %v after failed piece check\",\n\t\t\t\t\t\tc,\n\t\t\t\t\t\tpiece,\n\t\t\t\t\t)\n\t\t\t\t\tc.ban()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tt.onIncompletePiece(piece)\n\t\tp.Storage().MarkNotComplete()\n\t}\n\tt.updatePieceCompletion(piece)\n}\n\nfunc (t *Torrent) cancelRequestsForPiece(piece pieceIndex) {\n\tstart := t.pieceRequestIndexOffset(piece)\n\tend := start + t.pieceNumChunks(piece)\n\tfor ri := start; ri < end; ri++ {\n\t\tt.cancelRequest(ri)\n\t}\n}\n\nfunc (t *Torrent) onPieceCompleted(piece pieceIndex) {\n\tt.pendAllChunkSpecs(piece)\n\tt.cancelRequestsForPiece(piece)\n\tt.piece(piece).readerCond.Broadcast()\n\tfor conn := range t.conns {\n\t\tconn.have(piece)\n\t\tt.maybeDropMutuallyCompletePeer(conn)\n\t}\n}\n\n// Called when a piece is found to be not complete.\nfunc (t *Torrent) onIncompletePiece(piece pieceIndex) {\n\tif t.pieceAllDirty(piece) {\n\t\tt.pendAllChunkSpecs(piece)\n\t}\n\tif !t.wantPieceIndex(piece) {\n\t\t// t.logger.Printf(\"piece %d incomplete and unwanted\", piece)\n\t\treturn\n\t}\n\t// We could drop any connections that we told we have a piece that we\n\t// don't here. But there's a test failure, and it seems clients don't care\n\t// if you request pieces that you already claim to have. Pruning bad\n\t// connections might just remove any connections that aren't treating us\n\t// favourably anyway.\n\n\t// for c := range t.conns {\n\t// \tif c.sentHave(piece) {\n\t// \t\tc.drop()\n\t// \t}\n\t// }\n\tt.iterPeers(func(conn *Peer) {\n\t\tif conn.peerHasPiece(piece) {\n\t\t\tconn.updateRequests(\"piece incomplete\")\n\t\t}\n\t})\n}\n\nfunc (t *Torrent) tryCreateMorePieceHashers() {\n\tfor !t.closed.IsSet() && t.activePieceHashes < t.cl.config.PieceHashersPerTorrent && t.tryCreatePieceHasher() {\n\t}\n}\n\nfunc (t *Torrent) tryCreatePieceHasher() bool {\n\tif t.storage == nil {\n\t\treturn false\n\t}\n\tpi, ok := t.getPieceToHash()\n\tif !ok {\n\t\treturn false\n\t}\n\tp := t.piece(pi)\n\tt.piecesQueuedForHash.Remove(bitmap.BitIndex(pi))\n\tp.hashing = true\n\tt.publishPieceStateChange(pi)\n\tt.updatePiecePriority(pi, \"Torrent.tryCreatePieceHasher\")\n\tt.storageLock.RLock()\n\tt.activePieceHashes++\n\tgo t.pieceHasher(pi)\n\treturn true\n}\n\nfunc (t *Torrent) getPieceToHash() (ret pieceIndex, ok bool) {\n\tt.piecesQueuedForHash.IterTyped(func(i pieceIndex) bool {\n\t\tif t.piece(i).hashing {\n\t\t\treturn true\n\t\t}\n\t\tret = i\n\t\tok = true\n\t\treturn false\n\t})\n\treturn\n}\n\nfunc (t *Torrent) dropBannedPeers() {\n\tt.iterPeers(func(p *Peer) {\n\t\tremoteIp := p.remoteIp()\n\t\tif remoteIp == nil {\n\t\t\tif p.bannableAddr.Ok {\n\t\t\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\"can't get remote ip for peer %v\", p)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tnetipAddr := netip.MustParseAddr(remoteIp.String())\n\t\tif Some(netipAddr) != p.bannableAddr {\n\t\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\n\t\t\t\t\"peer remote ip does not match its bannable addr [peer=%v, remote ip=%v, bannable addr=%v]\",\n\t\t\t\tp, remoteIp, p.bannableAddr)\n\t\t}\n\t\tif _, ok := t.cl.badPeerIPs[netipAddr]; ok {\n\t\t\t// Should this be a close?\n\t\t\tp.drop()\n\t\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\"dropped %v for banned remote IP %v\", p, netipAddr)\n\t\t}\n\t})\n}\n\nfunc (t *Torrent) pieceHasher(index pieceIndex) {\n\tp := t.piece(index)\n\t// Do we really need to spell out that it's a copy error? If it's a failure to hash the hash\n\t// will just be wrong.\n\tcorrect, failedPeers, copyErr := t.hashPiece(index)\n\tswitch copyErr {\n\tcase nil, io.EOF:\n\tdefault:\n\t\tt.logger.WithNames(\"hashing\").Levelf(\n\t\t\tlog.Warning,\n\t\t\t\"error hashing piece %v: %v\", index, copyErr)\n\t}\n\tt.storageLock.RUnlock()\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tif correct {\n\t\tfor peer := range failedPeers {\n\t\t\tt.cl.banPeerIP(peer.AsSlice())\n\t\t\tt.logger.WithDefaultLevel(log.Debug).Printf(\"smart banned %v for piece %v\", peer, index)\n\t\t}\n\t\tt.dropBannedPeers()\n\t\tfor ri := t.pieceRequestIndexOffset(index); ri < t.pieceRequestIndexOffset(index+1); ri++ {\n\t\t\tt.smartBanCache.ForgetBlock(ri)\n\t\t}\n\t}\n\tp.hashing = false\n\tt.pieceHashed(index, correct, copyErr)\n\tt.updatePiecePriority(index, \"Torrent.pieceHasher\")\n\tt.activePieceHashes--\n\tt.tryCreateMorePieceHashers()\n}\n\n// Return the connections that touched a piece, and clear the entries while doing it.\nfunc (t *Torrent) clearPieceTouchers(pi pieceIndex) {\n\tp := t.piece(pi)\n\tfor c := range p.dirtiers {\n\t\tdelete(c.peerTouchedPieces, pi)\n\t\tdelete(p.dirtiers, c)\n\t}\n}\n\nfunc (t *Torrent) peersAsSlice() (ret []*Peer) {\n\tt.iterPeers(func(p *Peer) {\n\t\tret = append(ret, p)\n\t})\n\treturn\n}\n\nfunc (t *Torrent) queueInitialPieceCheck(i pieceIndex) {\n\tif !t.initialPieceCheckDisabled && !t.piece(i).storageCompletionOk {\n\t\tt.queuePieceCheck(i)\n\t}\n}\n\nfunc (t *Torrent) queuePieceCheck(pieceIndex pieceIndex) {\n\tpiece := t.piece(pieceIndex)\n\tif !piece.haveHash() {\n\t\treturn\n\t}\n\tif piece.queuedForHash() {\n\t\treturn\n\t}\n\tt.piecesQueuedForHash.Add(bitmap.BitIndex(pieceIndex))\n\tt.publishPieceStateChange(pieceIndex)\n\tt.updatePiecePriority(pieceIndex, \"Torrent.queuePieceCheck\")\n\tt.tryCreateMorePieceHashers()\n}\n\n// Forces all the pieces to be re-hashed. See also Piece.VerifyData. This should not be called\n// before the Info is available.\nfunc (t *Torrent) VerifyData() {\n\tfor i := pieceIndex(0); i < t.NumPieces(); i++ {\n\t\tt.Piece(i).VerifyData()\n\t}\n}\n\nfunc (t *Torrent) connectingToPeerAddr(addrStr string) bool {\n\treturn len(t.halfOpen[addrStr]) != 0\n}\n\nfunc (t *Torrent) hasPeerConnForAddr(x PeerRemoteAddr) bool {\n\taddrStr := x.String()\n\tfor c := range t.conns {\n\t\tra := c.RemoteAddr\n\t\tif ra.String() == addrStr {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (t *Torrent) getHalfOpenPath(\n\taddrStr string,\n\tattemptKey outgoingConnAttemptKey,\n) nestedmaps.Path[*PeerInfo] {\n\treturn nestedmaps.Next(nestedmaps.Next(nestedmaps.Begin(&t.halfOpen), addrStr), attemptKey)\n}\n\nfunc (t *Torrent) addHalfOpen(addrStr string, attemptKey *PeerInfo) {\n\tpath := t.getHalfOpenPath(addrStr, attemptKey)\n\tif path.Exists() {\n\t\tpanic(\"should be unique\")\n\t}\n\tpath.Set(attemptKey)\n\tt.cl.numHalfOpen++\n}\n\n// Start the process of connecting to the given peer for the given torrent if appropriate. I'm not\n// sure all the PeerInfo fields are being used.\nfunc initiateConn(\n\topts outgoingConnOpts,\n\tignoreLimits bool,\n) {\n\tt := opts.t\n\tpeer := opts.peerInfo\n\tif peer.Id == t.cl.peerID {\n\t\treturn\n\t}\n\tif t.cl.badPeerAddr(peer.Addr) && !peer.Trusted {\n\t\treturn\n\t}\n\taddr := peer.Addr\n\taddrStr := addr.String()\n\tif !ignoreLimits {\n\t\tif t.connectingToPeerAddr(addrStr) {\n\t\t\treturn\n\t\t}\n\t}\n\tif t.hasPeerConnForAddr(addr) {\n\t\treturn\n\t}\n\tattemptKey := &peer\n\tt.addHalfOpen(addrStr, attemptKey)\n\tgo t.cl.outgoingConnection(\n\t\topts,\n\t\tattemptKey,\n\t)\n}\n\n// Adds a trusted, pending peer for each of the given Client's addresses. Typically used in tests to\n// quickly make one Client visible to the Torrent of another Client.\nfunc (t *Torrent) AddClientPeer(cl *Client) int {\n\treturn t.AddPeers(func() (ps []PeerInfo) {\n\t\tfor _, la := range cl.ListenAddrs() {\n\t\t\tps = append(ps, PeerInfo{\n\t\t\t\tAddr:    la,\n\t\t\t\tTrusted: true,\n\t\t\t})\n\t\t}\n\t\treturn\n\t}())\n}\n\n// All stats that include this Torrent. Useful when we want to increment ConnStats but not for every\n// connection.\nfunc (t *Torrent) allStats(f func(*ConnStats)) {\n\tf(&t.stats)\n\tf(&t.cl.connStats)\n}\n\nfunc (t *Torrent) hashingPiece(i pieceIndex) bool {\n\treturn t.pieces[i].hashing\n}\n\nfunc (t *Torrent) pieceQueuedForHash(i pieceIndex) bool {\n\treturn t.piecesQueuedForHash.Get(bitmap.BitIndex(i))\n}\n\nfunc (t *Torrent) dialTimeout() time.Duration {\n\treturn reducedDialTimeout(t.cl.config.MinDialTimeout, t.cl.config.NominalDialTimeout, t.cl.config.HalfOpenConnsPerTorrent, t.peers.Len())\n}\n\nfunc (t *Torrent) piece(i int) *Piece {\n\treturn &t.pieces[i]\n}\n\nfunc (t *Torrent) onWriteChunkErr(err error) {\n\tif t.userOnWriteChunkErr != nil {\n\t\tgo t.userOnWriteChunkErr(err)\n\t\treturn\n\t}\n\tt.logger.WithDefaultLevel(log.Critical).Printf(\"default chunk write error handler: disabling data download\")\n\tt.disallowDataDownloadLocked()\n}\n\nfunc (t *Torrent) DisallowDataDownload() {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.disallowDataDownloadLocked()\n}\n\nfunc (t *Torrent) disallowDataDownloadLocked() {\n\tt.dataDownloadDisallowed.Set()\n\tt.iterPeers(func(p *Peer) {\n\t\t// Could check if peer request state is empty/not interested?\n\t\tp.updateRequests(\"disallow data download\")\n\t\tp.cancelAllRequests()\n\t})\n}\n\nfunc (t *Torrent) AllowDataDownload() {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.dataDownloadDisallowed.Clear()\n\tt.iterPeers(func(p *Peer) {\n\t\tp.updateRequests(\"allow data download\")\n\t})\n}\n\n// Enables uploading data, if it was disabled.\nfunc (t *Torrent) AllowDataUpload() {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.dataUploadDisallowed = false\n\tt.iterPeers(func(p *Peer) {\n\t\tp.updateRequests(\"allow data upload\")\n\t})\n}\n\n// Disables uploading data, if it was enabled.\nfunc (t *Torrent) DisallowDataUpload() {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.dataUploadDisallowed = true\n\tfor c := range t.conns {\n\t\t// TODO: This doesn't look right. Shouldn't we tickle writers to choke peers or something instead?\n\t\tc.updateRequests(\"disallow data upload\")\n\t}\n}\n\n// Sets a handler that is called if there's an error writing a chunk to local storage. By default,\n// or if nil, a critical message is logged, and data download is disabled.\nfunc (t *Torrent) SetOnWriteChunkError(f func(error)) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tt.userOnWriteChunkErr = f\n}\n\nfunc (t *Torrent) iterPeers(f func(p *Peer)) {\n\tfor pc := range t.conns {\n\t\tf(&pc.Peer)\n\t}\n\tfor _, ws := range t.webSeeds {\n\t\tf(ws)\n\t}\n}\n\nfunc (t *Torrent) callbacks() *Callbacks {\n\treturn &t.cl.config.Callbacks\n}\n\ntype AddWebSeedsOpt func(*webseed.Client)\n\n// Sets the WebSeed trailing path escaper for a webseed.Client.\nfunc WebSeedPathEscaper(custom webseed.PathEscaper) AddWebSeedsOpt {\n\treturn func(c *webseed.Client) {\n\t\tc.PathEscaper = custom\n\t}\n}\n\nfunc (t *Torrent) AddWebSeeds(urls []string, opts ...AddWebSeedsOpt) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tfor _, u := range urls {\n\t\tt.addWebSeed(u, opts...)\n\t}\n}\n\nfunc (t *Torrent) addWebSeed(url string, opts ...AddWebSeedsOpt) {\n\tif t.cl.config.DisableWebseeds {\n\t\treturn\n\t}\n\tif _, ok := t.webSeeds[url]; ok {\n\t\treturn\n\t}\n\t// I don't think Go http supports pipelining requests. However, we can have more ready to go\n\t// right away. This value should be some multiple of the number of connections to a host. I\n\t// would expect that double maxRequests plus a bit would be appropriate. This value is based on\n\t// downloading Sintel (08ada5a7a6183aae1e09d831df6748d566095a10) from\n\t// \"https://webtorrent.io/torrents/\".\n\tconst maxRequests = 16\n\tws := webseedPeer{\n\t\tpeer: Peer{\n\t\t\tt:                        t,\n\t\t\toutgoing:                 true,\n\t\t\tNetwork:                  \"http\",\n\t\t\treconciledHandshakeStats: true,\n\t\t\t// This should affect how often we have to recompute requests for this peer. Note that\n\t\t\t// because we can request more than 1 thing at a time over HTTP, we will hit the low\n\t\t\t// requests mark more often, so recomputation is probably sooner than with regular peer\n\t\t\t// conns. ~4x maxRequests would be about right.\n\t\t\tPeerMaxRequests: 128,\n\t\t\t// TODO: Set ban prefix?\n\t\t\tRemoteAddr: remoteAddrFromUrl(url),\n\t\t\tcallbacks:  t.callbacks(),\n\t\t},\n\t\tclient: webseed.Client{\n\t\t\tHttpClient: t.cl.httpClient,\n\t\t\tUrl:        url,\n\t\t\tResponseBodyWrapper: func(r io.Reader) io.Reader {\n\t\t\t\treturn &rateLimitedReader{\n\t\t\t\t\tl: t.cl.config.DownloadRateLimiter,\n\t\t\t\t\tr: r,\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t\tactiveRequests: make(map[Request]webseed.Request, maxRequests),\n\t}\n\tws.peer.initRequestState()\n\tfor _, opt := range opts {\n\t\topt(&ws.client)\n\t}\n\tws.peer.initUpdateRequestsTimer()\n\tws.requesterCond.L = t.cl.locker()\n\tfor i := 0; i < maxRequests; i += 1 {\n\t\tgo ws.requester(i)\n\t}\n\tfor _, f := range t.callbacks().NewPeer {\n\t\tf(&ws.peer)\n\t}\n\tws.peer.logger = t.logger.WithContextValue(&ws).WithNames(\"webseed\")\n\tws.peer.peerImpl = &ws\n\tif t.haveInfo() {\n\t\tws.onGotInfo(t.info)\n\t}\n\tt.webSeeds[url] = &ws.peer\n\tws.peer.updateRequests(\"Torrent.addWebSeed\")\n}\n\nfunc (t *Torrent) peerIsActive(p *Peer) (active bool) {\n\tt.iterPeers(func(p1 *Peer) {\n\t\tif p1 == p {\n\t\t\tactive = true\n\t\t}\n\t})\n\treturn\n}\n\nfunc (t *Torrent) requestIndexToRequest(ri RequestIndex) Request {\n\tindex := t.pieceIndexOfRequestIndex(ri)\n\treturn Request{\n\t\tpp.Integer(index),\n\t\tt.piece(index).chunkIndexSpec(ri % t.chunksPerRegularPiece()),\n\t}\n}\n\nfunc (t *Torrent) requestIndexFromRequest(r Request) RequestIndex {\n\treturn t.pieceRequestIndexOffset(pieceIndex(r.Index)) + RequestIndex(r.Begin/t.chunkSize)\n}\n\nfunc (t *Torrent) pieceRequestIndexOffset(piece pieceIndex) RequestIndex {\n\treturn RequestIndex(piece) * t.chunksPerRegularPiece()\n}\n\nfunc (t *Torrent) updateComplete() {\n\tt.complete.SetBool(t.haveAllPieces())\n}\n\nfunc (t *Torrent) cancelRequest(r RequestIndex) *Peer {\n\tp := t.requestingPeer(r)\n\tif p != nil {\n\t\tp.cancel(r)\n\t}\n\t// TODO: This is a check that an old invariant holds. It can be removed after some testing.\n\t//delete(t.pendingRequests, r)\n\tif _, ok := t.requestState[r]; ok {\n\t\tpanic(\"expected request state to be gone\")\n\t}\n\treturn p\n}\n\nfunc (t *Torrent) requestingPeer(r RequestIndex) *Peer {\n\treturn t.requestState[r].peer\n}\n\nfunc (t *Torrent) addConnWithAllPieces(p *Peer) {\n\tif t.connsWithAllPieces == nil {\n\t\tt.connsWithAllPieces = make(map[*Peer]struct{}, t.maxEstablishedConns)\n\t}\n\tt.connsWithAllPieces[p] = struct{}{}\n}\n\nfunc (t *Torrent) deleteConnWithAllPieces(p *Peer) bool {\n\t_, ok := t.connsWithAllPieces[p]\n\tdelete(t.connsWithAllPieces, p)\n\treturn ok\n}\n\nfunc (t *Torrent) numActivePeers() int {\n\treturn len(t.conns) + len(t.webSeeds)\n}\n\nfunc (t *Torrent) hasStorageCap() bool {\n\tf := t.storage.Capacity\n\tif f == nil {\n\t\treturn false\n\t}\n\t_, ok := (*f)()\n\treturn ok\n}\n\nfunc (t *Torrent) pieceIndexOfRequestIndex(ri RequestIndex) pieceIndex {\n\treturn pieceIndex(ri / t.chunksPerRegularPiece())\n}\n\nfunc (t *Torrent) iterUndirtiedRequestIndexesInPiece(\n\treuseIter *typedRoaring.Iterator[RequestIndex],\n\tpiece pieceIndex,\n\tf func(RequestIndex),\n) {\n\treuseIter.Initialize(&t.dirtyChunks)\n\tpieceRequestIndexOffset := t.pieceRequestIndexOffset(piece)\n\titerBitmapUnsetInRange(\n\t\treuseIter,\n\t\tpieceRequestIndexOffset, pieceRequestIndexOffset+t.pieceNumChunks(piece),\n\t\tf,\n\t)\n}\n\ntype webRtcStatsReports map[string]webrtc.StatsReport\n\nfunc (t *Torrent) GetWebRtcPeerConnStats() map[string]webRtcStatsReports {\n\tstats := make(map[string]webRtcStatsReports)\n\ttrackersMap := t.cl.websocketTrackers.clients\n\tfor i, trackerClient := range trackersMap {\n\t\tts := trackerClient.RtcPeerConnStats()\n\t\tstats[i] = ts\n\t}\n\treturn stats\n}\n\ntype requestState struct {\n\tpeer *Peer\n\twhen time.Time\n}\n\n// Returns an error if a received chunk is out of bounds in someway.\nfunc (t *Torrent) checkValidReceiveChunk(r Request) error {\n\tif !t.haveInfo() {\n\t\treturn errors.New(\"torrent missing info\")\n\t}\n\tif int(r.Index) >= t.numPieces() {\n\t\treturn fmt.Errorf(\"chunk index %v, torrent num pieces %v\", r.Index, t.numPieces())\n\t}\n\tpieceLength := t.pieceLength(pieceIndex(r.Index))\n\tif r.Begin >= pieceLength {\n\t\treturn fmt.Errorf(\"chunk begins beyond end of piece (%v >= %v)\", r.Begin, pieceLength)\n\t}\n\t// We could check chunk lengths here, but chunk request size is not changed often, and tricky\n\t// for peers to manipulate as they need to send potentially large buffers to begin with. There\n\t// should be considerable checks elsewhere for this case due to the network overhead. We should\n\t// catch most of the overflow manipulation stuff by checking index and begin above.\n\treturn nil\n}\n\nfunc (t *Torrent) peerConnsWithDialAddrPort(target netip.AddrPort) (ret []*PeerConn) {\n\tfor pc := range t.conns {\n\t\tdialAddr, err := pc.remoteDialAddrPort()\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif dialAddr != target {\n\t\t\tcontinue\n\t\t}\n\t\tret = append(ret, pc)\n\t}\n\treturn\n}\n\nfunc wrapUtHolepunchMsgForPeerConn(\n\trecipient *PeerConn,\n\tmsg utHolepunch.Msg,\n) pp.Message {\n\textendedPayload, err := msg.MarshalBinary()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn pp.Message{\n\t\tType:            pp.Extended,\n\t\tExtendedID:      MapMustGet(recipient.PeerExtensionIDs, utHolepunch.ExtensionName),\n\t\tExtendedPayload: extendedPayload,\n\t}\n}\n\nfunc sendUtHolepunchMsg(\n\tpc *PeerConn,\n\tmsgType utHolepunch.MsgType,\n\taddrPort netip.AddrPort,\n\terrCode utHolepunch.ErrCode,\n) {\n\tholepunchMsg := utHolepunch.Msg{\n\t\tMsgType:  msgType,\n\t\tAddrPort: addrPort,\n\t\tErrCode:  errCode,\n\t}\n\tincHolepunchMessagesSent(holepunchMsg)\n\tppMsg := wrapUtHolepunchMsgForPeerConn(pc, holepunchMsg)\n\tpc.write(ppMsg)\n}\n\nfunc incHolepunchMessages(msg utHolepunch.Msg, verb string) {\n\ttorrent.Add(\n\t\tfmt.Sprintf(\n\t\t\t\"holepunch %v %v messages %v\",\n\t\t\tmsg.MsgType,\n\t\t\taddrPortProtocolStr(msg.AddrPort),\n\t\t\tverb,\n\t\t),\n\t\t1,\n\t)\n}\n\nfunc incHolepunchMessagesReceived(msg utHolepunch.Msg) {\n\tincHolepunchMessages(msg, \"received\")\n}\n\nfunc incHolepunchMessagesSent(msg utHolepunch.Msg) {\n\tincHolepunchMessages(msg, \"sent\")\n}\n\nfunc (t *Torrent) handleReceivedUtHolepunchMsg(msg utHolepunch.Msg, sender *PeerConn) error {\n\tincHolepunchMessagesReceived(msg)\n\tswitch msg.MsgType {\n\tcase utHolepunch.Rendezvous:\n\t\tt.logger.Printf(\"got holepunch rendezvous request for %v from %p\", msg.AddrPort, sender)\n\t\tsendMsg := sendUtHolepunchMsg\n\t\tsenderAddrPort, err := sender.remoteDialAddrPort()\n\t\tif err != nil {\n\t\t\tsender.logger.Levelf(\n\t\t\t\tlog.Warning,\n\t\t\t\t\"error getting ut_holepunch rendezvous sender's dial address: %v\",\n\t\t\t\terr,\n\t\t\t)\n\t\t\t// There's no better error code. The sender's address itself is invalid. I don't see\n\t\t\t// this error message being appropriate anywhere else anyway.\n\t\t\tsendMsg(sender, utHolepunch.Error, msg.AddrPort, utHolepunch.NoSuchPeer)\n\t\t}\n\t\ttargets := t.peerConnsWithDialAddrPort(msg.AddrPort)\n\t\tif len(targets) == 0 {\n\t\t\tsendMsg(sender, utHolepunch.Error, msg.AddrPort, utHolepunch.NotConnected)\n\t\t\treturn nil\n\t\t}\n\t\tfor _, pc := range targets {\n\t\t\tif !pc.supportsExtension(utHolepunch.ExtensionName) {\n\t\t\t\tsendMsg(sender, utHolepunch.Error, msg.AddrPort, utHolepunch.NoSupport)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tsendMsg(sender, utHolepunch.Connect, msg.AddrPort, 0)\n\t\t\tsendMsg(pc, utHolepunch.Connect, senderAddrPort, 0)\n\t\t}\n\t\treturn nil\n\tcase utHolepunch.Connect:\n\t\tholepunchAddr := msg.AddrPort\n\t\tt.logger.Printf(\"got holepunch connect request for %v from %p\", holepunchAddr, sender)\n\t\tif g.MapContains(t.cl.undialableWithoutHolepunch, holepunchAddr) {\n\t\t\tsetAdd(&t.cl.undialableWithoutHolepunchDialedAfterHolepunchConnect, holepunchAddr)\n\t\t\tif g.MapContains(t.cl.accepted, holepunchAddr) {\n\t\t\t\tsetAdd(&t.cl.probablyOnlyConnectedDueToHolepunch, holepunchAddr)\n\t\t\t}\n\t\t}\n\t\topts := outgoingConnOpts{\n\t\t\tpeerInfo: PeerInfo{\n\t\t\t\tAddr:         msg.AddrPort,\n\t\t\t\tSource:       PeerSourceUtHolepunch,\n\t\t\t\tPexPeerFlags: sender.pex.remoteLiveConns[msg.AddrPort].UnwrapOrZeroValue(),\n\t\t\t},\n\t\t\tt: t,\n\t\t\t// Don't attempt to start our own rendezvous if we fail to connect.\n\t\t\tskipHolepunchRendezvous:  true,\n\t\t\treceivedHolepunchConnect: true,\n\t\t\t// Assume that the other end initiated the rendezvous, and will use our preferred\n\t\t\t// encryption. So we will act normally.\n\t\t\tHeaderObfuscationPolicy: t.cl.config.HeaderObfuscationPolicy,\n\t\t}\n\t\tinitiateConn(opts, true)\n\t\treturn nil\n\tcase utHolepunch.Error:\n\t\ttorrent.Add(\"holepunch error messages received\", 1)\n\t\tt.logger.Levelf(log.Debug, \"received ut_holepunch error message from %v: %v\", sender, msg.ErrCode)\n\t\treturn nil\n\tdefault:\n\t\treturn fmt.Errorf(\"unhandled msg type %v\", msg.MsgType)\n\t}\n}\n\nfunc addrPortProtocolStr(addrPort netip.AddrPort) string {\n\taddr := addrPort.Addr()\n\tswitch {\n\tcase addr.Is4():\n\t\treturn \"ipv4\"\n\tcase addr.Is6():\n\t\treturn \"ipv6\"\n\tdefault:\n\t\tpanic(addrPort)\n\t}\n}\n\nfunc (t *Torrent) trySendHolepunchRendezvous(addrPort netip.AddrPort) error {\n\trzsSent := 0\n\tfor pc := range t.conns {\n\t\tif !pc.supportsExtension(utHolepunch.ExtensionName) {\n\t\t\tcontinue\n\t\t}\n\t\tif pc.supportsExtension(pp.ExtensionNamePex) {\n\t\t\tif !g.MapContains(pc.pex.remoteLiveConns, addrPort) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tt.logger.Levelf(log.Debug, \"sent ut_holepunch rendezvous message to %v for %v\", pc, addrPort)\n\t\tsendUtHolepunchMsg(pc, utHolepunch.Rendezvous, addrPort, 0)\n\t\trzsSent++\n\t}\n\tif rzsSent == 0 {\n\t\treturn errors.New(\"no eligible relays\")\n\t}\n\treturn nil\n}\n\nfunc (t *Torrent) numHalfOpenAttempts() (num int) {\n\tfor _, attempts := range t.halfOpen {\n\t\tnum += len(attempts)\n\t}\n\treturn\n}\n\nfunc (t *Torrent) getDialTimeoutUnlocked() time.Duration {\n\tcl := t.cl\n\tcl.rLock()\n\tdefer cl.rUnlock()\n\treturn t.dialTimeout()\n}\n\nfunc (t *Torrent) canonicalShortInfohash() *infohash.T {\n\tif t.infoHash.Ok {\n\t\treturn &t.infoHash.Value\n\t}\n\treturn t.infoHashV2.UnwrapPtr().ToShort()\n}\n\nfunc (t *Torrent) eachShortInfohash(each func(short [20]byte)) {\n\tif t.infoHash.Value == *t.infoHashV2.Value.ToShort() {\n\t\t// This includes zero values, since they both should not be zero. Plus Option should not\n\t\t// allow non-zero values for None.\n\t\tpanic(\"v1 and v2 info hashes should not be the same\")\n\t}\n\tif t.infoHash.Ok {\n\t\teach(t.infoHash.Value)\n\t}\n\tif t.infoHashV2.Ok {\n\t\tv2Short := *t.infoHashV2.Value.ToShort()\n\t\teach(v2Short)\n\t}\n}\n\nfunc (t *Torrent) getFileByPiecesRoot(hash [32]byte) *File {\n\tfor _, f := range *t.files {\n\t\tif f.piecesRoot.Unwrap() == hash {\n\t\t\treturn f\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (t *Torrent) pieceLayers() (pieceLayers map[string]string) {\n\tif t.files == nil {\n\t\treturn\n\t}\n\tfiles := *t.files\n\tg.MakeMapWithCap(&pieceLayers, len(files))\nfile:\n\tfor _, f := range files {\n\t\tif !f.piecesRoot.Ok {\n\t\t\tcontinue\n\t\t}\n\t\tkey := f.piecesRoot.Value\n\t\tvar value strings.Builder\n\t\tfor i := f.BeginPieceIndex(); i < f.EndPieceIndex(); i++ {\n\t\t\thashOpt := t.piece(i).hashV2\n\t\t\tif !hashOpt.Ok {\n\t\t\t\t// All hashes must be present. This implementation should handle missing files, so\n\t\t\t\t// move on to the next file.\n\t\t\t\tcontinue file\n\t\t\t}\n\t\t\tvalue.Write(hashOpt.Value[:])\n\t\t}\n\t\tif value.Len() == 0 {\n\t\t\t// Non-empty files are not recorded in piece layers.\n\t\t\tcontinue\n\t\t}\n\t\t// If multiple files have the same root that shouldn't matter.\n\t\tpieceLayers[string(key[:])] = value.String()\n\t}\n\treturn\n}\n\n// Is On when all pieces are complete.\nfunc (t *Torrent) Complete() chansync.ReadOnlyFlag {\n\treturn &t.complete\n}\n"
        },
        {
          "name": "torrent_mmap_test.go",
          "type": "blob",
          "size": 0.32421875,
          "content": "//go:build !wasm\n// +build !wasm\n\npackage torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc TestEmptyFilesAndZeroPieceLengthWithMMapStorage(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tci := storage.NewMMap(cfg.DataDir)\n\tdefer ci.Close()\n\tcfg.DefaultStorage = ci\n\ttestEmptyFilesAndZeroPieceLength(t, cfg)\n}\n"
        },
        {
          "name": "torrent_test.go",
          "type": "blob",
          "size": 6.837890625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sync\"\n\t\"testing\"\n\n\tg \"github.com/anacrolix/generics\"\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2\"\n\t\"github.com/anacrolix/missinggo/v2/bitmap\"\n\tqt \"github.com/frankban/quicktest\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/anacrolix/torrent/bencode\"\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/storage\"\n)\n\nfunc r(i, b, l pp.Integer) Request {\n\treturn Request{i, ChunkSpec{b, l}}\n}\n\n// Check the given request is correct for various torrent offsets.\nfunc TestTorrentRequest(t *testing.T) {\n\tconst s = 472183431 // Length of torrent.\n\tfor _, _case := range []struct {\n\t\toff int64   // An offset into the torrent.\n\t\treq Request // The expected request. The zero value means !ok.\n\t}{\n\t\t// Invalid offset.\n\t\t{-1, Request{}},\n\t\t{0, r(0, 0, 16384)},\n\t\t// One before the end of a piece.\n\t\t{1<<18 - 1, r(0, 1<<18-16384, 16384)},\n\t\t// Offset beyond torrent length.\n\t\t{472 * 1 << 20, Request{}},\n\t\t// One before the end of the torrent. Complicates the chunk length.\n\t\t{s - 1, r((s-1)/(1<<18), (s-1)%(1<<18)/(16384)*(16384), 12935)},\n\t\t{1, r(0, 0, 16384)},\n\t\t// One before end of chunk.\n\t\t{16383, r(0, 0, 16384)},\n\t\t// Second chunk.\n\t\t{16384, r(0, 16384, 16384)},\n\t} {\n\t\treq, ok := torrentOffsetRequest(472183431, 1<<18, 16384, _case.off)\n\t\tif (_case.req == Request{}) == ok {\n\t\t\tt.Fatalf(\"expected %v, got %v\", _case.req, req)\n\t\t}\n\t\tif req != _case.req {\n\t\t\tt.Fatalf(\"expected %v, got %v\", _case.req, req)\n\t\t}\n\t}\n}\n\nfunc TestAppendToCopySlice(t *testing.T) {\n\torig := []int{1, 2, 3}\n\tdupe := append([]int{}, orig...)\n\tdupe[0] = 4\n\tif orig[0] != 1 {\n\t\tt.FailNow()\n\t}\n}\n\nfunc TestTorrentString(t *testing.T) {\n\ttor := &Torrent{}\n\ttor.infoHash.Ok = true\n\ttor.infoHash.Value[0] = 1\n\ts := tor.InfoHash().HexString()\n\tif s != \"0100000000000000000000000000000000000000\" {\n\t\tt.FailNow()\n\t}\n}\n\n// This benchmark is from the observation that a lot of overlapping Readers on\n// a large torrent with small pieces had a lot of overhead in recalculating\n// piece priorities everytime a reader (possibly in another Torrent) changed.\nfunc BenchmarkUpdatePiecePriorities(b *testing.B) {\n\tconst (\n\t\tnumPieces   = 13410\n\t\tpieceLength = 256 << 10\n\t)\n\tcl := &Client{config: TestingConfig(b)}\n\tcl.initLogger()\n\tt := cl.newTorrentForTesting()\n\trequire.NoError(b, t.setInfo(&metainfo.Info{\n\t\tPieces:      make([]byte, metainfo.HashSize*numPieces),\n\t\tPieceLength: pieceLength,\n\t\tLength:      pieceLength * numPieces,\n\t}))\n\tt.onSetInfo()\n\tassert.EqualValues(b, 13410, t.numPieces())\n\tfor i := 0; i < 7; i += 1 {\n\t\tr := t.NewReader()\n\t\tr.SetReadahead(32 << 20)\n\t\tr.Seek(3500000, io.SeekStart)\n\t}\n\tassert.Len(b, t.readers, 7)\n\tfor i := 0; i < t.numPieces(); i += 3 {\n\t\tt._completedPieces.Add(bitmap.BitIndex(i))\n\t}\n\tt.DownloadPieces(0, t.numPieces())\n\tfor i := 0; i < b.N; i += 1 {\n\t\tt.updateAllPiecePriorities(\"\")\n\t}\n}\n\n// Check that a torrent containing zero-length file(s) will start, and that\n// they're created in the filesystem. The client storage is assumed to be\n// file-based on the native filesystem based.\nfunc testEmptyFilesAndZeroPieceLength(t *testing.T, cfg *ClientConfig) {\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\tib, err := bencode.Marshal(metainfo.Info{\n\t\tName:        \"empty\",\n\t\tLength:      0,\n\t\tPieceLength: 0,\n\t})\n\trequire.NoError(t, err)\n\tfp := filepath.Join(cfg.DataDir, \"empty\")\n\tos.Remove(fp)\n\tassert.False(t, missinggo.FilePathExists(fp))\n\ttt, err := cl.AddTorrent(&metainfo.MetaInfo{\n\t\tInfoBytes: ib,\n\t})\n\trequire.NoError(t, err)\n\tdefer tt.Drop()\n\ttt.DownloadAll()\n\trequire.True(t, cl.WaitAll())\n\tassert.True(t, tt.Complete().Bool())\n\tassert.True(t, missinggo.FilePathExists(fp))\n}\n\nfunc TestEmptyFilesAndZeroPieceLengthWithFileStorage(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tci := storage.NewFile(cfg.DataDir)\n\tdefer ci.Close()\n\tcfg.DefaultStorage = ci\n\ttestEmptyFilesAndZeroPieceLength(t, cfg)\n}\n\nfunc TestPieceHashFailed(t *testing.T) {\n\tmi := testutil.GreetingMetaInfo()\n\tcl := newTestingClient(t)\n\ttt := cl.newTorrent(mi.HashInfoBytes(), badStorage{})\n\ttt.setChunkSize(2)\n\trequire.NoError(t, tt.setInfoBytesLocked(mi.InfoBytes))\n\ttt.cl.lock()\n\ttt.dirtyChunks.AddRange(\n\t\tuint64(tt.pieceRequestIndexOffset(1)),\n\t\tuint64(tt.pieceRequestIndexOffset(1)+3))\n\trequire.True(t, tt.pieceAllDirty(1))\n\ttt.pieceHashed(1, false, nil)\n\t// Dirty chunks should be cleared so we can try again.\n\trequire.False(t, tt.pieceAllDirty(1))\n\ttt.cl.unlock()\n}\n\n// Check the behaviour of Torrent.Metainfo when metadata is not completed.\nfunc TestTorrentMetainfoIncompleteMetadata(t *testing.T) {\n\tcfg := TestingConfig(t)\n\tcfg.Debug = true\n\t// Disable this just because we manually initiate a connection without it.\n\tcfg.MinPeerExtensions.SetBit(pp.ExtensionBitFast, false)\n\tcl, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer cl.Close()\n\n\tmi := testutil.GreetingMetaInfo()\n\tih := mi.HashInfoBytes()\n\n\ttt, _ := cl.AddTorrentInfoHash(ih)\n\tassert.Nil(t, tt.Metainfo().InfoBytes)\n\tassert.False(t, tt.haveAllMetadataPieces())\n\n\tnc, err := net.Dial(\"tcp\", fmt.Sprintf(\":%d\", cl.LocalPort()))\n\trequire.NoError(t, err)\n\tdefer nc.Close()\n\n\tvar pex PeerExtensionBits\n\tpex.SetBit(pp.ExtensionBitLtep, true)\n\thr, err := pp.Handshake(context.Background(), nc, &ih, [20]byte{}, pex)\n\trequire.NoError(t, err)\n\tassert.True(t, hr.PeerExtensionBits.GetBit(pp.ExtensionBitLtep))\n\tassert.EqualValues(t, cl.PeerID(), hr.PeerID)\n\tassert.EqualValues(t, ih, hr.Hash)\n\n\tassert.EqualValues(t, 0, tt.metadataSize())\n\n\tfunc() {\n\t\tcl.lock()\n\t\tdefer cl.unlock()\n\t\tgo func() {\n\t\t\t_, err = nc.Write(pp.Message{\n\t\t\t\tType:       pp.Extended,\n\t\t\t\tExtendedID: pp.HandshakeExtendedID,\n\t\t\t\tExtendedPayload: func() []byte {\n\t\t\t\t\td := map[string]interface{}{\n\t\t\t\t\t\t\"metadata_size\": len(mi.InfoBytes),\n\t\t\t\t\t}\n\t\t\t\t\tb, err := bencode.Marshal(d)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tpanic(err)\n\t\t\t\t\t}\n\t\t\t\t\treturn b\n\t\t\t\t}(),\n\t\t\t}.MustMarshalBinary())\n\t\t\trequire.NoError(t, err)\n\t\t}()\n\t\ttt.metadataChanged.Wait()\n\t}()\n\tassert.Equal(t, make([]byte, len(mi.InfoBytes)), tt.metadataBytes)\n\tassert.False(t, tt.haveAllMetadataPieces())\n\tassert.Nil(t, tt.Metainfo().InfoBytes)\n}\n\nfunc TestRelativeAvailabilityHaveNone(t *testing.T) {\n\tc := qt.New(t)\n\tvar err error\n\tcl := Client{\n\t\tconfig: TestingConfig(t),\n\t}\n\ttt := Torrent{\n\t\tcl:           &cl,\n\t\tlogger:       log.Default,\n\t\tgotMetainfoC: make(chan struct{}),\n\t}\n\ttt.setChunkSize(2)\n\tg.MakeMapIfNil(&tt.conns)\n\tpc := PeerConn{}\n\tpc.t = &tt\n\tpc.peerImpl = &pc\n\tpc.initRequestState()\n\tg.InitNew(&pc.callbacks)\n\ttt.conns[&pc] = struct{}{}\n\terr = pc.peerSentHave(0)\n\tc.Assert(err, qt.IsNil)\n\tinfo := testutil.Greeting.Info(5)\n\terr = tt.setInfo(&info)\n\tc.Assert(err, qt.IsNil)\n\ttt.onSetInfo()\n\terr = pc.peerSentHaveNone()\n\tc.Assert(err, qt.IsNil)\n\tvar wg sync.WaitGroup\n\ttt.close(&wg)\n\ttt.assertAllPiecesRelativeAvailabilityZero()\n}\n"
        },
        {
          "name": "tracker",
          "type": "tree",
          "content": null
        },
        {
          "name": "tracker_scraper.go",
          "type": "blob",
          "size": 6.6875,
          "content": "package torrent\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/url\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/anacrolix/dht/v2/krpc\"\n\t\"github.com/anacrolix/log\"\n\n\t\"github.com/anacrolix/torrent/tracker\"\n)\n\n// Announces a torrent to a tracker at regular intervals, when peers are\n// required.\ntype trackerScraper struct {\n\tshortInfohash   [20]byte\n\tu               url.URL\n\tt               *Torrent\n\tlastAnnounce    trackerAnnounceResult\n\tlookupTrackerIp func(*url.URL) ([]net.IP, error)\n\n\tstopOnce sync.Once\n\tstopCh   chan struct{}\n}\n\ntype torrentTrackerAnnouncer interface {\n\tstatusLine() string\n\tURL() *url.URL\n\n\tStop()\n}\n\nfunc (me trackerScraper) URL() *url.URL {\n\treturn &me.u\n}\n\nfunc (ts *trackerScraper) statusLine() string {\n\tvar w bytes.Buffer\n\tfmt.Fprintf(&w, \"next ann: %v, last ann: %v\",\n\t\tfunc() string {\n\t\t\tna := time.Until(ts.lastAnnounce.Completed.Add(ts.lastAnnounce.Interval))\n\t\t\tif na > 0 {\n\t\t\t\tna /= time.Second\n\t\t\t\tna *= time.Second\n\t\t\t\treturn na.String()\n\t\t\t} else {\n\t\t\t\treturn \"anytime\"\n\t\t\t}\n\t\t}(),\n\t\tfunc() string {\n\t\t\tif ts.lastAnnounce.Err != nil {\n\t\t\t\treturn ts.lastAnnounce.Err.Error()\n\t\t\t}\n\t\t\tif ts.lastAnnounce.Completed.IsZero() {\n\t\t\t\treturn \"never\"\n\t\t\t}\n\t\t\treturn fmt.Sprintf(\"%d peers\", ts.lastAnnounce.NumPeers)\n\t\t}(),\n\t)\n\treturn w.String()\n}\n\ntype trackerAnnounceResult struct {\n\tErr       error\n\tNumPeers  int\n\tInterval  time.Duration\n\tCompleted time.Time\n}\n\nfunc (me *trackerScraper) getIp() (ip net.IP, err error) {\n\tvar ips []net.IP\n\tif me.lookupTrackerIp != nil {\n\t\tips, err = me.lookupTrackerIp(&me.u)\n\t} else {\n\t\t// Do a regular dns lookup\n\t\tips, err = net.LookupIP(me.u.Hostname())\n\t}\n\tif err != nil {\n\t\treturn\n\t}\n\tif len(ips) == 0 {\n\t\terr = errors.New(\"no ips\")\n\t\treturn\n\t}\n\tme.t.cl.rLock()\n\tdefer me.t.cl.rUnlock()\n\tif me.t.cl.closed.IsSet() {\n\t\terr = errors.New(\"client is closed\")\n\t\treturn\n\t}\n\tfor _, ip = range ips {\n\t\tif me.t.cl.ipIsBlocked(ip) {\n\t\t\tcontinue\n\t\t}\n\t\tswitch me.u.Scheme {\n\t\tcase \"udp4\":\n\t\t\tif ip.To4() == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\tcase \"udp6\":\n\t\t\tif ip.To4() != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\terr = errors.New(\"no acceptable ips\")\n\treturn\n}\n\nfunc (me *trackerScraper) trackerUrl(ip net.IP) string {\n\tu := me.u\n\tif u.Port() != \"\" {\n\t\tu.Host = net.JoinHostPort(ip.String(), u.Port())\n\t}\n\treturn u.String()\n}\n\n// Return how long to wait before trying again. For most errors, we return 5\n// minutes, a relatively quick turn around for DNS changes.\nfunc (me *trackerScraper) announce(\n\tctx context.Context,\n\tevent tracker.AnnounceEvent,\n) (ret trackerAnnounceResult) {\n\tdefer func() {\n\t\tret.Completed = time.Now()\n\t}()\n\tret.Interval = time.Minute\n\n\t// Limit concurrent use of the same tracker URL by the Client.\n\tref := me.t.cl.activeAnnounceLimiter.GetRef(me.u.String())\n\tdefer ref.Drop()\n\tselect {\n\tcase <-ctx.Done():\n\t\tret.Err = ctx.Err()\n\t\treturn\n\tcase ref.C() <- struct{}{}:\n\t}\n\tdefer func() {\n\t\tselect {\n\t\tcase <-ref.C():\n\t\tdefault:\n\t\t\tpanic(\"should return immediately\")\n\t\t}\n\t}()\n\n\tip, err := me.getIp()\n\tif err != nil {\n\t\tret.Err = fmt.Errorf(\"error getting ip: %s\", err)\n\t\treturn\n\t}\n\tme.t.cl.rLock()\n\treq := me.t.announceRequest(event, me.shortInfohash)\n\tme.t.cl.rUnlock()\n\t// The default timeout works well as backpressure on concurrent access to the tracker. Since\n\t// we're passing our own Context now, we will include that timeout ourselves to maintain similar\n\t// behavior to previously, albeit with this context now being cancelled when the Torrent is\n\t// closed.\n\tctx, cancel := context.WithTimeout(ctx, tracker.DefaultTrackerAnnounceTimeout)\n\tdefer cancel()\n\tme.t.logger.WithDefaultLevel(log.Debug).Printf(\"announcing to %q: %#v\", me.u.String(), req)\n\tres, err := tracker.Announce{\n\t\tContext:             ctx,\n\t\tHttpProxy:           me.t.cl.config.HTTPProxy,\n\t\tHttpRequestDirector: me.t.cl.config.HttpRequestDirector,\n\t\tDialContext:         me.t.cl.config.TrackerDialContext,\n\t\tListenPacket:        me.t.cl.config.TrackerListenPacket,\n\t\tUserAgent:           me.t.cl.config.HTTPUserAgent,\n\t\tTrackerUrl:          me.trackerUrl(ip),\n\t\tRequest:             req,\n\t\tHostHeader:          me.u.Host,\n\t\tServerName:          me.u.Hostname(),\n\t\tUdpNetwork:          me.u.Scheme,\n\t\tClientIp4:           krpc.NodeAddr{IP: me.t.cl.config.PublicIp4},\n\t\tClientIp6:           krpc.NodeAddr{IP: me.t.cl.config.PublicIp6},\n\t\tLogger:              me.t.logger,\n\t}.Do()\n\tme.t.logger.WithDefaultLevel(log.Debug).Printf(\"announce to %q returned %#v: %v\", me.u.String(), res, err)\n\tif err != nil {\n\t\tret.Err = fmt.Errorf(\"announcing: %w\", err)\n\t\treturn\n\t}\n\tme.t.AddPeers(peerInfos(nil).AppendFromTracker(res.Peers))\n\tret.NumPeers = len(res.Peers)\n\tret.Interval = time.Duration(res.Interval) * time.Second\n\treturn\n}\n\n// Returns whether we can shorten the interval, and sets notify to a channel that receives when we\n// might change our mind, or leaves it if we won't.\nfunc (me *trackerScraper) canIgnoreInterval(notify *<-chan struct{}) bool {\n\tgotInfo := me.t.GotInfo()\n\tselect {\n\tcase <-gotInfo:\n\t\t// Private trackers really don't like us announcing more than they specify. They're also\n\t\t// tracking us very carefully, so it's best to comply.\n\t\tprivate := me.t.info.Private\n\t\treturn private == nil || !*private\n\tdefault:\n\t\t*notify = gotInfo\n\t\treturn false\n\t}\n}\n\nfunc (me *trackerScraper) Stop() {\n\tme.stopOnce.Do(func() {\n\t\tclose(me.stopCh)\n\t})\n}\n\nfunc (me *trackerScraper) Run() {\n\tdefer me.announceStopped()\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tgo func() {\n\t\tdefer cancel()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\tcase <-me.t.Closed():\n\t\t}\n\t}()\n\n\t// make sure first announce is a \"started\"\n\te := tracker.Started\n\n\tfor {\n\t\tar := me.announce(ctx, e)\n\t\t// after first announce, get back to regular \"none\"\n\t\te = tracker.None\n\t\tme.t.cl.lock()\n\t\tme.lastAnnounce = ar\n\t\tme.t.cl.unlock()\n\n\trecalculate:\n\t\t// Make sure we don't announce for at least a minute since the last one.\n\t\tinterval := ar.Interval\n\t\tif interval < time.Minute {\n\t\t\tinterval = time.Minute\n\t\t}\n\n\t\tme.t.cl.lock()\n\t\twantPeers := me.t.wantPeersEvent.C()\n\t\tme.t.cl.unlock()\n\n\t\t// If we want peers, reduce the interval to the minimum if it's appropriate.\n\n\t\t// A channel that receives when we should reconsider our interval. Starts as nil since that\n\t\t// never receives.\n\t\tvar reconsider <-chan struct{}\n\t\tselect {\n\t\tcase <-wantPeers:\n\t\t\tif interval > time.Minute && me.canIgnoreInterval(&reconsider) {\n\t\t\t\tinterval = time.Minute\n\t\t\t}\n\t\tdefault:\n\t\t\treconsider = wantPeers\n\t\t}\n\n\t\tselect {\n\t\tcase <-me.stopCh:\n\t\t\treturn\n\t\tcase <-me.t.closed.Done():\n\t\t\treturn\n\t\tcase <-reconsider:\n\t\t\t// Recalculate the interval.\n\t\t\tgoto recalculate\n\t\tcase <-time.After(time.Until(ar.Completed.Add(interval))):\n\t\t}\n\t}\n}\n\nfunc (me *trackerScraper) announceStopped() {\n\tctx, cancel := context.WithTimeout(context.Background(), tracker.DefaultTrackerAnnounceTimeout)\n\tdefer cancel()\n\tme.announce(ctx, tracker.Stopped)\n}\n"
        },
        {
          "name": "typed-roaring",
          "type": "tree",
          "content": null
        },
        {
          "name": "types",
          "type": "tree",
          "content": null
        },
        {
          "name": "undirtied-chunks-iter.go",
          "type": "blob",
          "size": 0.48046875,
          "content": "package torrent\n\nimport (\n\ttypedRoaring \"github.com/anacrolix/torrent/typed-roaring\"\n)\n\nfunc iterBitmapUnsetInRange[T typedRoaring.BitConstraint](\n\tit *typedRoaring.Iterator[T],\n\tstart, end T,\n\tf func(T),\n) {\n\tit.AdvanceIfNeeded(start)\n\tlastDirty := start - 1\n\tfor it.HasNext() {\n\t\tnext := it.Next()\n\t\tif next >= end {\n\t\t\tbreak\n\t\t}\n\t\tfor index := lastDirty + 1; index < next; index++ {\n\t\t\tf(index)\n\t\t}\n\t\tlastDirty = next\n\t}\n\tfor index := lastDirty + 1; index < end; index++ {\n\t\tf(index)\n\t}\n}\n"
        },
        {
          "name": "undirtied-chunks-iter_test.go",
          "type": "blob",
          "size": 0.5205078125,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\ttypedRoaring \"github.com/anacrolix/torrent/typed-roaring\"\n)\n\nfunc BenchmarkIterUndirtiedRequestIndexesInPiece(b *testing.B) {\n\tvar bitmap typedRoaring.Bitmap[RequestIndex]\n\tit := bitmap.IteratorType()\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t// This is the worst case, when Torrent.iterUndirtiedRequestIndexesInPiece can't find a\n\t\t// usable cached iterator. This should be the only allocation.\n\t\tit.Initialize(&bitmap)\n\t\titerBitmapUnsetInRange(&it, 69, 420, func(RequestIndex) {})\n\t}\n}\n"
        },
        {
          "name": "url-net-addr.go",
          "type": "blob",
          "size": 0.3369140625,
          "content": "package torrent\n\nimport (\n\t\"net\"\n\t\"net/url\"\n)\n\ntype urlNetAddr struct {\n\tu *url.URL\n}\n\nfunc (me urlNetAddr) Network() string {\n\treturn me.u.Scheme\n}\n\nfunc (me urlNetAddr) String() string {\n\treturn me.u.Host\n}\n\nfunc remoteAddrFromUrl(urlStr string) net.Addr {\n\tu, err := url.Parse(urlStr)\n\tif err != nil {\n\t\treturn nil\n\t}\n\treturn urlNetAddr{u}\n}\n"
        },
        {
          "name": "ut-holepunching.go",
          "type": "blob",
          "size": 0.015625,
          "content": "package torrent\n"
        },
        {
          "name": "ut-holepunching_test.go",
          "type": "blob",
          "size": 10.2490234375,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"net\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\t\"testing/iotest\"\n\t\"time\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/missinggo/v2/iter\"\n\tqt \"github.com/frankban/quicktest\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/anacrolix/torrent/internal/testutil\"\n)\n\n// Check that after completing leeching, a leecher transitions to a seeding\n// correctly. Connected in a chain like so: Seeder <-> Leecher <-> LeecherLeecher.\nfunc TestHolepunchConnect(t *testing.T) {\n\tc := qt.New(t)\n\tgreetingTempDir, mi := testutil.GreetingTestTorrent()\n\tdefer os.RemoveAll(greetingTempDir)\n\n\tcfg := TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.MaxAllocPeerRequestDataPerConn = 4\n\tcfg.DataDir = greetingTempDir\n\tcfg.DisablePEX = true\n\tcfg.Debug = true\n\tcfg.AcceptPeerConnections = false\n\t// Listening, even without accepting, still means the leecher-leecher completes the dial to the\n\t// seeder, and so it won't attempt to holepunch.\n\tcfg.DisableTCP = true\n\t// Ensure that responding to holepunch connects don't wait around for the dial limit. We also\n\t// have to allow the initial connection to the leecher though, so it can rendezvous for us.\n\tcfg.DialRateLimiter = rate.NewLimiter(0, 1)\n\tcfg.Logger = cfg.Logger.WithContextText(\"seeder\")\n\tseeder, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer seeder.Close()\n\tdefer testutil.ExportStatusWriter(seeder, \"s\", t)()\n\tseederTorrent, ok, err := seeder.AddTorrentSpec(TorrentSpecFromMetaInfo(mi))\n\trequire.NoError(t, err)\n\tassert.True(t, ok)\n\tseederTorrent.VerifyData()\n\n\tcfg = TestingConfig(t)\n\tcfg.Seed = true\n\tcfg.DataDir = t.TempDir()\n\tcfg.AlwaysWantConns = true\n\tcfg.Logger = cfg.Logger.WithContextText(\"leecher\")\n\t// This way the leecher leecher will still try to use this peer as a relay, but won't be told\n\t// about the seeder via PEX.\n\t//cfg.DisablePEX = true\n\tcfg.Debug = true\n\tleecher, err := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer leecher.Close()\n\tdefer testutil.ExportStatusWriter(leecher, \"l\", t)()\n\n\tcfg = TestingConfig(t)\n\tcfg.Seed = false\n\tcfg.DataDir = t.TempDir()\n\tcfg.MaxAllocPeerRequestDataPerConn = 4\n\tcfg.Debug = true\n\tcfg.NominalDialTimeout = time.Second\n\tcfg.Logger = cfg.Logger.WithContextText(\"leecher-leecher\")\n\t//cfg.DisableUTP = true\n\tleecherLeecher, _ := NewClient(cfg)\n\trequire.NoError(t, err)\n\tdefer leecherLeecher.Close()\n\tdefer testutil.ExportStatusWriter(leecherLeecher, \"ll\", t)()\n\tleecherGreeting, ok, err := leecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 2\n\t\treturn\n\t}())\n\t_ = leecherGreeting\n\trequire.NoError(t, err)\n\tassert.True(t, ok)\n\tllg, ok, err := leecherLeecher.AddTorrentSpec(func() (ret *TorrentSpec) {\n\t\tret = TorrentSpecFromMetaInfo(mi)\n\t\tret.ChunkSize = 3\n\t\treturn\n\t}())\n\trequire.NoError(t, err)\n\tassert.True(t, ok)\n\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tr := llg.NewReader()\n\t\tdefer r.Close()\n\t\tqt.Check(t, iotest.TestReader(r, []byte(testutil.GreetingFileContents)), qt.IsNil)\n\t}()\n\tgo seederTorrent.AddClientPeer(leecher)\n\twaitForConns(seederTorrent)\n\tgo llg.AddClientPeer(leecher)\n\twaitForConns(llg)\n\ttime.Sleep(time.Second)\n\tllg.cl.lock()\n\ttargetAddr := seeder.ListenAddrs()[0]\n\tlog.Printf(\"trying to initiate to %v\", targetAddr)\n\tinitiateConn(outgoingConnOpts{\n\t\tpeerInfo: PeerInfo{\n\t\t\tAddr: targetAddr,\n\t\t},\n\t\tt:                       llg,\n\t\trequireRendezvous:       true,\n\t\tskipHolepunchRendezvous: false,\n\t\tHeaderObfuscationPolicy: llg.cl.config.HeaderObfuscationPolicy,\n\t}, true)\n\tllg.cl.unlock()\n\twg.Wait()\n\n\tc.Check(seeder.dialedSuccessfullyAfterHolepunchConnect, qt.Not(qt.HasLen), 0)\n\tc.Check(leecherLeecher.probablyOnlyConnectedDueToHolepunch, qt.Not(qt.HasLen), 0)\n\n\tllClientStats := leecherLeecher.Stats()\n\tc.Check(llClientStats.NumPeersUndialableWithoutHolepunch, qt.Not(qt.Equals), 0)\n\tc.Check(llClientStats.NumPeersUndialableWithoutHolepunchDialedAfterHolepunchConnect, qt.Not(qt.Equals), 0)\n\tc.Check(llClientStats.NumPeersProbablyOnlyConnectedDueToHolepunch, qt.Not(qt.Equals), 0)\n}\n\nfunc waitForConns(t *Torrent) {\n\tt.cl.lock()\n\tdefer t.cl.unlock()\n\tfor {\n\t\tfor range t.conns {\n\t\t\treturn\n\t\t}\n\t\tt.cl.event.Wait()\n\t}\n}\n\n// Show that dialling TCP will complete before the other side accepts.\nfunc TestDialTcpNotAccepting(t *testing.T) {\n\tl, err := net.Listen(\"tcp\", \"localhost:0\")\n\tc := qt.New(t)\n\tc.Check(err, qt.IsNil)\n\tdefer l.Close()\n\tdialedConn, err := net.Dial(\"tcp\", l.Addr().String())\n\tc.Assert(err, qt.IsNil)\n\tdialedConn.Close()\n}\n\nfunc TestTcpSimultaneousOpen(t *testing.T) {\n\tconst network = \"tcp\"\n\tctx := context.Background()\n\tmakeDialer := func(localPort int, remoteAddr string) func() (net.Conn, error) {\n\t\tdialer := net.Dialer{\n\t\t\tLocalAddr: &net.TCPAddr{\n\t\t\t\t//IP:   net.IPv6loopback,\n\t\t\t\tPort: localPort,\n\t\t\t},\n\t\t}\n\t\treturn func() (net.Conn, error) {\n\t\t\treturn dialer.DialContext(ctx, network, remoteAddr)\n\t\t}\n\t}\n\tc := qt.New(t)\n\t// I really hate doing this in unit tests, but we would need to pick apart Dialer to get\n\t// perfectly synchronized simultaneous dials.\n\tfor range iter.N(10) {\n\t\tfirst, second := randPortPair()\n\t\tt.Logf(\"ports are %v and %v\", first, second)\n\t\terr := testSimultaneousOpen(\n\t\t\tc.Cleanup,\n\t\t\tmakeDialer(first, fmt.Sprintf(\"localhost:%d\", second)),\n\t\t\tmakeDialer(second, fmt.Sprintf(\"localhost:%d\", first)),\n\t\t)\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\t// This proves that the connections are not the same.\n\t\tif errors.Is(err, errMsgNotReceived) {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\t// Could be a timing issue, so try again.\n\t\tt.Log(err)\n\t}\n\t// If we weren't able to get a simultaneous dial to occur, then we can't call it a failure.\n\tt.Skip(\"couldn't synchronize dials\")\n}\n\nfunc randIntInRange(low, high int) int {\n\treturn rand.Intn(high-low+1) + low\n}\n\nfunc randDynamicPort() int {\n\treturn randIntInRange(49152, 65535)\n}\n\nfunc randPortPair() (first int, second int) {\n\tfirst = randDynamicPort()\n\tfor {\n\t\tsecond = randDynamicPort()\n\t\tif second != first {\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc writeMsg(conn net.Conn) {\n\tconn.Write([]byte(defaultMsg))\n\t// Writing must be closed so the reader will get EOF and stop reading.\n\tconn.Close()\n}\n\nfunc readMsg(conn net.Conn) error {\n\tmsgBytes, err := io.ReadAll(conn)\n\tif err != nil {\n\t\treturn err\n\t}\n\tmsgStr := string(msgBytes)\n\tif msgStr != defaultMsg {\n\t\treturn fmt.Errorf(\"read %q\", msgStr)\n\t}\n\treturn nil\n}\n\nvar errMsgNotReceived = errors.New(\"msg not received in time\")\n\n// Runs two dialers simultaneously, then sends a message on one connection and check it reads from\n// the other, thereby showing that both dials obtained endpoints to the same connection.\nfunc testSimultaneousOpen(\n\tcleanup func(func()),\n\tfirstDialer, secondDialer func() (net.Conn, error),\n) error {\n\terrs := make(chan error)\n\tvar dialsDone sync.WaitGroup\n\tconst numDials = 2\n\tdialsDone.Add(numDials)\n\tsignal := make(chan struct{})\n\tvar dialersDone sync.WaitGroup\n\tdialersDone.Add(numDials)\n\tdoDial := func(\n\t\tdialer func() (net.Conn, error),\n\t\tonSignal func(net.Conn),\n\t) {\n\t\tdefer dialersDone.Done()\n\t\tconn, err := dialer()\n\t\tdialsDone.Done()\n\t\terrs <- err\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tcleanup(func() {\n\t\t\tconn.Close()\n\t\t})\n\t\t<-signal\n\t\tonSignal(conn)\n\t\t//if err == nil {\n\t\t//\tconn.Close()\n\t\t//}\n\t}\n\tgo doDial(\n\t\tfirstDialer,\n\t\tfunc(conn net.Conn) {\n\t\t\twriteMsg(conn)\n\t\t\terrs <- nil\n\t\t},\n\t)\n\tgo doDial(\n\t\tsecondDialer,\n\t\tfunc(conn net.Conn) {\n\t\t\tgotMsg := make(chan error, 1)\n\t\t\tgo func() {\n\t\t\t\tgotMsg <- readMsg(conn)\n\t\t\t}()\n\t\t\tselect {\n\t\t\tcase err := <-gotMsg:\n\t\t\t\terrs <- err\n\t\t\tcase <-time.After(time.Second):\n\t\t\t\terrs <- errMsgNotReceived\n\t\t\t}\n\t\t},\n\t)\n\tdialsDone.Wait()\n\tfor range iter.N(numDials) {\n\t\terr := <-errs\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tclose(signal)\n\tfor range iter.N(numDials) {\n\t\terr := <-errs\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tdialersDone.Wait()\n\treturn nil\n}\n\nconst defaultMsg = \"hello\"\n\n// Show that uTP doesn't implement simultaneous open. When two sockets dial each other, they both\n// get separate connections. This means that holepunch connect may result in an accept (and dial)\n// for one or both peers involved.\nfunc TestUtpSimultaneousOpen(t *testing.T) {\n\tt.Parallel()\n\tc := qt.New(t)\n\tconst network = \"udp\"\n\tctx := context.Background()\n\tnewUtpSocket := func(addr string) utpSocket {\n\t\tsocket, err := NewUtpSocket(\n\t\t\tnetwork,\n\t\t\taddr,\n\t\t\tfunc(net.Addr) bool {\n\t\t\t\treturn false\n\t\t\t},\n\t\t\tlog.Default,\n\t\t)\n\t\tc.Assert(err, qt.IsNil)\n\t\treturn socket\n\t}\n\tfirst := newUtpSocket(\"localhost:0\")\n\tdefer first.Close()\n\tsecond := newUtpSocket(\"localhost:0\")\n\tdefer second.Close()\n\tgetDial := func(sock utpSocket, addr string) func() (net.Conn, error) {\n\t\treturn func() (net.Conn, error) {\n\t\t\treturn sock.DialContext(ctx, network, addr)\n\t\t}\n\t}\n\tt.Logf(\"first addr is %v. second addr is %v\", first.Addr().String(), second.Addr().String())\n\tfor range iter.N(10) {\n\t\terr := testSimultaneousOpen(\n\t\t\tc.Cleanup,\n\t\t\tgetDial(first, second.Addr().String()),\n\t\t\tgetDial(second, first.Addr().String()),\n\t\t)\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected utp to fail simultaneous open\")\n\t\t}\n\t\tif errors.Is(err, errMsgNotReceived) {\n\t\t\treturn\n\t\t}\n\t\tskipGoUtpDialIssue(t, err)\n\t\tt.Log(err)\n\t\ttime.Sleep(time.Second)\n\t}\n\tt.FailNow()\n}\n\nfunc writeAndReadMsg(r, w net.Conn) error {\n\tgo writeMsg(w)\n\treturn readMsg(r)\n}\n\nfunc skipGoUtpDialIssue(t *testing.T, err error) {\n\tif err.Error() == \"timed out waiting for ack\" {\n\t\tt.Skip(\"anacrolix go utp implementation has issues. Use anacrolix/go-libutp by enabling CGO.\")\n\t}\n}\n\n// Show that dialling one socket and accepting from the other results in them having ends of the\n// same connection.\nfunc TestUtpDirectDialMsg(t *testing.T) {\n\tt.Parallel()\n\tc := qt.New(t)\n\tconst network = \"udp4\"\n\tctx := context.Background()\n\tnewUtpSocket := func(addr string) utpSocket {\n\t\tsocket, err := NewUtpSocket(network, addr, func(net.Addr) bool {\n\t\t\treturn false\n\t\t}, log.Default)\n\t\tc.Assert(err, qt.IsNil)\n\t\treturn socket\n\t}\n\tfor range iter.N(10) {\n\t\terr := func() error {\n\t\t\tfirst := newUtpSocket(\"localhost:0\")\n\t\t\tdefer first.Close()\n\t\t\tsecond := newUtpSocket(\"localhost:0\")\n\t\t\tdefer second.Close()\n\t\t\twriter, err := first.DialContext(ctx, network, second.Addr().String())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer writer.Close()\n\t\t\treader, err := second.Accept()\n\t\t\tdefer reader.Close()\n\t\t\tc.Assert(err, qt.IsNil)\n\t\t\treturn writeAndReadMsg(reader, writer)\n\t\t}()\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\tskipGoUtpDialIssue(t, err)\n\t\tt.Log(err)\n\t\ttime.Sleep(time.Second)\n\t}\n\tt.FailNow()\n}\n"
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "utp.go",
          "type": "blob",
          "size": 0.4296875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"net\"\n)\n\n// Abstracts the utp Socket, so the implementation can be selected from\n// different packages.\ntype utpSocket interface {\n\tnet.PacketConn\n\t// net.Listener, but we can't have duplicate Close.\n\tAccept() (net.Conn, error)\n\tAddr() net.Addr\n\t// net.Dialer but there's no interface.\n\tDialContext(ctx context.Context, network, addr string) (net.Conn, error)\n\t// Dial(addr string) (net.Conn, error)\n}\n"
        },
        {
          "name": "utp_go.go",
          "type": "blob",
          "size": 0.3408203125,
          "content": "//go:build !cgo || disable_libutp\n// +build !cgo disable_libutp\n\npackage torrent\n\nimport (\n\t\"github.com/anacrolix/log\"\n\t\"github.com/anacrolix/utp\"\n)\n\nfunc NewUtpSocket(network, addr string, _ firewallCallback, _ log.Logger) (utpSocket, error) {\n\ts, err := utp.NewSocket(network, addr)\n\tif s == nil {\n\t\treturn nil, err\n\t} else {\n\t\treturn s, err\n\t}\n}\n"
        },
        {
          "name": "utp_libutp.go",
          "type": "blob",
          "size": 0.4755859375,
          "content": "//go:build cgo && !disable_libutp\n// +build cgo,!disable_libutp\n\npackage torrent\n\nimport (\n\tutp \"github.com/anacrolix/go-libutp\"\n\t\"github.com/anacrolix/log\"\n)\n\nfunc NewUtpSocket(network, addr string, fc firewallCallback, logger log.Logger) (utpSocket, error) {\n\ts, err := utp.NewSocket(network, addr, utp.WithLogger(logger))\n\tif s == nil {\n\t\treturn nil, err\n\t}\n\tif err != nil {\n\t\treturn s, err\n\t}\n\tif fc != nil {\n\t\ts.SetSyncFirewallCallback(utp.FirewallCallback(fc))\n\t}\n\treturn s, err\n}\n"
        },
        {
          "name": "utp_test.go",
          "type": "blob",
          "size": 0.3017578125,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewUtpSocketErrorNilInterface(t *testing.T) {\n\ts, err := NewUtpSocket(\"fix\", \"your:language\", nil, log.Default)\n\tassert.Error(t, err)\n\tif s != nil {\n\t\tt.Fatalf(\"expected nil, got %#v\", s)\n\t}\n}\n"
        },
        {
          "name": "version",
          "type": "tree",
          "content": null
        },
        {
          "name": "webrtc.go",
          "type": "blob",
          "size": 2.2314453125,
          "content": "package torrent\n\nimport (\n\t\"io\"\n\t\"net\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/pion/webrtc/v4\"\n\t\"go.opentelemetry.io/otel\"\n\t\"go.opentelemetry.io/otel/attribute\"\n\t\"go.opentelemetry.io/otel/trace\"\n\n\t\"github.com/anacrolix/torrent/webtorrent\"\n)\n\nconst webrtcNetwork = \"webrtc\"\n\ntype webrtcNetConn struct {\n\tio.ReadWriteCloser\n\twebtorrent.DataChannelContext\n}\n\ntype webrtcNetAddr struct {\n\t*webrtc.ICECandidate\n}\n\nvar _ net.Addr = webrtcNetAddr{}\n\nfunc (webrtcNetAddr) Network() string {\n\t// Now that we have the ICE candidate, we can tell if it's over udp or tcp. But should we use\n\t// that for the network?\n\treturn webrtcNetwork\n}\n\nfunc (me webrtcNetAddr) String() string {\n\treturn net.JoinHostPort(me.Address, strconv.FormatUint(uint64(me.Port), 10))\n}\n\nfunc (me webrtcNetConn) LocalAddr() net.Addr {\n\t// I'm not sure if this evolves over time. It might also be unavailable if the PeerConnection is\n\t// closed or closes itself. The same concern applies to RemoteAddr.\n\tpair, err := me.DataChannelContext.GetSelectedIceCandidatePair()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn webrtcNetAddr{pair.Local}\n}\n\nfunc (me webrtcNetConn) RemoteAddr() net.Addr {\n\t// See comments on LocalAddr.\n\tpair, err := me.DataChannelContext.GetSelectedIceCandidatePair()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn webrtcNetAddr{pair.Remote}\n}\n\n// Do we need these for WebRTC connections exposed as net.Conns? Can we set them somewhere inside\n// PeerConnection or on the channel or some transport?\n\nfunc (w webrtcNetConn) SetDeadline(t time.Time) error {\n\tw.Span.AddEvent(\"SetDeadline\", trace.WithAttributes(attribute.String(\"time\", t.String())))\n\treturn nil\n}\n\nfunc (w webrtcNetConn) SetReadDeadline(t time.Time) error {\n\tw.Span.AddEvent(\"SetReadDeadline\", trace.WithAttributes(attribute.String(\"time\", t.String())))\n\treturn nil\n}\n\nfunc (w webrtcNetConn) SetWriteDeadline(t time.Time) error {\n\tw.Span.AddEvent(\"SetWriteDeadline\", trace.WithAttributes(attribute.String(\"time\", t.String())))\n\treturn nil\n}\n\nfunc (w webrtcNetConn) Read(b []byte) (n int, err error) {\n\t_, span := otel.Tracer(tracerName).Start(w.Context, \"Read\")\n\tdefer span.End()\n\tspan.SetAttributes(attribute.Int(\"buf_len\", len(b)))\n\tn, err = w.ReadWriteCloser.Read(b)\n\tspan.RecordError(err)\n\tspan.SetAttributes(attribute.Int(\"bytes_read\", n))\n\treturn\n}\n"
        },
        {
          "name": "webseed-peer.go",
          "type": "blob",
          "size": 5.9404296875,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/RoaringBitmap/roaring\"\n\t\"github.com/anacrolix/log\"\n\n\t\"github.com/anacrolix/torrent/metainfo\"\n\tpp \"github.com/anacrolix/torrent/peer_protocol\"\n\t\"github.com/anacrolix/torrent/webseed\"\n)\n\nconst (\n\twebseedPeerCloseOnUnhandledError = false\n)\n\ntype webseedPeer struct {\n\t// First field for stats alignment.\n\tpeer             Peer\n\tclient           webseed.Client\n\tactiveRequests   map[Request]webseed.Request\n\trequesterCond    sync.Cond\n\tlastUnhandledErr time.Time\n}\n\nvar _ peerImpl = (*webseedPeer)(nil)\n\nfunc (me *webseedPeer) peerImplStatusLines() []string {\n\treturn []string{\n\t\tme.client.Url,\n\t\tfmt.Sprintf(\"last unhandled error: %v\", eventAgeString(me.lastUnhandledErr)),\n\t}\n}\n\nfunc (ws *webseedPeer) String() string {\n\treturn fmt.Sprintf(\"webseed peer for %q\", ws.client.Url)\n}\n\nfunc (ws *webseedPeer) onGotInfo(info *metainfo.Info) {\n\tws.client.SetInfo(info)\n\t// There should be probably be a callback in Client instead, so it can remove pieces at its whim\n\t// too.\n\tws.client.Pieces.Iterate(func(x uint32) bool {\n\t\tws.peer.t.incPieceAvailability(pieceIndex(x))\n\t\treturn true\n\t})\n}\n\nfunc (ws *webseedPeer) writeInterested(interested bool) bool {\n\treturn true\n}\n\nfunc (ws *webseedPeer) _cancel(r RequestIndex) bool {\n\tif active, ok := ws.activeRequests[ws.peer.t.requestIndexToRequest(r)]; ok {\n\t\tactive.Cancel()\n\t\t// The requester is running and will handle the result.\n\t\treturn true\n\t}\n\t// There should be no requester handling this, so no further events will occur.\n\treturn false\n}\n\nfunc (ws *webseedPeer) intoSpec(r Request) webseed.RequestSpec {\n\treturn webseed.RequestSpec{ws.peer.t.requestOffset(r), int64(r.Length)}\n}\n\nfunc (ws *webseedPeer) _request(r Request) bool {\n\tws.requesterCond.Signal()\n\treturn true\n}\n\n// Returns true if we should look for another request to start. Returns false if we handled this\n// one.\nfunc (ws *webseedPeer) requestIteratorLocked(requesterIndex int, x RequestIndex) bool {\n\tr := ws.peer.t.requestIndexToRequest(x)\n\tif _, ok := ws.activeRequests[r]; ok {\n\t\treturn true\n\t}\n\twebseedRequest := ws.client.StartNewRequest(ws.intoSpec(r))\n\tws.activeRequests[r] = webseedRequest\n\tlocker := ws.requesterCond.L\n\terr := func() error {\n\t\tlocker.Unlock()\n\t\tdefer locker.Lock()\n\t\treturn ws.requestResultHandler(r, webseedRequest)\n\t}()\n\tdelete(ws.activeRequests, r)\n\tif err != nil {\n\t\tlevel := log.Warning\n\t\tif errors.Is(err, context.Canceled) {\n\t\t\tlevel = log.Debug\n\t\t}\n\t\tws.peer.logger.Levelf(level, \"requester %v: error doing webseed request %v: %v\", requesterIndex, r, err)\n\t\t// This used to occur only on webseed.ErrTooFast but I think it makes sense to slow down any\n\t\t// kind of error. There are maxRequests (in Torrent.addWebSeed) requestors bouncing around\n\t\t// it doesn't hurt to slow a few down if there are issues.\n\t\tlocker.Unlock()\n\t\tselect {\n\t\tcase <-ws.peer.closed.Done():\n\t\tcase <-time.After(time.Duration(rand.Int63n(int64(10 * time.Second)))):\n\t\t}\n\t\tlocker.Lock()\n\t\tws.peer.updateRequests(\"webseedPeer request errored\")\n\t}\n\treturn false\n\n}\n\nfunc (ws *webseedPeer) requester(i int) {\n\tws.requesterCond.L.Lock()\n\tdefer ws.requesterCond.L.Unlock()\nstart:\n\tfor !ws.peer.closed.IsSet() {\n\t\tfor reqIndex := range ws.peer.requestState.Requests.Iterator() {\n\t\t\tif !ws.requestIteratorLocked(i, reqIndex) {\n\t\t\t\tgoto start\n\t\t\t}\n\t\t}\n\t\t// Found no requests to handle, so wait.\n\t\tws.requesterCond.Wait()\n\t}\n}\n\nfunc (ws *webseedPeer) connectionFlags() string {\n\treturn \"WS\"\n}\n\n// Maybe this should drop all existing connections, or something like that.\nfunc (ws *webseedPeer) drop() {}\n\nfunc (cn *webseedPeer) ban() {\n\tcn.peer.close()\n}\n\nfunc (ws *webseedPeer) handleUpdateRequests() {\n\t// Because this is synchronous, webseed peers seem to get first dibs on newly prioritized\n\t// pieces.\n\tgo func() {\n\t\tws.peer.t.cl.lock()\n\t\tdefer ws.peer.t.cl.unlock()\n\t\tws.peer.maybeUpdateActualRequestState()\n\t}()\n}\n\nfunc (ws *webseedPeer) onClose() {\n\tws.peer.logger.Levelf(log.Debug, \"closing\")\n\t// Just deleting them means we would have to manually cancel active requests.\n\tws.peer.cancelAllRequests()\n\tws.peer.t.iterPeers(func(p *Peer) {\n\t\tif p.isLowOnRequests() {\n\t\t\tp.updateRequests(\"webseedPeer.onClose\")\n\t\t}\n\t})\n\tws.requesterCond.Broadcast()\n}\n\nfunc (ws *webseedPeer) requestResultHandler(r Request, webseedRequest webseed.Request) error {\n\tresult := <-webseedRequest.Result\n\tclose(webseedRequest.Result) // one-shot\n\t// We do this here rather than inside receiveChunk, since we want to count errors too. I'm not\n\t// sure if we can divine which errors indicate cancellation on our end without hitting the\n\t// network though.\n\tif len(result.Bytes) != 0 || result.Err == nil {\n\t\t// Increment ChunksRead and friends\n\t\tws.peer.doChunkReadStats(int64(len(result.Bytes)))\n\t}\n\tws.peer.readBytes(int64(len(result.Bytes)))\n\tws.peer.t.cl.lock()\n\tdefer ws.peer.t.cl.unlock()\n\tif ws.peer.t.closed.IsSet() {\n\t\treturn nil\n\t}\n\terr := result.Err\n\tif err != nil {\n\t\tswitch {\n\t\tcase errors.Is(err, context.Canceled):\n\t\tcase errors.Is(err, webseed.ErrTooFast):\n\t\tcase ws.peer.closed.IsSet():\n\t\tdefault:\n\t\t\tws.peer.logger.Printf(\"Request %v rejected: %v\", r, result.Err)\n\t\t\t// // Here lies my attempt to extract something concrete from Go's error system. RIP.\n\t\t\t// cfg := spew.NewDefaultConfig()\n\t\t\t// cfg.DisableMethods = true\n\t\t\t// cfg.Dump(result.Err)\n\n\t\t\tif webseedPeerCloseOnUnhandledError {\n\t\t\t\tlog.Printf(\"closing %v\", ws)\n\t\t\t\tws.peer.close()\n\t\t\t} else {\n\t\t\t\tws.lastUnhandledErr = time.Now()\n\t\t\t}\n\t\t}\n\t\tif !ws.peer.remoteRejectedRequest(ws.peer.t.requestIndexFromRequest(r)) {\n\t\t\tpanic(\"invalid reject\")\n\t\t}\n\t\treturn err\n\t}\n\terr = ws.peer.receiveChunk(&pp.Message{\n\t\tType:  pp.Piece,\n\t\tIndex: r.Index,\n\t\tBegin: r.Begin,\n\t\tPiece: result.Bytes,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn err\n}\n\nfunc (me *webseedPeer) peerPieces() *roaring.Bitmap {\n\treturn &me.client.Pieces\n}\n\nfunc (cn *webseedPeer) peerHasAllPieces() (all, known bool) {\n\tif !cn.peer.t.haveInfo() {\n\t\treturn true, false\n\t}\n\treturn cn.client.Pieces.GetCardinality() == uint64(cn.peer.t.numPieces()), true\n}\n"
        },
        {
          "name": "webseed",
          "type": "tree",
          "content": null
        },
        {
          "name": "webtorrent",
          "type": "tree",
          "content": null
        },
        {
          "name": "worse-conns.go",
          "type": "blob",
          "size": 2.720703125,
          "content": "package torrent\n\nimport (\n\t\"container/heap\"\n\t\"fmt\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/anacrolix/multiless\"\n\t\"github.com/anacrolix/sync\"\n)\n\ntype worseConnInput struct {\n\tBadDirection        bool\n\tUseful              bool\n\tLastHelpful         time.Time\n\tCompletedHandshake  time.Time\n\tGetPeerPriority     func() (peerPriority, error)\n\tgetPeerPriorityOnce sync.Once\n\tpeerPriority        peerPriority\n\tpeerPriorityErr     error\n\tPointer             uintptr\n}\n\nfunc (me *worseConnInput) doGetPeerPriority() {\n\tme.peerPriority, me.peerPriorityErr = me.GetPeerPriority()\n}\n\nfunc (me *worseConnInput) doGetPeerPriorityOnce() {\n\tme.getPeerPriorityOnce.Do(me.doGetPeerPriority)\n}\n\ntype worseConnLensOpts struct {\n\tincomingIsBad, outgoingIsBad bool\n}\n\nfunc worseConnInputFromPeer(p *PeerConn, opts worseConnLensOpts) *worseConnInput {\n\tret := &worseConnInput{\n\t\tUseful:             p.useful(),\n\t\tLastHelpful:        p.lastHelpful(),\n\t\tCompletedHandshake: p.completedHandshake,\n\t\tPointer:            uintptr(unsafe.Pointer(p)),\n\t\tGetPeerPriority:    p.peerPriority,\n\t}\n\tif opts.incomingIsBad && !p.outgoing {\n\t\tret.BadDirection = true\n\t} else if opts.outgoingIsBad && p.outgoing {\n\t\tret.BadDirection = true\n\t}\n\treturn ret\n}\n\nfunc (l *worseConnInput) Less(r *worseConnInput) bool {\n\tless, ok := multiless.New().Bool(\n\t\tr.BadDirection, l.BadDirection).Bool(\n\t\tl.Useful, r.Useful).CmpInt64(\n\t\tl.LastHelpful.Sub(r.LastHelpful).Nanoseconds()).CmpInt64(\n\t\tl.CompletedHandshake.Sub(r.CompletedHandshake).Nanoseconds()).LazySameLess(\n\t\tfunc() (same, less bool) {\n\t\t\tl.doGetPeerPriorityOnce()\n\t\t\tif l.peerPriorityErr != nil {\n\t\t\t\tsame = true\n\t\t\t\treturn\n\t\t\t}\n\t\t\tr.doGetPeerPriorityOnce()\n\t\t\tif r.peerPriorityErr != nil {\n\t\t\t\tsame = true\n\t\t\t\treturn\n\t\t\t}\n\t\t\tsame = l.peerPriority == r.peerPriority\n\t\t\tless = l.peerPriority < r.peerPriority\n\t\t\treturn\n\t\t}).Uintptr(\n\t\tl.Pointer, r.Pointer,\n\t).LessOk()\n\tif !ok {\n\t\tpanic(fmt.Sprintf(\"cannot differentiate %#v and %#v\", l, r))\n\t}\n\treturn less\n}\n\ntype worseConnSlice struct {\n\tconns []*PeerConn\n\tkeys  []*worseConnInput\n}\n\nfunc (me *worseConnSlice) initKeys(opts worseConnLensOpts) {\n\tme.keys = make([]*worseConnInput, len(me.conns))\n\tfor i, c := range me.conns {\n\t\tme.keys[i] = worseConnInputFromPeer(c, opts)\n\t}\n}\n\nvar _ heap.Interface = (*worseConnSlice)(nil)\n\nfunc (me *worseConnSlice) Len() int {\n\treturn len(me.conns)\n}\n\nfunc (me *worseConnSlice) Less(i, j int) bool {\n\treturn me.keys[i].Less(me.keys[j])\n}\n\nfunc (me *worseConnSlice) Pop() interface{} {\n\ti := len(me.conns) - 1\n\tret := me.conns[i]\n\tme.conns = me.conns[:i]\n\treturn ret\n}\n\nfunc (me *worseConnSlice) Push(x interface{}) {\n\tpanic(\"not implemented\")\n}\n\nfunc (me *worseConnSlice) Swap(i, j int) {\n\tme.conns[i], me.conns[j] = me.conns[j], me.conns[i]\n\tme.keys[i], me.keys[j] = me.keys[j], me.keys[i]\n}\n"
        },
        {
          "name": "worse-conns_test.go",
          "type": "blob",
          "size": 1.201171875,
          "content": "package torrent\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\tqt \"github.com/frankban/quicktest\"\n)\n\nfunc TestWorseConnLastHelpful(t *testing.T) {\n\tc := qt.New(t)\n\tc.Check((&worseConnInput{}).Less(&worseConnInput{LastHelpful: time.Now()}), qt.IsTrue)\n\tc.Check((&worseConnInput{}).Less(&worseConnInput{CompletedHandshake: time.Now()}), qt.IsTrue)\n\tc.Check((&worseConnInput{LastHelpful: time.Now()}).Less(&worseConnInput{CompletedHandshake: time.Now()}), qt.IsFalse)\n\tc.Check((&worseConnInput{\n\t\tLastHelpful: time.Now(),\n\t}).Less(&worseConnInput{\n\t\tLastHelpful:        time.Now(),\n\t\tCompletedHandshake: time.Now(),\n\t}), qt.IsTrue)\n\tnow := time.Now()\n\tc.Check((&worseConnInput{\n\t\tLastHelpful: now,\n\t}).Less(&worseConnInput{\n\t\tLastHelpful:        now.Add(-time.Nanosecond),\n\t\tCompletedHandshake: now,\n\t}), qt.IsFalse)\n\treadyPeerPriority := func() (peerPriority, error) {\n\t\treturn 42, nil\n\t}\n\tc.Check((&worseConnInput{\n\t\tGetPeerPriority: readyPeerPriority,\n\t}).Less(&worseConnInput{\n\t\tGetPeerPriority: readyPeerPriority,\n\t\tPointer:         1,\n\t}), qt.IsTrue)\n\tc.Check((&worseConnInput{\n\t\tGetPeerPriority: readyPeerPriority,\n\t\tPointer:         2,\n\t}).Less(&worseConnInput{\n\t\tGetPeerPriority: readyPeerPriority,\n\t\tPointer:         1,\n\t}), qt.IsFalse)\n}\n"
        },
        {
          "name": "wstracker.go",
          "type": "blob",
          "size": 2.7275390625,
          "content": "package torrent\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net\"\n\tnetHttp \"net/http\"\n\t\"net/url\"\n\t\"sync\"\n\n\t\"github.com/anacrolix/log\"\n\t\"github.com/gorilla/websocket\"\n\t\"github.com/pion/webrtc/v4\"\n\n\t\"github.com/anacrolix/torrent/tracker\"\n\thttpTracker \"github.com/anacrolix/torrent/tracker/http\"\n\t\"github.com/anacrolix/torrent/webtorrent\"\n)\n\ntype websocketTrackerStatus struct {\n\turl url.URL\n\ttc  *webtorrent.TrackerClient\n}\n\nfunc (me websocketTrackerStatus) statusLine() string {\n\treturn fmt.Sprintf(\"%+v\", me.tc.Stats())\n}\n\nfunc (me websocketTrackerStatus) URL() *url.URL {\n\treturn &me.url\n}\n\nfunc (me websocketTrackerStatus) Stop() {\n}\n\ntype refCountedWebtorrentTrackerClient struct {\n\twebtorrent.TrackerClient\n\trefCount int\n}\n\ntype websocketTrackers struct {\n\tPeerId                     [20]byte\n\tLogger                     log.Logger\n\tGetAnnounceRequest         func(event tracker.AnnounceEvent, infoHash [20]byte) (tracker.AnnounceRequest, error)\n\tOnConn                     func(webtorrent.DataChannelConn, webtorrent.DataChannelContext)\n\tmu                         sync.Mutex\n\tclients                    map[string]*refCountedWebtorrentTrackerClient\n\tProxy                      httpTracker.ProxyFunc\n\tDialContext                func(ctx context.Context, network, addr string) (net.Conn, error)\n\tWebsocketTrackerHttpHeader func() netHttp.Header\n\tICEServers                 []webrtc.ICEServer\n}\n\nfunc (me *websocketTrackers) Get(url string, infoHash [20]byte) (*webtorrent.TrackerClient, func()) {\n\tme.mu.Lock()\n\tdefer me.mu.Unlock()\n\tvalue, ok := me.clients[url]\n\tif !ok {\n\t\tdialer := &websocket.Dialer{\n\t\t\tProxy:            me.Proxy,\n\t\t\tNetDialContext:   me.DialContext,\n\t\t\tHandshakeTimeout: websocket.DefaultDialer.HandshakeTimeout,\n\t\t}\n\t\tvalue = &refCountedWebtorrentTrackerClient{\n\t\t\tTrackerClient: webtorrent.TrackerClient{\n\t\t\t\tDialer:             dialer,\n\t\t\t\tUrl:                url,\n\t\t\t\tGetAnnounceRequest: me.GetAnnounceRequest,\n\t\t\t\tPeerId:             me.PeerId,\n\t\t\t\tOnConn:             me.OnConn,\n\t\t\t\tLogger: me.Logger.WithText(\n\t\t\t\t\tfunc(m log.Msg) string {\n\t\t\t\t\t\treturn fmt.Sprintf(\"tracker client for %q: %v\", url, m)\n\t\t\t\t\t},\n\t\t\t\t),\n\t\t\t\tWebsocketTrackerHttpHeader: me.WebsocketTrackerHttpHeader,\n\t\t\t\tICEServers:                 me.ICEServers,\n\t\t\t},\n\t\t}\n\t\tvalue.TrackerClient.Start(func(err error) {\n\t\t\tif err != nil {\n\t\t\t\tme.Logger.Printf(\"error running tracker client for %q: %v\", url, err)\n\t\t\t}\n\t\t})\n\t\tif me.clients == nil {\n\t\t\tme.clients = make(map[string]*refCountedWebtorrentTrackerClient)\n\t\t}\n\t\tme.clients[url] = value\n\t}\n\tvalue.refCount++\n\treturn &value.TrackerClient, func() {\n\t\tme.mu.Lock()\n\t\tdefer me.mu.Unlock()\n\t\tvalue.TrackerClient.CloseOffersForInfohash(infoHash)\n\t\tvalue.refCount--\n\t\tif value.refCount == 0 {\n\t\t\tvalue.TrackerClient.Close()\n\t\t\tdelete(me.clients, url)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "zero-reader.go",
          "type": "blob",
          "size": 0.1669921875,
          "content": "package torrent\n\nvar zeroReader zeroReaderType\n\ntype zeroReaderType struct{}\n\nfunc (me zeroReaderType) Read(b []byte) (n int, err error) {\n\tclear(b)\n\tn = len(b)\n\treturn\n}\n"
        }
      ]
    }
  ]
}