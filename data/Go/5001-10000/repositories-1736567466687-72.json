{
  "metadata": {
    "timestamp": 1736567466687,
    "page": 72,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "centrifugal/centrifugo",
      "stars": 8594,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0244140625,
          "content": "misc/* linguist-vendored\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3466796875,
          "content": ".DS_Store\ncentrifugo\nconfig.yaml\nconfig.json\nconfig.json.*\nconfig.*.json\nBUILDS\nPACKAGES\nFlameGraph\ntorch.svg\nprotoc-3*\n.venv\n.vscode\n.idea\ndocs/site\ninternal/ultra\nmisc/clickhouse_cluster/clickhouse*\nmisc/clickhouse_cluster/zookeeper\nmisc/redis_instances/redis_data\nmisc/redis_cluster/cluster_data\nmisc/nats_cluster/nats_logs\nvendor/\n*.orig\ntmp/\n.rocks/\n"
        },
        {
          "name": ".goreleaser.yml",
          "type": "blob",
          "size": 3.9609375,
          "content": "project_name: centrifugo\nrelease:\n  github:\n    owner: centrifugal\n    name: centrifugo\n  name_template: '{{.Tag}}'\n  prerelease: auto\n  draft: true\n  extra_files:\n    - glob: ./PACKAGES/*.deb\n    - glob: ./PACKAGES/*.rpm\n    - glob: ./PACKAGES/*.txt\nbrews:\n  -\n    tap:\n      owner: centrifugal\n      name: homebrew-centrifugo\n    folder: Formula\n    description: \"Scalable real-time messaging server in a language-agnostic way\"\n    commit_author:\n      name: Alexander Emelin\n      email: frvzmb@gmail.com\n    install: bin.install \"centrifugo\"\n    homepage: \"https://github.com/centrifugal/centrifugo\"\nbuilds:\n- goos:\n  - linux\n  - darwin\n  - freebsd\n  - windows\n  goarch:\n  - amd64\n  - \"386\"\n  - arm  \n  - arm64\n  ignore:\n    - goos: darwin\n      goarch: \"386\"\n    - goos: windows\n      goarch: \"386\"\n    - goos: freebsd\n      goarch: \"386\"\n    - goos: darwin\n      goarch: arm\n    - goos: windows\n      goarch: arm\n    - goos: freebsd\n      goarch: arm\n    - goos: windows\n      goarch: arm64\n    - goos: freebsd\n      goarch: arm64\n  main: .\n  ldflags: -s -w -X github.com/centrifugal/centrifugo/v5/internal/build.Version={{.Version}} -X github.com/centrifugal/centrifugo/v5/internal/build.UsageStatsEndpoint={{ .Env.STATS_ENDPOINT }} -X github.com/centrifugal/centrifugo/v5/internal/build.UsageStatsToken={{ .Env.STATS_TOKEN }}\n  binary: centrifugo\n  env:\n    # https://github.com/goreleaser/goreleaser/issues/225\n    - CGO_ENABLED=0\narchives:\n  - id: centrifugo\n    name_template: '{{ .ProjectName }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}'\n    format: tar.gz\n    files:\n    - LICENSE*\n    - README*\n    - CHANGELOG*\n    format_overrides:\n      - goos: windows\n        format: zip\nchecksum:\n  name_template: '{{ .ProjectName }}_{{ .Version }}_checksums.txt'\ndist: dist\nsigns:\n  -\n    cmd: gpg\n    args:\n    - --output\n    - $signature\n    - --detach-sig\n    - $artifact\n    signature: ${artifact}.sig\n    artifacts: none\ndockers:\n  - ids:\n      - centrifugo\n    goos: linux\n    goarch: amd64\n    image_templates:\n    - \"centrifugo/centrifugo:{{ .Tag }}-amd64\"\n    - \"centrifugo/centrifugo:v{{ .Major }}-amd64\"\n    - \"centrifugo/centrifugo:v{{ .Major }}.{{ .Minor }}-amd64\"\n    - \"centrifugo/centrifugo:latest-amd64\"\n    use: buildx\n    build_flag_templates:\n    - \"--pull\"\n    - \"--label=org.opencontainers.image.created={{.Date}}\"\n    - \"--label=org.opencontainers.image.name={{.ProjectName}}\"\n    - \"--label=org.opencontainers.image.revision={{.FullCommit}}\"\n    - \"--label=org.opencontainers.image.version={{.Version}}\"\n    - \"--label=org.opencontainers.image.source={{.GitURL}}\"\n    - \"--platform=linux/amd64\"\n  - ids:\n      - centrifugo\n    goos: linux\n    goarch: arm64\n    image_templates:\n    - \"centrifugo/centrifugo:{{ .Tag }}-arm64v8\"\n    - \"centrifugo/centrifugo:v{{ .Major }}-arm64v8\"\n    - \"centrifugo/centrifugo:v{{ .Major }}.{{ .Minor }}-arm64v8\"\n    - \"centrifugo/centrifugo:latest-arm64v8\"\n    use: buildx\n    build_flag_templates:\n    - \"--pull\"\n    - \"--label=org.opencontainers.image.created={{.Date}}\"\n    - \"--label=org.opencontainers.image.name={{.ProjectName}}\"\n    - \"--label=org.opencontainers.image.revision={{.FullCommit}}\"\n    - \"--label=org.opencontainers.image.version={{.Version}}\"\n    - \"--label=org.opencontainers.image.source={{.GitURL}}\"\n    - \"--platform=linux/arm64/v8\"\ndocker_manifests:\n  - name_template: centrifugo/centrifugo:{{ .Tag }}\n    image_templates:\n      - centrifugo/centrifugo:{{ .Tag }}-arm64v8\n      - centrifugo/centrifugo:{{ .Tag }}-amd64\n  - name_template: centrifugo/centrifugo:v{{ .Major }}\n    image_templates:\n      - centrifugo/centrifugo:{{ .Tag }}-arm64v8\n      - centrifugo/centrifugo:{{ .Tag }}-amd64\n  - name_template: centrifugo/centrifugo:v{{ .Major }}.{{ .Minor }}\n    image_templates:\n      - centrifugo/centrifugo:{{ .Tag }}-arm64v8\n      - centrifugo/centrifugo:{{ .Tag }}-amd64\n  - name_template: centrifugo/centrifugo:latest\n    image_templates:\n      - centrifugo/centrifugo:{{ .Tag }}-arm64v8\n      - centrifugo/centrifugo:{{ .Tag }}-amd64\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 98.517578125,
          "content": "v5.1.2 and higher\n=================\n\nSince Centrifugo v5.1.2 we do not maintain CHANGELOG.md file.\n\nAll changes may be found on [Centrifugo releases page](https://github.com/centrifugal/centrifugo/releases) on Github.\n\nv5.1.1\n======\n\n### Improvements\n\n* Option to extract client connection user ID from HTTP header [#730](https://github.com/centrifugal/centrifugo/pull/730). See [documentation](https://centrifugal.dev/docs/server/configuration#client_user_id_http_header) for it.\n* Speed up channel config operations by using atomic.Value and reduce allocations upon channel namespace extraction by using channel options cache, [#727](https://github.com/centrifugal/centrifugo/pull/727)\n* New metrics for the size of messages sent and received by Centrifugo real-time transport. And we finally described all the metrics exposed by Centrifugo in docs - see [Server observability -> Exposed metrics](https://centrifugal.dev/docs/server/observability#exposed-metrics)\n\n### Fixes\n\n* Fix `Lua redis lib command arguments must be strings or integers script` error when calling Redis reversed history and the stream metadata key does not exist, [#732](https://github.com/centrifugal/centrifugo/issues/732)\n\n### Misc\n\n* Dependencies updated (rueidis, quic-go, etc)\n* Improved logging for bidirectional emulation transports and unidirectional transports - avoid unnecessary error logs\n\nv5.1.0\n======\n\n### Improvements\n\n* Support for EC keys in JWK sets and EC JWTs when using JWKS [#720](https://github.com/centrifugal/centrifugo/pull/720) by @shaunco, [JWKS docs updated](https://centrifugal.dev/docs/server/authentication#json-web-key-support)\n* Experimental GRPC proxy subscription streams [#722](https://github.com/centrifugal/centrifugo/pull/722) - this is like [Websocketd](https://github.com/joewalnes/websocketd) but on network steroids 🔥. Streaming request semantics - both unidirectional and bidirectional – is now super-simple to achieve with Centrifugo and GRPC. See additional details about motivation, design, scalability concerns and basic examples in [docs](https://centrifugal.dev/docs/server/proxy_streams)\n* Transport error mode for server HTTP and GRPC APIs [#690](https://github.com/centrifugal/centrifugo/pull/690) - read [more in docs](https://centrifugal.dev/docs/server/server_api#transport-error-mode)\n* Support GRPC gzip compression [#723](https://github.com/centrifugal/centrifugo/pull/723). GRPC servers Centrifugo has now recognize gzip compression, proxy requests can optionally use compression for calls (see [updated proxy docs](https://centrifugal.dev/docs/server/proxy)).\n\n### Misc\n\n* Release is built with Go 1.21.3\n* Dependencies updated (crypto, otel, msgpack, etc)\n\nv5.0.4\n======\n\n### Improvements\n\n* Support `expire_at` field of SubscribeResult from Subscribe Proxy [#707](https://github.com/centrifugal/centrifugo/pull/707)\n* Option to skip client token signature verification [#708](https://github.com/centrifugal/centrifugo/pull/708)\n\n### Fixes\n\n* Fix connecting to Redis server over unix socket - inherited from [centrifugal/centrifuge#318](https://github.com/centrifugal/centrifuge/pull/318) by @tie\n\n### Misc\n\n* Release is built with Go 1.21.1\n* Dependencies updated (centrifuge, quic-go, grpc, and others)\n\nv5.0.3\n======\n\n### Improvements\n\n* Add support for GRPC exporter protocol in opentelemetry tracing, by @SinimaWath in [#691](https://github.com/centrifugal/centrifugo/pull/691)\n\n### Misc\n\n* Release is built with Go 1.20.7\n* Dependencies updated (rueidis, quic-go, opentelemetry, etc)\n\nv5.0.2\n======\n\n### Improvements\n\n* Quiet mode and no expiration for gentoken/gensubtoken cli commands [#681](https://github.com/centrifugal/centrifugo/pull/681) - so token generation using cli helpers is more flexible now\n* Add `proxy_static_http_headers` option and `static_http_headers` key for granular proxy [#687](https://github.com/centrifugal/centrifugo/pull/687) - so it's possible to append custom headers to HTTP proxy requests.\n\n### Fixes\n\n* Suppress warnings about k8s env vars, see [issue](https://github.com/centrifugal/centrifugo/issues/678)\n\n### Misc\n\n* Release is built with Go 1.20.7\n* Dependencies updated (rueidis, quic-go, crypto, etc)\n* Replace `interface{}` with `any` in code base, [#682](https://github.com/centrifugal/centrifugo/pull/682)\n\nv5.0.1\n======\n\n* Fix panic upon subscription token validation caused by nil interface comparison, [commit](https://github.com/centrifugal/centrifugo/commit/fe2a92da24d1e8a473e559224fc5c87895713f6a)\n\nv5.0.0\n======\n\nIn Centrifugo v5 we're phasing out old client protocol support, introducing a more intuitive HTTP API, adjusting token management behaviour in SDKs, improving configuration process, and refactoring the history meta ttl option. As the result you get a cleaner, more user-friendly, and optimized Centrifugo experience.\n\nAll the major details about the release may be found in [Centrifugo v5 release announcement](https://centrifugal.dev/blog/2023/06/29/centrifugo-v5-released) in our blog.\n\nWe also prepared [Centrifugo v5 migration guide](https://centrifugal.dev/docs/getting-started/migration_v5) which has more specific details about changes.\n\nv4.1.3\n======\n\n### Improvements\n\n* Dynamic JWKS endpoint based on iss and aud – implemented in [#638](https://github.com/centrifugal/centrifugo/pull/638), [documented here](https://centrifugal.dev/docs/server/authentication#dynamic-jwks-endpoint)\n* Add [redis_force_resp2](https://centrifugal.dev/docs/server/engines#redis_force_resp2) option, [#641](https://github.com/centrifugal/centrifugo/pull/641)\n* Document [client_stale_close_delay](https://centrifugal.dev/docs/server/configuration#client_stale_close_delay), make it 10 sec  instead of 25 sec by default, relates [#639](https://github.com/centrifugal/centrifugo/issues/639)\n\n### Misc\n\n* This release is built with Go 1.20.3\n\nv4.1.2\n======\n\n### Fixes\n\n* Fix decoding of large protocol messages. The bug was introduced by v4.1.1. See [bug report](https://github.com/centrifugal/centrifugo/issues/603)\n\nv4.1.1\n======\n\n### Improvements\n\n* Possibility to disable client protocol v1 using `disable_client_protocol_v1` boolean option. To remind you about client protocol v1 vs v2 migration in Centrifugo v4 take a look at [v3 to v4 migration guide](https://centrifugal.dev/docs/getting-started/migration_v4#client-sdk-migration). Centrifugo v4 uses client protocol v2 by default, all our recent SDKs only support client protocol v2. So if you are using modern stack then you can disable clients to use outdated protocol v1 right now. In Centrifugo v5 support for client protocol v1 will be completely removed, see [Centrifugo v5 roadmap](https://github.com/centrifugal/centrifugo/issues/599).\n* New boolean option `disallow_anonymous_connection_tokens`. When the option is set Centrifugo won't accept connections from anonymous users even if they provided a valid JWT. See [#591](https://github.com/centrifugal/centrifugo/issues/591)\n* New option `client_connection_rate_limit` to limit the number of new real-time connections Centrifugo may accept per second, see [docs](https://centrifugal.dev/docs/server/configuration#client_connection_rate_limit)\n* Implement `sub_refresh` proxy to periodically validate expiring subscriptions over the call from Centrifugo to the backend endpoint, see [#592](https://github.com/centrifugal/centrifugo/issues/592) and [docs](https://centrifugal.dev/docs/server/proxy#sub-refresh-proxy)\n* More human-readable tracing logging output (especially in Protobuf protocol case). On the other hand, tracing log level is much more expensive now. We never assumed it will be used in production – so seems an acceptable trade-off.\n* Several internal optimizations in client protocol to reduce memory allocations.\n* More strict client protocol: only allow one pong message from client to server after receiving ping, disable sending commands over the connection which returned an error to the Connect command\n\n### Fixes\n\n* Fix: slow down subscription dissolver workers while Redis PUB/SUB is unavailable. This solves a CPU usage spike which may happen while Redis PUB/SUB is unavailable and last client unsubscribes from some channel.\n* Relative static paths in Centrifugo admin web UI (to fix work behind reverse proxy on sub-path)\n\nv4.1.0\n======\n\n### Improvements\n\n* Fully rewritten Redis engine using [rueian/rueidis](https://github.com/rueian/rueidis) library. Many thanks to [@j178](https://github.com/j178) and [@rueian](https://github.com/rueian) for the help. Check out details in our blog post [Improving Centrifugo Redis Engine throughput and allocation efficiency with Rueidis Go library](https://centrifugal.dev/blog/2022/12/20/improving-redis-engine-performance). We expect that new implementation is backwards compatible with the previous one except some timeout options which were not documented, please report issues if any.\n* Extended TLS configuration for Redis – it's now possible to set CA root cert, client TLS certs, set custom server name for TLS. See more details in the [updated Redis Engine option docs](https://centrifugal.dev/docs/server/engines#redis-engine-options). Also, it's now possible to provide certificates as strings.\n\nv4.0.5\n======\n\n### Fixes\n\n* Fix non-working bidirectional emulation in multi-node case [#590](https://github.com/centrifugal/centrifugo/issues/590)\n* Process client channels for no-credentials case also, see issue [#581](https://github.com/centrifugal/centrifugo/issues/581)\n* Fix setting `allow_positioning` for top-level namespace, [commit](https://github.com/centrifugal/centrifugo/commit/dbaf01776ff294ee6731cd5422146c0f23107cce)\n\n### Misc\n\n* This release is built with Go 1.19.4\n\nv4.0.4\n======\n\nThis release contains an important fix of Centrifugo memory leak. The leak happens in all setups which use Centrifugo v4.0.2 or v4.0.3.\n\n### Fixes\n\n* Fix goroutine leak on connection close introduced by v4.0.2, [commit](https://github.com/centrifugal/centrifuge/commit/82107b38a42561ca022d50f7ee2ca038a6f120e9)\n\n### Misc\n\n* This release is built with Go 1.19.3\n\nv4.0.3\n======\n\n### Fixes\n\n* Fix insensitive case match for granular proxy headers, [#572](https://github.com/centrifugal/centrifugo/issues/572)\n\nv4.0.2\n======\n\nThis release contains one more fix of v4 degradation (not respecting `force_push_join_leave` option for top-level namespace), comes with updated admin web UI and other improvements.\n\n### Fixes\n\n* Handle `force_push_join_leave` option set for top-level namespace – it was ignored so join/leave messages were not delivered to clients, [commit](https://github.com/centrifugal/centrifugo/commit/a2409fb7465e348275d87a9d94db5bea5bae357d)\n* Properly handle `b64data` in server publish API, [commit](https://github.com/centrifugal/centrifugo/commit/e205bca549c6104b608273e2a9c8a777f0083d92)\n\n### Improvements\n\n* Updated admin web UI. It now uses modern React stack, fresh look based on Material UI and several other small improvements. See [#566](https://github.com/centrifugal/centrifugo/pull/566) for more details\n* Case-insensitive http proxy header configuration [#558](https://github.com/centrifugal/centrifugo/pull/558)\n* Use Alpine 3.16 instead of 3.13 for Docker builds, [commit](https://github.com/centrifugal/centrifugo/commit/0c1332ffb335266ce4ff88750985c27263b13de2)\n* Add missing empty object results to API command responses, [commit](https://github.com/centrifugal/centrifugo/commit/bdfdc1eeadd99eb4e30162c70accb02b1b1e32d2)\n* Disconnect clients in case of inappropriate protocol [centrifugal/centrifuge#256](https://github.com/centrifugal/centrifuge/pull/256)\n\n### Misc\n\n* This release is built with Go 1.19.2\n\nv4.0.1\n======\n\nThis release contains an important fix of v4 degradation (proxying user limited channel) and comes with several nice improvements.\n\n### Fixes\n\n* Avoid proxying user limited channel [#550](https://github.com/centrifugal/centrifugo/pull/550)\n* Look at subscription source to handle token subs change [#545](https://github.com/centrifugal/centrifugo/pull/545)\n\n### Improvements\n\n* Configure server-to-client ping/pong intervals [#551](https://github.com/centrifugal/centrifugo/pull/551), [docs](https://centrifugal.dev/docs/transports/overview#pingpong-behavior)\n* Option `client_connection_limit` to set client connection limit for a single Centrifugo node [#546](https://github.com/centrifugal/centrifugo/pull/546), [docs](https://centrifugal.dev/docs/server/configuration#client_connection_limit)\n* Option `api_external` to expose API handler on external port [#536](https://github.com/centrifugal/centrifugo/issues/536)\n* Use `go.uber.org/automaxprocs` to set GOMAXPROCS [#528](https://github.com/centrifugal/centrifugo/pull/528), this may help to automatically improve Centrifugo performance when it's running in an environment with cgroup-restricted CPU resources (Docker, Kubernetes).\n* Nats broker: use push format from client protocol v2 [#542](https://github.com/centrifugal/centrifugo/pull/542)\n\n### Misc\n\n* While working on [Centrifuge](https://github.com/centrifugal/centrifuge) lib [@j178](https://github.com/j178) found a scenario where connection to Redis could leak, this was not observed and reported in Centrifugo outside the test suite, but it seems that theoretically connections to Redis from Centrifugo could leak with time if the network between Centrifugo and Redis is unstable. This release contains an updated Redis engine which eliminates this.\n* This release is built with Go 1.18.5\n\nv4.0.0\n======\n\nNew v4 release puts Centrifugo to the next level in terms of client protocol performance, WebSocket fallback simplicity, SDK ecosystem and channel security model. This is a major release with breaking changes according to our [Centrifugo v4 roadmap](https://github.com/centrifugal/centrifugo/issues/500).\n\nSeveral important documents we have at this point can help you get started with Centrifugo v4:\n\n* Centrifugo v4 [release blog post](https://centrifugal.dev/blog/2022/07/10/centrifugo-v4-released)\n* Centrifugo v3 -> v4 [migration guide](https://centrifugal.dev/docs/getting-started/migration_v4)\n* Client SDK API [specification](https://centrifugal.dev/docs/transports/client_api)\n* Updated [quickstart tutorial](https://centrifugal.dev/docs/getting-started/quickstart)\n\n### Highlights\n\n* New client protocol iteration and unified client SDK API. See client SDK API [specification](https://centrifugal.dev/docs/transports/client_api).\n* All SDKs now support all the core features of Centrifugo - see [feature matrix](https://centrifugal.dev/docs/transports/client_sdk#sdk-feature-matrix)\n* Our own WebSocket bidirectional emulation layer based on HTTP-streaming and SSE (EventSource). Without sticky session requirement for a distributed case. See details in release post and [centrifuge-js README](https://github.com/centrifugal/centrifuge-js/tree/master#bidirectional-emulation)\n* SockJS is still supported but DEPRECATED\n* Redesigned, more efficient PING-PONG – see details in release post\n* Optimistic subscriptions support (implemented in `centrifuge-js` only at this point) – see details in release post\n* Secure by default channel namespaces – see details in release post\n* Private channel and subscription JWT concepts revised – see details in release post\n* Possibility to enable join/leave, recovery and positioning from the client-side\n* Experimental HTTP/3 support - see details in release post\n* Experimental WebTransport support - see details in release post\n* Avoid sending JSON in WebSocket Close frame reason\n* Temporary flag for errors, allows resilient behavior of Subscriptions\n* `gensubtoken` and `checksubtoken` helper cli commands as subscription JWT now behaves similar to connection JWT\n* Legacy options removed, some options renamed, see [migration guide](https://centrifugal.dev/docs/getting-started/migration_v4) for details.\n* `meta` attached to a connection now updated upon connection refresh\n* `centrifuge-js` migrated to Typescript\n* The docs on [centrifugal.dev](https://centrifugal.dev/) were updated for v4, docs for v3 are still there but under version switch widget.\n* Use constant time compare function to compare admin_password and api_key [#527](https://github.com/centrifugal/centrifugo/pull/527)\n\n### Misc\n\n* This release is built with Go 1.18.4\n\nv3.2.3\n======\n\nNo backwards incompatible changes here.\n\n### Improvements\n\n* Support Debian bullseye DEB package release, drop Debian jessie, [#520](https://github.com/centrifugal/centrifugo/issues/520)\n\n### Fixes\n\n* Fix emitting Join message in dynamic server subscribe case (when calling subscribe server API), [centrifugal/centrifuge#231](https://github.com/centrifugal/centrifuge/issues/231).\n\nv3.2.2\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* Fix top-level granular subscribe and publish proxies [#517](https://github.com/centrifugal/centrifugo/issues/517).\n\n### Misc\n\n* This release is built with Go 1.17.11.\n\nv3.2.1\n======\n\nNo backwards incompatible changes here.\n\n### Improvements\n\n* Centrifugo now periodically sends anonymous usage information (once in 24 hours). That information is impersonal and does not include sensitive data, passwords, IP addresses, hostnames, etc. Only counters to estimate version and installation size distribution, and feature usage. See implementation in [#516](https://github.com/centrifugal/centrifugo/pull/516). Please do not disable usage stats sending without reason. If you depend on Centrifugo – sure you are interested in further project improvements. Usage stats help us understand Centrifugo use cases better, concentrate on widely-used features, and be confident we are moving in the right direction. Developing in the dark is hard, and decisions may be non-optimal. See [docs](https://centrifugal.dev/docs/next/server/configuration#anonymous-usage-stats) for more details.\n\n### Misc\n\n* We continue working on Centrifugo v4, look at our [v4 roadmap](https://github.com/centrifugal/centrifugo/issues/500) where the latest updates are shared. BTW Centrifugo v3 already has code to work over new protocol which we aim to make default in v4. It's already possible to try out our own bidirectional emulation layer with HTTP-streaming and Eventsource transports. Don't hesitate reaching out if you depend on Centrifugo and want to understand more what's coming in next major release. We are actively collecting feedback at the moment.\n* This release is built with Go 1.17.10.\n\nv3.2.0\n======\n\nThis release **contains backwards incompatible changes in experimental Tarantool engine** (see details below).\n\n### Improvements\n\n* Support checking `aud` and `iss` JWT claims [#496](https://github.com/centrifugal/centrifugo/pull/496). See more details in docs: [aud](https://centrifugal.dev/docs/server/authentication#aud), [iss](https://centrifugal.dev/docs/server/authentication#iss).\n* Channel Publication now has `tags` field (`map[string]string`) – this is a map with arbitrary keys and values which travels with publications. It may help to put some useful info into publication without modifying payload. It can also help to avoid processing payload in some scenarios. Publish and broadcast server APIs got support for setting `tags`. Though supporting this field throughout our ecosystem (for example expose it in all our client SDKs) may take some time. Server API docs for [publish](https://centrifugal.dev/docs/server/server_api#publish) and [broadcast](https://centrifugal.dev/docs/server/server_api#broadcast) commands have been updated.\n* Support setting user for Redis ACL-based auth, for Redis itself and for Sentinel. See [in docs](https://centrifugal.dev/docs/server/engines#redis_user).\n* Unidirectional transports now return a per-connection generated `session` unique string. This unique string attached to a connection on start, in addition to client ID. It allows controlling unidirectional connections using server API. Previously we suggested using client ID for this – but turns out it's not really a working approach since client ID can be exposed to other users in Publications, presence, join/leave messages. So backend can not distinguish whether user passed its own client ID or not. With `session` which is not shared at all things work in a more secure manner. Server API docs for [subscribe](https://centrifugal.dev/docs/server/server_api#subscribe), [unsubscribe](https://centrifugal.dev/docs/server/server_api#unsubscribe), [disconnect](https://centrifugal.dev/docs/server/server_api#disconnect) and [refresh](https://centrifugal.dev/docs/server/server_api#refresh) commands have been updated.\n* Report line and column for JSON config file syntax error – see [#497](https://github.com/centrifugal/centrifugo/issues/497)\n* Improve performance (less memory allocations) in message broadcast, during WebSocket initial connect and during disconnect.\n\n### Breaking changes\n\n* **Breaking change in experimental Tarantool integration**. In Centrifugo v3.2.0 we updated code to work with a new version of [tarantool-centrifuge](https://github.com/centrifugal/tarantool-centrifuge). `tarantool-centrifuge` v0.2.0 has an [updated space schema](https://github.com/centrifugal/tarantool-centrifuge/releases/tag/v0.2.0). This means that Centrifugo v3.2.0 will only work with `tarantool-centrifuge` >= v0.2.0 or [rotor](https://github.com/centrifugal/rotor) >= v0.2.0. We do not provide any migration plan for this update – spaces in Tarantool must be created from scratch. We continue considering Tarantool integration experimental.\n\n### Misc\n\n* This release is built with Go 1.17.9.\n* We continue working on client protocol v2. Centrifugo v3.2.0 includes more parts of it and includes experimental bidirectional emulation support. More details in [#515](https://github.com/centrifugal/centrifugo/pull/515).\n* Check out our progress regarding Centrifugo v4 in [#500](https://github.com/centrifugal/centrifugo/issues/500).\n* New community-driven Centrifugo server API library [Centrifugo.AspNetCore](https://github.com/ismkdc/Centrifugo.AspNetCore) for ASP.NET Core released.\n\nv3.1.1\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Massive JSON client protocol performance improvements in decoding multiple commands in a single frame. See [#215](https://github.com/centrifugal/centrifuge/pull/215) for details.\n* General JSON client protocol performance improvements for unmarshalling messages (~8-10% according to [#215](https://github.com/centrifugal/centrifuge/pull/215))\n* Subscribe proxy can now proxy custom `data` from a client passed in a subscribe command.\n\nThis release is built with Go 1.17.4.\n\nv3.1.0\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Introducing a [granular proxy mode](https://centrifugal.dev/docs/server/proxy#granular-proxy-mode) for a fine-grained proxy configuration. Some background can be found in [#477](https://github.com/centrifugal/centrifugo/issues/477).\n\nAlso check out new tutorials in our blog (both examples can be run with single `docker compose up` command):\n\n* [Centrifugo integration with NodeJS tutorial](https://centrifugal.dev/blog/2021/10/18/integrating-with-nodejs)\n* [Centrifugo integration with Django – building a basic chat application](https://centrifugal.dev/blog/2021/11/04/integrating-with-django-building-chat-application)\n\nCentrifugo [dashboard for Grafana](https://grafana.com/grafana/dashboards/13039) was updated and now uses [$__rate_interval](https://grafana.com/blog/2020/09/28/new-in-grafana-7.2-__rate_interval-for-prometheus-rate-queries-that-just-work/) function of Grafana.\n\nThis release is built with Go 1.17.3.\n\nv3.0.5\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix subscription cleanup on client close. Addresses one more problem found in [this report](https://github.com/centrifugal/centrifugo/issues/486).\n\nv3.0.4\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix deadlock during PUB/SUB sync in channels with recovery. Addresses [this report](https://github.com/centrifugal/centrifugo/issues/486).\n* Fix `redis_db` option: was ignored previously – [#487](https://github.com/centrifugal/centrifugo/issues/487).\n\nv3.0.3\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix passing `data` from subscribe proxy result towards client connection.\n\nThis release is built with Go 1.17.2.\n\nv3.0.2\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix SockJS data escaping on EventSource fallback. See [igm/sockjs-go#100](https://github.com/igm/sockjs-go/issues/100) for more information. In short – this bug could prevent a message with `%` symbol inside be properly parsed by a SockJS Javascript client – thus not processed by a frontend at all.\n* Fix panic on concurrent subscribe to the same channels with recovery feature on. More details in [centrifugal/centrifuge#207](https://github.com/centrifugal/centrifuge/pull/207)\n\nv3.0.1\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix proxy behavior for disconnected clients, should be now consistent between HTTP and GRPC proxy types.\n* Fix `bufio: buffer full` error when unmarshalling large client protocol JSON messages.\n* Fix `unexpected end of JSON input` errors in Javascript client with Centrifugo v3.0.0 when publishing formatted JSON (with new lines).\n\nThis release uses Go 1.17.1. We also added more tests for proxy package, thanks to [@silischev](https://github.com/silischev).\n\nv3.0.0\n======\n\nCentrifugo v3 release is targeting to improve Centrifugo adoption for basic real-time application cases, improves server performance and extends existing features with new functionality. It comes with unidirectional real-time transports, protocol speedups, super-fast engine implementation based on Tarantool, new documentation site ([centrifugal.dev](https://centrifugal.dev)), GRPC proxy, API extensions and PRO version which provides unique possibilities for business adopters.\n\n[Centrifugo v3 introductory blog post](https://centrifugal.dev/blog/2021/08/31/hello-centrifugo-v3) describes the most notable aspects of v3.\n\nThe release has backward incompatible changes. [Centrifugo v3 migration guide](https://centrifugal.dev/docs/getting-started/migration_v3) aims to help with v2 to v3 migration. Migration guide contains a best-effort configuration converter to adapt the existing configuration file for v3.\n\nRelease summary:\n\n* License changed from MIT to Apache 2.0.\n* Support for unidirectional transports (Eventsource, GRPC, HTTP-streaming, WebSocket). [Docs](https://centrifugal.dev/docs/transports/overview) and [introductory blog post](https://centrifugal.dev/blog/2021/08/31/hello-centrifugo-v3) provide more information.\n* Better performance:\n  * Drastically improved JSON client protocol performance, addresses [#460](https://github.com/centrifugal/centrifugo/issues/460)\n  * Sharded in-memory connections hub to reduce lock contention\n  * Less memory allocations during message broadcast\n  * 5% overall additional performance boost due to using Go 1.17\n  * More details in the [introductory blog post](https://centrifugal.dev/blog/2021/08/31/hello-centrifugo-v3)\n* Enhanced client history API (iteration support, [docs](https://centrifugal.dev/docs/server/history_and_recovery)), breaking change in client history call behavior – history now does not return all existing publications in a channel by default. [Migration guide](https://centrifugal.dev/docs/getting-started/migration_v3) covers this.\n* Configuration options cleanups and changes (breaking changes described in details in [migration guide](https://centrifugal.dev/docs/getting-started/migration_v3)).\n  * Channel options changes\n  * Time intervals now set as human-readable durations\n  * Client transport endpoint requests with Origin header set should now explicitly match patterns in `allowed_origins`\n  * Improved Redis Engine configuration\n  * SockJS disabled by default\n  * Some options renamed, and some removed\n  * `history_max_publication_limit` and `recovery_max_publication_limit` options added\n  * `proxy_binary_encoding` option to give a tip to proxy that data should be encoded into base64.\n  * HTTP proxy does not have default headers – should be set explicitly now\n* JWT improvements and changes:\n  * Possibility to pass a list of server-side subscriptions with channel options\n  * Better control on token and connection expiration\n  * See [docs](https://centrifugal.dev/docs/server/authentication)\n* Redis Engine uses Redis Streams by default. [Migration guide](https://centrifugal.dev/docs/getting-started/migration_v3) covers this.\n* GRPC proxy in addition to the existing HTTP proxy. [Docs](https://centrifugal.dev/docs/server/proxy#grpc-proxy).\n* Experimental Tarantool Engine. [Docs](https://centrifugal.dev/docs/server/engines#tarantool-engine).\n* Enhanced server API functionality:\n  * `publish` API now returns offset and epoch for channels with history, fixes [#446](https://github.com/centrifugal/centrifugo/issues/446)\n  * Refactor `channels` API call to work in all cases (was unavailable for Redis Cluster and Nats broker before, fixes [#382](https://github.com/centrifugal/centrifugo/issues/382))\n  * `b64data` and `skip_history` added to Publish API\n  * Enhanced `history` API (iteration)\n  * Extended `disconnect` API\n  * Extended `unsubscribe` API\n  * New `subscribe` API call, fixes [#367](https://github.com/centrifugal/centrifugo/issues/367)\n  * Refer to the [docs](https://centrifugal.dev/docs/server/server_api).\n* Enhanced proxy functionality\n  * Add custom data in subscribe response to a client\n  * `skip_history` for publish proxy\n  * More control over disconnect\n  * Possibility to override subscription related channel options\n  * Possibility to attach custom connection `meta` information which won't be visible by clients, addresses [#457](https://github.com/centrifugal/centrifugo/issues/457)\n  * Refer to the [docs](https://centrifugal.dev/docs/server/proxy).\n* `trace` log level added\n* Better clustering – handle node shutdown\n* Better GRPC API package name – fixes [#379](https://github.com/centrifugal/centrifugo/issues/379)\n* Show total number of different subscriptions on Centrifugo node in Web UI\n* Check user ID to be the same as the current user ID during a client-side refresh, fixes [#456](https://github.com/centrifugal/centrifugo/issues/456)\n* Drop support for POSTing Protobuf to HTTP API endpoint\n* Using Alpine 3.13 as Docker image base\n* Various client connector libraries improvements\n* Various admin web UI improvements\n* Introducing [Centrifugo PRO](https://centrifugal.dev/docs/pro/overview)\n\nv2.8.6\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* RPM and DEB packages now additionally added to release assets\n\nFixes:\n\n* Fixes accidentally pushed Docker latest tag from Centrifugo v3 PRO beta.\n\nCentrifugo v2.8.6 based on latest Go 1.16.6\n\nv2.8.5\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Possibility to modify data in publish proxy – see [#439](https://github.com/centrifugal/centrifugo/issues/439) and [updated docs for publish proxy](https://centrifugal.github.io/centrifugo/server/proxy/#publish-proxy)\n\nFixes:\n\n* Use default timeouts for subscribe and publish proxy (1 second). Previously these proxy had no default timeout at all.\n\nCentrifugo v2.8.5 based on Go 1.16.4\n\nv2.8.4\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* New subcommand `serve` to quickly run a static file server\n\nFixes:\n\n* Fix panic when using connect proxy with a personal channel feature on. See [#436](https://github.com/centrifugal/centrifugo/issues/436)\n\nCentrifugo v2.8.4 based on Go 1.16.3\n\nv2.8.3\n======\n\n**Security warning**: take a closer look at new option `allowed_origins` **if you are using connect proxy feature**.\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Possibility to set `allowed_origins` option ([#431](https://github.com/centrifugal/centrifugo/pull/431)). This option allows setting an array of allowed origin patterns (array of strings) for WebSocket and SockJS endpoints to prevent [Cross site request forgery](https://en.wikipedia.org/wiki/Cross-site_request_forgery) attack. This can be especially important when using [connect proxy](https://centrifugal.github.io/centrifugo/server/proxy/#connect-proxy) feature. If you are using JWT authentication then you should be safe. Note, that since you get an origin header as part of proxy request from Centrifugo it's possible to check allowed origins without upgrading to Centrifugo v2.8.3. See [docs](https://centrifugal.github.io/centrifugo/server/configuration/#allowed_origins) for more details about this new option\n* Multi-arch Docker build support - at the moment for `linux/amd64` and `linux/arm64`. See [#433](https://github.com/centrifugal/centrifugo/pull/433)\n\nCentrifugo v2.8.3 based on latest Go 1.16.2, Centrifugo does not vendor its dependencies anymore.\n\nv2.8.2\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* [JSON Web Key](https://tools.ietf.org/html/rfc7517) support - see [pull request #410](https://github.com/centrifugal/centrifugo/pull/410) and [description in docs](https://centrifugal.github.io/centrifugo/server/authentication/#json-web-key-support)\n* Support ECDSA algorithm for verifying JWT - see [pull request #420](https://github.com/centrifugal/centrifugo/pull/420) and updated [authentication docs chapter](https://centrifugal.github.io/centrifugo/server/authentication/)\n* Various documentation clarifications - did you know that you can [use subscribe proxy instead of private channels](https://centrifugal.github.io/centrifugo/server/proxy/#subscribe-proxy) for example?\n\nFixes:\n\n* Use more strict file permissions for a log file created (when using `log_file` option): `0666` -> `0644`\n* Fix [issue](https://github.com/centrifugal/web/issues/36) with opening admin web UI menu on small screens\n\nOther:\n\n* Centrifugo repo [migrated from Travis CI to GH actions](https://github.com/centrifugal/centrifugo/issues/414), `golangci-lint` now works in CI\n* Check out [a new community package](https://github.com/denis660/laravel-centrifugo) for Laravel that works with the latest version of framework\n\nv2.8.1\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* fix concurrent map access which could result in runtime crash when using presence feature.\n\nv2.8.0\n======\n\nMinor backwards incompatible changes here when using `client_user_connection_limit` option – see below.\n\nCentrifugo v2.8.0 has many internal changes that could affect overall performance and latency. In general, we expect better latency between a client and a server, but servers under heavy load can notice a small regression in CPU usage.\n\nImprovements:\n\n* Centrifugo can now maintain a single connection from a user when personal server-side channel used. See [#396](https://github.com/centrifugal/centrifugo/issues/396) and [docs](https://centrifugal.github.io/centrifugo/server/server_subs/#maintain-single-user-connection)\n* New option `client_concurrency`. This option allows processing client commands concurrently. Depending on your use case this option has potential to radically reduce latency between a client and Centrifugo. See [detailed description in docs](https://centrifugal.github.io/centrifugo/server/configuration/#client_concurrency)\n* When using `client_user_connection_limit` and user reaches max amount of connections Centrifugo will now disconnect client with `connection limit` reason instead of returning `limit exceeded` error. Centrifugo will give a client advice to not reconnect.\n\nCentrifugo v2.8.0 based on latest Go 1.15.5\n\nv2.7.2\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix client reconnects due to `InsufficientState` errors. There were two scenarios when this could happen. The first one is using Redis engine with `seq`/`gen` legacy fields (i.e. not using **v3_use_offset** option). The second when publishing a lot of messages in parallel with Memory engine. Both scenarios should be fixed now.\n* Fix non-working SockJS transport close with custom disconnect code: this is a regression introduced by v2.6.2\n\nv2.7.1\n======\n\nNo backwards incompatible changes here.\n\nFixes:\n\n* Fix non-working websocket close with custom disconnect code: this is a regression introduced by v2.6.2\n\nv2.7.0\n======\n\nThis release has minor backwards incompatible changes in some Prometheus/Graphite metric names. This means that you may need to adapt your monitoring dashboards a bit. See details below.\n\nImprovements:\n\n* Previously metrics exposed by Centrifuge library (which Centrifugo is built on top of) belonged to `centrifuge` Prometheus namespace. This lead to a situation where part of Centrifugo metrics belonged to `centrifugo` and part to `centrifuge` Prometheus namespaces. Starting from v2.7.0 Centrifuge library specific metrics also belong to `centrifugo` namespace. So the rule to migrate is simple: if see `centrifuge` word in a metric name – change it to `centrifugo`. \n* Refreshed login screen of admin web interface with moving Centrifugo logo on canvas – just check it out!\n* New gauge that shows amount of running Centrifugo nodes\n* Centrifugal organization just got [the first baker on Opencollective](https://opencollective.com/centrifugal) ❤️. This is a nice first step in making Centrifugo development sustainable.\n\nFixes:\n\n* Fix `messages_sent_count` counter which did not show control, join and leave messages\n\n**Coming soon 🔥:**\n\n* Official Grafana Dashboard for Prometheus storage is on its way to Centrifugo users. [Track this issue](https://github.com/centrifugal/centrifugo/issues/383) for a status, the work almost finished. \n* Official Centrifugo Helm Chart for Kubernetes. [Track this issue](https://github.com/centrifugal/centrifugo/issues/385) for a status, the work almost finished.\n\nv2.6.2\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Internal refactoring of WebSocket graceful close, should make things a bit more performant (though only in apps which read lots of messages from WebSocket connections)\n* Disconnect code is now `uint32` internally\n* A bit more performant permission checks for publish, history and presence ops \n* Connect proxy request payload can optionally contain `name` and `version` of client if set on client side, see updated [connect proxy docs](https://centrifugal.github.io/centrifugo/server/proxy/#connect-proxy)\n* New blog post [Experimenting with QUIC and WebTransport in Go](https://centrifugal.github.io/centrifugo/blog/quic_web_transport/) in Centrifugo blog\n\nFixes:\n\n* fix panic on connect in 32-bit ARM builds, see [#387](https://github.com/centrifugal/centrifugo/issues/387)\n\nv2.6.1\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Add `grpc_api_key` option, see [in docs](https://centrifugal.github.io/centrifugo/server/grpc_api/#api-key-authorization)\n\nFixes:\n\n* Fix Redis Engine errors related to missing epoch in Redis HASH. If you see errors in servers logs, like `wrong Redis reply epoch` or `redigo: nil returned`, then those should be fixed here. Also take a look at v2.5.2 release which contains backport of this fix if you are on v2.5.x release branch.\n\nv2.6.0\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* New section in docs – Centrifugo dev blog, check out [first post about scaling WebSocket](https://centrifugal.github.io/centrifugo/blog/scaling_websocket/)\n* Possibility to [scale with Nats server](https://centrifugal.github.io/centrifugo/server/engines/#nats-broker) for **unreliable at most once PUB/SUB**\n* Subscribe HTTP proxy, [see docs](https://centrifugal.github.io/centrifugo/server/proxy/#subscribe-proxy)\n* Publish HTTP proxy, [see docs](https://centrifugal.github.io/centrifugo/server/proxy/#publish-proxy)\n* Support for setting Redis Sentinel password, [see in docs](https://centrifugal.github.io/centrifugo/server/engines/#redis-sentinel-for-high-availability)\n* Various documentation improvements since previous release\n\nThis release based on massively updated [Centrifuge](https://github.com/centrifugal/centrifuge) library, we don't expect problems but since many things were refactored – we suggest to carefully test your app.\n\nv2.5.1\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* refreshed [documentation design](https://centrifugal.github.io/centrifugo/)\n* new [Quick start](https://centrifugal.github.io/centrifugo/quick_start/) chapter for those who just start working with Centrifugo \n* faster marshal of disconnect messages into close frame texts, significantly reduces amount of memory allocations during server graceful shutdown in deployments with many connections\n* one beautiful Centrifugo integration with Symfony framework from our community - [check it out](https://github.com/fre5h/CentrifugoBundle)\n\nFixes:\n\n* add `Content-Type: application/json` header to outgoing HTTP proxy requests to app backend for better integration with some frameworks. [#368](https://github.com/centrifugal/centrifugo/issues/368)\n* fix wrong channel name in Join messages sent to client in case of server-side subscription to many channels\n* fix disconnect code unmarshalling after receiving response from HTTP proxy requests, it was ignored previously\n\nv2.5.0\n======\n\nNo backwards incompatible changes here.\n\nStarting from this release we begin migration to new `offset` `uint64` client-server protocol field for Publication position inside history stream instead of currently used `seq` and `gen` (both `uint32`) fields. This `offset` field will be used in Centrifugo v3 by default. This change required to simplify working with history API, and due to this change history API can be later extended with pagination features.\n\nOur client libraries `centrifuge-js`, `centrifuge-go` and `centrifuge-mobile` were updated to support `offset` field. If you are using these libraries then you can update `centrifuge-js` to at least `2.6.0`, `centrifuge-go` to at least `0.5.0` and `centrifuge-mobile` to at least `0.5.0` to work with the newest client-server protocol. As soon as you upgraded mentioned libraries you can enable `offset` support without waiting for Centrifugo v3 release with `v3_use_offset` option:\n\n```json\n{\n  \"v3_use_offset\": true\n}\n```\n\nAll other client libraries except `centrifuge-js`, `centrifuge-go` and `centrifuge-mobile` do not support recovery at this moment and will only work with `offset` field in the future.\n\nIt's important to mention that `centrifuge-js`, `centrifuge-go` and `centrifuge-mobile` will continue to work with a server which is using `seq` and `gen` fields for recovery until Centrifugo v3 release. With Centrifugo v3 release those libraries will be updated to only work with `offset` field.\n\nCommand `centrifugo genconfig` will now generate config file with `v3_use_offset` option enabled. Documentation has been updated to suggest turning on this option for fresh installations.\n\nImprovements:\n\n* support [Redis Streams](https://redis.io/topics/streams-intro) - radically reduces amount of memory allocations during recovery in large history streams. This also opens a road to paginate over history stream in future releases, see description of new `redis_streams` option [in Redis engine docs](https://centrifugal.github.io/centrifugo/server/engines/#redis-streams)\n* support [Redis Cluster](https://redis.io/topics/cluster-tutorial), client-side sharding between different Redis Clusters also works, see more [in docs](https://centrifugal.github.io/centrifugo/server/engines/#redis-cluster)\n* faster HMAC-based JWT parsing\n* faster Memory engine, possibility to expire history stream metadata (more [in docs](https://centrifugal.github.io/centrifugo/server/engines/#memory-engine))\n* releases for Centos 8, Debian Buster, Ubuntu Focal Fossa\n* new cli-command `centrifugo gentoken` to quickly generate HMAC SHA256 based connection JWT, [see docs](https://centrifugal.github.io/centrifugo/server/configuration/#gentoken-command)\n* new cli-command `centrifugo checktoken` to quickly validate connection JWT while developing application, [see docs](https://centrifugal.github.io/centrifugo/server/configuration/#checktoken-command)\n\nFixes:\n\n* fix server side subscriptions to private channels (were ignored before)\n* fix `channels` counter update frequency in server `info` – this includes how fast `channels` counter updated in admin web interface (previously `num clients` and `num users` updated once in 3 seconds while `num channels` only once in a minute, now `num channels` updated once in 3 seconds too)\n\nThis release based on Go 1.14.x\n\nv2.4.0\n======\n\nThis release is a step towards new interesting possibilities with Centrifugo. It adds server-side subscriptions support and some sugar on top of it. With server-side subscriptions you don't need to call `Subscribe` method on client side at all. Follow release notes to know more.\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Server-side subscriptions, this functionality requires updating client code so at moment usage is limited to `centrifuge-js`. Also there is a possibility to automatically subscribe user connection to personal notifications channel. More info in [new documentation chapter](https://centrifugal.github.io/centrifugo/server/server_subs/)\n* New private subscription JWT `eto` claim - see [its description in docs](https://centrifugal.github.io/centrifugo/server/private_channels/#eto)\n* Options to disable WebSocket, SockJS and API handlers – [see docs](https://centrifugal.github.io/centrifugo/server/configuration/#disable-default-endpoints)\n* New option `websocket_use_write_buffer_pool` – [see docs](https://centrifugal.github.io/centrifugo/transports/websocket/)\n* Metrics now include histograms of requests durations - [pull request](https://github.com/centrifugal/centrifugo/pull/337)\n* Add Linux ARM binary release\n\nFixes:\n\n* Fix unreliable unsubscriptions from Redis PUB/SUB channels under load, now we unsubscribe nodes from PUB/SUB channels over in-memory queue\n* Fix `tls_external` option regression\n\nv2.3.1\n======\n\nThis release contains several improvements to proxy feature introduced in v2.3.0, no backwards incompatible changes here.\n\nImprovements:\n\n* With `proxy_extra_http_headers` configuration option it's now possible to set a list of extra headers that should be copied from original client request to proxied HTTP request - see [#334](https://github.com/centrifugal/centrifugo/issues/334) for motivation and [updated proxy docs](https://centrifugal.github.io/centrifugo/server/proxy/)\n* You can pass custom data in response to connect event and this data will be available in `connect` event callback context on client side. See [#332](https://github.com/centrifugal/centrifugo/issues/332) for more details\n* Starting from this release `Origin` header is proxied to your backend by default - see [full list in docs](https://centrifugal.github.io/centrifugo/server/proxy/#proxy-headers)\n\nv2.3.0\n======\n\nThis release is a big shift in Centrifugo possibilities due to HTTP request proxy feature. It was a pretty long term work but the final result opens a new commucation direction: from client to server – see details below.\n\nRelease has some internal backwards incompatible changes in Redis engine and deprecations. **Migration must be smooth but we strongly suggest to test your functionality** before running new version in production. Read release notes below for more information.\n\nImprovements:\n\n* It's now possible to proxy some client connection events over HTTP to application backend and react to them in a way you need. For example you can authenticate connection via request from Centrifugo to your app backend, refresh client sessions and answer to RPC calls sent by client over WebSocket or SockJS connections. More information in [new documentation chapter](https://centrifugal.github.io/centrifugo/server/proxy/)\n* Centrifugo now supports RSA-based JWT. You can enable this by setting `token_rsa_public_key` option. See [updated authentication chapter](https://centrifugal.github.io/centrifugo/server/authentication/) in docs for more details. Due to this addition we also renamed `secret` option to `token_hmac_secret_key` so it's much more meaningful in modern context. But don't worry - old `secret` option will work and continue to set token HMAC secret key until Centrifugo v3 release (which is not even planned yet). But we adjusted docs and `genconfig` command to use new naming\n* New option `redis_sequence_ttl` for Redis engine. It allows to expire internal keys related to history sequnce meta data in Redis – current sequence number in channel and epoch value. See more motivation behind this option in [its description in Redis Engine docs](https://centrifugal.github.io/centrifugo/server/engines/#redis-engine). While adding this feature we changed how sequence and epoch values are stored in Redis - both are now fields of single Redis HASH key. This means that after updating to this version your clients won't recover missed messages - but your frontend application will receive `recovered: false` in subscription context so it should tolerate this loss gracefully recovering state from your main database (if everything done right on your client side of course)\n* More validation of configuration file is now performed. Specifically we now check history recovery configuration - see [this issue](https://github.com/centrifugal/centrifuge-js/issues/99) to see how absence of such misconfiguration check resulted in confused Centrifugo behaviour - no messages were received by subscribers\n* Go internal logs from HTTP server are now wrapped in our structured logging mechanism - those errors will look as warns in Centrifugo logs now\n* Alpine 3.10 instead of Alpine 3.8 as Centrifugo docker image base\n\nv2.2.7\n======\n\nImprovements:\n\n* Support passing `api_key` over URL param, see [#317](https://github.com/centrifugal/centrifugo/issues/317) for reasoning behind this feature\n\nv2.2.6\n======\n\nThis is a quick fix release. Fixes an error on start when `namespaces` not set in configuration file,the bug was introduced in v2.2.5, see [#319](https://github.com/centrifugal/centrifugo/issues/319) for details.\n\nv2.2.5\n======\n\nCentrifugo now uses `https://cdn.jsdelivr.net/npm/sockjs-client@1/dist/sockjs.min.js` as default SockJS url. This allows Centrifugo to always be in sync with recent v1 SockJS client. This is important to note because SockJS requires client versions to exactly match on server and client sides when using transports involving iframe. Don't forget that Centrifugo has `sockjs_url` option to set custom SockJS URL to use on server side.\n\nImprovements:\n\n* support setting all configuration options over environment variables in format `CENTRIFUGO_<OPTION_NAME>`. This was available before but starting from this release we will support setting **all** options over env\n* show HTTP status code in logs when debug log level on\n* option to customize HTTP handler endpoints, see [docs](https://centrifugal.github.io/centrifugo/server/configuration/#customize-handler-endpoints)\n* possibility to provide custom key and cert files for GRPC API server TLS, see `centrifugo -h` for a bunch of new options \n\nFixes:\n\n* Fix setting `presence_disable_for_client` and `history_disable_for_client` on config top level\n* Fix Let's Encrypt integration by updating to ACMEv2 / RFC 8555 compilant acme library, see [#311](https://github.com/centrifugal/centrifugo/issues/311)\n\n\nv2.2.4\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Improve web interface: show total client information (sum of all client connections on all running nodes)\n\nFixes:\n\n* Fixes SockJS WebSocket 403 response for cross domain requests: this is a regression in v2.2.3\n\n\nv2.2.3\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* New chapter in docs: [Benchmarking server](https://centrifugal.github.io/centrifugo/misc/benchmark/). This chapter contains information about test stand inside Kubernetes with million WebSocket connections to a server based on Centrifuge library (the core of Centrifugo). It gives some numbers and insights about hardware requirements and scalability of Centrifugo\n* New channel and channel namespace options: `presence_disable_for_client` and `history_disable_for_client`. `presence_disable_for_client` allows to make presence available only for server side API. `history_disable_for_client` allows to make history available only for server side API. Previously when enabled presence and history were available for both client and server APIs. Now you can disable for client side. History recovery mechanism if enabled will continue to work for clients anyway even if `history_disable_for_client` is on\n* Wait for close handshake completion before terminating WebSocket connection from server side. This allows to gracefully shutdown WebSocket sessions\n\nFixes:\n\n* Fix crash due to race condition, race reproduced when history recover option was on. See [commit](https://github.com/centrifugal/centrifuge/pull/73/files) with fix details\n* Fix lack of `client_anonymous` option. See [#304](https://github.com/centrifugal/centrifugo/issues/304)\n\nThis release based on Go 1.13.x\n\nv2.2.2\n======\n\nNo backwards incompatible changes here.\n\nImprovements:\n\n* Support for `tls-alpn-01` ACME challenge, see [#283](https://github.com/centrifugal/centrifugo/issues/283)\n\nFixes:\n\n* fix running HTTP server several times when http-01 ACME challenge used, see [#288](https://github.com/centrifugal/centrifugo/issues/288)\n\n\nv2.2.1\n======\n\nThis release fixes two regressions introduced by v2.2.0.\n\nImprovements:\n\n* [New documentation chapter](https://centrifugal.github.io/centrifugo/server/grpc_api/) about GRPC API in Centrifugo.\n\nFixes:\n\n* Fix client disconnect in channels with enabled history but disabled recovery\n* Fix wrong Push type sent in Redis engine: Leave message was used where Join required\n\nv2.2.0\n======\n\nThis release based on latest refactoring of Centrifuge library. The refactoring opens a road for possible interesting improvements in Centrifugo – such as possibility to use any PUB/SUB broker instead of Redis (here is an [example of possible integration](https://github.com/centrifugal/centrifugo/pull/273) with Nats server), or even combine another broker with existing Redis engine features to still have recovery and presence features. Though these ideas are not implemented in Centrifugo yet. Performance of broadcast operations can be slightly decreased due to some internal changes in Centrifuge library. Also take a close look at backwards incompatible changes section below for one breaking change.\n\nImprovements:\n\n* Track client position in channels with `history_recover` option enabled and disconnect in case of insufficient state. This resolves an edge case when messages could be lost in channels with `history_recover` option enabled after node reconnect to Redis (imagine situation when Redis was unavailable for some time but before Centrifugo node reconnects publisher was able to successfully send a message to channel on another node which reconnected to Redis faster). With new mechanism client won't miss messages though can receive them with some delay. As such situations should be pretty rare on practice it should be a reasonable compromise for applications. New mechanism adds more load on Redis as Centrifugo node periodically polls channel history state. The load is linearly proportional to amount of active channels with `history_recover` option on. By default Centrifugo will check client position in channel stream not often than once in 40 seconds so an additional load on Redis should not be too high\n* New options for more flexible conrol over exposed endpoint interfaces and ports: `internal_address`, `tls_external`, `admin_external`. See description calling `centrifugo -h`. [#262](https://github.com/centrifugal/centrifugo/pull/262), [#264](https://github.com/centrifugal/centrifugo/pull/264)\n* Small optimizations in Websocket and SockjS transports writes\n* Server initiated disconnect number metrics labeled with disconnect code \n\nBackwards incompatible changes:\n\n* This release removes a possibility to set `uid` to Publication over API. This feature was not documented in [API reference](https://centrifugal.github.io/centrifugo/server/api/) and `uid` field does not make sense to be kept on client protocol top level as in Centrifugo v2 it does not serve any internal protocol purpose. This is just an application specific information that can be put into `data` payload\n\nRelease based on Go 1.12.x\n\nv2.1.0\n======\n\nThis release contains changes in metric paths exported to Graphite, you may need to fix your dashboard when upgrading. Otherwise everything in backwards compatible.\n\nImprovements:\n\n* Refactored export to Graphite, you can now control aggregation interval using `graphite_interval` option (in seconds), during refactoring some magical path transformation was removed so now we have more predictable path generation. Though Graphite paths changed with this refactoring\n* Web interface rewritten using modern Javascript stack - latest React, Webpack instead of Gulp, ES6 syntax \n* Aggregated metrics also added to `info` command reply. This makes it possible to look at metrics in admin panel too when calling `info` command\n* More options can be set over environment variables – see [#254](https://github.com/centrifugal/centrifugo/issues/254)\n* Healthcheck endpoint – see [#252](https://github.com/centrifugal/centrifugo/issues/252)\n* New important chapter in docs – [integration guide](https://centrifugal.github.io/centrifugo/guide/)\n* Support setting `api_key` when using `Deploy on Heroku` button\n* Better timeout handling in Redis engine – client timeout is now bigger than default `redis_read_timeout` so application can more reliably handle errors\n\nFixes:\n\n* Dockerfile had no correct `WORKDIR` set so it was only possible to use absolute config file path, now this is fixed in [this commit](https://github.com/centrifugal/centrifugo/commit/08be85223aa849d9996c16971f9d049125ade50c) \n* Show node version in admin web panel\n* Fix possible goroutine leak on client connection close, [commit](https://github.com/centrifugal/centrifuge/commit/a70909c2a2677932fcef0910525ea9497ff9acf2)\n\nv2.0.2\n======\n\n**Important** If you are using `rpm` or `deb` packages from packagecloud.io then you have to re-run the [installation method of your choice](https://packagecloud.io/FZambia/centrifugo/install) for Centrifugo repository. This is required to update GPG key used. This is a standard process that all packages hosted on packagecloud should do. \n\nImprovements:\n\n* Redis TLS connection support - see [issue in Centrifuge lib](https://github.com/centrifugal/centrifuge/issues/23) and [updated docs](https://centrifugal.github.io/centrifugo/server/engines/#redis-engine)\n* Do not send Authorization header in admin web interface when insecure admin mode enabled - helps to protect admin interface with basic authorization (see [#240](https://github.com/centrifugal/centrifugo/issues/240))\n\nFixes:\n\n* Resubscribe only to shard subset of channels after reconnect to Redis ([issue](https://github.com/centrifugal/centrifuge/issues/25))\n\n\nv2.0.1\n======\n\nThis release has several fixes and performance improvements\n\nImprovements:\n\n* Use latest SockJS url (SockJS version 1.3) for iframe transports\n* Improve performance of massive subscriptions to different channels\n* Allow dot in namespace names\n\nFixes:\n\n* Fix of possible deadlock in Redis Engine when subscribe operation fails\n* Fix admin web interface [logout issue](https://github.com/centrifugal/web/issues/14) when session expired\n* Fix io timeout error when using Redis Engine with sharding enabled\n* Fix `checkconfig` command\n* Fix typo in metric name - see [#233](https://github.com/centrifugal/centrifugo/pull/233)\n\nv2.0.0\n======\n\nThis is a new major version of Centrifugo. New version has some important changes and useful features.\n\nCentrifugo v2 serves the same purpose as Centrifugo v1. Centrifugo v2 is not backwards compatible with v1 – migration to it will require adapting both backend and frontend sides of your application (of course if you decide to migrate).\n\nCentrifugo is now based on new library [centrifuge](https://github.com/centrifugal/centrifuge) for Go language. That library can be used standalone to get even more than Centrifugo server provides – like custom authentication, your own permission management, asynchronous message passing, RPC calls etc.\n\nHighlights of v2:\n\n* Cleaner and more structured client-server protocol defined in protobuf schema. Protocol is more compact because some fields with default values that were sent previously now omitted\n* Binary Websocket support (Protobuf). Protobuf allows to transfer data in much more compact and performant way than before. Of course JSON is still the main serialization format\n* JWT for authentication and private channel authorization instead of hand-crafted HMAC sign. This means that there is no need in extra libraries to generate connection and subscription tokens. There are [plenty of JWT libraries](https://jwt.io/) for all languages\n* Prometheus integration and automatic export of stats to Graphite. Now Centrifugo easily integrates in modern monitoring stack – no need to manually export stats\n* Refactored [Javascript](https://github.com/centrifugal/centrifuge-js) (ES6), [Go](https://github.com/centrifugal/centrifuge-go) and [gomobile client](https://github.com/centrifugal/centrifuge-mobile) libraries\n* Simplified HTTP API authentication (no request body signing anymore)\n* GRPC for server API\n* New `presence_stats` API command to get compact presence information - how many clients and unique users in channel\n* Structured logging with coloured output during development\n* Mechanism to automatically merge several Websocket messages into one to reduce syscall amount thus be more performant under heavy load\n* Better recovery algorithm to fix several `recovered` flag false positives\n* Goreleaser for automatic releases to Github\n\nSome things were removed from Centrifugo in v2 release:\n\n* Publishing over Redis queue\n* Admin websocket endpoint\n* Client limited channels\n* `history_drop_inactive` channel option now gone\n* Websocket prepared message support (though this one can be pushed back at some point).\n\n[New documentation](https://centrifugal.github.io/centrifugo/) contains actual information and tips about migration from v1.\n\nAs mentioned above new version uses JWT tokens for authentication and private channel authorization. And there is no API request body signing anymore. This all means that using API clients (like `cent`, `phpcent`, `jscent`, `rubycent`, `gocent` before) is not necessary anymore – you can use any JWT library for your language and just send commands from your code – this is just simple JSON objects. Though API libraries still make sense to simplify integration a bit.\n\nAt moment there are no native mobile clients. I.e. `centrifuge-ios` and `centrifuge-android` have not been updated to Centrifugo v2 yet.\n\nv1.8.0\n======\n\nNo backwards incompatible changes here.\n\n### Features\n\n* package for Ubuntu 18.04\n* add Centrifugo `version` to stats output. Also add rusage stime and utime values to metrics. See [#222](https://github.com/centrifugal/centrifugo/issues/222) for details. Thanks to @Sannis for contributions\n* expose more configuration options to be set over environment variables. See [commit](https://github.com/centrifugal/centrifugo/commit/bf8655914ef94aaa4b2579d943b64fc63e7b9b08) and [related issue](https://github.com/centrifugal/centrifugo/issues/223)\n* more context in debug logs regarding to client connection. See [#201](https://github.com/centrifugal/centrifugo/issues/201)\n* fix deb package upgrade - see [#219](https://github.com/centrifugal/centrifugo/issues/219) for details\n\n### Internal\n\n* using Go 1.10.3 for builds\n\nv1.7.9\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* fix malformed JSON when using empty `info` in connection refresh request - see [#214](https://github.com/centrifugal/centrifugo/issues/214).\n\n### Features\n\n* support ACME http_01 challenge using new `ssl_autocert_http` boolean option. Centrifugo will serve http_01 ACME challenge on port 80. See [#210](https://github.com/centrifugal/centrifugo/issues/210) for more details. \n\n### Internal\n\n* using Go 1.10.1 for builds\n\nv1.7.8\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* the fix of goroutine leak in 1.7.7 was incomplete - looks like in this release the problem described in [#207](https://github.com/centrifugal/centrifugo/issues/207) gone away.\n\nv1.7.7\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* fix goroutine leak due to deadlock, see [#207](https://github.com/centrifugal/centrifugo/issues/207)\n\n### Features\n\n* possibility to set message `uid` via API request - see [#205](https://github.com/centrifugal/centrifugo/pull/205)\n\n### Internal\n\n* do not send `unsubscribe` messages to client on shutdown - it will unsubscribe automatically on disconnect on client side\n* using Go 1.10 for builds\n\nv1.7.6\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* fix setting config via environment vars - `CENTRIFUGO_` prefix did not work since 1.7.4  \n\nv1.7.5\n======\n\nNo backwards incompatible changes here.\n\nThe only change is using new version of Go for builds (Go 1.9.2). This will allow to analize performance profiles more easily without having to use binaries. See [this new wiki page](https://github.com/centrifugal/centrifugo/wiki/Investigating-performance-issues) about investigating performance issues.\n\nv1.7.4\n======\n\nNo backwards incompatible changes here.\n\nThis release is centered around internal refactoring to detach node from server - see more details in [#186](https://github.com/centrifugal/centrifugo/pull/186).\n\n### Features\n\n* optionally create PID file using `--pid_file` command line option.\n* create connections in separate goroutines to slightly improve GC (and therefore reduce memory usage).\n\n### Internal (for developers/contributors)\n\n* Using Go 1.8.3 for builds\n\nv1.7.3\n======\n\nNo backwards incompatible changes here.\n\nThis release built using new version of Go - 1.8.1, previously Centrifugo used Go 1.7.5, so here we benefit from Go evolution improvements - the most notable is improvements in GC pauses which should in turn improve Centrifugo latency. It also reduces memory usage by about 15-20% when websocket compression enabled.\n\nv1.7.2\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* fix reusing read and write buffers returned from connection hijack. This was added in previous release but due to the bug in configuration the feature did not work.\n\nv1.7.1\n======\n\nNo backwards incompatible changes here.\n\n### Fixes\n\n* fix mass resubscribe after several Redis disconnects in a row - more details in [#163](https://github.com/centrifugal/centrifugo/pull/163)\n\n### Features\n\n* update Gorilla Websocket lib - it now tries to reuse buffers returned from Go http library `hijack` method. We adapted Centrifugo default websocket buffer options to utilize this feature (`websocket_read_buffer_size` and `websocket_write_buffer_size` now `0` by default).\n\n\nv1.7.0\n======\n\nThis release changes two important aspects of Centrifugo. We expect that it will be fully backwards compatible with previous one in most scenarios until you were using `timestamp` message field somehow.\n\n### What's changed\n\n* integration with Gorilla Websocket [PreparedMessage](https://godoc.org/github.com/gorilla/websocket#PreparedMessage) for raw websocket. We expect it to drastically improve websocket compression case - reducing both memory and CPU in large fan-out scenarios. This change does not affect SockJS in any way.\n* `timestamp` field removed from message. See [#147](https://github.com/centrifugal/centrifugo/issues/147) for motivation.\n* Several new memory metrics - `node_memory_heap_sys`, `node_memory_heap_alloc`, `node_memory_stack_inuse`\n\nv1.6.5\n======\n\nNo backwards incompatible changes here.\n\n### Features\n\n* resolve `history_drop_inactive` option edge case (described in [#50](https://github.com/centrifugal/centrifugo/issues/50))\n* two new options for autocert: `ssl_autocert_force_rsa` and `ssl_autocert_server_name`. See [docs](https://fzambia.gitbooks.io/centrifugal/content/deploy/certificates.html#automatic-certificates) for description \n\n### Fixes\n\n* update web interface - in new version we don't show connection endpoints on main page as we can't show them reliably. Final endpoints depend on your production proxy/firewall politics (and port configuration) so we don't try to guess.\n\n\nv1.6.4\n======\n\nNo backwards incompatible changes here.\n\nWe **consider removing** `timestamp` field from message as it's seems useless and never used by Centrifugo users. Applications that need timestamp for some reason can include it into message JSON payload. If you have any objections please look at [issue #147](https://github.com/centrifugal/centrifugo/issues/147) and write your thoughts against removing this field.\n\n### Features\n\n* configurable websocket compression level - see [updated docs](https://fzambia.gitbooks.io/centrifugal/content/mixed/websocket_compression.html). Bear in mind that compression is still very CPU and memory expensive\n* new metric `node_uptime_seconds` - see [updated docs](https://fzambia.gitbooks.io/centrifugal/content/server/stats.html) for stats\n\n### Fixes\n\n* fixes crash when using builtin TLS server - see [#145](https://github.com/centrifugal/centrifugo/issues/145)\n* redirect Go std lib logging into our INFO logger\n\n### Internal (for developers/contributors)\n\n* Using Go 1.7.5 for builds\n* As soon as Go 1.8 out we will be able to remove `x/net/http2` dependency as standard lib will contain fix for [#145](https://github.com/centrifugal/centrifugo/issues/145)\n\n\nv1.6.3\n======\n\nThis release fixes wrong decision made in 1.6.x related to pings. We don't rely on client to server \npings to disconnect clients anymore, we also moved back SockJS heartbeat frames - i.e. sending them \nfrom server to client every 25 seconds as before (in Centrifugo < 1.6.0). Recent changes in `centrifuge-js` (version 1.4.2) allowed us to not introduce addition reconnects for SockJS polling \ntransports when sending client to server automatic ping. We also updated documentation [chapter about \npings](https://fzambia.gitbooks.io/centrifugal/content/mixed/ping.html) a bit.\n\n### Fixes\n\n* Random disconnects from Centrifugo when using automatic client to server pings. This is a default \nbehaviour so it affects almost everyone who using Centrifugo 1.6.x, fixes https://github.com/centrifugal/centrifugo/issues/142\n* Fix writing headers after headers already written in raw websocket endpoint - this remove annoying log line appearing after client can't upgrade connection to Websocket.\n\n\nv1.6.2\n======\n\n### Features\n\n* Use Redis pipelining and single connection for presence/history/channels operations. This increases performance of those operations especially on systems with many CPU cores.\n* Homebrew formula to install Centrifugo on MacOS, see README for instructions.\n* Update gorilla websocket library - there is one more update for websocket compression: pool flate readers which should increase compression performance.\n\n### Fixes\n\n* Fix calling presence remove for every channel (not only channels with presence option enabled).\n* Change subscribing/unsubscribing algorithm to Redis channels - it fixes theoretical possibility of wrong subscribing state in Redis.\n\n### Internal (for developers/contributors)\n\n* We don't use `disconnect` message before closing client connections anymore - we rely on websocket/SockJS close reason now (which is JSON encoded `DisconnectAdvice`). Our js client already handles that reason, so no breaking changes there. Some work required in other clients though to support `reconnect: false` in advice.\n\nv1.6.1\n======\n\nThis release fixes some configuration problems introduced by v1.6.0 and adds Let's Encrypt support.\n\n### Features\n\n* automatic TLS certificates from Let's Encrypt - see [#133](https://github.com/centrifugal/centrifugo/issues/133) and new [dedicated documentation chapter](https://fzambia.gitbooks.io/centrifugal/content/deploy/certificates.html)\n* websocket compression performance improvement (due to Gorilla Websocket library update)\n\n### Fixes\n\n* fix SSL/TLS certificates file option names - see [#132](https://github.com/centrifugal/centrifugo/issues/132)\n* fix `web` option that must enable admin socket automatically - see [#136](https://github.com/centrifugal/centrifugo/issues/136)\n\nv1.6.0\n======\n\nThis Centrifugo release is a massive 4-months refactoring of internals with the goal to separate code of different components such as engine, server, metrics, clients to own packages with well-defined API to communicate between them. The code layout changed dramatically. Look at `libcentrifugo` folder [before](https://github.com/centrifugal/centrifugo/tree/v1.5.1/libcentrifugo) and [after](https://github.com/centrifugal/centrifugo/tree/master/libcentrifugo)! Unfortunately there are backwards incompatibilities with previous release - see notes below. The most significant one is changed metrics format in `stats` and `node` API command responses.\n\nWith new code layout it's much more simple to create custom engines or servers – each with own metrics and configuration options. **We can not guarantee** though that we will keep `libcentrifugo` packages API stable – **our primary goal is still building Centrifugo standalone server**. So if we find something that must be fixed or improved internally - we will fix/improve it even if this could result in packages API changes.\n\nAs Centrifugo written in Go the only performant way to write plugins is to import them in `main.go` file and build Centrifugo with them. So if you want to create custom build with custom server or custom engine you will need to change `main.go` file and build Centrifugo yourself. But at least it's easier than supporting full Centrifugo fork.\n\n### Release highlights:\n\n* New metrics. Several useful new metrics have been added. For example HTTP API and client request HDR histograms. See updated documentation for complete list. Refactoring resulted in backwards incompatible issue when working with Centrifugo metrics (see below). [Here is a docs chapter](https://fzambia.gitbooks.io/centrifugal/content/server/stats.html) about metrics.\n* Optimizations for client side ping, `centrifuge-js` now automatically sends periodic `ping` commands to server. Centrifugo checks client's last activity time and closes stale connections. Builtin SockJS server won't send heartbeat frames to SockJS clients by default. You can restore the old behaviour though: setting `ping: false` on client side and `sockjs_heartbeat_delay: 25` option in Centrifugo configuration. This all means that you better update `centrifuge-js` client to latest version (`1.4.0`). Read [more about pings in docs](https://fzambia.gitbooks.io/centrifugal/content/mixed/ping.html).\n* Experimental websocket compression support for raw websockets - see [#115](https://github.com/centrifugal/centrifugo/issues/115). Read more details how to enable it [in docs](https://fzambia.gitbooks.io/centrifugal/content/mixed/websocket_compression.html). Keep in mind that enabling websocket compression can result in slower Centrifugo performance - depending on your load this can be noticeable.\n* Serious improvements in Redis API queue consuming. There was a bottleneck as we used BLPOP command to get every message from Redis which resulted in extra RTT. Now it's fixed and we can get several API messages from queue at once and process them. The format of Redis API queue changed - see new format description [in docs](https://fzambia.gitbooks.io/centrifugal/content/server/engines.html). Actually it's now the same as single HTTP API command - so we believe you should be comfortable with it. Old format is still supported but **DEPRECATED** and will be removed in next releases.\n* Redis sharding support. See more details [in docs](https://fzambia.gitbooks.io/centrifugal/content/server/scaling.html). This resolves some fears about Redis being bottleneck on some large Centrifugo setups. Though we have not heard such stories yet. Redis is single-threaded server, it's insanely fast but if your Redis approaches 100% CPU usage then this sharding feature is what can help your application to scale. \n* Many minor internal improvements.\n\n### Fixes:\n\n* This release fixes crash when `jsonp` transport was used by SockJS client - this was fixed recently in sockjs-go library.\n* Memory bursts fixed on node shutdown when we gracefully disconnect many connected clients.\n\n### Backwards incompatible changes:\n\n* `stats` and `node` command response body format changed – metrics now represented as map containing string keys and integer values. So you may need to update your monitoring scripts.\n* Default log level now is `info` - `debug` level is too chatty for production logs as there are tons of API requests per second, tons of client connect/disconnect events. If you still want to see logs about all connections and API requests - set `log_level` option to `debug`.\n* `channel_prefix` option renamed to `redis_prefix`.\n* `web_password` and `web_secret` option aliases not supported anymore. Use `admin_password` and `admin_secret`.\n* `insecure_web` option removed – web interface now available without any password if `insecure_admin` option enabled. Of course in this case you should remember about protecting your admin endpoints with firewall rules. Btw we recommend to do this even if you are using admin password.\n* Admin `info` response format changed a bit - but this most possibly will not affect anyone as it was mostly used by embedded web interface only.\n* Some internal undocumented options have been changed. Btw [we documented several useful options](https://fzambia.gitbooks.io/centrifugal/content/server/advanced_configuration.html) which can be helpful in some cases.\n\n### Several internal highlights (mostly for Go developers):\n\n* Code base is more simple and readable now.\n* Protobuf v3 for message schema (using gogoprotobuf library). proto2 and proto3 are wire compatible.\n* Client transport now abstracted away - so it would be much easier in future to add new transport in addition/replacement to Websocket/SockJS.\n* API abstracted away from protocol - it would be easier in future to add new API requests source.\n* No performance penalty was introduced during this refactoring.\n* We process PUB/SUB messages in several goroutines, preserving message order.\n* We use `statik` (https://github.com/rakyll/statik) to embed web interface now.\n* go1.7.4 used for builds.\n\n\nv1.5.1\n======\n\n* Fixes [#94](https://github.com/centrifugal/centrifugo/issues).\n\n\nv1.5.0\n======\n\nSome upgrade steps needed to migrate to this release, see below.\n\nThis release is a major refactoring of Centrifugo internal engine. Centrifugo now uses `protobuf` format while transferring data between nodes and serializing history/presence data in Redis. We expect that all those changes **should not affect your working application code** though as new serialization format used **you may need to run** `FLUSHDB` command if using Redis engine to remove presence/history data encoded as JSON (if you don't use presence and history then no need to do this). If you have any problems with new serialization format used by Centrifugo internally – we can consider making old JSON encoding optional in future releases. Depending on how you use Centrifugo with Redis Engine those internal changes can result in nearly the same performance (if real-time content mostly generated by users online, so messages coming to Centrifugo have to be delivered to at least one client) or up to 2x API request speed up (if your real-time mostly generated by application backend itself so some messages published in channel with no active subscribers and there is no need to do JSON encoding work).\n\n* Using SockJS 1.1 by default (actually as by default we use jsdelivr.net CDN version it will be latest minor release - at moment of writing 1.1.1) – this means that you need to also upgrade SockJS on client side to the same version (because **some iframe-based SockJS transports require exact version match on client and server**). Note that you can set desired SockJS version used by Centrifugo server via `sockjs_url` option (which is now by default `//cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js`). So if you don't want to upgrade SockJS on client side or just want to fix version used or use your own hosted SockJS library (which is good if you think about old browser support and don't want to be affected by minor SockJS library releases) - use that option.\n* `centrifugo version` now shows Go language version used to build binary.\n* Performance and memory allocation improvements.\n\n\nv1.4.5\n======\n\nNo backwards incompatible changes here. This release uses go1.6.2\n\n* HTTP/2 support. This means that Centrifugo can utilize HTTP/2 protocol automatically - this is especially useful for HTTP-based SockJS transports (no limits for open connections per domain anymore). Note that HTTP/2 will work only when your setup utilizes `https`. Also HTTP/2 does not affect websockets because of missing protocol upgrade possibilities in HTTP/2 protocol - so websockets will work in the same way as before. Also if you have any proxy before Centrifugo then depending on your setup some reconfiguration may be required to make HTTP/2 work.\n\nJust to remember how to test Centrifugo with SSL: [follow instructions](https://devcenter.heroku.com/articles/ssl-certificate-self) from Heroku article to generate self-signed certificate files. Then start Centrifugo like this:\n\n```\n./centrifugo --config=config.json --web --ssl --ssl_key=server.key --ssl_cert=server.crt\n```\n\nGo to https://localhost:8000/ and confirm that you trust certificate of this site (this is because of self-signed certificate, in case of valid certificate you don't need this step). Then you can test secure endpoint connections.\n\n\nv1.4.4\n======\n\nOne more fix for v1.4.2 release here\n\n* proper aliasing of `admin_password` and `admin_secret` configuration options. See [#88](https://github.com/centrifugal/centrifugo/issues/88) \n\n\nv1.4.3\n======\n\n**Fix of security vulnerability introduced in v1.4.2**, see below.\n\n* If you are using Centrifugo v1.4.2 (previous versions not affected) with admin socket enabled (with `--admin` or `--web` options) and your admin endpoint not protected by firewall somehow then you must update to this version. Otherwise it's possible to connect to admin websocket endpoint and run any command without authentication. It's recommended to update your secret key after upgrade. So sorry for this.\n\n\nv1.4.2\n======\n\n* Redis Sentinel support for Redis high availability setup. [Docs](https://fzambia.gitbooks.io/centrifugal/content/deploy/sentinel.html)\n* Redis Engine now uses Redis pipeline for batching publish operations - this results in latency and throughput improvments when publish rate is high.\n* Refactored admin websocket. New option `admin` to enable admin websocket. New option `insecure_admin` to make this endpoint insecure (useful when admin websocket endpoint/port protected by firewall rules). `web_password` option renamed to `admin_password`, `web_secret` option renamed to `admin_secret`, `insecure_web` renamed to `insecure_admin`. **But all old option names still supported to not break things in existing setups**. Also note, that when you run Centrifugo with `web` interface enabled - you also make admin websocket available, because web interface uses it. A little more info [in pull request](https://github.com/centrifugal/centrifugo/pull/83).\n* Presence Redis Engine methods rewritten to lua to be atomic.\n* Some Redis connection params now can be set over environment variables. See [#81](https://github.com/centrifugal/centrifugo/issues/81)\n* Fix busy loop when attempting to reconnect to Redis. Fixes large CPU usage while reconnecting.\n* Shorter message `uid`s (22 bytes instead of 36). This was made in order to get some performance improvements.\n\n\nv1.4.1\n======\n\n* fix server crash on 32-bit architectures (due to [this](https://golang.org/src/sync/atomic/doc.go?s=1207:1656#L36)), see more details in [#74](https://github.com/centrifugal/centrifugo/issues/74).\n* fix compatibility with gocent introduced in v1.4.0\n\n\nv1.4.0\n======\n\nNo backwards incompatible changes here for most usage scenarios, but look carefully on notes below.\n\n* Timers in metrics marked as deprecated. `time_api_mean`, `time_client_mean`, `time_api_max`, `time_client_max` now return 0. This was made because timer's implementation used `Timer` from `go-metrics` library that does not suit very well for Centrifugo needs - so values were mostly useless in practice. So we decided to get rid of them for now to not confuse our users.\n* New `node` API method to get information from single node. That information will contain counters without aggregation over minute interval (what `stats` method does by default). So it can be useful if your metric aggregation system can deal with non-aggregated counters over time period itself. Also note that to use this method you should send API request to each Centrifugo node separately - as this method returns current raw statistics about one node. See [issue](https://github.com/centrifugal/centrifugo/issues/68) for motivation description.\n* Centrifugo now handles SIGTERM in addition to SIGINT and makes `shutdown` when this signal received. During shutdown Centrifugo returns 503 status code on requests to handlers and closes client connections so clients will reconnect. If shutdown finished without errors in 10 seconds interval then Centrifugo exits with status code 0 (instead of 130 before, this fixes behaviour behind `systemd` after SIGTERM received).\n* Maximum limit in bytes for client request was added. It can be changed using `client_request_max_size` config option. By default 65536 bytes (64kb).\n* Packages for 64-bit Debian, Centos and Ubuntu [hosted on packagecloud.io](https://packagecloud.io/FZambia/centrifugo). If you are using Debian 7 or 8, Centos 6 or 7, Ubuntu 14.04 or Ubuntu 16.04 - you can find packages for those linux distribution following to packagecloud. Packages will be created every time we release new Centrifugo version.\n\n\nv1.3.3\n======\n\nNo backwards incompatible changes here\n\n* fix automatic presence expire in Redis engine - could lead to small memory leaks in Redis when using presence. Also could result in wrong presence information after non-graceful Centrifugo node shutdown.\n* configurable limit for amount of channels each client can subscribe to. Default `100`. Can be changed using `client_channel_limit` configuration option.\n\n\nv1.3.2\n======\n\nThis release built using go 1.5.3 and [includes security fix in Go lang](https://groups.google.com/forum/#!topic/golang-announce/MEATuOi_ei4)\n\n* empty errors not included in client response (**this requires using Javascript client >= 1.1.0**)\n* optimization in Redis engine when using history - one round trip to Redis to publish message and save it into history instead of two. This was done over registering lua script on server start.\n* client errors improvements - include error advice when error occurred (fix or retry at moment)\n\nAlso note that Javascript client will be fully refreshed soon. See [this pull request](https://github.com/centrifugal/centrifuge-js/pull/7)\n\nv1.3.1\n======\n\n* fix port configuration introduced in v1.3.0: `--port` should override default values for `admin_port` and `api_port`\n* use the same (http/https) scheme for Sockjs default iframe script source.\n* fix possible deadlock in shutdown\n\nv1.3.0\n======\n\nPossible backwards incompatibility here (in client side code) - see first point.\n\n* omit fields in message JSON if field contains empty value: `client` on top level, `info` on top level, `default_info` in `info` object, `channel_info` in `info` object. This also affects top level data in join/leave messages and presence data – i.e. `default_info` and `channel_info` keys not included in JSON when empty. This can require adapting your client side code a bit if you rely on these keys but for most cases this should not affect your application. But we strongly suggest to test before updating. This change allows to reduce message size. See migration notes below for more details.\n* new option `--admin_port` to bind admin websocket and web interface to separate port. [#44](https://github.com/centrifugal/centrifugo/issues/44)\n* new option `--api_port` to bind API endpoint to separate port. [#44](https://github.com/centrifugal/centrifugo/issues/44)\n* new option `--insecure_web` to use web interface without setting `web_password` and `web_secret` (for use in development or when you protected web interface by firewall rules). [#44](https://github.com/centrifugal/centrifugo/issues/44)\n* new channel option `history_drop_inactive` to drastically reduce resource usage (engine memory, messages travelling around) when you use message history. See [#50](https://github.com/centrifugal/centrifugo/issues/50)\n* new Redis engine option `--redis_api_num_shards`. This option sets a number of Redis shard queues Centrifugo will use in addition to standard `centrifugo.api` queue. This allows to increase amount of messages you can publish into Centrifugo and preserve message order in channels. See [#52](https://github.com/centrifugal/centrifugo/issues/52) and [documentation](https://fzambia.gitbooks.io/centrifugal/content/server/engines.html) for more details.\n* fix race condition resulting in client disconnections on high channel subscribe/unsubscribe rate. [#54](https://github.com/centrifugal/centrifugo/issues/54)\n* refactor `last_event_id` related stuff to prevent memory leaks on large amount of channels. [#48](https://github.com/centrifugal/centrifugo/issues/48)\n* send special disconnect message to client when we don't want it to reconnect to Centrifugo (at moment to client sending malformed message). \n* pong wait handler for raw websocket to detect non responding clients.\n\nAlso it's recommended to update javascipt client to latest version as it has some useful changes (see its changelog).\n\nHow to migrate\n--------------\n\nMessage before:\n\n```json\n{\n\t\"uid\":\"442586d4-688c-4a0d-52ad-d0a13d201dfc\",\n\t\"timestamp\":\"1450817253\",\n\t\"info\": null,\n\t\"channel\":\"$public:chat\",\n\t\"data\":{\"input\":\"1\"},\n\t\"client\":\"\"\n}\n```\n\nMessage now:\n\n```json\n{\n\t\"uid\":\"442586d4-688c-4a0d-52ad-d0a13d201dfc\",\n\t\"timestamp\":\"1450817253\",\n\t\"channel\":\"$public:chat\",\n\t\"data\":{\"input\":\"1\"}\n}\n```\n\nI.e. not using empty `client` and `info` keys. If those keys are non empty then they present in message.\n\nJoin message before:\n\n```json\n{\n\t\"user\":\"2694\",\n\t\"client\":\"93615872-4e45-4da2-4733-55c955133436\",\n\t\"default_info\": null,\n\t\"channel_info\":null\n}\n```\n\nJoin message now:\n\n```json\n{\n\t\"user\":\"2694\",\n\t\"client\":\"93615872-4e45-4da2-4733-55c955133436\"\n}\n```\n\nIf \"default_info\" or \"channel_info\" exist then they would be included:\n\n```json\n{\n\t\"user\":\"2694\",\n\t\"client\":\"93615872-4e45-4da2-4733-55c955133436\",\n\t\"default_info\": {\"username\": \"FZambia\"},\n\t\"channel_info\": {\"extra\": \"some data here\"}\n}\n```\n\n\nv1.2.0\n======\n\nNo backwards incompatible changes here.\n\n* New `recover` option to automatically recover missed messages based on last message ID. See [pull request](https://github.com/centrifugal/centrifugo/pull/42) and [chapter in docs](https://fzambia.gitbooks.io/centrifugal/content/server/recover.html) for more information. Note that you need centrifuge-js >= v1.1.0 to use new `recover` option\n* New `broadcast` API method to send the same data into many channels. See [issue](https://github.com/centrifugal/centrifugo/issues/41) and updated [API description in docs](https://fzambia.gitbooks.io/centrifugal/content/server/api.html)\n* Dockerfile now checks SHA256 sum when downloading release zip archive.\n* release built using Go 1.5.2\n\n\nv1.1.0\n======\n\nNo backwards incompatible changes here.\n\n* support enabling web interface over environment variable CENTRIFUGO_WEB\n* close client's connection after its message queue exceeds 10MB (default, can be modified using `max_client_queue_size` configuration file option)\n* fix theoretical server crash on start when reading from redis API queue\n\n\nv1.0.0\n======\n\nA bad and a good news here. Let's start with a good one. Centrifugo is still real-time messaging server and just got v1.0 release. The bad – it is not fully backwards compatible with previous versions. Actually there are three changes that ruin compatibility. If you don't use web interface and private channels then there is only one change. But it affects all stack - Centrifugo itself, client library and API library.\n\nStarting from this release Centrifugo won't support multiple registered projects. It will work with only one application. You don't need to use `project key` anymore. Changes resulted in simplified\nconfiguration file format. The only required option is `secret` now. See updated documentation \nto see how to set `secret`. Also changes opened a way for exporting Centrifugo node statistics via HTTP API `stats` command.\n\nAs this is v1 release we'll try to be more careful about backwards compatibility in future. But as we are trying to make a good software required changes will be done if needed.\n\nHighlights of this release are:\n\n* Centrifugo now works with single project only. No more `project key`. `secret` the only required configuration option.\n* web interface is now embedded, this means that when downloading release you get possibility to run Centrifugo web interface just providing `--web` flag to `centrifugo` when starting process.\n* when `secret` set via environment variable `CENTRIFUGO_SECRET` then configuration file is not required anymore. But note, that when Centrifugo configured via environment variables it's not possible to reload configuration sending HUP signal to process.\n* new `stats` command added to export various node stats and metrics via HTTP API call. Look its response example [in docs chapter](https://fzambia.gitbooks.io/centrifugal/content/server/api.html).\n* new `insecure_api` option to turn on insecure HTTP API mode. Read more [in docs chapter](https://fzambia.gitbooks.io/centrifugal/content/mixed/insecure_mode.html).\n* minor clean-ups in client protocol. But as protocol incapsulated in javascript client library you only need to update centrifuge-js.\n* release built using Go 1.5.1\n\n[Documentation](https://fzambia.gitbooks.io/centrifugal/content/) was updated to fit all these release notes. Also all API and client libraries were updated – Javascript browser client (`centrifuge-js`), Python API client (`cent`), Django helper module (`adjacent`). API clients for Ruby (`centrifuge-ruby`) and PHP (`phpcent`) too. Admin web interface was also updated to support changes introduced here.\n\nThere are 2 new API libraries: [gocent](https://github.com/centrifugal/gocent) and [jscent](https://github.com/centrifugal/jscent). First for Go language. And second for NodeJS.\n\nAlso if you are interested take a look at [centrifuge-go](https://github.com/centrifugal/centrifuge-go) – experimental Centrifugo client for Go language. It allows to connect to Centrifugo from non-browser environment. Also it can be used as a reference to make a client in another language (still hoping that clients in Java/Objective-C/Swift to use from Android/IOS applications appear one day – but we need community help here).\n\nHow to migrate\n--------------\n\n* Use new versions of Centrifugal libraries - browser client and API client. Project key not needed in client connection parameters, in client token generation, in HTTP API client initialization.\n* Another backwards incompatible change related to private channel subscriptions. Actually this is not related to Centrifugo but to Javascript client but it's better to write about it here. Centrifuge-js now sends JSON (`application/json`) request instead of `application/x-www-form-urlencoded` when client wants to subscribe on private channel. See [in docs](https://fzambia.gitbooks.io/centrifugal/content/mixed/private_channels.html) how to deal with JSON in this case.\n* `--web` is now a boolean flag. Previously it was used to set path to admin web interface. Now it indicates whether or not Centrifugo must serve web interface. To provide path to custom web application directory use `--web_path` string option.\n\nI.e. before v1 you started Centrifugo like this to use web interface:\n\n```\ncentrifugo --config=config.json --web=/path/to/web/app\n```\n\nNow all you need to do is run:\n\n```\ncentrifugo --config=config.json --web\n```\n\nAnd no need to download web interface repository at all! Just run command above and check http://localhost:8000.\n\nIf you don't want to use embedded web interface you can still specify path to your own web interface directory:\n\n```\ncentrifugo --config=config.json --web --web_path=/path/to/web/app\n```\n\n\nv0.3.0\n======\n\n* new `channels` API command – allows to get list of active channnels in project at moment (with one or more subscribers).\n* `message_send_timeout` option default value is now 0 (last default value was 60 seconds) i.e. send timeout is not used by default. This means that Centrifugo won't start lots of goroutines and timers for every message sent to client. This helps to drastically reduce memory allocations. But in this case it's recommended to keep Centrifugo behind properly configured reverse proxy like Nginx to deal with connection edge cases - slow reads, slow writes etc.\n* Centrifugo now sends pings into pure Websocket connections. Default value is 25 seconds and can be adjusted using `ping_interval` configuration option. Note that this option also sets SockJS heartbeat messages interval. This opens a road to set reasonable value for Nginx `proxy_read_timeout` for `/connection` location to mimic behaviour of `message_send_timeout` which is now not used by default\n* improvements in Redis Engine locking.\n* tests now require Redis instance running to test Redis engine. Tests use Redis database 9 to run commands and if that database is not empty then tests will fail to prevent corrupting existing data.\n* all dependencies now vendored.\n\nv0.2.4\n======\n\n* HTTP API endpoint now can handle json requests. Used in client written in Go at moment. Old behaviour have not changed, so this is absolutely optional.\n* dependency packages updated to latest versions - websocket, securecookie, sockjs-go.\n\nv0.2.3\n======\n\nCritical bug fix for Redis Engine!\n\n* fixed bug when entire server could unsubscribe from Redis channel when client closed its connection.\n\n\nv0.2.2\n======\n\n* Add TLS support. New flags are:\n  * `--ssl`                   - accept SSL connections. This requires an X509 certificate and a key file.\n  * `--ssl_cert=\"file.cert\"`  - path to X509 certificate file.\n  * `--ssl_key=\"file.key\"`    - path to X509 certificate key.\n* Updated Dockerfile\n\nv0.2.1\n======\n\n* set expire on presence hash and set keys in Redis Engine. This prevents staling presence keys in Redis.\n\nv0.2.0\n======\n\n* add optional `client` field to publish API requests. `client` will be added on top level of \n\tpublished message. This means that there is now a way to include `client` connection ID to \n\tpublish API request to Centrifugo (to get client connection ID call `centrifuge.getClientId()` in \n\tjavascript). This client will be included in a message as I said above and you can compare\n\tcurrent client ID in javascript with `client` ID in message and if both values equal then in \n\tsome situations you will wish to drop this message as it was published by this client and \n\tprobably already processed (via optimistic optimization or after successful AJAX call to web \n\tapplication backend initiated this message).\n* client limited channels - like user limited channels but for client. Only client with ID used in\n\tchannel name can subscribe on such channel. Default client channel boundary is `&`. If you have\n\tchannels with `&` in its name - then you must adapt your channel names to not use `&` or run Centrifugo with another client channel boundary using `client_channel_boundary` configuration\n\tfile option.\n* fix for presence and history client calls - check subscription on channel before returning result \n\tor return Permission Denied error if not subscribed.\n* handle interrupts - unsubscribe clients from all channels. Many thanks again to Mr Klaus Post.\t\n* code refactoring, detach libcentrifugo real-time core from Centrifugo service.\n\nv0.1.1\n======\n\nLots of internal refactoring, no API changes. Thanks to Mr Klaus Post (@klauspost) and Mr Dmitry Chestnykh (@dchest)\n\nv0.1.0\n======\n\nFirst release. New [documentation](http://fzambia.gitbooks.io/centrifugal/content/).\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.330078125,
          "content": "FROM alpine:3.21\n\nARG USER=centrifugo\nARG UID=1000\nARG GID=1000\n\nRUN addgroup -S -g $GID $USER && \\\n    adduser -S -G $USER -u $UID $USER\n\nRUN apk --no-cache upgrade && \\\n    apk --no-cache add ca-certificates && \\\n    update-ca-certificates\n\nUSER $USER\n\nWORKDIR /centrifugo\n\nCOPY centrifugo /usr/local/bin/centrifugo\n\nCMD [\"centrifugo\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0849609375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2023 Centrifugal Labs LTD\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.3193359375,
          "content": "VERSION := $(shell git describe --tags | sed -e 's/^v//g' | awk -F \"-\" '{print $$1}')\nITERATION := $(shell git describe --tags --long | awk -F \"-\" '{print $$2}')\nTESTFOLDERS := $(shell go list ./... | grep -v /misc/)\n\nall: test\n\ntest:\n\tgo test -count=1 -v $(TESTFOLDERS) -cover -race\n\ntest-integration:\n\tgo test -count=1 -v $(TESTFOLDERS) -cover -race --tags=integration\n\ngenerate:\n\tbash misc/scripts/generate.sh\n\tgo generate ./...\n\nweb:\n\t./misc/scripts/update_web.sh\n\nswagger-web:\n\tmake generate\n\t./misc/scripts/update_swagger_web.sh\n\npackage:\n\t./misc/scripts/package.sh $(VERSION) $(ITERATION)\n\npackagecloud:\n\tmake packagecloud-deb\n\tmake packagecloud-rpm\n\npackagecloud-deb:\n\t# PACKAGECLOUD_TOKEN env must be set\n\tpackage_cloud push FZambia/centrifugo/debian/buster PACKAGES/*.deb\n\tpackage_cloud push FZambia/centrifugo/debian/bullseye PACKAGES/*.deb\n\tpackage_cloud push FZambia/centrifugo/debian/bookworm PACKAGES/*.deb\n\n\tpackage_cloud push FZambia/centrifugo/ubuntu/bionic PACKAGES/*.deb\n\tpackage_cloud push FZambia/centrifugo/ubuntu/focal PACKAGES/*.deb\n\tpackage_cloud push FZambia/centrifugo/ubuntu/jammy PACKAGES/*.deb\n\npackagecloud-rpm:\n\t# PACKAGECLOUD_TOKEN env must be set\n\tpackage_cloud push FZambia/centrifugo/el/7 PACKAGES/*.rpm\n\ndeps:\n\tgo mod tidy\n\nlocal-deps:\n\tgo mod tidy\n\tgo mod download\n\tgo mod vendor\n\nbuild:\n\tCGO_ENABLED=0 go build\n"
        },
        {
          "name": "Procfile",
          "type": "blob",
          "size": 0.0537109375,
          "content": "web: centrifugo --port=$PORT --address=0.0.0.0 --admin\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.85546875,
          "content": "Centrifugo is an open-source scalable real-time messaging server. Centrifugo can instantly deliver messages to application online users connected over supported transports (WebSocket, HTTP-streaming, SSE/EventSource, GRPC, WebTransport). Centrifugo has the concept of channel subscriptions – so it's a user-facing PUB/SUB server.\n\nCentrifugo is language-agnostic and can be used to build chat apps, live comments, multiplayer games, real-time data visualizations, collaborative tools, etc. in combination with any backend. It is well suited for modern architectures and allows decoupling the business logic from the real-time transport layer.\n\nSeveral official client SDKs for browser and mobile development wrap the bidirectional protocol. In addition, Centrifugo supports a unidirectional approach for simple use cases with no SDK dependency.\n\n## Documentation\n\n* [Centrifugo official documentation site](https://centrifugal.dev)\n* [Installation instructions](https://centrifugal.dev/docs/getting-started/installation)\n* [Getting started tutorial](https://centrifugal.dev/docs/getting-started/quickstart)\n* [Design overview and idiomatic usage](https://centrifugal.dev/docs/getting-started/design)\n* [Build a WebSocket chat/messenger app with Centrifugo](https://centrifugal.dev/docs/tutorial/intro) tutorial\n* [Centrifugal blog](https://centrifugal.dev/blog)\n* [FAQ](https://centrifugal.dev/docs/faq)\n\n## Join community\n\n* [Telegram](https://t.me/joinchat/ABFVWBE0AhkyyhREoaboXQ)\n* [Discord](https://discord.gg/tYgADKx)\n* [Twitter](https://twitter.com/centrifugalabs)\n\n## Why Centrifugo\n\nThe core idea of Centrifugo is simple – it's a PUB/SUB server on top of modern real-time transports:\n\n<img src=\"https://centrifugal.dev/img/protocol_pub_sub.png?v=2\" />\n\nThe hard part is to make this concept production-ready, efficient, flexible and available from different application environments. Centrifugo is a mature solution that already helped many projects with adding real-time features and scale towards many concurrent connections. Centrifugo provides a set of features not available in other open-source solutions in the area:\n\n* Efficient real-time transports: WebSocket, HTTP-streaming, Server-Sent Events (SSE), GRPC, WebTransport\n* Built-in scalability with Redis (or Redis Cluster, or Redis-compatible storage – ex. AWS Elasticache, KeyDB, DragonflyDB, etc), or Nats.\n* Simple HTTP and GRPC server API to communicate with Centrifugo from the app backend\n* Flexible connection authentication mechanisms: JWT and proxy-like\n* Channel subscription multiplexing over a single connection\n* Different types of subscriptions: client-side and server-side\n* Various channel permission strategies, channel namespace concept\n* Hot message history in channels, with automatic message recovery upon reconnect, cache recovery mode (deliver latest publication immediately upon subscription)\n* Delta compression in channels based on Fossil algorithm\n* Online channel presence information, with join/leave notifications\n* A way to send RPC calls to the backend over the real-time connection\n* Strict and effective client protocol wrapped by several official SDKs\n* JSON and binary Protobuf message transfer, with optimized serialization\n* Beautiful embedded admin web UI\n* And much more, visit [Centrifugo documentation site](https://centrifugal.dev)\n\n## Backing\n\nThis repository is hosted by [packagecloud.io](https://packagecloud.io/).\n\n<a href=\"https://packagecloud.io/\"><img height=\"46\" width=\"158\" alt=\"Private NPM registry and Maven, RPM, DEB, PyPi and RubyGem Repository · packagecloud\" src=\"https://packagecloud.io/images/packagecloud-badge.png\" /></a>\n\nAlso thanks to [JetBrains](https://www.jetbrains.com/) for supporting OSS (most of the code here written in Goland):\n\n<a href=\"https://www.jetbrains.com/\"><img height=\"140\" src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jb_beam.png\" alt=\"JetBrains logo\"></a>\n"
        },
        {
          "name": "buf.yaml",
          "type": "blob",
          "size": 0.392578125,
          "content": "version: v2\nmodules:\n  - path: internal/apiproto\n    name: buf.build/centrifugo/apiproto\n    excludes:\n      - internal/apiproto/swagger\n  - path: internal/proxyproto\n    name: buf.build/centrifugo/proxyproto\n  - path: internal/unigrpc/unistream\n    name: buf.build/centrifugo/unistream\nlint:\n  use:\n    - DEFAULT\n  ignore:\n    - internal/apiproto/swagger/api.swagger.proto\nbreaking:\n  use:\n    - FILE\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 1.40625,
          "content": "version: \"3.8\"\n\nservices:\n  nats:\n    image: nats:2.9-alpine\n    container_name: nats_server\n    ports:\n      - \"4222:4222\"\n      - \"8222:8222\"\n\n  postgres:\n    image: postgres:15\n    ports:\n      - \"5432:5432\"\n    environment:\n      POSTGRES_USER: test\n      POSTGRES_PASSWORD: test\n      POSTGRES_DB: test\n    tmpfs:\n      - /var/lib/postgresql/data\n    healthcheck:\n      test: [ \"CMD\", \"pg_isready\", \"-U\", \"test\" ]\n      interval: 1s\n      timeout: 5s\n      retries: 10\n    command: [\"postgres\", \"-c\", \"wal_level=logical\", \"-c\", \"wal_writer_delay=10ms\"]\n\n  zookeeper:\n    image: confluentinc/cp-zookeeper:latest\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n\n  kafka:\n    image: confluentinc/cp-kafka:latest\n    depends_on:\n      - zookeeper\n    ports:\n      - \"29092:29092\"\n    healthcheck:\n      test: [\"CMD\", \"kafka-topics\", \"--list\", \"--bootstrap-server\", \"localhost:9092\"]\n      interval: 2s\n      timeout: 5s\n      retries: 10\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 5.0478515625,
          "content": "module github.com/centrifugal/centrifugo/v5\n\ngo 1.23.0\n\nrequire (\n\tgithub.com/FZambia/eagle v0.1.0\n\tgithub.com/FZambia/statik v0.1.2-0.20180217151304-b9f012bb2a1b\n\tgithub.com/FZambia/tarantool v0.3.1\n\tgithub.com/FZambia/viper-lite v0.0.0-20220110144934-1899f66c7d0e\n\tgithub.com/centrifugal/centrifuge v0.33.5-0.20241221140549-8f88728a2744\n\tgithub.com/centrifugal/protocol v0.13.4\n\tgithub.com/cristalhq/jwt/v5 v5.4.0\n\tgithub.com/gobwas/glob v0.2.3\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/gorilla/securecookie v1.1.2\n\tgithub.com/gorilla/websocket v1.5.0\n\tgithub.com/hashicorp/go-envparse v0.1.0\n\tgithub.com/jackc/pgx/v5 v5.7.2\n\tgithub.com/justinas/alice v1.2.0\n\tgithub.com/mattn/go-isatty v0.0.20\n\tgithub.com/mitchellh/mapstructure v1.5.0\n\tgithub.com/nats-io/nats.go v1.38.0\n\tgithub.com/prometheus/client_golang v1.20.5\n\tgithub.com/quic-go/quic-go v0.48.2\n\tgithub.com/quic-go/webtransport-go v0.8.1-0.20241018022711-4ac2c9250e66\n\tgithub.com/rakutentech/jwk-go v1.1.3\n\tgithub.com/rs/zerolog v1.33.0\n\tgithub.com/spf13/cobra v1.8.1\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/tidwall/gjson v1.18.0\n\tgithub.com/tidwall/sjson v1.2.5\n\tgithub.com/twmb/franz-go v1.18.0\n\tgithub.com/twmb/franz-go/pkg/kadm v1.14.0\n\tgithub.com/twmb/franz-go/pkg/kmsg v1.9.0\n\tgithub.com/valyala/fasttemplate v1.2.2\n\tgithub.com/vmihailenco/msgpack/v5 v5.4.1\n\tgo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.58.0\n\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.58.0\n\tgo.opentelemetry.io/otel v1.33.0\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.33.0\n\tgo.opentelemetry.io/otel/sdk v1.33.0\n\tgo.opentelemetry.io/otel/trace v1.33.0\n\tgo.uber.org/automaxprocs v1.6.0\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/sync v0.10.0\n\tgolang.org/x/time v0.8.0\n\tgoogle.golang.org/grpc v1.69.2\n\tgoogle.golang.org/protobuf v1.36.1\n)\n\nrequire (\n\tgithub.com/dolthub/maphash v0.1.0 // indirect\n\tgithub.com/gammazero/deque v0.2.1 // indirect\n\tgithub.com/jackc/pgpassfile v1.0.0 // indirect\n\tgithub.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761 // indirect\n\tgithub.com/jackc/puddle/v2 v2.2.2 // indirect\n\tgithub.com/maypok86/otter v1.2.4 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/pierrec/lz4/v4 v4.1.21 // indirect\n\tgithub.com/planetscale/vtprotobuf v0.6.1-0.20240319094008-0393e58bdf10 // indirect\n\tgithub.com/shadowspore/fossil-delta v0.0.0-20241003175239-d3b7ce6bda62 // indirect\n\tgithub.com/tidwall/match v1.1.1 // indirect\n\tgithub.com/tidwall/pretty v1.2.0 // indirect\n\tgo.opentelemetry.io/auto/sdk v1.1.0 // indirect\n\tgo.uber.org/mock v0.4.0 // indirect\n)\n\nrequire (\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cenkalti/backoff/v4 v4.3.0 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/felixge/httpsnoop v1.0.4 // indirect\n\tgithub.com/fsnotify/fsnotify v1.5.4 // indirect\n\tgithub.com/go-logr/logr v1.4.2 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572 // indirect\n\tgithub.com/google/pprof v0.0.0-20230926050212-f7f687d19a98 // indirect\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2 v2.24.0 // indirect\n\tgithub.com/igm/sockjs-go/v3 v3.0.3\n\tgithub.com/inconshreveable/mousetrap v1.1.0 // indirect\n\tgithub.com/josharian/intern v1.0.0 // indirect\n\tgithub.com/klauspost/compress v1.17.11 // indirect\n\tgithub.com/mailru/easyjson v0.7.7 // indirect\n\tgithub.com/mattn/go-colorable v0.1.13 // indirect\n\tgithub.com/nats-io/nkeys v0.4.9 // indirect\n\tgithub.com/nats-io/nuid v1.0.1 // indirect\n\tgithub.com/onsi/ginkgo v1.16.5 // indirect\n\tgithub.com/onsi/ginkgo/v2 v2.12.1 // indirect\n\tgithub.com/pelletier/go-toml v1.9.4 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/prometheus/client_model v0.6.1 // indirect\n\tgithub.com/prometheus/common v0.60.0 // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgithub.com/quic-go/qpack v0.5.1 // indirect\n\tgithub.com/redis/rueidis v1.0.51 // indirect\n\tgithub.com/segmentio/asm v1.2.0 // indirect\n\tgithub.com/segmentio/encoding v0.4.1 // indirect\n\tgithub.com/spf13/cast v1.4.1 // indirect\n\tgithub.com/spf13/jwalterweatherman v1.1.0 // indirect\n\tgithub.com/spf13/pflag v1.0.5 // indirect\n\tgithub.com/valyala/bytebufferpool v1.0.0 // indirect\n\tgithub.com/vmihailenco/tagparser/v2 v2.0.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.33.0\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.33.0\n\tgo.opentelemetry.io/otel/metric v1.33.0 // indirect\n\tgo.opentelemetry.io/proto/otlp v1.4.0 // indirect\n\tgolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56 // indirect\n\tgolang.org/x/mod v0.19.0 // indirect\n\tgolang.org/x/net v0.32.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgolang.org/x/tools v0.23.0 // indirect\n\tgoogle.golang.org/genproto/googleapis/api v0.0.0-20241209162323-e6fa225c2576 // indirect\n\tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241209162323-e6fa225c2576 // indirect\n\tgopkg.in/yaml.v2 v2.4.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 29.8896484375,
          "content": "github.com/FZambia/eagle v0.1.0 h1:9gyX6x+xjoIfglgyPTcYm7dvY7FJ93us1QY5De4CyXA=\ngithub.com/FZambia/eagle v0.1.0/go.mod h1:YjGSPVkQTNcVLfzEUQJNgW9ScPR0K4u/Ky0yeFa4oDA=\ngithub.com/FZambia/statik v0.1.2-0.20180217151304-b9f012bb2a1b h1:D3CXZ/tXFtPMSN5FlhHVezJJp9eqDPR3m27OVptqZYE=\ngithub.com/FZambia/statik v0.1.2-0.20180217151304-b9f012bb2a1b/go.mod h1:EqC55Pa/sH33dUeH/rkKY8EHRfnm2JyV+ORPzURdGm0=\ngithub.com/FZambia/tarantool v0.3.1 h1:M6FiJrUBu1TvE8aySwSu47He7aYrJvufr+VPzP8FPWo=\ngithub.com/FZambia/tarantool v0.3.1/go.mod h1:YHnvW/H6TPJP04s3RtbBFqvxTvqfYnPBd+TVM1GWdsw=\ngithub.com/FZambia/viper-lite v0.0.0-20220110144934-1899f66c7d0e h1:COyWHWCYUotWRo+Z1Lk8B9NDceEybV61C9diY7YVj8g=\ngithub.com/FZambia/viper-lite v0.0.0-20220110144934-1899f66c7d0e/go.mod h1:hx7D3T4iFXiy0QWL4m3yNfzz5CQCtbV5yNdE4UlWo0s=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=\ngithub.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=\ngithub.com/centrifugal/centrifuge v0.33.5-0.20241221140549-8f88728a2744 h1:VO3gP46i93SfvDDG2BHd1oXxeO+MEYBtYdwdXjgx2F4=\ngithub.com/centrifugal/centrifuge v0.33.5-0.20241221140549-8f88728a2744/go.mod h1:qByx68JcOJmF0svRIwcHsq8XVYsjptyTHJr/3P/JmRs=\ngithub.com/centrifugal/protocol v0.13.4 h1:I0YxXtFNfn/ndDIZp5RkkqQcSSNH7DNPUbXKYtJXDzs=\ngithub.com/centrifugal/protocol v0.13.4/go.mod h1:7V5vI30VcoxJe4UD87xi7bOsvI0bmEhvbQuMjrFM2L4=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/coreos/go-systemd/v22 v22.5.0/go.mod h1:Y58oyj3AT4RCenI/lSvhwexgC+NSVTIJ3seZv2GcEnc=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.4/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=\ngithub.com/cristalhq/jwt/v5 v5.4.0 h1:Wxi1TocFHaijyV608j7v7B9mPc4ZNjvWT3LKBO0d4QI=\ngithub.com/cristalhq/jwt/v5 v5.4.0/go.mod h1:+b/BzaCWEpFDmXxspJ5h4SdJ1N/45KMjKOetWzmHvDA=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dolthub/maphash v0.1.0 h1:bsQ7JsF4FkkWyrP3oCnFJgrCUAFbFf3kOl4L/QxPDyQ=\ngithub.com/dolthub/maphash v0.1.0/go.mod h1:gkg4Ch4CdCDu5h6PMriVLawB7koZ+5ijb9puGMV50a4=\ngithub.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2Wg=\ngithub.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=\ngithub.com/francoispqt/gojay v1.2.13 h1:d2m3sFjloqoIUQU3TsHBgj6qg/BVGlTBeHDUmyJnXKk=\ngithub.com/francoispqt/gojay v1.2.13/go.mod h1:ehT5mTG4ua4581f1++1WLG0vPdaA9HaiDsoyrBGkyDY=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.9/go.mod h1:znqG4EE+3YCdAaPaxE2ZRY/06pZUdp0tY4IgpuI1SZQ=\ngithub.com/fsnotify/fsnotify v1.5.4 h1:jRbGcIw6P2Meqdwuo0H1p6JVLbL5DHKAKlYndzMwVZI=\ngithub.com/fsnotify/fsnotify v1.5.4/go.mod h1:OVB6XrOHzAwXMpEM7uPOzcehqUV2UqJxmVXmkdnm1bU=\ngithub.com/gammazero/deque v0.2.1 h1:qSdsbG6pgp6nL7A0+K/B7s12mcCY/5l5SIUpMOl+dC0=\ngithub.com/gammazero/deque v0.2.1/go.mod h1:LFroj8x4cMYCukHJDbxFCkT+r9AndaJnFMuZDV34tuU=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.4.2 h1:6pFjapn8bFcIbiKo3XT4j/BhANplGihG6tvd+8rYgrY=\ngithub.com/go-logr/logr v1.4.2/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-task/slim-sprig v0.0.0-20210107165309-348f09dbbbc0/go.mod h1:fyg7847qk6SyHyPtNmDHnmrv/HOrqktSC+C9fM+CJOE=\ngithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572 h1:tfuBGBXKqDEevZMzYi5KSi8KkcZtzBcTgAUUtapy0OI=\ngithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572/go.mod h1:9Pwr4B2jHnOSGXyyzV8ROjYa2ojvAY6HCGYYfMoC3Ls=\ngithub.com/gobwas/glob v0.2.3 h1:A4xDbljILXROh+kObIiy5kIaPYD8e96x1tgBhUI5J+Y=\ngithub.com/gobwas/glob v0.2.3/go.mod h1:d3Ez4x06l9bZtSvzIay5+Yzi0fmZzPgnTbPcKjJAkT8=\ngithub.com/godbus/dbus/v5 v5.0.4/go.mod h1:xhWf0FNVPg57R7Z0UbKHbJfkEywrmjJnf7w5xrFpKfA=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.2.0 h1:xRy4A+RhZaiKjJ1bPfwQ8sedCA+YS2YcCHW6ec7JMi0=\ngithub.com/google/gofuzz v1.2.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/pprof v0.0.0-20230926050212-f7f687d19a98 h1:pUa4ghanp6q4IJHwE9RwLgmVFfReJN+KbQ8ExNEUUoQ=\ngithub.com/google/pprof v0.0.0-20230926050212-f7f687d19a98/go.mod h1:czg5+yv1E0ZGTi6S6vVK1mke0fV+FaUhNGcd6VRS9Ik=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/gorilla/securecookie v1.1.2 h1:YCIWL56dvtr73r6715mJs5ZvhtnY73hBvEF8kXD8ePA=\ngithub.com/gorilla/securecookie v1.1.2/go.mod h1:NfCASbcHqRSY+3a8tlWJwsQap2VX5pwzwo4h3eOamfo=\ngithub.com/gorilla/websocket v1.4.2/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/gorilla/websocket v1.5.0 h1:PPwGk2jz7EePpoHN/+ClbZu8SPxiqlu12wZP/3sWmnc=\ngithub.com/gorilla/websocket v1.5.0/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.24.0 h1:TmHmbvxPmaegwhDubVz0lICL0J5Ka2vwTzhoePEXsGE=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.24.0/go.mod h1:qztMSjm835F2bXf+5HKAPIS5qsmQDqZna/PgVt4rWtI=\ngithub.com/hashicorp/go-envparse v0.1.0 h1:bE++6bhIsNCPLvgDZkYqo3nA+/PFI51pkrHdmPSDFPY=\ngithub.com/hashicorp/go-envparse v0.1.0/go.mod h1:OHheN1GoygLlAkTlXLXvAdnXdZxy8JUweQ1rAXx1xnc=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/igm/sockjs-go/v3 v3.0.3 h1:TlRBWiMzYO73iF6F9Q2Frgz90sN35VJB88qPDkNUJHc=\ngithub.com/igm/sockjs-go/v3 v3.0.3/go.mod h1:UqchsOjeagIBFHvd+RZpLaVRbCwGilEC08EDHsD1jYE=\ngithub.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=\ngithub.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=\ngithub.com/jackc/pgpassfile v1.0.0 h1:/6Hmqy13Ss2zCq62VdNG8tM1wchn8zjSGOBJ6icpsIM=\ngithub.com/jackc/pgpassfile v1.0.0/go.mod h1:CEx0iS5ambNFdcRtxPj5JhEz+xB6uRky5eyVu/W2HEg=\ngithub.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761 h1:iCEnooe7UlwOQYpKFhBabPMi4aNAfoODPEFNiAnClxo=\ngithub.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761/go.mod h1:5TJZWKEWniPve33vlWYSoGYefn3gLQRzjfDlhSJ9ZKM=\ngithub.com/jackc/pgx/v5 v5.7.2 h1:mLoDLV6sonKlvjIEsV56SkWNCnuNv531l94GaIzO+XI=\ngithub.com/jackc/pgx/v5 v5.7.2/go.mod h1:ncY89UGWxg82EykZUwSpUKEfccBGGYq1xjrOpsbsfGQ=\ngithub.com/jackc/puddle/v2 v2.2.2 h1:PR8nw+E/1w0GLuRFSmiioY6UooMp6KJv0/61nB7icHo=\ngithub.com/jackc/puddle/v2 v2.2.2/go.mod h1:vriiEXHvEE654aYKXXjOvZM39qJ0q+azkZFrfEOc3H4=\ngithub.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=\ngithub.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=\ngithub.com/justinas/alice v1.2.0 h1:+MHSA/vccVCF4Uq37S42jwlkvI2Xzl7zTPCN5BnZNVo=\ngithub.com/justinas/alice v1.2.0/go.mod h1:fN5HRH/reO/zrUflLfTN43t3vXvKzvZIENsNEe7i7qA=\ngithub.com/klauspost/compress v1.17.11 h1:In6xLpyWOi1+C7tXUUWv2ot1QvBjxevKAaI6IXrJmUc=\ngithub.com/klauspost/compress v1.17.11/go.mod h1:pMDklpSncoRMuLFrf1W9Ss9KT+0rH90U12bZKk7uwG0=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/kylelemons/godebug v1.1.0 h1:RPNrshWIDI6G2gRW9EHilWtl7Z6Sb1BR0xunSBf0SNc=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=\ngithub.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=\ngithub.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=\ngithub.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-isatty v0.0.19/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/maypok86/otter v1.2.4 h1:HhW1Pq6VdJkmWwcZZq19BlEQkHtI8xgsQzBVXJU0nfc=\ngithub.com/maypok86/otter v1.2.4/go.mod h1:mKLfoI7v1HOmQMwFgX4QkRk23mX6ge3RDvjdHOWG4R4=\ngithub.com/mitchellh/mapstructure v1.5.0 h1:jeMsZIYE/09sWLaz43PL7Gy6RuMjD2eJVyuac5Z2hdY=\ngithub.com/mitchellh/mapstructure v1.5.0/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/nats-io/nats.go v1.38.0 h1:A7P+g7Wjp4/NWqDOOP/K6hfhr54DvdDQUznt5JFg9XA=\ngithub.com/nats-io/nats.go v1.38.0/go.mod h1:IGUM++TwokGnXPs82/wCuiHS02/aKrdYUQkU8If6yjw=\ngithub.com/nats-io/nkeys v0.4.9 h1:qe9Faq2Gxwi6RZnZMXfmGMZkg3afLLOtrU+gDZJ35b0=\ngithub.com/nats-io/nkeys v0.4.9/go.mod h1:jcMqs+FLG+W5YO36OX6wFIFcmpdAns+w1Wm6D3I/evE=\ngithub.com/nats-io/nuid v1.0.1 h1:5iA8DT8V7q8WK2EScv2padNa/rTESc1KdnPw4TC2paw=\ngithub.com/nats-io/nuid v1.0.1/go.mod h1:19wcPz3Ph3q0Jbyiqsd0kePYG7A95tJPxeL+1OSON2c=\ngithub.com/nxadm/tail v1.4.4/go.mod h1:kenIhsEOeOJmVchQTgglprH7qJGnHDVpk1VPCcaMI8A=\ngithub.com/nxadm/tail v1.4.8 h1:nPr65rt6Y5JFSKQO7qToXr7pePgD6Gwiw05lkbyAQTE=\ngithub.com/nxadm/tail v1.4.8/go.mod h1:+ncqLTQzXmGhMZNUePPaPqPvBxHAIsmXswZKocGu+AU=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.12.0/go.mod h1:oUhWkIvk5aDxtKvDDuw8gItl8pKl42LzjC9KZE0HfGg=\ngithub.com/onsi/ginkgo v1.12.1/go.mod h1:zj2OWP4+oCPe1qIXoGWkgMRwljMUYCdkwsT2108oapk=\ngithub.com/onsi/ginkgo v1.16.5 h1:8xi0RTUf59SOSfEtZMvwTvXYMzG4gV23XVHOZiXNtnE=\ngithub.com/onsi/ginkgo v1.16.5/go.mod h1:+E8gABHa3K6zRBolWtd+ROzc/U5bkGt0FwiG042wbpU=\ngithub.com/onsi/ginkgo/v2 v2.12.1 h1:uHNEO1RP2SpuZApSkel9nEh1/Mu+hmQe7Q+Pepg5OYA=\ngithub.com/onsi/ginkgo/v2 v2.12.1/go.mod h1:TE309ZR8s5FsKKpuB1YAQYBzCaAfUgatB/xlT/ETL/o=\ngithub.com/onsi/gomega v1.7.1/go.mod h1:XdKZgCCFLUoM/7CFJVPcG8C1xQ1AJ0vpAezJrB7JYyY=\ngithub.com/onsi/gomega v1.9.0/go.mod h1:Ho0h+IUsWyvy1OpqCwxlQ/21gkhVunqlU8fDGcoTdcA=\ngithub.com/onsi/gomega v1.10.1/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=\ngithub.com/onsi/gomega v1.34.1 h1:EUMJIKUjM8sKjYbtxQI9A4z2o+rruxnzNvpknOXie6k=\ngithub.com/onsi/gomega v1.34.1/go.mod h1:kU1QgUvBDLXBJq618Xvm2LUX6rSAfRaFRTcdOeDLwwY=\ngithub.com/pelletier/go-toml v1.9.4 h1:tjENF6MfZAg8e4ZmZTeWaWiT2vXtsoO6+iuOjFhECwM=\ngithub.com/pelletier/go-toml v1.9.4/go.mod h1:u1nR/EPcESfeI/szUZKdtJ0xRNbUoANCkoOuaOx1Y+c=\ngithub.com/pierrec/lz4/v4 v4.1.21 h1:yOVMLb6qSIDP67pl/5F7RepeKYu/VmTyEXvuMI5d9mQ=\ngithub.com/pierrec/lz4/v4 v4.1.21/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/planetscale/vtprotobuf v0.6.1-0.20240319094008-0393e58bdf10 h1:GFCKgmp0tecUJ0sJuv4pzYCqS9+RGSn52M3FUwPs+uo=\ngithub.com/planetscale/vtprotobuf v0.6.1-0.20240319094008-0393e58bdf10/go.mod h1:t/avpk3KcrXxUnYOhZhMXJlSEyie6gQbtLq5NM3loB8=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prashantv/gostub v1.1.0 h1:BTyx3RfQjRHnUWaGF9oQos79AlQ5k8WNktv7VGvVH4g=\ngithub.com/prashantv/gostub v1.1.0/go.mod h1:A5zLQHz7ieHGG7is6LLXLz7I8+3LZzsrV0P1IAHhP5U=\ngithub.com/prometheus/client_golang v1.20.5 h1:cxppBPuYhUnsO6yo/aoRol4L7q7UFfdm+bR9r+8l63Y=\ngithub.com/prometheus/client_golang v1.20.5/go.mod h1:PIEt8X02hGcP8JWbeHyeZ53Y/jReSnHgO035n//V5WE=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.60.0 h1:+V9PAREWNvJMAuJ1x1BaWl9dewMW4YrHZQbx0sJNllA=\ngithub.com/prometheus/common v0.60.0/go.mod h1:h0LYf1R1deLSKtD4Vdg8gy4RuOvENW2J/h19V5NADQw=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/quic-go/qpack v0.5.1 h1:giqksBPnT/HDtZ6VhtFKgoLOWmlyo9Ei6u9PqzIMbhI=\ngithub.com/quic-go/qpack v0.5.1/go.mod h1:+PC4XFrEskIVkcLzpEkbLqq1uCoxPhQuvK5rH1ZgaEg=\ngithub.com/quic-go/quic-go v0.48.2 h1:wsKXZPeGWpMpCGSWqOcqpW2wZYic/8T3aqiOID0/KWE=\ngithub.com/quic-go/quic-go v0.48.2/go.mod h1:yBgs3rWBOADpga7F+jJsb6Ybg1LSYiQvwWlLX+/6HMs=\ngithub.com/quic-go/webtransport-go v0.8.1-0.20241018022711-4ac2c9250e66 h1:4WFk6u3sOT6pLa1kQ50ZVdm8BQFgJNA117cepZxtLIg=\ngithub.com/quic-go/webtransport-go v0.8.1-0.20241018022711-4ac2c9250e66/go.mod h1:Vp72IJajgeOL6ddqrAhmp7IM9zbTcgkQxD/YdxrVwMw=\ngithub.com/rakutentech/jwk-go v1.1.3 h1:PiLwepKyUaW+QFG3ki78DIO2+b4IVK3nMhlxM70zrQ4=\ngithub.com/rakutentech/jwk-go v1.1.3/go.mod h1:LtzSv4/+Iti1nnNeVQiP6l5cI74GBStbhyXCYvgPZFk=\ngithub.com/redis/rueidis v1.0.51 h1:NZ1KIncPIQtjrp+GDLynrLKBiPU106EN5cJHOFSqvDM=\ngithub.com/redis/rueidis v1.0.51/go.mod h1:by+34b0cFXndxtYmPAHpoTHO5NkosDlBvhexoTURIxM=\ngithub.com/rogpeppe/go-internal v1.13.1 h1:KvO1DLK/DRN07sQ1LQKScxyZJuNnedQ5/wKSR38lUII=\ngithub.com/rogpeppe/go-internal v1.13.1/go.mod h1:uMEvuHeurkdAXX61udpOXGD/AzZDWNMNyH2VO9fmH0o=\ngithub.com/rs/xid v1.5.0/go.mod h1:trrq9SKmegXys3aeAKXMUTdJsYXVwGY3RLcfgqegfbg=\ngithub.com/rs/zerolog v1.33.0 h1:1cU2KZkvPxNyfgEmhHAz/1A9Bz+llsdYzklWFzgp0r8=\ngithub.com/rs/zerolog v1.33.0/go.mod h1:/7mN4D5sKwJLZQ2b/znpjC3/GQWY/xaDXUM0kKWRHss=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/segmentio/asm v1.2.0 h1:9BQrFxC+YOHJlTlHGkTrFWf59nbL3XnCoFLTwDCI7ys=\ngithub.com/segmentio/asm v1.2.0/go.mod h1:BqMnlJP91P8d+4ibuonYZw9mfnzI9HfxselHZr5aAcs=\ngithub.com/segmentio/encoding v0.4.1 h1:KLGaLSW0jrmhB58Nn4+98spfvPvmo4Ci1P/WIQ9wn7w=\ngithub.com/segmentio/encoding v0.4.1/go.mod h1:/d03Cd8PoaDeceuhUUUQWjU0KhWjrmYrWPgtJHYZSnI=\ngithub.com/shadowspore/fossil-delta v0.0.0-20241003175239-d3b7ce6bda62 h1:2OBZQ+j6pNlvhcUJqV5WtoyMEv32vpZyKE9+ta2Sr+Y=\ngithub.com/shadowspore/fossil-delta v0.0.0-20241003175239-d3b7ce6bda62/go.mod h1:TNFF98m0aYYsGHXAKrlG2T6Tr/hUV2MbNHPdmyA6PFg=\ngithub.com/spf13/cast v1.4.1 h1:s0hze+J0196ZfEMTs80N7UlFt0BDuQ7Q+JDnHiMWKdA=\ngithub.com/spf13/cast v1.4.1/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=\ngithub.com/spf13/cobra v1.8.1 h1:e5/vxKd/rZsfSJMUX1agtjeTDf+qv1/JdBF8gg5k9ZM=\ngithub.com/spf13/cobra v1.8.1/go.mod h1:wHxEcudfqmLYa8iTfL+OuZPbBZkmvliBWKIezN3kD9Y=\ngithub.com/spf13/jwalterweatherman v1.1.0 h1:ue6voC5bR5F8YxI5S67j9i582FU4Qvo2bmqnqMYADFk=\ngithub.com/spf13/jwalterweatherman v1.1.0/go.mod h1:aNWZUN0dPAAO/Ljvb5BEdw96iTZ0EXowPYD95IqWIGo=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/tidwall/gjson v1.14.2/go.mod h1:/wbyibRr2FHMks5tjHJ5F8dMZh3AcwJEMf5vlfC0lxk=\ngithub.com/tidwall/gjson v1.18.0 h1:FIDeeyB800efLX89e5a8Y0BNH+LOngJyGrIWxG2FKQY=\ngithub.com/tidwall/gjson v1.18.0/go.mod h1:/wbyibRr2FHMks5tjHJ5F8dMZh3AcwJEMf5vlfC0lxk=\ngithub.com/tidwall/match v1.1.1 h1:+Ho715JplO36QYgwN9PGYNhgZvoUSc9X2c80KVTi+GA=\ngithub.com/tidwall/match v1.1.1/go.mod h1:eRSPERbgtNPcGhD8UCthc6PmLEQXEWd3PRB5JTxsfmM=\ngithub.com/tidwall/pretty v1.2.0 h1:RWIZEg2iJ8/g6fDDYzMpobmaoGh5OLl4AXtGUGPcqCs=\ngithub.com/tidwall/pretty v1.2.0/go.mod h1:ITEVvHYasfjBbM0u2Pg8T2nJnzm8xPwvNhhsoaGGjNU=\ngithub.com/tidwall/sjson v1.2.5 h1:kLy8mja+1c9jlljvWTlSazM7cKDRfJuR/bOJhcY5NcY=\ngithub.com/tidwall/sjson v1.2.5/go.mod h1:Fvgq9kS/6ociJEDnK0Fk1cpYF4FIW6ZF7LAe+6jwd28=\ngithub.com/twmb/franz-go v1.18.0 h1:25FjMZfdozBywVX+5xrWC2W+W76i0xykKjTdEeD2ejw=\ngithub.com/twmb/franz-go v1.18.0/go.mod h1:zXCGy74M0p5FbXsLeASdyvfLFsBvTubVqctIaa5wQ+I=\ngithub.com/twmb/franz-go/pkg/kadm v1.14.0 h1:nAn1co1lXzJQocpzyIyOFOjUBf4WHWs5/fTprXy2IZs=\ngithub.com/twmb/franz-go/pkg/kadm v1.14.0/go.mod h1:XjOPz6ZaXXjrW2jVCfLuucP8H1w2TvD6y3PT2M+aAM4=\ngithub.com/twmb/franz-go/pkg/kmsg v1.9.0 h1:JojYUph2TKAau6SBtErXpXGC7E3gg4vGZMv9xFU/B6M=\ngithub.com/twmb/franz-go/pkg/kmsg v1.9.0/go.mod h1:CMbfazviCyY6HM0SXuG5t9vOwYDHRCSrJJyBAe5paqg=\ngithub.com/valyala/bytebufferpool v1.0.0 h1:GqA5TC/0021Y/b9FG4Oi9Mr3q7XYx6KllzawFIhcdPw=\ngithub.com/valyala/bytebufferpool v1.0.0/go.mod h1:6bBcMArwyJ5K/AmCkWv1jt77kVWyCJ6HpOuEn7z0Csc=\ngithub.com/valyala/fasttemplate v1.2.2 h1:lxLXG0uE3Qnshl9QyaK6XJxMXlQZELvChBOCmQD0Loo=\ngithub.com/valyala/fasttemplate v1.2.2/go.mod h1:KHLXt3tVN2HBp8eijSv/kGJopbvo7S+qRAEEKiv+SiQ=\ngithub.com/vmihailenco/msgpack/v5 v5.3.5/go.mod h1:7xyJ9e+0+9SaZT0Wt1RGleJXzli6Q/V5KbhBonMG9jc=\ngithub.com/vmihailenco/msgpack/v5 v5.4.1 h1:cQriyiUvjTwOHg8QZaPihLWeRAAVoCpE00IUPn0Bjt8=\ngithub.com/vmihailenco/msgpack/v5 v5.4.1/go.mod h1:GaZTsDaehaPpQVyxrf5mtQlH+pc21PIudVV/E3rRQok=\ngithub.com/vmihailenco/tagparser/v2 v2.0.0 h1:y09buUbR+b5aycVFQs/g70pqKVZNBmxwAhO7/IwNM9g=\ngithub.com/vmihailenco/tagparser/v2 v2.0.0/go.mod h1:Wri+At7QHww0WTrCBeu4J6bNtoV6mEfg5OIWRZA9qds=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngo.opentelemetry.io/auto/sdk v1.1.0 h1:cH53jehLUN6UFLY71z+NDOiNJqDdPRaXzTel0sJySYA=\ngo.opentelemetry.io/auto/sdk v1.1.0/go.mod h1:3wSPjt5PWp2RhlCcmmOial7AvC4DQqZb7a7wCow3W8A=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.58.0 h1:PS8wXpbyaDJQ2VDHHncMe9Vct0Zn1fEjpsjrLxGJoSc=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.58.0/go.mod h1:HDBUsEjOuRC0EzKZ1bSaRGZWUBAzo+MhAcUUORSr4D0=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.58.0 h1:yd02MEjBdJkG3uabWP9apV+OuWRIXGDuJEUJbOHmCFU=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.58.0/go.mod h1:umTcuxiv1n/s/S6/c2AT/g2CQ7u5C59sHDNmfSwgz7Q=\ngo.opentelemetry.io/otel v1.33.0 h1:/FerN9bax5LoK51X/sI0SVYrjSE0/yUL7DpxW4K3FWw=\ngo.opentelemetry.io/otel v1.33.0/go.mod h1:SUUkR6csvUQl+yjReHu5uM3EtVV7MBm5FHKRlNx4I8I=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.33.0 h1:Vh5HayB/0HHfOQA7Ctx69E/Y/DcQSMPpKANYVMQ7fBA=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.33.0/go.mod h1:cpgtDBaqD/6ok/UG0jT15/uKjAY8mRA53diogHBg3UI=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.33.0 h1:5pojmb1U1AogINhN3SurB+zm/nIcusopeBNp42f45QM=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.33.0/go.mod h1:57gTHJSE5S1tqg+EKsLPlTWhpHMsWlVmer+LA926XiA=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.33.0 h1:wpMfgF8E1rkrT1Z6meFh1NDtownE9Ii3n3X2GJYjsaU=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.33.0/go.mod h1:wAy0T/dUbs468uOlkT31xjvqQgEVXv58BRFWEgn5v/0=\ngo.opentelemetry.io/otel/metric v1.33.0 h1:r+JOocAyeRVXD8lZpjdQjzMadVZp2M4WmQ+5WtEnklQ=\ngo.opentelemetry.io/otel/metric v1.33.0/go.mod h1:L9+Fyctbp6HFTddIxClbQkjtubW6O9QS3Ann/M82u6M=\ngo.opentelemetry.io/otel/sdk v1.33.0 h1:iax7M131HuAm9QkZotNHEfstof92xM+N8sr3uHXc2IM=\ngo.opentelemetry.io/otel/sdk v1.33.0/go.mod h1:A1Q5oi7/9XaMlIWzPSxLRWOI8nG3FnzHJNbiENQuihM=\ngo.opentelemetry.io/otel/sdk/metric v1.31.0 h1:i9hxxLJF/9kkvfHppyLL55aW7iIJz4JjxTeYusH7zMc=\ngo.opentelemetry.io/otel/sdk/metric v1.31.0/go.mod h1:CRInTMVvNhUKgSAMbKyTMxqOBC0zgyxzW55lZzX43Y8=\ngo.opentelemetry.io/otel/trace v1.33.0 h1:cCJuF7LRjUFso9LPnEAHJDB2pqzp+hbO8eu1qqW2d/s=\ngo.opentelemetry.io/otel/trace v1.33.0/go.mod h1:uIcdVUZMpTAmz0tI1z04GoVSezK37CbGV4fr1f2nBck=\ngo.opentelemetry.io/proto/otlp v1.4.0 h1:TA9WRvW6zMwP+Ssb6fLoUIuirti1gGbP28GcKG1jgeg=\ngo.opentelemetry.io/proto/otlp v1.4.0/go.mod h1:PPBWZIP98o2ElSqI35IHfu7hIhSwvc5N38Jw8pXuGFY=\ngo.uber.org/automaxprocs v1.6.0 h1:O3y2/QNTOdbF+e/dpXNNW7Rx2hZ4sTIPyybbxyNqTUs=\ngo.uber.org/automaxprocs v1.6.0/go.mod h1:ifeIMSnPZuznNm6jmdzmU3/bfk01Fe2fotchwEFJ8r8=\ngo.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=\ngo.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=\ngo.uber.org/mock v0.4.0 h1:VcM4ZOtdbR4f6VXfiOpwpVJDL6lCReaZ6mw31wqh7KU=\ngo.uber.org/mock v0.4.0/go.mod h1:a6FSlNadKUHUa9IP5Vyt1zh4fC7uAwxMutEAscFbkZc=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200323165209-0ec3e9974c59/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56 h1:2dVuKD2vS7b0QIHQbpyTISPd0LeHDbnYEryqj5Q1ug8=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56/go.mod h1:M4RDyNAINzryxdtnbRXRL/OHtkFuWGRjvuhBJpk2IlY=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.19.0 h1:fEdghXQSo20giMthA7cd28ZC+jts4amQ3YMXiP5oMQ8=\ngolang.org/x/mod v0.19.0/go.mod h1:hTbmBsO62+eylJbnUtE2MGJUyE7QWk4xUqPFrRgJ+7c=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200520004742-59133d7f0dd7/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.32.0 h1:ZqPmj8Kzc+Y6e0+skZsuACbx+wzMgo5MQsJh9Qd6aYI=\ngolang.org/x/net v0.32.0/go.mod h1:CwU0IoeOlnQQWJ6ioyFrfRuomB8GKF6KbYXZVyeXNfs=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190904154756-749cb33beabd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191120155948-bd437916bb0e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210112080510-489259a85091/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20220412211240-33da011f77ad/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.12.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/time v0.8.0 h1:9i3RxcPv3PZnitoVGMPDKZSq1xW1gK1Xy3ArNOGZfEg=\ngolang.org/x/time v0.8.0/go.mod h1:3BpzKBy/shNhVucY/MWOyx10tF3SFh9QdLuxbVysPQM=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20201224043029-2b0845dc783e/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.23.0 h1:SGsXPZ+2l4JsgaCKkx+FQ9YZ5XEtA1GZYuoDjenLjvg=\ngolang.org/x/tools v0.23.0/go.mod h1:pnu6ufv6vQkll6szChhK3C3L/ruaIv5eBeztNG8wtsI=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20241209162323-e6fa225c2576 h1:CkkIfIt50+lT6NHAVoRYEyAvQGFM7xEwXUUywFvEb3Q=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20241209162323-e6fa225c2576/go.mod h1:1R3kvZ1dtP3+4p4d3G8uJ8rFk/fWlScl38vanWACI08=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241209162323-e6fa225c2576 h1:8ZmaLZE4XWrtU3MyClkYqqtl6Oegr3235h7jxsDyqCY=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241209162323-e6fa225c2576/go.mod h1:5uTbfoYQed2U9p3KIj2/Zzm02PYhndfdmML0qC3q3FU=\ngoogle.golang.org/grpc v1.69.2 h1:U3S9QEtbXC0bYNvRtcoklF3xGtLViumSYxWykJS+7AU=\ngoogle.golang.org/grpc v1.69.2/go.mod h1:vyjdE6jLBI76dgpDojsFGNaHlxdjXN9ghpnd2o7JGZ4=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.36.1 h1:yBPeRvTftaleIgM3PZ/WBIZ7XM/eEYAaEyCwvyjq/gk=\ngoogle.golang.org/protobuf v1.36.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 h1:uRGJdciOHaEIrze2W8Q3AKkepLTh2hOroT7a+7czfdQ=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 110.5498046875,
          "content": "// Copyright (c) 2015 Centrifugal\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\npackage main\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"errors\"\n\t\"fmt\"\n\tstdlog \"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/pprof\"\n\t\"os\"\n\t\"os/signal\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/centrifugal/centrifugo/v5/internal/admin\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/api\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/build\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/cli\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/client\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/consuming\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/health\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/jwtutils\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/jwtverify\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/logutils\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/metrics/graphite\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/middleware\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/natsbroker\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/notify\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/origin\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/proxy\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/redisnatsbroker\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/rule\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/service\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/sockjs\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/survey\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/swaggerui\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/telemetry\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/tntengine\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/tools\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/unigrpc\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/unihttpstream\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/unisse\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/uniws\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/usage\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/webui\"\n\t\"github.com/centrifugal/centrifugo/v5/internal/wt\"\n\n\t\"github.com/FZambia/viper-lite\"\n\t\"github.com/centrifugal/centrifuge\"\n\t\"github.com/justinas/alice\"\n\t\"github.com/mattn/go-isatty\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"github.com/quic-go/quic-go/http3\"\n\t\"github.com/quic-go/webtransport-go\"\n\t\"github.com/rs/zerolog\"\n\t\"github.com/rs/zerolog/log\"\n\t\"github.com/spf13/cobra\"\n\t\"go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc\"\n\t\"go.uber.org/automaxprocs/maxprocs\"\n\t\"golang.org/x/crypto/acme\"\n\t\"golang.org/x/crypto/acme/autocert\"\n\t\"golang.org/x/sync/errgroup\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n\t_ \"google.golang.org/grpc/encoding/gzip\"\n\t\"google.golang.org/grpc/keepalive\"\n\t\"google.golang.org/grpc/reflection\"\n)\n\n//go:generate go run internal/gen/api/main.go\n\nvar defaults = map[string]any{\n\t\"gomaxprocs\": 0,\n\t\"name\":       \"\",\n\t\"engine\":     \"memory\",\n\t\"broker\":     \"\",\n\n\t\"pid_file\": \"\",\n\n\t\"granular_proxy_mode\": false,\n\n\t\"opentelemetry\":           false,\n\t\"opentelemetry_api\":       false,\n\t\"opentelemetry_consuming\": false,\n\n\t\"client_insecure\": false,\n\t\"client_insecure_skip_token_signature_verify\": false,\n\t\"api_insecure\": false,\n\n\t\"client_user_id_http_header\": \"\",\n\n\t\"token_hmac_secret_key\":      \"\",\n\t\"token_rsa_public_key\":       \"\",\n\t\"token_ecdsa_public_key\":     \"\",\n\t\"token_jwks_public_endpoint\": \"\",\n\t\"token_audience\":             \"\",\n\t\"token_audience_regex\":       \"\",\n\t\"token_issuer\":               \"\",\n\t\"token_issuer_regex\":         \"\",\n\t\"token_user_id_claim\":        \"\",\n\n\t\"separate_subscription_token_config\":      false,\n\t\"subscription_token_hmac_secret_key\":      \"\",\n\t\"subscription_token_rsa_public_key\":       \"\",\n\t\"subscription_token_ecdsa_public_key\":     \"\",\n\t\"subscription_token_jwks_public_endpoint\": \"\",\n\t\"subscription_token_audience\":             \"\",\n\t\"subscription_token_audience_regex\":       \"\",\n\t\"subscription_token_issuer\":               \"\",\n\t\"subscription_token_issuer_regex\":         \"\",\n\t\"subscription_token_user_id_claim\":        \"\",\n\n\t\"allowed_origins\": []string{},\n\n\t\"global_history_meta_ttl\":            rule.DefaultGlobalHistoryMetaTTL,\n\t\"global_presence_ttl\":                60 * time.Second,\n\t\"global_redis_presence_user_mapping\": false,\n\t\"redis_presence_hash_field_ttl\":      false,\n\n\t\"allowed_delta_types\": []centrifuge.DeltaType{},\n\t\"delta_publish\":       false,\n\n\t\"presence\":                      false,\n\t\"join_leave\":                    false,\n\t\"force_push_join_leave\":         false,\n\t\"history_size\":                  0,\n\t\"history_ttl\":                   0,\n\t\"history_meta_ttl\":              0,\n\t\"force_positioning\":             false,\n\t\"allow_positioning\":             false,\n\t\"force_recovery\":                false,\n\t\"allow_recovery\":                false,\n\t\"force_recovery_mode\":           \"\",\n\t\"allow_subscribe_for_anonymous\": false,\n\t\"allow_subscribe_for_client\":    false,\n\t\"allow_publish_for_anonymous\":   false,\n\t\"allow_publish_for_client\":      false,\n\t\"allow_publish_for_subscriber\":  false,\n\t\"allow_presence_for_anonymous\":  false,\n\t\"allow_presence_for_client\":     false,\n\t\"allow_presence_for_subscriber\": false,\n\t\"allow_history_for_anonymous\":   false,\n\t\"allow_history_for_client\":      false,\n\t\"allow_history_for_subscriber\":  false,\n\t\"allow_user_limited_channels\":   false,\n\t\"channel_regex\":                 \"\",\n\t\"proxy_subscribe\":               false,\n\t\"proxy_publish\":                 false,\n\t\"proxy_sub_refresh\":             false,\n\t\"subscribe_proxy_name\":          \"\",\n\t\"publish_proxy_name\":            \"\",\n\t\"sub_refresh_proxy_name\":        \"\",\n\n\t\"node_info_metrics_aggregate_interval\": 60 * time.Second,\n\n\t\"allow_anonymous_connect_without_token\": false,\n\t\"disallow_anonymous_connection_tokens\":  false,\n\n\t\"client_expired_close_delay\":           25 * time.Second,\n\t\"client_expired_sub_close_delay\":       25 * time.Second,\n\t\"client_stale_close_delay\":             10 * time.Second,\n\t\"client_channel_limit\":                 128,\n\t\"client_queue_max_size\":                1048576, // 1 MB\n\t\"client_presence_update_interval\":      27 * time.Second,\n\t\"client_user_connection_limit\":         0,\n\t\"client_concurrency\":                   0,\n\t\"client_channel_position_check_delay\":  40 * time.Second,\n\t\"client_channel_position_max_time_lag\": 0,\n\t\"client_connection_limit\":              0,\n\t\"client_connection_rate_limit\":         0,\n\t\"client_connect_include_server_time\":   false,\n\n\t\"channel_max_length\":         255,\n\t\"channel_private_prefix\":     \"$\",\n\t\"channel_namespace_boundary\": \":\",\n\t\"channel_user_boundary\":      \"#\",\n\t\"channel_user_separator\":     \",\",\n\n\t\"rpc_namespace_boundary\": \":\",\n\n\t\"rpc_ping\":        false,\n\t\"rpc_ping_method\": \"ping\",\n\n\t\"user_subscribe_to_personal\":      false,\n\t\"user_personal_channel_namespace\": \"\",\n\t\"user_personal_single_connection\": false,\n\n\t\"debug\":      false,\n\t\"prometheus\": false,\n\t\"health\":     false,\n\n\t\"admin\":                   false,\n\t\"admin_password\":          \"\",\n\t\"admin_secret\":            \"\",\n\t\"admin_insecure\":          false,\n\t\"admin_web_path\":          \"\",\n\t\"admin_web_proxy_address\": \"\",\n\n\t\"sockjs\":     false,\n\t\"sockjs_url\": \"https://cdn.jsdelivr.net/npm/sockjs-client@1/dist/sockjs.min.js\",\n\n\t\"websocket_compression\":           false,\n\t\"websocket_compression_min_size\":  0,\n\t\"websocket_compression_level\":     1,\n\t\"websocket_read_buffer_size\":      0,\n\t\"websocket_use_write_buffer_pool\": false,\n\t\"websocket_write_buffer_size\":     0,\n\t\"websocket_write_timeout\":         time.Second,\n\t\"websocket_message_size_limit\":    65536, // 64KB\n\n\t\"uni_websocket\":                       false,\n\t\"uni_websocket_compression\":           false,\n\t\"uni_websocket_compression_min_size\":  0,\n\t\"uni_websocket_compression_level\":     1,\n\t\"uni_websocket_read_buffer_size\":      0,\n\t\"uni_websocket_use_write_buffer_pool\": false,\n\t\"uni_websocket_write_buffer_size\":     0,\n\t\"uni_websocket_write_timeout\":         time.Second,\n\t\"uni_websocket_message_size_limit\":    65536, // 64KB\n\n\t\"uni_sse\":         false,\n\t\"uni_http_stream\": false,\n\n\t\"client_connect_code_to_unidirectional_disconnect.enabled\":    false,\n\t\"client_connect_code_to_unidirectional_disconnect.transforms\": []any{},\n\n\t\"uni_sse_connect_code_to_http_response.enabled\":            false,\n\t\"uni_sse_connect_code_to_http_response.transforms\":         []any{},\n\t\"uni_http_stream_connect_code_to_http_response.enabled\":    false,\n\t\"uni_http_stream_connect_code_to_http_response.transforms\": []any{},\n\n\t\"log_level\": \"info\",\n\t\"log_file\":  \"\",\n\n\t\"tls\":                      false,\n\t\"tls_key\":                  \"\",\n\t\"tls_cert\":                 \"\",\n\t\"tls_cert_pem\":             \"\",\n\t\"tls_key_pem\":              \"\",\n\t\"tls_root_ca\":              \"\",\n\t\"tls_root_ca_pem\":          \"\",\n\t\"tls_client_ca\":            \"\",\n\t\"tls_client_ca_pem\":        \"\",\n\t\"tls_server_name\":          \"\",\n\t\"tls_insecure_skip_verify\": false,\n\n\t\"swagger\":          false,\n\t\"admin_external\":   false,\n\t\"api_external\":     false,\n\t\"address\":          \"\",\n\t\"port\":             \"8000\",\n\t\"internal_address\": \"\",\n\t\"internal_port\":    \"\",\n\n\t\"webtransport\": false,\n\t\"http3\":        false,\n\n\t\"tls_external\": false,\n\n\t\"connect_proxy_name\": \"\",\n\t\"refresh_proxy_name\": \"\",\n\t\"rpc_proxy_name\":     \"\",\n\n\t\"proxy_connect_endpoint\":          \"\",\n\t\"proxy_refresh_endpoint\":          \"\",\n\t\"proxy_subscribe_endpoint\":        \"\",\n\t\"proxy_publish_endpoint\":          \"\",\n\t\"proxy_sub_refresh_endpoint\":      \"\",\n\t\"proxy_rpc_endpoint\":              \"\",\n\t\"proxy_subscribe_stream_endpoint\": \"\",\n\n\t\"proxy_connect_timeout\":          time.Second,\n\t\"proxy_rpc_timeout\":              time.Second,\n\t\"proxy_refresh_timeout\":          time.Second,\n\t\"proxy_subscribe_timeout\":        time.Second,\n\t\"proxy_publish_timeout\":          time.Second,\n\t\"proxy_sub_refresh_timeout\":      time.Second,\n\t\"proxy_subscribe_stream_timeout\": time.Second,\n\n\t\"proxy_http_status_code_transforms\": []any{},\n\t\"proxy_grpc_metadata\":               []string{},\n\t\"proxy_http_headers\":                []string{},\n\t\"proxy_static_http_headers\":         map[string]string{},\n\t\"proxy_binary_encoding\":             false,\n\t\"proxy_include_connection_meta\":     false,\n\t\"proxy_grpc_cert_file\":              \"\",\n\t\"proxy_grpc_compression\":            false,\n\t\"proxy_grpc_tls\":                    tools.TLSConfig{},\n\n\t\"tarantool_mode\":     \"standalone\",\n\t\"tarantool_address\":  \"tcp://127.0.0.1:3301\",\n\t\"tarantool_user\":     \"\",\n\t\"tarantool_password\": \"\",\n\n\t\"api_key\":        \"\",\n\t\"api_error_mode\": \"\",\n\n\t\"uni_http_stream_max_request_body_size\": 65536, // 64KB\n\t\"uni_sse_max_request_body_size\":         65536, // 64KB\n\t\"http_stream_max_request_body_size\":     65536, // 64KB\n\t\"sse_max_request_body_size\":             65536, // 64KB\n\n\t\"tls_autocert\":                false,\n\t\"tls_autocert_host_whitelist\": \"\",\n\t\"tls_autocert_cache_dir\":      \"\",\n\t\"tls_autocert_email\":          \"\",\n\t\"tls_autocert_server_name\":    \"\",\n\t\"tls_autocert_http\":           false,\n\t\"tls_autocert_http_addr\":      \":80\",\n\n\t\"grpc_api\":                          false,\n\t\"grpc_api_error_mode\":               \"\",\n\t\"grpc_api_address\":                  \"\",\n\t\"grpc_api_port\":                     10000,\n\t\"grpc_api_key\":                      \"\",\n\t\"grpc_api_tls_disable\":              false,\n\t\"grpc_api_reflection\":               false,\n\t\"grpc_api_tls\":                      false,\n\t\"grpc_api_tls_key\":                  \"\",\n\t\"grpc_api_tls_cert\":                 \"\",\n\t\"grpc_api_tls_cert_pem\":             \"\",\n\t\"grpc_api_tls_key_pem\":              \"\",\n\t\"grpc_api_tls_root_ca\":              \"\",\n\t\"grpc_api_tls_root_ca_pem\":          \"\",\n\t\"grpc_api_tls_client_ca\":            \"\",\n\t\"grpc_api_tls_client_ca_pem\":        \"\",\n\t\"grpc_api_tls_server_name\":          \"\",\n\t\"grpc_api_tls_insecure_skip_verify\": false,\n\t\"grpc_api_max_receive_message_size\": 0,\n\n\t\"shutdown_timeout\":           30 * time.Second,\n\t\"shutdown_termination_delay\": 0,\n\n\t\"graphite\":          false,\n\t\"graphite_host\":     \"localhost\",\n\t\"graphite_port\":     2003,\n\t\"graphite_prefix\":   \"centrifugo\",\n\t\"graphite_interval\": 10 * time.Second,\n\t\"graphite_tags\":     false,\n\n\t\"nats_prefix\":          \"centrifugo\",\n\t\"nats_url\":             \"nats://127.0.0.1:4222\",\n\t\"nats_dial_timeout\":    time.Second,\n\t\"nats_write_timeout\":   time.Second,\n\t\"nats_allow_wildcards\": false,\n\n\t\"nats_raw_mode.enabled\":              false,\n\t\"nats_raw_mode.channel_replacements\": map[string]string{},\n\t\"nats_raw_mode.prefix\":               \"\",\n\n\t\"websocket_disable\": false,\n\t\"api_disable\":       false,\n\n\t\"websocket_handler_prefix\":       \"/connection/websocket\",\n\t\"webtransport_handler_prefix\":    \"/connection/webtransport\",\n\t\"sockjs_handler_prefix\":          \"/connection/sockjs\",\n\t\"http_stream_handler_prefix\":     \"/connection/http_stream\",\n\t\"sse_handler_prefix\":             \"/connection/sse\",\n\t\"uni_websocket_handler_prefix\":   \"/connection/uni_websocket\",\n\t\"uni_sse_handler_prefix\":         \"/connection/uni_sse\",\n\t\"uni_http_stream_handler_prefix\": \"/connection/uni_http_stream\",\n\n\t\"uni_grpc\":                          false,\n\t\"uni_grpc_address\":                  \"\",\n\t\"uni_grpc_port\":                     11000,\n\t\"uni_grpc_max_receive_message_size\": 65536,\n\t\"uni_grpc_tls_disable\":              false,\n\t\"uni_grpc_tls\":                      false,\n\t\"uni_grpc_tls_key\":                  \"\",\n\t\"uni_grpc_tls_cert\":                 \"\",\n\t\"uni_grpc_tls_cert_pem\":             \"\",\n\t\"uni_grpc_tls_key_pem\":              \"\",\n\t\"uni_grpc_tls_root_ca\":              \"\",\n\t\"uni_grpc_tls_root_ca_pem\":          \"\",\n\t\"uni_grpc_tls_client_ca\":            \"\",\n\t\"uni_grpc_tls_client_ca_pem\":        \"\",\n\t\"uni_grpc_tls_server_name\":          \"\",\n\t\"uni_grpc_tls_insecure_skip_verify\": false,\n\n\t\"http_stream\": false,\n\t\"sse\":         false,\n\n\t\"emulation_handler_prefix\":        \"/emulation\",\n\t\"emulation_max_request_body_size\": 65536, // 64KB\n\n\t\"admin_handler_prefix\":      \"\",\n\t\"api_handler_prefix\":        \"/api\",\n\t\"prometheus_handler_prefix\": \"/metrics\",\n\t\"health_handler_prefix\":     \"/health\",\n\t\"swagger_handler_prefix\":    \"/swagger\",\n\n\t\"client_history_max_publication_limit\":  300,\n\t\"client_recovery_max_publication_limit\": 300,\n\n\t\"usage_stats_disable\": false,\n\n\t\"ping_interval\": 25 * time.Second,\n\t\"pong_timeout\":  8 * time.Second,\n\n\t\"namespaces\":     []any{},\n\t\"rpc_namespaces\": []any{},\n\n\t\"proxies\": []any{},\n\n\t\"proxy_grpc_credentials_key\":   \"\",\n\t\"proxy_grpc_credentials_value\": \"\",\n\n\t\"enable_unreleased_features\": false,\n\n\t\"consumers\": []any{},\n}\n\nfunc init() {\n\tredisConfigPrefixes := []string{\n\t\t\"\",\n\t}\n\tfor _, prefix := range redisConfigPrefixes {\n\t\tkeyMap := map[string]any{\n\t\t\tprefix + \"redis_address\":                           \"redis://127.0.0.1:6379\",\n\t\t\tprefix + \"redis_prefix\":                            \"centrifugo\",\n\t\t\tprefix + \"redis_connect_timeout\":                   time.Second,\n\t\t\tprefix + \"redis_io_timeout\":                        4 * time.Second,\n\t\t\tprefix + \"redis_use_lists\":                         false,\n\t\t\tprefix + \"redis_db\":                                0,\n\t\t\tprefix + \"redis_user\":                              \"\",\n\t\t\tprefix + \"redis_password\":                          \"\",\n\t\t\tprefix + \"redis_client_name\":                       \"\",\n\t\t\tprefix + \"redis_force_resp2\":                       false,\n\t\t\tprefix + \"redis_cluster_address\":                   []string{},\n\t\t\tprefix + \"redis_sentinel_address\":                  []string{},\n\t\t\tprefix + \"redis_sentinel_user\":                     \"\",\n\t\t\tprefix + \"redis_sentinel_password\":                 \"\",\n\t\t\tprefix + \"redis_sentinel_master_name\":              \"\",\n\t\t\tprefix + \"redis_sentinel_client_name\":              \"\",\n\t\t\tprefix + \"redis_tls\":                               false,\n\t\t\tprefix + \"redis_tls_key\":                           \"\",\n\t\t\tprefix + \"redis_tls_cert\":                          \"\",\n\t\t\tprefix + \"redis_tls_cert_pem\":                      \"\",\n\t\t\tprefix + \"redis_tls_key_pem\":                       \"\",\n\t\t\tprefix + \"redis_tls_root_ca\":                       \"\",\n\t\t\tprefix + \"redis_tls_root_ca_pem\":                   \"\",\n\t\t\tprefix + \"redis_tls_client_ca\":                     \"\",\n\t\t\tprefix + \"redis_tls_client_ca_pem\":                 \"\",\n\t\t\tprefix + \"redis_tls_server_name\":                   \"\",\n\t\t\tprefix + \"redis_tls_insecure_skip_verify\":          false,\n\t\t\tprefix + \"redis_sentinel_tls\":                      false,\n\t\t\tprefix + \"redis_sentinel_tls_key\":                  \"\",\n\t\t\tprefix + \"redis_sentinel_tls_cert\":                 \"\",\n\t\t\tprefix + \"redis_sentinel_tls_cert_pem\":             \"\",\n\t\t\tprefix + \"redis_sentinel_tls_key_pem\":              \"\",\n\t\t\tprefix + \"redis_sentinel_tls_root_ca\":              \"\",\n\t\t\tprefix + \"redis_sentinel_tls_root_ca_pem\":          \"\",\n\t\t\tprefix + \"redis_sentinel_tls_client_ca\":            \"\",\n\t\t\tprefix + \"redis_sentinel_tls_client_ca_pem\":        \"\",\n\t\t\tprefix + \"redis_sentinel_tls_server_name\":          \"\",\n\t\t\tprefix + \"redis_sentinel_tls_insecure_skip_verify\": false,\n\t\t}\n\t\tfor k, v := range keyMap {\n\t\t\tdefaults[k] = v\n\t\t}\n\t}\n\ttlsConfigPrefixes := []string{\n\t\t\"nats_tls.\",\n\t\t\"proxy_grpc_tls.\",\n\t}\n\tfor _, prefix := range tlsConfigPrefixes {\n\t\tkeyMap := map[string]any{\n\t\t\tprefix + \"enabled\":              false,\n\t\t\tprefix + \"cert_pem\":             \"\",\n\t\t\tprefix + \"cert_pem_file\":        \"\",\n\t\t\tprefix + \"cert_pem_b64\":         \"\",\n\t\t\tprefix + \"key_pem\":              \"\",\n\t\t\tprefix + \"key_pem_file\":         \"\",\n\t\t\tprefix + \"key_pem_b64\":          \"\",\n\t\t\tprefix + \"server_ca_pem\":        \"\",\n\t\t\tprefix + \"server_ca_pem_file\":   \"\",\n\t\t\tprefix + \"server_ca_pem_b64\":    \"\",\n\t\t\tprefix + \"client_ca_pem\":        \"\",\n\t\t\tprefix + \"client_ca_pem_file\":   \"\",\n\t\t\tprefix + \"client_ca_pem_b64\":    \"\",\n\t\t\tprefix + \"server_name\":          \"\",\n\t\t\tprefix + \"insecure_skip_verify\": false,\n\t\t}\n\t\tfor k, v := range keyMap {\n\t\t\tdefaults[k] = v\n\t\t}\n\t}\n}\n\nfunc bindCentrifugoConfig() {\n\tviper.SetEnvPrefix(\"centrifugo\")\n\n\tfor k, v := range defaults {\n\t\tviper.SetDefault(k, v)\n\t}\n\n\treplacer := strings.NewReplacer(\".\", \"_\")\n\tviper.SetEnvKeyReplacer(replacer)\n\tviper.AutomaticEnv()\n}\n\nconst edition = \"oss\"\n\nconst transportErrorMode = \"transport\"\n\nfunc main() {\n\tvar configFile string\n\n\tvar rootCmd = &cobra.Command{\n\t\tUse:   \"\",\n\t\tShort: \"Centrifugo\",\n\t\tLong:  \"Centrifugo – scalable real-time messaging server in language-agnostic way\",\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\n\t\t\tbindPFlags := []string{\n\t\t\t\t\"engine\", \"log_level\", \"log_file\", \"pid_file\", \"debug\", \"name\", \"admin\",\n\t\t\t\t\"admin_external\", \"client_insecure\", \"admin_insecure\", \"api_insecure\", \"api_external\",\n\t\t\t\t\"port\", \"address\", \"tls\", \"tls_cert\", \"tls_key\", \"tls_external\", \"internal_port\",\n\t\t\t\t\"internal_address\", \"prometheus\", \"health\", \"redis_address\", \"tarantool_address\",\n\t\t\t\t\"broker\", \"nats_url\", \"grpc_api\", \"grpc_api_tls\", \"grpc_api_tls_disable\",\n\t\t\t\t\"grpc_api_tls_cert\", \"grpc_api_tls_key\", \"grpc_api_port\", \"sockjs\", \"uni_grpc\",\n\t\t\t\t\"uni_grpc_port\", \"uni_websocket\", \"uni_sse\", \"uni_http_stream\", \"sse\", \"http_stream\",\n\t\t\t\t\"swagger\",\n\t\t\t}\n\t\t\tfor _, flag := range bindPFlags {\n\t\t\t\t_ = viper.BindPFlag(flag, cmd.Flags().Lookup(flag))\n\t\t\t}\n\t\t\tviper.SetConfigFile(configFile)\n\n\t\t\tabsConfPath, err := filepath.Abs(configFile)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error retrieving config file absolute path: %v\", err)\n\t\t\t}\n\n\t\t\terr = viper.ReadInConfig()\n\t\t\tconfigFound := true\n\t\t\tif err != nil {\n\t\t\t\tvar configParseError viper.ConfigParseError\n\t\t\t\tswitch {\n\t\t\t\tcase errors.As(err, &configParseError):\n\t\t\t\t\tlog.Fatal().Msg(tools.ErrorMessageFromConfigError(err, absConfPath))\n\t\t\t\tdefault:\n\t\t\t\t\tconfigFound = false\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfile := setupLogging()\n\t\t\tif file != nil {\n\t\t\t\tdefer func() { _ = file.Close() }()\n\t\t\t}\n\n\t\t\terr = writePidFile(viper.GetString(\"pid_file\"))\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error writing PID: %v\", err)\n\t\t\t}\n\n\t\t\tif os.Getenv(\"GOMAXPROCS\") == \"\" {\n\t\t\t\tif viper.IsSet(\"gomaxprocs\") && viper.GetInt(\"gomaxprocs\") > 0 {\n\t\t\t\t\truntime.GOMAXPROCS(viper.GetInt(\"gomaxprocs\"))\n\t\t\t\t} else {\n\t\t\t\t\t_, _ = maxprocs.Set()\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tengineName := viper.GetString(\"engine\")\n\n\t\t\tlog.Info().\n\t\t\t\tStr(\"version\", build.Version).\n\t\t\t\tStr(\"runtime\", runtime.Version()).\n\t\t\t\tInt(\"pid\", os.Getpid()).\n\t\t\t\tStr(\"engine\", engineName).\n\t\t\t\tInt(\"gomaxprocs\", runtime.GOMAXPROCS(0)).Msg(\"starting Centrifugo\")\n\n\t\t\tlog.Info().Str(\"path\", absConfPath).Msg(\"using config file\")\n\n\t\t\truleConfig := ruleConfig()\n\t\t\terr = ruleConfig.Validate()\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error validating config: %v\", err)\n\t\t\t}\n\t\t\truleContainer, err := rule.NewContainer(ruleConfig)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating config: %v\", err)\n\t\t\t}\n\t\t\truleContainer.ChannelOptionsCacheTTL = 200 * time.Millisecond\n\n\t\t\tgranularProxyMode := viper.GetBool(\"granular_proxy_mode\")\n\t\t\tvar proxyMap *client.ProxyMap\n\t\t\tvar keepHeadersInContext bool\n\t\t\tif granularProxyMode {\n\t\t\t\tproxyMap, keepHeadersInContext = granularProxyMapConfig(ruleConfig)\n\t\t\t\tlog.Info().Msg(\"using granular proxy configuration\")\n\t\t\t} else {\n\t\t\t\tproxyMap, keepHeadersInContext = proxyMapConfig()\n\t\t\t}\n\n\t\t\tnodeCfg := nodeConfig(build.Version)\n\n\t\t\tnode, err := centrifuge.New(nodeCfg)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating Centrifuge Node: %v\", err)\n\t\t\t}\n\n\t\t\tif viper.GetBool(\"opentelemetry\") {\n\t\t\t\t_, err := telemetry.SetupTracing(context.Background())\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error setting up opentelemetry tracing: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbrokerName := viper.GetString(\"broker\")\n\t\t\tif brokerName != \"\" && brokerName != \"nats\" {\n\t\t\t\tlog.Fatal().Msgf(\"unknown broker: %s\", brokerName)\n\t\t\t}\n\n\t\t\tvar broker centrifuge.Broker\n\t\t\tvar presenceManager centrifuge.PresenceManager\n\n\t\t\tvar engineMode string\n\n\t\t\tif engineName == \"memory\" {\n\t\t\t\tbroker, presenceManager, engineMode, err = memoryEngine(node)\n\t\t\t} else if engineName == \"redis\" {\n\t\t\t\tbroker, presenceManager, engineMode, err = redisEngine(node)\n\t\t\t} else if engineName == \"tarantool\" {\n\t\t\t\tbroker, presenceManager, engineMode, err = tarantoolEngine(node)\n\t\t\t} else if engineName == \"redisnats\" {\n\t\t\t\tif !viper.GetBool(\"enable_unreleased_features\") {\n\t\t\t\t\tlog.Fatal().Msg(\"redisnats engine requires enable_unreleased_features on\")\n\t\t\t\t}\n\t\t\t\tlog.Warn().Msg(\"redisnats engine is not released, it may be changed or removed at any point\")\n\t\t\t\tvar natsBroker *natsbroker.NatsBroker\n\t\t\t\tvar redisBroker *centrifuge.RedisBroker\n\t\t\t\tredisBroker, presenceManager, engineMode, err = redisEngine(node)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating redis engine: %v\", err)\n\t\t\t\t}\n\t\t\t\tnatsBroker, err = initNatsBroker(node)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating nats broker: %v\", err)\n\t\t\t\t}\n\t\t\t\tbroker, err = redisnatsbroker.New(natsBroker, redisBroker)\n\t\t\t} else {\n\t\t\t\tlog.Fatal().Msgf(\"unknown engine: %s\", engineName)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating engine: %v\", err)\n\t\t\t}\n\t\t\tnode.SetBroker(broker)\n\t\t\tnode.SetPresenceManager(presenceManager)\n\n\t\t\tif !configFound {\n\t\t\t\tlog.Warn().Msg(\"config file not found\")\n\t\t\t}\n\n\t\t\tvar disableHistoryPresence bool\n\t\t\tif engineName == \"memory\" && brokerName == \"nats\" {\n\t\t\t\t// Presence and History won't work with Memory engine in distributed case.\n\t\t\t\tdisableHistoryPresence = true\n\t\t\t\tnode.SetPresenceManager(nil)\n\t\t\t}\n\n\t\t\tif disableHistoryPresence {\n\t\t\t\tlog.Warn().Msgf(\"presence, history and recovery disabled with Memory engine and Nats broker\")\n\t\t\t}\n\n\t\t\tif brokerName == \"nats\" {\n\t\t\t\tbroker, err = initNatsBroker(node)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating broker: %v\", err)\n\t\t\t\t}\n\t\t\t\tnode.SetBroker(broker)\n\t\t\t}\n\n\t\t\tverifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating JWT verifier config: %v\", err)\n\t\t\t}\n\n\t\t\ttokenVerifier, err := jwtverify.NewTokenVerifierJWT(verifierConfig, ruleContainer)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating token verifier: %v\", err)\n\t\t\t}\n\n\t\t\tvar subTokenVerifier *jwtverify.VerifierJWT\n\t\t\tif viper.GetBool(\"separate_subscription_token_config\") {\n\t\t\t\tlog.Info().Msg(\"initializing separate verifier for subscription tokens\")\n\t\t\t\tvar err error\n\n\t\t\t\tsubVerifier, err := subJWTVerifierConfig()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating subscription JWT verifier config: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tsubTokenVerifier, err = jwtverify.NewTokenVerifierJWT(subVerifier, ruleContainer)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating token verifier: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tclientHandler := client.NewHandler(node, ruleContainer, tokenVerifier, subTokenVerifier, proxyMap, granularProxyMode)\n\t\t\terr = clientHandler.Setup()\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error setting up client handler: %v\", err)\n\t\t\t}\n\t\t\tif viper.GetBool(\"rpc_ping\") {\n\t\t\t\tpingMethod := viper.GetString(\"rpc_ping_method\")\n\t\t\t\tlog.Info().Str(\"method\", pingMethod).Msg(\"RPC ping extension enabled\")\n\t\t\t\tclientHandler.SetRPCExtension(pingMethod, func(c client.Client, e centrifuge.RPCEvent) (centrifuge.RPCReply, error) {\n\t\t\t\t\treturn centrifuge.RPCReply{}, nil\n\t\t\t\t})\n\t\t\t}\n\n\t\t\tsurveyCaller := survey.NewCaller(node)\n\n\t\t\tuseAPIOpentelemetry := viper.GetBool(\"opentelemetry\") && viper.GetBool(\"opentelemetry_api\")\n\t\t\tuseConsumingOpentelemetry := viper.GetBool(\"opentelemetry\") && viper.GetBool(\"opentelemetry_consuming\")\n\n\t\t\thttpAPIExecutor := api.NewExecutor(node, ruleContainer, surveyCaller, api.ExecutorConfig{\n\t\t\t\tProtocol:         \"http\",\n\t\t\t\tUseOpenTelemetry: useAPIOpentelemetry,\n\t\t\t})\n\t\t\tgrpcAPIExecutor := api.NewExecutor(node, ruleContainer, surveyCaller, api.ExecutorConfig{\n\t\t\t\tProtocol:         \"grpc\",\n\t\t\t\tUseOpenTelemetry: useAPIOpentelemetry,\n\t\t\t})\n\t\t\tconsumingAPIExecutor := api.NewExecutor(node, ruleContainer, surveyCaller, api.ExecutorConfig{\n\t\t\t\tProtocol:         \"consuming\",\n\t\t\t\tUseOpenTelemetry: useConsumingOpentelemetry,\n\t\t\t})\n\n\t\t\tvar services []service.Service\n\n\t\t\tconsumingHandler := api.NewConsumingHandler(node, consumingAPIExecutor, api.ConsumingHandlerConfig{\n\t\t\t\tUseOpenTelemetry: useConsumingOpentelemetry,\n\t\t\t})\n\n\t\t\tconsumers := consumersFromConfig(viper.GetViper())\n\t\t\tconsumingServices, err := consuming.New(node.ID(), node, consumingHandler, consumers)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error initializing consumers: %v\", err)\n\t\t\t}\n\n\t\t\tservices = append(services, consumingServices...)\n\n\t\t\tif err = node.Run(); err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error running node: %v\", err)\n\t\t\t}\n\n\t\t\tif viper.GetBool(\"client_insecure\") {\n\t\t\t\tlog.Warn().Msg(\"INSECURE client mode enabled, make sure you understand risks\")\n\t\t\t}\n\t\t\tif viper.GetBool(\"api_insecure\") {\n\t\t\t\tlog.Warn().Msg(\"INSECURE API mode enabled, make sure you understand risks\")\n\t\t\t}\n\t\t\tif viper.GetBool(\"admin_insecure\") {\n\t\t\t\tlog.Warn().Msg(\"INSECURE admin mode enabled, make sure you understand risks\")\n\t\t\t}\n\t\t\tif viper.GetBool(\"debug\") {\n\t\t\t\tlog.Warn().Msg(\"DEBUG mode enabled, see /debug/pprof\")\n\t\t\t}\n\n\t\t\tvar grpcAPIServer *grpc.Server\n\t\t\tvar grpcAPIAddr string\n\t\t\tif viper.GetBool(\"grpc_api\") {\n\t\t\t\tgrpcAPIAddr = net.JoinHostPort(viper.GetString(\"grpc_api_address\"), viper.GetString(\"grpc_api_port\"))\n\t\t\t\tgrpcAPIConn, err := net.Listen(\"tcp\", grpcAPIAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"cannot listen to address %s\", grpcAPIAddr)\n\t\t\t\t}\n\t\t\t\tvar grpcOpts []grpc.ServerOption\n\t\t\t\tvar tlsConfig *tls.Config\n\t\t\t\tvar tlsErr error\n\n\t\t\t\tif viper.GetString(\"grpc_api_key\") != \"\" {\n\t\t\t\t\tgrpcOpts = append(grpcOpts, api.GRPCKeyAuth(viper.GetString(\"grpc_api_key\")))\n\t\t\t\t}\n\t\t\t\tif viper.GetInt(\"grpc_api_max_receive_message_size\") > 0 {\n\t\t\t\t\tgrpcOpts = append(grpcOpts, grpc.MaxRecvMsgSize(viper.GetInt(\"grpc_api_max_receive_message_size\")))\n\t\t\t\t}\n\t\t\t\tif viper.GetBool(\"grpc_api_tls\") {\n\t\t\t\t\ttlsConfig, tlsErr = tlsConfigForGRPC()\n\t\t\t\t} else if !viper.GetBool(\"grpc_api_tls_disable\") {\n\t\t\t\t\ttlsConfig, tlsErr = getTLSConfig()\n\t\t\t\t}\n\t\t\t\tif tlsErr != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error getting TLS config: %v\", tlsErr)\n\t\t\t\t}\n\t\t\t\tif tlsConfig != nil {\n\t\t\t\t\tgrpcOpts = append(grpcOpts, grpc.Creds(credentials.NewTLS(tlsConfig)))\n\t\t\t\t}\n\t\t\t\tif useAPIOpentelemetry {\n\t\t\t\t\tgrpcOpts = append(grpcOpts, grpc.StatsHandler(otelgrpc.NewServerHandler()))\n\t\t\t\t}\n\t\t\t\tgrpcErrorMode, err := tools.OptionalStringChoice(viper.GetViper(), \"grpc_api_error_mode\", []string{transportErrorMode})\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error in config: %v\", err)\n\t\t\t\t}\n\t\t\t\tgrpcAPIServer = grpc.NewServer(grpcOpts...)\n\t\t\t\t_ = api.RegisterGRPCServerAPI(node, grpcAPIExecutor, grpcAPIServer, api.GRPCAPIServiceConfig{\n\t\t\t\t\tUseOpenTelemetry:      useAPIOpentelemetry,\n\t\t\t\t\tUseTransportErrorMode: grpcErrorMode == transportErrorMode,\n\t\t\t\t})\n\t\t\t\tif viper.GetBool(\"grpc_api_reflection\") {\n\t\t\t\t\treflection.Register(grpcAPIServer)\n\t\t\t\t}\n\t\t\t\tgo func() {\n\t\t\t\t\tif err := grpcAPIServer.Serve(grpcAPIConn); err != nil {\n\t\t\t\t\t\tlog.Fatal().Msgf(\"serve GRPC API: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tif grpcAPIServer != nil {\n\t\t\t\tlog.Info().Msgf(\"serving GRPC API service on %s\", grpcAPIAddr)\n\t\t\t}\n\n\t\t\tvar grpcUniServer *grpc.Server\n\t\t\tvar grpcUniAddr string\n\t\t\tif viper.GetBool(\"uni_grpc\") {\n\t\t\t\tgrpcUniAddr = net.JoinHostPort(viper.GetString(\"uni_grpc_address\"), viper.GetString(\"uni_grpc_port\"))\n\t\t\t\tgrpcUniConn, err := net.Listen(\"tcp\", grpcUniAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"cannot listen to address %s\", grpcUniAddr)\n\t\t\t\t}\n\t\t\t\tvar grpcOpts []grpc.ServerOption\n\t\t\t\t//nolint:staticcheck\n\t\t\t\t//goland:noinspection GoDeprecation\n\t\t\t\tgrpcOpts = append(grpcOpts, grpc.CustomCodec(&unigrpc.RawCodec{}), grpc.MaxRecvMsgSize(viper.GetInt(\"uni_grpc_max_receive_message_size\")))\n\t\t\t\tvar tlsConfig *tls.Config\n\t\t\t\tvar tlsErr error\n\n\t\t\t\tif viper.GetBool(\"uni_grpc_tls\") {\n\t\t\t\t\ttlsConfig, tlsErr = tlsConfigForUniGRPC()\n\t\t\t\t} else if !viper.GetBool(\"uni_grpc_tls_disable\") {\n\t\t\t\t\ttlsConfig, tlsErr = getTLSConfig()\n\t\t\t\t}\n\t\t\t\tif tlsErr != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error getting TLS config: %v\", tlsErr)\n\t\t\t\t}\n\t\t\t\tif tlsConfig != nil {\n\t\t\t\t\tgrpcOpts = append(grpcOpts, grpc.Creds(credentials.NewTLS(tlsConfig)))\n\t\t\t\t}\n\t\t\t\tkeepAliveEnforcementPolicy := keepalive.EnforcementPolicy{\n\t\t\t\t\tMinTime: 5 * time.Second,\n\t\t\t\t}\n\t\t\t\tkeepAliveServerParams := keepalive.ServerParameters{\n\t\t\t\t\tTime:    25 * time.Second,\n\t\t\t\t\tTimeout: 5 * time.Second,\n\t\t\t\t}\n\t\t\t\tgrpcOpts = append(grpcOpts, grpc.KeepaliveEnforcementPolicy(keepAliveEnforcementPolicy))\n\t\t\t\tgrpcOpts = append(grpcOpts, grpc.KeepaliveParams(keepAliveServerParams))\n\t\t\t\tgrpcUniServer = grpc.NewServer(grpcOpts...)\n\t\t\t\t_ = unigrpc.RegisterService(grpcUniServer, unigrpc.NewService(node, uniGRPCHandlerConfig()))\n\t\t\t\tgo func() {\n\t\t\t\t\tif err := grpcUniServer.Serve(grpcUniConn); err != nil {\n\t\t\t\t\t\tlog.Fatal().Msgf(\"serve uni GRPC: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tif grpcUniServer != nil {\n\t\t\t\tlog.Info().Msgf(\"serving unidirectional GRPC on %s\", grpcUniAddr)\n\t\t\t}\n\n\t\t\thttpServers, err := runHTTPServers(node, ruleContainer, httpAPIExecutor, keepHeadersInContext)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error running HTTP server: %v\", err)\n\t\t\t}\n\n\t\t\tvar exporter *graphite.Exporter\n\t\t\tif viper.GetBool(\"graphite\") {\n\t\t\t\texporter = graphite.New(graphite.Config{\n\t\t\t\t\tAddress:  net.JoinHostPort(viper.GetString(\"graphite_host\"), strconv.Itoa(viper.GetInt(\"graphite_port\"))),\n\t\t\t\t\tGatherer: prometheus.DefaultGatherer,\n\t\t\t\t\tPrefix:   strings.TrimSuffix(viper.GetString(\"graphite_prefix\"), \".\") + \".\" + graphite.PreparePathComponent(nodeCfg.Name),\n\t\t\t\t\tInterval: GetDuration(\"graphite_interval\"),\n\t\t\t\t\tTags:     viper.GetBool(\"graphite_tags\"),\n\t\t\t\t})\n\t\t\t\tservices = append(services, exporter)\n\t\t\t}\n\n\t\t\tvar statsSender *usage.Sender\n\t\t\tif !viper.GetBool(\"usage_stats_disable\") {\n\t\t\t\tstatsSender = usage.NewSender(node, ruleContainer, usage.Features{\n\t\t\t\t\tEdition:    edition,\n\t\t\t\t\tVersion:    build.Version,\n\t\t\t\t\tEngine:     engineName,\n\t\t\t\t\tEngineMode: engineMode,\n\t\t\t\t\tBroker:     brokerName,\n\t\t\t\t\tBrokerMode: \"\",\n\n\t\t\t\t\tWebsocket:     !viper.GetBool(\"websocket_disable\"),\n\t\t\t\t\tHTTPStream:    viper.GetBool(\"http_stream\"),\n\t\t\t\t\tSSE:           viper.GetBool(\"sse\"),\n\t\t\t\t\tSockJS:        viper.GetBool(\"sockjs\"),\n\t\t\t\t\tUniWebsocket:  viper.GetBool(\"uni_websocket\"),\n\t\t\t\t\tUniHTTPStream: viper.GetBool(\"uni_http_stream\"),\n\t\t\t\t\tUniSSE:        viper.GetBool(\"uni_sse\"),\n\t\t\t\t\tUniGRPC:       viper.GetBool(\"uni_grpc\"),\n\n\t\t\t\t\tEnabledConsumers: usage.GetEnabledConsumers(consumers),\n\n\t\t\t\t\tGrpcAPI:             viper.GetBool(\"grpc_api\"),\n\t\t\t\t\tSubscribeToPersonal: viper.GetBool(\"user_subscribe_to_personal\"),\n\t\t\t\t\tAdmin:               viper.GetBool(\"admin\"),\n\n\t\t\t\t\tConnectProxy:         proxyMap.ConnectProxy != nil,\n\t\t\t\t\tRefreshProxy:         proxyMap.RefreshProxy != nil,\n\t\t\t\t\tSubscribeProxy:       len(proxyMap.SubscribeProxies) > 0,\n\t\t\t\t\tPublishProxy:         len(proxyMap.PublishProxies) > 0,\n\t\t\t\t\tRPCProxy:             len(proxyMap.RpcProxies) > 0,\n\t\t\t\t\tSubRefreshProxy:      len(proxyMap.SubRefreshProxies) > 0,\n\t\t\t\t\tSubscribeStreamProxy: len(proxyMap.SubscribeStreamProxies) > 0,\n\n\t\t\t\t\tClickhouseAnalytics: false,\n\t\t\t\t\tUserStatus:          false,\n\t\t\t\t\tThrottling:          false,\n\t\t\t\t\tSingleflight:        false,\n\t\t\t\t})\n\t\t\t\tservices = append(services, statsSender)\n\t\t\t}\n\n\t\t\tnotify.RegisterHandlers(node, statsSender)\n\n\t\t\ttools.CheckPlainConfigKeys(defaults, viper.AllKeys())\n\n\t\t\tvar serviceGroup *errgroup.Group\n\t\t\tserviceCancel := func() {}\n\t\t\tif len(services) > 0 {\n\t\t\t\tvar serviceCtx context.Context\n\t\t\t\tserviceCtx, serviceCancel = context.WithCancel(context.Background())\n\t\t\t\tserviceGroup, serviceCtx = errgroup.WithContext(serviceCtx)\n\t\t\t\tfor _, s := range services {\n\t\t\t\t\ts := s\n\t\t\t\t\tserviceGroup.Go(func() error {\n\t\t\t\t\t\treturn s.Run(serviceCtx)\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\n\t\t\thandleSignals(\n\t\t\t\tconfigFile, node, ruleContainer, tokenVerifier, subTokenVerifier,\n\t\t\t\thttpServers, grpcAPIServer, grpcUniServer,\n\t\t\t\tserviceGroup, serviceCancel,\n\t\t\t)\n\t\t},\n\t}\n\n\trootCmd.Flags().StringVarP(&configFile, \"config\", \"c\", \"config.json\", \"path to config file\")\n\trootCmd.Flags().StringP(\"engine\", \"e\", \"memory\", \"engine to use: memory or redis\")\n\trootCmd.Flags().StringP(\"broker\", \"\", \"\", \"custom broker to use: ex. nats\")\n\trootCmd.Flags().StringP(\"log_level\", \"\", \"info\", \"set the log level: trace, debug, info, error, fatal or none\")\n\trootCmd.Flags().StringP(\"log_file\", \"\", \"\", \"optional log file - if not specified logs go to STDOUT\")\n\trootCmd.Flags().StringP(\"pid_file\", \"\", \"\", \"optional path to create PID file\")\n\trootCmd.Flags().StringP(\"name\", \"n\", \"\", \"unique node name\")\n\n\trootCmd.Flags().BoolP(\"debug\", \"\", false, \"enable debug endpoints\")\n\trootCmd.Flags().BoolP(\"admin\", \"\", false, \"enable admin web interface\")\n\trootCmd.Flags().BoolP(\"admin_external\", \"\", false, \"expose admin web interface on external port\")\n\trootCmd.Flags().BoolP(\"prometheus\", \"\", false, \"enable Prometheus metrics endpoint\")\n\trootCmd.Flags().BoolP(\"swagger\", \"\", false, \"enable Swagger UI endpoint describing server HTTP API\")\n\trootCmd.Flags().BoolP(\"health\", \"\", false, \"enable health check endpoint\")\n\trootCmd.Flags().BoolP(\"sockjs\", \"\", false, \"enable SockJS endpoint\")\n\trootCmd.Flags().BoolP(\"uni_websocket\", \"\", false, \"enable unidirectional websocket endpoint\")\n\trootCmd.Flags().BoolP(\"uni_sse\", \"\", false, \"enable unidirectional SSE (EventSource) endpoint\")\n\trootCmd.Flags().BoolP(\"uni_http_stream\", \"\", false, \"enable unidirectional HTTP-streaming endpoint\")\n\trootCmd.Flags().BoolP(\"sse\", \"\", false, \"enable bidirectional SSE (EventSource) endpoint (with emulation layer)\")\n\trootCmd.Flags().BoolP(\"http_stream\", \"\", false, \"enable bidirectional HTTP-streaming endpoint (with emulation layer)\")\n\n\trootCmd.Flags().BoolP(\"client_insecure\", \"\", false, \"start in insecure client mode\")\n\trootCmd.Flags().BoolP(\"api_insecure\", \"\", false, \"use insecure API mode\")\n\trootCmd.Flags().BoolP(\"api_external\", \"\", false, \"expose API handler on external port\")\n\trootCmd.Flags().BoolP(\"admin_insecure\", \"\", false, \"use insecure admin mode – no auth required for admin socket\")\n\n\trootCmd.Flags().StringP(\"address\", \"a\", \"\", \"interface address to listen on\")\n\trootCmd.Flags().StringP(\"port\", \"p\", \"8000\", \"port to bind HTTP server to\")\n\trootCmd.Flags().StringP(\"internal_address\", \"\", \"\", \"custom interface address to listen on for internal endpoints\")\n\trootCmd.Flags().StringP(\"internal_port\", \"\", \"\", \"custom port for internal endpoints\")\n\n\trootCmd.Flags().BoolP(\"tls\", \"\", false, \"enable TLS, requires an X509 certificate and a key file\")\n\trootCmd.Flags().StringP(\"tls_cert\", \"\", \"\", \"path to an X509 certificate file\")\n\trootCmd.Flags().StringP(\"tls_key\", \"\", \"\", \"path to an X509 certificate key\")\n\trootCmd.Flags().BoolP(\"tls_external\", \"\", false, \"enable TLS only for external endpoints\")\n\n\trootCmd.Flags().BoolP(\"grpc_api\", \"\", false, \"enable GRPC API server\")\n\trootCmd.Flags().IntP(\"grpc_api_port\", \"\", 10000, \"port to bind GRPC API server to\")\n\trootCmd.Flags().BoolP(\"grpc_api_tls\", \"\", false, \"enable TLS for GRPC API server, requires an X509 certificate and a key file\")\n\trootCmd.Flags().StringP(\"grpc_api_tls_cert\", \"\", \"\", \"path to an X509 certificate file for GRPC API server\")\n\trootCmd.Flags().StringP(\"grpc_api_tls_key\", \"\", \"\", \"path to an X509 certificate key for GRPC API server\")\n\trootCmd.Flags().BoolP(\"grpc_api_tls_disable\", \"\", false, \"disable general TLS for GRPC API server\")\n\n\trootCmd.Flags().BoolP(\"uni_grpc\", \"\", false, \"enable unidirectional GRPC endpoint\")\n\trootCmd.Flags().IntP(\"uni_grpc_port\", \"\", 11000, \"port to bind unidirectional GRPC server to\")\n\n\trootCmd.Flags().StringP(\"redis_address\", \"\", \"redis://127.0.0.1:6379\", \"Redis connection address (Redis engine)\")\n\trootCmd.Flags().StringP(\"tarantool_address\", \"\", \"tcp://127.0.0.1:3301\", \"Tarantool connection address (Tarantool engine)\")\n\trootCmd.Flags().StringP(\"nats_url\", \"\", \"nats://127.0.0.1:4222\", \"Nats connection URL in format nats://user:pass@localhost:4222 (Nats broker)\")\n\n\tvar versionCmd = &cobra.Command{\n\t\tUse:   \"version\",\n\t\tShort: \"Centrifugo version information\",\n\t\tLong:  `Print the version information of Centrifugo`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tfmt.Printf(\"Centrifugo v%s (Go version: %s)\\n\", build.Version, runtime.Version())\n\t\t},\n\t}\n\n\tvar checkConfigFile string\n\n\tvar checkConfigCmd = &cobra.Command{\n\t\tUse:   \"checkconfig\",\n\t\tShort: \"Check configuration file\",\n\t\tLong:  `Check Centrifugo configuration file`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\t\t\terr := validateConfig(checkConfigFile)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"%s\\n\", tools.ErrorMessageFromConfigError(err, checkConfigFile))\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t},\n\t}\n\tcheckConfigCmd.Flags().StringVarP(&checkConfigFile, \"config\", \"c\", \"config.json\", \"path to config file to check\")\n\n\tvar outputConfigFile string\n\n\tvar genConfigCmd = &cobra.Command{\n\t\tUse:   \"genconfig\",\n\t\tShort: \"Generate minimal configuration file to start with\",\n\t\tLong:  `Generate minimal configuration file to start with`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\terr := tools.GenerateConfig(outputConfigFile)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tbindCentrifugoConfig()\n\t\t\terr = validateConfig(outputConfigFile)\n\t\t\tif err != nil {\n\t\t\t\t_ = os.Remove(outputConfigFile)\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t},\n\t}\n\tgenConfigCmd.Flags().StringVarP(&outputConfigFile, \"config\", \"c\", \"config.json\", \"path to output config file\")\n\n\tvar genTokenConfigFile string\n\tvar genTokenUser string\n\tvar genTokenTTL int64\n\tvar genTokenQuiet bool\n\n\tvar genTokenCmd = &cobra.Command{\n\t\tUse:   \"gentoken\",\n\t\tShort: \"Generate sample connection JWT for user\",\n\t\tLong:  `Generate sample connection JWT for user`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\t\t\terr := readConfig(genTokenConfigFile)\n\t\t\tif err != nil && !errors.Is(err, errConfigFileNotFound) {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tjwtVerifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\ttoken, err := cli.GenerateToken(jwtVerifierConfig, genTokenUser, genTokenTTL)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tvar user = fmt.Sprintf(\"user \\\"%s\\\"\", genTokenUser)\n\t\t\tif genTokenUser == \"\" {\n\t\t\t\tuser = \"anonymous user\"\n\t\t\t}\n\t\t\texp := \"without expiration\"\n\t\t\tif genTokenTTL >= 0 {\n\t\t\t\texp = fmt.Sprintf(\"with expiration TTL %s\", time.Duration(genTokenTTL)*time.Second)\n\t\t\t}\n\t\t\tif genTokenQuiet {\n\t\t\t\tfmt.Print(token)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tfmt.Printf(\"HMAC SHA-256 JWT for %s %s:\\n%s\\n\", user, exp, token)\n\t\t},\n\t}\n\tgenTokenCmd.Flags().StringVarP(&genTokenConfigFile, \"config\", \"c\", \"config.json\", \"path to config file\")\n\tgenTokenCmd.Flags().StringVarP(&genTokenUser, \"user\", \"u\", \"\", \"user ID, by default anonymous\")\n\tgenTokenCmd.Flags().Int64VarP(&genTokenTTL, \"ttl\", \"t\", 3600*24*7, \"token TTL in seconds, use -1 for token without expiration\")\n\tgenTokenCmd.Flags().BoolVarP(&genTokenQuiet, \"quiet\", \"q\", false, \"only output the token without anything else\")\n\n\tvar genSubTokenConfigFile string\n\tvar genSubTokenUser string\n\tvar genSubTokenChannel string\n\tvar genSubTokenTTL int64\n\tvar genSubTokenQuiet bool\n\n\tvar genSubTokenCmd = &cobra.Command{\n\t\tUse:   \"gensubtoken\",\n\t\tShort: \"Generate sample subscription JWT for user\",\n\t\tLong:  `Generate sample subscription JWT for user`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\t\t\terr := readConfig(genSubTokenConfigFile)\n\t\t\tif err != nil && !errors.Is(err, errConfigFileNotFound) {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif genSubTokenChannel == \"\" {\n\t\t\t\tfmt.Println(\"channel is required\")\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tverifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif viper.GetBool(\"separate_subscription_token_config\") {\n\t\t\t\tverifierConfig, err = subJWTVerifierConfig()\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t\ttoken, err := cli.GenerateSubToken(verifierConfig, genSubTokenUser, genSubTokenChannel, genSubTokenTTL)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tvar user = fmt.Sprintf(\"user \\\"%s\\\"\", genSubTokenUser)\n\t\t\tif genSubTokenUser == \"\" {\n\t\t\t\tuser = \"anonymous user\"\n\t\t\t}\n\t\t\texp := \"without expiration\"\n\t\t\tif genSubTokenTTL >= 0 {\n\t\t\t\texp = fmt.Sprintf(\"with expiration TTL %s\", time.Duration(genSubTokenTTL)*time.Second)\n\t\t\t}\n\t\t\tif genSubTokenQuiet {\n\t\t\t\tfmt.Print(token)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tfmt.Printf(\"HMAC SHA-256 JWT for %s and channel \\\"%s\\\" %s:\\n%s\\n\", user, genSubTokenChannel, exp, token)\n\t\t},\n\t}\n\tgenSubTokenCmd.Flags().StringVarP(&genSubTokenConfigFile, \"config\", \"c\", \"config.json\", \"path to config file\")\n\tgenSubTokenCmd.Flags().StringVarP(&genSubTokenUser, \"user\", \"u\", \"\", \"user ID\")\n\tgenSubTokenCmd.Flags().StringVarP(&genSubTokenChannel, \"channel\", \"s\", \"\", \"channel\")\n\tgenSubTokenCmd.Flags().Int64VarP(&genSubTokenTTL, \"ttl\", \"t\", 3600*24*7, \"token TTL in seconds, use -1 for token without expiration\")\n\tgenSubTokenCmd.Flags().BoolVarP(&genSubTokenQuiet, \"quiet\", \"q\", false, \"only output the token without anything else\")\n\n\tvar checkTokenConfigFile string\n\n\tvar checkTokenCmd = &cobra.Command{\n\t\tUse:   \"checktoken [TOKEN]\",\n\t\tShort: \"Check connection JWT\",\n\t\tLong:  `Check connection JWT`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\t\t\terr := readConfig(checkTokenConfigFile)\n\t\t\tif err != nil && !errors.Is(err, errConfigFileNotFound) {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tverifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif len(args) != 1 {\n\t\t\t\tfmt.Printf(\"error: provide token to check [centrifugo checktoken <TOKEN>]\\n\")\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tsubject, claims, err := cli.CheckToken(verifierConfig, ruleConfig(), args[0])\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tvar user = fmt.Sprintf(\"user %s\", subject)\n\t\t\tif subject == \"\" {\n\t\t\t\tuser = \"anonymous user\"\n\t\t\t}\n\t\t\tfmt.Printf(\"valid token for %s\\npayload: %s\\n\", user, string(claims))\n\t\t},\n\t}\n\tcheckTokenCmd.Flags().StringVarP(&checkTokenConfigFile, \"config\", \"c\", \"config.json\", \"path to config file\")\n\n\tvar checkSubTokenConfigFile string\n\n\tvar checkSubTokenCmd = &cobra.Command{\n\t\tUse:   \"checksubtoken [TOKEN]\",\n\t\tShort: \"Check subscription JWT\",\n\t\tLong:  `Check subscription JWT`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tbindCentrifugoConfig()\n\t\t\terr := readConfig(checkSubTokenConfigFile)\n\t\t\tif err != nil && !errors.Is(err, errConfigFileNotFound) {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tverifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif viper.GetBool(\"separate_subscription_token_config\") {\n\t\t\t\tverifierConfig, err = subJWTVerifierConfig()\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(args) != 1 {\n\t\t\t\tfmt.Printf(\"error: provide token to check [centrifugo checksubtoken <TOKEN>]\\n\")\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tsubject, channel, claims, err := cli.CheckSubToken(verifierConfig, ruleConfig(), args[0])\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"error: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tvar user = fmt.Sprintf(\"user \\\"%s\\\"\", subject)\n\t\t\tif subject == \"\" {\n\t\t\t\tuser = \"anonymous user\"\n\t\t\t}\n\t\t\tfmt.Printf(\"valid subscription token for %s and channel \\\"%s\\\"\\npayload: %s\\n\", user, channel, string(claims))\n\t\t},\n\t}\n\tcheckSubTokenCmd.Flags().StringVarP(&checkSubTokenConfigFile, \"config\", \"c\", \"config.json\", \"path to config file\")\n\n\tvar serveDir string\n\tvar servePort int\n\tvar serveAddr string\n\n\tvar serveCmd = &cobra.Command{\n\t\tUse:   \"serve\",\n\t\tShort: \"Run static file server (for development only)\",\n\t\tLong:  `Run static file server (for development only)`,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\taddress := net.JoinHostPort(serveAddr, strconv.Itoa(servePort))\n\t\t\tfmt.Printf(\"start serving %s on %s\\n\", serveDir, address)\n\t\t\tif err := http.ListenAndServe(address, http.FileServer(http.Dir(serveDir))); err != nil {\n\t\t\t\tfmt.Println(err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t},\n\t}\n\tserveCmd.Flags().StringVarP(&serveDir, \"dir\", \"d\", \"./\", \"path to directory\")\n\tserveCmd.Flags().IntVarP(&servePort, \"port\", \"p\", 3000, \"port to serve on\")\n\tserveCmd.Flags().StringVarP(&serveAddr, \"address\", \"a\", \"\", \"interface to serve on (default: all interfaces)\")\n\n\trootCmd.AddCommand(serveCmd)\n\trootCmd.AddCommand(versionCmd)\n\trootCmd.AddCommand(checkConfigCmd)\n\trootCmd.AddCommand(genConfigCmd)\n\trootCmd.AddCommand(genTokenCmd)\n\trootCmd.AddCommand(genSubTokenCmd)\n\trootCmd.AddCommand(checkTokenCmd)\n\trootCmd.AddCommand(checkSubTokenCmd)\n\t_ = rootCmd.Execute()\n}\n\nfunc writePidFile(pidFile string) error {\n\tif pidFile == \"\" {\n\t\treturn nil\n\t}\n\tpid := []byte(strconv.Itoa(os.Getpid()) + \"\\n\")\n\treturn os.WriteFile(pidFile, pid, 0644)\n}\n\nvar logLevelMatches = map[string]zerolog.Level{\n\t\"NONE\":  zerolog.NoLevel,\n\t\"TRACE\": zerolog.TraceLevel,\n\t\"DEBUG\": zerolog.DebugLevel,\n\t\"INFO\":  zerolog.InfoLevel,\n\t\"WARN\":  zerolog.WarnLevel,\n\t\"ERROR\": zerolog.ErrorLevel,\n\t\"FATAL\": zerolog.FatalLevel,\n}\n\nfunc configureConsoleWriter() {\n\tif isTerminalAttached() {\n\t\tlog.Logger = log.Output(zerolog.ConsoleWriter{\n\t\t\tOut:                 os.Stdout,\n\t\t\tTimeFormat:          \"2006-01-02 15:04:05\",\n\t\t\tFormatLevel:         logutils.ConsoleFormatLevel(),\n\t\t\tFormatErrFieldName:  logutils.ConsoleFormatErrFieldName(),\n\t\t\tFormatErrFieldValue: logutils.ConsoleFormatErrFieldValue(),\n\t\t})\n\t}\n}\n\nfunc isTerminalAttached() bool {\n\t//goland:noinspection GoBoolExpressions – Goland is not smart enough here.\n\treturn isatty.IsTerminal(os.Stdout.Fd()) && runtime.GOOS != \"windows\"\n}\n\nfunc setupLogging() *os.File {\n\tconfigureConsoleWriter()\n\n\tzerolog.SetGlobalLevel(zerolog.InfoLevel)\n\tlogLevel, ok := logLevelMatches[strings.ToUpper(viper.GetString(\"log_level\"))]\n\tif !ok {\n\t\tlogLevel = zerolog.InfoLevel\n\t}\n\tzerolog.SetGlobalLevel(logLevel)\n\n\tif viper.IsSet(\"log_file\") && viper.GetString(\"log_file\") != \"\" {\n\t\tf, err := os.OpenFile(viper.GetString(\"log_file\"), os.O_RDWR|os.O_CREATE|os.O_APPEND, 0644)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error opening log file: %v\", err)\n\t\t}\n\t\tlog.Logger = log.Output(f)\n\t\treturn f\n\t}\n\n\treturn nil\n}\n\nfunc handleSignals(\n\tconfigFile string, n *centrifuge.Node, ruleContainer *rule.Container, tokenVerifier *jwtverify.VerifierJWT,\n\tsubTokenVerifier *jwtverify.VerifierJWT, httpServers []*http.Server, grpcAPIServer *grpc.Server, grpcUniServer *grpc.Server,\n\tserviceGroup *errgroup.Group, serviceCancel context.CancelFunc,\n) {\n\tsigCh := make(chan os.Signal, 1)\n\tsignal.Notify(sigCh, syscall.SIGHUP, syscall.SIGINT, os.Interrupt, syscall.SIGTERM)\n\tfor {\n\t\tsig := <-sigCh\n\t\tlog.Info().Msgf(\"signal received: %v\", sig)\n\t\tswitch sig {\n\t\tcase syscall.SIGHUP:\n\t\t\t// Reload application configuration on SIGHUP.\n\t\t\t// Note that Centrifugo can't reload config for everything – just best effort to reload what's possible.\n\t\t\t// We can now reload channel options and token verifiers.\n\t\t\tlog.Info().Msg(\"reloading configuration\")\n\t\t\terr := validateConfig(configFile)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error().Msg(tools.ErrorMessageFromConfigError(err, configFile))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\truleConfig := ruleConfig()\n\n\t\t\tverifierConfig, err := jwtVerifierConfig()\n\t\t\tif err != nil {\n\t\t\t\tlog.Error().Msgf(\"error reloading: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err := tokenVerifier.Reload(verifierConfig); err != nil {\n\t\t\t\tlog.Error().Msgf(\"error reloading: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif subTokenVerifier != nil {\n\t\t\t\tsubVerifierConfig, err := subJWTVerifierConfig()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Error().Msgf(\"error reloading: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif err := subTokenVerifier.Reload(subVerifierConfig); err != nil {\n\t\t\t\t\tlog.Error().Msgf(\"error reloading: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tif err := ruleContainer.Reload(ruleConfig); err != nil {\n\t\t\t\tlog.Error().Msgf(\"error reloading: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tlog.Info().Msg(\"configuration successfully reloaded\")\n\t\tcase syscall.SIGINT, os.Interrupt, syscall.SIGTERM:\n\t\t\tlog.Info().Msg(\"shutting down ...\")\n\t\t\tpidFile := viper.GetString(\"pid_file\")\n\t\t\tshutdownTimeout := GetDuration(\"shutdown_timeout\")\n\t\t\tgo time.AfterFunc(shutdownTimeout, func() {\n\t\t\t\tif pidFile != \"\" {\n\t\t\t\t\t_ = os.Remove(pidFile)\n\t\t\t\t}\n\t\t\t\tos.Exit(1)\n\t\t\t})\n\n\t\t\tvar wg sync.WaitGroup\n\n\t\t\tif serviceGroup != nil {\n\t\t\t\tserviceCancel()\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func() {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\t_ = serviceGroup.Wait()\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tif grpcAPIServer != nil {\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func() {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\tgrpcAPIServer.GracefulStop()\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tif grpcUniServer != nil {\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func() {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\tgrpcUniServer.GracefulStop()\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), shutdownTimeout)\n\n\t\t\tfor _, srv := range httpServers {\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(srv *http.Server) {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\t_ = srv.Shutdown(ctx)\n\t\t\t\t}(srv)\n\t\t\t}\n\n\t\t\t_ = n.Shutdown(ctx)\n\n\t\t\twg.Wait()\n\t\t\tcancel()\n\n\t\t\tif pidFile != \"\" {\n\t\t\t\t_ = os.Remove(pidFile)\n\t\t\t}\n\t\t\ttime.Sleep(GetDuration(\"shutdown_termination_delay\"))\n\t\t\tos.Exit(0)\n\t\t}\n\t}\n}\n\nvar startHTTPChallengeServerOnce sync.Once\n\nfunc getTLSConfig() (*tls.Config, error) {\n\ttlsEnabled := viper.GetBool(\"tls\")\n\ttlsAutocertEnabled := viper.GetBool(\"tls_autocert\")\n\tautocertHostWhitelist := viper.GetString(\"tls_autocert_host_whitelist\")\n\tvar tlsAutocertHostWhitelist []string\n\tif autocertHostWhitelist != \"\" {\n\t\ttlsAutocertHostWhitelist = strings.Split(autocertHostWhitelist, \",\")\n\t} else {\n\t\ttlsAutocertHostWhitelist = nil\n\t}\n\ttlsAutocertCacheDir := viper.GetString(\"tls_autocert_cache_dir\")\n\ttlsAutocertEmail := viper.GetString(\"tls_autocert_email\")\n\ttlsAutocertServerName := viper.GetString(\"tls_autocert_server_name\")\n\ttlsAutocertHTTP := viper.GetBool(\"tls_autocert_http\")\n\ttlsAutocertHTTPAddr := viper.GetString(\"tls_autocert_http_addr\")\n\n\tif tlsAutocertEnabled {\n\t\tcertManager := autocert.Manager{\n\t\t\tPrompt: autocert.AcceptTOS,\n\t\t\tEmail:  tlsAutocertEmail,\n\t\t}\n\t\tif tlsAutocertHostWhitelist != nil {\n\t\t\tcertManager.HostPolicy = autocert.HostWhitelist(tlsAutocertHostWhitelist...)\n\t\t}\n\t\tif tlsAutocertCacheDir != \"\" {\n\t\t\tcertManager.Cache = autocert.DirCache(tlsAutocertCacheDir)\n\t\t}\n\n\t\tif tlsAutocertHTTP {\n\t\t\tstartHTTPChallengeServerOnce.Do(func() {\n\t\t\t\t// getTLSConfig can be called several times.\n\t\t\t\tacmeHTTPServer := &http.Server{\n\t\t\t\t\tHandler:  certManager.HTTPHandler(nil),\n\t\t\t\t\tAddr:     tlsAutocertHTTPAddr,\n\t\t\t\t\tErrorLog: stdlog.New(&httpErrorLogWriter{log.Logger}, \"\", 0),\n\t\t\t\t}\n\t\t\t\tgo func() {\n\t\t\t\t\tlog.Info().Msgf(\"serving ACME http_01 challenge on %s\", tlsAutocertHTTPAddr)\n\t\t\t\t\tif err := acmeHTTPServer.ListenAndServe(); err != nil {\n\t\t\t\t\t\tlog.Fatal().Msgf(\"can't create server on %s to serve acme http challenge: %v\", tlsAutocertHTTPAddr, err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t})\n\t\t}\n\n\t\treturn &tls.Config{\n\t\t\tGetCertificate: func(hello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n\t\t\t\t// See https://github.com/centrifugal/centrifugo/issues/144#issuecomment-279393819\n\t\t\t\tif tlsAutocertServerName != \"\" && hello.ServerName == \"\" {\n\t\t\t\t\thello.ServerName = tlsAutocertServerName\n\t\t\t\t}\n\t\t\t\treturn certManager.GetCertificate(hello)\n\t\t\t},\n\t\t\tNextProtos: []string{\n\t\t\t\t\"h2\", \"http/1.1\", acme.ALPNProto,\n\t\t\t},\n\t\t}, nil\n\n\t} else if tlsEnabled {\n\t\t// Autocert disabled - just try to use provided SSL cert and key files.\n\t\treturn tools.MakeTLSConfig(viper.GetViper(), \"\", os.ReadFile)\n\t}\n\n\treturn nil, nil\n}\n\nfunc tlsConfigForGRPC() (*tls.Config, error) {\n\treturn tools.MakeTLSConfig(viper.GetViper(), \"grpc_api_\", os.ReadFile)\n}\n\nfunc tlsConfigForUniGRPC() (*tls.Config, error) {\n\treturn tools.MakeTLSConfig(viper.GetViper(), \"uni_grpc_\", os.ReadFile)\n}\n\ntype httpErrorLogWriter struct {\n\tzerolog.Logger\n}\n\nfunc (w *httpErrorLogWriter) Write(data []byte) (int, error) {\n\tw.Logger.Warn().Msg(strings.TrimSpace(string(data)))\n\treturn len(data), nil\n}\n\nfunc runHTTPServers(n *centrifuge.Node, ruleContainer *rule.Container, apiExecutor *api.Executor, keepHeadersInContext bool) ([]*http.Server, error) {\n\tdebug := viper.GetBool(\"debug\")\n\tuseAdmin := viper.GetBool(\"admin\")\n\tusePrometheus := viper.GetBool(\"prometheus\")\n\tuseHealth := viper.GetBool(\"health\")\n\tuseSwagger := viper.GetBool(\"swagger\")\n\n\tadminExternal := viper.GetBool(\"admin_external\")\n\tapiExternal := viper.GetBool(\"api_external\")\n\n\tapiDisabled := viper.GetBool(\"api_disable\")\n\n\thttpAddress := viper.GetString(\"address\")\n\thttpPort := viper.GetString(\"port\")\n\thttpInternalAddress := viper.GetString(\"internal_address\")\n\thttpInternalPort := viper.GetString(\"internal_port\")\n\n\tif httpInternalAddress == \"\" && httpAddress != \"\" {\n\t\t// If custom internal address not explicitly set we try to reuse main\n\t\t// address for internal endpoints too.\n\t\thttpInternalAddress = httpAddress\n\t}\n\n\tif httpInternalPort == \"\" {\n\t\t// If custom internal port not set we use default http port for\n\t\t// internal endpoints too.\n\t\thttpInternalPort = httpPort\n\t}\n\n\t// addrToHandlerFlags contains mapping between HTTP server address and\n\t// handler flags to serve on this address.\n\taddrToHandlerFlags := map[string]HandlerFlag{}\n\n\tvar portFlags HandlerFlag\n\n\texternalAddr := net.JoinHostPort(httpAddress, httpPort)\n\tportFlags = addrToHandlerFlags[externalAddr]\n\tif !viper.GetBool(\"websocket_disable\") {\n\t\tportFlags |= HandlerWebsocket\n\t}\n\tif viper.GetBool(\"webtransport\") {\n\t\tif !viper.GetBool(\"http3\") {\n\t\t\tlog.Fatal().Msg(\"can not enable webtransport without experimental HTTP/3\")\n\t\t}\n\t\tportFlags |= HandlerWebtransport\n\t}\n\tif viper.GetBool(\"sockjs\") {\n\t\tportFlags |= HandlerSockJS\n\t}\n\tif viper.GetBool(\"sse\") {\n\t\tportFlags |= HandlerSSE\n\t}\n\tif viper.GetBool(\"http_stream\") {\n\t\tportFlags |= HandlerHTTPStream\n\t}\n\tif viper.GetBool(\"sse\") || viper.GetBool(\"http_stream\") {\n\t\tportFlags |= HandlerEmulation\n\t}\n\tif useAdmin && adminExternal {\n\t\tportFlags |= HandlerAdmin\n\t}\n\tif !apiDisabled && apiExternal {\n\t\tportFlags |= HandlerAPI\n\t}\n\tif viper.GetBool(\"uni_websocket\") {\n\t\tportFlags |= HandlerUniWebsocket\n\t}\n\tif viper.GetBool(\"uni_sse\") {\n\t\tportFlags |= HandlerUniSSE\n\t}\n\tif viper.GetBool(\"uni_http_stream\") {\n\t\tportFlags |= HandlerUniHTTPStream\n\t}\n\taddrToHandlerFlags[externalAddr] = portFlags\n\n\tinternalAddr := net.JoinHostPort(httpInternalAddress, httpInternalPort)\n\tportFlags = addrToHandlerFlags[internalAddr]\n\tif !apiDisabled && !apiExternal {\n\t\tportFlags |= HandlerAPI\n\t}\n\n\tif useAdmin && !adminExternal {\n\t\tportFlags |= HandlerAdmin\n\t}\n\tif usePrometheus {\n\t\tportFlags |= HandlerPrometheus\n\t}\n\tif useSwagger {\n\t\tportFlags |= HandlerSwagger\n\t}\n\tif debug {\n\t\tportFlags |= HandlerDebug\n\t}\n\tif useHealth {\n\t\tportFlags |= HandlerHealth\n\t}\n\taddrToHandlerFlags[internalAddr] = portFlags\n\n\tvar servers []*http.Server\n\n\ttlsConfig, err := getTLSConfig()\n\tif err != nil {\n\t\tlog.Fatal().Msgf(\"can not get TLS config: %v\", err)\n\t}\n\n\t// Iterate over port-to-flags mapping and start HTTP servers\n\t// on separate ports serving handlers specified in flags.\n\tfor addr, handlerFlags := range addrToHandlerFlags {\n\t\taddr := addr\n\t\tif handlerFlags == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tvar addrTLSConfig *tls.Config\n\t\tif !viper.GetBool(\"tls_external\") || addr == externalAddr {\n\t\t\taddrTLSConfig = tlsConfig\n\t\t}\n\n\t\tuseHTTP3 := viper.GetBool(\"http3\") && addr == externalAddr\n\n\t\tvar wtServer *webtransport.Server\n\t\tif useHTTP3 {\n\t\t\twtServer = &webtransport.Server{\n\t\t\t\tCheckOrigin: getCheckOrigin(),\n\t\t\t}\n\t\t}\n\n\t\tmux := Mux(n, ruleContainer, apiExecutor, handlerFlags, keepHeadersInContext, wtServer)\n\n\t\tif useHTTP3 {\n\t\t\twtServer.H3 = http3.Server{\n\t\t\t\tAddr:      addr,\n\t\t\t\tTLSConfig: addrTLSConfig,\n\t\t\t\tHandler:   mux,\n\t\t\t}\n\t\t}\n\n\t\tvar protoSuffix string\n\t\tif useHTTP3 {\n\t\t\tprotoSuffix = \" with HTTP/3 (experimental)\"\n\t\t}\n\t\tlog.Info().Msgf(\"serving %s endpoints on %s%s\", handlerFlags, addr, protoSuffix)\n\n\t\tserver := &http.Server{\n\t\t\tAddr:      addr,\n\t\t\tHandler:   mux,\n\t\t\tTLSConfig: addrTLSConfig,\n\t\t\tErrorLog:  stdlog.New(&httpErrorLogWriter{log.Logger}, \"\", 0),\n\t\t}\n\n\t\tif useHTTP3 {\n\t\t\tserver.Handler = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\t_ = wtServer.H3.SetQUICHeaders(w.Header())\n\t\t\t\tmux.ServeHTTP(w, r)\n\t\t\t})\n\t\t}\n\n\t\tservers = append(servers, server)\n\n\t\tgo func() {\n\t\t\tif useHTTP3 {\n\t\t\t\tif addrTLSConfig == nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"HTTP/3 requires TLS configured\")\n\t\t\t\t}\n\t\t\t\tif viper.GetBool(\"tls_autocert\") {\n\t\t\t\t\tlog.Fatal().Msgf(\"can not use HTTP/3 with autocert\")\n\t\t\t\t}\n\n\t\t\t\tudpAddr, err := net.ResolveUDPAddr(\"udp\", addr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"can not start HTTP/3, resolve UDP: %v\", err)\n\t\t\t\t}\n\t\t\t\tudpConn, err := net.ListenUDP(\"udp\", udpAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"can not start HTTP/3, listen UDP: %v\", err)\n\t\t\t\t}\n\t\t\t\tdefer func() { _ = udpConn.Close() }()\n\n\t\t\t\ttcpAddr, err := net.ResolveTCPAddr(\"tcp\", addr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"can not start HTTP/3, resolve TCP: %v\", err)\n\t\t\t\t}\n\t\t\t\ttcpConn, err := net.ListenTCP(\"tcp\", tcpAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"can not start HTTP/3, listen TCP: %v\", err)\n\t\t\t\t}\n\t\t\t\tdefer func() { _ = tcpConn.Close() }()\n\n\t\t\t\ttlsConn := tls.NewListener(tcpConn, addrTLSConfig)\n\t\t\t\tdefer func() { _ = tlsConn.Close() }()\n\n\t\t\t\thErr := make(chan error)\n\t\t\t\tqErr := make(chan error)\n\t\t\t\tgo func() {\n\t\t\t\t\thErr <- server.Serve(tlsConn)\n\t\t\t\t}()\n\t\t\t\tgo func() {\n\t\t\t\t\tqErr <- wtServer.Serve(udpConn)\n\t\t\t\t}()\n\n\t\t\t\tselect {\n\t\t\t\tcase err := <-hErr:\n\t\t\t\t\t_ = wtServer.Close()\n\t\t\t\t\tif !errors.Is(err, http.ErrServerClosed) {\n\t\t\t\t\t\tlog.Fatal().Msgf(\"ListenAndServe: %v\", err)\n\t\t\t\t\t}\n\t\t\t\tcase err := <-qErr:\n\t\t\t\t\t// Cannot close the HTTP server or wait for requests to complete properly.\n\t\t\t\t\tlog.Fatal().Msgf(\"ListenAndServe HTTP/3: %v\", err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif addrTLSConfig != nil {\n\t\t\t\t\tif err := server.ListenAndServeTLS(\"\", \"\"); err != nil {\n\t\t\t\t\t\tif !errors.Is(err, http.ErrServerClosed) {\n\t\t\t\t\t\t\tlog.Fatal().Msgf(\"ListenAndServe: %v\", err)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif err := server.ListenAndServe(); err != nil {\n\t\t\t\t\t\tif !errors.Is(err, http.ErrServerClosed) {\n\t\t\t\t\t\t\tlog.Fatal().Msgf(\"ListenAndServe: %v\", err)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\treturn servers, nil\n}\n\nvar errConfigFileNotFound = errors.New(\"unable to find configuration file\")\n\n// readConfig reads config.\nfunc readConfig(f string) error {\n\tviper.SetConfigFile(f)\n\terr := viper.ReadInConfig()\n\tif err != nil {\n\t\tvar configParseError viper.ConfigParseError\n\t\tswitch {\n\t\tcase errors.As(err, &configParseError):\n\t\t\treturn err\n\t\tdefault:\n\t\t\treturn errConfigFileNotFound\n\t\t}\n\t}\n\treturn nil\n}\n\n// validateConfig validates config file located at provided path.\nfunc validateConfig(f string) error {\n\terr := readConfig(f)\n\tif err != nil {\n\t\treturn err\n\t}\n\truleConfig := ruleConfig()\n\tif err := ruleConfig.Validate(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc ruleConfig() rule.Config {\n\tv := viper.GetViper()\n\tcfg := rule.Config{}\n\n\tcfg.Presence = v.GetBool(\"presence\")\n\tcfg.JoinLeave = v.GetBool(\"join_leave\")\n\tcfg.ForcePushJoinLeave = v.GetBool(\"force_push_join_leave\")\n\tcfg.HistorySize = v.GetInt(\"history_size\")\n\tcfg.HistoryTTL = tools.Duration(GetDuration(\"history_ttl\", true))\n\tcfg.HistoryMetaTTL = tools.Duration(GetDuration(\"history_meta_ttl\", true))\n\tcfg.ForcePositioning = v.GetBool(\"force_positioning\")\n\tcfg.AllowPositioning = v.GetBool(\"allow_positioning\")\n\tcfg.AllowRecovery = v.GetBool(\"allow_recovery\")\n\tcfg.ForceRecovery = v.GetBool(\"force_recovery\")\n\tcfg.ForceRecoveryMode = v.GetString(\"force_recovery_mode\")\n\tcfg.SubscribeForAnonymous = v.GetBool(\"allow_subscribe_for_anonymous\")\n\tcfg.SubscribeForClient = v.GetBool(\"allow_subscribe_for_client\")\n\tcfg.PublishForAnonymous = v.GetBool(\"allow_publish_for_anonymous\")\n\tcfg.PublishForClient = v.GetBool(\"allow_publish_for_client\")\n\tcfg.PublishForSubscriber = v.GetBool(\"allow_publish_for_subscriber\")\n\tcfg.PresenceForAnonymous = v.GetBool(\"allow_presence_for_anonymous\")\n\tcfg.PresenceForClient = v.GetBool(\"allow_presence_for_client\")\n\tcfg.PresenceForSubscriber = v.GetBool(\"allow_presence_for_subscriber\")\n\tcfg.HistoryForAnonymous = v.GetBool(\"allow_history_for_anonymous\")\n\tcfg.HistoryForClient = v.GetBool(\"allow_history_for_client\")\n\tcfg.HistoryForSubscriber = v.GetBool(\"allow_history_for_subscriber\")\n\tcfg.UserLimitedChannels = v.GetBool(\"allow_user_limited_channels\")\n\tcfg.ChannelRegex = v.GetString(\"channel_regex\")\n\tcfg.ProxySubscribe = v.GetBool(\"proxy_subscribe\")\n\tcfg.ProxyPublish = v.GetBool(\"proxy_publish\")\n\tcfg.ProxySubRefresh = v.GetBool(\"proxy_sub_refresh\")\n\tcfg.SubscribeProxyName = v.GetString(\"subscribe_proxy_name\")\n\tcfg.PublishProxyName = v.GetString(\"publish_proxy_name\")\n\tcfg.SubRefreshProxyName = v.GetString(\"sub_refresh_proxy_name\")\n\tcfg.ProxySubscribeStream = v.GetBool(\"proxy_stream_subscribe\")\n\tcfg.ProxySubscribeStreamBidirectional = v.GetBool(\"proxy_subscribe_stream_bidirectional\")\n\t// GlobalHistoryMetaTTL is required here only for validation purposes.\n\tcfg.GlobalHistoryMetaTTL = GetDuration(\"global_history_meta_ttl\", true)\n\tcfg.DeltaPublish = v.GetBool(\"delta_publish\")\n\tallowedDeltaTypes := v.GetStringSlice(\"allowed_delta_types\")\n\tfor _, dt := range allowedDeltaTypes {\n\t\tcfg.AllowedDeltaTypes = append(cfg.AllowedDeltaTypes, centrifuge.DeltaType(dt))\n\t}\n\n\tcfg.Namespaces = namespacesFromConfig(v)\n\n\tcfg.ChannelPrivatePrefix = v.GetString(\"channel_private_prefix\")\n\tcfg.ChannelNamespaceBoundary = v.GetString(\"channel_namespace_boundary\")\n\tcfg.ChannelUserBoundary = v.GetString(\"channel_user_boundary\")\n\tcfg.ChannelUserSeparator = v.GetString(\"channel_user_separator\")\n\tcfg.UserSubscribeToPersonal = v.GetBool(\"user_subscribe_to_personal\")\n\tcfg.UserPersonalSingleConnection = v.GetBool(\"user_personal_single_connection\")\n\tcfg.UserPersonalChannelNamespace = v.GetString(\"user_personal_channel_namespace\")\n\tcfg.ClientInsecure = v.GetBool(\"client_insecure\")\n\tcfg.ClientInsecureSkipTokenSignatureVerify = v.GetBool(\"client_insecure_skip_token_signature_verify\")\n\tcfg.AnonymousConnectWithoutToken = v.GetBool(\"allow_anonymous_connect_without_token\")\n\tcfg.DisallowAnonymousConnectionTokens = v.GetBool(\"disallow_anonymous_connection_tokens\")\n\tcfg.ClientConcurrency = v.GetInt(\"client_concurrency\")\n\tcfg.RpcNamespaceBoundary = v.GetString(\"rpc_namespace_boundary\")\n\tcfg.RpcProxyName = v.GetString(\"rpc_proxy_name\")\n\tcfg.RpcNamespaces = rpcNamespacesFromConfig(v)\n\tcfg.ClientConnectionLimit = v.GetInt(\"client_connection_limit\")\n\tcfg.ClientConnectionRateLimit = v.GetInt(\"client_connection_rate_limit\")\n\n\treturn cfg\n}\n\n// rpcNamespacesFromConfig allows to unmarshal rpc namespaces.\nfunc rpcNamespacesFromConfig(v *viper.Viper) []rule.RpcNamespace {\n\tvar ns []rule.RpcNamespace\n\tif !v.IsSet(\"rpc_namespaces\") {\n\t\treturn ns\n\t}\n\tjsonData := tools.DecodeSlice(v, &ns, \"rpc_namespaces\")\n\trule.WarnUnknownRpcNamespaceKeys(jsonData)\n\treturn ns\n}\n\n// namespacesFromConfig allows to unmarshal channel namespaces.\nfunc namespacesFromConfig(v *viper.Viper) []rule.ChannelNamespace {\n\tvar ns []rule.ChannelNamespace\n\tif !v.IsSet(\"namespaces\") {\n\t\treturn ns\n\t}\n\tjsonData := tools.DecodeSlice(v, &ns, \"namespaces\")\n\trule.WarnUnknownNamespaceKeys(jsonData)\n\treturn ns\n}\n\nvar proxyNamePattern = \"^[-a-zA-Z0-9_.]{2,}$\"\nvar proxyNameRe = regexp.MustCompile(proxyNamePattern)\n\nfunc granularProxiesFromConfig(v *viper.Viper) []proxy.Config {\n\tvar proxies []proxy.Config\n\tif !v.IsSet(\"proxies\") {\n\t\treturn proxies\n\t}\n\tjsonData := tools.DecodeSlice(v, &proxies, \"proxies\")\n\tproxy.WarnUnknownProxyKeys(jsonData)\n\n\tnames := map[string]struct{}{}\n\tfor _, p := range proxies {\n\t\tif !proxyNameRe.Match([]byte(p.Name)) {\n\t\t\tlog.Fatal().Msgf(\"invalid proxy name: %s, must match %s regular expression\", p.Name, proxyNamePattern)\n\t\t}\n\t\tif _, ok := names[p.Name]; ok {\n\t\t\tlog.Fatal().Msgf(\"duplicate proxy name: %s\", p.Name)\n\t\t}\n\t\tif p.Timeout == 0 {\n\t\t\tp.Timeout = tools.Duration(time.Second)\n\t\t}\n\t\tif p.Endpoint == \"\" {\n\t\t\tlog.Fatal().Msgf(\"no endpoint set for proxy %s\", p.Name)\n\t\t}\n\t\tfor i, transform := range p.HttpStatusTransforms {\n\t\t\tif err := transform.Validate(); err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error validating proxy_http_status_code_transforms[%d] in proxy %s: %v\", i, p.Name, err)\n\t\t\t}\n\t\t}\n\t\tnames[p.Name] = struct{}{}\n\t}\n\n\treturn proxies\n}\n\n// consumersFromConfig allows to unmarshal rpc namespaces.\nfunc consumersFromConfig(v *viper.Viper) []consuming.ConsumerConfig {\n\tvar consumers []consuming.ConsumerConfig\n\tif !v.IsSet(\"consumers\") {\n\t\treturn consumers\n\t}\n\tjsonData := tools.DecodeSlice(v, &consumers, \"consumers\")\n\tconsuming.WarnUnknownConsumerConfigKeys(jsonData)\n\treturn consumers\n}\n\n// Now Centrifugo uses https://github.com/tidwall/gjson to extract custom claims from JWT. So technically\n// we could support extracting from nested objects using dot syntax, like \"centrifugo.user\". But for now\n// not using this feature to keep things simple until necessary.\nvar customClaimRe = regexp.MustCompile(\"^[a-zA-Z_]+$\")\n\nfunc jwtVerifierConfig() (jwtverify.VerifierConfig, error) {\n\tv := viper.GetViper()\n\tcfg := jwtverify.VerifierConfig{}\n\n\tcfg.HMACSecretKey = v.GetString(\"token_hmac_secret_key\")\n\n\trsaPublicKey := v.GetString(\"token_rsa_public_key\")\n\tif rsaPublicKey != \"\" {\n\t\tpubKey, err := jwtutils.ParseRSAPublicKeyFromPEM([]byte(rsaPublicKey))\n\t\tif err != nil {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"error parsing RSA public key: %w\", err)\n\t\t}\n\t\tcfg.RSAPublicKey = pubKey\n\t}\n\n\tecdsaPublicKey := v.GetString(\"token_ecdsa_public_key\")\n\tif ecdsaPublicKey != \"\" {\n\t\tpubKey, err := jwtutils.ParseECDSAPublicKeyFromPEM([]byte(ecdsaPublicKey))\n\t\tif err != nil {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"error parsing ECDSA public key: %w\", err)\n\t\t}\n\t\tcfg.ECDSAPublicKey = pubKey\n\t}\n\n\tcfg.JWKSPublicEndpoint = v.GetString(\"token_jwks_public_endpoint\")\n\tcfg.Audience = v.GetString(\"token_audience\")\n\tcfg.AudienceRegex = v.GetString(\"token_audience_regex\")\n\tcfg.Issuer = v.GetString(\"token_issuer\")\n\tcfg.IssuerRegex = v.GetString(\"token_issuer_regex\")\n\n\tif v.GetString(\"token_user_id_claim\") != \"\" {\n\t\tcustomUserIDClaim := v.GetString(\"token_user_id_claim\")\n\t\tif !customClaimRe.MatchString(customUserIDClaim) {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"invalid user ID claim: %s, must match %s regular expression\", customUserIDClaim, customClaimRe.String())\n\t\t}\n\t\tcfg.UserIDClaim = customUserIDClaim\n\t}\n\n\treturn cfg, nil\n}\n\nfunc subJWTVerifierConfig() (jwtverify.VerifierConfig, error) {\n\tv := viper.GetViper()\n\tcfg := jwtverify.VerifierConfig{}\n\n\tcfg.HMACSecretKey = v.GetString(\"subscription_token_hmac_secret_key\")\n\n\trsaPublicKey := v.GetString(\"subscription_token_rsa_public_key\")\n\tif rsaPublicKey != \"\" {\n\t\tpubKey, err := jwtutils.ParseRSAPublicKeyFromPEM([]byte(rsaPublicKey))\n\t\tif err != nil {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"error parsing RSA public key: %w\", err)\n\t\t}\n\t\tcfg.RSAPublicKey = pubKey\n\t}\n\n\tecdsaPublicKey := v.GetString(\"subscription_token_ecdsa_public_key\")\n\tif ecdsaPublicKey != \"\" {\n\t\tpubKey, err := jwtutils.ParseECDSAPublicKeyFromPEM([]byte(ecdsaPublicKey))\n\t\tif err != nil {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"error parsing ECDSA public key: %w\", err)\n\t\t}\n\t\tcfg.ECDSAPublicKey = pubKey\n\t}\n\n\tcfg.JWKSPublicEndpoint = v.GetString(\"subscription_token_jwks_public_endpoint\")\n\tcfg.Audience = v.GetString(\"subscription_token_audience\")\n\tcfg.AudienceRegex = v.GetString(\"subscription_token_audience_regex\")\n\tcfg.Issuer = v.GetString(\"subscription_token_issuer\")\n\tcfg.IssuerRegex = v.GetString(\"subscription_token_issuer_regex\")\n\n\tif v.GetString(\"subscription_token_user_id_claim\") != \"\" {\n\t\tcustomUserIDClaim := v.GetString(\"subscription_token_user_id_claim\")\n\t\tif !customClaimRe.MatchString(customUserIDClaim) {\n\t\t\treturn jwtverify.VerifierConfig{}, fmt.Errorf(\"invalid user ID claim: %s, must match %s regular expression\", customUserIDClaim, customClaimRe.String())\n\t\t}\n\t\tcfg.UserIDClaim = customUserIDClaim\n\t}\n\n\treturn cfg, nil\n}\n\nfunc GetDuration(key string, secondsPrecision ...bool) time.Duration {\n\tdurationString := viper.GetString(key)\n\tduration, err := time.ParseDuration(durationString)\n\tif err != nil {\n\t\tlog.Fatal().Msgf(\"malformed duration for key '%s': %v\", key, err)\n\t}\n\tif duration > 0 && duration < time.Millisecond {\n\t\tlog.Fatal().Msgf(\"malformed duration for key '%s': %s, minimal duration resolution is 1ms – make sure correct time unit set\", key, duration)\n\t}\n\tif duration > 0 && duration < time.Second && len(secondsPrecision) > 0 && secondsPrecision[0] {\n\t\tlog.Fatal().Msgf(\"malformed duration for key '%s': %s, minimal duration resolution is 1s for this key\", key, duration)\n\t}\n\tif duration > 0 && duration%time.Second != 0 && len(secondsPrecision) > 0 && secondsPrecision[0] {\n\t\tlog.Fatal().Msgf(\"malformed duration for key '%s': %s, sub-second precision is not supported for this key\", key, duration)\n\t}\n\treturn duration\n}\n\nfunc proxyMapConfig() (*client.ProxyMap, bool) {\n\tv := viper.GetViper()\n\n\tproxyMap := &client.ProxyMap{\n\t\tSubscribeProxies:       map[string]proxy.SubscribeProxy{},\n\t\tPublishProxies:         map[string]proxy.PublishProxy{},\n\t\tRpcProxies:             map[string]proxy.RPCProxy{},\n\t\tSubRefreshProxies:      map[string]proxy.SubRefreshProxy{},\n\t\tSubscribeStreamProxies: map[string]*proxy.SubscribeStreamProxy{},\n\t}\n\n\ttlsConfig, err := tools.ExtractTLSConfig(viper.GetViper(), \"proxy_grpc_tls\")\n\tif err != nil {\n\t\tlog.Fatal().Msgf(\"error extracting TLS config for proxy GRPC: %v\", err)\n\t}\n\n\tproxyConfig := proxy.Config{\n\t\tBinaryEncoding:        v.GetBool(\"proxy_binary_encoding\"),\n\t\tIncludeConnectionMeta: v.GetBool(\"proxy_include_connection_meta\"),\n\t\tGrpcCertFile:          v.GetString(\"proxy_grpc_cert_file\"),\n\t\tGrpcTLS:               tlsConfig,\n\t\tGrpcCredentialsKey:    v.GetString(\"proxy_grpc_credentials_key\"),\n\t\tGrpcCredentialsValue:  v.GetString(\"proxy_grpc_credentials_value\"),\n\t\tGrpcMetadata:          v.GetStringSlice(\"proxy_grpc_metadata\"),\n\t\tGrpcCompression:       v.GetBool(\"proxy_grpc_compression\"),\n\t}\n\n\tproxyConfig.HttpHeaders = v.GetStringSlice(\"proxy_http_headers\")\n\tfor i, header := range proxyConfig.HttpHeaders {\n\t\tproxyConfig.HttpHeaders[i] = strings.ToLower(header)\n\t}\n\n\tstaticHttpHeaders, err := tools.MapStringString(v, \"proxy_static_http_headers\")\n\tif err != nil {\n\t\tlog.Fatal().Err(err).Msg(\"malformed configuration for proxy_static_http_headers\")\n\t}\n\tproxyConfig.StaticHttpHeaders = staticHttpHeaders\n\n\tvar httpStatusTransforms []proxy.HttpStatusToCodeTransform\n\tif v.IsSet(\"proxy_http_status_code_transforms\") {\n\t\ttools.DecodeSlice(v, &httpStatusTransforms, \"proxy_http_status_code_transforms\")\n\t}\n\tfor i, transform := range httpStatusTransforms {\n\t\tif err := transform.Validate(); err != nil {\n\t\t\tlog.Fatal().Msgf(\"error validating proxy_http_status_code_transforms[%d]: %v\", i, err)\n\t\t}\n\t}\n\tproxyConfig.HttpStatusTransforms = httpStatusTransforms\n\n\tconnectEndpoint := v.GetString(\"proxy_connect_endpoint\")\n\tconnectTimeout := GetDuration(\"proxy_connect_timeout\")\n\trefreshEndpoint := v.GetString(\"proxy_refresh_endpoint\")\n\trefreshTimeout := GetDuration(\"proxy_refresh_timeout\")\n\trpcEndpoint := v.GetString(\"proxy_rpc_endpoint\")\n\trpcTimeout := GetDuration(\"proxy_rpc_timeout\")\n\tsubscribeEndpoint := v.GetString(\"proxy_subscribe_endpoint\")\n\tsubscribeTimeout := GetDuration(\"proxy_subscribe_timeout\")\n\tpublishEndpoint := v.GetString(\"proxy_publish_endpoint\")\n\tpublishTimeout := GetDuration(\"proxy_publish_timeout\")\n\tsubRefreshEndpoint := v.GetString(\"proxy_sub_refresh_endpoint\")\n\tsubRefreshTimeout := GetDuration(\"proxy_sub_refresh_timeout\")\n\tproxyStreamSubscribeEndpoint := v.GetString(\"proxy_subscribe_stream_endpoint\")\n\tif strings.HasPrefix(proxyStreamSubscribeEndpoint, \"http\") {\n\t\tlog.Fatal().Msg(\"error creating subscribe stream proxy: only GRPC endpoints supported\")\n\t}\n\tproxyStreamSubscribeTimeout := GetDuration(\"proxy_subscribe_stream_timeout\")\n\n\tif connectEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = connectEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(connectTimeout)\n\t\tvar err error\n\t\tproxyMap.ConnectProxy, err = proxy.GetConnectProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating connect proxy: %v\", err)\n\t\t}\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(connectEndpoint)[0]).Msg(\"connect proxy enabled\")\n\t}\n\n\tif refreshEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = refreshEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(refreshTimeout)\n\t\tvar err error\n\t\tproxyMap.RefreshProxy, err = proxy.GetRefreshProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating refresh proxy: %v\", err)\n\t\t}\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(refreshEndpoint)[0]).Msg(\"refresh proxy enabled\")\n\t}\n\n\tif subscribeEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = subscribeEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(subscribeTimeout)\n\t\tsp, err := proxy.GetSubscribeProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating subscribe proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubscribeProxies[\"\"] = sp\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(subscribeEndpoint)[0]).Msg(\"subscribe proxy enabled\")\n\t}\n\n\tif publishEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = publishEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(publishTimeout)\n\t\tpp, err := proxy.GetPublishProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating publish proxy: %v\", err)\n\t\t}\n\t\tproxyMap.PublishProxies[\"\"] = pp\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(publishEndpoint)[0]).Msg(\"publish proxy enabled\")\n\t}\n\n\tif rpcEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = rpcEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(rpcTimeout)\n\t\trp, err := proxy.GetRpcProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating rpc proxy: %v\", err)\n\t\t}\n\t\tproxyMap.RpcProxies[\"\"] = rp\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(rpcEndpoint)[0]).Msg(\"RPC proxy enabled\")\n\t}\n\n\tif subRefreshEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = subRefreshEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(subRefreshTimeout)\n\t\tsrp, err := proxy.GetSubRefreshProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating sub refresh proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubRefreshProxies[\"\"] = srp\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(subRefreshEndpoint)[0]).Msg(\"sub refresh proxy enabled\")\n\t}\n\n\tif proxyStreamSubscribeEndpoint != \"\" {\n\t\tproxyConfig.Endpoint = proxyStreamSubscribeEndpoint\n\t\tproxyConfig.Timeout = tools.Duration(proxyStreamSubscribeTimeout)\n\t\tstreamProxy, err := proxy.NewSubscribeStreamProxy(proxyConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating subscribe stream proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubscribeStreamProxies[\"\"] = streamProxy\n\t\tlog.Info().Str(\"endpoint\", tools.RedactedLogURLs(proxyStreamSubscribeEndpoint)[0]).Msg(\"subscribe stream proxy enabled\")\n\t}\n\n\tkeepHeadersInContext := connectEndpoint != \"\" || refreshEndpoint != \"\" ||\n\t\trpcEndpoint != \"\" || subscribeEndpoint != \"\" || publishEndpoint != \"\" ||\n\t\tsubRefreshEndpoint != \"\" || proxyStreamSubscribeEndpoint != \"\"\n\n\treturn proxyMap, keepHeadersInContext\n}\n\nfunc granularProxyMapConfig(ruleConfig rule.Config) (*client.ProxyMap, bool) {\n\tproxyMap := &client.ProxyMap{\n\t\tRpcProxies:             map[string]proxy.RPCProxy{},\n\t\tPublishProxies:         map[string]proxy.PublishProxy{},\n\t\tSubscribeProxies:       map[string]proxy.SubscribeProxy{},\n\t\tSubRefreshProxies:      map[string]proxy.SubRefreshProxy{},\n\t\tSubscribeStreamProxies: map[string]*proxy.SubscribeStreamProxy{},\n\t\tCacheEmptyProxies:      map[string]proxy.CacheEmptyProxy{},\n\t}\n\tproxyList := granularProxiesFromConfig(viper.GetViper())\n\tproxies := make(map[string]proxy.Config)\n\tfor _, p := range proxyList {\n\t\tfor i, header := range p.HttpHeaders {\n\t\t\tp.HttpHeaders[i] = strings.ToLower(header)\n\t\t}\n\t\tproxies[p.Name] = p\n\t}\n\n\tvar keepHeadersInContext bool\n\n\tconnectProxyName := viper.GetString(\"connect_proxy_name\")\n\tif connectProxyName != \"\" {\n\t\tp, ok := proxies[connectProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"connect proxy not found: %s\", connectProxyName)\n\t\t}\n\t\tvar err error\n\t\tproxyMap.ConnectProxy, err = proxy.GetConnectProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating connect proxy: %v\", err)\n\t\t}\n\t\tkeepHeadersInContext = true\n\t}\n\trefreshProxyName := viper.GetString(\"refresh_proxy_name\")\n\tif refreshProxyName != \"\" {\n\t\tp, ok := proxies[refreshProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"refresh proxy not found: %s\", refreshProxyName)\n\t\t}\n\t\tvar err error\n\t\tproxyMap.RefreshProxy, err = proxy.GetRefreshProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating refresh proxy: %v\", err)\n\t\t}\n\t\tkeepHeadersInContext = true\n\t}\n\tsubscribeProxyName := ruleConfig.SubscribeProxyName\n\tif subscribeProxyName != \"\" {\n\t\tp, ok := proxies[subscribeProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"subscribe proxy not found: %s\", subscribeProxyName)\n\t\t}\n\t\tsp, err := proxy.GetSubscribeProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating subscribe proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubscribeProxies[subscribeProxyName] = sp\n\t\tkeepHeadersInContext = true\n\t}\n\n\tpublishProxyName := ruleConfig.PublishProxyName\n\tif publishProxyName != \"\" {\n\t\tp, ok := proxies[publishProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"publish proxy not found: %s\", publishProxyName)\n\t\t}\n\t\tpp, err := proxy.GetPublishProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating publish proxy: %v\", err)\n\t\t}\n\t\tproxyMap.PublishProxies[publishProxyName] = pp\n\t\tkeepHeadersInContext = true\n\t}\n\n\tsubRefreshProxyName := ruleConfig.SubRefreshProxyName\n\tif subRefreshProxyName != \"\" {\n\t\tp, ok := proxies[subRefreshProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"sub refresh proxy not found: %s\", subRefreshProxyName)\n\t\t}\n\t\tsrp, err := proxy.GetSubRefreshProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating publish proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubRefreshProxies[subRefreshProxyName] = srp\n\t\tkeepHeadersInContext = true\n\t}\n\n\tsubscribeStreamProxyName := ruleConfig.SubscribeStreamProxyName\n\tif subscribeStreamProxyName != \"\" {\n\t\tp, ok := proxies[subscribeStreamProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"subscribe stream proxy not found: %s\", subscribeStreamProxyName)\n\t\t}\n\t\tif strings.HasPrefix(p.Endpoint, \"http\") {\n\t\t\tlog.Fatal().Msgf(\"error creating subscribe stream proxy %s only GRPC endpoints supported\", subscribeStreamProxyName)\n\t\t}\n\t\tsp, err := proxy.NewSubscribeStreamProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating subscribe proxy: %v\", err)\n\t\t}\n\t\tproxyMap.SubscribeStreamProxies[subscribeProxyName] = sp\n\t\tkeepHeadersInContext = true\n\t}\n\n\tfor _, ns := range ruleConfig.Namespaces {\n\t\tsubscribeProxyName := ns.SubscribeProxyName\n\t\tpublishProxyName := ns.PublishProxyName\n\t\tsubRefreshProxyName := ns.SubRefreshProxyName\n\t\tsubscribeStreamProxyName := ns.SubscribeStreamProxyName\n\n\t\tif subscribeProxyName != \"\" {\n\t\t\tp, ok := proxies[subscribeProxyName]\n\t\t\tif !ok {\n\t\t\t\tlog.Fatal().Msgf(\"subscribe proxy not found: %s\", subscribeProxyName)\n\t\t\t}\n\t\t\tsp, err := proxy.GetSubscribeProxy(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating subscribe proxy: %v\", err)\n\t\t\t}\n\t\t\tproxyMap.SubscribeProxies[subscribeProxyName] = sp\n\t\t\tkeepHeadersInContext = true\n\t\t}\n\n\t\tif publishProxyName != \"\" {\n\t\t\tp, ok := proxies[publishProxyName]\n\t\t\tif !ok {\n\t\t\t\tlog.Fatal().Msgf(\"publish proxy not found: %s\", publishProxyName)\n\t\t\t}\n\t\t\tpp, err := proxy.GetPublishProxy(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating publish proxy: %v\", err)\n\t\t\t}\n\t\t\tproxyMap.PublishProxies[publishProxyName] = pp\n\t\t\tkeepHeadersInContext = true\n\t\t}\n\n\t\tif subRefreshProxyName != \"\" {\n\t\t\tp, ok := proxies[subRefreshProxyName]\n\t\t\tif !ok {\n\t\t\t\tlog.Fatal().Msgf(\"sub refresh proxy not found: %s\", subRefreshProxyName)\n\t\t\t}\n\t\t\tsrp, err := proxy.GetSubRefreshProxy(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating sub refresh proxy: %v\", err)\n\t\t\t}\n\t\t\tproxyMap.SubRefreshProxies[subRefreshProxyName] = srp\n\t\t\tkeepHeadersInContext = true\n\t\t}\n\n\t\tif subscribeStreamProxyName != \"\" {\n\t\t\tp, ok := proxies[subscribeStreamProxyName]\n\t\t\tif !ok {\n\t\t\t\tlog.Fatal().Msgf(\"subscribe stream proxy not found: %s\", subscribeStreamProxyName)\n\t\t\t}\n\t\t\tif strings.HasPrefix(p.Endpoint, \"http\") {\n\t\t\t\tlog.Fatal().Msgf(\"error creating subscribe stream proxy %s only GRPC endpoints supported\", subscribeStreamProxyName)\n\t\t\t}\n\t\t\tssp, err := proxy.NewSubscribeStreamProxy(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating subscribe stream proxy: %v\", err)\n\t\t\t}\n\t\t\tproxyMap.SubscribeStreamProxies[subscribeStreamProxyName] = ssp\n\t\t\tkeepHeadersInContext = true\n\t\t}\n\t}\n\n\trpcProxyName := ruleConfig.RpcProxyName\n\tif rpcProxyName != \"\" {\n\t\tp, ok := proxies[rpcProxyName]\n\t\tif !ok {\n\t\t\tlog.Fatal().Msgf(\"rpc proxy not found: %s\", rpcProxyName)\n\t\t}\n\t\trp, err := proxy.GetRpcProxy(p)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating rpc proxy: %v\", err)\n\t\t}\n\t\tproxyMap.RpcProxies[rpcProxyName] = rp\n\t\tkeepHeadersInContext = true\n\t}\n\n\tfor _, ns := range ruleConfig.RpcNamespaces {\n\t\trpcProxyName := ns.RpcProxyName\n\t\tif rpcProxyName != \"\" {\n\t\t\tp, ok := proxies[rpcProxyName]\n\t\t\tif !ok {\n\t\t\t\tlog.Fatal().Msgf(\"rpc proxy not found: %s\", rpcProxyName)\n\t\t\t}\n\t\t\trp, err := proxy.GetRpcProxy(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error creating rpc proxy: %v\", err)\n\t\t\t}\n\t\t\tproxyMap.RpcProxies[rpcProxyName] = rp\n\t\t\tkeepHeadersInContext = true\n\t\t}\n\t}\n\n\treturn proxyMap, keepHeadersInContext\n}\n\nfunc nodeConfig(version string) centrifuge.Config {\n\tv := viper.GetViper()\n\tcfg := centrifuge.Config{}\n\tcfg.Version = version\n\tcfg.MetricsNamespace = \"centrifugo\"\n\tcfg.Name = applicationName()\n\tcfg.ChannelMaxLength = v.GetInt(\"channel_max_length\")\n\tcfg.ClientPresenceUpdateInterval = GetDuration(\"client_presence_update_interval\")\n\tcfg.ClientExpiredCloseDelay = GetDuration(\"client_expired_close_delay\")\n\tcfg.ClientExpiredSubCloseDelay = GetDuration(\"client_expired_sub_close_delay\")\n\tcfg.ClientStaleCloseDelay = GetDuration(\"client_stale_close_delay\")\n\tcfg.ClientQueueMaxSize = v.GetInt(\"client_queue_max_size\")\n\tcfg.ClientChannelLimit = v.GetInt(\"client_channel_limit\")\n\tcfg.ClientChannelPositionCheckDelay = GetDuration(\"client_channel_position_check_delay\")\n\tcfg.ClientChannelPositionMaxTimeLag = GetDuration(\"client_channel_position_max_time_lag\")\n\tcfg.UserConnectionLimit = v.GetInt(\"client_user_connection_limit\")\n\tcfg.NodeInfoMetricsAggregateInterval = GetDuration(\"node_info_metrics_aggregate_interval\")\n\tcfg.HistoryMaxPublicationLimit = v.GetInt(\"client_history_max_publication_limit\")\n\tcfg.RecoveryMaxPublicationLimit = v.GetInt(\"client_recovery_max_publication_limit\")\n\tcfg.HistoryMetaTTL = GetDuration(\"global_history_meta_ttl\", true)\n\tcfg.ClientConnectIncludeServerTime = v.GetBool(\"client_connect_include_server_time\")\n\n\tlevel, ok := logStringToLevel[strings.ToLower(v.GetString(\"log_level\"))]\n\tif !ok {\n\t\tlevel = centrifuge.LogLevelInfo\n\t}\n\tcfg.LogLevel = level\n\tcfg.LogHandler = newLogHandler().handle\n\n\tuniCodeTransformsEnabled := viper.GetBool(\"client_connect_code_to_unidirectional_disconnect.enabled\")\n\tif uniCodeTransformsEnabled {\n\t\tvar uniCodeToDisconnectTransforms []tools.UniConnectCodeToDisconnectTransform\n\t\tif viper.IsSet(\"client_connect_code_to_unidirectional_disconnect.transforms\") {\n\t\t\ttools.DecodeSlice(viper.GetViper(), &uniCodeToDisconnectTransforms, \"client_connect_code_to_unidirectional_disconnect.transforms\")\n\t\t}\n\t\tuniCodeTransforms := make(map[uint32]centrifuge.Disconnect)\n\t\tfor _, transform := range uniCodeToDisconnectTransforms {\n\t\t\tif err := transform.Validate(); err != nil {\n\t\t\t\tlog.Fatal().Msgf(\"error validating unidirectional code to disconnect transform: %v\", err)\n\t\t\t}\n\t\t\tuniCodeTransforms[transform.Code] = centrifuge.Disconnect{Code: transform.To.Code, Reason: transform.To.Reason}\n\t\t}\n\t\tcfg.UnidirectionalCodeToDisconnect = uniCodeTransforms\n\t}\n\n\treturn cfg\n}\n\n// LogStringToLevel matches level string to Centrifuge LogLevel.\nvar logStringToLevel = map[string]centrifuge.LogLevel{\n\t\"trace\": centrifuge.LogLevelTrace,\n\t\"debug\": centrifuge.LogLevelDebug,\n\t\"info\":  centrifuge.LogLevelInfo,\n\t\"error\": centrifuge.LogLevelError,\n\t\"none\":  centrifuge.LogLevelNone,\n}\n\n// applicationName returns a name for this centrifuge. If no name provided\n// in configuration then it constructs node name based on hostname and port\nfunc applicationName() string {\n\tv := viper.GetViper()\n\n\tname := v.GetString(\"name\")\n\tif name != \"\" {\n\t\treturn name\n\t}\n\tport := v.GetString(\"port\")\n\tvar hostname string\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"?\"\n\t}\n\treturn hostname + \"_\" + port\n}\n\nfunc getPingPongConfig() centrifuge.PingPongConfig {\n\tpingInterval := GetDuration(\"ping_interval\")\n\tpongTimeout := GetDuration(\"pong_timeout\")\n\tif pingInterval <= pongTimeout {\n\t\tlog.Fatal().Msgf(\"ping_interval (%s) must be greater than pong_timeout (%s)\", pingInterval, pongTimeout)\n\t}\n\treturn centrifuge.PingPongConfig{\n\t\tPingInterval: pingInterval,\n\t\tPongTimeout:  pongTimeout,\n\t}\n}\n\nfunc websocketHandlerConfig() centrifuge.WebsocketConfig {\n\tv := viper.GetViper()\n\tcfg := centrifuge.WebsocketConfig{}\n\tcfg.Compression = v.GetBool(\"websocket_compression\")\n\tcfg.CompressionLevel = v.GetInt(\"websocket_compression_level\")\n\tcfg.CompressionMinSize = v.GetInt(\"websocket_compression_min_size\")\n\tcfg.ReadBufferSize = v.GetInt(\"websocket_read_buffer_size\")\n\tcfg.WriteBufferSize = v.GetInt(\"websocket_write_buffer_size\")\n\tcfg.UseWriteBufferPool = v.GetBool(\"websocket_use_write_buffer_pool\")\n\tcfg.WriteTimeout = GetDuration(\"websocket_write_timeout\")\n\tcfg.MessageSizeLimit = v.GetInt(\"websocket_message_size_limit\")\n\tcfg.CheckOrigin = getCheckOrigin()\n\tcfg.PingPongConfig = getPingPongConfig()\n\treturn cfg\n}\n\nfunc httpStreamHandlerConfig() centrifuge.HTTPStreamConfig {\n\treturn centrifuge.HTTPStreamConfig{\n\t\tMaxRequestBodySize: viper.GetInt(\"http_stream_max_request_body_size\"),\n\t\tPingPongConfig:     getPingPongConfig(),\n\t}\n}\n\nfunc sseHandlerConfig() centrifuge.SSEConfig {\n\treturn centrifuge.SSEConfig{\n\t\tMaxRequestBodySize: viper.GetInt(\"sse_max_request_body_size\"),\n\t\tPingPongConfig:     getPingPongConfig(),\n\t}\n}\n\nfunc emulationHandlerConfig() centrifuge.EmulationConfig {\n\treturn centrifuge.EmulationConfig{\n\t\tMaxRequestBodySize: viper.GetInt(\"emulation_max_request_body_size\"),\n\t}\n}\n\nvar warnAllowedOriginsOnce sync.Once\n\nfunc getCheckOrigin() func(r *http.Request) bool {\n\tv := viper.GetViper()\n\tallowedOrigins := v.GetStringSlice(\"allowed_origins\")\n\tif len(allowedOrigins) == 0 {\n\t\treturn func(r *http.Request) bool {\n\t\t\t// Only allow connections without Origin in this case.\n\t\t\toriginHeader := r.Header.Get(\"Origin\")\n\t\t\tif originHeader == \"\" {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tlog.Info().Str(\"origin\", originHeader).Msg(\"request Origin is not authorized due to empty allowed_origins\")\n\t\t\treturn false\n\t\t}\n\t}\n\toriginChecker, err := origin.NewPatternChecker(allowedOrigins)\n\tif err != nil {\n\t\tlog.Fatal().Msgf(\"error creating origin checker: %v\", err)\n\t}\n\tif len(allowedOrigins) == 1 && allowedOrigins[0] == \"*\" {\n\t\t// Fast path for *.\n\t\twarnAllowedOriginsOnce.Do(func() {\n\t\t\tlog.Warn().Msg(\"usage of allowed_origins * is discouraged for security reasons, consider setting exact list of origins\")\n\t\t})\n\t\treturn func(r *http.Request) bool {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn func(r *http.Request) bool {\n\t\tok := originChecker.Check(r)\n\t\tif !ok {\n\t\t\tlog.Info().Str(\"origin\", r.Header.Get(\"Origin\")).Strs(\"allowed_origins\", allowedOrigins).Msg(\"request Origin is not authorized\")\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t}\n}\n\nfunc uniWebsocketHandlerConfig() uniws.Config {\n\tv := viper.GetViper()\n\treturn uniws.Config{\n\t\tCompression:        v.GetBool(\"uni_websocket_compression\"),\n\t\tCompressionLevel:   v.GetInt(\"uni_websocket_compression_level\"),\n\t\tCompressionMinSize: v.GetInt(\"uni_websocket_compression_min_size\"),\n\t\tReadBufferSize:     v.GetInt(\"uni_websocket_read_buffer_size\"),\n\t\tWriteBufferSize:    v.GetInt(\"uni_websocket_write_buffer_size\"),\n\t\tUseWriteBufferPool: v.GetBool(\"uni_websocket_use_write_buffer_pool\"),\n\t\tWriteTimeout:       GetDuration(\"uni_websocket_write_timeout\"),\n\t\tMessageSizeLimit:   v.GetInt(\"uni_websocket_message_size_limit\"),\n\t\tCheckOrigin:        getCheckOrigin(),\n\t\tPingPongConfig:     getPingPongConfig(),\n\t}\n}\n\nfunc uniSSEHandlerConfig() unisse.Config {\n\tconnectCodeToHttpStatusEnabled := viper.GetBool(\"uni_sse_connect_code_to_http_response.enabled\")\n\tvar connectCodeToHTTPStatusTransforms []tools.ConnectCodeToHTTPStatusTransform\n\tif viper.IsSet(\"uni_sse_connect_code_to_http_response.transforms\") {\n\t\ttools.DecodeSlice(viper.GetViper(), &connectCodeToHTTPStatusTransforms, \"uni_sse_connect_code_to_http_response.transforms\")\n\t}\n\tfor i, transform := range connectCodeToHTTPStatusTransforms {\n\t\tif err := transform.Validate(); err != nil {\n\t\t\tlog.Fatal().Msgf(\"error validating uni_sse_connect_code_to_http_response.transforms[%d]: %v\", i, err)\n\t\t}\n\t}\n\treturn unisse.Config{\n\t\tMaxRequestBodySize: viper.GetInt(\"uni_sse_max_request_body_size\"),\n\t\tPingPongConfig:     getPingPongConfig(),\n\t\tConnectCodeToHTTPStatus: tools.ConnectCodeToHTTPStatus{\n\t\t\tEnabled:    connectCodeToHttpStatusEnabled,\n\t\t\tTransforms: connectCodeToHTTPStatusTransforms,\n\t\t},\n\t}\n}\n\nfunc uniStreamHandlerConfig() unihttpstream.Config {\n\tconnectCodeToHttpStatusEnabled := viper.GetBool(\"uni_http_stream_connect_code_to_http_response.enabled\")\n\tvar connectCodeToHTTPStatusTransforms []tools.ConnectCodeToHTTPStatusTransform\n\tif viper.IsSet(\"uni_http_stream_connect_code_to_http_response.transforms\") {\n\t\ttools.DecodeSlice(viper.GetViper(), &connectCodeToHTTPStatusTransforms, \"uni_http_stream_connect_code_to_http_response.transforms\")\n\t}\n\tfor i, transform := range connectCodeToHTTPStatusTransforms {\n\t\tif err := transform.Validate(); err != nil {\n\t\t\tlog.Fatal().Msgf(\"error validating uni_http_stream_connect_code_to_http_response.transforms[%d]: %v\", i, err)\n\t\t}\n\t}\n\treturn unihttpstream.Config{\n\t\tMaxRequestBodySize: viper.GetInt(\"uni_http_stream_max_request_body_size\"),\n\t\tPingPongConfig:     getPingPongConfig(),\n\t\tConnectCodeToHTTPStatus: tools.ConnectCodeToHTTPStatus{\n\t\t\tEnabled:    connectCodeToHttpStatusEnabled,\n\t\t\tTransforms: connectCodeToHTTPStatusTransforms,\n\t\t},\n\t}\n}\n\nfunc uniGRPCHandlerConfig() unigrpc.Config {\n\treturn unigrpc.Config{}\n}\n\nfunc sockjsHandlerConfig() sockjs.Config {\n\tv := viper.GetViper()\n\tcfg := sockjs.Config{}\n\tcfg.URL = v.GetString(\"sockjs_url\")\n\tcfg.WebsocketReadBufferSize = v.GetInt(\"websocket_read_buffer_size\")\n\tcfg.WebsocketWriteBufferSize = v.GetInt(\"websocket_write_buffer_size\")\n\tcfg.WebsocketUseWriteBufferPool = v.GetBool(\"websocket_use_write_buffer_pool\")\n\tcfg.WebsocketWriteTimeout = GetDuration(\"websocket_write_timeout\")\n\tcfg.CheckOrigin = getCheckOrigin()\n\tcfg.WebsocketCheckOrigin = getCheckOrigin()\n\tcfg.PingPongConfig = getPingPongConfig()\n\treturn cfg\n}\n\nfunc webTransportHandlerConfig() wt.Config {\n\treturn wt.Config{\n\t\tPingPongConfig: getPingPongConfig(),\n\t}\n}\n\nfunc adminHandlerConfig() admin.Config {\n\tv := viper.GetViper()\n\tcfg := admin.Config{}\n\tcfg.WebFS = webui.FS\n\tcfg.WebPath = v.GetString(\"admin_web_path\")\n\tcfg.WebProxyAddress = v.GetString(\"admin_web_proxy_address\")\n\tcfg.Password = v.GetString(\"admin_password\")\n\tcfg.Secret = v.GetString(\"admin_secret\")\n\tcfg.Insecure = v.GetBool(\"admin_insecure\")\n\tcfg.Prefix = v.GetString(\"admin_handler_prefix\")\n\treturn cfg\n}\n\nfunc memoryEngine(n *centrifuge.Node) (centrifuge.Broker, centrifuge.PresenceManager, string, error) {\n\tbrokerConf, err := memoryBrokerConfig()\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\tbroker, err := centrifuge.NewMemoryBroker(n, *brokerConf)\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\tpresenceManagerConf, err := memoryPresenceManagerConfig()\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\tpresenceManager, err := centrifuge.NewMemoryPresenceManager(n, *presenceManagerConf)\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\treturn broker, presenceManager, \"\", nil\n}\n\nfunc memoryBrokerConfig() (*centrifuge.MemoryBrokerConfig, error) {\n\treturn &centrifuge.MemoryBrokerConfig{}, nil\n}\n\nfunc memoryPresenceManagerConfig() (*centrifuge.MemoryPresenceManagerConfig, error) {\n\treturn &centrifuge.MemoryPresenceManagerConfig{}, nil\n}\n\nfunc addRedisShardCommonSettings(shardConf *centrifuge.RedisShardConfig) {\n\tshardConf.DB = viper.GetInt(\"redis_db\")\n\tshardConf.User = viper.GetString(\"redis_user\")\n\tshardConf.Password = viper.GetString(\"redis_password\")\n\tshardConf.ClientName = viper.GetString(\"redis_client_name\")\n\n\tif viper.GetBool(\"redis_tls\") {\n\t\ttlsConfig, err := tools.MakeTLSConfig(viper.GetViper(), \"redis_\", os.ReadFile)\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error creating Redis TLS config: %v\", err)\n\t\t}\n\t\tshardConf.TLSConfig = tlsConfig\n\t}\n\tshardConf.ConnectTimeout = GetDuration(\"redis_connect_timeout\")\n\tshardConf.IOTimeout = GetDuration(\"redis_io_timeout\")\n\tshardConf.ForceRESP2 = viper.GetBool(\"redis_force_resp2\")\n}\n\nfunc getRedisShardConfigs() ([]centrifuge.RedisShardConfig, string, error) {\n\tvar shardConfigs []centrifuge.RedisShardConfig\n\n\tclusterShards := viper.GetStringSlice(\"redis_cluster_address\")\n\tvar useCluster bool\n\tif len(clusterShards) > 0 {\n\t\tuseCluster = true\n\t}\n\n\tif useCluster {\n\t\tfor _, clusterAddress := range clusterShards {\n\t\t\tclusterAddresses := strings.Split(clusterAddress, \",\")\n\t\t\tfor _, address := range clusterAddresses {\n\t\t\t\tif _, _, err := net.SplitHostPort(address); err != nil {\n\t\t\t\t\treturn nil, \"\", fmt.Errorf(\"malformed Redis Cluster address: %s\", address)\n\t\t\t\t}\n\t\t\t}\n\t\t\tconf := &centrifuge.RedisShardConfig{\n\t\t\t\tClusterAddresses: clusterAddresses,\n\t\t\t}\n\t\t\taddRedisShardCommonSettings(conf)\n\t\t\tshardConfigs = append(shardConfigs, *conf)\n\t\t}\n\t\treturn shardConfigs, \"cluster\", nil\n\t}\n\n\tsentinelShards := viper.GetStringSlice(\"redis_sentinel_address\")\n\tvar useSentinel bool\n\tif len(sentinelShards) > 0 {\n\t\tuseSentinel = true\n\t}\n\n\tif useSentinel {\n\t\tfor _, sentinelAddress := range sentinelShards {\n\t\t\tsentinelAddresses := strings.Split(sentinelAddress, \",\")\n\t\t\tfor _, address := range sentinelAddresses {\n\t\t\t\tif _, _, err := net.SplitHostPort(address); err != nil {\n\t\t\t\t\treturn nil, \"\", fmt.Errorf(\"malformed Redis Sentinel address: %s\", address)\n\t\t\t\t}\n\t\t\t}\n\t\t\tconf := &centrifuge.RedisShardConfig{\n\t\t\t\tSentinelAddresses: sentinelAddresses,\n\t\t\t}\n\t\t\taddRedisShardCommonSettings(conf)\n\t\t\tconf.SentinelUser = viper.GetString(\"redis_sentinel_user\")\n\t\t\tconf.SentinelPassword = viper.GetString(\"redis_sentinel_password\")\n\t\t\tconf.SentinelMasterName = viper.GetString(\"redis_sentinel_master_name\")\n\t\t\tif conf.SentinelMasterName == \"\" {\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"master name must be set when using Redis Sentinel\")\n\t\t\t}\n\t\t\tconf.SentinelClientName = viper.GetString(\"redis_sentinel_client_name\")\n\t\t\tif viper.GetBool(\"redis_sentinel_tls\") {\n\t\t\t\ttlsConfig, err := tools.MakeTLSConfig(viper.GetViper(), \"redis_sentinel_\", os.ReadFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal().Msgf(\"error creating Redis Sentinel TLS config: %v\", err)\n\t\t\t\t}\n\t\t\t\tconf.SentinelTLSConfig = tlsConfig\n\t\t\t}\n\t\t\tshardConfigs = append(shardConfigs, *conf)\n\t\t}\n\t\treturn shardConfigs, \"sentinel\", nil\n\t}\n\n\tredisAddresses := viper.GetStringSlice(\"redis_address\")\n\tif len(redisAddresses) == 0 {\n\t\tredisAddresses = []string{\"127.0.0.1:6379\"}\n\t}\n\tfor _, redisAddress := range redisAddresses {\n\t\tconf := &centrifuge.RedisShardConfig{\n\t\t\tAddress: redisAddress,\n\t\t}\n\t\taddRedisShardCommonSettings(conf)\n\t\tshardConfigs = append(shardConfigs, *conf)\n\t}\n\n\treturn shardConfigs, \"standalone\", nil\n}\n\nfunc getRedisShards(n *centrifuge.Node) ([]*centrifuge.RedisShard, string, error) {\n\tredisShardConfigs, mode, err := getRedisShardConfigs()\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\tredisShards := make([]*centrifuge.RedisShard, 0, len(redisShardConfigs))\n\n\tfor _, redisConf := range redisShardConfigs {\n\t\tredisShard, err := centrifuge.NewRedisShard(n, redisConf)\n\t\tif err != nil {\n\t\t\treturn nil, \"\", err\n\t\t}\n\t\tredisShards = append(redisShards, redisShard)\n\t}\n\n\tif len(redisShards) > 1 {\n\t\tmode += \"_sharded\"\n\t}\n\n\treturn redisShards, mode, nil\n}\n\nfunc initNatsBroker(node *centrifuge.Node) (*natsbroker.NatsBroker, error) {\n\treplacements, err := tools.MapStringString(viper.GetViper(), \"nats_raw_mode.channel_replacements\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error parsing nats_raw_mode_channel_replacements: %v\", err)\n\t}\n\ttlsConfig, err := tools.ExtractGoTLSConfig(viper.GetViper(), \"nats_tls\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error configuring nats tls: %v\", err)\n\t}\n\treturn natsbroker.New(node, natsbroker.Config{\n\t\tURL:            viper.GetString(\"nats_url\"),\n\t\tPrefix:         viper.GetString(\"nats_prefix\"),\n\t\tDialTimeout:    GetDuration(\"nats_dial_timeout\"),\n\t\tWriteTimeout:   GetDuration(\"nats_write_timeout\"),\n\t\tAllowWildcards: viper.GetBool(\"nats_allow_wildcards\"),\n\t\tTLS:            tlsConfig,\n\t\tRawMode: natsbroker.RawModeConfig{\n\t\t\tEnabled:             viper.GetBool(\"nats_raw_mode.enabled\"),\n\t\t\tPrefix:              viper.GetString(\"nats_raw_mode.prefix\"),\n\t\t\tChannelReplacements: replacements,\n\t\t},\n\t})\n}\n\nfunc redisEngine(n *centrifuge.Node) (*centrifuge.RedisBroker, centrifuge.PresenceManager, string, error) {\n\tredisShards, mode, err := getRedisShards(n)\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\n\tbroker, err := centrifuge.NewRedisBroker(n, centrifuge.RedisBrokerConfig{\n\t\tShards:     redisShards,\n\t\tPrefix:     viper.GetString(\"redis_prefix\"),\n\t\tUseLists:   viper.GetBool(\"redis_use_lists\"),\n\t\tSkipPubSub: viper.GetString(\"broker\") == \"redisnats\",\n\t})\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\n\tpresenceManagerConfig := centrifuge.RedisPresenceManagerConfig{\n\t\tShards:          redisShards,\n\t\tPrefix:          viper.GetString(\"redis_prefix\"),\n\t\tPresenceTTL:     GetDuration(\"global_presence_ttl\", true),\n\t\tUseHashFieldTTL: viper.GetBool(\"redis_presence_hash_field_ttl\"),\n\t}\n\tif viper.GetBool(\"global_redis_presence_user_mapping\") {\n\t\tpresenceManagerConfig.EnableUserMapping = func(_ string) bool {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tpresenceManager, err := centrifuge.NewRedisPresenceManager(n, presenceManagerConfig)\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\n\treturn broker, presenceManager, mode, nil\n}\n\nfunc getTarantoolShardConfigs() ([]tntengine.ShardConfig, string, error) {\n\tvar shardConfigs []tntengine.ShardConfig\n\n\tmode := tntengine.ConnectionModeSingleInstance\n\tif viper.IsSet(\"tarantool_mode\") {\n\t\tswitch viper.GetString(\"tarantool_mode\") {\n\t\tcase \"standalone\":\n\t\t\t// default.\n\t\tcase \"leader-follower\":\n\t\t\tmode = tntengine.ConnectionModeLeaderFollower\n\t\tcase \"leader-follower-raft\":\n\t\t\tmode = tntengine.ConnectionModeLeaderFollowerRaft\n\t\tdefault:\n\t\t\treturn nil, \"\", fmt.Errorf(\"unknown Tarantool mode: %s\", viper.GetString(\"tarantool_mode\"))\n\t\t}\n\t}\n\n\tvar shardAddresses [][]string\n\n\ttarantoolAddresses := viper.GetStringSlice(\"tarantool_address\")\n\tfor _, shardPart := range tarantoolAddresses {\n\t\tshardAddresses = append(shardAddresses, strings.Split(shardPart, \",\"))\n\t}\n\n\tfor _, tarantoolAddresses := range shardAddresses {\n\t\tconf := &tntengine.ShardConfig{\n\t\t\tAddresses:      tarantoolAddresses,\n\t\t\tUser:           viper.GetString(\"tarantool_user\"),\n\t\t\tPassword:       viper.GetString(\"tarantool_password\"),\n\t\t\tConnectionMode: mode,\n\t\t}\n\t\tshardConfigs = append(shardConfigs, *conf)\n\t}\n\treturn shardConfigs, string(mode), nil\n}\n\nfunc getTarantoolShards() ([]*tntengine.Shard, string, error) {\n\ttarantoolShardConfigs, mode, err := getTarantoolShardConfigs()\n\tif err != nil {\n\t\treturn nil, mode, err\n\t}\n\ttarantoolShards := make([]*tntengine.Shard, 0, len(tarantoolShardConfigs))\n\n\tfor _, tarantoolConf := range tarantoolShardConfigs {\n\t\ttarantoolShard, err := tntengine.NewShard(tarantoolConf)\n\t\tif err != nil {\n\t\t\treturn nil, mode, err\n\t\t}\n\t\ttarantoolShards = append(tarantoolShards, tarantoolShard)\n\t}\n\n\tif len(tarantoolShards) > 1 {\n\t\tmode += \"_sharded\"\n\t}\n\n\treturn tarantoolShards, mode, nil\n}\n\nfunc tarantoolEngine(n *centrifuge.Node) (centrifuge.Broker, centrifuge.PresenceManager, string, error) {\n\ttarantoolShards, mode, err := getTarantoolShards()\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\tbroker, err := tntengine.NewBroker(n, tntengine.BrokerConfig{\n\t\tShards: tarantoolShards,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\tpresenceManager, err := tntengine.NewPresenceManager(n, tntengine.PresenceManagerConfig{\n\t\tShards:      tarantoolShards,\n\t\tPresenceTTL: GetDuration(\"global_presence_ttl\", true),\n\t})\n\tif err != nil {\n\t\treturn nil, nil, \"\", err\n\t}\n\treturn broker, presenceManager, mode, nil\n}\n\ntype logHandler struct {\n\tentries chan centrifuge.LogEntry\n}\n\nfunc newLogHandler() *logHandler {\n\th := &logHandler{\n\t\tentries: make(chan centrifuge.LogEntry, 64),\n\t}\n\tgo h.readEntries()\n\treturn h\n}\n\nfunc (h *logHandler) readEntries() {\n\tfor entry := range h.entries {\n\t\tvar l *zerolog.Event\n\t\tswitch entry.Level {\n\t\tcase centrifuge.LogLevelTrace:\n\t\t\tl = log.Trace()\n\t\tcase centrifuge.LogLevelDebug:\n\t\t\tl = log.Debug()\n\t\tcase centrifuge.LogLevelInfo:\n\t\t\tl = log.Info()\n\t\tcase centrifuge.LogLevelWarn:\n\t\t\tl = log.Warn()\n\t\tcase centrifuge.LogLevelError:\n\t\t\tl = log.Error()\n\t\tdefault:\n\t\t\tcontinue\n\t\t}\n\t\tif entry.Fields != nil {\n\t\t\tl.Fields(entry.Fields).Msg(entry.Message)\n\t\t} else {\n\t\t\tl.Msg(entry.Message)\n\t\t}\n\t}\n}\n\nfunc (h *logHandler) handle(entry centrifuge.LogEntry) {\n\tselect {\n\tcase h.entries <- entry:\n\tdefault:\n\t\treturn\n\t}\n}\n\n// HandlerFlag is a bit mask of handlers that must be enabled in mux.\ntype HandlerFlag int\n\nconst (\n\t// HandlerWebsocket enables Raw Websocket handler.\n\tHandlerWebsocket HandlerFlag = 1 << iota\n\t// HandlerSockJS enables SockJS handler.\n\tHandlerSockJS\n\t// HandlerWebtransport enables Webtransport handler (requires HTTP/3)\n\tHandlerWebtransport\n\t// HandlerAPI enables API handler.\n\tHandlerAPI\n\t// HandlerAdmin enables admin web interface.\n\tHandlerAdmin\n\t// HandlerDebug enables debug handlers.\n\tHandlerDebug\n\t// HandlerPrometheus enables Prometheus handler.\n\tHandlerPrometheus\n\t// HandlerHealth enables Health check endpoint.\n\tHandlerHealth\n\t// HandlerUniWebsocket enables unidirectional websocket endpoint.\n\tHandlerUniWebsocket\n\t// HandlerUniSSE enables unidirectional SSE endpoint.\n\tHandlerUniSSE\n\t// HandlerUniHTTPStream enables unidirectional HTTP stream endpoint.\n\tHandlerUniHTTPStream\n\t// HandlerSSE enables bidirectional SSE endpoint (with emulation layer).\n\tHandlerSSE\n\t// HandlerHTTPStream enables bidirectional HTTP stream endpoint (with emulation layer).\n\tHandlerHTTPStream\n\t// HandlerEmulation handles client-to-server requests in an emulation layer.\n\tHandlerEmulation\n\t// HandlerSwagger handles swagger UI.\n\tHandlerSwagger\n)\n\nvar handlerText = map[HandlerFlag]string{\n\tHandlerWebsocket:     \"websocket\",\n\tHandlerSockJS:        \"sockjs\",\n\tHandlerWebtransport:  \"webtransport\",\n\tHandlerAPI:           \"api\",\n\tHandlerAdmin:         \"admin\",\n\tHandlerDebug:         \"debug\",\n\tHandlerPrometheus:    \"prometheus\",\n\tHandlerHealth:        \"health\",\n\tHandlerUniWebsocket:  \"uni_websocket\",\n\tHandlerUniSSE:        \"uni_sse\",\n\tHandlerUniHTTPStream: \"uni_http_stream\",\n\tHandlerSSE:           \"sse\",\n\tHandlerHTTPStream:    \"http_stream\",\n\tHandlerEmulation:     \"emulation\",\n\tHandlerSwagger:       \"swagger\",\n}\n\nfunc (flags HandlerFlag) String() string {\n\tflagsOrdered := []HandlerFlag{HandlerWebsocket, HandlerSockJS, HandlerWebtransport, HandlerHTTPStream, HandlerSSE, HandlerEmulation, HandlerAPI, HandlerAdmin, HandlerPrometheus, HandlerDebug, HandlerHealth, HandlerUniWebsocket, HandlerUniSSE, HandlerUniHTTPStream, HandlerSwagger}\n\tvar endpoints []string\n\tfor _, flag := range flagsOrdered {\n\t\ttext, ok := handlerText[flag]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tif flags&flag != 0 {\n\t\t\tendpoints = append(endpoints, text)\n\t\t}\n\t}\n\treturn strings.Join(endpoints, \", \")\n}\n\n// Mux returns a mux including set of default handlers for Centrifugo server.\nfunc Mux(n *centrifuge.Node, ruleContainer *rule.Container, apiExecutor *api.Executor, flags HandlerFlag, keepHeadersInContext bool, wtServer *webtransport.Server) *http.ServeMux {\n\tmux := http.NewServeMux()\n\tv := viper.GetViper()\n\n\tvar commonMiddlewares []alice.Constructor\n\n\tuseLoggingMW := zerolog.GlobalLevel() <= zerolog.DebugLevel\n\tif useLoggingMW {\n\t\tcommonMiddlewares = append(commonMiddlewares, middleware.LogRequest)\n\t}\n\n\tbasicMiddlewares := append([]alice.Constructor{}, commonMiddlewares...)\n\tbasicChain := alice.New(basicMiddlewares...)\n\n\tif flags&HandlerDebug != 0 {\n\t\tmux.Handle(\"/debug/pprof/\", basicChain.Then(http.HandlerFunc(pprof.Index)))\n\t\tmux.Handle(\"/debug/pprof/cmdline\", basicChain.Then(http.HandlerFunc(pprof.Cmdline)))\n\t\tmux.Handle(\"/debug/pprof/profile\", basicChain.Then(http.HandlerFunc(pprof.Profile)))\n\t\tmux.Handle(\"/debug/pprof/symbol\", basicChain.Then(http.HandlerFunc(pprof.Symbol)))\n\t\tmux.Handle(\"/debug/pprof/trace\", basicChain.Then(http.HandlerFunc(pprof.Trace)))\n\t}\n\n\tif flags&HandlerEmulation != 0 {\n\t\t// register bidirectional SSE connection endpoint.\n\t\temulationMiddlewares := append([]alice.Constructor{}, commonMiddlewares...)\n\t\temulationMiddlewares = append(emulationMiddlewares, middleware.NewCORS(getCheckOrigin()).Middleware)\n\t\temulationChain := alice.New(emulationMiddlewares...)\n\n\t\temulationPrefix := strings.TrimRight(v.GetString(\"emulation_handler_prefix\"), \"/\")\n\t\tif emulationPrefix == \"\" {\n\t\t\temulationPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(emulationPrefix, emulationChain.Then(centrifuge.NewEmulationHandler(n, emulationHandlerConfig())))\n\t}\n\n\tconnMiddlewares := append([]alice.Constructor{}, commonMiddlewares...)\n\tconnLimit := ruleContainer.Config().ClientConnectionLimit\n\tif connLimit > 0 {\n\t\tconnLimitMW := middleware.NewConnLimit(n, ruleContainer)\n\t\tconnMiddlewares = append(connMiddlewares, connLimitMW.Middleware)\n\t}\n\tuserIDHTTPHeader := v.GetString(\"client_user_id_http_header\")\n\tif userIDHTTPHeader != \"\" {\n\t\tconnMiddlewares = append(connMiddlewares, middleware.UserHeaderAuth(userIDHTTPHeader))\n\t}\n\tif keepHeadersInContext {\n\t\tconnMiddlewares = append(connMiddlewares, middleware.HeadersToContext)\n\t}\n\tconnMiddlewares = append(connMiddlewares, middleware.NewCORS(getCheckOrigin()).Middleware)\n\tconnChain := alice.New(connMiddlewares...)\n\n\tif flags&HandlerWebsocket != 0 {\n\t\t// register WebSocket connection endpoint.\n\t\twsPrefix := strings.TrimRight(v.GetString(\"websocket_handler_prefix\"), \"/\")\n\t\tif wsPrefix == \"\" {\n\t\t\twsPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(wsPrefix, connChain.Then(centrifuge.NewWebsocketHandler(n, websocketHandlerConfig())))\n\t}\n\n\tif flags&HandlerWebtransport != 0 {\n\t\t// register WebTransport connection endpoint.\n\t\twtPrefix := strings.TrimRight(v.GetString(\"webtransport_handler_prefix\"), \"/\")\n\t\tif wtPrefix == \"\" {\n\t\t\twtPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(wtPrefix, connChain.Then(wt.NewHandler(n, wtServer, webTransportHandlerConfig())))\n\t}\n\n\tif flags&HandlerHTTPStream != 0 {\n\t\t// register bidirectional HTTP stream connection endpoint.\n\t\tstreamPrefix := strings.TrimRight(v.GetString(\"http_stream_handler_prefix\"), \"/\")\n\t\tif streamPrefix == \"\" {\n\t\t\tstreamPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(streamPrefix, connChain.Then(centrifuge.NewHTTPStreamHandler(n, httpStreamHandlerConfig())))\n\t}\n\tif flags&HandlerSSE != 0 {\n\t\t// register bidirectional SSE connection endpoint.\n\t\tssePrefix := strings.TrimRight(v.GetString(\"sse_handler_prefix\"), \"/\")\n\t\tif ssePrefix == \"\" {\n\t\t\tssePrefix = \"/\"\n\t\t}\n\t\tmux.Handle(ssePrefix, connChain.Then(centrifuge.NewSSEHandler(n, sseHandlerConfig())))\n\t}\n\n\tif flags&HandlerSockJS != 0 {\n\t\t// register SockJS connection endpoints.\n\t\tsockjsConfig := sockjsHandlerConfig()\n\t\tsockjsPrefix := strings.TrimRight(v.GetString(\"sockjs_handler_prefix\"), \"/\")\n\t\tsockjsConfig.HandlerPrefix = sockjsPrefix\n\t\tmux.Handle(sockjsPrefix+\"/\", connChain.Then(sockjs.NewHandler(n, sockjsConfig)))\n\t}\n\n\tif flags&HandlerUniWebsocket != 0 {\n\t\t// register unidirectional WebSocket connection endpoint.\n\t\twsPrefix := strings.TrimRight(v.GetString(\"uni_websocket_handler_prefix\"), \"/\")\n\t\tif wsPrefix == \"\" {\n\t\t\twsPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(wsPrefix, connChain.Then(uniws.NewHandler(n, uniWebsocketHandlerConfig())))\n\t}\n\n\tif flags&HandlerUniSSE != 0 {\n\t\t// register unidirectional SSE connection endpoint.\n\t\tssePrefix := strings.TrimRight(v.GetString(\"uni_sse_handler_prefix\"), \"/\")\n\t\tif ssePrefix == \"\" {\n\t\t\tssePrefix = \"/\"\n\t\t}\n\t\tmux.Handle(ssePrefix, connChain.Then(unisse.NewHandler(n, uniSSEHandlerConfig())))\n\t}\n\n\tif flags&HandlerUniHTTPStream != 0 {\n\t\t// register unidirectional HTTP stream connection endpoint.\n\t\tstreamPrefix := strings.TrimRight(v.GetString(\"uni_http_stream_handler_prefix\"), \"/\")\n\t\tif streamPrefix == \"\" {\n\t\t\tstreamPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(streamPrefix, connChain.Then(unihttpstream.NewHandler(n, uniStreamHandlerConfig())))\n\t}\n\n\tif flags&HandlerAPI != 0 {\n\t\t// register HTTP API endpoints.\n\t\thttpErrorMode, err := tools.OptionalStringChoice(viper.GetViper(), \"api_error_mode\", []string{transportErrorMode})\n\t\tif err != nil {\n\t\t\tlog.Fatal().Msgf(\"error in config: %v\", err)\n\t\t}\n\t\tuseOpenTelemetry := viper.GetBool(\"opentelemetry\") && viper.GetBool(\"opentelemetry_api\")\n\t\tapiHandler := api.NewHandler(n, apiExecutor, api.Config{\n\t\t\tUseOpenTelemetry:      useOpenTelemetry,\n\t\t\tUseTransportErrorMode: httpErrorMode == transportErrorMode,\n\t\t})\n\t\tapiPrefix := strings.TrimRight(v.GetString(\"api_handler_prefix\"), \"/\")\n\t\tif apiPrefix == \"\" {\n\t\t\tapiPrefix = \"/\"\n\t\t}\n\n\t\tapiChain := func(op string) alice.Chain {\n\t\t\tapiMiddlewares := append([]alice.Constructor{}, commonMiddlewares...)\n\t\t\totelHandler := middleware.NewOpenTelemetryHandler(op, nil)\n\t\t\tif useOpenTelemetry {\n\t\t\t\tapiMiddlewares = append(apiMiddlewares, otelHandler.Middleware)\n\t\t\t}\n\t\t\tapiMiddlewares = append(apiMiddlewares, middleware.Post)\n\t\t\tif !viper.GetBool(\"api_insecure\") {\n\t\t\t\tapiMiddlewares = append(apiMiddlewares, middleware.NewAPIKeyAuth(viper.GetString(\"api_key\")).Middleware)\n\t\t\t}\n\t\t\tapiChain := alice.New(apiMiddlewares...)\n\t\t\treturn apiChain\n\t\t}\n\n\t\tmux.Handle(apiPrefix, apiChain(apiPrefix).Then(apiHandler.OldRoute()))\n\t\tif apiPrefix != \"/\" {\n\t\t\tfor path, handler := range apiHandler.Routes() {\n\t\t\t\thandlePath := apiPrefix + path\n\t\t\t\tmux.Handle(handlePath, apiChain(handlePath).Then(handler))\n\t\t\t}\n\t\t} else {\n\t\t\tfor path, handler := range apiHandler.Routes() {\n\t\t\t\tmux.Handle(path, apiChain(path).Then(handler))\n\t\t\t}\n\t\t}\n\t}\n\n\tif flags&HandlerSwagger != 0 {\n\t\t// register Swagger UI endpoint.\n\t\tswaggerPrefix := strings.TrimRight(v.GetString(\"swagger_handler_prefix\"), \"/\") + \"/\"\n\t\tif swaggerPrefix == \"\" {\n\t\t\tswaggerPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(swaggerPrefix, basicChain.Then(http.StripPrefix(swaggerPrefix, http.FileServer(swaggerui.FS))))\n\t}\n\n\tif flags&HandlerPrometheus != 0 {\n\t\t// register Prometheus metrics export endpoint.\n\t\tprometheusPrefix := strings.TrimRight(v.GetString(\"prometheus_handler_prefix\"), \"/\")\n\t\tif prometheusPrefix == \"\" {\n\t\t\tprometheusPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(prometheusPrefix, basicChain.Then(promhttp.Handler()))\n\t}\n\n\tif flags&HandlerAdmin != 0 {\n\t\t// register admin web interface API endpoints.\n\t\tadminPrefix := strings.TrimRight(v.GetString(\"admin_handler_prefix\"), \"/\")\n\t\tmux.Handle(adminPrefix+\"/\", basicChain.Then(admin.NewHandler(n, apiExecutor, adminHandlerConfig())))\n\t}\n\n\tif flags&HandlerHealth != 0 {\n\t\thealthPrefix := strings.TrimRight(v.GetString(\"health_handler_prefix\"), \"/\")\n\t\tif healthPrefix == \"\" {\n\t\t\thealthPrefix = \"/\"\n\t\t}\n\t\tmux.Handle(healthPrefix, basicChain.Then(health.NewHandler(n, health.Config{})))\n\t}\n\n\treturn mux\n}\n"
        },
        {
          "name": "misc",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}