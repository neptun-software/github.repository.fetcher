{
  "metadata": {
    "timestamp": 1736567655559,
    "page": 238,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "google/gopacket",
      "stars": 6402,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5771484375,
          "content": "# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n#*\n*~\n\n# examples binaries\nexamples/synscan/synscan\nexamples/pfdump/pfdump\nexamples/pcapdump/pcapdump\nexamples/httpassembly/httpassembly\nexamples/statsassembly/statsassembly\nexamples/arpscan/arpscan\nexamples/bidirectional/bidirectional\nexamples/bytediff/bytediff\nexamples/reassemblydump/reassemblydump\nlayers/gen\nmacs/gen\npcap/pcap_tester\n"
        },
        {
          "name": ".travis.gofmt.sh",
          "type": "blob",
          "size": 0.1611328125,
          "content": "#!/bin/bash\n\ncd \"$(dirname $0)\"\nif [ -n \"$(go fmt ./...)\" ]; then\n  echo \"Go code is not formatted, run 'go fmt github.com/google/stenographer/...'\" >&2\n  exit 1\nfi\n"
        },
        {
          "name": ".travis.golint.sh",
          "type": "blob",
          "size": 0.69921875,
          "content": "#!/bin/bash\n\ncd \"$(dirname $0)\"\n\ngo get golang.org/x/lint/golint\nDIRS=\". tcpassembly tcpassembly/tcpreader ip4defrag reassembly macs pcapgo pcap afpacket pfring routing defrag/lcmdefrag\"\n# Add subdirectories here as we clean up golint on each.\nfor subdir in $DIRS; do\n  pushd $subdir\n  if golint |\n      grep -v CannotSetRFMon |  # pcap exported error name\n      grep -v DataLost |        # tcpassembly/tcpreader exported error name\n      grep .; then\n    exit 1\n  fi\n  popd\ndone\n\npushd layers\nfor file in *.go; do\n  if cat .lint_blacklist | grep -q $file; then\n    echo \"Skipping lint of $file due to .lint_blacklist\"\n  elif golint $file | grep .; then\n    echo \"Lint error in file $file\"\n    exit 1\n  fi\ndone\npopd\n"
        },
        {
          "name": ".travis.govet.sh",
          "type": "blob",
          "size": 0.2060546875,
          "content": "#!/bin/bash\n\ncd \"$(dirname $0)\"\nDIRS=\". layers pcap pcapgo tcpassembly tcpassembly/tcpreader routing ip4defrag bytediff macs defrag/lcmdefrag\"\nset -e\nfor subdir in $DIRS; do\n  pushd $subdir\n  go vet\n  popd\ndone\n"
        },
        {
          "name": ".travis.install.sh",
          "type": "blob",
          "size": 0.2236328125,
          "content": "#!/bin/bash\n\nset -ev\n\ngo get github.com/google/gopacket\ngo get github.com/google/gopacket/layers\ngo get github.com/google/gopacket/tcpassembly\ngo get github.com/google/gopacket/reassembly\ngo get github.com/google/gopacket/pcapgo\n"
        },
        {
          "name": ".travis.script.sh",
          "type": "blob",
          "size": 0.3232421875,
          "content": "#!/bin/bash\n\nset -ev\n\ngo test github.com/google/gopacket\ngo test github.com/google/gopacket/layers\ngo test github.com/google/gopacket/tcpassembly\ngo test github.com/google/gopacket/reassembly\ngo test github.com/google/gopacket/pcapgo\ngo test github.com/google/gopacket/pcap\nsudo $(which go) test github.com/google/gopacket/routing\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.0634765625,
          "content": "language: go\ngo:\n - 1.11.x\n - 1.12.x\n - 1.13.x\n - master\n\naddons:\n  apt:\n    packages:\n      libpcap-dev\n\n# use modules except for older versions (see below)\ninstall: true\n\nenv:\n  - GO111MODULE=on\n\nscript: ./.travis.script.sh\n\nmatrix:\n  fast_finish: true\n  allow_failures:\n    - go: master\n\njobs:\n  include:\n    - go: 1.5.x\n      install: ./.travis.install.sh\n    - go: 1.6.x\n      install: ./.travis.install.sh\n    - go: 1.7.x\n      install: ./.travis.install.sh\n    - go: 1.8.x\n      install: ./.travis.install.sh\n    - go: 1.9.x\n      install: ./.travis.install.sh\n    - go: 1.10.x\n      install: ./.travis.install.sh\n    - os: osx\n      go: 1.x\n# windows doesn't work on travis (package installation just hangs and then errors out)\n#    - os: windows\n#      go: 1.x\n#      # We don't need nmap - but that's the only way to get npcap:\n#      before_install: choco install npcap --version 0.86 -y\n    - stage: style\n      name: \"fmt/vet/lint\"\n      go: 1.x\n      script:\n        - ./.travis.gofmt.sh\n        - ./.travis.govet.sh\n        - ./.travis.golint.sh\n\nstages:\n  - style\n  - test\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 1.7021484375,
          "content": "AUTHORS AND MAINTAINERS:\n\nMAIN DEVELOPERS:\nGraeme Connell   <gconnell@google.com, gsconnell@gmail.com>\n\nAUTHORS:\nNigel Tao <nigeltao@google.com>\nCole Mickens <cole.mickens@gmail.com>\nBen Daglish <bdaglish@restorepoint.com>\nLuis Martinez <martinezlc99@gmail.com>\nRemco Verhoef <remco@dutchcoders.io>\nHiroaki Kawai <Hiroaki.Kawai@gmail.com>\nLukas Lueg <lukas.lueg@gmail.com>\nLaurent Hausermann <laurent.hausermann@gmail.com>\nBill Green <bgreen@newrelic.com>\nChristian Mäder <christian.maeder@nine.ch>\nGernot Vormayr <gvormayr@gmail.com>\nVitor Garcia Graveto <victor.graveto@gmail.com>\nElias Chavarria Reyes <elchavar@cisco.com>\nDaniel Rittweiler <ripx80@protonmail.com>\n\nCONTRIBUTORS:\nAttila Oláh <attila@attilaolah.eu>\nVittus Mikiassen <matt.miki.vimik@gmail.com>\nMatthias Radestock <matthias.radestock@gmail.com>\nMatthew Sackman <matthew@wellquite.org>\nLoic Prylli <loicp@google.com>\nAlexandre Fiori <fiorix@gmail.com>\nAdrian Tam <adrian.c.m.tam@gmail.com>\nSatoshi Matsumoto <kaorimatz@gmail.com>\nDavid Stainton <dstainton415@gmail.com>\nJesse Ward <jesse@jesseward.com>\nKane Mathers <kane@kanemathers.name>\nJose Selvi <jselvi@pentester.es>\nYerden Zhumabekov <yerden.zhumabekov@gmail.com>\nJensen Hwa <jensenhwa@gmail.com>\n\n-----------------------------------------------\nFORKED FROM github.com/akrennmair/gopcap\nALL THE FOLLOWING ARE FOR THAT PROJECT\n\nMAIN DEVELOPERS:\nAndreas Krennmair <ak@synflood.at>\n\nCONTRIBUTORS:\nAndrea Nall <anall@andreanall.com>\nDaniel Arndt <danielarndt@gmail.com>\nDustin Sallings <dustin@spy.net>\nGraeme Connell <gconnell@google.com, gsconnell@gmail.com>\nGuillaume Savary <guillaume@savary.name>\nMark Smith <mark@qq.is>\nMiek Gieben <miek@miek.nl>\nMike Bell <mike@mikebell.org>\nTrevor Strohman <strohman@google.com>\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 8.7119140625,
          "content": "Contributing To gopacket\n========================\n\nSo you've got some code and you'd like it to be part of gopacket... wonderful!\nWe're happy to accept contributions, whether they're fixes to old protocols, new\nprotocols entirely, or anything else you think would improve the gopacket\nlibrary.  This document is designed to help you to do just that.\n\nThe first section deals with the plumbing:  how to actually get a change\nsubmitted.\n\nThe second section deals with coding style... Go is great in that it\nhas a uniform style implemented by 'go fmt', but there's still some decisions\nwe've made that go above and beyond, and if you follow them, they won't come up\nin your code review.\n\nThe third section deals with some of the implementation decisions we've made,\nwhich may help you to understand the current code and which we may ask you to\nconform to (or provide compelling reasons for ignoring).\n\nOverall, we hope this document will help you to understand our system and write\ngreat code which fits in, and help us to turn around on your code review quickly\nso the code can make it into the master branch as quickly as possible.\n\n\nHow To Submit Code\n------------------\n\nWe use github.com's Pull Request feature to receive code contributions from\nexternal contributors.  See\nhttps://help.github.com/articles/creating-a-pull-request/ for details on\nhow to create a request.\n\nAlso, there's a local script `gc` in the base directory of GoPacket that\nruns a local set of checks, which should give you relatively high confidence\nthat your pull won't fail github pull checks.\n\n```sh\ngo get github.com/google/gopacket\ncd $GOROOT/src/pkg/github.com/google/gopacket\ngit checkout -b <mynewfeature>  # create a new branch to work from\n... code code code ...\n./gc  # Run this to do local commits, it performs a number of checks\n```\n\nTo sum up:\n\n* DO\n    + Pull down the latest version.\n    + Make a feature-specific branch.\n    + Code using the style and methods discussed in the rest of this document.\n    + Use the ./gc command to do local commits or check correctness.\n    + Push your new feature branch up to github.com, as a pull request.\n    + Handle comments and requests from reviewers, pushing new commits up to\n      your feature branch as problems are addressed.\n    + Put interesting comments and discussions into commit comments.\n* DON'T\n    + Push to someone else's branch without their permission.\n\n\nCoding Style\n------------\n\n* Go code must be run through `go fmt`, `go vet`, and `golint`\n* Follow http://golang.org/doc/effective_go.html as much as possible.\n    + In particular, http://golang.org/doc/effective_go.html#mixed-caps.  Enums\n      should be be CamelCase, with acronyms capitalized (TCPSourcePort, vs.\n      TcpSourcePort or TCP_SOURCE_PORT).\n* Bonus points for giving enum types a String() field.\n* Any exported types or functions should have commentary\n  (http://golang.org/doc/effective_go.html#commentary)\n\n\nCoding Methods And Implementation Notes\n---------------------------------------\n\n### Error Handling\n\nMany times, you'll be decoding a protocol and run across something bad, a packet\ncorruption or the like.  How do you handle this?  First off, ALWAYS report the\nerror.  You can do this either by returning the error from the decode() function\n(most common), or if you're up for it you can implement and add an ErrorLayer\nthrough the packet builder (the first method is a simple shortcut that does\nexactly this, then stops any future decoding).\n\nOften, you'll already have decode some part of your protocol by the time you hit\nyour error.  Use your own discretion to determine whether the stuff you've\nalready decoded should be returned to the caller or not:\n\n```go\nfunc decodeMyProtocol(data []byte, p gopacket.PacketBuilder) error {\n  prot := &MyProtocol{}\n  if len(data) < 10 {\n    // This error occurred before we did ANYTHING, so there's nothing in my\n    // protocol that the caller could possibly want.  Just return the error.\n    return fmt.Errorf(\"Length %d less than 10\", len(data))\n  }\n  prot.ImportantField1 = data[:5]\n  prot.ImportantField2 = data[5:10]\n  // At this point, we've already got enough information in 'prot' to\n  // warrant returning it to the caller, so we'll add it now.\n  p.AddLayer(prot)\n  if len(data) < 15 {\n    // We encountered an error later in the packet, but the caller already\n    // has the important info we've gleaned so far.\n    return fmt.Errorf(\"Length %d less than 15\", len(data))\n  }\n  prot.ImportantField3 = data[10:15]\n  return nil  // We've already added the layer, we can just return success.\n}\n```\n\nIn general, our code follows the approach of returning the first error it\nencounters.  In general, we don't trust any bytes after the first error we see.\n\n### What Is A Layer?\n\nThe definition of a layer is up to the discretion of the coder.  It should be\nsomething important enough that it's actually useful to the caller (IE: every\nTLV value should probably NOT be a layer).  However, it can be more granular\nthan a single protocol... IPv6 and SCTP both implement many layers to handle the\nvarious parts of the protocol.  Use your best judgement, and prepare to defend\nyour decisions during code review. ;)\n\n### Performance\n\nWe strive to make gopacket as fast as possible while still providing lots of\nfeatures.  In general, this means:\n\n* Focus performance tuning on common protocols (IP4/6, TCP, etc), and optimize\n  others on an as-needed basis (tons of MPLS on your network?  Time to optimize\n  MPLS!)\n* Use fast operations.  See the toplevel benchmark_test for benchmarks of some\n  of Go's underlying features and types.\n* Test your performance changes!  You should use the ./gc script's --benchmark\n  flag to submit any performance-related changes.  Use pcap/gopacket_benchmark\n  to test your change against a PCAP file based on your traffic patterns.\n* Don't be TOO hacky.  Sometimes, removing an unused struct from a field causes\n  a huge performance hit, due to the way that Go currently handles its segmented\n  stack... don't be afraid to clean it up anyway.  We'll trust the Go compiler\n  to get good enough over time to handle this.  Also, this type of\n  compiler-specific optimization is very fragile; someone adding a field to an\n  entirely different struct elsewhere in the codebase could reverse any gains\n  you might achieve by aligning your allocations.\n* Try to minimize memory allocations.  If possible, use []byte to reference\n  pieces of the input, instead of using string, which requires copying the bytes\n  into a new memory allocation.\n* Think hard about what should be evaluated lazily vs. not.  In general, a\n  layer's struct should almost exactly mirror the layer's frame.  Anything\n  that's more interesting should be a function.  This may not always be\n  possible, but it's a good rule of thumb.\n* Don't fear micro-optimizations.  With the above in mind, we welcome\n  micro-optimizations that we think will have positive/neutral impacts on the\n  majority of workloads.  A prime example of this is pre-allocating certain\n  structs within a larger one:\n\n```go\ntype MyProtocol struct {\n  // Most packets have 1-4 of VeryCommon, so we preallocate it here.\n  initialAllocation [4]uint32\n  VeryCommon []uint32\n}\n\nfunc decodeMyProtocol(data []byte, p gopacket.PacketBuilder) error {\n  prot := &MyProtocol{}\n  prot.VeryCommon = proto.initialAllocation[:0]\n  for len(data) > 4 {\n    field := binary.BigEndian.Uint32(data[:4])\n    data = data[4:]\n    // Since we're using the underlying initialAllocation, we won't need to\n    // allocate new memory for the following append unless we more than 16\n    // bytes of data, which should be the uncommon case.\n    prot.VeryCommon = append(prot.VeryCommon, field)\n  }\n  p.AddLayer(prot)\n  if len(data) > 0 {\n    return fmt.Errorf(\"MyProtocol packet has %d bytes left after decoding\", len(data))\n  }\n  return nil\n}\n```\n\n### Slices And Data\n\nIf you're pulling a slice from the data you're decoding, don't copy it.  Just\nuse the slice itself.\n\n```go\ntype MyProtocol struct {\n  A, B net.IP\n}\nfunc decodeMyProtocol(data []byte, p gopacket.PacketBuilder) error {\n  p.AddLayer(&MyProtocol{\n    A: data[:4],\n    B: data[4:8],\n  })\n  return nil\n}\n```\n\nThe caller has already agreed, by using this library, that they won't modify the\nset of bytes they pass in to the decoder, or the library has already copied the\nset of bytes to a read-only location.  See DecodeOptions.NoCopy for more\ninformation.\n\n### Enums/Types\n\nIf a protocol has an integer field (uint8, uint16, etc) with a couple of known\nvalues that mean something special, make it a type.  This allows us to do really\nnice things like adding a String() function to them, so we can more easily\ndisplay those to users.  Check out layers/enums.go for one example, as well as\nlayers/icmp.go for layer-specific enums.\n\nWhen naming things, try for descriptiveness over suscinctness.  For example,\nchoose DNSResponseRecord over DNSRR.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.5185546875,
          "content": "Copyright (c) 2012 Google, Inc. All rights reserved.\nCopyright (c) 2009-2011 Andreas Krennmair. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n   * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n   * Neither the name of Andreas Krennmair, Google, nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.6357421875,
          "content": "# GoPacket\n\nThis library provides packet decoding capabilities for Go.\nSee [godoc](https://godoc.org/github.com/google/gopacket) for more details.\n\n[![Build Status](https://travis-ci.org/google/gopacket.svg?branch=master)](https://travis-ci.org/google/gopacket)\n[![GoDoc](https://godoc.org/github.com/google/gopacket?status.svg)](https://godoc.org/github.com/google/gopacket)\n\nMinimum Go version required is 1.5 except for pcapgo/EthernetHandle, afpacket, and bsdbpf which need at least 1.9 due to x/sys/unix dependencies.\n\nOriginally forked from the gopcap project written by Andreas\nKrennmair <ak@synflood.at> (http://github.com/akrennmair/gopcap).\n"
        },
        {
          "name": "afpacket",
          "type": "tree",
          "content": null
        },
        {
          "name": "base.go",
          "type": "blob",
          "size": 5.580078125,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n)\n\n// Layer represents a single decoded packet layer (using either the\n// OSI or TCP/IP definition of a layer).  When decoding, a packet's data is\n// broken up into a number of layers.  The caller may call LayerType() to\n// figure out which type of layer they've received from the packet.  Optionally,\n// they may then use a type assertion to get the actual layer type for deep\n// inspection of the data.\ntype Layer interface {\n\t// LayerType is the gopacket type for this layer.\n\tLayerType() LayerType\n\t// LayerContents returns the set of bytes that make up this layer.\n\tLayerContents() []byte\n\t// LayerPayload returns the set of bytes contained within this layer, not\n\t// including the layer itself.\n\tLayerPayload() []byte\n}\n\n// Payload is a Layer containing the payload of a packet.  The definition of\n// what constitutes the payload of a packet depends on previous layers; for\n// TCP and UDP, we stop decoding above layer 4 and return the remaining\n// bytes as a Payload.  Payload is an ApplicationLayer.\ntype Payload []byte\n\n// LayerType returns LayerTypePayload\nfunc (p Payload) LayerType() LayerType { return LayerTypePayload }\n\n// LayerContents returns the bytes making up this layer.\nfunc (p Payload) LayerContents() []byte { return []byte(p) }\n\n// LayerPayload returns the payload within this layer.\nfunc (p Payload) LayerPayload() []byte { return nil }\n\n// Payload returns this layer as bytes.\nfunc (p Payload) Payload() []byte { return []byte(p) }\n\n// String implements fmt.Stringer.\nfunc (p Payload) String() string { return fmt.Sprintf(\"%d byte(s)\", len(p)) }\n\n// GoString implements fmt.GoStringer.\nfunc (p Payload) GoString() string { return LongBytesGoString([]byte(p)) }\n\n// CanDecode implements DecodingLayer.\nfunc (p Payload) CanDecode() LayerClass { return LayerTypePayload }\n\n// NextLayerType implements DecodingLayer.\nfunc (p Payload) NextLayerType() LayerType { return LayerTypeZero }\n\n// DecodeFromBytes implements DecodingLayer.\nfunc (p *Payload) DecodeFromBytes(data []byte, df DecodeFeedback) error {\n\t*p = Payload(data)\n\treturn nil\n}\n\n// SerializeTo writes the serialized form of this layer into the\n// SerializationBuffer, implementing gopacket.SerializableLayer.\n// See the docs for gopacket.SerializableLayer for more info.\nfunc (p Payload) SerializeTo(b SerializeBuffer, opts SerializeOptions) error {\n\tbytes, err := b.PrependBytes(len(p))\n\tif err != nil {\n\t\treturn err\n\t}\n\tcopy(bytes, p)\n\treturn nil\n}\n\n// decodePayload decodes data by returning it all in a Payload layer.\nfunc decodePayload(data []byte, p PacketBuilder) error {\n\tpayload := &Payload{}\n\tif err := payload.DecodeFromBytes(data, p); err != nil {\n\t\treturn err\n\t}\n\tp.AddLayer(payload)\n\tp.SetApplicationLayer(payload)\n\treturn nil\n}\n\n// Fragment is a Layer containing a fragment of a larger frame, used by layers\n// like IPv4 and IPv6 that allow for fragmentation of their payloads.\ntype Fragment []byte\n\n// LayerType returns LayerTypeFragment\nfunc (p *Fragment) LayerType() LayerType { return LayerTypeFragment }\n\n// LayerContents implements Layer.\nfunc (p *Fragment) LayerContents() []byte { return []byte(*p) }\n\n// LayerPayload implements Layer.\nfunc (p *Fragment) LayerPayload() []byte { return nil }\n\n// Payload returns this layer as a byte slice.\nfunc (p *Fragment) Payload() []byte { return []byte(*p) }\n\n// String implements fmt.Stringer.\nfunc (p *Fragment) String() string { return fmt.Sprintf(\"%d byte(s)\", len(*p)) }\n\n// CanDecode implements DecodingLayer.\nfunc (p *Fragment) CanDecode() LayerClass { return LayerTypeFragment }\n\n// NextLayerType implements DecodingLayer.\nfunc (p *Fragment) NextLayerType() LayerType { return LayerTypeZero }\n\n// DecodeFromBytes implements DecodingLayer.\nfunc (p *Fragment) DecodeFromBytes(data []byte, df DecodeFeedback) error {\n\t*p = Fragment(data)\n\treturn nil\n}\n\n// SerializeTo writes the serialized form of this layer into the\n// SerializationBuffer, implementing gopacket.SerializableLayer.\n// See the docs for gopacket.SerializableLayer for more info.\nfunc (p *Fragment) SerializeTo(b SerializeBuffer, opts SerializeOptions) error {\n\tbytes, err := b.PrependBytes(len(*p))\n\tif err != nil {\n\t\treturn err\n\t}\n\tcopy(bytes, *p)\n\treturn nil\n}\n\n// decodeFragment decodes data by returning it all in a Fragment layer.\nfunc decodeFragment(data []byte, p PacketBuilder) error {\n\tpayload := &Fragment{}\n\tif err := payload.DecodeFromBytes(data, p); err != nil {\n\t\treturn err\n\t}\n\tp.AddLayer(payload)\n\tp.SetApplicationLayer(payload)\n\treturn nil\n}\n\n// These layers correspond to Internet Protocol Suite (TCP/IP) layers, and their\n// corresponding OSI layers, as best as possible.\n\n// LinkLayer is the packet layer corresponding to TCP/IP layer 1 (OSI layer 2)\ntype LinkLayer interface {\n\tLayer\n\tLinkFlow() Flow\n}\n\n// NetworkLayer is the packet layer corresponding to TCP/IP layer 2 (OSI\n// layer 3)\ntype NetworkLayer interface {\n\tLayer\n\tNetworkFlow() Flow\n}\n\n// TransportLayer is the packet layer corresponding to the TCP/IP layer 3 (OSI\n// layer 4)\ntype TransportLayer interface {\n\tLayer\n\tTransportFlow() Flow\n}\n\n// ApplicationLayer is the packet layer corresponding to the TCP/IP layer 4 (OSI\n// layer 7), also known as the packet payload.\ntype ApplicationLayer interface {\n\tLayer\n\tPayload() []byte\n}\n\n// ErrorLayer is a packet layer created when decoding of the packet has failed.\n// Its payload is all the bytes that we were unable to decode, and the returned\n// error details why the decoding failed.\ntype ErrorLayer interface {\n\tLayer\n\tError() error\n}\n"
        },
        {
          "name": "benchmark_test.go",
          "type": "blob",
          "size": 3.71484375,
          "content": "// Copyright 2012, Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"runtime\"\n\t\"testing\"\n)\n\n// A few benchmarks for figuring out exactly how fast some underlying Go\n// things are.\n\ntype testError struct{}\n\nfunc (t *testError) Error() string { return \"abc\" }\n\nfunc BenchmarkTypeAssertion(b *testing.B) {\n\tvar e error = &testError{}\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = e.(*testError)\n\t}\n}\n\nfunc BenchmarkMapLookup(b *testing.B) {\n\tm := map[LayerType]bool{\n\t\tLayerTypePayload: true,\n\t}\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = m[LayerTypePayload]\n\t}\n}\n\nfunc BenchmarkNilMapLookup(b *testing.B) {\n\tvar m map[LayerType]bool\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = m[LayerTypePayload]\n\t}\n}\n\nfunc BenchmarkNilMapLookupWithNilCheck(b *testing.B) {\n\tvar m map[LayerType]bool\n\tfor i := 0; i < b.N; i++ {\n\t\tif m != nil {\n\t\t\t_ = m[LayerTypePayload]\n\t\t}\n\t}\n}\n\nfunc BenchmarkArrayLookup(b *testing.B) {\n\tm := make([]bool, 100)\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = m[LayerTypePayload]\n\t}\n}\n\nvar testError1 = &testError{}\nvar testError2 error = testError1\n\nfunc BenchmarkTypeToInterface1(b *testing.B) {\n\tvar e error\n\tfor i := 0; i < b.N; i++ {\n\t\te = testError1\n\t}\n\t// Have to do someting with 'e' or the compiler complains about an unused\n\t// variable.\n\ttestError2 = e\n}\nfunc BenchmarkTypeToInterface2(b *testing.B) {\n\tvar e error\n\tfor i := 0; i < b.N; i++ {\n\t\te = testError2\n\t}\n\t// Have to do someting with 'e' or the compiler complains about an unused\n\t// variable.\n\ttestError2 = e\n}\n\nvar decodeOpts DecodeOptions\n\nfunc decodeOptsByValue(_ DecodeOptions)    {}\nfunc decodeOptsByPointer(_ *DecodeOptions) {}\nfunc BenchmarkPassDecodeOptionsByValue(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tdecodeOptsByValue(decodeOpts)\n\t}\n}\nfunc BenchmarkPassDecodeOptionsByPointer(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tdecodeOptsByPointer(&decodeOpts)\n\t}\n}\n\nfunc BenchmarkLockOSThread(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\truntime.LockOSThread()\n\t}\n}\nfunc BenchmarkUnlockOSThread(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\truntime.UnlockOSThread()\n\t}\n}\nfunc lockUnlock() {\n\truntime.LockOSThread()\n\truntime.UnlockOSThread()\n}\nfunc lockDeferUnlock() {\n\truntime.LockOSThread()\n\tdefer runtime.UnlockOSThread()\n}\nfunc BenchmarkLockUnlockOSThread(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tlockUnlock()\n\t}\n}\nfunc BenchmarkLockDeferUnlockOSThread(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tlockDeferUnlock()\n\t}\n}\n\nfunc BenchmarkUnbufferedChannel(b *testing.B) {\n\tca := make(chan bool)\n\tcb := make(chan bool)\n\tdefer close(ca)\n\tgo func() {\n\t\tdefer close(cb)\n\t\tfor range ca {\n\t\t\tcb <- true\n\t\t}\n\t}()\n\tfor i := 0; i < b.N; i++ {\n\t\tca <- true\n\t\t<-cb\n\t}\n}\nfunc BenchmarkSmallBufferedChannel(b *testing.B) {\n\tca := make(chan bool, 1)\n\tcb := make(chan bool, 1)\n\tdefer close(ca)\n\tgo func() {\n\t\tdefer close(cb)\n\t\tfor range ca {\n\t\t\tcb <- true\n\t\t}\n\t}()\n\tfor i := 0; i < b.N; i++ {\n\t\tca <- true\n\t\t<-cb\n\t}\n}\nfunc BenchmarkLargeBufferedChannel(b *testing.B) {\n\tca := make(chan bool, 1000)\n\tcb := make(chan bool, 1000)\n\tdefer close(ca)\n\tgo func() {\n\t\tdefer close(cb)\n\t\tfor range ca {\n\t\t\tcb <- true\n\t\t}\n\t}()\n\tfor i := 0; i < b.N; i++ {\n\t\tca <- true\n\t\t<-cb\n\t}\n}\nfunc BenchmarkEndpointFastHashShort(b *testing.B) {\n\te := Endpoint{typ: 1, len: 2}\n\tfor i := 0; i < b.N; i++ {\n\t\te.FastHash()\n\t}\n}\nfunc BenchmarkEndpointFastHashLong(b *testing.B) {\n\te := Endpoint{typ: 1, len: 16}\n\tfor i := 0; i < b.N; i++ {\n\t\te.FastHash()\n\t}\n}\nfunc BenchmarkFlowFastHashShort(b *testing.B) {\n\te := Flow{typ: 1, slen: 2, dlen: 2}\n\tfor i := 0; i < b.N; i++ {\n\t\te.FastHash()\n\t}\n}\nfunc BenchmarkFlowFastHashLong(b *testing.B) {\n\te := Flow{typ: 1, slen: 16, dlen: 16}\n\tfor i := 0; i < b.N; i++ {\n\t\te.FastHash()\n\t}\n}\n"
        },
        {
          "name": "bsdbpf",
          "type": "tree",
          "content": null
        },
        {
          "name": "bytediff",
          "type": "tree",
          "content": null
        },
        {
          "name": "decode.go",
          "type": "blob",
          "size": 5.9755859375,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"errors\"\n)\n\n// DecodeFeedback is used by DecodingLayer layers to provide decoding metadata.\ntype DecodeFeedback interface {\n\t// SetTruncated should be called if during decoding you notice that a packet\n\t// is shorter than internal layer variables (HeaderLength, or the like) say it\n\t// should be.  It sets packet.Metadata().Truncated.\n\tSetTruncated()\n}\n\ntype nilDecodeFeedback struct{}\n\nfunc (nilDecodeFeedback) SetTruncated() {}\n\n// NilDecodeFeedback implements DecodeFeedback by doing nothing.\nvar NilDecodeFeedback DecodeFeedback = nilDecodeFeedback{}\n\n// PacketBuilder is used by layer decoders to store the layers they've decoded,\n// and to defer future decoding via NextDecoder.\n// Typically, the pattern for use is:\n//  func (m *myDecoder) Decode(data []byte, p PacketBuilder) error {\n//    if myLayer, err := myDecodingLogic(data); err != nil {\n//      return err\n//    } else {\n//      p.AddLayer(myLayer)\n//    }\n//    // maybe do this, if myLayer is a LinkLayer\n//    p.SetLinkLayer(myLayer)\n//    return p.NextDecoder(nextDecoder)\n//  }\ntype PacketBuilder interface {\n\tDecodeFeedback\n\t// AddLayer should be called by a decoder immediately upon successful\n\t// decoding of a layer.\n\tAddLayer(l Layer)\n\t// The following functions set the various specific layers in the final\n\t// packet.  Note that if many layers call SetX, the first call is kept and all\n\t// other calls are ignored.\n\tSetLinkLayer(LinkLayer)\n\tSetNetworkLayer(NetworkLayer)\n\tSetTransportLayer(TransportLayer)\n\tSetApplicationLayer(ApplicationLayer)\n\tSetErrorLayer(ErrorLayer)\n\t// NextDecoder should be called by a decoder when they're done decoding a\n\t// packet layer but not done with decoding the entire packet.  The next\n\t// decoder will be called to decode the last AddLayer's LayerPayload.\n\t// Because of this, NextDecoder must only be called once all other\n\t// PacketBuilder calls have been made.  Set*Layer and AddLayer calls after\n\t// NextDecoder calls will behave incorrectly.\n\tNextDecoder(next Decoder) error\n\t// DumpPacketData is used solely for decoding.  If you come across an error\n\t// you need to diagnose while processing a packet, call this and your packet's\n\t// data will be dumped to stderr so you can create a test.  This should never\n\t// be called from a production decoder.\n\tDumpPacketData()\n\t// DecodeOptions returns the decode options\n\tDecodeOptions() *DecodeOptions\n}\n\n// Decoder is an interface for logic to decode a packet layer.  Users may\n// implement a Decoder to handle their own strange packet types, or may use one\n// of the many decoders available in the 'layers' subpackage to decode things\n// for them.\ntype Decoder interface {\n\t// Decode decodes the bytes of a packet, sending decoded values and other\n\t// information to PacketBuilder, and returning an error if unsuccessful.  See\n\t// the PacketBuilder documentation for more details.\n\tDecode([]byte, PacketBuilder) error\n}\n\n// DecodeFunc wraps a function to make it a Decoder.\ntype DecodeFunc func([]byte, PacketBuilder) error\n\n// Decode implements Decoder by calling itself.\nfunc (d DecodeFunc) Decode(data []byte, p PacketBuilder) error {\n\t// function, call thyself.\n\treturn d(data, p)\n}\n\n// DecodePayload is a Decoder that returns a Payload layer containing all\n// remaining bytes.\nvar DecodePayload Decoder = DecodeFunc(decodePayload)\n\n// DecodeUnknown is a Decoder that returns an Unknown layer containing all\n// remaining bytes, useful if you run up against a layer that you're unable to\n// decode yet.  This layer is considered an ErrorLayer.\nvar DecodeUnknown Decoder = DecodeFunc(decodeUnknown)\n\n// DecodeFragment is a Decoder that returns a Fragment layer containing all\n// remaining bytes.\nvar DecodeFragment Decoder = DecodeFunc(decodeFragment)\n\n// LayerTypeZero is an invalid layer type, but can be used to determine whether\n// layer type has actually been set correctly.\nvar LayerTypeZero = RegisterLayerType(0, LayerTypeMetadata{Name: \"Unknown\", Decoder: DecodeUnknown})\n\n// LayerTypeDecodeFailure is the layer type for the default error layer.\nvar LayerTypeDecodeFailure = RegisterLayerType(1, LayerTypeMetadata{Name: \"DecodeFailure\", Decoder: DecodeUnknown})\n\n// LayerTypePayload is the layer type for a payload that we don't try to decode\n// but treat as a success, IE: an application-level payload.\nvar LayerTypePayload = RegisterLayerType(2, LayerTypeMetadata{Name: \"Payload\", Decoder: DecodePayload})\n\n// LayerTypeFragment is the layer type for a fragment of a layer transported\n// by an underlying layer that supports fragmentation.\nvar LayerTypeFragment = RegisterLayerType(3, LayerTypeMetadata{Name: \"Fragment\", Decoder: DecodeFragment})\n\n// DecodeFailure is a packet layer created if decoding of the packet data failed\n// for some reason.  It implements ErrorLayer.  LayerContents will be the entire\n// set of bytes that failed to parse, and Error will return the reason parsing\n// failed.\ntype DecodeFailure struct {\n\tdata  []byte\n\terr   error\n\tstack []byte\n}\n\n// Error returns the error encountered during decoding.\nfunc (d *DecodeFailure) Error() error { return d.err }\n\n// LayerContents implements Layer.\nfunc (d *DecodeFailure) LayerContents() []byte { return d.data }\n\n// LayerPayload implements Layer.\nfunc (d *DecodeFailure) LayerPayload() []byte { return nil }\n\n// String implements fmt.Stringer.\nfunc (d *DecodeFailure) String() string {\n\treturn \"Packet decoding error: \" + d.Error().Error()\n}\n\n// Dump implements Dumper.\nfunc (d *DecodeFailure) Dump() (s string) {\n\tif d.stack != nil {\n\t\ts = string(d.stack)\n\t}\n\treturn\n}\n\n// LayerType returns LayerTypeDecodeFailure\nfunc (d *DecodeFailure) LayerType() LayerType { return LayerTypeDecodeFailure }\n\n// decodeUnknown \"decodes\" unsupported data types by returning an error.\n// This decoder will thus always return a DecodeFailure layer.\nfunc decodeUnknown(data []byte, p PacketBuilder) error {\n\treturn errors.New(\"Layer type not currently supported\")\n}\n"
        },
        {
          "name": "defrag",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 17.951171875,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\n/*\nPackage gopacket provides packet decoding for the Go language.\n\ngopacket contains many sub-packages with additional functionality you may find\nuseful, including:\n\n * layers: You'll probably use this every time.  This contains of the logic\n     built into gopacket for decoding packet protocols.  Note that all example\n     code below assumes that you have imported both gopacket and\n     gopacket/layers.\n * pcap: C bindings to use libpcap to read packets off the wire.\n * pfring: C bindings to use PF_RING to read packets off the wire.\n * afpacket: C bindings for Linux's AF_PACKET to read packets off the wire.\n * tcpassembly: TCP stream reassembly\n\nAlso, if you're looking to dive right into code, see the examples subdirectory\nfor numerous simple binaries built using gopacket libraries.\n\nMinimum go version required is 1.5 except for pcapgo/EthernetHandle, afpacket,\nand bsdbpf which need at least 1.7 due to x/sys/unix dependencies.\n\nBasic Usage\n\ngopacket takes in packet data as a []byte and decodes it into a packet with\na non-zero number of \"layers\".  Each layer corresponds to a protocol\nwithin the bytes.  Once a packet has been decoded, the layers of the packet\ncan be requested from the packet.\n\n // Decode a packet\n packet := gopacket.NewPacket(myPacketData, layers.LayerTypeEthernet, gopacket.Default)\n // Get the TCP layer from this packet\n if tcpLayer := packet.Layer(layers.LayerTypeTCP); tcpLayer != nil {\n   fmt.Println(\"This is a TCP packet!\")\n   // Get actual TCP data from this layer\n   tcp, _ := tcpLayer.(*layers.TCP)\n   fmt.Printf(\"From src port %d to dst port %d\\n\", tcp.SrcPort, tcp.DstPort)\n }\n // Iterate over all layers, printing out each layer type\n for _, layer := range packet.Layers() {\n   fmt.Println(\"PACKET LAYER:\", layer.LayerType())\n }\n\nPackets can be decoded from a number of starting points.  Many of our base\ntypes implement Decoder, which allow us to decode packets for which\nwe don't have full data.\n\n // Decode an ethernet packet\n ethP := gopacket.NewPacket(p1, layers.LayerTypeEthernet, gopacket.Default)\n // Decode an IPv6 header and everything it contains\n ipP := gopacket.NewPacket(p2, layers.LayerTypeIPv6, gopacket.Default)\n // Decode a TCP header and its payload\n tcpP := gopacket.NewPacket(p3, layers.LayerTypeTCP, gopacket.Default)\n\n\nReading Packets From A Source\n\nMost of the time, you won't just have a []byte of packet data lying around.\nInstead, you'll want to read packets in from somewhere (file, interface, etc)\nand process them.  To do that, you'll want to build a PacketSource.\n\nFirst, you'll need to construct an object that implements the PacketDataSource\ninterface.  There are implementations of this interface bundled with gopacket\nin the gopacket/pcap and gopacket/pfring subpackages... see their documentation\nfor more information on their usage.  Once you have a PacketDataSource, you can\npass it into NewPacketSource, along with a Decoder of your choice, to create\na PacketSource.\n\nOnce you have a PacketSource, you can read packets from it in multiple ways.\nSee the docs for PacketSource for more details.  The easiest method is the\nPackets function, which returns a channel, then asynchronously writes new\npackets into that channel, closing the channel if the packetSource hits an\nend-of-file.\n\n  packetSource := ...  // construct using pcap or pfring\n  for packet := range packetSource.Packets() {\n    handlePacket(packet)  // do something with each packet\n  }\n\nYou can change the decoding options of the packetSource by setting fields in\npacketSource.DecodeOptions... see the following sections for more details.\n\n\nLazy Decoding\n\ngopacket optionally decodes packet data lazily, meaning it\nonly decodes a packet layer when it needs to handle a function call.\n\n // Create a packet, but don't actually decode anything yet\n packet := gopacket.NewPacket(myPacketData, layers.LayerTypeEthernet, gopacket.Lazy)\n // Now, decode the packet up to the first IPv4 layer found but no further.\n // If no IPv4 layer was found, the whole packet will be decoded looking for\n // it.\n ip4 := packet.Layer(layers.LayerTypeIPv4)\n // Decode all layers and return them.  The layers up to the first IPv4 layer\n // are already decoded, and will not require decoding a second time.\n layers := packet.Layers()\n\nLazily-decoded packets are not concurrency-safe.  Since layers have not all been\ndecoded, each call to Layer() or Layers() has the potential to mutate the packet\nin order to decode the next layer.  If a packet is used\nin multiple goroutines concurrently, don't use gopacket.Lazy.  Then gopacket\nwill decode the packet fully, and all future function calls won't mutate the\nobject.\n\n\nNoCopy Decoding\n\nBy default, gopacket will copy the slice passed to NewPacket and store the\ncopy within the packet, so future mutations to the bytes underlying the slice\ndon't affect the packet and its layers.  If you can guarantee that the\nunderlying slice bytes won't be changed, you can use NoCopy to tell\ngopacket.NewPacket, and it'll use the passed-in slice itself.\n\n // This channel returns new byte slices, each of which points to a new\n // memory location that's guaranteed immutable for the duration of the\n // packet.\n for data := range myByteSliceChannel {\n   p := gopacket.NewPacket(data, layers.LayerTypeEthernet, gopacket.NoCopy)\n   doSomethingWithPacket(p)\n }\n\nThe fastest method of decoding is to use both Lazy and NoCopy, but note from\nthe many caveats above that for some implementations either or both may be\ndangerous.\n\n\nPointers To Known Layers\n\nDuring decoding, certain layers are stored in the packet as well-known\nlayer types.  For example, IPv4 and IPv6 are both considered NetworkLayer\nlayers, while TCP and UDP are both TransportLayer layers.  We support 4\nlayers, corresponding to the 4 layers of the TCP/IP layering scheme (roughly\nanagalous to layers 2, 3, 4, and 7 of the OSI model).  To access these,\nyou can use the packet.LinkLayer, packet.NetworkLayer,\npacket.TransportLayer, and packet.ApplicationLayer functions.  Each of\nthese functions returns a corresponding interface\n(gopacket.{Link,Network,Transport,Application}Layer).  The first three\nprovide methods for getting src/dst addresses for that particular layer,\nwhile the final layer provides a Payload function to get payload data.\nThis is helpful, for example, to get payloads for all packets regardless\nof their underlying data type:\n\n // Get packets from some source\n for packet := range someSource {\n   if app := packet.ApplicationLayer(); app != nil {\n     if strings.Contains(string(app.Payload()), \"magic string\") {\n       fmt.Println(\"Found magic string in a packet!\")\n     }\n   }\n }\n\nA particularly useful layer is ErrorLayer, which is set whenever there's\nan error parsing part of the packet.\n\n packet := gopacket.NewPacket(myPacketData, layers.LayerTypeEthernet, gopacket.Default)\n if err := packet.ErrorLayer(); err != nil {\n   fmt.Println(\"Error decoding some part of the packet:\", err)\n }\n\nNote that we don't return an error from NewPacket because we may have decoded\na number of layers successfully before running into our erroneous layer.  You\nmay still be able to get your Ethernet and IPv4 layers correctly, even if\nyour TCP layer is malformed.\n\n\nFlow And Endpoint\n\ngopacket has two useful objects, Flow and Endpoint, for communicating in a protocol\nindependent manner the fact that a packet is coming from A and going to B.\nThe general layer types LinkLayer, NetworkLayer, and TransportLayer all provide\nmethods for extracting their flow information, without worrying about the type\nof the underlying Layer.\n\nA Flow is a simple object made up of a set of two Endpoints, one source and one\ndestination.  It details the sender and receiver of the Layer of the Packet.\n\nAn Endpoint is a hashable representation of a source or destination.  For\nexample, for LayerTypeIPv4, an Endpoint contains the IP address bytes for a v4\nIP packet.  A Flow can be broken into Endpoints, and Endpoints can be combined\ninto Flows:\n\n packet := gopacket.NewPacket(myPacketData, layers.LayerTypeEthernet, gopacket.Lazy)\n netFlow := packet.NetworkLayer().NetworkFlow()\n src, dst := netFlow.Endpoints()\n reverseFlow := gopacket.NewFlow(dst, src)\n\nBoth Endpoint and Flow objects can be used as map keys, and the equality\noperator can compare them, so you can easily group together all packets\nbased on endpoint criteria:\n\n flows := map[gopacket.Endpoint]chan gopacket.Packet\n packet := gopacket.NewPacket(myPacketData, layers.LayerTypeEthernet, gopacket.Lazy)\n // Send all TCP packets to channels based on their destination port.\n if tcp := packet.Layer(layers.LayerTypeTCP); tcp != nil {\n   flows[tcp.TransportFlow().Dst()] <- packet\n }\n // Look for all packets with the same source and destination network address\n if net := packet.NetworkLayer(); net != nil {\n   src, dst := net.NetworkFlow().Endpoints()\n   if src == dst {\n     fmt.Println(\"Fishy packet has same network source and dst: %s\", src)\n   }\n }\n // Find all packets coming from UDP port 1000 to UDP port 500\n interestingFlow := gopacket.FlowFromEndpoints(layers.NewUDPPortEndpoint(1000), layers.NewUDPPortEndpoint(500))\n if t := packet.NetworkLayer(); t != nil && t.TransportFlow() == interestingFlow {\n   fmt.Println(\"Found that UDP flow I was looking for!\")\n }\n\nFor load-balancing purposes, both Flow and Endpoint have FastHash() functions,\nwhich provide quick, non-cryptographic hashes of their contents.  Of particular\nimportance is the fact that Flow FastHash() is symmetric: A->B will have the same\nhash as B->A.  An example usage could be:\n\n channels := [8]chan gopacket.Packet\n for i := 0; i < 8; i++ {\n   channels[i] = make(chan gopacket.Packet)\n   go packetHandler(channels[i])\n }\n for packet := range getPackets() {\n   if net := packet.NetworkLayer(); net != nil {\n     channels[int(net.NetworkFlow().FastHash()) & 0x7] <- packet\n   }\n }\n\nThis allows us to split up a packet stream while still making sure that each\nstream sees all packets for a flow (and its bidirectional opposite).\n\n\nImplementing Your Own Decoder\n\nIf your network has some strange encapsulation, you can implement your own\ndecoder.  In this example, we handle Ethernet packets which are encapsulated\nin a 4-byte header.\n\n // Create a layer type, should be unique and high, so it doesn't conflict,\n // giving it a name and a decoder to use.\n var MyLayerType = gopacket.RegisterLayerType(12345, gopacket.LayerTypeMetadata{Name: \"MyLayerType\", Decoder: gopacket.DecodeFunc(decodeMyLayer)})\n\n // Implement my layer\n type MyLayer struct {\n   StrangeHeader []byte\n   payload []byte\n }\n func (m MyLayer) LayerType() gopacket.LayerType { return MyLayerType }\n func (m MyLayer) LayerContents() []byte { return m.StrangeHeader }\n func (m MyLayer) LayerPayload() []byte { return m.payload }\n\n // Now implement a decoder... this one strips off the first 4 bytes of the\n // packet.\n func decodeMyLayer(data []byte, p gopacket.PacketBuilder) error {\n   // Create my layer\n   p.AddLayer(&MyLayer{data[:4], data[4:]})\n   // Determine how to handle the rest of the packet\n   return p.NextDecoder(layers.LayerTypeEthernet)\n }\n\n // Finally, decode your packets:\n p := gopacket.NewPacket(data, MyLayerType, gopacket.Lazy)\n\nSee the docs for Decoder and PacketBuilder for more details on how coding\ndecoders works, or look at RegisterLayerType and RegisterEndpointType to see how\nto add layer/endpoint types to gopacket.\n\n\nFast Decoding With DecodingLayerParser\n\nTLDR:  DecodingLayerParser takes about 10% of the time as NewPacket to decode\npacket data, but only for known packet stacks.\n\nBasic decoding using gopacket.NewPacket or PacketSource.Packets is somewhat slow\ndue to its need to allocate a new packet and every respective layer.  It's very\nversatile and can handle all known layer types, but sometimes you really only\ncare about a specific set of layers regardless, so that versatility is wasted.\n\nDecodingLayerParser avoids memory allocation altogether by decoding packet\nlayers directly into preallocated objects, which you can then reference to get\nthe packet's information.  A quick example:\n\n func main() {\n   var eth layers.Ethernet\n   var ip4 layers.IPv4\n   var ip6 layers.IPv6\n   var tcp layers.TCP\n   parser := gopacket.NewDecodingLayerParser(layers.LayerTypeEthernet, &eth, &ip4, &ip6, &tcp)\n   decoded := []gopacket.LayerType{}\n   for packetData := range somehowGetPacketData() {\n     if err := parser.DecodeLayers(packetData, &decoded); err != nil {\n       fmt.Fprintf(os.Stderr, \"Could not decode layers: %v\\n\", err)\n       continue\n     }\n     for _, layerType := range decoded {\n       switch layerType {\n         case layers.LayerTypeIPv6:\n           fmt.Println(\"    IP6 \", ip6.SrcIP, ip6.DstIP)\n         case layers.LayerTypeIPv4:\n           fmt.Println(\"    IP4 \", ip4.SrcIP, ip4.DstIP)\n       }\n     }\n   }\n }\n\nThe important thing to note here is that the parser is modifying the passed in\nlayers (eth, ip4, ip6, tcp) instead of allocating new ones, thus greatly\nspeeding up the decoding process.  It's even branching based on layer type...\nit'll handle an (eth, ip4, tcp) or (eth, ip6, tcp) stack.  However, it won't\nhandle any other type... since no other decoders were passed in, an (eth, ip4,\nudp) stack will stop decoding after ip4, and only pass back [LayerTypeEthernet,\nLayerTypeIPv4] through the 'decoded' slice (along with an error saying it can't\ndecode a UDP packet).\n\nUnfortunately, not all layers can be used by DecodingLayerParser... only those\nimplementing the DecodingLayer interface are usable.  Also, it's possible to\ncreate DecodingLayers that are not themselves Layers... see\nlayers.IPv6ExtensionSkipper for an example of this.\n\nFaster And Customized Decoding with DecodingLayerContainer\n\nBy default, DecodingLayerParser uses native map to store and search for a layer\nto decode. Though being versatile, in some cases this solution may be not so\noptimal. For example, if you have only few layers faster operations may be\nprovided by sparse array indexing or linear array scan.\n\nTo accomodate these scenarios, DecodingLayerContainer interface is introduced\nalong with its implementations: DecodingLayerSparse, DecodingLayerArray and\nDecodingLayerMap. You can specify a container implementation to\nDecodingLayerParser with SetDecodingLayerContainer method. Example:\n\n dlp := gopacket.NewDecodingLayerParser(LayerTypeEthernet)\n dlp.SetDecodingLayerContainer(gopacket.DecodingLayerSparse(nil))\n var eth layers.Ethernet\n dlp.AddDecodingLayer(&eth)\n // ... add layers and use DecodingLayerParser as usual...\n\nTo skip one level of indirection (though sacrificing some capabilities) you may\nalso use DecodingLayerContainer as a decoding tool as it is. In this case you have to\nhandle unknown layer types and layer panics by yourself. Example:\n\n func main() {\n   var eth layers.Ethernet\n   var ip4 layers.IPv4\n   var ip6 layers.IPv6\n   var tcp layers.TCP\n   dlc := gopacket.DecodingLayerContainer(gopacket.DecodingLayerArray(nil))\n   dlc = dlc.Put(&eth)\n   dlc = dlc.Put(&ip4)\n   dlc = dlc.Put(&ip6)\n   dlc = dlc.Put(&tcp)\n   // you may specify some meaningful DecodeFeedback\n   decoder := dlc.LayersDecoder(LayerTypeEthernet, gopacket.NilDecodeFeedback)\n   decoded := make([]gopacket.LayerType, 0, 20)\n   for packetData := range somehowGetPacketData() {\n     lt, err := decoder(packetData, &decoded)\n     if err != nil {\n       fmt.Fprintf(os.Stderr, \"Could not decode layers: %v\\n\", err)\n       continue\n     }\n     if lt != gopacket.LayerTypeZero {\n       fmt.Fprintf(os.Stderr, \"unknown layer type: %v\\n\", lt)\n       continue\n     }\n     for _, layerType := range decoded {\n       // examine decoded layertypes just as already shown above\n     }\n   }\n }\n\nDecodingLayerSparse is the fastest but most effective when LayerType values\nthat layers in use can decode are not large because otherwise that would lead\nto bigger memory footprint. DecodingLayerArray is very compact and primarily\nusable if the number of decoding layers is not big (up to ~10-15, but please do\nyour own benchmarks). DecodingLayerMap is the most versatile one and used by\nDecodingLayerParser by default. Please refer to tests and benchmarks in layers\nsubpackage to further examine usage examples and performance measurements.\n\nYou may also choose to implement your own DecodingLayerContainer if you want to\nmake use of your own internal packet decoding logic.\n\nCreating Packet Data\n\nAs well as offering the ability to decode packet data, gopacket will allow you\nto create packets from scratch, as well.  A number of gopacket layers implement\nthe SerializableLayer interface; these layers can be serialized to a []byte in\nthe following manner:\n\n  ip := &layers.IPv4{\n    SrcIP: net.IP{1, 2, 3, 4},\n    DstIP: net.IP{5, 6, 7, 8},\n    // etc...\n  }\n  buf := gopacket.NewSerializeBuffer()\n  opts := gopacket.SerializeOptions{}  // See SerializeOptions for more details.\n  err := ip.SerializeTo(buf, opts)\n  if err != nil { panic(err) }\n  fmt.Println(buf.Bytes())  // prints out a byte slice containing the serialized IPv4 layer.\n\nSerializeTo PREPENDS the given layer onto the SerializeBuffer, and they treat\nthe current buffer's Bytes() slice as the payload of the serializing layer.\nTherefore, you can serialize an entire packet by serializing a set of layers in\nreverse order (Payload, then TCP, then IP, then Ethernet, for example).  The\nSerializeBuffer's SerializeLayers function is a helper that does exactly that.\n\nTo generate a (empty and useless, because no fields are set)\nEthernet(IPv4(TCP(Payload))) packet, for example, you can run:\n\n  buf := gopacket.NewSerializeBuffer()\n  opts := gopacket.SerializeOptions{}\n  gopacket.SerializeLayers(buf, opts,\n    &layers.Ethernet{},\n    &layers.IPv4{},\n    &layers.TCP{},\n    gopacket.Payload([]byte{1, 2, 3, 4}))\n  packetData := buf.Bytes()\n\nA Final Note\n\nIf you use gopacket, you'll almost definitely want to make sure gopacket/layers\nis imported, since when imported it sets all the LayerType variables and fills\nin a lot of interesting variables/maps (DecodersByLayerName, etc).  Therefore,\nit's recommended that even if you don't use any layers functions directly, you still import with:\n\n  import (\n    _ \"github.com/google/gopacket/layers\"\n  )\n*/\npackage gopacket\n"
        },
        {
          "name": "dumpcommand",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flows.go",
          "type": "blob",
          "size": 7.689453125,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"strconv\"\n)\n\n// MaxEndpointSize determines the maximum size in bytes of an endpoint address.\n//\n// Endpoints/Flows have a problem:  They need to be hashable.  Therefore, they\n// can't use a byte slice.  The two obvious choices are to use a string or a\n// byte array.  Strings work great, but string creation requires memory\n// allocation, which can be slow.  Arrays work great, but have a fixed size.  We\n// originally used the former, now we've switched to the latter.  Use of a fixed\n// byte-array doubles the speed of constructing a flow (due to not needing to\n// allocate).  This is a huge increase... too much for us to pass up.\n//\n// The end result of this, though, is that an endpoint/flow can't be created\n// using more than MaxEndpointSize bytes per address.\nconst MaxEndpointSize = 16\n\n// Endpoint is the set of bytes used to address packets at various layers.\n// See LinkLayer, NetworkLayer, and TransportLayer specifications.\n// Endpoints are usable as map keys.\ntype Endpoint struct {\n\ttyp EndpointType\n\tlen int\n\traw [MaxEndpointSize]byte\n}\n\n// EndpointType returns the endpoint type associated with this endpoint.\nfunc (a Endpoint) EndpointType() EndpointType { return a.typ }\n\n// Raw returns the raw bytes of this endpoint.  These aren't human-readable\n// most of the time, but they are faster than calling String.\nfunc (a Endpoint) Raw() []byte { return a.raw[:a.len] }\n\n// LessThan provides a stable ordering for all endpoints.  It sorts first based\n// on the EndpointType of an endpoint, then based on the raw bytes of that\n// endpoint.\n//\n// For some endpoints, the actual comparison may not make sense, however this\n// ordering does provide useful information for most Endpoint types.\n// Ordering is based first on endpoint type, then on raw endpoint bytes.\n// Endpoint bytes are sorted lexicographically.\nfunc (a Endpoint) LessThan(b Endpoint) bool {\n\treturn a.typ < b.typ || (a.typ == b.typ && bytes.Compare(a.raw[:a.len], b.raw[:b.len]) < 0)\n}\n\n// fnvHash is used by our FastHash functions, and implements the FNV hash\n// created by Glenn Fowler, Landon Curt Noll, and Phong Vo.\n// See http://isthe.com/chongo/tech/comp/fnv/.\nfunc fnvHash(s []byte) (h uint64) {\n\th = fnvBasis\n\tfor i := 0; i < len(s); i++ {\n\t\th ^= uint64(s[i])\n\t\th *= fnvPrime\n\t}\n\treturn\n}\n\nconst fnvBasis = 14695981039346656037\nconst fnvPrime = 1099511628211\n\n// FastHash provides a quick hashing function for an endpoint, useful if you'd\n// like to split up endpoints by modulos or other load-balancing techniques.\n// It uses a variant of Fowler-Noll-Vo hashing.\n//\n// The output of FastHash is not guaranteed to remain the same through future\n// code revisions, so should not be used to key values in persistent storage.\nfunc (a Endpoint) FastHash() (h uint64) {\n\th = fnvHash(a.raw[:a.len])\n\th ^= uint64(a.typ)\n\th *= fnvPrime\n\treturn\n}\n\n// NewEndpoint creates a new Endpoint object.\n//\n// The size of raw must be less than MaxEndpointSize, otherwise this function\n// will panic.\nfunc NewEndpoint(typ EndpointType, raw []byte) (e Endpoint) {\n\te.len = len(raw)\n\tif e.len > MaxEndpointSize {\n\t\tpanic(\"raw byte length greater than MaxEndpointSize\")\n\t}\n\te.typ = typ\n\tcopy(e.raw[:], raw)\n\treturn\n}\n\n// EndpointTypeMetadata is used to register a new endpoint type.\ntype EndpointTypeMetadata struct {\n\t// Name is the string returned by an EndpointType's String function.\n\tName string\n\t// Formatter is called from an Endpoint's String function to format the raw\n\t// bytes in an Endpoint into a human-readable string.\n\tFormatter func([]byte) string\n}\n\n// EndpointType is the type of a gopacket Endpoint.  This type determines how\n// the bytes stored in the endpoint should be interpreted.\ntype EndpointType int64\n\nvar endpointTypes = map[EndpointType]EndpointTypeMetadata{}\n\n// RegisterEndpointType creates a new EndpointType and registers it globally.\n// It MUST be passed a unique number, or it will panic.  Numbers 0-999 are\n// reserved for gopacket's use.\nfunc RegisterEndpointType(num int, meta EndpointTypeMetadata) EndpointType {\n\tt := EndpointType(num)\n\tif _, ok := endpointTypes[t]; ok {\n\t\tpanic(\"Endpoint type number already in use\")\n\t}\n\tendpointTypes[t] = meta\n\treturn t\n}\n\nfunc (e EndpointType) String() string {\n\tif t, ok := endpointTypes[e]; ok {\n\t\treturn t.Name\n\t}\n\treturn strconv.Itoa(int(e))\n}\n\nfunc (a Endpoint) String() string {\n\tif t, ok := endpointTypes[a.typ]; ok && t.Formatter != nil {\n\t\treturn t.Formatter(a.raw[:a.len])\n\t}\n\treturn fmt.Sprintf(\"%v:%v\", a.typ, a.raw)\n}\n\n// Flow represents the direction of traffic for a packet layer, as a source and destination Endpoint.\n// Flows are usable as map keys.\ntype Flow struct {\n\ttyp        EndpointType\n\tslen, dlen int\n\tsrc, dst   [MaxEndpointSize]byte\n}\n\n// FlowFromEndpoints creates a new flow by pasting together two endpoints.\n// The endpoints must have the same EndpointType, or this function will return\n// an error.\nfunc FlowFromEndpoints(src, dst Endpoint) (_ Flow, err error) {\n\tif src.typ != dst.typ {\n\t\terr = fmt.Errorf(\"Mismatched endpoint types: %v->%v\", src.typ, dst.typ)\n\t\treturn\n\t}\n\treturn Flow{src.typ, src.len, dst.len, src.raw, dst.raw}, nil\n}\n\n// FastHash provides a quick hashing function for a flow, useful if you'd\n// like to split up flows by modulos or other load-balancing techniques.\n// It uses a variant of Fowler-Noll-Vo hashing, and is guaranteed to collide\n// with its reverse flow.  IE: the flow A->B will have the same hash as the flow\n// B->A.\n//\n// The output of FastHash is not guaranteed to remain the same through future\n// code revisions, so should not be used to key values in persistent storage.\nfunc (f Flow) FastHash() (h uint64) {\n\t// This combination must be commutative.  We don't use ^, since that would\n\t// give the same hash for all A->A flows.\n\th = fnvHash(f.src[:f.slen]) + fnvHash(f.dst[:f.dlen])\n\th ^= uint64(f.typ)\n\th *= fnvPrime\n\treturn\n}\n\n// String returns a human-readable representation of this flow, in the form\n// \"Src->Dst\"\nfunc (f Flow) String() string {\n\ts, d := f.Endpoints()\n\treturn fmt.Sprintf(\"%v->%v\", s, d)\n}\n\n// EndpointType returns the EndpointType for this Flow.\nfunc (f Flow) EndpointType() EndpointType {\n\treturn f.typ\n}\n\n// Endpoints returns the two Endpoints for this flow.\nfunc (f Flow) Endpoints() (src, dst Endpoint) {\n\treturn Endpoint{f.typ, f.slen, f.src}, Endpoint{f.typ, f.dlen, f.dst}\n}\n\n// Src returns the source Endpoint for this flow.\nfunc (f Flow) Src() (src Endpoint) {\n\tsrc, _ = f.Endpoints()\n\treturn\n}\n\n// Dst returns the destination Endpoint for this flow.\nfunc (f Flow) Dst() (dst Endpoint) {\n\t_, dst = f.Endpoints()\n\treturn\n}\n\n// Reverse returns a new flow with endpoints reversed.\nfunc (f Flow) Reverse() Flow {\n\treturn Flow{f.typ, f.dlen, f.slen, f.dst, f.src}\n}\n\n// NewFlow creates a new flow.\n//\n// src and dst must have length <= MaxEndpointSize, otherwise NewFlow will\n// panic.\nfunc NewFlow(t EndpointType, src, dst []byte) (f Flow) {\n\tf.slen = len(src)\n\tf.dlen = len(dst)\n\tif f.slen > MaxEndpointSize || f.dlen > MaxEndpointSize {\n\t\tpanic(\"flow raw byte length greater than MaxEndpointSize\")\n\t}\n\tf.typ = t\n\tcopy(f.src[:], src)\n\tcopy(f.dst[:], dst)\n\treturn\n}\n\n// EndpointInvalid is an endpoint type used for invalid endpoints, IE endpoints\n// that are specified incorrectly during creation.\nvar EndpointInvalid = RegisterEndpointType(0, EndpointTypeMetadata{Name: \"invalid\", Formatter: func(b []byte) string {\n\treturn fmt.Sprintf(\"%v\", b)\n}})\n\n// InvalidEndpoint is a singleton Endpoint of type EndpointInvalid.\nvar InvalidEndpoint = NewEndpoint(EndpointInvalid, nil)\n\n// InvalidFlow is a singleton Flow of type EndpointInvalid.\nvar InvalidFlow = NewFlow(EndpointInvalid, nil, nil)\n"
        },
        {
          "name": "gc",
          "type": "blob",
          "size": 6.3173828125,
          "content": "#!/bin/bash\n# Copyright 2012 Google, Inc. All rights reserved.\n\n# This script provides a simple way to run benchmarks against previous code and\n# keep a log of how benchmarks change over time.  When used with the --benchmark\n# flag, it runs benchmarks from the current code and from the last commit run\n# with --benchmark, then stores the results in the git commit description.  We\n# rerun the old benchmarks along with the new ones, since there's no guarantee\n# that git commits will happen on the same machine, so machine differences could\n# cause wildly inaccurate results.\n#\n# If you're making changes to 'gopacket' which could cause performance changes,\n# you may be requested to use this commit script to make sure your changes don't\n# have large detrimental effects (or to show off how awesome your performance\n# improvements are).\n#\n# If not run with the --benchmark flag, this script is still very useful... it\n# makes sure all the correct go formatting, building, and testing work as\n# expected.\n\nfunction Usage {\n  cat <<EOF\nUSAGE:  $0 [--benchmark regexp] [--root] [--gen] <git commit flags...>\n\n--benchmark:  Run benchmark comparisons against last benchmark'd commit\n--root:  Run tests that require root priviledges\n--gen:  Generate code for MACs/ports by pulling down external data\n\nNote, some 'git commit' flags are necessary, if all else fails, pass in -a\nEOF\n  exit 1\n}\n\nBENCH=\"\"\nGEN=\"\"\nROOT=\"\"\nwhile [ ! -z \"$1\" ]; do\n  case \"$1\" in\n    \"--benchmark\")\n      BENCH=\"$2\"\n      shift\n      shift\n      ;;\n    \"--gen\")\n      GEN=\"yes\"\n      shift\n      ;;\n    \"--root\")\n      ROOT=\"yes\"\n      shift\n      ;;\n    \"--help\")\n      Usage\n      ;;\n    \"-h\")\n      Usage\n      ;;\n    \"help\")\n      Usage\n      ;;\n    *)\n      break\n      ;;\n  esac\ndone\n\nfunction Root {\n  if [ ! -z \"$ROOT\" ]; then\n    local exec=\"$1\"\n    # Some folks (like me) keep source code in places inaccessible by root (like\n    # NFS), so to make sure things run smoothly we copy them to a /tmp location.\n    local tmpfile=\"$(mktemp -t gopacket_XXXXXXXX)\"\n    echo \"Running root test executable $exec as $tmpfile\"\n    cp \"$exec\" \"$tmpfile\"\n    chmod a+x \"$tmpfile\"\n    shift\n    sudo \"$tmpfile\" \"$@\"\n  fi\n}\n\nif [ \"$#\" -eq \"0\" ]; then\n  Usage\nfi\n\ncd $(dirname $0)\n\n# Check for copyright notices.\nfor filename in $(find ./ -type f -name '*.go'); do\n  if ! head -n 1 \"$filename\" | grep -q Copyright; then\n    echo \"File '$filename' may not have copyright notice\"\n    exit 1\n  fi\ndone\n\nset -e\nset -x\n\nif [ ! -z \"$ROOT\" ]; then\n  echo \"Running SUDO to get root priviledges for root tests\"\n  sudo echo \"have root\"\nfi\n\nif [ ! -z \"$GEN\" ]; then\n  pushd macs\n  go run gen.go | gofmt > valid_mac_prefixes.go\n  popd\n  pushd layers\n  go run gen.go | gofmt > iana_ports.go\n  go run gen2.go | gofmt > enums_generated.go\n  popd\nfi\n\n# Make sure everything is formatted, compiles, and tests pass.\ngo fmt ./...\ngo test -i ./... 2>/dev/null >/dev/null || true\ngo test\ngo build\npushd examples/bytediff\ngo build\npopd\nif [ -f /usr/include/pcap.h ]; then\n  pushd pcap\n  go test ./...\n  go build ./...\n  go build pcap_tester.go\n  Root pcap_tester --mode=basic\n  Root pcap_tester --mode=filtered\n  Root pcap_tester --mode=timestamp || echo \"You might not support timestamp sources\"\n  popd\n  pushd examples/afpacket\n  go build\n  popd\n  pushd examples/pcapdump\n  go build\n  popd\n  pushd examples/arpscan\n  go build\n  popd\n  pushd examples/bidirectional\n  go build\n  popd\n  pushd examples/synscan\n  go build\n  popd\n  pushd examples/httpassembly\n  go build\n  popd\n  pushd examples/statsassembly\n  go build\n  popd\nfi\npushd macs\ngo test ./...\ngofmt -w gen.go\ngo build gen.go\npopd\npushd tcpassembly\ngo test ./...\npopd\npushd reassembly\ngo test ./...\npopd\npushd layers\ngofmt -w gen.go\ngo build gen.go\ngo test ./...\npopd\npushd pcapgo\ngo test ./...\ngo build ./...\npopd\nif [ -f /usr/include/linux/if_packet.h ]; then\n  if grep -q TPACKET_V3 /usr/include/linux/if_packet.h; then\n    pushd afpacket\n    go build ./...\n    go test ./...\n    popd\n  fi\nfi\nif [ -f /usr/include/pfring.h ]; then\n  pushd pfring\n  go test ./...\n  go build ./...\n  popd\n  pushd examples/pfdump\n  go build\n  popd\nfi\npushd ip4defrag\ngo test ./...\npopd\npushd defrag\ngo test ./...\npopd\n\nfor travis_script in `ls .travis.*.sh`; do\n  ./$travis_script\ndone\n\n# Run our initial commit\ngit commit \"$@\"\n\nif [ -z \"$BENCH\" ]; then\n  set +x\n  echo \"We're not benchmarking and we've committed... we're done!\"\n  exit\nfi\n\n### If we get here, we want to run benchmarks from current commit, and compare\n### then to benchmarks from the last --benchmark commit.\n\n# Get our current branch.\nBRANCH=\"$(git branch | grep '^*' | awk '{print $2}')\"\n\n# File we're going to build our commit description in.\nCOMMIT_FILE=\"$(mktemp /tmp/tmp.XXXXXXXX)\"\n\n# Add the word \"BENCH\" to the start of the git commit.\necho -n \"BENCH \" > $COMMIT_FILE\n\n# Get the current description... there must be an easier way.\ngit log -n 1 | grep '^ ' | sed 's/^    //' >> $COMMIT_FILE\n\n# Get the commit sha for the last benchmark commit\nPREV=$(git log -n 1 --grep='BENCHMARK_MARKER_DO_NOT_CHANGE' | head -n 1 | awk '{print $2}')\n\n## Run current benchmarks\n\ncat >> $COMMIT_FILE <<EOF\n\n\n----------------------------------------------------------\nBENCHMARK_MARKER_DO_NOT_CHANGE\n----------------------------------------------------------\n\nGo version $(go version)\n\n\nTEST BENCHMARKS \"$BENCH\"\nEOF\n# go seems to have trouble with 'go test --bench=. ./...'\ngo test --test.bench=\"$BENCH\" 2>&1 | tee -a $COMMIT_FILE\npushd layers\ngo test --test.bench=\"$BENCH\" 2>&1 | tee -a $COMMIT_FILE\npopd\ncat >> $COMMIT_FILE <<EOF\n\n\nPCAP BENCHMARK\nEOF\nif [ \"$BENCH\" -eq \".*\" ]; then\n  go run pcap/gopacket_benchmark/*.go 2>&1 | tee -a $COMMIT_FILE\nfi\n\n\n\n## Reset to last benchmark commit, run benchmarks\n\ngit checkout $PREV\n\ncat >> $COMMIT_FILE <<EOF\n----------------------------------------------------------\nBENCHMARKING AGAINST COMMIT $PREV\n----------------------------------------------------------\n\n\nOLD TEST BENCHMARKS\nEOF\n# go seems to have trouble with 'go test --bench=. ./...'\ngo test --test.bench=\"$BENCH\" 2>&1 | tee -a $COMMIT_FILE\npushd layers\ngo test --test.bench=\"$BENCH\" 2>&1 | tee -a $COMMIT_FILE\npopd\ncat >> $COMMIT_FILE <<EOF\n\n\nOLD PCAP BENCHMARK\nEOF\nif [ \"$BENCH\" -eq \".*\" ]; then\n  go run pcap/gopacket_benchmark/*.go 2>&1 | tee -a $COMMIT_FILE\nfi\n\n\n\n## Reset back to the most recent commit, edit the commit message by appending\n## benchmark results.\ngit checkout $BRANCH\ngit commit --amend -F $COMMIT_FILE\n"
        },
        {
          "name": "gen.go",
          "type": "blob",
          "size": 1.826171875,
          "content": "// Copyright 2019 The GoPacket Authors. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\n// +build ignore\n\n// This file generates LayersDecoder function for DecodingLayerContainer\n// go run gen.go | gofmt > layers_decoder.go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n)\n\nconst headerFmt = `// Copyright 2019 The GoPacket Authors. All rights reserved.\n\npackage gopacket\n\n// Created by gen.go, don't edit manually\n// Generated at %s\n\n// LayersDecoder returns DecodingLayerFunc for specified\n// DecodingLayerContainer, LayerType value to start decoding with and\n// some DecodeFeedback.\nfunc LayersDecoder(dl DecodingLayerContainer, first LayerType, df DecodeFeedback) DecodingLayerFunc {\n  firstDec, ok := dl.Decoder(first)\n  if !ok {\n    return func([]byte, *[]LayerType) (LayerType, error) {\n      return first, nil\n    }\n  }\n`\n\nvar funcBody = `return func(data []byte, decoded *[]LayerType) (LayerType, error) {\n  *decoded = (*decoded)[:0] // Truncated decoded layers.\n  typ := first\n  decoder := firstDec\n  for {\n    if err := decoder.DecodeFromBytes(data, df); err != nil {\n      return LayerTypeZero, err\n    }\n    *decoded = append(*decoded, typ)\n    typ = decoder.NextLayerType()\n    if data = decoder.LayerPayload(); len(data) == 0 {\n      break\n    }\n    if decoder, ok = dlc.Decoder(typ); !ok {\n      return typ, nil\n    }\n  }\n  return LayerTypeZero, nil\n}`\n\nfunc main() {\n\tfmt.Fprintf(os.Stderr, \"Writing results to stdout\\n\")\n\ttypes := []string{\n\t\t\"DecodingLayerSparse\",\n\t\t\"DecodingLayerArray\",\n\t\t\"DecodingLayerMap\",\n\t}\n\n\tfmt.Printf(headerFmt, time.Now())\n\tfor _, t := range types {\n\t\tfmt.Printf(\"if dlc, ok := dl.(%s); ok {\", t)\n\t\tfmt.Println(funcBody)\n\t\tfmt.Println(\"}\")\n\t}\n\tfmt.Println(\"dlc := dl\")\n\tfmt.Println(funcBody)\n\tfmt.Println(\"}\")\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.32421875,
          "content": "module github.com/google/gopacket\n\ngo 1.12\n\nrequire (\n\tgithub.com/vishvananda/netlink v1.1.0\n\tgithub.com/vishvananda/netns v0.0.0-20210104183010-2eb08e3e575f\n\tgolang.org/x/lint v0.0.0-20200302205851-738671d3881b // indirect\n\tgolang.org/x/net v0.0.0-20190620200207-3b0461eec859\n\tgolang.org/x/sys v0.0.0-20200217220822-9197077df867\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.759765625,
          "content": "github.com/vishvananda/netlink v1.1.0 h1:1iyaYNBLmP6L0220aDnYQpo1QEV4t4hJ+xEEhhJH8j0=\ngithub.com/vishvananda/netlink v1.1.0/go.mod h1:cTgwzPIzzgDAYoQrMm0EdrjRUBkTqKYppBueQtXaqoE=\ngithub.com/vishvananda/netns v0.0.0-20191106174202-0a2b9b5464df/go.mod h1:JP3t17pCcGlemwknint6hfoeCVQrEMVwxRLRjXpq+BU=\ngithub.com/vishvananda/netns v0.0.0-20210104183010-2eb08e3e575f h1:p4VB7kIXpOQvVn1ZaTIVp+3vuYAXFe3OJEvjbUYJLaA=\ngithub.com/vishvananda/netns v0.0.0-20210104183010-2eb08e3e575f/go.mod h1:DD4vA1DwXk04H54A1oHXtwZmA0grkVMdPxx/VGLCah0=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b h1:Wh+f8QHJXR411sJR8/vRBTZ7YapZaRvUcLFFJhusH0k=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3 h1:0GoQqolDA55aaLxZyTzK/Y2ePZzZTUrRacwib7cNsYQ=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859 h1:R/3boaszxrf1GEUWTVDzSKVwLmSJpwZ1yqXm8j0v2QI=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190405154228-4b34438f7a67 h1:1Fzlr8kkDLQwqMP8GxrhptBLqZG/EDpiATneiZHY998=\ngolang.org/x/sys v0.0.0-20190405154228-4b34438f7a67/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d h1:+R4KGOnez64A81RvjARKc4UT5/tI9ujCIVX+P5KiHuI=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606203320-7fc4e5ec1444/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200217220822-9197077df867 h1:JoRuNIf+rpHl+VhScRQQvzbHed86tKkqwPMV34T8myw=\ngolang.org/x/sys v0.0.0-20200217220822-9197077df867/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7 h1:EBZoQjiKKPaLbPrbpssUfuHtwM6KV/vb4U85g/cigFY=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n"
        },
        {
          "name": "ip4defrag",
          "type": "tree",
          "content": null
        },
        {
          "name": "layerclass.go",
          "type": "blob",
          "size": 2.9267578125,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\n// LayerClass is a set of LayerTypes, used for grabbing one of a number of\n// different types from a packet.\ntype LayerClass interface {\n\t// Contains returns true if the given layer type should be considered part\n\t// of this layer class.\n\tContains(LayerType) bool\n\t// LayerTypes returns the set of all layer types in this layer class.\n\t// Note that this may not be a fast operation on all LayerClass\n\t// implementations.\n\tLayerTypes() []LayerType\n}\n\n// Contains implements LayerClass.\nfunc (l LayerType) Contains(a LayerType) bool {\n\treturn l == a\n}\n\n// LayerTypes implements LayerClass.\nfunc (l LayerType) LayerTypes() []LayerType {\n\treturn []LayerType{l}\n}\n\n// LayerClassSlice implements a LayerClass with a slice.\ntype LayerClassSlice []bool\n\n// Contains returns true if the given layer type should be considered part\n// of this layer class.\nfunc (s LayerClassSlice) Contains(t LayerType) bool {\n\treturn int(t) < len(s) && s[t]\n}\n\n// LayerTypes returns all layer types in this LayerClassSlice.\n// Because of LayerClassSlice's implementation, this could be quite slow.\nfunc (s LayerClassSlice) LayerTypes() (all []LayerType) {\n\tfor i := 0; i < len(s); i++ {\n\t\tif s[i] {\n\t\t\tall = append(all, LayerType(i))\n\t\t}\n\t}\n\treturn\n}\n\n// NewLayerClassSlice creates a new LayerClassSlice by creating a slice of\n// size max(types) and setting slice[t] to true for each type t.  Note, if\n// you implement your own LayerType and give it a high value, this WILL create\n// a very large slice.\nfunc NewLayerClassSlice(types []LayerType) LayerClassSlice {\n\tvar max LayerType\n\tfor _, typ := range types {\n\t\tif typ > max {\n\t\t\tmax = typ\n\t\t}\n\t}\n\tt := make([]bool, int(max+1))\n\tfor _, typ := range types {\n\t\tt[typ] = true\n\t}\n\treturn t\n}\n\n// LayerClassMap implements a LayerClass with a map.\ntype LayerClassMap map[LayerType]bool\n\n// Contains returns true if the given layer type should be considered part\n// of this layer class.\nfunc (m LayerClassMap) Contains(t LayerType) bool {\n\treturn m[t]\n}\n\n// LayerTypes returns all layer types in this LayerClassMap.\nfunc (m LayerClassMap) LayerTypes() (all []LayerType) {\n\tfor t := range m {\n\t\tall = append(all, t)\n\t}\n\treturn\n}\n\n// NewLayerClassMap creates a LayerClassMap and sets map[t] to true for each\n// type in types.\nfunc NewLayerClassMap(types []LayerType) LayerClassMap {\n\tm := LayerClassMap{}\n\tfor _, typ := range types {\n\t\tm[typ] = true\n\t}\n\treturn m\n}\n\n// NewLayerClass creates a LayerClass, attempting to be smart about which type\n// it creates based on which types are passed in.\nfunc NewLayerClass(types []LayerType) LayerClass {\n\tfor _, typ := range types {\n\t\tif typ > maxLayerType {\n\t\t\t// NewLayerClassSlice could create a very large object, so instead create\n\t\t\t// a map.\n\t\t\treturn NewLayerClassMap(types)\n\t\t}\n\t}\n\treturn NewLayerClassSlice(types)\n}\n"
        },
        {
          "name": "layers",
          "type": "tree",
          "content": null
        },
        {
          "name": "layers_decoder.go",
          "type": "blob",
          "size": 2.759765625,
          "content": "// Copyright 2019 The GoPacket Authors. All rights reserved.\n\npackage gopacket\n\n// Created by gen.go, don't edit manually\n// Generated at 2019-06-18 11:37:31.308731293 +0600 +06 m=+0.000842599\n\n// LayersDecoder returns DecodingLayerFunc for specified\n// DecodingLayerContainer, LayerType value to start decoding with and\n// some DecodeFeedback.\nfunc LayersDecoder(dl DecodingLayerContainer, first LayerType, df DecodeFeedback) DecodingLayerFunc {\n\tfirstDec, ok := dl.Decoder(first)\n\tif !ok {\n\t\treturn func([]byte, *[]LayerType) (LayerType, error) {\n\t\t\treturn first, nil\n\t\t}\n\t}\n\tif dlc, ok := dl.(DecodingLayerSparse); ok {\n\t\treturn func(data []byte, decoded *[]LayerType) (LayerType, error) {\n\t\t\t*decoded = (*decoded)[:0] // Truncated decoded layers.\n\t\t\ttyp := first\n\t\t\tdecoder := firstDec\n\t\t\tfor {\n\t\t\t\tif err := decoder.DecodeFromBytes(data, df); err != nil {\n\t\t\t\t\treturn LayerTypeZero, err\n\t\t\t\t}\n\t\t\t\t*decoded = append(*decoded, typ)\n\t\t\t\ttyp = decoder.NextLayerType()\n\t\t\t\tif data = decoder.LayerPayload(); len(data) == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif decoder, ok = dlc.Decoder(typ); !ok {\n\t\t\t\t\treturn typ, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn LayerTypeZero, nil\n\t\t}\n\t}\n\tif dlc, ok := dl.(DecodingLayerArray); ok {\n\t\treturn func(data []byte, decoded *[]LayerType) (LayerType, error) {\n\t\t\t*decoded = (*decoded)[:0] // Truncated decoded layers.\n\t\t\ttyp := first\n\t\t\tdecoder := firstDec\n\t\t\tfor {\n\t\t\t\tif err := decoder.DecodeFromBytes(data, df); err != nil {\n\t\t\t\t\treturn LayerTypeZero, err\n\t\t\t\t}\n\t\t\t\t*decoded = append(*decoded, typ)\n\t\t\t\ttyp = decoder.NextLayerType()\n\t\t\t\tif data = decoder.LayerPayload(); len(data) == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif decoder, ok = dlc.Decoder(typ); !ok {\n\t\t\t\t\treturn typ, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn LayerTypeZero, nil\n\t\t}\n\t}\n\tif dlc, ok := dl.(DecodingLayerMap); ok {\n\t\treturn func(data []byte, decoded *[]LayerType) (LayerType, error) {\n\t\t\t*decoded = (*decoded)[:0] // Truncated decoded layers.\n\t\t\ttyp := first\n\t\t\tdecoder := firstDec\n\t\t\tfor {\n\t\t\t\tif err := decoder.DecodeFromBytes(data, df); err != nil {\n\t\t\t\t\treturn LayerTypeZero, err\n\t\t\t\t}\n\t\t\t\t*decoded = append(*decoded, typ)\n\t\t\t\ttyp = decoder.NextLayerType()\n\t\t\t\tif data = decoder.LayerPayload(); len(data) == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif decoder, ok = dlc.Decoder(typ); !ok {\n\t\t\t\t\treturn typ, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn LayerTypeZero, nil\n\t\t}\n\t}\n\tdlc := dl\n\treturn func(data []byte, decoded *[]LayerType) (LayerType, error) {\n\t\t*decoded = (*decoded)[:0] // Truncated decoded layers.\n\t\ttyp := first\n\t\tdecoder := firstDec\n\t\tfor {\n\t\t\tif err := decoder.DecodeFromBytes(data, df); err != nil {\n\t\t\t\treturn LayerTypeZero, err\n\t\t\t}\n\t\t\t*decoded = append(*decoded, typ)\n\t\t\ttyp = decoder.NextLayerType()\n\t\t\tif data = decoder.LayerPayload(); len(data) == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif decoder, ok = dlc.Decoder(typ); !ok {\n\t\t\t\treturn typ, nil\n\t\t\t}\n\t\t}\n\t\treturn LayerTypeZero, nil\n\t}\n}\n"
        },
        {
          "name": "layertype.go",
          "type": "blob",
          "size": 3.3046875,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\n// LayerType is a unique identifier for each type of layer.  This enumeration\n// does not match with any externally available numbering scheme... it's solely\n// usable/useful within this library as a means for requesting layer types\n// (see Packet.Layer) and determining which types of layers have been decoded.\n//\n// New LayerTypes may be created by calling gopacket.RegisterLayerType.\ntype LayerType int64\n\n// LayerTypeMetadata contains metadata associated with each LayerType.\ntype LayerTypeMetadata struct {\n\t// Name is the string returned by each layer type's String method.\n\tName string\n\t// Decoder is the decoder to use when the layer type is passed in as a\n\t// Decoder.\n\tDecoder Decoder\n}\n\ntype layerTypeMetadata struct {\n\tinUse bool\n\tLayerTypeMetadata\n}\n\n// DecodersByLayerName maps layer names to decoders for those layers.\n// This allows users to specify decoders by name to a program and have that\n// program pick the correct decoder accordingly.\nvar DecodersByLayerName = map[string]Decoder{}\n\nconst maxLayerType = 2000\n\nvar ltMeta [maxLayerType]layerTypeMetadata\nvar ltMetaMap = map[LayerType]layerTypeMetadata{}\n\n// RegisterLayerType creates a new layer type and registers it globally.\n// The number passed in must be unique, or a runtime panic will occur.  Numbers\n// 0-999 are reserved for the gopacket library.  Numbers 1000-1999 should be\n// used for common application-specific types, and are very fast.  Any other\n// number (negative or >= 2000) may be used for uncommon application-specific\n// types, and are somewhat slower (they require a map lookup over an array\n// index).\nfunc RegisterLayerType(num int, meta LayerTypeMetadata) LayerType {\n\tif 0 <= num && num < maxLayerType {\n\t\tif ltMeta[num].inUse {\n\t\t\tpanic(\"Layer type already exists\")\n\t\t}\n\t} else {\n\t\tif ltMetaMap[LayerType(num)].inUse {\n\t\t\tpanic(\"Layer type already exists\")\n\t\t}\n\t}\n\treturn OverrideLayerType(num, meta)\n}\n\n// OverrideLayerType acts like RegisterLayerType, except that if the layer type\n// has already been registered, it overrides the metadata with the passed-in\n// metadata intead of panicing.\nfunc OverrideLayerType(num int, meta LayerTypeMetadata) LayerType {\n\tif 0 <= num && num < maxLayerType {\n\t\tltMeta[num] = layerTypeMetadata{\n\t\t\tinUse:             true,\n\t\t\tLayerTypeMetadata: meta,\n\t\t}\n\t} else {\n\t\tltMetaMap[LayerType(num)] = layerTypeMetadata{\n\t\t\tinUse:             true,\n\t\t\tLayerTypeMetadata: meta,\n\t\t}\n\t}\n\tDecodersByLayerName[meta.Name] = meta.Decoder\n\treturn LayerType(num)\n}\n\n// Decode decodes the given data using the decoder registered with the layer\n// type.\nfunc (t LayerType) Decode(data []byte, c PacketBuilder) error {\n\tvar d Decoder\n\tif 0 <= int(t) && int(t) < maxLayerType {\n\t\td = ltMeta[int(t)].Decoder\n\t} else {\n\t\td = ltMetaMap[t].Decoder\n\t}\n\tif d != nil {\n\t\treturn d.Decode(data, c)\n\t}\n\treturn fmt.Errorf(\"Layer type %v has no associated decoder\", t)\n}\n\n// String returns the string associated with this layer type.\nfunc (t LayerType) String() (s string) {\n\tif 0 <= int(t) && int(t) < maxLayerType {\n\t\ts = ltMeta[int(t)].Name\n\t} else {\n\t\ts = ltMetaMap[t].Name\n\t}\n\tif s == \"\" {\n\t\ts = strconv.Itoa(int(t))\n\t}\n\treturn\n}\n"
        },
        {
          "name": "macs",
          "type": "tree",
          "content": null
        },
        {
          "name": "packet.go",
          "type": "blob",
          "size": 26.361328125,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"bytes\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"reflect\"\n\t\"runtime/debug\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n)\n\n// CaptureInfo provides standardized information about a packet captured off\n// the wire or read from a file.\ntype CaptureInfo struct {\n\t// Timestamp is the time the packet was captured, if that is known.\n\tTimestamp time.Time\n\t// CaptureLength is the total number of bytes read off of the wire.\n\tCaptureLength int\n\t// Length is the size of the original packet.  Should always be >=\n\t// CaptureLength.\n\tLength int\n\t// InterfaceIndex\n\tInterfaceIndex int\n\t// The packet source can place ancillary data of various types here.\n\t// For example, the afpacket source can report the VLAN of captured\n\t// packets this way.\n\tAncillaryData []interface{}\n}\n\n// PacketMetadata contains metadata for a packet.\ntype PacketMetadata struct {\n\tCaptureInfo\n\t// Truncated is true if packet decoding logic detects that there are fewer\n\t// bytes in the packet than are detailed in various headers (for example, if\n\t// the number of bytes in the IPv4 contents/payload is less than IPv4.Length).\n\t// This is also set automatically for packets captured off the wire if\n\t// CaptureInfo.CaptureLength < CaptureInfo.Length.\n\tTruncated bool\n}\n\n// Packet is the primary object used by gopacket.  Packets are created by a\n// Decoder's Decode call.  A packet is made up of a set of Data, which\n// is broken into a number of Layers as it is decoded.\ntype Packet interface {\n\t//// Functions for outputting the packet as a human-readable string:\n\t//// ------------------------------------------------------------------\n\t// String returns a human-readable string representation of the packet.\n\t// It uses LayerString on each layer to output the layer.\n\tString() string\n\t// Dump returns a verbose human-readable string representation of the packet,\n\t// including a hex dump of all layers.  It uses LayerDump on each layer to\n\t// output the layer.\n\tDump() string\n\n\t//// Functions for accessing arbitrary packet layers:\n\t//// ------------------------------------------------------------------\n\t// Layers returns all layers in this packet, computing them as necessary\n\tLayers() []Layer\n\t// Layer returns the first layer in this packet of the given type, or nil\n\tLayer(LayerType) Layer\n\t// LayerClass returns the first layer in this packet of the given class,\n\t// or nil.\n\tLayerClass(LayerClass) Layer\n\n\t//// Functions for accessing specific types of packet layers.  These functions\n\t//// return the first layer of each type found within the packet.\n\t//// ------------------------------------------------------------------\n\t// LinkLayer returns the first link layer in the packet\n\tLinkLayer() LinkLayer\n\t// NetworkLayer returns the first network layer in the packet\n\tNetworkLayer() NetworkLayer\n\t// TransportLayer returns the first transport layer in the packet\n\tTransportLayer() TransportLayer\n\t// ApplicationLayer returns the first application layer in the packet\n\tApplicationLayer() ApplicationLayer\n\t// ErrorLayer is particularly useful, since it returns nil if the packet\n\t// was fully decoded successfully, and non-nil if an error was encountered\n\t// in decoding and the packet was only partially decoded.  Thus, its output\n\t// can be used to determine if the entire packet was able to be decoded.\n\tErrorLayer() ErrorLayer\n\n\t//// Functions for accessing data specific to the packet:\n\t//// ------------------------------------------------------------------\n\t// Data returns the set of bytes that make up this entire packet.\n\tData() []byte\n\t// Metadata returns packet metadata associated with this packet.\n\tMetadata() *PacketMetadata\n}\n\n// packet contains all the information we need to fulfill the Packet interface,\n// and its two \"subclasses\" (yes, no such thing in Go, bear with me),\n// eagerPacket and lazyPacket, provide eager and lazy decoding logic around the\n// various functions needed to access this information.\ntype packet struct {\n\t// data contains the entire packet data for a packet\n\tdata []byte\n\t// initialLayers is space for an initial set of layers already created inside\n\t// the packet.\n\tinitialLayers [6]Layer\n\t// layers contains each layer we've already decoded\n\tlayers []Layer\n\t// last is the last layer added to the packet\n\tlast Layer\n\t// metadata is the PacketMetadata for this packet\n\tmetadata PacketMetadata\n\n\tdecodeOptions DecodeOptions\n\n\t// Pointers to the various important layers\n\tlink        LinkLayer\n\tnetwork     NetworkLayer\n\ttransport   TransportLayer\n\tapplication ApplicationLayer\n\tfailure     ErrorLayer\n}\n\nfunc (p *packet) SetTruncated() {\n\tp.metadata.Truncated = true\n}\n\nfunc (p *packet) SetLinkLayer(l LinkLayer) {\n\tif p.link == nil {\n\t\tp.link = l\n\t}\n}\n\nfunc (p *packet) SetNetworkLayer(l NetworkLayer) {\n\tif p.network == nil {\n\t\tp.network = l\n\t}\n}\n\nfunc (p *packet) SetTransportLayer(l TransportLayer) {\n\tif p.transport == nil {\n\t\tp.transport = l\n\t}\n}\n\nfunc (p *packet) SetApplicationLayer(l ApplicationLayer) {\n\tif p.application == nil {\n\t\tp.application = l\n\t}\n}\n\nfunc (p *packet) SetErrorLayer(l ErrorLayer) {\n\tif p.failure == nil {\n\t\tp.failure = l\n\t}\n}\n\nfunc (p *packet) AddLayer(l Layer) {\n\tp.layers = append(p.layers, l)\n\tp.last = l\n}\n\nfunc (p *packet) DumpPacketData() {\n\tfmt.Fprint(os.Stderr, p.packetDump())\n\tos.Stderr.Sync()\n}\n\nfunc (p *packet) Metadata() *PacketMetadata {\n\treturn &p.metadata\n}\n\nfunc (p *packet) Data() []byte {\n\treturn p.data\n}\n\nfunc (p *packet) DecodeOptions() *DecodeOptions {\n\treturn &p.decodeOptions\n}\n\nfunc (p *packet) addFinalDecodeError(err error, stack []byte) {\n\tfail := &DecodeFailure{err: err, stack: stack}\n\tif p.last == nil {\n\t\tfail.data = p.data\n\t} else {\n\t\tfail.data = p.last.LayerPayload()\n\t}\n\tp.AddLayer(fail)\n\tp.SetErrorLayer(fail)\n}\n\nfunc (p *packet) recoverDecodeError() {\n\tif !p.decodeOptions.SkipDecodeRecovery {\n\t\tif r := recover(); r != nil {\n\t\t\tp.addFinalDecodeError(fmt.Errorf(\"%v\", r), debug.Stack())\n\t\t}\n\t}\n}\n\n// LayerString outputs an individual layer as a string.  The layer is output\n// in a single line, with no trailing newline.  This function is specifically\n// designed to do the right thing for most layers... it follows the following\n// rules:\n//  * If the Layer has a String function, just output that.\n//  * Otherwise, output all exported fields in the layer, recursing into\n//    exported slices and structs.\n// NOTE:  This is NOT THE SAME AS fmt's \"%#v\".  %#v will output both exported\n// and unexported fields... many times packet layers contain unexported stuff\n// that would just mess up the output of the layer, see for example the\n// Payload layer and it's internal 'data' field, which contains a large byte\n// array that would really mess up formatting.\nfunc LayerString(l Layer) string {\n\treturn fmt.Sprintf(\"%v\\t%s\", l.LayerType(), layerString(reflect.ValueOf(l), false, false))\n}\n\n// Dumper dumps verbose information on a value.  If a layer type implements\n// Dumper, then its LayerDump() string will include the results in its output.\ntype Dumper interface {\n\tDump() string\n}\n\n// LayerDump outputs a very verbose string representation of a layer.  Its\n// output is a concatenation of LayerString(l) and hex.Dump(l.LayerContents()).\n// It contains newlines and ends with a newline.\nfunc LayerDump(l Layer) string {\n\tvar b bytes.Buffer\n\tb.WriteString(LayerString(l))\n\tb.WriteByte('\\n')\n\tif d, ok := l.(Dumper); ok {\n\t\tdump := d.Dump()\n\t\tif dump != \"\" {\n\t\t\tb.WriteString(dump)\n\t\t\tif dump[len(dump)-1] != '\\n' {\n\t\t\t\tb.WriteByte('\\n')\n\t\t\t}\n\t\t}\n\t}\n\tb.WriteString(hex.Dump(l.LayerContents()))\n\treturn b.String()\n}\n\n// layerString outputs, recursively, a layer in a \"smart\" way.  See docs for\n// LayerString for more details.\n//\n// Params:\n//   i - value to write out\n//   anonymous:  if we're currently recursing an anonymous member of a struct\n//   writeSpace:  if we've already written a value in a struct, and need to\n//     write a space before writing more.  This happens when we write various\n//     anonymous values, and need to keep writing more.\nfunc layerString(v reflect.Value, anonymous bool, writeSpace bool) string {\n\t// Let String() functions take precedence.\n\tif v.CanInterface() {\n\t\tif s, ok := v.Interface().(fmt.Stringer); ok {\n\t\t\treturn s.String()\n\t\t}\n\t}\n\t// Reflect, and spit out all the exported fields as key=value.\n\tswitch v.Type().Kind() {\n\tcase reflect.Interface, reflect.Ptr:\n\t\tif v.IsNil() {\n\t\t\treturn \"nil\"\n\t\t}\n\t\tr := v.Elem()\n\t\treturn layerString(r, anonymous, writeSpace)\n\tcase reflect.Struct:\n\t\tvar b bytes.Buffer\n\t\ttyp := v.Type()\n\t\tif !anonymous {\n\t\t\tb.WriteByte('{')\n\t\t}\n\t\tfor i := 0; i < v.NumField(); i++ {\n\t\t\t// Check if this is upper-case.\n\t\t\tftype := typ.Field(i)\n\t\t\tf := v.Field(i)\n\t\t\tif ftype.Anonymous {\n\t\t\t\tanonStr := layerString(f, true, writeSpace)\n\t\t\t\twriteSpace = writeSpace || anonStr != \"\"\n\t\t\t\tb.WriteString(anonStr)\n\t\t\t} else if ftype.PkgPath == \"\" { // exported\n\t\t\t\tif writeSpace {\n\t\t\t\t\tb.WriteByte(' ')\n\t\t\t\t}\n\t\t\t\twriteSpace = true\n\t\t\t\tfmt.Fprintf(&b, \"%s=%s\", typ.Field(i).Name, layerString(f, false, writeSpace))\n\t\t\t}\n\t\t}\n\t\tif !anonymous {\n\t\t\tb.WriteByte('}')\n\t\t}\n\t\treturn b.String()\n\tcase reflect.Slice:\n\t\tvar b bytes.Buffer\n\t\tb.WriteByte('[')\n\t\tif v.Len() > 4 {\n\t\t\tfmt.Fprintf(&b, \"..%d..\", v.Len())\n\t\t} else {\n\t\t\tfor j := 0; j < v.Len(); j++ {\n\t\t\t\tif j != 0 {\n\t\t\t\t\tb.WriteString(\", \")\n\t\t\t\t}\n\t\t\t\tb.WriteString(layerString(v.Index(j), false, false))\n\t\t\t}\n\t\t}\n\t\tb.WriteByte(']')\n\t\treturn b.String()\n\t}\n\treturn fmt.Sprintf(\"%v\", v.Interface())\n}\n\nconst (\n\tlongBytesLength = 128\n)\n\n// LongBytesGoString returns a string representation of the byte slice shortened\n// using the format '<type>{<truncated slice> ... (<n> bytes)}' if it\n// exceeds a predetermined length. Can be used to avoid filling the display with\n// very long byte strings.\nfunc LongBytesGoString(buf []byte) string {\n\tif len(buf) < longBytesLength {\n\t\treturn fmt.Sprintf(\"%#v\", buf)\n\t}\n\ts := fmt.Sprintf(\"%#v\", buf[:longBytesLength-1])\n\ts = strings.TrimSuffix(s, \"}\")\n\treturn fmt.Sprintf(\"%s ... (%d bytes)}\", s, len(buf))\n}\n\nfunc baseLayerString(value reflect.Value) string {\n\tt := value.Type()\n\tcontent := value.Field(0)\n\tc := make([]byte, content.Len())\n\tfor i := range c {\n\t\tc[i] = byte(content.Index(i).Uint())\n\t}\n\tpayload := value.Field(1)\n\tp := make([]byte, payload.Len())\n\tfor i := range p {\n\t\tp[i] = byte(payload.Index(i).Uint())\n\t}\n\treturn fmt.Sprintf(\"%s{Contents:%s, Payload:%s}\", t.String(),\n\t\tLongBytesGoString(c),\n\t\tLongBytesGoString(p))\n}\n\nfunc layerGoString(i interface{}, b *bytes.Buffer) {\n\tif s, ok := i.(fmt.GoStringer); ok {\n\t\tb.WriteString(s.GoString())\n\t\treturn\n\t}\n\n\tvar v reflect.Value\n\tvar ok bool\n\tif v, ok = i.(reflect.Value); !ok {\n\t\tv = reflect.ValueOf(i)\n\t}\n\tswitch v.Kind() {\n\tcase reflect.Ptr, reflect.Interface:\n\t\tif v.Kind() == reflect.Ptr {\n\t\t\tb.WriteByte('&')\n\t\t}\n\t\tlayerGoString(v.Elem().Interface(), b)\n\tcase reflect.Struct:\n\t\tt := v.Type()\n\t\tb.WriteString(t.String())\n\t\tb.WriteByte('{')\n\t\tfor i := 0; i < v.NumField(); i++ {\n\t\t\tif i > 0 {\n\t\t\t\tb.WriteString(\", \")\n\t\t\t}\n\t\t\tif t.Field(i).Name == \"BaseLayer\" {\n\t\t\t\tfmt.Fprintf(b, \"BaseLayer:%s\", baseLayerString(v.Field(i)))\n\t\t\t} else if v.Field(i).Kind() == reflect.Struct {\n\t\t\t\tfmt.Fprintf(b, \"%s:\", t.Field(i).Name)\n\t\t\t\tlayerGoString(v.Field(i), b)\n\t\t\t} else if v.Field(i).Kind() == reflect.Ptr {\n\t\t\t\tb.WriteByte('&')\n\t\t\t\tlayerGoString(v.Field(i), b)\n\t\t\t} else {\n\t\t\t\tfmt.Fprintf(b, \"%s:%#v\", t.Field(i).Name, v.Field(i))\n\t\t\t}\n\t\t}\n\t\tb.WriteByte('}')\n\tdefault:\n\t\tfmt.Fprintf(b, \"%#v\", i)\n\t}\n}\n\n// LayerGoString returns a representation of the layer in Go syntax,\n// taking care to shorten \"very long\" BaseLayer byte slices\nfunc LayerGoString(l Layer) string {\n\tb := new(bytes.Buffer)\n\tlayerGoString(l, b)\n\treturn b.String()\n}\n\nfunc (p *packet) packetString() string {\n\tvar b bytes.Buffer\n\tfmt.Fprintf(&b, \"PACKET: %d bytes\", len(p.Data()))\n\tif p.metadata.Truncated {\n\t\tb.WriteString(\", truncated\")\n\t}\n\tif p.metadata.Length > 0 {\n\t\tfmt.Fprintf(&b, \", wire length %d cap length %d\", p.metadata.Length, p.metadata.CaptureLength)\n\t}\n\tif !p.metadata.Timestamp.IsZero() {\n\t\tfmt.Fprintf(&b, \" @ %v\", p.metadata.Timestamp)\n\t}\n\tb.WriteByte('\\n')\n\tfor i, l := range p.layers {\n\t\tfmt.Fprintf(&b, \"- Layer %d (%02d bytes) = %s\\n\", i+1, len(l.LayerContents()), LayerString(l))\n\t}\n\treturn b.String()\n}\n\nfunc (p *packet) packetDump() string {\n\tvar b bytes.Buffer\n\tfmt.Fprintf(&b, \"-- FULL PACKET DATA (%d bytes) ------------------------------------\\n%s\", len(p.data), hex.Dump(p.data))\n\tfor i, l := range p.layers {\n\t\tfmt.Fprintf(&b, \"--- Layer %d ---\\n%s\", i+1, LayerDump(l))\n\t}\n\treturn b.String()\n}\n\n// eagerPacket is a packet implementation that does eager decoding.  Upon\n// initial construction, it decodes all the layers it can from packet data.\n// eagerPacket implements Packet and PacketBuilder.\ntype eagerPacket struct {\n\tpacket\n}\n\nvar errNilDecoder = errors.New(\"NextDecoder passed nil decoder, probably an unsupported decode type\")\n\nfunc (p *eagerPacket) NextDecoder(next Decoder) error {\n\tif next == nil {\n\t\treturn errNilDecoder\n\t}\n\tif p.last == nil {\n\t\treturn errors.New(\"NextDecoder called, but no layers added yet\")\n\t}\n\td := p.last.LayerPayload()\n\tif len(d) == 0 {\n\t\treturn nil\n\t}\n\t// Since we're eager, immediately call the next decoder.\n\treturn next.Decode(d, p)\n}\nfunc (p *eagerPacket) initialDecode(dec Decoder) {\n\tdefer p.recoverDecodeError()\n\terr := dec.Decode(p.data, p)\n\tif err != nil {\n\t\tp.addFinalDecodeError(err, nil)\n\t}\n}\nfunc (p *eagerPacket) LinkLayer() LinkLayer {\n\treturn p.link\n}\nfunc (p *eagerPacket) NetworkLayer() NetworkLayer {\n\treturn p.network\n}\nfunc (p *eagerPacket) TransportLayer() TransportLayer {\n\treturn p.transport\n}\nfunc (p *eagerPacket) ApplicationLayer() ApplicationLayer {\n\treturn p.application\n}\nfunc (p *eagerPacket) ErrorLayer() ErrorLayer {\n\treturn p.failure\n}\nfunc (p *eagerPacket) Layers() []Layer {\n\treturn p.layers\n}\nfunc (p *eagerPacket) Layer(t LayerType) Layer {\n\tfor _, l := range p.layers {\n\t\tif l.LayerType() == t {\n\t\t\treturn l\n\t\t}\n\t}\n\treturn nil\n}\nfunc (p *eagerPacket) LayerClass(lc LayerClass) Layer {\n\tfor _, l := range p.layers {\n\t\tif lc.Contains(l.LayerType()) {\n\t\t\treturn l\n\t\t}\n\t}\n\treturn nil\n}\nfunc (p *eagerPacket) String() string { return p.packetString() }\nfunc (p *eagerPacket) Dump() string   { return p.packetDump() }\n\n// lazyPacket does lazy decoding on its packet data.  On construction it does\n// no initial decoding.  For each function call, it decodes only as many layers\n// as are necessary to compute the return value for that function.\n// lazyPacket implements Packet and PacketBuilder.\ntype lazyPacket struct {\n\tpacket\n\tnext Decoder\n}\n\nfunc (p *lazyPacket) NextDecoder(next Decoder) error {\n\tif next == nil {\n\t\treturn errNilDecoder\n\t}\n\tp.next = next\n\treturn nil\n}\nfunc (p *lazyPacket) decodeNextLayer() {\n\tif p.next == nil {\n\t\treturn\n\t}\n\td := p.data\n\tif p.last != nil {\n\t\td = p.last.LayerPayload()\n\t}\n\tnext := p.next\n\tp.next = nil\n\t// We've just set p.next to nil, so if we see we have no data, this should be\n\t// the final call we get to decodeNextLayer if we return here.\n\tif len(d) == 0 {\n\t\treturn\n\t}\n\tdefer p.recoverDecodeError()\n\terr := next.Decode(d, p)\n\tif err != nil {\n\t\tp.addFinalDecodeError(err, nil)\n\t}\n}\nfunc (p *lazyPacket) LinkLayer() LinkLayer {\n\tfor p.link == nil && p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.link\n}\nfunc (p *lazyPacket) NetworkLayer() NetworkLayer {\n\tfor p.network == nil && p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.network\n}\nfunc (p *lazyPacket) TransportLayer() TransportLayer {\n\tfor p.transport == nil && p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.transport\n}\nfunc (p *lazyPacket) ApplicationLayer() ApplicationLayer {\n\tfor p.application == nil && p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.application\n}\nfunc (p *lazyPacket) ErrorLayer() ErrorLayer {\n\tfor p.failure == nil && p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.failure\n}\nfunc (p *lazyPacket) Layers() []Layer {\n\tfor p.next != nil {\n\t\tp.decodeNextLayer()\n\t}\n\treturn p.layers\n}\nfunc (p *lazyPacket) Layer(t LayerType) Layer {\n\tfor _, l := range p.layers {\n\t\tif l.LayerType() == t {\n\t\t\treturn l\n\t\t}\n\t}\n\tnumLayers := len(p.layers)\n\tfor p.next != nil {\n\t\tp.decodeNextLayer()\n\t\tfor _, l := range p.layers[numLayers:] {\n\t\t\tif l.LayerType() == t {\n\t\t\t\treturn l\n\t\t\t}\n\t\t}\n\t\tnumLayers = len(p.layers)\n\t}\n\treturn nil\n}\nfunc (p *lazyPacket) LayerClass(lc LayerClass) Layer {\n\tfor _, l := range p.layers {\n\t\tif lc.Contains(l.LayerType()) {\n\t\t\treturn l\n\t\t}\n\t}\n\tnumLayers := len(p.layers)\n\tfor p.next != nil {\n\t\tp.decodeNextLayer()\n\t\tfor _, l := range p.layers[numLayers:] {\n\t\t\tif lc.Contains(l.LayerType()) {\n\t\t\t\treturn l\n\t\t\t}\n\t\t}\n\t\tnumLayers = len(p.layers)\n\t}\n\treturn nil\n}\nfunc (p *lazyPacket) String() string { p.Layers(); return p.packetString() }\nfunc (p *lazyPacket) Dump() string   { p.Layers(); return p.packetDump() }\n\n// DecodeOptions tells gopacket how to decode a packet.\ntype DecodeOptions struct {\n\t// Lazy decoding decodes the minimum number of layers needed to return data\n\t// for a packet at each function call.  Be careful using this with concurrent\n\t// packet processors, as each call to packet.* could mutate the packet, and\n\t// two concurrent function calls could interact poorly.\n\tLazy bool\n\t// NoCopy decoding doesn't copy its input buffer into storage that's owned by\n\t// the packet.  If you can guarantee that the bytes underlying the slice\n\t// passed into NewPacket aren't going to be modified, this can be faster.  If\n\t// there's any chance that those bytes WILL be changed, this will invalidate\n\t// your packets.\n\tNoCopy bool\n\t// SkipDecodeRecovery skips over panic recovery during packet decoding.\n\t// Normally, when packets decode, if a panic occurs, that panic is captured\n\t// by a recover(), and a DecodeFailure layer is added to the packet detailing\n\t// the issue.  If this flag is set, panics are instead allowed to continue up\n\t// the stack.\n\tSkipDecodeRecovery bool\n\t// DecodeStreamsAsDatagrams enables routing of application-level layers in the TCP\n\t// decoder. If true, we should try to decode layers after TCP in single packets.\n\t// This is disabled by default because the reassembly package drives the decoding\n\t// of TCP payload data after reassembly.\n\tDecodeStreamsAsDatagrams bool\n}\n\n// Default decoding provides the safest (but slowest) method for decoding\n// packets.  It eagerly processes all layers (so it's concurrency-safe) and it\n// copies its input buffer upon creation of the packet (so the packet remains\n// valid if the underlying slice is modified.  Both of these take time,\n// though, so beware.  If you can guarantee that the packet will only be used\n// by one goroutine at a time, set Lazy decoding.  If you can guarantee that\n// the underlying slice won't change, set NoCopy decoding.\nvar Default = DecodeOptions{}\n\n// Lazy is a DecodeOptions with just Lazy set.\nvar Lazy = DecodeOptions{Lazy: true}\n\n// NoCopy is a DecodeOptions with just NoCopy set.\nvar NoCopy = DecodeOptions{NoCopy: true}\n\n// DecodeStreamsAsDatagrams is a DecodeOptions with just DecodeStreamsAsDatagrams set.\nvar DecodeStreamsAsDatagrams = DecodeOptions{DecodeStreamsAsDatagrams: true}\n\n// NewPacket creates a new Packet object from a set of bytes.  The\n// firstLayerDecoder tells it how to interpret the first layer from the bytes,\n// future layers will be generated from that first layer automatically.\nfunc NewPacket(data []byte, firstLayerDecoder Decoder, options DecodeOptions) Packet {\n\tif !options.NoCopy {\n\t\tdataCopy := make([]byte, len(data))\n\t\tcopy(dataCopy, data)\n\t\tdata = dataCopy\n\t}\n\tif options.Lazy {\n\t\tp := &lazyPacket{\n\t\t\tpacket: packet{data: data, decodeOptions: options},\n\t\t\tnext:   firstLayerDecoder,\n\t\t}\n\t\tp.layers = p.initialLayers[:0]\n\t\t// Crazy craziness:\n\t\t// If the following return statemet is REMOVED, and Lazy is FALSE, then\n\t\t// eager packet processing becomes 17% FASTER.  No, there is no logical\n\t\t// explanation for this.  However, it's such a hacky micro-optimization that\n\t\t// we really can't rely on it.  It appears to have to do with the size the\n\t\t// compiler guesses for this function's stack space, since one symptom is\n\t\t// that with the return statement in place, we more than double calls to\n\t\t// runtime.morestack/runtime.lessstack.  We'll hope the compiler gets better\n\t\t// over time and we get this optimization for free.  Until then, we'll have\n\t\t// to live with slower packet processing.\n\t\treturn p\n\t}\n\tp := &eagerPacket{\n\t\tpacket: packet{data: data, decodeOptions: options},\n\t}\n\tp.layers = p.initialLayers[:0]\n\tp.initialDecode(firstLayerDecoder)\n\treturn p\n}\n\n// PacketDataSource is an interface for some source of packet data.  Users may\n// create their own implementations, or use the existing implementations in\n// gopacket/pcap (libpcap, allows reading from live interfaces or from\n// pcap files) or gopacket/pfring (PF_RING, allows reading from live\n// interfaces).\ntype PacketDataSource interface {\n\t// ReadPacketData returns the next packet available from this data source.\n\t// It returns:\n\t//  data:  The bytes of an individual packet.\n\t//  ci:  Metadata about the capture\n\t//  err:  An error encountered while reading packet data.  If err != nil,\n\t//    then data/ci will be ignored.\n\tReadPacketData() (data []byte, ci CaptureInfo, err error)\n}\n\n// ConcatFinitePacketDataSources returns a PacketDataSource that wraps a set\n// of internal PacketDataSources, each of which will stop with io.EOF after\n// reading a finite number of packets.  The returned PacketDataSource will\n// return all packets from the first finite source, followed by all packets from\n// the second, etc.  Once all finite sources have returned io.EOF, the returned\n// source will as well.\nfunc ConcatFinitePacketDataSources(pds ...PacketDataSource) PacketDataSource {\n\tc := concat(pds)\n\treturn &c\n}\n\ntype concat []PacketDataSource\n\nfunc (c *concat) ReadPacketData() (data []byte, ci CaptureInfo, err error) {\n\tfor len(*c) > 0 {\n\t\tdata, ci, err = (*c)[0].ReadPacketData()\n\t\tif err == io.EOF {\n\t\t\t*c = (*c)[1:]\n\t\t\tcontinue\n\t\t}\n\t\treturn\n\t}\n\treturn nil, CaptureInfo{}, io.EOF\n}\n\n// ZeroCopyPacketDataSource is an interface to pull packet data from sources\n// that allow data to be returned without copying to a user-controlled buffer.\n// It's very similar to PacketDataSource, except that the caller must be more\n// careful in how the returned buffer is handled.\ntype ZeroCopyPacketDataSource interface {\n\t// ZeroCopyReadPacketData returns the next packet available from this data source.\n\t// It returns:\n\t//  data:  The bytes of an individual packet.  Unlike with\n\t//    PacketDataSource's ReadPacketData, the slice returned here points\n\t//    to a buffer owned by the data source.  In particular, the bytes in\n\t//    this buffer may be changed by future calls to\n\t//    ZeroCopyReadPacketData.  Do not use the returned buffer after\n\t//    subsequent ZeroCopyReadPacketData calls.\n\t//  ci:  Metadata about the capture\n\t//  err:  An error encountered while reading packet data.  If err != nil,\n\t//    then data/ci will be ignored.\n\tZeroCopyReadPacketData() (data []byte, ci CaptureInfo, err error)\n}\n\n// PacketSource reads in packets from a PacketDataSource, decodes them, and\n// returns them.\n//\n// There are currently two different methods for reading packets in through\n// a PacketSource:\n//\n// Reading With Packets Function\n//\n// This method is the most convenient and easiest to code, but lacks\n// flexibility.  Packets returns a 'chan Packet', then asynchronously writes\n// packets into that channel.  Packets uses a blocking channel, and closes\n// it if an io.EOF is returned by the underlying PacketDataSource.  All other\n// PacketDataSource errors are ignored and discarded.\n//  for packet := range packetSource.Packets() {\n//    ...\n//  }\n//\n// Reading With NextPacket Function\n//\n// This method is the most flexible, and exposes errors that may be\n// encountered by the underlying PacketDataSource.  It's also the fastest\n// in a tight loop, since it doesn't have the overhead of a channel\n// read/write.  However, it requires the user to handle errors, most\n// importantly the io.EOF error in cases where packets are being read from\n// a file.\n//  for {\n//    packet, err := packetSource.NextPacket()\n//    if err == io.EOF {\n//      break\n//    } else if err != nil {\n//      log.Println(\"Error:\", err)\n//      continue\n//    }\n//    handlePacket(packet)  // Do something with each packet.\n//  }\ntype PacketSource struct {\n\tsource  PacketDataSource\n\tdecoder Decoder\n\t// DecodeOptions is the set of options to use for decoding each piece\n\t// of packet data.  This can/should be changed by the user to reflect the\n\t// way packets should be decoded.\n\tDecodeOptions\n\tc chan Packet\n}\n\n// NewPacketSource creates a packet data source.\nfunc NewPacketSource(source PacketDataSource, decoder Decoder) *PacketSource {\n\treturn &PacketSource{\n\t\tsource:  source,\n\t\tdecoder: decoder,\n\t}\n}\n\n// NextPacket returns the next decoded packet from the PacketSource.  On error,\n// it returns a nil packet and a non-nil error.\nfunc (p *PacketSource) NextPacket() (Packet, error) {\n\tdata, ci, err := p.source.ReadPacketData()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpacket := NewPacket(data, p.decoder, p.DecodeOptions)\n\tm := packet.Metadata()\n\tm.CaptureInfo = ci\n\tm.Truncated = m.Truncated || ci.CaptureLength < ci.Length\n\treturn packet, nil\n}\n\n// packetsToChannel reads in all packets from the packet source and sends them\n// to the given channel. This routine terminates when a non-temporary error\n// is returned by NextPacket().\nfunc (p *PacketSource) packetsToChannel() {\n\tdefer close(p.c)\n\tfor {\n\t\tpacket, err := p.NextPacket()\n\t\tif err == nil {\n\t\t\tp.c <- packet\n\t\t\tcontinue\n\t\t}\n\n\t\t// Immediately retry for temporary network errors\n\t\tif nerr, ok := err.(net.Error); ok && nerr.Temporary() {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Immediately retry for EAGAIN\n\t\tif err == syscall.EAGAIN {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Immediately break for known unrecoverable errors\n\t\tif err == io.EOF || err == io.ErrUnexpectedEOF ||\n\t\t\terr == io.ErrNoProgress || err == io.ErrClosedPipe || err == io.ErrShortBuffer ||\n\t\t\terr == syscall.EBADF ||\n\t\t\tstrings.Contains(err.Error(), \"use of closed file\") {\n\t\t\tbreak\n\t\t}\n\n\t\t// Sleep briefly and try again\n\t\ttime.Sleep(time.Millisecond * time.Duration(5))\n\t}\n}\n\n// Packets returns a channel of packets, allowing easy iterating over\n// packets.  Packets will be asynchronously read in from the underlying\n// PacketDataSource and written to the returned channel.  If the underlying\n// PacketDataSource returns an io.EOF error, the channel will be closed.\n// If any other error is encountered, it is ignored.\n//\n//  for packet := range packetSource.Packets() {\n//    handlePacket(packet)  // Do something with each packet.\n//  }\n//\n// If called more than once, returns the same channel.\nfunc (p *PacketSource) Packets() chan Packet {\n\tif p.c == nil {\n\t\tp.c = make(chan Packet, 1000)\n\t\tgo p.packetsToChannel()\n\t}\n\treturn p.c\n}\n"
        },
        {
          "name": "packet_test.go",
          "type": "blob",
          "size": 1.5556640625,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"io\"\n\t\"reflect\"\n\t\"testing\"\n)\n\ntype embedded struct {\n\tA, B int\n}\n\ntype embedding struct {\n\tembedded\n\tC, D int\n}\n\nfunc TestDumpEmbedded(t *testing.T) {\n\te := embedding{embedded: embedded{A: 1, B: 2}, C: 3, D: 4}\n\tif got, want := layerString(reflect.ValueOf(e), false, false), \"{A=1 B=2 C=3 D=4}\"; got != want {\n\t\tt.Errorf(\"embedded dump mismatch:\\n   got: %v\\n  want: %v\", got, want)\n\t}\n}\n\ntype singlePacketSource [1][]byte\n\nfunc (s *singlePacketSource) ReadPacketData() ([]byte, CaptureInfo, error) {\n\tif (*s)[0] == nil {\n\t\treturn nil, CaptureInfo{}, io.EOF\n\t}\n\tout := (*s)[0]\n\t(*s)[0] = nil\n\treturn out, CaptureInfo{}, nil\n}\n\nfunc TestConcatPacketSources(t *testing.T) {\n\tsourceA := &singlePacketSource{[]byte{1}}\n\tsourceB := &singlePacketSource{[]byte{2}}\n\tsourceC := &singlePacketSource{[]byte{3}}\n\tconcat := ConcatFinitePacketDataSources(sourceA, sourceB, sourceC)\n\ta, _, err := concat.ReadPacketData()\n\tif err != nil || len(a) != 1 || a[0] != 1 {\n\t\tt.Errorf(\"expected [1], got %v/%v\", a, err)\n\t}\n\tb, _, err := concat.ReadPacketData()\n\tif err != nil || len(b) != 1 || b[0] != 2 {\n\t\tt.Errorf(\"expected [2], got %v/%v\", b, err)\n\t}\n\tc, _, err := concat.ReadPacketData()\n\tif err != nil || len(c) != 1 || c[0] != 3 {\n\t\tt.Errorf(\"expected [3], got %v/%v\", c, err)\n\t}\n\tif _, _, err := concat.ReadPacketData(); err != io.EOF {\n\t\tt.Errorf(\"expected io.EOF, got %v\", err)\n\t}\n}\n"
        },
        {
          "name": "parser.go",
          "type": "blob",
          "size": 12.287109375,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n)\n\n// A container for single LayerType->DecodingLayer mapping.\ntype decodingLayerElem struct {\n\ttyp LayerType\n\tdec DecodingLayer\n}\n\n// DecodingLayer is an interface for packet layers that can decode themselves.\n//\n// The important part of DecodingLayer is that they decode themselves in-place.\n// Calling DecodeFromBytes on a DecodingLayer totally resets the entire layer to\n// the new state defined by the data passed in.  A returned error leaves the\n// DecodingLayer in an unknown intermediate state, thus its fields should not be\n// trusted.\n//\n// Because the DecodingLayer is resetting its own fields, a call to\n// DecodeFromBytes should normally not require any memory allocation.\ntype DecodingLayer interface {\n\t// DecodeFromBytes resets the internal state of this layer to the state\n\t// defined by the passed-in bytes.  Slices in the DecodingLayer may\n\t// reference the passed-in data, so care should be taken to copy it\n\t// first should later modification of data be required before the\n\t// DecodingLayer is discarded.\n\tDecodeFromBytes(data []byte, df DecodeFeedback) error\n\t// CanDecode returns the set of LayerTypes this DecodingLayer can\n\t// decode.  For Layers that are also DecodingLayers, this will most\n\t// often be that Layer's LayerType().\n\tCanDecode() LayerClass\n\t// NextLayerType returns the LayerType which should be used to decode\n\t// the LayerPayload.\n\tNextLayerType() LayerType\n\t// LayerPayload is the set of bytes remaining to decode after a call to\n\t// DecodeFromBytes.\n\tLayerPayload() []byte\n}\n\n// DecodingLayerFunc decodes given packet and stores decoded LayerType\n// values into specified slice. Returns either first encountered\n// unsupported LayerType value or decoding error. In case of success,\n// returns (LayerTypeZero, nil).\ntype DecodingLayerFunc func([]byte, *[]LayerType) (LayerType, error)\n\n// DecodingLayerContainer stores all DecodingLayer-s and serves as a\n// searching tool for DecodingLayerParser.\ntype DecodingLayerContainer interface {\n\t// Put adds new DecodingLayer to container. The new instance of\n\t// the same DecodingLayerContainer is returned so it may be\n\t// implemented as a value receiver.\n\tPut(DecodingLayer) DecodingLayerContainer\n\t// Decoder returns DecodingLayer to decode given LayerType and\n\t// true if it was found. If no decoder found, return false.\n\tDecoder(LayerType) (DecodingLayer, bool)\n\t// LayersDecoder returns DecodingLayerFunc which decodes given\n\t// packet, starting with specified LayerType and DecodeFeedback.\n\tLayersDecoder(first LayerType, df DecodeFeedback) DecodingLayerFunc\n}\n\n// DecodingLayerSparse is a sparse array-based implementation of\n// DecodingLayerContainer. Each DecodingLayer is addressed in an\n// allocated slice by LayerType value itself. Though this is the\n// fastest container it may be memory-consuming if used with big\n// LayerType values.\ntype DecodingLayerSparse []DecodingLayer\n\n// Put implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerSparse) Put(d DecodingLayer) DecodingLayerContainer {\n\tmaxLayerType := LayerType(len(dl) - 1)\n\tfor _, typ := range d.CanDecode().LayerTypes() {\n\t\tif typ > maxLayerType {\n\t\t\tmaxLayerType = typ\n\t\t}\n\t}\n\n\tif extra := maxLayerType - LayerType(len(dl)) + 1; extra > 0 {\n\t\tdl = append(dl, make([]DecodingLayer, extra)...)\n\t}\n\n\tfor _, typ := range d.CanDecode().LayerTypes() {\n\t\tdl[typ] = d\n\t}\n\treturn dl\n}\n\n// LayersDecoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerSparse) LayersDecoder(first LayerType, df DecodeFeedback) DecodingLayerFunc {\n\treturn LayersDecoder(dl, first, df)\n}\n\n// Decoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerSparse) Decoder(typ LayerType) (DecodingLayer, bool) {\n\tif int64(typ) < int64(len(dl)) {\n\t\tdecoder := dl[typ]\n\t\treturn decoder, decoder != nil\n\t}\n\treturn nil, false\n}\n\n// DecodingLayerArray is an array-based implementation of\n// DecodingLayerContainer. Each DecodingLayer is searched linearly in\n// an allocated slice in one-by-one fashion.\ntype DecodingLayerArray []decodingLayerElem\n\n// Put implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerArray) Put(d DecodingLayer) DecodingLayerContainer {\nTYPES:\n\tfor _, typ := range d.CanDecode().LayerTypes() {\n\t\tfor i := range dl {\n\t\t\tif dl[i].typ == typ {\n\t\t\t\tdl[i].dec = d\n\t\t\t\tcontinue TYPES\n\t\t\t}\n\t\t}\n\t\tdl = append(dl, decodingLayerElem{typ, d})\n\t}\n\treturn dl\n}\n\n// Decoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerArray) Decoder(typ LayerType) (DecodingLayer, bool) {\n\tfor i := range dl {\n\t\tif dl[i].typ == typ {\n\t\t\treturn dl[i].dec, true\n\t\t}\n\t}\n\treturn nil, false\n}\n\n// LayersDecoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerArray) LayersDecoder(first LayerType, df DecodeFeedback) DecodingLayerFunc {\n\treturn LayersDecoder(dl, first, df)\n}\n\n// DecodingLayerMap is an map-based implementation of\n// DecodingLayerContainer. Each DecodingLayer is searched in a map\n// hashed by LayerType value.\ntype DecodingLayerMap map[LayerType]DecodingLayer\n\n// Put implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerMap) Put(d DecodingLayer) DecodingLayerContainer {\n\tfor _, typ := range d.CanDecode().LayerTypes() {\n\t\tif dl == nil {\n\t\t\tdl = make(map[LayerType]DecodingLayer)\n\t\t}\n\t\tdl[typ] = d\n\t}\n\treturn dl\n}\n\n// Decoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerMap) Decoder(typ LayerType) (DecodingLayer, bool) {\n\td, ok := dl[typ]\n\treturn d, ok\n}\n\n// LayersDecoder implements DecodingLayerContainer interface.\nfunc (dl DecodingLayerMap) LayersDecoder(first LayerType, df DecodeFeedback) DecodingLayerFunc {\n\treturn LayersDecoder(dl, first, df)\n}\n\n// Static code check.\nvar (\n\t_ = []DecodingLayerContainer{\n\t\tDecodingLayerSparse(nil),\n\t\tDecodingLayerMap(nil),\n\t\tDecodingLayerArray(nil),\n\t}\n)\n\n// DecodingLayerParser parses a given set of layer types.  See DecodeLayers for\n// more information on how DecodingLayerParser should be used.\ntype DecodingLayerParser struct {\n\t// DecodingLayerParserOptions is the set of options available to the\n\t// user to define the parser's behavior.\n\tDecodingLayerParserOptions\n\tdlc   DecodingLayerContainer\n\tfirst LayerType\n\tdf    DecodeFeedback\n\n\tdecodeFunc DecodingLayerFunc\n\n\t// Truncated is set when a decode layer detects that the packet has been\n\t// truncated.\n\tTruncated bool\n}\n\n// AddDecodingLayer adds a decoding layer to the parser.  This adds support for\n// the decoding layer's CanDecode layers to the parser... should they be\n// encountered, they'll be parsed.\nfunc (l *DecodingLayerParser) AddDecodingLayer(d DecodingLayer) {\n\tl.SetDecodingLayerContainer(l.dlc.Put(d))\n}\n\n// SetTruncated is used by DecodingLayers to set the Truncated boolean in the\n// DecodingLayerParser.  Users should simply read Truncated after calling\n// DecodeLayers.\nfunc (l *DecodingLayerParser) SetTruncated() {\n\tl.Truncated = true\n}\n\n// NewDecodingLayerParser creates a new DecodingLayerParser and adds in all\n// of the given DecodingLayers with AddDecodingLayer.\n//\n// Each call to DecodeLayers will attempt to decode the given bytes first by\n// treating them as a 'first'-type layer, then by using NextLayerType on\n// subsequently decoded layers to find the next relevant decoder.  Should a\n// deoder not be available for the layer type returned by NextLayerType,\n// decoding will stop.\n//\n// NewDecodingLayerParser uses DecodingLayerMap container by\n// default.\nfunc NewDecodingLayerParser(first LayerType, decoders ...DecodingLayer) *DecodingLayerParser {\n\tdlp := &DecodingLayerParser{first: first}\n\tdlp.df = dlp // Cast this once to the interface\n\t// default container\n\tdlc := DecodingLayerContainer(DecodingLayerMap(make(map[LayerType]DecodingLayer)))\n\tfor _, d := range decoders {\n\t\tdlc = dlc.Put(d)\n\t}\n\n\tdlp.SetDecodingLayerContainer(dlc)\n\treturn dlp\n}\n\n// SetDecodingLayerContainer specifies container with decoders. This\n// call replaces all decoders already registered in given instance of\n// DecodingLayerParser.\nfunc (l *DecodingLayerParser) SetDecodingLayerContainer(dlc DecodingLayerContainer) {\n\tl.dlc = dlc\n\tl.decodeFunc = l.dlc.LayersDecoder(l.first, l.df)\n}\n\n// DecodeLayers decodes as many layers as possible from the given data.  It\n// initially treats the data as layer type 'typ', then uses NextLayerType on\n// each subsequent decoded layer until it gets to a layer type it doesn't know\n// how to parse.\n//\n// For each layer successfully decoded, DecodeLayers appends the layer type to\n// the decoded slice.  DecodeLayers truncates the 'decoded' slice initially, so\n// there's no need to empty it yourself.\n//\n// This decoding method is about an order of magnitude faster than packet\n// decoding, because it only decodes known layers that have already been\n// allocated.  This means it doesn't need to allocate each layer it returns...\n// instead it overwrites the layers that already exist.\n//\n// Example usage:\n//    func main() {\n//      var eth layers.Ethernet\n//      var ip4 layers.IPv4\n//      var ip6 layers.IPv6\n//      var tcp layers.TCP\n//      var udp layers.UDP\n//      var payload gopacket.Payload\n//      parser := gopacket.NewDecodingLayerParser(layers.LayerTypeEthernet, &eth, &ip4, &ip6, &tcp, &udp, &payload)\n//      var source gopacket.PacketDataSource = getMyDataSource()\n//      decodedLayers := make([]gopacket.LayerType, 0, 10)\n//      for {\n//        data, _, err := source.ReadPacketData()\n//        if err != nil {\n//          fmt.Println(\"Error reading packet data: \", err)\n//          continue\n//        }\n//        fmt.Println(\"Decoding packet\")\n//        err = parser.DecodeLayers(data, &decodedLayers)\n//        for _, typ := range decodedLayers {\n//          fmt.Println(\"  Successfully decoded layer type\", typ)\n//          switch typ {\n//            case layers.LayerTypeEthernet:\n//              fmt.Println(\"    Eth \", eth.SrcMAC, eth.DstMAC)\n//            case layers.LayerTypeIPv4:\n//              fmt.Println(\"    IP4 \", ip4.SrcIP, ip4.DstIP)\n//            case layers.LayerTypeIPv6:\n//              fmt.Println(\"    IP6 \", ip6.SrcIP, ip6.DstIP)\n//            case layers.LayerTypeTCP:\n//              fmt.Println(\"    TCP \", tcp.SrcPort, tcp.DstPort)\n//            case layers.LayerTypeUDP:\n//              fmt.Println(\"    UDP \", udp.SrcPort, udp.DstPort)\n//          }\n//        }\n//        if decodedLayers.Truncated {\n//          fmt.Println(\"  Packet has been truncated\")\n//        }\n//        if err != nil {\n//          fmt.Println(\"  Error encountered:\", err)\n//        }\n//      }\n//    }\n//\n// If DecodeLayers is unable to decode the next layer type, it will return the\n// error UnsupportedLayerType.\nfunc (l *DecodingLayerParser) DecodeLayers(data []byte, decoded *[]LayerType) (err error) {\n\tl.Truncated = false\n\tif !l.IgnorePanic {\n\t\tdefer panicToError(&err)\n\t}\n\ttyp, err := l.decodeFunc(data, decoded)\n\tif typ != LayerTypeZero {\n\t\t// no decoder\n\t\tif l.IgnoreUnsupported {\n\t\t\treturn nil\n\t\t}\n\t\treturn UnsupportedLayerType(typ)\n\t}\n\treturn err\n}\n\n// UnsupportedLayerType is returned by DecodingLayerParser if DecodeLayers\n// encounters a layer type that the DecodingLayerParser has no decoder for.\ntype UnsupportedLayerType LayerType\n\n// Error implements the error interface, returning a string to say that the\n// given layer type is unsupported.\nfunc (e UnsupportedLayerType) Error() string {\n\treturn fmt.Sprintf(\"No decoder for layer type %v\", LayerType(e))\n}\n\nfunc panicToError(e *error) {\n\tif r := recover(); r != nil {\n\t\t*e = fmt.Errorf(\"panic: %v\", r)\n\t}\n}\n\n// DecodingLayerParserOptions provides options to affect the behavior of a given\n// DecodingLayerParser.\ntype DecodingLayerParserOptions struct {\n\t// IgnorePanic determines whether a DecodingLayerParser should stop\n\t// panics on its own (by returning them as an error from DecodeLayers)\n\t// or should allow them to raise up the stack.  Handling errors does add\n\t// latency to the process of decoding layers, but is much safer for\n\t// callers.  IgnorePanic defaults to false, thus if the caller does\n\t// nothing decode panics will be returned as errors.\n\tIgnorePanic bool\n\t// IgnoreUnsupported will stop parsing and return a nil error when it\n\t// encounters a layer it doesn't have a parser for, instead of returning an\n\t// UnsupportedLayerType error.  If this is true, it's up to the caller to make\n\t// sure that all expected layers have been parsed (by checking the decoded\n\t// slice).\n\tIgnoreUnsupported bool\n}\n"
        },
        {
          "name": "pcap",
          "type": "tree",
          "content": null
        },
        {
          "name": "pcapgo",
          "type": "tree",
          "content": null
        },
        {
          "name": "pfring",
          "type": "tree",
          "content": null
        },
        {
          "name": "reassembly",
          "type": "tree",
          "content": null
        },
        {
          "name": "routing",
          "type": "tree",
          "content": null
        },
        {
          "name": "tcpassembly",
          "type": "tree",
          "content": null
        },
        {
          "name": "time.go",
          "type": "blob",
          "size": 2.3564453125,
          "content": "// Copyright 2018 The GoPacket Authors. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"time\"\n)\n\n// TimestampResolution represents the resolution of timestamps in Base^Exponent.\ntype TimestampResolution struct {\n\tBase, Exponent int\n}\n\nfunc (t TimestampResolution) String() string {\n\treturn fmt.Sprintf(\"%d^%d\", t.Base, t.Exponent)\n}\n\n// ToDuration returns the smallest representable time difference as a time.Duration\nfunc (t TimestampResolution) ToDuration() time.Duration {\n\tif t.Base == 0 {\n\t\treturn 0\n\t}\n\tif t.Exponent == 0 {\n\t\treturn time.Second\n\t}\n\tswitch t.Base {\n\tcase 10:\n\t\treturn time.Duration(math.Pow10(t.Exponent + 9))\n\tcase 2:\n\t\tif t.Exponent < 0 {\n\t\t\treturn time.Second >> uint(-t.Exponent)\n\t\t}\n\t\treturn time.Second << uint(t.Exponent)\n\tdefault:\n\t\t// this might loose precision\n\t\treturn time.Duration(float64(time.Second) * math.Pow(float64(t.Base), float64(t.Exponent)))\n\t}\n}\n\n// TimestampResolutionInvalid represents an invalid timestamp resolution\nvar TimestampResolutionInvalid = TimestampResolution{}\n\n// TimestampResolutionMillisecond is a resolution of 10^-3s\nvar TimestampResolutionMillisecond = TimestampResolution{10, -3}\n\n// TimestampResolutionMicrosecond is a resolution of 10^-6s\nvar TimestampResolutionMicrosecond = TimestampResolution{10, -6}\n\n// TimestampResolutionNanosecond is a resolution of 10^-9s\nvar TimestampResolutionNanosecond = TimestampResolution{10, -9}\n\n// TimestampResolutionNTP is the resolution of NTP timestamps which is 2^-32 ≈ 233 picoseconds\nvar TimestampResolutionNTP = TimestampResolution{2, -32}\n\n// TimestampResolutionCaptureInfo is the resolution used in CaptureInfo, which his currently nanosecond\nvar TimestampResolutionCaptureInfo = TimestampResolutionNanosecond\n\n// PacketSourceResolution is an interface for packet data sources that\n// support reporting the timestamp resolution of the aqcuired timestamps.\n// Returned timestamps will always have NanosecondTimestampResolution due\n// to the use of time.Time, but scaling might have occured if acquired\n// timestamps have a different resolution.\ntype PacketSourceResolution interface {\n\t// Resolution returns the timestamp resolution of acquired timestamps before scaling to NanosecondTimestampResolution.\n\tResolution() TimestampResolution\n}\n"
        },
        {
          "name": "time_test.go",
          "type": "blob",
          "size": 1.205078125,
          "content": "// Copyright 2019 The GoPacket Authors. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestToDuration(t *testing.T) {\n\tfor i, test := range []struct {\n\t\tr TimestampResolution\n\t\td time.Duration\n\t}{\n\t\t{\n\t\t\tTimestampResolutionMillisecond,\n\t\t\ttime.Millisecond,\n\t\t},\n\t\t{\n\t\t\tTimestampResolutionMicrosecond,\n\t\t\ttime.Microsecond,\n\t\t},\n\t\t{\n\t\t\tTimestampResolutionNanosecond,\n\t\t\ttime.Nanosecond,\n\t\t},\n\t\t{\n\t\t\tTimestampResolutionNTP,\n\t\t\t0, // this is not representable since it's ~0.233 nanoseconds\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{2, -16},\n\t\t\t15258,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{2, 1},\n\t\t\t2 * time.Second,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{10, 1},\n\t\t\t10 * time.Second,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{10, 0},\n\t\t\ttime.Second,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{2, 0},\n\t\t\ttime.Second,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{0, 0},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{3, 2},\n\t\t\t9 * time.Second,\n\t\t},\n\t\t{\n\t\t\tTimestampResolution{3, -2},\n\t\t\t111111111,\n\t\t},\n\t} {\n\t\td := test.r.ToDuration()\n\t\tif d != test.d {\n\t\t\tt.Errorf(\"%d: resolution: %s want: %d got: %d\", i, test.r, test.d, d)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "writer.go",
          "type": "blob",
          "size": 8.8349609375,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n)\n\n// SerializableLayer allows its implementations to be written out as a set of bytes,\n// so those bytes may be sent on the wire or otherwise used by the caller.\n// SerializableLayer is implemented by certain Layer types, and can be encoded to\n// bytes using the LayerWriter object.\ntype SerializableLayer interface {\n\t// SerializeTo writes this layer to a slice, growing that slice if necessary\n\t// to make it fit the layer's data.\n\t//  Args:\n\t//   b:  SerializeBuffer to write this layer on to.  When called, b.Bytes()\n\t//     is the payload this layer should wrap, if any.  Note that this\n\t//     layer can either prepend itself (common), append itself\n\t//     (uncommon), or both (sometimes padding or footers are required at\n\t//     the end of packet data). It's also possible (though probably very\n\t//     rarely needed) to overwrite any bytes in the current payload.\n\t//     After this call, b.Bytes() should return the byte encoding of\n\t//     this layer wrapping the original b.Bytes() payload.\n\t//   opts:  options to use while writing out data.\n\t//  Returns:\n\t//   error if a problem was encountered during encoding.  If an error is\n\t//   returned, the bytes in data should be considered invalidated, and\n\t//   not used.\n\t//\n\t// SerializeTo calls SHOULD entirely ignore LayerContents and\n\t// LayerPayload.  It just serializes based on struct fields, neither\n\t// modifying nor using contents/payload.\n\tSerializeTo(b SerializeBuffer, opts SerializeOptions) error\n\t// LayerType returns the type of the layer that is being serialized to the buffer\n\tLayerType() LayerType\n}\n\n// SerializeOptions provides options for behaviors that SerializableLayers may want to\n// implement.\ntype SerializeOptions struct {\n\t// FixLengths determines whether, during serialization, layers should fix\n\t// the values for any length field that depends on the payload.\n\tFixLengths bool\n\t// ComputeChecksums determines whether, during serialization, layers\n\t// should recompute checksums based on their payloads.\n\tComputeChecksums bool\n}\n\n// SerializeBuffer is a helper used by gopacket for writing out packet layers.\n// SerializeBuffer starts off as an empty []byte.  Subsequent calls to PrependBytes\n// return byte slices before the current Bytes(), AppendBytes returns byte\n// slices after.\n//\n// Byte slices returned by PrependBytes/AppendBytes are NOT zero'd out, so if\n// you want to make sure they're all zeros, set them as such.\n//\n// SerializeBuffer is specifically designed to handle packet writing, where unlike\n// with normal writes it's easier to start writing at the inner-most layer and\n// work out, meaning that we often need to prepend bytes.  This runs counter to\n// typical writes to byte slices using append(), where we only write at the end\n// of the buffer.\n//\n// It can be reused via Clear.  Note, however, that a Clear call will invalidate the\n// byte slices returned by any previous Bytes() call (the same buffer is\n// reused).\n//\n//  1) Reusing a write buffer is generally much faster than creating a new one,\n//     and with the default implementation it avoids additional memory allocations.\n//  2) If a byte slice from a previous Bytes() call will continue to be used,\n//     it's better to create a new SerializeBuffer.\n//\n// The Clear method is specifically designed to minimize memory allocations for\n// similar later workloads on the SerializeBuffer.  IE: if you make a set of\n// Prepend/Append calls, then clear, then make the same calls with the same\n// sizes, the second round (and all future similar rounds) shouldn't allocate\n// any new memory.\ntype SerializeBuffer interface {\n\t// Bytes returns the contiguous set of bytes collected so far by Prepend/Append\n\t// calls.  The slice returned by Bytes will be modified by future Clear calls,\n\t// so if you're planning on clearing this SerializeBuffer, you may want to copy\n\t// Bytes somewhere safe first.\n\tBytes() []byte\n\t// PrependBytes returns a set of bytes which prepends the current bytes in this\n\t// buffer.  These bytes start in an indeterminate state, so they should be\n\t// overwritten by the caller.  The caller must only call PrependBytes if they\n\t// know they're going to immediately overwrite all bytes returned.\n\tPrependBytes(num int) ([]byte, error)\n\t// AppendBytes returns a set of bytes which appends the current bytes in this\n\t// buffer.  These bytes start in an indeterminate state, so they should be\n\t// overwritten by the caller.  The caller must only call AppendBytes if they\n\t// know they're going to immediately overwrite all bytes returned.\n\tAppendBytes(num int) ([]byte, error)\n\t// Clear resets the SerializeBuffer to a new, empty buffer.  After a call to clear,\n\t// the byte slice returned by any previous call to Bytes() for this buffer\n\t// should be considered invalidated.\n\tClear() error\n\t// Layers returns all the Layers that have been successfully serialized into this buffer\n\t// already.\n\tLayers() []LayerType\n\t// PushLayer adds the current Layer to the list of Layers that have been serialized\n\t// into this buffer.\n\tPushLayer(LayerType)\n}\n\ntype serializeBuffer struct {\n\tdata                []byte\n\tstart               int\n\tprepended, appended int\n\tlayers              []LayerType\n}\n\n// NewSerializeBuffer creates a new instance of the default implementation of\n// the SerializeBuffer interface.\nfunc NewSerializeBuffer() SerializeBuffer {\n\treturn &serializeBuffer{}\n}\n\n// NewSerializeBufferExpectedSize creates a new buffer for serialization, optimized for an\n// expected number of bytes prepended/appended.  This tends to decrease the\n// number of memory allocations made by the buffer during writes.\nfunc NewSerializeBufferExpectedSize(expectedPrependLength, expectedAppendLength int) SerializeBuffer {\n\treturn &serializeBuffer{\n\t\tdata:      make([]byte, expectedPrependLength, expectedPrependLength+expectedAppendLength),\n\t\tstart:     expectedPrependLength,\n\t\tprepended: expectedPrependLength,\n\t\tappended:  expectedAppendLength,\n\t}\n}\n\nfunc (w *serializeBuffer) Bytes() []byte {\n\treturn w.data[w.start:]\n}\n\nfunc (w *serializeBuffer) PrependBytes(num int) ([]byte, error) {\n\tif num < 0 {\n\t\tpanic(\"num < 0\")\n\t}\n\tif w.start < num {\n\t\ttoPrepend := w.prepended\n\t\tif toPrepend < num {\n\t\t\ttoPrepend = num\n\t\t}\n\t\tw.prepended += toPrepend\n\t\tlength := cap(w.data) + toPrepend\n\t\tnewData := make([]byte, length)\n\t\tnewStart := w.start + toPrepend\n\t\tcopy(newData[newStart:], w.data[w.start:])\n\t\tw.start = newStart\n\t\tw.data = newData[:toPrepend+len(w.data)]\n\t}\n\tw.start -= num\n\treturn w.data[w.start : w.start+num], nil\n}\n\nfunc (w *serializeBuffer) AppendBytes(num int) ([]byte, error) {\n\tif num < 0 {\n\t\tpanic(\"num < 0\")\n\t}\n\tinitialLength := len(w.data)\n\tif cap(w.data)-initialLength < num {\n\t\ttoAppend := w.appended\n\t\tif toAppend < num {\n\t\t\ttoAppend = num\n\t\t}\n\t\tw.appended += toAppend\n\t\tnewData := make([]byte, cap(w.data)+toAppend)\n\t\tcopy(newData[w.start:], w.data[w.start:])\n\t\tw.data = newData[:initialLength]\n\t}\n\t// Grow the buffer.  We know it'll be under capacity given above.\n\tw.data = w.data[:initialLength+num]\n\treturn w.data[initialLength:], nil\n}\n\nfunc (w *serializeBuffer) Clear() error {\n\tw.start = w.prepended\n\tw.data = w.data[:w.start]\n\tw.layers = w.layers[:0]\n\treturn nil\n}\n\nfunc (w *serializeBuffer) Layers() []LayerType {\n\treturn w.layers\n}\n\nfunc (w *serializeBuffer) PushLayer(l LayerType) {\n\tw.layers = append(w.layers, l)\n}\n\n// SerializeLayers clears the given write buffer, then writes all layers into it so\n// they correctly wrap each other.  Note that by clearing the buffer, it\n// invalidates all slices previously returned by w.Bytes()\n//\n// Example:\n//   buf := gopacket.NewSerializeBuffer()\n//   opts := gopacket.SerializeOptions{}\n//   gopacket.SerializeLayers(buf, opts, a, b, c)\n//   firstPayload := buf.Bytes()  // contains byte representation of a(b(c))\n//   gopacket.SerializeLayers(buf, opts, d, e, f)\n//   secondPayload := buf.Bytes()  // contains byte representation of d(e(f)). firstPayload is now invalidated, since the SerializeLayers call Clears buf.\nfunc SerializeLayers(w SerializeBuffer, opts SerializeOptions, layers ...SerializableLayer) error {\n\tw.Clear()\n\tfor i := len(layers) - 1; i >= 0; i-- {\n\t\tlayer := layers[i]\n\t\terr := layer.SerializeTo(w, opts)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tw.PushLayer(layer.LayerType())\n\t}\n\treturn nil\n}\n\n// SerializePacket is a convenience function that calls SerializeLayers\n// on packet's Layers().\n// It returns an error if one of the packet layers is not a SerializableLayer.\nfunc SerializePacket(buf SerializeBuffer, opts SerializeOptions, packet Packet) error {\n\tsls := []SerializableLayer{}\n\tfor _, layer := range packet.Layers() {\n\t\tsl, ok := layer.(SerializableLayer)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"layer %s is not serializable\", layer.LayerType().String())\n\t\t}\n\t\tsls = append(sls, sl)\n\t}\n\treturn SerializeLayers(buf, opts, sls...)\n}\n"
        },
        {
          "name": "writer_test.go",
          "type": "blob",
          "size": 1.7294921875,
          "content": "// Copyright 2012 Google, Inc. All rights reserved.\n//\n// Use of this source code is governed by a BSD-style license\n// that can be found in the LICENSE file in the root of the source\n// tree.\n\npackage gopacket\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestExponentialSizeIncreasePrepend(t *testing.T) {\n\tvar b serializeBuffer\n\tfor i, test := range []struct {\n\t\tprepend, size int\n\t}{\n\t\t{2, 2},\n\t\t{2, 4},\n\t\t{2, 8},\n\t\t{2, 8},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 32},\n\t} {\n\t\tb.PrependBytes(test.prepend)\n\t\tif test.size != cap(b.data) {\n\t\t\tt.Error(i, \"size want\", test.size, \"got\", cap(b.data))\n\t\t}\n\t}\n\tb.Clear()\n\tif b.start != 32 {\n\t\tt.Error(b.start)\n\t}\n}\n\nfunc TestExponentialSizeIncreaseAppend(t *testing.T) {\n\tvar b serializeBuffer\n\tfor i, test := range []struct {\n\t\tappnd, size int\n\t}{\n\t\t{2, 2},\n\t\t{2, 4},\n\t\t{2, 8},\n\t\t{2, 8},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 16},\n\t\t{2, 32},\n\t} {\n\t\tb.AppendBytes(test.appnd)\n\t\tif test.size != cap(b.data) {\n\t\t\tt.Error(i, \"size want\", test.size, \"got\", cap(b.data))\n\t\t}\n\t}\n\tb.Clear()\n\tif b.start != 0 {\n\t\tt.Error(b.start)\n\t}\n}\n\nfunc ExampleSerializeBuffer() {\n\tb := NewSerializeBuffer()\n\tfmt.Println(\"1:\", b.Bytes())\n\tbytes, _ := b.PrependBytes(3)\n\tcopy(bytes, []byte{1, 2, 3})\n\tfmt.Println(\"2:\", b.Bytes())\n\tbytes, _ = b.AppendBytes(2)\n\tcopy(bytes, []byte{4, 5})\n\tfmt.Println(\"3:\", b.Bytes())\n\tbytes, _ = b.PrependBytes(1)\n\tcopy(bytes, []byte{0})\n\tfmt.Println(\"4:\", b.Bytes())\n\tbytes, _ = b.AppendBytes(3)\n\tcopy(bytes, []byte{6, 7, 8})\n\tfmt.Println(\"5:\", b.Bytes())\n\tb.Clear()\n\tfmt.Println(\"6:\", b.Bytes())\n\tbytes, _ = b.PrependBytes(2)\n\tcopy(bytes, []byte{9, 9})\n\tfmt.Println(\"7:\", b.Bytes())\n\t// Output:\n\t// 1: []\n\t// 2: [1 2 3]\n\t// 3: [1 2 3 4 5]\n\t// 4: [0 1 2 3 4 5]\n\t// 5: [0 1 2 3 4 5 6 7 8]\n\t// 6: []\n\t// 7: [9 9]\n}\n"
        }
      ]
    }
  ]
}