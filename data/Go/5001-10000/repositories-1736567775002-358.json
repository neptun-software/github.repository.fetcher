{
  "metadata": {
    "timestamp": 1736567775002,
    "page": 358,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "buger/jsonparser",
      "stars": 5484,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.080078125,
          "content": "\n*.test\n\n*.out\n\n*.mprof\n\n.idea\n\nvendor/github.com/buger/goterm/\nprof.cpu\nprof.mem\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.146484375,
          "content": "language: go\narch:\n    - amd64\n    - ppc64le\ngo:\n    - 1.13.x\n    - 1.14.x\n    - 1.15.x\n    - 1.16.x\n    - 1.17.x\n    - 1.18.x\nscript: go test -v ./.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.384765625,
          "content": "FROM golang:1.6\n\nRUN go get github.com/Jeffail/gabs\nRUN go get github.com/bitly/go-simplejson\nRUN go get github.com/pquerna/ffjson\nRUN go get github.com/antonholmquist/jason\nRUN go get github.com/mreiferson/go-ujson\nRUN go get -tags=unsafe -u github.com/ugorji/go/codec\nRUN go get github.com/mailru/easyjson\n\nWORKDIR /go/src/github.com/buger/jsonparser\nADD . /go/src/github.com/buger/jsonparser"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.044921875,
          "content": "MIT License\n\nCopyright (c) 2016 Leonid Bugaev\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.9921875,
          "content": "SOURCE = parser.go\nCONTAINER = jsonparser\nSOURCE_PATH = /go/src/github.com/buger/jsonparser\nBENCHMARK = JsonParser\nBENCHTIME = 5s\nTEST = .\nDRUN = docker run -v `pwd`:$(SOURCE_PATH) -i -t $(CONTAINER)\n\nbuild:\n\tdocker build -t $(CONTAINER) .\n\nrace:\n\t$(DRUN) --env GORACE=\"halt_on_error=1\" go test ./. $(ARGS) -v -race -timeout 15s\n\nbench:\n\t$(DRUN) go test $(LDFLAGS) -test.benchmem -bench $(BENCHMARK) ./benchmark/ $(ARGS) -benchtime $(BENCHTIME) -v\n\nbench_local:\n\t$(DRUN) go test $(LDFLAGS) -test.benchmem -bench . $(ARGS) -benchtime $(BENCHTIME) -v\n\nprofile:\n\t$(DRUN) go test $(LDFLAGS) -test.benchmem -bench $(BENCHMARK) ./benchmark/ $(ARGS) -memprofile mem.mprof -v\n\t$(DRUN) go test $(LDFLAGS) -test.benchmem -bench $(BENCHMARK) ./benchmark/ $(ARGS) -cpuprofile cpu.out -v\n\t$(DRUN) go test $(LDFLAGS) -test.benchmem -bench $(BENCHMARK) ./benchmark/ $(ARGS) -c\n\ntest:\n\t$(DRUN) go test $(LDFLAGS) ./ -run $(TEST) -timeout 10s $(ARGS) -v\n\nfmt:\n\t$(DRUN) go fmt ./...\n\nvet:\n\t$(DRUN) go vet ./.\n\nbash:\n\t$(DRUN) /bin/bash"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.080078125,
          "content": "[![Go Report Card](https://goreportcard.com/badge/github.com/buger/jsonparser)](https://goreportcard.com/report/github.com/buger/jsonparser) ![License](https://img.shields.io/dub/l/vibe-d.svg)\n# Alternative JSON parser for Go (10x times faster standard library)\n\nIt does not require you to know the structure of the payload (eg. create structs), and allows accessing fields by providing the path to them. It is up to **10 times faster** than standard `encoding/json` package (depending on payload size and usage), **allocates no memory**. See benchmarks below.\n\n## Rationale\nOriginally I made this for a project that relies on a lot of 3rd party APIs that can be unpredictable and complex.\nI love simplicity and prefer to avoid external dependecies. `encoding/json` requires you to know exactly your data structures, or if you prefer to use `map[string]interface{}` instead, it will be very slow and hard to manage.\nI investigated what's on the market and found that most libraries are just wrappers around `encoding/json`, there is few options with own parsers (`ffjson`, `easyjson`), but they still requires you to create data structures.\n\n\nGoal of this project is to push JSON parser to the performance limits and not sacrifice with compliance and developer user experience.\n\n## Example\nFor the given JSON our goal is to extract the user's full name, number of github followers and avatar.\n\n```go\nimport \"github.com/buger/jsonparser\"\n\n...\n\ndata := []byte(`{\n  \"person\": {\n    \"name\": {\n      \"first\": \"Leonid\",\n      \"last\": \"Bugaev\",\n      \"fullName\": \"Leonid Bugaev\"\n    },\n    \"github\": {\n      \"handle\": \"buger\",\n      \"followers\": 109\n    },\n    \"avatars\": [\n      { \"url\": \"https://avatars1.githubusercontent.com/u/14009?v=3&s=460\", \"type\": \"thumbnail\" }\n    ]\n  },\n  \"company\": {\n    \"name\": \"Acme\"\n  }\n}`)\n\n// You can specify key path by providing arguments to Get function\njsonparser.Get(data, \"person\", \"name\", \"fullName\")\n\n// There is `GetInt` and `GetBoolean` helpers if you exactly know key data type\njsonparser.GetInt(data, \"person\", \"github\", \"followers\")\n\n// When you try to get object, it will return you []byte slice pointer to data containing it\n// In `company` it will be `{\"name\": \"Acme\"}`\njsonparser.Get(data, \"company\")\n\n// If the key doesn't exist it will throw an error\nvar size int64\nif value, err := jsonparser.GetInt(data, \"company\", \"size\"); err == nil {\n  size = value\n}\n\n// You can use `ArrayEach` helper to iterate items [item1, item2 .... itemN]\njsonparser.ArrayEach(data, func(value []byte, dataType jsonparser.ValueType, offset int, err error) {\n\tfmt.Println(jsonparser.Get(value, \"url\"))\n}, \"person\", \"avatars\")\n\n// Or use can access fields by index!\njsonparser.GetString(data, \"person\", \"avatars\", \"[0]\", \"url\")\n\n// You can use `ObjectEach` helper to iterate objects { \"key1\":object1, \"key2\":object2, .... \"keyN\":objectN }\njsonparser.ObjectEach(data, func(key []byte, value []byte, dataType jsonparser.ValueType, offset int) error {\n        fmt.Printf(\"Key: '%s'\\n Value: '%s'\\n Type: %s\\n\", string(key), string(value), dataType)\n\treturn nil\n}, \"person\", \"name\")\n\n// The most efficient way to extract multiple keys is `EachKey`\n\npaths := [][]string{\n  []string{\"person\", \"name\", \"fullName\"},\n  []string{\"person\", \"avatars\", \"[0]\", \"url\"},\n  []string{\"company\", \"url\"},\n}\njsonparser.EachKey(data, func(idx int, value []byte, vt jsonparser.ValueType, err error){\n  switch idx {\n  case 0: // []string{\"person\", \"name\", \"fullName\"}\n    ...\n  case 1: // []string{\"person\", \"avatars\", \"[0]\", \"url\"}\n    ...\n  case 2: // []string{\"company\", \"url\"},\n    ...\n  }\n}, paths...)\n\n// For more information see docs below\n```\n\n## Reference\n\nLibrary API is really simple. You just need the `Get` method to perform any operation. The rest is just helpers around it.\n\nYou also can view API at [godoc.org](https://godoc.org/github.com/buger/jsonparser)\n\n\n### **`Get`**\n```go\nfunc Get(data []byte, keys ...string) (value []byte, dataType jsonparser.ValueType, offset int, err error)\n```\nReceives data structure, and key path to extract value from.\n\nReturns:\n* `value` - Pointer to original data structure containing key value, or just empty slice if nothing found or error\n* `dataType` - \tCan be: `NotExist`, `String`, `Number`, `Object`, `Array`, `Boolean` or `Null`\n* `offset` - Offset from provided data structure where key value ends. Used mostly internally, for example for `ArrayEach` helper.\n* `err` - If the key is not found or any other parsing issue, it should return error. If key not found it also sets `dataType` to `NotExist`\n\nAccepts multiple keys to specify path to JSON value (in case of quering nested structures).\nIf no keys are provided it will try to extract the closest JSON value (simple ones or object/array), useful for reading streams or arrays, see `ArrayEach` implementation.\n\nNote that keys can be an array indexes: `jsonparser.GetInt(\"person\", \"avatars\", \"[0]\", \"url\")`, pretty cool, yeah?\n\n### **`GetString`**\n```go\nfunc GetString(data []byte, keys ...string) (val string, err error)\n```\nReturns strings properly handing escaped and unicode characters. Note that this will cause additional memory allocations.\n\n### **`GetUnsafeString`**\nIf you need string in your app, and ready to sacrifice with support of escaped symbols in favor of speed. It returns string mapped to existing byte slice memory, without any allocations:\n```go\ns, _, := jsonparser.GetUnsafeString(data, \"person\", \"name\", \"title\")\nswitch s {\n  case 'CEO':\n    ...\n  case 'Engineer'\n    ...\n  ...\n}\n```\nNote that `unsafe` here means that your string will exist until GC will free underlying byte slice, for most of cases it means that you can use this string only in current context, and should not pass it anywhere externally: through channels or any other way.\n\n\n### **`GetBoolean`**, **`GetInt`** and **`GetFloat`**\n```go\nfunc GetBoolean(data []byte, keys ...string) (val bool, err error)\n\nfunc GetFloat(data []byte, keys ...string) (val float64, err error)\n\nfunc GetInt(data []byte, keys ...string) (val int64, err error)\n```\nIf you know the key type, you can use the helpers above.\nIf key data type do not match, it will return error.\n\n### **`ArrayEach`**\n```go\nfunc ArrayEach(data []byte, cb func(value []byte, dataType jsonparser.ValueType, offset int, err error), keys ...string)\n```\nNeeded for iterating arrays, accepts a callback function with the same return arguments as `Get`.\n\n### **`ObjectEach`**\n```go\nfunc ObjectEach(data []byte, callback func(key []byte, value []byte, dataType ValueType, offset int) error, keys ...string) (err error)\n```\nNeeded for iterating object, accepts a callback function. Example:\n```go\nvar handler func([]byte, []byte, jsonparser.ValueType, int) error\nhandler = func(key []byte, value []byte, dataType jsonparser.ValueType, offset int) error {\n\t//do stuff here\n}\njsonparser.ObjectEach(myJson, handler)\n```\n\n\n### **`EachKey`**\n```go\nfunc EachKey(data []byte, cb func(idx int, value []byte, dataType jsonparser.ValueType, err error), paths ...[]string)\n```\nWhen you need to read multiple keys, and you do not afraid of low-level API `EachKey` is your friend. It read payload only single time, and calls callback function once path is found. For example when you call multiple times `Get`, it has to process payload multiple times, each time you call it. Depending on payload `EachKey` can be multiple times faster than `Get`. Path can use nested keys as well!\n\n```go\npaths := [][]string{\n\t[]string{\"uuid\"},\n\t[]string{\"tz\"},\n\t[]string{\"ua\"},\n\t[]string{\"st\"},\n}\nvar data SmallPayload\n\njsonparser.EachKey(smallFixture, func(idx int, value []byte, vt jsonparser.ValueType, err error){\n\tswitch idx {\n\tcase 0:\n\t\tdata.Uuid, _ = value\n\tcase 1:\n\t\tv, _ := jsonparser.ParseInt(value)\n\t\tdata.Tz = int(v)\n\tcase 2:\n\t\tdata.Ua, _ = value\n\tcase 3:\n\t\tv, _ := jsonparser.ParseInt(value)\n\t\tdata.St = int(v)\n\t}\n}, paths...)\n```\n\n### **`Set`**\n```go\nfunc Set(data []byte, setValue []byte, keys ...string) (value []byte, err error)\n```\nReceives existing data structure, key path to set, and value to set at that key. *This functionality is experimental.*\n\nReturns:\n* `value` - Pointer to original data structure with updated or added key value.\n* `err` - If any parsing issue, it should return error.\n\nAccepts multiple keys to specify path to JSON value (in case of updating or creating  nested structures).\n\nNote that keys can be an array indexes: `jsonparser.Set(data, []byte(\"http://github.com\"), \"person\", \"avatars\", \"[0]\", \"url\")`\n\n### **`Delete`**\n```go\nfunc Delete(data []byte, keys ...string) value []byte\n```\nReceives existing data structure, and key path to delete. *This functionality is experimental.*\n\nReturns:\n* `value` - Pointer to original data structure with key path deleted if it can be found. If there is no key path, then the whole data structure is deleted.\n\nAccepts multiple keys to specify path to JSON value (in case of updating or creating  nested structures).\n\nNote that keys can be an array indexes: `jsonparser.Delete(data, \"person\", \"avatars\", \"[0]\", \"url\")`\n\n\n## What makes it so fast?\n* It does not rely on `encoding/json`, `reflection` or `interface{}`, the only real package dependency is `bytes`.\n* Operates with JSON payload on byte level, providing you pointers to the original data structure: no memory allocation.\n* No automatic type conversions, by default everything is a []byte, but it provides you value type, so you can convert by yourself (there is few helpers included).\n* Does not parse full record, only keys you specified\n\n\n## Benchmarks\n\nThere are 3 benchmark types, trying to simulate real-life usage for small, medium and large JSON payloads.\nFor each metric, the lower value is better. Time/op is in nanoseconds. Values better than standard encoding/json marked as bold text.\nBenchmarks run on standard Linode 1024 box.\n\nCompared libraries:\n* https://golang.org/pkg/encoding/json\n* https://github.com/Jeffail/gabs\n* https://github.com/a8m/djson\n* https://github.com/bitly/go-simplejson\n* https://github.com/antonholmquist/jason\n* https://github.com/mreiferson/go-ujson\n* https://github.com/ugorji/go/codec\n* https://github.com/pquerna/ffjson\n* https://github.com/mailru/easyjson\n* https://github.com/buger/jsonparser\n\n#### TLDR\nIf you want to skip next sections we have 2 winner: `jsonparser` and `easyjson`.\n`jsonparser` is up to 10 times faster than standard `encoding/json` package (depending on payload size and usage), and almost infinitely (literally) better in memory consumption because it operates with data on byte level, and provide direct slice pointers.\n`easyjson` wins in CPU in medium tests and frankly i'm impressed with this package: it is remarkable results considering that it is almost drop-in replacement for `encoding/json` (require some code generation).\n\nIt's hard to fully compare `jsonparser` and `easyjson` (or `ffson`), they a true parsers and fully process record, unlike `jsonparser` which parse only keys you specified.\n\nIf you searching for replacement of `encoding/json` while keeping structs, `easyjson` is an amazing choice. If you want to process dynamic JSON, have memory constrains, or more control over your data you should try `jsonparser`.\n\n`jsonparser` performance heavily depends on usage, and it works best when you do not need to process full record, only some keys. The more calls you need to make, the slower it will be, in contrast `easyjson` (or `ffjson`, `encoding/json`) parser record only 1 time, and then you can make as many calls as you want.\n\nWith great power comes great responsibility! :)\n\n\n#### Small payload\n\nEach test processes 190 bytes of http log as a JSON record.\nIt should read multiple fields.\nhttps://github.com/buger/jsonparser/blob/master/benchmark/benchmark_small_payload_test.go\n\nLibrary | time/op | bytes/op | allocs/op \n ------ | ------- | -------- | -------\nencoding/json struct | 7879 | 880 | 18 \nencoding/json interface{} | 8946 | 1521 | 38\nJeffail/gabs | 10053 | 1649 | 46\nbitly/go-simplejson | 10128 | 2241 | 36 \nantonholmquist/jason | 27152 | 7237 | 101 \ngithub.com/ugorji/go/codec | 8806 | 2176 | 31 \nmreiferson/go-ujson | **7008** | **1409** | 37 \na8m/djson | 3862 | 1249 | 30 \npquerna/ffjson | **3769** | **624** | **15** \nmailru/easyjson | **2002** | **192** | **9** \nbuger/jsonparser | **1367** | **0** | **0** \nbuger/jsonparser (EachKey API) | **809** | **0** | **0** \n\nWinners are ffjson, easyjson and jsonparser, where jsonparser is up to 9.8x faster than encoding/json and 4.6x faster than ffjson, and slightly faster than easyjson.\nIf you look at memory allocation, jsonparser has no rivals, as it makes no data copy and operates with raw []byte structures and pointers to it.\n\n#### Medium payload\n\nEach test processes a 2.4kb JSON record (based on Clearbit API).\nIt should read multiple nested fields and 1 array.\n\nhttps://github.com/buger/jsonparser/blob/master/benchmark/benchmark_medium_payload_test.go\n\n| Library | time/op | bytes/op | allocs/op |\n| ------- | ------- | -------- | --------- |\n| encoding/json struct | 57749 | 1336 | 29 |\n| encoding/json interface{} | 79297 | 10627 | 215 |\n| Jeffail/gabs | 83807 | 11202 | 235 |\n| bitly/go-simplejson | 88187 | 17187 | 220 |\n| antonholmquist/jason | 94099 | 19013 | 247 |\n| github.com/ugorji/go/codec | 114719 | 6712 | 152 |\n| mreiferson/go-ujson | **56972** | 11547 | 270 |\n| a8m/djson | 28525 | 10196 | 198 | \n| pquerna/ffjson | **20298** | **856** | **20** |\n| mailru/easyjson | **10512** | **336** | **12** |\n| buger/jsonparser | **15955** | **0** | **0** |\n| buger/jsonparser (EachKey API) | **8916** | **0** | **0** |\n\nThe difference between ffjson and jsonparser in CPU usage is smaller, while the memory consumption difference is growing. On the other hand `easyjson` shows remarkable performance for medium payload.\n\n`gabs`, `go-simplejson` and `jason` are based on encoding/json and map[string]interface{} and actually only helpers for unstructured JSON, their performance correlate with `encoding/json interface{}`, and they will skip next round.\n`go-ujson` while have its own parser, shows same performance as `encoding/json`, also skips next round. Same situation with `ugorji/go/codec`, but it showed unexpectedly bad performance for complex payloads.\n\n\n#### Large payload\n\nEach test processes a 24kb JSON record (based on Discourse API)\nIt should read 2 arrays, and for each item in array get a few fields.\nBasically it means processing a full JSON file.\n\nhttps://github.com/buger/jsonparser/blob/master/benchmark/benchmark_large_payload_test.go\n\n| Library | time/op | bytes/op | allocs/op |\n| --- | --- | --- | --- |\n| encoding/json struct | 748336 | 8272 | 307 |\n| encoding/json interface{} | 1224271 | 215425 | 3395 |\n| a8m/djson | 510082 | 213682 | 2845 |\n| pquerna/ffjson | **312271** | **7792** | **298** |\n| mailru/easyjson | **154186** | **6992** | **288** |\n| buger/jsonparser | **85308** | **0** | **0** |\n\n`jsonparser` now is a winner, but do not forget that it is way more lightweight parser than `ffson` or `easyjson`, and they have to parser all the data, while `jsonparser` parse only what you need. All `ffjson`, `easysjon` and `jsonparser` have their own parsing code, and does not depend on `encoding/json` or `interface{}`, thats one of the reasons why they are so fast. `easyjson` also use a bit of `unsafe` package to reduce memory consuption (in theory it can lead to some unexpected GC issue, but i did not tested enough)\n\nAlso last benchmark did not included `EachKey` test, because in this particular case we need to read lot of Array values, and using `ArrayEach` is more efficient. \n\n## Questions and support\n\nAll bug-reports and suggestions should go though Github Issues.\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (git checkout -b my-new-feature)\n3. Commit your changes (git commit -am 'Added some feature')\n4. Push to the branch (git push origin my-new-feature)\n5. Create new Pull Request\n\n## Development\n\nAll my development happens using Docker, and repo include some Make tasks to simplify development.\n\n* `make build` - builds docker image, usually can be called only once\n* `make test` - run tests\n* `make fmt` - run go fmt\n* `make bench` - run benchmarks (if you need to run only single benchmark modify `BENCHMARK` variable in make file)\n* `make profile` - runs benchmark and generate 3 files-  `cpu.out`, `mem.mprof` and `benchmark.test` binary, which can be used for `go tool pprof`\n* `make bash` - enter container (i use it for running `go tool pprof` above)\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "bytes.go",
          "type": "blob",
          "size": 0.83203125,
          "content": "package jsonparser\n\nconst absMinInt64 = 1 << 63\nconst maxInt64 = 1<<63 - 1\nconst maxUint64 = 1<<64 - 1\n\n// About 2x faster then strconv.ParseInt because it only supports base 10, which is enough for JSON\nfunc parseInt(bytes []byte) (v int64, ok bool, overflow bool) {\n\tif len(bytes) == 0 {\n\t\treturn 0, false, false\n\t}\n\n\tvar neg bool = false\n\tif bytes[0] == '-' {\n\t\tneg = true\n\t\tbytes = bytes[1:]\n\t}\n\n\tvar n uint64 = 0\n\tfor _, c := range bytes {\n\t\tif c < '0' || c > '9' {\n\t\t\treturn 0, false, false\n\t\t}\n\t\tif n > maxUint64/10 {\n\t\t\treturn 0, false, true\n\t\t}\n\t\tn *= 10\n\t\tn1 := n + uint64(c-'0')\n\t\tif n1 < n {\n\t\t\treturn 0, false, true\n\t\t}\n\t\tn = n1\n\t}\n\n\tif n > maxInt64 {\n\t\tif neg && n == absMinInt64 {\n\t\t\treturn -absMinInt64, true, false\n\t\t}\n\t\treturn 0, false, true\n\t}\n\n\tif neg {\n\t\treturn -int64(n), true, false\n\t} else {\n\t\treturn int64(n), true, false\n\t}\n}\n"
        },
        {
          "name": "bytes_safe.go",
          "type": "blob",
          "size": 0.4677734375,
          "content": "// +build appengine appenginevm\n\npackage jsonparser\n\nimport (\n\t\"strconv\"\n)\n\n// See fastbytes_unsafe.go for explanation on why *[]byte is used (signatures must be consistent with those in that file)\n\nfunc equalStr(b *[]byte, s string) bool {\n\treturn string(*b) == s\n}\n\nfunc parseFloat(b *[]byte) (float64, error) {\n\treturn strconv.ParseFloat(string(*b), 64)\n}\n\nfunc bytesToString(b *[]byte) string {\n\treturn string(*b)\n}\n\nfunc StringToBytes(s string) []byte {\n\treturn []byte(s)\n}\n"
        },
        {
          "name": "bytes_test.go",
          "type": "blob",
          "size": 2.8623046875,
          "content": "package jsonparser\n\nimport (\n\t\"strconv\"\n\t\"testing\"\n\t\"unsafe\"\n)\n\ntype ParseIntTest struct {\n\tin         string\n\tout        int64\n\tisErr      bool\n\tisOverflow bool\n}\n\nvar parseIntTests = []ParseIntTest{\n\t{\n\t\tin:  \"0\",\n\t\tout: 0,\n\t},\n\t{\n\t\tin:  \"1\",\n\t\tout: 1,\n\t},\n\t{\n\t\tin:  \"-1\",\n\t\tout: -1,\n\t},\n\t{\n\t\tin:  \"12345\",\n\t\tout: 12345,\n\t},\n\t{\n\t\tin:  \"-12345\",\n\t\tout: -12345,\n\t},\n\t{\n\t\tin:  \"9223372036854775807\", // = math.MaxInt64\n\t\tout: 9223372036854775807,\n\t},\n\t{\n\t\tin:  \"-9223372036854775808\", // = math.MinInt64\n\t\tout: -9223372036854775808,\n\t},\n\t{\n\t\tin:         \"-92233720368547758081\",\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n\t{\n\t\tin:         \"18446744073709551616\", // = 2^64\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n\t{\n\t\tin:         \"9223372036854775808\", // = math.MaxInt64 - 1\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n\t{\n\t\tin:         \"-9223372036854775809\", // = math.MaxInt64 - 1\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n\t{\n\t\tin:    \"\",\n\t\tisErr: true,\n\t},\n\t{\n\t\tin:    \"abc\",\n\t\tisErr: true,\n\t},\n\t{\n\t\tin:    \"12345x\",\n\t\tisErr: true,\n\t},\n\t{\n\t\tin:    \"123e5\",\n\t\tisErr: true,\n\t},\n\t{\n\t\tin:    \"9223372036854775807x\",\n\t\tisErr: true,\n\t},\n\t{\n\t\tin:         \"27670116110564327410\",\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n\t{\n\t\tin:         \"-27670116110564327410\",\n\t\tout:        0,\n\t\tisErr:      true,\n\t\tisOverflow: true,\n\t},\n}\n\nfunc TestBytesParseInt(t *testing.T) {\n\tfor _, test := range parseIntTests {\n\t\tout, ok, overflow := parseInt([]byte(test.in))\n\t\tif overflow != test.isOverflow {\n\t\t\tt.Errorf(\"Test '%s' error return did not overflow expectation (obtained %t, expected %t)\", test.in, overflow, test.isOverflow)\n\t\t}\n\t\tif ok != !test.isErr {\n\t\t\tt.Errorf(\"Test '%s' error return did not match expectation (obtained %t, expected %t)\", test.in, !ok, test.isErr)\n\t\t} else if ok && out != test.out {\n\t\t\tt.Errorf(\"Test '%s' did not return the expected value (obtained %d, expected %d)\", test.in, out, test.out)\n\t\t}\n\t}\n}\n\nfunc BenchmarkParseInt(b *testing.B) {\n\tbytes := []byte(\"123\")\n\tfor i := 0; i < b.N; i++ {\n\t\tparseInt(bytes)\n\t}\n}\n\n// Alternative implementation using unsafe and delegating to strconv.ParseInt\nfunc BenchmarkParseIntUnsafeSlower(b *testing.B) {\n\tbytes := []byte(\"123\")\n\tfor i := 0; i < b.N; i++ {\n\t\tstrconv.ParseInt(*(*string)(unsafe.Pointer(&bytes)), 10, 64)\n\t}\n}\n\n// Old implementation that did not check for overflows.\nfunc BenchmarkParseIntOverflows(b *testing.B) {\n\tbytes := []byte(\"123\")\n\tfor i := 0; i < b.N; i++ {\n\t\tparseIntOverflows(bytes)\n\t}\n}\n\nfunc parseIntOverflows(bytes []byte) (v int64, ok bool) {\n\tif len(bytes) == 0 {\n\t\treturn 0, false\n\t}\n\n\tvar neg bool = false\n\tif bytes[0] == '-' {\n\t\tneg = true\n\t\tbytes = bytes[1:]\n\t}\n\n\tfor _, c := range bytes {\n\t\tif c >= '0' && c <= '9' {\n\t\t\tv = (10 * v) + int64(c-'0')\n\t\t} else {\n\t\t\treturn 0, false\n\t\t}\n\t}\n\n\tif neg {\n\t\treturn -v, true\n\t} else {\n\t\treturn v, true\n\t}\n}\n"
        },
        {
          "name": "bytes_unsafe.go",
          "type": "blob",
          "size": 1.2265625,
          "content": "// +build !appengine,!appenginevm\n\npackage jsonparser\n\nimport (\n\t\"reflect\"\n\t\"strconv\"\n\t\"unsafe\"\n\t\"runtime\"\n)\n\n//\n// The reason for using *[]byte rather than []byte in parameters is an optimization. As of Go 1.6,\n// the compiler cannot perfectly inline the function when using a non-pointer slice. That is,\n// the non-pointer []byte parameter version is slower than if its function body is manually\n// inlined, whereas the pointer []byte version is equally fast to the manually inlined\n// version. Instruction count in assembly taken from \"go tool compile\" confirms this difference.\n//\n// TODO: Remove hack after Go 1.7 release\n//\nfunc equalStr(b *[]byte, s string) bool {\n\treturn *(*string)(unsafe.Pointer(b)) == s\n}\n\nfunc parseFloat(b *[]byte) (float64, error) {\n\treturn strconv.ParseFloat(*(*string)(unsafe.Pointer(b)), 64)\n}\n\n// A hack until issue golang/go#2632 is fixed.\n// See: https://github.com/golang/go/issues/2632\nfunc bytesToString(b *[]byte) string {\n\treturn *(*string)(unsafe.Pointer(b))\n}\n\nfunc StringToBytes(s string) []byte {\n\tb := make([]byte, 0, 0)\n\tbh := (*reflect.SliceHeader)(unsafe.Pointer(&b))\n\tsh := (*reflect.StringHeader)(unsafe.Pointer(&s))\n\tbh.Data = sh.Data\n\tbh.Cap = sh.Len\n\tbh.Len = sh.Len\n\truntime.KeepAlive(s)\n\treturn b\n}\n"
        },
        {
          "name": "bytes_unsafe_test.go",
          "type": "blob",
          "size": 1.69921875,
          "content": "// +build !appengine,!appenginevm\n\npackage jsonparser\n\nimport (\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\t\"unsafe\"\n)\n\nvar (\n\t// short string/[]byte sequences, as the difference between these\n\t// three methods is a constant overhead\n\tbenchmarkString = \"0123456789x\"\n\tbenchmarkBytes  = []byte(\"0123456789y\")\n)\n\nfunc bytesEqualStrSafe(abytes []byte, bstr string) bool {\n\treturn bstr == string(abytes)\n}\n\nfunc bytesEqualStrUnsafeSlower(abytes *[]byte, bstr string) bool {\n\taslicehdr := (*reflect.SliceHeader)(unsafe.Pointer(abytes))\n\tastrhdr := reflect.StringHeader{Data: aslicehdr.Data, Len: aslicehdr.Len}\n\treturn *(*string)(unsafe.Pointer(&astrhdr)) == bstr\n}\n\nfunc TestEqual(t *testing.T) {\n\tif !equalStr(&[]byte{}, \"\") {\n\t\tt.Errorf(`equalStr(\"\", \"\"): expected true, obtained false`)\n\t\treturn\n\t}\n\n\tlongstr := strings.Repeat(\"a\", 1000)\n\tfor i := 0; i < len(longstr); i++ {\n\t\ts1, s2 := longstr[:i]+\"1\", longstr[:i]+\"2\"\n\t\tb1 := []byte(s1)\n\n\t\tif !equalStr(&b1, s1) {\n\t\t\tt.Errorf(`equalStr(\"a\"*%d + \"1\", \"a\"*%d + \"1\"): expected true, obtained false`, i, i)\n\t\t\tbreak\n\t\t}\n\t\tif equalStr(&b1, s2) {\n\t\t\tt.Errorf(`equalStr(\"a\"*%d + \"1\", \"a\"*%d + \"2\"): expected false, obtained true`, i, i)\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc BenchmarkEqualStr(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tequalStr(&benchmarkBytes, benchmarkString)\n\t}\n}\n\n// Alternative implementation without using unsafe\nfunc BenchmarkBytesEqualStrSafe(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbytesEqualStrSafe(benchmarkBytes, benchmarkString)\n\t}\n}\n\n// Alternative implementation using unsafe, but that is slower than the current implementation\nfunc BenchmarkBytesEqualStrUnsafeSlower(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbytesEqualStrUnsafeSlower(&benchmarkBytes, benchmarkString)\n\t}\n}\n"
        },
        {
          "name": "escape.go",
          "type": "blob",
          "size": 5.12109375,
          "content": "package jsonparser\n\nimport (\n\t\"bytes\"\n\t\"unicode/utf8\"\n)\n\n// JSON Unicode stuff: see https://tools.ietf.org/html/rfc7159#section-7\n\nconst supplementalPlanesOffset = 0x10000\nconst highSurrogateOffset = 0xD800\nconst lowSurrogateOffset = 0xDC00\n\nconst basicMultilingualPlaneReservedOffset = 0xDFFF\nconst basicMultilingualPlaneOffset = 0xFFFF\n\nfunc combineUTF16Surrogates(high, low rune) rune {\n\treturn supplementalPlanesOffset + (high-highSurrogateOffset)<<10 + (low - lowSurrogateOffset)\n}\n\nconst badHex = -1\n\nfunc h2I(c byte) int {\n\tswitch {\n\tcase c >= '0' && c <= '9':\n\t\treturn int(c - '0')\n\tcase c >= 'A' && c <= 'F':\n\t\treturn int(c - 'A' + 10)\n\tcase c >= 'a' && c <= 'f':\n\t\treturn int(c - 'a' + 10)\n\t}\n\treturn badHex\n}\n\n// decodeSingleUnicodeEscape decodes a single \\uXXXX escape sequence. The prefix \\u is assumed to be present and\n// is not checked.\n// In JSON, these escapes can either come alone or as part of \"UTF16 surrogate pairs\" that must be handled together.\n// This function only handles one; decodeUnicodeEscape handles this more complex case.\nfunc decodeSingleUnicodeEscape(in []byte) (rune, bool) {\n\t// We need at least 6 characters total\n\tif len(in) < 6 {\n\t\treturn utf8.RuneError, false\n\t}\n\n\t// Convert hex to decimal\n\th1, h2, h3, h4 := h2I(in[2]), h2I(in[3]), h2I(in[4]), h2I(in[5])\n\tif h1 == badHex || h2 == badHex || h3 == badHex || h4 == badHex {\n\t\treturn utf8.RuneError, false\n\t}\n\n\t// Compose the hex digits\n\treturn rune(h1<<12 + h2<<8 + h3<<4 + h4), true\n}\n\n// isUTF16EncodedRune checks if a rune is in the range for non-BMP characters,\n// which is used to describe UTF16 chars.\n// Source: https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane\nfunc isUTF16EncodedRune(r rune) bool {\n\treturn highSurrogateOffset <= r && r <= basicMultilingualPlaneReservedOffset\n}\n\nfunc decodeUnicodeEscape(in []byte) (rune, int) {\n\tif r, ok := decodeSingleUnicodeEscape(in); !ok {\n\t\t// Invalid Unicode escape\n\t\treturn utf8.RuneError, -1\n\t} else if r <= basicMultilingualPlaneOffset && !isUTF16EncodedRune(r) {\n\t\t// Valid Unicode escape in Basic Multilingual Plane\n\t\treturn r, 6\n\t} else if r2, ok := decodeSingleUnicodeEscape(in[6:]); !ok { // Note: previous decodeSingleUnicodeEscape success guarantees at least 6 bytes remain\n\t\t// UTF16 \"high surrogate\" without manditory valid following Unicode escape for the \"low surrogate\"\n\t\treturn utf8.RuneError, -1\n\t} else if r2 < lowSurrogateOffset {\n\t\t// Invalid UTF16 \"low surrogate\"\n\t\treturn utf8.RuneError, -1\n\t} else {\n\t\t// Valid UTF16 surrogate pair\n\t\treturn combineUTF16Surrogates(r, r2), 12\n\t}\n}\n\n// backslashCharEscapeTable: when '\\X' is found for some byte X, it is to be replaced with backslashCharEscapeTable[X]\nvar backslashCharEscapeTable = [...]byte{\n\t'\"':  '\"',\n\t'\\\\': '\\\\',\n\t'/':  '/',\n\t'b':  '\\b',\n\t'f':  '\\f',\n\t'n':  '\\n',\n\t'r':  '\\r',\n\t't':  '\\t',\n}\n\n// unescapeToUTF8 unescapes the single escape sequence starting at 'in' into 'out' and returns\n// how many characters were consumed from 'in' and emitted into 'out'.\n// If a valid escape sequence does not appear as a prefix of 'in', (-1, -1) to signal the error.\nfunc unescapeToUTF8(in, out []byte) (inLen int, outLen int) {\n\tif len(in) < 2 || in[0] != '\\\\' {\n\t\t// Invalid escape due to insufficient characters for any escape or no initial backslash\n\t\treturn -1, -1\n\t}\n\n\t// https://tools.ietf.org/html/rfc7159#section-7\n\tswitch e := in[1]; e {\n\tcase '\"', '\\\\', '/', 'b', 'f', 'n', 'r', 't':\n\t\t// Valid basic 2-character escapes (use lookup table)\n\t\tout[0] = backslashCharEscapeTable[e]\n\t\treturn 2, 1\n\tcase 'u':\n\t\t// Unicode escape\n\t\tif r, inLen := decodeUnicodeEscape(in); inLen == -1 {\n\t\t\t// Invalid Unicode escape\n\t\t\treturn -1, -1\n\t\t} else {\n\t\t\t// Valid Unicode escape; re-encode as UTF8\n\t\t\toutLen := utf8.EncodeRune(out, r)\n\t\t\treturn inLen, outLen\n\t\t}\n\t}\n\n\treturn -1, -1\n}\n\n// unescape unescapes the string contained in 'in' and returns it as a slice.\n// If 'in' contains no escaped characters:\n//   Returns 'in'.\n// Else, if 'out' is of sufficient capacity (guaranteed if cap(out) >= len(in)):\n//   'out' is used to build the unescaped string and is returned with no extra allocation\n// Else:\n//   A new slice is allocated and returned.\nfunc Unescape(in, out []byte) ([]byte, error) {\n\tfirstBackslash := bytes.IndexByte(in, '\\\\')\n\tif firstBackslash == -1 {\n\t\treturn in, nil\n\t}\n\n\t// Get a buffer of sufficient size (allocate if needed)\n\tif cap(out) < len(in) {\n\t\tout = make([]byte, len(in))\n\t} else {\n\t\tout = out[0:len(in)]\n\t}\n\n\t// Copy the first sequence of unescaped bytes to the output and obtain a buffer pointer (subslice)\n\tcopy(out, in[:firstBackslash])\n\tin = in[firstBackslash:]\n\tbuf := out[firstBackslash:]\n\n\tfor len(in) > 0 {\n\t\t// Unescape the next escaped character\n\t\tinLen, bufLen := unescapeToUTF8(in, buf)\n\t\tif inLen == -1 {\n\t\t\treturn nil, MalformedStringEscapeError\n\t\t}\n\n\t\tin = in[inLen:]\n\t\tbuf = buf[bufLen:]\n\n\t\t// Copy everything up until the next backslash\n\t\tnextBackslash := bytes.IndexByte(in, '\\\\')\n\t\tif nextBackslash == -1 {\n\t\t\tcopy(buf, in)\n\t\t\tbuf = buf[len(in):]\n\t\t\tbreak\n\t\t} else {\n\t\t\tcopy(buf, in[:nextBackslash])\n\t\t\tbuf = buf[nextBackslash:]\n\t\t\tin = in[nextBackslash:]\n\t\t}\n\t}\n\n\t// Trim the out buffer to the amount that was actually emitted\n\treturn out[:len(out)-len(buf)], nil\n}\n"
        },
        {
          "name": "escape_test.go",
          "type": "blob",
          "size": 6.0703125,
          "content": "package jsonparser\n\nimport (\n\t\"bytes\"\n\t\"testing\"\n)\n\nfunc TestH2I(t *testing.T) {\n\thexChars := []byte{'0', '9', 'A', 'F', 'a', 'f', 'x', '\\000'}\n\thexValues := []int{0, 9, 10, 15, 10, 15, -1, -1}\n\n\tfor i, c := range hexChars {\n\t\tif v := h2I(c); v != hexValues[i] {\n\t\t\tt.Errorf(\"h2I('%c') returned wrong value (obtained %d, expected %d)\", c, v, hexValues[i])\n\t\t}\n\t}\n}\n\ntype escapedUnicodeRuneTest struct {\n\tin    string\n\tisErr bool\n\tout   rune\n\tlen   int\n}\n\nvar commonUnicodeEscapeTests = []escapedUnicodeRuneTest{\n\t{in: `\\u0041`, out: 'A', len: 6},\n\t{in: `\\u0000`, out: 0, len: 6},\n\t{in: `\\u00b0`, out: '°', len: 6},\n\t{in: `\\u00B0`, out: '°', len: 6},\n\n\t{in: `\\x1234`, out: 0x1234, len: 6}, // These functions do not check the \\u prefix\n\n\t{in: ``, isErr: true},\n\t{in: `\\`, isErr: true},\n\t{in: `\\u`, isErr: true},\n\t{in: `\\u1`, isErr: true},\n\t{in: `\\u11`, isErr: true},\n\t{in: `\\u111`, isErr: true},\n\t{in: `\\u123X`, isErr: true},\n}\n\nvar singleUnicodeEscapeTests = append([]escapedUnicodeRuneTest{\n\t{in: `\\uD83D`, out: 0xD83D, len: 6},\n\t{in: `\\uDE03`, out: 0xDE03, len: 6},\n\t{in: `\\uFFFF`, out: 0xFFFF, len: 6},\n\t{in: `\\uFF11`, out: '１', len: 6},\n}, commonUnicodeEscapeTests...)\n\nvar multiUnicodeEscapeTests = append([]escapedUnicodeRuneTest{\n\t{in: `\\uD83D`, isErr: true},\n\t{in: `\\uDE03`, isErr: true},\n\t{in: `\\uFFFF`, out: '\\uFFFF', len: 6},\n\t{in: `\\uFF11`, out: '１', len: 6},\n\n\t{in: `\\uD83D\\uDE03`, out: '\\U0001F603', len: 12},\n\t{in: `\\uD800\\uDC00`, out: '\\U00010000', len: 12},\n\n\t{in: `\\uD800\\`, isErr: true},\n\t{in: `\\uD800\\u`, isErr: true},\n\t{in: `\\uD800\\uD`, isErr: true},\n\t{in: `\\uD800\\uDC`, isErr: true},\n\t{in: `\\uD800\\uDC0`, isErr: true},\n\t{in: `\\uD800\\uDBFF`, isErr: true}, // invalid low surrogate\n}, commonUnicodeEscapeTests...)\n\nfunc TestDecodeSingleUnicodeEscape(t *testing.T) {\n\tfor _, test := range singleUnicodeEscapeTests {\n\t\tr, ok := decodeSingleUnicodeEscape([]byte(test.in))\n\t\tisErr := !ok\n\n\t\tif isErr != test.isErr {\n\t\t\tt.Errorf(\"decodeSingleUnicodeEscape(%s) returned isErr mismatch: expected %t, obtained %t\", test.in, test.isErr, isErr)\n\t\t} else if isErr {\n\t\t\tcontinue\n\t\t} else if r != test.out {\n\t\t\tt.Errorf(\"decodeSingleUnicodeEscape(%s) returned rune mismatch: expected %x (%c), obtained %x (%c)\", test.in, test.out, test.out, r, r)\n\t\t}\n\t}\n}\n\nfunc TestDecodeUnicodeEscape(t *testing.T) {\n\tfor _, test := range multiUnicodeEscapeTests {\n\t\tr, len := decodeUnicodeEscape([]byte(test.in))\n\t\tisErr := (len == -1)\n\n\t\tif isErr != test.isErr {\n\t\t\tt.Errorf(\"decodeUnicodeEscape(%s) returned isErr mismatch: expected %t, obtained %t\", test.in, test.isErr, isErr)\n\t\t} else if isErr {\n\t\t\tcontinue\n\t\t} else if len != test.len {\n\t\t\tt.Errorf(\"decodeUnicodeEscape(%s) returned length mismatch: expected %d, obtained %d\", test.in, test.len, len)\n\t\t} else if r != test.out {\n\t\t\tt.Errorf(\"decodeUnicodeEscape(%s) returned rune mismatch: expected %x (%c), obtained %x (%c)\", test.in, test.out, test.out, r, r)\n\t\t}\n\t}\n}\n\ntype unescapeTest struct {\n\tin       string // escaped string\n\tout      string // expected unescaped string\n\tcanAlloc bool   // can unescape cause an allocation (depending on buffer size)? true iff 'in' contains escape sequence(s)\n\tisErr    bool   // should this operation result in an error\n}\n\nvar unescapeTests = []unescapeTest{\n\t{in: ``, out: ``, canAlloc: false},\n\t{in: `a`, out: `a`, canAlloc: false},\n\t{in: `abcde`, out: `abcde`, canAlloc: false},\n\n\t{in: `ab\\\\de`, out: `ab\\de`, canAlloc: true},\n\t{in: `ab\\\"de`, out: `ab\"de`, canAlloc: true},\n\t{in: `ab \\u00B0 de`, out: `ab ° de`, canAlloc: true},\n\t{in: `ab \\uFF11 de`, out: `ab １ de`, canAlloc: true},\n\t{in: `\\uFFFF`, out: \"\\uFFFF\", canAlloc: true},\n\t{in: `ab \\uD83D\\uDE03 de`, out: \"ab \\U0001F603 de\", canAlloc: true},\n\t{in: `\\u0000\\u0000\\u0000\\u0000\\u0000`, out: \"\\u0000\\u0000\\u0000\\u0000\\u0000\", canAlloc: true},\n\t{in: `\\u0000 \\u0000 \\u0000 \\u0000 \\u0000`, out: \"\\u0000 \\u0000 \\u0000 \\u0000 \\u0000\", canAlloc: true},\n\t{in: ` \\u0000 \\u0000 \\u0000 \\u0000 \\u0000 `, out: \" \\u0000 \\u0000 \\u0000 \\u0000 \\u0000 \", canAlloc: true},\n\n\t{in: `\\uD800`, isErr: true},\n\t{in: `abcde\\`, isErr: true},\n\t{in: `abcde\\x`, isErr: true},\n\t{in: `abcde\\u`, isErr: true},\n\t{in: `abcde\\u1`, isErr: true},\n\t{in: `abcde\\u12`, isErr: true},\n\t{in: `abcde\\u123`, isErr: true},\n\t{in: `abcde\\uD800`, isErr: true},\n\t{in: `ab\\uD800de`, isErr: true},\n\t{in: `\\uD800abcde`, isErr: true},\n}\n\n// isSameMemory checks if two slices contain the same memory pointer (meaning one is a\n// subslice of the other, with possibly differing lengths/capacities).\nfunc isSameMemory(a, b []byte) bool {\n\tif cap(a) == 0 || cap(b) == 0 {\n\t\treturn cap(a) == cap(b)\n\t} else if a, b = a[:1], b[:1]; a[0] != b[0] {\n\t\treturn false\n\t} else {\n\t\ta[0]++\n\t\tsame := (a[0] == b[0])\n\t\ta[0]--\n\t\treturn same\n\t}\n\n}\n\nfunc TestUnescape(t *testing.T) {\n\tfor _, test := range unescapeTests {\n\t\ttype bufferTestCase struct {\n\t\t\tbuf        []byte\n\t\t\tisTooSmall bool\n\t\t}\n\n\t\tvar bufs []bufferTestCase\n\n\t\tif len(test.in) == 0 {\n\t\t\t// If the input string is length 0, only a buffer of size 0 is a meaningful test\n\t\t\tbufs = []bufferTestCase{{nil, false}}\n\t\t} else {\n\t\t\t// For non-empty input strings, we can try several buffer sizes (0, len-1, len)\n\t\t\tbufs = []bufferTestCase{\n\t\t\t\t{nil, true},\n\t\t\t\t{make([]byte, 0, len(test.in)-1), true},\n\t\t\t\t{make([]byte, 0, len(test.in)), false},\n\t\t\t}\n\t\t}\n\n\t\tfor _, buftest := range bufs {\n\t\t\tin := []byte(test.in)\n\t\t\tbuf := buftest.buf\n\n\t\t\tout, err := Unescape(in, buf)\n\t\t\tisErr := (err != nil)\n\t\t\tisAlloc := !isSameMemory(out, in) && !isSameMemory(out, buf)\n\n\t\t\tif isErr != test.isErr {\n\t\t\t\tt.Errorf(\"Unescape(`%s`, bufsize=%d) returned isErr mismatch: expected %t, obtained %t\", test.in, cap(buf), test.isErr, isErr)\n\t\t\t\tbreak\n\t\t\t} else if isErr {\n\t\t\t\tcontinue\n\t\t\t} else if !bytes.Equal(out, []byte(test.out)) {\n\t\t\t\tt.Errorf(\"Unescape(`%s`, bufsize=%d) returned unescaped mismatch: expected `%s` (%v, len %d), obtained `%s` (%v, len %d)\", test.in, cap(buf), test.out, []byte(test.out), len(test.out), string(out), out, len(out))\n\t\t\t\tbreak\n\t\t\t} else if isAlloc != (test.canAlloc && buftest.isTooSmall) {\n\t\t\t\tt.Errorf(\"Unescape(`%s`, bufsize=%d) returned isAlloc mismatch: expected %t, obtained %t\", test.in, cap(buf), buftest.isTooSmall, isAlloc)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "fuzz.go",
          "type": "blob",
          "size": 1.8271484375,
          "content": "package jsonparser\n\nfunc FuzzParseString(data []byte) int {\n\tr, err := ParseString(data)\n\tif err != nil || r == \"\" {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzEachKey(data []byte) int {\n\tpaths := [][]string{\n\t\t{\"name\"},\n\t\t{\"order\"},\n\t\t{\"nested\", \"a\"},\n\t\t{\"nested\", \"b\"},\n\t\t{\"nested2\", \"a\"},\n\t\t{\"nested\", \"nested3\", \"b\"},\n\t\t{\"arr\", \"[1]\", \"b\"},\n\t\t{\"arrInt\", \"[3]\"},\n\t\t{\"arrInt\", \"[5]\"},\n\t\t{\"nested\"},\n\t\t{\"arr\", \"[\"},\n\t\t{\"a\\n\", \"b\\n\"},\n\t}\n\tEachKey(data, func(idx int, value []byte, vt ValueType, err error) {}, paths...)\n\treturn 1\n}\n\nfunc FuzzDelete(data []byte) int {\n\tDelete(data, \"test\")\n\treturn 1\n}\n\nfunc FuzzSet(data []byte) int {\n\t_, err := Set(data, []byte(`\"new value\"`), \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzObjectEach(data []byte) int {\n\t_ = ObjectEach(data, func(key, value []byte, valueType ValueType, off int) error {\n\t\treturn nil\n\t})\n\treturn 1\n}\n\nfunc FuzzParseFloat(data []byte) int {\n\t_, err := ParseFloat(data)\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzParseInt(data []byte) int {\n\t_, err := ParseInt(data)\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzParseBool(data []byte) int {\n\t_, err := ParseBoolean(data)\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzTokenStart(data []byte) int {\n\t_ = tokenStart(data)\n\treturn 1\n}\n\nfunc FuzzGetString(data []byte) int {\n\t_, err := GetString(data, \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzGetFloat(data []byte) int {\n\t_, err := GetFloat(data, \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzGetInt(data []byte) int {\n\t_, err := GetInt(data, \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzGetBoolean(data []byte) int {\n\t_, err := GetBoolean(data, \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n\nfunc FuzzGetUnsafeString(data []byte) int {\n\t_, err := GetUnsafeString(data, \"test\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0439453125,
          "content": "module github.com/buger/jsonparser\n\ngo 1.13\n\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "oss-fuzz-build.sh",
          "type": "blob",
          "size": 1.794921875,
          "content": "#!/bin/bash -eu\n\ngit clone https://github.com/dvyukov/go-fuzz-corpus\nzip corpus.zip go-fuzz-corpus/json/corpus/*\n\ncp corpus.zip $OUT/fuzzparsestring_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzParseString fuzzparsestring\n\ncp corpus.zip $OUT/fuzzeachkey_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzEachKey fuzzeachkey\n\ncp corpus.zip $OUT/fuzzdelete_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzDelete fuzzdelete\n\ncp corpus.zip $OUT/fuzzset_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzSet fuzzset\n\ncp corpus.zip $OUT/fuzzobjecteach_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzObjectEach fuzzobjecteach\n\ncp corpus.zip $OUT/fuzzparsefloat_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzParseFloat fuzzparsefloat\n\ncp corpus.zip $OUT/fuzzparseint_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzParseInt fuzzparseint\n\ncp corpus.zip $OUT/fuzzparsebool_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzParseBool fuzzparsebool\n\ncp corpus.zip $OUT/fuzztokenstart_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzTokenStart fuzztokenstart\n\ncp corpus.zip $OUT/fuzzgetstring_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzGetString fuzzgetstring\n\ncp corpus.zip $OUT/fuzzgetfloat_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzGetFloat fuzzgetfloat\n\ncp corpus.zip $OUT/fuzzgetint_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzGetInt fuzzgetint\n\ncp corpus.zip $OUT/fuzzgetboolean_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzGetBoolean fuzzgetboolean\n\ncp corpus.zip $OUT/fuzzgetunsafestring_seed_corpus.zip\ncompile_go_fuzzer github.com/buger/jsonparser FuzzGetUnsafeString fuzzgetunsafestring\n\n"
        },
        {
          "name": "parser.go",
          "type": "blob",
          "size": 30.083984375,
          "content": "package jsonparser\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"strconv\"\n)\n\n// Errors\nvar (\n\tKeyPathNotFoundError       = errors.New(\"Key path not found\")\n\tUnknownValueTypeError      = errors.New(\"Unknown value type\")\n\tMalformedJsonError         = errors.New(\"Malformed JSON error\")\n\tMalformedStringError       = errors.New(\"Value is string, but can't find closing '\\\"' symbol\")\n\tMalformedArrayError        = errors.New(\"Value is array, but can't find closing ']' symbol\")\n\tMalformedObjectError       = errors.New(\"Value looks like object, but can't find closing '}' symbol\")\n\tMalformedValueError        = errors.New(\"Value looks like Number/Boolean/None, but can't find its end: ',' or '}' symbol\")\n\tOverflowIntegerError       = errors.New(\"Value is number, but overflowed while parsing\")\n\tMalformedStringEscapeError = errors.New(\"Encountered an invalid escape sequence in a string\")\n\tNullValueError             = errors.New(\"Value is null\")\n)\n\n// How much stack space to allocate for unescaping JSON strings; if a string longer\n// than this needs to be escaped, it will result in a heap allocation\nconst unescapeStackBufSize = 64\n\nfunc tokenEnd(data []byte) int {\n\tfor i, c := range data {\n\t\tswitch c {\n\t\tcase ' ', '\\n', '\\r', '\\t', ',', '}', ']':\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn len(data)\n}\n\nfunc findTokenStart(data []byte, token byte) int {\n\tfor i := len(data) - 1; i >= 0; i-- {\n\t\tswitch data[i] {\n\t\tcase token:\n\t\t\treturn i\n\t\tcase '[', '{':\n\t\t\treturn 0\n\t\t}\n\t}\n\n\treturn 0\n}\n\nfunc findKeyStart(data []byte, key string) (int, error) {\n\ti := nextToken(data)\n\tif i == -1 {\n\t\treturn i, KeyPathNotFoundError\n\t}\n\tln := len(data)\n\tif ln > 0 && (data[i] == '{' || data[i] == '[') {\n\t\ti += 1\n\t}\n\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\n\tif ku, err := Unescape(StringToBytes(key), stackbuf[:]); err == nil {\n\t\tkey = bytesToString(&ku)\n\t}\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"':\n\t\t\ti++\n\t\t\tkeyBegin := i\n\n\t\t\tstrEnd, keyEscaped := stringEnd(data[i:])\n\t\t\tif strEnd == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ti += strEnd\n\t\t\tkeyEnd := i - 1\n\n\t\t\tvalueOffset := nextToken(data[i:])\n\t\t\tif valueOffset == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\ti += valueOffset\n\n\t\t\t// if string is a key, and key level match\n\t\t\tk := data[keyBegin:keyEnd]\n\t\t\t// for unescape: if there are no escape sequences, this is cheap; if there are, it is a\n\t\t\t// bit more expensive, but causes no allocations unless len(key) > unescapeStackBufSize\n\t\t\tif keyEscaped {\n\t\t\t\tif ku, err := Unescape(k, stackbuf[:]); err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t} else {\n\t\t\t\t\tk = ku\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif data[i] == ':' && len(key) == len(k) && bytesToString(&k) == key {\n\t\t\t\treturn keyBegin - 1, nil\n\t\t\t}\n\n\t\tcase '[':\n\t\t\tend := blockEnd(data[i:], data[i], ']')\n\t\t\tif end != -1 {\n\t\t\t\ti = i + end\n\t\t\t}\n\t\tcase '{':\n\t\t\tend := blockEnd(data[i:], data[i], '}')\n\t\t\tif end != -1 {\n\t\t\t\ti = i + end\n\t\t\t}\n\t\t}\n\t\ti++\n\t}\n\n\treturn -1, KeyPathNotFoundError\n}\n\nfunc tokenStart(data []byte) int {\n\tfor i := len(data) - 1; i >= 0; i-- {\n\t\tswitch data[i] {\n\t\tcase '\\n', '\\r', '\\t', ',', '{', '[':\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn 0\n}\n\n// Find position of next character which is not whitespace\nfunc nextToken(data []byte) int {\n\tfor i, c := range data {\n\t\tswitch c {\n\t\tcase ' ', '\\n', '\\r', '\\t':\n\t\t\tcontinue\n\t\tdefault:\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn -1\n}\n\n// Find position of last character which is not whitespace\nfunc lastToken(data []byte) int {\n\tfor i := len(data) - 1; i >= 0; i-- {\n\t\tswitch data[i] {\n\t\tcase ' ', '\\n', '\\r', '\\t':\n\t\t\tcontinue\n\t\tdefault:\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn -1\n}\n\n// Tries to find the end of string\n// Support if string contains escaped quote symbols.\nfunc stringEnd(data []byte) (int, bool) {\n\tescaped := false\n\tfor i, c := range data {\n\t\tif c == '\"' {\n\t\t\tif !escaped {\n\t\t\t\treturn i + 1, false\n\t\t\t} else {\n\t\t\t\tj := i - 1\n\t\t\t\tfor {\n\t\t\t\t\tif j < 0 || data[j] != '\\\\' {\n\t\t\t\t\t\treturn i + 1, true // even number of backslashes\n\t\t\t\t\t}\n\t\t\t\t\tj--\n\t\t\t\t\tif j < 0 || data[j] != '\\\\' {\n\t\t\t\t\t\tbreak // odd number of backslashes\n\t\t\t\t\t}\n\t\t\t\t\tj--\n\n\t\t\t\t}\n\t\t\t}\n\t\t} else if c == '\\\\' {\n\t\t\tescaped = true\n\t\t}\n\t}\n\n\treturn -1, escaped\n}\n\n// Find end of the data structure, array or object.\n// For array openSym and closeSym will be '[' and ']', for object '{' and '}'\nfunc blockEnd(data []byte, openSym byte, closeSym byte) int {\n\tlevel := 0\n\ti := 0\n\tln := len(data)\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"': // If inside string, skip it\n\t\t\tse, _ := stringEnd(data[i+1:])\n\t\t\tif se == -1 {\n\t\t\t\treturn -1\n\t\t\t}\n\t\t\ti += se\n\t\tcase openSym: // If open symbol, increase level\n\t\t\tlevel++\n\t\tcase closeSym: // If close symbol, increase level\n\t\t\tlevel--\n\n\t\t\t// If we have returned to the original level, we're done\n\t\t\tif level == 0 {\n\t\t\t\treturn i + 1\n\t\t\t}\n\t\t}\n\t\ti++\n\t}\n\n\treturn -1\n}\n\nfunc searchKeys(data []byte, keys ...string) int {\n\tkeyLevel := 0\n\tlevel := 0\n\ti := 0\n\tln := len(data)\n\tlk := len(keys)\n\tlastMatched := true\n\n\tif lk == 0 {\n\t\treturn 0\n\t}\n\n\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"':\n\t\t\ti++\n\t\t\tkeyBegin := i\n\n\t\t\tstrEnd, keyEscaped := stringEnd(data[i:])\n\t\t\tif strEnd == -1 {\n\t\t\t\treturn -1\n\t\t\t}\n\t\t\ti += strEnd\n\t\t\tkeyEnd := i - 1\n\n\t\t\tvalueOffset := nextToken(data[i:])\n\t\t\tif valueOffset == -1 {\n\t\t\t\treturn -1\n\t\t\t}\n\n\t\t\ti += valueOffset\n\n\t\t\t// if string is a key\n\t\t\tif data[i] == ':' {\n\t\t\t\tif level < 1 {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\n\t\t\t\tkey := data[keyBegin:keyEnd]\n\n\t\t\t\t// for unescape: if there are no escape sequences, this is cheap; if there are, it is a\n\t\t\t\t// bit more expensive, but causes no allocations unless len(key) > unescapeStackBufSize\n\t\t\t\tvar keyUnesc []byte\n\t\t\t\tif !keyEscaped {\n\t\t\t\t\tkeyUnesc = key\n\t\t\t\t} else if ku, err := Unescape(key, stackbuf[:]); err != nil {\n\t\t\t\t\treturn -1\n\t\t\t\t} else {\n\t\t\t\t\tkeyUnesc = ku\n\t\t\t\t}\n\n\t\t\t\tif level <= len(keys) {\n\t\t\t\t\tif equalStr(&keyUnesc, keys[level-1]) {\n\t\t\t\t\t\tlastMatched = true\n\n\t\t\t\t\t\t// if key level match\n\t\t\t\t\t\tif keyLevel == level-1 {\n\t\t\t\t\t\t\tkeyLevel++\n\t\t\t\t\t\t\t// If we found all keys in path\n\t\t\t\t\t\t\tif keyLevel == lk {\n\t\t\t\t\t\t\t\treturn i + 1\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlastMatched = false\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti--\n\t\t\t}\n\t\tcase '{':\n\n\t\t\t// in case parent key is matched then only we will increase the level otherwise can directly\n\t\t\t// can move to the end of this block\n\t\t\tif !lastMatched {\n\t\t\t\tend := blockEnd(data[i:], '{', '}')\n\t\t\t\tif end == -1 {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t\ti += end - 1\n\t\t\t} else {\n\t\t\t\tlevel++\n\t\t\t}\n\t\tcase '}':\n\t\t\tlevel--\n\t\t\tif level == keyLevel {\n\t\t\t\tkeyLevel--\n\t\t\t}\n\t\tcase '[':\n\t\t\t// If we want to get array element by index\n\t\t\tif keyLevel == level && keys[level][0] == '[' {\n\t\t\t\tkeyLen := len(keys[level])\n\t\t\t\tif keyLen < 3 || keys[level][0] != '[' || keys[level][keyLen-1] != ']' {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t\taIdx, err := strconv.Atoi(keys[level][1 : keyLen-1])\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t\tvar curIdx int\n\t\t\t\tvar valueFound []byte\n\t\t\t\tvar valueOffset int\n\t\t\t\tcurI := i\n\t\t\t\tArrayEach(data[i:], func(value []byte, dataType ValueType, offset int, err error) {\n\t\t\t\t\tif curIdx == aIdx {\n\t\t\t\t\t\tvalueFound = value\n\t\t\t\t\t\tvalueOffset = offset\n\t\t\t\t\t\tif dataType == String {\n\t\t\t\t\t\t\tvalueOffset = valueOffset - 2\n\t\t\t\t\t\t\tvalueFound = data[curI+valueOffset : curI+valueOffset+len(value)+2]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcurIdx += 1\n\t\t\t\t})\n\n\t\t\t\tif valueFound == nil {\n\t\t\t\t\treturn -1\n\t\t\t\t} else {\n\t\t\t\t\tsubIndex := searchKeys(valueFound, keys[level+1:]...)\n\t\t\t\t\tif subIndex < 0 {\n\t\t\t\t\t\treturn -1\n\t\t\t\t\t}\n\t\t\t\t\treturn i + valueOffset + subIndex\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Do not search for keys inside arrays\n\t\t\t\tif arraySkip := blockEnd(data[i:], '[', ']'); arraySkip == -1 {\n\t\t\t\t\treturn -1\n\t\t\t\t} else {\n\t\t\t\t\ti += arraySkip - 1\n\t\t\t\t}\n\t\t\t}\n\t\tcase ':': // If encountered, JSON data is malformed\n\t\t\treturn -1\n\t\t}\n\n\t\ti++\n\t}\n\n\treturn -1\n}\n\nfunc sameTree(p1, p2 []string) bool {\n\tminLen := len(p1)\n\tif len(p2) < minLen {\n\t\tminLen = len(p2)\n\t}\n\n\tfor pi_1, p_1 := range p1[:minLen] {\n\t\tif p2[pi_1] != p_1 {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\nconst stackArraySize = 128\n\nfunc EachKey(data []byte, cb func(int, []byte, ValueType, error), paths ...[]string) int {\n\tvar x struct{}\n\tvar level, pathsMatched, i int\n\tln := len(data)\n\n\tpathFlags := make([]bool, stackArraySize)[:]\n\tif len(paths) > cap(pathFlags) {\n\t\tpathFlags = make([]bool, len(paths))[:]\n\t}\n\tpathFlags = pathFlags[0:len(paths)]\n\n\tvar maxPath int\n\tfor _, p := range paths {\n\t\tif len(p) > maxPath {\n\t\t\tmaxPath = len(p)\n\t\t}\n\t}\n\n\tpathsBuf := make([]string, stackArraySize)[:]\n\tif maxPath > cap(pathsBuf) {\n\t\tpathsBuf = make([]string, maxPath)[:]\n\t}\n\tpathsBuf = pathsBuf[0:maxPath]\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"':\n\t\t\ti++\n\t\t\tkeyBegin := i\n\n\t\t\tstrEnd, keyEscaped := stringEnd(data[i:])\n\t\t\tif strEnd == -1 {\n\t\t\t\treturn -1\n\t\t\t}\n\t\t\ti += strEnd\n\n\t\t\tkeyEnd := i - 1\n\n\t\t\tvalueOffset := nextToken(data[i:])\n\t\t\tif valueOffset == -1 {\n\t\t\t\treturn -1\n\t\t\t}\n\n\t\t\ti += valueOffset\n\n\t\t\t// if string is a key, and key level match\n\t\t\tif data[i] == ':' {\n\t\t\t\tmatch := -1\n\t\t\t\tkey := data[keyBegin:keyEnd]\n\n\t\t\t\t// for unescape: if there are no escape sequences, this is cheap; if there are, it is a\n\t\t\t\t// bit more expensive, but causes no allocations unless len(key) > unescapeStackBufSize\n\t\t\t\tvar keyUnesc []byte\n\t\t\t\tif !keyEscaped {\n\t\t\t\t\tkeyUnesc = key\n\t\t\t\t} else {\n\t\t\t\t\tvar stackbuf [unescapeStackBufSize]byte\n\t\t\t\t\tif ku, err := Unescape(key, stackbuf[:]); err != nil {\n\t\t\t\t\t\treturn -1\n\t\t\t\t\t} else {\n\t\t\t\t\t\tkeyUnesc = ku\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif maxPath >= level {\n\t\t\t\t\tif level < 1 {\n\t\t\t\t\t\tcb(-1, nil, Unknown, MalformedJsonError)\n\t\t\t\t\t\treturn -1\n\t\t\t\t\t}\n\n\t\t\t\t\tpathsBuf[level-1] = bytesToString(&keyUnesc)\n\t\t\t\t\tfor pi, p := range paths {\n\t\t\t\t\t\tif len(p) != level || pathFlags[pi] || !equalStr(&keyUnesc, p[level-1]) || !sameTree(p, pathsBuf[:level]) {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tmatch = pi\n\n\t\t\t\t\t\tpathsMatched++\n\t\t\t\t\t\tpathFlags[pi] = true\n\n\t\t\t\t\t\tv, dt, _, e := Get(data[i+1:])\n\t\t\t\t\t\tcb(pi, v, dt, e)\n\n\t\t\t\t\t\tif pathsMatched == len(paths) {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif pathsMatched == len(paths) {\n\t\t\t\t\t\treturn i\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif match == -1 {\n\t\t\t\t\ttokenOffset := nextToken(data[i+1:])\n\t\t\t\t\ti += tokenOffset\n\n\t\t\t\t\tif data[i] == '{' {\n\t\t\t\t\t\tblockSkip := blockEnd(data[i:], '{', '}')\n\t\t\t\t\t\ti += blockSkip + 1\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif i < ln {\n\t\t\t\t\tswitch data[i] {\n\t\t\t\t\tcase '{', '}', '[', '\"':\n\t\t\t\t\t\ti--\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti--\n\t\t\t}\n\t\tcase '{':\n\t\t\tlevel++\n\t\tcase '}':\n\t\t\tlevel--\n\t\tcase '[':\n\t\t\tvar ok bool\n\t\t\tarrIdxFlags := make(map[int]struct{})\n\n\t\t\tpIdxFlags := make([]bool, stackArraySize)[:]\n\t\t\tif len(paths) > cap(pIdxFlags) {\n\t\t\t\tpIdxFlags = make([]bool, len(paths))[:]\n\t\t\t}\n\t\t\tpIdxFlags = pIdxFlags[0:len(paths)]\n\n\t\t\tif level < 0 {\n\t\t\t\tcb(-1, nil, Unknown, MalformedJsonError)\n\t\t\t\treturn -1\n\t\t\t}\n\n\t\t\tfor pi, p := range paths {\n\t\t\t\tif len(p) < level+1 || pathFlags[pi] || p[level][0] != '[' || !sameTree(p, pathsBuf[:level]) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif len(p[level]) >= 2 {\n\t\t\t\t\taIdx, _ := strconv.Atoi(p[level][1 : len(p[level])-1])\n\t\t\t\t\tarrIdxFlags[aIdx] = x\n\t\t\t\t\tpIdxFlags[pi] = true\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(arrIdxFlags) > 0 {\n\t\t\t\tlevel++\n\n\t\t\t\tvar curIdx int\n\t\t\t\tarrOff, _ := ArrayEach(data[i:], func(value []byte, dataType ValueType, offset int, err error) {\n\t\t\t\t\tif _, ok = arrIdxFlags[curIdx]; ok {\n\t\t\t\t\t\tfor pi, p := range paths {\n\t\t\t\t\t\t\tif pIdxFlags[pi] {\n\t\t\t\t\t\t\t\taIdx, _ := strconv.Atoi(p[level-1][1 : len(p[level-1])-1])\n\n\t\t\t\t\t\t\t\tif curIdx == aIdx {\n\t\t\t\t\t\t\t\t\tof := searchKeys(value, p[level:]...)\n\n\t\t\t\t\t\t\t\t\tpathsMatched++\n\t\t\t\t\t\t\t\t\tpathFlags[pi] = true\n\n\t\t\t\t\t\t\t\t\tif of != -1 {\n\t\t\t\t\t\t\t\t\t\tv, dt, _, e := Get(value[of:])\n\t\t\t\t\t\t\t\t\t\tcb(pi, v, dt, e)\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tcurIdx += 1\n\t\t\t\t})\n\n\t\t\t\tif pathsMatched == len(paths) {\n\t\t\t\t\treturn i\n\t\t\t\t}\n\n\t\t\t\ti += arrOff - 1\n\t\t\t} else {\n\t\t\t\t// Do not search for keys inside arrays\n\t\t\t\tif arraySkip := blockEnd(data[i:], '[', ']'); arraySkip == -1 {\n\t\t\t\t\treturn -1\n\t\t\t\t} else {\n\t\t\t\t\ti += arraySkip - 1\n\t\t\t\t}\n\t\t\t}\n\t\tcase ']':\n\t\t\tlevel--\n\t\t}\n\n\t\ti++\n\t}\n\n\treturn -1\n}\n\n// Data types available in valid JSON data.\ntype ValueType int\n\nconst (\n\tNotExist = ValueType(iota)\n\tString\n\tNumber\n\tObject\n\tArray\n\tBoolean\n\tNull\n\tUnknown\n)\n\nfunc (vt ValueType) String() string {\n\tswitch vt {\n\tcase NotExist:\n\t\treturn \"non-existent\"\n\tcase String:\n\t\treturn \"string\"\n\tcase Number:\n\t\treturn \"number\"\n\tcase Object:\n\t\treturn \"object\"\n\tcase Array:\n\t\treturn \"array\"\n\tcase Boolean:\n\t\treturn \"boolean\"\n\tcase Null:\n\t\treturn \"null\"\n\tdefault:\n\t\treturn \"unknown\"\n\t}\n}\n\nvar (\n\ttrueLiteral  = []byte(\"true\")\n\tfalseLiteral = []byte(\"false\")\n\tnullLiteral  = []byte(\"null\")\n)\n\nfunc createInsertComponent(keys []string, setValue []byte, comma, object bool) []byte {\n\tisIndex := string(keys[0][0]) == \"[\"\n\toffset := 0\n\tlk := calcAllocateSpace(keys, setValue, comma, object)\n\tbuffer := make([]byte, lk, lk)\n\tif comma {\n\t\toffset += WriteToBuffer(buffer[offset:], \",\")\n\t}\n\tif isIndex && !comma {\n\t\toffset += WriteToBuffer(buffer[offset:], \"[\")\n\t} else {\n\t\tif object {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"{\")\n\t\t}\n\t\tif !isIndex {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"\\\"\")\n\t\t\toffset += WriteToBuffer(buffer[offset:], keys[0])\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"\\\":\")\n\t\t}\n\t}\n\n\tfor i := 1; i < len(keys); i++ {\n\t\tif string(keys[i][0]) == \"[\" {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"[\")\n\t\t} else {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"{\\\"\")\n\t\t\toffset += WriteToBuffer(buffer[offset:], keys[i])\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"\\\":\")\n\t\t}\n\t}\n\toffset += WriteToBuffer(buffer[offset:], string(setValue))\n\tfor i := len(keys) - 1; i > 0; i-- {\n\t\tif string(keys[i][0]) == \"[\" {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"]\")\n\t\t} else {\n\t\t\toffset += WriteToBuffer(buffer[offset:], \"}\")\n\t\t}\n\t}\n\tif isIndex && !comma {\n\t\toffset += WriteToBuffer(buffer[offset:], \"]\")\n\t}\n\tif object && !isIndex {\n\t\toffset += WriteToBuffer(buffer[offset:], \"}\")\n\t}\n\treturn buffer\n}\n\nfunc calcAllocateSpace(keys []string, setValue []byte, comma, object bool) int {\n\tisIndex := string(keys[0][0]) == \"[\"\n\tlk := 0\n\tif comma {\n\t\t// ,\n\t\tlk += 1\n\t}\n\tif isIndex && !comma {\n\t\t// []\n\t\tlk += 2\n\t} else {\n\t\tif object {\n\t\t\t// {\n\t\t\tlk += 1\n\t\t}\n\t\tif !isIndex {\n\t\t\t// \"keys[0]\"\n\t\t\tlk += len(keys[0]) + 3\n\t\t}\n\t}\n\n\tlk += len(setValue)\n\tfor i := 1; i < len(keys); i++ {\n\t\tif string(keys[i][0]) == \"[\" {\n\t\t\t// []\n\t\t\tlk += 2\n\t\t} else {\n\t\t\t// {\"keys[i]\":setValue}\n\t\t\tlk += len(keys[i]) + 5\n\t\t}\n\t}\n\n\tif object && !isIndex {\n\t\t// }\n\t\tlk += 1\n\t}\n\n\treturn lk\n}\n\nfunc WriteToBuffer(buffer []byte, str string) int {\n\tcopy(buffer, str)\n\treturn len(str)\n}\n\n/*\n\nDel - Receives existing data structure, path to delete.\n\nReturns:\n`data` - return modified data\n\n*/\nfunc Delete(data []byte, keys ...string) []byte {\n\tlk := len(keys)\n\tif lk == 0 {\n\t\treturn data[:0]\n\t}\n\n\tarray := false\n\tif len(keys[lk-1]) > 0 && string(keys[lk-1][0]) == \"[\" {\n\t\tarray = true\n\t}\n\n\tvar startOffset, keyOffset int\n\tendOffset := len(data)\n\tvar err error\n\tif !array {\n\t\tif len(keys) > 1 {\n\t\t\t_, _, startOffset, endOffset, err = internalGet(data, keys[:lk-1]...)\n\t\t\tif err == KeyPathNotFoundError {\n\t\t\t\t// problem parsing the data\n\t\t\t\treturn data\n\t\t\t}\n\t\t}\n\n\t\tkeyOffset, err = findKeyStart(data[startOffset:endOffset], keys[lk-1])\n\t\tif err == KeyPathNotFoundError {\n\t\t\t// problem parsing the data\n\t\t\treturn data\n\t\t}\n\t\tkeyOffset += startOffset\n\t\t_, _, _, subEndOffset, _ := internalGet(data[startOffset:endOffset], keys[lk-1])\n\t\tendOffset = startOffset + subEndOffset\n\t\ttokEnd := tokenEnd(data[endOffset:])\n\t\ttokStart := findTokenStart(data[:keyOffset], \",\"[0])\n\n\t\tif data[endOffset+tokEnd] == \",\"[0] {\n\t\t\tendOffset += tokEnd + 1\n\t\t} else if data[endOffset+tokEnd] == \" \"[0] && len(data) > endOffset+tokEnd+1 && data[endOffset+tokEnd+1] == \",\"[0] {\n\t\t\tendOffset += tokEnd + 2\n\t\t} else if data[endOffset+tokEnd] == \"}\"[0] && data[tokStart] == \",\"[0] {\n\t\t\tkeyOffset = tokStart\n\t\t}\n\t} else {\n\t\t_, _, keyOffset, endOffset, err = internalGet(data, keys...)\n\t\tif err == KeyPathNotFoundError {\n\t\t\t// problem parsing the data\n\t\t\treturn data\n\t\t}\n\n\t\ttokEnd := tokenEnd(data[endOffset:])\n\t\ttokStart := findTokenStart(data[:keyOffset], \",\"[0])\n\n\t\tif data[endOffset+tokEnd] == \",\"[0] {\n\t\t\tendOffset += tokEnd + 1\n\t\t} else if data[endOffset+tokEnd] == \"]\"[0] && data[tokStart] == \",\"[0] {\n\t\t\tkeyOffset = tokStart\n\t\t}\n\t}\n\n\t// We need to remove remaining trailing comma if we delete las element in the object\n\tprevTok := lastToken(data[:keyOffset])\n\tremainedValue := data[endOffset:]\n\n\tvar newOffset int\n\tif nextToken(remainedValue) > -1 && remainedValue[nextToken(remainedValue)] == '}' && data[prevTok] == ',' {\n\t\tnewOffset = prevTok\n\t} else {\n\t\tnewOffset = prevTok + 1\n\t}\n\n\t// We have to make a copy here if we don't want to mangle the original data, because byte slices are\n\t// accessed by reference and not by value\n\tdataCopy := make([]byte, len(data))\n\tcopy(dataCopy, data)\n\tdata = append(dataCopy[:newOffset], dataCopy[endOffset:]...)\n\n\treturn data\n}\n\n/*\n\nSet - Receives existing data structure, path to set, and data to set at that key.\n\nReturns:\n`value` - modified byte array\n`err` - On any parsing error\n\n*/\nfunc Set(data []byte, setValue []byte, keys ...string) (value []byte, err error) {\n\t// ensure keys are set\n\tif len(keys) == 0 {\n\t\treturn nil, KeyPathNotFoundError\n\t}\n\n\t_, _, startOffset, endOffset, err := internalGet(data, keys...)\n\tif err != nil {\n\t\tif err != KeyPathNotFoundError {\n\t\t\t// problem parsing the data\n\t\t\treturn nil, err\n\t\t}\n\t\t// full path doesnt exist\n\t\t// does any subpath exist?\n\t\tvar depth int\n\t\tfor i := range keys {\n\t\t\t_, _, start, end, sErr := internalGet(data, keys[:i+1]...)\n\t\t\tif sErr != nil {\n\t\t\t\tbreak\n\t\t\t} else {\n\t\t\t\tendOffset = end\n\t\t\t\tstartOffset = start\n\t\t\t\tdepth++\n\t\t\t}\n\t\t}\n\t\tcomma := true\n\t\tobject := false\n\t\tif endOffset == -1 {\n\t\t\tfirstToken := nextToken(data)\n\t\t\t// We can't set a top-level key if data isn't an object\n\t\t\tif firstToken < 0 || data[firstToken] != '{' {\n\t\t\t\treturn nil, KeyPathNotFoundError\n\t\t\t}\n\t\t\t// Don't need a comma if the input is an empty object\n\t\t\tsecondToken := firstToken + 1 + nextToken(data[firstToken+1:])\n\t\t\tif data[secondToken] == '}' {\n\t\t\t\tcomma = false\n\t\t\t}\n\t\t\t// Set the top level key at the end (accounting for any trailing whitespace)\n\t\t\t// This assumes last token is valid like '}', could check and return error\n\t\t\tendOffset = lastToken(data)\n\t\t}\n\t\tdepthOffset := endOffset\n\t\tif depth != 0 {\n\t\t\t// if subpath is a non-empty object, add to it\n\t\t\t// or if subpath is a non-empty array, add to it\n\t\t\tif (data[startOffset] == '{' && data[startOffset+1+nextToken(data[startOffset+1:])] != '}') ||\n\t\t\t\t(data[startOffset] == '[' && data[startOffset+1+nextToken(data[startOffset+1:])] == '{') && keys[depth:][0][0] == 91 {\n\t\t\t\tdepthOffset--\n\t\t\t\tstartOffset = depthOffset\n\t\t\t\t// otherwise, over-write it with a new object\n\t\t\t} else {\n\t\t\t\tcomma = false\n\t\t\t\tobject = true\n\t\t\t}\n\t\t} else {\n\t\t\tstartOffset = depthOffset\n\t\t}\n\t\tvalue = append(data[:startOffset], append(createInsertComponent(keys[depth:], setValue, comma, object), data[depthOffset:]...)...)\n\t} else {\n\t\t// path currently exists\n\t\tstartComponent := data[:startOffset]\n\t\tendComponent := data[endOffset:]\n\n\t\tvalue = make([]byte, len(startComponent)+len(endComponent)+len(setValue))\n\t\tnewEndOffset := startOffset + len(setValue)\n\t\tcopy(value[0:startOffset], startComponent)\n\t\tcopy(value[startOffset:newEndOffset], setValue)\n\t\tcopy(value[newEndOffset:], endComponent)\n\t}\n\treturn value, nil\n}\n\nfunc getType(data []byte, offset int) ([]byte, ValueType, int, error) {\n\tvar dataType ValueType\n\tendOffset := offset\n\n\t// if string value\n\tif data[offset] == '\"' {\n\t\tdataType = String\n\t\tif idx, _ := stringEnd(data[offset+1:]); idx != -1 {\n\t\t\tendOffset += idx + 1\n\t\t} else {\n\t\t\treturn nil, dataType, offset, MalformedStringError\n\t\t}\n\t} else if data[offset] == '[' { // if array value\n\t\tdataType = Array\n\t\t// break label, for stopping nested loops\n\t\tendOffset = blockEnd(data[offset:], '[', ']')\n\n\t\tif endOffset == -1 {\n\t\t\treturn nil, dataType, offset, MalformedArrayError\n\t\t}\n\n\t\tendOffset += offset\n\t} else if data[offset] == '{' { // if object value\n\t\tdataType = Object\n\t\t// break label, for stopping nested loops\n\t\tendOffset = blockEnd(data[offset:], '{', '}')\n\n\t\tif endOffset == -1 {\n\t\t\treturn nil, dataType, offset, MalformedObjectError\n\t\t}\n\n\t\tendOffset += offset\n\t} else {\n\t\t// Number, Boolean or None\n\t\tend := tokenEnd(data[endOffset:])\n\n\t\tif end == -1 {\n\t\t\treturn nil, dataType, offset, MalformedValueError\n\t\t}\n\n\t\tvalue := data[offset : endOffset+end]\n\n\t\tswitch data[offset] {\n\t\tcase 't', 'f': // true or false\n\t\t\tif bytes.Equal(value, trueLiteral) || bytes.Equal(value, falseLiteral) {\n\t\t\t\tdataType = Boolean\n\t\t\t} else {\n\t\t\t\treturn nil, Unknown, offset, UnknownValueTypeError\n\t\t\t}\n\t\tcase 'u', 'n': // undefined or null\n\t\t\tif bytes.Equal(value, nullLiteral) {\n\t\t\t\tdataType = Null\n\t\t\t} else {\n\t\t\t\treturn nil, Unknown, offset, UnknownValueTypeError\n\t\t\t}\n\t\tcase '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-':\n\t\t\tdataType = Number\n\t\tdefault:\n\t\t\treturn nil, Unknown, offset, UnknownValueTypeError\n\t\t}\n\n\t\tendOffset += end\n\t}\n\treturn data[offset:endOffset], dataType, endOffset, nil\n}\n\n/*\nGet - Receives data structure, and key path to extract value from.\n\nReturns:\n`value` - Pointer to original data structure containing key value, or just empty slice if nothing found or error\n`dataType` -    Can be: `NotExist`, `String`, `Number`, `Object`, `Array`, `Boolean` or `Null`\n`offset` - Offset from provided data structure where key value ends. Used mostly internally, for example for `ArrayEach` helper.\n`err` - If key not found or any other parsing issue it should return error. If key not found it also sets `dataType` to `NotExist`\n\nAccept multiple keys to specify path to JSON value (in case of quering nested structures).\nIf no keys provided it will try to extract closest JSON value (simple ones or object/array), useful for reading streams or arrays, see `ArrayEach` implementation.\n*/\nfunc Get(data []byte, keys ...string) (value []byte, dataType ValueType, offset int, err error) {\n\ta, b, _, d, e := internalGet(data, keys...)\n\treturn a, b, d, e\n}\n\nfunc internalGet(data []byte, keys ...string) (value []byte, dataType ValueType, offset, endOffset int, err error) {\n\tif len(keys) > 0 {\n\t\tif offset = searchKeys(data, keys...); offset == -1 {\n\t\t\treturn nil, NotExist, -1, -1, KeyPathNotFoundError\n\t\t}\n\t}\n\n\t// Go to closest value\n\tnO := nextToken(data[offset:])\n\tif nO == -1 {\n\t\treturn nil, NotExist, offset, -1, MalformedJsonError\n\t}\n\n\toffset += nO\n\tvalue, dataType, endOffset, err = getType(data, offset)\n\tif err != nil {\n\t\treturn value, dataType, offset, endOffset, err\n\t}\n\n\t// Strip quotes from string values\n\tif dataType == String {\n\t\tvalue = value[1 : len(value)-1]\n\t}\n\n\treturn value[:len(value):len(value)], dataType, offset, endOffset, nil\n}\n\n// ArrayEach is used when iterating arrays, accepts a callback function with the same return arguments as `Get`.\nfunc ArrayEach(data []byte, cb func(value []byte, dataType ValueType, offset int, err error), keys ...string) (offset int, err error) {\n\tif len(data) == 0 {\n\t\treturn -1, MalformedObjectError\n\t}\n\n\tnT := nextToken(data)\n\tif nT == -1 {\n\t\treturn -1, MalformedJsonError\n\t}\n\n\toffset = nT + 1\n\n\tif len(keys) > 0 {\n\t\tif offset = searchKeys(data, keys...); offset == -1 {\n\t\t\treturn offset, KeyPathNotFoundError\n\t\t}\n\n\t\t// Go to closest value\n\t\tnO := nextToken(data[offset:])\n\t\tif nO == -1 {\n\t\t\treturn offset, MalformedJsonError\n\t\t}\n\n\t\toffset += nO\n\n\t\tif data[offset] != '[' {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\n\t\toffset++\n\t}\n\n\tnO := nextToken(data[offset:])\n\tif nO == -1 {\n\t\treturn offset, MalformedJsonError\n\t}\n\n\toffset += nO\n\n\tif data[offset] == ']' {\n\t\treturn offset, nil\n\t}\n\n\tfor true {\n\t\tv, t, o, e := Get(data[offset:])\n\n\t\tif e != nil {\n\t\t\treturn offset, e\n\t\t}\n\n\t\tif o == 0 {\n\t\t\tbreak\n\t\t}\n\n\t\tif t != NotExist {\n\t\t\tcb(v, t, offset+o-len(v), e)\n\t\t}\n\n\t\tif e != nil {\n\t\t\tbreak\n\t\t}\n\n\t\toffset += o\n\n\t\tskipToToken := nextToken(data[offset:])\n\t\tif skipToToken == -1 {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\t\toffset += skipToToken\n\n\t\tif data[offset] == ']' {\n\t\t\tbreak\n\t\t}\n\n\t\tif data[offset] != ',' {\n\t\t\treturn offset, MalformedArrayError\n\t\t}\n\n\t\toffset++\n\t}\n\n\treturn offset, nil\n}\n\n// ObjectEach iterates over the key-value pairs of a JSON object, invoking a given callback for each such entry\nfunc ObjectEach(data []byte, callback func(key []byte, value []byte, dataType ValueType, offset int) error, keys ...string) (err error) {\n\toffset := 0\n\n\t// Descend to the desired key, if requested\n\tif len(keys) > 0 {\n\t\tif off := searchKeys(data, keys...); off == -1 {\n\t\t\treturn KeyPathNotFoundError\n\t\t} else {\n\t\t\toffset = off\n\t\t}\n\t}\n\n\t// Validate and skip past opening brace\n\tif off := nextToken(data[offset:]); off == -1 {\n\t\treturn MalformedObjectError\n\t} else if offset += off; data[offset] != '{' {\n\t\treturn MalformedObjectError\n\t} else {\n\t\toffset++\n\t}\n\n\t// Skip to the first token inside the object, or stop if we find the ending brace\n\tif off := nextToken(data[offset:]); off == -1 {\n\t\treturn MalformedJsonError\n\t} else if offset += off; data[offset] == '}' {\n\t\treturn nil\n\t}\n\n\t// Loop pre-condition: data[offset] points to what should be either the next entry's key, or the closing brace (if it's anything else, the JSON is malformed)\n\tfor offset < len(data) {\n\t\t// Step 1: find the next key\n\t\tvar key []byte\n\n\t\t// Check what the the next token is: start of string, end of object, or something else (error)\n\t\tswitch data[offset] {\n\t\tcase '\"':\n\t\t\toffset++ // accept as string and skip opening quote\n\t\tcase '}':\n\t\t\treturn nil // we found the end of the object; stop and return success\n\t\tdefault:\n\t\t\treturn MalformedObjectError\n\t\t}\n\n\t\t// Find the end of the key string\n\t\tvar keyEscaped bool\n\t\tif off, esc := stringEnd(data[offset:]); off == -1 {\n\t\t\treturn MalformedJsonError\n\t\t} else {\n\t\t\tkey, keyEscaped = data[offset:offset+off-1], esc\n\t\t\toffset += off\n\t\t}\n\n\t\t// Unescape the string if needed\n\t\tif keyEscaped {\n\t\t\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\t\t\tif keyUnescaped, err := Unescape(key, stackbuf[:]); err != nil {\n\t\t\t\treturn MalformedStringEscapeError\n\t\t\t} else {\n\t\t\t\tkey = keyUnescaped\n\t\t\t}\n\t\t}\n\n\t\t// Step 2: skip the colon\n\t\tif off := nextToken(data[offset:]); off == -1 {\n\t\t\treturn MalformedJsonError\n\t\t} else if offset += off; data[offset] != ':' {\n\t\t\treturn MalformedJsonError\n\t\t} else {\n\t\t\toffset++\n\t\t}\n\n\t\t// Step 3: find the associated value, then invoke the callback\n\t\tif value, valueType, off, err := Get(data[offset:]); err != nil {\n\t\t\treturn err\n\t\t} else if err := callback(key, value, valueType, offset+off); err != nil { // Invoke the callback here!\n\t\t\treturn err\n\t\t} else {\n\t\t\toffset += off\n\t\t}\n\n\t\t// Step 4: skip over the next comma to the following token, or stop if we hit the ending brace\n\t\tif off := nextToken(data[offset:]); off == -1 {\n\t\t\treturn MalformedArrayError\n\t\t} else {\n\t\t\toffset += off\n\t\t\tswitch data[offset] {\n\t\t\tcase '}':\n\t\t\t\treturn nil // Stop if we hit the close brace\n\t\t\tcase ',':\n\t\t\t\toffset++ // Ignore the comma\n\t\t\tdefault:\n\t\t\t\treturn MalformedObjectError\n\t\t\t}\n\t\t}\n\n\t\t// Skip to the next token after the comma\n\t\tif off := nextToken(data[offset:]); off == -1 {\n\t\t\treturn MalformedArrayError\n\t\t} else {\n\t\t\toffset += off\n\t\t}\n\t}\n\n\treturn MalformedObjectError // we shouldn't get here; it's expected that we will return via finding the ending brace\n}\n\n// GetUnsafeString returns the value retrieved by `Get`, use creates string without memory allocation by mapping string to slice memory. It does not handle escape symbols.\nfunc GetUnsafeString(data []byte, keys ...string) (val string, err error) {\n\tv, _, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn \"\", e\n\t}\n\n\treturn bytesToString(&v), nil\n}\n\n// GetString returns the value retrieved by `Get`, cast to a string if possible, trying to properly handle escape and utf8 symbols\n// If key data type do not match, it will return an error.\nfunc GetString(data []byte, keys ...string) (val string, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn \"\", e\n\t}\n\n\tif t != String {\n\t\tif t == Null {\n\t\t\treturn \"\", NullValueError\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"Value is not a string: %s\", string(v))\n\t}\n\n\t// If no escapes return raw content\n\tif bytes.IndexByte(v, '\\\\') == -1 {\n\t\treturn string(v), nil\n\t}\n\n\treturn ParseString(v)\n}\n\n// GetFloat returns the value retrieved by `Get`, cast to a float64 if possible.\n// The offset is the same as in `Get`.\n// If key data type do not match, it will return an error.\nfunc GetFloat(data []byte, keys ...string) (val float64, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn 0, e\n\t}\n\n\tif t != Number {\n\t\tif t == Null {\n\t\t\treturn 0, NullValueError\n\t\t}\n\t\treturn 0, fmt.Errorf(\"Value is not a number: %s\", string(v))\n\t}\n\n\treturn ParseFloat(v)\n}\n\n// GetInt returns the value retrieved by `Get`, cast to a int64 if possible.\n// If key data type do not match, it will return an error.\nfunc GetInt(data []byte, keys ...string) (val int64, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn 0, e\n\t}\n\n\tif t != Number {\n\t\tif t == Null {\n\t\t\treturn 0, NullValueError\n\t\t}\n\t\treturn 0, fmt.Errorf(\"Value is not a number: %s\", string(v))\n\t}\n\n\treturn ParseInt(v)\n}\n\n// GetBoolean returns the value retrieved by `Get`, cast to a bool if possible.\n// The offset is the same as in `Get`.\n// If key data type do not match, it will return error.\nfunc GetBoolean(data []byte, keys ...string) (val bool, err error) {\n\tv, t, _, e := Get(data, keys...)\n\n\tif e != nil {\n\t\treturn false, e\n\t}\n\n\tif t != Boolean {\n\t\tif t == Null {\n\t\t\treturn false, NullValueError\n\t\t}\n\t\treturn false, fmt.Errorf(\"Value is not a boolean: %s\", string(v))\n\t}\n\n\treturn ParseBoolean(v)\n}\n\n// ParseBoolean parses a Boolean ValueType into a Go bool (not particularly useful, but here for completeness)\nfunc ParseBoolean(b []byte) (bool, error) {\n\tswitch {\n\tcase bytes.Equal(b, trueLiteral):\n\t\treturn true, nil\n\tcase bytes.Equal(b, falseLiteral):\n\t\treturn false, nil\n\tdefault:\n\t\treturn false, MalformedValueError\n\t}\n}\n\n// ParseString parses a String ValueType into a Go string (the main parsing work is unescaping the JSON string)\nfunc ParseString(b []byte) (string, error) {\n\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\tif bU, err := Unescape(b, stackbuf[:]); err != nil {\n\t\treturn \"\", MalformedValueError\n\t} else {\n\t\treturn string(bU), nil\n\t}\n}\n\n// ParseNumber parses a Number ValueType into a Go float64\nfunc ParseFloat(b []byte) (float64, error) {\n\tif v, err := parseFloat(&b); err != nil {\n\t\treturn 0, MalformedValueError\n\t} else {\n\t\treturn v, nil\n\t}\n}\n\n// ParseInt parses a Number ValueType into a Go int64\nfunc ParseInt(b []byte) (int64, error) {\n\tif v, ok, overflow := parseInt(b); !ok {\n\t\tif overflow {\n\t\t\treturn 0, OverflowIntegerError\n\t\t}\n\t\treturn 0, MalformedValueError\n\t} else {\n\t\treturn v, nil\n\t}\n}\n"
        },
        {
          "name": "parser_error_test.go",
          "type": "blob",
          "size": 3.931640625,
          "content": "package jsonparser\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"testing\"\n)\n\nvar testPaths = [][]string{\n\t[]string{\"test\"},\n\t[]string{\"these\"},\n\t[]string{\"keys\"},\n\t[]string{\"please\"},\n}\n\nfunc testIter(data []byte) (err error) {\n\tEachKey(data, func(idx int, value []byte, vt ValueType, iterErr error) {\n\t\tif iterErr != nil {\n\t\t\terr = fmt.Errorf(\"Error parsing json: %s\", iterErr.Error())\n\t\t}\n\t}, testPaths...)\n\treturn err\n}\n\nfunc TestPanickingErrors(t *testing.T) {\n\tif err := testIter([]byte(`{\"test\":`)); err == nil {\n\t\tt.Error(\"Expected error...\")\n\t}\n\n\tif err := testIter([]byte(`{\"test\":0}some\":[{\"these\":[{\"keys\":\"some\"}]}]}some\"}]}],\"please\":\"some\"}`)); err == nil {\n\t\tt.Error(\"Expected error...\")\n\t}\n\n\tif _, _, _, err := Get([]byte(`{\"test\":`), \"test\"); err == nil {\n\t\tt.Error(\"Expected error...\")\n\t}\n\n\tif _, _, _, err := Get([]byte(`{\"some\":0}some\":[{\"some\":[{\"some\":\"some\"}]}]}some\"}]}],\"some\":\"some\"}`), \"x\"); err == nil {\n\t\tt.Error(\"Expected error...\")\n\t}\n}\n\n// check having a very deep key depth\nfunc TestKeyDepth(t *testing.T) {\n\tvar sb strings.Builder\n\tvar keys []string\n\t//build data\n\tsb.WriteString(\"{\")\n\tfor i := 0; i < 128; i++ {\n\t\tfmt.Fprintf(&sb, `\"key%d\": %dx,`, i, i)\n\t\tkeys = append(keys, fmt.Sprintf(\"key%d\", i))\n\t}\n\tsb.WriteString(\"}\")\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys)\n}\n\n// check having a bunch of keys in a call to EachKey\nfunc TestKeyCount(t *testing.T) {\n\tvar sb strings.Builder\n\tvar keys [][]string\n\t//build data\n\tsb.WriteString(\"{\")\n\tfor i := 0; i < 128; i++ {\n\t\tfmt.Fprintf(&sb, `\"key%d\":\"%d\"`, i, i)\n\t\tif i < 127 {\n\t\t\tsb.WriteString(\",\")\n\t\t}\n\t\tkeys = append(keys, []string{fmt.Sprintf(\"key%d\", i)})\n\t}\n\tsb.WriteString(\"}\")\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys...)\n}\n\n// try pulling lots of keys out of a big array\nfunc TestKeyDepthArray(t *testing.T) {\n\tvar sb strings.Builder\n\tvar keys []string\n\t//build data\n\tsb.WriteString(\"[\")\n\tfor i := 0; i < 128; i++ {\n\t\tfmt.Fprintf(&sb, `{\"key\": %d},`, i)\n\t\tkeys = append(keys, fmt.Sprintf(\"[%d].key\", i))\n\t}\n\tsb.WriteString(\"]\")\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys)\n}\n\n// check having a bunch of keys\nfunc TestKeyCountArray(t *testing.T) {\n\tvar sb strings.Builder\n\tvar keys [][]string\n\t//build data\n\tsb.WriteString(\"[\")\n\tfor i := 0; i < 128; i++ {\n\t\tfmt.Fprintf(&sb, `{\"key\":\"%d\"}`, i)\n\t\tif i < 127 {\n\t\t\tsb.WriteString(\",\")\n\t\t}\n\t\tkeys = append(keys, []string{fmt.Sprintf(\"[%d].key\", i)})\n\t}\n\tsb.WriteString(\"]\")\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys...)\n}\n\n// check having a bunch of keys in a super deep array\nfunc TestEachKeyArray(t *testing.T) {\n\tvar sb strings.Builder\n\tvar keys [][]string\n\t//build data\n\tsb.WriteString(`[`)\n\tfor i := 0; i < 127; i++ {\n\t\tfmt.Fprintf(&sb, `%d`, i)\n\t\tif i < 127 {\n\t\t\tsb.WriteString(\",\")\n\t\t}\n\t\tif i < 32 {\n\t\t\tkeys = append(keys, []string{fmt.Sprintf(\"[%d]\", 128+i)})\n\t\t}\n\t}\n\tsb.WriteString(`]`)\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys...)\n}\n\nfunc TestLargeArray(t *testing.T) {\n\tvar sb strings.Builder\n\t//build data\n\tsb.WriteString(`[`)\n\tfor i := 0; i < 127; i++ {\n\t\tfmt.Fprintf(&sb, `%d`, i)\n\t\tif i < 127 {\n\t\t\tsb.WriteString(\",\")\n\t\t}\n\t}\n\tsb.WriteString(`]`)\n\tkeys := [][]string{[]string{`[1]`}}\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys...)\n}\n\nfunc TestArrayOutOfBounds(t *testing.T) {\n\tvar sb strings.Builder\n\t//build data\n\tsb.WriteString(`[`)\n\tfor i := 0; i < 61; i++ {\n\t\tfmt.Fprintf(&sb, `%d`, i)\n\t\tif i < 61 {\n\t\t\tsb.WriteString(\",\")\n\t\t}\n\t}\n\tsb.WriteString(`]`)\n\tkeys := [][]string{[]string{`[128]`}}\n\n\tdata := []byte(sb.String())\n\tEachKey(data, func(offset int, value []byte, dt ValueType, err error) {\n\t\treturn\n\t}, keys...)\n}\n"
        },
        {
          "name": "parser_test.go",
          "type": "blob",
          "size": 48.15234375,
          "content": "package jsonparser\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t_ \"fmt\"\n\t\"reflect\"\n\t\"testing\"\n)\n\n// Set it to non-empty value if want to run only specific test\nvar activeTest = \"\"\n\nfunc toArray(data []byte) (result [][]byte) {\n\tArrayEach(data, func(value []byte, dataType ValueType, offset int, err error) {\n\t\tresult = append(result, value)\n\t})\n\n\treturn\n}\n\nfunc toStringArray(data []byte) (result []string) {\n\tArrayEach(data, func(value []byte, dataType ValueType, offset int, err error) {\n\t\tresult = append(result, string(value))\n\t})\n\n\treturn\n}\n\ntype GetTest struct {\n\tdesc string\n\tjson string\n\tpath []string\n\n\tisErr   bool\n\tisFound bool\n\n\tdata interface{}\n}\n\ntype SetTest struct {\n\tdesc    string\n\tjson    string\n\tsetData string\n\tpath    []string\n\n\tisErr   bool\n\tisFound bool\n\n\tdata interface{}\n}\n\ntype DeleteTest struct {\n\tdesc string\n\tjson string\n\tpath []string\n\n\tdata interface{}\n}\n\nvar deleteTests = []DeleteTest{\n\t{\n\t\tdesc: \"Delete test key\",\n\t\tjson: `{\"test\":\"input\"}`,\n\t\tpath: []string{\"test\"},\n\t\tdata: `{}`,\n\t},\n\t{\n\t\tdesc: \"Delete object\",\n\t\tjson: `{\"test\":\"input\"}`,\n\t\tpath: []string{},\n\t\tdata: ``,\n\t},\n\t{\n\t\tdesc: \"Delete a nested object\",\n\t\tjson: `{\"test\":\"input\",\"new.field\":{\"key\": \"new object\"}}`,\n\t\tpath: []string{\"new.field\", \"key\"},\n\t\tdata: `{\"test\":\"input\",\"new.field\":{}}`,\n\t},\n\t{\n\t\tdesc: \"Deleting a key that doesn't exist should return the same object\",\n\t\tjson: `{\"test\":\"input\"}`,\n\t\tpath: []string{\"test2\"},\n\t\tdata: `{\"test\":\"input\"}`,\n\t},\n\t{\n\t\tdesc: \"Delete object in an array\",\n\t\tjson: `{\"test\":[{\"key\":\"val-obj1\"}]}`,\n\t\tpath: []string{\"test\", \"[0]\"},\n\t\tdata: `{\"test\":[]}`,\n\t},\n\t{\n\t\tdesc: \"Deleting a object in an array that doesn't exists should return the same object\",\n\t\tjson: `{\"test\":[{\"key\":\"val-obj1\"}]}`,\n\t\tpath: []string{\"test\", \"[1]\"},\n\t\tdata: `{\"test\":[{\"key\":\"val-obj1\"}]}`,\n\t},\n\t{\n\t\tdesc: \"Delete a complex object in a nested array\",\n\t\tjson: `{\"test\":[{\"key\":[{\"innerKey\":\"innerKeyValue\"}]}]}`,\n\t\tpath: []string{\"test\", \"[0]\", \"key\", \"[0]\"},\n\t\tdata: `{\"test\":[{\"key\":[]}]}`,\n\t},\n\t{\n\t\tdesc: \"Delete known key (simple type within nested array)\",\n\t\tjson: `{\"test\":[{\"key\":[\"innerKey\"]}]}`,\n\t\tpath: []string{\"test\", \"[0]\", \"key\", \"[0]\"},\n\t\tdata: `{\"test\":[{\"key\":[]}]}`,\n\t},\n\t{\n\t\tdesc: \"Delete in empty json\",\n\t\tjson: `{}`,\n\t\tpath: []string{},\n\t\tdata: ``,\n\t},\n\t{\n\t\tdesc: \"Delete empty array\",\n\t\tjson: `[]`,\n\t\tpath: []string{},\n\t\tdata: ``,\n\t},\n\t{\n\t\tdesc: \"Deleting non json should return the same value\",\n\t\tjson: `1.323`,\n\t\tpath: []string{\"foo\"},\n\t\tdata: `1.323`,\n\t},\n\t{\n\t\tdesc: \"Delete known key (top level array)\",\n\t\tjson: `[{\"key\":\"val-obj1\"}]`,\n\t\tpath: []string{\"[0]\"},\n\t\tdata: `[]`,\n\t},\n\t{ // This test deletes the key instead of returning a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc: `malformed with trailing whitespace`,\n\t\tjson: `{\"a\":1 `,\n\t\tpath: []string{\"a\"},\n\t\tdata: `{ `,\n\t},\n\t{ // This test dels the key instead of returning a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc: \"malformed 'colon chain', delete b\",\n\t\tjson: `{\"a\":\"b\":\"c\"}`,\n\t\tpath: []string{\"b\"},\n\t\tdata: `{\"a\":}`,\n\t},\n\t{\n\t\tdesc: \"Delete object without inner array\",\n\t\tjson: `{\"a\": {\"b\": 1}, \"b\": 2}`,\n\t\tpath: []string{\"b\"},\n\t\tdata: `{\"a\": {\"b\": 1}}`,\n\t},\n\t{\n\t\tdesc: \"Delete object without inner array\",\n\t\tjson: `{\"a\": [{\"b\": 1}], \"b\": 2}`,\n\t\tpath: []string{\"b\"},\n\t\tdata: `{\"a\": [{\"b\": 1}]}`,\n\t},\n\t{\n\t\tdesc: \"Delete object without inner array\",\n\t\tjson: `{\"a\": {\"c\": {\"b\": 3}, \"b\": 1}, \"b\": 2}`,\n\t\tpath: []string{\"a\", \"b\"},\n\t\tdata: `{\"a\": {\"c\": {\"b\": 3}}, \"b\": 2}`,\n\t},\n\t{\n\t\tdesc: \"Delete object without inner array\",\n\t\tjson: `{\"a\": [{\"c\": {\"b\": 3}, \"b\": 1}], \"b\": 2}`,\n\t\tpath: []string{\"a\", \"[0]\", \"b\"},\n\t\tdata: `{\"a\": [{\"c\": {\"b\": 3}}], \"b\": 2}`,\n\t},\n\t{\n\t\tdesc: \"Remove trailing comma if last object is deleted\",\n\t\tjson: `{\"a\": \"1\", \"b\": \"2\"}`,\n\t\tpath: []string{\"b\"},\n\t\tdata: `{\"a\": \"1\"}`,\n\t},\n\t{\n\t\tdesc: \"Correctly delete first element with space-comma\",\n\t\tjson: `{\"a\": \"1\" ,\"b\": \"2\" }`,\n\t\tpath: []string{\"a\"},\n\t\tdata: `{\"b\": \"2\" }`,\n\t},\n\t{\n\t\tdesc: \"Correctly delete middle element with space-comma\",\n\t\tjson: `{\"a\": \"1\" ,\"b\": \"2\" , \"c\": 3}`,\n\t\tpath: []string{\"b\"},\n\t\tdata: `{\"a\": \"1\" , \"c\": 3}`,\n\t},\n\t{\n\t\tdesc: \"Delete non-last key\",\n\t\tjson: `{\"test\":\"input\",\"test1\":\"input1\"}`,\n\t\tpath: []string{\"test\"},\n\t\tdata: `{\"test1\":\"input1\"}`,\n\t},\n\t{\n\t\tdesc: \"Delete non-exist key\",\n\t\tjson: `{\"test:\":\"input\"}`,\n\t\tpath: []string{\"test\", \"test1\"},\n\t\tdata: `{\"test:\":\"input\"}`,\n\t},\n\t{\n\t\tdesc: \"Delete non-last object in an array\",\n\t\tjson: `[{\"key\":\"val-obj1\"},{\"key2\":\"val-obj2\"}]`,\n\t\tpath: []string{\"[0]\"},\n\t\tdata: `[{\"key2\":\"val-obj2\"}]`,\n\t},\n\t{\n\t\tdesc: \"Delete non-first object in an array\",\n\t\tjson: `[{\"key\":\"val-obj1\"},{\"key2\":\"val-obj2\"}]`,\n\t\tpath: []string{\"[1]\"},\n\t\tdata: `[{\"key\":\"val-obj1\"}]`,\n\t},\n\t{\n\t\tdesc: \"Issue #188: infinite loop in Delete\",\n\t\tjson: `^_ï¿½^C^A^@[`,\n\t\tpath: []string{\"\"},\n\t\tdata: `^_ï¿½^C^A^@[`,\n\t},\n\t{\n\t\tdesc: \"Issue #188: infinite loop in Delete\",\n\t\tjson: `^_ï¿½^C^A^@{`,\n\t\tpath: []string{\"\"},\n\t\tdata: `^_ï¿½^C^A^@{`,\n\t},\n\t{\n\t\tdesc: \"Issue #150: leading space\",\n\t\tjson: `   {\"test\":\"input\"}`,\n\t\tpath: []string{\"test\"},\n\t\tdata: `   {}`,\n\t},\n}\n\nvar setTests = []SetTest{\n\t{\n\t\tdesc:    \"set unknown key (string)\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"new.field\"},\n\t\tsetData: `\"new value\"`,\n\t\tdata:    `{\"test\":\"input\",\"new.field\":\"new value\"}`,\n\t},\n\t{\n\t\tdesc:    \"set known key (string)\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\"},\n\t\tsetData: `\"new value\"`,\n\t\tdata:    `{\"test\":\"new value\"}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (object)\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"new.field\"},\n\t\tsetData: `{\"key\": \"new object\"}`,\n\t\tdata:    `{\"test\":\"input\",\"new.field\":{\"key\": \"new object\"}}`,\n\t},\n\t{\n\t\tdesc:    \"set known key (object)\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\"},\n\t\tsetData: `{\"key\": \"new object\"}`,\n\t\tdata:    `{\"test\":{\"key\": \"new object\"}}`,\n\t},\n\t{\n\t\tdesc:    \"set known key (object within array)\",\n\t\tjson:    `{\"test\":[{\"key\":\"val-obj1\"}]}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"[0]\"},\n\t\tsetData: `{\"key\":\"new object\"}`,\n\t\tdata:    `{\"test\":[{\"key\":\"new object\"}]}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (replace object)\",\n\t\tjson:    `{\"test\":[{\"key\":\"val-obj1\"}]}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"newKey\"},\n\t\tsetData: `\"new object\"`,\n\t\tdata:    `{\"test\":{\"newKey\":\"new object\"}}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (complex object within nested array)\",\n\t\tjson:    `{\"test\":[{\"key\":[{\"innerKey\":\"innerKeyValue\"}]}]}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"[0]\", \"key\", \"[0]\", \"newInnerKey\"},\n\t\tsetData: `{\"key\":\"new object\"}`,\n\t\tdata:    `{\"test\":[{\"key\":[{\"innerKey\":\"innerKeyValue\",\"newInnerKey\":{\"key\":\"new object\"}}]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set known key (complex object within nested array)\",\n\t\tjson:    `{\"test\":[{\"key\":[{\"innerKey\":\"innerKeyValue\"}]}]}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"[0]\", \"key\", \"[0]\", \"innerKey\"},\n\t\tsetData: `{\"key\":\"new object\"}`,\n\t\tdata:    `{\"test\":[{\"key\":[{\"innerKey\":{\"key\":\"new object\"}}]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (object, partial subtree exists)\",\n\t\tjson:    `{\"test\":{\"input\":\"output\"}}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"new.field\"},\n\t\tsetData: `{\"key\":\"new object\"}`,\n\t\tdata:    `{\"test\":{\"input\":\"output\",\"new.field\":{\"key\":\"new object\"}}}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (object, empty partial subtree exists)\",\n\t\tjson:    `{\"test\":{}}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"new.field\"},\n\t\tsetData: `{\"key\":\"new object\"}`,\n\t\tdata:    `{\"test\":{\"new.field\":{\"key\":\"new object\"}}}`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (object, no subtree exists)\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"new.field\", \"nested\", \"value\"},\n\t\tsetData: `{\"key\": \"new object\"}`,\n\t\tdata:    `{\"test\":\"input\",\"new.field\":{\"nested\":{\"value\":{\"key\": \"new object\"}}}}`,\n\t},\n\t{\n\t\tdesc:    \"set in empty json\",\n\t\tjson:    `{}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"foo\"},\n\t\tsetData: `\"null\"`,\n\t\tdata:    `{\"foo\":\"null\"}`,\n\t},\n\t{\n\t\tdesc:    \"set subtree in empty json\",\n\t\tjson:    `{}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"foo\", \"bar\"},\n\t\tsetData: `\"null\"`,\n\t\tdata:    `{\"foo\":{\"bar\":\"null\"}}`,\n\t},\n\t{\n\t\tdesc:    \"set in empty string - not found\",\n\t\tjson:    ``,\n\t\tisFound: false,\n\t\tpath:    []string{\"foo\"},\n\t\tsetData: `\"null\"`,\n\t\tdata:    ``,\n\t},\n\t{\n\t\tdesc:    \"set in Number - not found\",\n\t\tjson:    `1.323`,\n\t\tisFound: false,\n\t\tpath:    []string{\"foo\"},\n\t\tsetData: `\"null\"`,\n\t\tdata:    `1.323`,\n\t},\n\t{\n\t\tdesc:    \"set known key (top level array)\",\n\t\tjson:    `[{\"key\":\"val-obj1\"}]`,\n\t\tisFound: true,\n\t\tpath:    []string{\"[0]\", \"key\"},\n\t\tsetData: `\"new object\"`,\n\t\tdata:    `[{\"key\":\"new object\"}]`,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (trailing whitespace)\",\n\t\tjson:    `{\"key\":\"val-obj1\"}  `,\n\t\tisFound: true,\n\t\tpath:    []string{\"alt-key\"},\n\t\tsetData: `\"new object\"`,\n\t\tdata:    `{\"key\":\"val-obj1\",\"alt-key\":\"new object\"}  `,\n\t},\n\t{ // This test sets the key instead of returning a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc:    `malformed with trailing whitespace`,\n\t\tjson:    `{\"a\":1 `,\n\t\tpath:    []string{\"a\"},\n\t\tsetData: `2`,\n\t\tisFound: true,\n\t\tdata:    `{\"a\":2 `,\n\t},\n\t{ // This test sets the key instead of returning a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc:    \"malformed 'colon chain', set second string\",\n\t\tjson:    `{\"a\":\"b\":\"c\"}`,\n\t\tpath:    []string{\"b\"},\n\t\tsetData: `\"d\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"a\":\"b\":\"d\"}`,\n\t},\n\t{\n\t\tdesc:    \"set indexed path to object on empty JSON\",\n\t\tjson:    `{}`,\n\t\tpath:    []string{\"top\", \"[0]\", \"middle\", \"[0]\", \"bottom\"},\n\t\tsetData: `\"value\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"top\":[{\"middle\":[{\"bottom\":\"value\"}]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set indexed path on existing object with object\",\n\t\tjson:    `{\"top\":[{\"middle\":[]}]}`,\n\t\tpath:    []string{\"top\", \"[0]\", \"middle\", \"[0]\", \"bottom\"},\n\t\tsetData: `\"value\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"top\":[{\"middle\":[{\"bottom\":\"value\"}]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set indexed path on existing object with value\",\n\t\tjson:    `{\"top\":[{\"middle\":[]}]}`,\n\t\tpath:    []string{\"top\", \"[0]\", \"middle\", \"[0]\"},\n\t\tsetData: `\"value\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"top\":[{\"middle\":[\"value\"]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set indexed path on empty object with value\",\n\t\tjson:    `{}`,\n\t\tpath:    []string{\"top\", \"[0]\", \"middle\", \"[0]\"},\n\t\tsetData: `\"value\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"top\":[{\"middle\":[\"value\"]}]}`,\n\t},\n\t{\n\t\tdesc:    \"set indexed path on object with existing array\",\n\t\tjson:    `{\"top\":[\"one\", \"two\", \"three\"]}`,\n\t\tpath:    []string{\"top\", \"[2]\"},\n\t\tsetData: `\"value\"`,\n\t\tisFound: true,\n\t\tdata:    `{\"top\":[\"one\", \"two\", \"value\"]}`,\n\t},\n\t{\n\t\tdesc:    \"set non-exist key\",\n\t\tjson:    `{\"test\":\"input\"}`,\n\t\tsetData: `\"new value\"`,\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"set key in invalid json\",\n\t\tjson:    `{\"test\"::\"input\"}`,\n\t\tpath:    []string{\"test\"},\n\t\tsetData: \"new value\",\n\t\tisErr:   true,\n\t},\n\t{\n\t\tdesc:    \"set unknown key (simple object within nested array)\",\n\t\tjson:    `{\"test\":{\"key\":[{\"innerKey\":\"innerKeyValue\", \"innerKey2\":\"innerKeyValue2\"}]}}`,\n\t\tisFound: true,\n\t\tpath:    []string{\"test\", \"key\", \"[1]\", \"newInnerKey\"},\n\t\tsetData: `\"new object\"`,\n\t\tdata:    `{\"test\":{\"key\":[{\"innerKey\":\"innerKeyValue\", \"innerKey2\":\"innerKeyValue2\"},{\"newInnerKey\":\"new object\"}]}}`,\n\t},\n}\n\nvar getTests = []GetTest{\n\t// Trivial tests\n\t{\n\t\tdesc:    \"read string\",\n\t\tjson:    `\"\"`,\n\t\tisFound: true,\n\t\tdata:    ``,\n\t},\n\t{\n\t\tdesc:    \"read number\",\n\t\tjson:    `0`,\n\t\tisFound: true,\n\t\tdata:    `0`,\n\t},\n\t{\n\t\tdesc:    \"read object\",\n\t\tjson:    `{}`,\n\t\tisFound: true,\n\t\tdata:    `{}`,\n\t},\n\t{\n\t\tdesc:    \"read array\",\n\t\tjson:    `[]`,\n\t\tisFound: true,\n\t\tdata:    `[]`,\n\t},\n\t{\n\t\tdesc:    \"read boolean\",\n\t\tjson:    `true`,\n\t\tisFound: true,\n\t\tdata:    `true`,\n\t},\n\n\t// Found key tests\n\t{\n\t\tdesc:    \"handling multiple nested keys with same name\",\n\t\tjson:    `{\"a\":[{\"b\":1},{\"b\":2},3],\"c\":{\"c\":[1,2]}} }`,\n\t\tpath:    []string{\"c\", \"c\"},\n\t\tisFound: true,\n\t\tdata:    `[1,2]`,\n\t},\n\t{\n\t\tdesc:    \"read basic key\",\n\t\tjson:    `{\"a\":\"b\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `b`,\n\t},\n\t{\n\t\tdesc:    \"read basic key with space\",\n\t\tjson:    `{\"a\": \"b\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `b`,\n\t},\n\t{\n\t\tdesc:    \"read composite key\",\n\t\tjson:    `{\"a\": { \"b\":{\"c\":\"d\" }}}`,\n\t\tpath:    []string{\"a\", \"b\", \"c\"},\n\t\tisFound: true,\n\t\tdata:    `d`,\n\t},\n\t{\n\t\tdesc:    `read numberic value as string`,\n\t\tjson:    `{\"a\": \"b\", \"c\": 1}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{\n\t\tdesc:    `handle multiple nested keys with same name`,\n\t\tjson:    `{\"a\":[{\"b\":1},{\"b\":2},3],\"c\":{\"c\":[1,2]}} }`,\n\t\tpath:    []string{\"c\", \"c\"},\n\t\tisFound: true,\n\t\tdata:    `[1,2]`,\n\t},\n\t{\n\t\tdesc:    `read string values with quotes`,\n\t\tjson:    `{\"a\": \"string\\\"with\\\"quotes\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `string\\\"with\\\"quotes`,\n\t},\n\t{\n\t\tdesc:    `read object`,\n\t\tjson:    `{\"a\": { \"b\":{\"c\":\"d\" }}}`,\n\t\tpath:    []string{\"a\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    `{\"c\":\"d\" }`,\n\t},\n\t{\n\t\tdesc:    `empty path`,\n\t\tjson:    `{\"c\":\"d\" }`,\n\t\tpath:    []string{},\n\t\tisFound: true,\n\t\tdata:    `{\"c\":\"d\" }`,\n\t},\n\t{\n\t\tdesc:    `formatted JSON value`,\n\t\tjson:    \"{\\n  \\\"a\\\": \\\"b\\\"\\n}\",\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `b`,\n\t},\n\t{\n\t\tdesc:    `formatted JSON value 2`,\n\t\tjson:    \"{\\n  \\\"a\\\":\\n    {\\n\\\"b\\\":\\n   {\\\"c\\\":\\\"d\\\",\\n\\\"e\\\": \\\"f\\\"}\\n}\\n}\",\n\t\tpath:    []string{\"a\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    \"{\\\"c\\\":\\\"d\\\",\\n\\\"e\\\": \\\"f\\\"}\",\n\t},\n\t{\n\t\tdesc:    `whitespace`,\n\t\tjson:    \" \\n\\r\\t{ \\n\\r\\t\\\"whitespace\\\" \\n\\r\\t: \\n\\r\\t333 \\n\\r\\t} \\n\\r\\t\",\n\t\tpath:    []string{\"whitespace\"},\n\t\tisFound: true,\n\t\tdata:    \"333\",\n\t},\n\t{\n\t\tdesc:    `escaped backslash quote`,\n\t\tjson:    `{\"a\": \"\\\\\\\"\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `\\\\\\\"`,\n\t},\n\t{\n\t\tdesc:    `unescaped backslash quote`,\n\t\tjson:    `{\"a\": \"\\\\\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `\\\\`,\n\t},\n\t{\n\t\tdesc:    `unicode in JSON`,\n\t\tjson:    `{\"a\": \"15°C\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `15°C`,\n\t},\n\t{\n\t\tdesc:    `no padding + nested`,\n\t\tjson:    `{\"a\":{\"a\":\"1\"},\"b\":2}`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: true,\n\t\tdata:    `2`,\n\t},\n\t{\n\t\tdesc:    `no padding + nested + array`,\n\t\tjson:    `{\"a\":{\"b\":[1,2]},\"c\":3}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `3`,\n\t},\n\t{\n\t\tdesc:    `empty key`,\n\t\tjson:    `{\"\":{\"\":{\"\":true}}}`,\n\t\tpath:    []string{\"\", \"\", \"\"},\n\t\tisFound: true,\n\t\tdata:    `true`,\n\t},\n\n\t// Escaped key tests\n\t{\n\t\tdesc:    `key with simple escape`,\n\t\tjson:    `{\"a\\\\b\":1}`,\n\t\tpath:    []string{\"a\\\\b\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{\n\t\tdesc:    `key and value with whitespace escapes`,\n\t\tjson:    `{\"key\\b\\f\\n\\r\\tkey\":\"value\\b\\f\\n\\r\\tvalue\"}`,\n\t\tpath:    []string{\"key\\b\\f\\n\\r\\tkey\"},\n\t\tisFound: true,\n\t\tdata:    `value\\b\\f\\n\\r\\tvalue`, // value is not unescaped since this is Get(), but the key should work correctly\n\t},\n\t{\n\t\tdesc:    `key with Unicode escape`,\n\t\tjson:    `{\"a\\u00B0b\":1}`,\n\t\tpath:    []string{\"a\\u00B0b\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{\n\t\tdesc:    `key with complex escape`,\n\t\tjson:    `{\"a\\uD83D\\uDE03b\":1}`,\n\t\tpath:    []string{\"a\\U0001F603b\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\n\t{ // This test returns a match instead of a parse error, as checking for the malformed JSON would reduce performance\n\t\tdesc:    `malformed with trailing whitespace`,\n\t\tjson:    `{\"a\":1 `,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{ // This test returns a match instead of a parse error, as checking for the malformed JSON would reduce performance\n\t\tdesc:    `malformed with wrong closing bracket`,\n\t\tjson:    `{\"a\":1]`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\n\t// Not found key tests\n\t{\n\t\tdesc:    `empty input`,\n\t\tjson:    ``,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"non-existent key 1\",\n\t\tjson:    `{\"a\":\"b\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"non-existent key 2\",\n\t\tjson:    `{\"a\":\"b\"}`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"non-existent key 3\",\n\t\tjson:    `{\"aa\":\"b\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"apply scope of parent when search for nested key\",\n\t\tjson:    `{\"a\": { \"b\": 1}, \"c\": 2 }`,\n\t\tpath:    []string{\"a\", \"b\", \"c\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    `apply scope to key level`,\n\t\tjson:    `{\"a\": { \"b\": 1}, \"c\": 2 }`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    `handle escaped quote in key name in JSON`,\n\t\tjson:    `{\"key\\\"key\": 1}`,\n\t\tpath:    []string{\"key\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"handling multiple keys with different name\",\n\t\tjson:    `{\"a\":{\"a\":1},\"b\":{\"a\":3,\"c\":[1,2]}}`,\n\t\tpath:    []string{\"a\", \"c\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    \"handling nested json\",\n\t\tjson:    `{\"a\":{\"b\":{\"c\":1},\"d\":4}}`,\n\t\tpath:    []string{\"a\", \"d\"},\n\t\tisFound: true,\n\t\tdata:    `4`,\n\t},\n\t{ // Issue #148\n\t\tdesc:    `missing key in different key same level`,\n\t\tjson:    `{\"s\":\"s\",\"ic\":2,\"r\":{\"o\":\"invalid\"}}`,\n\t\tpath:    []string{\"ic\", \"o\"},\n\t\tisFound: false,\n\t},\n\n\t// Error/invalid tests\n\t{\n\t\tdesc:    `handle escaped quote in key name in JSON`,\n\t\tjson:    `{\"key\\\"key\": 1}`,\n\t\tpath:    []string{\"key\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    `missing closing brace, but can still find key`,\n\t\tjson:    `{\"a\":\"b\"`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    `b`,\n\t},\n\t{\n\t\tdesc:  `missing value closing quote`,\n\t\tjson:  `{\"a\":\"b`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `missing value closing curly brace`,\n\t\tjson:  `{\"a\": { \"b\": \"c\"`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `missing value closing square bracket`,\n\t\tjson:  `{\"a\": [1, 2, 3 }`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `missing value 1`,\n\t\tjson:  `{\"a\":`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `missing value 2`,\n\t\tjson:  `{\"a\": `,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `missing value 3`,\n\t\tjson:  `{\"a\":}`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:    `malformed array (no closing brace)`,\n\t\tjson:    `{\"a\":[, \"b\":123}`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: false,\n\t},\n\t{ // Issue #81\n\t\tdesc:    `missing key in object in array`,\n\t\tjson:    `{\"p\":{\"a\":[{\"u\":\"abc\",\"t\":\"th\"}]}}`,\n\t\tpath:    []string{\"p\", \"a\", \"[0]\", \"x\"},\n\t\tisFound: false,\n\t},\n\t{ // Issue #81 counter test\n\t\tdesc:    `existing key in object in array`,\n\t\tjson:    `{\"p\":{\"a\":[{\"u\":\"abc\",\"t\":\"th\"}]}}`,\n\t\tpath:    []string{\"p\", \"a\", \"[0]\", \"u\"},\n\t\tisFound: true,\n\t\tdata:    \"abc\",\n\t},\n\t{ // This test returns not found instead of a parse error, as checking for the malformed JSON would reduce performance\n\t\tdesc:    \"malformed key (followed by comma followed by colon)\",\n\t\tjson:    `{\"a\",:1}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: false,\n\t},\n\t{ // This test returns a match instead of a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc:    \"malformed 'colon chain', lookup first string\",\n\t\tjson:    `{\"a\":\"b\":\"c\"}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    \"b\",\n\t},\n\t{ // This test returns a match instead of a parse error, as checking for the malformed JSON would reduce performance (this is not ideal)\n\t\tdesc:    \"malformed 'colon chain', lookup second string\",\n\t\tjson:    `{\"a\":\"b\":\"c\"}`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: true,\n\t\tdata:    \"c\",\n\t},\n\t// Array index paths\n\t{\n\t\tdesc:    \"last key in path is index\",\n\t\tjson:    `{\"a\":[{\"b\":1},{\"b\":\"2\"}, 3],\"c\":{\"c\":[1,2]}}`,\n\t\tpath:    []string{\"a\", \"[1]\"},\n\t\tisFound: true,\n\t\tdata:    `{\"b\":\"2\"}`,\n\t},\n\t{\n\t\tdesc:    \"get string from array\",\n\t\tjson:    `{\"a\":[{\"b\":1},\"foo\", 3],\"c\":{\"c\":[1,2]}}`,\n\t\tpath:    []string{\"a\", \"[1]\"},\n\t\tisFound: true,\n\t\tdata:    \"foo\",\n\t},\n\t{\n\t\tdesc:    \"key in path is index\",\n\t\tjson:    `{\"a\":[{\"b\":\"1\"},{\"b\":\"2\"},3],\"c\":{\"c\":[1,2]}}`,\n\t\tpath:    []string{\"a\", \"[0]\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{\n\t\tdesc: \"last key in path is an index to value in array (formatted json)\",\n\t\tjson: `{\n\t\t    \"a\": [\n\t\t\t{\n\t\t\t    \"b\": 1\n\t\t\t},\n\t\t\t{\"b\":\"2\"},\n\t\t\t3\n\t\t    ],\n\t\t    \"c\": {\n\t\t\t\"c\": [\n\t\t\t    1,\n\t\t\t    2\n\t\t\t]\n\t\t    }\n\t\t}`,\n\t\tpath:    []string{\"a\", \"[1]\"},\n\t\tisFound: true,\n\t\tdata:    `{\"b\":\"2\"}`,\n\t},\n\t{\n\t\tdesc: \"key in path is index (formatted json)\",\n\t\tjson: `{\n\t\t    \"a\": [\n\t\t\t{\"b\": 1},\n\t\t\t{\"b\": \"2\"},\n\t\t\t3\n\t\t    ],\n\t\t    \"c\": {\n\t\t\t\"c\": [\n\t\t\t    1,\n\t\t\t    2\n\t\t\t]\n\t\t    }\n\t\t}`,\n\t\tpath:    []string{\"a\", \"[0]\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    `1`,\n\t},\n\t{\n\t\t// Issue #178: Crash in searchKeys\n\t\tdesc:    `invalid json`,\n\t\tjson:    `{{{\"\":`,\n\t\tpath:    []string{\"a\", \"b\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    `opening brace instead of closing and without key`,\n\t\tjson:    `{\"a\":1{`,\n\t\tpath:    []string{\"b\"},\n\t\tisFound: false,\n\t},\n}\n\nvar getIntTests = []GetTest{\n\t{\n\t\tdesc:    `read numeric value as number`,\n\t\tjson:    `{\"a\": \"b\", \"c\": 1}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    int64(1),\n\t},\n\t{\n\t\tdesc:    `read numeric value as number in formatted JSON`,\n\t\tjson:    \"{\\\"a\\\": \\\"b\\\", \\\"c\\\": 1 \\n}\",\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    int64(1),\n\t},\n\t{ // Issue #138: overflow detection\n\t\tdesc:  `Fails because of overflow`,\n\t\tjson:  `{\"p\":9223372036854775808}`,\n\t\tpath:  []string{\"p\"},\n\t\tisErr: true,\n\t},\n\t{ // Issue #138: overflow detection\n\t\tdesc:  `Fails because of underflow`,\n\t\tjson:  `{\"p\":-9223372036854775809}`,\n\t\tpath:  []string{\"p\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `read non-numeric value as integer`,\n\t\tjson:  `{\"a\": \"b\", \"c\": \"d\"}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `null test`,\n\t\tjson:  `{\"a\": \"b\", \"c\": null}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n}\n\nvar getFloatTests = []GetTest{\n\t{\n\t\tdesc:    `read numeric value as number`,\n\t\tjson:    `{\"a\": \"b\", \"c\": 1.123}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    float64(1.123),\n\t},\n\t{\n\t\tdesc:    `read numeric value as number in formatted JSON`,\n\t\tjson:    \"{\\\"a\\\": \\\"b\\\", \\\"c\\\": 23.41323 \\n}\",\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    float64(23.41323),\n\t},\n\t{\n\t\tdesc:  `read non-numeric value as float`,\n\t\tjson:  `{\"a\": \"b\", \"c\": \"d\"}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `null test`,\n\t\tjson:  `{\"a\": \"b\", \"c\": null}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n}\n\nvar getStringTests = []GetTest{\n\t{\n\t\tdesc:    `Translate Unicode symbols`,\n\t\tjson:    `{\"c\": \"test\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `test`,\n\t},\n\t{\n\t\tdesc:    `Translate Unicode symbols`,\n\t\tjson:    `{\"c\": \"15\\u00b0C\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `15°C`,\n\t},\n\t{\n\t\tdesc:    `Translate supplementary Unicode symbols`,\n\t\tjson:    `{\"c\": \"\\uD83D\\uDE03\"}`, // Smiley face (UTF16 surrogate pair)\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    \"\\U0001F603\", // Smiley face\n\t},\n\t{\n\t\tdesc:    `Translate escape symbols`,\n\t\tjson:    `{\"c\": \"\\\\\\\"\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `\\\"`,\n\t},\n\t{\n\t\tdesc:    `key and value with whitespace escapes`,\n\t\tjson:    `{\"key\\b\\f\\n\\r\\tkey\":\"value\\b\\f\\n\\r\\tvalue\"}`,\n\t\tpath:    []string{\"key\\b\\f\\n\\r\\tkey\"},\n\t\tisFound: true,\n\t\tdata:    \"value\\b\\f\\n\\r\\tvalue\", // value is unescaped since this is GetString()\n\t},\n\t{ // This test checks we avoid an infinite loop for certain malformed JSON. We don't check for all malformed JSON as it would reduce performance.\n\t\tdesc:    `malformed with double quotes`,\n\t\tjson:    `{\"a\"\":1}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: false,\n\t\tdata:    ``,\n\t},\n\t{ // More malformed JSON testing, to be sure we avoid an infinite loop.\n\t\tdesc:    `malformed with double quotes, and path does not exist`,\n\t\tjson:    `{\"z\":123,\"y\":{\"x\":7,\"w\":0},\"v\":{\"u\":\"t\",\"s\":\"r\",\"q\":0,\"p\":1558051800},\"a\":\"b\",\"c\":\"2016-11-02T20:10:11Z\",\"d\":\"e\",\"f\":\"g\",\"h\":{\"i\":\"j\"\"},\"k\":{\"l\":\"m\"}}`,\n\t\tpath:    []string{\"o\"},\n\t\tisFound: false,\n\t\tdata:    ``,\n\t},\n\t{\n\t\tdesc:  `read non-string as string`,\n\t\tjson:  `{\"c\": true}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:    `empty array index`,\n\t\tjson:    `[\"\"]`,\n\t\tpath:    []string{\"[]\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:    `malformed array index`,\n\t\tjson:    `[\"\"]`,\n\t\tpath:    []string{\"[\"},\n\t\tisFound: false,\n\t},\n\t{\n\t\tdesc:  `null test`,\n\t\tjson:  `{\"c\": null}`,\n\t\tpath:  []string{\"c\"},\n\t\tisErr: true,\n\t},\n}\n\nvar getUnsafeStringTests = []GetTest{\n\t{\n\t\tdesc:    `Do not translate Unicode symbols`,\n\t\tjson:    `{\"c\": \"test\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `test`,\n\t},\n\t{\n\t\tdesc:    `Do not translate Unicode symbols`,\n\t\tjson:    `{\"c\": \"15\\u00b0C\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `15\\u00b0C`,\n\t},\n\t{\n\t\tdesc:    `Do not translate supplementary Unicode symbols`,\n\t\tjson:    `{\"c\": \"\\uD83D\\uDE03\"}`, // Smiley face (UTF16 surrogate pair)\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `\\uD83D\\uDE03`, // Smiley face\n\t},\n\t{\n\t\tdesc:    `Do not translate escape symbols`,\n\t\tjson:    `{\"c\": \"\\\\\\\"\"}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    `\\\\\\\"`,\n\t},\n}\n\nvar getBoolTests = []GetTest{\n\t{\n\t\tdesc:    `read boolean true as boolean`,\n\t\tjson:    `{\"a\": \"b\", \"c\": true}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    true,\n\t},\n\t{\n\t\tdesc:    `boolean true in formatted JSON`,\n\t\tjson:    \"{\\\"a\\\": \\\"b\\\", \\\"c\\\": true \\n}\",\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    true,\n\t},\n\t{\n\t\tdesc:    `read boolean false as boolean`,\n\t\tjson:    `{\"a\": \"b\", \"c\": false}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    false,\n\t},\n\t{\n\t\tdesc:    `boolean true in formatted JSON`,\n\t\tjson:    \"{\\\"a\\\": \\\"b\\\", \\\"c\\\": false \\n}\",\n\t\tpath:    []string{\"c\"},\n\t\tisFound: true,\n\t\tdata:    false,\n\t},\n\t{\n\t\tdesc:  `read fake boolean true`,\n\t\tjson:  `{\"a\": txyz}`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  `read fake boolean false`,\n\t\tjson:  `{\"a\": fwxyz}`,\n\t\tpath:  []string{\"a\"},\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:    `read boolean true with whitespace and another key`,\n\t\tjson:    \"{\\r\\t\\n \\\"a\\\"\\r\\t\\n :\\r\\t\\n true\\r\\t\\n ,\\r\\t\\n \\\"b\\\": 1}\",\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    true,\n\t},\n\t{\n\t\tdesc:    `null test`,\n\t\tjson:    `{\"a\": \"b\", \"c\": null}`,\n\t\tpath:    []string{\"c\"},\n\t\tisFound: false,\n\t\tisErr:   true,\n\t},\n}\n\nvar getArrayTests = []GetTest{\n\t{\n\t\tdesc:    `read array of simple values`,\n\t\tjson:    `{\"a\": { \"b\":[1,2,3,4]}}`,\n\t\tpath:    []string{\"a\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    []string{`1`, `2`, `3`, `4`},\n\t},\n\t{\n\t\tdesc:    `read array via empty path`,\n\t\tjson:    `[1,2,3,4]`,\n\t\tpath:    []string{},\n\t\tisFound: true,\n\t\tdata:    []string{`1`, `2`, `3`, `4`},\n\t},\n\t{\n\t\tdesc:    `read array of objects`,\n\t\tjson:    `{\"a\": { \"b\":[{\"x\":1},{\"x\":2},{\"x\":3},{\"x\":4}]}}`,\n\t\tpath:    []string{\"a\", \"b\"},\n\t\tisFound: true,\n\t\tdata:    []string{`{\"x\":1}`, `{\"x\":2}`, `{\"x\":3}`, `{\"x\":4}`},\n\t},\n\t{\n\t\tdesc:    `read nested array`,\n\t\tjson:    `{\"a\": [[[1]],[[2]]]}`,\n\t\tpath:    []string{\"a\"},\n\t\tisFound: true,\n\t\tdata:    []string{`[[1]]`, `[[2]]`},\n\t},\n}\n\n// checkFoundAndNoError checks the dataType and error return from Get*() against the test case expectations.\n// Returns true the test should proceed to checking the actual data returned from Get*(), or false if the test is finished.\nfunc getTestCheckFoundAndNoError(t *testing.T, testKind string, test GetTest, jtype ValueType, value interface{}, err error) bool {\n\tisFound := (err != KeyPathNotFoundError)\n\tisErr := (err != nil && err != KeyPathNotFoundError)\n\n\tif test.isErr != isErr {\n\t\t// If the call didn't match the error expectation, fail\n\t\tt.Errorf(\"%s test '%s' isErr mismatch: expected %t, obtained %t (err %v). Value: %v\", testKind, test.desc, test.isErr, isErr, err, value)\n\t\treturn false\n\t} else if isErr {\n\t\t// Else, if there was an error, don't fail and don't check isFound or the value\n\t\treturn false\n\t} else if test.isFound != isFound {\n\t\t// Else, if the call didn't match the is-found expectation, fail\n\t\tt.Errorf(\"%s test '%s' isFound mismatch: expected %t, obtained %t\", testKind, test.desc, test.isFound, isFound)\n\t\treturn false\n\t} else if !isFound {\n\t\t// Else, if no value was found, don't fail and don't check the value\n\t\treturn false\n\t} else {\n\t\t// Else, there was no error and a value was found, so check the value\n\t\treturn true\n\t}\n}\n\nfunc runGetTests(t *testing.T, testKind string, tests []GetTest, runner func(GetTest) (interface{}, ValueType, error), resultChecker func(GetTest, interface{}) (bool, interface{})) {\n\tfor _, test := range tests {\n\t\tif activeTest != \"\" && test.desc != activeTest {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Println(\"Running:\", test.desc)\n\n\t\tvalue, dataType, err := runner(test)\n\n\t\tif getTestCheckFoundAndNoError(t, testKind, test, dataType, value, err) {\n\t\t\tif test.data == nil {\n\t\t\t\tt.Errorf(\"MALFORMED TEST: %v\", test)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ok, expected := resultChecker(test, value); !ok {\n\t\t\t\tif expectedBytes, ok := expected.([]byte); ok {\n\t\t\t\t\texpected = string(expectedBytes)\n\t\t\t\t}\n\t\t\t\tif valueBytes, ok := value.([]byte); ok {\n\t\t\t\t\tvalue = string(valueBytes)\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"%s test '%s' expected to return value %v, but did returned %v instead\", testKind, test.desc, expected, value)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc setTestCheckFoundAndNoError(t *testing.T, testKind string, test SetTest, value interface{}, err error) bool {\n\tisFound := (err != KeyPathNotFoundError)\n\tisErr := (err != nil && err != KeyPathNotFoundError)\n\n\tif test.isErr != isErr {\n\t\t// If the call didn't match the error expectation, fail\n\t\tt.Errorf(\"%s test '%s' isErr mismatch: expected %t, obtained %t (err %v). Value: %v\", testKind, test.desc, test.isErr, isErr, err, value)\n\t\treturn false\n\t} else if isErr {\n\t\t// Else, if there was an error, don't fail and don't check isFound or the value\n\t\treturn false\n\t} else if test.isFound != isFound {\n\t\t// Else, if the call didn't match the is-found expectation, fail\n\t\tt.Errorf(\"%s test '%s' isFound mismatch: expected %t, obtained %t\", testKind, test.desc, test.isFound, isFound)\n\t\treturn false\n\t} else if !isFound {\n\t\t// Else, if no value was found, don't fail and don't check the value\n\t\treturn false\n\t} else {\n\t\t// Else, there was no error and a value was found, so check the value\n\t\treturn true\n\t}\n}\n\nfunc runSetTests(t *testing.T, testKind string, tests []SetTest, runner func(SetTest) (interface{}, ValueType, error), resultChecker func(SetTest, interface{}) (bool, interface{})) {\n\tfor _, test := range tests {\n\t\tif activeTest != \"\" && test.desc != activeTest {\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Println(\"Running:\", test.desc)\n\n\t\tvalue, _, err := runner(test)\n\n\t\tif setTestCheckFoundAndNoError(t, testKind, test, value, err) {\n\t\t\tif test.data == nil {\n\t\t\t\tt.Errorf(\"MALFORMED TEST: %v\", test)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif string(value.([]byte)) != test.data {\n\t\t\t\tt.Errorf(\"Unexpected result on %s test '%s'\", testKind, test.desc)\n\t\t\t\tt.Log(\"Got:     \", string(value.([]byte)))\n\t\t\t\tt.Log(\"Expected:\", test.data)\n\t\t\t\tt.Log(\"Error:   \", err)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc runDeleteTests(t *testing.T, testKind string, tests []DeleteTest, runner func(DeleteTest) (interface{}, []byte), resultChecker func(DeleteTest, interface{}) (bool, interface{})) {\n\tfor _, test := range tests {\n\t\tif activeTest != \"\" && test.desc != activeTest {\n\t\t\tcontinue\n\t\t}\n\n\t\toriginal := make([]byte, len(test.json))\n\t\tcopy(original, test.json)\n\n\t\tfmt.Println(\"Running:\", test.desc)\n\n\t\tvalue, bytes := runner(test)\n\n\t\tif string(original) != string(bytes) {\n\t\t\tt.Errorf(\"ORIGINAL DATA MALFORMED: %v, %v\", string(original), string(bytes))\n\t\t\tcontinue\n\t\t}\n\n\t\tif test.data == nil {\n\t\t\tt.Errorf(\"MALFORMED TEST: %v\", test)\n\t\t\tcontinue\n\t\t}\n\n\t\tif ok, expected := resultChecker(test, value); !ok {\n\t\t\tif expectedBytes, ok := expected.([]byte); ok {\n\t\t\t\texpected = string(expectedBytes)\n\t\t\t}\n\t\t\tif valueBytes, ok := value.([]byte); ok {\n\t\t\t\tvalue = string(valueBytes)\n\t\t\t}\n\t\t\tt.Errorf(\"%s test '%s' expected to return value %v, but did returned %v instead\", testKind, test.desc, expected, value)\n\t\t}\n\t}\n}\n\nfunc TestSet(t *testing.T) {\n\trunSetTests(t, \"Set()\", setTests,\n\t\tfunc(test SetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = Set([]byte(test.json), []byte(test.setData), test.path...)\n\t\t\treturn\n\t\t},\n\t\tfunc(test SetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := []byte(test.data.(string))\n\t\t\treturn bytes.Equal(expected, value.([]byte)), expected\n\t\t},\n\t)\n}\n\nfunc TestDelete(t *testing.T) {\n\trunDeleteTests(t, \"Delete()\", deleteTests,\n\t\tfunc(test DeleteTest) (interface{}, []byte) {\n\t\t\tba := []byte(test.json)\n\t\t\treturn Delete(ba, test.path...), ba\n\t\t},\n\t\tfunc(test DeleteTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := []byte(test.data.(string))\n\t\t\treturn bytes.Equal(expected, value.([]byte)), expected\n\t\t},\n\t)\n}\n\nfunc TestGet(t *testing.T) {\n\trunGetTests(t, \"Get()\", getTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, dataType, _, err = Get([]byte(test.json), test.path...)\n\t\t\treturn\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := []byte(test.data.(string))\n\t\t\treturn bytes.Equal(expected, value.([]byte)), expected\n\t\t},\n\t)\n}\n\nfunc TestGetString(t *testing.T) {\n\trunGetTests(t, \"GetString()\", getStringTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = GetString([]byte(test.json), test.path...)\n\t\t\treturn value, String, err\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.(string)\n\t\t\treturn expected == value.(string), expected\n\t\t},\n\t)\n}\n\nfunc TestGetUnsafeString(t *testing.T) {\n\trunGetTests(t, \"GetUnsafeString()\", getUnsafeStringTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = GetUnsafeString([]byte(test.json), test.path...)\n\t\t\treturn value, String, err\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.(string)\n\t\t\treturn expected == value.(string), expected\n\t\t},\n\t)\n}\n\nfunc TestGetInt(t *testing.T) {\n\trunGetTests(t, \"GetInt()\", getIntTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = GetInt([]byte(test.json), test.path...)\n\t\t\treturn value, Number, err\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.(int64)\n\t\t\treturn expected == value.(int64), expected\n\t\t},\n\t)\n}\n\nfunc TestGetFloat(t *testing.T) {\n\trunGetTests(t, \"GetFloat()\", getFloatTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = GetFloat([]byte(test.json), test.path...)\n\t\t\treturn value, Number, err\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.(float64)\n\t\t\treturn expected == value.(float64), expected\n\t\t},\n\t)\n}\n\nfunc TestGetBoolean(t *testing.T) {\n\trunGetTests(t, \"GetBoolean()\", getBoolTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, err = GetBoolean([]byte(test.json), test.path...)\n\t\t\treturn value, Boolean, err\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.(bool)\n\t\t\treturn expected == value.(bool), expected\n\t\t},\n\t)\n}\n\nfunc TestGetSlice(t *testing.T) {\n\trunGetTests(t, \"Get()-for-arrays\", getArrayTests,\n\t\tfunc(test GetTest) (value interface{}, dataType ValueType, err error) {\n\t\t\tvalue, dataType, _, err = Get([]byte(test.json), test.path...)\n\t\t\treturn\n\t\t},\n\t\tfunc(test GetTest, value interface{}) (bool, interface{}) {\n\t\t\texpected := test.data.([]string)\n\t\t\treturn reflect.DeepEqual(expected, toStringArray(value.([]byte))), expected\n\t\t},\n\t)\n}\n\nfunc TestArrayEach(t *testing.T) {\n\tmock := []byte(`{\"a\": { \"b\":[{\"x\": 1} ,{\"x\":2},{ \"x\":3}, {\"x\":4} ]}}`)\n\tcount := 0\n\n\tArrayEach(mock, func(value []byte, dataType ValueType, offset int, err error) {\n\t\tcount++\n\n\t\tswitch count {\n\t\tcase 1:\n\t\t\tif string(value) != `{\"x\": 1}` {\n\t\t\t\tt.Errorf(\"Wrong first item: %s\", string(value))\n\t\t\t}\n\t\tcase 2:\n\t\t\tif string(value) != `{\"x\":2}` {\n\t\t\t\tt.Errorf(\"Wrong second item: %s\", string(value))\n\t\t\t}\n\t\tcase 3:\n\t\t\tif string(value) != `{ \"x\":3}` {\n\t\t\t\tt.Errorf(\"Wrong third item: %s\", string(value))\n\t\t\t}\n\t\tcase 4:\n\t\t\tif string(value) != `{\"x\":4}` {\n\t\t\t\tt.Errorf(\"Wrong forth item: %s\", string(value))\n\t\t\t}\n\t\tdefault:\n\t\t\tt.Errorf(\"Should process only 4 items\")\n\t\t}\n\t}, \"a\", \"b\")\n}\n\nfunc TestArrayEachWithWhiteSpace(t *testing.T) {\n\t// Issue #159\n\tcount := 0\n\tfuncError := func([]byte, ValueType, int, error) { t.Errorf(\"Run func not allow\") }\n\tfuncSuccess := func(value []byte, dataType ValueType, index int, err error) {\n\t\tcount++\n\n\t\tswitch count {\n\t\tcase 1:\n\t\t\tif string(value) != `AAA` {\n\t\t\t\tt.Errorf(\"Wrong first item: %s\", string(value))\n\t\t\t}\n\t\tcase 2:\n\t\t\tif string(value) != `BBB` {\n\t\t\t\tt.Errorf(\"Wrong second item: %s\", string(value))\n\t\t\t}\n\t\tcase 3:\n\t\t\tif string(value) != `CCC` {\n\t\t\t\tt.Errorf(\"Wrong third item: %s\", string(value))\n\t\t\t}\n\t\tdefault:\n\t\t\tt.Errorf(\"Should process only 3 items\")\n\t\t}\n\t}\n\n\ttype args struct {\n\t\tdata []byte\n\t\tcb   func(value []byte, dataType ValueType, offset int, err error)\n\t\tkeys []string\n\t}\n\ttests := []struct {\n\t\tname    string\n\t\targs    args\n\t\twantErr bool\n\t}{\n\t\t{\"Array with white space\", args{[]byte(`    [\"AAA\", \"BBB\", \"CCC\"]`), funcSuccess, []string{}}, false},\n\t\t{\"Array with only one character after white space\", args{[]byte(`    1`), funcError, []string{}}, true},\n\t\t{\"Only white space\", args{[]byte(`    `), funcError, []string{}}, true},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\t_, err := ArrayEach(tt.args.data, tt.args.cb, tt.args.keys...)\n\t\t\tif (err != nil) != tt.wantErr {\n\t\t\t\tt.Errorf(\"ArrayEach() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t\treturn\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestArrayEachEmpty(t *testing.T) {\n\tfuncError := func([]byte, ValueType, int, error) { t.Errorf(\"Run func not allow\") }\n\n\ttype args struct {\n\t\tdata []byte\n\t\tcb   func(value []byte, dataType ValueType, offset int, err error)\n\t\tkeys []string\n\t}\n\ttests := []struct {\n\t\tname       string\n\t\targs       args\n\t\twantOffset int\n\t\twantErr    bool\n\t}{\n\t\t{\"Empty array\", args{[]byte(\"[]\"), funcError, []string{}}, 1, false},\n\t\t{\"Empty array with space\", args{[]byte(\"[ ]\"), funcError, []string{}}, 2, false},\n\t\t{\"Empty array with \\n\", args{[]byte(\"[\\n]\"), funcError, []string{}}, 2, false},\n\t\t{\"Empty field array\", args{[]byte(\"{\\\"data\\\": []}\"), funcError, []string{\"data\"}}, 10, false},\n\t\t{\"Empty field array with space\", args{[]byte(\"{\\\"data\\\": [ ]}\"), funcError, []string{\"data\"}}, 11, false},\n\t\t{\"Empty field array with \\n\", args{[]byte(\"{\\\"data\\\": [\\n]}\"), funcError, []string{\"data\"}}, 11, false},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgotOffset, err := ArrayEach(tt.args.data, tt.args.cb, tt.args.keys...)\n\t\t\tif (err != nil) != tt.wantErr {\n\t\t\t\tt.Errorf(\"ArrayEach() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif gotOffset != tt.wantOffset {\n\t\t\t\tt.Errorf(\"ArrayEach() = %v, want %v\", gotOffset, tt.wantOffset)\n\t\t\t}\n\t\t})\n\t}\n}\n\ntype keyValueEntry struct {\n\tkey       string\n\tvalue     string\n\tvalueType ValueType\n}\n\nfunc (kv keyValueEntry) String() string {\n\treturn fmt.Sprintf(\"[%s: %s (%s)]\", kv.key, kv.value, kv.valueType)\n}\n\ntype ObjectEachTest struct {\n\tdesc string\n\tjson string\n\n\tisErr   bool\n\tentries []keyValueEntry\n}\n\nvar objectEachTests = []ObjectEachTest{\n\t{\n\t\tdesc:    \"empty object\",\n\t\tjson:    `{}`,\n\t\tentries: []keyValueEntry{},\n\t},\n\t{\n\t\tdesc: \"single key-value object\",\n\t\tjson: `{\"key\": \"value\"}`,\n\t\tentries: []keyValueEntry{\n\t\t\t{\"key\", \"value\", String},\n\t\t},\n\t},\n\t{\n\t\tdesc: \"multiple key-value object with many value types\",\n\t\tjson: `{\n\t\t  \"key1\": null,\n\t\t  \"key2\": true,\n\t\t  \"key3\": 1.23,\n\t\t  \"key4\": \"string value\",\n\t\t  \"key5\": [1,2,3],\n\t\t  \"key6\": {\"a\":\"b\"}\n\t\t}`,\n\t\tentries: []keyValueEntry{\n\t\t\t{\"key1\", \"null\", Null},\n\t\t\t{\"key2\", \"true\", Boolean},\n\t\t\t{\"key3\", \"1.23\", Number},\n\t\t\t{\"key4\", \"string value\", String},\n\t\t\t{\"key5\", \"[1,2,3]\", Array},\n\t\t\t{\"key6\", `{\"a\":\"b\"}`, Object},\n\t\t},\n\t},\n\t{\n\t\tdesc: \"escaped key\",\n\t\tjson: `{\"key\\\"\\\\\\/\\b\\f\\n\\r\\t\\u00B0\": \"value\"}`,\n\t\tentries: []keyValueEntry{\n\t\t\t{\"key\\\"\\\\/\\b\\f\\n\\r\\t\\u00B0\", \"value\", String},\n\t\t},\n\t},\n\t// Error cases\n\t{\n\t\tdesc:  \"no object present\",\n\t\tjson:  ` \\t\\n\\r`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"unmatched braces 1\",\n\t\tjson:  `{`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"unmatched braces 2\",\n\t\tjson:  `}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"unmatched braces 3\",\n\t\tjson:  `}{}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad key (number)\",\n\t\tjson:  `{123: \"value\"}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad key (unclosed quote)\",\n\t\tjson:  `{\"key: 123}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad value (no value)\",\n\t\tjson:  `{\"key\":}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad value (bogus value)\",\n\t\tjson:  `{\"key\": notavalue}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad entry (missing colon)\",\n\t\tjson:  `{\"key\" \"value\"}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad entry (no trailing comma)\",\n\t\tjson:  `{\"key\": \"value\" \"key2\": \"value2\"}`,\n\t\tisErr: true,\n\t},\n\t{\n\t\tdesc:  \"bad entry (two commas)\",\n\t\tjson:  `{\"key\": \"value\",, \"key2\": \"value2\"}`,\n\t\tisErr: true,\n\t},\n}\n\nfunc TestObjectEach(t *testing.T) {\n\tfor _, test := range objectEachTests {\n\t\tif activeTest != \"\" && test.desc != activeTest {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Execute ObjectEach and capture all of the entries visited, in order\n\t\tvar entries []keyValueEntry\n\t\terr := ObjectEach([]byte(test.json), func(key, value []byte, valueType ValueType, off int) error {\n\t\t\tentries = append(entries, keyValueEntry{\n\t\t\t\tkey:       string(key),\n\t\t\t\tvalue:     string(value),\n\t\t\t\tvalueType: valueType,\n\t\t\t})\n\t\t\treturn nil\n\t\t})\n\n\t\t// Check the correctness of the result\n\t\tisErr := (err != nil)\n\t\tif test.isErr != isErr {\n\t\t\t// If the call didn't match the error expectation, fail\n\t\t\tt.Errorf(\"ObjectEach test '%s' isErr mismatch: expected %t, obtained %t (err %v)\", test.desc, test.isErr, isErr, err)\n\t\t} else if isErr {\n\t\t\t// Else, if there was an expected error, don't fail and don't check anything further\n\t\t} else if len(test.entries) != len(entries) {\n\t\t\tt.Errorf(\"ObjectEach test '%s' mismatch in number of key-value entries: expected %d, obtained %d (entries found: %s)\", test.desc, len(test.entries), len(entries), entries)\n\t\t} else {\n\t\t\tfor i, entry := range entries {\n\t\t\t\texpectedEntry := test.entries[i]\n\t\t\t\tif expectedEntry.key != entry.key {\n\t\t\t\t\tt.Errorf(\"ObjectEach test '%s' key mismatch at entry %d: expected %s, obtained %s\", test.desc, i, expectedEntry.key, entry.key)\n\t\t\t\t\tbreak\n\t\t\t\t} else if expectedEntry.value != entry.value {\n\t\t\t\t\tt.Errorf(\"ObjectEach test '%s' value mismatch at entry %d: expected %s, obtained %s\", test.desc, i, expectedEntry.value, entry.value)\n\t\t\t\t\tbreak\n\t\t\t\t} else if expectedEntry.valueType != entry.valueType {\n\t\t\t\t\tt.Errorf(\"ObjectEach test '%s' value type mismatch at entry %d: expected %s, obtained %s\", test.desc, i, expectedEntry.valueType, entry.valueType)\n\t\t\t\t\tbreak\n\t\t\t\t} else {\n\t\t\t\t\t// Success for this entry\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nvar testJson = []byte(`{\n\t\"name\": \"Name\", \n\t\"order\": \"Order\", \n\t\"sum\": 100, \n\t\"len\": 12, \n\t\"isPaid\": true, \n\t\"nested\": {\"a\":\"test\", \"b\":2, \"nested3\":{\"a\":\"test3\",\"b\":4}, \"c\": \"unknown\"}, \n\t\"nested2\": {\n\t\t\"a\":\"test2\", \n\t\t\"b\":3\n\t}, \n\t\"arr\": [\n\t\t{\n\t\t\t\"a\":\"zxc\", \n\t\t\t\"b\": 1\n\t\t}, \n\t\t{\n\t\t\t\"a\":\"123\", \n\t\t\t\"b\":2\n\t\t}\n\t], \n\t\"arrInt\": [1,2,3,4], \n\t\"intPtr\": 10, \n\t\"a\\n\":{\n\t\t\"b\\n\":99\n\t}\n}`)\n\nfunc TestEachKey(t *testing.T) {\n\tpaths := [][]string{\n\t\t{\"name\"},\n\t\t{\"order\"},\n\t\t{\"nested\", \"a\"},\n\t\t{\"nested\", \"b\"},\n\t\t{\"nested2\", \"a\"},\n\t\t{\"nested\", \"nested3\", \"b\"},\n\t\t{\"arr\", \"[1]\", \"b\"},\n\t\t{\"arrInt\", \"[3]\"},\n\t\t{\"arrInt\", \"[5]\"}, // Should not find last key\n\t\t{\"nested\"},\n\t\t{\"arr\", \"[\"},    // issue#177 Invalid arguments\n\t\t{\"a\\n\", \"b\\n\"},  // issue#165\n\t\t{\"nested\", \"b\"}, // Should find repeated key\n\t}\n\n\tkeysFound := 0\n\n\tEachKey(testJson, func(idx int, value []byte, vt ValueType, err error) {\n\t\tkeysFound++\n\n\t\tswitch idx {\n\t\tcase 0:\n\t\t\tif string(value) != \"Name\" {\n\t\t\t\tt.Error(\"Should find 1 key\", string(value))\n\t\t\t}\n\t\tcase 1:\n\t\t\tif string(value) != \"Order\" {\n\t\t\t\tt.Errorf(\"Should find 2 key\")\n\t\t\t}\n\t\tcase 2:\n\t\t\tif string(value) != \"test\" {\n\t\t\t\tt.Errorf(\"Should find 3 key\")\n\t\t\t}\n\t\tcase 3:\n\t\t\tif string(value) != \"2\" {\n\t\t\t\tt.Errorf(\"Should find 4 key\")\n\t\t\t}\n\t\tcase 4:\n\t\t\tif string(value) != \"test2\" {\n\t\t\t\tt.Error(\"Should find 5 key\", string(value))\n\t\t\t}\n\t\tcase 5:\n\t\t\tif string(value) != \"4\" {\n\t\t\t\tt.Errorf(\"Should find 6 key\")\n\t\t\t}\n\t\tcase 6:\n\t\t\tif string(value) != \"2\" {\n\t\t\t\tt.Errorf(\"Should find 7 key\")\n\t\t\t}\n\t\tcase 7:\n\t\t\tif string(value) != \"4\" {\n\t\t\t\tt.Error(\"Should find 8 key\", string(value))\n\t\t\t}\n\t\tcase 8:\n\t\t\tt.Errorf(\"Found key #8 that should not be found\")\n\t\tcase 9:\n\t\t\tif string(value) != `{\"a\":\"test\", \"b\":2, \"nested3\":{\"a\":\"test3\",\"b\":4}, \"c\": \"unknown\"}` {\n\t\t\t\tt.Error(\"Should find 9 key\", string(value))\n\t\t\t}\n\t\tcase 10:\n\t\t\tt.Errorf(\"Found key #10 that should not be found\")\n\t\tcase 11:\n\t\t\tif string(value) != \"99\" {\n\t\t\t\tt.Error(\"Should find 10 key\", string(value))\n\t\t\t}\n\t\tcase 12:\n\t\t\tif string(value) != \"2\" {\n\t\t\t\tt.Errorf(\"Should find 11 key\")\n\t\t\t}\n\t\tdefault:\n\t\t\tt.Errorf(\"Should find only 10 keys, got %v key\", idx)\n\t\t}\n\t}, paths...)\n\n\tif keysFound != 11 {\n\t\tt.Errorf(\"Should find 11 keys: %d\", keysFound)\n\t}\n}\n\ntype ParseTest struct {\n\tin     string\n\tintype ValueType\n\tout    interface{}\n\tisErr  bool\n}\n\nvar parseBoolTests = []ParseTest{\n\t{\n\t\tin:     \"true\",\n\t\tintype: Boolean,\n\t\tout:    true,\n\t},\n\t{\n\t\tin:     \"false\",\n\t\tintype: Boolean,\n\t\tout:    false,\n\t},\n\t{\n\t\tin:     \"foo\",\n\t\tintype: Boolean,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"trux\",\n\t\tintype: Boolean,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"truex\",\n\t\tintype: Boolean,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"\",\n\t\tintype: Boolean,\n\t\tisErr:  true,\n\t},\n}\n\nvar parseFloatTest = []ParseTest{\n\t{\n\t\tin:     \"0\",\n\t\tintype: Number,\n\t\tout:    float64(0),\n\t},\n\t{\n\t\tin:     \"0.0\",\n\t\tintype: Number,\n\t\tout:    float64(0.0),\n\t},\n\t{\n\t\tin:     \"1\",\n\t\tintype: Number,\n\t\tout:    float64(1),\n\t},\n\t{\n\t\tin:     \"1.234\",\n\t\tintype: Number,\n\t\tout:    float64(1.234),\n\t},\n\t{\n\t\tin:     \"1.234e5\",\n\t\tintype: Number,\n\t\tout:    float64(1.234e5),\n\t},\n\t{\n\t\tin:     \"-1.234e5\",\n\t\tintype: Number,\n\t\tout:    float64(-1.234e5),\n\t},\n\t{\n\t\tin:     \"+1.234e5\", // Note: + sign not allowed under RFC7159, but our parser accepts it since it uses strconv.ParseFloat\n\t\tintype: Number,\n\t\tout:    float64(1.234e5),\n\t},\n\t{\n\t\tin:     \"1.2.3\",\n\t\tintype: Number,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"1..1\",\n\t\tintype: Number,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"1a\",\n\t\tintype: Number,\n\t\tisErr:  true,\n\t},\n\t{\n\t\tin:     \"\",\n\t\tintype: Number,\n\t\tisErr:  true,\n\t},\n}\n\n// parseTestCheckNoError checks the error return from Parse*() against the test case expectations.\n// Returns true the test should proceed to checking the actual data returned from Parse*(), or false if the test is finished.\nfunc parseTestCheckNoError(t *testing.T, testKind string, test ParseTest, value interface{}, err error) bool {\n\tif isErr := (err != nil); test.isErr != isErr {\n\t\t// If the call didn't match the error expectation, fail\n\t\tt.Errorf(\"%s test '%s' isErr mismatch: expected %t, obtained %t (err %v). Obtained value: %v\", testKind, test.in, test.isErr, isErr, err, value)\n\t\treturn false\n\t} else if isErr {\n\t\t// Else, if there was an error, don't fail and don't check isFound or the value\n\t\treturn false\n\t} else {\n\t\t// Else, there was no error and a value was found, so check the value\n\t\treturn true\n\t}\n}\n\nfunc runParseTests(t *testing.T, testKind string, tests []ParseTest, runner func(ParseTest) (interface{}, error), resultChecker func(ParseTest, interface{}) (bool, interface{})) {\n\tfor _, test := range tests {\n\t\tvalue, err := runner(test)\n\n\t\tif parseTestCheckNoError(t, testKind, test, value, err) {\n\t\t\tif test.out == nil {\n\t\t\t\tt.Errorf(\"MALFORMED TEST: %v\", test)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ok, expected := resultChecker(test, value); !ok {\n\t\t\t\tif expectedBytes, ok := expected.([]byte); ok {\n\t\t\t\t\texpected = string(expectedBytes)\n\t\t\t\t}\n\t\t\t\tif valueBytes, ok := value.([]byte); ok {\n\t\t\t\t\tvalue = string(valueBytes)\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"%s test '%s' expected to return value %v, but did returned %v instead\", testKind, test.in, expected, value)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestParseBoolean(t *testing.T) {\n\trunParseTests(t, \"ParseBoolean()\", parseBoolTests,\n\t\tfunc(test ParseTest) (value interface{}, err error) {\n\t\t\treturn ParseBoolean([]byte(test.in))\n\t\t},\n\t\tfunc(test ParseTest, obtained interface{}) (bool, interface{}) {\n\t\t\texpected := test.out.(bool)\n\t\t\treturn obtained.(bool) == expected, expected\n\t\t},\n\t)\n}\n\nfunc TestParseFloat(t *testing.T) {\n\trunParseTests(t, \"ParseFloat()\", parseFloatTest,\n\t\tfunc(test ParseTest) (value interface{}, err error) {\n\t\t\treturn ParseFloat([]byte(test.in))\n\t\t},\n\t\tfunc(test ParseTest, obtained interface{}) (bool, interface{}) {\n\t\t\texpected := test.out.(float64)\n\t\t\treturn obtained.(float64) == expected, expected\n\t\t},\n\t)\n}\n\nvar parseStringTest = []ParseTest{\n\t{\n\t\tin:     `\\uFF11`,\n\t\tintype: String,\n\t\tout:    \"\\uFF11\",\n\t},\n\t{\n\t\tin:     `\\uFFFF`,\n\t\tintype: String,\n\t\tout:    \"\\uFFFF\",\n\t},\n\t{\n\t\tin:     `\\uDF00`,\n\t\tintype: String,\n\t\tisErr:  true,\n\t},\n}\n\nfunc TestParseString(t *testing.T) {\n\trunParseTests(t, \"ParseString()\", parseStringTest,\n\t\tfunc(test ParseTest) (value interface{}, err error) {\n\t\t\treturn ParseString([]byte(test.in))\n\t\t},\n\t\tfunc(test ParseTest, obtained interface{}) (bool, interface{}) {\n\t\t\texpected := test.out.(string)\n\t\t\treturn obtained.(string) == expected, expected\n\t\t},\n\t)\n}\n"
        }
      ]
    }
  ]
}