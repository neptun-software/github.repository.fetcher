{
  "metadata": {
    "timestamp": 1736567646685,
    "page": 227,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "cilium/ebpf",
      "stars": 6501,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.8427734375,
          "content": "---\nLanguage:        Cpp\nBasedOnStyle:    LLVM\nAlignAfterOpenBracket: DontAlign\nAlignConsecutiveAssignments: true\nAlignEscapedNewlines: DontAlign\n# mkdocs annotations in source code are written as trailing comments\n# and alignment pushes these really far away from the content.\nAlignTrailingComments: false\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: false\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortFunctionsOnASingleLine: false\nBreakBeforeBraces: Attach\nIndentWidth:     4\nKeepEmptyLinesAtTheStartOfBlocks: false\nTabWidth:        4\nUseTab:          ForContinuationAndIndentation\nColumnLimit:     1000\n# Go compiler comments need to stay unindented.\nCommentPragmas: '^go:.*'\n# linux/bpf.h needs to be included before bpf/bpf_helpers.h for types like __u64\n# and sorting makes this impossible.\nSortIncludes: false\n...\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0458984375,
          "content": "internal/sys/types.go linguist-generated=false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.201171875,
          "content": "# Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n*.o\n!*_bpf*.o\n\n# Test binary, build with `go test -c`\n*.test\n\n# Output of the go coverage tool, specifically when used with LiteIDE\n*.out\n"
        },
        {
          "name": ".golangci.yaml",
          "type": "blob",
          "size": 0.4052734375,
          "content": "---\nlinters:\n  disable-all: true\n  enable:\n    - goimports\n    - gosimple\n    - govet\n    - ineffassign\n    - misspell\n    - staticcheck\n    - typecheck\n    - unused\n    - gofmt\nlinters-settings:\n  goimports:\n    # A comma-separated list of prefixes, which, if set, checks import paths\n    # with the given prefixes are grouped after 3rd-party packages.\n    # Default: \"\"\n    local-prefixes: github.com/cilium/ebpf\n"
        },
        {
          "name": ".vimto.toml",
          "type": "blob",
          "size": 0.25390625,
          "content": "kernel=\"ghcr.io/cilium/ci-kernels:stable\"\nsmp=\"cpus=2\"\nmemory=\"1G\"\nuser=\"root\"\nsetup=[\n  \"mount -t cgroup2 -o nosuid,noexec,nodev cgroup2 /sys/fs/cgroup\",\n  \"/bin/sh -c 'modprobe bpf_testmod || true'\",\n  \"dmesg --clear\",\n]\nteardown=[\n  \"dmesg --read-clear\",\n]\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 0.15234375,
          "content": "* @cilium/ebpf-lib-maintainers\n\nfeatures/ @rgo3\nlink/ @mmat11\n\nperf/ @florianl\nringbuf/ @florianl\n\nbtf/ @dylandreimerink\n\ncmd/bpf2go/ @mejedi\n\ndocs/ @ti-mo\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1689453125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at nathanjsweet at gmail dot com or i at lmb dot io. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.1875,
          "content": "# Contributing to ebpf-go\n\nWant to contribute to ebpf-go? There are a few things you need to know.\n\nWe wrote a [contribution guide](https://ebpf-go.dev/contributing/) to help you get started.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.115234375,
          "content": "MIT License\n\nCopyright (c) 2017 Nathan Sweet\nCopyright (c) 2018, 2019 Cloudflare\nCopyright (c) 2019 Authors of Cilium\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MAINTAINERS.md",
          "type": "blob",
          "size": 0.1376953125,
          "content": "# Maintainers\n\nMaintainers can be found in the [Cilium Maintainers file](https://github.com/cilium/community/blob/main/roles/Maintainers.md)\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.408203125,
          "content": "# The development version of clang is distributed as the 'clang' binary,\n# while stable/released versions have a version number attached.\n# Pin the default clang to a stable version.\nCLANG ?= clang-17\nSTRIP ?= llvm-strip-17\nOBJCOPY ?= llvm-objcopy-17\nCFLAGS := -O2 -g -Wall -Werror $(CFLAGS)\n\nCI_KERNEL_URL ?= https://github.com/cilium/ci-kernels/raw/master/\n\n# Obtain an absolute path to the directory of the Makefile.\n# Assume the Makefile is in the root of the repository.\nREPODIR := $(shell dirname $(realpath $(firstword $(MAKEFILE_LIST))))\nUIDGID := $(shell stat -c '%u:%g' ${REPODIR})\n\n# Prefer podman if installed, otherwise use docker.\n# Note: Setting the var at runtime will always override.\nCONTAINER_ENGINE ?= $(if $(shell command -v podman), podman, docker)\nCONTAINER_RUN_ARGS ?= $(if $(filter ${CONTAINER_ENGINE}, podman), --log-driver=none, --user \"${UIDGID}\")\n\nIMAGE := $(shell cat ${REPODIR}/testdata/docker/IMAGE)\nVERSION := $(shell cat ${REPODIR}/testdata/docker/VERSION)\n\nTARGETS := \\\n\ttestdata/loader-clang-11 \\\n\ttestdata/loader-clang-14 \\\n\ttestdata/loader-$(CLANG) \\\n\ttestdata/manyprogs \\\n\ttestdata/btf_map_init \\\n\ttestdata/invalid_map \\\n\ttestdata/raw_tracepoint \\\n\ttestdata/invalid_map_static \\\n\ttestdata/invalid_btf_map_init \\\n\ttestdata/strings \\\n\ttestdata/freplace \\\n\ttestdata/fentry_fexit \\\n\ttestdata/iproute2_map_compat \\\n\ttestdata/map_spin_lock \\\n\ttestdata/subprog_reloc \\\n\ttestdata/fwd_decl \\\n\ttestdata/kconfig \\\n\ttestdata/ksym \\\n\ttestdata/kfunc \\\n\ttestdata/invalid-kfunc \\\n\ttestdata/kfunc-kmod \\\n\ttestdata/constants \\\n\ttestdata/errors \\\n\ttestdata/variables \\\n\tbtf/testdata/relocs \\\n\tbtf/testdata/relocs_read \\\n\tbtf/testdata/relocs_read_tgt \\\n\tbtf/testdata/relocs_enum \\\n\tbtf/testdata/tags \\\n\tcmd/bpf2go/testdata/minimal\n\n.PHONY: all clean container-all container-shell generate\n\n.DEFAULT_TARGET = container-all\n\n# Build all ELF binaries using a containerized LLVM toolchain.\ncontainer-all:\n\t+${CONTAINER_ENGINE} run --rm -ti ${CONTAINER_RUN_ARGS} \\\n\t\t-v \"${REPODIR}\":/ebpf -w /ebpf --env MAKEFLAGS \\\n\t\t--env HOME=\"/tmp\" \\\n\t\t--env BPF2GO_CC=\"$(CLANG)\" \\\n\t\t--env BPF2GO_FLAGS=\"-fdebug-prefix-map=/ebpf=. $(CFLAGS)\" \\\n\t\t\"${IMAGE}:${VERSION}\" \\\n\t\tmake all\n\n# (debug) Drop the user into a shell inside the container as root.\n# Set BPF2GO_ envs to make 'make generate' just work.\ncontainer-shell:\n\t${CONTAINER_ENGINE} run --rm -ti \\\n\t\t-v \"${REPODIR}\":/ebpf -w /ebpf \\\n\t\t--env BPF2GO_CC=\"$(CLANG)\" \\\n\t\t--env BPF2GO_FLAGS=\"-fdebug-prefix-map=/ebpf=. $(CFLAGS)\" \\\n\t\t\"${IMAGE}:${VERSION}\"\n\nclean:\n\tfind \"$(CURDIR)\" -name \"*.elf\" -delete\n\tfind \"$(CURDIR)\" -name \"*.o\" -delete\n\nformat:\n\tfind . -type f -name \"*.c\" | xargs clang-format -i\n\nall: format $(addsuffix -el.elf,$(TARGETS)) $(addsuffix -eb.elf,$(TARGETS)) generate\n\tln -srf testdata/loader-$(CLANG)-el.elf testdata/loader-el.elf\n\tln -srf testdata/loader-$(CLANG)-eb.elf testdata/loader-eb.elf\n\ngenerate:\n\tgo generate -run \"internal/cmd/gentypes\" ./...\n\tgo generate -skip \"internal/cmd/gentypes\" ./...\n\ntestdata/loader-%-el.elf: testdata/loader.c\n\t$* $(CFLAGS) -target bpfel -c $< -o $@\n\t$(STRIP) -g $@\n\ntestdata/loader-%-eb.elf: testdata/loader.c\n\t$* $(CFLAGS) -target bpfeb -c $< -o $@\n\t$(STRIP) -g $@\n\n%-el.elf: %.c\n\t$(CLANG) $(CFLAGS) -target bpfel -c $< -o $@\n\t$(STRIP) -g $@\n\n%-eb.elf : %.c\n\t$(CLANG) $(CFLAGS) -target bpfeb -c $< -o $@\n\t$(STRIP) -g $@\n\n.PHONY: update-kernel-deps\nupdate-kernel-deps: export KERNEL_VERSION?=6.8\nupdate-kernel-deps:\n\t./testdata/sh/update-kernel-deps.sh\n\t$(MAKE) container-all\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.0888671875,
          "content": "# eBPF\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/cilium/ebpf)](https://pkg.go.dev/github.com/cilium/ebpf)\n\n![HoneyGopher](docs/ebpf/ebpf-go.png)\n\nebpf-go is a pure Go library that provides utilities for loading, compiling, and\ndebugging eBPF programs. It has minimal external dependencies and is intended to\nbe used in long running processes.\n\nSee [ebpf.io](https://ebpf.io) for complementary projects from the wider eBPF\necosystem.\n\n## Getting Started\n\nPlease take a look at our [Getting Started] guide.\n\n[Contributions](https://ebpf-go.dev/contributing) are highly encouraged, as they highlight certain use cases of\neBPF and the library, and help shape the future of the project.\n\n## Getting Help\n\nThe community actively monitors our [GitHub Discussions](https://github.com/cilium/ebpf/discussions) page.\nPlease search for existing threads before starting a new one. Refrain from\nopening issues on the bug tracker if you're just starting out or if you're not\nsure if something is a bug in the library code.\n\nAlternatively, [join](https://ebpf.io/slack) the\n[#ebpf-go](https://cilium.slack.com/messages/ebpf-go) channel on Slack if you\nhave other questions regarding the project. Note that this channel is ephemeral\nand has its history erased past a certain point, which is less helpful for\nothers running into the same problem later.\n\n## Packages\n\nThis library includes the following packages:\n\n* [asm](https://pkg.go.dev/github.com/cilium/ebpf/asm) contains a basic\n  assembler, allowing you to write eBPF assembly instructions directly\n  within your Go code. (You don't need to use this if you prefer to write your eBPF program in C.)\n* [cmd/bpf2go](https://pkg.go.dev/github.com/cilium/ebpf/cmd/bpf2go) allows\n  compiling and embedding eBPF programs written in C within Go code. As well as\n  compiling the C code, it auto-generates Go code for loading and manipulating\n  the eBPF program and map objects.\n* [link](https://pkg.go.dev/github.com/cilium/ebpf/link) allows attaching eBPF\n  to various hooks\n* [perf](https://pkg.go.dev/github.com/cilium/ebpf/perf) allows reading from a\n  `PERF_EVENT_ARRAY`\n* [ringbuf](https://pkg.go.dev/github.com/cilium/ebpf/ringbuf) allows reading from a\n  `BPF_MAP_TYPE_RINGBUF` map\n* [features](https://pkg.go.dev/github.com/cilium/ebpf/features) implements the equivalent\n  of `bpftool feature probe` for discovering BPF-related kernel features using native Go.\n* [rlimit](https://pkg.go.dev/github.com/cilium/ebpf/rlimit) provides a convenient API to lift\n  the `RLIMIT_MEMLOCK` constraint on kernels before 5.11.\n* [btf](https://pkg.go.dev/github.com/cilium/ebpf/btf) allows reading the BPF Type Format.\n* [pin](https://pkg.go.dev/github.com/cilium/ebpf/pin) provides APIs for working with pinned objects on bpffs.\n\n## Requirements\n\n* A version of Go that is [supported by\n  upstream](https://golang.org/doc/devel/release.html#policy)\n* CI is run against kernel.org LTS releases. >= 4.4 should work but EOL'ed versions\n  are not supported.\n\n## License\n\nMIT\n\n### eBPF Gopher\n\nThe eBPF honeygopher is based on the Go gopher designed by Renee French.\n\n[Getting Started]: https://ebpf-go.dev/guides/getting-started/\n"
        },
        {
          "name": "asm",
          "type": "tree",
          "content": null
        },
        {
          "name": "attachtype_string.go",
          "type": "blob",
          "size": 3.4208984375,
          "content": "// Code generated by \"stringer -type AttachType -trimprefix Attach\"; DO NOT EDIT.\n\npackage ebpf\n\nimport \"strconv\"\n\nfunc _() {\n\t// An \"invalid array index\" compiler error signifies that the constant values have changed.\n\t// Re-run the stringer command to generate them again.\n\tvar x [1]struct{}\n\t_ = x[AttachNone-0]\n\t_ = x[AttachCGroupInetIngress-0]\n\t_ = x[AttachCGroupInetEgress-1]\n\t_ = x[AttachCGroupInetSockCreate-2]\n\t_ = x[AttachCGroupSockOps-3]\n\t_ = x[AttachSkSKBStreamParser-4]\n\t_ = x[AttachSkSKBStreamVerdict-5]\n\t_ = x[AttachCGroupDevice-6]\n\t_ = x[AttachSkMsgVerdict-7]\n\t_ = x[AttachCGroupInet4Bind-8]\n\t_ = x[AttachCGroupInet6Bind-9]\n\t_ = x[AttachCGroupInet4Connect-10]\n\t_ = x[AttachCGroupInet6Connect-11]\n\t_ = x[AttachCGroupInet4PostBind-12]\n\t_ = x[AttachCGroupInet6PostBind-13]\n\t_ = x[AttachCGroupUDP4Sendmsg-14]\n\t_ = x[AttachCGroupUDP6Sendmsg-15]\n\t_ = x[AttachLircMode2-16]\n\t_ = x[AttachFlowDissector-17]\n\t_ = x[AttachCGroupSysctl-18]\n\t_ = x[AttachCGroupUDP4Recvmsg-19]\n\t_ = x[AttachCGroupUDP6Recvmsg-20]\n\t_ = x[AttachCGroupGetsockopt-21]\n\t_ = x[AttachCGroupSetsockopt-22]\n\t_ = x[AttachTraceRawTp-23]\n\t_ = x[AttachTraceFEntry-24]\n\t_ = x[AttachTraceFExit-25]\n\t_ = x[AttachModifyReturn-26]\n\t_ = x[AttachLSMMac-27]\n\t_ = x[AttachTraceIter-28]\n\t_ = x[AttachCgroupInet4GetPeername-29]\n\t_ = x[AttachCgroupInet6GetPeername-30]\n\t_ = x[AttachCgroupInet4GetSockname-31]\n\t_ = x[AttachCgroupInet6GetSockname-32]\n\t_ = x[AttachXDPDevMap-33]\n\t_ = x[AttachCgroupInetSockRelease-34]\n\t_ = x[AttachXDPCPUMap-35]\n\t_ = x[AttachSkLookup-36]\n\t_ = x[AttachXDP-37]\n\t_ = x[AttachSkSKBVerdict-38]\n\t_ = x[AttachSkReuseportSelect-39]\n\t_ = x[AttachSkReuseportSelectOrMigrate-40]\n\t_ = x[AttachPerfEvent-41]\n\t_ = x[AttachTraceKprobeMulti-42]\n\t_ = x[AttachLSMCgroup-43]\n\t_ = x[AttachStructOps-44]\n\t_ = x[AttachNetfilter-45]\n\t_ = x[AttachTCXIngress-46]\n\t_ = x[AttachTCXEgress-47]\n\t_ = x[AttachTraceUprobeMulti-48]\n\t_ = x[AttachCgroupUnixConnect-49]\n\t_ = x[AttachCgroupUnixSendmsg-50]\n\t_ = x[AttachCgroupUnixRecvmsg-51]\n\t_ = x[AttachCgroupUnixGetpeername-52]\n\t_ = x[AttachCgroupUnixGetsockname-53]\n\t_ = x[AttachNetkitPrimary-54]\n\t_ = x[AttachNetkitPeer-55]\n}\n\nconst _AttachType_name = \"NoneCGroupInetEgressCGroupInetSockCreateCGroupSockOpsSkSKBStreamParserSkSKBStreamVerdictCGroupDeviceSkMsgVerdictCGroupInet4BindCGroupInet6BindCGroupInet4ConnectCGroupInet6ConnectCGroupInet4PostBindCGroupInet6PostBindCGroupUDP4SendmsgCGroupUDP6SendmsgLircMode2FlowDissectorCGroupSysctlCGroupUDP4RecvmsgCGroupUDP6RecvmsgCGroupGetsockoptCGroupSetsockoptTraceRawTpTraceFEntryTraceFExitModifyReturnLSMMacTraceIterCgroupInet4GetPeernameCgroupInet6GetPeernameCgroupInet4GetSocknameCgroupInet6GetSocknameXDPDevMapCgroupInetSockReleaseXDPCPUMapSkLookupXDPSkSKBVerdictSkReuseportSelectSkReuseportSelectOrMigratePerfEventTraceKprobeMultiLSMCgroupStructOpsNetfilterTCXIngressTCXEgressTraceUprobeMultiCgroupUnixConnectCgroupUnixSendmsgCgroupUnixRecvmsgCgroupUnixGetpeernameCgroupUnixGetsocknameNetkitPrimaryNetkitPeer\"\n\nvar _AttachType_index = [...]uint16{0, 4, 20, 40, 53, 70, 88, 100, 112, 127, 142, 160, 178, 197, 216, 233, 250, 259, 272, 284, 301, 318, 334, 350, 360, 371, 381, 393, 399, 408, 430, 452, 474, 496, 505, 526, 535, 543, 546, 558, 575, 601, 610, 626, 635, 644, 653, 663, 672, 688, 705, 722, 739, 760, 781, 794, 804}\n\nfunc (i AttachType) String() string {\n\tif i >= AttachType(len(_AttachType_index)-1) {\n\t\treturn \"AttachType(\" + strconv.FormatInt(int64(i), 10) + \")\"\n\t}\n\treturn _AttachType_name[_AttachType_index[i]:_AttachType_index[i+1]]\n}\n"
        },
        {
          "name": "btf",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "collection.go",
          "type": "blob",
          "size": 29.0703125,
          "content": "package ebpf\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/kallsyms\"\n\t\"github.com/cilium/ebpf/internal/kconfig\"\n\t\"github.com/cilium/ebpf/internal/linux\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n)\n\n// CollectionOptions control loading a collection into the kernel.\n//\n// Maps and Programs are passed to NewMapWithOptions and NewProgramsWithOptions.\ntype CollectionOptions struct {\n\tMaps     MapOptions\n\tPrograms ProgramOptions\n\n\t// MapReplacements takes a set of Maps that will be used instead of\n\t// creating new ones when loading the CollectionSpec.\n\t//\n\t// For each given Map, there must be a corresponding MapSpec in\n\t// CollectionSpec.Maps, and its type, key/value size, max entries and flags\n\t// must match the values of the MapSpec.\n\t//\n\t// The given Maps are Clone()d before being used in the Collection, so the\n\t// caller can Close() them freely when they are no longer needed.\n\tMapReplacements map[string]*Map\n}\n\n// CollectionSpec describes a collection.\ntype CollectionSpec struct {\n\tMaps     map[string]*MapSpec\n\tPrograms map[string]*ProgramSpec\n\n\t// Variables refer to global variables declared in the ELF. They can be read\n\t// and modified freely before loading the Collection. Modifying them after\n\t// loading has no effect on a running eBPF program.\n\tVariables map[string]*VariableSpec\n\n\t// Types holds type information about Maps and Programs.\n\t// Modifications to Types are currently undefined behaviour.\n\tTypes *btf.Spec\n\n\t// ByteOrder specifies whether the ELF was compiled for\n\t// big-endian or little-endian architectures.\n\tByteOrder binary.ByteOrder\n}\n\n// Copy returns a recursive copy of the spec.\nfunc (cs *CollectionSpec) Copy() *CollectionSpec {\n\tif cs == nil {\n\t\treturn nil\n\t}\n\n\tcpy := CollectionSpec{\n\t\tMaps:      make(map[string]*MapSpec, len(cs.Maps)),\n\t\tPrograms:  make(map[string]*ProgramSpec, len(cs.Programs)),\n\t\tVariables: make(map[string]*VariableSpec, len(cs.Variables)),\n\t\tByteOrder: cs.ByteOrder,\n\t\tTypes:     cs.Types.Copy(),\n\t}\n\n\tfor name, spec := range cs.Maps {\n\t\tcpy.Maps[name] = spec.Copy()\n\t}\n\n\tfor name, spec := range cs.Programs {\n\t\tcpy.Programs[name] = spec.Copy()\n\t}\n\n\tfor name, spec := range cs.Variables {\n\t\tcpy.Variables[name] = spec.copy(&cpy)\n\t}\n\n\treturn &cpy\n}\n\n// RewriteMaps replaces all references to specific maps.\n//\n// Use this function to use pre-existing maps instead of creating new ones\n// when calling NewCollection. Any named maps are removed from CollectionSpec.Maps.\n//\n// Returns an error if a named map isn't used in at least one program.\n//\n// Deprecated: Pass CollectionOptions.MapReplacements when loading the Collection\n// instead.\nfunc (cs *CollectionSpec) RewriteMaps(maps map[string]*Map) error {\n\tfor symbol, m := range maps {\n\t\t// have we seen a program that uses this symbol / map\n\t\tseen := false\n\t\tfor progName, progSpec := range cs.Programs {\n\t\t\terr := progSpec.Instructions.AssociateMap(symbol, m)\n\n\t\t\tswitch {\n\t\t\tcase err == nil:\n\t\t\t\tseen = true\n\n\t\t\tcase errors.Is(err, asm.ErrUnreferencedSymbol):\n\t\t\t\t// Not all programs need to use the map\n\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"program %s: %w\", progName, err)\n\t\t\t}\n\t\t}\n\n\t\tif !seen {\n\t\t\treturn fmt.Errorf(\"map %s not referenced by any programs\", symbol)\n\t\t}\n\n\t\t// Prevent NewCollection from creating rewritten maps\n\t\tdelete(cs.Maps, symbol)\n\t}\n\n\treturn nil\n}\n\n// MissingConstantsError is returned by [CollectionSpec.RewriteConstants].\ntype MissingConstantsError struct {\n\t// The constants missing from .rodata.\n\tConstants []string\n}\n\nfunc (m *MissingConstantsError) Error() string {\n\treturn fmt.Sprintf(\"some constants are missing from .rodata: %s\", strings.Join(m.Constants, \", \"))\n}\n\n// RewriteConstants replaces the value of multiple constants.\n//\n// The constant must be defined like so in the C program:\n//\n//\tvolatile const type foobar;\n//\tvolatile const type foobar = default;\n//\n// Replacement values must be of the same length as the C sizeof(type).\n// If necessary, they are marshalled according to the same rules as\n// map values.\n//\n// From Linux 5.5 the verifier will use constants to eliminate dead code.\n//\n// Returns an error wrapping [MissingConstantsError] if a constant doesn't exist.\n//\n// Deprecated: Use [CollectionSpec.Variables] to interact with constants instead.\n// RewriteConstants is now a wrapper around the VariableSpec API.\nfunc (cs *CollectionSpec) RewriteConstants(consts map[string]interface{}) error {\n\tvar missing []string\n\tfor n, c := range consts {\n\t\tv, ok := cs.Variables[n]\n\t\tif !ok {\n\t\t\tmissing = append(missing, n)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !v.Constant() {\n\t\t\treturn fmt.Errorf(\"variable %s is not a constant\", n)\n\t\t}\n\n\t\tif err := v.Set(c); err != nil {\n\t\t\treturn fmt.Errorf(\"rewriting constant %s: %w\", n, err)\n\t\t}\n\t}\n\n\tif len(missing) != 0 {\n\t\treturn fmt.Errorf(\"rewrite constants: %w\", &MissingConstantsError{Constants: missing})\n\t}\n\n\treturn nil\n}\n\n// Assign the contents of a CollectionSpec to a struct.\n//\n// This function is a shortcut to manually checking the presence\n// of maps and programs in a CollectionSpec. Consider using bpf2go\n// if this sounds useful.\n//\n// 'to' must be a pointer to a struct. A field of the\n// struct is updated with values from Programs, Maps or Variables if it\n// has an `ebpf` tag and its type is *ProgramSpec, *MapSpec or *VariableSpec.\n// The tag's value specifies the name of the program or map as\n// found in the CollectionSpec.\n//\n//\tstruct {\n//\t    Foo     *ebpf.ProgramSpec  `ebpf:\"xdp_foo\"`\n//\t    Bar     *ebpf.MapSpec      `ebpf:\"bar_map\"`\n//\t    Var     *ebpf.VariableSpec `ebpf:\"some_var\"`\n//\t    Ignored int\n//\t}\n//\n// Returns an error if any of the eBPF objects can't be found, or\n// if the same Spec is assigned multiple times.\nfunc (cs *CollectionSpec) Assign(to interface{}) error {\n\tgetValue := func(typ reflect.Type, name string) (interface{}, error) {\n\t\tswitch typ {\n\t\tcase reflect.TypeOf((*ProgramSpec)(nil)):\n\t\t\tif p := cs.Programs[name]; p != nil {\n\t\t\t\treturn p, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing program %q\", name)\n\n\t\tcase reflect.TypeOf((*MapSpec)(nil)):\n\t\t\tif m := cs.Maps[name]; m != nil {\n\t\t\t\treturn m, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing map %q\", name)\n\n\t\tcase reflect.TypeOf((*VariableSpec)(nil)):\n\t\t\tif v := cs.Variables[name]; v != nil {\n\t\t\t\treturn v, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing variable %q\", name)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported type %s\", typ)\n\t\t}\n\t}\n\n\treturn assignValues(to, getValue)\n}\n\n// LoadAndAssign loads Maps and Programs into the kernel and assigns them\n// to a struct.\n//\n// Omitting Map/Program.Close() during application shutdown is an error.\n// See the package documentation for details around Map and Program lifecycle.\n//\n// This function is a shortcut to manually checking the presence\n// of maps and programs in a CollectionSpec. Consider using bpf2go\n// if this sounds useful.\n//\n// 'to' must be a pointer to a struct. A field of the struct is updated with\n// a Program or Map if it has an `ebpf` tag and its type is *Program or *Map.\n// The tag's value specifies the name of the program or map as found in the\n// CollectionSpec. Before updating the struct, the requested objects and their\n// dependent resources are loaded into the kernel and populated with values if\n// specified.\n//\n//\tstruct {\n//\t    Foo     *ebpf.Program `ebpf:\"xdp_foo\"`\n//\t    Bar     *ebpf.Map     `ebpf:\"bar_map\"`\n//\t    Ignored int\n//\t}\n//\n// opts may be nil.\n//\n// Returns an error if any of the fields can't be found, or\n// if the same Map or Program is assigned multiple times.\nfunc (cs *CollectionSpec) LoadAndAssign(to interface{}, opts *CollectionOptions) error {\n\tloader, err := newCollectionLoader(cs, opts)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer loader.close()\n\n\t// Support assigning Programs and Maps, lazy-loading the required objects.\n\tassignedMaps := make(map[string]bool)\n\tassignedProgs := make(map[string]bool)\n\tassignedVars := make(map[string]bool)\n\n\tgetValue := func(typ reflect.Type, name string) (interface{}, error) {\n\t\tswitch typ {\n\n\t\tcase reflect.TypeOf((*Program)(nil)):\n\t\t\tassignedProgs[name] = true\n\t\t\treturn loader.loadProgram(name)\n\n\t\tcase reflect.TypeOf((*Map)(nil)):\n\t\t\tassignedMaps[name] = true\n\t\t\treturn loader.loadMap(name)\n\n\t\tcase reflect.TypeOf((*Variable)(nil)):\n\t\t\tassignedVars[name] = true\n\t\t\treturn loader.loadVariable(name)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported type %s\", typ)\n\t\t}\n\t}\n\n\t// Load the Maps and Programs requested by the annotated struct.\n\tif err := assignValues(to, getValue); err != nil {\n\t\treturn err\n\t}\n\n\t// Populate the requested maps. Has a chance of lazy-loading other dependent maps.\n\tif err := loader.populateDeferredMaps(); err != nil {\n\t\treturn err\n\t}\n\n\t// Evaluate the loader's objects after all (lazy)loading has taken place.\n\tfor n, m := range loader.maps {\n\t\tswitch m.typ {\n\t\tcase ProgramArray:\n\t\t\t// Require all lazy-loaded ProgramArrays to be assigned to the given object.\n\t\t\t// The kernel empties a ProgramArray once the last user space reference\n\t\t\t// to it closes, which leads to failed tail calls. Combined with the library\n\t\t\t// closing map fds via GC finalizers this can lead to surprising behaviour.\n\t\t\t// Only allow unassigned ProgramArrays when the library hasn't pre-populated\n\t\t\t// any entries from static value declarations. At this point, we know the map\n\t\t\t// is empty and there's no way for the caller to interact with the map going\n\t\t\t// forward.\n\t\t\tif !assignedMaps[n] && len(cs.Maps[n].Contents) > 0 {\n\t\t\t\treturn fmt.Errorf(\"ProgramArray %s must be assigned to prevent missed tail calls\", n)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Prevent loader.cleanup() from closing assigned Maps and Programs.\n\tfor m := range assignedMaps {\n\t\tdelete(loader.maps, m)\n\t}\n\tfor p := range assignedProgs {\n\t\tdelete(loader.programs, p)\n\t}\n\tfor p := range assignedVars {\n\t\tdelete(loader.vars, p)\n\t}\n\n\treturn nil\n}\n\n// Collection is a collection of live BPF resources present in the kernel.\ntype Collection struct {\n\tPrograms map[string]*Program\n\tMaps     map[string]*Map\n\n\t// Variables contains global variables used by the Collection's program(s). On\n\t// kernels older than 5.5, most interactions with Variables return\n\t// [ErrNotSupported].\n\tVariables map[string]*Variable\n}\n\n// NewCollection creates a Collection from the given spec, creating and\n// loading its declared resources into the kernel.\n//\n// Omitting Collection.Close() during application shutdown is an error.\n// See the package documentation for details around Map and Program lifecycle.\nfunc NewCollection(spec *CollectionSpec) (*Collection, error) {\n\treturn NewCollectionWithOptions(spec, CollectionOptions{})\n}\n\n// NewCollectionWithOptions creates a Collection from the given spec using\n// options, creating and loading its declared resources into the kernel.\n//\n// Omitting Collection.Close() during application shutdown is an error.\n// See the package documentation for details around Map and Program lifecycle.\nfunc NewCollectionWithOptions(spec *CollectionSpec, opts CollectionOptions) (*Collection, error) {\n\tloader, err := newCollectionLoader(spec, &opts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer loader.close()\n\n\t// Create maps first, as their fds need to be linked into programs.\n\tfor mapName := range spec.Maps {\n\t\tif _, err := loader.loadMap(mapName); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfor progName, prog := range spec.Programs {\n\t\tif prog.Type == UnspecifiedProgram {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, err := loader.loadProgram(progName); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfor varName := range spec.Variables {\n\t\tif _, err := loader.loadVariable(varName); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Maps can contain Program and Map stubs, so populate them after\n\t// all Maps and Programs have been successfully loaded.\n\tif err := loader.populateDeferredMaps(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Prevent loader.cleanup from closing maps, programs and vars.\n\tmaps, progs, vars := loader.maps, loader.programs, loader.vars\n\tloader.maps, loader.programs, loader.vars = nil, nil, nil\n\n\treturn &Collection{\n\t\tprogs,\n\t\tmaps,\n\t\tvars,\n\t}, nil\n}\n\ntype collectionLoader struct {\n\tcoll     *CollectionSpec\n\topts     *CollectionOptions\n\tmaps     map[string]*Map\n\tprograms map[string]*Program\n\tvars     map[string]*Variable\n}\n\nfunc newCollectionLoader(coll *CollectionSpec, opts *CollectionOptions) (*collectionLoader, error) {\n\tif opts == nil {\n\t\topts = &CollectionOptions{}\n\t}\n\n\t// Check for existing MapSpecs in the CollectionSpec for all provided replacement maps.\n\tfor name, m := range opts.MapReplacements {\n\t\tspec, ok := coll.Maps[name]\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"replacement map %s not found in CollectionSpec\", name)\n\t\t}\n\n\t\tif err := spec.Compatible(m); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"using replacement map %s: %w\", spec.Name, err)\n\t\t}\n\t}\n\n\tif err := populateKallsyms(coll.Programs); err != nil {\n\t\treturn nil, fmt.Errorf(\"populating kallsyms caches: %w\", err)\n\t}\n\n\treturn &collectionLoader{\n\t\tcoll,\n\t\topts,\n\t\tmake(map[string]*Map),\n\t\tmake(map[string]*Program),\n\t\tmake(map[string]*Variable),\n\t}, nil\n}\n\n// populateKallsyms populates kallsyms caches, making lookups cheaper later on\n// during individual program loading. Since we have less context available\n// at those stages, we batch the lookups here instead to avoid redundant work.\nfunc populateKallsyms(progs map[string]*ProgramSpec) error {\n\t// Look up associated kernel modules for all symbols referenced by\n\t// ProgramSpec.AttachTo for program types that support attaching to kmods.\n\tmods := make(map[string]string)\n\tfor _, p := range progs {\n\t\tif p.AttachTo != \"\" && p.targetsKernelModule() {\n\t\t\tmods[p.AttachTo] = \"\"\n\t\t}\n\t}\n\tif len(mods) != 0 {\n\t\tif err := kallsyms.AssignModules(mods); err != nil {\n\t\t\treturn fmt.Errorf(\"getting modules from kallsyms: %w\", err)\n\t\t}\n\t}\n\n\t// Look up addresses of all kernel symbols referenced by all programs.\n\taddrs := make(map[string]uint64)\n\tfor _, p := range progs {\n\t\titer := p.Instructions.Iterate()\n\t\tfor iter.Next() {\n\t\t\tins := iter.Ins\n\t\t\tmeta, _ := ins.Metadata.Get(ksymMetaKey{}).(*ksymMeta)\n\t\t\tif meta != nil {\n\t\t\t\taddrs[meta.Name] = 0\n\t\t\t}\n\t\t}\n\t}\n\tif len(addrs) != 0 {\n\t\tif err := kallsyms.AssignAddresses(addrs); err != nil {\n\t\t\treturn fmt.Errorf(\"getting addresses from kallsyms: %w\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// close all resources left over in the collectionLoader.\nfunc (cl *collectionLoader) close() {\n\tfor _, m := range cl.maps {\n\t\tm.Close()\n\t}\n\tfor _, p := range cl.programs {\n\t\tp.Close()\n\t}\n}\n\nfunc (cl *collectionLoader) loadMap(mapName string) (*Map, error) {\n\tif m := cl.maps[mapName]; m != nil {\n\t\treturn m, nil\n\t}\n\n\tmapSpec := cl.coll.Maps[mapName]\n\tif mapSpec == nil {\n\t\treturn nil, fmt.Errorf(\"missing map %s\", mapName)\n\t}\n\n\tif replaceMap, ok := cl.opts.MapReplacements[mapName]; ok {\n\t\t// Clone the map to avoid closing user's map later on.\n\t\tm, err := replaceMap.Clone()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcl.maps[mapName] = m\n\t\treturn m, nil\n\t}\n\n\t// Defer setting the mmapable flag on maps until load time. This avoids the\n\t// MapSpec having different flags on some kernel versions. Also avoid running\n\t// syscalls during ELF loading, so platforms like wasm can also parse an ELF.\n\tif isDataSection(mapSpec.Name) && haveMmapableMaps() == nil {\n\t\tmapSpec.Flags |= sys.BPF_F_MMAPABLE\n\t}\n\n\tm, err := newMapWithOptions(mapSpec, cl.opts.Maps)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"map %s: %w\", mapName, err)\n\t}\n\n\t// Finalize 'scalar' maps that don't refer to any other eBPF resources\n\t// potentially pending creation. This is needed for frozen maps like .rodata\n\t// that need to be finalized before invoking the verifier.\n\tif !mapSpec.Type.canStoreMapOrProgram() {\n\t\tif err := m.finalize(mapSpec); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"finalizing map %s: %w\", mapName, err)\n\t\t}\n\t}\n\n\tcl.maps[mapName] = m\n\treturn m, nil\n}\n\nfunc (cl *collectionLoader) loadProgram(progName string) (*Program, error) {\n\tif prog := cl.programs[progName]; prog != nil {\n\t\treturn prog, nil\n\t}\n\n\tprogSpec := cl.coll.Programs[progName]\n\tif progSpec == nil {\n\t\treturn nil, fmt.Errorf(\"unknown program %s\", progName)\n\t}\n\n\t// Bail out early if we know the kernel is going to reject the program.\n\t// This skips loading map dependencies, saving some cleanup work later.\n\tif progSpec.Type == UnspecifiedProgram {\n\t\treturn nil, fmt.Errorf(\"cannot load program %s: program type is unspecified\", progName)\n\t}\n\n\tprogSpec = progSpec.Copy()\n\n\t// Rewrite any reference to a valid map in the program's instructions,\n\t// which includes all of its dependencies.\n\tfor i := range progSpec.Instructions {\n\t\tins := &progSpec.Instructions[i]\n\n\t\tif !ins.IsLoadFromMap() || ins.Reference() == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Don't overwrite map loads containing non-zero map fd's,\n\t\t// they can be manually included by the caller.\n\t\t// Map FDs/IDs are placed in the lower 32 bits of Constant.\n\t\tif int32(ins.Constant) > 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tm, err := cl.loadMap(ins.Reference())\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"program %s: %w\", progName, err)\n\t\t}\n\n\t\tif err := ins.AssociateMap(m); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"program %s: map %s: %w\", progName, ins.Reference(), err)\n\t\t}\n\t}\n\n\tprog, err := newProgramWithOptions(progSpec, cl.opts.Programs)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"program %s: %w\", progName, err)\n\t}\n\n\tcl.programs[progName] = prog\n\treturn prog, nil\n}\n\nfunc (cl *collectionLoader) loadVariable(varName string) (*Variable, error) {\n\tif v := cl.vars[varName]; v != nil {\n\t\treturn v, nil\n\t}\n\n\tvarSpec := cl.coll.Variables[varName]\n\tif varSpec == nil {\n\t\treturn nil, fmt.Errorf(\"unknown variable %s\", varName)\n\t}\n\n\t// Get the key of the VariableSpec's MapSpec in the CollectionSpec.\n\tvar mapName string\n\tfor n, ms := range cl.coll.Maps {\n\t\tif ms == varSpec.m {\n\t\t\tmapName = n\n\t\t\tbreak\n\t\t}\n\t}\n\tif mapName == \"\" {\n\t\treturn nil, fmt.Errorf(\"variable %s: underlying MapSpec %s was removed from CollectionSpec\", varName, varSpec.m.Name)\n\t}\n\n\tm, err := cl.loadMap(mapName)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"variable %s: %w\", varName, err)\n\t}\n\n\t// If the kernel is too old or the underlying map was created without\n\t// BPF_F_MMAPABLE, [Map.Memory] will return ErrNotSupported. In this case,\n\t// emit a Variable with a nil Memory. This keeps Collection{Spec}.Variables\n\t// consistent across systems with different feature sets without breaking\n\t// LoadAndAssign.\n\tmm, err := m.Memory()\n\tif err != nil && !errors.Is(err, ErrNotSupported) {\n\t\treturn nil, fmt.Errorf(\"variable %s: getting memory for map %s: %w\", varName, mapName, err)\n\t}\n\n\tv, err := newVariable(\n\t\tvarSpec.name,\n\t\tvarSpec.offset,\n\t\tvarSpec.size,\n\t\tvarSpec.t,\n\t\tmm,\n\t)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"variable %s: %w\", varName, err)\n\t}\n\n\tcl.vars[varName] = v\n\treturn v, nil\n}\n\n// populateDeferredMaps iterates maps holding programs or other maps and loads\n// any dependencies. Populates all maps in cl and freezes them if specified.\nfunc (cl *collectionLoader) populateDeferredMaps() error {\n\tfor mapName, m := range cl.maps {\n\t\tmapSpec, ok := cl.coll.Maps[mapName]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"missing map spec %s\", mapName)\n\t\t}\n\n\t\t// Scalar maps without Map or Program references are finalized during\n\t\t// creation. Don't finalize them again.\n\t\tif !mapSpec.Type.canStoreMapOrProgram() {\n\t\t\tcontinue\n\t\t}\n\n\t\tmapSpec = mapSpec.Copy()\n\n\t\t// MapSpecs that refer to inner maps or programs within the same\n\t\t// CollectionSpec do so using strings. These strings are used as the key\n\t\t// to look up the respective object in the Maps or Programs fields.\n\t\t// Resolve those references to actual Map or Program resources that\n\t\t// have been loaded into the kernel.\n\t\tfor i, kv := range mapSpec.Contents {\n\t\t\tobjName, ok := kv.Value.(string)\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch t := mapSpec.Type; {\n\t\t\tcase t.canStoreProgram():\n\t\t\t\t// loadProgram is idempotent and could return an existing Program.\n\t\t\t\tprog, err := cl.loadProgram(objName)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"loading program %s, for map %s: %w\", objName, mapName, err)\n\t\t\t\t}\n\t\t\t\tmapSpec.Contents[i] = MapKV{kv.Key, prog}\n\n\t\t\tcase t.canStoreMap():\n\t\t\t\t// loadMap is idempotent and could return an existing Map.\n\t\t\t\tinnerMap, err := cl.loadMap(objName)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"loading inner map %s, for map %s: %w\", objName, mapName, err)\n\t\t\t\t}\n\t\t\t\tmapSpec.Contents[i] = MapKV{kv.Key, innerMap}\n\t\t\t}\n\t\t}\n\n\t\t// Populate and freeze the map if specified.\n\t\tif err := m.finalize(mapSpec); err != nil {\n\t\t\treturn fmt.Errorf(\"populating map %s: %w\", mapName, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// resolveKconfig resolves all variables declared in .kconfig and populates\n// m.Contents. Does nothing if the given m.Contents is non-empty.\nfunc resolveKconfig(m *MapSpec) error {\n\tds, ok := m.Value.(*btf.Datasec)\n\tif !ok {\n\t\treturn errors.New(\"map value is not a Datasec\")\n\t}\n\n\ttype configInfo struct {\n\t\toffset uint32\n\t\tsize   uint32\n\t\ttyp    btf.Type\n\t}\n\n\tconfigs := make(map[string]configInfo)\n\n\tdata := make([]byte, ds.Size)\n\tfor _, vsi := range ds.Vars {\n\t\tv := vsi.Type.(*btf.Var)\n\t\tn := v.TypeName()\n\n\t\tswitch n {\n\t\tcase \"LINUX_KERNEL_VERSION\":\n\t\t\tif integer, ok := v.Type.(*btf.Int); !ok || integer.Size != 4 {\n\t\t\t\treturn fmt.Errorf(\"variable %s must be a 32 bits integer, got %s\", n, v.Type)\n\t\t\t}\n\n\t\t\tkv, err := linux.KernelVersion()\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"getting kernel version: %w\", err)\n\t\t\t}\n\t\t\tinternal.NativeEndian.PutUint32(data[vsi.Offset:], kv.Kernel())\n\n\t\tcase \"LINUX_HAS_SYSCALL_WRAPPER\":\n\t\t\tinteger, ok := v.Type.(*btf.Int)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"variable %s must be an integer, got %s\", n, v.Type)\n\t\t\t}\n\t\t\tvar value uint64 = 1\n\t\t\tif err := haveSyscallWrapper(); errors.Is(err, ErrNotSupported) {\n\t\t\t\tvalue = 0\n\t\t\t} else if err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to derive a value for LINUX_HAS_SYSCALL_WRAPPER: %w\", err)\n\t\t\t}\n\n\t\t\tif err := kconfig.PutInteger(data[vsi.Offset:], integer, value); err != nil {\n\t\t\t\treturn fmt.Errorf(\"set LINUX_HAS_SYSCALL_WRAPPER: %w\", err)\n\t\t\t}\n\n\t\tdefault: // Catch CONFIG_*.\n\t\t\tconfigs[n] = configInfo{\n\t\t\t\toffset: vsi.Offset,\n\t\t\t\tsize:   vsi.Size,\n\t\t\t\ttyp:    v.Type,\n\t\t\t}\n\t\t}\n\t}\n\n\t// We only parse kconfig file if a CONFIG_* variable was found.\n\tif len(configs) > 0 {\n\t\tf, err := linux.FindKConfig()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot find a kconfig file: %w\", err)\n\t\t}\n\t\tdefer f.Close()\n\n\t\tfilter := make(map[string]struct{}, len(configs))\n\t\tfor config := range configs {\n\t\t\tfilter[config] = struct{}{}\n\t\t}\n\n\t\tkernelConfig, err := kconfig.Parse(f, filter)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot parse kconfig file: %w\", err)\n\t\t}\n\n\t\tfor n, info := range configs {\n\t\t\tvalue, ok := kernelConfig[n]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"config option %q does not exist on this kernel\", n)\n\t\t\t}\n\n\t\t\terr := kconfig.PutValue(data[info.offset:info.offset+info.size], info.typ, value)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"problem adding value for %s: %w\", n, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tm.Contents = []MapKV{{uint32(0), data}}\n\n\treturn nil\n}\n\n// LoadCollection reads an object file and creates and loads its declared\n// resources into the kernel.\n//\n// Omitting Collection.Close() during application shutdown is an error.\n// See the package documentation for details around Map and Program lifecycle.\nfunc LoadCollection(file string) (*Collection, error) {\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn NewCollection(spec)\n}\n\n// Assign the contents of a Collection to a struct.\n//\n// This function bridges functionality between bpf2go generated\n// code and any functionality better implemented in Collection.\n//\n// 'to' must be a pointer to a struct. A field of the\n// struct is updated with values from Programs or Maps if it\n// has an `ebpf` tag and its type is *Program or *Map.\n// The tag's value specifies the name of the program or map as\n// found in the CollectionSpec.\n//\n//\tstruct {\n//\t    Foo     *ebpf.Program `ebpf:\"xdp_foo\"`\n//\t    Bar     *ebpf.Map     `ebpf:\"bar_map\"`\n//\t    Ignored int\n//\t}\n//\n// Returns an error if any of the eBPF objects can't be found, or\n// if the same Map or Program is assigned multiple times.\n//\n// Ownership and Close()ing responsibility is transferred to `to`\n// for any successful assigns. On error `to` is left in an undefined state.\nfunc (coll *Collection) Assign(to interface{}) error {\n\tassignedMaps := make(map[string]bool)\n\tassignedProgs := make(map[string]bool)\n\tassignedVars := make(map[string]bool)\n\n\t// Assign() only transfers already-loaded Maps and Programs. No extra\n\t// loading is done.\n\tgetValue := func(typ reflect.Type, name string) (interface{}, error) {\n\t\tswitch typ {\n\n\t\tcase reflect.TypeOf((*Program)(nil)):\n\t\t\tif p := coll.Programs[name]; p != nil {\n\t\t\t\tassignedProgs[name] = true\n\t\t\t\treturn p, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing program %q\", name)\n\n\t\tcase reflect.TypeOf((*Map)(nil)):\n\t\t\tif m := coll.Maps[name]; m != nil {\n\t\t\t\tassignedMaps[name] = true\n\t\t\t\treturn m, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing map %q\", name)\n\n\t\tcase reflect.TypeOf((*Variable)(nil)):\n\t\t\tif v := coll.Variables[name]; v != nil {\n\t\t\t\tassignedVars[name] = true\n\t\t\t\treturn v, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"missing variable %q\", name)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported type %s\", typ)\n\t\t}\n\t}\n\n\tif err := assignValues(to, getValue); err != nil {\n\t\treturn err\n\t}\n\n\t// Finalize ownership transfer\n\tfor p := range assignedProgs {\n\t\tdelete(coll.Programs, p)\n\t}\n\tfor m := range assignedMaps {\n\t\tdelete(coll.Maps, m)\n\t}\n\tfor s := range assignedVars {\n\t\tdelete(coll.Variables, s)\n\t}\n\n\treturn nil\n}\n\n// Close frees all maps and programs associated with the collection.\n//\n// The collection mustn't be used afterwards.\nfunc (coll *Collection) Close() {\n\tfor _, prog := range coll.Programs {\n\t\tprog.Close()\n\t}\n\tfor _, m := range coll.Maps {\n\t\tm.Close()\n\t}\n}\n\n// DetachMap removes the named map from the Collection.\n//\n// This means that a later call to Close() will not affect this map.\n//\n// Returns nil if no map of that name exists.\nfunc (coll *Collection) DetachMap(name string) *Map {\n\tm := coll.Maps[name]\n\tdelete(coll.Maps, name)\n\treturn m\n}\n\n// DetachProgram removes the named program from the Collection.\n//\n// This means that a later call to Close() will not affect this program.\n//\n// Returns nil if no program of that name exists.\nfunc (coll *Collection) DetachProgram(name string) *Program {\n\tp := coll.Programs[name]\n\tdelete(coll.Programs, name)\n\treturn p\n}\n\n// structField represents a struct field containing the ebpf struct tag.\ntype structField struct {\n\treflect.StructField\n\tvalue reflect.Value\n}\n\n// ebpfFields extracts field names tagged with 'ebpf' from a struct type.\n// Keep track of visited types to avoid infinite recursion.\nfunc ebpfFields(structVal reflect.Value, visited map[reflect.Type]bool) ([]structField, error) {\n\tif visited == nil {\n\t\tvisited = make(map[reflect.Type]bool)\n\t}\n\n\tstructType := structVal.Type()\n\tif structType.Kind() != reflect.Struct {\n\t\treturn nil, fmt.Errorf(\"%s is not a struct\", structType)\n\t}\n\n\tif visited[structType] {\n\t\treturn nil, fmt.Errorf(\"recursion on type %s\", structType)\n\t}\n\n\tfields := make([]structField, 0, structType.NumField())\n\tfor i := 0; i < structType.NumField(); i++ {\n\t\tfield := structField{structType.Field(i), structVal.Field(i)}\n\n\t\t// If the field is tagged, gather it and move on.\n\t\tname := field.Tag.Get(\"ebpf\")\n\t\tif name != \"\" {\n\t\t\tfields = append(fields, field)\n\t\t\tcontinue\n\t\t}\n\n\t\t// If the field does not have an ebpf tag, but is a struct or a pointer\n\t\t// to a struct, attempt to gather its fields as well.\n\t\tvar v reflect.Value\n\t\tswitch field.Type.Kind() {\n\t\tcase reflect.Ptr:\n\t\t\tif field.Type.Elem().Kind() != reflect.Struct {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif field.value.IsNil() {\n\t\t\t\treturn nil, fmt.Errorf(\"nil pointer to %s\", structType)\n\t\t\t}\n\n\t\t\t// Obtain the destination type of the pointer.\n\t\t\tv = field.value.Elem()\n\n\t\tcase reflect.Struct:\n\t\t\t// Reference the value's type directly.\n\t\t\tv = field.value\n\n\t\tdefault:\n\t\t\tcontinue\n\t\t}\n\n\t\tinner, err := ebpfFields(v, visited)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"field %s: %w\", field.Name, err)\n\t\t}\n\n\t\tfields = append(fields, inner...)\n\t}\n\n\treturn fields, nil\n}\n\n// assignValues attempts to populate all fields of 'to' tagged with 'ebpf'.\n//\n// getValue is called for every tagged field of 'to' and must return the value\n// to be assigned to the field with the given typ and name.\nfunc assignValues(to interface{},\n\tgetValue func(typ reflect.Type, name string) (interface{}, error)) error {\n\n\ttoValue := reflect.ValueOf(to)\n\tif toValue.Type().Kind() != reflect.Ptr {\n\t\treturn fmt.Errorf(\"%T is not a pointer to struct\", to)\n\t}\n\n\tif toValue.IsNil() {\n\t\treturn fmt.Errorf(\"nil pointer to %T\", to)\n\t}\n\n\tfields, err := ebpfFields(toValue.Elem(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttype elem struct {\n\t\t// Either *Map or *Program\n\t\ttyp  reflect.Type\n\t\tname string\n\t}\n\n\tassigned := make(map[elem]string)\n\tfor _, field := range fields {\n\t\t// Get string value the field is tagged with.\n\t\ttag := field.Tag.Get(\"ebpf\")\n\t\tif strings.Contains(tag, \",\") {\n\t\t\treturn fmt.Errorf(\"field %s: ebpf tag contains a comma\", field.Name)\n\t\t}\n\n\t\t// Check if the eBPF object with the requested\n\t\t// type and tag was already assigned elsewhere.\n\t\te := elem{field.Type, tag}\n\t\tif af := assigned[e]; af != \"\" {\n\t\t\treturn fmt.Errorf(\"field %s: object %q was already assigned to %s\", field.Name, tag, af)\n\t\t}\n\n\t\t// Get the eBPF object referred to by the tag.\n\t\tvalue, err := getValue(field.Type, tag)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"field %s: %w\", field.Name, err)\n\t\t}\n\n\t\tif !field.value.CanSet() {\n\t\t\treturn fmt.Errorf(\"field %s: can't set value\", field.Name)\n\t\t}\n\t\tfield.value.Set(reflect.ValueOf(value))\n\n\t\tassigned[e] = field.Name\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "collection_test.go",
          "type": "blob",
          "size": 15.572265625,
          "content": "package ebpf\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/go-quicktest/qt\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n\t\"github.com/cilium/ebpf/internal/testutils/fdtrace\"\n)\n\nfunc TestMain(m *testing.M) {\n\tfdtrace.TestMain(m)\n}\n\nfunc TestCollectionSpecNotModified(t *testing.T) {\n\tcs := CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"my-map\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"test\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R1, 0, asm.DWord).WithReference(\"my-map\"),\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\tcoll, err := NewCollection(&cs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tcoll.Close()\n\n\tif cs.Programs[\"test\"].Instructions[0].Constant != 0 {\n\t\tt.Error(\"Creating a collection modifies input spec\")\n\t}\n}\n\nfunc TestCollectionSpecCopy(t *testing.T) {\n\tms := &MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t}\n\n\tcs := &CollectionSpec{\n\t\tmap[string]*MapSpec{\"my-map\": ms},\n\t\tmap[string]*ProgramSpec{\n\t\t\t\"test\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadMapPtr(asm.R1, 0),\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t\tmap[string]*VariableSpec{\n\t\t\t\"my-var\": {\n\t\t\t\tname:   \"my-var\",\n\t\t\t\toffset: 0,\n\t\t\t\tsize:   4,\n\t\t\t\tm:      ms,\n\t\t\t},\n\t\t},\n\t\t&btf.Spec{},\n\t\tbinary.LittleEndian,\n\t}\n\n\tqt.Check(t, qt.IsNil((*CollectionSpec)(nil).Copy()))\n\tqt.Assert(t, testutils.IsDeepCopy(cs.Copy(), cs))\n}\n\nfunc TestCollectionSpecLoadCopy(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/loader-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tspec2 := spec.Copy()\n\n\tvar objs struct {\n\t\tProg *Program `ebpf:\"xdp_prog\"`\n\t}\n\n\terr = spec.LoadAndAssign(&objs, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Loading original spec:\", err)\n\t}\n\tdefer objs.Prog.Close()\n\n\tif err := spec2.LoadAndAssign(&objs, nil); err != nil {\n\t\tt.Fatal(\"Loading copied spec:\", err)\n\t}\n\tdefer objs.Prog.Close()\n}\n\nfunc TestCollectionSpecRewriteMaps(t *testing.T) {\n\tinsns := asm.Instructions{\n\t\t// R1 map\n\t\tasm.LoadMapPtr(asm.R1, 0).WithReference(\"test-map\"),\n\t\t// R2 key\n\t\tasm.Mov.Reg(asm.R2, asm.R10),\n\t\tasm.Add.Imm(asm.R2, -4),\n\t\tasm.StoreImm(asm.R2, 0, 0, asm.Word),\n\t\t// Lookup map[0]\n\t\tasm.FnMapLookupElem.Call(),\n\t\tasm.JEq.Imm(asm.R0, 0, \"ret\"),\n\t\tasm.LoadMem(asm.R0, asm.R0, 0, asm.Word),\n\t\tasm.Return().WithSymbol(\"ret\"),\n\t}\n\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"test-map\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"test-prog\": {\n\t\t\t\tType:         SocketFilter,\n\t\t\t\tInstructions: insns,\n\t\t\t\tLicense:      \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\t// Override the map with another one\n\tnewMap, err := NewMap(cs.Maps[\"test-map\"])\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer newMap.Close()\n\n\terr = newMap.Put(uint32(0), uint32(2))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = cs.RewriteMaps(map[string]*Map{\n\t\t\"test-map\": newMap,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif cs.Maps[\"test-map\"] != nil {\n\t\tt.Error(\"RewriteMaps doesn't remove map from CollectionSpec.Maps\")\n\t}\n\n\tcoll, err := NewCollection(cs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer coll.Close()\n\n\tret, _, err := coll.Programs[\"test-prog\"].Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 2 {\n\t\tt.Fatal(\"new / override map not used\")\n\t}\n}\n\nfunc TestCollectionSpecMapReplacements(t *testing.T) {\n\tinsns := asm.Instructions{\n\t\t// R1 map\n\t\tasm.LoadMapPtr(asm.R1, 0).WithReference(\"test-map\"),\n\t\t// R2 key\n\t\tasm.Mov.Reg(asm.R2, asm.R10),\n\t\tasm.Add.Imm(asm.R2, -4),\n\t\tasm.StoreImm(asm.R2, 0, 0, asm.Word),\n\t\t// Lookup map[0]\n\t\tasm.FnMapLookupElem.Call(),\n\t\tasm.JEq.Imm(asm.R0, 0, \"ret\"),\n\t\tasm.LoadMem(asm.R0, asm.R0, 0, asm.Word),\n\t\tasm.Return().WithSymbol(\"ret\"),\n\t}\n\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"test-map\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"test-prog\": {\n\t\t\t\tType:         SocketFilter,\n\t\t\t\tInstructions: insns,\n\t\t\t\tLicense:      \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\t// Replace the map with another one\n\tnewMap, err := NewMap(cs.Maps[\"test-map\"])\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer newMap.Close()\n\n\terr = newMap.Put(uint32(0), uint32(2))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcoll, err := NewCollectionWithOptions(cs, CollectionOptions{\n\t\tMapReplacements: map[string]*Map{\n\t\t\t\"test-map\": newMap,\n\t\t},\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer coll.Close()\n\n\tret, _, err := coll.Programs[\"test-prog\"].Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 2 {\n\t\tt.Fatal(\"new / override map not used\")\n\t}\n\n\t// Check that newMap isn't closed when the collection is closed\n\tcoll.Close()\n\terr = newMap.Put(uint32(0), uint32(3))\n\tif err != nil {\n\t\tt.Fatalf(\"failed to update replaced map: %s\", err)\n\t}\n}\nfunc TestCollectionSpecMapReplacements_NonExistingMap(t *testing.T) {\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"test-map\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t}\n\n\t// Override non-existing map\n\tnewMap, err := NewMap(cs.Maps[\"test-map\"])\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer newMap.Close()\n\n\tcoll, err := NewCollectionWithOptions(cs, CollectionOptions{\n\t\tMapReplacements: map[string]*Map{\n\t\t\t\"non-existing-map\": newMap,\n\t\t},\n\t})\n\tif err == nil {\n\t\tcoll.Close()\n\t\tt.Fatal(\"Overriding a non existing map did not fail\")\n\t}\n}\n\nfunc TestCollectionSpecMapReplacements_SpecMismatch(t *testing.T) {\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"test-map\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t}\n\n\t// Override map with mismatching spec\n\tnewMap, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  8, // this is different\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\t// Map fd is duplicated by MapReplacements, this one can be safely closed.\n\tdefer newMap.Close()\n\n\tcoll, err := NewCollectionWithOptions(cs, CollectionOptions{\n\t\tMapReplacements: map[string]*Map{\n\t\t\t\"test-map\": newMap,\n\t\t},\n\t})\n\tif err == nil {\n\t\tcoll.Close()\n\t\tt.Fatal(\"Overriding a map with a mismatching spec did not fail\")\n\t}\n\tif !errors.Is(err, ErrMapIncompatible) {\n\t\tt.Fatalf(\"Overriding a map with a mismatching spec failed with the wrong error\")\n\t}\n}\n\nfunc TestCollectionSpec_LoadAndAssign_LazyLoading(t *testing.T) {\n\tspec := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"valid\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t\t\"bogus\": {\n\t\t\t\tType:       Array,\n\t\t\t\tMaxEntries: 0,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"valid\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t\t\"bogus\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\t// Undefined return value is rejected\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\tvar objs struct {\n\t\tProg *Program `ebpf:\"valid\"`\n\t\tMap  *Map     `ebpf:\"valid\"`\n\t}\n\n\tif err := spec.LoadAndAssign(&objs, nil); err != nil {\n\t\tt.Fatal(\"Assign loads a map or program that isn't requested in the struct:\", err)\n\t}\n\tdefer objs.Prog.Close()\n\tdefer objs.Map.Close()\n\n\tif objs.Prog == nil {\n\t\tt.Error(\"Program is nil\")\n\t}\n\n\tif objs.Map == nil {\n\t\tt.Error(\"Map is nil\")\n\t}\n}\n\nfunc TestCollectionSpecAssign(t *testing.T) {\n\tvar specs struct {\n\t\tProgram  *ProgramSpec  `ebpf:\"prog1\"`\n\t\tMap      *MapSpec      `ebpf:\"map1\"`\n\t\tVariable *VariableSpec `ebpf:\"var1\"`\n\t}\n\n\tmapSpec := &MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t}\n\tprogSpec := &ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}\n\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"map1\": mapSpec,\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"prog1\": progSpec,\n\t\t},\n\t\tVariables: map[string]*VariableSpec{\n\t\t\t\"var1\": {},\n\t\t},\n\t}\n\n\tif err := cs.Assign(&specs); err != nil {\n\t\tt.Fatal(\"Can't assign spec:\", err)\n\t}\n\n\tif specs.Program != progSpec {\n\t\tt.Fatalf(\"Expected Program to be %p, got %p\", progSpec, specs.Program)\n\t}\n\n\tif specs.Map != mapSpec {\n\t\tt.Fatalf(\"Expected Map to be %p, got %p\", mapSpec, specs.Map)\n\t}\n\n\tif err := cs.Assign(new(int)); err == nil {\n\t\tt.Fatal(\"Assign allows to besides *struct\")\n\t}\n\n\tif err := cs.Assign(new(struct{ Foo int })); err != nil {\n\t\tt.Fatal(\"Assign doesn't ignore untagged fields\")\n\t}\n\n\tunexported := new(struct {\n\t\tfoo *MapSpec `ebpf:\"map1\"`\n\t})\n\n\tif err := cs.Assign(unexported); err == nil {\n\t\tt.Error(\"Assign should return an error on unexported fields\")\n\t}\n}\n\nfunc TestAssignValues(t *testing.T) {\n\tzero := func(t reflect.Type, name string) (interface{}, error) {\n\t\treturn reflect.Zero(t).Interface(), nil\n\t}\n\n\ttype t1 struct {\n\t\tBar int `ebpf:\"bar\"`\n\t}\n\n\ttype t2 struct {\n\t\tt1\n\t\tFoo int `ebpf:\"foo\"`\n\t}\n\n\ttype t2ptr struct {\n\t\t*t1\n\t\tFoo int `ebpf:\"foo\"`\n\t}\n\n\tinvalid := []struct {\n\t\tname string\n\t\tto   interface{}\n\t}{\n\t\t{\"non-struct\", 1},\n\t\t{\"non-pointer struct\", t1{}},\n\t\t{\"pointer to non-struct\", new(int)},\n\t\t{\"embedded nil pointer\", &t2ptr{}},\n\t\t{\"unexported field\", new(struct {\n\t\t\tfoo int `ebpf:\"foo\"`\n\t\t})},\n\t\t{\"identical tag\", new(struct {\n\t\t\tFoo1 int `ebpf:\"foo\"`\n\t\t\tFoo2 int `ebpf:\"foo\"`\n\t\t})},\n\t}\n\n\tfor _, testcase := range invalid {\n\t\tt.Run(testcase.name, func(t *testing.T) {\n\t\t\tif err := assignValues(testcase.to, zero); err == nil {\n\t\t\t\tt.Fatal(\"assignValues didn't return an error\")\n\t\t\t} else {\n\t\t\t\tt.Log(err)\n\t\t\t}\n\t\t})\n\t}\n\n\tvalid := []struct {\n\t\tname string\n\t\tto   interface{}\n\t}{\n\t\t{\"pointer to struct\", new(t1)},\n\t\t{\"embedded struct\", new(t2)},\n\t\t{\"embedded struct pointer\", &t2ptr{t1: new(t1)}},\n\t\t{\"untagged field\", new(struct{ Foo int })},\n\t}\n\n\tfor _, testcase := range valid {\n\t\tt.Run(testcase.name, func(t *testing.T) {\n\t\t\tif err := assignValues(testcase.to, zero); err != nil {\n\t\t\t\tt.Fatal(\"assignValues returned\", err)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCollectionAssign(t *testing.T) {\n\tvar objs struct {\n\t\tProgram *Program `ebpf:\"prog1\"`\n\t\tMap     *Map     `ebpf:\"map1\"`\n\t}\n\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"map1\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"prog1\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\tcoll, err := NewCollection(cs)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer coll.Close()\n\n\tqt.Assert(t, qt.IsNil(coll.Assign(&objs)))\n\tdefer objs.Program.Close()\n\tdefer objs.Map.Close()\n\n\t// Check that objs has received ownership of map and prog\n\tqt.Assert(t, qt.IsTrue(objs.Program.FD() >= 0))\n\tqt.Assert(t, qt.IsTrue(objs.Map.FD() >= 0))\n\n\t// Check that the collection has lost ownership\n\tqt.Assert(t, qt.IsNil(coll.Programs[\"prog1\"]))\n\tqt.Assert(t, qt.IsNil(coll.Maps[\"map1\"]))\n}\n\nfunc TestCollectionAssignFail(t *testing.T) {\n\t// `map2` does not exist\n\tvar objs struct {\n\t\tProgram *Program `ebpf:\"prog1\"`\n\t\tMap     *Map     `ebpf:\"map2\"`\n\t}\n\n\tcs := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"map1\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"prog1\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\tcoll, err := NewCollection(cs)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer coll.Close()\n\n\tqt.Assert(t, qt.IsNotNil(coll.Assign(&objs)))\n\n\t// Check that the collection has retained ownership\n\tqt.Assert(t, qt.IsNotNil(coll.Programs[\"prog1\"]))\n\tqt.Assert(t, qt.IsNotNil(coll.Maps[\"map1\"]))\n}\n\nfunc TestIncompleteLoadAndAssign(t *testing.T) {\n\tspec := &CollectionSpec{\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"valid\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t\t\"invalid\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\ts := struct {\n\t\t// Assignment to Valid should execute and succeed.\n\t\tValid *Program `ebpf:\"valid\"`\n\t\t// Assignment to Invalid should fail and cause Valid's fd to be closed.\n\t\tInvalid *Program `ebpf:\"invalid\"`\n\t}{}\n\n\tif err := spec.LoadAndAssign(&s, nil); err == nil {\n\t\tt.Fatal(\"expected error loading invalid ProgramSpec\")\n\t}\n\n\tif s.Valid == nil {\n\t\tt.Fatal(\"expected valid prog to be non-nil\")\n\t}\n\n\tif fd := s.Valid.FD(); fd != -1 {\n\t\tt.Fatal(\"expected valid prog to have closed fd -1, got:\", fd)\n\t}\n\n\tif s.Invalid != nil {\n\t\tt.Fatal(\"expected invalid prog to be nil due to never being assigned\")\n\t}\n}\n\nfunc BenchmarkNewCollection(b *testing.B) {\n\tfile := testutils.NativeFile(b, \"testdata/loader-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tspec.Maps[\"array_of_hash_map\"].InnerMap = spec.Maps[\"hash_map\"]\n\tfor _, m := range spec.Maps {\n\t\tm.Pinning = PinNone\n\t}\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tcoll, err := NewCollection(spec)\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tcoll.Close()\n\t}\n}\n\nfunc BenchmarkNewCollectionManyProgs(b *testing.B) {\n\tfile := testutils.NativeFile(b, \"testdata/manyprogs-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tcoll, err := NewCollection(spec)\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tcoll.Close()\n\t}\n}\n\nfunc BenchmarkLoadCollectionManyProgs(b *testing.B) {\n\tfile, err := os.Open(testutils.NativeFile(b, \"testdata/manyprogs-%s.elf\"))\n\tqt.Assert(b, qt.IsNil(err))\n\tdefer file.Close()\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\t_, err := file.Seek(0, io.SeekStart)\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\n\t\t_, err = LoadCollectionSpecFromReader(file)\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t}\n}\n\nfunc ExampleCollectionSpec_Assign() {\n\tspec := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"map1\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"prog1\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\ttype maps struct {\n\t\tMap *MapSpec `ebpf:\"map1\"`\n\t}\n\n\tvar specs struct {\n\t\tmaps\n\t\tProgram *ProgramSpec `ebpf:\"prog1\"`\n\t}\n\n\tif err := spec.Assign(&specs); err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Println(specs.Program.Type)\n\tfmt.Println(specs.Map.Type)\n\n\t// Output: SocketFilter\n\t// Array\n}\n\nfunc ExampleCollectionSpec_LoadAndAssign() {\n\tspec := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"map1\": {\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"prog1\": {\n\t\t\t\tType: SocketFilter,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"MIT\",\n\t\t\t},\n\t\t},\n\t}\n\n\tvar objs struct {\n\t\tProgram *Program `ebpf:\"prog1\"`\n\t\tMap     *Map     `ebpf:\"map1\"`\n\t}\n\n\tif err := spec.LoadAndAssign(&objs, nil); err != nil {\n\t\tpanic(err)\n\t}\n\tdefer objs.Program.Close()\n\tdefer objs.Map.Close()\n\n\tfmt.Println(objs.Program.Type())\n\tfmt.Println(objs.Map.Type())\n\n\t// Output: SocketFilter\n\t// Array\n}\n"
        },
        {
          "name": "cpu.go",
          "type": "blob",
          "size": 1.4853515625,
          "content": "package ebpf\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n)\n\nvar possibleCPU = sync.OnceValues(func() (int, error) {\n\treturn parseCPUsFromFile(\"/sys/devices/system/cpu/possible\")\n})\n\n// PossibleCPU returns the max number of CPUs a system may possibly have\n// Logical CPU numbers must be of the form 0-n\nfunc PossibleCPU() (int, error) {\n\treturn possibleCPU()\n}\n\n// MustPossibleCPU is a helper that wraps a call to PossibleCPU and panics if\n// the error is non-nil.\nfunc MustPossibleCPU() int {\n\tcpus, err := PossibleCPU()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn cpus\n}\n\nfunc parseCPUsFromFile(path string) (int, error) {\n\tspec, err := os.ReadFile(path)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tn, err := parseCPUs(string(spec))\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"can't parse %s: %v\", path, err)\n\t}\n\n\treturn n, nil\n}\n\n// parseCPUs parses the number of cpus from a string produced\n// by bitmap_list_string() in the Linux kernel.\n// Multiple ranges are rejected, since they can't be unified\n// into a single number.\n// This is the format of /sys/devices/system/cpu/possible, it\n// is not suitable for /sys/devices/system/cpu/online, etc.\nfunc parseCPUs(spec string) (int, error) {\n\tif strings.Trim(spec, \"\\n\") == \"0\" {\n\t\treturn 1, nil\n\t}\n\n\tvar low, high int\n\tn, err := fmt.Sscanf(spec, \"%d-%d\\n\", &low, &high)\n\tif n != 2 || err != nil {\n\t\treturn 0, fmt.Errorf(\"invalid format: %s\", spec)\n\t}\n\tif low != 0 {\n\t\treturn 0, fmt.Errorf(\"CPU spec doesn't start at zero: %s\", spec)\n\t}\n\n\t// cpus is 0 indexed\n\treturn high + 1, nil\n}\n"
        },
        {
          "name": "cpu_test.go",
          "type": "blob",
          "size": 0.501953125,
          "content": "package ebpf\n\nimport (\n\t\"testing\"\n)\n\nfunc TestParseCPUs(t *testing.T) {\n\tfor str, result := range map[string]int{\n\t\t\"0-1\":   2,\n\t\t\"0-2\\n\": 3,\n\t\t\"0\":     1,\n\t} {\n\t\tn, err := parseCPUs(str)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Can't parse `%s`: %v\", str, err)\n\t\t} else if n != result {\n\t\t\tt.Error(\"Parsing\", str, \"returns\", n, \"instead of\", result)\n\t\t}\n\t}\n\n\tfor _, str := range []string{\n\t\t\"0,3-4\",\n\t\t\"0-\",\n\t\t\"1,\",\n\t\t\"\",\n\t} {\n\t\t_, err := parseCPUs(str)\n\t\tif err == nil {\n\t\t\tt.Error(\"Parsed invalid format:\", str)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 1.326171875,
          "content": "// Package ebpf is a toolkit for working with eBPF programs.\n//\n// eBPF programs are small snippets of code which are executed directly\n// in a VM in the Linux kernel, which makes them very fast and flexible.\n// Many Linux subsystems now accept eBPF programs. This makes it possible\n// to implement highly application specific logic inside the kernel,\n// without having to modify the actual kernel itself.\n//\n// This package is designed for long-running processes which\n// want to use eBPF to implement part of their application logic. It has no\n// run-time dependencies outside of the library and the Linux kernel itself.\n// eBPF code should be compiled ahead of time using clang, and shipped with\n// your application as any other resource.\n//\n// Use the link subpackage to attach a loaded program to a hook in the kernel.\n//\n// Note that losing all references to Map and Program resources will cause\n// their underlying file descriptors to be closed, potentially removing those\n// objects from the kernel. Always retain a reference by e.g. deferring a\n// Close() of a Collection or LoadAndAssign object until application exit.\n//\n// Special care needs to be taken when handling maps of type ProgramArray,\n// as the kernel erases its contents when the last userspace or bpffs\n// reference disappears, regardless of the map being in active use.\npackage ebpf\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "elf_reader.go",
          "type": "blob",
          "size": 42.1083984375,
          "content": "package ebpf\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"debug/elf\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n)\n\ntype kconfigMetaKey struct{}\n\ntype kconfigMeta struct {\n\tMap    *MapSpec\n\tOffset uint32\n}\n\ntype kfuncMetaKey struct{}\n\ntype kfuncMeta struct {\n\tBinding elf.SymBind\n\tFunc    *btf.Func\n}\n\ntype ksymMetaKey struct{}\n\ntype ksymMeta struct {\n\tBinding elf.SymBind\n\tName    string\n}\n\n// elfCode is a convenience to reduce the amount of arguments that have to\n// be passed around explicitly. You should treat its contents as immutable.\ntype elfCode struct {\n\t*internal.SafeELFFile\n\tsections map[elf.SectionIndex]*elfSection\n\tlicense  string\n\tversion  uint32\n\tbtf      *btf.Spec\n\textInfo  *btf.ExtInfos\n\tmaps     map[string]*MapSpec\n\tvars     map[string]*VariableSpec\n\tkfuncs   map[string]*btf.Func\n\tksyms    map[string]struct{}\n\tkconfig  *MapSpec\n}\n\n// LoadCollectionSpec parses an ELF file into a CollectionSpec.\nfunc LoadCollectionSpec(file string) (*CollectionSpec, error) {\n\tf, err := os.Open(file)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\n\tspec, err := LoadCollectionSpecFromReader(f)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"file %s: %w\", file, err)\n\t}\n\treturn spec, nil\n}\n\n// LoadCollectionSpecFromReader parses an ELF file into a CollectionSpec.\nfunc LoadCollectionSpecFromReader(rd io.ReaderAt) (*CollectionSpec, error) {\n\tf, err := internal.NewSafeELFFile(rd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Checks if the ELF file is for BPF data.\n\t// Old LLVM versions set e_machine to EM_NONE.\n\tif f.File.Machine != elf.EM_NONE && f.File.Machine != elf.EM_BPF {\n\t\treturn nil, fmt.Errorf(\"unexpected machine type for BPF ELF: %s\", f.File.Machine)\n\t}\n\n\tvar (\n\t\tlicenseSection *elf.Section\n\t\tversionSection *elf.Section\n\t\tsections       = make(map[elf.SectionIndex]*elfSection)\n\t\trelSections    = make(map[elf.SectionIndex]*elf.Section)\n\t)\n\n\t// This is the target of relocations generated by inline assembly.\n\tsections[elf.SHN_UNDEF] = newElfSection(new(elf.Section), undefSection)\n\n\t// Collect all the sections we're interested in. This includes relocations\n\t// which we parse later.\n\t//\n\t// Keep the documentation at docs/ebpf/loading/elf-sections.md up-to-date.\n\tfor i, sec := range f.Sections {\n\t\tidx := elf.SectionIndex(i)\n\n\t\tswitch {\n\t\tcase strings.HasPrefix(sec.Name, \"license\"):\n\t\t\tlicenseSection = sec\n\t\tcase strings.HasPrefix(sec.Name, \"version\"):\n\t\t\tversionSection = sec\n\t\tcase strings.HasPrefix(sec.Name, \"maps\"):\n\t\t\tsections[idx] = newElfSection(sec, mapSection)\n\t\tcase sec.Name == \".maps\":\n\t\t\tsections[idx] = newElfSection(sec, btfMapSection)\n\t\tcase isDataSection(sec.Name):\n\t\t\tsections[idx] = newElfSection(sec, dataSection)\n\t\tcase sec.Type == elf.SHT_REL:\n\t\t\t// Store relocations under the section index of the target\n\t\t\trelSections[elf.SectionIndex(sec.Info)] = sec\n\t\tcase sec.Type == elf.SHT_PROGBITS && (sec.Flags&elf.SHF_EXECINSTR) != 0 && sec.Size > 0:\n\t\t\tsections[idx] = newElfSection(sec, programSection)\n\t\t}\n\t}\n\n\tlicense, err := loadLicense(licenseSection)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load license: %w\", err)\n\t}\n\n\tversion, err := loadVersion(versionSection, f.ByteOrder)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load version: %w\", err)\n\t}\n\n\tbtfSpec, btfExtInfo, err := btf.LoadSpecAndExtInfosFromReader(rd)\n\tif err != nil && !errors.Is(err, btf.ErrNotFound) {\n\t\treturn nil, fmt.Errorf(\"load BTF: %w\", err)\n\t}\n\n\tec := &elfCode{\n\t\tSafeELFFile: f,\n\t\tsections:    sections,\n\t\tlicense:     license,\n\t\tversion:     version,\n\t\tbtf:         btfSpec,\n\t\textInfo:     btfExtInfo,\n\t\tmaps:        make(map[string]*MapSpec),\n\t\tvars:        make(map[string]*VariableSpec),\n\t\tkfuncs:      make(map[string]*btf.Func),\n\t\tksyms:       make(map[string]struct{}),\n\t}\n\n\tsymbols, err := f.Symbols()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load symbols: %v\", err)\n\t}\n\n\tec.assignSymbols(symbols)\n\n\tif err := ec.loadRelocations(relSections, symbols); err != nil {\n\t\treturn nil, fmt.Errorf(\"load relocations: %w\", err)\n\t}\n\n\tif err := ec.loadMaps(); err != nil {\n\t\treturn nil, fmt.Errorf(\"load maps: %w\", err)\n\t}\n\n\tif err := ec.loadBTFMaps(); err != nil {\n\t\treturn nil, fmt.Errorf(\"load BTF maps: %w\", err)\n\t}\n\n\tif err := ec.loadDataSections(); err != nil {\n\t\treturn nil, fmt.Errorf(\"load data sections: %w\", err)\n\t}\n\n\tif err := ec.loadKconfigSection(); err != nil {\n\t\treturn nil, fmt.Errorf(\"load virtual .kconfig section: %w\", err)\n\t}\n\n\tif err := ec.loadKsymsSection(); err != nil {\n\t\treturn nil, fmt.Errorf(\"load virtual .ksyms section: %w\", err)\n\t}\n\n\t// Finally, collect programs and link them.\n\tprogs, err := ec.loadProgramSections()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load programs: %w\", err)\n\t}\n\n\treturn &CollectionSpec{ec.maps, progs, ec.vars, btfSpec, ec.ByteOrder}, nil\n}\n\nfunc loadLicense(sec *elf.Section) (string, error) {\n\tif sec == nil {\n\t\treturn \"\", nil\n\t}\n\n\tdata, err := sec.Data()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"section %s: %v\", sec.Name, err)\n\t}\n\treturn string(bytes.TrimRight(data, \"\\000\")), nil\n}\n\nfunc loadVersion(sec *elf.Section, bo binary.ByteOrder) (uint32, error) {\n\tif sec == nil {\n\t\treturn 0, nil\n\t}\n\n\tvar version uint32\n\tif err := binary.Read(sec.Open(), bo, &version); err != nil {\n\t\treturn 0, fmt.Errorf(\"section %s: %v\", sec.Name, err)\n\t}\n\treturn version, nil\n}\n\nfunc isDataSection(name string) bool {\n\treturn name == \".bss\" || strings.HasPrefix(name, \".data\") || strings.HasPrefix(name, \".rodata\")\n}\n\nfunc isConstantDataSection(name string) bool {\n\treturn strings.HasPrefix(name, \".rodata\")\n}\n\nfunc isKconfigSection(name string) bool {\n\treturn name == \".kconfig\"\n}\n\ntype elfSectionKind int\n\nconst (\n\tundefSection elfSectionKind = iota\n\tmapSection\n\tbtfMapSection\n\tprogramSection\n\tdataSection\n)\n\ntype elfSection struct {\n\t*elf.Section\n\tkind elfSectionKind\n\t// Offset from the start of the section to a symbol\n\tsymbols map[uint64]elf.Symbol\n\t// Offset from the start of the section to a relocation, which points at\n\t// a symbol in another section.\n\trelocations map[uint64]elf.Symbol\n\t// The number of relocations pointing at this section.\n\treferences int\n}\n\nfunc newElfSection(section *elf.Section, kind elfSectionKind) *elfSection {\n\treturn &elfSection{\n\t\tsection,\n\t\tkind,\n\t\tmake(map[uint64]elf.Symbol),\n\t\tmake(map[uint64]elf.Symbol),\n\t\t0,\n\t}\n}\n\n// assignSymbols takes a list of symbols and assigns them to their\n// respective sections, indexed by name.\nfunc (ec *elfCode) assignSymbols(symbols []elf.Symbol) {\n\tfor _, symbol := range symbols {\n\t\tsymType := elf.ST_TYPE(symbol.Info)\n\t\tsymSection := ec.sections[symbol.Section]\n\t\tif symSection == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Anonymous symbols only occur in debug sections which we don't process\n\t\t// relocations for. Anonymous symbols are not referenced from other sections.\n\t\tif symbol.Name == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Older versions of LLVM don't tag symbols correctly, so keep\n\t\t// all NOTYPE ones.\n\t\tswitch symSection.kind {\n\t\tcase mapSection, btfMapSection, dataSection:\n\t\t\tif symType != elf.STT_NOTYPE && symType != elf.STT_OBJECT {\n\t\t\t\tcontinue\n\t\t\t}\n\t\tcase programSection:\n\t\t\tif symType != elf.STT_NOTYPE && symType != elf.STT_FUNC {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// LLVM emits LBB_ (Local Basic Block) symbols that seem to be jump\n\t\t\t// targets within sections, but BPF has no use for them.\n\t\t\tif symType == elf.STT_NOTYPE && elf.ST_BIND(symbol.Info) == elf.STB_LOCAL &&\n\t\t\t\tstrings.HasPrefix(symbol.Name, \"LBB\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t// Only collect symbols that occur in program/maps/data sections.\n\t\tdefault:\n\t\t\tcontinue\n\t\t}\n\n\t\tsymSection.symbols[symbol.Value] = symbol\n\t}\n}\n\n// loadRelocations iterates .rel* sections and extracts relocation entries for\n// sections of interest. Makes sure relocations point at valid sections.\nfunc (ec *elfCode) loadRelocations(relSections map[elf.SectionIndex]*elf.Section, symbols []elf.Symbol) error {\n\tfor idx, relSection := range relSections {\n\t\tsection := ec.sections[idx]\n\t\tif section == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\trels, err := ec.loadSectionRelocations(relSection, symbols)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"relocation for section %q: %w\", section.Name, err)\n\t\t}\n\n\t\tfor _, rel := range rels {\n\t\t\ttarget := ec.sections[rel.Section]\n\t\t\tif target == nil {\n\t\t\t\treturn fmt.Errorf(\"section %q: reference to %q in section %s: %w\", section.Name, rel.Name, rel.Section, ErrNotSupported)\n\t\t\t}\n\n\t\t\ttarget.references++\n\t\t}\n\n\t\tsection.relocations = rels\n\t}\n\n\treturn nil\n}\n\n// loadProgramSections iterates ec's sections and emits a ProgramSpec\n// for each function it finds.\n//\n// The resulting map is indexed by function name.\nfunc (ec *elfCode) loadProgramSections() (map[string]*ProgramSpec, error) {\n\n\tprogs := make(map[string]*ProgramSpec)\n\n\t// Generate a ProgramSpec for each function found in each program section.\n\tvar export []string\n\tfor _, sec := range ec.sections {\n\t\tif sec.kind != programSection {\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(sec.symbols) == 0 {\n\t\t\treturn nil, fmt.Errorf(\"section %v: missing symbols\", sec.Name)\n\t\t}\n\n\t\tfuncs, err := ec.loadFunctions(sec)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"section %v: %w\", sec.Name, err)\n\t\t}\n\n\t\tprogType, attachType, progFlags, attachTo := getProgType(sec.Name)\n\n\t\tfor name, insns := range funcs {\n\t\t\tspec := &ProgramSpec{\n\t\t\t\tName:          name,\n\t\t\t\tType:          progType,\n\t\t\t\tFlags:         progFlags,\n\t\t\t\tAttachType:    attachType,\n\t\t\t\tAttachTo:      attachTo,\n\t\t\t\tSectionName:   sec.Name,\n\t\t\t\tLicense:       ec.license,\n\t\t\t\tKernelVersion: ec.version,\n\t\t\t\tInstructions:  insns,\n\t\t\t\tByteOrder:     ec.ByteOrder,\n\t\t\t}\n\n\t\t\t// Function names must be unique within a single ELF blob.\n\t\t\tif progs[name] != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"duplicate program name %s\", name)\n\t\t\t}\n\t\t\tprogs[name] = spec\n\n\t\t\tif spec.SectionName != \".text\" {\n\t\t\t\texport = append(export, name)\n\t\t\t}\n\t\t}\n\t}\n\n\tflattenPrograms(progs, export)\n\n\t// Hide programs (e.g. library functions) that were not explicitly emitted\n\t// to an ELF section. These could be exposed in a separate CollectionSpec\n\t// field later to allow them to be modified.\n\tfor n, p := range progs {\n\t\tif p.SectionName == \".text\" {\n\t\t\tdelete(progs, n)\n\t\t}\n\t}\n\n\treturn progs, nil\n}\n\n// loadFunctions extracts instruction streams from the given program section\n// starting at each symbol in the section. The section's symbols must already\n// be narrowed down to STT_NOTYPE (emitted by clang <8) or STT_FUNC.\n//\n// The resulting map is indexed by function name.\nfunc (ec *elfCode) loadFunctions(section *elfSection) (map[string]asm.Instructions, error) {\n\tr := bufio.NewReader(section.Open())\n\n\t// Decode the section's instruction stream.\n\tinsns := make(asm.Instructions, 0, section.Size/asm.InstructionSize)\n\tif err := insns.Unmarshal(r, ec.ByteOrder); err != nil {\n\t\treturn nil, fmt.Errorf(\"decoding instructions for section %s: %w\", section.Name, err)\n\t}\n\tif len(insns) == 0 {\n\t\treturn nil, fmt.Errorf(\"no instructions found in section %s\", section.Name)\n\t}\n\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tins := iter.Ins\n\t\toffset := iter.Offset.Bytes()\n\n\t\t// Tag Symbol Instructions.\n\t\tif sym, ok := section.symbols[offset]; ok {\n\t\t\t*ins = ins.WithSymbol(sym.Name)\n\t\t}\n\n\t\t// Apply any relocations for the current instruction.\n\t\t// If no relocation is present, resolve any section-relative function calls.\n\t\tif rel, ok := section.relocations[offset]; ok {\n\t\t\tif err := ec.relocateInstruction(ins, rel); err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"offset %d: relocating instruction: %w\", offset, err)\n\t\t\t}\n\t\t} else {\n\t\t\tif err := referenceRelativeJump(ins, offset, section.symbols); err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"offset %d: resolving relative jump: %w\", offset, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif ec.extInfo != nil {\n\t\tec.extInfo.Assign(insns, section.Name)\n\t}\n\n\treturn splitSymbols(insns)\n}\n\n// referenceRelativeJump turns a relative jump to another bpf subprogram within\n// the same ELF section into a Reference Instruction.\n//\n// Up to LLVM 9, calls to subprograms within the same ELF section are sometimes\n// encoded using relative jumps instead of relocation entries. These jumps go\n// out of bounds of the current program, so their targets must be memoized\n// before the section's instruction stream is split.\n//\n// The relative jump Constant is blinded to -1 and the target Symbol is set as\n// the Instruction's Reference so it can be resolved by the linker.\nfunc referenceRelativeJump(ins *asm.Instruction, offset uint64, symbols map[uint64]elf.Symbol) error {\n\tif !ins.IsFunctionReference() || ins.Constant == -1 {\n\t\treturn nil\n\t}\n\n\ttgt := jumpTarget(offset, *ins)\n\tsym := symbols[tgt].Name\n\tif sym == \"\" {\n\t\treturn fmt.Errorf(\"no jump target found at offset %d\", tgt)\n\t}\n\n\t*ins = ins.WithReference(sym)\n\tins.Constant = -1\n\n\treturn nil\n}\n\n// jumpTarget takes ins' offset within an instruction stream (in bytes)\n// and returns its absolute jump destination (in bytes) within the\n// instruction stream.\nfunc jumpTarget(offset uint64, ins asm.Instruction) uint64 {\n\t// A relative jump instruction describes the amount of raw BPF instructions\n\t// to jump, convert the offset into bytes.\n\tdest := ins.Constant * asm.InstructionSize\n\n\t// The starting point of the jump is the end of the current instruction.\n\tdest += int64(offset + asm.InstructionSize)\n\n\tif dest < 0 {\n\t\treturn 0\n\t}\n\n\treturn uint64(dest)\n}\n\nvar errUnsupportedBinding = errors.New(\"unsupported binding\")\n\nfunc (ec *elfCode) relocateInstruction(ins *asm.Instruction, rel elf.Symbol) error {\n\tvar (\n\t\ttyp  = elf.ST_TYPE(rel.Info)\n\t\tbind = elf.ST_BIND(rel.Info)\n\t\tname = rel.Name\n\t)\n\n\ttarget := ec.sections[rel.Section]\n\n\tswitch target.kind {\n\tcase mapSection, btfMapSection:\n\t\tif bind == elf.STB_LOCAL {\n\t\t\treturn fmt.Errorf(\"possible erroneous static qualifier on map definition: found reference to %q\", name)\n\t\t}\n\n\t\tif bind != elf.STB_GLOBAL {\n\t\t\treturn fmt.Errorf(\"map %q: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t}\n\n\t\tif typ != elf.STT_OBJECT && typ != elf.STT_NOTYPE {\n\t\t\t// STT_NOTYPE is generated on clang < 8 which doesn't tag\n\t\t\t// relocations appropriately.\n\t\t\treturn fmt.Errorf(\"map load: incorrect relocation type %v\", typ)\n\t\t}\n\n\t\tins.Src = asm.PseudoMapFD\n\n\tcase dataSection:\n\t\tvar offset uint32\n\t\tswitch typ {\n\t\tcase elf.STT_SECTION:\n\t\t\tif bind != elf.STB_LOCAL {\n\t\t\t\treturn fmt.Errorf(\"direct load: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t}\n\n\t\t\t// This is really a reference to a static symbol, which clang doesn't\n\t\t\t// emit a symbol table entry for. Instead it encodes the offset in\n\t\t\t// the instruction itself.\n\t\t\toffset = uint32(uint64(ins.Constant))\n\n\t\tcase elf.STT_OBJECT:\n\t\t\t// LLVM 9 emits OBJECT-LOCAL symbols for anonymous constants.\n\t\t\tif bind != elf.STB_GLOBAL && bind != elf.STB_LOCAL && bind != elf.STB_WEAK {\n\t\t\t\treturn fmt.Errorf(\"direct load: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t}\n\n\t\t\toffset = uint32(rel.Value)\n\n\t\tcase elf.STT_NOTYPE:\n\t\t\t// LLVM 7 emits NOTYPE-LOCAL symbols for anonymous constants.\n\t\t\tif bind != elf.STB_LOCAL {\n\t\t\t\treturn fmt.Errorf(\"direct load: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t}\n\n\t\t\toffset = uint32(rel.Value)\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"incorrect relocation type %v for direct map load\", typ)\n\t\t}\n\n\t\t// We rely on using the name of the data section as the reference. It\n\t\t// would be nicer to keep the real name in case of an STT_OBJECT, but\n\t\t// it's not clear how to encode that into Instruction.\n\t\tname = target.Name\n\n\t\t// The kernel expects the offset in the second basic BPF instruction.\n\t\tins.Constant = int64(uint64(offset) << 32)\n\t\tins.Src = asm.PseudoMapValue\n\n\tcase programSection:\n\t\tswitch opCode := ins.OpCode; {\n\t\tcase opCode.JumpOp() == asm.Call:\n\t\t\tif ins.Src != asm.PseudoCall {\n\t\t\t\treturn fmt.Errorf(\"call: %s: incorrect source register\", name)\n\t\t\t}\n\n\t\t\tswitch typ {\n\t\t\tcase elf.STT_NOTYPE, elf.STT_FUNC:\n\t\t\t\tif bind != elf.STB_GLOBAL {\n\t\t\t\t\treturn fmt.Errorf(\"call: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t\t}\n\n\t\t\tcase elf.STT_SECTION:\n\t\t\t\tif bind != elf.STB_LOCAL {\n\t\t\t\t\treturn fmt.Errorf(\"call: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t\t}\n\n\t\t\t\t// The function we want to call is in the indicated section,\n\t\t\t\t// at the offset encoded in the instruction itself. Reverse\n\t\t\t\t// the calculation to find the real function we're looking for.\n\t\t\t\t// A value of -1 references the first instruction in the section.\n\t\t\t\toffset := int64(int32(ins.Constant)+1) * asm.InstructionSize\n\t\t\t\tsym, ok := target.symbols[uint64(offset)]\n\t\t\t\tif !ok {\n\t\t\t\t\treturn fmt.Errorf(\"call: no symbol at offset %d\", offset)\n\t\t\t\t}\n\n\t\t\t\tname = sym.Name\n\t\t\t\tins.Constant = -1\n\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"call: %s: invalid symbol type %s\", name, typ)\n\t\t\t}\n\t\tcase opCode.IsDWordLoad():\n\t\t\tswitch typ {\n\t\t\tcase elf.STT_FUNC:\n\t\t\t\tif bind != elf.STB_GLOBAL {\n\t\t\t\t\treturn fmt.Errorf(\"load: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t\t}\n\n\t\t\tcase elf.STT_SECTION:\n\t\t\t\tif bind != elf.STB_LOCAL {\n\t\t\t\t\treturn fmt.Errorf(\"load: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t\t}\n\n\t\t\t\t// ins.Constant already contains the offset in bytes from the\n\t\t\t\t// start of the section. This is different than a call to a\n\t\t\t\t// static function.\n\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"load: %s: invalid symbol type %s\", name, typ)\n\t\t\t}\n\n\t\t\tsym, ok := target.symbols[uint64(ins.Constant)]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"load: no symbol at offset %d\", ins.Constant)\n\t\t\t}\n\n\t\t\tname = sym.Name\n\t\t\tins.Constant = -1\n\t\t\tins.Src = asm.PseudoFunc\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"neither a call nor a load instruction: %v\", ins)\n\t\t}\n\n\t// The Undefined section is used for 'virtual' symbols that aren't backed by\n\t// an ELF section. This includes symbol references from inline asm, forward\n\t// function declarations, as well as extern kfunc declarations using __ksym\n\t// and extern kconfig variables declared using __kconfig.\n\tcase undefSection:\n\t\tif bind != elf.STB_GLOBAL && bind != elf.STB_WEAK {\n\t\t\treturn fmt.Errorf(\"asm relocation: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t}\n\n\t\tif typ != elf.STT_NOTYPE {\n\t\t\treturn fmt.Errorf(\"asm relocation: %s: unsupported type %s\", name, typ)\n\t\t}\n\n\t\tkf := ec.kfuncs[name]\n\t\t_, ks := ec.ksyms[name]\n\n\t\tswitch {\n\t\t// If a Call / DWordLoad instruction is found and the datasec has a btf.Func with a Name\n\t\t// that matches the symbol name we mark the instruction as a referencing a kfunc.\n\t\tcase kf != nil && ins.OpCode.JumpOp() == asm.Call:\n\t\t\tins.Metadata.Set(kfuncMetaKey{}, &kfuncMeta{\n\t\t\t\tFunc:    kf,\n\t\t\t\tBinding: bind,\n\t\t\t})\n\n\t\t\tins.Src = asm.PseudoKfuncCall\n\t\t\tins.Constant = -1\n\n\t\tcase kf != nil && ins.OpCode.IsDWordLoad():\n\t\t\tins.Metadata.Set(kfuncMetaKey{}, &kfuncMeta{\n\t\t\t\tFunc:    kf,\n\t\t\t\tBinding: bind,\n\t\t\t})\n\n\t\t\tins.Constant = 0\n\n\t\tcase ks && ins.OpCode.IsDWordLoad():\n\t\t\tif bind != elf.STB_GLOBAL && bind != elf.STB_WEAK {\n\t\t\t\treturn fmt.Errorf(\"asm relocation: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t}\n\t\t\tins.Metadata.Set(ksymMetaKey{}, &ksymMeta{\n\t\t\t\tBinding: bind,\n\t\t\t\tName:    name,\n\t\t\t})\n\n\t\t// If no kconfig map is found, this must be a symbol reference from inline\n\t\t// asm (see testdata/loader.c:asm_relocation()) or a call to a forward\n\t\t// function declaration (see testdata/fwd_decl.c). Don't interfere, These\n\t\t// remain standard symbol references.\n\t\t// extern __kconfig reads are represented as dword loads that need to be\n\t\t// rewritten to pseudo map loads from .kconfig. If the map is present,\n\t\t// require it to contain the symbol to disambiguate between inline asm\n\t\t// relos and kconfigs.\n\t\tcase ec.kconfig != nil && ins.OpCode.IsDWordLoad():\n\t\t\tif bind != elf.STB_GLOBAL {\n\t\t\t\treturn fmt.Errorf(\"asm relocation: %s: %w: %s\", name, errUnsupportedBinding, bind)\n\t\t\t}\n\n\t\t\tfor _, vsi := range ec.kconfig.Value.(*btf.Datasec).Vars {\n\t\t\t\tif vsi.Type.(*btf.Var).Name != rel.Name {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tins.Src = asm.PseudoMapValue\n\t\t\t\tins.Metadata.Set(kconfigMetaKey{}, &kconfigMeta{ec.kconfig, vsi.Offset})\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\treturn fmt.Errorf(\"kconfig %s not found in .kconfig\", rel.Name)\n\t\t}\n\n\tdefault:\n\t\treturn fmt.Errorf(\"relocation to %q: %w\", target.Name, ErrNotSupported)\n\t}\n\n\t*ins = ins.WithReference(name)\n\treturn nil\n}\n\nfunc (ec *elfCode) loadMaps() error {\n\tfor _, sec := range ec.sections {\n\t\tif sec.kind != mapSection {\n\t\t\tcontinue\n\t\t}\n\n\t\tnSym := len(sec.symbols)\n\t\tif nSym == 0 {\n\t\t\treturn fmt.Errorf(\"section %v: no symbols\", sec.Name)\n\t\t}\n\n\t\tif sec.Size%uint64(nSym) != 0 {\n\t\t\treturn fmt.Errorf(\"section %v: map descriptors are not of equal size\", sec.Name)\n\t\t}\n\n\t\tvar (\n\t\t\tr    = bufio.NewReader(sec.Open())\n\t\t\tsize = sec.Size / uint64(nSym)\n\t\t)\n\t\tfor i, offset := 0, uint64(0); i < nSym; i, offset = i+1, offset+size {\n\t\t\tmapSym, ok := sec.symbols[offset]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"section %s: missing symbol for map at offset %d\", sec.Name, offset)\n\t\t\t}\n\n\t\t\tmapName := mapSym.Name\n\t\t\tif ec.maps[mapName] != nil {\n\t\t\t\treturn fmt.Errorf(\"section %v: map %v already exists\", sec.Name, mapSym)\n\t\t\t}\n\n\t\t\tlr := io.LimitReader(r, int64(size))\n\n\t\t\tspec := MapSpec{\n\t\t\t\tName: SanitizeName(mapName, -1),\n\t\t\t}\n\t\t\tswitch {\n\t\t\tcase binary.Read(lr, ec.ByteOrder, &spec.Type) != nil:\n\t\t\t\treturn fmt.Errorf(\"map %s: missing type\", mapName)\n\t\t\tcase binary.Read(lr, ec.ByteOrder, &spec.KeySize) != nil:\n\t\t\t\treturn fmt.Errorf(\"map %s: missing key size\", mapName)\n\t\t\tcase binary.Read(lr, ec.ByteOrder, &spec.ValueSize) != nil:\n\t\t\t\treturn fmt.Errorf(\"map %s: missing value size\", mapName)\n\t\t\tcase binary.Read(lr, ec.ByteOrder, &spec.MaxEntries) != nil:\n\t\t\t\treturn fmt.Errorf(\"map %s: missing max entries\", mapName)\n\t\t\tcase binary.Read(lr, ec.ByteOrder, &spec.Flags) != nil:\n\t\t\t\treturn fmt.Errorf(\"map %s: missing flags\", mapName)\n\t\t\t}\n\n\t\t\textra, err := io.ReadAll(lr)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"map %s: reading map tail: %w\", mapName, err)\n\t\t\t}\n\t\t\tif len(extra) > 0 {\n\t\t\t\tspec.Extra = bytes.NewReader(extra)\n\t\t\t}\n\n\t\t\tec.maps[mapName] = &spec\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// loadBTFMaps iterates over all ELF sections marked as BTF map sections\n// (like .maps) and parses them into MapSpecs. Dump the .maps section and\n// any relocations with `readelf -x .maps -r <elf_file>`.\nfunc (ec *elfCode) loadBTFMaps() error {\n\tfor _, sec := range ec.sections {\n\t\tif sec.kind != btfMapSection {\n\t\t\tcontinue\n\t\t}\n\n\t\tif ec.btf == nil {\n\t\t\treturn fmt.Errorf(\"missing BTF\")\n\t\t}\n\n\t\t// Each section must appear as a DataSec in the ELF's BTF blob.\n\t\tvar ds *btf.Datasec\n\t\tif err := ec.btf.TypeByName(sec.Name, &ds); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot find section '%s' in BTF: %w\", sec.Name, err)\n\t\t}\n\n\t\t// Open a Reader to the ELF's raw section bytes so we can assert that all\n\t\t// of them are zero on a per-map (per-Var) basis. For now, the section's\n\t\t// sole purpose is to receive relocations, so all must be zero.\n\t\trs := sec.Open()\n\n\t\tfor _, vs := range ds.Vars {\n\t\t\t// BPF maps are declared as and assigned to global variables,\n\t\t\t// so iterate over each Var in the DataSec and validate their types.\n\t\t\tv, ok := vs.Type.(*btf.Var)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"section %v: unexpected type %s\", sec.Name, vs.Type)\n\t\t\t}\n\t\t\tname := string(v.Name)\n\n\t\t\t// The BTF metadata for each Var contains the full length of the map\n\t\t\t// declaration, so read the corresponding amount of bytes from the ELF.\n\t\t\t// This way, we can pinpoint which map declaration contains unexpected\n\t\t\t// (and therefore unsupported) data.\n\t\t\t_, err := io.Copy(internal.DiscardZeroes{}, io.LimitReader(rs, int64(vs.Size)))\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"section %v: map %s: initializing BTF map definitions: %w\", sec.Name, name, internal.ErrNotSupported)\n\t\t\t}\n\n\t\t\tif ec.maps[name] != nil {\n\t\t\t\treturn fmt.Errorf(\"section %v: map %s already exists\", sec.Name, name)\n\t\t\t}\n\n\t\t\t// Each Var representing a BTF map definition contains a Struct.\n\t\t\tmapStruct, ok := btf.UnderlyingType(v.Type).(*btf.Struct)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"expected struct, got %s\", v.Type)\n\t\t\t}\n\n\t\t\tmapSpec, err := mapSpecFromBTF(sec, &vs, mapStruct, ec.btf, name, false)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"map %v: %w\", name, err)\n\t\t\t}\n\n\t\t\tec.maps[name] = mapSpec\n\t\t}\n\n\t\t// Drain the ELF section reader to make sure all bytes are accounted for\n\t\t// with BTF metadata.\n\t\ti, err := io.Copy(io.Discard, rs)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"section %v: unexpected error reading remainder of ELF section: %w\", sec.Name, err)\n\t\t}\n\t\tif i > 0 {\n\t\t\treturn fmt.Errorf(\"section %v: %d unexpected remaining bytes in ELF section, invalid BTF?\", sec.Name, i)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// mapSpecFromBTF produces a MapSpec based on a btf.Struct def representing\n// a BTF map definition. The name and spec arguments will be copied to the\n// resulting MapSpec, and inner must be true on any recursive invocations.\nfunc mapSpecFromBTF(es *elfSection, vs *btf.VarSecinfo, def *btf.Struct, spec *btf.Spec, name string, inner bool) (*MapSpec, error) {\n\tvar (\n\t\tkey, value         btf.Type\n\t\tkeySize, valueSize uint32\n\t\tmapType            MapType\n\t\tflags, maxEntries  uint32\n\t\tpinType            PinType\n\t\tinnerMapSpec       *MapSpec\n\t\tcontents           []MapKV\n\t\terr                error\n\t)\n\n\tfor i, member := range def.Members {\n\t\tswitch member.Name {\n\t\tcase \"type\":\n\t\t\tmt, err := uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get type: %w\", err)\n\t\t\t}\n\t\t\tmapType = MapType(mt)\n\n\t\tcase \"map_flags\":\n\t\t\tflags, err = uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get BTF map flags: %w\", err)\n\t\t\t}\n\n\t\tcase \"max_entries\":\n\t\t\tmaxEntries, err = uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get BTF map max entries: %w\", err)\n\t\t\t}\n\n\t\tcase \"key\":\n\t\t\tif keySize != 0 {\n\t\t\t\treturn nil, errors.New(\"both key and key_size given\")\n\t\t\t}\n\n\t\t\tpk, ok := member.Type.(*btf.Pointer)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"key type is not a pointer: %T\", member.Type)\n\t\t\t}\n\n\t\t\tkey = pk.Target\n\n\t\t\tsize, err := btf.Sizeof(pk.Target)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get size of BTF key: %w\", err)\n\t\t\t}\n\n\t\t\tkeySize = uint32(size)\n\n\t\tcase \"value\":\n\t\t\tif valueSize != 0 {\n\t\t\t\treturn nil, errors.New(\"both value and value_size given\")\n\t\t\t}\n\n\t\t\tvk, ok := member.Type.(*btf.Pointer)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"value type is not a pointer: %T\", member.Type)\n\t\t\t}\n\n\t\t\tvalue = vk.Target\n\n\t\t\tsize, err := btf.Sizeof(vk.Target)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get size of BTF value: %w\", err)\n\t\t\t}\n\n\t\t\tvalueSize = uint32(size)\n\n\t\tcase \"key_size\":\n\t\t\t// Key needs to be nil and keySize needs to be 0 for key_size to be\n\t\t\t// considered a valid member.\n\t\t\tif key != nil || keySize != 0 {\n\t\t\t\treturn nil, errors.New(\"both key and key_size given\")\n\t\t\t}\n\n\t\t\tkeySize, err = uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get BTF key size: %w\", err)\n\t\t\t}\n\n\t\tcase \"value_size\":\n\t\t\t// Value needs to be nil and valueSize needs to be 0 for value_size to be\n\t\t\t// considered a valid member.\n\t\t\tif value != nil || valueSize != 0 {\n\t\t\t\treturn nil, errors.New(\"both value and value_size given\")\n\t\t\t}\n\n\t\t\tvalueSize, err = uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get BTF value size: %w\", err)\n\t\t\t}\n\n\t\tcase \"pinning\":\n\t\t\tif inner {\n\t\t\t\treturn nil, errors.New(\"inner maps can't be pinned\")\n\t\t\t}\n\n\t\t\tpinning, err := uintFromBTF(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get pinning: %w\", err)\n\t\t\t}\n\n\t\t\tpinType = PinType(pinning)\n\n\t\tcase \"values\":\n\t\t\t// The 'values' field in BTF map definitions is used for declaring map\n\t\t\t// value types that are references to other BPF objects, like other maps\n\t\t\t// or programs. It is always expected to be an array of pointers.\n\t\t\tif i != len(def.Members)-1 {\n\t\t\t\treturn nil, errors.New(\"'values' must be the last member in a BTF map definition\")\n\t\t\t}\n\n\t\t\tif valueSize != 0 && valueSize != 4 {\n\t\t\t\treturn nil, errors.New(\"value_size must be 0 or 4\")\n\t\t\t}\n\t\t\tvalueSize = 4\n\n\t\t\tvalueType, err := resolveBTFArrayMacro(member.Type)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"can't resolve type of member 'values': %w\", err)\n\t\t\t}\n\n\t\t\tswitch t := valueType.(type) {\n\t\t\tcase *btf.Struct:\n\t\t\t\t// The values member pointing to an array of structs means we're expecting\n\t\t\t\t// a map-in-map declaration.\n\t\t\t\tif mapType != ArrayOfMaps && mapType != HashOfMaps {\n\t\t\t\t\treturn nil, errors.New(\"outer map needs to be an array or a hash of maps\")\n\t\t\t\t}\n\t\t\t\tif inner {\n\t\t\t\t\treturn nil, fmt.Errorf(\"nested inner maps are not supported\")\n\t\t\t\t}\n\n\t\t\t\t// This inner map spec is used as a map template, but it needs to be\n\t\t\t\t// created as a traditional map before it can be used to do so.\n\t\t\t\t// libbpf names the inner map template '<outer_name>.inner', but we\n\t\t\t\t// opted for _inner to simplify validation logic. (dots only supported\n\t\t\t\t// on kernels 5.2 and up)\n\t\t\t\t// Pass the BTF spec from the parent object, since both parent and\n\t\t\t\t// child must be created from the same BTF blob (on kernels that support BTF).\n\t\t\t\tinnerMapSpec, err = mapSpecFromBTF(es, vs, t, spec, name+\"_inner\", true)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"can't parse BTF map definition of inner map: %w\", err)\n\t\t\t\t}\n\n\t\t\tcase *btf.FuncProto:\n\t\t\t\t// The values member contains an array of function pointers, meaning an\n\t\t\t\t// autopopulated PROG_ARRAY.\n\t\t\t\tif mapType != ProgramArray {\n\t\t\t\t\treturn nil, errors.New(\"map needs to be a program array\")\n\t\t\t\t}\n\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"unsupported value type %q in 'values' field\", t)\n\t\t\t}\n\n\t\t\tcontents, err = resolveBTFValuesContents(es, vs, member)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"resolving values contents: %w\", err)\n\t\t\t}\n\n\t\tcase \"map_extra\":\n\t\t\treturn nil, fmt.Errorf(\"BTF map definition: field %s: %w\", member.Name, ErrNotSupported)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unrecognized field %s in BTF map definition\", member.Name)\n\t\t}\n\t}\n\n\t// Some maps don't support value sizes, but annotating their map definitions\n\t// with __type macros can still be useful, especially to let bpf2go generate\n\t// type definitions for them.\n\tif value != nil && !mapType.canHaveValueSize() {\n\t\tvalueSize = 0\n\t}\n\n\treturn &MapSpec{\n\t\tName:       SanitizeName(name, -1),\n\t\tType:       MapType(mapType),\n\t\tKeySize:    keySize,\n\t\tValueSize:  valueSize,\n\t\tMaxEntries: maxEntries,\n\t\tFlags:      flags,\n\t\tKey:        key,\n\t\tValue:      value,\n\t\tPinning:    pinType,\n\t\tInnerMap:   innerMapSpec,\n\t\tContents:   contents,\n\t}, nil\n}\n\n// uintFromBTF resolves the __uint macro, which is a pointer to a sized\n// array, e.g. for int (*foo)[10], this function will return 10.\nfunc uintFromBTF(typ btf.Type) (uint32, error) {\n\tptr, ok := typ.(*btf.Pointer)\n\tif !ok {\n\t\treturn 0, fmt.Errorf(\"not a pointer: %v\", typ)\n\t}\n\n\tarr, ok := ptr.Target.(*btf.Array)\n\tif !ok {\n\t\treturn 0, fmt.Errorf(\"not a pointer to array: %v\", typ)\n\t}\n\n\treturn arr.Nelems, nil\n}\n\n// resolveBTFArrayMacro resolves the __array macro, which declares an array\n// of pointers to a given type. This function returns the target Type of\n// the pointers in the array.\nfunc resolveBTFArrayMacro(typ btf.Type) (btf.Type, error) {\n\tarr, ok := typ.(*btf.Array)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"not an array: %v\", typ)\n\t}\n\n\tptr, ok := arr.Type.(*btf.Pointer)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"not an array of pointers: %v\", typ)\n\t}\n\n\treturn ptr.Target, nil\n}\n\n// resolveBTFValuesContents resolves relocations into ELF sections belonging\n// to btf.VarSecinfo's. This can be used on the 'values' member in BTF map\n// definitions to extract static declarations of map contents.\nfunc resolveBTFValuesContents(es *elfSection, vs *btf.VarSecinfo, member btf.Member) ([]MapKV, error) {\n\t// The elements of a .values pointer array are not encoded in BTF.\n\t// Instead, relocations are generated into each array index.\n\t// However, it's possible to leave certain array indices empty, so all\n\t// indices' offsets need to be checked for emitted relocations.\n\n\t// The offset of the 'values' member within the _struct_ (in bits)\n\t// is the starting point of the array. Convert to bytes. Add VarSecinfo\n\t// offset to get the absolute position in the ELF blob.\n\tstart := member.Offset.Bytes() + vs.Offset\n\t// 'values' is encoded in BTF as a zero (variable) length struct\n\t// member, and its contents run until the end of the VarSecinfo.\n\t// Add VarSecinfo offset to get the absolute position in the ELF blob.\n\tend := vs.Size + vs.Offset\n\t// The size of an address in this section. This determines the width of\n\t// an index in the array.\n\talign := uint32(es.SectionHeader.Addralign)\n\n\t// Check if variable-length section is aligned.\n\tif (end-start)%align != 0 {\n\t\treturn nil, errors.New(\"unaligned static values section\")\n\t}\n\telems := (end - start) / align\n\n\tif elems == 0 {\n\t\treturn nil, nil\n\t}\n\n\tcontents := make([]MapKV, 0, elems)\n\n\t// k is the array index, off is its corresponding ELF section offset.\n\tfor k, off := uint32(0), start; k < elems; k, off = k+1, off+align {\n\t\tr, ok := es.relocations[uint64(off)]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Relocation exists for the current offset in the ELF section.\n\t\t// Emit a value stub based on the type of relocation to be replaced by\n\t\t// a real fd later in the pipeline before populating the map.\n\t\t// Map keys are encoded in MapKV entries, so empty array indices are\n\t\t// skipped here.\n\t\tswitch t := elf.ST_TYPE(r.Info); t {\n\t\tcase elf.STT_FUNC:\n\t\t\tcontents = append(contents, MapKV{uint32(k), r.Name})\n\t\tcase elf.STT_OBJECT:\n\t\t\tcontents = append(contents, MapKV{uint32(k), r.Name})\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unknown relocation type %v for symbol %s\", t, r.Name)\n\t\t}\n\t}\n\n\treturn contents, nil\n}\n\nfunc (ec *elfCode) loadDataSections() error {\n\tfor _, sec := range ec.sections {\n\t\tif sec.kind != dataSection {\n\t\t\tcontinue\n\t\t}\n\n\t\t// If a section has no references, it will be freed as soon as the\n\t\t// Collection closes, so creating and populating it is wasteful. If it has\n\t\t// no symbols, it is likely an ephemeral section used during compilation\n\t\t// that wasn't sanitized by the bpf linker. (like .rodata.str1.1)\n\t\t//\n\t\t// No symbols means no VariableSpecs can be generated from it, making it\n\t\t// pointless to emit a data section for.\n\t\tif sec.references == 0 && len(sec.symbols) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif sec.Size > math.MaxUint32 {\n\t\t\treturn fmt.Errorf(\"data section %s: contents exceed maximum size\", sec.Name)\n\t\t}\n\n\t\tmapSpec := &MapSpec{\n\t\t\tName:       SanitizeName(sec.Name, -1),\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  uint32(sec.Size),\n\t\t\tMaxEntries: 1,\n\t\t}\n\n\t\tif isConstantDataSection(sec.Name) {\n\t\t\tmapSpec.Flags = sys.BPF_F_RDONLY_PROG\n\t\t}\n\n\t\tswitch sec.Type {\n\t\t// Only open the section if we know there's actual data to be read.\n\t\tcase elf.SHT_PROGBITS:\n\t\t\tdata, err := sec.Data()\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"data section %s: can't get contents: %w\", sec.Name, err)\n\t\t\t}\n\t\t\tmapSpec.Contents = []MapKV{{uint32(0), data}}\n\n\t\tcase elf.SHT_NOBITS:\n\t\t\t// NOBITS sections like .bss contain only zeroes and are not allocated in\n\t\t\t// the ELF. Since data sections are Arrays, the kernel can preallocate\n\t\t\t// them. Don't attempt reading zeroes from the ELF, instead allocate the\n\t\t\t// zeroed memory to support getting and setting VariableSpecs for sections\n\t\t\t// like .bss.\n\t\t\tmapSpec.Contents = []MapKV{{uint32(0), make([]byte, sec.Size)}}\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"data section %s: unknown section type %s\", sec.Name, sec.Type)\n\t\t}\n\n\t\tfor off, sym := range sec.symbols {\n\t\t\t// Skip symbols marked with the 'hidden' attribute.\n\t\t\tif elf.ST_VISIBILITY(sym.Other) == elf.STV_HIDDEN ||\n\t\t\t\telf.ST_VISIBILITY(sym.Other) == elf.STV_INTERNAL {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Only accept symbols with global or weak bindings. The common\n\t\t\t// alternative is STB_LOCAL, which are either function-scoped or declared\n\t\t\t// 'static'.\n\t\t\tif elf.ST_BIND(sym.Info) != elf.STB_GLOBAL &&\n\t\t\t\telf.ST_BIND(sym.Info) != elf.STB_WEAK {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ec.vars[sym.Name] != nil {\n\t\t\t\treturn fmt.Errorf(\"data section %s: duplicate variable %s\", sec.Name, sym.Name)\n\t\t\t}\n\n\t\t\t// Skip symbols starting with a dot, they are compiler-internal symbols\n\t\t\t// emitted by clang 11 and earlier and are not cleaned up by the bpf\n\t\t\t// compiler backend (e.g. symbols named .Lconstinit.1 in sections like\n\t\t\t// .rodata.cst32). Variables in C cannot start with a dot, so filter these\n\t\t\t// out.\n\t\t\tif strings.HasPrefix(sym.Name, \".\") {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tec.vars[sym.Name] = &VariableSpec{\n\t\t\t\tname:   sym.Name,\n\t\t\t\toffset: off,\n\t\t\t\tsize:   sym.Size,\n\t\t\t\tm:      mapSpec,\n\t\t\t}\n\t\t}\n\n\t\t// It is possible for a data section to exist without a corresponding BTF Datasec\n\t\t// if it only contains anonymous values like macro-defined arrays.\n\t\tif ec.btf != nil {\n\t\t\tvar ds *btf.Datasec\n\t\t\tif ec.btf.TypeByName(sec.Name, &ds) == nil {\n\t\t\t\t// Assign the spec's key and BTF only if the Datasec lookup was successful.\n\t\t\t\tmapSpec.Key = &btf.Void{}\n\t\t\t\tmapSpec.Value = ds\n\n\t\t\t\t// Populate VariableSpecs with type information, if available.\n\t\t\t\tfor _, v := range ds.Vars {\n\t\t\t\t\tname := v.Type.TypeName()\n\t\t\t\t\tif name == \"\" {\n\t\t\t\t\t\treturn fmt.Errorf(\"data section %s: anonymous variable %v\", sec.Name, v)\n\t\t\t\t\t}\n\n\t\t\t\t\tvt, ok := v.Type.(*btf.Var)\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn fmt.Errorf(\"data section %s: unexpected type %T for variable %s\", sec.Name, v.Type, name)\n\t\t\t\t\t}\n\n\t\t\t\t\tev := ec.vars[name]\n\t\t\t\t\tif ev == nil {\n\t\t\t\t\t\t// Hidden symbols appear in the BTF Datasec but don't receive a VariableSpec.\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\tif uint64(v.Offset) != ev.offset {\n\t\t\t\t\t\treturn fmt.Errorf(\"data section %s: variable %s datasec offset (%d) doesn't match ELF symbol offset (%d)\", sec.Name, name, v.Offset, ev.offset)\n\t\t\t\t\t}\n\n\t\t\t\t\tif uint64(v.Size) != ev.size {\n\t\t\t\t\t\treturn fmt.Errorf(\"data section %s: variable %s size in datasec (%d) doesn't match ELF symbol size (%d)\", sec.Name, name, v.Size, ev.size)\n\t\t\t\t\t}\n\n\t\t\t\t\t// Decouple the Var in the VariableSpec from the underlying DataSec in\n\t\t\t\t\t// the MapSpec to avoid modifications from affecting map loads later on.\n\t\t\t\t\tev.t = btf.Copy(vt).(*btf.Var)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tec.maps[sec.Name] = mapSpec\n\t}\n\n\treturn nil\n}\n\n// loadKconfigSection handles the 'virtual' Datasec .kconfig that doesn't\n// have a corresponding ELF section and exist purely in BTF.\nfunc (ec *elfCode) loadKconfigSection() error {\n\tif ec.btf == nil {\n\t\treturn nil\n\t}\n\n\tvar ds *btf.Datasec\n\terr := ec.btf.TypeByName(\".kconfig\", &ds)\n\tif errors.Is(err, btf.ErrNotFound) {\n\t\treturn nil\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif ds.Size == 0 {\n\t\treturn errors.New(\"zero-length .kconfig\")\n\t}\n\n\tec.kconfig = &MapSpec{\n\t\tName:       \".kconfig\",\n\t\tType:       Array,\n\t\tKeySize:    uint32(4),\n\t\tValueSize:  ds.Size,\n\t\tMaxEntries: 1,\n\t\tFlags:      sys.BPF_F_RDONLY_PROG,\n\t\tKey:        &btf.Int{Size: 4},\n\t\tValue:      ds,\n\t}\n\n\treturn nil\n}\n\n// loadKsymsSection handles the 'virtual' Datasec .ksyms that doesn't\n// have a corresponding ELF section and exist purely in BTF.\nfunc (ec *elfCode) loadKsymsSection() error {\n\tif ec.btf == nil {\n\t\treturn nil\n\t}\n\n\tvar ds *btf.Datasec\n\terr := ec.btf.TypeByName(\".ksyms\", &ds)\n\tif errors.Is(err, btf.ErrNotFound) {\n\t\treturn nil\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, v := range ds.Vars {\n\t\tswitch t := v.Type.(type) {\n\t\tcase *btf.Func:\n\t\t\tec.kfuncs[t.TypeName()] = t\n\t\tcase *btf.Var:\n\t\t\tec.ksyms[t.TypeName()] = struct{}{}\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unexpected variable type in .ksyms: %T\", v)\n\t\t}\n\t}\n\n\treturn nil\n}\n\ntype libbpfElfSectionDef struct {\n\tpattern     string\n\tprogramType sys.ProgType\n\tattachType  sys.AttachType\n\tflags       libbpfElfSectionFlag\n}\n\ntype libbpfElfSectionFlag uint32\n\n// The values correspond to enum sec_def_flags in libbpf.\nconst (\n\t_SEC_NONE libbpfElfSectionFlag = 0\n\n\t_SEC_EXP_ATTACH_OPT libbpfElfSectionFlag = 1 << (iota - 1)\n\t_SEC_ATTACHABLE\n\t_SEC_ATTACH_BTF\n\t_SEC_SLEEPABLE\n\t_SEC_XDP_FRAGS\n\t_SEC_USDT\n\n\t// Ignore any present extra in order to preserve backwards compatibility\n\t// with earlier versions of the library.\n\tignoreExtra\n\n\t_SEC_ATTACHABLE_OPT = _SEC_ATTACHABLE | _SEC_EXP_ATTACH_OPT\n)\n\nfunc init() {\n\t// Compatibility with older versions of the library.\n\t// We prepend libbpf definitions since they contain a prefix match\n\t// for \"xdp\".\n\telfSectionDefs = append([]libbpfElfSectionDef{\n\t\t{\"xdp.frags/\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP, _SEC_XDP_FRAGS | ignoreExtra},\n\t\t{\"xdp.frags_devmap/\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_DEVMAP, _SEC_XDP_FRAGS},\n\t\t{\"xdp_devmap/\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_DEVMAP, 0},\n\t\t{\"xdp.frags_cpumap/\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_CPUMAP, _SEC_XDP_FRAGS},\n\t\t{\"xdp_cpumap/\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_CPUMAP, 0},\n\t\t// This has been in the library since the beginning of time. Not sure\n\t\t// where it came from.\n\t\t{\"seccomp\", sys.BPF_PROG_TYPE_SOCKET_FILTER, 0, _SEC_NONE},\n\t}, elfSectionDefs...)\n}\n\nfunc getProgType(sectionName string) (ProgramType, AttachType, uint32, string) {\n\t// Skip optional program marking for now.\n\tsectionName = strings.TrimPrefix(sectionName, \"?\")\n\n\tfor _, t := range elfSectionDefs {\n\t\textra, ok := matchSectionName(sectionName, t.pattern)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tprogramType := ProgramType(t.programType)\n\t\tattachType := AttachType(t.attachType)\n\n\t\tvar flags uint32\n\t\tif t.flags&_SEC_SLEEPABLE > 0 {\n\t\t\tflags |= sys.BPF_F_SLEEPABLE\n\t\t}\n\t\tif t.flags&_SEC_XDP_FRAGS > 0 {\n\t\t\tflags |= sys.BPF_F_XDP_HAS_FRAGS\n\t\t}\n\t\tif t.flags&_SEC_EXP_ATTACH_OPT > 0 {\n\t\t\tif programType == XDP {\n\t\t\t\t// The library doesn't yet have code to fallback to not specifying\n\t\t\t\t// attach type. Only do this for XDP since we've enforced correct\n\t\t\t\t// attach type for all other program types.\n\t\t\t\tattachType = AttachNone\n\t\t\t}\n\t\t}\n\t\tif t.flags&ignoreExtra > 0 {\n\t\t\textra = \"\"\n\t\t}\n\n\t\treturn programType, attachType, flags, extra\n\t}\n\n\treturn UnspecifiedProgram, AttachNone, 0, \"\"\n}\n\n// matchSectionName checks a section name against a pattern.\n//\n// It's behaviour mirrors that of libbpf's sec_def_matches.\nfunc matchSectionName(sectionName, pattern string) (extra string, found bool) {\n\thave, extra, found := strings.Cut(sectionName, \"/\")\n\twant := strings.TrimRight(pattern, \"+/\")\n\n\tif strings.HasSuffix(pattern, \"/\") {\n\t\t// Section name must have a slash and extra may be empty.\n\t\treturn extra, have == want && found\n\t} else if strings.HasSuffix(pattern, \"+\") {\n\t\t// Section name may have a slash and extra may be empty.\n\t\treturn extra, have == want\n\t}\n\n\t// Section name must have a prefix. extra is ignored.\n\treturn \"\", strings.HasPrefix(sectionName, pattern)\n}\n\nfunc (ec *elfCode) loadSectionRelocations(sec *elf.Section, symbols []elf.Symbol) (map[uint64]elf.Symbol, error) {\n\trels := make(map[uint64]elf.Symbol)\n\n\tif sec.Entsize < 16 {\n\t\treturn nil, fmt.Errorf(\"section %s: relocations are less than 16 bytes\", sec.Name)\n\t}\n\n\tr := bufio.NewReader(sec.Open())\n\tfor off := uint64(0); off < sec.Size; off += sec.Entsize {\n\t\tent := io.LimitReader(r, int64(sec.Entsize))\n\n\t\tvar rel elf.Rel64\n\t\tif binary.Read(ent, ec.ByteOrder, &rel) != nil {\n\t\t\treturn nil, fmt.Errorf(\"can't parse relocation at offset %v\", off)\n\t\t}\n\n\t\tsymNo := int(elf.R_SYM64(rel.Info) - 1)\n\t\tif symNo >= len(symbols) {\n\t\t\treturn nil, fmt.Errorf(\"offset %d: symbol %d doesn't exist\", off, symNo)\n\t\t}\n\n\t\tsymbol := symbols[symNo]\n\t\trels[rel.Off] = symbol\n\t}\n\n\treturn rels, nil\n}\n"
        },
        {
          "name": "elf_reader_test.go",
          "type": "blob",
          "size": 36.4140625,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"syscall\"\n\t\"testing\"\n\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/kallsyms\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n\n\t\"github.com/google/go-cmp/cmp\"\n\t\"github.com/google/go-cmp/cmp/cmpopts\"\n\n\t\"github.com/go-quicktest/qt\"\n)\n\nfunc TestLoadCollectionSpec(t *testing.T) {\n\tcoll := &CollectionSpec{\n\t\tMaps: map[string]*MapSpec{\n\t\t\t\"hash_map\": {\n\t\t\t\tName:       \"hash_map\",\n\t\t\t\tType:       Hash,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  8,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tFlags:      sys.BPF_F_NO_PREALLOC,\n\t\t\t},\n\t\t\t\"hash_map2\": {\n\t\t\t\tName:       \"hash_map2\",\n\t\t\t\tType:       Hash,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  8,\n\t\t\t\tMaxEntries: 2,\n\t\t\t},\n\t\t\t\"array_of_hash_map\": {\n\t\t\t\tName:       \"array_of_hash_map\",\n\t\t\t\tType:       ArrayOfMaps,\n\t\t\t\tKeySize:    4,\n\t\t\t\tMaxEntries: 2,\n\t\t\t},\n\t\t\t\"perf_event_array\": {\n\t\t\t\tName:       \"perf_event_array\",\n\t\t\t\tType:       PerfEventArray,\n\t\t\t\tMaxEntries: 4096,\n\t\t\t},\n\t\t\t\"btf_pin\": {\n\t\t\t\tName:       \"btf_pin\",\n\t\t\t\tType:       Hash,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  8,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tPinning:    PinByName,\n\t\t\t},\n\t\t\t\"btf_outer_map\": {\n\t\t\t\tName:       \"btf_outer_map\",\n\t\t\t\tType:       ArrayOfMaps,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tInnerMap: &MapSpec{\n\t\t\t\t\tName:       \"btf_outer_map_inner\",\n\t\t\t\t\tType:       Hash,\n\t\t\t\t\tKeySize:    4,\n\t\t\t\t\tValueSize:  4,\n\t\t\t\t\tMaxEntries: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"btf_outer_map_anon\": {\n\t\t\t\tName:       \"btf_outer_map_anon\",\n\t\t\t\tType:       ArrayOfMaps,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tInnerMap: &MapSpec{\n\t\t\t\t\tName:       \"btf_outer_map_anon_inner\",\n\t\t\t\t\tType:       Hash,\n\t\t\t\t\tKeySize:    4,\n\t\t\t\t\tValueSize:  4,\n\t\t\t\t\tMaxEntries: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"btf_typedef_map\": {\n\t\t\t\tName:       \"btf_typedef_map\",\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  8,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t\t\".bss\": {\n\t\t\t\tName:       SanitizeName(\".bss\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t\t\".data\": {\n\t\t\t\tName:       SanitizeName(\".data\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t\t\".data.test\": {\n\t\t\t\tName:       SanitizeName(\".data.test\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t},\n\t\t\t\".rodata\": {\n\t\t\t\tName:       SanitizeName(\".rodata\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  24,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tFlags:      sys.BPF_F_RDONLY_PROG,\n\t\t\t},\n\t\t\t\".rodata.test\": {\n\t\t\t\tName:       SanitizeName(\".rodata.test\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tFlags:      sys.BPF_F_RDONLY_PROG,\n\t\t\t},\n\t\t\t\".rodata.cst32\": {\n\t\t\t\tName:       SanitizeName(\".rodata.cst32\", -1),\n\t\t\t\tType:       Array,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  32,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tFlags:      sys.BPF_F_RDONLY_PROG,\n\t\t\t},\n\t\t},\n\t\tPrograms: map[string]*ProgramSpec{\n\t\t\t\"xdp_prog\": {\n\t\t\t\tName:        \"xdp_prog\",\n\t\t\t\tType:        XDP,\n\t\t\t\tSectionName: \"xdp\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"no_relocation\": {\n\t\t\t\tName:        \"no_relocation\",\n\t\t\t\tType:        SocketFilter,\n\t\t\t\tSectionName: \"socket\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"asm_relocation\": {\n\t\t\t\tName:        \"asm_relocation\",\n\t\t\t\tType:        SocketFilter,\n\t\t\t\tSectionName: \"socket/2\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"data_sections\": {\n\t\t\t\tName:        \"data_sections\",\n\t\t\t\tType:        SocketFilter,\n\t\t\t\tSectionName: \"socket/3\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"global_fn3\": {\n\t\t\t\tName:        \"global_fn3\",\n\t\t\t\tType:        UnspecifiedProgram,\n\t\t\t\tSectionName: \"other\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"static_fn\": {\n\t\t\t\tName:        \"static_fn\",\n\t\t\t\tType:        UnspecifiedProgram,\n\t\t\t\tSectionName: \"static\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t\t\"anon_const\": {\n\t\t\t\tName:        \"anon_const\",\n\t\t\t\tType:        SocketFilter,\n\t\t\t\tSectionName: \"socket/4\",\n\t\t\t\tLicense:     \"MIT\",\n\t\t\t},\n\t\t},\n\t\tVariables: map[string]*VariableSpec{\n\t\t\t\"arg\":  {name: \"arg\", offset: 4, size: 4},\n\t\t\t\"arg2\": {name: \"arg2\", offset: 0, size: 4},\n\t\t\t\"arg3\": {name: \"arg3\", offset: 0, size: 4},\n\t\t\t\"key1\": {name: \"key1\", offset: 0, size: 4},\n\t\t\t\"key2\": {name: \"key2\", offset: 0, size: 4},\n\t\t\t\"key3\": {name: \"key3\", offset: 0, size: 4},\n\t\t\t\"neg\":  {name: \"neg\", offset: 12, size: 4},\n\t\t\t\"uneg\": {name: \"uneg\", offset: 8, size: 4},\n\t\t},\n\t}\n\n\tcmpOpts := cmp.Options{\n\t\t// Dummy Comparer that works with empty readers to support test cases.\n\t\tcmp.Comparer(func(a, b bytes.Reader) bool {\n\t\t\tif a.Len() == 0 && b.Len() == 0 {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t}),\n\t\tcmp.Comparer(func(a, b *VariableSpec) bool {\n\t\t\tif a.name != b.name || a.offset != b.offset || a.size != b.size {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn true\n\t\t}),\n\t\tcmpopts.IgnoreTypes(new(btf.Spec)),\n\t\tcmpopts.IgnoreFields(CollectionSpec{}, \"ByteOrder\", \"Types\"),\n\t\tcmpopts.IgnoreFields(ProgramSpec{}, \"Instructions\", \"ByteOrder\"),\n\t\tcmpopts.IgnoreFields(MapSpec{}, \"Key\", \"Value\", \"Contents\"),\n\t\tcmpopts.IgnoreUnexported(ProgramSpec{}),\n\t}\n\n\ttestutils.Files(t, testutils.Glob(t, \"testdata/loader-*.elf\"), func(t *testing.T, file string) {\n\t\thave, err := LoadCollectionSpec(file)\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t\t}\n\n\t\terr = have.RewriteConstants(map[string]interface{}{\n\t\t\t\"arg\":  uint32(1),\n\t\t\t\"arg2\": uint32(2),\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't rewrite constant:\", err)\n\t\t}\n\n\t\terr = have.RewriteConstants(map[string]interface{}{\n\t\t\t\"totallyBogus\":  uint32(1),\n\t\t\t\"totallyBogus2\": uint32(2),\n\t\t})\n\t\tif err == nil {\n\t\t\tt.Error(\"Rewriting a bogus constant doesn't fail\")\n\t\t}\n\n\t\tvar mErr *MissingConstantsError\n\t\tif !errors.As(err, &mErr) {\n\t\t\tt.Fatal(\"Error doesn't wrap MissingConstantsError:\", err)\n\t\t}\n\t\tqt.Assert(t, qt.ContentEquals(mErr.Constants, []string{\"totallyBogus\", \"totallyBogus2\"}))\n\n\t\tqt.Assert(t, qt.Equals(have.Maps[\"perf_event_array\"].ValueSize, 0))\n\t\tqt.Assert(t, qt.IsNotNil(have.Maps[\"perf_event_array\"].Value))\n\n\t\tif diff := cmp.Diff(coll, have, cmpOpts...); diff != \"\" {\n\t\t\tt.Errorf(\"MapSpec mismatch (-want +got):\\n%s\", diff)\n\t\t}\n\n\t\tif have.ByteOrder != internal.NativeEndian {\n\t\t\treturn\n\t\t}\n\n\t\thave.Maps[\"array_of_hash_map\"].InnerMap = have.Maps[\"hash_map\"]\n\t\tcoll, err := NewCollectionWithOptions(have, CollectionOptions{\n\t\t\tMaps: MapOptions{\n\t\t\t\tPinPath: testutils.TempBPFFS(t),\n\t\t\t},\n\t\t\tPrograms: ProgramOptions{\n\t\t\t\tLogLevel: LogLevelBranch,\n\t\t\t},\n\t\t})\n\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tdefer coll.Close()\n\n\t\tret, _, err := coll.Programs[\"xdp_prog\"].Test(internal.EmptyBPFContext)\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't run program:\", err)\n\t\t}\n\n\t\tif ret != 7 {\n\t\t\tt.Error(\"Unexpected return value:\", ret)\n\t\t}\n\t})\n}\n\nfunc BenchmarkELFLoader(b *testing.B) {\n\tb.ReportAllocs()\n\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = LoadCollectionSpec(\"testdata/loader-el.elf\")\n\t}\n}\n\nfunc TestDataSections(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/loader-%s.elf\")\n\tcoll, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tt.Log(coll.Programs[\"data_sections\"].Instructions)\n\n\tvar obj struct {\n\t\tProgram *Program `ebpf:\"data_sections\"`\n\t}\n\n\terr = coll.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.Program.Close()\n\n\tret, _, err := obj.Program.Test(internal.EmptyBPFContext)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 0 {\n\t\tt.Error(\"BPF assertion failed on line\", ret)\n\t}\n}\n\nfunc TestInlineASMConstant(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/loader-%s.elf\")\n\tcoll, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tspec := coll.Programs[\"asm_relocation\"]\n\tif spec.Instructions[0].Reference() != \"MY_CONST\" {\n\t\tt.Fatal(\"First instruction is not a reference to MY_CONST\")\n\t}\n\n\t// -1 is used by the loader to find unrewritten maps.\n\tspec.Instructions[0].Constant = -1\n\n\tt.Log(spec.Instructions)\n\n\tvar obj struct {\n\t\tProgram *Program `ebpf:\"asm_relocation\"`\n\t}\n\n\terr = coll.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tobj.Program.Close()\n}\n\nfunc TestFreezeRodata(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.9\", \"sk_lookup program type\")\n\n\tfile := testutils.NativeFile(t, \"testdata/constants-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tProgram *Program `ebpf:\"freeze_rodata\"`\n\t}\n\n\tif err := spec.RewriteConstants(map[string]interface{}{\n\t\t\"ret\": uint32(1),\n\t}); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.Program.Close()\n}\n\nfunc TestCollectionSpecDetach(t *testing.T) {\n\tcoll := Collection{\n\t\tMaps: map[string]*Map{\n\t\t\t\"foo\": new(Map),\n\t\t},\n\t\tPrograms: map[string]*Program{\n\t\t\t\"bar\": new(Program),\n\t\t},\n\t}\n\n\tfoo := coll.DetachMap(\"foo\")\n\tif foo == nil {\n\t\tt.Error(\"Program not returned from DetachMap\")\n\t}\n\n\tif _, ok := coll.Programs[\"foo\"]; ok {\n\t\tt.Error(\"DetachMap doesn't remove map from Maps\")\n\t}\n\n\tbar := coll.DetachProgram(\"bar\")\n\tif bar == nil {\n\t\tt.Fatal(\"Program not returned from DetachProgram\")\n\t}\n\n\tif _, ok := coll.Programs[\"bar\"]; ok {\n\t\tt.Error(\"DetachProgram doesn't remove program from Programs\")\n\t}\n}\n\nfunc TestLoadInvalidMap(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/invalid_map-%s.elf\")\n\tcs, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(\"Can't load CollectionSpec\", err)\n\t}\n\n\tms, ok := cs.Maps[\"invalid_map\"]\n\tif !ok {\n\t\tt.Fatal(\"invalid_map not found in CollectionSpec\")\n\t}\n\n\tm, err := NewMap(ms)\n\tt.Log(err)\n\tif err == nil {\n\t\tm.Close()\n\t\tt.Fatal(\"Creating a Map from a MapSpec with non-zero Extra is expected to fail.\")\n\t}\n}\n\nfunc TestLoadInvalidMapMissingSymbol(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/invalid_map_static-%s.elf\")\n\t_, err := LoadCollectionSpec(file)\n\tt.Log(err)\n\tif err == nil {\n\t\tt.Fatal(\"Loading a map with static qualifier should fail\")\n\t}\n}\n\nfunc TestLoadInitializedBTFMap(t *testing.T) {\n\ttestutils.Files(t, testutils.Glob(t, \"testdata/btf_map_init-*.elf\"), func(t *testing.T, file string) {\n\t\tcoll, err := LoadCollectionSpec(file)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tt.Run(\"NewCollection\", func(t *testing.T) {\n\t\t\tif coll.ByteOrder != internal.NativeEndian {\n\t\t\t\tt.Skipf(\"Skipping %s collection\", coll.ByteOrder)\n\t\t\t}\n\n\t\t\ttmp, err := NewCollection(coll)\n\t\t\ttestutils.SkipIfNotSupported(t, err)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(\"NewCollection failed:\", err)\n\t\t\t}\n\t\t\ttmp.Close()\n\t\t})\n\n\t\tt.Run(\"prog_array\", func(t *testing.T) {\n\t\t\tm, ok := coll.Maps[\"prog_array_init\"]\n\t\t\tif !ok {\n\t\t\t\tt.Fatal(\"map prog_array_init not found in program\")\n\t\t\t}\n\n\t\t\tif len(m.Contents) != 1 {\n\t\t\t\tt.Error(\"expecting exactly 1 item in MapSpec contents\")\n\t\t\t}\n\n\t\t\tp := m.Contents[0]\n\t\t\tif cmp.Equal(p.Key, 1) {\n\t\t\t\tt.Errorf(\"expecting MapSpec entry Key to equal 1, got %v\", p.Key)\n\t\t\t}\n\n\t\t\tif _, ok := p.Value.(string); !ok {\n\t\t\t\tt.Errorf(\"expecting MapSpec entry Value to be a string, got %T\", p.Value)\n\t\t\t}\n\n\t\t\tif p.Value != \"tail_1\" {\n\t\t\t\tt.Errorf(\"expected MapSpec entry Value 'tail_1', got: %s\", p.Value)\n\t\t\t}\n\t\t})\n\n\t\tt.Run(\"array_of_maps\", func(t *testing.T) {\n\t\t\tm, ok := coll.Maps[\"outer_map_init\"]\n\t\t\tif !ok {\n\t\t\t\tt.Fatal(\"map outer_map_init not found in program\")\n\t\t\t}\n\n\t\t\tif len(m.Contents) != 1 {\n\t\t\t\tt.Error(\"expecting exactly 1 item in MapSpec contents\")\n\t\t\t}\n\n\t\t\tif m.Key == nil {\n\t\t\t\tt.Error(\"Expected non-nil key\")\n\t\t\t}\n\n\t\t\tif m.Value == nil {\n\t\t\t\tt.Error(\"Expected non-nil value\")\n\t\t\t}\n\n\t\t\tif m.InnerMap.Key == nil {\n\t\t\t\tt.Error(\"Expected non-nil InnerMap key\")\n\t\t\t}\n\n\t\t\tif m.InnerMap.Value == nil {\n\t\t\t\tt.Error(\"Expected non-nil InnerMap value\")\n\t\t\t}\n\n\t\t\tp := m.Contents[0]\n\t\t\tif cmp.Equal(p.Key, 1) {\n\t\t\t\tt.Errorf(\"expecting MapSpec entry Key to equal 1, got %v\", p.Key)\n\t\t\t}\n\n\t\t\tif _, ok := p.Value.(string); !ok {\n\t\t\t\tt.Errorf(\"expecting MapSpec entry Value to be a string, got %T\", p.Value)\n\t\t\t}\n\n\t\t\tif p.Value != \"inner_map\" {\n\t\t\t\tt.Errorf(\"expected MapSpec entry Value 'inner_map', got: %s\", p.Value)\n\t\t\t}\n\t\t})\n\t})\n}\n\nfunc TestLoadInvalidInitializedBTFMap(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/invalid_btf_map_init-%s.elf\")\n\t_, err := LoadCollectionSpec(file)\n\tt.Log(err)\n\tif !errors.Is(err, internal.ErrNotSupported) {\n\t\tt.Fatal(\"Loading an initialized BTF map should be unsupported\")\n\t}\n}\n\nfunc TestStringSection(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/strings-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatalf(\"load collection spec: %s\", err)\n\t}\n\n\tfor name := range spec.Maps {\n\t\tt.Log(name)\n\t}\n\n\tstrMap := spec.Maps[\".rodata.str1.1\"]\n\tif strMap == nil {\n\t\tt.Fatal(\"Unable to find map '.rodata.str1.1' in loaded collection\")\n\t}\n\n\tif !strMap.readOnly() {\n\t\tt.Fatal(\"Read only data maps should be frozen\")\n\t}\n\n\tif strMap.Flags != sys.BPF_F_RDONLY_PROG {\n\t\tt.Fatal(\"Read only data maps should have the prog-read-only flag set\")\n\t}\n\n\tcoll, err := NewCollection(spec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatalf(\"new collection: %s\", err)\n\t}\n\tdefer coll.Close()\n\n\tprog := coll.Programs[\"filter\"]\n\tif prog == nil {\n\t\tt.Fatal(\"program not found\")\n\t}\n\n\ttestMap := coll.Maps[\"my_map\"]\n\tif testMap == nil {\n\t\tt.Fatal(\"test map not found\")\n\t}\n\n\t_, err = prog.Run(&RunOptions{\n\t\tData: internal.EmptyBPFContext, // Min size for XDP programs\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"prog run: %s\", err)\n\t}\n\n\tkey := []byte(\"This string is allocated in the string section\\n\\x00\")\n\tvar value uint32\n\tif err = testMap.Lookup(&key, &value); err != nil {\n\t\tt.Fatalf(\"test map lookup: %s\", err)\n\t}\n\n\tif value != 1 {\n\t\tt.Fatal(\"Test map value not 1!\")\n\t}\n}\n\nfunc TestLoadRawTracepoint(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.17\", \"BPF_RAW_TRACEPOINT API\")\n\n\tfile := testutils.NativeFile(t, \"testdata/raw_tracepoint-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\n\tcoll, err := NewCollectionWithOptions(spec, CollectionOptions{\n\t\tPrograms: ProgramOptions{\n\t\t\tLogLevel: LogLevelBranch,\n\t\t},\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Can't create collection:\", err)\n\t}\n\n\tcoll.Close()\n}\n\nfunc TestTailCall(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/btf_map_init-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tTailMain  *Program `ebpf:\"tail_main\"`\n\t\tProgArray *Map     `ebpf:\"prog_array_init\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.TailMain.Close()\n\tdefer obj.ProgArray.Close()\n\n\tret, _, err := obj.TailMain.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Expect the tail_1 tail call to be taken, returning value 42.\n\tif ret != 42 {\n\t\tt.Fatalf(\"Expected tail call to return value 42, got %d\", ret)\n\t}\n}\n\nfunc TestKconfig(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/kconfig-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMain *Program `ebpf:\"kconfig\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.Main.Close()\n\n\tret, _, err := obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tqt.Assert(t, qt.Equals(ret, 0), qt.Commentf(\"Failed assertion at line %d in testdata/kconfig.c\", ret))\n}\n\nfunc TestKsym(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/ksym-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tvar obj struct {\n\t\tMain     *Program `ebpf:\"ksym_test\"`\n\t\tArrayMap *Map     `ebpf:\"array_map\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer obj.Main.Close()\n\tdefer obj.ArrayMap.Close()\n\n\t_, _, err = obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tksyms := map[string]uint64{\n\t\t\"bpf_init\":       0,\n\t\t\"bpf_trace_run1\": 0,\n\t}\n\n\tqt.Assert(t, qt.IsNil(kallsyms.AssignAddresses(ksyms)))\n\tqt.Assert(t, qt.Not(qt.Equals(ksyms[\"bpf_init\"], 0)))\n\tqt.Assert(t, qt.Not(qt.Equals(ksyms[\"bpf_trace_run1\"], 0)))\n\n\tvar value uint64\n\tqt.Assert(t, qt.IsNil(obj.ArrayMap.Lookup(uint32(0), &value)))\n\tqt.Assert(t, qt.Equals(value, ksyms[\"bpf_init\"]))\n\n\tqt.Assert(t, qt.IsNil(obj.ArrayMap.Lookup(uint32(1), &value)))\n\tqt.Assert(t, qt.Equals(value, ksyms[\"bpf_trace_run1\"]))\n}\n\nfunc TestKsymWeakMissing(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/ksym-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tvar obj struct {\n\t\tMain *Program `ebpf:\"ksym_missing_test\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer obj.Main.Close()\n\n\tres, _, err := obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(res, 1))\n}\n\nfunc TestKfunc(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.18\", \"kfunc support\")\n\tfile := testutils.NativeFile(t, \"testdata/kfunc-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMain *Program `ebpf:\"call_kfunc\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatalf(\"%+v\", err)\n\t}\n\tdefer obj.Main.Close()\n\n\tret, _, err := obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 1 {\n\t\tt.Fatalf(\"Expected kfunc to return value 1, got %d\", ret)\n\t}\n}\n\nfunc TestWeakKfunc(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.18\", \"kfunc support\")\n\tfile := testutils.NativeFile(t, \"testdata/kfunc-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMissing *Program `ebpf:\"weak_kfunc_missing\"`\n\t\tCalling *Program `ebpf:\"call_weak_kfunc\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatalf(\"%+v\", err)\n\t}\n\tdefer obj.Missing.Close()\n\tdefer obj.Calling.Close()\n}\n\nfunc TestInvalidKfunc(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.18\", \"kfunc support\")\n\n\tif !haveTestmod(t) {\n\t\tt.Skip(\"bpf_testmod not loaded\")\n\t}\n\n\tfile := testutils.NativeFile(t, \"testdata/invalid-kfunc-%s.elf\")\n\tcoll, err := LoadCollection(file)\n\tif err == nil {\n\t\tcoll.Close()\n\t\tt.Fatal(\"Expected an error\")\n\t}\n\n\tvar ike *incompatibleKfuncError\n\tif !errors.As(err, &ike) {\n\t\tt.Fatalf(\"Expected an error wrapping incompatibleKfuncError, got %s\", err)\n\t}\n}\n\nfunc TestKfuncKmod(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.18\", \"Kernel module function calls\")\n\n\tif !haveTestmod(t) {\n\t\tt.Skip(\"bpf_testmod not loaded\")\n\t}\n\n\tfile := testutils.NativeFile(t, \"testdata/kfunc-kmod-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMain *Program `ebpf:\"call_kfunc\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatalf(\"%v+\", err)\n\t}\n\tdefer obj.Main.Close()\n\n\tret, _, err := obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 1 {\n\t\tt.Fatalf(\"Expected kfunc to return value 1, got %d\", ret)\n\t}\n}\n\nfunc TestSubprogRelocation(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.13\", \"bpf_for_each_map_elem\")\n\n\tfile := testutils.NativeFile(t, \"testdata/subprog_reloc-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMain    *Program `ebpf:\"fp_relocation\"`\n\t\tHashMap *Map     `ebpf:\"hash_map\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.Main.Close()\n\tdefer obj.HashMap.Close()\n\n\tret, _, err := obj.Main.Test(internal.EmptyBPFContext)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 42 {\n\t\tt.Fatalf(\"Expected subprog reloc to return value 42, got %d\", ret)\n\t}\n}\n\nfunc TestUnassignedProgArray(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/btf_map_init-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// tail_main references a ProgArray that is not being assigned\n\t// to this struct. Normally, this would clear all its entries\n\t// and make any tail calls into the ProgArray result in a miss.\n\t// The library needs to explicitly refuse such operations.\n\tvar obj struct {\n\t\tTailMain *Program `ebpf:\"tail_main\"`\n\t\t// ProgArray *Map     `ebpf:\"prog_array_init\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err == nil {\n\t\tobj.TailMain.Close()\n\t\tt.Fatal(\"Expecting LoadAndAssign to return error\")\n\t}\n}\n\nfunc TestIPRoute2Compat(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/iproute2_map_compat-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\n\tms, ok := spec.Maps[\"hash_map\"]\n\tif !ok {\n\t\tt.Fatal(\"Map hash_map not found\")\n\t}\n\n\tvar id, pinning, innerID, innerIndex uint32\n\n\tif ms.Extra == nil {\n\t\tt.Fatal(\"missing extra bytes\")\n\t}\n\n\tswitch {\n\tcase binary.Read(ms.Extra, spec.ByteOrder, &id) != nil:\n\t\tt.Fatal(\"missing id\")\n\tcase binary.Read(ms.Extra, spec.ByteOrder, &pinning) != nil:\n\t\tt.Fatal(\"missing pinning\")\n\tcase binary.Read(ms.Extra, spec.ByteOrder, &innerID) != nil:\n\t\tt.Fatal(\"missing inner_id\")\n\tcase binary.Read(ms.Extra, spec.ByteOrder, &innerIndex) != nil:\n\t\tt.Fatal(\"missing inner_idx\")\n\t}\n\n\tif id != 0 || innerID != 0 || innerIndex != 0 {\n\t\tt.Fatal(\"expecting id, inner_id and inner_idx to be zero\")\n\t}\n\n\tif pinning != 2 {\n\t\tt.Fatal(\"expecting pinning field to be 2 (PIN_GLOBAL_NS)\")\n\t}\n\n\t// iproute2 (tc) pins maps in /sys/fs/bpf/tc/globals with PIN_GLOBAL_NS,\n\t// which needs to be configured in this library using MapOptions.PinPath.\n\t// For the sake of the test, we use a tempdir on bpffs below.\n\tms.Pinning = PinByName\n\n\tcoll, err := NewCollectionWithOptions(spec, CollectionOptions{\n\t\tMaps: MapOptions{\n\t\t\tPinPath: testutils.TempBPFFS(t),\n\t\t},\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Can't create collection:\", err)\n\t}\n\n\tcoll.Close()\n}\n\nvar (\n\telfPath    = flag.String(\"elfs\", os.Getenv(\"CI_KERNEL_SELFTESTS\"), \"`Path` containing libbpf-compatible ELFs (defaults to $CI_KERNEL_SELFTESTS)\")\n\telfPattern = flag.String(\"elf-pattern\", \"*.o\", \"Glob `pattern` for object files that should be tested\")\n)\n\nfunc TestLibBPFCompat(t *testing.T) {\n\tif *elfPath == \"\" {\n\t\t// Specify the path to the directory containing the eBPF for\n\t\t// the kernel's selftests if you want to run this test.\n\t\t// As of 5.2 that is tools/testing/selftests/bpf/\n\t\tt.Skip(\"No path specified\")\n\t}\n\n\tload := func(t *testing.T, spec *CollectionSpec, opts CollectionOptions, valid bool) {\n\t\t// Disable retrying a program load with the log enabled, it leads\n\t\t// to OOM kills.\n\t\topts.Programs.LogDisabled = true\n\n\t\tcoll, err := NewCollectionWithOptions(spec, opts)\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tvar errno syscall.Errno\n\t\tif errors.As(err, &errno) {\n\t\t\t// This error is most likely from a syscall and caused by us not\n\t\t\t// replicating some fixups done in the selftests or the test\n\t\t\t// intentionally failing. This is expected, so skip the test\n\t\t\t// instead of failing.\n\t\t\tt.Skip(\"Skipping since the kernel rejected the program:\", err)\n\t\t}\n\t\tif err == nil {\n\t\t\tcoll.Close()\n\t\t}\n\t\tif !valid {\n\t\t\tif err == nil {\n\t\t\t\tt.Fatal(\"Expected an error during load\")\n\t\t\t}\n\t\t} else if err != nil {\n\t\t\tt.Fatal(\"Error during loading:\", err)\n\t\t}\n\t}\n\n\tfiles := testutils.Glob(t, filepath.Join(*elfPath, *elfPattern),\n\t\t// These files are only used as a source of btf.\n\t\t\"btf__core_reloc_*\",\n\t)\n\n\ttestutils.Files(t, files, func(t *testing.T, path string) {\n\t\tname := selftestName(path)\n\t\tswitch name {\n\t\tcase \"test_map_in_map\", \"test_select_reuseport_kern\":\n\t\t\tt.Skip(\"Skipping due to missing InnerMap in map definition\")\n\t\tcase \"test_core_autosize\":\n\t\t\tt.Skip(\"Skipping since the test generates dynamic BTF\")\n\t\tcase \"test_static_linked\":\n\t\t\tt.Skip(\"Skipping since .text contains 'subprog' twice\")\n\t\tcase \"bloom_filter_map\", \"bloom_filter_bench\":\n\t\t\tt.Skip(\"Skipping due to missing MapExtra field in MapSpec\")\n\t\tcase \"netif_receive_skb\",\n\t\t\t\"local_kptr_stash\",\n\t\t\t\"local_kptr_stash_fail\",\n\t\t\t\"type_cast\",\n\t\t\t\"preempted_bpf_ma_op\",\n\t\t\t\"percpu_alloc_fail\":\n\t\t\t// Error message like\n\t\t\t//    fixup for CORERelocation(local_type_id, Struct:\"bin_data\"[0],\n\t\t\t//    local_id=27): invalid immediate 31, expected 27 (fixup: local_type_id=27->1)\n\t\t\t// See https://github.com/cilium/ebpf/issues/739\n\t\t\tt.Skip(\"Skipping due to bug in libbpf type deduplication\")\n\t\tcase \"test_usdt\", \"test_urandom_usdt\", \"test_usdt_multispec\":\n\t\t\tt.Skip(\"Skipping due to missing support for usdt.bpf.h\")\n\t\tcase \"lsm_cgroup\", \"bpf_iter_ipv6_route\", \"test_core_extern\",\n\t\t\t\"profiler1\", \"profiler2\", \"profiler3\":\n\t\t\tt.Skip(\"Skipping due to using weak CONFIG_* variables\")\n\t\tcase \"linked_maps\", \"linked_maps1\", \"linked_maps2\", \"linked_funcs1\", \"linked_funcs2\",\n\t\t\t\"test_subskeleton\", \"test_subskeleton_lib\":\n\t\t\tt.Skip(\"Skipping due to relying on cross ELF linking\")\n\t\tcase \"test_log_fixup\":\n\t\t\tt.Skip(\"Skipping due to intentionally broken CO-RE relocations\")\n\t\t}\n\n\t\tt.Parallel()\n\n\t\tspec, err := LoadCollectionSpec(path)\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tif errors.Is(err, errUnsupportedBinding) {\n\t\t\tt.Skip(err)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tswitch name {\n\t\tcase \"test_sk_assign\":\n\t\t\t// Test contains a legacy iproute2 bpf_elf_map definition.\n\t\t\tfor _, m := range spec.Maps {\n\t\t\t\tif m.Extra == nil || m.Extra.Len() == 0 {\n\t\t\t\t\tt.Fatalf(\"Expected extra bytes in map %s\", m.Name)\n\t\t\t\t}\n\t\t\t\tm.Extra = nil\n\t\t\t}\n\n\t\tcase \"fexit_bpf2bpf\",\n\t\t\t\"freplace_get_constant\",\n\t\t\t\"freplace_global_func\":\n\t\t\tloadTargetProgram(t, spec, \"test_pkt_access.bpf.o\", \"test_pkt_access\")\n\n\t\tcase \"freplace_cls_redirect\":\n\t\t\tloadTargetProgram(t, spec, \"test_cls_redirect.bpf.o\", \"cls_redirect\")\n\n\t\tcase \"test_trace_ext\":\n\t\t\tloadTargetProgram(t, spec, \"test_pkt_md_access.bpf.o\", \"test_pkt_md_access\")\n\n\t\tcase \"freplace_progmap\":\n\t\t\tloadTargetProgram(t, spec, \"xdp_dummy.bpf.o\", \"xdp_dummy_prog\")\n\n\t\t\tif prog := spec.Programs[\"xdp_cpumap_prog\"]; prog.AttachTo == \"\" {\n\t\t\t\tprog.AttachTo = \"xdp_dummy_prog\"\n\t\t\t}\n\n\t\tcase \"freplace_attach_probe\":\n\t\t\t// Looks like the test should have a target, but 6.6 selftests don't\n\t\t\t// seem to be using it.\n\t\t}\n\n\t\tvar opts CollectionOptions\n\t\tfor _, mapSpec := range spec.Maps {\n\t\t\tif mapSpec.Pinning != PinNone {\n\t\t\t\topts.Maps.PinPath = testutils.TempBPFFS(t)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tcoreFiles := sourceOfBTF(t, path)\n\t\tif len(coreFiles) == 0 {\n\t\t\t// NB: test_core_reloc_kernel.o doesn't have dedicated BTF and\n\t\t\t// therefore goes via this code path.\n\t\t\tload(t, spec, opts, true)\n\t\t\treturn\n\t\t}\n\n\t\tfor _, coreFile := range coreFiles {\n\t\t\tname := selftestName(coreFile)\n\t\t\tt.Run(name, func(t *testing.T) {\n\t\t\t\t// Some files like btf__core_reloc_arrays___err_too_small.o\n\t\t\t\t// trigger an error on purpose. Use the name to infer whether\n\t\t\t\t// the test should succeed.\n\t\t\t\tvar valid bool\n\t\t\t\tswitch name {\n\t\t\t\tcase \"btf__core_reloc_existence___err_wrong_arr_kind\",\n\t\t\t\t\t\"btf__core_reloc_existence___err_wrong_arr_value_type\",\n\t\t\t\t\t\"btf__core_reloc_existence___err_wrong_int_kind\",\n\t\t\t\t\t\"btf__core_reloc_existence___err_wrong_int_sz\",\n\t\t\t\t\t\"btf__core_reloc_existence___err_wrong_int_type\",\n\t\t\t\t\t\"btf__core_reloc_existence___err_wrong_struct_type\":\n\t\t\t\t\t// These tests are buggy upstream, see https://lore.kernel.org/bpf/20210420111639.155580-1-lmb@cloudflare.com/\n\t\t\t\t\tvalid = true\n\t\t\t\tcase \"btf__core_reloc_ints___err_wrong_sz_16\",\n\t\t\t\t\t\"btf__core_reloc_ints___err_wrong_sz_32\",\n\t\t\t\t\t\"btf__core_reloc_ints___err_wrong_sz_64\",\n\t\t\t\t\t\"btf__core_reloc_ints___err_wrong_sz_8\",\n\t\t\t\t\t\"btf__core_reloc_arrays___err_wrong_val_type1\",\n\t\t\t\t\t\"btf__core_reloc_arrays___err_wrong_val_type2\":\n\t\t\t\t\t// These tests are valid according to current libbpf behaviour,\n\t\t\t\t\t// see commit 42765ede5c54ca915de5bfeab83be97207e46f68.\n\t\t\t\t\tvalid = true\n\t\t\t\tcase \"btf__core_reloc_type_id___missing_targets\",\n\t\t\t\t\t\"btf__core_reloc_flavors__err_wrong_name\":\n\t\t\t\t\tvalid = false\n\t\t\t\tcase \"btf__core_reloc_ints___err_bitfield\":\n\t\t\t\t\t// Bitfields are now valid.\n\t\t\t\t\tvalid = true\n\t\t\t\tdefault:\n\t\t\t\t\tvalid = !strings.Contains(name, \"___err_\")\n\t\t\t\t}\n\n\t\t\t\tfh, err := os.Open(coreFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\t\t\t\tdefer fh.Close()\n\n\t\t\t\tbtfSpec, err := btf.LoadSpec(coreFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\topts := opts // copy\n\t\t\t\topts.Programs.KernelTypes = btfSpec\n\t\t\t\tload(t, spec, opts, valid)\n\t\t\t})\n\t\t}\n\t})\n}\n\nfunc loadTargetProgram(tb testing.TB, spec *CollectionSpec, file, program string) {\n\ttargetSpec, err := LoadCollectionSpec(filepath.Join(*elfPath, file))\n\tif errors.Is(err, os.ErrNotExist) && strings.HasSuffix(file, \".bpf.o\") {\n\t\t// Prior to v6.1 BPF ELF used a plain .o suffix.\n\t\tfile = strings.TrimSuffix(file, \".bpf.o\") + \".o\"\n\t\ttargetSpec, err = LoadCollectionSpec(filepath.Join(*elfPath, file))\n\t}\n\tif err != nil {\n\t\ttb.Fatalf(\"Can't read %s: %s\", file, err)\n\t}\n\n\tqt.Assert(tb, qt.IsNotNil(targetSpec.Programs[program]))\n\n\tcoll, err := NewCollectionWithOptions(targetSpec, CollectionOptions{\n\t\tPrograms: ProgramOptions{LogDisabled: true},\n\t})\n\tif err != nil {\n\t\ttb.Fatalf(\"Can't load target: %s\", err)\n\t}\n\ttb.Cleanup(func() { coll.Close() })\n\n\ttarget := coll.Programs[program]\n\tfor _, prog := range spec.Programs {\n\t\tif prog.Type == Extension && prog.AttachType == AttachNone {\n\t\t\tprog.AttachTarget = target\n\t\t\tcontinue\n\t\t}\n\n\t\tif prog.Type == Tracing {\n\t\t\tswitch prog.AttachType {\n\t\t\tcase AttachTraceFEntry, AttachTraceFExit, AttachModifyReturn:\n\t\t\t\tprog.AttachTarget = target\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc sourceOfBTF(tb testing.TB, path string) []string {\n\tconst testPrefix = \"test_core_reloc_\"\n\tconst btfPrefix = \"btf__core_reloc_\"\n\n\tdir, base := filepath.Split(path)\n\tif !strings.HasPrefix(base, testPrefix) {\n\t\treturn nil\n\t}\n\n\tbase = strings.TrimSuffix(base[len(testPrefix):], \".o\")\n\tswitch base {\n\tcase \"bitfields_direct\", \"bitfields_probed\":\n\t\tbase = \"bitfields\"\n\t}\n\n\treturn testutils.Glob(tb, filepath.Join(dir, btfPrefix+base+\"*.o\"))\n}\n\nfunc TestELFSectionProgramTypes(t *testing.T) {\n\ttype testcase struct {\n\t\tSection     string\n\t\tProgramType ProgramType\n\t\tAttachType  AttachType\n\t\tFlags       uint32\n\t\tExtra       string\n\t}\n\n\ttestcases := []testcase{\n\t\t{\"socket\", SocketFilter, AttachNone, 0, \"\"},\n\t\t{\"socket/garbage\", SocketFilter, AttachNone, 0, \"\"},\n\t\t{\"sk_reuseport/migrate\", SkReuseport, AttachSkReuseportSelectOrMigrate, 0, \"\"},\n\t\t{\"sk_reuseport\", SkReuseport, AttachSkReuseportSelect, 0, \"\"},\n\t\t{\"kprobe/\", Kprobe, AttachNone, 0, \"\"},\n\t\t{\"kprobe/func\", Kprobe, AttachNone, 0, \"func\"},\n\t\t{\"uprobe/\", Kprobe, AttachNone, 0, \"\"},\n\t\t{\"kretprobe/\", Kprobe, AttachNone, 0, \"\"},\n\t\t{\"uretprobe/\", Kprobe, AttachNone, 0, \"\"},\n\t\t{\"tc\", SchedCLS, AttachNone, 0, \"\"},\n\t\t{\"classifier\", SchedCLS, AttachNone, 0, \"\"},\n\t\t{\"action\", SchedACT, AttachNone, 0, \"\"},\n\t\t{\"tracepoint/\", TracePoint, AttachNone, 0, \"\"},\n\t\t{\"tp/\", TracePoint, AttachNone, 0, \"\"},\n\t\t{\"raw_tracepoint/\", RawTracepoint, AttachNone, 0, \"\"},\n\t\t{\"raw_tp/\", RawTracepoint, AttachNone, 0, \"\"},\n\t\t{\"raw_tracepoint.w/\", RawTracepointWritable, AttachNone, 0, \"\"},\n\t\t{\"raw_tp.w/\", RawTracepointWritable, AttachNone, 0, \"\"},\n\t\t{\"tp_btf/\", Tracing, AttachTraceRawTp, 0, \"\"},\n\t\t{\"fentry/\", Tracing, AttachTraceFEntry, 0, \"\"},\n\t\t{\"fmod_ret/\", Tracing, AttachModifyReturn, 0, \"\"},\n\t\t{\"fexit/\", Tracing, AttachTraceFExit, 0, \"\"},\n\t\t{\"fentry.s/\", Tracing, AttachTraceFEntry, sys.BPF_F_SLEEPABLE, \"\"},\n\t\t{\"fmod_ret.s/\", Tracing, AttachModifyReturn, sys.BPF_F_SLEEPABLE, \"\"},\n\t\t{\"fexit.s/\", Tracing, AttachTraceFExit, sys.BPF_F_SLEEPABLE, \"\"},\n\t\t{\"freplace/\", Extension, AttachNone, 0, \"\"},\n\t\t{\"lsm/foo\", LSM, AttachLSMMac, 0, \"foo\"},\n\t\t{\"lsm.s/foo\", LSM, AttachLSMMac, sys.BPF_F_SLEEPABLE, \"foo\"},\n\t\t{\"iter/bpf_map\", Tracing, AttachTraceIter, 0, \"bpf_map\"},\n\t\t{\"iter.s/\", Tracing, AttachTraceIter, sys.BPF_F_SLEEPABLE, \"\"},\n\t\t// Was missing sleepable.\n\t\t{\"syscall\", Syscall, AttachNone, sys.BPF_F_SLEEPABLE, \"\"},\n\t\t{\"xdp.frags_devmap/foo\", XDP, AttachXDPDevMap, sys.BPF_F_XDP_HAS_FRAGS, \"foo\"},\n\t\t{\"xdp_devmap/foo\", XDP, AttachXDPDevMap, 0, \"foo\"},\n\t\t{\"xdp.frags_cpumap/\", XDP, AttachXDPCPUMap, sys.BPF_F_XDP_HAS_FRAGS, \"\"},\n\t\t{\"xdp_cpumap/\", XDP, AttachXDPCPUMap, 0, \"\"},\n\t\t// Used incorrect attach type.\n\t\t{\"xdp.frags/foo\", XDP, AttachXDP, sys.BPF_F_XDP_HAS_FRAGS, \"\"},\n\t\t{\"xdp/foo\", XDP, AttachNone, 0, \"\"},\n\t\t{\"perf_event\", PerfEvent, AttachNone, 0, \"\"},\n\t\t{\"lwt_in\", LWTIn, AttachNone, 0, \"\"},\n\t\t{\"lwt_out\", LWTOut, AttachNone, 0, \"\"},\n\t\t{\"lwt_xmit\", LWTXmit, AttachNone, 0, \"\"},\n\t\t{\"lwt_seg6local\", LWTSeg6Local, AttachNone, 0, \"\"},\n\t\t{\"cgroup_skb/ingress\", CGroupSKB, AttachCGroupInetIngress, 0, \"\"},\n\t\t{\"cgroup_skb/egress\", CGroupSKB, AttachCGroupInetEgress, 0, \"\"},\n\t\t{\"cgroup/skb\", CGroupSKB, AttachNone, 0, \"\"},\n\t\t{\"cgroup/sock_create\", CGroupSock, AttachCGroupInetSockCreate, 0, \"\"},\n\t\t{\"cgroup/sock_release\", CGroupSock, AttachCgroupInetSockRelease, 0, \"\"},\n\t\t{\"cgroup/sock\", CGroupSock, AttachCGroupInetSockCreate, 0, \"\"},\n\t\t{\"cgroup/post_bind4\", CGroupSock, AttachCGroupInet4PostBind, 0, \"\"},\n\t\t{\"cgroup/post_bind6\", CGroupSock, AttachCGroupInet6PostBind, 0, \"\"},\n\t\t{\"cgroup/dev\", CGroupDevice, AttachCGroupDevice, 0, \"\"},\n\t\t{\"sockops\", SockOps, AttachCGroupSockOps, 0, \"\"},\n\t\t{\"sk_skb/stream_parser\", SkSKB, AttachSkSKBStreamParser, 0, \"\"},\n\t\t{\"sk_skb/stream_verdict\", SkSKB, AttachSkSKBStreamVerdict, 0, \"\"},\n\t\t{\"sk_skb/stream_verdict/foo\", SkSKB, AttachSkSKBStreamVerdict, 0, \"\"},\n\t\t{\"sk_skb\", SkSKB, AttachNone, 0, \"\"},\n\t\t{\"sk_skb/bar\", SkSKB, AttachNone, 0, \"\"},\n\t\t{\"sk_msg\", SkMsg, AttachSkMsgVerdict, 0, \"\"},\n\t\t{\"lirc_mode2\", LircMode2, AttachLircMode2, 0, \"\"},\n\t\t{\"flow_dissector\", FlowDissector, AttachFlowDissector, 0, \"\"},\n\t\t{\"cgroup/bind4\", CGroupSockAddr, AttachCGroupInet4Bind, 0, \"\"},\n\t\t{\"cgroup/bind6\", CGroupSockAddr, AttachCGroupInet6Bind, 0, \"\"},\n\t\t{\"cgroup/connect4\", CGroupSockAddr, AttachCGroupInet4Connect, 0, \"\"},\n\t\t{\"cgroup/connect6\", CGroupSockAddr, AttachCGroupInet6Connect, 0, \"\"},\n\t\t{\"cgroup/sendmsg4\", CGroupSockAddr, AttachCGroupUDP4Sendmsg, 0, \"\"},\n\t\t{\"cgroup/sendmsg6\", CGroupSockAddr, AttachCGroupUDP6Sendmsg, 0, \"\"},\n\t\t{\"cgroup/recvmsg4\", CGroupSockAddr, AttachCGroupUDP4Recvmsg, 0, \"\"},\n\t\t{\"cgroup/recvmsg6\", CGroupSockAddr, AttachCGroupUDP6Recvmsg, 0, \"\"},\n\t\t{\"cgroup/getpeername4\", CGroupSockAddr, AttachCgroupInet4GetPeername, 0, \"\"},\n\t\t{\"cgroup/getpeername6\", CGroupSockAddr, AttachCgroupInet6GetPeername, 0, \"\"},\n\t\t{\"cgroup/getsockname4\", CGroupSockAddr, AttachCgroupInet4GetSockname, 0, \"\"},\n\t\t{\"cgroup/getsockname6\", CGroupSockAddr, AttachCgroupInet6GetSockname, 0, \"\"},\n\t\t{\"cgroup/sysctl\", CGroupSysctl, AttachCGroupSysctl, 0, \"\"},\n\t\t{\"cgroup/getsockopt\", CGroupSockopt, AttachCGroupGetsockopt, 0, \"\"},\n\t\t{\"cgroup/setsockopt\", CGroupSockopt, AttachCGroupSetsockopt, 0, \"\"},\n\t\t// Bogus pattern means it never matched anything.\n\t\t// {\"struct_ops+\", StructOps, AttachNone, 0, \"\"},\n\t\t{\"sk_lookup/\", SkLookup, AttachSkLookup, 0, \"\"},\n\t\t{\"seccomp\", SocketFilter, AttachNone, 0, \"\"},\n\t\t{\"kprobe.multi\", Kprobe, AttachTraceKprobeMulti, 0, \"\"},\n\t\t{\"kretprobe.multi\", Kprobe, AttachTraceKprobeMulti, 0, \"\"},\n\t}\n\n\tfor _, tc := range testcases {\n\t\tt.Run(tc.Section, func(t *testing.T) {\n\t\t\tpt, at, fl, extra := getProgType(tc.Section)\n\t\t\thave := testcase{tc.Section, pt, at, fl, extra}\n\t\t\tqt.Assert(t, qt.DeepEquals(have, tc))\n\t\t})\n\t}\n}\n\nfunc TestMatchSectionName(t *testing.T) {\n\tfor _, testcase := range []struct {\n\t\tpattern string\n\t\tinput   string\n\t\tmatches bool\n\t\textra   string\n\t}{\n\t\t{\"prefix/\", \"prefix/\", true, \"\"},\n\t\t{\"prefix/\", \"prefix/a\", true, \"a\"},\n\t\t{\"prefix/\", \"prefix/b\", true, \"b\"},\n\t\t{\"prefix/\", \"prefix\", false, \"\"},\n\t\t{\"prefix/\", \"junk\", false, \"\"},\n\n\t\t{\"prefix+\", \"prefix/\", true, \"\"},\n\t\t{\"prefix+\", \"prefix/a\", true, \"a\"},\n\t\t{\"prefix+\", \"prefix/b\", true, \"b\"},\n\t\t{\"prefix+\", \"prefix\", true, \"\"},\n\t\t{\"prefix+\", \"junk\", false, \"\"},\n\n\t\t{\"exact\", \"exact\", true, \"\"},\n\t\t{\"exact\", \"exact/\", true, \"\"},\n\t\t{\"exact\", \"exact/a\", true, \"\"},\n\t\t{\"exact\", \"exactement\", true, \"\"},\n\t\t{\"exact\", \"junk\", false, \"\"},\n\t} {\n\t\tname := fmt.Sprintf(\"%s:%s\", testcase.pattern, testcase.input)\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\textra, matches := matchSectionName(testcase.input, testcase.pattern)\n\t\t\tqt.Assert(t, qt.Equals(matches, testcase.matches))\n\t\t\tif testcase.matches {\n\t\t\t\tqt.Assert(t, qt.Equals(extra, testcase.extra))\n\t\t\t}\n\t\t})\n\t}\n}\n\n// selftestName takes a path to a file and derives a canonical name from it.\n//\n// It strips various suffixes used by the selftest build system.\nfunc selftestName(path string) string {\n\tfile := filepath.Base(path)\n\n\tname := strings.TrimSuffix(file, \".o\")\n\t// Strip various suffixes.\n\t// Various linking suffixes.\n\tname = strings.TrimSuffix(name, \".linked3\")\n\tname = strings.TrimSuffix(name, \".llinked1\")\n\tname = strings.TrimSuffix(name, \".llinked2\")\n\tname = strings.TrimSuffix(name, \".llinked3\")\n\t// v6.1 started adding .bpf to all BPF ELF.\n\tname = strings.TrimSuffix(name, \".bpf\")\n\n\treturn name\n}\n"
        },
        {
          "name": "elf_sections.go",
          "type": "blob",
          "size": 8.2978515625,
          "content": "// Code generated by internal/cmd/gensections.awk; DO NOT EDIT.\n\npackage ebpf\n\n// Code in this file is derived from libbpf, available under BSD-2-Clause.\n\nimport \"github.com/cilium/ebpf/internal/sys\"\n\nvar elfSectionDefs = []libbpfElfSectionDef{\n\t{\"socket\", sys.BPF_PROG_TYPE_SOCKET_FILTER, 0, _SEC_NONE},\n\t{\"sk_reuseport/migrate\", sys.BPF_PROG_TYPE_SK_REUSEPORT, sys.BPF_SK_REUSEPORT_SELECT_OR_MIGRATE, _SEC_ATTACHABLE},\n\t{\"sk_reuseport\", sys.BPF_PROG_TYPE_SK_REUSEPORT, sys.BPF_SK_REUSEPORT_SELECT, _SEC_ATTACHABLE},\n\t{\"kprobe+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"uprobe+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"uprobe.s+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_SLEEPABLE},\n\t{\"kretprobe+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"uretprobe+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"uretprobe.s+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_SLEEPABLE},\n\t{\"kprobe.multi+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_KPROBE_MULTI, _SEC_NONE},\n\t{\"kretprobe.multi+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_KPROBE_MULTI, _SEC_NONE},\n\t{\"uprobe.multi+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_UPROBE_MULTI, _SEC_NONE},\n\t{\"uretprobe.multi+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_UPROBE_MULTI, _SEC_NONE},\n\t{\"uprobe.multi.s+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_UPROBE_MULTI, _SEC_SLEEPABLE},\n\t{\"uretprobe.multi.s+\", sys.BPF_PROG_TYPE_KPROBE, sys.BPF_TRACE_UPROBE_MULTI, _SEC_SLEEPABLE},\n\t{\"ksyscall+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"kretsyscall+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_NONE},\n\t{\"usdt+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_USDT},\n\t{\"usdt.s+\", sys.BPF_PROG_TYPE_KPROBE, 0, _SEC_USDT | _SEC_SLEEPABLE},\n\t{\"tc/ingress\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_TCX_INGRESS, _SEC_NONE},\n\t{\"tc/egress\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_TCX_EGRESS, _SEC_NONE},\n\t{\"tcx/ingress\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_TCX_INGRESS, _SEC_NONE},\n\t{\"tcx/egress\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_TCX_EGRESS, _SEC_NONE},\n\t{\"tc\", sys.BPF_PROG_TYPE_SCHED_CLS, 0, _SEC_NONE},\n\t{\"classifier\", sys.BPF_PROG_TYPE_SCHED_CLS, 0, _SEC_NONE},\n\t{\"action\", sys.BPF_PROG_TYPE_SCHED_ACT, 0, _SEC_NONE},\n\t{\"netkit/primary\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_NETKIT_PRIMARY, _SEC_NONE},\n\t{\"netkit/peer\", sys.BPF_PROG_TYPE_SCHED_CLS, sys.BPF_NETKIT_PEER, _SEC_NONE},\n\t{\"tracepoint+\", sys.BPF_PROG_TYPE_TRACEPOINT, 0, _SEC_NONE},\n\t{\"tp+\", sys.BPF_PROG_TYPE_TRACEPOINT, 0, _SEC_NONE},\n\t{\"raw_tracepoint+\", sys.BPF_PROG_TYPE_RAW_TRACEPOINT, 0, _SEC_NONE},\n\t{\"raw_tp+\", sys.BPF_PROG_TYPE_RAW_TRACEPOINT, 0, _SEC_NONE},\n\t{\"raw_tracepoint.w+\", sys.BPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE, 0, _SEC_NONE},\n\t{\"raw_tp.w+\", sys.BPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE, 0, _SEC_NONE},\n\t{\"tp_btf+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_RAW_TP, _SEC_ATTACH_BTF},\n\t{\"fentry+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_FENTRY, _SEC_ATTACH_BTF},\n\t{\"fmod_ret+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_MODIFY_RETURN, _SEC_ATTACH_BTF},\n\t{\"fexit+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_FEXIT, _SEC_ATTACH_BTF},\n\t{\"fentry.s+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_FENTRY, _SEC_ATTACH_BTF | _SEC_SLEEPABLE},\n\t{\"fmod_ret.s+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_MODIFY_RETURN, _SEC_ATTACH_BTF | _SEC_SLEEPABLE},\n\t{\"fexit.s+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_FEXIT, _SEC_ATTACH_BTF | _SEC_SLEEPABLE},\n\t{\"freplace+\", sys.BPF_PROG_TYPE_EXT, 0, _SEC_ATTACH_BTF},\n\t{\"lsm+\", sys.BPF_PROG_TYPE_LSM, sys.BPF_LSM_MAC, _SEC_ATTACH_BTF},\n\t{\"lsm.s+\", sys.BPF_PROG_TYPE_LSM, sys.BPF_LSM_MAC, _SEC_ATTACH_BTF | _SEC_SLEEPABLE},\n\t{\"lsm_cgroup+\", sys.BPF_PROG_TYPE_LSM, sys.BPF_LSM_CGROUP, _SEC_ATTACH_BTF},\n\t{\"iter+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_ITER, _SEC_ATTACH_BTF},\n\t{\"iter.s+\", sys.BPF_PROG_TYPE_TRACING, sys.BPF_TRACE_ITER, _SEC_ATTACH_BTF | _SEC_SLEEPABLE},\n\t{\"syscall\", sys.BPF_PROG_TYPE_SYSCALL, 0, _SEC_SLEEPABLE},\n\t{\"xdp.frags/devmap\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_DEVMAP, _SEC_XDP_FRAGS},\n\t{\"xdp/devmap\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_DEVMAP, _SEC_ATTACHABLE},\n\t{\"xdp.frags/cpumap\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_CPUMAP, _SEC_XDP_FRAGS},\n\t{\"xdp/cpumap\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP_CPUMAP, _SEC_ATTACHABLE},\n\t{\"xdp.frags\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP, _SEC_XDP_FRAGS},\n\t{\"xdp\", sys.BPF_PROG_TYPE_XDP, sys.BPF_XDP, _SEC_ATTACHABLE_OPT},\n\t{\"perf_event\", sys.BPF_PROG_TYPE_PERF_EVENT, 0, _SEC_NONE},\n\t{\"lwt_in\", sys.BPF_PROG_TYPE_LWT_IN, 0, _SEC_NONE},\n\t{\"lwt_out\", sys.BPF_PROG_TYPE_LWT_OUT, 0, _SEC_NONE},\n\t{\"lwt_xmit\", sys.BPF_PROG_TYPE_LWT_XMIT, 0, _SEC_NONE},\n\t{\"lwt_seg6local\", sys.BPF_PROG_TYPE_LWT_SEG6LOCAL, 0, _SEC_NONE},\n\t{\"sockops\", sys.BPF_PROG_TYPE_SOCK_OPS, sys.BPF_CGROUP_SOCK_OPS, _SEC_ATTACHABLE_OPT},\n\t{\"sk_skb/stream_parser\", sys.BPF_PROG_TYPE_SK_SKB, sys.BPF_SK_SKB_STREAM_PARSER, _SEC_ATTACHABLE_OPT},\n\t{\"sk_skb/stream_verdict\", sys.BPF_PROG_TYPE_SK_SKB, sys.BPF_SK_SKB_STREAM_VERDICT, _SEC_ATTACHABLE_OPT},\n\t{\"sk_skb\", sys.BPF_PROG_TYPE_SK_SKB, 0, _SEC_NONE},\n\t{\"sk_msg\", sys.BPF_PROG_TYPE_SK_MSG, sys.BPF_SK_MSG_VERDICT, _SEC_ATTACHABLE_OPT},\n\t{\"lirc_mode2\", sys.BPF_PROG_TYPE_LIRC_MODE2, sys.BPF_LIRC_MODE2, _SEC_ATTACHABLE_OPT},\n\t{\"flow_dissector\", sys.BPF_PROG_TYPE_FLOW_DISSECTOR, sys.BPF_FLOW_DISSECTOR, _SEC_ATTACHABLE_OPT},\n\t{\"cgroup_skb/ingress\", sys.BPF_PROG_TYPE_CGROUP_SKB, sys.BPF_CGROUP_INET_INGRESS, _SEC_ATTACHABLE_OPT},\n\t{\"cgroup_skb/egress\", sys.BPF_PROG_TYPE_CGROUP_SKB, sys.BPF_CGROUP_INET_EGRESS, _SEC_ATTACHABLE_OPT},\n\t{\"cgroup/skb\", sys.BPF_PROG_TYPE_CGROUP_SKB, 0, _SEC_NONE},\n\t{\"cgroup/sock_create\", sys.BPF_PROG_TYPE_CGROUP_SOCK, sys.BPF_CGROUP_INET_SOCK_CREATE, _SEC_ATTACHABLE},\n\t{\"cgroup/sock_release\", sys.BPF_PROG_TYPE_CGROUP_SOCK, sys.BPF_CGROUP_INET_SOCK_RELEASE, _SEC_ATTACHABLE},\n\t{\"cgroup/sock\", sys.BPF_PROG_TYPE_CGROUP_SOCK, sys.BPF_CGROUP_INET_SOCK_CREATE, _SEC_ATTACHABLE_OPT},\n\t{\"cgroup/post_bind4\", sys.BPF_PROG_TYPE_CGROUP_SOCK, sys.BPF_CGROUP_INET4_POST_BIND, _SEC_ATTACHABLE},\n\t{\"cgroup/post_bind6\", sys.BPF_PROG_TYPE_CGROUP_SOCK, sys.BPF_CGROUP_INET6_POST_BIND, _SEC_ATTACHABLE},\n\t{\"cgroup/bind4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET4_BIND, _SEC_ATTACHABLE},\n\t{\"cgroup/bind6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET6_BIND, _SEC_ATTACHABLE},\n\t{\"cgroup/connect4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET4_CONNECT, _SEC_ATTACHABLE},\n\t{\"cgroup/connect6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET6_CONNECT, _SEC_ATTACHABLE},\n\t{\"cgroup/connect_unix\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UNIX_CONNECT, _SEC_ATTACHABLE},\n\t{\"cgroup/sendmsg4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UDP4_SENDMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/sendmsg6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UDP6_SENDMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/sendmsg_unix\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UNIX_SENDMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/recvmsg4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UDP4_RECVMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/recvmsg6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UDP6_RECVMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/recvmsg_unix\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UNIX_RECVMSG, _SEC_ATTACHABLE},\n\t{\"cgroup/getpeername4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET4_GETPEERNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/getpeername6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET6_GETPEERNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/getpeername_unix\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UNIX_GETPEERNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/getsockname4\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET4_GETSOCKNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/getsockname6\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_INET6_GETSOCKNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/getsockname_unix\", sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR, sys.BPF_CGROUP_UNIX_GETSOCKNAME, _SEC_ATTACHABLE},\n\t{\"cgroup/sysctl\", sys.BPF_PROG_TYPE_CGROUP_SYSCTL, sys.BPF_CGROUP_SYSCTL, _SEC_ATTACHABLE},\n\t{\"cgroup/getsockopt\", sys.BPF_PROG_TYPE_CGROUP_SOCKOPT, sys.BPF_CGROUP_GETSOCKOPT, _SEC_ATTACHABLE},\n\t{\"cgroup/setsockopt\", sys.BPF_PROG_TYPE_CGROUP_SOCKOPT, sys.BPF_CGROUP_SETSOCKOPT, _SEC_ATTACHABLE},\n\t{\"cgroup/dev\", sys.BPF_PROG_TYPE_CGROUP_DEVICE, sys.BPF_CGROUP_DEVICE, _SEC_ATTACHABLE_OPT},\n\t{\"struct_ops+\", sys.BPF_PROG_TYPE_STRUCT_OPS, 0, _SEC_NONE},\n\t{\"struct_ops.s+\", sys.BPF_PROG_TYPE_STRUCT_OPS, 0, _SEC_SLEEPABLE},\n\t{\"sk_lookup\", sys.BPF_PROG_TYPE_SK_LOOKUP, sys.BPF_SK_LOOKUP, _SEC_ATTACHABLE},\n\t{\"netfilter\", sys.BPF_PROG_TYPE_NETFILTER, sys.BPF_NETFILTER, _SEC_NONE},\n}\n"
        },
        {
          "name": "example_sock_elf_test.go",
          "type": "blob",
          "size": 7.9658203125,
          "content": "//go:build linux\n\npackage ebpf_test\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"flag\"\n\t\"fmt\"\n\t\"syscall\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/cilium/ebpf\"\n)\n\nvar program = [...]byte{\n\t0177, 0105, 0114, 0106, 0002, 0001, 0001, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0001, 0000, 0367, 0000, 0001, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0340, 0001, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0100, 0000, 0000, 0000, 0000, 0000, 0100, 0000, 0010, 0000, 0001, 0000,\n\t0277, 0026, 0000, 0000, 0000, 0000, 0000, 0000, 0060, 0000, 0000, 0000, 0027, 0000, 0000, 0000,\n\t0143, 0012, 0374, 0377, 0000, 0000, 0000, 0000, 0141, 0141, 0004, 0000, 0000, 0000, 0000, 0000,\n\t0125, 0001, 0010, 0000, 0004, 0000, 0000, 0000, 0277, 0242, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0007, 0002, 0000, 0000, 0374, 0377, 0377, 0377, 0030, 0001, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0205, 0000, 0000, 0000, 0001, 0000, 0000, 0000,\n\t0025, 0000, 0002, 0000, 0000, 0000, 0000, 0000, 0141, 0141, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0333, 0020, 0000, 0000, 0000, 0000, 0000, 0000, 0267, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0225, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0002, 0000, 0000, 0000, 0004, 0000, 0000, 0000,\n\t0010, 0000, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0000, 0000, 0000, 0002, 0000, 0000, 0000,\n\t0004, 0000, 0000, 0000, 0010, 0000, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0107, 0120, 0114, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0065, 0000, 0000, 0000, 0000, 0000, 0003, 0000, 0150, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0034, 0000, 0000, 0000, 0020, 0000, 0006, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0110, 0000, 0000, 0000, 0020, 0000, 0003, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0014, 0000, 0000, 0000, 0020, 0000, 0005, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0023, 0000, 0000, 0000, 0020, 0000, 0005, 0000, 0024, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0070, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0001, 0000, 0000, 0000, 0004, 0000, 0000, 0000, 0000, 0056, 0164, 0145, 0170, 0164, 0000, 0155,\n\t0141, 0160, 0163, 0000, 0155, 0171, 0137, 0155, 0141, 0160, 0000, 0164, 0145, 0163, 0164, 0137,\n\t0155, 0141, 0160, 0000, 0137, 0154, 0151, 0143, 0145, 0156, 0163, 0145, 0000, 0056, 0163, 0164,\n\t0162, 0164, 0141, 0142, 0000, 0056, 0163, 0171, 0155, 0164, 0141, 0142, 0000, 0114, 0102, 0102,\n\t0060, 0137, 0063, 0000, 0056, 0162, 0145, 0154, 0163, 0157, 0143, 0153, 0145, 0164, 0061, 0000,\n\t0142, 0160, 0146, 0137, 0160, 0162, 0157, 0147, 0061, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0045, 0000, 0000, 0000, 0003, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0210, 0001, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0122, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0001, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0001, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0006, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0100, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0004, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0100, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0006, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0100, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0170, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0010, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0074, 0000, 0000, 0000, 0011, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0170, 0001, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0020, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0007, 0000, 0000, 0000, 0003, 0000, 0000, 0000,\n\t0010, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0020, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0007, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0003, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0270, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0050, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0004, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0035, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0003, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0340, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0004, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0001, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0055, 0000, 0000, 0000, 0002, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0350, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n\t0220, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0001, 0000, 0000, 0000, 0002, 0000, 0000, 0000,\n\t0010, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0030, 0000, 0000, 0000, 0000, 0000, 0000, 0000,\n}\n\n// ExampleSocketELF demonstrates how to load an eBPF program from an ELF,\n// and attach it to a raw socket.\nfunc Example_socketELF() {\n\tconst SO_ATTACH_BPF = 50\n\n\tindex := flag.Int(\"index\", 0, \"specify ethernet index\")\n\tflag.Parse()\n\n\tspec, err := ebpf.LoadCollectionSpecFromReader(bytes.NewReader(program[:]))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar objs struct {\n\t\tProg  *ebpf.Program `ebpf:\"bpf_prog1\"`\n\t\tStats *ebpf.Map     `ebpf:\"my_map\"`\n\t}\n\n\tif err := spec.LoadAndAssign(&objs, nil); err != nil {\n\t\tpanic(err)\n\t}\n\tdefer objs.Prog.Close()\n\tdefer objs.Stats.Close()\n\n\tsock, err := openRawSock(*index)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer syscall.Close(sock)\n\n\tif err := syscall.SetsockoptInt(sock, syscall.SOL_SOCKET, SO_ATTACH_BPF, objs.Prog.FD()); err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Printf(\"Filtering on eth index: %d\\n\", *index)\n\tfmt.Println(\"Packet stats:\")\n\n\tfor {\n\t\tconst (\n\t\t\tICMP = 0x01\n\t\t\tTCP  = 0x06\n\t\t\tUDP  = 0x11\n\t\t)\n\n\t\ttime.Sleep(time.Second)\n\t\tvar icmp uint64\n\t\tvar tcp uint64\n\t\tvar udp uint64\n\t\terr := objs.Stats.Lookup(uint32(ICMP), &icmp)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\terr = objs.Stats.Lookup(uint32(TCP), &tcp)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\terr = objs.Stats.Lookup(uint32(UDP), &udp)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tfmt.Printf(\"\\r\\033[m\\tICMP: %d TCP: %d UDP: %d\", icmp, tcp, udp)\n\t}\n}\n\nfunc openRawSock(index int) (int, error) {\n\tsock, err := syscall.Socket(syscall.AF_PACKET, syscall.SOCK_RAW|syscall.SOCK_NONBLOCK|syscall.SOCK_CLOEXEC, int(htons(syscall.ETH_P_ALL)))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tsll := syscall.SockaddrLinklayer{\n\t\tIfindex:  index,\n\t\tProtocol: htons(syscall.ETH_P_ALL),\n\t}\n\tif err := syscall.Bind(sock, &sll); err != nil {\n\t\treturn 0, err\n\t}\n\treturn sock, nil\n}\n\n// htons converts the unsigned short integer hostshort from host byte order to network byte order.\nfunc htons(i uint16) uint16 {\n\tb := make([]byte, 2)\n\tbinary.BigEndian.PutUint16(b, i)\n\treturn *(*uint16)(unsafe.Pointer(&b[0]))\n}\n"
        },
        {
          "name": "example_sock_extract_dist_test.go",
          "type": "blob",
          "size": 5.05859375,
          "content": "//go:build linux\n\npackage ebpf_test\n\n// This code is derived from https://github.com/cloudflare/cloudflare-blog/tree/master/2018-03-ebpf\n//\n// Copyright (c) 2015-2017 Cloudflare, Inc. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of the Cloudflare, Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"syscall\"\n\n\t\"github.com/cilium/ebpf\"\n\t\"github.com/cilium/ebpf/asm\"\n)\n\n// ExampleExtractDistance shows how to attach an eBPF socket filter to\n// extract the network distance of an IP host.\nfunc Example_extractDistance() {\n\tfilter, TTLs, err := newDistanceFilter()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer filter.Close()\n\tdefer TTLs.Close()\n\n\t// Attach filter before the call to connect()\n\tdialer := net.Dialer{\n\t\tControl: func(network, address string, c syscall.RawConn) (err error) {\n\t\t\tconst SO_ATTACH_BPF = 50\n\n\t\t\terr = c.Control(func(fd uintptr) {\n\t\t\t\terr = syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, SO_ATTACH_BPF, filter.FD())\n\t\t\t})\n\t\t\treturn err\n\t\t},\n\t}\n\n\tconn, err := dialer.Dial(\"tcp\", \"1.1.1.1:53\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tconn.Close()\n\n\tminDist, err := minDistance(TTLs)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Println(\"1.1.1.1:53 is\", minDist, \"hops away\")\n}\n\nfunc newDistanceFilter() (*ebpf.Program, *ebpf.Map, error) {\n\tconst ETH_P_IPV6 uint16 = 0x86DD\n\n\tttls, err := ebpf.NewMap(&ebpf.MapSpec{\n\t\tType:       ebpf.Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  8,\n\t\tMaxEntries: 4,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tinsns := asm.Instructions{\n\t\t// r1 has ctx\n\t\t// r0 = ctx[16] (aka protocol)\n\t\tasm.LoadMem(asm.R0, asm.R1, 16, asm.Word),\n\n\t\t// Perhaps ipv6\n\t\tasm.LoadImm(asm.R2, int64(ETH_P_IPV6), asm.DWord),\n\t\tasm.HostTo(asm.BE, asm.R2, asm.Half),\n\t\tasm.JEq.Reg(asm.R0, asm.R2, \"ipv6\"),\n\n\t\t// otherwise assume ipv4\n\t\t// 8th byte in IPv4 is TTL\n\t\t// LDABS requires ctx in R6\n\t\tasm.Mov.Reg(asm.R6, asm.R1),\n\t\tasm.LoadAbs(-0x100000+8, asm.Byte),\n\t\tasm.Ja.Label(\"store-ttl\"),\n\n\t\t// 7th byte in IPv6 is Hop count\n\t\t// LDABS requires ctx in R6\n\t\tasm.Mov.Reg(asm.R6, asm.R1).WithSymbol(\"ipv6\"),\n\t\tasm.LoadAbs(-0x100000+7, asm.Byte),\n\n\t\t// stash the load result into FP[-4]\n\t\tasm.StoreMem(asm.RFP, -4, asm.R0, asm.Word).WithSymbol(\"store-ttl\"),\n\t\t// stash the &FP[-4] into r2\n\t\tasm.Mov.Reg(asm.R2, asm.RFP),\n\t\tasm.Add.Imm(asm.R2, -4),\n\n\t\t// r1 must point to map\n\t\tasm.LoadMapPtr(asm.R1, ttls.FD()),\n\t\tasm.FnMapLookupElem.Call(),\n\n\t\t// load ok? inc. Otherwise? jmp to mapupdate\n\t\tasm.JEq.Imm(asm.R0, 0, \"update-map\"),\n\t\tasm.Mov.Imm(asm.R1, 1),\n\t\tasm.StoreXAdd(asm.R0, asm.R1, asm.DWord),\n\t\tasm.Ja.Label(\"exit\"),\n\n\t\t// MapUpdate\n\t\t// r1 has map ptr\n\t\tasm.LoadMapPtr(asm.R1, ttls.FD()).WithSymbol(\"update-map\"),\n\t\t// r2 has key -> &FP[-4]\n\t\tasm.Mov.Reg(asm.R2, asm.RFP),\n\t\tasm.Add.Imm(asm.R2, -4),\n\t\t// r3 has value -> &FP[-16] , aka 1\n\t\tasm.StoreImm(asm.RFP, -16, 1, asm.DWord),\n\t\tasm.Mov.Reg(asm.R3, asm.RFP),\n\t\tasm.Add.Imm(asm.R3, -16),\n\t\t// r4 has flags, 0\n\t\tasm.Mov.Imm(asm.R4, 0),\n\t\tasm.FnMapUpdateElem.Call(),\n\n\t\t// set exit code to -1, don't trunc packet\n\t\tasm.Mov.Imm(asm.R0, -1).WithSymbol(\"exit\"),\n\t\tasm.Return(),\n\t}\n\n\tprog, err := ebpf.NewProgram(&ebpf.ProgramSpec{\n\t\tName:         \"distance_filter\",\n\t\tType:         ebpf.SocketFilter,\n\t\tLicense:      \"GPL\",\n\t\tInstructions: insns,\n\t})\n\tif err != nil {\n\t\tttls.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn prog, ttls, nil\n}\n\nfunc minDistance(TTLs *ebpf.Map) (int, error) {\n\tvar (\n\t\tentries = TTLs.Iterate()\n\t\tttl     uint32\n\t\tminDist uint32 = 255\n\t\tcount   uint64\n\t)\n\tfor entries.Next(&ttl, &count) {\n\t\tvar dist uint32\n\t\tswitch {\n\t\tcase ttl > 128:\n\t\t\tdist = 255 - ttl\n\t\tcase ttl > 64:\n\t\t\tdist = 128 - ttl\n\t\tcase ttl > 32:\n\t\t\tdist = 64 - ttl\n\t\tdefault:\n\t\t\tdist = 32 - ttl\n\t\t}\n\t\tif minDist > dist {\n\t\t\tminDist = dist\n\t\t}\n\t}\n\treturn int(minDist), entries.Err()\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "features",
          "type": "tree",
          "content": null
        },
        {
          "name": "fuzz_test.go",
          "type": "blob",
          "size": 0.4423828125,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"debug/elf\"\n\t\"testing\"\n)\n\nfunc FuzzLoadCollectionSpec(f *testing.F) {\n\tf.Add([]byte(elf.ELFMAG))\n\tf.Fuzz(func(t *testing.T, data []byte) {\n\t\tif len(data) < len(elf.ELFMAG) {\n\t\t\tt.Skip(\"input can't be valid ELF\")\n\t\t}\n\n\t\tspec, err := LoadCollectionSpecFromReader(bytes.NewReader(data))\n\t\tif err != nil {\n\t\t\tif spec != nil {\n\t\t\t\tt.Fatal(\"spec is not nil\")\n\t\t\t}\n\t\t} else if spec == nil {\n\t\t\tt.Fatal(\"spec is nil\")\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.54296875,
          "content": "module github.com/cilium/ebpf\n\ngo 1.22\n\nrequire (\n\tgithub.com/go-quicktest/qt v1.101.0\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/jsimonetti/rtnetlink/v2 v2.0.1\n\tgolang.org/x/sys v0.26.0\n)\n\nrequire (\n\tgithub.com/josharian/native v1.1.0 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/mdlayher/netlink v1.7.2 // indirect\n\tgithub.com/mdlayher/socket v0.4.1 // indirect\n\tgithub.com/rogpeppe/go-internal v1.11.0 // indirect\n\tgolang.org/x/net v0.23.0 // indirect\n\tgolang.org/x/sync v0.1.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.3857421875,
          "content": "github.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/go-quicktest/qt v1.101.0 h1:O1K29Txy5P2OK0dGo59b7b0LR6wKfIhttaAhHUyn7eI=\ngithub.com/go-quicktest/qt v1.101.0/go.mod h1:14Bz/f7NwaXPtdYEgzsx46kqSxVwTbzVZsDC26tQJow=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/josharian/native v1.1.0 h1:uuaP0hAbW7Y4l0ZRQ6C9zfb7Mg1mbFKry/xzDAfmtLA=\ngithub.com/josharian/native v1.1.0/go.mod h1:7X/raswPFr05uY3HiLlYeyQntB6OO7E/d2Cu7qoaN2w=\ngithub.com/jsimonetti/rtnetlink/v2 v2.0.1 h1:xda7qaHDSVOsADNouv7ukSuicKZO7GgVUCXxpaIEIlM=\ngithub.com/jsimonetti/rtnetlink/v2 v2.0.1/go.mod h1:7MoNYNbb3UaDHtF8udiJo/RH6VsTKP1pqKLUTVCvToE=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/mdlayher/netlink v1.7.2 h1:/UtM3ofJap7Vl4QWCPDGXY8d3GIY2UGSDbK+QWmY8/g=\ngithub.com/mdlayher/netlink v1.7.2/go.mod h1:xraEF7uJbxLhc5fpHL4cPe221LI2bdttWlU+ZGLfQSw=\ngithub.com/mdlayher/socket v0.4.1 h1:eM9y2/jlbs1M615oshPQOHZzj6R6wMT7bX5NPiQvn2U=\ngithub.com/mdlayher/socket v0.4.1/go.mod h1:cAqeGjoufqdxWkD7DkpyS+wcefOtmu5OQ8KuoJGIReA=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/rogpeppe/go-internal v1.11.0 h1:cWPaGQEPrBb5/AsnsZesgZZ9yb1OQ+GOISoDNXVBh4M=\ngithub.com/rogpeppe/go-internal v1.11.0/go.mod h1:ddIwULY96R17DhadqLgMfk9H9tvdUzkipdSkR5nkCZA=\ngolang.org/x/net v0.23.0 h1:7EYJ93RZ9vYSZAIb2x3lnuvqO5zneoD6IvWjuhfxjTs=\ngolang.org/x/net v0.23.0/go.mod h1:JKghWKKOSdJwpW2GEx0Ja7fmaKnMsbu+MWVZTokSYmg=\ngolang.org/x/sync v0.1.0 h1:wsuoTGHzEhffawBOhz5CYhcrV4IdKZbEyZjBMuTp12o=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.20.0 h1:Od9JTbYCk261bKm4M/mw7AklTlFYIa0bIp9BgSm1S8Y=\ngolang.org/x/sys v0.20.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.26.0 h1:KHjCJyddX0LoSTb3J+vWpupP9p0oznkqVk/IfjymZbo=\ngolang.org/x/sys v0.26.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\n"
        },
        {
          "name": "helpers_test.go",
          "type": "blob",
          "size": 0.5849609375,
          "content": "package ebpf\n\nimport (\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n)\n\nfunc haveTestmod(tb testing.TB) bool {\n\thaveTestmod := false\n\tif !testutils.IsKernelLessThan(tb, \"5.11\") {\n\t\t// See https://github.com/torvalds/linux/commit/290248a5b7d829871b3ea3c62578613a580a1744\n\t\ttestmod, err := btf.FindHandle(func(info *btf.HandleInfo) bool {\n\t\t\treturn info.IsModule() && info.Name == \"bpf_testmod\"\n\t\t})\n\t\tif err != nil && !errors.Is(err, btf.ErrNotFound) {\n\t\t\ttb.Fatal(err)\n\t\t}\n\t\thaveTestmod = testmod != nil\n\t\ttestmod.Close()\n\t}\n\n\treturn haveTestmod\n}\n"
        },
        {
          "name": "info.go",
          "type": "blob",
          "size": 22.716796875,
          "content": "package ebpf\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\n// The *Info structs expose metadata about a program or map. Most\n// fields are exposed via a getter:\n//\n//     func (*MapInfo) ID() (MapID, bool)\n//\n// This is because the metadata available changes based on kernel version.\n// The second boolean return value indicates whether a particular field is\n// available on the current kernel.\n//\n// Always add new metadata as such a getter, unless you can somehow get the\n// value of the field on all supported kernels. Also document which version\n// a particular field first appeared in.\n//\n// Some metadata is a buffer which needs additional parsing. In this case,\n// store the undecoded data in the Info struct and provide a getter which\n// decodes it when necessary. See ProgramInfo.Instructions for an example.\n\n// MapInfo describes a map.\ntype MapInfo struct {\n\t// Type of the map.\n\tType MapType\n\t// KeySize is the size of the map key in bytes.\n\tKeySize uint32\n\t// ValueSize is the size of the map value in bytes.\n\tValueSize uint32\n\t// MaxEntries is the maximum number of entries the map can hold. Its meaning\n\t// is map-specific.\n\tMaxEntries uint32\n\t// Flags used during map creation.\n\tFlags uint32\n\t// Name as supplied by user space at load time. Available from 4.15.\n\tName string\n\n\tid       MapID\n\tbtf      btf.ID\n\tmapExtra uint64\n\tmemlock  uint64\n\tfrozen   bool\n}\n\n// newMapInfoFromFd queries map information about the given fd. [sys.ObjInfo] is\n// attempted first, supplementing any missing values with information from\n// /proc/self/fdinfo. Ignores EINVAL from ObjInfo as well as ErrNotSupported\n// from reading fdinfo (indicating the file exists, but no fields of interest\n// were found). If both fail, an error is always returned.\nfunc newMapInfoFromFd(fd *sys.FD) (*MapInfo, error) {\n\tvar info sys.MapInfo\n\terr1 := sys.ObjInfo(fd, &info)\n\t// EINVAL means the kernel doesn't support BPF_OBJ_GET_INFO_BY_FD. Continue\n\t// with fdinfo if that's the case.\n\tif err1 != nil && !errors.Is(err1, unix.EINVAL) {\n\t\treturn nil, fmt.Errorf(\"getting object info: %w\", err1)\n\t}\n\n\tmi := &MapInfo{\n\t\tMapType(info.Type),\n\t\tinfo.KeySize,\n\t\tinfo.ValueSize,\n\t\tinfo.MaxEntries,\n\t\tuint32(info.MapFlags),\n\t\tunix.ByteSliceToString(info.Name[:]),\n\t\tMapID(info.Id),\n\t\tbtf.ID(info.BtfId),\n\t\tinfo.MapExtra,\n\t\t0,\n\t\tfalse,\n\t}\n\n\t// Supplement OBJ_INFO with data from /proc/self/fdinfo. It contains fields\n\t// like memlock and frozen that are not present in OBJ_INFO.\n\terr2 := readMapInfoFromProc(fd, mi)\n\tif err2 != nil && !errors.Is(err2, ErrNotSupported) {\n\t\treturn nil, fmt.Errorf(\"getting map info from fdinfo: %w\", err2)\n\t}\n\n\tif err1 != nil && err2 != nil {\n\t\treturn nil, fmt.Errorf(\"ObjInfo and fdinfo both failed: objinfo: %w, fdinfo: %w\", err1, err2)\n\t}\n\n\treturn mi, nil\n}\n\n// readMapInfoFromProc queries map information about the given fd from\n// /proc/self/fdinfo. It only writes data into fields that have a zero value.\nfunc readMapInfoFromProc(fd *sys.FD, mi *MapInfo) error {\n\treturn scanFdInfo(fd, map[string]interface{}{\n\t\t\"map_type\":    &mi.Type,\n\t\t\"map_id\":      &mi.id,\n\t\t\"key_size\":    &mi.KeySize,\n\t\t\"value_size\":  &mi.ValueSize,\n\t\t\"max_entries\": &mi.MaxEntries,\n\t\t\"map_flags\":   &mi.Flags,\n\t\t\"map_extra\":   &mi.mapExtra,\n\t\t\"memlock\":     &mi.memlock,\n\t\t\"frozen\":      &mi.frozen,\n\t})\n}\n\n// ID returns the map ID.\n//\n// Available from 4.13.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (mi *MapInfo) ID() (MapID, bool) {\n\treturn mi.id, mi.id > 0\n}\n\n// BTFID returns the BTF ID associated with the Map.\n//\n// The ID is only valid as long as the associated Map is kept alive.\n// Available from 4.18.\n//\n// The bool return value indicates whether this optional field is available and\n// populated. (The field may be available but not populated if the kernel\n// supports the field but the Map was loaded without BTF information.)\nfunc (mi *MapInfo) BTFID() (btf.ID, bool) {\n\treturn mi.btf, mi.btf > 0\n}\n\n// MapExtra returns an opaque field whose meaning is map-specific.\n//\n// Available from 5.16.\n//\n// The bool return value indicates whether this optional field is available and\n// populated, if it was specified during Map creation.\nfunc (mi *MapInfo) MapExtra() (uint64, bool) {\n\treturn mi.mapExtra, mi.mapExtra > 0\n}\n\n// Memlock returns an approximate number of bytes allocated to this map.\n//\n// Available from 4.10.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (mi *MapInfo) Memlock() (uint64, bool) {\n\treturn mi.memlock, mi.memlock > 0\n}\n\n// Frozen indicates whether [Map.Freeze] was called on this map. If true,\n// modifications from user space are not allowed.\n//\n// Available from 5.2. Requires access to procfs.\n//\n// If the kernel doesn't support map freezing, this field will always be false.\nfunc (mi *MapInfo) Frozen() bool {\n\treturn mi.frozen\n}\n\n// programStats holds statistics of a program.\ntype programStats struct {\n\t// Total accumulated runtime of the program ins ns.\n\truntime time.Duration\n\t// Total number of times the program was called.\n\trunCount uint64\n\t// Total number of times the programm was NOT called.\n\t// Added in commit 9ed9e9ba2337 (\"bpf: Count the number of times recursion was prevented\").\n\trecursionMisses uint64\n}\n\n// programJitedInfo holds information about JITed info of a program.\ntype programJitedInfo struct {\n\t// ksyms holds the ksym addresses of the BPF program, including those of its\n\t// subprograms.\n\t//\n\t// Available from 4.18.\n\tksyms    []uintptr\n\tnumKsyms uint32\n\n\t// insns holds the JITed machine native instructions of the program,\n\t// including those of its subprograms.\n\t//\n\t// Available from 4.13.\n\tinsns    []byte\n\tnumInsns uint32\n\n\t// lineInfos holds the JITed line infos, which are kernel addresses.\n\t//\n\t// Available from 5.0.\n\tlineInfos    []uint64\n\tnumLineInfos uint32\n\n\t// lineInfoRecSize is the size of a single line info record.\n\t//\n\t// Available from 5.0.\n\tlineInfoRecSize uint32\n\n\t// funcLens holds the insns length of each function.\n\t//\n\t// Available from 4.18.\n\tfuncLens    []uint32\n\tnumFuncLens uint32\n}\n\n// ProgramInfo describes a program.\ntype ProgramInfo struct {\n\tType ProgramType\n\tid   ProgramID\n\t// Truncated hash of the BPF bytecode. Available from 4.13.\n\tTag string\n\t// Name as supplied by user space at load time. Available from 4.15.\n\tName string\n\n\tcreatedByUID     uint32\n\thaveCreatedByUID bool\n\tbtf              btf.ID\n\tstats            *programStats\n\tloadTime         time.Duration\n\n\tmaps                 []MapID\n\tinsns                []byte\n\tjitedSize            uint32\n\tverifiedInstructions uint32\n\n\tjitedInfo programJitedInfo\n\n\tlineInfos    []byte\n\tnumLineInfos uint32\n\tfuncInfos    []byte\n\tnumFuncInfos uint32\n}\n\nfunc newProgramInfoFromFd(fd *sys.FD) (*ProgramInfo, error) {\n\tvar info sys.ProgInfo\n\terr := sys.ObjInfo(fd, &info)\n\tif errors.Is(err, syscall.EINVAL) {\n\t\treturn newProgramInfoFromProc(fd)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpi := ProgramInfo{\n\t\tType: ProgramType(info.Type),\n\t\tid:   ProgramID(info.Id),\n\t\tTag:  hex.EncodeToString(info.Tag[:]),\n\t\tName: unix.ByteSliceToString(info.Name[:]),\n\t\tbtf:  btf.ID(info.BtfId),\n\t\tstats: &programStats{\n\t\t\truntime:         time.Duration(info.RunTimeNs),\n\t\t\trunCount:        info.RunCnt,\n\t\t\trecursionMisses: info.RecursionMisses,\n\t\t},\n\t\tjitedSize:            info.JitedProgLen,\n\t\tloadTime:             time.Duration(info.LoadTime),\n\t\tverifiedInstructions: info.VerifiedInsns,\n\t}\n\n\t// Start with a clean struct for the second call, otherwise we may get EFAULT.\n\tvar info2 sys.ProgInfo\n\n\tmakeSecondCall := false\n\n\tif info.NrMapIds > 0 {\n\t\tpi.maps = make([]MapID, info.NrMapIds)\n\t\tinfo2.NrMapIds = info.NrMapIds\n\t\tinfo2.MapIds = sys.NewSlicePointer(pi.maps)\n\t\tmakeSecondCall = true\n\t} else if haveProgramInfoMapIDs() == nil {\n\t\t// This program really has no associated maps.\n\t\tpi.maps = make([]MapID, 0)\n\t} else {\n\t\t// The kernel doesn't report associated maps.\n\t\tpi.maps = nil\n\t}\n\n\t// createdByUID and NrMapIds were introduced in the same kernel version.\n\tif pi.maps != nil {\n\t\tpi.createdByUID = info.CreatedByUid\n\t\tpi.haveCreatedByUID = true\n\t}\n\n\tif info.XlatedProgLen > 0 {\n\t\tpi.insns = make([]byte, info.XlatedProgLen)\n\t\tinfo2.XlatedProgLen = info.XlatedProgLen\n\t\tinfo2.XlatedProgInsns = sys.NewSlicePointer(pi.insns)\n\t\tmakeSecondCall = true\n\t}\n\n\tif info.NrLineInfo > 0 {\n\t\tpi.lineInfos = make([]byte, btf.LineInfoSize*info.NrLineInfo)\n\t\tinfo2.LineInfo = sys.NewSlicePointer(pi.lineInfos)\n\t\tinfo2.LineInfoRecSize = btf.LineInfoSize\n\t\tinfo2.NrLineInfo = info.NrLineInfo\n\t\tpi.numLineInfos = info.NrLineInfo\n\t\tmakeSecondCall = true\n\t}\n\n\tif info.NrFuncInfo > 0 {\n\t\tpi.funcInfos = make([]byte, btf.FuncInfoSize*info.NrFuncInfo)\n\t\tinfo2.FuncInfo = sys.NewSlicePointer(pi.funcInfos)\n\t\tinfo2.FuncInfoRecSize = btf.FuncInfoSize\n\t\tinfo2.NrFuncInfo = info.NrFuncInfo\n\t\tpi.numFuncInfos = info.NrFuncInfo\n\t\tmakeSecondCall = true\n\t}\n\n\tpi.jitedInfo.lineInfoRecSize = info.JitedLineInfoRecSize\n\tif info.JitedProgLen > 0 {\n\t\tpi.jitedInfo.numInsns = info.JitedProgLen\n\t\tpi.jitedInfo.insns = make([]byte, info.JitedProgLen)\n\t\tinfo2.JitedProgLen = info.JitedProgLen\n\t\tinfo2.JitedProgInsns = sys.NewSlicePointer(pi.jitedInfo.insns)\n\t\tmakeSecondCall = true\n\t}\n\n\tif info.NrJitedFuncLens > 0 {\n\t\tpi.jitedInfo.numFuncLens = info.NrJitedFuncLens\n\t\tpi.jitedInfo.funcLens = make([]uint32, info.NrJitedFuncLens)\n\t\tinfo2.NrJitedFuncLens = info.NrJitedFuncLens\n\t\tinfo2.JitedFuncLens = sys.NewSlicePointer(pi.jitedInfo.funcLens)\n\t\tmakeSecondCall = true\n\t}\n\n\tif info.NrJitedLineInfo > 0 {\n\t\tpi.jitedInfo.numLineInfos = info.NrJitedLineInfo\n\t\tpi.jitedInfo.lineInfos = make([]uint64, info.NrJitedLineInfo)\n\t\tinfo2.NrJitedLineInfo = info.NrJitedLineInfo\n\t\tinfo2.JitedLineInfo = sys.NewSlicePointer(pi.jitedInfo.lineInfos)\n\t\tinfo2.JitedLineInfoRecSize = info.JitedLineInfoRecSize\n\t\tmakeSecondCall = true\n\t}\n\n\tif info.NrJitedKsyms > 0 {\n\t\tpi.jitedInfo.numKsyms = info.NrJitedKsyms\n\t\tpi.jitedInfo.ksyms = make([]uintptr, info.NrJitedKsyms)\n\t\tinfo2.JitedKsyms = sys.NewSlicePointer(pi.jitedInfo.ksyms)\n\t\tinfo2.NrJitedKsyms = info.NrJitedKsyms\n\t\tmakeSecondCall = true\n\t}\n\n\tif makeSecondCall {\n\t\tif err := sys.ObjInfo(fd, &info2); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &pi, nil\n}\n\nfunc newProgramInfoFromProc(fd *sys.FD) (*ProgramInfo, error) {\n\tvar info ProgramInfo\n\terr := scanFdInfo(fd, map[string]interface{}{\n\t\t\"prog_type\": &info.Type,\n\t\t\"prog_tag\":  &info.Tag,\n\t})\n\tif errors.Is(err, ErrNotSupported) {\n\t\treturn nil, &internal.UnsupportedFeatureError{\n\t\t\tName:           \"reading program info from /proc/self/fdinfo\",\n\t\t\tMinimumVersion: internal.Version{4, 10, 0},\n\t\t}\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &info, nil\n}\n\n// ID returns the program ID.\n//\n// Available from 4.13.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) ID() (ProgramID, bool) {\n\treturn pi.id, pi.id > 0\n}\n\n// CreatedByUID returns the Uid that created the program.\n//\n// Available from 4.15.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) CreatedByUID() (uint32, bool) {\n\treturn pi.createdByUID, pi.haveCreatedByUID\n}\n\n// BTFID returns the BTF ID associated with the program.\n//\n// The ID is only valid as long as the associated program is kept alive.\n// Available from 5.0.\n//\n// The bool return value indicates whether this optional field is available and\n// populated. (The field may be available but not populated if the kernel\n// supports the field but the program was loaded without BTF information.)\nfunc (pi *ProgramInfo) BTFID() (btf.ID, bool) {\n\treturn pi.btf, pi.btf > 0\n}\n\n// RunCount returns the total number of times the program was called.\n//\n// Can return 0 if the collection of statistics is not enabled. See EnableStats().\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) RunCount() (uint64, bool) {\n\tif pi.stats != nil {\n\t\treturn pi.stats.runCount, true\n\t}\n\treturn 0, false\n}\n\n// Runtime returns the total accumulated runtime of the program.\n//\n// Can return 0 if the collection of statistics is not enabled. See EnableStats().\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) Runtime() (time.Duration, bool) {\n\tif pi.stats != nil {\n\t\treturn pi.stats.runtime, true\n\t}\n\treturn time.Duration(0), false\n}\n\n// RecursionMisses returns the total number of times the program was NOT called.\n// This can happen when another bpf program is already running on the cpu, which\n// is likely to happen for example when you interrupt bpf program execution.\nfunc (pi *ProgramInfo) RecursionMisses() (uint64, bool) {\n\tif pi.stats != nil {\n\t\treturn pi.stats.recursionMisses, true\n\t}\n\treturn 0, false\n}\n\n// btfSpec returns the BTF spec associated with the program.\nfunc (pi *ProgramInfo) btfSpec() (*btf.Spec, error) {\n\tid, ok := pi.BTFID()\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"program created without BTF or unsupported kernel: %w\", ErrNotSupported)\n\t}\n\n\th, err := btf.NewHandleFromID(id)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get BTF handle: %w\", err)\n\t}\n\tdefer h.Close()\n\n\tspec, err := h.Spec(nil)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get BTF spec: %w\", err)\n\t}\n\n\treturn spec, nil\n}\n\n// LineInfos returns the BTF line information of the program.\n//\n// Available from 5.0.\n//\n// Requires CAP_SYS_ADMIN or equivalent for reading BTF information. Returns\n// ErrNotSupported if the program was created without BTF or if the kernel\n// doesn't support the field.\nfunc (pi *ProgramInfo) LineInfos() (btf.LineOffsets, error) {\n\tif len(pi.lineInfos) == 0 {\n\t\treturn nil, fmt.Errorf(\"insufficient permissions or unsupported kernel: %w\", ErrNotSupported)\n\t}\n\n\tspec, err := pi.btfSpec()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn btf.LoadLineInfos(\n\t\tbytes.NewReader(pi.lineInfos),\n\t\tinternal.NativeEndian,\n\t\tpi.numLineInfos,\n\t\tspec,\n\t)\n}\n\n// Instructions returns the 'xlated' instruction stream of the program\n// after it has been verified and rewritten by the kernel. These instructions\n// cannot be loaded back into the kernel as-is, this is mainly used for\n// inspecting loaded programs for troubleshooting, dumping, etc.\n//\n// For example, map accesses are made to reference their kernel map IDs,\n// not the FDs they had when the program was inserted. Note that before\n// the introduction of bpf_insn_prepare_dump in kernel 4.16, xlated\n// instructions were not sanitized, making the output even less reusable\n// and less likely to round-trip or evaluate to the same program Tag.\n//\n// The first instruction is marked as a symbol using the Program's name.\n//\n// If available, the instructions will be annotated with metadata from the\n// BTF. This includes line information and function information. Reading\n// this metadata requires CAP_SYS_ADMIN or equivalent. If capability is\n// unavailable, the instructions will be returned without metadata.\n//\n// Available from 4.13. Requires CAP_BPF or equivalent for plain instructions.\n// Requires CAP_SYS_ADMIN for instructions with metadata.\nfunc (pi *ProgramInfo) Instructions() (asm.Instructions, error) {\n\t// If the calling process is not BPF-capable or if the kernel doesn't\n\t// support getting xlated instructions, the field will be zero.\n\tif len(pi.insns) == 0 {\n\t\treturn nil, fmt.Errorf(\"insufficient permissions or unsupported kernel: %w\", ErrNotSupported)\n\t}\n\n\tr := bytes.NewReader(pi.insns)\n\tvar insns asm.Instructions\n\tif err := insns.Unmarshal(r, internal.NativeEndian); err != nil {\n\t\treturn nil, fmt.Errorf(\"unmarshaling instructions: %w\", err)\n\t}\n\n\tif pi.btf != 0 {\n\t\tbtfh, err := btf.NewHandleFromID(pi.btf)\n\t\tif err != nil {\n\t\t\t// Getting a BTF handle requires CAP_SYS_ADMIN, if not available we get an -EPERM.\n\t\t\t// Ignore it and fall back to instructions without metadata.\n\t\t\tif !errors.Is(err, unix.EPERM) {\n\t\t\t\treturn nil, fmt.Errorf(\"unable to get BTF handle: %w\", err)\n\t\t\t}\n\t\t}\n\n\t\t// If we have a BTF handle, we can use it to assign metadata to the instructions.\n\t\tif btfh != nil {\n\t\t\tdefer btfh.Close()\n\n\t\t\tspec, err := btfh.Spec(nil)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unable to get BTF spec: %w\", err)\n\t\t\t}\n\n\t\t\tlineInfos, err := btf.LoadLineInfos(\n\t\t\t\tbytes.NewReader(pi.lineInfos),\n\t\t\t\tinternal.NativeEndian,\n\t\t\t\tpi.numLineInfos,\n\t\t\t\tspec,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parse line info: %w\", err)\n\t\t\t}\n\n\t\t\tfuncInfos, err := btf.LoadFuncInfos(\n\t\t\t\tbytes.NewReader(pi.funcInfos),\n\t\t\t\tinternal.NativeEndian,\n\t\t\t\tpi.numFuncInfos,\n\t\t\t\tspec,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parse func info: %w\", err)\n\t\t\t}\n\n\t\t\tbtf.AssignMetadataToInstructions(insns, funcInfos, lineInfos, btf.CORERelocationInfos{})\n\t\t}\n\t}\n\n\tfn := btf.FuncMetadata(&insns[0])\n\tname := pi.Name\n\tif fn != nil {\n\t\tname = fn.Name\n\t}\n\tinsns[0] = insns[0].WithSymbol(name)\n\n\treturn insns, nil\n}\n\n// JitedSize returns the size of the program's JIT-compiled machine code in bytes, which is the\n// actual code executed on the host's CPU. This field requires the BPF JIT compiler to be enabled.\n//\n// Available from 4.13. Reading this metadata requires CAP_BPF or equivalent.\nfunc (pi *ProgramInfo) JitedSize() (uint32, error) {\n\tif pi.jitedSize == 0 {\n\t\treturn 0, fmt.Errorf(\"insufficient permissions, unsupported kernel, or JIT compiler disabled: %w\", ErrNotSupported)\n\t}\n\treturn pi.jitedSize, nil\n}\n\n// TranslatedSize returns the size of the program's translated instructions in bytes, after it has\n// been verified and rewritten by the kernel.\n//\n// Available from 4.13. Reading this metadata requires CAP_BPF or equivalent.\nfunc (pi *ProgramInfo) TranslatedSize() (int, error) {\n\tinsns := len(pi.insns)\n\tif insns == 0 {\n\t\treturn 0, fmt.Errorf(\"insufficient permissions or unsupported kernel: %w\", ErrNotSupported)\n\t}\n\treturn insns, nil\n}\n\n// MapIDs returns the maps related to the program.\n//\n// Available from 4.15.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) MapIDs() ([]MapID, bool) {\n\treturn pi.maps, pi.maps != nil\n}\n\n// LoadTime returns when the program was loaded since boot time.\n//\n// Available from 4.15.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) LoadTime() (time.Duration, bool) {\n\t// loadTime and NrMapIds were introduced in the same kernel version.\n\treturn pi.loadTime, pi.loadTime > 0\n}\n\n// VerifiedInstructions returns the number verified instructions in the program.\n//\n// Available from 5.16.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) VerifiedInstructions() (uint32, bool) {\n\treturn pi.verifiedInstructions, pi.verifiedInstructions > 0\n}\n\n// JitedKsymAddrs returns the ksym addresses of the BPF program, including its\n// subprograms. The addresses correspond to their symbols in /proc/kallsyms.\n//\n// Available from 4.18. Note that before 5.x, this field can be empty for\n// programs without subprograms (bpf2bpf calls).\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) JitedKsymAddrs() ([]uintptr, bool) {\n\treturn pi.jitedInfo.ksyms, len(pi.jitedInfo.ksyms) > 0\n}\n\n// JitedInsns returns the JITed machine native instructions of the program.\n//\n// Available from 4.13.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) JitedInsns() ([]byte, bool) {\n\treturn pi.jitedInfo.insns, len(pi.jitedInfo.insns) > 0\n}\n\n// JitedLineInfos returns the JITed line infos of the program.\n//\n// Available from 5.0.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) JitedLineInfos() ([]uint64, bool) {\n\treturn pi.jitedInfo.lineInfos, len(pi.jitedInfo.lineInfos) > 0\n}\n\n// JitedFuncLens returns the insns length of each function in the JITed program.\n//\n// Available from 4.18.\n//\n// The bool return value indicates whether this optional field is available.\nfunc (pi *ProgramInfo) JitedFuncLens() ([]uint32, bool) {\n\treturn pi.jitedInfo.funcLens, len(pi.jitedInfo.funcLens) > 0\n}\n\n// FuncInfos returns the offset and function information of all (sub)programs in\n// a BPF program.\n//\n// Available from 5.0.\n//\n// Requires CAP_SYS_ADMIN or equivalent for reading BTF information. Returns\n// ErrNotSupported if the program was created without BTF or if the kernel\n// doesn't support the field.\nfunc (pi *ProgramInfo) FuncInfos() (btf.FuncOffsets, error) {\n\tif len(pi.funcInfos) == 0 {\n\t\treturn nil, fmt.Errorf(\"insufficient permissions or unsupported kernel: %w\", ErrNotSupported)\n\t}\n\n\tspec, err := pi.btfSpec()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn btf.LoadFuncInfos(\n\t\tbytes.NewReader(pi.funcInfos),\n\t\tinternal.NativeEndian,\n\t\tpi.numFuncInfos,\n\t\tspec,\n\t)\n}\n\nfunc scanFdInfo(fd *sys.FD, fields map[string]interface{}) error {\n\tfh, err := os.Open(fmt.Sprintf(\"/proc/self/fdinfo/%d\", fd.Int()))\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer fh.Close()\n\n\tif err := scanFdInfoReader(fh, fields); err != nil {\n\t\treturn fmt.Errorf(\"%s: %w\", fh.Name(), err)\n\t}\n\treturn nil\n}\n\nfunc scanFdInfoReader(r io.Reader, fields map[string]interface{}) error {\n\tvar (\n\t\tscanner = bufio.NewScanner(r)\n\t\tscanned int\n\t)\n\n\tfor scanner.Scan() {\n\t\tparts := strings.SplitN(scanner.Text(), \"\\t\", 2)\n\t\tif len(parts) != 2 {\n\t\t\tcontinue\n\t\t}\n\n\t\tname := strings.TrimSuffix(parts[0], \":\")\n\t\tfield, ok := fields[string(name)]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\t// If field already contains a non-zero value, don't overwrite it with fdinfo.\n\t\tif zero(field) {\n\t\t\tif n, err := fmt.Sscanln(parts[1], field); err != nil || n != 1 {\n\t\t\t\treturn fmt.Errorf(\"can't parse field %s: %v\", name, err)\n\t\t\t}\n\t\t}\n\n\t\tscanned++\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\treturn fmt.Errorf(\"scanning fdinfo: %w\", err)\n\t}\n\n\tif len(fields) > 0 && scanned == 0 {\n\t\treturn ErrNotSupported\n\t}\n\n\treturn nil\n}\n\nfunc zero(arg any) bool {\n\tv := reflect.ValueOf(arg)\n\n\t// Unwrap pointers and interfaces.\n\tfor v.Kind() == reflect.Pointer ||\n\t\tv.Kind() == reflect.Interface {\n\t\tv = v.Elem()\n\t}\n\n\treturn v.IsZero()\n}\n\n// EnableStats starts the measuring of the runtime\n// and run counts of eBPF programs.\n//\n// Collecting statistics can have an impact on the performance.\n//\n// Requires at least 5.8.\nfunc EnableStats(which uint32) (io.Closer, error) {\n\tfd, err := sys.EnableStats(&sys.EnableStatsAttr{\n\t\tType: which,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn fd, nil\n}\n\nvar haveProgramInfoMapIDs = internal.NewFeatureTest(\"map IDs in program info\", func() error {\n\tprog, err := progLoad(asm.Instructions{\n\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\tasm.Return(),\n\t}, SocketFilter, \"MIT\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer prog.Close()\n\n\terr = sys.ObjInfo(prog, &sys.ProgInfo{\n\t\t// NB: Don't need to allocate MapIds since the program isn't using\n\t\t// any maps.\n\t\tNrMapIds: 1,\n\t})\n\tif errors.Is(err, unix.EINVAL) {\n\t\t// Most likely the syscall doesn't exist.\n\t\treturn internal.ErrNotSupported\n\t}\n\tif errors.Is(err, unix.E2BIG) {\n\t\t// We've hit check_uarg_tail_zero on older kernels.\n\t\treturn internal.ErrNotSupported\n\t}\n\n\treturn err\n}, \"4.15\")\n"
        },
        {
          "name": "info_test.go",
          "type": "blob",
          "size": 13.7822265625,
          "content": "package ebpf\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/go-quicktest/qt\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n)\n\nvar btfFn = &btf.Func{\n\tName: \"_\",\n\tType: &btf.FuncProto{\n\t\tReturn: &btf.Int{Size: 16},\n\t\tParams: []btf.FuncParam{},\n\t},\n\tLinkage: btf.StaticFunc,\n}\n\nvar multiprogSpec = &ProgramSpec{\n\tName: \"test\",\n\tType: SocketFilter,\n\tInstructions: asm.Instructions{\n\t\tbtf.WithFuncMetadata(asm.LoadImm(asm.R0, 0, asm.DWord), btfFn).\n\t\t\tWithSource(asm.Comment(\"line info\")),\n\t\tasm.Call.Label(\"fn\"),\n\t\tasm.Return(),\n\t\tbtf.WithFuncMetadata(asm.LoadImm(asm.R0, 0, asm.DWord), btfFn).\n\t\t\tWithSource(asm.Comment(\"line info\")).WithSymbol(\"fn\"),\n\t\tasm.Return(),\n\t},\n\tLicense: \"MIT\",\n}\n\nfunc TestMapInfoFromProc(t *testing.T) {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  5,\n\t\tMaxEntries: 2,\n\t\tFlags:      sys.BPF_F_NO_PREALLOC,\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer hash.Close()\n\n\tvar info MapInfo\n\terr = readMapInfoFromProc(hash.fd, &info)\n\ttestutils.SkipIfNotSupported(t, err)\n\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(info.Type, Hash))\n\tqt.Assert(t, qt.Equals(info.KeySize, 4))\n\tqt.Assert(t, qt.Equals(info.ValueSize, 5))\n\tqt.Assert(t, qt.Equals(info.MaxEntries, 2))\n\tqt.Assert(t, qt.Equals(info.Flags, sys.BPF_F_NO_PREALLOC))\n}\n\nfunc TestMapInfoFromProcOuterMap(t *testing.T) {\n\touter, err := NewMap(&MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tKeySize:    4,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 2,\n\t\t},\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer outer.Close()\n\n\tvar info MapInfo\n\terr = readMapInfoFromProc(outer.fd, &info)\n\ttestutils.SkipIfNotSupported(t, err)\n\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(info.KeySize, 4))\n\tqt.Assert(t, qt.Equals(info.MaxEntries, 2))\n}\n\nfunc validateProgInfo(t *testing.T, info *ProgramInfo) {\n\tt.Helper()\n\n\tqt.Assert(t, qt.Equals(info.Type, SocketFilter))\n\tqt.Assert(t, qt.Equals(info.Tag, \"d7edec644f05498d\"))\n}\n\nfunc TestProgramInfo(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\tinfo, err := newProgramInfoFromFd(prog.fd)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tvalidateProgInfo(t, info)\n\n\tid, ok := info.ID()\n\tqt.Assert(t, qt.IsTrue(ok))\n\tqt.Assert(t, qt.Not(qt.Equals(id, 0)))\n\n\tif testutils.IsKernelLessThan(t, \"4.15\") {\n\t\tqt.Assert(t, qt.Equals(info.Name, \"\"))\n\t} else {\n\t\tqt.Assert(t, qt.Equals(info.Name, \"test\"))\n\t}\n\n\tif jitedSize, err := info.JitedSize(); testutils.IsKernelLessThan(t, \"4.13\") {\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t} else {\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.IsTrue(jitedSize > 0))\n\t}\n\n\tif xlatedSize, err := info.TranslatedSize(); testutils.IsKernelLessThan(t, \"4.13\") {\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t} else {\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.IsTrue(xlatedSize > 0))\n\t}\n\n\tif uid, ok := info.CreatedByUID(); testutils.IsKernelLessThan(t, \"4.15\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.Equals(uid, uint32(os.Getuid())))\n\t}\n\n\tif loadTime, ok := info.LoadTime(); testutils.IsKernelLessThan(t, \"4.15\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(loadTime > 0))\n\t}\n\n\tif verifiedInsns, ok := info.VerifiedInstructions(); testutils.IsKernelLessThan(t, \"5.16\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(verifiedInsns > 0))\n\t}\n\n\tif insns, ok := info.JitedInsns(); testutils.IsKernelLessThan(t, \"4.13\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(len(insns) > 0))\n\t}\n}\n\nfunc TestProgramInfoProc(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\tinfo, err := newProgramInfoFromProc(prog.fd)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tvalidateProgInfo(t, info)\n}\n\nfunc TestProgramInfoBTF(t *testing.T) {\n\tprog, err := NewProgram(multiprogSpec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tt.Cleanup(func() { prog.Close() })\n\n\tinfo, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\t// On kernels before 5.x, nr_jited_ksyms is not set for programs without subprogs.\n\t// It's included here since this test uses a bpf program with subprogs.\n\tif addrs, ok := info.JitedKsymAddrs(); testutils.IsKernelLessThan(t, \"4.18\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(len(addrs) > 0))\n\t}\n\n\tif lens, ok := info.JitedFuncLens(); testutils.IsKernelLessThan(t, \"4.18\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(len(lens) > 0))\n\t}\n\n\tif infos, ok := info.JitedLineInfos(); testutils.IsKernelLessThan(t, \"5.0\") {\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t} else {\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.IsTrue(len(infos) > 0))\n\t}\n\n\tif funcs, err := info.FuncInfos(); testutils.IsKernelLessThan(t, \"5.0\") {\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t} else {\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.HasLen(funcs, 2))\n\t\tqt.Assert(t, qt.ContentEquals(funcs[0].Func, btfFn))\n\t\tqt.Assert(t, qt.ContentEquals(funcs[1].Func, btfFn))\n\t}\n\n\tif lines, err := info.LineInfos(); testutils.IsKernelLessThan(t, \"5.0\") {\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t} else {\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.HasLen(lines, 2))\n\t\tqt.Assert(t, qt.Equals(lines[0].Line.Line(), \"line info\"))\n\t\tqt.Assert(t, qt.Equals(lines[1].Line.Line(), \"line info\"))\n\t}\n}\n\nfunc TestProgramInfoMapIDs(t *testing.T) {\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer arr.Close()\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadMapPtr(asm.R0, arr.FD()),\n\t\t\tasm.LoadImm(asm.R0, 2, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer prog.Close()\n\n\tinfo, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tids, ok := info.MapIDs()\n\tswitch {\n\tcase testutils.IsKernelLessThan(t, \"4.15\"):\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t\tqt.Assert(t, qt.HasLen(ids, 0))\n\n\tdefault:\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\n\t\tmapInfo, err := arr.Info()\n\t\tqt.Assert(t, qt.IsNil(err))\n\n\t\tmapID, ok := mapInfo.ID()\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.ContentEquals(ids, []MapID{mapID}))\n\t}\n}\n\nfunc TestProgramInfoMapIDsNoMaps(t *testing.T) {\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer prog.Close()\n\n\tinfo, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tids, ok := info.MapIDs()\n\tswitch {\n\tcase testutils.IsKernelLessThan(t, \"4.15\"):\n\t\tqt.Assert(t, qt.IsFalse(ok))\n\t\tqt.Assert(t, qt.HasLen(ids, 0))\n\n\tdefault:\n\t\tqt.Assert(t, qt.IsTrue(ok))\n\t\tqt.Assert(t, qt.HasLen(ids, 0))\n\t}\n}\n\nfunc TestScanFdInfoReader(t *testing.T) {\n\ttests := []struct {\n\t\tfields map[string]interface{}\n\t\tvalid  bool\n\t}{\n\t\t{nil, true},\n\t\t{map[string]interface{}{\"foo\": new(string)}, true},\n\t\t{map[string]interface{}{\"zap\": new(string)}, false},\n\t\t{map[string]interface{}{\"foo\": new(int)}, false},\n\t}\n\n\tfor _, test := range tests {\n\t\terr := scanFdInfoReader(strings.NewReader(\"foo:\\tbar\\n\"), test.fields)\n\t\tif test.valid {\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"fields %v returns an error: %s\", test.fields, err)\n\t\t\t}\n\t\t} else {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"fields %v doesn't return an error\", test.fields)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestStats loads a BPF program once and executes back-to-back test runs\n// of the program. See testStats for details.\nfunc TestStats(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.8\", \"BPF_ENABLE_STATS\")\n\n\tprog := mustSocketFilter(t)\n\n\tpi, err := prog.Info()\n\tif err != nil {\n\t\tt.Errorf(\"failed to get ProgramInfo: %v\", err)\n\t}\n\n\trc, ok := pi.RunCount()\n\tif !ok {\n\t\tt.Errorf(\"expected run count info to be available\")\n\t}\n\tif rc != 0 {\n\t\tt.Errorf(\"expected a run count of 0 but got %d\", rc)\n\t}\n\n\trt, ok := pi.Runtime()\n\tif !ok {\n\t\tt.Errorf(\"expected runtime info to be available\")\n\t}\n\tif rt != 0 {\n\t\tt.Errorf(\"expected a runtime of 0ns but got %v\", rt)\n\t}\n\n\trm, ok := pi.RecursionMisses()\n\tif !ok {\n\t\tt.Errorf(\"expected recursion misses info to be available\")\n\t}\n\tif rm != 0 {\n\t\tt.Errorf(\"expected a recursion misses of 0 but got %v\", rm)\n\t}\n\n\tif err := testStats(prog); err != nil {\n\t\tt.Error(err)\n\t}\n}\n\n// BenchmarkStats is a benchmark of TestStats. See testStats for details.\nfunc BenchmarkStats(b *testing.B) {\n\ttestutils.SkipOnOldKernel(b, \"5.8\", \"BPF_ENABLE_STATS\")\n\n\tprog := mustSocketFilter(b)\n\n\tfor n := 0; n < b.N; n++ {\n\t\tif err := testStats(prog); err != nil {\n\t\t\tb.Fatal(fmt.Errorf(\"iter %d: %w\", n, err))\n\t\t}\n\t}\n}\n\n// testStats implements the behaviour under test for TestStats\n// and BenchmarkStats. First, a test run is executed with runtime statistics\n// enabled, followed by another with runtime stats disabled. Counters are only\n// expected to increase on the runs where runtime stats are enabled.\n//\n// Due to runtime behaviour on Go 1.14 and higher, the syscall backing\n// (*Program).Test() could be invoked multiple times for each call to Test(),\n// resulting in RunCount incrementing by more than one. Expecting RunCount to\n// be of a specific value after a call to Test() is therefore not possible.\n// See https://golang.org/doc/go1.14#runtime for more details.\nfunc testStats(prog *Program) error {\n\tin := internal.EmptyBPFContext\n\n\tstats, err := EnableStats(uint32(sys.BPF_STATS_RUN_TIME))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to enable stats: %v\", err)\n\t}\n\tdefer stats.Close()\n\n\t// Program execution with runtime statistics enabled.\n\t// Should increase both runtime and run counter.\n\tif _, _, err := prog.Test(in); err != nil {\n\t\treturn fmt.Errorf(\"failed to trigger program: %v\", err)\n\t}\n\n\tpi, err := prog.Info()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get ProgramInfo: %v\", err)\n\t}\n\n\trc, ok := pi.RunCount()\n\tif !ok {\n\t\treturn errors.New(\"expected run count info to be available\")\n\t}\n\tif rc < 1 {\n\t\treturn fmt.Errorf(\"expected a run count of at least 1 but got %d\", rc)\n\t}\n\t// Store the run count for the next invocation.\n\tlc := rc\n\n\trt, ok := pi.Runtime()\n\tif !ok {\n\t\treturn errors.New(\"expected runtime info to be available\")\n\t}\n\tif rt == 0 {\n\t\treturn errors.New(\"expected a runtime other than 0ns\")\n\t}\n\t// Store the runtime value for the next invocation.\n\tlt := rt\n\n\tif err := stats.Close(); err != nil {\n\t\treturn fmt.Errorf(\"failed to disable statistics: %v\", err)\n\t}\n\n\t// Second program execution, with runtime statistics gathering disabled.\n\t// Total runtime and run counters are not expected to increase.\n\tif _, _, err := prog.Test(in); err != nil {\n\t\treturn fmt.Errorf(\"failed to trigger program: %v\", err)\n\t}\n\n\tpi, err = prog.Info()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get ProgramInfo: %v\", err)\n\t}\n\n\trc, ok = pi.RunCount()\n\tif !ok {\n\t\treturn errors.New(\"expected run count info to be available\")\n\t}\n\tif rc != lc {\n\t\treturn fmt.Errorf(\"run count unexpectedly increased over previous value (current: %v, prev: %v)\", rc, lc)\n\t}\n\n\trt, ok = pi.Runtime()\n\tif !ok {\n\t\treturn errors.New(\"expected runtime info to be available\")\n\t}\n\tif rt != lt {\n\t\treturn fmt.Errorf(\"runtime unexpectedly increased over the previous value (current: %v, prev: %v)\", rt, lt)\n\t}\n\n\treturn nil\n}\n\nfunc TestHaveProgramInfoMapIDs(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveProgramInfoMapIDs)\n}\n\nfunc TestProgInfoExtBTF(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.0\", \"Program BTF (func/line_info)\")\n\n\tspec, err := LoadCollectionSpec(testutils.NativeFile(t, \"testdata/loader-%s.elf\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar obj struct {\n\t\tMain *Program `ebpf:\"xdp_prog\"`\n\t}\n\n\terr = spec.LoadAndAssign(&obj, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer obj.Main.Close()\n\n\tinfo, err := obj.Main.Info()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tinst, err := info.Instructions()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texpectedLineInfoCount := 28\n\texpectedFuncInfo := map[string]bool{\n\t\t\"xdp_prog\":   false,\n\t\t\"static_fn\":  false,\n\t\t\"global_fn2\": false,\n\t\t\"global_fn3\": false,\n\t}\n\n\tlineInfoCount := 0\n\n\tfor _, ins := range inst {\n\t\tif ins.Source() != nil {\n\t\t\tlineInfoCount++\n\t\t}\n\n\t\tfn := btf.FuncMetadata(&ins)\n\t\tif fn != nil {\n\t\t\texpectedFuncInfo[fn.Name] = true\n\t\t}\n\t}\n\n\tif lineInfoCount != expectedLineInfoCount {\n\t\tt.Errorf(\"expected %d line info entries, got %d\", expectedLineInfoCount, lineInfoCount)\n\t}\n\n\tfor fn, found := range expectedFuncInfo {\n\t\tif !found {\n\t\t\tt.Errorf(\"func %q not found\", fn)\n\t\t}\n\t}\n}\n\nfunc TestInfoExportedFields(t *testing.T) {\n\t// It is highly unlikely that you should be adjusting the asserts below.\n\t// See the comment at the top of info.go for more information.\n\n\tvar names []string\n\tfor _, field := range reflect.VisibleFields(reflect.TypeOf(MapInfo{})) {\n\t\tif field.IsExported() {\n\t\t\tnames = append(names, field.Name)\n\t\t}\n\t}\n\tqt.Assert(t, qt.ContentEquals(names, []string{\n\t\t\"Type\",\n\t\t\"KeySize\",\n\t\t\"ValueSize\",\n\t\t\"MaxEntries\",\n\t\t\"Flags\",\n\t\t\"Name\",\n\t}))\n\n\tnames = nil\n\tfor _, field := range reflect.VisibleFields(reflect.TypeOf(ProgramInfo{})) {\n\t\tif field.IsExported() {\n\t\t\tnames = append(names, field.Name)\n\t\t}\n\t}\n\tqt.Assert(t, qt.ContentEquals(names, []string{\n\t\t\"Type\",\n\t\t\"Tag\",\n\t\t\"Name\",\n\t}))\n}\n\nfunc TestZero(t *testing.T) {\n\tvar (\n\t\tnul uint32 = 0\n\t\tone uint32 = 1\n\n\t\tinul any = uint32(0)\n\t\tione any = uint32(1)\n\t)\n\n\tqt.Assert(t, qt.IsTrue(zero(nul)))\n\tqt.Assert(t, qt.IsFalse(zero(one)))\n\n\tqt.Assert(t, qt.IsTrue(zero(&nul)))\n\tqt.Assert(t, qt.IsFalse(zero(&one)))\n\n\tqt.Assert(t, qt.IsTrue(zero(inul)))\n\tqt.Assert(t, qt.IsFalse(zero(ione)))\n\n\tqt.Assert(t, qt.IsTrue(zero(&inul)))\n\tqt.Assert(t, qt.IsFalse(zero(&ione)))\n}\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "link",
          "type": "tree",
          "content": null
        },
        {
          "name": "linker.go",
          "type": "blob",
          "size": 12.6953125,
          "content": "package ebpf\n\nimport (\n\t\"debug/elf\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"math\"\n\t\"slices\"\n\t\"strings\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/kallsyms\"\n)\n\n// handles stores handle objects to avoid gc cleanup\ntype handles []*btf.Handle\n\nfunc (hs *handles) add(h *btf.Handle) (int, error) {\n\tif h == nil {\n\t\treturn 0, nil\n\t}\n\n\tif len(*hs) == math.MaxInt16 {\n\t\treturn 0, fmt.Errorf(\"can't add more than %d module FDs to fdArray\", math.MaxInt16)\n\t}\n\n\t*hs = append(*hs, h)\n\n\t// return length of slice so that indexes start at 1\n\treturn len(*hs), nil\n}\n\nfunc (hs handles) fdArray() []int32 {\n\t// first element of fda is reserved as no module can be indexed with 0\n\tfda := []int32{0}\n\tfor _, h := range hs {\n\t\tfda = append(fda, int32(h.FD()))\n\t}\n\n\treturn fda\n}\n\nfunc (hs *handles) Close() error {\n\tvar errs []error\n\tfor _, h := range *hs {\n\t\terrs = append(errs, h.Close())\n\t}\n\treturn errors.Join(errs...)\n}\n\n// splitSymbols splits insns into subsections delimited by Symbol Instructions.\n// insns cannot be empty and must start with a Symbol Instruction.\n//\n// The resulting map is indexed by Symbol name.\nfunc splitSymbols(insns asm.Instructions) (map[string]asm.Instructions, error) {\n\tif len(insns) == 0 {\n\t\treturn nil, errors.New(\"insns is empty\")\n\t}\n\n\tcurrentSym := insns[0].Symbol()\n\tif currentSym == \"\" {\n\t\treturn nil, errors.New(\"insns must start with a Symbol\")\n\t}\n\n\tstart := 0\n\tprogs := make(map[string]asm.Instructions)\n\tfor i, ins := range insns[1:] {\n\t\ti := i + 1\n\n\t\tsym := ins.Symbol()\n\t\tif sym == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// New symbol, flush the old one out.\n\t\tprogs[currentSym] = slices.Clone(insns[start:i])\n\n\t\tif progs[sym] != nil {\n\t\t\treturn nil, fmt.Errorf(\"insns contains duplicate Symbol %s\", sym)\n\t\t}\n\t\tcurrentSym = sym\n\t\tstart = i\n\t}\n\n\tif tail := insns[start:]; len(tail) > 0 {\n\t\tprogs[currentSym] = slices.Clone(tail)\n\t}\n\n\treturn progs, nil\n}\n\n// The linker is responsible for resolving bpf-to-bpf calls between programs\n// within an ELF. Each BPF program must be a self-contained binary blob,\n// so when an instruction in one ELF program section wants to jump to\n// a function in another, the linker needs to pull in the bytecode\n// (and BTF info) of the target function and concatenate the instruction\n// streams.\n//\n// Later on in the pipeline, all call sites are fixed up with relative jumps\n// within this newly-created instruction stream to then finally hand off to\n// the kernel with BPF_PROG_LOAD.\n//\n// Each function is denoted by an ELF symbol and the compiler takes care of\n// register setup before each jump instruction.\n\n// hasFunctionReferences returns true if insns contains one or more bpf2bpf\n// function references.\nfunc hasFunctionReferences(insns asm.Instructions) bool {\n\tfor _, i := range insns {\n\t\tif i.IsFunctionReference() {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// applyRelocations collects and applies any CO-RE relocations in insns.\n//\n// Passing a nil target will relocate against the running kernel. insns are\n// modified in place.\nfunc applyRelocations(insns asm.Instructions, targets []*btf.Spec, kmodName string, bo binary.ByteOrder, b *btf.Builder) error {\n\tvar relos []*btf.CORERelocation\n\tvar reloInsns []*asm.Instruction\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tif relo := btf.CORERelocationMetadata(iter.Ins); relo != nil {\n\t\t\trelos = append(relos, relo)\n\t\t\treloInsns = append(reloInsns, iter.Ins)\n\t\t}\n\t}\n\n\tif len(relos) == 0 {\n\t\treturn nil\n\t}\n\n\tif bo == nil {\n\t\tbo = internal.NativeEndian\n\t}\n\n\tif len(targets) == 0 {\n\t\tkernelTarget, err := btf.LoadKernelSpec()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"load kernel spec: %w\", err)\n\t\t}\n\t\ttargets = append(targets, kernelTarget)\n\n\t\tif kmodName != \"\" {\n\t\t\tkmodTarget, err := btf.LoadKernelModuleSpec(kmodName)\n\t\t\t// Ignore ErrNotExists to cater to kernels which have CONFIG_DEBUG_INFO_BTF_MODULES disabled.\n\t\t\tif err != nil && !errors.Is(err, fs.ErrNotExist) {\n\t\t\t\treturn fmt.Errorf(\"load kernel module spec: %w\", err)\n\t\t\t}\n\t\t\tif err == nil {\n\t\t\t\ttargets = append(targets, kmodTarget)\n\t\t\t}\n\t\t}\n\t}\n\n\tfixups, err := btf.CORERelocate(relos, targets, bo, b.Add)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor i, fixup := range fixups {\n\t\tif err := fixup.Apply(reloInsns[i]); err != nil {\n\t\t\treturn fmt.Errorf(\"fixup for %s: %w\", relos[i], err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// flattenPrograms resolves bpf-to-bpf calls for a set of programs.\n//\n// Links all programs in names by modifying their ProgramSpec in progs.\nfunc flattenPrograms(progs map[string]*ProgramSpec, names []string) {\n\t// Pre-calculate all function references.\n\trefs := make(map[*ProgramSpec][]string)\n\tfor _, prog := range progs {\n\t\trefs[prog] = prog.Instructions.FunctionReferences()\n\t}\n\n\t// Create a flattened instruction stream, but don't modify progs yet to\n\t// avoid linking multiple times.\n\tflattened := make([]asm.Instructions, 0, len(names))\n\tfor _, name := range names {\n\t\tflattened = append(flattened, flattenInstructions(name, progs, refs))\n\t}\n\n\t// Finally, assign the flattened instructions.\n\tfor i, name := range names {\n\t\tprogs[name].Instructions = flattened[i]\n\t}\n}\n\n// flattenInstructions resolves bpf-to-bpf calls for a single program.\n//\n// Flattens the instructions of prog by concatenating the instructions of all\n// direct and indirect dependencies.\n//\n// progs contains all referenceable programs, while refs contain the direct\n// dependencies of each program.\nfunc flattenInstructions(name string, progs map[string]*ProgramSpec, refs map[*ProgramSpec][]string) asm.Instructions {\n\tprog := progs[name]\n\n\tinsns := make(asm.Instructions, len(prog.Instructions))\n\tcopy(insns, prog.Instructions)\n\n\t// Add all direct references of prog to the list of to be linked programs.\n\tpending := make([]string, len(refs[prog]))\n\tcopy(pending, refs[prog])\n\n\t// All references for which we've appended instructions.\n\tlinked := make(map[string]bool)\n\n\t// Iterate all pending references. We can't use a range since pending is\n\t// modified in the body below.\n\tfor len(pending) > 0 {\n\t\tvar ref string\n\t\tref, pending = pending[0], pending[1:]\n\n\t\tif linked[ref] {\n\t\t\t// We've already linked this ref, don't append instructions again.\n\t\t\tcontinue\n\t\t}\n\n\t\tprogRef := progs[ref]\n\t\tif progRef == nil {\n\t\t\t// We don't have instructions that go with this reference. This\n\t\t\t// happens when calling extern functions.\n\t\t\tcontinue\n\t\t}\n\n\t\tinsns = append(insns, progRef.Instructions...)\n\t\tlinked[ref] = true\n\n\t\t// Make sure we link indirect references.\n\t\tpending = append(pending, refs[progRef]...)\n\t}\n\n\treturn insns\n}\n\n// fixupAndValidate is called by the ELF reader right before marshaling the\n// instruction stream. It performs last-minute adjustments to the program and\n// runs some sanity checks before sending it off to the kernel.\nfunc fixupAndValidate(insns asm.Instructions) error {\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tins := iter.Ins\n\n\t\t// Map load was tagged with a Reference, but does not contain a Map pointer.\n\t\tneedsMap := ins.Reference() != \"\" || ins.Metadata.Get(kconfigMetaKey{}) != nil\n\t\tif ins.IsLoadFromMap() && needsMap && ins.Map() == nil {\n\t\t\treturn fmt.Errorf(\"instruction %d: %w\", iter.Index, asm.ErrUnsatisfiedMapReference)\n\t\t}\n\n\t\tfixupProbeReadKernel(ins)\n\t}\n\n\treturn nil\n}\n\n// POISON_CALL_KFUNC_BASE in libbpf.\n// https://github.com/libbpf/libbpf/blob/2778cbce609aa1e2747a69349f7f46a2f94f0522/src/libbpf.c#L5767\nconst kfuncCallPoisonBase = 2002000000\n\n// fixupKfuncs loops over all instructions in search for kfunc calls.\n// If at least one is found, the current kernels BTF and module BTFis are searched to set Instruction.Constant\n// and Instruction.Offset to the correct values.\nfunc fixupKfuncs(insns asm.Instructions) (_ handles, err error) {\n\tcloseOnError := func(c io.Closer) {\n\t\tif err != nil {\n\t\t\tc.Close()\n\t\t}\n\t}\n\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tins := iter.Ins\n\t\tif metadata := ins.Metadata.Get(kfuncMetaKey{}); metadata != nil {\n\t\t\tgoto fixups\n\t\t}\n\t}\n\n\treturn nil, nil\n\nfixups:\n\t// only load the kernel spec if we found at least one kfunc call\n\tkernelSpec, err := btf.LoadKernelSpec()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfdArray := make(handles, 0)\n\tdefer closeOnError(&fdArray)\n\n\tfor {\n\t\tins := iter.Ins\n\n\t\tmetadata := ins.Metadata.Get(kfuncMetaKey{})\n\t\tif metadata == nil {\n\t\t\tif !iter.Next() {\n\t\t\t\t// break loop if this was the last instruction in the stream.\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// check meta, if no meta return err\n\t\tkfm, _ := metadata.(*kfuncMeta)\n\t\tif kfm == nil {\n\t\t\treturn nil, fmt.Errorf(\"kfuncMetaKey doesn't contain kfuncMeta\")\n\t\t}\n\n\t\ttarget := btf.Type((*btf.Func)(nil))\n\t\tspec, module, err := findTargetInKernel(kernelSpec, kfm.Func.Name, &target)\n\t\tif kfm.Binding == elf.STB_WEAK && errors.Is(err, btf.ErrNotFound) {\n\t\t\tif ins.IsKfuncCall() {\n\t\t\t\t// If the kfunc call is weak and not found, poison the call. Use a recognizable constant\n\t\t\t\t// to make it easier to debug. And set src to zero so the verifier doesn't complain\n\t\t\t\t// about the invalid imm/offset values before dead-code elimination.\n\t\t\t\tins.Constant = kfuncCallPoisonBase\n\t\t\t\tins.Src = 0\n\t\t\t} else if ins.OpCode.IsDWordLoad() {\n\t\t\t\t// If the kfunc DWordLoad is weak and not found, set its address to 0.\n\t\t\t\tins.Constant = 0\n\t\t\t\tins.Src = 0\n\t\t\t} else {\n\t\t\t\treturn nil, fmt.Errorf(\"only kfunc calls and dword loads may have kfunc metadata\")\n\t\t\t}\n\n\t\t\titer.Next()\n\t\t\tcontinue\n\t\t}\n\t\t// Error on non-weak kfunc not found.\n\t\tif errors.Is(err, btf.ErrNotFound) {\n\t\t\treturn nil, fmt.Errorf(\"kfunc %q: %w\", kfm.Func.Name, ErrNotSupported)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tidx, err := fdArray.add(module)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif err := btf.CheckTypeCompatibility(kfm.Func.Type, target.(*btf.Func).Type); err != nil {\n\t\t\treturn nil, &incompatibleKfuncError{kfm.Func.Name, err}\n\t\t}\n\n\t\tid, err := spec.TypeID(target)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tins.Constant = int64(id)\n\t\tins.Offset = int16(idx)\n\n\t\tif !iter.Next() {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn fdArray, nil\n}\n\ntype incompatibleKfuncError struct {\n\tname string\n\terr  error\n}\n\nfunc (ike *incompatibleKfuncError) Error() string {\n\treturn fmt.Sprintf(\"kfunc %q: %s\", ike.name, ike.err)\n}\n\n// fixupProbeReadKernel replaces calls to bpf_probe_read_{kernel,user}(_str)\n// with bpf_probe_read(_str) on kernels that don't support it yet.\nfunc fixupProbeReadKernel(ins *asm.Instruction) {\n\tif !ins.IsBuiltinCall() {\n\t\treturn\n\t}\n\n\t// Kernel supports bpf_probe_read_kernel, nothing to do.\n\tif haveProbeReadKernel() == nil {\n\t\treturn\n\t}\n\n\tswitch asm.BuiltinFunc(ins.Constant) {\n\tcase asm.FnProbeReadKernel, asm.FnProbeReadUser:\n\t\tins.Constant = int64(asm.FnProbeRead)\n\tcase asm.FnProbeReadKernelStr, asm.FnProbeReadUserStr:\n\t\tins.Constant = int64(asm.FnProbeReadStr)\n\t}\n}\n\n// resolveKconfigReferences creates and populates a .kconfig map if necessary.\n//\n// Returns a nil Map and no error if no references exist.\nfunc resolveKconfigReferences(insns asm.Instructions) (_ *Map, err error) {\n\tcloseOnError := func(c io.Closer) {\n\t\tif err != nil {\n\t\t\tc.Close()\n\t\t}\n\t}\n\n\tvar spec *MapSpec\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tmeta, _ := iter.Ins.Metadata.Get(kconfigMetaKey{}).(*kconfigMeta)\n\t\tif meta != nil {\n\t\t\tspec = meta.Map\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif spec == nil {\n\t\treturn nil, nil\n\t}\n\n\tcpy := spec.Copy()\n\tif err := resolveKconfig(cpy); err != nil {\n\t\treturn nil, err\n\t}\n\n\tkconfig, err := NewMap(cpy)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer closeOnError(kconfig)\n\n\t// Resolve all instructions which load from .kconfig map with actual map\n\t// and offset inside it.\n\titer = insns.Iterate()\n\tfor iter.Next() {\n\t\tmeta, _ := iter.Ins.Metadata.Get(kconfigMetaKey{}).(*kconfigMeta)\n\t\tif meta == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif meta.Map != spec {\n\t\t\treturn nil, fmt.Errorf(\"instruction %d: reference to multiple .kconfig maps is not allowed\", iter.Index)\n\t\t}\n\n\t\tif err := iter.Ins.AssociateMap(kconfig); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"instruction %d: %w\", iter.Index, err)\n\t\t}\n\n\t\t// Encode a map read at the offset of the var in the datasec.\n\t\titer.Ins.Constant = int64(uint64(meta.Offset) << 32)\n\t\titer.Ins.Metadata.Set(kconfigMetaKey{}, nil)\n\t}\n\n\treturn kconfig, nil\n}\n\nfunc resolveKsymReferences(insns asm.Instructions) error {\n\tvar missing []string\n\n\titer := insns.Iterate()\n\tfor iter.Next() {\n\t\tins := iter.Ins\n\t\tmeta, _ := ins.Metadata.Get(ksymMetaKey{}).(*ksymMeta)\n\t\tif meta == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\taddr, err := kallsyms.Address(meta.Name)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"resolve ksym %s: %w\", meta.Name, err)\n\t\t}\n\t\tif addr != 0 {\n\t\t\tins.Constant = int64(addr)\n\t\t\tcontinue\n\t\t}\n\n\t\tif meta.Binding == elf.STB_WEAK {\n\t\t\t// A weak ksym variable in eBPF C means its resolution is optional.\n\t\t\t// Set a zero constant explicitly for clarity.\n\t\t\tins.Constant = 0\n\t\t\tcontinue\n\t\t}\n\n\t\tif !slices.Contains(missing, meta.Name) {\n\t\t\tmissing = append(missing, meta.Name)\n\t\t}\n\t}\n\n\tif len(missing) > 0 {\n\t\treturn fmt.Errorf(\"kernel is missing symbol: %s\", strings.Join(missing, \",\"))\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "linker_test.go",
          "type": "blob",
          "size": 4.0634765625,
          "content": "package ebpf\n\nimport (\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n\n\t\"github.com/go-quicktest/qt\"\n)\n\nfunc TestFindReferences(t *testing.T) {\n\tprogs := map[string]*ProgramSpec{\n\t\t\"entrypoint\": {\n\t\t\tType: SocketFilter,\n\t\t\tInstructions: asm.Instructions{\n\t\t\t\t// Make sure the call doesn't happen at instruction 0\n\t\t\t\t// to exercise the relative offset calculation.\n\t\t\t\tasm.Mov.Reg(asm.R0, asm.R1),\n\t\t\t\tasm.Call.Label(\"my_func\"),\n\t\t\t\tasm.Return(),\n\t\t\t},\n\t\t\tLicense: \"MIT\",\n\t\t},\n\t\t\"my_other_func\": {\n\t\t\tInstructions: asm.Instructions{\n\t\t\t\tasm.LoadImm(asm.R0, 1337, asm.DWord).WithSymbol(\"my_other_func\"),\n\t\t\t\tasm.Return(),\n\t\t\t},\n\t\t},\n\t\t\"my_func\": {\n\t\t\tInstructions: asm.Instructions{\n\t\t\t\tasm.Call.Label(\"my_other_func\").WithSymbol(\"my_func\"),\n\t\t\t\tasm.Return(),\n\t\t\t},\n\t\t},\n\t}\n\n\tflattenPrograms(progs, []string{\"entrypoint\"})\n\n\tprog, err := NewProgram(progs[\"entrypoint\"])\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tret, _, err := prog.Test(internal.EmptyBPFContext)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 1337 {\n\t\tt.Errorf(\"Expected return code 1337, got %d\", ret)\n\t}\n}\n\nfunc TestForwardFunctionDeclaration(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/fwd_decl-%s.elf\")\n\tcoll, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tspec := coll.Programs[\"call_fwd\"]\n\n\t// This program calls an unimplemented forward function declaration.\n\t_, err = NewProgram(spec)\n\tif !errors.Is(err, asm.ErrUnsatisfiedProgramReference) {\n\t\tt.Fatal(\"Expected an error wrapping ErrUnsatisfiedProgramReference, got:\", err)\n\t}\n\n\t// Append the implementation of fwd().\n\tspec.Instructions = append(spec.Instructions,\n\t\tasm.Mov.Imm32(asm.R0, 23).WithSymbol(\"fwd\"),\n\t\tasm.Return(),\n\t)\n\n\t// The body of the subprog we appended does not come with BTF func_infos,\n\t// so the verifier will reject it. Load without BTF.\n\tfor i, ins := range spec.Instructions {\n\t\tif btf.FuncMetadata(&ins) != nil || ins.Source() != nil {\n\t\t\tsym := ins.Symbol()\n\t\t\tref := ins.Reference()\n\t\t\tins.Metadata = asm.Metadata{}\n\t\t\tspec.Instructions[i] = ins.WithSymbol(sym).WithReference(ref)\n\t\t}\n\t}\n\n\tprog, err := NewProgram(spec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatalf(\"%+v\", err)\n\t}\n\tdefer prog.Close()\n\n\tret, _, err := prog.Test(internal.EmptyBPFContext)\n\tif err != nil {\n\t\tt.Fatal(\"Running program:\", err)\n\t}\n\tif ret != 23 {\n\t\tt.Fatalf(\"Expected 23, got %d\", ret)\n\t}\n}\n\nfunc TestSplitSymbols(t *testing.T) {\n\n\t// Splitting an empty insns results in an error.\n\t_, err := splitSymbols(asm.Instructions{})\n\tqt.Assert(t, qt.IsNotNil(err), qt.Commentf(\"empty insns\"))\n\n\t// Splitting non-empty insns without a leading Symbol is an error.\n\t_, err = splitSymbols(asm.Instructions{\n\t\tasm.Return(),\n\t})\n\tqt.Assert(t, qt.IsNotNil(err), qt.Commentf(\"insns without leading Symbol\"))\n\n\t// Non-empty insns with a single Instruction that is a Symbol.\n\tinsns := asm.Instructions{\n\t\tasm.Return().WithSymbol(\"sym\"),\n\t}\n\tm, err := splitSymbols(insns)\n\tqt.Assert(t, qt.IsNil(err), qt.Commentf(\"insns with a single Symbol\"))\n\n\tqt.Assert(t, qt.HasLen(m, 1))\n\tqt.Assert(t, qt.HasLen(m[\"sym\"], 1))\n\n\t// Insns containing duplicate Symbols.\n\t_, err = splitSymbols(asm.Instructions{\n\t\tasm.Return().WithSymbol(\"sym\"),\n\t\tasm.Return().WithSymbol(\"sym\"),\n\t})\n\tqt.Assert(t, qt.IsNotNil(err), qt.Commentf(\"insns containing duplicate Symbols\"))\n\n\t// Insns with multiple Symbols and subprogs of various lengths.\n\tm, err = splitSymbols(asm.Instructions{\n\t\tasm.Return().WithSymbol(\"sym1\"),\n\n\t\tasm.Mov.Imm(asm.R0, 0).WithSymbol(\"sym2\"),\n\t\tasm.Return(),\n\n\t\tasm.Mov.Imm(asm.R0, 0).WithSymbol(\"sym3\"),\n\t\tasm.Mov.Imm(asm.R0, 1),\n\t\tasm.Return(),\n\n\t\tasm.Mov.Imm(asm.R0, 0).WithSymbol(\"sym4\"),\n\t\tasm.Mov.Imm(asm.R0, 1),\n\t\tasm.Mov.Imm(asm.R0, 2),\n\t\tasm.Return(),\n\t})\n\tqt.Assert(t, qt.IsNil(err), qt.Commentf(\"insns with multiple Symbols\"))\n\n\tqt.Assert(t, qt.HasLen(m, 4))\n\tqt.Assert(t, qt.HasLen(m[\"sym1\"], 1))\n\tqt.Assert(t, qt.HasLen(m[\"sym2\"], 2))\n\tqt.Assert(t, qt.HasLen(m[\"sym3\"], 3))\n\tqt.Assert(t, qt.HasLen(m[\"sym4\"], 4))\n}\n"
        },
        {
          "name": "map.go",
          "type": "blob",
          "size": 46.9833984375,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"slices\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/sysenc\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\n// Errors returned by Map and MapIterator methods.\nvar (\n\tErrKeyNotExist      = errors.New(\"key does not exist\")\n\tErrKeyExist         = errors.New(\"key already exists\")\n\tErrIterationAborted = errors.New(\"iteration aborted\")\n\tErrMapIncompatible  = errors.New(\"map spec is incompatible with existing map\")\n\terrMapNoBTFValue    = errors.New(\"map spec does not contain a BTF Value\")\n\n\t// pre-allocating these errors here since they may get called in hot code paths\n\t// and cause unnecessary memory allocations\n\terrMapLookupKeyNotExist = fmt.Errorf(\"lookup: %w\", sysErrKeyNotExist)\n)\n\n// MapOptions control loading a map into the kernel.\ntype MapOptions struct {\n\t// The base path to pin maps in if requested via PinByName.\n\t// Existing maps will be re-used if they are compatible, otherwise an\n\t// error is returned.\n\tPinPath        string\n\tLoadPinOptions LoadPinOptions\n}\n\n// MapID represents the unique ID of an eBPF map\ntype MapID uint32\n\n// MapSpec defines a Map.\ntype MapSpec struct {\n\t// Name is passed to the kernel as a debug aid. Must only contain\n\t// alpha numeric and '_' characters.\n\tName       string\n\tType       MapType\n\tKeySize    uint32\n\tValueSize  uint32\n\tMaxEntries uint32\n\n\t// Flags is passed to the kernel and specifies additional map\n\t// creation attributes.\n\tFlags uint32\n\n\t// Automatically pin and load a map from MapOptions.PinPath.\n\t// Generates an error if an existing pinned map is incompatible with the MapSpec.\n\tPinning PinType\n\n\t// Specify numa node during map creation\n\t// (effective only if sys.BPF_F_NUMA_NODE flag is set,\n\t// which can be imported from golang.org/x/sys/unix)\n\tNumaNode uint32\n\n\t// The initial contents of the map. May be nil.\n\tContents []MapKV\n\n\t// InnerMap is used as a template for ArrayOfMaps and HashOfMaps\n\tInnerMap *MapSpec\n\n\t// Extra trailing bytes found in the ELF map definition when using structs\n\t// larger than libbpf's bpf_map_def. nil if no trailing bytes were present.\n\t// Must be nil or empty before instantiating the MapSpec into a Map.\n\tExtra *bytes.Reader\n\n\t// The key and value type of this map. May be nil.\n\tKey, Value btf.Type\n}\n\nfunc (ms *MapSpec) String() string {\n\treturn fmt.Sprintf(\"%s(keySize=%d, valueSize=%d, maxEntries=%d, flags=%d)\", ms.Type, ms.KeySize, ms.ValueSize, ms.MaxEntries, ms.Flags)\n}\n\n// Copy returns a copy of the spec.\n//\n// MapSpec.Contents is a shallow copy.\nfunc (ms *MapSpec) Copy() *MapSpec {\n\tif ms == nil {\n\t\treturn nil\n\t}\n\n\tcpy := *ms\n\tcpy.Contents = slices.Clone(cpy.Contents)\n\tcpy.Key = btf.Copy(cpy.Key)\n\tcpy.Value = btf.Copy(cpy.Value)\n\n\tif cpy.InnerMap == ms {\n\t\tcpy.InnerMap = &cpy\n\t} else {\n\t\tcpy.InnerMap = ms.InnerMap.Copy()\n\t}\n\n\tif cpy.Extra != nil {\n\t\textra := *cpy.Extra\n\t\tcpy.Extra = &extra\n\t}\n\n\treturn &cpy\n}\n\n// fixupMagicFields fills fields of MapSpec which are usually\n// left empty in ELF or which depend on runtime information.\n//\n// The method doesn't modify Spec, instead returning a copy.\n// The copy is only performed if fixups are necessary, so callers mustn't mutate\n// the returned spec.\nfunc (spec *MapSpec) fixupMagicFields() (*MapSpec, error) {\n\tswitch spec.Type {\n\tcase ArrayOfMaps, HashOfMaps:\n\t\tif spec.ValueSize != 0 && spec.ValueSize != 4 {\n\t\t\treturn nil, errors.New(\"ValueSize must be zero or four for map of map\")\n\t\t}\n\n\t\tspec = spec.Copy()\n\t\tspec.ValueSize = 4\n\n\tcase PerfEventArray:\n\t\tif spec.KeySize != 0 && spec.KeySize != 4 {\n\t\t\treturn nil, errors.New(\"KeySize must be zero or four for perf event array\")\n\t\t}\n\n\t\tif spec.ValueSize != 0 && spec.ValueSize != 4 {\n\t\t\treturn nil, errors.New(\"ValueSize must be zero or four for perf event array\")\n\t\t}\n\n\t\tspec = spec.Copy()\n\t\tspec.KeySize = 4\n\t\tspec.ValueSize = 4\n\n\t\tn, err := PossibleCPU()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"fixup perf event array: %w\", err)\n\t\t}\n\n\t\tif n := uint32(n); spec.MaxEntries == 0 || spec.MaxEntries > n {\n\t\t\t// MaxEntries should be zero most of the time, but there is code\n\t\t\t// out there which hardcodes large constants. Clamp the number\n\t\t\t// of entries to the number of CPUs at most. Allow creating maps with\n\t\t\t// less than n items since some kernel selftests relied on this\n\t\t\t// behaviour in the past.\n\t\t\tspec.MaxEntries = n\n\t\t}\n\n\tcase CPUMap:\n\t\tn, err := PossibleCPU()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"fixup cpu map: %w\", err)\n\t\t}\n\n\t\tif n := uint32(n); spec.MaxEntries == 0 || spec.MaxEntries > n {\n\t\t\t// Perform clamping similar to PerfEventArray.\n\t\t\tspec.MaxEntries = n\n\t\t}\n\t}\n\n\treturn spec, nil\n}\n\n// dataSection returns the contents and BTF Datasec descriptor of the spec.\nfunc (ms *MapSpec) dataSection() ([]byte, *btf.Datasec, error) {\n\tif ms.Value == nil {\n\t\treturn nil, nil, errMapNoBTFValue\n\t}\n\n\tds, ok := ms.Value.(*btf.Datasec)\n\tif !ok {\n\t\treturn nil, nil, fmt.Errorf(\"map value BTF is a %T, not a *btf.Datasec\", ms.Value)\n\t}\n\n\tif n := len(ms.Contents); n != 1 {\n\t\treturn nil, nil, fmt.Errorf(\"expected one key, found %d\", n)\n\t}\n\n\tkv := ms.Contents[0]\n\tvalue, ok := kv.Value.([]byte)\n\tif !ok {\n\t\treturn nil, nil, fmt.Errorf(\"value at first map key is %T, not []byte\", kv.Value)\n\t}\n\n\treturn value, ds, nil\n}\n\nfunc (ms *MapSpec) readOnly() bool {\n\treturn (ms.Flags & sys.BPF_F_RDONLY_PROG) > 0\n}\n\nfunc (ms *MapSpec) writeOnly() bool {\n\treturn (ms.Flags & sys.BPF_F_WRONLY_PROG) > 0\n}\n\n// MapKV is used to initialize the contents of a Map.\ntype MapKV struct {\n\tKey   interface{}\n\tValue interface{}\n}\n\n// Compatible returns nil if an existing map may be used instead of creating\n// one from the spec.\n//\n// Returns an error wrapping [ErrMapIncompatible] otherwise.\nfunc (ms *MapSpec) Compatible(m *Map) error {\n\tms, err := ms.fixupMagicFields()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdiffs := []string{}\n\tif m.typ != ms.Type {\n\t\tdiffs = append(diffs, fmt.Sprintf(\"Type: %s changed to %s\", m.typ, ms.Type))\n\t}\n\tif m.keySize != ms.KeySize {\n\t\tdiffs = append(diffs, fmt.Sprintf(\"KeySize: %d changed to %d\", m.keySize, ms.KeySize))\n\t}\n\tif m.valueSize != ms.ValueSize {\n\t\tdiffs = append(diffs, fmt.Sprintf(\"ValueSize: %d changed to %d\", m.valueSize, ms.ValueSize))\n\t}\n\tif m.maxEntries != ms.MaxEntries {\n\t\tdiffs = append(diffs, fmt.Sprintf(\"MaxEntries: %d changed to %d\", m.maxEntries, ms.MaxEntries))\n\t}\n\n\t// BPF_F_RDONLY_PROG is set unconditionally for devmaps. Explicitly allow this\n\t// mismatch.\n\tif !((ms.Type == DevMap || ms.Type == DevMapHash) && m.flags^ms.Flags == sys.BPF_F_RDONLY_PROG) &&\n\t\tm.flags != ms.Flags {\n\t\tdiffs = append(diffs, fmt.Sprintf(\"Flags: %d changed to %d\", m.flags, ms.Flags))\n\t}\n\n\tif len(diffs) == 0 {\n\t\treturn nil\n\t}\n\n\treturn fmt.Errorf(\"%s: %w\", strings.Join(diffs, \", \"), ErrMapIncompatible)\n}\n\n// Map represents a Map file descriptor.\n//\n// It is not safe to close a map which is used by other goroutines.\n//\n// Methods which take interface{} arguments by default encode\n// them using binary.Read/Write in the machine's native endianness.\n//\n// Implement encoding.BinaryMarshaler or encoding.BinaryUnmarshaler\n// if you require custom encoding.\ntype Map struct {\n\tname       string\n\tfd         *sys.FD\n\ttyp        MapType\n\tkeySize    uint32\n\tvalueSize  uint32\n\tmaxEntries uint32\n\tflags      uint32\n\tpinnedPath string\n\t// Per CPU maps return values larger than the size in the spec\n\tfullValueSize int\n\n\tmemory *Memory\n}\n\n// NewMapFromFD creates a map from a raw fd.\n//\n// You should not use fd after calling this function.\nfunc NewMapFromFD(fd int) (*Map, error) {\n\tf, err := sys.NewFD(fd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newMapFromFD(f)\n}\n\nfunc newMapFromFD(fd *sys.FD) (*Map, error) {\n\tinfo, err := newMapInfoFromFd(fd)\n\tif err != nil {\n\t\tfd.Close()\n\t\treturn nil, fmt.Errorf(\"get map info: %w\", err)\n\t}\n\n\treturn newMap(fd, info.Name, info.Type, info.KeySize, info.ValueSize, info.MaxEntries, info.Flags)\n}\n\n// NewMap creates a new Map.\n//\n// It's equivalent to calling NewMapWithOptions with default options.\nfunc NewMap(spec *MapSpec) (*Map, error) {\n\treturn NewMapWithOptions(spec, MapOptions{})\n}\n\n// NewMapWithOptions creates a new Map.\n//\n// Creating a map for the first time will perform feature detection\n// by creating small, temporary maps.\n//\n// The caller is responsible for ensuring the process' rlimit is set\n// sufficiently high for locking memory during map creation. This can be done\n// by calling rlimit.RemoveMemlock() prior to calling NewMapWithOptions.\n//\n// May return an error wrapping ErrMapIncompatible.\nfunc NewMapWithOptions(spec *MapSpec, opts MapOptions) (*Map, error) {\n\tm, err := newMapWithOptions(spec, opts)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating map: %w\", err)\n\t}\n\n\tif err := m.finalize(spec); err != nil {\n\t\tm.Close()\n\t\treturn nil, fmt.Errorf(\"populating map: %w\", err)\n\t}\n\n\treturn m, nil\n}\n\nfunc newMapWithOptions(spec *MapSpec, opts MapOptions) (_ *Map, err error) {\n\tcloseOnError := func(c io.Closer) {\n\t\tif err != nil {\n\t\t\tc.Close()\n\t\t}\n\t}\n\n\tswitch spec.Pinning {\n\tcase PinByName:\n\t\tif spec.Name == \"\" {\n\t\t\treturn nil, fmt.Errorf(\"pin by name: missing Name\")\n\t\t}\n\n\t\tif opts.PinPath == \"\" {\n\t\t\treturn nil, fmt.Errorf(\"pin by name: missing MapOptions.PinPath\")\n\t\t}\n\n\t\tpath := filepath.Join(opts.PinPath, spec.Name)\n\t\tm, err := LoadPinnedMap(path, &opts.LoadPinOptions)\n\t\tif errors.Is(err, unix.ENOENT) {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"load pinned map: %w\", err)\n\t\t}\n\t\tdefer closeOnError(m)\n\n\t\tif err := spec.Compatible(m); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"use pinned map %s: %w\", spec.Name, err)\n\t\t}\n\n\t\treturn m, nil\n\n\tcase PinNone:\n\t\t// Nothing to do here\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"pin type %d: %w\", int(spec.Pinning), ErrNotSupported)\n\t}\n\n\tvar innerFd *sys.FD\n\tif spec.Type == ArrayOfMaps || spec.Type == HashOfMaps {\n\t\tif spec.InnerMap == nil {\n\t\t\treturn nil, fmt.Errorf(\"%s requires InnerMap\", spec.Type)\n\t\t}\n\n\t\tif spec.InnerMap.Pinning != PinNone {\n\t\t\treturn nil, errors.New(\"inner maps cannot be pinned\")\n\t\t}\n\n\t\ttemplate, err := spec.InnerMap.createMap(nil)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"inner map: %w\", err)\n\t\t}\n\t\tdefer template.Close()\n\n\t\t// Intentionally skip populating and freezing (finalizing)\n\t\t// the inner map template since it will be removed shortly.\n\n\t\tinnerFd = template.fd\n\t}\n\n\tm, err := spec.createMap(innerFd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer closeOnError(m)\n\n\tif spec.Pinning == PinByName {\n\t\tpath := filepath.Join(opts.PinPath, spec.Name)\n\t\tif err := m.Pin(path); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"pin map to %s: %w\", path, err)\n\t\t}\n\t}\n\n\treturn m, nil\n}\n\n// Memory returns a memory-mapped region for the Map. The Map must have been\n// created with the BPF_F_MMAPABLE flag. Repeated calls to Memory return the\n// same mapping. Callers are responsible for coordinating access to Memory.\nfunc (m *Map) Memory() (*Memory, error) {\n\tif m.memory != nil {\n\t\treturn m.memory, nil\n\t}\n\n\tif m.flags&sys.BPF_F_MMAPABLE == 0 {\n\t\treturn nil, fmt.Errorf(\"Map was not created with the BPF_F_MMAPABLE flag: %w\", ErrNotSupported)\n\t}\n\n\tsize, err := m.memorySize()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmm, err := newMemory(m.FD(), size)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating new Memory: %w\", err)\n\t}\n\n\tm.memory = mm\n\n\treturn mm, nil\n}\n\nfunc (m *Map) memorySize() (int, error) {\n\tswitch m.Type() {\n\tcase Array:\n\t\t// In Arrays, values are always laid out on 8-byte boundaries regardless of\n\t\t// architecture. Multiply by MaxEntries and align the result to the host's\n\t\t// page size.\n\t\tsize := int(internal.Align(m.ValueSize(), 8) * m.MaxEntries())\n\t\tsize = internal.Align(size, os.Getpagesize())\n\t\treturn size, nil\n\tcase Arena:\n\t\t// For Arenas, MaxEntries denotes the maximum number of pages available to\n\t\t// the arena.\n\t\treturn int(m.MaxEntries()) * os.Getpagesize(), nil\n\t}\n\n\treturn 0, fmt.Errorf(\"determine memory size of map type %s: %w\", m.Type(), ErrNotSupported)\n}\n\n// createMap validates the spec's properties and creates the map in the kernel\n// using the given opts. It does not populate or freeze the map.\nfunc (spec *MapSpec) createMap(inner *sys.FD) (_ *Map, err error) {\n\tcloseOnError := func(closer io.Closer) {\n\t\tif err != nil {\n\t\t\tcloser.Close()\n\t\t}\n\t}\n\n\t// Kernels 4.13 through 5.4 used a struct bpf_map_def that contained\n\t// additional 'inner_map_idx' and later 'numa_node' fields.\n\t// In order to support loading these definitions, tolerate the presence of\n\t// extra bytes, but require them to be zeroes.\n\tif spec.Extra != nil {\n\t\tif _, err := io.Copy(internal.DiscardZeroes{}, spec.Extra); err != nil {\n\t\t\treturn nil, errors.New(\"extra contains unhandled non-zero bytes, drain before creating map\")\n\t\t}\n\t}\n\n\tspec, err = spec.fixupMagicFields()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tattr := sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(spec.Type),\n\t\tKeySize:    spec.KeySize,\n\t\tValueSize:  spec.ValueSize,\n\t\tMaxEntries: spec.MaxEntries,\n\t\tMapFlags:   spec.Flags,\n\t\tNumaNode:   spec.NumaNode,\n\t}\n\n\tif inner != nil {\n\t\tattr.InnerMapFd = inner.Uint()\n\t}\n\n\tif haveObjName() == nil {\n\t\tattr.MapName = sys.NewObjName(spec.Name)\n\t}\n\n\tif spec.Key != nil || spec.Value != nil {\n\t\thandle, keyTypeID, valueTypeID, err := btf.MarshalMapKV(spec.Key, spec.Value)\n\t\tif err != nil && !errors.Is(err, btf.ErrNotSupported) {\n\t\t\treturn nil, fmt.Errorf(\"load BTF: %w\", err)\n\t\t}\n\n\t\tif handle != nil {\n\t\t\tdefer handle.Close()\n\n\t\t\t// Use BTF k/v during map creation.\n\t\t\tattr.BtfFd = uint32(handle.FD())\n\t\t\tattr.BtfKeyTypeId = keyTypeID\n\t\t\tattr.BtfValueTypeId = valueTypeID\n\t\t}\n\t}\n\n\tfd, err := sys.MapCreate(&attr)\n\n\t// Some map types don't support BTF k/v in earlier kernel versions.\n\t// Remove BTF metadata and retry map creation.\n\tif (errors.Is(err, sys.ENOTSUPP) || errors.Is(err, unix.EINVAL)) && attr.BtfFd != 0 {\n\t\tattr.BtfFd, attr.BtfKeyTypeId, attr.BtfValueTypeId = 0, 0, 0\n\t\tfd, err = sys.MapCreate(&attr)\n\t}\n\tif err != nil {\n\t\treturn nil, handleMapCreateError(attr, spec, err)\n\t}\n\n\tdefer closeOnError(fd)\n\tm, err := newMap(fd, spec.Name, spec.Type, spec.KeySize, spec.ValueSize, spec.MaxEntries, spec.Flags)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"map create: %w\", err)\n\t}\n\treturn m, nil\n}\n\nfunc handleMapCreateError(attr sys.MapCreateAttr, spec *MapSpec, err error) error {\n\tif errors.Is(err, unix.EPERM) {\n\t\treturn fmt.Errorf(\"map create: %w (MEMLOCK may be too low, consider rlimit.RemoveMemlock)\", err)\n\t}\n\tif errors.Is(err, unix.EINVAL) && spec.MaxEntries == 0 {\n\t\treturn fmt.Errorf(\"map create: %w (MaxEntries may be incorrectly set to zero)\", err)\n\t}\n\tif errors.Is(err, unix.EINVAL) && spec.Type == UnspecifiedMap {\n\t\treturn fmt.Errorf(\"map create: cannot use type %s\", UnspecifiedMap)\n\t}\n\tif errors.Is(err, unix.EINVAL) && spec.Flags&sys.BPF_F_NO_PREALLOC > 0 {\n\t\treturn fmt.Errorf(\"map create: %w (noPrealloc flag may be incompatible with map type %s)\", err, spec.Type)\n\t}\n\n\tif spec.Type.canStoreMap() {\n\t\tif haveFeatErr := haveNestedMaps(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"map create: %w\", haveFeatErr)\n\t\t}\n\t}\n\n\tif spec.readOnly() || spec.writeOnly() {\n\t\tif haveFeatErr := haveMapMutabilityModifiers(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"map create: %w\", haveFeatErr)\n\t\t}\n\t}\n\tif spec.Flags&sys.BPF_F_MMAPABLE > 0 {\n\t\tif haveFeatErr := haveMmapableMaps(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"map create: %w\", haveFeatErr)\n\t\t}\n\t}\n\tif spec.Flags&sys.BPF_F_INNER_MAP > 0 {\n\t\tif haveFeatErr := haveInnerMaps(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"map create: %w\", haveFeatErr)\n\t\t}\n\t}\n\tif spec.Flags&sys.BPF_F_NO_PREALLOC > 0 {\n\t\tif haveFeatErr := haveNoPreallocMaps(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"map create: %w\", haveFeatErr)\n\t\t}\n\t}\n\t// BPF_MAP_TYPE_RINGBUF's max_entries must be a power-of-2 multiple of kernel's page size.\n\tif errors.Is(err, unix.EINVAL) &&\n\t\t(attr.MapType == sys.BPF_MAP_TYPE_RINGBUF || attr.MapType == sys.BPF_MAP_TYPE_USER_RINGBUF) {\n\t\tpageSize := uint32(os.Getpagesize())\n\t\tmaxEntries := attr.MaxEntries\n\t\tif maxEntries%pageSize != 0 || !internal.IsPow(maxEntries) {\n\t\t\treturn fmt.Errorf(\"map create: %w (ring map size %d not a multiple of page size %d)\", err, maxEntries, pageSize)\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"map create: %w\", err)\n}\n\n// newMap allocates and returns a new Map structure.\n// Sets the fullValueSize on per-CPU maps.\nfunc newMap(fd *sys.FD, name string, typ MapType, keySize, valueSize, maxEntries, flags uint32) (*Map, error) {\n\tm := &Map{\n\t\tname,\n\t\tfd,\n\t\ttyp,\n\t\tkeySize,\n\t\tvalueSize,\n\t\tmaxEntries,\n\t\tflags,\n\t\t\"\",\n\t\tint(valueSize),\n\t\tnil,\n\t}\n\n\tif !typ.hasPerCPUValue() {\n\t\treturn m, nil\n\t}\n\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tm.fullValueSize = int(internal.Align(valueSize, 8)) * possibleCPUs\n\treturn m, nil\n}\n\nfunc (m *Map) String() string {\n\tif m.name != \"\" {\n\t\treturn fmt.Sprintf(\"%s(%s)#%v\", m.typ, m.name, m.fd)\n\t}\n\treturn fmt.Sprintf(\"%s#%v\", m.typ, m.fd)\n}\n\n// Type returns the underlying type of the map.\nfunc (m *Map) Type() MapType {\n\treturn m.typ\n}\n\n// KeySize returns the size of the map key in bytes.\nfunc (m *Map) KeySize() uint32 {\n\treturn m.keySize\n}\n\n// ValueSize returns the size of the map value in bytes.\nfunc (m *Map) ValueSize() uint32 {\n\treturn m.valueSize\n}\n\n// MaxEntries returns the maximum number of elements the map can hold.\nfunc (m *Map) MaxEntries() uint32 {\n\treturn m.maxEntries\n}\n\n// Flags returns the flags of the map.\nfunc (m *Map) Flags() uint32 {\n\treturn m.flags\n}\n\n// Info returns metadata about the map. This was first introduced in Linux 4.5,\n// but newer kernels support more MapInfo fields with the introduction of more\n// features. See [MapInfo] and its methods for more details.\n//\n// Returns an error wrapping ErrNotSupported if the kernel supports neither\n// BPF_OBJ_GET_INFO_BY_FD nor reading map information from /proc/self/fdinfo.\nfunc (m *Map) Info() (*MapInfo, error) {\n\treturn newMapInfoFromFd(m.fd)\n}\n\n// Handle returns a reference to the Map's type information in the kernel.\n//\n// Returns ErrNotSupported if the kernel has no BTF support, or if there is no\n// BTF associated with the Map.\nfunc (m *Map) Handle() (*btf.Handle, error) {\n\tinfo, err := m.Info()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tid, ok := info.BTFID()\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"map %s: retrieve BTF ID: %w\", m, ErrNotSupported)\n\t}\n\n\treturn btf.NewHandleFromID(id)\n}\n\n// MapLookupFlags controls the behaviour of the map lookup calls.\ntype MapLookupFlags uint64\n\n// LookupLock look up the value of a spin-locked map.\nconst LookupLock MapLookupFlags = sys.BPF_F_LOCK\n\n// Lookup retrieves a value from a Map.\n//\n// Calls Close() on valueOut if it is of type **Map or **Program,\n// and *valueOut is not nil.\n//\n// Returns an error if the key doesn't exist, see ErrKeyNotExist.\nfunc (m *Map) Lookup(key, valueOut interface{}) error {\n\treturn m.LookupWithFlags(key, valueOut, 0)\n}\n\n// LookupWithFlags retrieves a value from a Map with flags.\n//\n// Passing LookupLock flag will look up the value of a spin-locked\n// map without returning the lock. This must be specified if the\n// elements contain a spinlock.\n//\n// Calls Close() on valueOut if it is of type **Map or **Program,\n// and *valueOut is not nil.\n//\n// Returns an error if the key doesn't exist, see ErrKeyNotExist.\nfunc (m *Map) LookupWithFlags(key, valueOut interface{}, flags MapLookupFlags) error {\n\tif m.typ.hasPerCPUValue() {\n\t\treturn m.lookupPerCPU(key, valueOut, flags)\n\t}\n\n\tvalueBytes := makeMapSyscallOutput(valueOut, m.fullValueSize)\n\tif err := m.lookup(key, valueBytes.Pointer(), flags); err != nil {\n\t\treturn err\n\t}\n\n\treturn m.unmarshalValue(valueOut, valueBytes)\n}\n\n// LookupAndDelete retrieves and deletes a value from a Map.\n//\n// Returns ErrKeyNotExist if the key doesn't exist.\nfunc (m *Map) LookupAndDelete(key, valueOut interface{}) error {\n\treturn m.LookupAndDeleteWithFlags(key, valueOut, 0)\n}\n\n// LookupAndDeleteWithFlags retrieves and deletes a value from a Map.\n//\n// Passing LookupLock flag will look up and delete the value of a spin-locked\n// map without returning the lock. This must be specified if the elements\n// contain a spinlock.\n//\n// Returns ErrKeyNotExist if the key doesn't exist.\nfunc (m *Map) LookupAndDeleteWithFlags(key, valueOut interface{}, flags MapLookupFlags) error {\n\tif m.typ.hasPerCPUValue() {\n\t\treturn m.lookupAndDeletePerCPU(key, valueOut, flags)\n\t}\n\n\tvalueBytes := makeMapSyscallOutput(valueOut, m.fullValueSize)\n\tif err := m.lookupAndDelete(key, valueBytes.Pointer(), flags); err != nil {\n\t\treturn err\n\t}\n\treturn m.unmarshalValue(valueOut, valueBytes)\n}\n\n// LookupBytes gets a value from Map.\n//\n// Returns a nil value if a key doesn't exist.\nfunc (m *Map) LookupBytes(key interface{}) ([]byte, error) {\n\tvalueBytes := make([]byte, m.fullValueSize)\n\tvaluePtr := sys.NewSlicePointer(valueBytes)\n\n\terr := m.lookup(key, valuePtr, 0)\n\tif errors.Is(err, ErrKeyNotExist) {\n\t\treturn nil, nil\n\t}\n\n\treturn valueBytes, err\n}\n\nfunc (m *Map) lookupPerCPU(key, valueOut any, flags MapLookupFlags) error {\n\tslice, err := ensurePerCPUSlice(valueOut)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvalueBytes := make([]byte, m.fullValueSize)\n\tif err := m.lookup(key, sys.NewSlicePointer(valueBytes), flags); err != nil {\n\t\treturn err\n\t}\n\treturn unmarshalPerCPUValue(slice, int(m.valueSize), valueBytes)\n}\n\nfunc (m *Map) lookup(key interface{}, valueOut sys.Pointer, flags MapLookupFlags) error {\n\tkeyPtr, err := m.marshalKey(key)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't marshal key: %w\", err)\n\t}\n\n\tattr := sys.MapLookupElemAttr{\n\t\tMapFd: m.fd.Uint(),\n\t\tKey:   keyPtr,\n\t\tValue: valueOut,\n\t\tFlags: uint64(flags),\n\t}\n\n\tif err = sys.MapLookupElem(&attr); err != nil {\n\t\tif errors.Is(err, unix.ENOENT) {\n\t\t\treturn errMapLookupKeyNotExist\n\t\t}\n\t\treturn fmt.Errorf(\"lookup: %w\", wrapMapError(err))\n\t}\n\treturn nil\n}\n\nfunc (m *Map) lookupAndDeletePerCPU(key, valueOut any, flags MapLookupFlags) error {\n\tslice, err := ensurePerCPUSlice(valueOut)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvalueBytes := make([]byte, m.fullValueSize)\n\tif err := m.lookupAndDelete(key, sys.NewSlicePointer(valueBytes), flags); err != nil {\n\t\treturn err\n\t}\n\treturn unmarshalPerCPUValue(slice, int(m.valueSize), valueBytes)\n}\n\n// ensurePerCPUSlice allocates a slice for a per-CPU value if necessary.\nfunc ensurePerCPUSlice(sliceOrPtr any) (any, error) {\n\tsliceOrPtrType := reflect.TypeOf(sliceOrPtr)\n\tif sliceOrPtrType.Kind() == reflect.Slice {\n\t\t// The target is a slice, the caller is responsible for ensuring that\n\t\t// size is correct.\n\t\treturn sliceOrPtr, nil\n\t}\n\n\tslicePtrType := sliceOrPtrType\n\tif slicePtrType.Kind() != reflect.Ptr || slicePtrType.Elem().Kind() != reflect.Slice {\n\t\treturn nil, fmt.Errorf(\"per-cpu value requires a slice or a pointer to slice\")\n\t}\n\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsliceType := slicePtrType.Elem()\n\tslice := reflect.MakeSlice(sliceType, possibleCPUs, possibleCPUs)\n\n\tsliceElemType := sliceType.Elem()\n\tsliceElemIsPointer := sliceElemType.Kind() == reflect.Ptr\n\treflect.ValueOf(sliceOrPtr).Elem().Set(slice)\n\tif !sliceElemIsPointer {\n\t\treturn slice.Interface(), nil\n\t}\n\tsliceElemType = sliceElemType.Elem()\n\n\tfor i := 0; i < possibleCPUs; i++ {\n\t\tnewElem := reflect.New(sliceElemType)\n\t\tslice.Index(i).Set(newElem)\n\t}\n\n\treturn slice.Interface(), nil\n}\n\nfunc (m *Map) lookupAndDelete(key any, valuePtr sys.Pointer, flags MapLookupFlags) error {\n\tkeyPtr, err := m.marshalKey(key)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't marshal key: %w\", err)\n\t}\n\n\tattr := sys.MapLookupAndDeleteElemAttr{\n\t\tMapFd: m.fd.Uint(),\n\t\tKey:   keyPtr,\n\t\tValue: valuePtr,\n\t\tFlags: uint64(flags),\n\t}\n\n\tif err := sys.MapLookupAndDeleteElem(&attr); err != nil {\n\t\treturn fmt.Errorf(\"lookup and delete: %w\", wrapMapError(err))\n\t}\n\n\treturn nil\n}\n\n// MapUpdateFlags controls the behaviour of the Map.Update call.\n//\n// The exact semantics depend on the specific MapType.\ntype MapUpdateFlags uint64\n\nconst (\n\t// UpdateAny creates a new element or update an existing one.\n\tUpdateAny MapUpdateFlags = iota\n\t// UpdateNoExist creates a new element.\n\tUpdateNoExist MapUpdateFlags = 1 << (iota - 1)\n\t// UpdateExist updates an existing element.\n\tUpdateExist\n\t// UpdateLock updates elements under bpf_spin_lock.\n\tUpdateLock\n)\n\n// Put replaces or creates a value in map.\n//\n// It is equivalent to calling Update with UpdateAny.\nfunc (m *Map) Put(key, value interface{}) error {\n\treturn m.Update(key, value, UpdateAny)\n}\n\n// Update changes the value of a key.\nfunc (m *Map) Update(key, value any, flags MapUpdateFlags) error {\n\tif m.typ.hasPerCPUValue() {\n\t\treturn m.updatePerCPU(key, value, flags)\n\t}\n\n\tvaluePtr, err := m.marshalValue(value)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshal value: %w\", err)\n\t}\n\n\treturn m.update(key, valuePtr, flags)\n}\n\nfunc (m *Map) updatePerCPU(key, value any, flags MapUpdateFlags) error {\n\tvaluePtr, err := marshalPerCPUValue(value, int(m.valueSize))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshal value: %w\", err)\n\t}\n\n\treturn m.update(key, valuePtr, flags)\n}\n\nfunc (m *Map) update(key any, valuePtr sys.Pointer, flags MapUpdateFlags) error {\n\tkeyPtr, err := m.marshalKey(key)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshal key: %w\", err)\n\t}\n\n\tattr := sys.MapUpdateElemAttr{\n\t\tMapFd: m.fd.Uint(),\n\t\tKey:   keyPtr,\n\t\tValue: valuePtr,\n\t\tFlags: uint64(flags),\n\t}\n\n\tif err = sys.MapUpdateElem(&attr); err != nil {\n\t\treturn fmt.Errorf(\"update: %w\", wrapMapError(err))\n\t}\n\n\treturn nil\n}\n\n// Delete removes a value.\n//\n// Returns ErrKeyNotExist if the key does not exist.\nfunc (m *Map) Delete(key interface{}) error {\n\tkeyPtr, err := m.marshalKey(key)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't marshal key: %w\", err)\n\t}\n\n\tattr := sys.MapDeleteElemAttr{\n\t\tMapFd: m.fd.Uint(),\n\t\tKey:   keyPtr,\n\t}\n\n\tif err = sys.MapDeleteElem(&attr); err != nil {\n\t\treturn fmt.Errorf(\"delete: %w\", wrapMapError(err))\n\t}\n\treturn nil\n}\n\n// NextKey finds the key following an initial key.\n//\n// See NextKeyBytes for details.\n//\n// Returns ErrKeyNotExist if there is no next key.\nfunc (m *Map) NextKey(key, nextKeyOut interface{}) error {\n\tnextKeyBytes := makeMapSyscallOutput(nextKeyOut, int(m.keySize))\n\n\tif err := m.nextKey(key, nextKeyBytes.Pointer()); err != nil {\n\t\treturn err\n\t}\n\n\tif err := nextKeyBytes.Unmarshal(nextKeyOut); err != nil {\n\t\treturn fmt.Errorf(\"can't unmarshal next key: %w\", err)\n\t}\n\treturn nil\n}\n\n// NextKeyBytes returns the key following an initial key as a byte slice.\n//\n// Passing nil will return the first key.\n//\n// Use Iterate if you want to traverse all entries in the map.\n//\n// Returns nil if there are no more keys.\nfunc (m *Map) NextKeyBytes(key interface{}) ([]byte, error) {\n\tnextKey := make([]byte, m.keySize)\n\tnextKeyPtr := sys.NewSlicePointer(nextKey)\n\n\terr := m.nextKey(key, nextKeyPtr)\n\tif errors.Is(err, ErrKeyNotExist) {\n\t\treturn nil, nil\n\t}\n\n\treturn nextKey, err\n}\n\nfunc (m *Map) nextKey(key interface{}, nextKeyOut sys.Pointer) error {\n\tvar (\n\t\tkeyPtr sys.Pointer\n\t\terr    error\n\t)\n\n\tif key != nil {\n\t\tkeyPtr, err = m.marshalKey(key)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"can't marshal key: %w\", err)\n\t\t}\n\t}\n\n\tattr := sys.MapGetNextKeyAttr{\n\t\tMapFd:   m.fd.Uint(),\n\t\tKey:     keyPtr,\n\t\tNextKey: nextKeyOut,\n\t}\n\n\tif err = sys.MapGetNextKey(&attr); err != nil {\n\t\t// Kernels 4.4.131 and earlier return EFAULT instead of a pointer to the\n\t\t// first map element when a nil key pointer is specified.\n\t\tif key == nil && errors.Is(err, unix.EFAULT) {\n\t\t\tvar guessKey []byte\n\t\t\tguessKey, err = m.guessNonExistentKey()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Retry the syscall with a valid non-existing key.\n\t\t\tattr.Key = sys.NewSlicePointer(guessKey)\n\t\t\tif err = sys.MapGetNextKey(&attr); err == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\n\t\treturn fmt.Errorf(\"next key: %w\", wrapMapError(err))\n\t}\n\n\treturn nil\n}\n\nvar mmapProtectedPage = sync.OnceValues(func() ([]byte, error) {\n\treturn unix.Mmap(-1, 0, os.Getpagesize(), unix.PROT_NONE, unix.MAP_ANON|unix.MAP_SHARED)\n})\n\n// guessNonExistentKey attempts to perform a map lookup that returns ENOENT.\n// This is necessary on kernels before 4.4.132, since those don't support\n// iterating maps from the start by providing an invalid key pointer.\nfunc (m *Map) guessNonExistentKey() ([]byte, error) {\n\t// Map a protected page and use that as the value pointer. This saves some\n\t// work copying out the value, which we're not interested in.\n\tpage, err := mmapProtectedPage()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvaluePtr := sys.NewSlicePointer(page)\n\n\trandKey := make([]byte, int(m.keySize))\n\n\tfor i := 0; i < 4; i++ {\n\t\tswitch i {\n\t\t// For hash maps, the 0 key is less likely to be occupied. They're often\n\t\t// used for storing data related to pointers, and their access pattern is\n\t\t// generally scattered across the keyspace.\n\t\tcase 0:\n\t\t// An all-0xff key is guaranteed to be out of bounds of any array, since\n\t\t// those have a fixed key size of 4 bytes. The only corner case being\n\t\t// arrays with 2^32 max entries, but those are prohibitively expensive\n\t\t// in many environments.\n\t\tcase 1:\n\t\t\tfor r := range randKey {\n\t\t\t\trandKey[r] = 0xff\n\t\t\t}\n\t\t// Inspired by BCC, 0x55 is an alternating binary pattern (0101), so\n\t\t// is unlikely to be taken.\n\t\tcase 2:\n\t\t\tfor r := range randKey {\n\t\t\t\trandKey[r] = 0x55\n\t\t\t}\n\t\t// Last ditch effort, generate a random key.\n\t\tcase 3:\n\t\t\trand.New(rand.NewSource(time.Now().UnixNano())).Read(randKey)\n\t\t}\n\n\t\terr := m.lookup(randKey, valuePtr, 0)\n\t\tif errors.Is(err, ErrKeyNotExist) {\n\t\t\treturn randKey, nil\n\t\t}\n\t}\n\n\treturn nil, errors.New(\"couldn't find non-existing key\")\n}\n\n// BatchLookup looks up many elements in a map at once.\n//\n// \"keysOut\" and \"valuesOut\" must be of type slice, a pointer\n// to a slice or buffer will not work.\n// \"cursor\" is an pointer to an opaque handle. It must be non-nil. Pass\n// \"cursor\" to subsequent calls of this function to continue the batching\n// operation in the case of chunking.\n//\n// Warning: This API is not very safe to use as the kernel implementation for\n// batching relies on the user to be aware of subtle details with regarding to\n// different map type implementations.\n//\n// ErrKeyNotExist is returned when the batch lookup has reached\n// the end of all possible results, even when partial results\n// are returned. It should be used to evaluate when lookup is \"done\".\nfunc (m *Map) BatchLookup(cursor *MapBatchCursor, keysOut, valuesOut interface{}, opts *BatchOptions) (int, error) {\n\tn, err := m.batchLookup(sys.BPF_MAP_LOOKUP_BATCH, cursor, keysOut, valuesOut, opts)\n\tif err != nil {\n\t\treturn n, fmt.Errorf(\"map batch lookup: %w\", err)\n\t}\n\treturn n, nil\n}\n\n// BatchLookupAndDelete looks up many elements in a map at once,\n//\n// It then deletes all those elements.\n// \"keysOut\" and \"valuesOut\" must be of type slice, a pointer\n// to a slice or buffer will not work.\n// \"cursor\" is an pointer to an opaque handle. It must be non-nil. Pass\n// \"cursor\" to subsequent calls of this function to continue the batching\n// operation in the case of chunking.\n//\n// Warning: This API is not very safe to use as the kernel implementation for\n// batching relies on the user to be aware of subtle details with regarding to\n// different map type implementations.\n//\n// ErrKeyNotExist is returned when the batch lookup has reached\n// the end of all possible results, even when partial results\n// are returned. It should be used to evaluate when lookup is \"done\".\nfunc (m *Map) BatchLookupAndDelete(cursor *MapBatchCursor, keysOut, valuesOut interface{}, opts *BatchOptions) (int, error) {\n\tn, err := m.batchLookup(sys.BPF_MAP_LOOKUP_AND_DELETE_BATCH, cursor, keysOut, valuesOut, opts)\n\tif err != nil {\n\t\treturn n, fmt.Errorf(\"map batch lookup and delete: %w\", err)\n\t}\n\treturn n, nil\n}\n\n// MapBatchCursor represents a starting point for a batch operation.\ntype MapBatchCursor struct {\n\tm      *Map\n\topaque []byte\n}\n\nfunc (m *Map) batchLookup(cmd sys.Cmd, cursor *MapBatchCursor, keysOut, valuesOut interface{}, opts *BatchOptions) (int, error) {\n\tif m.typ.hasPerCPUValue() {\n\t\treturn m.batchLookupPerCPU(cmd, cursor, keysOut, valuesOut, opts)\n\t}\n\n\tcount, err := batchCount(keysOut, valuesOut)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tvalueBuf := sysenc.SyscallOutput(valuesOut, count*int(m.fullValueSize))\n\n\tn, err := m.batchLookupCmd(cmd, cursor, count, keysOut, valueBuf.Pointer(), opts)\n\tif errors.Is(err, unix.ENOSPC) {\n\t\t// Hash tables return ENOSPC when the size of the batch is smaller than\n\t\t// any bucket.\n\t\treturn n, fmt.Errorf(\"%w (batch size too small?)\", err)\n\t} else if err != nil {\n\t\treturn n, err\n\t}\n\n\terr = valueBuf.Unmarshal(valuesOut)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn n, nil\n}\n\nfunc (m *Map) batchLookupPerCPU(cmd sys.Cmd, cursor *MapBatchCursor, keysOut, valuesOut interface{}, opts *BatchOptions) (int, error) {\n\tcount, err := sliceLen(keysOut)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"keys: %w\", err)\n\t}\n\n\tvalueBuf := make([]byte, count*int(m.fullValueSize))\n\tvaluePtr := sys.NewSlicePointer(valueBuf)\n\n\tn, sysErr := m.batchLookupCmd(cmd, cursor, count, keysOut, valuePtr, opts)\n\tif sysErr != nil && !errors.Is(sysErr, unix.ENOENT) {\n\t\treturn 0, err\n\t}\n\n\terr = unmarshalBatchPerCPUValue(valuesOut, count, int(m.valueSize), valueBuf)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn n, sysErr\n}\n\nfunc (m *Map) batchLookupCmd(cmd sys.Cmd, cursor *MapBatchCursor, count int, keysOut any, valuePtr sys.Pointer, opts *BatchOptions) (int, error) {\n\tcursorLen := int(m.keySize)\n\tif cursorLen < 4 {\n\t\t// * generic_map_lookup_batch requires that batch_out is key_size bytes.\n\t\t//   This is used by array and LPM maps.\n\t\t//\n\t\t// * __htab_map_lookup_and_delete_batch requires u32. This is used by the\n\t\t//   various hash maps.\n\t\t//\n\t\t// Use a minimum of 4 bytes to avoid having to distinguish between the two.\n\t\tcursorLen = 4\n\t}\n\n\tinBatch := cursor.opaque\n\tif inBatch == nil {\n\t\t// This is the first lookup, allocate a buffer to hold the cursor.\n\t\tcursor.opaque = make([]byte, cursorLen)\n\t\tcursor.m = m\n\t} else if cursor.m != m {\n\t\t// Prevent reuse of a cursor across maps. First, it's unlikely to work.\n\t\t// Second, the maps may require different cursorLen and cursor.opaque\n\t\t// may therefore be too short. This could lead to the kernel clobbering\n\t\t// user space memory.\n\t\treturn 0, errors.New(\"a cursor may not be reused across maps\")\n\t}\n\n\tif err := haveBatchAPI(); err != nil {\n\t\treturn 0, err\n\t}\n\n\tkeyBuf := sysenc.SyscallOutput(keysOut, count*int(m.keySize))\n\n\tattr := sys.MapLookupBatchAttr{\n\t\tMapFd:    m.fd.Uint(),\n\t\tKeys:     keyBuf.Pointer(),\n\t\tValues:   valuePtr,\n\t\tCount:    uint32(count),\n\t\tInBatch:  sys.NewSlicePointer(inBatch),\n\t\tOutBatch: sys.NewSlicePointer(cursor.opaque),\n\t}\n\n\tif opts != nil {\n\t\tattr.ElemFlags = opts.ElemFlags\n\t\tattr.Flags = opts.Flags\n\t}\n\n\t_, sysErr := sys.BPF(cmd, unsafe.Pointer(&attr), unsafe.Sizeof(attr))\n\tsysErr = wrapMapError(sysErr)\n\tif sysErr != nil && !errors.Is(sysErr, unix.ENOENT) {\n\t\treturn 0, sysErr\n\t}\n\n\tif err := keyBuf.Unmarshal(keysOut); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn int(attr.Count), sysErr\n}\n\n// BatchUpdate updates the map with multiple keys and values\n// simultaneously.\n// \"keys\" and \"values\" must be of type slice, a pointer\n// to a slice or buffer will not work.\nfunc (m *Map) BatchUpdate(keys, values interface{}, opts *BatchOptions) (int, error) {\n\tif m.typ.hasPerCPUValue() {\n\t\treturn m.batchUpdatePerCPU(keys, values, opts)\n\t}\n\n\tcount, err := batchCount(keys, values)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tvaluePtr, err := marshalMapSyscallInput(values, count*int(m.valueSize))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn m.batchUpdate(count, keys, valuePtr, opts)\n}\n\nfunc (m *Map) batchUpdate(count int, keys any, valuePtr sys.Pointer, opts *BatchOptions) (int, error) {\n\tkeyPtr, err := marshalMapSyscallInput(keys, count*int(m.keySize))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tattr := sys.MapUpdateBatchAttr{\n\t\tMapFd:  m.fd.Uint(),\n\t\tKeys:   keyPtr,\n\t\tValues: valuePtr,\n\t\tCount:  uint32(count),\n\t}\n\tif opts != nil {\n\t\tattr.ElemFlags = opts.ElemFlags\n\t\tattr.Flags = opts.Flags\n\t}\n\n\terr = sys.MapUpdateBatch(&attr)\n\tif err != nil {\n\t\tif haveFeatErr := haveBatchAPI(); haveFeatErr != nil {\n\t\t\treturn 0, haveFeatErr\n\t\t}\n\t\treturn int(attr.Count), fmt.Errorf(\"batch update: %w\", wrapMapError(err))\n\t}\n\n\treturn int(attr.Count), nil\n}\n\nfunc (m *Map) batchUpdatePerCPU(keys, values any, opts *BatchOptions) (int, error) {\n\tcount, err := sliceLen(keys)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"keys: %w\", err)\n\t}\n\n\tvalueBuf, err := marshalBatchPerCPUValue(values, count, int(m.valueSize))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn m.batchUpdate(count, keys, sys.NewSlicePointer(valueBuf), opts)\n}\n\n// BatchDelete batch deletes entries in the map by keys.\n// \"keys\" must be of type slice, a pointer to a slice or buffer will not work.\nfunc (m *Map) BatchDelete(keys interface{}, opts *BatchOptions) (int, error) {\n\tcount, err := sliceLen(keys)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"keys: %w\", err)\n\t}\n\n\tkeyPtr, err := marshalMapSyscallInput(keys, count*int(m.keySize))\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"cannot marshal keys: %v\", err)\n\t}\n\n\tattr := sys.MapDeleteBatchAttr{\n\t\tMapFd: m.fd.Uint(),\n\t\tKeys:  keyPtr,\n\t\tCount: uint32(count),\n\t}\n\n\tif opts != nil {\n\t\tattr.ElemFlags = opts.ElemFlags\n\t\tattr.Flags = opts.Flags\n\t}\n\n\tif err = sys.MapDeleteBatch(&attr); err != nil {\n\t\tif haveFeatErr := haveBatchAPI(); haveFeatErr != nil {\n\t\t\treturn 0, haveFeatErr\n\t\t}\n\t\treturn int(attr.Count), fmt.Errorf(\"batch delete: %w\", wrapMapError(err))\n\t}\n\n\treturn int(attr.Count), nil\n}\n\nfunc batchCount(keys, values any) (int, error) {\n\tkeysLen, err := sliceLen(keys)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"keys: %w\", err)\n\t}\n\n\tvaluesLen, err := sliceLen(values)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"values: %w\", err)\n\t}\n\n\tif keysLen != valuesLen {\n\t\treturn 0, fmt.Errorf(\"keys and values must have the same length\")\n\t}\n\n\treturn keysLen, nil\n}\n\n// Iterate traverses a map.\n//\n// It's safe to create multiple iterators at the same time.\n//\n// It's not possible to guarantee that all keys in a map will be\n// returned if there are concurrent modifications to the map.\nfunc (m *Map) Iterate() *MapIterator {\n\treturn newMapIterator(m)\n}\n\n// Close the Map's underlying file descriptor, which could unload the\n// Map from the kernel if it is not pinned or in use by a loaded Program.\nfunc (m *Map) Close() error {\n\tif m == nil {\n\t\t// This makes it easier to clean up when iterating maps\n\t\t// of maps / programs.\n\t\treturn nil\n\t}\n\n\treturn m.fd.Close()\n}\n\n// FD gets the file descriptor of the Map.\n//\n// Calling this function is invalid after Close has been called.\nfunc (m *Map) FD() int {\n\treturn m.fd.Int()\n}\n\n// Clone creates a duplicate of the Map.\n//\n// Closing the duplicate does not affect the original, and vice versa.\n// Changes made to the map are reflected by both instances however.\n// If the original map was pinned, the cloned map will not be pinned by default.\n//\n// Cloning a nil Map returns nil.\nfunc (m *Map) Clone() (*Map, error) {\n\tif m == nil {\n\t\treturn nil, nil\n\t}\n\n\tdup, err := m.fd.Dup()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"can't clone map: %w\", err)\n\t}\n\n\treturn &Map{\n\t\tm.name,\n\t\tdup,\n\t\tm.typ,\n\t\tm.keySize,\n\t\tm.valueSize,\n\t\tm.maxEntries,\n\t\tm.flags,\n\t\t\"\",\n\t\tm.fullValueSize,\n\t\tnil,\n\t}, nil\n}\n\n// Pin persists the map on the BPF virtual file system past the lifetime of\n// the process that created it .\n//\n// Calling Pin on a previously pinned map will overwrite the path, except when\n// the new path already exists. Re-pinning across filesystems is not supported.\n// You can Clone a map to pin it to a different path.\n//\n// This requires bpffs to be mounted above fileName.\n// See https://docs.cilium.io/en/stable/network/kubernetes/configuration/#mounting-bpffs-with-systemd\nfunc (m *Map) Pin(fileName string) error {\n\tif err := sys.Pin(m.pinnedPath, fileName, m.fd); err != nil {\n\t\treturn err\n\t}\n\tm.pinnedPath = fileName\n\treturn nil\n}\n\n// Unpin removes the persisted state for the map from the BPF virtual filesystem.\n//\n// Failed calls to Unpin will not alter the state returned by IsPinned.\n//\n// Unpinning an unpinned Map returns nil.\nfunc (m *Map) Unpin() error {\n\tif err := sys.Unpin(m.pinnedPath); err != nil {\n\t\treturn err\n\t}\n\tm.pinnedPath = \"\"\n\treturn nil\n}\n\n// IsPinned returns true if the map has a non-empty pinned path.\nfunc (m *Map) IsPinned() bool {\n\treturn m.pinnedPath != \"\"\n}\n\n// Freeze prevents a map to be modified from user space.\n//\n// It makes no changes to kernel-side restrictions.\nfunc (m *Map) Freeze() error {\n\tattr := sys.MapFreezeAttr{\n\t\tMapFd: m.fd.Uint(),\n\t}\n\n\tif err := sys.MapFreeze(&attr); err != nil {\n\t\tif haveFeatErr := haveMapMutabilityModifiers(); haveFeatErr != nil {\n\t\t\treturn fmt.Errorf(\"can't freeze map: %w\", haveFeatErr)\n\t\t}\n\t\treturn fmt.Errorf(\"can't freeze map: %w\", err)\n\t}\n\treturn nil\n}\n\n// finalize populates the Map according to the Contents specified\n// in spec and freezes the Map if requested by spec.\nfunc (m *Map) finalize(spec *MapSpec) error {\n\tfor _, kv := range spec.Contents {\n\t\tif err := m.Put(kv.Key, kv.Value); err != nil {\n\t\t\treturn fmt.Errorf(\"putting value: key %v: %w\", kv.Key, err)\n\t\t}\n\t}\n\n\tif isConstantDataSection(spec.Name) || isKconfigSection(spec.Name) {\n\t\tif err := m.Freeze(); err != nil {\n\t\t\treturn fmt.Errorf(\"freezing map: %w\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (m *Map) marshalKey(data interface{}) (sys.Pointer, error) {\n\tif data == nil {\n\t\tif m.keySize == 0 {\n\t\t\t// Queues have a key length of zero, so passing nil here is valid.\n\t\t\treturn sys.NewPointer(nil), nil\n\t\t}\n\t\treturn sys.Pointer{}, errors.New(\"can't use nil as key of map\")\n\t}\n\n\treturn marshalMapSyscallInput(data, int(m.keySize))\n}\n\nfunc (m *Map) marshalValue(data interface{}) (sys.Pointer, error) {\n\tvar (\n\t\tbuf []byte\n\t\terr error\n\t)\n\n\tswitch value := data.(type) {\n\tcase *Map:\n\t\tif !m.typ.canStoreMap() {\n\t\t\treturn sys.Pointer{}, fmt.Errorf(\"can't store map in %s\", m.typ)\n\t\t}\n\t\tbuf, err = marshalMap(value, int(m.valueSize))\n\n\tcase *Program:\n\t\tif !m.typ.canStoreProgram() {\n\t\t\treturn sys.Pointer{}, fmt.Errorf(\"can't store program in %s\", m.typ)\n\t\t}\n\t\tbuf, err = marshalProgram(value, int(m.valueSize))\n\n\tdefault:\n\t\treturn marshalMapSyscallInput(data, int(m.valueSize))\n\t}\n\n\tif err != nil {\n\t\treturn sys.Pointer{}, err\n\t}\n\n\treturn sys.NewSlicePointer(buf), nil\n}\n\nfunc (m *Map) unmarshalValue(value any, buf sysenc.Buffer) error {\n\tswitch value := value.(type) {\n\tcase **Map:\n\t\tif !m.typ.canStoreMap() {\n\t\t\treturn fmt.Errorf(\"can't read a map from %s\", m.typ)\n\t\t}\n\n\t\tother, err := unmarshalMap(buf)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// The caller might close the map externally, so ignore errors.\n\t\t_ = (*value).Close()\n\n\t\t*value = other\n\t\treturn nil\n\n\tcase *Map:\n\t\tif !m.typ.canStoreMap() {\n\t\t\treturn fmt.Errorf(\"can't read a map from %s\", m.typ)\n\t\t}\n\t\treturn errors.New(\"require pointer to *Map\")\n\n\tcase **Program:\n\t\tif !m.typ.canStoreProgram() {\n\t\t\treturn fmt.Errorf(\"can't read a program from %s\", m.typ)\n\t\t}\n\n\t\tother, err := unmarshalProgram(buf)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// The caller might close the program externally, so ignore errors.\n\t\t_ = (*value).Close()\n\n\t\t*value = other\n\t\treturn nil\n\n\tcase *Program:\n\t\tif !m.typ.canStoreProgram() {\n\t\t\treturn fmt.Errorf(\"can't read a program from %s\", m.typ)\n\t\t}\n\t\treturn errors.New(\"require pointer to *Program\")\n\t}\n\n\treturn buf.Unmarshal(value)\n}\n\n// LoadPinnedMap opens a Map from a pin (file) on the BPF virtual filesystem.\n//\n// Requires at least Linux 4.5.\nfunc LoadPinnedMap(fileName string, opts *LoadPinOptions) (*Map, error) {\n\tfd, typ, err := sys.ObjGetTyped(&sys.ObjGetAttr{\n\t\tPathname:  sys.NewStringPointer(fileName),\n\t\tFileFlags: opts.Marshal(),\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif typ != sys.BPF_TYPE_MAP {\n\t\t_ = fd.Close()\n\t\treturn nil, fmt.Errorf(\"%s is not a Map\", fileName)\n\t}\n\n\tm, err := newMapFromFD(fd)\n\tif err == nil {\n\t\tm.pinnedPath = fileName\n\t}\n\n\treturn m, err\n}\n\n// unmarshalMap creates a map from a map ID encoded in host endianness.\nfunc unmarshalMap(buf sysenc.Buffer) (*Map, error) {\n\tvar id uint32\n\tif err := buf.Unmarshal(&id); err != nil {\n\t\treturn nil, err\n\t}\n\treturn NewMapFromID(MapID(id))\n}\n\n// marshalMap marshals the fd of a map into a buffer in host endianness.\nfunc marshalMap(m *Map, length int) ([]byte, error) {\n\tif m == nil {\n\t\treturn nil, errors.New(\"can't marshal a nil Map\")\n\t}\n\n\tif length != 4 {\n\t\treturn nil, fmt.Errorf(\"can't marshal map to %d bytes\", length)\n\t}\n\n\tbuf := make([]byte, 4)\n\tinternal.NativeEndian.PutUint32(buf, m.fd.Uint())\n\treturn buf, nil\n}\n\n// MapIterator iterates a Map.\n//\n// See Map.Iterate.\ntype MapIterator struct {\n\ttarget *Map\n\t// Temporary storage to avoid allocations in Next(). This is any instead\n\t// of []byte to avoid allocations.\n\tcursor            any\n\tcount, maxEntries uint32\n\tdone              bool\n\terr               error\n}\n\nfunc newMapIterator(target *Map) *MapIterator {\n\treturn &MapIterator{\n\t\ttarget:     target,\n\t\tmaxEntries: target.maxEntries,\n\t}\n}\n\n// Next decodes the next key and value.\n//\n// Iterating a hash map from which keys are being deleted is not\n// safe. You may see the same key multiple times. Iteration may\n// also abort with an error, see IsIterationAborted.\n//\n// Returns false if there are no more entries. You must check\n// the result of Err afterwards.\n//\n// See Map.Get for further caveats around valueOut.\nfunc (mi *MapIterator) Next(keyOut, valueOut interface{}) bool {\n\tif mi.err != nil || mi.done {\n\t\treturn false\n\t}\n\n\t// For array-like maps NextKey returns nil only after maxEntries\n\t// iterations.\n\tfor mi.count <= mi.maxEntries {\n\t\tif mi.cursor == nil {\n\t\t\t// Pass nil interface to NextKey to make sure the Map's first key\n\t\t\t// is returned. If we pass an uninitialized []byte instead, it'll see a\n\t\t\t// non-nil interface and try to marshal it.\n\t\t\tmi.cursor = make([]byte, mi.target.keySize)\n\t\t\tmi.err = mi.target.NextKey(nil, mi.cursor)\n\t\t} else {\n\t\t\tmi.err = mi.target.NextKey(mi.cursor, mi.cursor)\n\t\t}\n\n\t\tif errors.Is(mi.err, ErrKeyNotExist) {\n\t\t\tmi.done = true\n\t\t\tmi.err = nil\n\t\t\treturn false\n\t\t} else if mi.err != nil {\n\t\t\tmi.err = fmt.Errorf(\"get next key: %w\", mi.err)\n\t\t\treturn false\n\t\t}\n\n\t\tmi.count++\n\t\tmi.err = mi.target.Lookup(mi.cursor, valueOut)\n\t\tif errors.Is(mi.err, ErrKeyNotExist) {\n\t\t\t// Even though the key should be valid, we couldn't look up\n\t\t\t// its value. If we're iterating a hash map this is probably\n\t\t\t// because a concurrent delete removed the value before we\n\t\t\t// could get it. This means that the next call to NextKeyBytes\n\t\t\t// is very likely to restart iteration.\n\t\t\t// If we're iterating one of the fd maps like\n\t\t\t// ProgramArray it means that a given slot doesn't have\n\t\t\t// a valid fd associated. It's OK to continue to the next slot.\n\t\t\tcontinue\n\t\t}\n\t\tif mi.err != nil {\n\t\t\tmi.err = fmt.Errorf(\"look up next key: %w\", mi.err)\n\t\t\treturn false\n\t\t}\n\n\t\tbuf := mi.cursor.([]byte)\n\t\tif ptr, ok := keyOut.(unsafe.Pointer); ok {\n\t\t\tcopy(unsafe.Slice((*byte)(ptr), len(buf)), buf)\n\t\t} else {\n\t\t\tmi.err = sysenc.Unmarshal(keyOut, buf)\n\t\t}\n\n\t\treturn mi.err == nil\n\t}\n\n\tmi.err = fmt.Errorf(\"%w\", ErrIterationAborted)\n\treturn false\n}\n\n// Err returns any encountered error.\n//\n// The method must be called after Next returns nil.\n//\n// Returns ErrIterationAborted if it wasn't possible to do a full iteration.\nfunc (mi *MapIterator) Err() error {\n\treturn mi.err\n}\n\n// MapGetNextID returns the ID of the next eBPF map.\n//\n// Returns ErrNotExist, if there is no next eBPF map.\nfunc MapGetNextID(startID MapID) (MapID, error) {\n\tattr := &sys.MapGetNextIdAttr{Id: uint32(startID)}\n\treturn MapID(attr.NextId), sys.MapGetNextId(attr)\n}\n\n// NewMapFromID returns the map for a given id.\n//\n// Returns ErrNotExist, if there is no eBPF map with the given id.\nfunc NewMapFromID(id MapID) (*Map, error) {\n\tfd, err := sys.MapGetFdById(&sys.MapGetFdByIdAttr{\n\t\tId: uint32(id),\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newMapFromFD(fd)\n}\n\n// sliceLen returns the length if the value is a slice or an error otherwise.\nfunc sliceLen(slice any) (int, error) {\n\tsliceValue := reflect.ValueOf(slice)\n\tif sliceValue.Kind() != reflect.Slice {\n\t\treturn 0, fmt.Errorf(\"%T is not a slice\", slice)\n\t}\n\treturn sliceValue.Len(), nil\n}\n"
        },
        {
          "name": "map_test.go",
          "type": "blob",
          "size": 54.3818359375,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"testing\"\n\t\"unsafe\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n\n\t\"github.com/go-quicktest/qt\"\n)\n\nvar (\n\tspec1 = &MapSpec{\n\t\tName:       \"foo\",\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tPinning:    PinByName,\n\t}\n)\n\n// newHash returns a new Map of type Hash. Cleanup is handled automatically.\nfunc newHash(t *testing.T) *Map {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tt.Cleanup(func() { hash.Close() })\n\treturn hash\n}\n\nfunc TestMap(t *testing.T) {\n\tm := createArray(t)\n\n\tt.Log(m)\n\n\tif err := m.Put(uint32(0), uint32(42)); err != nil {\n\t\tt.Fatal(\"Can't put:\", err)\n\t}\n\tif err := m.Put(uint32(1), uint32(4242)); err != nil {\n\t\tt.Fatal(\"Can't put:\", err)\n\t}\n\n\tm2, err := m.Clone()\n\tif err != nil {\n\t\tt.Fatal(\"Can't clone map:\", err)\n\t}\n\tdefer m2.Close()\n\n\tm.Close()\n\tm = m2\n\n\tvar v uint32\n\tif err := m.Lookup(uint32(0), &v); err != nil {\n\t\tt.Fatal(\"Can't lookup 0:\", err)\n\t}\n\tif v != 42 {\n\t\tt.Error(\"Want value 42, got\", v)\n\t}\n\n\tsliceVal := make([]uint32, 1)\n\tqt.Assert(t, qt.IsNil(m.Lookup(uint32(0), sliceVal)))\n\tqt.Assert(t, qt.DeepEquals(sliceVal, []uint32{42}))\n\n\tvar slice []byte\n\tqt.Assert(t, qt.IsNil(m.Lookup(uint32(0), &slice)))\n\tqt.Assert(t, qt.DeepEquals(slice, internal.NativeEndian.AppendUint32(nil, 42)))\n\n\tvar k uint32\n\tif err := m.NextKey(uint32(0), &k); err != nil {\n\t\tt.Fatal(\"Can't get:\", err)\n\t}\n\tif k != 1 {\n\t\tt.Error(\"Want key 1, got\", k)\n\t}\n}\n\nfunc TestMapSpecCopy(t *testing.T) {\n\ta := &MapSpec{\n\t\t\"foo\",\n\t\tHash,\n\t\t4,\n\t\t4,\n\t\t1,\n\t\t1,\n\t\tPinByName,\n\t\t1,\n\t\t[]MapKV{{1, 2}}, // Can't copy Contents, use value types\n\t\tnil,             // InnerMap\n\t\tbytes.NewReader(nil),\n\t\t&btf.Int{},\n\t\t&btf.Int{},\n\t}\n\ta.InnerMap = a\n\n\tqt.Check(t, qt.IsNil((*MapSpec)(nil).Copy()))\n\tqt.Assert(t, testutils.IsDeepCopy(a.Copy(), a))\n}\n\nfunc TestMapBatch(t *testing.T) {\n\tif err := haveBatchAPI(); err != nil {\n\t\tt.Skipf(\"batch api not available: %v\", err)\n\t}\n\n\tcontents := []uint32{\n\t\t42, 4242, 23, 2323,\n\t}\n\n\tmustNewMap := func(t *testing.T, mapType MapType, max uint32) *Map {\n\t\tm, err := NewMap(&MapSpec{\n\t\t\tType:       mapType,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: max,\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tt.Cleanup(func() { m.Close() })\n\t\treturn m\n\t}\n\n\tkeysAndValuesForMap := func(m *Map, contents []uint32) (keys, values []uint32, stride int) {\n\t\tpossibleCPU := 1\n\t\tif m.Type().hasPerCPUValue() {\n\t\t\tpossibleCPU = MustPossibleCPU()\n\t\t}\n\n\t\tkeys = make([]uint32, 0, len(contents))\n\t\tvalues = make([]uint32, 0, len(contents)*possibleCPU)\n\t\tfor key, value := range contents {\n\t\t\tkeys = append(keys, uint32(key))\n\t\t\tfor i := 0; i < possibleCPU; i++ {\n\t\t\t\tvalues = append(values, value*uint32((i+1)))\n\t\t\t}\n\t\t}\n\n\t\treturn keys, values, possibleCPU\n\t}\n\n\tfor _, typ := range []MapType{Array, PerCPUArray} {\n\t\tt.Run(typ.String(), func(t *testing.T) {\n\t\t\tif typ == PerCPUArray {\n\t\t\t\t// https://lore.kernel.org/bpf/20210424214510.806627-2-pctammela@mojatatu.com/\n\t\t\t\ttestutils.SkipOnOldKernel(t, \"5.13\", \"batched ops support for percpu array\")\n\t\t\t}\n\n\t\t\tm := mustNewMap(t, typ, uint32(len(contents)))\n\t\t\tkeys, values, _ := keysAndValuesForMap(m, contents)\n\t\t\tcount, err := m.BatchUpdate(keys, values, nil)\n\t\t\tqt.Assert(t, qt.IsNil(err))\n\t\t\tqt.Assert(t, qt.Equals(count, len(contents)))\n\n\t\t\tlookupKeys := make([]uint32, len(keys))\n\t\t\tlookupValues := make([]uint32, len(values))\n\n\t\t\tvar cursor MapBatchCursor\n\t\t\tcount, err = m.BatchLookup(&cursor, lookupKeys, lookupValues, nil)\n\t\t\tqt.Assert(t, qt.IsNil(err))\n\t\t\tqt.Assert(t, qt.Equals(count, len(contents)))\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupKeys, keys))\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupValues, values))\n\n\t\t\tcount, err = m.BatchLookup(&cursor, lookupKeys, lookupValues, nil)\n\t\t\tqt.Assert(t, qt.ErrorIs(err, ErrKeyNotExist))\n\t\t\tqt.Assert(t, qt.Equals(count, 0))\n\t\t})\n\t}\n\n\tfor _, typ := range []MapType{Hash, PerCPUHash} {\n\t\tt.Run(typ.String(), func(t *testing.T) {\n\t\t\tm := mustNewMap(t, typ, uint32(len(contents)))\n\t\t\tkeys, values, stride := keysAndValuesForMap(m, contents)\n\t\t\tcount, err := m.BatchUpdate(keys, values, nil)\n\t\t\tqt.Assert(t, qt.IsNil(err))\n\t\t\tqt.Assert(t, qt.Equals(count, len(contents)))\n\n\t\t\t// BPF hash tables seem to have lots of collisions when keys\n\t\t\t// are following a sequence.\n\t\t\t// This causes ENOSPC since a single large bucket may be larger\n\t\t\t// than the batch size. We work around this by making the batch size\n\t\t\t// equal to the map size.\n\t\t\tlookupKeys := make([]uint32, len(keys))\n\t\t\tlookupValues := make([]uint32, len(values))\n\n\t\t\tvar cursor MapBatchCursor\n\t\t\tcount, err = m.BatchLookup(&cursor, lookupKeys, lookupValues, nil)\n\t\t\tqt.Assert(t, qt.ErrorIs(err, ErrKeyNotExist))\n\t\t\tqt.Assert(t, qt.Equals(count, len(contents)))\n\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupKeys, keys))\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupValues, values))\n\n\t\t\tcursor = MapBatchCursor{}\n\t\t\tcount, err = m.BatchLookupAndDelete(&cursor, lookupKeys, lookupValues, nil)\n\t\t\tqt.Assert(t, qt.ErrorIs(err, ErrKeyNotExist))\n\t\t\tqt.Assert(t, qt.Equals(count, len(contents)))\n\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupKeys, keys))\n\t\t\tqt.Assert(t, qt.ContentEquals(lookupValues, values))\n\n\t\t\tif stride > 1 {\n\t\t\t\tvalues := make([]uint32, stride)\n\t\t\t\tqt.Assert(t, qt.ErrorIs(m.Lookup(uint32(0), values), ErrKeyNotExist))\n\t\t\t} else {\n\t\t\t\tvar v uint32\n\t\t\t\tqt.Assert(t, qt.ErrorIs(m.Lookup(uint32(0), &v), ErrKeyNotExist))\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestMapBatchCursorReuse(t *testing.T) {\n\tspec := &MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 4,\n\t}\n\n\tarr1, err := NewMap(spec)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer arr1.Close()\n\n\tarr2, err := NewMap(spec)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer arr2.Close()\n\n\ttmp := make([]uint32, 2)\n\n\tvar cursor MapBatchCursor\n\t_, err = arr1.BatchLookup(&cursor, tmp, tmp, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\n\t_, err = arr2.BatchLookup(&cursor, tmp, tmp, nil)\n\tqt.Assert(t, qt.IsNotNil(err))\n}\n\nfunc TestMapLookupKeyTooSmall(t *testing.T) {\n\tm := createArray(t)\n\tdefer m.Close()\n\n\tvar small uint16\n\tqt.Assert(t, qt.IsNil(m.Put(uint32(0), uint32(1234))))\n\tqt.Assert(t, qt.IsNotNil(m.Lookup(uint32(0), &small)))\n}\n\nfunc TestMapLookupKeyNotFoundAllocations(t *testing.T) {\n\tm := createArray(t)\n\tdefer m.Close()\n\tvar key, out uint32 = 3, 0\n\n\tallocs := testing.AllocsPerRun(5, func() {\n\t\t_ = m.Lookup(&key, &out)\n\t})\n\tqt.Assert(t, qt.Equals(allocs, float64(0)))\n}\n\nfunc TestBatchAPIMapDelete(t *testing.T) {\n\tif err := haveBatchAPI(); err != nil {\n\t\tt.Skipf(\"batch api not available: %v\", err)\n\t}\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\tvar (\n\t\tkeys   = []uint32{0, 1}\n\t\tvalues = []uint32{42, 4242}\n\t)\n\n\tcount, err := m.BatchUpdate(keys, values, nil)\n\tif err != nil {\n\t\tt.Fatalf(\"BatchUpdate: %v\", err)\n\t}\n\tif count != len(keys) {\n\t\tt.Fatalf(\"BatchUpdate: expected count, %d, to be %d\", count, len(keys))\n\t}\n\n\tvar v uint32\n\tif err := m.Lookup(uint32(0), &v); err != nil {\n\t\tt.Fatal(\"Can't lookup 0:\", err)\n\t}\n\tif v != 42 {\n\t\tt.Error(\"Want value 42, got\", v)\n\t}\n\n\tcount, err = m.BatchDelete(keys, nil)\n\tif err != nil {\n\t\tt.Fatalf(\"BatchDelete: %v\", err)\n\t}\n\tif count != len(keys) {\n\t\tt.Fatalf(\"BatchDelete: expected %d deletions got %d\", len(keys), count)\n\t}\n\n\tif err := m.Lookup(uint32(0), &v); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Fatalf(\"Lookup should have failed with error, %v, instead error is %v\", ErrKeyNotExist, err)\n\t}\n}\n\nfunc TestMapClose(t *testing.T) {\n\tm := createArray(t)\n\n\tif err := m.Close(); err != nil {\n\t\tt.Fatal(\"Can't close map:\", err)\n\t}\n\n\tif err := m.Put(uint32(0), uint32(42)); !errors.Is(err, sys.ErrClosedFd) {\n\t\tt.Fatal(\"Put doesn't check for closed fd\", err)\n\t}\n\n\tif _, err := m.LookupBytes(uint32(0)); !errors.Is(err, sys.ErrClosedFd) {\n\t\tt.Fatal(\"Get doesn't check for closed fd\", err)\n\t}\n}\n\nfunc TestBatchMapWithLock(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.13\", \"MAP BATCH BPF_F_LOCK\")\n\tfile := testutils.NativeFile(t, \"testdata/map_spin_lock-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\n\tcoll, err := NewCollection(spec)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\tdefer coll.Close()\n\n\ttype spinLockValue struct {\n\t\tCnt     uint32\n\t\tPadding uint32\n\t}\n\n\tm, ok := coll.Maps[\"spin_lock_map\"]\n\tif !ok {\n\t\tt.Fatal(err)\n\t}\n\n\tkeys := []uint32{0, 1}\n\tvalues := []spinLockValue{{Cnt: 42}, {Cnt: 4242}}\n\tcount, err := m.BatchUpdate(keys, values, &BatchOptions{ElemFlags: uint64(UpdateLock)})\n\tif err != nil {\n\t\tt.Fatalf(\"BatchUpdate: %v\", err)\n\t}\n\tif count != len(keys) {\n\t\tt.Fatalf(\"BatchUpdate: expected count, %d, to be %d\", count, len(keys))\n\t}\n\n\tvar cursor MapBatchCursor\n\tlookupKeys := make([]uint32, 2)\n\tlookupValues := make([]spinLockValue, 2)\n\tcount, err = m.BatchLookup(&cursor, lookupKeys, lookupValues, &BatchOptions{ElemFlags: uint64(LookupLock)})\n\tif !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Fatalf(\"BatchLookup: %v\", err)\n\t}\n\tif count != 2 {\n\t\tt.Fatalf(\"BatchLookup: expected two keys, got %d\", count)\n\t}\n\n\tcursor = MapBatchCursor{}\n\tdeleteKeys := []uint32{0, 1}\n\tdeleteValues := make([]spinLockValue, 2)\n\tcount, err = m.BatchLookupAndDelete(&cursor, deleteKeys, deleteValues, nil)\n\tif !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Fatalf(\"BatchLookupAndDelete: %v\", err)\n\t}\n\tif count != 2 {\n\t\tt.Fatalf(\"BatchLookupAndDelete: expected two keys, got %d\", count)\n\t}\n}\n\nfunc TestMapWithLock(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.13\", \"MAP BPF_F_LOCK\")\n\tfile := testutils.NativeFile(t, \"testdata/map_spin_lock-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\n\tcoll, err := NewCollection(spec)\n\tif err != nil {\n\t\tt.Fatal(\"Can't parse ELF:\", err)\n\t}\n\tdefer coll.Close()\n\n\ttype spinLockValue struct {\n\t\tCnt     uint32\n\t\tPadding uint32\n\t}\n\n\tm, ok := coll.Maps[\"spin_lock_map\"]\n\tif !ok {\n\t\tt.Fatal(err)\n\t}\n\n\tkey := uint32(1)\n\tvalue := spinLockValue{Cnt: 5}\n\terr = m.Update(key, value, UpdateLock)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalue.Cnt = 0\n\terr = m.LookupWithFlags(&key, &value, LookupLock)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif value.Cnt != 5 {\n\t\tt.Fatalf(\"Want value 5, got %d\", value.Cnt)\n\t}\n\n\tt.Run(\"LookupAndDelete\", func(t *testing.T) {\n\t\ttestutils.SkipOnOldKernel(t, \"5.14\", \"LOOKUP_AND_DELETE flags\")\n\n\t\tvalue.Cnt = 0\n\t\terr = m.LookupAndDeleteWithFlags(&key, &value, LookupLock)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif value.Cnt != 5 {\n\t\t\tt.Fatalf(\"Want value 5, got %d\", value.Cnt)\n\t\t}\n\n\t\terr = m.LookupWithFlags(&key, &value, LookupLock)\n\t\tif err != nil && !errors.Is(err, ErrKeyNotExist) {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n}\n\nfunc TestMapCloneNil(t *testing.T) {\n\tm, err := (*Map)(nil).Clone()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif m != nil {\n\t\tt.Fatal(\"Cloning a nil map doesn't return nil\")\n\t}\n}\n\nfunc TestMapPin(t *testing.T) {\n\tm := createArray(t)\n\n\tif err := m.Put(uint32(0), uint32(42)); err != nil {\n\t\tt.Fatal(\"Can't put:\", err)\n\t}\n\n\ttmp := testutils.TempBPFFS(t)\n\tpath := filepath.Join(tmp, \"map\")\n\n\tif err := m.Pin(path); err != nil {\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tt.Fatal(err)\n\t}\n\n\tpinned := m.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tm.Close()\n\n\tm, err := LoadPinnedMap(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\tvar v uint32\n\tif err := m.Lookup(uint32(0), &v); err != nil {\n\t\tt.Fatal(\"Can't lookup 0:\", err)\n\t}\n\tif v != 42 {\n\t\tt.Error(\"Want value 42, got\", v)\n\t}\n}\n\nfunc TestNestedMapPin(t *testing.T) {\n\tm, err := NewMap(&MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 1,\n\t\t},\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\ttmp, err := os.MkdirTemp(\"/sys/fs/bpf\", \"ebpf-test\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmp)\n\n\tpath := filepath.Join(tmp, \"nested\")\n\tif err := m.Pin(path); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tm.Close()\n\n\tm, err = LoadPinnedMap(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n}\n\nfunc TestNestedMapPinNested(t *testing.T) {\n\tif _, err := NewMap(&MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tName:       \"inner\",\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 1,\n\t\t\tPinning:    PinByName,\n\t\t},\n\t}); err == nil {\n\t\tt.Error(\"Inner maps should not be pinnable\")\n\t}\n}\n\nfunc TestMapPinMultiple(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.9\", \"atomic re-pinning was introduced in 4.9 series\")\n\n\ttmp := testutils.TempBPFFS(t)\n\n\tspec := spec1.Copy()\n\n\tm1, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tif err != nil {\n\t\tt.Fatal(\"Can't create map:\", err)\n\t}\n\tdefer m1.Close()\n\tpinned := m1.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tnewPath := filepath.Join(tmp, \"bar\")\n\terr = m1.Pin(newPath)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\toldPath := filepath.Join(tmp, spec.Name)\n\tif _, err := os.Stat(oldPath); err == nil {\n\t\tt.Fatal(\"Previous pinned map path still exists:\", err)\n\t}\n\tm2, err := LoadPinnedMap(newPath, nil)\n\tqt.Assert(t, qt.IsNil(err))\n\tpinned = m2.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\tdefer m2.Close()\n}\n\nfunc TestMapPinWithEmptyPath(t *testing.T) {\n\tm := createArray(t)\n\n\terr := m.Pin(\"\")\n\n\tqt.Assert(t, qt.Not(qt.IsNil(err)))\n}\n\nfunc TestMapPinFailReplace(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\tspec := spec1.Copy()\n\tspec2 := spec1.Copy()\n\tspec2.Name = spec1.Name + \"bar\"\n\n\tm, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tif err != nil {\n\t\tt.Fatal(\"Failed to create map:\", err)\n\t}\n\tdefer m.Close()\n\tm2, err := NewMapWithOptions(spec2, MapOptions{PinPath: tmp})\n\tif err != nil {\n\t\tt.Fatal(\"Failed to create map2:\", err)\n\t}\n\tdefer m2.Close()\n\tqt.Assert(t, qt.IsTrue(m.IsPinned()))\n\tnewPath := filepath.Join(tmp, spec2.Name)\n\n\tqt.Assert(t, qt.Not(qt.IsNil(m.Pin(newPath))), qt.Commentf(\"Pin didn't\"+\n\t\t\" fail new path from replacing an existing path\"))\n}\n\nfunc TestMapUnpin(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\tspec := spec1.Copy()\n\n\tm, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tif err != nil {\n\t\tt.Fatal(\"Failed to create map:\", err)\n\t}\n\tdefer m.Close()\n\n\tpinned := m.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\tpath := filepath.Join(tmp, spec.Name)\n\tm2, err := LoadPinnedMap(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m2.Close()\n\n\tif err = m.Unpin(); err != nil {\n\t\tt.Fatal(\"Failed to unpin map:\", err)\n\t}\n\tif _, err := os.Stat(path); err == nil {\n\t\tt.Fatal(\"Pinned map path still exists after unpinning:\", err)\n\t}\n}\n\nfunc TestMapLoadPinned(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\n\tspec := spec1.Copy()\n\n\tm1, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m1.Close()\n\tpinned := m1.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tpath := filepath.Join(tmp, spec.Name)\n\tm2, err := LoadPinnedMap(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m2.Close()\n\tpinned = m2.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n}\n\nfunc TestMapLoadReusePinned(t *testing.T) {\n\tfor _, typ := range []MapType{Array, Hash, DevMap, DevMapHash} {\n\t\tt.Run(typ.String(), func(t *testing.T) {\n\t\t\tif typ == DevMap {\n\t\t\t\ttestutils.SkipOnOldKernel(t, \"4.14\", \"devmap\")\n\t\t\t}\n\t\t\tif typ == DevMapHash {\n\t\t\t\ttestutils.SkipOnOldKernel(t, \"5.4\", \"devmap_hash\")\n\t\t\t}\n\t\t\ttmp := testutils.TempBPFFS(t)\n\t\t\tspec := &MapSpec{\n\t\t\t\tName:       \"pinmap\",\n\t\t\t\tType:       typ,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: 1,\n\t\t\t\tPinning:    PinByName,\n\t\t\t}\n\n\t\t\tm1, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\t\t\tqt.Assert(t, qt.IsNil(err))\n\t\t\tdefer m1.Close()\n\n\t\t\tm2, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\t\t\tqt.Assert(t, qt.IsNil(err))\n\t\t\tdefer m2.Close()\n\t\t})\n\t}\n}\n\nfunc TestMapLoadPinnedUnpin(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\n\tspec := spec1.Copy()\n\n\tm1, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m1.Close()\n\tpinned := m1.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tpath := filepath.Join(tmp, spec.Name)\n\tm2, err := LoadPinnedMap(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m2.Close()\n\terr = m1.Unpin()\n\tqt.Assert(t, qt.IsNil(err))\n\terr = m2.Unpin()\n\tqt.Assert(t, qt.IsNil(err))\n}\n\nfunc TestMapLoadPinnedWithOptions(t *testing.T) {\n\t// Introduced in commit 6e71b04a8224.\n\ttestutils.SkipOnOldKernel(t, \"4.15\", \"file_flags in BPF_OBJ_GET\")\n\n\tarray := createArray(t)\n\n\ttmp := testutils.TempBPFFS(t)\n\n\tpath := filepath.Join(tmp, \"map\")\n\tif err := array.Pin(path); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := array.Put(uint32(0), uint32(123)); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tarray.Close()\n\n\tt.Run(\"read-only\", func(t *testing.T) {\n\t\tarray, err := LoadPinnedMap(path, &LoadPinOptions{\n\t\t\tReadOnly: true,\n\t\t})\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't load map:\", err)\n\t\t}\n\t\tdefer array.Close()\n\n\t\tif err := array.Put(uint32(0), uint32(1)); !errors.Is(err, unix.EPERM) {\n\t\t\tt.Fatal(\"Expected EPERM from Put, got\", err)\n\t\t}\n\t})\n\n\tt.Run(\"write-only\", func(t *testing.T) {\n\t\tarray, err := LoadPinnedMap(path, &LoadPinOptions{\n\t\t\tWriteOnly: true,\n\t\t})\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't load map:\", err)\n\t\t}\n\t\tdefer array.Close()\n\n\t\tvar value uint32\n\t\tif err := array.Lookup(uint32(0), &value); !errors.Is(err, unix.EPERM) {\n\t\t\tt.Fatal(\"Expected EPERM from Lookup, got\", err)\n\t\t}\n\t})\n}\n\nfunc TestMapPinFlags(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\n\tspec := &MapSpec{\n\t\tName:       \"map\",\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tPinning:    PinByName,\n\t}\n\n\tm, err := NewMapWithOptions(spec, MapOptions{\n\t\tPinPath: tmp,\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tm.Close()\n\n\t_, err = NewMapWithOptions(spec, MapOptions{\n\t\tPinPath: tmp,\n\t\tLoadPinOptions: LoadPinOptions{\n\t\t\tFlags: math.MaxUint32,\n\t\t},\n\t})\n\tif !errors.Is(err, unix.EINVAL) {\n\t\tt.Fatal(\"Invalid flags should trigger EINVAL:\", err)\n\t}\n}\n\nfunc createArray(t *testing.T) *Map {\n\tt.Helper()\n\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tt.Cleanup(func() { m.Close() })\n\treturn m\n}\n\nfunc TestMapQueue(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.20\", \"map type queue\")\n\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Queue,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\tfor _, v := range []uint32{42, 4242} {\n\t\tif err := m.Put(nil, v); err != nil {\n\t\t\tt.Fatalf(\"Can't put %d: %s\", v, err)\n\t\t}\n\t}\n\n\tvar v uint32\n\tif err := m.Lookup(nil, &v); err != nil {\n\t\tt.Fatal(\"Lookup (Peek) on Queue:\", err)\n\t}\n\tif v != 42 {\n\t\tt.Error(\"Want value 42, got\", v)\n\t}\n\tv = 0\n\n\tif err := m.LookupAndDelete(nil, &v); err != nil {\n\t\tt.Fatal(\"Can't lookup and delete element:\", err)\n\t}\n\tif v != 42 {\n\t\tt.Error(\"Want value 42, got\", v)\n\t}\n\n\tv = 0\n\tif err := m.LookupAndDelete(nil, unsafe.Pointer(&v)); err != nil {\n\t\tt.Fatal(\"Can't lookup and delete element using unsafe.Pointer:\", err)\n\t}\n\tif v != 4242 {\n\t\tt.Error(\"Want value 4242, got\", v)\n\t}\n\n\tif err := m.LookupAndDelete(nil, &v); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Fatal(\"Lookup and delete on empty Queue:\", err)\n\t}\n\n\tif err := m.Lookup(nil, &v); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Fatal(\"Lookup (Peek) on empty Queue:\", err)\n\t}\n}\n\nfunc TestMapInMap(t *testing.T) {\n\tfor _, typ := range []MapType{ArrayOfMaps, HashOfMaps} {\n\t\tt.Run(typ.String(), func(t *testing.T) {\n\t\t\tspec := &MapSpec{\n\t\t\t\tType:       typ,\n\t\t\t\tKeySize:    4,\n\t\t\t\tMaxEntries: 2,\n\t\t\t\tInnerMap: &MapSpec{\n\t\t\t\t\tType:       Array,\n\t\t\t\t\tKeySize:    4,\n\t\t\t\t\tValueSize:  4,\n\t\t\t\t\tMaxEntries: 2,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tinner, err := NewMap(spec.InnerMap)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif err := inner.Put(uint32(1), uint32(4242)); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer inner.Close()\n\n\t\t\touter, err := NewMap(spec)\n\t\t\ttestutils.SkipIfNotSupported(t, err)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer outer.Close()\n\n\t\t\tif err := outer.Put(uint32(0), inner); err != nil {\n\t\t\t\tt.Fatal(\"Can't put inner map:\", err)\n\t\t\t}\n\n\t\t\tif err := outer.Put(uint32(0), (*Map)(nil)); err == nil {\n\t\t\t\tt.Fatal(\"Put accepted a nil Map\")\n\t\t\t}\n\n\t\t\tvar inner2 *Map\n\t\t\tif err := outer.Lookup(uint32(0), &inner2); err != nil {\n\t\t\t\tt.Fatal(\"Can't lookup 0:\", err)\n\t\t\t}\n\t\t\tdefer inner2.Close()\n\n\t\t\tvar v uint32\n\t\t\tif err := inner2.Lookup(uint32(1), &v); err != nil {\n\t\t\t\tt.Fatal(\"Can't lookup 1 in inner2:\", err)\n\t\t\t}\n\n\t\t\tif v != 4242 {\n\t\t\t\tt.Error(\"Expected value 4242, got\", v)\n\t\t\t}\n\n\t\t\tinner2.Close()\n\n\t\t\t// Make sure we can still access the original map\n\t\t\tif err := inner.Lookup(uint32(1), &v); err != nil {\n\t\t\t\tt.Fatal(\"Can't lookup 1 in inner:\", err)\n\t\t\t}\n\n\t\t\tif v != 4242 {\n\t\t\t\tt.Error(\"Expected value 4242, got\", v)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestNewMapInMapFromFD(t *testing.T) {\n\tnested, err := NewMap(&MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tKeySize:    4,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 2,\n\t\t},\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer nested.Close()\n\n\t// Do not copy this, use Clone instead.\n\tanother, err := NewMapFromFD(dupFD(t, nested.FD()))\n\tif err != nil {\n\t\tt.Fatal(\"Can't create a new nested map from an FD\")\n\t}\n\tanother.Close()\n}\n\nfunc TestPerfEventArray(t *testing.T) {\n\tspecs := []*MapSpec{\n\t\t{Type: PerfEventArray},\n\t\t{Type: PerfEventArray, KeySize: 4},\n\t\t{Type: PerfEventArray, ValueSize: 4},\n\t}\n\n\tfor _, spec := range specs {\n\t\tm, err := NewMap(spec)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Can't create perf event array from %v: %s\", spec, err)\n\t\t} else {\n\t\t\tm.Close()\n\t\t}\n\t}\n}\n\nfunc TestCPUMap(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.15\", \"cpu map\")\n\n\tm, err := NewMap(&MapSpec{Type: CPUMap, KeySize: 4, ValueSize: 4})\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(m.MaxEntries(), uint32(MustPossibleCPU())))\n\tm.Close()\n}\n\nfunc createMapInMap(t *testing.T, typ MapType) *Map {\n\tt.Helper()\n\n\tspec := &MapSpec{\n\t\tType:       typ,\n\t\tKeySize:    4,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 2,\n\t\t},\n\t}\n\n\tm, err := NewMap(spec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treturn m\n}\n\nfunc TestMapInMapValueSize(t *testing.T) {\n\tspec := &MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tKeySize:    4,\n\t\tValueSize:  0,\n\t\tMaxEntries: 2,\n\t\tInnerMap: &MapSpec{\n\t\t\tType:       Array,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  4,\n\t\t\tMaxEntries: 2,\n\t\t},\n\t}\n\n\tm, err := NewMap(spec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tm.Close()\n\n\tspec.ValueSize = 4\n\tm, err = NewMap(spec)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tm.Close()\n\n\tspec.ValueSize = 1\n\tif _, err := NewMap(spec); err == nil {\n\t\tt.Fatal(\"Expected an error\")\n\t}\n}\n\nfunc TestIterateEmptyMap(t *testing.T) {\n\tmakeMap := func(t *testing.T, mapType MapType) *Map {\n\t\tm, err := NewMap(&MapSpec{\n\t\t\tType:       mapType,\n\t\t\tKeySize:    4,\n\t\t\tValueSize:  8,\n\t\t\tMaxEntries: 2,\n\t\t})\n\t\tif errors.Is(err, unix.EINVAL) {\n\t\t\tt.Skip(mapType, \"is not supported\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't create map:\", err)\n\t\t}\n\t\tt.Cleanup(func() { m.Close() })\n\t\treturn m\n\t}\n\n\tfor _, mapType := range []MapType{\n\t\tHash,\n\t\tSockHash,\n\t} {\n\t\tt.Run(mapType.String(), func(t *testing.T) {\n\t\t\tm := makeMap(t, mapType)\n\t\t\tentries := m.Iterate()\n\n\t\t\tvar key string\n\t\t\tvar value uint64\n\t\t\tif entries.Next(&key, &value) {\n\t\t\t\tt.Error(\"Empty hash should not be iterable\")\n\t\t\t}\n\t\t\tif err := entries.Err(); err != nil {\n\t\t\t\tt.Error(\"Empty hash shouldn't return an error:\", err)\n\t\t\t}\n\t\t})\n\t}\n\n\tfor _, mapType := range []MapType{\n\t\tArray,\n\t\tSockMap,\n\t} {\n\t\tt.Run(mapType.String(), func(t *testing.T) {\n\t\t\tm := makeMap(t, mapType)\n\t\t\tentries := m.Iterate()\n\t\t\tvar key string\n\t\t\tvar value uint64\n\t\t\tfor entries.Next(&key, &value) {\n\t\t\t\t// Some empty arrays like sockmap don't return any keys.\n\t\t\t}\n\t\t\tif err := entries.Err(); err != nil {\n\t\t\t\tt.Error(\"Empty array shouldn't return an error:\", err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestMapIterate(t *testing.T) {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer hash.Close()\n\n\tdata := []string{\"hello\", \"world\"}\n\tfor i, k := range data {\n\t\tif err := hash.Put(k, uint32(i)); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\tvar key string\n\tvar value uint32\n\tvar keys []string\n\n\tentries := hash.Iterate()\n\tfor entries.Next(&key, &value) {\n\t\tkeys = append(keys, key)\n\t}\n\tqt.Assert(t, qt.IsNil(entries.Err()))\n\n\tsort.Strings(keys)\n\tqt.Assert(t, qt.DeepEquals(keys, data))\n}\n\nfunc TestIterateWrongMap(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.20\", \"map type queue\")\n\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Queue,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t\tContents: []MapKV{\n\t\t\t{nil, uint32(0)},\n\t\t\t{nil, uint32(1)},\n\t\t},\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m.Close()\n\n\tvar value uint32\n\tentries := m.Iterate()\n\n\tqt.Assert(t, qt.IsFalse(entries.Next(nil, &value)))\n\tqt.Assert(t, qt.IsNotNil(entries.Err()))\n}\n\nfunc TestMapIteratorAllocations(t *testing.T) {\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer arr.Close()\n\n\tvar k, v uint32\n\titer := arr.Iterate()\n\n\t// AllocsPerRun warms up the function for us.\n\tallocs := testing.AllocsPerRun(int(arr.MaxEntries()-1), func() {\n\t\tif !iter.Next(&k, &v) {\n\t\t\tt.Fatal(\"Next failed while iterating: %w\", iter.Err())\n\t\t}\n\t})\n\n\tqt.Assert(t, qt.Equals(allocs, float64(0)))\n}\n\nfunc TestMapBatchLookupAllocations(t *testing.T) {\n\ttestutils.SkipIfNotSupported(t, haveBatchAPI())\n\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer arr.Close()\n\n\tvar cursor MapBatchCursor\n\ttmp := make([]uint32, 2)\n\tinput := any(tmp)\n\n\t// AllocsPerRun warms up the function for us.\n\tallocs := testing.AllocsPerRun(1, func() {\n\t\t_, err := arr.BatchLookup(&cursor, input, input, nil)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n\n\tqt.Assert(t, qt.Equals(allocs, 0))\n}\n\nfunc TestMapIterateHashKeyOneByteFull(t *testing.T) {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    1,\n\t\tValueSize:  1,\n\t\tMaxEntries: 256,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer hash.Close()\n\n\tfor i := 0; i < int(hash.MaxEntries()); i++ {\n\t\tif err := hash.Put(uint8(i), uint8(i)); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\tvar key uint8\n\tvar value uint8\n\tvar keys int\n\n\tentries := hash.Iterate()\n\tfor entries.Next(&key, &value) {\n\t\tif key != value {\n\t\t\tt.Fatalf(\"Expected key == value, got key %v value %v\", key, value)\n\t\t}\n\t\tkeys++\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif keys != int(hash.MaxEntries()) {\n\t\tt.Fatalf(\"Expected to get %d keys, have %d\", hash.MaxEntries(), keys)\n\t}\n}\n\nfunc TestMapGuessNonExistentKey(t *testing.T) {\n\ttests := []struct {\n\t\tname    string\n\t\tmapType MapType\n\t\tkeys    []uint32\n\t}{\n\t\t{\n\t\t\t\"empty\", Hash, []uint32{},\n\t\t},\n\t\t{\n\t\t\t\"all zero key\", Hash, []uint32{0},\n\t\t},\n\t\t{\n\t\t\t\"all ones key\", Hash, []uint32{math.MaxUint32},\n\t\t},\n\t\t{\n\t\t\t\"alternating bits key\", Hash, []uint32{0x5555_5555},\n\t\t},\n\t\t{\n\t\t\t\"all special patterns\", Hash, []uint32{0, math.MaxUint32, 0x5555_5555},\n\t\t},\n\t\t{\n\t\t\t\"empty\", Array, []uint32{},\n\t\t},\n\t\t{\n\t\t\t\"all zero key\", Array, []uint32{0},\n\t\t},\n\t\t{\n\t\t\t\"full\", Array, []uint32{0, 1},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(fmt.Sprintf(\"%s: %s\", tt.mapType, tt.name), func(t *testing.T) {\n\t\t\tmaxEntries := uint32(len(tt.keys))\n\t\t\tif maxEntries == 0 {\n\t\t\t\tmaxEntries = 1\n\t\t\t}\n\n\t\t\tm, err := NewMap(&MapSpec{\n\t\t\t\tType:       tt.mapType,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  4,\n\t\t\t\tMaxEntries: maxEntries,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer m.Close()\n\n\t\t\tfor _, key := range tt.keys {\n\t\t\t\tif err := m.Put(key, key); err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tguess, err := m.guessNonExistentKey()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tif len(guess) != int(m.keySize) {\n\t\t\t\tt.Fatal(\"Guessed key has wrong size\")\n\t\t\t}\n\n\t\t\tvar value uint32\n\t\t\tif err := m.Lookup(guess, &value); !errors.Is(err, unix.ENOENT) {\n\t\t\t\tt.Fatal(\"Doesn't return ENOENT:\", err)\n\t\t\t}\n\t\t})\n\t}\n\n\tt.Run(\"Hash: full\", func(t *testing.T) {\n\t\tconst n = math.MaxUint8 + 1\n\n\t\thash, err := NewMap(&MapSpec{\n\t\t\tType:       Hash,\n\t\t\tKeySize:    1,\n\t\t\tValueSize:  1,\n\t\t\tMaxEntries: n,\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tdefer hash.Close()\n\n\t\tfor i := 0; i < n; i++ {\n\t\t\tif err := hash.Put(uint8(i), uint8(i)); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t}\n\n\t\t_, err = hash.guessNonExistentKey()\n\t\tif err == nil {\n\t\t\tt.Fatal(\"guessNonExistentKey doesn't return error on full hash table\")\n\t\t}\n\t})\n}\n\nfunc TestNotExist(t *testing.T) {\n\thash := newHash(t)\n\n\tvar tmp uint32\n\terr := hash.Lookup(\"hello\", &tmp)\n\tif !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Error(\"Lookup doesn't return ErrKeyNotExist\")\n\t}\n\n\tbuf, err := hash.LookupBytes(\"hello\")\n\tif err != nil {\n\t\tt.Error(\"Looking up non-existent key return an error:\", err)\n\t}\n\tif buf != nil {\n\t\tt.Error(\"LookupBytes returns non-nil buffer for non-existent key\")\n\t}\n\n\tif err := hash.Delete(\"hello\"); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Error(\"Deleting unknown key doesn't return ErrKeyNotExist\", err)\n\t}\n\n\tvar k = []byte{1, 2, 3, 4, 5}\n\tif err := hash.NextKey(&k, &tmp); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Error(\"Looking up next key in empty map doesn't return a non-existing error\", err)\n\t}\n\n\tif err := hash.NextKey(nil, &tmp); !errors.Is(err, ErrKeyNotExist) {\n\t\tt.Error(\"Looking up next key in empty map doesn't return a non-existing error\", err)\n\t}\n}\n\nfunc TestExist(t *testing.T) {\n\thash := newHash(t)\n\n\tif err := hash.Put(\"hello\", uint32(21)); err != nil {\n\t\tt.Errorf(\"Failed to put key/value pair into hash: %v\", err)\n\t}\n\n\tif err := hash.Update(\"hello\", uint32(42), UpdateNoExist); !errors.Is(err, ErrKeyExist) {\n\t\tt.Error(\"Updating existing key doesn't return ErrKeyExist\")\n\t}\n}\n\nfunc TestIterateMapInMap(t *testing.T) {\n\tconst idx = uint32(1)\n\n\tparent := createMapInMap(t, ArrayOfMaps)\n\tdefer parent.Close()\n\n\ta := createArray(t)\n\n\tif err := parent.Put(idx, a); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar (\n\t\tkey     uint32\n\t\tm       *Map\n\t\tentries = parent.Iterate()\n\t)\n\n\tif !entries.Next(&key, &m) {\n\t\tt.Fatal(\"Iterator encountered error:\", entries.Err())\n\t}\n\tm.Close()\n\n\tif key != 1 {\n\t\tt.Error(\"Iterator didn't skip first entry\")\n\t}\n\n\tif m == nil {\n\t\tt.Fatal(\"Map is nil\")\n\t}\n}\n\nfunc TestPerCPUMarshaling(t *testing.T) {\n\tfor _, typ := range []MapType{PerCPUHash, PerCPUArray, LRUCPUHash} {\n\t\tt.Run(typ.String(), func(t *testing.T) {\n\t\t\tnumCPU := MustPossibleCPU()\n\t\t\tif numCPU < 2 {\n\t\t\t\tt.Skip(\"Test requires at least two CPUs\")\n\t\t\t}\n\t\t\tif typ == PerCPUHash || typ == PerCPUArray {\n\t\t\t\ttestutils.SkipOnOldKernel(t, \"4.6\", \"per-CPU hash and array\")\n\t\t\t}\n\t\t\tif typ == LRUCPUHash {\n\t\t\t\ttestutils.SkipOnOldKernel(t, \"4.10\", \"LRU per-CPU hash\")\n\t\t\t}\n\n\t\t\tarr, err := NewMap(&MapSpec{\n\t\t\t\tType:       typ,\n\t\t\t\tKeySize:    4,\n\t\t\t\tValueSize:  5,\n\t\t\t\tMaxEntries: 1,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer arr.Close()\n\n\t\t\tvalues := []*customEncoding{\n\t\t\t\t{\"hello\"},\n\t\t\t\t{\"world\"},\n\t\t\t}\n\t\t\tif err := arr.Put(uint32(0), values); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\t// Make sure unmarshaling works on slices containing pointers\n\t\t\tretrievedVal := make([]*customEncoding, numCPU)\n\t\t\tif err := arr.Lookup(uint32(0), retrievedVal); err == nil {\n\t\t\t\tt.Fatal(\"Slices with nil values should generate error\")\n\t\t\t}\n\t\t\tfor i := range retrievedVal {\n\t\t\t\tretrievedVal[i] = &customEncoding{}\n\t\t\t}\n\t\t\tif err := arr.Lookup(uint32(0), retrievedVal); err != nil {\n\t\t\t\tt.Fatal(\"Can't retrieve key 0:\", err)\n\t\t\t}\n\t\t\tvar retrieved []*customEncoding\n\t\t\tif err := arr.Lookup(uint32(0), &retrieved); err != nil {\n\t\t\t\tt.Fatal(\"Can't retrieve key 0:\", err)\n\t\t\t}\n\n\t\t\tfor i, want := range []string{\"HELLO\", \"WORLD\"} {\n\t\t\t\tif retrieved[i] == nil {\n\t\t\t\t\tt.Error(\"First item is nil\")\n\t\t\t\t} else if have := retrieved[i].data; have != want {\n\t\t\t\t\tt.Errorf(\"Put doesn't use BinaryMarshaler, expected %s but got %s\", want, have)\n\t\t\t\t}\n\t\t\t}\n\n\t\t})\n\t}\n}\n\ntype bpfCgroupStorageKey struct {\n\tCgroupInodeId uint64\n\tAttachType    AttachType\n\t_             [4]byte // Padding\n}\n\nfunc TestCgroupPerCPUStorageMarshaling(t *testing.T) {\n\tnumCPU := MustPossibleCPU()\n\tif numCPU < 2 {\n\t\tt.Skip(\"Test requires at least two CPUs\")\n\t}\n\ttestutils.SkipOnOldKernel(t, \"5.9\", \"per-CPU CGoup storage with write from user space support\")\n\n\tcgroup := testutils.CreateCgroup(t)\n\n\tarr, err := NewMap(&MapSpec{\n\t\tType:      PerCPUCGroupStorage,\n\t\tKeySize:   uint32(unsafe.Sizeof(bpfCgroupStorageKey{})),\n\t\tValueSize: uint32(unsafe.Sizeof(uint64(0))),\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tt.Cleanup(func() {\n\t\tarr.Close()\n\t})\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tType:       CGroupSKB,\n\t\tAttachType: AttachCGroupInetEgress,\n\t\tLicense:    \"MIT\",\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadMapPtr(asm.R1, arr.FD()),\n\t\t\tasm.Mov.Imm(asm.R2, 0),\n\t\t\tasm.FnGetLocalStorage.Call(),\n\t\t\tasm.Mov.Imm(asm.R0, 0),\n\t\t\tasm.Return(),\n\t\t},\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tprogAttachAttrs := sys.ProgAttachAttr{\n\t\tTargetFdOrIfindex: uint32(cgroup.Fd()),\n\t\tAttachBpfFd:       uint32(prog.FD()),\n\t\tAttachType:        uint32(AttachCGroupInetEgress),\n\t\tAttachFlags:       0,\n\t\tReplaceBpfFd:      0,\n\t}\n\terr = sys.ProgAttach(&progAttachAttrs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer func() {\n\t\tattr := sys.ProgDetachAttr{\n\t\t\tTargetFdOrIfindex: uint32(cgroup.Fd()),\n\t\t\tAttachBpfFd:       uint32(prog.FD()),\n\t\t\tAttachType:        uint32(AttachCGroupInetEgress),\n\t\t}\n\t\tif err := sys.ProgDetach(&attr); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}()\n\n\tvar mapKey = &bpfCgroupStorageKey{\n\t\tCgroupInodeId: testutils.GetCgroupIno(t, cgroup),\n\t\tAttachType:    AttachCGroupInetEgress,\n\t}\n\n\tvalues := []uint64{1, 2}\n\tif err := arr.Put(mapKey, values); err != nil {\n\t\tt.Fatalf(\"Can't set cgroup %s storage: %s\", cgroup.Name(), err)\n\t}\n\n\tvar retrieved []uint64\n\tif err := arr.Lookup(mapKey, &retrieved); err != nil {\n\t\tt.Fatalf(\"Can't retrieve cgroup %s storage: %s\", cgroup.Name(), err)\n\t}\n\n\tfor i, want := range []uint64{1, 2} {\n\t\tif retrieved[i] == 0 {\n\t\t\tt.Errorf(\"Item %d is 0\", i)\n\t\t} else if have := retrieved[i]; have != want {\n\t\t\tt.Errorf(\"PerCPUCGroupStorage map is not correctly unmarshaled, expected %d but got %d\", want, have)\n\t\t}\n\t}\n}\n\nfunc TestMapMarshalUnsafe(t *testing.T) {\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\tkey := uint32(1)\n\tvalue := uint32(42)\n\n\tif err := m.Put(unsafe.Pointer(&key), unsafe.Pointer(&value)); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar res uint32\n\tif err := m.Lookup(unsafe.Pointer(&key), unsafe.Pointer(&res)); err != nil {\n\t\tt.Fatal(\"Can't get item:\", err)\n\t}\n\n\tvar sum uint32\n\titer := m.Iterate()\n\tfor iter.Next(&key, unsafe.Pointer(&res)) {\n\t\tsum += res\n\t}\n\tif err := iter.Err(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif res != 42 {\n\t\tt.Fatalf(\"Expected 42, got %d\", res)\n\t}\n\n\titer = m.Iterate()\n\titer.Next(unsafe.Pointer(&key), &res)\n\tif err := iter.Err(); err != nil {\n\t\tt.Error(err)\n\t}\n\tif key != 1 {\n\t\tt.Errorf(\"Expected key 1, got %d\", key)\n\t}\n\n\tif err := m.Delete(unsafe.Pointer(&key)); err != nil {\n\t\tt.Fatal(\"Can't delete:\", err)\n\t}\n}\n\nfunc TestMapName(t *testing.T) {\n\tif err := haveObjName(); err != nil {\n\t\tt.Skip(err)\n\t}\n\n\tm, err := NewMap(&MapSpec{\n\t\tName:       \"test\",\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m.Close()\n\n\tvar info sys.MapInfo\n\tif err := sys.ObjInfo(m.fd, &info); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif name := unix.ByteSliceToString(info.Name[:]); name != \"test\" {\n\t\tt.Error(\"Expected name to be test, got\", name)\n\t}\n}\n\nfunc TestMapFromFD(t *testing.T) {\n\tm := createArray(t)\n\n\tif err := m.Put(uint32(0), uint32(123)); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// If you're thinking about copying this, don't. Use\n\t// Clone() instead.\n\tm2, err := NewMapFromFD(dupFD(t, m.FD()))\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer m2.Close()\n\n\tvar val uint32\n\tif err := m2.Lookup(uint32(0), &val); err != nil {\n\t\tt.Fatal(\"Can't look up key:\", err)\n\t}\n\n\tif val != 123 {\n\t\tt.Error(\"Wrong value\")\n\t}\n}\n\nfunc TestMapContents(t *testing.T) {\n\tspec := &MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t\tContents: []MapKV{\n\t\t\t{uint32(0), uint32(23)},\n\t\t\t{uint32(1), uint32(42)},\n\t\t},\n\t}\n\n\tm, err := NewMap(spec)\n\tif err != nil {\n\t\tt.Fatal(\"Can't create map:\", err)\n\t}\n\tdefer m.Close()\n\n\tvar value uint32\n\tif err := m.Lookup(uint32(0), &value); err != nil {\n\t\tt.Error(\"Can't look up key 0:\", err)\n\t} else if value != 23 {\n\t\tt.Errorf(\"Incorrect value for key 0, expected 23, have %d\", value)\n\t}\n\n\tif err := m.Lookup(uint32(1), &value); err != nil {\n\t\tt.Error(\"Can't look up key 1:\", err)\n\t} else if value != 42 {\n\t\tt.Errorf(\"Incorrect value for key 0, expected 23, have %d\", value)\n\t}\n\n\tspec.Contents = []MapKV{\n\t\t// Key is larger than MaxEntries\n\t\t{uint32(14), uint32(0)},\n\t}\n\n\tif _, err = NewMap(spec); err == nil {\n\t\tt.Error(\"Invalid contents should be rejected\")\n\t}\n}\n\nfunc TestMapFreeze(t *testing.T) {\n\tarr := createArray(t)\n\n\terr := arr.Freeze()\n\ttestutils.SkipIfNotSupported(t, err)\n\n\tif err != nil {\n\t\tt.Fatal(\"Can't freeze map:\", err)\n\t}\n\n\tif err := arr.Put(uint32(0), uint32(1)); err == nil {\n\t\tt.Error(\"Freeze doesn't prevent modification from user space\")\n\t}\n}\n\nfunc TestMapGetNextID(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.13\", \"bpf_map_get_next_id\")\n\tvar next MapID\n\tvar err error\n\n\t// Ensure there is at least one map on the system.\n\t_ = newHash(t)\n\n\tif next, err = MapGetNextID(MapID(0)); err != nil {\n\t\tt.Fatal(\"Can't get next ID:\", err)\n\t}\n\tif next == MapID(0) {\n\t\tt.Fatal(\"Expected next ID other than 0\")\n\t}\n\n\t// As there can be multiple eBPF maps, we loop over all of them and\n\t// make sure, the IDs increase and the last call will return ErrNotExist\n\tfor {\n\t\tlast := next\n\t\tif next, err = MapGetNextID(last); err != nil {\n\t\t\tif !errors.Is(err, os.ErrNotExist) {\n\t\t\t\tt.Fatal(\"Expected ErrNotExist, got:\", err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tif next <= last {\n\t\t\tt.Fatalf(\"Expected next ID (%d) to be higher than the last ID (%d)\", next, last)\n\t\t}\n\t}\n}\n\nfunc TestNewMapFromID(t *testing.T) {\n\thash := newHash(t)\n\n\tinfo, err := hash.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't get map info:\", err)\n\t}\n\n\tid, ok := info.ID()\n\tif !ok {\n\t\tt.Skip(\"Map ID not supported\")\n\t}\n\n\thash2, err := NewMapFromID(id)\n\tif err != nil {\n\t\tt.Fatalf(\"Can't get map for ID %d: %v\", id, err)\n\t}\n\thash2.Close()\n\n\t// As there can be multiple maps, we use max(uint32) as MapID to trigger an expected error.\n\t_, err = NewMapFromID(MapID(math.MaxUint32))\n\tif !errors.Is(err, os.ErrNotExist) {\n\t\tt.Fatal(\"Expected ErrNotExist, got:\", err)\n\t}\n}\n\nfunc TestMapPinning(t *testing.T) {\n\ttmp := testutils.TempBPFFS(t)\n\n\tspec := &MapSpec{\n\t\tName:       \"test\",\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tPinning:    PinByName,\n\t}\n\n\tm1, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tif err != nil {\n\t\tt.Fatal(\"Can't create map:\", err)\n\t}\n\tdefer m1.Close()\n\tpinned := m1.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tm1Info, err := m1.Info()\n\tqt.Assert(t, qt.IsNil(err))\n\n\tif err := m1.Put(uint32(0), uint32(42)); err != nil {\n\t\tt.Fatal(\"Can't write value:\", err)\n\t}\n\n\tm2, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Can't create map:\", err)\n\t}\n\tdefer m2.Close()\n\n\tm2Info, err := m2.Info()\n\tqt.Assert(t, qt.IsNil(err))\n\n\tif m1ID, ok := m1Info.ID(); ok {\n\t\tm2ID, _ := m2Info.ID()\n\t\tqt.Assert(t, qt.Equals(m2ID, m1ID))\n\t}\n\n\tvar value uint32\n\tif err := m2.Lookup(uint32(0), &value); err != nil {\n\t\tt.Fatal(\"Can't read from map:\", err)\n\t}\n\n\tif value != 42 {\n\t\tt.Fatal(\"Pinning doesn't use pinned maps\")\n\t}\n\n\tspec.KeySize = 8\n\tspec.ValueSize = 8\n\tm3, err := NewMapWithOptions(spec, MapOptions{PinPath: tmp})\n\tif err == nil {\n\t\tm3.Close()\n\t\tt.Fatalf(\"Opening a pinned map with a mismatching spec did not fail\")\n\t}\n\tif !errors.Is(err, ErrMapIncompatible) {\n\t\tt.Fatalf(\"Opening a pinned map with a mismatching spec failed with the wrong error\")\n\t}\n\n\t// Check if error string mentions both KeySize and ValueSize.\n\tqt.Assert(t, qt.StringContains(err.Error(), \"KeySize\"))\n\tqt.Assert(t, qt.StringContains(err.Error(), \"ValueSize\"))\n}\n\nfunc TestMapHandle(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.18\", \"btf_id in map info\")\n\n\tkv := &btf.Int{Size: 4}\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    kv.Size,\n\t\tValueSize:  kv.Size,\n\t\tKey:        kv,\n\t\tValue:      kv,\n\t\tMaxEntries: 1,\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m.Close()\n\n\th, err := m.Handle()\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.IsNotNil(h))\n\tdefer h.Close()\n\n\tspec, err := h.Spec(nil)\n\tqt.Assert(t, qt.IsNil(err))\n\n\ttyp, err := spec.TypeByID(1)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.ContentEquals(typ, btf.Type(kv)))\n}\n\nfunc TestPerfEventArrayCompatible(t *testing.T) {\n\tms := &MapSpec{\n\t\tType: PerfEventArray,\n\t}\n\n\tm, err := NewMap(ms)\n\tqt.Assert(t, qt.IsNil(err))\n\tdefer m.Close()\n\n\tqt.Assert(t, qt.IsNil(ms.Compatible(m)))\n\n\tms.MaxEntries = m.MaxEntries() - 1\n\tqt.Assert(t, qt.IsNotNil(ms.Compatible(m)))\n}\n\nfunc TestLoadWrongPin(t *testing.T) {\n\tp := mustSocketFilter(t)\n\tm := newHash(t)\n\ttmp := testutils.TempBPFFS(t)\n\n\tppath := filepath.Join(tmp, \"prog\")\n\tmpath := filepath.Join(tmp, \"map\")\n\n\tqt.Assert(t, qt.IsNil(m.Pin(mpath)))\n\tqt.Assert(t, qt.IsNil(p.Pin(ppath)))\n\n\tt.Run(\"Program\", func(t *testing.T) {\n\t\tlp, err := LoadPinnedProgram(ppath, nil)\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.IsNil(lp.Close()))\n\n\t\t_, err = LoadPinnedProgram(mpath, nil)\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t})\n\n\tt.Run(\"Map\", func(t *testing.T) {\n\t\tlm, err := LoadPinnedMap(mpath, nil)\n\t\ttestutils.SkipIfNotSupported(t, err)\n\t\tqt.Assert(t, qt.IsNil(err))\n\t\tqt.Assert(t, qt.IsNil(lm.Close()))\n\n\t\t_, err = LoadPinnedMap(ppath, nil)\n\t\tqt.Assert(t, qt.IsNotNil(err))\n\t})\n}\n\ntype benchValue struct {\n\tID      uint32\n\tVal16   uint16\n\tVal16_2 uint16\n\tName    [8]byte\n\tLID     uint64\n}\n\ntype customBenchValue benchValue\n\nfunc (cbv *customBenchValue) UnmarshalBinary(buf []byte) error {\n\tcbv.ID = internal.NativeEndian.Uint32(buf)\n\tcbv.Val16 = internal.NativeEndian.Uint16(buf[4:])\n\tcbv.Val16_2 = internal.NativeEndian.Uint16(buf[6:])\n\tcopy(cbv.Name[:], buf[8:])\n\tcbv.LID = internal.NativeEndian.Uint64(buf[16:])\n\treturn nil\n}\n\nfunc (cbv *customBenchValue) MarshalBinary() ([]byte, error) {\n\tbuf := make([]byte, 24)\n\tinternal.NativeEndian.PutUint32(buf, cbv.ID)\n\tinternal.NativeEndian.PutUint16(buf[4:], cbv.Val16)\n\tinternal.NativeEndian.PutUint16(buf[6:], cbv.Val16_2)\n\tcopy(buf[8:], cbv.Name[:])\n\tinternal.NativeEndian.PutUint64(buf[16:], cbv.LID)\n\treturn buf, nil\n}\n\ntype benchKey struct {\n\tid uint64\n}\n\nfunc (bk *benchKey) MarshalBinary() ([]byte, error) {\n\tbuf := make([]byte, 8)\n\tinternal.NativeEndian.PutUint64(buf, bk.id)\n\treturn buf, nil\n}\n\nfunc BenchmarkMarshaling(b *testing.B) {\n\tnewMap := func(valueSize uint32) *Map {\n\t\tm, err := NewMap(&MapSpec{\n\t\t\tType:       Hash,\n\t\t\tKeySize:    8,\n\t\t\tValueSize:  valueSize,\n\t\t\tMaxEntries: 1,\n\t\t})\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\treturn m\n\t}\n\n\tkey := uint64(0)\n\n\tm := newMap(24)\n\tif err := m.Put(key, benchValue{}); err != nil {\n\t\tb.Fatal(err)\n\t}\n\tb.Cleanup(func() { m.Close() })\n\n\tb.Run(\"ValueUnmarshalReflect\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar value benchValue\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(unsafe.Pointer(&key), &value)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"KeyMarshalReflect\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar value benchValue\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(&key, unsafe.Pointer(&value))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"ValueBinaryUnmarshaler\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar value customBenchValue\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(unsafe.Pointer(&key), &value)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"KeyBinaryMarshaler\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar key benchKey\n\t\tvar value customBenchValue\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(&key, unsafe.Pointer(&value))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"KeyValueUnsafe\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar value benchValue\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(unsafe.Pointer(&key), unsafe.Pointer(&value))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkPerCPUMarshalling(b *testing.B) {\n\tkey := uint64(1)\n\tval := make([]uint64, MustPossibleCPU())\n\tfor i := range val {\n\t\tval[i] = uint64(i)\n\t}\n\n\tm, err := NewMap(&MapSpec{\n\t\tType:       PerCPUHash,\n\t\tKeySize:    8,\n\t\tValueSize:  8,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tb.Cleanup(func() { m.Close() })\n\tif err := m.Put(key, val[0:]); err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tb.Run(\"reflection\", func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tvar value []uint64\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(unsafe.Pointer(&key), &value)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(\"Can't get key:\", err)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkMap(b *testing.B) {\n\tm, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\tb.Cleanup(func() { m.Close() })\n\n\tif err := m.Put(uint32(0), uint32(42)); err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tb.Run(\"Lookup\", func(b *testing.B) {\n\t\tvar key, value uint32\n\n\t\tb.ReportAllocs()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Lookup(unsafe.Pointer(&key), unsafe.Pointer(&value))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"Update\", func(b *testing.B) {\n\t\tvar key, value uint32\n\n\t\tb.ReportAllocs()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Update(unsafe.Pointer(&key), unsafe.Pointer(&value), UpdateAny)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"NextKey\", func(b *testing.B) {\n\t\tvar key uint32\n\n\t\tb.ReportAllocs()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.NextKey(nil, unsafe.Pointer(&key))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\t\t}\n\t})\n\n\tb.Run(\"Delete\", func(b *testing.B) {\n\t\tvar key uint32\n\n\t\tb.ReportAllocs()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\terr := m.Delete(unsafe.Pointer(&key))\n\t\t\tif err != nil && !errors.Is(err, ErrKeyNotExist) {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkIterate(b *testing.B) {\n\tfor _, mt := range []MapType{Hash, PerCPUHash} {\n\t\tm, err := NewMap(&MapSpec{\n\t\t\tType:       mt,\n\t\t\tKeySize:    8,\n\t\t\tValueSize:  8,\n\t\t\tMaxEntries: 1000,\n\t\t})\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tb.Cleanup(func() {\n\t\t\tm.Close()\n\t\t})\n\t\tpossibleCPU := 1\n\t\tif m.Type().hasPerCPUValue() {\n\t\t\tpossibleCPU = MustPossibleCPU()\n\t\t}\n\t\tvar (\n\t\t\tn      = m.MaxEntries()\n\t\t\tkeys   = make([]uint64, n)\n\t\t\tvalues = make([]uint64, n*uint32(possibleCPU))\n\t\t)\n\n\t\tfor i := 0; uint32(i) < n; i++ {\n\t\t\tkeys[i] = uint64(i)\n\t\t\tfor j := 0; j < possibleCPU; j++ {\n\t\t\t\tvalues[i] = uint64((i * possibleCPU) + j)\n\t\t\t}\n\t\t}\n\n\t\t_, err = m.BatchUpdate(keys, values, nil)\n\t\ttestutils.SkipIfNotSupported(b, err)\n\t\tqt.Assert(b, qt.IsNil(err))\n\n\t\tb.Run(m.Type().String(), func(b *testing.B) {\n\t\t\tb.Run(\"MapIterator\", func(b *testing.B) {\n\t\t\t\tvar k uint64\n\t\t\t\tv := make([]uint64, possibleCPU)\n\n\t\t\t\tb.ReportAllocs()\n\t\t\t\tb.ResetTimer()\n\n\t\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\t\titer := m.Iterate()\n\t\t\t\t\tfor iter.Next(&k, v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := iter.Err(); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tb.Run(\"MapIteratorDelete\", func(b *testing.B) {\n\t\t\t\tvar k uint64\n\t\t\t\tv := make([]uint64, possibleCPU)\n\n\t\t\t\tb.ReportAllocs()\n\t\t\t\tb.ResetTimer()\n\n\t\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\t\tb.StopTimer()\n\t\t\t\t\tif _, err := m.BatchUpdate(keys, values, nil); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t\tb.StartTimer()\n\n\t\t\t\t\titer := m.Iterate()\n\t\t\t\t\tfor iter.Next(&k, &v) {\n\t\t\t\t\t\tif err := m.Delete(&k); err != nil {\n\t\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif err := iter.Err(); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tb.Run(\"BatchLookup\", func(b *testing.B) {\n\t\t\t\tk := make([]uint64, m.MaxEntries())\n\t\t\t\tv := make([]uint64, m.MaxEntries()*uint32(possibleCPU))\n\n\t\t\t\tb.ReportAllocs()\n\t\t\t\tb.ResetTimer()\n\n\t\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\t\tvar cursor MapBatchCursor\n\t\t\t\t\tfor {\n\t\t\t\t\t\t_, err := m.BatchLookup(&cursor, k, v, nil)\n\t\t\t\t\t\tif errors.Is(err, ErrKeyNotExist) {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tb.Run(\"BatchLookupAndDelete\", func(b *testing.B) {\n\t\t\t\tk := make([]uint64, m.MaxEntries())\n\t\t\t\tv := make([]uint64, m.MaxEntries()*uint32(possibleCPU))\n\n\t\t\t\tb.ReportAllocs()\n\t\t\t\tb.ResetTimer()\n\n\t\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\t\tb.StopTimer()\n\t\t\t\t\tif _, err := m.BatchUpdate(keys, values, nil); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t\tb.StartTimer()\n\n\t\t\t\t\tvar cursor MapBatchCursor\n\t\t\t\t\tfor {\n\t\t\t\t\t\t_, err := m.BatchLookupAndDelete(&cursor, k, v, nil)\n\t\t\t\t\t\tif errors.Is(err, ErrKeyNotExist) {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tb.Run(\"BatchDelete\", func(b *testing.B) {\n\t\t\t\tb.ReportAllocs()\n\t\t\t\tb.ResetTimer()\n\n\t\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\t\tb.StopTimer()\n\t\t\t\t\tif _, err := m.BatchUpdate(keys, values, nil); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t\tb.StartTimer()\n\n\t\t\t\t\tif _, err := m.BatchDelete(keys, nil); err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\t\t})\n\t}\n}\n\n// Per CPU maps store a distinct value for each CPU. They are useful\n// to collect metrics.\nfunc ExampleMap_perCPU() {\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       PerCPUArray,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer arr.Close()\n\n\tpossibleCPUs := MustPossibleCPU()\n\tperCPUValues := map[uint32]uint32{\n\t\t0: 4,\n\t\t1: 5,\n\t}\n\n\tfor k, v := range perCPUValues {\n\t\t// We set each perCPU slots to the same value.\n\t\tvalues := make([]uint32, possibleCPUs)\n\t\tfor i := range values {\n\t\t\tvalues[i] = v\n\t\t}\n\t\tif err := arr.Put(k, values); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}\n\n\tfor k := 0; k < 2; k++ {\n\t\tvar values []uint32\n\t\tif err := arr.Lookup(uint32(k), &values); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\t// Note we will print an unexpected message if this is not true.\n\t\tfmt.Printf(\"Value of key %v on all CPUs: %v\\n\", k, values[0])\n\t}\n\tvar (\n\t\tkey     uint32\n\t\tentries = arr.Iterate()\n\t)\n\n\tvar values []uint32\n\tfor entries.Next(&key, &values) {\n\t\texpected, ok := perCPUValues[key]\n\t\tif !ok {\n\t\t\tfmt.Printf(\"Unexpected key %v\\n\", key)\n\t\t\tcontinue\n\t\t}\n\n\t\tfor i, n := range values {\n\t\t\tif n != expected {\n\t\t\t\tfmt.Printf(\"Key %v, Value for cpu %v is %v not %v\\n\",\n\t\t\t\t\tkey, i, n, expected)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tpanic(err)\n\t}\n\t// Output:\n\t// Value of key 0 on all CPUs: 4\n\t// Value of key 1 on all CPUs: 5\n}\n\n// It is possible to use unsafe.Pointer to avoid marshalling\n// and copy overhead. It is the responsibility of the caller to ensure\n// the correct size of unsafe.Pointers.\n//\n// Note that using unsafe.Pointer is only marginally faster than\n// implementing Marshaler on the type.\nfunc ExampleMap_zeroCopy() {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer hash.Close()\n\n\tkey := [5]byte{'h', 'e', 'l', 'l', 'o'}\n\tvalue := uint32(23)\n\n\tif err := hash.Put(unsafe.Pointer(&key), unsafe.Pointer(&value)); err != nil {\n\t\tpanic(err)\n\t}\n\n\tvalue = 0\n\tif err := hash.Lookup(unsafe.Pointer(&key), unsafe.Pointer(&value)); err != nil {\n\t\tpanic(\"can't get value:\" + err.Error())\n\t}\n\n\tfmt.Printf(\"The value is: %d\\n\", value)\n\t// Output: The value is: 23\n}\n\nfunc ExampleMap_NextKey() {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t\tContents: []MapKV{\n\t\t\t{\"hello\", uint32(21)},\n\t\t\t{\"world\", uint32(42)},\n\t\t},\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer hash.Close()\n\n\tvar cur, next string\n\tvar keys []string\n\n\tfor err = hash.NextKey(nil, &next); ; err = hash.NextKey(cur, &next) {\n\t\tif errors.Is(err, ErrKeyNotExist) {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tkeys = append(keys, next)\n\t\tcur = next\n\t}\n\n\t// Order of keys is non-deterministic due to randomized map seed\n\tsort.Strings(keys)\n\tfmt.Printf(\"Keys are %v\\n\", keys)\n\t// Output: Keys are [hello world]\n}\n\n// ExampleMap_Iterate demonstrates how to iterate over all entries\n// in a map.\nfunc ExampleMap_Iterate() {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t\tContents: []MapKV{\n\t\t\t{\"hello\", uint32(21)},\n\t\t\t{\"world\", uint32(42)},\n\t\t},\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer hash.Close()\n\n\tvar (\n\t\tkey     string\n\t\tvalue   uint32\n\t\tentries = hash.Iterate()\n\t)\n\n\tvalues := make(map[string]uint32)\n\tfor entries.Next(&key, &value) {\n\t\t// Order of keys is non-deterministic due to randomized map seed\n\t\tvalues[key] = value\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tpanic(fmt.Sprint(\"Iterator encountered an error:\", err))\n\t}\n\n\tfor k, v := range values {\n\t\tfmt.Printf(\"key: %s, value: %d\\n\", k, v)\n\t}\n\n\t// Unordered output:\n\t// key: hello, value: 21\n\t// key: world, value: 42\n}\n\n// It is possible to iterate nested maps and program arrays by\n// unmarshaling into a *Map or *Program.\nfunc ExampleMap_Iterate_nestedMapsAndProgramArrays() {\n\tinner := &MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 2,\n\t\tContents: []MapKV{\n\t\t\t{uint32(0), uint32(1)},\n\t\t\t{uint32(1), uint32(2)},\n\t\t},\n\t}\n\tim, err := NewMap(inner)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer im.Close()\n\n\touter := &MapSpec{\n\t\tType:       ArrayOfMaps,\n\t\tInnerMap:   inner,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t\tContents: []MapKV{\n\t\t\t{uint32(0), im},\n\t\t},\n\t}\n\tarrayOfMaps, err := NewMap(outer)\n\tif errors.Is(err, internal.ErrNotSupported) {\n\t\t// Fake the output if on very old kernel.\n\t\tfmt.Println(\"outerKey: 0\")\n\t\tfmt.Println(\"\\tinnerKey 0 innerValue 1\")\n\t\tfmt.Println(\"\\tinnerKey 1 innerValue 2\")\n\t\treturn\n\t}\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer arrayOfMaps.Close()\n\n\tvar (\n\t\tkey     uint32\n\t\tm       *Map\n\t\tentries = arrayOfMaps.Iterate()\n\t)\n\tfor entries.Next(&key, &m) {\n\t\t// Make sure that the iterated map is closed after\n\t\t// we are done.\n\t\tdefer m.Close()\n\n\t\t// Order of keys is non-deterministic due to randomized map seed\n\t\tfmt.Printf(\"outerKey: %v\\n\", key)\n\n\t\tvar innerKey, innerValue uint32\n\t\titems := m.Iterate()\n\t\tfor items.Next(&innerKey, &innerValue) {\n\t\t\tfmt.Printf(\"\\tinnerKey %v innerValue %v\\n\", innerKey, innerValue)\n\t\t}\n\t\tif err := items.Err(); err != nil {\n\t\t\tpanic(fmt.Sprint(\"Inner Iterator encountered an error:\", err))\n\t\t}\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tpanic(fmt.Sprint(\"Iterator encountered an error:\", err))\n\t}\n\t// Output:\n\t// outerKey: 0\n\t//\tinnerKey 0 innerValue 1\n\t// \tinnerKey 1 innerValue 2\n}\n"
        },
        {
          "name": "marshaler_example_test.go",
          "type": "blob",
          "size": 1.087890625,
          "content": "package ebpf\n\nimport (\n\t\"encoding\"\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Assert that customEncoding implements the correct interfaces.\nvar (\n\t_ encoding.BinaryMarshaler   = (*customEncoding)(nil)\n\t_ encoding.BinaryUnmarshaler = (*customEncoding)(nil)\n)\n\ntype customEncoding struct {\n\tdata string\n}\n\nfunc (ce *customEncoding) MarshalBinary() ([]byte, error) {\n\treturn []byte(strings.ToUpper(ce.data)), nil\n}\n\nfunc (ce *customEncoding) UnmarshalBinary(buf []byte) error {\n\tce.data = string(buf)\n\treturn nil\n}\n\n// ExampleMarshaler shows how to use custom encoding with map methods.\nfunc Example_customMarshaler() {\n\thash, err := NewMap(&MapSpec{\n\t\tType:       Hash,\n\t\tKeySize:    5,\n\t\tValueSize:  4,\n\t\tMaxEntries: 10,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer hash.Close()\n\n\tif err := hash.Put(&customEncoding{\"hello\"}, uint32(111)); err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar (\n\t\tkey     customEncoding\n\t\tvalue   uint32\n\t\tentries = hash.Iterate()\n\t)\n\n\tfor entries.Next(&key, &value) {\n\t\tfmt.Printf(\"key: %s, value: %d\\n\", key.data, value)\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Output: key: HELLO, value: 111\n}\n"
        },
        {
          "name": "marshalers.go",
          "type": "blob",
          "size": 5.99609375,
          "content": "package ebpf\n\nimport (\n\t\"encoding\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"slices\"\n\t\"unsafe\"\n\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/sysenc\"\n)\n\n// marshalMapSyscallInput converts an arbitrary value into a pointer suitable\n// to be passed to the kernel.\n//\n// As an optimization, it returns the original value if it is an\n// unsafe.Pointer.\nfunc marshalMapSyscallInput(data any, length int) (sys.Pointer, error) {\n\tif ptr, ok := data.(unsafe.Pointer); ok {\n\t\treturn sys.NewPointer(ptr), nil\n\t}\n\n\tbuf, err := sysenc.Marshal(data, length)\n\tif err != nil {\n\t\treturn sys.Pointer{}, err\n\t}\n\n\treturn buf.Pointer(), nil\n}\n\nfunc makeMapSyscallOutput(dst any, length int) sysenc.Buffer {\n\tif ptr, ok := dst.(unsafe.Pointer); ok {\n\t\treturn sysenc.UnsafeBuffer(ptr)\n\t}\n\n\t_, ok := dst.(encoding.BinaryUnmarshaler)\n\tif ok {\n\t\treturn sysenc.SyscallOutput(nil, length)\n\t}\n\n\treturn sysenc.SyscallOutput(dst, length)\n}\n\n// appendPerCPUSlice encodes a slice containing one value per\n// possible CPU into a buffer of bytes.\n//\n// Values are initialized to zero if the slice has less elements than CPUs.\nfunc appendPerCPUSlice(buf []byte, slice any, possibleCPUs, elemLength, alignedElemLength int) ([]byte, error) {\n\tsliceType := reflect.TypeOf(slice)\n\tif sliceType.Kind() != reflect.Slice {\n\t\treturn nil, errors.New(\"per-CPU value requires slice\")\n\t}\n\n\tsliceValue := reflect.ValueOf(slice)\n\tsliceLen := sliceValue.Len()\n\tif sliceLen > possibleCPUs {\n\t\treturn nil, fmt.Errorf(\"per-CPU value greater than number of CPUs\")\n\t}\n\n\t// Grow increases the slice's capacity, _if_necessary_\n\tbuf = slices.Grow(buf, alignedElemLength*possibleCPUs)\n\tfor i := 0; i < sliceLen; i++ {\n\t\telem := sliceValue.Index(i).Interface()\n\t\telemBytes, err := sysenc.Marshal(elem, elemLength)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tbuf = elemBytes.AppendTo(buf)\n\t\tbuf = append(buf, make([]byte, alignedElemLength-elemLength)...)\n\t}\n\n\t// Ensure buf is zero-padded full size.\n\tbuf = append(buf, make([]byte, (possibleCPUs-sliceLen)*alignedElemLength)...)\n\n\treturn buf, nil\n}\n\n// marshalPerCPUValue encodes a slice containing one value per\n// possible CPU into a buffer of bytes.\n//\n// Values are initialized to zero if the slice has less elements than CPUs.\nfunc marshalPerCPUValue(slice any, elemLength int) (sys.Pointer, error) {\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn sys.Pointer{}, err\n\t}\n\n\talignedElemLength := internal.Align(elemLength, 8)\n\tbuf := make([]byte, 0, alignedElemLength*possibleCPUs)\n\tbuf, err = appendPerCPUSlice(buf, slice, possibleCPUs, elemLength, alignedElemLength)\n\tif err != nil {\n\t\treturn sys.Pointer{}, err\n\t}\n\n\treturn sys.NewSlicePointer(buf), nil\n}\n\n// marshalBatchPerCPUValue encodes a batch-sized slice of slices containing\n// one value per possible CPU into a buffer of bytes.\nfunc marshalBatchPerCPUValue(slice any, batchLen, elemLength int) ([]byte, error) {\n\tsliceType := reflect.TypeOf(slice)\n\tif sliceType.Kind() != reflect.Slice {\n\t\treturn nil, fmt.Errorf(\"batch value requires a slice\")\n\t}\n\tsliceValue := reflect.ValueOf(slice)\n\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif sliceValue.Len() != batchLen*possibleCPUs {\n\t\treturn nil, fmt.Errorf(\"per-CPU slice has incorrect length, expected %d, got %d\",\n\t\t\tbatchLen*possibleCPUs, sliceValue.Len())\n\t}\n\talignedElemLength := internal.Align(elemLength, 8)\n\tbuf := make([]byte, 0, batchLen*alignedElemLength*possibleCPUs)\n\tfor i := 0; i < batchLen; i++ {\n\t\tbatch := sliceValue.Slice(i*possibleCPUs, (i+1)*possibleCPUs).Interface()\n\t\tbuf, err = appendPerCPUSlice(buf, batch, possibleCPUs, elemLength, alignedElemLength)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"batch %d: %w\", i, err)\n\t\t}\n\t}\n\treturn buf, nil\n}\n\n// unmarshalPerCPUValue decodes a buffer into a slice containing one value per\n// possible CPU.\n//\n// slice must be a literal slice and not a pointer.\nfunc unmarshalPerCPUValue(slice any, elemLength int, buf []byte) error {\n\tsliceType := reflect.TypeOf(slice)\n\tif sliceType.Kind() != reflect.Slice {\n\t\treturn fmt.Errorf(\"per-CPU value requires a slice\")\n\t}\n\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsliceValue := reflect.ValueOf(slice)\n\tif sliceValue.Len() != possibleCPUs {\n\t\treturn fmt.Errorf(\"per-CPU slice has incorrect length, expected %d, got %d\",\n\t\t\tpossibleCPUs, sliceValue.Len())\n\t}\n\n\tsliceElemType := sliceType.Elem()\n\tsliceElemIsPointer := sliceElemType.Kind() == reflect.Ptr\n\tstride := internal.Align(elemLength, 8)\n\tfor i := 0; i < possibleCPUs; i++ {\n\t\tvar elem any\n\t\tv := sliceValue.Index(i)\n\t\tif sliceElemIsPointer {\n\t\t\tif !v.Elem().CanAddr() {\n\t\t\t\treturn fmt.Errorf(\"per-CPU slice elements cannot be nil\")\n\t\t\t}\n\t\t\telem = v.Elem().Addr().Interface()\n\t\t} else {\n\t\t\telem = v.Addr().Interface()\n\t\t}\n\t\terr := sysenc.Unmarshal(elem, buf[:elemLength])\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cpu %d: %w\", i, err)\n\t\t}\n\n\t\tbuf = buf[stride:]\n\t}\n\treturn nil\n}\n\n// unmarshalBatchPerCPUValue decodes a buffer into a batch-sized slice\n// containing one value per possible CPU.\n//\n// slice must have length batchLen * PossibleCPUs().\nfunc unmarshalBatchPerCPUValue(slice any, batchLen, elemLength int, buf []byte) error {\n\tsliceType := reflect.TypeOf(slice)\n\tif sliceType.Kind() != reflect.Slice {\n\t\treturn fmt.Errorf(\"batch requires a slice\")\n\t}\n\n\tsliceValue := reflect.ValueOf(slice)\n\tpossibleCPUs, err := PossibleCPU()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif sliceValue.Len() != batchLen*possibleCPUs {\n\t\treturn fmt.Errorf(\"per-CPU slice has incorrect length, expected %d, got %d\",\n\t\t\tsliceValue.Len(), batchLen*possibleCPUs)\n\t}\n\n\tfullValueSize := possibleCPUs * internal.Align(elemLength, 8)\n\tif len(buf) != batchLen*fullValueSize {\n\t\treturn fmt.Errorf(\"input buffer has incorrect length, expected %d, got %d\",\n\t\t\tlen(buf), batchLen*fullValueSize)\n\t}\n\n\tfor i := 0; i < batchLen; i++ {\n\t\telem := sliceValue.Slice(i*possibleCPUs, (i+1)*possibleCPUs).Interface()\n\t\tif err := unmarshalPerCPUValue(elem, elemLength, buf[:fullValueSize]); err != nil {\n\t\t\treturn fmt.Errorf(\"batch %d: %w\", i, err)\n\t\t}\n\t\tbuf = buf[fullValueSize:]\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "marshalers_test.go",
          "type": "blob",
          "size": 3.4990234375,
          "content": "package ebpf\n\nimport (\n\t\"testing\"\n\n\t\"github.com/cilium/ebpf/internal\"\n\n\t\"github.com/go-quicktest/qt\"\n)\n\nfunc TestMarshalUnmarshalBatchPerCPUValue(t *testing.T) {\n\tconst (\n\t\tbatchLen   = 3\n\t\telemLength = 4\n\t)\n\tpossibleCPU := MustPossibleCPU()\n\tsliceLen := batchLen * possibleCPU\n\tslice := makeFilledSlice(sliceLen)\n\tbuf, err := marshalBatchPerCPUValue(slice, batchLen, elemLength)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\toutput := make([]uint32, sliceLen)\n\terr = unmarshalBatchPerCPUValue(output, batchLen, elemLength, buf)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tqt.Assert(t, qt.DeepEquals(output, slice))\n}\n\nfunc TestMarshalBatchPerCPUValue(t *testing.T) {\n\tconst (\n\t\tbatchLen   = 3\n\t\telemLength = 4\n\t)\n\tpossibleCPU := MustPossibleCPU()\n\tsliceLen := batchLen * possibleCPU\n\tslice := makeFilledSlice(sliceLen)\n\texpected := make([]byte, sliceLen*internal.Align(elemLength, 8))\n\tb := expected\n\tfor _, elem := range slice {\n\t\tinternal.NativeEndian.PutUint32(b, elem)\n\t\tb = b[8:]\n\t}\n\tbuf, err := marshalBatchPerCPUValue(slice, batchLen, elemLength)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.DeepEquals(buf, expected))\n\n\ttooSmall := slice[:len(slice)-1]\n\tbuf, err = marshalBatchPerCPUValue(tooSmall, batchLen, elemLength)\n\tqt.Assert(t, qt.IsNotNil(err))\n\tqt.Assert(t, qt.HasLen(buf, 0))\n\n\ttooBig := append(slice, 0)\n\tbuf, err = marshalBatchPerCPUValue(tooBig, batchLen, elemLength)\n\tqt.Assert(t, qt.IsNotNil(err))\n\tqt.Assert(t, qt.HasLen(buf, 0))\n}\n\nfunc TestUnmarshalBatchPerCPUValue(t *testing.T) {\n\tconst (\n\t\tbatchLen   = 3\n\t\telemLength = 4\n\t)\n\tpossibleCPU := MustPossibleCPU()\n\toutputLen := batchLen * possibleCPU\n\toutput := make([]uint32, outputLen)\n\texpected := makeFilledSlice(batchLen * possibleCPU)\n\n\tbuf := make([]byte, batchLen*possibleCPU*internal.Align(elemLength, 8))\n\tb := buf\n\tfor _, elem := range expected {\n\t\tinternal.NativeEndian.PutUint32(b, elem)\n\t\tb = b[8:]\n\t}\n\terr := unmarshalBatchPerCPUValue(output, batchLen, elemLength, buf)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.DeepEquals(output, expected))\n\n\ttooSmall := make([]uint32, outputLen-1)\n\terr = unmarshalBatchPerCPUValue(tooSmall, batchLen, elemLength, buf)\n\tqt.Assert(t, qt.IsNotNil(err))\n\n\ttooBig := make([]uint32, outputLen+1)\n\terr = unmarshalBatchPerCPUValue(tooBig, batchLen, elemLength, buf)\n\tqt.Assert(t, qt.IsNotNil(err))\n\n\tempty := make([]uint32, outputLen)\n\ttooSmallBuf := buf[:len(buf)-1]\n\terr = unmarshalBatchPerCPUValue(empty, batchLen, elemLength, tooSmallBuf)\n\tqt.Assert(t, qt.IsNotNil(err))\n\n\ttooBigBuf := append(buf, 0)\n\terr = unmarshalBatchPerCPUValue(empty, batchLen, elemLength, tooBigBuf)\n\tqt.Assert(t, qt.IsNotNil(err))\n}\n\nfunc TestUnmarshalPerCPUValue(t *testing.T) {\n\tpossibleCPUs := MustPossibleCPU()\n\texpected := make([]uint32, possibleCPUs)\n\tfor i := 0; i < possibleCPUs; i++ {\n\t\texpected[i] = uint32(1021 * (i + 1))\n\t}\n\telemLength := 4\n\n\tbuf := make([]byte, possibleCPUs*internal.Align(elemLength, 8))\n\tb := buf\n\tfor _, elem := range expected {\n\t\tinternal.NativeEndian.PutUint32(b, elem)\n\t\tb = b[8:]\n\t}\n\tslice := make([]uint32, possibleCPUs)\n\terr := unmarshalPerCPUValue(slice, elemLength, buf)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tqt.Assert(t, qt.DeepEquals(slice, expected))\n\n\tsmallSlice := make([]uint32, possibleCPUs-1)\n\tqt.Assert(t, qt.IsNotNil(unmarshalPerCPUValue(smallSlice, elemLength, buf)))\n\n\tnilElemSlice := make([]*uint32, possibleCPUs)\n\tqt.Assert(t, qt.IsNotNil(unmarshalPerCPUValue(nilElemSlice, elemLength, buf)))\n}\n\nfunc makeFilledSlice(len int) []uint32 {\n\tslice := make([]uint32, len)\n\tfor i := range slice {\n\t\tslice[i] = uint32(1021 * (i + 1))\n\t}\n\treturn slice\n}\n"
        },
        {
          "name": "memory.go",
          "type": "blob",
          "size": 4.2890625,
          "content": "package ebpf\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"runtime\"\n\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\n// Memory is the building block for accessing the memory of specific bpf map\n// types (Array and Arena at the time of writing) without going through the bpf\n// syscall interface.\n//\n// Given the fd of a bpf map created with the BPF_F_MMAPABLE flag, a shared\n// 'file'-based memory-mapped region can be allocated in the process' address\n// space, exposing the bpf map's memory by simply accessing a memory location.\n\nvar ErrReadOnly = errors.New(\"resource is read-only\")\n\n// Memory implements accessing a Map's memory without making any syscalls.\n// Pay attention to the difference between Go and C struct alignment rules. Use\n// [structs.HostLayout] on supported Go versions to help with alignment.\n//\n// Note on memory coherence: avoid using packed structs in memory shared between\n// user space and eBPF C programs. This drops a struct's memory alignment to 1,\n// forcing the compiler to use single-byte loads and stores for field accesses.\n// This may lead to partially-written data to be observed from user space.\n//\n// On most architectures, the memmove implementation used by Go's copy() will\n// access data in word-sized chunks. If paired with a matching access pattern on\n// the eBPF C side (and if using default memory alignment), accessing shared\n// memory without atomics or other synchronization primitives should be sound\n// for individual values. For accesses beyond a single value, the usual\n// concurrent programming rules apply.\ntype Memory struct {\n\tb  []byte\n\tro bool\n}\n\nfunc newMemory(fd, size int) (*Memory, error) {\n\t// Typically, maps created with BPF_F_RDONLY_PROG remain writable from user\n\t// space until frozen. As a security precaution, the kernel doesn't allow\n\t// mapping bpf map memory as read-write into user space if the bpf map was\n\t// frozen, or if it was created using the RDONLY_PROG flag.\n\t//\n\t// The user would be able to write to the map after freezing (since the kernel\n\t// can't change the protection mode of an already-mapped page), while the\n\t// verifier assumes the contents to be immutable.\n\tb, err := unix.Mmap(fd, 0, size, unix.PROT_READ|unix.PROT_WRITE, unix.MAP_SHARED)\n\n\t// If the map is frozen when an rw mapping is requested, expect EPERM. If the\n\t// map was created with BPF_F_RDONLY_PROG, expect EACCES.\n\tvar ro bool\n\tif errors.Is(err, unix.EPERM) || errors.Is(err, unix.EACCES) {\n\t\tro = true\n\t\tb, err = unix.Mmap(fd, 0, size, unix.PROT_READ, unix.MAP_SHARED)\n\t}\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"setting up memory-mapped region: %w\", err)\n\t}\n\n\tmm := &Memory{\n\t\tb,\n\t\tro,\n\t}\n\truntime.SetFinalizer(mm, (*Memory).close)\n\n\treturn mm, nil\n}\n\nfunc (mm *Memory) close() {\n\tif err := unix.Munmap(mm.b); err != nil {\n\t\tpanic(fmt.Errorf(\"unmapping memory: %w\", err))\n\t}\n\tmm.b = nil\n}\n\n// Size returns the size of the memory-mapped region in bytes.\nfunc (mm *Memory) Size() int {\n\treturn len(mm.b)\n}\n\n// ReadOnly returns true if the memory-mapped region is read-only.\nfunc (mm *Memory) ReadOnly() bool {\n\treturn mm.ro\n}\n\n// bounds returns true if an access at off of the given size is within bounds.\nfunc (mm *Memory) bounds(off uint64, size uint64) bool {\n\treturn off+size < uint64(len(mm.b))\n}\n\n// ReadAt implements [io.ReaderAt]. Useful for creating a new [io.OffsetWriter].\n//\n// See [Memory] for details around memory coherence.\nfunc (mm *Memory) ReadAt(p []byte, off int64) (int, error) {\n\tif mm.b == nil {\n\t\treturn 0, fmt.Errorf(\"memory-mapped region closed\")\n\t}\n\n\tif p == nil {\n\t\treturn 0, fmt.Errorf(\"input buffer p is nil\")\n\t}\n\n\tif off < 0 || off >= int64(len(mm.b)) {\n\t\treturn 0, fmt.Errorf(\"read offset out of range\")\n\t}\n\n\tn := copy(p, mm.b[off:])\n\tif n < len(p) {\n\t\treturn n, io.EOF\n\t}\n\n\treturn n, nil\n}\n\n// WriteAt implements [io.WriterAt]. Useful for creating a new\n// [io.SectionReader].\n//\n// See [Memory] for details around memory coherence.\nfunc (mm *Memory) WriteAt(p []byte, off int64) (int, error) {\n\tif mm.b == nil {\n\t\treturn 0, fmt.Errorf(\"memory-mapped region closed\")\n\t}\n\tif mm.ro {\n\t\treturn 0, fmt.Errorf(\"memory-mapped region not writable: %w\", ErrReadOnly)\n\t}\n\n\tif p == nil {\n\t\treturn 0, fmt.Errorf(\"output buffer p is nil\")\n\t}\n\n\tif off < 0 || off >= int64(len(mm.b)) {\n\t\treturn 0, fmt.Errorf(\"write offset out of range\")\n\t}\n\n\tn := copy(mm.b[off:], p)\n\tif n < len(p) {\n\t\treturn n, io.EOF\n\t}\n\n\treturn n, nil\n}\n"
        },
        {
          "name": "memory_test.go",
          "type": "blob",
          "size": 2.3671875,
          "content": "package ebpf\n\nimport (\n\t\"io\"\n\t\"os\"\n\t\"runtime\"\n\t\"testing\"\n\n\t\"github.com/go-quicktest/qt\"\n\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n)\n\nfunc mustMmapableArray(tb testing.TB, extraFlags uint32) *Map {\n\ttb.Helper()\n\n\tm, err := NewMap(&MapSpec{\n\t\tName:       \"ebpf_mmap\",\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  8,\n\t\tMaxEntries: 8,\n\t\tFlags:      sys.BPF_F_MMAPABLE | extraFlags,\n\t})\n\ttestutils.SkipIfNotSupported(tb, err)\n\tqt.Assert(tb, qt.IsNil(err))\n\ttb.Cleanup(func() {\n\t\tm.Close()\n\t})\n\treturn m\n}\n\nfunc TestMemory(t *testing.T) {\n\tmm, err := mustMmapableArray(t, 0).Memory()\n\tqt.Assert(t, qt.IsNil(err))\n\n\t// The mapping is always at least one page long, and the Map created here fits\n\t// in a single page.\n\tqt.Assert(t, qt.Equals(mm.Size(), os.Getpagesize()))\n\n\t// No BPF_F_RDONLY_PROG flag, so the Memory should be read-write.\n\tqt.Assert(t, qt.IsFalse(mm.ReadOnly()))\n\n\twant := []byte{1, 2, 3, 4, 4, 3, 2, 1}\n\tw := io.NewOffsetWriter(mm, 16)\n\tn, err := w.Write(want)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(n, 8))\n\n\tr := io.NewSectionReader(mm, 16, int64(len(want)))\n\tgot := make([]byte, len(want))\n\tn, err = r.Read(got)\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.Equals(n, len(want)))\n}\n\nfunc TestMemoryBounds(t *testing.T) {\n\tmm, err := mustMmapableArray(t, 0).Memory()\n\tqt.Assert(t, qt.IsNil(err))\n\n\tsize := uint64(mm.Size())\n\tend := size - 1\n\n\tqt.Assert(t, qt.IsTrue(mm.bounds(0, 0)))\n\tqt.Assert(t, qt.IsTrue(mm.bounds(end, 0)))\n\tqt.Assert(t, qt.IsTrue(mm.bounds(end-8, 8)))\n\tqt.Assert(t, qt.IsTrue(mm.bounds(0, end)))\n\n\tqt.Assert(t, qt.IsFalse(mm.bounds(end-8, 9)))\n\tqt.Assert(t, qt.IsFalse(mm.bounds(end, 1)))\n\tqt.Assert(t, qt.IsFalse(mm.bounds(0, size)))\n}\n\nfunc TestMemoryReadOnly(t *testing.T) {\n\trd, err := mustMmapableArray(t, sys.BPF_F_RDONLY_PROG).Memory()\n\tqt.Assert(t, qt.IsNil(err))\n\n\t// BPF_F_RDONLY_PROG flag, so the Memory should be read-only.\n\tqt.Assert(t, qt.IsTrue(rd.ReadOnly()))\n\n\t// Frozen maps can't be mapped rw either.\n\tfrozen := mustMmapableArray(t, 0)\n\tqt.Assert(t, qt.IsNil(frozen.Freeze()))\n\tfz, err := frozen.Memory()\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.IsTrue(fz.ReadOnly()))\n}\n\nfunc TestMemoryUnmap(t *testing.T) {\n\tmm, err := mustMmapableArray(t, 0).Memory()\n\tqt.Assert(t, qt.IsNil(err))\n\n\t// Avoid unmap running twice.\n\truntime.SetFinalizer(mm, nil)\n\n\t// unmap panics if the operation fails.\n\tmm.close()\n}\n"
        },
        {
          "name": "netlify.toml",
          "type": "blob",
          "size": 0.0703125,
          "content": "[build]\n  base = \"docs/\"\n  publish = \"site/\"\n  command = \"mkdocs build\"\n"
        },
        {
          "name": "perf",
          "type": "tree",
          "content": null
        },
        {
          "name": "pin",
          "type": "tree",
          "content": null
        },
        {
          "name": "prog.go",
          "type": "blob",
          "size": 33.97265625,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/kallsyms\"\n\t\"github.com/cilium/ebpf/internal/linux\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/sysenc\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\n// ErrNotSupported is returned whenever the kernel doesn't support a feature.\nvar ErrNotSupported = internal.ErrNotSupported\n\n// errBadRelocation is returned when the verifier rejects a program due to a\n// bad CO-RE relocation.\n//\n// This error is detected based on heuristics and therefore may not be reliable.\nvar errBadRelocation = errors.New(\"bad CO-RE relocation\")\n\n// errUnknownKfunc is returned when the verifier rejects a program due to an\n// unknown kfunc.\n//\n// This error is detected based on heuristics and therefore may not be reliable.\nvar errUnknownKfunc = errors.New(\"unknown kfunc\")\n\n// ProgramID represents the unique ID of an eBPF program.\ntype ProgramID uint32\n\nconst (\n\t// Number of bytes to pad the output buffer for BPF_PROG_TEST_RUN.\n\t// This is currently the maximum of spare space allocated for SKB\n\t// and XDP programs, and equal to XDP_PACKET_HEADROOM + NET_IP_ALIGN.\n\toutputPad = 256 + 2\n)\n\n// minVerifierLogSize is the default number of bytes allocated for the\n// verifier log.\nconst minVerifierLogSize = 64 * 1024\n\n// maxVerifierLogSize is the maximum size of verifier log buffer the kernel\n// will accept before returning EINVAL. May be increased to MaxUint32 in the\n// future, but avoid the unnecessary EINVAL for now.\nconst maxVerifierLogSize = math.MaxUint32 >> 2\n\n// ProgramOptions control loading a program into the kernel.\ntype ProgramOptions struct {\n\t// Bitmap controlling the detail emitted by the kernel's eBPF verifier log.\n\t// LogLevel-type values can be ORed together to request specific kinds of\n\t// verifier output. See the documentation on [ebpf.LogLevel] for details.\n\t//\n\t//  opts.LogLevel = (ebpf.LogLevelBranch | ebpf.LogLevelStats)\n\t//\n\t// If left to its default value, the program will first be loaded without\n\t// verifier output enabled. Upon error, the program load will be repeated\n\t// with LogLevelBranch and the given (or default) LogSize value.\n\t//\n\t// Unless LogDisabled is set, setting this to a non-zero value will enable the verifier\n\t// log, populating the [ebpf.Program.VerifierLog] field on successful loads\n\t// and including detailed verifier errors if the program is rejected. This\n\t// will always allocate an output buffer, but will result in only a single\n\t// attempt at loading the program.\n\tLogLevel LogLevel\n\n\t// Starting size of the verifier log buffer. If the verifier log is larger\n\t// than this size, the buffer will be grown to fit the entire log. Leave at\n\t// its default value unless troubleshooting.\n\tLogSizeStart uint32\n\n\t// Disables the verifier log completely, regardless of other options.\n\tLogDisabled bool\n\n\t// Type information used for CO-RE relocations.\n\t//\n\t// This is useful in environments where the kernel BTF is not available\n\t// (containers) or where it is in a non-standard location. Defaults to\n\t// use the kernel BTF from a well-known location if nil.\n\tKernelTypes *btf.Spec\n\n\t// Type information used for CO-RE relocations of kernel modules,\n\t// indexed by module name.\n\t//\n\t// This is useful in environments where the kernel BTF is not available\n\t// (containers) or where it is in a non-standard location. Defaults to\n\t// use the kernel module BTF from a well-known location if nil.\n\tKernelModuleTypes map[string]*btf.Spec\n}\n\n// ProgramSpec defines a Program.\ntype ProgramSpec struct {\n\t// Name is passed to the kernel as a debug aid. Must only contain\n\t// alpha numeric and '_' characters.\n\tName string\n\n\t// Type determines at which hook in the kernel a program will run.\n\tType ProgramType\n\n\t// AttachType of the program, needed to differentiate allowed context\n\t// accesses in some newer program types like CGroupSockAddr.\n\t//\n\t// Available on kernels 4.17 and later.\n\tAttachType AttachType\n\n\t// Name of a kernel data structure or function to attach to. Its\n\t// interpretation depends on Type and AttachType.\n\tAttachTo string\n\n\t// The program to attach to. Must be provided manually.\n\tAttachTarget *Program\n\n\t// The name of the ELF section this program originated from.\n\tSectionName string\n\n\tInstructions asm.Instructions\n\n\t// Flags is passed to the kernel and specifies additional program\n\t// load attributes.\n\tFlags uint32\n\n\t// License of the program. Some helpers are only available if\n\t// the license is deemed compatible with the GPL.\n\t//\n\t// See https://www.kernel.org/doc/html/latest/process/license-rules.html#id1\n\tLicense string\n\n\t// Version used by Kprobe programs.\n\t//\n\t// Deprecated on kernels 5.0 and later. Leave empty to let the library\n\t// detect this value automatically.\n\tKernelVersion uint32\n\n\t// The byte order this program was compiled for, may be nil.\n\tByteOrder binary.ByteOrder\n}\n\n// Copy returns a copy of the spec.\nfunc (ps *ProgramSpec) Copy() *ProgramSpec {\n\tif ps == nil {\n\t\treturn nil\n\t}\n\n\tcpy := *ps\n\tcpy.Instructions = make(asm.Instructions, len(ps.Instructions))\n\tcopy(cpy.Instructions, ps.Instructions)\n\treturn &cpy\n}\n\n// Tag calculates the kernel tag for a series of instructions.\n//\n// Use asm.Instructions.Tag if you need to calculate for non-native endianness.\nfunc (ps *ProgramSpec) Tag() (string, error) {\n\treturn ps.Instructions.Tag(internal.NativeEndian)\n}\n\n// kernelModule returns the kernel module providing the symbol in\n// ProgramSpec.AttachTo, if any. Returns an empty string if the symbol is not\n// present or not part of a kernel module.\nfunc (ps *ProgramSpec) kernelModule() (string, error) {\n\tif ps.AttachTo == \"\" && ps.targetsKernelModule() {\n\t\treturn kallsyms.Module(ps.AttachTo)\n\t}\n\n\treturn \"\", nil\n}\n\n// targetsKernelModule returns true if the program supports being attached to a\n// symbol provided by a kernel module.\nfunc (ps *ProgramSpec) targetsKernelModule() bool {\n\tif ps.AttachTo == \"\" {\n\t\treturn false\n\t}\n\n\tswitch ps.Type {\n\tcase Tracing:\n\t\tswitch ps.AttachType {\n\t\tcase AttachTraceFEntry, AttachTraceFExit:\n\t\t\treturn true\n\t\t}\n\tcase Kprobe:\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// VerifierError is returned by [NewProgram] and [NewProgramWithOptions] if a\n// program is rejected by the verifier.\n//\n// Use [errors.As] to access the error.\ntype VerifierError = internal.VerifierError\n\n// Program represents BPF program loaded into the kernel.\n//\n// It is not safe to close a Program which is used by other goroutines.\ntype Program struct {\n\t// Contains the output of the kernel verifier if enabled,\n\t// otherwise it is empty.\n\tVerifierLog string\n\n\tfd         *sys.FD\n\tname       string\n\tpinnedPath string\n\ttyp        ProgramType\n}\n\n// NewProgram creates a new Program.\n//\n// See [NewProgramWithOptions] for details.\n//\n// Returns a [VerifierError] containing the full verifier log if the program is\n// rejected by the kernel.\nfunc NewProgram(spec *ProgramSpec) (*Program, error) {\n\treturn NewProgramWithOptions(spec, ProgramOptions{})\n}\n\n// NewProgramWithOptions creates a new Program.\n//\n// Loading a program for the first time will perform\n// feature detection by loading small, temporary programs.\n//\n// Returns a [VerifierError] containing the full verifier log if the program is\n// rejected by the kernel.\nfunc NewProgramWithOptions(spec *ProgramSpec, opts ProgramOptions) (*Program, error) {\n\tif spec == nil {\n\t\treturn nil, errors.New(\"can't load a program from a nil spec\")\n\t}\n\n\tprog, err := newProgramWithOptions(spec, opts)\n\tif errors.Is(err, asm.ErrUnsatisfiedMapReference) {\n\t\treturn nil, fmt.Errorf(\"cannot load program without loading its whole collection: %w\", err)\n\t}\n\treturn prog, err\n}\n\nvar (\n\tcoreBadLoad = []byte(fmt.Sprintf(\"(18) r10 = 0x%x\\n\", btf.COREBadRelocationSentinel))\n\t// This log message was introduced by ebb676daa1a3 (\"bpf: Print function name in\n\t// addition to function id\") which first appeared in v4.10 and has remained\n\t// unchanged since.\n\tcoreBadCall  = []byte(fmt.Sprintf(\"invalid func unknown#%d\\n\", btf.COREBadRelocationSentinel))\n\tkfuncBadCall = []byte(fmt.Sprintf(\"invalid func unknown#%d\\n\", kfuncCallPoisonBase))\n)\n\nfunc newProgramWithOptions(spec *ProgramSpec, opts ProgramOptions) (*Program, error) {\n\tif len(spec.Instructions) == 0 {\n\t\treturn nil, errors.New(\"instructions cannot be empty\")\n\t}\n\n\tif spec.Type == UnspecifiedProgram {\n\t\treturn nil, errors.New(\"can't load program of unspecified type\")\n\t}\n\n\tif spec.ByteOrder != nil && spec.ByteOrder != internal.NativeEndian {\n\t\treturn nil, fmt.Errorf(\"can't load %s program on %s\", spec.ByteOrder, internal.NativeEndian)\n\t}\n\n\t// Kernels before 5.0 (6c4fc209fcf9 \"bpf: remove useless version check for prog load\")\n\t// require the version field to be set to the value of the KERNEL_VERSION\n\t// macro for kprobe-type programs.\n\t// Overwrite Kprobe program version if set to zero or the magic version constant.\n\tkv := spec.KernelVersion\n\tif spec.Type == Kprobe && (kv == 0 || kv == internal.MagicKernelVersion) {\n\t\tv, err := linux.KernelVersion()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"detecting kernel version: %w\", err)\n\t\t}\n\t\tkv = v.Kernel()\n\t}\n\n\tattr := &sys.ProgLoadAttr{\n\t\tProgType:           sys.ProgType(spec.Type),\n\t\tProgFlags:          spec.Flags,\n\t\tExpectedAttachType: sys.AttachType(spec.AttachType),\n\t\tLicense:            sys.NewStringPointer(spec.License),\n\t\tKernVersion:        kv,\n\t}\n\n\tif haveObjName() == nil {\n\t\tattr.ProgName = sys.NewObjName(spec.Name)\n\t}\n\n\tinsns := make(asm.Instructions, len(spec.Instructions))\n\tcopy(insns, spec.Instructions)\n\n\tkmodName, err := spec.kernelModule()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"kernel module search: %w\", err)\n\t}\n\n\tvar targets []*btf.Spec\n\tif opts.KernelTypes != nil {\n\t\ttargets = append(targets, opts.KernelTypes)\n\t}\n\tif kmodName != \"\" && opts.KernelModuleTypes != nil {\n\t\tif modBTF, ok := opts.KernelModuleTypes[kmodName]; ok {\n\t\t\ttargets = append(targets, modBTF)\n\t\t}\n\t}\n\n\tvar b btf.Builder\n\tif err := applyRelocations(insns, targets, kmodName, spec.ByteOrder, &b); err != nil {\n\t\treturn nil, fmt.Errorf(\"apply CO-RE relocations: %w\", err)\n\t}\n\n\terrExtInfos := haveProgramExtInfos()\n\tif !b.Empty() && errors.Is(errExtInfos, ErrNotSupported) {\n\t\t// There is at least one CO-RE relocation which relies on a stable local\n\t\t// type ID.\n\t\t// Return ErrNotSupported instead of E2BIG if there is no BTF support.\n\t\treturn nil, errExtInfos\n\t}\n\n\tif errExtInfos == nil {\n\t\t// Only add func and line info if the kernel supports it. This allows\n\t\t// BPF compiled with modern toolchains to work on old kernels.\n\t\tfib, lib, err := btf.MarshalExtInfos(insns, &b)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"marshal ext_infos: %w\", err)\n\t\t}\n\n\t\tattr.FuncInfoRecSize = btf.FuncInfoSize\n\t\tattr.FuncInfoCnt = uint32(len(fib)) / btf.FuncInfoSize\n\t\tattr.FuncInfo = sys.NewSlicePointer(fib)\n\n\t\tattr.LineInfoRecSize = btf.LineInfoSize\n\t\tattr.LineInfoCnt = uint32(len(lib)) / btf.LineInfoSize\n\t\tattr.LineInfo = sys.NewSlicePointer(lib)\n\t}\n\n\tif !b.Empty() {\n\t\thandle, err := btf.NewHandle(&b)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"load BTF: %w\", err)\n\t\t}\n\t\tdefer handle.Close()\n\n\t\tattr.ProgBtfFd = uint32(handle.FD())\n\t}\n\n\tkconfig, err := resolveKconfigReferences(insns)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"resolve .kconfig: %w\", err)\n\t}\n\tdefer kconfig.Close()\n\n\tif err := resolveKsymReferences(insns); err != nil {\n\t\treturn nil, fmt.Errorf(\"resolve .ksyms: %w\", err)\n\t}\n\n\tif err := fixupAndValidate(insns); err != nil {\n\t\treturn nil, err\n\t}\n\n\thandles, err := fixupKfuncs(insns)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"fixing up kfuncs: %w\", err)\n\t}\n\tdefer handles.Close()\n\n\tif len(handles) > 0 {\n\t\tfdArray := handles.fdArray()\n\t\tattr.FdArray = sys.NewPointer(unsafe.Pointer(&fdArray[0]))\n\t}\n\n\tbuf := bytes.NewBuffer(make([]byte, 0, insns.Size()))\n\terr = insns.Marshal(buf, internal.NativeEndian)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbytecode := buf.Bytes()\n\tattr.Insns = sys.NewSlicePointer(bytecode)\n\tattr.InsnCnt = uint32(len(bytecode) / asm.InstructionSize)\n\n\tif spec.AttachTarget != nil {\n\t\ttargetID, err := findTargetInProgram(spec.AttachTarget, spec.AttachTo, spec.Type, spec.AttachType)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"attach %s/%s: %w\", spec.Type, spec.AttachType, err)\n\t\t}\n\n\t\tattr.AttachBtfId = targetID\n\t\tattr.AttachBtfObjFd = uint32(spec.AttachTarget.FD())\n\t\tdefer runtime.KeepAlive(spec.AttachTarget)\n\t} else if spec.AttachTo != \"\" {\n\t\tmodule, targetID, err := findProgramTargetInKernel(spec.AttachTo, spec.Type, spec.AttachType)\n\t\tif err != nil && !errors.Is(err, errUnrecognizedAttachType) {\n\t\t\t// We ignore errUnrecognizedAttachType since AttachTo may be non-empty\n\t\t\t// for programs that don't attach anywhere.\n\t\t\treturn nil, fmt.Errorf(\"attach %s/%s: %w\", spec.Type, spec.AttachType, err)\n\t\t}\n\n\t\tattr.AttachBtfId = targetID\n\t\tif module != nil {\n\t\t\tattr.AttachBtfObjFd = uint32(module.FD())\n\t\t\tdefer module.Close()\n\t\t}\n\t}\n\n\t// The caller requested a specific verifier log level. Set up the log buffer\n\t// so that there is a chance of loading the program in a single shot.\n\tlogSize := internal.Between(opts.LogSizeStart, minVerifierLogSize, maxVerifierLogSize)\n\tvar logBuf []byte\n\tif !opts.LogDisabled && opts.LogLevel != 0 {\n\t\tlogBuf = make([]byte, logSize)\n\t\tattr.LogLevel = opts.LogLevel\n\t\tattr.LogSize = uint32(len(logBuf))\n\t\tattr.LogBuf = sys.NewSlicePointer(logBuf)\n\t}\n\n\tfor {\n\t\tvar fd *sys.FD\n\t\tfd, err = sys.ProgLoad(attr)\n\t\tif err == nil {\n\t\t\treturn &Program{unix.ByteSliceToString(logBuf), fd, spec.Name, \"\", spec.Type}, nil\n\t\t}\n\n\t\tif opts.LogDisabled {\n\t\t\tbreak\n\t\t}\n\n\t\tif attr.LogTrueSize != 0 && attr.LogSize >= attr.LogTrueSize {\n\t\t\t// The log buffer already has the correct size.\n\t\t\tbreak\n\t\t}\n\n\t\tif attr.LogSize != 0 && !errors.Is(err, unix.ENOSPC) {\n\t\t\t// Logging is enabled and the error is not ENOSPC, so we can infer\n\t\t\t// that the log buffer is large enough.\n\t\t\tbreak\n\t\t}\n\n\t\tif attr.LogLevel == 0 {\n\t\t\t// Logging is not enabled but loading the program failed. Enable\n\t\t\t// basic logging.\n\t\t\tattr.LogLevel = LogLevelBranch\n\t\t}\n\n\t\t// Make an educated guess how large the buffer should be by multiplying.\n\t\t// Ensure the size doesn't overflow.\n\t\tconst factor = 2\n\t\tlogSize = internal.Between(logSize, minVerifierLogSize, maxVerifierLogSize/factor)\n\t\tlogSize *= factor\n\n\t\tif attr.LogTrueSize != 0 {\n\t\t\t// The kernel has given us a hint how large the log buffer has to be.\n\t\t\tlogSize = attr.LogTrueSize\n\t\t}\n\n\t\tlogBuf = make([]byte, logSize)\n\t\tattr.LogSize = logSize\n\t\tattr.LogBuf = sys.NewSlicePointer(logBuf)\n\t}\n\n\tend := bytes.IndexByte(logBuf, 0)\n\tif end < 0 {\n\t\tend = len(logBuf)\n\t}\n\n\ttail := logBuf[max(end-256, 0):end]\n\tswitch {\n\tcase errors.Is(err, unix.EPERM):\n\t\tif len(logBuf) > 0 && logBuf[0] == 0 {\n\t\t\t// EPERM due to RLIMIT_MEMLOCK happens before the verifier, so we can\n\t\t\t// check that the log is empty to reduce false positives.\n\t\t\treturn nil, fmt.Errorf(\"load program: %w (MEMLOCK may be too low, consider rlimit.RemoveMemlock)\", err)\n\t\t}\n\n\tcase errors.Is(err, unix.EFAULT):\n\t\t// EFAULT is returned when the kernel hits a verifier bug, and always\n\t\t// overrides ENOSPC, defeating the buffer growth strategy. Warn the user\n\t\t// that they may need to increase the buffer size manually.\n\t\treturn nil, fmt.Errorf(\"load program: %w (hit verifier bug, increase LogSizeStart to fit the log and check dmesg)\", err)\n\n\tcase errors.Is(err, unix.EINVAL):\n\t\tif bytes.Contains(tail, coreBadCall) {\n\t\t\terr = errBadRelocation\n\t\t\tbreak\n\t\t} else if bytes.Contains(tail, kfuncBadCall) {\n\t\t\terr = errUnknownKfunc\n\t\t\tbreak\n\t\t}\n\n\tcase errors.Is(err, unix.EACCES):\n\t\tif bytes.Contains(tail, coreBadLoad) {\n\t\t\terr = errBadRelocation\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// hasFunctionReferences may be expensive, so check it last.\n\tif (errors.Is(err, unix.EINVAL) || errors.Is(err, unix.EPERM)) &&\n\t\thasFunctionReferences(spec.Instructions) {\n\t\tif err := haveBPFToBPFCalls(); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"load program: %w\", err)\n\t\t}\n\t}\n\n\treturn nil, internal.ErrorWithLog(\"load program\", err, logBuf)\n}\n\n// NewProgramFromFD creates a program from a raw fd.\n//\n// You should not use fd after calling this function.\n//\n// Requires at least Linux 4.10.\nfunc NewProgramFromFD(fd int) (*Program, error) {\n\tf, err := sys.NewFD(fd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newProgramFromFD(f)\n}\n\n// NewProgramFromID returns the program for a given id.\n//\n// Returns ErrNotExist, if there is no eBPF program with the given id.\nfunc NewProgramFromID(id ProgramID) (*Program, error) {\n\tfd, err := sys.ProgGetFdById(&sys.ProgGetFdByIdAttr{\n\t\tId: uint32(id),\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get program by id: %w\", err)\n\t}\n\n\treturn newProgramFromFD(fd)\n}\n\nfunc newProgramFromFD(fd *sys.FD) (*Program, error) {\n\tinfo, err := newProgramInfoFromFd(fd)\n\tif err != nil {\n\t\tfd.Close()\n\t\treturn nil, fmt.Errorf(\"discover program type: %w\", err)\n\t}\n\n\treturn &Program{\"\", fd, info.Name, \"\", info.Type}, nil\n}\n\nfunc (p *Program) String() string {\n\tif p.name != \"\" {\n\t\treturn fmt.Sprintf(\"%s(%s)#%v\", p.typ, p.name, p.fd)\n\t}\n\treturn fmt.Sprintf(\"%s(%v)\", p.typ, p.fd)\n}\n\n// Type returns the underlying type of the program.\nfunc (p *Program) Type() ProgramType {\n\treturn p.typ\n}\n\n// Info returns metadata about the program.\n//\n// Requires at least 4.10.\nfunc (p *Program) Info() (*ProgramInfo, error) {\n\treturn newProgramInfoFromFd(p.fd)\n}\n\n// Handle returns a reference to the program's type information in the kernel.\n//\n// Returns ErrNotSupported if the kernel has no BTF support, or if there is no\n// BTF associated with the program.\nfunc (p *Program) Handle() (*btf.Handle, error) {\n\tinfo, err := p.Info()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tid, ok := info.BTFID()\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"program %s: retrieve BTF ID: %w\", p, ErrNotSupported)\n\t}\n\n\treturn btf.NewHandleFromID(id)\n}\n\n// FD gets the file descriptor of the Program.\n//\n// It is invalid to call this function after Close has been called.\nfunc (p *Program) FD() int {\n\treturn p.fd.Int()\n}\n\n// Clone creates a duplicate of the Program.\n//\n// Closing the duplicate does not affect the original, and vice versa.\n//\n// Cloning a nil Program returns nil.\nfunc (p *Program) Clone() (*Program, error) {\n\tif p == nil {\n\t\treturn nil, nil\n\t}\n\n\tdup, err := p.fd.Dup()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"can't clone program: %w\", err)\n\t}\n\n\treturn &Program{p.VerifierLog, dup, p.name, \"\", p.typ}, nil\n}\n\n// Pin persists the Program on the BPF virtual file system past the lifetime of\n// the process that created it\n//\n// Calling Pin on a previously pinned program will overwrite the path, except when\n// the new path already exists. Re-pinning across filesystems is not supported.\n//\n// This requires bpffs to be mounted above fileName.\n// See https://docs.cilium.io/en/stable/network/kubernetes/configuration/#mounting-bpffs-with-systemd\nfunc (p *Program) Pin(fileName string) error {\n\tif err := sys.Pin(p.pinnedPath, fileName, p.fd); err != nil {\n\t\treturn err\n\t}\n\tp.pinnedPath = fileName\n\treturn nil\n}\n\n// Unpin removes the persisted state for the Program from the BPF virtual filesystem.\n//\n// Failed calls to Unpin will not alter the state returned by IsPinned.\n//\n// Unpinning an unpinned Program returns nil.\nfunc (p *Program) Unpin() error {\n\tif err := sys.Unpin(p.pinnedPath); err != nil {\n\t\treturn err\n\t}\n\tp.pinnedPath = \"\"\n\treturn nil\n}\n\n// IsPinned returns true if the Program has a non-empty pinned path.\nfunc (p *Program) IsPinned() bool {\n\treturn p.pinnedPath != \"\"\n}\n\n// Close the Program's underlying file descriptor, which could unload\n// the program from the kernel if it is not pinned or attached to a\n// kernel hook.\nfunc (p *Program) Close() error {\n\tif p == nil {\n\t\treturn nil\n\t}\n\n\treturn p.fd.Close()\n}\n\n// Various options for Run'ing a Program\ntype RunOptions struct {\n\t// Program's data input. Required field.\n\t//\n\t// The kernel expects at least 14 bytes input for an ethernet header for\n\t// XDP and SKB programs.\n\tData []byte\n\t// Program's data after Program has run. Caller must allocate. Optional field.\n\tDataOut []byte\n\t// Program's context input. Optional field.\n\tContext interface{}\n\t// Program's context after Program has run. Must be a pointer or slice. Optional field.\n\tContextOut interface{}\n\t// Minimum number of times to run Program. Optional field. Defaults to 1.\n\t//\n\t// The program may be executed more often than this due to interruptions, e.g.\n\t// when runtime.AllThreadsSyscall is invoked.\n\tRepeat uint32\n\t// Optional flags.\n\tFlags uint32\n\t// CPU to run Program on. Optional field.\n\t// Note not all program types support this field.\n\tCPU uint32\n\t// Called whenever the syscall is interrupted, and should be set to testing.B.ResetTimer\n\t// or similar. Typically used during benchmarking. Optional field.\n\t//\n\t// Deprecated: use [testing.B.ReportMetric] with unit \"ns/op\" instead.\n\tReset func()\n}\n\n// Test runs the Program in the kernel with the given input and returns the\n// value returned by the eBPF program.\n//\n// Note: the kernel expects at least 14 bytes input for an ethernet header for\n// XDP and SKB programs.\n//\n// This function requires at least Linux 4.12.\nfunc (p *Program) Test(in []byte) (uint32, []byte, error) {\n\t// Older kernels ignore the dataSizeOut argument when copying to user space.\n\t// Combined with things like bpf_xdp_adjust_head() we don't really know what the final\n\t// size will be. Hence we allocate an output buffer which we hope will always be large\n\t// enough, and panic if the kernel wrote past the end of the allocation.\n\t// See https://patchwork.ozlabs.org/cover/1006822/\n\tvar out []byte\n\tif len(in) > 0 {\n\t\tout = make([]byte, len(in)+outputPad)\n\t}\n\n\topts := RunOptions{\n\t\tData:    in,\n\t\tDataOut: out,\n\t\tRepeat:  1,\n\t}\n\n\tret, _, err := p.run(&opts)\n\tif err != nil {\n\t\treturn ret, nil, fmt.Errorf(\"test program: %w\", err)\n\t}\n\treturn ret, opts.DataOut, nil\n}\n\n// Run runs the Program in kernel with given RunOptions.\n//\n// Note: the same restrictions from Test apply.\nfunc (p *Program) Run(opts *RunOptions) (uint32, error) {\n\tif opts == nil {\n\t\topts = &RunOptions{}\n\t}\n\n\tret, _, err := p.run(opts)\n\tif err != nil {\n\t\treturn ret, fmt.Errorf(\"run program: %w\", err)\n\t}\n\treturn ret, nil\n}\n\n// Benchmark runs the Program with the given input for a number of times\n// and returns the time taken per iteration.\n//\n// Returns the result of the last execution of the program and the time per\n// run or an error. reset is called whenever the benchmark syscall is\n// interrupted, and should be set to testing.B.ResetTimer or similar.\n//\n// This function requires at least Linux 4.12.\nfunc (p *Program) Benchmark(in []byte, repeat int, reset func()) (uint32, time.Duration, error) {\n\tif uint(repeat) > math.MaxUint32 {\n\t\treturn 0, 0, fmt.Errorf(\"repeat is too high\")\n\t}\n\n\topts := RunOptions{\n\t\tData:   in,\n\t\tRepeat: uint32(repeat),\n\t\tReset:  reset,\n\t}\n\n\tret, total, err := p.run(&opts)\n\tif err != nil {\n\t\treturn ret, total, fmt.Errorf(\"benchmark program: %w\", err)\n\t}\n\treturn ret, total, nil\n}\n\nvar haveProgRun = internal.NewFeatureTest(\"BPF_PROG_RUN\", func() error {\n\tprog, err := NewProgram(&ProgramSpec{\n\t\t// SocketFilter does not require privileges on newer kernels.\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t})\n\tif err != nil {\n\t\t// This may be because we lack sufficient permissions, etc.\n\t\treturn err\n\t}\n\tdefer prog.Close()\n\n\tin := internal.EmptyBPFContext\n\tattr := sys.ProgRunAttr{\n\t\tProgFd:     uint32(prog.FD()),\n\t\tDataSizeIn: uint32(len(in)),\n\t\tDataIn:     sys.NewSlicePointer(in),\n\t}\n\n\terr = sys.ProgRun(&attr)\n\tswitch {\n\tcase errors.Is(err, unix.EINVAL):\n\t\t// Check for EINVAL specifically, rather than err != nil since we\n\t\t// otherwise misdetect due to insufficient permissions.\n\t\treturn internal.ErrNotSupported\n\n\tcase errors.Is(err, unix.EINTR):\n\t\t// We know that PROG_TEST_RUN is supported if we get EINTR.\n\t\treturn nil\n\n\tcase errors.Is(err, sys.ENOTSUPP):\n\t\t// The first PROG_TEST_RUN patches shipped in 4.12 didn't include\n\t\t// a test runner for SocketFilter. ENOTSUPP means PROG_TEST_RUN is\n\t\t// supported, but not for the program type used in the probe.\n\t\treturn nil\n\t}\n\n\treturn err\n}, \"4.12\")\n\nfunc (p *Program) run(opts *RunOptions) (uint32, time.Duration, error) {\n\tif uint(len(opts.Data)) > math.MaxUint32 {\n\t\treturn 0, 0, fmt.Errorf(\"input is too long\")\n\t}\n\n\tif err := haveProgRun(); err != nil {\n\t\treturn 0, 0, err\n\t}\n\n\tvar ctxBytes []byte\n\tif opts.Context != nil {\n\t\tctx := new(bytes.Buffer)\n\t\tif err := binary.Write(ctx, internal.NativeEndian, opts.Context); err != nil {\n\t\t\treturn 0, 0, fmt.Errorf(\"cannot serialize context: %v\", err)\n\t\t}\n\t\tctxBytes = ctx.Bytes()\n\t}\n\n\tvar ctxOut []byte\n\tif opts.ContextOut != nil {\n\t\tctxOut = make([]byte, binary.Size(opts.ContextOut))\n\t}\n\n\tattr := sys.ProgRunAttr{\n\t\tProgFd:      p.fd.Uint(),\n\t\tDataSizeIn:  uint32(len(opts.Data)),\n\t\tDataSizeOut: uint32(len(opts.DataOut)),\n\t\tDataIn:      sys.NewSlicePointer(opts.Data),\n\t\tDataOut:     sys.NewSlicePointer(opts.DataOut),\n\t\tRepeat:      uint32(opts.Repeat),\n\t\tCtxSizeIn:   uint32(len(ctxBytes)),\n\t\tCtxSizeOut:  uint32(len(ctxOut)),\n\t\tCtxIn:       sys.NewSlicePointer(ctxBytes),\n\t\tCtxOut:      sys.NewSlicePointer(ctxOut),\n\t\tFlags:       opts.Flags,\n\t\tCpu:         opts.CPU,\n\t}\n\nretry:\n\tfor {\n\t\terr := sys.ProgRun(&attr)\n\t\tif err == nil {\n\t\t\tbreak retry\n\t\t}\n\n\t\tif errors.Is(err, unix.EINTR) {\n\t\t\tif attr.Repeat <= 1 {\n\t\t\t\t// Older kernels check whether enough repetitions have been\n\t\t\t\t// executed only after checking for pending signals.\n\t\t\t\t//\n\t\t\t\t//     run signal? done? run ...\n\t\t\t\t//\n\t\t\t\t// As a result we can get EINTR for repeat==1 even though\n\t\t\t\t// the program was run exactly once. Treat this as a\n\t\t\t\t// successful run instead.\n\t\t\t\t//\n\t\t\t\t// Since commit 607b9cc92bd7 (\"bpf: Consolidate shared test timing code\")\n\t\t\t\t// the conditions are reversed:\n\t\t\t\t//     run done? signal? ...\n\t\t\t\tbreak retry\n\t\t\t}\n\n\t\t\tif opts.Reset != nil {\n\t\t\t\topts.Reset()\n\t\t\t}\n\t\t\tcontinue retry\n\t\t}\n\n\t\tif errors.Is(err, sys.ENOTSUPP) {\n\t\t\treturn 0, 0, fmt.Errorf(\"kernel doesn't support running %s: %w\", p.Type(), ErrNotSupported)\n\t\t}\n\n\t\treturn 0, 0, err\n\t}\n\n\tif opts.DataOut != nil {\n\t\tif int(attr.DataSizeOut) > cap(opts.DataOut) {\n\t\t\t// Houston, we have a problem. The program created more data than we allocated,\n\t\t\t// and the kernel wrote past the end of our buffer.\n\t\t\tpanic(\"kernel wrote past end of output buffer\")\n\t\t}\n\t\topts.DataOut = opts.DataOut[:int(attr.DataSizeOut)]\n\t}\n\n\tif len(ctxOut) != 0 {\n\t\tb := bytes.NewReader(ctxOut)\n\t\tif err := binary.Read(b, internal.NativeEndian, opts.ContextOut); err != nil {\n\t\t\treturn 0, 0, fmt.Errorf(\"failed to decode ContextOut: %v\", err)\n\t\t}\n\t}\n\n\ttotal := time.Duration(attr.Duration) * time.Nanosecond\n\treturn attr.Retval, total, nil\n}\n\nfunc unmarshalProgram(buf sysenc.Buffer) (*Program, error) {\n\tvar id uint32\n\tif err := buf.Unmarshal(&id); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Looking up an entry in a nested map or prog array returns an id,\n\t// not an fd.\n\treturn NewProgramFromID(ProgramID(id))\n}\n\nfunc marshalProgram(p *Program, length int) ([]byte, error) {\n\tif p == nil {\n\t\treturn nil, errors.New(\"can't marshal a nil Program\")\n\t}\n\n\tif length != 4 {\n\t\treturn nil, fmt.Errorf(\"can't marshal program to %d bytes\", length)\n\t}\n\n\tbuf := make([]byte, 4)\n\tinternal.NativeEndian.PutUint32(buf, p.fd.Uint())\n\treturn buf, nil\n}\n\n// LoadPinnedProgram loads a Program from a pin (file) on the BPF virtual\n// filesystem.\n//\n// Requires at least Linux 4.11.\nfunc LoadPinnedProgram(fileName string, opts *LoadPinOptions) (*Program, error) {\n\tfd, typ, err := sys.ObjGetTyped(&sys.ObjGetAttr{\n\t\tPathname:  sys.NewStringPointer(fileName),\n\t\tFileFlags: opts.Marshal(),\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif typ != sys.BPF_TYPE_PROG {\n\t\t_ = fd.Close()\n\t\treturn nil, fmt.Errorf(\"%s is not a Program\", fileName)\n\t}\n\n\tinfo, err := newProgramInfoFromFd(fd)\n\tif err != nil {\n\t\t_ = fd.Close()\n\t\treturn nil, fmt.Errorf(\"info for %s: %w\", fileName, err)\n\t}\n\n\tvar progName string\n\tif haveObjName() == nil {\n\t\tprogName = info.Name\n\t} else {\n\t\tprogName = filepath.Base(fileName)\n\t}\n\n\treturn &Program{\"\", fd, progName, fileName, info.Type}, nil\n}\n\n// SanitizeName replaces all invalid characters in name with replacement.\n// Passing a negative value for replacement will delete characters instead\n// of replacing them. Use this to automatically generate valid names for maps\n// and programs at runtime.\n//\n// The set of allowed characters depends on the running kernel version.\n// Dots are only allowed as of kernel 5.2.\nfunc SanitizeName(name string, replacement rune) string {\n\treturn strings.Map(func(char rune) rune {\n\t\tif invalidBPFObjNameChar(char) {\n\t\t\treturn replacement\n\t\t}\n\t\treturn char\n\t}, name)\n}\n\n// ProgramGetNextID returns the ID of the next eBPF program.\n//\n// Returns ErrNotExist, if there is no next eBPF program.\nfunc ProgramGetNextID(startID ProgramID) (ProgramID, error) {\n\tattr := &sys.ProgGetNextIdAttr{Id: uint32(startID)}\n\treturn ProgramID(attr.NextId), sys.ProgGetNextId(attr)\n}\n\n// BindMap binds map to the program and is only released once program is released.\n//\n// This may be used in cases where metadata should be associated with the program\n// which otherwise does not contain any references to the map.\nfunc (p *Program) BindMap(m *Map) error {\n\tattr := &sys.ProgBindMapAttr{\n\t\tProgFd: uint32(p.FD()),\n\t\tMapFd:  uint32(m.FD()),\n\t}\n\n\treturn sys.ProgBindMap(attr)\n}\n\nvar errUnrecognizedAttachType = errors.New(\"unrecognized attach type\")\n\n// find an attach target type in the kernel.\n//\n// name, progType and attachType determine which type we need to attach to.\n//\n// The attach target may be in a loaded kernel module.\n// In that case the returned handle will be non-nil.\n// The caller is responsible for closing the handle.\n//\n// Returns errUnrecognizedAttachType if the combination of progType and attachType\n// is not recognised.\nfunc findProgramTargetInKernel(name string, progType ProgramType, attachType AttachType) (*btf.Handle, btf.TypeID, error) {\n\ttype match struct {\n\t\tp ProgramType\n\t\ta AttachType\n\t}\n\n\tvar (\n\t\ttypeName, featureName string\n\t\ttarget                btf.Type\n\t)\n\n\tswitch (match{progType, attachType}) {\n\tcase match{LSM, AttachLSMMac}:\n\t\ttypeName = \"bpf_lsm_\" + name\n\t\tfeatureName = name + \" LSM hook\"\n\t\ttarget = (*btf.Func)(nil)\n\tcase match{Tracing, AttachTraceIter}:\n\t\ttypeName = \"bpf_iter_\" + name\n\t\tfeatureName = name + \" iterator\"\n\t\ttarget = (*btf.Func)(nil)\n\tcase match{Tracing, AttachTraceFEntry}:\n\t\ttypeName = name\n\t\tfeatureName = fmt.Sprintf(\"fentry %s\", name)\n\t\ttarget = (*btf.Func)(nil)\n\tcase match{Tracing, AttachTraceFExit}:\n\t\ttypeName = name\n\t\tfeatureName = fmt.Sprintf(\"fexit %s\", name)\n\t\ttarget = (*btf.Func)(nil)\n\tcase match{Tracing, AttachModifyReturn}:\n\t\ttypeName = name\n\t\tfeatureName = fmt.Sprintf(\"fmod_ret %s\", name)\n\t\ttarget = (*btf.Func)(nil)\n\tcase match{Tracing, AttachTraceRawTp}:\n\t\ttypeName = fmt.Sprintf(\"btf_trace_%s\", name)\n\t\tfeatureName = fmt.Sprintf(\"raw_tp %s\", name)\n\t\ttarget = (*btf.Typedef)(nil)\n\tdefault:\n\t\treturn nil, 0, errUnrecognizedAttachType\n\t}\n\n\tspec, err := btf.LoadKernelSpec()\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"load kernel spec: %w\", err)\n\t}\n\n\tspec, module, err := findTargetInKernel(spec, typeName, &target)\n\tif errors.Is(err, btf.ErrNotFound) {\n\t\treturn nil, 0, &internal.UnsupportedFeatureError{Name: featureName}\n\t}\n\t// See cilium/ebpf#894. Until we can disambiguate between equally-named kernel\n\t// symbols, we should explicitly refuse program loads. They will not reliably\n\t// do what the caller intended.\n\tif errors.Is(err, btf.ErrMultipleMatches) {\n\t\treturn nil, 0, fmt.Errorf(\"attaching to ambiguous kernel symbol is not supported: %w\", err)\n\t}\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"find target for %s: %w\", featureName, err)\n\t}\n\n\tid, err := spec.TypeID(target)\n\tif err != nil {\n\t\tmodule.Close()\n\t\treturn nil, 0, err\n\t}\n\n\treturn module, id, nil\n}\n\n// findTargetInKernel attempts to find a named type in the current kernel.\n//\n// target will point at the found type after a successful call. Searches both\n// vmlinux and any loaded modules.\n//\n// Returns a non-nil handle if the type was found in a module, or btf.ErrNotFound\n// if the type wasn't found at all.\nfunc findTargetInKernel(kernelSpec *btf.Spec, typeName string, target *btf.Type) (*btf.Spec, *btf.Handle, error) {\n\terr := kernelSpec.TypeByName(typeName, target)\n\tif errors.Is(err, btf.ErrNotFound) {\n\t\tspec, module, err := findTargetInModule(kernelSpec, typeName, target)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"find target in modules: %w\", err)\n\t\t}\n\t\treturn spec, module, nil\n\t}\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"find target in vmlinux: %w\", err)\n\t}\n\treturn kernelSpec, nil, err\n}\n\n// findTargetInModule attempts to find a named type in any loaded module.\n//\n// base must contain the kernel's types and is used to parse kmod BTF. Modules\n// are searched in the order they were loaded.\n//\n// Returns btf.ErrNotFound if the target can't be found in any module.\nfunc findTargetInModule(base *btf.Spec, typeName string, target *btf.Type) (*btf.Spec, *btf.Handle, error) {\n\tit := new(btf.HandleIterator)\n\tdefer it.Handle.Close()\n\n\tfor it.Next() {\n\t\tinfo, err := it.Handle.Info()\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"get info for BTF ID %d: %w\", it.ID, err)\n\t\t}\n\n\t\tif !info.IsModule() {\n\t\t\tcontinue\n\t\t}\n\n\t\tspec, err := it.Handle.Spec(base)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"parse types for module %s: %w\", info.Name, err)\n\t\t}\n\n\t\terr = spec.TypeByName(typeName, target)\n\t\tif errors.Is(err, btf.ErrNotFound) {\n\t\t\tcontinue\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"lookup type in module %s: %w\", info.Name, err)\n\t\t}\n\n\t\treturn spec, it.Take(), nil\n\t}\n\tif err := it.Err(); err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"iterate modules: %w\", err)\n\t}\n\n\treturn nil, nil, btf.ErrNotFound\n}\n\n// find an attach target type in a program.\n//\n// Returns errUnrecognizedAttachType.\nfunc findTargetInProgram(prog *Program, name string, progType ProgramType, attachType AttachType) (btf.TypeID, error) {\n\ttype match struct {\n\t\tp ProgramType\n\t\ta AttachType\n\t}\n\n\tvar typeName string\n\tswitch (match{progType, attachType}) {\n\tcase match{Extension, AttachNone},\n\t\tmatch{Tracing, AttachTraceFEntry},\n\t\tmatch{Tracing, AttachTraceFExit}:\n\t\ttypeName = name\n\tdefault:\n\t\treturn 0, errUnrecognizedAttachType\n\t}\n\n\tbtfHandle, err := prog.Handle()\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"load target BTF: %w\", err)\n\t}\n\tdefer btfHandle.Close()\n\n\tspec, err := btfHandle.Spec(nil)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tvar targetFunc *btf.Func\n\terr = spec.TypeByName(typeName, &targetFunc)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"find target %s: %w\", typeName, err)\n\t}\n\n\treturn spec.TypeID(targetFunc)\n}\n"
        },
        {
          "name": "prog_test.go",
          "type": "blob",
          "size": 25.861328125,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"slices\"\n\t\"strings\"\n\t\"syscall\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-quicktest/qt\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\nfunc TestProgramRun(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.8\", \"XDP program\")\n\n\tpat := []byte{0xDE, 0xAD, 0xBE, 0xEF}\n\tbuf := internal.EmptyBPFContext\n\n\t// r1  : ctx_start\n\t// r1+4: ctx_end\n\tins := asm.Instructions{\n\t\t// r2 = *(r1+4)\n\t\tasm.LoadMem(asm.R2, asm.R1, 4, asm.Word),\n\t\t// r1 = *(r1+0)\n\t\tasm.LoadMem(asm.R1, asm.R1, 0, asm.Word),\n\t\t// r3 = r1\n\t\tasm.Mov.Reg(asm.R3, asm.R1),\n\t\t// r3 += len(buf)\n\t\tasm.Add.Imm(asm.R3, int32(len(buf))),\n\t\t// if r3 > r2 goto +len(pat)\n\t\tasm.JGT.Reg(asm.R3, asm.R2, \"out\"),\n\t}\n\tfor i, b := range pat {\n\t\tins = append(ins, asm.StoreImm(asm.R1, int16(i), int64(b), asm.Byte))\n\t}\n\tins = append(ins,\n\t\t// return 42\n\t\tasm.LoadImm(asm.R0, 42, asm.DWord).WithSymbol(\"out\"),\n\t\tasm.Return(),\n\t)\n\n\tt.Log(ins)\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tName:         \"test\",\n\t\tType:         XDP,\n\t\tInstructions: ins,\n\t\tLicense:      \"MIT\",\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tp2, err := prog.Clone()\n\tif err != nil {\n\t\tt.Fatal(\"Can't clone program\")\n\t}\n\tdefer p2.Close()\n\n\tprog.Close()\n\tprog = p2\n\n\tret, out, err := prog.Test(buf)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 42 {\n\t\tt.Error(\"Expected return value to be 42, got\", ret)\n\t}\n\n\tif !bytes.Equal(out[:len(pat)], pat) {\n\t\tt.Errorf(\"Expected %v, got %v\", pat, out)\n\t}\n}\n\nfunc TestProgramRunWithOptions(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.15\", \"XDP ctx_in/ctx_out\")\n\n\tins := asm.Instructions{\n\t\t// Return XDP_ABORTED\n\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\tasm.Return(),\n\t}\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tName:         \"test\",\n\t\tType:         XDP,\n\t\tInstructions: ins,\n\t\tLicense:      \"MIT\",\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tbuf := internal.EmptyBPFContext\n\txdp := sys.XdpMd{\n\t\tData:    0,\n\t\tDataEnd: uint32(len(buf)),\n\t}\n\txdpOut := sys.XdpMd{}\n\topts := RunOptions{\n\t\tData:       buf,\n\t\tContext:    xdp,\n\t\tContextOut: &xdpOut,\n\t}\n\tret, err := prog.Run(&opts)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 0 {\n\t\tt.Error(\"Expected return value to be 0, got\", ret)\n\t}\n\n\tif xdp != xdpOut {\n\t\tt.Errorf(\"Expect xdp (%+v) == xdpOut (%+v)\", xdp, xdpOut)\n\t}\n}\n\nfunc TestProgramRunRawTracepoint(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.10\", \"RawTracepoint test run\")\n\n\tins := asm.Instructions{\n\t\t// Return 0\n\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\tasm.Return(),\n\t}\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tName:         \"test\",\n\t\tType:         RawTracepoint,\n\t\tInstructions: ins,\n\t\tLicense:      \"MIT\",\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tret, err := prog.Run(&RunOptions{})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 0 {\n\t\tt.Error(\"Expected return value to be 0, got\", ret)\n\t}\n}\n\nfunc TestProgramRunEmptyData(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.13\", \"sk_lookup BPF_PROG_RUN\")\n\n\tins := asm.Instructions{\n\t\t// Return SK_DROP\n\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\tasm.Return(),\n\t}\n\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tName:         \"test\",\n\t\tType:         SkLookup,\n\t\tAttachType:   AttachSkLookup,\n\t\tInstructions: ins,\n\t\tLicense:      \"MIT\",\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\topts := RunOptions{\n\t\tContext: sys.SkLookup{\n\t\t\tFamily: syscall.AF_INET,\n\t\t},\n\t}\n\tret, err := prog.Run(&opts)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif ret != 0 {\n\t\tt.Error(\"Expected return value to be 0, got\", ret)\n\t}\n}\n\nfunc TestProgramBenchmark(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\tret, duration, err := prog.Benchmark(internal.EmptyBPFContext, 1, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Error from Benchmark:\", err)\n\t}\n\n\tif ret != 2 {\n\t\tt.Error(\"Expected return value 2, got\", ret)\n\t}\n\n\tif duration == 0 {\n\t\tt.Error(\"Expected non-zero duration\")\n\t}\n}\n\nfunc TestProgramTestRunInterrupt(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.0\", \"EINTR from BPF_PROG_TEST_RUN\")\n\n\tprog := mustSocketFilter(t)\n\n\tvar (\n\t\ttgid    = unix.Getpid()\n\t\ttidChan = make(chan int, 1)\n\t\texit    = make(chan struct{})\n\t\terrs    = make(chan error, 1)\n\t\ttimeout = time.After(5 * time.Second)\n\t)\n\n\tdefer close(exit)\n\n\tgo func() {\n\t\truntime.LockOSThread()\n\t\tdefer func() {\n\t\t\t// Wait for the test to allow us to unlock the OS thread, to\n\t\t\t// ensure that we don't send SIGUSR1 to the wrong thread.\n\t\t\t<-exit\n\t\t\truntime.UnlockOSThread()\n\t\t}()\n\n\t\ttidChan <- unix.Gettid()\n\n\t\t// Block this thread in the BPF syscall, so that we can\n\t\t// trigger EINTR by sending a signal.\n\t\topts := RunOptions{\n\t\t\tData:   internal.EmptyBPFContext,\n\t\t\tRepeat: math.MaxInt32,\n\t\t\tReset: func() {\n\t\t\t\t// We don't know how long finishing the\n\t\t\t\t// test run would take, so flag that we've seen\n\t\t\t\t// an interruption and abort the goroutine.\n\t\t\t\tclose(errs)\n\t\t\t\truntime.Goexit()\n\t\t\t},\n\t\t}\n\t\t_, _, err := prog.run(&opts)\n\n\t\terrs <- err\n\t}()\n\n\ttid := <-tidChan\n\tfor {\n\t\terr := unix.Tgkill(tgid, tid, unix.SIGUSR1)\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Can't send signal to goroutine thread:\", err)\n\t\t}\n\n\t\tselect {\n\t\tcase err, ok := <-errs:\n\t\t\tif !ok {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\ttestutils.SkipIfNotSupported(t, err)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatal(\"testRun wasn't interrupted\")\n\t\t\t}\n\n\t\t\tt.Fatal(\"testRun returned an error:\", err)\n\n\t\tcase <-timeout:\n\t\t\tt.Fatal(\"Timed out trying to interrupt the goroutine\")\n\n\t\tdefault:\n\t\t}\n\t}\n}\n\nfunc TestProgramClose(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\tif err := prog.Close(); err != nil {\n\t\tt.Fatal(\"Can't close program:\", err)\n\t}\n}\n\nfunc TestProgramPin(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\ttmp := testutils.TempBPFFS(t)\n\n\tpath := filepath.Join(tmp, \"program\")\n\tif err := prog.Pin(path); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tpinned := prog.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tprog.Close()\n\n\tprog, err := LoadPinnedProgram(path, nil)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tif prog.Type() != SocketFilter {\n\t\tt.Error(\"Expected pinned program to have type SocketFilter, but got\", prog.Type())\n\t}\n\n\tif haveObjName() == nil {\n\t\tif prog.name != \"test\" {\n\t\t\tt.Errorf(\"Expected program to have object name 'test', got '%s'\", prog.name)\n\t\t}\n\t} else {\n\t\tif prog.name != \"program\" {\n\t\t\tt.Errorf(\"Expected program to have file name 'program', got '%s'\", prog.name)\n\t\t}\n\t}\n\n\tif !prog.IsPinned() {\n\t\tt.Error(\"Expected IsPinned to be true\")\n\t}\n}\n\nfunc TestProgramUnpin(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\ttmp := testutils.TempBPFFS(t)\n\n\tpath := filepath.Join(tmp, \"program\")\n\tif err := prog.Pin(path); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tpinned := prog.IsPinned()\n\tqt.Assert(t, qt.IsTrue(pinned))\n\n\tif err := prog.Unpin(); err != nil {\n\t\tt.Fatal(\"Failed to unpin program:\", err)\n\t}\n\tif _, err := os.Stat(path); err == nil {\n\t\tt.Fatal(\"Pinned program path still exists after unpinning:\", err)\n\t}\n}\n\nfunc TestProgramLoadPinnedWithFlags(t *testing.T) {\n\t// Introduced in commit 6e71b04a8224.\n\ttestutils.SkipOnOldKernel(t, \"4.14\", \"file_flags in BPF_OBJ_GET\")\n\n\tprog := mustSocketFilter(t)\n\n\ttmp := testutils.TempBPFFS(t)\n\n\tpath := filepath.Join(tmp, \"program\")\n\tif err := prog.Pin(path); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tprog.Close()\n\n\t_, err := LoadPinnedProgram(path, &LoadPinOptions{\n\t\tFlags: math.MaxUint32,\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif !errors.Is(err, unix.EINVAL) {\n\t\tt.Fatal(\"Invalid flags don't trigger an error:\", err)\n\t}\n}\n\nfunc TestProgramVerifierOutputOnError(t *testing.T) {\n\t_, err := NewProgram(&ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t})\n\tif err == nil {\n\t\tt.Fatal(\"Expected program to be invalid\")\n\t}\n\n\tve, ok := err.(*VerifierError)\n\tif !ok {\n\t\tt.Fatal(\"NewProgram does return an unwrapped VerifierError\")\n\t}\n\n\tif !strings.Contains(ve.Error(), \"R0 !read_ok\") {\n\t\tt.Logf(\"%+v\", ve)\n\t\tt.Error(\"Missing verifier log in error summary\")\n\t}\n}\n\nfunc TestProgramKernelVersion(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.20\", \"KernelVersion\")\n\tprog, err := NewProgram(&ProgramSpec{\n\t\tType: Kprobe,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tKernelVersion: 42,\n\t\tLicense:       \"MIT\",\n\t})\n\tif err != nil {\n\t\tt.Fatal(\"Could not load Kprobe program\")\n\t}\n\tdefer prog.Close()\n}\n\nfunc TestProgramVerifierOutput(t *testing.T) {\n\tprog, err := NewProgramWithOptions(socketFilterSpec, ProgramOptions{\n\t\tLogLevel: LogLevelInstruction,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tif prog.VerifierLog == \"\" {\n\t\tt.Error(\"Expected VerifierLog to be present\")\n\t}\n\n\t// Issue 64\n\t_, err = NewProgramWithOptions(&ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.Mov.Reg(asm.R0, asm.R1),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}, ProgramOptions{\n\t\tLogLevel: LogLevelInstruction,\n\t})\n\n\tif err == nil {\n\t\tt.Fatal(\"Expected an error from invalid program\")\n\t}\n\n\tvar ve *internal.VerifierError\n\tif !errors.As(err, &ve) {\n\t\tt.Error(\"Error is not a VerifierError\")\n\t}\n}\n\nfunc TestProgramVerifierLog(t *testing.T) {\n\tcheck := func(t *testing.T, err error) {\n\t\tt.Helper()\n\n\t\tvar ve *internal.VerifierError\n\t\tqt.Assert(t, qt.ErrorAs(err, &ve))\n\n\t\tloglen := len(fmt.Sprintf(\"%+v\", ve))\n\t\tqt.Assert(t, qt.IsTrue(loglen > minVerifierLogSize),\n\t\t\tqt.Commentf(\"Log buffer didn't grow past minimum, got %d bytes\", loglen))\n\t}\n\n\t// Generate a base program of sufficient size whose verifier log does not fit\n\t// in the minimum buffer size. Stay under 4096 insn limit of older kernels.\n\tvar base asm.Instructions\n\tfor i := 0; i < 4093; i++ {\n\t\tbase = append(base, asm.Mov.Reg(asm.R0, asm.R1))\n\t}\n\n\t// Touch R10 (read-only frame pointer) to reliably force a verifier error.\n\tinvalid := slices.Clone(base)\n\tinvalid = append(invalid, asm.Mov.Reg(asm.R10, asm.R0))\n\tinvalid = append(invalid, asm.Return())\n\n\tvalid := slices.Clone(base)\n\tvalid = append(valid, asm.Return())\n\n\t// Start out with testing against the invalid program.\n\tspec := &ProgramSpec{\n\t\tType:         SocketFilter,\n\t\tLicense:      \"MIT\",\n\t\tInstructions: invalid,\n\t}\n\n\t// Don't explicitly request a verifier log for an invalid program.\n\t_, err := NewProgramWithOptions(spec, ProgramOptions{})\n\tcheck(t, err)\n\n\t// Explicitly request a verifier log for an invalid program.\n\t_, err = NewProgramWithOptions(spec, ProgramOptions{\n\t\tLogLevel: LogLevelInstruction,\n\t})\n\tcheck(t, err)\n\n\t// Disabling the verifier log should result in a VerifierError without a log.\n\t_, err = NewProgramWithOptions(spec, ProgramOptions{\n\t\tLogDisabled: true,\n\t})\n\tvar ve *internal.VerifierError\n\tqt.Assert(t, qt.ErrorAs(err, &ve))\n\tqt.Assert(t, qt.HasLen(ve.Log, 0))\n\n\t// Run tests against a valid program from here on out.\n\tspec.Instructions = valid\n\n\t// Don't request a verifier log, expect the valid program to be created\n\t// without errors.\n\tprog, err := NewProgramWithOptions(spec, ProgramOptions{})\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.HasLen(prog.VerifierLog, 0))\n\tprog.Close()\n\n\t// Explicitly request verifier log for a valid program. If a log is requested\n\t// and the buffer is too small, ENOSPC occurs even for valid programs.\n\tprog, err = NewProgramWithOptions(spec, ProgramOptions{\n\t\tLogLevel: LogLevelInstruction,\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.IsTrue(len(prog.VerifierLog) > minVerifierLogSize))\n\tprog.Close()\n\n\t// Repeat the previous test with a larger starting buffer size.\n\tprog, err = NewProgramWithOptions(spec, ProgramOptions{\n\t\tLogLevel:     LogLevelInstruction,\n\t\tLogSizeStart: minVerifierLogSize * 2,\n\t})\n\tqt.Assert(t, qt.IsNil(err))\n\tqt.Assert(t, qt.IsTrue(len(prog.VerifierLog) > minVerifierLogSize))\n\tprog.Close()\n}\n\nfunc TestProgramWithUnsatisfiedMap(t *testing.T) {\n\tcoll, err := LoadCollectionSpec(\"testdata/loader-el.elf\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// The program will have at least one map reference.\n\tprogSpec := coll.Programs[\"xdp_prog\"]\n\tprogSpec.ByteOrder = nil\n\n\t_, err = NewProgram(progSpec)\n\ttestutils.SkipIfNotSupported(t, err)\n\tif !errors.Is(err, asm.ErrUnsatisfiedMapReference) {\n\t\tt.Fatal(\"Expected an error wrapping asm.ErrUnsatisfiedMapReference, got\", err)\n\t}\n\tt.Log(err)\n}\n\nfunc TestProgramName(t *testing.T) {\n\tif err := haveObjName(); err != nil {\n\t\tt.Skip(err)\n\t}\n\n\tprog := mustSocketFilter(t)\n\n\tvar info sys.ProgInfo\n\tif err := sys.ObjInfo(prog.fd, &info); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif name := unix.ByteSliceToString(info.Name[:]); name != \"test\" {\n\t\tt.Errorf(\"Name is not test, got '%s'\", name)\n\t}\n}\n\nfunc TestSanitizeName(t *testing.T) {\n\tfor input, want := range map[string]string{\n\t\t\"test\":     \"test\",\n\t\t\"t-est\":    \"test\",\n\t\t\"t_est\":    \"t_est\",\n\t\t\"hrnchen\": \"hrnchen\",\n\t} {\n\t\tif have := SanitizeName(input, -1); have != want {\n\t\t\tt.Errorf(\"Wanted '%s' got '%s'\", want, have)\n\t\t}\n\t}\n}\n\nfunc TestProgramCloneNil(t *testing.T) {\n\tp, err := (*Program)(nil).Clone()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif p != nil {\n\t\tt.Fatal(\"Cloning a nil Program doesn't return nil\")\n\t}\n}\n\nfunc TestProgramMarshaling(t *testing.T) {\n\tconst idx = uint32(0)\n\n\tarr := createProgramArray(t)\n\tdefer arr.Close()\n\n\tif err := arr.Put(idx, (*Program)(nil)); err == nil {\n\t\tt.Fatal(\"Put accepted a nil Program\")\n\t}\n\n\tprog := mustSocketFilter(t)\n\n\tif err := arr.Put(idx, prog); err != nil {\n\t\tt.Fatal(\"Can't put program:\", err)\n\t}\n\n\tif err := arr.Lookup(idx, Program{}); err == nil {\n\t\tt.Fatal(\"Lookup accepts non-pointer Program\")\n\t}\n\n\tvar prog2 *Program\n\tdefer prog2.Close()\n\n\tif err := arr.Lookup(idx, prog2); err == nil {\n\t\tt.Fatal(\"Get accepts *Program\")\n\t}\n\n\ttestutils.SkipOnOldKernel(t, \"4.12\", \"lookup for ProgramArray\")\n\n\tif err := arr.Lookup(idx, &prog2); err != nil {\n\t\tt.Fatal(\"Can't unmarshal program:\", err)\n\t}\n\tdefer prog2.Close()\n\n\tif prog2 == nil {\n\t\tt.Fatal(\"Unmarshalling set program to nil\")\n\t}\n}\n\nfunc TestProgramFromFD(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\t// If you're thinking about copying this, don't. Use\n\t// Clone() instead.\n\tprog2, err := NewProgramFromFD(dupFD(t, prog.FD()))\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog2.Close()\n\n\t// Name and type are supposed to be copied from program info.\n\tif haveObjName() == nil && prog2.name != \"test\" {\n\t\tt.Errorf(\"Expected program to have name test, got '%s'\", prog2.name)\n\t}\n\n\tif prog2.typ != SocketFilter {\n\t\tt.Errorf(\"Expected program to have type SocketFilter, got '%s'\", prog2.typ)\n\t}\n}\n\nfunc TestHaveProgTestRun(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveProgRun)\n}\n\nfunc TestProgramGetNextID(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.13\", \"bpf_prog_get_next_id\")\n\n\t// Ensure there is at least one program loaded\n\t_ = mustSocketFilter(t)\n\n\t// As there can be multiple eBPF programs, we loop over all of them and\n\t// make sure, the IDs increase and the last call will return ErrNotExist\n\tlast := ProgramID(0)\n\tfor {\n\t\tnext, err := ProgramGetNextID(last)\n\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\tif last == 0 {\n\t\t\t\tt.Fatal(\"Got ErrNotExist on the first iteration\")\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatal(\"Unexpected error:\", err)\n\t\t}\n\t\tif next <= last {\n\t\t\tt.Fatalf(\"Expected next ID (%d) to be higher than the last ID (%d)\", next, last)\n\t\t}\n\t\tlast = next\n\t}\n}\n\nfunc TestNewProgramFromID(t *testing.T) {\n\tprog := mustSocketFilter(t)\n\n\tinfo, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"Could not get program info:\", err)\n\t}\n\n\tid, ok := info.ID()\n\tif !ok {\n\t\tt.Skip(\"Program ID not supported\")\n\t}\n\n\tprog2, err := NewProgramFromID(id)\n\tif err != nil {\n\t\tt.Fatalf(\"Can't get FD for program ID %d: %v\", id, err)\n\t}\n\tprog2.Close()\n\n\t// As there can be multiple programs, we use max(uint32) as ProgramID to trigger an expected error.\n\t_, err = NewProgramFromID(ProgramID(math.MaxUint32))\n\tif !errors.Is(err, os.ErrNotExist) {\n\t\tt.Fatal(\"Expected ErrNotExist, got:\", err)\n\t}\n}\n\nfunc TestProgramRejectIncorrectByteOrder(t *testing.T) {\n\tspec := socketFilterSpec.Copy()\n\n\tspec.ByteOrder = binary.BigEndian\n\tif spec.ByteOrder == internal.NativeEndian {\n\t\tspec.ByteOrder = binary.LittleEndian\n\t}\n\n\t_, err := NewProgram(spec)\n\tif err == nil {\n\t\tt.Error(\"Incorrect ByteOrder should be rejected at load time\")\n\t}\n}\n\nfunc TestProgramSpecCopy(t *testing.T) {\n\ta := &ProgramSpec{\n\t\t\"test\",\n\t\t1,\n\t\t1,\n\t\t\"attach\",\n\t\tnil, // Can't copy Program\n\t\t\"section\",\n\t\tasm.Instructions{\n\t\t\tasm.Return(),\n\t\t},\n\t\t1,\n\t\t\"license\",\n\t\t1,\n\t\tbinary.LittleEndian,\n\t}\n\n\tqt.Check(t, qt.IsNil((*ProgramSpec)(nil).Copy()))\n\tqt.Assert(t, testutils.IsDeepCopy(a.Copy(), a))\n}\n\nfunc TestProgramSpecTag(t *testing.T) {\n\tarr := createArray(t)\n\n\tspec := &ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, -1, asm.DWord),\n\t\t\tasm.LoadMapPtr(asm.R1, arr.FD()),\n\t\t\tasm.Mov.Imm32(asm.R0, 0),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}\n\n\tprog, err := NewProgram(spec)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tinfo, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttag, err := spec.Tag()\n\tif err != nil {\n\t\tt.Fatal(\"Can't calculate tag:\", err)\n\t}\n\n\tif tag != info.Tag {\n\t\tt.Errorf(\"Calculated tag %s doesn't match kernel tag %s\", tag, info.Tag)\n\t}\n}\n\nfunc TestProgramAttachToKernel(t *testing.T) {\n\t// See https://github.com/torvalds/linux/commit/290248a5b7d829871b3ea3c62578613a580a1744\n\ttestutils.SkipOnOldKernel(t, \"5.5\", \"attach_btf_id\")\n\n\thaveTestmod := haveTestmod(t)\n\n\ttests := []struct {\n\t\tattachTo    string\n\t\tprogramType ProgramType\n\t\tattachType  AttachType\n\t\tflags       uint32\n\t}{\n\t\t{\n\t\t\tattachTo:    \"task_getpgid\",\n\t\t\tprogramType: LSM,\n\t\t\tattachType:  AttachLSMMac,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"inet_dgram_connect\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceFEntry,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"inet_dgram_connect\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceFExit,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"bpf_modify_return_test\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachModifyReturn,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"kfree_skb\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceRawTp,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"bpf_testmod_test_read\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceFEntry,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"bpf_testmod_test_read\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceFExit,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"bpf_testmod_test_read\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachModifyReturn,\n\t\t},\n\t\t{\n\t\t\tattachTo:    \"bpf_testmod_test_read\",\n\t\t\tprogramType: Tracing,\n\t\t\tattachType:  AttachTraceRawTp,\n\t\t},\n\t}\n\tfor _, test := range tests {\n\t\tname := fmt.Sprintf(\"%s:%s\", test.attachType, test.attachTo)\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tif strings.HasPrefix(test.attachTo, \"bpf_testmod_\") && !haveTestmod {\n\t\t\t\tt.Skip(\"bpf_testmod not loaded\")\n\t\t\t}\n\n\t\t\tprog, err := NewProgram(&ProgramSpec{\n\t\t\t\tAttachTo:   test.attachTo,\n\t\t\t\tAttachType: test.attachType,\n\t\t\t\tInstructions: asm.Instructions{\n\t\t\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t\t\tasm.Return(),\n\t\t\t\t},\n\t\t\t\tLicense: \"GPL\",\n\t\t\t\tType:    test.programType,\n\t\t\t\tFlags:   test.flags,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(\"Can't load program:\", err)\n\t\t\t}\n\t\t\tprog.Close()\n\t\t})\n\t}\n}\n\nfunc TestProgramKernelTypes(t *testing.T) {\n\tif _, err := os.Stat(\"/sys/kernel/btf/vmlinux\"); os.IsNotExist(err) {\n\t\tt.Skip(\"/sys/kernel/btf/vmlinux not present\")\n\t}\n\n\tbtfSpec, err := btf.LoadSpec(\"/sys/kernel/btf/vmlinux\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tprog, err := NewProgramWithOptions(&ProgramSpec{\n\t\tType:       Tracing,\n\t\tAttachType: AttachTraceIter,\n\t\tAttachTo:   \"bpf_map\",\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.Mov.Imm(asm.R0, 0),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}, ProgramOptions{\n\t\tKernelTypes: btfSpec,\n\t})\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(\"NewProgram with Target:\", err)\n\t}\n\tprog.Close()\n}\n\nfunc TestProgramBindMap(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"5.10\", \"BPF_PROG_BIND_MAP\")\n\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       Array,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load map: %v\", err)\n\t}\n\tdefer arr.Close()\n\n\tprog := mustSocketFilter(t)\n\n\t// The attached map does not contain BTF information. So\n\t// the metadata part of the program will be empty. This\n\t// test just makes sure that we can bind a map to a program.\n\tif err := prog.BindMap(arr); err != nil {\n\t\tt.Errorf(\"Failed to bind map to program: %v\", err)\n\t}\n}\n\nfunc TestProgramInstructions(t *testing.T) {\n\tname := \"test_prog\"\n\tspec := &ProgramSpec{\n\t\tType: SocketFilter,\n\t\tName: name,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, -1, asm.DWord).WithSymbol(name),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}\n\n\tprog, err := NewProgram(spec)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer prog.Close()\n\n\tpi, err := prog.Info()\n\ttestutils.SkipIfNotSupported(t, err)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tinsns, err := pi.Instructions()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttag, err := spec.Tag()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttagXlated, err := insns.Tag(internal.NativeEndian)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif tag != tagXlated {\n\t\tt.Fatalf(\"tag %s differs from xlated instructions tag %s\", tag, tagXlated)\n\t}\n}\n\nfunc TestProgramLoadErrors(t *testing.T) {\n\ttestutils.SkipOnOldKernel(t, \"4.10\", \"stable verifier log output\")\n\n\tspec, err := LoadCollectionSpec(testutils.NativeFile(t, \"testdata/errors-%s.elf\"))\n\tqt.Assert(t, qt.IsNil(err))\n\n\tvar b btf.Builder\n\traw, err := b.Marshal(nil, nil)\n\tqt.Assert(t, qt.IsNil(err))\n\tempty, err := btf.LoadSpecFromReader(bytes.NewReader(raw))\n\tqt.Assert(t, qt.IsNil(err))\n\n\tfor _, test := range []struct {\n\t\tname string\n\t\twant error\n\t}{\n\t\t{\"poisoned_single\", errBadRelocation},\n\t\t{\"poisoned_double\", errBadRelocation},\n\t\t{\"poisoned_kfunc\", errUnknownKfunc},\n\t} {\n\t\tprogSpec := spec.Programs[test.name]\n\t\tqt.Assert(t, qt.IsNotNil(progSpec))\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Log(progSpec.Instructions)\n\t\t\t_, err := NewProgramWithOptions(progSpec, ProgramOptions{\n\t\t\t\tKernelTypes: empty,\n\t\t\t})\n\t\t\ttestutils.SkipIfNotSupported(t, err)\n\n\t\t\tvar ve *VerifierError\n\t\t\tqt.Assert(t, qt.ErrorAs(err, &ve))\n\t\t\tt.Logf(\"%-5v\", ve)\n\n\t\t\tqt.Assert(t, qt.ErrorIs(err, test.want))\n\t\t})\n\t}\n}\n\nfunc BenchmarkNewProgram(b *testing.B) {\n\ttestutils.SkipOnOldKernel(b, \"5.18\", \"kfunc support\")\n\tspec, err := LoadCollectionSpec(testutils.NativeFile(b, \"testdata/kfunc-%s.elf\"))\n\tqt.Assert(b, qt.IsNil(err))\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\t_, err := NewProgram(spec.Programs[\"benchmark\"])\n\t\tif !errors.Is(err, unix.EACCES) {\n\t\t\tb.Fatal(\"Unexpected error:\", err)\n\t\t}\n\t}\n}\n\nfunc createProgramArray(t *testing.T) *Map {\n\tt.Helper()\n\n\tarr, err := NewMap(&MapSpec{\n\t\tType:       ProgramArray,\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treturn arr\n}\n\nvar socketFilterSpec = &ProgramSpec{\n\tName: \"test\",\n\tType: SocketFilter,\n\tInstructions: asm.Instructions{\n\t\tasm.LoadImm(asm.R0, 2, asm.DWord),\n\t\tasm.Return(),\n\t},\n\tLicense: \"MIT\",\n}\n\nfunc mustSocketFilter(tb testing.TB) *Program {\n\ttb.Helper()\n\n\tprog, err := NewProgram(socketFilterSpec)\n\tif err != nil {\n\t\ttb.Fatal(err)\n\t}\n\ttb.Cleanup(func() { prog.Close() })\n\n\treturn prog\n}\n\n// Print the full verifier log when loading a program fails.\nfunc ExampleVerifierError_retrieveFullLog() {\n\t_, err := NewProgram(&ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\t// Missing Return\n\t\t},\n\t\tLicense: \"MIT\",\n\t})\n\n\tvar ve *VerifierError\n\tif errors.As(err, &ve) {\n\t\t// Using %+v will print the whole verifier error, not just the last\n\t\t// few lines.\n\t\tfmt.Printf(\"Verifier error: %+v\\n\", ve)\n\t}\n}\n\n// VerifierLog understands a variety of formatting flags.\nfunc ExampleVerifierError() {\n\terr := internal.ErrorWithLog(\n\t\t\"catastrophe\",\n\t\tsyscall.ENOSPC,\n\t\t[]byte(\"first\\nsecond\\nthird\"),\n\t)\n\n\tfmt.Printf(\"With %%s: %s\\n\", err)\n\tfmt.Printf(\"All log lines: %+v\\n\", err)\n\tfmt.Printf(\"First line: %+1v\\n\", err)\n\tfmt.Printf(\"Last two lines: %-2v\\n\", err)\n\n\t// Output: With %s: catastrophe: no space left on device: third (2 line(s) omitted)\n\t// All log lines: catastrophe: no space left on device:\n\t// \tfirst\n\t// \tsecond\n\t// \tthird\n\t// First line: catastrophe: no space left on device:\n\t// \tfirst\n\t// \t(2 line(s) omitted)\n\t// Last two lines: catastrophe: no space left on device:\n\t// \t(1 line(s) omitted)\n\t// \tsecond\n\t// \tthird\n}\n\n// Use NewProgramWithOptions if you'd like to get the verifier output\n// for a program, or if you want to change the buffer size used when\n// generating error messages.\nfunc ExampleProgram_retrieveVerifierLog() {\n\tspec := &ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}\n\n\tprog, err := NewProgramWithOptions(spec, ProgramOptions{\n\t\tLogLevel: LogLevelInstruction,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer prog.Close()\n\n\tfmt.Println(\"The verifier output is:\")\n\tfmt.Println(prog.VerifierLog)\n}\n\n// It's possible to read a program directly from a ProgramArray.\nfunc ExampleProgram_unmarshalFromMap() {\n\tprogArray, err := LoadPinnedMap(\"/path/to/map\", nil)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer progArray.Close()\n\n\t// Load a single program\n\tvar prog *Program\n\tif err := progArray.Lookup(uint32(0), &prog); err != nil {\n\t\tpanic(err)\n\t}\n\tdefer prog.Close()\n\n\tfmt.Println(\"first prog:\", prog)\n\n\t// Iterate all programs\n\tvar (\n\t\tkey     uint32\n\t\tentries = progArray.Iterate()\n\t)\n\n\tfor entries.Next(&key, &prog) {\n\t\tfmt.Println(key, \"is\", prog)\n\t}\n\n\tif err := entries.Err(); err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc ExampleProgramSpec_Tag() {\n\tspec := &ProgramSpec{\n\t\tType: SocketFilter,\n\t\tInstructions: asm.Instructions{\n\t\t\tasm.LoadImm(asm.R0, 0, asm.DWord),\n\t\t\tasm.Return(),\n\t\t},\n\t\tLicense: \"MIT\",\n\t}\n\n\tprog, _ := NewProgram(spec)\n\tinfo, _ := prog.Info()\n\ttag, _ := spec.Tag()\n\n\tif info.Tag != tag {\n\t\tfmt.Printf(\"The tags don't match: %s != %s\\n\", info.Tag, tag)\n\t} else {\n\t\tfmt.Println(\"The programs are identical, tag is\", tag)\n\t}\n}\n\nfunc dupFD(tb testing.TB, fd int) int {\n\ttb.Helper()\n\n\tdup, err := unix.FcntlInt(uintptr(fd), unix.F_DUPFD_CLOEXEC, 1)\n\tif err != nil {\n\t\ttb.Fatal(\"Can't dup fd:\", err)\n\t}\n\n\treturn dup\n}\n"
        },
        {
          "name": "ringbuf",
          "type": "tree",
          "content": null
        },
        {
          "name": "rlimit",
          "type": "tree",
          "content": null
        },
        {
          "name": "syscalls.go",
          "type": "blob",
          "size": 7.9755859375,
          "content": "package ebpf\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"runtime\"\n\n\t\"github.com/cilium/ebpf/asm\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/linux\"\n\t\"github.com/cilium/ebpf/internal/sys\"\n\t\"github.com/cilium/ebpf/internal/tracefs\"\n\t\"github.com/cilium/ebpf/internal/unix\"\n)\n\nvar (\n\t// pre-allocating these here since they may\n\t// get called in hot code paths and cause\n\t// unnecessary memory allocations\n\tsysErrKeyNotExist  = sys.Error(ErrKeyNotExist, unix.ENOENT)\n\tsysErrKeyExist     = sys.Error(ErrKeyExist, unix.EEXIST)\n\tsysErrNotSupported = sys.Error(ErrNotSupported, sys.ENOTSUPP)\n)\n\n// invalidBPFObjNameChar returns true if char may not appear in\n// a BPF object name.\nfunc invalidBPFObjNameChar(char rune) bool {\n\tdotAllowed := objNameAllowsDot() == nil\n\n\tswitch {\n\tcase char >= 'A' && char <= 'Z':\n\t\treturn false\n\tcase char >= 'a' && char <= 'z':\n\t\treturn false\n\tcase char >= '0' && char <= '9':\n\t\treturn false\n\tcase dotAllowed && char == '.':\n\t\treturn false\n\tcase char == '_':\n\t\treturn false\n\tdefault:\n\t\treturn true\n\t}\n}\n\nfunc progLoad(insns asm.Instructions, typ ProgramType, license string) (*sys.FD, error) {\n\tbuf := bytes.NewBuffer(make([]byte, 0, insns.Size()))\n\tif err := insns.Marshal(buf, internal.NativeEndian); err != nil {\n\t\treturn nil, err\n\t}\n\tbytecode := buf.Bytes()\n\n\treturn sys.ProgLoad(&sys.ProgLoadAttr{\n\t\tProgType: sys.ProgType(typ),\n\t\tLicense:  sys.NewStringPointer(license),\n\t\tInsns:    sys.NewSlicePointer(bytecode),\n\t\tInsnCnt:  uint32(len(bytecode) / asm.InstructionSize),\n\t})\n}\n\nvar haveNestedMaps = internal.NewFeatureTest(\"nested maps\", func() error {\n\t_, err := sys.MapCreate(&sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(ArrayOfMaps),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\t// Invalid file descriptor.\n\t\tInnerMapFd: ^uint32(0),\n\t})\n\tif errors.Is(err, unix.EINVAL) {\n\t\treturn internal.ErrNotSupported\n\t}\n\tif errors.Is(err, unix.EBADF) {\n\t\treturn nil\n\t}\n\treturn err\n}, \"4.12\")\n\nvar haveMapMutabilityModifiers = internal.NewFeatureTest(\"read- and write-only maps\", func() error {\n\t// This checks BPF_F_RDONLY_PROG and BPF_F_WRONLY_PROG. Since\n\t// BPF_MAP_FREEZE appeared in 5.2 as well we don't do a separate check.\n\tm, err := sys.MapCreate(&sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Array),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapFlags:   sys.BPF_F_RDONLY_PROG,\n\t})\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = m.Close()\n\treturn nil\n}, \"5.2\")\n\nvar haveMmapableMaps = internal.NewFeatureTest(\"mmapable maps\", func() error {\n\t// This checks BPF_F_MMAPABLE, which appeared in 5.5 for array maps.\n\tm, err := sys.MapCreate(&sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Array),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapFlags:   sys.BPF_F_MMAPABLE,\n\t})\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = m.Close()\n\treturn nil\n}, \"5.5\")\n\nvar haveInnerMaps = internal.NewFeatureTest(\"inner maps\", func() error {\n\t// This checks BPF_F_INNER_MAP, which appeared in 5.10.\n\tm, err := sys.MapCreate(&sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Array),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapFlags:   sys.BPF_F_INNER_MAP,\n\t})\n\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = m.Close()\n\treturn nil\n}, \"5.10\")\n\nvar haveNoPreallocMaps = internal.NewFeatureTest(\"prealloc maps\", func() error {\n\t// This checks BPF_F_NO_PREALLOC, which appeared in 4.6.\n\tm, err := sys.MapCreate(&sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Hash),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapFlags:   sys.BPF_F_NO_PREALLOC,\n\t})\n\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = m.Close()\n\treturn nil\n}, \"4.6\")\n\nfunc wrapMapError(err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\tif errors.Is(err, unix.ENOENT) {\n\t\treturn sysErrKeyNotExist\n\t}\n\n\tif errors.Is(err, unix.EEXIST) {\n\t\treturn sysErrKeyExist\n\t}\n\n\tif errors.Is(err, sys.ENOTSUPP) {\n\t\treturn sysErrNotSupported\n\t}\n\n\tif errors.Is(err, unix.E2BIG) {\n\t\treturn fmt.Errorf(\"key too big for map: %w\", err)\n\t}\n\n\treturn err\n}\n\nvar haveObjName = internal.NewFeatureTest(\"object names\", func() error {\n\tattr := sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Array),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapName:    sys.NewObjName(\"feature_test\"),\n\t}\n\n\t// Tolerate EPERM as this runs during ELF loading which is potentially\n\t// unprivileged. Only EINVAL is conclusive, thrown from CHECK_ATTR.\n\tfd, err := sys.MapCreate(&attr)\n\tif errors.Is(err, unix.EPERM) {\n\t\treturn nil\n\t}\n\tif errors.Is(err, unix.EINVAL) {\n\t\treturn internal.ErrNotSupported\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_ = fd.Close()\n\treturn nil\n}, \"4.15\")\n\nvar objNameAllowsDot = internal.NewFeatureTest(\"dot in object names\", func() error {\n\tif err := haveObjName(); err != nil {\n\t\treturn err\n\t}\n\n\tattr := sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Array),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: 1,\n\t\tMapName:    sys.NewObjName(\".test\"),\n\t}\n\n\t// Tolerate EPERM, otherwise MapSpec.Name has its dots removed when run by\n\t// unprivileged tools. (bpf2go, other code gen). Only EINVAL is conclusive,\n\t// thrown from bpf_obj_name_cpy().\n\tfd, err := sys.MapCreate(&attr)\n\tif errors.Is(err, unix.EPERM) {\n\t\treturn nil\n\t}\n\tif errors.Is(err, unix.EINVAL) {\n\t\treturn internal.ErrNotSupported\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_ = fd.Close()\n\treturn nil\n}, \"5.2\")\n\nvar haveBatchAPI = internal.NewFeatureTest(\"map batch api\", func() error {\n\tvar maxEntries uint32 = 2\n\tattr := sys.MapCreateAttr{\n\t\tMapType:    sys.MapType(Hash),\n\t\tKeySize:    4,\n\t\tValueSize:  4,\n\t\tMaxEntries: maxEntries,\n\t}\n\n\tfd, err := sys.MapCreate(&attr)\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\tdefer fd.Close()\n\n\tkeys := []uint32{1, 2}\n\tvalues := []uint32{3, 4}\n\tkp, _ := marshalMapSyscallInput(keys, 8)\n\tvp, _ := marshalMapSyscallInput(values, 8)\n\n\terr = sys.MapUpdateBatch(&sys.MapUpdateBatchAttr{\n\t\tMapFd:  fd.Uint(),\n\t\tKeys:   kp,\n\t\tValues: vp,\n\t\tCount:  maxEntries,\n\t})\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\treturn nil\n}, \"5.6\")\n\nvar haveProbeReadKernel = internal.NewFeatureTest(\"bpf_probe_read_kernel\", func() error {\n\tinsns := asm.Instructions{\n\t\tasm.Mov.Reg(asm.R1, asm.R10),\n\t\tasm.Add.Imm(asm.R1, -8),\n\t\tasm.Mov.Imm(asm.R2, 8),\n\t\tasm.Mov.Imm(asm.R3, 0),\n\t\tasm.FnProbeReadKernel.Call(),\n\t\tasm.Return(),\n\t}\n\n\tfd, err := progLoad(insns, Kprobe, \"GPL\")\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = fd.Close()\n\treturn nil\n}, \"5.5\")\n\nvar haveBPFToBPFCalls = internal.NewFeatureTest(\"bpf2bpf calls\", func() error {\n\tinsns := asm.Instructions{\n\t\tasm.Call.Label(\"prog2\").WithSymbol(\"prog1\"),\n\t\tasm.Return(),\n\t\tasm.Mov.Imm(asm.R0, 0).WithSymbol(\"prog2\"),\n\t\tasm.Return(),\n\t}\n\n\tfd, err := progLoad(insns, SocketFilter, \"MIT\")\n\tif err != nil {\n\t\treturn internal.ErrNotSupported\n\t}\n\t_ = fd.Close()\n\treturn nil\n}, \"4.16\")\n\nvar haveSyscallWrapper = internal.NewFeatureTest(\"syscall wrapper\", func() error {\n\tprefix := linux.PlatformPrefix()\n\tif prefix == \"\" {\n\t\treturn fmt.Errorf(\"unable to find the platform prefix for (%s)\", runtime.GOARCH)\n\t}\n\n\targs := tracefs.ProbeArgs{\n\t\tType:   tracefs.Kprobe,\n\t\tSymbol: prefix + \"sys_bpf\",\n\t\tPid:    -1,\n\t}\n\n\tvar err error\n\targs.Group, err = tracefs.RandomGroup(\"ebpf_probe\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tevt, err := tracefs.NewEvent(args)\n\tif errors.Is(err, os.ErrNotExist) {\n\t\treturn internal.ErrNotSupported\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn evt.Close()\n}, \"4.17\")\n\nvar haveProgramExtInfos = internal.NewFeatureTest(\"program ext_infos\", func() error {\n\tinsns := asm.Instructions{\n\t\tasm.Mov.Imm(asm.R0, 0),\n\t\tasm.Return(),\n\t}\n\n\tbuf := bytes.NewBuffer(make([]byte, 0, insns.Size()))\n\tif err := insns.Marshal(buf, internal.NativeEndian); err != nil {\n\t\treturn err\n\t}\n\tbytecode := buf.Bytes()\n\n\t_, err := sys.ProgLoad(&sys.ProgLoadAttr{\n\t\tProgType:    sys.ProgType(SocketFilter),\n\t\tLicense:     sys.NewStringPointer(\"MIT\"),\n\t\tInsns:       sys.NewSlicePointer(bytecode),\n\t\tInsnCnt:     uint32(len(bytecode) / asm.InstructionSize),\n\t\tFuncInfoCnt: 1,\n\t\tProgBtfFd:   math.MaxUint32,\n\t})\n\n\tif errors.Is(err, unix.EBADF) {\n\t\treturn nil\n\t}\n\n\tif errors.Is(err, unix.E2BIG) {\n\t\treturn ErrNotSupported\n\t}\n\n\treturn err\n}, \"5.0\")\n"
        },
        {
          "name": "syscalls_test.go",
          "type": "blob",
          "size": 1.4755859375,
          "content": "package ebpf\n\nimport (\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/cilium/ebpf/internal/testutils\"\n)\n\nfunc TestObjNameCharacters(t *testing.T) {\n\tfor in, valid := range map[string]bool{\n\t\t\"test\":    true,\n\t\t\"\":        true,\n\t\t\"a-b\":     false,\n\t\t\"yeah so\": false,\n\t\t\"dot.\":    objNameAllowsDot() == nil,\n\t\t\"Capital\": true,\n\t} {\n\t\tresult := strings.IndexFunc(in, invalidBPFObjNameChar) == -1\n\t\tif result != valid {\n\t\t\tt.Errorf(\"Name '%s' classified incorrectly\", in)\n\t\t}\n\t}\n}\n\nfunc TestHaveBatchAPI(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveBatchAPI)\n}\n\nfunc TestHaveObjName(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveObjName)\n}\n\nfunc TestObjNameAllowsDot(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, objNameAllowsDot)\n}\n\nfunc TestHaveNestedMaps(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveNestedMaps)\n}\n\nfunc TestHaveMapMutabilityModifiers(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveMapMutabilityModifiers)\n}\n\nfunc TestHaveMmapableMaps(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveMmapableMaps)\n}\n\nfunc TestHaveInnerMaps(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveInnerMaps)\n}\n\nfunc TestHaveProbeReadKernel(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveProbeReadKernel)\n}\n\nfunc TestHaveBPFToBPFCalls(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveBPFToBPFCalls)\n}\n\nfunc TestHaveSyscallWrapper(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveSyscallWrapper)\n}\n\nfunc TestHaveProgramExtInfos(t *testing.T) {\n\ttestutils.CheckFeatureTest(t, haveProgramExtInfos)\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "types.go",
          "type": "blob",
          "size": 14.07421875,
          "content": "package ebpf\n\nimport (\n\t\"github.com/cilium/ebpf/internal/sys\"\n)\n\n//go:generate go run golang.org/x/tools/cmd/stringer@latest -output types_string.go -type=MapType,ProgramType,PinType\n\n// MapType indicates the type map structure\n// that will be initialized in the kernel.\ntype MapType uint32\n\n// All the various map types that can be created\nconst (\n\tUnspecifiedMap MapType = iota\n\t// Hash is a hash map\n\tHash\n\t// Array is an array map\n\tArray\n\t// ProgramArray - A program array map is a special kind of array map whose map\n\t// values contain only file descriptors referring to other eBPF\n\t// programs.  Thus, both the key_size and value_size must be\n\t// exactly four bytes.  This map is used in conjunction with the\n\t// TailCall helper.\n\tProgramArray\n\t// PerfEventArray - A perf event array is used in conjunction with PerfEventRead\n\t// and PerfEventOutput calls, to read the raw bpf_perf_data from the registers.\n\tPerfEventArray\n\t// PerCPUHash - This data structure is useful for people who have high performance\n\t// network needs and can reconcile adds at the end of some cycle, so that\n\t// hashes can be lock free without the use of XAdd, which can be costly.\n\tPerCPUHash\n\t// PerCPUArray - This data structure is useful for people who have high performance\n\t// network needs and can reconcile adds at the end of some cycle, so that\n\t// hashes can be lock free without the use of XAdd, which can be costly.\n\t// Each CPU gets a copy of this hash, the contents of all of which can be reconciled\n\t// later.\n\tPerCPUArray\n\t// StackTrace - This holds whole user and kernel stack traces, it can be retrieved with\n\t// GetStackID\n\tStackTrace\n\t// CGroupArray - This is a very niche structure used to help SKBInCGroup determine\n\t// if an skb is from a socket belonging to a specific cgroup\n\tCGroupArray\n\t// LRUHash - This allows you to create a small hash structure that will purge the\n\t// least recently used items rather than throw an error when you run out of memory\n\tLRUHash\n\t// LRUCPUHash - This is NOT like PerCPUHash, this structure is shared among the CPUs,\n\t// it has more to do with including the CPU id with the LRU calculation so that if a\n\t// particular CPU is using a value over-and-over again, then it will be saved, but if\n\t// a value is being retrieved a lot but sparsely across CPUs it is not as important, basically\n\t// giving weight to CPU locality over overall usage.\n\tLRUCPUHash\n\t// LPMTrie - This is an implementation of Longest-Prefix-Match Trie structure. It is useful,\n\t// for storing things like IP addresses which can be bit masked allowing for keys of differing\n\t// values to refer to the same reference based on their masks. See wikipedia for more details.\n\tLPMTrie\n\t// ArrayOfMaps - Each item in the array is another map. The inner map mustn't be a map of maps\n\t// itself.\n\tArrayOfMaps\n\t// HashOfMaps - Each item in the hash map is another map. The inner map mustn't be a map of maps\n\t// itself.\n\tHashOfMaps\n\t// DevMap - Specialized map to store references to network devices.\n\tDevMap\n\t// SockMap - Specialized map to store references to sockets.\n\tSockMap\n\t// CPUMap - Specialized map to store references to CPUs.\n\tCPUMap\n\t// XSKMap - Specialized map for XDP programs to store references to open sockets.\n\tXSKMap\n\t// SockHash - Specialized hash to store references to sockets.\n\tSockHash\n\t// CGroupStorage - Special map for CGroups.\n\tCGroupStorage\n\t// ReusePortSockArray - Specialized map to store references to sockets that can be reused.\n\tReusePortSockArray\n\t// PerCPUCGroupStorage - Special per CPU map for CGroups.\n\tPerCPUCGroupStorage\n\t// Queue - FIFO storage for BPF programs.\n\tQueue\n\t// Stack - LIFO storage for BPF programs.\n\tStack\n\t// SkStorage - Specialized map for local storage at SK for BPF programs.\n\tSkStorage\n\t// DevMapHash - Hash-based indexing scheme for references to network devices.\n\tDevMapHash\n\t// StructOpsMap - This map holds a kernel struct with its function pointer implemented in a BPF\n\t// program.\n\tStructOpsMap\n\t// RingBuf - Similar to PerfEventArray, but shared across all CPUs.\n\tRingBuf\n\t// InodeStorage - Specialized local storage map for inodes.\n\tInodeStorage\n\t// TaskStorage - Specialized local storage map for task_struct.\n\tTaskStorage\n\t// BloomFilter - Space-efficient data structure to quickly test whether an element exists in a set.\n\tBloomFilter\n\t// UserRingbuf - The reverse of RingBuf, used to send messages from user space to BPF programs.\n\tUserRingbuf\n\t// CgroupStorage - Store data keyed on a cgroup. If the cgroup disappears, the key is automatically removed.\n\tCgroupStorage\n\t// Arena - Sparse shared memory region between a BPF program and user space.\n\tArena\n)\n\n// hasPerCPUValue returns true if the Map stores a value per CPU.\nfunc (mt MapType) hasPerCPUValue() bool {\n\treturn mt == PerCPUHash || mt == PerCPUArray || mt == LRUCPUHash || mt == PerCPUCGroupStorage\n}\n\n// canStoreMapOrProgram returns true if the Map stores references to another Map\n// or Program.\nfunc (mt MapType) canStoreMapOrProgram() bool {\n\treturn mt.canStoreMap() || mt.canStoreProgram()\n}\n\n// canStoreMap returns true if the map type accepts a map fd\n// for update and returns a map id for lookup.\nfunc (mt MapType) canStoreMap() bool {\n\treturn mt == ArrayOfMaps || mt == HashOfMaps\n}\n\n// canStoreProgram returns true if the map type accepts a program fd\n// for update and returns a program id for lookup.\nfunc (mt MapType) canStoreProgram() bool {\n\treturn mt == ProgramArray\n}\n\n// canHaveValueSize returns true if the map type supports setting a value size.\nfunc (mt MapType) canHaveValueSize() bool {\n\tswitch mt {\n\tcase RingBuf, Arena:\n\t\treturn false\n\n\t// Special-case perf events since they require a value size of either 0 or 4\n\t// for historical reasons. Let the library fix this up later.\n\tcase PerfEventArray:\n\t\treturn false\n\t}\n\n\treturn true\n}\n\n// ProgramType of the eBPF program\ntype ProgramType uint32\n\n// eBPF program types\nconst (\n\tUnspecifiedProgram    = ProgramType(sys.BPF_PROG_TYPE_UNSPEC)\n\tSocketFilter          = ProgramType(sys.BPF_PROG_TYPE_SOCKET_FILTER)\n\tKprobe                = ProgramType(sys.BPF_PROG_TYPE_KPROBE)\n\tSchedCLS              = ProgramType(sys.BPF_PROG_TYPE_SCHED_CLS)\n\tSchedACT              = ProgramType(sys.BPF_PROG_TYPE_SCHED_ACT)\n\tTracePoint            = ProgramType(sys.BPF_PROG_TYPE_TRACEPOINT)\n\tXDP                   = ProgramType(sys.BPF_PROG_TYPE_XDP)\n\tPerfEvent             = ProgramType(sys.BPF_PROG_TYPE_PERF_EVENT)\n\tCGroupSKB             = ProgramType(sys.BPF_PROG_TYPE_CGROUP_SKB)\n\tCGroupSock            = ProgramType(sys.BPF_PROG_TYPE_CGROUP_SOCK)\n\tLWTIn                 = ProgramType(sys.BPF_PROG_TYPE_LWT_IN)\n\tLWTOut                = ProgramType(sys.BPF_PROG_TYPE_LWT_OUT)\n\tLWTXmit               = ProgramType(sys.BPF_PROG_TYPE_LWT_XMIT)\n\tSockOps               = ProgramType(sys.BPF_PROG_TYPE_SOCK_OPS)\n\tSkSKB                 = ProgramType(sys.BPF_PROG_TYPE_SK_SKB)\n\tCGroupDevice          = ProgramType(sys.BPF_PROG_TYPE_CGROUP_DEVICE)\n\tSkMsg                 = ProgramType(sys.BPF_PROG_TYPE_SK_MSG)\n\tRawTracepoint         = ProgramType(sys.BPF_PROG_TYPE_RAW_TRACEPOINT)\n\tCGroupSockAddr        = ProgramType(sys.BPF_PROG_TYPE_CGROUP_SOCK_ADDR)\n\tLWTSeg6Local          = ProgramType(sys.BPF_PROG_TYPE_LWT_SEG6LOCAL)\n\tLircMode2             = ProgramType(sys.BPF_PROG_TYPE_LIRC_MODE2)\n\tSkReuseport           = ProgramType(sys.BPF_PROG_TYPE_SK_REUSEPORT)\n\tFlowDissector         = ProgramType(sys.BPF_PROG_TYPE_FLOW_DISSECTOR)\n\tCGroupSysctl          = ProgramType(sys.BPF_PROG_TYPE_CGROUP_SYSCTL)\n\tRawTracepointWritable = ProgramType(sys.BPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE)\n\tCGroupSockopt         = ProgramType(sys.BPF_PROG_TYPE_CGROUP_SOCKOPT)\n\tTracing               = ProgramType(sys.BPF_PROG_TYPE_TRACING)\n\tStructOps             = ProgramType(sys.BPF_PROG_TYPE_STRUCT_OPS)\n\tExtension             = ProgramType(sys.BPF_PROG_TYPE_EXT)\n\tLSM                   = ProgramType(sys.BPF_PROG_TYPE_LSM)\n\tSkLookup              = ProgramType(sys.BPF_PROG_TYPE_SK_LOOKUP)\n\tSyscall               = ProgramType(sys.BPF_PROG_TYPE_SYSCALL)\n\tNetfilter             = ProgramType(sys.BPF_PROG_TYPE_NETFILTER)\n)\n\n// AttachType of the eBPF program, needed to differentiate allowed context accesses in\n// some newer program types like CGroupSockAddr. Should be set to AttachNone if not required.\n// Will cause invalid argument (EINVAL) at program load time if set incorrectly.\ntype AttachType uint32\n\n//go:generate go run golang.org/x/tools/cmd/stringer@latest -type AttachType -trimprefix Attach\n\n// AttachNone is an alias for AttachCGroupInetIngress for readability reasons.\nconst AttachNone AttachType = 0\n\nconst (\n\tAttachCGroupInetIngress          = AttachType(sys.BPF_CGROUP_INET_INGRESS)\n\tAttachCGroupInetEgress           = AttachType(sys.BPF_CGROUP_INET_EGRESS)\n\tAttachCGroupInetSockCreate       = AttachType(sys.BPF_CGROUP_INET_SOCK_CREATE)\n\tAttachCGroupSockOps              = AttachType(sys.BPF_CGROUP_SOCK_OPS)\n\tAttachSkSKBStreamParser          = AttachType(sys.BPF_SK_SKB_STREAM_PARSER)\n\tAttachSkSKBStreamVerdict         = AttachType(sys.BPF_SK_SKB_STREAM_VERDICT)\n\tAttachCGroupDevice               = AttachType(sys.BPF_CGROUP_DEVICE)\n\tAttachSkMsgVerdict               = AttachType(sys.BPF_SK_MSG_VERDICT)\n\tAttachCGroupInet4Bind            = AttachType(sys.BPF_CGROUP_INET4_BIND)\n\tAttachCGroupInet6Bind            = AttachType(sys.BPF_CGROUP_INET6_BIND)\n\tAttachCGroupInet4Connect         = AttachType(sys.BPF_CGROUP_INET4_CONNECT)\n\tAttachCGroupInet6Connect         = AttachType(sys.BPF_CGROUP_INET6_CONNECT)\n\tAttachCGroupInet4PostBind        = AttachType(sys.BPF_CGROUP_INET4_POST_BIND)\n\tAttachCGroupInet6PostBind        = AttachType(sys.BPF_CGROUP_INET6_POST_BIND)\n\tAttachCGroupUDP4Sendmsg          = AttachType(sys.BPF_CGROUP_UDP4_SENDMSG)\n\tAttachCGroupUDP6Sendmsg          = AttachType(sys.BPF_CGROUP_UDP6_SENDMSG)\n\tAttachLircMode2                  = AttachType(sys.BPF_LIRC_MODE2)\n\tAttachFlowDissector              = AttachType(sys.BPF_FLOW_DISSECTOR)\n\tAttachCGroupSysctl               = AttachType(sys.BPF_CGROUP_SYSCTL)\n\tAttachCGroupUDP4Recvmsg          = AttachType(sys.BPF_CGROUP_UDP4_RECVMSG)\n\tAttachCGroupUDP6Recvmsg          = AttachType(sys.BPF_CGROUP_UDP6_RECVMSG)\n\tAttachCGroupGetsockopt           = AttachType(sys.BPF_CGROUP_GETSOCKOPT)\n\tAttachCGroupSetsockopt           = AttachType(sys.BPF_CGROUP_SETSOCKOPT)\n\tAttachTraceRawTp                 = AttachType(sys.BPF_TRACE_RAW_TP)\n\tAttachTraceFEntry                = AttachType(sys.BPF_TRACE_FENTRY)\n\tAttachTraceFExit                 = AttachType(sys.BPF_TRACE_FEXIT)\n\tAttachModifyReturn               = AttachType(sys.BPF_MODIFY_RETURN)\n\tAttachLSMMac                     = AttachType(sys.BPF_LSM_MAC)\n\tAttachTraceIter                  = AttachType(sys.BPF_TRACE_ITER)\n\tAttachCgroupInet4GetPeername     = AttachType(sys.BPF_CGROUP_INET4_GETPEERNAME)\n\tAttachCgroupInet6GetPeername     = AttachType(sys.BPF_CGROUP_INET6_GETPEERNAME)\n\tAttachCgroupInet4GetSockname     = AttachType(sys.BPF_CGROUP_INET4_GETSOCKNAME)\n\tAttachCgroupInet6GetSockname     = AttachType(sys.BPF_CGROUP_INET6_GETSOCKNAME)\n\tAttachXDPDevMap                  = AttachType(sys.BPF_XDP_DEVMAP)\n\tAttachCgroupInetSockRelease      = AttachType(sys.BPF_CGROUP_INET_SOCK_RELEASE)\n\tAttachXDPCPUMap                  = AttachType(sys.BPF_XDP_CPUMAP)\n\tAttachSkLookup                   = AttachType(sys.BPF_SK_LOOKUP)\n\tAttachXDP                        = AttachType(sys.BPF_XDP)\n\tAttachSkSKBVerdict               = AttachType(sys.BPF_SK_SKB_VERDICT)\n\tAttachSkReuseportSelect          = AttachType(sys.BPF_SK_REUSEPORT_SELECT)\n\tAttachSkReuseportSelectOrMigrate = AttachType(sys.BPF_SK_REUSEPORT_SELECT_OR_MIGRATE)\n\tAttachPerfEvent                  = AttachType(sys.BPF_PERF_EVENT)\n\tAttachTraceKprobeMulti           = AttachType(sys.BPF_TRACE_KPROBE_MULTI)\n\tAttachLSMCgroup                  = AttachType(sys.BPF_LSM_CGROUP)\n\tAttachStructOps                  = AttachType(sys.BPF_STRUCT_OPS)\n\tAttachNetfilter                  = AttachType(sys.BPF_NETFILTER)\n\tAttachTCXIngress                 = AttachType(sys.BPF_TCX_INGRESS)\n\tAttachTCXEgress                  = AttachType(sys.BPF_TCX_EGRESS)\n\tAttachTraceUprobeMulti           = AttachType(sys.BPF_TRACE_UPROBE_MULTI)\n\tAttachCgroupUnixConnect          = AttachType(sys.BPF_CGROUP_UNIX_CONNECT)\n\tAttachCgroupUnixSendmsg          = AttachType(sys.BPF_CGROUP_UNIX_SENDMSG)\n\tAttachCgroupUnixRecvmsg          = AttachType(sys.BPF_CGROUP_UNIX_RECVMSG)\n\tAttachCgroupUnixGetpeername      = AttachType(sys.BPF_CGROUP_UNIX_GETPEERNAME)\n\tAttachCgroupUnixGetsockname      = AttachType(sys.BPF_CGROUP_UNIX_GETSOCKNAME)\n\tAttachNetkitPrimary              = AttachType(sys.BPF_NETKIT_PRIMARY)\n\tAttachNetkitPeer                 = AttachType(sys.BPF_NETKIT_PEER)\n)\n\n// AttachFlags of the eBPF program used in BPF_PROG_ATTACH command\ntype AttachFlags uint32\n\n// PinType determines whether a map is pinned into a BPFFS.\ntype PinType uint32\n\n// Valid pin types.\n//\n// Mirrors enum libbpf_pin_type.\nconst (\n\tPinNone PinType = iota\n\t// Pin an object by using its name as the filename.\n\tPinByName\n)\n\n// LoadPinOptions control how a pinned object is loaded.\ntype LoadPinOptions struct {\n\t// Request a read-only or write-only object. The default is a read-write\n\t// object. Only one of the flags may be set.\n\tReadOnly  bool\n\tWriteOnly bool\n\n\t// Raw flags for the syscall. Other fields of this struct take precedence.\n\tFlags uint32\n}\n\n// Marshal returns a value suitable for BPF_OBJ_GET syscall file_flags parameter.\nfunc (lpo *LoadPinOptions) Marshal() uint32 {\n\tif lpo == nil {\n\t\treturn 0\n\t}\n\n\tflags := lpo.Flags\n\tif lpo.ReadOnly {\n\t\tflags |= sys.BPF_F_RDONLY\n\t}\n\tif lpo.WriteOnly {\n\t\tflags |= sys.BPF_F_WRONLY\n\t}\n\treturn flags\n}\n\n// BatchOptions batch map operations options\n//\n// Mirrors libbpf struct bpf_map_batch_opts\n// Currently BPF_F_FLAG is the only supported\n// flag (for ElemFlags).\ntype BatchOptions struct {\n\tElemFlags uint64\n\tFlags     uint64\n}\n\n// LogLevel controls the verbosity of the kernel's eBPF program verifier.\n// These constants can be used for the ProgramOptions.LogLevel field.\ntype LogLevel = sys.LogLevel\n\nconst (\n\t// Print verifier state at branch points.\n\tLogLevelBranch = sys.BPF_LOG_LEVEL1\n\n\t// Print verifier state for every instruction.\n\t// Available since Linux v5.2.\n\tLogLevelInstruction = sys.BPF_LOG_LEVEL2\n\n\t// Print verifier errors and stats at the end of the verification process.\n\t// Available since Linux v5.2.\n\tLogLevelStats = sys.BPF_LOG_STATS\n)\n"
        },
        {
          "name": "types_string.go",
          "type": "blob",
          "size": 3.8623046875,
          "content": "// Code generated by \"stringer -output types_string.go -type=MapType,ProgramType,PinType\"; DO NOT EDIT.\n\npackage ebpf\n\nimport \"strconv\"\n\nfunc _() {\n\t// An \"invalid array index\" compiler error signifies that the constant values have changed.\n\t// Re-run the stringer command to generate them again.\n\tvar x [1]struct{}\n\t_ = x[UnspecifiedMap-0]\n\t_ = x[Hash-1]\n\t_ = x[Array-2]\n\t_ = x[ProgramArray-3]\n\t_ = x[PerfEventArray-4]\n\t_ = x[PerCPUHash-5]\n\t_ = x[PerCPUArray-6]\n\t_ = x[StackTrace-7]\n\t_ = x[CGroupArray-8]\n\t_ = x[LRUHash-9]\n\t_ = x[LRUCPUHash-10]\n\t_ = x[LPMTrie-11]\n\t_ = x[ArrayOfMaps-12]\n\t_ = x[HashOfMaps-13]\n\t_ = x[DevMap-14]\n\t_ = x[SockMap-15]\n\t_ = x[CPUMap-16]\n\t_ = x[XSKMap-17]\n\t_ = x[SockHash-18]\n\t_ = x[CGroupStorage-19]\n\t_ = x[ReusePortSockArray-20]\n\t_ = x[PerCPUCGroupStorage-21]\n\t_ = x[Queue-22]\n\t_ = x[Stack-23]\n\t_ = x[SkStorage-24]\n\t_ = x[DevMapHash-25]\n\t_ = x[StructOpsMap-26]\n\t_ = x[RingBuf-27]\n\t_ = x[InodeStorage-28]\n\t_ = x[TaskStorage-29]\n\t_ = x[BloomFilter-30]\n\t_ = x[UserRingbuf-31]\n\t_ = x[CgroupStorage-32]\n\t_ = x[Arena-33]\n}\n\nconst _MapType_name = \"UnspecifiedMapHashArrayProgramArrayPerfEventArrayPerCPUHashPerCPUArrayStackTraceCGroupArrayLRUHashLRUCPUHashLPMTrieArrayOfMapsHashOfMapsDevMapSockMapCPUMapXSKMapSockHashCGroupStorageReusePortSockArrayPerCPUCGroupStorageQueueStackSkStorageDevMapHashStructOpsMapRingBufInodeStorageTaskStorageBloomFilterUserRingbufCgroupStorageArena\"\n\nvar _MapType_index = [...]uint16{0, 14, 18, 23, 35, 49, 59, 70, 80, 91, 98, 108, 115, 126, 136, 142, 149, 155, 161, 169, 182, 200, 219, 224, 229, 238, 248, 260, 267, 279, 290, 301, 312, 325, 330}\n\nfunc (i MapType) String() string {\n\tif i >= MapType(len(_MapType_index)-1) {\n\t\treturn \"MapType(\" + strconv.FormatInt(int64(i), 10) + \")\"\n\t}\n\treturn _MapType_name[_MapType_index[i]:_MapType_index[i+1]]\n}\nfunc _() {\n\t// An \"invalid array index\" compiler error signifies that the constant values have changed.\n\t// Re-run the stringer command to generate them again.\n\tvar x [1]struct{}\n\t_ = x[UnspecifiedProgram-0]\n\t_ = x[SocketFilter-1]\n\t_ = x[Kprobe-2]\n\t_ = x[SchedCLS-3]\n\t_ = x[SchedACT-4]\n\t_ = x[TracePoint-5]\n\t_ = x[XDP-6]\n\t_ = x[PerfEvent-7]\n\t_ = x[CGroupSKB-8]\n\t_ = x[CGroupSock-9]\n\t_ = x[LWTIn-10]\n\t_ = x[LWTOut-11]\n\t_ = x[LWTXmit-12]\n\t_ = x[SockOps-13]\n\t_ = x[SkSKB-14]\n\t_ = x[CGroupDevice-15]\n\t_ = x[SkMsg-16]\n\t_ = x[RawTracepoint-17]\n\t_ = x[CGroupSockAddr-18]\n\t_ = x[LWTSeg6Local-19]\n\t_ = x[LircMode2-20]\n\t_ = x[SkReuseport-21]\n\t_ = x[FlowDissector-22]\n\t_ = x[CGroupSysctl-23]\n\t_ = x[RawTracepointWritable-24]\n\t_ = x[CGroupSockopt-25]\n\t_ = x[Tracing-26]\n\t_ = x[StructOps-27]\n\t_ = x[Extension-28]\n\t_ = x[LSM-29]\n\t_ = x[SkLookup-30]\n\t_ = x[Syscall-31]\n\t_ = x[Netfilter-32]\n}\n\nconst _ProgramType_name = \"UnspecifiedProgramSocketFilterKprobeSchedCLSSchedACTTracePointXDPPerfEventCGroupSKBCGroupSockLWTInLWTOutLWTXmitSockOpsSkSKBCGroupDeviceSkMsgRawTracepointCGroupSockAddrLWTSeg6LocalLircMode2SkReuseportFlowDissectorCGroupSysctlRawTracepointWritableCGroupSockoptTracingStructOpsExtensionLSMSkLookupSyscallNetfilter\"\n\nvar _ProgramType_index = [...]uint16{0, 18, 30, 36, 44, 52, 62, 65, 74, 83, 93, 98, 104, 111, 118, 123, 135, 140, 153, 167, 179, 188, 199, 212, 224, 245, 258, 265, 274, 283, 286, 294, 301, 310}\n\nfunc (i ProgramType) String() string {\n\tif i >= ProgramType(len(_ProgramType_index)-1) {\n\t\treturn \"ProgramType(\" + strconv.FormatInt(int64(i), 10) + \")\"\n\t}\n\treturn _ProgramType_name[_ProgramType_index[i]:_ProgramType_index[i+1]]\n}\nfunc _() {\n\t// An \"invalid array index\" compiler error signifies that the constant values have changed.\n\t// Re-run the stringer command to generate them again.\n\tvar x [1]struct{}\n\t_ = x[PinNone-0]\n\t_ = x[PinByName-1]\n}\n\nconst _PinType_name = \"PinNonePinByName\"\n\nvar _PinType_index = [...]uint8{0, 7, 16}\n\nfunc (i PinType) String() string {\n\tif i >= PinType(len(_PinType_index)-1) {\n\t\treturn \"PinType(\" + strconv.FormatInt(int64(i), 10) + \")\"\n\t}\n\treturn _PinType_name[_PinType_index[i]:_PinType_index[i+1]]\n}\n"
        },
        {
          "name": "variable.go",
          "type": "blob",
          "size": 6.130859375,
          "content": "package ebpf\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal/sysenc\"\n)\n\n// VariableSpec is a convenience wrapper for modifying global variables of a\n// CollectionSpec before loading it into the kernel.\n//\n// All operations on a VariableSpec's underlying MapSpec are performed in the\n// host's native endianness.\ntype VariableSpec struct {\n\tname   string\n\toffset uint64\n\tsize   uint64\n\n\tm *MapSpec\n\tt *btf.Var\n}\n\n// Set sets the value of the VariableSpec to the provided input using the host's\n// native endianness.\nfunc (s *VariableSpec) Set(in any) error {\n\tbuf, err := sysenc.Marshal(in, int(s.size))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshaling value %s: %w\", s.name, err)\n\t}\n\n\tb, _, err := s.m.dataSection()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting data section of map %s: %w\", s.m.Name, err)\n\t}\n\n\tif int(s.offset+s.size) > len(b) {\n\t\treturn fmt.Errorf(\"offset %d(+%d) for variable %s is out of bounds\", s.offset, s.size, s.name)\n\t}\n\n\t// MapSpec.Copy() performs a shallow copy. Fully copy the byte slice\n\t// to avoid any changes affecting other copies of the MapSpec.\n\tcpy := make([]byte, len(b))\n\tcopy(cpy, b)\n\n\tbuf.CopyTo(cpy[s.offset : s.offset+s.size])\n\n\ts.m.Contents[0] = MapKV{Key: uint32(0), Value: cpy}\n\n\treturn nil\n}\n\n// Get writes the value of the VariableSpec to the provided output using the\n// host's native endianness.\nfunc (s *VariableSpec) Get(out any) error {\n\tb, _, err := s.m.dataSection()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting data section of map %s: %w\", s.m.Name, err)\n\t}\n\n\tif int(s.offset+s.size) > len(b) {\n\t\treturn fmt.Errorf(\"offset %d(+%d) for variable %s is out of bounds\", s.offset, s.size, s.name)\n\t}\n\n\tif err := sysenc.Unmarshal(out, b[s.offset:s.offset+s.size]); err != nil {\n\t\treturn fmt.Errorf(\"unmarshaling value: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// Size returns the size of the variable in bytes.\nfunc (s *VariableSpec) Size() uint64 {\n\treturn s.size\n}\n\n// MapName returns the name of the underlying MapSpec.\nfunc (s *VariableSpec) MapName() string {\n\treturn s.m.Name\n}\n\n// Offset returns the offset of the variable in the underlying MapSpec.\nfunc (s *VariableSpec) Offset() uint64 {\n\treturn s.offset\n}\n\n// Constant returns true if the VariableSpec represents a variable that is\n// read-only from the perspective of the BPF program.\nfunc (s *VariableSpec) Constant() bool {\n\treturn s.m.readOnly()\n}\n\n// Type returns the [btf.Var] representing the variable in its data section.\n// This is useful for inspecting the variable's decl tags and the type\n// information of the inner type.\n//\n// Returns nil if the original ELF object did not contain BTF information.\nfunc (s *VariableSpec) Type() *btf.Var {\n\treturn s.t\n}\n\nfunc (s *VariableSpec) String() string {\n\treturn fmt.Sprintf(\"%s (type=%v, map=%s, offset=%d, size=%d)\", s.name, s.t, s.m.Name, s.offset, s.size)\n}\n\n// copy returns a new VariableSpec with the same values as the original,\n// but with a different underlying MapSpec. This is useful when copying a\n// CollectionSpec. Returns nil if a MapSpec with the same name is not found.\nfunc (s *VariableSpec) copy(cpy *CollectionSpec) *VariableSpec {\n\tout := &VariableSpec{\n\t\tname:   s.name,\n\t\toffset: s.offset,\n\t\tsize:   s.size,\n\t}\n\tif s.t != nil {\n\t\tout.t = btf.Copy(s.t).(*btf.Var)\n\t}\n\n\t// Attempt to find a MapSpec with the same name in the copied CollectionSpec.\n\tfor _, m := range cpy.Maps {\n\t\tif m.Name == s.m.Name {\n\t\t\tout.m = m\n\t\t\treturn out\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Variable is a convenience wrapper for modifying global variables of a\n// Collection after loading it into the kernel. Operations on a Variable are\n// performed using direct memory access, bypassing the BPF map syscall API.\n//\n// On kernels older than 5.5, most interactions with Variable return\n// [ErrNotSupported].\ntype Variable struct {\n\tname   string\n\toffset uint64\n\tsize   uint64\n\tt      *btf.Var\n\n\tmm *Memory\n}\n\nfunc newVariable(name string, offset, size uint64, t *btf.Var, mm *Memory) (*Variable, error) {\n\tif mm != nil {\n\t\tif int(offset+size) > mm.Size() {\n\t\t\treturn nil, fmt.Errorf(\"offset %d(+%d) is out of bounds\", offset, size)\n\t\t}\n\t}\n\n\treturn &Variable{\n\t\tname:   name,\n\t\toffset: offset,\n\t\tsize:   size,\n\t\tt:      t,\n\t\tmm:     mm,\n\t}, nil\n}\n\n// Size returns the size of the variable.\nfunc (v *Variable) Size() uint64 {\n\treturn v.size\n}\n\n// ReadOnly returns true if the Variable represents a variable that is read-only\n// after loading the Collection into the kernel.\n//\n// On systems without BPF_F_MMAPABLE support, ReadOnly always returns true.\nfunc (v *Variable) ReadOnly() bool {\n\tif v.mm == nil {\n\t\treturn true\n\t}\n\treturn v.mm.ReadOnly()\n}\n\n// Type returns the [btf.Var] representing the variable in its data section.\n// This is useful for inspecting the variable's decl tags and the type\n// information of the inner type.\n//\n// Returns nil if the original ELF object did not contain BTF information.\nfunc (v *Variable) Type() *btf.Var {\n\treturn v.t\n}\n\nfunc (v *Variable) String() string {\n\treturn fmt.Sprintf(\"%s (type=%v)\", v.name, v.t)\n}\n\n// Set the value of the Variable to the provided input. The input must marshal\n// to the same length as the size of the Variable.\nfunc (v *Variable) Set(in any) error {\n\tif v.mm == nil {\n\t\treturn fmt.Errorf(\"variable %s: direct access requires Linux 5.5 or later: %w\", v.name, ErrNotSupported)\n\t}\n\n\tif v.ReadOnly() {\n\t\treturn fmt.Errorf(\"variable %s: %w\", v.name, ErrReadOnly)\n\t}\n\n\tbuf, err := sysenc.Marshal(in, int(v.size))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshaling value %s: %w\", v.name, err)\n\t}\n\n\tif _, err := v.mm.WriteAt(buf.Bytes(), int64(v.offset)); err != nil {\n\t\treturn fmt.Errorf(\"writing value to %s: %w\", v.name, err)\n\t}\n\n\treturn nil\n}\n\n// Get writes the value of the Variable to the provided output. The output must\n// be a pointer to a value whose size matches the Variable.\nfunc (v *Variable) Get(out any) error {\n\tif v.mm == nil {\n\t\treturn fmt.Errorf(\"variable %s: direct access requires Linux 5.5 or later: %w\", v.name, ErrNotSupported)\n\t}\n\n\tif !v.mm.bounds(v.offset, v.size) {\n\t\treturn fmt.Errorf(\"variable %s: access out of bounds: %w\", v.name, io.EOF)\n\t}\n\n\tif err := sysenc.Unmarshal(out, v.mm.b[v.offset:v.offset+v.size]); err != nil {\n\t\treturn fmt.Errorf(\"unmarshaling value %s: %w\", v.name, err)\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "variable_test.go",
          "type": "blob",
          "size": 5.251953125,
          "content": "package ebpf\n\nimport (\n\t\"testing\"\n\n\t\"github.com/go-quicktest/qt\"\n\n\t\"github.com/cilium/ebpf/btf\"\n\t\"github.com/cilium/ebpf/internal\"\n\t\"github.com/cilium/ebpf/internal/testutils\"\n)\n\nfunc TestVariableSpec(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/variables-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"hidden\"]))\n\tqt.Assert(t, qt.IsNotNil(spec.Variables[\"weak\"]))\n\n\tconst want uint32 = 12345\n\n\t// Update a variable in each type of data section (.bss,.data,.rodata)\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_bss\"].Set(want)))\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_data\"].Set(want)))\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_rodata\"].Set(want)))\n\n\tvar v uint32\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_bss\"].Get(&v)))\n\tqt.Assert(t, qt.Equals(v, want))\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_data\"].Get(&v)))\n\tqt.Assert(t, qt.Equals(v, want))\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_rodata\"].Get(&v)))\n\tqt.Assert(t, qt.Equals(v, want))\n\n\t// Composite values.\n\ttype structT struct {\n\t\tA, B uint64\n\t}\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_struct\"].Set(&structT{1, 2})))\n\n\tvar s structT\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_struct\"].Get(&s)))\n\tqt.Assert(t, qt.Equals(s, structT{1, 2}))\n}\n\nfunc TestVariableSpecCopy(t *testing.T) {\n\tfile := testutils.NativeFile(t, \"testdata/variables-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcpy := spec.Copy()\n\n\t// Update a variable in a section with only a single variable (.rodata).\n\tconst want uint32 = 0xfefefefe\n\twantb := []byte{0xfe, 0xfe, 0xfe, 0xfe} // Same byte sequence regardless of endianness\n\tqt.Assert(t, qt.IsNil(cpy.Variables[\"var_rodata\"].Set(want)))\n\tqt.Assert(t, qt.DeepEquals(cpy.Maps[\".rodata\"].Contents[0].Value.([]byte), wantb))\n\n\t// Verify that the original underlying MapSpec was not modified.\n\tzero := make([]byte, 4)\n\tqt.Assert(t, qt.DeepEquals(spec.Maps[\".rodata\"].Contents[0].Value.([]byte), zero))\n\n\t// Check that modifications to the VariableSpec's Type don't affect the\n\t// underlying MapSpec's type information on either the original or the copy.\n\tcpy.Variables[\"var_rodata\"].Type().Name = \"modified\"\n\tspec.Variables[\"var_rodata\"].Type().Name = \"modified\"\n\n\tqt.Assert(t, qt.Equals(cpy.Maps[\".rodata\"].Value.(*btf.Datasec).Vars[0].Type.(*btf.Var).Name, \"var_rodata\"))\n\tqt.Assert(t, qt.Equals(spec.Maps[\".rodata\"].Value.(*btf.Datasec).Vars[0].Type.(*btf.Var).Name, \"var_rodata\"))\n}\n\nfunc mustReturn(tb testing.TB, prog *Program, value uint32) {\n\ttb.Helper()\n\n\tret, _, err := prog.Test(internal.EmptyBPFContext)\n\tqt.Assert(tb, qt.IsNil(err))\n\tqt.Assert(tb, qt.Equals(ret, value))\n}\n\nfunc TestVariable(t *testing.T) {\n\ttestutils.SkipIfNotSupported(t, haveMmapableMaps())\n\n\tfile := testutils.NativeFile(t, \"testdata/variables-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tobj := struct {\n\t\tGetBSS      *Program `ebpf:\"get_bss\"`\n\t\tGetData     *Program `ebpf:\"get_data\"`\n\t\tCheckStruct *Program `ebpf:\"check_struct\"`\n\n\t\tBSS    *Variable `ebpf:\"var_bss\"`\n\t\tData   *Variable `ebpf:\"var_data\"`\n\t\tStruct *Variable `ebpf:\"var_struct\"`\n\t}{}\n\n\tqt.Assert(t, qt.IsNil(spec.LoadAndAssign(&obj, nil)))\n\tt.Cleanup(func() {\n\t\tobj.GetBSS.Close()\n\t\tobj.GetData.Close()\n\t\tobj.CheckStruct.Close()\n\t})\n\n\tmustReturn(t, obj.GetBSS, 0)\n\tmustReturn(t, obj.GetData, 0)\n\tmustReturn(t, obj.CheckStruct, 0)\n\n\twant := uint32(4242424242)\n\tqt.Assert(t, qt.IsNil(obj.BSS.Set(want)))\n\tmustReturn(t, obj.GetBSS, want)\n\tqt.Assert(t, qt.IsNil(obj.Data.Set(want)))\n\tmustReturn(t, obj.GetData, want)\n\tqt.Assert(t, qt.IsNil(obj.Struct.Set(&struct{ A, B uint64 }{0xa, 0xb})))\n\tmustReturn(t, obj.CheckStruct, 1)\n\n\ttyp := obj.BSS.Type()\n\tqt.Assert(t, qt.IsNotNil(typ))\n\ti, ok := btf.As[*btf.Int](typ.Type)\n\tqt.Assert(t, qt.IsTrue(ok))\n\tqt.Assert(t, qt.Equals(i.Size, 4))\n\n\tqt.Assert(t, qt.IsNotNil(obj.Data.Type()))\n\tqt.Assert(t, qt.IsNotNil(obj.Struct.Type()))\n}\n\nfunc TestVariableConst(t *testing.T) {\n\ttestutils.SkipIfNotSupported(t, haveMmapableMaps())\n\n\tfile := testutils.NativeFile(t, \"testdata/variables-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\twant := uint32(12345)\n\tqt.Assert(t, qt.IsNil(spec.Variables[\"var_rodata\"].Set(want)))\n\n\tobj := struct {\n\t\tGetRodata *Program  `ebpf:\"get_rodata\"`\n\t\tRodata    *Variable `ebpf:\"var_rodata\"`\n\t}{}\n\n\tqt.Assert(t, qt.IsNil(spec.LoadAndAssign(&obj, nil)))\n\tt.Cleanup(func() {\n\t\tobj.GetRodata.Close()\n\t})\n\n\tvar got uint32\n\tqt.Assert(t, qt.IsNil(obj.Rodata.Get(&got)))\n\tqt.Assert(t, qt.Equals(got, want))\n\tmustReturn(t, obj.GetRodata, want)\n\n\tqt.Assert(t, qt.IsTrue(obj.Rodata.ReadOnly()))\n\tqt.Assert(t, qt.ErrorIs(obj.Rodata.Set(want), ErrReadOnly))\n}\n\nfunc TestVariableFallback(t *testing.T) {\n\t// LoadAndAssign should work on Variable regardless of BPF_F_MMAPABLE support.\n\tfile := testutils.NativeFile(t, \"testdata/variables-%s.elf\")\n\tspec, err := LoadCollectionSpec(file)\n\tqt.Assert(t, qt.IsNil(err))\n\n\tobj := struct {\n\t\tData *Variable `ebpf:\"var_data\"`\n\t}{}\n\tqt.Assert(t, qt.IsNil(spec.LoadAndAssign(&obj, nil)))\n\n\t// Expect either success or ErrNotSupported on all systems.\n\tu32 := uint32(0)\n\tif err := obj.Data.Get(&u32); err != nil {\n\t\tqt.Assert(t, qt.ErrorIs(err, ErrNotSupported))\n\t}\n\n\tif err := obj.Data.Set(&u32); err != nil {\n\t\tqt.Assert(t, qt.ErrorIs(err, ErrNotSupported))\n\t}\n}\n"
        }
      ]
    }
  ]
}