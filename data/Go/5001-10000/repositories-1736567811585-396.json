{
  "metadata": {
    "timestamp": 1736567811585,
    "page": 396,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "coocood/freecache",
      "stars": 5144,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.044921875,
          "content": "The MIT License\n\nCopyright (c) 2015 Ewan Chou.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.1884765625,
          "content": "# FreeCache - A cache library for Go with zero GC overhead and high concurrent performance.\n\nLong lived objects in memory introduce expensive GC overhead, With FreeCache, you can cache unlimited number of objects in memory \nwithout increased latency and degraded throughput. \n\n[![Build Status](https://github.com/coocood/freecache/workflows/Test/badge.svg)](https://github.com/coocood/freecache/actions/workflows/test.yml)\n[![GoCover](http://github.com/coocood/freecache/wiki/coverage.svg)](https://raw.githack.com/wiki/coocood/freecache/coverage.html)\n[![GoDoc](https://godoc.org/github.com/coocood/freecache?status.svg)](https://godoc.org/github.com/coocood/freecache)\n\n## Features\n\n* Store hundreds of millions of entries\n* Zero GC overhead\n* High concurrent thread-safe access\n* Pure Go implementation\n* Expiration support\n* Nearly LRU algorithm\n* Strictly limited memory usage\n* Come with a toy server that supports a few basic Redis commands with pipeline\n* Iterator support\n\n## Performance\n\nHere is the benchmark result compares to built-in map, `Set` performance is about 2x faster than built-in map, `Get` performance is about 1/2x slower than built-in map. Since it is single threaded benchmark, in multi-threaded environment, \nFreeCache should be many times faster than single lock protected built-in map.\n\n    BenchmarkCacheSet        3000000               446 ns/op\n    BenchmarkMapSet          2000000               861 ns/op\n    BenchmarkCacheGet        3000000               517 ns/op\n    BenchmarkMapGet         10000000               212 ns/op\n\n## Example Usage\n\n```go\n// In bytes, where 1024 * 1024 represents a single Megabyte, and 100 * 1024*1024 represents 100 Megabytes.\ncacheSize := 100 * 1024 * 1024\ncache := freecache.NewCache(cacheSize)\ndebug.SetGCPercent(20)\nkey := []byte(\"abc\")\nval := []byte(\"def\")\nexpire := 60 // expire in 60 seconds\ncache.Set(key, val, expire)\ngot, err := cache.Get(key)\nif err != nil {\n    fmt.Println(err)\n} else {\n    fmt.Printf(\"%s\\n\", got)\n}\naffected := cache.Del(key)\nfmt.Println(\"deleted key \", affected)\nfmt.Println(\"entry count \", cache.EntryCount())\n```\n\n## Notice\n\n* Memory is preallocated.\n* If you allocate large amount of memory, you may need to set `debug.SetGCPercent()`\nto a much lower percentage to get a normal GC frequency.\n* If you set a key to be expired in X seconds, e.g. using `cache.Set(key, val, X)`, \nthe effective cache duration will be within this range: `(X-1, X] seconds`.\nThis is because that sub-second time at the moment will be ignored when calculating the\nthe expiration: for example, if the current time is 8:15::01.800 (800 milliseconds passed\nsince 8:15::01), the actual duration will be `X-800ms`.\n\n## How it is done\n\nFreeCache avoids GC overhead by reducing the number of pointers.\nNo matter how many entries stored in it, there are only 512 pointers.\nThe data set is sharded into 256 segments by the hash value of the key.\nEach segment has only two pointers, one is the ring buffer that stores keys and values, \nthe other one is the index slice which used to lookup for an entry.\nEach segment has its own lock, so it supports high concurrent access.\n\n## TODO\n\n* Support dump to file and load from file.\n* Support resize cache size at runtime.\n\n## License\n\nThe MIT License\n"
        },
        {
          "name": "cache.go",
          "type": "blob",
          "size": 12.66015625,
          "content": "package freecache\n\nimport (\n\t\"encoding/binary\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\t\"github.com/cespare/xxhash/v2\"\n)\n\nconst (\n\t// segmentCount represents the number of segments within a freecache instance.\n\tsegmentCount = 256\n\t// segmentAndOpVal is bitwise AND applied to the hashVal to find the segment id.\n\tsegmentAndOpVal = 255\n\tminBufSize      = 512 * 1024\n)\n\n// Cache is a freecache instance.\ntype Cache struct {\n\tlocks    [segmentCount]sync.Mutex\n\tsegments [segmentCount]segment\n}\n\ntype Updater func(value []byte, found bool) (newValue []byte, replace bool, expireSeconds int)\n\nfunc hashFunc(data []byte) uint64 {\n\treturn xxhash.Sum64(data)\n}\n\n// NewCache returns a newly initialize cache by size.\n// The cache size will be set to 512KB at minimum.\n// If the size is set relatively large, you should call\n// `debug.SetGCPercent()`, set it to a much smaller value\n// to limit the memory consumption and GC pause time.\nfunc NewCache(size int) (cache *Cache) {\n\treturn NewCacheCustomTimer(size, defaultTimer{})\n}\n\n// NewCacheCustomTimer returns new cache with custom timer.\nfunc NewCacheCustomTimer(size int, timer Timer) (cache *Cache) {\n\tif size < minBufSize {\n\t\tsize = minBufSize\n\t}\n\tif timer == nil {\n\t\ttimer = defaultTimer{}\n\t}\n\tcache = new(Cache)\n\tfor i := 0; i < segmentCount; i++ {\n\t\tcache.segments[i] = newSegment(size/segmentCount, i, timer)\n\t}\n\treturn\n}\n\n// Set sets a key, value and expiration for a cache entry and stores it in the cache.\n// If the key is larger than 65535 or value is larger than 1/1024 of the cache size,\n// the entry will not be written to the cache. expireSeconds <= 0 means no expire,\n// but it can be evicted when cache is full.\nfunc (cache *Cache) Set(key, value []byte, expireSeconds int) (err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\terr = cache.segments[segID].set(key, value, hashVal, expireSeconds)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// Touch updates the expiration time of an existing key. expireSeconds <= 0 means no expire,\n// but it can be evicted when cache is full.\nfunc (cache *Cache) Touch(key []byte, expireSeconds int) (err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\terr = cache.segments[segID].touch(key, hashVal, expireSeconds)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// Get returns the value or not found error.\nfunc (cache *Cache) Get(key []byte) (value []byte, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tvalue, _, err = cache.segments[segID].get(key, nil, hashVal, false)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// GetFn is equivalent to Get or GetWithBuf, but it attempts to be zero-copy,\n// calling the provided function with slice view over the current underlying\n// value of the key in memory. The slice is constrained in length and capacity.\n//\n// In moth cases, this method will not alloc a byte buffer. The only exception\n// is when the value wraps around the underlying segment ring buffer.\n//\n// The method will return ErrNotFound is there's a miss, and the function will\n// not be called. Errors returned by the function will be propagated.\nfunc (cache *Cache) GetFn(key []byte, fn func([]byte) error) (err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\terr = cache.segments[segID].view(key, fn, hashVal, false)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// GetOrSet returns existing value or if record doesn't exist\n// it sets a new key, value and expiration for a cache entry and stores it in the cache, returns nil in that case\nfunc (cache *Cache) GetOrSet(key, value []byte, expireSeconds int) (retValue []byte, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tdefer cache.locks[segID].Unlock()\n\n\tretValue, _, err = cache.segments[segID].get(key, nil, hashVal, false)\n\tif err != nil {\n\t\terr = cache.segments[segID].set(key, value, hashVal, expireSeconds)\n\t}\n\treturn\n}\n\n// SetAndGet sets a key, value and expiration for a cache entry and stores it in the cache.\n// If the key is larger than 65535 or value is larger than 1/1024 of the cache size,\n// the entry will not be written to the cache. expireSeconds <= 0 means no expire,\n// but it can be evicted when cache is full.  Returns existing value if record exists\n// with a bool value to indicate whether an existing record was found\nfunc (cache *Cache) SetAndGet(key, value []byte, expireSeconds int) (retValue []byte, found bool, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tdefer cache.locks[segID].Unlock()\n\n\tretValue, _, err = cache.segments[segID].get(key, nil, hashVal, false)\n\tif err == nil {\n\t\tfound = true\n\t}\n\terr = cache.segments[segID].set(key, value, hashVal, expireSeconds)\n\treturn\n}\n\n// Update gets value for a key, passes it to updater function that decides if set should be called as well\n// This allows for an atomic Get plus Set call using the existing value to decide on whether to call Set.\n// If the key is larger than 65535 or value is larger than 1/1024 of the cache size,\n// the entry will not be written to the cache. expireSeconds <= 0 means no expire,\n// but it can be evicted when cache is full. Returns bool value to indicate if existing record was found along with bool\n// value indicating the value was replaced and error if any\nfunc (cache *Cache) Update(key []byte, updater Updater) (found bool, replaced bool, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tdefer cache.locks[segID].Unlock()\n\n\tretValue, _, err := cache.segments[segID].get(key, nil, hashVal, false)\n\tif err == nil {\n\t\tfound = true\n\t} else {\n\t\terr = nil // Clear ErrNotFound error since we're returning found flag\n\t}\n\tvalue, replaced, expireSeconds := updater(retValue, found)\n\tif !replaced {\n\t\treturn\n\t}\n\terr = cache.segments[segID].set(key, value, hashVal, expireSeconds)\n\treturn\n}\n\n// Peek returns the value or not found error, without updating access time or counters.\n// Warning: No expiry check is performed so if an expired value is found, it will be\n// returned without error\nfunc (cache *Cache) Peek(key []byte) (value []byte, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tvalue, _, err = cache.segments[segID].get(key, nil, hashVal, true)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// PeekFn is equivalent to Peek, but it attempts to be zero-copy, calling the\n// provided function with slice view over the current underlying value of the\n// key in memory. The slice is constrained in length and capacity.\n//\n// In most cases, this method will not alloc a byte buffer. The only exception\n// is when the value wraps around the underlying segment ring buffer.\n//\n// The method will return ErrNotFound is there's a miss, and the function will\n// not be called. Errors returned by the function will be propagated.\n// Warning: No expiry check is performed so if an expired value is found, it will be\n// returned without error\nfunc (cache *Cache) PeekFn(key []byte, fn func([]byte) error) (err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\terr = cache.segments[segID].view(key, fn, hashVal, true)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// GetWithBuf copies the value to the buf or returns not found error.\n// This method doesn't allocate memory when the capacity of buf is greater or equal to value.\nfunc (cache *Cache) GetWithBuf(key, buf []byte) (value []byte, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tvalue, _, err = cache.segments[segID].get(key, buf, hashVal, false)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// GetWithExpiration returns the value with expiration or not found error.\nfunc (cache *Cache) GetWithExpiration(key []byte) (value []byte, expireAt uint32, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tvalue, expireAt, err = cache.segments[segID].get(key, nil, hashVal, false)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// TTL returns the TTL time left for a given key or a not found error.\nfunc (cache *Cache) TTL(key []byte) (timeLeft uint32, err error) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\ttimeLeft, err = cache.segments[segID].ttl(key, hashVal)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// Del deletes an item in the cache by key and returns true or false if a delete occurred.\nfunc (cache *Cache) Del(key []byte) (affected bool) {\n\thashVal := hashFunc(key)\n\tsegID := hashVal & segmentAndOpVal\n\tcache.locks[segID].Lock()\n\taffected = cache.segments[segID].del(key, hashVal)\n\tcache.locks[segID].Unlock()\n\treturn\n}\n\n// SetInt stores in integer value in the cache.\nfunc (cache *Cache) SetInt(key int64, value []byte, expireSeconds int) (err error) {\n\tvar bKey [8]byte\n\tbinary.LittleEndian.PutUint64(bKey[:], uint64(key))\n\treturn cache.Set(bKey[:], value, expireSeconds)\n}\n\n// GetInt returns the value for an integer within the cache or a not found error.\nfunc (cache *Cache) GetInt(key int64) (value []byte, err error) {\n\tvar bKey [8]byte\n\tbinary.LittleEndian.PutUint64(bKey[:], uint64(key))\n\treturn cache.Get(bKey[:])\n}\n\n// GetIntWithExpiration returns the value and expiration or a not found error.\nfunc (cache *Cache) GetIntWithExpiration(key int64) (value []byte, expireAt uint32, err error) {\n\tvar bKey [8]byte\n\tbinary.LittleEndian.PutUint64(bKey[:], uint64(key))\n\treturn cache.GetWithExpiration(bKey[:])\n}\n\n// DelInt deletes an item in the cache by int key and returns true or false if a delete occurred.\nfunc (cache *Cache) DelInt(key int64) (affected bool) {\n\tvar bKey [8]byte\n\tbinary.LittleEndian.PutUint64(bKey[:], uint64(key))\n\treturn cache.Del(bKey[:])\n}\n\n// EvacuateCount is a metric indicating the number of times an eviction occurred.\nfunc (cache *Cache) EvacuateCount() (count int64) {\n\tfor i := range cache.segments {\n\t\tcount += atomic.LoadInt64(&cache.segments[i].totalEvacuate)\n\t}\n\treturn\n}\n\n// ExpiredCount is a metric indicating the number of times an expire occurred.\nfunc (cache *Cache) ExpiredCount() (count int64) {\n\tfor i := range cache.segments {\n\t\tcount += atomic.LoadInt64(&cache.segments[i].totalExpired)\n\t}\n\treturn\n}\n\n// EntryCount returns the number of items currently in the cache.\nfunc (cache *Cache) EntryCount() (entryCount int64) {\n\tfor i := range cache.segments {\n\t\tentryCount += atomic.LoadInt64(&cache.segments[i].entryCount)\n\t}\n\treturn\n}\n\n// AverageAccessTime returns the average unix timestamp when a entry being accessed.\n// Entries have greater access time will be evacuated when it\n// is about to be overwritten by new value.\nfunc (cache *Cache) AverageAccessTime() int64 {\n\tvar entryCount, totalTime int64\n\tfor i := range cache.segments {\n\t\ttotalTime += atomic.LoadInt64(&cache.segments[i].totalTime)\n\t\tentryCount += atomic.LoadInt64(&cache.segments[i].totalCount)\n\t}\n\tif entryCount == 0 {\n\t\treturn 0\n\t} else {\n\t\treturn totalTime / entryCount\n\t}\n}\n\n// HitCount is a metric that returns number of times a key was found in the cache.\nfunc (cache *Cache) HitCount() (count int64) {\n\tfor i := range cache.segments {\n\t\tcount += atomic.LoadInt64(&cache.segments[i].hitCount)\n\t}\n\treturn\n}\n\n// MissCount is a metric that returns the number of times a miss occurred in the cache.\nfunc (cache *Cache) MissCount() (count int64) {\n\tfor i := range cache.segments {\n\t\tcount += atomic.LoadInt64(&cache.segments[i].missCount)\n\t}\n\treturn\n}\n\n// LookupCount is a metric that returns the number of times a lookup for a given key occurred.\nfunc (cache *Cache) LookupCount() int64 {\n\treturn cache.HitCount() + cache.MissCount()\n}\n\n// HitRate is the ratio of hits over lookups.\nfunc (cache *Cache) HitRate() float64 {\n\thitCount, missCount := cache.HitCount(), cache.MissCount()\n\tlookupCount := hitCount + missCount\n\tif lookupCount == 0 {\n\t\treturn 0\n\t} else {\n\t\treturn float64(hitCount) / float64(lookupCount)\n\t}\n}\n\n// OverwriteCount indicates the number of times entries have been overridden.\nfunc (cache *Cache) OverwriteCount() (overwriteCount int64) {\n\tfor i := range cache.segments {\n\t\toverwriteCount += atomic.LoadInt64(&cache.segments[i].overwrites)\n\t}\n\treturn\n}\n\n// TouchedCount indicates the number of times entries have had their expiration time extended.\nfunc (cache *Cache) TouchedCount() (touchedCount int64) {\n\tfor i := range cache.segments {\n\t\ttouchedCount += atomic.LoadInt64(&cache.segments[i].touched)\n\t}\n\treturn\n}\n\n// Clear clears the cache.\nfunc (cache *Cache) Clear() {\n\tfor i := range cache.segments {\n\t\tcache.locks[i].Lock()\n\t\tcache.segments[i].clear()\n\t\tcache.locks[i].Unlock()\n\t}\n}\n\n// ResetStatistics refreshes the current state of the statistics.\nfunc (cache *Cache) ResetStatistics() {\n\tfor i := range cache.segments {\n\t\tcache.locks[i].Lock()\n\t\tcache.segments[i].resetStatistics()\n\t\tcache.locks[i].Unlock()\n\t}\n}\n"
        },
        {
          "name": "cache_test.go",
          "type": "blob",
          "size": 27.537109375,
          "content": "package freecache\n\nimport (\n\t\"bytes\"\n\t\"crypto/rand\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\tmrand \"math/rand\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\n// mockTimer is a mock for Timer contract.\ntype mockTimer struct {\n\tnowCallsCnt uint32        // stores the number of times Now() was called\n\tnowCallback func() uint32 // callback to be executed inside Now()\n}\n\n// Now mock logic.\nfunc (mock *mockTimer) Now() uint32 {\n\tatomic.AddUint32(&mock.nowCallsCnt, 1)\n\tif mock.nowCallback != nil {\n\t\treturn mock.nowCallback()\n\t}\n\n\treturn uint32(time.Now().Unix())\n}\n\n// SetNowCallback sets the callback to be executed inside Now().\n// You can control the return value this way.\nfunc (mock *mockTimer) SetNowCallback(callback func() uint32) {\n\tmock.nowCallback = callback\n}\n\n// nowCallsCount returns the number of times Now() was called.\nfunc (mock *mockTimer) NowCallsCount() int {\n\treturn int(atomic.LoadUint32(&mock.nowCallsCnt))\n}\n\nfunc TestFreeCache(t *testing.T) {\n\tcache := NewCache(1024)\n\tif cache.HitRate() != 0 {\n\t\tt.Error(\"initial hit rate should be zero\")\n\t}\n\tif cache.AverageAccessTime() != 0 {\n\t\tt.Error(\"initial average access time should be zero\")\n\t}\n\tkey := []byte(\"abcd\")\n\tval := []byte(\"efghijkl\")\n\terr := cache.Set(key, val, 0)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\tvalue, err := cache.Get(key)\n\tif err != nil || !bytes.Equal(value, val) {\n\t\tt.Error(\"value not equal\")\n\t}\n\taffected := cache.Del(key)\n\tif !affected {\n\t\tt.Error(\"del should return affected true\")\n\t}\n\tvalue, err = cache.Get(key)\n\tif err != ErrNotFound {\n\t\tt.Error(\"error should be ErrNotFound after being deleted\")\n\t}\n\taffected = cache.Del(key)\n\tif affected {\n\t\tt.Error(\"del should not return affected true\")\n\t}\n\n\tcache.Clear()\n\tn := 5000\n\tfor i := 0; i < n; i++ {\n\t\tkeyStr := fmt.Sprintf(\"key%v\", i)\n\t\tvalStr := strings.Repeat(keyStr, 10)\n\t\terr = cache.Set([]byte(keyStr), []byte(valStr), 0)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}\n\ttime.Sleep(time.Second)\n\tfor i := 1; i < n; i += 2 {\n\t\tkeyStr := fmt.Sprintf(\"key%v\", i)\n\t\tcache.Get([]byte(keyStr))\n\t}\n\n\tfor i := 1; i < n; i += 8 {\n\t\tkeyStr := fmt.Sprintf(\"key%v\", i)\n\t\tcache.Del([]byte(keyStr))\n\t}\n\n\tfor i := 0; i < n; i += 2 {\n\t\tkeyStr := fmt.Sprintf(\"key%v\", i)\n\t\tvalStr := strings.Repeat(keyStr, 10)\n\t\terr = cache.Set([]byte(keyStr), []byte(valStr), 0)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}\n\tfor i := 1; i < n; i += 2 {\n\t\tkeyStr := fmt.Sprintf(\"key%v\", i)\n\t\texpectedValStr := strings.Repeat(keyStr, 10)\n\t\tvalue, err = cache.Get([]byte(keyStr))\n\t\tif err == nil {\n\t\t\tif string(value) != expectedValStr {\n\t\t\t\tt.Errorf(\"value is %v, expected %v\", string(value), expectedValStr)\n\t\t\t}\n\t\t}\n\t\terr = cache.GetFn([]byte(keyStr), func(val []byte) error {\n\t\t\tif string(val) != expectedValStr {\n\t\t\t\tt.Errorf(\"getfn: value is %v, expected %v\", string(val), expectedValStr)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t}\n\n\tt.Logf(\"hit rate is %v, evacuates %v, entries %v, average time %v, expire count %v\\n\",\n\t\tcache.HitRate(), cache.EvacuateCount(), cache.EntryCount(), cache.AverageAccessTime(), cache.ExpiredCount())\n\n\tcache.ResetStatistics()\n\tt.Logf(\"hit rate is %v, evacuates %v, entries %v, average time %v, expire count %v\\n\",\n\t\tcache.HitRate(), cache.EvacuateCount(), cache.EntryCount(), cache.AverageAccessTime(), cache.ExpiredCount())\n}\n\nfunc TestOverwrite(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tvar val []byte\n\tcache.Set(key, val, 0)\n\tval = []byte(\"efgh\")\n\tcache.Set(key, val, 0)\n\tval = append(val, 'i')\n\tcache.Set(key, val, 0)\n\tif count := cache.OverwriteCount(); count != 0 {\n\t\tt.Error(\"overwrite count is\", count, \"expected \", 0)\n\t}\n\tres, _ := cache.Get(key)\n\tif string(res) != string(val) {\n\t\tt.Error(string(res))\n\t}\n\tval = append(val, 'j')\n\tcache.Set(key, val, 0)\n\tres, _ = cache.Get(key)\n\tif string(res) != string(val) {\n\t\tt.Error(string(res), \"aaa\")\n\t}\n\tval = append(val, 'k')\n\tcache.Set(key, val, 0)\n\tres, _ = cache.Get(key)\n\tif string(res) != \"efghijk\" {\n\t\tt.Error(string(res))\n\t}\n\tval = append(val, 'l')\n\tcache.Set(key, val, 0)\n\tres, _ = cache.Get(key)\n\tif string(res) != \"efghijkl\" {\n\t\tt.Error(string(res))\n\t}\n\tval = append(val, 'm')\n\tcache.Set(key, val, 0)\n\tif count := cache.OverwriteCount(); count != 3 {\n\t\tt.Error(\"overwrite count is\", count, \"expected \", 3)\n\t}\n}\n\nfunc TestGetOrSet(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tval := []byte(\"efgh\")\n\n\tr, err := cache.GetOrSet(key, val, 10)\n\tif err != nil || r != nil {\n\t\tt.Errorf(\"Expected to have nils: value=%v, err=%v\", string(r), err)\n\t}\n\n\t// check entry\n\tr, err = cache.Get(key)\n\tif err != nil || string(r) != \"efgh\" {\n\t\tt.Errorf(\"Expected to have val=%v and err != nil, got: value=%v, err=%v\", string(val), string(r), err)\n\t}\n\n\t// call twice for the same key\n\tval = []byte(\"xxxx\")\n\tr, err = cache.GetOrSet(key, val, 10)\n\tif err != nil || string(r) != \"efgh\" {\n\t\tt.Errorf(\"Expected to get old record, got: value=%v, err=%v\", string(r), err)\n\t}\n\terr = cache.GetFn(key, func(val []byte) error {\n\t\tif string(val) != \"efgh\" {\n\t\t\tt.Errorf(\"getfn: Expected to get old record, got: value=%v, err=%v\", string(r), err)\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"did not expect error from GetFn, got: %s\", err)\n\t}\n}\n\nfunc TestGetWithExpiration(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tval := []byte(\"efgh\")\n\terr := cache.Set(key, val, 2)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\n\tres, expiry, err := cache.GetWithExpiration(key)\n\tvar expireTime time.Time\n\tvar startTime = time.Now()\n\tfor {\n\t\t_, _, err := cache.GetWithExpiration(key)\n\t\texpireTime = time.Now()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t\tif time.Now().Unix() > int64(expiry+1) {\n\t\t\tbreak\n\t\t}\n\t\ttime.Sleep(1 * time.Millisecond)\n\t}\n\tif time.Second > expireTime.Sub(startTime) || 3*time.Second < expireTime.Sub(startTime) {\n\t\tt.Error(\"Cache should expire within a second of the expire time\")\n\t}\n\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\tif !bytes.Equal(val, res) {\n\t\tt.Fatalf(\"%s should be the same as %s but isn't\", res, val)\n\t}\n}\n\nfunc TestExpire(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tval := []byte(\"efgh\")\n\terr := cache.Set(key, val, 1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\ttime.Sleep(time.Second)\n\tval, err = cache.Get(key)\n\tif err == nil {\n\t\tt.Fatal(\"key should be expired\", string(val))\n\t}\n\n\tcache.ResetStatistics()\n\tif cache.ExpiredCount() != 0 {\n\t\tt.Error(\"expired count should be zero.\")\n\t}\n}\n\nfunc TestTTL(t *testing.T) {\n\tt.Run(\"with no expire key\", testTTLWithNoExpireKey)\n\tt.Run(\"with expire key, not yet expired\", testTTLWithNotYetExpiredKey)\n\tt.Run(\"with expire key, expired\", testTTLWithExpiredKey)\n\tt.Run(\"with not found key\", testTTLWithNotFoundKey)\n}\n\nfunc testTTLWithNoExpireKey(t *testing.T) {\n\tt.Parallel()\n\n\t// arrange\n\tvar now uint32 = 1659954367\n\ttimer := new(mockTimer)\n\ttimer.SetNowCallback(func() uint32 {\n\t\treturn now\n\t})\n\tcache := NewCacheCustomTimer(512*1024, timer)\n\tkey := []byte(\"test-key\")\n\tvalue := []byte(\"this key does not expire\")\n\texpireSeconds := 0\n\tif err := cache.Set(key, value, expireSeconds); err != nil {\n\t\tt.Fatalf(\"prerequisite failed: could not set the key to query ttl for: %v\", err)\n\t}\n\n\t// act\n\tttl, err := cache.TTL(key)\n\n\t// assert\n\tif err != nil {\n\t\tt.Errorf(\"expected nil, but got %v\", err)\n\t}\n\tif ttl != uint32(expireSeconds) {\n\t\tt.Errorf(\"expected %d, but got %d \", expireSeconds, ttl)\n\t}\n\tif timer.NowCallsCount() != 1 {\n\t\tt.Errorf(\"expected %d, but got %d \", 1, timer.NowCallsCount())\n\t}\n}\n\nfunc testTTLWithNotYetExpiredKey(t *testing.T) {\n\tt.Parallel()\n\n\t// arrange\n\tvar now uint32 = 1659954368\n\ttimer := new(mockTimer)\n\ttimer.SetNowCallback(func() uint32 {\n\t\treturn now\n\t})\n\tcache := NewCacheCustomTimer(512*1024, timer)\n\tkey := []byte(\"test-key\")\n\tvalue := []byte(\"this key expires, but is not expired\")\n\texpireSeconds := 300\n\tif err := cache.Set(key, value, expireSeconds); err != nil {\n\t\tt.Fatalf(\"prerequisite failed: could not set the key to query ttl for: %v\", err)\n\t}\n\n\t// act\n\tttl, err := cache.TTL(key)\n\n\t// assert\n\tif err != nil {\n\t\tt.Errorf(\"expected nil, but got %v\", err)\n\t}\n\tif ttl != uint32(expireSeconds) {\n\t\tt.Errorf(\"expected %d, but got %d \", expireSeconds, ttl)\n\t}\n\tif timer.NowCallsCount() != 2 { // one call from set, one from ttl\n\t\tt.Errorf(\"expected %d, but got %d \", 2, timer.NowCallsCount())\n\t}\n}\n\nfunc testTTLWithExpiredKey(t *testing.T) {\n\tt.Parallel()\n\n\t// arrange\n\tvar now uint32 = 1659954369\n\texpireSeconds := 600\n\ttimer := new(mockTimer)\n\ttimer.SetNowCallback(func() uint32 {\n\t\tswitch timer.NowCallsCount() {\n\t\tcase 1:\n\t\t\treturn now\n\t\tcase 2:\n\t\t\treturn now + uint32(expireSeconds)\n\t\t}\n\n\t\treturn now\n\t})\n\tcache := NewCacheCustomTimer(512*1024, timer)\n\tkey := []byte(\"test-key\")\n\tvalue := []byte(\"this key is expired\")\n\tif err := cache.Set(key, value, expireSeconds); err != nil {\n\t\tt.Fatalf(\"prerequisite failed: could not set the key to query ttl for: %v\", err)\n\t}\n\n\t// act\n\tttl, err := cache.TTL(key)\n\n\t// assert\n\tif !errors.Is(err, ErrNotFound) {\n\t\tt.Errorf(\"expected %v, but got %v\", ErrNotFound, err)\n\t}\n\tif ttl != 0 {\n\t\tt.Errorf(\"expected %d, but got %d \", 0, ttl)\n\t}\n\tif timer.NowCallsCount() != 2 { // one call from set, one from ttl\n\t\tt.Errorf(\"expected %d, but got %d \", 2, timer.NowCallsCount())\n\t}\n}\n\nfunc testTTLWithNotFoundKey(t *testing.T) {\n\tt.Parallel()\n\n\t// arrange\n\ttimer := new(mockTimer)\n\tcache := NewCacheCustomTimer(512*1024, timer)\n\tkey := []byte(\"test-not-found-key\")\n\n\t// act\n\tttl, err := cache.TTL(key)\n\n\t// assert\n\tif !errors.Is(err, ErrNotFound) {\n\t\tt.Errorf(\"expected %v, but got %v\", ErrNotFound, err)\n\t}\n\tif ttl != 0 {\n\t\tt.Errorf(\"expected %d, but got %d \", 0, ttl)\n\t}\n\tif timer.NowCallsCount() != 0 {\n\t\tt.Errorf(\"expected %d, but got %d \", 0, timer.NowCallsCount())\n\t}\n}\n\nfunc TestTouch(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey1 := []byte(\"abcd\")\n\tval1 := []byte(\"efgh\")\n\tkey2 := []byte(\"ijkl\")\n\tval2 := []byte(\"mnop\")\n\terr := cache.Set(key1, val1, 1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\terr = cache.Set(key2, val2, 1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\tif touched := cache.TouchedCount(); touched != 0 {\n\t\tt.Fatalf(\"touched count should be 0, but %d returned\", touched)\n\t}\n\terr = cache.Touch(key1, 2)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\ttime.Sleep(time.Second)\n\tttl, err := cache.TTL(key1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\", err.Error())\n\t}\n\tif ttl != 1 {\n\t\tt.Fatalf(\"ttl should be 1, but %d returned\", ttl)\n\t}\n\tif touched := cache.TouchedCount(); touched != 1 {\n\t\tt.Fatalf(\"touched count should be 1, but %d returned\", touched)\n\t}\n\terr = cache.Touch(key2, 2)\n\tif err != ErrNotFound {\n\t\tt.Error(\"error should be ErrNotFound after expiring\")\n\t}\n\tif touched := cache.TouchedCount(); touched != 1 {\n\t\tt.Fatalf(\"touched count should be 1, but %d returned\", touched)\n\t}\n}\n\nfunc TestAverageAccessTimeWhenUpdateInplace(t *testing.T) {\n\tcache := NewCache(1024)\n\n\tkey := []byte(\"test-key\")\n\tvalueLong := []byte(\"very-long-de-value\")\n\tvalueShort := []byte(\"short\")\n\n\terr := cache.Set(key, valueLong, 0)\n\tif err != nil {\n\t\tt.Fatal(\"err should be nil\")\n\t}\n\tnow := time.Now().Unix()\n\taat := cache.AverageAccessTime()\n\tif (now - aat) > 1 {\n\t\tt.Fatalf(\"track average access time error, now:%d, aat:%d\", now, aat)\n\t}\n\n\ttime.Sleep(time.Second * 4)\n\terr = cache.Set(key, valueShort, 0)\n\tif err != nil {\n\t\tt.Fatal(\"err should be nil\")\n\t}\n\tnow = time.Now().Unix()\n\taat = cache.AverageAccessTime()\n\tif (now - aat) > 1 {\n\t\tt.Fatalf(\"track average access time error, now:%d, aat:%d\", now, aat)\n\t}\n}\n\nfunc TestAverageAccessTimeWhenUpdateWithNewSpace(t *testing.T) {\n\tcache := NewCache(1024)\n\n\tkey := []byte(\"test-key\")\n\tvalueLong := []byte(\"very-long-de-value\")\n\tvalueShort := []byte(\"short\")\n\n\terr := cache.Set(key, valueShort, 0)\n\tif err != nil {\n\t\tt.Fatal(\"err should be nil\")\n\t}\n\tnow := time.Now().Unix()\n\taat := cache.AverageAccessTime()\n\tif (now - aat) > 1 {\n\t\tt.Fatalf(\"track average access time error, now:%d, aat:%d\", now, aat)\n\t}\n\n\ttime.Sleep(time.Second * 4)\n\terr = cache.Set(key, valueLong, 0)\n\tif err != nil {\n\t\tt.Fatal(\"err should be nil\")\n\t}\n\tnow = time.Now().Unix()\n\taat = cache.AverageAccessTime()\n\tif (now - aat) > 2 {\n\t\tt.Fatalf(\"track average access time error, now:%d, aat:%d\", now, aat)\n\t}\n}\n\nfunc TestLargeEntry(t *testing.T) {\n\tcacheSize := 512 * 1024\n\tcache := NewCache(cacheSize)\n\tkey := make([]byte, 65536)\n\tval := []byte(\"efgh\")\n\terr := cache.Set(key, val, 0)\n\tif err != ErrLargeKey {\n\t\tt.Error(\"large key should return ErrLargeKey\")\n\t}\n\tval, err = cache.Get(key)\n\tif val != nil {\n\t\tt.Error(\"value should be nil when get a big key\")\n\t}\n\tkey = []byte(\"abcd\")\n\tmaxValLen := cacheSize/1024 - ENTRY_HDR_SIZE - len(key)\n\tval = make([]byte, maxValLen+1)\n\terr = cache.Set(key, val, 0)\n\tif err != ErrLargeEntry {\n\t\tt.Error(\"err should be ErrLargeEntry\", err)\n\t}\n\tval = make([]byte, maxValLen-2)\n\terr = cache.Set(key, val, 0)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tval = append(val, 0)\n\terr = cache.Set(key, val, 0)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tval = append(val, 0)\n\terr = cache.Set(key, val, 0)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif cache.OverwriteCount() != 1 {\n\t\tt.Errorf(\"over write count should be one, actual: %d.\", cache.OverwriteCount())\n\t}\n\tval = append(val, 0)\n\terr = cache.Set(key, val, 0)\n\tif err != ErrLargeEntry {\n\t\tt.Error(\"err should be ErrLargeEntry\", err)\n\t}\n\n\tcache.ResetStatistics()\n\tif cache.OverwriteCount() != 0 {\n\t\tt.Error(\"over write count should be zero.\")\n\t}\n}\n\nfunc TestInt64Key(t *testing.T) {\n\tcache := NewCache(1024)\n\terr := cache.SetInt(1, []byte(\"abc\"), 3)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\terr = cache.SetInt(2, []byte(\"cde\"), 3)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\tval, err := cache.GetInt(1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\tif !bytes.Equal(val, []byte(\"abc\")) {\n\t\tt.Error(\"value not equal\")\n\t}\n\ttime.Sleep(2 * time.Second)\n\tval, expiry, err := cache.GetIntWithExpiration(1)\n\tif err != nil {\n\t\tt.Error(\"err should be nil\")\n\t}\n\tif !bytes.Equal(val, []byte(\"abc\")) {\n\t\tt.Error(\"value not equal\")\n\t}\n\tnow := time.Now()\n\tif expiry != uint32(now.Unix()+1) {\n\t\tt.Errorf(\"Expiry should one second in the future but was %v\", now)\n\t}\n\n\taffected := cache.DelInt(1)\n\tif !affected {\n\t\tt.Error(\"del should return affected true\")\n\t}\n\t_, err = cache.GetInt(1)\n\tif err != ErrNotFound {\n\t\tt.Error(\"error should be ErrNotFound after being deleted\")\n\t}\n}\n\nfunc TestIterator(t *testing.T) {\n\tcache := NewCache(1024)\n\tcount := 10000\n\tfor i := 0; i < count; i++ {\n\t\terr := cache.Set([]byte(fmt.Sprintf(\"%d\", i)), []byte(fmt.Sprintf(\"val%d\", i)), 0)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}\n\t// Set some value that expires to make sure expired entry is not returned.\n\tcache.Set([]byte(\"abc\"), []byte(\"def\"), 1)\n\ttime.Sleep(2 * time.Second)\n\tit := cache.NewIterator()\n\tfor i := 0; i < count; i++ {\n\t\tentry := it.Next()\n\t\tif entry == nil {\n\t\t\tt.Fatalf(\"entry is nil for %d\", i)\n\t\t}\n\t\tif string(entry.Value) != \"val\"+string(entry.Key) {\n\t\t\tt.Fatalf(\"entry key value not match %s %s\", entry.Key, entry.Value)\n\t\t}\n\t}\n\te := it.Next()\n\tif e != nil {\n\t\tt.Fail()\n\t}\n}\n\nfunc TestIteratorExpireAt(t *testing.T) {\n\tcache := NewCache(1024)\n\texpireSecond := uint32(5)\n\t// Set some value that expires to make sure expired entry is not returned.\n\tcache.Set([]byte(\"no_expire\"), []byte(\"def\"), 0)\n\tcache.Set([]byte(\"has_expire\"), []byte(\"exp\"), int(expireSecond))\n\n\tit := cache.NewIterator()\n\tfor {\n\t\tnext := it.Next()\n\t\tif next == nil {\n\t\t\tbreak\n\t\t}\n\t\tif string(next.Key) == \"no_expire\" && next.ExpireAt != 0 {\n\t\t\tt.Fatalf(\"no_expire's ExpireAt should be 0\")\n\t\t}\n\t\texpectExpireAt := uint32(time.Now().Unix()) + expireSecond\n\t\tif string(next.Key) == \"has_expire\" && next.ExpireAt != expectExpireAt {\n\t\t\tt.Fatalf(\"has_expire's ExpireAt should be 10,actually is %d\", next.ExpireAt)\n\t\t}\n\t}\n\ttime.Sleep(time.Duration(expireSecond) * time.Second)\n\tit2 := cache.NewIterator()\n\tfor {\n\t\tnext := it2.Next()\n\t\tif next == nil {\n\t\t\treturn\n\t\t}\n\t\tif string(next.Key) == \"no_expire\" && next.ExpireAt != 0 {\n\t\t\tt.Fatalf(\"no_expire's ExpireAt should be 0\")\n\t\t}\n\t\tif string(next.Key) == \"has_expire\" {\n\t\t\tt.Fatalf(\"has_expire should expired\")\n\t\t}\n\t}\n}\n\nfunc TestSetLargerEntryDeletesWrongEntry(t *testing.T) {\n\tcachesize := 512 * 1024\n\tcache := NewCache(cachesize)\n\n\tvalue1 := \"aaa\"\n\tkey1 := []byte(\"key1\")\n\tvalue := value1\n\tcache.Set(key1, []byte(value), 0)\n\n\tit := cache.NewIterator()\n\tentry := it.Next()\n\tif !bytes.Equal(entry.Key, key1) {\n\t\tt.Fatalf(\"key %s not equal to %s\", entry.Key, key1)\n\t}\n\tif !bytes.Equal(entry.Value, []byte(value)) {\n\t\tt.Fatalf(\"value %s not equal to %s\", entry.Value, value)\n\t}\n\tentry = it.Next()\n\tif entry != nil {\n\t\tt.Fatalf(\"expected nil entry but got %s %s\", entry.Key, entry.Value)\n\t}\n\n\tvalue = value1 + \"XXXXXX\"\n\tcache.Set(key1, []byte(value), 0)\n\n\tvalue = value1 + \"XXXXYYYYYYY\"\n\tcache.Set(key1, []byte(value), 0)\n\tit = cache.NewIterator()\n\tentry = it.Next()\n\tif !bytes.Equal(entry.Key, key1) {\n\t\tt.Fatalf(\"key %s not equal to %s\", entry.Key, key1)\n\t}\n\tif !bytes.Equal(entry.Value, []byte(value)) {\n\t\tt.Fatalf(\"value %s not equal to %s\", entry.Value, value)\n\t}\n\tentry = it.Next()\n\tif entry != nil {\n\t\tt.Fatalf(\"expected nil entry but got %s %s\", entry.Key, entry.Value)\n\t}\n}\n\nfunc TestRace(t *testing.T) {\n\tcache := NewCache(minBufSize)\n\tinUse := 8\n\twg := sync.WaitGroup{}\n\tvar iters int64 = 1000\n\n\twg.Add(6)\n\taddFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\terr := cache.SetInt(int64(mrand.Intn(inUse)), []byte(\"abc\"), 1)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"err: %s\", err)\n\t\t\t}\n\t\t}\n\t\twg.Done()\n\t}\n\tgetFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\t_, _ = cache.GetInt(int64(mrand.Intn(inUse))) // it will likely error w/ delFunc running too\n\t\t}\n\t\twg.Done()\n\t}\n\tdelFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\tcache.DelInt(int64(mrand.Intn(inUse)))\n\t\t}\n\t\twg.Done()\n\t}\n\tevacFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\t_ = cache.EvacuateCount()\n\t\t\t_ = cache.ExpiredCount()\n\t\t\t_ = cache.EntryCount()\n\t\t\t_ = cache.AverageAccessTime()\n\t\t\t_ = cache.HitCount()\n\t\t\t_ = cache.LookupCount()\n\t\t\t_ = cache.HitRate()\n\t\t\t_ = cache.OverwriteCount()\n\t\t}\n\t\twg.Done()\n\t}\n\tresetFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\tcache.ResetStatistics()\n\t\t}\n\t\twg.Done()\n\t}\n\tclearFunc := func() {\n\t\tvar i int64\n\t\tfor i = 0; i < iters; i++ {\n\t\t\tcache.Clear()\n\t\t}\n\t\twg.Done()\n\t}\n\n\tgo addFunc()\n\tgo getFunc()\n\tgo delFunc()\n\tgo evacFunc()\n\tgo resetFunc()\n\tgo clearFunc()\n\twg.Wait()\n}\n\nfunc TestConcurrentSet(t *testing.T) {\n\tvar wg sync.WaitGroup\n\tcache := NewCache(256 * 1024 * 1024)\n\tN := 4000\n\troutines := 50\n\twg.Add(routines)\n\tfor k := 0; k < routines; k++ {\n\t\tgo func(fact int) {\n\t\t\tdefer wg.Done()\n\t\t\tfor i := N * fact; i < (fact+1)*N; i++ {\n\t\t\t\tvar key, value [8]byte\n\n\t\t\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\t\t\tbinary.LittleEndian.PutUint64(value[:], uint64(i*2))\n\t\t\t\tcache.Set(key[:], value[:], 0)\n\t\t\t}\n\t\t}(k)\n\t}\n\twg.Wait()\n\tfor i := 0; i < routines*N; i++ {\n\t\tvar key, value [8]byte\n\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.GetWithBuf(key[:], value[:])\n\t\tvar num uint64\n\t\tbinary.Read(bytes.NewBuffer(value[:]), binary.LittleEndian, &num)\n\t\tif num != uint64(i*2) {\n\t\t\tt.Fatalf(\"key %d not equal to %d\", int(num), (i * 2))\n\t\t}\n\t}\n}\n\nfunc TestEvacuateCount(t *testing.T) {\n\tcache := NewCache(1024 * 1024)\n\tn := 100000\n\tfor i := 0; i < n; i++ {\n\t\terr := cache.Set([]byte(strconv.Itoa(i)), []byte(\"A\"), 0)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}\n\tmissingItems := 0\n\tfor i := 0; i < n; i++ {\n\t\tres, err := cache.Get([]byte(strconv.Itoa(i)))\n\t\tif err == ErrNotFound || (err == nil && string(res) != \"A\") {\n\t\t\tmissingItems++\n\t\t} else if err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}\n\tif cache.EntryCount()+cache.EvacuateCount() != int64(n) {\n\t\tt.Fatal(cache.EvacuateCount(), cache.EvacuateCount())\n\t}\n}\n\nfunc BenchmarkCacheSet(b *testing.B) {\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], make([]byte, 8), 0)\n\t}\n}\nfunc BenchmarkParallelCacheSet(b *testing.B) {\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tcounter := 0\n\t\tb.ReportAllocs()\n\n\t\tfor pb.Next() {\n\t\t\tbinary.LittleEndian.PutUint64(key[:], uint64(counter))\n\t\t\tcache.Set(key[:], make([]byte, 8), 0)\n\t\t\tcounter = counter + 1\n\t\t}\n\t})\n}\n\nfunc BenchmarkMapSet(b *testing.B) {\n\tm := make(map[string][]byte)\n\tvar key [8]byte\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tm[string(key[:])] = make([]byte, 8)\n\t}\n}\n\nfunc BenchmarkCacheGet(b *testing.B) {\n\tb.ReportAllocs()\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tbuf := make([]byte, 64)\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], buf, 0)\n\t}\n\tb.StartTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Get(key[:])\n\t}\n}\n\nfunc BenchmarkCacheGetFn(b *testing.B) {\n\tb.ReportAllocs()\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tbuf := make([]byte, 64)\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], buf, 0)\n\t}\n\tb.StartTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\t_ = cache.GetFn(key[:], func(val []byte) error {\n\t\t\t_ = val\n\t\t\treturn nil\n\t\t})\n\t}\n\tb.Logf(\"b.N: %d; hit rate: %f\", b.N, cache.HitRate())\n}\n\nfunc BenchmarkParallelCacheGet(b *testing.B) {\n\tb.ReportAllocs()\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tbuf := make([]byte, 64)\n\tvar key [8]byte\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], buf, 0)\n\t}\n\tb.StartTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tcounter := 0\n\t\tb.ReportAllocs()\n\t\tfor pb.Next() {\n\t\t\tbinary.LittleEndian.PutUint64(key[:], uint64(counter))\n\t\t\tcache.Get(key[:])\n\t\t\tcounter = counter + 1\n\t\t}\n\t})\n}\n\nfunc BenchmarkCacheGetWithBuf(b *testing.B) {\n\tb.ReportAllocs()\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tbuf := make([]byte, 64)\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], buf, 0)\n\t}\n\tb.StartTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.GetWithBuf(key[:], buf)\n\t}\n}\n\nfunc BenchmarkParallelCacheGetWithBuf(b *testing.B) {\n\tb.ReportAllocs()\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tbuf := make([]byte, 64)\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], buf, 0)\n\t}\n\tb.StartTimer()\n\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tcounter := 0\n\t\tb.ReportAllocs()\n\t\tfor pb.Next() {\n\t\t\tbinary.LittleEndian.PutUint64(key[:], uint64(counter))\n\t\t\tcache.GetWithBuf(key[:], buf)\n\t\t\tcounter = counter + 1\n\t\t}\n\t})\n}\n\nfunc BenchmarkCacheGetWithExpiration(b *testing.B) {\n\tb.StopTimer()\n\tcache := NewCache(256 * 1024 * 1024)\n\tvar key [8]byte\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.Set(key[:], make([]byte, 8), 0)\n\t}\n\tb.StartTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tcache.GetWithExpiration(key[:])\n\t}\n}\n\nfunc BenchmarkMapGet(b *testing.B) {\n\tb.StopTimer()\n\tm := make(map[string][]byte)\n\tvar key [8]byte\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tm[string(key[:])] = make([]byte, 8)\n\t}\n\tb.StartTimer()\n\tvar hitCount int64\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.LittleEndian.PutUint64(key[:], uint64(i))\n\t\tif m[string(key[:])] != nil {\n\t\t\thitCount++\n\t\t}\n\t}\n}\n\nfunc BenchmarkHashFunc(b *testing.B) {\n\tkey := make([]byte, 8)\n\trand.Read(key)\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\thashFunc(key)\n\t}\n}\n\nfunc benchmarkTTL(expireSeconds int) func(b *testing.B) {\n\treturn func(b *testing.B) {\n\t\tcache := NewCache(512 * 1024)\n\t\tkey := []byte(\"bench-ttl-key\")\n\t\tvalue := []byte(\"bench-ttl-value\")\n\t\tif err := cache.Set(key, value, expireSeconds); err != nil {\n\t\t\tb.Fatalf(\"prerequisite failed: could not set the key to query TTL for: %v\", err)\n\t\t}\n\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\t_, err := cache.TTL(key)\n\t\t\tif err != nil {\n\t\t\t\tb.Error(err)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc BenchmarkTTL_withKeyThatDoesNotExpire(b *testing.B) {\n\tbenchmarkTTL(0)(b)\n}\n\nfunc BenchmarkTTL_withKeyThatDoesExpire(b *testing.B) {\n\tbenchmarkTTL(30)(b)\n}\n\nfunc TestConcurrentGetTTL(t *testing.T) {\n\tcache := NewCache(256 * 1024 * 1024)\n\tprimaryKey := []byte(\"hello\")\n\tprimaryVal := []byte(\"world\")\n\tcache.Set(primaryKey, primaryVal, 2)\n\n\t// Do concurrent mutation by adding various keys.\n\tfor i := 0; i < 1000; i++ {\n\t\tgo func(idx int) {\n\t\t\tkeyValue := []byte(fmt.Sprintf(\"counter_%d\", idx))\n\t\t\tcache.Set(keyValue, keyValue, 0)\n\t\t}(i)\n\t}\n\n\t// While trying to read the TTL.\n\t_, err := cache.TTL(primaryKey)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to get the TTL with an error: %+v\", err)\n\t}\n}\n\nfunc TestSetAndGet(t *testing.T) {\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tval1 := []byte(\"efgh\")\n\n\t_, found, _ := cache.SetAndGet(key, val1, 0)\n\tif found == true {\n\t\tt.Fatalf(\"SetAndGet unexpected found data\")\n\t}\n\n\tval2 := []byte(\"ijkl\")\n\trval, found, _ := cache.SetAndGet(key, val2, 0)\n\tif found == false {\n\t\tt.Fatalf(\"SetAndGet expected found data\")\n\t}\n\tif string(val1) != string(rval) {\n\t\tt.Fatalf(\"SetAndGet expected SetAndGet %s: got %s\", string(val1), string(rval))\n\t}\n}\n\nfunc TestUpdate(t *testing.T) {\n\ttestName := \"Update\"\n\tcache := NewCache(1024)\n\tkey := []byte(\"abcd\")\n\tval1 := []byte(\"efgh\")\n\tval2 := []byte(\"ijkl\")\n\n\tvar found, replaced bool\n\tvar err error\n\tvar prevVal, updaterVal []byte\n\tupdaterReplace := false\n\texpireSeconds := 123\n\n\tupdater := func(value []byte, found bool) ([]byte, bool, int) {\n\t\tprevVal = value\n\t\treturn updaterVal, updaterReplace, expireSeconds\n\t}\n\n\tsetUpdaterResponse := func(value []byte, replace bool) {\n\t\tupdaterVal = value\n\t\tupdaterReplace = replace\n\t}\n\n\tassertExpectations := func(testCase int, expectedFound, expectedReplaced bool, expectedPrevVal []byte,\n\t\texpectedVal []byte) {\n\t\tfailPrefix := fmt.Sprintf(\"%s(%d)\", testName, testCase)\n\n\t\tif expectedFound != found {\n\t\t\tt.Fatalf(\"%s found should be %v\", failPrefix, expectedFound)\n\t\t}\n\t\tif expectedReplaced != replaced {\n\t\t\tt.Fatalf(\"%s found should be %v\", failPrefix, expectedReplaced)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"%s unexpected err %v\", failPrefix, err)\n\t\t}\n\t\tif string(prevVal) != string(expectedPrevVal) {\n\t\t\tt.Fatalf(\"%s previous value expected %s instead of %s\", failPrefix, string(expectedPrevVal),\n\t\t\t\tstring(prevVal))\n\t\t}\n\n\t\t// Check value\n\t\tvalue, err := cache.Get(key)\n\t\tif err == ErrNotFound && expectedVal != nil {\n\t\t\tt.Fatalf(\"%s previous value expected %s instead of nil\", failPrefix, string(expectedVal))\n\t\t}\n\t\tif string(value) != string(expectedVal) {\n\t\t\tt.Fatalf(\"%s previous value expected %s instead of %s\", failPrefix, string(expectedVal), string(value))\n\t\t}\n\t}\n\n\t// Doesn't exist yet, decide not to update, set should not be called\n\tfound, replaced, err = cache.Update(key, updater)\n\tassertExpectations(1, false, false, nil, nil)\n\n\t// Doesn't exist yet, decide to update, set should be called with new value\n\tsetUpdaterResponse(val1, true)\n\tfound, replaced, err = cache.Update(key, updater)\n\tassertExpectations(2, false, true, nil, val1)\n\n\t// Key exists, decide to update, updater is given old value and set should be called with new value\n\tsetUpdaterResponse(val2, true)\n\tfound, replaced, err = cache.Update(key, updater)\n\tassertExpectations(3, true, true, val1, val2)\n\n\t// Key exists, decide not to update, updater is given old value and set should not be called\n\tsetUpdaterResponse(val1, false)\n\tfound, replaced, err = cache.Update(key, updater)\n\tassertExpectations(4, true, false, val2, val2)\n}\n\nfunc TestBenchmarkCacheGetWithBuf(t *testing.T) {\n\talloc := testing.Benchmark(BenchmarkCacheGetWithBuf).AllocsPerOp()\n\tif alloc > 0 {\n\t\tt.Errorf(\"current alloc count '%d' is higher than 0\", alloc)\n\t}\n}\n\nfunc TestBenchmarkCacheSet(t *testing.T) {\n\talloc := testing.Benchmark(BenchmarkCacheSet).AllocsPerOp()\n\tif alloc > 0 {\n\t\tt.Errorf(\"current alloc count '%d' is higher than 0\", alloc)\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.087890625,
          "content": "module github.com/coocood/freecache\n\ngo 1.13\n\nrequire github.com/cespare/xxhash/v2 v2.1.2\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.1708984375,
          "content": "github.com/cespare/xxhash/v2 v2.1.2 h1:YRXhKfTDauu4ajMg1TPgFO5jnlC2HCbmLXMcTG5cbYE=\ngithub.com/cespare/xxhash/v2 v2.1.2/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\n"
        },
        {
          "name": "iterator.go",
          "type": "blob",
          "size": 1.859375,
          "content": "package freecache\n\nimport (\n\t\"unsafe\"\n)\n\n// Iterator iterates the entries for the cache.\ntype Iterator struct {\n\tcache      *Cache\n\tsegmentIdx int\n\tslotIdx    int\n\tentryIdx   int\n}\n\n// Entry represents a key/value pair.\ntype Entry struct {\n\tKey      []byte\n\tValue    []byte\n\tExpireAt uint32\n}\n\n// Next returns the next entry for the iterator.\n// The order of the entries is not guaranteed.\n// If there is no more entries to return, nil will be returned.\nfunc (it *Iterator) Next() *Entry {\n\tfor it.segmentIdx < 256 {\n\t\tentry := it.nextForSegment(it.segmentIdx)\n\t\tif entry != nil {\n\t\t\treturn entry\n\t\t}\n\t\tit.segmentIdx++\n\t\tit.slotIdx = 0\n\t\tit.entryIdx = 0\n\t}\n\treturn nil\n}\n\nfunc (it *Iterator) nextForSegment(segIdx int) *Entry {\n\tit.cache.locks[segIdx].Lock()\n\tdefer it.cache.locks[segIdx].Unlock()\n\tseg := &it.cache.segments[segIdx]\n\tfor it.slotIdx < 256 {\n\t\tentry := it.nextForSlot(seg, it.slotIdx)\n\t\tif entry != nil {\n\t\t\treturn entry\n\t\t}\n\t\tit.slotIdx++\n\t\tit.entryIdx = 0\n\t}\n\treturn nil\n}\n\nfunc (it *Iterator) nextForSlot(seg *segment, slotId int) *Entry {\n\tslotOff := int32(it.slotIdx) * seg.slotCap\n\tslot := seg.slotsData[slotOff : slotOff+seg.slotLens[it.slotIdx] : slotOff+seg.slotCap]\n\tfor it.entryIdx < len(slot) {\n\t\tptr := slot[it.entryIdx]\n\t\tit.entryIdx++\n\t\tnow := seg.timer.Now()\n\t\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\t\tseg.rb.ReadAt(hdrBuf[:], ptr.offset)\n\t\thdr := (*entryHdr)(unsafe.Pointer(&hdrBuf[0]))\n\t\tif hdr.expireAt == 0 || hdr.expireAt > now {\n\t\t\tentry := new(Entry)\n\t\t\tentry.Key = make([]byte, hdr.keyLen)\n\t\t\tentry.Value = make([]byte, hdr.valLen)\n\t\t\tentry.ExpireAt = hdr.expireAt\n\t\t\tseg.rb.ReadAt(entry.Key, ptr.offset+ENTRY_HDR_SIZE)\n\t\t\tseg.rb.ReadAt(entry.Value, ptr.offset+ENTRY_HDR_SIZE+int64(hdr.keyLen))\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}\n\n// NewIterator creates a new iterator for the cache.\nfunc (cache *Cache) NewIterator() *Iterator {\n\treturn &Iterator{\n\t\tcache: cache,\n\t}\n}\n"
        },
        {
          "name": "ringbuf.go",
          "type": "blob",
          "size": 5.734375,
          "content": "package freecache\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n)\n\nvar ErrOutOfRange = errors.New(\"out of range\")\n\n// Ring buffer has a fixed size, when data exceeds the\n// size, old data will be overwritten by new data.\n// It only contains the data in the stream from begin to end\ntype RingBuf struct {\n\tbegin int64 // beginning offset of the data stream.\n\tend   int64 // ending offset of the data stream.\n\tdata  []byte\n\tindex int //range from '0' to 'len(rb.data)-1'\n}\n\nfunc NewRingBuf(size int, begin int64) (rb RingBuf) {\n\trb.data = make([]byte, size)\n\trb.Reset(begin)\n\treturn\n}\n\n// Reset the ring buffer\n//\n// Parameters:\n//     begin: beginning offset of the data stream\nfunc (rb *RingBuf) Reset(begin int64) {\n\trb.begin = begin\n\trb.end = begin\n\trb.index = 0\n}\n\n// Create a copy of the buffer.\nfunc (rb *RingBuf) Dump() []byte {\n\tdump := make([]byte, len(rb.data))\n\tcopy(dump, rb.data)\n\treturn dump\n}\n\nfunc (rb *RingBuf) String() string {\n\treturn fmt.Sprintf(\"[size:%v, start:%v, end:%v, index:%v]\", len(rb.data), rb.begin, rb.end, rb.index)\n}\n\nfunc (rb *RingBuf) Size() int64 {\n\treturn int64(len(rb.data))\n}\n\nfunc (rb *RingBuf) Begin() int64 {\n\treturn rb.begin\n}\n\nfunc (rb *RingBuf) End() int64 {\n\treturn rb.end\n}\n\n// read up to len(p), at off of the data stream.\nfunc (rb *RingBuf) ReadAt(p []byte, off int64) (n int, err error) {\n\tif off > rb.end || off < rb.begin {\n\t\terr = ErrOutOfRange\n\t\treturn\n\t}\n\treadOff := rb.getDataOff(off)\n\treadEnd := readOff + int(rb.end-off)\n\tif readEnd <= len(rb.data) {\n\t\tn = copy(p, rb.data[readOff:readEnd])\n\t} else {\n\t\tn = copy(p, rb.data[readOff:])\n\t\tif n < len(p) {\n\t\t\tn += copy(p[n:], rb.data[:readEnd-len(rb.data)])\n\t\t}\n\t}\n\tif n < len(p) {\n\t\terr = io.EOF\n\t}\n\treturn\n}\n\nfunc (rb *RingBuf) getDataOff(off int64) int {\n\tvar dataOff int\n\tif rb.end-rb.begin < int64(len(rb.data)) {\n\t\tdataOff = int(off - rb.begin)\n\t} else {\n\t\tdataOff = rb.index + int(off-rb.begin)\n\t}\n\tif dataOff >= len(rb.data) {\n\t\tdataOff -= len(rb.data)\n\t}\n\treturn dataOff\n}\n\n// Slice returns a slice of the supplied range of the ring buffer. It will\n// not alloc unless the requested range wraps the ring buffer.\nfunc (rb *RingBuf) Slice(off, length int64) ([]byte, error) {\n\tif off > rb.end || off < rb.begin {\n\t\treturn nil, ErrOutOfRange\n\t}\n\treadOff := rb.getDataOff(off)\n\treadEnd := readOff + int(length)\n\tif readEnd <= len(rb.data) {\n\t\treturn rb.data[readOff:readEnd:readEnd], nil\n\t}\n\tbuf := make([]byte, length)\n\tn := copy(buf, rb.data[readOff:])\n\tif n < int(length) {\n\t\tn += copy(buf[n:], rb.data[:readEnd-len(rb.data)])\n\t}\n\tif n < int(length) {\n\t\treturn nil, io.EOF\n\t}\n\treturn buf, nil\n}\n\nfunc (rb *RingBuf) Write(p []byte) (n int, err error) {\n\tif len(p) > len(rb.data) {\n\t\terr = ErrOutOfRange\n\t\treturn\n\t}\n\tfor n < len(p) {\n\t\twritten := copy(rb.data[rb.index:], p[n:])\n\t\trb.end += int64(written)\n\t\tn += written\n\t\trb.index += written\n\t\tif rb.index >= len(rb.data) {\n\t\t\trb.index -= len(rb.data)\n\t\t}\n\t}\n\tif int(rb.end-rb.begin) > len(rb.data) {\n\t\trb.begin = rb.end - int64(len(rb.data))\n\t}\n\treturn\n}\n\nfunc (rb *RingBuf) WriteAt(p []byte, off int64) (n int, err error) {\n\tif off+int64(len(p)) > rb.end || off < rb.begin {\n\t\terr = ErrOutOfRange\n\t\treturn\n\t}\n\twriteOff := rb.getDataOff(off)\n\twriteEnd := writeOff + int(rb.end-off)\n\tif writeEnd <= len(rb.data) {\n\t\tn = copy(rb.data[writeOff:writeEnd], p)\n\t} else {\n\t\tn = copy(rb.data[writeOff:], p)\n\t\tif n < len(p) {\n\t\t\tn += copy(rb.data[:writeEnd-len(rb.data)], p[n:])\n\t\t}\n\t}\n\treturn\n}\n\nfunc (rb *RingBuf) EqualAt(p []byte, off int64) bool {\n\tif off+int64(len(p)) > rb.end || off < rb.begin {\n\t\treturn false\n\t}\n\treadOff := rb.getDataOff(off)\n\treadEnd := readOff + len(p)\n\tif readEnd <= len(rb.data) {\n\t\treturn bytes.Equal(p, rb.data[readOff:readEnd])\n\t} else {\n\t\tfirstLen := len(rb.data) - readOff\n\t\tequal := bytes.Equal(p[:firstLen], rb.data[readOff:])\n\t\tif equal {\n\t\t\tsecondLen := len(p) - firstLen\n\t\t\tequal = bytes.Equal(p[firstLen:], rb.data[:secondLen])\n\t\t}\n\t\treturn equal\n\t}\n}\n\n// Evacuate read the data at off, then write it to the the data stream,\n// Keep it from being overwritten by new data.\nfunc (rb *RingBuf) Evacuate(off int64, length int) (newOff int64) {\n\tif off+int64(length) > rb.end || off < rb.begin {\n\t\treturn -1\n\t}\n\treadOff := rb.getDataOff(off)\n\tif readOff == rb.index {\n\t\t// no copy evacuate\n\t\trb.index += length\n\t\tif rb.index >= len(rb.data) {\n\t\t\trb.index -= len(rb.data)\n\t\t}\n\t} else if readOff < rb.index {\n\t\tvar n = copy(rb.data[rb.index:], rb.data[readOff:readOff+length])\n\t\trb.index += n\n\t\tif rb.index == len(rb.data) {\n\t\t\trb.index = copy(rb.data, rb.data[readOff+n:readOff+length])\n\t\t}\n\t} else {\n\t\tvar readEnd = readOff + length\n\t\tvar n int\n\t\tif readEnd <= len(rb.data) {\n\t\t\tn = copy(rb.data[rb.index:], rb.data[readOff:readEnd])\n\t\t\trb.index += n\n\t\t} else {\n\t\t\tn = copy(rb.data[rb.index:], rb.data[readOff:])\n\t\t\trb.index += n\n\t\t\tvar tail = length - n\n\t\t\tn = copy(rb.data[rb.index:], rb.data[:tail])\n\t\t\trb.index += n\n\t\t\tif rb.index == len(rb.data) {\n\t\t\t\trb.index = copy(rb.data, rb.data[n:tail])\n\t\t\t}\n\t\t}\n\t}\n\tnewOff = rb.end\n\trb.end += int64(length)\n\tif rb.begin < rb.end-int64(len(rb.data)) {\n\t\trb.begin = rb.end - int64(len(rb.data))\n\t}\n\treturn\n}\n\nfunc (rb *RingBuf) Resize(newSize int) {\n\tif len(rb.data) == newSize {\n\t\treturn\n\t}\n\tnewData := make([]byte, newSize)\n\tvar offset int\n\tif rb.end-rb.begin == int64(len(rb.data)) {\n\t\toffset = rb.index\n\t}\n\tif int(rb.end-rb.begin) > newSize {\n\t\tdiscard := int(rb.end-rb.begin) - newSize\n\t\toffset = (offset + discard) % len(rb.data)\n\t\trb.begin = rb.end - int64(newSize)\n\t}\n\tn := copy(newData, rb.data[offset:])\n\tif n < newSize {\n\t\tcopy(newData[n:], rb.data[:offset])\n\t}\n\trb.data = newData\n\trb.index = 0\n}\n\nfunc (rb *RingBuf) Skip(length int64) {\n\trb.end += length\n\trb.index += int(length)\n\tfor rb.index >= len(rb.data) {\n\t\trb.index -= len(rb.data)\n\t}\n\tif int(rb.end-rb.begin) > len(rb.data) {\n\t\trb.begin = rb.end - int64(len(rb.data))\n\t}\n}\n"
        },
        {
          "name": "ringbuf_test.go",
          "type": "blob",
          "size": 0.9091796875,
          "content": "package freecache\n\nimport (\n\t\"testing\"\n)\n\nfunc TestRingBuf(t *testing.T) {\n\trb := NewRingBuf(16, 0)\n\tfor i := 0; i < 2; i++ {\n\t\trb.Write([]byte(\"fghibbbbccccddde\"))\n\t\trb.Write([]byte(\"fghibbbbc\"))\n\t\trb.Resize(16)\n\t\toff := rb.Evacuate(9, 3)\n\t\tt.Log(string(rb.Dump()))\n\t\tif off != rb.End()-3 {\n\t\t\tt.Log(string(rb.Dump()), rb.End())\n\t\t\tt.Fatalf(\"off got %v\", off)\n\t\t}\n\t\toff = rb.Evacuate(15, 5)\n\t\tt.Log(string(rb.Dump()))\n\t\tif off != rb.End()-5 {\n\t\t\tt.Fatalf(\"off got %v\", off)\n\t\t}\n\t\trb.Resize(64)\n\t\trb.Resize(32)\n\t\tdata := make([]byte, 5)\n\t\trb.ReadAt(data, off)\n\t\tif string(data) != \"efghi\" {\n\t\t\tt.Fatalf(\"read at should be efghi, got %v\", string(data))\n\t\t}\n\n\t\toff = rb.Evacuate(0, 10)\n\t\tif off != -1 {\n\t\t\tt.Fatal(\"evacutate out of range offset should return error\")\n\t\t}\n\n\t\t/* -- After reset the buffer should behave exactly the same as a new one.\n\t\t *    Hence, run the test once more again with reset buffer. */\n\t\trb.Reset(0)\n\t}\n}\n"
        },
        {
          "name": "segment.go",
          "type": "blob",
          "size": 13.13671875,
          "content": "package freecache\n\nimport (\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"unsafe\"\n)\n\nconst HASH_ENTRY_SIZE = 16\nconst ENTRY_HDR_SIZE = 24\n\nvar ErrLargeKey = errors.New(\"The key is larger than 65535\")\nvar ErrLargeEntry = errors.New(\"The entry size is larger than 1/1024 of cache size\")\nvar ErrNotFound = errors.New(\"Entry not found\")\n\n// entry pointer struct points to an entry in ring buffer\ntype entryPtr struct {\n\toffset   int64  // entry offset in ring buffer\n\thash16   uint16 // entries are ordered by hash16 in a slot.\n\tkeyLen   uint16 // used to compare a key\n\treserved uint32\n}\n\n// entry header struct in ring buffer, followed by key and value.\ntype entryHdr struct {\n\taccessTime uint32\n\texpireAt   uint32\n\tkeyLen     uint16\n\thash16     uint16\n\tvalLen     uint32\n\tvalCap     uint32\n\tdeleted    bool\n\tslotId     uint8\n\treserved   uint16\n}\n\n// a segment contains 256 slots, a slot is an array of entry pointers ordered by hash16 value\n// the entry can be looked up by hash value of the key.\ntype segment struct {\n\trb            RingBuf // ring buffer that stores data\n\tsegId         int\n\t_             uint32\n\tmissCount     int64\n\thitCount      int64\n\tentryCount    int64\n\ttotalCount    int64      // number of entries in ring buffer, including deleted entries.\n\ttotalTime     int64      // used to calculate least recent used entry.\n\ttimer         Timer      // Timer giving current time\n\ttotalEvacuate int64      // used for debug\n\ttotalExpired  int64      // used for debug\n\toverwrites    int64      // used for debug\n\ttouched       int64      // used for debug\n\tvacuumLen     int64      // up to vacuumLen, new data can be written without overwriting old data.\n\tslotLens      [256]int32 // The actual length for every slot.\n\tslotCap       int32      // max number of entry pointers a slot can hold.\n\tslotsData     []entryPtr // shared by all 256 slots\n}\n\nfunc newSegment(bufSize int, segId int, timer Timer) (seg segment) {\n\tseg.rb = NewRingBuf(bufSize, 0)\n\tseg.segId = segId\n\tseg.timer = timer\n\tseg.vacuumLen = int64(bufSize)\n\tseg.slotCap = 1\n\tseg.slotsData = make([]entryPtr, 256*seg.slotCap)\n\treturn\n}\n\nfunc (seg *segment) set(key, value []byte, hashVal uint64, expireSeconds int) (err error) {\n\tif len(key) > 65535 {\n\t\treturn ErrLargeKey\n\t}\n\tmaxKeyValLen := len(seg.rb.data)/4 - ENTRY_HDR_SIZE\n\tif len(key)+len(value) > maxKeyValLen {\n\t\t// Do not accept large entry.\n\t\treturn ErrLargeEntry\n\t}\n\tnow := seg.timer.Now()\n\texpireAt := uint32(0)\n\tif expireSeconds > 0 {\n\t\texpireAt = now + uint32(expireSeconds)\n\t}\n\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key)\n\n\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\thdr := (*entryHdr)(unsafe.Pointer(&hdrBuf[0]))\n\tif match {\n\t\tmatchedPtr := &slot[idx]\n\t\tseg.rb.ReadAt(hdrBuf[:], matchedPtr.offset)\n\t\thdr.slotId = slotId\n\t\thdr.hash16 = hash16\n\t\thdr.keyLen = uint16(len(key))\n\t\toriginAccessTime := hdr.accessTime\n\t\thdr.accessTime = now\n\t\thdr.expireAt = expireAt\n\t\thdr.valLen = uint32(len(value))\n\t\tif hdr.valCap >= hdr.valLen {\n\t\t\t// in place overwrite\n\t\t\tatomic.AddInt64(&seg.totalTime, int64(hdr.accessTime)-int64(originAccessTime))\n\t\t\tseg.rb.WriteAt(hdrBuf[:], matchedPtr.offset)\n\t\t\tseg.rb.WriteAt(value, matchedPtr.offset+ENTRY_HDR_SIZE+int64(hdr.keyLen))\n\t\t\tatomic.AddInt64(&seg.overwrites, 1)\n\t\t\treturn\n\t\t}\n\t\t// avoid unnecessary memory copy.\n\t\tseg.delEntryPtr(slotId, slot, idx)\n\t\tmatch = false\n\t\t// increase capacity and limit entry len.\n\t\tfor hdr.valCap < hdr.valLen {\n\t\t\thdr.valCap *= 2\n\t\t}\n\t\tif hdr.valCap > uint32(maxKeyValLen-len(key)) {\n\t\t\thdr.valCap = uint32(maxKeyValLen - len(key))\n\t\t}\n\t} else {\n\t\thdr.slotId = slotId\n\t\thdr.hash16 = hash16\n\t\thdr.keyLen = uint16(len(key))\n\t\thdr.accessTime = now\n\t\thdr.expireAt = expireAt\n\t\thdr.valLen = uint32(len(value))\n\t\thdr.valCap = uint32(len(value))\n\t\tif hdr.valCap == 0 { // avoid infinite loop when increasing capacity.\n\t\t\thdr.valCap = 1\n\t\t}\n\t}\n\n\tentryLen := ENTRY_HDR_SIZE + int64(len(key)) + int64(hdr.valCap)\n\tslotModified := seg.evacuate(entryLen, slotId, now)\n\tif slotModified {\n\t\t// the slot has been modified during evacuation, we need to looked up for the 'idx' again.\n\t\t// otherwise there would be index out of bound error.\n\t\tslot = seg.getSlot(slotId)\n\t\tidx, match = seg.lookup(slot, hash16, key)\n\t\t// assert(match == false)\n\t}\n\tnewOff := seg.rb.End()\n\tseg.insertEntryPtr(slotId, hash16, newOff, idx, hdr.keyLen)\n\tseg.rb.Write(hdrBuf[:])\n\tseg.rb.Write(key)\n\tseg.rb.Write(value)\n\tseg.rb.Skip(int64(hdr.valCap - hdr.valLen))\n\tatomic.AddInt64(&seg.totalTime, int64(now))\n\tatomic.AddInt64(&seg.totalCount, 1)\n\tseg.vacuumLen -= entryLen\n\treturn\n}\n\nfunc (seg *segment) touch(key []byte, hashVal uint64, expireSeconds int) (err error) {\n\tif len(key) > 65535 {\n\t\treturn ErrLargeKey\n\t}\n\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key)\n\tif !match {\n\t\terr = ErrNotFound\n\t\treturn\n\t}\n\tmatchedPtr := &slot[idx]\n\n\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\tseg.rb.ReadAt(hdrBuf[:], matchedPtr.offset)\n\thdr := (*entryHdr)(unsafe.Pointer(&hdrBuf[0]))\n\n\tnow := seg.timer.Now()\n\tif isExpired(hdr.expireAt, now) {\n\t\tseg.delEntryPtr(slotId, slot, idx)\n\t\tatomic.AddInt64(&seg.totalExpired, 1)\n\t\terr = ErrNotFound\n\t\tatomic.AddInt64(&seg.missCount, 1)\n\t\treturn\n\t}\n\n\texpireAt := uint32(0)\n\tif expireSeconds > 0 {\n\t\texpireAt = now + uint32(expireSeconds)\n\t}\n\n\toriginAccessTime := hdr.accessTime\n\thdr.accessTime = now\n\thdr.expireAt = expireAt\n\t// in place overwrite\n\tatomic.AddInt64(&seg.totalTime, int64(hdr.accessTime)-int64(originAccessTime))\n\tseg.rb.WriteAt(hdrBuf[:], matchedPtr.offset)\n\tatomic.AddInt64(&seg.touched, 1)\n\treturn\n}\n\nfunc (seg *segment) evacuate(entryLen int64, slotId uint8, now uint32) (slotModified bool) {\n\tvar oldHdrBuf [ENTRY_HDR_SIZE]byte\n\tconsecutiveEvacuate := 0\n\tfor seg.vacuumLen < entryLen {\n\t\toldOff := seg.rb.End() + seg.vacuumLen - seg.rb.Size()\n\t\tseg.rb.ReadAt(oldHdrBuf[:], oldOff)\n\t\toldHdr := (*entryHdr)(unsafe.Pointer(&oldHdrBuf[0]))\n\t\toldEntryLen := ENTRY_HDR_SIZE + int64(oldHdr.keyLen) + int64(oldHdr.valCap)\n\t\tif oldHdr.deleted {\n\t\t\tconsecutiveEvacuate = 0\n\t\t\tatomic.AddInt64(&seg.totalTime, -int64(oldHdr.accessTime))\n\t\t\tatomic.AddInt64(&seg.totalCount, -1)\n\t\t\tseg.vacuumLen += oldEntryLen\n\t\t\tcontinue\n\t\t}\n\t\texpired := isExpired(oldHdr.expireAt, now)\n\t\tleastRecentUsed := int64(oldHdr.accessTime)*atomic.LoadInt64(&seg.totalCount) <= atomic.LoadInt64(&seg.totalTime)\n\t\tif expired || leastRecentUsed || consecutiveEvacuate > 5 {\n\t\t\tseg.delEntryPtrByOffset(oldHdr.slotId, oldHdr.hash16, oldOff)\n\t\t\tif oldHdr.slotId == slotId {\n\t\t\t\tslotModified = true\n\t\t\t}\n\t\t\tconsecutiveEvacuate = 0\n\t\t\tatomic.AddInt64(&seg.totalTime, -int64(oldHdr.accessTime))\n\t\t\tatomic.AddInt64(&seg.totalCount, -1)\n\t\t\tseg.vacuumLen += oldEntryLen\n\t\t\tif expired {\n\t\t\t\tatomic.AddInt64(&seg.totalExpired, 1)\n\t\t\t} else {\n\t\t\t\tatomic.AddInt64(&seg.totalEvacuate, 1)\n\t\t\t}\n\t\t} else {\n\t\t\t// evacuate an old entry that has been accessed recently for better cache hit rate.\n\t\t\tnewOff := seg.rb.Evacuate(oldOff, int(oldEntryLen))\n\t\t\tseg.updateEntryPtr(oldHdr.slotId, oldHdr.hash16, oldOff, newOff)\n\t\t\tconsecutiveEvacuate++\n\t\t\tatomic.AddInt64(&seg.totalEvacuate, 1)\n\t\t}\n\t}\n\treturn\n}\n\nfunc (seg *segment) get(key, buf []byte, hashVal uint64, peek bool) (value []byte, expireAt uint32, err error) {\n\thdr, ptrOffset, err := seg.locate(key, hashVal, peek)\n\tif err != nil {\n\t\treturn\n\t}\n\texpireAt = hdr.expireAt\n\tif cap(buf) >= int(hdr.valLen) {\n\t\tvalue = buf[:hdr.valLen]\n\t} else {\n\t\tvalue = make([]byte, hdr.valLen)\n\t}\n\n\tseg.rb.ReadAt(value, ptrOffset+ENTRY_HDR_SIZE+int64(hdr.keyLen))\n\tif !peek {\n\t\tatomic.AddInt64(&seg.hitCount, 1)\n\t}\n\treturn\n}\n\n// view provides zero-copy access to the element's value, without copying to\n// an intermediate buffer.\nfunc (seg *segment) view(key []byte, fn func([]byte) error, hashVal uint64, peek bool) (err error) {\n\thdr, ptrOffset, err := seg.locate(key, hashVal, peek)\n\tif err != nil {\n\t\treturn\n\t}\n\tstart := ptrOffset + ENTRY_HDR_SIZE + int64(hdr.keyLen)\n\tval, err := seg.rb.Slice(start, int64(hdr.valLen))\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = fn(val)\n\tif !peek {\n\t\tatomic.AddInt64(&seg.hitCount, 1)\n\t}\n\treturn\n}\n\nfunc (seg *segment) locate(key []byte, hashVal uint64, peek bool) (hdrEntry entryHdr, ptrOffset int64, err error) {\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key)\n\tif !match {\n\t\terr = ErrNotFound\n\t\tif !peek {\n\t\t\tatomic.AddInt64(&seg.missCount, 1)\n\t\t}\n\t\treturn\n\t}\n\tptr := &slot[idx]\n\n\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\tseg.rb.ReadAt(hdrBuf[:], ptr.offset)\n\thdr := (*entryHdr)(unsafe.Pointer(&hdrBuf[0]))\n\tif !peek {\n\t\tnow := seg.timer.Now()\n\t\tif isExpired(hdr.expireAt, now) {\n\t\t\tseg.delEntryPtr(slotId, slot, idx)\n\t\t\tatomic.AddInt64(&seg.totalExpired, 1)\n\t\t\terr = ErrNotFound\n\t\t\tatomic.AddInt64(&seg.missCount, 1)\n\t\t\treturn\n\t\t}\n\t\tatomic.AddInt64(&seg.totalTime, int64(now-hdr.accessTime))\n\t\thdr.accessTime = now\n\t\tseg.rb.WriteAt(hdrBuf[:], ptr.offset)\n\t}\n\treturn *hdr, ptr.offset, nil\n}\n\nfunc (seg *segment) del(key []byte, hashVal uint64) (affected bool) {\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key)\n\tif !match {\n\t\treturn false\n\t}\n\tseg.delEntryPtr(slotId, slot, idx)\n\treturn true\n}\n\nfunc (seg *segment) ttl(key []byte, hashVal uint64) (timeLeft uint32, err error) {\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key)\n\tif !match {\n\t\terr = ErrNotFound\n\t\treturn\n\t}\n\tptr := &slot[idx]\n\n\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\tseg.rb.ReadAt(hdrBuf[:], ptr.offset)\n\thdr := (*entryHdr)(unsafe.Pointer(&hdrBuf[0]))\n\n\tif hdr.expireAt == 0 {\n\t\treturn\n\t} else {\n\t\tnow := seg.timer.Now()\n\t\tif !isExpired(hdr.expireAt, now) {\n\t\t\ttimeLeft = hdr.expireAt - now\n\t\t\treturn\n\t\t}\n\t}\n\terr = ErrNotFound\n\treturn\n}\n\nfunc (seg *segment) expand() {\n\tnewSlotData := make([]entryPtr, seg.slotCap*2*256)\n\tfor i := 0; i < 256; i++ {\n\t\toff := int32(i) * seg.slotCap\n\t\tcopy(newSlotData[off*2:], seg.slotsData[off:off+seg.slotLens[i]])\n\t}\n\tseg.slotCap *= 2\n\tseg.slotsData = newSlotData\n}\n\nfunc (seg *segment) updateEntryPtr(slotId uint8, hash16 uint16, oldOff, newOff int64) {\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookupByOff(slot, hash16, oldOff)\n\tif !match {\n\t\treturn\n\t}\n\tptr := &slot[idx]\n\tptr.offset = newOff\n}\n\nfunc (seg *segment) insertEntryPtr(slotId uint8, hash16 uint16, offset int64, idx int, keyLen uint16) {\n\tif seg.slotLens[slotId] == seg.slotCap {\n\t\tseg.expand()\n\t}\n\tseg.slotLens[slotId]++\n\tatomic.AddInt64(&seg.entryCount, 1)\n\tslot := seg.getSlot(slotId)\n\tcopy(slot[idx+1:], slot[idx:])\n\tslot[idx].offset = offset\n\tslot[idx].hash16 = hash16\n\tslot[idx].keyLen = keyLen\n}\n\nfunc (seg *segment) delEntryPtrByOffset(slotId uint8, hash16 uint16, offset int64) {\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookupByOff(slot, hash16, offset)\n\tif !match {\n\t\treturn\n\t}\n\tseg.delEntryPtr(slotId, slot, idx)\n}\n\nfunc (seg *segment) delEntryPtr(slotId uint8, slot []entryPtr, idx int) {\n\toffset := slot[idx].offset\n\tvar entryHdrBuf [ENTRY_HDR_SIZE]byte\n\tseg.rb.ReadAt(entryHdrBuf[:], offset)\n\tentryHdr := (*entryHdr)(unsafe.Pointer(&entryHdrBuf[0]))\n\tentryHdr.deleted = true\n\tseg.rb.WriteAt(entryHdrBuf[:], offset)\n\tcopy(slot[idx:], slot[idx+1:])\n\tseg.slotLens[slotId]--\n\tatomic.AddInt64(&seg.entryCount, -1)\n}\n\nfunc entryPtrIdx(slot []entryPtr, hash16 uint16) (idx int) {\n\thigh := len(slot)\n\tfor idx < high {\n\t\tmid := (idx + high) >> 1\n\t\toldEntry := &slot[mid]\n\t\tif oldEntry.hash16 < hash16 {\n\t\t\tidx = mid + 1\n\t\t} else {\n\t\t\thigh = mid\n\t\t}\n\t}\n\treturn\n}\n\nfunc (seg *segment) lookup(slot []entryPtr, hash16 uint16, key []byte) (idx int, match bool) {\n\tidx = entryPtrIdx(slot, hash16)\n\tfor idx < len(slot) {\n\t\tptr := &slot[idx]\n\t\tif ptr.hash16 != hash16 {\n\t\t\tbreak\n\t\t}\n\t\tmatch = int(ptr.keyLen) == len(key) && seg.rb.EqualAt(key, ptr.offset+ENTRY_HDR_SIZE)\n\t\tif match {\n\t\t\treturn\n\t\t}\n\t\tidx++\n\t}\n\treturn\n}\n\nfunc (seg *segment) lookupByOff(slot []entryPtr, hash16 uint16, offset int64) (idx int, match bool) {\n\tidx = entryPtrIdx(slot, hash16)\n\tfor idx < len(slot) {\n\t\tptr := &slot[idx]\n\t\tif ptr.hash16 != hash16 {\n\t\t\tbreak\n\t\t}\n\t\tmatch = ptr.offset == offset\n\t\tif match {\n\t\t\treturn\n\t\t}\n\t\tidx++\n\t}\n\treturn\n}\n\nfunc (seg *segment) resetStatistics() {\n\tatomic.StoreInt64(&seg.totalEvacuate, 0)\n\tatomic.StoreInt64(&seg.totalExpired, 0)\n\tatomic.StoreInt64(&seg.overwrites, 0)\n\tatomic.StoreInt64(&seg.hitCount, 0)\n\tatomic.StoreInt64(&seg.missCount, 0)\n}\n\nfunc (seg *segment) clear() {\n\tbufSize := len(seg.rb.data)\n\tseg.rb.Reset(0)\n\tseg.vacuumLen = int64(bufSize)\n\tseg.slotCap = 1\n\tseg.slotsData = make([]entryPtr, 256*seg.slotCap)\n\tfor i := 0; i < len(seg.slotLens); i++ {\n\t\tseg.slotLens[i] = 0\n\t}\n\n\tatomic.StoreInt64(&seg.hitCount, 0)\n\tatomic.StoreInt64(&seg.missCount, 0)\n\tatomic.StoreInt64(&seg.entryCount, 0)\n\tatomic.StoreInt64(&seg.totalCount, 0)\n\tatomic.StoreInt64(&seg.totalTime, 0)\n\tatomic.StoreInt64(&seg.totalEvacuate, 0)\n\tatomic.StoreInt64(&seg.totalExpired, 0)\n\tatomic.StoreInt64(&seg.overwrites, 0)\n}\n\nfunc (seg *segment) getSlot(slotId uint8) []entryPtr {\n\tslotOff := int32(slotId) * seg.slotCap\n\treturn seg.slotsData[slotOff : slotOff+seg.slotLens[slotId] : slotOff+seg.slotCap]\n}\n\n// isExpired checks if a key is expired.\nfunc isExpired(keyExpireAt, now uint32) bool {\n\treturn keyExpireAt != 0 && keyExpireAt <= now\n}\n"
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        },
        {
          "name": "timer.go",
          "type": "blob",
          "size": 1.5517578125,
          "content": "package freecache\n\nimport (\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n// Timer holds representation of current time.\ntype Timer interface {\n\t// Give current time (in seconds)\n\tNow() uint32\n}\n\n// Timer that must be stopped.\ntype StoppableTimer interface {\n\tTimer\n\n\t// Release resources of the timer, functionality may or may not be affected\n\t// It is not called automatically, so user must call it just once\n\tStop()\n}\n\n// Helper function that returns Unix time in seconds\nfunc getUnixTime() uint32 {\n\treturn uint32(time.Now().Unix())\n}\n\n// Default timer reads Unix time always when requested\ntype defaultTimer struct{}\n\nfunc (timer defaultTimer) Now() uint32 {\n\treturn getUnixTime()\n}\n\n// Cached timer stores Unix time every second and returns the cached value\ntype cachedTimer struct {\n\tnow    uint32\n\tticker *time.Ticker\n\tdone   chan bool\n}\n\n// Create cached timer and start runtime timer that updates time every second\nfunc NewCachedTimer() StoppableTimer {\n\ttimer := &cachedTimer{\n\t\tnow:    getUnixTime(),\n\t\tticker: time.NewTicker(time.Second),\n\t\tdone:   make(chan bool),\n\t}\n\n\tgo timer.update()\n\n\treturn timer\n}\n\nfunc (timer *cachedTimer) Now() uint32 {\n\treturn atomic.LoadUint32(&timer.now)\n}\n\n// Stop runtime timer and finish routine that updates time\nfunc (timer *cachedTimer) Stop() {\n\ttimer.ticker.Stop()\n\ttimer.done <- true\n\tclose(timer.done)\n\n\ttimer.done = nil\n\ttimer.ticker = nil\n}\n\n// Periodically check and update  of time\nfunc (timer *cachedTimer) update() {\n\tfor {\n\t\tselect {\n\t\tcase <-timer.done:\n\t\t\treturn\n\t\tcase <-timer.ticker.C:\n\t\t\tatomic.StoreUint32(&timer.now, getUnixTime())\n\t\t}\n\t}\n}\n"
        }
      ]
    }
  ]
}