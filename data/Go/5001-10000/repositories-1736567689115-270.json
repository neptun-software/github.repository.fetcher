{
  "metadata": {
    "timestamp": 1736567689115,
    "page": 270,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "go-ego/riot",
      "stars": 6101,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.1240234375,
          "content": "# Object files\n.DS_Store\n.vscode\n.idea\n# vendor\n\nriot-index\ndata/data\ndata/riot/riot\ndata/riot/heartb/heartb\ndata/riot/riot-index\ndata/riot1/riot-index\ndata/riot1/riot1\ndata/riot1/heartb/heartb\ndata/client/client\nexamples/benchmark/benchmark\nexamples/codelab/codelab\nexamples/dict/dict\nexamples/logic/logic\nexamples/new/new\nexamples/new/riot-index\nexamples/pinyin/pinyin\nexamples/pinyin/riot-index\nexamples/pinyin_weibo/pinyin_weibo\nexamples/store/store\nexamples/store/riot-index\nexamples/simple/simple\nexamples/simple/zh/zh\nexamples/weibo/weibo\n\n# Debug files\n*.dSYM/\n*.su\ndebug\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.o\n*.ko\n*.obj\n*.elf\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n\n# Project-local glide cache, RE: https://github.com/Masterminds/glide/issues/736\n .glide/\n\n# Test binary, build with `go test -c`\n*.test\n\n# Output of the go coverage tool, specifically when used with LiteIDE\n# *.out\n\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.5322265625,
          "content": "language: go\n\ngo_import_path: github.com/go-ego/riot\n\ngo:\n  # - 1.7.x\n  # - 1.8.x\n  # - 1.9.x\n  # - 1.10.x\n  # - 1.11.x\n  # - 1.12.x\n  # - 1.13.x\n  - 1.14.x\n  # - tip\n\ninstall:\n  - export PATH=$PATH:$HOME/gopath/bin\n  # - go get -u github.com/go-ego/gse\n  # - go get -u github.com/go-ego/gpy\n  # - go get -u github.com/go-ego/murmur\n  # - go get -u golang.org/x/sys/unix\n  # - go get -u github.com/shirou/gopsutil\n  - go get -v -t ./...\n  \n# after_success:\n#   - bash <(curl -s https://codecov.io/bash)\n\n# notifications:\n#   email:\n#     - .com\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.3583984375,
          "content": "# Contribution Guidelines\n\n## Introduction\n\nThis document explains how to contribute changes to the Ego project. It assumes you have followed the README.md and [API Document](https://github.com/go-ego/riot/tree/master/docs). <!--Sensitive security-related issues should be reported to [security@Ego.io](mailto:security@Ego.io.)-->\n\n## Bug reports\n\nPlease search the issues on the issue tracker with a variety of keywords to ensure your bug is not already reported.\n\nIf unique, [open an issue](https://github.com/go-ego/riot/issues/new) and answer the questions so we can understand and reproduce the problematic behavior.\n\nThe burden is on you to convince us that it is actually a bug in Ego. This is easiest to do when you write clear, concise instructions so we can reproduce the behavior (even if it seems obvious). The more detailed and specific you are, the faster we will be able to help you. Check out [How to Report Bugs Effectively](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html).\n\nPlease be kind, remember that Ego comes at no cost to you, and you're getting free help.\n\n## Discuss your design\n\nThe project welcomes submissions but please let everyone know what you're working on if you want to change or add something to the Ego repositories.\n\nBefore starting to write something new for the Ego project, please [file an issue](https://github.com/go-ego/riot/issues/new). Significant changes must go through the [change proposal process](https://github.com/go-ego/proposals) before they can be accepted.\n\nThis process gives everyone a chance to validate the design, helps prevent duplication of effort, and ensures that the idea fits inside the goals for the project and tools. It also checks that the design is sound before code is written; the code review tool is not the place for high-level discussions.\n\n## Testing redux\n\nBefore sending code out for review, run all the tests for the whole tree to make sure the changes don't break other usage and keep the compatibility on upgrade. You must be test on Mac, Windows, Linux and other. You should install the CLI for Circle CI, as we are using the server for continous testing.\n\n## Code review\n\nIn addition to the owner, Changes to Ego must be reviewed before they are accepted, no matter who makes the change even if it is a maintainer. We use GitHub's pull request workflow to do that and we also use [LGTM](http://lgtm.co) to ensure every PR is reviewed by vz or least 2 maintainers.\n\n\n## Sign your work\n\nThe sign-off is a simple line at the end of the explanation for the patch. Your signature certifies that you wrote the patch or otherwise have the right to pass it on as an open-source patch. \n\n## Maintainers\n\nTo make sure every PR is checked, we got team maintainers. A maintainer should be a contributor of Ego and contributed at least 4 accepted PRs. \n\n## Owners\n\nSince Ego is a pure community organization without any company support, Copyright 2016 The go-ego Project Developers.\n\n\n## Versions\n\nEgo has the `master` branch as a tip branch and has version branches such as `v0.30.0`. `v0.40.0` is a release branch and we will tag `v0.40.0` for binary download. If `v0.40.0` has bugs, we will accept pull requests on the `v0.40.0` branch and publish a `v0.40.1` tag, after bringing the bug fix also to the master branch.\n\nSince the `master` branch is a tip version, if you wish to use Ego in production, please download the latest release tag version. All the branches will be protected via GitHub, all the PRs to every branch must be reviewed by two maintainers and must pass the automatic tests.\n\n## Copyright\n\nCode that you contribute should use the standard copyright header:\n\n```\n// Copyright 2016 The go-ego Project Developers. \n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n```\n\nFiles in the repository contain copyright from the year they are added to the year they are last changed. If the copyright author is changed, just paste the header below the old one.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.130859375,
          "content": "# Riot search\n\n<img align=\"right\" src=\"logo/512px.svg\" width=\"15%\"/>\n\n<!--<img align=\"right\" src=\"https://raw.githubusercontent.com/go-ego/ego/master/logo.jpg\">-->\n<!--<a href=\"https://circleci.com/gh/go-ego/ego/tree/dev\"><img src=\"https://img.shields.io/circleci/project/go-ego/ego/dev.svg\" alt=\"Build Status\"></a>-->\n[![CircleCI Status](https://circleci.com/gh/go-ego/riot.svg?style=shield)](https://circleci.com/gh/go-ego/riot)\n![Appveyor](https://ci.appveyor.com/api/projects/status/github/go-ego/riot?branch=master&svg=true)\n[![codecov](https://codecov.io/gh/go-ego/riot/branch/master/graph/badge.svg)](https://codecov.io/gh/go-ego/riot)\n[![Build Status](https://travis-ci.org/go-ego/riot.svg)](https://travis-ci.org/go-ego/riot)\n[![Go Report Card](https://goreportcard.com/badge/github.com/go-ego/riot)](https://goreportcard.com/report/github.com/go-ego/riot)\n[![GoDoc](https://godoc.org/github.com/go-ego/riot?status.svg)](https://godoc.org/github.com/go-ego/riot)\n[![GitHub release](https://img.shields.io/github/release/go-ego/riot.svg)](https://github.com/go-ego/riot/releases/latest)\n[![Join the chat at https://gitter.im/go-ego/ego](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/go-ego/ego?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n<!-- [![Release](https://github-release-version.herokuapp.com/github/go-ego/riot/release.svg?style=flat)](https://github.com/go-ego/riot/releases/latest) -->\n<!--<a href=\"https://github.com/go-ego/ego/releases\"><img src=\"https://img.shields.io/badge/%20version%20-%206.0.0%20-blue.svg?style=flat-square\" alt=\"Releases\"></a>-->\n\n<!-- ![ego Logo](logo/512px.svg) -->\nGo Open Source, Distributed, Simple and efficient full text search engine.\n\n[简体中文](https://github.com/go-ego/riot/blob/master/README_zh.md)\n\n# Features\n\n* [Efficient indexing and search](/docs/en/benchmarking.md) (1M blog 500M data 28 seconds index finished, 1.65 ms search response time, 19K search QPS）\n* Support for [logical search](https://github.com/go-ego/riot/blob/master/docs/en/logic.md)\n* Support Chinese word segmentation (use [gse word segmentation package](https://github.com/go-ego/gse) concurrent word, speed 27MB / s）\n* Support the calculation of the keyword in the text [close to the distance](/docs/en/token_proximity.md)（token proximity）\n* Support calculation [BM25 correlation](/docs/en/bm25.md)\n* Support [custom scoring field and scoring rules](/docs/en/custom_scoring_criteria.md)\n* Support [add online, delete index](/docs/en/realtime_indexing.md)\n* Support heartbeat\n* Support multiple [persistent storage](/docs/en/persistent_storage.md)\n* Support [distributed index and search](https://github.com/go-ego/riot/tree/master/data)\n* Can be achieved [distributed index and search](/docs/en/distributed_indexing_and_search.md)\n\n* [Look at Word segmentation rules](https://github.com/go-ego/riot/blob/master/docs/en/segmenter.md)\n\n<!-- \nRiot v0.20.0 was released in Nov 2017, check the [Changelog](https://github.com/go-ego/riot/blob/master/docs/CHANGELOG.md) for the full details. -->\n\n## Requirements\nGo version >= 1.8\n\n### Dependencies\n\nRiot uses go module or dep to manage dependencies. \n\n## Installation/Update\n\n```\ngo get -u github.com/go-ego/riot\n```\n\n## [Build-tools](https://github.com/go-ego/re)\n```\ngo get -u github.com/go-ego/re \n```\n### re riot\nTo create a new riot application\n\n```\n$ re riot my-riotapp\n```\n\n### re run\n\nTo run the application we just created, you can navigate to the application folder and execute:\n```\n$ cd my-riotapp && re run\n```\n\n## Usage:\n\n#### [Look at an example](/examples/simple/main.go)\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/go-ego/riot\"\n\t\"github.com/go-ego/riot/types\"\n)\n\nvar (\n\t// searcher is coroutine safe\n\tsearcher = riot.Engine{}\n)\n\nfunc main() {\n\t// Init\n\tsearcher.Init(types.EngineOpts{\n\t\t// Using:             4,\n\t\tNotUseGse: true,\n\t\t})\n\tdefer searcher.Close()\n\n\ttext := \"Google Is Experimenting With Virtual Reality Advertising\"\n\ttext1 := `Google accidentally pushed Bluetooth update for Home\n\tspeaker early`\n\ttext2 := `Google is testing another Search results layout with \n\trounded cards, new colors, and the 4 mysterious colored dots again`\n\t\n\t// Add the document to the index, docId starts at 1\n\tsearcher.Index(\"1\", types.DocData{Content: text})\n\tsearcher.Index(\"2\", types.DocData{Content: text1}, false)\n\tsearcher.IndexDoc(\"3\", types.DocData{Content: text2}, true)\n\n\t// Wait for the index to refresh\n\tsearcher.Flush()\n\t// engine.FlushIndex()\n\n\t// The search output format is found in the types.SearchResp structure\n\tlog.Print(searcher.Search(types.SearchReq{Text:\"google testing\"}))\n}\n```\n\nIt is very simple!\n\n### Use default engine:\n\n```Go\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/go-ego/riot\"\n\t\"github.com/go-ego/riot/types\"\n)\n\nvar (\n\tsearcher = riot.New(\"zh\")\n)\n\nfunc main() {\n\tdata := types.DocData{Content: `I wonder how, I wonder why\n\t\t, I wonder where they are`}\n\tdata1 := types.DocData{Content: \"所以, 你好, 再见\"}\n\tdata2 := types.DocData{Content: \"没有理由\"}\n\n\tsearcher.Index(\"1\", data)\n\tsearcher.Index(\"2\", data1)\n\tsearcher.Index(\"3\", data2)\n\tsearcher.Flush()\n\n\treq := types.SearchReq{Text: \"你好\"}\n\tsearch := searcher.Search(req)\n\tlog.Println(\"search...\", search)\n}\n```\n\n#### [Look at more Examples](https://github.com/go-ego/riot/tree/master/examples)\n\n#### [Look at Store example](https://github.com/go-ego/riot/blob/master/examples/store/main.go)\n#### [Look at Logic search example](https://github.com/go-ego/riot/blob/master/examples/logic/main.go)\n\n#### [Look at Pinyin search example](https://github.com/go-ego/riot/blob/master/examples/pinyin/main.go)\n\n#### [Look at different dict and language search example](https://github.com/go-ego/riot/blob/master/examples/dict/main.go)\n\n#### [Look at benchmark example](https://github.com/go-ego/riot/blob/master/examples/benchmark/benchmark.go)\n\n#### [Riot search engine templates, client and dictionaries](https://github.com/go-ego/riot/tree/master/data)\n\n## Authors\n\n* [Maintainers](https://github.com/orgs/go-ego/people)\n* [Contributors](https://github.com/go-ego/riot/graphs/contributors)\n\n## License\n\nRiot is primarily distributed under the terms of the Apache License (Version 2.0), base on [wukong](https://github.com/huichen/wukong).\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 6.296875,
          "content": "# [Riot 搜索引擎](https://github.com/go-ego/riot)\r\n\r\n<!--<img align=\"right\" src=\"https://raw.githubusercontent.com/go-ego/ego/master/logo.jpg\">-->\r\n<!--<a href=\"https://circleci.com/gh/go-ego/ego/tree/dev\"><img src=\"https://img.shields.io/circleci/project/go-ego/ego/dev.svg\" alt=\"Build Status\"></a>-->\r\n[![CircleCI Status](https://circleci.com/gh/go-ego/riot.svg?style=shield)](https://circleci.com/gh/go-ego/riot)\r\n![Appveyor](https://ci.appveyor.com/api/projects/status/github/go-ego/riot?branch=master&svg=true)\r\n[![codecov](https://codecov.io/gh/go-ego/riot/branch/master/graph/badge.svg)](https://codecov.io/gh/go-ego/riot)\r\n[![Build Status](https://travis-ci.org/go-ego/riot.svg)](https://travis-ci.org/go-ego/riot)\r\n[![Go Report Card](https://goreportcard.com/badge/github.com/go-ego/riot)](https://goreportcard.com/report/github.com/go-ego/riot)\r\n[![GoDoc](https://godoc.org/github.com/go-ego/riot?status.svg)](https://godoc.org/github.com/go-ego/riot)\r\n[![GitHub release](https://img.shields.io/github/release/go-ego/riot.svg)](https://github.com/go-ego/riot/releases/latest)\r\n[![Join the chat at https://gitter.im/go-ego/ego](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/go-ego/ego?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\r\n<!--<a href=\"https://github.com/go-ego/ego/releases\"><img src=\"https://img.shields.io/badge/%20version%20-%206.0.0%20-blue.svg?style=flat-square\" alt=\"Releases\"></a>-->\r\n\r\n\r\nGo Open Source, Distributed, Simple and efficient full text search engine.\r\n\r\n# Features\r\n\r\n* [高效索引和搜索](/docs/zh/benchmarking.md)（1M 条微博 500M 数据28秒索引完，1.65毫秒搜索响应时间，19K 搜索 QPS）\r\n* 支持中文分词（使用 [gse 分词包](https://github.com/go-ego/gse)并发分词，速度 27MB/秒）\r\n* 支持[逻辑搜索](https://github.com/go-ego/riot/blob/master/docs/zh/logic.md)\r\n* 支持中文转拼音搜索(使用 [gpy](https://github.com/go-ego/gpy) 中文转拼音)\r\n* 支持计算关键词在文本中的[紧邻距离](/docs/zh/token_proximity.md)（token proximity）\r\n* 支持计算[BM25相关度](/docs/zh/bm25.md)\r\n* 支持[自定义评分字段和评分规则](/docs/zh/custom_scoring_criteria.md)\r\n* 支持[在线添加、删除索引](/docs/zh/realtime_indexing.md)\r\n* 支持多种[持久存储](/docs/zh/persistent_storage.md)\r\n* 支持 heartbeat\r\n* 支持[分布式索引和搜索](https://github.com/go-ego/riot/tree/master/data)\r\n* 可实现[分布式索引和搜索](/docs/zh/distributed_indexing_and_search.md)\r\n* 采用对商业应用友好的[Apache License v2](/LICENSE)发布\r\n\r\n* [查看分词规则](https://github.com/go-ego/riot/blob/master/docs/zh/segmenter.md)\r\n<!-- \r\nRiot v0.10.0 was released in Nov 2017, check the [Changelog](https://github.com/go-ego/riot/blob/master/docs/CHANGELOG.md) for the full details. -->\r\n\r\n\r\n## 安装/更新\r\n\r\n```\r\ngo get -u github.com/go-ego/riot\r\n```\r\n\r\n## Requirements\r\n\r\n需要 Go 版本至少 1.8\r\n\r\n### Dependencies\r\n\r\nRiot 使用 go module 或 dep 管理依赖. \r\n\r\n## [Build-tools](https://github.com/go-ego/re)\r\n```\r\ngo get -u github.com/go-ego/re \r\n```\r\n### re riot\r\n创建 riot 项目\r\n\r\n```\r\n$ re riot my-riotapp\r\n```\r\n\r\n### re run\r\n\r\n运行我们创建的 riot 项目, 你可以导航到应用程序文件夹并执行:\r\n```\r\n$ cd my-riotapp && re run\r\n```\r\n\r\n## 使用\r\n\r\n先看一个例子（来自 [simplest_example.go](/examples/simple/zh/main.go)）\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"log\"\r\n\r\n\t\"github.com/go-ego/riot\"\r\n\t\"github.com/go-ego/riot/types\"\r\n)\r\n\r\nvar (\r\n\t// searcher 是协程安全的\r\n\tsearcher = riot.Engine{}\r\n)\r\n\r\nfunc main() {\r\n\t// 初始化\r\n\tsearcher.Init(types.EngineOpts{\r\n\t\tUsing:             3,\r\n\t\tGseDict: \"zh\",\r\n\t\t// GseDict: \"your gopath\"+\"/src/github.com/go-ego/riot/data/dict/dictionary.txt\",\r\n\t})\r\n\tdefer searcher.Close()\r\n\r\n\ttext := \"《复仇者联盟3：无限战争》是全片使用IMAX摄影机拍摄\"\r\n\ttext1 := \"在IMAX影院放映时\"\r\n\ttext2 := \"全片以上下扩展至IMAX 1.9：1的宽高比来呈现\"\r\n\t\r\n\t// 将文档加入索引，docId 从1开始\r\n\tsearcher.Index(\"1\", types.DocData{Content: text})\r\n\tsearcher.Index(\"2\", types.DocData{Content: text1}, false)\r\n\tsearcher.Index(\"3\", types.DocData{Content: text2}, true)\r\n\r\n\t// 等待索引刷新完毕\r\n\tsearcher.Flush()\r\n\t// engine.FlushIndex()\r\n\r\n\t// 搜索输出格式见 types.SearchResp 结构体\r\n\tlog.Print(searcher.Search(types.SearchReq{Text:\"复仇者\"}))\r\n}\r\n```\r\n\r\n是不是很简单！\r\n\r\n然后看看一个[入门教程](/docs/zh/codelab.md)，教你用不到200行 Go 代码实现一个微博搜索网站。\r\n\r\n### 使用默认引擎:\r\n\r\n```Go\r\npackage main\r\n\r\nimport (\r\n\t\"log\"\r\n\r\n\t\"github.com/go-ego/riot\"\r\n\t\"github.com/go-ego/riot/types\"\r\n)\r\n\r\nvar (\r\n\tsearcher = riot.New(\"zh\")\r\n)\r\n\r\nfunc main() {\r\n\tdata := types.DocData{Content: `I wonder how, I wonder why\r\n\t\t, I wonder where they are`}\r\n\tdata1 := types.DocData{Content: \"所以, 你好, 再见\"}\r\n\tdata2 := types.DocData{Content: \"没有理由\"}\r\n\r\n\tsearcher.Index(\"1\", data)\r\n\tsearcher.Index(\"2\", data1)\r\n\tsearcher.IndexDoc(\"3\", data2)\r\n\tsearcher.Flush()\r\n\r\n\treq := types.SearchReq{Text: \"你好\"}\r\n\tsearch := searcher.Search(req)\r\n\tlog.Println(\"search...\", search)\r\n}\r\n```\r\n\r\n#### [查看更多例子](https://github.com/go-ego/riot/tree/master/examples)\r\n\r\n#### [持久化的例子](https://github.com/go-ego/riot/blob/master/examples/store/main.go)\r\n#### [逻辑搜索的例子](https://github.com/go-ego/riot/blob/master/examples/logic/main.go)\r\n\r\n#### [拼音搜索的例子](https://github.com/go-ego/riot/blob/master/examples/pinyin/main.go)\r\n\r\n#### [不同字典和语言例子](https://github.com/go-ego/riot/blob/master/examples/dict/main.go)\r\n\r\n#### [benchmark](https://github.com/go-ego/riot/blob/master/examples/benchmark/benchmark.go)\r\n\r\n#### [Riot 搜索模板, 客户端和字典](https://github.com/go-ego/riot/tree/master/data)\r\n\r\n## 主要改进:\r\n\r\n- 增加逻辑搜索 \r\n- 增加拼音搜索 \r\n- 增加分布式 \r\n- 分词等改进 \r\n- 增加更多 api\r\n- 支持 heartbeat\r\n- 修复 bug\r\n- 删除依赖 cgo 的存储引擎, 增加 badger和 leveldb 持久化引擎\r\n\r\n## Authors\r\n\r\n* [Maintainers](https://github.com/orgs/go-ego/people)\r\n* [Contributors](https://github.com/go-ego/riot/graphs/contributors)\r\n\r\n## License\r\n\r\nRiot is primarily distributed under the terms of the Apache License (Version 2.0), base on [wukong](https://github.com/huichen/wukong).\r\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 1.1845703125,
          "content": "version: \"{build}\"\nimage: \"Visual Studio 2017\"\n# platform: x64\n\nclone_folder: c:\\gopath\\src\\github.com\\go-ego\\riot\n# max_jobs: 1\n\nenvironment:\n  global:\n    GOPATH: C:\\gopath\n    # CC: gcc.exe\n  matrix:\n    - GOARCH: amd64\n    # - GOARCH: 386\n  GOVERSION: 1.14.4\n  # GOPATH: c:\\gopath\n\ninstall:\n  - set PATH=%GOPATH%\\bin;c:\\go\\bin;%PATH%\n  - git submodule update --init\n  - rmdir C:\\go /s /q\n  - appveyor DownloadFile https://storage.googleapis.com/golang/go%GOVERSION%.windows-%GOARCH%.zip\n  - 7z x go%GOVERSION%.windows-%GOARCH%.zip -y -oC:\\ > NUL\n  - go version\n  - go env\n  # - gcc --version\n\n# To run your custom scripts instead of automatic MSBuild\nbuild_script:\n  # We need to disable firewall - https://github.com/appveyor/ci/issues/1579#issuecomment-309830648\n  - ps: Disable-NetFirewallRule -DisplayName 'File and Printer Sharing (SMB-Out)'\n  - cd c:\\gopath\\src\\github.com\\go-ego\\riot\n  - git branch\n  - go get -t ./...\n\n# To run your custom scripts instead of automatic tests\ntest_script:\n  # Unit tests\n  - ps: Add-AppveyorTest \"Unit Tests\" -Outcome Running\n  # - go test -u github.com/go-ego/riot/...\n  - go test -v github.com/go-ego/riot/...\n  - ps: Update-AppveyorTest \"Unit Tests\" -Outcome Passed\n"
        },
        {
          "name": "circle.yml",
          "type": "blob",
          "size": 0.857421875,
          "content": "# circle.yml #\n# machine:\n#   go:\n#     version: 1.9.1\n\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: golang:1.14.4\n    working_directory: /gopath/src/github.com/go-ego/riot\n    steps:\n      - checkout\n      # specify any bash command here prefixed with `run: `\n      # - run: go get -u github.com/go-ego/gse\n      # - run: go get -u github.com/go-ego/gpy\n      # - run: go get -u github.com/go-ego/murmur\n      # - run: go get -u golang.org/x/sys/unix\n      # - run: go get -u github.com/shirou/gopsutil\n      - run: go get -v -t -d ./...\n      - run: go test -v ./...\n      # codecov.io\n      - run: go test -v -covermode=count -coverprofile=coverage.out\n      - run: bash <(curl -s https://codecov.io/bash)\n\n# script:\n#   - ./go.test.sh\n\n# test:\n#   post:\n#     - go test -v -covermode=count -coverprofile=coverage.out\n#     - bash <(curl -s https://codecov.io/bash)\n"
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "counters.go",
          "type": "blob",
          "size": 1.3740234375,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\n// NumTokenAdded added token index number\nfunc (engine *Engine) NumTokenAdded() uint64 {\n\treturn engine.numTokenIndexAdded\n}\n\n// NumIndexed documents indexed number\nfunc (engine *Engine) NumIndexed() uint64 {\n\treturn engine.numDocsIndexed\n}\n\n// NumRemoved documents removed number\nfunc (engine *Engine) NumRemoved() uint64 {\n\treturn engine.numDocsRemoved\n}\n\n// NumTokenIndexAdded added token index number, deprecated\nfunc (engine *Engine) NumTokenIndexAdded() uint64 {\n\treturn engine.numTokenIndexAdded\n}\n\n// NumDocsIndexed documents indexed number, deprecated\nfunc (engine *Engine) NumDocsIndexed() uint64 {\n\treturn engine.numDocsIndexed\n}\n\n// NumDocsRemoved documents removed number, deprecated\nfunc (engine *Engine) NumDocsRemoved() uint64 {\n\treturn engine.numDocsRemoved\n}\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "engine.go",
          "type": "blob",
          "size": 22.619140625,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\n/*\n\nPackage riot is riot engine\n*/\npackage riot\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"sync/atomic\"\n\n\t\"github.com/go-ego/riot/core\"\n\t\"github.com/go-ego/riot/store\"\n\t\"github.com/go-ego/riot/types\"\n\t\"github.com/go-ego/riot/utils\"\n\n\t\"github.com/go-ego/gse\"\n\t\"github.com/go-ego/murmur\"\n\t\"github.com/shirou/gopsutil/mem\"\n)\n\nconst (\n\t// Version get the riot version\n\tVersion string = \"v0.10.0.425, Danube River!\"\n\n\t// NumNanosecondsInAMillisecond nano-seconds in a milli-second num\n\tNumNanosecondsInAMillisecond = 1000000\n\t// StoreFilePrefix persistent store file prefix\n\tStoreFilePrefix = \"riot\"\n\n\t// DefaultPath default db path\n\tDefaultPath = \"./riot-index\"\n)\n\n// GetVersion get the riot version\nfunc GetVersion() string {\n\treturn Version\n}\n\n// Engine initialize the engine\ntype Engine struct {\n\tloc sync.RWMutex\n\n\t// 计数器，用来统计有多少文档被索引等信息\n\tnumDocsIndexed      uint64\n\tnumDocsRemoved      uint64\n\tnumDocsForceUpdated uint64\n\n\tnumIndexingReqs      uint64\n\tnumRemovingReqs      uint64\n\tnumForceUpdatingReqs uint64\n\tnumTokenIndexAdded   uint64\n\tnumDocsStored        uint64\n\n\t// 记录初始化参数\n\tinitOptions types.EngineOpts\n\tinitialized bool\n\n\tindexers   []core.Indexer\n\trankers    []core.Ranker\n\tsegmenter  gse.Segmenter\n\tloaded     bool\n\tstopTokens StopTokens\n\tdbs        []store.Store\n\n\t// 建立索引器使用的通信通道\n\tsegmenterChan         chan segmenterReq\n\tindexerAddDocChans    []chan indexerAddDocReq\n\tindexerRemoveDocChans []chan indexerRemoveDocReq\n\trankerAddDocChans     []chan rankerAddDocReq\n\n\t// 建立排序器使用的通信通道\n\tindexerLookupChans   []chan indexerLookupReq\n\trankerRankChans      []chan rankerRankReq\n\trankerRemoveDocChans []chan rankerRemoveDocReq\n\n\t// 建立持久存储使用的通信通道\n\tstoreIndexDocChans []chan storeIndexDocReq\n\tstoreInitChan      chan bool\n}\n\n// Indexer initialize the indexer channel\nfunc (engine *Engine) Indexer(options types.EngineOpts) {\n\tengine.indexerAddDocChans = make(\n\t\t[]chan indexerAddDocReq, options.NumShards)\n\n\tengine.indexerRemoveDocChans = make(\n\t\t[]chan indexerRemoveDocReq, options.NumShards)\n\n\tengine.indexerLookupChans = make(\n\t\t[]chan indexerLookupReq, options.NumShards)\n\n\tfor shard := 0; shard < options.NumShards; shard++ {\n\t\tengine.indexerAddDocChans[shard] = make(\n\t\t\tchan indexerAddDocReq, options.IndexerBufLen)\n\n\t\tengine.indexerRemoveDocChans[shard] = make(\n\t\t\tchan indexerRemoveDocReq, options.IndexerBufLen)\n\n\t\tengine.indexerLookupChans[shard] = make(\n\t\t\tchan indexerLookupReq, options.IndexerBufLen)\n\t}\n}\n\n// Ranker initialize the ranker channel\nfunc (engine *Engine) Ranker(options types.EngineOpts) {\n\tengine.rankerAddDocChans = make(\n\t\t[]chan rankerAddDocReq, options.NumShards)\n\n\tengine.rankerRankChans = make(\n\t\t[]chan rankerRankReq, options.NumShards)\n\n\tengine.rankerRemoveDocChans = make(\n\t\t[]chan rankerRemoveDocReq, options.NumShards)\n\n\tfor shard := 0; shard < options.NumShards; shard++ {\n\t\tengine.rankerAddDocChans[shard] = make(\n\t\t\tchan rankerAddDocReq, options.RankerBufLen)\n\n\t\tengine.rankerRankChans[shard] = make(\n\t\t\tchan rankerRankReq, options.RankerBufLen)\n\n\t\tengine.rankerRemoveDocChans[shard] = make(\n\t\t\tchan rankerRemoveDocReq, options.RankerBufLen)\n\t}\n}\n\n// InitStore initialize the persistent store channel\nfunc (engine *Engine) InitStore() {\n\tengine.storeIndexDocChans = make(\n\t\t[]chan storeIndexDocReq, engine.initOptions.StoreShards)\n\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\tengine.storeIndexDocChans[shard] = make(\n\t\t\tchan storeIndexDocReq)\n\t}\n\tengine.storeInitChan = make(\n\t\tchan bool, engine.initOptions.StoreShards)\n}\n\n// CheckMem check the memory when the memory is larger\n// than 99.99% using the store\nfunc (engine *Engine) CheckMem() {\n\t// Todo test\n\tif !engine.initOptions.UseStore {\n\t\tlog.Println(\"Check virtualMemory...\")\n\n\t\tvmem, _ := mem.VirtualMemory()\n\t\tlog.Printf(\"Total: %v, Free: %v, UsedPercent: %f%%\\n\",\n\t\t\tvmem.Total, vmem.Free, vmem.UsedPercent)\n\n\t\tuseMem := fmt.Sprintf(\"%.2f\", vmem.UsedPercent)\n\t\tif useMem == \"99.99\" {\n\t\t\tengine.initOptions.UseStore = true\n\t\t\tengine.initOptions.StoreFolder = DefaultPath\n\t\t\t// os.MkdirAll(DefaultPath, 0777)\n\t\t}\n\t}\n}\n\n// Store start the persistent store work connection\nfunc (engine *Engine) Store() {\n\t// if engine.initOptions.UseStore {\n\terr := os.MkdirAll(engine.initOptions.StoreFolder, 0700)\n\tif err != nil {\n\t\tlog.Fatalf(\"Can not create directory: %s ; %v\",\n\t\t\tengine.initOptions.StoreFolder, err)\n\t}\n\n\t// 打开或者创建数据库\n\tengine.dbs = make([]store.Store, engine.initOptions.StoreShards)\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\tdbPath := engine.initOptions.StoreFolder + \"/\" +\n\t\t\tStoreFilePrefix + \".\" + strconv.Itoa(shard)\n\n\t\tdb, err := store.OpenStore(dbPath, engine.initOptions.StoreEngine)\n\t\tif db == nil || err != nil {\n\t\t\tlog.Fatal(\"Unable to open database \", dbPath, \": \", err)\n\t\t}\n\t\tengine.dbs[shard] = db\n\t}\n\n\t// 从数据库中恢复\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\tgo engine.storeInit(shard)\n\t}\n\n\t// 等待恢复完成\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\t<-engine.storeInitChan\n\t}\n\n\tfor {\n\t\truntime.Gosched()\n\n\t\tinx := atomic.LoadUint64(&engine.numDocsIndexed)\n\t\tnumDoced := engine.numIndexingReqs == inx\n\n\t\tif numDoced {\n\t\t\tbreak\n\t\t}\n\n\t}\n\n\t// 关闭并重新打开数据库\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\tengine.dbs[shard].Close()\n\t\tdbPath := engine.initOptions.StoreFolder + \"/\" +\n\t\t\tStoreFilePrefix + \".\" + strconv.Itoa(shard)\n\n\t\tdb, err := store.OpenStore(dbPath, engine.initOptions.StoreEngine)\n\t\tif db == nil || err != nil {\n\t\t\tlog.Fatal(\"Unable to open database \", dbPath, \": \", err)\n\t\t}\n\t\tengine.dbs[shard] = db\n\t}\n\n\tfor shard := 0; shard < engine.initOptions.StoreShards; shard++ {\n\t\tgo engine.storeIndexDoc(shard)\n\t}\n\t// }\n}\n\n// WithGse Using user defined segmenter\n// If using a not nil segmenter and the dictionary is loaded,\n// the `opt.GseDict` will be ignore.\nfunc (engine *Engine) WithGse(segmenter gse.Segmenter) *Engine {\n\tif engine.initialized {\n\t\tlog.Fatal(`Do not re-initialize the engine, \n\t\t\tWithGse should call before initialize the engine.`)\n\t}\n\n\tengine.segmenter = segmenter\n\tengine.loaded = true\n\treturn engine\n}\n\nfunc (engine *Engine) initDef(options types.EngineOpts) types.EngineOpts {\n\tif options.GseDict == \"\" && !options.NotUseGse && !engine.loaded {\n\t\tlog.Printf(\"Dictionary file path is empty, load the default dictionary file.\")\n\t\toptions.GseDict = \"zh\"\n\t}\n\n\tif options.UseStore == true && options.StoreFolder == \"\" {\n\t\tlog.Printf(\"Store file path is empty, use default folder path.\")\n\t\toptions.StoreFolder = DefaultPath\n\t\t// os.MkdirAll(DefaultPath, 0777)\n\t}\n\n\treturn options\n}\n\n// Init initialize the engine\nfunc (engine *Engine) Init(options types.EngineOpts) {\n\t// 将线程数设置为CPU数\n\t// runtime.GOMAXPROCS(runtime.NumCPU())\n\t// runtime.GOMAXPROCS(128)\n\n\t// 初始化初始参数\n\tif engine.initialized {\n\t\tlog.Fatal(\"Do not re-initialize the engine.\")\n\t}\n\toptions = engine.initDef(options)\n\n\toptions.Init()\n\tengine.initOptions = options\n\tengine.initialized = true\n\n\tif !options.NotUseGse {\n\t\tif !engine.loaded {\n\t\t\t// 载入分词器词典\n\t\t\tengine.segmenter.LoadDict(options.GseDict)\n\t\t\tengine.loaded = true\n\t\t}\n\n\t\t// 初始化停用词\n\t\tengine.stopTokens.Init(options.StopTokenFile)\n\t}\n\n\t// 初始化索引器和排序器\n\tfor shard := 0; shard < options.NumShards; shard++ {\n\t\tengine.indexers = append(engine.indexers, core.Indexer{})\n\t\tengine.indexers[shard].Init(*options.IndexerOpts)\n\n\t\tengine.rankers = append(engine.rankers, core.Ranker{})\n\t\tengine.rankers[shard].Init(options.IDOnly)\n\t}\n\n\t// 初始化分词器通道\n\tengine.segmenterChan = make(\n\t\tchan segmenterReq, options.NumGseThreads)\n\n\t// 初始化索引器通道\n\tengine.Indexer(options)\n\n\t// 初始化排序器通道\n\tengine.Ranker(options)\n\n\t// engine.CheckMem(engine.initOptions.UseStore)\n\tengine.CheckMem()\n\n\t// 初始化持久化存储通道\n\tif engine.initOptions.UseStore {\n\t\tengine.InitStore()\n\t}\n\n\t// 启动分词器\n\tfor iThread := 0; iThread < options.NumGseThreads; iThread++ {\n\t\tgo engine.segmenterWorker()\n\t}\n\n\t// 启动索引器和排序器\n\tfor shard := 0; shard < options.NumShards; shard++ {\n\t\tgo engine.indexerAddDoc(shard)\n\t\tgo engine.indexerRemoveDoc(shard)\n\t\tgo engine.rankerAddDoc(shard)\n\t\tgo engine.rankerRemoveDoc(shard)\n\n\t\tfor i := 0; i < options.NumIndexerThreads; i++ {\n\t\t\tgo engine.indexerLookup(shard)\n\t\t}\n\t\tfor i := 0; i < options.NumRankerThreads; i++ {\n\t\t\tgo engine.rankerRank(shard)\n\t\t}\n\t}\n\n\t// 启动持久化存储工作协程\n\tif engine.initOptions.UseStore {\n\t\tengine.Store()\n\t}\n\n\tatomic.AddUint64(&engine.numDocsStored, engine.numIndexingReqs)\n}\n\n// IndexDoc add the document to the index\n// 将文档加入索引\n//\n// 输入参数：\n//  docId\t      标识文档编号，必须唯一，docId == 0 表示非法文档（用于强制刷新索引），[1, +oo) 表示合法文档\n//  data\t      见 DocIndexData 注释\n//  forceUpdate 是否强制刷新 cache，如果设为 true，则尽快添加到索引，否则等待 cache 满之后一次全量添加\n//\n// 注意：\n//      1. 这个函数是线程安全的，请尽可能并发调用以提高索引速度\n//      2. 这个函数调用是非同步的，也就是说在函数返回时有可能文档还没有加入索引中，因此\n//         如果立刻调用Search可能无法查询到这个文档。强制刷新索引请调用FlushIndex函数。\nfunc (engine *Engine) IndexDoc(docId string, data types.DocData,\n\tforceUpdate ...bool) {\n\tengine.Index(docId, data, forceUpdate...)\n}\n\n// Index add the document to the index\nfunc (engine *Engine) Index(docId string, data types.DocData,\n\tforceUpdate ...bool) {\n\n\tvar force bool\n\tif len(forceUpdate) > 0 {\n\t\tforce = forceUpdate[0]\n\t}\n\n\t// if engine.HasDoc(docId) {\n\t// \tengine.RemoveDoc(docId)\n\t// }\n\n\t// data.Tokens\n\tengine.internalIndexDoc(docId, data, force)\n\n\thash := murmur.Sum32(docId) % uint32(engine.initOptions.StoreShards)\n\n\tif engine.initOptions.UseStore && docId != \"0\" {\n\t\tengine.storeIndexDocChans[hash] <- storeIndexDocReq{\n\t\t\tdocId: docId, data: data}\n\t}\n}\n\nfunc (engine *Engine) internalIndexDoc(docId string, data types.DocData,\n\tforceUpdate bool) {\n\n\tif !engine.initialized {\n\t\tlog.Fatal(\"The engine must be initialized first.\")\n\t}\n\n\tif docId != \"0\" {\n\t\tatomic.AddUint64(&engine.numIndexingReqs, 1)\n\t}\n\tif forceUpdate {\n\t\tatomic.AddUint64(&engine.numForceUpdatingReqs, 1)\n\t}\n\n\thash := murmur.Sum32(fmt.Sprintf(\"%s%s\", docId, data.Content))\n\tengine.segmenterChan <- segmenterReq{\n\t\tdocId: docId, hash: hash, data: data, forceUpdate: forceUpdate}\n}\n\n// RemoveDoc remove the document from the index\n// 将文档从索引中删除\n//\n// 输入参数：\n//  docId\t      标识文档编号，必须唯一，docId == 0 表示非法文档（用于强制刷新索引），[1, +oo) 表示合法文档\n//  forceUpdate 是否强制刷新 cache，如果设为 true，则尽快删除索引，否则等待 cache 满之后一次全量删除\n//\n// 注意：\n//      1. 这个函数是线程安全的，请尽可能并发调用以提高索引速度\n//      2. 这个函数调用是非同步的，也就是说在函数返回时有可能文档还没有加入索引中，因此\n//         如果立刻调用 Search 可能无法查询到这个文档。强制刷新索引请调用 FlushIndex 函数。\nfunc (engine *Engine) RemoveDoc(docId string, forceUpdate ...bool) {\n\tvar force bool\n\tif len(forceUpdate) > 0 {\n\t\tforce = forceUpdate[0]\n\t}\n\n\tif !engine.initialized {\n\t\tlog.Fatal(\"The engine must be initialized first.\")\n\t}\n\n\tif docId != \"0\" {\n\t\tatomic.AddUint64(&engine.numRemovingReqs, 1)\n\t}\n\n\tif force {\n\t\tatomic.AddUint64(&engine.numForceUpdatingReqs, 1)\n\t}\n\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\tengine.indexerRemoveDocChans[shard] <- indexerRemoveDocReq{\n\t\t\tdocId: docId, forceUpdate: force}\n\n\t\tif docId == \"0\" {\n\t\t\tcontinue\n\t\t}\n\t\tengine.rankerRemoveDocChans[shard] <- rankerRemoveDocReq{docId: docId}\n\t}\n\n\tif engine.initOptions.UseStore && docId != \"0\" {\n\t\t// 从数据库中删除\n\t\thash := murmur.Sum32(docId) % uint32(engine.initOptions.StoreShards)\n\n\t\tgo engine.storeRemoveDoc(docId, hash)\n\t}\n}\n\n// // 获取文本的分词结果\n// func (engine *Engine) Tokens(text []byte) (tokens []string) {\n// \tquerySegments := engine.segmenter.Segment(text)\n// \tfor _, s := range querySegments {\n// \t\ttoken := s.Token().Text()\n// \t\tif !engine.stopTokens.IsStopToken(token) {\n// \t\t\ttokens = append(tokens, token)\n// \t\t}\n// \t}\n// \treturn tokens\n// }\n\n// Segment get the word segmentation result of the text\n// 获取文本的分词结果, 只分词与过滤弃用词\nfunc (engine *Engine) Segment(content string) (keywords []string) {\n\n\tvar segments []string\n\thmm := engine.initOptions.Hmm\n\n\tif engine.initOptions.GseMode {\n\t\tsegments = engine.segmenter.CutSearch(content, hmm)\n\t} else {\n\t\tsegments = engine.segmenter.Cut(content, hmm)\n\t}\n\n\tfor _, token := range segments {\n\t\tif !engine.stopTokens.IsStopToken(token) {\n\t\t\tkeywords = append(keywords, token)\n\t\t}\n\t}\n\n\treturn\n}\n\n// Tokens get the engine tokens\nfunc (engine *Engine) Tokens(request types.SearchReq) (tokens []string) {\n\t// 收集关键词\n\t// tokens := []string{}\n\tif request.Text != \"\" {\n\t\treqText := strings.ToLower(request.Text)\n\t\tif engine.initOptions.NotUseGse {\n\t\t\ttokens = strings.Split(reqText, \" \")\n\t\t} else {\n\t\t\t// querySegments := engine.segmenter.Segment([]byte(reqText))\n\t\t\t// tokens = engine.Tokens([]byte(reqText))\n\t\t\ttokens = engine.Segment(reqText)\n\t\t}\n\n\t\t// 叠加 tokens\n\t\tfor _, t := range request.Tokens {\n\t\t\ttokens = append(tokens, t)\n\t\t}\n\n\t\treturn\n\t}\n\n\tfor _, t := range request.Tokens {\n\t\ttokens = append(tokens, t)\n\t}\n\treturn\n}\n\nfunc maxRankOutput(rankOpts types.RankOpts, rankLen int) (int, int) {\n\tvar start, end int\n\tif rankOpts.MaxOutputs == 0 {\n\t\tstart = utils.MinInt(rankOpts.OutputOffset, rankLen)\n\t\tend = rankLen\n\t\treturn start, end\n\t}\n\n\tstart = utils.MinInt(rankOpts.OutputOffset, rankLen)\n\tend = utils.MinInt(start+rankOpts.MaxOutputs, rankLen)\n\treturn start, end\n}\n\nfunc (engine *Engine) rankOutID(rankerOutput rankerReturnReq,\n\trankOutArr types.ScoredIDs) types.ScoredIDs {\n\tfor _, doc := range rankerOutput.docs.(types.ScoredIDs) {\n\t\trankOutArr = append(rankOutArr, doc)\n\t}\n\treturn rankOutArr\n}\n\nfunc (engine *Engine) rankOutDocs(rankerOutput rankerReturnReq,\n\trankOutArr types.ScoredDocs) types.ScoredDocs {\n\tfor _, doc := range rankerOutput.docs.(types.ScoredDocs) {\n\t\trankOutArr = append(rankOutArr, doc)\n\t}\n\treturn rankOutArr\n}\n\n// NotTimeOut not set engine timeout\nfunc (engine *Engine) NotTimeOut(request types.SearchReq,\n\trankerReturnChan chan rankerReturnReq) (\n\trankOutArr interface{}, numDocs int) {\n\n\tvar (\n\t\trankOutID  types.ScoredIDs\n\t\trankOutDoc types.ScoredDocs\n\t\tidOnly     = engine.initOptions.IDOnly\n\t)\n\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\trankerOutput := <-rankerReturnChan\n\t\tif !request.CountDocsOnly {\n\t\t\tif rankerOutput.docs != nil {\n\t\t\t\tif idOnly {\n\t\t\t\t\trankOutID = engine.rankOutID(rankerOutput, rankOutID)\n\t\t\t\t} else {\n\t\t\t\t\trankOutDoc = engine.rankOutDocs(rankerOutput, rankOutDoc)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tnumDocs += rankerOutput.numDocs\n\t}\n\n\tif idOnly {\n\t\trankOutArr = rankOutID\n\t\treturn\n\t}\n\n\trankOutArr = rankOutDoc\n\treturn\n}\n\n// TimeOut set engine timeout\nfunc (engine *Engine) TimeOut(request types.SearchReq,\n\trankerReturnChan chan rankerReturnReq) (\n\trankOutArr interface{}, numDocs int, isTimeout bool) {\n\n\tdeadline := time.Now().Add(time.Nanosecond *\n\t\ttime.Duration(NumNanosecondsInAMillisecond*request.Timeout))\n\n\tvar (\n\t\trankOutID  types.ScoredIDs\n\t\trankOutDoc types.ScoredDocs\n\t\tidOnly     = engine.initOptions.IDOnly\n\t)\n\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\tselect {\n\t\tcase rankerOutput := <-rankerReturnChan:\n\t\t\tif !request.CountDocsOnly {\n\t\t\t\tif rankerOutput.docs != nil {\n\t\t\t\t\tif idOnly {\n\t\t\t\t\t\trankOutID = engine.rankOutID(rankerOutput, rankOutID)\n\t\t\t\t\t} else {\n\t\t\t\t\t\trankOutDoc = engine.rankOutDocs(rankerOutput, rankOutDoc)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnumDocs += rankerOutput.numDocs\n\t\tcase <-time.After(deadline.Sub(time.Now())):\n\t\t\tisTimeout = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif idOnly {\n\t\trankOutArr = rankOutID\n\t\treturn\n\t}\n\n\trankOutArr = rankOutDoc\n\treturn\n}\n\n// RankID rank docs by types.ScoredIDs\nfunc (engine *Engine) RankID(request types.SearchReq, rankOpts types.RankOpts,\n\ttokens []string, rankerReturnChan chan rankerReturnReq) (output types.SearchResp) {\n\t// 从通信通道读取排序器的输出\n\tnumDocs := 0\n\trankOutput := types.ScoredIDs{}\n\n\t//**********/ begin\n\ttimeout := request.Timeout\n\tisTimeout := false\n\tif timeout <= 0 {\n\t\t// 不设置超时\n\t\trankOutArr, num := engine.NotTimeOut(request, rankerReturnChan)\n\t\trankOutput = rankOutArr.(types.ScoredIDs)\n\t\tnumDocs += num\n\t} else {\n\t\t// 设置超时\n\t\trankOutArr, num, timeout := engine.TimeOut(request, rankerReturnChan)\n\t\trankOutput = rankOutArr.(types.ScoredIDs)\n\t\tnumDocs += num\n\t\tisTimeout = timeout\n\t}\n\n\t// 再排序\n\tif !request.CountDocsOnly && !request.Orderless {\n\t\tif rankOpts.ReverseOrder {\n\t\t\tsort.Sort(sort.Reverse(rankOutput))\n\t\t} else {\n\t\t\tsort.Sort(rankOutput)\n\t\t}\n\t}\n\n\t// 准备输出\n\toutput.Tokens = tokens\n\t// 仅当 CountDocsOnly 为 false 时才充填 output.Docs\n\tif !request.CountDocsOnly {\n\t\tif request.Orderless {\n\t\t\t// 无序状态无需对 Offset 截断\n\t\t\toutput.Docs = rankOutput\n\t\t} else {\n\t\t\trankOutLen := len(rankOutput)\n\t\t\tstart, end := maxRankOutput(rankOpts, rankOutLen)\n\n\t\t\toutput.Docs = rankOutput[start:end]\n\t\t}\n\t}\n\n\toutput.NumDocs = numDocs\n\toutput.Timeout = isTimeout\n\n\treturn\n}\n\n// Ranks rank docs by types.ScoredDocs\nfunc (engine *Engine) Ranks(request types.SearchReq, rankOpts types.RankOpts,\n\ttokens []string, rankerReturnChan chan rankerReturnReq) (output types.SearchResp) {\n\t// 从通信通道读取排序器的输出\n\tnumDocs := 0\n\trankOutput := types.ScoredDocs{}\n\n\t//**********/ begin\n\ttimeout := request.Timeout\n\tisTimeout := false\n\tif timeout <= 0 {\n\t\t// 不设置超时\n\t\trankOutArr, num := engine.NotTimeOut(request, rankerReturnChan)\n\t\trankOutput = rankOutArr.(types.ScoredDocs)\n\t\tnumDocs += num\n\t} else {\n\t\t// 设置超时\n\t\trankOutArr, num, timeout := engine.TimeOut(request, rankerReturnChan)\n\t\trankOutput = rankOutArr.(types.ScoredDocs)\n\t\tnumDocs += num\n\t\tisTimeout = timeout\n\t}\n\n\t// 再排序\n\tif !request.CountDocsOnly && !request.Orderless {\n\t\tif rankOpts.ReverseOrder {\n\t\t\tsort.Sort(sort.Reverse(rankOutput))\n\t\t} else {\n\t\t\tsort.Sort(rankOutput)\n\t\t}\n\t}\n\n\t// 准备输出\n\toutput.Tokens = tokens\n\t// 仅当 CountDocsOnly 为 false 时才充填 output.Docs\n\tif !request.CountDocsOnly {\n\t\tif request.Orderless {\n\t\t\t// 无序状态无需对 Offset 截断\n\t\t\toutput.Docs = rankOutput\n\t\t} else {\n\t\t\trankOutLen := len(rankOutput)\n\t\t\tstart, end := maxRankOutput(rankOpts, rankOutLen)\n\n\t\t\toutput.Docs = rankOutput[start:end]\n\t\t}\n\t}\n\n\toutput.NumDocs = numDocs\n\toutput.Timeout = isTimeout\n\n\treturn\n}\n\n// SearchDoc find the document that satisfies the search criteria.\n// This function is thread safe, return not IDonly\nfunc (engine *Engine) SearchDoc(request types.SearchReq) (output types.SearchDoc) {\n\tresp := engine.Search(request)\n\treturn types.SearchDoc{\n\t\tBaseResp: resp.BaseResp,\n\t\tDocs:     resp.Docs.(types.ScoredDocs),\n\t}\n}\n\n// SearchID find the document that satisfies the search criteria.\n// This function is thread safe, return IDonly\nfunc (engine *Engine) SearchID(request types.SearchReq) (output types.SearchID) {\n\t// return types.SearchID(engine.Search(request))\n\tresp := engine.Search(request)\n\treturn types.SearchID{\n\t\tBaseResp: resp.BaseResp,\n\t\tDocs:     resp.Docs.(types.ScoredIDs),\n\t}\n}\n\n// Search find the document that satisfies the search criteria.\n// This function is thread safe\n// 查找满足搜索条件的文档，此函数线程安全\nfunc (engine *Engine) Search(request types.SearchReq) (output types.SearchResp) {\n\tif !engine.initialized {\n\t\tlog.Fatal(\"The engine must be initialized first.\")\n\t}\n\n\ttokens := engine.Tokens(request)\n\n\tvar rankOpts types.RankOpts\n\tif request.RankOpts == nil {\n\t\trankOpts = *engine.initOptions.DefRankOpts\n\t} else {\n\t\trankOpts = *request.RankOpts\n\t}\n\n\tif rankOpts.ScoringCriteria == nil {\n\t\trankOpts.ScoringCriteria = engine.initOptions.DefRankOpts.ScoringCriteria\n\t}\n\n\t// 建立排序器返回的通信通道\n\trankerReturnChan := make(\n\t\tchan rankerReturnReq, engine.initOptions.NumShards)\n\n\t// 生成查找请求\n\tlookupRequest := indexerLookupReq{\n\t\tcountDocsOnly:    request.CountDocsOnly,\n\t\ttokens:           tokens,\n\t\tlabels:           request.Labels,\n\t\tdocIds:           request.DocIds,\n\t\toptions:          rankOpts,\n\t\trankerReturnChan: rankerReturnChan,\n\t\torderless:        request.Orderless,\n\t\tlogic:            request.Logic,\n\t}\n\n\t// 向索引器发送查找请求\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\tengine.indexerLookupChans[shard] <- lookupRequest\n\t}\n\n\tif engine.initOptions.IDOnly {\n\t\toutput = engine.RankID(request, rankOpts, tokens, rankerReturnChan)\n\t\treturn\n\t}\n\n\toutput = engine.Ranks(request, rankOpts, tokens, rankerReturnChan)\n\treturn\n}\n\n// Flush block wait until all indexes are added\n// 阻塞等待直到所有索引添加完毕\nfunc (engine *Engine) Flush() {\n\tfor {\n\t\truntime.Gosched()\n\n\t\tinxd := engine.numIndexingReqs == atomic.LoadUint64(&engine.numDocsIndexed)\n\t\tnumRm := engine.numRemovingReqs * uint64(engine.initOptions.NumShards)\n\t\trmd := numRm == atomic.LoadUint64(&engine.numDocsRemoved)\n\n\t\tnums := engine.numIndexingReqs == atomic.LoadUint64(&engine.numDocsStored)\n\t\tstored := !engine.initOptions.UseStore || nums\n\n\t\tif inxd && rmd && stored {\n\t\t\t// 保证 CHANNEL 中 REQUESTS 全部被执行完\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// 强制更新，保证其为最后的请求\n\tengine.IndexDoc(\"0\", types.DocData{}, true)\n\tfor {\n\t\truntime.Gosched()\n\n\t\tnumf := engine.numForceUpdatingReqs * uint64(engine.initOptions.NumShards)\n\t\tforced := numf == atomic.LoadUint64(&engine.numDocsForceUpdated)\n\n\t\tif forced {\n\t\t\treturn\n\t\t}\n\n\t}\n}\n\n// FlushIndex block wait until all indexes are added\n// 阻塞等待直到所有索引添加完毕\nfunc (engine *Engine) FlushIndex() {\n\tengine.Flush()\n}\n\n// Close close the engine\n// 关闭引擎\nfunc (engine *Engine) Close() {\n\tengine.Flush()\n\tif engine.initOptions.UseStore {\n\t\tfor _, db := range engine.dbs {\n\t\t\tdb.Close()\n\t\t}\n\t}\n}\n\n// 从文本hash得到要分配到的 shard\nfunc (engine *Engine) getShard(hash uint32) int {\n\treturn int(hash - hash/uint32(engine.initOptions.NumShards)*\n\t\tuint32(engine.initOptions.NumShards))\n}\n"
        },
        {
          "name": "engine",
          "type": "tree",
          "content": null
        },
        {
          "name": "engine_test.go",
          "type": "blob",
          "size": 18.322265625,
          "content": "package riot\n\nimport (\n\t\"encoding/gob\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"testing\"\n\n\t\"github.com/go-ego/gse\"\n\t\"github.com/go-ego/riot/types\"\n\t\"github.com/vcaesar/tt\"\n)\n\nfunc TestGetVer(t *testing.T) {\n\tfmt.Println(\"go version: \", runtime.Version())\n\tver := GetVersion()\n\ttt.Expect(t, Version, ver)\n\ttt.Equal(t, Version, ver)\n}\n\nfunc TestTry(t *testing.T) {\n\tvar arr []int\n\n\tTry(func() {\n\t\tfmt.Println(arr[2])\n\t}, func(err interface{}) {\n\t\tlog.Println(\"err\", err)\n\t\ttt.Expect(t, \"runtime error: index out of range [2] with length 0\", err)\n\t})\n}\n\nfunc TestEngineIndexDoc(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(TestIndexOpts)\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"world\", outputs.Tokens[0])\n\ttt.Expect(t, \"人口\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"3\", len(outDocs))\n\n\tlog.Println(\"TestEngineIndexDoc:\", outDocs)\n\ttt.Expect(t, \"2\", outDocs[0].DocId)\n\ttt.Expect(t, \"333\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[4 11]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"5\", outDocs[1].DocId)\n\ttt.Expect(t, \"83\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[4 20]\", outDocs[1].TokenSnippetLocs)\n\n\ttt.Expect(t, \"1\", outDocs[2].DocId)\n\ttt.Expect(t, \"66\", int(outDocs[2].Scores[0]*1000))\n\ttt.Expect(t, \"[4 23]\", outDocs[2].TokenSnippetLocs)\n\n\tengine.Close()\n}\n\nfunc TestReverseOrder(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(orderOpts)\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"3\", len(outDocs))\n\n\ttt.Expect(t, \"1\", outDocs[0].DocId)\n\ttt.Expect(t, \"5\", outDocs[1].DocId)\n\ttt.Expect(t, \"2\", outDocs[2].DocId)\n\n\tengine.Close()\n}\n\nfunc TestOffsetAndMaxOutputs(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(types.EngineOpts{\n\t\tUsing:       1,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankOptsMax3,\n\t\tIndexerOpts: inxOpts,\n\t})\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"5\", outDocs[0].DocId)\n\ttt.Expect(t, \"2\", outDocs[1].DocId)\n\n\tengine.Close()\n}\n\ntype TestScoringCriteria struct {\n}\n\nfunc (criteria TestScoringCriteria) Score(\n\tdoc types.IndexedDoc, fields interface{}) []float32 {\n\tif reflect.TypeOf(fields) != reflect.TypeOf(ScoringFields{}) {\n\t\treturn []float32{}\n\t}\n\tfs := fields.(ScoringFields)\n\treturn []float32{float32(doc.TokenProximity)*fs.A + fs.B*fs.C}\n}\n\nvar (\n\tengOpts = types.EngineOpts{\n\t\tUsing:   1,\n\t\tGseDict: \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &types.RankOpts{\n\t\t\tScoringCriteria: TestScoringCriteria{},\n\t\t},\n\t\tIndexerOpts: inxOpts,\n\t}\n)\n\nfunc TestSearchWithCriteria(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(engOpts)\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\tlog.Println(outDocs)\n\ttt.Expect(t, \"1\", outDocs[0].DocId)\n\ttt.Expect(t, \"20000\", int(outDocs[0].Scores[0]*1000))\n\n\ttt.Expect(t, \"5\", outDocs[1].DocId)\n\ttt.Expect(t, \"9000\", int(outDocs[1].Scores[0]*1000))\n\n\tengine.Close()\n}\n\nfunc TestCompactIndex(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(useOpts)\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"5\", outDocs[0].DocId)\n\ttt.Expect(t, \"9000\", int(outDocs[0].Scores[0]*1000))\n\n\ttt.Expect(t, \"1\", outDocs[1].DocId)\n\ttt.Expect(t, \"6000\", int(outDocs[1].Scores[0]*1000))\n\n\tengine.Close()\n}\n\ntype BM25ScoringCriteria struct {\n}\n\nfunc (criteria BM25ScoringCriteria) Score(\n\tdoc types.IndexedDoc, fields interface{}) []float32 {\n\tif reflect.TypeOf(fields) != reflect.TypeOf(ScoringFields{}) {\n\t\treturn []float32{}\n\t}\n\treturn []float32{doc.BM25}\n}\n\nfunc TestFrequenciesIndex(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(types.EngineOpts{\n\t\tUsing:   1,\n\t\tGseDict: \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &types.RankOpts{\n\t\t\tScoringCriteria: BM25ScoringCriteria{},\n\t\t},\n\t\tIndexerOpts: &types.IndexerOpts{\n\t\t\tIndexType: types.FrequenciesIndex,\n\t\t},\n\t})\n\n\tAddDocs(&engine)\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"1\", outDocs[0].DocId)\n\ttt.Expect(t, \"2374\", int(outDocs[0].Scores[0]*1000))\n\n\ttt.Expect(t, \"5\", outDocs[1].DocId)\n\ttt.Expect(t, \"2133\", int(outDocs[1].Scores[0]*1000))\n\n\tengine.Close()\n}\n\nvar (\n\tuseOpts = types.EngineOpts{\n\t\tUsing:   1,\n\t\tGseDict: \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &types.RankOpts{\n\t\t\tScoringCriteria: TestScoringCriteria{},\n\t\t},\n\t}\n)\n\nfunc TestRemoveDoc(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(useOpts)\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.RemoveDoc(\"6\")\n\tengine.Flush()\n\n\tengine.Index(\"6\", types.DocData{\n\t\tContent: \"World, 人口有七十亿\",\n\t\tFields:  score091,\n\t})\n\tengine.Flush()\n\n\toutputs := engine.Search(Req1)\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"6\", outDocs[0].DocId)\n\ttt.Expect(t, \"9000\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"1\", outDocs[1].DocId)\n\ttt.Expect(t, \"6000\", int(outDocs[1].Scores[0]*1000))\n\n\tengine.Close()\n}\n\nfunc TestEngineIndexWithTokens(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(TestIndexOpts)\n\n\tdata1 := types.TokenData{\n\t\tText:      \"world\",\n\t\tLocations: []int{0},\n\t}\n\t// docId := uint64(1)\n\tengine.Index(\"1\", types.DocData{\n\t\tContent: \"\",\n\t\tTokens: []types.TokenData{\n\t\t\tdata1,\n\t\t\t{\"人口\", []int{18, 24}},\n\t\t},\n\t\tFields: score1,\n\t})\n\n\t// docId++\n\tengine.Index(\"2\", types.DocData{\n\t\tContent: \"\",\n\t\tTokens: []types.TokenData{\n\t\t\tdata1,\n\t\t\t{\"人口\", []int{6}},\n\t\t},\n\t\tFields: score1,\n\t})\n\n\tengine.Index(\"3\", types.DocData{\n\t\tContent: \"The world, 七十亿人口\",\n\t\tFields:  score091,\n\t})\n\tengine.FlushIndex()\n\n\toutputs := engine.Search(Req1)\n\tlog.Println(\"TestEngineIndexWithTokens: \", outputs)\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"world\", outputs.Tokens[0])\n\ttt.Expect(t, \"人口\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"3\", len(outDocs))\n\n\ttt.Expect(t, \"2\", outDocs[0].DocId)\n\ttt.Expect(t, \"500\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[0 6]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"3\", outDocs[1].DocId)\n\ttt.Expect(t, \"83\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[4 20]\", outDocs[1].TokenSnippetLocs)\n\n\ttt.Expect(t, \"1\", outDocs[2].DocId)\n\ttt.Expect(t, \"71\", int(outDocs[2].Scores[0]*1000))\n\ttt.Expect(t, \"[0 18]\", outDocs[2].TokenSnippetLocs)\n\n\tengine.Close()\n}\n\nfunc testLabelsOpts(indexType int) types.EngineOpts {\n\treturn types.EngineOpts{\n\t\tGseDict: \"./data/dict/dictionary.txt\",\n\t\tIndexerOpts: &types.IndexerOpts{\n\t\t\tIndexType: indexType,\n\t\t},\n\t}\n}\n\nfunc TestEngineIndexWithContentAndLabels(t *testing.T) {\n\tvar engine1, engine2 Engine\n\tengine1.Init(testLabelsOpts(types.LocsIndex))\n\tengine2.Init(testLabelsOpts(types.DocIdsIndex))\n\n\tAddDocsWithLabels(&engine1)\n\tAddDocsWithLabels(&engine2)\n\n\toutputs1 := engine1.Search(reqG)\n\toutputs2 := engine2.Search(reqG)\n\ttt.Expect(t, \"1\", len(outputs1.Tokens))\n\ttt.Expect(t, \"1\", len(outputs2.Tokens))\n\ttt.Expect(t, \"google\", outputs1.Tokens[0])\n\ttt.Expect(t, \"google\", outputs2.Tokens[0])\n\n\toutDocs := outputs1.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\ttt.Expect(t, \"2\", len(outputs2.Docs.(types.ScoredDocs)))\n\n\tengine1.Close()\n\tengine2.Close()\n}\n\nfunc TestIndexWithLabelsStopTokenFile(t *testing.T) {\n\tvar engine1 Engine\n\n\tengine1.Init(types.EngineOpts{\n\t\tGseDict:       \"./data/dict/dictionary.txt\",\n\t\tStopTokenFile: \"./testdata/test_stop_dict.txt\",\n\t\tIndexerOpts:   inxOpts,\n\t})\n\n\tAddDocsWithLabels(&engine1)\n\n\toutputs1 := engine1.Search(reqG)\n\toutputsDoc := engine1.SearchDoc(reqG)\n\ttt.Expect(t, \"1\", len(outputs1.Tokens))\n\t// tt.Expect(t, \"Google\", outputs1.Tokens[0])\n\n\toutDocs := outputs1.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\ttt.Expect(t, \"2\", len(outputsDoc.Docs))\n}\n\nfunc TestEngineIndexWithStore(t *testing.T) {\n\tgob.Register(ScoringFields{})\n\n\tvar opts = types.EngineOpts{\n\t\tUsing:       1,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankOptsMax10,\n\t\tIndexerOpts: inxOpts,\n\t\tUseStore:    true,\n\t\tStoreFolder: \"riot.persistent\",\n\t\tStoreShards: 2,\n\t}\n\n\tvar engine Engine\n\tengine.Init(opts)\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\", true)\n\tengine.Flush()\n\n\tengine.Close()\n\n\tvar engine1 Engine\n\tengine1.Init(opts)\n\tengine1.Flush()\n\n\toutputs := engine1.Search(Req1)\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"world\", outputs.Tokens[0])\n\ttt.Expect(t, \"人口\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"2\", outDocs[0].DocId)\n\ttt.Expect(t, \"333\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[4 11]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"1\", outDocs[1].DocId)\n\ttt.Expect(t, \"66\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[4 23]\", outDocs[1].TokenSnippetLocs)\n\n\tengine1.Close()\n\tos.RemoveAll(\"riot.persistent\")\n}\n\nfunc TestCountDocsOnly(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(types.EngineOpts{\n\t\tUsing:       1,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankOptsMax1,\n\t\tIndexerOpts: inxOpts,\n\t})\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\toutputs := engine.Search(\n\t\ttypes.SearchReq{Text: reqText, CountDocsOnly: true},\n\t)\n\t// tt.Expect(t, \"0\", len(outputs.Docs))\n\tif outputs.Docs == nil {\n\t\ttt.Expect(t, \"0\", 0)\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\tengine.Close()\n}\n\nfunc TestDocOrderless(t *testing.T) {\n\tvar engine, engine1 Engine\n\tengine.Init(OrderlessOpts(false))\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\torderReq := types.SearchReq{Text: reqText, Orderless: true}\n\toutputs := engine.Search(orderReq)\n\t// tt.Expect(t, \"0\", len(outputs.Docs))\n\tif outputs.Docs == nil {\n\t\ttt.Expect(t, \"0\", 0)\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\tengine1.Init(OrderlessOpts(true))\n\n\tAddDocs(&engine1)\n\n\tengine1.RemoveDoc(\"5\")\n\tengine1.Flush()\n\n\toutputs1 := engine1.Search(orderReq)\n\tif outputs1.Docs == nil {\n\t\ttt.Expect(t, \"0\", 0)\n\t}\n\n\ttt.Expect(t, \"2\", len(outputs1.Tokens))\n\ttt.Expect(t, \"2\", outputs1.NumDocs)\n\n\tengine.Close()\n}\n\nvar (\n\ttestIDInlyOpts = types.EngineOpts{\n\t\t// Using:       1,\n\t\tIDOnly:      true,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankOptsMax1,\n\t\tIndexerOpts: inxOpts,\n\t}\n)\n\nfunc TestDocOnlyID(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(testIDInlyOpts)\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\treq := types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: makeDocIds(),\n\t}\n\toutputs := engine.Search(req)\n\toutputsID := engine.SearchID(req)\n\ttt.Expect(t, \"1\", len(outputsID.Docs))\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"1\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\toutputs1 := engine.Search(types.SearchReq{\n\t\tText:    reqText,\n\t\tTimeout: 10,\n\t\tDocIds:  makeDocIds(),\n\t})\n\n\tif outputs1.Docs != nil {\n\t\toutDocs1 := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"1\", len(outDocs1))\n\t}\n\ttt.Expect(t, \"2\", len(outputs1.Tokens))\n\ttt.Expect(t, \"2\", outputs1.NumDocs)\n\n\tengine.Close()\n}\n\nfunc TestSearchWithin(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(orderOpts)\n\n\tAddDocs(&engine)\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: docIds,\n\t})\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"world\", outputs.Tokens[0])\n\ttt.Expect(t, \"人口\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"1\", outDocs[0].DocId)\n\ttt.Expect(t, \"66\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[4 23]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"5\", outDocs[1].DocId)\n\ttt.Expect(t, \"83\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[4 20]\", outDocs[1].TokenSnippetLocs)\n\n\tengine.Close()\n}\n\nfunc testJPOpts(use int) types.EngineOpts {\n\treturn types.EngineOpts{\n\t\t// Using:           1,\n\t\tUsing:       use,\n\t\tGseDict:     \"./testdata/test_dict_jp.txt\",\n\t\tDefRankOpts: &rankOptsMax10Order,\n\t\tIndexerOpts: inxOpts,\n\t}\n}\n\nfunc TestSearchJp(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(testJPOpts(1))\n\n\tAddDocs(&engine)\n\n\tengine.Index(\"7\", types.DocData{\n\t\tContent: textJP1,\n\t\tFields:  score1,\n\t})\n\tengine.Flush()\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\tdocIds[\"7\"] = true\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   textJP,\n\t\tDocIds: docIds,\n\t})\n\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"こんにちは\", outputs.Tokens[0])\n\ttt.Expect(t, \"世界\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\tlog.Println(\"outputs docs...\", outDocs)\n\ttt.Expect(t, \"1\", len(outDocs))\n\n\ttt.Expect(t, \"7\", outDocs[0].DocId)\n\ttt.Expect(t, \"1000\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[0 15]\", outDocs[0].TokenSnippetLocs)\n\n\tengine.Close()\n}\n\nfunc makeGseDocIds() map[string]bool {\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\tdocIds[\"6\"] = true\n\tdocIds[\"7\"] = true\n\tdocIds[\"8\"] = true\n\n\treturn docIds\n}\n\nfunc tokenData() []types.TokenData {\n\ttokenData := types.TokenData{\n\t\tText:      \"こんにちは\",\n\t\tLocations: []int{10, 20},\n\t}\n\n\treturn []types.TokenData{tokenData}\n}\n\nfunc TestSearchGse(t *testing.T) {\n\tlog.Println(\"Test search gse ...\")\n\tvar engine Engine\n\tengine.Init(testJPOpts(0))\n\n\tAddDocs(&engine)\n\n\tengine.Index(\"7\", types.DocData{\n\t\tContent: textJP1,\n\t\tFields:  score1,\n\t})\n\n\ttokenDatas := tokenData()\n\tengine.Index(\"8\", types.DocData{\n\t\tContent: text1,\n\t\tTokens:  tokenDatas,\n\t\tFields:  ScoringFields{4, 5, 6},\n\t})\n\tengine.Flush()\n\n\tdocIds := makeGseDocIds()\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   textJP,\n\t\tDocIds: docIds,\n\t})\n\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"こんにちは\", outputs.Tokens[0])\n\ttt.Expect(t, \"世界\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\tlog.Println(\"outputs docs...\", outDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"8\", outDocs[0].DocId)\n\ttt.Expect(t, \"142\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[10 19]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"7\", outDocs[1].DocId)\n\ttt.Expect(t, \"1000\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[0 15]\", outDocs[1].TokenSnippetLocs)\n\n\tengine.Close()\n}\n\nfunc TestSearchNotUseGse(t *testing.T) {\n\tvar engine, engine1 Engine\n\tengine.Init(types.EngineOpts{\n\t\tUsing:     4,\n\t\tNotUseGse: true,\n\t})\n\n\tengine1.Init(types.EngineOpts{\n\t\tIDOnly:    true,\n\t\tNotUseGse: true,\n\t})\n\n\tAddDocs(&engine)\n\tAddDocs(&engine1)\n\n\tdata := types.DocData{\n\t\tContent: \"Google Is Experimenting With Virtual Reality Advertising\",\n\t\tFields:  score1,\n\t\tTokens:  []types.TokenData{{Text: \"test\"}},\n\t}\n\n\tengine.Index(\"7\", data)\n\tengine.Index(\"8\", data)\n\n\tengine1.Index(\"7\", data, true)\n\tengine1.Index(\"8\", data, true)\n\n\tengine.Flush()\n\tengine1.Flush()\n\n\tdocIds := makeGseDocIds()\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   \"google is\",\n\t\tDocIds: docIds,\n\t})\n\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"google\", outputs.Tokens[0])\n\ttt.Expect(t, \"is\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\tlog.Println(\"outputs docs...\", outDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"8\", outDocs[0].DocId)\n\ttt.Expect(t, \"3736\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[]\", outDocs[0].TokenSnippetLocs)\n\n\toutputs1 := engine1.Search(types.SearchReq{\n\t\tText:   \"google\",\n\t\tDocIds: docIds})\n\ttt.Expect(t, \"1\", len(outputs1.Tokens))\n\ttt.Expect(t, \"2\", outputs1.NumDocs)\n\n\tengine.Close()\n\tengine1.Close()\n}\n\nfunc TestSearchWithGse(t *testing.T) {\n\tseg := gse.Segmenter{}\n\tseg.LoadDict(\"zh\") // ./data/dict/dictionary.txt\n\n\tvar engine1, engine2, searcher2 Engine\n\tsearcher2.Init(types.EngineOpts{\n\t\tUsing: 1,\n\t})\n\tdefer searcher2.Close()\n\n\tengine1.WithGse(seg).Init(types.EngineOpts{\n\t\tIndexerOpts: inxOpts,\n\t})\n\n\tengine2.WithGse(seg).Init(types.EngineOpts{\n\t\t// GseDict: \"./data/dict/dictionary.txt\",\n\t\tIndexerOpts: &types.IndexerOpts{\n\t\t\tIndexType: types.DocIdsIndex,\n\t\t},\n\t})\n\n\tAddDocsWithLabels(&engine1)\n\tAddDocsWithLabels(&engine2)\n\n\toutputs1 := engine1.Search(reqG)\n\toutputs2 := engine2.Search(reqG)\n\ttt.Expect(t, \"1\", len(outputs1.Tokens))\n\ttt.Expect(t, \"1\", len(outputs2.Tokens))\n\ttt.Expect(t, \"google\", outputs1.Tokens[0])\n\ttt.Expect(t, \"google\", outputs2.Tokens[0])\n\n\toutDocs := outputs1.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\ttt.Expect(t, \"2\", len(outputs2.Docs.(types.ScoredDocs)))\n\n\tengine1.Close()\n\tengine2.Close()\n}\n\nfunc TestRiotGse(t *testing.T) {\n\tvar engine, engine1 Engine\n\tengine.Init(types.EngineOpts{\n\t\tUsing: 1,\n\t})\n\n\tAddDocs(&engine)\n\n\tengine1.Init(types.EngineOpts{\n\t\tUsing:   1,\n\t\tGseMode: true,\n\t})\n\n\tAddDocs(&engine1)\n\ttt.Equal(t, \"[《 复仇者 联盟 3 ： 无限 战争 》 是 全片 使用 IMAX 摄影机 拍摄]\",\n\t\tengine.Segment(\"《复仇者联盟3：无限战争》是全片使用IMAX摄影机拍摄\"))\n\ttt.Equal(t, \"[此次 Google 收购 将 成 世界 互联 联网 互联网 最大 并购]\",\n\t\tengine1.Segment(\"此次Google收购将成世界互联网最大并购\"))\n\n\tengine.Close()\n\tengine1.Close()\n}\n\nfunc TestSearchLogic(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(testJPOpts(0))\n\n\tAddDocs(&engine)\n\n\tengine.Index(\"7\", types.DocData{\n\t\tContent: textJP1,\n\t\tFields:  score1,\n\t})\n\n\ttokenDatas := tokenData()\n\tengine.Index(\"8\", types.DocData{\n\t\tContent: text1,\n\t\tTokens:  tokenDatas,\n\t\tFields:  score1,\n\t})\n\n\tengine.Index(\"9\", types.DocData{\n\t\tContent: text1,\n\t\tFields:  score1,\n\t})\n\n\tengine.Index(\"10\", types.DocData{\n\t\tContent: \"Hello, 你好世界!\",\n\t\tTokens: []types.TokenData{{\n\t\t\t\"世界\",\n\t\t\t[]int{2, 3},\n\t\t}},\n\t\tFields: score091,\n\t})\n\n\tengine.Flush()\n\n\tdocIds := make(map[string]bool)\n\tfor index := 0; index < 10; index++ {\n\t\tdocIds[strconv.Itoa(index)] = true\n\t}\n\n\tstrArr := []string{\"こんにちは\"}\n\tlogic := types.Logic{\n\t\tShould: true,\n\t\tExpr: types.Expr{\n\t\t\tNotIn: strArr,\n\t\t},\n\t}\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   textJP,\n\t\tDocIds: docIds,\n\t\tLogic:  logic,\n\t})\n\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"こんにちは\", outputs.Tokens[0])\n\ttt.Expect(t, \"世界\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\tlog.Println(\"outputs docs...\", outDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\ttt.Expect(t, \"10\", outDocs[0].DocId)\n\ttt.Expect(t, \"1000\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[]\", outDocs[0].TokenSnippetLocs)\n\n\ttt.Expect(t, \"9\", outDocs[1].DocId)\n\ttt.Expect(t, \"1000\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[]\", outDocs[1].TokenSnippetLocs)\n\n\tengine.Close()\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "geo",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 2.46875,
          "content": "module github.com/go-ego/riot\n\ngo 1.13\n\nrequire (\n\tgithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96 // indirect\n\tgithub.com/StackExchange/wmi v0.0.0-20190523213315-cbe66965904d // indirect\n\tgithub.com/coreos/bbolt v1.3.3 // indirect\n\tgithub.com/coreos/go-systemd/v22 v22.0.0 // indirect\n\tgithub.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f // indirect\n\tgithub.com/dgraph-io/badger v1.6.1\n\tgithub.com/dgrijalva/jwt-go v3.2.0+incompatible // indirect\n\tgithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 // indirect\n\tgithub.com/go-ego/gpy v0.31.0\n\tgithub.com/go-ego/gse v0.50.3\n\tgithub.com/go-ego/murmur v0.10.0\n\tgithub.com/go-ole/go-ole v1.2.4 // indirect\n\tgithub.com/go-vgo/grpclb v0.0.0-20181128171039-89526b0a742e\n\tgithub.com/go-vgo/gt v0.20.0 // indirect\n\tgithub.com/go-vgo/gt/conf v0.0.0-20200606140533-a397c46789df\n\tgithub.com/go-vgo/gt/info v0.0.0-20200606140533-a397c46789df\n\tgithub.com/go-vgo/zlog v0.0.0-20200606142114-9aade0d23ce3\n\tgithub.com/gogo/protobuf v1.2.1\n\tgithub.com/golang/groupcache v0.0.0-20191027212112-611e8accdfc9 // indirect\n\tgithub.com/golang/protobuf v1.4.2 // indirect\n\tgithub.com/golang/snappy v0.0.1 // indirect\n\tgithub.com/google/btree v1.0.0 // indirect\n\tgithub.com/gorilla/websocket v1.4.1 // indirect\n\tgithub.com/grpc-ecosystem/go-grpc-middleware v1.1.0 // indirect\n\tgithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0 // indirect\n\tgithub.com/grpc-ecosystem/grpc-gateway v1.12.1 // indirect\n\tgithub.com/jonboulle/clockwork v0.1.0 // indirect\n\tgithub.com/onsi/ginkgo v1.8.0 // indirect\n\tgithub.com/onsi/gomega v1.5.0 // indirect\n\tgithub.com/pelletier/go-toml v1.8.0 // indirect\n\tgithub.com/pkg/errors v0.9.1 // indirect\n\tgithub.com/prometheus/client_golang v1.2.1 // indirect\n\tgithub.com/prometheus/client_model v0.0.0-20191202183732-d1d2010b5bee // indirect\n\tgithub.com/shirou/gopsutil v2.20.5+incompatible\n\tgithub.com/soheilhy/cmux v0.1.4 // indirect\n\tgithub.com/syndtr/goleveldb v1.0.0\n\tgithub.com/tmc/grpc-websocket-proxy v0.0.0-20190109142713-0ad062ec5ee5 // indirect\n\tgithub.com/vcaesar/tt v0.10.0\n\tgithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2 // indirect\n\tgo.etcd.io/bbolt v1.3.4\n\tgolang.org/x/net v0.0.0-20200602114024-627f9648deb9\n\tgolang.org/x/sys v0.0.0-20200610111108-226ff32320da // indirect\n\tgolang.org/x/text v0.3.2 // indirect\n\tgolang.org/x/time v0.0.0-20191024005414-555d28b269f0 // indirect\n\tgoogle.golang.org/grpc v1.27.0\n\tgoogle.golang.org/protobuf v1.24.0 // indirect\n\tgopkg.in/natefinch/lumberjack.v2 v2.0.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 38.107421875,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190306092124-e2d15f34fcf9 h1:HD8gA2tkByhMAwYaFAX9w2l7vxvBQ5NMoxDrkhqhtn4=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190306092124-e2d15f34fcf9/go.mod h1:bOvUY6CB00SOBii9/FifXqc0awNKxLFCL/+pkDPuyl8=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96 h1:cTp8I5+VIoKjsnZuH8vjyaysT/ses3EvZeaV/1UkF2M=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96/go.mod h1:bOvUY6CB00SOBii9/FifXqc0awNKxLFCL/+pkDPuyl8=\ngithub.com/BurntSushi/toml v0.3.1 h1:WXkYYl6Yr3qBf1K79EBnL4mak0OimBfB0XUf9Vl28OQ=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/OneOfOne/xxhash v1.2.2 h1:KMrpdQIwFcEqXDklaen+P1axHaj9BSKzvpUUfnHldSE=\ngithub.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=\ngithub.com/StackExchange/wmi v0.0.0-20180116203802-5d049714c4a6/go.mod h1:3eOhrUMpNV+6aFIbp5/iudMxNCF27Vw2OZgy4xEx0Fg=\ngithub.com/StackExchange/wmi v0.0.0-20180725035823-b12b22c5341f/go.mod h1:3eOhrUMpNV+6aFIbp5/iudMxNCF27Vw2OZgy4xEx0Fg=\ngithub.com/StackExchange/wmi v0.0.0-20190523213315-cbe66965904d h1:G0m3OIz70MZUWq3EgK3CesDbo8upS2Vm9/P3FtgI+Jk=\ngithub.com/StackExchange/wmi v0.0.0-20190523213315-cbe66965904d/go.mod h1:3eOhrUMpNV+6aFIbp5/iudMxNCF27Vw2OZgy4xEx0Fg=\ngithub.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190717042225-c3de453c63f4/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/antihax/optional v0.0.0-20180407024304-ca021399b1a6/go.mod h1:V8iCPQYkqmusNa815XgQio277wI47sdRh1dUOLdyC6Q=\ngithub.com/armon/consul-api v0.0.0-20180202201655-eb2c6b5be1b6/go.mod h1:grANhF5doyWs3UAsr3K4I6qtAmlQcZDesFNEHPZAzj8=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash v1.1.0 h1:a6HrQnmkObjyL+Gs60czilIUGqrzKutQD6XZog3p+ko=\ngithub.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=\ngithub.com/cespare/xxhash/v2 v2.1.0 h1:yTUvW7Vhb89inJ+8irsUqiWjh8iT6sQPZiQzI6ReGkA=\ngithub.com/cespare/xxhash/v2 v2.1.0/go.mod h1:dgIUBU3pDso/gPgZ1osOZ0iQf77oPR28Tjxl5dIMyVM=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/coreos/bbolt v1.3.3 h1:n6AiVyVRKQFNb6mJlwESEvvLoDyiTzXX7ORAUlkeBdY=\ngithub.com/coreos/bbolt v1.3.3/go.mod h1:iRUV2dpdMOn7Bo10OQBFzIJO9kkE559Wcmn+qkEiiKk=\ngithub.com/coreos/etcd v3.3.10+incompatible h1:jFneRYjIvLMLhDLCzuTuU4rSJUjRplcJQ7pD7MnhC04=\ngithub.com/coreos/etcd v3.3.10+incompatible/go.mod h1:uF7uidLiAD3TWHmW31ZFd/JWoc32PjwdhPthX9715RE=\ngithub.com/coreos/go-etcd v2.0.0+incompatible/go.mod h1:Jez6KQU2B/sWsbdaef3ED8NzMklzPG4d5KIOhIy30Tk=\ngithub.com/coreos/go-semver v0.2.0 h1:3Jm3tLmsgAYcjC+4Up7hJrFBPr+n7rAqYeSw/SZazuY=\ngithub.com/coreos/go-semver v0.2.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=\ngithub.com/coreos/go-systemd/v22 v22.0.0/go.mod h1:xO0FLkIi5MaZafQlIrOotqXZ90ih+1atmu1JpKERPPk=\ngithub.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f h1:lBNOc5arjvs8E5mO2tbpBpLoyyu8B6e44T7hJy6potg=\ngithub.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=\ngithub.com/cpuguy83/go-md2man v1.0.10/go.mod h1:SmD6nW6nTyfqj6ABTjUi3V3JVMnlJmwcJI5acqYI6dE=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dgraph-io/badger v1.6.0 h1:DshxFxZWXUcO0xX476VJC07Xsr6ZCBVRHKZ93Oh7Evo=\ngithub.com/dgraph-io/badger v1.6.0/go.mod h1:zwt7syl517jmP8s94KqSxTlM6IMsdhYy6psNgSztDR4=\ngithub.com/dgraph-io/badger v1.6.1 h1:w9pSFNSdq/JPM1N12Fz/F/bzo993Is1W+Q7HjPzi7yg=\ngithub.com/dgraph-io/badger v1.6.1/go.mod h1:FRmFw3uxvcpa8zG3Rxs0th+hCLIuaQg8HlNV5bjgnuU=\ngithub.com/dgraph-io/ristretto v0.0.2 h1:a5WaUrDa0qm0YrAAS1tUykT5El3kt62KNZZeMxQn3po=\ngithub.com/dgraph-io/ristretto v0.0.2/go.mod h1:KPxhHT9ZxKefz+PCeOGsrHpl1qZ7i70dGTu2u+Ahh6E=\ngithub.com/dgrijalva/jwt-go v3.2.0+incompatible h1:7qlOGliEKZXTDg6OTjfoBKDXWrumCAMpl/TFQ4/5kLM=\ngithub.com/dgrijalva/jwt-go v3.2.0+incompatible/go.mod h1:E3ru+11k8xSBh+hMPgOLZmtrrCbhqsmaPHjLKYnJCaQ=\ngithub.com/dgryski/go-farm v0.0.0-20190423205320-6a90982ecee2 h1:tdlZCpZ/P9DhczCTSixgIKmwPv6+wP5DGjqLYw5SUiA=\ngithub.com/dgryski/go-farm v0.0.0-20190423205320-6a90982ecee2/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dgryski/go-farm v0.0.0-20191112170834-c2139c5d712b h1:SeiGBzKrEtuDddnBABHkp4kq9sBGE9nuYmk6FPTg0zg=\ngithub.com/dgryski/go-farm v0.0.0-20191112170834-c2139c5d712b/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 h1:fAjc9m62+UWV/WAFKLNi6ZS0675eEUC9y3AlwSbQu1Y=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dustin/go-humanize v1.0.0 h1:VSnTsYCnlFHaM2/igO1h6X3HA71jcobQuxemgkq4zYo=\ngithub.com/dustin/go-humanize v1.0.0/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/fsnotify/fsnotify v1.4.7 h1:IXs+QLmnXW2CcXuY+8Mzv/fWEsPGWxqefPtCP5CnV9I=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.9 h1:hsms1Qyu0jgnwNXIxa+/V/PDsU6CfLf6CNO8H7IWoS4=\ngithub.com/fsnotify/fsnotify v1.4.9/go.mod h1:znqG4EE+3YCdAaPaxE2ZRY/06pZUdp0tY4IgpuI1SZQ=\ngithub.com/ghodss/yaml v1.0.0 h1:wQHKEahhL6wmXdzwWG11gIVCkOv05bNOh+Rxn0yngAk=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/go-ego/cedar v0.0.0-20191026170511-cf63283d1a1d/go.mod h1:2tj8NEwz6OsMT56YhN7mL7dYCncJs7dOmz/Xki1ofCU=\ngithub.com/go-ego/cedar v0.0.0-20191129121850-43a3778f11e4 h1:FjeZ5bryMJYMG5L7CX3YjlZWJnMSPfcEXU3WFQSXn3U=\ngithub.com/go-ego/cedar v0.0.0-20191129121850-43a3778f11e4/go.mod h1:fEBCL8k9n1uTGCgRVWR/ANO+13P6wx6l9Q1tCKLzqIw=\ngithub.com/go-ego/cedar v0.10.0 h1:422oGVkurGN2JZ0kiOev4hF6gsQULbePfjQIB4JHl8M=\ngithub.com/go-ego/cedar v0.10.0/go.mod h1:DPGtR4K0NDHs/TlwrY063w9Mx1o8+OBegu+nINLhP84=\ngithub.com/go-ego/gpy v0.0.0-20191128165300-d7ffd622e115 h1:a/VNeZI9+jEhqhxcLXkew3bHWsJUHvi1PEyCAg7lfCs=\ngithub.com/go-ego/gpy v0.0.0-20191128165300-d7ffd622e115/go.mod h1:XHtccmBUOwbRnjkNY/vOijl/XnNIvBH8d6gTUKWYwhA=\ngithub.com/go-ego/gpy v0.31.0 h1:A8AByouCkPQd8HW9tbPgSU6t7G5FNa9inWtcsWp49tw=\ngithub.com/go-ego/gpy v0.31.0/go.mod h1:ZVApRKPCwHXFSgdJSLcUL+wbEPnK91MZQzxkKPHH3nY=\ngithub.com/go-ego/gse v0.0.0-20191212182315-b30156ea952e h1:Y3PLgnqXxfnAJA1myyb2W8KHpLUqcR9HOGDTgEYoU1U=\ngithub.com/go-ego/gse v0.0.0-20191212182315-b30156ea952e/go.mod h1:CEs4Qx+i8pnxDPG0Tlbb1GqVI4NxCbgNHcy+lQiDyTQ=\ngithub.com/go-ego/gse v0.50.3 h1:bzQiq6DyKgXaTiym3hOkBmr2FOtZdMHiHRUoT1aMsvA=\ngithub.com/go-ego/gse v0.50.3/go.mod h1:YA6Poe9bIZUJYtSmzHPZ7tqj2Z7Hk8lo8kKETnCxMXQ=\ngithub.com/go-ego/murmur v0.0.0-20191001133222-eab2da088fb4 h1:9MiRSwErSh7DPk2M0LErU89FW4WNZokN4sTQ+fhwfc0=\ngithub.com/go-ego/murmur v0.0.0-20191001133222-eab2da088fb4/go.mod h1:lU1gHnF7CmWCb66VY6nH4NsCavMUA4ESUMAE9iO5FSY=\ngithub.com/go-ego/murmur v0.10.0 h1:n4AvncV+xqShlqNMvCUwIn00/SvIilcpsCZBOVS5FAc=\ngithub.com/go-ego/murmur v0.10.0/go.mod h1:3totV5vjjhL8PklmyrbKawM/QNRKrE72vfRAEmD1t3g=\ngithub.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.9.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=\ngithub.com/go-logfmt/logfmt v0.4.0/go.mod h1:3RMwSq7FuexP4Kalkev3ejPJsZTpXXBr9+V4qmtdjCk=\ngithub.com/go-ole/go-ole v1.2.1/go.mod h1:7FAglXiTm7HKlQRDeOQ6ZNUHidzCWXuZWq/1dTyBNF8=\ngithub.com/go-ole/go-ole v1.2.4 h1:nNBDSCOigTSiarFpYE9J/KtEA1IOW4CNeqT9TQDqCxI=\ngithub.com/go-ole/go-ole v1.2.4/go.mod h1:XCwSNxSkXRo4vlyPy93sltvi/qJq0jqQhjqQNIwKuxM=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/go-vgo/grpclb v0.0.0-20181128171039-89526b0a742e h1:tWgVtSQeg8f4cVBwHKH5q5saPMZNRvR5GSOx+ytAe9g=\ngithub.com/go-vgo/grpclb v0.0.0-20181128171039-89526b0a742e/go.mod h1:RLBU+1pK/TEou3dxzHEhdxhgwuSFTq8UYahALbc6tN4=\ngithub.com/go-vgo/gt v0.0.0-20191129122048-b43b4ceeec26 h1:r6LQVeALyMwvQv9VEbOiXbYoqQNxDtWfOpbUohptyrw=\ngithub.com/go-vgo/gt v0.0.0-20191129122048-b43b4ceeec26/go.mod h1:nOd/5lXyOr4ILPGo4nO6iEgKxb8v++eaZPDLb29KooE=\ngithub.com/go-vgo/gt v0.20.0 h1:Yj5OZ0JtOxoPgV0jG77i+GNIHbWo1AhagvayRbHx6S4=\ngithub.com/go-vgo/gt v0.20.0/go.mod h1:UuZqSKlavn1bytrdx/cnbnwUBsJ3HBt0vpMHYdo49lM=\ngithub.com/go-vgo/gt/conf v0.0.0-20190822172343-e8dae7b097a1/go.mod h1:YWt7auzuo/LKrRh82hRFvmoXRSrCjgITXPbpgjM+sMo=\ngithub.com/go-vgo/gt/conf v0.0.0-20191129122048-b43b4ceeec26 h1:SQtIeXQn3NIEyqldM1dzGN3C/kf8PBsdo79gkTpPD3o=\ngithub.com/go-vgo/gt/conf v0.0.0-20191129122048-b43b4ceeec26/go.mod h1:Ba0HbzBCvoeeYe9/gkghpwz913uTgJg49+26G6wbV4c=\ngithub.com/go-vgo/gt/conf v0.0.0-20200606140533-a397c46789df h1:shJeNwLPXz6yfhpQm8OOJS4R9HbQQ7JXDKQRxAptpE0=\ngithub.com/go-vgo/gt/conf v0.0.0-20200606140533-a397c46789df/go.mod h1:MHs4G2Hbf6Cyl7POO3+MCEg4VJ92v68GwibmUACCjgU=\ngithub.com/go-vgo/gt/info v0.0.0-20200606140533-a397c46789df h1:ULtirwL4ObVnO6CrcLagDDk6k/GdB/QgHtxbd9xO13M=\ngithub.com/go-vgo/gt/info v0.0.0-20200606140533-a397c46789df/go.mod h1:oNEHyJBeLzb115lhNoO8XkhkgbXmw9wxF0uU6Jshun8=\ngithub.com/go-vgo/zlog v0.0.0-20200606142114-9aade0d23ce3 h1:2HUWQ9lbNl5i21Rxb+7ssnZ6z+zB5UYuywa+vhyGCE0=\ngithub.com/go-vgo/zlog v0.0.0-20200606142114-9aade0d23ce3/go.mod h1:ZGTLsWVYOOIAzYOYX/KNXrH7XuSxbNNORQ2BvaJcMc0=\ngithub.com/godbus/dbus/v5 v5.0.3/go.mod h1:xhWf0FNVPg57R7Z0UbKHbJfkEywrmjJnf7w5xrFpKfA=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/gogo/protobuf v1.2.1 h1:/s5zKNz0uPFCZ5hddgPdo2TK2TVrUNMn0OOX8/aZMTE=\ngithub.com/gogo/protobuf v1.2.1/go.mod h1:hp+jE20tsWTFYpLwKvXlhS1hjn+gTNwPg2I6zVXpSg4=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b h1:VKtxabqXZkF25pY9ekfRL6a582T4P37/31XEstQ5p58=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/groupcache v0.0.0-20191027212112-611e8accdfc9 h1:uHTyIjqVhYRhLbJ8nIiOJHkEZZ+5YoOsAbD3sk82NiE=\ngithub.com/golang/groupcache v0.0.0-20191027212112-611e8accdfc9/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/lint v0.0.0-20180702182130-06c8688daad7/go.mod h1:tluoj9z5200jBnyusfRPU2LqT6J+DAorxEvtC7LHB+E=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2 h1:6nsPYzhq5kReh6QImI3k5qWzO4PEbvbIW2cwSfR/6xs=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2 h1:+Z5KGCizgyZCbGh1KZqA0fcLLkwbsjIzS4aV2v7wJX0=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/snappy v0.0.0-20180518054509-2e65f85255db h1:woRePGFeVFfLKN/pOkfl+p/TAqKOfFu+7KPlMVpok/w=\ngithub.com/golang/snappy v0.0.0-20180518054509-2e65f85255db/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.1 h1:Qgr9rKW7uDUkrbSmQeiDsGa8SjGyCOGtuasMWwvp2P4=\ngithub.com/golang/snappy v0.0.1/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/btree v1.0.0 h1:0udJVsspx3VBr5FwtLhQQtuAsVc79tTq0ocGIPAU6qo=\ngithub.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0 h1:crn/baboCvb5fXaQ0IJ1SGTsTVrWpDsCWC8EGETZijY=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0 h1:xsAVV57WRhGj6kEIi8ReJzQlHHqcBYCElAvkovg3B/4=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/gorilla/websocket v1.4.1 h1:q7AeDBpnBk8AogcD4DSag/Ukw/KV+YhzLj2bP5HvKCM=\ngithub.com/gorilla/websocket v1.4.1/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.1.0 h1:THDBEeQ9xZ8JEaCLyLQqXMMdRqNr0QAUJTIkQAUtFjg=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.1.0/go.mod h1:f5nM7jw/oeRSadq3xCzHAvxcr8HZnzsqU6ILg/0NiiE=\ngithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0 h1:Ovs26xHkKqVztRpIrF/92BcuyuQ/YW4NSIpoGtfXNho=\ngithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0/go.mod h1:8NvIoxWQoOIhqOTXgfV/d3M/q6VIi02HzZEHgUlZvzk=\ngithub.com/grpc-ecosystem/grpc-gateway v1.12.1 h1:zCy2xE9ablevUOrUZc3Dl72Dt+ya2FNAvC2yLYMHzi4=\ngithub.com/grpc-ecosystem/grpc-gateway v1.12.1/go.mod h1:8XEsbTttt/W+VvjtQhLACqCisSPWTxCZ7sBRjU6iH9c=\ngithub.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=\ngithub.com/hpcloud/tail v1.0.0 h1:nfCOvKYfkgYP8hkirhJocXT2+zOD8yUNjXaWfTlyFKI=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=\ngithub.com/jinzhu/now v0.0.0-20181116074157-8ec929ed50c3/go.mod h1:oHTiXerJ20+SfYcrdlBO7rzZRJWGwSTQ0iUY2jI6Gfc=\ngithub.com/jinzhu/now v1.1.1/go.mod h1:d3SSVoowX0Lcu0IBviAWJpolVfI5UJVZZ7cO71lE/z8=\ngithub.com/jonboulle/clockwork v0.1.0 h1:VKV+ZcuP6l3yW9doeqz6ziZGgcynBVQO+obU0+0hcPo=\ngithub.com/jonboulle/clockwork v0.1.0/go.mod h1:Ii8DK3G1RaLaWxj9trq07+26W01tbo22gdxWY5EU2bo=\ngithub.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=\ngithub.com/json-iterator/go v1.1.7/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/kisielk/errcheck v1.1.0/go.mod h1:EZBBE59ingxPouuu3KfxchcWSUPOHkagtvWXihfKN4Q=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1 h1:mweAR1A6xJ3oS2pRaGiHgQ4OO8tzTaLawm8vnODuwDk=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=\ngithub.com/kr/pretty v0.1.0 h1:L/CwN0zerZDmRFUapSPitk6f+Q3+0za1rQkzVuMiMFI=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.0 h1:s5hAObm+yFO5uHYt5dYjxi2rXrsnmRpJx4OYvIWUaQs=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/magiconair/properties v1.8.0/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1 h1:4hp9jkHxhMHkqkrB3Ix0jegS5sx/RkqARlsWZ6pIwiU=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=\ngithub.com/mitchellh/mapstructure v1.1.2/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v0.0.0-20180701023420-4b7aa43c6742/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.7.0 h1:WSHQ+IS43OoUrWtD1/bbclrwK8TTH5hzp+umCiuxHgs=\ngithub.com/onsi/ginkgo v1.7.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.8.0 h1:VkHVNpR4iVnU8XQR6DBm8BqYjN7CRzw+xKUbVVbbW9w=\ngithub.com/onsi/ginkgo v1.8.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/gomega v1.4.3 h1:RE1xgDvH7imwFD45h+u2SgIfERHlS2yNG4DObb5BSKU=\ngithub.com/onsi/gomega v1.4.3/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/onsi/gomega v1.5.0 h1:izbySO9zDPmjJ8rDjLvkA2zJHIo+HkYXHnf7eN7SSyo=\ngithub.com/onsi/gomega v1.5.0/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/opentracing/opentracing-go v1.1.0/go.mod h1:UkNAQd3GIcIGf0SeVgPpRdFStlNbqXla1AfSYxPUl2o=\ngithub.com/pelletier/go-toml v1.2.0/go.mod h1:5z9KED0ma1S8pY6P1sdut58dfprrGBbd/94hg7ilaic=\ngithub.com/pelletier/go-toml v1.3.0/go.mod h1:PN7xzY2wHTK0K9p34ErDQMlFxa51Fk0OUruD3k1mMwo=\ngithub.com/pelletier/go-toml v1.4.0/go.mod h1:PN7xzY2wHTK0K9p34ErDQMlFxa51Fk0OUruD3k1mMwo=\ngithub.com/pelletier/go-toml v1.6.0 h1:aetoXYr0Tv7xRU/V4B4IZJ2QcbtMUFoNb3ORp7TzIK4=\ngithub.com/pelletier/go-toml v1.6.0/go.mod h1:5N711Q9dKgbdkxHL+MEfF31hpT7l0S0s/t2kKREewys=\ngithub.com/pelletier/go-toml v1.7.0/go.mod h1:vwGMzjaWMwyfHwgIBhI2YUM4fB6nL6lVAvS1LBMMhTE=\ngithub.com/pelletier/go-toml v1.8.0 h1:Keo9qb7iRJs2voHvunFtuuYFsbWeOBh8/P9v/kVMFtw=\ngithub.com/pelletier/go-toml v1.8.0/go.mod h1:D6yutnOGMveHEPV7VQOuvI/gXY61bv+9bAOTRnLElKs=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.8.1 h1:iURUrRGxPUNPdy5/HRSm+Yj6okJ6UtLINN0Q9M4+h3I=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v1.0.0/go.mod h1:db9x61etRT2tGnBNRi70OPL5FsnadC4Ky3P0J6CfImo=\ngithub.com/prometheus/client_golang v1.2.1 h1:JnMpQc6ppsNgw9QPAGF6Dod479itz7lvlsMzzNayLOI=\ngithub.com/prometheus/client_golang v1.2.1/go.mod h1:XMU6Z2MjaRKVu/dC1qupJI9SiNkDYzz3xecMgSW/F+U=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.0.0-20191202183732-d1d2010b5bee h1:iBZPTYkGLvdu6+A5TsMUJQkQX9Ad4aCEnSQtdxPuTCQ=\ngithub.com/prometheus/client_model v0.0.0-20191202183732-d1d2010b5bee/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/common v0.4.1/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.7.0 h1:L+1lyG48J1zAQXA3RBX/nG/B3gjlHq0zTt2tlbJLyCY=\ngithub.com/prometheus/common v0.7.0/go.mod h1:DjGbpBbp5NYNiECxcL/VnbXCCaQpKd3tt26CguLLsqA=\ngithub.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.2/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.0.5 h1:3+auTFlqw+ZaQYJARz6ArODtkaIwtvBTx3N2NehQlL8=\ngithub.com/prometheus/procfs v0.0.5/go.mod h1:4A/X28fw3Fc593LaREMrKMqOKvUAntwMDaekg4FpcdQ=\ngithub.com/rogpeppe/fastuuid v1.2.0/go.mod h1:jVj6XXZzXRy/MSR5jhDC/2q6DgLz+nrA6LYCDYWNEvQ=\ngithub.com/russross/blackfriday v1.5.2/go.mod h1:JO/DiYxRf+HjHt06OyowR9PTA263kcR/rfWxYHBV53g=\ngithub.com/shirou/gopsutil v2.18.10+incompatible/go.mod h1:5b4v6he4MtMOwMlS0TUMTu2PcXUg8+E1lC7eC3UO/RA=\ngithub.com/shirou/gopsutil v2.19.6+incompatible/go.mod h1:WWnYX4lzhCH5h/3YBfyVA3VbLYjlMZZAQcW9ojMexNc=\ngithub.com/shirou/gopsutil v2.19.11+incompatible h1:lJHR0foqAjI4exXqWsU3DbH7bX1xvdhGdnXTIARA9W4=\ngithub.com/shirou/gopsutil v2.19.11+incompatible/go.mod h1:5b4v6he4MtMOwMlS0TUMTu2PcXUg8+E1lC7eC3UO/RA=\ngithub.com/shirou/gopsutil v2.20.5+incompatible h1:tYH07UPoQt0OCQdgWWMgYHy3/a9bcxNpBIysykNIP7I=\ngithub.com/shirou/gopsutil v2.20.5+incompatible/go.mod h1:5b4v6he4MtMOwMlS0TUMTu2PcXUg8+E1lC7eC3UO/RA=\ngithub.com/shirou/w32 v0.0.0-20160930032740-bb4de0191aa4 h1:udFKJ0aHUL60LboW/A+DfgoHVedieIzIXE8uylPue0U=\ngithub.com/shirou/w32 v0.0.0-20160930032740-bb4de0191aa4/go.mod h1:qsXQc7+bwAM3Q1u/4XEfrquwF8Lw7D7y5cD8CuHnfIc=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/sirupsen/logrus v1.4.2 h1:SPIRibHv4MatM3XXNO2BJeFLZwZ2LvZgfQ5+UNI2im4=\ngithub.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\ngithub.com/soheilhy/cmux v0.1.4 h1:0HKaf1o97UwFjHH9o5XsHUOF+tqmdA7KEzXLpiyaw0E=\ngithub.com/soheilhy/cmux v0.1.4/go.mod h1:IM3LyeVVIOuxMH7sFAkER9+bJ4dT7Ms6E4xg4kGIyLM=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spaolacci/murmur3 v1.1.0 h1:7c1g84S4BPRrfL5Xrdp6fOJ206sU9y293DDHaoy0bLI=\ngithub.com/spaolacci/murmur3 v1.1.0/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spf13/afero v1.1.2/go.mod h1:j4pytiNVoe2o6bmDsKpLACNPDBIoEAkihy7loJ1B0CQ=\ngithub.com/spf13/cast v1.3.0/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=\ngithub.com/spf13/cobra v0.0.5/go.mod h1:3K3wKZymM7VvHMDS9+Akkh4K60UwM26emMESw8tLCHU=\ngithub.com/spf13/jwalterweatherman v1.0.0/go.mod h1:cQK4TGJAtQXfYWX+Ddv3mKDzgVb68N+wFjFa4jdeBTo=\ngithub.com/spf13/pflag v1.0.3/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/viper v1.3.2/go.mod h1:ZiWeW+zYFKm7srdB9IoDzzZXaJaI5eL9QjNiN/DMA2s=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0 h1:2E4SXV/wtOkTonXsotYi4li6zVWxYlZuYNCXe9XRJyk=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/syndtr/goleveldb v1.0.0 h1:fBdIW9lB4Iz0n9khmH8w27SJ3QEJ7+IgjPEwGSZiFdE=\ngithub.com/syndtr/goleveldb v1.0.0/go.mod h1:ZVVdQEZoIme9iO1Ch2Jdy24qqXrMMOU6lpPAyBWyWuQ=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20190109142713-0ad062ec5ee5 h1:LnC5Kc/wtumK+WB441p7ynQJzVuNRJiqddSIE3IlSEQ=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20190109142713-0ad062ec5ee5/go.mod h1:ncp9v5uamzpCO7NfCPTXjqaC+bZgJeR0sMTm6dMHP7U=\ngithub.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8 h1:3SVOIvH7Ae1KRYyQWRjXWJEA9sS/c/pjvH++55Gr648=\ngithub.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8/go.mod h1:VFNgLljTbGfSG7qAOspJ7OScBnGdDN/yBr0sguwnwf0=\ngithub.com/vcaesar/tt v0.0.0-20181105181427-53fc2b08e954/go.mod h1:xKkGp+ufbz/1DQmNxdbAMFqZJOVIJEX7dGvLZMhPIWg=\ngithub.com/vcaesar/tt v0.0.0-20190922170245-9d197389a6ac/go.mod h1:xKkGp+ufbz/1DQmNxdbAMFqZJOVIJEX7dGvLZMhPIWg=\ngithub.com/vcaesar/tt v0.0.0-20191103173835-6896a351024b h1:psGhQitWSo4KBpLghvJPlhHxTJ8LQl1y0ekjSreqvu4=\ngithub.com/vcaesar/tt v0.0.0-20191103173835-6896a351024b/go.mod h1:GHPxQYhn+7OgKakRusH7KJ0M5MhywoeLb8Fcffs/Gtg=\ngithub.com/vcaesar/tt v0.0.0-20191220180712-e14ab9e55f21/go.mod h1:GHPxQYhn+7OgKakRusH7KJ0M5MhywoeLb8Fcffs/Gtg=\ngithub.com/vcaesar/tt v0.10.0 h1:jPtFiRRnCOXVakd5ujCed2dwWwTs91wh8W1iHeUIfc0=\ngithub.com/vcaesar/tt v0.10.0/go.mod h1:GHPxQYhn+7OgKakRusH7KJ0M5MhywoeLb8Fcffs/Gtg=\ngithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2 h1:eY9dn8+vbi4tKz5Qo6v2eYzo7kUS51QINcR5jNpbZS8=\ngithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2/go.mod h1:UETIi67q53MR2AWcXfiuqkDkRtnGDLqkBTpCHuJHxtU=\ngithub.com/xordataexchange/crypt v0.0.3-0.20170626215501-b2862e3d0a77/go.mod h1:aYKd//L2LvnjZzWKhF00oedf4jCCReLcmhLdhm1A27Q=\ngo.etcd.io/bbolt v1.3.3 h1:MUGmc65QhB3pIlaQ5bB4LwqSj6GIonVJXpZiaKNyaKk=\ngo.etcd.io/bbolt v1.3.3/go.mod h1:IbVyRI1SCnLcuJnV2u8VeU0CEYM7e686BmAb1XKL+uU=\ngo.etcd.io/bbolt v1.3.4 h1:hi1bXHMVrlQh6WwxAy+qZCV/SYIlqo+Ushwdpa4tAKg=\ngo.etcd.io/bbolt v1.3.4/go.mod h1:G5EMThwa9y8QZGBClrRx5EY+Yw9kAhnjy3bSjsnlVTQ=\ngo.etcd.io/etcd v3.3.10+incompatible h1:qXVcIR1kU3CYLD8zXDseOmBNwg0uaui53e4Wg4uj0rk=\ngo.etcd.io/etcd v3.3.10+incompatible/go.mod h1:yaeTdrJi5lOmYerz05bd8+V7KubZs8YSFZfzsF9A6aI=\ngo.uber.org/atomic v1.4.0 h1:cxzIVoETapQEqDhQu3QfnvXAV4AlzcvUCxkVUFw3+EU=\ngo.uber.org/atomic v1.4.0/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngo.uber.org/multierr v1.1.0 h1:HoEmRHQPVSqub6w2z2d2EOVs2fjyFRGyofhKuyDq0QI=\ngo.uber.org/multierr v1.1.0/go.mod h1:wR5kodmAFQ0UK8QlbwjlSNy0Z68gJhDJUG5sjR94q/0=\ngo.uber.org/zap v1.10.0 h1:ORx85nbTijNz8ljznvCMR1ZBIPKFn3jQrag10X2AsuM=\ngo.uber.org/zap v1.10.0/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2 h1:VklqNMn3ovrHsnt90PveolxSbWFaJdECFbxSq0Mqo2M=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190911031432-227b76d455e7 h1:0hQKqeLdqlt5iIwVOBErRisrHJAN57yOiPRQItI20fU=\ngolang.org/x/crypto v0.0.0-20190911031432-227b76d455e7/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200604202706-70a84ac30bf9 h1:vEg9joUBmeBcK9iSJftGNf3coIG4HqZElCPehJsfAYM=\ngolang.org/x/crypto v0.0.0-20200604202706-70a84ac30bf9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/lint v0.0.0-20180702182130-06c8688daad7/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190613194153-d28f0bde5980/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191002035440-2ec189313ef0 h1:2mqDk8w/o6UmeUCu5Qiq2y7iMf6anbx+YA8d1JFoFrs=\ngolang.org/x/net v0.0.0-20191002035440-2ec189313ef0/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200602114024-627f9648deb9 h1:pNX+40auqi2JqRfOP1akLGtYcn15TUbkhwuCO3foqqM=\ngolang.org/x/net v0.0.0-20200602114024-627f9648deb9/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181205085412-a5c9d58dba9a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190626221950-04f50cda93cb/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190913121621-c3b328c6e5a7/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190916165910-8a69140bde95/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191010194322-b09406accb47/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191210023423-ac6580df4449 h1:gSbV7h1NRL2G1xTg/owz62CST1oJBmxy4QpMMregXVQ=\ngolang.org/x/sys v0.0.0-20191210023423-ac6580df4449/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191224085550-c709ea063b76/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200511232937-7e40ca221e25/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200610111108-226ff32320da h1:bGb80FudwxpeucJUjPYJXuJ8Hk91vNtfvrymzwiei38=\ngolang.org/x/sys v0.0.0-20200610111108-226ff32320da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/text v0.3.0 h1:g61tztE5qeGQ89tm6NTjjM9VPIm088od1l6aSorWRWg=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2 h1:tW2bmiBqwgJj/UpqtC8EpXEZVYOwU0yG4iWbprSVAcs=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/time v0.0.0-20191024005414-555d28b269f0 h1:/5xXl8Y5W96D+TtHSlonuFqGHIWVuyCkGJLwGh9JJFs=\ngolang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180221164845-07fd8470d635/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180828015842-6cd1fcedba52/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543 h1:E7g+9GITq07hpfrRu66IVDexMakfv52eLZ2CXBWiKr4=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8 h1:Nw54tB0rB7hY/N0NQvRW8DG4Yk3Q6T9cu9RcFQDu1tc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190927181202-20e1ac93f88c h1:hrpEMCZ2O7DR5gC1n2AJGVhrwiEjOi35+jxtIuZpTMo=\ngoogle.golang.org/genproto v0.0.0-20190927181202-20e1ac93f88c/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013 h1:+kGHl1aib/qcwaRi1CbqBZ1rk19r85MNUf8HaBghugY=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/grpc v1.16.0/go.mod h1:0JHn/cJsOMiMfNA9+DeHDlAU7KAAB5GDlYFpa9MZMio=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.24.0 h1:vb/1TCsVn3DcJlQ0Gs1yB1pKI6Do2/QNwxdKqmc/b0s=\ngoogle.golang.org/grpc v1.24.0/go.mod h1:XDChyiUovWa60DnaeDeZmSW86xtLtjtZbwvSiRnRtcA=\ngoogle.golang.org/grpc v1.27.0 h1:rRYRFMVgRv6E0D70Skyfsr28tDXIuuPZyWGMPdMcnXg=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0 h1:4MY060fB1DLGMB/7MBTLnwQUY6+F09GEiz6SsrNqyzM=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.24.0 h1:UhZDfRO8JRQru4/+LlLE0BRKGF8L+PICnvYZmx/fEGA=\ngoogle.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 h1:qIbj1fsPNlZgppZ+VLlY7N33q108Sa+fhmuc+sWQYwY=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15 h1:YR8cESwS4TdDjEe65xsg0ogRM/Nc3DYOhEAlW+xobZo=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/fsnotify.v1 v1.4.7 h1:xOHLXZwVvI9hhs+cLKq5+I5onOuwQLhQwiu63xxlHs4=\ngopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=\ngopkg.in/natefinch/lumberjack.v2 v2.0.0 h1:1Lc07Kr7qY4U2YPouBjpCLxpiyxIVoxqXgkXLknAOE8=\ngopkg.in/natefinch/lumberjack.v2 v2.0.0/go.mod h1:l0ndWWf7gzL7RNwBG7wST/UCcT4T24xpD6X8LsfU/+k=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 h1:uRGJdciOHaEIrze2W8Q3AKkepLTh2hOroT7a+7czfdQ=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4 h1:/eiJrUcujPVeJ3xlSWaiNi3uSVmDGBK1pDHUHAnao1I=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0 h1:clyUAQHOM3G0M3f5vQj7LuJrETvjVot3Z5el9nffUtU=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\nhonnef.co/go/tools v0.0.0-20180728063816-88497007e858/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\n"
        },
        {
          "name": "indexer_worker.go",
          "type": "blob",
          "size": 3.4609375,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"sync/atomic\"\n\n\t\"github.com/go-ego/riot/types\"\n)\n\ntype indexerAddDocReq struct {\n\tdoc         *types.DocIndex\n\tforceUpdate bool\n}\n\ntype indexerLookupReq struct {\n\tcountDocsOnly bool\n\ttokens        []string\n\tlabels        []string\n\n\tdocIds           map[string]bool\n\toptions          types.RankOpts\n\trankerReturnChan chan rankerReturnReq\n\torderless        bool\n\tlogic            types.Logic\n}\n\ntype indexerRemoveDocReq struct {\n\tdocId       string\n\tforceUpdate bool\n}\n\nfunc (engine *Engine) indexerAddDoc(shard int) {\n\tfor {\n\t\trequest := <-engine.indexerAddDocChans[shard]\n\t\tengine.indexers[shard].AddDocToCache(request.doc, request.forceUpdate)\n\t\tif request.doc != nil {\n\t\t\tatomic.AddUint64(&engine.numTokenIndexAdded,\n\t\t\t\tuint64(len(request.doc.Keywords)))\n\n\t\t\tatomic.AddUint64(&engine.numDocsIndexed, 1)\n\t\t}\n\t\tif request.forceUpdate {\n\t\t\tatomic.AddUint64(&engine.numDocsForceUpdated, 1)\n\t\t}\n\t}\n}\n\nfunc (engine *Engine) indexerRemoveDoc(shard int) {\n\tfor {\n\t\trequest := <-engine.indexerRemoveDocChans[shard]\n\t\tengine.indexers[shard].RemoveDocToCache(request.docId, request.forceUpdate)\n\t\tif request.docId != \"0\" {\n\t\t\tatomic.AddUint64(&engine.numDocsRemoved, 1)\n\t\t}\n\t\tif request.forceUpdate {\n\t\t\tatomic.AddUint64(&engine.numDocsForceUpdated, 1)\n\t\t}\n\t}\n}\n\nfunc (engine *Engine) orderLess(\n\trequest indexerLookupReq, docs []types.IndexedDoc) {\n\n\tif engine.initOptions.IDOnly {\n\t\tvar outputDocs types.ScoredIDs\n\t\tfor _, d := range docs {\n\t\t\toutputDocs = append(outputDocs, types.ScoredID{\n\t\t\t\tDocId:            d.DocId,\n\t\t\t\tTokenSnippetLocs: d.TokenSnippetLocs,\n\t\t\t\tTokenLocs:        d.TokenLocs,\n\t\t\t})\n\t\t}\n\n\t\trequest.rankerReturnChan <- rankerReturnReq{\n\t\t\tdocs:    outputDocs,\n\t\t\tnumDocs: len(outputDocs),\n\t\t}\n\n\t\treturn\n\t}\n\n\tvar outputDocs types.ScoredDocs\n\tfor _, d := range docs {\n\t\tids := types.ScoredID{\n\t\t\tDocId:            d.DocId,\n\t\t\tTokenSnippetLocs: d.TokenSnippetLocs,\n\t\t\tTokenLocs:        d.TokenLocs,\n\t\t}\n\n\t\toutputDocs = append(outputDocs, types.ScoredDoc{\n\t\t\tScoredID: ids,\n\t\t})\n\t}\n\n\trequest.rankerReturnChan <- rankerReturnReq{\n\t\tdocs:    outputDocs,\n\t\tnumDocs: len(outputDocs),\n\t}\n}\n\nfunc (engine *Engine) indexerLookup(shard int) {\n\tfor {\n\t\trequest := <-engine.indexerLookupChans[shard]\n\n\t\tdocs, numDocs := engine.indexers[shard].Lookup(\n\t\t\trequest.tokens, request.labels,\n\t\t\trequest.docIds, request.countDocsOnly, request.logic)\n\n\t\tif request.countDocsOnly {\n\t\t\trequest.rankerReturnChan <- rankerReturnReq{numDocs: numDocs}\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(docs) == 0 {\n\t\t\trequest.rankerReturnChan <- rankerReturnReq{}\n\t\t\tcontinue\n\t\t}\n\n\t\tif request.orderless {\n\t\t\t// var outputDocs interface{}\n\t\t\tengine.orderLess(request, docs)\n\n\t\t\tcontinue\n\t\t}\n\n\t\trankerRequest := rankerRankReq{\n\t\t\tcountDocsOnly:    request.countDocsOnly,\n\t\t\tdocs:             docs,\n\t\t\toptions:          request.options,\n\t\t\trankerReturnChan: request.rankerReturnChan,\n\t\t}\n\t\tengine.rankerRankChans[shard] <- rankerRequest\n\t}\n}\n"
        },
        {
          "name": "info.go",
          "type": "blob",
          "size": 3.3017578125,
          "content": "// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"sync\"\n\n\t\"github.com/go-vgo/gt/info\"\n)\n\nvar (\n\tlck sync.RWMutex\n\n\t// InitMemUsed init mem used\n\tInitMemUsed uint64\n\t// InitDiskUsed init disk used\n\tInitDiskUsed uint64\n)\n\nfunc init() {\n\tlck.Lock()\n\tInitMemUsed, _ = MemUsed()\n\tInitDiskUsed, _ = DiskUsed()\n\tlck.Unlock()\n}\n\n// MemPercent returns the amount of use memory in percent.\nfunc MemPercent() (string, error) {\n\treturn info.MemPercent()\n}\n\n// MemUsed returns the amount of used memory in bytes.\nfunc MemUsed() (uint64, error) {\n\treturn info.MemUsed()\n}\n\n// UsedMem returns the amount of riot used memory in bytes\n// after init() func.\nfunc (engine *Engine) UsedMem() (uint64, error) {\n\tmemUsed, err := MemUsed()\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn memUsed - InitMemUsed, err\n}\n\n// MemTotal returns the amount of total memory in bytes.\nfunc MemTotal() (uint64, error) {\n\treturn info.MemTotal()\n}\n\n// MemFree returns the amount of free memory in bytes.\nfunc MemFree() (uint64, error) {\n\treturn info.MemFree()\n}\n\n// ToKB bytes to kb\nfunc ToKB(data uint64) uint64 {\n\treturn data / 1024\n}\n\n// ToMB bytes to mb\nfunc ToMB(data uint64) uint64 {\n\treturn data / 1024 / 1024\n}\n\n// ToGB bytes to gb\nfunc ToGB(data uint64) uint64 {\n\treturn data / 1024 / 1024 / 1024\n}\n\n// Disk init the disk\n// func Disk(pt ...bool) ([]*disk.UsageStat, error) {\n// \treturn info.Disk(pt...)\n// }\n\n// DiskPercent returns the amount of use disk in percent.\nfunc DiskPercent() (string, error) {\n\treturn info.DiskPercent()\n}\n\n// DiskUsed returns the amount of use disk in bytes.\nfunc DiskUsed() (uint64, error) {\n\treturn info.DiskUsed()\n}\n\n// UsedDisk returns the amount of use disk in bytes\n// after init() func.\nfunc (engine *Engine) UsedDisk() (uint64, error) {\n\tdiskUsed, err := DiskUsed()\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn diskUsed - InitDiskUsed, err\n}\n\n// DiskTotal returns the amount of total disk in bytes.\nfunc DiskTotal() (uint64, error) {\n\treturn info.DiskTotal()\n}\n\n// DiskFree returns the amount of free disk in bytes.\nfunc DiskFree() (uint64, error) {\n\treturn info.DiskFree()\n}\n\n// CPUInfo returns the cpu info\nfunc CPUInfo(args ...int) (string, error) {\n\treturn info.CPUInfo(args...)\n}\n\n// CPUPercent returns the amount of use cpu in percent.\nfunc CPUPercent() ([]float64, error) {\n\treturn info.CPUPercent()\n}\n\n// Uptime returns the system uptime in seconds.\nfunc Uptime() (uptime uint64, err error) {\n\treturn info.Uptime()\n}\n\n// PlatformInfo fetches system platform information.\nfunc PlatformInfo() (platform, family, osVersion string, err error) {\n\treturn info.PlatformInfo()\n}\n\n// Platform returns the platform name and OS Version.\nfunc Platform() (string, error) {\n\treturn info.Platform()\n}\n\n// KernelVer returns the kernel version as a string.\nfunc KernelVer() (string, error) {\n\treturn info.KernelVer()\n}\n"
        },
        {
          "name": "info_test.go",
          "type": "blob",
          "size": 2.04296875,
          "content": "// +build !windows\n\npackage riot\n\nimport (\n\t\"log\"\n\t\"testing\"\n\n\t\"github.com/vcaesar/tt\"\n)\n\n// TestSysInfo\nfunc TestMem(t *testing.T) {\n\tlog.Println(\"SYS info test...\")\n\tvar engine Engine\n\n\tlog.Println(\"Mem info test...\")\n\ttt.Equal(t, true, InitMemUsed != 0)\n\ttt.Equal(t, true, InitMemUsed != 0)\n\n\tmemPercent, err := MemPercent()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, memPercent != \"\")\n\n\tmem, err := MemUsed()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, mem != 0)\n\n\tuseMem, err := engine.UsedMem()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, useMem != 0)\n\n\tmemT, err := MemTotal()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, memT != 0)\n\n\tmemFree, err := MemFree()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, memFree != 0)\n\n\ttt.Equal(t, 1, ToKB(1024))\n\ttt.Equal(t, 1, ToMB(1024*1024))\n\ttt.Equal(t, 1, ToGB(1024*1024*1024))\n}\n\nfunc TestDisk(t *testing.T) {\n\tlog.Println(\"Disk info test...\")\n\tvar engine Engine\n\n\tdiskPercent, err := DiskPercent()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, diskPercent != \"\")\n\n\tdisk, err := DiskUsed()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, disk != 0)\n\n\tuseDisk, err := engine.UsedDisk()\n\ttt.Equal(t, nil, err)\n\tlog.Println(\"useDisk: \", useDisk)\n\t// tt.Equal(t, true, useDisk != 0)\n\n\tdiskTotal, err := DiskTotal()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, diskTotal != 0)\n\n\tdiskFree, err := DiskFree()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, diskFree != 0)\n}\n\nfunc TestCPU(t *testing.T) {\n\tlog.Println(\"CPU info test...\")\n\n\tcpuInfo, err := CPUInfo()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, cpuInfo != \"\")\n\n\tcpuPct, err := CPUPercent()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, cpuPct != nil)\n}\n\nfunc TestPlatform(t *testing.T) {\n\tlog.Println(\"Platform info test...\")\n\n\tuptime, err := Uptime()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, uptime != 0)\n\n\tplatform, family, osVersion, err := PlatformInfo()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, platform != \"\" && osVersion != \"\")\n\tlog.Println(family)\n\n\tpalt, err := Platform()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, palt != \"\")\n\n\tkver, err := KernelVer()\n\ttt.Equal(t, nil, err)\n\ttt.Equal(t, true, kver != \"\")\n}\n"
        },
        {
          "name": "logo",
          "type": "tree",
          "content": null
        },
        {
          "name": "net",
          "type": "tree",
          "content": null
        },
        {
          "name": "ranker_worker.go",
          "type": "blob",
          "size": 1.9814453125,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"github.com/go-ego/riot/types\"\n)\n\ntype rankerAddDocReq struct {\n\tdocId  string\n\tfields interface{}\n\t// new\n\tcontent string\n\t// new 属性\n\tattri interface{}\n}\n\ntype rankerRankReq struct {\n\tdocs             []types.IndexedDoc\n\toptions          types.RankOpts\n\trankerReturnChan chan rankerReturnReq\n\tcountDocsOnly    bool\n}\n\ntype rankerReturnReq struct {\n\t// docs    types.ScoredDocs\n\tdocs    interface{}\n\tnumDocs int\n}\n\ntype rankerRemoveDocReq struct {\n\tdocId string\n}\n\nfunc (engine *Engine) rankerAddDoc(shard int) {\n\tfor {\n\t\trequest := <-engine.rankerAddDocChans[shard]\n\t\tif engine.initOptions.IDOnly {\n\t\t\tengine.rankers[shard].AddDoc(request.docId, request.fields)\n\t\t} else {\n\t\t\tengine.rankers[shard].AddDoc(request.docId, request.fields,\n\t\t\t\trequest.content, request.attri)\n\t\t}\n\t}\n}\n\nfunc (engine *Engine) rankerRank(shard int) {\n\tfor {\n\t\trequest := <-engine.rankerRankChans[shard]\n\t\tif request.options.MaxOutputs != 0 {\n\t\t\trequest.options.MaxOutputs += request.options.OutputOffset\n\t\t}\n\t\trequest.options.OutputOffset = 0\n\t\toutputDocs, numDocs := engine.rankers[shard].Rank(request.docs,\n\t\t\trequest.options, request.countDocsOnly)\n\n\t\trequest.rankerReturnChan <- rankerReturnReq{\n\t\t\tdocs: outputDocs, numDocs: numDocs}\n\t}\n}\n\nfunc (engine *Engine) rankerRemoveDoc(shard int) {\n\tfor {\n\t\trequest := <-engine.rankerRemoveDocChans[shard]\n\t\tengine.rankers[shard].RemoveDoc(request.docId)\n\t}\n}\n"
        },
        {
          "name": "riot.go",
          "type": "blob",
          "size": 4.0986328125,
          "content": "// Copyright 2017 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"bytes\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\n\t\"encoding/gob\"\n\n\t\"github.com/go-ego/murmur\"\n\t\"github.com/go-ego/riot/core\"\n\t\"github.com/go-ego/riot/types\"\n\ttoml \"github.com/go-vgo/gt/conf\"\n)\n\n// New create a new engine with mode\nfunc New(conf ...interface{}) *Engine {\n\t// func (engine *Engine) New(conf com.Config) *Engine{\n\tif len(conf) > 0 && strings.HasSuffix(conf[0].(string), \".toml\") {\n\t\tvar (\n\t\t\tconfig   types.EngineOpts\n\t\t\tsearcher = &Engine{}\n\t\t)\n\n\t\tfs := conf[0].(string)\n\t\tlog.Println(\"conf path is: \", fs)\n\t\ttoml.Init(fs, &config)\n\t\tgo toml.Watch(fs, &config)\n\n\t\tsearcher.Init(config)\n\t\treturn searcher\n\t}\n\n\treturn NewEngine(conf...)\n}\n\n// NewEngine create a new engine\nfunc NewEngine(conf ...interface{}) *Engine {\n\tvar (\n\t\tsearcher = &Engine{}\n\n\t\tpath          = DefaultPath\n\t\tstorageShards = 10\n\t\tnumShards     = 10\n\n\t\tsegmentDict string\n\t)\n\n\tif len(conf) > 0 {\n\t\tsegmentDict = conf[0].(string)\n\t}\n\n\tif len(conf) > 1 {\n\t\tpath = conf[1].(string)\n\t}\n\n\tif len(conf) > 2 {\n\t\tnumShards = conf[2].(int)\n\t\tstorageShards = conf[2].(int)\n\t}\n\n\tsearcher.Init(types.EngineOpts{\n\t\t// Using:         using,\n\t\tStoreShards: storageShards,\n\t\tNumShards:   numShards,\n\t\tIndexerOpts: &types.IndexerOpts{\n\t\t\tIndexType: types.DocIdsIndex,\n\t\t},\n\t\tUseStore:    true,\n\t\tStoreFolder: path,\n\t\t// StoreEngine: storageEngine,\n\t\tGseDict: segmentDict,\n\t\t// StopTokenFile: stopTokenFile,\n\t})\n\n\t// defer searcher.Close()\n\tos.MkdirAll(path, 0777)\n\n\t// 等待索引刷新完毕\n\t// searcher.Flush()\n\t// log.Println(\"recover index number: \", searcher.NumDocsIndexed())\n\n\treturn searcher\n}\n\n// func (engine *Engine) IsDocExist(docId uint64) bool {\n// \treturn core.IsDocExist(docId)\n// }\n\n// HasDoc if the document is exist return true\nfunc (engine *Engine) HasDoc(docId string) bool {\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\tengine.indexers = append(engine.indexers, core.Indexer{})\n\n\t\thas := engine.indexers[shard].HasDoc(docId)\n\n\t\tif has {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\n// HasDocDB if the document is exist in the database\n// return true\nfunc (engine *Engine) HasDocDB(docId string) bool {\n\tshard := murmur.Sum32(docId) % uint32(engine.initOptions.StoreShards)\n\n\thas, err := engine.dbs[shard].Has([]byte(docId))\n\tif err != nil {\n\t\tlog.Println(\"engine.dbs[shard].Has(b[0:length]): \", err)\n\t}\n\n\treturn has\n}\n\n// GetDBAllIds get all the DocId from the storage database\n// and return\n// 从数据库遍历所有的 DocId, 并返回\nfunc (engine *Engine) GetDBAllIds() []string {\n\tdocsId := make([]string, 0)\n\n\tfor i := range engine.dbs {\n\t\tengine.dbs[i].ForEach(func(k, v []byte) error {\n\t\t\t// fmt.Println(k, v)\n\t\t\tdocsId = append(docsId, string(k))\n\t\t\treturn nil\n\t\t})\n\t}\n\n\treturn docsId\n}\n\n// GetDBAllDocs get the db all docs\nfunc (engine *Engine) GetDBAllDocs() (docsId []string, docsData []types.DocData) {\n\tfor i := range engine.dbs {\n\t\tengine.dbs[i].ForEach(func(key, val []byte) error {\n\t\t\t// fmt.Println(k, v)\n\t\t\tdocsId = append(docsId, string(key))\n\n\t\t\tbuf := bytes.NewReader(val)\n\t\t\tdec := gob.NewDecoder(buf)\n\n\t\t\tvar data types.DocData\n\t\t\terr := dec.Decode(&data)\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"dec.decode: \", err)\n\t\t\t}\n\n\t\t\tdocsData = append(docsData, data)\n\n\t\t\treturn nil\n\t\t})\n\t}\n\n\treturn docsId, docsData\n}\n\n// GetAllDocIds get all the DocId from the storage database\n// and return\n// 从数据库遍历所有的 DocId, 并返回\nfunc (engine *Engine) GetAllDocIds() []string {\n\treturn engine.GetDBAllIds()\n}\n\n// Try handler(err)\nfunc Try(fun func(), handler func(interface{})) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\thandler(err)\n\t\t}\n\t}()\n\tfun()\n}\n"
        },
        {
          "name": "riot_pkg.go",
          "type": "blob",
          "size": 0.869140625,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\n/*\n\nPackage riot full text search engine\n*/\npackage riot\n\n// import (\n// \t// _ \"github.com/cznic/kv\"\n// \t_ \"github.com/dgraph-io/badger\"\n// \t_ \"github.com/go-ego/gse\"\n// \t_ \"github.com/go-ego/murmur\"\n// \t_ \"github.com/syndtr/goleveldb/leveldb\"\n// \t_ \"go.etcd.io/bbolt\"\n// )\n"
        },
        {
          "name": "riot_test.go",
          "type": "blob",
          "size": 9.12890625,
          "content": "package riot\n\nimport (\n\t\"encoding/gob\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/go-ego/riot/types\"\n\t\"github.com/vcaesar/tt\"\n)\n\nfunc TestEngineIndexWithNewStore(t *testing.T) {\n\tgob.Register(ScoringFields{})\n\tvar engine = New(\"./testdata/test_dict.txt\", \"./riot.new\", 8)\n\tlog.Println(\"new engine start...\")\n\t// engine = engine.New()\n\tAddDocs(engine)\n\n\tengine.RemoveDoc(\"5\", true)\n\tengine.Flush()\n\n\tengine.Close()\n\t// os.RemoveAll(\"riot.new\")\n\n\t// var engine1 = New(\"./testdata/test_dict.txt\", \"./riot.new\")\n\tvar engine1 = New(\"./testdata/test_new.toml\")\n\t// engine1 = engine1.New()\n\tlog.Println(\"test...\")\n\tengine1.Flush()\n\tlog.Println(\"new engine1 start...\")\n\n\toutputs := engine1.Search(types.SearchReq{Text: reqText})\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"world\", outputs.Tokens[0])\n\ttt.Expect(t, \"人口\", outputs.Tokens[1])\n\n\toutDocs := outputs.Docs.(types.ScoredDocs)\n\ttt.Expect(t, \"2\", len(outDocs))\n\n\t// tt.Expect(t, \"2\", outDocs[0].DocId)\n\ttt.Expect(t, \"2500\", int(outDocs[0].Scores[0]*1000))\n\ttt.Expect(t, \"[]\", outDocs[0].TokenSnippetLocs)\n\n\t// tt.Expect(t, \"1\", outDocs[1].DocId)\n\ttt.Expect(t, \"2215\", int(outDocs[1].Scores[0]*1000))\n\ttt.Expect(t, \"[]\", outDocs[1].TokenSnippetLocs)\n\n\tengine1.Close()\n\tos.RemoveAll(\"riot.new\")\n\t// os.RemoveAll(\"riot-index\")\n}\n\nvar (\n\trankTestOpts = rankOptsMax(0, 1)\n)\n\nfunc testRankOpt(idOnly bool) types.EngineOpts {\n\treturn types.EngineOpts{\n\t\tUsing:       1,\n\t\tIDOnly:      idOnly,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankTestOpts,\n\t\tIndexerOpts: inxOpts,\n\t}\n}\n\nfunc lookupReq(engine *Engine) (types.SearchReq, []string, chan rankerReturnReq) {\n\trequest := types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: makeDocIds(),\n\t}\n\n\ttokens := engine.Tokens(request)\n\t// 建立排序器返回的通信通道\n\trankerReturnChan := make(\n\t\tchan rankerReturnReq, engine.initOptions.NumShards)\n\n\t// 生成查找请求\n\tlookupRequest := indexerLookupReq{\n\t\tcountDocsOnly:    request.CountDocsOnly,\n\t\ttokens:           tokens,\n\t\tlabels:           request.Labels,\n\t\tdocIds:           request.DocIds,\n\t\toptions:          rankTestOpts,\n\t\trankerReturnChan: rankerReturnChan,\n\t\torderless:        request.Orderless,\n\t\tlogic:            request.Logic,\n\t}\n\n\t// 向索引器发送查找请求\n\tfor shard := 0; shard < engine.initOptions.NumShards; shard++ {\n\t\tengine.indexerLookupChans[shard] <- lookupRequest\n\t}\n\n\treturn request, tokens, rankerReturnChan\n}\n\nfunc TestDocRankID(t *testing.T) {\n\tvar engine Engine\n\n\tengine.Init(testRankOpt(true))\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\trequest, tokens, rankerReturnChan := lookupReq(&engine)\n\toutputs := engine.RankID(request, rankTestOpts, tokens, rankerReturnChan)\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"1\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\tengine.Close()\n}\n\nfunc TestDocRanks(t *testing.T) {\n\tvar engine Engine\n\n\tengine.Init(testRankOpt(false))\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\trequest, tokens, rankerReturnChan := lookupReq(&engine)\n\toutputs := engine.Ranks(request, rankTestOpts, tokens, rankerReturnChan)\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredDocs)\n\t\ttt.Expect(t, \"1\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\t// test search\n\toutputs1 := engine.Search(types.SearchReq{\n\t\tText:    reqText,\n\t\tTimeout: 1000,\n\t\tDocIds:  makeDocIds()})\n\n\tif outputs1.Docs != nil {\n\t\toutDocs1 := outputs.Docs.(types.ScoredDocs)\n\t\ttt.Expect(t, \"1\", len(outDocs1))\n\t}\n\ttt.Expect(t, \"2\", len(outputs1.Tokens))\n\ttt.Expect(t, \"2\", outputs1.NumDocs)\n\n\tengine.Close()\n}\n\nfunc TestDocGetAllDocAndID(t *testing.T) {\n\tgob.Register(ScoringFields{})\n\n\tvar engine Engine\n\topts := types.EngineOpts{\n\t\tUsing:     1,\n\t\tNumShards: 5,\n\t\tUseStore:  true,\n\t\t// StoreEngine: \"bg\",\n\t\tStoreFolder: \"riot.id\",\n\t\tIDOnly:      true,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankTestOpts,\n\t\tIndexerOpts: inxOpts,\n\t}\n\tengine.Init(opts)\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\tallIds := engine.GetDBAllIds()\n\tfmt.Println(\"all id\", allIds)\n\ttt.Expect(t, \"5\", len(allIds))\n\ttt.Expect(t, \"[3 4 1 6 2]\", allIds)\n\n\tallIds = engine.GetAllDocIds()\n\tfmt.Println(\"all doc id\", allIds)\n\ttt.Expect(t, \"5\", len(allIds))\n\ttt.Expect(t, \"[3 4 1 6 2]\", allIds)\n\n\tids, docs := engine.GetDBAllDocs()\n\tfmt.Println(\"all id and doc\", allIds, docs)\n\ttt.Expect(t, \"5\", len(ids))\n\ttt.Expect(t, \"5\", len(docs))\n\ttt.Expect(t, \"[3 4 1 6 2]\", ids)\n\tallDoc := `[{The world <nil> [] [] <nil>} {有人口 <nil> [] [] {2 3 1}} {The world, 有七十亿人口人口 <nil> [] [] {1 2 3}} {有七十亿人口 <nil> [] [] {2 3 3}} {The world, 人口 <nil> [] [] <nil>}]`\n\ttt.Expect(t, allDoc, docs)\n\n\thas := engine.HasDoc(\"5\")\n\ttt.Expect(t, \"false\", has)\n\n\thas = engine.HasDoc(\"2\")\n\ttt.Equal(t, true, has)\n\thas = engine.HasDoc(\"3\")\n\ttt.Equal(t, true, has)\n\thas = engine.HasDoc(\"4\")\n\ttt.Expect(t, \"true\", has)\n\n\tdbhas := engine.HasDocDB(\"5\")\n\ttt.Expect(t, \"false\", dbhas)\n\n\tdbhas = engine.HasDocDB(\"2\")\n\ttt.Equal(t, true, dbhas)\n\tdbhas = engine.HasDocDB(\"3\")\n\ttt.Equal(t, true, dbhas)\n\tdbhas = engine.HasDocDB(\"4\")\n\ttt.Expect(t, \"true\", dbhas)\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: docIds})\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\tfmt.Println(\"output docs: \", outputs)\n\t\ttt.Expect(t, \"1\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"1\", outputs.NumDocs)\n\n\tengine.Close()\n\tos.RemoveAll(\"riot.id\")\n}\n\nfunc testOpts(use int, store string, args ...bool) types.EngineOpts {\n\tvar pinyin bool\n\tif len(args) > 0 {\n\t\tpinyin = args[0]\n\t}\n\n\treturn types.EngineOpts{\n\t\t// Using:      1,\n\t\tUsing:       use,\n\t\tUseStore:    true,\n\t\tStoreFolder: store,\n\t\tPinYin:      pinyin,\n\t\tIDOnly:      true,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t}\n}\n\nfunc TestDocPinYin(t *testing.T) {\n\tvar engine, pinyinOpt Engine\n\tengine.Init(testOpts(0, \"riot.py\"))\n\tpinyinOpt.Init(testOpts(0, \"riot.py.opt\", true))\n\n\t// AddDocs(&engine)\n\t// engine.RemoveDoc(5)\n\n\ttokens := engine.PinYin(text2)\n\tfmt.Println(\"tokens...\", tokens)\n\ttt.Expect(t, \"46\", len(tokens))\n\n\tvar tokenDatas []types.TokenData\n\t// tokens := []string{\"z\", \"zl\"}\n\tfor i := 0; i < len(tokens); i++ {\n\t\ttokenData := types.TokenData{Text: tokens[i]}\n\t\ttokenDatas = append(tokenDatas, tokenData)\n\t}\n\n\tindex1 := types.DocData{Tokens: tokenDatas, Fields: \"在路上\"}\n\tindex2 := types.DocData{Content: text2, Tokens: tokenDatas}\n\n\tengine.Index(\"10\", index1)\n\tengine.Index(\"11\", index2)\n\tengine.Flush()\n\n\tdata := types.DocData{Content: text2}\n\tpinyinOpt.Index(\"10\", data)\n\tpinyinOpt.Index(\"11\", data)\n\tpinyinOpt.Flush()\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"10\"] = true\n\tdocIds[\"11\"] = true\n\n\tpyOutputs := pinyinOpt.SearchID(types.SearchReq{\n\t\tText:   \"zl\",\n\t\tDocIds: docIds,\n\t})\n\n\ttt.Expect(t, \"2\", len(pyOutputs.Docs))\n\ttt.Expect(t, \"1\", len(pyOutputs.Tokens))\n\ttt.Expect(t, \"2\", pyOutputs.NumDocs)\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   \"zl\",\n\t\tDocIds: docIds,\n\t})\n\n\tfmt.Println(\"outputs\", outputs.Docs)\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"2\", len(outDocs))\n\t\t// tt.Expect(t, \"11\", outDocs[0].DocId)\n\t\t// tt.Expect(t, \"10\", outDocs[1].DocId)\n\t}\n\ttt.Expect(t, \"1\", len(outputs.Tokens))\n\ttt.Expect(t, \"2\", outputs.NumDocs)\n\n\tengine.Close()\n\tpinyinOpt.Close()\n\tos.RemoveAll(\"riot.py\")\n\tos.RemoveAll(\"riot.py.opt\")\n}\n\nfunc TestForSplitData(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(testOpts(4, \"riot.data\"))\n\n\tAddDocs(&engine)\n\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\ttokenDatas := engine.PinYin(text2)\n\ttokens, num := engine.ForSplitData(tokenDatas, len(tokenDatas))\n\ttt.Expect(t, \"81\", len(tokens))\n\ttt.Expect(t, \"92\", num)\n\n\tindex1 := types.DocData{Content: \"在路上\"}\n\tengine.Index(\"10\", index1, true)\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: docIds})\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"0\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"0\", outputs.NumDocs)\n\n\tengine.Close()\n\tos.RemoveAll(\"riot.data\")\n}\n\nfunc testNum(t *testing.T, numAdd, numInx, numRm uint64) {\n\ttt.Expect(t, \"26\", numAdd)\n\ttt.Expect(t, \"6\", numInx)\n\ttt.Expect(t, \"8\", numRm)\n}\nfunc TestDocCounters(t *testing.T) {\n\tvar engine Engine\n\tengine.Init(testOpts(1, \"riot.doc\"))\n\n\tAddDocs(&engine)\n\tengine.RemoveDoc(\"5\")\n\tengine.Flush()\n\n\tnumAdd := engine.NumTokenAdded()\n\tnumInx := engine.NumIndexed()\n\tnumRm := engine.NumRemoved()\n\ttestNum(t, numAdd, numInx, numRm)\n\n\tnumAdd = engine.NumTokenIndexAdded()\n\tnumInx = engine.NumDocsIndexed()\n\tnumRm = engine.NumDocsRemoved()\n\ttestNum(t, numAdd, numInx, numRm)\n\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"1\"] = true\n\n\toutputs := engine.Search(types.SearchReq{\n\t\tText:   reqText,\n\t\tDocIds: docIds})\n\n\tif outputs.Docs != nil {\n\t\toutDocs := outputs.Docs.(types.ScoredIDs)\n\t\ttt.Expect(t, \"1\", len(outDocs))\n\t}\n\ttt.Expect(t, \"2\", len(outputs.Tokens))\n\ttt.Expect(t, \"1\", outputs.NumDocs)\n\n\tengine.Close()\n\tos.RemoveAll(\"riot.doc\")\n}\n"
        },
        {
          "name": "segment.go",
          "type": "blob",
          "size": 9.21484375,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t// \"fmt\"\n\n\t\"strings\"\n\n\t\"github.com/go-ego/gpy\"\n\t\"github.com/go-ego/gpy/phrase\"\n\t\"github.com/go-ego/riot/types\"\n)\n\n// TMap defines the tokens map type map[string][]int\ntype TMap map[string][]int\n\ntype segmenterReq struct {\n\tdocId string\n\thash  uint32\n\tdata  types.DocData\n\t// data        types.DocumentIndexData\n\tforceUpdate bool\n}\n\n// ForSplitData for split segment's data, segspl\nfunc (engine *Engine) ForSplitData(strData []string, num int) (TMap, int) {\n\tvar (\n\t\tnumTokens int\n\t\tsplitStr  string\n\t)\n\ttokensMap := make(map[string][]int)\n\n\tfor i := 0; i < num; i++ {\n\t\tif strData[i] != \"\" {\n\t\t\tif !engine.stopTokens.IsStopToken(strData[i]) {\n\t\t\t\tnumTokens++\n\t\t\t\ttokensMap[strData[i]] = append(tokensMap[strData[i]], numTokens)\n\t\t\t}\n\n\t\t\tsplitStr += strData[i]\n\t\t\tif !engine.stopTokens.IsStopToken(splitStr) {\n\t\t\t\tnumTokens++\n\t\t\t\ttokensMap[splitStr] = append(tokensMap[splitStr], numTokens)\n\t\t\t}\n\n\t\t\tif engine.initOptions.Using == 6 {\n\t\t\t\t// more combination\n\t\t\t\tvar splitsStr string\n\t\t\t\tfor s := i + 1; s < len(strData); s++ {\n\t\t\t\t\tsplitsStr += strData[s]\n\n\t\t\t\t\tif !engine.stopTokens.IsStopToken(splitsStr) {\n\t\t\t\t\t\tnumTokens++\n\t\t\t\t\t\ttokensMap[splitsStr] = append(tokensMap[splitsStr], numTokens)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\t}\n\n\treturn tokensMap, numTokens\n}\n\nfunc (engine *Engine) splitData(request segmenterReq) (TMap, int) {\n\tvar (\n\t\tnum       int\n\t\tnumTokens int\n\t)\n\ttokensMap := make(map[string][]int)\n\n\tif request.data.Content != \"\" {\n\t\tcontent := strings.ToLower(request.data.Content)\n\t\tif engine.initOptions.Using == 3 {\n\t\t\t// use segmenter\n\t\t\tsegments := engine.segmenter.ModeSegment([]byte(content),\n\t\t\t\tengine.initOptions.GseMode)\n\n\t\t\tfor _, segment := range segments {\n\t\t\t\ttoken := segment.Token().Text()\n\t\t\t\tif !engine.stopTokens.IsStopToken(token) {\n\t\t\t\t\ttokensMap[token] = append(tokensMap[token], segment.Start())\n\t\t\t\t}\n\t\t\t}\n\t\t\tnumTokens += len(segments)\n\t\t}\n\n\t\tif engine.initOptions.Using == 4 {\n\t\t\ttokensMap, numTokens = engine.defaultTokens(content)\n\t\t}\n\n\t\tif engine.initOptions.Using != 4 {\n\t\t\tstrData := strings.Split(content, \"\")\n\t\t\tnum = len(strData)\n\t\t\ttokenMap, numToken := engine.ForSplitData(strData, num)\n\t\t\tnumTokens += numToken\n\t\t\tfor key, val := range tokenMap {\n\t\t\t\ttokensMap[key] = val\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, t := range request.data.Tokens {\n\t\tif !engine.stopTokens.IsStopToken(t.Text) {\n\t\t\ttokensMap[t.Text] = t.Locations\n\t\t}\n\t}\n\n\tnumTokens += len(request.data.Tokens)\n\n\treturn tokensMap, numTokens\n}\n\nfunc (engine *Engine) segmenterData(request segmenterReq) (TMap, int) {\n\ttokensMap := make(map[string][]int)\n\tnumTokens := 0\n\n\tif engine.initOptions.Using == 0 && request.data.Content != \"\" {\n\t\t// Content 分词, 当文档正文不为空时，优先从内容分词中得到关键词\n\t\tsegments := engine.segmenter.ModeSegment([]byte(request.data.Content),\n\t\t\tengine.initOptions.GseMode)\n\n\t\tfor _, segment := range segments {\n\t\t\ttoken := segment.Token().Text()\n\t\t\tif !engine.stopTokens.IsStopToken(token) {\n\t\t\t\ttokensMap[token] = append(tokensMap[token], segment.Start())\n\t\t\t}\n\t\t}\n\n\t\tfor _, t := range request.data.Tokens {\n\t\t\tif !engine.stopTokens.IsStopToken(t.Text) {\n\t\t\t\ttokensMap[t.Text] = t.Locations\n\t\t\t}\n\t\t}\n\n\t\tnumTokens = len(segments) + len(request.data.Tokens)\n\n\t\treturn tokensMap, numTokens\n\t}\n\n\tif engine.initOptions.Using == 1 && request.data.Content != \"\" {\n\t\t// Content 分词, 当文档正文不为空时，优先从内容分词中得到关键词\n\t\tsegments := engine.segmenter.ModeSegment([]byte(request.data.Content),\n\t\t\tengine.initOptions.GseMode)\n\n\t\tfor _, segment := range segments {\n\t\t\ttoken := segment.Token().Text()\n\t\t\tif !engine.stopTokens.IsStopToken(token) {\n\t\t\t\ttokensMap[token] = append(tokensMap[token], segment.Start())\n\t\t\t}\n\t\t}\n\t\tnumTokens = len(segments)\n\n\t\treturn tokensMap, numTokens\n\t}\n\n\tuseOpts := engine.initOptions.Using == 1 || engine.initOptions.Using == 3\n\tcontentNil := request.data.Content == \"\"\n\topts := useOpts && contentNil\n\n\tif engine.initOptions.Using == 2 || opts {\n\t\tfor _, t := range request.data.Tokens {\n\t\t\tif !engine.stopTokens.IsStopToken(t.Text) {\n\t\t\t\ttokensMap[t.Text] = t.Locations\n\t\t\t}\n\t\t}\n\n\t\tnumTokens = len(request.data.Tokens)\n\n\t\treturn tokensMap, numTokens\n\t}\n\n\ttokenMap, lenSplitData := engine.splitData(request)\n\n\treturn tokenMap, lenSplitData\n}\n\nfunc (engine *Engine) defaultTokens(content string) (tokensMap TMap, numTokens int) {\n\t// use segmenter\n\ttokensMap = make(map[string][]int)\n\tstrData := strings.Split(content, \" \")\n\tnum := len(strData)\n\n\tif num > 0 {\n\t\ttokenMap, numToken := engine.ForSplitData(strData, num)\n\t\tnumTokens += numToken\n\n\t\tfor key, val := range tokenMap {\n\t\t\ttokensMap[key] = val\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc (engine *Engine) makeTokensMap(request segmenterReq) (map[string][]int, int) {\n\ttokensMap := make(map[string][]int)\n\tnumTokens := 0\n\n\tif !(engine.initOptions.NotUseGse && engine.initOptions.Using == 0) {\n\t\ttokensMap, numTokens = engine.segmenterData(request)\n\t} else {\n\t\tif request.data.Content != \"\" {\n\t\t\tcontent := strings.ToLower(request.data.Content)\n\t\t\ttokensMap, numTokens = engine.defaultTokens(content)\n\t\t}\n\n\t\tfor _, t := range request.data.Tokens {\n\t\t\tif !engine.stopTokens.IsStopToken(t.Text) {\n\t\t\t\ttokensMap[t.Text] = t.Locations\n\t\t\t}\n\t\t}\n\n\t\tnumTokens += len(request.data.Tokens)\n\t}\n\n\tif engine.initOptions.PinYin {\n\t\tstrArr := engine.PinYin(request.data.Content)\n\t\tcount := len(strArr)\n\n\t\tfor i := 0; i < count; i++ {\n\t\t\tstr := strArr[i]\n\t\t\tif !engine.stopTokens.IsStopToken(str) {\n\t\t\t\ttokensMap[str] = []int{i}\n\t\t\t}\n\t\t}\n\n\t\tnumTokens += count\n\t}\n\n\treturn tokensMap, numTokens\n}\n\nfunc (engine *Engine) segmenterWorker() {\n\tfor {\n\t\trequest := <-engine.segmenterChan\n\t\tif request.docId == \"0\" {\n\t\t\tif request.forceUpdate {\n\t\t\t\tfor i := 0; i < engine.initOptions.NumShards; i++ {\n\t\t\t\t\tengine.indexerAddDocChans[i] <- indexerAddDocReq{\n\t\t\t\t\t\tforceUpdate: true}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tshard := engine.getShard(request.hash)\n\t\ttokensMap, numTokens := engine.makeTokensMap(request)\n\n\t\t// 加入非分词的文档标签\n\t\tfor _, label := range request.data.Labels {\n\t\t\tif !engine.initOptions.NotUseGse {\n\t\t\t\tif !engine.stopTokens.IsStopToken(label) {\n\t\t\t\t\t// 当正文中已存在关键字时，若不判断，位置信息将会丢失\n\t\t\t\t\tif _, ok := tokensMap[label]; !ok {\n\t\t\t\t\t\ttokensMap[label] = []int{}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// 当正文中已存在关键字时，若不判断，位置信息将会丢失\n\t\t\t\tif _, ok := tokensMap[label]; !ok {\n\t\t\t\t\ttokensMap[label] = []int{}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tindexerRequest := indexerAddDocReq{\n\t\t\tdoc: &types.DocIndex{\n\t\t\t\tDocId:    request.docId,\n\t\t\t\tTokenLen: float32(numTokens),\n\t\t\t\tKeywords: make([]types.KeywordIndex, len(tokensMap)),\n\t\t\t},\n\t\t\tforceUpdate: request.forceUpdate,\n\t\t}\n\t\tiTokens := 0\n\t\tfor k, v := range tokensMap {\n\t\t\tindexerRequest.doc.Keywords[iTokens] = types.KeywordIndex{\n\t\t\t\tText: k,\n\t\t\t\t// 非分词标注的词频设置为0，不参与tf-idf计算\n\t\t\t\tFrequency: float32(len(v)),\n\t\t\t\tStarts:    v}\n\t\t\tiTokens++\n\t\t}\n\n\t\tengine.indexerAddDocChans[shard] <- indexerRequest\n\t\tif request.forceUpdate {\n\t\t\tfor i := 0; i < engine.initOptions.NumShards; i++ {\n\t\t\t\tif i == shard {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tengine.indexerAddDocChans[i] <- indexerAddDocReq{forceUpdate: true}\n\t\t\t}\n\t\t}\n\t\trankerRequest := rankerAddDocReq{\n\t\t\t// docId: request.docId, fields: request.data.Fields}\n\t\t\tdocId: request.docId, fields: request.data.Fields,\n\t\t\tcontent: request.data.Content, attri: request.data.Attri}\n\t\tengine.rankerAddDocChans[shard] <- rankerRequest\n\t}\n}\n\n// PinYin get the Chinese alphabet and abbreviation\nfunc (engine *Engine) PinYin(hans string) []string {\n\tif engine.initOptions.UsePhrase {\n\t\tif !engine.initOptions.NotUseGse {\n\t\t\tphrase.WithGse(engine.segmenter)\n\t\t}\n\n\t\treturn phrase.Pinyin(hans)\n\t}\n\n\tvar (\n\t\tstr      string\n\t\tpyStr    string\n\t\tstrArr   []string\n\t\tsplitStr string\n\t\t// splitArr []string\n\t)\n\n\t//\n\tsplitHans := strings.Split(hans, \"\")\n\tfor i := 0; i < len(splitHans); i++ {\n\t\tif splitHans[i] != \"\" {\n\t\t\tif !engine.stopTokens.IsStopToken(splitHans[i]) {\n\t\t\t\tstrArr = append(strArr, splitHans[i])\n\t\t\t}\n\t\t\tsplitStr += splitHans[i]\n\t\t}\n\t\tif !engine.stopTokens.IsStopToken(splitStr) {\n\t\t\tstrArr = append(strArr, splitStr)\n\t\t}\n\t}\n\n\t// Segment 分词\n\tif !engine.initOptions.NotUseGse {\n\t\tsehans := engine.Segment(hans)\n\t\tfor h := 0; h < len(sehans); h++ {\n\t\t\tif !engine.stopTokens.IsStopToken(sehans[h]) {\n\t\t\t\tstrArr = append(strArr, sehans[h])\n\t\t\t}\n\t\t}\n\t}\n\t//\n\t// py := pinyin.LazyConvert(sehans[h], nil)\n\tpy := gpy.LazyConvert(hans, nil)\n\n\t// log.Println(\"py...\", py)\n\tfor i := 0; i < len(py); i++ {\n\t\t// log.Println(\"py[i]...\", py[i])\n\t\tpyStr += py[i]\n\t\tif !engine.stopTokens.IsStopToken(pyStr) {\n\t\t\tstrArr = append(strArr, pyStr)\n\t\t}\n\n\t\tif len(py[i]) > 0 {\n\t\t\tstr += py[i][0:1]\n\t\t\tif !engine.stopTokens.IsStopToken(str) {\n\t\t\t\tstrArr = append(strArr, str)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn strArr\n}\n"
        },
        {
          "name": "stop_tokens.go",
          "type": "blob",
          "size": 1.380859375,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"bufio\"\n\t\"log\"\n\t\"os\"\n)\n\n// StopTokens stop tokens map\ntype StopTokens struct {\n\tstopTokens map[string]bool\n}\n\n// Init 从 stopTokenFile 中读入停用词，一个词一行\n// 文档索引建立时会跳过这些停用词\nfunc (st *StopTokens) Init(stopTokenFile string) {\n\tst.stopTokens = make(map[string]bool)\n\tif stopTokenFile == \"\" {\n\t\treturn\n\t}\n\n\tfile, err := os.Open(stopTokenFile)\n\tif err != nil {\n\t\tlog.Fatal(\"Open stop token file error: \", err)\n\t}\n\tdefer file.Close()\n\n\tscanner := bufio.NewScanner(file)\n\tfor scanner.Scan() {\n\t\ttext := scanner.Text()\n\t\tif text != \"\" {\n\t\t\tst.stopTokens[text] = true\n\t\t}\n\t}\n\n}\n\n// IsStopToken to determine whether to stop token\nfunc (st *StopTokens) IsStopToken(token string) bool {\n\t_, found := st.stopTokens[token]\n\treturn found\n}\n"
        },
        {
          "name": "store",
          "type": "tree",
          "content": null
        },
        {
          "name": "store_worker.go",
          "type": "blob",
          "size": 2.08203125,
          "content": "// Copyright 2013 Hui Chen\n// Copyright 2016 ego authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n// not use this file except in compliance with the License. You may obtain\n// a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n// WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n// License for the specific language governing permissions and limitations\n// under the License.\n\npackage riot\n\nimport (\n\t\"bytes\"\n\n\t\"encoding/gob\"\n\t\"sync/atomic\"\n\n\t\"github.com/go-ego/riot/types\"\n)\n\ntype storeIndexDocReq struct {\n\tdocId string\n\tdata  types.DocData\n\t// data        types.DocumentIndexData\n}\n\nfunc (engine *Engine) storeIndexDoc(shard int) {\n\tfor {\n\t\trequest := <-engine.storeIndexDocChans[shard]\n\n\t\t// 得到 key\n\t\tb := []byte(request.docId)\n\n\t\t// 得到 value\n\t\tvar buf bytes.Buffer\n\t\tenc := gob.NewEncoder(&buf)\n\t\terr := enc.Encode(request.data)\n\t\tif err != nil {\n\t\t\tatomic.AddUint64(&engine.numDocsStored, 1)\n\t\t\tcontinue\n\t\t}\n\n\t\t// has, err := engine.dbs[shard].Has(b[0:length])\n\t\t// if err != nil {\n\t\t// \tlog.Println(\"engine.dbs[shard].Has(b[0:length]) \", err)\n\t\t// }\n\n\t\t// if has {\n\t\t// \tengine.dbs[shard].Delete(b[0:length])\n\t\t// }\n\n\t\t// 将 key-value 写入数据库\n\t\tengine.dbs[shard].Set(b, buf.Bytes())\n\n\t\tatomic.AddUint64(&engine.numDocsStored, 1)\n\t}\n}\n\nfunc (engine *Engine) storeRemoveDoc(docId string, shard uint32) {\n\t// 得到 key\n\tb := []byte(docId)\n\t// 从数据库删除该key\n\tengine.dbs[shard].Delete(b)\n}\n\n// storeInit persistent storage init worker\nfunc (engine *Engine) storeInit(shard int) {\n\tengine.dbs[shard].ForEach(func(k, v []byte) error {\n\t\tkey, value := k, v\n\t\t// 得到docID\n\t\tdocId := string(key)\n\n\t\t// 得到 data\n\t\tbuf := bytes.NewReader(value)\n\t\tdec := gob.NewDecoder(buf)\n\t\tvar data types.DocData\n\t\terr := dec.Decode(&data)\n\t\tif err == nil {\n\t\t\t// 添加索引\n\t\t\tengine.internalIndexDoc(docId, data, false)\n\t\t}\n\t\treturn nil\n\t})\n\tengine.storeInitChan <- true\n}\n"
        },
        {
          "name": "test_utils.go",
          "type": "blob",
          "size": 3.4775390625,
          "content": "package riot\n\nimport (\n\t\"log\"\n\n\t\"github.com/go-ego/riot/types\"\n)\n\ntype ScoringFields struct {\n\tA, B, C float32\n}\n\nvar (\n\ttext1 = \"Hello world, 你好世界!\"\n\ttext2 = \"在路上, in the way\"\n\n\ttextJP  = \"こんにちは世界\"\n\ttextJP1 = \"こんにちは世界, こんにちは\"\n\treqText = \"World人口\"\n\n\treqG = types.SearchReq{Text: \"Google\"}\n\tReq1 = types.SearchReq{Text: reqText}\n\n\tscore1   = ScoringFields{1, 2, 3}\n\tscore091 = ScoringFields{0, 9, 1}\n\n\tinxOpts = &types.IndexerOpts{\n\t\tIndexType: types.LocsIndex,\n\t}\n)\n\nvar (\n\trankOptsMax1 = rankOptsMax(0, 1)\n\n\trankOptsMax10      = rankOptsOrder(false)\n\trankOptsMax10Order = rankOptsOrder(true)\n\n\trankOptsMax3 = rankOptsMax(1, 3)\n)\n\nfunc makeDocIds() map[string]bool {\n\tdocIds := make(map[string]bool)\n\tdocIds[\"5\"] = true\n\tdocIds[\"3\"] = true\n\tdocIds[\"1\"] = true\n\tdocIds[\"2\"] = true\n\n\treturn docIds\n}\n\ntype RankByTokenProximity struct {\n}\n\nfunc (rule RankByTokenProximity) Score(\n\tdoc types.IndexedDoc, fields interface{}) []float32 {\n\tif doc.TokenProximity < 0 {\n\t\treturn []float32{}\n\t}\n\treturn []float32{1.0 / (float32(doc.TokenProximity) + 1)}\n}\n\nfunc OrderlessOpts(idOnly bool) types.EngineOpts {\n\treturn types.EngineOpts{\n\t\tUsing:   1,\n\t\tIDOnly:  idOnly,\n\t\tGseDict: \"./testdata/test_dict.txt\",\n\t}\n}\n\nfunc rankEngineOpts(rankOpts types.RankOpts) types.EngineOpts {\n\treturn types.EngineOpts{\n\t\tUsing:       1,\n\t\tGseDict:     \"./testdata/test_dict.txt\",\n\t\tDefRankOpts: &rankOpts,\n\t\tIndexerOpts: inxOpts,\n\t}\n}\n\nfunc rankOptsOrder(order bool) types.RankOpts {\n\treturn types.RankOpts{\n\t\tReverseOrder:    order,\n\t\tOutputOffset:    0,\n\t\tMaxOutputs:      10,\n\t\tScoringCriteria: &RankByTokenProximity{},\n\t}\n}\n\nfunc rankOptsMax(output, max int) types.RankOpts {\n\treturn types.RankOpts{\n\t\tReverseOrder:    true,\n\t\tOutputOffset:    output,\n\t\tMaxOutputs:      max,\n\t\tScoringCriteria: &RankByTokenProximity{},\n\t}\n}\n\nvar (\n\tTestIndexOpts = rankEngineOpts(rankOptsMax10)\n\n\torderOpts = rankEngineOpts(rankOptsMax10Order)\n)\n\nfunc AddDocs(engine *Engine) {\n\t// docId := uint64(1)\n\tengine.Index(\"1\", types.DocData{\n\t\tContent: \"The world, 有七十亿人口人口\",\n\t\tFields:  score1,\n\t})\n\n\t// docId++\n\tengine.IndexDoc(\"2\", types.DocIndexData{\n\t\tContent: \"The world, 人口\",\n\t\tFields:  nil,\n\t})\n\n\tengine.Index(\"3\", types.DocData{\n\t\tContent: \"The world\",\n\t\tFields:  nil,\n\t})\n\n\tengine.Index(\"4\", types.DocData{\n\t\tContent: \"有人口\",\n\t\tFields:  ScoringFields{2, 3, 1},\n\t})\n\n\tengine.Index(\"5\", types.DocData{\n\t\tContent: \"The world, 七十亿人口\",\n\t\tFields:  score091,\n\t})\n\n\tengine.Index(\"6\", types.DocData{\n\t\tContent: \"有七十亿人口\",\n\t\tFields:  ScoringFields{2, 3, 3},\n\t})\n\n\tengine.Flush()\n}\n\nfunc AddDocsWithLabels(engine *Engine) {\n\t// docId := uint64(1)\n\tengine.Index(\"1\", types.DocData{\n\t\tContent: \"《复仇者联盟3：无限战争》是全片使用IMAX摄影机拍摄\",\n\t\tLabels:  []string{\"复仇者\", \"战争\"},\n\t})\n\tlog.Println(\"engine.Segment(): \",\n\t\tengine.Segment(\"《复仇者联盟3：无限战争》是全片使用IMAX摄影机拍摄\"))\n\n\t// docId++\n\tengine.Index(\"2\", types.DocData{\n\t\tContent: \"在IMAX影院放映时\",\n\t\tLabels:  []string{\"影院\"},\n\t})\n\n\tengine.Index(\"3\", types.DocData{\n\t\tContent: \" Google 是世界最大搜索引擎, baidu 是最大中文的搜索引擎\",\n\t\tLabels:  []string{\"Google\"},\n\t})\n\n\tengine.Index(\"4\", types.DocData{\n\t\tContent: \"Google 在研制无人汽车\",\n\t\tLabels:  []string{\"Google\"},\n\t})\n\n\tengine.Index(\"5\", types.DocData{\n\t\tContent: \" GAMAF 世界五大互联网巨头, BAT 是中国互联网三巨头\",\n\t\tLabels:  []string{\"互联网\"},\n\t})\n\n\tengine.Flush()\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "types",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}