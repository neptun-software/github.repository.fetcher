{
  "metadata": {
    "timestamp": 1736567665807,
    "page": 247,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "btcsuite/btcd",
      "stars": 6311,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.552734375,
          "content": "# Temp files\n*~\n\n# Databases\nbtcd.db\n*-shm\n*-wal\n\n# Log files\n*.log\n\n# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\nvendor\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n\n# Code coverage files\nprofile.tmp\nprofile.cov\ncoverage.txt\nbtcec/coverage.txt\nbtcutil/coverage.txt\nbtcutil/psbt/coverage.txt\n\n# vim\n*.swp\n*.swo\n/.vim\n\n# Binaries produced by \"make build\"\n/addblock\n/btcctl\n/btcd\n/findcheckpoint\n/gencerts\n"
        },
        {
          "name": "CHANGES",
          "type": "blob",
          "size": 57.4443359375,
          "content": "============================================================================\nUser visible changes for btcd\n  A full-node bitcoin implementation written in Go\n============================================================================\n\nChanges in 0.22.0 (Tue Jun 01 2021)\n  - Protocol and network-related changes:\n    - Add support for witness tx and block in notfound msg (#1625)\n    - Add support for receiving sendaddrv2 messages from a peer (#1670)\n    - Fix bug in peer package causing last block height to go backwards\n      (#1606)\n    - Add chain parameters for connecting to the public Signet network\n      (#1692, #1718)\n  - Crypto changes:\n    - Fix bug causing panic due to bad R and S signature components in\n      btcec.RecoverCompact (#1691)\n    - Set the name (secp256k1) in the CurveParams of the S256 curve\n      (#1565)\n  - Notable developer-related package changes:\n    - Remove unknown block version warning in the blockchain package,\n      due to false positives triggered by AsicBoost (#1463)\n    - Add chaincfg.RegisterHDKeyID function to populate HD key ID pairs\n      (#1617)\n    - Add new method mining.AddWitnessCommitment to add the witness\n      commitment as an OP_RETURN output within the coinbase transaction.\n      (#1716)\n  - RPC changes:\n    - Support Batch JSON-RPC in rpcclient and server (#1583)\n    - Add rpcclient method to invoke getdescriptorinfo JSON-RPC command\n      (#1578)\n    - Update the rpcserver handler for validateaddress JSON-RPC command to\n      have parity with the bitcoind 0.20.0 interface (#1613)\n    - Add rpcclient method to invoke getblockfilter JSON-RPC command\n      (#1579)\n    - Add signmessagewithprivkey JSON-RPC command in rpcserver (#1585)\n    - Add rpcclient method to invoke importmulti JSON-RPC command (#1579)\n    - Add watchOnly argument in rpcclient method to invoke\n      listtransactions JSON-RPC command (#1628)\n    - Update btcjson.ListTransactionsResult for compatibility with Bitcoin\n      Core 0.20.0 (#1626)\n    - Support nullable optional JSON-RPC parameters (#1594)\n    - Add rpcclient and server method to invoke getnodeaddresses JSON-RPC\n      command (#1590)\n    - Add rpcclient methods to invoke PSBT JSON-RPC commands (#1596)\n    - Add rpcclient method to invoke listsinceblock with the\n      include_watchonly parameter enabled (#1451)\n    - Add rpcclient method to invoke deriveaddresses JSON-RPC command\n      (#1631)\n    - Add rpcclient method to invoke getblocktemplate JSON-RPC command\n      (#1629)\n    - Add rpcclient method to invoke getaddressinfo JSON-RPC command\n      (#1633)\n    - Add rpcclient method to invoke getwalletinfo JSON-RPC command\n      (#1638)\n    - Fix error message in rpcserver when an unknown RPC command is\n      encountered (#1695)\n    - Fix error message returned by estimatefee when the number of blocks\n      exceeds the max depth (#1678)\n    - Update btcjson.GetBlockChainInfoResult to include new fields in\n      Bitcoin Core (#1676)\n    - Add ExtraHeaders in rpcclient.ConnConfig struct (#1669)\n    - Fix bitcoind compatibility issue with the sendrawtransaction\n      JSON-RPC command (#1659)\n    - Add new JSON-RPC errors to btcjson package, and documented them\n      (#1648)\n    - Add rpcclient method to invoke createwallet JSON-RPC command\n      (#1650)\n    - Add rpcclient methods to invoke backupwallet, dumpwallet, loadwallet\n      and unloadwallet JSON-RPC commands (#1645)\n    - Fix unmarshalling error in getmininginfo JSON-RPC command, for valid\n      integers in scientific notation (#1644)\n    - Add rpcclient method to invoke gettxoutsetinfo JSON-RPC command\n      (#1641)\n    - Add rpcclient method to invoke signrawtransactionwithwallet JSON-RPC\n      command (#1642)\n    - Add txid to getblocktemplate response of rpcserver (#1639)\n    - Fix monetary unit used in createrawtransaction JSON-RPC command in\n      rpcserver (#1614)\n    - Add rawtx field to btcjson.GetBlockVerboseTxResult to provide\n      backwards compatibility with older versions of Bitcoin Core (#1677)\n  - Misc changes:\n    - Update btcutil dependency (#1704)\n    - Add Dockerfile to build and run btcd on Docker (#1465)\n    - Rework documentation and publish on https://btcd.readthedocs.io (#1468)\n    - Add support for Go 1.15 (#1619)\n    - Add Go 1.14 as the minimum supported version of Golang (#1621)\n  - Contributors (alphabetical order):\n    - 10gic\n    - Andrew Tugarinov\n    - Anirudha Bose\n    - Appelberg-s\n    - Armando Ochoa\n    - Aurèle Oulès\n    - Calvin Kim\n    - Christian Lehmann\n    - Conner Fromknecht\n    - Dan Cline\n    - David Mazary\n    - Elliott Minns\n    - Federico Bond\n    - Friedger Müffke\n    - Gustavo Chain\n    - Hanjun Kim\n    - Henry Fisher\n    - Iskander Sharipov\n    - Jake Sylvestre\n    - Johan T. Halseth\n    - John C. Vernaleo\n    - Liran Sharir\n    - Mikael Lindlof\n    - Olaoluwa Osuntokun\n    - Oliver Gugger\n    - Rjected\n    - Steven Kreuzer\n    - Torkel Rogstad\n    - Tristyn\n    - Victor Lavaud\n    - Vinayak Borkar\n    - Wilmer Paulino\n    - Yaacov Akiba Slama\n    - ebiiim\n    - ipriver\n    - wakiyamap\n    - yyforyongyu\n\nChanges in 0.21.0 (Thu Aug 27 2020)\n  - Network-related changes:\n    - Handle notfound messages from peers in netsync package (#1603)\n  - RPC changes:\n    - Add compatibility for getblock RPC changes in bitcoind 0.15.0 (#1529)\n    - Add new optional Params field to rpcclient.ConnConfig (#1467)\n    - Add new error code ErrRPCInWarmup in btcjson (#1541)\n    - Add compatibility for changes to getmempoolentry response in bitcoind\n      0.19.0 (#1524)\n    - Add rpcclient methods for estimatesmartfee and generatetoaddress\n      commands (#1500)\n    - Add rpcclient method for getblockstats command (#1500)\n    - Parse serialized transaction from createrawtransaction command using\n      both segwit, and legacy format (#1502)\n    - Support cookie-based authentication in rpcclient (#1460)\n    - Add rpcclient method for getchaintxstats command (#1571)\n    - Add rpcclient method for fundrawtransaction command (#1553)\n    - Add rpcclient method for getbalances command (#1595)\n    - Add new method rpcclient.GetTransactionWatchOnly (#1592)\n  - Crypto changes:\n    - Fix panic in fieldVal.SetByteSlice when called with large values, and\n      improve the method to be 35% faster (#1602)\n  - btcctl changes:\n    - Add -regtest mode to btcctl (#1556)\n  - Misc changes:\n    - Fix a bug due to a deadlock in connmgr's dynamic ban scoring (#1509)\n    - Add blockchain.NewUtxoEntry() to directly create entries for\n      UtxoViewpoint (#1588)\n    - Replace LRU cache implementation in peer package with a generic one\n      from decred/dcrd (#1599)\n  - Contributors (alphabetical order):\n    - Anirudha Bose\n    - Antonin Hildebrand\n    - Dan Cline\n    - Daniel McNally\n    - David Hill\n    - Federico Bond\n    - George Tankersley\n    - Henry\n    - Henry Harder\n    - Iskander Sharipov\n    - Ivan Kuznetsov\n    - Jake Sylvestre\n    - Javed Khan\n    - JeremyRand\n    - Jin\n    - John C. Vernaleo\n    - Kulpreet Singh\n    - Mikael Lindlof\n    - Murray Nesbitt\n    - Nisen\n    - Olaoluwa Osuntokun\n    - Oliver Gugger\n    - Steven Roose\n    - Torkel Rogstad\n    - Tyler Chambers\n    - Wilmer Paulino\n    - Yash Bhutwala\n    - adiabat\n    - jalavosus\n    - mohanson\n    - qqjettkgjzhxmwj\n    - qshuai\n    - shuai.qi\n    - tpkeeper\n\nChanges in v0.20.1 (Wed Nov 13 2019)\n  - RPC changes:\n    - Add compatibility for bitcoind v0.19.0 in rpcclient and btcjson\n      packages (#1484)\n  - Contributors (alphabetical order):\n    - Eugene Zeigel\n    - Olaoluwa Osuntokun\n    - Wilmer Paulino\n\nChanges in v0.20.0 (Tue Oct 15 2019)\n  - Significant changes made since 0.12.0. See git log or refer to release\n    notes on GitHub for full details.\n  - Contributors (alphabetical order):\n    - Albert Puigsech Galicia\n    - Alex Akselrod\n    - Alex Bosworth\n    - Alex Manuskin\n    - Alok Menghrajani\n    - Anatoli Babenia\n    - Andy Weidenbaum\n    - Calvin McAnarney\n    - Chris Martin\n    - Chris Pacia\n    - Chris Shepherd\n    - Conner Fromknecht\n    - Craig Sturdy\n    - Cédric Félizard\n    - Daniel Krawisz\n    - Daniel Martí\n    - Daniel McNally\n    - Dario Nieuwenhuis\n    - Dave Collins\n    - David Hill\n    - David de Kloet\n    - GeertJohan\n    - Grace Noah\n    - Gregory Trubetskoy\n    - Hector Jusforgues\n    - Iskander (Alex) Sharipov\n    - Janus Troelsen\n    - Jasper\n    - Javed Khan\n    - Jeremiah Goyette\n    - Jim Posen\n    - Jimmy Song\n    - Johan T. Halseth\n    - John C. Vernaleo\n    - Jonathan Gillham\n    - Josh Rickmar\n    - Jon Underwood\n    - Jonathan Zeppettini\n    - Jouke Hofman\n    - Julian Meyer\n    - Kai\n    - Kamil Slowikowski\n    - Kefkius\n    - Leonardo Lazzaro\n    - Marco Peereboom\n    - Marko Bencun\n    - Mawueli Kofi Adzoe\n    - Michail Kargakis\n    - Mitchell Paull\n    - Nathan Bass\n    - Nicola 'tekNico' Larosa\n    - Olaoluwa Osuntokun\n    - Pedro Martelletto\n    - Ricardo Velhote\n    - Roei Erez\n    - Ruben de Vries\n    - Rune T. Aune\n    - Sad Pencil\n    - Shuai Qi\n    - Steven Roose\n    - Tadge Dryja\n    - Tibor Bősze\n    - Tomás Senart\n    - Tzu-Jung Lee\n    - Vadym Popov\n    - Waldir Pimenta\n    - Wilmer Paulino\n    - benma\n    - danda\n    - dskloet\n    - esemplastic\n    - jadeblaquiere\n    - nakagawa\n    - preminem\n    - qshuai\n\nChanges in 0.12.0 (Fri Nov 20 2015)\n  - Protocol and network related changes:\n    - Add a new checkpoint at block height 382320 (#555)\n    - Implement BIP0065 which includes support for version 4 blocks, a new\n      consensus opcode (OP_CHECKLOCKTIMEVERIFY) that enforces transaction\n      lock times, and a double-threshold switchover mechanism (#535, #459,\n      #455)\n    - Implement BIP0111 which provides a new bloom filter service flag and\n      hence provides support for protocol version 70011 (#499)\n    - Add a new parameter --nopeerbloomfilters to allow disabling bloom\n      filter support (#499)\n    - Reject non-canonically encoded variable length integers (#507)\n    - Add mainnet peer discovery DNS seed (seed.bitcoin.jonasschnelli.ch)\n      (#496)\n    - Correct reconnect handling for persistent peers (#463, #464)\n    - Ignore requests for block headers if not fully synced (#444)\n    - Add CLI support for specifying the zone id on IPv6 addresses (#538)\n    - Fix a couple of issues where the initial block sync could stall (#518,\n      #229, #486)\n    - Fix an issue which prevented the --onion option from working as\n      intended (#446)\n  - Transaction relay (memory pool) changes:\n    - Require transactions to only include signatures encoded with the\n    canonical 'low-s' encoding (#512)\n    - Add a new parameter --minrelaytxfee to allow the minimum transaction\n      fee in BTC/kB to be overridden (#520)\n    - Retain memory pool transactions when they redeem another one that is\n      removed when a block is accepted (#539)\n    - Do not send reject messages for a transaction if it is valid but\n      causes an orphan transaction which depends on it to be determined\n      as invalid (#546)\n    - Refrain from attempting to add orphans to the memory pool multiple\n      times when the transaction they redeem is added (#551)\n    - Modify minimum transaction fee calculations to scale based on bytes\n      instead of full kilobyte boundaries (#521, #537)\n  - Implement signature cache:\n    - Provides a limited memory cache of validated signatures which is a\n      huge optimization when verifying blocks for transactions that are\n      already in the memory pool (#506)\n    - Add a new parameter '--sigcachemaxsize' which allows the size of the\n      new cache to be manually changed if desired (#506)\n  - Mining support changes:\n    - Notify getblocktemplate long polling clients when a block is pushed\n      via submitblock (#488)\n    - Speed up getblocktemplate by making use of the new signature cache\n      (#506)\n  - RPC changes:\n    - Implement getmempoolinfo command (#453)\n    - Implement getblockheader command (#461)\n    - Modify createrawtransaction command to accept a new optional parameter\n      'locktime' (#529)\n    - Modify listunspent result to include the 'spendable' field (#440)\n    - Modify getinfo command to include 'errors' field (#511)\n    - Add timestamps to blockconnected and blockdisconnected notifications\n      (#450)\n    - Several modifications to searchrawtranscations command:\n      - Accept a new optional parameter 'vinextra' which causes the results\n        to include information about the outputs referenced by a transaction's\n        inputs (#485, #487)\n      - Skip entries in the mempool too (#495)\n      - Accept a new optional parameter 'reverse' to return the results in\n        reverse order (most recent to oldest) (#497)\n      - Accept a new optional parameter 'filteraddrs' which causes the\n        results to only include inputs and outputs which involve the\n        provided addresses (#516)\n    - Change the notification order to notify clients about mined\n      transactions (recvtx, redeemingtx) before the blockconnected\n      notification (#449)\n    - Update verifymessage RPC to use the standard algorithm so it is\n      compatible with other implementations (#515)\n    - Improve ping statistics by pinging on an interval (#517)\n  - Websocket changes:\n    - Implement session command which returns a per-session unique id (#500,\n      #503)\n  - btcctl utility changes:\n    - Add getmempoolinfo command (#453)\n    - Add getblockheader command (#461)\n    - Add getwalletinfo command (#471)\n  - Notable developer-related package changes:\n    - Introduce a new peer package which acts a common base for creating and\n      concurrently managing bitcoin network peers (#445)\n    - Various cleanup of the new peer package (#528, #531, #524, #534,\n      #549)\n    - Blocks heights now consistently use int32 everywhere (#481)\n    - The BlockHeader type in the wire package now provides the BtcDecode\n      and BtcEncode methods (#467)\n    - Update wire package to recognize BIP0064 (getutxo) service bit (#489)\n    - Export LockTimeThreshold constant from txscript package (#454)\n    - Export MaxDataCarrierSize constant from txscript package (#466)\n    - Provide new IsUnspendable function from the txscript package (#478)\n    - Export variable length string functions from the wire package (#514)\n    - Export DNS Seeds for each network from the chaincfg package (#544)\n    - Preliminary work towards separating the memory pool into a separate\n      package (#525, #548)\n  - Misc changes:\n    - Various documentation updates (#442, #462, #465, #460, #470, #473,\n      #505, #530, #545)\n    - Add installation instructions for gentoo (#542)\n    - Ensure an error is shown if OS limits can't be set at startup (#498)\n    - Tighten the standardness checks for multisig scripts (#526)\n    - Test coverage improvement (#468, #494, #527, #543, #550)\n    - Several optimizations (#457, #474, #475, #476, #508, #509)\n    - Minor code cleanup and refactoring (#472, #479, #482, #519, #540)\n  - Contributors (alphabetical order):\n    - Ben Echols\n    - Bruno Clermont\n    - danda\n    - Daniel Krawisz\n    - Dario Nieuwenhuis\n    - Dave Collins\n    - David Hill\n    - Javed Khan\n    - Jonathan Gillham\n    - Joseph Becher\n    - Josh Rickmar\n    - Justus Ranvier\n    - Mawuli Adzoe\n    - Olaoluwa Osuntokun\n    - Rune T. Aune\n\nChanges in 0.11.1 (Wed May 27 2015)\n  - Protocol and network related changes:\n    - Use correct sub-command in reject message for rejected transactions\n      (#436, #437)\n    - Add a new parameter --torisolation which forces new circuits for each\n      connection when using tor (#430)\n  - Transaction relay (memory pool) changes:\n    - Reduce the default number max number of allowed orphan transactions\n      to 1000 (#419)\n    - Add a new parameter --maxorphantx which allows the maximum number of\n      orphan transactions stored in the mempool to be specified (#419)\n  - RPC changes:\n    - Modify listtransactions result to include the 'involveswatchonly' and\n      'vout' fields (#427)\n    - Update getrawtransaction result to omit the 'confirmations' field\n      when it is 0 (#420, #422)\n    - Update signrawtransaction result to include errors (#423)\n  - btcctl utility changes:\n    - Add gettxoutproof command (#428)\n    - Add verifytxoutproof command (#428)\n  - Notable developer-related package changes:\n    - The btcec package now provides the ability to perform ECDH\n      encryption and decryption (#375)\n    - The block and header validation in the blockchain package has been\n      split to help pave the way toward concurrent downloads (#386)\n  - Misc changes:\n    - Minor peer optimization (#433)\n  - Contributors (alphabetical order):\n    - Dave Collins\n    - David Hill\n    - Federico Bond\n    - Ishbir Singh\n    - Josh Rickmar\n\nChanges in 0.11.0 (Wed May 06 2015)\n  - Protocol and network related changes:\n    - **IMPORTANT: Update is required due to the following point**\n    - Correct a few corner cases in script handling which could result in\n      forking from the network on non-standard transactions (#425)\n    - Add a new checkpoint at block height 352940 (#418)\n    - Optimized script execution (#395, #400, #404, #409)\n    - Fix a case that could lead stalled syncs (#138, #296)\n  - Network address manager changes:\n    - Implement eclipse attack countermeasures as proposed in\n      http://cs-people.bu.edu/heilman/eclipse (#370, #373)\n  - Optional address indexing changes:\n    - Fix an issue where a reorg could cause an orderly shutdown when the\n      address index is active (#340, #357)\n  - Transaction relay (memory pool) changes:\n    - Increase maximum allowed space for nulldata transactions to 80 bytes\n      (#331)\n    - Implement support for the following rules specified by BIP0062:\n      - The S value in ECDSA signature must be at most half the curve order\n        (rule 5) (#349)\n      - Script execution must result in a single non-zero value on the stack\n        (rule 6) (#347)\n      - NOTE: All 7 rules of BIP0062 are now implemented\n    - Use network adjusted time in finalized transaction checks to improve\n      consistency across nodes (#332)\n    - Process orphan transactions on acceptance of new transactions (#345)\n  - RPC changes:\n    - Add support for a limited RPC user which is not allowed admin level\n      operations on the server (#363)\n    - Implement node command for more unified control over connected peers\n      (#79, #341)\n    - Implement generate command for regtest/simnet to support\n      deterministically mining a specified number of blocks (#362, #407)\n    - Update searchrawtransactions to return the matching transactions in\n      order (#354)\n    - Correct an issue with searchrawtransactions where it could return\n      duplicates (#346, #354)\n    - Increase precision of 'difficulty' field in getblock result to 8\n      (#414, #415)\n    - Omit 'nextblockhash' field from getblock result when it is empty\n      (#416, #417)\n    - Add 'id' and 'timeoffset' fields to getpeerinfo result (#335)\n  - Websocket changes:\n    - Implement new commands stopnotifyspent, stopnotifyreceived,\n      stopnotifyblocks, and stopnotifynewtransactions to allow clients to\n      cancel notification registrations (#122, #342)\n  - btcctl utility changes:\n    - A single dash can now be used as an argument to cause that argument to\n      be read from stdin (#348)\n    - Add generate command\n  - Notable developer-related package changes:\n    - The new version 2 btcjson package has now replaced the deprecated\n      version 1 package (#368)\n    - The btcec package now performs all signing using RFC6979 deterministic\n      signatures (#358, #360)\n    - The txscript package has been significantly cleaned up and had a few\n      API changes (#387, #388, #389, #390, #391, #392, #393, #395, #396,\n      #400, #403, #404, #405, #406, #408, #409, #410, #412)\n    - A new PkScriptLocs function has been added to the wire package MsgTx\n      type which provides callers that deal with scripts optimization\n      opportunities (#343)\n  - Misc changes:\n    - Minor wire hashing optimizations (#366, #367)\n    - Other minor internal optimizations\n  - Contributors (alphabetical order):\n    - Alex Akselrod\n    - Arne Brutschy\n    - Chris Jepson\n    - Daniel Krawisz\n    - Dave Collins\n    - David Hill\n    - Jimmy Song\n    - Jonas Nick\n    - Josh Rickmar\n    - Olaoluwa Osuntokun\n    - Oleg Andreev\n\nChanges in 0.10.0 (Sun Mar 01 2015)\n  - Protocol and network related changes:\n    - Add a new checkpoint at block height 343185\n    - Implement BIP066 which includes support for version 3 blocks, a new\n      consensus rule which prevents non-DER encoded signatures, and a\n      double-threshold switchover mechanism\n    - Rather than announcing all known addresses on getaddr requests which\n      can possibly result in multiple messages, randomize the results and\n      limit them to the max allowed by a single message (1000 addresses)\n    - Add more reserved IP spaces to the address manager\n  - Transaction relay (memory pool) changes:\n    - Make transactions which contain reserved opcodes nonstandard\n    - No longer accept or relay free and low-fee transactions that have\n      insufficient priority to be mined in the next block\n    - Implement support for the following rules specified by BIP0062:\n      - ECDSA signature must use strict DER encoding (rule 1)\n      - The signature script must only contain push operations (rule 2)\n      - All push operations must use the smallest possible encoding (rule 3)\n      - All stack values interpreted as a number must be encoding using the\n        shortest possible form (rule 4)\n      - NOTE: Rule 1 was already enforced, however the entire script now\n        evaluates to false rather than only the signature verification as\n        required by BIP0062\n    - Allow transactions with nulldata transaction outputs to be treated as\n      standard\n  - Mining support changes:\n    - Modify the getblocktemplate RPC to generate and return block templates\n      for version 3 blocks which are compatible with BIP0066\n    - Allow getblocktemplate to serve blocks when the current time is\n      less than the minimum allowed time for a generated block template\n      (https://github.com/btcsuite/btcd/issues/209)\n  - Crypto changes:\n    - Optimize scalar multiplication by the base point by using a\n      pre-computed table which results in approximately a 35% speedup\n     (https://github.com/btcsuite/btcec/issues/2)\n    - Optimize general scalar multiplication by using the secp256k1\n      endomorphism which results in approximately a 17-20% speedup\n     (https://github.com/btcsuite/btcec/issues/1)\n    - Optimize general scalar multiplication by using non-adjacent form\n      which results in approximately an additional 8% speedup\n     (https://github.com/btcsuite/btcec/issues/3)\n  - Implement optional address indexing:\n    - Add a new parameter --addrindex which will enable the creation of an\n      address index which can be queried to determine all transactions which\n      involve a given address\n      (https://github.com/btcsuite/btcd/issues/190)\n    - Add a new logging subsystem for address index related operations\n    - Support new searchrawtransactions RPC\n      (https://github.com/btcsuite/btcd/issues/185)\n  - RPC changes:\n    - Require TLS version 1.2 as the minimum version for all TLS connections\n    - Provide support for disabling TLS when only listening on localhost\n      (https://github.com/btcsuite/btcd/pull/192)\n    - Modify help output for all commands to provide much more consistent\n      and detailed information\n    - Correct case in getrawtransaction which would refuse to serve certain\n      transactions with invalid scripts\n      (https://github.com/btcsuite/btcd/issues/210)\n    - Correct error handling in the getrawtransaction RPC which could lead\n      to a crash in rare cases\n      (https://github.com/btcsuite/btcd/issues/196)\n    - Update getinfo RPC to include the appropriate 'timeoffset' calculated\n      from the median network time\n    - Modify listreceivedbyaddress result type to include txids field so it\n      is compatible\n    - Add 'iswatchonly' field to validateaddress result\n    - Add 'startingpriority' and 'currentpriority' fields to getrawmempool\n      (https://github.com/btcsuite/btcd/issues/178)\n    - Don't omit the 'confirmations' field from getrawtransaction when it is\n      zero\n  - Websocket changes:\n    - Modify the behavior of the rescan command to automatically register\n      for notifications about transactions paying to rescanned addresses\n      or spending outputs from the final rescan utxo set when the rescan\n      is through the best block in the chain\n  - btcctl utility changes:\n    - Make the list of commands available via the -l option rather than\n      dumping the entire list on usage errors\n    - Alphabetize and categorize the list of commands by chain and wallet\n    - Make the help option only show the help options instead of also\n      dumping all of the commands\n    - Make the usage syntax much more consistent and correct a few cases of\n      misnamed fields\n      (https://github.com/btcsuite/btcd/issues/305)\n    - Improve usage errors to show the specific parameter number, reason,\n      and error code\n    - Only show the usage for specific command is shown when a valid command\n      is provided with invalid parameters\n    - Add support for a SOCK5 proxy\n    - Modify output for integer fields (such as timestamps) to display\n      normally instead in scientific notation\n    - Add invalidateblock command\n    - Add reconsiderblock command\n    - Add createnewaccount command\n    - Add renameaccount command\n    - Add searchrawtransactions command\n    - Add importaddress command\n    - Add importpubkey command\n  - showblock utility changes:\n    - Remove utility in favor of the RPC getblock method\n  - Notable developer-related package changes:\n    - Many of the core packages have been relocated into the btcd repository\n      (https://github.com/btcsuite/btcd/issues/214)\n    - A new version of the btcjson package that has been completely\n      redesigned from the ground up based based upon how the project has\n      evolved and lessons learned while using it since it was first written\n      is now available in the btcjson/v2/btcjson directory\n      - This will ultimately replace the current version so anyone making\n        use of this package will need to update their code accordingly\n    - The btcec package now provides better facilities for working directly\n      with its public and private keys without having to mix elements from\n      the ecdsa package\n    - Update the script builder to ensure all rules specified by BIP0062 are\n      adhered to when creating scripts\n    - The blockchain package now provides a MedianTimeSource interface and\n      concrete implementation for providing time samples from remote peers\n      and using that data to calculate an offset against the local time\n  - Misc changes:\n    - Fix a slow memory leak due to tickers not being stopped\n      (https://github.com/btcsuite/btcd/issues/189)\n    - Fix an issue where a mix of orphans and SPV clients could trigger a\n      condition where peers would no longer be served\n      (https://github.com/btcsuite/btcd/issues/231)\n    - The RPC username and password can now contain symbols which previously\n      conflicted with special symbols used in URLs\n    - Improve handling of obtaining random nonces to prevent cases where it\n      could error when not enough entropy was available\n    - Improve handling of home directory creation errors such as in the case\n      of unmounted symlinks (https://github.com/btcsuite/btcd/issues/193)\n    - Improve the error reporting for rejected transactions to include the\n      inputs which are missing and/or being double spent\n    - Update sample config file with new options and correct a comment\n      regarding the fact the RPC server only listens on localhost by default\n      (https://github.com/btcsuite/btcd/issues/218)\n    - Update the continuous integration builds to run several tools which\n      help keep code quality high\n    - Significant amount of internal code cleanup and improvements\n    - Other minor internal optimizations\n  - Code Contributors (alphabetical order):\n    - Beldur\n    - Ben Holden-Crowther\n    - Dave Collins\n    - David Evans\n    - David Hill\n    - Guilherme Salgado\n    - Javed Khan\n    - Jimmy Song\n    - John C. Vernaleo\n    - Jonathan Gillham\n    - Josh Rickmar\n    - Michael Ford\n    - Michail Kargakis\n    - kac\n    - Olaoluwa Osuntokun\n\nChanges in 0.9.0 (Sat Sep 20 2014)\n  - Protocol and network related changes:\n    - Add a new checkpoint at block height 319400\n    - Add support for BIP0037 bloom filters\n      (https://github.com/conformal/btcd/issues/132)\n    - Implement BIP0061 reject handling and hence support for protocol\n      version 70002 (https://github.com/conformal/btcd/issues/133)\n    - Add testnet DNS seeds for peer discovery (testnet-seed.alexykot.me\n      and testnet-seed.bitcoin.schildbach.de)\n    - Add mainnet DNS seed for peer discovery (seeds.bitcoin.open-nodes.org)\n    - Make multisig transactions with non-null dummy data nonstandard\n      (https://github.com/conformal/btcd/issues/131)\n    - Make transactions with an excessive number of signature operations\n      nonstandard\n    - Perform initial DNS lookups concurrently which allows connections\n      more quickly\n    - Improve the address manager to significantly reduce memory usage and\n      add tests\n    - Remove orphan transactions when they appear in a mined block\n      (https://github.com/conformal/btcd/issues/166)\n    - Apply incremental back off on connection retries for persistent peers\n      that give invalid replies to mirror the logic used for failed\n      connections (https://github.com/conformal/btcd/issues/103)\n    - Correct rate-limiting of free and low-fee transactions\n  - Mining support changes:\n    - Implement getblocktemplate RPC with the following support:\n      (https://github.com/conformal/btcd/issues/124)\n      - BIP0022 Non-Optional Sections\n      - BIP0022 Long Polling\n      - BIP0023 Basic Pool Extensions\n      - BIP0023 Mutation coinbase/append\n      - BIP0023 Mutations time, time/increment, and time/decrement\n      - BIP0023 Mutation transactions/add\n      - BIP0023 Mutations prevblock, coinbase, and generation\n      - BIP0023 Block Proposals\n    - Implement built-in concurrent CPU miner\n      (https://github.com/conformal/btcd/issues/137)\n      NOTE: CPU mining on mainnet is pointless.  This has been provided\n      for testing purposes such as for the new simulation test network\n    - Add --generate flag to enable CPU mining\n    - Deprecate the --getworkkey flag in favor of --miningaddr which\n      specifies which addresses generated blocks will choose from to pay\n      the subsidy to\n  - RPC changes:\n    - Implement gettxout command\n      (https://github.com/conformal/btcd/issues/141)\n    - Implement validateaddress command\n    - Implement verifymessage command\n    - Mark getunconfirmedbalance RPC as wallet-only\n    - Mark getwalletinfo RPC as wallet-only\n    - Update getgenerate, setgenerate, gethashespersec, and getmininginfo\n      to return the appropriate information about new CPU mining status\n    - Modify getpeerinfo pingtime and pingwait field types to float64 so\n      they are compatible\n    - Improve disconnect handling for normal HTTP clients\n    - Make error code returns for invalid hex more consistent\n  - Websocket changes:\n    - Switch to a new more efficient websocket package\n      (https://github.com/conformal/btcd/issues/134)\n    - Add rescanfinished notification\n    - Modify the rescanprogress notification to include block hash as well\n      as height (https://github.com/conformal/btcd/issues/151)\n  - btcctl utility changes:\n    - Accept --simnet flag which automatically selects the appropriate port\n      and TLS certificates needed to communicate with btcd and btcwallet on\n      the simulation test network\n    - Fix createrawtransaction command to send amounts denominated in BTC\n    - Add estimatefee command\n    - Add estimatepriority command\n    - Add getmininginfo command\n    - Add getnetworkinfo command\n    - Add gettxout command\n    - Add lockunspent command\n    - Add signrawtransaction command\n  - addblock utility changes:\n    - Accept --simnet flag which automatically selects the appropriate port\n      and TLS certificates needed to communicate with btcd and btcwallet on\n      the simulation test network\n  - Notable developer-related package changes:\n    - Provide a new bloom package in btcutil which allows creating and\n      working with BIP0037 bloom filters\n    - Provide a new hdkeychain package in btcutil which allows working with\n      BIP0032 hierarchical deterministic key chains\n    - Introduce a new btcnet package which houses network parameters\n    - Provide new simnet network (--simnet) which is useful for private\n      simulation testing\n    - Enforce low S values in serialized signatures as detailed in BIP0062\n    - Return errors from all methods on the btcdb.Db interface\n      (https://github.com/conformal/btcdb/issues/5)\n    - Allow behavior flags to alter btcchain.ProcessBlock\n      (https://github.com/conformal/btcchain/issues/5)\n    - Provide a new SerializeSize API for blocks\n      (https://github.com/conformal/btcwire/issues/19)\n    - Several of the core packages now work with Google App Engine\n  - Misc changes:\n    - Correct an issue where the database could corrupt under certain\n      circumstances which would require a new chain download\n    - Slightly optimize deserialization\n    - Use the correct IP block for he.net\n    - Fix an issue where it was possible the block manager could hang on\n      shutdown\n    - Update sample config file so the comments are on a separate line\n      rather than the end of a line so they are not interpreted as settings\n      (https://github.com/conformal/btcd/issues/135)\n    - Correct an issue where getdata requests were not being properly\n      throttled which could lead to larger than necessary memory usage\n    - Always show help when given the help flag even when the config file\n      contains invalid entries\n    - General code cleanup and minor optimizations\n\nChanges in 0.8.0-beta (Sun May 25 2014)\n  - Btcd is now Beta (https://github.com/conformal/btcd/issues/130)\n  - Add a new checkpoint at block height 300255\n  - Protocol and network related changes:\n    - Lower the minimum transaction relay fee to 1000 satoshi to match\n      recent reference client changes\n      (https://github.com/conformal/btcd/issues/100)\n    - Raise the maximum signature script size to support standard 15-of-15\n      multi-signature pay-to-script-hash transactions with compressed pubkeys\n      to remain compatible with the reference client\n      (https://github.com/conformal/btcd/issues/128)\n    - Reduce max bytes allowed for a standard nulldata transaction to 40 for\n      compatibility with the reference client\n    - Introduce a new btcnet package which houses all of the network params\n      for each network (mainnet, testnet3, regtest) to ultimately enable\n      easier addition and tweaking of networks without needing to change\n      several packages\n    - Fix several script discrepancies found by reference client test data\n    - Add new DNS seed for peer discovery (seed.bitnodes.io)\n    - Reduce the max known inventory cache from 20000 items to 1000 items\n    - Fix an issue where unknown inventory types could lead to a hung peer\n    - Implement inventory rebroadcast handler for sendrawtransaction\n      (https://github.com/conformal/btcd/issues/99)\n    - Update user agent to fully support BIP0014\n      (https://github.com/conformal/btcwire/issues/10)\n  - Implement initial mining support:\n    - Add a new logging subsystem for mining related operations\n    - Implement infrastructure for creating block templates\n    - Provide options to control block template creation settings\n    - Support the getwork RPC\n    - Allow address identifiers to apply to more than one network since both\n      testnet3 and the regression test network unfortunately use the same\n      identifier\n  - RPC changes:\n    - Set the content type for HTTP POST RPC connections to application/json\n      (https://github.com/conformal/btcd/issues/121)\n    - Modified the RPC server startup so it only requires at least one valid\n      listen interface\n    - Correct an error path where it was possible certain errors would not\n      be returned\n    - Implement getwork command\n      (https://github.com/conformal/btcd/issues/125)\n    - Update sendrawtransaction command to reject orphans\n    - Update sendrawtransaction command to include the reason a transaction\n      was rejected\n    - Update getinfo command to populate connection count field\n    - Update getinfo command to include relay fee field\n      (https://github.com/conformal/btcd/issues/107)\n    - Allow transactions submitted with sendrawtransaction to bypass the\n      rate limiter\n    - Allow the getcurrentnet and getbestblock extensions to be accessed via\n      HTTP POST in addition to Websockets\n      (https://github.com/conformal/btcd/issues/127)\n  - Websocket changes:\n    - Rework notifications to ensure they are delivered in the order they\n      occur\n    - Rename notifynewtxs command to notifyreceived (funds received)\n    - Rename notifyallnewtxs command to notifynewtransactions\n    - Rename alltx notification to txaccepted\n    - Rename allverbosetx notification to txacceptedverbose\n      (https://github.com/conformal/btcd/issues/98)\n    - Add rescan progress notification\n    - Add recvtx notification\n    - Add redeemingtx notification\n    - Modify notifyspent command to accept an array of outpoints\n      (https://github.com/conformal/btcd/issues/123)\n    - Significantly optimize the rescan command to yield up to a 60x speed\n      increase\n  - btcctl utility changes:\n    - Add createencryptedwallet command\n    - Add getblockchaininfo command\n    - Add importwallet command\n    - Add addmultisigaddress command\n    - Add setgenerate command\n    - Accept --testnet and --wallet flags which automatically select\n      the appropriate port and TLS certificates needed to communicate\n      with btcd and btcwallet (https://github.com/conformal/btcd/issues/112)\n    - Allow path expansion from config file entries\n      (https://github.com/conformal/btcd/issues/113)\n    - Minor refactor simplify handling of options\n  - addblock utility changes:\n    - Improve logging by making it consistent with the logging provided by\n      btcd (https://github.com/conformal/btcd/issues/90)\n  - Improve several package APIs for developers:\n    - Add new amount type for consistently handling monetary values\n    - Add new coin selector API\n    - Add new WIF (Wallet Import Format) API\n    - Add new crypto types for private keys and signatures\n    - Add new API to sign transactions including script merging and hash\n      types\n    - Expose function to extract all pushed data from a script\n      (https://github.com/conformal/btcscript/issues/8)\n  - Misc changes:\n    - Optimize address manager shuffling to do 67% less work on average\n    - Resolve a couple of benign data races found by the race detector\n      (https://github.com/conformal/btcd/issues/101)\n    - Add IP address to all peer related errors to clarify which peer is the\n      cause (https://github.com/conformal/btcd/issues/102)\n    - Fix a UPNP case issue that prevented the --upnp option from working\n      with some UPNP servers\n    - Update documentation in the sample config file regarding debug levels\n    - Adjust some logging levels to improve debug messages\n    - Improve the throughput of query messages to the block manager\n    - Several minor optimizations to reduce GC churn and enhance speed\n    - Other minor refactoring\n    - General code cleanup\n\nChanges in 0.7.0 (Thu Feb 20 2014)\n  - Fix an issue when parsing scripts which contain a multi-signature script\n    which require zero signatures such as testnet block\n    000000001881dccfeda317393c261f76d09e399e15e27d280e5368420f442632\n    (https://github.com/conformal/btcscript/issues/7)\n  - Add check to ensure all transactions accepted to mempool only contain\n    canonical data pushes (https://github.com/conformal/btcscript/issues/6)\n  - Fix an issue causing excessive memory consumption\n  - Significantly rework and improve the websocket notification system:\n    - Each client is now independent so slow clients no longer limit the\n      speed of other connected clients\n    - Potentially long-running operations such as rescans are now run in\n      their own handler and rate-limited to one operation at a time without\n      preventing simultaneous requests from the same client for the faster\n      requests or notifications\n    - A couple of scenarios which could cause shutdown to hang have been\n      resolved\n    - Update notifynewtx notifications to support all address types instead\n      of only pay-to-pubkey-hash\n    - Provide a --rpcmaxwebsockets option to allow limiting the number of\n      concurrent websocket clients\n    - Add a new websocket command notifyallnewtxs to request notifications\n      (https://github.com/conformal/btcd/issues/86) (thanks @flammit)\n  - Improve btcctl utility in the following ways:\n    - Add getnetworkhashps command\n    - Add gettransaction command (wallet-specific)\n    - Add signmessage command (wallet-specific)\n    - Update getwork command to accept\n  - Continue cleanup and work on implementing the RPC API:\n    - Implement getnettotals command\n      (https://github.com/conformal/btcd/issues/84)\n    - Implement networkhashps command\n      (https://github.com/conformal/btcd/issues/87)\n    - Update getpeerinfo to always include syncnode field even when false\n    - Remove help addenda for getpeerinfo now that it supports all fields\n  - Close standard RPC connections on auth failure\n  - Provide a --rpcmaxclients option to allow limiting the number of\n    concurrent RPC clients (https://github.com/conformal/btcd/issues/68)\n  - Include IP address in RPC auth failure log messages\n  - Resolve a rather harmless data races found by the race detector\n    (https://github.com/conformal/btcd/issues/94)\n  - Increase block priority size and max standard transaction size to 50k\n    and 100k, respectively (https://github.com/conformal/btcd/issues/71)\n  - Add rate limiting of free transactions to the memory pool to prevent\n    penny flooding (https://github.com/conformal/btcd/issues/40)\n  - Provide a --logdir option (https://github.com/conformal/btcd/issues/95)\n  - Change the default log file path to include the network\n  - Add a new ScriptBuilder interface to btcscript to support creation of\n    custom scripts (https://github.com/conformal/btcscript/issues/5)\n  - General code cleanup\n\nChanges in 0.6.0 (Tue Feb 04 2014)\n  - Fix an issue when parsing scripts which contain invalid signatures that\n    caused a chain fork on block\n    0000000000000001e4241fd0b3469a713f41c5682605451c05d3033288fb2244\n  - Correct an issue which could lead to an error in removeBlockNode\n    (https://github.com/conformal/btcchain/issues/4)\n  - Improve addblock utility as follows:\n    - Check imported blocks against all chain rules and checkpoints\n    - Skip blocks which are already known so you can stop and restart the\n      import or start the import after you have already downloaded a portion\n      of the chain\n    - Correct an issue where the utility did not shutdown cleanly after\n      processing all blocks\n    - Add error on attempt to import orphan blocks\n    - Improve error handling and reporting\n    - Display statistics after input file has been fully processed\n  - Rework, optimize, and improve headers-first mode:\n    - Resuming the chain sync from any point before the final checkpoint\n      will now use headers-first mode\n      (https://github.com/conformal/btcd/issues/69)\n    - Verify all checkpoints as opposed to only the final one\n    - Reduce and bound memory usage\n    - Rollback to the last known good point when a header does not match a\n      checkpoint\n    - Log information about what is happening with headers\n  - Improve btcctl utility in the following ways:\n    - Add getaddednodeinfo command\n    - Add getnettotals command\n    - Add getblocktemplate command (wallet-specific)\n    - Add getwork command (wallet-specific)\n    - Add getnewaddress command (wallet-specific)\n    - Add walletpassphrasechange command (wallet-specific)\n    - Add walletlock command (wallet-specific)\n    - Add sendfrom command (wallet-specific)\n    - Add sendmany command (wallet-specific)\n    - Add settxfee command (wallet-specific)\n    - Add listsinceblock command (wallet-specific)\n    - Add listaccounts command (wallet-specific)\n    - Add keypoolrefill command (wallet-specific)\n    - Add getreceivedbyaccount command (wallet-specific)\n    - Add getrawchangeaddress command (wallet-specific)\n    - Add gettxoutsetinfo command (wallet-specific)\n    - Add listaddressgroupings command (wallet-specific)\n    - Add listlockunspent command (wallet-specific)\n    - Add listlock command (wallet-specific)\n    - Add listreceivedbyaccount command (wallet-specific)\n    - Add validateaddress command (wallet-specific)\n    - Add verifymessage command (wallet-specific)\n    - Add sendtoaddress command (wallet-specific)\n  - Continue cleanup and work on implementing the RPC API:\n    - Implement submitblock command\n      (https://github.com/conformal/btcd/issues/61)\n    - Implement help command\n    - Implement ping command\n    - Implement getaddednodeinfo command\n      (https://github.com/conformal/btcd/issues/78)\n    - Implement getinfo command\n    - Update getpeerinfo to support bytesrecv and bytessent\n      (https://github.com/conformal/btcd/issues/83)\n  - Improve and correct several RPC server and websocket areas:\n    - Change the connection endpoint for websockets from /wallet to /ws\n      (https://github.com/conformal/btcd/issues/80)\n    - Implement an alternative authentication for websockets so clients\n      such as javascript from browsers that don't support setting HTTP\n      headers can authenticate (https://github.com/conformal/btcd/issues/77)\n    - Add an authentication deadline for RPC connections\n      (https://github.com/conformal/btcd/issues/68)\n    - Use standard authentication failure responses for RPC connections\n    - Make automatically generated certificate more standard so it works\n      from client such as node.js and Firefox\n    - Correct some minor issues which could prevent the RPC server from\n      shutting down in an orderly fashion\n    - Make all websocket notifications require registration\n    - Change the data sent over websockets to text since it is JSON-RPC\n    - Allow connections that do not have an Origin header set\n  - Expose and track the number of bytes read and written per peer\n    (https://github.com/conformal/btcwire/issues/6)\n  - Correct an issue with sendrawtransaction when invoked via websockets\n    which prevented a minedtx notification from being added\n  - Rescan operations issued from remote wallets are no stopped when\n    the wallet disconnects mid-operation\n    (https://github.com/conformal/btcd/issues/66)\n  - Several optimizations related to fetching block information from the\n    database\n  - General code cleanup\n\nChanges in 0.5.0 (Mon Jan 13 2014)\n  - Optimize initial block download by introducing a new mode which\n    downloads the block headers first (up to the final checkpoint)\n  - Improve peer handling to remove the potential for slow peers to cause\n    sluggishness amongst all peers\n    (https://github.com/conformal/btcd/issues/63)\n  - Fix an issue where the initial block sync could stall when the sync peer\n    disconnects (https://github.com/conformal/btcd/issues/62)\n  - Correct an issue where --externalip was doing a DNS lookup on the full\n    host:port instead of just the host portion\n    (https://github.com/conformal/btcd/issues/38)\n  - Fix an issue which could lead to a panic on chain switches\n    (https://github.com/conformal/btcd/issues/70)\n  - Improve btcctl utility in the following ways:\n    - Show getdifficulty output as floating point to 6 digits of precision\n    - Show all JSON object replies formatted as standard JSON\n    - Allow btcctl getblock to accept optional params\n    - Add getaccount command (wallet-specific)\n    - Add getaccountaddress command (wallet-specific)\n    - Add sendrawtransaction command\n  - Continue cleanup and work on implementing RPC API calls\n    - Update getrawmempool to support new optional verbose flag\n    - Update getrawtransaction to match the reference client\n    - Update getblock to support new optional verbose flag\n    - Update raw transactions to fully match the reference client including\n      support for all transaction types and address types\n    - Correct getrawmempool fee field to return BTC instead of Satoshi\n    - Correct getpeerinfo service flag to return 8 digit string so it\n      matches the reference client\n    - Correct verifychain to return a boolean\n    - Implement decoderawtransaction command\n    - Implement createrawtransaction command\n    - Implement decodescript command\n    - Implement gethashespersec command\n    - Allow RPC handler overrides when invoked via a websocket versus\n      legacy connection\n  - Add new DNS seed for peer discovery\n  - Display user agent on new valid peer log message\n    (https://github.com/conformal/btcd/issues/64)\n  - Notify wallet when new transactions that pay to registered addresses\n    show up in the mempool before being mined into a block\n  - Support a tor-specific proxy in addition to a normal proxy\n    (https://github.com/conformal/btcd/issues/47)\n  - Remove deprecated sqlite3 imports from utilities\n  - Remove leftover profile write from addblock utility\n  - Quite a bit of code cleanup and refactoring to improve maintainability\n\nChanges in 0.4.0 (Thu Dec 12 2013)\n  - Allow listen interfaces to be specified via --listen instead of only the\n    port (https://github.com/conformal/btcd/issues/33)\n  - Allow listen interfaces for the RPC server to be specified via\n    --rpclisten instead of only the port\n    (https://github.com/conformal/btcd/issues/34)\n  - Only disable listening when --connect or --proxy are used when no\n    --listen interface are specified\n    (https://github.com/conformal/btcd/issues/10)\n  - Add several new standard transaction checks to transaction memory pool:\n    - Support nulldata scripts as standard\n    - Only allow a max of one nulldata output per transaction\n    - Enforce a maximum of 3 public keys in multi-signature transactions\n    - The number of signatures in multi-signature transactions must not\n      exceed the number of public keys\n    - The number of inputs to a signature script must match the expected\n      number of inputs for the script type\n    - The number of inputs pushed onto the stack by a redeeming signature\n      script must match the number of inputs consumed by the referenced\n      public key script\n  - When a block is connected, remove any transactions from the memory pool\n    which are now double spends as a result of the newly connected\n    transactions\n  - Don't relay transactions resurrected during a chain switch since\n    other peers will also be switching chains and therefore already know\n    about them\n  - Cleanup a few cases where rejected transactions showed as an error\n    rather than as a rejected transaction\n  - Ignore the default configuration file when --regtest (regression test\n    mode) is specified\n  - Implement TLS support for RPC including automatic certificate generation\n  - Support HTTP authentication headers for web sockets\n  - Update address manager to recognize and properly work with Tor\n    addresses (https://github.com/conformal/btcd/issues/36) and\n    (https://github.com/conformal/btcd/issues/37)\n  - Improve btcctl utility in the following ways:\n    - Add the ability to specify a configuration file\n    - Add a default entry for the RPC cert to point to the location\n      it will likely be in the btcd home directory\n    - Implement --version flag\n    - Provide a --notls option to support non-TLS configurations\n  - Fix a couple of minor races found by the Go race detector\n  - Improve logging\n    - Allow logging level to be specified on a per subsystem basis\n      (https://github.com/conformal/btcd/issues/48)\n    - Allow logging levels to be dynamically changed via RPC\n      (https://github.com/conformal/btcd/issues/15)\n    - Implement a rolling log file with a max of 10MB per file and a\n      rotation size of 3 which results in a max logging size of 30 MB\n  - Correct a minor issue with the rescanning websocket call\n    (https://github.com/conformal/btcd/issues/54)\n  - Fix a race with pushing address messages that could lead to a panic\n    (https://github.com/conformal/btcd/issues/58)\n  - Improve which external IP address is reported to peers based on which\n    interface they are connected through\n    (https://github.com/conformal/btcd/issues/35)\n  - Add --externalip option to allow an external IP address to be specified\n    for cases such as tor hidden services or advanced network configurations\n    (https://github.com/conformal/btcd/issues/38)\n  - Add --upnp option to support automatic port mapping via UPnP\n    (https://github.com/conformal/btcd/issues/51)\n  - Update Ctrl+C interrupt handler to properly sync address manager and\n    remove the UPnP port mapping (if needed)\n  - Continue cleanup and work on implementing RPC API calls\n    - Add importprivkey (import private key) command to btcctl\n    - Update getrawtransaction to provide addresses properly, support\n      new verbose param, and match the reference implementation with the\n      exception of MULTISIG (thanks @flammit)\n    - Update getblock with new verbose flag (thanks @flammit)\n    - Add listtransactions command to btcctl\n    - Add getbalance command to btcctl\n  - Add basic support for btcd to run as a native Windows service\n    (https://github.com/conformal/btcd/issues/42)\n  - Package addblock utility with Windows MSIs\n  - Add support for TravisCI (continuous build integration)\n  - Cleanup some documentation and usage\n  - Several other minor bug fixes and general code cleanup\n\nChanges in 0.3.3 (Wed Nov 13 2013)\n  - Significantly improve initial block chain download speed\n    (https://github.com/conformal/btcd/issues/20)\n  - Add a new checkpoint at block height 267300\n  - Optimize most recently used inventory handling\n    (https://github.com/conformal/btcd/issues/21)\n  - Optimize duplicate transaction input check\n    (https://github.com/conformal/btcchain/issues/2)\n  - Optimize transaction hashing\n    (https://github.com/conformal/btcd/issues/25)\n  - Rework and optimize wallet listener notifications\n    (https://github.com/conformal/btcd/issues/22)\n  - Optimize serialization and deserialization\n    (https://github.com/conformal/btcd/issues/27)\n  - Add support for minimum transaction fee to memory pool acceptance\n    (https://github.com/conformal/btcd/issues/29)\n  - Improve leveldb database performance by removing explicit GC call\n  - Fix an issue where Ctrl+C was not always finishing orderly database\n    shutdown\n  - Fix an issue in the script handling for OP_CHECKSIG\n  - Impose max limits on all variable length protocol entries to prevent\n    abuse from malicious peers\n  - Enforce DER signatures for transactions allowed into the memory pool\n  - Separate the debug profile http server from the RPC server\n  - Rework of the RPC code to improve performance and make the code cleaner\n  - The getrawtransaction RPC call now properly checks the memory pool\n    before consulting the db (https://github.com/conformal/btcd/issues/26)\n  - Add support for the following RPC calls: getpeerinfo, getconnectedcount,\n    addnode, verifychain\n    (https://github.com/conformal/btcd/issues/13)\n    (https://github.com/conformal/btcd/issues/17)\n  - Implement rescan websocket extension to allow wallet rescans\n  - Use correct paths for application data storage for all supported\n    operating systems (https://github.com/conformal/btcd/issues/30)\n  - Add a default redirect to the http profiling page when accessing the\n    http profile server\n  - Add a new --cpuprofile option which can be used to generate CPU\n    profiling data on platforms that support it\n  - Several other minor performance optimizations\n  - Other minor bug fixes and general code cleanup\n\nChanges in 0.3.2 (Tue Oct 22 2013)\n  - Fix an issue that could cause the download of the block chain to stall\n    (https://github.com/conformal/btcd/issues/12)\n  - Remove deprecated sqlite as an available database backend\n  - Close sqlite compile issue as sqlite has now been removed\n    (https://github.com/conformal/btcd/issues/11)\n  - Change default RPC ports to 8334 (mainnet) and 18334 (testnet)\n  - Continue cleanup and work on implementing RPC API calls\n  - Add support for the following RPC calls: getrawmempool,\n    getbestblockhash, decoderawtransaction, getdifficulty,\n    getconnectioncount, getpeerinfo, and addnode\n  - Improve the btcctl utility that is used to issue JSON-RPC commands\n  - Fix an issue preventing btcd from cleanly shutting down with the RPC\n    stop command\n  - Add a number of database interface tests to ensure backends implement\n    the expected interface\n  - Expose some additional information from btcscript to be used for\n    identifying \"standard\"\" transactions\n  - Add support for plan9 - thanks @mischief\n    (https://github.com/conformal/btcd/pull/19)\n  - Other minor bug fixes and general code cleanup\n\nChanges in 0.3.1-alpha (Tue Oct 15 2013)\n  - Change default database to leveldb\n    NOTE: This does mean you will have to redownload the block chain.  Since we\n    are still in alpha, we didn't feel writing a converter was worth the time as\n    it would take away from more important issues at this stage\n  - Add a warning if there are multiple block chain databases of different types\n  - Fix issue with unexpected EOF in leveldb -- https://github.com/conformal/btcd/issues/18\n  - Fix issue preventing block 21066 on testnet -- https://github.com/conformal/btcchain/issues/1\n  - Fix issue preventing block 96464 on testnet -- https://github.com/conformal/btcscript/issues/1\n  - Optimize transaction lookups\n  - Correct a few cases of list removal that could result in improper cleanup\n    of no longer needed orphans\n  - Add functionality to increase ulimits on non-Windows platforms\n  - Add support for mempool command which allows remote peers to query the\n    transaction memory pool via the bitcoin protocol\n  - Clean up logging a bit\n  - Add a flag to disable checkpoints for developers\n  - Add a lot of useful debug logging such as message summaries\n  - Other minor bug fixes and general code cleanup\n\nInitial Release 0.3.0-alpha (Sat Oct 05 2013):\n  - Initial release\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.46875,
          "content": "# This Dockerfile builds btcd from source and creates a small (55 MB) docker container based on alpine linux.\n#\n# Clone this repository and run the following command to build and tag a fresh btcd amd64 container:\n#\n# docker build . -t yourregistry/btcd\n#\n# You can use the following command to build an arm64v8 container:\n#\n# docker build . -t yourregistry/btcd --build-arg ARCH=arm64v8\n#\n# For more information how to use this docker image visit:\n# https://github.com/btcsuite/btcd/tree/master/docs\n#\n# 8333  Mainnet Bitcoin peer-to-peer port\n# 8334  Mainet RPC port\n\nARG ARCH=amd64\n# using the SHA256 instead of tags\n# https://github.com/opencontainers/image-spec/blob/main/descriptor.md#digests\n# https://cloud.google.com/architecture/using-container-images\n# https://github.com/google/go-containerregistry/blob/main/cmd/crane/README.md\n# ➜  ~ crane digest golang:1.17.13-alpine3.16\n# sha256:c80567372be0d486766593cc722d3401038e2f150a0f6c5c719caa63afb4026a\nFROM golang@sha256:c80567372be0d486766593cc722d3401038e2f150a0f6c5c719caa63afb4026a AS build-container\n\nARG ARCH\n\nADD . /app\nWORKDIR /app\nRUN set -ex \\\n  && if [ \"${ARCH}\" = \"amd64\" ]; then export GOARCH=amd64; fi \\\n  && if [ \"${ARCH}\" = \"arm32v7\" ]; then export GOARCH=arm; fi \\\n  && if [ \"${ARCH}\" = \"arm64v8\" ]; then export GOARCH=arm64; fi \\\n  && echo \"Compiling for $GOARCH\" \\\n  && go install -v . ./cmd/...\n\nFROM $ARCH/alpine:3.16\n\nCOPY --from=build-container /go/bin /bin\n\nVOLUME [\"/root/.btcd\"]\n\nEXPOSE 8333 8334\n\nENTRYPOINT [\"btcd\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.783203125,
          "content": "ISC License\n\nCopyright (c) 2013-2024 The btcsuite developers\nCopyright (c) 2015-2016 The Decred developers\n\nPermission to use, copy, modify, and distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\nOR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 4.3701171875,
          "content": "PKG := github.com/btcsuite/btcd\n\nLINT_PKG := github.com/golangci/golangci-lint/cmd/golangci-lint\nGOACC_PKG := github.com/ory/go-acc\nGOIMPORTS_PKG := golang.org/x/tools/cmd/goimports\n\nGO_BIN := ${GOPATH}/bin\nLINT_BIN := $(GO_BIN)/golangci-lint\nGOACC_BIN := $(GO_BIN)/go-acc\n\nLINT_COMMIT := v1.18.0\nGOACC_COMMIT := 80342ae2e0fcf265e99e76bcc4efd022c7c3811b\n\nDEPGET := cd /tmp && go get -v\nGOBUILD := go build -v\nGOINSTALL := go install -v \nDEV_TAGS := rpctest\nGOTEST_DEV = go test -v -tags=$(DEV_TAGS)\nGOTEST := go test -v\n\nGOFILES_NOVENDOR = $(shell find . -type f -name '*.go' -not -path \"./vendor/*\")\n\nRM := rm -f\nCP := cp\nMAKE := make\nXARGS := xargs -L 1\n\n# Linting uses a lot of memory, so keep it under control by limiting the number\n# of workers if requested.\nifneq ($(workers),)\nLINT_WORKERS = --concurrency=$(workers)\nendif\n\nLINT = $(LINT_BIN) run -v $(LINT_WORKERS)\n\nGREEN := \"\\\\033[0;32m\"\nNC := \"\\\\033[0m\"\ndefine print\n\techo $(GREEN)$1$(NC)\nendef\n\n#? default: Run `make build`\ndefault: build\n\n#? all: Run `make build` and `make check`\nall: build check\n\n# ============\n# DEPENDENCIES\n# ============\n\n$(LINT_BIN):\n\t@$(call print, \"Fetching linter\")\n\t$(DEPGET) $(LINT_PKG)@$(LINT_COMMIT)\n\n$(GOACC_BIN):\n\t@$(call print, \"Fetching go-acc\")\n\t$(DEPGET) $(GOACC_PKG)@$(GOACC_COMMIT)\n\n#? goimports: Install goimports\ngoimports:\n\t@$(call print, \"Installing goimports.\")\n\t$(DEPGET) $(GOIMPORTS_PKG)\n\n# ============\n# INSTALLATION\n# ============\n\n#? build: Build all binaries, place them in project directory\nbuild:\n\t@$(call print, \"Building all binaries\")\n\t$(GOBUILD) $(PKG)\n\t$(GOBUILD) $(PKG)/cmd/btcctl\n\t$(GOBUILD) $(PKG)/cmd/gencerts\n\t$(GOBUILD) $(PKG)/cmd/findcheckpoint\n\t$(GOBUILD) $(PKG)/cmd/addblock\n\n#? install: Install all binaries, place them in $GOPATH/bin\ninstall:\n\t@$(call print, \"Installing all binaries\")\n\t$(GOINSTALL) $(PKG)\n\t$(GOINSTALL) $(PKG)/cmd/btcctl\n\t$(GOINSTALL) $(PKG)/cmd/gencerts\n\t$(GOINSTALL) $(PKG)/cmd/findcheckpoint\n\t$(GOINSTALL) $(PKG)/cmd/addblock\n\n#? release-install: Install btcd and btcctl release binaries, place them in $GOPATH/bin\nrelease-install:\n\t@$(call print, \"Installing btcd and btcctl release binaries\")\n\tenv CGO_ENABLED=0 $(GOINSTALL) -trimpath -ldflags=\"-s -w -buildid=\" $(PKG)\n\tenv CGO_ENABLED=0 $(GOINSTALL) -trimpath -ldflags=\"-s -w -buildid=\" $(PKG)/cmd/btcctl\n\n# =======\n# TESTING\n# =======\n\n#? check: Run `make unit`\ncheck: unit\n\n#? unit: Run unit tests\nunit:\n\t@$(call print, \"Running unit tests.\")\n\t$(GOTEST_DEV) ./... -test.timeout=20m\n\tcd btcec; $(GOTEST_DEV) ./... -test.timeout=20m\n\tcd btcutil; $(GOTEST_DEV) ./... -test.timeout=20m\n\tcd btcutil/psbt; $(GOTEST_DEV) ./... -test.timeout=20m\n\n#? unit-cover: Run unit coverage tests\nunit-cover: $(GOACC_BIN)\n\t@$(call print, \"Running unit coverage tests.\")\n\t$(GOACC_BIN) ./...\n\t\n\t# We need to remove the /v2 pathing from the module to have it work\n\t# nicely with the CI tool we use to render live code coverage.\n\tcd btcec; $(GOACC_BIN) ./...; sed -i.bak 's/v2\\///g' coverage.txt\n\n\tcd btcutil; $(GOACC_BIN) ./...\n\n\tcd btcutil/psbt; $(GOACC_BIN) ./...\n\n#? unit-race: Run unit race tests\nunit-race:\n\t@$(call print, \"Running unit race tests.\")\n\tenv CGO_ENABLED=1 GORACE=\"history_size=7 halt_on_errors=1\" $(GOTEST) -race -test.timeout=20m ./...\n\tcd btcec; env CGO_ENABLED=1 GORACE=\"history_size=7 halt_on_errors=1\" $(GOTEST) -race -test.timeout=20m ./...\n\tcd btcutil; env CGO_ENABLED=1 GORACE=\"history_size=7 halt_on_errors=1\" $(GOTEST) -race -test.timeout=20m ./...\n\tcd btcutil/psbt; env CGO_ENABLED=1 GORACE=\"history_size=7 halt_on_errors=1\" $(GOTEST) -race -test.timeout=20m ./...\n\n# =========\n# UTILITIES\n# =========\n\n#? fmt: Fix imports and formatting source\nfmt: goimports\n\t@$(call print, \"Fixing imports.\")\n\tgoimports -w $(GOFILES_NOVENDOR)\n\t@$(call print, \"Formatting source.\")\n\tgofmt -l -w -s $(GOFILES_NOVENDOR)\n\n#? lint: Lint source\nlint: $(LINT_BIN)\n\t@$(call print, \"Linting source.\")\n\t$(LINT)\n\n#? clean: Clean source\nclean:\n\t@$(call print, \"Cleaning source.$(NC)\")\n\t$(RM) coverage.txt btcec/coverage.txt btcutil/coverage.txt btcutil/psbt/coverage.txt\n\t\n#? tidy-module: Run 'go mod tidy' for all modules\ntidy-module:\n\techo \"Running 'go mod tidy' for all modules\"\n\tscripts/tidy_modules.sh\n\n.PHONY: all \\\n\tdefault \\\n\tbuild \\\n\tcheck \\\n\tunit \\\n\tunit-cover \\\n\tunit-race \\\n\tfmt \\\n\tlint \\\n\tclean\n\n#? help: Get more info on make commands\nhelp: Makefile\n\t@echo \" Choose a command run in btcd:\"\n\t@sed -n 's/^#?//p' $< | column -t -s ':' |  sort | sed -e 's/^/ /'\n\n.PHONY: help\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.3154296875,
          "content": "btcd\n====\n\n[![Build Status](https://github.com/btcsuite/btcd/workflows/Build%20and%20Test/badge.svg)](https://github.com/btcsuite/btcd/actions)\n[![Coverage Status](https://coveralls.io/repos/github/btcsuite/btcd/badge.svg?branch=master)](https://coveralls.io/github/btcsuite/btcd?branch=master)\n[![ISC License](https://img.shields.io/badge/license-ISC-blue.svg)](http://copyfree.org)\n[![GoDoc](https://img.shields.io/badge/godoc-reference-blue.svg)](https://pkg.go.dev/github.com/btcsuite/btcd)\n\nbtcd is an alternative full node bitcoin implementation written in Go (golang).\n\nThis project is currently under active development and is in a Beta state.  It\nis extremely stable and has been in production use since October 2013.\n\nIt properly downloads, validates, and serves the block chain using the exact\nrules (including consensus bugs) for block acceptance as Bitcoin Core.  We have\ntaken great care to avoid btcd causing a fork to the block chain.  It includes a\nfull block validation testing framework which contains all of the 'official'\nblock acceptance tests (and some additional ones) that is run on every pull\nrequest to help ensure it properly follows consensus.  Also, it passes all of\nthe JSON test data in the Bitcoin Core code.\n\nIt also properly relays newly mined blocks, maintains a transaction pool, and\nrelays individual transactions that have not yet made it into a block.  It\nensures all individual transactions admitted to the pool follow the rules\nrequired by the block chain and also includes more strict checks which filter\ntransactions based on miner requirements (\"standard\" transactions).\n\nOne key difference between btcd and Bitcoin Core is that btcd does *NOT* include\nwallet functionality and this was a very intentional design decision.  See the\nblog entry [here](https://web.archive.org/web/20171125143919/https://blog.conformal.com/btcd-not-your-moms-bitcoin-daemon)\nfor more details.  This means you can't actually make or receive payments\ndirectly with btcd.  That functionality is provided by the\n[btcwallet](https://github.com/btcsuite/btcwallet) and\n[Paymetheus](https://github.com/btcsuite/Paymetheus) (Windows-only) projects\nwhich are both under active development.\n\n## Requirements\n\n[Go](http://golang.org) 1.17 or newer.\n\n## Installation\n\nhttps://github.com/btcsuite/btcd/releases\n\n#### Linux/BSD/MacOSX/POSIX - Build from Source\n\n- Install Go according to the installation instructions here:\n  http://golang.org/doc/install\n\n- Ensure Go was installed properly and is a supported version:\n\n```bash\n$ go version\n$ go env GOROOT GOPATH\n```\n\nNOTE: The `GOROOT` and `GOPATH` above must not be the same path.  It is\nrecommended that `GOPATH` is set to a directory in your home directory such as\n`~/goprojects` to avoid write permission issues.  It is also recommended to add\n`$GOPATH/bin` to your `PATH` at this point.\n\n- Run the following commands to obtain btcd, all dependencies, and install it:\n\n```bash\n$ cd $GOPATH/src/github.com/btcsuite/btcd\n$ go install -v . ./cmd/...\n```\n\n- btcd (and utilities) will now be installed in ```$GOPATH/bin```.  If you did\n  not already add the bin directory to your system path during Go installation,\n  we recommend you do so now.\n\n## Updating\n\n#### Linux/BSD/MacOSX/POSIX - Build from Source\n\n- Run the following commands to update btcd, all dependencies, and install it:\n\n```bash\n$ cd $GOPATH/src/github.com/btcsuite/btcd\n$ git pull\n$ go install -v . ./cmd/...\n```\n\n## Getting Started\n\nbtcd has several configuration options available to tweak how it runs, but all\nof the basic operations described in the intro section work with zero\nconfiguration.\n\n#### Linux/BSD/POSIX/Source\n\n```bash\n$ ./btcd\n```\n\n## IRC\n\n- irc.libera.chat\n- channel #btcd\n- [webchat](https://web.libera.chat/gamja/?channels=btcd)\n\n## Issue Tracker\n\nThe [integrated github issue tracker](https://github.com/btcsuite/btcd/issues)\nis used for this project.\n\n## Documentation\n\nThe documentation is a work-in-progress.  It is located in the [docs](https://github.com/btcsuite/btcd/tree/master/docs) folder.\n\n## Release Verification\n\nPlease see our [documentation on the current build/verification\nprocess](https://github.com/btcsuite/btcd/tree/master/release) for all our\nreleases for information on how to verify the integrity of published releases\nusing our reproducible build system.\n\n## License\n\nbtcd is licensed under the [copyfree](http://copyfree.org) ISC License.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.5234375,
          "content": "# Security Policy\n\n## Supported Versions\n\nThe last major `btcd` release is to be considered the current support version.\nGiven an issue severe enough, a backport will be issued either to the prior\nmajor release or the set of releases considered utilized enough. \n\n## Reporting a Vulnerability\n\nTo report security issues, send an email to security@lightning.engineering\n(this list isn't to be used for support). \n\nThe following key can be used to communicate sensitive information: `91FE 464C\nD751 01DA 6B6B  AB60 555C 6465 E5BC B3AF`. \n"
        },
        {
          "name": "addrmgr",
          "type": "tree",
          "content": null
        },
        {
          "name": "blockchain",
          "type": "tree",
          "content": null
        },
        {
          "name": "btcd.go",
          "type": "blob",
          "size": 14.052734375,
          "content": "// Copyright (c) 2013-2016 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t_ \"net/http/pprof\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"runtime/pprof\"\n\t\"runtime/trace\"\n\n\t\"github.com/btcsuite/btcd/blockchain/indexers\"\n\t\"github.com/btcsuite/btcd/database\"\n\t\"github.com/btcsuite/btcd/limits\"\n\t\"github.com/btcsuite/btcd/ossec\"\n)\n\nconst (\n\t// blockDbNamePrefix is the prefix for the block database name.  The\n\t// database type is appended to this value to form the full block\n\t// database name.\n\tblockDbNamePrefix = \"blocks\"\n)\n\nvar (\n\tcfg *config\n)\n\n// winServiceMain is only invoked on Windows.  It detects when btcd is running\n// as a service and reacts accordingly.\nvar winServiceMain func() (bool, error)\n\n// btcdMain is the real main function for btcd.  It is necessary to work around\n// the fact that deferred functions do not run when os.Exit() is called.  The\n// optional serverChan parameter is mainly used by the service code to be\n// notified with the server once it is setup so it can gracefully stop it when\n// requested from the service control manager.\nfunc btcdMain(serverChan chan<- *server) error {\n\t// Load configuration and parse command line.  This function also\n\t// initializes logging and configures it accordingly.\n\ttcfg, _, err := loadConfig()\n\tif err != nil {\n\t\treturn err\n\t}\n\tcfg = tcfg\n\tdefer func() {\n\t\tif logRotator != nil {\n\t\t\tlogRotator.Close()\n\t\t}\n\t}()\n\n\t// Get a channel that will be closed when a shutdown signal has been\n\t// triggered either from an OS signal such as SIGINT (Ctrl+C) or from\n\t// another subsystem such as the RPC server.\n\tinterrupt := interruptListener()\n\tdefer btcdLog.Info(\"Shutdown complete\")\n\n\t// Show version at startup.\n\tbtcdLog.Infof(\"Version %s\", version())\n\n\t// Enable http profiling server if requested.\n\tif cfg.Profile != \"\" {\n\t\tgo func() {\n\t\t\tlistenAddr := net.JoinHostPort(\"\", cfg.Profile)\n\t\t\tbtcdLog.Infof(\"Profile server listening on %s\", listenAddr)\n\t\t\tprofileRedirect := http.RedirectHandler(\"/debug/pprof\",\n\t\t\t\thttp.StatusSeeOther)\n\t\t\thttp.Handle(\"/\", profileRedirect)\n\t\t\tbtcdLog.Errorf(\"%v\", http.ListenAndServe(listenAddr, nil))\n\t\t}()\n\t}\n\n\t// Write cpu profile if requested.\n\tif cfg.CPUProfile != \"\" {\n\t\tf, err := os.Create(cfg.CPUProfile)\n\t\tif err != nil {\n\t\t\tbtcdLog.Errorf(\"Unable to create cpu profile: %v\", err)\n\t\t\treturn err\n\t\t}\n\t\tpprof.StartCPUProfile(f)\n\t\tdefer f.Close()\n\t\tdefer pprof.StopCPUProfile()\n\t}\n\n\t// Write mem profile if requested.\n\tif cfg.MemoryProfile != \"\" {\n\t\tf, err := os.Create(cfg.MemoryProfile)\n\t\tif err != nil {\n\t\t\tbtcdLog.Errorf(\"Unable to create memory profile: %v\", err)\n\t\t\treturn err\n\t\t}\n\t\tdefer f.Close()\n\t\tdefer pprof.WriteHeapProfile(f)\n\t\tdefer runtime.GC()\n\t}\n\n\t// Write execution trace if requested.\n\tif cfg.TraceProfile != \"\" {\n\t\tf, err := os.Create(cfg.TraceProfile)\n\t\tif err != nil {\n\t\t\tbtcdLog.Errorf(\"Unable to create execution trace: %v\", err)\n\t\t\treturn err\n\t\t}\n\t\ttrace.Start(f)\n\t\tdefer f.Close()\n\t\tdefer trace.Stop()\n\t}\n\n\t// Perform upgrades to btcd as new versions require it.\n\tif err := doUpgrades(); err != nil {\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\n\t// Return now if an interrupt signal was triggered.\n\tif interruptRequested(interrupt) {\n\t\treturn nil\n\t}\n\n\t// Load the block database.\n\tdb, err := loadBlockDB()\n\tif err != nil {\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\tdefer func() {\n\t\t// Ensure the database is sync'd and closed on shutdown.\n\t\tbtcdLog.Infof(\"Gracefully shutting down the database...\")\n\t\tdb.Close()\n\t}()\n\n\t// Return now if an interrupt signal was triggered.\n\tif interruptRequested(interrupt) {\n\t\treturn nil\n\t}\n\n\t// Drop indexes and exit if requested.\n\t//\n\t// NOTE: The order is important here because dropping the tx index also\n\t// drops the address index since it relies on it.\n\tif cfg.DropAddrIndex {\n\t\tif err := indexers.DropAddrIndex(db, interrupt); err != nil {\n\t\t\tbtcdLog.Errorf(\"%v\", err)\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}\n\tif cfg.DropTxIndex {\n\t\tif err := indexers.DropTxIndex(db, interrupt); err != nil {\n\t\t\tbtcdLog.Errorf(\"%v\", err)\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}\n\tif cfg.DropCfIndex {\n\t\tif err := indexers.DropCfIndex(db, interrupt); err != nil {\n\t\t\tbtcdLog.Errorf(\"%v\", err)\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}\n\n\t// Check if the database had previously been pruned.  If it had been, it's\n\t// not possible to newly generate the tx index and addr index.\n\tvar beenPruned bool\n\tdb.View(func(dbTx database.Tx) error {\n\t\tbeenPruned, err = dbTx.BeenPruned()\n\t\treturn err\n\t})\n\tif err != nil {\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\tif beenPruned && cfg.Prune == 0 {\n\t\terr = fmt.Errorf(\"--prune cannot be disabled as the node has been \"+\n\t\t\t\"previously pruned. You must delete the files in the datadir: \\\"%s\\\" \"+\n\t\t\t\"and sync from the beginning to disable pruning\", cfg.DataDir)\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\tif beenPruned && cfg.TxIndex {\n\t\terr = fmt.Errorf(\"--txindex cannot be enabled as the node has been \"+\n\t\t\t\"previously pruned. You must delete the files in the datadir: \\\"%s\\\" \"+\n\t\t\t\"and sync from the beginning to enable the desired index\", cfg.DataDir)\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\tif beenPruned && cfg.AddrIndex {\n\t\terr = fmt.Errorf(\"--addrindex cannot be enabled as the node has been \"+\n\t\t\t\"previously pruned. You must delete the files in the datadir: \\\"%s\\\" \"+\n\t\t\t\"and sync from the beginning to enable the desired index\", cfg.DataDir)\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\t// If we've previously been pruned and the cfindex isn't present, it means that the\n\t// user wants to enable the cfindex after the node has already synced up and been\n\t// pruned.\n\tif beenPruned && !indexers.CfIndexInitialized(db) && !cfg.NoCFilters {\n\t\terr = fmt.Errorf(\"compact filters cannot be enabled as the node has been \"+\n\t\t\t\"previously pruned. You must delete the files in the datadir: \\\"%s\\\" \"+\n\t\t\t\"and sync from the beginning to enable the desired index. You may \"+\n\t\t\t\"use the --nocfilters flag to start the node up without the compact \"+\n\t\t\t\"filters\", cfg.DataDir)\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\t// If the user wants to disable the cfindex and is pruned or has enabled pruning, force\n\t// the user to either drop the cfindex manually or restart the node without the --nocfilters\n\t// flag.\n\tif (beenPruned || cfg.Prune != 0) && indexers.CfIndexInitialized(db) && cfg.NoCFilters {\n\t\terr = fmt.Errorf(\"--nocfilters flag was given but the compact filters have \" +\n\t\t\t\"previously been enabled on this node and the index data currently \" +\n\t\t\t\"exists in the database. The node has also been previously pruned and \" +\n\t\t\t\"the database would be left in an inconsistent state if the compact \" +\n\t\t\t\"filters don't get indexed now. To disable compact filters, please drop the \" +\n\t\t\t\"index completely with the --dropcfindex flag and restart the node. \" +\n\t\t\t\"To keep the compact filters, restart the node without the --nocfilters \" +\n\t\t\t\"flag\")\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\n\t// Enforce removal of txindex and addrindex if user requested pruning.\n\t// This is to require explicit action from the user before removing\n\t// indexes that won't be useful when block files are pruned.\n\t//\n\t// NOTE: The order is important here because dropping the tx index also\n\t// drops the address index since it relies on it.  We explicitly make the\n\t// user drop both indexes if --addrindex was enabled previously.\n\tif cfg.Prune != 0 && indexers.AddrIndexInitialized(db) {\n\t\terr = fmt.Errorf(\"--prune flag may not be given when the address index \" +\n\t\t\t\"has been initialized. Please drop the address index with the \" +\n\t\t\t\"--dropaddrindex flag before enabling pruning\")\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\tif cfg.Prune != 0 && indexers.TxIndexInitialized(db) {\n\t\terr = fmt.Errorf(\"--prune flag may not be given when the transaction index \" +\n\t\t\t\"has been initialized. Please drop the transaction index with the \" +\n\t\t\t\"--droptxindex flag before enabling pruning\")\n\t\tbtcdLog.Errorf(\"%v\", err)\n\t\treturn err\n\t}\n\n\t// The config file is already created if it did not exist and the log\n\t// file has already been opened by now so we only need to allow\n\t// creating rpc cert and key files if they don't exist.\n\tunveilx(cfg.RPCKey, \"rwc\")\n\tunveilx(cfg.RPCCert, \"rwc\")\n\tunveilx(cfg.DataDir, \"rwc\")\n\n\t// drop unveil and tty\n\tpledgex(\"stdio rpath wpath cpath flock dns inet\")\n\n\t// Create server and start it.\n\tserver, err := newServer(cfg.Listeners, cfg.AgentBlacklist,\n\t\tcfg.AgentWhitelist, db, activeNetParams.Params, interrupt)\n\tif err != nil {\n\t\t// TODO: this logging could do with some beautifying.\n\t\tbtcdLog.Errorf(\"Unable to start server on %v: %v\",\n\t\t\tcfg.Listeners, err)\n\t\treturn err\n\t}\n\tdefer func() {\n\t\tbtcdLog.Infof(\"Gracefully shutting down the server...\")\n\t\tserver.Stop()\n\t\tserver.WaitForShutdown()\n\t\tsrvrLog.Infof(\"Server shutdown complete\")\n\t}()\n\tserver.Start()\n\tif serverChan != nil {\n\t\tserverChan <- server\n\t}\n\n\t// Wait until the interrupt signal is received from an OS signal or\n\t// shutdown is requested through one of the subsystems such as the RPC\n\t// server.\n\t<-interrupt\n\treturn nil\n}\n\n// removeRegressionDB removes the existing regression test database if running\n// in regression test mode and it already exists.\nfunc removeRegressionDB(dbPath string) error {\n\t// Don't do anything if not in regression test mode.\n\tif !cfg.RegressionTest {\n\t\treturn nil\n\t}\n\n\t// Remove the old regression test database if it already exists.\n\tfi, err := os.Stat(dbPath)\n\tif err == nil {\n\t\tbtcdLog.Infof(\"Removing regression test database from '%s'\", dbPath)\n\t\tif fi.IsDir() {\n\t\t\terr := os.RemoveAll(dbPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\terr := os.Remove(dbPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// dbPath returns the path to the block database given a database type.\nfunc blockDbPath(dbType string) string {\n\t// The database name is based on the database type.\n\tdbName := blockDbNamePrefix + \"_\" + dbType\n\tif dbType == \"sqlite\" {\n\t\tdbName = dbName + \".db\"\n\t}\n\tdbPath := filepath.Join(cfg.DataDir, dbName)\n\treturn dbPath\n}\n\n// warnMultipleDBs shows a warning if multiple block database types are detected.\n// This is not a situation most users want.  It is handy for development however\n// to support multiple side-by-side databases.\nfunc warnMultipleDBs() {\n\t// This is intentionally not using the known db types which depend\n\t// on the database types compiled into the binary since we want to\n\t// detect legacy db types as well.\n\tdbTypes := []string{\"ffldb\", \"leveldb\", \"sqlite\"}\n\tduplicateDbPaths := make([]string, 0, len(dbTypes)-1)\n\tfor _, dbType := range dbTypes {\n\t\tif dbType == cfg.DbType {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Store db path as a duplicate db if it exists.\n\t\tdbPath := blockDbPath(dbType)\n\t\tif fileExists(dbPath) {\n\t\t\tduplicateDbPaths = append(duplicateDbPaths, dbPath)\n\t\t}\n\t}\n\n\t// Warn if there are extra databases.\n\tif len(duplicateDbPaths) > 0 {\n\t\tselectedDbPath := blockDbPath(cfg.DbType)\n\t\tbtcdLog.Warnf(\"WARNING: There are multiple block chain databases \"+\n\t\t\t\"using different database types.\\nYou probably don't \"+\n\t\t\t\"want to waste disk space by having more than one.\\n\"+\n\t\t\t\"Your current database is located at [%v].\\nThe \"+\n\t\t\t\"additional database is located at %v\", selectedDbPath,\n\t\t\tduplicateDbPaths)\n\t}\n}\n\n// loadBlockDB loads (or creates when needed) the block database taking into\n// account the selected database backend and returns a handle to it.  It also\n// contains additional logic such warning the user if there are multiple\n// databases which consume space on the file system and ensuring the regression\n// test database is clean when in regression test mode.\nfunc loadBlockDB() (database.DB, error) {\n\t// The memdb backend does not have a file path associated with it, so\n\t// handle it uniquely.  We also don't want to worry about the multiple\n\t// database type warnings when running with the memory database.\n\tif cfg.DbType == \"memdb\" {\n\t\tbtcdLog.Infof(\"Creating block database in memory.\")\n\t\tdb, err := database.Create(cfg.DbType)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn db, nil\n\t}\n\n\twarnMultipleDBs()\n\n\t// The database name is based on the database type.\n\tdbPath := blockDbPath(cfg.DbType)\n\n\t// The regression test is special in that it needs a clean database for\n\t// each run, so remove it now if it already exists.\n\tremoveRegressionDB(dbPath)\n\n\tbtcdLog.Infof(\"Loading block database from '%s'\", dbPath)\n\tdb, err := database.Open(cfg.DbType, dbPath, activeNetParams.Net)\n\tif err != nil {\n\t\t// Return the error if it's not because the database doesn't\n\t\t// exist.\n\t\tif dbErr, ok := err.(database.Error); !ok || dbErr.ErrorCode !=\n\t\t\tdatabase.ErrDbDoesNotExist {\n\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Create the db if it does not exist.\n\t\terr = os.MkdirAll(cfg.DataDir, 0700)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdb, err = database.Create(cfg.DbType, dbPath, activeNetParams.Net)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tbtcdLog.Info(\"Block database loaded\")\n\treturn db, nil\n}\n\nfunc unveilx(path string, perms string) {\n\terr := ossec.Unveil(path, perms)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"unveil failed: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n}\n\nfunc pledgex(promises string) {\n\terr := ossec.PledgePromises(promises)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"pledge failed: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n}\n\nfunc init() {\n\tpledgex(\"unveil stdio id rpath wpath cpath flock dns inet tty\")\n}\n\nfunc main() {\n\t// If GOGC is not explicitly set, override GC percent.\n\tif os.Getenv(\"GOGC\") == \"\" {\n\t\t// Block and transaction processing can cause bursty allocations.  This\n\t\t// limits the garbage collector from excessively overallocating during\n\t\t// bursts.  This value was arrived at with the help of profiling live\n\t\t// usage.\n\t\tdebug.SetGCPercent(10)\n\t}\n\n\t// Up some limits.\n\tif err := limits.SetLimits(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"failed to set limits: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Call serviceMain on Windows to handle running as a service.  When\n\t// the return isService flag is true, exit now since we ran as a\n\t// service.  Otherwise, just fall through to normal operation.\n\tif runtime.GOOS == \"windows\" {\n\t\tisService, err := winServiceMain()\n\t\tif err != nil {\n\t\t\tfmt.Println(err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif isService {\n\t\t\tos.Exit(0)\n\t\t}\n\t}\n\n\t// Work around defer not working after os.Exit()\n\tif err := btcdMain(nil); err != nil {\n\t\tos.Exit(1)\n\t}\n}\n"
        },
        {
          "name": "btcec",
          "type": "tree",
          "content": null
        },
        {
          "name": "btcjson",
          "type": "tree",
          "content": null
        },
        {
          "name": "btcutil",
          "type": "tree",
          "content": null
        },
        {
          "name": "chaincfg",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 49.2412109375,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"bufio\"\n\t\"crypto/rand\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/chaincfg\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/connmgr\"\n\t\"github.com/btcsuite/btcd/database\"\n\t_ \"github.com/btcsuite/btcd/database/ffldb\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/peer\"\n\t\"github.com/btcsuite/btcd/wire\"\n\t\"github.com/btcsuite/go-socks/socks\"\n\tflags \"github.com/jessevdk/go-flags\"\n)\n\nconst (\n\tdefaultConfigFilename        = \"btcd.conf\"\n\tdefaultDataDirname           = \"data\"\n\tdefaultLogLevel              = \"info\"\n\tdefaultLogDirname            = \"logs\"\n\tdefaultLogFilename           = \"btcd.log\"\n\tdefaultMaxPeers              = 125\n\tdefaultBanDuration           = time.Hour * 24\n\tdefaultBanThreshold          = 100\n\tdefaultConnectTimeout        = time.Second * 30\n\tdefaultMaxRPCClients         = 10\n\tdefaultMaxRPCWebsockets      = 25\n\tdefaultMaxRPCConcurrentReqs  = 20\n\tdefaultDbType                = \"ffldb\"\n\tdefaultFreeTxRelayLimit      = 15.0\n\tdefaultTrickleInterval       = peer.DefaultTrickleInterval\n\tdefaultBlockMinSize          = 0\n\tdefaultBlockMaxSize          = 750000\n\tdefaultBlockMinWeight        = 0\n\tdefaultBlockMaxWeight        = 3000000\n\tblockMaxSizeMin              = 1000\n\tblockMaxSizeMax              = blockchain.MaxBlockBaseSize - 1000\n\tblockMaxWeightMin            = 4000\n\tblockMaxWeightMax            = blockchain.MaxBlockWeight - 4000\n\tdefaultGenerate              = false\n\tdefaultMaxOrphanTransactions = 100\n\tdefaultMaxOrphanTxSize       = 100000\n\tdefaultSigCacheMaxSize       = 100000\n\tdefaultUtxoCacheMaxSizeMiB   = 250\n\tsampleConfigFilename         = \"sample-btcd.conf\"\n\tdefaultTxIndex               = false\n\tdefaultAddrIndex             = false\n\tpruneMinSize                 = 1536\n)\n\nvar (\n\tdefaultHomeDir     = btcutil.AppDataDir(\"btcd\", false)\n\tdefaultConfigFile  = filepath.Join(defaultHomeDir, defaultConfigFilename)\n\tdefaultDataDir     = filepath.Join(defaultHomeDir, defaultDataDirname)\n\tknownDbTypes       = database.SupportedDrivers()\n\tdefaultRPCKeyFile  = filepath.Join(defaultHomeDir, \"rpc.key\")\n\tdefaultRPCCertFile = filepath.Join(defaultHomeDir, \"rpc.cert\")\n\tdefaultLogDir      = filepath.Join(defaultHomeDir, defaultLogDirname)\n)\n\n// runServiceCommand is only set to a real function on Windows.  It is used\n// to parse and execute service commands specified via the -s flag.\nvar runServiceCommand func(string) error\n\n// minUint32 is a helper function to return the minimum of two uint32s.\n// This avoids a math import and the need to cast to floats.\nfunc minUint32(a, b uint32) uint32 {\n\tif a < b {\n\t\treturn a\n\t}\n\treturn b\n}\n\n// config defines the configuration options for btcd.\n//\n// See loadConfig for details on the configuration load process.\ntype config struct {\n\tAddCheckpoints       []string      `long:\"addcheckpoint\" description:\"Add a custom checkpoint.  Format: '<height>:<hash>'\"`\n\tAddPeers             []string      `short:\"a\" long:\"addpeer\" description:\"Add a peer to connect with at startup\"`\n\tAddrIndex            bool          `long:\"addrindex\" description:\"Maintain a full address-based transaction index which makes the searchrawtransactions RPC available\"`\n\tAgentBlacklist       []string      `long:\"agentblacklist\" description:\"A comma separated list of user-agent substrings which will cause btcd to reject any peers whose user-agent contains any of the blacklisted substrings.\"`\n\tAgentWhitelist       []string      `long:\"agentwhitelist\" description:\"A comma separated list of user-agent substrings which will cause btcd to require all peers' user-agents to contain one of the whitelisted substrings. The blacklist is applied before the whitelist, and an empty whitelist will allow all agents that do not fail the blacklist.\"`\n\tBanDuration          time.Duration `long:\"banduration\" description:\"How long to ban misbehaving peers.  Valid time units are {s, m, h}.  Minimum 1 second\"`\n\tBanThreshold         uint32        `long:\"banthreshold\" description:\"Maximum allowed ban score before disconnecting and banning misbehaving peers.\"`\n\tBlockMaxSize         uint32        `long:\"blockmaxsize\" description:\"Maximum block size in bytes to be used when creating a block\"`\n\tBlockMinSize         uint32        `long:\"blockminsize\" description:\"Minimum block size in bytes to be used when creating a block\"`\n\tBlockMaxWeight       uint32        `long:\"blockmaxweight\" description:\"Maximum block weight to be used when creating a block\"`\n\tBlockMinWeight       uint32        `long:\"blockminweight\" description:\"Minimum block weight to be used when creating a block\"`\n\tBlockPrioritySize    uint32        `long:\"blockprioritysize\" description:\"Size in bytes for high-priority/low-fee transactions when creating a block\"`\n\tBlocksOnly           bool          `long:\"blocksonly\" description:\"Do not accept transactions from remote peers.\"`\n\tConfigFile           string        `short:\"C\" long:\"configfile\" description:\"Path to configuration file\"`\n\tConnectPeers         []string      `long:\"connect\" description:\"Connect only to the specified peers at startup\"`\n\tCPUProfile           string        `long:\"cpuprofile\" description:\"Write CPU profile to the specified file\"`\n\tMemoryProfile        string        `long:\"memprofile\" description:\"Write memory profile to the specified file\"`\n\tTraceProfile         string        `long:\"traceprofile\" description:\"Write execution trace to the specified file\"`\n\tDataDir              string        `short:\"b\" long:\"datadir\" description:\"Directory to store data\"`\n\tDbType               string        `long:\"dbtype\" description:\"Database backend to use for the Block Chain\"`\n\tDebugLevel           string        `short:\"d\" long:\"debuglevel\" description:\"Logging level for all subsystems {trace, debug, info, warn, error, critical} -- You may also specify <subsystem>=<level>,<subsystem2>=<level>,... to set the log level for individual subsystems -- Use show to list available subsystems\"`\n\tDropAddrIndex        bool          `long:\"dropaddrindex\" description:\"Deletes the address-based transaction index from the database on start up and then exits.\"`\n\tDropCfIndex          bool          `long:\"dropcfindex\" description:\"Deletes the index used for committed filtering (CF) support from the database on start up and then exits.\"`\n\tDropTxIndex          bool          `long:\"droptxindex\" description:\"Deletes the hash-based transaction index from the database on start up and then exits.\"`\n\tExternalIPs          []string      `long:\"externalip\" description:\"Add an ip to the list of local addresses we claim to listen on to peers\"`\n\tGenerate             bool          `long:\"generate\" description:\"Generate (mine) bitcoins using the CPU\"`\n\tFreeTxRelayLimit     float64       `long:\"limitfreerelay\" description:\"Limit relay of transactions with no transaction fee to the given amount in thousands of bytes per minute\"`\n\tListeners            []string      `long:\"listen\" description:\"Add an interface/port to listen for connections (default all interfaces port: 8333, testnet: 18333)\"`\n\tLogDir               string        `long:\"logdir\" description:\"Directory to log output.\"`\n\tMaxOrphanTxs         int           `long:\"maxorphantx\" description:\"Max number of orphan transactions to keep in memory\"`\n\tMaxPeers             int           `long:\"maxpeers\" description:\"Max number of inbound and outbound peers\"`\n\tMiningAddrs          []string      `long:\"miningaddr\" description:\"Add the specified payment address to the list of addresses to use for generated blocks -- At least one address is required if the generate option is set\"`\n\tMinRelayTxFee        float64       `long:\"minrelaytxfee\" description:\"The minimum transaction fee in BTC/kB to be considered a non-zero fee.\"`\n\tDisableBanning       bool          `long:\"nobanning\" description:\"Disable banning of misbehaving peers\"`\n\tNoCFilters           bool          `long:\"nocfilters\" description:\"Disable committed filtering (CF) support\"`\n\tDisableCheckpoints   bool          `long:\"nocheckpoints\" description:\"Disable built-in checkpoints.  Don't do this unless you know what you're doing.\"`\n\tDisableDNSSeed       bool          `long:\"nodnsseed\" description:\"Disable DNS seeding for peers\"`\n\tDisableListen        bool          `long:\"nolisten\" description:\"Disable listening for incoming connections -- NOTE: Listening is automatically disabled if the --connect or --proxy options are used without also specifying listen interfaces via --listen\"`\n\tNoOnion              bool          `long:\"noonion\" description:\"Disable connecting to tor hidden services\"`\n\tNoPeerBloomFilters   bool          `long:\"nopeerbloomfilters\" description:\"Disable bloom filtering support\"`\n\tNoRelayPriority      bool          `long:\"norelaypriority\" description:\"Do not require free or low-fee transactions to have high priority for relaying\"`\n\tNoWinService         bool          `long:\"nowinservice\" description:\"Do not start as a background service on Windows -- NOTE: This flag only works on the command line, not in the config file\"`\n\tDisableRPC           bool          `long:\"norpc\" description:\"Disable built-in RPC server -- NOTE: The RPC server is disabled by default if no rpcuser/rpcpass or rpclimituser/rpclimitpass is specified\"`\n\tDisableStallHandler  bool          `long:\"nostalldetect\" description:\"Disables the stall handler system for each peer, useful in simnet/regtest integration tests frameworks\"`\n\tDisableTLS           bool          `long:\"notls\" description:\"Disable TLS for the RPC server -- NOTE: This is only allowed if the RPC server is bound to localhost\"`\n\tOnionProxy           string        `long:\"onion\" description:\"Connect to tor hidden services via SOCKS5 proxy (eg. 127.0.0.1:9050)\"`\n\tOnionProxyPass       string        `long:\"onionpass\" default-mask:\"-\" description:\"Password for onion proxy server\"`\n\tOnionProxyUser       string        `long:\"onionuser\" description:\"Username for onion proxy server\"`\n\tProfile              string        `long:\"profile\" description:\"Enable HTTP profiling on given port -- NOTE port must be between 1024 and 65536\"`\n\tProxy                string        `long:\"proxy\" description:\"Connect via SOCKS5 proxy (eg. 127.0.0.1:9050)\"`\n\tProxyPass            string        `long:\"proxypass\" default-mask:\"-\" description:\"Password for proxy server\"`\n\tProxyUser            string        `long:\"proxyuser\" description:\"Username for proxy server\"`\n\tPrune                uint64        `long:\"prune\" description:\"Prune already validated blocks from the database. Must specify a target size in MiB (minimum value of 1536, default value of 0 will disable pruning)\"`\n\tRegressionTest       bool          `long:\"regtest\" description:\"Use the regression test network\"`\n\tRejectNonStd         bool          `long:\"rejectnonstd\" description:\"Reject non-standard transactions regardless of the default settings for the active network.\"`\n\tRejectReplacement    bool          `long:\"rejectreplacement\" description:\"Reject transactions that attempt to replace existing transactions within the mempool through the Replace-By-Fee (RBF) signaling policy.\"`\n\tRelayNonStd          bool          `long:\"relaynonstd\" description:\"Relay non-standard transactions regardless of the default settings for the active network.\"`\n\tRPCCert              string        `long:\"rpccert\" description:\"File containing the certificate file\"`\n\tRPCKey               string        `long:\"rpckey\" description:\"File containing the certificate key\"`\n\tRPCLimitPass         string        `long:\"rpclimitpass\" default-mask:\"-\" description:\"Password for limited RPC connections\"`\n\tRPCLimitUser         string        `long:\"rpclimituser\" description:\"Username for limited RPC connections\"`\n\tRPCListeners         []string      `long:\"rpclisten\" description:\"Add an interface/port to listen for RPC connections (default port: 8334, testnet: 18334)\"`\n\tRPCMaxClients        int           `long:\"rpcmaxclients\" description:\"Max number of RPC clients for standard connections\"`\n\tRPCMaxConcurrentReqs int           `long:\"rpcmaxconcurrentreqs\" description:\"Max number of concurrent RPC requests that may be processed concurrently\"`\n\tRPCMaxWebsockets     int           `long:\"rpcmaxwebsockets\" description:\"Max number of RPC websocket connections\"`\n\tRPCQuirks            bool          `long:\"rpcquirks\" description:\"Mirror some JSON-RPC quirks of Bitcoin Core -- NOTE: Discouraged unless interoperability issues need to be worked around\"`\n\tRPCPass              string        `short:\"P\" long:\"rpcpass\" default-mask:\"-\" description:\"Password for RPC connections\"`\n\tRPCUser              string        `short:\"u\" long:\"rpcuser\" description:\"Username for RPC connections\"`\n\tSigCacheMaxSize      uint          `long:\"sigcachemaxsize\" description:\"The maximum number of entries in the signature verification cache\"`\n\tSimNet               bool          `long:\"simnet\" description:\"Use the simulation test network\"`\n\tSigNet               bool          `long:\"signet\" description:\"Use the signet test network\"`\n\tSigNetChallenge      string        `long:\"signetchallenge\" description:\"Connect to a custom signet network defined by this challenge instead of using the global default signet test network -- Can be specified multiple times\"`\n\tSigNetSeedNode       []string      `long:\"signetseednode\" description:\"Specify a seed node for the signet network instead of using the global default signet network seed nodes\"`\n\tTestNet3             bool          `long:\"testnet\" description:\"Use the test network\"`\n\tTorIsolation         bool          `long:\"torisolation\" description:\"Enable Tor stream isolation by randomizing user credentials for each connection.\"`\n\tTrickleInterval      time.Duration `long:\"trickleinterval\" description:\"Minimum time between attempts to send new inventory to a connected peer\"`\n\tUtxoCacheMaxSizeMiB  uint          `long:\"utxocachemaxsize\" description:\"The maximum size in MiB of the UTXO cache\"`\n\tTxIndex              bool          `long:\"txindex\" description:\"Maintain a full hash-based transaction index which makes all transactions available via the getrawtransaction RPC\"`\n\tUserAgentComments    []string      `long:\"uacomment\" description:\"Comment to add to the user agent -- See BIP 14 for more information.\"`\n\tUpnp                 bool          `long:\"upnp\" description:\"Use UPnP to map our listening port outside of NAT\"`\n\tShowVersion          bool          `short:\"V\" long:\"version\" description:\"Display version information and exit\"`\n\tWhitelists           []string      `long:\"whitelist\" description:\"Add an IP network or IP that will not be banned. (eg. 192.168.1.0/24 or ::1)\"`\n\tlookup               func(string) ([]net.IP, error)\n\toniondial            func(string, string, time.Duration) (net.Conn, error)\n\tdial                 func(string, string, time.Duration) (net.Conn, error)\n\taddCheckpoints       []chaincfg.Checkpoint\n\tminingAddrs          []btcutil.Address\n\tminRelayTxFee        btcutil.Amount\n\twhitelists           []*net.IPNet\n}\n\n// serviceOptions defines the configuration options for the daemon as a service on\n// Windows.\ntype serviceOptions struct {\n\tServiceCommand string `short:\"s\" long:\"service\" description:\"Service command {install, remove, start, stop}\"`\n}\n\n// cleanAndExpandPath expands environment variables and leading ~ in the\n// passed path, cleans the result, and returns it.\nfunc cleanAndExpandPath(path string) string {\n\t// Expand initial ~ to OS specific home directory.\n\tif strings.HasPrefix(path, \"~\") {\n\t\thomeDir := filepath.Dir(defaultHomeDir)\n\t\tpath = strings.Replace(path, \"~\", homeDir, 1)\n\t}\n\n\t// NOTE: The os.ExpandEnv doesn't work with Windows-style %VARIABLE%,\n\t// but they variables can still be expanded via POSIX-style $VARIABLE.\n\treturn filepath.Clean(os.ExpandEnv(path))\n}\n\n// validLogLevel returns whether or not logLevel is a valid debug log level.\nfunc validLogLevel(logLevel string) bool {\n\tswitch logLevel {\n\tcase \"trace\":\n\t\tfallthrough\n\tcase \"debug\":\n\t\tfallthrough\n\tcase \"info\":\n\t\tfallthrough\n\tcase \"warn\":\n\t\tfallthrough\n\tcase \"error\":\n\t\tfallthrough\n\tcase \"critical\":\n\t\treturn true\n\t}\n\treturn false\n}\n\n// supportedSubsystems returns a sorted slice of the supported subsystems for\n// logging purposes.\nfunc supportedSubsystems() []string {\n\t// Convert the subsystemLoggers map keys to a slice.\n\tsubsystems := make([]string, 0, len(subsystemLoggers))\n\tfor subsysID := range subsystemLoggers {\n\t\tsubsystems = append(subsystems, subsysID)\n\t}\n\n\t// Sort the subsystems for stable display.\n\tsort.Strings(subsystems)\n\treturn subsystems\n}\n\n// parseAndSetDebugLevels attempts to parse the specified debug level and set\n// the levels accordingly.  An appropriate error is returned if anything is\n// invalid.\nfunc parseAndSetDebugLevels(debugLevel string) error {\n\t// When the specified string doesn't have any delimiters, treat it as\n\t// the log level for all subsystems.\n\tif !strings.Contains(debugLevel, \",\") && !strings.Contains(debugLevel, \"=\") {\n\t\t// Validate debug log level.\n\t\tif !validLogLevel(debugLevel) {\n\t\t\tstr := \"The specified debug level [%v] is invalid\"\n\t\t\treturn fmt.Errorf(str, debugLevel)\n\t\t}\n\n\t\t// Change the logging level for all subsystems.\n\t\tsetLogLevels(debugLevel)\n\n\t\treturn nil\n\t}\n\n\t// Split the specified string into subsystem/level pairs while detecting\n\t// issues and update the log levels accordingly.\n\tfor _, logLevelPair := range strings.Split(debugLevel, \",\") {\n\t\tif !strings.Contains(logLevelPair, \"=\") {\n\t\t\tstr := \"The specified debug level contains an invalid \" +\n\t\t\t\t\"subsystem/level pair [%v]\"\n\t\t\treturn fmt.Errorf(str, logLevelPair)\n\t\t}\n\n\t\t// Extract the specified subsystem and log level.\n\t\tfields := strings.Split(logLevelPair, \"=\")\n\t\tsubsysID, logLevel := fields[0], fields[1]\n\n\t\t// Validate subsystem.\n\t\tif _, exists := subsystemLoggers[subsysID]; !exists {\n\t\t\tstr := \"The specified subsystem [%v] is invalid -- \" +\n\t\t\t\t\"supported subsystems %v\"\n\t\t\treturn fmt.Errorf(str, subsysID, supportedSubsystems())\n\t\t}\n\n\t\t// Validate log level.\n\t\tif !validLogLevel(logLevel) {\n\t\t\tstr := \"The specified debug level [%v] is invalid\"\n\t\t\treturn fmt.Errorf(str, logLevel)\n\t\t}\n\n\t\tsetLogLevel(subsysID, logLevel)\n\t}\n\n\treturn nil\n}\n\n// validDbType returns whether or not dbType is a supported database type.\nfunc validDbType(dbType string) bool {\n\tfor _, knownType := range knownDbTypes {\n\t\tif dbType == knownType {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicateAddresses returns a new slice with all duplicate entries in\n// addrs removed.\nfunc removeDuplicateAddresses(addrs []string) []string {\n\tresult := make([]string, 0, len(addrs))\n\tseen := map[string]struct{}{}\n\tfor _, val := range addrs {\n\t\tif _, ok := seen[val]; !ok {\n\t\t\tresult = append(result, val)\n\t\t\tseen[val] = struct{}{}\n\t\t}\n\t}\n\treturn result\n}\n\n// normalizeAddress returns addr with the passed default port appended if\n// there is not already a port specified.\nfunc normalizeAddress(addr, defaultPort string) string {\n\t_, _, err := net.SplitHostPort(addr)\n\tif err != nil {\n\t\treturn net.JoinHostPort(addr, defaultPort)\n\t}\n\treturn addr\n}\n\n// normalizeAddresses returns a new slice with all the passed peer addresses\n// normalized with the given default port, and all duplicates removed.\nfunc normalizeAddresses(addrs []string, defaultPort string) []string {\n\tfor i, addr := range addrs {\n\t\taddrs[i] = normalizeAddress(addr, defaultPort)\n\t}\n\n\treturn removeDuplicateAddresses(addrs)\n}\n\n// newCheckpointFromStr parses checkpoints in the '<height>:<hash>' format.\nfunc newCheckpointFromStr(checkpoint string) (chaincfg.Checkpoint, error) {\n\tparts := strings.Split(checkpoint, \":\")\n\tif len(parts) != 2 {\n\t\treturn chaincfg.Checkpoint{}, fmt.Errorf(\"unable to parse \"+\n\t\t\t\"checkpoint %q -- use the syntax <height>:<hash>\",\n\t\t\tcheckpoint)\n\t}\n\n\theight, err := strconv.ParseInt(parts[0], 10, 32)\n\tif err != nil {\n\t\treturn chaincfg.Checkpoint{}, fmt.Errorf(\"unable to parse \"+\n\t\t\t\"checkpoint %q due to malformed height\", checkpoint)\n\t}\n\n\tif len(parts[1]) == 0 {\n\t\treturn chaincfg.Checkpoint{}, fmt.Errorf(\"unable to parse \"+\n\t\t\t\"checkpoint %q due to missing hash\", checkpoint)\n\t}\n\thash, err := chainhash.NewHashFromStr(parts[1])\n\tif err != nil {\n\t\treturn chaincfg.Checkpoint{}, fmt.Errorf(\"unable to parse \"+\n\t\t\t\"checkpoint %q due to malformed hash\", checkpoint)\n\t}\n\n\treturn chaincfg.Checkpoint{\n\t\tHeight: int32(height),\n\t\tHash:   hash,\n\t}, nil\n}\n\n// parseCheckpoints checks the checkpoint strings for valid syntax\n// ('<height>:<hash>') and parses them to chaincfg.Checkpoint instances.\nfunc parseCheckpoints(checkpointStrings []string) ([]chaincfg.Checkpoint, error) {\n\tif len(checkpointStrings) == 0 {\n\t\treturn nil, nil\n\t}\n\tcheckpoints := make([]chaincfg.Checkpoint, len(checkpointStrings))\n\tfor i, cpString := range checkpointStrings {\n\t\tcheckpoint, err := newCheckpointFromStr(cpString)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcheckpoints[i] = checkpoint\n\t}\n\treturn checkpoints, nil\n}\n\n// fileExists reports whether the named file or directory exists.\nfunc fileExists(name string) bool {\n\tif _, err := os.Stat(name); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// newConfigParser returns a new command line flags parser.\nfunc newConfigParser(cfg *config, so *serviceOptions, options flags.Options) *flags.Parser {\n\tparser := flags.NewParser(cfg, options)\n\tif runtime.GOOS == \"windows\" {\n\t\tparser.AddGroup(\"Service Options\", \"Service Options\", so)\n\t}\n\treturn parser\n}\n\n// loadConfig initializes and parses the config using a config file and command\n// line options.\n//\n// The configuration proceeds as follows:\n//  1. Start with a default config with sane settings\n//  2. Pre-parse the command line to check for an alternative config file\n//  3. Load configuration file overwriting defaults with any specified options\n//  4. Parse CLI options and overwrite/add any specified options\n//\n// The above results in btcd functioning properly without any config settings\n// while still allowing the user to override settings with config files and\n// command line options.  Command line options always take precedence.\nfunc loadConfig() (*config, []string, error) {\n\t// Default config.\n\tcfg := config{\n\t\tConfigFile:           defaultConfigFile,\n\t\tDebugLevel:           defaultLogLevel,\n\t\tMaxPeers:             defaultMaxPeers,\n\t\tBanDuration:          defaultBanDuration,\n\t\tBanThreshold:         defaultBanThreshold,\n\t\tRPCMaxClients:        defaultMaxRPCClients,\n\t\tRPCMaxWebsockets:     defaultMaxRPCWebsockets,\n\t\tRPCMaxConcurrentReqs: defaultMaxRPCConcurrentReqs,\n\t\tDataDir:              defaultDataDir,\n\t\tLogDir:               defaultLogDir,\n\t\tDbType:               defaultDbType,\n\t\tRPCKey:               defaultRPCKeyFile,\n\t\tRPCCert:              defaultRPCCertFile,\n\t\tMinRelayTxFee:        mempool.DefaultMinRelayTxFee.ToBTC(),\n\t\tFreeTxRelayLimit:     defaultFreeTxRelayLimit,\n\t\tTrickleInterval:      defaultTrickleInterval,\n\t\tBlockMinSize:         defaultBlockMinSize,\n\t\tBlockMaxSize:         defaultBlockMaxSize,\n\t\tBlockMinWeight:       defaultBlockMinWeight,\n\t\tBlockMaxWeight:       defaultBlockMaxWeight,\n\t\tBlockPrioritySize:    mempool.DefaultBlockPrioritySize,\n\t\tMaxOrphanTxs:         defaultMaxOrphanTransactions,\n\t\tSigCacheMaxSize:      defaultSigCacheMaxSize,\n\t\tUtxoCacheMaxSizeMiB:  defaultUtxoCacheMaxSizeMiB,\n\t\tGenerate:             defaultGenerate,\n\t\tTxIndex:              defaultTxIndex,\n\t\tAddrIndex:            defaultAddrIndex,\n\t}\n\n\t// Service options which are only added on Windows.\n\tserviceOpts := serviceOptions{}\n\n\t// Pre-parse the command line options to see if an alternative config\n\t// file or the version flag was specified.  Any errors aside from the\n\t// help message error can be ignored here since they will be caught by\n\t// the final parse below.\n\tpreCfg := cfg\n\tpreParser := newConfigParser(&preCfg, &serviceOpts, flags.HelpFlag)\n\t_, err := preParser.Parse()\n\tif err != nil {\n\t\tif e, ok := err.(*flags.Error); ok && e.Type == flags.ErrHelp {\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\t// Show the version and exit if the version flag was specified.\n\tappName := filepath.Base(os.Args[0])\n\tappName = strings.TrimSuffix(appName, filepath.Ext(appName))\n\tusageMessage := fmt.Sprintf(\"Use %s -h to show usage\", appName)\n\tif preCfg.ShowVersion {\n\t\tfmt.Println(appName, \"version\", version())\n\t\tos.Exit(0)\n\t}\n\n\t// Perform service command and exit if specified.  Invalid service\n\t// commands show an appropriate error.  Only runs on Windows since\n\t// the runServiceCommand function will be nil when not on Windows.\n\tif serviceOpts.ServiceCommand != \"\" && runServiceCommand != nil {\n\t\terr := runServiceCommand(serviceOpts.ServiceCommand)\n\t\tif err != nil {\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t}\n\t\tos.Exit(0)\n\t}\n\n\t// Load additional config from file.\n\tvar configFileError error\n\tparser := newConfigParser(&cfg, &serviceOpts, flags.Default)\n\tif !(preCfg.RegressionTest || preCfg.SimNet || preCfg.SigNet) ||\n\t\tpreCfg.ConfigFile != defaultConfigFile {\n\n\t\tif _, err := os.Stat(preCfg.ConfigFile); os.IsNotExist(err) {\n\t\t\terr := createDefaultConfigFile(preCfg.ConfigFile)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"Error creating a \"+\n\t\t\t\t\t\"default config file: %v\\n\", err)\n\t\t\t}\n\t\t}\n\n\t\terr := flags.NewIniParser(parser).ParseFile(preCfg.ConfigFile)\n\t\tif err != nil {\n\t\t\tif _, ok := err.(*os.PathError); !ok {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"Error parsing config \"+\n\t\t\t\t\t\"file: %v\\n\", err)\n\t\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tconfigFileError = err\n\t\t}\n\t}\n\n\t// Don't add peers from the config file when in regression test mode.\n\tif preCfg.RegressionTest && len(cfg.AddPeers) > 0 {\n\t\tcfg.AddPeers = nil\n\t}\n\n\t// Parse command line options again to ensure they take precedence.\n\tremainingArgs, err := parser.Parse()\n\tif err != nil {\n\t\tif e, ok := err.(*flags.Error); !ok || e.Type != flags.ErrHelp {\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t}\n\t\treturn nil, nil, err\n\t}\n\n\t// Create the home directory if it doesn't already exist.\n\tfuncName := \"loadConfig\"\n\terr = os.MkdirAll(defaultHomeDir, 0700)\n\tif err != nil {\n\t\t// Show a nicer error message if it's because a symlink is\n\t\t// linked to a directory that does not exist (probably because\n\t\t// it's not mounted).\n\t\tif e, ok := err.(*os.PathError); ok && os.IsExist(err) {\n\t\t\tif link, lerr := os.Readlink(e.Path); lerr == nil {\n\t\t\t\tstr := \"is symlink %s -> %s mounted?\"\n\t\t\t\terr = fmt.Errorf(str, e.Path, link)\n\t\t\t}\n\t\t}\n\n\t\tstr := \"%s: Failed to create home directory: %v\"\n\t\terr := fmt.Errorf(str, funcName, err)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\treturn nil, nil, err\n\t}\n\n\t// Multiple networks can't be selected simultaneously.\n\tnumNets := 0\n\t// Count number of network flags passed; assign active network params\n\t// while we're at it\n\tif cfg.TestNet3 {\n\t\tnumNets++\n\t\tactiveNetParams = &testNet3Params\n\t}\n\tif cfg.RegressionTest {\n\t\tnumNets++\n\t\tactiveNetParams = &regressionNetParams\n\t}\n\tif cfg.SimNet {\n\t\tnumNets++\n\t\t// Also disable dns seeding on the simulation test network.\n\t\tactiveNetParams = &simNetParams\n\t\tcfg.DisableDNSSeed = true\n\t}\n\tif cfg.SigNet {\n\t\tnumNets++\n\t\tactiveNetParams = &sigNetParams\n\n\t\t// Let the user overwrite the default signet parameters. The\n\t\t// challenge defines the actual signet network to join and the\n\t\t// seed nodes are needed for network discovery.\n\t\tsigNetChallenge := chaincfg.DefaultSignetChallenge\n\t\tsigNetSeeds := chaincfg.DefaultSignetDNSSeeds\n\t\tif cfg.SigNetChallenge != \"\" {\n\t\t\tchallenge, err := hex.DecodeString(cfg.SigNetChallenge)\n\t\t\tif err != nil {\n\t\t\t\tstr := \"%s: Invalid signet challenge, hex \" +\n\t\t\t\t\t\"decode failed: %v\"\n\t\t\t\terr := fmt.Errorf(str, funcName, err)\n\t\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tsigNetChallenge = challenge\n\t\t}\n\n\t\tif len(cfg.SigNetSeedNode) > 0 {\n\t\t\tsigNetSeeds = make(\n\t\t\t\t[]chaincfg.DNSSeed, len(cfg.SigNetSeedNode),\n\t\t\t)\n\t\t\tfor idx, seed := range cfg.SigNetSeedNode {\n\t\t\t\tsigNetSeeds[idx] = chaincfg.DNSSeed{\n\t\t\t\t\tHost:         seed,\n\t\t\t\t\tHasFiltering: false,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tchainParams := chaincfg.CustomSignetParams(\n\t\t\tsigNetChallenge, sigNetSeeds,\n\t\t)\n\t\tactiveNetParams.Params = &chainParams\n\t}\n\tif numNets > 1 {\n\t\tstr := \"%s: The testnet, regtest, segnet, signet and simnet \" +\n\t\t\t\"params can't be used together -- choose one of the \" +\n\t\t\t\"five\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// If mainnet is active, then we won't allow the stall handler to be\n\t// disabled.\n\tif activeNetParams.Params.Net == wire.MainNet && cfg.DisableStallHandler {\n\t\tstr := \"%s: stall handler cannot be disabled on mainnet\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Set the default policy for relaying non-standard transactions\n\t// according to the default of the active network. The set\n\t// configuration value takes precedence over the default value for the\n\t// selected network.\n\trelayNonStd := activeNetParams.RelayNonStdTxs\n\tswitch {\n\tcase cfg.RelayNonStd && cfg.RejectNonStd:\n\t\tstr := \"%s: rejectnonstd and relaynonstd cannot be used \" +\n\t\t\t\"together -- choose only one\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\tcase cfg.RejectNonStd:\n\t\trelayNonStd = false\n\tcase cfg.RelayNonStd:\n\t\trelayNonStd = true\n\t}\n\tcfg.RelayNonStd = relayNonStd\n\n\t// Append the network type to the data directory so it is \"namespaced\"\n\t// per network.  In addition to the block database, there are other\n\t// pieces of data that are saved to disk such as address manager state.\n\t// All data is specific to a network, so namespacing the data directory\n\t// means each individual piece of serialized data does not have to\n\t// worry about changing names per network and such.\n\tcfg.DataDir = cleanAndExpandPath(cfg.DataDir)\n\tcfg.DataDir = filepath.Join(cfg.DataDir, netName(activeNetParams))\n\n\t// Append the network type to the log directory so it is \"namespaced\"\n\t// per network in the same fashion as the data directory.\n\tcfg.LogDir = cleanAndExpandPath(cfg.LogDir)\n\tcfg.LogDir = filepath.Join(cfg.LogDir, netName(activeNetParams))\n\n\t// Special show command to list supported subsystems and exit.\n\tif cfg.DebugLevel == \"show\" {\n\t\tfmt.Println(\"Supported subsystems\", supportedSubsystems())\n\t\tos.Exit(0)\n\t}\n\n\t// Initialize log rotation.  After log rotation has been initialized, the\n\t// logger variables may be used.\n\tinitLogRotator(filepath.Join(cfg.LogDir, defaultLogFilename))\n\n\t// Parse, validate, and set debug log level(s).\n\tif err := parseAndSetDebugLevels(cfg.DebugLevel); err != nil {\n\t\terr := fmt.Errorf(\"%s: %v\", funcName, err.Error())\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Validate database type.\n\tif !validDbType(cfg.DbType) {\n\t\tstr := \"%s: The specified database type [%v] is invalid -- \" +\n\t\t\t\"supported types %v\"\n\t\terr := fmt.Errorf(str, funcName, cfg.DbType, knownDbTypes)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Validate profile port number\n\tif cfg.Profile != \"\" {\n\t\tprofilePort, err := strconv.Atoi(cfg.Profile)\n\t\tif err != nil || profilePort < 1024 || profilePort > 65535 {\n\t\t\tstr := \"%s: The profile port must be between 1024 and 65535\"\n\t\t\terr := fmt.Errorf(str, funcName)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\t// Don't allow ban durations that are too short.\n\tif cfg.BanDuration < time.Second {\n\t\tstr := \"%s: The banduration option may not be less than 1s -- parsed [%v]\"\n\t\terr := fmt.Errorf(str, funcName, cfg.BanDuration)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Validate any given whitelisted IP addresses and networks.\n\tif len(cfg.Whitelists) > 0 {\n\t\tvar ip net.IP\n\t\tcfg.whitelists = make([]*net.IPNet, 0, len(cfg.Whitelists))\n\n\t\tfor _, addr := range cfg.Whitelists {\n\t\t\t_, ipnet, err := net.ParseCIDR(addr)\n\t\t\tif err != nil {\n\t\t\t\tip = net.ParseIP(addr)\n\t\t\t\tif ip == nil {\n\t\t\t\t\tstr := \"%s: The whitelist value of '%s' is invalid\"\n\t\t\t\t\terr = fmt.Errorf(str, funcName, addr)\n\t\t\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\t\t\treturn nil, nil, err\n\t\t\t\t}\n\t\t\t\tvar bits int\n\t\t\t\tif ip.To4() == nil {\n\t\t\t\t\t// IPv6\n\t\t\t\t\tbits = 128\n\t\t\t\t} else {\n\t\t\t\t\tbits = 32\n\t\t\t\t}\n\t\t\t\tipnet = &net.IPNet{\n\t\t\t\t\tIP:   ip,\n\t\t\t\t\tMask: net.CIDRMask(bits, bits),\n\t\t\t\t}\n\t\t\t}\n\t\t\tcfg.whitelists = append(cfg.whitelists, ipnet)\n\t\t}\n\t}\n\n\t// --addPeer and --connect do not mix.\n\tif len(cfg.AddPeers) > 0 && len(cfg.ConnectPeers) > 0 {\n\t\tstr := \"%s: the --addpeer and --connect options can not be \" +\n\t\t\t\"mixed\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// --proxy or --connect without --listen disables listening.\n\tif (cfg.Proxy != \"\" || len(cfg.ConnectPeers) > 0) &&\n\t\tlen(cfg.Listeners) == 0 {\n\t\tcfg.DisableListen = true\n\t}\n\n\t// Connect means no DNS seeding.\n\tif len(cfg.ConnectPeers) > 0 {\n\t\tcfg.DisableDNSSeed = true\n\t}\n\n\t// Add the default listener if none were specified. The default\n\t// listener is all addresses on the listen port for the network\n\t// we are to connect to.\n\tif len(cfg.Listeners) == 0 {\n\t\tcfg.Listeners = []string{\n\t\t\tnet.JoinHostPort(\"\", activeNetParams.DefaultPort),\n\t\t}\n\t}\n\n\t// Check to make sure limited and admin users don't have the same username\n\tif cfg.RPCUser == cfg.RPCLimitUser && cfg.RPCUser != \"\" {\n\t\tstr := \"%s: --rpcuser and --rpclimituser must not specify the \" +\n\t\t\t\"same username\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Check to make sure limited and admin users don't have the same password\n\tif cfg.RPCPass == cfg.RPCLimitPass && cfg.RPCPass != \"\" {\n\t\tstr := \"%s: --rpcpass and --rpclimitpass must not specify the \" +\n\t\t\t\"same password\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// The RPC server is disabled if no username or password is provided.\n\tif (cfg.RPCUser == \"\" || cfg.RPCPass == \"\") &&\n\t\t(cfg.RPCLimitUser == \"\" || cfg.RPCLimitPass == \"\") {\n\t\tcfg.DisableRPC = true\n\t}\n\n\tif cfg.DisableRPC {\n\t\tbtcdLog.Infof(\"RPC service is disabled\")\n\t}\n\n\t// Default RPC to listen on localhost only.\n\tif !cfg.DisableRPC && len(cfg.RPCListeners) == 0 {\n\t\taddrs, err := net.LookupHost(\"localhost\")\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tcfg.RPCListeners = make([]string, 0, len(addrs))\n\t\tfor _, addr := range addrs {\n\t\t\taddr = net.JoinHostPort(addr, activeNetParams.rpcPort)\n\t\t\tcfg.RPCListeners = append(cfg.RPCListeners, addr)\n\t\t}\n\t}\n\n\tif cfg.RPCMaxConcurrentReqs < 0 {\n\t\tstr := \"%s: The rpcmaxwebsocketconcurrentrequests option may \" +\n\t\t\t\"not be less than 0 -- parsed [%d]\"\n\t\terr := fmt.Errorf(str, funcName, cfg.RPCMaxConcurrentReqs)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Validate the minrelaytxfee.\n\tcfg.minRelayTxFee, err = btcutil.NewAmount(cfg.MinRelayTxFee)\n\tif err != nil {\n\t\tstr := \"%s: invalid minrelaytxfee: %v\"\n\t\terr := fmt.Errorf(str, funcName, err)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Limit the max block size to a sane value.\n\tif cfg.BlockMaxSize < blockMaxSizeMin || cfg.BlockMaxSize >\n\t\tblockMaxSizeMax {\n\n\t\tstr := \"%s: The blockmaxsize option must be in between %d \" +\n\t\t\t\"and %d -- parsed [%d]\"\n\t\terr := fmt.Errorf(str, funcName, blockMaxSizeMin,\n\t\t\tblockMaxSizeMax, cfg.BlockMaxSize)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Limit the max block weight to a sane value.\n\tif cfg.BlockMaxWeight < blockMaxWeightMin ||\n\t\tcfg.BlockMaxWeight > blockMaxWeightMax {\n\n\t\tstr := \"%s: The blockmaxweight option must be in between %d \" +\n\t\t\t\"and %d -- parsed [%d]\"\n\t\terr := fmt.Errorf(str, funcName, blockMaxWeightMin,\n\t\t\tblockMaxWeightMax, cfg.BlockMaxWeight)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Limit the max orphan count to a sane vlue.\n\tif cfg.MaxOrphanTxs < 0 {\n\t\tstr := \"%s: The maxorphantx option may not be less than 0 \" +\n\t\t\t\"-- parsed [%d]\"\n\t\terr := fmt.Errorf(str, funcName, cfg.MaxOrphanTxs)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Limit the block priority and minimum block sizes to max block size.\n\tcfg.BlockPrioritySize = minUint32(cfg.BlockPrioritySize, cfg.BlockMaxSize)\n\tcfg.BlockMinSize = minUint32(cfg.BlockMinSize, cfg.BlockMaxSize)\n\tcfg.BlockMinWeight = minUint32(cfg.BlockMinWeight, cfg.BlockMaxWeight)\n\n\tswitch {\n\t// If the max block size isn't set, but the max weight is, then we'll\n\t// set the limit for the max block size to a safe limit so weight takes\n\t// precedence.\n\tcase cfg.BlockMaxSize == defaultBlockMaxSize &&\n\t\tcfg.BlockMaxWeight != defaultBlockMaxWeight:\n\n\t\tcfg.BlockMaxSize = blockchain.MaxBlockBaseSize - 1000\n\n\t// If the max block weight isn't set, but the block size is, then we'll\n\t// scale the set weight accordingly based on the max block size value.\n\tcase cfg.BlockMaxSize != defaultBlockMaxSize &&\n\t\tcfg.BlockMaxWeight == defaultBlockMaxWeight:\n\n\t\tcfg.BlockMaxWeight = cfg.BlockMaxSize * blockchain.WitnessScaleFactor\n\t}\n\n\t// Look for illegal characters in the user agent comments.\n\tfor _, uaComment := range cfg.UserAgentComments {\n\t\tif strings.ContainsAny(uaComment, \"/:()\") {\n\t\t\terr := fmt.Errorf(\"%s: The following characters must not \"+\n\t\t\t\t\"appear in user agent comments: '/', ':', '(', ')'\",\n\t\t\t\tfuncName)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\t// --txindex and --droptxindex do not mix.\n\tif cfg.TxIndex && cfg.DropTxIndex {\n\t\terr := fmt.Errorf(\"%s: the --txindex and --droptxindex \"+\n\t\t\t\"options may  not be activated at the same time\",\n\t\t\tfuncName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// --addrindex and --dropaddrindex do not mix.\n\tif cfg.AddrIndex && cfg.DropAddrIndex {\n\t\terr := fmt.Errorf(\"%s: the --addrindex and --dropaddrindex \"+\n\t\t\t\"options may not be activated at the same time\",\n\t\t\tfuncName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// --addrindex and --droptxindex do not mix.\n\tif cfg.AddrIndex && cfg.DropTxIndex {\n\t\terr := fmt.Errorf(\"%s: the --addrindex and --droptxindex \"+\n\t\t\t\"options may not be activated at the same time \"+\n\t\t\t\"because the address index relies on the transaction \"+\n\t\t\t\"index\",\n\t\t\tfuncName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Check mining addresses are valid and saved parsed versions.\n\tcfg.miningAddrs = make([]btcutil.Address, 0, len(cfg.MiningAddrs))\n\tfor _, strAddr := range cfg.MiningAddrs {\n\t\taddr, err := btcutil.DecodeAddress(strAddr, activeNetParams.Params)\n\t\tif err != nil {\n\t\t\tstr := \"%s: mining address '%s' failed to decode: %v\"\n\t\t\terr := fmt.Errorf(str, funcName, strAddr, err)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tif !addr.IsForNet(activeNetParams.Params) {\n\t\t\tstr := \"%s: mining address '%s' is on the wrong network\"\n\t\t\terr := fmt.Errorf(str, funcName, strAddr)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tcfg.miningAddrs = append(cfg.miningAddrs, addr)\n\t}\n\n\t// Ensure there is at least one mining address when the generate flag is\n\t// set.\n\tif cfg.Generate && len(cfg.MiningAddrs) == 0 {\n\t\tstr := \"%s: the generate flag is set, but there are no mining \" +\n\t\t\t\"addresses specified \"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Add default port to all listener addresses if needed and remove\n\t// duplicate addresses.\n\tcfg.Listeners = normalizeAddresses(cfg.Listeners,\n\t\tactiveNetParams.DefaultPort)\n\n\t// Add default port to all rpc listener addresses if needed and remove\n\t// duplicate addresses.\n\tcfg.RPCListeners = normalizeAddresses(cfg.RPCListeners,\n\t\tactiveNetParams.rpcPort)\n\n\t// Only allow TLS to be disabled if the RPC is bound to localhost\n\t// addresses.\n\tif !cfg.DisableRPC && cfg.DisableTLS {\n\t\tallowedTLSListeners := map[string]struct{}{\n\t\t\t\"localhost\": {},\n\t\t\t\"127.0.0.1\": {},\n\t\t\t\"::1\":       {},\n\t\t}\n\t\tfor _, addr := range cfg.RPCListeners {\n\t\t\thost, _, err := net.SplitHostPort(addr)\n\t\t\tif err != nil {\n\t\t\t\tstr := \"%s: RPC listen interface '%s' is \" +\n\t\t\t\t\t\"invalid: %v\"\n\t\t\t\terr := fmt.Errorf(str, funcName, addr, err)\n\t\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tif _, ok := allowedTLSListeners[host]; !ok {\n\t\t\t\tstr := \"%s: the --notls option may not be used \" +\n\t\t\t\t\t\"when binding RPC to non localhost \" +\n\t\t\t\t\t\"addresses: %s\"\n\t\t\t\terr := fmt.Errorf(str, funcName, addr)\n\t\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\t// Add default port to all added peer addresses if needed and remove\n\t// duplicate addresses.\n\tcfg.AddPeers = normalizeAddresses(cfg.AddPeers,\n\t\tactiveNetParams.DefaultPort)\n\tcfg.ConnectPeers = normalizeAddresses(cfg.ConnectPeers,\n\t\tactiveNetParams.DefaultPort)\n\n\t// --noonion and --onion do not mix.\n\tif cfg.NoOnion && cfg.OnionProxy != \"\" {\n\t\terr := fmt.Errorf(\"%s: the --noonion and --onion options may \"+\n\t\t\t\"not be activated at the same time\", funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Check the checkpoints for syntax errors.\n\tcfg.addCheckpoints, err = parseCheckpoints(cfg.AddCheckpoints)\n\tif err != nil {\n\t\tstr := \"%s: Error parsing checkpoints: %v\"\n\t\terr := fmt.Errorf(str, funcName, err)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Tor stream isolation requires either proxy or onion proxy to be set.\n\tif cfg.TorIsolation && cfg.Proxy == \"\" && cfg.OnionProxy == \"\" {\n\t\tstr := \"%s: Tor stream isolation requires either proxy or \" +\n\t\t\t\"onionproxy to be set\"\n\t\terr := fmt.Errorf(str, funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Setup dial and DNS resolution (lookup) functions depending on the\n\t// specified options.  The default is to use the standard\n\t// net.DialTimeout function as well as the system DNS resolver.  When a\n\t// proxy is specified, the dial function is set to the proxy specific\n\t// dial function and the lookup is set to use tor (unless --noonion is\n\t// specified in which case the system DNS resolver is used).\n\tcfg.dial = net.DialTimeout\n\tcfg.lookup = net.LookupIP\n\tif cfg.Proxy != \"\" {\n\t\t_, _, err := net.SplitHostPort(cfg.Proxy)\n\t\tif err != nil {\n\t\t\tstr := \"%s: Proxy address '%s' is invalid: %v\"\n\t\t\terr := fmt.Errorf(str, funcName, cfg.Proxy, err)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\n\t\t// Tor isolation flag means proxy credentials will be overridden\n\t\t// unless there is also an onion proxy configured in which case\n\t\t// that one will be overridden.\n\t\ttorIsolation := false\n\t\tif cfg.TorIsolation && cfg.OnionProxy == \"\" &&\n\t\t\t(cfg.ProxyUser != \"\" || cfg.ProxyPass != \"\") {\n\n\t\t\ttorIsolation = true\n\t\t\tfmt.Fprintln(os.Stderr, \"Tor isolation set -- \"+\n\t\t\t\t\"overriding specified proxy user credentials\")\n\t\t}\n\n\t\tproxy := &socks.Proxy{\n\t\t\tAddr:         cfg.Proxy,\n\t\t\tUsername:     cfg.ProxyUser,\n\t\t\tPassword:     cfg.ProxyPass,\n\t\t\tTorIsolation: torIsolation,\n\t\t}\n\t\tcfg.dial = proxy.DialTimeout\n\n\t\t// Treat the proxy as tor and perform DNS resolution through it\n\t\t// unless the --noonion flag is set or there is an\n\t\t// onion-specific proxy configured.\n\t\tif !cfg.NoOnion && cfg.OnionProxy == \"\" {\n\t\t\tcfg.lookup = func(host string) ([]net.IP, error) {\n\t\t\t\treturn connmgr.TorLookupIP(host, cfg.Proxy)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Setup onion address dial function depending on the specified options.\n\t// The default is to use the same dial function selected above.  However,\n\t// when an onion-specific proxy is specified, the onion address dial\n\t// function is set to use the onion-specific proxy while leaving the\n\t// normal dial function as selected above.  This allows .onion address\n\t// traffic to be routed through a different proxy than normal traffic.\n\tif cfg.OnionProxy != \"\" {\n\t\t_, _, err := net.SplitHostPort(cfg.OnionProxy)\n\t\tif err != nil {\n\t\t\tstr := \"%s: Onion proxy address '%s' is invalid: %v\"\n\t\t\terr := fmt.Errorf(str, funcName, cfg.OnionProxy, err)\n\t\t\tfmt.Fprintln(os.Stderr, err)\n\t\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\t\treturn nil, nil, err\n\t\t}\n\n\t\t// Tor isolation flag means onion proxy credentials will be\n\t\t// overridden.\n\t\tif cfg.TorIsolation &&\n\t\t\t(cfg.OnionProxyUser != \"\" || cfg.OnionProxyPass != \"\") {\n\t\t\tfmt.Fprintln(os.Stderr, \"Tor isolation set -- \"+\n\t\t\t\t\"overriding specified onionproxy user \"+\n\t\t\t\t\"credentials \")\n\t\t}\n\n\t\tcfg.oniondial = func(network, addr string, timeout time.Duration) (net.Conn, error) {\n\t\t\tproxy := &socks.Proxy{\n\t\t\t\tAddr:         cfg.OnionProxy,\n\t\t\t\tUsername:     cfg.OnionProxyUser,\n\t\t\t\tPassword:     cfg.OnionProxyPass,\n\t\t\t\tTorIsolation: cfg.TorIsolation,\n\t\t\t}\n\t\t\treturn proxy.DialTimeout(network, addr, timeout)\n\t\t}\n\n\t\t// When configured in bridge mode (both --onion and --proxy are\n\t\t// configured), it means that the proxy configured by --proxy is\n\t\t// not a tor proxy, so override the DNS resolution to use the\n\t\t// onion-specific proxy.\n\t\tif cfg.Proxy != \"\" {\n\t\t\tcfg.lookup = func(host string) ([]net.IP, error) {\n\t\t\t\treturn connmgr.TorLookupIP(host, cfg.OnionProxy)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tcfg.oniondial = cfg.dial\n\t}\n\n\t// Specifying --noonion means the onion address dial function results in\n\t// an error.\n\tif cfg.NoOnion {\n\t\tcfg.oniondial = func(a, b string, t time.Duration) (net.Conn, error) {\n\t\t\treturn nil, errors.New(\"tor has been disabled\")\n\t\t}\n\t}\n\n\tif cfg.Prune != 0 && cfg.Prune < pruneMinSize {\n\t\terr := fmt.Errorf(\"%s: the minimum value for --prune is %d. Got %d\",\n\t\t\tfuncName, pruneMinSize, cfg.Prune)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\tif cfg.Prune != 0 && cfg.TxIndex {\n\t\terr := fmt.Errorf(\"%s: the --prune and --txindex options may \"+\n\t\t\t\"not be activated at the same time\", funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\tif cfg.Prune != 0 && cfg.AddrIndex {\n\t\terr := fmt.Errorf(\"%s: the --prune and --addrindex options may \"+\n\t\t\t\"not be activated at the same time\", funcName)\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tfmt.Fprintln(os.Stderr, usageMessage)\n\t\treturn nil, nil, err\n\t}\n\n\t// Warn about missing config file only after all other configuration is\n\t// done.  This prevents the warning on help messages and invalid\n\t// options.  Note this should go directly before the return.\n\tif configFileError != nil {\n\t\tbtcdLog.Warnf(\"%v\", configFileError)\n\t}\n\n\treturn &cfg, remainingArgs, nil\n}\n\n// createDefaultConfig copies the file sample-btcd.conf to the given destination path,\n// and populates it with some randomly generated RPC username and password.\nfunc createDefaultConfigFile(destinationPath string) error {\n\t// Create the destination directory if it does not exists\n\terr := os.MkdirAll(filepath.Dir(destinationPath), 0700)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// We assume sample config file path is same as binary\n\tpath, err := filepath.Abs(filepath.Dir(os.Args[0]))\n\tif err != nil {\n\t\treturn err\n\t}\n\tsampleConfigPath := filepath.Join(path, sampleConfigFilename)\n\n\t// We generate a random user and password\n\trandomBytes := make([]byte, 20)\n\t_, err = rand.Read(randomBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\tgeneratedRPCUser := base64.StdEncoding.EncodeToString(randomBytes)\n\n\t_, err = rand.Read(randomBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\tgeneratedRPCPass := base64.StdEncoding.EncodeToString(randomBytes)\n\n\tsrc, err := os.Open(sampleConfigPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer src.Close()\n\n\tdest, err := os.OpenFile(destinationPath,\n\t\tos.O_RDWR|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer dest.Close()\n\n\t// We copy every line from the sample config file to the destination,\n\t// only replacing the two lines for rpcuser and rpcpass\n\treader := bufio.NewReader(src)\n\tfor err != io.EOF {\n\t\tvar line string\n\t\tline, err = reader.ReadString('\\n')\n\t\tif err != nil && err != io.EOF {\n\t\t\treturn err\n\t\t}\n\n\t\tif strings.Contains(line, \"rpcuser=\") {\n\t\t\tline = \"rpcuser=\" + generatedRPCUser + \"\\n\"\n\t\t} else if strings.Contains(line, \"rpcpass=\") {\n\t\t\tline = \"rpcpass=\" + generatedRPCPass + \"\\n\"\n\t\t}\n\n\t\tif _, err := dest.WriteString(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// btcdDial connects to the address on the named network using the appropriate\n// dial function depending on the address and configuration options.  For\n// example, .onion addresses will be dialed using the onion specific proxy if\n// one was specified, but will otherwise use the normal dial function (which\n// could itself use a proxy or not).\nfunc btcdDial(addr net.Addr) (net.Conn, error) {\n\tif strings.Contains(addr.String(), \".onion:\") {\n\t\treturn cfg.oniondial(addr.Network(), addr.String(),\n\t\t\tdefaultConnectTimeout)\n\t}\n\treturn cfg.dial(addr.Network(), addr.String(), defaultConnectTimeout)\n}\n\n// btcdLookup resolves the IP of the given host using the correct DNS lookup\n// function depending on the configuration options.  For example, addresses will\n// be resolved using tor when the --proxy flag was specified unless --noonion\n// was also specified in which case the normal system DNS resolver will be used.\n//\n// Any attempt to resolve a tor address (.onion) will return an error since they\n// are not intended to be resolved outside of the tor proxy.\nfunc btcdLookup(host string) ([]net.IP, error) {\n\tif strings.HasSuffix(host, \".onion\") {\n\t\treturn nil, fmt.Errorf(\"attempt to resolve tor address %s\", host)\n\t}\n\n\treturn cfg.lookup(host)\n}\n"
        },
        {
          "name": "config_test.go",
          "type": "blob",
          "size": 1.6865234375,
          "content": "package main\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"testing\"\n)\n\nvar (\n\trpcuserRegexp = regexp.MustCompile(\"(?m)^rpcuser=.+$\")\n\trpcpassRegexp = regexp.MustCompile(\"(?m)^rpcpass=.+$\")\n)\n\nfunc TestCreateDefaultConfigFile(t *testing.T) {\n\t// find out where the sample config lives\n\t_, path, _, ok := runtime.Caller(0)\n\tif !ok {\n\t\tt.Fatalf(\"Failed finding config file path\")\n\t}\n\tsampleConfigFile := filepath.Join(filepath.Dir(path), \"sample-btcd.conf\")\n\n\t// Setup a temporary directory\n\ttmpDir, err := os.MkdirTemp(\"\", \"btcd\")\n\tif err != nil {\n\t\tt.Fatalf(\"Failed creating a temporary directory: %v\", err)\n\t}\n\ttestpath := filepath.Join(tmpDir, \"test.conf\")\n\n\t// copy config file to location of btcd binary\n\tdata, err := os.ReadFile(sampleConfigFile)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed reading sample config file: %v\", err)\n\t}\n\tappPath, err := filepath.Abs(filepath.Dir(os.Args[0]))\n\tif err != nil {\n\t\tt.Fatalf(\"Failed obtaining app path: %v\", err)\n\t}\n\ttmpConfigFile := filepath.Join(appPath, \"sample-btcd.conf\")\n\terr = os.WriteFile(tmpConfigFile, data, 0644)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed copying sample config file: %v\", err)\n\t}\n\n\t// Clean-up\n\tdefer func() {\n\t\tos.Remove(testpath)\n\t\tos.Remove(tmpConfigFile)\n\t\tos.Remove(tmpDir)\n\t}()\n\n\terr = createDefaultConfigFile(testpath)\n\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to create a default config file: %v\", err)\n\t}\n\n\tcontent, err := os.ReadFile(testpath)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read generated default config file: %v\", err)\n\t}\n\n\tif !rpcuserRegexp.Match(content) {\n\t\tt.Error(\"Could not find rpcuser in generated default config file.\")\n\t}\n\n\tif !rpcpassRegexp.Match(content) {\n\t\tt.Error(\"Could not find rpcpass in generated default config file.\")\n\t}\n}\n"
        },
        {
          "name": "connmgr",
          "type": "tree",
          "content": null
        },
        {
          "name": "database",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 9.41015625,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\n/*\nbtcd is a full-node bitcoin implementation written in Go.\n\nThe default options are sane for most users.  This means btcd will work 'out of\nthe box' for most users.  However, there are also a wide variety of flags that\ncan be used to control it.\n\nThe following section provides a usage overview which enumerates the flags.  An\ninteresting point to note is that the long form of all of these options\n(except -C) can be specified in a configuration file that is automatically\nparsed when btcd starts up.  By default, the configuration file is located at\n~/.btcd/btcd.conf on POSIX-style operating systems and %LOCALAPPDATA%\\btcd\\btcd.conf\non Windows.  The -C (--configfile) flag, as shown below, can be used to override\nthis location.\n\nUsage:\n\n\tbtcd [OPTIONS]\n\nApplication Options:\n\n\t    --addcheckpoint=        Add a custom checkpoint.  Format:\n\t                            '<height>:<hash>'\n\t-a, --addpeer=              Add a peer to connect with at startup\n\t    --addrindex             Maintain a full address-based transaction index\n\t                            which makes the searchrawtransactions RPC\n\t                            available\n\t    --banduration=          How long to ban misbehaving peers.  Valid time\n\t                            units are {s, m, h}.  Minimum 1 second (default:\n\t                            24h0m0s)\n\t    --banthreshold=         Maximum allowed ban score before disconnecting\n\t                            and banning misbehaving peers. (default: 100)\n\t    --blockmaxsize=         Maximum block size in bytes to be used when\n\t                            creating a block (default: 750000)\n\t    --blockminsize=         Minimum block size in bytes to be used when\n\t                            creating a block\n\t    --blockmaxweight=       Maximum block weight to be used when creating a\n\t                            block (default: 3000000)\n\t    --blockminweight=       Minimum block weight to be used when creating a\n\t                            block\n\t    --blockprioritysize=    Size in bytes for high-priority/low-fee\n\t                            transactions when creating a block (default:\n\t                            50000)\n\t    --blocksonly            Do not accept transactions from remote peers.\n\t-C, --configfile=           Path to configuration file\n\t    --connect=              Connect only to the specified peers at startup\n\t    --cpuprofile=           Write CPU profile to the specified file\n\t-b, --datadir=              Directory to store data\n\t    --dbtype=               Database backend to use for the Block Chain\n\t                            (default: ffldb)\n\t-d, --debuglevel=           Logging level for all subsystems {trace, debug,\n\t                            info, warn, error, critical} -- You may also\n\t                            specify\n\t                            <subsystem>=<level>,<subsystem2>=<level>,... to\n\t                            set the log level for individual subsystems --\n\t                            Use show to list available subsystems (default:\n\t                            info)\n\t    --dropaddrindex         Deletes the address-based transaction index from\n\t                            the database on start up and then exits.\n\t    --dropcfindex           Deletes the index used for committed filtering\n\t                            (CF) support from the database on start up and\n\t                            then exits.\n\t    --droptxindex           Deletes the hash-based transaction index from the\n\t                            database on start up and then exits.\n\t    --externalip=           Add an ip to the list of local addresses we claim\n\t                            to listen on to peers\n\t    --generate              Generate (mine) bitcoins using the CPU\n\t    --limitfreerelay=       Limit relay of transactions with no transaction\n\t                            fee to the given amount in thousands of bytes per\n\t                            minute (default: 15)\n\t    --listen=               Add an interface/port to listen for connections\n\t                            (default all interfaces port: 8333, testnet:\n\t                            18333, signet: 38333)\n\t    --logdir=               Directory to log output\n\t    --maxorphantx=          Max number of orphan transactions to keep in\n\t                            memory (default: 100)\n\t    --maxpeers=             Max number of inbound and outbound peers\n\t                            (default: 125)\n\t    --miningaddr=           Add the specified payment address to the list of\n\t                            addresses to use for generated blocks -- At least\n\t                            one address is required if the generate option is\n\t                            set\n\t    --minrelaytxfee=        The minimum transaction fee in BTC/kB to be\n\t                            considered a non-zero fee. (default: 1e-05)\n\t    --nobanning             Disable banning of misbehaving peers\n\t    --nocfilters            Disable committed filtering (CF) support\n\t    --nocheckpoints         Disable built-in checkpoints.  Don't do this\n\t                            unless you know what you're doing.\n\t    --nodnsseed             Disable DNS seeding for peers\n\t    --nolisten              Disable listening for incoming connections --\n\t                            NOTE: Listening is automatically disabled if the\n\t                            --connect or --proxy options are used without\n\t                            also specifying listen interfaces via --listen\n\t    --noonion               Disable connecting to tor hidden services\n\t    --nopeerbloomfilters    Disable bloom filtering support\n\t    --norelaypriority       Do not require free or low-fee transactions to\n\t                            have high priority for relaying\n\t    --norpc                 Disable built-in RPC server -- NOTE: The RPC\n\t                            server is disabled by default if no\n\t                            rpcuser/rpcpass or rpclimituser/rpclimitpass is\n\t                            specified\n\t    --notls                 Disable TLS for the RPC server -- NOTE: This is\n\t                            only allowed if the RPC server is bound to\n\t                            localhost\n\t    --onion=                Connect to tor hidden services via SOCKS5 proxy\n\t                            (eg. 127.0.0.1:9050)\n\t    --onionpass=            Password for onion proxy server\n\t    --onionuser=            Username for onion proxy server\n\t    --profile=              Enable HTTP profiling on given port -- NOTE port\n\t                            must be between 1024 and 65536\n\t    --proxy=                Connect via SOCKS5 proxy (eg. 127.0.0.1:9050)\n\t    --proxypass=            Password for proxy server\n\t    --proxyuser=            Username for proxy server\n\t    --regtest               Use the regression test network\n\t    --rejectnonstd          Reject non-standard transactions regardless of\n\t                            the default settings for the active network.\n\t    --relaynonstd           Relay non-standard transactions regardless of the\n\t                            default settings for the active network.\n\t    --rpccert=              File containing the certificate file\n\t    --rpckey=               File containing the certificate key\n\t    --rpclimitpass=         Password for limited RPC connections\n\t    --rpclimituser=         Username for limited RPC connections\n\t    --rpclisten=            Add an interface/port to listen for RPC\n\t                            connections (default port: 8334, testnet: 18334)\n\t    --rpcmaxclients=        Max number of RPC clients for standard\n\t                            connections (default: 10)\n\t    --rpcmaxconcurrentreqs= Max number of concurrent RPC requests that may be\n\t                            processed concurrently (default: 20)\n\t    --rpcmaxwebsockets=     Max number of RPC websocket connections (default:\n\t                            25)\n\t    --rpcquirks             Mirror some JSON-RPC quirks of Bitcoin Core --\n\t                            NOTE: Discouraged unless interoperability issues\n\t                            need to be worked around\n\t-P, --rpcpass=              Password for RPC connections\n\t-u, --rpcuser=              Username for RPC connections\n\t    --sigcachemaxsize=      The maximum number of entries in the signature\n\t                            verification cache (default: 100000)\n\t    --simnet                Use the simulation test network\n\t    --testnet               Use the test network\n\t    --torisolation          Enable Tor stream isolation by randomizing user\n\t                            credentials for each connection.\n\t    --trickleinterval=      Minimum time between attempts to send new\n\t                            inventory to a connected peer (default: 10s)\n\t    --txindex               Maintain a full hash-based transaction index\n\t                            which makes all transactions available via the\n\t                            getrawtransaction RPC\n\t    --uacomment=            Comment to add to the user agent -- See BIP 14\n\t                            for more information.\n\t    --upnp                  Use UPnP to map our listening port outside of NAT\n\t-V, --version               Display version information and exit\n\t    --whitelist=            Add an IP network or IP that will not be banned.\n\t                            (eg. 192.168.1.0/24 or ::1)\n\nHelp Options:\n\n\t-h, --help           Show this help message\n*/\npackage main\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.5029296875,
          "content": "module github.com/btcsuite/btcd\n\nrequire (\n\tgithub.com/btcsuite/btcd/btcec/v2 v2.3.4\n\tgithub.com/btcsuite/btcd/btcutil v1.1.5\n\tgithub.com/btcsuite/btcd/chaincfg/chainhash v1.1.0\n\tgithub.com/btcsuite/btclog v0.0.0-20170628155309-84c8d2346e9f\n\tgithub.com/btcsuite/go-socks v0.0.0-20170105172521-4720035b7bfd\n\tgithub.com/btcsuite/websocket v0.0.0-20150119174127-31079b680792\n\tgithub.com/btcsuite/winsvc v1.0.0\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/decred/dcrd/dcrec/secp256k1/v4 v4.0.1\n\tgithub.com/decred/dcrd/lru v1.0.0\n\tgithub.com/gorilla/websocket v1.5.0\n\tgithub.com/jessevdk/go-flags v1.4.0\n\tgithub.com/jrick/logrotate v1.0.0\n\tgithub.com/stretchr/testify v1.8.4\n\tgithub.com/syndtr/goleveldb v1.0.1-0.20210819022825-2ae1ddf74ef7\n\tgolang.org/x/crypto v0.22.0\n\tgolang.org/x/sys v0.19.0\n)\n\nrequire (\n\tgithub.com/aead/siphash v1.0.1 // indirect\n\tgithub.com/decred/dcrd/crypto/blake256 v1.0.0 // indirect\n\tgithub.com/golang/snappy v0.0.4 // indirect\n\tgithub.com/kkdai/bstream v0.0.0-20161212061736-f391b8402d23 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/stretchr/objx v0.5.0 // indirect\n\tgolang.org/x/net v0.24.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n\n// The retract statements below fixes an accidental push of the tags of a btcd\n// fork.\nretract (\n\tv0.18.1\n\tv0.18.0\n\tv0.17.1\n\tv0.17.0\n\tv0.16.5\n\tv0.16.4\n\tv0.16.3\n\tv0.16.2\n\tv0.16.1\n\tv0.16.0\n\n\tv0.15.2\n\tv0.15.1\n\tv0.15.0\n\n\tv0.14.7\n\tv0.14.6\n\tv0.14.6\n\tv0.14.5\n\tv0.14.4\n\tv0.14.3\n\tv0.14.2\n\tv0.14.1\n\n\tv0.14.0\n\tv0.13.0-beta2\n\tv0.13.0-beta\n)\n\ngo 1.17\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 16.26953125,
          "content": "github.com/aead/siphash v1.0.1 h1:FwHfE/T45KPKYuuSAKyyvE+oPWcaQ+CUmFW0bPlM+kg=\ngithub.com/aead/siphash v1.0.1/go.mod h1:Nywa3cDsYNNK3gaciGTWPwHt0wlpNV15vwmswBAUSII=\ngithub.com/btcsuite/btcd v0.20.1-beta/go.mod h1:wVuoA8VJLEcwgqHBwHmzLRazpKxTv13Px/pDuV7OomQ=\ngithub.com/btcsuite/btcd v0.22.0-beta.0.20220111032746-97732e52810c/go.mod h1:tjmYdS6MLJ5/s0Fj4DbLgSbDHbEqLJrtnHecBFkdz5M=\ngithub.com/btcsuite/btcd v0.23.5-0.20231215221805-96c9fd8078fd/go.mod h1:nm3Bko6zh6bWP60UxwoT5LzdGJsQJaPo6HjduXq9p6A=\ngithub.com/btcsuite/btcd/btcec/v2 v2.1.0/go.mod h1:2VzYrv4Gm4apmbVVsSq5bqf1Ec8v56E48Vt0Y/umPgA=\ngithub.com/btcsuite/btcd/btcec/v2 v2.1.3/go.mod h1:ctjw4H1kknNJmRN4iP1R7bTQ+v3GJkZBd6mui8ZsAZE=\ngithub.com/btcsuite/btcd/btcec/v2 v2.3.4 h1:3EJjcN70HCu/mwqlUsGK8GcNVyLVxFDlWurTXGPFfiQ=\ngithub.com/btcsuite/btcd/btcec/v2 v2.3.4/go.mod h1:zYzJ8etWJQIv1Ogk7OzpWjowwOdXY1W/17j2MW85J04=\ngithub.com/btcsuite/btcd/btcutil v1.0.0/go.mod h1:Uoxwv0pqYWhD//tfTiipkxNfdhG9UrLwaeswfjfdF0A=\ngithub.com/btcsuite/btcd/btcutil v1.1.0/go.mod h1:5OapHB7A2hBBWLm48mmw4MOHNJCcUBTwmWH/0Jn8VHE=\ngithub.com/btcsuite/btcd/btcutil v1.1.5 h1:+wER79R5670vs/ZusMTF1yTcRYE5GUsFbdjdisflzM8=\ngithub.com/btcsuite/btcd/btcutil v1.1.5/go.mod h1:PSZZ4UitpLBWzxGd5VGOrLnmOjtPP/a6HaFo12zMs00=\ngithub.com/btcsuite/btcd/chaincfg/chainhash v1.0.0/go.mod h1:7SFka0XMvUgj3hfZtydOrQY2mwhPclbT2snogU7SQQc=\ngithub.com/btcsuite/btcd/chaincfg/chainhash v1.0.1/go.mod h1:7SFka0XMvUgj3hfZtydOrQY2mwhPclbT2snogU7SQQc=\ngithub.com/btcsuite/btcd/chaincfg/chainhash v1.1.0 h1:59Kx4K6lzOW5w6nFlA0v5+lk/6sjybR934QNHSJZPTQ=\ngithub.com/btcsuite/btcd/chaincfg/chainhash v1.1.0/go.mod h1:7SFka0XMvUgj3hfZtydOrQY2mwhPclbT2snogU7SQQc=\ngithub.com/btcsuite/btclog v0.0.0-20170628155309-84c8d2346e9f h1:bAs4lUbRJpnnkd9VhRV3jjAVU7DJVjMaK+IsvSeZvFo=\ngithub.com/btcsuite/btclog v0.0.0-20170628155309-84c8d2346e9f/go.mod h1:TdznJufoqS23FtqVCzL0ZqgP5MqXbb4fg/WgDys70nA=\ngithub.com/btcsuite/btcutil v0.0.0-20190425235716-9e5f4b9a998d/go.mod h1:+5NJ2+qvTyV9exUAL/rxXi3DcLg2Ts+ymUAY5y4NvMg=\ngithub.com/btcsuite/go-socks v0.0.0-20170105172521-4720035b7bfd h1:R/opQEbFEy9JGkIguV40SvRY1uliPX8ifOvi6ICsFCw=\ngithub.com/btcsuite/go-socks v0.0.0-20170105172521-4720035b7bfd/go.mod h1:HHNXQzUsZCxOoE+CPiyCTO6x34Zs86zZUiwtpXoGdtg=\ngithub.com/btcsuite/goleveldb v0.0.0-20160330041536-7834afc9e8cd/go.mod h1:F+uVaaLLH7j4eDXPRvw78tMflu7Ie2bzYOH4Y8rRKBY=\ngithub.com/btcsuite/goleveldb v1.0.0/go.mod h1:QiK9vBlgftBg6rWQIj6wFzbPfRjiykIEhBH4obrXJ/I=\ngithub.com/btcsuite/snappy-go v0.0.0-20151229074030-0bdef8d06723/go.mod h1:8woku9dyThutzjeg+3xrA5iCpBRH8XEEg3lh6TiUghc=\ngithub.com/btcsuite/snappy-go v1.0.0/go.mod h1:8woku9dyThutzjeg+3xrA5iCpBRH8XEEg3lh6TiUghc=\ngithub.com/btcsuite/websocket v0.0.0-20150119174127-31079b680792 h1:R8vQdOQdZ9Y3SkEwmHoWBmX1DNXhXZqlTpq6s4tyJGc=\ngithub.com/btcsuite/websocket v0.0.0-20150119174127-31079b680792/go.mod h1:ghJtEyQwv5/p4Mg4C0fgbePVuGr935/5ddU9Z3TmDRY=\ngithub.com/btcsuite/winsvc v1.0.0 h1:J9B4L7e3oqhXOcm+2IuNApwzQec85lE+QaikUcCs+dk=\ngithub.com/btcsuite/winsvc v1.0.0/go.mod h1:jsenWakMcC0zFBFurPLEAyrnc/teJEM1O46fmI40EZs=\ngithub.com/davecgh/go-spew v0.0.0-20171005155431-ecdeabc65495/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/decred/dcrd/crypto/blake256 v1.0.0 h1:/8DMNYp9SGi5f0w7uCm6d6M4OU2rGFK09Y2A4Xv7EE0=\ngithub.com/decred/dcrd/crypto/blake256 v1.0.0/go.mod h1:sQl2p6Y26YV+ZOcSTP6thNdn47hh8kt6rqSlvmrXFAc=\ngithub.com/decred/dcrd/dcrec/secp256k1/v4 v4.0.1 h1:YLtO71vCjJRCBcrPMtQ9nqBsqpA1m5sE92cU+pd5Mcc=\ngithub.com/decred/dcrd/dcrec/secp256k1/v4 v4.0.1/go.mod h1:hyedUtir6IdtD/7lIxGeCxkaw7y45JueMRL4DIyJDKs=\ngithub.com/decred/dcrd/lru v1.0.0 h1:Kbsb1SFDsIlaupWPwsPp+dkxiBY1frcS07PCPgotKz8=\ngithub.com/decred/dcrd/lru v1.0.0/go.mod h1:mxKOwFd7lFjN2GZYsiz/ecgqR6kkYAl+0pz0tEMk218=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.9 h1:hsms1Qyu0jgnwNXIxa+/V/PDsU6CfLf6CNO8H7IWoS4=\ngithub.com/fsnotify/fsnotify v1.4.9/go.mod h1:znqG4EE+3YCdAaPaxE2ZRY/06pZUdp0tY4IgpuI1SZQ=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/gorilla/websocket v1.5.0 h1:PPwGk2jz7EePpoHN/+ClbZu8SPxiqlu12wZP/3sWmnc=\ngithub.com/gorilla/websocket v1.5.0/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/jessevdk/go-flags v0.0.0-20141203071132-1679536dcc89/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=\ngithub.com/jessevdk/go-flags v1.4.0 h1:4IU2WS7AumrZ/40jfhf4QVDMsQwqA7VEHozFRrGARJA=\ngithub.com/jessevdk/go-flags v1.4.0/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=\ngithub.com/jrick/logrotate v1.0.0 h1:lQ1bL/n9mBNeIXoTUoYRlK4dHuNJVofX9oWqBtPnSzI=\ngithub.com/jrick/logrotate v1.0.0/go.mod h1:LNinyqDIJnpAur+b8yyulnQw/wDuN1+BYKlTRt3OuAQ=\ngithub.com/kkdai/bstream v0.0.0-20161212061736-f391b8402d23 h1:FOOIBWrEkLgmlgGfMuZT83xIwfPDxEI2OHu6xUmJMFE=\ngithub.com/kkdai/bstream v0.0.0-20161212061736-f391b8402d23/go.mod h1:J+Gs4SYgM6CZQHDETBtE9HaSEkGmuNXF86RwHhHUvq4=\ngithub.com/nxadm/tail v1.4.4 h1:DQuhQpB1tVlglWS2hLQ5OV6B5r8aGxSrPc5Qo6uTN78=\ngithub.com/nxadm/tail v1.4.4/go.mod h1:kenIhsEOeOJmVchQTgglprH7qJGnHDVpk1VPCcaMI8A=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.7.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.12.1/go.mod h1:zj2OWP4+oCPe1qIXoGWkgMRwljMUYCdkwsT2108oapk=\ngithub.com/onsi/ginkgo v1.14.0 h1:2mOpI4JVVPBN+WQRa0WKH2eXR+Ey+uK4n7Zj0aYpIQA=\ngithub.com/onsi/ginkgo v1.14.0/go.mod h1:iSB4RoI2tjJc9BBv4NKIKWKya62Rps+oPG/Lv9klQyY=\ngithub.com/onsi/gomega v1.4.1/go.mod h1:C1qb7wdrVGGVU+Z6iS04AVkA3Q65CEZX59MT0QO5uiA=\ngithub.com/onsi/gomega v1.4.3/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/onsi/gomega v1.7.1/go.mod h1:XdKZgCCFLUoM/7CFJVPcG8C1xQ1AJ0vpAezJrB7JYyY=\ngithub.com/onsi/gomega v1.10.1 h1:o0+MgICZLuZ7xjH7Vx6zS/zcu93/BEp1VwkIW1mEXCE=\ngithub.com/onsi/gomega v1.10.1/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0 h1:1zr/of2m5FGMsad5YfcqgdqdWrIhu+EBEJRhR1U7z/c=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.4 h1:CcVxjf3Q8PM0mHUKJCdn+eZZtm5yQwehR5yeSVQQcUk=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/syndtr/goleveldb v1.0.1-0.20210819022825-2ae1ddf74ef7 h1:epCh84lMvA70Z7CTTCmYQn2CKbY8j86K7/FAIr141uY=\ngithub.com/syndtr/goleveldb v1.0.1-0.20210819022825-2ae1ddf74ef7/go.mod h1:q4W45IWZaF22tdD+VEXcAWRA037jwmWEB5VWYORlTpc=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngolang.org/x/crypto v0.0.0-20170930174604-9419663f5a44/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.19.0/go.mod h1:Iy9bg/ha4yyC70EfRS8jz+B6ybOBKMaSxLj6P6oBDfU=\ngolang.org/x/crypto v0.22.0 h1:g1v0xeRhjcugydODzvb3mEM9SQ0HGp9s/nh3COQ/C30=\ngolang.org/x/crypto v0.22.0/go.mod h1:vr6Su+7cTlO45qkww3VDJlzDn0ctJvRgYbC2NvXHt+M=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/net v0.0.0-20180719180050-a680a1efc54d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200520004742-59133d7f0dd7/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200813134508-3edf25e44fcc/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.10.0/go.mod h1:0qNGK6F8kojg2nk9dLZ2mShWaEBan6FAoqfSigmmuDg=\ngolang.org/x/net v0.21.0/go.mod h1:bIjVDfnllIU7BJ2DNgfnXvpSvtn8VRwhlsaeUTyUS44=\ngolang.org/x/net v0.24.0 h1:1PcaxkF854Fu3+lvBIx5SYn9wRlBzzcnHZSiaFFAb0w=\ngolang.org/x/net v0.24.0/go.mod h1:2Q7sJY5mzlzWjKtYUEXSlBWCdyaioyXzRB2RtU8KVE8=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190904154756-749cb33beabd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191120155948-bd437916bb0e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200519105757-fe76b779f299/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200814200057-3d37ad5750ed/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.17.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.19.0 h1:q5f1RH2jigJ1MoAWp2KTp3gm5zAGFUTarQZ5U386+4o=\ngolang.org/x/sys v0.19.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.8.0/go.mod h1:xPskH00ivmX89bAKVGSKKtLOWNx2+17Eiy94tnKShWo=\ngolang.org/x/term v0.17.0/go.mod h1:lLRBjIVuehSbZlaOtGMbcMncT+aqLLLmKrsjNrUguwk=\ngolang.org/x/term v0.19.0/go.mod h1:2CuTdWZ7KHSQwUzKva0cbMg6q2DMI3Mmxp+gKJbskEk=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.9.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=\ngolang.org/x/text v0.14.0 h1:ScX5w1eTa3QqT8oi6+ziP7dTV1S2+ALU0bI+0zXKWiQ=\ngolang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 h1:go1bK/D/BFZV2I8cIQd1NKEZ+0owSTG1fDTci4IqFcE=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 h1:uRGJdciOHaEIrze2W8Q3AKkepLTh2hOroT7a+7czfdQ=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0 h1:clyUAQHOM3G0M3f5vQj7LuJrETvjVot3Z5el9nffUtU=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "integration",
          "type": "tree",
          "content": null
        },
        {
          "name": "limits",
          "type": "tree",
          "content": null
        },
        {
          "name": "log.go",
          "type": "blob",
          "size": 4.9306640625,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Copyright (c) 2017 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/btcsuite/btcd/addrmgr\"\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/blockchain/indexers\"\n\t\"github.com/btcsuite/btcd/connmgr\"\n\t\"github.com/btcsuite/btcd/database\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/mining\"\n\t\"github.com/btcsuite/btcd/mining/cpuminer\"\n\t\"github.com/btcsuite/btcd/netsync\"\n\t\"github.com/btcsuite/btcd/peer\"\n\t\"github.com/btcsuite/btcd/txscript\"\n\n\t\"github.com/btcsuite/btclog\"\n\t\"github.com/jrick/logrotate/rotator\"\n)\n\n// logWriter implements an io.Writer that outputs to both standard output and\n// the write-end pipe of an initialized log rotator.\ntype logWriter struct{}\n\nfunc (logWriter) Write(p []byte) (n int, err error) {\n\tos.Stdout.Write(p)\n\tlogRotator.Write(p)\n\treturn len(p), nil\n}\n\n// Loggers per subsystem.  A single backend logger is created and all subsystem\n// loggers created from it will write to the backend.  When adding new\n// subsystems, add the subsystem logger variable here and to the\n// subsystemLoggers map.\n//\n// Loggers can not be used before the log rotator has been initialized with a\n// log file.  This must be performed early during application startup by calling\n// initLogRotator.\nvar (\n\t// backendLog is the logging backend used to create all subsystem loggers.\n\t// The backend must not be used before the log rotator has been initialized,\n\t// or data races and/or nil pointer dereferences will occur.\n\tbackendLog = btclog.NewBackend(logWriter{})\n\n\t// logRotator is one of the logging outputs.  It should be closed on\n\t// application shutdown.\n\tlogRotator *rotator.Rotator\n\n\tadxrLog = backendLog.Logger(\"ADXR\")\n\tamgrLog = backendLog.Logger(\"AMGR\")\n\tcmgrLog = backendLog.Logger(\"CMGR\")\n\tbcdbLog = backendLog.Logger(\"BCDB\")\n\tbtcdLog = backendLog.Logger(\"BTCD\")\n\tchanLog = backendLog.Logger(\"CHAN\")\n\tdiscLog = backendLog.Logger(\"DISC\")\n\tindxLog = backendLog.Logger(\"INDX\")\n\tminrLog = backendLog.Logger(\"MINR\")\n\tpeerLog = backendLog.Logger(\"PEER\")\n\trpcsLog = backendLog.Logger(\"RPCS\")\n\tscrpLog = backendLog.Logger(\"SCRP\")\n\tsrvrLog = backendLog.Logger(\"SRVR\")\n\tsyncLog = backendLog.Logger(\"SYNC\")\n\ttxmpLog = backendLog.Logger(\"TXMP\")\n)\n\n// Initialize package-global logger variables.\nfunc init() {\n\taddrmgr.UseLogger(amgrLog)\n\tconnmgr.UseLogger(cmgrLog)\n\tdatabase.UseLogger(bcdbLog)\n\tblockchain.UseLogger(chanLog)\n\tindexers.UseLogger(indxLog)\n\tmining.UseLogger(minrLog)\n\tcpuminer.UseLogger(minrLog)\n\tpeer.UseLogger(peerLog)\n\ttxscript.UseLogger(scrpLog)\n\tnetsync.UseLogger(syncLog)\n\tmempool.UseLogger(txmpLog)\n}\n\n// subsystemLoggers maps each subsystem identifier to its associated logger.\nvar subsystemLoggers = map[string]btclog.Logger{\n\t\"ADXR\": adxrLog,\n\t\"AMGR\": amgrLog,\n\t\"CMGR\": cmgrLog,\n\t\"BCDB\": bcdbLog,\n\t\"BTCD\": btcdLog,\n\t\"CHAN\": chanLog,\n\t\"DISC\": discLog,\n\t\"INDX\": indxLog,\n\t\"MINR\": minrLog,\n\t\"PEER\": peerLog,\n\t\"RPCS\": rpcsLog,\n\t\"SCRP\": scrpLog,\n\t\"SRVR\": srvrLog,\n\t\"SYNC\": syncLog,\n\t\"TXMP\": txmpLog,\n}\n\n// initLogRotator initializes the logging rotater to write logs to logFile and\n// create roll files in the same directory.  It must be called before the\n// package-global log rotater variables are used.\nfunc initLogRotator(logFile string) {\n\tlogDir, _ := filepath.Split(logFile)\n\terr := os.MkdirAll(logDir, 0700)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"failed to create log directory: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tr, err := rotator.New(logFile, 10*1024, false, 3)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"failed to create file rotator: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogRotator = r\n}\n\n// setLogLevel sets the logging level for provided subsystem.  Invalid\n// subsystems are ignored.  Uninitialized subsystems are dynamically created as\n// needed.\nfunc setLogLevel(subsystemID string, logLevel string) {\n\t// Ignore invalid subsystems.\n\tlogger, ok := subsystemLoggers[subsystemID]\n\tif !ok {\n\t\treturn\n\t}\n\n\t// Defaults to info if the log level is invalid.\n\tlevel, _ := btclog.LevelFromString(logLevel)\n\tlogger.SetLevel(level)\n}\n\n// setLogLevels sets the log level for all subsystem loggers to the passed\n// level.  It also dynamically creates the subsystem loggers as needed, so it\n// can be used to initialize the logging system.\nfunc setLogLevels(logLevel string) {\n\t// Configure all sub-systems with the new logging level.  Dynamically\n\t// create loggers as needed.\n\tfor subsystemID := range subsystemLoggers {\n\t\tsetLogLevel(subsystemID, logLevel)\n\t}\n}\n\n// directionString is a helper function that returns a string that represents\n// the direction of a connection (inbound or outbound).\nfunc directionString(inbound bool) string {\n\tif inbound {\n\t\treturn \"inbound\"\n\t}\n\treturn \"outbound\"\n}\n\n// pickNoun returns the singular or plural form of a noun depending\n// on the count n.\nfunc pickNoun(n uint64, singular, plural string) string {\n\tif n == 1 {\n\t\treturn singular\n\t}\n\treturn plural\n}\n"
        },
        {
          "name": "mempool",
          "type": "tree",
          "content": null
        },
        {
          "name": "mining",
          "type": "tree",
          "content": null
        },
        {
          "name": "netsync",
          "type": "tree",
          "content": null
        },
        {
          "name": "ossec",
          "type": "tree",
          "content": null
        },
        {
          "name": "params.go",
          "type": "blob",
          "size": 2.7470703125,
          "content": "// Copyright (c) 2013-2016 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"github.com/btcsuite/btcd/chaincfg\"\n\t\"github.com/btcsuite/btcd/wire\"\n)\n\n// activeNetParams is a pointer to the parameters specific to the\n// currently active bitcoin network.\nvar activeNetParams = &mainNetParams\n\n// params is used to group parameters for various networks such as the main\n// network and test networks.\ntype params struct {\n\t*chaincfg.Params\n\trpcPort string\n}\n\n// mainNetParams contains parameters specific to the main network\n// (wire.MainNet).  NOTE: The RPC port is intentionally different than the\n// reference implementation because btcd does not handle wallet requests.  The\n// separate wallet process listens on the well-known port and forwards requests\n// it does not handle on to btcd.  This approach allows the wallet process\n// to emulate the full reference implementation RPC API.\nvar mainNetParams = params{\n\tParams:  &chaincfg.MainNetParams,\n\trpcPort: \"8334\",\n}\n\n// regressionNetParams contains parameters specific to the regression test\n// network (wire.TestNet).  NOTE: The RPC port is intentionally different\n// than the reference implementation - see the mainNetParams comment for\n// details.\nvar regressionNetParams = params{\n\tParams:  &chaincfg.RegressionNetParams,\n\trpcPort: \"18334\",\n}\n\n// testNet3Params contains parameters specific to the test network (version 3)\n// (wire.TestNet3).  NOTE: The RPC port is intentionally different than the\n// reference implementation - see the mainNetParams comment for details.\nvar testNet3Params = params{\n\tParams:  &chaincfg.TestNet3Params,\n\trpcPort: \"18334\",\n}\n\n// simNetParams contains parameters specific to the simulation test network\n// (wire.SimNet).\nvar simNetParams = params{\n\tParams:  &chaincfg.SimNetParams,\n\trpcPort: \"18556\",\n}\n\n// sigNetParams contains parameters specific to the Signet network\n// (wire.SigNet).\nvar sigNetParams = params{\n\tParams:  &chaincfg.SigNetParams,\n\trpcPort: \"38332\",\n}\n\n// netName returns the name used when referring to a bitcoin network.  At the\n// time of writing, btcd currently places blocks for testnet version 3 in the\n// data and log directory \"testnet\", which does not match the Name field of the\n// chaincfg parameters.  This function can be used to override this directory\n// name as \"testnet\" when the passed active network matches wire.TestNet3.\n//\n// A proper upgrade to move the data and log directories for this network to\n// \"testnet3\" is planned for the future, at which point this function can be\n// removed and the network parameter's name used instead.\nfunc netName(chainParams *params) string {\n\tswitch chainParams.Net {\n\tcase wire.TestNet3:\n\t\treturn \"testnet\"\n\tdefault:\n\t\treturn chainParams.Name\n\t}\n}\n"
        },
        {
          "name": "peer",
          "type": "tree",
          "content": null
        },
        {
          "name": "release",
          "type": "tree",
          "content": null
        },
        {
          "name": "rpcadapters.go",
          "type": "blob",
          "size": 9.734375,
          "content": "// Copyright (c) 2017 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"sync/atomic\"\n\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/netsync\"\n\t\"github.com/btcsuite/btcd/peer\"\n\t\"github.com/btcsuite/btcd/wire\"\n)\n\n// rpcPeer provides a peer for use with the RPC server and implements the\n// rpcserverPeer interface.\ntype rpcPeer serverPeer\n\n// Ensure rpcPeer implements the rpcserverPeer interface.\nvar _ rpcserverPeer = (*rpcPeer)(nil)\n\n// ToPeer returns the underlying peer instance.\n//\n// This function is safe for concurrent access and is part of the rpcserverPeer\n// interface implementation.\nfunc (p *rpcPeer) ToPeer() *peer.Peer {\n\tif p == nil {\n\t\treturn nil\n\t}\n\treturn (*serverPeer)(p).Peer\n}\n\n// IsTxRelayDisabled returns whether or not the peer has disabled transaction\n// relay.\n//\n// This function is safe for concurrent access and is part of the rpcserverPeer\n// interface implementation.\nfunc (p *rpcPeer) IsTxRelayDisabled() bool {\n\treturn (*serverPeer)(p).disableRelayTx\n}\n\n// BanScore returns the current integer value that represents how close the peer\n// is to being banned.\n//\n// This function is safe for concurrent access and is part of the rpcserverPeer\n// interface implementation.\nfunc (p *rpcPeer) BanScore() uint32 {\n\treturn (*serverPeer)(p).banScore.Int()\n}\n\n// FeeFilter returns the requested current minimum fee rate for which\n// transactions should be announced.\n//\n// This function is safe for concurrent access and is part of the rpcserverPeer\n// interface implementation.\nfunc (p *rpcPeer) FeeFilter() int64 {\n\treturn atomic.LoadInt64(&(*serverPeer)(p).feeFilter)\n}\n\n// rpcConnManager provides a connection manager for use with the RPC server and\n// implements the rpcserverConnManager interface.\ntype rpcConnManager struct {\n\tserver *server\n}\n\n// Ensure rpcConnManager implements the rpcserverConnManager interface.\nvar _ rpcserverConnManager = &rpcConnManager{}\n\n// Connect adds the provided address as a new outbound peer.  The permanent flag\n// indicates whether or not to make the peer persistent and reconnect if the\n// connection is lost.  Attempting to connect to an already existing peer will\n// return an error.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) Connect(addr string, permanent bool) error {\n\treplyChan := make(chan error)\n\tcm.server.query <- connectNodeMsg{\n\t\taddr:      addr,\n\t\tpermanent: permanent,\n\t\treply:     replyChan,\n\t}\n\treturn <-replyChan\n}\n\n// RemoveByID removes the peer associated with the provided id from the list of\n// persistent peers.  Attempting to remove an id that does not exist will return\n// an error.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) RemoveByID(id int32) error {\n\treplyChan := make(chan error)\n\tcm.server.query <- removeNodeMsg{\n\t\tcmp:   func(sp *serverPeer) bool { return sp.ID() == id },\n\t\treply: replyChan,\n\t}\n\treturn <-replyChan\n}\n\n// RemoveByAddr removes the peer associated with the provided address from the\n// list of persistent peers.  Attempting to remove an address that does not\n// exist will return an error.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) RemoveByAddr(addr string) error {\n\treplyChan := make(chan error)\n\tcm.server.query <- removeNodeMsg{\n\t\tcmp:   func(sp *serverPeer) bool { return sp.Addr() == addr },\n\t\treply: replyChan,\n\t}\n\treturn <-replyChan\n}\n\n// DisconnectByID disconnects the peer associated with the provided id.  This\n// applies to both inbound and outbound peers.  Attempting to remove an id that\n// does not exist will return an error.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) DisconnectByID(id int32) error {\n\treplyChan := make(chan error)\n\tcm.server.query <- disconnectNodeMsg{\n\t\tcmp:   func(sp *serverPeer) bool { return sp.ID() == id },\n\t\treply: replyChan,\n\t}\n\treturn <-replyChan\n}\n\n// DisconnectByAddr disconnects the peer associated with the provided address.\n// This applies to both inbound and outbound peers.  Attempting to remove an\n// address that does not exist will return an error.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) DisconnectByAddr(addr string) error {\n\treplyChan := make(chan error)\n\tcm.server.query <- disconnectNodeMsg{\n\t\tcmp:   func(sp *serverPeer) bool { return sp.Addr() == addr },\n\t\treply: replyChan,\n\t}\n\treturn <-replyChan\n}\n\n// ConnectedCount returns the number of currently connected peers.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) ConnectedCount() int32 {\n\treturn cm.server.ConnectedCount()\n}\n\n// NetTotals returns the sum of all bytes received and sent across the network\n// for all peers.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) NetTotals() (uint64, uint64) {\n\treturn cm.server.NetTotals()\n}\n\n// ConnectedPeers returns an array consisting of all connected peers.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) ConnectedPeers() []rpcserverPeer {\n\treplyChan := make(chan []*serverPeer)\n\tcm.server.query <- getPeersMsg{reply: replyChan}\n\tserverPeers := <-replyChan\n\n\t// Convert to RPC server peers.\n\tpeers := make([]rpcserverPeer, 0, len(serverPeers))\n\tfor _, sp := range serverPeers {\n\t\tpeers = append(peers, (*rpcPeer)(sp))\n\t}\n\treturn peers\n}\n\n// PersistentPeers returns an array consisting of all the added persistent\n// peers.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) PersistentPeers() []rpcserverPeer {\n\treplyChan := make(chan []*serverPeer)\n\tcm.server.query <- getAddedNodesMsg{reply: replyChan}\n\tserverPeers := <-replyChan\n\n\t// Convert to generic peers.\n\tpeers := make([]rpcserverPeer, 0, len(serverPeers))\n\tfor _, sp := range serverPeers {\n\t\tpeers = append(peers, (*rpcPeer)(sp))\n\t}\n\treturn peers\n}\n\n// BroadcastMessage sends the provided message to all currently connected peers.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) BroadcastMessage(msg wire.Message) {\n\tcm.server.BroadcastMessage(msg)\n}\n\n// AddRebroadcastInventory adds the provided inventory to the list of\n// inventories to be rebroadcast at random intervals until they show up in a\n// block.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) AddRebroadcastInventory(iv *wire.InvVect, data interface{}) {\n\tcm.server.AddRebroadcastInventory(iv, data)\n}\n\n// RelayTransactions generates and relays inventory vectors for all of the\n// passed transactions to all connected peers.\nfunc (cm *rpcConnManager) RelayTransactions(txns []*mempool.TxDesc) {\n\tcm.server.relayTransactions(txns)\n}\n\n// NodeAddresses returns an array consisting node addresses which can\n// potentially be used to find new nodes in the network.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverConnManager interface implementation.\nfunc (cm *rpcConnManager) NodeAddresses() []*wire.NetAddressV2 {\n\treturn cm.server.addrManager.AddressCache()\n}\n\n// rpcSyncMgr provides a block manager for use with the RPC server and\n// implements the rpcserverSyncManager interface.\ntype rpcSyncMgr struct {\n\tserver  *server\n\tsyncMgr *netsync.SyncManager\n}\n\n// Ensure rpcSyncMgr implements the rpcserverSyncManager interface.\nvar _ rpcserverSyncManager = (*rpcSyncMgr)(nil)\n\n// IsCurrent returns whether or not the sync manager believes the chain is\n// current as compared to the rest of the network.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverSyncManager interface implementation.\nfunc (b *rpcSyncMgr) IsCurrent() bool {\n\treturn b.syncMgr.IsCurrent()\n}\n\n// SubmitBlock submits the provided block to the network after processing it\n// locally.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverSyncManager interface implementation.\nfunc (b *rpcSyncMgr) SubmitBlock(block *btcutil.Block, flags blockchain.BehaviorFlags) (bool, error) {\n\treturn b.syncMgr.ProcessBlock(block, flags)\n}\n\n// Pause pauses the sync manager until the returned channel is closed.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverSyncManager interface implementation.\nfunc (b *rpcSyncMgr) Pause() chan<- struct{} {\n\treturn b.syncMgr.Pause()\n}\n\n// SyncPeerID returns the peer that is currently the peer being used to sync\n// from.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverSyncManager interface implementation.\nfunc (b *rpcSyncMgr) SyncPeerID() int32 {\n\treturn b.syncMgr.SyncPeerID()\n}\n\n// LocateHeaders returns the hashes of the blocks after the first known block in\n// the provided locators until the provided stop hash or the current tip is\n// reached, up to a max of wire.MaxBlockHeadersPerMsg hashes.\n//\n// This function is safe for concurrent access and is part of the\n// rpcserverSyncManager interface implementation.\nfunc (b *rpcSyncMgr) LocateHeaders(locators []*chainhash.Hash, hashStop *chainhash.Hash) []wire.BlockHeader {\n\treturn b.server.chain.LocateHeaders(locators, hashStop)\n}\n"
        },
        {
          "name": "rpcclient",
          "type": "tree",
          "content": null
        },
        {
          "name": "rpcserver.go",
          "type": "blob",
          "size": 153.7109375,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Copyright (c) 2015-2017 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"bytes\"\n\t\"crypto/sha256\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"math/big\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/blockchain/indexers\"\n\t\"github.com/btcsuite/btcd/btcec/v2/ecdsa\"\n\t\"github.com/btcsuite/btcd/btcjson\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/chaincfg\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/database\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/mining\"\n\t\"github.com/btcsuite/btcd/mining/cpuminer\"\n\t\"github.com/btcsuite/btcd/peer\"\n\t\"github.com/btcsuite/btcd/txscript\"\n\t\"github.com/btcsuite/btcd/wire\"\n\t\"github.com/btcsuite/websocket\"\n)\n\n// API version constants\nconst (\n\tjsonrpcSemverString = \"1.3.0\"\n\tjsonrpcSemverMajor  = 1\n\tjsonrpcSemverMinor  = 3\n\tjsonrpcSemverPatch  = 0\n)\n\nconst (\n\t// rpcAuthTimeoutSeconds is the number of seconds a connection to the\n\t// RPC server is allowed to stay open without authenticating before it\n\t// is closed.\n\trpcAuthTimeoutSeconds = 10\n\n\t// uint256Size is the number of bytes needed to represent an unsigned\n\t// 256-bit integer.\n\tuint256Size = 32\n\n\t// gbtNonceRange is two 32-bit big-endian hexadecimal integers which\n\t// represent the valid ranges of nonces returned by the getblocktemplate\n\t// RPC.\n\tgbtNonceRange = \"00000000ffffffff\"\n\n\t// gbtRegenerateSeconds is the number of seconds that must pass before\n\t// a new template is generated when the previous block hash has not\n\t// changed and there have been changes to the available transactions\n\t// in the memory pool.\n\tgbtRegenerateSeconds = 60\n\n\t// maxProtocolVersion is the max protocol version the server supports.\n\tmaxProtocolVersion = 70002\n\n\t// defaultMaxFeeRate is the default value to use(0.1 BTC/kvB) when the\n\t// `MaxFee` field is not set when calling `testmempoolaccept`.\n\tdefaultMaxFeeRate = 0.1\n)\n\nvar (\n\t// gbtMutableFields are the manipulations the server allows to be made\n\t// to block templates generated by the getblocktemplate RPC.  It is\n\t// declared here to avoid the overhead of creating the slice on every\n\t// invocation for constant data.\n\tgbtMutableFields = []string{\n\t\t\"time\", \"transactions/add\", \"prevblock\", \"coinbase/append\",\n\t}\n\n\t// gbtCoinbaseAux describes additional data that miners should include\n\t// in the coinbase signature script.  It is declared here to avoid the\n\t// overhead of creating a new object on every invocation for constant\n\t// data.\n\tgbtCoinbaseAux = &btcjson.GetBlockTemplateResultAux{\n\t\tFlags: hex.EncodeToString(builderScript(txscript.\n\t\t\tNewScriptBuilder().\n\t\t\tAddData([]byte(mining.CoinbaseFlags)))),\n\t}\n\n\t// gbtCapabilities describes additional capabilities returned with a\n\t// block template generated by the getblocktemplate RPC.    It is\n\t// declared here to avoid the overhead of creating the slice on every\n\t// invocation for constant data.\n\tgbtCapabilities = []string{\"proposal\"}\n\n\t// JSON 2.0 batched request prefix\n\tbatchedRequestPrefix = []byte(\"[\")\n)\n\n// Errors\nvar (\n\t// ErrRPCUnimplemented is an error returned to RPC clients when the\n\t// provided command is recognized, but not implemented.\n\tErrRPCUnimplemented = &btcjson.RPCError{\n\t\tCode:    btcjson.ErrRPCUnimplemented,\n\t\tMessage: \"Command unimplemented\",\n\t}\n\n\t// ErrRPCNoWallet is an error returned to RPC clients when the provided\n\t// command is recognized as a wallet command.\n\tErrRPCNoWallet = &btcjson.RPCError{\n\t\tCode:    btcjson.ErrRPCNoWallet,\n\t\tMessage: \"This implementation does not implement wallet commands\",\n\t}\n)\n\ntype commandHandler func(*rpcServer, interface{}, <-chan struct{}) (interface{}, error)\n\n// rpcHandlers maps RPC command strings to appropriate handler functions.\n// This is set by init because help references rpcHandlers and thus causes\n// a dependency loop.\nvar rpcHandlers map[string]commandHandler\nvar rpcHandlersBeforeInit = map[string]commandHandler{\n\t\"addnode\":                handleAddNode,\n\t\"createrawtransaction\":   handleCreateRawTransaction,\n\t\"debuglevel\":             handleDebugLevel,\n\t\"decoderawtransaction\":   handleDecodeRawTransaction,\n\t\"decodescript\":           handleDecodeScript,\n\t\"estimatefee\":            handleEstimateFee,\n\t\"generate\":               handleGenerate,\n\t\"getaddednodeinfo\":       handleGetAddedNodeInfo,\n\t\"getbestblock\":           handleGetBestBlock,\n\t\"getbestblockhash\":       handleGetBestBlockHash,\n\t\"getblock\":               handleGetBlock,\n\t\"getblockchaininfo\":      handleGetBlockChainInfo,\n\t\"getblockcount\":          handleGetBlockCount,\n\t\"getblockhash\":           handleGetBlockHash,\n\t\"getblockheader\":         handleGetBlockHeader,\n\t\"getblocktemplate\":       handleGetBlockTemplate,\n\t\"getchaintips\":           handleGetChainTips,\n\t\"getcfilter\":             handleGetCFilter,\n\t\"getcfilterheader\":       handleGetCFilterHeader,\n\t\"getconnectioncount\":     handleGetConnectionCount,\n\t\"getcurrentnet\":          handleGetCurrentNet,\n\t\"getdifficulty\":          handleGetDifficulty,\n\t\"getgenerate\":            handleGetGenerate,\n\t\"gethashespersec\":        handleGetHashesPerSec,\n\t\"getheaders\":             handleGetHeaders,\n\t\"getinfo\":                handleGetInfo,\n\t\"getmempoolinfo\":         handleGetMempoolInfo,\n\t\"getmininginfo\":          handleGetMiningInfo,\n\t\"getnettotals\":           handleGetNetTotals,\n\t\"getnetworkhashps\":       handleGetNetworkHashPS,\n\t\"getnodeaddresses\":       handleGetNodeAddresses,\n\t\"getpeerinfo\":            handleGetPeerInfo,\n\t\"getrawmempool\":          handleGetRawMempool,\n\t\"getrawtransaction\":      handleGetRawTransaction,\n\t\"gettxout\":               handleGetTxOut,\n\t\"help\":                   handleHelp,\n\t\"invalidateblock\":        handleInvalidateBlock,\n\t\"node\":                   handleNode,\n\t\"ping\":                   handlePing,\n\t\"reconsiderblock\":        handleReconsiderBlock,\n\t\"searchrawtransactions\":  handleSearchRawTransactions,\n\t\"sendrawtransaction\":     handleSendRawTransaction,\n\t\"setgenerate\":            handleSetGenerate,\n\t\"signmessagewithprivkey\": handleSignMessageWithPrivKey,\n\t\"stop\":                   handleStop,\n\t\"submitblock\":            handleSubmitBlock,\n\t\"uptime\":                 handleUptime,\n\t\"validateaddress\":        handleValidateAddress,\n\t\"verifychain\":            handleVerifyChain,\n\t\"verifymessage\":          handleVerifyMessage,\n\t\"version\":                handleVersion,\n\t\"testmempoolaccept\":      handleTestMempoolAccept,\n\t\"gettxspendingprevout\":   handleGetTxSpendingPrevOut,\n}\n\n// list of commands that we recognize, but for which btcd has no support because\n// it lacks support for wallet functionality. For these commands the user\n// should ask a connected instance of btcwallet.\nvar rpcAskWallet = map[string]struct{}{\n\t\"addmultisigaddress\":     {},\n\t\"backupwallet\":           {},\n\t\"createencryptedwallet\":  {},\n\t\"createmultisig\":         {},\n\t\"dumpprivkey\":            {},\n\t\"dumpwallet\":             {},\n\t\"encryptwallet\":          {},\n\t\"getaccount\":             {},\n\t\"getaccountaddress\":      {},\n\t\"getaddressesbyaccount\":  {},\n\t\"getbalance\":             {},\n\t\"getnewaddress\":          {},\n\t\"getrawchangeaddress\":    {},\n\t\"getreceivedbyaccount\":   {},\n\t\"getreceivedbyaddress\":   {},\n\t\"gettransaction\":         {},\n\t\"gettxoutsetinfo\":        {},\n\t\"getunconfirmedbalance\":  {},\n\t\"getwalletinfo\":          {},\n\t\"importprivkey\":          {},\n\t\"importwallet\":           {},\n\t\"keypoolrefill\":          {},\n\t\"listaccounts\":           {},\n\t\"listaddressgroupings\":   {},\n\t\"listlockunspent\":        {},\n\t\"listreceivedbyaccount\":  {},\n\t\"listreceivedbyaddress\":  {},\n\t\"listsinceblock\":         {},\n\t\"listtransactions\":       {},\n\t\"listunspent\":            {},\n\t\"lockunspent\":            {},\n\t\"move\":                   {},\n\t\"sendfrom\":               {},\n\t\"sendmany\":               {},\n\t\"sendtoaddress\":          {},\n\t\"setaccount\":             {},\n\t\"settxfee\":               {},\n\t\"signmessage\":            {},\n\t\"signrawtransaction\":     {},\n\t\"walletlock\":             {},\n\t\"walletpassphrase\":       {},\n\t\"walletpassphrasechange\": {},\n}\n\n// Commands that are currently unimplemented, but should ultimately be.\nvar rpcUnimplemented = map[string]struct{}{\n\t\"estimatepriority\": {},\n\t\"getmempoolentry\":  {},\n\t\"getnetworkinfo\":   {},\n\t\"getwork\":          {},\n\t\"preciousblock\":    {},\n}\n\n// Commands that are available to a limited user\nvar rpcLimited = map[string]struct{}{\n\t// Websockets commands\n\t\"loadtxfilter\":          {},\n\t\"notifyblocks\":          {},\n\t\"notifynewtransactions\": {},\n\t\"notifyreceived\":        {},\n\t\"notifyspent\":           {},\n\t\"rescan\":                {},\n\t\"rescanblocks\":          {},\n\t\"session\":               {},\n\n\t// Websockets AND HTTP/S commands\n\t\"help\": {},\n\n\t// HTTP/S-only commands\n\t\"createrawtransaction\":  {},\n\t\"decoderawtransaction\":  {},\n\t\"decodescript\":          {},\n\t\"estimatefee\":           {},\n\t\"getbestblock\":          {},\n\t\"getbestblockhash\":      {},\n\t\"getblock\":              {},\n\t\"getblockcount\":         {},\n\t\"getblockhash\":          {},\n\t\"getblockheader\":        {},\n\t\"getchaintips\":          {},\n\t\"getcfilter\":            {},\n\t\"getcfilterheader\":      {},\n\t\"getcurrentnet\":         {},\n\t\"getdifficulty\":         {},\n\t\"getheaders\":            {},\n\t\"getinfo\":               {},\n\t\"getnettotals\":          {},\n\t\"getnetworkhashps\":      {},\n\t\"getrawmempool\":         {},\n\t\"getrawtransaction\":     {},\n\t\"gettxout\":              {},\n\t\"invalidateblock\":       {},\n\t\"reconsiderblock\":       {},\n\t\"searchrawtransactions\": {},\n\t\"sendrawtransaction\":    {},\n\t\"submitblock\":           {},\n\t\"uptime\":                {},\n\t\"validateaddress\":       {},\n\t\"verifymessage\":         {},\n\t\"version\":               {},\n}\n\n// builderScript is a convenience function which is used for hard-coded scripts\n// built with the script builder.   Any errors are converted to a panic since it\n// is only, and must only, be used with hard-coded, and therefore, known good,\n// scripts.\nfunc builderScript(builder *txscript.ScriptBuilder) []byte {\n\tscript, err := builder.Script()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn script\n}\n\n// internalRPCError is a convenience function to convert an internal error to\n// an RPC error with the appropriate code set.  It also logs the error to the\n// RPC server subsystem since internal errors really should not occur.  The\n// context parameter is only used in the log message and may be empty if it's\n// not needed.\nfunc internalRPCError(errStr, context string) *btcjson.RPCError {\n\tlogStr := errStr\n\tif context != \"\" {\n\t\tlogStr = context + \": \" + errStr\n\t}\n\trpcsLog.Error(logStr)\n\treturn btcjson.NewRPCError(btcjson.ErrRPCInternal.Code, errStr)\n}\n\n// rpcDecodeHexError is a convenience function for returning a nicely formatted\n// RPC error which indicates the provided hex string failed to decode.\nfunc rpcDecodeHexError(gotHex string) *btcjson.RPCError {\n\treturn btcjson.NewRPCError(btcjson.ErrRPCDecodeHexString,\n\t\tfmt.Sprintf(\"Argument must be hexadecimal string (not %q)\",\n\t\t\tgotHex))\n}\n\n// rpcNoTxInfoError is a convenience function for returning a nicely formatted\n// RPC error which indicates there is no information available for the provided\n// transaction hash.\nfunc rpcNoTxInfoError(txHash *chainhash.Hash) *btcjson.RPCError {\n\treturn btcjson.NewRPCError(btcjson.ErrRPCNoTxInfo,\n\t\tfmt.Sprintf(\"No information available about transaction %v\",\n\t\t\ttxHash))\n}\n\n// gbtWorkState houses state that is used in between multiple RPC invocations to\n// getblocktemplate.\ntype gbtWorkState struct {\n\tsync.Mutex\n\tlastTxUpdate  time.Time\n\tlastGenerated time.Time\n\tprevHash      *chainhash.Hash\n\tminTimestamp  time.Time\n\ttemplate      *mining.BlockTemplate\n\tnotifyMap     map[chainhash.Hash]map[int64]chan struct{}\n\ttimeSource    blockchain.MedianTimeSource\n}\n\n// newGbtWorkState returns a new instance of a gbtWorkState with all internal\n// fields initialized and ready to use.\nfunc newGbtWorkState(timeSource blockchain.MedianTimeSource) *gbtWorkState {\n\treturn &gbtWorkState{\n\t\tnotifyMap:  make(map[chainhash.Hash]map[int64]chan struct{}),\n\t\ttimeSource: timeSource,\n\t}\n}\n\n// handleUnimplemented is the handler for commands that should ultimately be\n// supported but are not yet implemented.\nfunc handleUnimplemented(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn nil, ErrRPCUnimplemented\n}\n\n// handleAskWallet is the handler for commands that are recognized as valid, but\n// are unable to answer correctly since it involves wallet state.\n// These commands will be implemented in btcwallet.\nfunc handleAskWallet(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn nil, ErrRPCNoWallet\n}\n\n// handleAddNode handles addnode commands.\nfunc handleAddNode(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.AddNodeCmd)\n\n\taddr := normalizeAddress(c.Addr, s.cfg.ChainParams.DefaultPort)\n\tvar err error\n\tswitch c.SubCmd {\n\tcase \"add\":\n\t\terr = s.cfg.ConnMgr.Connect(addr, true)\n\tcase \"remove\":\n\t\terr = s.cfg.ConnMgr.RemoveByAddr(addr)\n\tcase \"onetry\":\n\t\terr = s.cfg.ConnMgr.Connect(addr, false)\n\tdefault:\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: \"invalid subcommand for addnode\",\n\t\t}\n\t}\n\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: err.Error(),\n\t\t}\n\t}\n\n\t// no data returned unless an error.\n\treturn nil, nil\n}\n\n// handleNode handles node commands.\nfunc handleNode(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.NodeCmd)\n\n\tvar addr string\n\tvar nodeID uint64\n\tvar errN, err error\n\tparams := s.cfg.ChainParams\n\tswitch c.SubCmd {\n\tcase \"disconnect\":\n\t\t// If we have a valid uint disconnect by node id. Otherwise,\n\t\t// attempt to disconnect by address, returning an error if a\n\t\t// valid IP address is not supplied.\n\t\tif nodeID, errN = strconv.ParseUint(c.Target, 10, 32); errN == nil {\n\t\t\terr = s.cfg.ConnMgr.DisconnectByID(int32(nodeID))\n\t\t} else {\n\t\t\tif _, _, errP := net.SplitHostPort(c.Target); errP == nil || net.ParseIP(c.Target) != nil {\n\t\t\t\taddr = normalizeAddress(c.Target, params.DefaultPort)\n\t\t\t\terr = s.cfg.ConnMgr.DisconnectByAddr(addr)\n\t\t\t} else {\n\t\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\t\t\tMessage: \"invalid address or node ID\",\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif err != nil && peerExists(s.cfg.ConnMgr, addr, int32(nodeID)) {\n\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCMisc,\n\t\t\t\tMessage: \"can't disconnect a permanent peer, use remove\",\n\t\t\t}\n\t\t}\n\n\tcase \"remove\":\n\t\t// If we have a valid uint disconnect by node id. Otherwise,\n\t\t// attempt to disconnect by address, returning an error if a\n\t\t// valid IP address is not supplied.\n\t\tif nodeID, errN = strconv.ParseUint(c.Target, 10, 32); errN == nil {\n\t\t\terr = s.cfg.ConnMgr.RemoveByID(int32(nodeID))\n\t\t} else {\n\t\t\tif _, _, errP := net.SplitHostPort(c.Target); errP == nil || net.ParseIP(c.Target) != nil {\n\t\t\t\taddr = normalizeAddress(c.Target, params.DefaultPort)\n\t\t\t\terr = s.cfg.ConnMgr.RemoveByAddr(addr)\n\t\t\t} else {\n\t\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\t\t\tMessage: \"invalid address or node ID\",\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif err != nil && peerExists(s.cfg.ConnMgr, addr, int32(nodeID)) {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCMisc,\n\t\t\t\tMessage: \"can't remove a temporary peer, use disconnect\",\n\t\t\t}\n\t\t}\n\n\tcase \"connect\":\n\t\taddr = normalizeAddress(c.Target, params.DefaultPort)\n\n\t\t// Default to temporary connections.\n\t\tsubCmd := \"temp\"\n\t\tif c.ConnectSubCmd != nil {\n\t\t\tsubCmd = *c.ConnectSubCmd\n\t\t}\n\n\t\tswitch subCmd {\n\t\tcase \"perm\", \"temp\":\n\t\t\terr = s.cfg.ConnMgr.Connect(addr, subCmd == \"perm\")\n\t\tdefault:\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\t\tMessage: \"invalid subcommand for node connect\",\n\t\t\t}\n\t\t}\n\tdefault:\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: \"invalid subcommand for node\",\n\t\t}\n\t}\n\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: err.Error(),\n\t\t}\n\t}\n\n\t// no data returned unless an error.\n\treturn nil, nil\n}\n\n// peerExists determines if a certain peer is currently connected given\n// information about all currently connected peers. Peer existence is\n// determined using either a target address or node id.\nfunc peerExists(connMgr rpcserverConnManager, addr string, nodeID int32) bool {\n\tfor _, p := range connMgr.ConnectedPeers() {\n\t\tif p.ToPeer().ID() == nodeID || p.ToPeer().Addr() == addr {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// messageToHex serializes a message to the wire protocol encoding using the\n// latest protocol version and returns a hex-encoded string of the result.\nfunc messageToHex(msg wire.Message) (string, error) {\n\tvar buf bytes.Buffer\n\tif err := msg.BtcEncode(&buf, maxProtocolVersion, wire.WitnessEncoding); err != nil {\n\t\tcontext := fmt.Sprintf(\"Failed to encode msg of type %T\", msg)\n\t\treturn \"\", internalRPCError(err.Error(), context)\n\t}\n\n\treturn hex.EncodeToString(buf.Bytes()), nil\n}\n\n// handleCreateRawTransaction handles createrawtransaction commands.\nfunc handleCreateRawTransaction(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.CreateRawTransactionCmd)\n\n\t// Validate the locktime, if given.\n\tif c.LockTime != nil &&\n\t\t(*c.LockTime < 0 || *c.LockTime > int64(wire.MaxTxInSequenceNum)) {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: \"Locktime out of range\",\n\t\t}\n\t}\n\n\t// Add all transaction inputs to a new transaction after performing\n\t// some validity checks.\n\tmtx := wire.NewMsgTx(wire.TxVersion)\n\tfor _, input := range c.Inputs {\n\t\ttxHash, err := chainhash.NewHashFromStr(input.Txid)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(input.Txid)\n\t\t}\n\n\t\tprevOut := wire.NewOutPoint(txHash, input.Vout)\n\t\ttxIn := wire.NewTxIn(prevOut, []byte{}, nil)\n\t\tif c.LockTime != nil && *c.LockTime != 0 {\n\t\t\ttxIn.Sequence = wire.MaxTxInSequenceNum - 1\n\t\t}\n\t\tmtx.AddTxIn(txIn)\n\t}\n\n\t// Add all transaction outputs to the transaction after performing\n\t// some validity checks.\n\tparams := s.cfg.ChainParams\n\tfor encodedAddr, amount := range c.Amounts {\n\t\t// Ensure amount is in the valid range for monetary amounts.\n\t\tif amount <= 0 || amount*btcutil.SatoshiPerBitcoin > btcutil.MaxSatoshi {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCType,\n\t\t\t\tMessage: \"Invalid amount\",\n\t\t\t}\n\t\t}\n\n\t\t// Decode the provided address.\n\t\taddr, err := btcutil.DecodeAddress(encodedAddr, params)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\t\tMessage: \"Invalid address or key: \" + err.Error(),\n\t\t\t}\n\t\t}\n\n\t\t// Ensure the address is one of the supported types and that\n\t\t// the network encoded with the address matches the network the\n\t\t// server is currently on.\n\t\tswitch addr.(type) {\n\t\tcase *btcutil.AddressPubKeyHash:\n\t\tcase *btcutil.AddressScriptHash:\n\t\tdefault:\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\t\tMessage: \"Invalid address or key\",\n\t\t\t}\n\t\t}\n\t\tif !addr.IsForNet(params) {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\t\tMessage: \"Invalid address: \" + encodedAddr +\n\t\t\t\t\t\" is for the wrong network\",\n\t\t\t}\n\t\t}\n\n\t\t// Create a new script which pays to the provided address.\n\t\tpkScript, err := txscript.PayToAddrScript(addr)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to generate pay-to-address script\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\t// Convert the amount to satoshi.\n\t\tsatoshi, err := btcutil.NewAmount(amount)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to convert amount\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\ttxOut := wire.NewTxOut(int64(satoshi), pkScript)\n\t\tmtx.AddTxOut(txOut)\n\t}\n\n\t// Set the Locktime, if given.\n\tif c.LockTime != nil {\n\t\tmtx.LockTime = uint32(*c.LockTime)\n\t}\n\n\t// Return the serialized and hex-encoded transaction.  Note that this\n\t// is intentionally not directly returning because the first return\n\t// value is a string and it would result in returning an empty string to\n\t// the client instead of nothing (nil) in the case of an error.\n\tmtxHex, err := messageToHex(mtx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn mtxHex, nil\n}\n\n// handleDebugLevel handles debuglevel commands.\nfunc handleDebugLevel(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.DebugLevelCmd)\n\n\t// Special show command to list supported subsystems.\n\tif c.LevelSpec == \"show\" {\n\t\treturn fmt.Sprintf(\"Supported subsystems %v\",\n\t\t\tsupportedSubsystems()), nil\n\t}\n\n\terr := parseAndSetDebugLevels(c.LevelSpec)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParams.Code,\n\t\t\tMessage: err.Error(),\n\t\t}\n\t}\n\n\treturn \"Done.\", nil\n}\n\n// createVinList returns a slice of JSON objects for the inputs of the passed\n// transaction.\nfunc createVinList(mtx *wire.MsgTx) []btcjson.Vin {\n\t// Coinbase transactions only have a single txin by definition.\n\tvinList := make([]btcjson.Vin, len(mtx.TxIn))\n\tif blockchain.IsCoinBaseTx(mtx) {\n\t\ttxIn := mtx.TxIn[0]\n\t\tvinList[0].Coinbase = hex.EncodeToString(txIn.SignatureScript)\n\t\tvinList[0].Sequence = txIn.Sequence\n\t\tvinList[0].Witness = txIn.Witness.ToHexStrings()\n\t\treturn vinList\n\t}\n\n\tfor i, txIn := range mtx.TxIn {\n\t\t// The disassembled string will contain [error] inline\n\t\t// if the script doesn't fully parse, so ignore the\n\t\t// error here.\n\t\tdisbuf, _ := txscript.DisasmString(txIn.SignatureScript)\n\n\t\tvinEntry := &vinList[i]\n\t\tvinEntry.Txid = txIn.PreviousOutPoint.Hash.String()\n\t\tvinEntry.Vout = txIn.PreviousOutPoint.Index\n\t\tvinEntry.Sequence = txIn.Sequence\n\t\tvinEntry.ScriptSig = &btcjson.ScriptSig{\n\t\t\tAsm: disbuf,\n\t\t\tHex: hex.EncodeToString(txIn.SignatureScript),\n\t\t}\n\n\t\tif mtx.HasWitness() {\n\t\t\tvinEntry.Witness = txIn.Witness.ToHexStrings()\n\t\t}\n\t}\n\n\treturn vinList\n}\n\n// createVoutList returns a slice of JSON objects for the outputs of the passed\n// transaction.\nfunc createVoutList(mtx *wire.MsgTx, chainParams *chaincfg.Params, filterAddrMap map[string]struct{}) []btcjson.Vout {\n\tvoutList := make([]btcjson.Vout, 0, len(mtx.TxOut))\n\tfor i, v := range mtx.TxOut {\n\t\t// The disassembled string will contain [error] inline if the\n\t\t// script doesn't fully parse, so ignore the error here.\n\t\tdisbuf, _ := txscript.DisasmString(v.PkScript)\n\n\t\t// Ignore the error here since an error means the script\n\t\t// couldn't parse and there is no additional information about\n\t\t// it anyways.\n\t\tscriptClass, addrs, reqSigs, _ := txscript.ExtractPkScriptAddrs(\n\t\t\tv.PkScript, chainParams)\n\n\t\t// Encode the addresses while checking if the address passes the\n\t\t// filter when needed.\n\t\tpassesFilter := len(filterAddrMap) == 0\n\t\tencodedAddrs := make([]string, len(addrs))\n\t\tfor j, addr := range addrs {\n\t\t\tencodedAddr := addr.EncodeAddress()\n\t\t\tencodedAddrs[j] = encodedAddr\n\n\t\t\t// No need to check the map again if the filter already\n\t\t\t// passes.\n\t\t\tif passesFilter {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, exists := filterAddrMap[encodedAddr]; exists {\n\t\t\t\tpassesFilter = true\n\t\t\t}\n\t\t}\n\n\t\tif !passesFilter {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar vout btcjson.Vout\n\t\tvout.N = uint32(i)\n\t\tvout.Value = btcutil.Amount(v.Value).ToBTC()\n\t\tvout.ScriptPubKey.Addresses = encodedAddrs\n\t\tvout.ScriptPubKey.Asm = disbuf\n\t\tvout.ScriptPubKey.Hex = hex.EncodeToString(v.PkScript)\n\t\tvout.ScriptPubKey.Type = scriptClass.String()\n\t\tvout.ScriptPubKey.ReqSigs = int32(reqSigs)\n\n\t\t// Address is defined when there's a single well-defined\n\t\t// receiver address. To spend the output a signature for this,\n\t\t// and only this, address is required.\n\t\tif len(encodedAddrs) == 1 && reqSigs <= 1 {\n\t\t\tvout.ScriptPubKey.Address = encodedAddrs[0]\n\t\t}\n\n\t\tvoutList = append(voutList, vout)\n\t}\n\n\treturn voutList\n}\n\n// createTxRawResult converts the passed transaction and associated parameters\n// to a raw transaction JSON object.\nfunc createTxRawResult(chainParams *chaincfg.Params, mtx *wire.MsgTx,\n\ttxHash string, blkHeader *wire.BlockHeader, blkHash string,\n\tblkHeight int32, chainHeight int32) (*btcjson.TxRawResult, error) {\n\n\tmtxHex, err := messageToHex(mtx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttxReply := &btcjson.TxRawResult{\n\t\tHex:      mtxHex,\n\t\tTxid:     txHash,\n\t\tHash:     mtx.WitnessHash().String(),\n\t\tSize:     int32(mtx.SerializeSize()),\n\t\tVsize:    int32(mempool.GetTxVirtualSize(btcutil.NewTx(mtx))),\n\t\tWeight:   int32(blockchain.GetTransactionWeight(btcutil.NewTx(mtx))),\n\t\tVin:      createVinList(mtx),\n\t\tVout:     createVoutList(mtx, chainParams, nil),\n\t\tVersion:  uint32(mtx.Version),\n\t\tLockTime: mtx.LockTime,\n\t}\n\n\tif blkHeader != nil {\n\t\t// This is not a typo, they are identical in bitcoind as well.\n\t\ttxReply.Time = blkHeader.Timestamp.Unix()\n\t\ttxReply.Blocktime = blkHeader.Timestamp.Unix()\n\t\ttxReply.BlockHash = blkHash\n\t\ttxReply.Confirmations = uint64(1 + chainHeight - blkHeight)\n\t}\n\n\treturn txReply, nil\n}\n\n// handleDecodeRawTransaction handles decoderawtransaction commands.\nfunc handleDecodeRawTransaction(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.DecodeRawTransactionCmd)\n\n\t// Deserialize the transaction.\n\thexStr := c.HexTx\n\tif len(hexStr)%2 != 0 {\n\t\thexStr = \"0\" + hexStr\n\t}\n\tserializedTx, err := hex.DecodeString(hexStr)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(hexStr)\n\t}\n\tvar mtx wire.MsgTx\n\terr = mtx.Deserialize(bytes.NewReader(serializedTx))\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDeserialization,\n\t\t\tMessage: \"TX decode failed: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Create and return the result.\n\ttxReply := btcjson.TxRawDecodeResult{\n\t\tTxid:     mtx.TxHash().String(),\n\t\tVersion:  mtx.Version,\n\t\tLocktime: mtx.LockTime,\n\t\tVin:      createVinList(&mtx),\n\t\tVout:     createVoutList(&mtx, s.cfg.ChainParams, nil),\n\t}\n\treturn txReply, nil\n}\n\n// handleDecodeScript handles decodescript commands.\nfunc handleDecodeScript(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.DecodeScriptCmd)\n\n\t// Convert the hex script to bytes.\n\thexStr := c.HexScript\n\tif len(hexStr)%2 != 0 {\n\t\thexStr = \"0\" + hexStr\n\t}\n\tscript, err := hex.DecodeString(hexStr)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(hexStr)\n\t}\n\n\t// The disassembled string will contain [error] inline if the script\n\t// doesn't fully parse, so ignore the error here.\n\tdisbuf, _ := txscript.DisasmString(script)\n\n\t// Get information about the script.\n\t// Ignore the error here since an error means the script couldn't parse\n\t// and there is no additional information about it anyways.\n\tscriptClass, addrs, reqSigs, _ := txscript.ExtractPkScriptAddrs(script,\n\t\ts.cfg.ChainParams)\n\taddresses := make([]string, len(addrs))\n\tfor i, addr := range addrs {\n\t\taddresses[i] = addr.EncodeAddress()\n\t}\n\n\t// Convert the script itself to a pay-to-script-hash address.\n\tp2sh, err := btcutil.NewAddressScriptHash(script, s.cfg.ChainParams)\n\tif err != nil {\n\t\tcontext := \"Failed to convert script to pay-to-script-hash\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\n\t// Generate and return the reply.\n\treply := btcjson.DecodeScriptResult{\n\t\tAsm:       disbuf,\n\t\tReqSigs:   int32(reqSigs),\n\t\tType:      scriptClass.String(),\n\t\tAddresses: addresses,\n\t}\n\tif scriptClass != txscript.ScriptHashTy {\n\t\treply.P2sh = p2sh.EncodeAddress()\n\t}\n\n\t// Address is defined when there's a single well-defined\n\t// receiver address. To spend the output a signature for this,\n\t// and only this, address is required.\n\tif len(addresses) == 1 && reqSigs <= 1 {\n\t\treply.Address = addresses[0]\n\t}\n\treturn reply, nil\n}\n\n// handleEstimateFee handles estimatefee commands.\nfunc handleEstimateFee(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.EstimateFeeCmd)\n\n\tif s.cfg.FeeEstimator == nil {\n\t\treturn nil, errors.New(\"Fee estimation disabled\")\n\t}\n\n\tif c.NumBlocks <= 0 {\n\t\treturn -1.0, errors.New(\"Parameter NumBlocks must be positive\")\n\t}\n\n\tfeeRate, err := s.cfg.FeeEstimator.EstimateFee(uint32(c.NumBlocks))\n\n\tif err != nil {\n\t\treturn -1.0, err\n\t}\n\n\t// Convert to satoshis per kb.\n\treturn float64(feeRate), nil\n}\n\n// handleGenerate handles generate commands.\nfunc handleGenerate(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Respond with an error if there are no addresses to pay the\n\t// created blocks to.\n\tif len(cfg.miningAddrs) == 0 {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\tMessage: \"No payment addresses specified \" +\n\t\t\t\t\"via --miningaddr\",\n\t\t}\n\t}\n\n\t// Respond with an error if there's virtually 0 chance of mining a block\n\t// with the CPU.\n\tif !s.cfg.ChainParams.GenerateSupported {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCDifficulty,\n\t\t\tMessage: fmt.Sprintf(\"No support for `generate` on \"+\n\t\t\t\t\"the current network, %s, as it's unlikely to \"+\n\t\t\t\t\"be possible to mine a block with the CPU.\",\n\t\t\t\ts.cfg.ChainParams.Net),\n\t\t}\n\t}\n\n\tc := cmd.(*btcjson.GenerateCmd)\n\n\t// Respond with an error if the client is requesting 0 blocks to be generated.\n\tif c.NumBlocks == 0 {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInternal.Code,\n\t\t\tMessage: \"Please request a nonzero number of blocks to generate.\",\n\t\t}\n\t}\n\n\t// Create a reply\n\treply := make([]string, c.NumBlocks)\n\n\tblockHashes, err := s.cfg.CPUMiner.GenerateNBlocks(c.NumBlocks)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInternal.Code,\n\t\t\tMessage: err.Error(),\n\t\t}\n\t}\n\n\t// Mine the correct number of blocks, assigning the hex representation of the\n\t// hash of each one to its place in the reply.\n\tfor i, hash := range blockHashes {\n\t\treply[i] = hash.String()\n\t}\n\n\treturn reply, nil\n}\n\n// handleGetAddedNodeInfo handles getaddednodeinfo commands.\nfunc handleGetAddedNodeInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetAddedNodeInfoCmd)\n\n\t// Retrieve a list of persistent (added) peers from the server and\n\t// filter the list of peers per the specified address (if any).\n\tpeers := s.cfg.ConnMgr.PersistentPeers()\n\tif c.Node != nil {\n\t\tnode := *c.Node\n\t\tfound := false\n\t\tfor i, peer := range peers {\n\t\t\tif peer.ToPeer().Addr() == node {\n\t\t\t\tpeers = peers[i : i+1]\n\t\t\t\tfound = true\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCClientNodeNotAdded,\n\t\t\t\tMessage: \"Node has not been added\",\n\t\t\t}\n\t\t}\n\t}\n\n\t// Without the dns flag, the result is just a slice of the addresses as\n\t// strings.\n\tif !c.DNS {\n\t\tresults := make([]string, 0, len(peers))\n\t\tfor _, peer := range peers {\n\t\t\tresults = append(results, peer.ToPeer().Addr())\n\t\t}\n\t\treturn results, nil\n\t}\n\n\t// With the dns flag, the result is an array of JSON objects which\n\t// include the result of DNS lookups for each peer.\n\tresults := make([]*btcjson.GetAddedNodeInfoResult, 0, len(peers))\n\tfor _, rpcPeer := range peers {\n\t\t// Set the \"address\" of the peer which could be an ip address\n\t\t// or a domain name.\n\t\tpeer := rpcPeer.ToPeer()\n\t\tvar result btcjson.GetAddedNodeInfoResult\n\t\tresult.AddedNode = peer.Addr()\n\t\tresult.Connected = btcjson.Bool(peer.Connected())\n\n\t\t// Split the address into host and port portions so we can do\n\t\t// a DNS lookup against the host.  When no port is specified in\n\t\t// the address, just use the address as the host.\n\t\thost, _, err := net.SplitHostPort(peer.Addr())\n\t\tif err != nil {\n\t\t\thost = peer.Addr()\n\t\t}\n\n\t\tvar ipList []string\n\t\tswitch {\n\t\tcase net.ParseIP(host) != nil, strings.HasSuffix(host, \".onion\"):\n\t\t\tipList = make([]string, 1)\n\t\t\tipList[0] = host\n\t\tdefault:\n\t\t\t// Do a DNS lookup for the address.  If the lookup fails, just\n\t\t\t// use the host.\n\t\t\tips, err := btcdLookup(host)\n\t\t\tif err != nil {\n\t\t\t\tipList = make([]string, 1)\n\t\t\t\tipList[0] = host\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tipList = make([]string, 0, len(ips))\n\t\t\tfor _, ip := range ips {\n\t\t\t\tipList = append(ipList, ip.String())\n\t\t\t}\n\t\t}\n\n\t\t// Add the addresses and connection info to the result.\n\t\taddrs := make([]btcjson.GetAddedNodeInfoResultAddr, 0, len(ipList))\n\t\tfor _, ip := range ipList {\n\t\t\tvar addr btcjson.GetAddedNodeInfoResultAddr\n\t\t\taddr.Address = ip\n\t\t\taddr.Connected = \"false\"\n\t\t\tif ip == host && peer.Connected() {\n\t\t\t\taddr.Connected = directionString(peer.Inbound())\n\t\t\t}\n\t\t\taddrs = append(addrs, addr)\n\t\t}\n\t\tresult.Addresses = &addrs\n\t\tresults = append(results, &result)\n\t}\n\treturn results, nil\n}\n\n// handleGetBestBlock implements the getbestblock command.\nfunc handleGetBestBlock(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// All other \"get block\" commands give either the height, the\n\t// hash, or both but require the block SHA.  This gets both for\n\t// the best block.\n\tbest := s.cfg.Chain.BestSnapshot()\n\tresult := &btcjson.GetBestBlockResult{\n\t\tHash:   best.Hash.String(),\n\t\tHeight: best.Height,\n\t}\n\treturn result, nil\n}\n\n// handleGetBestBlockHash implements the getbestblockhash command.\nfunc handleGetBestBlockHash(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tbest := s.cfg.Chain.BestSnapshot()\n\treturn best.Hash.String(), nil\n}\n\n// getDifficultyRatio returns the proof-of-work difficulty as a multiple of the\n// minimum difficulty using the passed bits field from the header of a block.\nfunc getDifficultyRatio(bits uint32, params *chaincfg.Params) float64 {\n\t// The minimum difficulty is the max possible proof-of-work limit bits\n\t// converted back to a number.  Note this is not the same as the proof of\n\t// work limit directly because the block difficulty is encoded in a block\n\t// with the compact form which loses precision.\n\tmax := blockchain.CompactToBig(params.PowLimitBits)\n\ttarget := blockchain.CompactToBig(bits)\n\n\tdifficulty := new(big.Rat).SetFrac(max, target)\n\toutString := difficulty.FloatString(8)\n\tdiff, err := strconv.ParseFloat(outString, 64)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Cannot get difficulty: %v\", err)\n\t\treturn 0\n\t}\n\treturn diff\n}\n\n// handleGetBlock implements the getblock command.\nfunc handleGetBlock(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetBlockCmd)\n\n\t// Load the raw block bytes from the database.\n\thash, err := chainhash.NewHashFromStr(c.Hash)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Hash)\n\t}\n\tvar blkBytes []byte\n\terr = s.cfg.DB.View(func(dbTx database.Tx) error {\n\t\tvar err error\n\t\tblkBytes, err = dbTx.FetchBlock(hash)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\tMessage: \"Block not found\",\n\t\t}\n\t}\n\t// If verbosity is 0, return the serialized block as a hex encoded string.\n\tif c.Verbosity != nil && *c.Verbosity == 0 {\n\t\treturn hex.EncodeToString(blkBytes), nil\n\t}\n\n\t// Otherwise, generate the JSON object and return it.\n\n\t// Deserialize the block.\n\tblk, err := btcutil.NewBlockFromBytes(blkBytes)\n\tif err != nil {\n\t\tcontext := \"Failed to deserialize block\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\n\t// Get the block height from chain.\n\tblockHeight, err := s.cfg.Chain.BlockHeightByHash(hash)\n\tif err != nil {\n\t\tcontext := \"Failed to obtain block height\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\tblk.SetHeight(blockHeight)\n\tbest := s.cfg.Chain.BestSnapshot()\n\n\t// Get next block hash unless there are none.\n\tvar nextHashString string\n\tif blockHeight < best.Height {\n\t\tnextHash, err := s.cfg.Chain.BlockHashByHeight(blockHeight + 1)\n\t\tif err != nil {\n\t\t\tcontext := \"No next block\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\tnextHashString = nextHash.String()\n\t}\n\n\tparams := s.cfg.ChainParams\n\tblockHeader := &blk.MsgBlock().Header\n\tblockReply := btcjson.GetBlockVerboseResult{\n\t\tHash:          c.Hash,\n\t\tVersion:       blockHeader.Version,\n\t\tVersionHex:    fmt.Sprintf(\"%08x\", blockHeader.Version),\n\t\tMerkleRoot:    blockHeader.MerkleRoot.String(),\n\t\tPreviousHash:  blockHeader.PrevBlock.String(),\n\t\tNonce:         blockHeader.Nonce,\n\t\tTime:          blockHeader.Timestamp.Unix(),\n\t\tConfirmations: int64(1 + best.Height - blockHeight),\n\t\tHeight:        int64(blockHeight),\n\t\tSize:          int32(len(blkBytes)),\n\t\tStrippedSize:  int32(blk.MsgBlock().SerializeSizeStripped()),\n\t\tWeight:        int32(blockchain.GetBlockWeight(blk)),\n\t\tBits:          strconv.FormatInt(int64(blockHeader.Bits), 16),\n\t\tDifficulty:    getDifficultyRatio(blockHeader.Bits, params),\n\t\tNextHash:      nextHashString,\n\t}\n\n\tif *c.Verbosity == 1 {\n\t\ttransactions := blk.Transactions()\n\t\ttxNames := make([]string, len(transactions))\n\t\tfor i, tx := range transactions {\n\t\t\ttxNames[i] = tx.Hash().String()\n\t\t}\n\n\t\tblockReply.Tx = txNames\n\t} else {\n\t\ttxns := blk.Transactions()\n\t\trawTxns := make([]btcjson.TxRawResult, len(txns))\n\t\tfor i, tx := range txns {\n\t\t\trawTxn, err := createTxRawResult(params, tx.MsgTx(),\n\t\t\t\ttx.Hash().String(), blockHeader, hash.String(),\n\t\t\t\tblockHeight, best.Height)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\trawTxns[i] = *rawTxn\n\t\t}\n\t\tblockReply.RawTx = rawTxns\n\t}\n\n\treturn blockReply, nil\n}\n\n// softForkStatus converts a ThresholdState state into a human readable string\n// corresponding to the particular state.\nfunc softForkStatus(state blockchain.ThresholdState) (string, error) {\n\tswitch state {\n\tcase blockchain.ThresholdDefined:\n\t\treturn \"defined\", nil\n\tcase blockchain.ThresholdStarted:\n\t\treturn \"started\", nil\n\tcase blockchain.ThresholdLockedIn:\n\t\treturn \"lockedin\", nil\n\tcase blockchain.ThresholdActive:\n\t\treturn \"active\", nil\n\tcase blockchain.ThresholdFailed:\n\t\treturn \"failed\", nil\n\tdefault:\n\t\treturn \"\", fmt.Errorf(\"unknown deployment state: %v\", state)\n\t}\n}\n\n// handleGetBlockChainInfo implements the getblockchaininfo command.\nfunc handleGetBlockChainInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Obtain a snapshot of the current best known blockchain state. We'll\n\t// populate the response to this call primarily from this snapshot.\n\tparams := s.cfg.ChainParams\n\tchain := s.cfg.Chain\n\tchainSnapshot := chain.BestSnapshot()\n\n\tchainInfo := &btcjson.GetBlockChainInfoResult{\n\t\tChain:         params.Name,\n\t\tBlocks:        chainSnapshot.Height,\n\t\tHeaders:       chainSnapshot.Height,\n\t\tBestBlockHash: chainSnapshot.Hash.String(),\n\t\tDifficulty:    getDifficultyRatio(chainSnapshot.Bits, params),\n\t\tMedianTime:    chainSnapshot.MedianTime.Unix(),\n\t\tPruned:        cfg.Prune != 0,\n\t\tSoftForks: &btcjson.SoftForks{\n\t\t\tBip9SoftForks: make(map[string]*btcjson.Bip9SoftForkDescription),\n\t\t},\n\t}\n\n\t// Next, populate the response with information describing the current\n\t// status of soft-forks deployed via the super-majority block\n\t// signalling mechanism.\n\theight := chainSnapshot.Height\n\tchainInfo.SoftForks.SoftForks = []*btcjson.SoftForkDescription{\n\t\t{\n\t\t\tID:      \"bip34\",\n\t\t\tVersion: 2,\n\t\t\tReject: struct {\n\t\t\t\tStatus bool `json:\"status\"`\n\t\t\t}{\n\t\t\t\tStatus: height >= params.BIP0034Height,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tID:      \"bip66\",\n\t\t\tVersion: 3,\n\t\t\tReject: struct {\n\t\t\t\tStatus bool `json:\"status\"`\n\t\t\t}{\n\t\t\t\tStatus: height >= params.BIP0066Height,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tID:      \"bip65\",\n\t\t\tVersion: 4,\n\t\t\tReject: struct {\n\t\t\t\tStatus bool `json:\"status\"`\n\t\t\t}{\n\t\t\t\tStatus: height >= params.BIP0065Height,\n\t\t\t},\n\t\t},\n\t}\n\n\t// Finally, query the BIP0009 version bits state for all currently\n\t// defined BIP0009 soft-fork deployments.\n\tfor deployment, deploymentDetails := range params.Deployments {\n\t\t// Map the integer deployment ID into a human readable\n\t\t// fork-name.\n\t\tvar forkName string\n\t\tswitch deployment {\n\t\tcase chaincfg.DeploymentTestDummy:\n\t\t\tforkName = \"dummy\"\n\n\t\tcase chaincfg.DeploymentTestDummyMinActivation:\n\t\t\tforkName = \"dummy-min-activation\"\n\n\t\tcase chaincfg.DeploymentCSV:\n\t\t\tforkName = \"csv\"\n\n\t\tcase chaincfg.DeploymentSegwit:\n\t\t\tforkName = \"segwit\"\n\n\t\tcase chaincfg.DeploymentTaproot:\n\t\t\tforkName = \"taproot\"\n\n\t\tdefault:\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\t\tMessage: fmt.Sprintf(\"Unknown deployment %v \"+\n\t\t\t\t\t\"detected\", deployment),\n\t\t\t}\n\t\t}\n\n\t\t// Query the chain for the current status of the deployment as\n\t\t// identified by its deployment ID.\n\t\tdeploymentStatus, err := chain.ThresholdState(uint32(deployment))\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to obtain deployment status\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\t// Attempt to convert the current deployment status into a\n\t\t// human readable string. If the status is unrecognized, then a\n\t\t// non-nil error is returned.\n\t\tstatusString, err := softForkStatus(deploymentStatus)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\t\tMessage: fmt.Sprintf(\"unknown deployment status: %v\",\n\t\t\t\t\tdeploymentStatus),\n\t\t\t}\n\t\t}\n\n\t\t// Finally, populate the soft-fork description with all the\n\t\t// information gathered above.\n\t\tvar startTime, endTime int64\n\t\tif starter, ok := deploymentDetails.DeploymentStarter.(*chaincfg.MedianTimeDeploymentStarter); ok {\n\t\t\tstartTime = starter.StartTime().Unix()\n\t\t}\n\t\tif ender, ok := deploymentDetails.DeploymentEnder.(*chaincfg.MedianTimeDeploymentEnder); ok {\n\t\t\tendTime = ender.EndTime().Unix()\n\t\t}\n\t\tchainInfo.SoftForks.Bip9SoftForks[forkName] = &btcjson.Bip9SoftForkDescription{\n\t\t\tStatus:              strings.ToLower(statusString),\n\t\t\tBit:                 deploymentDetails.BitNumber,\n\t\t\tStartTime2:          startTime,\n\t\t\tTimeout:             endTime,\n\t\t\tMinActivationHeight: int32(deploymentDetails.MinActivationHeight),\n\t\t}\n\t}\n\n\treturn chainInfo, nil\n}\n\n// handleGetBlockCount implements the getblockcount command.\nfunc handleGetBlockCount(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tbest := s.cfg.Chain.BestSnapshot()\n\treturn int64(best.Height), nil\n}\n\n// handleGetBlockHash implements the getblockhash command.\nfunc handleGetBlockHash(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetBlockHashCmd)\n\thash, err := s.cfg.Chain.BlockHashByHeight(int32(c.Index))\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCOutOfRange,\n\t\t\tMessage: \"Block number out of range\",\n\t\t}\n\t}\n\n\treturn hash.String(), nil\n}\n\n// handleGetBlockHeader implements the getblockheader command.\nfunc handleGetBlockHeader(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetBlockHeaderCmd)\n\n\t// Fetch the header from chain.\n\thash, err := chainhash.NewHashFromStr(c.Hash)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Hash)\n\t}\n\tblockHeader, err := s.cfg.Chain.HeaderByHash(hash)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\tMessage: \"Block not found\",\n\t\t}\n\t}\n\n\t// When the verbose flag isn't set, simply return the serialized block\n\t// header as a hex-encoded string.\n\tif c.Verbose != nil && !*c.Verbose {\n\t\tvar headerBuf bytes.Buffer\n\t\terr := blockHeader.Serialize(&headerBuf)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to serialize block header\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\treturn hex.EncodeToString(headerBuf.Bytes()), nil\n\t}\n\n\t// The verbose flag is set, so generate the JSON object and return it.\n\n\t// Get the block height from chain.\n\tblockHeight, err := s.cfg.Chain.BlockHeightByHash(hash)\n\tif err != nil {\n\t\tcontext := \"Failed to obtain block height\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\tbest := s.cfg.Chain.BestSnapshot()\n\n\t// Get next block hash unless there are none.\n\tvar nextHashString string\n\tif blockHeight < best.Height {\n\t\tnextHash, err := s.cfg.Chain.BlockHashByHeight(blockHeight + 1)\n\t\tif err != nil {\n\t\t\tcontext := \"No next block\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\tnextHashString = nextHash.String()\n\t}\n\n\tparams := s.cfg.ChainParams\n\tblockHeaderReply := btcjson.GetBlockHeaderVerboseResult{\n\t\tHash:          c.Hash,\n\t\tConfirmations: int64(1 + best.Height - blockHeight),\n\t\tHeight:        blockHeight,\n\t\tVersion:       blockHeader.Version,\n\t\tVersionHex:    fmt.Sprintf(\"%08x\", blockHeader.Version),\n\t\tMerkleRoot:    blockHeader.MerkleRoot.String(),\n\t\tNextHash:      nextHashString,\n\t\tPreviousHash:  blockHeader.PrevBlock.String(),\n\t\tNonce:         uint64(blockHeader.Nonce),\n\t\tTime:          blockHeader.Timestamp.Unix(),\n\t\tBits:          strconv.FormatInt(int64(blockHeader.Bits), 16),\n\t\tDifficulty:    getDifficultyRatio(blockHeader.Bits, params),\n\t}\n\treturn blockHeaderReply, nil\n}\n\n// encodeTemplateID encodes the passed details into an ID that can be used to\n// uniquely identify a block template.\nfunc encodeTemplateID(prevHash *chainhash.Hash, lastGenerated time.Time) string {\n\treturn fmt.Sprintf(\"%s-%d\", prevHash.String(), lastGenerated.Unix())\n}\n\n// decodeTemplateID decodes an ID that is used to uniquely identify a block\n// template.  This is mainly used as a mechanism to track when to update clients\n// that are using long polling for block templates.  The ID consists of the\n// previous block hash for the associated template and the time the associated\n// template was generated.\nfunc decodeTemplateID(templateID string) (*chainhash.Hash, int64, error) {\n\tfields := strings.Split(templateID, \"-\")\n\tif len(fields) != 2 {\n\t\treturn nil, 0, errors.New(\"invalid longpollid format\")\n\t}\n\n\tprevHash, err := chainhash.NewHashFromStr(fields[0])\n\tif err != nil {\n\t\treturn nil, 0, errors.New(\"invalid longpollid format\")\n\t}\n\tlastGenerated, err := strconv.ParseInt(fields[1], 10, 64)\n\tif err != nil {\n\t\treturn nil, 0, errors.New(\"invalid longpollid format\")\n\t}\n\n\treturn prevHash, lastGenerated, nil\n}\n\n// notifyLongPollers notifies any channels that have been registered to be\n// notified when block templates are stale.\n//\n// This function MUST be called with the state locked.\nfunc (state *gbtWorkState) notifyLongPollers(latestHash *chainhash.Hash, lastGenerated time.Time) {\n\t// Notify anything that is waiting for a block template update from a\n\t// hash which is not the hash of the tip of the best chain since their\n\t// work is now invalid.\n\tfor hash, channels := range state.notifyMap {\n\t\tif !hash.IsEqual(latestHash) {\n\t\t\tfor _, c := range channels {\n\t\t\t\tclose(c)\n\t\t\t}\n\t\t\tdelete(state.notifyMap, hash)\n\t\t}\n\t}\n\n\t// Return now if the provided last generated timestamp has not been\n\t// initialized.\n\tif lastGenerated.IsZero() {\n\t\treturn\n\t}\n\n\t// Return now if there is nothing registered for updates to the current\n\t// best block hash.\n\tchannels, ok := state.notifyMap[*latestHash]\n\tif !ok {\n\t\treturn\n\t}\n\n\t// Notify anything that is waiting for a block template update from a\n\t// block template generated before the most recently generated block\n\t// template.\n\tlastGeneratedUnix := lastGenerated.Unix()\n\tfor lastGen, c := range channels {\n\t\tif lastGen < lastGeneratedUnix {\n\t\t\tclose(c)\n\t\t\tdelete(channels, lastGen)\n\t\t}\n\t}\n\n\t// Remove the entry altogether if there are no more registered\n\t// channels.\n\tif len(channels) == 0 {\n\t\tdelete(state.notifyMap, *latestHash)\n\t}\n}\n\n// NotifyBlockConnected uses the newly-connected block to notify any long poll\n// clients with a new block template when their existing block template is\n// stale due to the newly connected block.\nfunc (state *gbtWorkState) NotifyBlockConnected(blockHash *chainhash.Hash) {\n\tgo func() {\n\t\tstate.Lock()\n\t\tdefer state.Unlock()\n\n\t\tstate.notifyLongPollers(blockHash, state.lastTxUpdate)\n\t}()\n}\n\n// NotifyMempoolTx uses the new last updated time for the transaction memory\n// pool to notify any long poll clients with a new block template when their\n// existing block template is stale due to enough time passing and the contents\n// of the memory pool changing.\nfunc (state *gbtWorkState) NotifyMempoolTx(lastUpdated time.Time) {\n\tgo func() {\n\t\tstate.Lock()\n\t\tdefer state.Unlock()\n\n\t\t// No need to notify anything if no block templates have been generated\n\t\t// yet.\n\t\tif state.prevHash == nil || state.lastGenerated.IsZero() {\n\t\t\treturn\n\t\t}\n\n\t\tif time.Now().After(state.lastGenerated.Add(time.Second *\n\t\t\tgbtRegenerateSeconds)) {\n\n\t\t\tstate.notifyLongPollers(state.prevHash, lastUpdated)\n\t\t}\n\t}()\n}\n\n// templateUpdateChan returns a channel that will be closed once the block\n// template associated with the passed previous hash and last generated time\n// is stale.  The function will return existing channels for duplicate\n// parameters which allows multiple clients to wait for the same block template\n// without requiring a different channel for each client.\n//\n// This function MUST be called with the state locked.\nfunc (state *gbtWorkState) templateUpdateChan(prevHash *chainhash.Hash, lastGenerated int64) chan struct{} {\n\t// Either get the current list of channels waiting for updates about\n\t// changes to block template for the previous hash or create a new one.\n\tchannels, ok := state.notifyMap[*prevHash]\n\tif !ok {\n\t\tm := make(map[int64]chan struct{})\n\t\tstate.notifyMap[*prevHash] = m\n\t\tchannels = m\n\t}\n\n\t// Get the current channel associated with the time the block template\n\t// was last generated or create a new one.\n\tc, ok := channels[lastGenerated]\n\tif !ok {\n\t\tc = make(chan struct{})\n\t\tchannels[lastGenerated] = c\n\t}\n\n\treturn c\n}\n\n// updateBlockTemplate creates or updates a block template for the work state.\n// A new block template will be generated when the current best block has\n// changed or the transactions in the memory pool have been updated and it has\n// been long enough since the last template was generated.  Otherwise, the\n// timestamp for the existing block template is updated (and possibly the\n// difficulty on testnet per the consesus rules).  Finally, if the\n// useCoinbaseValue flag is false and the existing block template does not\n// already contain a valid payment address, the block template will be updated\n// with a randomly selected payment address from the list of configured\n// addresses.\n//\n// This function MUST be called with the state locked.\nfunc (state *gbtWorkState) updateBlockTemplate(s *rpcServer, useCoinbaseValue bool) error {\n\tgenerator := s.cfg.Generator\n\tlastTxUpdate := generator.TxSource().LastUpdated()\n\tif lastTxUpdate.IsZero() {\n\t\tlastTxUpdate = time.Now()\n\t}\n\n\t// Generate a new block template when the current best block has\n\t// changed or the transactions in the memory pool have been updated and\n\t// it has been at least gbtRegenerateSecond since the last template was\n\t// generated.\n\tvar msgBlock *wire.MsgBlock\n\tvar targetDifficulty string\n\tlatestHash := &s.cfg.Chain.BestSnapshot().Hash\n\ttemplate := state.template\n\tif template == nil || state.prevHash == nil ||\n\t\t!state.prevHash.IsEqual(latestHash) ||\n\t\t(state.lastTxUpdate != lastTxUpdate &&\n\t\t\ttime.Now().After(state.lastGenerated.Add(time.Second*\n\t\t\t\tgbtRegenerateSeconds))) {\n\n\t\t// Reset the previous best hash the block template was generated\n\t\t// against so any errors below cause the next invocation to try\n\t\t// again.\n\t\tstate.prevHash = nil\n\n\t\t// Choose a payment address at random if the caller requests a\n\t\t// full coinbase as opposed to only the pertinent details needed\n\t\t// to create their own coinbase.\n\t\tvar payAddr btcutil.Address\n\t\tif !useCoinbaseValue {\n\t\t\tpayAddr = cfg.miningAddrs[rand.Intn(len(cfg.miningAddrs))]\n\t\t}\n\n\t\t// Create a new block template that has a coinbase which anyone\n\t\t// can redeem.  This is only acceptable because the returned\n\t\t// block template doesn't include the coinbase, so the caller\n\t\t// will ultimately create their own coinbase which pays to the\n\t\t// appropriate address(es).\n\t\tblkTemplate, err := generator.NewBlockTemplate(payAddr)\n\t\tif err != nil {\n\t\t\treturn internalRPCError(\"Failed to create new block \"+\n\t\t\t\t\"template: \"+err.Error(), \"\")\n\t\t}\n\t\ttemplate = blkTemplate\n\t\tmsgBlock = template.Block\n\t\ttargetDifficulty = fmt.Sprintf(\"%064x\",\n\t\t\tblockchain.CompactToBig(msgBlock.Header.Bits))\n\n\t\t// Get the minimum allowed timestamp for the block based on the\n\t\t// median timestamp of the last several blocks per the chain\n\t\t// consensus rules.\n\t\tbest := s.cfg.Chain.BestSnapshot()\n\t\tminTimestamp := mining.MinimumMedianTime(best)\n\n\t\t// Update work state to ensure another block template isn't\n\t\t// generated until needed.\n\t\tstate.template = template\n\t\tstate.lastGenerated = time.Now()\n\t\tstate.lastTxUpdate = lastTxUpdate\n\t\tstate.prevHash = latestHash\n\t\tstate.minTimestamp = minTimestamp\n\n\t\trpcsLog.Debugf(\"Generated block template (timestamp %v, \"+\n\t\t\t\"target %s, merkle root %s)\",\n\t\t\tmsgBlock.Header.Timestamp, targetDifficulty,\n\t\t\tmsgBlock.Header.MerkleRoot)\n\n\t\t// Notify any clients that are long polling about the new\n\t\t// template.\n\t\tstate.notifyLongPollers(latestHash, lastTxUpdate)\n\t} else {\n\t\t// At this point, there is a saved block template and another\n\t\t// request for a template was made, but either the available\n\t\t// transactions haven't change or it hasn't been long enough to\n\t\t// trigger a new block template to be generated.  So, update the\n\t\t// existing block template.\n\n\t\t// When the caller requires a full coinbase as opposed to only\n\t\t// the pertinent details needed to create their own coinbase,\n\t\t// add a payment address to the output of the coinbase of the\n\t\t// template if it doesn't already have one.  Since this requires\n\t\t// mining addresses to be specified via the config, an error is\n\t\t// returned if none have been specified.\n\t\tif !useCoinbaseValue && !template.ValidPayAddress {\n\t\t\t// Choose a payment address at random.\n\t\t\tpayToAddr := cfg.miningAddrs[rand.Intn(len(cfg.miningAddrs))]\n\n\t\t\t// Update the block coinbase output of the template to\n\t\t\t// pay to the randomly selected payment address.\n\t\t\tpkScript, err := txscript.PayToAddrScript(payToAddr)\n\t\t\tif err != nil {\n\t\t\t\tcontext := \"Failed to create pay-to-addr script\"\n\t\t\t\treturn internalRPCError(err.Error(), context)\n\t\t\t}\n\t\t\ttemplate.Block.Transactions[0].TxOut[0].PkScript = pkScript\n\t\t\ttemplate.ValidPayAddress = true\n\n\t\t\t// Update the merkle root.\n\t\t\tblock := btcutil.NewBlock(template.Block)\n\t\t\tmerkleRoot := blockchain.CalcMerkleRoot(block.Transactions(), false)\n\t\t\ttemplate.Block.Header.MerkleRoot = merkleRoot\n\t\t}\n\n\t\t// Set locals for convenience.\n\t\tmsgBlock = template.Block\n\t\ttargetDifficulty = fmt.Sprintf(\"%064x\",\n\t\t\tblockchain.CompactToBig(msgBlock.Header.Bits))\n\n\t\t// Update the time of the block template to the current time\n\t\t// while accounting for the median time of the past several\n\t\t// blocks per the chain consensus rules.\n\t\tgenerator.UpdateBlockTime(msgBlock)\n\t\tmsgBlock.Header.Nonce = 0\n\n\t\trpcsLog.Debugf(\"Updated block template (timestamp %v, \"+\n\t\t\t\"target %s)\", msgBlock.Header.Timestamp,\n\t\t\ttargetDifficulty)\n\t}\n\n\treturn nil\n}\n\n// blockTemplateResult returns the current block template associated with the\n// state as a btcjson.GetBlockTemplateResult that is ready to be encoded to JSON\n// and returned to the caller.\n//\n// This function MUST be called with the state locked.\nfunc (state *gbtWorkState) blockTemplateResult(useCoinbaseValue bool, submitOld *bool) (*btcjson.GetBlockTemplateResult, error) {\n\t// Ensure the timestamps are still in valid range for the template.\n\t// This should really only ever happen if the local clock is changed\n\t// after the template is generated, but it's important to avoid serving\n\t// invalid block templates.\n\ttemplate := state.template\n\tmsgBlock := template.Block\n\theader := &msgBlock.Header\n\tadjustedTime := state.timeSource.AdjustedTime()\n\tmaxTime := adjustedTime.Add(time.Second * blockchain.MaxTimeOffsetSeconds)\n\tif header.Timestamp.After(maxTime) {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCOutOfRange,\n\t\t\tMessage: fmt.Sprintf(\"The template time is after the \"+\n\t\t\t\t\"maximum allowed time for a block - template \"+\n\t\t\t\t\"time %v, maximum time %v\", adjustedTime,\n\t\t\t\tmaxTime),\n\t\t}\n\t}\n\n\t// Convert each transaction in the block template to a template result\n\t// transaction.  The result does not include the coinbase, so notice\n\t// the adjustments to the various lengths and indices.\n\tnumTx := len(msgBlock.Transactions)\n\ttransactions := make([]btcjson.GetBlockTemplateResultTx, 0, numTx-1)\n\ttxIndex := make(map[chainhash.Hash]int64, numTx)\n\tfor i, tx := range msgBlock.Transactions {\n\t\ttxID := tx.TxHash()\n\t\ttxIndex[txID] = int64(i)\n\n\t\t// Skip the coinbase transaction.\n\t\tif i == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create an array of 1-based indices to transactions that come\n\t\t// before this one in the transactions list which this one\n\t\t// depends on.  This is necessary since the created block must\n\t\t// ensure proper ordering of the dependencies.  A map is used\n\t\t// before creating the final array to prevent duplicate entries\n\t\t// when multiple inputs reference the same transaction.\n\t\tdependsMap := make(map[int64]struct{})\n\t\tfor _, txIn := range tx.TxIn {\n\t\t\tif idx, ok := txIndex[txIn.PreviousOutPoint.Hash]; ok {\n\t\t\t\tdependsMap[idx] = struct{}{}\n\t\t\t}\n\t\t}\n\t\tdepends := make([]int64, 0, len(dependsMap))\n\t\tfor idx := range dependsMap {\n\t\t\tdepends = append(depends, idx)\n\t\t}\n\n\t\t// Serialize the transaction for later conversion to hex.\n\t\ttxBuf := bytes.NewBuffer(make([]byte, 0, tx.SerializeSize()))\n\t\tif err := tx.Serialize(txBuf); err != nil {\n\t\t\tcontext := \"Failed to serialize transaction\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\tbTx := btcutil.NewTx(tx)\n\t\tresultTx := btcjson.GetBlockTemplateResultTx{\n\t\t\tData:    hex.EncodeToString(txBuf.Bytes()),\n\t\t\tTxID:    txID.String(),\n\t\t\tHash:    tx.WitnessHash().String(),\n\t\t\tDepends: depends,\n\t\t\tFee:     template.Fees[i],\n\t\t\tSigOps:  template.SigOpCosts[i],\n\t\t\tWeight:  blockchain.GetTransactionWeight(bTx),\n\t\t}\n\t\ttransactions = append(transactions, resultTx)\n\t}\n\n\t// Generate the block template reply.  Note that following mutations are\n\t// implied by the included or omission of fields:\n\t//  Including MinTime -> time/decrement\n\t//  Omitting CoinbaseTxn -> coinbase, generation\n\ttargetDifficulty := fmt.Sprintf(\"%064x\", blockchain.CompactToBig(header.Bits))\n\ttemplateID := encodeTemplateID(state.prevHash, state.lastGenerated)\n\treply := btcjson.GetBlockTemplateResult{\n\t\tBits:         strconv.FormatInt(int64(header.Bits), 16),\n\t\tCurTime:      header.Timestamp.Unix(),\n\t\tHeight:       int64(template.Height),\n\t\tPreviousHash: header.PrevBlock.String(),\n\t\tWeightLimit:  blockchain.MaxBlockWeight,\n\t\tSigOpLimit:   blockchain.MaxBlockSigOpsCost,\n\t\tSizeLimit:    wire.MaxBlockPayload,\n\t\tTransactions: transactions,\n\t\tVersion:      header.Version,\n\t\tLongPollID:   templateID,\n\t\tSubmitOld:    submitOld,\n\t\tTarget:       targetDifficulty,\n\t\tMinTime:      state.minTimestamp.Unix(),\n\t\tMaxTime:      maxTime.Unix(),\n\t\tMutable:      gbtMutableFields,\n\t\tNonceRange:   gbtNonceRange,\n\t\tCapabilities: gbtCapabilities,\n\t}\n\t// If the generated block template includes transactions with witness\n\t// data, then include the witness commitment in the GBT result.\n\tif template.WitnessCommitment != nil {\n\t\treply.DefaultWitnessCommitment = hex.EncodeToString(template.WitnessCommitment)\n\t}\n\n\tif useCoinbaseValue {\n\t\treply.CoinbaseAux = gbtCoinbaseAux\n\t\treply.CoinbaseValue = &msgBlock.Transactions[0].TxOut[0].Value\n\t} else {\n\t\t// Ensure the template has a valid payment address associated\n\t\t// with it when a full coinbase is requested.\n\t\tif !template.ValidPayAddress {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\t\tMessage: \"A coinbase transaction has been \" +\n\t\t\t\t\t\"requested, but the server has not \" +\n\t\t\t\t\t\"been configured with any payment \" +\n\t\t\t\t\t\"addresses via --miningaddr\",\n\t\t\t}\n\t\t}\n\n\t\t// Serialize the transaction for conversion to hex.\n\t\ttx := msgBlock.Transactions[0]\n\t\ttxBuf := bytes.NewBuffer(make([]byte, 0, tx.SerializeSize()))\n\t\tif err := tx.Serialize(txBuf); err != nil {\n\t\t\tcontext := \"Failed to serialize transaction\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\tresultTx := btcjson.GetBlockTemplateResultTx{\n\t\t\tData:    hex.EncodeToString(txBuf.Bytes()),\n\t\t\tHash:    tx.TxHash().String(),\n\t\t\tDepends: []int64{},\n\t\t\tFee:     template.Fees[0],\n\t\t\tSigOps:  template.SigOpCosts[0],\n\t\t}\n\n\t\treply.CoinbaseTxn = &resultTx\n\t}\n\n\treturn &reply, nil\n}\n\n// handleGetBlockTemplateLongPoll is a helper for handleGetBlockTemplateRequest\n// which deals with handling long polling for block templates.  When a caller\n// sends a request with a long poll ID that was previously returned, a response\n// is not sent until the caller should stop working on the previous block\n// template in favor of the new one.  In particular, this is the case when the\n// old block template is no longer valid due to a solution already being found\n// and added to the block chain, or new transactions have shown up and some time\n// has passed without finding a solution.\n//\n// See https://en.bitcoin.it/wiki/BIP_0022 for more details.\nfunc handleGetBlockTemplateLongPoll(s *rpcServer, longPollID string, useCoinbaseValue bool, closeChan <-chan struct{}) (interface{}, error) {\n\tstate := s.gbtWorkState\n\tstate.Lock()\n\t// The state unlock is intentionally not deferred here since it needs to\n\t// be manually unlocked before waiting for a notification about block\n\t// template changes.\n\n\tif err := state.updateBlockTemplate(s, useCoinbaseValue); err != nil {\n\t\tstate.Unlock()\n\t\treturn nil, err\n\t}\n\n\t// Just return the current block template if the long poll ID provided by\n\t// the caller is invalid.\n\tprevHash, lastGenerated, err := decodeTemplateID(longPollID)\n\tif err != nil {\n\t\tresult, err := state.blockTemplateResult(useCoinbaseValue, nil)\n\t\tif err != nil {\n\t\t\tstate.Unlock()\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstate.Unlock()\n\t\treturn result, nil\n\t}\n\n\t// Return the block template now if the specific block template\n\t// identified by the long poll ID no longer matches the current block\n\t// template as this means the provided template is stale.\n\tprevTemplateHash := &state.template.Block.Header.PrevBlock\n\tif !prevHash.IsEqual(prevTemplateHash) ||\n\t\tlastGenerated != state.lastGenerated.Unix() {\n\n\t\t// Include whether or not it is valid to submit work against the\n\t\t// old block template depending on whether or not a solution has\n\t\t// already been found and added to the block chain.\n\t\tsubmitOld := prevHash.IsEqual(prevTemplateHash)\n\t\tresult, err := state.blockTemplateResult(useCoinbaseValue,\n\t\t\t&submitOld)\n\t\tif err != nil {\n\t\t\tstate.Unlock()\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstate.Unlock()\n\t\treturn result, nil\n\t}\n\n\t// Register the previous hash and last generated time for notifications\n\t// Get a channel that will be notified when the template associated with\n\t// the provided ID is stale and a new block template should be returned to\n\t// the caller.\n\tlongPollChan := state.templateUpdateChan(prevHash, lastGenerated)\n\tstate.Unlock()\n\n\tselect {\n\t// When the client closes before it's time to send a reply, just return\n\t// now so the goroutine doesn't hang around.\n\tcase <-closeChan:\n\t\treturn nil, ErrClientQuit\n\n\t// Wait until signal received to send the reply.\n\tcase <-longPollChan:\n\t\t// Fallthrough\n\t}\n\n\t// Get the lastest block template\n\tstate.Lock()\n\tdefer state.Unlock()\n\n\tif err := state.updateBlockTemplate(s, useCoinbaseValue); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Include whether or not it is valid to submit work against the old\n\t// block template depending on whether or not a solution has already\n\t// been found and added to the block chain.\n\tsubmitOld := prevHash.IsEqual(&state.template.Block.Header.PrevBlock)\n\tresult, err := state.blockTemplateResult(useCoinbaseValue, &submitOld)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn result, nil\n}\n\n// handleGetBlockTemplateRequest is a helper for handleGetBlockTemplate which\n// deals with generating and returning block templates to the caller.  It\n// handles both long poll requests as specified by BIP 0022 as well as regular\n// requests.  In addition, it detects the capabilities reported by the caller\n// in regards to whether or not it supports creating its own coinbase (the\n// coinbasetxn and coinbasevalue capabilities) and modifies the returned block\n// template accordingly.\nfunc handleGetBlockTemplateRequest(s *rpcServer, request *btcjson.TemplateRequest, closeChan <-chan struct{}) (interface{}, error) {\n\t// Extract the relevant passed capabilities and restrict the result to\n\t// either a coinbase value or a coinbase transaction object depending on\n\t// the request.  Default to only providing a coinbase value.\n\tuseCoinbaseValue := true\n\tif request != nil {\n\t\tvar hasCoinbaseValue, hasCoinbaseTxn bool\n\t\tfor _, capability := range request.Capabilities {\n\t\t\tswitch capability {\n\t\t\tcase \"coinbasetxn\":\n\t\t\t\thasCoinbaseTxn = true\n\t\t\tcase \"coinbasevalue\":\n\t\t\t\thasCoinbaseValue = true\n\t\t\t}\n\t\t}\n\n\t\tif hasCoinbaseTxn && !hasCoinbaseValue {\n\t\t\tuseCoinbaseValue = false\n\t\t}\n\t}\n\n\t// When a coinbase transaction has been requested, respond with an error\n\t// if there are no addresses to pay the created block template to.\n\tif !useCoinbaseValue && len(cfg.miningAddrs) == 0 {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\tMessage: \"A coinbase transaction has been requested, \" +\n\t\t\t\t\"but the server has not been configured with \" +\n\t\t\t\t\"any payment addresses via --miningaddr\",\n\t\t}\n\t}\n\n\t// Return an error if there are no peers connected since there is no\n\t// way to relay a found block or receive transactions to work on.\n\t// However, allow this state when running in the regression test or\n\t// simulation test mode.\n\tif !(cfg.RegressionTest || cfg.SimNet) &&\n\t\ts.cfg.ConnMgr.ConnectedCount() == 0 {\n\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCClientNotConnected,\n\t\t\tMessage: \"Bitcoin is not connected\",\n\t\t}\n\t}\n\n\t// No point in generating or accepting work before the chain is synced.\n\tcurrentHeight := s.cfg.Chain.BestSnapshot().Height\n\tif currentHeight != 0 && !s.cfg.SyncMgr.IsCurrent() {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCClientInInitialDownload,\n\t\t\tMessage: \"Bitcoin is downloading blocks...\",\n\t\t}\n\t}\n\n\t// When a long poll ID was provided, this is a long poll request by the\n\t// client to be notified when block template referenced by the ID should\n\t// be replaced with a new one.\n\tif request != nil && request.LongPollID != \"\" {\n\t\treturn handleGetBlockTemplateLongPoll(s, request.LongPollID,\n\t\t\tuseCoinbaseValue, closeChan)\n\t}\n\n\t// Protect concurrent access when updating block templates.\n\tstate := s.gbtWorkState\n\tstate.Lock()\n\tdefer state.Unlock()\n\n\t// Get and return a block template.  A new block template will be\n\t// generated when the current best block has changed or the transactions\n\t// in the memory pool have been updated and it has been at least five\n\t// seconds since the last template was generated.  Otherwise, the\n\t// timestamp for the existing block template is updated (and possibly\n\t// the difficulty on testnet per the consesus rules).\n\tif err := state.updateBlockTemplate(s, useCoinbaseValue); err != nil {\n\t\treturn nil, err\n\t}\n\treturn state.blockTemplateResult(useCoinbaseValue, nil)\n}\n\n// chainErrToGBTErrString converts an error returned from btcchain to a string\n// which matches the reasons and format described in BIP0022 for rejection\n// reasons.\nfunc chainErrToGBTErrString(err error) string {\n\t// When the passed error is not a RuleError, just return a generic\n\t// rejected string with the error text.\n\truleErr, ok := err.(blockchain.RuleError)\n\tif !ok {\n\t\treturn \"rejected: \" + err.Error()\n\t}\n\n\tswitch ruleErr.ErrorCode {\n\tcase blockchain.ErrDuplicateBlock:\n\t\treturn \"duplicate\"\n\tcase blockchain.ErrBlockTooBig:\n\t\treturn \"bad-blk-length\"\n\tcase blockchain.ErrBlockWeightTooHigh:\n\t\treturn \"bad-blk-weight\"\n\tcase blockchain.ErrBlockVersionTooOld:\n\t\treturn \"bad-version\"\n\tcase blockchain.ErrInvalidTime:\n\t\treturn \"bad-time\"\n\tcase blockchain.ErrTimeTooOld:\n\t\treturn \"time-too-old\"\n\tcase blockchain.ErrTimeTooNew:\n\t\treturn \"time-too-new\"\n\tcase blockchain.ErrDifficultyTooLow:\n\t\treturn \"bad-diffbits\"\n\tcase blockchain.ErrUnexpectedDifficulty:\n\t\treturn \"bad-diffbits\"\n\tcase blockchain.ErrHighHash:\n\t\treturn \"high-hash\"\n\tcase blockchain.ErrBadMerkleRoot:\n\t\treturn \"bad-txnmrklroot\"\n\tcase blockchain.ErrBadCheckpoint:\n\t\treturn \"bad-checkpoint\"\n\tcase blockchain.ErrForkTooOld:\n\t\treturn \"fork-too-old\"\n\tcase blockchain.ErrCheckpointTimeTooOld:\n\t\treturn \"checkpoint-time-too-old\"\n\tcase blockchain.ErrNoTransactions:\n\t\treturn \"bad-txns-none\"\n\tcase blockchain.ErrNoTxInputs:\n\t\treturn \"bad-txns-noinputs\"\n\tcase blockchain.ErrNoTxOutputs:\n\t\treturn \"bad-txns-nooutputs\"\n\tcase blockchain.ErrTxTooBig:\n\t\treturn \"bad-txns-size\"\n\tcase blockchain.ErrBadTxOutValue:\n\t\treturn \"bad-txns-outputvalue\"\n\tcase blockchain.ErrDuplicateTxInputs:\n\t\treturn \"bad-txns-dupinputs\"\n\tcase blockchain.ErrBadTxInput:\n\t\treturn \"bad-txns-badinput\"\n\tcase blockchain.ErrMissingTxOut:\n\t\treturn \"bad-txns-missinginput\"\n\tcase blockchain.ErrUnfinalizedTx:\n\t\treturn \"bad-txns-unfinalizedtx\"\n\tcase blockchain.ErrDuplicateTx:\n\t\treturn \"bad-txns-duplicate\"\n\tcase blockchain.ErrOverwriteTx:\n\t\treturn \"bad-txns-overwrite\"\n\tcase blockchain.ErrImmatureSpend:\n\t\treturn \"bad-txns-maturity\"\n\tcase blockchain.ErrSpendTooHigh:\n\t\treturn \"bad-txns-highspend\"\n\tcase blockchain.ErrBadFees:\n\t\treturn \"bad-txns-fees\"\n\tcase blockchain.ErrTooManySigOps:\n\t\treturn \"high-sigops\"\n\tcase blockchain.ErrFirstTxNotCoinbase:\n\t\treturn \"bad-txns-nocoinbase\"\n\tcase blockchain.ErrMultipleCoinbases:\n\t\treturn \"bad-txns-multicoinbase\"\n\tcase blockchain.ErrBadCoinbaseScriptLen:\n\t\treturn \"bad-cb-length\"\n\tcase blockchain.ErrBadCoinbaseValue:\n\t\treturn \"bad-cb-value\"\n\tcase blockchain.ErrMissingCoinbaseHeight:\n\t\treturn \"bad-cb-height\"\n\tcase blockchain.ErrBadCoinbaseHeight:\n\t\treturn \"bad-cb-height\"\n\tcase blockchain.ErrScriptMalformed:\n\t\treturn \"bad-script-malformed\"\n\tcase blockchain.ErrScriptValidation:\n\t\treturn \"bad-script-validate\"\n\tcase blockchain.ErrUnexpectedWitness:\n\t\treturn \"unexpected-witness\"\n\tcase blockchain.ErrInvalidWitnessCommitment:\n\t\treturn \"bad-witness-nonce-size\"\n\tcase blockchain.ErrWitnessCommitmentMismatch:\n\t\treturn \"bad-witness-merkle-match\"\n\tcase blockchain.ErrPreviousBlockUnknown:\n\t\treturn \"prev-blk-not-found\"\n\tcase blockchain.ErrInvalidAncestorBlock:\n\t\treturn \"bad-prevblk\"\n\tcase blockchain.ErrPrevBlockNotBest:\n\t\treturn \"inconclusive-not-best-prvblk\"\n\t}\n\n\treturn \"rejected: \" + err.Error()\n}\n\n// handleGetBlockTemplateProposal is a helper for handleGetBlockTemplate which\n// deals with block proposals.\n//\n// See https://en.bitcoin.it/wiki/BIP_0023 for more details.\nfunc handleGetBlockTemplateProposal(s *rpcServer, request *btcjson.TemplateRequest) (interface{}, error) {\n\thexData := request.Data\n\tif hexData == \"\" {\n\t\treturn false, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCType,\n\t\t\tMessage: fmt.Sprintf(\"Data must contain the \" +\n\t\t\t\t\"hex-encoded serialized block that is being \" +\n\t\t\t\t\"proposed\"),\n\t\t}\n\t}\n\n\t// Ensure the provided data is sane and deserialize the proposed block.\n\tif len(hexData)%2 != 0 {\n\t\thexData = \"0\" + hexData\n\t}\n\tdataBytes, err := hex.DecodeString(hexData)\n\tif err != nil {\n\t\treturn false, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCDeserialization,\n\t\t\tMessage: fmt.Sprintf(\"Data must be \"+\n\t\t\t\t\"hexadecimal string (not %q)\", hexData),\n\t\t}\n\t}\n\tvar msgBlock wire.MsgBlock\n\tif err := msgBlock.Deserialize(bytes.NewReader(dataBytes)); err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDeserialization,\n\t\t\tMessage: \"Block decode failed: \" + err.Error(),\n\t\t}\n\t}\n\tblock := btcutil.NewBlock(&msgBlock)\n\n\t// Ensure the block is building from the expected previous block.\n\texpectedPrevHash := s.cfg.Chain.BestSnapshot().Hash\n\tprevHash := &block.MsgBlock().Header.PrevBlock\n\tif !expectedPrevHash.IsEqual(prevHash) {\n\t\treturn \"bad-prevblk\", nil\n\t}\n\n\tif err := s.cfg.Chain.CheckConnectBlockTemplate(block); err != nil {\n\t\tif _, ok := err.(blockchain.RuleError); !ok {\n\t\t\terrStr := fmt.Sprintf(\"Failed to process block proposal: %v\", err)\n\t\t\trpcsLog.Error(errStr)\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCVerify,\n\t\t\t\tMessage: errStr,\n\t\t\t}\n\t\t}\n\n\t\trpcsLog.Infof(\"Rejected block proposal: %v\", err)\n\t\treturn chainErrToGBTErrString(err), nil\n\t}\n\n\treturn nil, nil\n}\n\n// handleGetBlockTemplate implements the getblocktemplate command.\n//\n// See https://en.bitcoin.it/wiki/BIP_0022 and\n// https://en.bitcoin.it/wiki/BIP_0023 for more details.\nfunc handleGetBlockTemplate(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetBlockTemplateCmd)\n\trequest := c.Request\n\n\t// Set the default mode and override it if supplied.\n\tmode := \"template\"\n\tif request != nil && request.Mode != \"\" {\n\t\tmode = request.Mode\n\t}\n\n\tswitch mode {\n\tcase \"template\":\n\t\treturn handleGetBlockTemplateRequest(s, request, closeChan)\n\tcase \"proposal\":\n\t\treturn handleGetBlockTemplateProposal(s, request)\n\t}\n\n\treturn nil, &btcjson.RPCError{\n\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\tMessage: \"Invalid mode\",\n\t}\n}\n\n// handleGetChainTips implements the getchaintips command.\nfunc handleGetChainTips(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tchainTips := s.cfg.Chain.ChainTips()\n\n\tret := make([]btcjson.GetChainTipsResult, 0, len(chainTips))\n\tfor _, chainTip := range chainTips {\n\t\tret = append(ret, struct {\n\t\t\tHeight    int32  \"json:\\\"height\\\"\"\n\t\t\tHash      string \"json:\\\"hash\\\"\"\n\t\t\tBranchLen int32  \"json:\\\"branchlen\\\"\"\n\t\t\tStatus    string \"json:\\\"status\\\"\"\n\t\t}{\n\t\t\tHeight:    chainTip.Height,\n\t\t\tHash:      chainTip.BlockHash.String(),\n\t\t\tBranchLen: chainTip.BranchLen,\n\t\t\tStatus:    chainTip.Status.String(),\n\t\t})\n\t}\n\n\treturn ret, nil\n}\n\n// handleGetCFilter implements the getcfilter command.\nfunc handleGetCFilter(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tif s.cfg.CfIndex == nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCNoCFIndex,\n\t\t\tMessage: \"The CF index must be enabled for this command\",\n\t\t}\n\t}\n\n\tc := cmd.(*btcjson.GetCFilterCmd)\n\thash, err := chainhash.NewHashFromStr(c.Hash)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Hash)\n\t}\n\n\tfilterBytes, err := s.cfg.CfIndex.FilterByBlockHash(hash, c.FilterType)\n\tif err != nil {\n\t\trpcsLog.Debugf(\"Could not find committed filter for %v: %v\",\n\t\t\thash, err)\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\tMessage: \"Block not found\",\n\t\t}\n\t}\n\n\trpcsLog.Debugf(\"Found committed filter for %v\", hash)\n\treturn hex.EncodeToString(filterBytes), nil\n}\n\n// handleGetCFilterHeader implements the getcfilterheader command.\nfunc handleGetCFilterHeader(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tif s.cfg.CfIndex == nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCNoCFIndex,\n\t\t\tMessage: \"The CF index must be enabled for this command\",\n\t\t}\n\t}\n\n\tc := cmd.(*btcjson.GetCFilterHeaderCmd)\n\thash, err := chainhash.NewHashFromStr(c.Hash)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Hash)\n\t}\n\n\theaderBytes, err := s.cfg.CfIndex.FilterHeaderByBlockHash(hash, c.FilterType)\n\tif len(headerBytes) > 0 {\n\t\trpcsLog.Debugf(\"Found header of committed filter for %v\", hash)\n\t} else {\n\t\trpcsLog.Debugf(\"Could not find header of committed filter for %v: %v\",\n\t\t\thash, err)\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\tMessage: \"Block not found\",\n\t\t}\n\t}\n\n\thash.SetBytes(headerBytes)\n\treturn hash.String(), nil\n}\n\n// handleGetConnectionCount implements the getconnectioncount command.\nfunc handleGetConnectionCount(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn s.cfg.ConnMgr.ConnectedCount(), nil\n}\n\n// handleGetCurrentNet implements the getcurrentnet command.\nfunc handleGetCurrentNet(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn s.cfg.ChainParams.Net, nil\n}\n\n// handleGetDifficulty implements the getdifficulty command.\nfunc handleGetDifficulty(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tbest := s.cfg.Chain.BestSnapshot()\n\treturn getDifficultyRatio(best.Bits, s.cfg.ChainParams), nil\n}\n\n// handleGetGenerate implements the getgenerate command.\nfunc handleGetGenerate(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn s.cfg.CPUMiner.IsMining(), nil\n}\n\n// handleGetHashesPerSec implements the gethashespersec command.\nfunc handleGetHashesPerSec(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn int64(s.cfg.CPUMiner.HashesPerSecond()), nil\n}\n\n// handleGetHeaders implements the getheaders command.\n//\n// NOTE: This is a btcsuite extension originally ported from\n// github.com/decred/dcrd.\nfunc handleGetHeaders(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetHeadersCmd)\n\n\t// Fetch the requested headers from chain while respecting the provided\n\t// block locators and stop hash.\n\tblockLocators := make([]*chainhash.Hash, len(c.BlockLocators))\n\tfor i := range c.BlockLocators {\n\t\tblockLocator, err := chainhash.NewHashFromStr(c.BlockLocators[i])\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(c.BlockLocators[i])\n\t\t}\n\t\tblockLocators[i] = blockLocator\n\t}\n\tvar hashStop chainhash.Hash\n\tif c.HashStop != \"\" {\n\t\terr := chainhash.Decode(&hashStop, c.HashStop)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(c.HashStop)\n\t\t}\n\t}\n\theaders := s.cfg.SyncMgr.LocateHeaders(blockLocators, &hashStop)\n\n\t// Return the serialized block headers as hex-encoded strings.\n\thexBlockHeaders := make([]string, len(headers))\n\tvar buf bytes.Buffer\n\tfor i, h := range headers {\n\t\terr := h.Serialize(&buf)\n\t\tif err != nil {\n\t\t\treturn nil, internalRPCError(err.Error(),\n\t\t\t\t\"Failed to serialize block header\")\n\t\t}\n\t\thexBlockHeaders[i] = hex.EncodeToString(buf.Bytes())\n\t\tbuf.Reset()\n\t}\n\treturn hexBlockHeaders, nil\n}\n\n// handleGetInfo implements the getinfo command. We only return the fields\n// that are not related to wallet functionality.\nfunc handleGetInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tbest := s.cfg.Chain.BestSnapshot()\n\tret := &btcjson.InfoChainResult{\n\t\tVersion:         int32(1000000*appMajor + 10000*appMinor + 100*appPatch),\n\t\tProtocolVersion: int32(maxProtocolVersion),\n\t\tBlocks:          best.Height,\n\t\tTimeOffset:      int64(s.cfg.TimeSource.Offset().Seconds()),\n\t\tConnections:     s.cfg.ConnMgr.ConnectedCount(),\n\t\tProxy:           cfg.Proxy,\n\t\tDifficulty:      getDifficultyRatio(best.Bits, s.cfg.ChainParams),\n\t\tTestNet:         cfg.TestNet3,\n\t\tRelayFee:        cfg.minRelayTxFee.ToBTC(),\n\t}\n\n\treturn ret, nil\n}\n\n// handleGetMempoolInfo implements the getmempoolinfo command.\nfunc handleGetMempoolInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tmempoolTxns := s.cfg.TxMemPool.TxDescs()\n\n\tvar numBytes int64\n\tfor _, txD := range mempoolTxns {\n\t\tnumBytes += int64(txD.Tx.MsgTx().SerializeSize())\n\t}\n\n\tret := &btcjson.GetMempoolInfoResult{\n\t\tSize:  int64(len(mempoolTxns)),\n\t\tBytes: numBytes,\n\t}\n\n\treturn ret, nil\n}\n\n// handleGetMiningInfo implements the getmininginfo command. We only return the\n// fields that are not related to wallet functionality.\nfunc handleGetMiningInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Create a default getnetworkhashps command to use defaults and make\n\t// use of the existing getnetworkhashps handler.\n\tgnhpsCmd := btcjson.NewGetNetworkHashPSCmd(nil, nil)\n\tnetworkHashesPerSecIface, err := handleGetNetworkHashPS(s, gnhpsCmd,\n\t\tcloseChan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnetworkHashesPerSec, ok := networkHashesPerSecIface.(float64)\n\tif !ok {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInternal.Code,\n\t\t\tMessage: \"networkHashesPerSec is not a float64\",\n\t\t}\n\t}\n\n\tbest := s.cfg.Chain.BestSnapshot()\n\tresult := btcjson.GetMiningInfoResult{\n\t\tBlocks:             int64(best.Height),\n\t\tCurrentBlockSize:   best.BlockSize,\n\t\tCurrentBlockWeight: best.BlockWeight,\n\t\tCurrentBlockTx:     best.NumTxns,\n\t\tDifficulty:         getDifficultyRatio(best.Bits, s.cfg.ChainParams),\n\t\tGenerate:           s.cfg.CPUMiner.IsMining(),\n\t\tGenProcLimit:       s.cfg.CPUMiner.NumWorkers(),\n\t\tHashesPerSec:       s.cfg.CPUMiner.HashesPerSecond(),\n\t\tNetworkHashPS:      networkHashesPerSec,\n\t\tPooledTx:           uint64(s.cfg.TxMemPool.Count()),\n\t\tTestNet:            cfg.TestNet3,\n\t}\n\treturn &result, nil\n}\n\n// handleGetNetTotals implements the getnettotals command.\nfunc handleGetNetTotals(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\ttotalBytesRecv, totalBytesSent := s.cfg.ConnMgr.NetTotals()\n\treply := &btcjson.GetNetTotalsResult{\n\t\tTotalBytesRecv: totalBytesRecv,\n\t\tTotalBytesSent: totalBytesSent,\n\t\tTimeMillis:     time.Now().UTC().UnixNano() / int64(time.Millisecond),\n\t}\n\treturn reply, nil\n}\n\n// handleGetNetworkHashPS implements the getnetworkhashps command.\nfunc handleGetNetworkHashPS(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Note: All valid error return paths should return a float64.\n\t// Literal zeros are inferred as int, and won't coerce to float64\n\t// because the return value is an interface{}.\n\n\tc := cmd.(*btcjson.GetNetworkHashPSCmd)\n\n\t// When the passed height is too high or zero, just return 0 now\n\t// since we can't reasonably calculate the number of network hashes\n\t// per second from invalid values.  When it's negative, use the current\n\t// best block height.\n\tbest := s.cfg.Chain.BestSnapshot()\n\tendHeight := int32(-1)\n\tif c.Height != nil {\n\t\tendHeight = int32(*c.Height)\n\t}\n\tif endHeight > best.Height || endHeight == 0 {\n\t\treturn float64(0), nil\n\t}\n\tif endHeight < 0 {\n\t\tendHeight = best.Height\n\t}\n\n\t// Calculate the number of blocks per retarget interval based on the\n\t// chain parameters.\n\tblocksPerRetarget := int32(s.cfg.ChainParams.TargetTimespan /\n\t\ts.cfg.ChainParams.TargetTimePerBlock)\n\n\t// Calculate the starting block height based on the passed number of\n\t// blocks.  When the passed value is negative, use the last block the\n\t// difficulty changed as the starting height.  Also make sure the\n\t// starting height is not before the beginning of the chain.\n\tnumBlocks := int32(120)\n\tif c.Blocks != nil {\n\t\tnumBlocks = int32(*c.Blocks)\n\t}\n\tvar startHeight int32\n\tif numBlocks <= 0 {\n\t\tstartHeight = endHeight - ((endHeight % blocksPerRetarget) + 1)\n\t} else {\n\t\tstartHeight = endHeight - numBlocks\n\t}\n\tif startHeight < 0 {\n\t\tstartHeight = 0\n\t}\n\trpcsLog.Debugf(\"Calculating network hashes per second from %d to %d\",\n\t\tstartHeight, endHeight)\n\n\t// Find the min and max block timestamps as well as calculate the total\n\t// amount of work that happened between the start and end blocks.\n\tvar minTimestamp, maxTimestamp time.Time\n\ttotalWork := big.NewInt(0)\n\tfor curHeight := startHeight; curHeight <= endHeight; curHeight++ {\n\t\thash, err := s.cfg.Chain.BlockHashByHeight(curHeight)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to fetch block hash\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\t// Fetch the header from chain.\n\t\theader, err := s.cfg.Chain.HeaderByHash(hash)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to fetch block header\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\tif curHeight == startHeight {\n\t\t\tminTimestamp = header.Timestamp\n\t\t\tmaxTimestamp = minTimestamp\n\t\t} else {\n\t\t\ttotalWork.Add(totalWork, blockchain.CalcWork(header.Bits))\n\n\t\t\tif minTimestamp.After(header.Timestamp) {\n\t\t\t\tminTimestamp = header.Timestamp\n\t\t\t}\n\t\t\tif maxTimestamp.Before(header.Timestamp) {\n\t\t\t\tmaxTimestamp = header.Timestamp\n\t\t\t}\n\t\t}\n\t}\n\n\t// Calculate the difference in seconds between the min and max block\n\t// timestamps and avoid division by zero in the case where there is no\n\t// time difference.\n\ttimeDiff := maxTimestamp.Sub(minTimestamp).Seconds()\n\tif timeDiff == 0 {\n\t\treturn timeDiff, nil\n\t}\n\n\thashesPerSec, _ := new(big.Float).Quo(new(big.Float).SetInt(totalWork), new(big.Float).SetFloat64(timeDiff)).Float64()\n\treturn hashesPerSec, nil\n}\n\n// handleGetNodeAddresses implements the getnodeaddresses command.\nfunc handleGetNodeAddresses(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetNodeAddressesCmd)\n\n\tcount := int32(1)\n\tif c.Count != nil {\n\t\tcount = *c.Count\n\t\tif count <= 0 {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\t\tMessage: \"Address count out of range\",\n\t\t\t}\n\t\t}\n\t}\n\n\tnodes := s.cfg.ConnMgr.NodeAddresses()\n\tif n := int32(len(nodes)); n < count {\n\t\tcount = n\n\t}\n\n\taddresses := make([]*btcjson.GetNodeAddressesResult, 0, count)\n\tfor _, node := range nodes[:count] {\n\t\taddress := &btcjson.GetNodeAddressesResult{\n\t\t\tTime:     node.Timestamp.Unix(),\n\t\t\tServices: uint64(node.Services),\n\t\t\tAddress:  node.Addr.String(),\n\t\t\tPort:     node.Port,\n\t\t}\n\t\taddresses = append(addresses, address)\n\t}\n\n\treturn addresses, nil\n}\n\n// handleGetPeerInfo implements the getpeerinfo command.\nfunc handleGetPeerInfo(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tpeers := s.cfg.ConnMgr.ConnectedPeers()\n\tsyncPeerID := s.cfg.SyncMgr.SyncPeerID()\n\tinfos := make([]*btcjson.GetPeerInfoResult, 0, len(peers))\n\tfor _, p := range peers {\n\t\tstatsSnap := p.ToPeer().StatsSnapshot()\n\t\tinfo := &btcjson.GetPeerInfoResult{\n\t\t\tID:             statsSnap.ID,\n\t\t\tAddr:           statsSnap.Addr,\n\t\t\tAddrLocal:      p.ToPeer().LocalAddr().String(),\n\t\t\tServices:       fmt.Sprintf(\"%08d\", uint64(statsSnap.Services)),\n\t\t\tRelayTxes:      !p.IsTxRelayDisabled(),\n\t\t\tLastSend:       statsSnap.LastSend.Unix(),\n\t\t\tLastRecv:       statsSnap.LastRecv.Unix(),\n\t\t\tBytesSent:      statsSnap.BytesSent,\n\t\t\tBytesRecv:      statsSnap.BytesRecv,\n\t\t\tConnTime:       statsSnap.ConnTime.Unix(),\n\t\t\tPingTime:       float64(statsSnap.LastPingMicros),\n\t\t\tTimeOffset:     statsSnap.TimeOffset,\n\t\t\tVersion:        statsSnap.Version,\n\t\t\tSubVer:         statsSnap.UserAgent,\n\t\t\tInbound:        statsSnap.Inbound,\n\t\t\tStartingHeight: statsSnap.StartingHeight,\n\t\t\tCurrentHeight:  statsSnap.LastBlock,\n\t\t\tBanScore:       int32(p.BanScore()),\n\t\t\tFeeFilter:      p.FeeFilter(),\n\t\t\tSyncNode:       statsSnap.ID == syncPeerID,\n\t\t}\n\t\tif p.ToPeer().LastPingNonce() != 0 {\n\t\t\twait := float64(time.Since(statsSnap.LastPingTime).Nanoseconds())\n\t\t\t// We actually want microseconds.\n\t\t\tinfo.PingWait = wait / 1000\n\t\t}\n\t\tinfos = append(infos, info)\n\t}\n\treturn infos, nil\n}\n\n// handleGetRawMempool implements the getrawmempool command.\nfunc handleGetRawMempool(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetRawMempoolCmd)\n\tmp := s.cfg.TxMemPool\n\n\tif c.Verbose != nil && *c.Verbose {\n\t\treturn mp.RawMempoolVerbose(), nil\n\t}\n\n\t// The response is simply an array of the transaction hashes if the\n\t// verbose flag is not set.\n\tdescs := mp.TxDescs()\n\thashStrings := make([]string, len(descs))\n\tfor i := range hashStrings {\n\t\thashStrings[i] = descs[i].Tx.Hash().String()\n\t}\n\n\treturn hashStrings, nil\n}\n\n// handleGetRawTransaction implements the getrawtransaction command.\nfunc handleGetRawTransaction(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetRawTransactionCmd)\n\n\t// Convert the provided transaction hash hex to a Hash.\n\ttxHash, err := chainhash.NewHashFromStr(c.Txid)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Txid)\n\t}\n\n\tverbose := false\n\tif c.Verbose != nil {\n\t\tverbose = *c.Verbose != 0\n\t}\n\n\t// Try to fetch the transaction from the memory pool and if that fails,\n\t// try the block database.\n\tvar mtx *wire.MsgTx\n\tvar blkHash *chainhash.Hash\n\tvar blkHeight int32\n\ttx, err := s.cfg.TxMemPool.FetchTransaction(txHash)\n\tif err != nil {\n\t\tif s.cfg.TxIndex == nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCNoTxInfo,\n\t\t\t\tMessage: \"The transaction index must be \" +\n\t\t\t\t\t\"enabled to query the blockchain \" +\n\t\t\t\t\t\"(specify --txindex)\",\n\t\t\t}\n\t\t}\n\n\t\t// Look up the location of the transaction.\n\t\tblockRegion, err := s.cfg.TxIndex.TxBlockRegion(txHash)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to retrieve transaction location\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\tif blockRegion == nil {\n\t\t\treturn nil, rpcNoTxInfoError(txHash)\n\t\t}\n\n\t\t// Load the raw transaction bytes from the database.\n\t\tvar txBytes []byte\n\t\terr = s.cfg.DB.View(func(dbTx database.Tx) error {\n\t\t\tvar err error\n\t\t\ttxBytes, err = dbTx.FetchBlockRegion(blockRegion)\n\t\t\treturn err\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, rpcNoTxInfoError(txHash)\n\t\t}\n\n\t\t// When the verbose flag isn't set, simply return the serialized\n\t\t// transaction as a hex-encoded string.  This is done here to\n\t\t// avoid deserializing it only to reserialize it again later.\n\t\tif !verbose {\n\t\t\treturn hex.EncodeToString(txBytes), nil\n\t\t}\n\n\t\t// Grab the block height.\n\t\tblkHash = blockRegion.Hash\n\t\tblkHeight, err = s.cfg.Chain.BlockHeightByHash(blkHash)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to retrieve block height\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\t// Deserialize the transaction\n\t\tvar msgTx wire.MsgTx\n\t\terr = msgTx.Deserialize(bytes.NewReader(txBytes))\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to deserialize transaction\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\tmtx = &msgTx\n\t} else {\n\t\t// When the verbose flag isn't set, simply return the\n\t\t// network-serialized transaction as a hex-encoded string.\n\t\tif !verbose {\n\t\t\t// Note that this is intentionally not directly\n\t\t\t// returning because the first return value is a\n\t\t\t// string and it would result in returning an empty\n\t\t\t// string to the client instead of nothing (nil) in the\n\t\t\t// case of an error.\n\t\t\tmtxHex, err := messageToHex(tx.MsgTx())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn mtxHex, nil\n\t\t}\n\n\t\tmtx = tx.MsgTx()\n\t}\n\n\t// The verbose flag is set, so generate the JSON object and return it.\n\tvar blkHeader *wire.BlockHeader\n\tvar blkHashStr string\n\tvar chainHeight int32\n\tif blkHash != nil {\n\t\t// Fetch the header from chain.\n\t\theader, err := s.cfg.Chain.HeaderByHash(blkHash)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to fetch block header\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\tblkHeader = &header\n\t\tblkHashStr = blkHash.String()\n\t\tchainHeight = s.cfg.Chain.BestSnapshot().Height\n\t}\n\n\trawTxn, err := createTxRawResult(s.cfg.ChainParams, mtx, txHash.String(),\n\t\tblkHeader, blkHashStr, blkHeight, chainHeight)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn *rawTxn, nil\n}\n\n// handleGetTxOut handles gettxout commands.\nfunc handleGetTxOut(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.GetTxOutCmd)\n\n\t// Convert the provided transaction hash hex to a Hash.\n\ttxHash, err := chainhash.NewHashFromStr(c.Txid)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(c.Txid)\n\t}\n\n\t// If requested and the tx is available in the mempool try to fetch it\n\t// from there, otherwise attempt to fetch from the block database.\n\tvar bestBlockHash string\n\tvar confirmations int32\n\tvar value int64\n\tvar pkScript []byte\n\tvar isCoinbase bool\n\tvar address string\n\tincludeMempool := true\n\tif c.IncludeMempool != nil {\n\t\tincludeMempool = *c.IncludeMempool\n\t}\n\t// TODO: This is racy.  It should attempt to fetch it directly and check\n\t// the error.\n\tif includeMempool && s.cfg.TxMemPool.HaveTransaction(txHash) {\n\t\ttx, err := s.cfg.TxMemPool.FetchTransaction(txHash)\n\t\tif err != nil {\n\t\t\treturn nil, rpcNoTxInfoError(txHash)\n\t\t}\n\n\t\tmtx := tx.MsgTx()\n\t\tif c.Vout > uint32(len(mtx.TxOut)-1) {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInvalidTxVout,\n\t\t\t\tMessage: \"Output index number (vout) does not \" +\n\t\t\t\t\t\"exist for transaction.\",\n\t\t\t}\n\t\t}\n\n\t\ttxOut := mtx.TxOut[c.Vout]\n\t\tif txOut == nil {\n\t\t\terrStr := fmt.Sprintf(\"Output index: %d for txid: %s \"+\n\t\t\t\t\"does not exist\", c.Vout, txHash)\n\t\t\treturn nil, internalRPCError(errStr, \"\")\n\t\t}\n\n\t\tbest := s.cfg.Chain.BestSnapshot()\n\t\tbestBlockHash = best.Hash.String()\n\t\tconfirmations = 0\n\t\tvalue = txOut.Value\n\t\tpkScript = txOut.PkScript\n\t\tisCoinbase = blockchain.IsCoinBaseTx(mtx)\n\t} else {\n\t\tout := wire.OutPoint{Hash: *txHash, Index: c.Vout}\n\t\tentry, err := s.cfg.Chain.FetchUtxoEntry(out)\n\t\tif err != nil {\n\t\t\treturn nil, rpcNoTxInfoError(txHash)\n\t\t}\n\n\t\t// To match the behavior of the reference client, return nil\n\t\t// (JSON null) if the transaction output is spent by another\n\t\t// transaction already in the main chain.  Mined transactions\n\t\t// that are spent by a mempool transaction are not affected by\n\t\t// this.\n\t\tif entry == nil || entry.IsSpent() {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\tbest := s.cfg.Chain.BestSnapshot()\n\t\tbestBlockHash = best.Hash.String()\n\t\tconfirmations = 1 + best.Height - entry.BlockHeight()\n\t\tvalue = entry.Amount()\n\t\tpkScript = entry.PkScript()\n\t\tisCoinbase = entry.IsCoinBase()\n\t}\n\n\t// Disassemble script into single line printable format.\n\t// The disassembled string will contain [error] inline if the script\n\t// doesn't fully parse, so ignore the error here.\n\tdisbuf, _ := txscript.DisasmString(pkScript)\n\n\t// Get further info about the script.\n\t// Ignore the error here since an error means the script couldn't parse\n\t// and there is no additional information about it anyways.\n\tscriptClass, addrs, reqSigs, _ := txscript.ExtractPkScriptAddrs(pkScript,\n\t\ts.cfg.ChainParams)\n\taddresses := make([]string, len(addrs))\n\tfor i, addr := range addrs {\n\t\taddresses[i] = addr.EncodeAddress()\n\t}\n\n\t// Address is defined when there's a single well-defined\n\t// receiver address. To spend the output a signature for this,\n\t// and only this, address is required.\n\tif len(addresses) == 1 && reqSigs <= 1 {\n\t\taddress = addresses[0]\n\t}\n\n\ttxOutReply := &btcjson.GetTxOutResult{\n\t\tBestBlock:     bestBlockHash,\n\t\tConfirmations: int64(confirmations),\n\t\tValue:         btcutil.Amount(value).ToBTC(),\n\t\tScriptPubKey: btcjson.ScriptPubKeyResult{\n\t\t\tAsm:       disbuf,\n\t\t\tHex:       hex.EncodeToString(pkScript),\n\t\t\tReqSigs:   int32(reqSigs),\n\t\t\tType:      scriptClass.String(),\n\t\t\tAddress:   address,\n\t\t\tAddresses: addresses,\n\t\t},\n\t\tCoinbase: isCoinbase,\n\t}\n\n\treturn txOutReply, nil\n}\n\n// handleInvalidateBlock implements the invalidateblock command.\nfunc handleInvalidateBlock(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.InvalidateBlockCmd)\n\n\tinvalidateHash, err := chainhash.NewHashFromStr(c.BlockHash)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCDeserialization,\n\t\t\tMessage: fmt.Sprintf(\"Failed to deserialize blockhash from string of %s\",\n\t\t\t\tinvalidateHash),\n\t\t}\n\t}\n\n\terr = s.cfg.Chain.InvalidateBlock(invalidateHash)\n\treturn nil, err\n}\n\n// handleHelp implements the help command.\nfunc handleHelp(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.HelpCmd)\n\n\t// Provide a usage overview of all commands when no specific command\n\t// was specified.\n\tvar command string\n\tif c.Command != nil {\n\t\tcommand = *c.Command\n\t}\n\tif command == \"\" {\n\t\tusage, err := s.helpCacher.rpcUsage(false)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to generate RPC usage\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\treturn usage, nil\n\t}\n\n\t// Check that the command asked for is supported and implemented.  Only\n\t// search the main list of handlers since help should not be provided\n\t// for commands that are unimplemented or related to wallet\n\t// functionality.\n\tif _, ok := rpcHandlers[command]; !ok {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: \"Unknown command: \" + command,\n\t\t}\n\t}\n\n\t// Get the help for the command.\n\thelp, err := s.helpCacher.rpcMethodHelp(command)\n\tif err != nil {\n\t\tcontext := \"Failed to generate help\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\treturn help, nil\n}\n\n// handlePing implements the ping command.\nfunc handlePing(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Ask server to ping \\o_\n\tnonce, err := wire.RandomUint64()\n\tif err != nil {\n\t\treturn nil, internalRPCError(\"Not sending ping - failed to \"+\n\t\t\t\"generate nonce: \"+err.Error(), \"\")\n\t}\n\ts.cfg.ConnMgr.BroadcastMessage(wire.NewMsgPing(nonce))\n\n\treturn nil, nil\n}\n\n// retrievedTx represents a transaction that was either loaded from the\n// transaction memory pool or from the database.  When a transaction is loaded\n// from the database, it is loaded with the raw serialized bytes while the\n// mempool has the fully deserialized structure.  This structure therefore will\n// have one of the two fields set depending on where is was retrieved from.\n// This is mainly done for efficiency to avoid extra serialization steps when\n// possible.\ntype retrievedTx struct {\n\ttxBytes []byte\n\tblkHash *chainhash.Hash // Only set when transaction is in a block.\n\ttx      *btcutil.Tx\n}\n\n// fetchInputTxos fetches the outpoints from all transactions referenced by the\n// inputs to the passed transaction by checking the transaction mempool first\n// then the transaction index for those already mined into blocks.\nfunc fetchInputTxos(s *rpcServer, tx *wire.MsgTx) (map[wire.OutPoint]wire.TxOut, error) {\n\tmp := s.cfg.TxMemPool\n\toriginOutputs := make(map[wire.OutPoint]wire.TxOut)\n\tfor txInIndex, txIn := range tx.TxIn {\n\t\t// Attempt to fetch and use the referenced transaction from the\n\t\t// memory pool.\n\t\torigin := &txIn.PreviousOutPoint\n\t\toriginTx, err := mp.FetchTransaction(&origin.Hash)\n\t\tif err == nil {\n\t\t\ttxOuts := originTx.MsgTx().TxOut\n\t\t\tif origin.Index >= uint32(len(txOuts)) {\n\t\t\t\terrStr := fmt.Sprintf(\"unable to find output \"+\n\t\t\t\t\t\"%v referenced from transaction %s:%d\",\n\t\t\t\t\torigin, tx.TxHash(), txInIndex)\n\t\t\t\treturn nil, internalRPCError(errStr, \"\")\n\t\t\t}\n\n\t\t\toriginOutputs[*origin] = *txOuts[origin.Index]\n\t\t\tcontinue\n\t\t}\n\n\t\t// Look up the location of the transaction.\n\t\tblockRegion, err := s.cfg.TxIndex.TxBlockRegion(&origin.Hash)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to retrieve transaction location\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\tif blockRegion == nil {\n\t\t\treturn nil, rpcNoTxInfoError(&origin.Hash)\n\t\t}\n\n\t\t// Load the raw transaction bytes from the database.\n\t\tvar txBytes []byte\n\t\terr = s.cfg.DB.View(func(dbTx database.Tx) error {\n\t\t\tvar err error\n\t\t\ttxBytes, err = dbTx.FetchBlockRegion(blockRegion)\n\t\t\treturn err\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, rpcNoTxInfoError(&origin.Hash)\n\t\t}\n\n\t\t// Deserialize the transaction\n\t\tvar msgTx wire.MsgTx\n\t\terr = msgTx.Deserialize(bytes.NewReader(txBytes))\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to deserialize transaction\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t\t// Add the referenced output to the map.\n\t\tif origin.Index >= uint32(len(msgTx.TxOut)) {\n\t\t\terrStr := fmt.Sprintf(\"unable to find output %v \"+\n\t\t\t\t\"referenced from transaction %s:%d\", origin,\n\t\t\t\ttx.TxHash(), txInIndex)\n\t\t\treturn nil, internalRPCError(errStr, \"\")\n\t\t}\n\t\toriginOutputs[*origin] = *msgTx.TxOut[origin.Index]\n\t}\n\n\treturn originOutputs, nil\n}\n\n// createVinListPrevOut returns a slice of JSON objects for the inputs of the\n// passed transaction.\nfunc createVinListPrevOut(s *rpcServer, mtx *wire.MsgTx, chainParams *chaincfg.Params, vinExtra bool, filterAddrMap map[string]struct{}) ([]btcjson.VinPrevOut, error) {\n\t// Coinbase transactions only have a single txin by definition.\n\tif blockchain.IsCoinBaseTx(mtx) {\n\t\t// Only include the transaction if the filter map is empty\n\t\t// because a coinbase input has no addresses and so would never\n\t\t// match a non-empty filter.\n\t\tif len(filterAddrMap) != 0 {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\ttxIn := mtx.TxIn[0]\n\t\tvinList := make([]btcjson.VinPrevOut, 1)\n\t\tvinList[0].Coinbase = hex.EncodeToString(txIn.SignatureScript)\n\t\tvinList[0].Sequence = txIn.Sequence\n\t\treturn vinList, nil\n\t}\n\n\t// Use a dynamically sized list to accommodate the address filter.\n\tvinList := make([]btcjson.VinPrevOut, 0, len(mtx.TxIn))\n\n\t// Lookup all of the referenced transaction outputs needed to populate\n\t// the previous output information if requested.\n\tvar originOutputs map[wire.OutPoint]wire.TxOut\n\tif vinExtra || len(filterAddrMap) > 0 {\n\t\tvar err error\n\t\toriginOutputs, err = fetchInputTxos(s, mtx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfor _, txIn := range mtx.TxIn {\n\t\t// The disassembled string will contain [error] inline\n\t\t// if the script doesn't fully parse, so ignore the\n\t\t// error here.\n\t\tdisbuf, _ := txscript.DisasmString(txIn.SignatureScript)\n\n\t\t// Create the basic input entry without the additional optional\n\t\t// previous output details which will be added later if\n\t\t// requested and available.\n\t\tprevOut := &txIn.PreviousOutPoint\n\t\tvinEntry := btcjson.VinPrevOut{\n\t\t\tTxid:     prevOut.Hash.String(),\n\t\t\tVout:     prevOut.Index,\n\t\t\tSequence: txIn.Sequence,\n\t\t\tScriptSig: &btcjson.ScriptSig{\n\t\t\t\tAsm: disbuf,\n\t\t\t\tHex: hex.EncodeToString(txIn.SignatureScript),\n\t\t\t},\n\t\t}\n\n\t\tif len(txIn.Witness) != 0 {\n\t\t\tvinEntry.Witness = txIn.Witness.ToHexStrings()\n\t\t}\n\n\t\t// Add the entry to the list now if it already passed the filter\n\t\t// since the previous output might not be available.\n\t\tpassesFilter := len(filterAddrMap) == 0\n\t\tif passesFilter {\n\t\t\tvinList = append(vinList, vinEntry)\n\t\t}\n\n\t\t// Only populate previous output information if requested and\n\t\t// available.\n\t\tif len(originOutputs) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\toriginTxOut, ok := originOutputs[*prevOut]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Ignore the error here since an error means the script\n\t\t// couldn't parse and there is no additional information about\n\t\t// it anyways.\n\t\t_, addrs, _, _ := txscript.ExtractPkScriptAddrs(\n\t\t\toriginTxOut.PkScript, chainParams)\n\n\t\t// Encode the addresses while checking if the address passes the\n\t\t// filter when needed.\n\t\tencodedAddrs := make([]string, len(addrs))\n\t\tfor j, addr := range addrs {\n\t\t\tencodedAddr := addr.EncodeAddress()\n\t\t\tencodedAddrs[j] = encodedAddr\n\n\t\t\t// No need to check the map again if the filter already\n\t\t\t// passes.\n\t\t\tif passesFilter {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, exists := filterAddrMap[encodedAddr]; exists {\n\t\t\t\tpassesFilter = true\n\t\t\t}\n\t\t}\n\n\t\t// Ignore the entry if it doesn't pass the filter.\n\t\tif !passesFilter {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Add entry to the list if it wasn't already done above.\n\t\tif len(filterAddrMap) != 0 {\n\t\t\tvinList = append(vinList, vinEntry)\n\t\t}\n\n\t\t// Update the entry with previous output information if\n\t\t// requested.\n\t\tif vinExtra {\n\t\t\tvinListEntry := &vinList[len(vinList)-1]\n\t\t\tvinListEntry.PrevOut = &btcjson.PrevOut{\n\t\t\t\tAddresses: encodedAddrs,\n\t\t\t\tValue:     btcutil.Amount(originTxOut.Value).ToBTC(),\n\t\t\t}\n\t\t}\n\t}\n\n\treturn vinList, nil\n}\n\n// fetchMempoolTxnsForAddress queries the address index for all unconfirmed\n// transactions that involve the provided address.  The results will be limited\n// by the number to skip and the number requested.\nfunc fetchMempoolTxnsForAddress(s *rpcServer, addr btcutil.Address, numToSkip, numRequested uint32) ([]*btcutil.Tx, uint32) {\n\t// There are no entries to return when there are less available than the\n\t// number being skipped.\n\tmpTxns := s.cfg.AddrIndex.UnconfirmedTxnsForAddress(addr)\n\tnumAvailable := uint32(len(mpTxns))\n\tif numToSkip > numAvailable {\n\t\treturn nil, numAvailable\n\t}\n\n\t// Filter the available entries based on the number to skip and number\n\t// requested.\n\trangeEnd := numToSkip + numRequested\n\tif rangeEnd > numAvailable {\n\t\trangeEnd = numAvailable\n\t}\n\treturn mpTxns[numToSkip:rangeEnd], numToSkip\n}\n\n// handleReconsiderBlock implements the reconsiderblock command.\nfunc handleReconsiderBlock(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.ReconsiderBlockCmd)\n\n\treconsiderHash, err := chainhash.NewHashFromStr(c.BlockHash)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode: btcjson.ErrRPCDeserialization,\n\t\t\tMessage: fmt.Sprintf(\"Failed to deserialize blockhash from string of %s\",\n\t\t\t\treconsiderHash),\n\t\t}\n\t}\n\n\terr = s.cfg.Chain.ReconsiderBlock(reconsiderHash)\n\treturn nil, err\n}\n\n// handleSearchRawTransactions implements the searchrawtransactions command.\nfunc handleSearchRawTransactions(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\t// Respond with an error if the address index is not enabled.\n\taddrIndex := s.cfg.AddrIndex\n\tif addrIndex == nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCMisc,\n\t\t\tMessage: \"Address index must be enabled (--addrindex)\",\n\t\t}\n\t}\n\n\t// Override the flag for including extra previous output information in\n\t// each input if needed.\n\tc := cmd.(*btcjson.SearchRawTransactionsCmd)\n\tvinExtra := false\n\tif c.VinExtra != nil {\n\t\tvinExtra = *c.VinExtra != 0\n\t}\n\n\t// Including the extra previous output information requires the\n\t// transaction index.  Currently the address index relies on the\n\t// transaction index, so this check is redundant, but it's better to be\n\t// safe in case the address index is ever changed to not rely on it.\n\tif vinExtra && s.cfg.TxIndex == nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCMisc,\n\t\t\tMessage: \"Transaction index must be enabled (--txindex)\",\n\t\t}\n\t}\n\n\t// Attempt to decode the supplied address.\n\tparams := s.cfg.ChainParams\n\taddr, err := btcutil.DecodeAddress(c.Address, params)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\tMessage: \"Invalid address or key: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Override the default number of requested entries if needed.  Also,\n\t// just return now if the number of requested entries is zero to avoid\n\t// extra work.\n\tnumRequested := 100\n\tif c.Count != nil {\n\t\tnumRequested = *c.Count\n\t\tif numRequested < 0 {\n\t\t\tnumRequested = 1\n\t\t}\n\t}\n\tif numRequested == 0 {\n\t\treturn nil, nil\n\t}\n\n\t// Override the default number of entries to skip if needed.\n\tvar numToSkip int\n\tif c.Skip != nil {\n\t\tnumToSkip = *c.Skip\n\t\tif numToSkip < 0 {\n\t\t\tnumToSkip = 0\n\t\t}\n\t}\n\n\t// Override the reverse flag if needed.\n\tvar reverse bool\n\tif c.Reverse != nil {\n\t\treverse = *c.Reverse\n\t}\n\n\t// Add transactions from mempool first if client asked for reverse\n\t// order.  Otherwise, they will be added last (as needed depending on\n\t// the requested counts).\n\t//\n\t// NOTE: This code doesn't sort by dependency.  This might be something\n\t// to do in the future for the client's convenience, or leave it to the\n\t// client.\n\tnumSkipped := uint32(0)\n\taddressTxns := make([]retrievedTx, 0, numRequested)\n\tif reverse {\n\t\t// Transactions in the mempool are not in a block header yet,\n\t\t// so the block header field in the retrieved transaction struct\n\t\t// is left nil.\n\t\tmpTxns, mpSkipped := fetchMempoolTxnsForAddress(s, addr,\n\t\t\tuint32(numToSkip), uint32(numRequested))\n\t\tnumSkipped += mpSkipped\n\t\tfor _, tx := range mpTxns {\n\t\t\taddressTxns = append(addressTxns, retrievedTx{tx: tx})\n\t\t}\n\t}\n\n\t// Fetch transactions from the database in the desired order if more are\n\t// needed.\n\tif len(addressTxns) < numRequested {\n\t\terr = s.cfg.DB.View(func(dbTx database.Tx) error {\n\t\t\tregions, dbSkipped, err := addrIndex.TxRegionsForAddress(\n\t\t\t\tdbTx, addr, uint32(numToSkip)-numSkipped,\n\t\t\t\tuint32(numRequested-len(addressTxns)), reverse)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Load the raw transaction bytes from the database.\n\t\t\tserializedTxns, err := dbTx.FetchBlockRegions(regions)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Add the transaction and the hash of the block it is\n\t\t\t// contained in to the list.  Note that the transaction\n\t\t\t// is left serialized here since the caller might have\n\t\t\t// requested non-verbose output and hence there would be\n\t\t\t// no point in deserializing it just to reserialize it\n\t\t\t// later.\n\t\t\tfor i, serializedTx := range serializedTxns {\n\t\t\t\taddressTxns = append(addressTxns, retrievedTx{\n\t\t\t\t\ttxBytes: serializedTx,\n\t\t\t\t\tblkHash: regions[i].Hash,\n\t\t\t\t})\n\t\t\t}\n\t\t\tnumSkipped += dbSkipped\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to load address index entries\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\n\t}\n\n\t// Add transactions from mempool last if client did not request reverse\n\t// order and the number of results is still under the number requested.\n\tif !reverse && len(addressTxns) < numRequested {\n\t\t// Transactions in the mempool are not in a block header yet,\n\t\t// so the block header field in the retrieved transaction struct\n\t\t// is left nil.\n\t\tmpTxns, mpSkipped := fetchMempoolTxnsForAddress(s, addr,\n\t\t\tuint32(numToSkip)-numSkipped, uint32(numRequested-\n\t\t\t\tlen(addressTxns)))\n\t\tnumSkipped += mpSkipped\n\t\tfor _, tx := range mpTxns {\n\t\t\taddressTxns = append(addressTxns, retrievedTx{tx: tx})\n\t\t}\n\t}\n\n\t// Address has never been used if neither source yielded any results.\n\tif len(addressTxns) == 0 {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCNoTxInfo,\n\t\t\tMessage: \"No information available about address\",\n\t\t}\n\t}\n\n\t// Serialize all of the transactions to hex.\n\thexTxns := make([]string, len(addressTxns))\n\tfor i := range addressTxns {\n\t\t// Simply encode the raw bytes to hex when the retrieved\n\t\t// transaction is already in serialized form.\n\t\trtx := &addressTxns[i]\n\t\tif rtx.txBytes != nil {\n\t\t\thexTxns[i] = hex.EncodeToString(rtx.txBytes)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Serialize the transaction first and convert to hex when the\n\t\t// retrieved transaction is the deserialized structure.\n\t\thexTxns[i], err = messageToHex(rtx.tx.MsgTx())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// When not in verbose mode, simply return a list of serialized txns.\n\tif c.Verbose != nil && *c.Verbose == 0 {\n\t\treturn hexTxns, nil\n\t}\n\n\t// Normalize the provided filter addresses (if any) to ensure there are\n\t// no duplicates.\n\tfilterAddrMap := make(map[string]struct{})\n\tif c.FilterAddrs != nil && len(*c.FilterAddrs) > 0 {\n\t\tfor _, addr := range *c.FilterAddrs {\n\t\t\tfilterAddrMap[addr] = struct{}{}\n\t\t}\n\t}\n\n\t// The verbose flag is set, so generate the JSON object and return it.\n\tbest := s.cfg.Chain.BestSnapshot()\n\tsrtList := make([]btcjson.SearchRawTransactionsResult, len(addressTxns))\n\tfor i := range addressTxns {\n\t\t// The deserialized transaction is needed, so deserialize the\n\t\t// retrieved transaction if it's in serialized form (which will\n\t\t// be the case when it was lookup up from the database).\n\t\t// Otherwise, use the existing deserialized transaction.\n\t\trtx := &addressTxns[i]\n\t\tvar mtx *wire.MsgTx\n\t\tif rtx.tx == nil {\n\t\t\t// Deserialize the transaction.\n\t\t\tmtx = new(wire.MsgTx)\n\t\t\terr := mtx.Deserialize(bytes.NewReader(rtx.txBytes))\n\t\t\tif err != nil {\n\t\t\t\tcontext := \"Failed to deserialize transaction\"\n\t\t\t\treturn nil, internalRPCError(err.Error(),\n\t\t\t\t\tcontext)\n\t\t\t}\n\t\t} else {\n\t\t\tmtx = rtx.tx.MsgTx()\n\t\t}\n\n\t\tresult := &srtList[i]\n\t\tresult.Hex = hexTxns[i]\n\t\tresult.Txid = mtx.TxHash().String()\n\t\tresult.Vin, err = createVinListPrevOut(s, mtx, params, vinExtra,\n\t\t\tfilterAddrMap)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresult.Vout = createVoutList(mtx, params, filterAddrMap)\n\t\tresult.Version = mtx.Version\n\t\tresult.LockTime = mtx.LockTime\n\n\t\t// Transactions grabbed from the mempool aren't yet in a block,\n\t\t// so conditionally fetch block details here.  This will be\n\t\t// reflected in the final JSON output (mempool won't have\n\t\t// confirmations or block information).\n\t\tvar blkHeader *wire.BlockHeader\n\t\tvar blkHashStr string\n\t\tvar blkHeight int32\n\t\tif blkHash := rtx.blkHash; blkHash != nil {\n\t\t\t// Fetch the header from chain.\n\t\t\theader, err := s.cfg.Chain.HeaderByHash(blkHash)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\t\t\tMessage: \"Block not found\",\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Get the block height from chain.\n\t\t\theight, err := s.cfg.Chain.BlockHeightByHash(blkHash)\n\t\t\tif err != nil {\n\t\t\t\tcontext := \"Failed to obtain block height\"\n\t\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t\t}\n\n\t\t\tblkHeader = &header\n\t\t\tblkHashStr = blkHash.String()\n\t\t\tblkHeight = height\n\t\t}\n\n\t\t// Add the block information to the result if there is any.\n\t\tif blkHeader != nil {\n\t\t\t// This is not a typo, they are identical in Bitcoin\n\t\t\t// Core as well.\n\t\t\tresult.Time = blkHeader.Timestamp.Unix()\n\t\t\tresult.Blocktime = blkHeader.Timestamp.Unix()\n\t\t\tresult.BlockHash = blkHashStr\n\t\t\tresult.Confirmations = uint64(1 + best.Height - blkHeight)\n\t\t}\n\t}\n\n\treturn srtList, nil\n}\n\n// handleSendRawTransaction implements the sendrawtransaction command.\nfunc handleSendRawTransaction(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.SendRawTransactionCmd)\n\t// Deserialize and send off to tx relay\n\thexStr := c.HexTx\n\tif len(hexStr)%2 != 0 {\n\t\thexStr = \"0\" + hexStr\n\t}\n\tserializedTx, err := hex.DecodeString(hexStr)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(hexStr)\n\t}\n\tvar msgTx wire.MsgTx\n\terr = msgTx.Deserialize(bytes.NewReader(serializedTx))\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDeserialization,\n\t\t\tMessage: \"TX decode failed: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Use 0 for the tag to represent local node.\n\ttx := btcutil.NewTx(&msgTx)\n\tacceptedTxs, err := s.cfg.TxMemPool.ProcessTransaction(tx, false, false, 0)\n\tif err != nil {\n\t\t// When the error is a rule error, it means the transaction was\n\t\t// simply rejected as opposed to something actually going wrong,\n\t\t// so log it as such. Otherwise, something really did go wrong,\n\t\t// so log it as an actual error and return.\n\t\truleErr, ok := err.(mempool.RuleError)\n\t\tif !ok {\n\t\t\trpcsLog.Errorf(\"Failed to process transaction %v: %v\",\n\t\t\t\ttx.Hash(), err)\n\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCTxError,\n\t\t\t\tMessage: \"TX rejected: \" + err.Error(),\n\t\t\t}\n\t\t}\n\n\t\trpcsLog.Debugf(\"Rejected transaction %v: %v\", tx.Hash(), err)\n\n\t\t// We'll then map the rule error to the appropriate RPC error,\n\t\t// matching bitcoind's behavior.\n\t\tcode := btcjson.ErrRPCTxError\n\t\tif txRuleErr, ok := ruleErr.Err.(mempool.TxRuleError); ok {\n\t\t\terrDesc := txRuleErr.Description\n\t\t\tswitch {\n\t\t\tcase strings.Contains(\n\t\t\t\tstrings.ToLower(errDesc), \"orphan transaction\",\n\t\t\t):\n\t\t\t\tcode = btcjson.ErrRPCTxError\n\n\t\t\tcase strings.Contains(\n\t\t\t\tstrings.ToLower(errDesc), \"transaction already exists\",\n\t\t\t):\n\t\t\t\tcode = btcjson.ErrRPCTxAlreadyInChain\n\n\t\t\tdefault:\n\t\t\t\tcode = btcjson.ErrRPCTxRejected\n\t\t\t}\n\t\t}\n\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    code,\n\t\t\tMessage: \"TX rejected: \" + err.Error(),\n\t\t}\n\t}\n\n\t// When the transaction was accepted it should be the first item in the\n\t// returned array of accepted transactions.  The only way this will not\n\t// be true is if the API for ProcessTransaction changes and this code is\n\t// not properly updated, but ensure the condition holds as a safeguard.\n\t//\n\t// Also, since an error is being returned to the caller, ensure the\n\t// transaction is removed from the memory pool.\n\tif len(acceptedTxs) == 0 || !acceptedTxs[0].Tx.Hash().IsEqual(tx.Hash()) {\n\t\ts.cfg.TxMemPool.RemoveTransaction(tx, true)\n\n\t\terrStr := fmt.Sprintf(\"transaction %v is not in accepted list\",\n\t\t\ttx.Hash())\n\t\treturn nil, internalRPCError(errStr, \"\")\n\t}\n\n\t// Generate and relay inventory vectors for all newly accepted\n\t// transactions into the memory pool due to the original being\n\t// accepted.\n\ts.cfg.ConnMgr.RelayTransactions(acceptedTxs)\n\n\t// Notify both websocket and getblocktemplate long poll clients of all\n\t// newly accepted transactions.\n\ts.NotifyNewTransactions(acceptedTxs)\n\n\t// Keep track of all the sendrawtransaction request txns so that they\n\t// can be rebroadcast if they don't make their way into a block.\n\ttxD := acceptedTxs[0]\n\tiv := wire.NewInvVect(wire.InvTypeTx, txD.Tx.Hash())\n\ts.cfg.ConnMgr.AddRebroadcastInventory(iv, txD)\n\n\treturn tx.Hash().String(), nil\n}\n\n// handleSetGenerate implements the setgenerate command.\nfunc handleSetGenerate(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.SetGenerateCmd)\n\n\t// Disable generation regardless of the provided generate flag if the\n\t// maximum number of threads (goroutines for our purposes) is 0.\n\t// Otherwise enable or disable it depending on the provided flag.\n\tgenerate := c.Generate\n\tgenProcLimit := -1\n\tif c.GenProcLimit != nil {\n\t\tgenProcLimit = *c.GenProcLimit\n\t}\n\tif genProcLimit == 0 {\n\t\tgenerate = false\n\t}\n\n\tif !generate {\n\t\ts.cfg.CPUMiner.Stop()\n\t} else {\n\t\t// Respond with an error if there are no addresses to pay the\n\t\t// created blocks to.\n\t\tif len(cfg.miningAddrs) == 0 {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInternal.Code,\n\t\t\t\tMessage: \"No payment addresses specified \" +\n\t\t\t\t\t\"via --miningaddr\",\n\t\t\t}\n\t\t}\n\n\t\t// It's safe to call start even if it's already started.\n\t\ts.cfg.CPUMiner.SetNumWorkers(int32(genProcLimit))\n\t\ts.cfg.CPUMiner.Start()\n\t}\n\treturn nil, nil\n}\n\n// Text used to signify that a signed message follows and to prevent\n// inadvertently signing a transaction.\nconst messageSignatureHeader = \"Bitcoin Signed Message:\\n\"\n\n// handleSignMessageWithPrivKey implements the signmessagewithprivkey command.\nfunc handleSignMessageWithPrivKey(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.SignMessageWithPrivKeyCmd)\n\n\twif, err := btcutil.DecodeWIF(c.PrivKey)\n\tif err != nil {\n\t\tmessage := \"Invalid private key\"\n\t\tswitch err {\n\t\tcase btcutil.ErrMalformedPrivateKey:\n\t\t\tmessage = \"Malformed private key\"\n\t\tcase btcutil.ErrChecksumMismatch:\n\t\t\tmessage = \"Private key checksum mismatch\"\n\t\t}\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\tMessage: message,\n\t\t}\n\t}\n\tif !wif.IsForNet(s.cfg.ChainParams) {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\tMessage: \"Private key for wrong network\",\n\t\t}\n\t}\n\n\tvar buf bytes.Buffer\n\twire.WriteVarString(&buf, 0, messageSignatureHeader)\n\twire.WriteVarString(&buf, 0, c.Message)\n\tmessageHash := chainhash.DoubleHashB(buf.Bytes())\n\n\tsig := ecdsa.SignCompact(wif.PrivKey, messageHash, wif.CompressPubKey)\n\n\treturn base64.StdEncoding.EncodeToString(sig), nil\n}\n\n// handleStop implements the stop command.\nfunc handleStop(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tselect {\n\tcase s.requestProcessShutdown <- struct{}{}:\n\tdefault:\n\t}\n\treturn \"btcd stopping.\", nil\n}\n\n// handleSubmitBlock implements the submitblock command.\nfunc handleSubmitBlock(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.SubmitBlockCmd)\n\n\t// Deserialize the submitted block.\n\thexStr := c.HexBlock\n\tif len(hexStr)%2 != 0 {\n\t\thexStr = \"0\" + c.HexBlock\n\t}\n\tserializedBlock, err := hex.DecodeString(hexStr)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(hexStr)\n\t}\n\n\tblock, err := btcutil.NewBlockFromBytes(serializedBlock)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDeserialization,\n\t\t\tMessage: \"Block decode failed: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Process this block using the same rules as blocks coming from other\n\t// nodes.  This will in turn relay it to the network like normal.\n\t_, err = s.cfg.SyncMgr.SubmitBlock(block, blockchain.BFNone)\n\tif err != nil {\n\t\treturn fmt.Sprintf(\"rejected: %s\", err.Error()), nil\n\t}\n\n\trpcsLog.Infof(\"Accepted block %s via submitblock\", block.Hash())\n\treturn nil, nil\n}\n\n// handleUptime implements the uptime command.\nfunc handleUptime(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\treturn time.Now().Unix() - s.cfg.StartupTime, nil\n}\n\n// handleValidateAddress implements the validateaddress command.\nfunc handleValidateAddress(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.ValidateAddressCmd)\n\n\tresult := btcjson.ValidateAddressChainResult{}\n\taddr, err := btcutil.DecodeAddress(c.Address, s.cfg.ChainParams)\n\tif err != nil {\n\t\t// Return the default value (false) for IsValid.\n\t\treturn result, nil\n\t}\n\n\tswitch addr := addr.(type) {\n\tcase *btcutil.AddressPubKeyHash:\n\t\tresult.IsScript = btcjson.Bool(false)\n\t\tresult.IsWitness = btcjson.Bool(false)\n\n\tcase *btcutil.AddressScriptHash:\n\t\tresult.IsScript = btcjson.Bool(true)\n\t\tresult.IsWitness = btcjson.Bool(false)\n\n\tcase *btcutil.AddressPubKey:\n\t\tresult.IsScript = btcjson.Bool(false)\n\t\tresult.IsWitness = btcjson.Bool(false)\n\n\tcase *btcutil.AddressWitnessPubKeyHash:\n\t\tresult.IsScript = btcjson.Bool(false)\n\t\tresult.IsWitness = btcjson.Bool(true)\n\t\tresult.WitnessVersion = btcjson.Int32(int32(addr.WitnessVersion()))\n\t\tresult.WitnessProgram = btcjson.String(hex.EncodeToString(addr.WitnessProgram()))\n\n\tcase *btcutil.AddressWitnessScriptHash:\n\t\tresult.IsScript = btcjson.Bool(true)\n\t\tresult.IsWitness = btcjson.Bool(true)\n\t\tresult.WitnessVersion = btcjson.Int32(int32(addr.WitnessVersion()))\n\t\tresult.WitnessProgram = btcjson.String(hex.EncodeToString(addr.WitnessProgram()))\n\n\tdefault:\n\t\t// Handle the case when a new Address is supported by btcutil, but none\n\t\t// of the cases were matched in the switch block. The current behaviour\n\t\t// is to do nothing, and only populate the Address and IsValid fields.\n\t}\n\n\tresult.Address = addr.EncodeAddress()\n\tresult.IsValid = true\n\n\treturn result, nil\n}\n\nfunc verifyChain(s *rpcServer, level, depth int32) error {\n\tbest := s.cfg.Chain.BestSnapshot()\n\tfinishHeight := best.Height - depth\n\tif finishHeight < 0 {\n\t\tfinishHeight = 0\n\t}\n\trpcsLog.Infof(\"Verifying chain for %d blocks at level %d\",\n\t\tbest.Height-finishHeight, level)\n\n\tfor height := best.Height; height > finishHeight; height-- {\n\t\t// Level 0 just looks up the block.\n\t\tblock, err := s.cfg.Chain.BlockByHeight(height)\n\t\tif err != nil {\n\t\t\trpcsLog.Errorf(\"Verify is unable to fetch block at \"+\n\t\t\t\t\"height %d: %v\", height, err)\n\t\t\treturn err\n\t\t}\n\n\t\t// Level 1 does basic chain sanity checks.\n\t\tif level > 0 {\n\t\t\terr := blockchain.CheckBlockSanity(block,\n\t\t\t\ts.cfg.ChainParams.PowLimit, s.cfg.TimeSource)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Verify is unable to validate \"+\n\t\t\t\t\t\"block at hash %v height %d: %v\",\n\t\t\t\t\tblock.Hash(), height, err)\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\trpcsLog.Infof(\"Chain verify completed successfully\")\n\n\treturn nil\n}\n\n// handleVerifyChain implements the verifychain command.\nfunc handleVerifyChain(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.VerifyChainCmd)\n\n\tvar checkLevel, checkDepth int32\n\tif c.CheckLevel != nil {\n\t\tcheckLevel = *c.CheckLevel\n\t}\n\tif c.CheckDepth != nil {\n\t\tcheckDepth = *c.CheckDepth\n\t}\n\n\terr := verifyChain(s, checkLevel, checkDepth)\n\treturn err == nil, nil\n}\n\n// handleVerifyMessage implements the verifymessage command.\nfunc handleVerifyMessage(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tc := cmd.(*btcjson.VerifyMessageCmd)\n\n\t// Decode the provided address.\n\tparams := s.cfg.ChainParams\n\taddr, err := btcutil.DecodeAddress(c.Address, params)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\tMessage: \"Invalid address or key: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Only P2PKH addresses are valid for signing.\n\tif _, ok := addr.(*btcutil.AddressPubKeyHash); !ok {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCType,\n\t\t\tMessage: \"Address is not a pay-to-pubkey-hash address\",\n\t\t}\n\t}\n\n\t// Decode base64 signature.\n\tsig, err := base64.StdEncoding.DecodeString(c.Signature)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCParse.Code,\n\t\t\tMessage: \"Malformed base64 encoding: \" + err.Error(),\n\t\t}\n\t}\n\n\t// Validate the signature - this just shows that it was valid at all.\n\t// we will compare it with the key next.\n\tvar buf bytes.Buffer\n\twire.WriteVarString(&buf, 0, messageSignatureHeader)\n\twire.WriteVarString(&buf, 0, c.Message)\n\texpectedMessageHash := chainhash.DoubleHashB(buf.Bytes())\n\tpk, wasCompressed, err := ecdsa.RecoverCompact(sig,\n\t\texpectedMessageHash)\n\tif err != nil {\n\t\t// Mirror Bitcoin Core behavior, which treats error in\n\t\t// RecoverCompact as invalid signature.\n\t\treturn false, nil\n\t}\n\n\t// Reconstruct the pubkey hash.\n\tvar serializedPK []byte\n\tif wasCompressed {\n\t\tserializedPK = pk.SerializeCompressed()\n\t} else {\n\t\tserializedPK = pk.SerializeUncompressed()\n\t}\n\taddress, err := btcutil.NewAddressPubKey(serializedPK, params)\n\tif err != nil {\n\t\t// Again mirror Bitcoin Core behavior, which treats error in public key\n\t\t// reconstruction as invalid signature.\n\t\treturn false, nil\n\t}\n\n\t// Return boolean if addresses match.\n\treturn address.EncodeAddress() == c.Address, nil\n}\n\n// handleVersion implements the version command.\n//\n// NOTE: This is a btcsuite extension ported from github.com/decred/dcrd.\nfunc handleVersion(s *rpcServer, cmd interface{}, closeChan <-chan struct{}) (interface{}, error) {\n\tresult := map[string]btcjson.VersionResult{\n\t\t\"btcdjsonrpcapi\": {\n\t\t\tVersionString: jsonrpcSemverString,\n\t\t\tMajor:         jsonrpcSemverMajor,\n\t\t\tMinor:         jsonrpcSemverMinor,\n\t\t\tPatch:         jsonrpcSemverPatch,\n\t\t},\n\t}\n\treturn result, nil\n}\n\n// handleTestMempoolAccept implements the testmempoolaccept command.\nfunc handleTestMempoolAccept(s *rpcServer, cmd interface{},\n\tcloseChan <-chan struct{}) (interface{}, error) {\n\n\tc := cmd.(*btcjson.TestMempoolAcceptCmd)\n\n\t// Create txns to hold the decoded tx.\n\ttxns := make([]*btcutil.Tx, 0, len(c.RawTxns))\n\n\t// Iterate the raw hex slice and decode them.\n\tfor _, rawTx := range c.RawTxns {\n\t\trawBytes, err := hex.DecodeString(rawTx)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(rawTx)\n\t\t}\n\n\t\ttx, err := btcutil.NewTxFromBytes(rawBytes)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCDeserialization,\n\t\t\t\tMessage: \"TX decode failed: \" + err.Error(),\n\t\t\t}\n\t\t}\n\n\t\ttxns = append(txns, tx)\n\t}\n\n\tresults := make([]*btcjson.TestMempoolAcceptResult, 0, len(txns))\n\tfor _, tx := range txns {\n\t\t// Create a test result item.\n\t\titem := &btcjson.TestMempoolAcceptResult{\n\t\t\tTxid:  tx.Hash().String(),\n\t\t\tWtxid: tx.WitnessHash().String(),\n\t\t}\n\n\t\t// Check the mempool acceptance.\n\t\tresult, err := s.cfg.TxMemPool.CheckMempoolAcceptance(tx)\n\n\t\t// If an error is returned, this tx is not allow, hence we\n\t\t// record the reason.\n\t\tif err != nil {\n\t\t\titem.Allowed = false\n\n\t\t\t// TODO(yy): differentiate the errors and put package\n\t\t\t// error in `PackageError` field.\n\t\t\titem.RejectReason = err.Error()\n\n\t\t\tresults = append(results, item)\n\n\t\t\t// Move to the next transaction.\n\t\t\tcontinue\n\t\t}\n\n\t\t// If this transaction is an orphan, it's not allowed.\n\t\tif result.MissingParents != nil {\n\t\t\titem.Allowed = false\n\n\t\t\t// NOTE: \"missing-inputs\" is what bitcoind returns\n\t\t\t// here, so we mimic the same error message.\n\t\t\titem.RejectReason = \"missing-inputs\"\n\n\t\t\tresults = append(results, item)\n\n\t\t\t// Move to the next transaction.\n\t\t\tcontinue\n\t\t}\n\n\t\t// Otherwise this tx is allowed if its fee rate is below the\n\t\t// max fee rate, we now patch the fields in\n\t\t// `TestMempoolAcceptItem` as much as possible.\n\t\t//\n\t\t// Calculate the fee field and validate its fee rate.\n\t\titem.Fees, item.Allowed = validateFeeRate(\n\t\t\tresult.TxFee, result.TxSize, c.MaxFeeRate,\n\t\t)\n\n\t\t// If the fee rate check passed, assign the corresponding\n\t\t// fields.\n\t\tif item.Allowed {\n\t\t\titem.Vsize = int32(result.TxSize)\n\t\t} else {\n\t\t\t// NOTE: \"max-fee-exceeded\" is what bitcoind returns\n\t\t\t// here, so we mimic the same error message.\n\t\t\titem.RejectReason = \"max-fee-exceeded\"\n\t\t}\n\n\t\tresults = append(results, item)\n\t}\n\n\treturn results, nil\n}\n\n// handleGetTxSpendingPrevOut implements the gettxspendingprevout command.\nfunc handleGetTxSpendingPrevOut(s *rpcServer, cmd interface{},\n\tcloseChan <-chan struct{}) (interface{}, error) {\n\n\tc := cmd.(*btcjson.GetTxSpendingPrevOutCmd)\n\n\t// Convert the outpoints.\n\tops := make([]wire.OutPoint, 0, len(c.Outputs))\n\tfor _, o := range c.Outputs {\n\t\thash, err := chainhash.NewHashFromStr(o.Txid)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tops = append(ops, wire.OutPoint{\n\t\t\tHash:  *hash,\n\t\t\tIndex: o.Vout,\n\t\t})\n\t}\n\n\t// Check mempool spend for all the outpoints.\n\tresults := make([]*btcjson.GetTxSpendingPrevOutResult, 0, len(ops))\n\tfor _, op := range ops {\n\t\t// Create a result entry.\n\t\tresult := &btcjson.GetTxSpendingPrevOutResult{\n\t\t\tTxid: op.Hash.String(),\n\t\t\tVout: op.Index,\n\t\t}\n\n\t\t// Check the mempool spend.\n\t\tspendingTx := s.cfg.TxMemPool.CheckSpend(op)\n\n\t\t// Set the spending txid if found.\n\t\tif spendingTx != nil {\n\t\t\tresult.SpendingTxid = spendingTx.Hash().String()\n\t\t}\n\n\t\tresults = append(results, result)\n\t}\n\n\treturn results, nil\n}\n\n// validateFeeRate checks that the fee rate used by transaction doesn't exceed\n// the max fee rate specified.\nfunc validateFeeRate(feeSats btcutil.Amount, txSize int64,\n\tmaxFeeRate float64) (*btcjson.TestMempoolAcceptFees, bool) {\n\n\t// Calculate fee rate in sats/kvB.\n\tfeeRateSatsPerKVB := feeSats * 1e3 / btcutil.Amount(txSize)\n\n\t// Convert sats/vB to BTC/kvB.\n\tfeeRate := feeRateSatsPerKVB.ToBTC()\n\n\t// Get the max fee rate, if not provided, default to 0.1 BTC/kvB.\n\tif maxFeeRate == 0 {\n\t\tmaxFeeRate = defaultMaxFeeRate\n\t}\n\n\t// If the fee rate is above the max fee rate, this tx is not accepted.\n\tif feeRate > maxFeeRate {\n\t\treturn nil, false\n\t}\n\n\treturn &btcjson.TestMempoolAcceptFees{\n\t\tBase:             feeSats.ToBTC(),\n\t\tEffectiveFeeRate: feeRate,\n\t}, true\n}\n\n// rpcServer provides a concurrent safe RPC server to a chain server.\ntype rpcServer struct {\n\tstarted                int32\n\tshutdown               int32\n\tcfg                    rpcserverConfig\n\tauthsha                [sha256.Size]byte\n\tlimitauthsha           [sha256.Size]byte\n\tntfnMgr                *wsNotificationManager\n\tnumClients             int32\n\tstatusLines            map[int]string\n\tstatusLock             sync.RWMutex\n\twg                     sync.WaitGroup\n\tgbtWorkState           *gbtWorkState\n\thelpCacher             *helpCacher\n\trequestProcessShutdown chan struct{}\n\tquit                   chan int\n}\n\n// httpStatusLine returns a response Status-Line (RFC 2616 Section 6.1)\n// for the given request and response status code.  This function was lifted and\n// adapted from the standard library HTTP server code since it's not exported.\nfunc (s *rpcServer) httpStatusLine(req *http.Request, code int) string {\n\t// Fast path:\n\tkey := code\n\tproto11 := req.ProtoAtLeast(1, 1)\n\tif !proto11 {\n\t\tkey = -key\n\t}\n\ts.statusLock.RLock()\n\tline, ok := s.statusLines[key]\n\ts.statusLock.RUnlock()\n\tif ok {\n\t\treturn line\n\t}\n\n\t// Slow path:\n\tproto := \"HTTP/1.0\"\n\tif proto11 {\n\t\tproto = \"HTTP/1.1\"\n\t}\n\tcodeStr := strconv.Itoa(code)\n\ttext := http.StatusText(code)\n\tif text != \"\" {\n\t\tline = proto + \" \" + codeStr + \" \" + text + \"\\r\\n\"\n\t\ts.statusLock.Lock()\n\t\ts.statusLines[key] = line\n\t\ts.statusLock.Unlock()\n\t} else {\n\t\ttext = \"status code \" + codeStr\n\t\tline = proto + \" \" + codeStr + \" \" + text + \"\\r\\n\"\n\t}\n\n\treturn line\n}\n\n// writeHTTPResponseHeaders writes the necessary response headers prior to\n// writing an HTTP body given a request to use for protocol negotiation, headers\n// to write, a status code, and a writer.\nfunc (s *rpcServer) writeHTTPResponseHeaders(req *http.Request, headers http.Header, code int, w io.Writer) error {\n\t_, err := io.WriteString(w, s.httpStatusLine(req, code))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = headers.Write(w)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.WriteString(w, \"\\r\\n\")\n\treturn err\n}\n\n// Stop is used by server.go to stop the rpc listener.\nfunc (s *rpcServer) Stop() error {\n\tif atomic.AddInt32(&s.shutdown, 1) != 1 {\n\t\trpcsLog.Infof(\"RPC server is already in the process of shutting down\")\n\t\treturn nil\n\t}\n\trpcsLog.Warnf(\"RPC server shutting down\")\n\tfor _, listener := range s.cfg.Listeners {\n\t\terr := listener.Close()\n\t\tif err != nil {\n\t\t\trpcsLog.Errorf(\"Problem shutting down rpc: %v\", err)\n\t\t\treturn err\n\t\t}\n\t}\n\ts.ntfnMgr.Shutdown()\n\ts.ntfnMgr.WaitForShutdown()\n\tclose(s.quit)\n\ts.wg.Wait()\n\trpcsLog.Infof(\"RPC server shutdown complete\")\n\treturn nil\n}\n\n// RequestedProcessShutdown returns a channel that is sent to when an authorized\n// RPC client requests the process to shutdown.  If the request can not be read\n// immediately, it is dropped.\nfunc (s *rpcServer) RequestedProcessShutdown() <-chan struct{} {\n\treturn s.requestProcessShutdown\n}\n\n// NotifyNewTransactions notifies both websocket and getblocktemplate long\n// poll clients of the passed transactions.  This function should be called\n// whenever new transactions are added to the mempool.\nfunc (s *rpcServer) NotifyNewTransactions(txns []*mempool.TxDesc) {\n\tfor _, txD := range txns {\n\t\t// Notify websocket clients about mempool transactions.\n\t\ts.ntfnMgr.NotifyMempoolTx(txD.Tx, true)\n\n\t\t// Potentially notify any getblocktemplate long poll clients\n\t\t// about stale block templates due to the new transaction.\n\t\ts.gbtWorkState.NotifyMempoolTx(s.cfg.TxMemPool.LastUpdated())\n\t}\n}\n\n// limitConnections responds with a 503 service unavailable and returns true if\n// adding another client would exceed the maximum allow RPC clients.\n//\n// This function is safe for concurrent access.\nfunc (s *rpcServer) limitConnections(w http.ResponseWriter, remoteAddr string) bool {\n\tif int(atomic.LoadInt32(&s.numClients)+1) > cfg.RPCMaxClients {\n\t\trpcsLog.Infof(\"Max RPC clients exceeded [%d] - \"+\n\t\t\t\"disconnecting client %s\", cfg.RPCMaxClients,\n\t\t\tremoteAddr)\n\t\thttp.Error(w, \"503 Too busy.  Try again later.\",\n\t\t\thttp.StatusServiceUnavailable)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// incrementClients adds one to the number of connected RPC clients.  Note\n// this only applies to standard clients.  Websocket clients have their own\n// limits and are tracked separately.\n//\n// This function is safe for concurrent access.\nfunc (s *rpcServer) incrementClients() {\n\tatomic.AddInt32(&s.numClients, 1)\n}\n\n// decrementClients subtracts one from the number of connected RPC clients.\n// Note this only applies to standard clients.  Websocket clients have their own\n// limits and are tracked separately.\n//\n// This function is safe for concurrent access.\nfunc (s *rpcServer) decrementClients() {\n\tatomic.AddInt32(&s.numClients, -1)\n}\n\n// checkAuth checks the HTTP Basic authentication supplied by a wallet\n// or RPC client in the HTTP request r.  If the supplied authentication\n// does not match the username and password expected, a non-nil error is\n// returned.\n//\n// This check is time-constant.\n//\n// The first bool return value signifies auth success (true if successful) and\n// the second bool return value specifies whether the user can change the state\n// of the server (true) or whether the user is limited (false). The second is\n// always false if the first is.\nfunc (s *rpcServer) checkAuth(r *http.Request, require bool) (bool, bool, error) {\n\tauthhdr := r.Header[\"Authorization\"]\n\tif len(authhdr) <= 0 {\n\t\tif require {\n\t\t\trpcsLog.Warnf(\"RPC authentication failure from %s\",\n\t\t\t\tr.RemoteAddr)\n\t\t\treturn false, false, errors.New(\"auth failure\")\n\t\t}\n\n\t\treturn false, false, nil\n\t}\n\n\tauthsha := sha256.Sum256([]byte(authhdr[0]))\n\n\t// Check for limited auth first as in environments with limited users, those\n\t// are probably expected to have a higher volume of calls\n\tlimitcmp := subtle.ConstantTimeCompare(authsha[:], s.limitauthsha[:])\n\tif limitcmp == 1 {\n\t\treturn true, false, nil\n\t}\n\n\t// Check for admin-level auth\n\tcmp := subtle.ConstantTimeCompare(authsha[:], s.authsha[:])\n\tif cmp == 1 {\n\t\treturn true, true, nil\n\t}\n\n\t// Request's auth doesn't match either user\n\trpcsLog.Warnf(\"RPC authentication failure from %s\", r.RemoteAddr)\n\treturn false, false, errors.New(\"auth failure\")\n}\n\n// parsedRPCCmd represents a JSON-RPC request object that has been parsed into\n// a known concrete command along with any error that might have happened while\n// parsing it.\ntype parsedRPCCmd struct {\n\tjsonrpc btcjson.RPCVersion\n\tid      interface{}\n\tmethod  string\n\tcmd     interface{}\n\terr     *btcjson.RPCError\n}\n\n// standardCmdResult checks that a parsed command is a standard Bitcoin JSON-RPC\n// command and runs the appropriate handler to reply to the command.  Any\n// commands which are not recognized or not implemented will return an error\n// suitable for use in replies.\nfunc (s *rpcServer) standardCmdResult(cmd *parsedRPCCmd, closeChan <-chan struct{}) (interface{}, error) {\n\thandler, ok := rpcHandlers[cmd.method]\n\tif ok {\n\t\tgoto handled\n\t}\n\t_, ok = rpcAskWallet[cmd.method]\n\tif ok {\n\t\thandler = handleAskWallet\n\t\tgoto handled\n\t}\n\t_, ok = rpcUnimplemented[cmd.method]\n\tif ok {\n\t\thandler = handleUnimplemented\n\t\tgoto handled\n\t}\n\treturn nil, btcjson.ErrRPCMethodNotFound\nhandled:\n\n\treturn handler(s, cmd.cmd, closeChan)\n}\n\n// parseCmd parses a JSON-RPC request object into known concrete command.  The\n// err field of the returned parsedRPCCmd struct will contain an RPC error that\n// is suitable for use in replies if the command is invalid in some way such as\n// an unregistered command or invalid parameters.\nfunc parseCmd(request *btcjson.Request) *parsedRPCCmd {\n\tparsedCmd := parsedRPCCmd{\n\t\tjsonrpc: request.Jsonrpc,\n\t\tid:      request.ID,\n\t\tmethod:  request.Method,\n\t}\n\n\tcmd, err := btcjson.UnmarshalCmd(request)\n\tif err != nil {\n\t\t// When the error is because the method is not registered,\n\t\t// produce a method not found RPC error.\n\t\tif jerr, ok := err.(btcjson.Error); ok &&\n\t\t\tjerr.ErrorCode == btcjson.ErrUnregisteredMethod {\n\n\t\t\tparsedCmd.err = btcjson.ErrRPCMethodNotFound\n\t\t\treturn &parsedCmd\n\t\t}\n\n\t\t// Otherwise, some type of invalid parameters is the\n\t\t// cause, so produce the equivalent RPC error.\n\t\tparsedCmd.err = btcjson.NewRPCError(\n\t\t\tbtcjson.ErrRPCInvalidParams.Code, err.Error())\n\t\treturn &parsedCmd\n\t}\n\n\tparsedCmd.cmd = cmd\n\treturn &parsedCmd\n}\n\n// createMarshalledReply returns a new marshalled JSON-RPC response given the\n// passed parameters.  It will automatically convert errors that are not of\n// the type *btcjson.RPCError to the appropriate type as needed.\nfunc createMarshalledReply(rpcVersion btcjson.RPCVersion, id interface{}, result interface{}, replyErr error) ([]byte, error) {\n\tvar jsonErr *btcjson.RPCError\n\tif replyErr != nil {\n\t\tif jErr, ok := replyErr.(*btcjson.RPCError); ok {\n\t\t\tjsonErr = jErr\n\t\t} else {\n\t\t\tjsonErr = internalRPCError(replyErr.Error(), \"\")\n\t\t}\n\t}\n\n\treturn btcjson.MarshalResponse(rpcVersion, id, result, jsonErr)\n}\n\n// processRequest determines the incoming request type (single or batched),\n// parses it and returns a marshalled response.\nfunc (s *rpcServer) processRequest(request *btcjson.Request, isAdmin bool, closeChan <-chan struct{}) []byte {\n\tvar result interface{}\n\tvar err error\n\tvar jsonErr *btcjson.RPCError\n\n\tif !isAdmin {\n\t\tif _, ok := rpcLimited[request.Method]; !ok {\n\t\t\tjsonErr = internalRPCError(\"limited user not \"+\n\t\t\t\t\"authorized for this method\", \"\")\n\t\t}\n\t}\n\n\tif jsonErr == nil {\n\t\tif request.Method == \"\" || request.Params == nil {\n\t\t\tjsonErr = &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\tMessage: \"Invalid request: malformed\",\n\t\t\t}\n\t\t\tmsg, err := createMarshalledReply(request.Jsonrpc, request.ID, result, jsonErr)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn msg\n\t\t}\n\n\t\t// Valid requests with no ID (notifications) must not have a response\n\t\t// per the JSON-RPC spec.\n\t\tif request.ID == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Attempt to parse the JSON-RPC request into a known\n\t\t// concrete command.\n\t\tparsedCmd := parseCmd(request)\n\t\tif parsedCmd.err != nil {\n\t\t\tjsonErr = parsedCmd.err\n\t\t} else {\n\t\t\tresult, err = s.standardCmdResult(parsedCmd,\n\t\t\t\tcloseChan)\n\t\t\tif err != nil {\n\t\t\t\tif rpcErr, ok := err.(*btcjson.RPCError); ok {\n\t\t\t\t\tjsonErr = rpcErr\n\t\t\t\t} else {\n\t\t\t\t\tjsonErr = &btcjson.RPCError{\n\t\t\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\tMessage: \"Invalid request: malformed\",\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Marshal the response.\n\tmsg, err := createMarshalledReply(request.Jsonrpc, request.ID, result, jsonErr)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\treturn nil\n\t}\n\treturn msg\n}\n\n// jsonRPCRead handles reading and responding to RPC messages.\nfunc (s *rpcServer) jsonRPCRead(w http.ResponseWriter, r *http.Request, isAdmin bool) {\n\tif atomic.LoadInt32(&s.shutdown) != 0 {\n\t\treturn\n\t}\n\n\t// Read and close the JSON-RPC request body from the caller.\n\tbody, err := ioutil.ReadAll(r.Body)\n\tr.Body.Close()\n\tif err != nil {\n\t\terrCode := http.StatusBadRequest\n\t\thttp.Error(w, fmt.Sprintf(\"%d error reading JSON message: %v\",\n\t\t\terrCode, err), errCode)\n\t\treturn\n\t}\n\n\t// Unfortunately, the http server doesn't provide the ability to\n\t// change the read deadline for the new connection and having one breaks\n\t// long polling.  However, not having a read deadline on the initial\n\t// connection would mean clients can connect and idle forever.  Thus,\n\t// hijack the connection from the HTTP server, clear the read deadline,\n\t// and handle writing the response manually.\n\thj, ok := w.(http.Hijacker)\n\tif !ok {\n\t\terrMsg := \"webserver doesn't support hijacking\"\n\t\trpcsLog.Warnf(errMsg)\n\t\terrCode := http.StatusInternalServerError\n\t\thttp.Error(w, strconv.Itoa(errCode)+\" \"+errMsg, errCode)\n\t\treturn\n\t}\n\tconn, buf, err := hj.Hijack()\n\tif err != nil {\n\t\trpcsLog.Warnf(\"Failed to hijack HTTP connection: %v\", err)\n\t\terrCode := http.StatusInternalServerError\n\t\thttp.Error(w, strconv.Itoa(errCode)+\" \"+err.Error(), errCode)\n\t\treturn\n\t}\n\tdefer conn.Close()\n\tdefer buf.Flush()\n\tconn.SetReadDeadline(timeZeroVal)\n\n\t// Attempt to parse the raw body into a JSON-RPC request.\n\t// Setup a close notifier.  Since the connection is hijacked,\n\t// the CloseNotifier on the ResponseWriter is not available.\n\tcloseChan := make(chan struct{}, 1)\n\tgo func() {\n\t\t_, err = conn.Read(make([]byte, 1))\n\t\tif err != nil {\n\t\t\tclose(closeChan)\n\t\t}\n\t}()\n\n\tvar results []json.RawMessage\n\tvar batchSize int\n\tvar batchedRequest bool\n\n\t// Determine request type\n\tif bytes.HasPrefix(body, batchedRequestPrefix) {\n\t\tbatchedRequest = true\n\t}\n\n\t// Process a single request\n\tif !batchedRequest {\n\t\tvar req btcjson.Request\n\t\tvar resp json.RawMessage\n\t\terr = json.Unmarshal(body, &req)\n\t\tif err != nil {\n\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCParse.Code,\n\t\t\t\tMessage: fmt.Sprintf(\"Failed to parse request: %v\",\n\t\t\t\t\terr),\n\t\t\t}\n\t\t\tresp, err = btcjson.MarshalResponse(btcjson.RpcVersion1, nil, nil, jsonErr)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\tif err == nil {\n\t\t\t// The JSON-RPC 1.0 spec defines that notifications must have their \"id\"\n\t\t\t// set to null and states that notifications do not have a response.\n\t\t\t//\n\t\t\t// A JSON-RPC 2.0 notification is a request with \"json-rpc\":\"2.0\", and\n\t\t\t// without an \"id\" member. The specification states that notifications\n\t\t\t// must not be responded to. JSON-RPC 2.0 permits the null value as a\n\t\t\t// valid request id, therefore such requests are not notifications.\n\t\t\t//\n\t\t\t// Bitcoin Core serves requests with \"id\":null or even an absent \"id\",\n\t\t\t// and responds to such requests with \"id\":null in the response.\n\t\t\t//\n\t\t\t// Btcd does not respond to any request without and \"id\" or \"id\":null,\n\t\t\t// regardless the indicated JSON-RPC protocol version unless RPC quirks\n\t\t\t// are enabled. With RPC quirks enabled, such requests will be responded\n\t\t\t// to if the request does not indicate JSON-RPC version.\n\t\t\t//\n\t\t\t// RPC quirks can be enabled by the user to avoid compatibility issues\n\t\t\t// with software relying on Core's behavior.\n\t\t\tif req.ID == nil && !(cfg.RPCQuirks && req.Jsonrpc == \"\") {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tresp = s.processRequest(&req, isAdmin, closeChan)\n\t\t}\n\n\t\tif resp != nil {\n\t\t\tresults = append(results, resp)\n\t\t}\n\t}\n\n\t// Process a batched request\n\tif batchedRequest {\n\t\tvar batchedRequests []interface{}\n\t\tvar resp json.RawMessage\n\t\terr = json.Unmarshal(body, &batchedRequests)\n\t\tif err != nil {\n\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCParse.Code,\n\t\t\t\tMessage: fmt.Sprintf(\"Failed to parse request: %v\",\n\t\t\t\t\terr),\n\t\t\t}\n\t\t\tresp, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t}\n\n\t\t\tif resp != nil {\n\t\t\t\tresults = append(results, resp)\n\t\t\t}\n\t\t}\n\n\t\tif err == nil {\n\t\t\t// Response with an empty batch error if the batch size is zero\n\t\t\tif len(batchedRequests) == 0 {\n\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\tMessage: \"Invalid request: empty batch\",\n\t\t\t\t}\n\t\t\t\tresp, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tif resp != nil {\n\t\t\t\t\tresults = append(results, resp)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Process each batch entry individually\n\t\t\tif len(batchedRequests) > 0 {\n\t\t\t\tbatchSize = len(batchedRequests)\n\n\t\t\t\tfor _, entry := range batchedRequests {\n\t\t\t\t\tvar reqBytes []byte\n\t\t\t\t\treqBytes, err = json.Marshal(entry)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\tCode: btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\t\tMessage: fmt.Sprintf(\"Invalid request: %v\",\n\t\t\t\t\t\t\t\terr),\n\t\t\t\t\t\t}\n\t\t\t\t\t\tresp, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif resp != nil {\n\t\t\t\t\t\t\tresults = append(results, resp)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\tvar req btcjson.Request\n\t\t\t\t\terr := json.Unmarshal(reqBytes, &req)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\tCode: btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\t\tMessage: fmt.Sprintf(\"Invalid request: %v\",\n\t\t\t\t\t\t\t\terr),\n\t\t\t\t\t\t}\n\t\t\t\t\t\tresp, err = btcjson.MarshalResponse(\"\", nil, nil, jsonErr)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif resp != nil {\n\t\t\t\t\t\t\tresults = append(results, resp)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\tresp = s.processRequest(&req, isAdmin, closeChan)\n\t\t\t\t\tif resp != nil {\n\t\t\t\t\t\tresults = append(results, resp)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tvar msg = []byte{}\n\tif batchedRequest && batchSize > 0 {\n\t\tif len(results) > 0 {\n\t\t\t// Form the batched response json\n\t\t\tvar buffer bytes.Buffer\n\t\t\tbuffer.WriteByte('[')\n\t\t\tfor idx, reply := range results {\n\t\t\t\tif idx == len(results)-1 {\n\t\t\t\t\tbuffer.Write(reply)\n\t\t\t\t\tbuffer.WriteByte(']')\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tbuffer.Write(reply)\n\t\t\t\tbuffer.WriteByte(',')\n\t\t\t}\n\t\t\tmsg = buffer.Bytes()\n\t\t}\n\t}\n\n\tif !batchedRequest || batchSize == 0 {\n\t\t// Respond with the first results entry for single requests\n\t\tif len(results) > 0 {\n\t\t\tmsg = results[0]\n\t\t}\n\t}\n\n\t// Write the response.\n\terr = s.writeHTTPResponseHeaders(r, w.Header(), http.StatusOK, buf)\n\tif err != nil {\n\t\trpcsLog.Error(err)\n\t\treturn\n\t}\n\tif _, err := buf.Write(msg); err != nil {\n\t\trpcsLog.Errorf(\"Failed to write marshalled reply: %v\", err)\n\t}\n\n\t// Terminate with newline to maintain compatibility with Bitcoin Core.\n\tif err := buf.WriteByte('\\n'); err != nil {\n\t\trpcsLog.Errorf(\"Failed to append terminating newline to reply: %v\", err)\n\t}\n}\n\n// jsonAuthFail sends a message back to the client if the http auth is rejected.\nfunc jsonAuthFail(w http.ResponseWriter) {\n\tw.Header().Add(\"WWW-Authenticate\", `Basic realm=\"btcd RPC\"`)\n\thttp.Error(w, \"401 Unauthorized.\", http.StatusUnauthorized)\n}\n\n// Start is used by server.go to start the rpc listener.\nfunc (s *rpcServer) Start() {\n\tif atomic.AddInt32(&s.started, 1) != 1 {\n\t\treturn\n\t}\n\n\trpcsLog.Trace(\"Starting RPC server\")\n\trpcServeMux := http.NewServeMux()\n\thttpServer := &http.Server{\n\t\tHandler: rpcServeMux,\n\n\t\t// Timeout connections which don't complete the initial\n\t\t// handshake within the allowed timeframe.\n\t\tReadTimeout: time.Second * rpcAuthTimeoutSeconds,\n\t}\n\trpcServeMux.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Connection\", \"close\")\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tr.Close = true\n\n\t\t// Limit the number of connections to max allowed.\n\t\tif s.limitConnections(w, r.RemoteAddr) {\n\t\t\treturn\n\t\t}\n\n\t\t// Keep track of the number of connected clients.\n\t\ts.incrementClients()\n\t\tdefer s.decrementClients()\n\t\t_, isAdmin, err := s.checkAuth(r, true)\n\t\tif err != nil {\n\t\t\tjsonAuthFail(w)\n\t\t\treturn\n\t\t}\n\n\t\t// Read and respond to the request.\n\t\ts.jsonRPCRead(w, r, isAdmin)\n\t})\n\n\t// Websocket endpoint.\n\trpcServeMux.HandleFunc(\"/ws\", func(w http.ResponseWriter, r *http.Request) {\n\t\tauthenticated, isAdmin, err := s.checkAuth(r, false)\n\t\tif err != nil {\n\t\t\tjsonAuthFail(w)\n\t\t\treturn\n\t\t}\n\n\t\t// Attempt to upgrade the connection to a websocket connection\n\t\t// using the default size for read/write buffers.\n\t\tws, err := websocket.Upgrade(w, r, nil, 0, 0)\n\t\tif err != nil {\n\t\t\tif _, ok := err.(websocket.HandshakeError); !ok {\n\t\t\t\trpcsLog.Errorf(\"Unexpected websocket error: %v\",\n\t\t\t\t\terr)\n\t\t\t}\n\t\t\thttp.Error(w, \"400 Bad Request.\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\ts.WebsocketHandler(ws, r.RemoteAddr, authenticated, isAdmin)\n\t})\n\n\tfor _, listener := range s.cfg.Listeners {\n\t\ts.wg.Add(1)\n\t\tgo func(listener net.Listener) {\n\t\t\trpcsLog.Infof(\"RPC server listening on %s\", listener.Addr())\n\t\t\thttpServer.Serve(listener)\n\t\t\trpcsLog.Tracef(\"RPC listener done for %s\", listener.Addr())\n\t\t\ts.wg.Done()\n\t\t}(listener)\n\t}\n\n\ts.ntfnMgr.Start()\n}\n\n// genCertPair generates a key/cert pair to the paths provided.\nfunc genCertPair(certFile, keyFile string) error {\n\trpcsLog.Infof(\"Generating TLS certificates...\")\n\n\torg := \"btcd autogenerated cert\"\n\tvalidUntil := time.Now().Add(10 * 365 * 24 * time.Hour)\n\tcert, key, err := btcutil.NewTLSCertPair(org, validUntil, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Write cert and key files.\n\tif err = os.WriteFile(certFile, cert, 0666); err != nil {\n\t\treturn err\n\t}\n\tif err = os.WriteFile(keyFile, key, 0600); err != nil {\n\t\tos.Remove(certFile)\n\t\treturn err\n\t}\n\n\trpcsLog.Infof(\"Done generating TLS certificates\")\n\treturn nil\n}\n\n// rpcserverPeer represents a peer for use with the RPC server.\n//\n// The interface contract requires that all of these methods are safe for\n// concurrent access.\ntype rpcserverPeer interface {\n\t// ToPeer returns the underlying peer instance.\n\tToPeer() *peer.Peer\n\n\t// IsTxRelayDisabled returns whether or not the peer has disabled\n\t// transaction relay.\n\tIsTxRelayDisabled() bool\n\n\t// BanScore returns the current integer value that represents how close\n\t// the peer is to being banned.\n\tBanScore() uint32\n\n\t// FeeFilter returns the requested current minimum fee rate for which\n\t// transactions should be announced.\n\tFeeFilter() int64\n}\n\n// rpcserverConnManager represents a connection manager for use with the RPC\n// server.\n//\n// The interface contract requires that all of these methods are safe for\n// concurrent access.\ntype rpcserverConnManager interface {\n\t// Connect adds the provided address as a new outbound peer.  The\n\t// permanent flag indicates whether or not to make the peer persistent\n\t// and reconnect if the connection is lost.  Attempting to connect to an\n\t// already existing peer will return an error.\n\tConnect(addr string, permanent bool) error\n\n\t// RemoveByID removes the peer associated with the provided id from the\n\t// list of persistent peers.  Attempting to remove an id that does not\n\t// exist will return an error.\n\tRemoveByID(id int32) error\n\n\t// RemoveByAddr removes the peer associated with the provided address\n\t// from the list of persistent peers.  Attempting to remove an address\n\t// that does not exist will return an error.\n\tRemoveByAddr(addr string) error\n\n\t// DisconnectByID disconnects the peer associated with the provided id.\n\t// This applies to both inbound and outbound peers.  Attempting to\n\t// remove an id that does not exist will return an error.\n\tDisconnectByID(id int32) error\n\n\t// DisconnectByAddr disconnects the peer associated with the provided\n\t// address.  This applies to both inbound and outbound peers.\n\t// Attempting to remove an address that does not exist will return an\n\t// error.\n\tDisconnectByAddr(addr string) error\n\n\t// ConnectedCount returns the number of currently connected peers.\n\tConnectedCount() int32\n\n\t// NetTotals returns the sum of all bytes received and sent across the\n\t// network for all peers.\n\tNetTotals() (uint64, uint64)\n\n\t// ConnectedPeers returns an array consisting of all connected peers.\n\tConnectedPeers() []rpcserverPeer\n\n\t// PersistentPeers returns an array consisting of all the persistent\n\t// peers.\n\tPersistentPeers() []rpcserverPeer\n\n\t// BroadcastMessage sends the provided message to all currently\n\t// connected peers.\n\tBroadcastMessage(msg wire.Message)\n\n\t// AddRebroadcastInventory adds the provided inventory to the list of\n\t// inventories to be rebroadcast at random intervals until they show up\n\t// in a block.\n\tAddRebroadcastInventory(iv *wire.InvVect, data interface{})\n\n\t// RelayTransactions generates and relays inventory vectors for all of\n\t// the passed transactions to all connected peers.\n\tRelayTransactions(txns []*mempool.TxDesc)\n\n\t// NodeAddresses returns an array consisting node addresses which can\n\t// potentially be used to find new nodes in the network.\n\tNodeAddresses() []*wire.NetAddressV2\n}\n\n// rpcserverSyncManager represents a sync manager for use with the RPC server.\n//\n// The interface contract requires that all of these methods are safe for\n// concurrent access.\ntype rpcserverSyncManager interface {\n\t// IsCurrent returns whether or not the sync manager believes the chain\n\t// is current as compared to the rest of the network.\n\tIsCurrent() bool\n\n\t// SubmitBlock submits the provided block to the network after\n\t// processing it locally.\n\tSubmitBlock(block *btcutil.Block, flags blockchain.BehaviorFlags) (bool, error)\n\n\t// Pause pauses the sync manager until the returned channel is closed.\n\tPause() chan<- struct{}\n\n\t// SyncPeerID returns the ID of the peer that is currently the peer being\n\t// used to sync from or 0 if there is none.\n\tSyncPeerID() int32\n\n\t// LocateHeaders returns the headers of the blocks after the first known\n\t// block in the provided locators until the provided stop hash or the\n\t// current tip is reached, up to a max of wire.MaxBlockHeadersPerMsg\n\t// hashes.\n\tLocateHeaders(locators []*chainhash.Hash, hashStop *chainhash.Hash) []wire.BlockHeader\n}\n\n// rpcserverConfig is a descriptor containing the RPC server configuration.\ntype rpcserverConfig struct {\n\t// Listeners defines a slice of listeners for which the RPC server will\n\t// take ownership of and accept connections.  Since the RPC server takes\n\t// ownership of these listeners, they will be closed when the RPC server\n\t// is stopped.\n\tListeners []net.Listener\n\n\t// StartupTime is the unix timestamp for when the server that is hosting\n\t// the RPC server started.\n\tStartupTime int64\n\n\t// ConnMgr defines the connection manager for the RPC server to use.  It\n\t// provides the RPC server with a means to do things such as add,\n\t// remove, connect, disconnect, and query peers as well as other\n\t// connection-related data and tasks.\n\tConnMgr rpcserverConnManager\n\n\t// SyncMgr defines the sync manager for the RPC server to use.\n\tSyncMgr rpcserverSyncManager\n\n\t// These fields allow the RPC server to interface with the local block\n\t// chain data and state.\n\tTimeSource  blockchain.MedianTimeSource\n\tChain       *blockchain.BlockChain\n\tChainParams *chaincfg.Params\n\tDB          database.DB\n\n\t// TxMemPool defines the transaction memory pool to interact with.\n\tTxMemPool mempool.TxMempool\n\n\t// These fields allow the RPC server to interface with mining.\n\t//\n\t// Generator produces block templates and the CPUMiner solves them using\n\t// the CPU.  CPU mining is typically only useful for test purposes when\n\t// doing regression or simulation testing.\n\tGenerator *mining.BlkTmplGenerator\n\tCPUMiner  *cpuminer.CPUMiner\n\n\t// These fields define any optional indexes the RPC server can make use\n\t// of to provide additional data when queried.\n\tTxIndex   *indexers.TxIndex\n\tAddrIndex *indexers.AddrIndex\n\tCfIndex   *indexers.CfIndex\n\n\t// The fee estimator keeps track of how long transactions are left in\n\t// the mempool before they are mined into blocks.\n\tFeeEstimator *mempool.FeeEstimator\n}\n\n// newRPCServer returns a new instance of the rpcServer struct.\nfunc newRPCServer(config *rpcserverConfig) (*rpcServer, error) {\n\trpc := rpcServer{\n\t\tcfg:                    *config,\n\t\tstatusLines:            make(map[int]string),\n\t\tgbtWorkState:           newGbtWorkState(config.TimeSource),\n\t\thelpCacher:             newHelpCacher(),\n\t\trequestProcessShutdown: make(chan struct{}),\n\t\tquit:                   make(chan int),\n\t}\n\tif cfg.RPCUser != \"\" && cfg.RPCPass != \"\" {\n\t\tlogin := cfg.RPCUser + \":\" + cfg.RPCPass\n\t\tauth := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(login))\n\t\trpc.authsha = sha256.Sum256([]byte(auth))\n\t}\n\tif cfg.RPCLimitUser != \"\" && cfg.RPCLimitPass != \"\" {\n\t\tlogin := cfg.RPCLimitUser + \":\" + cfg.RPCLimitPass\n\t\tauth := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(login))\n\t\trpc.limitauthsha = sha256.Sum256([]byte(auth))\n\t}\n\trpc.ntfnMgr = newWsNotificationManager(&rpc)\n\trpc.cfg.Chain.Subscribe(rpc.handleBlockchainNotification)\n\n\treturn &rpc, nil\n}\n\n// Callback for notifications from blockchain.  It notifies clients that are\n// long polling for changes or subscribed to websockets notifications.\nfunc (s *rpcServer) handleBlockchainNotification(notification *blockchain.Notification) {\n\tswitch notification.Type {\n\tcase blockchain.NTBlockAccepted:\n\t\tblock, ok := notification.Data.(*btcutil.Block)\n\t\tif !ok {\n\t\t\trpcsLog.Warnf(\"Chain accepted notification is not a block.\")\n\t\t\tbreak\n\t\t}\n\n\t\t// Allow any clients performing long polling via the\n\t\t// getblocktemplate RPC to be notified when the new block causes\n\t\t// their old block template to become stale.\n\t\ts.gbtWorkState.NotifyBlockConnected(block.Hash())\n\n\tcase blockchain.NTBlockConnected:\n\t\tblock, ok := notification.Data.(*btcutil.Block)\n\t\tif !ok {\n\t\t\trpcsLog.Warnf(\"Chain connected notification is not a block.\")\n\t\t\tbreak\n\t\t}\n\n\t\t// Notify registered websocket clients of incoming block.\n\t\ts.ntfnMgr.NotifyBlockConnected(block)\n\n\tcase blockchain.NTBlockDisconnected:\n\t\tblock, ok := notification.Data.(*btcutil.Block)\n\t\tif !ok {\n\t\t\trpcsLog.Warnf(\"Chain disconnected notification is not a block.\")\n\t\t\tbreak\n\t\t}\n\n\t\t// Notify registered websocket clients.\n\t\ts.ntfnMgr.NotifyBlockDisconnected(block)\n\t}\n}\n\nfunc init() {\n\trpcHandlers = rpcHandlersBeforeInit\n\trand.Seed(time.Now().UnixNano())\n}\n"
        },
        {
          "name": "rpcserver_test.go",
          "type": "blob",
          "size": 13.6005859375,
          "content": "package main\n\nimport (\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/btcsuite/btcd/btcjson\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/wire\"\n\t\"github.com/stretchr/testify/require\"\n)\n\n// TestHandleTestMempoolAcceptFailDecode checks that when invalid hex string is\n// used as the raw txns, the corresponding error is returned.\nfunc TestHandleTestMempoolAcceptFailDecode(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\t// Create a testing server.\n\ts := &rpcServer{}\n\n\ttestCases := []struct {\n\t\tname            string\n\t\ttxns            []string\n\t\texpectedErrCode btcjson.RPCErrorCode\n\t}{\n\t\t{\n\t\t\tname:            \"hex decode fail\",\n\t\t\ttxns:            []string{\"invalid\"},\n\t\t\texpectedErrCode: btcjson.ErrRPCDecodeHexString,\n\t\t},\n\t\t{\n\t\t\tname:            \"tx decode fail\",\n\t\t\ttxns:            []string{\"696e76616c6964\"},\n\t\t\texpectedErrCode: btcjson.ErrRPCDeserialization,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\t// Create a request that uses invalid raw txns.\n\t\t\tcmd := btcjson.NewTestMempoolAcceptCmd(tc.txns, 0)\n\n\t\t\t// Call the method under test.\n\t\t\tcloseChan := make(chan struct{})\n\t\t\tresult, err := handleTestMempoolAccept(\n\t\t\t\ts, cmd, closeChan,\n\t\t\t)\n\n\t\t\t// Ensure the expected error is returned.\n\t\t\trequire.Error(err)\n\t\t\trpcErr, ok := err.(*btcjson.RPCError)\n\t\t\trequire.True(ok)\n\t\t\trequire.Equal(tc.expectedErrCode, rpcErr.Code)\n\n\t\t\t// No result should be returned.\n\t\t\trequire.Nil(result)\n\t\t})\n\t}\n}\n\nvar (\n\t// TODO(yy): make a `btctest` package and move these testing txns there\n\t// so they be used in other tests.\n\t//\n\t// txHex1 is taken from `txscript/data/tx_valid.json`.\n\ttxHex1 = \"0100000001b14bdcbc3e01bdaad36cc08e81e69c82e1060bc14e518db2b\" +\n\t\t\"49aa43ad90ba26000000000490047304402203f16c6f40162ab686621ef3\" +\n\t\t\"000b04e75418a0c0cb2d8aebeac894ae360ac1e780220ddc15ecdfc3507a\" +\n\t\t\"c48e1681a33eb60996631bf6bf5bc0a0682c4db743ce7ca2b01ffffffff0\" +\n\t\t\"140420f00000000001976a914660d4ef3a743e3e696ad990364e555c271a\" +\n\t\t\"d504b88ac00000000\"\n\n\t// txHex2 is taken from `txscript/data/tx_valid.json`.\n\ttxHex2 = \"0100000001b14bdcbc3e01bdaad36cc08e81e69c82e1060bc14e518db2b\" +\n\t\t\"49aa43ad90ba260000000004a0048304402203f16c6f40162ab686621ef3\" +\n\t\t\"000b04e75418a0c0cb2d8aebeac894ae360ac1e780220ddc15ecdfc3507a\" +\n\t\t\"c48e1681a33eb60996631bf6bf5bc0a0682c4db743ce7ca2bab01fffffff\" +\n\t\t\"f0140420f00000000001976a914660d4ef3a743e3e696ad990364e555c27\" +\n\t\t\"1ad504b88ac00000000\"\n\n\t// txHex3 is taken from `txscript/data/tx_valid.json`.\n\ttxHex3 = \"0100000001b14bdcbc3e01bdaad36cc08e81e69c82e1060bc14e518db2b\" +\n\t\t\"49aa43ad90ba260000000004a01ff47304402203f16c6f40162ab686621e\" +\n\t\t\"f3000b04e75418a0c0cb2d8aebeac894ae360ac1e780220ddc15ecdfc350\" +\n\t\t\"7ac48e1681a33eb60996631bf6bf5bc0a0682c4db743ce7ca2b01fffffff\" +\n\t\t\"f0140420f00000000001976a914660d4ef3a743e3e696ad990364e555c27\" +\n\t\t\"1ad504b88ac00000000\"\n)\n\n// decodeTxHex decodes the given hex string into a transaction.\nfunc decodeTxHex(t *testing.T, txHex string) *btcutil.Tx {\n\trawBytes, err := hex.DecodeString(txHex)\n\trequire.NoError(t, err)\n\ttx, err := btcutil.NewTxFromBytes(rawBytes)\n\trequire.NoError(t, err)\n\n\treturn tx\n}\n\n// TestHandleTestMempoolAcceptMixedResults checks that when different txns get\n// different responses from calling the mempool method `CheckMempoolAcceptance`\n// their results are correctly returned.\nfunc TestHandleTestMempoolAcceptMixedResults(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\t// Create a mock mempool.\n\tmm := &mempool.MockTxMempool{}\n\n\t// Create a testing server with the mock mempool.\n\ts := &rpcServer{cfg: rpcserverConfig{\n\t\tTxMemPool: mm,\n\t}}\n\n\t// Decode the hex so we can assert the mock mempool is called with it.\n\ttx1 := decodeTxHex(t, txHex1)\n\ttx2 := decodeTxHex(t, txHex2)\n\ttx3 := decodeTxHex(t, txHex3)\n\n\t// Create a slice to hold the expected results. We will use three txns\n\t// so we expect threeresults.\n\texpectedResults := make([]*btcjson.TestMempoolAcceptResult, 3)\n\n\t// We now mock the first call to `CheckMempoolAcceptance` to return an\n\t// error.\n\tdummyErr := errors.New(\"dummy error\")\n\tmm.On(\"CheckMempoolAcceptance\", tx1).Return(nil, dummyErr).Once()\n\n\t// Since the call failed, we expect the first result to give us the\n\t// error.\n\texpectedResults[0] = &btcjson.TestMempoolAcceptResult{\n\t\tTxid:         tx1.Hash().String(),\n\t\tWtxid:        tx1.WitnessHash().String(),\n\t\tAllowed:      false,\n\t\tRejectReason: dummyErr.Error(),\n\t}\n\n\t// We mock the second call to `CheckMempoolAcceptance` to return a\n\t// result saying the tx is missing inputs.\n\tmm.On(\"CheckMempoolAcceptance\", tx2).Return(\n\t\t&mempool.MempoolAcceptResult{\n\t\t\tMissingParents: []*chainhash.Hash{},\n\t\t}, nil,\n\t).Once()\n\n\t// We expect the second result to give us the missing-inputs error.\n\texpectedResults[1] = &btcjson.TestMempoolAcceptResult{\n\t\tTxid:         tx2.Hash().String(),\n\t\tWtxid:        tx2.WitnessHash().String(),\n\t\tAllowed:      false,\n\t\tRejectReason: \"missing-inputs\",\n\t}\n\n\t// We mock the third call to `CheckMempoolAcceptance` to return a\n\t// result saying the tx allowed.\n\tconst feeSats = btcutil.Amount(1000)\n\tmm.On(\"CheckMempoolAcceptance\", tx3).Return(\n\t\t&mempool.MempoolAcceptResult{\n\t\t\tTxFee:  feeSats,\n\t\t\tTxSize: 100,\n\t\t}, nil,\n\t).Once()\n\n\t// We expect the third result to give us the fee details.\n\texpectedResults[2] = &btcjson.TestMempoolAcceptResult{\n\t\tTxid:    tx3.Hash().String(),\n\t\tWtxid:   tx3.WitnessHash().String(),\n\t\tAllowed: true,\n\t\tVsize:   100,\n\t\tFees: &btcjson.TestMempoolAcceptFees{\n\t\t\tBase:             feeSats.ToBTC(),\n\t\t\tEffectiveFeeRate: feeSats.ToBTC() * 1e3 / 100,\n\t\t},\n\t}\n\n\t// Create a mock request with default max fee rate of 0.1 BTC/KvB.\n\tcmd := btcjson.NewTestMempoolAcceptCmd(\n\t\t[]string{txHex1, txHex2, txHex3}, 0.1,\n\t)\n\n\t// Call the method handler and assert the expected results are\n\t// returned.\n\tcloseChan := make(chan struct{})\n\tresults, err := handleTestMempoolAccept(s, cmd, closeChan)\n\trequire.NoError(err)\n\trequire.Equal(expectedResults, results)\n\n\t// Assert the mocked method is called as expected.\n\tmm.AssertExpectations(t)\n}\n\n// TestValidateFeeRate checks that `validateFeeRate` behaves as expected.\nfunc TestValidateFeeRate(t *testing.T) {\n\tt.Parallel()\n\n\tconst (\n\t\t// testFeeRate is in BTC/kvB.\n\t\ttestFeeRate = 0.1\n\n\t\t// testTxSize is in vb.\n\t\ttestTxSize = 100\n\n\t\t// testFeeSats is in sats.\n\t\t// We have 0.1BTC/kvB =\n\t\t//   0.1 * 1e8 sats/kvB =\n\t\t//   0.1 * 1e8 / 1e3 sats/vb = 0.1 * 1e5 sats/vb.\n\t\ttestFeeSats = btcutil.Amount(testFeeRate * 1e5 * testTxSize)\n\t)\n\n\ttestCases := []struct {\n\t\tname         string\n\t\tfeeSats      btcutil.Amount\n\t\ttxSize       int64\n\t\tmaxFeeRate   float64\n\t\texpectedFees *btcjson.TestMempoolAcceptFees\n\t\tallowed      bool\n\t}{\n\t\t{\n\t\t\t// When the fee rate(0.1) is above the max fee\n\t\t\t// rate(0.01), we expect a nil result and false.\n\t\t\tname:         \"fee rate above max\",\n\t\t\tfeeSats:      testFeeSats,\n\t\t\ttxSize:       testTxSize,\n\t\t\tmaxFeeRate:   testFeeRate / 10,\n\t\t\texpectedFees: nil,\n\t\t\tallowed:      false,\n\t\t},\n\t\t{\n\t\t\t// When the fee rate(0.1) is no greater than the max\n\t\t\t// fee rate(0.1), we expect a result and true.\n\t\t\tname:       \"fee rate below max\",\n\t\t\tfeeSats:    testFeeSats,\n\t\t\ttxSize:     testTxSize,\n\t\t\tmaxFeeRate: testFeeRate,\n\t\t\texpectedFees: &btcjson.TestMempoolAcceptFees{\n\t\t\t\tBase:             testFeeSats.ToBTC(),\n\t\t\t\tEffectiveFeeRate: testFeeRate,\n\t\t\t},\n\t\t\tallowed: true,\n\t\t},\n\t\t{\n\t\t\t// When the fee rate(1) is above the default max fee\n\t\t\t// rate(0.1), we expect a nil result and false.\n\t\t\tname:         \"fee rate above default max\",\n\t\t\tfeeSats:      testFeeSats,\n\t\t\ttxSize:       testTxSize / 10,\n\t\t\texpectedFees: nil,\n\t\t\tallowed:      false,\n\t\t},\n\t\t{\n\t\t\t// When the fee rate(0.1) is no greater than the\n\t\t\t// default max fee rate(0.1), we expect a result and\n\t\t\t// true.\n\t\t\tname:    \"fee rate below default max\",\n\t\t\tfeeSats: testFeeSats,\n\t\t\ttxSize:  testTxSize,\n\t\t\texpectedFees: &btcjson.TestMempoolAcceptFees{\n\t\t\t\tBase:             testFeeSats.ToBTC(),\n\t\t\t\tEffectiveFeeRate: testFeeRate,\n\t\t\t},\n\t\t\tallowed: true,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\tresult, allowed := validateFeeRate(\n\t\t\t\ttc.feeSats, tc.txSize, tc.maxFeeRate,\n\t\t\t)\n\n\t\t\trequire.Equal(tc.expectedFees, result)\n\t\t\trequire.Equal(tc.allowed, allowed)\n\t\t})\n\t}\n}\n\n// TestHandleTestMempoolAcceptFees checks that the `Fees` field is correctly\n// populated based on the max fee rate and the tx being checked.\nfunc TestHandleTestMempoolAcceptFees(t *testing.T) {\n\tt.Parallel()\n\n\t// Create a mock mempool.\n\tmm := &mempool.MockTxMempool{}\n\n\t// Create a testing server with the mock mempool.\n\ts := &rpcServer{cfg: rpcserverConfig{\n\t\tTxMemPool: mm,\n\t}}\n\n\tconst (\n\t\t// Set transaction's fee rate to be 0.2BTC/kvB.\n\t\tfeeRate = defaultMaxFeeRate * 2\n\n\t\t// txSize is 100vb.\n\t\ttxSize = 100\n\n\t\t// feeSats is 2e6 sats.\n\t\tfeeSats = feeRate * 1e8 * txSize / 1e3\n\t)\n\n\ttestCases := []struct {\n\t\tname         string\n\t\tmaxFeeRate   float64\n\t\ttxHex        string\n\t\trejectReason string\n\t\tallowed      bool\n\t}{\n\t\t{\n\t\t\t// When the fee rate(0.2) used by the tx is below the\n\t\t\t// max fee rate(2) specified, the result should allow\n\t\t\t// it.\n\t\t\tname:       \"below max fee rate\",\n\t\t\tmaxFeeRate: feeRate * 10,\n\t\t\ttxHex:      txHex1,\n\t\t\tallowed:    true,\n\t\t},\n\t\t{\n\t\t\t// When the fee rate(0.2) used by the tx is above the\n\t\t\t// max fee rate(0.02) specified, the result should\n\t\t\t// disallow it.\n\t\t\tname:         \"above max fee rate\",\n\t\t\tmaxFeeRate:   feeRate / 10,\n\t\t\ttxHex:        txHex1,\n\t\t\tallowed:      false,\n\t\t\trejectReason: \"max-fee-exceeded\",\n\t\t},\n\t\t{\n\t\t\t// When the max fee rate is not set, the default\n\t\t\t// 0.1BTC/kvB is used and the fee rate(0.2) used by the\n\t\t\t// tx is above it, the result should disallow it.\n\t\t\tname:         \"above default max fee rate\",\n\t\t\ttxHex:        txHex1,\n\t\t\tallowed:      false,\n\t\t\trejectReason: \"max-fee-exceeded\",\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\t// Decode the hex so we can assert the mock mempool is\n\t\t\t// called with it.\n\t\t\ttx := decodeTxHex(t, txHex1)\n\n\t\t\t// We mock the call to `CheckMempoolAcceptance` to\n\t\t\t// return the result.\n\t\t\tmm.On(\"CheckMempoolAcceptance\", tx).Return(\n\t\t\t\t&mempool.MempoolAcceptResult{\n\t\t\t\t\tTxFee:  feeSats,\n\t\t\t\t\tTxSize: txSize,\n\t\t\t\t}, nil,\n\t\t\t).Once()\n\n\t\t\t// We expect the third result to give us the fee\n\t\t\t// details.\n\t\t\texpected := &btcjson.TestMempoolAcceptResult{\n\t\t\t\tTxid:    tx.Hash().String(),\n\t\t\t\tWtxid:   tx.WitnessHash().String(),\n\t\t\t\tAllowed: tc.allowed,\n\t\t\t}\n\n\t\t\tif tc.allowed {\n\t\t\t\texpected.Vsize = txSize\n\t\t\t\texpected.Fees = &btcjson.TestMempoolAcceptFees{\n\t\t\t\t\tBase:             feeSats / 1e8,\n\t\t\t\t\tEffectiveFeeRate: feeRate,\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\texpected.RejectReason = tc.rejectReason\n\t\t\t}\n\n\t\t\t// Create a mock request with specified max fee rate.\n\t\t\tcmd := btcjson.NewTestMempoolAcceptCmd(\n\t\t\t\t[]string{txHex1}, tc.maxFeeRate,\n\t\t\t)\n\n\t\t\t// Call the method handler and assert the expected\n\t\t\t// result is returned.\n\t\t\tcloseChan := make(chan struct{})\n\t\t\tr, err := handleTestMempoolAccept(s, cmd, closeChan)\n\t\t\trequire.NoError(err)\n\n\t\t\t// Check the interface type.\n\t\t\tresults, ok := r.([]*btcjson.TestMempoolAcceptResult)\n\t\t\trequire.True(ok)\n\n\t\t\t// Expect exactly one result.\n\t\t\trequire.Len(results, 1)\n\n\t\t\t// Check the result is returned as expected.\n\t\t\trequire.Equal(expected, results[0])\n\n\t\t\t// Assert the mocked method is called as expected.\n\t\t\tmm.AssertExpectations(t)\n\t\t})\n\t}\n}\n\n// TestGetTxSpendingPrevOut checks that handleGetTxSpendingPrevOut handles the\n// cmd as expected.\nfunc TestGetTxSpendingPrevOut(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\t// Create a mock mempool.\n\tmm := &mempool.MockTxMempool{}\n\tdefer mm.AssertExpectations(t)\n\n\t// Create a testing server with the mock mempool.\n\ts := &rpcServer{cfg: rpcserverConfig{\n\t\tTxMemPool: mm,\n\t}}\n\n\t// First, check the error case.\n\t//\n\t// Create a request that will cause an error.\n\tcmd := &btcjson.GetTxSpendingPrevOutCmd{\n\t\tOutputs: []*btcjson.GetTxSpendingPrevOutCmdOutput{\n\t\t\t{Txid: \"invalid\"},\n\t\t},\n\t}\n\n\t// Call the method handler and assert the error is returned.\n\tcloseChan := make(chan struct{})\n\tresults, err := handleGetTxSpendingPrevOut(s, cmd, closeChan)\n\trequire.Error(err)\n\trequire.Nil(results)\n\n\t// We now check the normal case. Two outputs will be tested - one found\n\t// in mempool and other not.\n\t//\n\t// Decode the hex so we can assert the mock mempool is called with it.\n\ttx := decodeTxHex(t, txHex1)\n\n\t// Create testing outpoints.\n\topInMempool := wire.OutPoint{Hash: chainhash.Hash{1}, Index: 1}\n\topNotInMempool := wire.OutPoint{Hash: chainhash.Hash{2}, Index: 1}\n\n\t// We only expect to see one output being found as spent in mempool.\n\texpectedResults := []*btcjson.GetTxSpendingPrevOutResult{\n\t\t{\n\t\t\tTxid:         opInMempool.Hash.String(),\n\t\t\tVout:         opInMempool.Index,\n\t\t\tSpendingTxid: tx.Hash().String(),\n\t\t},\n\t\t{\n\t\t\tTxid: opNotInMempool.Hash.String(),\n\t\t\tVout: opNotInMempool.Index,\n\t\t},\n\t}\n\n\t// We mock the first call to `CheckSpend` to return a result saying the\n\t// output is found.\n\tmm.On(\"CheckSpend\", opInMempool).Return(tx).Once()\n\n\t// We mock the second call to `CheckSpend` to return a result saying the\n\t// output is NOT found.\n\tmm.On(\"CheckSpend\", opNotInMempool).Return(nil).Once()\n\n\t// Create a request with the above outputs.\n\tcmd = &btcjson.GetTxSpendingPrevOutCmd{\n\t\tOutputs: []*btcjson.GetTxSpendingPrevOutCmdOutput{\n\t\t\t{\n\t\t\t\tTxid: opInMempool.Hash.String(),\n\t\t\t\tVout: opInMempool.Index,\n\t\t\t},\n\t\t\t{\n\t\t\t\tTxid: opNotInMempool.Hash.String(),\n\t\t\t\tVout: opNotInMempool.Index,\n\t\t\t},\n\t\t},\n\t}\n\n\t// Call the method handler and assert the expected result is returned.\n\tcloseChan = make(chan struct{})\n\tresults, err = handleGetTxSpendingPrevOut(s, cmd, closeChan)\n\trequire.NoError(err)\n\trequire.Equal(expectedResults, results)\n}\n"
        },
        {
          "name": "rpcserverhelp.go",
          "type": "blob",
          "size": 54.1318359375,
          "content": "// Copyright (c) 2015-2017 The btcsuite developers\n// Copyright (c) 2015-2017 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"errors\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/btcsuite/btcd/btcjson\"\n)\n\n// helpDescsEnUS defines the English descriptions used for the help strings.\nvar helpDescsEnUS = map[string]string{\n\t// DebugLevelCmd help.\n\t\"debuglevel--synopsis\": \"Dynamically changes the debug logging level.\\n\" +\n\t\t\"The levelspec can either a debug level or of the form:\\n\" +\n\t\t\"<subsystem>=<level>,<subsystem2>=<level2>,...\\n\" +\n\t\t\"The valid debug levels are trace, debug, info, warn, error, and critical.\\n\" +\n\t\t\"The valid subsystems are AMGR, ADXR, BCDB, BMGR, BTCD, CHAN, DISC, PEER, RPCS, SCRP, SRVR, and TXMP.\\n\" +\n\t\t\"Finally the keyword 'show' will return a list of the available subsystems.\",\n\t\"debuglevel-levelspec\":   \"The debug level(s) to use or the keyword 'show'\",\n\t\"debuglevel--condition0\": \"levelspec!=show\",\n\t\"debuglevel--condition1\": \"levelspec=show\",\n\t\"debuglevel--result0\":    \"The string 'Done.'\",\n\t\"debuglevel--result1\":    \"The list of subsystems\",\n\n\t// AddNodeCmd help.\n\t\"addnode--synopsis\": \"Attempts to add or remove a persistent peer.\",\n\t\"addnode-addr\":      \"IP address and port of the peer to operate on\",\n\t\"addnode-subcmd\":    \"'add' to add a persistent peer, 'remove' to remove a persistent peer, or 'onetry' to try a single connection to a peer\",\n\n\t// NodeCmd help.\n\t\"node--synopsis\":     \"Attempts to add or remove a peer.\",\n\t\"node-subcmd\":        \"'disconnect' to remove all matching non-persistent peers, 'remove' to remove a persistent peer, or 'connect' to connect to a peer\",\n\t\"node-target\":        \"Either the IP address and port of the peer to operate on, or a valid peer ID.\",\n\t\"node-connectsubcmd\": \"'perm' to make the connected peer a permanent one, 'temp' to try a single connect to a peer\",\n\n\t// TransactionInput help.\n\t\"transactioninput-txid\": \"The hash of the input transaction\",\n\t\"transactioninput-vout\": \"The specific output of the input transaction to redeem\",\n\n\t// CreateRawTransactionCmd help.\n\t\"createrawtransaction--synopsis\": \"Returns a new transaction spending the provided inputs and sending to the provided addresses.\\n\" +\n\t\t\"The transaction inputs are not signed in the created transaction.\\n\" +\n\t\t\"The signrawtransaction RPC command provided by wallet must be used to sign the resulting transaction.\",\n\t\"createrawtransaction-inputs\":         \"The inputs to the transaction\",\n\t\"createrawtransaction-amounts\":        \"JSON object with the destination addresses as keys and amounts as values\",\n\t\"createrawtransaction-amounts--key\":   \"address\",\n\t\"createrawtransaction-amounts--value\": \"n.nnn\",\n\t\"createrawtransaction-amounts--desc\":  \"The destination address as the key and the amount in BTC as the value\",\n\t\"createrawtransaction-locktime\":       \"Locktime value; a non-zero value will also locktime-activate the inputs\",\n\t\"createrawtransaction--result0\":       \"Hex-encoded bytes of the serialized transaction\",\n\n\t// ScriptSig help.\n\t\"scriptsig-asm\": \"Disassembly of the script\",\n\t\"scriptsig-hex\": \"Hex-encoded bytes of the script\",\n\n\t// PrevOut help.\n\t\"prevout-addresses\": \"previous output addresses\",\n\t\"prevout-value\":     \"previous output value\",\n\n\t// VinPrevOut help.\n\t\"vinprevout-coinbase\":    \"The hex-encoded bytes of the signature script (coinbase txns only)\",\n\t\"vinprevout-txid\":        \"The hash of the origin transaction (non-coinbase txns only)\",\n\t\"vinprevout-vout\":        \"The index of the output being redeemed from the origin transaction (non-coinbase txns only)\",\n\t\"vinprevout-scriptSig\":   \"The signature script used to redeem the origin transaction as a JSON object (non-coinbase txns only)\",\n\t\"vinprevout-txinwitness\": \"The witness stack of the passed input, encoded as a JSON string array\",\n\t\"vinprevout-prevOut\":     \"Data from the origin transaction output with index vout.\",\n\t\"vinprevout-sequence\":    \"The script sequence number\",\n\n\t// Vin help.\n\t\"vin-coinbase\":    \"The hex-encoded bytes of the signature script (coinbase txns only)\",\n\t\"vin-txid\":        \"The hash of the origin transaction (non-coinbase txns only)\",\n\t\"vin-vout\":        \"The index of the output being redeemed from the origin transaction (non-coinbase txns only)\",\n\t\"vin-scriptSig\":   \"The signature script used to redeem the origin transaction as a JSON object (non-coinbase txns only)\",\n\t\"vin-txinwitness\": \"The witness used to redeem the input encoded as a string array of its items\",\n\t\"vin-sequence\":    \"The script sequence number\",\n\n\t// ScriptPubKeyResult help.\n\t\"scriptpubkeyresult-asm\":       \"Disassembly of the script\",\n\t\"scriptpubkeyresult-hex\":       \"Hex-encoded bytes of the script\",\n\t\"scriptpubkeyresult-reqSigs\":   \"(DEPRECATED) The number of required signatures\",\n\t\"scriptpubkeyresult-type\":      \"The type of the script (e.g. 'pubkeyhash')\",\n\t\"scriptpubkeyresult-address\":   \"The bitcoin address associated with this script (only if a well-defined address exists)\",\n\t\"scriptpubkeyresult-addresses\": \"(DEPRECATED) The bitcoin addresses associated with this script\",\n\n\t// Vout help.\n\t\"vout-value\":        \"The amount in BTC\",\n\t\"vout-n\":            \"The index of this transaction output\",\n\t\"vout-scriptPubKey\": \"The public key script used to pay coins as a JSON object\",\n\n\t// TxRawDecodeResult help.\n\t\"txrawdecoderesult-txid\":     \"The hash of the transaction\",\n\t\"txrawdecoderesult-version\":  \"The transaction version\",\n\t\"txrawdecoderesult-locktime\": \"The transaction lock time\",\n\t\"txrawdecoderesult-vin\":      \"The transaction inputs as JSON objects\",\n\t\"txrawdecoderesult-vout\":     \"The transaction outputs as JSON objects\",\n\n\t// DecodeRawTransactionCmd help.\n\t\"decoderawtransaction--synopsis\": \"Returns a JSON object representing the provided serialized, hex-encoded transaction.\",\n\t\"decoderawtransaction-hextx\":     \"Serialized, hex-encoded transaction\",\n\n\t// DecodeScriptResult help.\n\t\"decodescriptresult-asm\":       \"Disassembly of the script\",\n\t\"decodescriptresult-reqSigs\":   \"(DEPRECATED) The number of required signatures\",\n\t\"decodescriptresult-type\":      \"The type of the script (e.g. 'pubkeyhash')\",\n\t\"decodescriptresult-address\":   \"The bitcoin address associated with this script (only if a well-defined address exists)\",\n\t\"decodescriptresult-addresses\": \"(DEPRECATED) The bitcoin addresses associated with this script\",\n\t\"decodescriptresult-p2sh\":      \"The script hash for use in pay-to-script-hash transactions (only present if the provided redeem script is not already a pay-to-script-hash script)\",\n\n\t// DecodeScriptCmd help.\n\t\"decodescript--synopsis\": \"Returns a JSON object with information about the provided hex-encoded script.\",\n\t\"decodescript-hexscript\": \"Hex-encoded script\",\n\n\t// EstimateFeeCmd help.\n\t\"estimatefee--synopsis\": \"Estimate the fee per kilobyte in satoshis \" +\n\t\t\"required for a transaction to be mined before a certain number of \" +\n\t\t\"blocks have been generated.\",\n\t\"estimatefee-numblocks\": \"The maximum number of blocks which can be \" +\n\t\t\"generated before the transaction is mined.\",\n\t\"estimatefee--result0\": \"Estimated fee per kilobyte in satoshis for a block to \" +\n\t\t\"be mined in the next NumBlocks blocks.\",\n\n\t// GenerateCmd help\n\t\"generate--synopsis\": \"Generates a set number of blocks (simnet or regtest only) and returns a JSON\\n\" +\n\t\t\" array of their hashes.\",\n\t\"generate-numblocks\": \"Number of blocks to generate\",\n\t\"generate--result0\":  \"The hashes, in order, of blocks generated by the call\",\n\n\t// GetAddedNodeInfoResultAddr help.\n\t\"getaddednodeinforesultaddr-address\":   \"The ip address for this DNS entry\",\n\t\"getaddednodeinforesultaddr-connected\": \"The connection 'direction' (inbound/outbound/false)\",\n\n\t// GetAddedNodeInfoResult help.\n\t\"getaddednodeinforesult-addednode\": \"The ip address or domain of the added peer\",\n\t\"getaddednodeinforesult-connected\": \"Whether or not the peer is currently connected\",\n\t\"getaddednodeinforesult-addresses\": \"DNS lookup and connection information about the peer\",\n\n\t// GetAddedNodeInfo help.\n\t\"getaddednodeinfo--synopsis\":   \"Returns information about manually added (persistent) peers.\",\n\t\"getaddednodeinfo-dns\":         \"Specifies whether the returned data is a JSON object including DNS and connection information, or just a list of added peers\",\n\t\"getaddednodeinfo-node\":        \"Only return information about this specific peer instead of all added peers\",\n\t\"getaddednodeinfo--condition0\": \"dns=false\",\n\t\"getaddednodeinfo--condition1\": \"dns=true\",\n\t\"getaddednodeinfo--result0\":    \"List of added peers\",\n\n\t// GetBestBlockResult help.\n\t\"getbestblockresult-hash\":   \"Hex-encoded bytes of the best block hash\",\n\t\"getbestblockresult-height\": \"Height of the best block\",\n\n\t// GetBestBlockCmd help.\n\t\"getbestblock--synopsis\": \"Get block height and hash of best block in the main chain.\",\n\t\"getbestblock--result0\":  \"Get block height and hash of best block in the main chain.\",\n\n\t// GetBestBlockHashCmd help.\n\t\"getbestblockhash--synopsis\": \"Returns the hash of the of the best (most recent) block in the longest block chain.\",\n\t\"getbestblockhash--result0\":  \"The hex-encoded block hash\",\n\n\t// GetBlockCmd help.\n\t\"getblock--synopsis\":   \"Returns information about a block given its hash.\",\n\t\"getblock-hash\":        \"The hash of the block\",\n\t\"getblock-verbosity\":   \"Specifies whether the block data should be returned as a hex-encoded string (0), as parsed data with a slice of TXIDs (1), or as parsed data with parsed transaction data (2) \",\n\t\"getblock--condition0\": \"verbosity=0\",\n\t\"getblock--condition1\": \"verbosity=1\",\n\t\"getblock--result0\":    \"Hex-encoded bytes of the serialized block\",\n\n\t// GetBlockChainInfoCmd help.\n\t\"getblockchaininfo--synopsis\": \"Returns information about the current blockchain state and the status of any active soft-fork deployments.\",\n\n\t// GetBlockChainInfoResult help.\n\t\"getblockchaininforesult-chain\":                \"The name of the chain the daemon is on (testnet, mainnet, etc)\",\n\t\"getblockchaininforesult-blocks\":               \"The number of blocks in the best known chain\",\n\t\"getblockchaininforesult-headers\":              \"The number of headers that we've gathered for in the best known chain\",\n\t\"getblockchaininforesult-bestblockhash\":        \"The block hash for the latest block in the main chain\",\n\t\"getblockchaininforesult-difficulty\":           \"The current chain difficulty\",\n\t\"getblockchaininforesult-mediantime\":           \"The median time from the PoV of the best block in the chain\",\n\t\"getblockchaininforesult-verificationprogress\": \"An estimate for how much of the best chain we've verified\",\n\t\"getblockchaininforesult-pruned\":               \"A bool that indicates if the node is pruned or not\",\n\t\"getblockchaininforesult-pruneheight\":          \"The lowest block retained in the current pruned chain\",\n\t\"getblockchaininforesult-chainwork\":            \"The total cumulative work in the best chain\",\n\t\"getblockchaininforesult-size_on_disk\":         \"The estimated size of the block and undo files on disk\",\n\t\"getblockchaininforesult-initialblockdownload\": \"Estimate of whether this node is in Initial Block Download mode\",\n\t\"getblockchaininforesult-softforks\":            \"The status of the super-majority soft-forks\",\n\t\"getblockchaininforesult-unifiedsoftforks\":     \"The status of the super-majority soft-forks used by bitcoind on or after v0.19.0\",\n\n\t// SoftForkDescription help.\n\t\"softforkdescription-reject\":  \"The current activation status of the softfork\",\n\t\"softforkdescription-version\": \"The block version that signals enforcement of this softfork\",\n\t\"softforkdescription-id\":      \"The string identifier for the soft fork\",\n\t\"-status\":                     \"A bool which indicates if the soft fork is active\",\n\n\t// SoftForks help.\n\t\"softforks-softforks\":             \"The status of the super-majority soft-forks\",\n\t\"softforks-bip9_softforks\":        \"JSON object describing active BIP0009 deployments\",\n\t\"softforks-bip9_softforks--key\":   \"bip9_softforks\",\n\t\"softforks-bip9_softforks--value\": \"An object describing a particular BIP009 deployment\",\n\t\"softforks-bip9_softforks--desc\":  \"The status of any defined BIP0009 soft-fork deployments\",\n\n\t// UnifiedSoftForks help.\n\t\"unifiedsoftforks-softforks\":        \"The status of the super-majority soft-forks used by bitcoind on or after v0.19.0\",\n\t\"unifiedsoftforks-softforks--key\":   \"softforks\",\n\t\"unifiedsoftforks-softforks--value\": \"An object describing an active softfork deployment used by bitcoind on or after v0.19.0\",\n\t\"unifiedsoftforks-softforks--desc\":  \"JSON object describing an active softfork deployment used by bitcoind on or after v0.19.0\",\n\n\t// TxRawResult help.\n\t\"txrawresult-hex\":           \"Hex-encoded transaction\",\n\t\"txrawresult-txid\":          \"The hash of the transaction\",\n\t\"txrawresult-version\":       \"The transaction version\",\n\t\"txrawresult-locktime\":      \"The transaction lock time\",\n\t\"txrawresult-vin\":           \"The transaction inputs as JSON objects\",\n\t\"txrawresult-vout\":          \"The transaction outputs as JSON objects\",\n\t\"txrawresult-blockhash\":     \"Hash of the block the transaction is part of\",\n\t\"txrawresult-confirmations\": \"Number of confirmations of the block\",\n\t\"txrawresult-time\":          \"Transaction time in seconds since 1 Jan 1970 GMT\",\n\t\"txrawresult-blocktime\":     \"Block time in seconds since the 1 Jan 1970 GMT\",\n\t\"txrawresult-size\":          \"The size of the transaction in bytes\",\n\t\"txrawresult-vsize\":         \"The virtual size of the transaction in bytes\",\n\t\"txrawresult-weight\":        \"The transaction's weight (between vsize*4-3 and vsize*4)\",\n\t\"txrawresult-hash\":          \"The wtxid of the transaction\",\n\n\t// SearchRawTransactionsResult help.\n\t\"searchrawtransactionsresult-hex\":           \"Hex-encoded transaction\",\n\t\"searchrawtransactionsresult-txid\":          \"The hash of the transaction\",\n\t\"searchrawtransactionsresult-hash\":          \"The wxtid of the transaction\",\n\t\"searchrawtransactionsresult-version\":       \"The transaction version\",\n\t\"searchrawtransactionsresult-locktime\":      \"The transaction lock time\",\n\t\"searchrawtransactionsresult-vin\":           \"The transaction inputs as JSON objects\",\n\t\"searchrawtransactionsresult-vout\":          \"The transaction outputs as JSON objects\",\n\t\"searchrawtransactionsresult-blockhash\":     \"Hash of the block the transaction is part of\",\n\t\"searchrawtransactionsresult-confirmations\": \"Number of confirmations of the block\",\n\t\"searchrawtransactionsresult-time\":          \"Transaction time in seconds since 1 Jan 1970 GMT\",\n\t\"searchrawtransactionsresult-blocktime\":     \"Block time in seconds since the 1 Jan 1970 GMT\",\n\t\"searchrawtransactionsresult-size\":          \"The size of the transaction in bytes\",\n\t\"searchrawtransactionsresult-vsize\":         \"The virtual size of the transaction in bytes\",\n\t\"searchrawtransactionsresult-weight\":        \"The transaction's weight (between vsize*4-3 and vsize*4)\",\n\n\t// GetBlockVerboseResult help.\n\t\"getblockverboseresult-hash\":              \"The hash of the block (same as provided)\",\n\t\"getblockverboseresult-confirmations\":     \"The number of confirmations\",\n\t\"getblockverboseresult-size\":              \"The size of the block\",\n\t\"getblockverboseresult-height\":            \"The height of the block in the block chain\",\n\t\"getblockverboseresult-version\":           \"The block version\",\n\t\"getblockverboseresult-versionHex\":        \"The block version in hexadecimal\",\n\t\"getblockverboseresult-merkleroot\":        \"Root hash of the merkle tree\",\n\t\"getblockverboseresult-tx\":                \"The transaction hashes (only when verbosity=1)\",\n\t\"getblockverboseresult-rawtx\":             \"The transactions as JSON objects (only when verbosity=2)\",\n\t\"getblockverboseresult-time\":              \"The block time in seconds since 1 Jan 1970 GMT\",\n\t\"getblockverboseresult-nonce\":             \"The block nonce\",\n\t\"getblockverboseresult-bits\":              \"The bits which represent the block difficulty\",\n\t\"getblockverboseresult-difficulty\":        \"The proof-of-work difficulty as a multiple of the minimum difficulty\",\n\t\"getblockverboseresult-previousblockhash\": \"The hash of the previous block\",\n\t\"getblockverboseresult-nextblockhash\":     \"The hash of the next block (only if there is one)\",\n\t\"getblockverboseresult-strippedsize\":      \"The size of the block without witness data\",\n\t\"getblockverboseresult-weight\":            \"The weight of the block\",\n\n\t// GetBlockCountCmd help.\n\t\"getblockcount--synopsis\": \"Returns the number of blocks in the longest block chain.\",\n\t\"getblockcount--result0\":  \"The current block count\",\n\n\t// GetBlockHashCmd help.\n\t\"getblockhash--synopsis\": \"Returns hash of the block in best block chain at the given height.\",\n\t\"getblockhash-index\":     \"The block height\",\n\t\"getblockhash--result0\":  \"The block hash\",\n\n\t// GetBlockHeaderCmd help.\n\t\"getblockheader--synopsis\":   \"Returns information about a block header given its hash.\",\n\t\"getblockheader-hash\":        \"The hash of the block\",\n\t\"getblockheader-verbose\":     \"Specifies the block header is returned as a JSON object instead of hex-encoded string\",\n\t\"getblockheader--condition0\": \"verbose=false\",\n\t\"getblockheader--condition1\": \"verbose=true\",\n\t\"getblockheader--result0\":    \"The block header hash\",\n\n\t// GetBlockHeaderVerboseResult help.\n\t\"getblockheaderverboseresult-hash\":              \"The hash of the block (same as provided)\",\n\t\"getblockheaderverboseresult-confirmations\":     \"The number of confirmations\",\n\t\"getblockheaderverboseresult-height\":            \"The height of the block in the block chain\",\n\t\"getblockheaderverboseresult-version\":           \"The block version\",\n\t\"getblockheaderverboseresult-versionHex\":        \"The block version in hexadecimal\",\n\t\"getblockheaderverboseresult-merkleroot\":        \"Root hash of the merkle tree\",\n\t\"getblockheaderverboseresult-time\":              \"The block time in seconds since 1 Jan 1970 GMT\",\n\t\"getblockheaderverboseresult-nonce\":             \"The block nonce\",\n\t\"getblockheaderverboseresult-bits\":              \"The bits which represent the block difficulty\",\n\t\"getblockheaderverboseresult-difficulty\":        \"The proof-of-work difficulty as a multiple of the minimum difficulty\",\n\t\"getblockheaderverboseresult-previousblockhash\": \"The hash of the previous block\",\n\t\"getblockheaderverboseresult-nextblockhash\":     \"The hash of the next block (only if there is one)\",\n\n\t// TemplateRequest help.\n\t\"templaterequest-mode\":         \"This is 'template', 'proposal', or omitted\",\n\t\"templaterequest-capabilities\": \"List of capabilities\",\n\t\"templaterequest-longpollid\":   \"The long poll ID of a job to monitor for expiration; required and valid only for long poll requests \",\n\t\"templaterequest-sigoplimit\":   \"Number of signature operations allowed in blocks (this parameter is ignored)\",\n\t\"templaterequest-sizelimit\":    \"Number of bytes allowed in blocks (this parameter is ignored)\",\n\t\"templaterequest-maxversion\":   \"Highest supported block version number (this parameter is ignored)\",\n\t\"templaterequest-target\":       \"The desired target for the block template (this parameter is ignored)\",\n\t\"templaterequest-data\":         \"Hex-encoded block data (only for mode=proposal)\",\n\t\"templaterequest-workid\":       \"The server provided workid if provided in block template (not applicable)\",\n\t\"templaterequest-rules\":        \"Specific block rules that are to be enforced e.g. '[\\\"segwit\\\"]\",\n\n\t// GetBlockTemplateResultTx help.\n\t\"getblocktemplateresulttx-data\":    \"Hex-encoded transaction data (byte-for-byte)\",\n\t\"getblocktemplateresulttx-hash\":    \"Hex-encoded transaction hash (little endian if treated as a 256-bit number)\",\n\t\"getblocktemplateresulttx-depends\": \"Other transactions before this one (by 1-based index in the 'transactions'  list) that must be present in the final block if this one is\",\n\t\"getblocktemplateresulttx-fee\":     \"Difference in value between transaction inputs and outputs (in Satoshi)\",\n\t\"getblocktemplateresulttx-sigops\":  \"Total number of signature operations as counted for purposes of block limits\",\n\t\"getblocktemplateresulttx-txid\":    \"The transaction id, can be different from hash.\",\n\t\"getblocktemplateresulttx-weight\":  \"The weight of the transaction\",\n\n\t// GetBlockTemplateResultAux help.\n\t\"getblocktemplateresultaux-flags\": \"Hex-encoded byte-for-byte data to include in the coinbase signature script\",\n\n\t// GetBlockTemplateResult help.\n\t\"getblocktemplateresult-bits\":                       \"Hex-encoded compressed difficulty\",\n\t\"getblocktemplateresult-curtime\":                    \"Current time as seen by the server (recommended for block time); must fall within mintime/maxtime rules\",\n\t\"getblocktemplateresult-height\":                     \"Height of the block to be solved\",\n\t\"getblocktemplateresult-previousblockhash\":          \"Hex-encoded big-endian hash of the previous block\",\n\t\"getblocktemplateresult-sigoplimit\":                 \"Number of sigops allowed in blocks \",\n\t\"getblocktemplateresult-sizelimit\":                  \"Number of bytes allowed in blocks\",\n\t\"getblocktemplateresult-transactions\":               \"Array of transactions as JSON objects\",\n\t\"getblocktemplateresult-version\":                    \"The block version\",\n\t\"getblocktemplateresult-coinbaseaux\":                \"Data that should be included in the coinbase signature script\",\n\t\"getblocktemplateresult-coinbasetxn\":                \"Information about the coinbase transaction\",\n\t\"getblocktemplateresult-coinbasevalue\":              \"Total amount available for the coinbase in Satoshi\",\n\t\"getblocktemplateresult-workid\":                     \"This value must be returned with result if provided (not provided)\",\n\t\"getblocktemplateresult-longpollid\":                 \"Identifier for long poll request which allows monitoring for expiration\",\n\t\"getblocktemplateresult-longpolluri\":                \"An alternate URI to use for long poll requests if provided (not provided)\",\n\t\"getblocktemplateresult-submitold\":                  \"Not applicable\",\n\t\"getblocktemplateresult-target\":                     \"Hex-encoded big-endian number which valid results must be less than\",\n\t\"getblocktemplateresult-expires\":                    \"Maximum number of seconds (starting from when the server sent the response) this work is valid for\",\n\t\"getblocktemplateresult-maxtime\":                    \"Maximum allowed time\",\n\t\"getblocktemplateresult-mintime\":                    \"Minimum allowed time\",\n\t\"getblocktemplateresult-mutable\":                    \"List of mutations the server explicitly allows\",\n\t\"getblocktemplateresult-noncerange\":                 \"Two concatenated hex-encoded big-endian 32-bit integers which represent the valid ranges of nonces the miner may scan\",\n\t\"getblocktemplateresult-capabilities\":               \"List of server capabilities including 'proposal' to indicate support for block proposals\",\n\t\"getblocktemplateresult-reject-reason\":              \"Reason the proposal was invalid as-is (only applies to proposal responses)\",\n\t\"getblocktemplateresult-default_witness_commitment\": \"The witness commitment itself. Will be populated if the block has witness data\",\n\t\"getblocktemplateresult-weightlimit\":                \"The current limit on the max allowed weight of a block\",\n\n\t// GetBlockTemplateCmd help.\n\t\"getblocktemplate--synopsis\": \"Returns a JSON object with information necessary to construct a block to mine or accepts a proposal to validate.\\n\" +\n\t\t\"See BIP0022 and BIP0023 for the full specification.\",\n\t\"getblocktemplate-request\":     \"Request object which controls the mode and several parameters\",\n\t\"getblocktemplate--condition0\": \"mode=template\",\n\t\"getblocktemplate--condition1\": \"mode=proposal, rejected\",\n\t\"getblocktemplate--condition2\": \"mode=proposal, accepted\",\n\t\"getblocktemplate--result1\":    \"An error string which represents why the proposal was rejected or nothing if accepted\",\n\n\t// GetChainTipsResult help.\n\t\"getchaintipsresult-chaintips\": \"The chaintips that this node is aware of\",\n\t\"getchaintipsresult-height\":    \"The height of the chain tip\",\n\t\"getchaintipsresult-hash\":      \"The block hash of the chain tip\",\n\t\"getchaintipsresult-branchlen\": \"Returns zero for main chain. Otherwise is the length of branch connecting the tip to the main chain\",\n\t\"getchaintipsresult-status\":    \"Status of the chain. Returns \\\"active\\\" for the main chain\",\n\t// GetChainTipsCmd help.\n\t\"getchaintips--synopsis\": \"Returns information about all known tips in the block tree, including the main chain as well as orphaned branches.\",\n\n\t// GetCFilterCmd help.\n\t\"getcfilter--synopsis\":  \"Returns a block's committed filter given its hash.\",\n\t\"getcfilter-filtertype\": \"The type of filter to return (0=regular)\",\n\t\"getcfilter-hash\":       \"The hash of the block\",\n\t\"getcfilter--result0\":   \"The block's committed filter\",\n\n\t// GetCFilterHeaderCmd help.\n\t\"getcfilterheader--synopsis\":  \"Returns a block's compact filter header given its hash.\",\n\t\"getcfilterheader-filtertype\": \"The type of filter header to return (0=regular)\",\n\t\"getcfilterheader-hash\":       \"The hash of the block\",\n\t\"getcfilterheader--result0\":   \"The block's gcs filter header\",\n\n\t// GetConnectionCountCmd help.\n\t\"getconnectioncount--synopsis\": \"Returns the number of active connections to other peers.\",\n\t\"getconnectioncount--result0\":  \"The number of connections\",\n\n\t// GetCurrentNetCmd help.\n\t\"getcurrentnet--synopsis\": \"Get bitcoin network the server is running on.\",\n\t\"getcurrentnet--result0\":  \"The network identifier\",\n\n\t// GetDifficultyCmd help.\n\t\"getdifficulty--synopsis\": \"Returns the proof-of-work difficulty as a multiple of the minimum difficulty.\",\n\t\"getdifficulty--result0\":  \"The difficulty\",\n\n\t// GetGenerateCmd help.\n\t\"getgenerate--synopsis\": \"Returns if the server is set to generate coins (mine) or not.\",\n\t\"getgenerate--result0\":  \"True if mining, false if not\",\n\n\t// GetHashesPerSecCmd help.\n\t\"gethashespersec--synopsis\": \"Returns a recent hashes per second performance measurement while generating coins (mining).\",\n\t\"gethashespersec--result0\":  \"The number of hashes per second\",\n\n\t// InfoChainResult help.\n\t\"infochainresult-version\":         \"The version of the server\",\n\t\"infochainresult-protocolversion\": \"The latest supported protocol version\",\n\t\"infochainresult-blocks\":          \"The number of blocks processed\",\n\t\"infochainresult-timeoffset\":      \"The time offset\",\n\t\"infochainresult-connections\":     \"The number of connected peers\",\n\t\"infochainresult-proxy\":           \"The proxy used by the server\",\n\t\"infochainresult-difficulty\":      \"The current target difficulty\",\n\t\"infochainresult-testnet\":         \"Whether or not server is using testnet\",\n\t\"infochainresult-relayfee\":        \"The minimum relay fee for non-free transactions in BTC/KB\",\n\t\"infochainresult-errors\":          \"Any current errors\",\n\n\t// InfoWalletResult help.\n\t\"infowalletresult-version\":         \"The version of the server\",\n\t\"infowalletresult-protocolversion\": \"The latest supported protocol version\",\n\t\"infowalletresult-walletversion\":   \"The version of the wallet server\",\n\t\"infowalletresult-balance\":         \"The total bitcoin balance of the wallet\",\n\t\"infowalletresult-blocks\":          \"The number of blocks processed\",\n\t\"infowalletresult-timeoffset\":      \"The time offset\",\n\t\"infowalletresult-connections\":     \"The number of connected peers\",\n\t\"infowalletresult-proxy\":           \"The proxy used by the server\",\n\t\"infowalletresult-difficulty\":      \"The current target difficulty\",\n\t\"infowalletresult-testnet\":         \"Whether or not server is using testnet\",\n\t\"infowalletresult-keypoololdest\":   \"Seconds since 1 Jan 1970 GMT of the oldest pre-generated key in the key pool\",\n\t\"infowalletresult-keypoolsize\":     \"The number of new keys that are pre-generated\",\n\t\"infowalletresult-unlocked_until\":  \"The timestamp in seconds since 1 Jan 1970 GMT that the wallet is unlocked for transfers, or 0 if the wallet is locked\",\n\t\"infowalletresult-paytxfee\":        \"The transaction fee set in BTC/KB\",\n\t\"infowalletresult-relayfee\":        \"The minimum relay fee for non-free transactions in BTC/KB\",\n\t\"infowalletresult-errors\":          \"Any current errors\",\n\n\t// GetHeadersCmd help.\n\t\"getheaders--synopsis\":     \"Returns block headers starting with the first known block hash from the request\",\n\t\"getheaders-blocklocators\": \"JSON array of hex-encoded hashes of blocks.  Headers are returned starting from the first known hash in this list\",\n\t\"getheaders-hashstop\":      \"Block hash to stop including block headers for; if not found, all headers to the latest known block are returned.\",\n\t\"getheaders--result0\":      \"Serialized block headers of all located blocks, limited to some arbitrary maximum number of hashes (currently 2000, which matches the wire protocol headers message, but this is not guaranteed)\",\n\n\t// GetInfoCmd help.\n\t\"getinfo--synopsis\": \"Returns a JSON object containing various state info.\",\n\n\t// GetMempoolInfoCmd help.\n\t\"getmempoolinfo--synopsis\": \"Returns memory pool information\",\n\n\t// GetMempoolInfoResult help.\n\t\"getmempoolinforesult-bytes\": \"Size in bytes of the mempool\",\n\t\"getmempoolinforesult-size\":  \"Number of transactions in the mempool\",\n\n\t// GetMiningInfoResult help.\n\t\"getmininginforesult-blocks\":             \"Height of the latest best block\",\n\t\"getmininginforesult-currentblocksize\":   \"Size of the latest best block\",\n\t\"getmininginforesult-currentblockweight\": \"Weight of the latest best block\",\n\t\"getmininginforesult-currentblocktx\":     \"Number of transactions in the latest best block\",\n\t\"getmininginforesult-difficulty\":         \"Current target difficulty\",\n\t\"getmininginforesult-errors\":             \"Any current errors\",\n\t\"getmininginforesult-generate\":           \"Whether or not server is set to generate coins\",\n\t\"getmininginforesult-genproclimit\":       \"Number of processors to use for coin generation (-1 when disabled)\",\n\t\"getmininginforesult-hashespersec\":       \"Recent hashes per second performance measurement while generating coins\",\n\t\"getmininginforesult-networkhashps\":      \"Estimated network hashes per second for the most recent blocks\",\n\t\"getmininginforesult-pooledtx\":           \"Number of transactions in the memory pool\",\n\t\"getmininginforesult-testnet\":            \"Whether or not server is using testnet\",\n\n\t// GetMiningInfoCmd help.\n\t\"getmininginfo--synopsis\": \"Returns a JSON object containing mining-related information.\",\n\n\t// GetNetworkHashPSCmd help.\n\t\"getnetworkhashps--synopsis\": \"Returns the estimated network hashes per second for the block heights provided by the parameters.\",\n\t\"getnetworkhashps-blocks\":    \"The number of blocks, or -1 for blocks since last difficulty change\",\n\t\"getnetworkhashps-height\":    \"Perform estimate ending with this height or -1 for current best chain block height\",\n\t\"getnetworkhashps--result0\":  \"Estimated hashes per second\",\n\n\t// GetNetTotalsCmd help.\n\t\"getnettotals--synopsis\": \"Returns a JSON object containing network traffic statistics.\",\n\n\t// GetNetTotalsResult help.\n\t\"getnettotalsresult-totalbytesrecv\": \"Total bytes received\",\n\t\"getnettotalsresult-totalbytessent\": \"Total bytes sent\",\n\t\"getnettotalsresult-timemillis\":     \"Number of milliseconds since 1 Jan 1970 GMT\",\n\n\t// GetNodeAddressesResult help.\n\t\"getnodeaddressesresult-time\":     \"Timestamp in seconds since epoch (Jan 1 1970 GMT) keeping track of when the node was last seen\",\n\t\"getnodeaddressesresult-services\": \"The services offered\",\n\t\"getnodeaddressesresult-address\":  \"The address of the node\",\n\t\"getnodeaddressesresult-port\":     \"The port of the node\",\n\n\t// GetNodeAddressesCmd help.\n\t\"getnodeaddresses--synopsis\": \"Return known addresses which can potentially be used to find new nodes in the network\",\n\t\"getnodeaddresses-count\":     \"How many addresses to return. Limited to the smaller of 2500 or 23% of all known addresses\",\n\t\"getnodeaddresses--result0\":  \"List of node addresses\",\n\n\t// GetPeerInfoResult help.\n\t\"getpeerinforesult-id\":             \"A unique node ID\",\n\t\"getpeerinforesult-addr\":           \"The ip address and port of the peer\",\n\t\"getpeerinforesult-addrlocal\":      \"Local address\",\n\t\"getpeerinforesult-services\":       \"Services bitmask which represents the services supported by the peer\",\n\t\"getpeerinforesult-relaytxes\":      \"Peer has requested transactions be relayed to it\",\n\t\"getpeerinforesult-lastsend\":       \"Time the last message was received in seconds since 1 Jan 1970 GMT\",\n\t\"getpeerinforesult-lastrecv\":       \"Time the last message was sent in seconds since 1 Jan 1970 GMT\",\n\t\"getpeerinforesult-bytessent\":      \"Total bytes sent\",\n\t\"getpeerinforesult-bytesrecv\":      \"Total bytes received\",\n\t\"getpeerinforesult-conntime\":       \"Time the connection was made in seconds since 1 Jan 1970 GMT\",\n\t\"getpeerinforesult-timeoffset\":     \"The time offset of the peer\",\n\t\"getpeerinforesult-pingtime\":       \"Number of microseconds the last ping took\",\n\t\"getpeerinforesult-pingwait\":       \"Number of microseconds a queued ping has been waiting for a response\",\n\t\"getpeerinforesult-version\":        \"The protocol version of the peer\",\n\t\"getpeerinforesult-subver\":         \"The user agent of the peer\",\n\t\"getpeerinforesult-inbound\":        \"Whether or not the peer is an inbound connection\",\n\t\"getpeerinforesult-startingheight\": \"The latest block height the peer knew about when the connection was established\",\n\t\"getpeerinforesult-currentheight\":  \"The current height of the peer\",\n\t\"getpeerinforesult-banscore\":       \"The ban score\",\n\t\"getpeerinforesult-feefilter\":      \"The requested minimum fee a transaction must have to be announced to the peer\",\n\t\"getpeerinforesult-syncnode\":       \"Whether or not the peer is the sync peer\",\n\n\t// GetPeerInfoCmd help.\n\t\"getpeerinfo--synopsis\": \"Returns data about each connected network peer as an array of json objects.\",\n\n\t// GetRawMempoolVerboseResult help.\n\t\"getrawmempoolverboseresult-size\":             \"Transaction size in bytes\",\n\t\"getrawmempoolverboseresult-fee\":              \"Transaction fee in bitcoins\",\n\t\"getrawmempoolverboseresult-time\":             \"Local time transaction entered pool in seconds since 1 Jan 1970 GMT\",\n\t\"getrawmempoolverboseresult-height\":           \"Block height when transaction entered the pool\",\n\t\"getrawmempoolverboseresult-startingpriority\": \"Priority when transaction entered the pool\",\n\t\"getrawmempoolverboseresult-currentpriority\":  \"Current priority\",\n\t\"getrawmempoolverboseresult-depends\":          \"Unconfirmed transactions used as inputs for this transaction\",\n\t\"getrawmempoolverboseresult-vsize\":            \"The virtual size of a transaction\",\n\t\"getrawmempoolverboseresult-weight\":           \"The transaction's weight (between vsize*4-3 and vsize*4)\",\n\n\t// GetRawMempoolCmd help.\n\t\"getrawmempool--synopsis\":   \"Returns information about all of the transactions currently in the memory pool.\",\n\t\"getrawmempool-verbose\":     \"Returns JSON object when true or an array of transaction hashes when false\",\n\t\"getrawmempool--condition0\": \"verbose=false\",\n\t\"getrawmempool--condition1\": \"verbose=true\",\n\t\"getrawmempool--result0\":    \"Array of transaction hashes\",\n\n\t// GetRawTransactionCmd help.\n\t\"getrawtransaction--synopsis\":   \"Returns information about a transaction given its hash.\",\n\t\"getrawtransaction-txid\":        \"The hash of the transaction\",\n\t\"getrawtransaction-verbose\":     \"Specifies the transaction is returned as a JSON object instead of a hex-encoded string\",\n\t\"getrawtransaction--condition0\": \"verbose=false\",\n\t\"getrawtransaction--condition1\": \"verbose=true\",\n\t\"getrawtransaction--result0\":    \"Hex-encoded bytes of the serialized transaction\",\n\n\t// GetTxOutResult help.\n\t\"gettxoutresult-bestblock\":     \"The block hash that contains the transaction output\",\n\t\"gettxoutresult-confirmations\": \"The number of confirmations\",\n\t\"gettxoutresult-value\":         \"The transaction amount in BTC\",\n\t\"gettxoutresult-scriptPubKey\":  \"The public key script used to pay coins as a JSON object\",\n\t\"gettxoutresult-version\":       \"The transaction version\",\n\t\"gettxoutresult-coinbase\":      \"Whether or not the transaction is a coinbase\",\n\n\t// GetTxOutCmd help.\n\t\"gettxout--synopsis\":      \"Returns information about an unspent transaction output.\",\n\t\"gettxout-txid\":           \"The hash of the transaction\",\n\t\"gettxout-vout\":           \"The index of the output\",\n\t\"gettxout-includemempool\": \"Include the mempool when true\",\n\n\t// InvalidateBlockCmd help.\n\t\"invalidateblock--synopsis\": \"Invalidates the block of the given block hash. To re-validate the invalidated block, use the reconsiderblock rpc\",\n\t\"invalidateblock-blockhash\": \"The block hash of the block to invalidate\",\n\n\t// HelpCmd help.\n\t\"help--synopsis\":   \"Returns a list of all commands or help for a specified command.\",\n\t\"help-command\":     \"The command to retrieve help for\",\n\t\"help--condition0\": \"no command provided\",\n\t\"help--condition1\": \"command specified\",\n\t\"help--result0\":    \"List of commands\",\n\t\"help--result1\":    \"Help for specified command\",\n\n\t// PingCmd help.\n\t\"ping--synopsis\": \"Queues a ping to be sent to each connected peer.\\n\" +\n\t\t\"Ping times are provided by getpeerinfo via the pingtime and pingwait fields.\",\n\n\t// SearchRawTransactionsCmd help.\n\t\"searchrawtransactions--synopsis\": \"Returns raw data for transactions involving the passed address.\\n\" +\n\t\t\"Returned transactions are pulled from both the database, and transactions currently in the mempool.\\n\" +\n\t\t\"Transactions pulled from the mempool will have the 'confirmations' field set to 0.\\n\" +\n\t\t\"Usage of this RPC requires the optional --addrindex flag to be activated, otherwise all responses will simply return with an error stating the address index has not yet been built.\\n\" +\n\t\t\"Similarly, until the address index has caught up with the current best height, all requests will return an error response in order to avoid serving stale data.\",\n\t\"searchrawtransactions-address\":     \"The Bitcoin address to search for\",\n\t\"searchrawtransactions-verbose\":     \"Specifies the transaction is returned as a JSON object instead of hex-encoded string\",\n\t\"searchrawtransactions--condition0\": \"verbose=0\",\n\t\"searchrawtransactions--condition1\": \"verbose=1\",\n\t\"searchrawtransactions-skip\":        \"The number of leading transactions to leave out of the final response\",\n\t\"searchrawtransactions-count\":       \"The maximum number of transactions to return\",\n\t\"searchrawtransactions-vinextra\":    \"Specify that extra data from previous output will be returned in vin\",\n\t\"searchrawtransactions-reverse\":     \"Specifies that the transactions should be returned in reverse chronological order\",\n\t\"searchrawtransactions-filteraddrs\": \"Address list.  Only inputs or outputs with matching address will be returned\",\n\t\"searchrawtransactions--result0\":    \"Hex-encoded serialized transaction\",\n\n\t// SendRawTransactionCmd help.\n\t\"sendrawtransaction--synopsis\":    \"Submits the serialized, hex-encoded transaction to the local peer and relays it to the network.\",\n\t\"sendrawtransaction-hextx\":        \"Serialized, hex-encoded signed transaction\",\n\t\"sendrawtransaction-feesetting\":   \"Whether or not to allow insanely high fees in bitcoind < v0.19.0 or the max fee rate for bitcoind v0.19.0 and later (btcd does not yet implement this parameter, so it has no effect)\",\n\t\"sendrawtransaction--result0\":     \"The hash of the transaction\",\n\t\"allowhighfeesormaxfeerate-value\": \"Either the boolean value for the allowhighfees parameter in bitcoind < v0.19.0 or the numerical value for the maxfeerate field in bitcoind v0.19.0 and later\",\n\n\t// SetGenerateCmd help.\n\t\"setgenerate--synopsis\":    \"Set the server to generate coins (mine) or not.\",\n\t\"setgenerate-generate\":     \"Use true to enable generation, false to disable it\",\n\t\"setgenerate-genproclimit\": \"The number of processors (cores) to limit generation to or -1 for default\",\n\n\t// SignMessageWithPrivKeyCmd help.\n\t\"signmessagewithprivkey--synopsis\": \"Sign a message with the private key of an address\",\n\t\"signmessagewithprivkey-privkey\":   \"The private key to sign the message with\",\n\t\"signmessagewithprivkey-message\":   \"The message to create a signature of\",\n\t\"signmessagewithprivkey--result0\":  \"The signature of the message encoded in base 64\",\n\n\t// StopCmd help.\n\t\"stop--synopsis\": \"Shutdown btcd.\",\n\t\"stop--result0\":  \"The string 'btcd stopping.'\",\n\n\t// SubmitBlockOptions help.\n\t\"submitblockoptions-workid\": \"This parameter is currently ignored\",\n\n\t// SubmitBlockCmd help.\n\t\"submitblock--synopsis\":   \"Attempts to submit a new serialized, hex-encoded block to the network.\",\n\t\"submitblock-hexblock\":    \"Serialized, hex-encoded block\",\n\t\"submitblock-options\":     \"This parameter is currently ignored\",\n\t\"submitblock--condition0\": \"Block successfully submitted\",\n\t\"submitblock--condition1\": \"Block rejected\",\n\t\"submitblock--result1\":    \"The reason the block was rejected\",\n\n\t// ValidateAddressResult help.\n\t\"validateaddresschainresult-isvalid\":         \"Whether or not the address is valid\",\n\t\"validateaddresschainresult-address\":         \"The bitcoin address (only when isvalid is true)\",\n\t\"validateaddresschainresult-isscript\":        \"If the key is a script\",\n\t\"validateaddresschainresult-iswitness\":       \"If the address is a witness address\",\n\t\"validateaddresschainresult-witness_version\": \"The version number of the witness program\",\n\t\"validateaddresschainresult-witness_program\": \"The hex value of the witness program\",\n\n\t// ValidateAddressCmd help.\n\t\"validateaddress--synopsis\": \"Verify an address is valid.\",\n\t\"validateaddress-address\":   \"Bitcoin address to validate\",\n\n\t// VerifyChainCmd help.\n\t\"verifychain--synopsis\": \"Verifies the block chain database.\\n\" +\n\t\t\"The actual checks performed by the checklevel parameter are implementation specific.\\n\" +\n\t\t\"For btcd this is:\\n\" +\n\t\t\"checklevel=0 - Look up each block and ensure it can be loaded from the database.\\n\" +\n\t\t\"checklevel=1 - Perform basic context-free sanity checks on each block.\",\n\t\"verifychain-checklevel\": \"How thorough the block verification is\",\n\t\"verifychain-checkdepth\": \"The number of blocks to check\",\n\t\"verifychain--result0\":   \"Whether or not the chain verified\",\n\n\t// VerifyMessageCmd help.\n\t\"verifymessage--synopsis\": \"Verify a signed message.\",\n\t\"verifymessage-address\":   \"The bitcoin address to use for the signature\",\n\t\"verifymessage-signature\": \"The base-64 encoded signature provided by the signer\",\n\t\"verifymessage-message\":   \"The signed message\",\n\t\"verifymessage--result0\":  \"Whether or not the signature verified\",\n\n\t// -------- Websocket-specific help --------\n\n\t// Session help.\n\t\"session--synopsis\":       \"Return details regarding a websocket client's current connection session.\",\n\t\"sessionresult-sessionid\": \"The unique session ID for a client's websocket connection.\",\n\n\t// NotifyBlocksCmd help.\n\t\"notifyblocks--synopsis\": \"Request notifications for whenever a block is connected or disconnected from the main (best) chain.\",\n\n\t// StopNotifyBlocksCmd help.\n\t\"stopnotifyblocks--synopsis\": \"Cancel registered notifications for whenever a block is connected or disconnected from the main (best) chain.\",\n\n\t// NotifyNewTransactionsCmd help.\n\t\"notifynewtransactions--synopsis\": \"Send either a txaccepted or a txacceptedverbose notification when a new transaction is accepted into the mempool.\",\n\t\"notifynewtransactions-verbose\":   \"Specifies which type of notification to receive. If verbose is true, then the caller receives txacceptedverbose, otherwise the caller receives txaccepted\",\n\n\t// StopNotifyNewTransactionsCmd help.\n\t\"stopnotifynewtransactions--synopsis\": \"Stop sending either a txaccepted or a txacceptedverbose notification when a new transaction is accepted into the mempool.\",\n\n\t// NotifyReceivedCmd help.\n\t\"notifyreceived--synopsis\": \"Send a recvtx notification when a transaction added to mempool or appears in a newly-attached block contains a txout pkScript sending to any of the passed addresses.\\n\" +\n\t\t\"Matching outpoints are automatically registered for redeemingtx notifications.\",\n\t\"notifyreceived-addresses\": \"List of address to receive notifications about\",\n\n\t// StopNotifyReceivedCmd help.\n\t\"stopnotifyreceived--synopsis\": \"Cancel registered receive notifications for each passed address.\",\n\t\"stopnotifyreceived-addresses\": \"List of address to cancel receive notifications for\",\n\n\t// OutPoint help.\n\t\"outpoint-hash\":  \"The hex-encoded bytes of the outpoint hash\",\n\t\"outpoint-index\": \"The index of the outpoint\",\n\n\t// NotifySpentCmd help.\n\t\"notifyspent--synopsis\": \"Send a redeemingtx notification when a transaction spending an outpoint appears in mempool (if relayed to this btcd instance) and when such a transaction first appears in a newly-attached block.\",\n\t\"notifyspent-outpoints\": \"List of transaction outpoints to monitor.\",\n\n\t// StopNotifySpentCmd help.\n\t\"stopnotifyspent--synopsis\": \"Cancel registered spending notifications for each passed outpoint.\",\n\t\"stopnotifyspent-outpoints\": \"List of transaction outpoints to stop monitoring.\",\n\n\t// LoadTxFilterCmd help.\n\t\"loadtxfilter--synopsis\": \"Load, add to, or reload a websocket client's transaction filter for mempool transactions, new blocks and rescanblocks.\",\n\t\"loadtxfilter-reload\":    \"Load a new filter instead of adding data to an existing one\",\n\t\"loadtxfilter-addresses\": \"Array of addresses to add to the transaction filter\",\n\t\"loadtxfilter-outpoints\": \"Array of outpoints to add to the transaction filter\",\n\n\t// ReconsiderBlockCmd help.\n\t\"reconsiderblock--synopsis\": \"Reconsiders the block of the given block hash. Can be used to re-validate blocks invalidated with invalidateblock\",\n\t\"reconsiderblock-blockhash\": \"The block hash of the block to reconsider\",\n\n\t// Rescan help.\n\t\"rescan--synopsis\": \"Rescan block chain for transactions to addresses.\\n\" +\n\t\t\"When the endblock parameter is omitted, the rescan continues through the best block in the main chain.\\n\" +\n\t\t\"Rescan results are sent as recvtx and redeemingtx notifications.\\n\" +\n\t\t\"This call returns once the rescan completes.\",\n\t\"rescan-beginblock\": \"Hash of the first block to begin rescanning\",\n\t\"rescan-addresses\":  \"List of addresses to include in the rescan\",\n\t\"rescan-outpoints\":  \"List of transaction outpoints to include in the rescan\",\n\t\"rescan-endblock\":   \"Hash of final block to rescan\",\n\n\t// RescanBlocks help.\n\t\"rescanblocks--synopsis\":   \"Rescan blocks for transactions matching the loaded transaction filter.\",\n\t\"rescanblocks-blockhashes\": \"List of hashes to rescan.  Each next block must be a child of the previous.\",\n\t\"rescanblocks--result0\":    \"List of matching blocks.\",\n\n\t// RescannedBlock help.\n\t\"rescannedblock-hash\":         \"Hash of the matching block.\",\n\t\"rescannedblock-transactions\": \"List of matching transactions, serialized and hex-encoded.\",\n\n\t// Uptime help.\n\t\"uptime--synopsis\": \"Returns the total uptime of the server.\",\n\t\"uptime--result0\":  \"The number of seconds that the server has been running\",\n\n\t// Version help.\n\t\"version--synopsis\":       \"Returns the JSON-RPC API version (semver)\",\n\t\"version--result0--desc\":  \"Version objects keyed by the program or API name\",\n\t\"version--result0--key\":   \"Program or API name\",\n\t\"version--result0--value\": \"Object containing the semantic version\",\n\n\t// VersionResult help.\n\t\"versionresult-versionstring\": \"The JSON-RPC API version (semver)\",\n\t\"versionresult-major\":         \"The major component of the JSON-RPC API version\",\n\t\"versionresult-minor\":         \"The minor component of the JSON-RPC API version\",\n\t\"versionresult-patch\":         \"The patch component of the JSON-RPC API version\",\n\t\"versionresult-prerelease\":    \"Prerelease info about the current build\",\n\t\"versionresult-buildmetadata\": \"Metadata about the current build\",\n\n\t// TestMempoolAcceptCmd help.\n\t\"testmempoolaccept--synopsis\":  \"Returns result of mempool acceptance tests indicating if raw transaction(s) would be accepted by mempool.\",\n\t\"testmempoolaccept-rawtxns\":    \"Serialized transactions to test.\",\n\t\"testmempoolaccept-maxfeerate\": \"Maximum acceptable fee rate in BTC/kB\",\n\n\t// TestMempoolAcceptCmd result help.\n\t\"testmempoolacceptresult-txid\":             \"The transaction hash in hex.\",\n\t\"testmempoolacceptresult-wtxid\":            \"The transaction witness hash in hex.\",\n\t\"testmempoolacceptresult-package-error\":    \"Package validation error, if any (only possible if rawtxs had more than 1 transaction).\",\n\t\"testmempoolacceptresult-allowed\":          \"Whether the transaction would be accepted to the mempool.\",\n\t\"testmempoolacceptresult-vsize\":            \"Virtual transaction size as defined in BIP 141.(only present when 'allowed' is true)\",\n\t\"testmempoolacceptresult-reject-reason\":    \"Rejection string (only present when 'allowed' is false).\",\n\t\"testmempoolacceptresult-fees\":             \"Transaction fees (only present if 'allowed' is true).\",\n\t\"testmempoolacceptfees-base\":               \"Transaction fees (only present if 'allowed' is true).\",\n\t\"testmempoolacceptfees-effective-feerate\":  \"The effective feerate in BTC per KvB.\",\n\t\"testmempoolacceptfees-effective-includes\": \"Transactions whose fees and vsizes are included in effective-feerate. Each item is a transaction wtxid in hex.\",\n\n\t// GetTxSpendingPrevOutCmd help.\n\t\"gettxspendingprevout--synopsis\": \"Scans the mempool to find transactions spending any of the given outputs\",\n\t\"gettxspendingprevout-outputs\":   \"The transaction outputs that we want to check, and within each, the txid (string) vout (numeric).\",\n\t\"gettxspendingprevout-txid\":      \"The transaction id\",\n\t\"gettxspendingprevout-vout\":      \"The output number\",\n\n\t// GetTxSpendingPrevOutCmd result help.\n\t\"gettxspendingprevoutresult-txid\":         \"The transaction hash in hex.\",\n\t\"gettxspendingprevoutresult-vout\":         \"The output index.\",\n\t\"gettxspendingprevoutresult-spendingtxid\": \"The hash of the transaction that spends the output.\",\n}\n\n// rpcResultTypes specifies the result types that each RPC command can return.\n// This information is used to generate the help.  Each result type must be a\n// pointer to the type (or nil to indicate no return value).\nvar rpcResultTypes = map[string][]interface{}{\n\t\"addnode\":                nil,\n\t\"createrawtransaction\":   {(*string)(nil)},\n\t\"debuglevel\":             {(*string)(nil), (*string)(nil)},\n\t\"decoderawtransaction\":   {(*btcjson.TxRawDecodeResult)(nil)},\n\t\"decodescript\":           {(*btcjson.DecodeScriptResult)(nil)},\n\t\"estimatefee\":            {(*float64)(nil)},\n\t\"generate\":               {(*[]string)(nil)},\n\t\"getaddednodeinfo\":       {(*[]string)(nil), (*[]btcjson.GetAddedNodeInfoResult)(nil)},\n\t\"getbestblock\":           {(*btcjson.GetBestBlockResult)(nil)},\n\t\"getbestblockhash\":       {(*string)(nil)},\n\t\"getblock\":               {(*string)(nil), (*btcjson.GetBlockVerboseResult)(nil)},\n\t\"getblockcount\":          {(*int64)(nil)},\n\t\"getblockhash\":           {(*string)(nil)},\n\t\"getblockheader\":         {(*string)(nil), (*btcjson.GetBlockHeaderVerboseResult)(nil)},\n\t\"getblocktemplate\":       {(*btcjson.GetBlockTemplateResult)(nil), (*string)(nil), nil},\n\t\"getblockchaininfo\":      {(*btcjson.GetBlockChainInfoResult)(nil)},\n\t\"getchaintips\":           {(*[]btcjson.GetChainTipsResult)(nil)},\n\t\"getcfilter\":             {(*string)(nil)},\n\t\"getcfilterheader\":       {(*string)(nil)},\n\t\"getconnectioncount\":     {(*int32)(nil)},\n\t\"getcurrentnet\":          {(*uint32)(nil)},\n\t\"getdifficulty\":          {(*float64)(nil)},\n\t\"getgenerate\":            {(*bool)(nil)},\n\t\"gethashespersec\":        {(*float64)(nil)},\n\t\"getheaders\":             {(*[]string)(nil)},\n\t\"getinfo\":                {(*btcjson.InfoChainResult)(nil)},\n\t\"getmempoolinfo\":         {(*btcjson.GetMempoolInfoResult)(nil)},\n\t\"getmininginfo\":          {(*btcjson.GetMiningInfoResult)(nil)},\n\t\"getnettotals\":           {(*btcjson.GetNetTotalsResult)(nil)},\n\t\"getnetworkhashps\":       {(*float64)(nil)},\n\t\"getnodeaddresses\":       {(*[]btcjson.GetNodeAddressesResult)(nil)},\n\t\"getpeerinfo\":            {(*[]btcjson.GetPeerInfoResult)(nil)},\n\t\"getrawmempool\":          {(*[]string)(nil), (*btcjson.GetRawMempoolVerboseResult)(nil)},\n\t\"getrawtransaction\":      {(*string)(nil), (*btcjson.TxRawResult)(nil)},\n\t\"gettxout\":               {(*btcjson.GetTxOutResult)(nil)},\n\t\"node\":                   nil,\n\t\"help\":                   {(*string)(nil), (*string)(nil)},\n\t\"invalidateblock\":        nil,\n\t\"ping\":                   nil,\n\t\"reconsiderblock\":        nil,\n\t\"searchrawtransactions\":  {(*string)(nil), (*[]btcjson.SearchRawTransactionsResult)(nil)},\n\t\"sendrawtransaction\":     {(*string)(nil)},\n\t\"setgenerate\":            nil,\n\t\"signmessagewithprivkey\": {(*string)(nil)},\n\t\"stop\":                   {(*string)(nil)},\n\t\"submitblock\":            {nil, (*string)(nil)},\n\t\"uptime\":                 {(*int64)(nil)},\n\t\"validateaddress\":        {(*btcjson.ValidateAddressChainResult)(nil)},\n\t\"verifychain\":            {(*bool)(nil)},\n\t\"verifymessage\":          {(*bool)(nil)},\n\t\"version\":                {(*map[string]btcjson.VersionResult)(nil)},\n\t\"testmempoolaccept\":      {(*[]btcjson.TestMempoolAcceptResult)(nil)},\n\t\"gettxspendingprevout\":   {(*[]btcjson.GetTxSpendingPrevOutResult)(nil)},\n\n\t// Websocket commands.\n\t\"loadtxfilter\":              nil,\n\t\"session\":                   {(*btcjson.SessionResult)(nil)},\n\t\"notifyblocks\":              nil,\n\t\"stopnotifyblocks\":          nil,\n\t\"notifynewtransactions\":     nil,\n\t\"stopnotifynewtransactions\": nil,\n\t\"notifyreceived\":            nil,\n\t\"stopnotifyreceived\":        nil,\n\t\"notifyspent\":               nil,\n\t\"stopnotifyspent\":           nil,\n\t\"rescan\":                    nil,\n\t\"rescanblocks\":              {(*[]btcjson.RescannedBlock)(nil)},\n}\n\n// helpCacher provides a concurrent safe type that provides help and usage for\n// the RPC server commands and caches the results for future calls.\ntype helpCacher struct {\n\tsync.Mutex\n\tusage      string\n\tmethodHelp map[string]string\n}\n\n// rpcMethodHelp returns an RPC help string for the provided method.\n//\n// This function is safe for concurrent access.\nfunc (c *helpCacher) rpcMethodHelp(method string) (string, error) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// Return the cached method help if it exists.\n\tif help, exists := c.methodHelp[method]; exists {\n\t\treturn help, nil\n\t}\n\n\t// Look up the result types for the method.\n\tresultTypes, ok := rpcResultTypes[method]\n\tif !ok {\n\t\treturn \"\", errors.New(\"no result types specified for method \" +\n\t\t\tmethod)\n\t}\n\n\t// Generate, cache, and return the help.\n\thelp, err := btcjson.GenerateHelp(method, helpDescsEnUS, resultTypes...)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tc.methodHelp[method] = help\n\treturn help, nil\n}\n\n// rpcUsage returns one-line usage for all support RPC commands.\n//\n// This function is safe for concurrent access.\nfunc (c *helpCacher) rpcUsage(includeWebsockets bool) (string, error) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// Return the cached usage if it is available.\n\tif c.usage != \"\" {\n\t\treturn c.usage, nil\n\t}\n\n\t// Generate a list of one-line usage for every command.\n\tusageTexts := make([]string, 0, len(rpcHandlers))\n\tfor k := range rpcHandlers {\n\t\tusage, err := btcjson.MethodUsageText(k)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tusageTexts = append(usageTexts, usage)\n\t}\n\n\t// Include websockets commands if requested.\n\tif includeWebsockets {\n\t\tfor k := range wsHandlers {\n\t\t\tusage, err := btcjson.MethodUsageText(k)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t\tusageTexts = append(usageTexts, usage)\n\t\t}\n\t}\n\n\tsort.Strings(usageTexts)\n\tc.usage = strings.Join(usageTexts, \"\\n\")\n\treturn c.usage, nil\n}\n\n// newHelpCacher returns a new instance of a help cacher which provides help and\n// usage for the RPC server commands and caches the results for future calls.\nfunc newHelpCacher() *helpCacher {\n\treturn &helpCacher{\n\t\tmethodHelp: make(map[string]string),\n\t}\n}\n"
        },
        {
          "name": "rpcserverhelp_test.go",
          "type": "blob",
          "size": 1.8740234375,
          "content": "// Copyright (c) 2015 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport \"testing\"\n\n// TestHelp ensures the help is reasonably accurate by checking that every\n// command specified also has result types defined and the one-line usage and\n// help text can be generated for them.\nfunc TestHelp(t *testing.T) {\n\t// Ensure there are result types specified for every handler.\n\tfor k := range rpcHandlers {\n\t\tif _, ok := rpcResultTypes[k]; !ok {\n\t\t\tt.Errorf(\"RPC handler defined for method '%v' without \"+\n\t\t\t\t\"also specifying result types\", k)\n\t\t\tcontinue\n\t\t}\n\n\t}\n\tfor k := range wsHandlers {\n\t\tif _, ok := rpcResultTypes[k]; !ok {\n\t\t\tt.Errorf(\"RPC handler defined for method '%v' without \"+\n\t\t\t\t\"also specifying result types\", k)\n\t\t\tcontinue\n\t\t}\n\n\t}\n\n\t// Ensure the usage for every command can be generated without errors.\n\thelpCacher := newHelpCacher()\n\tif _, err := helpCacher.rpcUsage(true); err != nil {\n\t\tt.Fatalf(\"Failed to generate one-line usage: %v\", err)\n\t}\n\tif _, err := helpCacher.rpcUsage(true); err != nil {\n\t\tt.Fatalf(\"Failed to generate one-line usage (cached): %v\", err)\n\t}\n\n\t// Ensure the help for every command can be generated without errors.\n\tfor k := range rpcHandlers {\n\t\tif _, err := helpCacher.rpcMethodHelp(k); err != nil {\n\t\t\tt.Errorf(\"Failed to generate help for method '%v': %v\",\n\t\t\t\tk, err)\n\t\t\tcontinue\n\t\t}\n\t\tif _, err := helpCacher.rpcMethodHelp(k); err != nil {\n\t\t\tt.Errorf(\"Failed to generate help for method '%v'\"+\n\t\t\t\t\"(cached): %v\", k, err)\n\t\t\tcontinue\n\t\t}\n\t}\n\tfor k := range wsHandlers {\n\t\tif _, err := helpCacher.rpcMethodHelp(k); err != nil {\n\t\t\tt.Errorf(\"Failed to generate help for method '%v': %v\",\n\t\t\t\tk, err)\n\t\t\tcontinue\n\t\t}\n\t\tif _, err := helpCacher.rpcMethodHelp(k); err != nil {\n\t\t\tt.Errorf(\"Failed to generate help for method '%v'\"+\n\t\t\t\t\"(cached): %v\", k, err)\n\t\t\tcontinue\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "rpcwebsocket.go",
          "type": "blob",
          "size": 89.2939453125,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Copyright (c) 2015-2017 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"bytes\"\n\t\"container/list\"\n\t\"crypto/sha256\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/btcjson\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/chaincfg\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/database\"\n\t\"github.com/btcsuite/btcd/txscript\"\n\t\"github.com/btcsuite/btcd/wire\"\n\t\"github.com/btcsuite/websocket\"\n\t\"golang.org/x/crypto/ripemd160\"\n)\n\nconst (\n\t// websocketSendBufferSize is the number of elements the send channel\n\t// can queue before blocking.  Note that this only applies to requests\n\t// handled directly in the websocket client input handler or the async\n\t// handler since notifications have their own queuing mechanism\n\t// independent of the send channel buffer.\n\twebsocketSendBufferSize = 50\n)\n\ntype semaphore chan struct{}\n\nfunc makeSemaphore(n int) semaphore {\n\treturn make(chan struct{}, n)\n}\n\nfunc (s semaphore) acquire() { s <- struct{}{} }\nfunc (s semaphore) release() { <-s }\n\n// timeZeroVal is simply the zero value for a time.Time and is used to avoid\n// creating multiple instances.\nvar timeZeroVal time.Time\n\n// wsCommandHandler describes a callback function used to handle a specific\n// command.\ntype wsCommandHandler func(*wsClient, interface{}) (interface{}, error)\n\n// wsHandlers maps RPC command strings to appropriate websocket handler\n// functions.  This is set by init because help references wsHandlers and thus\n// causes a dependency loop.\nvar wsHandlers map[string]wsCommandHandler\nvar wsHandlersBeforeInit = map[string]wsCommandHandler{\n\t\"loadtxfilter\":              handleLoadTxFilter,\n\t\"help\":                      handleWebsocketHelp,\n\t\"notifyblocks\":              handleNotifyBlocks,\n\t\"notifynewtransactions\":     handleNotifyNewTransactions,\n\t\"notifyreceived\":            handleNotifyReceived,\n\t\"notifyspent\":               handleNotifySpent,\n\t\"session\":                   handleSession,\n\t\"stopnotifyblocks\":          handleStopNotifyBlocks,\n\t\"stopnotifynewtransactions\": handleStopNotifyNewTransactions,\n\t\"stopnotifyspent\":           handleStopNotifySpent,\n\t\"stopnotifyreceived\":        handleStopNotifyReceived,\n\t\"rescan\":                    handleRescan,\n\t\"rescanblocks\":              handleRescanBlocks,\n}\n\n// WebsocketHandler handles a new websocket client by creating a new wsClient,\n// starting it, and blocking until the connection closes.  Since it blocks, it\n// must be run in a separate goroutine.  It should be invoked from the websocket\n// server handler which runs each new connection in a new goroutine thereby\n// satisfying the requirement.\nfunc (s *rpcServer) WebsocketHandler(conn *websocket.Conn, remoteAddr string,\n\tauthenticated bool, isAdmin bool) {\n\n\t// Clear the read deadline that was set before the websocket hijacked\n\t// the connection.\n\tconn.SetReadDeadline(timeZeroVal)\n\n\t// Limit max number of websocket clients.\n\trpcsLog.Infof(\"New websocket client %s\", remoteAddr)\n\tif s.ntfnMgr.NumClients()+1 > cfg.RPCMaxWebsockets {\n\t\trpcsLog.Infof(\"Max websocket clients exceeded [%d] - \"+\n\t\t\t\"disconnecting client %s\", cfg.RPCMaxWebsockets,\n\t\t\tremoteAddr)\n\t\tconn.Close()\n\t\treturn\n\t}\n\n\t// Create a new websocket client to handle the new websocket connection\n\t// and wait for it to shutdown.  Once it has shutdown (and hence\n\t// disconnected), remove it and any notifications it registered for.\n\tclient, err := newWebsocketClient(s, conn, remoteAddr, authenticated, isAdmin)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to serve client %s: %v\", remoteAddr, err)\n\t\tconn.Close()\n\t\treturn\n\t}\n\ts.ntfnMgr.AddClient(client)\n\tclient.Start()\n\tclient.WaitForShutdown()\n\ts.ntfnMgr.RemoveClient(client)\n\trpcsLog.Infof(\"Disconnected websocket client %s\", remoteAddr)\n}\n\n// wsNotificationManager is a connection and notification manager used for\n// websockets.  It allows websocket clients to register for notifications they\n// are interested in.  When an event happens elsewhere in the code such as\n// transactions being added to the memory pool or block connects/disconnects,\n// the notification manager is provided with the relevant details needed to\n// figure out which websocket clients need to be notified based on what they\n// have registered for and notifies them accordingly.  It is also used to keep\n// track of all connected websocket clients.\ntype wsNotificationManager struct {\n\t// server is the RPC server the notification manager is associated with.\n\tserver *rpcServer\n\n\t// queueNotification queues a notification for handling.\n\tqueueNotification chan interface{}\n\n\t// notificationMsgs feeds notificationHandler with notifications\n\t// and client (un)registration requests from a queue as well as\n\t// registration and unregistration requests from clients.\n\tnotificationMsgs chan interface{}\n\n\t// Access channel for current number of connected clients.\n\tnumClients chan int\n\n\t// Shutdown handling\n\twg   sync.WaitGroup\n\tquit chan struct{}\n}\n\n// queueHandler manages a queue of empty interfaces, reading from in and\n// sending the oldest unsent to out.  This handler stops when either of the\n// in or quit channels are closed, and closes out before returning, without\n// waiting to send any variables still remaining in the queue.\nfunc queueHandler(in <-chan interface{}, out chan<- interface{}, quit <-chan struct{}) {\n\tvar q []interface{}\n\tvar dequeue chan<- interface{}\n\tskipQueue := out\n\tvar next interface{}\nout:\n\tfor {\n\t\tselect {\n\t\tcase n, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\t// Sender closed input channel.\n\t\t\t\tbreak out\n\t\t\t}\n\n\t\t\t// Either send to out immediately if skipQueue is\n\t\t\t// non-nil (queue is empty) and reader is ready,\n\t\t\t// or append to the queue and send later.\n\t\t\tselect {\n\t\t\tcase skipQueue <- n:\n\t\t\tdefault:\n\t\t\t\tq = append(q, n)\n\t\t\t\tdequeue = out\n\t\t\t\tskipQueue = nil\n\t\t\t\tnext = q[0]\n\t\t\t}\n\n\t\tcase dequeue <- next:\n\t\t\tcopy(q, q[1:])\n\t\t\tq[len(q)-1] = nil // avoid leak\n\t\t\tq = q[:len(q)-1]\n\t\t\tif len(q) == 0 {\n\t\t\t\tdequeue = nil\n\t\t\t\tskipQueue = out\n\t\t\t} else {\n\t\t\t\tnext = q[0]\n\t\t\t}\n\n\t\tcase <-quit:\n\t\t\tbreak out\n\t\t}\n\t}\n\tclose(out)\n}\n\n// queueHandler maintains a queue of notifications and notification handler\n// control messages.\nfunc (m *wsNotificationManager) queueHandler() {\n\tqueueHandler(m.queueNotification, m.notificationMsgs, m.quit)\n\tm.wg.Done()\n}\n\n// NotifyBlockConnected passes a block newly-connected to the best chain\n// to the notification manager for block and transaction notification\n// processing.\nfunc (m *wsNotificationManager) NotifyBlockConnected(block *btcutil.Block) {\n\t// As NotifyBlockConnected will be called by the block manager\n\t// and the RPC server may no longer be running, use a select\n\t// statement to unblock enqueuing the notification once the RPC\n\t// server has begun shutting down.\n\tselect {\n\tcase m.queueNotification <- (*notificationBlockConnected)(block):\n\tcase <-m.quit:\n\t}\n}\n\n// NotifyBlockDisconnected passes a block disconnected from the best chain\n// to the notification manager for block notification processing.\nfunc (m *wsNotificationManager) NotifyBlockDisconnected(block *btcutil.Block) {\n\t// As NotifyBlockDisconnected will be called by the block manager\n\t// and the RPC server may no longer be running, use a select\n\t// statement to unblock enqueuing the notification once the RPC\n\t// server has begun shutting down.\n\tselect {\n\tcase m.queueNotification <- (*notificationBlockDisconnected)(block):\n\tcase <-m.quit:\n\t}\n}\n\n// NotifyMempoolTx passes a transaction accepted by mempool to the\n// notification manager for transaction notification processing.  If\n// isNew is true, the tx is a new transaction, rather than one\n// added to the mempool during a reorg.\nfunc (m *wsNotificationManager) NotifyMempoolTx(tx *btcutil.Tx, isNew bool) {\n\tn := &notificationTxAcceptedByMempool{\n\t\tisNew: isNew,\n\t\ttx:    tx,\n\t}\n\n\t// As NotifyMempoolTx will be called by mempool and the RPC server\n\t// may no longer be running, use a select statement to unblock\n\t// enqueuing the notification once the RPC server has begun\n\t// shutting down.\n\tselect {\n\tcase m.queueNotification <- n:\n\tcase <-m.quit:\n\t}\n}\n\n// wsClientFilter tracks relevant addresses for each websocket client for\n// the `rescanblocks` extension. It is modified by the `loadtxfilter` command.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\ntype wsClientFilter struct {\n\tmu sync.Mutex\n\n\t// Implemented fast paths for address lookup.\n\tpubKeyHashes        map[[ripemd160.Size]byte]struct{}\n\tscriptHashes        map[[ripemd160.Size]byte]struct{}\n\tcompressedPubKeys   map[[33]byte]struct{}\n\tuncompressedPubKeys map[[65]byte]struct{}\n\n\t// A fallback address lookup map in case a fast path doesn't exist.\n\t// Only exists for completeness.  If using this shows up in a profile,\n\t// there's a good chance a fast path should be added.\n\totherAddresses map[string]struct{}\n\n\t// Outpoints of unspent outputs.\n\tunspent map[wire.OutPoint]struct{}\n}\n\n// newWSClientFilter creates a new, empty wsClientFilter struct to be used\n// for a websocket client.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc newWSClientFilter(addresses []string, unspentOutPoints []wire.OutPoint, params *chaincfg.Params) *wsClientFilter {\n\tfilter := &wsClientFilter{\n\t\tpubKeyHashes:        map[[ripemd160.Size]byte]struct{}{},\n\t\tscriptHashes:        map[[ripemd160.Size]byte]struct{}{},\n\t\tcompressedPubKeys:   map[[33]byte]struct{}{},\n\t\tuncompressedPubKeys: map[[65]byte]struct{}{},\n\t\totherAddresses:      map[string]struct{}{},\n\t\tunspent:             make(map[wire.OutPoint]struct{}, len(unspentOutPoints)),\n\t}\n\n\tfor _, s := range addresses {\n\t\tfilter.addAddressStr(s, params)\n\t}\n\tfor i := range unspentOutPoints {\n\t\tfilter.addUnspentOutPoint(&unspentOutPoints[i])\n\t}\n\n\treturn filter\n}\n\n// addAddress adds an address to a wsClientFilter, treating it correctly based\n// on the type of address passed as an argument.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) addAddress(a btcutil.Address) {\n\tswitch a := a.(type) {\n\tcase *btcutil.AddressPubKeyHash:\n\t\tf.pubKeyHashes[*a.Hash160()] = struct{}{}\n\t\treturn\n\tcase *btcutil.AddressScriptHash:\n\t\tf.scriptHashes[*a.Hash160()] = struct{}{}\n\t\treturn\n\tcase *btcutil.AddressPubKey:\n\t\tserializedPubKey := a.ScriptAddress()\n\t\tswitch len(serializedPubKey) {\n\t\tcase 33: // compressed\n\t\t\tvar compressedPubKey [33]byte\n\t\t\tcopy(compressedPubKey[:], serializedPubKey)\n\t\t\tf.compressedPubKeys[compressedPubKey] = struct{}{}\n\t\t\treturn\n\t\tcase 65: // uncompressed\n\t\t\tvar uncompressedPubKey [65]byte\n\t\t\tcopy(uncompressedPubKey[:], serializedPubKey)\n\t\t\tf.uncompressedPubKeys[uncompressedPubKey] = struct{}{}\n\t\t\treturn\n\t\t}\n\t}\n\n\tf.otherAddresses[a.EncodeAddress()] = struct{}{}\n}\n\n// addAddressStr parses an address from a string and then adds it to the\n// wsClientFilter using addAddress.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) addAddressStr(s string, params *chaincfg.Params) {\n\t// If address can't be decoded, no point in saving it since it should also\n\t// impossible to create the address from an inspected transaction output\n\t// script.\n\ta, err := btcutil.DecodeAddress(s, params)\n\tif err != nil {\n\t\treturn\n\t}\n\tf.addAddress(a)\n}\n\n// existsAddress returns true if the passed address has been added to the\n// wsClientFilter.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) existsAddress(a btcutil.Address) bool {\n\tswitch a := a.(type) {\n\tcase *btcutil.AddressPubKeyHash:\n\t\t_, ok := f.pubKeyHashes[*a.Hash160()]\n\t\treturn ok\n\tcase *btcutil.AddressScriptHash:\n\t\t_, ok := f.scriptHashes[*a.Hash160()]\n\t\treturn ok\n\tcase *btcutil.AddressPubKey:\n\t\tserializedPubKey := a.ScriptAddress()\n\t\tswitch len(serializedPubKey) {\n\t\tcase 33: // compressed\n\t\t\tvar compressedPubKey [33]byte\n\t\t\tcopy(compressedPubKey[:], serializedPubKey)\n\t\t\t_, ok := f.compressedPubKeys[compressedPubKey]\n\t\t\tif !ok {\n\t\t\t\t_, ok = f.pubKeyHashes[*a.AddressPubKeyHash().Hash160()]\n\t\t\t}\n\t\t\treturn ok\n\t\tcase 65: // uncompressed\n\t\t\tvar uncompressedPubKey [65]byte\n\t\t\tcopy(uncompressedPubKey[:], serializedPubKey)\n\t\t\t_, ok := f.uncompressedPubKeys[uncompressedPubKey]\n\t\t\tif !ok {\n\t\t\t\t_, ok = f.pubKeyHashes[*a.AddressPubKeyHash().Hash160()]\n\t\t\t}\n\t\t\treturn ok\n\t\t}\n\t}\n\n\t_, ok := f.otherAddresses[a.EncodeAddress()]\n\treturn ok\n}\n\n// removeAddress removes the passed address, if it exists, from the\n// wsClientFilter.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) removeAddress(a btcutil.Address) {\n\tswitch a := a.(type) {\n\tcase *btcutil.AddressPubKeyHash:\n\t\tdelete(f.pubKeyHashes, *a.Hash160())\n\t\treturn\n\tcase *btcutil.AddressScriptHash:\n\t\tdelete(f.scriptHashes, *a.Hash160())\n\t\treturn\n\tcase *btcutil.AddressPubKey:\n\t\tserializedPubKey := a.ScriptAddress()\n\t\tswitch len(serializedPubKey) {\n\t\tcase 33: // compressed\n\t\t\tvar compressedPubKey [33]byte\n\t\t\tcopy(compressedPubKey[:], serializedPubKey)\n\t\t\tdelete(f.compressedPubKeys, compressedPubKey)\n\t\t\treturn\n\t\tcase 65: // uncompressed\n\t\t\tvar uncompressedPubKey [65]byte\n\t\t\tcopy(uncompressedPubKey[:], serializedPubKey)\n\t\t\tdelete(f.uncompressedPubKeys, uncompressedPubKey)\n\t\t\treturn\n\t\t}\n\t}\n\n\tdelete(f.otherAddresses, a.EncodeAddress())\n}\n\n// removeAddressStr parses an address from a string and then removes it from the\n// wsClientFilter using removeAddress.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) removeAddressStr(s string, params *chaincfg.Params) {\n\ta, err := btcutil.DecodeAddress(s, params)\n\tif err == nil {\n\t\tf.removeAddress(a)\n\t} else {\n\t\tdelete(f.otherAddresses, s)\n\t}\n}\n\n// addUnspentOutPoint adds an outpoint to the wsClientFilter.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) addUnspentOutPoint(op *wire.OutPoint) {\n\tf.unspent[*op] = struct{}{}\n}\n\n// existsUnspentOutPoint returns true if the passed outpoint has been added to\n// the wsClientFilter.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) existsUnspentOutPoint(op *wire.OutPoint) bool {\n\t_, ok := f.unspent[*op]\n\treturn ok\n}\n\n// removeUnspentOutPoint removes the passed outpoint, if it exists, from the\n// wsClientFilter.\n//\n// NOTE: This extension was ported from github.com/decred/dcrd\nfunc (f *wsClientFilter) removeUnspentOutPoint(op *wire.OutPoint) {\n\tdelete(f.unspent, *op)\n}\n\n// Notification types\ntype notificationBlockConnected btcutil.Block\ntype notificationBlockDisconnected btcutil.Block\ntype notificationTxAcceptedByMempool struct {\n\tisNew bool\n\ttx    *btcutil.Tx\n}\n\n// Notification control requests\ntype notificationRegisterClient wsClient\ntype notificationUnregisterClient wsClient\ntype notificationRegisterBlocks wsClient\ntype notificationUnregisterBlocks wsClient\ntype notificationRegisterNewMempoolTxs wsClient\ntype notificationUnregisterNewMempoolTxs wsClient\ntype notificationRegisterSpent struct {\n\twsc *wsClient\n\tops []*wire.OutPoint\n}\ntype notificationUnregisterSpent struct {\n\twsc *wsClient\n\top  *wire.OutPoint\n}\ntype notificationRegisterAddr struct {\n\twsc   *wsClient\n\taddrs []string\n}\ntype notificationUnregisterAddr struct {\n\twsc  *wsClient\n\taddr string\n}\n\n// notificationHandler reads notifications and control messages from the queue\n// handler and processes one at a time.\nfunc (m *wsNotificationManager) notificationHandler() {\n\t// clients is a map of all currently connected websocket clients.\n\tclients := make(map[chan struct{}]*wsClient)\n\n\t// Maps used to hold lists of websocket clients to be notified on\n\t// certain events.  Each websocket client also keeps maps for the events\n\t// which have multiple triggers to make removal from these lists on\n\t// connection close less horrendously expensive.\n\t//\n\t// Where possible, the quit channel is used as the unique id for a client\n\t// since it is quite a bit more efficient than using the entire struct.\n\tblockNotifications := make(map[chan struct{}]*wsClient)\n\ttxNotifications := make(map[chan struct{}]*wsClient)\n\twatchedOutPoints := make(map[wire.OutPoint]map[chan struct{}]*wsClient)\n\twatchedAddrs := make(map[string]map[chan struct{}]*wsClient)\n\nout:\n\tfor {\n\t\tselect {\n\t\tcase n, ok := <-m.notificationMsgs:\n\t\t\tif !ok {\n\t\t\t\t// queueHandler quit.\n\t\t\t\tbreak out\n\t\t\t}\n\t\t\tswitch n := n.(type) {\n\t\t\tcase *notificationBlockConnected:\n\t\t\t\tblock := (*btcutil.Block)(n)\n\n\t\t\t\t// Skip iterating through all txs if no\n\t\t\t\t// tx notification requests exist.\n\t\t\t\tif len(watchedOutPoints) != 0 || len(watchedAddrs) != 0 {\n\t\t\t\t\tfor _, tx := range block.Transactions() {\n\t\t\t\t\t\tm.notifyForTx(watchedOutPoints,\n\t\t\t\t\t\t\twatchedAddrs, tx, block)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif len(blockNotifications) != 0 {\n\t\t\t\t\tm.notifyBlockConnected(blockNotifications,\n\t\t\t\t\t\tblock)\n\t\t\t\t\tm.notifyFilteredBlockConnected(blockNotifications,\n\t\t\t\t\t\tblock)\n\t\t\t\t}\n\n\t\t\tcase *notificationBlockDisconnected:\n\t\t\t\tblock := (*btcutil.Block)(n)\n\n\t\t\t\tif len(blockNotifications) != 0 {\n\t\t\t\t\tm.notifyBlockDisconnected(blockNotifications,\n\t\t\t\t\t\tblock)\n\t\t\t\t\tm.notifyFilteredBlockDisconnected(blockNotifications,\n\t\t\t\t\t\tblock)\n\t\t\t\t}\n\n\t\t\tcase *notificationTxAcceptedByMempool:\n\t\t\t\tif n.isNew && len(txNotifications) != 0 {\n\t\t\t\t\tm.notifyForNewTx(txNotifications, n.tx)\n\t\t\t\t}\n\t\t\t\tm.notifyForTx(watchedOutPoints, watchedAddrs, n.tx, nil)\n\t\t\t\tm.notifyRelevantTxAccepted(n.tx, clients)\n\n\t\t\tcase *notificationRegisterBlocks:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\tblockNotifications[wsc.quit] = wsc\n\n\t\t\tcase *notificationUnregisterBlocks:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\tdelete(blockNotifications, wsc.quit)\n\n\t\t\tcase *notificationRegisterClient:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\tclients[wsc.quit] = wsc\n\n\t\t\tcase *notificationUnregisterClient:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\t// Remove any requests made by the client as well as\n\t\t\t\t// the client itself.\n\t\t\t\tdelete(blockNotifications, wsc.quit)\n\t\t\t\tdelete(txNotifications, wsc.quit)\n\t\t\t\tfor k := range wsc.spentRequests {\n\t\t\t\t\top := k\n\t\t\t\t\tm.removeSpentRequest(watchedOutPoints, wsc, &op)\n\t\t\t\t}\n\t\t\t\tfor addr := range wsc.addrRequests {\n\t\t\t\t\tm.removeAddrRequest(watchedAddrs, wsc, addr)\n\t\t\t\t}\n\t\t\t\tdelete(clients, wsc.quit)\n\n\t\t\tcase *notificationRegisterSpent:\n\t\t\t\tm.addSpentRequests(watchedOutPoints, n.wsc, n.ops)\n\n\t\t\tcase *notificationUnregisterSpent:\n\t\t\t\tm.removeSpentRequest(watchedOutPoints, n.wsc, n.op)\n\n\t\t\tcase *notificationRegisterAddr:\n\t\t\t\tm.addAddrRequests(watchedAddrs, n.wsc, n.addrs)\n\n\t\t\tcase *notificationUnregisterAddr:\n\t\t\t\tm.removeAddrRequest(watchedAddrs, n.wsc, n.addr)\n\n\t\t\tcase *notificationRegisterNewMempoolTxs:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\ttxNotifications[wsc.quit] = wsc\n\n\t\t\tcase *notificationUnregisterNewMempoolTxs:\n\t\t\t\twsc := (*wsClient)(n)\n\t\t\t\tdelete(txNotifications, wsc.quit)\n\n\t\t\tdefault:\n\t\t\t\trpcsLog.Warn(\"Unhandled notification type\")\n\t\t\t}\n\n\t\tcase m.numClients <- len(clients):\n\n\t\tcase <-m.quit:\n\t\t\t// RPC server shutting down.\n\t\t\tbreak out\n\t\t}\n\t}\n\n\tfor _, c := range clients {\n\t\tc.Disconnect()\n\t}\n\tm.wg.Done()\n}\n\n// NumClients returns the number of clients actively being served.\nfunc (m *wsNotificationManager) NumClients() (n int) {\n\tselect {\n\tcase n = <-m.numClients:\n\tcase <-m.quit: // Use default n (0) if server has shut down.\n\t}\n\treturn\n}\n\n// RegisterBlockUpdates requests block update notifications to the passed\n// websocket client.\nfunc (m *wsNotificationManager) RegisterBlockUpdates(wsc *wsClient) {\n\tm.queueNotification <- (*notificationRegisterBlocks)(wsc)\n}\n\n// UnregisterBlockUpdates removes block update notifications for the passed\n// websocket client.\nfunc (m *wsNotificationManager) UnregisterBlockUpdates(wsc *wsClient) {\n\tm.queueNotification <- (*notificationUnregisterBlocks)(wsc)\n}\n\n// subscribedClients returns the set of all websocket client quit channels that\n// are registered to receive notifications regarding tx, either due to tx\n// spending a watched output or outputting to a watched address.  Matching\n// client's filters are updated based on this transaction's outputs and output\n// addresses that may be relevant for a client.\nfunc (m *wsNotificationManager) subscribedClients(tx *btcutil.Tx,\n\tclients map[chan struct{}]*wsClient) map[chan struct{}]struct{} {\n\n\t// Use a map of client quit channels as keys to prevent duplicates when\n\t// multiple inputs and/or outputs are relevant to the client.\n\tsubscribed := make(map[chan struct{}]struct{})\n\n\tmsgTx := tx.MsgTx()\n\tfor _, input := range msgTx.TxIn {\n\t\tfor quitChan, wsc := range clients {\n\t\t\twsc.Lock()\n\t\t\tfilter := wsc.filterData\n\t\t\twsc.Unlock()\n\t\t\tif filter == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfilter.mu.Lock()\n\t\t\tif filter.existsUnspentOutPoint(&input.PreviousOutPoint) {\n\t\t\t\tsubscribed[quitChan] = struct{}{}\n\t\t\t}\n\t\t\tfilter.mu.Unlock()\n\t\t}\n\t}\n\n\tfor i, output := range msgTx.TxOut {\n\t\t_, addrs, _, err := txscript.ExtractPkScriptAddrs(\n\t\t\toutput.PkScript, m.server.cfg.ChainParams)\n\t\tif err != nil {\n\t\t\t// Clients are not able to subscribe to\n\t\t\t// nonstandard or non-address outputs.\n\t\t\tcontinue\n\t\t}\n\t\tfor quitChan, wsc := range clients {\n\t\t\twsc.Lock()\n\t\t\tfilter := wsc.filterData\n\t\t\twsc.Unlock()\n\t\t\tif filter == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfilter.mu.Lock()\n\t\t\tfor _, a := range addrs {\n\t\t\t\tif filter.existsAddress(a) {\n\t\t\t\t\tsubscribed[quitChan] = struct{}{}\n\t\t\t\t\top := wire.OutPoint{\n\t\t\t\t\t\tHash:  *tx.Hash(),\n\t\t\t\t\t\tIndex: uint32(i),\n\t\t\t\t\t}\n\t\t\t\t\tfilter.addUnspentOutPoint(&op)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfilter.mu.Unlock()\n\t\t}\n\t}\n\n\treturn subscribed\n}\n\n// notifyBlockConnected notifies websocket clients that have registered for\n// block updates when a block is connected to the main chain.\nfunc (*wsNotificationManager) notifyBlockConnected(clients map[chan struct{}]*wsClient,\n\tblock *btcutil.Block) {\n\n\t// Notify interested websocket clients about the connected block.\n\tntfn := btcjson.NewBlockConnectedNtfn(block.Hash().String(), block.Height(),\n\t\tblock.MsgBlock().Header.Timestamp.Unix())\n\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal block connected notification: \"+\n\t\t\t\"%v\", err)\n\t\treturn\n\t}\n\tfor _, wsc := range clients {\n\t\twsc.QueueNotification(marshalledJSON)\n\t}\n}\n\n// notifyBlockDisconnected notifies websocket clients that have registered for\n// block updates when a block is disconnected from the main chain (due to a\n// reorganize).\nfunc (*wsNotificationManager) notifyBlockDisconnected(clients map[chan struct{}]*wsClient, block *btcutil.Block) {\n\t// Skip notification creation if no clients have requested block\n\t// connected/disconnected notifications.\n\tif len(clients) == 0 {\n\t\treturn\n\t}\n\n\t// Notify interested websocket clients about the disconnected block.\n\tntfn := btcjson.NewBlockDisconnectedNtfn(block.Hash().String(),\n\t\tblock.Height(), block.MsgBlock().Header.Timestamp.Unix())\n\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal block disconnected \"+\n\t\t\t\"notification: %v\", err)\n\t\treturn\n\t}\n\tfor _, wsc := range clients {\n\t\twsc.QueueNotification(marshalledJSON)\n\t}\n}\n\n// notifyFilteredBlockConnected notifies websocket clients that have registered for\n// block updates when a block is connected to the main chain.\nfunc (m *wsNotificationManager) notifyFilteredBlockConnected(clients map[chan struct{}]*wsClient,\n\tblock *btcutil.Block) {\n\n\t// Create the common portion of the notification that is the same for\n\t// every client.\n\tvar w bytes.Buffer\n\terr := block.MsgBlock().Header.Serialize(&w)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to serialize header for filtered block \"+\n\t\t\t\"connected notification: %v\", err)\n\t\treturn\n\t}\n\tntfn := btcjson.NewFilteredBlockConnectedNtfn(block.Height(),\n\t\thex.EncodeToString(w.Bytes()), nil)\n\n\t// Search for relevant transactions for each client and save them\n\t// serialized in hex encoding for the notification.\n\tsubscribedTxs := make(map[chan struct{}][]string)\n\tfor _, tx := range block.Transactions() {\n\t\tvar txHex string\n\t\tfor quitChan := range m.subscribedClients(tx, clients) {\n\t\t\tif txHex == \"\" {\n\t\t\t\ttxHex = txHexString(tx.MsgTx())\n\t\t\t}\n\t\t\tsubscribedTxs[quitChan] = append(subscribedTxs[quitChan], txHex)\n\t\t}\n\t}\n\tfor quitChan, wsc := range clients {\n\t\t// Add all discovered transactions for this client. For clients\n\t\t// that have no new-style filter, add the empty string slice.\n\t\tntfn.SubscribedTxs = subscribedTxs[quitChan]\n\n\t\t// Marshal and queue notification.\n\t\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\t\tif err != nil {\n\t\t\trpcsLog.Errorf(\"Failed to marshal filtered block \"+\n\t\t\t\t\"connected notification: %v\", err)\n\t\t\treturn\n\t\t}\n\t\twsc.QueueNotification(marshalledJSON)\n\t}\n}\n\n// notifyFilteredBlockDisconnected notifies websocket clients that have registered for\n// block updates when a block is disconnected from the main chain (due to a\n// reorganize).\nfunc (*wsNotificationManager) notifyFilteredBlockDisconnected(clients map[chan struct{}]*wsClient,\n\tblock *btcutil.Block) {\n\t// Skip notification creation if no clients have requested block\n\t// connected/disconnected notifications.\n\tif len(clients) == 0 {\n\t\treturn\n\t}\n\n\t// Notify interested websocket clients about the disconnected block.\n\tvar w bytes.Buffer\n\terr := block.MsgBlock().Header.Serialize(&w)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to serialize header for filtered block \"+\n\t\t\t\"disconnected notification: %v\", err)\n\t\treturn\n\t}\n\tntfn := btcjson.NewFilteredBlockDisconnectedNtfn(block.Height(),\n\t\thex.EncodeToString(w.Bytes()))\n\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal filtered block disconnected \"+\n\t\t\t\"notification: %v\", err)\n\t\treturn\n\t}\n\tfor _, wsc := range clients {\n\t\twsc.QueueNotification(marshalledJSON)\n\t}\n}\n\n// RegisterNewMempoolTxsUpdates requests notifications to the passed websocket\n// client when new transactions are added to the memory pool.\nfunc (m *wsNotificationManager) RegisterNewMempoolTxsUpdates(wsc *wsClient) {\n\tm.queueNotification <- (*notificationRegisterNewMempoolTxs)(wsc)\n}\n\n// UnregisterNewMempoolTxsUpdates removes notifications to the passed websocket\n// client when new transaction are added to the memory pool.\nfunc (m *wsNotificationManager) UnregisterNewMempoolTxsUpdates(wsc *wsClient) {\n\tm.queueNotification <- (*notificationUnregisterNewMempoolTxs)(wsc)\n}\n\n// notifyForNewTx notifies websocket clients that have registered for updates\n// when a new transaction is added to the memory pool.\nfunc (m *wsNotificationManager) notifyForNewTx(clients map[chan struct{}]*wsClient, tx *btcutil.Tx) {\n\ttxHashStr := tx.Hash().String()\n\tmtx := tx.MsgTx()\n\n\tvar amount int64\n\tfor _, txOut := range mtx.TxOut {\n\t\tamount += txOut.Value\n\t}\n\n\tntfn := btcjson.NewTxAcceptedNtfn(txHashStr, btcutil.Amount(amount).ToBTC())\n\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal tx notification: %s\", err.Error())\n\t\treturn\n\t}\n\n\tvar verboseNtfn *btcjson.TxAcceptedVerboseNtfn\n\tvar marshalledJSONVerbose []byte\n\tfor _, wsc := range clients {\n\t\tif wsc.verboseTxUpdates {\n\t\t\tif marshalledJSONVerbose != nil {\n\t\t\t\twsc.QueueNotification(marshalledJSONVerbose)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tnet := m.server.cfg.ChainParams\n\t\t\trawTx, err := createTxRawResult(net, mtx, txHashStr, nil,\n\t\t\t\t\"\", 0, 0)\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tverboseNtfn = btcjson.NewTxAcceptedVerboseNtfn(*rawTx)\n\t\t\tmarshalledJSONVerbose, err = btcjson.MarshalCmd(btcjson.RpcVersion1, nil,\n\t\t\t\tverboseNtfn)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to marshal verbose tx \"+\n\t\t\t\t\t\"notification: %s\", err.Error())\n\t\t\t\treturn\n\t\t\t}\n\t\t\twsc.QueueNotification(marshalledJSONVerbose)\n\t\t} else {\n\t\t\twsc.QueueNotification(marshalledJSON)\n\t\t}\n\t}\n}\n\n// RegisterSpentRequests requests a notification when each of the passed\n// outpoints is confirmed spent (contained in a block connected to the main\n// chain) for the passed websocket client.  The request is automatically\n// removed once the notification has been sent.\nfunc (m *wsNotificationManager) RegisterSpentRequests(wsc *wsClient, ops []*wire.OutPoint) {\n\tm.queueNotification <- &notificationRegisterSpent{\n\t\twsc: wsc,\n\t\tops: ops,\n\t}\n}\n\n// addSpentRequests modifies a map of watched outpoints to sets of websocket\n// clients to add a new request watch all of the outpoints in ops and create\n// and send a notification when spent to the websocket client wsc.\nfunc (m *wsNotificationManager) addSpentRequests(opMap map[wire.OutPoint]map[chan struct{}]*wsClient,\n\twsc *wsClient, ops []*wire.OutPoint) {\n\n\tfor _, op := range ops {\n\t\t// Track the request in the client as well so it can be quickly\n\t\t// be removed on disconnect.\n\t\twsc.spentRequests[*op] = struct{}{}\n\n\t\t// Add the client to the list to notify when the outpoint is seen.\n\t\t// Create the list as needed.\n\t\tcmap, ok := opMap[*op]\n\t\tif !ok {\n\t\t\tcmap = make(map[chan struct{}]*wsClient)\n\t\t\topMap[*op] = cmap\n\t\t}\n\t\tcmap[wsc.quit] = wsc\n\t}\n\n\t// Check if any transactions spending these outputs already exists in\n\t// the mempool, if so send the notification immediately.\n\tspends := make(map[chainhash.Hash]*btcutil.Tx)\n\tfor _, op := range ops {\n\t\tspend := m.server.cfg.TxMemPool.CheckSpend(*op)\n\t\tif spend != nil {\n\t\t\trpcsLog.Debugf(\"Found existing mempool spend for \"+\n\t\t\t\t\"outpoint<%v>: %v\", op, spend.Hash())\n\t\t\tspends[*spend.Hash()] = spend\n\t\t}\n\t}\n\n\tfor _, spend := range spends {\n\t\tm.notifyForTx(opMap, nil, spend, nil)\n\t}\n}\n\n// UnregisterSpentRequest removes a request from the passed websocket client\n// to be notified when the passed outpoint is confirmed spent (contained in a\n// block connected to the main chain).\nfunc (m *wsNotificationManager) UnregisterSpentRequest(wsc *wsClient, op *wire.OutPoint) {\n\tm.queueNotification <- &notificationUnregisterSpent{\n\t\twsc: wsc,\n\t\top:  op,\n\t}\n}\n\n// removeSpentRequest modifies a map of watched outpoints to remove the\n// websocket client wsc from the set of clients to be notified when a\n// watched outpoint is spent.  If wsc is the last client, the outpoint\n// key is removed from the map.\nfunc (*wsNotificationManager) removeSpentRequest(ops map[wire.OutPoint]map[chan struct{}]*wsClient,\n\twsc *wsClient, op *wire.OutPoint) {\n\n\t// Remove the request tracking from the client.\n\tdelete(wsc.spentRequests, *op)\n\n\t// Remove the client from the list to notify.\n\tnotifyMap, ok := ops[*op]\n\tif !ok {\n\t\trpcsLog.Warnf(\"Attempt to remove nonexistent spent request \"+\n\t\t\t\"for websocket client %s\", wsc.addr)\n\t\treturn\n\t}\n\tdelete(notifyMap, wsc.quit)\n\n\t// Remove the map entry altogether if there are\n\t// no more clients interested in it.\n\tif len(notifyMap) == 0 {\n\t\tdelete(ops, *op)\n\t}\n}\n\n// txHexString returns the serialized transaction encoded in hexadecimal.\nfunc txHexString(tx *wire.MsgTx) string {\n\tbuf := bytes.NewBuffer(make([]byte, 0, tx.SerializeSize()))\n\t// Ignore Serialize's error, as writing to a bytes.buffer cannot fail.\n\ttx.Serialize(buf)\n\treturn hex.EncodeToString(buf.Bytes())\n}\n\n// blockDetails creates a BlockDetails struct to include in btcws notifications\n// from a block and a transaction's block index.\nfunc blockDetails(block *btcutil.Block, txIndex int) *btcjson.BlockDetails {\n\tif block == nil {\n\t\treturn nil\n\t}\n\treturn &btcjson.BlockDetails{\n\t\tHeight: block.Height(),\n\t\tHash:   block.Hash().String(),\n\t\tIndex:  txIndex,\n\t\tTime:   block.MsgBlock().Header.Timestamp.Unix(),\n\t}\n}\n\n// newRedeemingTxNotification returns a new marshalled redeemingtx notification\n// with the passed parameters.\nfunc newRedeemingTxNotification(txHex string, index int, block *btcutil.Block) ([]byte, error) {\n\t// Create and marshal the notification.\n\tntfn := btcjson.NewRedeemingTxNtfn(txHex, blockDetails(block, index))\n\treturn btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n}\n\n// notifyForTxOuts examines each transaction output, notifying interested\n// websocket clients of the transaction if an output spends to a watched\n// address.  A spent notification request is automatically registered for\n// the client for each matching output.\nfunc (m *wsNotificationManager) notifyForTxOuts(ops map[wire.OutPoint]map[chan struct{}]*wsClient,\n\taddrs map[string]map[chan struct{}]*wsClient, tx *btcutil.Tx, block *btcutil.Block) {\n\n\t// Nothing to do if nobody is listening for address notifications.\n\tif len(addrs) == 0 {\n\t\treturn\n\t}\n\n\ttxHex := \"\"\n\twscNotified := make(map[chan struct{}]struct{})\n\tfor i, txOut := range tx.MsgTx().TxOut {\n\t\t_, txAddrs, _, err := txscript.ExtractPkScriptAddrs(\n\t\t\ttxOut.PkScript, m.server.cfg.ChainParams)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, txAddr := range txAddrs {\n\t\t\tcmap, ok := addrs[txAddr.EncodeAddress()]\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif txHex == \"\" {\n\t\t\t\ttxHex = txHexString(tx.MsgTx())\n\t\t\t}\n\t\t\tntfn := btcjson.NewRecvTxNtfn(txHex, blockDetails(block,\n\t\t\t\ttx.Index()))\n\n\t\t\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to marshal processedtx notification: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\top := []*wire.OutPoint{wire.NewOutPoint(tx.Hash(), uint32(i))}\n\t\t\tfor wscQuit, wsc := range cmap {\n\t\t\t\tm.addSpentRequests(ops, wsc, op)\n\n\t\t\t\tif _, ok := wscNotified[wscQuit]; !ok {\n\t\t\t\t\twscNotified[wscQuit] = struct{}{}\n\t\t\t\t\twsc.QueueNotification(marshalledJSON)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// notifyRelevantTxAccepted examines the inputs and outputs of the passed\n// transaction, notifying websocket clients of outputs spending to a watched\n// address and inputs spending a watched outpoint.  Any outputs paying to a\n// watched address result in the output being watched as well for future\n// notifications.\nfunc (m *wsNotificationManager) notifyRelevantTxAccepted(tx *btcutil.Tx,\n\tclients map[chan struct{}]*wsClient) {\n\n\tclientsToNotify := m.subscribedClients(tx, clients)\n\n\tif len(clientsToNotify) != 0 {\n\t\tn := btcjson.NewRelevantTxAcceptedNtfn(txHexString(tx.MsgTx()))\n\t\tmarshalled, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, n)\n\t\tif err != nil {\n\t\t\trpcsLog.Errorf(\"Failed to marshal notification: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tfor quitChan := range clientsToNotify {\n\t\t\tclients[quitChan].QueueNotification(marshalled)\n\t\t}\n\t}\n}\n\n// notifyForTx examines the inputs and outputs of the passed transaction,\n// notifying websocket clients of outputs spending to a watched address\n// and inputs spending a watched outpoint.\nfunc (m *wsNotificationManager) notifyForTx(ops map[wire.OutPoint]map[chan struct{}]*wsClient,\n\taddrs map[string]map[chan struct{}]*wsClient, tx *btcutil.Tx, block *btcutil.Block) {\n\n\tif len(ops) != 0 {\n\t\tm.notifyForTxIns(ops, tx, block)\n\t}\n\tif len(addrs) != 0 {\n\t\tm.notifyForTxOuts(ops, addrs, tx, block)\n\t}\n}\n\n// notifyForTxIns examines the inputs of the passed transaction and sends\n// interested websocket clients a redeemingtx notification if any inputs\n// spend a watched output.  If block is non-nil, any matching spent\n// requests are removed.\nfunc (m *wsNotificationManager) notifyForTxIns(ops map[wire.OutPoint]map[chan struct{}]*wsClient,\n\ttx *btcutil.Tx, block *btcutil.Block) {\n\n\t// Nothing to do if nobody is watching outpoints.\n\tif len(ops) == 0 {\n\t\treturn\n\t}\n\n\ttxHex := \"\"\n\twscNotified := make(map[chan struct{}]struct{})\n\tfor _, txIn := range tx.MsgTx().TxIn {\n\t\tprevOut := &txIn.PreviousOutPoint\n\t\tif cmap, ok := ops[*prevOut]; ok {\n\t\t\tif txHex == \"\" {\n\t\t\t\ttxHex = txHexString(tx.MsgTx())\n\t\t\t}\n\t\t\tmarshalledJSON, err := newRedeemingTxNotification(txHex, tx.Index(), block)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Warnf(\"Failed to marshal redeemingtx notification: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor wscQuit, wsc := range cmap {\n\t\t\t\tif block != nil {\n\t\t\t\t\tm.removeSpentRequest(ops, wsc, prevOut)\n\t\t\t\t}\n\n\t\t\t\tif _, ok := wscNotified[wscQuit]; !ok {\n\t\t\t\t\twscNotified[wscQuit] = struct{}{}\n\t\t\t\t\twsc.QueueNotification(marshalledJSON)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// RegisterTxOutAddressRequests requests notifications to the passed websocket\n// client when a transaction output spends to the passed address.\nfunc (m *wsNotificationManager) RegisterTxOutAddressRequests(wsc *wsClient, addrs []string) {\n\tm.queueNotification <- &notificationRegisterAddr{\n\t\twsc:   wsc,\n\t\taddrs: addrs,\n\t}\n}\n\n// addAddrRequests adds the websocket client wsc to the address to client set\n// addrMap so wsc will be notified for any mempool or block transaction outputs\n// spending to any of the addresses in addrs.\nfunc (*wsNotificationManager) addAddrRequests(addrMap map[string]map[chan struct{}]*wsClient,\n\twsc *wsClient, addrs []string) {\n\n\tfor _, addr := range addrs {\n\t\t// Track the request in the client as well so it can be quickly be\n\t\t// removed on disconnect.\n\t\twsc.addrRequests[addr] = struct{}{}\n\n\t\t// Add the client to the set of clients to notify when the\n\t\t// outpoint is seen.  Create map as needed.\n\t\tcmap, ok := addrMap[addr]\n\t\tif !ok {\n\t\t\tcmap = make(map[chan struct{}]*wsClient)\n\t\t\taddrMap[addr] = cmap\n\t\t}\n\t\tcmap[wsc.quit] = wsc\n\t}\n}\n\n// UnregisterTxOutAddressRequest removes a request from the passed websocket\n// client to be notified when a transaction spends to the passed address.\nfunc (m *wsNotificationManager) UnregisterTxOutAddressRequest(wsc *wsClient, addr string) {\n\tm.queueNotification <- &notificationUnregisterAddr{\n\t\twsc:  wsc,\n\t\taddr: addr,\n\t}\n}\n\n// removeAddrRequest removes the websocket client wsc from the address to\n// client set addrs so it will no longer receive notification updates for\n// any transaction outputs send to addr.\nfunc (*wsNotificationManager) removeAddrRequest(addrs map[string]map[chan struct{}]*wsClient,\n\twsc *wsClient, addr string) {\n\n\t// Remove the request tracking from the client.\n\tdelete(wsc.addrRequests, addr)\n\n\t// Remove the client from the list to notify.\n\tcmap, ok := addrs[addr]\n\tif !ok {\n\t\trpcsLog.Warnf(\"Attempt to remove nonexistent addr request \"+\n\t\t\t\"<%s> for websocket client %s\", addr, wsc.addr)\n\t\treturn\n\t}\n\tdelete(cmap, wsc.quit)\n\n\t// Remove the map entry altogether if there are no more clients\n\t// interested in it.\n\tif len(cmap) == 0 {\n\t\tdelete(addrs, addr)\n\t}\n}\n\n// AddClient adds the passed websocket client to the notification manager.\nfunc (m *wsNotificationManager) AddClient(wsc *wsClient) {\n\tm.queueNotification <- (*notificationRegisterClient)(wsc)\n}\n\n// RemoveClient removes the passed websocket client and all notifications\n// registered for it.\nfunc (m *wsNotificationManager) RemoveClient(wsc *wsClient) {\n\tselect {\n\tcase m.queueNotification <- (*notificationUnregisterClient)(wsc):\n\tcase <-m.quit:\n\t}\n}\n\n// Start starts the goroutines required for the manager to queue and process\n// websocket client notifications.\nfunc (m *wsNotificationManager) Start() {\n\tm.wg.Add(2)\n\tgo m.queueHandler()\n\tgo m.notificationHandler()\n}\n\n// WaitForShutdown blocks until all notification manager goroutines have\n// finished.\nfunc (m *wsNotificationManager) WaitForShutdown() {\n\tm.wg.Wait()\n}\n\n// Shutdown shuts down the manager, stopping the notification queue and\n// notification handler goroutines.\nfunc (m *wsNotificationManager) Shutdown() {\n\tclose(m.quit)\n}\n\n// newWsNotificationManager returns a new notification manager ready for use.\n// See wsNotificationManager for more details.\nfunc newWsNotificationManager(server *rpcServer) *wsNotificationManager {\n\treturn &wsNotificationManager{\n\t\tserver:            server,\n\t\tqueueNotification: make(chan interface{}),\n\t\tnotificationMsgs:  make(chan interface{}),\n\t\tnumClients:        make(chan int),\n\t\tquit:              make(chan struct{}),\n\t}\n}\n\n// wsResponse houses a message to send to a connected websocket client as\n// well as a channel to reply on when the message is sent.\ntype wsResponse struct {\n\tmsg      []byte\n\tdoneChan chan bool\n}\n\n// wsClient provides an abstraction for handling a websocket client.  The\n// overall data flow is split into 3 main goroutines, a possible 4th goroutine\n// for long-running operations (only started if request is made), and a\n// websocket manager which is used to allow things such as broadcasting\n// requested notifications to all connected websocket clients.   Inbound\n// messages are read via the inHandler goroutine and generally dispatched to\n// their own handler.  However, certain potentially long-running operations such\n// as rescans, are sent to the asyncHandler goroutine and are limited to one at a\n// time.  There are two outbound message types - one for responding to client\n// requests and another for async notifications.  Responses to client requests\n// use SendMessage which employs a buffered channel thereby limiting the number\n// of outstanding requests that can be made.  Notifications are sent via\n// QueueNotification which implements a queue via notificationQueueHandler to\n// ensure sending notifications from other subsystems can't block.  Ultimately,\n// all messages are sent via the outHandler.\ntype wsClient struct {\n\tsync.Mutex\n\n\t// server is the RPC server that is servicing the client.\n\tserver *rpcServer\n\n\t// conn is the underlying websocket connection.\n\tconn *websocket.Conn\n\n\t// disconnected indicated whether or not the websocket client is\n\t// disconnected.\n\tdisconnected bool\n\n\t// addr is the remote address of the client.\n\taddr string\n\n\t// authenticated specifies whether a client has been authenticated\n\t// and therefore is allowed to communicated over the websocket.\n\tauthenticated bool\n\n\t// isAdmin specifies whether a client may change the state of the server;\n\t// false means its access is only to the limited set of RPC calls.\n\tisAdmin bool\n\n\t// sessionID is a random ID generated for each client when connected.\n\t// These IDs may be queried by a client using the session RPC.  A change\n\t// to the session ID indicates that the client reconnected.\n\tsessionID uint64\n\n\t// verboseTxUpdates specifies whether a client has requested verbose\n\t// information about all new transactions.\n\tverboseTxUpdates bool\n\n\t// addrRequests is a set of addresses the caller has requested to be\n\t// notified about.  It is maintained here so all requests can be removed\n\t// when a wallet disconnects.  Owned by the notification manager.\n\taddrRequests map[string]struct{}\n\n\t// spentRequests is a set of unspent Outpoints a wallet has requested\n\t// notifications for when they are spent by a processed transaction.\n\t// Owned by the notification manager.\n\tspentRequests map[wire.OutPoint]struct{}\n\n\t// filterData is the new generation transaction filter backported from\n\t// github.com/decred/dcrd for the new backported `loadtxfilter` and\n\t// `rescanblocks` methods.\n\tfilterData *wsClientFilter\n\n\t// Networking infrastructure.\n\tserviceRequestSem semaphore\n\tntfnChan          chan []byte\n\tsendChan          chan wsResponse\n\tquit              chan struct{}\n\twg                sync.WaitGroup\n}\n\n// inHandler handles all incoming messages for the websocket connection.  It\n// must be run as a goroutine.\nfunc (c *wsClient) inHandler() {\nout:\n\tfor {\n\t\t// Break out of the loop once the quit channel has been closed.\n\t\t// Use a non-blocking select here so we fall through otherwise.\n\t\tselect {\n\t\tcase <-c.quit:\n\t\t\tbreak out\n\t\tdefault:\n\t\t}\n\n\t\t_, msg, err := c.conn.ReadMessage()\n\t\tif err != nil {\n\t\t\t// Log the error if it's not due to disconnecting.\n\t\t\tif err != io.EOF {\n\t\t\t\trpcsLog.Errorf(\"Websocket receive error from \"+\n\t\t\t\t\t\"%s: %v\", c.addr, err)\n\t\t\t}\n\t\t\tbreak out\n\t\t}\n\n\t\tvar batchedRequest bool\n\n\t\t// Determine request type\n\t\tif bytes.HasPrefix(msg, batchedRequestPrefix) {\n\t\t\tbatchedRequest = true\n\t\t}\n\n\t\tif !batchedRequest {\n\t\t\tvar req btcjson.Request\n\t\t\tvar reply json.RawMessage\n\t\t\terr = json.Unmarshal(msg, &req)\n\t\t\tif err != nil {\n\t\t\t\t// only process requests from authenticated clients\n\t\t\t\tif !c.authenticated {\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\n\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCParse.Code,\n\t\t\t\t\tMessage: \"Failed to parse request: \" + err.Error(),\n\t\t\t\t}\n\t\t\t\treply, err = createMarshalledReply(btcjson.RpcVersion1, nil, nil, jsonErr)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tc.SendMessage(reply, nil)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif req.Method == \"\" || req.Params == nil {\n\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\tMessage: \"Invalid request: malformed\",\n\t\t\t\t}\n\t\t\t\treply, err := createMarshalledReply(req.Jsonrpc, req.ID, nil, jsonErr)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tc.SendMessage(reply, nil)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Valid requests with no ID (notifications) must not have a response\n\t\t\t// per the JSON-RPC spec.\n\t\t\tif req.ID == nil {\n\t\t\t\tif !c.authenticated {\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcmd := parseCmd(&req)\n\t\t\tif cmd.err != nil {\n\t\t\t\t// Only process requests from authenticated clients\n\t\t\t\tif !c.authenticated {\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\n\t\t\t\treply, err = createMarshalledReply(cmd.jsonrpc, cmd.id, nil, cmd.err)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tc.SendMessage(reply, nil)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\trpcsLog.Debugf(\"Received command <%s> from %s\", cmd.method, c.addr)\n\n\t\t\t// Check auth.  The client is immediately disconnected if the\n\t\t\t// first request of an unauthentiated websocket client is not\n\t\t\t// the authenticate request, an authenticate request is received\n\t\t\t// when the client is already authenticated, or incorrect\n\t\t\t// authentication credentials are provided in the request.\n\t\t\tswitch authCmd, ok := cmd.cmd.(*btcjson.AuthenticateCmd); {\n\t\t\tcase c.authenticated && ok:\n\t\t\t\trpcsLog.Warnf(\"Websocket client %s is already authenticated\",\n\t\t\t\t\tc.addr)\n\t\t\t\tbreak out\n\t\t\tcase !c.authenticated && !ok:\n\t\t\t\trpcsLog.Warnf(\"Unauthenticated websocket message \" +\n\t\t\t\t\t\"received\")\n\t\t\t\tbreak out\n\t\t\tcase !c.authenticated:\n\t\t\t\t// Check credentials.\n\t\t\t\tlogin := authCmd.Username + \":\" + authCmd.Passphrase\n\t\t\t\tauth := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(login))\n\t\t\t\tauthSha := sha256.Sum256([]byte(auth))\n\t\t\t\tcmp := subtle.ConstantTimeCompare(authSha[:], c.server.authsha[:])\n\t\t\t\tlimitcmp := subtle.ConstantTimeCompare(authSha[:], c.server.limitauthsha[:])\n\t\t\t\tif cmp != 1 && limitcmp != 1 {\n\t\t\t\t\trpcsLog.Warnf(\"Auth failure.\")\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\t\t\t\tc.authenticated = true\n\t\t\t\tc.isAdmin = cmp == 1\n\n\t\t\t\t// Marshal and send response.\n\t\t\t\treply, err = createMarshalledReply(cmd.jsonrpc, cmd.id, nil, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal authenticate reply: \"+\n\t\t\t\t\t\t\"%v\", err.Error())\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tc.SendMessage(reply, nil)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Check if the client is using limited RPC credentials and\n\t\t\t// error when not authorized to call the supplied RPC.\n\t\t\tif !c.isAdmin {\n\t\t\t\tif _, ok := rpcLimited[req.Method]; !ok {\n\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\tCode:    btcjson.ErrRPCInvalidParams.Code,\n\t\t\t\t\t\tMessage: \"limited user not authorized for this method\",\n\t\t\t\t\t}\n\t\t\t\t\t// Marshal and send response.\n\t\t\t\t\treply, err = createMarshalledReply(\"\", req.ID, nil, jsonErr)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal parse failure \"+\n\t\t\t\t\t\t\t\"reply: %v\", err)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tc.SendMessage(reply, nil)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Asynchronously handle the request.  A semaphore is used to\n\t\t\t// limit the number of concurrent requests currently being\n\t\t\t// serviced.  If the semaphore can not be acquired, simply wait\n\t\t\t// until a request finished before reading the next RPC request\n\t\t\t// from the websocket client.\n\t\t\t//\n\t\t\t// This could be a little fancier by timing out and erroring\n\t\t\t// when it takes too long to service the request, but if that is\n\t\t\t// done, the read of the next request should not be blocked by\n\t\t\t// this semaphore, otherwise the next request will be read and\n\t\t\t// will probably sit here for another few seconds before timing\n\t\t\t// out as well.  This will cause the total timeout duration for\n\t\t\t// later requests to be much longer than the check here would\n\t\t\t// imply.\n\t\t\t//\n\t\t\t// If a timeout is added, the semaphore acquiring should be\n\t\t\t// moved inside of the new goroutine with a select statement\n\t\t\t// that also reads a time.After channel.  This will unblock the\n\t\t\t// read of the next request from the websocket client and allow\n\t\t\t// many requests to be waited on concurrently.\n\t\t\tc.serviceRequestSem.acquire()\n\t\t\tgo func() {\n\t\t\t\tc.serviceRequest(cmd)\n\t\t\t\tc.serviceRequestSem.release()\n\t\t\t}()\n\t\t}\n\n\t\t// Process a batched request\n\t\tif batchedRequest {\n\t\t\tvar batchedRequests []interface{}\n\t\t\tvar results []json.RawMessage\n\t\t\tvar batchSize int\n\t\t\tvar reply json.RawMessage\n\t\t\tc.serviceRequestSem.acquire()\n\t\t\terr = json.Unmarshal(msg, &batchedRequests)\n\t\t\tif err != nil {\n\t\t\t\t// Only process requests from authenticated clients\n\t\t\t\tif !c.authenticated {\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\n\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\tCode: btcjson.ErrRPCParse.Code,\n\t\t\t\t\tMessage: fmt.Sprintf(\"Failed to parse request: %v\",\n\t\t\t\t\t\terr),\n\t\t\t\t}\n\t\t\t\treply, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tif reply != nil {\n\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\t// Response with an empty batch error if the batch size is zero\n\t\t\t\tif len(batchedRequests) == 0 {\n\t\t\t\t\tif !c.authenticated {\n\t\t\t\t\t\tbreak out\n\t\t\t\t\t}\n\n\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\tMessage: \"Invalid request: empty batch\",\n\t\t\t\t\t}\n\t\t\t\t\treply, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Process each batch entry individually\n\t\t\t\tif len(batchedRequests) > 0 {\n\t\t\t\t\tbatchSize = len(batchedRequests)\n\t\t\t\t\tfor _, entry := range batchedRequests {\n\t\t\t\t\t\tvar reqBytes []byte\n\t\t\t\t\t\treqBytes, err = json.Marshal(entry)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t// Only process requests from authenticated clients\n\t\t\t\t\t\t\tif !c.authenticated {\n\t\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\t\tCode: btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\t\t\tMessage: fmt.Sprintf(\"Invalid request: %v\",\n\t\t\t\t\t\t\t\t\terr),\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treply, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar req btcjson.Request\n\t\t\t\t\t\terr := json.Unmarshal(reqBytes, &req)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t// Only process requests from authenticated clients\n\t\t\t\t\t\t\tif !c.authenticated {\n\t\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\t\tCode: btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\t\t\tMessage: fmt.Sprintf(\"Invalid request: %v\",\n\t\t\t\t\t\t\t\t\terr),\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treply, err = btcjson.MarshalResponse(btcjson.RpcVersion2, nil, nil, jsonErr)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to create reply: %v\", err)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif req.Method == \"\" || req.Params == nil {\n\t\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\t\tCode:    btcjson.ErrRPCInvalidRequest.Code,\n\t\t\t\t\t\t\t\tMessage: \"Invalid request: malformed\",\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treply, err := createMarshalledReply(req.Jsonrpc, req.ID, nil, jsonErr)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Valid requests with no ID (notifications) must not have a response\n\t\t\t\t\t\t// per the JSON-RPC spec.\n\t\t\t\t\t\tif req.ID == nil {\n\t\t\t\t\t\t\tif !c.authenticated {\n\t\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tcmd := parseCmd(&req)\n\t\t\t\t\t\tif cmd.err != nil {\n\t\t\t\t\t\t\t// Only process requests from authenticated clients\n\t\t\t\t\t\t\tif !c.authenticated {\n\t\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\treply, err = createMarshalledReply(cmd.jsonrpc, cmd.id, nil, cmd.err)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply: %v\", err)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\trpcsLog.Debugf(\"Received command <%s> from %s\", cmd.method, c.addr)\n\n\t\t\t\t\t\t// Check auth.  The client is immediately disconnected if the\n\t\t\t\t\t\t// first request of an unauthentiated websocket client is not\n\t\t\t\t\t\t// the authenticate request, an authenticate request is received\n\t\t\t\t\t\t// when the client is already authenticated, or incorrect\n\t\t\t\t\t\t// authentication credentials are provided in the request.\n\t\t\t\t\t\tswitch authCmd, ok := cmd.cmd.(*btcjson.AuthenticateCmd); {\n\t\t\t\t\t\tcase c.authenticated && ok:\n\t\t\t\t\t\t\trpcsLog.Warnf(\"Websocket client %s is already authenticated\",\n\t\t\t\t\t\t\t\tc.addr)\n\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\tcase !c.authenticated && !ok:\n\t\t\t\t\t\t\trpcsLog.Warnf(\"Unauthenticated websocket message \" +\n\t\t\t\t\t\t\t\t\"received\")\n\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\tcase !c.authenticated:\n\t\t\t\t\t\t\t// Check credentials.\n\t\t\t\t\t\t\tlogin := authCmd.Username + \":\" + authCmd.Passphrase\n\t\t\t\t\t\t\tauth := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(login))\n\t\t\t\t\t\t\tauthSha := sha256.Sum256([]byte(auth))\n\t\t\t\t\t\t\tcmp := subtle.ConstantTimeCompare(authSha[:], c.server.authsha[:])\n\t\t\t\t\t\t\tlimitcmp := subtle.ConstantTimeCompare(authSha[:], c.server.limitauthsha[:])\n\t\t\t\t\t\t\tif cmp != 1 && limitcmp != 1 {\n\t\t\t\t\t\t\t\trpcsLog.Warnf(\"Auth failure.\")\n\t\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tc.authenticated = true\n\t\t\t\t\t\t\tc.isAdmin = cmp == 1\n\n\t\t\t\t\t\t\t// Marshal and send response.\n\t\t\t\t\t\t\treply, err = createMarshalledReply(cmd.jsonrpc, cmd.id, nil, nil)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal authenticate reply: \"+\n\t\t\t\t\t\t\t\t\t\"%v\", err.Error())\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Check if the client is using limited RPC credentials and\n\t\t\t\t\t\t// error when not authorized to call the supplied RPC.\n\t\t\t\t\t\tif !c.isAdmin {\n\t\t\t\t\t\t\tif _, ok := rpcLimited[req.Method]; !ok {\n\t\t\t\t\t\t\t\tjsonErr := &btcjson.RPCError{\n\t\t\t\t\t\t\t\t\tCode:    btcjson.ErrRPCInvalidParams.Code,\n\t\t\t\t\t\t\t\t\tMessage: \"limited user not authorized for this method\",\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t// Marshal and send response.\n\t\t\t\t\t\t\t\treply, err = createMarshalledReply(req.Jsonrpc, req.ID, nil, jsonErr)\n\t\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal parse failure \"+\n\t\t\t\t\t\t\t\t\t\t\"reply: %v\", err)\n\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Lookup the websocket extension for the command, if it doesn't\n\t\t\t\t\t\t// exist fallback to handling the command as a standard command.\n\t\t\t\t\t\tvar resp interface{}\n\t\t\t\t\t\twsHandler, ok := wsHandlers[cmd.method]\n\t\t\t\t\t\tif ok {\n\t\t\t\t\t\t\tresp, err = wsHandler(c, cmd.cmd)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresp, err = c.server.standardCmdResult(cmd, nil)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Marshal request output.\n\t\t\t\t\t\treply, err := createMarshalledReply(cmd.jsonrpc, cmd.id, resp, err)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal reply for <%s> \"+\n\t\t\t\t\t\t\t\t\"command: %v\", cmd.method, err)\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif reply != nil {\n\t\t\t\t\t\t\tresults = append(results, reply)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// generate reply\n\t\t\tvar payload = []byte{}\n\t\t\tif batchedRequest && batchSize > 0 {\n\t\t\t\tif len(results) > 0 {\n\t\t\t\t\t// Form the batched response json\n\t\t\t\t\tvar buffer bytes.Buffer\n\t\t\t\t\tbuffer.WriteByte('[')\n\t\t\t\t\tfor idx, marshalledReply := range results {\n\t\t\t\t\t\tif idx == len(results)-1 {\n\t\t\t\t\t\t\tbuffer.Write(marshalledReply)\n\t\t\t\t\t\t\tbuffer.WriteByte(']')\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbuffer.Write(marshalledReply)\n\t\t\t\t\t\tbuffer.WriteByte(',')\n\t\t\t\t\t}\n\t\t\t\t\tpayload = buffer.Bytes()\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !batchedRequest || batchSize == 0 {\n\t\t\t\t// Respond with the first results entry for single requests\n\t\t\t\tif len(results) > 0 {\n\t\t\t\t\tpayload = results[0]\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tc.SendMessage(payload, nil)\n\t\t\tc.serviceRequestSem.release()\n\t\t}\n\t}\n\n\t// Ensure the connection is closed.\n\tc.Disconnect()\n\tc.wg.Done()\n\trpcsLog.Tracef(\"Websocket client input handler done for %s\", c.addr)\n}\n\n// serviceRequest services a parsed RPC request by looking up and executing the\n// appropriate RPC handler.  The response is marshalled and sent to the\n// websocket client.\nfunc (c *wsClient) serviceRequest(r *parsedRPCCmd) {\n\tvar (\n\t\tresult interface{}\n\t\terr    error\n\t)\n\n\t// Lookup the websocket extension for the command and if it doesn't\n\t// exist fallback to handling the command as a standard command.\n\twsHandler, ok := wsHandlers[r.method]\n\tif ok {\n\t\tresult, err = wsHandler(c, r.cmd)\n\t} else {\n\t\tresult, err = c.server.standardCmdResult(r, nil)\n\t}\n\treply, err := createMarshalledReply(r.jsonrpc, r.id, result, err)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal reply for <%s> \"+\n\t\t\t\"command: %v\", r.method, err)\n\t\treturn\n\t}\n\tc.SendMessage(reply, nil)\n}\n\n// notificationQueueHandler handles the queuing of outgoing notifications for\n// the websocket client.  This runs as a muxer for various sources of input to\n// ensure that queuing up notifications to be sent will not block.  Otherwise,\n// slow clients could bog down the other systems (such as the mempool or block\n// manager) which are queuing the data.  The data is passed on to outHandler to\n// actually be written.  It must be run as a goroutine.\nfunc (c *wsClient) notificationQueueHandler() {\n\tntfnSentChan := make(chan bool, 1) // nonblocking sync\n\n\t// pendingNtfns is used as a queue for notifications that are ready to\n\t// be sent once there are no outstanding notifications currently being\n\t// sent.  The waiting flag is used over simply checking for items in the\n\t// pending list to ensure cleanup knows what has and hasn't been sent\n\t// to the outHandler.  Currently no special cleanup is needed, however\n\t// if something like a done channel is added to notifications in the\n\t// future, not knowing what has and hasn't been sent to the outHandler\n\t// (and thus who should respond to the done channel) would be\n\t// problematic without using this approach.\n\tpendingNtfns := list.New()\n\twaiting := false\nout:\n\tfor {\n\t\tselect {\n\t\t// This channel is notified when a message is being queued to\n\t\t// be sent across the network socket.  It will either send the\n\t\t// message immediately if a send is not already in progress, or\n\t\t// queue the message to be sent once the other pending messages\n\t\t// are sent.\n\t\tcase msg := <-c.ntfnChan:\n\t\t\tif !waiting {\n\t\t\t\tc.SendMessage(msg, ntfnSentChan)\n\t\t\t} else {\n\t\t\t\tpendingNtfns.PushBack(msg)\n\t\t\t}\n\t\t\twaiting = true\n\n\t\t// This channel is notified when a notification has been sent\n\t\t// across the network socket.\n\t\tcase <-ntfnSentChan:\n\t\t\t// No longer waiting if there are no more messages in\n\t\t\t// the pending messages queue.\n\t\t\tnext := pendingNtfns.Front()\n\t\t\tif next == nil {\n\t\t\t\twaiting = false\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Notify the outHandler about the next item to\n\t\t\t// asynchronously send.\n\t\t\tmsg := pendingNtfns.Remove(next).([]byte)\n\t\t\tc.SendMessage(msg, ntfnSentChan)\n\n\t\tcase <-c.quit:\n\t\t\tbreak out\n\t\t}\n\t}\n\n\t// Drain any wait channels before exiting so nothing is left waiting\n\t// around to send.\ncleanup:\n\tfor {\n\t\tselect {\n\t\tcase <-c.ntfnChan:\n\t\tcase <-ntfnSentChan:\n\t\tdefault:\n\t\t\tbreak cleanup\n\t\t}\n\t}\n\tc.wg.Done()\n\trpcsLog.Tracef(\"Websocket client notification queue handler done \"+\n\t\t\"for %s\", c.addr)\n}\n\n// outHandler handles all outgoing messages for the websocket connection.  It\n// must be run as a goroutine.  It uses a buffered channel to serialize output\n// messages while allowing the sender to continue running asynchronously.  It\n// must be run as a goroutine.\nfunc (c *wsClient) outHandler() {\nout:\n\tfor {\n\t\t// Send any messages ready for send until the quit channel is\n\t\t// closed.\n\t\tselect {\n\t\tcase r := <-c.sendChan:\n\t\t\terr := c.conn.WriteMessage(websocket.TextMessage, r.msg)\n\t\t\tif err != nil {\n\t\t\t\tc.Disconnect()\n\t\t\t\tbreak out\n\t\t\t}\n\t\t\tif r.doneChan != nil {\n\t\t\t\tr.doneChan <- true\n\t\t\t}\n\n\t\tcase <-c.quit:\n\t\t\tbreak out\n\t\t}\n\t}\n\n\t// Drain any wait channels before exiting so nothing is left waiting\n\t// around to send.\ncleanup:\n\tfor {\n\t\tselect {\n\t\tcase r := <-c.sendChan:\n\t\t\tif r.doneChan != nil {\n\t\t\t\tr.doneChan <- false\n\t\t\t}\n\t\tdefault:\n\t\t\tbreak cleanup\n\t\t}\n\t}\n\tc.wg.Done()\n\trpcsLog.Tracef(\"Websocket client output handler done for %s\", c.addr)\n}\n\n// SendMessage sends the passed json to the websocket client.  It is backed\n// by a buffered channel, so it will not block until the send channel is full.\n// Note however that QueueNotification must be used for sending async\n// notifications instead of the this function.  This approach allows a limit to\n// the number of outstanding requests a client can make without preventing or\n// blocking on async notifications.\nfunc (c *wsClient) SendMessage(marshalledJSON []byte, doneChan chan bool) {\n\t// Don't send the message if disconnected.\n\tif c.Disconnected() {\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- false\n\t\t}\n\t\treturn\n\t}\n\n\tc.sendChan <- wsResponse{msg: marshalledJSON, doneChan: doneChan}\n}\n\n// ErrClientQuit describes the error where a client send is not processed due\n// to the client having already been disconnected or dropped.\nvar ErrClientQuit = errors.New(\"client quit\")\n\n// QueueNotification queues the passed notification to be sent to the websocket\n// client.  This function, as the name implies, is only intended for\n// notifications since it has additional logic to prevent other subsystems, such\n// as the memory pool and block manager, from blocking even when the send\n// channel is full.\n//\n// If the client is in the process of shutting down, this function returns\n// ErrClientQuit.  This is intended to be checked by long-running notification\n// handlers to stop processing if there is no more work needed to be done.\nfunc (c *wsClient) QueueNotification(marshalledJSON []byte) error {\n\t// Don't queue the message if disconnected.\n\tif c.Disconnected() {\n\t\treturn ErrClientQuit\n\t}\n\n\tc.ntfnChan <- marshalledJSON\n\treturn nil\n}\n\n// Disconnected returns whether or not the websocket client is disconnected.\nfunc (c *wsClient) Disconnected() bool {\n\tc.Lock()\n\tisDisconnected := c.disconnected\n\tc.Unlock()\n\n\treturn isDisconnected\n}\n\n// Disconnect disconnects the websocket client.\nfunc (c *wsClient) Disconnect() {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// Nothing to do if already disconnected.\n\tif c.disconnected {\n\t\treturn\n\t}\n\n\trpcsLog.Tracef(\"Disconnecting websocket client %s\", c.addr)\n\tclose(c.quit)\n\tc.conn.Close()\n\tc.disconnected = true\n}\n\n// Start begins processing input and output messages.\nfunc (c *wsClient) Start() {\n\trpcsLog.Tracef(\"Starting websocket client %s\", c.addr)\n\n\t// Start processing input and output.\n\tc.wg.Add(3)\n\tgo c.inHandler()\n\tgo c.notificationQueueHandler()\n\tgo c.outHandler()\n}\n\n// WaitForShutdown blocks until the websocket client goroutines are stopped\n// and the connection is closed.\nfunc (c *wsClient) WaitForShutdown() {\n\tc.wg.Wait()\n}\n\n// newWebsocketClient returns a new websocket client given the notification\n// manager, websocket connection, remote address, and whether or not the client\n// has already been authenticated (via HTTP Basic access authentication).  The\n// returned client is ready to start.  Once started, the client will process\n// incoming and outgoing messages in separate goroutines complete with queuing\n// and asynchrous handling for long-running operations.\nfunc newWebsocketClient(server *rpcServer, conn *websocket.Conn,\n\tremoteAddr string, authenticated bool, isAdmin bool) (*wsClient, error) {\n\n\tsessionID, err := wire.RandomUint64()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclient := &wsClient{\n\t\tconn:              conn,\n\t\taddr:              remoteAddr,\n\t\tauthenticated:     authenticated,\n\t\tisAdmin:           isAdmin,\n\t\tsessionID:         sessionID,\n\t\tserver:            server,\n\t\taddrRequests:      make(map[string]struct{}),\n\t\tspentRequests:     make(map[wire.OutPoint]struct{}),\n\t\tserviceRequestSem: makeSemaphore(cfg.RPCMaxConcurrentReqs),\n\t\tntfnChan:          make(chan []byte, 1), // nonblocking sync\n\t\tsendChan:          make(chan wsResponse, websocketSendBufferSize),\n\t\tquit:              make(chan struct{}),\n\t}\n\treturn client, nil\n}\n\n// handleWebsocketHelp implements the help command for websocket connections.\nfunc handleWebsocketHelp(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.HelpCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\t// Provide a usage overview of all commands when no specific command\n\t// was specified.\n\tvar command string\n\tif cmd.Command != nil {\n\t\tcommand = *cmd.Command\n\t}\n\tif command == \"\" {\n\t\tusage, err := wsc.server.helpCacher.rpcUsage(true)\n\t\tif err != nil {\n\t\t\tcontext := \"Failed to generate RPC usage\"\n\t\t\treturn nil, internalRPCError(err.Error(), context)\n\t\t}\n\t\treturn usage, nil\n\t}\n\n\t// Check that the command asked for is supported and implemented.\n\t// Search the list of websocket handlers as well as the main list of\n\t// handlers since help should only be provided for those cases.\n\tvalid := true\n\tif _, ok := rpcHandlers[command]; !ok {\n\t\tif _, ok := wsHandlers[command]; !ok {\n\t\t\tvalid = false\n\t\t}\n\t}\n\tif !valid {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\tMessage: \"Unknown command: \" + command,\n\t\t}\n\t}\n\n\t// Get the help for the command.\n\thelp, err := wsc.server.helpCacher.rpcMethodHelp(command)\n\tif err != nil {\n\t\tcontext := \"Failed to generate help\"\n\t\treturn nil, internalRPCError(err.Error(), context)\n\t}\n\treturn help, nil\n}\n\n// handleLoadTxFilter implements the loadtxfilter command extension for\n// websocket connections.\n//\n// NOTE: This extension is ported from github.com/decred/dcrd\nfunc handleLoadTxFilter(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd := icmd.(*btcjson.LoadTxFilterCmd)\n\n\toutPoints := make([]wire.OutPoint, len(cmd.OutPoints))\n\tfor i := range cmd.OutPoints {\n\t\thash, err := chainhash.NewHashFromStr(cmd.OutPoints[i].Hash)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCInvalidParameter,\n\t\t\t\tMessage: err.Error(),\n\t\t\t}\n\t\t}\n\t\toutPoints[i] = wire.OutPoint{\n\t\t\tHash:  *hash,\n\t\t\tIndex: cmd.OutPoints[i].Index,\n\t\t}\n\t}\n\n\tparams := wsc.server.cfg.ChainParams\n\n\twsc.Lock()\n\tif cmd.Reload || wsc.filterData == nil {\n\t\twsc.filterData = newWSClientFilter(cmd.Addresses, outPoints,\n\t\t\tparams)\n\t\twsc.Unlock()\n\t} else {\n\t\twsc.Unlock()\n\n\t\twsc.filterData.mu.Lock()\n\t\tfor _, a := range cmd.Addresses {\n\t\t\twsc.filterData.addAddressStr(a, params)\n\t\t}\n\t\tfor i := range outPoints {\n\t\t\twsc.filterData.addUnspentOutPoint(&outPoints[i])\n\t\t}\n\t\twsc.filterData.mu.Unlock()\n\t}\n\n\treturn nil, nil\n}\n\n// handleNotifyBlocks implements the notifyblocks command extension for\n// websocket connections.\nfunc handleNotifyBlocks(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\twsc.server.ntfnMgr.RegisterBlockUpdates(wsc)\n\treturn nil, nil\n}\n\n// handleSession implements the session command extension for websocket\n// connections.\nfunc handleSession(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\treturn &btcjson.SessionResult{SessionID: wsc.sessionID}, nil\n}\n\n// handleStopNotifyBlocks implements the stopnotifyblocks command extension for\n// websocket connections.\nfunc handleStopNotifyBlocks(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\twsc.server.ntfnMgr.UnregisterBlockUpdates(wsc)\n\treturn nil, nil\n}\n\n// handleNotifySpent implements the notifyspent command extension for\n// websocket connections.\nfunc handleNotifySpent(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.NotifySpentCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\toutpoints, err := deserializeOutpoints(cmd.OutPoints)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\twsc.server.ntfnMgr.RegisterSpentRequests(wsc, outpoints)\n\treturn nil, nil\n}\n\n// handleNotifyNewTransactions implements the notifynewtransactions command\n// extension for websocket connections.\nfunc handleNotifyNewTransactions(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.NotifyNewTransactionsCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\twsc.verboseTxUpdates = cmd.Verbose != nil && *cmd.Verbose\n\twsc.server.ntfnMgr.RegisterNewMempoolTxsUpdates(wsc)\n\treturn nil, nil\n}\n\n// handleStopNotifyNewTransactions implements the stopnotifynewtransactions\n// command extension for websocket connections.\nfunc handleStopNotifyNewTransactions(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\twsc.server.ntfnMgr.UnregisterNewMempoolTxsUpdates(wsc)\n\treturn nil, nil\n}\n\n// handleNotifyReceived implements the notifyreceived command extension for\n// websocket connections.\nfunc handleNotifyReceived(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.NotifyReceivedCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\t// Decode addresses to validate input, but the strings slice is used\n\t// directly if these are all ok.\n\terr := checkAddressValidity(cmd.Addresses, wsc.server.cfg.ChainParams)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\twsc.server.ntfnMgr.RegisterTxOutAddressRequests(wsc, cmd.Addresses)\n\treturn nil, nil\n}\n\n// handleStopNotifySpent implements the stopnotifyspent command extension for\n// websocket connections.\nfunc handleStopNotifySpent(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.StopNotifySpentCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\toutpoints, err := deserializeOutpoints(cmd.OutPoints)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, outpoint := range outpoints {\n\t\twsc.server.ntfnMgr.UnregisterSpentRequest(wsc, outpoint)\n\t}\n\n\treturn nil, nil\n}\n\n// handleStopNotifyReceived implements the stopnotifyreceived command extension\n// for websocket connections.\nfunc handleStopNotifyReceived(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.StopNotifyReceivedCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\t// Decode addresses to validate input, but the strings slice is used\n\t// directly if these are all ok.\n\terr := checkAddressValidity(cmd.Addresses, wsc.server.cfg.ChainParams)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, addr := range cmd.Addresses {\n\t\twsc.server.ntfnMgr.UnregisterTxOutAddressRequest(wsc, addr)\n\t}\n\n\treturn nil, nil\n}\n\n// checkAddressValidity checks the validity of each address in the passed\n// string slice. It does this by attempting to decode each address using the\n// current active network parameters. If any single address fails to decode\n// properly, the function returns an error. Otherwise, nil is returned.\nfunc checkAddressValidity(addrs []string, params *chaincfg.Params) error {\n\tfor _, addr := range addrs {\n\t\t_, err := btcutil.DecodeAddress(addr, params)\n\t\tif err != nil {\n\t\t\treturn &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInvalidAddressOrKey,\n\t\t\t\tMessage: fmt.Sprintf(\"Invalid address or key: %v\",\n\t\t\t\t\taddr),\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// deserializeOutpoints deserializes each serialized outpoint.\nfunc deserializeOutpoints(serializedOuts []btcjson.OutPoint) ([]*wire.OutPoint, error) {\n\toutpoints := make([]*wire.OutPoint, 0, len(serializedOuts))\n\tfor i := range serializedOuts {\n\t\tblockHash, err := chainhash.NewHashFromStr(serializedOuts[i].Hash)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(serializedOuts[i].Hash)\n\t\t}\n\t\tindex := serializedOuts[i].Index\n\t\toutpoints = append(outpoints, wire.NewOutPoint(blockHash, index))\n\t}\n\n\treturn outpoints, nil\n}\n\ntype rescanKeys struct {\n\taddrs   map[string]struct{}\n\tunspent map[wire.OutPoint]struct{}\n}\n\n// unspentSlice returns a slice of currently-unspent outpoints for the rescan\n// lookup keys.  This is primarily intended to be used to register outpoints\n// for continuous notifications after a rescan has completed.\nfunc (r *rescanKeys) unspentSlice() []*wire.OutPoint {\n\tops := make([]*wire.OutPoint, 0, len(r.unspent))\n\tfor op := range r.unspent {\n\t\topCopy := op\n\t\tops = append(ops, &opCopy)\n\t}\n\treturn ops\n}\n\n// ErrRescanReorg defines the error that is returned when an unrecoverable\n// reorganize is detected during a rescan.\nvar ErrRescanReorg = btcjson.RPCError{\n\tCode:    btcjson.ErrRPCDatabase,\n\tMessage: \"Reorganize\",\n}\n\n// rescanBlock rescans all transactions in a single block.  This is a helper\n// function for handleRescan.\nfunc rescanBlock(wsc *wsClient, lookups *rescanKeys, blk *btcutil.Block) {\n\tfor _, tx := range blk.Transactions() {\n\t\t// Hexadecimal representation of this tx.  Only created if\n\t\t// needed, and reused for later notifications if already made.\n\t\tvar txHex string\n\n\t\t// All inputs and outputs must be iterated through to correctly\n\t\t// modify the unspent map, however, just a single notification\n\t\t// for any matching transaction inputs or outputs should be\n\t\t// created and sent.\n\t\tspentNotified := false\n\t\trecvNotified := false\n\n\t\t// notifySpend is a closure we'll use when we first detect that\n\t\t// a transactions spends an outpoint/script in our filter list.\n\t\tnotifySpend := func() error {\n\t\t\tif txHex == \"\" {\n\t\t\t\ttxHex = txHexString(tx.MsgTx())\n\t\t\t}\n\t\t\tmarshalledJSON, err := newRedeemingTxNotification(\n\t\t\t\ttxHex, tx.Index(), blk,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to marshal \"+\n\t\t\t\t\t\"btcjson.RedeeminTxNtfn: %v\", err)\n\t\t\t}\n\n\t\t\treturn wsc.QueueNotification(marshalledJSON)\n\t\t}\n\n\t\t// We'll start by iterating over the transaction's inputs to\n\t\t// determine if it spends an outpoint/script in our filter list.\n\t\tfor _, txin := range tx.MsgTx().TxIn {\n\t\t\t// If it spends an outpoint, we'll dispatch a spend\n\t\t\t// notification for the transaction.\n\t\t\tif _, ok := lookups.unspent[txin.PreviousOutPoint]; ok {\n\t\t\t\tdelete(lookups.unspent, txin.PreviousOutPoint)\n\n\t\t\t\tif spentNotified {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\terr := notifySpend()\n\n\t\t\t\t// Stop the rescan early if the websocket client\n\t\t\t\t// disconnected.\n\t\t\t\tif err == ErrClientQuit {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Unable to notify \"+\n\t\t\t\t\t\t\"redeeming transaction %v: %v\",\n\t\t\t\t\t\ttx.Hash(), err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tspentNotified = true\n\t\t\t}\n\n\t\t\t// We'll also recompute the pkScript the input is\n\t\t\t// attempting to spend to determine whether it is\n\t\t\t// relevant to us.\n\t\t\tpkScript, err := txscript.ComputePkScript(\n\t\t\t\ttxin.SignatureScript, txin.Witness,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\taddr, err := pkScript.Address(wsc.server.cfg.ChainParams)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If it is, we'll also dispatch a spend notification\n\t\t\t// for this transaction if we haven't already.\n\t\t\tif _, ok := lookups.addrs[addr.String()]; ok {\n\t\t\t\tif spentNotified {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\terr := notifySpend()\n\n\t\t\t\t// Stop the rescan early if the websocket client\n\t\t\t\t// disconnected.\n\t\t\t\tif err == ErrClientQuit {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Unable to notify \"+\n\t\t\t\t\t\t\"redeeming transaction %v: %v\",\n\t\t\t\t\t\ttx.Hash(), err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tspentNotified = true\n\t\t\t}\n\t\t}\n\n\t\tfor txOutIdx, txout := range tx.MsgTx().TxOut {\n\t\t\t_, addrs, _, _ := txscript.ExtractPkScriptAddrs(\n\t\t\t\ttxout.PkScript, wsc.server.cfg.ChainParams)\n\n\t\t\tfor _, addr := range addrs {\n\t\t\t\tif _, ok := lookups.addrs[addr.String()]; !ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\toutpoint := wire.OutPoint{\n\t\t\t\t\tHash:  *tx.Hash(),\n\t\t\t\t\tIndex: uint32(txOutIdx),\n\t\t\t\t}\n\t\t\t\tlookups.unspent[outpoint] = struct{}{}\n\n\t\t\t\tif recvNotified {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif txHex == \"\" {\n\t\t\t\t\ttxHex = txHexString(tx.MsgTx())\n\t\t\t\t}\n\t\t\t\tntfn := btcjson.NewRecvTxNtfn(txHex,\n\t\t\t\t\tblockDetails(blk, tx.Index()))\n\n\t\t\t\tmarshalledJSON, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, ntfn)\n\t\t\t\tif err != nil {\n\t\t\t\t\trpcsLog.Errorf(\"Failed to marshal recvtx notification: %v\", err)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\terr = wsc.QueueNotification(marshalledJSON)\n\t\t\t\t// Stop the rescan early if the websocket client\n\t\t\t\t// disconnected.\n\t\t\t\tif err == ErrClientQuit {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\trecvNotified = true\n\t\t\t}\n\t\t}\n\t}\n}\n\n// rescanBlockFilter rescans a block for any relevant transactions for the\n// passed lookup keys. Any discovered transactions are returned hex encoded as\n// a string slice.\n//\n// NOTE: This extension is ported from github.com/decred/dcrd\nfunc rescanBlockFilter(filter *wsClientFilter, block *btcutil.Block, params *chaincfg.Params) []string {\n\tvar transactions []string\n\n\tfilter.mu.Lock()\n\tfor _, tx := range block.Transactions() {\n\t\tmsgTx := tx.MsgTx()\n\n\t\t// Keep track of whether the transaction has already been added\n\t\t// to the result.  It shouldn't be added twice.\n\t\tadded := false\n\n\t\t// Scan inputs if not a coinbase transaction.\n\t\tif !blockchain.IsCoinBaseTx(msgTx) {\n\t\t\tfor _, input := range msgTx.TxIn {\n\t\t\t\tif !filter.existsUnspentOutPoint(&input.PreviousOutPoint) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif !added {\n\t\t\t\t\ttransactions = append(\n\t\t\t\t\t\ttransactions,\n\t\t\t\t\t\ttxHexString(msgTx))\n\t\t\t\t\tadded = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Scan outputs.\n\t\tfor i, output := range msgTx.TxOut {\n\t\t\t_, addrs, _, err := txscript.ExtractPkScriptAddrs(\n\t\t\t\toutput.PkScript, params)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, a := range addrs {\n\t\t\t\tif !filter.existsAddress(a) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\top := wire.OutPoint{\n\t\t\t\t\tHash:  *tx.Hash(),\n\t\t\t\t\tIndex: uint32(i),\n\t\t\t\t}\n\t\t\t\tfilter.addUnspentOutPoint(&op)\n\n\t\t\t\tif !added {\n\t\t\t\t\ttransactions = append(\n\t\t\t\t\t\ttransactions,\n\t\t\t\t\t\ttxHexString(msgTx))\n\t\t\t\t\tadded = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfilter.mu.Unlock()\n\n\treturn transactions\n}\n\n// handleRescanBlocks implements the rescanblocks command extension for\n// websocket connections.\n//\n// NOTE: This extension is ported from github.com/decred/dcrd\nfunc handleRescanBlocks(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.RescanBlocksCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\t// Load client's transaction filter.  Must exist in order to continue.\n\twsc.Lock()\n\tfilter := wsc.filterData\n\twsc.Unlock()\n\tif filter == nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCMisc,\n\t\t\tMessage: \"Transaction filter must be loaded before rescanning\",\n\t\t}\n\t}\n\n\tblockHashes := make([]*chainhash.Hash, len(cmd.BlockHashes))\n\n\tfor i := range cmd.BlockHashes {\n\t\thash, err := chainhash.NewHashFromStr(cmd.BlockHashes[i])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tblockHashes[i] = hash\n\t}\n\n\tdiscoveredData := make([]btcjson.RescannedBlock, 0, len(blockHashes))\n\n\t// Iterate over each block in the request and rescan.  When a block\n\t// contains relevant transactions, add it to the response.\n\tbc := wsc.server.cfg.Chain\n\tparams := wsc.server.cfg.ChainParams\n\tvar lastBlockHash *chainhash.Hash\n\tfor i := range blockHashes {\n\t\tblock, err := bc.BlockByHash(blockHashes[i])\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\t\tMessage: \"Failed to fetch block: \" + err.Error(),\n\t\t\t}\n\t\t}\n\t\tif lastBlockHash != nil && block.MsgBlock().Header.PrevBlock != *lastBlockHash {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode: btcjson.ErrRPCInvalidParameter,\n\t\t\t\tMessage: fmt.Sprintf(\"Block %v is not a child of %v\",\n\t\t\t\t\tblockHashes[i], lastBlockHash),\n\t\t\t}\n\t\t}\n\t\tlastBlockHash = blockHashes[i]\n\n\t\ttransactions := rescanBlockFilter(filter, block, params)\n\t\tif len(transactions) != 0 {\n\t\t\tdiscoveredData = append(discoveredData, btcjson.RescannedBlock{\n\t\t\t\tHash:         cmd.BlockHashes[i],\n\t\t\t\tTransactions: transactions,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn &discoveredData, nil\n}\n\n// recoverFromReorg attempts to recover from a detected reorganize during a\n// rescan.  It fetches a new range of block shas from the database and\n// verifies that the new range of blocks is on the same fork as a previous\n// range of blocks.  If this condition does not hold true, the JSON-RPC error\n// for an unrecoverable reorganize is returned.\nfunc recoverFromReorg(chain *blockchain.BlockChain, minBlock, maxBlock int32,\n\tlastBlock *chainhash.Hash) ([]chainhash.Hash, error) {\n\n\thashList, err := chain.HeightRange(minBlock, maxBlock)\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Error looking up block range: %v\", err)\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDatabase,\n\t\t\tMessage: \"Database error: \" + err.Error(),\n\t\t}\n\t}\n\tif lastBlock == nil || len(hashList) == 0 {\n\t\treturn hashList, nil\n\t}\n\n\tblk, err := chain.BlockByHash(&hashList[0])\n\tif err != nil {\n\t\trpcsLog.Errorf(\"Error looking up possibly reorged block: %v\",\n\t\t\terr)\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCDatabase,\n\t\t\tMessage: \"Database error: \" + err.Error(),\n\t\t}\n\t}\n\tjsonErr := descendantBlock(lastBlock, blk)\n\tif jsonErr != nil {\n\t\treturn nil, jsonErr\n\t}\n\treturn hashList, nil\n}\n\n// descendantBlock returns the appropriate JSON-RPC error if a current block\n// fetched during a reorganize is not a direct child of the parent block hash.\nfunc descendantBlock(prevHash *chainhash.Hash, curBlock *btcutil.Block) error {\n\tcurHash := &curBlock.MsgBlock().Header.PrevBlock\n\tif !prevHash.IsEqual(curHash) {\n\t\trpcsLog.Errorf(\"Stopping rescan for reorged block %v \"+\n\t\t\t\"(replaced by block %v)\", prevHash, curHash)\n\t\treturn &ErrRescanReorg\n\t}\n\treturn nil\n}\n\n// scanBlockChunks executes a rescan in chunked stages. We do this to limit the\n// amount of memory that we'll allocate to a given rescan. Every so often,\n// we'll send back a rescan progress notification to the websockets client. The\n// final block and block hash that we've scanned will be returned.\nfunc scanBlockChunks(wsc *wsClient, cmd *btcjson.RescanCmd, lookups *rescanKeys, minBlock,\n\tmaxBlock int32, chain *blockchain.BlockChain) (\n\t*btcutil.Block, *chainhash.Hash, error) {\n\n\t// lastBlock and lastBlockHash track the previously-rescanned block.\n\t// They equal nil when no previous blocks have been rescanned.\n\tvar (\n\t\tlastBlock     *btcutil.Block\n\t\tlastBlockHash *chainhash.Hash\n\t)\n\n\t// A ticker is created to wait at least 10 seconds before notifying the\n\t// websocket client of the current progress completed by the rescan.\n\tticker := time.NewTicker(10 * time.Second)\n\tdefer ticker.Stop()\n\n\t// Instead of fetching all block shas at once, fetch in smaller chunks\n\t// to ensure large rescans consume a limited amount of memory.\nfetchRange:\n\tfor minBlock < maxBlock {\n\t\t// Limit the max number of hashes to fetch at once to the\n\t\t// maximum number of items allowed in a single inventory.\n\t\t// This value could be higher since it's not creating inventory\n\t\t// messages, but this mirrors the limiting logic used in the\n\t\t// peer-to-peer protocol.\n\t\tmaxLoopBlock := maxBlock\n\t\tif maxLoopBlock-minBlock > wire.MaxInvPerMsg {\n\t\t\tmaxLoopBlock = minBlock + wire.MaxInvPerMsg\n\t\t}\n\t\thashList, err := chain.HeightRange(minBlock, maxLoopBlock)\n\t\tif err != nil {\n\t\t\trpcsLog.Errorf(\"Error looking up block range: %v\", err)\n\t\t\treturn nil, nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCDatabase,\n\t\t\t\tMessage: \"Database error: \" + err.Error(),\n\t\t\t}\n\t\t}\n\t\tif len(hashList) == 0 {\n\t\t\t// The rescan is finished if no blocks hashes for this\n\t\t\t// range were successfully fetched and a stop block\n\t\t\t// was provided.\n\t\t\tif maxBlock != math.MaxInt32 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// If the rescan is through the current block, set up\n\t\t\t// the client to continue to receive notifications\n\t\t\t// regarding all rescanned addresses and the current set\n\t\t\t// of unspent outputs.\n\t\t\t//\n\t\t\t// This is done safely by temporarily grabbing exclusive\n\t\t\t// access of the block manager.  If no more blocks have\n\t\t\t// been attached between this pause and the fetch above,\n\t\t\t// then it is safe to register the websocket client for\n\t\t\t// continuous notifications if necessary.  Otherwise,\n\t\t\t// continue the fetch loop again to rescan the new\n\t\t\t// blocks (or error due to an irrecoverable reorganize).\n\t\t\tpauseGuard := wsc.server.cfg.SyncMgr.Pause()\n\t\t\tbest := wsc.server.cfg.Chain.BestSnapshot()\n\t\t\tcurHash := &best.Hash\n\t\t\tagain := true\n\t\t\tif lastBlockHash == nil || *lastBlockHash == *curHash {\n\t\t\t\tagain = false\n\t\t\t\tn := wsc.server.ntfnMgr\n\t\t\t\tn.RegisterSpentRequests(wsc, lookups.unspentSlice())\n\t\t\t\tn.RegisterTxOutAddressRequests(wsc, cmd.Addresses)\n\t\t\t}\n\t\t\tclose(pauseGuard)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Error fetching best block \"+\n\t\t\t\t\t\"hash: %v\", err)\n\t\t\t\treturn nil, nil, &btcjson.RPCError{\n\t\t\t\t\tCode: btcjson.ErrRPCDatabase,\n\t\t\t\t\tMessage: \"Database error: \" +\n\t\t\t\t\t\terr.Error(),\n\t\t\t\t}\n\t\t\t}\n\t\t\tif again {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\tloopHashList:\n\t\tfor i := range hashList {\n\t\t\tblk, err := chain.BlockByHash(&hashList[i])\n\t\t\tif err != nil {\n\t\t\t\t// Only handle reorgs if a block could not be\n\t\t\t\t// found for the hash.\n\t\t\t\tif dbErr, ok := err.(database.Error); !ok ||\n\t\t\t\t\tdbErr.ErrorCode != database.ErrBlockNotFound {\n\n\t\t\t\t\trpcsLog.Errorf(\"Error looking up \"+\n\t\t\t\t\t\t\"block: %v\", err)\n\t\t\t\t\treturn nil, nil, &btcjson.RPCError{\n\t\t\t\t\t\tCode: btcjson.ErrRPCDatabase,\n\t\t\t\t\t\tMessage: \"Database error: \" +\n\t\t\t\t\t\t\terr.Error(),\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If an absolute max block was specified, don't\n\t\t\t\t// attempt to handle the reorg.\n\t\t\t\tif maxBlock != math.MaxInt32 {\n\t\t\t\t\trpcsLog.Errorf(\"Stopping rescan for \"+\n\t\t\t\t\t\t\"reorged block %v\",\n\t\t\t\t\t\tcmd.EndBlock)\n\t\t\t\t\treturn nil, nil, &ErrRescanReorg\n\t\t\t\t}\n\n\t\t\t\t// If the lookup for the previously valid block\n\t\t\t\t// hash failed, there may have been a reorg.\n\t\t\t\t// Fetch a new range of block hashes and verify\n\t\t\t\t// that the previously processed block (if there\n\t\t\t\t// was any) still exists in the database.  If it\n\t\t\t\t// doesn't, we error.\n\t\t\t\t//\n\t\t\t\t// A goto is used to branch execution back to\n\t\t\t\t// before the range was evaluated, as it must be\n\t\t\t\t// reevaluated for the new hashList.\n\t\t\t\tminBlock += int32(i)\n\t\t\t\thashList, err = recoverFromReorg(\n\t\t\t\t\tchain, minBlock, maxBlock, lastBlockHash,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, nil, err\n\t\t\t\t}\n\t\t\t\tif len(hashList) == 0 {\n\t\t\t\t\tbreak fetchRange\n\t\t\t\t}\n\t\t\t\tgoto loopHashList\n\t\t\t}\n\t\t\tif i == 0 && lastBlockHash != nil {\n\t\t\t\t// Ensure the new hashList is on the same fork\n\t\t\t\t// as the last block from the old hashList.\n\t\t\t\tjsonErr := descendantBlock(lastBlockHash, blk)\n\t\t\t\tif jsonErr != nil {\n\t\t\t\t\treturn nil, nil, jsonErr\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// A select statement is used to stop rescans if the\n\t\t\t// client requesting the rescan has disconnected.\n\t\t\tselect {\n\t\t\tcase <-wsc.quit:\n\t\t\t\trpcsLog.Debugf(\"Stopped rescan at height %v \"+\n\t\t\t\t\t\"for disconnected client\", blk.Height())\n\t\t\t\treturn nil, nil, nil\n\t\t\tdefault:\n\t\t\t\trescanBlock(wsc, lookups, blk)\n\t\t\t\tlastBlock = blk\n\t\t\t\tlastBlockHash = blk.Hash()\n\t\t\t}\n\n\t\t\t// Periodically notify the client of the progress\n\t\t\t// completed.  Continue with next block if no progress\n\t\t\t// notification is needed yet.\n\t\t\tselect {\n\t\t\tcase <-ticker.C: // fallthrough\n\t\t\tdefault:\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tn := btcjson.NewRescanProgressNtfn(\n\t\t\t\thashList[i].String(), blk.Height(),\n\t\t\t\tblk.MsgBlock().Header.Timestamp.Unix(),\n\t\t\t)\n\t\t\tmn, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, n)\n\t\t\tif err != nil {\n\t\t\t\trpcsLog.Errorf(\"Failed to marshal rescan \"+\n\t\t\t\t\t\"progress notification: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err = wsc.QueueNotification(mn); err == ErrClientQuit {\n\t\t\t\t// Finished if the client disconnected.\n\t\t\t\trpcsLog.Debugf(\"Stopped rescan at height %v \"+\n\t\t\t\t\t\"for disconnected client\", blk.Height())\n\t\t\t\treturn nil, nil, nil\n\t\t\t}\n\t\t}\n\n\t\tminBlock += int32(len(hashList))\n\t}\n\n\treturn lastBlock, lastBlockHash, nil\n}\n\n// handleRescan implements the rescan command extension for websocket\n// connections.\n//\n// NOTE: This does not smartly handle reorgs, and fixing requires database\n// changes (for safe, concurrent access to full block ranges, and support\n// for other chains than the best chain).  It will, however, detect whether\n// a reorg removed a block that was previously processed, and result in the\n// handler erroring.  Clients must handle this by finding a block still in\n// the chain (perhaps from a rescanprogress notification) to resume their\n// rescan.\nfunc handleRescan(wsc *wsClient, icmd interface{}) (interface{}, error) {\n\tcmd, ok := icmd.(*btcjson.RescanCmd)\n\tif !ok {\n\t\treturn nil, btcjson.ErrRPCInternal\n\t}\n\n\toutpoints := make([]*wire.OutPoint, 0, len(cmd.OutPoints))\n\tfor i := range cmd.OutPoints {\n\t\tcmdOutpoint := &cmd.OutPoints[i]\n\t\tblockHash, err := chainhash.NewHashFromStr(cmdOutpoint.Hash)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(cmdOutpoint.Hash)\n\t\t}\n\t\toutpoint := wire.NewOutPoint(blockHash, cmdOutpoint.Index)\n\t\toutpoints = append(outpoints, outpoint)\n\t}\n\n\tnumAddrs := len(cmd.Addresses)\n\tif numAddrs == 1 {\n\t\trpcsLog.Info(\"Beginning rescan for 1 address\")\n\t} else {\n\t\trpcsLog.Infof(\"Beginning rescan for %d addresses\", numAddrs)\n\t}\n\n\t// Build lookup maps.\n\tlookups := rescanKeys{\n\t\taddrs:   map[string]struct{}{},\n\t\tunspent: map[wire.OutPoint]struct{}{},\n\t}\n\tfor _, addrStr := range cmd.Addresses {\n\t\tlookups.addrs[addrStr] = struct{}{}\n\t}\n\tfor _, outpoint := range outpoints {\n\t\tlookups.unspent[*outpoint] = struct{}{}\n\t}\n\n\tchain := wsc.server.cfg.Chain\n\n\tminBlockHash, err := chainhash.NewHashFromStr(cmd.BeginBlock)\n\tif err != nil {\n\t\treturn nil, rpcDecodeHexError(cmd.BeginBlock)\n\t}\n\tminBlock, err := chain.BlockHeightByHash(minBlockHash)\n\tif err != nil {\n\t\treturn nil, &btcjson.RPCError{\n\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\tMessage: \"Error getting block: \" + err.Error(),\n\t\t}\n\t}\n\n\tmaxBlock := int32(math.MaxInt32)\n\tif cmd.EndBlock != nil {\n\t\tmaxBlockHash, err := chainhash.NewHashFromStr(*cmd.EndBlock)\n\t\tif err != nil {\n\t\t\treturn nil, rpcDecodeHexError(*cmd.EndBlock)\n\t\t}\n\t\tmaxBlock, err = chain.BlockHeightByHash(maxBlockHash)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\t\tMessage: \"Error getting block: \" + err.Error(),\n\t\t\t}\n\t\t}\n\t}\n\n\tvar (\n\t\tlastBlock     *btcutil.Block\n\t\tlastBlockHash *chainhash.Hash\n\t)\n\tif len(lookups.addrs) != 0 || len(lookups.unspent) != 0 {\n\t\t// With all the arguments parsed, we'll execute our chunked rescan\n\t\t// which will notify the clients of any address deposits or output\n\t\t// spends.\n\t\tlastBlock, lastBlockHash, err = scanBlockChunks(\n\t\t\twsc, cmd, &lookups, minBlock, maxBlock, chain,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// If the last block is nil, then this means that the client\n\t\t// disconnected mid-rescan. As a result, we don't need to send\n\t\t// anything back to them.\n\t\tif lastBlock == nil {\n\t\t\treturn nil, nil\n\t\t}\n\t} else {\n\t\trpcsLog.Infof(\"Skipping rescan as client has no addrs/utxos\")\n\n\t\t// If we didn't actually do a rescan, then we'll give the\n\t\t// client our best known block within the final rescan finished\n\t\t// notification.\n\t\tchainTip := chain.BestSnapshot()\n\t\tlastBlockHash = &chainTip.Hash\n\t\tlastBlock, err = chain.BlockByHash(lastBlockHash)\n\t\tif err != nil {\n\t\t\treturn nil, &btcjson.RPCError{\n\t\t\t\tCode:    btcjson.ErrRPCBlockNotFound,\n\t\t\t\tMessage: \"Error getting block: \" + err.Error(),\n\t\t\t}\n\t\t}\n\t}\n\n\t// Notify websocket client of the finished rescan.  Due to how btcd\n\t// asynchronously queues notifications to not block calling code,\n\t// there is no guarantee that any of the notifications created during\n\t// rescan (such as rescanprogress, recvtx and redeemingtx) will be\n\t// received before the rescan RPC returns.  Therefore, another method\n\t// is needed to safely inform clients that all rescan notifications have\n\t// been sent.\n\tn := btcjson.NewRescanFinishedNtfn(\n\t\tlastBlockHash.String(), lastBlock.Height(),\n\t\tlastBlock.MsgBlock().Header.Timestamp.Unix(),\n\t)\n\tif mn, err := btcjson.MarshalCmd(btcjson.RpcVersion1, nil, n); err != nil {\n\t\trpcsLog.Errorf(\"Failed to marshal rescan finished \"+\n\t\t\t\"notification: %v\", err)\n\t} else {\n\t\t// The rescan is finished, so we don't care whether the client\n\t\t// has disconnected at this point, so discard error.\n\t\t_ = wsc.QueueNotification(mn)\n\t}\n\n\trpcsLog.Info(\"Finished rescan\")\n\treturn nil, nil\n}\n\nfunc init() {\n\twsHandlers = wsHandlersBeforeInit\n}\n"
        },
        {
          "name": "sample-btcd.conf",
          "type": "blob",
          "size": 13.6591796875,
          "content": "[Application Options]\n\n; ------------------------------------------------------------------------------\n; Data settings\n; ------------------------------------------------------------------------------\n\n; The directory to store data such as the block chain and peer addresses.  The\n; block chain takes several GB, so this location must have a lot of free space.\n; The default is ~/.btcd/data on POSIX OSes, $LOCALAPPDATA/Btcd/data on Windows,\n; ~/Library/Application Support/Btcd/data on Mac OS, and $home/btcd/data on\n; Plan9.  Environment variables are expanded so they may be used.  NOTE: Windows\n; environment variables are typically %VARIABLE%, but they must be accessed with\n; $VARIABLE here.  Also, ~ is expanded to $LOCALAPPDATA on Windows.\n; datadir=~/.btcd/data\n\n; The prune option removes old blocks from disk after they're downloaded and\n; verified.  The smallest value is 1536 which will limit the block data to 1536\n; mebibytes.\n; NOTE: This limit does not apply to indexes and the UTXO set which are both\n; larger than 1536 mebibytes as of December 2024.\n; prune=1536\n\n; ------------------------------------------------------------------------------\n; Network settings\n; ------------------------------------------------------------------------------\n\n; Use testnet.\n; testnet=1\n\n; Connect via a SOCKS5 proxy.  NOTE: Specifying a proxy will disable listening\n; for incoming connections unless listen addresses are provided via the 'listen'\n; option.\n; proxy=127.0.0.1:9050\n; proxyuser=\n; proxypass=\n\n; The SOCKS5 proxy above is assumed to be Tor (https://www.torproject.org).\n; If the proxy is not tor the following may be used to prevent using tor\n; specific SOCKS queries to lookup addresses (this increases anonymity when tor\n; is used by preventing your IP being leaked via DNS).\n; noonion=1\n\n; Use an alternative proxy to connect to .onion addresses. The proxy is assumed\n; to be a Tor node. Non .onion addresses will be contacted with the main proxy\n; or without a proxy if none is set.\n; onion=127.0.0.1:9051\n; onionuser=\n; onionpass=\n\n; Enable Tor stream isolation by randomizing proxy user credentials resulting in\n; Tor creating a new circuit for each connection.  This makes it more difficult\n; to correlate connections.\n; torisolation=1\n\n; Use Universal Plug and Play (UPnP) to automatically open the listen port\n; and obtain the external IP address from supported devices.  NOTE: This option\n; will have no effect if external IP addresses are specified.\n; upnp=1\n\n; Specify the external IP addresses your node is listening on.  One address per\n; line.  btcd will not contact 3rd-party sites to obtain external ip addresses.\n; This means if you are behind NAT, your node will not be able to advertise a\n; reachable address unless you specify it here or enable the 'upnp' option (and\n; have a supported device).\n; externalip=1.2.3.4\n; externalip=2002::1234\n\n; ******************************************************************************\n; Summary of 'addpeer' versus 'connect'.\n;\n; Only one of the following two options, 'addpeer' and 'connect', may be\n; specified.  Both allow you to specify peers that you want to stay connected\n; with, but the behavior is slightly different.  By default, btcd will query DNS\n; to find peers to connect to, so unless you have a specific reason such as\n; those described below, you probably won't need to modify anything here.\n;\n; 'addpeer' does not prevent connections to other peers discovered from\n; the peers you are connected to and also lets the remote peers know you are\n; available so they can notify other peers they can to connect to you.  This\n; option might be useful if you are having problems finding a node for some\n; reason (perhaps due to a firewall).\n;\n; 'connect', on the other hand, will ONLY connect to the specified peers and\n; no others.  It also disables listening (unless you explicitly set listen\n; addresses via the 'listen' option) and DNS seeding, so you will not be\n; advertised as an available peer to the peers you connect to and won't accept\n; connections from any other peers.  So, the 'connect' option effectively allows\n; you to only connect to \"trusted\" peers.\n; ******************************************************************************\n\n; Add persistent peers to connect to as desired.  One peer per line.\n; You may specify each IP address with or without a port.  The default port will\n; be added automatically if one is not specified here.\n; addpeer=192.168.1.1\n; addpeer=10.0.0.2:8333\n; addpeer=fe80::1\n; addpeer=[fe80::2]:8333\n\n; Add persistent peers that you ONLY want to connect to as desired.  One peer\n; per line.  You may specify each IP address with or without a port.  The\n; default port will be added automatically if one is not specified here.\n; NOTE: Specifying this option has other side effects as described above in\n; the 'addpeer' versus 'connect' summary section.\n; connect=192.168.1.1\n; connect=10.0.0.2:8333\n; connect=fe80::1\n; connect=[fe80::2]:8333\n\n; Maximum number of inbound and outbound peers.\n; maxpeers=125\n\n; Disable banning of misbehaving peers.\n; nobanning=1\n\n; Maximum allowed ban score before disconnecting and banning misbehaving peers.\n; banthreshold=100\n\n; How long to ban misbehaving peers. Valid time units are {s, m, h}.\n; Minimum 1s.\n; banduration=24h\n; banduration=11h30m15s\n\n; Add whitelisted IP networks and IPs. Connected peers whose IP matches a\n; whitelist will not have their ban score increased.\n; whitelist=127.0.0.1\n; whitelist=::1\n; whitelist=192.168.0.0/24\n; whitelist=fd00::/16\n\n; Disable DNS seeding for peers.  By default, when btcd starts, it will use\n; DNS to query for available peers to connect with.\n; nodnsseed=1\n\n; Specify the interfaces to listen on.  One listen address per line.\n; NOTE: The default port is modified by some options such as 'testnet', so it is\n; recommended to not specify a port and allow a proper default to be chosen\n; unless you have a specific reason to do otherwise.\n; All interfaces on default port (this is the default):\n;  listen=\n; All ipv4 interfaces on default port:\n;  listen=0.0.0.0\n; All ipv6 interfaces on default port:\n;   listen=::\n; All interfaces on port 8333:\n;   listen=:8333\n; All ipv4 interfaces on port 8333:\n;   listen=0.0.0.0:8333\n; All ipv6 interfaces on port 8333:\n;   listen=[::]:8333\n; Only ipv4 localhost on port 8333:\n;   listen=127.0.0.1:8333\n; Only ipv6 localhost on port 8333:\n;   listen=[::1]:8333\n; Only ipv4 localhost on non-standard port 8336:\n;   listen=127.0.0.1:8336\n; All interfaces on non-standard port 8336:\n;   listen=:8336\n; All ipv4 interfaces on non-standard port 8336:\n;   listen=0.0.0.0:8336\n; All ipv6 interfaces on non-standard port 8336:\n;   listen=[::]:8336\n\n; Disable listening for incoming connections.  This will override all listeners.\n; nolisten=1\n\n; Disable peer bloom filtering.  See BIP0111.\n; nopeerbloomfilters=1\n\n; Add additional checkpoints. Format: '<height>:<hash>'\n; addcheckpoint=<height>:<hash>\n\n; Add comments to the user agent that is advertised to peers.\n; Must not include characters '/', ':', '(' and ')'.\n; uacomment=\n\n; Disable committed peer filtering (CF).\n; nocfilters=1\n\n; ------------------------------------------------------------------------------\n; RPC server options - The following options control the built-in RPC server\n; which is used to control and query information from a running btcd process.\n;\n; NOTE: The RPC server is disabled by default if rpcuser AND rpcpass, or\n; rpclimituser AND rpclimitpass, are not specified.\n; ------------------------------------------------------------------------------\n\n; Secure the RPC API by specifying the username and password.  You can also\n; specify a limited username and password.  You must specify at least one\n; full set of credentials - limited or admin - or the RPC server will\n; be disabled.\n; rpcuser=whatever_admin_username_you_want\n; rpcpass=\n; rpclimituser=whatever_limited_username_you_want\n; rpclimitpass=\n\n; Specify the interfaces for the RPC server listen on.  One listen address per\n; line.  NOTE: The default port is modified by some options such as 'testnet',\n; so it is recommended to not specify a port and allow a proper default to be\n; chosen unless you have a specific reason to do otherwise.  By default, the\n; RPC server will only listen on localhost for IPv4 and IPv6.\n; All interfaces on default port:\n;   rpclisten=\n; All ipv4 interfaces on default port:\n;   rpclisten=0.0.0.0\n; All ipv6 interfaces on default port:\n;   rpclisten=::\n; All interfaces on port 8334:\n;   rpclisten=:8334\n; All ipv4 interfaces on port 8334:\n;   rpclisten=0.0.0.0:8334\n; All ipv6 interfaces on port 8334:\n;   rpclisten=[::]:8334\n; Only ipv4 localhost on port 8334:\n;   rpclisten=127.0.0.1:8334\n; Only ipv6 localhost on port 8334:\n;   rpclisten=[::1]:8334\n; Only ipv4 localhost on non-standard port 8337:\n;   rpclisten=127.0.0.1:8337\n; All interfaces on non-standard port 8337:\n;   rpclisten=:8337\n; All ipv4 interfaces on non-standard port 8337:\n;   rpclisten=0.0.0.0:8337\n; All ipv6 interfaces on non-standard port 8337:\n;   rpclisten=[::]:8337\n\n; Specify the maximum number of concurrent RPC clients for standard connections.\n; rpcmaxclients=10\n\n; Specify the maximum number of concurrent RPC websocket clients.\n; rpcmaxwebsockets=25\n\n; Mirror some JSON-RPC quirks of Bitcoin Core -- NOTE: Discouraged unless\n; interoperability issues need to be worked around\n; rpcquirks=1\n\n; Use the following setting to disable the RPC server even if the rpcuser and\n; rpcpass are specified above.  This allows one to quickly disable the RPC\n; server without having to remove credentials from the config file.\n; norpc=1\n\n; Use the following setting to disable TLS for the RPC server.  NOTE: This\n; option only works if the RPC server is bound to localhost interfaces (which is\n; the default).\n; notls=1\n\n\n; ------------------------------------------------------------------------------\n; Mempool Settings - The following options\n; ------------------------------------------------------------------------------\n\n; Set the minimum transaction fee to be considered a non-zero fee,\n; minrelaytxfee=0.00001\n\n; Rate-limit free transactions to the value 15 * 1000 bytes per\n; minute.\n; limitfreerelay=15\n\n; Require high priority for relaying free or low-fee transactions.\n; norelaypriority=0\n\n; Limit orphan transaction pool to 100 transactions.\n; maxorphantx=100\n\n; Do not accept transactions from remote peers.\n; blocksonly=1\n\n; Relay non-standard transactions regardless of default network settings.\n; relaynonstd=1\n\n; Reject non-standard transactions regardless of default network settings.\n; rejectnonstd=1\n\n\n; ------------------------------------------------------------------------------\n; Optional Indexes\n; ------------------------------------------------------------------------------\n\n; Build and maintain a full hash-based transaction index which makes all\n; transactions available via the getrawtransaction RPC.\n; txindex=1\n\n; Build and maintain a full address-based transaction index which makes the\n; searchrawtransactions RPC available.\n; addrindex=1\n\n; Delete the entire address index on start up, then exit.\n; dropaddrindex=0\n\n\n; ------------------------------------------------------------------------------\n; Signature Verification Cache\n; ------------------------------------------------------------------------------\n\n; Limit the signature cache to a max of 50000 entries.\n; sigcachemaxsize=50000\n\n\n; ------------------------------------------------------------------------------\n; Coin Generation (Mining) Settings - The following options control the\n; generation of block templates used by external mining applications through RPC\n; calls as well as the built-in CPU miner (if enabled).\n; ------------------------------------------------------------------------------\n\n; Enable built-in CPU mining.\n;\n; NOTE: This is typically only useful for testing purposes such as testnet or\n; simnet since the difficulty on mainnet is far too high for CPU mining to be\n; worth your while.\n; generate=false\n\n; Add addresses to pay mined blocks to for CPU mining and potentially in the\n; block templates generated for the getblocktemplate RPC.  One address per line.\n; miningaddr=1yourbitcoinaddress\n; miningaddr=1yourbitcoinaddress2\n; miningaddr=1yourbitcoinaddress3\n\n; Specify the minimum block size in bytes to create.  By default, only\n; transactions which have enough fees or a high enough priority will be included\n; in generated block templates.  Specifying a minimum block size will instead\n; attempt to fill generated block templates up with transactions until it is at\n; least the specified number of bytes.\n; blockminsize=0\n\n; Specify the maximum block size in bytes to create.  This value will be limited\n; to the consensus limit if it is larger than that value.\n; blockmaxsize=750000\n\n; Specify the size in bytes of the high-priority/low-fee area when creating a\n; block.  Transactions which consist of large amounts, old inputs, and small\n; sizes have the highest priority.  One consequence of this is that as low-fee\n; or free transactions age, they raise in priority thereby making them more\n; likely to be included in this section of a new block.  This value is limited\n; by the blockmaxsize option and will be limited as needed.\n; blockprioritysize=50000\n\n\n; ------------------------------------------------------------------------------\n; Debug\n; ------------------------------------------------------------------------------\n\n; Debug logging level.\n; Valid levels are {trace, debug, info, warn, error, critical}\n; You may also specify <subsystem>=<level>,<subsystem2>=<level>,... to set\n; log level for individual subsystems.  Use btcd --debuglevel=show to list\n; available subsystems.\n; debuglevel=info\n\n; The port used to listen for HTTP profile requests.  The profile server will\n; be disabled if this option is not specified.  The profile information can be\n; accessed at http://localhost:<profileport>/debug/pprof once running.\n; profile=6061\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "server.go",
          "type": "blob",
          "size": 103.2421875,
          "content": "// Copyright (c) 2013-2017 The btcsuite developers\n// Copyright (c) 2015-2018 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"bytes\"\n\t\"crypto/rand\"\n\t\"crypto/tls\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"net\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/btcsuite/btcd/addrmgr\"\n\t\"github.com/btcsuite/btcd/blockchain\"\n\t\"github.com/btcsuite/btcd/blockchain/indexers\"\n\t\"github.com/btcsuite/btcd/btcutil\"\n\t\"github.com/btcsuite/btcd/btcutil/bloom\"\n\t\"github.com/btcsuite/btcd/chaincfg\"\n\t\"github.com/btcsuite/btcd/chaincfg/chainhash\"\n\t\"github.com/btcsuite/btcd/connmgr\"\n\t\"github.com/btcsuite/btcd/database\"\n\t\"github.com/btcsuite/btcd/mempool\"\n\t\"github.com/btcsuite/btcd/mining\"\n\t\"github.com/btcsuite/btcd/mining/cpuminer\"\n\t\"github.com/btcsuite/btcd/netsync\"\n\t\"github.com/btcsuite/btcd/peer\"\n\t\"github.com/btcsuite/btcd/txscript\"\n\t\"github.com/btcsuite/btcd/wire\"\n\t\"github.com/decred/dcrd/lru\"\n)\n\nconst (\n\t// defaultServices describes the default services that are supported by\n\t// the server.\n\tdefaultServices = wire.SFNodeNetwork | wire.SFNodeNetworkLimited |\n\t\twire.SFNodeBloom | wire.SFNodeWitness | wire.SFNodeCF\n\n\t// defaultRequiredServices describes the default services that are\n\t// required to be supported by outbound peers.\n\tdefaultRequiredServices = wire.SFNodeNetwork\n\n\t// defaultTargetOutbound is the default number of outbound peers to target.\n\tdefaultTargetOutbound = 8\n\n\t// connectionRetryInterval is the base amount of time to wait in between\n\t// retries when connecting to persistent peers.  It is adjusted by the\n\t// number of retries such that there is a retry backoff.\n\tconnectionRetryInterval = time.Second * 5\n)\n\nvar (\n\t// userAgentName is the user agent name and is used to help identify\n\t// ourselves to other bitcoin peers.\n\tuserAgentName = \"btcd\"\n\n\t// userAgentVersion is the user agent version and is used to help\n\t// identify ourselves to other bitcoin peers.\n\tuserAgentVersion = fmt.Sprintf(\"%d.%d.%d\", appMajor, appMinor, appPatch)\n)\n\n// zeroHash is the zero value hash (all zeros).  It is defined as a convenience.\nvar zeroHash chainhash.Hash\n\n// onionAddr implements the net.Addr interface and represents a tor address.\ntype onionAddr struct {\n\taddr string\n}\n\n// String returns the onion address.\n//\n// This is part of the net.Addr interface.\nfunc (oa *onionAddr) String() string {\n\treturn oa.addr\n}\n\n// Network returns \"onion\".\n//\n// This is part of the net.Addr interface.\nfunc (oa *onionAddr) Network() string {\n\treturn \"onion\"\n}\n\n// Ensure onionAddr implements the net.Addr interface.\nvar _ net.Addr = (*onionAddr)(nil)\n\n// simpleAddr implements the net.Addr interface with two struct fields\ntype simpleAddr struct {\n\tnet, addr string\n}\n\n// String returns the address.\n//\n// This is part of the net.Addr interface.\nfunc (a simpleAddr) String() string {\n\treturn a.addr\n}\n\n// Network returns the network.\n//\n// This is part of the net.Addr interface.\nfunc (a simpleAddr) Network() string {\n\treturn a.net\n}\n\n// Ensure simpleAddr implements the net.Addr interface.\nvar _ net.Addr = simpleAddr{}\n\n// broadcastMsg provides the ability to house a bitcoin message to be broadcast\n// to all connected peers except specified excluded peers.\ntype broadcastMsg struct {\n\tmessage      wire.Message\n\texcludePeers []*serverPeer\n}\n\n// broadcastInventoryAdd is a type used to declare that the InvVect it contains\n// needs to be added to the rebroadcast map\ntype broadcastInventoryAdd relayMsg\n\n// broadcastInventoryDel is a type used to declare that the InvVect it contains\n// needs to be removed from the rebroadcast map\ntype broadcastInventoryDel *wire.InvVect\n\n// relayMsg packages an inventory vector along with the newly discovered\n// inventory so the relay has access to that information.\ntype relayMsg struct {\n\tinvVect *wire.InvVect\n\tdata    interface{}\n}\n\n// updatePeerHeightsMsg is a message sent from the blockmanager to the server\n// after a new block has been accepted. The purpose of the message is to update\n// the heights of peers that were known to announce the block before we\n// connected it to the main chain or recognized it as an orphan. With these\n// updates, peer heights will be kept up to date, allowing for fresh data when\n// selecting sync peer candidacy.\ntype updatePeerHeightsMsg struct {\n\tnewHash    *chainhash.Hash\n\tnewHeight  int32\n\toriginPeer *peer.Peer\n}\n\n// peerState maintains state of inbound, persistent, outbound peers as well\n// as banned peers and outbound groups.\ntype peerState struct {\n\tinboundPeers    map[int32]*serverPeer\n\toutboundPeers   map[int32]*serverPeer\n\tpersistentPeers map[int32]*serverPeer\n\tbanned          map[string]time.Time\n\toutboundGroups  map[string]int\n}\n\n// Count returns the count of all known peers.\nfunc (ps *peerState) Count() int {\n\treturn len(ps.inboundPeers) + len(ps.outboundPeers) +\n\t\tlen(ps.persistentPeers)\n}\n\n// forAllOutboundPeers is a helper function that runs closure on all outbound\n// peers known to peerState.\nfunc (ps *peerState) forAllOutboundPeers(closure func(sp *serverPeer)) {\n\tfor _, e := range ps.outboundPeers {\n\t\tclosure(e)\n\t}\n\tfor _, e := range ps.persistentPeers {\n\t\tclosure(e)\n\t}\n}\n\n// forAllPeers is a helper function that runs closure on all peers known to\n// peerState.\nfunc (ps *peerState) forAllPeers(closure func(sp *serverPeer)) {\n\tfor _, e := range ps.inboundPeers {\n\t\tclosure(e)\n\t}\n\tps.forAllOutboundPeers(closure)\n}\n\n// cfHeaderKV is a tuple of a filter header and its associated block hash. The\n// struct is used to cache cfcheckpt responses.\ntype cfHeaderKV struct {\n\tblockHash    chainhash.Hash\n\tfilterHeader chainhash.Hash\n}\n\n// server provides a bitcoin server for handling communications to and from\n// bitcoin peers.\ntype server struct {\n\t// The following variables must only be used atomically.\n\t// Putting the uint64s first makes them 64-bit aligned for 32-bit systems.\n\tbytesReceived uint64 // Total bytes received from all peers since start.\n\tbytesSent     uint64 // Total bytes sent by all peers since start.\n\tstarted       int32\n\tshutdown      int32\n\tshutdownSched int32\n\tstartupTime   int64\n\n\tchainParams          *chaincfg.Params\n\taddrManager          *addrmgr.AddrManager\n\tconnManager          *connmgr.ConnManager\n\tsigCache             *txscript.SigCache\n\thashCache            *txscript.HashCache\n\trpcServer            *rpcServer\n\tsyncManager          *netsync.SyncManager\n\tchain                *blockchain.BlockChain\n\ttxMemPool            *mempool.TxPool\n\tcpuMiner             *cpuminer.CPUMiner\n\tmodifyRebroadcastInv chan interface{}\n\tnewPeers             chan *serverPeer\n\tdonePeers            chan *serverPeer\n\tbanPeers             chan *serverPeer\n\tquery                chan interface{}\n\trelayInv             chan relayMsg\n\tbroadcast            chan broadcastMsg\n\tpeerHeightsUpdate    chan updatePeerHeightsMsg\n\twg                   sync.WaitGroup\n\tquit                 chan struct{}\n\tnat                  NAT\n\tdb                   database.DB\n\ttimeSource           blockchain.MedianTimeSource\n\tservices             wire.ServiceFlag\n\n\t// The following fields are used for optional indexes.  They will be nil\n\t// if the associated index is not enabled.  These fields are set during\n\t// initial creation of the server and never changed afterwards, so they\n\t// do not need to be protected for concurrent access.\n\ttxIndex   *indexers.TxIndex\n\taddrIndex *indexers.AddrIndex\n\tcfIndex   *indexers.CfIndex\n\n\t// The fee estimator keeps track of how long transactions are left in\n\t// the mempool before they are mined into blocks.\n\tfeeEstimator *mempool.FeeEstimator\n\n\t// cfCheckptCaches stores a cached slice of filter headers for cfcheckpt\n\t// messages for each filter type.\n\tcfCheckptCaches    map[wire.FilterType][]cfHeaderKV\n\tcfCheckptCachesMtx sync.RWMutex\n\n\t// agentBlacklist is a list of blacklisted substrings by which to filter\n\t// user agents.\n\tagentBlacklist []string\n\n\t// agentWhitelist is a list of whitelisted user agent substrings, no\n\t// whitelisting will be applied if the list is empty or nil.\n\tagentWhitelist []string\n}\n\n// serverPeer extends the peer to maintain state shared by the server and\n// the blockmanager.\ntype serverPeer struct {\n\t// The following variables must only be used atomically\n\tfeeFilter int64\n\n\t*peer.Peer\n\n\tconnReq        *connmgr.ConnReq\n\tserver         *server\n\tpersistent     bool\n\tcontinueHash   *chainhash.Hash\n\trelayMtx       sync.Mutex\n\tdisableRelayTx bool\n\tsentAddrs      bool\n\tisWhitelisted  bool\n\tfilter         *bloom.Filter\n\taddressesMtx   sync.RWMutex\n\tknownAddresses lru.Cache\n\tbanScore       connmgr.DynamicBanScore\n\tquit           chan struct{}\n\t// The following chans are used to sync blockmanager and server.\n\ttxProcessed    chan struct{}\n\tblockProcessed chan struct{}\n}\n\n// newServerPeer returns a new serverPeer instance. The peer needs to be set by\n// the caller.\nfunc newServerPeer(s *server, isPersistent bool) *serverPeer {\n\treturn &serverPeer{\n\t\tserver:         s,\n\t\tpersistent:     isPersistent,\n\t\tfilter:         bloom.LoadFilter(nil),\n\t\tknownAddresses: lru.NewCache(5000),\n\t\tquit:           make(chan struct{}),\n\t\ttxProcessed:    make(chan struct{}, 1),\n\t\tblockProcessed: make(chan struct{}, 1),\n\t}\n}\n\n// newestBlock returns the current best block hash and height using the format\n// required by the configuration for the peer package.\nfunc (sp *serverPeer) newestBlock() (*chainhash.Hash, int32, error) {\n\tbest := sp.server.chain.BestSnapshot()\n\treturn &best.Hash, best.Height, nil\n}\n\n// addKnownAddresses adds the given addresses to the set of known addresses to\n// the peer to prevent sending duplicate addresses.\nfunc (sp *serverPeer) addKnownAddresses(addresses []*wire.NetAddressV2) {\n\tsp.addressesMtx.Lock()\n\tfor _, na := range addresses {\n\t\tsp.knownAddresses.Add(addrmgr.NetAddressKey(na))\n\t}\n\tsp.addressesMtx.Unlock()\n}\n\n// addressKnown true if the given address is already known to the peer.\nfunc (sp *serverPeer) addressKnown(na *wire.NetAddressV2) bool {\n\tsp.addressesMtx.RLock()\n\texists := sp.knownAddresses.Contains(addrmgr.NetAddressKey(na))\n\tsp.addressesMtx.RUnlock()\n\treturn exists\n}\n\n// setDisableRelayTx toggles relaying of transactions for the given peer.\n// It is safe for concurrent access.\nfunc (sp *serverPeer) setDisableRelayTx(disable bool) {\n\tsp.relayMtx.Lock()\n\tsp.disableRelayTx = disable\n\tsp.relayMtx.Unlock()\n}\n\n// relayTxDisabled returns whether or not relaying of transactions for the given\n// peer is disabled.\n// It is safe for concurrent access.\nfunc (sp *serverPeer) relayTxDisabled() bool {\n\tsp.relayMtx.Lock()\n\tisDisabled := sp.disableRelayTx\n\tsp.relayMtx.Unlock()\n\n\treturn isDisabled\n}\n\n// pushAddrMsg sends a legacy addr message to the connected peer using the\n// provided addresses.\nfunc (sp *serverPeer) pushAddrMsg(addresses []*wire.NetAddressV2) {\n\tif sp.WantsAddrV2() {\n\t\t// If the peer supports addrv2, we'll be pushing an addrv2\n\t\t// message instead. The logic is otherwise identical to the\n\t\t// addr case below.\n\t\taddrs := make([]*wire.NetAddressV2, 0, len(addresses))\n\t\tfor _, addr := range addresses {\n\t\t\t// Filter addresses already known to the peer.\n\t\t\tif sp.addressKnown(addr) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\taddrs = append(addrs, addr)\n\t\t}\n\n\t\tknown, err := sp.PushAddrV2Msg(addrs)\n\t\tif err != nil {\n\t\t\tpeerLog.Errorf(\"Can't push addrv2 message to %s: %v\",\n\t\t\t\tsp.Peer, err)\n\t\t\tsp.Disconnect()\n\t\t\treturn\n\t\t}\n\n\t\t// Add the final set of addresses sent to the set the peer\n\t\t// knows of.\n\t\tsp.addKnownAddresses(known)\n\t\treturn\n\t}\n\n\taddrs := make([]*wire.NetAddress, 0, len(addresses))\n\tfor _, addr := range addresses {\n\t\t// Filter addresses already known to the peer.\n\t\tif sp.addressKnown(addr) {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Must skip the V3 addresses for legacy ADDR messages.\n\t\tif addr.IsTorV3() {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Convert the NetAddressV2 to a legacy address.\n\t\taddrs = append(addrs, addr.ToLegacy())\n\t}\n\n\tknown, err := sp.PushAddrMsg(addrs)\n\tif err != nil {\n\t\tpeerLog.Errorf(\n\t\t\t\"Can't push address message to %s: %v\", sp.Peer, err,\n\t\t)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\t// Convert all of the known addresses to NetAddressV2 to add them to\n\t// the set of known addresses.\n\tknownAddrs := make([]*wire.NetAddressV2, 0, len(known))\n\tfor _, knownAddr := range known {\n\t\tcurrentKna := wire.NetAddressV2FromBytes(\n\t\t\tknownAddr.Timestamp, knownAddr.Services,\n\t\t\tknownAddr.IP, knownAddr.Port,\n\t\t)\n\t\tknownAddrs = append(knownAddrs, currentKna)\n\t}\n\tsp.addKnownAddresses(knownAddrs)\n}\n\n// addBanScore increases the persistent and decaying ban score fields by the\n// values passed as parameters. If the resulting score exceeds half of the ban\n// threshold, a warning is logged including the reason provided. Further, if\n// the score is above the ban threshold, the peer will be banned and\n// disconnected.\nfunc (sp *serverPeer) addBanScore(persistent, transient uint32, reason string) bool {\n\t// No warning is logged and no score is calculated if banning is disabled.\n\tif cfg.DisableBanning {\n\t\treturn false\n\t}\n\tif sp.isWhitelisted {\n\t\tpeerLog.Debugf(\"Misbehaving whitelisted peer %s: %s\", sp, reason)\n\t\treturn false\n\t}\n\n\twarnThreshold := cfg.BanThreshold >> 1\n\tif transient == 0 && persistent == 0 {\n\t\t// The score is not being increased, but a warning message is still\n\t\t// logged if the score is above the warn threshold.\n\t\tscore := sp.banScore.Int()\n\t\tif score > warnThreshold {\n\t\t\tpeerLog.Warnf(\"Misbehaving peer %s: %s -- ban score is %d, \"+\n\t\t\t\t\"it was not increased this time\", sp, reason, score)\n\t\t}\n\t\treturn false\n\t}\n\tscore := sp.banScore.Increase(persistent, transient)\n\tif score > warnThreshold {\n\t\tpeerLog.Warnf(\"Misbehaving peer %s: %s -- ban score increased to %d\",\n\t\t\tsp, reason, score)\n\t\tif score > cfg.BanThreshold {\n\t\t\tpeerLog.Warnf(\"Misbehaving peer %s -- banning and disconnecting\",\n\t\t\t\tsp)\n\t\t\tsp.server.BanPeer(sp)\n\t\t\tsp.Disconnect()\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// hasServices returns whether or not the provided advertised service flags have\n// all of the provided desired service flags set.\nfunc hasServices(advertised, desired wire.ServiceFlag) bool {\n\treturn advertised&desired == desired\n}\n\n// OnVersion is invoked when a peer receives a version bitcoin message\n// and is used to negotiate the protocol version details as well as kick start\n// the communications.\nfunc (sp *serverPeer) OnVersion(_ *peer.Peer, msg *wire.MsgVersion) *wire.MsgReject {\n\t// Update the address manager with the advertised services for outbound\n\t// connections in case they have changed.  This is not done for inbound\n\t// connections to help prevent malicious behavior and is skipped when\n\t// running on the simulation test network since it is only intended to\n\t// connect to specified peers and actively avoids advertising and\n\t// connecting to discovered peers.\n\t//\n\t// NOTE: This is done before rejecting peers that are too old to ensure\n\t// it is updated regardless in the case a new minimum protocol version is\n\t// enforced and the remote node has not upgraded yet.\n\tisInbound := sp.Inbound()\n\tremoteAddr := sp.NA()\n\taddrManager := sp.server.addrManager\n\tif !cfg.SimNet && !isInbound {\n\t\taddrManager.SetServices(remoteAddr, msg.Services)\n\t}\n\n\t// Ignore peers that have a protocol version that is too old.  The peer\n\t// negotiation logic will disconnect it after this callback returns.\n\tif msg.ProtocolVersion < int32(peer.MinAcceptableProtocolVersion) {\n\t\treturn nil\n\t}\n\n\t// Reject outbound peers that are not full nodes.\n\twantServices := wire.SFNodeNetwork\n\tif !isInbound && !hasServices(msg.Services, wantServices) {\n\t\tmissingServices := wantServices & ^msg.Services\n\t\tsrvrLog.Debugf(\"Rejecting peer %s with services %v due to not \"+\n\t\t\t\"providing desired services %v\", sp.Peer, msg.Services,\n\t\t\tmissingServices)\n\t\treason := fmt.Sprintf(\"required services %#x not offered\",\n\t\t\tuint64(missingServices))\n\t\treturn wire.NewMsgReject(msg.Command(), wire.RejectNonstandard, reason)\n\t}\n\n\tif !cfg.SimNet && !isInbound {\n\t\t// After soft-fork activation, only make outbound\n\t\t// connection to peers if they flag that they're segwit\n\t\t// enabled.\n\t\tchain := sp.server.chain\n\t\tsegwitActive, err := chain.IsDeploymentActive(chaincfg.DeploymentSegwit)\n\t\tif err != nil {\n\t\t\tpeerLog.Errorf(\"Unable to query for segwit soft-fork state: %v\",\n\t\t\t\terr)\n\t\t\treturn nil\n\t\t}\n\n\t\tif segwitActive && !sp.IsWitnessEnabled() {\n\t\t\tpeerLog.Infof(\"Disconnecting non-segwit peer %v, isn't segwit \"+\n\t\t\t\t\"enabled and we need more segwit enabled peers\", sp)\n\t\t\tsp.Disconnect()\n\t\t\treturn nil\n\t\t}\n\t}\n\n\t// Add the remote peer time as a sample for creating an offset against\n\t// the local clock to keep the network time in sync.\n\tsp.server.timeSource.AddTimeSample(sp.Addr(), msg.Timestamp)\n\n\t// Choose whether or not to relay transactions before a filter command\n\t// is received.\n\tsp.setDisableRelayTx(msg.DisableRelayTx)\n\n\treturn nil\n}\n\n// OnVerAck is invoked when a peer receives a verack bitcoin message and is used\n// to kick start communication with them.\nfunc (sp *serverPeer) OnVerAck(_ *peer.Peer, _ *wire.MsgVerAck) {\n\tsp.server.AddPeer(sp)\n}\n\n// OnMemPool is invoked when a peer receives a mempool bitcoin message.\n// It creates and sends an inventory message with the contents of the memory\n// pool up to the maximum inventory allowed per message.  When the peer has a\n// bloom filter loaded, the contents are filtered accordingly.\nfunc (sp *serverPeer) OnMemPool(_ *peer.Peer, msg *wire.MsgMemPool) {\n\t// Only allow mempool requests if the server has bloom filtering\n\t// enabled.\n\tif sp.server.services&wire.SFNodeBloom != wire.SFNodeBloom {\n\t\tpeerLog.Debugf(\"peer %v sent mempool request with bloom \"+\n\t\t\t\"filtering disabled -- disconnecting\", sp)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\t// A decaying ban score increase is applied to prevent flooding.\n\t// The ban score accumulates and passes the ban threshold if a burst of\n\t// mempool messages comes from a peer. The score decays each minute to\n\t// half of its value.\n\tif sp.addBanScore(0, 33, \"mempool\") {\n\t\treturn\n\t}\n\n\t// Generate inventory message with the available transactions in the\n\t// transaction memory pool.  Limit it to the max allowed inventory\n\t// per message.  The NewMsgInvSizeHint function automatically limits\n\t// the passed hint to the maximum allowed, so it's safe to pass it\n\t// without double checking it here.\n\ttxMemPool := sp.server.txMemPool\n\ttxDescs := txMemPool.TxDescs()\n\tinvMsg := wire.NewMsgInvSizeHint(uint(len(txDescs)))\n\n\tfor _, txDesc := range txDescs {\n\t\t// Either add all transactions when there is no bloom filter,\n\t\t// or only the transactions that match the filter when there is\n\t\t// one.\n\t\tif !sp.filter.IsLoaded() || sp.filter.MatchTxAndUpdate(txDesc.Tx) {\n\t\t\tiv := wire.NewInvVect(wire.InvTypeTx, txDesc.Tx.Hash())\n\t\t\tinvMsg.AddInvVect(iv)\n\t\t\tif len(invMsg.InvList)+1 > wire.MaxInvPerMsg {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// Send the inventory message if there is anything to send.\n\tif len(invMsg.InvList) > 0 {\n\t\tsp.QueueMessage(invMsg, nil)\n\t}\n}\n\n// OnTx is invoked when a peer receives a tx bitcoin message.  It blocks\n// until the bitcoin transaction has been fully processed.  Unlock the block\n// handler this does not serialize all transactions through a single thread\n// transactions don't rely on the previous one in a linear fashion like blocks.\nfunc (sp *serverPeer) OnTx(_ *peer.Peer, msg *wire.MsgTx) {\n\tif cfg.BlocksOnly {\n\t\tpeerLog.Tracef(\"Ignoring tx %v from %v - blocksonly enabled\",\n\t\t\tmsg.TxHash(), sp)\n\t\treturn\n\t}\n\n\t// Add the transaction to the known inventory for the peer.\n\t// Convert the raw MsgTx to a btcutil.Tx which provides some convenience\n\t// methods and things such as hash caching.\n\ttx := btcutil.NewTx(msg)\n\tiv := wire.NewInvVect(wire.InvTypeTx, tx.Hash())\n\tsp.AddKnownInventory(iv)\n\n\t// Queue the transaction up to be handled by the sync manager and\n\t// intentionally block further receives until the transaction is fully\n\t// processed and known good or bad.  This helps prevent a malicious peer\n\t// from queuing up a bunch of bad transactions before disconnecting (or\n\t// being disconnected) and wasting memory.\n\tsp.server.syncManager.QueueTx(tx, sp.Peer, sp.txProcessed)\n\t<-sp.txProcessed\n}\n\n// OnBlock is invoked when a peer receives a block bitcoin message.  It\n// blocks until the bitcoin block has been fully processed.\nfunc (sp *serverPeer) OnBlock(_ *peer.Peer, msg *wire.MsgBlock, buf []byte) {\n\t// Convert the raw MsgBlock to a btcutil.Block which provides some\n\t// convenience methods and things such as hash caching.\n\tblock := btcutil.NewBlockFromBlockAndBytes(msg, buf)\n\n\t// Add the block to the known inventory for the peer.\n\tiv := wire.NewInvVect(wire.InvTypeBlock, block.Hash())\n\tsp.AddKnownInventory(iv)\n\n\t// Queue the block up to be handled by the block\n\t// manager and intentionally block further receives\n\t// until the bitcoin block is fully processed and known\n\t// good or bad.  This helps prevent a malicious peer\n\t// from queuing up a bunch of bad blocks before\n\t// disconnecting (or being disconnected) and wasting\n\t// memory.  Additionally, this behavior is depended on\n\t// by at least the block acceptance test tool as the\n\t// reference implementation processes blocks in the same\n\t// thread and therefore blocks further messages until\n\t// the bitcoin block has been fully processed.\n\tsp.server.syncManager.QueueBlock(block, sp.Peer, sp.blockProcessed)\n\t<-sp.blockProcessed\n}\n\n// OnInv is invoked when a peer receives an inv bitcoin message and is\n// used to examine the inventory being advertised by the remote peer and react\n// accordingly.  We pass the message down to blockmanager which will call\n// QueueMessage with any appropriate responses.\nfunc (sp *serverPeer) OnInv(_ *peer.Peer, msg *wire.MsgInv) {\n\tif !cfg.BlocksOnly {\n\t\tif len(msg.InvList) > 0 {\n\t\t\tsp.server.syncManager.QueueInv(msg, sp.Peer)\n\t\t}\n\t\treturn\n\t}\n\n\tnewInv := wire.NewMsgInvSizeHint(uint(len(msg.InvList)))\n\tfor _, invVect := range msg.InvList {\n\t\tif invVect.Type == wire.InvTypeTx {\n\t\t\tpeerLog.Tracef(\"Ignoring tx %v in inv from %v -- \"+\n\t\t\t\t\"blocksonly enabled\", invVect.Hash, sp)\n\t\t\tif sp.ProtocolVersion() >= wire.BIP0037Version {\n\t\t\t\tpeerLog.Infof(\"Peer %v is announcing \"+\n\t\t\t\t\t\"transactions -- disconnecting\", sp)\n\t\t\t\tsp.Disconnect()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\terr := newInv.AddInvVect(invVect)\n\t\tif err != nil {\n\t\t\tpeerLog.Errorf(\"Failed to add inventory vector: %v\", err)\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif len(newInv.InvList) > 0 {\n\t\tsp.server.syncManager.QueueInv(newInv, sp.Peer)\n\t}\n}\n\n// OnHeaders is invoked when a peer receives a headers bitcoin\n// message.  The message is passed down to the sync manager.\nfunc (sp *serverPeer) OnHeaders(_ *peer.Peer, msg *wire.MsgHeaders) {\n\tsp.server.syncManager.QueueHeaders(msg, sp.Peer)\n}\n\n// handleGetData is invoked when a peer receives a getdata bitcoin message and\n// is used to deliver block and transaction information.\nfunc (sp *serverPeer) OnGetData(_ *peer.Peer, msg *wire.MsgGetData) {\n\tnumAdded := 0\n\tnotFound := wire.NewMsgNotFound()\n\n\tlength := len(msg.InvList)\n\t// A decaying ban score increase is applied to prevent exhausting resources\n\t// with unusually large inventory queries.\n\t// Requesting more than the maximum inventory vector length within a short\n\t// period of time yields a score above the default ban threshold. Sustained\n\t// bursts of small requests are not penalized as that would potentially ban\n\t// peers performing IBD.\n\t// This incremental score decays each minute to half of its value.\n\tif sp.addBanScore(0, uint32(length)*99/wire.MaxInvPerMsg, \"getdata\") {\n\t\treturn\n\t}\n\n\t// We wait on this wait channel periodically to prevent queuing\n\t// far more data than we can send in a reasonable time, wasting memory.\n\t// The waiting occurs after the database fetch for the next one to\n\t// provide a little pipelining.\n\tvar waitChan chan struct{}\n\tdoneChan := make(chan struct{}, 1)\n\n\tfor i, iv := range msg.InvList {\n\t\tvar c chan struct{}\n\t\t// If this will be the last message we send.\n\t\tif i == length-1 && len(notFound.InvList) == 0 {\n\t\t\tc = doneChan\n\t\t} else if (i+1)%3 == 0 {\n\t\t\t// Buffered so as to not make the send goroutine block.\n\t\t\tc = make(chan struct{}, 1)\n\t\t}\n\t\tvar err error\n\t\tswitch iv.Type {\n\t\tcase wire.InvTypeWitnessTx:\n\t\t\terr = sp.server.pushTxMsg(sp, &iv.Hash, c, waitChan, wire.WitnessEncoding)\n\t\tcase wire.InvTypeTx:\n\t\t\terr = sp.server.pushTxMsg(sp, &iv.Hash, c, waitChan, wire.BaseEncoding)\n\t\tcase wire.InvTypeWitnessBlock:\n\t\t\terr = sp.server.pushBlockMsg(sp, &iv.Hash, c, waitChan, wire.WitnessEncoding)\n\t\tcase wire.InvTypeBlock:\n\t\t\terr = sp.server.pushBlockMsg(sp, &iv.Hash, c, waitChan, wire.BaseEncoding)\n\t\tcase wire.InvTypeFilteredWitnessBlock:\n\t\t\terr = sp.server.pushMerkleBlockMsg(sp, &iv.Hash, c, waitChan, wire.WitnessEncoding)\n\t\tcase wire.InvTypeFilteredBlock:\n\t\t\terr = sp.server.pushMerkleBlockMsg(sp, &iv.Hash, c, waitChan, wire.BaseEncoding)\n\t\tdefault:\n\t\t\tpeerLog.Warnf(\"Unknown type in inventory request %d\",\n\t\t\t\tiv.Type)\n\t\t\tcontinue\n\t\t}\n\t\tif err != nil {\n\t\t\tnotFound.AddInvVect(iv)\n\n\t\t\t// When there is a failure fetching the final entry\n\t\t\t// and the done channel was sent in due to there\n\t\t\t// being no outstanding not found inventory, consume\n\t\t\t// it here because there is now not found inventory\n\t\t\t// that will use the channel momentarily.\n\t\t\tif i == len(msg.InvList)-1 && c != nil {\n\t\t\t\t<-c\n\t\t\t}\n\t\t}\n\t\tnumAdded++\n\t\twaitChan = c\n\t}\n\tif len(notFound.InvList) != 0 {\n\t\tsp.QueueMessage(notFound, doneChan)\n\t}\n\n\t// Wait for messages to be sent. We can send quite a lot of data at this\n\t// point and this will keep the peer busy for a decent amount of time.\n\t// We don't process anything else by them in this time so that we\n\t// have an idea of when we should hear back from them - else the idle\n\t// timeout could fire when we were only half done sending the blocks.\n\tif numAdded > 0 {\n\t\t<-doneChan\n\t}\n}\n\n// OnGetBlocks is invoked when a peer receives a getblocks bitcoin\n// message.\nfunc (sp *serverPeer) OnGetBlocks(_ *peer.Peer, msg *wire.MsgGetBlocks) {\n\t// Find the most recent known block in the best chain based on the block\n\t// locator and fetch all of the block hashes after it until either\n\t// wire.MaxBlocksPerMsg have been fetched or the provided stop hash is\n\t// encountered.\n\t//\n\t// Use the block after the genesis block if no other blocks in the\n\t// provided locator are known.  This does mean the client will start\n\t// over with the genesis block if unknown block locators are provided.\n\t//\n\t// This mirrors the behavior in the reference implementation.\n\tchain := sp.server.chain\n\thashList := chain.LocateBlocks(msg.BlockLocatorHashes, &msg.HashStop,\n\t\twire.MaxBlocksPerMsg)\n\n\t// Generate inventory message.\n\tinvMsg := wire.NewMsgInv()\n\tfor i := range hashList {\n\t\tiv := wire.NewInvVect(wire.InvTypeBlock, &hashList[i])\n\t\tinvMsg.AddInvVect(iv)\n\t}\n\n\t// Send the inventory message if there is anything to send.\n\tif len(invMsg.InvList) > 0 {\n\t\tinvListLen := len(invMsg.InvList)\n\t\tif invListLen == wire.MaxBlocksPerMsg {\n\t\t\t// Intentionally use a copy of the final hash so there\n\t\t\t// is not a reference into the inventory slice which\n\t\t\t// would prevent the entire slice from being eligible\n\t\t\t// for GC as soon as it's sent.\n\t\t\tcontinueHash := invMsg.InvList[invListLen-1].Hash\n\t\t\tsp.continueHash = &continueHash\n\t\t}\n\t\tsp.QueueMessage(invMsg, nil)\n\t}\n}\n\n// OnGetHeaders is invoked when a peer receives a getheaders bitcoin\n// message.\nfunc (sp *serverPeer) OnGetHeaders(_ *peer.Peer, msg *wire.MsgGetHeaders) {\n\t// Ignore getheaders requests if not in sync.\n\tif !sp.server.syncManager.IsCurrent() {\n\t\treturn\n\t}\n\n\t// Find the most recent known block in the best chain based on the block\n\t// locator and fetch all of the headers after it until either\n\t// wire.MaxBlockHeadersPerMsg have been fetched or the provided stop\n\t// hash is encountered.\n\t//\n\t// Use the block after the genesis block if no other blocks in the\n\t// provided locator are known.  This does mean the client will start\n\t// over with the genesis block if unknown block locators are provided.\n\t//\n\t// This mirrors the behavior in the reference implementation.\n\tchain := sp.server.chain\n\theaders := chain.LocateHeaders(msg.BlockLocatorHashes, &msg.HashStop)\n\n\t// Send found headers to the requesting peer.\n\tblockHeaders := make([]*wire.BlockHeader, len(headers))\n\tfor i := range headers {\n\t\tblockHeaders[i] = &headers[i]\n\t}\n\tsp.QueueMessage(&wire.MsgHeaders{Headers: blockHeaders}, nil)\n}\n\n// OnGetCFilters is invoked when a peer receives a getcfilters bitcoin message.\nfunc (sp *serverPeer) OnGetCFilters(_ *peer.Peer, msg *wire.MsgGetCFilters) {\n\t// Ignore getcfilters requests if not in sync.\n\tif !sp.server.syncManager.IsCurrent() {\n\t\treturn\n\t}\n\n\t// We'll also ensure that the remote party is requesting a set of\n\t// filters that we actually currently maintain.\n\tswitch msg.FilterType {\n\tcase wire.GCSFilterRegular:\n\t\tbreak\n\n\tdefault:\n\t\tpeerLog.Debug(\"Filter request for unknown filter: %v\",\n\t\t\tmsg.FilterType)\n\t\treturn\n\t}\n\n\thashes, err := sp.server.chain.HeightToHashRange(\n\t\tint32(msg.StartHeight), &msg.StopHash, wire.MaxGetCFiltersReqRange,\n\t)\n\tif err != nil {\n\t\tpeerLog.Debugf(\"Invalid getcfilters request: %v\", err)\n\t\treturn\n\t}\n\n\t// Create []*chainhash.Hash from []chainhash.Hash to pass to\n\t// FiltersByBlockHashes.\n\thashPtrs := make([]*chainhash.Hash, len(hashes))\n\tfor i := range hashes {\n\t\thashPtrs[i] = &hashes[i]\n\t}\n\n\tfilters, err := sp.server.cfIndex.FiltersByBlockHashes(\n\t\thashPtrs, msg.FilterType,\n\t)\n\tif err != nil {\n\t\tpeerLog.Errorf(\"Error retrieving cfilters: %v\", err)\n\t\treturn\n\t}\n\n\tfor i, filterBytes := range filters {\n\t\tif len(filterBytes) == 0 {\n\t\t\tpeerLog.Warnf(\"Could not obtain cfilter for %v\",\n\t\t\t\thashes[i])\n\t\t\treturn\n\t\t}\n\n\t\tfilterMsg := wire.NewMsgCFilter(\n\t\t\tmsg.FilterType, &hashes[i], filterBytes,\n\t\t)\n\t\tsp.QueueMessage(filterMsg, nil)\n\t}\n}\n\n// OnGetCFHeaders is invoked when a peer receives a getcfheader bitcoin message.\nfunc (sp *serverPeer) OnGetCFHeaders(_ *peer.Peer, msg *wire.MsgGetCFHeaders) {\n\t// Ignore getcfilterheader requests if not in sync.\n\tif !sp.server.syncManager.IsCurrent() {\n\t\treturn\n\t}\n\n\t// We'll also ensure that the remote party is requesting a set of\n\t// headers for filters that we actually currently maintain.\n\tswitch msg.FilterType {\n\tcase wire.GCSFilterRegular:\n\t\tbreak\n\n\tdefault:\n\t\tpeerLog.Debug(\"Filter request for unknown headers for \"+\n\t\t\t\"filter: %v\", msg.FilterType)\n\t\treturn\n\t}\n\n\tstartHeight := int32(msg.StartHeight)\n\tmaxResults := wire.MaxCFHeadersPerMsg\n\n\t// If StartHeight is positive, fetch the predecessor block hash so we\n\t// can populate the PrevFilterHeader field.\n\tif msg.StartHeight > 0 {\n\t\tstartHeight--\n\t\tmaxResults++\n\t}\n\n\t// Fetch the hashes from the block index.\n\thashList, err := sp.server.chain.HeightToHashRange(\n\t\tstartHeight, &msg.StopHash, maxResults,\n\t)\n\tif err != nil {\n\t\tpeerLog.Debugf(\"Invalid getcfheaders request: %v\", err)\n\t}\n\n\t// This is possible if StartHeight is one greater that the height of\n\t// StopHash, and we pull a valid range of hashes including the previous\n\t// filter header.\n\tif len(hashList) == 0 || (msg.StartHeight > 0 && len(hashList) == 1) {\n\t\tpeerLog.Debug(\"No results for getcfheaders request\")\n\t\treturn\n\t}\n\n\t// Create []*chainhash.Hash from []chainhash.Hash to pass to\n\t// FilterHeadersByBlockHashes.\n\thashPtrs := make([]*chainhash.Hash, len(hashList))\n\tfor i := range hashList {\n\t\thashPtrs[i] = &hashList[i]\n\t}\n\n\t// Fetch the raw filter hash bytes from the database for all blocks.\n\tfilterHashes, err := sp.server.cfIndex.FilterHashesByBlockHashes(\n\t\thashPtrs, msg.FilterType,\n\t)\n\tif err != nil {\n\t\tpeerLog.Errorf(\"Error retrieving cfilter hashes: %v\", err)\n\t\treturn\n\t}\n\n\t// Generate cfheaders message and send it.\n\theadersMsg := wire.NewMsgCFHeaders()\n\n\t// Populate the PrevFilterHeader field.\n\tif msg.StartHeight > 0 {\n\t\tprevBlockHash := &hashList[0]\n\n\t\t// Fetch the raw committed filter header bytes from the\n\t\t// database.\n\t\theaderBytes, err := sp.server.cfIndex.FilterHeaderByBlockHash(\n\t\t\tprevBlockHash, msg.FilterType)\n\t\tif err != nil {\n\t\t\tpeerLog.Errorf(\"Error retrieving CF header: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tif len(headerBytes) == 0 {\n\t\t\tpeerLog.Warnf(\"Could not obtain CF header for %v\", prevBlockHash)\n\t\t\treturn\n\t\t}\n\n\t\t// Deserialize the hash into PrevFilterHeader.\n\t\terr = headersMsg.PrevFilterHeader.SetBytes(headerBytes)\n\t\tif err != nil {\n\t\t\tpeerLog.Warnf(\"Committed filter header deserialize \"+\n\t\t\t\t\"failed: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\thashList = hashList[1:]\n\t\tfilterHashes = filterHashes[1:]\n\t}\n\n\t// Populate HeaderHashes.\n\tfor i, hashBytes := range filterHashes {\n\t\tif len(hashBytes) == 0 {\n\t\t\tpeerLog.Warnf(\"Could not obtain CF hash for %v\", hashList[i])\n\t\t\treturn\n\t\t}\n\n\t\t// Deserialize the hash.\n\t\tfilterHash, err := chainhash.NewHash(hashBytes)\n\t\tif err != nil {\n\t\t\tpeerLog.Warnf(\"Committed filter hash deserialize \"+\n\t\t\t\t\"failed: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\theadersMsg.AddCFHash(filterHash)\n\t}\n\n\theadersMsg.FilterType = msg.FilterType\n\theadersMsg.StopHash = msg.StopHash\n\n\tsp.QueueMessage(headersMsg, nil)\n}\n\n// OnGetCFCheckpt is invoked when a peer receives a getcfcheckpt bitcoin message.\nfunc (sp *serverPeer) OnGetCFCheckpt(_ *peer.Peer, msg *wire.MsgGetCFCheckpt) {\n\t// Ignore getcfcheckpt requests if not in sync.\n\tif !sp.server.syncManager.IsCurrent() {\n\t\treturn\n\t}\n\n\t// We'll also ensure that the remote party is requesting a set of\n\t// checkpoints for filters that we actually currently maintain.\n\tswitch msg.FilterType {\n\tcase wire.GCSFilterRegular:\n\t\tbreak\n\n\tdefault:\n\t\tpeerLog.Debug(\"Filter request for unknown checkpoints for \"+\n\t\t\t\"filter: %v\", msg.FilterType)\n\t\treturn\n\t}\n\n\t// Now that we know the client is fetching a filter that we know of,\n\t// we'll fetch the block hashes et each check point interval so we can\n\t// compare against our cache, and create new check points if necessary.\n\tblockHashes, err := sp.server.chain.IntervalBlockHashes(\n\t\t&msg.StopHash, wire.CFCheckptInterval,\n\t)\n\tif err != nil {\n\t\tpeerLog.Debugf(\"Invalid getcfilters request: %v\", err)\n\t\treturn\n\t}\n\n\tcheckptMsg := wire.NewMsgCFCheckpt(\n\t\tmsg.FilterType, &msg.StopHash, len(blockHashes),\n\t)\n\n\t// Fetch the current existing cache so we can decide if we need to\n\t// extend it or if its adequate as is.\n\tsp.server.cfCheckptCachesMtx.RLock()\n\tcheckptCache := sp.server.cfCheckptCaches[msg.FilterType]\n\n\t// If the set of block hashes is beyond the current size of the cache,\n\t// then we'll expand the size of the cache and also retain the write\n\t// lock.\n\tvar updateCache bool\n\tif len(blockHashes) > len(checkptCache) {\n\t\t// Now that we know we'll need to modify the size of the cache,\n\t\t// we'll release the read lock and grab the write lock to\n\t\t// possibly expand the cache size.\n\t\tsp.server.cfCheckptCachesMtx.RUnlock()\n\n\t\tsp.server.cfCheckptCachesMtx.Lock()\n\t\tdefer sp.server.cfCheckptCachesMtx.Unlock()\n\n\t\t// Now that we have the write lock, we'll check again as it's\n\t\t// possible that the cache has already been expanded.\n\t\tcheckptCache = sp.server.cfCheckptCaches[msg.FilterType]\n\n\t\t// If we still need to expand the cache, then We'll mark that\n\t\t// we need to update the cache for below and also expand the\n\t\t// size of the cache in place.\n\t\tif len(blockHashes) > len(checkptCache) {\n\t\t\tupdateCache = true\n\n\t\t\tadditionalLength := len(blockHashes) - len(checkptCache)\n\t\t\tnewEntries := make([]cfHeaderKV, additionalLength)\n\n\t\t\tpeerLog.Infof(\"Growing size of checkpoint cache from %v to %v \"+\n\t\t\t\t\"block hashes\", len(checkptCache), len(blockHashes))\n\n\t\t\tcheckptCache = append(\n\t\t\t\tsp.server.cfCheckptCaches[msg.FilterType],\n\t\t\t\tnewEntries...,\n\t\t\t)\n\t\t}\n\t} else {\n\t\t// Otherwise, we'll hold onto the read lock for the remainder\n\t\t// of this method.\n\t\tdefer sp.server.cfCheckptCachesMtx.RUnlock()\n\n\t\tpeerLog.Tracef(\"Serving stale cache of size %v\",\n\t\t\tlen(checkptCache))\n\t}\n\n\t// Now that we know the cache is of an appropriate size, we'll iterate\n\t// backwards until the find the block hash. We do this as it's possible\n\t// a re-org has occurred so items in the db are now in the main china\n\t// while the cache has been partially invalidated.\n\tvar forkIdx int\n\tfor forkIdx = len(blockHashes); forkIdx > 0; forkIdx-- {\n\t\tif checkptCache[forkIdx-1].blockHash == blockHashes[forkIdx-1] {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Now that we know the how much of the cache is relevant for this\n\t// query, we'll populate our check point message with the cache as is.\n\t// Shortly below, we'll populate the new elements of the cache.\n\tfor i := 0; i < forkIdx; i++ {\n\t\tcheckptMsg.AddCFHeader(&checkptCache[i].filterHeader)\n\t}\n\n\t// We'll now collect the set of hashes that are beyond our cache so we\n\t// can look up the filter headers to populate the final cache.\n\tblockHashPtrs := make([]*chainhash.Hash, 0, len(blockHashes)-forkIdx)\n\tfor i := forkIdx; i < len(blockHashes); i++ {\n\t\tblockHashPtrs = append(blockHashPtrs, &blockHashes[i])\n\t}\n\tfilterHeaders, err := sp.server.cfIndex.FilterHeadersByBlockHashes(\n\t\tblockHashPtrs, msg.FilterType,\n\t)\n\tif err != nil {\n\t\tpeerLog.Errorf(\"Error retrieving cfilter headers: %v\", err)\n\t\treturn\n\t}\n\n\t// Now that we have the full set of filter headers, we'll add them to\n\t// the checkpoint message, and also update our cache in line.\n\tfor i, filterHeaderBytes := range filterHeaders {\n\t\tif len(filterHeaderBytes) == 0 {\n\t\t\tpeerLog.Warnf(\"Could not obtain CF header for %v\",\n\t\t\t\tblockHashPtrs[i])\n\t\t\treturn\n\t\t}\n\n\t\tfilterHeader, err := chainhash.NewHash(filterHeaderBytes)\n\t\tif err != nil {\n\t\t\tpeerLog.Warnf(\"Committed filter header deserialize \"+\n\t\t\t\t\"failed: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tcheckptMsg.AddCFHeader(filterHeader)\n\n\t\t// If the new main chain is longer than what's in the cache,\n\t\t// then we'll override it beyond the fork point.\n\t\tif updateCache {\n\t\t\tcheckptCache[forkIdx+i] = cfHeaderKV{\n\t\t\t\tblockHash:    blockHashes[forkIdx+i],\n\t\t\t\tfilterHeader: *filterHeader,\n\t\t\t}\n\t\t}\n\t}\n\n\t// Finally, we'll update the cache if we need to, and send the final\n\t// message back to the requesting peer.\n\tif updateCache {\n\t\tsp.server.cfCheckptCaches[msg.FilterType] = checkptCache\n\t}\n\n\tsp.QueueMessage(checkptMsg, nil)\n}\n\n// enforceNodeBloomFlag disconnects the peer if the server is not configured to\n// allow bloom filters.  Additionally, if the peer has negotiated to a protocol\n// version  that is high enough to observe the bloom filter service support bit,\n// it will be banned since it is intentionally violating the protocol.\nfunc (sp *serverPeer) enforceNodeBloomFlag(cmd string) bool {\n\tif sp.server.services&wire.SFNodeBloom != wire.SFNodeBloom {\n\t\t// Ban the peer if the protocol version is high enough that the\n\t\t// peer is knowingly violating the protocol and banning is\n\t\t// enabled.\n\t\t//\n\t\t// NOTE: Even though the addBanScore function already examines\n\t\t// whether or not banning is enabled, it is checked here as well\n\t\t// to ensure the violation is logged and the peer is\n\t\t// disconnected regardless.\n\t\tif sp.ProtocolVersion() >= wire.BIP0111Version &&\n\t\t\t!cfg.DisableBanning {\n\n\t\t\t// Disconnect the peer regardless of whether it was\n\t\t\t// banned.\n\t\t\tsp.addBanScore(100, 0, cmd)\n\t\t\tsp.Disconnect()\n\t\t\treturn false\n\t\t}\n\n\t\t// Disconnect the peer regardless of protocol version or banning\n\t\t// state.\n\t\tpeerLog.Debugf(\"%s sent an unsupported %s request -- \"+\n\t\t\t\"disconnecting\", sp, cmd)\n\t\tsp.Disconnect()\n\t\treturn false\n\t}\n\n\treturn true\n}\n\n// OnFeeFilter is invoked when a peer receives a feefilter bitcoin message and\n// is used by remote peers to request that no transactions which have a fee rate\n// lower than provided value are inventoried to them.  The peer will be\n// disconnected if an invalid fee filter value is provided.\nfunc (sp *serverPeer) OnFeeFilter(_ *peer.Peer, msg *wire.MsgFeeFilter) {\n\t// Check that the passed minimum fee is a valid amount.\n\tif msg.MinFee < 0 || msg.MinFee > btcutil.MaxSatoshi {\n\t\tpeerLog.Debugf(\"Peer %v sent an invalid feefilter '%v' -- \"+\n\t\t\t\"disconnecting\", sp, btcutil.Amount(msg.MinFee))\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\tatomic.StoreInt64(&sp.feeFilter, msg.MinFee)\n}\n\n// OnFilterAdd is invoked when a peer receives a filteradd bitcoin\n// message and is used by remote peers to add data to an already loaded bloom\n// filter.  The peer will be disconnected if a filter is not loaded when this\n// message is received or the server is not configured to allow bloom filters.\nfunc (sp *serverPeer) OnFilterAdd(_ *peer.Peer, msg *wire.MsgFilterAdd) {\n\t// Disconnect and/or ban depending on the node bloom services flag and\n\t// negotiated protocol version.\n\tif !sp.enforceNodeBloomFlag(msg.Command()) {\n\t\treturn\n\t}\n\n\tif !sp.filter.IsLoaded() {\n\t\tpeerLog.Debugf(\"%s sent a filteradd request with no filter \"+\n\t\t\t\"loaded -- disconnecting\", sp)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\tsp.filter.Add(msg.Data)\n}\n\n// OnFilterClear is invoked when a peer receives a filterclear bitcoin\n// message and is used by remote peers to clear an already loaded bloom filter.\n// The peer will be disconnected if a filter is not loaded when this message is\n// received  or the server is not configured to allow bloom filters.\nfunc (sp *serverPeer) OnFilterClear(_ *peer.Peer, msg *wire.MsgFilterClear) {\n\t// Disconnect and/or ban depending on the node bloom services flag and\n\t// negotiated protocol version.\n\tif !sp.enforceNodeBloomFlag(msg.Command()) {\n\t\treturn\n\t}\n\n\tif !sp.filter.IsLoaded() {\n\t\tpeerLog.Debugf(\"%s sent a filterclear request with no \"+\n\t\t\t\"filter loaded -- disconnecting\", sp)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\tsp.filter.Unload()\n}\n\n// OnFilterLoad is invoked when a peer receives a filterload bitcoin\n// message and it used to load a bloom filter that should be used for\n// delivering merkle blocks and associated transactions that match the filter.\n// The peer will be disconnected if the server is not configured to allow bloom\n// filters.\nfunc (sp *serverPeer) OnFilterLoad(_ *peer.Peer, msg *wire.MsgFilterLoad) {\n\t// Disconnect and/or ban depending on the node bloom services flag and\n\t// negotiated protocol version.\n\tif !sp.enforceNodeBloomFlag(msg.Command()) {\n\t\treturn\n\t}\n\n\tsp.setDisableRelayTx(false)\n\n\tsp.filter.Reload(msg)\n}\n\n// OnGetAddr is invoked when a peer receives a getaddr bitcoin message\n// and is used to provide the peer with known addresses from the address\n// manager.\nfunc (sp *serverPeer) OnGetAddr(_ *peer.Peer, msg *wire.MsgGetAddr) {\n\t// Don't return any addresses when running on the simulation test\n\t// network.  This helps prevent the network from becoming another\n\t// public test network since it will not be able to learn about other\n\t// peers that have not specifically been provided.\n\tif cfg.SimNet {\n\t\treturn\n\t}\n\n\t// Do not accept getaddr requests from outbound peers.  This reduces\n\t// fingerprinting attacks.\n\tif !sp.Inbound() {\n\t\tpeerLog.Debugf(\"Ignoring getaddr request from outbound peer \"+\n\t\t\t\"%v\", sp)\n\t\treturn\n\t}\n\n\t// Only allow one getaddr request per connection to discourage\n\t// address stamping of inv announcements.\n\tif sp.sentAddrs {\n\t\tpeerLog.Debugf(\"Ignoring repeated getaddr request from peer \"+\n\t\t\t\"%v\", sp)\n\t\treturn\n\t}\n\tsp.sentAddrs = true\n\n\t// Get the current known addresses from the address manager.\n\taddrCache := sp.server.addrManager.AddressCache()\n\n\t// Push the addresses.\n\tsp.pushAddrMsg(addrCache)\n}\n\n// OnAddr is invoked when a peer receives an addr bitcoin message and is\n// used to notify the server about advertised addresses.\nfunc (sp *serverPeer) OnAddr(_ *peer.Peer, msg *wire.MsgAddr) {\n\t// Ignore addresses when running on the simulation test network.  This\n\t// helps prevent the network from becoming another public test network\n\t// since it will not be able to learn about other peers that have not\n\t// specifically been provided.\n\tif cfg.SimNet {\n\t\treturn\n\t}\n\n\t// Ignore old style addresses which don't include a timestamp.\n\tif sp.ProtocolVersion() < wire.NetAddressTimeVersion {\n\t\treturn\n\t}\n\n\t// A message that has no addresses is invalid.\n\tif len(msg.AddrList) == 0 {\n\t\tpeerLog.Errorf(\"Command [%s] from %s does not contain any addresses\",\n\t\t\tmsg.Command(), sp.Peer)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\taddrs := make([]*wire.NetAddressV2, 0, len(msg.AddrList))\n\tfor _, na := range msg.AddrList {\n\t\t// Don't add more address if we're disconnecting.\n\t\tif !sp.Connected() {\n\t\t\treturn\n\t\t}\n\n\t\t// Set the timestamp to 5 days ago if it's more than 24 hours\n\t\t// in the future so this address is one of the first to be\n\t\t// removed when space is needed.\n\t\tnow := time.Now()\n\t\tif na.Timestamp.After(now.Add(time.Minute * 10)) {\n\t\t\tna.Timestamp = now.Add(-1 * time.Hour * 24 * 5)\n\t\t}\n\n\t\t// Add address to known addresses for this peer. This is\n\t\t// converted to NetAddressV2 since that's what the address\n\t\t// manager uses.\n\t\tcurrentNa := wire.NetAddressV2FromBytes(\n\t\t\tna.Timestamp, na.Services, na.IP, na.Port,\n\t\t)\n\t\taddrs = append(addrs, currentNa)\n\t\tsp.addKnownAddresses([]*wire.NetAddressV2{currentNa})\n\t}\n\n\t// Add addresses to server address manager.  The address manager handles\n\t// the details of things such as preventing duplicate addresses, max\n\t// addresses, and last seen updates.\n\t// XXX bitcoind gives a 2 hour time penalty here, do we want to do the\n\t// same?\n\tsp.server.addrManager.AddAddresses(addrs, sp.NA())\n}\n\n// OnAddrV2 is invoked when a peer receives an addrv2 bitcoin message and is\n// used to notify the server about advertised addresses.\nfunc (sp *serverPeer) OnAddrV2(_ *peer.Peer, msg *wire.MsgAddrV2) {\n\t// Ignore if simnet for the same reasons as the regular addr message.\n\tif cfg.SimNet {\n\t\treturn\n\t}\n\n\t// An empty AddrV2 message is invalid.\n\tif len(msg.AddrList) == 0 {\n\t\tpeerLog.Errorf(\"Command [%s] from %s does not contain any \"+\n\t\t\t\"addresses\", msg.Command(), sp.Peer)\n\t\tsp.Disconnect()\n\t\treturn\n\t}\n\n\tfor _, na := range msg.AddrList {\n\t\t// Don't add more to the set of known addresses if we're\n\t\t// disconnecting.\n\t\tif !sp.Connected() {\n\t\t\treturn\n\t\t}\n\n\t\t// Set the timestamp to 5 days ago if the timestamp received is\n\t\t// more than 10 minutes in the future so this address is one of\n\t\t// the first to be removed.\n\t\tnow := time.Now()\n\t\tif na.Timestamp.After(now.Add(time.Minute * 10)) {\n\t\t\tna.Timestamp = now.Add(-1 * time.Hour * 24 * 5)\n\t\t}\n\n\t\t// Add to the set of known addresses.\n\t\tsp.addKnownAddresses([]*wire.NetAddressV2{na})\n\t}\n\n\t// Add the addresses to the addrmanager.\n\tsp.server.addrManager.AddAddresses(msg.AddrList, sp.NA())\n}\n\n// OnRead is invoked when a peer receives a message and it is used to update\n// the bytes received by the server.\nfunc (sp *serverPeer) OnRead(_ *peer.Peer, bytesRead int, msg wire.Message, err error) {\n\tsp.server.AddBytesReceived(uint64(bytesRead))\n}\n\n// OnWrite is invoked when a peer sends a message and it is used to update\n// the bytes sent by the server.\nfunc (sp *serverPeer) OnWrite(_ *peer.Peer, bytesWritten int, msg wire.Message, err error) {\n\tsp.server.AddBytesSent(uint64(bytesWritten))\n}\n\n// OnNotFound is invoked when a peer sends a notfound message.\nfunc (sp *serverPeer) OnNotFound(p *peer.Peer, msg *wire.MsgNotFound) {\n\tif !sp.Connected() {\n\t\treturn\n\t}\n\n\tvar numBlocks, numTxns uint32\n\tfor _, inv := range msg.InvList {\n\t\tswitch inv.Type {\n\t\tcase wire.InvTypeBlock:\n\t\t\tnumBlocks++\n\t\tcase wire.InvTypeWitnessBlock:\n\t\t\tnumBlocks++\n\t\tcase wire.InvTypeTx:\n\t\t\tnumTxns++\n\t\tcase wire.InvTypeWitnessTx:\n\t\t\tnumTxns++\n\t\tdefault:\n\t\t\tpeerLog.Debugf(\"Invalid inv type '%d' in notfound message from %s\",\n\t\t\t\tinv.Type, sp)\n\t\t\tsp.Disconnect()\n\t\t\treturn\n\t\t}\n\t}\n\tif numBlocks > 0 {\n\t\tblockStr := pickNoun(uint64(numBlocks), \"block\", \"blocks\")\n\t\treason := fmt.Sprintf(\"%d %v not found\", numBlocks, blockStr)\n\t\tif sp.addBanScore(20*numBlocks, 0, reason) {\n\t\t\treturn\n\t\t}\n\t}\n\tif numTxns > 0 {\n\t\ttxStr := pickNoun(uint64(numTxns), \"transaction\", \"transactions\")\n\t\treason := fmt.Sprintf(\"%d %v not found\", numTxns, txStr)\n\t\tif sp.addBanScore(0, 10*numTxns, reason) {\n\t\t\treturn\n\t\t}\n\t}\n\n\tsp.server.syncManager.QueueNotFound(msg, p)\n}\n\n// randomUint16Number returns a random uint16 in a specified input range.  Note\n// that the range is in zeroth ordering; if you pass it 1800, you will get\n// values from 0 to 1800.\nfunc randomUint16Number(max uint16) uint16 {\n\t// In order to avoid modulo bias and ensure every possible outcome in\n\t// [0, max) has equal probability, the random number must be sampled\n\t// from a random source that has a range limited to a multiple of the\n\t// modulus.\n\tvar randomNumber uint16\n\tvar limitRange = (math.MaxUint16 / max) * max\n\tfor {\n\t\tbinary.Read(rand.Reader, binary.LittleEndian, &randomNumber)\n\t\tif randomNumber < limitRange {\n\t\t\treturn (randomNumber % max)\n\t\t}\n\t}\n}\n\n// AddRebroadcastInventory adds 'iv' to the list of inventories to be\n// rebroadcasted at random intervals until they show up in a block.\nfunc (s *server) AddRebroadcastInventory(iv *wire.InvVect, data interface{}) {\n\t// Ignore if shutting down.\n\tif atomic.LoadInt32(&s.shutdown) != 0 {\n\t\treturn\n\t}\n\n\ts.modifyRebroadcastInv <- broadcastInventoryAdd{invVect: iv, data: data}\n}\n\n// RemoveRebroadcastInventory removes 'iv' from the list of items to be\n// rebroadcasted if present.\nfunc (s *server) RemoveRebroadcastInventory(iv *wire.InvVect) {\n\t// Ignore if shutting down.\n\tif atomic.LoadInt32(&s.shutdown) != 0 {\n\t\treturn\n\t}\n\n\ts.modifyRebroadcastInv <- broadcastInventoryDel(iv)\n}\n\n// relayTransactions generates and relays inventory vectors for all of the\n// passed transactions to all connected peers.\nfunc (s *server) relayTransactions(txns []*mempool.TxDesc) {\n\tfor _, txD := range txns {\n\t\tiv := wire.NewInvVect(wire.InvTypeTx, txD.Tx.Hash())\n\t\ts.RelayInventory(iv, txD)\n\t}\n}\n\n// AnnounceNewTransactions generates and relays inventory vectors and notifies\n// both websocket and getblocktemplate long poll clients of the passed\n// transactions.  This function should be called whenever new transactions\n// are added to the mempool.\nfunc (s *server) AnnounceNewTransactions(txns []*mempool.TxDesc) {\n\t// Generate and relay inventory vectors for all newly accepted\n\t// transactions.\n\ts.relayTransactions(txns)\n\n\t// Notify both websocket and getblocktemplate long poll clients of all\n\t// newly accepted transactions.\n\tif s.rpcServer != nil {\n\t\ts.rpcServer.NotifyNewTransactions(txns)\n\t}\n}\n\n// Transaction has one confirmation on the main chain. Now we can mark it as no\n// longer needing rebroadcasting.\nfunc (s *server) TransactionConfirmed(tx *btcutil.Tx) {\n\t// Rebroadcasting is only necessary when the RPC server is active.\n\tif s.rpcServer == nil {\n\t\treturn\n\t}\n\n\tiv := wire.NewInvVect(wire.InvTypeTx, tx.Hash())\n\ts.RemoveRebroadcastInventory(iv)\n}\n\n// pushTxMsg sends a tx message for the provided transaction hash to the\n// connected peer.  An error is returned if the transaction hash is not known.\nfunc (s *server) pushTxMsg(sp *serverPeer, hash *chainhash.Hash, doneChan chan<- struct{},\n\twaitChan <-chan struct{}, encoding wire.MessageEncoding) error {\n\n\t// Attempt to fetch the requested transaction from the pool.  A\n\t// call could be made to check for existence first, but simply trying\n\t// to fetch a missing transaction results in the same behavior.\n\ttx, err := s.txMemPool.FetchTransaction(hash)\n\tif err != nil {\n\t\tpeerLog.Tracef(\"Unable to fetch tx %v from transaction \"+\n\t\t\t\"pool: %v\", hash, err)\n\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- struct{}{}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Once we have fetched data wait for any previous operation to finish.\n\tif waitChan != nil {\n\t\t<-waitChan\n\t}\n\n\tsp.QueueMessageWithEncoding(tx.MsgTx(), doneChan, encoding)\n\n\treturn nil\n}\n\n// pushBlockMsg sends a block message for the provided block hash to the\n// connected peer.  An error is returned if the block hash is not known.\nfunc (s *server) pushBlockMsg(sp *serverPeer, hash *chainhash.Hash, doneChan chan<- struct{},\n\twaitChan <-chan struct{}, encoding wire.MessageEncoding) error {\n\n\t// Fetch the raw block bytes from the database.\n\tvar blockBytes []byte\n\terr := sp.server.db.View(func(dbTx database.Tx) error {\n\t\tvar err error\n\t\tblockBytes, err = dbTx.FetchBlock(hash)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\tpeerLog.Tracef(\"Unable to fetch requested block hash %v: %v\",\n\t\t\thash, err)\n\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- struct{}{}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Deserialize the block.\n\tvar msgBlock wire.MsgBlock\n\terr = msgBlock.Deserialize(bytes.NewReader(blockBytes))\n\tif err != nil {\n\t\tpeerLog.Tracef(\"Unable to deserialize requested block hash \"+\n\t\t\t\"%v: %v\", hash, err)\n\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- struct{}{}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Once we have fetched data wait for any previous operation to finish.\n\tif waitChan != nil {\n\t\t<-waitChan\n\t}\n\n\t// We only send the channel for this message if we aren't sending\n\t// an inv straight after.\n\tvar dc chan<- struct{}\n\tcontinueHash := sp.continueHash\n\tsendInv := continueHash != nil && continueHash.IsEqual(hash)\n\tif !sendInv {\n\t\tdc = doneChan\n\t}\n\tsp.QueueMessageWithEncoding(&msgBlock, dc, encoding)\n\n\t// When the peer requests the final block that was advertised in\n\t// response to a getblocks message which requested more blocks than\n\t// would fit into a single message, send it a new inventory message\n\t// to trigger it to issue another getblocks message for the next\n\t// batch of inventory.\n\tif sendInv {\n\t\tbest := sp.server.chain.BestSnapshot()\n\t\tinvMsg := wire.NewMsgInvSizeHint(1)\n\t\tiv := wire.NewInvVect(wire.InvTypeBlock, &best.Hash)\n\t\tinvMsg.AddInvVect(iv)\n\t\tsp.QueueMessage(invMsg, doneChan)\n\t\tsp.continueHash = nil\n\t}\n\treturn nil\n}\n\n// pushMerkleBlockMsg sends a merkleblock message for the provided block hash to\n// the connected peer.  Since a merkle block requires the peer to have a filter\n// loaded, this call will simply be ignored if there is no filter loaded.  An\n// error is returned if the block hash is not known.\nfunc (s *server) pushMerkleBlockMsg(sp *serverPeer, hash *chainhash.Hash,\n\tdoneChan chan<- struct{}, waitChan <-chan struct{}, encoding wire.MessageEncoding) error {\n\n\t// Do not send a response if the peer doesn't have a filter loaded.\n\tif !sp.filter.IsLoaded() {\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- struct{}{}\n\t\t}\n\t\treturn nil\n\t}\n\n\t// Fetch the raw block bytes from the database.\n\tblk, err := sp.server.chain.BlockByHash(hash)\n\tif err != nil {\n\t\tpeerLog.Tracef(\"Unable to fetch requested block hash %v: %v\",\n\t\t\thash, err)\n\n\t\tif doneChan != nil {\n\t\t\tdoneChan <- struct{}{}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Generate a merkle block by filtering the requested block according\n\t// to the filter for the peer.\n\tmerkle, matchedTxIndices := bloom.NewMerkleBlock(blk, sp.filter)\n\n\t// Once we have fetched data wait for any previous operation to finish.\n\tif waitChan != nil {\n\t\t<-waitChan\n\t}\n\n\t// Send the merkleblock.  Only send the done channel with this message\n\t// if no transactions will be sent afterwards.\n\tvar dc chan<- struct{}\n\tif len(matchedTxIndices) == 0 {\n\t\tdc = doneChan\n\t}\n\tsp.QueueMessage(merkle, dc)\n\n\t// Finally, send any matched transactions.\n\tblkTransactions := blk.MsgBlock().Transactions\n\tfor i, txIndex := range matchedTxIndices {\n\t\t// Only send the done channel on the final transaction.\n\t\tvar dc chan<- struct{}\n\t\tif i == len(matchedTxIndices)-1 {\n\t\t\tdc = doneChan\n\t\t}\n\t\tif txIndex < uint32(len(blkTransactions)) {\n\t\t\tsp.QueueMessageWithEncoding(blkTransactions[txIndex], dc,\n\t\t\t\tencoding)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// handleUpdatePeerHeight updates the heights of all peers who were known to\n// announce a block we recently accepted.\nfunc (s *server) handleUpdatePeerHeights(state *peerState, umsg updatePeerHeightsMsg) {\n\tstate.forAllPeers(func(sp *serverPeer) {\n\t\t// The origin peer should already have the updated height.\n\t\tif sp.Peer == umsg.originPeer {\n\t\t\treturn\n\t\t}\n\n\t\t// This is a pointer to the underlying memory which doesn't\n\t\t// change.\n\t\tlatestBlkHash := sp.LastAnnouncedBlock()\n\n\t\t// Skip this peer if it hasn't recently announced any new blocks.\n\t\tif latestBlkHash == nil {\n\t\t\treturn\n\t\t}\n\n\t\t// If the peer has recently announced a block, and this block\n\t\t// matches our newly accepted block, then update their block\n\t\t// height.\n\t\tif *latestBlkHash == *umsg.newHash {\n\t\t\tsp.UpdateLastBlockHeight(umsg.newHeight)\n\t\t\tsp.UpdateLastAnnouncedBlock(nil)\n\t\t}\n\t})\n}\n\n// handleAddPeerMsg deals with adding new peers.  It is invoked from the\n// peerHandler goroutine.\nfunc (s *server) handleAddPeerMsg(state *peerState, sp *serverPeer) bool {\n\tif sp == nil || !sp.Connected() {\n\t\treturn false\n\t}\n\n\t// Disconnect peers with unwanted user agents.\n\tif sp.HasUndesiredUserAgent(s.agentBlacklist, s.agentWhitelist) {\n\t\tsp.Disconnect()\n\t\treturn false\n\t}\n\n\t// Ignore new peers if we're shutting down.\n\tif atomic.LoadInt32(&s.shutdown) != 0 {\n\t\tsrvrLog.Infof(\"New peer %s ignored - server is shutting down\", sp)\n\t\tsp.Disconnect()\n\t\treturn false\n\t}\n\n\t// Disconnect banned peers.\n\thost, _, err := net.SplitHostPort(sp.Addr())\n\tif err != nil {\n\t\tsrvrLog.Debugf(\"can't split hostport %v\", err)\n\t\tsp.Disconnect()\n\t\treturn false\n\t}\n\tif banEnd, ok := state.banned[host]; ok {\n\t\tif time.Now().Before(banEnd) {\n\t\t\tsrvrLog.Debugf(\"Peer %s is banned for another %v - disconnecting\",\n\t\t\t\thost, time.Until(banEnd))\n\t\t\tsp.Disconnect()\n\t\t\treturn false\n\t\t}\n\n\t\tsrvrLog.Infof(\"Peer %s is no longer banned\", host)\n\t\tdelete(state.banned, host)\n\t}\n\n\t// TODO: Check for max peers from a single IP.\n\n\t// Limit max number of total peers.\n\tif state.Count() >= cfg.MaxPeers {\n\t\tsrvrLog.Infof(\"Max peers reached [%d] - disconnecting peer %s\",\n\t\t\tcfg.MaxPeers, sp)\n\t\tsp.Disconnect()\n\t\t// TODO: how to handle permanent peers here?\n\t\t// they should be rescheduled.\n\t\treturn false\n\t}\n\n\t// Add the new peer and start it.\n\tsrvrLog.Debugf(\"New peer %s\", sp)\n\tif sp.Inbound() {\n\t\tstate.inboundPeers[sp.ID()] = sp\n\t} else {\n\t\tstate.outboundGroups[addrmgr.GroupKey(sp.NA())]++\n\t\tif sp.persistent {\n\t\t\tstate.persistentPeers[sp.ID()] = sp\n\t\t} else {\n\t\t\tstate.outboundPeers[sp.ID()] = sp\n\t\t}\n\t}\n\n\t// Update the address' last seen time if the peer has acknowledged\n\t// our version and has sent us its version as well.\n\tif sp.VerAckReceived() && sp.VersionKnown() && sp.NA() != nil {\n\t\ts.addrManager.Connected(sp.NA())\n\t}\n\n\t// Signal the sync manager this peer is a new sync candidate.\n\ts.syncManager.NewPeer(sp.Peer)\n\n\t// Update the address manager and request known addresses from the\n\t// remote peer for outbound connections. This is skipped when running on\n\t// the simulation test network since it is only intended to connect to\n\t// specified peers and actively avoids advertising and connecting to\n\t// discovered peers.\n\tif !cfg.SimNet && !sp.Inbound() {\n\t\t// Advertise the local address when the server accepts incoming\n\t\t// connections and it believes itself to be close to the best\n\t\t// known tip.\n\t\tif !cfg.DisableListen && s.syncManager.IsCurrent() {\n\t\t\t// Get address that best matches.\n\t\t\tlna := s.addrManager.GetBestLocalAddress(sp.NA())\n\t\t\tif addrmgr.IsRoutable(lna) {\n\t\t\t\t// Filter addresses the peer already knows about.\n\t\t\t\taddresses := []*wire.NetAddressV2{lna}\n\t\t\t\tsp.pushAddrMsg(addresses)\n\t\t\t}\n\t\t}\n\n\t\t// Request known addresses if the server address manager needs\n\t\t// more and the peer has a protocol version new enough to\n\t\t// include a timestamp with addresses.\n\t\thasTimestamp := sp.ProtocolVersion() >= wire.NetAddressTimeVersion\n\t\tif s.addrManager.NeedMoreAddresses() && hasTimestamp {\n\t\t\tsp.QueueMessage(wire.NewMsgGetAddr(), nil)\n\t\t}\n\n\t\t// Mark the address as a known good address.\n\t\ts.addrManager.Good(sp.NA())\n\t}\n\n\treturn true\n}\n\n// handleDonePeerMsg deals with peers that have signalled they are done.  It is\n// invoked from the peerHandler goroutine.\nfunc (s *server) handleDonePeerMsg(state *peerState, sp *serverPeer) {\n\tvar list map[int32]*serverPeer\n\tif sp.persistent {\n\t\tlist = state.persistentPeers\n\t} else if sp.Inbound() {\n\t\tlist = state.inboundPeers\n\t} else {\n\t\tlist = state.outboundPeers\n\t}\n\n\t// Regardless of whether the peer was found in our list, we'll inform\n\t// our connection manager about the disconnection. This can happen if we\n\t// process a peer's `done` message before its `add`.\n\tif !sp.Inbound() {\n\t\tif sp.persistent {\n\t\t\ts.connManager.Disconnect(sp.connReq.ID())\n\t\t} else {\n\t\t\ts.connManager.Remove(sp.connReq.ID())\n\t\t\tgo s.connManager.NewConnReq()\n\t\t}\n\t}\n\n\tif _, ok := list[sp.ID()]; ok {\n\t\tif !sp.Inbound() && sp.VersionKnown() {\n\t\t\tstate.outboundGroups[addrmgr.GroupKey(sp.NA())]--\n\t\t}\n\t\tdelete(list, sp.ID())\n\t\tsrvrLog.Debugf(\"Removed peer %s\", sp)\n\t\treturn\n\t}\n}\n\n// handleBanPeerMsg deals with banning peers.  It is invoked from the\n// peerHandler goroutine.\nfunc (s *server) handleBanPeerMsg(state *peerState, sp *serverPeer) {\n\thost, _, err := net.SplitHostPort(sp.Addr())\n\tif err != nil {\n\t\tsrvrLog.Debugf(\"can't split ban peer %s %v\", sp.Addr(), err)\n\t\treturn\n\t}\n\tdirection := directionString(sp.Inbound())\n\tsrvrLog.Infof(\"Banned peer %s (%s) for %v\", host, direction,\n\t\tcfg.BanDuration)\n\tstate.banned[host] = time.Now().Add(cfg.BanDuration)\n}\n\n// handleRelayInvMsg deals with relaying inventory to peers that are not already\n// known to have it.  It is invoked from the peerHandler goroutine.\nfunc (s *server) handleRelayInvMsg(state *peerState, msg relayMsg) {\n\tstate.forAllPeers(func(sp *serverPeer) {\n\t\tif !sp.Connected() {\n\t\t\treturn\n\t\t}\n\n\t\t// If the inventory is a block and the peer prefers headers,\n\t\t// generate and send a headers message instead of an inventory\n\t\t// message.\n\t\tif msg.invVect.Type == wire.InvTypeBlock && sp.WantsHeaders() {\n\t\t\tblockHeader, ok := msg.data.(wire.BlockHeader)\n\t\t\tif !ok {\n\t\t\t\tpeerLog.Warnf(\"Underlying data for headers\" +\n\t\t\t\t\t\" is not a block header\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tmsgHeaders := wire.NewMsgHeaders()\n\t\t\tif err := msgHeaders.AddBlockHeader(&blockHeader); err != nil {\n\t\t\t\tpeerLog.Errorf(\"Failed to add block\"+\n\t\t\t\t\t\" header: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tsp.QueueMessage(msgHeaders, nil)\n\t\t\treturn\n\t\t}\n\n\t\tif msg.invVect.Type == wire.InvTypeTx {\n\t\t\t// Don't relay the transaction to the peer when it has\n\t\t\t// transaction relaying disabled.\n\t\t\tif sp.relayTxDisabled() {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\ttxD, ok := msg.data.(*mempool.TxDesc)\n\t\t\tif !ok {\n\t\t\t\tpeerLog.Warnf(\"Underlying data for tx inv \"+\n\t\t\t\t\t\"relay is not a *mempool.TxDesc: %T\",\n\t\t\t\t\tmsg.data)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Don't relay the transaction if the transaction fee-per-kb\n\t\t\t// is less than the peer's feefilter.\n\t\t\tfeeFilter := atomic.LoadInt64(&sp.feeFilter)\n\t\t\tif feeFilter > 0 && txD.FeePerKB < feeFilter {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Don't relay the transaction if there is a bloom\n\t\t\t// filter loaded and the transaction doesn't match it.\n\t\t\tif sp.filter.IsLoaded() {\n\t\t\t\tif !sp.filter.MatchTxAndUpdate(txD.Tx) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Queue the inventory to be relayed with the next batch.\n\t\t// It will be ignored if the peer is already known to\n\t\t// have the inventory.\n\t\tsp.QueueInventory(msg.invVect)\n\t})\n}\n\n// handleBroadcastMsg deals with broadcasting messages to peers.  It is invoked\n// from the peerHandler goroutine.\nfunc (s *server) handleBroadcastMsg(state *peerState, bmsg *broadcastMsg) {\n\tstate.forAllPeers(func(sp *serverPeer) {\n\t\tif !sp.Connected() {\n\t\t\treturn\n\t\t}\n\n\t\tfor _, ep := range bmsg.excludePeers {\n\t\t\tif sp == ep {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tsp.QueueMessage(bmsg.message, nil)\n\t})\n}\n\ntype getConnCountMsg struct {\n\treply chan int32\n}\n\ntype getPeersMsg struct {\n\treply chan []*serverPeer\n}\n\ntype getOutboundGroup struct {\n\tkey   string\n\treply chan int\n}\n\ntype getAddedNodesMsg struct {\n\treply chan []*serverPeer\n}\n\ntype disconnectNodeMsg struct {\n\tcmp   func(*serverPeer) bool\n\treply chan error\n}\n\ntype connectNodeMsg struct {\n\taddr      string\n\tpermanent bool\n\treply     chan error\n}\n\ntype removeNodeMsg struct {\n\tcmp   func(*serverPeer) bool\n\treply chan error\n}\n\n// handleQuery is the central handler for all queries and commands from other\n// goroutines related to peer state.\nfunc (s *server) handleQuery(state *peerState, querymsg interface{}) {\n\tswitch msg := querymsg.(type) {\n\tcase getConnCountMsg:\n\t\tnconnected := int32(0)\n\t\tstate.forAllPeers(func(sp *serverPeer) {\n\t\t\tif sp.Connected() {\n\t\t\t\tnconnected++\n\t\t\t}\n\t\t})\n\t\tmsg.reply <- nconnected\n\n\tcase getPeersMsg:\n\t\tpeers := make([]*serverPeer, 0, state.Count())\n\t\tstate.forAllPeers(func(sp *serverPeer) {\n\t\t\tif !sp.Connected() {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpeers = append(peers, sp)\n\t\t})\n\t\tmsg.reply <- peers\n\n\tcase connectNodeMsg:\n\t\t// TODO: duplicate oneshots?\n\t\t// Limit max number of total peers.\n\t\tif state.Count() >= cfg.MaxPeers {\n\t\t\tmsg.reply <- errors.New(\"max peers reached\")\n\t\t\treturn\n\t\t}\n\t\tfor _, peer := range state.persistentPeers {\n\t\t\tif peer.Addr() == msg.addr {\n\t\t\t\tif msg.permanent {\n\t\t\t\t\tmsg.reply <- errors.New(\"peer already connected\")\n\t\t\t\t} else {\n\t\t\t\t\tmsg.reply <- errors.New(\"peer exists as a permanent peer\")\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tnetAddr, err := addrStringToNetAddr(msg.addr)\n\t\tif err != nil {\n\t\t\tmsg.reply <- err\n\t\t\treturn\n\t\t}\n\n\t\t// TODO: if too many, nuke a non-perm peer.\n\t\tgo s.connManager.Connect(&connmgr.ConnReq{\n\t\t\tAddr:      netAddr,\n\t\t\tPermanent: msg.permanent,\n\t\t})\n\t\tmsg.reply <- nil\n\tcase removeNodeMsg:\n\t\tfound := disconnectPeer(state.persistentPeers, msg.cmp, func(sp *serverPeer) {\n\t\t\t// Keep group counts ok since we remove from\n\t\t\t// the list now.\n\t\t\tstate.outboundGroups[addrmgr.GroupKey(sp.NA())]--\n\t\t})\n\n\t\tif found {\n\t\t\tmsg.reply <- nil\n\t\t} else {\n\t\t\tmsg.reply <- errors.New(\"peer not found\")\n\t\t}\n\tcase getOutboundGroup:\n\t\tcount, ok := state.outboundGroups[msg.key]\n\t\tif ok {\n\t\t\tmsg.reply <- count\n\t\t} else {\n\t\t\tmsg.reply <- 0\n\t\t}\n\t// Request a list of the persistent (added) peers.\n\tcase getAddedNodesMsg:\n\t\t// Respond with a slice of the relevant peers.\n\t\tpeers := make([]*serverPeer, 0, len(state.persistentPeers))\n\t\tfor _, sp := range state.persistentPeers {\n\t\t\tpeers = append(peers, sp)\n\t\t}\n\t\tmsg.reply <- peers\n\tcase disconnectNodeMsg:\n\t\t// Check inbound peers. We pass a nil callback since we don't\n\t\t// require any additional actions on disconnect for inbound peers.\n\t\tfound := disconnectPeer(state.inboundPeers, msg.cmp, nil)\n\t\tif found {\n\t\t\tmsg.reply <- nil\n\t\t\treturn\n\t\t}\n\n\t\t// Check outbound peers.\n\t\tfound = disconnectPeer(state.outboundPeers, msg.cmp, func(sp *serverPeer) {\n\t\t\t// Keep group counts ok since we remove from\n\t\t\t// the list now.\n\t\t\tstate.outboundGroups[addrmgr.GroupKey(sp.NA())]--\n\t\t})\n\t\tif found {\n\t\t\t// If there are multiple outbound connections to the same\n\t\t\t// ip:port, continue disconnecting them all until no such\n\t\t\t// peers are found.\n\t\t\tfor found {\n\t\t\t\tfound = disconnectPeer(state.outboundPeers, msg.cmp, func(sp *serverPeer) {\n\t\t\t\t\tstate.outboundGroups[addrmgr.GroupKey(sp.NA())]--\n\t\t\t\t})\n\t\t\t}\n\t\t\tmsg.reply <- nil\n\t\t\treturn\n\t\t}\n\n\t\tmsg.reply <- errors.New(\"peer not found\")\n\t}\n}\n\n// disconnectPeer attempts to drop the connection of a targeted peer in the\n// passed peer list. Targets are identified via usage of the passed\n// `compareFunc`, which should return `true` if the passed peer is the target\n// peer. This function returns true on success and false if the peer is unable\n// to be located. If the peer is found, and the passed callback: `whenFound'\n// isn't nil, we call it with the peer as the argument before it is removed\n// from the peerList, and is disconnected from the server.\nfunc disconnectPeer(peerList map[int32]*serverPeer, compareFunc func(*serverPeer) bool, whenFound func(*serverPeer)) bool {\n\tfor addr, peer := range peerList {\n\t\tif compareFunc(peer) {\n\t\t\tif whenFound != nil {\n\t\t\t\twhenFound(peer)\n\t\t\t}\n\n\t\t\t// This is ok because we are not continuing\n\t\t\t// to iterate so won't corrupt the loop.\n\t\t\tdelete(peerList, addr)\n\t\t\tpeer.Disconnect()\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// newPeerConfig returns the configuration for the given serverPeer.\nfunc newPeerConfig(sp *serverPeer) *peer.Config {\n\treturn &peer.Config{\n\t\tListeners: peer.MessageListeners{\n\t\t\tOnVersion:      sp.OnVersion,\n\t\t\tOnVerAck:       sp.OnVerAck,\n\t\t\tOnMemPool:      sp.OnMemPool,\n\t\t\tOnTx:           sp.OnTx,\n\t\t\tOnBlock:        sp.OnBlock,\n\t\t\tOnInv:          sp.OnInv,\n\t\t\tOnHeaders:      sp.OnHeaders,\n\t\t\tOnGetData:      sp.OnGetData,\n\t\t\tOnGetBlocks:    sp.OnGetBlocks,\n\t\t\tOnGetHeaders:   sp.OnGetHeaders,\n\t\t\tOnGetCFilters:  sp.OnGetCFilters,\n\t\t\tOnGetCFHeaders: sp.OnGetCFHeaders,\n\t\t\tOnGetCFCheckpt: sp.OnGetCFCheckpt,\n\t\t\tOnFeeFilter:    sp.OnFeeFilter,\n\t\t\tOnFilterAdd:    sp.OnFilterAdd,\n\t\t\tOnFilterClear:  sp.OnFilterClear,\n\t\t\tOnFilterLoad:   sp.OnFilterLoad,\n\t\t\tOnGetAddr:      sp.OnGetAddr,\n\t\t\tOnAddr:         sp.OnAddr,\n\t\t\tOnAddrV2:       sp.OnAddrV2,\n\t\t\tOnRead:         sp.OnRead,\n\t\t\tOnWrite:        sp.OnWrite,\n\t\t\tOnNotFound:     sp.OnNotFound,\n\n\t\t\t// Note: The reference client currently bans peers that send alerts\n\t\t\t// not signed with its key.  We could verify against their key, but\n\t\t\t// since the reference client is currently unwilling to support\n\t\t\t// other implementations' alert messages, we will not relay theirs.\n\t\t\tOnAlert: nil,\n\t\t},\n\t\tNewestBlock:         sp.newestBlock,\n\t\tHostToNetAddress:    sp.server.addrManager.HostToNetAddress,\n\t\tProxy:               cfg.Proxy,\n\t\tUserAgentName:       userAgentName,\n\t\tUserAgentVersion:    userAgentVersion,\n\t\tUserAgentComments:   cfg.UserAgentComments,\n\t\tChainParams:         sp.server.chainParams,\n\t\tServices:            sp.server.services,\n\t\tDisableRelayTx:      cfg.BlocksOnly,\n\t\tProtocolVersion:     peer.MaxProtocolVersion,\n\t\tTrickleInterval:     cfg.TrickleInterval,\n\t\tDisableStallHandler: cfg.DisableStallHandler,\n\t}\n}\n\n// inboundPeerConnected is invoked by the connection manager when a new inbound\n// connection is established.  It initializes a new inbound server peer\n// instance, associates it with the connection, and starts a goroutine to wait\n// for disconnection.\nfunc (s *server) inboundPeerConnected(conn net.Conn) {\n\tsp := newServerPeer(s, false)\n\tsp.isWhitelisted = isWhitelisted(conn.RemoteAddr())\n\tsp.Peer = peer.NewInboundPeer(newPeerConfig(sp))\n\tsp.AssociateConnection(conn)\n\tgo s.peerDoneHandler(sp)\n}\n\n// outboundPeerConnected is invoked by the connection manager when a new\n// outbound connection is established.  It initializes a new outbound server\n// peer instance, associates it with the relevant state such as the connection\n// request instance and the connection itself, and finally notifies the address\n// manager of the attempt.\nfunc (s *server) outboundPeerConnected(c *connmgr.ConnReq, conn net.Conn) {\n\tsp := newServerPeer(s, c.Permanent)\n\tp, err := peer.NewOutboundPeer(newPeerConfig(sp), c.Addr.String())\n\tif err != nil {\n\t\tsrvrLog.Debugf(\"Cannot create outbound peer %s: %v\", c.Addr, err)\n\t\tif c.Permanent {\n\t\t\ts.connManager.Disconnect(c.ID())\n\t\t} else {\n\t\t\ts.connManager.Remove(c.ID())\n\t\t\tgo s.connManager.NewConnReq()\n\t\t}\n\t\treturn\n\t}\n\tsp.Peer = p\n\tsp.connReq = c\n\tsp.isWhitelisted = isWhitelisted(conn.RemoteAddr())\n\tsp.AssociateConnection(conn)\n\tgo s.peerDoneHandler(sp)\n}\n\n// peerDoneHandler handles peer disconnects by notifying the server that it's\n// done along with other performing other desirable cleanup.\nfunc (s *server) peerDoneHandler(sp *serverPeer) {\n\tsp.WaitForDisconnect()\n\ts.donePeers <- sp\n\n\t// Only tell sync manager we are gone if we ever told it we existed.\n\tif sp.VerAckReceived() {\n\t\ts.syncManager.DonePeer(sp.Peer)\n\n\t\t// Evict any remaining orphans that were sent by the peer.\n\t\tnumEvicted := s.txMemPool.RemoveOrphansByTag(mempool.Tag(sp.ID()))\n\t\tif numEvicted > 0 {\n\t\t\ttxmpLog.Debugf(\"Evicted %d %s from peer %v (id %d)\",\n\t\t\t\tnumEvicted, pickNoun(numEvicted, \"orphan\",\n\t\t\t\t\t\"orphans\"), sp, sp.ID())\n\t\t}\n\t}\n\tclose(sp.quit)\n}\n\n// peerHandler is used to handle peer operations such as adding and removing\n// peers to and from the server, banning peers, and broadcasting messages to\n// peers.  It must be run in a goroutine.\nfunc (s *server) peerHandler() {\n\t// Start the address manager and sync manager, both of which are needed\n\t// by peers.  This is done here since their lifecycle is closely tied\n\t// to this handler and rather than adding more channels to synchronize\n\t// things, it's easier and slightly faster to simply start and stop them\n\t// in this handler.\n\ts.addrManager.Start()\n\ts.syncManager.Start()\n\n\tsrvrLog.Tracef(\"Starting peer handler\")\n\n\tstate := &peerState{\n\t\tinboundPeers:    make(map[int32]*serverPeer),\n\t\tpersistentPeers: make(map[int32]*serverPeer),\n\t\toutboundPeers:   make(map[int32]*serverPeer),\n\t\tbanned:          make(map[string]time.Time),\n\t\toutboundGroups:  make(map[string]int),\n\t}\n\n\tif !cfg.DisableDNSSeed {\n\t\t// Add peers discovered through DNS to the address manager.\n\t\tconnmgr.SeedFromDNS(activeNetParams.Params, defaultRequiredServices,\n\t\t\tbtcdLookup, func(addrs []*wire.NetAddressV2) {\n\t\t\t\t// Bitcoind uses a lookup of the dns seeder here. This\n\t\t\t\t// is rather strange since the values looked up by the\n\t\t\t\t// DNS seed lookups will vary quite a lot.\n\t\t\t\t// to replicate this behaviour we put all addresses as\n\t\t\t\t// having come from the first one.\n\t\t\t\ts.addrManager.AddAddresses(addrs, addrs[0])\n\t\t\t})\n\t}\n\tgo s.connManager.Start()\n\nout:\n\tfor {\n\t\tselect {\n\t\t// New peers connected to the server.\n\t\tcase p := <-s.newPeers:\n\t\t\ts.handleAddPeerMsg(state, p)\n\n\t\t// Disconnected peers.\n\t\tcase p := <-s.donePeers:\n\t\t\ts.handleDonePeerMsg(state, p)\n\n\t\t// Block accepted in mainchain or orphan, update peer height.\n\t\tcase umsg := <-s.peerHeightsUpdate:\n\t\t\ts.handleUpdatePeerHeights(state, umsg)\n\n\t\t// Peer to ban.\n\t\tcase p := <-s.banPeers:\n\t\t\ts.handleBanPeerMsg(state, p)\n\n\t\t// New inventory to potentially be relayed to other peers.\n\t\tcase invMsg := <-s.relayInv:\n\t\t\ts.handleRelayInvMsg(state, invMsg)\n\n\t\t// Message to broadcast to all connected peers except those\n\t\t// which are excluded by the message.\n\t\tcase bmsg := <-s.broadcast:\n\t\t\ts.handleBroadcastMsg(state, &bmsg)\n\n\t\tcase qmsg := <-s.query:\n\t\t\ts.handleQuery(state, qmsg)\n\n\t\tcase <-s.quit:\n\t\t\t// Disconnect all peers on server shutdown.\n\t\t\tstate.forAllPeers(func(sp *serverPeer) {\n\t\t\t\tsrvrLog.Tracef(\"Shutdown peer %s\", sp)\n\t\t\t\tsp.Disconnect()\n\t\t\t})\n\t\t\tbreak out\n\t\t}\n\t}\n\n\ts.connManager.Stop()\n\ts.syncManager.Stop()\n\ts.addrManager.Stop()\n\n\t// Drain channels before exiting so nothing is left waiting around\n\t// to send.\ncleanup:\n\tfor {\n\t\tselect {\n\t\tcase <-s.newPeers:\n\t\tcase <-s.donePeers:\n\t\tcase <-s.peerHeightsUpdate:\n\t\tcase <-s.relayInv:\n\t\tcase <-s.broadcast:\n\t\tcase <-s.query:\n\t\tdefault:\n\t\t\tbreak cleanup\n\t\t}\n\t}\n\ts.wg.Done()\n\tsrvrLog.Tracef(\"Peer handler done\")\n}\n\n// AddPeer adds a new peer that has already been connected to the server.\nfunc (s *server) AddPeer(sp *serverPeer) {\n\ts.newPeers <- sp\n}\n\n// BanPeer bans a peer that has already been connected to the server by ip.\nfunc (s *server) BanPeer(sp *serverPeer) {\n\ts.banPeers <- sp\n}\n\n// RelayInventory relays the passed inventory vector to all connected peers\n// that are not already known to have it.\nfunc (s *server) RelayInventory(invVect *wire.InvVect, data interface{}) {\n\ts.relayInv <- relayMsg{invVect: invVect, data: data}\n}\n\n// BroadcastMessage sends msg to all peers currently connected to the server\n// except those in the passed peers to exclude.\nfunc (s *server) BroadcastMessage(msg wire.Message, exclPeers ...*serverPeer) {\n\t// XXX: Need to determine if this is an alert that has already been\n\t// broadcast and refrain from broadcasting again.\n\tbmsg := broadcastMsg{message: msg, excludePeers: exclPeers}\n\ts.broadcast <- bmsg\n}\n\n// ConnectedCount returns the number of currently connected peers.\nfunc (s *server) ConnectedCount() int32 {\n\treplyChan := make(chan int32)\n\n\ts.query <- getConnCountMsg{reply: replyChan}\n\n\treturn <-replyChan\n}\n\n// OutboundGroupCount returns the number of peers connected to the given\n// outbound group key.\nfunc (s *server) OutboundGroupCount(key string) int {\n\treplyChan := make(chan int)\n\ts.query <- getOutboundGroup{key: key, reply: replyChan}\n\treturn <-replyChan\n}\n\n// AddBytesSent adds the passed number of bytes to the total bytes sent counter\n// for the server.  It is safe for concurrent access.\nfunc (s *server) AddBytesSent(bytesSent uint64) {\n\tatomic.AddUint64(&s.bytesSent, bytesSent)\n}\n\n// AddBytesReceived adds the passed number of bytes to the total bytes received\n// counter for the server.  It is safe for concurrent access.\nfunc (s *server) AddBytesReceived(bytesReceived uint64) {\n\tatomic.AddUint64(&s.bytesReceived, bytesReceived)\n}\n\n// NetTotals returns the sum of all bytes received and sent across the network\n// for all peers.  It is safe for concurrent access.\nfunc (s *server) NetTotals() (uint64, uint64) {\n\treturn atomic.LoadUint64(&s.bytesReceived),\n\t\tatomic.LoadUint64(&s.bytesSent)\n}\n\n// UpdatePeerHeights updates the heights of all peers who have have announced\n// the latest connected main chain block, or a recognized orphan. These height\n// updates allow us to dynamically refresh peer heights, ensuring sync peer\n// selection has access to the latest block heights for each peer.\nfunc (s *server) UpdatePeerHeights(latestBlkHash *chainhash.Hash, latestHeight int32, updateSource *peer.Peer) {\n\ts.peerHeightsUpdate <- updatePeerHeightsMsg{\n\t\tnewHash:    latestBlkHash,\n\t\tnewHeight:  latestHeight,\n\t\toriginPeer: updateSource,\n\t}\n}\n\n// rebroadcastHandler keeps track of user submitted inventories that we have\n// sent out but have not yet made it into a block. We periodically rebroadcast\n// them in case our peers restarted or otherwise lost track of them.\nfunc (s *server) rebroadcastHandler() {\n\t// Wait 5 min before first tx rebroadcast.\n\ttimer := time.NewTimer(5 * time.Minute)\n\tpendingInvs := make(map[wire.InvVect]interface{})\n\nout:\n\tfor {\n\t\tselect {\n\t\tcase riv := <-s.modifyRebroadcastInv:\n\t\t\tswitch msg := riv.(type) {\n\t\t\t// Incoming InvVects are added to our map of RPC txs.\n\t\t\tcase broadcastInventoryAdd:\n\t\t\t\tpendingInvs[*msg.invVect] = msg.data\n\n\t\t\t// When an InvVect has been added to a block, we can\n\t\t\t// now remove it, if it was present.\n\t\t\tcase broadcastInventoryDel:\n\t\t\t\tdelete(pendingInvs, *msg)\n\t\t\t}\n\n\t\tcase <-timer.C:\n\t\t\t// Any inventory we have has not made it into a block\n\t\t\t// yet. We periodically resubmit them until they have.\n\t\t\tfor iv, data := range pendingInvs {\n\t\t\t\tivCopy := iv\n\t\t\t\ts.RelayInventory(&ivCopy, data)\n\t\t\t}\n\n\t\t\t// Process at a random time up to 30mins (in seconds)\n\t\t\t// in the future.\n\t\t\ttimer.Reset(time.Second *\n\t\t\t\ttime.Duration(randomUint16Number(1800)))\n\n\t\tcase <-s.quit:\n\t\t\tbreak out\n\t\t}\n\t}\n\n\ttimer.Stop()\n\n\t// Drain channels before exiting so nothing is left waiting around\n\t// to send.\ncleanup:\n\tfor {\n\t\tselect {\n\t\tcase <-s.modifyRebroadcastInv:\n\t\tdefault:\n\t\t\tbreak cleanup\n\t\t}\n\t}\n\ts.wg.Done()\n}\n\n// Start begins accepting connections from peers.\nfunc (s *server) Start() {\n\t// Already started?\n\tif atomic.AddInt32(&s.started, 1) != 1 {\n\t\treturn\n\t}\n\n\tsrvrLog.Trace(\"Starting server\")\n\n\t// Server startup time. Used for the uptime command for uptime calculation.\n\ts.startupTime = time.Now().Unix()\n\n\t// Start the peer handler which in turn starts the address and block\n\t// managers.\n\ts.wg.Add(1)\n\tgo s.peerHandler()\n\n\tif s.nat != nil {\n\t\ts.wg.Add(1)\n\t\tgo s.upnpUpdateThread()\n\t}\n\n\tif !cfg.DisableRPC {\n\t\ts.wg.Add(1)\n\n\t\t// Start the rebroadcastHandler, which ensures user tx received by\n\t\t// the RPC server are rebroadcast until being included in a block.\n\t\tgo s.rebroadcastHandler()\n\n\t\ts.rpcServer.cfg.StartupTime = s.startupTime\n\t\ts.rpcServer.Start()\n\t}\n\n\t// Start the CPU miner if generation is enabled.\n\tif cfg.Generate {\n\t\ts.cpuMiner.Start()\n\t}\n}\n\n// Stop gracefully shuts down the server by stopping and disconnecting all\n// peers and the main listener.\nfunc (s *server) Stop() error {\n\t// Make sure this only happens once.\n\tif atomic.AddInt32(&s.shutdown, 1) != 1 {\n\t\tsrvrLog.Infof(\"Server is already in the process of shutting down\")\n\t\treturn nil\n\t}\n\n\tsrvrLog.Warnf(\"Server shutting down\")\n\n\t// Stop the CPU miner if needed\n\ts.cpuMiner.Stop()\n\n\t// Shutdown the RPC server if it's not disabled.\n\tif !cfg.DisableRPC {\n\t\ts.rpcServer.Stop()\n\t}\n\n\t// Save fee estimator state in the database.\n\ts.db.Update(func(tx database.Tx) error {\n\t\tmetadata := tx.Metadata()\n\t\tmetadata.Put(mempool.EstimateFeeDatabaseKey, s.feeEstimator.Save())\n\n\t\treturn nil\n\t})\n\n\t// Signal the remaining goroutines to quit.\n\tclose(s.quit)\n\treturn nil\n}\n\n// WaitForShutdown blocks until the main listener and peer handlers are stopped.\nfunc (s *server) WaitForShutdown() {\n\ts.wg.Wait()\n}\n\n// ScheduleShutdown schedules a server shutdown after the specified duration.\n// It also dynamically adjusts how often to warn the server is going down based\n// on remaining duration.\nfunc (s *server) ScheduleShutdown(duration time.Duration) {\n\t// Don't schedule shutdown more than once.\n\tif atomic.AddInt32(&s.shutdownSched, 1) != 1 {\n\t\treturn\n\t}\n\tsrvrLog.Warnf(\"Server shutdown in %v\", duration)\n\tgo func() {\n\t\tremaining := duration\n\t\ttickDuration := dynamicTickDuration(remaining)\n\t\tdone := time.After(remaining)\n\t\tticker := time.NewTicker(tickDuration)\n\tout:\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-done:\n\t\t\t\tticker.Stop()\n\t\t\t\ts.Stop()\n\t\t\t\tbreak out\n\t\t\tcase <-ticker.C:\n\t\t\t\tremaining = remaining - tickDuration\n\t\t\t\tif remaining < time.Second {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Change tick duration dynamically based on remaining time.\n\t\t\t\tnewDuration := dynamicTickDuration(remaining)\n\t\t\t\tif tickDuration != newDuration {\n\t\t\t\t\ttickDuration = newDuration\n\t\t\t\t\tticker.Stop()\n\t\t\t\t\tticker = time.NewTicker(tickDuration)\n\t\t\t\t}\n\t\t\t\tsrvrLog.Warnf(\"Server shutdown in %v\", remaining)\n\t\t\t}\n\t\t}\n\t}()\n}\n\n// parseListeners determines whether each listen address is IPv4 and IPv6 and\n// returns a slice of appropriate net.Addrs to listen on with TCP. It also\n// properly detects addresses which apply to \"all interfaces\" and adds the\n// address as both IPv4 and IPv6.\nfunc parseListeners(addrs []string) ([]net.Addr, error) {\n\tnetAddrs := make([]net.Addr, 0, len(addrs)*2)\n\tfor _, addr := range addrs {\n\t\thost, _, err := net.SplitHostPort(addr)\n\t\tif err != nil {\n\t\t\t// Shouldn't happen due to already being normalized.\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Empty host or host of * on plan9 is both IPv4 and IPv6.\n\t\tif host == \"\" || (host == \"*\" && runtime.GOOS == \"plan9\") {\n\t\t\tnetAddrs = append(netAddrs, simpleAddr{net: \"tcp4\", addr: addr})\n\t\t\tnetAddrs = append(netAddrs, simpleAddr{net: \"tcp6\", addr: addr})\n\t\t\tcontinue\n\t\t}\n\n\t\t// Strip IPv6 zone id if present since net.ParseIP does not\n\t\t// handle it.\n\t\tzoneIndex := strings.LastIndex(host, \"%\")\n\t\tif zoneIndex > 0 {\n\t\t\thost = host[:zoneIndex]\n\t\t}\n\n\t\t// Parse the IP.\n\t\tip := net.ParseIP(host)\n\t\tif ip == nil {\n\t\t\treturn nil, fmt.Errorf(\"'%s' is not a valid IP address\", host)\n\t\t}\n\n\t\t// To4 returns nil when the IP is not an IPv4 address, so use\n\t\t// this determine the address type.\n\t\tif ip.To4() == nil {\n\t\t\tnetAddrs = append(netAddrs, simpleAddr{net: \"tcp6\", addr: addr})\n\t\t} else {\n\t\t\tnetAddrs = append(netAddrs, simpleAddr{net: \"tcp4\", addr: addr})\n\t\t}\n\t}\n\treturn netAddrs, nil\n}\n\nfunc (s *server) upnpUpdateThread() {\n\t// Go off immediately to prevent code duplication, thereafter we renew\n\t// lease every 15 minutes.\n\ttimer := time.NewTimer(0 * time.Second)\n\tlport, _ := strconv.ParseInt(activeNetParams.DefaultPort, 10, 16)\n\tfirst := true\nout:\n\tfor {\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\t// TODO: pick external port  more cleverly\n\t\t\t// TODO: know which ports we are listening to on an external net.\n\t\t\t// TODO: if specific listen port doesn't work then ask for wildcard\n\t\t\t// listen port?\n\t\t\t// XXX this assumes timeout is in seconds.\n\t\t\tlistenPort, err := s.nat.AddPortMapping(\"tcp\", int(lport), int(lport),\n\t\t\t\t\"btcd listen port\", 20*60)\n\t\t\tif err != nil {\n\t\t\t\tsrvrLog.Warnf(\"can't add UPnP port mapping: %v\", err)\n\t\t\t}\n\t\t\tif first && err == nil {\n\t\t\t\t// TODO: look this up periodically to see if upnp domain changed\n\t\t\t\t// and so did ip.\n\t\t\t\texternalip, err := s.nat.GetExternalAddress()\n\t\t\t\tif err != nil {\n\t\t\t\t\tsrvrLog.Warnf(\"UPnP can't get external address: %v\", err)\n\t\t\t\t\tcontinue out\n\t\t\t\t}\n\t\t\t\tna := wire.NetAddressV2FromBytes(time.Now(), s.services,\n\t\t\t\t\texternalip, uint16(listenPort))\n\t\t\t\terr = s.addrManager.AddLocalAddress(na, addrmgr.UpnpPrio)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// XXX DeletePortMapping?\n\t\t\t\t}\n\t\t\t\tsrvrLog.Warnf(\"Successfully bound via UPnP to %s\", addrmgr.NetAddressKey(na))\n\t\t\t\tfirst = false\n\t\t\t}\n\t\t\ttimer.Reset(time.Minute * 15)\n\t\tcase <-s.quit:\n\t\t\tbreak out\n\t\t}\n\t}\n\n\ttimer.Stop()\n\n\tif err := s.nat.DeletePortMapping(\"tcp\", int(lport), int(lport)); err != nil {\n\t\tsrvrLog.Warnf(\"unable to remove UPnP port mapping: %v\", err)\n\t} else {\n\t\tsrvrLog.Debugf(\"successfully disestablished UPnP port mapping\")\n\t}\n\n\ts.wg.Done()\n}\n\n// setupRPCListeners returns a slice of listeners that are configured for use\n// with the RPC server depending on the configuration settings for listen\n// addresses and TLS.\nfunc setupRPCListeners() ([]net.Listener, error) {\n\t// Setup TLS if not disabled.\n\tlistenFunc := net.Listen\n\tif !cfg.DisableTLS {\n\t\t// Generate the TLS cert and key file if both don't already\n\t\t// exist.\n\t\tif !fileExists(cfg.RPCKey) && !fileExists(cfg.RPCCert) {\n\t\t\terr := genCertPair(cfg.RPCCert, cfg.RPCKey)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tkeypair, err := tls.LoadX509KeyPair(cfg.RPCCert, cfg.RPCKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\ttlsConfig := tls.Config{\n\t\t\tCertificates: []tls.Certificate{keypair},\n\t\t\tMinVersion:   tls.VersionTLS12,\n\t\t}\n\n\t\t// Change the standard net.Listen function to the tls one.\n\t\tlistenFunc = func(net string, laddr string) (net.Listener, error) {\n\t\t\treturn tls.Listen(net, laddr, &tlsConfig)\n\t\t}\n\t}\n\n\tnetAddrs, err := parseListeners(cfg.RPCListeners)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlisteners := make([]net.Listener, 0, len(netAddrs))\n\tfor _, addr := range netAddrs {\n\t\tlistener, err := listenFunc(addr.Network(), addr.String())\n\t\tif err != nil {\n\t\t\trpcsLog.Warnf(\"Can't listen on %s: %v\", addr, err)\n\t\t\tcontinue\n\t\t}\n\t\tlisteners = append(listeners, listener)\n\t}\n\n\treturn listeners, nil\n}\n\n// newServer returns a new btcd server configured to listen on addr for the\n// bitcoin network type specified by chainParams.  Use start to begin accepting\n// connections from peers.\nfunc newServer(listenAddrs, agentBlacklist, agentWhitelist []string,\n\tdb database.DB, chainParams *chaincfg.Params,\n\tinterrupt <-chan struct{}) (*server, error) {\n\n\tservices := defaultServices\n\tif cfg.NoPeerBloomFilters {\n\t\tservices &^= wire.SFNodeBloom\n\t}\n\tif cfg.NoCFilters {\n\t\tservices &^= wire.SFNodeCF\n\t}\n\tif cfg.Prune != 0 {\n\t\tservices &^= wire.SFNodeNetwork\n\t}\n\n\tamgr := addrmgr.New(cfg.DataDir, btcdLookup)\n\n\tvar listeners []net.Listener\n\tvar nat NAT\n\tif !cfg.DisableListen {\n\t\tvar err error\n\t\tlisteners, nat, err = initListeners(amgr, listenAddrs, services)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif len(listeners) == 0 {\n\t\t\treturn nil, errors.New(\"no valid listen address\")\n\t\t}\n\t}\n\n\tif len(agentBlacklist) > 0 {\n\t\tsrvrLog.Infof(\"User-agent blacklist %s\", agentBlacklist)\n\t}\n\tif len(agentWhitelist) > 0 {\n\t\tsrvrLog.Infof(\"User-agent whitelist %s\", agentWhitelist)\n\t}\n\n\ts := server{\n\t\tchainParams:          chainParams,\n\t\taddrManager:          amgr,\n\t\tnewPeers:             make(chan *serverPeer, cfg.MaxPeers),\n\t\tdonePeers:            make(chan *serverPeer, cfg.MaxPeers),\n\t\tbanPeers:             make(chan *serverPeer, cfg.MaxPeers),\n\t\tquery:                make(chan interface{}),\n\t\trelayInv:             make(chan relayMsg, cfg.MaxPeers),\n\t\tbroadcast:            make(chan broadcastMsg, cfg.MaxPeers),\n\t\tquit:                 make(chan struct{}),\n\t\tmodifyRebroadcastInv: make(chan interface{}),\n\t\tpeerHeightsUpdate:    make(chan updatePeerHeightsMsg),\n\t\tnat:                  nat,\n\t\tdb:                   db,\n\t\ttimeSource:           blockchain.NewMedianTime(),\n\t\tservices:             services,\n\t\tsigCache:             txscript.NewSigCache(cfg.SigCacheMaxSize),\n\t\thashCache:            txscript.NewHashCache(cfg.SigCacheMaxSize),\n\t\tcfCheckptCaches:      make(map[wire.FilterType][]cfHeaderKV),\n\t\tagentBlacklist:       agentBlacklist,\n\t\tagentWhitelist:       agentWhitelist,\n\t}\n\n\t// Create the transaction and address indexes if needed.\n\t//\n\t// CAUTION: the txindex needs to be first in the indexes array because\n\t// the addrindex uses data from the txindex during catchup.  If the\n\t// addrindex is run first, it may not have the transactions from the\n\t// current block indexed.\n\tvar indexes []indexers.Indexer\n\tif cfg.TxIndex || cfg.AddrIndex {\n\t\t// Enable transaction index if address index is enabled since it\n\t\t// requires it.\n\t\tif !cfg.TxIndex {\n\t\t\tindxLog.Infof(\"Transaction index enabled because it \" +\n\t\t\t\t\"is required by the address index\")\n\t\t\tcfg.TxIndex = true\n\t\t} else {\n\t\t\tindxLog.Info(\"Transaction index is enabled\")\n\t\t}\n\n\t\ts.txIndex = indexers.NewTxIndex(db)\n\t\tindexes = append(indexes, s.txIndex)\n\t}\n\tif cfg.AddrIndex {\n\t\tindxLog.Info(\"Address index is enabled\")\n\t\ts.addrIndex = indexers.NewAddrIndex(db, chainParams)\n\t\tindexes = append(indexes, s.addrIndex)\n\t}\n\tif !cfg.NoCFilters {\n\t\tindxLog.Info(\"Committed filter index is enabled\")\n\t\ts.cfIndex = indexers.NewCfIndex(db, chainParams)\n\t\tindexes = append(indexes, s.cfIndex)\n\t}\n\n\t// Create an index manager if any of the optional indexes are enabled.\n\tvar indexManager blockchain.IndexManager\n\tif len(indexes) > 0 {\n\t\tindexManager = indexers.NewManager(db, indexes)\n\t}\n\n\t// Merge given checkpoints with the default ones unless they are disabled.\n\tvar checkpoints []chaincfg.Checkpoint\n\tif !cfg.DisableCheckpoints {\n\t\tcheckpoints = mergeCheckpoints(s.chainParams.Checkpoints, cfg.addCheckpoints)\n\t}\n\n\t// Log that the node is pruned.\n\tif cfg.Prune != 0 {\n\t\tbtcdLog.Infof(\"Prune set to %d MiB\", cfg.Prune)\n\t}\n\n\t// Create a new block chain instance with the appropriate configuration.\n\tvar err error\n\ts.chain, err = blockchain.New(&blockchain.Config{\n\t\tDB:               s.db,\n\t\tInterrupt:        interrupt,\n\t\tChainParams:      s.chainParams,\n\t\tCheckpoints:      checkpoints,\n\t\tTimeSource:       s.timeSource,\n\t\tSigCache:         s.sigCache,\n\t\tIndexManager:     indexManager,\n\t\tHashCache:        s.hashCache,\n\t\tPrune:            cfg.Prune * 1024 * 1024,\n\t\tUtxoCacheMaxSize: uint64(cfg.UtxoCacheMaxSizeMiB) * 1024 * 1024,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Search for a FeeEstimator state in the database. If none can be found\n\t// or if it cannot be loaded, create a new one.\n\tdb.Update(func(tx database.Tx) error {\n\t\tmetadata := tx.Metadata()\n\t\tfeeEstimationData := metadata.Get(mempool.EstimateFeeDatabaseKey)\n\t\tif feeEstimationData != nil {\n\t\t\t// delete it from the database so that we don't try to restore the\n\t\t\t// same thing again somehow.\n\t\t\tmetadata.Delete(mempool.EstimateFeeDatabaseKey)\n\n\t\t\t// If there is an error, log it and make a new fee estimator.\n\t\t\tvar err error\n\t\t\ts.feeEstimator, err = mempool.RestoreFeeEstimator(feeEstimationData)\n\n\t\t\tif err != nil {\n\t\t\t\tpeerLog.Errorf(\"Failed to restore fee estimator %v\", err)\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\n\t// If no feeEstimator has been found, or if the one that has been found\n\t// is behind somehow, create a new one and start over.\n\tif s.feeEstimator == nil || s.feeEstimator.LastKnownHeight() != s.chain.BestSnapshot().Height {\n\t\ts.feeEstimator = mempool.NewFeeEstimator(\n\t\t\tmempool.DefaultEstimateFeeMaxRollback,\n\t\t\tmempool.DefaultEstimateFeeMinRegisteredBlocks)\n\t}\n\n\ttxC := mempool.Config{\n\t\tPolicy: mempool.Policy{\n\t\t\tDisableRelayPriority: cfg.NoRelayPriority,\n\t\t\tAcceptNonStd:         cfg.RelayNonStd,\n\t\t\tFreeTxRelayLimit:     cfg.FreeTxRelayLimit,\n\t\t\tMaxOrphanTxs:         cfg.MaxOrphanTxs,\n\t\t\tMaxOrphanTxSize:      defaultMaxOrphanTxSize,\n\t\t\tMaxSigOpCostPerTx:    blockchain.MaxBlockSigOpsCost / 4,\n\t\t\tMinRelayTxFee:        cfg.minRelayTxFee,\n\t\t\tMaxTxVersion:         2,\n\t\t\tRejectReplacement:    cfg.RejectReplacement,\n\t\t},\n\t\tChainParams:    chainParams,\n\t\tFetchUtxoView:  s.chain.FetchUtxoView,\n\t\tBestHeight:     func() int32 { return s.chain.BestSnapshot().Height },\n\t\tMedianTimePast: func() time.Time { return s.chain.BestSnapshot().MedianTime },\n\t\tCalcSequenceLock: func(tx *btcutil.Tx, view *blockchain.UtxoViewpoint) (*blockchain.SequenceLock, error) {\n\t\t\treturn s.chain.CalcSequenceLock(tx, view, true)\n\t\t},\n\t\tIsDeploymentActive: s.chain.IsDeploymentActive,\n\t\tSigCache:           s.sigCache,\n\t\tHashCache:          s.hashCache,\n\t\tAddrIndex:          s.addrIndex,\n\t\tFeeEstimator:       s.feeEstimator,\n\t}\n\ts.txMemPool = mempool.New(&txC)\n\n\ts.syncManager, err = netsync.New(&netsync.Config{\n\t\tPeerNotifier:       &s,\n\t\tChain:              s.chain,\n\t\tTxMemPool:          s.txMemPool,\n\t\tChainParams:        s.chainParams,\n\t\tDisableCheckpoints: cfg.DisableCheckpoints,\n\t\tMaxPeers:           cfg.MaxPeers,\n\t\tFeeEstimator:       s.feeEstimator,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create the mining policy and block template generator based on the\n\t// configuration options.\n\t//\n\t// NOTE: The CPU miner relies on the mempool, so the mempool has to be\n\t// created before calling the function to create the CPU miner.\n\tpolicy := mining.Policy{\n\t\tBlockMinWeight:    cfg.BlockMinWeight,\n\t\tBlockMaxWeight:    cfg.BlockMaxWeight,\n\t\tBlockMinSize:      cfg.BlockMinSize,\n\t\tBlockMaxSize:      cfg.BlockMaxSize,\n\t\tBlockPrioritySize: cfg.BlockPrioritySize,\n\t\tTxMinFreeFee:      cfg.minRelayTxFee,\n\t}\n\tblockTemplateGenerator := mining.NewBlkTmplGenerator(&policy,\n\t\ts.chainParams, s.txMemPool, s.chain, s.timeSource,\n\t\ts.sigCache, s.hashCache)\n\ts.cpuMiner = cpuminer.New(&cpuminer.Config{\n\t\tChainParams:            chainParams,\n\t\tBlockTemplateGenerator: blockTemplateGenerator,\n\t\tMiningAddrs:            cfg.miningAddrs,\n\t\tProcessBlock:           s.syncManager.ProcessBlock,\n\t\tConnectedCount:         s.ConnectedCount,\n\t\tIsCurrent:              s.syncManager.IsCurrent,\n\t})\n\n\t// Only setup a function to return new addresses to connect to when\n\t// not running in connect-only mode.  The simulation network is always\n\t// in connect-only mode since it is only intended to connect to\n\t// specified peers and actively avoid advertising and connecting to\n\t// discovered peers in order to prevent it from becoming a public test\n\t// network.\n\tvar newAddressFunc func() (net.Addr, error)\n\tif !cfg.SimNet && len(cfg.ConnectPeers) == 0 {\n\t\tnewAddressFunc = func() (net.Addr, error) {\n\t\t\tfor tries := 0; tries < 100; tries++ {\n\t\t\t\taddr := s.addrManager.GetAddress()\n\t\t\t\tif addr == nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Address will not be invalid, local or unroutable\n\t\t\t\t// because addrmanager rejects those on addition.\n\t\t\t\t// Just check that we don't already have an address\n\t\t\t\t// in the same group so that we are not connecting\n\t\t\t\t// to the same network segment at the expense of\n\t\t\t\t// others.\n\t\t\t\tkey := addrmgr.GroupKey(addr.NetAddress())\n\t\t\t\tif s.OutboundGroupCount(key) != 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// only allow recent nodes (10mins) after we failed 30\n\t\t\t\t// times\n\t\t\t\tif tries < 30 && time.Since(addr.LastAttempt()) < 10*time.Minute {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// allow nondefault ports after 50 failed tries.\n\t\t\t\tif tries < 50 && fmt.Sprintf(\"%d\", addr.NetAddress().Port) !=\n\t\t\t\t\tactiveNetParams.DefaultPort {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Mark an attempt for the valid address.\n\t\t\t\ts.addrManager.Attempt(addr.NetAddress())\n\n\t\t\t\taddrString := addrmgr.NetAddressKey(addr.NetAddress())\n\t\t\t\treturn addrStringToNetAddr(addrString)\n\t\t\t}\n\n\t\t\treturn nil, errors.New(\"no valid connect address\")\n\t\t}\n\t}\n\n\t// Create a connection manager.\n\ttargetOutbound := defaultTargetOutbound\n\tif cfg.MaxPeers < targetOutbound {\n\t\ttargetOutbound = cfg.MaxPeers\n\t}\n\tcmgr, err := connmgr.New(&connmgr.Config{\n\t\tListeners:      listeners,\n\t\tOnAccept:       s.inboundPeerConnected,\n\t\tRetryDuration:  connectionRetryInterval,\n\t\tTargetOutbound: uint32(targetOutbound),\n\t\tDial:           btcdDial,\n\t\tOnConnection:   s.outboundPeerConnected,\n\t\tGetNewAddress:  newAddressFunc,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ts.connManager = cmgr\n\n\t// Start up persistent peers.\n\tpermanentPeers := cfg.ConnectPeers\n\tif len(permanentPeers) == 0 {\n\t\tpermanentPeers = cfg.AddPeers\n\t}\n\tfor _, addr := range permanentPeers {\n\t\tnetAddr, err := addrStringToNetAddr(addr)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tgo s.connManager.Connect(&connmgr.ConnReq{\n\t\t\tAddr:      netAddr,\n\t\t\tPermanent: true,\n\t\t})\n\t}\n\n\tif !cfg.DisableRPC {\n\t\t// Setup listeners for the configured RPC listen addresses and\n\t\t// TLS settings.\n\t\trpcListeners, err := setupRPCListeners()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif len(rpcListeners) == 0 {\n\t\t\treturn nil, errors.New(\"RPCS: No valid listen address\")\n\t\t}\n\n\t\ts.rpcServer, err = newRPCServer(&rpcserverConfig{\n\t\t\tListeners:    rpcListeners,\n\t\t\tStartupTime:  s.startupTime,\n\t\t\tConnMgr:      &rpcConnManager{&s},\n\t\t\tSyncMgr:      &rpcSyncMgr{&s, s.syncManager},\n\t\t\tTimeSource:   s.timeSource,\n\t\t\tChain:        s.chain,\n\t\t\tChainParams:  chainParams,\n\t\t\tDB:           db,\n\t\t\tTxMemPool:    s.txMemPool,\n\t\t\tGenerator:    blockTemplateGenerator,\n\t\t\tCPUMiner:     s.cpuMiner,\n\t\t\tTxIndex:      s.txIndex,\n\t\t\tAddrIndex:    s.addrIndex,\n\t\t\tCfIndex:      s.cfIndex,\n\t\t\tFeeEstimator: s.feeEstimator,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Signal process shutdown when the RPC server requests it.\n\t\tgo func() {\n\t\t\t<-s.rpcServer.RequestedProcessShutdown()\n\t\t\tshutdownRequestChannel <- struct{}{}\n\t\t}()\n\t}\n\n\treturn &s, nil\n}\n\n// initListeners initializes the configured net listeners and adds any bound\n// addresses to the address manager. Returns the listeners and a NAT interface,\n// which is non-nil if UPnP is in use.\nfunc initListeners(amgr *addrmgr.AddrManager, listenAddrs []string, services wire.ServiceFlag) ([]net.Listener, NAT, error) {\n\t// Listen for TCP connections at the configured addresses\n\tnetAddrs, err := parseListeners(listenAddrs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlisteners := make([]net.Listener, 0, len(netAddrs))\n\tfor _, addr := range netAddrs {\n\t\tlistener, err := net.Listen(addr.Network(), addr.String())\n\t\tif err != nil {\n\t\t\tsrvrLog.Warnf(\"Can't listen on %s: %v\", addr, err)\n\t\t\tcontinue\n\t\t}\n\t\tlisteners = append(listeners, listener)\n\t}\n\n\tvar nat NAT\n\tif len(cfg.ExternalIPs) != 0 {\n\t\tdefaultPort, err := strconv.ParseUint(activeNetParams.DefaultPort, 10, 16)\n\t\tif err != nil {\n\t\t\tsrvrLog.Errorf(\"Can not parse default port %s for active chain: %v\",\n\t\t\t\tactiveNetParams.DefaultPort, err)\n\t\t\treturn nil, nil, err\n\t\t}\n\n\t\tfor _, sip := range cfg.ExternalIPs {\n\t\t\teport := uint16(defaultPort)\n\t\t\thost, portstr, err := net.SplitHostPort(sip)\n\t\t\tif err != nil {\n\t\t\t\t// no port, use default.\n\t\t\t\thost = sip\n\t\t\t} else {\n\t\t\t\tport, err := strconv.ParseUint(portstr, 10, 16)\n\t\t\t\tif err != nil {\n\t\t\t\t\tsrvrLog.Warnf(\"Can not parse port from %s for \"+\n\t\t\t\t\t\t\"externalip: %v\", sip, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\teport = uint16(port)\n\t\t\t}\n\t\t\tna, err := amgr.HostToNetAddress(host, eport, services)\n\t\t\tif err != nil {\n\t\t\t\tsrvrLog.Warnf(\"Not adding %s as externalip: %v\", sip, err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\terr = amgr.AddLocalAddress(na, addrmgr.ManualPrio)\n\t\t\tif err != nil {\n\t\t\t\tamgrLog.Warnf(\"Skipping specified external IP: %v\", err)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif cfg.Upnp {\n\t\t\tvar err error\n\t\t\tnat, err = Discover()\n\t\t\tif err != nil {\n\t\t\t\tsrvrLog.Warnf(\"Can't discover upnp: %v\", err)\n\t\t\t}\n\t\t\t// nil nat here is fine, just means no upnp on network.\n\t\t}\n\n\t\t// Add bound addresses to address manager to be advertised to peers.\n\t\tfor _, listener := range listeners {\n\t\t\taddr := listener.Addr().String()\n\t\t\terr := addLocalAddress(amgr, addr, services)\n\t\t\tif err != nil {\n\t\t\t\tamgrLog.Warnf(\"Skipping bound address %s: %v\", addr, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn listeners, nat, nil\n}\n\n// addrStringToNetAddr takes an address in the form of 'host:port' and returns\n// a net.Addr which maps to the original address with any host names resolved\n// to IP addresses.  It also handles tor addresses properly by returning a\n// net.Addr that encapsulates the address.\nfunc addrStringToNetAddr(addr string) (net.Addr, error) {\n\thost, strPort, err := net.SplitHostPort(addr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tport, err := strconv.Atoi(strPort)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Skip if host is already an IP address.\n\tif ip := net.ParseIP(host); ip != nil {\n\t\treturn &net.TCPAddr{\n\t\t\tIP:   ip,\n\t\t\tPort: port,\n\t\t}, nil\n\t}\n\n\t// Tor addresses cannot be resolved to an IP, so just return an onion\n\t// address instead.\n\tif strings.HasSuffix(host, \".onion\") {\n\t\tif cfg.NoOnion {\n\t\t\treturn nil, errors.New(\"tor has been disabled\")\n\t\t}\n\n\t\treturn &onionAddr{addr: addr}, nil\n\t}\n\n\t// Attempt to look up an IP address associated with the parsed host.\n\tips, err := btcdLookup(host)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(ips) == 0 {\n\t\treturn nil, fmt.Errorf(\"no addresses found for %s\", host)\n\t}\n\n\treturn &net.TCPAddr{\n\t\tIP:   ips[0],\n\t\tPort: port,\n\t}, nil\n}\n\n// addLocalAddress adds an address that this node is listening on to the\n// address manager so that it may be relayed to peers.\nfunc addLocalAddress(addrMgr *addrmgr.AddrManager, addr string, services wire.ServiceFlag) error {\n\thost, portStr, err := net.SplitHostPort(addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tport, err := strconv.ParseUint(portStr, 10, 16)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif ip := net.ParseIP(host); ip != nil && ip.IsUnspecified() {\n\t\t// If bound to unspecified address, advertise all local interfaces\n\t\taddrs, err := net.InterfaceAddrs()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfor _, addr := range addrs {\n\t\t\tifaceIP, _, err := net.ParseCIDR(addr.String())\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If bound to 0.0.0.0, do not add IPv6 interfaces and if bound to\n\t\t\t// ::, do not add IPv4 interfaces.\n\t\t\tif (ip.To4() == nil) != (ifaceIP.To4() == nil) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tnetAddr := wire.NetAddressV2FromBytes(\n\t\t\t\ttime.Now(), services, ifaceIP, uint16(port),\n\t\t\t)\n\t\t\taddrMgr.AddLocalAddress(netAddr, addrmgr.BoundPrio)\n\t\t}\n\t} else {\n\t\tnetAddr, err := addrMgr.HostToNetAddress(host, uint16(port), services)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\taddrMgr.AddLocalAddress(netAddr, addrmgr.BoundPrio)\n\t}\n\n\treturn nil\n}\n\n// dynamicTickDuration is a convenience function used to dynamically choose a\n// tick duration based on remaining time.  It is primarily used during\n// server shutdown to make shutdown warnings more frequent as the shutdown time\n// approaches.\nfunc dynamicTickDuration(remaining time.Duration) time.Duration {\n\tswitch {\n\tcase remaining <= time.Second*5:\n\t\treturn time.Second\n\tcase remaining <= time.Second*15:\n\t\treturn time.Second * 5\n\tcase remaining <= time.Minute:\n\t\treturn time.Second * 15\n\tcase remaining <= time.Minute*5:\n\t\treturn time.Minute\n\tcase remaining <= time.Minute*15:\n\t\treturn time.Minute * 5\n\tcase remaining <= time.Hour:\n\t\treturn time.Minute * 15\n\t}\n\treturn time.Hour\n}\n\n// isWhitelisted returns whether the IP address is included in the whitelisted\n// networks and IPs.\nfunc isWhitelisted(addr net.Addr) bool {\n\tif len(cfg.whitelists) == 0 {\n\t\treturn false\n\t}\n\n\thost, _, err := net.SplitHostPort(addr.String())\n\tif err != nil {\n\t\tsrvrLog.Warnf(\"Unable to SplitHostPort on '%s': %v\", addr, err)\n\t\treturn false\n\t}\n\tip := net.ParseIP(host)\n\tif ip == nil {\n\t\tsrvrLog.Warnf(\"Unable to parse IP '%s'\", addr)\n\t\treturn false\n\t}\n\n\tfor _, ipnet := range cfg.whitelists {\n\t\tif ipnet.Contains(ip) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// checkpointSorter implements sort.Interface to allow a slice of checkpoints to\n// be sorted.\ntype checkpointSorter []chaincfg.Checkpoint\n\n// Len returns the number of checkpoints in the slice.  It is part of the\n// sort.Interface implementation.\nfunc (s checkpointSorter) Len() int {\n\treturn len(s)\n}\n\n// Swap swaps the checkpoints at the passed indices.  It is part of the\n// sort.Interface implementation.\nfunc (s checkpointSorter) Swap(i, j int) {\n\ts[i], s[j] = s[j], s[i]\n}\n\n// Less returns whether the checkpoint with index i should sort before the\n// checkpoint with index j.  It is part of the sort.Interface implementation.\nfunc (s checkpointSorter) Less(i, j int) bool {\n\treturn s[i].Height < s[j].Height\n}\n\n// mergeCheckpoints returns two slices of checkpoints merged into one slice\n// such that the checkpoints are sorted by height.  In the case the additional\n// checkpoints contain a checkpoint with the same height as a checkpoint in the\n// default checkpoints, the additional checkpoint will take precedence and\n// overwrite the default one.\nfunc mergeCheckpoints(defaultCheckpoints, additional []chaincfg.Checkpoint) []chaincfg.Checkpoint {\n\t// Create a map of the additional checkpoints to remove duplicates while\n\t// leaving the most recently-specified checkpoint.\n\textra := make(map[int32]chaincfg.Checkpoint)\n\tfor _, checkpoint := range additional {\n\t\textra[checkpoint.Height] = checkpoint\n\t}\n\n\t// Add all default checkpoints that do not have an override in the\n\t// additional checkpoints.\n\tnumDefault := len(defaultCheckpoints)\n\tcheckpoints := make([]chaincfg.Checkpoint, 0, numDefault+len(extra))\n\tfor _, checkpoint := range defaultCheckpoints {\n\t\tif _, exists := extra[checkpoint.Height]; !exists {\n\t\t\tcheckpoints = append(checkpoints, checkpoint)\n\t\t}\n\t}\n\n\t// Append the additional checkpoints and return the sorted results.\n\tfor _, checkpoint := range extra {\n\t\tcheckpoints = append(checkpoints, checkpoint)\n\t}\n\tsort.Sort(checkpointSorter(checkpoints))\n\treturn checkpoints\n}\n\n// HasUndesiredUserAgent determines whether the server should continue to pursue\n// a connection with this peer based on its advertised user agent. It performs\n// the following steps:\n// 1) Reject the peer if it contains a blacklisted agent.\n// 2) If no whitelist is provided, accept all user agents.\n// 3) Accept the peer if it contains a whitelisted agent.\n// 4) Reject all other peers.\nfunc (sp *serverPeer) HasUndesiredUserAgent(blacklistedAgents,\n\twhitelistedAgents []string) bool {\n\n\tagent := sp.UserAgent()\n\n\t// First, if peer's user agent contains any blacklisted substring, we\n\t// will ignore the connection request.\n\tfor _, blacklistedAgent := range blacklistedAgents {\n\t\tif strings.Contains(agent, blacklistedAgent) {\n\t\t\tsrvrLog.Debugf(\"Ignoring peer %s, user agent \"+\n\t\t\t\t\"contains blacklisted user agent: %s\", sp,\n\t\t\t\tagent)\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// If no whitelist is provided, we will accept all user agents.\n\tif len(whitelistedAgents) == 0 {\n\t\treturn false\n\t}\n\n\t// Peer's user agent passed blacklist. Now check to see if it contains\n\t// one of our whitelisted user agents, if so accept.\n\tfor _, whitelistedAgent := range whitelistedAgents {\n\t\tif strings.Contains(agent, whitelistedAgent) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Otherwise, the peer's user agent was not included in our whitelist.\n\t// Ignore just in case it could stall the initial block download.\n\tsrvrLog.Debugf(\"Ignoring peer %s, user agent: %s not found in \"+\n\t\t\"whitelist\", sp, agent)\n\n\treturn true\n}\n"
        },
        {
          "name": "service_windows.go",
          "type": "blob",
          "size": 8.9765625,
          "content": "// Copyright (c) 2013-2016 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"time\"\n\n\t\"github.com/btcsuite/winsvc/eventlog\"\n\t\"github.com/btcsuite/winsvc/mgr\"\n\t\"github.com/btcsuite/winsvc/svc\"\n)\n\nconst (\n\t// svcName is the name of btcd service.\n\tsvcName = \"btcdsvc\"\n\n\t// svcDisplayName is the service name that will be shown in the windows\n\t// services list.  Not the svcName is the \"real\" name which is used\n\t// to control the service.  This is only for display purposes.\n\tsvcDisplayName = \"Btcd Service\"\n\n\t// svcDesc is the description of the service.\n\tsvcDesc = \"Downloads and stays synchronized with the bitcoin block \" +\n\t\t\"chain and provides chain services to applications.\"\n)\n\n// elog is used to send messages to the Windows event log.\nvar elog *eventlog.Log\n\n// logServiceStartOfDay logs information about btcd when the main server has\n// been started to the Windows event log.\nfunc logServiceStartOfDay(srvr *server) {\n\tvar message string\n\tmessage += fmt.Sprintf(\"Version %s\\n\", version())\n\tmessage += fmt.Sprintf(\"Configuration directory: %s\\n\", defaultHomeDir)\n\tmessage += fmt.Sprintf(\"Configuration file: %s\\n\", cfg.ConfigFile)\n\tmessage += fmt.Sprintf(\"Data directory: %s\\n\", cfg.DataDir)\n\n\telog.Info(1, message)\n}\n\n// btcdService houses the main service handler which handles all service\n// updates and launching btcdMain.\ntype btcdService struct{}\n\n// Execute is the main entry point the winsvc package calls when receiving\n// information from the Windows service control manager.  It launches the\n// long-running btcdMain (which is the real meat of btcd), handles service\n// change requests, and notifies the service control manager of changes.\nfunc (s *btcdService) Execute(args []string, r <-chan svc.ChangeRequest, changes chan<- svc.Status) (bool, uint32) {\n\t// Service start is pending.\n\tconst cmdsAccepted = svc.AcceptStop | svc.AcceptShutdown\n\tchanges <- svc.Status{State: svc.StartPending}\n\n\t// Start btcdMain in a separate goroutine so the service can start\n\t// quickly.  Shutdown (along with a potential error) is reported via\n\t// doneChan.  serverChan is notified with the main server instance once\n\t// it is started so it can be gracefully stopped.\n\tdoneChan := make(chan error)\n\tserverChan := make(chan *server)\n\tgo func() {\n\t\terr := btcdMain(serverChan)\n\t\tdoneChan <- err\n\t}()\n\n\t// Service is now started.\n\tchanges <- svc.Status{State: svc.Running, Accepts: cmdsAccepted}\n\n\tvar mainServer *server\nloop:\n\tfor {\n\t\tselect {\n\t\tcase c := <-r:\n\t\t\tswitch c.Cmd {\n\t\t\tcase svc.Interrogate:\n\t\t\t\tchanges <- c.CurrentStatus\n\n\t\t\tcase svc.Stop, svc.Shutdown:\n\t\t\t\t// Service stop is pending.  Don't accept any\n\t\t\t\t// more commands while pending.\n\t\t\t\tchanges <- svc.Status{State: svc.StopPending}\n\n\t\t\t\t// Signal the main function to exit.\n\t\t\t\tshutdownRequestChannel <- struct{}{}\n\n\t\t\tdefault:\n\t\t\t\telog.Error(1, fmt.Sprintf(\"Unexpected control \"+\n\t\t\t\t\t\"request #%d.\", c))\n\t\t\t}\n\n\t\tcase srvr := <-serverChan:\n\t\t\tmainServer = srvr\n\t\t\tlogServiceStartOfDay(mainServer)\n\n\t\tcase err := <-doneChan:\n\t\t\tif err != nil {\n\t\t\t\telog.Error(1, err.Error())\n\t\t\t}\n\t\t\tbreak loop\n\t\t}\n\t}\n\n\t// Service is now stopped.\n\tchanges <- svc.Status{State: svc.Stopped}\n\treturn false, 0\n}\n\n// installService attempts to install the btcd service.  Typically this should\n// be done by the msi installer, but it is provided here since it can be useful\n// for development.\nfunc installService() error {\n\t// Get the path of the current executable.  This is needed because\n\t// os.Args[0] can vary depending on how the application was launched.\n\t// For example, under cmd.exe it will only be the name of the app\n\t// without the path or extension, but under mingw it will be the full\n\t// path including the extension.\n\texePath, err := filepath.Abs(os.Args[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\tif filepath.Ext(exePath) == \"\" {\n\t\texePath += \".exe\"\n\t}\n\n\t// Connect to the windows service manager.\n\tserviceManager, err := mgr.Connect()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer serviceManager.Disconnect()\n\n\t// Ensure the service doesn't already exist.\n\tservice, err := serviceManager.OpenService(svcName)\n\tif err == nil {\n\t\tservice.Close()\n\t\treturn fmt.Errorf(\"service %s already exists\", svcName)\n\t}\n\n\t// Install the service.\n\tservice, err = serviceManager.CreateService(svcName, exePath, mgr.Config{\n\t\tDisplayName: svcDisplayName,\n\t\tDescription: svcDesc,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer service.Close()\n\n\t// Support events to the event log using the standard \"standard\" Windows\n\t// EventCreate.exe message file.  This allows easy logging of custom\n\t// messages instead of needing to create our own message catalog.\n\teventlog.Remove(svcName)\n\teventsSupported := uint32(eventlog.Error | eventlog.Warning | eventlog.Info)\n\treturn eventlog.InstallAsEventCreate(svcName, eventsSupported)\n}\n\n// removeService attempts to uninstall the btcd service.  Typically this should\n// be done by the msi uninstaller, but it is provided here since it can be\n// useful for development.  Not the eventlog entry is intentionally not removed\n// since it would invalidate any existing event log messages.\nfunc removeService() error {\n\t// Connect to the windows service manager.\n\tserviceManager, err := mgr.Connect()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer serviceManager.Disconnect()\n\n\t// Ensure the service exists.\n\tservice, err := serviceManager.OpenService(svcName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"service %s is not installed\", svcName)\n\t}\n\tdefer service.Close()\n\n\t// Remove the service.\n\treturn service.Delete()\n}\n\n// startService attempts to start the btcd service.\nfunc startService() error {\n\t// Connect to the windows service manager.\n\tserviceManager, err := mgr.Connect()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer serviceManager.Disconnect()\n\n\tservice, err := serviceManager.OpenService(svcName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not access service: %v\", err)\n\t}\n\tdefer service.Close()\n\n\terr = service.Start(os.Args)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not start service: %v\", err)\n\t}\n\n\treturn nil\n}\n\n// controlService allows commands which change the status of the service.  It\n// also waits for up to 10 seconds for the service to change to the passed\n// state.\nfunc controlService(c svc.Cmd, to svc.State) error {\n\t// Connect to the windows service manager.\n\tserviceManager, err := mgr.Connect()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer serviceManager.Disconnect()\n\n\tservice, err := serviceManager.OpenService(svcName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not access service: %v\", err)\n\t}\n\tdefer service.Close()\n\n\tstatus, err := service.Control(c)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not send control=%d: %v\", c, err)\n\t}\n\n\t// Send the control message.\n\ttimeout := time.Now().Add(10 * time.Second)\n\tfor status.State != to {\n\t\tif timeout.Before(time.Now()) {\n\t\t\treturn fmt.Errorf(\"timeout waiting for service to go \"+\n\t\t\t\t\"to state=%d\", to)\n\t\t}\n\t\ttime.Sleep(300 * time.Millisecond)\n\t\tstatus, err = service.Query()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not retrieve service \"+\n\t\t\t\t\"status: %v\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// performServiceCommand attempts to run one of the supported service commands\n// provided on the command line via the service command flag.  An appropriate\n// error is returned if an invalid command is specified.\nfunc performServiceCommand(command string) error {\n\tvar err error\n\tswitch command {\n\tcase \"install\":\n\t\terr = installService()\n\n\tcase \"remove\":\n\t\terr = removeService()\n\n\tcase \"start\":\n\t\terr = startService()\n\n\tcase \"stop\":\n\t\terr = controlService(svc.Stop, svc.Stopped)\n\n\tdefault:\n\t\terr = fmt.Errorf(\"invalid service command [%s]\", command)\n\t}\n\n\treturn err\n}\n\n// serviceMain checks whether we're being invoked as a service, and if so uses\n// the service control manager to start the long-running server.  A flag is\n// returned to the caller so the application can determine whether to exit (when\n// running as a service) or launch in normal interactive mode.\nfunc serviceMain() (bool, error) {\n\t// Don't run as a service if the user explicitly requested it. This is\n\t// needed to run btcd on Windows in CI environments like Travis.\n\t// We can't use the config struct to access the value because that's not\n\t// parsed yet. But we add the flag to the struct anyway so the parser\n\t// won't complain about it later.\n\tnoService := false\n\tfor _, arg := range os.Args {\n\t\tif arg == \"--nowinservice\" {\n\t\t\tnoService = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif noService {\n\t\treturn false, nil\n\t}\n\n\t// Don't run as a service if we're running interactively (or that can't\n\t// be determined due to an error).\n\tisInteractive, err := svc.IsAnInteractiveSession()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif isInteractive {\n\t\treturn false, nil\n\t}\n\n\telog, err = eventlog.Open(svcName)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tdefer elog.Close()\n\n\terr = svc.Run(svcName, &btcdService{})\n\tif err != nil {\n\t\telog.Error(1, fmt.Sprintf(\"Service start failed: %v\", err))\n\t\treturn true, err\n\t}\n\n\treturn true, nil\n}\n\n// Set windows specific functions to real functions.\nfunc init() {\n\trunServiceCommand = performServiceCommand\n\twinServiceMain = serviceMain\n}\n"
        },
        {
          "name": "signal.go",
          "type": "blob",
          "size": 2.01171875,
          "content": "// Copyright (c) 2013-2016 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"os\"\n\t\"os/signal\"\n)\n\n// shutdownRequestChannel is used to initiate shutdown from one of the\n// subsystems using the same code paths as when an interrupt signal is received.\nvar shutdownRequestChannel = make(chan struct{})\n\n// interruptSignals defines the default signals to catch in order to do a proper\n// shutdown.  This may be modified during init depending on the platform.\nvar interruptSignals = []os.Signal{os.Interrupt}\n\n// interruptListener listens for OS Signals such as SIGINT (Ctrl+C) and shutdown\n// requests from shutdownRequestChannel.  It returns a channel that is closed\n// when either signal is received.\nfunc interruptListener() <-chan struct{} {\n\tc := make(chan struct{})\n\tgo func() {\n\t\tinterruptChannel := make(chan os.Signal, 1)\n\t\tsignal.Notify(interruptChannel, interruptSignals...)\n\n\t\t// Listen for initial shutdown signal and close the returned\n\t\t// channel to notify the caller.\n\t\tselect {\n\t\tcase sig := <-interruptChannel:\n\t\t\tbtcdLog.Infof(\"Received signal (%s).  Shutting down...\",\n\t\t\t\tsig)\n\n\t\tcase <-shutdownRequestChannel:\n\t\t\tbtcdLog.Info(\"Shutdown requested.  Shutting down...\")\n\t\t}\n\t\tclose(c)\n\n\t\t// Listen for repeated signals and display a message so the user\n\t\t// knows the shutdown is in progress and the process is not\n\t\t// hung.\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase sig := <-interruptChannel:\n\t\t\t\tbtcdLog.Infof(\"Received signal (%s).  Already \"+\n\t\t\t\t\t\"shutting down...\", sig)\n\n\t\t\tcase <-shutdownRequestChannel:\n\t\t\t\tbtcdLog.Info(\"Shutdown requested.  Already \" +\n\t\t\t\t\t\"shutting down...\")\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn c\n}\n\n// interruptRequested returns true when the channel returned by\n// interruptListener was closed.  This simplifies early shutdown slightly since\n// the caller can just use an if statement instead of a select.\nfunc interruptRequested(interrupted <-chan struct{}) bool {\n\tselect {\n\tcase <-interrupted:\n\t\treturn true\n\tdefault:\n\t}\n\n\treturn false\n}\n"
        },
        {
          "name": "signalsigterm.go",
          "type": "blob",
          "size": 0.40625,
          "content": "// Copyright (c) 2016 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\n//go:build darwin || dragonfly || freebsd || linux || netbsd || openbsd || solaris\n// +build darwin dragonfly freebsd linux netbsd openbsd solaris\n\npackage main\n\nimport (\n\t\"os\"\n\t\"syscall\"\n)\n\nfunc init() {\n\tinterruptSignals = []os.Signal{os.Interrupt, syscall.SIGTERM}\n}\n"
        },
        {
          "name": "txscript",
          "type": "tree",
          "content": null
        },
        {
          "name": "upgrade.go",
          "type": "blob",
          "size": 5.1123046875,
          "content": "// Copyright (c) 2013-2014 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\n// dirEmpty returns whether or not the specified directory path is empty.\nfunc dirEmpty(dirPath string) (bool, error) {\n\tf, err := os.Open(dirPath)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tdefer f.Close()\n\n\t// Read the names of a max of one entry from the directory.  When the\n\t// directory is empty, an io.EOF error will be returned, so allow it.\n\tnames, err := f.Readdirnames(1)\n\tif err != nil && err != io.EOF {\n\t\treturn false, err\n\t}\n\n\treturn len(names) == 0, nil\n}\n\n// oldBtcdHomeDir returns the OS specific home directory btcd used prior to\n// version 0.3.3.  This has since been replaced with btcutil.AppDataDir, but\n// this function is still provided for the automatic upgrade path.\nfunc oldBtcdHomeDir() string {\n\t// Search for Windows APPDATA first.  This won't exist on POSIX OSes.\n\tappData := os.Getenv(\"APPDATA\")\n\tif appData != \"\" {\n\t\treturn filepath.Join(appData, \"btcd\")\n\t}\n\n\t// Fall back to standard HOME directory that works for most POSIX OSes.\n\thome := os.Getenv(\"HOME\")\n\tif home != \"\" {\n\t\treturn filepath.Join(home, \".btcd\")\n\t}\n\n\t// In the worst case, use the current directory.\n\treturn \".\"\n}\n\n// upgradeDBPathNet moves the database for a specific network from its\n// location prior to btcd version 0.2.0 and uses heuristics to ascertain the old\n// database type to rename to the new format.\nfunc upgradeDBPathNet(oldDbPath, netName string) error {\n\t// Prior to version 0.2.0, the database was named the same thing for\n\t// both sqlite and leveldb.  Use heuristics to figure out the type\n\t// of the database and move it to the new path and name introduced with\n\t// version 0.2.0 accordingly.\n\tfi, err := os.Stat(oldDbPath)\n\tif err == nil {\n\t\toldDbType := \"sqlite\"\n\t\tif fi.IsDir() {\n\t\t\toldDbType = \"leveldb\"\n\t\t}\n\n\t\t// The new database name is based on the database type and\n\t\t// resides in a directory named after the network type.\n\t\tnewDbRoot := filepath.Join(filepath.Dir(cfg.DataDir), netName)\n\t\tnewDbName := blockDbNamePrefix + \"_\" + oldDbType\n\t\tif oldDbType == \"sqlite\" {\n\t\t\tnewDbName = newDbName + \".db\"\n\t\t}\n\t\tnewDbPath := filepath.Join(newDbRoot, newDbName)\n\n\t\t// Create the new path if needed.\n\t\terr = os.MkdirAll(newDbRoot, 0700)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Move and rename the old database.\n\t\terr := os.Rename(oldDbPath, newDbPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// upgradeDBPaths moves the databases from their locations prior to btcd\n// version 0.2.0 to their new locations.\nfunc upgradeDBPaths() error {\n\t// Prior to version 0.2.0, the databases were in the \"db\" directory and\n\t// their names were suffixed by \"testnet\" and \"regtest\" for their\n\t// respective networks.  Check for the old database and update it to the\n\t// new path introduced with version 0.2.0 accordingly.\n\toldDbRoot := filepath.Join(oldBtcdHomeDir(), \"db\")\n\tupgradeDBPathNet(filepath.Join(oldDbRoot, \"btcd.db\"), \"mainnet\")\n\tupgradeDBPathNet(filepath.Join(oldDbRoot, \"btcd_testnet.db\"), \"testnet\")\n\tupgradeDBPathNet(filepath.Join(oldDbRoot, \"btcd_regtest.db\"), \"regtest\")\n\n\t// Remove the old db directory.\n\treturn os.RemoveAll(oldDbRoot)\n}\n\n// upgradeDataPaths moves the application data from its location prior to btcd\n// version 0.3.3 to its new location.\nfunc upgradeDataPaths() error {\n\t// No need to migrate if the old and new home paths are the same.\n\toldHomePath := oldBtcdHomeDir()\n\tnewHomePath := defaultHomeDir\n\tif oldHomePath == newHomePath {\n\t\treturn nil\n\t}\n\n\t// Only migrate if the old path exists and the new one doesn't.\n\tif fileExists(oldHomePath) && !fileExists(newHomePath) {\n\t\t// Create the new path.\n\t\tbtcdLog.Infof(\"Migrating application home path from '%s' to '%s'\",\n\t\t\toldHomePath, newHomePath)\n\t\terr := os.MkdirAll(newHomePath, 0700)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Move old btcd.conf into new location if needed.\n\t\toldConfPath := filepath.Join(oldHomePath, defaultConfigFilename)\n\t\tnewConfPath := filepath.Join(newHomePath, defaultConfigFilename)\n\t\tif fileExists(oldConfPath) && !fileExists(newConfPath) {\n\t\t\terr := os.Rename(oldConfPath, newConfPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Move old data directory into new location if needed.\n\t\toldDataPath := filepath.Join(oldHomePath, defaultDataDirname)\n\t\tnewDataPath := filepath.Join(newHomePath, defaultDataDirname)\n\t\tif fileExists(oldDataPath) && !fileExists(newDataPath) {\n\t\t\terr := os.Rename(oldDataPath, newDataPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Remove the old home if it is empty or show a warning if not.\n\t\tohpEmpty, err := dirEmpty(oldHomePath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif ohpEmpty {\n\t\t\terr := os.Remove(oldHomePath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tbtcdLog.Warnf(\"Not removing '%s' since it contains files \"+\n\t\t\t\t\"not created by this application.  You may \"+\n\t\t\t\t\"want to manually move them or delete them.\",\n\t\t\t\toldHomePath)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// doUpgrades performs upgrades to btcd as new versions require it.\nfunc doUpgrades() error {\n\terr := upgradeDBPaths()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn upgradeDataPaths()\n}\n"
        },
        {
          "name": "upnp.go",
          "type": "blob",
          "size": 12.9443359375,
          "content": "package main\n\n// Upnp code taken from Taipei Torrent license is below:\n// Copyright (c) 2010 Jack Palevich. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//    * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//    * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//    * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// Just enough UPnP to be able to forward ports\n//\n\nimport (\n\t\"bytes\"\n\t\"encoding/xml\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// NAT is an interface representing a NAT traversal options for example UPNP or\n// NAT-PMP. It provides methods to query and manipulate this traversal to allow\n// access to services.\ntype NAT interface {\n\t// Get the external address from outside the NAT.\n\tGetExternalAddress() (addr net.IP, err error)\n\t// Add a port mapping for protocol (\"udp\" or \"tcp\") from external port to\n\t// internal port with description lasting for timeout.\n\tAddPortMapping(protocol string, externalPort, internalPort int, description string, timeout int) (mappedExternalPort int, err error)\n\t// Remove a previously added port mapping from external port to\n\t// internal port.\n\tDeletePortMapping(protocol string, externalPort, internalPort int) (err error)\n}\n\ntype upnpNAT struct {\n\tserviceURL string\n\tourIP      string\n}\n\n// Discover searches the local network for a UPnP router returning a NAT\n// for the network if so, nil if not.\nfunc Discover() (nat NAT, err error) {\n\tssdp, err := net.ResolveUDPAddr(\"udp4\", \"239.255.255.250:1900\")\n\tif err != nil {\n\t\treturn\n\t}\n\tconn, err := net.ListenPacket(\"udp4\", \":0\")\n\tif err != nil {\n\t\treturn\n\t}\n\tsocket := conn.(*net.UDPConn)\n\tdefer socket.Close()\n\n\terr = socket.SetDeadline(time.Now().Add(3 * time.Second))\n\tif err != nil {\n\t\treturn\n\t}\n\n\tst := \"ST: urn:schemas-upnp-org:device:InternetGatewayDevice:1\\r\\n\"\n\tbuf := bytes.NewBufferString(\n\t\t\"M-SEARCH * HTTP/1.1\\r\\n\" +\n\t\t\t\"HOST: 239.255.255.250:1900\\r\\n\" +\n\t\t\tst +\n\t\t\t\"MAN: \\\"ssdp:discover\\\"\\r\\n\" +\n\t\t\t\"MX: 2\\r\\n\\r\\n\")\n\tmessage := buf.Bytes()\n\tanswerBytes := make([]byte, 1024)\n\tfor i := 0; i < 3; i++ {\n\t\t_, err = socket.WriteToUDP(message, ssdp)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tvar n int\n\t\tn, _, err = socket.ReadFromUDP(answerBytes)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t\t// socket.Close()\n\t\t\t// return\n\t\t}\n\t\tanswer := string(answerBytes[0:n])\n\t\tif !strings.Contains(answer, \"\\r\\n\"+st) {\n\t\t\tcontinue\n\t\t}\n\t\t// HTTP header field names are case-insensitive.\n\t\t// http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.2\n\t\tlocString := \"\\r\\nlocation: \"\n\t\tlocIndex := strings.Index(strings.ToLower(answer), locString)\n\t\tif locIndex < 0 {\n\t\t\tcontinue\n\t\t}\n\t\tloc := answer[locIndex+len(locString):]\n\t\tendIndex := strings.Index(loc, \"\\r\\n\")\n\t\tif endIndex < 0 {\n\t\t\tcontinue\n\t\t}\n\t\tlocURL := loc[0:endIndex]\n\t\tvar serviceURL string\n\t\tserviceURL, err = getServiceURL(locURL)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tvar ourIP string\n\t\tourIP, err = getOurIP()\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tnat = &upnpNAT{serviceURL: serviceURL, ourIP: ourIP}\n\t\treturn\n\t}\n\terr = errors.New(\"UPnP port discovery failed\")\n\treturn\n}\n\n// service represents the Service type in an UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype service struct {\n\tServiceType string `xml:\"serviceType\"`\n\tControlURL  string `xml:\"controlURL\"`\n}\n\n// deviceList represents the deviceList type in an UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype deviceList struct {\n\tXMLName xml.Name `xml:\"deviceList\"`\n\tDevice  []device `xml:\"device\"`\n}\n\n// serviceList represents the serviceList type in an UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype serviceList struct {\n\tXMLName xml.Name  `xml:\"serviceList\"`\n\tService []service `xml:\"service\"`\n}\n\n// device represents the device type in an UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype device struct {\n\tXMLName     xml.Name    `xml:\"device\"`\n\tDeviceType  string      `xml:\"deviceType\"`\n\tDeviceList  deviceList  `xml:\"deviceList\"`\n\tServiceList serviceList `xml:\"serviceList\"`\n}\n\n// specVersion represents the specVersion in a UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype specVersion struct {\n\tXMLName xml.Name `xml:\"specVersion\"`\n\tMajor   int      `xml:\"major\"`\n\tMinor   int      `xml:\"minor\"`\n}\n\n// root represents the Root document for a UPnP xml description.\n// Only the parts we care about are present and thus the xml may have more\n// fields than present in the structure.\ntype root struct {\n\tXMLName     xml.Name `xml:\"root\"`\n\tSpecVersion specVersion\n\tDevice      device\n}\n\n// getChildDevice searches the children of device for a device with the given\n// type.\nfunc getChildDevice(d *device, deviceType string) *device {\n\tfor i := range d.DeviceList.Device {\n\t\tif d.DeviceList.Device[i].DeviceType == deviceType {\n\t\t\treturn &d.DeviceList.Device[i]\n\t\t}\n\t}\n\treturn nil\n}\n\n// getChildService searches the service list of device for a service with the\n// given type.\nfunc getChildService(d *device, serviceType string) *service {\n\tfor i := range d.ServiceList.Service {\n\t\tif d.ServiceList.Service[i].ServiceType == serviceType {\n\t\t\treturn &d.ServiceList.Service[i]\n\t\t}\n\t}\n\treturn nil\n}\n\n// getOurIP returns a best guess at what the local IP is.\nfunc getOurIP() (ip string, err error) {\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\treturn\n\t}\n\treturn net.LookupCNAME(hostname)\n}\n\n// getServiceURL parses the xml description at the given root url to find the\n// url for the WANIPConnection service to be used for port forwarding.\nfunc getServiceURL(rootURL string) (url string, err error) {\n\tr, err := http.Get(rootURL)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer r.Body.Close()\n\tif r.StatusCode >= 400 {\n\t\terr = errors.New(fmt.Sprint(r.StatusCode))\n\t\treturn\n\t}\n\tvar root root\n\terr = xml.NewDecoder(r.Body).Decode(&root)\n\tif err != nil {\n\t\treturn\n\t}\n\ta := &root.Device\n\tif a.DeviceType != \"urn:schemas-upnp-org:device:InternetGatewayDevice:1\" {\n\t\terr = errors.New(\"no InternetGatewayDevice\")\n\t\treturn\n\t}\n\tb := getChildDevice(a, \"urn:schemas-upnp-org:device:WANDevice:1\")\n\tif b == nil {\n\t\terr = errors.New(\"no WANDevice\")\n\t\treturn\n\t}\n\tc := getChildDevice(b, \"urn:schemas-upnp-org:device:WANConnectionDevice:1\")\n\tif c == nil {\n\t\terr = errors.New(\"no WANConnectionDevice\")\n\t\treturn\n\t}\n\td := getChildService(c, \"urn:schemas-upnp-org:service:WANIPConnection:1\")\n\tif d == nil {\n\t\terr = errors.New(\"no WANIPConnection\")\n\t\treturn\n\t}\n\turl = combineURL(rootURL, d.ControlURL)\n\treturn\n}\n\n// combineURL appends subURL onto rootURL.\nfunc combineURL(rootURL, subURL string) string {\n\tprotocolEnd := \"://\"\n\tprotoEndIndex := strings.Index(rootURL, protocolEnd)\n\ta := rootURL[protoEndIndex+len(protocolEnd):]\n\trootIndex := strings.Index(a, \"/\")\n\treturn rootURL[0:protoEndIndex+len(protocolEnd)+rootIndex] + subURL\n}\n\n// soapBody represents the <s:Body> element in a SOAP reply.\n// fields we don't care about are elided.\ntype soapBody struct {\n\tXMLName xml.Name `xml:\"Body\"`\n\tData    []byte   `xml:\",innerxml\"`\n}\n\n// soapEnvelope represents the <s:Envelope> element in a SOAP reply.\n// fields we don't care about are elided.\ntype soapEnvelope struct {\n\tXMLName xml.Name `xml:\"Envelope\"`\n\tBody    soapBody `xml:\"Body\"`\n}\n\n// soapRequests performs a soap request with the given parameters and returns\n// the xml replied stripped of the soap headers. in the case that the request is\n// unsuccessful the an error is returned.\nfunc soapRequest(url, function, message string) (replyXML []byte, err error) {\n\tfullMessage := \"<?xml version=\\\"1.0\\\" ?>\" +\n\t\t\"<s:Envelope xmlns:s=\\\"http://schemas.xmlsoap.org/soap/envelope/\\\" s:encodingStyle=\\\"http://schemas.xmlsoap.org/soap/encoding/\\\">\\r\\n\" +\n\t\t\"<s:Body>\" + message + \"</s:Body></s:Envelope>\"\n\n\treq, err := http.NewRequest(\"POST\", url, strings.NewReader(fullMessage))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treq.Header.Set(\"Content-Type\", \"text/xml ; charset=\\\"utf-8\\\"\")\n\treq.Header.Set(\"User-Agent\", \"Darwin/10.0.0, UPnP/1.0, MiniUPnPc/1.3\")\n\treq.Header.Set(\"SOAPAction\", \"\\\"urn:schemas-upnp-org:service:WANIPConnection:1#\"+function+\"\\\"\")\n\treq.Header.Set(\"Connection\", \"Close\")\n\treq.Header.Set(\"Cache-Control\", \"no-cache\")\n\treq.Header.Set(\"Pragma\", \"no-cache\")\n\n\tr, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif r.Body != nil {\n\t\tdefer r.Body.Close()\n\t}\n\n\tif r.StatusCode >= 400 {\n\t\terr = errors.New(\"Error \" + strconv.Itoa(r.StatusCode) + \" for \" + function)\n\t\tr = nil\n\t\treturn\n\t}\n\tvar reply soapEnvelope\n\terr = xml.NewDecoder(r.Body).Decode(&reply)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn reply.Body.Data, nil\n}\n\n// getExternalIPAddressResponse represents the XML response to a\n// GetExternalIPAddress SOAP request.\ntype getExternalIPAddressResponse struct {\n\tXMLName           xml.Name `xml:\"GetExternalIPAddressResponse\"`\n\tExternalIPAddress string   `xml:\"NewExternalIPAddress\"`\n}\n\n// GetExternalAddress implements the NAT interface by fetching the external IP\n// from the UPnP router.\nfunc (n *upnpNAT) GetExternalAddress() (addr net.IP, err error) {\n\tmessage := \"<u:GetExternalIPAddress xmlns:u=\\\"urn:schemas-upnp-org:service:WANIPConnection:1\\\"/>\\r\\n\"\n\tresponse, err := soapRequest(n.serviceURL, \"GetExternalIPAddress\", message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar reply getExternalIPAddressResponse\n\terr = xml.Unmarshal(response, &reply)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\taddr = net.ParseIP(reply.ExternalIPAddress)\n\tif addr == nil {\n\t\treturn nil, errors.New(\"unable to parse ip address\")\n\t}\n\treturn addr, nil\n}\n\n// AddPortMapping implements the NAT interface by setting up a port forwarding\n// from the UPnP router to the local machine with the given ports and protocol.\nfunc (n *upnpNAT) AddPortMapping(protocol string, externalPort, internalPort int, description string, timeout int) (mappedExternalPort int, err error) {\n\t// A single concatenation would break ARM compilation.\n\tmessage := \"<u:AddPortMapping xmlns:u=\\\"urn:schemas-upnp-org:service:WANIPConnection:1\\\">\\r\\n\" +\n\t\t\"<NewRemoteHost></NewRemoteHost><NewExternalPort>\" + strconv.Itoa(externalPort)\n\tmessage += \"</NewExternalPort><NewProtocol>\" + strings.ToUpper(protocol) + \"</NewProtocol>\"\n\tmessage += \"<NewInternalPort>\" + strconv.Itoa(internalPort) + \"</NewInternalPort>\" +\n\t\t\"<NewInternalClient>\" + n.ourIP + \"</NewInternalClient>\" +\n\t\t\"<NewEnabled>1</NewEnabled><NewPortMappingDescription>\"\n\tmessage += description +\n\t\t\"</NewPortMappingDescription><NewLeaseDuration>\" + strconv.Itoa(timeout) +\n\t\t\"</NewLeaseDuration></u:AddPortMapping>\"\n\n\tresponse, err := soapRequest(n.serviceURL, \"AddPortMapping\", message)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// TODO: check response to see if the port was forwarded\n\t// If the port was not wildcard we don't get an reply with the port in\n\t// it. Not sure about wildcard yet. miniupnpc just checks for error\n\t// codes here.\n\tmappedExternalPort = externalPort\n\t_ = response\n\treturn\n}\n\n// DeletePortMapping implements the NAT interface by removing up a port forwarding\n// from the UPnP router to the local machine with the given ports and.\nfunc (n *upnpNAT) DeletePortMapping(protocol string, externalPort, internalPort int) (err error) {\n\n\tmessage := \"<u:DeletePortMapping xmlns:u=\\\"urn:schemas-upnp-org:service:WANIPConnection:1\\\">\\r\\n\" +\n\t\t\"<NewRemoteHost></NewRemoteHost><NewExternalPort>\" + strconv.Itoa(externalPort) +\n\t\t\"</NewExternalPort><NewProtocol>\" + strings.ToUpper(protocol) + \"</NewProtocol>\" +\n\t\t\"</u:DeletePortMapping>\"\n\n\tresponse, err := soapRequest(n.serviceURL, \"DeletePortMapping\", message)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// TODO: check response to see if the port was deleted\n\t// log.Println(message, response)\n\t_ = response\n\treturn\n}\n"
        },
        {
          "name": "version.go",
          "type": "blob",
          "size": 2.3857421875,
          "content": "// Copyright (c) 2013-2014 The btcsuite developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"strings\"\n)\n\n// semanticAlphabet\nconst semanticAlphabet = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-\"\n\n// These constants define the application version and follow the semantic\n// versioning 2.0.0 spec (http://semver.org/).\nconst (\n\tappMajor uint = 0\n\tappMinor uint = 24\n\tappPatch uint = 2\n\n\t// appPreRelease MUST only contain characters from semanticAlphabet\n\t// per the semantic versioning spec.\n\tappPreRelease = \"beta\"\n)\n\n// appBuild is defined as a variable so it can be overridden during the build\n// process with '-ldflags \"-X main.appBuild foo' if needed.  It MUST only\n// contain characters from semanticAlphabet per the semantic versioning spec.\nvar appBuild string\n\n// version returns the application version as a properly formed string per the\n// semantic versioning 2.0.0 spec (http://semver.org/).\nfunc version() string {\n\t// Start with the major, minor, and patch versions.\n\tversion := fmt.Sprintf(\"%d.%d.%d\", appMajor, appMinor, appPatch)\n\n\t// Append pre-release version if there is one.  The hyphen called for\n\t// by the semantic versioning spec is automatically appended and should\n\t// not be contained in the pre-release string.  The pre-release version\n\t// is not appended if it contains invalid characters.\n\tpreRelease := normalizeVerString(appPreRelease)\n\tif preRelease != \"\" {\n\t\tversion = fmt.Sprintf(\"%s-%s\", version, preRelease)\n\t}\n\n\t// Append build metadata if there is any.  The plus called for\n\t// by the semantic versioning spec is automatically appended and should\n\t// not be contained in the build metadata string.  The build metadata\n\t// string is not appended if it contains invalid characters.\n\tbuild := normalizeVerString(appBuild)\n\tif build != \"\" {\n\t\tversion = fmt.Sprintf(\"%s+%s\", version, build)\n\t}\n\n\treturn version\n}\n\n// normalizeVerString returns the passed string stripped of all characters which\n// are not valid according to the semantic versioning guidelines for pre-release\n// version and build metadata strings.  In particular they MUST only contain\n// characters in semanticAlphabet.\nfunc normalizeVerString(str string) string {\n\tvar result bytes.Buffer\n\tfor _, r := range str {\n\t\tif strings.ContainsRune(semanticAlphabet, r) {\n\t\t\tresult.WriteRune(r)\n\t\t}\n\t}\n\treturn result.String()\n}\n"
        },
        {
          "name": "wire",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}